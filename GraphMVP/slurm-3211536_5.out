>>> Starting run for dataset: hiv
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running RANDOM configs_split_experiments/GraphCL/hiv/random/train_prop=0.6.yml on cuda:0
Running RANDOM configs_split_experiments/GraphCL/hiv/random/train_prop=0.7.yml on cuda:1
Running RANDOM configs_split_experiments/GraphCL/hiv/random/train_prop=0.8.yml on cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/hiv/random/train_prop=0.8.yml --runseed 4 --device cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/hiv/random/train_prop=0.6.yml --runseed 4 --device cuda:0
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/hiv/random/train_prop=0.8.yml --runseed 5 --device cuda:2
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/hiv/random/train_prop=0.6.yml --runseed 5 --device cuda:0
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/hiv/random/train_prop=0.8.yml --runseed 6 --device cuda:2
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/hiv/random/train_prop=0.6.yml --runseed 6 --device cuda:0
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/hiv/random/train_prop=0.7.yml --runseed 4 --device cuda:1
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/hiv/random/train_prop=0.7.yml --runseed 5 --device cuda:1
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/hiv/random/train_prop=0.7.yml --runseed 6 --device cuda:1
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/hiv/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/hiv/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/hiv/random/train_prop=0.6/hiv_random_5_26-05_09-45-23  ]
[ Using Seed :  5  ]
[ Using device :  cuda:0  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
randomly split
Data(edge_attr=[84, 2], edge_index=[2, 84], id=[1], x=[39, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.3015050078133284
ROC train: 0.735438	val: 0.702461	test: 0.728590
PRC train: 0.183249	val: 0.189367	test: 0.217627

Epoch: 2
Loss: 0.13914835929746003
ROC train: 0.769648	val: 0.728190	test: 0.752625
PRC train: 0.237727	val: 0.236343	test: 0.263634

Epoch: 3
Loss: 0.13190661954330463
ROC train: 0.769548	val: 0.728237	test: 0.769454
PRC train: 0.251582	val: 0.249669	test: 0.287607

Epoch: 4
Loss: 0.1287977523783073
ROC train: 0.795119	val: 0.752975	test: 0.784027
PRC train: 0.319137	val: 0.299925	test: 0.335795

Epoch: 5
Loss: 0.12720759673916152
ROC train: 0.803536	val: 0.752660	test: 0.787574
PRC train: 0.327680	val: 0.276092	test: 0.357637

Epoch: 6
Loss: 0.12425233716819153
ROC train: 0.809674	val: 0.770231	test: 0.783162
PRC train: 0.303741	val: 0.276356	test: 0.319655

Epoch: 7
Loss: 0.12305208883236374
ROC train: 0.819786	val: 0.767040	test: 0.791628
PRC train: 0.354771	val: 0.324116	test: 0.357308

Epoch: 8
Loss: 0.12168548455580723
ROC train: 0.829655	val: 0.788851	test: 0.805593
PRC train: 0.343829	val: 0.311058	test: 0.349671

Epoch: 9
Loss: 0.1196230804289905
ROC train: 0.824452	val: 0.771497	test: 0.797576
PRC train: 0.354340	val: 0.306428	test: 0.346135

Epoch: 10
Loss: 0.11693608997151063
ROC train: 0.832432	val: 0.764554	test: 0.794975
PRC train: 0.378375	val: 0.306778	test: 0.377427

Epoch: 11
Loss: 0.11850663276966208
ROC train: 0.849826	val: 0.773300	test: 0.808300
PRC train: 0.384316	val: 0.289594	test: 0.373801

Epoch: 12
Loss: 0.11521836515198089
ROC train: 0.853018	val: 0.769426	test: 0.805787
PRC train: 0.395519	val: 0.317885	test: 0.386687

Epoch: 13
Loss: 0.1140884745876955
ROC train: 0.860785	val: 0.783436	test: 0.806293
PRC train: 0.420483	val: 0.324779	test: 0.390678

Epoch: 14
Loss: 0.11285781306086094
ROC train: 0.864881	val: 0.784853	test: 0.813539
PRC train: 0.436804	val: 0.323634	test: 0.390072

Epoch: 15
Loss: 0.11264514818459041
ROC train: 0.869806	val: 0.768897	test: 0.804831
PRC train: 0.455689	val: 0.343608	test: 0.399373

Epoch: 16
Loss: 0.11254574969134212
ROC train: 0.867789	val: 0.786909	test: 0.815472
PRC train: 0.449970	val: 0.344123	test: 0.409421

Epoch: 17
Loss: 0.11030663038732907
ROC train: 0.869438	val: 0.787616	test: 0.810769
PRC train: 0.445914	val: 0.340125	test: 0.403844

Epoch: 18
Loss: 0.10979690633461564
ROC train: 0.883482	val: 0.788422	test: 0.813233
PRC train: 0.479598	val: 0.333305	test: 0.424002

Epoch: 19
Loss: 0.10783250331303233
ROC train: 0.885779	val: 0.779428	test: 0.810322
PRC train: 0.480824	val: 0.336619	test: 0.421968

Epoch: 20
Loss: 0.10695129041631293
ROC train: 0.885285	val: 0.774978	test: 0.798879
PRC train: 0.475534	val: 0.328733	test: 0.420688

Epoch: 21
Loss: 0.10721064704859651
ROC train: 0.888675	val: 0.778260	test: 0.805499
PRC train: 0.458933	val: 0.351904	test: 0.398305

Epoch: 22
Loss: 0.10741015874081984
ROC train: 0.879617	val: 0.787525	test: 0.798354
PRC train: 0.486510	val: 0.344147	test: 0.418141

Epoch: 23
Loss: 0.10551927861392643
ROC train: 0.898565	val: 0.793839	test: 0.817202
PRC train: 0.495560	val: 0.361945	test: 0.412909

Epoch: 24
Loss: 0.10662792891648745
ROC train: 0.887884	val: 0.784875	test: 0.809879
PRC train: 0.470163	val: 0.335198	test: 0.409104

Epoch: 25
Loss: 0.10474498503043415
ROC train: 0.897759	val: 0.785498	test: 0.797090
PRC train: 0.511209	val: 0.349646	test: 0.440985

Epoch: 26
Loss: 0.10457894888397709
ROC train: 0.900127	val: 0.783589	test: 0.809181
PRC train: 0.512533	val: 0.339339	test: 0.428005

Epoch: 27
Loss: 0.10451088137107438
ROC train: 0.894822	val: 0.775542	test: 0.811649
PRC train: 0.480753	val: 0.349899	test: 0.396779

Epoch: 28
Loss: 0.10090654144615542
ROC train: 0.906422	val: 0.794742	test: 0.815359
PRC train: 0.528896	val: 0.355768	test: 0.433395

Epoch: 29
Loss: 0.10153811036298213
ROC train: 0.909399	val: 0.789262	test: 0.808690
PRC train: 0.510045	val: 0.362311	test: 0.421738

Epoch: 30
Loss: 0.10032215955689856
ROC train: 0.909250	val: 0.791210	test: 0.809414
PRC train: 0.521716	val: 0.351209	test: 0.408058

Epoch: 31
Loss: 0.10057625115016698
ROC train: 0.904419	val: 0.784779	test: 0.807161
PRC train: 0.540962	val: 0.350813	test: 0.419792

Epoch: 32
Loss: 0.09995599538169898
ROC train: 0.910394	val: 0.783111	test: 0.809601
PRC train: 0.550639	val: 0.371884	test: 0.433175

Epoch: 33
Loss: 0.09972644781993406Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/hiv/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/hiv/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/hiv/random/train_prop=0.6/hiv_random_4_26-05_09-45-23  ]
[ Using Seed :  4  ]
[ Using device :  cuda:0  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
randomly split
Data(edge_attr=[84, 2], edge_index=[2, 84], id=[1], x=[39, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.2839632742362959
ROC train: 0.723847	val: 0.707210	test: 0.729506
PRC train: 0.184994	val: 0.199133	test: 0.229592

Epoch: 2
Loss: 0.1382920761502324
ROC train: 0.765663	val: 0.738467	test: 0.786969
PRC train: 0.256237	val: 0.260902	test: 0.306260

Epoch: 3
Loss: 0.13112823010308527
ROC train: 0.782829	val: 0.736820	test: 0.777938
PRC train: 0.253165	val: 0.212689	test: 0.287117

Epoch: 4
Loss: 0.1284093045821754
ROC train: 0.799989	val: 0.752109	test: 0.785203
PRC train: 0.303058	val: 0.246827	test: 0.337273

Epoch: 5
Loss: 0.12600701258923036
ROC train: 0.815888	val: 0.767858	test: 0.784989
PRC train: 0.333705	val: 0.282504	test: 0.348139

Epoch: 6
Loss: 0.12388051613847233
ROC train: 0.819006	val: 0.772537	test: 0.794406
PRC train: 0.332572	val: 0.290875	test: 0.332664

Epoch: 7
Loss: 0.12337532916735394
ROC train: 0.825051	val: 0.763041	test: 0.789384
PRC train: 0.359646	val: 0.291582	test: 0.362320

Epoch: 8
Loss: 0.12054242734941961
ROC train: 0.824724	val: 0.770116	test: 0.802727
PRC train: 0.338675	val: 0.264694	test: 0.348945

Epoch: 9
Loss: 0.11944767858683368
ROC train: 0.837083	val: 0.783026	test: 0.793735
PRC train: 0.340497	val: 0.273949	test: 0.341366

Epoch: 10
Loss: 0.11827974270080928
ROC train: 0.843350	val: 0.770828	test: 0.804265
PRC train: 0.393796	val: 0.298789	test: 0.397285

Epoch: 11
Loss: 0.11608784870666668
ROC train: 0.858733	val: 0.781583	test: 0.814441
PRC train: 0.417617	val: 0.318524	test: 0.407772

Epoch: 12
Loss: 0.11588283606178916
ROC train: 0.843359	val: 0.757047	test: 0.803901
PRC train: 0.396676	val: 0.263182	test: 0.376870

Epoch: 13
Loss: 0.11617441561916138
ROC train: 0.861858	val: 0.778422	test: 0.810655
PRC train: 0.432965	val: 0.309877	test: 0.414144

Epoch: 14
Loss: 0.11350551072935328
ROC train: 0.862345	val: 0.783141	test: 0.810079
PRC train: 0.434261	val: 0.305441	test: 0.400039

Epoch: 15
Loss: 0.11305328077784317
ROC train: 0.862372	val: 0.766946	test: 0.810672
PRC train: 0.446134	val: 0.320670	test: 0.415365

Epoch: 16
Loss: 0.11038008307912803
ROC train: 0.872288	val: 0.786143	test: 0.816037
PRC train: 0.426885	val: 0.308296	test: 0.380415

Epoch: 17
Loss: 0.11064406892892775
ROC train: 0.873430	val: 0.787311	test: 0.813410
PRC train: 0.431360	val: 0.316802	test: 0.396851

Epoch: 18
Loss: 0.1085944163017652
ROC train: 0.879515	val: 0.775395	test: 0.812992
PRC train: 0.467292	val: 0.316427	test: 0.401790

Epoch: 19
Loss: 0.107762722029232
ROC train: 0.878767	val: 0.764120	test: 0.802956
PRC train: 0.481992	val: 0.324679	test: 0.398479

Epoch: 20
Loss: 0.10599116703643605
ROC train: 0.881270	val: 0.789130	test: 0.809115
PRC train: 0.476169	val: 0.333292	test: 0.418996

Epoch: 21
Loss: 0.10837023429986586
ROC train: 0.894219	val: 0.782611	test: 0.821644
PRC train: 0.466890	val: 0.322038	test: 0.378716

Epoch: 22
Loss: 0.10523969502040166
ROC train: 0.894230	val: 0.775070	test: 0.811930
PRC train: 0.484339	val: 0.324598	test: 0.403860

Epoch: 23
Loss: 0.106886887647809
ROC train: 0.901155	val: 0.783109	test: 0.816123
PRC train: 0.506457	val: 0.337155	test: 0.434696

Epoch: 24
Loss: 0.10423484445171102
ROC train: 0.899058	val: 0.796578	test: 0.819222
PRC train: 0.494395	val: 0.368737	test: 0.422924

Epoch: 25
Loss: 0.10289570793000712
ROC train: 0.897798	val: 0.776607	test: 0.812139
PRC train: 0.516556	val: 0.342512	test: 0.446363

Epoch: 26
Loss: 0.10281986578916938
ROC train: 0.903310	val: 0.777432	test: 0.814082
PRC train: 0.523347	val: 0.366904	test: 0.419500

Epoch: 27
Loss: 0.10218488449545866
ROC train: 0.901835	val: 0.788813	test: 0.814314
PRC train: 0.510566	val: 0.350156	test: 0.420484

Epoch: 28
Loss: 0.10291120632191172
ROC train: 0.912617	val: 0.776367	test: 0.814207
PRC train: 0.534579	val: 0.365055	test: 0.427071

Epoch: 29
Loss: 0.10121510007626394
ROC train: 0.911303	val: 0.779096	test: 0.812674
PRC train: 0.546473	val: 0.357060	test: 0.433038

Epoch: 30
Loss: 0.10001804444337152
ROC train: 0.912575	val: 0.777376	test: 0.806778
PRC train: 0.542329	val: 0.368197	test: 0.428315

Epoch: 31
Loss: 0.09986325259459797
ROC train: 0.914211	val: 0.772855	test: 0.807114
PRC train: 0.540438	val: 0.355228	test: 0.424303

Epoch: 32
Loss: 0.09972605800232304
ROC train: 0.909830	val: 0.789482	test: 0.801805
PRC train: 0.529978	val: 0.363043	test: 0.426415

Epoch: 33
Loss: 0.09993252449169089Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/hiv/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/hiv/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/hiv/random/train_prop=0.6/hiv_random_6_26-05_09-45-23  ]
[ Using Seed :  6  ]
[ Using device :  cuda:0  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
randomly split
Data(edge_attr=[84, 2], edge_index=[2, 84], id=[1], x=[39, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.3026430116247034
ROC train: 0.751472	val: 0.733385	test: 0.754745
PRC train: 0.194786	val: 0.207814	test: 0.230830

Epoch: 2
Loss: 0.13889417486237976
ROC train: 0.766700	val: 0.731075	test: 0.761617
PRC train: 0.222488	val: 0.219379	test: 0.261841

Epoch: 3
Loss: 0.1322988870427057
ROC train: 0.786849	val: 0.732701	test: 0.766150
PRC train: 0.279412	val: 0.266771	test: 0.302152

Epoch: 4
Loss: 0.12946934386888187
ROC train: 0.787699	val: 0.763610	test: 0.780618
PRC train: 0.251522	val: 0.243023	test: 0.258634

Epoch: 5
Loss: 0.12521115305690048
ROC train: 0.814141	val: 0.764029	test: 0.789470
PRC train: 0.342950	val: 0.312578	test: 0.358641

Epoch: 6
Loss: 0.12451141711181284
ROC train: 0.814845	val: 0.752674	test: 0.783524
PRC train: 0.334791	val: 0.295655	test: 0.336134

Epoch: 7
Loss: 0.12120509121039472
ROC train: 0.820000	val: 0.762495	test: 0.787376
PRC train: 0.359008	val: 0.295285	test: 0.337844

Epoch: 8
Loss: 0.12070026051174372
ROC train: 0.826245	val: 0.774276	test: 0.793114
PRC train: 0.364618	val: 0.315904	test: 0.348648

Epoch: 9
Loss: 0.11873381356368393
ROC train: 0.823305	val: 0.768087	test: 0.793613
PRC train: 0.382121	val: 0.309517	test: 0.364583

Epoch: 10
Loss: 0.11865548626249871
ROC train: 0.830238	val: 0.761645	test: 0.801923
PRC train: 0.394837	val: 0.317237	test: 0.362068

Epoch: 11
Loss: 0.11696686065037874
ROC train: 0.840799	val: 0.765705	test: 0.805973
PRC train: 0.389072	val: 0.295608	test: 0.372880

Epoch: 12
Loss: 0.11674644889413921
ROC train: 0.849306	val: 0.766883	test: 0.804283
PRC train: 0.406534	val: 0.312946	test: 0.372140

Epoch: 13
Loss: 0.11407955833847454
ROC train: 0.859969	val: 0.772125	test: 0.806077
PRC train: 0.421210	val: 0.318131	test: 0.400430

Epoch: 14
Loss: 0.11302810507815696
ROC train: 0.861191	val: 0.769198	test: 0.807328
PRC train: 0.428039	val: 0.333225	test: 0.377521

Epoch: 15
Loss: 0.11253427926450028
ROC train: 0.860398	val: 0.783477	test: 0.811281
PRC train: 0.439640	val: 0.338426	test: 0.406698

Epoch: 16
Loss: 0.11201096523742467
ROC train: 0.869931	val: 0.766168	test: 0.800691
PRC train: 0.430090	val: 0.333917	test: 0.375065

Epoch: 17
Loss: 0.11213111754892015
ROC train: 0.870089	val: 0.766272	test: 0.799847
PRC train: 0.420320	val: 0.300173	test: 0.388734

Epoch: 18
Loss: 0.1108344057243432
ROC train: 0.868710	val: 0.776615	test: 0.810271
PRC train: 0.440076	val: 0.331972	test: 0.387915

Epoch: 19
Loss: 0.11036924205358234
ROC train: 0.870943	val: 0.777596	test: 0.802375
PRC train: 0.457004	val: 0.324417	test: 0.396985

Epoch: 20
Loss: 0.10963250390414836
ROC train: 0.877290	val: 0.782703	test: 0.803747
PRC train: 0.473496	val: 0.347161	test: 0.391693

Epoch: 21
Loss: 0.1081291556434608
ROC train: 0.874345	val: 0.768566	test: 0.803976
PRC train: 0.441919	val: 0.310494	test: 0.383111

Epoch: 22
Loss: 0.10712582631959605
ROC train: 0.883335	val: 0.781336	test: 0.810351
PRC train: 0.462890	val: 0.342471	test: 0.411716

Epoch: 23
Loss: 0.10684228362467142
ROC train: 0.885774	val: 0.785497	test: 0.809389
PRC train: 0.482695	val: 0.350751	test: 0.404738

Epoch: 24
Loss: 0.10551287063865096
ROC train: 0.891991	val: 0.768943	test: 0.804119
PRC train: 0.481468	val: 0.309757	test: 0.409263

Epoch: 25
Loss: 0.10461213055182342
ROC train: 0.901390	val: 0.790995	test: 0.808509
PRC train: 0.508998	val: 0.339196	test: 0.431756

Epoch: 26
Loss: 0.10401293973569062
ROC train: 0.893990	val: 0.774626	test: 0.806687
PRC train: 0.502989	val: 0.366741	test: 0.426691

Epoch: 27
Loss: 0.10418421984753448
ROC train: 0.903904	val: 0.778802	test: 0.813918
PRC train: 0.507510	val: 0.344363	test: 0.427888

Epoch: 28
Loss: 0.102901102579083
ROC train: 0.901393	val: 0.767961	test: 0.803259
PRC train: 0.528641	val: 0.368641	test: 0.416244

Epoch: 29
Loss: 0.10200102791170974
ROC train: 0.910998	val: 0.776574	test: 0.812121
PRC train: 0.524414	val: 0.349725	test: 0.415553

Epoch: 30
Loss: 0.10314644137095104
ROC train: 0.908815	val: 0.773856	test: 0.806374
PRC train: 0.520783	val: 0.332606	test: 0.423442

Epoch: 31
Loss: 0.10019919571144738
ROC train: 0.912505	val: 0.769606	test: 0.804126
PRC train: 0.530462	val: 0.372776	test: 0.437064

Epoch: 32
Loss: 0.1008220663267275
ROC train: 0.911979	val: 0.783378	test: 0.818936
PRC train: 0.546026	val: 0.364293	test: 0.416524

Epoch: 33
Loss: 0.10123252695895477Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/hiv/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/hiv/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/hiv/random/train_prop=0.7/hiv_random_4_26-05_09-45-23  ]
[ Using Seed :  4  ]
[ Using device :  cuda:1  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
randomly split
Data(edge_attr=[84, 2], edge_index=[2, 84], id=[1], x=[39, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.26610022587969795
ROC train: 0.743000	val: 0.733117	test: 0.753862
PRC train: 0.176419	val: 0.235722	test: 0.226761

Epoch: 2
Loss: 0.13535750234810157
ROC train: 0.768096	val: 0.750231	test: 0.765022
PRC train: 0.254684	val: 0.305811	test: 0.309780

Epoch: 3
Loss: 0.13054017157152875
ROC train: 0.790367	val: 0.762453	test: 0.787017
PRC train: 0.299927	val: 0.339716	test: 0.338738

Epoch: 4
Loss: 0.12824401376171682
ROC train: 0.796941	val: 0.780087	test: 0.785901
PRC train: 0.281721	val: 0.321011	test: 0.309663

Epoch: 5
Loss: 0.12599911873793238
ROC train: 0.804910	val: 0.756410	test: 0.792547
PRC train: 0.320075	val: 0.338631	test: 0.344330

Epoch: 6
Loss: 0.12417173127133525
ROC train: 0.814938	val: 0.766454	test: 0.794092
PRC train: 0.330835	val: 0.357064	test: 0.364710

Epoch: 7
Loss: 0.12256444907274047
ROC train: 0.816985	val: 0.779679	test: 0.798069
PRC train: 0.328843	val: 0.357092	test: 0.353439

Epoch: 8
Loss: 0.11973672101171244
ROC train: 0.820465	val: 0.780914	test: 0.813961
PRC train: 0.332504	val: 0.366767	test: 0.359851

Epoch: 9
Loss: 0.11958270686361702
ROC train: 0.836071	val: 0.794816	test: 0.814635
PRC train: 0.367223	val: 0.390154	test: 0.383217

Epoch: 10
Loss: 0.11678299826393743
ROC train: 0.833955	val: 0.775416	test: 0.803804
PRC train: 0.369475	val: 0.368895	test: 0.388232

Epoch: 11
Loss: 0.11600245591324188
ROC train: 0.837812	val: 0.780781	test: 0.817412
PRC train: 0.389310	val: 0.364147	test: 0.405025

Epoch: 12
Loss: 0.11634687358045084
ROC train: 0.853404	val: 0.798200	test: 0.831608
PRC train: 0.413120	val: 0.380449	test: 0.412125

Epoch: 13
Loss: 0.11402303821422868
ROC train: 0.849295	val: 0.784371	test: 0.813858
PRC train: 0.427221	val: 0.400602	test: 0.414298

Epoch: 14
Loss: 0.11270932288749828
ROC train: 0.857429	val: 0.800496	test: 0.835003
PRC train: 0.403176	val: 0.394360	test: 0.389358

Epoch: 15
Loss: 0.11087889720075635
ROC train: 0.859888	val: 0.789199	test: 0.825786
PRC train: 0.434729	val: 0.384759	test: 0.421273

Epoch: 16
Loss: 0.1103148558391427
ROC train: 0.861237	val: 0.790510	test: 0.820480
PRC train: 0.451966	val: 0.410834	test: 0.429967

Epoch: 17
Loss: 0.10986578314334922
ROC train: 0.864158	val: 0.803499	test: 0.824198
PRC train: 0.431704	val: 0.400480	test: 0.411646

Epoch: 18
Loss: 0.10923450133006732
ROC train: 0.869936	val: 0.796254	test: 0.836384
PRC train: 0.438659	val: 0.387607	test: 0.402650

Epoch: 19
Loss: 0.10801084127129951
ROC train: 0.868259	val: 0.802553	test: 0.822226
PRC train: 0.451494	val: 0.405454	test: 0.427282

Epoch: 20
Loss: 0.10806999434067274
ROC train: 0.880409	val: 0.805363	test: 0.829447
PRC train: 0.474302	val: 0.407790	test: 0.427785

Epoch: 21
Loss: 0.10555226363408039
ROC train: 0.880569	val: 0.807988	test: 0.830796
PRC train: 0.468481	val: 0.402038	test: 0.430850

Epoch: 22
Loss: 0.10731407788188597
ROC train: 0.883529	val: 0.814148	test: 0.836984
PRC train: 0.494216	val: 0.431054	test: 0.445505

Epoch: 23
Loss: 0.10519173940938302
ROC train: 0.888235	val: 0.792767	test: 0.837496
PRC train: 0.495305	val: 0.393471	test: 0.446091

Epoch: 24
Loss: 0.10426657270303896
ROC train: 0.895091	val: 0.803506	test: 0.832707
PRC train: 0.496767	val: 0.423114	test: 0.445341

Epoch: 25
Loss: 0.10359885941574369
ROC train: 0.895812	val: 0.800791	test: 0.835540
PRC train: 0.507875	val: 0.427036	test: 0.453714

Epoch: 26
Loss: 0.10231739734696785
ROC train: 0.891644	val: 0.806202	test: 0.829801
PRC train: 0.485619	val: 0.400653	test: 0.443510

Epoch: 27
Loss: 0.10359481515622718
ROC train: 0.900088	val: 0.802026	test: 0.833261
PRC train: 0.514783	val: 0.401673	test: 0.432311

Epoch: 28
Loss: 0.10136888255045269
ROC train: 0.900861	val: 0.799572	test: 0.824286
PRC train: 0.506795	val: 0.428543	test: 0.451419

Epoch: 29
Loss: 0.10235022339103858
ROC train: 0.902820	val: 0.792984	test: 0.832594
PRC train: 0.520163	val: 0.412012	test: 0.446997

Epoch: 30
Loss: 0.10035694111176834
ROC train: 0.906871	val: 0.805357	test: 0.833995
PRC train: 0.532738	val: 0.423354	test: 0.456216

Epoch: 31
Loss: 0.10099071211859417
ROC train: 0.907290	val: 0.805231	test: 0.830654
PRC train: 0.533830	val: 0.428214	test: 0.440658

Epoch: 32
Loss: 0.09939076793062095
ROC train: 0.905290	val: 0.800936	test: 0.831239
PRC train: 0.535113	val: 0.424466	test: 0.461428

Epoch: 33
Loss: 0.0995590858350882Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/hiv/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/hiv/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/hiv/random/train_prop=0.7/hiv_random_5_26-05_09-45-23  ]
[ Using Seed :  5  ]
[ Using device :  cuda:1  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
randomly split
Data(edge_attr=[84, 2], edge_index=[2, 84], id=[1], x=[39, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.2772306558896843
ROC train: 0.747088	val: 0.714067	test: 0.766539
PRC train: 0.189795	val: 0.228953	test: 0.226198

Epoch: 2
Loss: 0.13655807437400252
ROC train: 0.777731	val: 0.753645	test: 0.779894
PRC train: 0.263902	val: 0.329807	test: 0.301432

Epoch: 3
Loss: 0.13044493112338698
ROC train: 0.779431	val: 0.752781	test: 0.790667
PRC train: 0.271369	val: 0.302435	test: 0.301986

Epoch: 4
Loss: 0.12747032495685615
ROC train: 0.786613	val: 0.760020	test: 0.792003
PRC train: 0.287558	val: 0.321271	test: 0.342404

Epoch: 5
Loss: 0.12499144784077929
ROC train: 0.800481	val: 0.773450	test: 0.800719
PRC train: 0.334696	val: 0.379543	test: 0.352929

Epoch: 6
Loss: 0.12308344488081123
ROC train: 0.817916	val: 0.790405	test: 0.801667
PRC train: 0.346988	val: 0.352548	test: 0.376946

Epoch: 7
Loss: 0.12150497846089282
ROC train: 0.818590	val: 0.787694	test: 0.803789
PRC train: 0.353648	val: 0.371348	test: 0.342929

Epoch: 8
Loss: 0.11933885295710067
ROC train: 0.829526	val: 0.790378	test: 0.810545
PRC train: 0.371242	val: 0.388112	test: 0.391520

Epoch: 9
Loss: 0.11986510585194685
ROC train: 0.826360	val: 0.786910	test: 0.807702
PRC train: 0.370495	val: 0.360754	test: 0.403057

Epoch: 10
Loss: 0.11792511674247212
ROC train: 0.834673	val: 0.781960	test: 0.810727
PRC train: 0.384143	val: 0.393436	test: 0.392723

Epoch: 11
Loss: 0.11611366727120465
ROC train: 0.839754	val: 0.794513	test: 0.820215
PRC train: 0.379445	val: 0.378883	test: 0.374219

Epoch: 12
Loss: 0.11826779438611236
ROC train: 0.848039	val: 0.795787	test: 0.822117
PRC train: 0.414960	val: 0.402196	test: 0.416222

Epoch: 13
Loss: 0.11412504877114922
ROC train: 0.858195	val: 0.811154	test: 0.824313
PRC train: 0.407620	val: 0.400998	test: 0.393911

Epoch: 14
Loss: 0.11264342875366612
ROC train: 0.853109	val: 0.800393	test: 0.819533
PRC train: 0.391148	val: 0.384058	test: 0.347498

Epoch: 15
Loss: 0.11170549998440084
ROC train: 0.860527	val: 0.809853	test: 0.823561
PRC train: 0.405651	val: 0.395441	test: 0.380624

Epoch: 16
Loss: 0.11052667796885707
ROC train: 0.869046	val: 0.820891	test: 0.829589
PRC train: 0.452653	val: 0.418820	test: 0.402979

Epoch: 17
Loss: 0.11044395762308021
ROC train: 0.866648	val: 0.798493	test: 0.830631
PRC train: 0.433448	val: 0.373998	test: 0.424045

Epoch: 18
Loss: 0.11026609063222576
ROC train: 0.872785	val: 0.792921	test: 0.831048
PRC train: 0.456426	val: 0.402061	test: 0.435698

Epoch: 19
Loss: 0.10770548985009974
ROC train: 0.880187	val: 0.816550	test: 0.827424
PRC train: 0.454195	val: 0.409491	test: 0.409205

Epoch: 20
Loss: 0.10898812401093044
ROC train: 0.877571	val: 0.812475	test: 0.829354
PRC train: 0.473306	val: 0.419318	test: 0.443696

Epoch: 21
Loss: 0.10720829311182163
ROC train: 0.877634	val: 0.811791	test: 0.831730
PRC train: 0.463177	val: 0.410950	test: 0.439415

Epoch: 22
Loss: 0.10639979508148005
ROC train: 0.881781	val: 0.809460	test: 0.832016
PRC train: 0.462194	val: 0.388678	test: 0.407024

Epoch: 23
Loss: 0.10526444405462955
ROC train: 0.881079	val: 0.814474	test: 0.821465
PRC train: 0.476253	val: 0.394251	test: 0.412347

Epoch: 24
Loss: 0.10454519711587155
ROC train: 0.896511	val: 0.807901	test: 0.830967
PRC train: 0.500324	val: 0.425251	test: 0.439266

Epoch: 25
Loss: 0.10430839311462375
ROC train: 0.897068	val: 0.817556	test: 0.826553
PRC train: 0.497441	val: 0.417627	test: 0.426518

Epoch: 26
Loss: 0.10374377844173241
ROC train: 0.903825	val: 0.810934	test: 0.830234
PRC train: 0.528983	val: 0.440002	test: 0.442229

Epoch: 27
Loss: 0.10134249482886265
ROC train: 0.900074	val: 0.802116	test: 0.831112
PRC train: 0.511568	val: 0.431311	test: 0.438621

Epoch: 28
Loss: 0.10199297367071121
ROC train: 0.901890	val: 0.813579	test: 0.836163
PRC train: 0.521119	val: 0.433406	test: 0.436848

Epoch: 29
Loss: 0.10111145355386252
ROC train: 0.904002	val: 0.815647	test: 0.820474
PRC train: 0.528360	val: 0.431419	test: 0.441810

Epoch: 30
Loss: 0.10212315345565189
ROC train: 0.908600	val: 0.815693	test: 0.838492
PRC train: 0.532283	val: 0.452446	test: 0.441261

Epoch: 31
Loss: 0.09782949761459915
ROC train: 0.904777	val: 0.817917	test: 0.828685
PRC train: 0.519330	val: 0.422458	test: 0.423373

Epoch: 32
Loss: 0.10077504350173574
ROC train: 0.912774	val: 0.800996	test: 0.829587
PRC train: 0.533249	val: 0.435797	test: 0.448791

Epoch: 33
Loss: 0.10012746793576353Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/hiv/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/hiv/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/hiv/random/train_prop=0.7/hiv_random_6_26-05_09-45-23  ]
[ Using Seed :  6  ]
[ Using device :  cuda:1  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
randomly split
Data(edge_attr=[84, 2], edge_index=[2, 84], id=[1], x=[39, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.27945070655025617
ROC train: 0.706487	val: 0.667748	test: 0.746186
PRC train: 0.154843	val: 0.170411	test: 0.220058

Epoch: 2
Loss: 0.1358800215438911
ROC train: 0.733038	val: 0.741915	test: 0.759973
PRC train: 0.198004	val: 0.225232	test: 0.259701

Epoch: 3
Loss: 0.1304150678397239
ROC train: 0.780935	val: 0.773759	test: 0.796033
PRC train: 0.252086	val: 0.318252	test: 0.292602

Epoch: 4
Loss: 0.1276770749446563
ROC train: 0.793915	val: 0.775181	test: 0.779463
PRC train: 0.259730	val: 0.318054	test: 0.268538

Epoch: 5
Loss: 0.12623149585288487
ROC train: 0.755172	val: 0.746471	test: 0.760602
PRC train: 0.123749	val: 0.152783	test: 0.137064

Epoch: 6
Loss: 0.12385873783260412
ROC train: 0.812953	val: 0.789834	test: 0.799367
PRC train: 0.326986	val: 0.360418	test: 0.350897

Epoch: 7
Loss: 0.12175391263762239
ROC train: 0.818430	val: 0.796834	test: 0.800888
PRC train: 0.333361	val: 0.363464	test: 0.366818

Epoch: 8
Loss: 0.12058424537540968
ROC train: 0.828113	val: 0.806625	test: 0.799236
PRC train: 0.346105	val: 0.359657	test: 0.367438

Epoch: 9
Loss: 0.1193446395899533
ROC train: 0.840038	val: 0.803466	test: 0.820328
PRC train: 0.381224	val: 0.390363	test: 0.393178

Epoch: 10
Loss: 0.11691295375616358
ROC train: 0.836092	val: 0.805469	test: 0.811341
PRC train: 0.356008	val: 0.358996	test: 0.341267

Epoch: 11
Loss: 0.117619852756609
ROC train: 0.844504	val: 0.786962	test: 0.822174
PRC train: 0.401521	val: 0.381674	test: 0.393511

Epoch: 12
Loss: 0.11341727420403602
ROC train: 0.852024	val: 0.799799	test: 0.816980
PRC train: 0.414788	val: 0.397793	test: 0.413367

Epoch: 13
Loss: 0.11546125198946267
ROC train: 0.845754	val: 0.806949	test: 0.815471
PRC train: 0.381168	val: 0.368208	test: 0.405628

Epoch: 14
Loss: 0.11450964940661482
ROC train: 0.852177	val: 0.794692	test: 0.808733
PRC train: 0.410685	val: 0.404962	test: 0.403366

Epoch: 15
Loss: 0.11314302167846674
ROC train: 0.861012	val: 0.800525	test: 0.820403
PRC train: 0.422679	val: 0.391375	test: 0.426456

Epoch: 16
Loss: 0.1126303360641484
ROC train: 0.855591	val: 0.800953	test: 0.819978
PRC train: 0.430583	val: 0.391117	test: 0.403830

Epoch: 17
Loss: 0.10971270152139567
ROC train: 0.850211	val: 0.804397	test: 0.807616
PRC train: 0.420271	val: 0.384101	test: 0.398550

Epoch: 18
Loss: 0.10829874211415862
ROC train: 0.868973	val: 0.807993	test: 0.823381
PRC train: 0.416638	val: 0.368882	test: 0.372257

Epoch: 19
Loss: 0.11036534747844993
ROC train: 0.884118	val: 0.801924	test: 0.833577
PRC train: 0.464261	val: 0.380818	test: 0.430467

Epoch: 20
Loss: 0.10773191613495803
ROC train: 0.876501	val: 0.804967	test: 0.832514
PRC train: 0.464503	val: 0.362156	test: 0.434025

Epoch: 21
Loss: 0.10724311900100839
ROC train: 0.873038	val: 0.788770	test: 0.809447
PRC train: 0.462283	val: 0.405717	test: 0.422797

Epoch: 22
Loss: 0.10588738280076103
ROC train: 0.885287	val: 0.792943	test: 0.813864
PRC train: 0.471615	val: 0.407313	test: 0.387260

Epoch: 23
Loss: 0.10607036102834673
ROC train: 0.876413	val: 0.799252	test: 0.812711
PRC train: 0.474631	val: 0.413252	test: 0.426529

Epoch: 24
Loss: 0.10508743970211919
ROC train: 0.889381	val: 0.797071	test: 0.815264
PRC train: 0.479319	val: 0.389056	test: 0.404677

Epoch: 25
Loss: 0.1043447368705357
ROC train: 0.898504	val: 0.802290	test: 0.821580
PRC train: 0.523177	val: 0.431352	test: 0.427277

Epoch: 26
Loss: 0.10369671628846328
ROC train: 0.899334	val: 0.802026	test: 0.833753
PRC train: 0.508788	val: 0.432627	test: 0.432695

Epoch: 27
Loss: 0.10199055648610603
ROC train: 0.899370	val: 0.805705	test: 0.834899
PRC train: 0.505999	val: 0.415659	test: 0.428365

Epoch: 28
Loss: 0.10287203282271062
ROC train: 0.894000	val: 0.798935	test: 0.801204
PRC train: 0.489009	val: 0.400395	test: 0.394825

Epoch: 29
Loss: 0.10104722924992382
ROC train: 0.906488	val: 0.819140	test: 0.827764
PRC train: 0.528478	val: 0.431629	test: 0.432886

Epoch: 30
Loss: 0.10135000776482803
ROC train: 0.909289	val: 0.812866	test: 0.832667
PRC train: 0.531135	val: 0.434321	test: 0.448262

Epoch: 31
Loss: 0.09983763301750012
ROC train: 0.913988	val: 0.812285	test: 0.822763
PRC train: 0.548591	val: 0.437802	test: 0.446460

Epoch: 32
Loss: 0.10037692826649143
ROC train: 0.915814	val: 0.798648	test: 0.823033
PRC train: 0.546685	val: 0.433157	test: 0.439162

Epoch: 33
Loss: 0.09870870592046269Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/hiv/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/hiv/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/hiv/random/train_prop=0.8/hiv_random_4_26-05_09-45-23  ]
[ Using Seed :  4  ]
[ Using device :  cuda:2  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
randomly split
Data(edge_attr=[84, 2], edge_index=[2, 84], id=[1], x=[39, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.2495224936944669
ROC train: 0.757962	val: 0.748904	test: 0.798429
PRC train: 0.236324	val: 0.234306	test: 0.314697

Epoch: 2
Loss: 0.13472815510706274
ROC train: 0.769425	val: 0.768785	test: 0.789140
PRC train: 0.254212	val: 0.233817	test: 0.309374

Epoch: 3
Loss: 0.1303054826512362
ROC train: 0.797390	val: 0.780521	test: 0.821818
PRC train: 0.287840	val: 0.269862	test: 0.321502

Epoch: 4
Loss: 0.12788739482773484
ROC train: 0.797751	val: 0.792657	test: 0.804260
PRC train: 0.303635	val: 0.291875	test: 0.372315

Epoch: 5
Loss: 0.1261986367129832
ROC train: 0.811878	val: 0.782574	test: 0.820100
PRC train: 0.327633	val: 0.310340	test: 0.405988

Epoch: 6
Loss: 0.12349145350859651
ROC train: 0.807841	val: 0.776312	test: 0.820388
PRC train: 0.328443	val: 0.316553	test: 0.411588

Epoch: 7
Loss: 0.1225378430030817
ROC train: 0.826320	val: 0.788670	test: 0.834231
PRC train: 0.356428	val: 0.341686	test: 0.401169

Epoch: 8
Loss: 0.12179539046015449
ROC train: 0.833872	val: 0.805688	test: 0.834793
PRC train: 0.387358	val: 0.354667	test: 0.463152

Epoch: 9
Loss: 0.11887822081967794
ROC train: 0.838056	val: 0.802200	test: 0.832680
PRC train: 0.368693	val: 0.328907	test: 0.416525

Epoch: 10
Loss: 0.11697204366051728
ROC train: 0.832104	val: 0.778238	test: 0.832729
PRC train: 0.383738	val: 0.331414	test: 0.435873

Epoch: 11
Loss: 0.1167146945458165
ROC train: 0.847663	val: 0.798574	test: 0.834199
PRC train: 0.405489	val: 0.369248	test: 0.439754

Epoch: 12
Loss: 0.11496470851113194
ROC train: 0.843538	val: 0.781939	test: 0.845612
PRC train: 0.409685	val: 0.347019	test: 0.448901

Epoch: 13
Loss: 0.1141714056366069
ROC train: 0.853718	val: 0.776691	test: 0.835836
PRC train: 0.428322	val: 0.383314	test: 0.479631

Epoch: 14
Loss: 0.1152961552474599
ROC train: 0.849158	val: 0.792976	test: 0.824791
PRC train: 0.425683	val: 0.360970	test: 0.460786

Epoch: 15
Loss: 0.11161583854380831
ROC train: 0.847085	val: 0.791054	test: 0.830002
PRC train: 0.442548	val: 0.380372	test: 0.479834

Epoch: 16
Loss: 0.11288253369063422
ROC train: 0.854567	val: 0.801331	test: 0.834227
PRC train: 0.413882	val: 0.373418	test: 0.457852

Epoch: 17
Loss: 0.10999486830939285
ROC train: 0.864544	val: 0.797670	test: 0.838982
PRC train: 0.463015	val: 0.403596	test: 0.484401

Epoch: 18
Loss: 0.11107765774451402
ROC train: 0.858960	val: 0.799620	test: 0.850650
PRC train: 0.438956	val: 0.394994	test: 0.477324

Epoch: 19
Loss: 0.110970285056265
ROC train: 0.875776	val: 0.818661	test: 0.837288
PRC train: 0.464656	val: 0.406578	test: 0.475855

Epoch: 20
Loss: 0.10825555225388424
ROC train: 0.874251	val: 0.802025	test: 0.828796
PRC train: 0.474767	val: 0.397630	test: 0.491303

Epoch: 21
Loss: 0.10715201567732505
ROC train: 0.883087	val: 0.800468	test: 0.847533
PRC train: 0.486849	val: 0.405624	test: 0.473051

Epoch: 22
Loss: 0.10758315099055016
ROC train: 0.875094	val: 0.785528	test: 0.845336
PRC train: 0.482416	val: 0.392259	test: 0.465109

Epoch: 23
Loss: 0.10709253365034013
ROC train: 0.889733	val: 0.806559	test: 0.838058
PRC train: 0.500032	val: 0.404843	test: 0.474962

Epoch: 24
Loss: 0.10669910736906103
ROC train: 0.889575	val: 0.806278	test: 0.844104
PRC train: 0.499625	val: 0.426349	test: 0.469546

Epoch: 25
Loss: 0.1052776897351512
ROC train: 0.887403	val: 0.815759	test: 0.834177
PRC train: 0.504191	val: 0.418393	test: 0.493785

Epoch: 26
Loss: 0.10440186653686474
ROC train: 0.897405	val: 0.811458	test: 0.845898
PRC train: 0.524717	val: 0.425468	test: 0.486254

Epoch: 27
Loss: 0.10300948184670121
ROC train: 0.891981	val: 0.796532	test: 0.845169
PRC train: 0.511150	val: 0.403115	test: 0.494118

Epoch: 28
Loss: 0.10405078609765489
ROC train: 0.890582	val: 0.809164	test: 0.831174
PRC train: 0.518664	val: 0.413058	test: 0.479737

Epoch: 29
Loss: 0.10162971788971065
ROC train: 0.898874	val: 0.782100	test: 0.838618
PRC train: 0.497764	val: 0.409472	test: 0.441270

Epoch: 30
Loss: 0.10091946521567255
ROC train: 0.896062	val: 0.785997	test: 0.836035
PRC train: 0.529567	val: 0.405809	test: 0.488354

Epoch: 31
Loss: 0.10144501777004379
ROC train: 0.900302	val: 0.798491	test: 0.864799
PRC train: 0.521498	val: 0.404001	test: 0.494937

Epoch: 32
Loss: 0.09977285207616683
ROC train: 0.895085	val: 0.804559	test: 0.839598
PRC train: 0.507143	val: 0.387286	test: 0.464123

Epoch: 33
Loss: 0.10245486094874816Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/hiv/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/hiv/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/hiv/random/train_prop=0.8/hiv_random_6_26-05_09-45-23  ]
[ Using Seed :  6  ]
[ Using device :  cuda:2  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
randomly split
Data(edge_attr=[84, 2], edge_index=[2, 84], id=[1], x=[39, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.2628729358387383
ROC train: 0.750886	val: 0.740265	test: 0.761114
PRC train: 0.199640	val: 0.216263	test: 0.259743

Epoch: 2
Loss: 0.13710983786273656
ROC train: 0.764436	val: 0.753382	test: 0.774332
PRC train: 0.260451	val: 0.278848	test: 0.324018

Epoch: 3
Loss: 0.13146302702052026
ROC train: 0.782728	val: 0.740686	test: 0.812898
PRC train: 0.299475	val: 0.297958	test: 0.360845

Epoch: 4
Loss: 0.1276404511705568
ROC train: 0.801492	val: 0.788150	test: 0.808827
PRC train: 0.313188	val: 0.327105	test: 0.377323

Epoch: 5
Loss: 0.12497299869232277
ROC train: 0.795281	val: 0.754690	test: 0.822795
PRC train: 0.328188	val: 0.319383	test: 0.429081

Epoch: 6
Loss: 0.1233072771416403
ROC train: 0.815647	val: 0.797576	test: 0.828059
PRC train: 0.356710	val: 0.327282	test: 0.419849

Epoch: 7
Loss: 0.1214064173962109
ROC train: 0.814411	val: 0.771555	test: 0.829980
PRC train: 0.338220	val: 0.326598	test: 0.442572

Epoch: 8
Loss: 0.12095246198105354
ROC train: 0.834079	val: 0.804009	test: 0.819979
PRC train: 0.387300	val: 0.363221	test: 0.442343

Epoch: 9
Loss: 0.12020866592405022
ROC train: 0.839327	val: 0.806634	test: 0.817270
PRC train: 0.363590	val: 0.341618	test: 0.400202

Epoch: 10
Loss: 0.11777884857454393
ROC train: 0.829539	val: 0.786501	test: 0.817768
PRC train: 0.361513	val: 0.322391	test: 0.425509

Epoch: 11
Loss: 0.11630751663190107
ROC train: 0.833626	val: 0.785097	test: 0.839268
PRC train: 0.393725	val: 0.368731	test: 0.457846

Epoch: 12
Loss: 0.11700337474614088
ROC train: 0.850143	val: 0.806308	test: 0.843249
PRC train: 0.411604	val: 0.370578	test: 0.443414

Epoch: 13
Loss: 0.11408503204647878
ROC train: 0.851942	val: 0.792201	test: 0.828714
PRC train: 0.422069	val: 0.369541	test: 0.462515

Epoch: 14
Loss: 0.1132257053527153
ROC train: 0.852882	val: 0.799789	test: 0.836914
PRC train: 0.419265	val: 0.367820	test: 0.432305

Epoch: 15
Loss: 0.1120616038869966
ROC train: 0.860614	val: 0.814514	test: 0.854180
PRC train: 0.442693	val: 0.396721	test: 0.487144

Epoch: 16
Loss: 0.11130341393755712
ROC train: 0.867982	val: 0.800364	test: 0.849962
PRC train: 0.448090	val: 0.381209	test: 0.468751

Epoch: 17
Loss: 0.10975740283413656
ROC train: 0.865920	val: 0.814179	test: 0.843901
PRC train: 0.460532	val: 0.396933	test: 0.493278

Epoch: 18
Loss: 0.1108750393173145
ROC train: 0.867721	val: 0.815585	test: 0.826851
PRC train: 0.443756	val: 0.341923	test: 0.467580

Epoch: 19
Loss: 0.10869562551310738
ROC train: 0.876350	val: 0.804881	test: 0.846179
PRC train: 0.481841	val: 0.388762	test: 0.473818

Epoch: 20
Loss: 0.10775938314943065
ROC train: 0.885269	val: 0.807075	test: 0.839498
PRC train: 0.492176	val: 0.425350	test: 0.488652

Epoch: 21
Loss: 0.1077664561076726
ROC train: 0.876548	val: 0.801897	test: 0.850347
PRC train: 0.487262	val: 0.411200	test: 0.467468

Epoch: 22
Loss: 0.10569751809166829
ROC train: 0.890742	val: 0.801296	test: 0.852412
PRC train: 0.496859	val: 0.414728	test: 0.485019

Epoch: 23
Loss: 0.10555269807270877
ROC train: 0.893158	val: 0.811596	test: 0.848111
PRC train: 0.511347	val: 0.397213	test: 0.478322

Epoch: 24
Loss: 0.10432565742564592
ROC train: 0.893820	val: 0.821829	test: 0.855162
PRC train: 0.508134	val: 0.417503	test: 0.501204

Epoch: 25
Loss: 0.1035412967361527
ROC train: 0.892766	val: 0.812403	test: 0.864724
PRC train: 0.506623	val: 0.410759	test: 0.478470

Epoch: 26
Loss: 0.10238791675388975
ROC train: 0.887825	val: 0.805334	test: 0.845167
PRC train: 0.505289	val: 0.401579	test: 0.478200

Epoch: 27
Loss: 0.10301684972888105
ROC train: 0.899518	val: 0.815534	test: 0.838461
PRC train: 0.525264	val: 0.414524	test: 0.492971

Epoch: 28
Loss: 0.10302708085656655
ROC train: 0.901758	val: 0.806625	test: 0.854009
PRC train: 0.525985	val: 0.394933	test: 0.481084

Epoch: 29
Loss: 0.10190277654215942
ROC train: 0.905622	val: 0.805010	test: 0.829864
PRC train: 0.510452	val: 0.389256	test: 0.452505

Epoch: 30
Loss: 0.10075580130274366
ROC train: 0.912736	val: 0.802723	test: 0.850946
PRC train: 0.540140	val: 0.399477	test: 0.483160

Epoch: 31
Loss: 0.10035857852162343
ROC train: 0.910725	val: 0.799955	test: 0.851530
PRC train: 0.551623	val: 0.428279	test: 0.494021

Epoch: 32
Loss: 0.0992576751730618
ROC train: 0.913035	val: 0.808622	test: 0.847127
PRC train: 0.550028	val: 0.436544	test: 0.491859

Epoch: 33
Loss: 0.10076538801150606Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/hiv/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/hiv/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/hiv/random/train_prop=0.8/hiv_random_5_26-05_09-45-23  ]
[ Using Seed :  5  ]
[ Using device :  cuda:2  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
randomly split
Data(edge_attr=[84, 2], edge_index=[2, 84], id=[1], x=[39, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.2628205044881735
ROC train: 0.751145	val: 0.718935	test: 0.761998
PRC train: 0.217469	val: 0.223967	test: 0.289701

Epoch: 2
Loss: 0.13576771993966535
ROC train: 0.731931	val: 0.723419	test: 0.767914
PRC train: 0.225539	val: 0.234154	test: 0.322146

Epoch: 3
Loss: 0.1305779244935874
ROC train: 0.780888	val: 0.754649	test: 0.806381
PRC train: 0.281929	val: 0.261439	test: 0.365884

Epoch: 4
Loss: 0.1276834263031081
ROC train: 0.796795	val: 0.758591	test: 0.812993
PRC train: 0.303363	val: 0.289108	test: 0.402533

Epoch: 5
Loss: 0.12490262257819489
ROC train: 0.808757	val: 0.766532	test: 0.812514
PRC train: 0.326480	val: 0.288240	test: 0.408419

Epoch: 6
Loss: 0.12301785869299307
ROC train: 0.816719	val: 0.774962	test: 0.820661
PRC train: 0.344575	val: 0.311125	test: 0.405266

Epoch: 7
Loss: 0.12112701077127329
ROC train: 0.823605	val: 0.781034	test: 0.818670
PRC train: 0.350731	val: 0.325351	test: 0.414455

Epoch: 8
Loss: 0.12000699486550391
ROC train: 0.836325	val: 0.801960	test: 0.840181
PRC train: 0.373064	val: 0.340972	test: 0.429662

Epoch: 9
Loss: 0.11794664579566357
ROC train: 0.841687	val: 0.802444	test: 0.841059
PRC train: 0.406999	val: 0.359477	test: 0.463852

Epoch: 10
Loss: 0.11776924626155902
ROC train: 0.843334	val: 0.799199	test: 0.838388
PRC train: 0.405723	val: 0.337898	test: 0.446813

Epoch: 11
Loss: 0.11583125933839629
ROC train: 0.845781	val: 0.798607	test: 0.837008
PRC train: 0.400571	val: 0.348731	test: 0.453875

Epoch: 12
Loss: 0.11397947627673939
ROC train: 0.854942	val: 0.791840	test: 0.834535
PRC train: 0.423077	val: 0.379082	test: 0.451977

Epoch: 13
Loss: 0.11508835753596368
ROC train: 0.854946	val: 0.802476	test: 0.833782
PRC train: 0.421364	val: 0.341198	test: 0.457795

Epoch: 14
Loss: 0.11144573808830024
ROC train: 0.865890	val: 0.790319	test: 0.839715
PRC train: 0.451120	val: 0.360827	test: 0.456461

Epoch: 15
Loss: 0.11186808441027311
ROC train: 0.866570	val: 0.798880	test: 0.843862
PRC train: 0.433936	val: 0.329255	test: 0.478497

Epoch: 16
Loss: 0.11127863034129598
ROC train: 0.863963	val: 0.815206	test: 0.837740
PRC train: 0.456113	val: 0.385178	test: 0.490178

Epoch: 17
Loss: 0.10879979740144735
ROC train: 0.874503	val: 0.798114	test: 0.863011
PRC train: 0.474850	val: 0.378463	test: 0.498876

Epoch: 18
Loss: 0.10889278105356728
ROC train: 0.873644	val: 0.815888	test: 0.835463
PRC train: 0.477743	val: 0.381246	test: 0.480077

Epoch: 19
Loss: 0.10774824956890819
ROC train: 0.881850	val: 0.805232	test: 0.846663
PRC train: 0.470419	val: 0.395242	test: 0.474141

Epoch: 20
Loss: 0.10734621632183332
ROC train: 0.885842	val: 0.816929	test: 0.848087
PRC train: 0.472796	val: 0.380384	test: 0.467856

Epoch: 21
Loss: 0.1066530645630175
ROC train: 0.892683	val: 0.797657	test: 0.845876
PRC train: 0.492047	val: 0.385618	test: 0.475403

Epoch: 22
Loss: 0.10636262677919732
ROC train: 0.888477	val: 0.796498	test: 0.846408
PRC train: 0.465083	val: 0.370153	test: 0.467297

Epoch: 23
Loss: 0.10621223998284673
ROC train: 0.884807	val: 0.802670	test: 0.850861
PRC train: 0.475654	val: 0.361278	test: 0.476216

Epoch: 24
Loss: 0.10467396206984507
ROC train: 0.893960	val: 0.813342	test: 0.847428
PRC train: 0.498449	val: 0.402312	test: 0.490689

Epoch: 25
Loss: 0.10315218578015674
ROC train: 0.900762	val: 0.815195	test: 0.858468
PRC train: 0.514469	val: 0.404322	test: 0.497471

Epoch: 26
Loss: 0.10440976356373134
ROC train: 0.904305	val: 0.803678	test: 0.864133
PRC train: 0.515744	val: 0.385419	test: 0.509985

Epoch: 27
Loss: 0.101917354314792
ROC train: 0.900001	val: 0.813618	test: 0.841799
PRC train: 0.529847	val: 0.396671	test: 0.481727

Epoch: 28
Loss: 0.101485103448929
ROC train: 0.901617	val: 0.827305	test: 0.843986
PRC train: 0.516826	val: 0.407360	test: 0.467251

Epoch: 29
Loss: 0.10242891707215883
ROC train: 0.907572	val: 0.810644	test: 0.852112
PRC train: 0.535682	val: 0.408713	test: 0.493116

Epoch: 30
Loss: 0.10158711809888872
ROC train: 0.909192	val: 0.828179	test: 0.856747
PRC train: 0.511246	val: 0.377674	test: 0.480043

Epoch: 31
Loss: 0.09972678201687647
ROC train: 0.903626	val: 0.806870	test: 0.849047
PRC train: 0.507339	val: 0.404328	test: 0.484691

Epoch: 32
Loss: 0.09931584852578348
ROC train: 0.915037	val: 0.810694	test: 0.844060
PRC train: 0.539227	val: 0.398157	test: 0.483488

Epoch: 33
Loss: 0.09821805042097402
ROC train: 0.915825	val: 0.787267	test: 0.806465
PRC train: 0.536218	val: 0.358628	test: 0.423551

Epoch: 34
Loss: 0.09862270572231598
ROC train: 0.921042	val: 0.792085	test: 0.819754
PRC train: 0.544252	val: 0.367814	test: 0.440463

Epoch: 35
Loss: 0.09805535470632326
ROC train: 0.918847	val: 0.782877	test: 0.815684
PRC train: 0.549961	val: 0.366325	test: 0.430789

Epoch: 36
Loss: 0.09724378958800113
ROC train: 0.921085	val: 0.792044	test: 0.804504
PRC train: 0.565471	val: 0.373150	test: 0.431927

Epoch: 37
Loss: 0.09799209472379239
ROC train: 0.922435	val: 0.782592	test: 0.811190
PRC train: 0.561162	val: 0.371519	test: 0.427910

Epoch: 38
Loss: 0.09497623400914261
ROC train: 0.921285	val: 0.775624	test: 0.810198
PRC train: 0.570836	val: 0.366311	test: 0.425082

Epoch: 39
Loss: 0.09677723538661098
ROC train: 0.928834	val: 0.780654	test: 0.800068
PRC train: 0.585158	val: 0.378018	test: 0.428132

Epoch: 40
Loss: 0.09605457905847029
ROC train: 0.929078	val: 0.781346	test: 0.825971
PRC train: 0.584255	val: 0.377633	test: 0.447766

Epoch: 41
Loss: 0.09615734295858062
ROC train: 0.924600	val: 0.786357	test: 0.806492
PRC train: 0.568559	val: 0.364377	test: 0.421523

Epoch: 42
Loss: 0.0957233611704677
ROC train: 0.931973	val: 0.784653	test: 0.807753
PRC train: 0.589298	val: 0.370416	test: 0.430205

Epoch: 43
Loss: 0.09373445625767025
ROC train: 0.932951	val: 0.791271	test: 0.809548
PRC train: 0.594380	val: 0.373395	test: 0.430115

Epoch: 44
Loss: 0.09518907116506678
ROC train: 0.931816	val: 0.776854	test: 0.802088
PRC train: 0.578498	val: 0.368925	test: 0.424681

Epoch: 45
Loss: 0.09342297207715879
ROC train: 0.935409	val: 0.785836	test: 0.809107
PRC train: 0.589848	val: 0.382445	test: 0.425829

Epoch: 46
Loss: 0.092716287980139
ROC train: 0.934367	val: 0.791331	test: 0.815998
PRC train: 0.594773	val: 0.388194	test: 0.437424

Epoch: 47
Loss: 0.09224132842900605
ROC train: 0.939605	val: 0.779730	test: 0.797602
PRC train: 0.590349	val: 0.366756	test: 0.430097

Epoch: 48
Loss: 0.09183335716082568
ROC train: 0.941766	val: 0.790377	test: 0.805907
PRC train: 0.611057	val: 0.380201	test: 0.441680

Epoch: 49
Loss: 0.0911180926654558
ROC train: 0.942658	val: 0.786750	test: 0.802264
PRC train: 0.626796	val: 0.391434	test: 0.447616

Epoch: 50
Loss: 0.09198225059075521
ROC train: 0.940727	val: 0.788145	test: 0.800049
PRC train: 0.623248	val: 0.381970	test: 0.436778

Epoch: 51
Loss: 0.0887588845352714
ROC train: 0.941268	val: 0.790285	test: 0.797678
PRC train: 0.606719	val: 0.375036	test: 0.421521

Epoch: 52
Loss: 0.09031647707824463
ROC train: 0.948411	val: 0.789261	test: 0.815333
PRC train: 0.632237	val: 0.397279	test: 0.438770

Epoch: 53
Loss: 0.08756294339881557
ROC train: 0.949122	val: 0.784669	test: 0.804327
PRC train: 0.634260	val: 0.383430	test: 0.429501

Epoch: 54
Loss: 0.08797948616825038
ROC train: 0.942711	val: 0.775470	test: 0.803120
PRC train: 0.618005	val: 0.384151	test: 0.443062

Epoch: 55
Loss: 0.08995199573617496
ROC train: 0.947214	val: 0.795496	test: 0.802739
PRC train: 0.613766	val: 0.378560	test: 0.420421

Epoch: 56
Loss: 0.08890151397165941
ROC train: 0.947586	val: 0.786629	test: 0.814058
PRC train: 0.629862	val: 0.369561	test: 0.433271

Epoch: 57
Loss: 0.08809098774987528
ROC train: 0.952306	val: 0.794472	test: 0.801603
PRC train: 0.651513	val: 0.384154	test: 0.430431

Epoch: 58
Loss: 0.08720628132661318
ROC train: 0.949415	val: 0.786400	test: 0.798206
PRC train: 0.642724	val: 0.385901	test: 0.417542

Epoch: 59
Loss: 0.08656253508890543
ROC train: 0.957376	val: 0.783835	test: 0.799004
PRC train: 0.658497	val: 0.377300	test: 0.424309

Epoch: 60
Loss: 0.08562153496507893
ROC train: 0.954399	val: 0.773062	test: 0.801710
PRC train: 0.651524	val: 0.382247	test: 0.442120

Epoch: 61
Loss: 0.08606309775300569
ROC train: 0.958286	val: 0.801629	test: 0.812734
PRC train: 0.668473	val: 0.393512	test: 0.422158

Epoch: 62
Loss: 0.08739264575905598
ROC train: 0.956042	val: 0.788442	test: 0.806625
PRC train: 0.659112	val: 0.403869	test: 0.429866

Epoch: 63
Loss: 0.08333452886241619
ROC train: 0.958148	val: 0.777139	test: 0.806488
PRC train: 0.664261	val: 0.357684	test: 0.433626

Epoch: 64
Loss: 0.08431562855474696
ROC train: 0.960910	val: 0.790093	test: 0.810307
PRC train: 0.671760	val: 0.391643	test: 0.436741

Epoch: 65
Loss: 0.08517324781349819
ROC train: 0.957813	val: 0.781953	test: 0.795964
PRC train: 0.668477	val: 0.388806	test: 0.434671

Epoch: 66
Loss: 0.08361009789777032
ROC train: 0.961043	val: 0.792793	test: 0.807124
PRC train: 0.668027	val: 0.381480	test: 0.439475

Epoch: 67
Loss: 0.08250669009497462
ROC train: 0.958621	val: 0.782820	test: 0.807970
PRC train: 0.670031	val: 0.380235	test: 0.437640

Epoch: 68
Loss: 0.08197635016977184
ROC train: 0.961393	val: 0.787985	test: 0.798082
PRC train: 0.680434	val: 0.375831	test: 0.429492

Epoch: 69
Loss: 0.08155781838356346
ROC train: 0.966056	val: 0.792311	test: 0.803852
PRC train: 0.693296	val: 0.393835	test: 0.438069

Epoch: 70
Loss: 0.08185515097505672
ROC train: 0.963549	val: 0.780203	test: 0.805897
PRC train: 0.686119	val: 0.372741	test: 0.421060

Epoch: 71
Loss: 0.08200072051497405
ROC train: 0.966518	val: 0.783193	test: 0.807163
PRC train: 0.706929	val: 0.370526	test: 0.426803

Epoch: 72
Loss: 0.07936661412718612
ROC train: 0.964508	val: 0.786928	test: 0.805158
PRC train: 0.683466	val: 0.386634	test: 0.419835

Epoch: 73
Loss: 0.08041827335383944
ROC train: 0.970355	val: 0.780598	test: 0.813184
PRC train: 0.717147	val: 0.390090	test: 0.436649

Epoch: 74
Loss: 0.08116377551916457
ROC train: 0.970163	val: 0.781099	test: 0.799766
PRC train: 0.701179	val: 0.383543	test: 0.421452

Epoch: 75
Loss: 0.08053235755415945
ROC train: 0.967768	val: 0.784910	test: 0.801173
PRC train: 0.684980	val: 0.355962	test: 0.415560

Epoch: 76
Loss: 0.07910176833994616
ROC train: 0.972223	val: 0.781746	test: 0.809695
PRC train: 0.724427	val: 0.403619	test: 0.439372

Epoch: 77
Loss: 0.07877438707432177
ROC train: 0.967088	val: 0.787463	test: 0.806986
PRC train: 0.697782	val: 0.382388	test: 0.435387

Epoch: 78
Loss: 0.07791874667226291
ROC train: 0.971175	val: 0.781491	test: 0.808956
PRC train: 0.718062	val: 0.387570	test: 0.430911

Epoch: 79
Loss: 0.07893979298544504
ROC train: 0.970494	val: 0.785696	test: 0.804918
PRC train: 0.721622	val: 0.379606	test: 0.423910

Epoch: 80
Loss: 0.07682696065406301
ROC train: 0.969001	val: 0.769491	test: 0.804415
PRC train: 0.705236	val: 0.380956	test: 0.434545

Epoch: 81
Loss: 0.07700859055376356
ROC train: 0.974761	val: 0.788742	test: 0.793765
PRC train: 0.740235	val: 0.371291	test: 0.427666

Epoch: 82
Loss: 0.0760750341186844
ROC train: 0.974442	val: 0.794800	test: 0.807854
PRC train: 0.739106	val: 0.387189	test: 0.435354

Epoch: 83
Loss: 0.07539505331127007
ROC train: 0.963293	val: 0.780483	test: 0.801795
PRC train: 0.691404	val: 0.361752	test: 0.413048

Epoch: 84
Loss: 0.07562002694375229
ROC train: 0.975275	val: 0.780388	test: 0.804471
PRC train: 0.741975	val: 0.362753	test: 0.414112

Epoch: 85
Loss: 0.076407723750073
ROC train: 0.976833	val: 0.785595	test: 0.799932
PRC train: 0.741229	val: 0.386302	test: 0.412472

Epoch: 86
Loss: 0.07452325169771051
ROC train: 0.976067	val: 0.780763	test: 0.804029
PRC train: 0.742463	val: 0.373179	test: 0.427571

Epoch: 87
Loss: 0.07658818541405402
ROC train: 0.976740	val: 0.786767	test: 0.798633
PRC train: 0.745807	val: 0.395741	test: 0.420554

Epoch: 88
Loss: 0.07399421178568757
ROC train: 0.978282	val: 0.783274	test: 0.804131
PRC train: 0.757800	val: 0.385197	test: 0.413579

Epoch: 89
Loss: 0.07409466152434077
ROC train: 0.979161	val: 0.784519	test: 0.818510
PRC train: 0.760849	val: 0.387845	test: 0.424414

Epoch: 90
Loss: 0.07216560714218959
ROC train: 0.979519	val: 0.783192	test: 0.810322
PRC train: 0.772515	val: 0.395201	test: 0.417542

Epoch: 91
Loss: 0.07262695370557799
ROC train: 0.978294	val: 0.783357	test: 0.800690
PRC train: 0.764707	val: 0.359580	test: 0.415605

Epoch: 92
Loss: 0.07473564476163373
ROC train: 0.976426	val: 0.792192	test: 0.809495
PRC train: 0.745972	val: 0.385035	test: 0.412044

Epoch: 93
Loss: 0.07288094886340964
ROC train: 0.981628	val: 0.777910	test: 0.806498
PRC train: 0.779375	val: 0.379632	test: 0.422223

Epoch: 94
Loss: 0.07306295947392161
ROC train: 0.925257	val: 0.773997	test: 0.806490
PRC train: 0.544898	val: 0.353098	test: 0.421647

Epoch: 34
Loss: 0.0972075057720036
ROC train: 0.918494	val: 0.792545	test: 0.804626
PRC train: 0.549223	val: 0.341758	test: 0.418662

Epoch: 35
Loss: 0.09759127594031433
ROC train: 0.922226	val: 0.791030	test: 0.801762
PRC train: 0.561418	val: 0.373687	test: 0.423041

Epoch: 36
Loss: 0.09529950199179002
ROC train: 0.919292	val: 0.784118	test: 0.798428
PRC train: 0.548254	val: 0.362508	test: 0.430647

Epoch: 37
Loss: 0.09637516133632092
ROC train: 0.919545	val: 0.774593	test: 0.797289
PRC train: 0.572197	val: 0.368975	test: 0.416896

Epoch: 38
Loss: 0.09712251715511269
ROC train: 0.920653	val: 0.783029	test: 0.797884
PRC train: 0.568794	val: 0.364795	test: 0.417961

Epoch: 39
Loss: 0.09508458452858627
ROC train: 0.927086	val: 0.794280	test: 0.806892
PRC train: 0.577273	val: 0.362474	test: 0.446769

Epoch: 40
Loss: 0.09485148460974599
ROC train: 0.934145	val: 0.792172	test: 0.805313
PRC train: 0.594713	val: 0.386252	test: 0.434227

Epoch: 41
Loss: 0.09445492820037608
ROC train: 0.929749	val: 0.780002	test: 0.798932
PRC train: 0.581195	val: 0.386175	test: 0.415490

Epoch: 42
Loss: 0.09409784704868604
ROC train: 0.935727	val: 0.774598	test: 0.802977
PRC train: 0.590763	val: 0.373987	test: 0.427362

Epoch: 43
Loss: 0.09216666757233617
ROC train: 0.937812	val: 0.789564	test: 0.810285
PRC train: 0.589392	val: 0.349831	test: 0.415694

Epoch: 44
Loss: 0.0930380415778368
ROC train: 0.942844	val: 0.781678	test: 0.803585
PRC train: 0.627452	val: 0.393790	test: 0.446470

Epoch: 45
Loss: 0.0928845211012773
ROC train: 0.941426	val: 0.775771	test: 0.809027
PRC train: 0.564590	val: 0.326139	test: 0.395314

Epoch: 46
Loss: 0.09225074687261245
ROC train: 0.940758	val: 0.792353	test: 0.810462
PRC train: 0.615542	val: 0.393731	test: 0.428256

Epoch: 47
Loss: 0.09031026081850096
ROC train: 0.944828	val: 0.780216	test: 0.811436
PRC train: 0.610529	val: 0.372688	test: 0.430185

Epoch: 48
Loss: 0.0904778043687351
ROC train: 0.950652	val: 0.802305	test: 0.816917
PRC train: 0.627218	val: 0.387832	test: 0.437432

Epoch: 49
Loss: 0.09013744884980286
ROC train: 0.952545	val: 0.788074	test: 0.809265
PRC train: 0.638516	val: 0.396783	test: 0.416352

Epoch: 50
Loss: 0.08868783865136426
ROC train: 0.952190	val: 0.789844	test: 0.809668
PRC train: 0.642150	val: 0.377449	test: 0.413026

Epoch: 51
Loss: 0.08832573038654178
ROC train: 0.951998	val: 0.782995	test: 0.805663
PRC train: 0.635681	val: 0.370001	test: 0.441627

Epoch: 52
Loss: 0.08896427345522374
ROC train: 0.955173	val: 0.786858	test: 0.808055
PRC train: 0.641639	val: 0.379261	test: 0.423122

Epoch: 53
Loss: 0.0874648598038094
ROC train: 0.957733	val: 0.787622	test: 0.809717
PRC train: 0.660927	val: 0.401525	test: 0.434262

Epoch: 54
Loss: 0.08720603367089169
ROC train: 0.950898	val: 0.793950	test: 0.797958
PRC train: 0.640818	val: 0.394475	test: 0.411479

Epoch: 55
Loss: 0.08730463886608307
ROC train: 0.954915	val: 0.781051	test: 0.815318
PRC train: 0.657477	val: 0.378232	test: 0.413823

Epoch: 56
Loss: 0.08701668523156628
ROC train: 0.957980	val: 0.784243	test: 0.800397
PRC train: 0.652342	val: 0.395508	test: 0.394758

Epoch: 57
Loss: 0.08699168936021251
ROC train: 0.952812	val: 0.778081	test: 0.802318
PRC train: 0.658450	val: 0.404986	test: 0.404565

Epoch: 58
Loss: 0.0851616713877089
ROC train: 0.959469	val: 0.784549	test: 0.811248
PRC train: 0.665279	val: 0.388785	test: 0.428641

Epoch: 59
Loss: 0.087639930960893
ROC train: 0.963177	val: 0.790212	test: 0.802081
PRC train: 0.674096	val: 0.395356	test: 0.418800

Epoch: 60
Loss: 0.08361767678727533
ROC train: 0.960493	val: 0.791997	test: 0.795645
PRC train: 0.670895	val: 0.411518	test: 0.407560

Epoch: 61
Loss: 0.0858834070217203
ROC train: 0.956642	val: 0.779170	test: 0.800478
PRC train: 0.665410	val: 0.396046	test: 0.420097

Epoch: 62
Loss: 0.08456801796430405
ROC train: 0.963486	val: 0.776935	test: 0.807092
PRC train: 0.685721	val: 0.380585	test: 0.419552

Epoch: 63
Loss: 0.08435962068498998
ROC train: 0.961295	val: 0.781711	test: 0.808502
PRC train: 0.680119	val: 0.385210	test: 0.413638

Epoch: 64
Loss: 0.0846068412442798
ROC train: 0.958698	val: 0.778286	test: 0.809486
PRC train: 0.673528	val: 0.399920	test: 0.413928

Epoch: 65
Loss: 0.08232365146670664
ROC train: 0.959228	val: 0.777774	test: 0.796127
PRC train: 0.680302	val: 0.410046	test: 0.412494

Epoch: 66
Loss: 0.08056626072799135
ROC train: 0.960107	val: 0.785210	test: 0.801377
PRC train: 0.691814	val: 0.389248	test: 0.402239

Epoch: 67
Loss: 0.08100421383795495
ROC train: 0.964811	val: 0.791124	test: 0.801234
PRC train: 0.695915	val: 0.408859	test: 0.427314

Epoch: 68
Loss: 0.08029689541959723
ROC train: 0.961646	val: 0.791039	test: 0.798557
PRC train: 0.677713	val: 0.378452	test: 0.408754

Epoch: 69
Loss: 0.08196111090066821
ROC train: 0.964707	val: 0.778314	test: 0.795336
PRC train: 0.677792	val: 0.369309	test: 0.407540

Epoch: 70
Loss: 0.07998834928574446
ROC train: 0.968712	val: 0.792946	test: 0.811014
PRC train: 0.704079	val: 0.397466	test: 0.415787

Epoch: 71
Loss: 0.08033097963878796
ROC train: 0.968524	val: 0.791320	test: 0.805152
PRC train: 0.701834	val: 0.390479	test: 0.406540

Epoch: 72
Loss: 0.07925676485054282
ROC train: 0.972399	val: 0.783338	test: 0.798777
PRC train: 0.727124	val: 0.392757	test: 0.405056

Epoch: 73
Loss: 0.08085927615594567
ROC train: 0.972212	val: 0.787072	test: 0.796361
PRC train: 0.724771	val: 0.397958	test: 0.403695

Epoch: 74
Loss: 0.0792551284064946
ROC train: 0.971730	val: 0.777285	test: 0.790877
PRC train: 0.714703	val: 0.386652	test: 0.405956

Epoch: 75
Loss: 0.07831980685636997
ROC train: 0.972427	val: 0.792536	test: 0.789794
PRC train: 0.721447	val: 0.408971	test: 0.400780

Epoch: 76
Loss: 0.07603516937741095
ROC train: 0.974677	val: 0.789117	test: 0.800920
PRC train: 0.737457	val: 0.399641	test: 0.409923

Epoch: 77
Loss: 0.07703877182391537
ROC train: 0.969311	val: 0.802115	test: 0.797233
PRC train: 0.712219	val: 0.406932	test: 0.395104

Epoch: 78
Loss: 0.07818949688100524
ROC train: 0.974226	val: 0.776641	test: 0.811229
PRC train: 0.730107	val: 0.354681	test: 0.416785

Epoch: 79
Loss: 0.07703710396790868
ROC train: 0.976687	val: 0.778459	test: 0.805662
PRC train: 0.744728	val: 0.380602	test: 0.417029

Epoch: 80
Loss: 0.07708707497189453
ROC train: 0.975903	val: 0.784275	test: 0.802412
PRC train: 0.737108	val: 0.398982	test: 0.414632

Epoch: 81
Loss: 0.07381517505885433
ROC train: 0.976379	val: 0.790942	test: 0.801434
PRC train: 0.746539	val: 0.367227	test: 0.406031

Epoch: 82
Loss: 0.07477868031321157
ROC train: 0.976546	val: 0.788049	test: 0.814145
PRC train: 0.747330	val: 0.374725	test: 0.403231

Epoch: 83
Loss: 0.07420302002107505
ROC train: 0.978277	val: 0.785730	test: 0.807161
PRC train: 0.753960	val: 0.384631	test: 0.425298

Epoch: 84
Loss: 0.07463056945863897
ROC train: 0.976601	val: 0.783700	test: 0.806948
PRC train: 0.746688	val: 0.366722	test: 0.389925

Epoch: 85
Loss: 0.07357562331557715
ROC train: 0.977638	val: 0.773420	test: 0.810678
PRC train: 0.756420	val: 0.382215	test: 0.428988

Epoch: 86
Loss: 0.0741961008323878
ROC train: 0.979341	val: 0.782785	test: 0.810191
PRC train: 0.754224	val: 0.360038	test: 0.389972

Epoch: 87
Loss: 0.07323506751844282
ROC train: 0.978801	val: 0.780846	test: 0.801236
PRC train: 0.759709	val: 0.378661	test: 0.402516

Epoch: 88
Loss: 0.07154407191465248
ROC train: 0.980038	val: 0.787643	test: 0.797215
PRC train: 0.760362	val: 0.392607	test: 0.402083

Epoch: 89
Loss: 0.07149425007359977
ROC train: 0.973507	val: 0.776702	test: 0.802963
PRC train: 0.730529	val: 0.364270	test: 0.402149

Epoch: 90
Loss: 0.07324427151919527
ROC train: 0.977444	val: 0.786474	test: 0.793633
PRC train: 0.765198	val: 0.395578	test: 0.394392

Epoch: 91
Loss: 0.06952736451304979
ROC train: 0.980677	val: 0.782846	test: 0.792274
PRC train: 0.768727	val: 0.406068	test: 0.389882

Epoch: 92
Loss: 0.07185268727581563
ROC train: 0.982302	val: 0.782684	test: 0.798482
PRC train: 0.791207	val: 0.383168	test: 0.418493

Epoch: 93
Loss: 0.0694478670543258
ROC train: 0.978581	val: 0.776222	test: 0.794918
PRC train: 0.766292	val: 0.383474	test: 0.415314

Epoch: 94
Loss: 0.07188287238972256
ROC train: 0.919592	val: 0.777457	test: 0.805405
PRC train: 0.562663	val: 0.368772	test: 0.422512

Epoch: 34
Loss: 0.09970555338319409
ROC train: 0.916924	val: 0.785610	test: 0.814847
PRC train: 0.551374	val: 0.355342	test: 0.429719

Epoch: 35
Loss: 0.09814221862683206
ROC train: 0.915233	val: 0.764075	test: 0.803624
PRC train: 0.550732	val: 0.350968	test: 0.434598

Epoch: 36
Loss: 0.09868577998290268
ROC train: 0.920130	val: 0.775816	test: 0.804529
PRC train: 0.553305	val: 0.363402	test: 0.432892

Epoch: 37
Loss: 0.09962018156453532
ROC train: 0.923369	val: 0.773762	test: 0.808605
PRC train: 0.552389	val: 0.339856	test: 0.422577

Epoch: 38
Loss: 0.09638105788263679
ROC train: 0.911842	val: 0.778215	test: 0.809909
PRC train: 0.534038	val: 0.354235	test: 0.431932

Epoch: 39
Loss: 0.09710877206074923
ROC train: 0.920968	val: 0.767807	test: 0.810298
PRC train: 0.555577	val: 0.359916	test: 0.452850

Epoch: 40
Loss: 0.09713129054509274
ROC train: 0.929833	val: 0.779759	test: 0.819866
PRC train: 0.580377	val: 0.364037	test: 0.431595

Epoch: 41
Loss: 0.09543911619339415
ROC train: 0.935839	val: 0.780760	test: 0.812114
PRC train: 0.604525	val: 0.385059	test: 0.445737

Epoch: 42
Loss: 0.0935352521334075
ROC train: 0.935439	val: 0.786833	test: 0.808011
PRC train: 0.597279	val: 0.387375	test: 0.437511

Epoch: 43
Loss: 0.09734538304226799
ROC train: 0.932933	val: 0.793736	test: 0.820540
PRC train: 0.556602	val: 0.354819	test: 0.421799

Epoch: 44
Loss: 0.09454466049779842
ROC train: 0.937314	val: 0.781373	test: 0.810093
PRC train: 0.584872	val: 0.386064	test: 0.432340

Epoch: 45
Loss: 0.09144391630991211
ROC train: 0.940579	val: 0.783627	test: 0.806850
PRC train: 0.607478	val: 0.388006	test: 0.446251

Epoch: 46
Loss: 0.09210113336107062
ROC train: 0.933735	val: 0.780970	test: 0.809873
PRC train: 0.567787	val: 0.359318	test: 0.405529

Epoch: 47
Loss: 0.09218089198175561
ROC train: 0.942439	val: 0.774248	test: 0.799456
PRC train: 0.602550	val: 0.366145	test: 0.413253

Epoch: 48
Loss: 0.09104616952024015
ROC train: 0.941243	val: 0.778712	test: 0.810665
PRC train: 0.596004	val: 0.375861	test: 0.447871

Epoch: 49
Loss: 0.09103787249031131
ROC train: 0.932279	val: 0.788166	test: 0.807778
PRC train: 0.569173	val: 0.335638	test: 0.400914

Epoch: 50
Loss: 0.09072745247068174
ROC train: 0.944554	val: 0.767184	test: 0.796966
PRC train: 0.618051	val: 0.370859	test: 0.445155

Epoch: 51
Loss: 0.0912498736069824
ROC train: 0.948408	val: 0.771966	test: 0.807213
PRC train: 0.626756	val: 0.385806	test: 0.453701

Epoch: 52
Loss: 0.09065733437896809
ROC train: 0.944498	val: 0.768185	test: 0.808457
PRC train: 0.626207	val: 0.371194	test: 0.439614

Epoch: 53
Loss: 0.08822278202607392
ROC train: 0.948387	val: 0.765523	test: 0.804361
PRC train: 0.640274	val: 0.377522	test: 0.453959

Epoch: 54
Loss: 0.08897250291995376
ROC train: 0.949517	val: 0.783952	test: 0.813315
PRC train: 0.625669	val: 0.370575	test: 0.431064

Epoch: 55
Loss: 0.08861767362160856
ROC train: 0.945938	val: 0.779576	test: 0.804345
PRC train: 0.628449	val: 0.375301	test: 0.413909

Epoch: 56
Loss: 0.08981555306702069
ROC train: 0.950558	val: 0.782411	test: 0.812326
PRC train: 0.635302	val: 0.381954	test: 0.440470

Epoch: 57
Loss: 0.08895440879202107
ROC train: 0.955345	val: 0.776102	test: 0.811428
PRC train: 0.649920	val: 0.383643	test: 0.443484

Epoch: 58
Loss: 0.08776723850719488
ROC train: 0.953972	val: 0.780975	test: 0.806160
PRC train: 0.648830	val: 0.412041	test: 0.439278

Epoch: 59
Loss: 0.08612613854279194
ROC train: 0.958292	val: 0.786459	test: 0.815523
PRC train: 0.661520	val: 0.396780	test: 0.433668

Epoch: 60
Loss: 0.08638178248102317
ROC train: 0.958917	val: 0.782498	test: 0.806272
PRC train: 0.668042	val: 0.394375	test: 0.441748

Epoch: 61
Loss: 0.08551098172539803
ROC train: 0.959620	val: 0.771645	test: 0.815920
PRC train: 0.656230	val: 0.387078	test: 0.458809

Epoch: 62
Loss: 0.08416183959344668
ROC train: 0.962354	val: 0.780995	test: 0.800558
PRC train: 0.669313	val: 0.417084	test: 0.445820

Epoch: 63
Loss: 0.08561369482410434
ROC train: 0.954889	val: 0.770722	test: 0.806081
PRC train: 0.645831	val: 0.377844	test: 0.435958

Epoch: 64
Loss: 0.08701559643667682
ROC train: 0.959360	val: 0.771095	test: 0.799069
PRC train: 0.679889	val: 0.392832	test: 0.438544

Epoch: 65
Loss: 0.08238607046025483
ROC train: 0.959045	val: 0.781353	test: 0.805653
PRC train: 0.661687	val: 0.378880	test: 0.423989

Epoch: 66
Loss: 0.08506994866339453
ROC train: 0.966462	val: 0.772398	test: 0.798502
PRC train: 0.695773	val: 0.388589	test: 0.433150

Epoch: 67
Loss: 0.08368564147759096
ROC train: 0.966903	val: 0.782208	test: 0.807668
PRC train: 0.687575	val: 0.381123	test: 0.438102

Epoch: 68
Loss: 0.08391965673297869
ROC train: 0.965258	val: 0.780049	test: 0.801699
PRC train: 0.684355	val: 0.377487	test: 0.417614

Epoch: 69
Loss: 0.0815302379548309
ROC train: 0.967014	val: 0.775734	test: 0.804885
PRC train: 0.691564	val: 0.382940	test: 0.433969

Epoch: 70
Loss: 0.08297803186815754
ROC train: 0.967063	val: 0.777452	test: 0.814999
PRC train: 0.699376	val: 0.391510	test: 0.440082

Epoch: 71
Loss: 0.0815092618574778
ROC train: 0.964623	val: 0.775745	test: 0.806298
PRC train: 0.685467	val: 0.361926	test: 0.427106

Epoch: 72
Loss: 0.08038239189123661
ROC train: 0.969650	val: 0.767761	test: 0.803470
PRC train: 0.705276	val: 0.396397	test: 0.427688

Epoch: 73
Loss: 0.08060227297701163
ROC train: 0.970388	val: 0.767973	test: 0.796514
PRC train: 0.707642	val: 0.390194	test: 0.421965

Epoch: 74
Loss: 0.07942831209047432
ROC train: 0.962976	val: 0.772649	test: 0.801450
PRC train: 0.658026	val: 0.348084	test: 0.400403

Epoch: 75
Loss: 0.07980006011802726
ROC train: 0.968692	val: 0.780086	test: 0.815009
PRC train: 0.709667	val: 0.389853	test: 0.432484

Epoch: 76
Loss: 0.08047604235470117
ROC train: 0.964281	val: 0.781851	test: 0.800692
PRC train: 0.679713	val: 0.376495	test: 0.419494

Epoch: 77
Loss: 0.07946905373263516
ROC train: 0.971203	val: 0.780064	test: 0.813777
PRC train: 0.702917	val: 0.381007	test: 0.425263

Epoch: 78
Loss: 0.07832302823846723
ROC train: 0.973795	val: 0.775391	test: 0.810241
PRC train: 0.729122	val: 0.383407	test: 0.445657

Epoch: 79
Loss: 0.07753774748713162
ROC train: 0.970863	val: 0.776730	test: 0.811930
PRC train: 0.713512	val: 0.379897	test: 0.421598

Epoch: 80
Loss: 0.07816772001728017
ROC train: 0.971259	val: 0.777949	test: 0.808296
PRC train: 0.716891	val: 0.391092	test: 0.415891

Epoch: 81
Loss: 0.07698712351168763
ROC train: 0.976761	val: 0.779550	test: 0.803689
PRC train: 0.742643	val: 0.403545	test: 0.431846

Epoch: 82
Loss: 0.07813243798216433
ROC train: 0.974295	val: 0.777291	test: 0.803039
PRC train: 0.724708	val: 0.365183	test: 0.416254

Epoch: 83
Loss: 0.07623763411453306
ROC train: 0.974739	val: 0.774821	test: 0.806455
PRC train: 0.737103	val: 0.386098	test: 0.431441

Epoch: 84
Loss: 0.07654424316026506
ROC train: 0.972037	val: 0.779075	test: 0.808570
PRC train: 0.715533	val: 0.365691	test: 0.422000

Epoch: 85
Loss: 0.07568532703235283
ROC train: 0.976793	val: 0.777438	test: 0.802853
PRC train: 0.744219	val: 0.405285	test: 0.415515

Epoch: 86
Loss: 0.0743229331092669
ROC train: 0.977317	val: 0.778099	test: 0.810764
PRC train: 0.749475	val: 0.389925	test: 0.425979

Epoch: 87
Loss: 0.07467523639637534
ROC train: 0.977879	val: 0.787942	test: 0.805541
PRC train: 0.751925	val: 0.379500	test: 0.414790

Epoch: 88
Loss: 0.0733410467520084
ROC train: 0.978028	val: 0.776186	test: 0.805277
PRC train: 0.752327	val: 0.381345	test: 0.419911

Epoch: 89
Loss: 0.07276716443573528
ROC train: 0.977624	val: 0.771495	test: 0.809111
PRC train: 0.737425	val: 0.393474	test: 0.413275

Epoch: 90
Loss: 0.07208801721786853
ROC train: 0.980165	val: 0.778215	test: 0.807375
PRC train: 0.757589	val: 0.388731	test: 0.421146

Epoch: 91
Loss: 0.07483282885371757
ROC train: 0.979938	val: 0.773593	test: 0.800207
PRC train: 0.757552	val: 0.395876	test: 0.409778

Epoch: 92
Loss: 0.07182677974434303
ROC train: 0.978934	val: 0.775476	test: 0.797376
PRC train: 0.730311	val: 0.375654	test: 0.406729

Epoch: 93
Loss: 0.07331322322360811
ROC train: 0.981740	val: 0.775616	test: 0.807066
PRC train: 0.767805	val: 0.390036	test: 0.428059

ROC train: 0.914006	val: 0.803698	test: 0.822507
PRC train: 0.533863	val: 0.417846	test: 0.436228

Epoch: 34
Loss: 0.09805324637702563
ROC train: 0.913060	val: 0.807486	test: 0.822153
PRC train: 0.520855	val: 0.405157	test: 0.441376

Epoch: 35
Loss: 0.0984963386515369
ROC train: 0.914803	val: 0.815231	test: 0.832926
PRC train: 0.531019	val: 0.429624	test: 0.442767

Epoch: 36
Loss: 0.09701973396045405
ROC train: 0.914472	val: 0.810478	test: 0.815115
PRC train: 0.540618	val: 0.433157	test: 0.431503

Epoch: 37
Loss: 0.09688839703696403
ROC train: 0.921027	val: 0.809413	test: 0.836600
PRC train: 0.570491	val: 0.440259	test: 0.469568

Epoch: 38
Loss: 0.09758433625717727
ROC train: 0.922423	val: 0.808849	test: 0.829128
PRC train: 0.564570	val: 0.428860	test: 0.447084

Epoch: 39
Loss: 0.09536266570339665
ROC train: 0.930312	val: 0.812123	test: 0.842867
PRC train: 0.576888	val: 0.448367	test: 0.467671

Epoch: 40
Loss: 0.09532369796904183
ROC train: 0.925941	val: 0.811008	test: 0.827656
PRC train: 0.574938	val: 0.443739	test: 0.458258

Epoch: 41
Loss: 0.09504662868291645
ROC train: 0.927745	val: 0.814375	test: 0.828557
PRC train: 0.572304	val: 0.436358	test: 0.457919

Epoch: 42
Loss: 0.09505224904245654
ROC train: 0.930499	val: 0.813296	test: 0.822359
PRC train: 0.587581	val: 0.451971	test: 0.458543

Epoch: 43
Loss: 0.09234553791299024
ROC train: 0.931637	val: 0.803031	test: 0.808492
PRC train: 0.576723	val: 0.427205	test: 0.422077

Epoch: 44
Loss: 0.09441160657798019
ROC train: 0.935850	val: 0.800016	test: 0.829135
PRC train: 0.600791	val: 0.452504	test: 0.453110

Epoch: 45
Loss: 0.09148605608759626
ROC train: 0.938483	val: 0.801336	test: 0.824389
PRC train: 0.596997	val: 0.438915	test: 0.429045

Epoch: 46
Loss: 0.09367839324578128
ROC train: 0.937022	val: 0.812762	test: 0.826930
PRC train: 0.606883	val: 0.454051	test: 0.455211

Epoch: 47
Loss: 0.09176047064741986
ROC train: 0.944011	val: 0.805174	test: 0.819749
PRC train: 0.612481	val: 0.437840	test: 0.424217

Epoch: 48
Loss: 0.09148705555189318
ROC train: 0.944972	val: 0.800894	test: 0.822649
PRC train: 0.616003	val: 0.430903	test: 0.434662

Epoch: 49
Loss: 0.09031908422602887
ROC train: 0.942547	val: 0.803847	test: 0.832923
PRC train: 0.619306	val: 0.430771	test: 0.420989

Epoch: 50
Loss: 0.08968708229625798
ROC train: 0.947072	val: 0.819320	test: 0.813784
PRC train: 0.617350	val: 0.456543	test: 0.402159

Epoch: 51
Loss: 0.09017209488892429
ROC train: 0.941702	val: 0.806881	test: 0.831812
PRC train: 0.601140	val: 0.430739	test: 0.432519

Epoch: 52
Loss: 0.08977339754033135
ROC train: 0.947326	val: 0.810304	test: 0.834056
PRC train: 0.632089	val: 0.458101	test: 0.463817

Epoch: 53
Loss: 0.0883341661725113
ROC train: 0.950900	val: 0.814720	test: 0.825154
PRC train: 0.636717	val: 0.464680	test: 0.428634

Epoch: 54
Loss: 0.08752655427548123
ROC train: 0.944400	val: 0.818968	test: 0.807636
PRC train: 0.615572	val: 0.441916	test: 0.403266

Epoch: 55
Loss: 0.08749426168890963
ROC train: 0.954233	val: 0.817707	test: 0.829794
PRC train: 0.646932	val: 0.448877	test: 0.438773

Epoch: 56
Loss: 0.08658317563601578
ROC train: 0.951624	val: 0.811200	test: 0.822868
PRC train: 0.642616	val: 0.446366	test: 0.422028

Epoch: 57
Loss: 0.08540997682541307
ROC train: 0.954999	val: 0.808326	test: 0.816263
PRC train: 0.659197	val: 0.437125	test: 0.433822

Epoch: 58
Loss: 0.08703889172426622
ROC train: 0.955495	val: 0.811118	test: 0.821869
PRC train: 0.638005	val: 0.425625	test: 0.420022

Epoch: 59
Loss: 0.08569091909830134
ROC train: 0.956845	val: 0.815433	test: 0.827765
PRC train: 0.661422	val: 0.449599	test: 0.433701

Epoch: 60
Loss: 0.08592052542734573
ROC train: 0.953612	val: 0.799413	test: 0.816320
PRC train: 0.646219	val: 0.433498	test: 0.449755

Epoch: 61
Loss: 0.08455853054850497
ROC train: 0.955859	val: 0.806555	test: 0.827013
PRC train: 0.655438	val: 0.433151	test: 0.428297

Epoch: 62
Loss: 0.08526545420390712
ROC train: 0.958504	val: 0.813435	test: 0.829481
PRC train: 0.660534	val: 0.453394	test: 0.435371

Epoch: 63
Loss: 0.08457498358745055
ROC train: 0.957666	val: 0.810674	test: 0.830903
PRC train: 0.661173	val: 0.425644	test: 0.415245

Epoch: 64
Loss: 0.08346156701789573
ROC train: 0.963082	val: 0.811729	test: 0.824291
PRC train: 0.679432	val: 0.434967	test: 0.428298

Epoch: 65
Loss: 0.08283992309746013
ROC train: 0.960174	val: 0.808407	test: 0.823797
PRC train: 0.686958	val: 0.448262	test: 0.427125

Epoch: 66
Loss: 0.08184385084846076
ROC train: 0.961160	val: 0.807107	test: 0.817288
PRC train: 0.686325	val: 0.435359	test: 0.408416

Epoch: 67
Loss: 0.08291272414424082
ROC train: 0.965983	val: 0.814523	test: 0.835393
PRC train: 0.696821	val: 0.438461	test: 0.419404

Epoch: 68
Loss: 0.08093645058971596
ROC train: 0.963769	val: 0.809189	test: 0.832316
PRC train: 0.685894	val: 0.454948	test: 0.452435

Epoch: 69
Loss: 0.08049777869359376
ROC train: 0.966118	val: 0.816357	test: 0.830916
PRC train: 0.701201	val: 0.461341	test: 0.434773

Epoch: 70
Loss: 0.07973912605170257
ROC train: 0.968150	val: 0.804725	test: 0.813127
PRC train: 0.710505	val: 0.448548	test: 0.438509

Epoch: 71
Loss: 0.08121420784555464
ROC train: 0.969076	val: 0.818797	test: 0.820592
PRC train: 0.715786	val: 0.442915	test: 0.431163

Epoch: 72
Loss: 0.07920610315491515
ROC train: 0.966280	val: 0.804866	test: 0.826459
PRC train: 0.702313	val: 0.439424	test: 0.447435

Epoch: 73
Loss: 0.08000687956456667
ROC train: 0.962600	val: 0.805838	test: 0.820138
PRC train: 0.685698	val: 0.447396	test: 0.432065

Epoch: 74
Loss: 0.08037055808480033
ROC train: 0.969050	val: 0.806473	test: 0.820131
PRC train: 0.714975	val: 0.446642	test: 0.432414

Epoch: 75
Loss: 0.07999162418403792
ROC train: 0.967747	val: 0.803522	test: 0.819514
PRC train: 0.713917	val: 0.439616	test: 0.428143

Epoch: 76
Loss: 0.07980359801633248
ROC train: 0.966509	val: 0.806209	test: 0.822642
PRC train: 0.708184	val: 0.454054	test: 0.432786

Epoch: 77
Loss: 0.07819135010800167
ROC train: 0.968121	val: 0.802871	test: 0.817595
PRC train: 0.715410	val: 0.439455	test: 0.419406

Epoch: 78
Loss: 0.07734636030686645
ROC train: 0.969335	val: 0.807571	test: 0.828574
PRC train: 0.722995	val: 0.455980	test: 0.436518

Epoch: 79
Loss: 0.07655238824836853
ROC train: 0.968440	val: 0.816469	test: 0.822824
PRC train: 0.724437	val: 0.457371	test: 0.418621

Epoch: 80
Loss: 0.07715781264959559
ROC train: 0.974337	val: 0.800969	test: 0.825707
PRC train: 0.737362	val: 0.438205	test: 0.418935

Epoch: 81
Loss: 0.07604171157695011
ROC train: 0.973376	val: 0.800596	test: 0.811875
PRC train: 0.732229	val: 0.443107	test: 0.417985

Epoch: 82
Loss: 0.07665560890429451
ROC train: 0.972736	val: 0.807844	test: 0.823262
PRC train: 0.726372	val: 0.438723	test: 0.394962

Epoch: 83
Loss: 0.07478318264605474
ROC train: 0.969814	val: 0.807806	test: 0.822157
PRC train: 0.721795	val: 0.426795	test: 0.423830

Epoch: 84
Loss: 0.0748550618789273
ROC train: 0.962666	val: 0.811190	test: 0.808353
PRC train: 0.699352	val: 0.421856	test: 0.382331

Epoch: 85
Loss: 0.07534298783891873
ROC train: 0.975481	val: 0.807971	test: 0.832470
PRC train: 0.749078	val: 0.433591	test: 0.421957

Epoch: 86
Loss: 0.07345204935746016
ROC train: 0.974943	val: 0.808809	test: 0.811044
PRC train: 0.746366	val: 0.446358	test: 0.423786

Epoch: 87
Loss: 0.07451479742872362
ROC train: 0.975470	val: 0.799207	test: 0.812911
PRC train: 0.739139	val: 0.439840	test: 0.401621

Epoch: 88
Loss: 0.07275066834572275
ROC train: 0.975484	val: 0.786628	test: 0.808996
PRC train: 0.746241	val: 0.432252	test: 0.387055

Epoch: 89
Loss: 0.07408067432808982
ROC train: 0.975134	val: 0.802411	test: 0.815893
PRC train: 0.722551	val: 0.434967	test: 0.360074

Epoch: 90
Loss: 0.07356811064396945
ROC train: 0.976677	val: 0.811217	test: 0.819201
PRC train: 0.758260	val: 0.434912	test: 0.412472

Epoch: 91
Loss: 0.07360935126738691
ROC train: 0.978042	val: 0.805793	test: 0.810132
PRC train: 0.760579	val: 0.439519	test: 0.419503

Epoch: 92
Loss: 0.07198472148270314
ROC train: 0.979115	val: 0.807578	test: 0.814640
PRC train: 0.763336	val: 0.445965	test: 0.418508

Epoch: 93
Loss: 0.07107459997073726
ROC train: 0.978764	val: 0.799663	test: 0.831351
PRC train: 0.764327	val: 0.430906	test: 0.407906
ROC train: 0.910263	val: 0.794971	test: 0.824861
PRC train: 0.546663	val: 0.441130	test: 0.454670

Epoch: 34
Loss: 0.09839602751986809
ROC train: 0.914072	val: 0.808933	test: 0.831162
PRC train: 0.545224	val: 0.417598	test: 0.442596

Epoch: 35
Loss: 0.0990172990338512
ROC train: 0.913161	val: 0.801117	test: 0.831199
PRC train: 0.552746	val: 0.434015	test: 0.451129

Epoch: 36
Loss: 0.09797355393495329
ROC train: 0.907697	val: 0.806331	test: 0.826388
PRC train: 0.538686	val: 0.425745	test: 0.433047

Epoch: 37
Loss: 0.09806749328206522
ROC train: 0.919026	val: 0.814135	test: 0.837890
PRC train: 0.564175	val: 0.439652	test: 0.467756

Epoch: 38
Loss: 0.09634746237968654
ROC train: 0.918823	val: 0.805702	test: 0.837744
PRC train: 0.560494	val: 0.401129	test: 0.452325

Epoch: 39
Loss: 0.09526748676299023
ROC train: 0.925773	val: 0.814873	test: 0.818750
PRC train: 0.568806	val: 0.433607	test: 0.453731

Epoch: 40
Loss: 0.09373248417169854
ROC train: 0.929843	val: 0.803657	test: 0.833669
PRC train: 0.581148	val: 0.419778	test: 0.447885

Epoch: 41
Loss: 0.09429292313813138
ROC train: 0.926766	val: 0.799932	test: 0.825377
PRC train: 0.572385	val: 0.405726	test: 0.432123

Epoch: 42
Loss: 0.094549063790402
ROC train: 0.931011	val: 0.804053	test: 0.832696
PRC train: 0.584360	val: 0.434479	test: 0.448545

Epoch: 43
Loss: 0.0944214222541826
ROC train: 0.931500	val: 0.807271	test: 0.830577
PRC train: 0.594877	val: 0.429428	test: 0.463756

Epoch: 44
Loss: 0.09293396116522248
ROC train: 0.936377	val: 0.809077	test: 0.834717
PRC train: 0.596698	val: 0.418514	test: 0.443024

Epoch: 45
Loss: 0.0925699775081108
ROC train: 0.935944	val: 0.805215	test: 0.831972
PRC train: 0.601794	val: 0.419998	test: 0.450444

Epoch: 46
Loss: 0.09352068751604181
ROC train: 0.933411	val: 0.805396	test: 0.833255
PRC train: 0.582346	val: 0.433493	test: 0.462379

Epoch: 47
Loss: 0.09252502850219588
ROC train: 0.939261	val: 0.804292	test: 0.826224
PRC train: 0.610938	val: 0.412027	test: 0.451903

Epoch: 48
Loss: 0.09097433594621883
ROC train: 0.936662	val: 0.801519	test: 0.814978
PRC train: 0.604276	val: 0.416610	test: 0.443559

Epoch: 49
Loss: 0.0917771708769043
ROC train: 0.937711	val: 0.804503	test: 0.826327
PRC train: 0.621042	val: 0.420154	test: 0.441849

Epoch: 50
Loss: 0.09055982855625683
ROC train: 0.939465	val: 0.805882	test: 0.815903
PRC train: 0.619875	val: 0.427730	test: 0.439451

Epoch: 51
Loss: 0.08940437160210146
ROC train: 0.943602	val: 0.812050	test: 0.825163
PRC train: 0.629428	val: 0.413387	test: 0.441310

Epoch: 52
Loss: 0.0883965627853254
ROC train: 0.936804	val: 0.796158	test: 0.818470
PRC train: 0.623630	val: 0.412642	test: 0.446241

Epoch: 53
Loss: 0.08830351496633339
ROC train: 0.937426	val: 0.803099	test: 0.818229
PRC train: 0.618321	val: 0.410862	test: 0.442274

Epoch: 54
Loss: 0.08674477987073682
ROC train: 0.946290	val: 0.810738	test: 0.830068
PRC train: 0.637572	val: 0.428025	test: 0.444101

Epoch: 55
Loss: 0.08901072754718292
ROC train: 0.948085	val: 0.800270	test: 0.822799
PRC train: 0.642490	val: 0.434954	test: 0.459796

Epoch: 56
Loss: 0.08702840569684353
ROC train: 0.943374	val: 0.794868	test: 0.814725
PRC train: 0.628344	val: 0.403761	test: 0.434947

Epoch: 57
Loss: 0.08690807973921619
ROC train: 0.953452	val: 0.805787	test: 0.823768
PRC train: 0.649881	val: 0.419774	test: 0.427592

Epoch: 58
Loss: 0.08770457824649418
ROC train: 0.952561	val: 0.808662	test: 0.821226
PRC train: 0.644629	val: 0.430661	test: 0.446516

Epoch: 59
Loss: 0.08754030193649681
ROC train: 0.952763	val: 0.808255	test: 0.820615
PRC train: 0.647396	val: 0.445717	test: 0.435212

Epoch: 60
Loss: 0.08706601525857303
ROC train: 0.955330	val: 0.815055	test: 0.819098
PRC train: 0.667723	val: 0.439073	test: 0.430158

Epoch: 61
Loss: 0.08629545105532514
ROC train: 0.951266	val: 0.814822	test: 0.834063
PRC train: 0.659665	val: 0.430874	test: 0.450334

Epoch: 62
Loss: 0.08521781422541115
ROC train: 0.959632	val: 0.808092	test: 0.801918
PRC train: 0.678486	val: 0.442330	test: 0.437124

Epoch: 63
Loss: 0.08456476938531966
ROC train: 0.956235	val: 0.806815	test: 0.822664
PRC train: 0.662500	val: 0.437381	test: 0.423922

Epoch: 64
Loss: 0.0828384639644029
ROC train: 0.953516	val: 0.806609	test: 0.817765
PRC train: 0.663552	val: 0.440376	test: 0.430777

Epoch: 65
Loss: 0.0838539377433509
ROC train: 0.954372	val: 0.808141	test: 0.815077
PRC train: 0.650750	val: 0.431759	test: 0.415766

Epoch: 66
Loss: 0.0828029645253081
ROC train: 0.956753	val: 0.804186	test: 0.816434
PRC train: 0.670419	val: 0.428947	test: 0.415712

Epoch: 67
Loss: 0.082920868565727
ROC train: 0.961522	val: 0.805626	test: 0.814049
PRC train: 0.674882	val: 0.423183	test: 0.425825

Epoch: 68
Loss: 0.08189684625808091
ROC train: 0.959209	val: 0.800347	test: 0.820427
PRC train: 0.679038	val: 0.425484	test: 0.420320

Epoch: 69
Loss: 0.08308037089033413
ROC train: 0.964126	val: 0.804133	test: 0.805141
PRC train: 0.698604	val: 0.431786	test: 0.422017

Epoch: 70
Loss: 0.08106125014414933
ROC train: 0.963493	val: 0.803769	test: 0.814698
PRC train: 0.691704	val: 0.428025	test: 0.426462

Epoch: 71
Loss: 0.08110058404457565
ROC train: 0.964592	val: 0.807781	test: 0.818214
PRC train: 0.708997	val: 0.449721	test: 0.421194

Epoch: 72
Loss: 0.08016662114522896
ROC train: 0.964080	val: 0.805838	test: 0.808598
PRC train: 0.698764	val: 0.438996	test: 0.426882

Epoch: 73
Loss: 0.07919537657865348
ROC train: 0.965571	val: 0.815286	test: 0.818109
PRC train: 0.694606	val: 0.449081	test: 0.437843

Epoch: 74
Loss: 0.0781847121129628
ROC train: 0.966343	val: 0.806655	test: 0.803118
PRC train: 0.705391	val: 0.449971	test: 0.421928

Epoch: 75
Loss: 0.07875252398345092
ROC train: 0.968902	val: 0.801967	test: 0.814846
PRC train: 0.707113	val: 0.440921	test: 0.406159

Epoch: 76
Loss: 0.07883689957405657
ROC train: 0.969498	val: 0.807055	test: 0.814873
PRC train: 0.721718	val: 0.440158	test: 0.418692

Epoch: 77
Loss: 0.07694979332909938
ROC train: 0.968446	val: 0.819857	test: 0.819664
PRC train: 0.701837	val: 0.432830	test: 0.420709

Epoch: 78
Loss: 0.0773429684938498
ROC train: 0.969350	val: 0.812251	test: 0.811220
PRC train: 0.712159	val: 0.419016	test: 0.388042

Epoch: 79
Loss: 0.07602208382952835
ROC train: 0.973735	val: 0.797120	test: 0.810907
PRC train: 0.738162	val: 0.411253	test: 0.409908

Epoch: 80
Loss: 0.07749870196351168
ROC train: 0.965071	val: 0.802512	test: 0.801348
PRC train: 0.699450	val: 0.416139	test: 0.398571

Epoch: 81
Loss: 0.07608851267868326
ROC train: 0.973742	val: 0.791994	test: 0.798702
PRC train: 0.730315	val: 0.414797	test: 0.395678

Epoch: 82
Loss: 0.0764678886700114
ROC train: 0.972285	val: 0.806845	test: 0.813522
PRC train: 0.732377	val: 0.424660	test: 0.422376

Epoch: 83
Loss: 0.07660335924052035
ROC train: 0.972658	val: 0.807414	test: 0.808181
PRC train: 0.731213	val: 0.428086	test: 0.415964

Epoch: 84
Loss: 0.07581345405581694
ROC train: 0.974725	val: 0.809740	test: 0.816625
PRC train: 0.744164	val: 0.419659	test: 0.408037

Epoch: 85
Loss: 0.07473953877368761
ROC train: 0.966909	val: 0.795085	test: 0.796622
PRC train: 0.712060	val: 0.429275	test: 0.395896

Epoch: 86
Loss: 0.07640430251410442
ROC train: 0.976471	val: 0.807084	test: 0.823037
PRC train: 0.756298	val: 0.448785	test: 0.422182

Epoch: 87
Loss: 0.0749293739918116
ROC train: 0.975357	val: 0.809904	test: 0.820405
PRC train: 0.750412	val: 0.429949	test: 0.421557

Epoch: 88
Loss: 0.07300329470524079
ROC train: 0.976593	val: 0.795368	test: 0.809042
PRC train: 0.754584	val: 0.429057	test: 0.409332

Epoch: 89
Loss: 0.07387362306966735
ROC train: 0.973628	val: 0.804566	test: 0.817488
PRC train: 0.727052	val: 0.416063	test: 0.395891

Epoch: 90
Loss: 0.0736875150213428
ROC train: 0.974008	val: 0.804040	test: 0.812444
PRC train: 0.739759	val: 0.426558	test: 0.400078

Epoch: 91
Loss: 0.07134389530400577
ROC train: 0.977158	val: 0.808835	test: 0.804438
PRC train: 0.758422	val: 0.428773	test: 0.399148

Epoch: 92
Loss: 0.07102140919432481
ROC train: 0.975652	val: 0.801236	test: 0.806609
PRC train: 0.740399	val: 0.409215	test: 0.393491

Epoch: 93
Loss: 0.0727590201299072
ROC train: 0.974429	val: 0.798011	test: 0.804125
PRC train: 0.743849	val: 0.408125	test: 0.390736

Epoch: 94
Loss: 0.07261942260066231
ROC train: 0.903903	val: 0.803796	test: 0.819894
PRC train: 0.533525	val: 0.452596	test: 0.432319

Epoch: 34
Loss: 0.09872952683248543
ROC train: 0.910183	val: 0.811170	test: 0.829325
PRC train: 0.561345	val: 0.432173	test: 0.447885

Epoch: 35
Loss: 0.09869199451857091
ROC train: 0.910430	val: 0.801133	test: 0.818898
PRC train: 0.532336	val: 0.415388	test: 0.415061

Epoch: 36
Loss: 0.09799247617344627
ROC train: 0.919868	val: 0.805814	test: 0.821580
PRC train: 0.567942	val: 0.443019	test: 0.450079

Epoch: 37
Loss: 0.0959194191910792
ROC train: 0.921196	val: 0.811301	test: 0.835020
PRC train: 0.575959	val: 0.435157	test: 0.454034

Epoch: 38
Loss: 0.09517825011191974
ROC train: 0.929068	val: 0.803879	test: 0.822524
PRC train: 0.591422	val: 0.433035	test: 0.434208

Epoch: 39
Loss: 0.09577521181040013
ROC train: 0.928058	val: 0.807356	test: 0.824081
PRC train: 0.582279	val: 0.429221	test: 0.452603

Epoch: 40
Loss: 0.0947832884559794
ROC train: 0.925628	val: 0.810969	test: 0.834766
PRC train: 0.558331	val: 0.416246	test: 0.434113

Epoch: 41
Loss: 0.09397161181751533
ROC train: 0.933054	val: 0.794016	test: 0.814407
PRC train: 0.600106	val: 0.433025	test: 0.439676

Epoch: 42
Loss: 0.0929116240489948
ROC train: 0.932441	val: 0.814389	test: 0.837449
PRC train: 0.595564	val: 0.432879	test: 0.437823

Epoch: 43
Loss: 0.09435644708827046
ROC train: 0.931724	val: 0.811601	test: 0.827691
PRC train: 0.591532	val: 0.441005	test: 0.454266

Epoch: 44
Loss: 0.0926252347353523
ROC train: 0.932126	val: 0.808590	test: 0.819426
PRC train: 0.598979	val: 0.444630	test: 0.444043

Epoch: 45
Loss: 0.09174793637885324
ROC train: 0.936379	val: 0.821953	test: 0.842958
PRC train: 0.601477	val: 0.420634	test: 0.437604

Epoch: 46
Loss: 0.09216600012525632
ROC train: 0.939953	val: 0.801205	test: 0.835183
PRC train: 0.619117	val: 0.432344	test: 0.432456

Epoch: 47
Loss: 0.09099650997609138
ROC train: 0.939437	val: 0.802133	test: 0.830496
PRC train: 0.612031	val: 0.417518	test: 0.429404

Epoch: 48
Loss: 0.09018499171268686
ROC train: 0.943208	val: 0.808395	test: 0.831680
PRC train: 0.629265	val: 0.426386	test: 0.438855

Epoch: 49
Loss: 0.08936628083355815
ROC train: 0.941333	val: 0.810412	test: 0.828866
PRC train: 0.619500	val: 0.428111	test: 0.441907

Epoch: 50
Loss: 0.09019933370242869
ROC train: 0.943551	val: 0.803955	test: 0.824421
PRC train: 0.625345	val: 0.446818	test: 0.467301

Epoch: 51
Loss: 0.09004057724752708
ROC train: 0.944723	val: 0.808757	test: 0.828161
PRC train: 0.612214	val: 0.413826	test: 0.408786

Epoch: 52
Loss: 0.08759966745253196
ROC train: 0.947902	val: 0.808284	test: 0.835306
PRC train: 0.626799	val: 0.421107	test: 0.432658

Epoch: 53
Loss: 0.08833553258814661
ROC train: 0.948968	val: 0.799613	test: 0.824218
PRC train: 0.639549	val: 0.416746	test: 0.428782

Epoch: 54
Loss: 0.0876464331371206
ROC train: 0.950240	val: 0.784523	test: 0.817274
PRC train: 0.634367	val: 0.424854	test: 0.450397

Epoch: 55
Loss: 0.08668748503855823
ROC train: 0.945067	val: 0.811668	test: 0.829672
PRC train: 0.634156	val: 0.415471	test: 0.445111

Epoch: 56
Loss: 0.08675195231455864
ROC train: 0.950974	val: 0.805648	test: 0.832920
PRC train: 0.655351	val: 0.433268	test: 0.456957

Epoch: 57
Loss: 0.08748790917002273
ROC train: 0.953412	val: 0.816436	test: 0.823651
PRC train: 0.658182	val: 0.437219	test: 0.426286

Epoch: 58
Loss: 0.08655042300030007
ROC train: 0.956609	val: 0.791863	test: 0.818635
PRC train: 0.662856	val: 0.431111	test: 0.440219

Epoch: 59
Loss: 0.08446716565204698
ROC train: 0.957577	val: 0.812055	test: 0.822155
PRC train: 0.673720	val: 0.437917	test: 0.442134

Epoch: 60
Loss: 0.08433546163753579
ROC train: 0.952163	val: 0.810996	test: 0.811368
PRC train: 0.646110	val: 0.429037	test: 0.410380

Epoch: 61
Loss: 0.0837176503955222
ROC train: 0.958145	val: 0.808388	test: 0.832095
PRC train: 0.674041	val: 0.434773	test: 0.439997

Epoch: 62
Loss: 0.08333006714617909
ROC train: 0.954773	val: 0.791096	test: 0.799655
PRC train: 0.665463	val: 0.412249	test: 0.395786

Epoch: 63
Loss: 0.0841077500228811
ROC train: 0.957884	val: 0.796877	test: 0.819933
PRC train: 0.659999	val: 0.442747	test: 0.429547

Epoch: 64
Loss: 0.08187773571501764
ROC train: 0.959628	val: 0.814339	test: 0.828258
PRC train: 0.679645	val: 0.446831	test: 0.447571

Epoch: 65
Loss: 0.08408973714420646
ROC train: 0.958240	val: 0.798893	test: 0.811628
PRC train: 0.667625	val: 0.434580	test: 0.436693

Epoch: 66
Loss: 0.0832946342891919
ROC train: 0.961282	val: 0.803804	test: 0.814404
PRC train: 0.693984	val: 0.441947	test: 0.442097

Epoch: 67
Loss: 0.0810772635642011
ROC train: 0.963924	val: 0.795722	test: 0.805256
PRC train: 0.692735	val: 0.428743	test: 0.411028

Epoch: 68
Loss: 0.08118034950873546
ROC train: 0.964199	val: 0.806435	test: 0.813523
PRC train: 0.684820	val: 0.435815	test: 0.433061

Epoch: 69
Loss: 0.08020181247598908
ROC train: 0.961049	val: 0.795058	test: 0.812292
PRC train: 0.680793	val: 0.420498	test: 0.409980

Epoch: 70
Loss: 0.08123776752707793
ROC train: 0.965641	val: 0.793741	test: 0.830605
PRC train: 0.697706	val: 0.424834	test: 0.419510

Epoch: 71
Loss: 0.08092854293986511
ROC train: 0.963290	val: 0.805762	test: 0.829107
PRC train: 0.687580	val: 0.438607	test: 0.421287

Epoch: 72
Loss: 0.08015017127200601
ROC train: 0.961279	val: 0.795768	test: 0.797872
PRC train: 0.687525	val: 0.437129	test: 0.411834

Epoch: 73
Loss: 0.0787660628658195
ROC train: 0.963340	val: 0.790899	test: 0.816199
PRC train: 0.705018	val: 0.444792	test: 0.410650

Epoch: 74
Loss: 0.07893241030581183
ROC train: 0.965713	val: 0.806376	test: 0.817868
PRC train: 0.704106	val: 0.428818	test: 0.388445

Epoch: 75
Loss: 0.07799009919164604
ROC train: 0.967134	val: 0.791417	test: 0.813218
PRC train: 0.714506	val: 0.436467	test: 0.421530

Epoch: 76
Loss: 0.07861405249815434
ROC train: 0.967596	val: 0.803898	test: 0.820188
PRC train: 0.703317	val: 0.436402	test: 0.417633

Epoch: 77
Loss: 0.07746152647685683
ROC train: 0.970776	val: 0.793589	test: 0.817513
PRC train: 0.720694	val: 0.433874	test: 0.421869

Epoch: 78
Loss: 0.07695066872400352
ROC train: 0.971305	val: 0.803152	test: 0.826551
PRC train: 0.724598	val: 0.428096	test: 0.406629

Epoch: 79
Loss: 0.07530241937167448
ROC train: 0.971653	val: 0.798271	test: 0.807310
PRC train: 0.732891	val: 0.433325	test: 0.412605

Epoch: 80
Loss: 0.07632386512321393
ROC train: 0.975458	val: 0.796790	test: 0.823855
PRC train: 0.744439	val: 0.442142	test: 0.419603

Epoch: 81
Loss: 0.07682258704184407
ROC train: 0.973411	val: 0.798118	test: 0.820252
PRC train: 0.736269	val: 0.426695	test: 0.417866

Epoch: 82
Loss: 0.07672598071987613
ROC train: 0.969430	val: 0.803677	test: 0.829942
PRC train: 0.707906	val: 0.432996	test: 0.432576

Epoch: 83
Loss: 0.07471551665793441
ROC train: 0.975401	val: 0.797061	test: 0.822168
PRC train: 0.748460	val: 0.436048	test: 0.417546

Epoch: 84
Loss: 0.0742253913974196
ROC train: 0.976208	val: 0.791153	test: 0.796748
PRC train: 0.749362	val: 0.446061	test: 0.409140

Epoch: 85
Loss: 0.07303754217050885
ROC train: 0.973382	val: 0.802293	test: 0.813716
PRC train: 0.737476	val: 0.435355	test: 0.408466

Epoch: 86
Loss: 0.07497030542384536
ROC train: 0.978055	val: 0.783752	test: 0.816300
PRC train: 0.757186	val: 0.421946	test: 0.403220

Epoch: 87
Loss: 0.07273435313311116
ROC train: 0.977569	val: 0.798179	test: 0.819330
PRC train: 0.760457	val: 0.423645	test: 0.411991

Epoch: 88
Loss: 0.07281692579470032
ROC train: 0.975469	val: 0.786246	test: 0.815313
PRC train: 0.749956	val: 0.395918	test: 0.393230

Epoch: 89
Loss: 0.07302914576229211
ROC train: 0.977369	val: 0.788073	test: 0.814961
PRC train: 0.754721	val: 0.416230	test: 0.391018

Epoch: 90
Loss: 0.07343490807678638
ROC train: 0.973888	val: 0.780875	test: 0.798552
PRC train: 0.741287	val: 0.426360	test: 0.413182

Epoch: 91
Loss: 0.0743098684672511
ROC train: 0.978623	val: 0.794933	test: 0.810374
PRC train: 0.771759	val: 0.427904	test: 0.394391

Epoch: 92
Loss: 0.07104727868187188
ROC train: 0.978822	val: 0.794141	test: 0.815311
PRC train: 0.763661	val: 0.414996	test: 0.383971

Epoch: 93
Loss: 0.07121216688558048
ROC train: 0.978658	val: 0.791642	test: 0.816181
PRC train: 0.775329	val: 0.429784	test: 0.420628

Epoch: 94
Loss: 0.07149055118462237
ROC train: 0.913323	val: 0.820360	test: 0.854443
PRC train: 0.551444	val: 0.404371	test: 0.468232

Epoch: 34
Loss: 0.09886636953798411
ROC train: 0.917831	val: 0.817373	test: 0.843354
PRC train: 0.568597	val: 0.438807	test: 0.465103

Epoch: 35
Loss: 0.09825978721403687
ROC train: 0.918472	val: 0.813019	test: 0.843955
PRC train: 0.542506	val: 0.440420	test: 0.457140

Epoch: 36
Loss: 0.096713791623555
ROC train: 0.923128	val: 0.831043	test: 0.835959
PRC train: 0.571118	val: 0.430730	test: 0.483631

Epoch: 37
Loss: 0.09604832697895607
ROC train: 0.919452	val: 0.808789	test: 0.841265
PRC train: 0.567897	val: 0.415726	test: 0.480848

Epoch: 38
Loss: 0.09676540663243101
ROC train: 0.921196	val: 0.818933	test: 0.844718
PRC train: 0.560340	val: 0.422223	test: 0.486444

Epoch: 39
Loss: 0.09611566417259455
ROC train: 0.922253	val: 0.818286	test: 0.854365
PRC train: 0.559273	val: 0.411661	test: 0.459367

Epoch: 40
Loss: 0.09599348037388712
ROC train: 0.926718	val: 0.816020	test: 0.848612
PRC train: 0.585984	val: 0.412718	test: 0.473669

Epoch: 41
Loss: 0.09590432320371622
ROC train: 0.926659	val: 0.811628	test: 0.857078
PRC train: 0.587775	val: 0.415197	test: 0.473620

Epoch: 42
Loss: 0.09500216133952433
ROC train: 0.933699	val: 0.810192	test: 0.854978
PRC train: 0.603685	val: 0.420708	test: 0.498195

Epoch: 43
Loss: 0.09415426446309712
ROC train: 0.935789	val: 0.825622	test: 0.849483
PRC train: 0.600063	val: 0.419812	test: 0.480422

Epoch: 44
Loss: 0.09438637891128171
ROC train: 0.930020	val: 0.799437	test: 0.833547
PRC train: 0.600988	val: 0.406542	test: 0.452316

Epoch: 45
Loss: 0.09396539937881403
ROC train: 0.933914	val: 0.797546	test: 0.829659
PRC train: 0.604436	val: 0.417138	test: 0.464343

Epoch: 46
Loss: 0.09216525995727692
ROC train: 0.939176	val: 0.808978	test: 0.846910
PRC train: 0.618624	val: 0.413724	test: 0.481348

Epoch: 47
Loss: 0.09159527904836431
ROC train: 0.941683	val: 0.834730	test: 0.850352
PRC train: 0.611972	val: 0.426592	test: 0.467886

Epoch: 48
Loss: 0.09014877789884301
ROC train: 0.943302	val: 0.820261	test: 0.856901
PRC train: 0.623623	val: 0.417952	test: 0.486074

Epoch: 49
Loss: 0.09153918556811678
ROC train: 0.942383	val: 0.808919	test: 0.840536
PRC train: 0.623445	val: 0.422585	test: 0.477809

Epoch: 50
Loss: 0.09065651734221293
ROC train: 0.942212	val: 0.803625	test: 0.857251
PRC train: 0.628673	val: 0.406805	test: 0.460136

Epoch: 51
Loss: 0.08945642024438107
ROC train: 0.939546	val: 0.809897	test: 0.835258
PRC train: 0.634165	val: 0.414203	test: 0.444450

Epoch: 52
Loss: 0.08900990453364728
ROC train: 0.947737	val: 0.808234	test: 0.856229
PRC train: 0.644686	val: 0.422857	test: 0.464482

Epoch: 53
Loss: 0.08747645023754598
ROC train: 0.946106	val: 0.813596	test: 0.846756
PRC train: 0.633759	val: 0.409786	test: 0.466258

Epoch: 54
Loss: 0.088093516714948
ROC train: 0.941766	val: 0.820603	test: 0.838547
PRC train: 0.613158	val: 0.411018	test: 0.425882

Epoch: 55
Loss: 0.08909074543597151
ROC train: 0.948097	val: 0.820208	test: 0.866215
PRC train: 0.644306	val: 0.425837	test: 0.482509

Epoch: 56
Loss: 0.0862700717894664
ROC train: 0.943245	val: 0.802221	test: 0.833459
PRC train: 0.631592	val: 0.405228	test: 0.459574

Epoch: 57
Loss: 0.08621859815014377
ROC train: 0.948698	val: 0.804467	test: 0.848139
PRC train: 0.647395	val: 0.414107	test: 0.469421

Epoch: 58
Loss: 0.08774235217753905
ROC train: 0.953716	val: 0.805556	test: 0.835509
PRC train: 0.657590	val: 0.405120	test: 0.474207

Epoch: 59
Loss: 0.08594871933874207
ROC train: 0.955569	val: 0.814589	test: 0.847015
PRC train: 0.674414	val: 0.426658	test: 0.449296

Epoch: 60
Loss: 0.0862551883998151
ROC train: 0.948256	val: 0.818076	test: 0.847361
PRC train: 0.642454	val: 0.418465	test: 0.466398

Epoch: 61
Loss: 0.08426970603348259
ROC train: 0.948608	val: 0.813525	test: 0.841172
PRC train: 0.654590	val: 0.400766	test: 0.476205

Epoch: 62
Loss: 0.08438411506480935
ROC train: 0.957931	val: 0.806895	test: 0.851581
PRC train: 0.672954	val: 0.404709	test: 0.474625

Epoch: 63
Loss: 0.0838512962397927
ROC train: 0.961105	val: 0.807658	test: 0.848116
PRC train: 0.688555	val: 0.421766	test: 0.464835

Epoch: 64
Loss: 0.08412932578762132
ROC train: 0.958529	val: 0.805669	test: 0.856208
PRC train: 0.683573	val: 0.425866	test: 0.459150

Epoch: 65
Loss: 0.08369637870677035
ROC train: 0.954554	val: 0.822939	test: 0.853938
PRC train: 0.657607	val: 0.400479	test: 0.465371

Epoch: 66
Loss: 0.08315022344725792
ROC train: 0.957907	val: 0.809571	test: 0.849737
PRC train: 0.673630	val: 0.413196	test: 0.451692

Epoch: 67
Loss: 0.08427090155892807
ROC train: 0.962254	val: 0.812135	test: 0.840959
PRC train: 0.692152	val: 0.423580	test: 0.446107

Epoch: 68
Loss: 0.08231569163933894
ROC train: 0.959426	val: 0.823994	test: 0.845756
PRC train: 0.682599	val: 0.407251	test: 0.460209

Epoch: 69
Loss: 0.08213398505539418
ROC train: 0.963771	val: 0.825517	test: 0.857407
PRC train: 0.701786	val: 0.415394	test: 0.450173

Epoch: 70
Loss: 0.08158503360340164
ROC train: 0.962143	val: 0.815384	test: 0.838315
PRC train: 0.703317	val: 0.415045	test: 0.442089

Epoch: 71
Loss: 0.08147661641557058
ROC train: 0.958292	val: 0.824514	test: 0.846210
PRC train: 0.683404	val: 0.418561	test: 0.444362

Epoch: 72
Loss: 0.08016173318202076
ROC train: 0.963431	val: 0.819084	test: 0.850865
PRC train: 0.701359	val: 0.428118	test: 0.446259

Epoch: 73
Loss: 0.08306523193978443
ROC train: 0.969712	val: 0.829104	test: 0.859912
PRC train: 0.713507	val: 0.419421	test: 0.438711

Epoch: 74
Loss: 0.07922544976872324
ROC train: 0.966054	val: 0.807882	test: 0.853580
PRC train: 0.713365	val: 0.408819	test: 0.461260

Epoch: 75
Loss: 0.07902267809657174
ROC train: 0.968914	val: 0.810764	test: 0.833263
PRC train: 0.723942	val: 0.415728	test: 0.435395

Epoch: 76
Loss: 0.07969078982980995
ROC train: 0.963365	val: 0.803924	test: 0.834989
PRC train: 0.702470	val: 0.411655	test: 0.423226

Epoch: 77
Loss: 0.07905740588640121
ROC train: 0.968949	val: 0.830385	test: 0.850235
PRC train: 0.721533	val: 0.442874	test: 0.437813

Epoch: 78
Loss: 0.07896242487997158
ROC train: 0.969022	val: 0.831498	test: 0.841866
PRC train: 0.722033	val: 0.437059	test: 0.455351

Epoch: 79
Loss: 0.07736303056815852
ROC train: 0.970962	val: 0.823920	test: 0.823184
PRC train: 0.715863	val: 0.422155	test: 0.434420

Epoch: 80
Loss: 0.07742013325277415
ROC train: 0.970280	val: 0.809304	test: 0.839635
PRC train: 0.730152	val: 0.416048	test: 0.422730

Epoch: 81
Loss: 0.07508115795766616
ROC train: 0.968961	val: 0.828424	test: 0.845651
PRC train: 0.722722	val: 0.419426	test: 0.444771

Epoch: 82
Loss: 0.07697584678893633
ROC train: 0.968242	val: 0.804999	test: 0.847713
PRC train: 0.713281	val: 0.387624	test: 0.448787

Epoch: 83
Loss: 0.07645091666364606
ROC train: 0.969326	val: 0.813201	test: 0.847657
PRC train: 0.722599	val: 0.414819	test: 0.437689

Epoch: 84
Loss: 0.07810986230028824
ROC train: 0.971740	val: 0.819799	test: 0.841592
PRC train: 0.746880	val: 0.425826	test: 0.447043

Epoch: 85
Loss: 0.07548409266459555
ROC train: 0.969076	val: 0.826177	test: 0.841144
PRC train: 0.723327	val: 0.423733	test: 0.435489

Epoch: 86
Loss: 0.07421937325266492
ROC train: 0.974756	val: 0.818148	test: 0.848249
PRC train: 0.760115	val: 0.421420	test: 0.440703

Epoch: 87
Loss: 0.07474638907048853
ROC train: 0.974135	val: 0.812094	test: 0.855574
PRC train: 0.750269	val: 0.432762	test: 0.439671

Epoch: 88
Loss: 0.07391948025671366
ROC train: 0.975131	val: 0.823268	test: 0.853656
PRC train: 0.755949	val: 0.425922	test: 0.424708

Epoch: 89
Loss: 0.07379904311143197
ROC train: 0.974927	val: 0.804233	test: 0.852935
PRC train: 0.743517	val: 0.384635	test: 0.421814

Epoch: 90
Loss: 0.07358653174645763
ROC train: 0.977701	val: 0.804647	test: 0.861601
PRC train: 0.762220	val: 0.400936	test: 0.456341

Epoch: 91
Loss: 0.07365135912990084
ROC train: 0.976539	val: 0.806044	test: 0.847610
PRC train: 0.768659	val: 0.414250	test: 0.436717

Epoch: 92
Loss: 0.07197405129702274
ROC train: 0.975217	val: 0.803081	test: 0.843825
PRC train: 0.755126	val: 0.384190	test: 0.418110

Epoch: 93
Loss: 0.07199142171378127
ROC train: 0.976612	val: 0.810153	test: 0.848728
PRC train: 0.751459	val: 0.409772	test: 0.431008


ROC train: 0.905535	val: 0.787829	test: 0.841997
PRC train: 0.532147	val: 0.390500	test: 0.481436

Epoch: 34
Loss: 0.1002058485421903
ROC train: 0.913328	val: 0.810551	test: 0.849651
PRC train: 0.554237	val: 0.421594	test: 0.502030

Epoch: 35
Loss: 0.0982008078309551
ROC train: 0.905553	val: 0.820150	test: 0.836509
PRC train: 0.516257	val: 0.390366	test: 0.472399

Epoch: 36
Loss: 0.09851832556120538
ROC train: 0.908529	val: 0.788984	test: 0.840932
PRC train: 0.527385	val: 0.393890	test: 0.466088

Epoch: 37
Loss: 0.09816387255581618
ROC train: 0.901795	val: 0.792583	test: 0.831809
PRC train: 0.544210	val: 0.387975	test: 0.474678

Epoch: 38
Loss: 0.09855111229914908
ROC train: 0.913372	val: 0.783846	test: 0.845160
PRC train: 0.552577	val: 0.403757	test: 0.483094

Epoch: 39
Loss: 0.09722994948852175
ROC train: 0.917098	val: 0.803116	test: 0.832137
PRC train: 0.573149	val: 0.428563	test: 0.500415

Epoch: 40
Loss: 0.09704941598686813
ROC train: 0.919308	val: 0.799483	test: 0.840270
PRC train: 0.573874	val: 0.377879	test: 0.495825

Epoch: 41
Loss: 0.0957550205056266
ROC train: 0.921989	val: 0.800862	test: 0.859407
PRC train: 0.570574	val: 0.388849	test: 0.501131

Epoch: 42
Loss: 0.09497182218700434
ROC train: 0.925833	val: 0.791947	test: 0.842313
PRC train: 0.576412	val: 0.394409	test: 0.467469

Epoch: 43
Loss: 0.09492364835783089
ROC train: 0.918417	val: 0.811381	test: 0.843794
PRC train: 0.568842	val: 0.385583	test: 0.484144

Epoch: 44
Loss: 0.09415781967021064
ROC train: 0.924895	val: 0.805787	test: 0.834317
PRC train: 0.584849	val: 0.423508	test: 0.498577

Epoch: 45
Loss: 0.09387041917476747
ROC train: 0.924415	val: 0.772975	test: 0.844478
PRC train: 0.565475	val: 0.382697	test: 0.466758

Epoch: 46
Loss: 0.09506715488781446
ROC train: 0.930867	val: 0.787759	test: 0.842014
PRC train: 0.593057	val: 0.396863	test: 0.475415

Epoch: 47
Loss: 0.09306891658148711
ROC train: 0.933774	val: 0.815090	test: 0.850360
PRC train: 0.599824	val: 0.410084	test: 0.479431

Epoch: 48
Loss: 0.09311384536527832
ROC train: 0.934481	val: 0.771573	test: 0.841557
PRC train: 0.604440	val: 0.402041	test: 0.467087

Epoch: 49
Loss: 0.09295453576422724
ROC train: 0.936906	val: 0.801269	test: 0.843588
PRC train: 0.607294	val: 0.415833	test: 0.496724

Epoch: 50
Loss: 0.09201676713715158
ROC train: 0.933032	val: 0.792388	test: 0.846274
PRC train: 0.603444	val: 0.419245	test: 0.494493

Epoch: 51
Loss: 0.09155716418457474
ROC train: 0.936564	val: 0.786355	test: 0.851156
PRC train: 0.606630	val: 0.394294	test: 0.502686

Epoch: 52
Loss: 0.09170532439017429
ROC train: 0.939941	val: 0.785040	test: 0.850285
PRC train: 0.623687	val: 0.399334	test: 0.493867

Epoch: 53
Loss: 0.09119790359602341
ROC train: 0.943334	val: 0.803258	test: 0.847535
PRC train: 0.619942	val: 0.412424	test: 0.492177

Epoch: 54
Loss: 0.08895318845314538
ROC train: 0.942886	val: 0.804451	test: 0.846836
PRC train: 0.629701	val: 0.415822	test: 0.493020

Epoch: 55
Loss: 0.08907643552442321
ROC train: 0.936362	val: 0.796181	test: 0.847283
PRC train: 0.602239	val: 0.402767	test: 0.485967

Epoch: 56
Loss: 0.08828670217726377
ROC train: 0.940303	val: 0.793820	test: 0.839139
PRC train: 0.623213	val: 0.399733	test: 0.482601

Epoch: 57
Loss: 0.08853087085443183
ROC train: 0.942506	val: 0.790199	test: 0.838589
PRC train: 0.620602	val: 0.393794	test: 0.471567

Epoch: 58
Loss: 0.08949868333755194
ROC train: 0.941784	val: 0.813641	test: 0.840561
PRC train: 0.628512	val: 0.414994	test: 0.475967

Epoch: 59
Loss: 0.0865737103011292
ROC train: 0.945326	val: 0.798670	test: 0.848029
PRC train: 0.637450	val: 0.404265	test: 0.481960

Epoch: 60
Loss: 0.08731723086209248
ROC train: 0.943690	val: 0.760657	test: 0.838740
PRC train: 0.633737	val: 0.389594	test: 0.465279

Epoch: 61
Loss: 0.08804158387738746
ROC train: 0.943115	val: 0.773743	test: 0.821565
PRC train: 0.616821	val: 0.406084	test: 0.447800

Epoch: 62
Loss: 0.08792598921128568
ROC train: 0.951413	val: 0.795129	test: 0.857004
PRC train: 0.662308	val: 0.408077	test: 0.495029

Epoch: 63
Loss: 0.08670176033730452
ROC train: 0.941309	val: 0.787662	test: 0.830862
PRC train: 0.640098	val: 0.384978	test: 0.459863

Epoch: 64
Loss: 0.0852363182835171
ROC train: 0.948865	val: 0.788208	test: 0.825354
PRC train: 0.648541	val: 0.396774	test: 0.465233

Epoch: 65
Loss: 0.08562348763848558
ROC train: 0.947411	val: 0.778569	test: 0.825107
PRC train: 0.647228	val: 0.408829	test: 0.463636

Epoch: 66
Loss: 0.08515043203400721
ROC train: 0.953953	val: 0.792306	test: 0.850633
PRC train: 0.651643	val: 0.394771	test: 0.490633

Epoch: 67
Loss: 0.0837880601498301
ROC train: 0.955559	val: 0.811731	test: 0.839343
PRC train: 0.673772	val: 0.421885	test: 0.474357

Epoch: 68
Loss: 0.0852107913992826
ROC train: 0.944959	val: 0.777242	test: 0.823206
PRC train: 0.636555	val: 0.378817	test: 0.449138

Epoch: 69
Loss: 0.0844821015629309
ROC train: 0.956501	val: 0.776911	test: 0.834942
PRC train: 0.660879	val: 0.390142	test: 0.460884

Epoch: 70
Loss: 0.0850144961916066
ROC train: 0.960823	val: 0.792010	test: 0.849480
PRC train: 0.684176	val: 0.415100	test: 0.472412

Epoch: 71
Loss: 0.0831309808954907
ROC train: 0.961002	val: 0.795370	test: 0.844358
PRC train: 0.683054	val: 0.398105	test: 0.474006

Epoch: 72
Loss: 0.08388043287007729
ROC train: 0.952965	val: 0.793406	test: 0.836534
PRC train: 0.660894	val: 0.380781	test: 0.473317

Epoch: 73
Loss: 0.08229397566558647
ROC train: 0.958535	val: 0.801500	test: 0.838908
PRC train: 0.683365	val: 0.390206	test: 0.450053

Epoch: 74
Loss: 0.08095560873642006
ROC train: 0.958572	val: 0.799248	test: 0.837347
PRC train: 0.689649	val: 0.389776	test: 0.472606

Epoch: 75
Loss: 0.08172340527776127
ROC train: 0.958484	val: 0.799453	test: 0.839131
PRC train: 0.682351	val: 0.399496	test: 0.471822

Epoch: 76
Loss: 0.0814724369595666
ROC train: 0.964462	val: 0.802214	test: 0.845910
PRC train: 0.708124	val: 0.400667	test: 0.473771

Epoch: 77
Loss: 0.08091310701187346
ROC train: 0.966616	val: 0.794703	test: 0.835758
PRC train: 0.715826	val: 0.409912	test: 0.471653

Epoch: 78
Loss: 0.07957538101121787
ROC train: 0.965073	val: 0.792883	test: 0.824295
PRC train: 0.709111	val: 0.395208	test: 0.434688

Epoch: 79
Loss: 0.07925269226042865
ROC train: 0.960184	val: 0.784670	test: 0.838141
PRC train: 0.686497	val: 0.375722	test: 0.444771

Epoch: 80
Loss: 0.07926566077719437
ROC train: 0.964315	val: 0.768218	test: 0.848762
PRC train: 0.715207	val: 0.386289	test: 0.461110

Epoch: 81
Loss: 0.07879522217900331
ROC train: 0.965500	val: 0.796692	test: 0.835228
PRC train: 0.705016	val: 0.391972	test: 0.438027

Epoch: 82
Loss: 0.0787894621060831
ROC train: 0.964322	val: 0.801195	test: 0.846007
PRC train: 0.685778	val: 0.395500	test: 0.469023

Epoch: 83
Loss: 0.07873461286399142
ROC train: 0.969137	val: 0.778049	test: 0.846299
PRC train: 0.728331	val: 0.396281	test: 0.469556

Epoch: 84
Loss: 0.0763941103266403
ROC train: 0.968210	val: 0.790095	test: 0.829168
PRC train: 0.715118	val: 0.396264	test: 0.465632

Epoch: 85
Loss: 0.0789924499496138
ROC train: 0.966996	val: 0.789399	test: 0.807099
PRC train: 0.718517	val: 0.406504	test: 0.467092

Epoch: 86
Loss: 0.077202686448099
ROC train: 0.968637	val: 0.784168	test: 0.828017
PRC train: 0.730552	val: 0.385923	test: 0.464399

Epoch: 87
Loss: 0.07653383752140867
ROC train: 0.970712	val: 0.792315	test: 0.838489
PRC train: 0.737212	val: 0.401794	test: 0.458530

Epoch: 88
Loss: 0.07658678599511819
ROC train: 0.968352	val: 0.789868	test: 0.840790
PRC train: 0.714488	val: 0.387503	test: 0.455351

Epoch: 89
Loss: 0.07684415556600264
ROC train: 0.969103	val: 0.812748	test: 0.825855
PRC train: 0.724859	val: 0.385704	test: 0.436914

Epoch: 90
Loss: 0.07574096626880955
ROC train: 0.970093	val: 0.800857	test: 0.833740
PRC train: 0.729381	val: 0.400262	test: 0.442681

Epoch: 91
Loss: 0.07454256143528058
ROC train: 0.974123	val: 0.796176	test: 0.839488
PRC train: 0.752676	val: 0.385430	test: 0.448409

Epoch: 92
Loss: 0.07440695587184472
ROC train: 0.974431	val: 0.800966	test: 0.836941
PRC train: 0.753269	val: 0.400556	test: 0.461496

Epoch: 93
Loss: 0.07477118072195935
ROC train: 0.975037	val: 0.785787	test: 0.838850
PRC train: 0.757655	val: 0.385678	test: 0.472125

Epoch: 94
Loss: 0.07515255909542021
ROC train: 0.919975	val: 0.825522	test: 0.842862
PRC train: 0.552015	val: 0.410080	test: 0.493325

Epoch: 34
Loss: 0.09700301470078639
ROC train: 0.911574	val: 0.815752	test: 0.841450
PRC train: 0.534678	val: 0.439517	test: 0.474628

Epoch: 35
Loss: 0.09923594595984708
ROC train: 0.920863	val: 0.827828	test: 0.852896
PRC train: 0.556297	val: 0.415639	test: 0.504345

Epoch: 36
Loss: 0.09792423657431486
ROC train: 0.924249	val: 0.813460	test: 0.853414
PRC train: 0.569780	val: 0.401600	test: 0.498749

Epoch: 37
Loss: 0.09722537729926148
ROC train: 0.921872	val: 0.815821	test: 0.841386
PRC train: 0.555348	val: 0.409774	test: 0.494257

Epoch: 38
Loss: 0.09682421612083279
ROC train: 0.920997	val: 0.805119	test: 0.840334
PRC train: 0.557666	val: 0.392325	test: 0.480296

Epoch: 39
Loss: 0.09648025288514502
ROC train: 0.926662	val: 0.810683	test: 0.845524
PRC train: 0.580734	val: 0.425655	test: 0.483525

Epoch: 40
Loss: 0.09542743952142717
ROC train: 0.931462	val: 0.800260	test: 0.849192
PRC train: 0.594291	val: 0.418913	test: 0.513162

Epoch: 41
Loss: 0.09511529949409457
ROC train: 0.930387	val: 0.810778	test: 0.849163
PRC train: 0.590638	val: 0.396797	test: 0.477330

Epoch: 42
Loss: 0.09473369130952655
ROC train: 0.932034	val: 0.807785	test: 0.860431
PRC train: 0.582526	val: 0.408811	test: 0.497792

Epoch: 43
Loss: 0.09385882231322408
ROC train: 0.932715	val: 0.812086	test: 0.848432
PRC train: 0.571417	val: 0.384589	test: 0.454049

Epoch: 44
Loss: 0.0934762587772604
ROC train: 0.934884	val: 0.795145	test: 0.855590
PRC train: 0.607673	val: 0.402746	test: 0.499082

Epoch: 45
Loss: 0.09223115883445644
ROC train: 0.930580	val: 0.805082	test: 0.846956
PRC train: 0.606171	val: 0.405560	test: 0.500278

Epoch: 46
Loss: 0.09181045009770673
ROC train: 0.936245	val: 0.799280	test: 0.865281
PRC train: 0.600945	val: 0.408822	test: 0.501600

Epoch: 47
Loss: 0.09199239018203306
ROC train: 0.936428	val: 0.802238	test: 0.860071
PRC train: 0.607525	val: 0.394675	test: 0.502510

Epoch: 48
Loss: 0.09076979811949282
ROC train: 0.940079	val: 0.807059	test: 0.851790
PRC train: 0.607175	val: 0.382563	test: 0.481970

Epoch: 49
Loss: 0.09273938165153264
ROC train: 0.941882	val: 0.825996	test: 0.859143
PRC train: 0.603651	val: 0.415493	test: 0.516161

Epoch: 50
Loss: 0.09086088475733935
ROC train: 0.944363	val: 0.825023	test: 0.844842
PRC train: 0.623537	val: 0.421706	test: 0.489404

Epoch: 51
Loss: 0.09006088754482078
ROC train: 0.946313	val: 0.832349	test: 0.857231
PRC train: 0.635026	val: 0.418141	test: 0.485840

Epoch: 52
Loss: 0.0896580064685225
ROC train: 0.939317	val: 0.819302	test: 0.840224
PRC train: 0.623060	val: 0.418460	test: 0.508828

Epoch: 53
Loss: 0.08948744484597901
ROC train: 0.943133	val: 0.805880	test: 0.836859
PRC train: 0.620102	val: 0.376544	test: 0.459735

Epoch: 54
Loss: 0.08783383632724123
ROC train: 0.951376	val: 0.821233	test: 0.848420
PRC train: 0.642037	val: 0.390130	test: 0.460330

Epoch: 55
Loss: 0.08801400167849807
ROC train: 0.949682	val: 0.811599	test: 0.862497
PRC train: 0.643006	val: 0.408709	test: 0.486406

Epoch: 56
Loss: 0.08816953850026343
ROC train: 0.951161	val: 0.812923	test: 0.855260
PRC train: 0.642899	val: 0.420241	test: 0.501626

Epoch: 57
Loss: 0.0872675202735768
ROC train: 0.951570	val: 0.806971	test: 0.855091
PRC train: 0.647890	val: 0.379829	test: 0.476201

Epoch: 58
Loss: 0.08648048760759561
ROC train: 0.954478	val: 0.794250	test: 0.850755
PRC train: 0.657700	val: 0.429057	test: 0.506014

Epoch: 59
Loss: 0.08650774605559644
ROC train: 0.952363	val: 0.796500	test: 0.867766
PRC train: 0.647842	val: 0.393668	test: 0.520207

Epoch: 60
Loss: 0.08527781131710842
ROC train: 0.955363	val: 0.802668	test: 0.844502
PRC train: 0.654844	val: 0.383977	test: 0.483331

Epoch: 61
Loss: 0.08535478012689593
ROC train: 0.953573	val: 0.798544	test: 0.836370
PRC train: 0.660094	val: 0.403085	test: 0.475087

Epoch: 62
Loss: 0.08530479030346552
ROC train: 0.957772	val: 0.789955	test: 0.856234
PRC train: 0.666382	val: 0.380877	test: 0.480213

Epoch: 63
Loss: 0.08480838821697849
ROC train: 0.954607	val: 0.824382	test: 0.845206
PRC train: 0.669576	val: 0.405940	test: 0.484611

Epoch: 64
Loss: 0.0847594004055461
ROC train: 0.959429	val: 0.810438	test: 0.857801
PRC train: 0.673075	val: 0.408322	test: 0.475323

Epoch: 65
Loss: 0.08315669974593648
ROC train: 0.959099	val: 0.810329	test: 0.850694
PRC train: 0.681577	val: 0.405720	test: 0.469523

Epoch: 66
Loss: 0.08240466305170978
ROC train: 0.962231	val: 0.790321	test: 0.861762
PRC train: 0.689625	val: 0.418727	test: 0.500206

Epoch: 67
Loss: 0.08379253147625207
ROC train: 0.964532	val: 0.819402	test: 0.860255
PRC train: 0.699950	val: 0.417599	test: 0.476222

Epoch: 68
Loss: 0.0812818204197127
ROC train: 0.964312	val: 0.803482	test: 0.845304
PRC train: 0.701441	val: 0.400133	test: 0.484067

Epoch: 69
Loss: 0.0825246043258099
ROC train: 0.961078	val: 0.818624	test: 0.852853
PRC train: 0.686059	val: 0.419852	test: 0.473612

Epoch: 70
Loss: 0.08135063508907638
ROC train: 0.961855	val: 0.810119	test: 0.842792
PRC train: 0.675748	val: 0.403138	test: 0.436733

Epoch: 71
Loss: 0.0809828651142502
ROC train: 0.966692	val: 0.811605	test: 0.855115
PRC train: 0.711892	val: 0.415430	test: 0.494406

Epoch: 72
Loss: 0.08062133328212136
ROC train: 0.965658	val: 0.819526	test: 0.859666
PRC train: 0.694187	val: 0.405626	test: 0.498087

Epoch: 73
Loss: 0.08119005447203861
ROC train: 0.968065	val: 0.793364	test: 0.856212
PRC train: 0.711060	val: 0.380329	test: 0.467714

Epoch: 74
Loss: 0.07911046744326848
ROC train: 0.967069	val: 0.779836	test: 0.846167
PRC train: 0.712753	val: 0.381647	test: 0.477909

Epoch: 75
Loss: 0.07987589471277197
ROC train: 0.963324	val: 0.804294	test: 0.848436
PRC train: 0.690585	val: 0.405064	test: 0.426985

Epoch: 76
Loss: 0.07824149581066912
ROC train: 0.969448	val: 0.807748	test: 0.848767
PRC train: 0.716393	val: 0.405936	test: 0.475350

Epoch: 77
Loss: 0.07888692739580343
ROC train: 0.966461	val: 0.805454	test: 0.838924
PRC train: 0.710896	val: 0.400520	test: 0.453343

Epoch: 78
Loss: 0.07727688506035992
ROC train: 0.968941	val: 0.796019	test: 0.849153
PRC train: 0.720862	val: 0.406625	test: 0.474819

Epoch: 79
Loss: 0.07709750803105084
ROC train: 0.971736	val: 0.792965	test: 0.843779
PRC train: 0.744092	val: 0.395400	test: 0.470475

Epoch: 80
Loss: 0.07824283010287417
ROC train: 0.971146	val: 0.790300	test: 0.851258
PRC train: 0.735959	val: 0.386719	test: 0.451250

Epoch: 81
Loss: 0.07712951330408821
ROC train: 0.973431	val: 0.793466	test: 0.849444
PRC train: 0.738190	val: 0.379758	test: 0.463534

Epoch: 82
Loss: 0.07677610413767003
ROC train: 0.971961	val: 0.809383	test: 0.840202
PRC train: 0.735221	val: 0.398476	test: 0.461424

Epoch: 83
Loss: 0.07573301220052657
ROC train: 0.975572	val: 0.816050	test: 0.844316
PRC train: 0.756367	val: 0.403076	test: 0.472060

Epoch: 84
Loss: 0.07612200209199882
ROC train: 0.974594	val: 0.808683	test: 0.850184
PRC train: 0.747528	val: 0.402780	test: 0.456445

Epoch: 85
Loss: 0.07588533742965992
ROC train: 0.971289	val: 0.804629	test: 0.836663
PRC train: 0.716594	val: 0.388804	test: 0.434367

Epoch: 86
Loss: 0.07537569071138735
ROC train: 0.975121	val: 0.805232	test: 0.849825
PRC train: 0.747128	val: 0.388336	test: 0.469170

Epoch: 87
Loss: 0.07690965265805538
ROC train: 0.976266	val: 0.812271	test: 0.847923
PRC train: 0.751948	val: 0.397162	test: 0.452152

Epoch: 88
Loss: 0.07385007009115765
ROC train: 0.973607	val: 0.802408	test: 0.847478
PRC train: 0.743445	val: 0.377121	test: 0.466563

Epoch: 89
Loss: 0.07349145844611894
ROC train: 0.975516	val: 0.794798	test: 0.843815
PRC train: 0.756151	val: 0.385181	test: 0.449575

Epoch: 90
Loss: 0.07320383998722989
ROC train: 0.975775	val: 0.795358	test: 0.842168
PRC train: 0.758995	val: 0.379531	test: 0.441760

Epoch: 91
Loss: 0.07381009564802037
ROC train: 0.977839	val: 0.819070	test: 0.861584
PRC train: 0.769860	val: 0.382784	test: 0.476115

Epoch: 92
Loss: 0.07255243927866899
ROC train: 0.976822	val: 0.806379	test: 0.845766
PRC train: 0.764101	val: 0.399799	test: 0.486876

Epoch: 93
Loss: 0.0729354126564852
ROC train: 0.980647	val: 0.787724	test: 0.859274
PRC train: 0.791957	val: 0.405731	test: 0.484638

Epoch: 94
Loss: 0.07049158676684958
ROC train: 0.979538	val: 0.782484	test: 0.801189
PRC train: 0.759911	val: 0.368255	test: 0.416210

Epoch: 95
Loss: 0.07022387592473889
ROC train: 0.982774	val: 0.786538	test: 0.803874
PRC train: 0.776775	val: 0.393831	test: 0.422405

Epoch: 96
Loss: 0.07152367279650973
ROC train: 0.980065	val: 0.792790	test: 0.806822
PRC train: 0.780580	val: 0.394451	test: 0.417864

Epoch: 97
Loss: 0.06925283087282107
ROC train: 0.981336	val: 0.786640	test: 0.799848
PRC train: 0.766445	val: 0.369755	test: 0.397480

Epoch: 98
Loss: 0.07272838227413933
ROC train: 0.984169	val: 0.786381	test: 0.800997
PRC train: 0.795956	val: 0.393835	test: 0.413811

Epoch: 99
Loss: 0.06962898925390759
ROC train: 0.979866	val: 0.783480	test: 0.797939
PRC train: 0.771399	val: 0.369962	test: 0.413416

Epoch: 100
Loss: 0.07077375353873772
ROC train: 0.982753	val: 0.796555	test: 0.813701
PRC train: 0.785637	val: 0.384873	test: 0.413910

Epoch: 101
Loss: 0.06954068311787077
ROC train: 0.982313	val: 0.782571	test: 0.804293
PRC train: 0.771204	val: 0.389324	test: 0.405028

Epoch: 102
Loss: 0.06861477512471921
ROC train: 0.985067	val: 0.786111	test: 0.805342
PRC train: 0.804260	val: 0.388883	test: 0.438777

Epoch: 103
Loss: 0.07072601030276202
ROC train: 0.983500	val: 0.783727	test: 0.803452
PRC train: 0.796373	val: 0.393860	test: 0.408803

Epoch: 104
Loss: 0.06887784008145222
ROC train: 0.982321	val: 0.790799	test: 0.807680
PRC train: 0.787334	val: 0.386895	test: 0.409179

Epoch: 105
Loss: 0.0694055029990875
ROC train: 0.982933	val: 0.782923	test: 0.804949
PRC train: 0.786752	val: 0.400972	test: 0.417024

Epoch: 106
Loss: 0.06992051239038254
ROC train: 0.985045	val: 0.787936	test: 0.813185
PRC train: 0.810254	val: 0.395370	test: 0.414642

Epoch: 107
Loss: 0.06858712010828646
ROC train: 0.986817	val: 0.790530	test: 0.812932
PRC train: 0.818611	val: 0.402027	test: 0.415713

Epoch: 108
Loss: 0.06705838857852268
ROC train: 0.984847	val: 0.784634	test: 0.801291
PRC train: 0.806446	val: 0.375750	test: 0.415299

Epoch: 109
Loss: 0.06844962681453254
ROC train: 0.986873	val: 0.788104	test: 0.802982
PRC train: 0.817378	val: 0.382136	test: 0.408007

Epoch: 110
Loss: 0.06522478028928573
ROC train: 0.985314	val: 0.792276	test: 0.804522
PRC train: 0.810516	val: 0.390685	test: 0.414563

Epoch: 111
Loss: 0.06413744727211021
ROC train: 0.985495	val: 0.774295	test: 0.806878
PRC train: 0.814769	val: 0.389726	test: 0.410779

Epoch: 112
Loss: 0.06765288799179241
ROC train: 0.984840	val: 0.784938	test: 0.801979
PRC train: 0.807539	val: 0.383543	test: 0.397266

Epoch: 113
Loss: 0.0654859731235409
ROC train: 0.987400	val: 0.781266	test: 0.809965
PRC train: 0.822694	val: 0.375604	test: 0.406862

Epoch: 114
Loss: 0.06737708919809728
ROC train: 0.982579	val: 0.788606	test: 0.812665
PRC train: 0.789213	val: 0.382388	test: 0.412631

Epoch: 115
Loss: 0.06570505215726907
ROC train: 0.987237	val: 0.780556	test: 0.814200
PRC train: 0.822186	val: 0.378029	test: 0.405716

Epoch: 116
Loss: 0.06364798747248951
ROC train: 0.987691	val: 0.781476	test: 0.804368
PRC train: 0.827076	val: 0.401405	test: 0.395448

Epoch: 117
Loss: 0.06475815949253283
ROC train: 0.987426	val: 0.797892	test: 0.805288
PRC train: 0.826078	val: 0.395729	test: 0.404575

Epoch: 118
Loss: 0.06330536383691995
ROC train: 0.986976	val: 0.772888	test: 0.808463
PRC train: 0.817768	val: 0.359398	test: 0.382001

Epoch: 119
Loss: 0.06546878990113572
ROC train: 0.985776	val: 0.783250	test: 0.810679
PRC train: 0.812669	val: 0.377373	test: 0.386904

Epoch: 120
Loss: 0.060242600299732454
ROC train: 0.988321	val: 0.781615	test: 0.810185
PRC train: 0.835841	val: 0.384056	test: 0.403006

Early stopping
Best (ROC):	 train: 0.958286	val: 0.801629	test: 0.812734
Best (PRC):	 train: 0.668473	val: 0.393512	test: 0.422158

ROC train: 0.982142	val: 0.776621	test: 0.793293
PRC train: 0.791071	val: 0.392176	test: 0.402169

Epoch: 95
Loss: 0.07045834319383651
ROC train: 0.983114	val: 0.780742	test: 0.815674
PRC train: 0.789889	val: 0.396891	test: 0.410328

Epoch: 96
Loss: 0.06900390082227739
ROC train: 0.982768	val: 0.771074	test: 0.801030
PRC train: 0.795020	val: 0.406100	test: 0.407960

Epoch: 97
Loss: 0.06731751410040103
ROC train: 0.982819	val: 0.779296	test: 0.799393
PRC train: 0.794847	val: 0.413823	test: 0.390362

Epoch: 98
Loss: 0.06848894278425693
ROC train: 0.984047	val: 0.785682	test: 0.802240
PRC train: 0.796621	val: 0.393994	test: 0.407180

Epoch: 99
Loss: 0.06891313584068862
ROC train: 0.982960	val: 0.782524	test: 0.799249
PRC train: 0.789942	val: 0.391797	test: 0.387277

Epoch: 100
Loss: 0.06858743905577278
ROC train: 0.983689	val: 0.787532	test: 0.803741
PRC train: 0.788991	val: 0.376535	test: 0.396819

Epoch: 101
Loss: 0.0676501550905321
ROC train: 0.984211	val: 0.773084	test: 0.807793
PRC train: 0.806319	val: 0.377776	test: 0.411805

Epoch: 102
Loss: 0.068100819945091
ROC train: 0.986936	val: 0.775260	test: 0.797869
PRC train: 0.817907	val: 0.392564	test: 0.404658

Epoch: 103
Loss: 0.06847709246379298
ROC train: 0.984696	val: 0.776526	test: 0.801083
PRC train: 0.809428	val: 0.392839	test: 0.398450

Epoch: 104
Loss: 0.06639376201936027
ROC train: 0.985910	val: 0.781894	test: 0.807358
PRC train: 0.806960	val: 0.391862	test: 0.407175

Epoch: 105
Loss: 0.06769851534292022
ROC train: 0.984242	val: 0.785874	test: 0.797265
PRC train: 0.798213	val: 0.392524	test: 0.390691

Epoch: 106
Loss: 0.06803431238002813
ROC train: 0.985605	val: 0.777046	test: 0.801429
PRC train: 0.809665	val: 0.378966	test: 0.394281

Epoch: 107
Loss: 0.06554900212347933
ROC train: 0.985601	val: 0.772358	test: 0.808094
PRC train: 0.816510	val: 0.399156	test: 0.414339

Epoch: 108
Loss: 0.06733873298575942
ROC train: 0.987002	val: 0.779620	test: 0.796624
PRC train: 0.828442	val: 0.396838	test: 0.380706

Epoch: 109
Loss: 0.06486767073752912
ROC train: 0.984245	val: 0.776721	test: 0.798600
PRC train: 0.800578	val: 0.391382	test: 0.401539

Epoch: 110
Loss: 0.06523975104497087
ROC train: 0.987459	val: 0.790023	test: 0.806566
PRC train: 0.824139	val: 0.395543	test: 0.402246

Epoch: 111
Loss: 0.06568120592190396
ROC train: 0.989017	val: 0.785409	test: 0.800788
PRC train: 0.835556	val: 0.390155	test: 0.396633

Epoch: 112
Loss: 0.06286820667762329
ROC train: 0.985690	val: 0.779514	test: 0.801249
PRC train: 0.817315	val: 0.372692	test: 0.387528

Epoch: 113
Loss: 0.06483077827499635
ROC train: 0.987783	val: 0.777581	test: 0.799721
PRC train: 0.829815	val: 0.390360	test: 0.388166

Epoch: 114
Loss: 0.0632484295026994
ROC train: 0.988729	val: 0.779537	test: 0.801126
PRC train: 0.842647	val: 0.390539	test: 0.383116

Epoch: 115
Loss: 0.06376930507955664
ROC train: 0.988675	val: 0.782004	test: 0.802797
PRC train: 0.834269	val: 0.386537	test: 0.379954

Epoch: 116
Loss: 0.061632617424770934
ROC train: 0.988117	val: 0.778830	test: 0.803966
PRC train: 0.826865	val: 0.382407	test: 0.370717

Epoch: 117
Loss: 0.06485642079046433
ROC train: 0.988629	val: 0.779670	test: 0.808694
PRC train: 0.835434	val: 0.404833	test: 0.391063

Epoch: 118
Loss: 0.0616982906747996
ROC train: 0.988795	val: 0.772527	test: 0.794416
PRC train: 0.838747	val: 0.393869	test: 0.375210

Epoch: 119
Loss: 0.06149719712687915
ROC train: 0.989557	val: 0.771540	test: 0.801536
PRC train: 0.847814	val: 0.387817	test: 0.373728

Epoch: 120
Loss: 0.06130324770185435
ROC train: 0.989237	val: 0.772893	test: 0.789427
PRC train: 0.839957	val: 0.373562	test: 0.364410

Early stopping
Best (ROC):	 train: 0.950652	val: 0.802305	test: 0.816917
Best (PRC):	 train: 0.627218	val: 0.387832	test: 0.437432

Epoch: 94
Loss: 0.07355244716991052
ROC train: 0.981972	val: 0.777247	test: 0.802727
PRC train: 0.774549	val: 0.401429	test: 0.412520

Epoch: 95
Loss: 0.07156828237884555
ROC train: 0.982067	val: 0.780541	test: 0.808420
PRC train: 0.767310	val: 0.379510	test: 0.416504

Epoch: 96
Loss: 0.07115893804694953
ROC train: 0.982243	val: 0.777932	test: 0.794435
PRC train: 0.778436	val: 0.395274	test: 0.386833

Epoch: 97
Loss: 0.07242560859237668
ROC train: 0.981080	val: 0.783235	test: 0.795136
PRC train: 0.781683	val: 0.379354	test: 0.399206

Epoch: 98
Loss: 0.07149607202178125
ROC train: 0.982364	val: 0.780561	test: 0.800747
PRC train: 0.773804	val: 0.395580	test: 0.416424

Epoch: 99
Loss: 0.06962019222219779
ROC train: 0.982697	val: 0.780055	test: 0.806193
PRC train: 0.784527	val: 0.402284	test: 0.424371

Epoch: 100
Loss: 0.06897003495723086
ROC train: 0.984102	val: 0.771686	test: 0.805254
PRC train: 0.791845	val: 0.390651	test: 0.429149

Epoch: 101
Loss: 0.06904225525918158
ROC train: 0.983609	val: 0.777302	test: 0.802132
PRC train: 0.789066	val: 0.392021	test: 0.430053

Epoch: 102
Loss: 0.06996067544180452
ROC train: 0.984932	val: 0.781808	test: 0.803780
PRC train: 0.802331	val: 0.395756	test: 0.417237

Epoch: 103
Loss: 0.06977060624510394
ROC train: 0.983417	val: 0.782183	test: 0.808743
PRC train: 0.780753	val: 0.384789	test: 0.420921

Epoch: 104
Loss: 0.06815729535061502
ROC train: 0.984885	val: 0.779752	test: 0.803952
PRC train: 0.796642	val: 0.385996	test: 0.407133

Epoch: 105
Loss: 0.06996481385823633
ROC train: 0.985135	val: 0.775904	test: 0.803528
PRC train: 0.800423	val: 0.391441	test: 0.401844

Epoch: 106
Loss: 0.06705259779567321
ROC train: 0.986431	val: 0.778144	test: 0.801887
PRC train: 0.805853	val: 0.399155	test: 0.409737

Epoch: 107
Loss: 0.07010531691708387
ROC train: 0.986121	val: 0.778199	test: 0.798311
PRC train: 0.797399	val: 0.407351	test: 0.410605

Epoch: 108
Loss: 0.06797836247168576
ROC train: 0.985140	val: 0.777608	test: 0.802684
PRC train: 0.800663	val: 0.393157	test: 0.418953

Epoch: 109
Loss: 0.06805587333343065
ROC train: 0.986181	val: 0.775997	test: 0.801217
PRC train: 0.808414	val: 0.381760	test: 0.400279

Epoch: 110
Loss: 0.06796680523120625
ROC train: 0.986441	val: 0.780499	test: 0.804966
PRC train: 0.806980	val: 0.392690	test: 0.422072

Epoch: 111
Loss: 0.06465806148974326
ROC train: 0.979788	val: 0.781730	test: 0.803980
PRC train: 0.774094	val: 0.375420	test: 0.403895

Epoch: 112
Loss: 0.06528726461752841
ROC train: 0.987982	val: 0.778492	test: 0.812334
PRC train: 0.824724	val: 0.400790	test: 0.410641

Epoch: 113
Loss: 0.06601931690670688
ROC train: 0.984654	val: 0.769587	test: 0.799196
PRC train: 0.810733	val: 0.391897	test: 0.399020

Epoch: 114
Loss: 0.06644943415994758
ROC train: 0.984213	val: 0.786078	test: 0.802891
PRC train: 0.798239	val: 0.374989	test: 0.410471

Epoch: 115
Loss: 0.06388565584281149
ROC train: 0.988937	val: 0.779010	test: 0.800697
PRC train: 0.828770	val: 0.394261	test: 0.413822

Epoch: 116
Loss: 0.06639323132331411
ROC train: 0.988322	val: 0.779240	test: 0.793178
PRC train: 0.823239	val: 0.375674	test: 0.384551

Epoch: 117
Loss: 0.06570208706671728
ROC train: 0.986606	val: 0.778676	test: 0.793532
PRC train: 0.808036	val: 0.372024	test: 0.394780

Epoch: 118
Loss: 0.06530332180095728
ROC train: 0.988383	val: 0.778601	test: 0.803568
PRC train: 0.826654	val: 0.392436	test: 0.393118

Epoch: 119
Loss: 0.06505714260020895
ROC train: 0.989459	val: 0.774177	test: 0.800750
PRC train: 0.832748	val: 0.373488	test: 0.389091

Epoch: 120
Loss: 0.06156306569939493
ROC train: 0.988576	val: 0.782213	test: 0.799123
PRC train: 0.829005	val: 0.385499	test: 0.398422

Early stopping
Best (ROC):	 train: 0.932933	val: 0.793736	test: 0.820540
Best (PRC):	 train: 0.556602	val: 0.354819	test: 0.421799
All runs completed.

ROC train: 0.980903	val: 0.800214	test: 0.818616
PRC train: 0.776816	val: 0.428112	test: 0.419601

Epoch: 95
Loss: 0.07077196690169064
ROC train: 0.978975	val: 0.795529	test: 0.815335
PRC train: 0.776679	val: 0.441044	test: 0.409183

Epoch: 96
Loss: 0.07131523872684721
ROC train: 0.980810	val: 0.790209	test: 0.813937
PRC train: 0.781212	val: 0.426220	test: 0.415391

Epoch: 97
Loss: 0.07107353947517425
ROC train: 0.981940	val: 0.796811	test: 0.818916
PRC train: 0.784244	val: 0.458657	test: 0.434032

Epoch: 98
Loss: 0.06827826924519535
ROC train: 0.979783	val: 0.792153	test: 0.817950
PRC train: 0.769766	val: 0.435812	test: 0.411307

Epoch: 99
Loss: 0.06833359894483046
ROC train: 0.980806	val: 0.793045	test: 0.816026
PRC train: 0.779606	val: 0.440618	test: 0.402526

Epoch: 100
Loss: 0.0697352644231274
ROC train: 0.981579	val: 0.785717	test: 0.810280
PRC train: 0.790296	val: 0.411358	test: 0.399896

Epoch: 101
Loss: 0.07002969979657435
ROC train: 0.981331	val: 0.805598	test: 0.824682
PRC train: 0.775906	val: 0.392003	test: 0.387872

Epoch: 102
Loss: 0.06833247494230017
ROC train: 0.983076	val: 0.794649	test: 0.824299
PRC train: 0.796126	val: 0.438498	test: 0.406412

Epoch: 103
Loss: 0.06616000626812914
ROC train: 0.982437	val: 0.780512	test: 0.794280
PRC train: 0.786952	val: 0.404139	test: 0.388336

Epoch: 104
Loss: 0.06861058675708713
ROC train: 0.984082	val: 0.785513	test: 0.810327
PRC train: 0.799743	val: 0.411963	test: 0.392794

Epoch: 105
Loss: 0.06771133674631842
ROC train: 0.982437	val: 0.787149	test: 0.797616
PRC train: 0.782892	val: 0.392869	test: 0.364260

Epoch: 106
Loss: 0.06704573325855824
ROC train: 0.984214	val: 0.790144	test: 0.809549
PRC train: 0.801582	val: 0.437811	test: 0.396608

Epoch: 107
Loss: 0.06698158075351054
ROC train: 0.985298	val: 0.795906	test: 0.817577
PRC train: 0.815573	val: 0.439292	test: 0.422657

Epoch: 108
Loss: 0.06729410068824986
ROC train: 0.983745	val: 0.786994	test: 0.806555
PRC train: 0.800488	val: 0.403477	test: 0.390418

Epoch: 109
Loss: 0.0664479404667705
ROC train: 0.983546	val: 0.786649	test: 0.803769
PRC train: 0.794925	val: 0.405030	test: 0.377293

Epoch: 110
Loss: 0.06477342874453486
ROC train: 0.985403	val: 0.792962	test: 0.802861
PRC train: 0.807144	val: 0.419993	test: 0.387307

Epoch: 111
Loss: 0.06406790549934561
ROC train: 0.986365	val: 0.788610	test: 0.816227
PRC train: 0.816483	val: 0.416959	test: 0.409046

Epoch: 112
Loss: 0.06701216960149967
ROC train: 0.986388	val: 0.790926	test: 0.813001
PRC train: 0.823273	val: 0.429449	test: 0.401392

Epoch: 113
Loss: 0.06401197801987464
ROC train: 0.984513	val: 0.790025	test: 0.816125
PRC train: 0.801353	val: 0.405135	test: 0.381448

Epoch: 114
Loss: 0.06601886206431001
ROC train: 0.986217	val: 0.796294	test: 0.810660
PRC train: 0.822469	val: 0.416121	test: 0.379786

Epoch: 115
Loss: 0.06254261991411468
ROC train: 0.987710	val: 0.783051	test: 0.796532
PRC train: 0.826072	val: 0.415264	test: 0.383944

Epoch: 116
Loss: 0.06477282602875949
ROC train: 0.987319	val: 0.792545	test: 0.806570
PRC train: 0.821178	val: 0.422766	test: 0.380056

Epoch: 117
Loss: 0.06357794050377982
ROC train: 0.985893	val: 0.784650	test: 0.810684
PRC train: 0.820834	val: 0.406967	test: 0.396672

Epoch: 118
Loss: 0.06457146830037931
ROC train: 0.985718	val: 0.787926	test: 0.801343
PRC train: 0.806066	val: 0.412861	test: 0.395232

Epoch: 119
Loss: 0.06324866366391974
ROC train: 0.986184	val: 0.793103	test: 0.812673
PRC train: 0.819029	val: 0.424833	test: 0.408224

Epoch: 120
Loss: 0.06271674723695184
ROC train: 0.988625	val: 0.792164	test: 0.814191
PRC train: 0.837464	val: 0.423254	test: 0.398925

Early stopping
Best (ROC):	 train: 0.936379	val: 0.821953	test: 0.842958
Best (PRC):	 train: 0.601477	val: 0.420634	test: 0.437604

ROC train: 0.977901	val: 0.806320	test: 0.805176
PRC train: 0.767254	val: 0.440037	test: 0.401402

Epoch: 95
Loss: 0.07282035884691151
ROC train: 0.980388	val: 0.809186	test: 0.809835
PRC train: 0.773841	val: 0.430743	test: 0.400998

Epoch: 96
Loss: 0.0726064588712346
ROC train: 0.979190	val: 0.796554	test: 0.805518
PRC train: 0.775949	val: 0.443599	test: 0.410120

Epoch: 97
Loss: 0.07277213271963222
ROC train: 0.981640	val: 0.798254	test: 0.812636
PRC train: 0.783459	val: 0.419384	test: 0.401110

Epoch: 98
Loss: 0.07206152508853142
ROC train: 0.981382	val: 0.801355	test: 0.813712
PRC train: 0.789041	val: 0.437845	test: 0.420418

Epoch: 99
Loss: 0.07080504065235685
ROC train: 0.980626	val: 0.803799	test: 0.813772
PRC train: 0.778287	val: 0.437653	test: 0.395197

Epoch: 100
Loss: 0.07026602427505506
ROC train: 0.980396	val: 0.805522	test: 0.812267
PRC train: 0.770105	val: 0.404591	test: 0.415275

Epoch: 101
Loss: 0.07062638702910672
ROC train: 0.979699	val: 0.807399	test: 0.820082
PRC train: 0.772626	val: 0.448135	test: 0.418121

Epoch: 102
Loss: 0.06967423614997638
ROC train: 0.981326	val: 0.798263	test: 0.808264
PRC train: 0.784047	val: 0.426155	test: 0.399683

Epoch: 103
Loss: 0.06877207307306797
ROC train: 0.980342	val: 0.799384	test: 0.809628
PRC train: 0.779715	val: 0.421149	test: 0.399242

Epoch: 104
Loss: 0.06774831845842427
ROC train: 0.980636	val: 0.807046	test: 0.804977
PRC train: 0.775193	val: 0.417716	test: 0.392140

Epoch: 105
Loss: 0.06743197556792344
ROC train: 0.983105	val: 0.805610	test: 0.809987
PRC train: 0.790627	val: 0.424745	test: 0.390471

Epoch: 106
Loss: 0.06761330293770314
ROC train: 0.984363	val: 0.800024	test: 0.804627
PRC train: 0.801251	val: 0.433368	test: 0.403112

Epoch: 107
Loss: 0.06736695733021816
ROC train: 0.983701	val: 0.797148	test: 0.806687
PRC train: 0.801636	val: 0.427391	test: 0.406372

Epoch: 108
Loss: 0.067435977404707
ROC train: 0.984863	val: 0.805229	test: 0.813924
PRC train: 0.800553	val: 0.437749	test: 0.395608

Epoch: 109
Loss: 0.06854174560355147
ROC train: 0.980378	val: 0.790739	test: 0.814983
PRC train: 0.774076	val: 0.423029	test: 0.389962

Epoch: 110
Loss: 0.06648846777236057
ROC train: 0.984324	val: 0.796044	test: 0.812786
PRC train: 0.803439	val: 0.426227	test: 0.392836

Epoch: 111
Loss: 0.06464357646092547
ROC train: 0.984463	val: 0.799594	test: 0.818116
PRC train: 0.802391	val: 0.423818	test: 0.409262

Epoch: 112
Loss: 0.06527659453671339
ROC train: 0.985028	val: 0.797728	test: 0.820023
PRC train: 0.807877	val: 0.437316	test: 0.412885

Epoch: 113
Loss: 0.06503319286615246
ROC train: 0.986776	val: 0.797157	test: 0.816319
PRC train: 0.819722	val: 0.429393	test: 0.396335

Epoch: 114
Loss: 0.0654888715251979
ROC train: 0.985587	val: 0.799368	test: 0.813988
PRC train: 0.809124	val: 0.418936	test: 0.398135

Epoch: 115
Loss: 0.06633379800994053
ROC train: 0.987134	val: 0.802190	test: 0.811365
PRC train: 0.819174	val: 0.416667	test: 0.389933

Epoch: 116
Loss: 0.06421655304687848
ROC train: 0.985792	val: 0.803740	test: 0.819703
PRC train: 0.809170	val: 0.436271	test: 0.400699

Epoch: 117
Loss: 0.06336824136200082
ROC train: 0.986556	val: 0.803456	test: 0.808753
PRC train: 0.819664	val: 0.448329	test: 0.392661

Epoch: 118
Loss: 0.06372503614875508
ROC train: 0.987817	val: 0.801220	test: 0.811710
PRC train: 0.825822	val: 0.422136	test: 0.367119

Epoch: 119
Loss: 0.06177071507875173
ROC train: 0.983708	val: 0.788306	test: 0.790519
PRC train: 0.799373	val: 0.410710	test: 0.362862

Epoch: 120
Loss: 0.0627917211476162
ROC train: 0.985836	val: 0.799448	test: 0.807645
PRC train: 0.813542	val: 0.413265	test: 0.386900

Early stopping
Best (ROC):	 train: 0.968446	val: 0.819857	test: 0.819664
Best (PRC):	 train: 0.701837	val: 0.432830	test: 0.420709


Epoch: 94
Loss: 0.07137657061157943
ROC train: 0.980958	val: 0.800227	test: 0.813470
PRC train: 0.774102	val: 0.447562	test: 0.397772

Epoch: 95
Loss: 0.07196525464601357
ROC train: 0.980461	val: 0.799344	test: 0.816491
PRC train: 0.763399	val: 0.425817	test: 0.416932

Epoch: 96
Loss: 0.0707379864077832
ROC train: 0.981713	val: 0.817004	test: 0.810880
PRC train: 0.781444	val: 0.429471	test: 0.418830

Epoch: 97
Loss: 0.06952745953871257
ROC train: 0.979242	val: 0.810096	test: 0.820797
PRC train: 0.755413	val: 0.429660	test: 0.407813

Epoch: 98
Loss: 0.07061570943789586
ROC train: 0.979721	val: 0.812217	test: 0.827145
PRC train: 0.774330	val: 0.427838	test: 0.398068

Epoch: 99
Loss: 0.07080811941477477
ROC train: 0.982680	val: 0.804179	test: 0.811692
PRC train: 0.788265	val: 0.444176	test: 0.408721

Epoch: 100
Loss: 0.071734922704171
ROC train: 0.982929	val: 0.816021	test: 0.805057
PRC train: 0.795993	val: 0.436167	test: 0.406416

Epoch: 101
Loss: 0.06930582433347322
ROC train: 0.980075	val: 0.792621	test: 0.815735
PRC train: 0.779442	val: 0.405677	test: 0.395500

Epoch: 102
Loss: 0.06894003616904842
ROC train: 0.983355	val: 0.803001	test: 0.813057
PRC train: 0.782537	val: 0.417507	test: 0.390783

Epoch: 103
Loss: 0.0718831863305594
ROC train: 0.980001	val: 0.816957	test: 0.819231
PRC train: 0.784138	val: 0.436801	test: 0.410743

Epoch: 104
Loss: 0.0674292380038041
ROC train: 0.980025	val: 0.787696	test: 0.815181
PRC train: 0.772673	val: 0.405329	test: 0.406880

Epoch: 105
Loss: 0.06937618472272458
ROC train: 0.984291	val: 0.804629	test: 0.824500
PRC train: 0.802445	val: 0.436634	test: 0.414207

Epoch: 106
Loss: 0.06760298411683122
ROC train: 0.982307	val: 0.799651	test: 0.820530
PRC train: 0.790685	val: 0.436612	test: 0.410146

Epoch: 107
Loss: 0.06686104439483767
ROC train: 0.983223	val: 0.798844	test: 0.829015
PRC train: 0.796897	val: 0.439069	test: 0.425693

Epoch: 108
Loss: 0.06534487636749493
ROC train: 0.986749	val: 0.808418	test: 0.815226
PRC train: 0.813347	val: 0.434822	test: 0.407779

Epoch: 109
Loss: 0.06685092520574402
ROC train: 0.984480	val: 0.796899	test: 0.833375
PRC train: 0.800091	val: 0.414209	test: 0.408959

Epoch: 110
Loss: 0.06676091934733723
ROC train: 0.985549	val: 0.817899	test: 0.824918
PRC train: 0.814740	val: 0.434863	test: 0.411995

Epoch: 111
Loss: 0.06560757716726441
ROC train: 0.986087	val: 0.800324	test: 0.821413
PRC train: 0.808327	val: 0.423901	test: 0.388314

Epoch: 112
Loss: 0.0650113893163862
ROC train: 0.984605	val: 0.804184	test: 0.815308
PRC train: 0.797537	val: 0.427152	test: 0.409430

Epoch: 113
Loss: 0.0656719827856577
ROC train: 0.986856	val: 0.804766	test: 0.827094
PRC train: 0.817702	val: 0.448481	test: 0.403844

Epoch: 114
Loss: 0.06445624120477136
ROC train: 0.987114	val: 0.802293	test: 0.812555
PRC train: 0.827245	val: 0.437353	test: 0.394929

Epoch: 115
Loss: 0.06437232651033467
ROC train: 0.984668	val: 0.798353	test: 0.823933
PRC train: 0.810990	val: 0.417890	test: 0.405274

Epoch: 116
Loss: 0.06353899063152638
ROC train: 0.986895	val: 0.795424	test: 0.825455
PRC train: 0.820970	val: 0.426298	test: 0.381321

Epoch: 117
Loss: 0.06471979038768698
ROC train: 0.989354	val: 0.798179	test: 0.822800
PRC train: 0.839627	val: 0.441271	test: 0.395167

Epoch: 118
Loss: 0.06269384278876468
ROC train: 0.988676	val: 0.808522	test: 0.805243
PRC train: 0.823308	val: 0.429536	test: 0.380982

Epoch: 119
Loss: 0.06395709415774518
ROC train: 0.987241	val: 0.806753	test: 0.816061
PRC train: 0.820347	val: 0.432500	test: 0.369215

Epoch: 120
Loss: 0.062271763818128906
ROC train: 0.987697	val: 0.782722	test: 0.822155
PRC train: 0.825383	val: 0.421427	test: 0.392004

Early stopping
Best (ROC):	 train: 0.869046	val: 0.820891	test: 0.829589
Best (PRC):	 train: 0.452653	val: 0.418820	test: 0.402979
All runs completed.

ROC train: 0.969028	val: 0.783597	test: 0.818640
PRC train: 0.718630	val: 0.382403	test: 0.393841

Epoch: 95
Loss: 0.07335716249286996
ROC train: 0.971938	val: 0.792247	test: 0.844740
PRC train: 0.739406	val: 0.386329	test: 0.436003

Epoch: 96
Loss: 0.07302222462992994
ROC train: 0.972896	val: 0.791228	test: 0.839475
PRC train: 0.748267	val: 0.383625	test: 0.449509

Epoch: 97
Loss: 0.07477078737008212
ROC train: 0.973703	val: 0.794433	test: 0.844334
PRC train: 0.750473	val: 0.393653	test: 0.440009

Epoch: 98
Loss: 0.07286169295705242
ROC train: 0.975203	val: 0.790908	test: 0.835573
PRC train: 0.744580	val: 0.403888	test: 0.422654

Epoch: 99
Loss: 0.07287384395519672
ROC train: 0.975738	val: 0.791087	test: 0.845727
PRC train: 0.764019	val: 0.399531	test: 0.464481

Epoch: 100
Loss: 0.07271821665227873
ROC train: 0.976822	val: 0.771299	test: 0.844246
PRC train: 0.763397	val: 0.382840	test: 0.453927

Epoch: 101
Loss: 0.07089741132535336
ROC train: 0.973697	val: 0.791348	test: 0.842457
PRC train: 0.750715	val: 0.390532	test: 0.443958

Epoch: 102
Loss: 0.07307444719731866
ROC train: 0.977176	val: 0.800302	test: 0.840871
PRC train: 0.764650	val: 0.376454	test: 0.450134

Epoch: 103
Loss: 0.07196435037529413
ROC train: 0.979771	val: 0.788460	test: 0.845367
PRC train: 0.783806	val: 0.388420	test: 0.444245

Epoch: 104
Loss: 0.07137104171519473
ROC train: 0.979562	val: 0.783578	test: 0.842589
PRC train: 0.776779	val: 0.407446	test: 0.462400

Epoch: 105
Loss: 0.07045557994506367
ROC train: 0.975602	val: 0.785393	test: 0.833142
PRC train: 0.759251	val: 0.382752	test: 0.453705

Epoch: 106
Loss: 0.06955446059471995
ROC train: 0.979101	val: 0.793513	test: 0.842179
PRC train: 0.775232	val: 0.396543	test: 0.480421

Epoch: 107
Loss: 0.0699509646734379
ROC train: 0.979555	val: 0.805982	test: 0.843075
PRC train: 0.775189	val: 0.401061	test: 0.456964

Epoch: 108
Loss: 0.0688908248038809
ROC train: 0.979466	val: 0.800753	test: 0.839190
PRC train: 0.773425	val: 0.386127	test: 0.438703

Epoch: 109
Loss: 0.06975175039786663
ROC train: 0.978720	val: 0.791202	test: 0.849986
PRC train: 0.763775	val: 0.370490	test: 0.464790

Epoch: 110
Loss: 0.07008980713854691
ROC train: 0.981983	val: 0.786818	test: 0.847743
PRC train: 0.801696	val: 0.396442	test: 0.466148

Epoch: 111
Loss: 0.06717038906650015
ROC train: 0.979585	val: 0.794886	test: 0.843659
PRC train: 0.778211	val: 0.398692	test: 0.452760

Epoch: 112
Loss: 0.0692850335352189
ROC train: 0.981898	val: 0.786876	test: 0.851486
PRC train: 0.794051	val: 0.406840	test: 0.462461

Epoch: 113
Loss: 0.06838456658070852
ROC train: 0.981165	val: 0.787045	test: 0.857227
PRC train: 0.789990	val: 0.402059	test: 0.470928

Epoch: 114
Loss: 0.06726310530179797
ROC train: 0.983563	val: 0.781129	test: 0.851960
PRC train: 0.808121	val: 0.393072	test: 0.443037

Epoch: 115
Loss: 0.06664992577983765
ROC train: 0.984028	val: 0.797291	test: 0.851296
PRC train: 0.815436	val: 0.389106	test: 0.455997

Epoch: 116
Loss: 0.06626656839740375
ROC train: 0.980905	val: 0.779062	test: 0.850076
PRC train: 0.791302	val: 0.358518	test: 0.435380

Epoch: 117
Loss: 0.06679139687904159
ROC train: 0.984513	val: 0.791297	test: 0.852605
PRC train: 0.813549	val: 0.387906	test: 0.474888

Epoch: 118
Loss: 0.06720318236714609
ROC train: 0.984428	val: 0.806522	test: 0.859155
PRC train: 0.807002	val: 0.388154	test: 0.451082

Epoch: 119
Loss: 0.06652563902666804
ROC train: 0.981909	val: 0.802518	test: 0.851933
PRC train: 0.795411	val: 0.391246	test: 0.454686

Epoch: 120
Loss: 0.06610680180542883
ROC train: 0.985982	val: 0.785879	test: 0.845903
PRC train: 0.823370	val: 0.365178	test: 0.451256

Early stopping
Best (ROC):	 train: 0.905553	val: 0.820150	test: 0.836509
Best (PRC):	 train: 0.516257	val: 0.390366	test: 0.472399

ROC train: 0.977272	val: 0.793348	test: 0.840446
PRC train: 0.774926	val: 0.390866	test: 0.457881

Epoch: 95
Loss: 0.07185952631546384
ROC train: 0.978263	val: 0.780031	test: 0.844158
PRC train: 0.774118	val: 0.401070	test: 0.479937

Epoch: 96
Loss: 0.0716757183266532
ROC train: 0.979435	val: 0.793846	test: 0.849942
PRC train: 0.774572	val: 0.375912	test: 0.450016

Epoch: 97
Loss: 0.07161837348552148
ROC train: 0.977515	val: 0.791517	test: 0.851213
PRC train: 0.765731	val: 0.350278	test: 0.450979

Epoch: 98
Loss: 0.07125542661031017
ROC train: 0.981232	val: 0.792643	test: 0.841924
PRC train: 0.792391	val: 0.396815	test: 0.457812

Epoch: 99
Loss: 0.07060788608857056
ROC train: 0.981721	val: 0.790127	test: 0.861430
PRC train: 0.789135	val: 0.380553	test: 0.465916

Epoch: 100
Loss: 0.07062174603474716
ROC train: 0.981305	val: 0.790219	test: 0.856763
PRC train: 0.784871	val: 0.377164	test: 0.465196

Epoch: 101
Loss: 0.07023040184712752
ROC train: 0.982490	val: 0.785567	test: 0.848992
PRC train: 0.793454	val: 0.377671	test: 0.452227

Epoch: 102
Loss: 0.06999981226697889
ROC train: 0.977541	val: 0.805896	test: 0.847156
PRC train: 0.760209	val: 0.384916	test: 0.426491

Epoch: 103
Loss: 0.06875230931004774
ROC train: 0.983507	val: 0.798353	test: 0.841929
PRC train: 0.803105	val: 0.397893	test: 0.446771

Epoch: 104
Loss: 0.06803538889227981
ROC train: 0.982700	val: 0.804028	test: 0.852591
PRC train: 0.798671	val: 0.364744	test: 0.428931

Epoch: 105
Loss: 0.0692122974209043
ROC train: 0.980698	val: 0.800224	test: 0.853348
PRC train: 0.790908	val: 0.375751	test: 0.422544

Epoch: 106
Loss: 0.07026957082369745
ROC train: 0.981518	val: 0.790247	test: 0.843333
PRC train: 0.786306	val: 0.374228	test: 0.444803

Epoch: 107
Loss: 0.06718528452840646
ROC train: 0.981712	val: 0.786640	test: 0.841047
PRC train: 0.793034	val: 0.375840	test: 0.427050

Epoch: 108
Loss: 0.06696898946866911
ROC train: 0.984321	val: 0.782463	test: 0.849477
PRC train: 0.810601	val: 0.376340	test: 0.480948

Epoch: 109
Loss: 0.0660181157019343
ROC train: 0.985334	val: 0.781421	test: 0.843300
PRC train: 0.810127	val: 0.353895	test: 0.450286

Epoch: 110
Loss: 0.06697935691320772
ROC train: 0.982975	val: 0.799167	test: 0.845458
PRC train: 0.797601	val: 0.384960	test: 0.446532

Epoch: 111
Loss: 0.06921088471499784
ROC train: 0.983688	val: 0.784936	test: 0.844233
PRC train: 0.799002	val: 0.381886	test: 0.429056

Epoch: 112
Loss: 0.06656284731965206
ROC train: 0.985533	val: 0.793769	test: 0.841111
PRC train: 0.825845	val: 0.376549	test: 0.417301

Epoch: 113
Loss: 0.0656987623289403
ROC train: 0.986226	val: 0.795473	test: 0.842565
PRC train: 0.822170	val: 0.378827	test: 0.420615

Epoch: 114
Loss: 0.06633467255156529
ROC train: 0.986964	val: 0.788310	test: 0.843283
PRC train: 0.823224	val: 0.391006	test: 0.453155

Epoch: 115
Loss: 0.06696025192128646
ROC train: 0.986926	val: 0.806546	test: 0.850616
PRC train: 0.827557	val: 0.392658	test: 0.414638

Epoch: 116
Loss: 0.06494864444197615
ROC train: 0.986978	val: 0.795758	test: 0.836103
PRC train: 0.826775	val: 0.378737	test: 0.433543

Epoch: 117
Loss: 0.06332834124741396
ROC train: 0.984608	val: 0.786210	test: 0.857899
PRC train: 0.814326	val: 0.370055	test: 0.439343

Epoch: 118
Loss: 0.0654132262748996
ROC train: 0.987233	val: 0.792439	test: 0.846872
PRC train: 0.828403	val: 0.378700	test: 0.410853

Epoch: 119
Loss: 0.06496406417924804
ROC train: 0.988419	val: 0.781502	test: 0.840235
PRC train: 0.838651	val: 0.373136	test: 0.426569

Epoch: 120
Loss: 0.06379308231897633
ROC train: 0.987777	val: 0.785579	test: 0.843496
PRC train: 0.834785	val: 0.389785	test: 0.442959

Early stopping
Best (ROC):	 train: 0.946313	val: 0.832349	test: 0.857231
Best (PRC):	 train: 0.635026	val: 0.418141	test: 0.485840
Epoch: 94
Loss: 0.07275347062027664
ROC train: 0.975631	val: 0.826798	test: 0.847373
PRC train: 0.759628	val: 0.409056	test: 0.429748

Epoch: 95
Loss: 0.07181118941923822
ROC train: 0.975361	val: 0.799560	test: 0.852432
PRC train: 0.761942	val: 0.411011	test: 0.444083

Epoch: 96
Loss: 0.07272961077117968
ROC train: 0.976677	val: 0.814612	test: 0.843373
PRC train: 0.759424	val: 0.410659	test: 0.406387

Epoch: 97
Loss: 0.07087606856178927
ROC train: 0.977637	val: 0.827125	test: 0.840519
PRC train: 0.776990	val: 0.414319	test: 0.403039

Epoch: 98
Loss: 0.07215471668861935
ROC train: 0.978164	val: 0.819052	test: 0.839283
PRC train: 0.770013	val: 0.426437	test: 0.431464

Epoch: 99
Loss: 0.07074474572926914
ROC train: 0.975090	val: 0.812901	test: 0.851831
PRC train: 0.762309	val: 0.397087	test: 0.432722

Epoch: 100
Loss: 0.06893284352612943
ROC train: 0.977824	val: 0.807975	test: 0.844798
PRC train: 0.766106	val: 0.408085	test: 0.429651

Epoch: 101
Loss: 0.06813651518665514
ROC train: 0.980117	val: 0.809101	test: 0.843953
PRC train: 0.785284	val: 0.388582	test: 0.427752

Epoch: 102
Loss: 0.07078193811209248
ROC train: 0.981399	val: 0.814797	test: 0.843292
PRC train: 0.798793	val: 0.424804	test: 0.451295

Epoch: 103
Loss: 0.0676521309116269
ROC train: 0.982201	val: 0.833297	test: 0.842653
PRC train: 0.804069	val: 0.412830	test: 0.429605

Epoch: 104
Loss: 0.06976048416196466
ROC train: 0.977650	val: 0.803685	test: 0.847381
PRC train: 0.773417	val: 0.407422	test: 0.447605

Epoch: 105
Loss: 0.06847846540054946
ROC train: 0.983352	val: 0.819810	test: 0.849839
PRC train: 0.801460	val: 0.411776	test: 0.419439

Epoch: 106
Loss: 0.06807228916527532
ROC train: 0.983885	val: 0.815775	test: 0.847801
PRC train: 0.810114	val: 0.417478	test: 0.422917

Epoch: 107
Loss: 0.06797680256902934
ROC train: 0.982463	val: 0.822328	test: 0.856286
PRC train: 0.797447	val: 0.403952	test: 0.429887

Epoch: 108
Loss: 0.06938865729999143
ROC train: 0.983696	val: 0.817273	test: 0.845404
PRC train: 0.806805	val: 0.402574	test: 0.427527

Epoch: 109
Loss: 0.06646498276873668
ROC train: 0.984866	val: 0.817944	test: 0.841587
PRC train: 0.814260	val: 0.412261	test: 0.420044

Epoch: 110
Loss: 0.0650942601184987
ROC train: 0.984383	val: 0.814683	test: 0.843036
PRC train: 0.809595	val: 0.407002	test: 0.411814

Epoch: 111
Loss: 0.06621426988055011
ROC train: 0.983018	val: 0.821170	test: 0.853581
PRC train: 0.805418	val: 0.396563	test: 0.424934

Epoch: 112
Loss: 0.06560566702312363
ROC train: 0.985479	val: 0.831851	test: 0.852092
PRC train: 0.822479	val: 0.411914	test: 0.434562

Epoch: 113
Loss: 0.06606054822742236
ROC train: 0.984904	val: 0.818309	test: 0.852434
PRC train: 0.811830	val: 0.396289	test: 0.444149

Epoch: 114
Loss: 0.06355435153531815
ROC train: 0.984460	val: 0.815983	test: 0.851597
PRC train: 0.812143	val: 0.397581	test: 0.428445

Epoch: 115
Loss: 0.06544672414858443
ROC train: 0.986171	val: 0.826320	test: 0.850787
PRC train: 0.832936	val: 0.402479	test: 0.433448

Epoch: 116
Loss: 0.06633126848755624
ROC train: 0.983603	val: 0.818978	test: 0.833545
PRC train: 0.807551	val: 0.403409	test: 0.421651

Epoch: 117
Loss: 0.06560787315791407
ROC train: 0.984215	val: 0.835427	test: 0.840533
PRC train: 0.812262	val: 0.405237	test: 0.392451

Epoch: 118
Loss: 0.06424549984000118
ROC train: 0.985360	val: 0.820044	test: 0.858710
PRC train: 0.823174	val: 0.385507	test: 0.408262

Epoch: 119
Loss: 0.06490320122718153
ROC train: 0.984626	val: 0.805131	test: 0.856036
PRC train: 0.822872	val: 0.392954	test: 0.435821

Epoch: 120
Loss: 0.06240699881534993
ROC train: 0.987427	val: 0.809818	test: 0.855450
PRC train: 0.837823	val: 0.381573	test: 0.411437

Epoch: 121
Loss: 0.06266795033428196
ROC train: 0.986391	val: 0.813680	test: 0.857451
PRC train: 0.822031	val: 0.399306	test: 0.427074

Epoch: 122
Loss: 0.06209230348200071
ROC train: 0.985338	val: 0.821080	test: 0.851237
PRC train: 0.825394	val: 0.413982	test: 0.401475

Epoch: 123
Loss: 0.06258415850601727
ROC train: 0.987851	val: 0.824174	test: 0.850787
PRC train: 0.834302	val: 0.384821	test: 0.414022

Epoch: 124
Loss: 0.0623852028351774
ROC train: 0.985334	val: 0.806999	test: 0.850431
PRC train: 0.822371	val: 0.389661	test: 0.401111

Epoch: 125
Loss: 0.06174069987581719
ROC train: 0.988165	val: 0.824308	test: 0.856574
PRC train: 0.843264	val: 0.403748	test: 0.427503

Epoch: 126
Loss: 0.0639103999617736
ROC train: 0.986122	val: 0.819248	test: 0.867084
PRC train: 0.835500	val: 0.421089	test: 0.430566

Epoch: 127
Loss: 0.060240694939549526
ROC train: 0.988810	val: 0.814297	test: 0.853998
PRC train: 0.848589	val: 0.400157	test: 0.418176

Epoch: 128
Loss: 0.06068769187862284
ROC train: 0.989076	val: 0.800480	test: 0.853586
PRC train: 0.853536	val: 0.390491	test: 0.431183

Epoch: 129
Loss: 0.059705571923889963
ROC train: 0.988298	val: 0.818939	test: 0.854240
PRC train: 0.843882	val: 0.388337	test: 0.426098

Epoch: 130
Loss: 0.06108063697831454
ROC train: 0.988189	val: 0.811509	test: 0.855800
PRC train: 0.846749	val: 0.401066	test: 0.429422

Epoch: 131
Loss: 0.059900672411078514
ROC train: 0.988512	val: 0.805672	test: 0.847317
PRC train: 0.845738	val: 0.398978	test: 0.414105

Epoch: 132
Loss: 0.060039697026524536
ROC train: 0.988716	val: 0.814691	test: 0.857234
PRC train: 0.854133	val: 0.407524	test: 0.411080

Epoch: 133
Loss: 0.062050906265171436
ROC train: 0.989406	val: 0.808553	test: 0.863761
PRC train: 0.848157	val: 0.387376	test: 0.431152

Epoch: 134
Loss: 0.060627062492609095
ROC train: 0.989769	val: 0.813795	test: 0.853657
PRC train: 0.847572	val: 0.388526	test: 0.426477

Epoch: 135
Loss: 0.060418400101144965
ROC train: 0.990040	val: 0.797700	test: 0.854216
PRC train: 0.865525	val: 0.383327	test: 0.429164

Epoch: 136
Loss: 0.0598373648500496
ROC train: 0.991185	val: 0.814521	test: 0.858091
PRC train: 0.868773	val: 0.395519	test: 0.436791

Epoch: 137
Loss: 0.05986946541598157
ROC train: 0.989415	val: 0.825451	test: 0.847269
PRC train: 0.855959	val: 0.408571	test: 0.410370

Epoch: 138
Loss: 0.05968938792362006
ROC train: 0.988143	val: 0.804730	test: 0.844163
PRC train: 0.836036	val: 0.365462	test: 0.414341

Epoch: 139
Loss: 0.0603365793151624
ROC train: 0.990644	val: 0.809783	test: 0.856249
PRC train: 0.862675	val: 0.398794	test: 0.450839

Epoch: 140
Loss: 0.05916020440676602
ROC train: 0.989844	val: 0.808104	test: 0.853202
PRC train: 0.855668	val: 0.392456	test: 0.409947

Epoch: 141
Loss: 0.05830888747061158
ROC train: 0.989824	val: 0.812248	test: 0.852432
PRC train: 0.857122	val: 0.379731	test: 0.406223

Epoch: 142
Loss: 0.058780523323817446
ROC train: 0.990389	val: 0.800816	test: 0.858353
PRC train: 0.866470	val: 0.385273	test: 0.434302

Epoch: 143
Loss: 0.05834397893187807
ROC train: 0.991350	val: 0.802450	test: 0.856154
PRC train: 0.872970	val: 0.389753	test: 0.416235

Epoch: 144
Loss: 0.05621791670437285
ROC train: 0.991570	val: 0.816501	test: 0.863426
PRC train: 0.876395	val: 0.403550	test: 0.412798

Epoch: 145
Loss: 0.0555506473690303
ROC train: 0.992257	val: 0.807945	test: 0.851010
PRC train: 0.877295	val: 0.398843	test: 0.408759

Epoch: 146
Loss: 0.0554730564421472
ROC train: 0.991025	val: 0.807184	test: 0.866139
PRC train: 0.860186	val: 0.392588	test: 0.425404

Epoch: 147
Loss: 0.05501549317662099
ROC train: 0.992074	val: 0.799891	test: 0.865220
PRC train: 0.877059	val: 0.380801	test: 0.398577

Epoch: 148
Loss: 0.055923149276241466
ROC train: 0.991634	val: 0.799874	test: 0.859133
PRC train: 0.873809	val: 0.368612	test: 0.377997

Epoch: 149
Loss: 0.05679975516591685
ROC train: 0.991539	val: 0.806275	test: 0.858387
PRC train: 0.879464	val: 0.391427	test: 0.416182

Epoch: 150
Loss: 0.05601525340215866
ROC train: 0.992107	val: 0.810699	test: 0.856406
PRC train: 0.877745	val: 0.372449	test: 0.412983

Epoch: 151
Loss: 0.05584423208500233
ROC train: 0.991879	val: 0.811141	test: 0.845472
PRC train: 0.873185	val: 0.381608	test: 0.421062

Epoch: 152
Loss: 0.05702120725268811
ROC train: 0.991528	val: 0.811402	test: 0.853652
PRC train: 0.871644	val: 0.386965	test: 0.432428

Early stopping
Best (ROC):	 train: 0.984215	val: 0.835427	test: 0.840533
Best (PRC):	 train: 0.812262	val: 0.405237	test: 0.392451
All runs completed.
