>>> Starting run for dataset: bace
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running RANDOM configs_split_experiments/GraphCL/bace/random/train_prop=0.6.yml on cuda:0
Running RANDOM configs_split_experiments/GraphCL/bace/random/train_prop=0.7.yml on cuda:1
Running RANDOM configs_split_experiments/GraphCL/bace/random/train_prop=0.8.yml on cuda:2
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.6.yml --runseed 1 --device cuda:0
Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.6.yml --runseed 2 --device cuda:0
Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.6.yml --runseed 3 --device cuda:0
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.7.yml --runseed 1 --device cuda:1
Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.7.yml --runseed 2 --device cuda:1
Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.7.yml --runseed 3 --device cuda:1
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.8.yml --runseed 1 --device cuda:2
Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.8.yml --runseed 2 --device cuda:2
Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.8.yml --runseed 3 --device cuda:2
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:0
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/random/train_prop=0.6/bace_random_3_20-05_14-43-16  ]
[ Using Seed :  3  ]
[ Using device :  cuda:0  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
randomly split
Data(edge_attr=[78, 2], edge_index=[2, 78], id=[1], x=[37, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6900256976227612
ROC train: 0.665234	val: 0.616941	test: 0.622679
PRC train: 0.609153	val: 0.577036	test: 0.558250

Epoch: 2
Loss: 0.657148793442655
ROC train: 0.736845	val: 0.683388	test: 0.696905
PRC train: 0.684286	val: 0.637925	test: 0.618521

Epoch: 3
Loss: 0.6306879770503834
ROC train: 0.781406	val: 0.729471	test: 0.739876
PRC train: 0.749867	val: 0.696624	test: 0.687901

Epoch: 4
Loss: 0.6005826908965173
ROC train: 0.808672	val: 0.746061	test: 0.749027
PRC train: 0.774744	val: 0.704028	test: 0.674836

Epoch: 5
Loss: 0.5696438649135722
ROC train: 0.828951	val: 0.760413	test: 0.770778
PRC train: 0.792985	val: 0.714338	test: 0.688689

Epoch: 6
Loss: 0.5489516640472041
ROC train: 0.844178	val: 0.768312	test: 0.799337
PRC train: 0.803862	val: 0.719751	test: 0.708561

Epoch: 7
Loss: 0.5298810011532016
ROC train: 0.859063	val: 0.776169	test: 0.802476
PRC train: 0.826203	val: 0.730973	test: 0.710960

Epoch: 8
Loss: 0.5115071572972274
ROC train: 0.873659	val: 0.777529	test: 0.812069
PRC train: 0.844561	val: 0.733446	test: 0.713445

Epoch: 9
Loss: 0.4732001411621761
ROC train: 0.884986	val: 0.781347	test: 0.819054
PRC train: 0.858434	val: 0.741953	test: 0.730961

Epoch: 10
Loss: 0.47731175958664096
ROC train: 0.893595	val: 0.788150	test: 0.822149
PRC train: 0.868432	val: 0.750767	test: 0.745318

Epoch: 11
Loss: 0.4665558812640801
ROC train: 0.898872	val: 0.797191	test: 0.825950
PRC train: 0.877421	val: 0.767993	test: 0.749538

Epoch: 12
Loss: 0.4528437980280598
ROC train: 0.904413	val: 0.806408	test: 0.828382
PRC train: 0.882955	val: 0.778245	test: 0.754177

Epoch: 13
Loss: 0.4483062404382334
ROC train: 0.908266	val: 0.810753	test: 0.825774
PRC train: 0.886316	val: 0.779235	test: 0.747814

Epoch: 14
Loss: 0.44236026490129965
ROC train: 0.908974	val: 0.813386	test: 0.823563
PRC train: 0.884418	val: 0.774011	test: 0.743076

Epoch: 15
Loss: 0.44370265329229347
ROC train: 0.909538	val: 0.808822	test: 0.820645
PRC train: 0.886877	val: 0.768123	test: 0.733658

Epoch: 16
Loss: 0.44444017336539915
ROC train: 0.910839	val: 0.808734	test: 0.820601
PRC train: 0.888468	val: 0.774040	test: 0.730384

Epoch: 17
Loss: 0.4203335983755424
ROC train: 0.915192	val: 0.811982	test: 0.825553
PRC train: 0.894025	val: 0.778164	test: 0.737517

Epoch: 18
Loss: 0.4138095670512294
ROC train: 0.912678	val: 0.812420	test: 0.827409
PRC train: 0.892368	val: 0.777451	test: 0.742147

Epoch: 19
Loss: 0.3990263722066136
ROC train: 0.915760	val: 0.814571	test: 0.830460
PRC train: 0.898737	val: 0.784485	test: 0.745389

Epoch: 20
Loss: 0.40766309359130887
ROC train: 0.921262	val: 0.818784	test: 0.830504
PRC train: 0.905424	val: 0.791389	test: 0.747433

Epoch: 21
Loss: 0.4099081481028261
ROC train: 0.925314	val: 0.818784	test: 0.831742
PRC train: 0.910487	val: 0.786357	test: 0.751924

Epoch: 22
Loss: 0.3963806248376963
ROC train: 0.928810	val: 0.816985	test: 0.834615
PRC train: 0.913605	val: 0.772095	test: 0.757250

Epoch: 23
Loss: 0.3635569930769794
ROC train: 0.928563	val: 0.815888	test: 0.833687
PRC train: 0.912227	val: 0.777507	test: 0.760914

Epoch: 24
Loss: 0.38283777654262
ROC train: 0.930679	val: 0.814790	test: 0.834306
PRC train: 0.914427	val: 0.775948	test: 0.764820

Epoch: 25
Loss: 0.36067352144785275
ROC train: 0.935464	val: 0.815361	test: 0.838771
PRC train: 0.920673	val: 0.770704	test: 0.770687

Epoch: 26
Loss: 0.3620295325150636
ROC train: 0.936931	val: 0.808339	test: 0.835323
PRC train: 0.923099	val: 0.755285	test: 0.763625

Epoch: 27
Loss: 0.387755492473275
ROC train: 0.939121	val: 0.812859	test: 0.836428
PRC train: 0.927045	val: 0.772462	test: 0.759927

Epoch: 28
Loss: 0.36702225181188014
ROC train: 0.936669	val: 0.814220	test: 0.837622
PRC train: 0.923539	val: 0.775824	test: 0.759498

Epoch: 29
Loss: 0.3728155207305364
ROC train: 0.938080	val: 0.819355	test: 0.839965
PRC train: 0.924345	val: 0.776464	test: 0.760182

Epoch: 30
Loss: 0.34516968903204676
ROC train: 0.942313	val: 0.822208	test: 0.837312
PRC train: 0.930334	val: 0.780071	test: 0.756305

Epoch: 31
Loss: 0.35811188243652553
ROC train: 0.944133	val: 0.818170	test: 0.835323
PRC train: 0.932489	val: 0.779814	test: 0.752934

Epoch: 32
Loss: 0.35183321805024753
ROC train: 0.943487	val: 0.814395	test: 0.832493
PRC train: 0.931079	val: 0.777688	test: 0.754622

Epoch: 33
Loss: 0.3558432342562241
ROC train: 0.945927	val: 0.820101	test: 0.838329Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:0
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/random/train_prop=0.6/bace_random_1_20-05_14-43-16  ]
[ Using Seed :  1  ]
[ Using device :  cuda:0  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
randomly split
Data(edge_attr=[78, 2], edge_index=[2, 78], id=[1], x=[37, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6905137286769084
ROC train: 0.653112	val: 0.622822	test: 0.630239
PRC train: 0.593095	val: 0.601525	test: 0.536508

Epoch: 2
Loss: 0.6460683757222159
ROC train: 0.710951	val: 0.706122	test: 0.713528
PRC train: 0.669573	val: 0.671147	test: 0.621064

Epoch: 3
Loss: 0.6321181108943706
ROC train: 0.771509	val: 0.737898	test: 0.743192
PRC train: 0.735947	val: 0.682346	test: 0.657193

Epoch: 4
Loss: 0.5893978072533663
ROC train: 0.826648	val: 0.752820	test: 0.782272
PRC train: 0.785938	val: 0.690614	test: 0.700234

Epoch: 5
Loss: 0.5669021043043053
ROC train: 0.840685	val: 0.754312	test: 0.802697
PRC train: 0.785016	val: 0.676740	test: 0.695010

Epoch: 6
Loss: 0.5381137011813751
ROC train: 0.859259	val: 0.764406	test: 0.811008
PRC train: 0.807123	val: 0.690426	test: 0.709076

Epoch: 7
Loss: 0.5379203395405137
ROC train: 0.871344	val: 0.773491	test: 0.805172
PRC train: 0.817123	val: 0.696063	test: 0.686600

Epoch: 8
Loss: 0.5165368769970096
ROC train: 0.876917	val: 0.778012	test: 0.804863
PRC train: 0.827621	val: 0.708691	test: 0.687117

Epoch: 9
Loss: 0.4849264658223085
ROC train: 0.879680	val: 0.776125	test: 0.807692
PRC train: 0.833735	val: 0.718267	test: 0.705214

Epoch: 10
Loss: 0.4796182236152057
ROC train: 0.888137	val: 0.780513	test: 0.813484
PRC train: 0.842463	val: 0.730807	test: 0.722896

Epoch: 11
Loss: 0.458507053376221
ROC train: 0.894785	val: 0.788852	test: 0.814677
PRC train: 0.853785	val: 0.747065	test: 0.739902

Epoch: 12
Loss: 0.4505018691084571
ROC train: 0.900736	val: 0.803511	test: 0.817551
PRC train: 0.863701	val: 0.765198	test: 0.746117

Epoch: 13
Loss: 0.4517166937929041
ROC train: 0.903614	val: 0.802941	test: 0.817639
PRC train: 0.870235	val: 0.762023	test: 0.746026

Epoch: 14
Loss: 0.44995560755886
ROC train: 0.902620	val: 0.800219	test: 0.814943
PRC train: 0.872264	val: 0.769111	test: 0.747518

Epoch: 15
Loss: 0.43767468524042535
ROC train: 0.905510	val: 0.799912	test: 0.820911
PRC train: 0.876701	val: 0.760781	test: 0.752138

Epoch: 16
Loss: 0.4194482978866586
ROC train: 0.909582	val: 0.793329	test: 0.824713
PRC train: 0.878090	val: 0.741731	test: 0.751991

Epoch: 17
Loss: 0.42325545741373155
ROC train: 0.912441	val: 0.795216	test: 0.819098
PRC train: 0.883477	val: 0.750188	test: 0.744667

Epoch: 18
Loss: 0.40941555138022195
ROC train: 0.915834	val: 0.803336	test: 0.817286
PRC train: 0.886084	val: 0.766453	test: 0.744752

Epoch: 19
Loss: 0.39728551256696365
ROC train: 0.918773	val: 0.809480	test: 0.818347
PRC train: 0.891123	val: 0.778706	test: 0.746894

Epoch: 20
Loss: 0.40725322682825443
ROC train: 0.921777	val: 0.810884	test: 0.824624
PRC train: 0.897064	val: 0.773266	test: 0.750314

Epoch: 21
Loss: 0.4064763110304178
ROC train: 0.924932	val: 0.813079	test: 0.828780
PRC train: 0.901065	val: 0.774951	test: 0.755663

Epoch: 22
Loss: 0.38972314176335304
ROC train: 0.930819	val: 0.810050	test: 0.827100
PRC train: 0.908788	val: 0.771577	test: 0.756174

Epoch: 23
Loss: 0.3865062128794204
ROC train: 0.929912	val: 0.804521	test: 0.821972
PRC train: 0.907339	val: 0.768353	test: 0.754473

Epoch: 24
Loss: 0.3922615089655431
ROC train: 0.930890	val: 0.810270	test: 0.821530
PRC train: 0.908464	val: 0.779443	test: 0.754258

Epoch: 25
Loss: 0.394238187541285
ROC train: 0.932063	val: 0.814790	test: 0.823475
PRC train: 0.910707	val: 0.787710	test: 0.756484

Epoch: 26
Loss: 0.38703294672379124
ROC train: 0.936703	val: 0.813123	test: 0.827586
PRC train: 0.916372	val: 0.778144	test: 0.764526

Epoch: 27
Loss: 0.36550246129501507
ROC train: 0.937299	val: 0.807505	test: 0.822944
PRC train: 0.917388	val: 0.771400	test: 0.758807

Epoch: 28
Loss: 0.37304219345649187
ROC train: 0.940116	val: 0.811367	test: 0.825729
PRC train: 0.922263	val: 0.779559	test: 0.757064

Epoch: 29
Loss: 0.3835878353310076
ROC train: 0.941909	val: 0.812420	test: 0.826790
PRC train: 0.925298	val: 0.778933	test: 0.757676

Epoch: 30
Loss: 0.3640242477437444
ROC train: 0.942144	val: 0.813649	test: 0.826083
PRC train: 0.926065	val: 0.781313	test: 0.753770

Epoch: 31
Loss: 0.35880847530937354
ROC train: 0.946056	val: 0.814308	test: 0.825420
PRC train: 0.930534	val: 0.780847	test: 0.753190

Epoch: 32
Loss: 0.3585014605538406
ROC train: 0.942933	val: 0.808822	test: 0.820469
PRC train: 0.927654	val: 0.777965	test: 0.747209

Epoch: 33
Loss: 0.36454507687252957
ROC train: 0.948278	val: 0.807812	test: 0.826614Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:0
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/random/train_prop=0.6/bace_random_2_20-05_14-43-16  ]
[ Using Seed :  2  ]
[ Using device :  cuda:0  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
randomly split
Data(edge_attr=[78, 2], edge_index=[2, 78], id=[1], x=[37, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6849963948106971
ROC train: 0.664935	val: 0.660127	test: 0.641512
PRC train: 0.603181	val: 0.624216	test: 0.568444

Epoch: 2
Loss: 0.6498497978704205
ROC train: 0.746739	val: 0.716348	test: 0.725464
PRC train: 0.671502	val: 0.674377	test: 0.619308

Epoch: 3
Loss: 0.6352919256068549
ROC train: 0.788868	val: 0.745315	test: 0.770557
PRC train: 0.727552	val: 0.679923	test: 0.656920

Epoch: 4
Loss: 0.6000541184493896
ROC train: 0.817383	val: 0.768839	test: 0.783024
PRC train: 0.766027	val: 0.697023	test: 0.660155

Epoch: 5
Loss: 0.581867029719433
ROC train: 0.829431	val: 0.778626	test: 0.800354
PRC train: 0.777868	val: 0.706354	test: 0.691060

Epoch: 6
Loss: 0.5434564790570846
ROC train: 0.847794	val: 0.784639	test: 0.810256
PRC train: 0.799831	val: 0.715359	test: 0.705325

Epoch: 7
Loss: 0.5238030906647806
ROC train: 0.863801	val: 0.794777	test: 0.808842
PRC train: 0.821916	val: 0.731563	test: 0.697024

Epoch: 8
Loss: 0.4883127829911275
ROC train: 0.874386	val: 0.789818	test: 0.811671
PRC train: 0.832341	val: 0.730329	test: 0.701798

Epoch: 9
Loss: 0.482288319556534
ROC train: 0.882076	val: 0.791486	test: 0.810964
PRC train: 0.845920	val: 0.742255	test: 0.707188

Epoch: 10
Loss: 0.4806824622948753
ROC train: 0.888948	val: 0.792188	test: 0.809505
PRC train: 0.855237	val: 0.747548	test: 0.710073

Epoch: 11
Loss: 0.44614088257104134
ROC train: 0.894403	val: 0.794163	test: 0.805880
PRC train: 0.864306	val: 0.753472	test: 0.709491

Epoch: 12
Loss: 0.4529949375343046
ROC train: 0.900582	val: 0.801580	test: 0.815164
PRC train: 0.868732	val: 0.758567	test: 0.728747

Epoch: 13
Loss: 0.43254709179718054
ROC train: 0.905770	val: 0.810314	test: 0.823298
PRC train: 0.875143	val: 0.766430	test: 0.742468

Epoch: 14
Loss: 0.4465973561870733
ROC train: 0.905251	val: 0.811455	test: 0.826614
PRC train: 0.877779	val: 0.767458	test: 0.745874

Epoch: 15
Loss: 0.4413492261722327
ROC train: 0.907343	val: 0.811806	test: 0.825243
PRC train: 0.883329	val: 0.765558	test: 0.737016

Epoch: 16
Loss: 0.4412469220503498
ROC train: 0.910645	val: 0.811279	test: 0.820203
PRC train: 0.888693	val: 0.763194	test: 0.727835

Epoch: 17
Loss: 0.42413493316445267
ROC train: 0.913749	val: 0.812815	test: 0.816490
PRC train: 0.891899	val: 0.772829	test: 0.735013

Epoch: 18
Loss: 0.41024346743181694
ROC train: 0.918195	val: 0.818082	test: 0.822900
PRC train: 0.895629	val: 0.781268	test: 0.747976

Epoch: 19
Loss: 0.4129510378795202
ROC train: 0.921613	val: 0.820233	test: 0.828338
PRC train: 0.898898	val: 0.787034	test: 0.753414

Epoch: 20
Loss: 0.4142356114202893
ROC train: 0.923835	val: 0.819355	test: 0.834129
PRC train: 0.899671	val: 0.783432	test: 0.761348

Epoch: 21
Loss: 0.39433750401626055
ROC train: 0.924285	val: 0.818433	test: 0.836030
PRC train: 0.899133	val: 0.783224	test: 0.762824

Epoch: 22
Loss: 0.3949477240828053
ROC train: 0.925917	val: 0.815888	test: 0.833775
PRC train: 0.902389	val: 0.779835	test: 0.758492

Epoch: 23
Loss: 0.3726348881771703
ROC train: 0.928193	val: 0.818082	test: 0.834085
PRC train: 0.907887	val: 0.783774	test: 0.760478

Epoch: 24
Loss: 0.3726268974382265
ROC train: 0.934214	val: 0.824139	test: 0.837577
PRC train: 0.915572	val: 0.786098	test: 0.766953

Epoch: 25
Loss: 0.3808106479937093
ROC train: 0.936113	val: 0.826289	test: 0.841026
PRC train: 0.917942	val: 0.786249	test: 0.764001

Epoch: 26
Loss: 0.36381317456715984
ROC train: 0.941867	val: 0.825499	test: 0.840186
PRC train: 0.924170	val: 0.790010	test: 0.762509

Epoch: 27
Loss: 0.3557977216241555
ROC train: 0.941012	val: 0.821374	test: 0.835013
PRC train: 0.922769	val: 0.788787	test: 0.760297

Epoch: 28
Loss: 0.3694350079085085
ROC train: 0.944611	val: 0.826377	test: 0.834660
PRC train: 0.928138	val: 0.803656	test: 0.760716

Epoch: 29
Loss: 0.37161916796182226
ROC train: 0.945001	val: 0.827343	test: 0.835942
PRC train: 0.929964	val: 0.808818	test: 0.766234

Epoch: 30
Loss: 0.3762367325686714
ROC train: 0.945731	val: 0.826991	test: 0.837224
PRC train: 0.930751	val: 0.801428	test: 0.762709

Epoch: 31
Loss: 0.37744256201037846
ROC train: 0.945939	val: 0.820891	test: 0.834394
PRC train: 0.930908	val: 0.792668	test: 0.761581

Epoch: 32
Loss: 0.35983790039499364
ROC train: 0.944327	val: 0.817599	test: 0.831653
PRC train: 0.930178	val: 0.792726	test: 0.762646

Epoch: 33
Loss: 0.3614856239762923
ROC train: 0.946725	val: 0.822778	test: 0.832980Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:1
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/random/train_prop=0.7/bace_random_1_20-05_14-43-16  ]
[ Using Seed :  1  ]
[ Using device :  cuda:1  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
randomly split
Data(edge_attr=[78, 2], edge_index=[2, 78], id=[1], x=[37, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6884677263725344
ROC train: 0.691453	val: 0.617237	test: 0.682389
PRC train: 0.616333	val: 0.573695	test: 0.616817

Epoch: 2
Loss: 0.650346668165802
ROC train: 0.733958	val: 0.686738	test: 0.740859
PRC train: 0.672292	val: 0.653156	test: 0.676662

Epoch: 3
Loss: 0.6317043197246444
ROC train: 0.787638	val: 0.718772	test: 0.812271
PRC train: 0.731984	val: 0.654074	test: 0.759550

Epoch: 4
Loss: 0.6044154209857515
ROC train: 0.809122	val: 0.729791	test: 0.845092
PRC train: 0.736097	val: 0.634793	test: 0.772702

Epoch: 5
Loss: 0.577567918855082
ROC train: 0.823769	val: 0.728296	test: 0.822796
PRC train: 0.769436	val: 0.639913	test: 0.751471

Epoch: 6
Loss: 0.5505512507774506
ROC train: 0.832068	val: 0.745376	test: 0.817105
PRC train: 0.784289	val: 0.672081	test: 0.756072

Epoch: 7
Loss: 0.5286697014671784
ROC train: 0.851880	val: 0.767100	test: 0.843221
PRC train: 0.799353	val: 0.696927	test: 0.780100

Epoch: 8
Loss: 0.5178698420556156
ROC train: 0.854452	val: 0.771822	test: 0.849536
PRC train: 0.802224	val: 0.698483	test: 0.770240

Epoch: 9
Loss: 0.5105542266890538
ROC train: 0.860575	val: 0.771980	test: 0.851719
PRC train: 0.798251	val: 0.694373	test: 0.761344

Epoch: 10
Loss: 0.5127096020317534
ROC train: 0.867659	val: 0.775128	test: 0.854604
PRC train: 0.819101	val: 0.711208	test: 0.777576

Epoch: 11
Loss: 0.5012218599501599
ROC train: 0.870155	val: 0.766470	test: 0.848990
PRC train: 0.828554	val: 0.706205	test: 0.781552

Epoch: 12
Loss: 0.4694862567318864
ROC train: 0.873824	val: 0.774813	test: 0.867233
PRC train: 0.822956	val: 0.711874	test: 0.818778

Epoch: 13
Loss: 0.48156932072013187
ROC train: 0.872914	val: 0.786777	test: 0.873314
PRC train: 0.819083	val: 0.722269	test: 0.831070

Epoch: 14
Loss: 0.4611401949338897
ROC train: 0.882954	val: 0.780716	test: 0.848912
PRC train: 0.841567	val: 0.740316	test: 0.793830

Epoch: 15
Loss: 0.4817007586662827
ROC train: 0.888155	val: 0.775521	test: 0.841974
PRC train: 0.852478	val: 0.734052	test: 0.768105

Epoch: 16
Loss: 0.4810745359674488
ROC train: 0.893511	val: 0.789217	test: 0.851017
PRC train: 0.863257	val: 0.757424	test: 0.785969

Epoch: 17
Loss: 0.44072227362034766
ROC train: 0.893726	val: 0.793703	test: 0.864738
PRC train: 0.863488	val: 0.762525	test: 0.808289

Epoch: 18
Loss: 0.4456779228558787
ROC train: 0.891690	val: 0.791106	test: 0.863413
PRC train: 0.858497	val: 0.757012	test: 0.810715

Epoch: 19
Loss: 0.45202882363787944
ROC train: 0.890668	val: 0.795199	test: 0.864816
PRC train: 0.857635	val: 0.751546	test: 0.814754

Epoch: 20
Loss: 0.41419680041253865
ROC train: 0.891848	val: 0.791027	test: 0.861854
PRC train: 0.860528	val: 0.752890	test: 0.811968

Epoch: 21
Loss: 0.4427988688079646
ROC train: 0.897791	val: 0.799843	test: 0.866765
PRC train: 0.867885	val: 0.764597	test: 0.811009

Epoch: 22
Loss: 0.4427065518980494
ROC train: 0.900566	val: 0.801338	test: 0.865596
PRC train: 0.870987	val: 0.761846	test: 0.813519

Epoch: 23
Loss: 0.45705698693392594
ROC train: 0.907743	val: 0.802046	test: 0.862400
PRC train: 0.880167	val: 0.758008	test: 0.802937

Epoch: 24
Loss: 0.42138761078070797
ROC train: 0.907488	val: 0.797796	test: 0.853512
PRC train: 0.879650	val: 0.762696	test: 0.783636

Epoch: 25
Loss: 0.42312987598261537
ROC train: 0.909880	val: 0.798505	test: 0.862634
PRC train: 0.882576	val: 0.768541	test: 0.797920

Epoch: 26
Loss: 0.4027466495716256
ROC train: 0.911672	val: 0.798898	test: 0.866532
PRC train: 0.890509	val: 0.764312	test: 0.807304

Epoch: 27
Loss: 0.43815615763581944
ROC train: 0.915994	val: 0.796537	test: 0.855929
PRC train: 0.895961	val: 0.764510	test: 0.784745

Epoch: 28
Loss: 0.39500283507670986
ROC train: 0.918084	val: 0.796930	test: 0.862867
PRC train: 0.898199	val: 0.766655	test: 0.785920

Epoch: 29
Loss: 0.37458668776294185
ROC train: 0.916058	val: 0.796301	test: 0.875497
PRC train: 0.895314	val: 0.759051	test: 0.805045

Epoch: 30
Loss: 0.38145725333664837
ROC train: 0.919668	val: 0.796301	test: 0.872768
PRC train: 0.897448	val: 0.752782	test: 0.805631

Epoch: 31
Loss: 0.4157140723303037
ROC train: 0.924487	val: 0.798662	test: 0.865284
PRC train: 0.904977	val: 0.753870	test: 0.796847

Epoch: 32
Loss: 0.42458215542778993
ROC train: 0.921504	val: 0.794963	test: 0.862010
PRC train: 0.902994	val: 0.753496	test: 0.792062

Epoch: 33
Loss: 0.4009086240346518
ROC train: 0.923609	val: 0.797324	test: 0.863491Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:1
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/random/train_prop=0.7/bace_random_3_20-05_14-43-16  ]
[ Using Seed :  3  ]
[ Using device :  cuda:1  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
randomly split
Data(edge_attr=[78, 2], edge_index=[2, 78], id=[1], x=[37, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.691278447719913
ROC train: 0.659652	val: 0.584494	test: 0.637795
PRC train: 0.575341	val: 0.550912	test: 0.557249

Epoch: 2
Loss: 0.6631499643984404
ROC train: 0.727564	val: 0.664856	test: 0.710610
PRC train: 0.669622	val: 0.644738	test: 0.651514

Epoch: 3
Loss: 0.6205033317743348
ROC train: 0.753520	val: 0.708776	test: 0.742029
PRC train: 0.699567	val: 0.670418	test: 0.700556

Epoch: 4
Loss: 0.6100640097449557
ROC train: 0.770439	val: 0.723337	test: 0.756139
PRC train: 0.716943	val: 0.687617	test: 0.722732

Epoch: 5
Loss: 0.5908156510436197
ROC train: 0.799046	val: 0.752774	test: 0.792157
PRC train: 0.746741	val: 0.712434	test: 0.759033

Epoch: 6
Loss: 0.5733237274225182
ROC train: 0.819525	val: 0.760488	test: 0.814844
PRC train: 0.775635	val: 0.720726	test: 0.760854

Epoch: 7
Loss: 0.5500169307466672
ROC train: 0.838477	val: 0.762141	test: 0.819833
PRC train: 0.799804	val: 0.735114	test: 0.760832

Epoch: 8
Loss: 0.5052607246537827
ROC train: 0.848698	val: 0.762771	test: 0.819599
PRC train: 0.812627	val: 0.737770	test: 0.765970

Epoch: 9
Loss: 0.5046072325528941
ROC train: 0.860794	val: 0.775679	test: 0.835425
PRC train: 0.826878	val: 0.752327	test: 0.779598

Epoch: 10
Loss: 0.49467301209713604
ROC train: 0.867677	val: 0.787721	test: 0.840259
PRC train: 0.833171	val: 0.760971	test: 0.775451

Epoch: 11
Loss: 0.4966565439232736
ROC train: 0.872842	val: 0.785518	test: 0.839791
PRC train: 0.843817	val: 0.754348	test: 0.773580

Epoch: 12
Loss: 0.47516329449026856
ROC train: 0.882049	val: 0.788430	test: 0.845872
PRC train: 0.854668	val: 0.748827	test: 0.777311

Epoch: 13
Loss: 0.44908559489690114
ROC train: 0.882792	val: 0.795986	test: 0.861620
PRC train: 0.855908	val: 0.756913	test: 0.801964

Epoch: 14
Loss: 0.4454510894287441
ROC train: 0.886375	val: 0.795435	test: 0.863101
PRC train: 0.860201	val: 0.754789	test: 0.797602

Epoch: 15
Loss: 0.4580566672825041
ROC train: 0.889416	val: 0.795671	test: 0.865284
PRC train: 0.862176	val: 0.760439	test: 0.795385

Epoch: 16
Loss: 0.4643293007216707
ROC train: 0.891839	val: 0.795750	test: 0.864738
PRC train: 0.866712	val: 0.764666	test: 0.796110

Epoch: 17
Loss: 0.451453003088307
ROC train: 0.894878	val: 0.786934	test: 0.847119
PRC train: 0.874482	val: 0.755867	test: 0.780040

Epoch: 18
Loss: 0.4320365322268732
ROC train: 0.900648	val: 0.794726	test: 0.851017
PRC train: 0.879383	val: 0.763134	test: 0.779912

Epoch: 19
Loss: 0.4378273008198338
ROC train: 0.897940	val: 0.804329	test: 0.859281
PRC train: 0.874984	val: 0.772299	test: 0.781113

Epoch: 20
Loss: 0.4274153403533112
ROC train: 0.900842	val: 0.798268	test: 0.860373
PRC train: 0.877302	val: 0.768254	test: 0.774627

Epoch: 21
Loss: 0.41495974834941485
ROC train: 0.907831	val: 0.797875	test: 0.861542
PRC train: 0.887199	val: 0.767926	test: 0.776862

Epoch: 22
Loss: 0.5067819532028175
ROC train: 0.906557	val: 0.799134	test: 0.859749
PRC train: 0.886321	val: 0.759847	test: 0.770045

Epoch: 23
Loss: 0.4109207975486672
ROC train: 0.910193	val: 0.811885	test: 0.872534
PRC train: 0.889819	val: 0.779469	test: 0.784585

Epoch: 24
Loss: 0.42642230348300936
ROC train: 0.908982	val: 0.813617	test: 0.870897
PRC train: 0.886105	val: 0.781708	test: 0.780360

Epoch: 25
Loss: 0.44664936075287615
ROC train: 0.910735	val: 0.810626	test: 0.864505
PRC train: 0.888752	val: 0.778566	test: 0.771398

Epoch: 26
Loss: 0.4463960181044639
ROC train: 0.915811	val: 0.806612	test: 0.868559
PRC train: 0.895276	val: 0.773272	test: 0.774834

Epoch: 27
Loss: 0.42448623487267245
ROC train: 0.915811	val: 0.809052	test: 0.873704
PRC train: 0.896568	val: 0.773187	test: 0.779327

Epoch: 28
Loss: 0.4063052415310063
ROC train: 0.909007	val: 0.806848	test: 0.873470
PRC train: 0.888612	val: 0.783726	test: 0.782708

Epoch: 29
Loss: 0.3924620572958439
ROC train: 0.913106	val: 0.804172	test: 0.867311
PRC train: 0.893264	val: 0.785754	test: 0.786961

Epoch: 30
Loss: 0.44168620552614424
ROC train: 0.919941	val: 0.802755	test: 0.857020
PRC train: 0.904879	val: 0.785341	test: 0.772188

Epoch: 31
Loss: 0.4155644151637935
ROC train: 0.917966	val: 0.813538	test: 0.851407
PRC train: 0.904450	val: 0.796163	test: 0.763014

Epoch: 32
Loss: 0.400638569701451
ROC train: 0.920484	val: 0.816686	test: 0.859905
PRC train: 0.908234	val: 0.797698	test: 0.769354

Epoch: 33
Loss: 0.42705312204206197
ROC train: 0.924855	val: 0.815033	test: 0.863179Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:1
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/random/train_prop=0.7/bace_random_2_20-05_14-43-16  ]
[ Using Seed :  2  ]
[ Using device :  cuda:1  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
randomly split
Data(edge_attr=[78, 2], edge_index=[2, 78], id=[1], x=[37, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6861991685967037
ROC train: 0.664923	val: 0.607792	test: 0.652140
PRC train: 0.593567	val: 0.553775	test: 0.620661

Epoch: 2
Loss: 0.6484536596865274
ROC train: 0.733839	val: 0.668949	test: 0.737273
PRC train: 0.655668	val: 0.596073	test: 0.685750

Epoch: 3
Loss: 0.6286995460349825
ROC train: 0.782077	val: 0.724439	test: 0.784361
PRC train: 0.703127	val: 0.650653	test: 0.719803

Epoch: 4
Loss: 0.6179353501209502
ROC train: 0.812562	val: 0.745848	test: 0.818586
PRC train: 0.746121	val: 0.669318	test: 0.743324

Epoch: 5
Loss: 0.5547287391732751
ROC train: 0.822671	val: 0.750728	test: 0.828409
PRC train: 0.764484	val: 0.677100	test: 0.742417

Epoch: 6
Loss: 0.5329567278364584
ROC train: 0.838135	val: 0.754900	test: 0.833944
PRC train: 0.787010	val: 0.673596	test: 0.734119

Epoch: 7
Loss: 0.5355804316336352
ROC train: 0.839590	val: 0.746320	test: 0.829110
PRC train: 0.786243	val: 0.662043	test: 0.728087

Epoch: 8
Loss: 0.5096806363884975
ROC train: 0.851509	val: 0.751830	test: 0.832853
PRC train: 0.800276	val: 0.665702	test: 0.740849

Epoch: 9
Loss: 0.49571464227672946
ROC train: 0.857472	val: 0.768123	test: 0.849146
PRC train: 0.804792	val: 0.682717	test: 0.766169

Epoch: 10
Loss: 0.5202537545895621
ROC train: 0.868875	val: 0.781267	test: 0.856397
PRC train: 0.823478	val: 0.715347	test: 0.778104

Epoch: 11
Loss: 0.4704171014374962
ROC train: 0.867098	val: 0.773554	test: 0.839323
PRC train: 0.834077	val: 0.726714	test: 0.740693

Epoch: 12
Loss: 0.4554677322374066
ROC train: 0.879645	val: 0.785124	test: 0.853746
PRC train: 0.852347	val: 0.736131	test: 0.759650

Epoch: 13
Loss: 0.46145758115850627
ROC train: 0.881413	val: 0.790397	test: 0.862711
PRC train: 0.852717	val: 0.740965	test: 0.782003

Epoch: 14
Loss: 0.4546894022662994
ROC train: 0.883733	val: 0.786462	test: 0.852031
PRC train: 0.857591	val: 0.745401	test: 0.774239

Epoch: 15
Loss: 0.44839945861082076
ROC train: 0.885712	val: 0.790634	test: 0.854292
PRC train: 0.857550	val: 0.749208	test: 0.780436

Epoch: 16
Loss: 0.4616367959275095
ROC train: 0.891912	val: 0.797009	test: 0.861854
PRC train: 0.862802	val: 0.755960	test: 0.789883

Epoch: 17
Loss: 0.44982467050942965
ROC train: 0.896185	val: 0.798190	test: 0.857800
PRC train: 0.871984	val: 0.760089	test: 0.787023

Epoch: 18
Loss: 0.46069575656993245
ROC train: 0.902570	val: 0.791342	test: 0.842676
PRC train: 0.877372	val: 0.754798	test: 0.767322

Epoch: 19
Loss: 0.41444800445092617
ROC train: 0.899122	val: 0.785596	test: 0.837764
PRC train: 0.872073	val: 0.746588	test: 0.744299

Epoch: 20
Loss: 0.447600670625075
ROC train: 0.904891	val: 0.801338	test: 0.855773
PRC train: 0.881449	val: 0.766175	test: 0.776182

Epoch: 21
Loss: 0.4569833513802015
ROC train: 0.900383	val: 0.801889	test: 0.855851
PRC train: 0.877632	val: 0.773022	test: 0.773420

Epoch: 22
Loss: 0.42466145091460133
ROC train: 0.903332	val: 0.801889	test: 0.862478
PRC train: 0.880404	val: 0.778607	test: 0.782574

Epoch: 23
Loss: 0.43698066960872667
ROC train: 0.908669	val: 0.810390	test: 0.865362
PRC train: 0.884790	val: 0.787125	test: 0.783919

Epoch: 24
Loss: 0.4635832939585411
ROC train: 0.912989	val: 0.809917	test: 0.868169
PRC train: 0.888373	val: 0.782765	test: 0.783990

Epoch: 25
Loss: 0.42971885110358327
ROC train: 0.910351	val: 0.803542	test: 0.870352
PRC train: 0.883635	val: 0.777848	test: 0.785084

Epoch: 26
Loss: 0.4278255980366813
ROC train: 0.899125	val: 0.803384	test: 0.869338
PRC train: 0.872582	val: 0.775033	test: 0.791005

Epoch: 27
Loss: 0.43205565003238966
ROC train: 0.901751	val: 0.805116	test: 0.870196
PRC train: 0.875675	val: 0.775802	test: 0.794846

Epoch: 28
Loss: 0.390669988094106
ROC train: 0.911624	val: 0.807163	test: 0.861932
PRC train: 0.887079	val: 0.779311	test: 0.780659

Epoch: 29
Loss: 0.3898425831807889
ROC train: 0.915703	val: 0.807320	test: 0.863647
PRC train: 0.894218	val: 0.781904	test: 0.783607

Epoch: 30
Loss: 0.39741360637018575
ROC train: 0.918659	val: 0.809917	test: 0.864349
PRC train: 0.900273	val: 0.789437	test: 0.784963

Epoch: 31
Loss: 0.3841585218310716
ROC train: 0.921019	val: 0.807950	test: 0.873158
PRC train: 0.902555	val: 0.789980	test: 0.808683

Epoch: 32
Loss: 0.3845377592846363
ROC train: 0.923120	val: 0.800551	test: 0.874639
PRC train: 0.903555	val: 0.783980	test: 0.811088

Epoch: 33
Loss: 0.4006730533960236
ROC train: 0.922513	val: 0.798190	test: 0.861698Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:2
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/random/train_prop=0.8/bace_random_1_20-05_14-43-16  ]
[ Using Seed :  1  ]
[ Using device :  cuda:2  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
randomly split
Data(edge_attr=[78, 2], edge_index=[2, 78], id=[1], x=[37, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6911889675414555
ROC train: 0.676454	val: 0.662740	test: 0.661590
PRC train: 0.627102	val: 0.585347	test: 0.618863

Epoch: 2
Loss: 0.6541440810486364
ROC train: 0.733759	val: 0.716202	test: 0.707108
PRC train: 0.669887	val: 0.658395	test: 0.644907

Epoch: 3
Loss: 0.6261914063490392
ROC train: 0.772583	val: 0.736680	test: 0.754202
PRC train: 0.707637	val: 0.640137	test: 0.679622

Epoch: 4
Loss: 0.5939956138020328
ROC train: 0.810903	val: 0.751722	test: 0.776261
PRC train: 0.750689	val: 0.626743	test: 0.691518

Epoch: 5
Loss: 0.570055680917131
ROC train: 0.833927	val: 0.765314	test: 0.810574
PRC train: 0.778305	val: 0.628441	test: 0.742239

Epoch: 6
Loss: 0.5385080399709181
ROC train: 0.847978	val: 0.772381	test: 0.835084
PRC train: 0.792360	val: 0.648672	test: 0.767660

Epoch: 7
Loss: 0.5086968695174867
ROC train: 0.859291	val: 0.778362	test: 0.833333
PRC train: 0.813358	val: 0.666085	test: 0.763041

Epoch: 8
Loss: 0.4975692928524511
ROC train: 0.869500	val: 0.788329	test: 0.838936
PRC train: 0.832020	val: 0.687519	test: 0.766500

Epoch: 9
Loss: 0.49546473354990905
ROC train: 0.875370	val: 0.791229	test: 0.836660
PRC train: 0.844295	val: 0.701929	test: 0.764929

Epoch: 10
Loss: 0.4785889416307567
ROC train: 0.878789	val: 0.789960	test: 0.843662
PRC train: 0.848941	val: 0.696363	test: 0.785782

Epoch: 11
Loss: 0.4739333079496638
ROC train: 0.886331	val: 0.805183	test: 0.846289
PRC train: 0.856862	val: 0.714124	test: 0.785601

Epoch: 12
Loss: 0.4621431179957523
ROC train: 0.887337	val: 0.810076	test: 0.842612
PRC train: 0.859101	val: 0.718715	test: 0.776485

Epoch: 13
Loss: 0.4524994237701912
ROC train: 0.890395	val: 0.806270	test: 0.855042
PRC train: 0.862550	val: 0.720035	test: 0.802477

Epoch: 14
Loss: 0.46459239822585685
ROC train: 0.894486	val: 0.804458	test: 0.853466
PRC train: 0.868336	val: 0.717861	test: 0.802154

Epoch: 15
Loss: 0.4560559400280887
ROC train: 0.896194	val: 0.815150	test: 0.833333
PRC train: 0.871733	val: 0.732486	test: 0.779412

Epoch: 16
Loss: 0.4271327424864605
ROC train: 0.897930	val: 0.805908	test: 0.847514
PRC train: 0.873014	val: 0.722995	test: 0.800969

Epoch: 17
Loss: 0.4408797820458144
ROC train: 0.902245	val: 0.804821	test: 0.849265
PRC train: 0.878645	val: 0.721520	test: 0.800018

Epoch: 18
Loss: 0.43284511935469494
ROC train: 0.905019	val: 0.808083	test: 0.850140
PRC train: 0.884150	val: 0.725621	test: 0.787156

Epoch: 19
Loss: 0.4187321860721502
ROC train: 0.909677	val: 0.811526	test: 0.846464
PRC train: 0.891769	val: 0.738426	test: 0.780962

Epoch: 20
Loss: 0.4107410652983531
ROC train: 0.911601	val: 0.820225	test: 0.851716
PRC train: 0.893242	val: 0.751225	test: 0.786799

Epoch: 21
Loss: 0.4156535354606793
ROC train: 0.911123	val: 0.814607	test: 0.844013
PRC train: 0.892971	val: 0.752560	test: 0.780055

Epoch: 22
Loss: 0.4109475811127776
ROC train: 0.915390	val: 0.825843	test: 0.836835
PRC train: 0.897185	val: 0.751562	test: 0.768853

Epoch: 23
Loss: 0.4287480108059757
ROC train: 0.918164	val: 0.831823	test: 0.847514
PRC train: 0.899342	val: 0.748425	test: 0.777358

Epoch: 24
Loss: 0.3895256201608164
ROC train: 0.920194	val: 0.827111	test: 0.852066
PRC train: 0.902227	val: 0.741678	test: 0.776642

Epoch: 25
Loss: 0.4000955542189816
ROC train: 0.920993	val: 0.823849	test: 0.856968
PRC train: 0.902606	val: 0.748612	test: 0.780398

Epoch: 26
Loss: 0.40481136009215557
ROC train: 0.921232	val: 0.825118	test: 0.851716
PRC train: 0.902602	val: 0.749108	test: 0.764365

Epoch: 27
Loss: 0.40882178562449417
ROC train: 0.922402	val: 0.828561	test: 0.857493
PRC train: 0.902694	val: 0.748952	test: 0.768843

Epoch: 28
Loss: 0.401676081133747
ROC train: 0.921209	val: 0.821493	test: 0.857668
PRC train: 0.903137	val: 0.740312	test: 0.766681

Epoch: 29
Loss: 0.39515333729615204
ROC train: 0.924991	val: 0.827292	test: 0.864846
PRC train: 0.907903	val: 0.757034	test: 0.785363

Epoch: 30
Loss: 0.40815215248375847
ROC train: 0.927008	val: 0.829105	test: 0.860294
PRC train: 0.911064	val: 0.760290	test: 0.789609

Epoch: 31
Loss: 0.3860080801971409
ROC train: 0.926264	val: 0.827474	test: 0.856092
PRC train: 0.909807	val: 0.755760	test: 0.785980

Epoch: 32
Loss: 0.3811909830277936
ROC train: 0.932120	val: 0.834723	test: 0.852766
PRC train: 0.918419	val: 0.763570	test: 0.762126

Epoch: 33
Loss: 0.3786873803577471
ROC train: 0.933231	val: 0.835629	test: 0.859244Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:2
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/random/train_prop=0.8/bace_random_3_20-05_14-43-16  ]
[ Using Seed :  3  ]
[ Using device :  cuda:2  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
randomly split
Data(edge_attr=[78, 2], edge_index=[2, 78], id=[1], x=[37, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.685526664455949
ROC train: 0.673136	val: 0.657122	test: 0.649335
PRC train: 0.614300	val: 0.605620	test: 0.573745

Epoch: 2
Loss: 0.6535006504427427
ROC train: 0.735547	val: 0.696267	test: 0.691176
PRC train: 0.699186	val: 0.647172	test: 0.638811

Epoch: 3
Loss: 0.6209222856656582
ROC train: 0.778509	val: 0.729612	test: 0.736169
PRC train: 0.743787	val: 0.667485	test: 0.720221

Epoch: 4
Loss: 0.5819761557769069
ROC train: 0.805266	val: 0.753171	test: 0.762955
PRC train: 0.769168	val: 0.682709	test: 0.748505

Epoch: 5
Loss: 0.5574774394705306
ROC train: 0.828865	val: 0.768576	test: 0.789566
PRC train: 0.797999	val: 0.694080	test: 0.754816

Epoch: 6
Loss: 0.537243958794167
ROC train: 0.844789	val: 0.789054	test: 0.816877
PRC train: 0.815871	val: 0.698139	test: 0.780317

Epoch: 7
Loss: 0.5326133865989465
ROC train: 0.856951	val: 0.795578	test: 0.824755
PRC train: 0.832580	val: 0.696339	test: 0.787788

Epoch: 8
Loss: 0.5093919946940235
ROC train: 0.866476	val: 0.801740	test: 0.837360
PRC train: 0.843196	val: 0.700169	test: 0.792316

Epoch: 9
Loss: 0.4887783990446639
ROC train: 0.873542	val: 0.803190	test: 0.839986
PRC train: 0.850694	val: 0.701061	test: 0.794557

Epoch: 10
Loss: 0.47434257896031273
ROC train: 0.879356	val: 0.812976	test: 0.842437
PRC train: 0.853898	val: 0.711435	test: 0.797569

Epoch: 11
Loss: 0.46064691496525817
ROC train: 0.885505	val: 0.816419	test: 0.849440
PRC train: 0.860742	val: 0.710686	test: 0.795218

Epoch: 12
Loss: 0.4611609977894265
ROC train: 0.887710	val: 0.817688	test: 0.843838
PRC train: 0.865523	val: 0.706573	test: 0.785433

Epoch: 13
Loss: 0.47237729420546054
ROC train: 0.891160	val: 0.815513	test: 0.844538
PRC train: 0.868516	val: 0.708357	test: 0.783227

Epoch: 14
Loss: 0.45605831798101965
ROC train: 0.896160	val: 0.815332	test: 0.848739
PRC train: 0.871869	val: 0.722258	test: 0.782660

Epoch: 15
Loss: 0.44698364131317386
ROC train: 0.898111	val: 0.815332	test: 0.859244
PRC train: 0.875473	val: 0.705522	test: 0.797632

Epoch: 16
Loss: 0.4369074507455985
ROC train: 0.900820	val: 0.828561	test: 0.870623
PRC train: 0.880107	val: 0.720335	test: 0.806964

Epoch: 17
Loss: 0.4229962027676769
ROC train: 0.903020	val: 0.831279	test: 0.872549
PRC train: 0.882580	val: 0.735489	test: 0.807061

Epoch: 18
Loss: 0.4374532367571449
ROC train: 0.908483	val: 0.827111	test: 0.867997
PRC train: 0.889704	val: 0.712940	test: 0.807415

Epoch: 19
Loss: 0.4117944691166975
ROC train: 0.910191	val: 0.820950	test: 0.872549
PRC train: 0.891277	val: 0.701635	test: 0.820186

Epoch: 20
Loss: 0.4197848005858365
ROC train: 0.912105	val: 0.822581	test: 0.870273
PRC train: 0.893129	val: 0.702901	test: 0.808314

Epoch: 21
Loss: 0.4089083967011488
ROC train: 0.912320	val: 0.828561	test: 0.875525
PRC train: 0.891523	val: 0.724914	test: 0.804146

Epoch: 22
Loss: 0.4155021369812985
ROC train: 0.917186	val: 0.838710	test: 0.876926
PRC train: 0.896735	val: 0.742196	test: 0.800663

Epoch: 23
Loss: 0.4028228091242731
ROC train: 0.919917	val: 0.838528	test: 0.870448
PRC train: 0.901326	val: 0.731287	test: 0.797561

Epoch: 24
Loss: 0.4060346714579783
ROC train: 0.924606	val: 0.842515	test: 0.879552
PRC train: 0.906876	val: 0.741814	test: 0.813785

Epoch: 25
Loss: 0.3950207511069016
ROC train: 0.924286	val: 0.837985	test: 0.880777
PRC train: 0.907331	val: 0.734639	test: 0.801899

Epoch: 26
Loss: 0.40029884135013916
ROC train: 0.924017	val: 0.839072	test: 0.871674
PRC train: 0.905529	val: 0.731366	test: 0.791864

Epoch: 27
Loss: 0.3962726373088437
ROC train: 0.923254	val: 0.837804	test: 0.867997
PRC train: 0.905277	val: 0.736600	test: 0.794665

Epoch: 28
Loss: 0.3829886541596908
ROC train: 0.929134	val: 0.843965	test: 0.873249
PRC train: 0.912969	val: 0.743215	test: 0.800172

Epoch: 29
Loss: 0.3930589473035274
ROC train: 0.929541	val: 0.848496	test: 0.867472
PRC train: 0.914782	val: 0.748712	test: 0.797225

Epoch: 30
Loss: 0.3853705280245211
ROC train: 0.932554	val: 0.845596	test: 0.872899
PRC train: 0.919543	val: 0.745572	test: 0.817649

Epoch: 31
Loss: 0.3952631952792926
ROC train: 0.934921	val: 0.842878	test: 0.866772
PRC train: 0.921592	val: 0.740531	test: 0.815928

Epoch: 32
Loss: 0.3914728131743391
ROC train: 0.933465	val: 0.843784	test: 0.865546
PRC train: 0.919393	val: 0.739673	test: 0.817731

Epoch: 33
Loss: 0.3843709190088888
ROC train: 0.932287	val: 0.846140	test: 0.869923Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:2
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/random/train_prop=0.8/bace_random_2_20-05_14-43-16  ]
[ Using Seed :  2  ]
[ Using device :  cuda:2  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
randomly split
Data(edge_attr=[78, 2], edge_index=[2, 78], id=[1], x=[37, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6804313372863146
ROC train: 0.674952	val: 0.662015	test: 0.653186
PRC train: 0.612994	val: 0.610377	test: 0.609785

Epoch: 2
Loss: 0.6480840520266684
ROC train: 0.746813	val: 0.716020	test: 0.739846
PRC train: 0.687537	val: 0.642656	test: 0.681293

Epoch: 3
Loss: 0.6092864202528634
ROC train: 0.794054	val: 0.746647	test: 0.785539
PRC train: 0.738380	val: 0.669485	test: 0.711185

Epoch: 4
Loss: 0.5702840633043714
ROC train: 0.827368	val: 0.771294	test: 0.828431
PRC train: 0.779668	val: 0.697352	test: 0.775424

Epoch: 5
Loss: 0.53048556592514
ROC train: 0.843183	val: 0.773650	test: 0.835434
PRC train: 0.811919	val: 0.698887	test: 0.769500

Epoch: 6
Loss: 0.5258058540950228
ROC train: 0.859661	val: 0.789054	test: 0.843312
PRC train: 0.828771	val: 0.708143	test: 0.776641

Epoch: 7
Loss: 0.4971974644975224
ROC train: 0.869710	val: 0.800652	test: 0.850315
PRC train: 0.836006	val: 0.718493	test: 0.777992

Epoch: 8
Loss: 0.5018712694715073
ROC train: 0.871016	val: 0.801015	test: 0.837710
PRC train: 0.844036	val: 0.709914	test: 0.756010

Epoch: 9
Loss: 0.4835067248029413
ROC train: 0.876707	val: 0.812794	test: 0.835784
PRC train: 0.849393	val: 0.717080	test: 0.743499

Epoch: 10
Loss: 0.48773952488920125
ROC train: 0.879940	val: 0.812251	test: 0.848039
PRC train: 0.851078	val: 0.737321	test: 0.757425

Epoch: 11
Loss: 0.466211896061597
ROC train: 0.879786	val: 0.808264	test: 0.820553
PRC train: 0.857464	val: 0.719246	test: 0.738932

Epoch: 12
Loss: 0.448246914792644
ROC train: 0.892749	val: 0.811707	test: 0.842612
PRC train: 0.869537	val: 0.723913	test: 0.754295

Epoch: 13
Loss: 0.44991885571626444
ROC train: 0.897796	val: 0.811345	test: 0.853817
PRC train: 0.874527	val: 0.724565	test: 0.774701

Epoch: 14
Loss: 0.45162730399037015
ROC train: 0.901064	val: 0.817144	test: 0.851716
PRC train: 0.879681	val: 0.731596	test: 0.761995

Epoch: 15
Loss: 0.4424658268104188
ROC train: 0.900778	val: 0.813157	test: 0.850665
PRC train: 0.880240	val: 0.723692	test: 0.761308

Epoch: 16
Loss: 0.4365371564804863
ROC train: 0.904426	val: 0.823124	test: 0.852241
PRC train: 0.884749	val: 0.737658	test: 0.766514

Epoch: 17
Loss: 0.4215111802697026
ROC train: 0.908364	val: 0.824574	test: 0.859594
PRC train: 0.889601	val: 0.741269	test: 0.773979

Epoch: 18
Loss: 0.42619747726690893
ROC train: 0.912704	val: 0.830192	test: 0.863971
PRC train: 0.894052	val: 0.747256	test: 0.780817

Epoch: 19
Loss: 0.42116509889763176
ROC train: 0.914535	val: 0.830736	test: 0.861870
PRC train: 0.896051	val: 0.747312	test: 0.776388

Epoch: 20
Loss: 0.41440066977973145
ROC train: 0.917068	val: 0.832004	test: 0.865371
PRC train: 0.899472	val: 0.744884	test: 0.784501

Epoch: 21
Loss: 0.4206456204915109
ROC train: 0.919480	val: 0.837079	test: 0.860119
PRC train: 0.903411	val: 0.743796	test: 0.792116

Epoch: 22
Loss: 0.41558926122188067
ROC train: 0.919005	val: 0.834179	test: 0.863620
PRC train: 0.903202	val: 0.742451	test: 0.793709

Epoch: 23
Loss: 0.4115081652665296
ROC train: 0.919392	val: 0.835266	test: 0.867822
PRC train: 0.902972	val: 0.741666	test: 0.800719

Epoch: 24
Loss: 0.40144330301779024
ROC train: 0.924726	val: 0.828199	test: 0.858894
PRC train: 0.909069	val: 0.722195	test: 0.796554

Epoch: 25
Loss: 0.4111577963956689
ROC train: 0.926014	val: 0.835266	test: 0.869573
PRC train: 0.909990	val: 0.753163	test: 0.807408

Epoch: 26
Loss: 0.4085174748350878
ROC train: 0.927621	val: 0.841791	test: 0.870623
PRC train: 0.912349	val: 0.768942	test: 0.815042

Epoch: 27
Loss: 0.3881347553528209
ROC train: 0.926905	val: 0.844146	test: 0.868697
PRC train: 0.912188	val: 0.766032	test: 0.807130

Epoch: 28
Loss: 0.38941114468365423
ROC train: 0.926885	val: 0.845777	test: 0.873424
PRC train: 0.911027	val: 0.767327	test: 0.807675

Epoch: 29
Loss: 0.38399784702912987
ROC train: 0.929969	val: 0.845959	test: 0.878852
PRC train: 0.915007	val: 0.766381	test: 0.812839

Epoch: 30
Loss: 0.3775831100175302
ROC train: 0.931790	val: 0.849583	test: 0.878326
PRC train: 0.916166	val: 0.765181	test: 0.812236

Epoch: 31
Loss: 0.3863657829432095
ROC train: 0.933638	val: 0.855926	test: 0.881303
PRC train: 0.917299	val: 0.776389	test: 0.827028

Epoch: 32
Loss: 0.36530451904922384
ROC train: 0.931606	val: 0.852302	test: 0.878501
PRC train: 0.916480	val: 0.776721	test: 0.824561

Epoch: 33
Loss: 0.3846163956960069
ROC train: 0.934515	val: 0.852120	test: 0.869923
PRC train: 0.933303	val: 0.785721	test: 0.764618

Epoch: 34
Loss: 0.36413255839867226
ROC train: 0.947627	val: 0.825499	test: 0.842175
PRC train: 0.934592	val: 0.796938	test: 0.775023

Epoch: 35
Loss: 0.35941637096276474
ROC train: 0.948229	val: 0.826904	test: 0.841645
PRC train: 0.936500	val: 0.793148	test: 0.776721

Epoch: 36
Loss: 0.3381538101938202
ROC train: 0.950620	val: 0.827913	test: 0.844695
PRC train: 0.939590	val: 0.797193	test: 0.776294

Epoch: 37
Loss: 0.3334808003812016
ROC train: 0.951728	val: 0.825850	test: 0.844297
PRC train: 0.940984	val: 0.799626	test: 0.776025

Epoch: 38
Loss: 0.3617274847644957
ROC train: 0.955005	val: 0.825631	test: 0.846950
PRC train: 0.944676	val: 0.799703	test: 0.782459

Epoch: 39
Loss: 0.33372920895138863
ROC train: 0.954520	val: 0.819443	test: 0.844695
PRC train: 0.944318	val: 0.788355	test: 0.779392

Epoch: 40
Loss: 0.3365624039764594
ROC train: 0.951703	val: 0.814000	test: 0.842971
PRC train: 0.940507	val: 0.774876	test: 0.775309

Epoch: 41
Loss: 0.3581296478913682
ROC train: 0.954104	val: 0.817775	test: 0.834881
PRC train: 0.945074	val: 0.784607	test: 0.766082

Epoch: 42
Loss: 0.31480613245105593
ROC train: 0.959297	val: 0.822998	test: 0.829355
PRC train: 0.951379	val: 0.804585	test: 0.765953

Epoch: 43
Loss: 0.3196511970850453
ROC train: 0.959586	val: 0.824534	test: 0.834836
PRC train: 0.951580	val: 0.803284	test: 0.773135

Epoch: 44
Loss: 0.32773098866223643
ROC train: 0.960003	val: 0.825368	test: 0.843236
PRC train: 0.952053	val: 0.799930	test: 0.781228

Epoch: 45
Loss: 0.31510904952493357
ROC train: 0.959190	val: 0.822032	test: 0.842750
PRC train: 0.950592	val: 0.791740	test: 0.777742

Epoch: 46
Loss: 0.3066036108923063
ROC train: 0.959192	val: 0.821725	test: 0.836649
PRC train: 0.950425	val: 0.794544	test: 0.768242

Epoch: 47
Loss: 0.3073482694021455
ROC train: 0.960993	val: 0.819223	test: 0.831344
PRC train: 0.951713	val: 0.800958	test: 0.757369

Epoch: 48
Loss: 0.33392927189166177
ROC train: 0.962639	val: 0.817380	test: 0.833378
PRC train: 0.954390	val: 0.794768	test: 0.758441

Epoch: 49
Loss: 0.2993006576293764
ROC train: 0.961634	val: 0.818916	test: 0.834350
PRC train: 0.954482	val: 0.788214	test: 0.762660

Epoch: 50
Loss: 0.30523051421230113
ROC train: 0.962431	val: 0.824446	test: 0.837931
PRC train: 0.955775	val: 0.789743	test: 0.768412

Epoch: 51
Loss: 0.28604609176778173
ROC train: 0.963361	val: 0.832565	test: 0.845314
PRC train: 0.956203	val: 0.803270	test: 0.778606

Epoch: 52
Loss: 0.2937327503153875
ROC train: 0.964579	val: 0.834979	test: 0.849248
PRC train: 0.957156	val: 0.807193	test: 0.783909

Epoch: 53
Loss: 0.2881477881936376
ROC train: 0.965848	val: 0.827650	test: 0.844253
PRC train: 0.958769	val: 0.797679	test: 0.778903

Epoch: 54
Loss: 0.29228752870993713
ROC train: 0.967426	val: 0.825148	test: 0.837577
PRC train: 0.960521	val: 0.801506	test: 0.771959

Epoch: 55
Loss: 0.32369944694162317
ROC train: 0.968695	val: 0.825982	test: 0.840628
PRC train: 0.961847	val: 0.802030	test: 0.777392

Epoch: 56
Loss: 0.30352193472824607
ROC train: 0.966647	val: 0.827299	test: 0.843236
PRC train: 0.960065	val: 0.786030	test: 0.780795

Epoch: 57
Loss: 0.3022140858967636
ROC train: 0.966916	val: 0.826991	test: 0.841379
PRC train: 0.960461	val: 0.789232	test: 0.780323

Epoch: 58
Loss: 0.31257991874053837
ROC train: 0.968655	val: 0.827825	test: 0.835853
PRC train: 0.961815	val: 0.803873	test: 0.773711

Epoch: 59
Loss: 0.2716322304307518
ROC train: 0.969430	val: 0.830503	test: 0.833378
PRC train: 0.962708	val: 0.811317	test: 0.769296

Epoch: 60
Loss: 0.2938547181209224
ROC train: 0.969939	val: 0.833575	test: 0.838240
PRC train: 0.964142	val: 0.814161	test: 0.779573

Epoch: 61
Loss: 0.28949677814922303
ROC train: 0.969047	val: 0.835989	test: 0.843590
PRC train: 0.962485	val: 0.811720	test: 0.785418

Epoch: 62
Loss: 0.29981461376825835
ROC train: 0.969290	val: 0.832521	test: 0.845049
PRC train: 0.962270	val: 0.804150	test: 0.784687

Epoch: 63
Loss: 0.2761809238766474
ROC train: 0.968308	val: 0.823875	test: 0.844783
PRC train: 0.961037	val: 0.789846	test: 0.779062

Epoch: 64
Loss: 0.29845913266322943
ROC train: 0.969395	val: 0.820496	test: 0.842042
PRC train: 0.962970	val: 0.785991	test: 0.768243

Epoch: 65
Loss: 0.26810018242120265
ROC train: 0.971762	val: 0.818960	test: 0.840539
PRC train: 0.965952	val: 0.785661	test: 0.755756

Epoch: 66
Loss: 0.2718130735861154
ROC train: 0.974280	val: 0.830766	test: 0.843811
PRC train: 0.968686	val: 0.815225	test: 0.757510

Epoch: 67
Loss: 0.2468119554911863
ROC train: 0.975647	val: 0.837832	test: 0.845800
PRC train: 0.970419	val: 0.822392	test: 0.759247

Epoch: 68
Loss: 0.2815423591505948
ROC train: 0.976659	val: 0.835155	test: 0.842750
PRC train: 0.971871	val: 0.814567	test: 0.760624

Epoch: 69
Loss: 0.2657725365204916
ROC train: 0.978153	val: 0.831556	test: 0.838329
PRC train: 0.973721	val: 0.810871	test: 0.762463

Epoch: 70
Loss: 0.26643729921531795
ROC train: 0.975118	val: 0.830283	test: 0.837312
PRC train: 0.970550	val: 0.806862	test: 0.764508

Epoch: 71
Loss: 0.24529812599269463
ROC train: 0.969385	val: 0.828396	test: 0.827056
PRC train: 0.964207	val: 0.791574	test: 0.745792

Epoch: 72
Loss: 0.26291767014708384
ROC train: 0.971451	val: 0.827562	test: 0.837975
PRC train: 0.965312	val: 0.795342	test: 0.764309

Epoch: 73
Loss: 0.2648194541882105
ROC train: 0.979077	val: 0.827518	test: 0.843015
PRC train: 0.974166	val: 0.802081	test: 0.775290

Epoch: 74
Loss: 0.2694938957501599
ROC train: 0.980341	val: 0.824797	test: 0.841733
PRC train: 0.976102	val: 0.798672	test: 0.771991

Epoch: 75
Loss: 0.26815834052778537
ROC train: 0.978547	val: 0.822339	test: 0.841777
PRC train: 0.974093	val: 0.785805	test: 0.773722

Epoch: 76
Loss: 0.24425888023782957
ROC train: 0.975314	val: 0.821593	test: 0.840628
PRC train: 0.969144	val: 0.781040	test: 0.772946

Epoch: 77
Loss: 0.2557938063471345
ROC train: 0.979101	val: 0.824358	test: 0.844651
PRC train: 0.974624	val: 0.785822	test: 0.775417

Epoch: 78
Loss: 0.2510132847739568
ROC train: 0.981223	val: 0.825148	test: 0.841424
PRC train: 0.977763	val: 0.786861	test: 0.767937

Epoch: 79
Loss: 0.25425274556455546
ROC train: 0.978905	val: 0.824885	test: 0.834394
PRC train: 0.974644	val: 0.799629	test: 0.762610

Epoch: 80
Loss: 0.25653009680559136
ROC train: 0.976235	val: 0.818960	test: 0.831300
PRC train: 0.971045	val: 0.799729	test: 0.761241

Epoch: 81
Loss: 0.2576569056028637
ROC train: 0.976397	val: 0.819487	test: 0.832228
PRC train: 0.971183	val: 0.802034	test: 0.764303

Epoch: 82
Loss: 0.2815224132726101
ROC train: 0.982274	val: 0.819530	test: 0.839523
PRC train: 0.978426	val: 0.798089	test: 0.770091

Epoch: 83
Loss: 0.23790775802345276
ROC train: 0.984794	val: 0.818433	test: 0.837533
PRC train: 0.981792	val: 0.800767	test: 0.768757

Epoch: 84
Loss: 0.23768713547972153
ROC train: 0.984593	val: 0.825982	test: 0.841335
PRC train: 0.981896	val: 0.799605	test: 0.767674

Epoch: 85
Loss: 0.2577650833393902
ROC train: 0.981110	val: 0.832697	test: 0.845402
PRC train: 0.977453	val: 0.807220	test: 0.772803

Epoch: 86
Loss: 0.25125360152458315
ROC train: 0.981830	val: 0.829976	test: 0.842617
PRC train: 0.978204	val: 0.805003	test: 0.773832

Epoch: 87
Loss: 0.26013288091090764
ROC train: 0.981624	val: 0.824139	test: 0.838462
PRC train: 0.978407	val: 0.800696	test: 0.773229

Epoch: 88
Loss: 0.2214174507494412
ROC train: 0.983697	val: 0.825411	test: 0.839920
PRC train: 0.980807	val: 0.796362	test: 0.767423

Epoch: 89
Loss: 0.23860283126565918
ROC train: 0.984652	val: 0.829054	test: 0.847878
PRC train: 0.981485	val: 0.805369	test: 0.771637

Epoch: 90
Loss: 0.23363989993318557
ROC train: 0.985005	val: 0.829713	test: 0.847834
PRC train: 0.981874	val: 0.806350	test: 0.775025

Epoch: 91
Loss: 0.2399414186939346
ROC train: 0.983611	val: 0.821461	test: 0.838727
PRC train: 0.980498	val: 0.787812	test: 0.767893

Epoch: 92
Loss: 0.2332641994982325
ROC train: 0.981977	val: 0.825280	test: 0.835013
PRC train: 0.978985	val: 0.794405	test: 0.766961

Epoch: 93
Loss: 0.24604508847588424
ROC train: 0.981913	val: 0.828045	test: 0.837577
PRC train: 0.978609	val: 0.801633	test: 0.770942

Epoch: 94
Loss: 0.2344192008624683
ROC train: 0.983550	val: 0.830898	test: 0.838638
PRC train: 0.934377	val: 0.770587	test: 0.747707

Epoch: 34
Loss: 0.3406300206677212
ROC train: 0.945123	val: 0.809655	test: 0.829266
PRC train: 0.930999	val: 0.772535	test: 0.753460

Epoch: 35
Loss: 0.3729853881852358
ROC train: 0.948856	val: 0.821110	test: 0.832361
PRC train: 0.934023	val: 0.785915	test: 0.762529

Epoch: 36
Loss: 0.3556434766257386
ROC train: 0.948920	val: 0.821110	test: 0.830769
PRC train: 0.934368	val: 0.787740	test: 0.766219

Epoch: 37
Loss: 0.3437455395344126
ROC train: 0.952335	val: 0.827518	test: 0.826835
PRC train: 0.939450	val: 0.793186	test: 0.764212

Epoch: 38
Loss: 0.3350912569845415
ROC train: 0.954741	val: 0.822515	test: 0.831123
PRC train: 0.942063	val: 0.783732	test: 0.767676

Epoch: 39
Loss: 0.34192860279720766
ROC train: 0.953237	val: 0.814176	test: 0.830504
PRC train: 0.940583	val: 0.771939	test: 0.763534

Epoch: 40
Loss: 0.32325820519055026
ROC train: 0.953124	val: 0.813737	test: 0.826702
PRC train: 0.939751	val: 0.775232	test: 0.758752

Epoch: 41
Loss: 0.34381597904133526
ROC train: 0.955098	val: 0.814264	test: 0.829178
PRC train: 0.941895	val: 0.774526	test: 0.763771

Epoch: 42
Loss: 0.31446892899853063
ROC train: 0.954212	val: 0.815273	test: 0.830637
PRC train: 0.940260	val: 0.772574	test: 0.765193

Epoch: 43
Loss: 0.31086764809412226
ROC train: 0.956666	val: 0.817907	test: 0.833024
PRC train: 0.942952	val: 0.777840	test: 0.769627

Epoch: 44
Loss: 0.3327167877679523
ROC train: 0.959969	val: 0.820233	test: 0.834218
PRC train: 0.947857	val: 0.784644	test: 0.771208

Epoch: 45
Loss: 0.31826086019986755
ROC train: 0.959831	val: 0.820452	test: 0.827011
PRC train: 0.948571	val: 0.785890	test: 0.758580

Epoch: 46
Loss: 0.32484255292273456
ROC train: 0.955711	val: 0.820540	test: 0.828161
PRC train: 0.943992	val: 0.783653	test: 0.760680

Epoch: 47
Loss: 0.31262915478173575
ROC train: 0.959346	val: 0.823305	test: 0.833422
PRC train: 0.947764	val: 0.781035	test: 0.769755

Epoch: 48
Loss: 0.31507839603386056
ROC train: 0.958117	val: 0.817512	test: 0.829310
PRC train: 0.946134	val: 0.768214	test: 0.766167

Epoch: 49
Loss: 0.3014195160470528
ROC train: 0.961629	val: 0.811850	test: 0.830239
PRC train: 0.951628	val: 0.757360	test: 0.765806

Epoch: 50
Loss: 0.3102955519699654
ROC train: 0.966191	val: 0.808602	test: 0.826790
PRC train: 0.957549	val: 0.768470	test: 0.754742

Epoch: 51
Loss: 0.2943350112161503
ROC train: 0.963942	val: 0.813605	test: 0.824801
PRC train: 0.954652	val: 0.778300	test: 0.744855

Epoch: 52
Loss: 0.3148182585584451
ROC train: 0.965706	val: 0.810402	test: 0.828117
PRC train: 0.956614	val: 0.762896	test: 0.753397

Epoch: 53
Loss: 0.31945696474196456
ROC train: 0.965064	val: 0.804872	test: 0.829001
PRC train: 0.956433	val: 0.749783	test: 0.764760

Epoch: 54
Loss: 0.29310247222139185
ROC train: 0.968702	val: 0.811192	test: 0.835146
PRC train: 0.961436	val: 0.757224	test: 0.770749

Epoch: 55
Loss: 0.2848427054890227
ROC train: 0.969611	val: 0.817292	test: 0.834262
PRC train: 0.962707	val: 0.773975	test: 0.765638

Epoch: 56
Loss: 0.2860252088480956
ROC train: 0.969807	val: 0.816019	test: 0.833820
PRC train: 0.963173	val: 0.764780	test: 0.764352

Epoch: 57
Loss: 0.30270668872423356
ROC train: 0.969723	val: 0.816590	test: 0.837356
PRC train: 0.962930	val: 0.758964	test: 0.772912

Epoch: 58
Loss: 0.2903012346585383
ROC train: 0.970302	val: 0.820276	test: 0.840981
PRC train: 0.963644	val: 0.766897	test: 0.781104

Epoch: 59
Loss: 0.28990488869726305
ROC train: 0.972413	val: 0.816239	test: 0.838196
PRC train: 0.965603	val: 0.770550	test: 0.775725

Epoch: 60
Loss: 0.2946224147122446
ROC train: 0.964310	val: 0.803774	test: 0.828117
PRC train: 0.956250	val: 0.749987	test: 0.762845

Epoch: 61
Loss: 0.3012154803316891
ROC train: 0.970914	val: 0.812508	test: 0.830460
PRC train: 0.963677	val: 0.766356	test: 0.764449

Epoch: 62
Loss: 0.2933599604794893
ROC train: 0.972257	val: 0.820233	test: 0.834041
PRC train: 0.965343	val: 0.783196	test: 0.768579

Epoch: 63
Loss: 0.29290551165072837
ROC train: 0.972901	val: 0.821769	test: 0.831300
PRC train: 0.966939	val: 0.780384	test: 0.754704

Epoch: 64
Loss: 0.26765638386289153
ROC train: 0.973844	val: 0.814308	test: 0.829620
PRC train: 0.968064	val: 0.760433	test: 0.757460

Epoch: 65
Loss: 0.2941545278873762
ROC train: 0.972362	val: 0.810226	test: 0.827454
PRC train: 0.965853	val: 0.752917	test: 0.757615

Epoch: 66
Loss: 0.26804826242160795
ROC train: 0.974628	val: 0.815273	test: 0.831786
PRC train: 0.968923	val: 0.765416	test: 0.760596

Epoch: 67
Loss: 0.26890442954469473
ROC train: 0.972646	val: 0.816370	test: 0.830858
PRC train: 0.966573	val: 0.783185	test: 0.756590

Epoch: 68
Loss: 0.2588673095471471
ROC train: 0.974839	val: 0.812859	test: 0.834925
PRC train: 0.969219	val: 0.776118	test: 0.769439

Epoch: 69
Loss: 0.2730409495323812
ROC train: 0.974966	val: 0.808514	test: 0.834704
PRC train: 0.969403	val: 0.764010	test: 0.776455

Epoch: 70
Loss: 0.2781069135190054
ROC train: 0.975255	val: 0.813474	test: 0.835544
PRC train: 0.970203	val: 0.762668	test: 0.770802

Epoch: 71
Loss: 0.2965769741417166
ROC train: 0.972031	val: 0.815888	test: 0.832405
PRC train: 0.965440	val: 0.752371	test: 0.754139

Epoch: 72
Loss: 0.26435540087384085
ROC train: 0.974395	val: 0.814000	test: 0.829443
PRC train: 0.968539	val: 0.761909	test: 0.745648

Epoch: 73
Loss: 0.24592463884582655
ROC train: 0.975613	val: 0.808558	test: 0.829531
PRC train: 0.970498	val: 0.757987	test: 0.750256

Epoch: 74
Loss: 0.25423324303636247
ROC train: 0.977474	val: 0.815361	test: 0.836030
PRC train: 0.972768	val: 0.763480	test: 0.755881

Epoch: 75
Loss: 0.23826912138926148
ROC train: 0.976019	val: 0.819882	test: 0.833731
PRC train: 0.970554	val: 0.766673	test: 0.755973

Epoch: 76
Loss: 0.22788532918032978
ROC train: 0.974437	val: 0.819969	test: 0.830018
PRC train: 0.968709	val: 0.759023	test: 0.753993

Epoch: 77
Loss: 0.2688202458849062
ROC train: 0.976730	val: 0.817380	test: 0.827763
PRC train: 0.972013	val: 0.768031	test: 0.755492

Epoch: 78
Loss: 0.2883692270853384
ROC train: 0.976698	val: 0.821461	test: 0.832980
PRC train: 0.972228	val: 0.776031	test: 0.767697

Epoch: 79
Loss: 0.2422277291771357
ROC train: 0.971426	val: 0.821681	test: 0.833466
PRC train: 0.962857	val: 0.779981	test: 0.761381

Epoch: 80
Loss: 0.25488860848853023
ROC train: 0.974883	val: 0.825280	test: 0.828912
PRC train: 0.968153	val: 0.790783	test: 0.762868

Epoch: 81
Loss: 0.24212351578945568
ROC train: 0.980478	val: 0.825850	test: 0.827454
PRC train: 0.975710	val: 0.792647	test: 0.764139

Epoch: 82
Loss: 0.25793549610763167
ROC train: 0.978773	val: 0.820847	test: 0.833731
PRC train: 0.974589	val: 0.782582	test: 0.774957

Epoch: 83
Loss: 0.25453562022650256
ROC train: 0.977555	val: 0.819618	test: 0.835190
PRC train: 0.972519	val: 0.772470	test: 0.767296

Epoch: 84
Loss: 0.2739283367976286
ROC train: 0.978996	val: 0.820496	test: 0.834660
PRC train: 0.973806	val: 0.772183	test: 0.762348

Epoch: 85
Loss: 0.2618121655308743
ROC train: 0.981683	val: 0.820057	test: 0.833731
PRC train: 0.977490	val: 0.762033	test: 0.756323

Epoch: 86
Loss: 0.23302798035503075
ROC train: 0.980987	val: 0.816853	test: 0.824182
PRC train: 0.976429	val: 0.761097	test: 0.740272

Epoch: 87
Loss: 0.25632649987742034
ROC train: 0.981862	val: 0.820628	test: 0.830106
PRC train: 0.977145	val: 0.779700	test: 0.757762

Epoch: 88
Loss: 0.23030514222247522
ROC train: 0.982286	val: 0.822690	test: 0.839876
PRC train: 0.977961	val: 0.781459	test: 0.771109

Epoch: 89
Loss: 0.2611095204789351
ROC train: 0.982288	val: 0.821242	test: 0.843236
PRC train: 0.978322	val: 0.786468	test: 0.777775

Epoch: 90
Loss: 0.255410003689993
ROC train: 0.981757	val: 0.819399	test: 0.842485
PRC train: 0.978191	val: 0.789615	test: 0.778238

Epoch: 91
Loss: 0.2543434294462935
ROC train: 0.980052	val: 0.811499	test: 0.836251
PRC train: 0.976449	val: 0.770427	test: 0.774710

Epoch: 92
Loss: 0.2418448918128493
ROC train: 0.979772	val: 0.808602	test: 0.835190
PRC train: 0.976078	val: 0.769445	test: 0.777060

Epoch: 93
Loss: 0.24685284989238268
ROC train: 0.984165	val: 0.820979	test: 0.837135
PRC train: 0.981222	val: 0.787924	test: 0.775038

Epoch: 94
Loss: 0.2519090792567059
ROC train: 0.982585	val: 0.822164	test: 0.835721
PRC train: 0.931219	val: 0.804268	test: 0.759928

Epoch: 34
Loss: 0.3533205054223143
ROC train: 0.948286	val: 0.826114	test: 0.831477
PRC train: 0.933402	val: 0.811385	test: 0.757787

Epoch: 35
Loss: 0.3486279532018446
ROC train: 0.948156	val: 0.822998	test: 0.832184
PRC train: 0.932914	val: 0.799561	test: 0.760674

Epoch: 36
Loss: 0.34413954798759083
ROC train: 0.948183	val: 0.823305	test: 0.832714
PRC train: 0.932232	val: 0.798943	test: 0.763559

Epoch: 37
Loss: 0.3358225780103188
ROC train: 0.951149	val: 0.819925	test: 0.830150
PRC train: 0.936768	val: 0.797276	test: 0.759149

Epoch: 38
Loss: 0.3279058130845228
ROC train: 0.954349	val: 0.816239	test: 0.829310
PRC train: 0.941254	val: 0.790448	test: 0.755175

Epoch: 39
Loss: 0.34232691220331923
ROC train: 0.955290	val: 0.816239	test: 0.831742
PRC train: 0.942849	val: 0.788245	test: 0.755136

Epoch: 40
Loss: 0.33392042291612406
ROC train: 0.953398	val: 0.819399	test: 0.836163
PRC train: 0.940282	val: 0.788718	test: 0.759288

Epoch: 41
Loss: 0.33470245722224506
ROC train: 0.957230	val: 0.825411	test: 0.834173
PRC train: 0.944311	val: 0.796551	test: 0.757945

Epoch: 42
Loss: 0.31803114181063913
ROC train: 0.959934	val: 0.828966	test: 0.836074
PRC train: 0.948140	val: 0.808190	test: 0.765377

Epoch: 43
Loss: 0.34112300842036725
ROC train: 0.956137	val: 0.827738	test: 0.840451
PRC train: 0.943538	val: 0.801362	test: 0.774231

Epoch: 44
Loss: 0.3248718486393588
ROC train: 0.956451	val: 0.825236	test: 0.837843
PRC train: 0.944322	val: 0.789969	test: 0.773868

Epoch: 45
Loss: 0.30949386897634573
ROC train: 0.959753	val: 0.827913	test: 0.831167
PRC train: 0.948859	val: 0.797194	test: 0.764426

Epoch: 46
Loss: 0.3070810670266355
ROC train: 0.962457	val: 0.822866	test: 0.833687
PRC train: 0.951875	val: 0.800703	test: 0.760406

Epoch: 47
Loss: 0.3044757417982544
ROC train: 0.965495	val: 0.824270	test: 0.835986
PRC train: 0.955646	val: 0.802903	test: 0.766916

Epoch: 48
Loss: 0.29572684857747794
ROC train: 0.964976	val: 0.829449	test: 0.837489
PRC train: 0.954946	val: 0.811074	test: 0.769609

Epoch: 49
Loss: 0.33698802947226847
ROC train: 0.964241	val: 0.829844	test: 0.837003
PRC train: 0.954514	val: 0.795578	test: 0.769322

Epoch: 50
Loss: 0.3085579621890623
ROC train: 0.964802	val: 0.827606	test: 0.834925
PRC train: 0.955903	val: 0.793809	test: 0.774474

Epoch: 51
Loss: 0.316982593871624
ROC train: 0.967009	val: 0.831029	test: 0.837135
PRC train: 0.957887	val: 0.803389	test: 0.775167

Epoch: 52
Loss: 0.288371656559336
ROC train: 0.967636	val: 0.835462	test: 0.840053
PRC train: 0.958231	val: 0.811573	test: 0.776293

Epoch: 53
Loss: 0.30695508973637775
ROC train: 0.970929	val: 0.834365	test: 0.840363
PRC train: 0.962236	val: 0.814117	test: 0.776673

Epoch: 54
Loss: 0.2832039257822282
ROC train: 0.968406	val: 0.825016	test: 0.841070
PRC train: 0.959186	val: 0.791059	test: 0.780409

Epoch: 55
Loss: 0.29364860786033176
ROC train: 0.968332	val: 0.824051	test: 0.842440
PRC train: 0.959741	val: 0.796456	test: 0.783645

Epoch: 56
Loss: 0.2967268336371804
ROC train: 0.969449	val: 0.828615	test: 0.842485
PRC train: 0.960989	val: 0.807339	test: 0.780797

Epoch: 57
Loss: 0.3080875423438104
ROC train: 0.969861	val: 0.835418	test: 0.839434
PRC train: 0.962428	val: 0.814360	test: 0.770060

Epoch: 58
Loss: 0.2912653278862568
ROC train: 0.970953	val: 0.835637	test: 0.845623
PRC train: 0.964212	val: 0.811820	test: 0.779641

Epoch: 59
Loss: 0.2838136646851315
ROC train: 0.970049	val: 0.831600	test: 0.853935
PRC train: 0.962115	val: 0.799988	test: 0.794986

Epoch: 60
Loss: 0.282453886718964
ROC train: 0.970914	val: 0.831644	test: 0.855703
PRC train: 0.963315	val: 0.805148	test: 0.799569

Epoch: 61
Loss: 0.2827016374701525
ROC train: 0.975615	val: 0.836471	test: 0.849646
PRC train: 0.969194	val: 0.825316	test: 0.790469

Epoch: 62
Loss: 0.28790327524959763
ROC train: 0.976262	val: 0.838007	test: 0.847347
PRC train: 0.971204	val: 0.831525	test: 0.782230

Epoch: 63
Loss: 0.2580826805451185
ROC train: 0.975544	val: 0.833048	test: 0.843811
PRC train: 0.970540	val: 0.823983	test: 0.775278

Epoch: 64
Loss: 0.2932305094349776
ROC train: 0.977264	val: 0.830941	test: 0.845447
PRC train: 0.971797	val: 0.813041	test: 0.779209

Epoch: 65
Loss: 0.29018350057984676
ROC train: 0.977626	val: 0.828791	test: 0.845933
PRC train: 0.971802	val: 0.803978	test: 0.779421

Epoch: 66
Loss: 0.28250775788215887
ROC train: 0.976171	val: 0.824753	test: 0.846684
PRC train: 0.969286	val: 0.798685	test: 0.780331

Epoch: 67
Loss: 0.2828709145621667
ROC train: 0.973761	val: 0.829888	test: 0.848674
PRC train: 0.965484	val: 0.805409	test: 0.779045

Epoch: 68
Loss: 0.25000244876052996
ROC train: 0.973619	val: 0.834321	test: 0.843546
PRC train: 0.966802	val: 0.810012	test: 0.772551

Epoch: 69
Loss: 0.2444978177548591
ROC train: 0.978665	val: 0.828001	test: 0.843678
PRC train: 0.973507	val: 0.807124	test: 0.777927

Epoch: 70
Loss: 0.25435256564108244
ROC train: 0.979255	val: 0.825016	test: 0.839876
PRC train: 0.974309	val: 0.807490	test: 0.772755

Epoch: 71
Loss: 0.27017645867675777
ROC train: 0.976813	val: 0.825236	test: 0.844562
PRC train: 0.971335	val: 0.797880	test: 0.781724

Epoch: 72
Loss: 0.2587034853732282
ROC train: 0.975902	val: 0.828045	test: 0.843324
PRC train: 0.970717	val: 0.797610	test: 0.781798

Epoch: 73
Loss: 0.2849592647730632
ROC train: 0.977739	val: 0.834452	test: 0.845225
PRC train: 0.972204	val: 0.815383	test: 0.786008

Epoch: 74
Loss: 0.2521150199664607
ROC train: 0.977146	val: 0.834101	test: 0.846861
PRC train: 0.971933	val: 0.815980	test: 0.790631

Epoch: 75
Loss: 0.2865901379568654
ROC train: 0.978743	val: 0.834277	test: 0.850398
PRC train: 0.974495	val: 0.808246	test: 0.793217

Epoch: 76
Loss: 0.242141817698319
ROC train: 0.979650	val: 0.828220	test: 0.852520
PRC train: 0.975740	val: 0.796799	test: 0.789985

Epoch: 77
Loss: 0.24603157046191546
ROC train: 0.982443	val: 0.830064	test: 0.853183
PRC train: 0.978694	val: 0.804374	test: 0.790924

Epoch: 78
Loss: 0.24005973173853218
ROC train: 0.980674	val: 0.834716	test: 0.848497
PRC train: 0.976640	val: 0.815058	test: 0.790177

Epoch: 79
Loss: 0.24492890031151482
ROC train: 0.982942	val: 0.829756	test: 0.853050
PRC train: 0.979225	val: 0.802007	test: 0.793929

Epoch: 80
Loss: 0.26683841962822713
ROC train: 0.983011	val: 0.825411	test: 0.852034
PRC train: 0.979539	val: 0.790181	test: 0.794510

Epoch: 81
Loss: 0.26085777979870417
ROC train: 0.984584	val: 0.823875	test: 0.846021
PRC train: 0.981348	val: 0.793274	test: 0.787916

Epoch: 82
Loss: 0.2560970699834602
ROC train: 0.983721	val: 0.830020	test: 0.841777
PRC train: 0.980339	val: 0.818216	test: 0.780900

Epoch: 83
Loss: 0.22772456406520275
ROC train: 0.981242	val: 0.831424	test: 0.848055
PRC train: 0.977406	val: 0.813009	test: 0.789399

Epoch: 84
Loss: 0.2313151091824148
ROC train: 0.981247	val: 0.824139	test: 0.849646
PRC train: 0.977596	val: 0.794425	test: 0.792991

Epoch: 85
Loss: 0.24083822141940436
ROC train: 0.981492	val: 0.822778	test: 0.848497
PRC train: 0.977926	val: 0.793165	test: 0.788326

Epoch: 86
Loss: 0.24929577365626232
ROC train: 0.984128	val: 0.827957	test: 0.849293
PRC train: 0.981137	val: 0.802526	test: 0.781658

Epoch: 87
Loss: 0.2558356353245427
ROC train: 0.984407	val: 0.831161	test: 0.851282
PRC train: 0.981727	val: 0.810119	test: 0.779517

Epoch: 88
Loss: 0.24939403180047243
ROC train: 0.986152	val: 0.827079	test: 0.847436
PRC train: 0.983850	val: 0.803745	test: 0.769619

Epoch: 89
Loss: 0.2522433647891894
ROC train: 0.987078	val: 0.828835	test: 0.853802
PRC train: 0.984384	val: 0.808114	test: 0.783167

Epoch: 90
Loss: 0.2297269001867004
ROC train: 0.986899	val: 0.831161	test: 0.851680
PRC train: 0.984084	val: 0.811600	test: 0.780277

Epoch: 91
Loss: 0.2275941561002561
ROC train: 0.985936	val: 0.829142	test: 0.843148
PRC train: 0.983002	val: 0.809685	test: 0.776474

Epoch: 92
Loss: 0.2211467702639986
ROC train: 0.986847	val: 0.833268	test: 0.840141
PRC train: 0.984267	val: 0.813846	test: 0.773039

Epoch: 93
Loss: 0.24420968606151022
ROC train: 0.987509	val: 0.830985	test: 0.840053
PRC train: 0.985602	val: 0.804758	test: 0.774308

Epoch: 94
Loss: 0.251345175845146
ROC train: 0.988523	val: 0.828791	test: 0.839965
PRC train: 0.907459	val: 0.754514	test: 0.794930

Epoch: 34
Loss: 0.36822870608001157
ROC train: 0.924730	val: 0.795986	test: 0.867233
PRC train: 0.910504	val: 0.755310	test: 0.802568

Epoch: 35
Loss: 0.4186289951327925
ROC train: 0.925376	val: 0.794569	test: 0.870274
PRC train: 0.910393	val: 0.754867	test: 0.810947

Epoch: 36
Loss: 0.39144175873569986
ROC train: 0.927629	val: 0.788981	test: 0.871287
PRC train: 0.910754	val: 0.754944	test: 0.814843

Epoch: 37
Loss: 0.3889917427870043
ROC train: 0.931097	val: 0.793625	test: 0.870352
PRC train: 0.913231	val: 0.763435	test: 0.808729

Epoch: 38
Loss: 0.36597253063447105
ROC train: 0.929807	val: 0.790555	test: 0.873860
PRC train: 0.912148	val: 0.751494	test: 0.811677

Epoch: 39
Loss: 0.40052819180197885
ROC train: 0.930707	val: 0.796065	test: 0.873548
PRC train: 0.914128	val: 0.755516	test: 0.806198

Epoch: 40
Loss: 0.39709367028156306
ROC train: 0.928706	val: 0.794097	test: 0.874795
PRC train: 0.914094	val: 0.762085	test: 0.812037

Epoch: 41
Loss: 0.3907106270682045
ROC train: 0.929448	val: 0.797245	test: 0.875185
PRC train: 0.915434	val: 0.767112	test: 0.809921

Epoch: 42
Loss: 0.36970157042881313
ROC train: 0.933836	val: 0.795041	test: 0.876277
PRC train: 0.918399	val: 0.771406	test: 0.810219

Epoch: 43
Loss: 0.33222602581161487
ROC train: 0.930635	val: 0.787564	test: 0.868792
PRC train: 0.913470	val: 0.766920	test: 0.789560

Epoch: 44
Loss: 0.3641201238425818
ROC train: 0.933591	val: 0.797009	test: 0.871443
PRC train: 0.917111	val: 0.779962	test: 0.800909

Epoch: 45
Loss: 0.3816542211181935
ROC train: 0.936655	val: 0.803227	test: 0.878459
PRC train: 0.921833	val: 0.783079	test: 0.813189

Epoch: 46
Loss: 0.3460063853462253
ROC train: 0.935592	val: 0.796773	test: 0.870508
PRC train: 0.920440	val: 0.768595	test: 0.809341

Epoch: 47
Loss: 0.391981688581552
ROC train: 0.937036	val: 0.795356	test: 0.870274
PRC train: 0.921774	val: 0.764707	test: 0.802864

Epoch: 48
Loss: 0.3439248134953635
ROC train: 0.941887	val: 0.796537	test: 0.878070
PRC train: 0.926605	val: 0.764916	test: 0.806125

Epoch: 49
Loss: 0.35855608798417615
ROC train: 0.938766	val: 0.793939	test: 0.882981
PRC train: 0.925271	val: 0.767311	test: 0.809518

Epoch: 50
Loss: 0.3552488228051631
ROC train: 0.936738	val: 0.793231	test: 0.879551
PRC train: 0.923840	val: 0.769136	test: 0.809632

Epoch: 51
Loss: 0.3959737644090552
ROC train: 0.943265	val: 0.796930	test: 0.876822
PRC train: 0.932260	val: 0.775424	test: 0.806452

Epoch: 52
Loss: 0.3616205662023803
ROC train: 0.942051	val: 0.788981	test: 0.863179
PRC train: 0.930298	val: 0.773403	test: 0.793647

Epoch: 53
Loss: 0.3387585741108165
ROC train: 0.942083	val: 0.790948	test: 0.867545
PRC train: 0.927245	val: 0.773545	test: 0.808456

Epoch: 54
Loss: 0.3720675547797551
ROC train: 0.938821	val: 0.788430	test: 0.875653
PRC train: 0.922512	val: 0.770276	test: 0.817399

Epoch: 55
Loss: 0.3315553574307459
ROC train: 0.939105	val: 0.783865	test: 0.871989
PRC train: 0.926611	val: 0.763844	test: 0.815895

Epoch: 56
Loss: 0.37143080102378445
ROC train: 0.939949	val: 0.781110	test: 0.863959
PRC train: 0.928050	val: 0.761673	test: 0.804413

Epoch: 57
Loss: 0.36938794407925746
ROC train: 0.945470	val: 0.787249	test: 0.861776
PRC train: 0.933372	val: 0.769230	test: 0.802639

Epoch: 58
Loss: 0.3428401911972695
ROC train: 0.943734	val: 0.784809	test: 0.865752
PRC train: 0.932817	val: 0.769758	test: 0.799477

Epoch: 59
Loss: 0.3494575568686692
ROC train: 0.943674	val: 0.793703	test: 0.866298
PRC train: 0.931306	val: 0.776800	test: 0.788408

Epoch: 60
Loss: 0.3509735665383944
ROC train: 0.942791	val: 0.794805	test: 0.869026
PRC train: 0.928028	val: 0.773737	test: 0.796389

Epoch: 61
Loss: 0.3596585097920197
ROC train: 0.943182	val: 0.793625	test: 0.876355
PRC train: 0.928120	val: 0.774942	test: 0.821091

Epoch: 62
Loss: 0.359701015077771
ROC train: 0.945420	val: 0.789453	test: 0.879005
PRC train: 0.931863	val: 0.765720	test: 0.819920

Epoch: 63
Loss: 0.35632507150839215
ROC train: 0.944842	val: 0.785360	test: 0.873470
PRC train: 0.932334	val: 0.759009	test: 0.803031

Epoch: 64
Loss: 0.33301820237518964
ROC train: 0.944249	val: 0.787643	test: 0.864115
PRC train: 0.932357	val: 0.760453	test: 0.788246

Epoch: 65
Loss: 0.32959878418304484
ROC train: 0.947949	val: 0.788508	test: 0.866220
PRC train: 0.936704	val: 0.770699	test: 0.792345

Epoch: 66
Loss: 0.33544225785160486
ROC train: 0.947511	val: 0.786226	test: 0.869260
PRC train: 0.936270	val: 0.763410	test: 0.792827

Epoch: 67
Loss: 0.332295972820115
ROC train: 0.946429	val: 0.792287	test: 0.878927
PRC train: 0.929068	val: 0.770036	test: 0.817621

Epoch: 68
Loss: 0.35360341432139
ROC train: 0.948398	val: 0.797245	test: 0.879863
PRC train: 0.933057	val: 0.772183	test: 0.823770

Epoch: 69
Loss: 0.3515269623925987
ROC train: 0.951160	val: 0.790555	test: 0.877680
PRC train: 0.940158	val: 0.769065	test: 0.824087

Epoch: 70
Loss: 0.3126222013936892
ROC train: 0.949030	val: 0.791421	test: 0.870508
PRC train: 0.938094	val: 0.767666	test: 0.819485

Epoch: 71
Loss: 0.3460959736490751
ROC train: 0.952241	val: 0.797639	test: 0.878693
PRC train: 0.940776	val: 0.772275	test: 0.832127

Epoch: 72
Loss: 0.31566020812063883
ROC train: 0.953820	val: 0.803699	test: 0.884385
PRC train: 0.940436	val: 0.778218	test: 0.835379

Epoch: 73
Loss: 0.34441996077773057
ROC train: 0.954519	val: 0.800630	test: 0.882825
PRC train: 0.942797	val: 0.775413	test: 0.832862

Epoch: 74
Loss: 0.3213724439781139
ROC train: 0.955805	val: 0.800315	test: 0.877914
PRC train: 0.946205	val: 0.777154	test: 0.825048

Epoch: 75
Loss: 0.31572986930420444
ROC train: 0.956832	val: 0.806297	test: 0.872846
PRC train: 0.947816	val: 0.785356	test: 0.810343

Epoch: 76
Loss: 0.32662266868330503
ROC train: 0.954777	val: 0.800551	test: 0.873392
PRC train: 0.946061	val: 0.774849	test: 0.804734

Epoch: 77
Loss: 0.3317688322657702
ROC train: 0.952374	val: 0.793388	test: 0.874717
PRC train: 0.943029	val: 0.753252	test: 0.804864

Epoch: 78
Loss: 0.37623130884740225
ROC train: 0.956516	val: 0.804644	test: 0.867155
PRC train: 0.948194	val: 0.771706	test: 0.796167

Epoch: 79
Loss: 0.31933301040774165
ROC train: 0.956494	val: 0.809130	test: 0.865752
PRC train: 0.945818	val: 0.781365	test: 0.788012

Epoch: 80
Loss: 0.35230969878793184
ROC train: 0.954544	val: 0.800394	test: 0.880876
PRC train: 0.942610	val: 0.769008	test: 0.803019

Epoch: 81
Loss: 0.2965226371768205
ROC train: 0.955043	val: 0.798505	test: 0.886879
PRC train: 0.944811	val: 0.768576	test: 0.812794

Epoch: 82
Loss: 0.3187590042187528
ROC train: 0.956818	val: 0.799843	test: 0.886178
PRC train: 0.946015	val: 0.769958	test: 0.828578

Epoch: 83
Loss: 0.31602685598180813
ROC train: 0.958783	val: 0.796537	test: 0.884073
PRC train: 0.948977	val: 0.773006	test: 0.826851

Epoch: 84
Loss: 0.3263731210112774
ROC train: 0.957730	val: 0.797875	test: 0.879941
PRC train: 0.948759	val: 0.761766	test: 0.808350

Epoch: 85
Loss: 0.3659728792961523
ROC train: 0.954928	val: 0.805274	test: 0.888205
PRC train: 0.945920	val: 0.782631	test: 0.816890

Epoch: 86
Loss: 0.3366097541585673
ROC train: 0.955363	val: 0.800079	test: 0.882669
PRC train: 0.947106	val: 0.773024	test: 0.826569

Epoch: 87
Loss: 0.3057560386936145
ROC train: 0.956545	val: 0.797324	test: 0.880019
PRC train: 0.949292	val: 0.766600	test: 0.820977

Epoch: 88
Loss: 0.3070307201571675
ROC train: 0.957486	val: 0.801495	test: 0.876510
PRC train: 0.949707	val: 0.770950	test: 0.814848

Epoch: 89
Loss: 0.3489530156426082
ROC train: 0.959099	val: 0.800000	test: 0.868325
PRC train: 0.950911	val: 0.773197	test: 0.807209

Epoch: 90
Loss: 0.359123940443567
ROC train: 0.959713	val: 0.799370	test: 0.867077
PRC train: 0.952266	val: 0.775034	test: 0.799020

Epoch: 91
Loss: 0.32716116906712733
ROC train: 0.960219	val: 0.812436	test: 0.870040
PRC train: 0.951544	val: 0.789326	test: 0.799288

Epoch: 92
Loss: 0.3022889742524717
ROC train: 0.959555	val: 0.825108	test: 0.879551
PRC train: 0.949891	val: 0.805919	test: 0.809791

Epoch: 93
Loss: 0.36022449274553847
ROC train: 0.960810	val: 0.823849	test: 0.875107
PRC train: 0.951239	val: 0.804699	test: 0.816239

Epoch: 94
Loss: 0.28905272280344324
ROC train: 0.958592	val: 0.809288	test: 0.877914
PRC train: 0.904034	val: 0.782510	test: 0.790828

Epoch: 34
Loss: 0.35910804998332146
ROC train: 0.924863	val: 0.800315	test: 0.862945
PRC train: 0.905965	val: 0.780551	test: 0.787740

Epoch: 35
Loss: 0.3729736602771883
ROC train: 0.928164	val: 0.803935	test: 0.871443
PRC train: 0.908981	val: 0.775772	test: 0.797027

Epoch: 36
Loss: 0.3971761467927852
ROC train: 0.928530	val: 0.808186	test: 0.877446
PRC train: 0.909679	val: 0.777024	test: 0.811646

Epoch: 37
Loss: 0.3748841603660698
ROC train: 0.927375	val: 0.803070	test: 0.869182
PRC train: 0.907492	val: 0.775384	test: 0.801799

Epoch: 38
Loss: 0.4201123365742359
ROC train: 0.924187	val: 0.801810	test: 0.859437
PRC train: 0.906417	val: 0.780312	test: 0.792580

Epoch: 39
Loss: 0.3941834893176422
ROC train: 0.927427	val: 0.809209	test: 0.861542
PRC train: 0.909692	val: 0.786984	test: 0.795004

Epoch: 40
Loss: 0.3800558342402479
ROC train: 0.928922	val: 0.815112	test: 0.866843
PRC train: 0.911569	val: 0.789197	test: 0.800616

Epoch: 41
Loss: 0.3893012481261698
ROC train: 0.933372	val: 0.817946	test: 0.876355
PRC train: 0.914718	val: 0.786324	test: 0.806691

Epoch: 42
Loss: 0.3747057028865261
ROC train: 0.931343	val: 0.808658	test: 0.880019
PRC train: 0.910997	val: 0.769638	test: 0.824795

Epoch: 43
Loss: 0.37870888441788025
ROC train: 0.933433	val: 0.806375	test: 0.876433
PRC train: 0.914037	val: 0.769173	test: 0.816940

Epoch: 44
Loss: 0.3763038700777738
ROC train: 0.935068	val: 0.799055	test: 0.875341
PRC train: 0.917152	val: 0.765672	test: 0.810403

Epoch: 45
Loss: 0.37870334298770303
ROC train: 0.935811	val: 0.807399	test: 0.877446
PRC train: 0.918248	val: 0.773699	test: 0.810239

Epoch: 46
Loss: 0.3840169404905257
ROC train: 0.938672	val: 0.821251	test: 0.881344
PRC train: 0.921971	val: 0.786854	test: 0.821245

Epoch: 47
Loss: 0.40486290245453044
ROC train: 0.935132	val: 0.829280	test: 0.882280
PRC train: 0.920541	val: 0.805205	test: 0.822222

Epoch: 48
Loss: 0.3567970599028079
ROC train: 0.936508	val: 0.820150	test: 0.871833
PRC train: 0.920800	val: 0.797309	test: 0.806229

Epoch: 49
Loss: 0.37140939868617406
ROC train: 0.937410	val: 0.815427	test: 0.870585
PRC train: 0.920937	val: 0.792269	test: 0.807597

Epoch: 50
Loss: 0.3735313224004933
ROC train: 0.937561	val: 0.809524	test: 0.881110
PRC train: 0.922346	val: 0.790003	test: 0.825971

Epoch: 51
Loss: 0.38678064828886394
ROC train: 0.942367	val: 0.812043	test: 0.878382
PRC train: 0.928519	val: 0.790702	test: 0.816461

Epoch: 52
Loss: 0.3760358218614789
ROC train: 0.942872	val: 0.819599	test: 0.872379
PRC train: 0.927424	val: 0.791622	test: 0.808600

Epoch: 53
Loss: 0.358772028411608
ROC train: 0.941684	val: 0.817237	test: 0.874639
PRC train: 0.924576	val: 0.785814	test: 0.799563

Epoch: 54
Loss: 0.4420768078138244
ROC train: 0.939622	val: 0.809839	test: 0.869806
PRC train: 0.922215	val: 0.777793	test: 0.791816

Epoch: 55
Loss: 0.349313669378314
ROC train: 0.941713	val: 0.805746	test: 0.858112
PRC train: 0.925745	val: 0.764518	test: 0.780943

Epoch: 56
Loss: 0.3591320392894427
ROC train: 0.942988	val: 0.812279	test: 0.869728
PRC train: 0.928883	val: 0.776622	test: 0.800354

Epoch: 57
Loss: 0.38981170145497035
ROC train: 0.942151	val: 0.815899	test: 0.878927
PRC train: 0.927358	val: 0.781744	test: 0.818330

Epoch: 58
Loss: 0.3510606902022502
ROC train: 0.941868	val: 0.811885	test: 0.875731
PRC train: 0.926564	val: 0.781114	test: 0.820162

Epoch: 59
Loss: 0.36647526415064136
ROC train: 0.943656	val: 0.811570	test: 0.875263
PRC train: 0.928549	val: 0.782286	test: 0.819062

Epoch: 60
Loss: 0.3611176536047948
ROC train: 0.941819	val: 0.819048	test: 0.880564
PRC train: 0.926996	val: 0.787981	test: 0.824121

Epoch: 61
Loss: 0.34052699918943696
ROC train: 0.944414	val: 0.816450	test: 0.880564
PRC train: 0.930133	val: 0.780988	test: 0.820532

Epoch: 62
Loss: 0.3430372071587769
ROC train: 0.946313	val: 0.815427	test: 0.871209
PRC train: 0.932349	val: 0.771479	test: 0.802416

Epoch: 63
Loss: 0.35828780923187564
ROC train: 0.944644	val: 0.811728	test: 0.870663
PRC train: 0.930505	val: 0.771543	test: 0.800680

Epoch: 64
Loss: 0.34326661835130556
ROC train: 0.944439	val: 0.816135	test: 0.871833
PRC train: 0.930040	val: 0.781162	test: 0.798556

Epoch: 65
Loss: 0.34966314833437956
ROC train: 0.942320	val: 0.824164	test: 0.872379
PRC train: 0.927671	val: 0.793976	test: 0.792470

Epoch: 66
Loss: 0.33619696791870296
ROC train: 0.944878	val: 0.821251	test: 0.872846
PRC train: 0.929563	val: 0.786409	test: 0.804665

Epoch: 67
Loss: 0.31922312309655443
ROC train: 0.946819	val: 0.815427	test: 0.875185
PRC train: 0.933051	val: 0.776518	test: 0.811042

Epoch: 68
Loss: 0.31814446095273535
ROC train: 0.948157	val: 0.818575	test: 0.876510
PRC train: 0.934473	val: 0.782254	test: 0.814920

Epoch: 69
Loss: 0.3141540255621041
ROC train: 0.947166	val: 0.819205	test: 0.877758
PRC train: 0.932373	val: 0.784971	test: 0.814419

Epoch: 70
Loss: 0.3496793631339187
ROC train: 0.949555	val: 0.820701	test: 0.869416
PRC train: 0.936655	val: 0.791204	test: 0.801361

Epoch: 71
Loss: 0.33312966355617035
ROC train: 0.951598	val: 0.820071	test: 0.859827
PRC train: 0.941548	val: 0.791264	test: 0.790568

Epoch: 72
Loss: 0.3363197972994613
ROC train: 0.950246	val: 0.815506	test: 0.864738
PRC train: 0.938780	val: 0.784304	test: 0.791375

Epoch: 73
Loss: 0.36351205458558755
ROC train: 0.948922	val: 0.819284	test: 0.870508
PRC train: 0.936260	val: 0.786369	test: 0.802298

Epoch: 74
Loss: 0.3229342263825284
ROC train: 0.944353	val: 0.821802	test: 0.875419
PRC train: 0.931315	val: 0.789771	test: 0.819044

Epoch: 75
Loss: 0.31497227676382256
ROC train: 0.952444	val: 0.829201	test: 0.874561
PRC train: 0.942852	val: 0.799455	test: 0.815943

Epoch: 76
Loss: 0.3570110712598501
ROC train: 0.953915	val: 0.825423	test: 0.868792
PRC train: 0.944235	val: 0.795398	test: 0.808852

Epoch: 77
Loss: 0.3085599943151507
ROC train: 0.952978	val: 0.825030	test: 0.877212
PRC train: 0.941522	val: 0.795437	test: 0.819531

Epoch: 78
Loss: 0.3263796155253146
ROC train: 0.950111	val: 0.826289	test: 0.884774
PRC train: 0.937603	val: 0.797562	test: 0.830627

Epoch: 79
Loss: 0.3108615739514955
ROC train: 0.950068	val: 0.828965	test: 0.877680
PRC train: 0.938577	val: 0.796707	test: 0.823700

Epoch: 80
Loss: 0.327166756423814
ROC train: 0.951595	val: 0.823062	test: 0.864505
PRC train: 0.941014	val: 0.789159	test: 0.804177

Epoch: 81
Loss: 0.3209816691226182
ROC train: 0.953835	val: 0.814325	test: 0.860684
PRC train: 0.942401	val: 0.777067	test: 0.796476

Epoch: 82
Loss: 0.31611294600277307
ROC train: 0.952673	val: 0.822747	test: 0.872846
PRC train: 0.941648	val: 0.790274	test: 0.818803

Epoch: 83
Loss: 0.3462632199825274
ROC train: 0.949515	val: 0.821645	test: 0.875419
PRC train: 0.935469	val: 0.787330	test: 0.820978

Epoch: 84
Loss: 0.3630471719680327
ROC train: 0.953984	val: 0.819126	test: 0.871755
PRC train: 0.943204	val: 0.782391	test: 0.811988

Epoch: 85
Loss: 0.3011769692023022
ROC train: 0.957145	val: 0.810783	test: 0.866142
PRC train: 0.948567	val: 0.773442	test: 0.808890

Epoch: 86
Loss: 0.3124493271123706
ROC train: 0.959494	val: 0.810704	test: 0.870118
PRC train: 0.950499	val: 0.776402	test: 0.816708

Epoch: 87
Loss: 0.3435617411871087
ROC train: 0.958513	val: 0.817395	test: 0.876199
PRC train: 0.948519	val: 0.784296	test: 0.824958

Epoch: 88
Loss: 0.2942160730981847
ROC train: 0.956811	val: 0.816450	test: 0.880175
PRC train: 0.946803	val: 0.783566	test: 0.829759

Epoch: 89
Loss: 0.33111238214095007
ROC train: 0.955140	val: 0.814404	test: 0.866064
PRC train: 0.945219	val: 0.783968	test: 0.812616

Epoch: 90
Loss: 0.3040401227807873
ROC train: 0.957583	val: 0.819048	test: 0.861932
PRC train: 0.947653	val: 0.790409	test: 0.812642

Epoch: 91
Loss: 0.30677517192225806
ROC train: 0.958429	val: 0.817080	test: 0.866843
PRC train: 0.948663	val: 0.783953	test: 0.818119

Epoch: 92
Loss: 0.32726950308318303
ROC train: 0.958678	val: 0.822904	test: 0.875185
PRC train: 0.949376	val: 0.786780	test: 0.821273

Epoch: 93
Loss: 0.29325384070837507
ROC train: 0.959835	val: 0.823377	test: 0.876744
PRC train: 0.951340	val: 0.789265	test: 0.820074

Epoch: 94
Loss: 0.2865725673935716
ROC train: 0.961405	val: 0.823613	test: 0.871599
PRC train: 0.912211	val: 0.789077	test: 0.782012

Epoch: 34
Loss: 0.3824439263680107
ROC train: 0.922697	val: 0.802125	test: 0.861230
PRC train: 0.908001	val: 0.764966	test: 0.782121

Epoch: 35
Loss: 0.4014076249626536
ROC train: 0.927016	val: 0.813302	test: 0.871911
PRC train: 0.912234	val: 0.787845	test: 0.794362

Epoch: 36
Loss: 0.38602423311547207
ROC train: 0.921001	val: 0.813144	test: 0.871053
PRC train: 0.904328	val: 0.786478	test: 0.799053

Epoch: 37
Loss: 0.39564952000305426
ROC train: 0.926896	val: 0.812436	test: 0.867857
PRC train: 0.911612	val: 0.783873	test: 0.788008

Epoch: 38
Loss: 0.37328787483558423
ROC train: 0.931461	val: 0.803384	test: 0.863647
PRC train: 0.916165	val: 0.764100	test: 0.789581

Epoch: 39
Loss: 0.3927609553933713
ROC train: 0.932672	val: 0.809366	test: 0.872768
PRC train: 0.919899	val: 0.777883	test: 0.801056

Epoch: 40
Loss: 0.3841488085142581
ROC train: 0.931400	val: 0.811649	test: 0.874016
PRC train: 0.918965	val: 0.786423	test: 0.799183

Epoch: 41
Loss: 0.36153221515843736
ROC train: 0.932984	val: 0.815427	test: 0.873158
PRC train: 0.919807	val: 0.788535	test: 0.796162

Epoch: 42
Loss: 0.40501250621797497
ROC train: 0.937905	val: 0.818182	test: 0.881656
PRC train: 0.925206	val: 0.788653	test: 0.809009

Epoch: 43
Loss: 0.40943956367224443
ROC train: 0.934101	val: 0.815584	test: 0.878849
PRC train: 0.918669	val: 0.781764	test: 0.814982

Epoch: 44
Loss: 0.3837708461021096
ROC train: 0.930107	val: 0.813932	test: 0.881266
PRC train: 0.912929	val: 0.779803	test: 0.818598

Epoch: 45
Loss: 0.38392001156765276
ROC train: 0.935140	val: 0.818261	test: 0.878849
PRC train: 0.920493	val: 0.782303	test: 0.807554

Epoch: 46
Loss: 0.37148352571649274
ROC train: 0.933189	val: 0.817001	test: 0.874094
PRC train: 0.917830	val: 0.786008	test: 0.793757

Epoch: 47
Loss: 0.39803521767119365
ROC train: 0.934640	val: 0.819835	test: 0.882903
PRC train: 0.921980	val: 0.792034	test: 0.805801

Epoch: 48
Loss: 0.36175976251671615
ROC train: 0.939928	val: 0.820937	test: 0.885008
PRC train: 0.929403	val: 0.798822	test: 0.810481

Epoch: 49
Loss: 0.3774659033171197
ROC train: 0.940449	val: 0.810547	test: 0.872612
PRC train: 0.929065	val: 0.788658	test: 0.798707

Epoch: 50
Loss: 0.36025477195232924
ROC train: 0.936517	val: 0.802046	test: 0.865518
PRC train: 0.923143	val: 0.772414	test: 0.797090

Epoch: 51
Loss: 0.3939381038061164
ROC train: 0.940556	val: 0.815427	test: 0.879707
PRC train: 0.929340	val: 0.787269	test: 0.807503

Epoch: 52
Loss: 0.3891312145400813
ROC train: 0.940937	val: 0.820937	test: 0.886957
PRC train: 0.932769	val: 0.796842	test: 0.819278

Epoch: 53
Loss: 0.36270234680010244
ROC train: 0.937140	val: 0.821015	test: 0.879785
PRC train: 0.927056	val: 0.799312	test: 0.812968

Epoch: 54
Loss: 0.35644807845596665
ROC train: 0.936061	val: 0.819835	test: 0.871833
PRC train: 0.923572	val: 0.796911	test: 0.796420

Epoch: 55
Loss: 0.35893200456377106
ROC train: 0.939741	val: 0.827470	test: 0.887581
PRC train: 0.928554	val: 0.802484	test: 0.819329

Epoch: 56
Loss: 0.34676603296536707
ROC train: 0.941515	val: 0.824715	test: 0.893428
PRC train: 0.931215	val: 0.791743	test: 0.834439

Epoch: 57
Loss: 0.35625739624343095
ROC train: 0.943735	val: 0.815899	test: 0.892336
PRC train: 0.932489	val: 0.781341	test: 0.821693

Epoch: 58
Loss: 0.3601443822677954
ROC train: 0.947408	val: 0.823770	test: 0.897248
PRC train: 0.935891	val: 0.789169	test: 0.823745

Epoch: 59
Loss: 0.35382417100818697
ROC train: 0.944659	val: 0.827076	test: 0.896702
PRC train: 0.932917	val: 0.798135	test: 0.824616

Epoch: 60
Loss: 0.42244467727130475
ROC train: 0.947268	val: 0.823455	test: 0.886489
PRC train: 0.937188	val: 0.793281	test: 0.815718

Epoch: 61
Loss: 0.3418237734340107
ROC train: 0.938940	val: 0.810232	test: 0.862634
PRC train: 0.927100	val: 0.769489	test: 0.797547

Epoch: 62
Loss: 0.36987638096465036
ROC train: 0.946904	val: 0.827470	test: 0.869494
PRC train: 0.934791	val: 0.801541	test: 0.797825

Epoch: 63
Loss: 0.3578151539325684
ROC train: 0.944871	val: 0.832035	test: 0.878615
PRC train: 0.933254	val: 0.811066	test: 0.822023

Epoch: 64
Loss: 0.3745352915983303
ROC train: 0.943112	val: 0.833688	test: 0.883371
PRC train: 0.930026	val: 0.810181	test: 0.826530

Epoch: 65
Loss: 0.3378756163639559
ROC train: 0.942302	val: 0.824242	test: 0.881422
PRC train: 0.928385	val: 0.798956	test: 0.828522

Epoch: 66
Loss: 0.36130672713445
ROC train: 0.946038	val: 0.815270	test: 0.878459
PRC train: 0.935548	val: 0.791651	test: 0.811699

Epoch: 67
Loss: 0.34197598724016187
ROC train: 0.950812	val: 0.815663	test: 0.874172
PRC train: 0.940328	val: 0.786185	test: 0.797200

Epoch: 68
Loss: 0.3435997080876434
ROC train: 0.951498	val: 0.824006	test: 0.884930
PRC train: 0.940697	val: 0.787843	test: 0.814816

Epoch: 69
Loss: 0.33121153755532107
ROC train: 0.950700	val: 0.824164	test: 0.893974
PRC train: 0.940776	val: 0.790589	test: 0.829627

Epoch: 70
Loss: 0.3362622364472089
ROC train: 0.951322	val: 0.827391	test: 0.891713
PRC train: 0.941037	val: 0.796912	test: 0.826069

Epoch: 71
Loss: 0.3051696050281805
ROC train: 0.952924	val: 0.824164	test: 0.887269
PRC train: 0.942498	val: 0.794070	test: 0.819128

Epoch: 72
Loss: 0.31837543100265064
ROC train: 0.954469	val: 0.821960	test: 0.878304
PRC train: 0.944422	val: 0.792596	test: 0.810217

Epoch: 73
Loss: 0.3432905413101796
ROC train: 0.955751	val: 0.817788	test: 0.870975
PRC train: 0.947296	val: 0.787195	test: 0.814830

Epoch: 74
Loss: 0.3490668686656062
ROC train: 0.954666	val: 0.823219	test: 0.873548
PRC train: 0.947008	val: 0.794502	test: 0.821293

Epoch: 75
Loss: 0.33381325523820354
ROC train: 0.950496	val: 0.826446	test: 0.873860
PRC train: 0.942170	val: 0.803771	test: 0.801529

Epoch: 76
Loss: 0.3186824643169253
ROC train: 0.949921	val: 0.819599	test: 0.871053
PRC train: 0.940316	val: 0.797372	test: 0.791498

Epoch: 77
Loss: 0.31365650226637504
ROC train: 0.954734	val: 0.823613	test: 0.871209
PRC train: 0.944013	val: 0.792927	test: 0.795071

Epoch: 78
Loss: 0.32164894382483517
ROC train: 0.956656	val: 0.834002	test: 0.876900
PRC train: 0.946410	val: 0.806852	test: 0.815660

Epoch: 79
Loss: 0.3215705430873891
ROC train: 0.957867	val: 0.829909	test: 0.879395
PRC train: 0.948887	val: 0.802291	test: 0.824286

Epoch: 80
Loss: 0.3504738390414391
ROC train: 0.958664	val: 0.826761	test: 0.883839
PRC train: 0.950155	val: 0.799982	test: 0.829049

Epoch: 81
Loss: 0.32849448784110286
ROC train: 0.959602	val: 0.820307	test: 0.880097
PRC train: 0.951272	val: 0.794240	test: 0.815977

Epoch: 82
Loss: 0.32745762463549316
ROC train: 0.957730	val: 0.813617	test: 0.870897
PRC train: 0.949577	val: 0.782316	test: 0.804945

Epoch: 83
Loss: 0.30350031073908273
ROC train: 0.959709	val: 0.821960	test: 0.874016
PRC train: 0.951699	val: 0.793349	test: 0.811612

Epoch: 84
Loss: 0.32334649571173796
ROC train: 0.959609	val: 0.822590	test: 0.874873
PRC train: 0.951369	val: 0.794644	test: 0.812322

Epoch: 85
Loss: 0.2979716649757272
ROC train: 0.957723	val: 0.824636	test: 0.868169
PRC train: 0.948947	val: 0.790398	test: 0.803262

Epoch: 86
Loss: 0.31457161872315925
ROC train: 0.958919	val: 0.826446	test: 0.874484
PRC train: 0.950412	val: 0.796344	test: 0.807997

Epoch: 87
Loss: 0.33905877603832246
ROC train: 0.959508	val: 0.825344	test: 0.875653
PRC train: 0.951048	val: 0.798251	test: 0.809898

Epoch: 88
Loss: 0.2975851875886202
ROC train: 0.960751	val: 0.826289	test: 0.874250
PRC train: 0.951393	val: 0.798298	test: 0.804693

Epoch: 89
Loss: 0.3038940288792401
ROC train: 0.963598	val: 0.824951	test: 0.875029
PRC train: 0.954517	val: 0.796741	test: 0.811035

Epoch: 90
Loss: 0.32763797552656637
ROC train: 0.962197	val: 0.822668	test: 0.874717
PRC train: 0.954007	val: 0.788221	test: 0.811106

Epoch: 91
Loss: 0.3350566335418447
ROC train: 0.958610	val: 0.815978	test: 0.867311
PRC train: 0.950075	val: 0.781783	test: 0.795718

Epoch: 92
Loss: 0.32310327498670494
ROC train: 0.960509	val: 0.819520	test: 0.865830
PRC train: 0.950942	val: 0.797492	test: 0.796367

Epoch: 93
Loss: 0.2840740544534238
ROC train: 0.962030	val: 0.825502	test: 0.864738
PRC train: 0.951974	val: 0.806323	test: 0.802688

Epoch: 94
Loss: 0.34865351910878734
ROC train: 0.963079	val: 0.826604	test: 0.864193
PRC train: 0.919377	val: 0.744904	test: 0.801647

Epoch: 34
Loss: 0.3742410295849815
ROC train: 0.934339	val: 0.845959	test: 0.875350
PRC train: 0.921942	val: 0.740939	test: 0.817130

Epoch: 35
Loss: 0.36874499949574785
ROC train: 0.939133	val: 0.848677	test: 0.881303
PRC train: 0.926309	val: 0.750182	test: 0.832009

Epoch: 36
Loss: 0.38040017726175673
ROC train: 0.938137	val: 0.856289	test: 0.884104
PRC train: 0.924679	val: 0.757760	test: 0.840611

Epoch: 37
Loss: 0.3699010840177817
ROC train: 0.939574	val: 0.846865	test: 0.880777
PRC train: 0.927681	val: 0.748579	test: 0.839645

Epoch: 38
Loss: 0.3621692751078304
ROC train: 0.937404	val: 0.844690	test: 0.879552
PRC train: 0.924660	val: 0.745940	test: 0.838134

Epoch: 39
Loss: 0.37838924650178174
ROC train: 0.938424	val: 0.844146	test: 0.880777
PRC train: 0.925046	val: 0.740332	test: 0.839900

Epoch: 40
Loss: 0.3535024315985838
ROC train: 0.941008	val: 0.841428	test: 0.871674
PRC train: 0.929436	val: 0.737281	test: 0.831863

Epoch: 41
Loss: 0.352269019632074
ROC train: 0.942653	val: 0.839253	test: 0.882003
PRC train: 0.930606	val: 0.733525	test: 0.842336

Epoch: 42
Loss: 0.36357625493558965
ROC train: 0.944533	val: 0.840884	test: 0.887780
PRC train: 0.933556	val: 0.734630	test: 0.847100

Epoch: 43
Loss: 0.36987813233598893
ROC train: 0.946190	val: 0.843240	test: 0.886555
PRC train: 0.936065	val: 0.734514	test: 0.845698

Epoch: 44
Loss: 0.35183839677179807
ROC train: 0.946530	val: 0.839435	test: 0.881828
PRC train: 0.936916	val: 0.736086	test: 0.843444

Epoch: 45
Loss: 0.34802924689405246
ROC train: 0.947536	val: 0.840884	test: 0.884629
PRC train: 0.937566	val: 0.731821	test: 0.845488

Epoch: 46
Loss: 0.3487569732148791
ROC train: 0.947539	val: 0.838347	test: 0.868522
PRC train: 0.937110	val: 0.725664	test: 0.826266

Epoch: 47
Loss: 0.3497283566867284
ROC train: 0.948044	val: 0.841247	test: 0.858543
PRC train: 0.938693	val: 0.726484	test: 0.814200

Epoch: 48
Loss: 0.34527148879486247
ROC train: 0.948355	val: 0.852664	test: 0.863270
PRC train: 0.939338	val: 0.746004	test: 0.819668

Epoch: 49
Loss: 0.3396286008298976
ROC train: 0.951656	val: 0.849221	test: 0.872899
PRC train: 0.942847	val: 0.753493	test: 0.830302

Epoch: 50
Loss: 0.3275552581072866
ROC train: 0.953569	val: 0.845959	test: 0.885854
PRC train: 0.945052	val: 0.749388	test: 0.842870

Epoch: 51
Loss: 0.3224901507612696
ROC train: 0.954664	val: 0.849040	test: 0.889531
PRC train: 0.946440	val: 0.762869	test: 0.845970

Epoch: 52
Loss: 0.31562675215216507
ROC train: 0.954609	val: 0.848496	test: 0.888480
PRC train: 0.946301	val: 0.764062	test: 0.846821

Epoch: 53
Loss: 0.331542833563016
ROC train: 0.956756	val: 0.844690	test: 0.881303
PRC train: 0.949520	val: 0.747163	test: 0.838684

Epoch: 54
Loss: 0.30972066290472505
ROC train: 0.954094	val: 0.836897	test: 0.874300
PRC train: 0.946956	val: 0.747048	test: 0.832875

Epoch: 55
Loss: 0.31746237059882454
ROC train: 0.956465	val: 0.848858	test: 0.877451
PRC train: 0.948026	val: 0.759876	test: 0.840844

Epoch: 56
Loss: 0.31102747880193715
ROC train: 0.955240	val: 0.847227	test: 0.896008
PRC train: 0.947236	val: 0.767304	test: 0.859995

Epoch: 57
Loss: 0.3283305881936001
ROC train: 0.957229	val: 0.838891	test: 0.873950
PRC train: 0.950564	val: 0.749702	test: 0.825847

Epoch: 58
Loss: 0.31061158662493005
ROC train: 0.957792	val: 0.845777	test: 0.866947
PRC train: 0.951334	val: 0.736379	test: 0.821106

Epoch: 59
Loss: 0.3201195392862443
ROC train: 0.955732	val: 0.850489	test: 0.866071
PRC train: 0.948674	val: 0.750169	test: 0.822202

Epoch: 60
Loss: 0.3251580538325029
ROC train: 0.958669	val: 0.843059	test: 0.864146
PRC train: 0.952700	val: 0.748395	test: 0.820842

Epoch: 61
Loss: 0.3240120737370483
ROC train: 0.962222	val: 0.831642	test: 0.878676
PRC train: 0.955909	val: 0.743670	test: 0.832378

Epoch: 62
Loss: 0.3158186880583332
ROC train: 0.961726	val: 0.843240	test: 0.871674
PRC train: 0.955642	val: 0.754198	test: 0.821404

Epoch: 63
Loss: 0.29719643150531105
ROC train: 0.961860	val: 0.848133	test: 0.874300
PRC train: 0.955379	val: 0.760781	test: 0.830776

Epoch: 64
Loss: 0.30885585925676323
ROC train: 0.963999	val: 0.845596	test: 0.865371
PRC train: 0.957676	val: 0.748588	test: 0.818014

Epoch: 65
Loss: 0.3001945808434809
ROC train: 0.964686	val: 0.846502	test: 0.865896
PRC train: 0.958797	val: 0.741779	test: 0.825126

Epoch: 66
Loss: 0.30669422245762623
ROC train: 0.963877	val: 0.853208	test: 0.860119
PRC train: 0.958384	val: 0.745828	test: 0.818541

Epoch: 67
Loss: 0.3108585310829751
ROC train: 0.965587	val: 0.846321	test: 0.862045
PRC train: 0.959923	val: 0.736142	test: 0.820997

Epoch: 68
Loss: 0.31528535416903675
ROC train: 0.963650	val: 0.846865	test: 0.873249
PRC train: 0.956815	val: 0.747544	test: 0.830070

Epoch: 69
Loss: 0.3054081719236248
ROC train: 0.964889	val: 0.848677	test: 0.864321
PRC train: 0.959839	val: 0.740009	test: 0.808072

Epoch: 70
Loss: 0.28416814171813665
ROC train: 0.966015	val: 0.849040	test: 0.858193
PRC train: 0.960579	val: 0.747480	test: 0.808424

Epoch: 71
Loss: 0.2995371932389842
ROC train: 0.967092	val: 0.847952	test: 0.860469
PRC train: 0.961742	val: 0.740787	test: 0.815397

Epoch: 72
Loss: 0.30732006820463026
ROC train: 0.967838	val: 0.849402	test: 0.861345
PRC train: 0.963383	val: 0.738544	test: 0.815300

Epoch: 73
Loss: 0.2890076172469864
ROC train: 0.967347	val: 0.848858	test: 0.865721
PRC train: 0.962780	val: 0.741733	test: 0.820475

Epoch: 74
Loss: 0.2971179958212221
ROC train: 0.967242	val: 0.839797	test: 0.870273
PRC train: 0.962321	val: 0.740180	test: 0.815437

Epoch: 75
Loss: 0.3034978639459819
ROC train: 0.968304	val: 0.840884	test: 0.862395
PRC train: 0.962750	val: 0.729868	test: 0.805292

Epoch: 76
Loss: 0.2978250090131039
ROC train: 0.968059	val: 0.849221	test: 0.848564
PRC train: 0.962779	val: 0.750511	test: 0.806923

Epoch: 77
Loss: 0.28131895019071507
ROC train: 0.968413	val: 0.850127	test: 0.840161
PRC train: 0.963949	val: 0.745057	test: 0.792344

Epoch: 78
Loss: 0.28924835774606866
ROC train: 0.970091	val: 0.838347	test: 0.857143
PRC train: 0.965440	val: 0.721354	test: 0.801277

Epoch: 79
Loss: 0.27173703584643355
ROC train: 0.972580	val: 0.843603	test: 0.861345
PRC train: 0.968538	val: 0.740598	test: 0.807492

Epoch: 80
Loss: 0.27443485350330904
ROC train: 0.972283	val: 0.851033	test: 0.859069
PRC train: 0.968112	val: 0.748489	test: 0.812276

Epoch: 81
Loss: 0.28433570920100826
ROC train: 0.971341	val: 0.848496	test: 0.860119
PRC train: 0.967446	val: 0.751233	test: 0.805039

Epoch: 82
Loss: 0.27296415094820187
ROC train: 0.971857	val: 0.839797	test: 0.864496
PRC train: 0.967623	val: 0.751684	test: 0.798700

Epoch: 83
Loss: 0.28881193154932794
ROC train: 0.972964	val: 0.840522	test: 0.869923
PRC train: 0.968633	val: 0.737397	test: 0.827280

Epoch: 84
Loss: 0.2802286958153874
ROC train: 0.971938	val: 0.849221	test: 0.873775
PRC train: 0.967590	val: 0.750912	test: 0.826194

Epoch: 85
Loss: 0.2756112557690256
ROC train: 0.973285	val: 0.843240	test: 0.865371
PRC train: 0.969676	val: 0.738243	test: 0.767865

Epoch: 86
Loss: 0.28728135895737983
ROC train: 0.974656	val: 0.845415	test: 0.863445
PRC train: 0.971377	val: 0.761215	test: 0.788537

Epoch: 87
Loss: 0.28228578506893454
ROC train: 0.973066	val: 0.848315	test: 0.855392
PRC train: 0.968398	val: 0.758695	test: 0.809544

Epoch: 88
Loss: 0.27027834876388074
ROC train: 0.975650	val: 0.850308	test: 0.863445
PRC train: 0.971376	val: 0.767973	test: 0.811550

Epoch: 89
Loss: 0.26546488662187767
ROC train: 0.975672	val: 0.854476	test: 0.863796
PRC train: 0.971742	val: 0.766914	test: 0.804365

Epoch: 90
Loss: 0.2657773880861104
ROC train: 0.975376	val: 0.847408	test: 0.866246
PRC train: 0.971648	val: 0.756970	test: 0.811268

Epoch: 91
Loss: 0.26641595503506454
ROC train: 0.976669	val: 0.845777	test: 0.867472
PRC train: 0.973223	val: 0.754631	test: 0.810235

Epoch: 92
Loss: 0.28836079530333436
ROC train: 0.976889	val: 0.846140	test: 0.863270
PRC train: 0.973524	val: 0.750402	test: 0.806602

Epoch: 93
Loss: 0.2718028679169422
ROC train: 0.978040	val: 0.847408	test: 0.865896
PRC train: 0.975025	val: 0.762066	test: 0.797047

Epoch: 94
Loss: 0.26685980829866046
ROC train: 0.976254	val: 0.838710	test: 0.854517
PRC train: 0.919692	val: 0.766353	test: 0.768478

Epoch: 34
Loss: 0.3678482882342465
ROC train: 0.934736	val: 0.834542	test: 0.853291
PRC train: 0.922208	val: 0.767779	test: 0.772263

Epoch: 35
Loss: 0.3657661298431379
ROC train: 0.935396	val: 0.832548	test: 0.848214
PRC train: 0.922170	val: 0.769918	test: 0.768583

Epoch: 36
Loss: 0.3721257831622757
ROC train: 0.937739	val: 0.830555	test: 0.849965
PRC train: 0.924833	val: 0.756206	test: 0.777812

Epoch: 37
Loss: 0.3720526287196311
ROC train: 0.938964	val: 0.827655	test: 0.845763
PRC train: 0.926179	val: 0.742744	test: 0.775026

Epoch: 38
Loss: 0.3571172875160323
ROC train: 0.938107	val: 0.823487	test: 0.854867
PRC train: 0.925292	val: 0.750218	test: 0.794835

Epoch: 39
Loss: 0.36389344583438454
ROC train: 0.937000	val: 0.823306	test: 0.854867
PRC train: 0.923707	val: 0.750536	test: 0.794698

Epoch: 40
Loss: 0.3589580366824919
ROC train: 0.940894	val: 0.825843	test: 0.846989
PRC train: 0.929493	val: 0.740373	test: 0.778454

Epoch: 41
Loss: 0.3757625931372323
ROC train: 0.940988	val: 0.831098	test: 0.853641
PRC train: 0.929848	val: 0.746523	test: 0.786312

Epoch: 42
Loss: 0.36729419371963273
ROC train: 0.941785	val: 0.832548	test: 0.863620
PRC train: 0.929320	val: 0.762374	test: 0.801391

Epoch: 43
Loss: 0.35073180227944645
ROC train: 0.944130	val: 0.836354	test: 0.865721
PRC train: 0.931797	val: 0.766835	test: 0.802428

Epoch: 44
Loss: 0.35248675621221087
ROC train: 0.946218	val: 0.838528	test: 0.866071
PRC train: 0.935213	val: 0.771742	test: 0.802796

Epoch: 45
Loss: 0.3409862026000665
ROC train: 0.946764	val: 0.829648	test: 0.862745
PRC train: 0.936684	val: 0.760979	test: 0.806444

Epoch: 46
Loss: 0.363250169136936
ROC train: 0.948351	val: 0.828199	test: 0.862745
PRC train: 0.937548	val: 0.757925	test: 0.801165

Epoch: 47
Loss: 0.3498542847287892
ROC train: 0.947961	val: 0.833454	test: 0.860819
PRC train: 0.935773	val: 0.754238	test: 0.799592

Epoch: 48
Loss: 0.3354379240830493
ROC train: 0.948561	val: 0.837804	test: 0.862395
PRC train: 0.937032	val: 0.763081	test: 0.791910

Epoch: 49
Loss: 0.3496773111021327
ROC train: 0.952101	val: 0.835991	test: 0.863971
PRC train: 0.943073	val: 0.764427	test: 0.770455

Epoch: 50
Loss: 0.3384870720454929
ROC train: 0.952164	val: 0.838710	test: 0.850840
PRC train: 0.943275	val: 0.773616	test: 0.752903

Epoch: 51
Loss: 0.35078860796790734
ROC train: 0.952241	val: 0.832729	test: 0.853291
PRC train: 0.942823	val: 0.761097	test: 0.792834

Epoch: 52
Loss: 0.33267254012663855
ROC train: 0.948973	val: 0.840884	test: 0.862395
PRC train: 0.938202	val: 0.777336	test: 0.803537

Epoch: 53
Loss: 0.33134087523932804
ROC train: 0.951837	val: 0.841247	test: 0.863445
PRC train: 0.942171	val: 0.768039	test: 0.806082

Epoch: 54
Loss: 0.33615698964439117
ROC train: 0.952354	val: 0.837441	test: 0.864321
PRC train: 0.942506	val: 0.769967	test: 0.812436

Epoch: 55
Loss: 0.33932761464870154
ROC train: 0.953007	val: 0.835266	test: 0.852066
PRC train: 0.943166	val: 0.761938	test: 0.805952

Epoch: 56
Loss: 0.32592980572628516
ROC train: 0.955485	val: 0.832729	test: 0.856268
PRC train: 0.947188	val: 0.760989	test: 0.802169

Epoch: 57
Loss: 0.32588840274049613
ROC train: 0.955591	val: 0.839435	test: 0.862220
PRC train: 0.947238	val: 0.778875	test: 0.804556

Epoch: 58
Loss: 0.31688302853549544
ROC train: 0.957094	val: 0.841972	test: 0.858894
PRC train: 0.949603	val: 0.778363	test: 0.795737

Epoch: 59
Loss: 0.32957252494742584
ROC train: 0.958278	val: 0.836173	test: 0.856793
PRC train: 0.951053	val: 0.777535	test: 0.776958

Epoch: 60
Loss: 0.3179693073609002
ROC train: 0.957832	val: 0.832910	test: 0.848739
PRC train: 0.951225	val: 0.769084	test: 0.750719

Epoch: 61
Loss: 0.31765867018718175
ROC train: 0.958978	val: 0.840884	test: 0.845413
PRC train: 0.952313	val: 0.777411	test: 0.746239

Epoch: 62
Loss: 0.3089072872342378
ROC train: 0.959234	val: 0.836897	test: 0.861345
PRC train: 0.951567	val: 0.773097	test: 0.769302

Epoch: 63
Loss: 0.3222060887654592
ROC train: 0.961121	val: 0.835266	test: 0.863095
PRC train: 0.954147	val: 0.772586	test: 0.783634

Epoch: 64
Loss: 0.32093920190574027
ROC train: 0.962719	val: 0.837804	test: 0.853291
PRC train: 0.957179	val: 0.768941	test: 0.791627

Epoch: 65
Loss: 0.3197879097894825
ROC train: 0.963568	val: 0.850127	test: 0.861169
PRC train: 0.957439	val: 0.784192	test: 0.791538

Epoch: 66
Loss: 0.3219470261812136
ROC train: 0.959915	val: 0.856651	test: 0.868347
PRC train: 0.951646	val: 0.794639	test: 0.800303

Epoch: 67
Loss: 0.3109959922108679
ROC train: 0.963633	val: 0.852664	test: 0.859944
PRC train: 0.956571	val: 0.792778	test: 0.810923

Epoch: 68
Loss: 0.29879425506332113
ROC train: 0.964058	val: 0.852845	test: 0.855392
PRC train: 0.957427	val: 0.785752	test: 0.802681

Epoch: 69
Loss: 0.3065584051866284
ROC train: 0.961184	val: 0.851758	test: 0.856793
PRC train: 0.953336	val: 0.780397	test: 0.815298

Epoch: 70
Loss: 0.3056185424593557
ROC train: 0.963171	val: 0.838891	test: 0.863270
PRC train: 0.955643	val: 0.779469	test: 0.821564

Epoch: 71
Loss: 0.2876529837402916
ROC train: 0.965095	val: 0.841609	test: 0.866071
PRC train: 0.958480	val: 0.783577	test: 0.821587

Epoch: 72
Loss: 0.3055707646981867
ROC train: 0.965547	val: 0.844871	test: 0.855042
PRC train: 0.960174	val: 0.764513	test: 0.796012

Epoch: 73
Loss: 0.306000834124609
ROC train: 0.966856	val: 0.843422	test: 0.868172
PRC train: 0.960603	val: 0.780817	test: 0.794981

Epoch: 74
Loss: 0.31242827279969754
ROC train: 0.966144	val: 0.848496	test: 0.864146
PRC train: 0.960402	val: 0.778229	test: 0.773302

Epoch: 75
Loss: 0.2886180771268062
ROC train: 0.967990	val: 0.848133	test: 0.860469
PRC train: 0.961874	val: 0.790006	test: 0.784831

Epoch: 76
Loss: 0.27642055320609504
ROC train: 0.968276	val: 0.844509	test: 0.857493
PRC train: 0.962684	val: 0.786940	test: 0.805358

Epoch: 77
Loss: 0.3004470436982057
ROC train: 0.968721	val: 0.846502	test: 0.849265
PRC train: 0.963240	val: 0.774892	test: 0.788569

Epoch: 78
Loss: 0.2945975292222096
ROC train: 0.969069	val: 0.846140	test: 0.848915
PRC train: 0.962895	val: 0.786547	test: 0.794504

Epoch: 79
Loss: 0.2896177476278473
ROC train: 0.968402	val: 0.846684	test: 0.852941
PRC train: 0.962363	val: 0.789969	test: 0.797869

Epoch: 80
Loss: 0.2949002557233425
ROC train: 0.968281	val: 0.843059	test: 0.848214
PRC train: 0.962620	val: 0.782281	test: 0.786729

Epoch: 81
Loss: 0.2853202475823163
ROC train: 0.968239	val: 0.846865	test: 0.844888
PRC train: 0.962633	val: 0.790944	test: 0.789567

Epoch: 82
Loss: 0.29018822509073067
ROC train: 0.971810	val: 0.848133	test: 0.838585
PRC train: 0.967133	val: 0.791929	test: 0.788532

Epoch: 83
Loss: 0.29836188594766916
ROC train: 0.972676	val: 0.853570	test: 0.838936
PRC train: 0.968169	val: 0.793521	test: 0.787703

Epoch: 84
Loss: 0.28771958492329774
ROC train: 0.973379	val: 0.845053	test: 0.842612
PRC train: 0.969276	val: 0.769758	test: 0.745870

Epoch: 85
Loss: 0.2796656926798379
ROC train: 0.970396	val: 0.848133	test: 0.835084
PRC train: 0.965868	val: 0.768520	test: 0.742235

Epoch: 86
Loss: 0.27624763109006
ROC train: 0.971061	val: 0.848496	test: 0.845588
PRC train: 0.966205	val: 0.780756	test: 0.769744

Epoch: 87
Loss: 0.2762475677192399
ROC train: 0.972755	val: 0.850308	test: 0.851891
PRC train: 0.967999	val: 0.783733	test: 0.803339

Epoch: 88
Loss: 0.26621706130130923
ROC train: 0.973615	val: 0.846140	test: 0.860294
PRC train: 0.969707	val: 0.777512	test: 0.805661

Epoch: 89
Loss: 0.2779146526593084
ROC train: 0.973266	val: 0.844509	test: 0.855217
PRC train: 0.969731	val: 0.782074	test: 0.796775

Epoch: 90
Loss: 0.27100071772055756
ROC train: 0.973912	val: 0.850489	test: 0.851716
PRC train: 0.969942	val: 0.791035	test: 0.799453

Epoch: 91
Loss: 0.26999874039043203
ROC train: 0.975377	val: 0.855201	test: 0.834034
PRC train: 0.971315	val: 0.778992	test: 0.771208

Epoch: 92
Loss: 0.26744847652376025
ROC train: 0.974054	val: 0.854657	test: 0.847514
PRC train: 0.969461	val: 0.784872	test: 0.766549

Epoch: 93
Loss: 0.2808466033272417
ROC train: 0.975700	val: 0.840884	test: 0.840686
PRC train: 0.972279	val: 0.767108	test: 0.766456

Epoch: 94
Loss: 0.2706781139689455
ROC train: 0.977702	val: 0.833817	test: 0.832458
PRC train: 0.920258	val: 0.767356	test: 0.808698

Epoch: 34
Loss: 0.3840689068652875
ROC train: 0.936292	val: 0.846684	test: 0.869398
PRC train: 0.923253	val: 0.769568	test: 0.815468

Epoch: 35
Loss: 0.3763398705207837
ROC train: 0.936890	val: 0.850671	test: 0.867122
PRC train: 0.923000	val: 0.778840	test: 0.814401

Epoch: 36
Loss: 0.3804437569940241
ROC train: 0.940532	val: 0.851395	test: 0.858543
PRC train: 0.926754	val: 0.773422	test: 0.805090

Epoch: 37
Loss: 0.36591306278854663
ROC train: 0.943067	val: 0.852483	test: 0.865546
PRC train: 0.930881	val: 0.772951	test: 0.812126

Epoch: 38
Loss: 0.3593375769681479
ROC train: 0.942631	val: 0.851758	test: 0.875175
PRC train: 0.930754	val: 0.773453	test: 0.828996

Epoch: 39
Loss: 0.36110972635486294
ROC train: 0.943746	val: 0.853208	test: 0.861870
PRC train: 0.931149	val: 0.769449	test: 0.814009

Epoch: 40
Loss: 0.3604609865401319
ROC train: 0.944364	val: 0.849040	test: 0.858018
PRC train: 0.932330	val: 0.771181	test: 0.799186

Epoch: 41
Loss: 0.34946150518478464
ROC train: 0.943235	val: 0.844871	test: 0.861870
PRC train: 0.931091	val: 0.771200	test: 0.791916

Epoch: 42
Loss: 0.3378539955198144
ROC train: 0.943979	val: 0.850671	test: 0.861870
PRC train: 0.931763	val: 0.771280	test: 0.796507

Epoch: 43
Loss: 0.3408496037972745
ROC train: 0.944838	val: 0.854657	test: 0.865721
PRC train: 0.931403	val: 0.773706	test: 0.814390

Epoch: 44
Loss: 0.36125653230413735
ROC train: 0.948643	val: 0.848858	test: 0.874825
PRC train: 0.936885	val: 0.767486	test: 0.815639

Epoch: 45
Loss: 0.35057538443173375
ROC train: 0.950360	val: 0.842878	test: 0.868697
PRC train: 0.939195	val: 0.754797	test: 0.804247

Epoch: 46
Loss: 0.34024057620368603
ROC train: 0.947764	val: 0.840522	test: 0.870448
PRC train: 0.936627	val: 0.753917	test: 0.815245

Epoch: 47
Loss: 0.34798550733405953
ROC train: 0.947402	val: 0.836354	test: 0.870973
PRC train: 0.937442	val: 0.742825	test: 0.817925

Epoch: 48
Loss: 0.34425867488215517
ROC train: 0.950623	val: 0.843965	test: 0.863971
PRC train: 0.941680	val: 0.745315	test: 0.813408

Epoch: 49
Loss: 0.3258289851455102
ROC train: 0.949080	val: 0.852664	test: 0.868873
PRC train: 0.935344	val: 0.756399	test: 0.823254

Epoch: 50
Loss: 0.33573308810705227
ROC train: 0.953605	val: 0.848858	test: 0.870798
PRC train: 0.943765	val: 0.753865	test: 0.829558

Epoch: 51
Loss: 0.334210254777774
ROC train: 0.955312	val: 0.840884	test: 0.863796
PRC train: 0.947074	val: 0.745967	test: 0.820455

Epoch: 52
Loss: 0.32633813630915565
ROC train: 0.955188	val: 0.843240	test: 0.864671
PRC train: 0.946782	val: 0.739346	test: 0.812191

Epoch: 53
Loss: 0.3323801757799935
ROC train: 0.953884	val: 0.851033	test: 0.869923
PRC train: 0.944027	val: 0.756416	test: 0.823889

Epoch: 54
Loss: 0.3313706226721118
ROC train: 0.956176	val: 0.844871	test: 0.866071
PRC train: 0.948283	val: 0.743081	test: 0.815871

Epoch: 55
Loss: 0.3259231710639338
ROC train: 0.958844	val: 0.836716	test: 0.854167
PRC train: 0.951358	val: 0.733307	test: 0.806625

Epoch: 56
Loss: 0.3249403653313726
ROC train: 0.957124	val: 0.837260	test: 0.851891
PRC train: 0.947756	val: 0.737721	test: 0.806858

Epoch: 57
Loss: 0.31285657550450574
ROC train: 0.957914	val: 0.842515	test: 0.865196
PRC train: 0.949129	val: 0.756699	test: 0.815617

Epoch: 58
Loss: 0.29554180286153126
ROC train: 0.960140	val: 0.847408	test: 0.876576
PRC train: 0.953488	val: 0.767058	test: 0.820854

Epoch: 59
Loss: 0.2976899074375449
ROC train: 0.962068	val: 0.847771	test: 0.874300
PRC train: 0.956248	val: 0.749603	test: 0.822809

Epoch: 60
Loss: 0.33805088483727475
ROC train: 0.961961	val: 0.850127	test: 0.867647
PRC train: 0.955327	val: 0.752480	test: 0.820836

Epoch: 61
Loss: 0.30342230370949275
ROC train: 0.964400	val: 0.844690	test: 0.858193
PRC train: 0.958460	val: 0.751810	test: 0.808429

Epoch: 62
Loss: 0.31876693668024914
ROC train: 0.964046	val: 0.843965	test: 0.861870
PRC train: 0.958859	val: 0.772178	test: 0.808541

Epoch: 63
Loss: 0.305909673180063
ROC train: 0.962530	val: 0.842697	test: 0.859244
PRC train: 0.956389	val: 0.771513	test: 0.805779

Epoch: 64
Loss: 0.3137591853245899
ROC train: 0.962667	val: 0.842697	test: 0.858018
PRC train: 0.955380	val: 0.764663	test: 0.808968

Epoch: 65
Loss: 0.3030144008466653
ROC train: 0.963661	val: 0.839072	test: 0.849090
PRC train: 0.957297	val: 0.750872	test: 0.792447

Epoch: 66
Loss: 0.2922178399897684
ROC train: 0.962462	val: 0.843603	test: 0.869223
PRC train: 0.954512	val: 0.753957	test: 0.824729

Epoch: 67
Loss: 0.2972744186117187
ROC train: 0.963300	val: 0.846865	test: 0.876926
PRC train: 0.956879	val: 0.759499	test: 0.832313

Epoch: 68
Loss: 0.3008524308255075
ROC train: 0.966279	val: 0.848677	test: 0.862570
PRC train: 0.961160	val: 0.752105	test: 0.804347

Epoch: 69
Loss: 0.2997047875118054
ROC train: 0.968822	val: 0.848315	test: 0.865546
PRC train: 0.964121	val: 0.751106	test: 0.817553

Epoch: 70
Loss: 0.3005098287906778
ROC train: 0.964207	val: 0.855745	test: 0.868522
PRC train: 0.956603	val: 0.761595	test: 0.830740

Epoch: 71
Loss: 0.3178603140789758
ROC train: 0.968465	val: 0.856289	test: 0.858018
PRC train: 0.962666	val: 0.757922	test: 0.820192

Epoch: 72
Loss: 0.29802036198707593
ROC train: 0.970377	val: 0.845234	test: 0.860644
PRC train: 0.964409	val: 0.746807	test: 0.823513

Epoch: 73
Loss: 0.296013833548358
ROC train: 0.968899	val: 0.847046	test: 0.858718
PRC train: 0.962389	val: 0.745315	test: 0.812756

Epoch: 74
Loss: 0.30085547789990275
ROC train: 0.970415	val: 0.851395	test: 0.856793
PRC train: 0.964755	val: 0.749159	test: 0.810123

Epoch: 75
Loss: 0.30134906763366154
ROC train: 0.971146	val: 0.847590	test: 0.865371
PRC train: 0.966456	val: 0.747685	test: 0.815061

Epoch: 76
Loss: 0.2819342990423673
ROC train: 0.971668	val: 0.852483	test: 0.865896
PRC train: 0.967324	val: 0.751637	test: 0.817523

Epoch: 77
Loss: 0.29483124632750934
ROC train: 0.973219	val: 0.861725	test: 0.855392
PRC train: 0.968964	val: 0.769149	test: 0.821198

Epoch: 78
Loss: 0.294601989244738
ROC train: 0.971835	val: 0.861725	test: 0.853992
PRC train: 0.966346	val: 0.775881	test: 0.814870

Epoch: 79
Loss: 0.27279185816640705
ROC train: 0.972280	val: 0.852664	test: 0.856618
PRC train: 0.967250	val: 0.752343	test: 0.810186

Epoch: 80
Loss: 0.2824553130664137
ROC train: 0.969547	val: 0.852483	test: 0.868873
PRC train: 0.963074	val: 0.751646	test: 0.823533

Epoch: 81
Loss: 0.27557000633300666
ROC train: 0.971379	val: 0.847046	test: 0.866422
PRC train: 0.965658	val: 0.749267	test: 0.820286

Epoch: 82
Loss: 0.26817033768419035
ROC train: 0.973382	val: 0.845959	test: 0.871148
PRC train: 0.968920	val: 0.748248	test: 0.816552

Epoch: 83
Loss: 0.27541048239623417
ROC train: 0.973892	val: 0.850852	test: 0.855917
PRC train: 0.969288	val: 0.753721	test: 0.795154

Epoch: 84
Loss: 0.2732787907460502
ROC train: 0.973439	val: 0.847408	test: 0.858894
PRC train: 0.968318	val: 0.744578	test: 0.807083

Epoch: 85
Loss: 0.272193461923091
ROC train: 0.973417	val: 0.845596	test: 0.866422
PRC train: 0.968480	val: 0.762989	test: 0.828593

Epoch: 86
Loss: 0.2735468761935442
ROC train: 0.974332	val: 0.844871	test: 0.866597
PRC train: 0.970511	val: 0.752361	test: 0.818133

Epoch: 87
Loss: 0.25824505129979103
ROC train: 0.974142	val: 0.850671	test: 0.869573
PRC train: 0.970164	val: 0.764113	test: 0.815918

Epoch: 88
Loss: 0.27402079047972494
ROC train: 0.975007	val: 0.847952	test: 0.877451
PRC train: 0.971262	val: 0.770214	test: 0.828564

Epoch: 89
Loss: 0.26375825448115886
ROC train: 0.975763	val: 0.852845	test: 0.882178
PRC train: 0.971794	val: 0.771254	test: 0.836005

Epoch: 90
Loss: 0.26134919893712694
ROC train: 0.976716	val: 0.853751	test: 0.873599
PRC train: 0.973342	val: 0.765504	test: 0.815761

Epoch: 91
Loss: 0.2619649752476533
ROC train: 0.977133	val: 0.853570	test: 0.864146
PRC train: 0.973672	val: 0.773543	test: 0.814152

Epoch: 92
Loss: 0.2673743724755612
ROC train: 0.978564	val: 0.857376	test: 0.870623
PRC train: 0.974947	val: 0.781234	test: 0.833094

Epoch: 93
Loss: 0.2627434998763586
ROC train: 0.979413	val: 0.849764	test: 0.867297
PRC train: 0.976544	val: 0.776679	test: 0.814890

Epoch: 94
Loss: 0.24580142785572864
ROC train: 0.978961	val: 0.844509	test: 0.876926
PRC train: 0.979833	val: 0.812273	test: 0.768684

Epoch: 95
Loss: 0.2257670790307738
ROC train: 0.983824	val: 0.826684	test: 0.837710
PRC train: 0.980458	val: 0.805228	test: 0.767562

Epoch: 96
Loss: 0.2358488785614602
ROC train: 0.985843	val: 0.829274	test: 0.837931
PRC train: 0.983585	val: 0.809606	test: 0.769304

Epoch: 97
Loss: 0.21407406143702834
ROC train: 0.987626	val: 0.830678	test: 0.845712
PRC train: 0.985820	val: 0.805836	test: 0.779802

Epoch: 98
Loss: 0.21807778119437946
ROC train: 0.988783	val: 0.829449	test: 0.848099
PRC train: 0.986995	val: 0.806090	test: 0.782889

Epoch: 99
Loss: 0.23112652983038862
ROC train: 0.988258	val: 0.828396	test: 0.847878
PRC train: 0.986177	val: 0.801299	test: 0.778520

Epoch: 100
Loss: 0.21984383409712493
ROC train: 0.987866	val: 0.825587	test: 0.844695
PRC train: 0.985700	val: 0.795826	test: 0.778060

Epoch: 101
Loss: 0.21411940544436647
ROC train: 0.987134	val: 0.826553	test: 0.841379
PRC train: 0.985012	val: 0.801064	test: 0.773043

Epoch: 102
Loss: 0.22891908326056348
ROC train: 0.988062	val: 0.829669	test: 0.840186
PRC train: 0.986248	val: 0.805131	test: 0.768756

Epoch: 103
Loss: 0.19744938604450368
ROC train: 0.988876	val: 0.830503	test: 0.840097
PRC train: 0.987027	val: 0.804830	test: 0.772171

Epoch: 104
Loss: 0.213673162131078
ROC train: 0.987898	val: 0.834628	test: 0.840981
PRC train: 0.985762	val: 0.811592	test: 0.768423

Epoch: 105
Loss: 0.20617094496895708
ROC train: 0.988810	val: 0.833399	test: 0.839523
PRC train: 0.986964	val: 0.806043	test: 0.765188

Epoch: 106
Loss: 0.20021952592398806
ROC train: 0.989157	val: 0.823480	test: 0.841556
PRC train: 0.987544	val: 0.793774	test: 0.769212

Epoch: 107
Loss: 0.2333066515486792
ROC train: 0.987695	val: 0.816765	test: 0.841026
PRC train: 0.985715	val: 0.786875	test: 0.768819

Epoch: 108
Loss: 0.22367260552627033
ROC train: 0.987683	val: 0.819925	test: 0.841424
PRC train: 0.986216	val: 0.794570	test: 0.772298

Epoch: 109
Loss: 0.2232101976521626
ROC train: 0.989385	val: 0.824841	test: 0.843546
PRC train: 0.987846	val: 0.803129	test: 0.773522

Epoch: 110
Loss: 0.20013427746839269
ROC train: 0.988035	val: 0.824665	test: 0.844960
PRC train: 0.985898	val: 0.802231	test: 0.782207

Epoch: 111
Loss: 0.21573696933225014
ROC train: 0.987607	val: 0.827825	test: 0.847038
PRC train: 0.985111	val: 0.808459	test: 0.783973

Epoch: 112
Loss: 0.23081817977560326
ROC train: 0.989733	val: 0.827299	test: 0.839788
PRC train: 0.988007	val: 0.805729	test: 0.770116

Epoch: 113
Loss: 0.2227837907132868
ROC train: 0.988699	val: 0.825587	test: 0.837622
PRC train: 0.986638	val: 0.793564	test: 0.767982

Epoch: 114
Loss: 0.21981073871198425
ROC train: 0.988925	val: 0.826333	test: 0.844032
PRC train: 0.986712	val: 0.795066	test: 0.776667

Epoch: 115
Loss: 0.20743721650557365
ROC train: 0.988102	val: 0.828133	test: 0.844828
PRC train: 0.985737	val: 0.799465	test: 0.777958

Epoch: 116
Loss: 0.20805388417633203
ROC train: 0.989993	val: 0.826070	test: 0.844960
PRC train: 0.987870	val: 0.800591	test: 0.780017

Epoch: 117
Loss: 0.20221989249991273
ROC train: 0.990262	val: 0.823568	test: 0.840097
PRC train: 0.988451	val: 0.804892	test: 0.769858

Epoch: 118
Loss: 0.2050458987398121
ROC train: 0.990287	val: 0.819706	test: 0.836472
PRC train: 0.988551	val: 0.794996	test: 0.756107

Epoch: 119
Loss: 0.21451150789857898
ROC train: 0.988332	val: 0.816414	test: 0.836251
PRC train: 0.986505	val: 0.781292	test: 0.759782

Epoch: 120
Loss: 0.20311809953940818
ROC train: 0.990267	val: 0.815624	test: 0.831211
PRC train: 0.988564	val: 0.775955	test: 0.753522

Early stopping
Best (ROC):	 train: 0.975647	val: 0.837832	test: 0.845800
Best (PRC):	 train: 0.970419	val: 0.822392	test: 0.759247

PRC train: 0.986725	val: 0.804499	test: 0.773763

Epoch: 95
Loss: 0.2307838226434841
ROC train: 0.988925	val: 0.826465	test: 0.838683
PRC train: 0.986931	val: 0.799478	test: 0.766857

Epoch: 96
Loss: 0.23350342946937241
ROC train: 0.987558	val: 0.830151	test: 0.840981
PRC train: 0.984874	val: 0.802356	test: 0.773418

Epoch: 97
Loss: 0.23454654293377658
ROC train: 0.988420	val: 0.831249	test: 0.846684
PRC train: 0.985936	val: 0.814158	test: 0.789086

Epoch: 98
Loss: 0.23005204406855026
ROC train: 0.989390	val: 0.835901	test: 0.843369
PRC train: 0.987477	val: 0.814954	test: 0.781952

Epoch: 99
Loss: 0.22315301894598277
ROC train: 0.987614	val: 0.836998	test: 0.846110
PRC train: 0.985227	val: 0.810336	test: 0.777499

Epoch: 100
Loss: 0.21283804280014848
ROC train: 0.988082	val: 0.829581	test: 0.848806
PRC train: 0.986180	val: 0.800042	test: 0.788428

Epoch: 101
Loss: 0.21781652661078732
ROC train: 0.987910	val: 0.826860	test: 0.849735
PRC train: 0.985518	val: 0.795591	test: 0.795663

Epoch: 102
Loss: 0.19923758200334243
ROC train: 0.989726	val: 0.832214	test: 0.843103
PRC train: 0.987792	val: 0.805997	test: 0.784359

Epoch: 103
Loss: 0.19686083739699767
ROC train: 0.989527	val: 0.834233	test: 0.842794
PRC train: 0.987779	val: 0.813455	test: 0.781137

Epoch: 104
Loss: 0.21449389775032535
ROC train: 0.988533	val: 0.833311	test: 0.845623
PRC train: 0.986909	val: 0.806924	test: 0.782845

Epoch: 105
Loss: 0.19228271522238227
ROC train: 0.987352	val: 0.829581	test: 0.847038
PRC train: 0.984950	val: 0.796145	test: 0.787091

Epoch: 106
Loss: 0.21088795988171904
ROC train: 0.990963	val: 0.827518	test: 0.846021
PRC train: 0.989644	val: 0.798315	test: 0.786514

Epoch: 107
Loss: 0.20590991490316107
ROC train: 0.990586	val: 0.823393	test: 0.843236
PRC train: 0.989228	val: 0.788401	test: 0.783125

Epoch: 108
Loss: 0.2137974009310599
ROC train: 0.989615	val: 0.822251	test: 0.846242
PRC train: 0.988041	val: 0.790217	test: 0.788562

Epoch: 109
Loss: 0.22158019760896377
ROC train: 0.989108	val: 0.829844	test: 0.852343
PRC train: 0.987611	val: 0.797473	test: 0.793298

Epoch: 110
Loss: 0.19797377175741343
ROC train: 0.989606	val: 0.831161	test: 0.847701
PRC train: 0.988240	val: 0.802996	test: 0.783252

Epoch: 111
Loss: 0.2272646609277146
ROC train: 0.989870	val: 0.828264	test: 0.841424
PRC train: 0.988348	val: 0.797202	test: 0.770970

Epoch: 112
Loss: 0.23769522206781052
ROC train: 0.989344	val: 0.818521	test: 0.847613
PRC train: 0.987463	val: 0.779093	test: 0.778883

Epoch: 113
Loss: 0.21900437368487885
ROC train: 0.989535	val: 0.826465	test: 0.839434
PRC train: 0.988008	val: 0.795890	test: 0.776076

Epoch: 114
Loss: 0.21466273260593943
ROC train: 0.989905	val: 0.826070	test: 0.845402
PRC train: 0.988341	val: 0.788053	test: 0.782381

Epoch: 115
Loss: 0.2000156792148499
ROC train: 0.989929	val: 0.825631	test: 0.847392
PRC train: 0.988264	val: 0.788221	test: 0.783519

Epoch: 116
Loss: 0.1886553529165439
ROC train: 0.991120	val: 0.824753	test: 0.843722
PRC train: 0.989677	val: 0.795264	test: 0.774605

Epoch: 117
Loss: 0.2033679632239729
ROC train: 0.991585	val: 0.821418	test: 0.843236
PRC train: 0.990380	val: 0.789335	test: 0.767369

Epoch: 118
Loss: 0.2115347690165837
ROC train: 0.988596	val: 0.820496	test: 0.844828
PRC train: 0.986674	val: 0.789013	test: 0.773101

Epoch: 119
Loss: 0.2127427702846557
ROC train: 0.989042	val: 0.830283	test: 0.844474
PRC train: 0.986971	val: 0.798926	test: 0.783794

Epoch: 120
Loss: 0.20336432576675087
ROC train: 0.992394	val: 0.833706	test: 0.840584
PRC train: 0.991304	val: 0.807505	test: 0.772485

Early stopping
Best (ROC):	 train: 0.976262	val: 0.838007	test: 0.847347
Best (PRC):	 train: 0.971204	val: 0.831525	test: 0.782230

PRC train: 0.979101	val: 0.774830	test: 0.767814

Epoch: 95
Loss: 0.2551371105144943
ROC train: 0.979557	val: 0.818170	test: 0.834527
PRC train: 0.974675	val: 0.754155	test: 0.765069

Epoch: 96
Loss: 0.23070351381288795
ROC train: 0.984488	val: 0.820803	test: 0.832228
PRC train: 0.981458	val: 0.768127	test: 0.756528

Epoch: 97
Loss: 0.22031870814569346
ROC train: 0.983917	val: 0.815185	test: 0.834439
PRC train: 0.980577	val: 0.764130	test: 0.752216

Epoch: 98
Loss: 0.25262643060268464
ROC train: 0.982786	val: 0.813869	test: 0.840893
PRC train: 0.979050	val: 0.762018	test: 0.762469

Epoch: 99
Loss: 0.2310763934488803
ROC train: 0.986186	val: 0.816678	test: 0.841424
PRC train: 0.983325	val: 0.776257	test: 0.772352

Epoch: 100
Loss: 0.2160512507979463
ROC train: 0.988011	val: 0.816765	test: 0.838506
PRC train: 0.985545	val: 0.787617	test: 0.774147

Epoch: 101
Loss: 0.2217472079244934
ROC train: 0.987107	val: 0.818521	test: 0.839832
PRC train: 0.984435	val: 0.784831	test: 0.777438

Epoch: 102
Loss: 0.20424702691101299
ROC train: 0.980733	val: 0.814615	test: 0.838948
PRC train: 0.976508	val: 0.766396	test: 0.779588

Epoch: 103
Loss: 0.2290993607005582
ROC train: 0.983638	val: 0.824314	test: 0.840805
PRC train: 0.980216	val: 0.780542	test: 0.783216

Epoch: 104
Loss: 0.23457114962429707
ROC train: 0.987229	val: 0.824270	test: 0.841910
PRC train: 0.984920	val: 0.785544	test: 0.783505

Epoch: 105
Loss: 0.21691708824763858
ROC train: 0.986654	val: 0.820057	test: 0.841821
PRC train: 0.984501	val: 0.786337	test: 0.779482

Epoch: 106
Loss: 0.22794999359056928
ROC train: 0.985583	val: 0.820145	test: 0.840451
PRC train: 0.982774	val: 0.779524	test: 0.776028

Epoch: 107
Loss: 0.21861476372982813
ROC train: 0.985801	val: 0.816019	test: 0.844695
PRC train: 0.983215	val: 0.775723	test: 0.782778

Epoch: 108
Loss: 0.2186511471664741
ROC train: 0.988577	val: 0.819135	test: 0.845712
PRC train: 0.986536	val: 0.787384	test: 0.788226

Epoch: 109
Loss: 0.21412059033552427
ROC train: 0.987447	val: 0.822910	test: 0.847259
PRC train: 0.985211	val: 0.789934	test: 0.789327

Epoch: 110
Loss: 0.23492869012378131
ROC train: 0.986901	val: 0.817994	test: 0.841733
PRC train: 0.984610	val: 0.763807	test: 0.781095

Epoch: 111
Loss: 0.20983983635651618
ROC train: 0.987695	val: 0.810138	test: 0.838329
PRC train: 0.985333	val: 0.755479	test: 0.777858

Epoch: 112
Loss: 0.21988897914133443
ROC train: 0.987352	val: 0.814132	test: 0.836207
PRC train: 0.984892	val: 0.775729	test: 0.773211

Epoch: 113
Loss: 0.21546368113083597
ROC train: 0.986607	val: 0.819311	test: 0.841026
PRC train: 0.984293	val: 0.780068	test: 0.771191

Epoch: 114
Loss: 0.22005704408657367
ROC train: 0.986117	val: 0.821593	test: 0.846861
PRC train: 0.983671	val: 0.774131	test: 0.776694

Epoch: 115
Loss: 0.21824636393163738
ROC train: 0.987146	val: 0.817731	test: 0.845402
PRC train: 0.985039	val: 0.761409	test: 0.777293

Epoch: 116
Loss: 0.2249964414768612
ROC train: 0.986223	val: 0.820891	test: 0.844783
PRC train: 0.983610	val: 0.779678	test: 0.776800

Epoch: 117
Loss: 0.22619367309212826
ROC train: 0.987817	val: 0.824753	test: 0.842308
PRC train: 0.985303	val: 0.784967	test: 0.773151

Epoch: 118
Loss: 0.20064364668712398
ROC train: 0.989194	val: 0.825192	test: 0.840628
PRC train: 0.986838	val: 0.782784	test: 0.765102

Epoch: 119
Loss: 0.215475775196399
ROC train: 0.989640	val: 0.821593	test: 0.838904
PRC train: 0.987571	val: 0.765388	test: 0.764196

Epoch: 120
Loss: 0.20921196278402518
ROC train: 0.989268	val: 0.814395	test: 0.840716
PRC train: 0.987251	val: 0.754194	test: 0.767456

Early stopping
Best (ROC):	 train: 0.952335	val: 0.827518	test: 0.826835
Best (PRC):	 train: 0.939450	val: 0.793186	test: 0.764212
All runs completed.

PRC train: 0.953189	val: 0.800842	test: 0.800049

Epoch: 95
Loss: 0.33344757002997094
ROC train: 0.960909	val: 0.833688	test: 0.872690
PRC train: 0.952053	val: 0.804745	test: 0.803161

Epoch: 96
Loss: 0.3316444919067519
ROC train: 0.954303	val: 0.826446	test: 0.872768
PRC train: 0.948062	val: 0.794199	test: 0.812684

Epoch: 97
Loss: 0.3403080696263125
ROC train: 0.961272	val: 0.825580	test: 0.869572
PRC train: 0.953373	val: 0.796268	test: 0.804787

Epoch: 98
Loss: 0.3193033933014663
ROC train: 0.961444	val: 0.828808	test: 0.874873
PRC train: 0.953769	val: 0.803058	test: 0.817444

Epoch: 99
Loss: 0.32355058967445305
ROC train: 0.961552	val: 0.828571	test: 0.871833
PRC train: 0.953978	val: 0.805731	test: 0.814055

Epoch: 100
Loss: 0.31687613394243047
ROC train: 0.963266	val: 0.822511	test: 0.874172
PRC train: 0.955752	val: 0.799970	test: 0.809901

Epoch: 101
Loss: 0.3120693974800822
ROC train: 0.962224	val: 0.813223	test: 0.873314
PRC train: 0.954463	val: 0.786137	test: 0.793103

Epoch: 102
Loss: 0.3260771932761949
ROC train: 0.966380	val: 0.813302	test: 0.882669
PRC train: 0.959309	val: 0.786722	test: 0.805357

Epoch: 103
Loss: 0.2892961703870266
ROC train: 0.964225	val: 0.821094	test: 0.882124
PRC train: 0.956302	val: 0.798569	test: 0.804518

Epoch: 104
Loss: 0.35830173755440126
ROC train: 0.963479	val: 0.823219	test: 0.881656
PRC train: 0.955165	val: 0.795427	test: 0.805755

Epoch: 105
Loss: 0.3131135018933689
ROC train: 0.965360	val: 0.827784	test: 0.879005
PRC train: 0.958241	val: 0.796480	test: 0.813873

Epoch: 106
Loss: 0.309221944656709
ROC train: 0.965863	val: 0.824400	test: 0.867311
PRC train: 0.959188	val: 0.795711	test: 0.812517

Epoch: 107
Loss: 0.28603203985940545
ROC train: 0.967386	val: 0.825344	test: 0.864037
PRC train: 0.961150	val: 0.797643	test: 0.804869

Epoch: 108
Loss: 0.2856137333085171
ROC train: 0.967141	val: 0.823770	test: 0.869572
PRC train: 0.961656	val: 0.792548	test: 0.804237

Epoch: 109
Loss: 0.30526959478065196
ROC train: 0.966721	val: 0.820858	test: 0.881344
PRC train: 0.961573	val: 0.778866	test: 0.827690

Epoch: 110
Loss: 0.2996256316788768
ROC train: 0.967264	val: 0.822039	test: 0.888049
PRC train: 0.961823	val: 0.776693	test: 0.838149

Epoch: 111
Loss: 0.259084242294544
ROC train: 0.967596	val: 0.824951	test: 0.887191
PRC train: 0.961446	val: 0.793151	test: 0.828310

Epoch: 112
Loss: 0.314293800341851
ROC train: 0.968183	val: 0.822826	test: 0.878226
PRC train: 0.961610	val: 0.802374	test: 0.819993

Epoch: 113
Loss: 0.28573781496570866
ROC train: 0.968726	val: 0.818654	test: 0.863023
PRC train: 0.961427	val: 0.800610	test: 0.803379

Epoch: 114
Loss: 0.2650151412123731
ROC train: 0.970245	val: 0.825030	test: 0.864505
PRC train: 0.963324	val: 0.806048	test: 0.810782

Epoch: 115
Loss: 0.2700051966404341
ROC train: 0.971993	val: 0.828020	test: 0.881500
PRC train: 0.967111	val: 0.798828	test: 0.833909

Epoch: 116
Loss: 0.28547357353017055
ROC train: 0.970137	val: 0.824951	test: 0.887971
PRC train: 0.965438	val: 0.792158	test: 0.837098

Epoch: 117
Loss: 0.2997267053706901
ROC train: 0.969049	val: 0.825580	test: 0.881344
PRC train: 0.964641	val: 0.793345	test: 0.822547

Epoch: 118
Loss: 0.25921163047119045
ROC train: 0.967991	val: 0.826761	test: 0.873080
PRC train: 0.961665	val: 0.803991	test: 0.812469

Epoch: 119
Loss: 0.29563794852766484
ROC train: 0.969800	val: 0.825580	test: 0.883995
PRC train: 0.963225	val: 0.805400	test: 0.821442

Epoch: 120
Loss: 0.2873605916199783
ROC train: 0.970748	val: 0.820464	test: 0.894130
PRC train: 0.964198	val: 0.801251	test: 0.837667

Early stopping
Best (ROC):	 train: 0.956656	val: 0.834002	test: 0.876900
Best (PRC):	 train: 0.946410	val: 0.806852	test: 0.815660

PRC train: 0.973238	val: 0.745885	test: 0.802937

Epoch: 95
Loss: 0.2646601407646689
ROC train: 0.976633	val: 0.850489	test: 0.856268
PRC train: 0.973592	val: 0.776118	test: 0.810977

Epoch: 96
Loss: 0.2574371136127914
ROC train: 0.976555	val: 0.851939	test: 0.854167
PRC train: 0.973037	val: 0.773529	test: 0.810615

Epoch: 97
Loss: 0.26693082067123963
ROC train: 0.978324	val: 0.849402	test: 0.850490
PRC train: 0.975198	val: 0.769211	test: 0.798175

Epoch: 98
Loss: 0.2569235833448881
ROC train: 0.978509	val: 0.852302	test: 0.852066
PRC train: 0.975608	val: 0.771339	test: 0.802086

Epoch: 99
Loss: 0.24692837345040028
ROC train: 0.977982	val: 0.853933	test: 0.851366
PRC train: 0.975251	val: 0.761766	test: 0.795132

Epoch: 100
Loss: 0.26988473488900666
ROC train: 0.978592	val: 0.850671	test: 0.861520
PRC train: 0.975982	val: 0.772739	test: 0.804030

Epoch: 101
Loss: 0.25420810203896954
ROC train: 0.977120	val: 0.847227	test: 0.864671
PRC train: 0.974038	val: 0.774147	test: 0.795394

Epoch: 102
Loss: 0.2579962040035428
ROC train: 0.980019	val: 0.835810	test: 0.856793
PRC train: 0.977050	val: 0.747320	test: 0.799021

Epoch: 103
Loss: 0.2724855672167059
ROC train: 0.980657	val: 0.835448	test: 0.862570
PRC train: 0.977547	val: 0.746202	test: 0.800000

Epoch: 104
Loss: 0.2570153353319451
ROC train: 0.976205	val: 0.841791	test: 0.871324
PRC train: 0.972431	val: 0.764064	test: 0.797354

Epoch: 105
Loss: 0.2595502505796843
ROC train: 0.979160	val: 0.845053	test: 0.861169
PRC train: 0.976433	val: 0.755697	test: 0.764278

Epoch: 106
Loss: 0.2769615931548942
ROC train: 0.980448	val: 0.842878	test: 0.860469
PRC train: 0.978033	val: 0.742518	test: 0.798935

Epoch: 107
Loss: 0.25827064944688
ROC train: 0.981695	val: 0.837260	test: 0.858018
PRC train: 0.978805	val: 0.733312	test: 0.807813

Epoch: 108
Loss: 0.25551444423837366
ROC train: 0.981220	val: 0.833273	test: 0.867647
PRC train: 0.978829	val: 0.742011	test: 0.806905

Epoch: 109
Loss: 0.2545065133477116
ROC train: 0.981841	val: 0.839072	test: 0.864321
PRC train: 0.979416	val: 0.757717	test: 0.808338

Epoch: 110
Loss: 0.238480270518341
ROC train: 0.983365	val: 0.848315	test: 0.849090
PRC train: 0.981110	val: 0.771058	test: 0.796152

Epoch: 111
Loss: 0.2509042379391923
ROC train: 0.982324	val: 0.851214	test: 0.843838
PRC train: 0.980103	val: 0.772229	test: 0.794397

Epoch: 112
Loss: 0.24043012804819702
ROC train: 0.981152	val: 0.845053	test: 0.854517
PRC train: 0.978696	val: 0.761825	test: 0.798197

Epoch: 113
Loss: 0.233795511776877
ROC train: 0.980674	val: 0.845234	test: 0.852766
PRC train: 0.977821	val: 0.754253	test: 0.800326

Epoch: 114
Loss: 0.2452721975962262
ROC train: 0.982690	val: 0.842334	test: 0.855742
PRC train: 0.979880	val: 0.754560	test: 0.812657

Epoch: 115
Loss: 0.23544269771844045
ROC train: 0.983689	val: 0.839253	test: 0.859769
PRC train: 0.981659	val: 0.751623	test: 0.813876

Epoch: 116
Loss: 0.22621664981434284
ROC train: 0.983637	val: 0.839616	test: 0.854867
PRC train: 0.981356	val: 0.748371	test: 0.780187

Epoch: 117
Loss: 0.24007978447492975
ROC train: 0.985626	val: 0.845777	test: 0.846464
PRC train: 0.983411	val: 0.750382	test: 0.785563

Epoch: 118
Loss: 0.23369184402207951
ROC train: 0.983017	val: 0.851758	test: 0.848915
PRC train: 0.980469	val: 0.752142	test: 0.795496

Epoch: 119
Loss: 0.24409389779934582
ROC train: 0.982735	val: 0.846321	test: 0.838235
PRC train: 0.980351	val: 0.746380	test: 0.793030

Epoch: 120
Loss: 0.2231230876903238
ROC train: 0.982643	val: 0.848133	test: 0.847864
PRC train: 0.980456	val: 0.765063	test: 0.772371

Early stopping
Best (ROC):	 train: 0.938137	val: 0.856289	test: 0.884104
Best (PRC):	 train: 0.924679	val: 0.757760	test: 0.840611

PRC train: 0.975977	val: 0.762868	test: 0.818268

Epoch: 95
Loss: 0.27521283133288355
ROC train: 0.977131	val: 0.839616	test: 0.882178
PRC train: 0.973355	val: 0.749596	test: 0.825072

Epoch: 96
Loss: 0.2698305178207451
ROC train: 0.978056	val: 0.840884	test: 0.867997
PRC train: 0.974282	val: 0.748199	test: 0.804760

Epoch: 97
Loss: 0.2405962912250322
ROC train: 0.978489	val: 0.843240	test: 0.863796
PRC train: 0.974398	val: 0.745434	test: 0.808399

Epoch: 98
Loss: 0.24525548218000268
ROC train: 0.978611	val: 0.842878	test: 0.874300
PRC train: 0.974699	val: 0.768044	test: 0.826522

Epoch: 99
Loss: 0.25169184407849654
ROC train: 0.979031	val: 0.843603	test: 0.868873
PRC train: 0.976053	val: 0.760253	test: 0.811579

Epoch: 100
Loss: 0.24337889185860245
ROC train: 0.979759	val: 0.849221	test: 0.873599
PRC train: 0.976560	val: 0.765486	test: 0.818820

Epoch: 101
Loss: 0.25708767396990745
ROC train: 0.979174	val: 0.852664	test: 0.866597
PRC train: 0.975403	val: 0.772997	test: 0.807758

Epoch: 102
Loss: 0.24872349890681758
ROC train: 0.982247	val: 0.847952	test: 0.856092
PRC train: 0.979509	val: 0.773630	test: 0.796545

Epoch: 103
Loss: 0.24365004182993988
ROC train: 0.982127	val: 0.843784	test: 0.861345
PRC train: 0.978812	val: 0.774662	test: 0.808588

Epoch: 104
Loss: 0.23593754056027333
ROC train: 0.978226	val: 0.849764	test: 0.866772
PRC train: 0.973924	val: 0.777251	test: 0.820868

Epoch: 105
Loss: 0.24551102808139139
ROC train: 0.977872	val: 0.853208	test: 0.861870
PRC train: 0.974633	val: 0.767751	test: 0.810257

Epoch: 106
Loss: 0.2378326111059108
ROC train: 0.980111	val: 0.848315	test: 0.857843
PRC train: 0.977085	val: 0.764781	test: 0.797767

Epoch: 107
Loss: 0.2468382533655546
ROC train: 0.980264	val: 0.850671	test: 0.858894
PRC train: 0.976484	val: 0.765724	test: 0.797074

Epoch: 108
Loss: 0.24254261569992633
ROC train: 0.979883	val: 0.853933	test: 0.868873
PRC train: 0.975775	val: 0.775282	test: 0.812467

Epoch: 109
Loss: 0.24120501579382472
ROC train: 0.980775	val: 0.858463	test: 0.861695
PRC train: 0.977666	val: 0.771475	test: 0.802453

Epoch: 110
Loss: 0.2566654571276518
ROC train: 0.982025	val: 0.853933	test: 0.865896
PRC train: 0.979384	val: 0.780319	test: 0.815131

Epoch: 111
Loss: 0.24309832052027947
ROC train: 0.980047	val: 0.840522	test: 0.879552
PRC train: 0.977246	val: 0.769784	test: 0.835338

Epoch: 112
Loss: 0.2548631066319279
ROC train: 0.982208	val: 0.840159	test: 0.876751
PRC train: 0.980130	val: 0.766667	test: 0.826618

Epoch: 113
Loss: 0.24589522134939612
ROC train: 0.983585	val: 0.849040	test: 0.863971
PRC train: 0.980996	val: 0.764019	test: 0.816625

Epoch: 114
Loss: 0.23701819021080853
ROC train: 0.984447	val: 0.852302	test: 0.852591
PRC train: 0.981502	val: 0.773088	test: 0.804275

Epoch: 115
Loss: 0.24107060889853216
ROC train: 0.982327	val: 0.849221	test: 0.856443
PRC train: 0.978825	val: 0.758000	test: 0.778179

Epoch: 116
Loss: 0.24060041490931489
ROC train: 0.983522	val: 0.848496	test: 0.864496
PRC train: 0.980563	val: 0.770126	test: 0.811183

Epoch: 117
Loss: 0.22600545855169552
ROC train: 0.983902	val: 0.855382	test: 0.864671
PRC train: 0.981078	val: 0.787810	test: 0.814451

Epoch: 118
Loss: 0.2286082654250718
ROC train: 0.983354	val: 0.852845	test: 0.869748
PRC train: 0.980795	val: 0.769672	test: 0.800846

Epoch: 119
Loss: 0.23216262988989103
ROC train: 0.981882	val: 0.854114	test: 0.869748
PRC train: 0.979143	val: 0.769096	test: 0.807532

Epoch: 120
Loss: 0.24317088946057813
ROC train: 0.983858	val: 0.849221	test: 0.869398
PRC train: 0.981689	val: 0.768865	test: 0.819159

Early stopping
Best (ROC):	 train: 0.971835	val: 0.861725	test: 0.853992
Best (PRC):	 train: 0.966346	val: 0.775881	test: 0.814870

PRC train: 0.974410	val: 0.748677	test: 0.767845

Epoch: 95
Loss: 0.2564662228175436
ROC train: 0.977718	val: 0.842153	test: 0.841912
PRC train: 0.974560	val: 0.764478	test: 0.785472

Epoch: 96
Loss: 0.25736603540260744
ROC train: 0.979037	val: 0.847408	test: 0.851015
PRC train: 0.976179	val: 0.782497	test: 0.786679

Epoch: 97
Loss: 0.26939005554857365
ROC train: 0.979704	val: 0.845596	test: 0.837185
PRC train: 0.976936	val: 0.775419	test: 0.771947

Epoch: 98
Loss: 0.2647512998462959
ROC train: 0.979539	val: 0.837079	test: 0.832983
PRC train: 0.976247	val: 0.755416	test: 0.763092

Epoch: 99
Loss: 0.2726974334210304
ROC train: 0.979180	val: 0.837079	test: 0.835784
PRC train: 0.975463	val: 0.753195	test: 0.771596

Epoch: 100
Loss: 0.2652760329241294
ROC train: 0.977628	val: 0.827655	test: 0.838235
PRC train: 0.974118	val: 0.742292	test: 0.780530

Epoch: 101
Loss: 0.28216404822405106
ROC train: 0.977661	val: 0.833273	test: 0.861345
PRC train: 0.974285	val: 0.751880	test: 0.818363

Epoch: 102
Loss: 0.2547313151016509
ROC train: 0.978298	val: 0.835810	test: 0.869748
PRC train: 0.975136	val: 0.756025	test: 0.817028

Epoch: 103
Loss: 0.25673617761357465
ROC train: 0.979748	val: 0.841066	test: 0.871148
PRC train: 0.976755	val: 0.770846	test: 0.825435

Epoch: 104
Loss: 0.24873520834915
ROC train: 0.979136	val: 0.848496	test: 0.862045
PRC train: 0.975853	val: 0.787222	test: 0.820945

Epoch: 105
Loss: 0.25920467106356176
ROC train: 0.978336	val: 0.853208	test: 0.866772
PRC train: 0.974659	val: 0.794547	test: 0.812518

Epoch: 106
Loss: 0.24827550565063938
ROC train: 0.981248	val: 0.848315	test: 0.853992
PRC train: 0.977825	val: 0.773154	test: 0.787646

Epoch: 107
Loss: 0.25367306054026434
ROC train: 0.982127	val: 0.853208	test: 0.848915
PRC train: 0.979193	val: 0.776204	test: 0.789288

Epoch: 108
Loss: 0.23801479327059596
ROC train: 0.981695	val: 0.855564	test: 0.849615
PRC train: 0.978772	val: 0.791448	test: 0.780718

Epoch: 109
Loss: 0.24269618733540196
ROC train: 0.983560	val: 0.844328	test: 0.840161
PRC train: 0.981523	val: 0.767596	test: 0.761582

Epoch: 110
Loss: 0.2510493800336651
ROC train: 0.979852	val: 0.848315	test: 0.834384
PRC train: 0.976997	val: 0.763344	test: 0.785858

Epoch: 111
Loss: 0.25696941663132056
ROC train: 0.979026	val: 0.847046	test: 0.837710
PRC train: 0.975988	val: 0.755127	test: 0.789727

Epoch: 112
Loss: 0.2412643574520196
ROC train: 0.983143	val: 0.852302	test: 0.846814
PRC train: 0.980635	val: 0.790232	test: 0.806486

Epoch: 113
Loss: 0.2209676337571679
ROC train: 0.981235	val: 0.840159	test: 0.846289
PRC train: 0.978261	val: 0.784763	test: 0.799329

Epoch: 114
Loss: 0.2424702208875928
ROC train: 0.982923	val: 0.841066	test: 0.840686
PRC train: 0.980321	val: 0.771554	test: 0.794323

Epoch: 115
Loss: 0.24878680160556915
ROC train: 0.982250	val: 0.843965	test: 0.848915
PRC train: 0.979449	val: 0.772323	test: 0.793714

Epoch: 116
Loss: 0.23811118259973538
ROC train: 0.982475	val: 0.844328	test: 0.848389
PRC train: 0.980057	val: 0.765859	test: 0.802904

Epoch: 117
Loss: 0.24289785508635933
ROC train: 0.981956	val: 0.852302	test: 0.842262
PRC train: 0.979494	val: 0.767280	test: 0.798294

Epoch: 118
Loss: 0.22952719853709563
ROC train: 0.983952	val: 0.848496	test: 0.849965
PRC train: 0.981724	val: 0.783039	test: 0.801688

Epoch: 119
Loss: 0.2393244579740645
ROC train: 0.981940	val: 0.847408	test: 0.841036
PRC train: 0.979077	val: 0.784195	test: 0.788031

Epoch: 120
Loss: 0.24134435290911438
ROC train: 0.985225	val: 0.852302	test: 0.837185
PRC train: 0.982905	val: 0.790596	test: 0.786545

Early stopping
Best (ROC):	 train: 0.959915	val: 0.856651	test: 0.868347
Best (PRC):	 train: 0.951646	val: 0.794639	test: 0.800303
All runs completed.

PRC train: 0.953074	val: 0.793058	test: 0.812345

Epoch: 95
Loss: 0.2887926184864171
ROC train: 0.962813	val: 0.829044	test: 0.878693
PRC train: 0.954253	val: 0.799525	test: 0.823656

Epoch: 96
Loss: 0.30685946140943915
ROC train: 0.963718	val: 0.831169	test: 0.885866
PRC train: 0.956181	val: 0.801187	test: 0.837827

Epoch: 97
Loss: 0.31986655806334563
ROC train: 0.961444	val: 0.818024	test: 0.885164
PRC train: 0.953520	val: 0.772389	test: 0.845494

Epoch: 98
Loss: 0.3022870440233222
ROC train: 0.959081	val: 0.816922	test: 0.877758
PRC train: 0.951037	val: 0.783263	test: 0.842802

Epoch: 99
Loss: 0.3517853456796728
ROC train: 0.962903	val: 0.826131	test: 0.873782
PRC train: 0.954651	val: 0.798147	test: 0.823256

Epoch: 100
Loss: 0.2962293009681335
ROC train: 0.960807	val: 0.818969	test: 0.875497
PRC train: 0.952811	val: 0.788552	test: 0.805638

Epoch: 101
Loss: 0.2921207263237463
ROC train: 0.957730	val: 0.808501	test: 0.870741
PRC train: 0.948695	val: 0.772083	test: 0.796723

Epoch: 102
Loss: 0.27313695691898493
ROC train: 0.961662	val: 0.813066	test: 0.879785
PRC train: 0.952987	val: 0.778519	test: 0.806169

Epoch: 103
Loss: 0.2875184719693558
ROC train: 0.963722	val: 0.817080	test: 0.886567
PRC train: 0.955614	val: 0.781268	test: 0.836195

Epoch: 104
Loss: 0.2857324238412112
ROC train: 0.964616	val: 0.819520	test: 0.892492
PRC train: 0.957137	val: 0.782387	test: 0.855895

Epoch: 105
Loss: 0.29356897661512893
ROC train: 0.967123	val: 0.821409	test: 0.885164
PRC train: 0.960129	val: 0.789862	test: 0.840996

Epoch: 106
Loss: 0.2881758007034045
ROC train: 0.966236	val: 0.823140	test: 0.885086
PRC train: 0.958359	val: 0.790697	test: 0.843410

Epoch: 107
Loss: 0.30417419971957427
ROC train: 0.964056	val: 0.831956	test: 0.881656
PRC train: 0.956007	val: 0.802437	test: 0.839683

Epoch: 108
Loss: 0.29129089360869814
ROC train: 0.963449	val: 0.825187	test: 0.889374
PRC train: 0.954492	val: 0.794416	test: 0.848895

Epoch: 109
Loss: 0.28565768452654694
ROC train: 0.965272	val: 0.818890	test: 0.889062
PRC train: 0.957147	val: 0.787433	test: 0.845925

Epoch: 110
Loss: 0.30058204311238684
ROC train: 0.967562	val: 0.818103	test: 0.879239
PRC train: 0.959998	val: 0.789060	test: 0.826401

Epoch: 111
Loss: 0.2555412560320289
ROC train: 0.966858	val: 0.823062	test: 0.880954
PRC train: 0.959485	val: 0.794103	test: 0.816355

Epoch: 112
Loss: 0.30964118555395576
ROC train: 0.966172	val: 0.823140	test: 0.882669
PRC train: 0.959103	val: 0.791904	test: 0.819872

Epoch: 113
Loss: 0.3072521113117811
ROC train: 0.957507	val: 0.811019	test: 0.868636
PRC train: 0.946847	val: 0.770616	test: 0.817026

Epoch: 114
Loss: 0.3584928240779803
ROC train: 0.962008	val: 0.817946	test: 0.869494
PRC train: 0.953700	val: 0.781104	test: 0.821659

Epoch: 115
Loss: 0.2859105357213116
ROC train: 0.965978	val: 0.825030	test: 0.867623
PRC train: 0.959213	val: 0.800893	test: 0.814194

Epoch: 116
Loss: 0.29618746355305864
ROC train: 0.965511	val: 0.830303	test: 0.880253
PRC train: 0.957573	val: 0.810679	test: 0.838313

Epoch: 117
Loss: 0.29869705348146636
ROC train: 0.964442	val: 0.829831	test: 0.881890
PRC train: 0.955697	val: 0.807161	test: 0.839545

Epoch: 118
Loss: 0.2806632878592995
ROC train: 0.965934	val: 0.818339	test: 0.881110
PRC train: 0.957652	val: 0.786873	test: 0.830008

Epoch: 119
Loss: 0.2640460793301677
ROC train: 0.967452	val: 0.810704	test: 0.885554
PRC train: 0.959860	val: 0.779394	test: 0.820437

Epoch: 120
Loss: 0.2675836238308583
ROC train: 0.968417	val: 0.809209	test: 0.887737
PRC train: 0.961061	val: 0.779519	test: 0.821925

Epoch: 121
Loss: 0.3015737084095053
ROC train: 0.969444	val: 0.813066	test: 0.878927
PRC train: 0.962085	val: 0.783354	test: 0.813362

Epoch: 122
Loss: 0.28375361194220294
ROC train: 0.970435	val: 0.817237	test: 0.880175
PRC train: 0.963405	val: 0.787373	test: 0.819630

Epoch: 123
Loss: 0.2818122943879965
ROC train: 0.970098	val: 0.815033	test: 0.879239
PRC train: 0.963012	val: 0.780776	test: 0.817657

Epoch: 124
Loss: 0.3031985655134172
ROC train: 0.971303	val: 0.819126	test: 0.882280
PRC train: 0.965196	val: 0.789252	test: 0.818821

Epoch: 125
Loss: 0.29548743532952615
ROC train: 0.972404	val: 0.819520	test: 0.887581
PRC train: 0.966503	val: 0.788197	test: 0.819768

Epoch: 126
Loss: 0.2577194075413071
ROC train: 0.969261	val: 0.820701	test: 0.894285
PRC train: 0.962694	val: 0.790024	test: 0.831668

Epoch: 127
Loss: 0.30021893375473174
ROC train: 0.969498	val: 0.822353	test: 0.888750
PRC train: 0.962294	val: 0.797904	test: 0.833054

Epoch: 128
Loss: 0.27563287062506736
ROC train: 0.967766	val: 0.820779	test: 0.880253
PRC train: 0.959541	val: 0.797060	test: 0.822963

Epoch: 129
Loss: 0.26921945523906016
ROC train: 0.966676	val: 0.821724	test: 0.885866
PRC train: 0.958486	val: 0.799246	test: 0.832123

Epoch: 130
Loss: 0.2965113672183103
ROC train: 0.967784	val: 0.820071	test: 0.888049
PRC train: 0.961116	val: 0.793417	test: 0.836232

Epoch: 131
Loss: 0.31815107861997843
ROC train: 0.968190	val: 0.814089	test: 0.891479
PRC train: 0.961785	val: 0.780826	test: 0.838584

Epoch: 132
Loss: 0.27064756686463526
ROC train: 0.963197	val: 0.814482	test: 0.893584
PRC train: 0.954693	val: 0.778134	test: 0.842235

Epoch: 133
Loss: 0.2684958148935988
ROC train: 0.965507	val: 0.817001	test: 0.887347
PRC train: 0.958155	val: 0.784236	test: 0.833809

Epoch: 134
Loss: 0.2600997712798984
ROC train: 0.967869	val: 0.818261	test: 0.881188
PRC train: 0.960541	val: 0.791406	test: 0.822651

Epoch: 135
Loss: 0.3095390779346313
ROC train: 0.970263	val: 0.822353	test: 0.886645
PRC train: 0.962624	val: 0.792889	test: 0.831890

Epoch: 136
Loss: 0.23428950433673407
ROC train: 0.972490	val: 0.822747	test: 0.886645
PRC train: 0.967050	val: 0.790931	test: 0.837036

Epoch: 137
Loss: 0.2755280286676437
ROC train: 0.974401	val: 0.823377	test: 0.881032
PRC train: 0.969423	val: 0.797109	test: 0.834437

Epoch: 138
Loss: 0.2846582662693907
ROC train: 0.975306	val: 0.821881	test: 0.874016
PRC train: 0.970733	val: 0.802492	test: 0.819074

Epoch: 139
Loss: 0.2419359221839287
ROC train: 0.974886	val: 0.824557	test: 0.875887
PRC train: 0.969853	val: 0.808999	test: 0.823475

Epoch: 140
Loss: 0.2543215923633214
ROC train: 0.972025	val: 0.823849	test: 0.884229
PRC train: 0.965827	val: 0.804266	test: 0.839266

Epoch: 141
Loss: 0.25988292778140104
ROC train: 0.972530	val: 0.830382	test: 0.882825
PRC train: 0.967059	val: 0.809972	test: 0.836147

Epoch: 142
Loss: 0.244908639877091
ROC train: 0.975572	val: 0.826368	test: 0.876744
PRC train: 0.971119	val: 0.802575	test: 0.835126

Early stopping
Best (ROC):	 train: 0.964056	val: 0.831956	test: 0.881656
Best (PRC):	 train: 0.956007	val: 0.802437	test: 0.839683

PRC train: 0.951367	val: 0.778436	test: 0.809494

Epoch: 95
Loss: 0.32331535903561953
ROC train: 0.957585	val: 0.805274	test: 0.881578
PRC train: 0.949955	val: 0.770485	test: 0.819062

Epoch: 96
Loss: 0.30605133050699596
ROC train: 0.957863	val: 0.819048	test: 0.880486
PRC train: 0.949187	val: 0.792021	test: 0.819013

Epoch: 97
Loss: 0.3230127690456852
ROC train: 0.964444	val: 0.827470	test: 0.870897
PRC train: 0.957483	val: 0.812870	test: 0.810537

Epoch: 98
Loss: 0.30473802321176613
ROC train: 0.965367	val: 0.812121	test: 0.865128
PRC train: 0.958867	val: 0.790715	test: 0.792701

Epoch: 99
Loss: 0.340660593341542
ROC train: 0.964810	val: 0.809681	test: 0.869962
PRC train: 0.957935	val: 0.791789	test: 0.796740

Epoch: 100
Loss: 0.31203045143220176
ROC train: 0.961915	val: 0.808264	test: 0.872223
PRC train: 0.954204	val: 0.795138	test: 0.807799

Epoch: 101
Loss: 0.29327462718549946
ROC train: 0.962303	val: 0.813932	test: 0.873704
PRC train: 0.955916	val: 0.796412	test: 0.811251

Epoch: 102
Loss: 0.28211509808290847
ROC train: 0.963054	val: 0.815270	test: 0.877602
PRC train: 0.956420	val: 0.792104	test: 0.806824

Epoch: 103
Loss: 0.2875016731630621
ROC train: 0.965857	val: 0.819362	test: 0.878771
PRC train: 0.958069	val: 0.796726	test: 0.798383

Epoch: 104
Loss: 0.285463379009292
ROC train: 0.966998	val: 0.820779	test: 0.879941
PRC train: 0.959044	val: 0.801614	test: 0.797405

Epoch: 105
Loss: 0.3356695776374702
ROC train: 0.968323	val: 0.814955	test: 0.870585
PRC train: 0.961854	val: 0.798515	test: 0.788744

Epoch: 106
Loss: 0.323104504245556
ROC train: 0.967847	val: 0.813144	test: 0.864972
PRC train: 0.960725	val: 0.789317	test: 0.785964

Epoch: 107
Loss: 0.29022829011439977
ROC train: 0.965859	val: 0.814325	test: 0.869806
PRC train: 0.957809	val: 0.787737	test: 0.791494

Epoch: 108
Loss: 0.3013431083399418
ROC train: 0.965320	val: 0.816529	test: 0.875653
PRC train: 0.957001	val: 0.787734	test: 0.795815

Epoch: 109
Loss: 0.2800635532668133
ROC train: 0.965162	val: 0.814246	test: 0.879317
PRC train: 0.956931	val: 0.790306	test: 0.802777

Epoch: 110
Loss: 0.29408170675230627
ROC train: 0.965525	val: 0.816135	test: 0.881422
PRC train: 0.956353	val: 0.793535	test: 0.805463

Epoch: 111
Loss: 0.2713930219715771
ROC train: 0.966419	val: 0.816135	test: 0.877602
PRC train: 0.957959	val: 0.793426	test: 0.800182

Epoch: 112
Loss: 0.25893911980531803
ROC train: 0.967910	val: 0.812121	test: 0.872612
PRC train: 0.959811	val: 0.792442	test: 0.806509

Epoch: 113
Loss: 0.28878378702054086
ROC train: 0.967845	val: 0.807950	test: 0.867779
PRC train: 0.960282	val: 0.791401	test: 0.783250

Epoch: 114
Loss: 0.27815188232810095
ROC train: 0.970245	val: 0.815742	test: 0.875419
PRC train: 0.963075	val: 0.800686	test: 0.794563

Epoch: 115
Loss: 0.2779910088431269
ROC train: 0.969642	val: 0.820779	test: 0.879239
PRC train: 0.961538	val: 0.805153	test: 0.800888

Epoch: 116
Loss: 0.27543614586610377
ROC train: 0.970848	val: 0.824242	test: 0.876588
PRC train: 0.962678	val: 0.809318	test: 0.806939

Epoch: 117
Loss: 0.2666173122838914
ROC train: 0.972901	val: 0.827706	test: 0.867623
PRC train: 0.965949	val: 0.813599	test: 0.800389

Epoch: 118
Loss: 0.30180823543579127
ROC train: 0.973151	val: 0.832664	test: 0.870585
PRC train: 0.965446	val: 0.818484	test: 0.802358

Epoch: 119
Loss: 0.31445142872412757
ROC train: 0.972416	val: 0.836600	test: 0.878459
PRC train: 0.965643	val: 0.820152	test: 0.800185

Epoch: 120
Loss: 0.268779679182813
ROC train: 0.970917	val: 0.825738	test: 0.866609
PRC train: 0.964811	val: 0.814627	test: 0.783645

Epoch: 121
Loss: 0.2746900565659977
ROC train: 0.968840	val: 0.821881	test: 0.860373
PRC train: 0.961974	val: 0.813683	test: 0.771152

Epoch: 122
Loss: 0.25132768998983473
ROC train: 0.970786	val: 0.824872	test: 0.870508
PRC train: 0.964732	val: 0.808318	test: 0.794464

Epoch: 123
Loss: 0.2834421349037898
ROC train: 0.971272	val: 0.821094	test: 0.877602
PRC train: 0.964686	val: 0.802812	test: 0.805173

Epoch: 124
Loss: 0.2615807976055103
ROC train: 0.971078	val: 0.811098	test: 0.868325
PRC train: 0.965972	val: 0.787842	test: 0.791036

Epoch: 125
Loss: 0.3285617857304549
ROC train: 0.967932	val: 0.800630	test: 0.857566
PRC train: 0.961431	val: 0.780636	test: 0.777467

Epoch: 126
Loss: 0.29430016770703005
ROC train: 0.969893	val: 0.804014	test: 0.864115
PRC train: 0.963562	val: 0.788191	test: 0.800673

Epoch: 127
Loss: 0.24283511812788997
ROC train: 0.973587	val: 0.820150	test: 0.881500
PRC train: 0.968082	val: 0.803042	test: 0.826698

Epoch: 128
Loss: 0.28551023462022773
ROC train: 0.974225	val: 0.825895	test: 0.887737
PRC train: 0.968980	val: 0.803343	test: 0.833363

Epoch: 129
Loss: 0.2723495781237041
ROC train: 0.972971	val: 0.823534	test: 0.882358
PRC train: 0.967496	val: 0.801665	test: 0.825023

Epoch: 130
Loss: 0.26480173645999805
ROC train: 0.972249	val: 0.820622	test: 0.876043
PRC train: 0.966661	val: 0.804188	test: 0.805692

Epoch: 131
Loss: 0.3297423244292345
ROC train: 0.971154	val: 0.813538	test: 0.874873
PRC train: 0.964817	val: 0.799831	test: 0.810320

Epoch: 132
Loss: 0.30615151504284155
ROC train: 0.966929	val: 0.815033	test: 0.872067
PRC train: 0.958905	val: 0.796784	test: 0.800197

Epoch: 133
Loss: 0.3106746474109448
ROC train: 0.974365	val: 0.819599	test: 0.869104
PRC train: 0.968893	val: 0.807423	test: 0.791306

Epoch: 134
Loss: 0.25362968530084734
ROC train: 0.972542	val: 0.808422	test: 0.863023
PRC train: 0.967291	val: 0.797131	test: 0.782449

Epoch: 135
Loss: 0.2752006576616866
ROC train: 0.971579	val: 0.806848	test: 0.870585
PRC train: 0.965999	val: 0.789112	test: 0.792093

Epoch: 136
Loss: 0.2582242024833973
ROC train: 0.974135	val: 0.816214	test: 0.879239
PRC train: 0.968633	val: 0.791208	test: 0.805720

Epoch: 137
Loss: 0.24630927307805917
ROC train: 0.973959	val: 0.820701	test: 0.880331
PRC train: 0.968753	val: 0.795511	test: 0.816200

Epoch: 138
Loss: 0.2978977200169842
ROC train: 0.975094	val: 0.823140	test: 0.874016
PRC train: 0.970001	val: 0.803380	test: 0.803867

Epoch: 139
Loss: 0.29910905112422304
ROC train: 0.970518	val: 0.806139	test: 0.860762
PRC train: 0.965480	val: 0.785693	test: 0.777294

Epoch: 140
Loss: 0.2483662482907573
ROC train: 0.973798	val: 0.817080	test: 0.863179
PRC train: 0.968940	val: 0.798156	test: 0.781623

Epoch: 141
Loss: 0.26658609229314967
ROC train: 0.975310	val: 0.826604	test: 0.874094
PRC train: 0.969540	val: 0.808080	test: 0.793766

Epoch: 142
Loss: 0.2905948969411202
ROC train: 0.971786	val: 0.825895	test: 0.880798
PRC train: 0.963848	val: 0.806531	test: 0.804442

Epoch: 143
Loss: 0.24944914913071545
ROC train: 0.977172	val: 0.819992	test: 0.875809
PRC train: 0.972361	val: 0.800952	test: 0.793523

Epoch: 144
Loss: 0.26780564555421604
ROC train: 0.977946	val: 0.813302	test: 0.865908
PRC train: 0.973512	val: 0.776506	test: 0.786112

Epoch: 145
Loss: 0.24255108199877906
ROC train: 0.979845	val: 0.816765	test: 0.870741
PRC train: 0.975595	val: 0.770887	test: 0.799336

Epoch: 146
Loss: 0.23787560648256112
ROC train: 0.979117	val: 0.824636	test: 0.876277
PRC train: 0.975004	val: 0.793585	test: 0.807958

Epoch: 147
Loss: 0.23941259110322172
ROC train: 0.975017	val: 0.830618	test: 0.882202
PRC train: 0.969517	val: 0.808280	test: 0.810010

Epoch: 148
Loss: 0.2688890847523949
ROC train: 0.976711	val: 0.829752	test: 0.884151
PRC train: 0.971602	val: 0.812304	test: 0.807692

Epoch: 149
Loss: 0.2628795356458723
ROC train: 0.979935	val: 0.820858	test: 0.886645
PRC train: 0.976039	val: 0.803319	test: 0.812981

Epoch: 150
Loss: 0.2737338273498435
ROC train: 0.979275	val: 0.806218	test: 0.876121
PRC train: 0.975775	val: 0.773802	test: 0.797983

Epoch: 151
Loss: 0.2697303241844547
ROC train: 0.976926	val: 0.816686	test: 0.875887
PRC train: 0.972413	val: 0.797627	test: 0.797624

Epoch: 152
Loss: 0.23807523653164683
ROC train: 0.977066	val: 0.822747	test: 0.870585
PRC train: 0.972258	val: 0.800775	test: 0.793356

Epoch: 153
Loss: 0.2487986723296304
ROC train: 0.978762	val: 0.824715	test: 0.870585
PRC train: 0.974378	val: 0.804307	test: 0.794791

Epoch: 154
Loss: 0.25567548823402036
ROC train: 0.978697	val: 0.830775	test: 0.885242
PRC train: 0.974861	val: 0.813775	test: 0.814959

Early stopping
Best (ROC):	 train: 0.972416	val: 0.836600	test: 0.878459
Best (PRC):	 train: 0.965643	val: 0.820152	test: 0.800185
All runs completed.
