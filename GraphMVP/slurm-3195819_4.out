>>> Starting run for dataset: clintox
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running SCAFF configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.6.yml on cuda:0
Running SCAFF configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.7.yml on cuda:1
Running SCAFF configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.8.yml on cuda:2
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.7.yml --runseed 1 --device cuda:1
Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.7.yml --runseed 2 --device cuda:1
Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.7.yml --runseed 3 --device cuda:1
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.6.yml --runseed 1 --device cuda:0
Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.6.yml --runseed 2 --device cuda:0
Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.6.yml --runseed 3 --device cuda:0
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.8.yml --runseed 1 --device cuda:2
Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.8.yml --runseed 2 --device cuda:2
Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.8.yml --runseed 3 --device cuda:2
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:0
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/clintox/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/clintox/scaff/train_prop=0.6/clintox_scaff_3_20-05_14-43-16  ]
[ Using Seed :  3  ]
[ Using device :  cuda:0  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6569896330900244
ROC train: 0.567423	val: 0.476401	test: 0.496346
PRC train: 0.522469	val: 0.515334	test: 0.507539

Epoch: 2
Loss: 0.5876873711266714
ROC train: 0.604678	val: 0.405019	test: 0.454086
PRC train: 0.533422	val: 0.496776	test: 0.504640

Epoch: 3
Loss: 0.5332494064898655
ROC train: 0.657997	val: 0.409757	test: 0.473963
PRC train: 0.554438	val: 0.500481	test: 0.532918

Epoch: 4
Loss: 0.47561475421134836
ROC train: 0.735525	val: 0.440022	test: 0.543707
PRC train: 0.586316	val: 0.505170	test: 0.539778

Epoch: 5
Loss: 0.4383370859992109
ROC train: 0.777817	val: 0.489697	test: 0.647653
PRC train: 0.599194	val: 0.511973	test: 0.535206

Epoch: 6
Loss: 0.3980240770216069
ROC train: 0.796544	val: 0.522728	test: 0.663785
PRC train: 0.613764	val: 0.516314	test: 0.557587

Epoch: 7
Loss: 0.36238742073662666
ROC train: 0.821042	val: 0.580092	test: 0.705813
PRC train: 0.640832	val: 0.527418	test: 0.550874

Epoch: 8
Loss: 0.33671698376095205
ROC train: 0.846248	val: 0.608576	test: 0.721791
PRC train: 0.671403	val: 0.531535	test: 0.549467

Epoch: 9
Loss: 0.31473509172849
ROC train: 0.859278	val: 0.579750	test: 0.706689
PRC train: 0.665606	val: 0.524644	test: 0.548476

Epoch: 10
Loss: 0.2855448252839562
ROC train: 0.874385	val: 0.603697	test: 0.703302
PRC train: 0.684593	val: 0.528889	test: 0.548981

Epoch: 11
Loss: 0.2719955010824668
ROC train: 0.887378	val: 0.641642	test: 0.719166
PRC train: 0.706321	val: 0.535470	test: 0.554930

Epoch: 12
Loss: 0.25936246602370355
ROC train: 0.899291	val: 0.696872	test: 0.744341
PRC train: 0.730763	val: 0.547013	test: 0.574369

Epoch: 13
Loss: 0.253269285581604
ROC train: 0.901998	val: 0.660564	test: 0.741148
PRC train: 0.732547	val: 0.539782	test: 0.561517

Epoch: 14
Loss: 0.24021477382845552
ROC train: 0.901969	val: 0.648487	test: 0.721877
PRC train: 0.729422	val: 0.535573	test: 0.549492

Epoch: 15
Loss: 0.21652262365546826
ROC train: 0.911393	val: 0.659950	test: 0.735210
PRC train: 0.749306	val: 0.539511	test: 0.556514

Epoch: 16
Loss: 0.22360785401663807
ROC train: 0.914549	val: 0.676522	test: 0.753927
PRC train: 0.761048	val: 0.546303	test: 0.570923

Epoch: 17
Loss: 0.21290989181328482
ROC train: 0.921773	val: 0.680987	test: 0.753142
PRC train: 0.768391	val: 0.552188	test: 0.597003

Epoch: 18
Loss: 0.2098949666803006
ROC train: 0.924921	val: 0.625307	test: 0.708272
PRC train: 0.793458	val: 0.537514	test: 0.557547

Epoch: 19
Loss: 0.19533847680394595
ROC train: 0.927276	val: 0.644340	test: 0.727965
PRC train: 0.784952	val: 0.550159	test: 0.566707

Epoch: 20
Loss: 0.18818735791607186
ROC train: 0.940303	val: 0.669339	test: 0.730858
PRC train: 0.805783	val: 0.557164	test: 0.567408

Epoch: 21
Loss: 0.18668435471234185
ROC train: 0.941808	val: 0.675259	test: 0.700968
PRC train: 0.816011	val: 0.553691	test: 0.555613

Epoch: 22
Loss: 0.18921942574983117
ROC train: 0.944347	val: 0.672150	test: 0.717318
PRC train: 0.819104	val: 0.551319	test: 0.555880

Epoch: 23
Loss: 0.17212305130048244
ROC train: 0.946547	val: 0.690115	test: 0.729460
PRC train: 0.816796	val: 0.564493	test: 0.557461

Epoch: 24
Loss: 0.16776178464920635
ROC train: 0.946983	val: 0.696736	test: 0.728224
PRC train: 0.819092	val: 0.565851	test: 0.567061

Epoch: 25
Loss: 0.17323759695008445
ROC train: 0.950804	val: 0.703161	test: 0.715769
PRC train: 0.826397	val: 0.564832	test: 0.572773

Epoch: 26
Loss: 0.17981081941791308
ROC train: 0.950703	val: 0.671129	test: 0.688838
PRC train: 0.830118	val: 0.552378	test: 0.557437

Epoch: 27
Loss: 0.16379394889732674
ROC train: 0.957889	val: 0.659959	test: 0.700390
PRC train: 0.841288	val: 0.554940	test: 0.554219

Epoch: 28
Loss: 0.17937327422673105
ROC train: 0.960494	val: 0.662455	test: 0.740769
PRC train: 0.839381	val: 0.553843	test: 0.569880

Epoch: 29
Loss: 0.1652673686725779
ROC train: 0.954521	val: 0.649111	test: 0.731835
PRC train: 0.834507	val: 0.552117	test: 0.563537

Epoch: 30
Loss: 0.16224654460646942
ROC train: 0.951426	val: 0.646694	test: 0.714417
PRC train: 0.836578	val: 0.547661	test: 0.559889

Epoch: 31
Loss: 0.16552311915590548
ROC train: 0.956644	val: 0.649408	test: 0.747806
PRC train: 0.847703	val: 0.546070	test: 0.567308

Epoch: 32
Loss: 0.1632046005061638
ROC train: 0.956721	val: 0.650028	test: 0.752977
PRC train: 0.849736	val: 0.555433	test: 0.567009

Epoch: 33
Loss: 0.1426545130315549Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:0
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/clintox/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/clintox/scaff/train_prop=0.6/clintox_scaff_2_20-05_14-43-16  ]
[ Using Seed :  2  ]
[ Using device :  cuda:0  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6919323631423587
ROC train: 0.536908	val: 0.392795	test: 0.365098
PRC train: 0.515374	val: 0.490849	test: 0.490225

Epoch: 2
Loss: 0.6208288899328767
ROC train: 0.606801	val: 0.417706	test: 0.407569
PRC train: 0.533018	val: 0.494590	test: 0.519128

Epoch: 3
Loss: 0.5675423472518981
ROC train: 0.657301	val: 0.450310	test: 0.458025
PRC train: 0.544805	val: 0.501435	test: 0.526353

Epoch: 4
Loss: 0.5088656311414632
ROC train: 0.741481	val: 0.507679	test: 0.543790
PRC train: 0.581004	val: 0.519020	test: 0.513067

Epoch: 5
Loss: 0.46318809591950055
ROC train: 0.761995	val: 0.520416	test: 0.544933
PRC train: 0.583922	val: 0.528704	test: 0.510536

Epoch: 6
Loss: 0.42862941349833117
ROC train: 0.763575	val: 0.515375	test: 0.523659
PRC train: 0.591827	val: 0.527925	test: 0.535082

Epoch: 7
Loss: 0.3780698087719862
ROC train: 0.801509	val: 0.539765	test: 0.574749
PRC train: 0.608684	val: 0.534899	test: 0.527511

Epoch: 8
Loss: 0.3691135525616297
ROC train: 0.819650	val: 0.559518	test: 0.623457
PRC train: 0.618297	val: 0.526986	test: 0.523744

Epoch: 9
Loss: 0.33636934718929334
ROC train: 0.838028	val: 0.615161	test: 0.665296
PRC train: 0.638959	val: 0.534527	test: 0.531697

Epoch: 10
Loss: 0.3052737764422825
ROC train: 0.842774	val: 0.620069	test: 0.612426
PRC train: 0.641346	val: 0.546644	test: 0.521417

Epoch: 11
Loss: 0.2965174562283897
ROC train: 0.854198	val: 0.646236	test: 0.625472
PRC train: 0.655460	val: 0.548413	test: 0.526420

Epoch: 12
Loss: 0.28087823348473356
ROC train: 0.873208	val: 0.681166	test: 0.680067
PRC train: 0.677613	val: 0.556458	test: 0.538694

Epoch: 13
Loss: 0.26200484553469017
ROC train: 0.890039	val: 0.676643	test: 0.679996
PRC train: 0.703751	val: 0.554413	test: 0.537727

Epoch: 14
Loss: 0.25413554102339536
ROC train: 0.899390	val: 0.648866	test: 0.682373
PRC train: 0.715737	val: 0.545269	test: 0.536990

Epoch: 15
Loss: 0.22584854004103105
ROC train: 0.904407	val: 0.626866	test: 0.671570
PRC train: 0.710740	val: 0.552332	test: 0.536653

Epoch: 16
Loss: 0.23158617429518974
ROC train: 0.918159	val: 0.647180	test: 0.701714
PRC train: 0.737004	val: 0.553671	test: 0.543305

Epoch: 17
Loss: 0.20949362260185866
ROC train: 0.926821	val: 0.671149	test: 0.723265
PRC train: 0.750463	val: 0.549896	test: 0.548725

Epoch: 18
Loss: 0.2038073818137251
ROC train: 0.927572	val: 0.658141	test: 0.699095
PRC train: 0.763283	val: 0.555038	test: 0.541901

Epoch: 19
Loss: 0.20544009685240291
ROC train: 0.934814	val: 0.676716	test: 0.705385
PRC train: 0.786044	val: 0.552519	test: 0.549881

Epoch: 20
Loss: 0.21700775995773436
ROC train: 0.935186	val: 0.690564	test: 0.718725
PRC train: 0.775491	val: 0.554813	test: 0.559212

Epoch: 21
Loss: 0.1928809672885076
ROC train: 0.941410	val: 0.678641	test: 0.727946
PRC train: 0.800173	val: 0.554941	test: 0.561691

Epoch: 22
Loss: 0.1948603842619501
ROC train: 0.941262	val: 0.661530	test: 0.750183
PRC train: 0.797678	val: 0.545450	test: 0.567606

Epoch: 23
Loss: 0.18801802804208972
ROC train: 0.941216	val: 0.664857	test: 0.754234
PRC train: 0.806165	val: 0.545153	test: 0.568245

Epoch: 24
Loss: 0.17714615587865198
ROC train: 0.942667	val: 0.685211	test: 0.762929
PRC train: 0.811690	val: 0.552281	test: 0.571472

Epoch: 25
Loss: 0.1753653450232238
ROC train: 0.944232	val: 0.666270	test: 0.751137
PRC train: 0.825201	val: 0.549228	test: 0.565443

Epoch: 26
Loss: 0.1766981737094741
ROC train: 0.946439	val: 0.643986	test: 0.735651
PRC train: 0.831016	val: 0.549442	test: 0.560603

Epoch: 27
Loss: 0.18019423789028008
ROC train: 0.948747	val: 0.652087	test: 0.735466
PRC train: 0.831872	val: 0.551977	test: 0.569821

Epoch: 28
Loss: 0.18880532721433066
ROC train: 0.947556	val: 0.667109	test: 0.756271
PRC train: 0.809626	val: 0.550165	test: 0.572822

Epoch: 29
Loss: 0.1617448160564188
ROC train: 0.953736	val: 0.676994	test: 0.747664
PRC train: 0.820788	val: 0.553490	test: 0.570185

Epoch: 30
Loss: 0.1512952782908045
ROC train: 0.959839	val: 0.671256	test: 0.729658
PRC train: 0.840949	val: 0.557088	test: 0.562658

Epoch: 31
Loss: 0.15851076565818958
ROC train: 0.962047	val: 0.675688	test: 0.738052
PRC train: 0.844604	val: 0.559864	test: 0.568907

Epoch: 32
Loss: 0.15532986636186602
ROC train: 0.959366	val: 0.684905	test: 0.744764
PRC train: 0.832938	val: 0.558829	test: 0.574753

Epoch: 33
Loss: 0.15047826504334555Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:0
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/clintox/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/clintox/scaff/train_prop=0.6/clintox_scaff_1_20-05_14-43-16  ]
[ Using Seed :  1  ]
[ Using device :  cuda:0  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6541831451570896
ROC train: 0.597259	val: 0.505924	test: 0.491021
PRC train: 0.534950	val: 0.513125	test: 0.505727

Epoch: 2
Loss: 0.5858792780080497
ROC train: 0.652270	val: 0.469415	test: 0.470939
PRC train: 0.545233	val: 0.508248	test: 0.528806

Epoch: 3
Loss: 0.5283475315777275
ROC train: 0.723406	val: 0.501745	test: 0.504359
PRC train: 0.580414	val: 0.515192	test: 0.530349

Epoch: 4
Loss: 0.47847303090116006
ROC train: 0.777595	val: 0.547363	test: 0.563985
PRC train: 0.610807	val: 0.523364	test: 0.537686

Epoch: 5
Loss: 0.4319526383721162
ROC train: 0.797050	val: 0.577182	test: 0.570310
PRC train: 0.629287	val: 0.528080	test: 0.538470

Epoch: 6
Loss: 0.3882146539065725
ROC train: 0.822973	val: 0.592764	test: 0.586816
PRC train: 0.643236	val: 0.533015	test: 0.540487

Epoch: 7
Loss: 0.3637364345533225
ROC train: 0.848467	val: 0.614954	test: 0.624825
PRC train: 0.661366	val: 0.538521	test: 0.548756

Epoch: 8
Loss: 0.33691598719947957
ROC train: 0.864335	val: 0.646563	test: 0.671565
PRC train: 0.686466	val: 0.542843	test: 0.538456

Epoch: 9
Loss: 0.3043080333565263
ROC train: 0.877156	val: 0.617522	test: 0.638085
PRC train: 0.685974	val: 0.534233	test: 0.555844

Epoch: 10
Loss: 0.28234361398843455
ROC train: 0.886861	val: 0.623542	test: 0.636348
PRC train: 0.682341	val: 0.533874	test: 0.557483

Epoch: 11
Loss: 0.2781591969617903
ROC train: 0.895357	val: 0.670066	test: 0.663228
PRC train: 0.702600	val: 0.548111	test: 0.552399

Epoch: 12
Loss: 0.25073046821715694
ROC train: 0.903013	val: 0.679972	test: 0.679242
PRC train: 0.716545	val: 0.553175	test: 0.545320

Epoch: 13
Loss: 0.234743785529183
ROC train: 0.904115	val: 0.681085	test: 0.663733
PRC train: 0.726421	val: 0.556270	test: 0.543226

Epoch: 14
Loss: 0.23252527983421387
ROC train: 0.908180	val: 0.705387	test: 0.667542
PRC train: 0.737012	val: 0.570723	test: 0.549192

Epoch: 15
Loss: 0.2204029741869999
ROC train: 0.920141	val: 0.676376	test: 0.673554
PRC train: 0.743030	val: 0.554808	test: 0.543536

Epoch: 16
Loss: 0.21885050405505788
ROC train: 0.922697	val: 0.666475	test: 0.682966
PRC train: 0.757583	val: 0.551234	test: 0.546210

Epoch: 17
Loss: 0.21346403499179814
ROC train: 0.927268	val: 0.683357	test: 0.713390
PRC train: 0.770557	val: 0.550985	test: 0.565719

Epoch: 18
Loss: 0.212307598151562
ROC train: 0.933638	val: 0.664724	test: 0.701154
PRC train: 0.794347	val: 0.548707	test: 0.569020

Epoch: 19
Loss: 0.19397807641382053
ROC train: 0.935237	val: 0.662273	test: 0.700105
PRC train: 0.794787	val: 0.552802	test: 0.587332

Epoch: 20
Loss: 0.1918789370397167
ROC train: 0.935577	val: 0.675613	test: 0.709188
PRC train: 0.799791	val: 0.554652	test: 0.602255

Epoch: 21
Loss: 0.2009111784875982
ROC train: 0.939441	val: 0.672068	test: 0.692845
PRC train: 0.811449	val: 0.557489	test: 0.573349

Epoch: 22
Loss: 0.19065785328881096
ROC train: 0.936024	val: 0.678894	test: 0.685167
PRC train: 0.806039	val: 0.576993	test: 0.563639

Epoch: 23
Loss: 0.178971352151356
ROC train: 0.935768	val: 0.693572	test: 0.693088
PRC train: 0.792686	val: 0.565468	test: 0.573648

Epoch: 24
Loss: 0.17691645127240965
ROC train: 0.937178	val: 0.676049	test: 0.686225
PRC train: 0.794769	val: 0.571146	test: 0.554030

Epoch: 25
Loss: 0.18271752957532128
ROC train: 0.944011	val: 0.675100	test: 0.678181
PRC train: 0.813749	val: 0.571184	test: 0.550830

Epoch: 26
Loss: 0.187107717884669
ROC train: 0.951603	val: 0.666158	test: 0.704395
PRC train: 0.829564	val: 0.552539	test: 0.555448

Epoch: 27
Loss: 0.17439621451259588
ROC train: 0.951455	val: 0.688071	test: 0.735968
PRC train: 0.829187	val: 0.552354	test: 0.564967

Epoch: 28
Loss: 0.17226389469721545
ROC train: 0.947587	val: 0.684986	test: 0.749779
PRC train: 0.823273	val: 0.544573	test: 0.560556

Epoch: 29
Loss: 0.1665456111022995
ROC train: 0.950622	val: 0.705157	test: 0.754445
PRC train: 0.830730	val: 0.551135	test: 0.557288

Epoch: 30
Loss: 0.16226691526750675
ROC train: 0.954615	val: 0.714103	test: 0.739004
PRC train: 0.844543	val: 0.558454	test: 0.564497

Epoch: 31
Loss: 0.16714226568749702
ROC train: 0.957744	val: 0.712723	test: 0.716041
PRC train: 0.859025	val: 0.563836	test: 0.563292

Epoch: 32
Loss: 0.16481693973400457
ROC train: 0.962963	val: 0.716931	test: 0.725303
PRC train: 0.863189	val: 0.569830	test: 0.567802

Epoch: 33
Loss: 0.15157393337441144Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:1
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/clintox/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/clintox/scaff/train_prop=0.7/clintox_scaff_1_20-05_14-43-16  ]
[ Using Seed :  1  ]
[ Using device :  cuda:1  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6526766077288693
ROC train: 0.582060	val: 0.541246	test: 0.510474
PRC train: 0.525537	val: 0.526843	test: 0.505627

Epoch: 2
Loss: 0.570401390799961
ROC train: 0.616701	val: 0.510175	test: 0.487889
PRC train: 0.528268	val: 0.518919	test: 0.504027

Epoch: 3
Loss: 0.5034982559209467
ROC train: 0.651151	val: 0.541409	test: 0.525389
PRC train: 0.538006	val: 0.526770	test: 0.505702

Epoch: 4
Loss: 0.44017035705924046
ROC train: 0.683879	val: 0.588314	test: 0.531319
PRC train: 0.551584	val: 0.538561	test: 0.506715

Epoch: 5
Loss: 0.40231841233026133
ROC train: 0.743960	val: 0.631038	test: 0.561965
PRC train: 0.574185	val: 0.548480	test: 0.507788

Epoch: 6
Loss: 0.365430323237618
ROC train: 0.776099	val: 0.641825	test: 0.572974
PRC train: 0.589635	val: 0.555758	test: 0.514065

Epoch: 7
Loss: 0.35301602692656936
ROC train: 0.797712	val: 0.683492	test: 0.608343
PRC train: 0.604827	val: 0.568423	test: 0.523481

Epoch: 8
Loss: 0.30255675767184154
ROC train: 0.792223	val: 0.670923	test: 0.610628
PRC train: 0.598810	val: 0.562487	test: 0.525037

Epoch: 9
Loss: 0.27676359512853077
ROC train: 0.793087	val: 0.661908	test: 0.616025
PRC train: 0.597662	val: 0.561851	test: 0.523009

Epoch: 10
Loss: 0.29610160372679073
ROC train: 0.829727	val: 0.662503	test: 0.604075
PRC train: 0.613734	val: 0.557189	test: 0.520617

Epoch: 11
Loss: 0.2720199888000666
ROC train: 0.846619	val: 0.664943	test: 0.554647
PRC train: 0.619944	val: 0.551741	test: 0.513360

Epoch: 12
Loss: 0.25459069483938934
ROC train: 0.867248	val: 0.696114	test: 0.587547
PRC train: 0.641043	val: 0.557888	test: 0.517773

Epoch: 13
Loss: 0.22673914492211286
ROC train: 0.869175	val: 0.700311	test: 0.606634
PRC train: 0.646555	val: 0.556186	test: 0.521372

Epoch: 14
Loss: 0.2569920424677514
ROC train: 0.878499	val: 0.669710	test: 0.610855
PRC train: 0.651630	val: 0.551603	test: 0.520224

Epoch: 15
Loss: 0.2618192915524737
ROC train: 0.877879	val: 0.649080	test: 0.637578
PRC train: 0.655950	val: 0.552320	test: 0.524347

Epoch: 16
Loss: 0.20375125096838104
ROC train: 0.870674	val: 0.639026	test: 0.632794
PRC train: 0.661940	val: 0.549589	test: 0.526549

Epoch: 17
Loss: 0.2548611267837924
ROC train: 0.886381	val: 0.651220	test: 0.627907
PRC train: 0.671559	val: 0.548396	test: 0.535659

Epoch: 18
Loss: 0.1933529298115188
ROC train: 0.896571	val: 0.691472	test: 0.657324
PRC train: 0.696114	val: 0.557333	test: 0.552987

Epoch: 19
Loss: 0.1934165798069805
ROC train: 0.889579	val: 0.690184	test: 0.666204
PRC train: 0.699384	val: 0.553745	test: 0.542900

Epoch: 20
Loss: 0.2908332386713838
ROC train: 0.896154	val: 0.695845	test: 0.682522
PRC train: 0.708002	val: 0.552694	test: 0.536453

Epoch: 21
Loss: 0.18018911134047005
ROC train: 0.904203	val: 0.707532	test: 0.701547
PRC train: 0.705036	val: 0.559912	test: 0.543320

Epoch: 22
Loss: 0.3028102337158295
ROC train: 0.902352	val: 0.717146	test: 0.705096
PRC train: 0.696624	val: 0.566342	test: 0.547304

Epoch: 23
Loss: 0.254000854830959
ROC train: 0.892430	val: 0.690207	test: 0.683815
PRC train: 0.710956	val: 0.566625	test: 0.544593

Epoch: 24
Loss: 0.19820285747778432
ROC train: 0.893621	val: 0.683360	test: 0.678843
PRC train: 0.726494	val: 0.563454	test: 0.540805

Epoch: 25
Loss: 0.18185917213727537
ROC train: 0.906494	val: 0.696237	test: 0.687403
PRC train: 0.749810	val: 0.567914	test: 0.553244

Epoch: 26
Loss: 0.18478412597050822
ROC train: 0.916954	val: 0.692581	test: 0.704745
PRC train: 0.752295	val: 0.559943	test: 0.559212

Epoch: 27
Loss: 0.21091491411502755
ROC train: 0.914210	val: 0.678476	test: 0.707111
PRC train: 0.744714	val: 0.559331	test: 0.557996

Epoch: 28
Loss: 0.17575211792439055
ROC train: 0.909973	val: 0.663208	test: 0.752931
PRC train: 0.731997	val: 0.564593	test: 0.564474

Epoch: 29
Loss: 0.2320084447315081
ROC train: 0.918507	val: 0.682205	test: 0.743175
PRC train: 0.745511	val: 0.576337	test: 0.549627

Epoch: 30
Loss: 0.2948449086927665
ROC train: 0.909549	val: 0.725014	test: 0.722517
PRC train: 0.732534	val: 0.598455	test: 0.540011

Epoch: 31
Loss: 0.16814665201709122
ROC train: 0.890473	val: 0.698577	test: 0.661479
PRC train: 0.702849	val: 0.568858	test: 0.530898

Epoch: 32
Loss: 0.2653011049561334
ROC train: 0.897937	val: 0.695542	test: 0.649676
PRC train: 0.704430	val: 0.577827	test: 0.535326

Epoch: 33
Loss: 0.2599282941082152Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:1
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/clintox/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/clintox/scaff/train_prop=0.7/clintox_scaff_3_20-05_14-43-16  ]
[ Using Seed :  3  ]
[ Using device :  cuda:1  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6464670934045824
ROC train: 0.580756	val: 0.449154	test: 0.483721
PRC train: 0.524506	val: 0.508637	test: 0.500400

Epoch: 2
Loss: 0.5693907524991443
ROC train: 0.605855	val: 0.450818	test: 0.477519
PRC train: 0.534621	val: 0.511096	test: 0.536199

Epoch: 3
Loss: 0.4986924422534319
ROC train: 0.642789	val: 0.469623	test: 0.493753
PRC train: 0.543442	val: 0.515538	test: 0.536860

Epoch: 4
Loss: 0.4899556496742064
ROC train: 0.665249	val: 0.482317	test: 0.488580
PRC train: 0.547408	val: 0.515458	test: 0.536624

Epoch: 5
Loss: 0.43176892706097486
ROC train: 0.724712	val: 0.563968	test: 0.568983
PRC train: 0.570766	val: 0.532555	test: 0.517076

Epoch: 6
Loss: 0.37552765188427845
ROC train: 0.759689	val: 0.589354	test: 0.574533
PRC train: 0.593611	val: 0.539214	test: 0.520706

Epoch: 7
Loss: 0.36006081545228574
ROC train: 0.797740	val: 0.604401	test: 0.509872
PRC train: 0.617789	val: 0.538075	test: 0.515539

Epoch: 8
Loss: 0.30281157834876227
ROC train: 0.807635	val: 0.625986	test: 0.501564
PRC train: 0.617406	val: 0.537738	test: 0.513864

Epoch: 9
Loss: 0.34406657792297396
ROC train: 0.814036	val: 0.655666	test: 0.569992
PRC train: 0.612817	val: 0.546818	test: 0.519369

Epoch: 10
Loss: 0.2904639359978181
ROC train: 0.822342	val: 0.637744	test: 0.591962
PRC train: 0.620646	val: 0.551278	test: 0.524471

Epoch: 11
Loss: 0.248240823201677
ROC train: 0.833767	val: 0.605351	test: 0.565043
PRC train: 0.623832	val: 0.550399	test: 0.555633

Epoch: 12
Loss: 0.26444823266977274
ROC train: 0.850763	val: 0.614961	test: 0.545020
PRC train: 0.634077	val: 0.550676	test: 0.550353

Epoch: 13
Loss: 0.27862974776732186
ROC train: 0.869086	val: 0.651987	test: 0.546925
PRC train: 0.651795	val: 0.565898	test: 0.531082

Epoch: 14
Loss: 0.21847413331015236
ROC train: 0.859165	val: 0.681600	test: 0.631342
PRC train: 0.664229	val: 0.564574	test: 0.534445

Epoch: 15
Loss: 0.23268427898479924
ROC train: 0.882697	val: 0.708643	test: 0.624239
PRC train: 0.685450	val: 0.575493	test: 0.529021

Epoch: 16
Loss: 0.20673107031188181
ROC train: 0.875221	val: 0.677993	test: 0.616036
PRC train: 0.657538	val: 0.565511	test: 0.522780

Epoch: 17
Loss: 0.20991099262623955
ROC train: 0.883065	val: 0.684075	test: 0.590072
PRC train: 0.685007	val: 0.572184	test: 0.530476

Epoch: 18
Loss: 0.2739183288951629
ROC train: 0.895972	val: 0.702231	test: 0.579454
PRC train: 0.693307	val: 0.577570	test: 0.529964

Epoch: 19
Loss: 0.21693607140375942
ROC train: 0.863697	val: 0.683101	test: 0.598439
PRC train: 0.645068	val: 0.583998	test: 0.534085

Epoch: 20
Loss: 0.2036325164895076
ROC train: 0.861374	val: 0.694518	test: 0.576886
PRC train: 0.669861	val: 0.594430	test: 0.536183

Epoch: 21
Loss: 0.19333879038811463
ROC train: 0.898635	val: 0.711929	test: 0.573326
PRC train: 0.715755	val: 0.615270	test: 0.539277

Epoch: 22
Loss: 0.25053547881481253
ROC train: 0.915207	val: 0.734340	test: 0.569017
PRC train: 0.724010	val: 0.630471	test: 0.533254

Epoch: 23
Loss: 0.17394514473509468
ROC train: 0.904883	val: 0.739651	test: 0.591869
PRC train: 0.700679	val: 0.596139	test: 0.536179

Epoch: 24
Loss: 0.17549407730594097
ROC train: 0.905432	val: 0.737620	test: 0.613751
PRC train: 0.705407	val: 0.589661	test: 0.541581

Epoch: 25
Loss: 0.19168350511975824
ROC train: 0.918606	val: 0.739739	test: 0.620880
PRC train: 0.737947	val: 0.589463	test: 0.543276

Epoch: 26
Loss: 0.18705409418906585
ROC train: 0.922983	val: 0.742019	test: 0.641269
PRC train: 0.756764	val: 0.602028	test: 0.546052

Epoch: 27
Loss: 0.18159519540729172
ROC train: 0.926992	val: 0.742799	test: 0.644024
PRC train: 0.765992	val: 0.587534	test: 0.547527

Epoch: 28
Loss: 0.17250733639368848
ROC train: 0.916275	val: 0.751753	test: 0.680538
PRC train: 0.748241	val: 0.584445	test: 0.556523

Epoch: 29
Loss: 0.22815531304197806
ROC train: 0.919530	val: 0.736705	test: 0.710351
PRC train: 0.759414	val: 0.576725	test: 0.559120

Epoch: 30
Loss: 0.17498190449326242
ROC train: 0.903120	val: 0.714502	test: 0.714061
PRC train: 0.749531	val: 0.576432	test: 0.555221

Epoch: 31
Loss: 0.21660672955216437
ROC train: 0.916331	val: 0.707098	test: 0.675666
PRC train: 0.756814	val: 0.572170	test: 0.540083

Epoch: 32
Loss: 0.16078867454158685
ROC train: 0.909431	val: 0.679980	test: 0.602714
PRC train: 0.744451	val: 0.566733	test: 0.532379

Epoch: 33
Loss: 0.16611482815410056Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:1
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/clintox/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/clintox/scaff/train_prop=0.7/clintox_scaff_2_20-05_14-43-16  ]
[ Using Seed :  2  ]
[ Using device :  cuda:1  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6859765488133049
ROC train: 0.545478	val: 0.387769	test: 0.365064
PRC train: 0.515882	val: 0.489723	test: 0.489901

Epoch: 2
Loss: 0.6067517796798302
ROC train: 0.611558	val: 0.461447	test: 0.409962
PRC train: 0.530901	val: 0.504706	test: 0.495273

Epoch: 3
Loss: 0.5645388827661091
ROC train: 0.621831	val: 0.476730	test: 0.431459
PRC train: 0.535147	val: 0.510320	test: 0.500707

Epoch: 4
Loss: 0.48155372360350823
ROC train: 0.626737	val: 0.484746	test: 0.468296
PRC train: 0.535707	val: 0.516173	test: 0.508540

Epoch: 5
Loss: 0.44218420340920106
ROC train: 0.665655	val: 0.500797	test: 0.538019
PRC train: 0.545347	val: 0.523536	test: 0.523419

Epoch: 6
Loss: 0.41216498092364234
ROC train: 0.716495	val: 0.555738	test: 0.581594
PRC train: 0.562184	val: 0.528951	test: 0.530307

Epoch: 7
Loss: 0.36994245699015216
ROC train: 0.731504	val: 0.573886	test: 0.571271
PRC train: 0.570954	val: 0.532620	test: 0.550290

Epoch: 8
Loss: 0.3447813420947401
ROC train: 0.734059	val: 0.575234	test: 0.556891
PRC train: 0.570070	val: 0.531560	test: 0.526704

Epoch: 9
Loss: 0.3032454114885366
ROC train: 0.749041	val: 0.626354	test: 0.604579
PRC train: 0.575981	val: 0.543169	test: 0.520413

Epoch: 10
Loss: 0.32260360352932876
ROC train: 0.776895	val: 0.656844	test: 0.632241
PRC train: 0.598178	val: 0.549286	test: 0.529137

Epoch: 11
Loss: 0.26784748456078383
ROC train: 0.785604	val: 0.642824	test: 0.630174
PRC train: 0.604750	val: 0.545033	test: 0.534045

Epoch: 12
Loss: 0.2500404015932537
ROC train: 0.805036	val: 0.626565	test: 0.596217
PRC train: 0.611568	val: 0.540698	test: 0.525836

Epoch: 13
Loss: 0.27459526474067664
ROC train: 0.824436	val: 0.646503	test: 0.570528
PRC train: 0.623133	val: 0.546414	test: 0.518267

Epoch: 14
Loss: 0.2995884364973306
ROC train: 0.840819	val: 0.681412	test: 0.592345
PRC train: 0.633807	val: 0.561993	test: 0.536648

Epoch: 15
Loss: 0.22026404101937472
ROC train: 0.842520	val: 0.668911	test: 0.573110
PRC train: 0.650277	val: 0.562845	test: 0.516597

Epoch: 16
Loss: 0.23500199732872318
ROC train: 0.841880	val: 0.675059	test: 0.575877
PRC train: 0.644947	val: 0.557842	test: 0.515709

Epoch: 17
Loss: 0.24334924619031112
ROC train: 0.859533	val: 0.708444	test: 0.628808
PRC train: 0.654705	val: 0.567005	test: 0.528662

Epoch: 18
Loss: 0.31298962855401014
ROC train: 0.871586	val: 0.717941	test: 0.615123
PRC train: 0.666266	val: 0.580416	test: 0.527988

Epoch: 19
Loss: 0.2099347441683354
ROC train: 0.869981	val: 0.668840	test: 0.521814
PRC train: 0.668521	val: 0.567131	test: 0.512231

Epoch: 20
Loss: 0.19733402327564314
ROC train: 0.839417	val: 0.619060	test: 0.489742
PRC train: 0.661387	val: 0.541351	test: 0.505634

Epoch: 21
Loss: 0.21604658086502432
ROC train: 0.881172	val: 0.643590	test: 0.524845
PRC train: 0.684631	val: 0.553756	test: 0.510867

Epoch: 22
Loss: 0.19931045779387563
ROC train: 0.887124	val: 0.666290	test: 0.595911
PRC train: 0.673310	val: 0.559604	test: 0.523431

Epoch: 23
Loss: 0.24762451351398318
ROC train: 0.877781	val: 0.698970	test: 0.606705
PRC train: 0.665412	val: 0.566090	test: 0.530572

Epoch: 24
Loss: 0.18393632202573995
ROC train: 0.902707	val: 0.705840	test: 0.612924
PRC train: 0.715181	val: 0.576342	test: 0.532925

Epoch: 25
Loss: 0.22023280574068088
ROC train: 0.905737	val: 0.700689	test: 0.609276
PRC train: 0.732584	val: 0.579982	test: 0.527804

Epoch: 26
Loss: 0.17442008918952862
ROC train: 0.904961	val: 0.705804	test: 0.614210
PRC train: 0.726393	val: 0.579285	test: 0.535204

Epoch: 27
Loss: 0.19613453856853685
ROC train: 0.912774	val: 0.692504	test: 0.602119
PRC train: 0.728864	val: 0.582932	test: 0.523683

Epoch: 28
Loss: 0.25134195857002994
ROC train: 0.907324	val: 0.677149	test: 0.621762
PRC train: 0.712589	val: 0.577929	test: 0.525043

Epoch: 29
Loss: 0.19813401201687939
ROC train: 0.912132	val: 0.673708	test: 0.610719
PRC train: 0.723858	val: 0.570644	test: 0.521065

Epoch: 30
Loss: 0.2283521548758963
ROC train: 0.890984	val: 0.630679	test: 0.542308
PRC train: 0.716336	val: 0.555462	test: 0.511854

Epoch: 31
Loss: 0.178698536257343
ROC train: 0.903248	val: 0.673760	test: 0.586889
PRC train: 0.718515	val: 0.571098	test: 0.517355

Epoch: 32
Loss: 0.18171958158822438
ROC train: 0.911492	val: 0.698499	test: 0.654398
PRC train: 0.723521	val: 0.580178	test: 0.539637

Epoch: 33
Loss: 0.1628736100785418Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:2
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/clintox/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/clintox/scaff/train_prop=0.8/clintox_scaff_3_20-05_14-43-16  ]
[ Using Seed :  3  ]
[ Using device :  cuda:2  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6453083756891819
ROC train: 0.558724	val: 0.665835	test: 0.427264
PRC train: 0.521872	val: 0.560861	test: 0.490137

Epoch: 2
Loss: 0.5667080449605557
ROC train: 0.620039	val: 0.699275	test: 0.464972
PRC train: 0.538899	val: 0.572956	test: 0.494866

Epoch: 3
Loss: 0.5000015160527536
ROC train: 0.673684	val: 0.764820	test: 0.510386
PRC train: 0.552628	val: 0.550476	test: 0.503479

Epoch: 4
Loss: 0.4483265703474603
ROC train: 0.702164	val: 0.784987	test: 0.531898
PRC train: 0.561958	val: 0.556091	test: 0.507443

Epoch: 5
Loss: 0.3981683737588341
ROC train: 0.735608	val: 0.828305	test: 0.548337
PRC train: 0.573451	val: 0.558617	test: 0.510717

Epoch: 6
Loss: 0.36105272638169655
ROC train: 0.776164	val: 0.865042	test: 0.578379
PRC train: 0.591844	val: 0.572919	test: 0.519809

Epoch: 7
Loss: 0.32939176159251926
ROC train: 0.809195	val: 0.865017	test: 0.603776
PRC train: 0.610799	val: 0.574451	test: 0.528142

Epoch: 8
Loss: 0.30552868882553774
ROC train: 0.827142	val: 0.851094	test: 0.612120
PRC train: 0.621236	val: 0.572936	test: 0.529814

Epoch: 9
Loss: 0.2802014579379041
ROC train: 0.843161	val: 0.866665	test: 0.668135
PRC train: 0.642459	val: 0.589612	test: 0.555344

Epoch: 10
Loss: 0.26155851509252825
ROC train: 0.857487	val: 0.880788	test: 0.596817
PRC train: 0.648470	val: 0.583582	test: 0.532114

Epoch: 11
Loss: 0.25348359569815604
ROC train: 0.874686	val: 0.889454	test: 0.619004
PRC train: 0.668989	val: 0.601303	test: 0.537031

Epoch: 12
Loss: 0.22945711270426422
ROC train: 0.888783	val: 0.897122	test: 0.639496
PRC train: 0.711548	val: 0.648642	test: 0.548910

Epoch: 13
Loss: 0.2278819004543446
ROC train: 0.904950	val: 0.895048	test: 0.656566
PRC train: 0.726613	val: 0.628043	test: 0.550794

Epoch: 14
Loss: 0.22028241791040398
ROC train: 0.909065	val: 0.883360	test: 0.694390
PRC train: 0.722763	val: 0.609726	test: 0.551887

Epoch: 15
Loss: 0.21222960476319405
ROC train: 0.915562	val: 0.868601	test: 0.688432
PRC train: 0.738191	val: 0.624753	test: 0.550647

Epoch: 16
Loss: 0.20138668257731038
ROC train: 0.921030	val: 0.818167	test: 0.703995
PRC train: 0.760947	val: 0.578061	test: 0.555463

Epoch: 17
Loss: 0.20085267309471472
ROC train: 0.920651	val: 0.815893	test: 0.723372
PRC train: 0.756945	val: 0.573755	test: 0.560680

Epoch: 18
Loss: 0.18929949876765195
ROC train: 0.924657	val: 0.818691	test: 0.713067
PRC train: 0.758928	val: 0.558738	test: 0.555599

Epoch: 19
Loss: 0.20643304951914385
ROC train: 0.929192	val: 0.813209	test: 0.684159
PRC train: 0.770203	val: 0.586382	test: 0.545316

Epoch: 20
Loss: 0.18525893133408824
ROC train: 0.939282	val: 0.834237	test: 0.713115
PRC train: 0.803180	val: 0.624416	test: 0.561154

Epoch: 21
Loss: 0.18602685417104053
ROC train: 0.937564	val: 0.836560	test: 0.691925
PRC train: 0.790347	val: 0.620721	test: 0.554377

Epoch: 22
Loss: 0.19030983570480314
ROC train: 0.936205	val: 0.826833	test: 0.699310
PRC train: 0.783370	val: 0.629857	test: 0.563655

Epoch: 23
Loss: 0.18944974877950282
ROC train: 0.940056	val: 0.829816	test: 0.731362
PRC train: 0.779222	val: 0.604227	test: 0.586183

Epoch: 24
Loss: 0.17556693758198186
ROC train: 0.944782	val: 0.797750	test: 0.747883
PRC train: 0.803318	val: 0.616394	test: 0.611611

Epoch: 25
Loss: 0.17922864940895789
ROC train: 0.948762	val: 0.754084	test: 0.739434
PRC train: 0.814162	val: 0.606271	test: 0.599593

Epoch: 26
Loss: 0.16901019377770002
ROC train: 0.951750	val: 0.790508	test: 0.760034
PRC train: 0.816967	val: 0.570766	test: 0.611891

Epoch: 27
Loss: 0.1719696086335382
ROC train: 0.950960	val: 0.788561	test: 0.753976
PRC train: 0.814519	val: 0.577957	test: 0.571540

Epoch: 28
Loss: 0.16709682962709177
ROC train: 0.956499	val: 0.778233	test: 0.776312
PRC train: 0.824405	val: 0.590959	test: 0.583233

Epoch: 29
Loss: 0.15815803518017307
ROC train: 0.954627	val: 0.804406	test: 0.766449
PRC train: 0.812888	val: 0.639768	test: 0.567099

Epoch: 30
Loss: 0.16905093671955804
ROC train: 0.959494	val: 0.781417	test: 0.809047
PRC train: 0.828233	val: 0.613956	test: 0.630664

Epoch: 31
Loss: 0.1591697011373259
ROC train: 0.963425	val: 0.731095	test: 0.770840
PRC train: 0.848020	val: 0.586871	test: 0.608780

Epoch: 32
Loss: 0.15511406201341932
ROC train: 0.963355	val: 0.750637	test: 0.777336
PRC train: 0.835867	val: 0.583361	test: 0.584732

Epoch: 33
Loss: 0.16544528222652644Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:2
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/clintox/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/clintox/scaff/train_prop=0.8/clintox_scaff_1_20-05_14-43-16  ]
[ Using Seed :  1  ]
[ Using device :  cuda:2  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6492521463851433
ROC train: 0.598577	val: 0.652116	test: 0.442498
PRC train: 0.529255	val: 0.537737	test: 0.496569

Epoch: 2
Loss: 0.5618986496753369
ROC train: 0.646052	val: 0.716199	test: 0.473145
PRC train: 0.537796	val: 0.615449	test: 0.496435

Epoch: 3
Loss: 0.49176063336212605
ROC train: 0.680839	val: 0.764384	test: 0.517842
PRC train: 0.549279	val: 0.567221	test: 0.503826

Epoch: 4
Loss: 0.4403367961039706
ROC train: 0.730998	val: 0.787711	test: 0.546148
PRC train: 0.569760	val: 0.624730	test: 0.507017

Epoch: 5
Loss: 0.39044907049170396
ROC train: 0.785750	val: 0.828393	test: 0.571869
PRC train: 0.590818	val: 0.588916	test: 0.518461

Epoch: 6
Loss: 0.348363967506526
ROC train: 0.773569	val: 0.827806	test: 0.561601
PRC train: 0.583939	val: 0.562696	test: 0.514885

Epoch: 7
Loss: 0.32264117264473996
ROC train: 0.815892	val: 0.853217	test: 0.577741
PRC train: 0.610554	val: 0.577976	test: 0.517283

Epoch: 8
Loss: 0.2937135998568122
ROC train: 0.838734	val: 0.863144	test: 0.605535
PRC train: 0.635432	val: 0.584273	test: 0.525993

Epoch: 9
Loss: 0.2715362470496085
ROC train: 0.839806	val: 0.829205	test: 0.570319
PRC train: 0.628504	val: 0.575277	test: 0.522353

Epoch: 10
Loss: 0.25784261707006206
ROC train: 0.857814	val: 0.834212	test: 0.610130
PRC train: 0.646245	val: 0.573235	test: 0.532203

Epoch: 11
Loss: 0.24673288467793322
ROC train: 0.876242	val: 0.832364	test: 0.588020
PRC train: 0.675203	val: 0.597645	test: 0.525386

Epoch: 12
Loss: 0.23553960711266209
ROC train: 0.883739	val: 0.856351	test: 0.580412
PRC train: 0.680080	val: 0.668089	test: 0.522492

Epoch: 13
Loss: 0.22297941462686657
ROC train: 0.896459	val: 0.820226	test: 0.623072
PRC train: 0.719441	val: 0.641265	test: 0.535129

Epoch: 14
Loss: 0.22173180424537936
ROC train: 0.893086	val: 0.864880	test: 0.580826
PRC train: 0.685575	val: 0.590551	test: 0.523144

Epoch: 15
Loss: 0.2119611701058613
ROC train: 0.913111	val: 0.811262	test: 0.612401
PRC train: 0.742618	val: 0.642351	test: 0.531430

Epoch: 16
Loss: 0.20340559425917015
ROC train: 0.914031	val: 0.805892	test: 0.681066
PRC train: 0.759123	val: 0.629768	test: 0.545374

Epoch: 17
Loss: 0.20000739231813958
ROC train: 0.917295	val: 0.859261	test: 0.681634
PRC train: 0.744718	val: 0.630436	test: 0.543910

Epoch: 18
Loss: 0.19071375276898245
ROC train: 0.926764	val: 0.804431	test: 0.737137
PRC train: 0.765875	val: 0.622139	test: 0.559166

Epoch: 19
Loss: 0.1942532983549285
ROC train: 0.920137	val: 0.791520	test: 0.723869
PRC train: 0.771677	val: 0.599368	test: 0.549348

Epoch: 20
Loss: 0.18533287576422372
ROC train: 0.936291	val: 0.832139	test: 0.727156
PRC train: 0.791637	val: 0.634936	test: 0.550770

Epoch: 21
Loss: 0.18305879610716952
ROC train: 0.937311	val: 0.889566	test: 0.705521
PRC train: 0.791273	val: 0.625189	test: 0.547485

Epoch: 22
Loss: 0.18249228086875996
ROC train: 0.931042	val: 0.840193	test: 0.733663
PRC train: 0.765773	val: 0.571807	test: 0.555902

Epoch: 23
Loss: 0.1807865508687698
ROC train: 0.943442	val: 0.844027	test: 0.735299
PRC train: 0.797786	val: 0.601241	test: 0.558453

Epoch: 24
Loss: 0.17311967330522254
ROC train: 0.949067	val: 0.770330	test: 0.762257
PRC train: 0.804870	val: 0.592633	test: 0.574447

Epoch: 25
Loss: 0.16605391896114596
ROC train: 0.939889	val: 0.838046	test: 0.703807
PRC train: 0.779355	val: 0.565464	test: 0.547377

Epoch: 26
Loss: 0.15995438513426727
ROC train: 0.936634	val: 0.865892	test: 0.725274
PRC train: 0.779064	val: 0.583862	test: 0.552383

Epoch: 27
Loss: 0.17444932511514738
ROC train: 0.952563	val: 0.817267	test: 0.773986
PRC train: 0.825470	val: 0.629518	test: 0.585317

Epoch: 28
Loss: 0.17079742189183497
ROC train: 0.952191	val: 0.806304	test: 0.787840
PRC train: 0.823256	val: 0.621046	test: 0.583723

Epoch: 29
Loss: 0.17108700134952395
ROC train: 0.952828	val: 0.886021	test: 0.763131
PRC train: 0.819355	val: 0.609191	test: 0.561350

Epoch: 30
Loss: 0.16207591829319518
ROC train: 0.954967	val: 0.883698	test: 0.778311
PRC train: 0.831187	val: 0.634047	test: 0.566977

Epoch: 31
Loss: 0.15947602920965182
ROC train: 0.957647	val: 0.869325	test: 0.781620
PRC train: 0.843415	val: 0.644682	test: 0.568698

Epoch: 32
Loss: 0.16215931456845387
ROC train: 0.960319	val: 0.858562	test: 0.794911
PRC train: 0.846399	val: 0.650065	test: 0.573379

Epoch: 33
Loss: 0.1505541053492488Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:2
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/clintox/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/clintox/scaff/train_prop=0.8/clintox_scaff_2_20-05_14-43-16  ]
[ Using Seed :  2  ]
[ Using device :  cuda:2  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6852502024769225
ROC train: 0.508911	val: 0.518630	test: 0.383786
PRC train: 0.509874	val: 0.518379	test: 0.484074

Epoch: 2
Loss: 0.5956639580194613
ROC train: 0.600047	val: 0.619386	test: 0.460639
PRC train: 0.528594	val: 0.528096	test: 0.495072

Epoch: 3
Loss: 0.5288898564528666
ROC train: 0.657603	val: 0.722166	test: 0.487003
PRC train: 0.542654	val: 0.542559	test: 0.499192

Epoch: 4
Loss: 0.46333479247853954
ROC train: 0.695934	val: 0.753009	test: 0.495385
PRC train: 0.557576	val: 0.550299	test: 0.503150

Epoch: 5
Loss: 0.41292495450354494
ROC train: 0.734981	val: 0.779906	test: 0.493405
PRC train: 0.569262	val: 0.553493	test: 0.504953

Epoch: 6
Loss: 0.37436056537624257
ROC train: 0.763599	val: 0.827831	test: 0.539831
PRC train: 0.578207	val: 0.563563	test: 0.518487

Epoch: 7
Loss: 0.3471556471465279
ROC train: 0.790979	val: 0.833088	test: 0.568361
PRC train: 0.593872	val: 0.560864	test: 0.521810

Epoch: 8
Loss: 0.3141370971132202
ROC train: 0.816826	val: 0.814284	test: 0.548650
PRC train: 0.620104	val: 0.566370	test: 0.516097

Epoch: 9
Loss: 0.29657590461492955
ROC train: 0.838059	val: 0.838658	test: 0.560218
PRC train: 0.643205	val: 0.566836	test: 0.519970

Epoch: 10
Loss: 0.2755707760389369
ROC train: 0.846143	val: 0.854478	test: 0.601079
PRC train: 0.640129	val: 0.572224	test: 0.526526

Epoch: 11
Loss: 0.2555847991864541
ROC train: 0.853399	val: 0.881150	test: 0.644001
PRC train: 0.657925	val: 0.665926	test: 0.542817

Epoch: 12
Loss: 0.242562767431079
ROC train: 0.841868	val: 0.817918	test: 0.611496
PRC train: 0.643305	val: 0.629798	test: 0.530542

Epoch: 13
Loss: 0.2405198716123021
ROC train: 0.871336	val: 0.853979	test: 0.620428
PRC train: 0.674438	val: 0.619154	test: 0.532964

Epoch: 14
Loss: 0.23027391528378968
ROC train: 0.897450	val: 0.862258	test: 0.615699
PRC train: 0.718071	val: 0.599669	test: 0.536199

Epoch: 15
Loss: 0.22119165231129506
ROC train: 0.904906	val: 0.881189	test: 0.622714
PRC train: 0.721905	val: 0.609568	test: 0.533356

Epoch: 16
Loss: 0.21277678565646924
ROC train: 0.907878	val: 0.892564	test: 0.673980
PRC train: 0.717995	val: 0.654455	test: 0.543580

Epoch: 17
Loss: 0.20565829895603566
ROC train: 0.918138	val: 0.873746	test: 0.718158
PRC train: 0.740249	val: 0.649389	test: 0.557287

Epoch: 18
Loss: 0.199704418258663
ROC train: 0.917732	val: 0.789710	test: 0.706182
PRC train: 0.744737	val: 0.622936	test: 0.546550

Epoch: 19
Loss: 0.19063071237382218
ROC train: 0.930751	val: 0.848360	test: 0.700368
PRC train: 0.752520	val: 0.585430	test: 0.552969

Epoch: 20
Loss: 0.1889498580791145
ROC train: 0.924251	val: 0.775886	test: 0.705533
PRC train: 0.743544	val: 0.555273	test: 0.555914

Epoch: 21
Loss: 0.17924492940119774
ROC train: 0.937827	val: 0.828755	test: 0.741085
PRC train: 0.775466	val: 0.619865	test: 0.559446

Epoch: 22
Loss: 0.18596697295292122
ROC train: 0.935053	val: 0.845812	test: 0.767019
PRC train: 0.777906	val: 0.645649	test: 0.590730

Epoch: 23
Loss: 0.18274786415257027
ROC train: 0.938272	val: 0.839919	test: 0.754539
PRC train: 0.794747	val: 0.599380	test: 0.568346

Epoch: 24
Loss: 0.17212648493303506
ROC train: 0.943205	val: 0.814446	test: 0.770560
PRC train: 0.817064	val: 0.585019	test: 0.576743

Epoch: 25
Loss: 0.17279025795943803
ROC train: 0.945790	val: 0.790483	test: 0.765607
PRC train: 0.814381	val: 0.546611	test: 0.570921

Epoch: 26
Loss: 0.17064490286726416
ROC train: 0.946764	val: 0.823111	test: 0.763583
PRC train: 0.814323	val: 0.557484	test: 0.565740

Epoch: 27
Loss: 0.17053898015523522
ROC train: 0.943257	val: 0.835811	test: 0.727100
PRC train: 0.814551	val: 0.606467	test: 0.547604

Epoch: 28
Loss: 0.16508629158347649
ROC train: 0.953260	val: 0.850795	test: 0.759922
PRC train: 0.814887	val: 0.599296	test: 0.560573

Epoch: 29
Loss: 0.17816509260783875
ROC train: 0.953457	val: 0.870175	test: 0.735176
PRC train: 0.811125	val: 0.587254	test: 0.556568

Epoch: 30
Loss: 0.1731631373248342
ROC train: 0.955846	val: 0.861422	test: 0.700878
PRC train: 0.814561	val: 0.584108	test: 0.549868

Epoch: 31
Loss: 0.1603536277848459
ROC train: 0.956307	val: 0.847474	test: 0.678037
PRC train: 0.829954	val: 0.597449	test: 0.544463

Epoch: 32
Loss: 0.16433099715671617
ROC train: 0.957554	val: 0.822475	test: 0.752612
PRC train: 0.833135	val: 0.580623	test: 0.557874

Epoch: 33
Loss: 0.16171205066397465
ROC train: 0.960543	val: 0.652377	test: 0.746459
PRC train: 0.855011	val: 0.554601	test: 0.563516

Epoch: 34
Loss: 0.15050550606452587
ROC train: 0.959193	val: 0.652797	test: 0.720206
PRC train: 0.851219	val: 0.571801	test: 0.565649

Epoch: 35
Loss: 0.162741683887579
ROC train: 0.963374	val: 0.659347	test: 0.738562
PRC train: 0.853610	val: 0.562302	test: 0.565535

Epoch: 36
Loss: 0.16184085049402377
ROC train: 0.961396	val: 0.637684	test: 0.706599
PRC train: 0.856115	val: 0.555548	test: 0.553910

Epoch: 37
Loss: 0.14985638392688735
ROC train: 0.962294	val: 0.651515	test: 0.707698
PRC train: 0.851528	val: 0.556636	test: 0.555375

Epoch: 38
Loss: 0.173155399293616
ROC train: 0.965951	val: 0.679592	test: 0.724041
PRC train: 0.856419	val: 0.561135	test: 0.575383

Epoch: 39
Loss: 0.1661026632921483
ROC train: 0.969051	val: 0.699843	test: 0.739997
PRC train: 0.864299	val: 0.559679	test: 0.612071

Epoch: 40
Loss: 0.14762586605013372
ROC train: 0.969650	val: 0.680823	test: 0.728565
PRC train: 0.865404	val: 0.557642	test: 0.607576

Epoch: 41
Loss: 0.1525431544491097
ROC train: 0.968553	val: 0.674596	test: 0.721248
PRC train: 0.867893	val: 0.557343	test: 0.597524

Epoch: 42
Loss: 0.16270984843959943
ROC train: 0.968976	val: 0.675239	test: 0.739019
PRC train: 0.871165	val: 0.553879	test: 0.578930

Epoch: 43
Loss: 0.1402455359169041
ROC train: 0.963011	val: 0.686985	test: 0.755471
PRC train: 0.853690	val: 0.556143	test: 0.576634

Epoch: 44
Loss: 0.14084709714904953
ROC train: 0.968431	val: 0.687724	test: 0.756505
PRC train: 0.865416	val: 0.560094	test: 0.584747

Epoch: 45
Loss: 0.14295557345977247
ROC train: 0.970866	val: 0.674285	test: 0.739541
PRC train: 0.873238	val: 0.562388	test: 0.581984

Epoch: 46
Loss: 0.1378436695559049
ROC train: 0.972799	val: 0.670087	test: 0.731225
PRC train: 0.876071	val: 0.558468	test: 0.579071

Epoch: 47
Loss: 0.1299351040061134
ROC train: 0.975460	val: 0.678304	test: 0.740678
PRC train: 0.878162	val: 0.559377	test: 0.585398

Epoch: 48
Loss: 0.13513024497961312
ROC train: 0.974686	val: 0.676658	test: 0.748582
PRC train: 0.876813	val: 0.560160	test: 0.586519

Epoch: 49
Loss: 0.14179003958851594
ROC train: 0.974036	val: 0.662070	test: 0.741502
PRC train: 0.880920	val: 0.556892	test: 0.561548

Epoch: 50
Loss: 0.12922238739206232
ROC train: 0.975303	val: 0.668752	test: 0.743586
PRC train: 0.887259	val: 0.560894	test: 0.571708

Epoch: 51
Loss: 0.1200957170422233
ROC train: 0.975418	val: 0.688777	test: 0.737553
PRC train: 0.881158	val: 0.564982	test: 0.587162

Epoch: 52
Loss: 0.13115845562109207
ROC train: 0.974181	val: 0.683187	test: 0.720155
PRC train: 0.876194	val: 0.560040	test: 0.589335

Epoch: 53
Loss: 0.12454780306153301
ROC train: 0.975848	val: 0.680918	test: 0.731510
PRC train: 0.880735	val: 0.557474	test: 0.597097

Epoch: 54
Loss: 0.13730366000141725
ROC train: 0.977775	val: 0.668145	test: 0.752024
PRC train: 0.886067	val: 0.556230	test: 0.593257

Epoch: 55
Loss: 0.13037598686670096
ROC train: 0.977801	val: 0.665307	test: 0.764153
PRC train: 0.886564	val: 0.559440	test: 0.590920

Epoch: 56
Loss: 0.12419275801466129
ROC train: 0.978615	val: 0.656305	test: 0.753350
PRC train: 0.891801	val: 0.557117	test: 0.585373

Epoch: 57
Loss: 0.12326465072981883
ROC train: 0.978449	val: 0.645493	test: 0.750602
PRC train: 0.894864	val: 0.551705	test: 0.582162

Epoch: 58
Loss: 0.1171479549850744
ROC train: 0.978181	val: 0.642202	test: 0.753698
PRC train: 0.893581	val: 0.548502	test: 0.580582

Epoch: 59
Loss: 0.13059694513288495
ROC train: 0.978763	val: 0.651843	test: 0.740274
PRC train: 0.893283	val: 0.552654	test: 0.603061

Epoch: 60
Loss: 0.12589994242141866
ROC train: 0.980211	val: 0.639117	test: 0.738880
PRC train: 0.898491	val: 0.549080	test: 0.579579

Epoch: 61
Loss: 0.13964490684849212
ROC train: 0.980328	val: 0.639226	test: 0.743461
PRC train: 0.899099	val: 0.549188	test: 0.570331

Epoch: 62
Loss: 0.1154205661178544
ROC train: 0.980021	val: 0.641458	test: 0.756465
PRC train: 0.891873	val: 0.551716	test: 0.596529

Epoch: 63
Loss: 0.12075180491201162
ROC train: 0.978445	val: 0.639906	test: 0.748085
PRC train: 0.888399	val: 0.553507	test: 0.600582

Epoch: 64
Loss: 0.12698844967506118
ROC train: 0.978583	val: 0.634330	test: 0.749890
PRC train: 0.892673	val: 0.548522	test: 0.586941

Epoch: 65
Loss: 0.11260054085130564
ROC train: 0.979096	val: 0.640523	test: 0.763616
PRC train: 0.893365	val: 0.551995	test: 0.602701

Epoch: 66
Loss: 0.13074034928642078
ROC train: 0.979354	val: 0.644576	test: 0.767969
PRC train: 0.893746	val: 0.554822	test: 0.618957

Epoch: 67
Loss: 0.11465854542630272
ROC train: 0.981248	val: 0.659534	test: 0.759660
PRC train: 0.898570	val: 0.558435	test: 0.605887

Epoch: 68
Loss: 0.10769260501999409
ROC train: 0.980550	val: 0.664326	test: 0.737370
PRC train: 0.898334	val: 0.558286	test: 0.619483

Epoch: 69
Loss: 0.11417039383506172
ROC train: 0.981144	val: 0.668206	test: 0.741620
PRC train: 0.896535	val: 0.559393	test: 0.620791

Epoch: 70
Loss: 0.11520066618137728
ROC train: 0.981636	val: 0.664767	test: 0.749147
PRC train: 0.896396	val: 0.556788	test: 0.607932

Epoch: 71
Loss: 0.12404024131781717
ROC train: 0.981966	val: 0.655712	test: 0.763283
PRC train: 0.904644	val: 0.555393	test: 0.608781

Epoch: 72
Loss: 0.11665111335530647
ROC train: 0.982097	val: 0.657286	test: 0.770647
PRC train: 0.906859	val: 0.558385	test: 0.595475

Epoch: 73
Loss: 0.11162461960360537
ROC train: 0.982062	val: 0.663712	test: 0.751386
PRC train: 0.905311	val: 0.556894	test: 0.619844

Epoch: 74
Loss: 0.11845428696486943
ROC train: 0.982590	val: 0.675989	test: 0.742444
PRC train: 0.906974	val: 0.561985	test: 0.598361

Epoch: 75
Loss: 0.1168845533753119
ROC train: 0.980760	val: 0.681482	test: 0.730836
PRC train: 0.898360	val: 0.563755	test: 0.594450

Epoch: 76
Loss: 0.11336774191532856
ROC train: 0.982145	val: 0.674633	test: 0.734924
PRC train: 0.905423	val: 0.566670	test: 0.578010

Epoch: 77
Loss: 0.1136337612110788
ROC train: 0.982807	val: 0.685691	test: 0.744996
PRC train: 0.907705	val: 0.572441	test: 0.578882

Epoch: 78
Loss: 0.11413898213497103
ROC train: 0.982519	val: 0.690537	test: 0.746909
PRC train: 0.905809	val: 0.576057	test: 0.580432

Epoch: 79
Loss: 0.12288858597114669
ROC train: 0.982455	val: 0.699279	test: 0.743909
PRC train: 0.906614	val: 0.577747	test: 0.589305

Epoch: 80
Loss: 0.11620256482490274
ROC train: 0.981151	val: 0.700414	test: 0.742227
PRC train: 0.903381	val: 0.577316	test: 0.589711

Epoch: 81
Loss: 0.12178732286825424
ROC train: 0.978583	val: 0.685923	test: 0.736198
PRC train: 0.895658	val: 0.570375	test: 0.583911

Epoch: 82
Loss: 0.11241943497964421
ROC train: 0.978888	val: 0.673119	test: 0.751883
PRC train: 0.891720	val: 0.564093	test: 0.593658

Epoch: 83
Loss: 0.11826707936169946
ROC train: 0.978628	val: 0.650865	test: 0.777916
PRC train: 0.889593	val: 0.552651	test: 0.581615

Epoch: 84
Loss: 0.1134922929554699
ROC train: 0.981081	val: 0.640946	test: 0.782924
PRC train: 0.897494	val: 0.549685	test: 0.578573

Epoch: 85
Loss: 0.11144426294366787
ROC train: 0.980560	val: 0.620785	test: 0.760766
PRC train: 0.898663	val: 0.546610	test: 0.569894

Epoch: 86
Loss: 0.11211271942460391
ROC train: 0.982747	val: 0.632450	test: 0.772806
PRC train: 0.906921	val: 0.551365	test: 0.585412

Epoch: 87
Loss: 0.10688751617899414
ROC train: 0.983849	val: 0.659377	test: 0.787699
PRC train: 0.909772	val: 0.564346	test: 0.600972

Epoch: 88
Loss: 0.10806694831803547
ROC train: 0.982341	val: 0.661603	test: 0.791211
PRC train: 0.903181	val: 0.564618	test: 0.607161

Epoch: 89
Loss: 0.11686634765263011
ROC train: 0.980117	val: 0.652167	test: 0.788286
PRC train: 0.905668	val: 0.559110	test: 0.589372

Epoch: 90
Loss: 0.11798171502466115
ROC train: 0.980755	val: 0.640107	test: 0.771422
PRC train: 0.903330	val: 0.552674	test: 0.577286

Epoch: 91
Loss: 0.12288627532131914
ROC train: 0.983540	val: 0.663194	test: 0.773394
PRC train: 0.912803	val: 0.568105	test: 0.585281

Epoch: 92
Loss: 0.10870697522986622
ROC train: 0.982534	val: 0.687605	test: 0.761105
PRC train: 0.905508	val: 0.572210	test: 0.605772

Epoch: 93
Loss: 0.11566114132775865
ROC train: 0.982917	val: 0.688746	test: 0.745241
PRC train: 0.908419	val: 0.571388	test: 0.589363

Epoch: 94
Loss: 0.10991791695226069
ROC train: 0.959108	val: 0.659605	test: 0.760120
PRC train: 0.847054	val: 0.554789	test: 0.564597

Epoch: 34
Loss: 0.145875678902531
ROC train: 0.959873	val: 0.617829	test: 0.749569
PRC train: 0.853981	val: 0.545406	test: 0.550945

Epoch: 35
Loss: 0.15840328267178705
ROC train: 0.964711	val: 0.639368	test: 0.773584
PRC train: 0.864962	val: 0.550836	test: 0.557654

Epoch: 36
Loss: 0.13363090020148274
ROC train: 0.967106	val: 0.667381	test: 0.782851
PRC train: 0.860973	val: 0.558186	test: 0.573350

Epoch: 37
Loss: 0.15058874073716427
ROC train: 0.968389	val: 0.672294	test: 0.776479
PRC train: 0.859859	val: 0.564401	test: 0.571602

Epoch: 38
Loss: 0.14859368126656453
ROC train: 0.965550	val: 0.640795	test: 0.747769
PRC train: 0.862341	val: 0.550107	test: 0.557880

Epoch: 39
Loss: 0.14815311735540299
ROC train: 0.969171	val: 0.655251	test: 0.768611
PRC train: 0.867678	val: 0.556213	test: 0.563589

Epoch: 40
Loss: 0.1335326888521007
ROC train: 0.970814	val: 0.668965	test: 0.785528
PRC train: 0.865054	val: 0.561917	test: 0.574998

Epoch: 41
Loss: 0.14907440347039697
ROC train: 0.971814	val: 0.655869	test: 0.775761
PRC train: 0.869647	val: 0.560439	test: 0.572330

Epoch: 42
Loss: 0.13861987304703383
ROC train: 0.972308	val: 0.639263	test: 0.785396
PRC train: 0.874325	val: 0.553738	test: 0.570231

Epoch: 43
Loss: 0.14015173286741744
ROC train: 0.972554	val: 0.634442	test: 0.796811
PRC train: 0.875991	val: 0.555900	test: 0.573931

Epoch: 44
Loss: 0.14025081808152587
ROC train: 0.974135	val: 0.643711	test: 0.802587
PRC train: 0.876335	val: 0.557830	test: 0.585715

Epoch: 45
Loss: 0.1330969592954191
ROC train: 0.971322	val: 0.656432	test: 0.776755
PRC train: 0.865991	val: 0.557309	test: 0.581692

Epoch: 46
Loss: 0.1388347045882473
ROC train: 0.974203	val: 0.659149	test: 0.760472
PRC train: 0.875525	val: 0.555836	test: 0.571081

Epoch: 47
Loss: 0.131994999788054
ROC train: 0.971914	val: 0.675137	test: 0.768218
PRC train: 0.875891	val: 0.556894	test: 0.577164

Epoch: 48
Loss: 0.14194705390827314
ROC train: 0.967247	val: 0.662552	test: 0.766240
PRC train: 0.876870	val: 0.557867	test: 0.567644

Epoch: 49
Loss: 0.12710758751324316
ROC train: 0.972875	val: 0.658201	test: 0.775125
PRC train: 0.881517	val: 0.555068	test: 0.572439

Epoch: 50
Loss: 0.12522633097634633
ROC train: 0.977493	val: 0.666052	test: 0.795174
PRC train: 0.889143	val: 0.560222	test: 0.592559

Epoch: 51
Loss: 0.14524454056636552
ROC train: 0.976721	val: 0.667707	test: 0.812369
PRC train: 0.884714	val: 0.559263	test: 0.594864

Epoch: 52
Loss: 0.14565223173393624
ROC train: 0.978040	val: 0.655918	test: 0.796370
PRC train: 0.892228	val: 0.558978	test: 0.579975

Epoch: 53
Loss: 0.1496368495549258
ROC train: 0.977458	val: 0.648807	test: 0.767537
PRC train: 0.893729	val: 0.553614	test: 0.563874

Epoch: 54
Loss: 0.12467861672793676
ROC train: 0.977801	val: 0.664805	test: 0.773579
PRC train: 0.890231	val: 0.564660	test: 0.571064

Epoch: 55
Loss: 0.1370351731513956
ROC train: 0.978642	val: 0.680733	test: 0.768321
PRC train: 0.890056	val: 0.569194	test: 0.581564

Epoch: 56
Loss: 0.11708436771717239
ROC train: 0.978797	val: 0.677033	test: 0.769764
PRC train: 0.887966	val: 0.564509	test: 0.583580

Epoch: 57
Loss: 0.1285070443786534
ROC train: 0.978053	val: 0.655785	test: 0.772823
PRC train: 0.886280	val: 0.554081	test: 0.577399

Epoch: 58
Loss: 0.13248170636599638
ROC train: 0.978905	val: 0.647997	test: 0.773254
PRC train: 0.889180	val: 0.552094	test: 0.574110

Epoch: 59
Loss: 0.11744397424227625
ROC train: 0.979359	val: 0.649663	test: 0.770455
PRC train: 0.887911	val: 0.554231	test: 0.584596

Epoch: 60
Loss: 0.13231939118261188
ROC train: 0.980050	val: 0.650882	test: 0.766093
PRC train: 0.891000	val: 0.555616	test: 0.584421

Epoch: 61
Loss: 0.13489759724917677
ROC train: 0.980461	val: 0.655327	test: 0.769593
PRC train: 0.894854	val: 0.556211	test: 0.588366

Epoch: 62
Loss: 0.12175423922606492
ROC train: 0.979466	val: 0.656312	test: 0.782784
PRC train: 0.892788	val: 0.558064	test: 0.593073

Epoch: 63
Loss: 0.12137690369787776
ROC train: 0.980364	val: 0.653233	test: 0.789121
PRC train: 0.895572	val: 0.555429	test: 0.598899

Epoch: 64
Loss: 0.12071531930635773
ROC train: 0.982028	val: 0.628390	test: 0.777684
PRC train: 0.906245	val: 0.556763	test: 0.579055

Epoch: 65
Loss: 0.1272303187542037
ROC train: 0.980889	val: 0.627727	test: 0.795166
PRC train: 0.899595	val: 0.556345	test: 0.577266

Epoch: 66
Loss: 0.1253217009584312
ROC train: 0.978914	val: 0.632942	test: 0.806747
PRC train: 0.894951	val: 0.550469	test: 0.577438

Epoch: 67
Loss: 0.12200197736739601
ROC train: 0.977930	val: 0.638136	test: 0.799569
PRC train: 0.893626	val: 0.553050	test: 0.580774

Epoch: 68
Loss: 0.12780289765901995
ROC train: 0.982435	val: 0.623774	test: 0.775794
PRC train: 0.908855	val: 0.553972	test: 0.580002

Epoch: 69
Loss: 0.11461109011676668
ROC train: 0.983989	val: 0.626683	test: 0.746903
PRC train: 0.916039	val: 0.552337	test: 0.574392

Epoch: 70
Loss: 0.11602862964002073
ROC train: 0.983268	val: 0.642270	test: 0.740370
PRC train: 0.913493	val: 0.555904	test: 0.580600

Epoch: 71
Loss: 0.11762348813208139
ROC train: 0.982397	val: 0.644474	test: 0.748479
PRC train: 0.906837	val: 0.552791	test: 0.582802

Epoch: 72
Loss: 0.12759698804423
ROC train: 0.983201	val: 0.653491	test: 0.761591
PRC train: 0.909222	val: 0.555657	test: 0.582153

Epoch: 73
Loss: 0.12285763780097872
ROC train: 0.982036	val: 0.654067	test: 0.763084
PRC train: 0.902752	val: 0.557463	test: 0.584913

Epoch: 74
Loss: 0.10781542318044401
ROC train: 0.979218	val: 0.652908	test: 0.749464
PRC train: 0.892175	val: 0.560916	test: 0.590010

Epoch: 75
Loss: 0.11085582626214491
ROC train: 0.981708	val: 0.651591	test: 0.751041
PRC train: 0.898595	val: 0.561857	test: 0.588647

Epoch: 76
Loss: 0.10590048946850514
ROC train: 0.983622	val: 0.642998	test: 0.758979
PRC train: 0.908359	val: 0.559714	test: 0.590265

Epoch: 77
Loss: 0.1146199227643026
ROC train: 0.982814	val: 0.638575	test: 0.761325
PRC train: 0.902995	val: 0.557282	test: 0.581149

Epoch: 78
Loss: 0.11773065083138065
ROC train: 0.983062	val: 0.633106	test: 0.765978
PRC train: 0.904805	val: 0.554410	test: 0.585530

Epoch: 79
Loss: 0.11592490195029534
ROC train: 0.984251	val: 0.633922	test: 0.764840
PRC train: 0.910781	val: 0.554546	test: 0.583831

Epoch: 80
Loss: 0.12151378560791745
ROC train: 0.983997	val: 0.643981	test: 0.770449
PRC train: 0.910815	val: 0.558400	test: 0.594785

Epoch: 81
Loss: 0.09632285463426819
ROC train: 0.977784	val: 0.636490	test: 0.758274
PRC train: 0.878475	val: 0.553902	test: 0.579574

Epoch: 82
Loss: 0.11236090084877258
ROC train: 0.984211	val: 0.649583	test: 0.783691
PRC train: 0.912818	val: 0.558298	test: 0.597094

Epoch: 83
Loss: 0.10475423966974458
ROC train: 0.982114	val: 0.646292	test: 0.779189
PRC train: 0.908773	val: 0.555404	test: 0.599580

Epoch: 84
Loss: 0.11591020359082767
ROC train: 0.982685	val: 0.640315	test: 0.780768
PRC train: 0.914215	val: 0.555446	test: 0.597551

Epoch: 85
Loss: 0.10952984342404669
ROC train: 0.983963	val: 0.632616	test: 0.786603
PRC train: 0.919541	val: 0.551401	test: 0.599524

Epoch: 86
Loss: 0.10263486426968751
ROC train: 0.983764	val: 0.638318	test: 0.791829
PRC train: 0.915185	val: 0.553965	test: 0.601331

Epoch: 87
Loss: 0.1128985337327258
ROC train: 0.985046	val: 0.636955	test: 0.791677
PRC train: 0.921127	val: 0.552555	test: 0.602736

Epoch: 88
Loss: 0.13557417628954643
ROC train: 0.983910	val: 0.645306	test: 0.786982
PRC train: 0.916810	val: 0.557292	test: 0.604246

Epoch: 89
Loss: 0.10403442012864975
ROC train: 0.983131	val: 0.666645	test: 0.784285
PRC train: 0.912827	val: 0.566925	test: 0.608621

Epoch: 90
Loss: 0.11808840991892242
ROC train: 0.984670	val: 0.674272	test: 0.800270
PRC train: 0.915154	val: 0.569561	test: 0.616240

Epoch: 91
Loss: 0.10416185074072831
ROC train: 0.985278	val: 0.656230	test: 0.794446
PRC train: 0.916358	val: 0.558150	test: 0.601299

Epoch: 92
Loss: 0.10238233002410282
ROC train: 0.984895	val: 0.638956	test: 0.776025
PRC train: 0.915959	val: 0.549662	test: 0.586485

Epoch: 93
Loss: 0.10398207566444108
ROC train: 0.984116	val: 0.646722	test: 0.762593
PRC train: 0.912699	val: 0.550338	test: 0.579732

Epoch: 94
Loss: 0.10899855574105247
ROC train: 0.963615	val: 0.718133	test: 0.726249
PRC train: 0.850055	val: 0.573652	test: 0.571614

Epoch: 34
Loss: 0.15033042362739849
ROC train: 0.962998	val: 0.721723	test: 0.720382
PRC train: 0.856740	val: 0.573327	test: 0.577765

Epoch: 35
Loss: 0.14042468692115578
ROC train: 0.963850	val: 0.729539	test: 0.710347
PRC train: 0.854498	val: 0.575278	test: 0.573941

Epoch: 36
Loss: 0.1557475572007798
ROC train: 0.964996	val: 0.726919	test: 0.704822
PRC train: 0.853949	val: 0.573188	test: 0.569531

Epoch: 37
Loss: 0.1570262000661695
ROC train: 0.965144	val: 0.719922	test: 0.719352
PRC train: 0.851711	val: 0.564093	test: 0.577980

Epoch: 38
Loss: 0.15614317964904492
ROC train: 0.966422	val: 0.695013	test: 0.715015
PRC train: 0.868853	val: 0.558572	test: 0.568390

Epoch: 39
Loss: 0.14317934377276145
ROC train: 0.966509	val: 0.690991	test: 0.719355
PRC train: 0.868193	val: 0.561450	test: 0.563818

Epoch: 40
Loss: 0.1470191471217194
ROC train: 0.965624	val: 0.697779	test: 0.739598
PRC train: 0.870024	val: 0.561600	test: 0.573765

Epoch: 41
Loss: 0.1474629280589304
ROC train: 0.965438	val: 0.698191	test: 0.744320
PRC train: 0.869321	val: 0.563376	test: 0.581549

Epoch: 42
Loss: 0.1370716423403542
ROC train: 0.966596	val: 0.689758	test: 0.726486
PRC train: 0.865507	val: 0.560306	test: 0.569143

Epoch: 43
Loss: 0.14280088773454785
ROC train: 0.969178	val: 0.696281	test: 0.743900
PRC train: 0.869059	val: 0.566145	test: 0.582835

Epoch: 44
Loss: 0.14530129378183582
ROC train: 0.969469	val: 0.710218	test: 0.765235
PRC train: 0.869392	val: 0.571379	test: 0.618694

Epoch: 45
Loss: 0.14106838947751418
ROC train: 0.972787	val: 0.711035	test: 0.768810
PRC train: 0.879646	val: 0.572773	test: 0.611129

Epoch: 46
Loss: 0.1365805556324169
ROC train: 0.973663	val: 0.696535	test: 0.758471
PRC train: 0.883234	val: 0.563933	test: 0.587896

Epoch: 47
Loss: 0.13791509388547132
ROC train: 0.968413	val: 0.699904	test: 0.782800
PRC train: 0.873742	val: 0.564051	test: 0.605376

Epoch: 48
Loss: 0.14274173168040766
ROC train: 0.967834	val: 0.689290	test: 0.780747
PRC train: 0.873344	val: 0.563332	test: 0.599614

Epoch: 49
Loss: 0.12377767381553531
ROC train: 0.973027	val: 0.669739	test: 0.761007
PRC train: 0.887235	val: 0.554780	test: 0.593872

Epoch: 50
Loss: 0.14343189738755346
ROC train: 0.974862	val: 0.657930	test: 0.761106
PRC train: 0.884682	val: 0.552833	test: 0.585778

Epoch: 51
Loss: 0.13954464143381423
ROC train: 0.974661	val: 0.687808	test: 0.781649
PRC train: 0.882837	val: 0.558167	test: 0.600766

Epoch: 52
Loss: 0.13359838199799762
ROC train: 0.975907	val: 0.698241	test: 0.771420
PRC train: 0.885790	val: 0.564407	test: 0.601521

Epoch: 53
Loss: 0.13204023852983493
ROC train: 0.976793	val: 0.696823	test: 0.761885
PRC train: 0.887095	val: 0.567118	test: 0.594724

Epoch: 54
Loss: 0.1375640623685669
ROC train: 0.976825	val: 0.702413	test: 0.762139
PRC train: 0.885564	val: 0.566811	test: 0.600173

Epoch: 55
Loss: 0.1279839660315386
ROC train: 0.976119	val: 0.707751	test: 0.771479
PRC train: 0.884509	val: 0.569244	test: 0.611423

Epoch: 56
Loss: 0.13525172825241166
ROC train: 0.975757	val: 0.701017	test: 0.770511
PRC train: 0.889450	val: 0.567247	test: 0.607050

Epoch: 57
Loss: 0.12003225406935704
ROC train: 0.975315	val: 0.698044	test: 0.774592
PRC train: 0.894664	val: 0.568083	test: 0.608981

Epoch: 58
Loss: 0.13360152269868197
ROC train: 0.977187	val: 0.702900	test: 0.771219
PRC train: 0.896120	val: 0.570519	test: 0.601732

Epoch: 59
Loss: 0.11441038894527727
ROC train: 0.979748	val: 0.706096	test: 0.773728
PRC train: 0.901129	val: 0.573480	test: 0.604940

Epoch: 60
Loss: 0.12063300297648094
ROC train: 0.981358	val: 0.704830	test: 0.771943
PRC train: 0.905764	val: 0.575359	test: 0.604176

Epoch: 61
Loss: 0.11740693754578345
ROC train: 0.982210	val: 0.705797	test: 0.762021
PRC train: 0.909613	val: 0.579536	test: 0.603962

Epoch: 62
Loss: 0.10900242525865873
ROC train: 0.981352	val: 0.705948	test: 0.749000
PRC train: 0.905129	val: 0.575534	test: 0.602395

Epoch: 63
Loss: 0.12576268889712894
ROC train: 0.981237	val: 0.703771	test: 0.745143
PRC train: 0.906142	val: 0.573228	test: 0.603739

Epoch: 64
Loss: 0.11195901193172002
ROC train: 0.981676	val: 0.689123	test: 0.754244
PRC train: 0.910631	val: 0.567769	test: 0.599504

Epoch: 65
Loss: 0.11629041146179007
ROC train: 0.981787	val: 0.681283	test: 0.748384
PRC train: 0.909532	val: 0.563200	test: 0.591016

Epoch: 66
Loss: 0.12177152847970966
ROC train: 0.980718	val: 0.689895	test: 0.747169
PRC train: 0.904414	val: 0.567159	test: 0.610993

Epoch: 67
Loss: 0.11911403027601575
ROC train: 0.982051	val: 0.699359	test: 0.726056
PRC train: 0.909378	val: 0.571016	test: 0.613514

Epoch: 68
Loss: 0.12150788286453494
ROC train: 0.983203	val: 0.698364	test: 0.729792
PRC train: 0.914077	val: 0.566713	test: 0.608407

Epoch: 69
Loss: 0.13249176874894103
ROC train: 0.983165	val: 0.707095	test: 0.747264
PRC train: 0.911995	val: 0.567158	test: 0.606457

Epoch: 70
Loss: 0.12312114666114607
ROC train: 0.981964	val: 0.711409	test: 0.755759
PRC train: 0.908802	val: 0.570549	test: 0.614314

Epoch: 71
Loss: 0.11844546322805162
ROC train: 0.979800	val: 0.706717	test: 0.744808
PRC train: 0.904618	val: 0.570721	test: 0.601233

Epoch: 72
Loss: 0.12031621420692067
ROC train: 0.983788	val: 0.707032	test: 0.759458
PRC train: 0.913136	val: 0.572308	test: 0.617475

Epoch: 73
Loss: 0.11893339219522327
ROC train: 0.981167	val: 0.703799	test: 0.772290
PRC train: 0.903173	val: 0.565634	test: 0.623873

Epoch: 74
Loss: 0.10892828291283928
ROC train: 0.980592	val: 0.686430	test: 0.767368
PRC train: 0.904199	val: 0.563310	test: 0.616597

Epoch: 75
Loss: 0.11611495825977128
ROC train: 0.984049	val: 0.665704	test: 0.748298
PRC train: 0.916242	val: 0.555467	test: 0.608813

Epoch: 76
Loss: 0.12945557851796502
ROC train: 0.984379	val: 0.679976	test: 0.745619
PRC train: 0.918774	val: 0.562184	test: 0.616825

Epoch: 77
Loss: 0.1169719306012099
ROC train: 0.983367	val: 0.705457	test: 0.760326
PRC train: 0.909635	val: 0.567883	test: 0.634942

Epoch: 78
Loss: 0.12117591068816946
ROC train: 0.982044	val: 0.708675	test: 0.757621
PRC train: 0.906954	val: 0.565643	test: 0.635460

Epoch: 79
Loss: 0.11843396670648201
ROC train: 0.984680	val: 0.692805	test: 0.749813
PRC train: 0.914838	val: 0.566616	test: 0.622651

Epoch: 80
Loss: 0.10283647320205924
ROC train: 0.984268	val: 0.676164	test: 0.746389
PRC train: 0.915363	val: 0.560128	test: 0.615555

Epoch: 81
Loss: 0.10735087770727947
ROC train: 0.983285	val: 0.682061	test: 0.753712
PRC train: 0.912729	val: 0.565510	test: 0.619520

Epoch: 82
Loss: 0.11425802148717623
ROC train: 0.984269	val: 0.684644	test: 0.749690
PRC train: 0.914022	val: 0.562634	test: 0.616301

Epoch: 83
Loss: 0.11083064517609154
ROC train: 0.984765	val: 0.681462	test: 0.746347
PRC train: 0.915155	val: 0.564309	test: 0.613764

Epoch: 84
Loss: 0.11890909870241342
ROC train: 0.984656	val: 0.679569	test: 0.740577
PRC train: 0.914137	val: 0.564651	test: 0.613923

Epoch: 85
Loss: 0.10849872900754913
ROC train: 0.983865	val: 0.684231	test: 0.740697
PRC train: 0.911596	val: 0.567250	test: 0.609491

Epoch: 86
Loss: 0.11497308550552411
ROC train: 0.984912	val: 0.689200	test: 0.732507
PRC train: 0.915683	val: 0.566847	test: 0.604583

Epoch: 87
Loss: 0.10747052689241558
ROC train: 0.984556	val: 0.686020	test: 0.717529
PRC train: 0.913247	val: 0.557002	test: 0.598192

Epoch: 88
Loss: 0.10985917411378136
ROC train: 0.985182	val: 0.703331	test: 0.732036
PRC train: 0.917577	val: 0.564706	test: 0.604802

Epoch: 89
Loss: 0.1133242060355588
ROC train: 0.983937	val: 0.716194	test: 0.755312
PRC train: 0.914006	val: 0.573596	test: 0.621505

Epoch: 90
Loss: 0.11035962866034167
ROC train: 0.985613	val: 0.712078	test: 0.758925
PRC train: 0.919335	val: 0.573544	test: 0.624875

Epoch: 91
Loss: 0.10592266818094084
ROC train: 0.985379	val: 0.707172	test: 0.763283
PRC train: 0.921265	val: 0.572338	test: 0.622508

Epoch: 92
Loss: 0.10996041760210243
ROC train: 0.985657	val: 0.704467	test: 0.775070
PRC train: 0.920718	val: 0.574826	test: 0.625173

Epoch: 93
Loss: 0.10534023190744124
ROC train: 0.985479	val: 0.699289	test: 0.778064
PRC train: 0.919328	val: 0.573543	test: 0.625347

Epoch: 94
Loss: 0.10310857310530336
ROC train: 0.894776	val: 0.675406	test: 0.674058
PRC train: 0.706281	val: 0.573937	test: 0.547878

Epoch: 34
Loss: 0.2203017621427908
ROC train: 0.891228	val: 0.667740	test: 0.683744
PRC train: 0.704895	val: 0.566883	test: 0.539459

Epoch: 35
Loss: 0.18937317547406587
ROC train: 0.898905	val: 0.697206	test: 0.687908
PRC train: 0.739569	val: 0.581436	test: 0.537975

Epoch: 36
Loss: 0.21096747133479649
ROC train: 0.899181	val: 0.708667	test: 0.674398
PRC train: 0.744050	val: 0.587363	test: 0.537823

Epoch: 37
Loss: 0.16534579696488508
ROC train: 0.906986	val: 0.690265	test: 0.636360
PRC train: 0.749817	val: 0.574719	test: 0.528391

Epoch: 38
Loss: 0.18642097258309362
ROC train: 0.907688	val: 0.669028	test: 0.613848
PRC train: 0.744023	val: 0.570324	test: 0.527200

Epoch: 39
Loss: 0.24455509316608187
ROC train: 0.913791	val: 0.692050	test: 0.645736
PRC train: 0.751833	val: 0.585374	test: 0.535189

Epoch: 40
Loss: 0.19111429518834439
ROC train: 0.910255	val: 0.731589	test: 0.658012
PRC train: 0.741743	val: 0.586235	test: 0.535705

Epoch: 41
Loss: 0.1650660102162237
ROC train: 0.908524	val: 0.734386	test: 0.632306
PRC train: 0.735728	val: 0.589480	test: 0.535096

Epoch: 42
Loss: 0.18074856278247417
ROC train: 0.917307	val: 0.707489	test: 0.638888
PRC train: 0.761130	val: 0.581563	test: 0.531366

Epoch: 43
Loss: 0.2444583481697909
ROC train: 0.892257	val: 0.629710	test: 0.647471
PRC train: 0.725547	val: 0.556609	test: 0.529049

Epoch: 44
Loss: 0.17018146272641863
ROC train: 0.922196	val: 0.719761	test: 0.709467
PRC train: 0.767110	val: 0.578870	test: 0.546531

Epoch: 45
Loss: 0.18256992620181864
ROC train: 0.927742	val: 0.739241	test: 0.727681
PRC train: 0.773766	val: 0.588014	test: 0.552423

Epoch: 46
Loss: 0.17657068425853079
ROC train: 0.930200	val: 0.723294	test: 0.700533
PRC train: 0.774434	val: 0.583521	test: 0.549042

Epoch: 47
Loss: 0.15547014702766143
ROC train: 0.915523	val: 0.706068	test: 0.663985
PRC train: 0.748706	val: 0.578110	test: 0.538197

Epoch: 48
Loss: 0.1735806389920364
ROC train: 0.925868	val: 0.717114	test: 0.679926
PRC train: 0.770131	val: 0.585189	test: 0.541154

Epoch: 49
Loss: 0.17696151533246723
ROC train: 0.937616	val: 0.729682	test: 0.699509
PRC train: 0.785532	val: 0.589083	test: 0.555179

Epoch: 50
Loss: 0.165538553137687
ROC train: 0.932516	val: 0.714799	test: 0.690901
PRC train: 0.795740	val: 0.603894	test: 0.559193

Epoch: 51
Loss: 0.20596647727530737
ROC train: 0.923197	val: 0.708051	test: 0.660476
PRC train: 0.788130	val: 0.583090	test: 0.548193

Epoch: 52
Loss: 0.18488349898562362
ROC train: 0.922086	val: 0.705831	test: 0.658883
PRC train: 0.763591	val: 0.582056	test: 0.545572

Epoch: 53
Loss: 0.16126176072827977
ROC train: 0.928426	val: 0.719614	test: 0.664591
PRC train: 0.778689	val: 0.585905	test: 0.539851

Epoch: 54
Loss: 0.22100011156555407
ROC train: 0.939047	val: 0.749259	test: 0.668883
PRC train: 0.791436	val: 0.608396	test: 0.553330

Epoch: 55
Loss: 0.17017387144889717
ROC train: 0.932419	val: 0.751043	test: 0.682018
PRC train: 0.772579	val: 0.603131	test: 0.561976

Epoch: 56
Loss: 0.1539761195619846
ROC train: 0.939429	val: 0.746872	test: 0.673409
PRC train: 0.801253	val: 0.594031	test: 0.561509

Epoch: 57
Loss: 0.1455458147435304
ROC train: 0.928956	val: 0.709279	test: 0.655646
PRC train: 0.791632	val: 0.594167	test: 0.547980

Epoch: 58
Loss: 0.13948569519856635
ROC train: 0.933683	val: 0.708127	test: 0.677874
PRC train: 0.801522	val: 0.594022	test: 0.552590

Epoch: 59
Loss: 0.14907478814727598
ROC train: 0.944121	val: 0.730091	test: 0.727443
PRC train: 0.813909	val: 0.592550	test: 0.561851

Epoch: 60
Loss: 0.14436179193844118
ROC train: 0.946470	val: 0.740281	test: 0.744487
PRC train: 0.811995	val: 0.594969	test: 0.565433

Epoch: 61
Loss: 0.15942850758848354
ROC train: 0.949327	val: 0.745018	test: 0.738600
PRC train: 0.816777	val: 0.597070	test: 0.562826

Epoch: 62
Loss: 0.16895681849048888
ROC train: 0.945553	val: 0.740566	test: 0.743679
PRC train: 0.819716	val: 0.610317	test: 0.554861

Epoch: 63
Loss: 0.14322734725031133
ROC train: 0.939666	val: 0.719649	test: 0.714671
PRC train: 0.812473	val: 0.605484	test: 0.544291

Epoch: 64
Loss: 0.15202575553694792
ROC train: 0.946899	val: 0.734188	test: 0.703974
PRC train: 0.825014	val: 0.602388	test: 0.540070

Epoch: 65
Loss: 0.13332312702003735
ROC train: 0.952901	val: 0.742800	test: 0.693667
PRC train: 0.814510	val: 0.594328	test: 0.544368

Epoch: 66
Loss: 0.20030209751754083
ROC train: 0.953546	val: 0.732034	test: 0.688526
PRC train: 0.811019	val: 0.582147	test: 0.551119

Epoch: 67
Loss: 0.19103132519766905
ROC train: 0.946225	val: 0.690441	test: 0.654526
PRC train: 0.799668	val: 0.567337	test: 0.529875

Epoch: 68
Loss: 0.19717869590392792
ROC train: 0.924125	val: 0.646641	test: 0.615186
PRC train: 0.754413	val: 0.550226	test: 0.529379

Epoch: 69
Loss: 0.1837652319701312
ROC train: 0.943877	val: 0.683803	test: 0.648715
PRC train: 0.799376	val: 0.564821	test: 0.538175

Epoch: 70
Loss: 0.2135154742597895
ROC train: 0.946169	val: 0.694501	test: 0.655260
PRC train: 0.794282	val: 0.571968	test: 0.536945

Epoch: 71
Loss: 0.18457779613494255
ROC train: 0.943727	val: 0.686338	test: 0.642981
PRC train: 0.803353	val: 0.579954	test: 0.537897

Epoch: 72
Loss: 0.14479697999849067
ROC train: 0.944395	val: 0.707924	test: 0.641535
PRC train: 0.789792	val: 0.595558	test: 0.548891

Epoch: 73
Loss: 0.20398066682520405
ROC train: 0.951393	val: 0.699542	test: 0.617890
PRC train: 0.794512	val: 0.606511	test: 0.545452

Epoch: 74
Loss: 0.16568022985545855
ROC train: 0.944373	val: 0.677215	test: 0.624415
PRC train: 0.788236	val: 0.592077	test: 0.545883

Epoch: 75
Loss: 0.13912896724267343
ROC train: 0.952182	val: 0.677363	test: 0.644710
PRC train: 0.798750	val: 0.575148	test: 0.542833

Epoch: 76
Loss: 0.14018751930268847
ROC train: 0.954902	val: 0.679109	test: 0.659840
PRC train: 0.809605	val: 0.576211	test: 0.545476

Epoch: 77
Loss: 0.1357723698723427
ROC train: 0.955826	val: 0.685190	test: 0.654710
PRC train: 0.820751	val: 0.576681	test: 0.544635

Epoch: 78
Loss: 0.15658031201014702
ROC train: 0.955908	val: 0.690378	test: 0.660790
PRC train: 0.824731	val: 0.572760	test: 0.546049

Epoch: 79
Loss: 0.16308800950680266
ROC train: 0.955138	val: 0.695207	test: 0.670697
PRC train: 0.819411	val: 0.570526	test: 0.557297

Epoch: 80
Loss: 0.15309657694284973
ROC train: 0.948452	val: 0.687544	test: 0.639302
PRC train: 0.793718	val: 0.554099	test: 0.529304

Epoch: 81
Loss: 0.21512392439021877
ROC train: 0.954174	val: 0.694355	test: 0.649262
PRC train: 0.819006	val: 0.560524	test: 0.536801

Epoch: 82
Loss: 0.16768709961451717
ROC train: 0.955299	val: 0.709177	test: 0.693701
PRC train: 0.809318	val: 0.566374	test: 0.556519

Epoch: 83
Loss: 0.2220594186908187
ROC train: 0.951640	val: 0.710612	test: 0.694915
PRC train: 0.807032	val: 0.570352	test: 0.551982

Epoch: 84
Loss: 0.13451750630376863
ROC train: 0.948469	val: 0.704444	test: 0.668460
PRC train: 0.795731	val: 0.573842	test: 0.542013

Epoch: 85
Loss: 0.17118757419121006
ROC train: 0.950764	val: 0.710671	test: 0.653094
PRC train: 0.808568	val: 0.584550	test: 0.541810

Epoch: 86
Loss: 0.16046839776832972
ROC train: 0.957458	val: 0.725320	test: 0.644086
PRC train: 0.836141	val: 0.596161	test: 0.545982

Epoch: 87
Loss: 0.2071438608127037
ROC train: 0.955963	val: 0.736045	test: 0.635436
PRC train: 0.831142	val: 0.600748	test: 0.532762

Epoch: 88
Loss: 0.15829329003091522
ROC train: 0.953265	val: 0.726188	test: 0.643996
PRC train: 0.817055	val: 0.601443	test: 0.530994

Epoch: 89
Loss: 0.13619713422862129
ROC train: 0.954038	val: 0.714080	test: 0.642488
PRC train: 0.811056	val: 0.588870	test: 0.530189

Epoch: 90
Loss: 0.1718961316947122
ROC train: 0.958722	val: 0.709400	test: 0.648565
PRC train: 0.818909	val: 0.581107	test: 0.539650

Epoch: 91
Loss: 0.19842667844027306
ROC train: 0.959608	val: 0.703343	test: 0.665762
PRC train: 0.830421	val: 0.598191	test: 0.546745

Epoch: 92
Loss: 0.14386155127534866
ROC train: 0.950371	val: 0.717336	test: 0.682120
PRC train: 0.802560	val: 0.603185	test: 0.553209

Epoch: 93
Loss: 0.19387961738757875
ROC train: 0.953033	val: 0.740506	test: 0.703112
PRC train: 0.803830	val: 0.601211	test: 0.566468

Epoch: 94
Loss: 0.14288183795974563
ROC train: 0.920965	val: 0.704224	test: 0.630999
PRC train: 0.758793	val: 0.572635	test: 0.530985

Epoch: 34
Loss: 0.1872340451873797
ROC train: 0.923605	val: 0.722983	test: 0.655453
PRC train: 0.766958	val: 0.578352	test: 0.534665

Epoch: 35
Loss: 0.15497138955685782
ROC train: 0.930194	val: 0.727230	test: 0.665158
PRC train: 0.777007	val: 0.574923	test: 0.535163

Epoch: 36
Loss: 0.15451121830395753
ROC train: 0.934856	val: 0.722153	test: 0.655940
PRC train: 0.782584	val: 0.576453	test: 0.531265

Epoch: 37
Loss: 0.17664216790826867
ROC train: 0.939926	val: 0.710116	test: 0.639937
PRC train: 0.793399	val: 0.571666	test: 0.528898

Epoch: 38
Loss: 0.16634234311583818
ROC train: 0.941219	val: 0.716999	test: 0.665090
PRC train: 0.788612	val: 0.578801	test: 0.535665

Epoch: 39
Loss: 0.17496649222549276
ROC train: 0.939647	val: 0.728938	test: 0.634064
PRC train: 0.792631	val: 0.591416	test: 0.532759

Epoch: 40
Loss: 0.1486876510147856
ROC train: 0.941787	val: 0.743838	test: 0.688815
PRC train: 0.797895	val: 0.579153	test: 0.543801

Epoch: 41
Loss: 0.20746878227018253
ROC train: 0.940803	val: 0.728804	test: 0.708934
PRC train: 0.794594	val: 0.565689	test: 0.545424

Epoch: 42
Loss: 0.2028156406552047
ROC train: 0.915163	val: 0.711396	test: 0.677408
PRC train: 0.767337	val: 0.559983	test: 0.546976

Epoch: 43
Loss: 0.15562650178327
ROC train: 0.915773	val: 0.686811	test: 0.659296
PRC train: 0.738738	val: 0.551434	test: 0.535881

Epoch: 44
Loss: 0.1653353352979919
ROC train: 0.917317	val: 0.680633	test: 0.634789
PRC train: 0.743521	val: 0.552282	test: 0.531990

Epoch: 45
Loss: 0.23689393442563897
ROC train: 0.939122	val: 0.702612	test: 0.655968
PRC train: 0.777942	val: 0.564720	test: 0.537902

Epoch: 46
Loss: 0.15156811144809065
ROC train: 0.918902	val: 0.727713	test: 0.684846
PRC train: 0.775975	val: 0.575210	test: 0.539225

Epoch: 47
Loss: 0.1501068257083783
ROC train: 0.925421	val: 0.727998	test: 0.690810
PRC train: 0.792276	val: 0.578865	test: 0.537755

Epoch: 48
Loss: 0.1816113372126435
ROC train: 0.943327	val: 0.725756	test: 0.698939
PRC train: 0.807908	val: 0.580130	test: 0.538942

Epoch: 49
Loss: 0.16439503732328328
ROC train: 0.936306	val: 0.729385	test: 0.712128
PRC train: 0.790171	val: 0.573906	test: 0.547372

Epoch: 50
Loss: 0.1456383813673306
ROC train: 0.940606	val: 0.730289	test: 0.678956
PRC train: 0.783322	val: 0.582535	test: 0.537501

Epoch: 51
Loss: 0.20389509885618057
ROC train: 0.941962	val: 0.743428	test: 0.686400
PRC train: 0.806526	val: 0.582488	test: 0.541679

Epoch: 52
Loss: 0.14033128701219189
ROC train: 0.906287	val: 0.757656	test: 0.723163
PRC train: 0.758464	val: 0.581157	test: 0.547342

Epoch: 53
Loss: 0.1801846759295892
ROC train: 0.911283	val: 0.765667	test: 0.698350
PRC train: 0.783775	val: 0.585769	test: 0.545594

Epoch: 54
Loss: 0.1481845902149382
ROC train: 0.941660	val: 0.746968	test: 0.665787
PRC train: 0.814469	val: 0.582656	test: 0.537018

Epoch: 55
Loss: 0.1520595479024687
ROC train: 0.945025	val: 0.728186	test: 0.631444
PRC train: 0.810248	val: 0.584417	test: 0.531865

Epoch: 56
Loss: 0.2393489271597912
ROC train: 0.945359	val: 0.731492	test: 0.628752
PRC train: 0.807909	val: 0.593899	test: 0.533719

Epoch: 57
Loss: 0.13802367602165894
ROC train: 0.925470	val: 0.703299	test: 0.591892
PRC train: 0.761430	val: 0.582022	test: 0.527359

Epoch: 58
Loss: 0.2471718023330574
ROC train: 0.939105	val: 0.740496	test: 0.657868
PRC train: 0.793615	val: 0.590646	test: 0.530351

Epoch: 59
Loss: 0.14788779058807716
ROC train: 0.909200	val: 0.731468	test: 0.655146
PRC train: 0.736605	val: 0.588263	test: 0.526382

Epoch: 60
Loss: 0.19163565315506195
ROC train: 0.921120	val: 0.735715	test: 0.661660
PRC train: 0.765929	val: 0.596875	test: 0.530070

Epoch: 61
Loss: 0.21469471058833908
ROC train: 0.931581	val: 0.725150	test: 0.641036
PRC train: 0.785683	val: 0.595440	test: 0.534129

Epoch: 62
Loss: 0.1715485368272259
ROC train: 0.923876	val: 0.701995	test: 0.634783
PRC train: 0.764695	val: 0.587177	test: 0.531590

Epoch: 63
Loss: 0.1692069950948445
ROC train: 0.921641	val: 0.710898	test: 0.630010
PRC train: 0.752454	val: 0.592108	test: 0.536607

Epoch: 64
Loss: 0.19151847006953798
ROC train: 0.930549	val: 0.706554	test: 0.621739
PRC train: 0.775663	val: 0.584611	test: 0.527133

Epoch: 65
Loss: 0.16736917459886153
ROC train: 0.916164	val: 0.681293	test: 0.585639
PRC train: 0.720194	val: 0.565019	test: 0.515278

Epoch: 66
Loss: 0.17020880176295483
ROC train: 0.930539	val: 0.674322	test: 0.598757
PRC train: 0.759832	val: 0.559746	test: 0.516729

Epoch: 67
Loss: 0.17785175880848408
ROC train: 0.946941	val: 0.693440	test: 0.648945
PRC train: 0.807518	val: 0.575687	test: 0.526239

Epoch: 68
Loss: 0.14317495342155356
ROC train: 0.943076	val: 0.708781	test: 0.662726
PRC train: 0.812003	val: 0.583202	test: 0.530935

Epoch: 69
Loss: 0.1573069893535875
ROC train: 0.940907	val: 0.720086	test: 0.663684
PRC train: 0.815750	val: 0.591399	test: 0.531166

Epoch: 70
Loss: 0.17288739634627337
ROC train: 0.946416	val: 0.737531	test: 0.676751
PRC train: 0.813546	val: 0.598117	test: 0.535185

Epoch: 71
Loss: 0.13987482299549428
ROC train: 0.938057	val: 0.748923	test: 0.694795
PRC train: 0.787301	val: 0.624956	test: 0.544537

Epoch: 72
Loss: 0.14403866210265007
ROC train: 0.941092	val: 0.753580	test: 0.696264
PRC train: 0.793292	val: 0.621432	test: 0.547726

Epoch: 73
Loss: 0.17032861764985607
ROC train: 0.951847	val: 0.755821	test: 0.687159
PRC train: 0.810584	val: 0.627674	test: 0.544409

Epoch: 74
Loss: 0.13712646445915405
ROC train: 0.948156	val: 0.770099	test: 0.674206
PRC train: 0.807188	val: 0.649219	test: 0.541653

Epoch: 75
Loss: 0.152921481581089
ROC train: 0.950349	val: 0.769851	test: 0.674081
PRC train: 0.812015	val: 0.640505	test: 0.543026

Epoch: 76
Loss: 0.18704071269096928
ROC train: 0.954499	val: 0.777791	test: 0.677604
PRC train: 0.820539	val: 0.624485	test: 0.537271

Epoch: 77
Loss: 0.1742031965127345
ROC train: 0.947381	val: 0.792926	test: 0.664869
PRC train: 0.809753	val: 0.620155	test: 0.531405

Epoch: 78
Loss: 0.14365141427455713
ROC train: 0.937598	val: 0.789360	test: 0.675300
PRC train: 0.780277	val: 0.594951	test: 0.536029

Epoch: 79
Loss: 0.19640625782410764
ROC train: 0.925007	val: 0.765161	test: 0.703588
PRC train: 0.771809	val: 0.589823	test: 0.551326

Epoch: 80
Loss: 0.1627661937067544
ROC train: 0.919391	val: 0.743547	test: 0.722443
PRC train: 0.770431	val: 0.582970	test: 0.554056

Epoch: 81
Loss: 0.18417087549677813
ROC train: 0.929959	val: 0.752269	test: 0.735737
PRC train: 0.796946	val: 0.595624	test: 0.553184

Epoch: 82
Loss: 0.1505818587451556
ROC train: 0.936306	val: 0.745915	test: 0.732795
PRC train: 0.810152	val: 0.594960	test: 0.556090

Epoch: 83
Loss: 0.1424896582777876
ROC train: 0.947490	val: 0.749159	test: 0.727517
PRC train: 0.817254	val: 0.601442	test: 0.549284

Epoch: 84
Loss: 0.13187233692330086
ROC train: 0.944703	val: 0.751549	test: 0.734127
PRC train: 0.806697	val: 0.608236	test: 0.552344

Epoch: 85
Loss: 0.12921883065682507
ROC train: 0.949735	val: 0.753158	test: 0.725408
PRC train: 0.811498	val: 0.611559	test: 0.545513

Epoch: 86
Loss: 0.13515412841094082
ROC train: 0.959249	val: 0.751983	test: 0.721020
PRC train: 0.827796	val: 0.612400	test: 0.541990

Epoch: 87
Loss: 0.27062506137203834
ROC train: 0.960497	val: 0.751550	test: 0.718679
PRC train: 0.831651	val: 0.602320	test: 0.546001

Epoch: 88
Loss: 0.19547393671980645
ROC train: 0.929644	val: 0.724581	test: 0.732554
PRC train: 0.788330	val: 0.574699	test: 0.562928

Epoch: 89
Loss: 0.175974750331757
ROC train: 0.927494	val: 0.718054	test: 0.750057
PRC train: 0.792922	val: 0.571725	test: 0.572719

Epoch: 90
Loss: 0.15292461776854088
ROC train: 0.946982	val: 0.735958	test: 0.745011
PRC train: 0.819487	val: 0.587001	test: 0.561285

Epoch: 91
Loss: 0.11912318136114083
ROC train: 0.963444	val: 0.748390	test: 0.703985
PRC train: 0.846575	val: 0.611754	test: 0.546812

Epoch: 92
Loss: 0.21001646162668544
ROC train: 0.966897	val: 0.756532	test: 0.700274
PRC train: 0.851744	val: 0.618595	test: 0.544475

Epoch: 93
Loss: 0.13261610534928642
ROC train: 0.951216	val: 0.776327	test: 0.715229
PRC train: 0.819527	val: 0.654726	test: 0.549316

Epoch: 94
Loss: 0.19238705810453496
ROC train: 0.913570	val: 0.699701	test: 0.677482
PRC train: 0.728567	val: 0.583624	test: 0.548973

Epoch: 34
Loss: 0.21947454199507277
ROC train: 0.927538	val: 0.695465	test: 0.663072
PRC train: 0.764182	val: 0.586114	test: 0.539309

Epoch: 35
Loss: 0.21253551157148526
ROC train: 0.914910	val: 0.662735	test: 0.620191
PRC train: 0.754403	val: 0.575065	test: 0.523413

Epoch: 36
Loss: 0.20899841234667452
ROC train: 0.909908	val: 0.653794	test: 0.614820
PRC train: 0.747288	val: 0.561046	test: 0.523872

Epoch: 37
Loss: 0.16758510661345466
ROC train: 0.919420	val: 0.668839	test: 0.657590
PRC train: 0.744765	val: 0.568371	test: 0.530486

Epoch: 38
Loss: 0.19599288578702642
ROC train: 0.929847	val: 0.689271	test: 0.675016
PRC train: 0.761257	val: 0.587465	test: 0.538608

Epoch: 39
Loss: 0.18744867377609606
ROC train: 0.934225	val: 0.679648	test: 0.645594
PRC train: 0.770891	val: 0.590984	test: 0.530584

Epoch: 40
Loss: 0.1968349685098249
ROC train: 0.928011	val: 0.675079	test: 0.638202
PRC train: 0.761684	val: 0.585264	test: 0.527279

Epoch: 41
Loss: 0.17682558913180627
ROC train: 0.924277	val: 0.688814	test: 0.695918
PRC train: 0.737816	val: 0.587104	test: 0.556142

Epoch: 42
Loss: 0.16380275945388548
ROC train: 0.924405	val: 0.681942	test: 0.697273
PRC train: 0.753715	val: 0.575797	test: 0.558564

Epoch: 43
Loss: 0.16903246296192673
ROC train: 0.910096	val: 0.678487	test: 0.689240
PRC train: 0.764341	val: 0.571306	test: 0.553698

Epoch: 44
Loss: 0.20471762350871975
ROC train: 0.916363	val: 0.679737	test: 0.701337
PRC train: 0.764997	val: 0.573539	test: 0.560310

Epoch: 45
Loss: 0.16588170042746428
ROC train: 0.912513	val: 0.683613	test: 0.731185
PRC train: 0.745251	val: 0.575017	test: 0.568619

Epoch: 46
Loss: 0.1904959625549246
ROC train: 0.922811	val: 0.687849	test: 0.725822
PRC train: 0.754162	val: 0.585543	test: 0.559997

Epoch: 47
Loss: 0.22642666537280257
ROC train: 0.933272	val: 0.678042	test: 0.708514
PRC train: 0.765869	val: 0.573994	test: 0.558356

Epoch: 48
Loss: 0.20106870130277218
ROC train: 0.943437	val: 0.676691	test: 0.661592
PRC train: 0.782173	val: 0.574932	test: 0.543049

Epoch: 49
Loss: 0.18129660192879885
ROC train: 0.946067	val: 0.667787	test: 0.686870
PRC train: 0.785865	val: 0.568584	test: 0.560350

Epoch: 50
Loss: 0.1568568871774038
ROC train: 0.939549	val: 0.683960	test: 0.710507
PRC train: 0.766664	val: 0.578793	test: 0.566929

Epoch: 51
Loss: 0.18155660809912205
ROC train: 0.943641	val: 0.686560	test: 0.714710
PRC train: 0.778221	val: 0.580604	test: 0.567151

Epoch: 52
Loss: 0.19020591950561752
ROC train: 0.945194	val: 0.694260	test: 0.692590
PRC train: 0.789781	val: 0.584899	test: 0.563501

Epoch: 53
Loss: 0.14359262260955655
ROC train: 0.930352	val: 0.690050	test: 0.663029
PRC train: 0.760405	val: 0.588684	test: 0.550141

Epoch: 54
Loss: 0.16222169338817924
ROC train: 0.931172	val: 0.672975	test: 0.653831
PRC train: 0.769154	val: 0.585105	test: 0.550230

Epoch: 55
Loss: 0.18452779716511697
ROC train: 0.933242	val: 0.670327	test: 0.655906
PRC train: 0.778965	val: 0.587135	test: 0.543498

Epoch: 56
Loss: 0.16476778305524545
ROC train: 0.931568	val: 0.678588	test: 0.675736
PRC train: 0.785704	val: 0.598819	test: 0.543282

Epoch: 57
Loss: 0.14469664123483494
ROC train: 0.929798	val: 0.686303	test: 0.701944
PRC train: 0.785979	val: 0.598978	test: 0.547938

Epoch: 58
Loss: 0.2233220629605877
ROC train: 0.933182	val: 0.699725	test: 0.718951
PRC train: 0.787542	val: 0.589903	test: 0.558127

Epoch: 59
Loss: 0.14824108157042937
ROC train: 0.935445	val: 0.716541	test: 0.719898
PRC train: 0.789725	val: 0.590617	test: 0.561022

Epoch: 60
Loss: 0.15501856864177274
ROC train: 0.933055	val: 0.709731	test: 0.734790
PRC train: 0.781310	val: 0.584703	test: 0.586806

Epoch: 61
Loss: 0.13534701492782833
ROC train: 0.940304	val: 0.708861	test: 0.703747
PRC train: 0.795980	val: 0.588468	test: 0.567469

Epoch: 62
Loss: 0.22215338371591148
ROC train: 0.931703	val: 0.702248	test: 0.698418
PRC train: 0.791239	val: 0.592729	test: 0.564148

Epoch: 63
Loss: 0.15051763613088184
ROC train: 0.923843	val: 0.707512	test: 0.735374
PRC train: 0.765172	val: 0.584679	test: 0.564288

Epoch: 64
Loss: 0.1672032916584008
ROC train: 0.936398	val: 0.695549	test: 0.746978
PRC train: 0.779308	val: 0.582643	test: 0.568722

Epoch: 65
Loss: 0.2306344982779982
ROC train: 0.946516	val: 0.690609	test: 0.732120
PRC train: 0.812703	val: 0.583151	test: 0.558307

Epoch: 66
Loss: 0.1703020520770615
ROC train: 0.942253	val: 0.716899	test: 0.744473
PRC train: 0.809534	val: 0.597623	test: 0.560133

Epoch: 67
Loss: 0.14450865015136777
ROC train: 0.940502	val: 0.723519	test: 0.750865
PRC train: 0.797800	val: 0.594643	test: 0.564674

Epoch: 68
Loss: 0.18939461901746935
ROC train: 0.941956	val: 0.733308	test: 0.746236
PRC train: 0.798617	val: 0.597646	test: 0.566041

Epoch: 69
Loss: 0.14865089625370467
ROC train: 0.932095	val: 0.732716	test: 0.709722
PRC train: 0.785544	val: 0.598255	test: 0.551875

Epoch: 70
Loss: 0.14095206323753778
ROC train: 0.938644	val: 0.727341	test: 0.678208
PRC train: 0.776977	val: 0.600814	test: 0.538967

Epoch: 71
Loss: 0.16404227382347436
ROC train: 0.944837	val: 0.733336	test: 0.681105
PRC train: 0.787279	val: 0.599241	test: 0.541848

Epoch: 72
Loss: 0.18620741665417243
ROC train: 0.949784	val: 0.736653	test: 0.678956
PRC train: 0.800995	val: 0.596514	test: 0.542624

Epoch: 73
Loss: 0.14308985306665253
ROC train: 0.944709	val: 0.722980	test: 0.665515
PRC train: 0.798818	val: 0.599849	test: 0.539914

Epoch: 74
Loss: 0.1432885735556082
ROC train: 0.945958	val: 0.713245	test: 0.679421
PRC train: 0.804172	val: 0.596207	test: 0.540016

Epoch: 75
Loss: 0.14631107075588062
ROC train: 0.947652	val: 0.710200	test: 0.684892
PRC train: 0.808129	val: 0.592154	test: 0.537475

Epoch: 76
Loss: 0.1848460446455747
ROC train: 0.951115	val: 0.716319	test: 0.695470
PRC train: 0.814967	val: 0.591893	test: 0.545378

Epoch: 77
Loss: 0.1706675612610868
ROC train: 0.943075	val: 0.743253	test: 0.684370
PRC train: 0.788652	val: 0.600967	test: 0.554417

Epoch: 78
Loss: 0.15940281962464542
ROC train: 0.950216	val: 0.736862	test: 0.673338
PRC train: 0.807835	val: 0.612590	test: 0.541203

Epoch: 79
Loss: 0.26332869685315236
ROC train: 0.953679	val: 0.746868	test: 0.688021
PRC train: 0.815521	val: 0.615464	test: 0.543914

Epoch: 80
Loss: 0.21666776665191728
ROC train: 0.939675	val: 0.759548	test: 0.731445
PRC train: 0.791670	val: 0.611009	test: 0.562897

Epoch: 81
Loss: 0.14546724543699607
ROC train: 0.940715	val: 0.722820	test: 0.719254
PRC train: 0.786906	val: 0.614912	test: 0.545078

Epoch: 82
Loss: 0.15790458413232802
ROC train: 0.934170	val: 0.684236	test: 0.684070
PRC train: 0.788389	val: 0.598728	test: 0.534494

Epoch: 83
Loss: 0.1568867317406581
ROC train: 0.942853	val: 0.695268	test: 0.688259
PRC train: 0.800289	val: 0.608097	test: 0.535653

Epoch: 84
Loss: 0.1561774480430998
ROC train: 0.953224	val: 0.722809	test: 0.715975
PRC train: 0.816716	val: 0.633501	test: 0.545982

Epoch: 85
Loss: 0.14204368436584033
ROC train: 0.956094	val: 0.725012	test: 0.733282
PRC train: 0.826714	val: 0.619718	test: 0.549044

Epoch: 86
Loss: 0.15599544917292113
ROC train: 0.957337	val: 0.716802	test: 0.728883
PRC train: 0.827036	val: 0.609164	test: 0.545842

Epoch: 87
Loss: 0.2321496035606312
ROC train: 0.955136	val: 0.708685	test: 0.685348
PRC train: 0.819657	val: 0.607794	test: 0.530861

Epoch: 88
Loss: 0.1665973651951808
ROC train: 0.948977	val: 0.704839	test: 0.671984
PRC train: 0.811212	val: 0.610051	test: 0.529335

Epoch: 89
Loss: 0.1398581628066884
ROC train: 0.947240	val: 0.702264	test: 0.678248
PRC train: 0.807562	val: 0.594163	test: 0.530892

Epoch: 90
Loss: 0.22137686122641992
ROC train: 0.945709	val: 0.712380	test: 0.716916
PRC train: 0.812990	val: 0.599613	test: 0.545526

Epoch: 91
Loss: 0.15717363128628087
ROC train: 0.935898	val: 0.704418	test: 0.745641
PRC train: 0.797980	val: 0.606289	test: 0.562128

Epoch: 92
Loss: 0.30296951787659576
ROC train: 0.935053	val: 0.708986	test: 0.752245
PRC train: 0.789458	val: 0.604370	test: 0.567537

Epoch: 93
Loss: 0.18256031235082046
ROC train: 0.923011	val: 0.730384	test: 0.702426
PRC train: 0.771770	val: 0.615652	test: 0.555993

Epoch: 94
Loss: 0.20905351986699133
ROC train: 0.965134	val: 0.830965	test: 0.807364
PRC train: 0.856197	val: 0.642348	test: 0.583831

Epoch: 34
Loss: 0.14752422529920228
ROC train: 0.967957	val: 0.805056	test: 0.791523
PRC train: 0.857426	val: 0.640297	test: 0.578540

Epoch: 35
Loss: 0.15304138592128808
ROC train: 0.965026	val: 0.853030	test: 0.773485
PRC train: 0.846767	val: 0.666742	test: 0.570405

Epoch: 36
Loss: 0.1435859055626898
ROC train: 0.965008	val: 0.835811	test: 0.803980
PRC train: 0.851311	val: 0.648043	test: 0.584977

Epoch: 37
Loss: 0.14439193004039033
ROC train: 0.967005	val: 0.817668	test: 0.807801
PRC train: 0.859154	val: 0.634251	test: 0.587035

Epoch: 38
Loss: 0.1483193799463447
ROC train: 0.970850	val: 0.842404	test: 0.806733
PRC train: 0.865781	val: 0.628604	test: 0.598813

Epoch: 39
Loss: 0.15133640202221493
ROC train: 0.969728	val: 0.847299	test: 0.775323
PRC train: 0.857136	val: 0.612672	test: 0.579942

Epoch: 40
Loss: 0.13948308757251854
ROC train: 0.971706	val: 0.813571	test: 0.824584
PRC train: 0.873250	val: 0.611440	test: 0.596806

Epoch: 41
Loss: 0.1462233992089255
ROC train: 0.974428	val: 0.839269	test: 0.805414
PRC train: 0.881161	val: 0.604645	test: 0.588580

Epoch: 42
Loss: 0.13944403895099783
ROC train: 0.969425	val: 0.881825	test: 0.793648
PRC train: 0.863106	val: 0.612461	test: 0.581791

Epoch: 43
Loss: 0.15196090842564086
ROC train: 0.970189	val: 0.883673	test: 0.790525
PRC train: 0.865227	val: 0.648718	test: 0.592356

Epoch: 44
Loss: 0.14096294644876947
ROC train: 0.970073	val: 0.842892	test: 0.810337
PRC train: 0.854594	val: 0.597659	test: 0.601206

Epoch: 45
Loss: 0.1462814821077812
ROC train: 0.970099	val: 0.847387	test: 0.809445
PRC train: 0.852839	val: 0.594309	test: 0.588270

Epoch: 46
Loss: 0.13310523307635425
ROC train: 0.975916	val: 0.826945	test: 0.842905
PRC train: 0.878249	val: 0.609579	test: 0.604727

Epoch: 47
Loss: 0.13729464714321724
ROC train: 0.977076	val: 0.789172	test: 0.838083
PRC train: 0.883714	val: 0.608735	test: 0.615057

Epoch: 48
Loss: 0.14921461193224483
ROC train: 0.976716	val: 0.790146	test: 0.828158
PRC train: 0.880620	val: 0.615218	test: 0.614738

Epoch: 49
Loss: 0.1380164592919106
ROC train: 0.974546	val: 0.816280	test: 0.835184
PRC train: 0.883282	val: 0.634780	test: 0.625037

Epoch: 50
Loss: 0.1336283779349733
ROC train: 0.972590	val: 0.832975	test: 0.827421
PRC train: 0.882330	val: 0.622482	test: 0.630354

Epoch: 51
Loss: 0.12783141377442236
ROC train: 0.974935	val: 0.789197	test: 0.827901
PRC train: 0.885670	val: 0.615793	test: 0.622075

Epoch: 52
Loss: 0.12869636781430452
ROC train: 0.977585	val: 0.762950	test: 0.838606
PRC train: 0.893737	val: 0.610303	test: 0.629872

Epoch: 53
Loss: 0.1313097993130114
ROC train: 0.977045	val: 0.821576	test: 0.821767
PRC train: 0.896427	val: 0.624632	test: 0.632301

Epoch: 54
Loss: 0.12965393723197827
ROC train: 0.974512	val: 0.862982	test: 0.806352
PRC train: 0.881459	val: 0.617206	test: 0.616793

Epoch: 55
Loss: 0.13403516992072953
ROC train: 0.978224	val: 0.829605	test: 0.812448
PRC train: 0.893746	val: 0.615963	test: 0.624611

Epoch: 56
Loss: 0.13014908859294236
ROC train: 0.979432	val: 0.787138	test: 0.817457
PRC train: 0.897181	val: 0.641908	test: 0.633075

Epoch: 57
Loss: 0.12267820261039264
ROC train: 0.979926	val: 0.799437	test: 0.818294
PRC train: 0.896984	val: 0.627180	test: 0.626456

Epoch: 58
Loss: 0.144483177134974
ROC train: 0.979091	val: 0.825859	test: 0.830624
PRC train: 0.890871	val: 0.612638	test: 0.630169

Epoch: 59
Loss: 0.13129348795549503
ROC train: 0.979373	val: 0.797701	test: 0.833097
PRC train: 0.895509	val: 0.613929	test: 0.629430

Epoch: 60
Loss: 0.11993406946185092
ROC train: 0.979590	val: 0.821302	test: 0.821992
PRC train: 0.896877	val: 0.607304	test: 0.626314

Epoch: 61
Loss: 0.12277756541129606
ROC train: 0.980984	val: 0.820328	test: 0.828737
PRC train: 0.898996	val: 0.607249	test: 0.633273

Epoch: 62
Loss: 0.11515029202283307
ROC train: 0.982838	val: 0.808704	test: 0.835270
PRC train: 0.904443	val: 0.600928	test: 0.637306

Epoch: 63
Loss: 0.1159526018329931
ROC train: 0.982055	val: 0.801349	test: 0.854152
PRC train: 0.903158	val: 0.641686	test: 0.642707

Epoch: 64
Loss: 0.12977535890200875
ROC train: 0.981857	val: 0.824524	test: 0.857294
PRC train: 0.903510	val: 0.614561	test: 0.666744

Epoch: 65
Loss: 0.12647430759450767
ROC train: 0.981580	val: 0.819766	test: 0.811036
PRC train: 0.911084	val: 0.689068	test: 0.629163

Epoch: 66
Loss: 0.12558906327866243
ROC train: 0.979982	val: 0.849284	test: 0.826351
PRC train: 0.902534	val: 0.713890	test: 0.634095

Epoch: 67
Loss: 0.12959727655226566
ROC train: 0.982122	val: 0.858463	test: 0.845076
PRC train: 0.903150	val: 0.634242	test: 0.650783

Epoch: 68
Loss: 0.11836904825986287
ROC train: 0.974753	val: 0.825111	test: 0.792386
PRC train: 0.882676	val: 0.596702	test: 0.608380

Epoch: 69
Loss: 0.12565266806051148
ROC train: 0.978110	val: 0.862796	test: 0.821992
PRC train: 0.894648	val: 0.620937	test: 0.646198

Epoch: 70
Loss: 0.12104812384032551
ROC train: 0.982783	val: 0.793119	test: 0.851747
PRC train: 0.906458	val: 0.590370	test: 0.661471

Epoch: 71
Loss: 0.1163002719095613
ROC train: 0.982771	val: 0.730160	test: 0.840941
PRC train: 0.908533	val: 0.575720	test: 0.658870

Epoch: 72
Loss: 0.11539790891084718
ROC train: 0.983302	val: 0.799124	test: 0.858243
PRC train: 0.908960	val: 0.633863	test: 0.680948

Epoch: 73
Loss: 0.11616169801758713
ROC train: 0.983605	val: 0.872298	test: 0.855744
PRC train: 0.912422	val: 0.639005	test: 0.684573

Epoch: 74
Loss: 0.11189942710563558
ROC train: 0.984009	val: 0.832989	test: 0.814233
PRC train: 0.914705	val: 0.633037	test: 0.642131

Epoch: 75
Loss: 0.11360004442575637
ROC train: 0.983608	val: 0.825884	test: 0.836619
PRC train: 0.913351	val: 0.664723	test: 0.659052

Epoch: 76
Loss: 0.1305878407624514
ROC train: 0.984618	val: 0.827170	test: 0.842965
PRC train: 0.915367	val: 0.621124	test: 0.657091

Epoch: 77
Loss: 0.11333213477852407
ROC train: 0.983928	val: 0.810201	test: 0.883777
PRC train: 0.911322	val: 0.626482	test: 0.696885

Epoch: 78
Loss: 0.1065470147793125
ROC train: 0.983907	val: 0.814509	test: 0.876743
PRC train: 0.916920	val: 0.630836	test: 0.704763

Epoch: 79
Loss: 0.11291473475198263
ROC train: 0.984712	val: 0.828681	test: 0.822578
PRC train: 0.918572	val: 0.625682	test: 0.657747

Epoch: 80
Loss: 0.11309947395286005
ROC train: 0.984633	val: 0.818417	test: 0.808306
PRC train: 0.916147	val: 0.595374	test: 0.655789

Epoch: 81
Loss: 0.1060136185238986
ROC train: 0.984748	val: 0.821551	test: 0.820117
PRC train: 0.917147	val: 0.598368	test: 0.654560

Epoch: 82
Loss: 0.10627859241239275
ROC train: 0.985799	val: 0.812998	test: 0.845300
PRC train: 0.921167	val: 0.598151	test: 0.664203

Epoch: 83
Loss: 0.11158437852211493
ROC train: 0.986129	val: 0.804244	test: 0.868186
PRC train: 0.922672	val: 0.595815	test: 0.684291

Epoch: 84
Loss: 0.09929005183351826
ROC train: 0.985453	val: 0.796689	test: 0.881177
PRC train: 0.915864	val: 0.633062	test: 0.700954

Epoch: 85
Loss: 0.10846378442765148
ROC train: 0.985802	val: 0.766521	test: 0.872220
PRC train: 0.921619	val: 0.631595	test: 0.699873

Epoch: 86
Loss: 0.10860695189802157
ROC train: 0.986180	val: 0.769992	test: 0.866636
PRC train: 0.927440	val: 0.631991	test: 0.690056

Epoch: 87
Loss: 0.11589501588382825
ROC train: 0.986241	val: 0.758730	test: 0.870009
PRC train: 0.923564	val: 0.618983	test: 0.698778

Epoch: 88
Loss: 0.10923650253640442
ROC train: 0.986645	val: 0.776936	test: 0.870733
PRC train: 0.922455	val: 0.576070	test: 0.730866

Epoch: 89
Loss: 0.11086309293263577
ROC train: 0.985732	val: 0.785739	test: 0.844426
PRC train: 0.920505	val: 0.578163	test: 0.685188

Epoch: 90
Loss: 0.10782219220754692
ROC train: 0.986336	val: 0.764187	test: 0.852389
PRC train: 0.923971	val: 0.581361	test: 0.684522

Epoch: 91
Loss: 0.11134445234239994
ROC train: 0.986085	val: 0.711167	test: 0.842790
PRC train: 0.924939	val: 0.578555	test: 0.669780

Epoch: 92
Loss: 0.10517678557820376
ROC train: 0.985184	val: 0.667350	test: 0.842427
PRC train: 0.918467	val: 0.608247	test: 0.667574

Epoch: 93
Loss: 0.10379781131915689
ROC train: 0.986852	val: 0.737751	test: 0.846349
PRC train: 0.924910	val: 0.618293	test: 0.688825

Epoch: 94
Loss: 0.10684821368258943
ROC train: 0.959946	val: 0.834325	test: 0.779458
PRC train: 0.832959	val: 0.601478	test: 0.567384

Epoch: 34
Loss: 0.15736255831700227
ROC train: 0.956236	val: 0.858013	test: 0.751144
PRC train: 0.815984	val: 0.571347	test: 0.562006

Epoch: 35
Loss: 0.15619571397438983
ROC train: 0.963426	val: 0.795666	test: 0.770538
PRC train: 0.846930	val: 0.578621	test: 0.568552

Epoch: 36
Loss: 0.1593386968775546
ROC train: 0.967007	val: 0.797676	test: 0.786566
PRC train: 0.859854	val: 0.594942	test: 0.583320

Epoch: 37
Loss: 0.1554443753070473
ROC train: 0.967145	val: 0.808328	test: 0.787408
PRC train: 0.862158	val: 0.579898	test: 0.574844

Epoch: 38
Loss: 0.1490409431934195
ROC train: 0.967746	val: 0.818554	test: 0.790962
PRC train: 0.865405	val: 0.588935	test: 0.576811

Epoch: 39
Loss: 0.15182467985292164
ROC train: 0.969914	val: 0.801310	test: 0.769331
PRC train: 0.862599	val: 0.572699	test: 0.568186

Epoch: 40
Loss: 0.15970957513293713
ROC train: 0.958575	val: 0.808166	test: 0.688560
PRC train: 0.833437	val: 0.559224	test: 0.550706

Epoch: 41
Loss: 0.15588731927371674
ROC train: 0.967088	val: 0.843078	test: 0.710426
PRC train: 0.853871	val: 0.593745	test: 0.572735

Epoch: 42
Loss: 0.14809113784836445
ROC train: 0.973333	val: 0.786038	test: 0.769500
PRC train: 0.870192	val: 0.564157	test: 0.578871

Epoch: 43
Loss: 0.14526193036171656
ROC train: 0.973691	val: 0.770105	test: 0.771599
PRC train: 0.875688	val: 0.569058	test: 0.583818

Epoch: 44
Loss: 0.14792393812109975
ROC train: 0.973980	val: 0.825547	test: 0.805420
PRC train: 0.873697	val: 0.587386	test: 0.592895

Epoch: 45
Loss: 0.15074146963097595
ROC train: 0.973922	val: 0.819791	test: 0.797880
PRC train: 0.867064	val: 0.572255	test: 0.583425

Epoch: 46
Loss: 0.13836485965258621
ROC train: 0.972904	val: 0.833826	test: 0.776470
PRC train: 0.864004	val: 0.581301	test: 0.575460

Epoch: 47
Loss: 0.13292708359984087
ROC train: 0.974001	val: 0.815458	test: 0.794507
PRC train: 0.876365	val: 0.594085	test: 0.597324

Epoch: 48
Loss: 0.13852172391699416
ROC train: 0.974957	val: 0.821801	test: 0.807911
PRC train: 0.878068	val: 0.643424	test: 0.598115

Epoch: 49
Loss: 0.13881017986861918
ROC train: 0.974324	val: 0.831528	test: 0.796031
PRC train: 0.874740	val: 0.604136	test: 0.587203

Epoch: 50
Loss: 0.13513877790685438
ROC train: 0.974927	val: 0.874695	test: 0.808287
PRC train: 0.875480	val: 0.643353	test: 0.617016

Epoch: 51
Loss: 0.14125543338116492
ROC train: 0.976482	val: 0.825821	test: 0.822896
PRC train: 0.884439	val: 0.605788	test: 0.615410

Epoch: 52
Loss: 0.13103399241034272
ROC train: 0.968221	val: 0.761738	test: 0.802759
PRC train: 0.869570	val: 0.573633	test: 0.605164

Epoch: 53
Loss: 0.14151372891613415
ROC train: 0.972938	val: 0.787760	test: 0.797406
PRC train: 0.877186	val: 0.606190	test: 0.594892

Epoch: 54
Loss: 0.13511099850858338
ROC train: 0.973647	val: 0.787623	test: 0.781654
PRC train: 0.877476	val: 0.614764	test: 0.588673

Epoch: 55
Loss: 0.12988312630633475
ROC train: 0.974596	val: 0.787573	test: 0.765690
PRC train: 0.880765	val: 0.595091	test: 0.580615

Epoch: 56
Loss: 0.12462058277642134
ROC train: 0.975348	val: 0.742309	test: 0.780642
PRC train: 0.878497	val: 0.578481	test: 0.608897

Epoch: 57
Loss: 0.12963424821310904
ROC train: 0.977101	val: 0.806753	test: 0.793977
PRC train: 0.889081	val: 0.599342	test: 0.616778

Epoch: 58
Loss: 0.134781408399503
ROC train: 0.978902	val: 0.841817	test: 0.783552
PRC train: 0.893560	val: 0.613416	test: 0.604890

Epoch: 59
Loss: 0.12450450567414284
ROC train: 0.972486	val: 0.881688	test: 0.749355
PRC train: 0.875214	val: 0.606777	test: 0.571950

Epoch: 60
Loss: 0.14286024100687267
ROC train: 0.977317	val: 0.874695	test: 0.759754
PRC train: 0.893564	val: 0.636279	test: 0.579602

Epoch: 61
Loss: 0.11751214488736828
ROC train: 0.978587	val: 0.826446	test: 0.789323
PRC train: 0.891383	val: 0.617158	test: 0.591566

Epoch: 62
Loss: 0.12276041744976232
ROC train: 0.979013	val: 0.769181	test: 0.802277
PRC train: 0.890345	val: 0.603375	test: 0.592299

Epoch: 63
Loss: 0.13493312090670567
ROC train: 0.979967	val: 0.769205	test: 0.803864
PRC train: 0.894935	val: 0.599133	test: 0.600771

Epoch: 64
Loss: 0.11227568406511206
ROC train: 0.980987	val: 0.777759	test: 0.807824
PRC train: 0.896375	val: 0.604889	test: 0.607265

Epoch: 65
Loss: 0.1206610725578974
ROC train: 0.979627	val: 0.841093	test: 0.789573
PRC train: 0.892615	val: 0.614105	test: 0.607341

Epoch: 66
Loss: 0.13747405917917616
ROC train: 0.981019	val: 0.796464	test: 0.783615
PRC train: 0.900537	val: 0.602418	test: 0.617624

Epoch: 67
Loss: 0.14046358331941
ROC train: 0.980168	val: 0.755694	test: 0.805713
PRC train: 0.897730	val: 0.617623	test: 0.631659

Epoch: 68
Loss: 0.13208945924971385
ROC train: 0.980597	val: 0.752960	test: 0.784814
PRC train: 0.900231	val: 0.574721	test: 0.636479

Epoch: 69
Loss: 0.11712353948654304
ROC train: 0.979470	val: 0.824422	test: 0.777344
PRC train: 0.900429	val: 0.615038	test: 0.608299

Epoch: 70
Loss: 0.11304284384552818
ROC train: 0.979943	val: 0.865217	test: 0.794758
PRC train: 0.897083	val: 0.615613	test: 0.606980

Epoch: 71
Loss: 0.12534139526075652
ROC train: 0.981548	val: 0.825160	test: 0.801253
PRC train: 0.901242	val: 0.607147	test: 0.627803

Epoch: 72
Loss: 0.13483800996837197
ROC train: 0.981098	val: 0.819116	test: 0.821827
PRC train: 0.897308	val: 0.595111	test: 0.635618

Epoch: 73
Loss: 0.12736369986708684
ROC train: 0.979958	val: 0.824260	test: 0.809598
PRC train: 0.898249	val: 0.598978	test: 0.634542

Epoch: 74
Loss: 0.11967531246233923
ROC train: 0.979885	val: 0.784815	test: 0.784814
PRC train: 0.896945	val: 0.600369	test: 0.657795

Epoch: 75
Loss: 0.1359404737582644
ROC train: 0.981248	val: 0.738176	test: 0.773747
PRC train: 0.901895	val: 0.588925	test: 0.646497

Epoch: 76
Loss: 0.12023586808233208
ROC train: 0.979951	val: 0.757855	test: 0.778431
PRC train: 0.897627	val: 0.601830	test: 0.640234

Epoch: 77
Loss: 0.11969920394779492
ROC train: 0.981904	val: 0.782815	test: 0.783477
PRC train: 0.906552	val: 0.624567	test: 0.619139

Epoch: 78
Loss: 0.1252425325162141
ROC train: 0.981622	val: 0.805580	test: 0.778431
PRC train: 0.903216	val: 0.620627	test: 0.609650

Epoch: 79
Loss: 0.12438639066325238
ROC train: 0.983298	val: 0.782654	test: 0.792221
PRC train: 0.907485	val: 0.627257	test: 0.613787

Epoch: 80
Loss: 0.12692815065137447
ROC train: 0.982919	val: 0.798450	test: 0.803764
PRC train: 0.909464	val: 0.633163	test: 0.641413

Epoch: 81
Loss: 0.11871527935882978
ROC train: 0.983222	val: 0.811311	test: 0.791078
PRC train: 0.909625	val: 0.629426	test: 0.630417

Epoch: 82
Loss: 0.12075530110970593
ROC train: 0.984092	val: 0.790708	test: 0.784015
PRC train: 0.911452	val: 0.624867	test: 0.628730

Epoch: 83
Loss: 0.11613120749870129
ROC train: 0.985028	val: 0.785451	test: 0.776488
PRC train: 0.915178	val: 0.609525	test: 0.629791

Epoch: 84
Loss: 0.1236543251306474
ROC train: 0.985378	val: 0.791432	test: 0.778393
PRC train: 0.917529	val: 0.598336	test: 0.633093

Epoch: 85
Loss: 0.11661582931551491
ROC train: 0.983555	val: 0.765371	test: 0.790585
PRC train: 0.906259	val: 0.595742	test: 0.637179

Epoch: 86
Loss: 0.1237811338401111
ROC train: 0.984081	val: 0.743820	test: 0.793708
PRC train: 0.912490	val: 0.581227	test: 0.638893

Epoch: 87
Loss: 0.10392880563952456
ROC train: 0.983203	val: 0.729285	test: 0.791560
PRC train: 0.912596	val: 0.576339	test: 0.631719

Epoch: 88
Loss: 0.12484759489551238
ROC train: 0.984219	val: 0.694021	test: 0.801029
PRC train: 0.911520	val: 0.611720	test: 0.641350

Epoch: 89
Loss: 0.11134571051517832
ROC train: 0.982947	val: 0.667061	test: 0.836862
PRC train: 0.903269	val: 0.617324	test: 0.666040

Epoch: 90
Loss: 0.11629484047844214
ROC train: 0.983011	val: 0.685679	test: 0.845987
PRC train: 0.908182	val: 0.636594	test: 0.697086

Epoch: 91
Loss: 0.1111406599356084
ROC train: 0.985123	val: 0.729633	test: 0.838223
PRC train: 0.917827	val: 0.648798	test: 0.667332

Epoch: 92
Loss: 0.10739237415382674
ROC train: 0.986012	val: 0.757655	test: 0.810573
PRC train: 0.923750	val: 0.612775	test: 0.653637

Epoch: 93
Loss: 0.11104104071915095
ROC train: 0.985526	val: 0.804743	test: 0.802297
PRC train: 0.920421	val: 0.617868	test: 0.633225

Epoch: 94
Loss: 0.10214316224940863
ROC train: 0.963268	val: 0.756804	test: 0.770452
PRC train: 0.829400	val: 0.587575	test: 0.587109

Epoch: 34
Loss: 0.1524060811204742
ROC train: 0.964205	val: 0.771201	test: 0.781658
PRC train: 0.841105	val: 0.620887	test: 0.594414

Epoch: 35
Loss: 0.1618388512013516
ROC train: 0.963996	val: 0.760677	test: 0.739083
PRC train: 0.841183	val: 0.566829	test: 0.575385

Epoch: 36
Loss: 0.15333668377301857
ROC train: 0.969834	val: 0.788210	test: 0.778427
PRC train: 0.858569	val: 0.593263	test: 0.621895

Epoch: 37
Loss: 0.14871836392836363
ROC train: 0.967940	val: 0.800822	test: 0.758413
PRC train: 0.860766	val: 0.599399	test: 0.590408

Epoch: 38
Loss: 0.15240543265216666
ROC train: 0.964128	val: 0.809213	test: 0.749239
PRC train: 0.838190	val: 0.573788	test: 0.580877

Epoch: 39
Loss: 0.1493968893818717
ROC train: 0.961971	val: 0.773187	test: 0.775188
PRC train: 0.851224	val: 0.582003	test: 0.587389

Epoch: 40
Loss: 0.14115496637246233
ROC train: 0.962992	val: 0.808876	test: 0.774082
PRC train: 0.855607	val: 0.594091	test: 0.575666

Epoch: 41
Loss: 0.15218711333397475
ROC train: 0.966624	val: 0.805717	test: 0.785767
PRC train: 0.850749	val: 0.585016	test: 0.575290

Epoch: 42
Loss: 0.13598326718314785
ROC train: 0.972229	val: 0.793628	test: 0.805392
PRC train: 0.870351	val: 0.605843	test: 0.583090

Epoch: 43
Loss: 0.13647076005922812
ROC train: 0.975538	val: 0.780317	test: 0.800981
PRC train: 0.877515	val: 0.614853	test: 0.582641

Epoch: 44
Loss: 0.13529077532938938
ROC train: 0.970730	val: 0.801883	test: 0.771561
PRC train: 0.858465	val: 0.606259	test: 0.582752

Epoch: 45
Loss: 0.13847465598101436
ROC train: 0.974761	val: 0.819077	test: 0.818880
PRC train: 0.878439	val: 0.622160	test: 0.606379

Epoch: 46
Loss: 0.1400737342376377
ROC train: 0.971279	val: 0.829904	test: 0.792023
PRC train: 0.864547	val: 0.635613	test: 0.585362

Epoch: 47
Loss: 0.12632256721887103
ROC train: 0.973554	val: 0.846311	test: 0.789401
PRC train: 0.863982	val: 0.667909	test: 0.579016

Epoch: 48
Loss: 0.1352913738411923
ROC train: 0.976131	val: 0.830765	test: 0.810162
PRC train: 0.874459	val: 0.679288	test: 0.591501

Epoch: 49
Loss: 0.12850884970835563
ROC train: 0.975233	val: 0.815444	test: 0.801630
PRC train: 0.866092	val: 0.637212	test: 0.596076

Epoch: 50
Loss: 0.13211806388634023
ROC train: 0.976493	val: 0.809600	test: 0.805003
PRC train: 0.875258	val: 0.610234	test: 0.591306

Epoch: 51
Loss: 0.13114094573506732
ROC train: 0.978372	val: 0.801746	test: 0.804985
PRC train: 0.886634	val: 0.604676	test: 0.595715

Epoch: 52
Loss: 0.14467624840220203
ROC train: 0.977318	val: 0.815194	test: 0.799221
PRC train: 0.882125	val: 0.592462	test: 0.590749

Epoch: 53
Loss: 0.13013692561630638
ROC train: 0.971529	val: 0.834961	test: 0.791638
PRC train: 0.858215	val: 0.581052	test: 0.589422

Epoch: 54
Loss: 0.13495676224616995
ROC train: 0.974833	val: 0.816006	test: 0.819676
PRC train: 0.882910	val: 0.603607	test: 0.599483

Epoch: 55
Loss: 0.12781848043802257
ROC train: 0.976818	val: 0.806778	test: 0.839331
PRC train: 0.883648	val: 0.600704	test: 0.611068

Epoch: 56
Loss: 0.13126513916818247
ROC train: 0.976442	val: 0.797638	test: 0.836145
PRC train: 0.879604	val: 0.561691	test: 0.622142

Epoch: 57
Loss: 0.13213878886935537
ROC train: 0.977774	val: 0.787436	test: 0.828013
PRC train: 0.884112	val: 0.568390	test: 0.629726

Epoch: 58
Loss: 0.12902333282915585
ROC train: 0.978722	val: 0.790195	test: 0.836933
PRC train: 0.884647	val: 0.578059	test: 0.627736

Epoch: 59
Loss: 0.12343042483945701
ROC train: 0.978536	val: 0.850532	test: 0.826515
PRC train: 0.888094	val: 0.605449	test: 0.610136

Epoch: 60
Loss: 0.12437268453702419
ROC train: 0.978234	val: 0.843876	test: 0.808302
PRC train: 0.900803	val: 0.654363	test: 0.608836

Epoch: 61
Loss: 0.13452690240331613
ROC train: 0.976387	val: 0.821063	test: 0.771864
PRC train: 0.890754	val: 0.650508	test: 0.591679

Epoch: 62
Loss: 0.133128556936955
ROC train: 0.975038	val: 0.795227	test: 0.783294
PRC train: 0.887748	val: 0.631063	test: 0.593800

Epoch: 63
Loss: 0.1193295625880662
ROC train: 0.977726	val: 0.750486	test: 0.801769
PRC train: 0.889012	val: 0.587729	test: 0.610102

Epoch: 64
Loss: 0.13069221104265927
ROC train: 0.975704	val: 0.736475	test: 0.780283
PRC train: 0.876412	val: 0.576994	test: 0.595707

Epoch: 65
Loss: 0.12650797410132514
ROC train: 0.979209	val: 0.784713	test: 0.811462
PRC train: 0.892772	val: 0.600907	test: 0.609808

Epoch: 66
Loss: 0.12967274694026304
ROC train: 0.979503	val: 0.805204	test: 0.808208
PRC train: 0.893393	val: 0.627787	test: 0.602467

Epoch: 67
Loss: 0.12465771798238989
ROC train: 0.980742	val: 0.790831	test: 0.802531
PRC train: 0.898657	val: 0.604707	test: 0.597853

Epoch: 68
Loss: 0.11043628507975004
ROC train: 0.980701	val: 0.785075	test: 0.805754
PRC train: 0.900289	val: 0.603209	test: 0.601603

Epoch: 69
Loss: 0.12325495469376788
ROC train: 0.981065	val: 0.755181	test: 0.819395
PRC train: 0.898493	val: 0.585947	test: 0.609696

Epoch: 70
Loss: 0.1376352452100973
ROC train: 0.979199	val: 0.771764	test: 0.790912
PRC train: 0.885518	val: 0.586204	test: 0.602416

Epoch: 71
Loss: 0.11861691211099694
ROC train: 0.982706	val: 0.772663	test: 0.798418
PRC train: 0.906985	val: 0.597661	test: 0.614141

Epoch: 72
Loss: 0.11822370733598501
ROC train: 0.983671	val: 0.781828	test: 0.821360
PRC train: 0.912188	val: 0.602437	test: 0.623936

Epoch: 73
Loss: 0.11964691479978258
ROC train: 0.982839	val: 0.813483	test: 0.820292
PRC train: 0.908846	val: 0.609706	test: 0.618695

Epoch: 74
Loss: 0.11842687704914816
ROC train: 0.982152	val: 0.806690	test: 0.823590
PRC train: 0.905385	val: 0.601753	test: 0.615493

Epoch: 75
Loss: 0.12661929424055116
ROC train: 0.978804	val: 0.774610	test: 0.815795
PRC train: 0.887820	val: 0.603363	test: 0.610750

Epoch: 76
Loss: 0.1223329966225227
ROC train: 0.980138	val: 0.784674	test: 0.831136
PRC train: 0.901465	val: 0.651544	test: 0.622263

Epoch: 77
Loss: 0.1139350346896986
ROC train: 0.982879	val: 0.818090	test: 0.842155
PRC train: 0.904870	val: 0.685471	test: 0.615581

Epoch: 78
Loss: 0.11193518900483372
ROC train: 0.981781	val: 0.819488	test: 0.840156
PRC train: 0.900080	val: 0.673918	test: 0.608522

Epoch: 79
Loss: 0.11461027769040177
ROC train: 0.981912	val: 0.826506	test: 0.844579
PRC train: 0.903298	val: 0.670753	test: 0.614141

Epoch: 80
Loss: 0.1254996038471881
ROC train: 0.982526	val: 0.819601	test: 0.852647
PRC train: 0.904013	val: 0.680185	test: 0.614303

Epoch: 81
Loss: 0.10184692591077557
ROC train: 0.983264	val: 0.804142	test: 0.844990
PRC train: 0.904441	val: 0.657585	test: 0.628820

Epoch: 82
Loss: 0.11477665696375143
ROC train: 0.982731	val: 0.813146	test: 0.843626
PRC train: 0.904960	val: 0.641962	test: 0.613428

Epoch: 83
Loss: 0.10306946764486843
ROC train: 0.981126	val: 0.814544	test: 0.831647
PRC train: 0.898970	val: 0.629439	test: 0.602418

Epoch: 84
Loss: 0.11270345829361003
ROC train: 0.982200	val: 0.781828	test: 0.839854
PRC train: 0.904918	val: 0.658856	test: 0.610021

Epoch: 85
Loss: 0.11396533075940987
ROC train: 0.982784	val: 0.768605	test: 0.822797
PRC train: 0.909572	val: 0.613167	test: 0.611690

Epoch: 86
Loss: 0.10899529321340395
ROC train: 0.981880	val: 0.769191	test: 0.811148
PRC train: 0.907551	val: 0.615834	test: 0.610627

Epoch: 87
Loss: 0.1043374459583977
ROC train: 0.981263	val: 0.757440	test: 0.821741
PRC train: 0.896931	val: 0.625411	test: 0.615434

Epoch: 88
Loss: 0.10573117947588422
ROC train: 0.982634	val: 0.778356	test: 0.810980
PRC train: 0.902302	val: 0.623908	test: 0.594860

Epoch: 89
Loss: 0.1137145086885331
ROC train: 0.983283	val: 0.811884	test: 0.812511
PRC train: 0.909209	val: 0.622446	test: 0.601185

Epoch: 90
Loss: 0.11541409816862218
ROC train: 0.984459	val: 0.814931	test: 0.822492
PRC train: 0.915427	val: 0.627432	test: 0.605453

Epoch: 91
Loss: 0.11689381139314284
ROC train: 0.984300	val: 0.783251	test: 0.828850
PRC train: 0.917537	val: 0.629255	test: 0.607867

Epoch: 92
Loss: 0.10291657537169216
ROC train: 0.983250	val: 0.774923	test: 0.819205
PRC train: 0.912988	val: 0.604432	test: 0.617439

Epoch: 93
Loss: 0.10315634605943928
ROC train: 0.986053	val: 0.760687	test: 0.833571
PRC train: 0.924782	val: 0.613572	test: 0.620797

Epoch: 94
Loss: 0.11076039636295101
ROC train: 0.981855	val: 0.687572	test: 0.728671
PRC train: 0.905667	val: 0.581026	test: 0.576334

Epoch: 95
Loss: 0.10746395166161679
ROC train: 0.982283	val: 0.685349	test: 0.719730
PRC train: 0.908605	val: 0.570237	test: 0.578579

Epoch: 96
Loss: 0.112613329902013
ROC train: 0.983186	val: 0.688807	test: 0.734731
PRC train: 0.906166	val: 0.574992	test: 0.600997

Epoch: 97
Loss: 0.11394919097070019
ROC train: 0.982511	val: 0.687674	test: 0.738297
PRC train: 0.904074	val: 0.579652	test: 0.602607

Epoch: 98
Loss: 0.11691949276586208
ROC train: 0.982359	val: 0.680800	test: 0.758914
PRC train: 0.905360	val: 0.577238	test: 0.616288

Epoch: 99
Loss: 0.10551001663998741
ROC train: 0.982781	val: 0.678421	test: 0.762906
PRC train: 0.907305	val: 0.575022	test: 0.616704

Epoch: 100
Loss: 0.09979083638054873
ROC train: 0.983511	val: 0.680976	test: 0.774146
PRC train: 0.909932	val: 0.574407	test: 0.611384

Epoch: 101
Loss: 0.11121970059901364
ROC train: 0.983194	val: 0.682455	test: 0.758489
PRC train: 0.909065	val: 0.569610	test: 0.604186

Epoch: 102
Loss: 0.11770354402126651
ROC train: 0.982896	val: 0.677801	test: 0.754134
PRC train: 0.910623	val: 0.564578	test: 0.595322

Epoch: 103
Loss: 0.10404156562631717
ROC train: 0.984402	val: 0.675686	test: 0.761490
PRC train: 0.914538	val: 0.564724	test: 0.596166

Epoch: 104
Loss: 0.10131508684203522
ROC train: 0.984436	val: 0.672803	test: 0.764904
PRC train: 0.911597	val: 0.563615	test: 0.594590

Epoch: 105
Loss: 0.1106463401886874
ROC train: 0.984248	val: 0.665881	test: 0.772764
PRC train: 0.908267	val: 0.562487	test: 0.592844

Epoch: 106
Loss: 0.10453285852744408
ROC train: 0.984123	val: 0.657189	test: 0.772157
PRC train: 0.913021	val: 0.557447	test: 0.587640

Epoch: 107
Loss: 0.10681655470804968
ROC train: 0.984418	val: 0.655072	test: 0.756322
PRC train: 0.918181	val: 0.560017	test: 0.582838

Epoch: 108
Loss: 0.12183492025426493
ROC train: 0.985345	val: 0.668712	test: 0.754631
PRC train: 0.924371	val: 0.566532	test: 0.597061

Epoch: 109
Loss: 0.09101039193100853
ROC train: 0.985576	val: 0.682344	test: 0.755003
PRC train: 0.920613	val: 0.575437	test: 0.626012

Epoch: 110
Loss: 0.11396434873415578
ROC train: 0.985566	val: 0.687702	test: 0.759545
PRC train: 0.916665	val: 0.580708	test: 0.630869

Epoch: 111
Loss: 0.11167448474366921
ROC train: 0.985338	val: 0.669760	test: 0.769895
PRC train: 0.918251	val: 0.576171	test: 0.613236

Epoch: 112
Loss: 0.10569918013369112
ROC train: 0.984519	val: 0.664297	test: 0.782617
PRC train: 0.912872	val: 0.567570	test: 0.589664

Epoch: 113
Loss: 0.11108139202253842
ROC train: 0.985570	val: 0.667266	test: 0.801838
PRC train: 0.920357	val: 0.567522	test: 0.608334

Epoch: 114
Loss: 0.11131851447683164
ROC train: 0.985764	val: 0.673686	test: 0.809558
PRC train: 0.920172	val: 0.566267	test: 0.612541

Epoch: 115
Loss: 0.10126453081139354
ROC train: 0.984606	val: 0.681076	test: 0.799998
PRC train: 0.913268	val: 0.566975	test: 0.640677

Epoch: 116
Loss: 0.10117894524888965
ROC train: 0.984807	val: 0.681114	test: 0.801227
PRC train: 0.913080	val: 0.566694	test: 0.644465

Epoch: 117
Loss: 0.10056351723576828
ROC train: 0.985242	val: 0.670308	test: 0.797135
PRC train: 0.915378	val: 0.565429	test: 0.623142

Epoch: 118
Loss: 0.10166114317801114
ROC train: 0.985593	val: 0.652600	test: 0.784990
PRC train: 0.916363	val: 0.561404	test: 0.609206

Epoch: 119
Loss: 0.09497963353211064
ROC train: 0.986310	val: 0.660185	test: 0.777354
PRC train: 0.920956	val: 0.561720	test: 0.626198

Epoch: 120
Loss: 0.10040230080801335
ROC train: 0.985882	val: 0.664740	test: 0.768345
PRC train: 0.922924	val: 0.562398	test: 0.629880

Early stopping
Best (ROC):	 train: 0.950804	val: 0.703161	test: 0.715769
Best (PRC):	 train: 0.826397	val: 0.564832	test: 0.572773

ROC train: 0.983841	val: 0.660227	test: 0.775668
PRC train: 0.914045	val: 0.559042	test: 0.586256

Epoch: 95
Loss: 0.11496976963126132
ROC train: 0.985305	val: 0.655803	test: 0.789554
PRC train: 0.924413	val: 0.556784	test: 0.590527

Epoch: 96
Loss: 0.10877336741641286
ROC train: 0.986903	val: 0.636328	test: 0.791538
PRC train: 0.933006	val: 0.550027	test: 0.581000

Epoch: 97
Loss: 0.0992847299511179
ROC train: 0.986280	val: 0.645463	test: 0.801624
PRC train: 0.926974	val: 0.554652	test: 0.587763

Epoch: 98
Loss: 0.10598253693238988
ROC train: 0.984552	val: 0.658936	test: 0.802665
PRC train: 0.916734	val: 0.563550	test: 0.604261

Epoch: 99
Loss: 0.1044279587348792
ROC train: 0.985337	val: 0.654956	test: 0.801626
PRC train: 0.920828	val: 0.559679	test: 0.598407

Epoch: 100
Loss: 0.11144809121237378
ROC train: 0.984486	val: 0.647533	test: 0.785175
PRC train: 0.919579	val: 0.557711	test: 0.583031

Epoch: 101
Loss: 0.11220433892067173
ROC train: 0.986459	val: 0.658221	test: 0.788924
PRC train: 0.927551	val: 0.559378	test: 0.595005

Epoch: 102
Loss: 0.10561908355080196
ROC train: 0.985614	val: 0.662991	test: 0.801287
PRC train: 0.920132	val: 0.562511	test: 0.616951

Epoch: 103
Loss: 0.10643991819986842
ROC train: 0.986077	val: 0.654526	test: 0.806281
PRC train: 0.923262	val: 0.562651	test: 0.608154

Epoch: 104
Loss: 0.09952994528170103
ROC train: 0.985763	val: 0.645704	test: 0.799844
PRC train: 0.921475	val: 0.558040	test: 0.612059

Epoch: 105
Loss: 0.09661667065777939
ROC train: 0.984943	val: 0.641687	test: 0.808950
PRC train: 0.915887	val: 0.557412	test: 0.615473

Epoch: 106
Loss: 0.10636856357321343
ROC train: 0.985757	val: 0.633614	test: 0.801068
PRC train: 0.922389	val: 0.552623	test: 0.611371

Epoch: 107
Loss: 0.09449205884518155
ROC train: 0.987174	val: 0.639553	test: 0.809407
PRC train: 0.929609	val: 0.555954	test: 0.615480

Epoch: 108
Loss: 0.09874947567546266
ROC train: 0.987015	val: 0.669837	test: 0.803329
PRC train: 0.927763	val: 0.564029	test: 0.628322

Epoch: 109
Loss: 0.09354376072463669
ROC train: 0.985913	val: 0.684451	test: 0.792995
PRC train: 0.922988	val: 0.567356	test: 0.635044

Epoch: 110
Loss: 0.10088222438743183
ROC train: 0.986035	val: 0.679170	test: 0.784219
PRC train: 0.923201	val: 0.565887	test: 0.627317

Epoch: 111
Loss: 0.11416967882062173
ROC train: 0.986566	val: 0.663408	test: 0.786980
PRC train: 0.928719	val: 0.562931	test: 0.621668

Epoch: 112
Loss: 0.09736708225036551
ROC train: 0.986803	val: 0.658292	test: 0.790073
PRC train: 0.929202	val: 0.565850	test: 0.616611

Epoch: 113
Loss: 0.10724275315657587
ROC train: 0.987419	val: 0.657475	test: 0.792997
PRC train: 0.931179	val: 0.561425	test: 0.616803

Epoch: 114
Loss: 0.09552772263349263
ROC train: 0.987155	val: 0.663482	test: 0.796034
PRC train: 0.927150	val: 0.562511	test: 0.618042

Epoch: 115
Loss: 0.11064024113668189
ROC train: 0.986481	val: 0.671383	test: 0.799168
PRC train: 0.923258	val: 0.565447	test: 0.624137

Epoch: 116
Loss: 0.1058530139419
ROC train: 0.987408	val: 0.660592	test: 0.802415
PRC train: 0.931585	val: 0.563352	test: 0.618969

Epoch: 117
Loss: 0.11238708320588398
ROC train: 0.987563	val: 0.652541	test: 0.801507
PRC train: 0.932597	val: 0.561299	test: 0.615053

Epoch: 118
Loss: 0.10362853637503407
ROC train: 0.987776	val: 0.649242	test: 0.787721
PRC train: 0.935106	val: 0.564111	test: 0.616887

Epoch: 119
Loss: 0.09778177206069291
ROC train: 0.986625	val: 0.663869	test: 0.788962
PRC train: 0.924554	val: 0.566436	test: 0.631428

Epoch: 120
Loss: 0.09104635674303338
ROC train: 0.987174	val: 0.669947	test: 0.786448
PRC train: 0.926923	val: 0.564246	test: 0.631705

Early stopping
Best (ROC):	 train: 0.935186	val: 0.690564	test: 0.718725
Best (PRC):	 train: 0.775491	val: 0.554813	test: 0.559212

ROC train: 0.985511	val: 0.699113	test: 0.777244
PRC train: 0.918196	val: 0.567850	test: 0.617243

Epoch: 95
Loss: 0.11142431718094085
ROC train: 0.985668	val: 0.704773	test: 0.777942
PRC train: 0.917063	val: 0.564723	test: 0.607398

Epoch: 96
Loss: 0.1041200749851666
ROC train: 0.986125	val: 0.706197	test: 0.779054
PRC train: 0.921032	val: 0.569613	test: 0.603337

Epoch: 97
Loss: 0.10737281926087078
ROC train: 0.985509	val: 0.705153	test: 0.777513
PRC train: 0.917380	val: 0.569706	test: 0.602807

Epoch: 98
Loss: 0.10763666409214129
ROC train: 0.983395	val: 0.698400	test: 0.778167
PRC train: 0.912765	val: 0.560892	test: 0.604617

Epoch: 99
Loss: 0.10216635873601068
ROC train: 0.984614	val: 0.703076	test: 0.787337
PRC train: 0.915719	val: 0.562578	test: 0.613984

Epoch: 100
Loss: 0.10997062894259602
ROC train: 0.984911	val: 0.702086	test: 0.795490
PRC train: 0.916211	val: 0.569842	test: 0.624077

Epoch: 101
Loss: 0.10342780886982175
ROC train: 0.986401	val: 0.696103	test: 0.783373
PRC train: 0.923047	val: 0.567011	test: 0.610845

Epoch: 102
Loss: 0.09572819136272949
ROC train: 0.986648	val: 0.689061	test: 0.758206
PRC train: 0.925097	val: 0.562912	test: 0.592392

Epoch: 103
Loss: 0.1288860003975305
ROC train: 0.985756	val: 0.691159	test: 0.752364
PRC train: 0.918621	val: 0.564373	test: 0.589570

Epoch: 104
Loss: 0.10213054664686058
ROC train: 0.983641	val: 0.698961	test: 0.782102
PRC train: 0.908963	val: 0.569061	test: 0.602152

Epoch: 105
Loss: 0.10590093736372333
ROC train: 0.983747	val: 0.697395	test: 0.807704
PRC train: 0.912554	val: 0.565651	test: 0.619898

Epoch: 106
Loss: 0.10987181819300423
ROC train: 0.985546	val: 0.690239	test: 0.801071
PRC train: 0.921873	val: 0.560460	test: 0.604491

Epoch: 107
Loss: 0.10303538786435193
ROC train: 0.985098	val: 0.689331	test: 0.787287
PRC train: 0.922805	val: 0.558374	test: 0.595940

Epoch: 108
Loss: 0.09931186409248122
ROC train: 0.984158	val: 0.705141	test: 0.794113
PRC train: 0.915564	val: 0.569490	test: 0.604286

Epoch: 109
Loss: 0.09819257959244601
ROC train: 0.985075	val: 0.714686	test: 0.798296
PRC train: 0.918121	val: 0.577415	test: 0.626999

Epoch: 110
Loss: 0.11362178558089571
ROC train: 0.985929	val: 0.719530	test: 0.791551
PRC train: 0.920646	val: 0.582282	test: 0.626503

Epoch: 111
Loss: 0.10502667666843107
ROC train: 0.986798	val: 0.713388	test: 0.792099
PRC train: 0.925531	val: 0.572902	test: 0.618379

Epoch: 112
Loss: 0.10389903134046309
ROC train: 0.987325	val: 0.707719	test: 0.788589
PRC train: 0.930830	val: 0.571610	test: 0.617715

Epoch: 113
Loss: 0.10505682338059902
ROC train: 0.986748	val: 0.709381	test: 0.792815
PRC train: 0.927764	val: 0.570016	test: 0.621557

Epoch: 114
Loss: 0.09745192352076298
ROC train: 0.987488	val: 0.703863	test: 0.787647
PRC train: 0.931237	val: 0.568167	test: 0.624177

Epoch: 115
Loss: 0.1018624682059788
ROC train: 0.987291	val: 0.703617	test: 0.781080
PRC train: 0.929641	val: 0.567508	test: 0.618102

Epoch: 116
Loss: 0.09934069039823303
ROC train: 0.986856	val: 0.711355	test: 0.776171
PRC train: 0.928712	val: 0.570907	test: 0.622891

Epoch: 117
Loss: 0.11257378203153874
ROC train: 0.986817	val: 0.712016	test: 0.772133
PRC train: 0.927646	val: 0.571126	test: 0.625324

Epoch: 118
Loss: 0.10126934954790584
ROC train: 0.986421	val: 0.713190	test: 0.777531
PRC train: 0.923685	val: 0.569308	test: 0.630829

Epoch: 119
Loss: 0.10759192641517099
ROC train: 0.987643	val: 0.697141	test: 0.777891
PRC train: 0.932839	val: 0.565924	test: 0.607475

Epoch: 120
Loss: 0.09610897547484869
ROC train: 0.987611	val: 0.693114	test: 0.778786
PRC train: 0.932945	val: 0.563120	test: 0.602068

Early stopping
Best (ROC):	 train: 0.963850	val: 0.729539	test: 0.710347
Best (PRC):	 train: 0.854498	val: 0.575278	test: 0.573941
All runs completed.

ROC train: 0.950212	val: 0.778829	test: 0.694121
PRC train: 0.815101	val: 0.658061	test: 0.542830

Epoch: 95
Loss: 0.1492234556665036
ROC train: 0.948716	val: 0.781702	test: 0.692256
PRC train: 0.812538	val: 0.660994	test: 0.546079

Epoch: 96
Loss: 0.1418763900002113
ROC train: 0.956314	val: 0.780043	test: 0.696590
PRC train: 0.822862	val: 0.652528	test: 0.544334

Epoch: 97
Loss: 0.15204529535170516
ROC train: 0.959259	val: 0.772811	test: 0.690844
PRC train: 0.830142	val: 0.637509	test: 0.539805

Epoch: 98
Loss: 0.12478843362619094
ROC train: 0.957310	val: 0.770002	test: 0.693494
PRC train: 0.829382	val: 0.616866	test: 0.540453

Epoch: 99
Loss: 0.1497416699105409
ROC train: 0.959112	val: 0.766499	test: 0.694560
PRC train: 0.832859	val: 0.606729	test: 0.540508

Epoch: 100
Loss: 0.14695060761026446
ROC train: 0.955899	val: 0.750077	test: 0.671020
PRC train: 0.829908	val: 0.615649	test: 0.532897

Epoch: 101
Loss: 0.208249251882321
ROC train: 0.956091	val: 0.758596	test: 0.702091
PRC train: 0.828315	val: 0.622392	test: 0.539845

Epoch: 102
Loss: 0.1441396115574545
ROC train: 0.948220	val: 0.760961	test: 0.733809
PRC train: 0.814256	val: 0.613521	test: 0.548548

Epoch: 103
Loss: 0.1356500081870669
ROC train: 0.953434	val: 0.773618	test: 0.739909
PRC train: 0.833430	val: 0.626393	test: 0.550501

Epoch: 104
Loss: 0.12782176303564177
ROC train: 0.953367	val: 0.763377	test: 0.680453
PRC train: 0.834240	val: 0.611976	test: 0.537698

Epoch: 105
Loss: 0.14202408000023753
ROC train: 0.953242	val: 0.759501	test: 0.666366
PRC train: 0.837625	val: 0.604743	test: 0.533261

Epoch: 106
Loss: 0.148529930773955
ROC train: 0.963033	val: 0.761568	test: 0.674829
PRC train: 0.845878	val: 0.614115	test: 0.534126

Epoch: 107
Loss: 0.15258968904189565
ROC train: 0.968030	val: 0.756528	test: 0.686955
PRC train: 0.849196	val: 0.614689	test: 0.540077

Epoch: 108
Loss: 0.12454255711181447
ROC train: 0.963883	val: 0.740023	test: 0.708568
PRC train: 0.838032	val: 0.604197	test: 0.547484

Epoch: 109
Loss: 0.11878339028399532
ROC train: 0.966518	val: 0.739873	test: 0.704489
PRC train: 0.837774	val: 0.603538	test: 0.547789

Epoch: 110
Loss: 0.14058448415522684
ROC train: 0.966494	val: 0.743872	test: 0.692108
PRC train: 0.837732	val: 0.607527	test: 0.545139

Epoch: 111
Loss: 0.1555190401343982
ROC train: 0.967780	val: 0.750002	test: 0.674568
PRC train: 0.843106	val: 0.599602	test: 0.542332

Epoch: 112
Loss: 0.13371930751712435
ROC train: 0.969009	val: 0.747712	test: 0.615651
PRC train: 0.852979	val: 0.604901	test: 0.525536

Epoch: 113
Loss: 0.13779343456082072
ROC train: 0.968569	val: 0.736642	test: 0.587651
PRC train: 0.853680	val: 0.604496	test: 0.521693

Epoch: 114
Loss: 0.13241149951200512
ROC train: 0.964150	val: 0.746088	test: 0.592147
PRC train: 0.847505	val: 0.615345	test: 0.523998

Epoch: 115
Loss: 0.12166799427609816
ROC train: 0.966457	val: 0.757590	test: 0.634041
PRC train: 0.851867	val: 0.618657	test: 0.534276

Epoch: 116
Loss: 0.11824163734902204
ROC train: 0.967832	val: 0.758445	test: 0.676643
PRC train: 0.853551	val: 0.604554	test: 0.544749

Epoch: 117
Loss: 0.12012264133612893
ROC train: 0.968113	val: 0.748689	test: 0.704586
PRC train: 0.854914	val: 0.599121	test: 0.553222

Epoch: 118
Loss: 0.1582188649073934
ROC train: 0.969788	val: 0.752022	test: 0.713327
PRC train: 0.859155	val: 0.597699	test: 0.554495

Epoch: 119
Loss: 0.1303919899050839
ROC train: 0.967776	val: 0.755885	test: 0.701581
PRC train: 0.855394	val: 0.599805	test: 0.541164

Epoch: 120
Loss: 0.1610297872728003
ROC train: 0.965427	val: 0.759872	test: 0.687159
PRC train: 0.841141	val: 0.598948	test: 0.537435

Early stopping
Best (ROC):	 train: 0.947381	val: 0.792926	test: 0.664869
Best (PRC):	 train: 0.809753	val: 0.620155	test: 0.531405

ROC train: 0.942025	val: 0.720081	test: 0.698854
PRC train: 0.798709	val: 0.612165	test: 0.551670

Epoch: 95
Loss: 0.22037862481870857
ROC train: 0.948116	val: 0.683800	test: 0.642743
PRC train: 0.789998	val: 0.595787	test: 0.526809

Epoch: 96
Loss: 0.20487154466783583
ROC train: 0.947669	val: 0.691540	test: 0.667443
PRC train: 0.790985	val: 0.594490	test: 0.530285

Epoch: 97
Loss: 0.17764307052076067
ROC train: 0.936271	val: 0.722869	test: 0.705810
PRC train: 0.764499	val: 0.602578	test: 0.540430

Epoch: 98
Loss: 0.17379751709734498
ROC train: 0.925101	val: 0.757725	test: 0.676683
PRC train: 0.758653	val: 0.613797	test: 0.548836

Epoch: 99
Loss: 0.19777568933732798
ROC train: 0.944775	val: 0.756661	test: 0.685113
PRC train: 0.790475	val: 0.606953	test: 0.552350

Epoch: 100
Loss: 0.18307692511673168
ROC train: 0.947918	val: 0.729271	test: 0.692616
PRC train: 0.807038	val: 0.601875	test: 0.542267

Epoch: 101
Loss: 0.1431166564773564
ROC train: 0.937518	val: 0.704554	test: 0.676020
PRC train: 0.791303	val: 0.590521	test: 0.538499

Epoch: 102
Loss: 0.13495256770532765
ROC train: 0.934560	val: 0.705036	test: 0.664432
PRC train: 0.787759	val: 0.591950	test: 0.534142

Epoch: 103
Loss: 0.13351803329649914
ROC train: 0.939277	val: 0.705197	test: 0.675005
PRC train: 0.797420	val: 0.595936	test: 0.536883

Epoch: 104
Loss: 0.25064117601608044
ROC train: 0.947128	val: 0.716379	test: 0.678534
PRC train: 0.824184	val: 0.606390	test: 0.537632

Epoch: 105
Loss: 0.14342600727942922
ROC train: 0.936715	val: 0.709917	test: 0.704090
PRC train: 0.811275	val: 0.576692	test: 0.537862

Epoch: 106
Loss: 0.13801689946622173
ROC train: 0.933383	val: 0.716009	test: 0.716933
PRC train: 0.803117	val: 0.576841	test: 0.545971

Epoch: 107
Loss: 0.14861056331910585
ROC train: 0.937679	val: 0.723401	test: 0.730034
PRC train: 0.811127	val: 0.581224	test: 0.565539

Epoch: 108
Loss: 0.2057743779351015
ROC train: 0.945030	val: 0.730879	test: 0.718188
PRC train: 0.817137	val: 0.587582	test: 0.582710

Epoch: 109
Loss: 0.24193594244789068
ROC train: 0.953469	val: 0.729146	test: 0.717585
PRC train: 0.825958	val: 0.586357	test: 0.573104

Epoch: 110
Loss: 0.18223926157926612
ROC train: 0.953877	val: 0.711255	test: 0.697080
PRC train: 0.821425	val: 0.575848	test: 0.544726

Epoch: 111
Loss: 0.14968528920916385
ROC train: 0.943057	val: 0.699381	test: 0.665660
PRC train: 0.787939	val: 0.563364	test: 0.533259

Epoch: 112
Loss: 0.16946016423758983
ROC train: 0.955059	val: 0.704086	test: 0.677775
PRC train: 0.807466	val: 0.576907	test: 0.535909

Epoch: 113
Loss: 0.12957531378186576
ROC train: 0.962957	val: 0.725310	test: 0.706754
PRC train: 0.827859	val: 0.589885	test: 0.539202

Epoch: 114
Loss: 0.17278551280004062
ROC train: 0.960480	val: 0.726646	test: 0.715697
PRC train: 0.829363	val: 0.586332	test: 0.541727

Epoch: 115
Loss: 0.13768772778150146
ROC train: 0.953238	val: 0.712753	test: 0.712965
PRC train: 0.821582	val: 0.572137	test: 0.543797

Epoch: 116
Loss: 0.13151868044321743
ROC train: 0.951590	val: 0.702698	test: 0.710133
PRC train: 0.818963	val: 0.568078	test: 0.541605

Epoch: 117
Loss: 0.15360741395215177
ROC train: 0.957894	val: 0.707019	test: 0.705510
PRC train: 0.830468	val: 0.573385	test: 0.542606

Epoch: 118
Loss: 0.12716209699437273
ROC train: 0.961355	val: 0.710944	test: 0.707109
PRC train: 0.836080	val: 0.576664	test: 0.542471

Epoch: 119
Loss: 0.22966941037192962
ROC train: 0.963450	val: 0.719972	test: 0.712681
PRC train: 0.840224	val: 0.579609	test: 0.545962

Epoch: 120
Loss: 0.15778824417808224
ROC train: 0.956687	val: 0.733396	test: 0.709864
PRC train: 0.824666	val: 0.588603	test: 0.552415

Early stopping
Best (ROC):	 train: 0.939675	val: 0.759548	test: 0.731445
Best (PRC):	 train: 0.791670	val: 0.611009	test: 0.562897

ROC train: 0.952014	val: 0.761123	test: 0.718325
PRC train: 0.810493	val: 0.601348	test: 0.571475

Epoch: 95
Loss: 0.15277324521338903
ROC train: 0.956300	val: 0.757680	test: 0.736006
PRC train: 0.830485	val: 0.608673	test: 0.585374

Epoch: 96
Loss: 0.16325194244232125
ROC train: 0.958182	val: 0.732208	test: 0.736729
PRC train: 0.836202	val: 0.590476	test: 0.580609

Epoch: 97
Loss: 0.1350652152236205
ROC train: 0.956857	val: 0.705360	test: 0.721003
PRC train: 0.828516	val: 0.581351	test: 0.567726

Epoch: 98
Loss: 0.19507657601924427
ROC train: 0.958835	val: 0.690721	test: 0.722208
PRC train: 0.831759	val: 0.575097	test: 0.564517

Epoch: 99
Loss: 0.12294137942010241
ROC train: 0.954654	val: 0.673348	test: 0.728844
PRC train: 0.820286	val: 0.571970	test: 0.567591

Epoch: 100
Loss: 0.15530323230694357
ROC train: 0.955159	val: 0.667650	test: 0.747631
PRC train: 0.824575	val: 0.578715	test: 0.595340

Epoch: 101
Loss: 0.20657458764350003
ROC train: 0.951829	val: 0.683860	test: 0.759572
PRC train: 0.819371	val: 0.597511	test: 0.604581

Epoch: 102
Loss: 0.14179239775798042
ROC train: 0.944852	val: 0.697754	test: 0.762534
PRC train: 0.810931	val: 0.614154	test: 0.589208

Epoch: 103
Loss: 0.13327096711461633
ROC train: 0.946026	val: 0.722025	test: 0.749405
PRC train: 0.814093	val: 0.612585	test: 0.607248

Epoch: 104
Loss: 0.14175155034317807
ROC train: 0.951807	val: 0.728675	test: 0.739320
PRC train: 0.825727	val: 0.610300	test: 0.600046

Epoch: 105
Loss: 0.1228105325375708
ROC train: 0.957594	val: 0.731981	test: 0.729705
PRC train: 0.840453	val: 0.611922	test: 0.575702

Epoch: 106
Loss: 0.20719625732539132
ROC train: 0.962641	val: 0.729721	test: 0.728322
PRC train: 0.851726	val: 0.617868	test: 0.567909

Epoch: 107
Loss: 0.1191718932636654
ROC train: 0.963922	val: 0.732564	test: 0.735828
PRC train: 0.848713	val: 0.608148	test: 0.572163

Epoch: 108
Loss: 0.14569745047984298
ROC train: 0.965067	val: 0.734632	test: 0.732457
PRC train: 0.850416	val: 0.604810	test: 0.572912

Epoch: 109
Loss: 0.17043841534558074
ROC train: 0.962092	val: 0.738879	test: 0.716663
PRC train: 0.841862	val: 0.605076	test: 0.576148

Epoch: 110
Loss: 0.13363469474763381
ROC train: 0.963499	val: 0.735833	test: 0.711014
PRC train: 0.851652	val: 0.611345	test: 0.579113

Epoch: 111
Loss: 0.16047825611991334
ROC train: 0.965082	val: 0.735821	test: 0.727522
PRC train: 0.858411	val: 0.623077	test: 0.579564

Epoch: 112
Loss: 0.1172748703332623
ROC train: 0.963251	val: 0.730819	test: 0.747443
PRC train: 0.857855	val: 0.607052	test: 0.591703

Epoch: 113
Loss: 0.23730417099158058
ROC train: 0.961838	val: 0.724825	test: 0.739872
PRC train: 0.852819	val: 0.600584	test: 0.578966

Epoch: 114
Loss: 0.1292157672564562
ROC train: 0.952053	val: 0.710597	test: 0.733713
PRC train: 0.835154	val: 0.598439	test: 0.592124

Epoch: 115
Loss: 0.13707904167769644
ROC train: 0.949294	val: 0.680209	test: 0.710606
PRC train: 0.827898	val: 0.588198	test: 0.579183

Epoch: 116
Loss: 0.1827422713034691
ROC train: 0.948295	val: 0.659531	test: 0.685209
PRC train: 0.823573	val: 0.574226	test: 0.561981

Epoch: 117
Loss: 0.11935182043691324
ROC train: 0.934252	val: 0.636414	test: 0.679342
PRC train: 0.812351	val: 0.571238	test: 0.577307

Epoch: 118
Loss: 0.12337174289343793
ROC train: 0.939161	val: 0.637082	test: 0.701916
PRC train: 0.815111	val: 0.571269	test: 0.583743

Epoch: 119
Loss: 0.12504978479107684
ROC train: 0.950546	val: 0.650864	test: 0.721831
PRC train: 0.828873	val: 0.576532	test: 0.593069

Epoch: 120
Loss: 0.13229350836655435
ROC train: 0.961854	val: 0.666131	test: 0.729014
PRC train: 0.852865	val: 0.588308	test: 0.606249

Epoch: 121
Loss: 0.1176395725486344
ROC train: 0.966968	val: 0.677685	test: 0.740329
PRC train: 0.856525	val: 0.595709	test: 0.626955

Epoch: 122
Loss: 0.12314602639597667
ROC train: 0.969077	val: 0.689559	test: 0.744779
PRC train: 0.857369	val: 0.600755	test: 0.630414

Epoch: 123
Loss: 0.11209143042874911
ROC train: 0.969398	val: 0.682142	test: 0.740635
PRC train: 0.864385	val: 0.603431	test: 0.625144

Epoch: 124
Loss: 0.15061880140037506
ROC train: 0.970205	val: 0.686005	test: 0.737203
PRC train: 0.870459	val: 0.603638	test: 0.608499

Epoch: 125
Loss: 0.1152405366645399
ROC train: 0.965353	val: 0.674079	test: 0.746729
PRC train: 0.863033	val: 0.595815	test: 0.602179

Epoch: 126
Loss: 0.16592937038621303
ROC train: 0.964747	val: 0.660011	test: 0.748606
PRC train: 0.863074	val: 0.588215	test: 0.607675

Epoch: 127
Loss: 0.1906069825362983
ROC train: 0.960855	val: 0.655394	test: 0.751741
PRC train: 0.842642	val: 0.580473	test: 0.598165

Epoch: 128
Loss: 0.12754633447268898
ROC train: 0.957160	val: 0.660694	test: 0.777841
PRC train: 0.838767	val: 0.590583	test: 0.609338

Epoch: 129
Loss: 0.15607883801569633
ROC train: 0.961396	val: 0.659392	test: 0.761200
PRC train: 0.852289	val: 0.595018	test: 0.603482

Early stopping
Best (ROC):	 train: 0.952014	val: 0.761123	test: 0.718325
Best (PRC):	 train: 0.810493	val: 0.601348	test: 0.571475

ROC train: 0.985687	val: 0.784365	test: 0.821047
PRC train: 0.924963	val: 0.621402	test: 0.673208

Epoch: 95
Loss: 0.10371884558326969
ROC train: 0.986214	val: 0.777910	test: 0.825738
PRC train: 0.926230	val: 0.580377	test: 0.655113

Epoch: 96
Loss: 0.10267680546694398
ROC train: 0.986170	val: 0.772927	test: 0.843301
PRC train: 0.921461	val: 0.580748	test: 0.668251

Epoch: 97
Loss: 0.10341663702734945
ROC train: 0.986534	val: 0.713876	test: 0.842726
PRC train: 0.923633	val: 0.610426	test: 0.674580

Epoch: 98
Loss: 0.10639207027431714
ROC train: 0.986466	val: 0.713627	test: 0.849666
PRC train: 0.923143	val: 0.610163	test: 0.678434

Epoch: 99
Loss: 0.10442425147670646
ROC train: 0.987146	val: 0.765523	test: 0.848960
PRC train: 0.929112	val: 0.618314	test: 0.670973

Epoch: 100
Loss: 0.10100419125485456
ROC train: 0.986933	val: 0.787099	test: 0.839491
PRC train: 0.926117	val: 0.580637	test: 0.654177

Epoch: 101
Loss: 0.09658844856599433
ROC train: 0.986830	val: 0.816143	test: 0.866124
PRC train: 0.925465	val: 0.626363	test: 0.671421

Epoch: 102
Loss: 0.10808314796243797
ROC train: 0.987536	val: 0.811599	test: 0.870946
PRC train: 0.930373	val: 0.624577	test: 0.678453

Epoch: 103
Loss: 0.1090230064120649
ROC train: 0.986549	val: 0.767884	test: 0.872145
PRC train: 0.926878	val: 0.619609	test: 0.704146

Epoch: 104
Loss: 0.1037785909882808
ROC train: 0.985332	val: 0.740000	test: 0.856255
PRC train: 0.922037	val: 0.575339	test: 0.677137

Epoch: 105
Loss: 0.10290630293559758
ROC train: 0.985102	val: 0.770579	test: 0.864507
PRC train: 0.917072	val: 0.584776	test: 0.677439

Epoch: 106
Loss: 0.09909857266672117
ROC train: 0.986999	val: 0.745780	test: 0.873120
PRC train: 0.926890	val: 0.570709	test: 0.681058

Epoch: 107
Loss: 0.11447729225818155
ROC train: 0.986922	val: 0.711304	test: 0.882589
PRC train: 0.925236	val: 0.566114	test: 0.696180

Epoch: 108
Loss: 0.10417017760441816
ROC train: 0.987682	val: 0.695283	test: 0.857204
PRC train: 0.931496	val: 0.571026	test: 0.675389

Epoch: 109
Loss: 0.10227398886730447
ROC train: 0.987234	val: 0.697044	test: 0.853394
PRC train: 0.929487	val: 0.612907	test: 0.677819

Epoch: 110
Loss: 0.09562279202369714
ROC train: 0.987621	val: 0.777685	test: 0.869859
PRC train: 0.929397	val: 0.578481	test: 0.697458

Epoch: 111
Loss: 0.10415929481984823
ROC train: 0.987338	val: 0.842829	test: 0.850021
PRC train: 0.930318	val: 0.589105	test: 0.668352

Epoch: 112
Loss: 0.1029773939602417
ROC train: 0.986977	val: 0.837909	test: 0.811708
PRC train: 0.932496	val: 0.586541	test: 0.641219

Epoch: 113
Loss: 0.10921044663856105
ROC train: 0.987132	val: 0.768882	test: 0.833433
PRC train: 0.929010	val: 0.577514	test: 0.654487

Epoch: 114
Loss: 0.10200927737869563
ROC train: 0.987408	val: 0.727251	test: 0.849110
PRC train: 0.929241	val: 0.575416	test: 0.660620

Epoch: 115
Loss: 0.10066244802138413
ROC train: 0.987505	val: 0.732195	test: 0.841340
PRC train: 0.929953	val: 0.579322	test: 0.653732

Epoch: 116
Loss: 0.09854021684471662
ROC train: 0.987922	val: 0.813672	test: 0.865325
PRC train: 0.931944	val: 0.588811	test: 0.672069

Epoch: 117
Loss: 0.09313362404767891
ROC train: 0.987455	val: 0.817306	test: 0.879709
PRC train: 0.931519	val: 0.588464	test: 0.709689

Epoch: 118
Loss: 0.09558733031962162
ROC train: 0.988151	val: 0.801985	test: 0.880415
PRC train: 0.934584	val: 0.592193	test: 0.705123

Epoch: 119
Loss: 0.1002082389307302
ROC train: 0.988074	val: 0.798439	test: 0.861115
PRC train: 0.934565	val: 0.591442	test: 0.691118

Epoch: 120
Loss: 0.09098140355600629
ROC train: 0.987228	val: 0.811687	test: 0.841527
PRC train: 0.928959	val: 0.591450	test: 0.674249

Early stopping
Best (ROC):	 train: 0.937311	val: 0.889566	test: 0.705521
Best (PRC):	 train: 0.791273	val: 0.625189	test: 0.547485

ROC train: 0.985591	val: 0.804381	test: 0.809904
PRC train: 0.923848	val: 0.613444	test: 0.627739

Epoch: 95
Loss: 0.10795141948580222
ROC train: 0.985296	val: 0.764985	test: 0.832327
PRC train: 0.919645	val: 0.599607	test: 0.653692

Epoch: 96
Loss: 0.09869485574193554
ROC train: 0.983305	val: 0.774912	test: 0.831352
PRC train: 0.914530	val: 0.640475	test: 0.637583

Epoch: 97
Loss: 0.10485002409014779
ROC train: 0.985740	val: 0.757855	test: 0.815081
PRC train: 0.921408	val: 0.639901	test: 0.642427

Epoch: 98
Loss: 0.11717193081613915
ROC train: 0.985591	val: 0.735677	test: 0.812833
PRC train: 0.918284	val: 0.634584	test: 0.648046

Epoch: 99
Loss: 0.10351731218372551
ROC train: 0.985757	val: 0.773925	test: 0.797918
PRC train: 0.919941	val: 0.652407	test: 0.629091

Epoch: 100
Loss: 0.10484890459149235
ROC train: 0.985771	val: 0.773426	test: 0.791672
PRC train: 0.919671	val: 0.649876	test: 0.618912

Epoch: 101
Loss: 0.11511158293362037
ROC train: 0.985824	val: 0.763498	test: 0.815657
PRC train: 0.915878	val: 0.648761	test: 0.655447

Epoch: 102
Loss: 0.10345002689272456
ROC train: 0.986202	val: 0.745517	test: 0.832746
PRC train: 0.916929	val: 0.636378	test: 0.671449

Epoch: 103
Loss: 0.10182491856915014
ROC train: 0.987824	val: 0.772839	test: 0.823090
PRC train: 0.927797	val: 0.638577	test: 0.678773

Epoch: 104
Loss: 0.10518331776505445
ROC train: 0.986601	val: 0.809413	test: 0.806576
PRC train: 0.922921	val: 0.610775	test: 0.668073

Epoch: 105
Loss: 0.11633609833124121
ROC train: 0.985031	val: 0.817130	test: 0.811798
PRC train: 0.914063	val: 0.610695	test: 0.651507

Epoch: 106
Loss: 0.1025733398509964
ROC train: 0.986675	val: 0.820539	test: 0.808492
PRC train: 0.923154	val: 0.631270	test: 0.650230

Epoch: 107
Loss: 0.10423649485850209
ROC train: 0.986599	val: 0.810724	test: 0.797062
PRC train: 0.925426	val: 0.620742	test: 0.643803

Epoch: 108
Loss: 0.11090174794796974
ROC train: 0.987310	val: 0.774150	test: 0.794108
PRC train: 0.930338	val: 0.638919	test: 0.644983

Epoch: 109
Loss: 0.10306154345771176
ROC train: 0.987496	val: 0.759665	test: 0.802090
PRC train: 0.930965	val: 0.632474	test: 0.673586

Epoch: 110
Loss: 0.09932009492100005
ROC train: 0.987345	val: 0.730420	test: 0.791635
PRC train: 0.927159	val: 0.588167	test: 0.676111

Epoch: 111
Loss: 0.09600493671143448
ROC train: 0.986806	val: 0.743507	test: 0.809236
PRC train: 0.923999	val: 0.633783	test: 0.672220

Epoch: 112
Loss: 0.10454208029697734
ROC train: 0.987518	val: 0.802308	test: 0.819679
PRC train: 0.930146	val: 0.639864	test: 0.672700

Epoch: 113
Loss: 0.10134010267162989
ROC train: 0.986379	val: 0.810861	test: 0.818817
PRC train: 0.925554	val: 0.617495	test: 0.638272

Epoch: 114
Loss: 0.10632449783033723
ROC train: 0.986866	val: 0.794391	test: 0.826911
PRC train: 0.928068	val: 0.624189	test: 0.645123

Epoch: 115
Loss: 0.09934138373077805
ROC train: 0.986443	val: 0.791706	test: 0.829197
PRC train: 0.930948	val: 0.631519	test: 0.656498

Epoch: 116
Loss: 0.11156703404120145
ROC train: 0.986427	val: 0.765983	test: 0.813046
PRC train: 0.928067	val: 0.602667	test: 0.670436

Epoch: 117
Loss: 0.1030090618209186
ROC train: 0.986635	val: 0.751111	test: 0.839279
PRC train: 0.924968	val: 0.587376	test: 0.677745

Epoch: 118
Loss: 0.09277578068727568
ROC train: 0.987175	val: 0.789647	test: 0.836574
PRC train: 0.930993	val: 0.585394	test: 0.656409

Epoch: 119
Loss: 0.09901097214937735
ROC train: 0.986617	val: 0.784952	test: 0.831696
PRC train: 0.930570	val: 0.588282	test: 0.651808

Epoch: 120
Loss: 0.09604268822291048
ROC train: 0.986791	val: 0.752847	test: 0.825962
PRC train: 0.928809	val: 0.639716	test: 0.664409

Early stopping
Best (ROC):	 train: 0.907878	val: 0.892564	test: 0.673980
Best (PRC):	 train: 0.717995	val: 0.654455	test: 0.543580

ROC train: 0.983941	val: 0.763871	test: 0.791773
PRC train: 0.914791	val: 0.617941	test: 0.614459

Epoch: 95
Loss: 0.11736441649100175
ROC train: 0.980276	val: 0.774747	test: 0.781255
PRC train: 0.896661	val: 0.661936	test: 0.608856

Epoch: 96
Loss: 0.11984959707674818
ROC train: 0.982995	val: 0.801981	test: 0.811985
PRC train: 0.908947	val: 0.706886	test: 0.601440

Epoch: 97
Loss: 0.09551859034841076
ROC train: 0.984646	val: 0.790743	test: 0.833448
PRC train: 0.913099	val: 0.659323	test: 0.612344

Epoch: 98
Loss: 0.11191503941025716
ROC train: 0.984217	val: 0.798348	test: 0.837732
PRC train: 0.908725	val: 0.656361	test: 0.612695

Epoch: 99
Loss: 0.10514257640312005
ROC train: 0.983998	val: 0.807776	test: 0.835446
PRC train: 0.912563	val: 0.654589	test: 0.622610

Epoch: 100
Loss: 0.12174358342534253
ROC train: 0.985286	val: 0.805952	test: 0.844915
PRC train: 0.917148	val: 0.685190	test: 0.610708

Epoch: 101
Loss: 0.11952316679613648
ROC train: 0.984244	val: 0.820100	test: 0.822242
PRC train: 0.912256	val: 0.689587	test: 0.602419

Epoch: 102
Loss: 0.1051492234283126
ROC train: 0.985598	val: 0.827430	test: 0.827288
PRC train: 0.922968	val: 0.664442	test: 0.603310

Epoch: 103
Loss: 0.11018735009489793
ROC train: 0.984508	val: 0.786523	test: 0.829974
PRC train: 0.920793	val: 0.620258	test: 0.627385

Epoch: 104
Loss: 0.11207822626505956
ROC train: 0.984775	val: 0.765719	test: 0.858205
PRC train: 0.919091	val: 0.628291	test: 0.639509

Epoch: 105
Loss: 0.1120626497093461
ROC train: 0.986242	val: 0.756579	test: 0.869691
PRC train: 0.925935	val: 0.613945	test: 0.655182

Epoch: 106
Loss: 0.10236417076277174
ROC train: 0.986073	val: 0.751435	test: 0.866643
PRC train: 0.924400	val: 0.606621	test: 0.667038

Epoch: 107
Loss: 0.10636084828980019
ROC train: 0.985941	val: 0.717457	test: 0.867312
PRC train: 0.921127	val: 0.593626	test: 0.653257

Epoch: 108
Loss: 0.09373501542812686
ROC train: 0.985142	val: 0.707779	test: 0.868261
PRC train: 0.916024	val: 0.590232	test: 0.649908

Epoch: 109
Loss: 0.10147186606903025
ROC train: 0.986171	val: 0.746202	test: 0.856412
PRC train: 0.925135	val: 0.605403	test: 0.647621

Epoch: 110
Loss: 0.10303834868240858
ROC train: 0.987382	val: 0.778244	test: 0.847255
PRC train: 0.931731	val: 0.637598	test: 0.633858

Epoch: 111
Loss: 0.10106464241973474
ROC train: 0.986955	val: 0.789819	test: 0.836675
PRC train: 0.931932	val: 0.651626	test: 0.634559

Epoch: 112
Loss: 0.09750710089012359
ROC train: 0.984533	val: 0.794015	test: 0.816557
PRC train: 0.916999	val: 0.624716	test: 0.632012

Epoch: 113
Loss: 0.0950195229390618
ROC train: 0.986295	val: 0.778743	test: 0.857268
PRC train: 0.922510	val: 0.650093	test: 0.645915

Epoch: 114
Loss: 0.0900840108426773
ROC train: 0.987402	val: 0.782464	test: 0.864477
PRC train: 0.928656	val: 0.655546	test: 0.647472

Epoch: 115
Loss: 0.09865017978417791
ROC train: 0.987034	val: 0.792841	test: 0.867237
PRC train: 0.927768	val: 0.647178	test: 0.639540

Epoch: 116
Loss: 0.09693466577244966
ROC train: 0.986973	val: 0.798885	test: 0.866763
PRC train: 0.928182	val: 0.646935	test: 0.633094

Epoch: 117
Loss: 0.10093966940193158
ROC train: 0.987551	val: 0.784987	test: 0.876769
PRC train: 0.931374	val: 0.657376	test: 0.641273

Epoch: 118
Loss: 0.09716590667349978
ROC train: 0.986729	val: 0.779955	test: 0.878843
PRC train: 0.927088	val: 0.656438	test: 0.662832

Epoch: 119
Loss: 0.08762665643509619
ROC train: 0.985886	val: 0.799722	test: 0.847369
PRC train: 0.925575	val: 0.616756	test: 0.646895

Epoch: 120
Loss: 0.09987403133554151
ROC train: 0.985863	val: 0.795751	test: 0.870898
PRC train: 0.921955	val: 0.617761	test: 0.643661

Early stopping
Best (ROC):	 train: 0.888783	val: 0.897122	test: 0.639496
Best (PRC):	 train: 0.711548	val: 0.648642	test: 0.548910
All runs completed.
All runs completed.
