>>> Starting run for dataset: clintox
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running SCAFF configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.6.yml on cuda:0
Running SCAFF configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.7.yml on cuda:1
Running SCAFF configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.8.yml on cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.6.yml --runseed 4 --device cuda:0
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.8.yml --runseed 4 --device cuda:2
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.6.yml --runseed 5 --device cuda:0
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.8.yml --runseed 5 --device cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.7.yml --runseed 4 --device cuda:1
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.6.yml --runseed 6 --device cuda:0
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.8.yml --runseed 6 --device cuda:2
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.7.yml --runseed 5 --device cuda:1
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.7.yml --runseed 6 --device cuda:1
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/clintox/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/clintox/scaff/train_prop=0.6/clintox_scaff_6_26-05_10-23-09  ]
[ Using Seed :  6  ]
[ Using device :  cuda:0  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6538030560048749
ROC train: 0.606243	val: 0.455423	test: 0.525324
PRC train: 0.528596	val: 0.498346	test: 0.511196

Epoch: 2
Loss: 0.5770268876017941
ROC train: 0.686088	val: 0.494193	test: 0.550129
PRC train: 0.549359	val: 0.509199	test: 0.516140

Epoch: 3
Loss: 0.517533785832901
ROC train: 0.741303	val: 0.519860	test: 0.601861
PRC train: 0.569230	val: 0.513905	test: 0.520086

Epoch: 4
Loss: 0.46904614407226763
ROC train: 0.771618	val: 0.535399	test: 0.630931
PRC train: 0.588263	val: 0.521211	test: 0.523323

Epoch: 5
Loss: 0.42612970166726377
ROC train: 0.822145	val: 0.550085	test: 0.643148
PRC train: 0.627116	val: 0.523810	test: 0.526501

Epoch: 6
Loss: 0.38514971829478206
ROC train: 0.851275	val: 0.586819	test: 0.661961
PRC train: 0.645988	val: 0.527349	test: 0.531625

Epoch: 7
Loss: 0.34795737500517304
ROC train: 0.861330	val: 0.573617	test: 0.665958
PRC train: 0.653777	val: 0.524424	test: 0.533274

Epoch: 8
Loss: 0.32437335002843215
ROC train: 0.872959	val: 0.600676	test: 0.695523
PRC train: 0.669237	val: 0.531392	test: 0.540653

Epoch: 9
Loss: 0.3009664887965266
ROC train: 0.887094	val: 0.616480	test: 0.684086
PRC train: 0.688227	val: 0.535111	test: 0.537869

Epoch: 10
Loss: 0.2851765772533754
ROC train: 0.896276	val: 0.635484	test: 0.662848
PRC train: 0.698137	val: 0.548391	test: 0.535345

Epoch: 11
Loss: 0.2646120748177374
ROC train: 0.909451	val: 0.657324	test: 0.674506
PRC train: 0.713747	val: 0.549276	test: 0.538725

Epoch: 12
Loss: 0.25308088436281817
ROC train: 0.910744	val: 0.638752	test: 0.675554
PRC train: 0.715993	val: 0.544112	test: 0.538791

Epoch: 13
Loss: 0.23840921138144355
ROC train: 0.917604	val: 0.645119	test: 0.681088
PRC train: 0.750554	val: 0.543519	test: 0.550475

Epoch: 14
Loss: 0.22441411117080107
ROC train: 0.921427	val: 0.642287	test: 0.705920
PRC train: 0.768785	val: 0.544497	test: 0.548866

Epoch: 15
Loss: 0.22286759978274812
ROC train: 0.928305	val: 0.647211	test: 0.717863
PRC train: 0.777268	val: 0.543869	test: 0.560839

Epoch: 16
Loss: 0.22225586037395872
ROC train: 0.929723	val: 0.679201	test: 0.740572
PRC train: 0.777242	val: 0.548823	test: 0.563839

Epoch: 17
Loss: 0.20111252947942576
ROC train: 0.930704	val: 0.707495	test: 0.747117
PRC train: 0.768700	val: 0.558424	test: 0.579163

Epoch: 18
Loss: 0.20367363197131483
ROC train: 0.931065	val: 0.673061	test: 0.713128
PRC train: 0.782816	val: 0.548078	test: 0.556758

Epoch: 19
Loss: 0.20345801888278278
ROC train: 0.936326	val: 0.637847	test: 0.710055
PRC train: 0.788051	val: 0.539300	test: 0.553123

Epoch: 20
Loss: 0.1805112023305996
ROC train: 0.943640	val: 0.651558	test: 0.760665
PRC train: 0.805359	val: 0.544269	test: 0.570352

Epoch: 21
Loss: 0.19139705170754095
ROC train: 0.948398	val: 0.650616	test: 0.763512
PRC train: 0.817804	val: 0.545423	test: 0.567732

Epoch: 22
Loss: 0.17677770278908628
ROC train: 0.950375	val: 0.633591	test: 0.762912
PRC train: 0.820421	val: 0.546324	test: 0.570471

Epoch: 23
Loss: 0.17838158815665203
ROC train: 0.955743	val: 0.638959	test: 0.775310
PRC train: 0.838383	val: 0.549278	test: 0.568067

Epoch: 24
Loss: 0.1675851402594862
ROC train: 0.955985	val: 0.667964	test: 0.790933
PRC train: 0.835970	val: 0.555793	test: 0.581313

Epoch: 25
Loss: 0.1583321434233811
ROC train: 0.956310	val: 0.643816	test: 0.784209
PRC train: 0.841492	val: 0.549887	test: 0.572464

Epoch: 26
Loss: 0.16319831132147816
ROC train: 0.953354	val: 0.645735	test: 0.785735
PRC train: 0.836116	val: 0.550241	test: 0.566835

Epoch: 27
Loss: 0.16998343431834723
ROC train: 0.955682	val: 0.671503	test: 0.810535
PRC train: 0.843404	val: 0.557126	test: 0.571465

Epoch: 28
Loss: 0.15739729380760364
ROC train: 0.955843	val: 0.697763	test: 0.810889
PRC train: 0.840102	val: 0.562904	test: 0.578020

Epoch: 29
Loss: 0.15708352775183737
ROC train: 0.961232	val: 0.685073	test: 0.793165
PRC train: 0.850056	val: 0.563314	test: 0.579958

Epoch: 30
Loss: 0.1687139295581489
ROC train: 0.960101	val: 0.670242	test: 0.787152
PRC train: 0.851618	val: 0.565275	test: 0.582228

Epoch: 31
Loss: 0.1619549337069561
ROC train: 0.960786	val: 0.676033	test: 0.799112
PRC train: 0.858186	val: 0.568710	test: 0.571094

Epoch: 32
Loss: 0.16672718547432142
ROC train: 0.956802	val: 0.685965	test: 0.812984
PRC train: 0.848079	val: 0.564406	test: 0.579818

Epoch: 33
Loss: 0.16009598073091386Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/clintox/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/clintox/scaff/train_prop=0.6/clintox_scaff_5_26-05_10-23-09  ]
[ Using Seed :  5  ]
[ Using device :  cuda:0  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6611349835475554
ROC train: 0.532647	val: 0.443093	test: 0.433258
PRC train: 0.514350	val: 0.500571	test: 0.524851

Epoch: 2
Loss: 0.5952619456788094
ROC train: 0.600594	val: 0.453736	test: 0.480128
PRC train: 0.531684	val: 0.501295	test: 0.528919

Epoch: 3
Loss: 0.5363115143365715
ROC train: 0.680677	val: 0.490673	test: 0.514220
PRC train: 0.556299	val: 0.511785	test: 0.532998

Epoch: 4
Loss: 0.4900278814467599
ROC train: 0.724109	val: 0.507183	test: 0.546022
PRC train: 0.573001	val: 0.513777	test: 0.537496

Epoch: 5
Loss: 0.4407907600968296
ROC train: 0.755846	val: 0.518718	test: 0.571741
PRC train: 0.585841	val: 0.517323	test: 0.541322

Epoch: 6
Loss: 0.40911149370580896
ROC train: 0.797115	val: 0.560730	test: 0.622517
PRC train: 0.604169	val: 0.523151	test: 0.549962

Epoch: 7
Loss: 0.371155473059124
ROC train: 0.816364	val: 0.609123	test: 0.665466
PRC train: 0.617457	val: 0.532479	test: 0.558767

Epoch: 8
Loss: 0.3405342292980882
ROC train: 0.839191	val: 0.614589	test: 0.669426
PRC train: 0.632556	val: 0.534012	test: 0.561201

Epoch: 9
Loss: 0.3160234375402905
ROC train: 0.861856	val: 0.608159	test: 0.677201
PRC train: 0.648216	val: 0.530631	test: 0.562880

Epoch: 10
Loss: 0.29263059807208186
ROC train: 0.873921	val: 0.615594	test: 0.680511
PRC train: 0.659970	val: 0.532819	test: 0.563445

Epoch: 11
Loss: 0.2747350619600235
ROC train: 0.887948	val: 0.629724	test: 0.694590
PRC train: 0.681245	val: 0.534936	test: 0.541589

Epoch: 12
Loss: 0.26279297774465554
ROC train: 0.896796	val: 0.641042	test: 0.686561
PRC train: 0.703285	val: 0.537014	test: 0.540788

Epoch: 13
Loss: 0.23966340176439832
ROC train: 0.905817	val: 0.656450	test: 0.674470
PRC train: 0.722785	val: 0.539091	test: 0.549432

Epoch: 14
Loss: 0.2270334769732144
ROC train: 0.915259	val: 0.685407	test: 0.685561
PRC train: 0.730023	val: 0.545391	test: 0.544784

Epoch: 15
Loss: 0.21720568281755162
ROC train: 0.919491	val: 0.689645	test: 0.714738
PRC train: 0.738811	val: 0.545682	test: 0.551018

Epoch: 16
Loss: 0.21000884706380749
ROC train: 0.916488	val: 0.648267	test: 0.712642
PRC train: 0.747793	val: 0.538911	test: 0.544859

Epoch: 17
Loss: 0.20520739615864608
ROC train: 0.914807	val: 0.640623	test: 0.710950
PRC train: 0.748504	val: 0.540650	test: 0.545573

Epoch: 18
Loss: 0.20299567080503433
ROC train: 0.930703	val: 0.668977	test: 0.734465
PRC train: 0.760629	val: 0.547579	test: 0.552584

Epoch: 19
Loss: 0.19274070605288313
ROC train: 0.937601	val: 0.709246	test: 0.771608
PRC train: 0.768801	val: 0.554674	test: 0.567145

Epoch: 20
Loss: 0.1876831907820965
ROC train: 0.938278	val: 0.705867	test: 0.773538
PRC train: 0.771125	val: 0.554274	test: 0.560292

Epoch: 21
Loss: 0.18874102409750654
ROC train: 0.944332	val: 0.686823	test: 0.769504
PRC train: 0.782129	val: 0.553037	test: 0.556157

Epoch: 22
Loss: 0.20009997743828767
ROC train: 0.942704	val: 0.682226	test: 0.787023
PRC train: 0.780422	val: 0.551381	test: 0.562535

Epoch: 23
Loss: 0.16754381109618038
ROC train: 0.942811	val: 0.697646	test: 0.797513
PRC train: 0.785546	val: 0.555931	test: 0.576233

Epoch: 24
Loss: 0.1716024917289614
ROC train: 0.950375	val: 0.696353	test: 0.798622
PRC train: 0.804687	val: 0.557162	test: 0.580748

Epoch: 25
Loss: 0.17887177554833136
ROC train: 0.945853	val: 0.698736	test: 0.792982
PRC train: 0.808691	val: 0.552530	test: 0.579880

Epoch: 26
Loss: 0.1736648082875764
ROC train: 0.953780	val: 0.695425	test: 0.793583
PRC train: 0.819716	val: 0.555484	test: 0.598754

Epoch: 27
Loss: 0.1794829451191681
ROC train: 0.956507	val: 0.666891	test: 0.792021
PRC train: 0.820046	val: 0.558595	test: 0.582510

Epoch: 28
Loss: 0.168282016411377
ROC train: 0.946471	val: 0.626732	test: 0.773054
PRC train: 0.812630	val: 0.544672	test: 0.558223

Epoch: 29
Loss: 0.17378263895746468
ROC train: 0.950900	val: 0.620899	test: 0.774481
PRC train: 0.823225	val: 0.540499	test: 0.559872

Epoch: 30
Loss: 0.16614551302702146
ROC train: 0.958950	val: 0.643092	test: 0.790367
PRC train: 0.831251	val: 0.543017	test: 0.571562

Epoch: 31
Loss: 0.1608815636042198
ROC train: 0.960539	val: 0.650379	test: 0.799746
PRC train: 0.837556	val: 0.542134	test: 0.572797

Epoch: 32
Loss: 0.16154130601799446
ROC train: 0.963008	val: 0.665621	test: 0.805095
PRC train: 0.840477	val: 0.544790	test: 0.573279

Epoch: 33
Loss: 0.1525165373480996Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/clintox/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/clintox/scaff/train_prop=0.6/clintox_scaff_4_26-05_10-23-09  ]
[ Using Seed :  4  ]
[ Using device :  cuda:0  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6747719876831045
ROC train: 0.584141	val: 0.447151	test: 0.474229
PRC train: 0.526720	val: 0.502890	test: 0.503540

Epoch: 2
Loss: 0.6054182112735998
ROC train: 0.654676	val: 0.455984	test: 0.476744
PRC train: 0.541752	val: 0.504007	test: 0.506169

Epoch: 3
Loss: 0.5479143258494577
ROC train: 0.722180	val: 0.479326	test: 0.496404
PRC train: 0.561387	val: 0.506222	test: 0.509663

Epoch: 4
Loss: 0.48909700376135995
ROC train: 0.782203	val: 0.520544	test: 0.564543
PRC train: 0.594063	val: 0.517840	test: 0.520470

Epoch: 5
Loss: 0.4462343196744313
ROC train: 0.788866	val: 0.531049	test: 0.579941
PRC train: 0.604941	val: 0.519984	test: 0.541018

Epoch: 6
Loss: 0.4148442419865375
ROC train: 0.806767	val: 0.564917	test: 0.657854
PRC train: 0.612781	val: 0.525761	test: 0.527329

Epoch: 7
Loss: 0.36129058372748657
ROC train: 0.836743	val: 0.588885	test: 0.672521
PRC train: 0.642744	val: 0.529433	test: 0.555691

Epoch: 8
Loss: 0.3396155398881422
ROC train: 0.853618	val: 0.595449	test: 0.651203
PRC train: 0.655056	val: 0.532580	test: 0.553699

Epoch: 9
Loss: 0.3221348115383074
ROC train: 0.871432	val: 0.619432	test: 0.681023
PRC train: 0.675690	val: 0.533763	test: 0.531294

Epoch: 10
Loss: 0.29513111220679233
ROC train: 0.883968	val: 0.645395	test: 0.725305
PRC train: 0.689860	val: 0.538762	test: 0.540637

Epoch: 11
Loss: 0.27856037547606693
ROC train: 0.897585	val: 0.652703	test: 0.710343
PRC train: 0.697691	val: 0.540317	test: 0.540044

Epoch: 12
Loss: 0.2600338874822589
ROC train: 0.905208	val: 0.633456	test: 0.687780
PRC train: 0.709658	val: 0.541666	test: 0.533983

Epoch: 13
Loss: 0.2551420818398812
ROC train: 0.915246	val: 0.656205	test: 0.705446
PRC train: 0.731864	val: 0.545145	test: 0.540502

Epoch: 14
Loss: 0.22850765981307325
ROC train: 0.914395	val: 0.685424	test: 0.751077
PRC train: 0.735286	val: 0.548026	test: 0.558719

Epoch: 15
Loss: 0.2243294296993775
ROC train: 0.910201	val: 0.646470	test: 0.735497
PRC train: 0.723743	val: 0.558061	test: 0.548492

Epoch: 16
Loss: 0.21642022172676728
ROC train: 0.925172	val: 0.676143	test: 0.740843
PRC train: 0.745346	val: 0.567160	test: 0.548229

Epoch: 17
Loss: 0.21242653232504294
ROC train: 0.930506	val: 0.696064	test: 0.740036
PRC train: 0.755538	val: 0.556207	test: 0.556610

Epoch: 18
Loss: 0.20594256427364005
ROC train: 0.930434	val: 0.659829	test: 0.689421
PRC train: 0.755566	val: 0.551508	test: 0.540550

Epoch: 19
Loss: 0.20242621170388697
ROC train: 0.937944	val: 0.657837	test: 0.712428
PRC train: 0.780077	val: 0.543425	test: 0.553058

Epoch: 20
Loss: 0.1826895906192983
ROC train: 0.925056	val: 0.708436	test: 0.771541
PRC train: 0.765242	val: 0.553568	test: 0.608627

Epoch: 21
Loss: 0.19009838275141946
ROC train: 0.938853	val: 0.696395	test: 0.747977
PRC train: 0.797322	val: 0.549647	test: 0.568887

Epoch: 22
Loss: 0.17941738650343259
ROC train: 0.937717	val: 0.664856	test: 0.675786
PRC train: 0.813831	val: 0.545443	test: 0.541820

Epoch: 23
Loss: 0.1761165008737598
ROC train: 0.943338	val: 0.694769	test: 0.700548
PRC train: 0.809958	val: 0.554677	test: 0.556587

Epoch: 24
Loss: 0.1873824984725711
ROC train: 0.942906	val: 0.702966	test: 0.732025
PRC train: 0.799045	val: 0.555718	test: 0.554636

Epoch: 25
Loss: 0.17548224102907742
ROC train: 0.947424	val: 0.709826	test: 0.758997
PRC train: 0.801468	val: 0.557547	test: 0.562946

Epoch: 26
Loss: 0.17816725597919672
ROC train: 0.950223	val: 0.706958	test: 0.767202
PRC train: 0.813537	val: 0.559700	test: 0.573413

Epoch: 27
Loss: 0.17583546424091218
ROC train: 0.952419	val: 0.698774	test: 0.763483
PRC train: 0.823725	val: 0.557448	test: 0.571474

Epoch: 28
Loss: 0.16776788185687913
ROC train: 0.957377	val: 0.709100	test: 0.761168
PRC train: 0.843502	val: 0.560224	test: 0.567791

Epoch: 29
Loss: 0.17396943099806353
ROC train: 0.958758	val: 0.702140	test: 0.753683
PRC train: 0.848120	val: 0.561188	test: 0.558519

Epoch: 30
Loss: 0.15616570693899198
ROC train: 0.960411	val: 0.705492	test: 0.740004
PRC train: 0.845836	val: 0.563627	test: 0.564382

Epoch: 31
Loss: 0.17085361758270018
ROC train: 0.962871	val: 0.703867	test: 0.738789
PRC train: 0.845349	val: 0.562978	test: 0.563092

Epoch: 32
Loss: 0.15514880940677117
ROC train: 0.966051	val: 0.689113	test: 0.751473
PRC train: 0.850386	val: 0.558451	test: 0.566739

Epoch: 33
Loss: 0.15726443725368605Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/clintox/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/clintox/scaff/train_prop=0.7/clintox_scaff_4_26-05_10-23-09  ]
[ Using Seed :  4  ]
[ Using device :  cuda:1  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.67110336663524
ROC train: 0.569961	val: 0.435321	test: 0.426680
PRC train: 0.523596	val: 0.501225	test: 0.500538

Epoch: 2
Loss: 0.5908407231514657
ROC train: 0.584504	val: 0.432088	test: 0.414843
PRC train: 0.537478	val: 0.508075	test: 0.506276

Epoch: 3
Loss: 0.5274693110771256
ROC train: 0.596849	val: 0.450675	test: 0.434804
PRC train: 0.549733	val: 0.516359	test: 0.498828

Epoch: 4
Loss: 0.47310375455302606
ROC train: 0.645403	val: 0.478069	test: 0.450461
PRC train: 0.557939	val: 0.522215	test: 0.500705

Epoch: 5
Loss: 0.44788797898945454
ROC train: 0.692353	val: 0.521532	test: 0.491392
PRC train: 0.555047	val: 0.545650	test: 0.505660

Epoch: 6
Loss: 0.4196808808008317
ROC train: 0.737188	val: 0.560001	test: 0.538461
PRC train: 0.574313	val: 0.536893	test: 0.513243

Epoch: 7
Loss: 0.34970101655969943
ROC train: 0.782216	val: 0.616256	test: 0.583317
PRC train: 0.593138	val: 0.548381	test: 0.520917

Epoch: 8
Loss: 0.33796682576073955
ROC train: 0.792315	val: 0.574885	test: 0.554068
PRC train: 0.601725	val: 0.550482	test: 0.529829

Epoch: 9
Loss: 0.29642453307189615
ROC train: 0.802020	val: 0.565921	test: 0.552560
PRC train: 0.601669	val: 0.536889	test: 0.522190

Epoch: 10
Loss: 0.3073130973273159
ROC train: 0.835782	val: 0.625719	test: 0.621739
PRC train: 0.619804	val: 0.543497	test: 0.525918

Epoch: 11
Loss: 0.34026753466396265
ROC train: 0.813710	val: 0.678425	test: 0.679370
PRC train: 0.622058	val: 0.558280	test: 0.540882

Epoch: 12
Loss: 0.2881658596887413
ROC train: 0.802399	val: 0.661484	test: 0.695512
PRC train: 0.619250	val: 0.554198	test: 0.544865

Epoch: 13
Loss: 0.24546808174538298
ROC train: 0.849976	val: 0.642199	test: 0.670543
PRC train: 0.646143	val: 0.558875	test: 0.531563

Epoch: 14
Loss: 0.2599505966154483
ROC train: 0.848075	val: 0.623019	test: 0.625829
PRC train: 0.633825	val: 0.545546	test: 0.522350

Epoch: 15
Loss: 0.25176460129307376
ROC train: 0.848651	val: 0.639283	test: 0.629120
PRC train: 0.636735	val: 0.543292	test: 0.522455

Epoch: 16
Loss: 0.2190915762370091
ROC train: 0.856268	val: 0.692644	test: 0.673401
PRC train: 0.647839	val: 0.558424	test: 0.531174

Epoch: 17
Loss: 0.26546623337705755
ROC train: 0.869382	val: 0.712183	test: 0.679257
PRC train: 0.668042	val: 0.566732	test: 0.536078

Epoch: 18
Loss: 0.2659587449517763
ROC train: 0.862975	val: 0.686856	test: 0.691932
PRC train: 0.658901	val: 0.564984	test: 0.538394

Epoch: 19
Loss: 0.28172872406359817
ROC train: 0.850626	val: 0.644767	test: 0.666915
PRC train: 0.636336	val: 0.547179	test: 0.531077

Epoch: 20
Loss: 0.20732736609324207
ROC train: 0.837404	val: 0.615903	test: 0.634540
PRC train: 0.616411	val: 0.539097	test: 0.524646

Epoch: 21
Loss: 0.20520188023432237
ROC train: 0.877205	val: 0.658983	test: 0.676108
PRC train: 0.657486	val: 0.550070	test: 0.532071

Epoch: 22
Loss: 0.18304674945712074
ROC train: 0.893963	val: 0.701668	test: 0.703152
PRC train: 0.701345	val: 0.559463	test: 0.542748

Epoch: 23
Loss: 0.20754780581855187
ROC train: 0.894454	val: 0.722113	test: 0.712409
PRC train: 0.702184	val: 0.564797	test: 0.550733

Epoch: 24
Loss: 0.1832373689326749
ROC train: 0.900513	val: 0.725879	test: 0.726020
PRC train: 0.716897	val: 0.563005	test: 0.556230

Epoch: 25
Loss: 0.17502671449686447
ROC train: 0.908123	val: 0.724083	test: 0.720215
PRC train: 0.728202	val: 0.563059	test: 0.549403

Epoch: 26
Loss: 0.1730043154161735
ROC train: 0.913917	val: 0.720591	test: 0.714611
PRC train: 0.729841	val: 0.562624	test: 0.551277

Epoch: 27
Loss: 0.1935020060710259
ROC train: 0.919533	val: 0.728182	test: 0.723245
PRC train: 0.740615	val: 0.570153	test: 0.557736

Epoch: 28
Loss: 0.19153502441153727
ROC train: 0.921539	val: 0.741072	test: 0.713463
PRC train: 0.739210	val: 0.582315	test: 0.558592

Epoch: 29
Loss: 0.1735584754482046
ROC train: 0.916056	val: 0.720701	test: 0.698140
PRC train: 0.720460	val: 0.576089	test: 0.546894

Epoch: 30
Loss: 0.18047786956650316
ROC train: 0.929260	val: 0.718286	test: 0.718855
PRC train: 0.743843	val: 0.580095	test: 0.551148

Epoch: 31
Loss: 0.16525289782290858
ROC train: 0.931004	val: 0.698410	test: 0.724186
PRC train: 0.750173	val: 0.571669	test: 0.560113

Epoch: 32
Loss: 0.19295323052636532
ROC train: 0.931677	val: 0.709703	test: 0.748277
PRC train: 0.751904	val: 0.580261	test: 0.587345

Epoch: 33
Loss: 0.16275830655507165Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/clintox/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/clintox/scaff/train_prop=0.7/clintox_scaff_6_26-05_10-23-09  ]
[ Using Seed :  6  ]
[ Using device :  cuda:1  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6462641355538608
ROC train: 0.619135	val: 0.477356	test: 0.550083
PRC train: 0.530985	val: 0.504936	test: 0.516887

Epoch: 2
Loss: 0.5537095227011538
ROC train: 0.661235	val: 0.570967	test: 0.562918
PRC train: 0.542980	val: 0.531878	test: 0.515712

Epoch: 3
Loss: 0.4957883538864474
ROC train: 0.671188	val: 0.577530	test: 0.564666
PRC train: 0.544612	val: 0.534701	test: 0.514118

Epoch: 4
Loss: 0.44531510694449644
ROC train: 0.697421	val: 0.558398	test: 0.565457
PRC train: 0.557496	val: 0.532657	test: 0.514394

Epoch: 5
Loss: 0.39815841172069893
ROC train: 0.786518	val: 0.637749	test: 0.574562
PRC train: 0.588352	val: 0.545519	test: 0.512753

Epoch: 6
Loss: 0.4187394678560006
ROC train: 0.796364	val: 0.673201	test: 0.583924
PRC train: 0.595709	val: 0.551155	test: 0.519631

Epoch: 7
Loss: 0.37123083742548557
ROC train: 0.767746	val: 0.540084	test: 0.525394
PRC train: 0.585054	val: 0.527075	test: 0.508382

Epoch: 8
Loss: 0.3061680566812481
ROC train: 0.703001	val: 0.508174	test: 0.494300
PRC train: 0.566309	val: 0.519105	test: 0.503761

Epoch: 9
Loss: 0.2772103396123377
ROC train: 0.787362	val: 0.594156	test: 0.539102
PRC train: 0.589056	val: 0.535465	test: 0.511780

Epoch: 10
Loss: 0.287213867885055
ROC train: 0.820887	val: 0.659999	test: 0.602521
PRC train: 0.607551	val: 0.553565	test: 0.518052

Epoch: 11
Loss: 0.2489722477220681
ROC train: 0.834024	val: 0.689397	test: 0.609222
PRC train: 0.622925	val: 0.562688	test: 0.518615

Epoch: 12
Loss: 0.25813270230522567
ROC train: 0.852650	val: 0.707761	test: 0.617130
PRC train: 0.645543	val: 0.565033	test: 0.521736

Epoch: 13
Loss: 0.24796096091605957
ROC train: 0.845530	val: 0.689968	test: 0.603451
PRC train: 0.653626	val: 0.554518	test: 0.521747

Epoch: 14
Loss: 0.21671450596932665
ROC train: 0.834879	val: 0.650182	test: 0.547634
PRC train: 0.630809	val: 0.543718	test: 0.513211

Epoch: 15
Loss: 0.23851841318533853
ROC train: 0.865135	val: 0.699382	test: 0.594063
PRC train: 0.651792	val: 0.556019	test: 0.519544

Epoch: 16
Loss: 0.2101511050752291
ROC train: 0.870061	val: 0.730118	test: 0.610662
PRC train: 0.659863	val: 0.567671	test: 0.531174

Epoch: 17
Loss: 0.268606187347969
ROC train: 0.881203	val: 0.723502	test: 0.610469
PRC train: 0.670920	val: 0.571777	test: 0.528702

Epoch: 18
Loss: 0.19571334271993118
ROC train: 0.870982	val: 0.705111	test: 0.622737
PRC train: 0.669130	val: 0.571313	test: 0.529002

Epoch: 19
Loss: 0.19016757954609695
ROC train: 0.868883	val: 0.702225	test: 0.626382
PRC train: 0.671170	val: 0.574787	test: 0.528581

Epoch: 20
Loss: 0.1836197352494009
ROC train: 0.887457	val: 0.711128	test: 0.652318
PRC train: 0.699367	val: 0.580759	test: 0.536885

Epoch: 21
Loss: 0.212363690398717
ROC train: 0.887636	val: 0.716169	test: 0.722109
PRC train: 0.696915	val: 0.582866	test: 0.557334

Epoch: 22
Loss: 0.18230264031402252
ROC train: 0.884250	val: 0.711143	test: 0.734229
PRC train: 0.694293	val: 0.578436	test: 0.561379

Epoch: 23
Loss: 0.19695165521034919
ROC train: 0.898682	val: 0.694896	test: 0.692415
PRC train: 0.734086	val: 0.574267	test: 0.539830

Epoch: 24
Loss: 0.1697495672004457
ROC train: 0.885078	val: 0.658030	test: 0.612034
PRC train: 0.716438	val: 0.560148	test: 0.522343

Epoch: 25
Loss: 0.31245812571599324
ROC train: 0.905784	val: 0.685521	test: 0.677193
PRC train: 0.750851	val: 0.573152	test: 0.536036

Epoch: 26
Loss: 0.2122432420591865
ROC train: 0.853011	val: 0.689029	test: 0.722800
PRC train: 0.691841	val: 0.570199	test: 0.564635

Epoch: 27
Loss: 0.2062350748404135
ROC train: 0.856787	val: 0.690564	test: 0.705232
PRC train: 0.687654	val: 0.576333	test: 0.552814

Epoch: 28
Loss: 0.20384371976789573
ROC train: 0.886519	val: 0.653178	test: 0.653293
PRC train: 0.707998	val: 0.553646	test: 0.530472

Epoch: 29
Loss: 0.23094334880833514
ROC train: 0.854508	val: 0.601466	test: 0.566302
PRC train: 0.676285	val: 0.536360	test: 0.515693

Epoch: 30
Loss: 0.17309524548711713
ROC train: 0.871423	val: 0.603908	test: 0.619999
PRC train: 0.693389	val: 0.537961	test: 0.522952

Epoch: 31
Loss: 0.17296971212397078
ROC train: 0.894219	val: 0.629762	test: 0.674299
PRC train: 0.727732	val: 0.550362	test: 0.532027

Epoch: 32
Loss: 0.16733418192317856
ROC train: 0.906146	val: 0.642045	test: 0.706264
PRC train: 0.732678	val: 0.552067	test: 0.544261

Epoch: 33
Loss: 0.18126873651915615Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/clintox/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/clintox/scaff/train_prop=0.7/clintox_scaff_5_26-05_10-23-09  ]
[ Using Seed :  5  ]
[ Using device :  cuda:1  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6515706784910547
ROC train: 0.526971	val: 0.430371	test: 0.450836
PRC train: 0.513308	val: 0.500665	test: 0.534921

Epoch: 2
Loss: 0.585605100186638
ROC train: 0.571875	val: 0.446942	test: 0.453256
PRC train: 0.523713	val: 0.507854	test: 0.534885

Epoch: 3
Loss: 0.5114389216889992
ROC train: 0.628731	val: 0.490140	test: 0.500264
PRC train: 0.534763	val: 0.514823	test: 0.504278

Epoch: 4
Loss: 0.4585801732166028
ROC train: 0.700983	val: 0.537293	test: 0.548677
PRC train: 0.552034	val: 0.525899	test: 0.513445

Epoch: 5
Loss: 0.4241817712821194
ROC train: 0.746052	val: 0.567868	test: 0.588462
PRC train: 0.570166	val: 0.533990	test: 0.523150

Epoch: 6
Loss: 0.39387254389696963
ROC train: 0.757955	val: 0.583484	test: 0.642261
PRC train: 0.578166	val: 0.533386	test: 0.527553

Epoch: 7
Loss: 0.33970985815358584
ROC train: 0.758393	val: 0.608213	test: 0.669702
PRC train: 0.580816	val: 0.538974	test: 0.532041

Epoch: 8
Loss: 0.3142009036695479
ROC train: 0.770712	val: 0.619961	test: 0.658616
PRC train: 0.584089	val: 0.546415	test: 0.529378

Epoch: 9
Loss: 0.2907115963820942
ROC train: 0.803597	val: 0.642449	test: 0.616875
PRC train: 0.599314	val: 0.552489	test: 0.523493

Epoch: 10
Loss: 0.28861504224177764
ROC train: 0.836559	val: 0.707673	test: 0.667536
PRC train: 0.638163	val: 0.573573	test: 0.536045

Epoch: 11
Loss: 0.34655311365873115
ROC train: 0.834763	val: 0.728689	test: 0.685918
PRC train: 0.636951	val: 0.573468	test: 0.538741

Epoch: 12
Loss: 0.3011538819193308
ROC train: 0.817477	val: 0.705077	test: 0.642102
PRC train: 0.633232	val: 0.568208	test: 0.527971

Epoch: 13
Loss: 0.26296825932743273
ROC train: 0.825215	val: 0.729446	test: 0.640050
PRC train: 0.645188	val: 0.581142	test: 0.529447

Epoch: 14
Loss: 0.21870953212239513
ROC train: 0.855853	val: 0.758048	test: 0.673990
PRC train: 0.670704	val: 0.604167	test: 0.554869

Epoch: 15
Loss: 0.235104074569806
ROC train: 0.866256	val: 0.749861	test: 0.655328
PRC train: 0.662053	val: 0.598830	test: 0.584599

Epoch: 16
Loss: 0.23504280816866152
ROC train: 0.871197	val: 0.745243	test: 0.664857
PRC train: 0.659904	val: 0.591051	test: 0.541908

Epoch: 17
Loss: 0.33412634388134893
ROC train: 0.866750	val: 0.678659	test: 0.613964
PRC train: 0.635461	val: 0.571806	test: 0.522946

Epoch: 18
Loss: 0.2184362063483249
ROC train: 0.879202	val: 0.649128	test: 0.595146
PRC train: 0.656215	val: 0.561537	test: 0.518439

Epoch: 19
Loss: 0.19937619852622698
ROC train: 0.899683	val: 0.667963	test: 0.636433
PRC train: 0.699896	val: 0.575564	test: 0.534435

Epoch: 20
Loss: 0.20305583252875178
ROC train: 0.886340	val: 0.700259	test: 0.645758
PRC train: 0.691275	val: 0.585419	test: 0.543321

Epoch: 21
Loss: 0.3654418742112734
ROC train: 0.894186	val: 0.700962	test: 0.668593
PRC train: 0.697884	val: 0.582836	test: 0.543884

Epoch: 22
Loss: 0.19396610695553998
ROC train: 0.901054	val: 0.668902	test: 0.661847
PRC train: 0.680806	val: 0.571402	test: 0.536192

Epoch: 23
Loss: 0.18720970286451638
ROC train: 0.901767	val: 0.654687	test: 0.649126
PRC train: 0.680259	val: 0.561967	test: 0.532387

Epoch: 24
Loss: 0.2068177120336665
ROC train: 0.909822	val: 0.670068	test: 0.663137
PRC train: 0.701746	val: 0.582967	test: 0.535967

Epoch: 25
Loss: 0.17443121040764029
ROC train: 0.909801	val: 0.698525	test: 0.666553
PRC train: 0.708367	val: 0.593318	test: 0.537138

Epoch: 26
Loss: 0.1906197570217008
ROC train: 0.907375	val: 0.704889	test: 0.659421
PRC train: 0.714357	val: 0.590222	test: 0.534076

Epoch: 27
Loss: 0.1785201808969811
ROC train: 0.904510	val: 0.700147	test: 0.647811
PRC train: 0.710087	val: 0.587874	test: 0.530638

Epoch: 28
Loss: 0.2538253323090589
ROC train: 0.912619	val: 0.705360	test: 0.645294
PRC train: 0.715068	val: 0.575715	test: 0.528883

Epoch: 29
Loss: 0.18000441862737873
ROC train: 0.918584	val: 0.718695	test: 0.645597
PRC train: 0.706823	val: 0.577567	test: 0.527987

Epoch: 30
Loss: 0.19749380970445987
ROC train: 0.922378	val: 0.726992	test: 0.660691
PRC train: 0.737674	val: 0.606174	test: 0.557610

Epoch: 31
Loss: 0.16943398826589318
ROC train: 0.912237	val: 0.720331	test: 0.681558
PRC train: 0.725045	val: 0.607964	test: 0.587092

Epoch: 32
Loss: 0.16948009609665576
ROC train: 0.923413	val: 0.692038	test: 0.691218
PRC train: 0.749201	val: 0.599557	test: 0.563029

Epoch: 33
Loss: 0.169761156995565Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/clintox/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/clintox/scaff/train_prop=0.8/clintox_scaff_6_26-05_10-23-09  ]
[ Using Seed :  6  ]
[ Using device :  cuda:2  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.642390788905668
ROC train: 0.553230	val: 0.550144	test: 0.520901
PRC train: 0.517697	val: 0.524407	test: 0.510676

Epoch: 2
Loss: 0.5618086520678188
ROC train: 0.607595	val: 0.584410	test: 0.502296
PRC train: 0.528856	val: 0.520944	test: 0.510492

Epoch: 3
Loss: 0.4931621635357761
ROC train: 0.683627	val: 0.724601	test: 0.536518
PRC train: 0.547143	val: 0.544047	test: 0.511277

Epoch: 4
Loss: 0.437021620901037
ROC train: 0.748913	val: 0.833724	test: 0.563640
PRC train: 0.573637	val: 0.568225	test: 0.517149

Epoch: 5
Loss: 0.3943038019578921
ROC train: 0.783857	val: 0.866328	test: 0.589593
PRC train: 0.591379	val: 0.574982	test: 0.525054

Epoch: 6
Loss: 0.3531205746493731
ROC train: 0.785450	val: 0.853716	test: 0.653171
PRC train: 0.596434	val: 0.571362	test: 0.544521

Epoch: 7
Loss: 0.3196784423515392
ROC train: 0.821164	val: 0.874969	test: 0.638555
PRC train: 0.612975	val: 0.576783	test: 0.539894

Epoch: 8
Loss: 0.29193429790048225
ROC train: 0.841867	val: 0.835499	test: 0.613345
PRC train: 0.632974	val: 0.631186	test: 0.529477

Epoch: 9
Loss: 0.2849911327981755
ROC train: 0.854645	val: 0.862870	test: 0.649346
PRC train: 0.634046	val: 0.570012	test: 0.536990

Epoch: 10
Loss: 0.25928741697442403
ROC train: 0.868698	val: 0.844800	test: 0.648166
PRC train: 0.660989	val: 0.569839	test: 0.538045

Epoch: 11
Loss: 0.24386465437480842
ROC train: 0.878883	val: 0.830779	test: 0.616834
PRC train: 0.671277	val: 0.559039	test: 0.529189

Epoch: 12
Loss: 0.23171155967837836
ROC train: 0.892543	val: 0.863569	test: 0.634924
PRC train: 0.684285	val: 0.578742	test: 0.532774

Epoch: 13
Loss: 0.2226519961074404
ROC train: 0.896690	val: 0.873658	test: 0.678123
PRC train: 0.689762	val: 0.585504	test: 0.546475

Epoch: 14
Loss: 0.21808166803892112
ROC train: 0.907509	val: 0.847162	test: 0.685074
PRC train: 0.717996	val: 0.577752	test: 0.546114

Epoch: 15
Loss: 0.215683971159563
ROC train: 0.919199	val: 0.825135	test: 0.700150
PRC train: 0.745641	val: 0.573711	test: 0.552081

Epoch: 16
Loss: 0.20396696270040415
ROC train: 0.919983	val: 0.856302	test: 0.689706
PRC train: 0.745732	val: 0.586736	test: 0.546233

Epoch: 17
Loss: 0.2043057313836431
ROC train: 0.920262	val: 0.878103	test: 0.689542
PRC train: 0.746218	val: 0.598217	test: 0.546018

Epoch: 18
Loss: 0.19042193278531283
ROC train: 0.914300	val: 0.877917	test: 0.648588
PRC train: 0.741531	val: 0.610467	test: 0.536073

Epoch: 19
Loss: 0.19493017449889433
ROC train: 0.925283	val: 0.856551	test: 0.700068
PRC train: 0.770673	val: 0.604879	test: 0.552504

Epoch: 20
Loss: 0.18931449600785255
ROC train: 0.927100	val: 0.836110	test: 0.740611
PRC train: 0.772702	val: 0.606060	test: 0.563099

Epoch: 21
Loss: 0.1823134632986665
ROC train: 0.937147	val: 0.859598	test: 0.741335
PRC train: 0.793651	val: 0.620911	test: 0.564353

Epoch: 22
Loss: 0.17894444873911988
ROC train: 0.939920	val: 0.867090	test: 0.749979
PRC train: 0.793372	val: 0.616814	test: 0.564545

Epoch: 23
Loss: 0.17377302152552104
ROC train: 0.942770	val: 0.863270	test: 0.720989
PRC train: 0.795683	val: 0.592947	test: 0.551952

Epoch: 24
Loss: 0.18149139475051357
ROC train: 0.943337	val: 0.865256	test: 0.731527
PRC train: 0.792692	val: 0.590812	test: 0.553382

Epoch: 25
Loss: 0.1699528753288136
ROC train: 0.947180	val: 0.842017	test: 0.771113
PRC train: 0.803954	val: 0.606494	test: 0.575251

Epoch: 26
Loss: 0.18143071293520138
ROC train: 0.948519	val: 0.827845	test: 0.786009
PRC train: 0.813707	val: 0.607548	test: 0.570987

Epoch: 27
Loss: 0.16876137757802182
ROC train: 0.948790	val: 0.836785	test: 0.773063
PRC train: 0.820006	val: 0.610411	test: 0.568482

Epoch: 28
Loss: 0.17699792629775682
ROC train: 0.952490	val: 0.798875	test: 0.802874
PRC train: 0.818092	val: 0.615439	test: 0.588015

Epoch: 29
Loss: 0.16562926946086
ROC train: 0.939685	val: 0.782081	test: 0.754936
PRC train: 0.790881	val: 0.561415	test: 0.562443

Epoch: 30
Loss: 0.1650474848083653
ROC train: 0.958175	val: 0.828031	test: 0.758921
PRC train: 0.833892	val: 0.628487	test: 0.570383

Epoch: 31
Loss: 0.1745795548601929
ROC train: 0.954828	val: 0.831166	test: 0.739658
PRC train: 0.833789	val: 0.639686	test: 0.561267

Epoch: 32
Loss: 0.16024958594118072
ROC train: 0.953493	val: 0.782566	test: 0.759896
PRC train: 0.821936	val: 0.649388	test: 0.564251

Epoch: 33
Loss: 0.15849633885555175Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/clintox/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/clintox/scaff/train_prop=0.8/clintox_scaff_4_26-05_10-23-09  ]
[ Using Seed :  4  ]
[ Using device :  cuda:2  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6693450937944463
ROC train: 0.576394	val: 0.625230	test: 0.459627
PRC train: 0.523156	val: 0.529411	test: 0.504759

Epoch: 2
Loss: 0.5850384557638553
ROC train: 0.650650	val: 0.723839	test: 0.520232
PRC train: 0.541734	val: 0.544808	test: 0.512246

Epoch: 3
Loss: 0.5161426569850958
ROC train: 0.682933	val: 0.741796	test: 0.530049
PRC train: 0.550031	val: 0.552637	test: 0.508442

Epoch: 4
Loss: 0.4534557823460374
ROC train: 0.748202	val: 0.825396	test: 0.562527
PRC train: 0.579995	val: 0.566820	test: 0.517422

Epoch: 5
Loss: 0.4056429941758486
ROC train: 0.767289	val: 0.803756	test: 0.576232
PRC train: 0.588206	val: 0.583385	test: 0.523993

Epoch: 6
Loss: 0.36271536859310965
ROC train: 0.800087	val: 0.817429	test: 0.599730
PRC train: 0.607871	val: 0.566614	test: 0.533274

Epoch: 7
Loss: 0.3342892630076305
ROC train: 0.819991	val: 0.831102	test: 0.598404
PRC train: 0.615977	val: 0.562701	test: 0.530326

Epoch: 8
Loss: 0.3118345695229505
ROC train: 0.851029	val: 0.795378	test: 0.629702
PRC train: 0.649572	val: 0.548247	test: 0.542663

Epoch: 9
Loss: 0.2830998940036438
ROC train: 0.856957	val: 0.794542	test: 0.626497
PRC train: 0.653265	val: 0.546488	test: 0.532850

Epoch: 10
Loss: 0.26643921710497687
ROC train: 0.870692	val: 0.834212	test: 0.634779
PRC train: 0.660993	val: 0.555191	test: 0.536510

Epoch: 11
Loss: 0.24420751174949723
ROC train: 0.879603	val: 0.843240	test: 0.659887
PRC train: 0.675288	val: 0.561781	test: 0.548500

Epoch: 12
Loss: 0.2367447151906858
ROC train: 0.895568	val: 0.842991	test: 0.712316
PRC train: 0.703291	val: 0.566423	test: 0.577544

Epoch: 13
Loss: 0.2348870821514545
ROC train: 0.909006	val: 0.838995	test: 0.708793
PRC train: 0.723863	val: 0.570022	test: 0.568372

Epoch: 14
Loss: 0.2073028044160734
ROC train: 0.910367	val: 0.849695	test: 0.695163
PRC train: 0.727179	val: 0.571760	test: 0.562671

Epoch: 15
Loss: 0.21655390706823083
ROC train: 0.913223	val: 0.857388	test: 0.673809
PRC train: 0.721793	val: 0.572353	test: 0.552214

Epoch: 16
Loss: 0.1998363474874491
ROC train: 0.918885	val: 0.832202	test: 0.686994
PRC train: 0.747712	val: 0.584125	test: 0.554815

Epoch: 17
Loss: 0.2096962651801114
ROC train: 0.926694	val: 0.855715	test: 0.684772
PRC train: 0.755967	val: 0.580638	test: 0.551362

Epoch: 18
Loss: 0.19377878934629905
ROC train: 0.933683	val: 0.829816	test: 0.701961
PRC train: 0.762072	val: 0.562526	test: 0.557347

Epoch: 19
Loss: 0.2005195460340199
ROC train: 0.937808	val: 0.821351	test: 0.695589
PRC train: 0.764008	val: 0.557448	test: 0.553276

Epoch: 20
Loss: 0.1899035392312175
ROC train: 0.936646	val: 0.842741	test: 0.676603
PRC train: 0.765673	val: 0.589199	test: 0.551544

Epoch: 21
Loss: 0.17653474342861428
ROC train: 0.938154	val: 0.881937	test: 0.662050
PRC train: 0.779867	val: 0.624555	test: 0.545636

Epoch: 22
Loss: 0.17958975521134518
ROC train: 0.943927	val: 0.880676	test: 0.687951
PRC train: 0.795169	val: 0.607363	test: 0.549455

Epoch: 23
Loss: 0.17863813975936496
ROC train: 0.942610	val: 0.797951	test: 0.719517
PRC train: 0.790360	val: 0.587515	test: 0.555593

Epoch: 24
Loss: 0.17856659419443893
ROC train: 0.955369	val: 0.824085	test: 0.721097
PRC train: 0.817829	val: 0.584385	test: 0.567659

Epoch: 25
Loss: 0.1746189536298089
ROC train: 0.955814	val: 0.862283	test: 0.717175
PRC train: 0.825359	val: 0.571008	test: 0.568727

Epoch: 26
Loss: 0.1731714589684146
ROC train: 0.952497	val: 0.886045	test: 0.702585
PRC train: 0.821651	val: 0.582428	test: 0.573213

Epoch: 27
Loss: 0.1649147370863802
ROC train: 0.954111	val: 0.901616	test: 0.709044
PRC train: 0.817975	val: 0.613226	test: 0.572035

Epoch: 28
Loss: 0.15736129817291797
ROC train: 0.957381	val: 0.859848	test: 0.748292
PRC train: 0.826657	val: 0.612927	test: 0.569364

Epoch: 29
Loss: 0.15656686983149964
ROC train: 0.960284	val: 0.862083	test: 0.750334
PRC train: 0.839637	val: 0.624858	test: 0.565379

Epoch: 30
Loss: 0.16057349572270757
ROC train: 0.958309	val: 0.832076	test: 0.756530
PRC train: 0.832013	val: 0.627743	test: 0.579571

Epoch: 31
Loss: 0.15607475010950164
ROC train: 0.965117	val: 0.827494	test: 0.750901
PRC train: 0.846327	val: 0.645229	test: 0.571300

Epoch: 32
Loss: 0.15989485916191165
ROC train: 0.969227	val: 0.826794	test: 0.757547
PRC train: 0.852797	val: 0.620448	test: 0.575440

Epoch: 33
Loss: 0.15274809191876165Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/clintox/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/clintox/scaff/train_prop=0.8/clintox_scaff_5_26-05_10-23-09  ]
[ Using Seed :  5  ]
[ Using device :  cuda:2  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6589424586094993
ROC train: 0.549494	val: 0.621800	test: 0.462496
PRC train: 0.517662	val: 0.598453	test: 0.494749

Epoch: 2
Loss: 0.5703475314395371
ROC train: 0.612327	val: 0.698217	test: 0.488363
PRC train: 0.532402	val: 0.542496	test: 0.495925

Epoch: 3
Loss: 0.5003888135634953
ROC train: 0.687642	val: 0.768018	test: 0.502011
PRC train: 0.552771	val: 0.560326	test: 0.501732

Epoch: 4
Loss: 0.4448916223743574
ROC train: 0.736747	val: 0.791956	test: 0.513255
PRC train: 0.569651	val: 0.567858	test: 0.505447

Epoch: 5
Loss: 0.39748666467214305
ROC train: 0.760172	val: 0.811086	test: 0.555908
PRC train: 0.579446	val: 0.564547	test: 0.516279

Epoch: 6
Loss: 0.3741821246209029
ROC train: 0.772621	val: 0.835411	test: 0.558205
PRC train: 0.582014	val: 0.561965	test: 0.515811

Epoch: 7
Loss: 0.33065599807443513
ROC train: 0.819735	val: 0.876793	test: 0.587023
PRC train: 0.613733	val: 0.575083	test: 0.521752

Epoch: 8
Loss: 0.3058455507619779
ROC train: 0.831033	val: 0.854341	test: 0.561881
PRC train: 0.623748	val: 0.565333	test: 0.518014

Epoch: 9
Loss: 0.28750762764709714
ROC train: 0.839455	val: 0.847099	test: 0.555553
PRC train: 0.630903	val: 0.570694	test: 0.517099

Epoch: 10
Loss: 0.26619051975487223
ROC train: 0.872236	val: 0.872435	test: 0.616427
PRC train: 0.664883	val: 0.575404	test: 0.531678

Epoch: 11
Loss: 0.24497685187971024
ROC train: 0.880811	val: 0.844951	test: 0.616569
PRC train: 0.675271	val: 0.563712	test: 0.531647

Epoch: 12
Loss: 0.23459929266255827
ROC train: 0.895654	val: 0.883722	test: 0.626957
PRC train: 0.695088	val: 0.582079	test: 0.536652

Epoch: 13
Loss: 0.22322926854862407
ROC train: 0.901432	val: 0.853368	test: 0.629138
PRC train: 0.716465	val: 0.588816	test: 0.545455

Epoch: 14
Loss: 0.21698479234621604
ROC train: 0.892876	val: 0.792757	test: 0.623435
PRC train: 0.723899	val: 0.562419	test: 0.539704

Epoch: 15
Loss: 0.21396749777166613
ROC train: 0.907705	val: 0.767796	test: 0.631686
PRC train: 0.739355	val: 0.579991	test: 0.545045

Epoch: 16
Loss: 0.20689552592239266
ROC train: 0.917316	val: 0.813398	test: 0.643123
PRC train: 0.756319	val: 0.606199	test: 0.546010

Epoch: 17
Loss: 0.19732342590586482
ROC train: 0.926178	val: 0.842955	test: 0.655491
PRC train: 0.772763	val: 0.595242	test: 0.541713

Epoch: 18
Loss: 0.19532495295819255
ROC train: 0.932277	val: 0.873760	test: 0.674511
PRC train: 0.775982	val: 0.602602	test: 0.549110

Epoch: 19
Loss: 0.18814603206780428
ROC train: 0.934036	val: 0.904902	test: 0.644924
PRC train: 0.777690	val: 0.637873	test: 0.543485

Epoch: 20
Loss: 0.19397031425603167
ROC train: 0.920346	val: 0.879741	test: 0.624372
PRC train: 0.760840	val: 0.637393	test: 0.532587

Epoch: 21
Loss: 0.1877398011429183
ROC train: 0.935520	val: 0.896535	test: 0.682452
PRC train: 0.788215	val: 0.591503	test: 0.552093

Epoch: 22
Loss: 0.1802564051033285
ROC train: 0.943223	val: 0.890104	test: 0.693102
PRC train: 0.795652	val: 0.596436	test: 0.552621

Epoch: 23
Loss: 0.1721709137951165
ROC train: 0.943276	val: 0.856340	test: 0.700860
PRC train: 0.795890	val: 0.581400	test: 0.551024

Epoch: 24
Loss: 0.1815048354454519
ROC train: 0.948416	val: 0.872797	test: 0.721247
PRC train: 0.800822	val: 0.575327	test: 0.560063

Epoch: 25
Loss: 0.1686897967633889
ROC train: 0.949413	val: 0.879003	test: 0.731078
PRC train: 0.798641	val: 0.577208	test: 0.565981

Epoch: 26
Loss: 0.1707956708366126
ROC train: 0.948133	val: 0.846638	test: 0.728068
PRC train: 0.798145	val: 0.559114	test: 0.558511

Epoch: 27
Loss: 0.16249874288792793
ROC train: 0.955049	val: 0.811149	test: 0.772088
PRC train: 0.816300	val: 0.597066	test: 0.571971

Epoch: 28
Loss: 0.17063629041089612
ROC train: 0.957737	val: 0.856390	test: 0.796072
PRC train: 0.818589	val: 0.599408	test: 0.588955

Epoch: 29
Loss: 0.15975214049310735
ROC train: 0.961814	val: 0.833889	test: 0.800469
PRC train: 0.832869	val: 0.591622	test: 0.586403

Epoch: 30
Loss: 0.15626908844735482
ROC train: 0.961582	val: 0.850946	test: 0.792894
PRC train: 0.841731	val: 0.577410	test: 0.593646

Epoch: 31
Loss: 0.15490959043176397
ROC train: 0.960227	val: 0.880240	test: 0.777004
PRC train: 0.837085	val: 0.594065	test: 0.578317

Epoch: 32
Loss: 0.15548479862811634
ROC train: 0.963706	val: 0.877692	test: 0.780645
PRC train: 0.837627	val: 0.580287	test: 0.572809

Epoch: 33
Loss: 0.1466063763827135
ROC train: 0.966305	val: 0.677906	test: 0.810563
PRC train: 0.848853	val: 0.550475	test: 0.575616

Epoch: 34
Loss: 0.15343466868436295
ROC train: 0.967854	val: 0.673756	test: 0.794236
PRC train: 0.856736	val: 0.554604	test: 0.574194

Epoch: 35
Loss: 0.15304313677024342
ROC train: 0.966443	val: 0.674419	test: 0.774465
PRC train: 0.858153	val: 0.558571	test: 0.566044

Epoch: 36
Loss: 0.1436117783355724
ROC train: 0.963646	val: 0.699490	test: 0.794608
PRC train: 0.841685	val: 0.562842	test: 0.569835

Epoch: 37
Loss: 0.15788802364714116
ROC train: 0.967959	val: 0.698107	test: 0.818295
PRC train: 0.855413	val: 0.566468	test: 0.576880

Epoch: 38
Loss: 0.1561620444071038
ROC train: 0.967869	val: 0.679075	test: 0.790955
PRC train: 0.858359	val: 0.559195	test: 0.560380

Epoch: 39
Loss: 0.13840071724410333
ROC train: 0.966564	val: 0.688071	test: 0.781732
PRC train: 0.851660	val: 0.559851	test: 0.559244

Epoch: 40
Loss: 0.14349657941120345
ROC train: 0.966816	val: 0.705810	test: 0.787597
PRC train: 0.847242	val: 0.562487	test: 0.565250

Epoch: 41
Loss: 0.15468346765253038
ROC train: 0.971424	val: 0.700093	test: 0.782666
PRC train: 0.868503	val: 0.562855	test: 0.572402

Epoch: 42
Loss: 0.13264938174568935
ROC train: 0.964864	val: 0.669122	test: 0.751396
PRC train: 0.863009	val: 0.558623	test: 0.554620

Epoch: 43
Loss: 0.15096302366980094
ROC train: 0.968177	val: 0.664032	test: 0.757069
PRC train: 0.863669	val: 0.556980	test: 0.553898

Epoch: 44
Loss: 0.15679714872385633
ROC train: 0.973675	val: 0.669921	test: 0.771817
PRC train: 0.867881	val: 0.557174	test: 0.574535

Epoch: 45
Loss: 0.14094507002573262
ROC train: 0.968930	val: 0.660287	test: 0.760270
PRC train: 0.863718	val: 0.552308	test: 0.565850

Epoch: 46
Loss: 0.14907018166349495
ROC train: 0.971181	val: 0.651660	test: 0.779645
PRC train: 0.869572	val: 0.549251	test: 0.578571

Epoch: 47
Loss: 0.13362953611211353
ROC train: 0.972212	val: 0.654800	test: 0.792782
PRC train: 0.874974	val: 0.551563	test: 0.578966

Epoch: 48
Loss: 0.15153083064748113
ROC train: 0.973482	val: 0.654320	test: 0.800203
PRC train: 0.880925	val: 0.557016	test: 0.583002

Epoch: 49
Loss: 0.13002231682983822
ROC train: 0.976766	val: 0.660186	test: 0.801634
PRC train: 0.884343	val: 0.559511	test: 0.584929

Epoch: 50
Loss: 0.13078815670775532
ROC train: 0.975143	val: 0.663118	test: 0.803957
PRC train: 0.879066	val: 0.554655	test: 0.586892

Epoch: 51
Loss: 0.1313759554133198
ROC train: 0.976137	val: 0.662625	test: 0.810159
PRC train: 0.881599	val: 0.556801	test: 0.591144

Epoch: 52
Loss: 0.14751974190319087
ROC train: 0.975650	val: 0.662312	test: 0.815266
PRC train: 0.879191	val: 0.558693	test: 0.596068

Epoch: 53
Loss: 0.1269155623877634
ROC train: 0.975884	val: 0.658723	test: 0.811065
PRC train: 0.884265	val: 0.557318	test: 0.584625

Epoch: 54
Loss: 0.14216225269579089
ROC train: 0.976367	val: 0.637369	test: 0.795612
PRC train: 0.883659	val: 0.552332	test: 0.575403

Epoch: 55
Loss: 0.12825652121035439
ROC train: 0.978691	val: 0.633132	test: 0.789879
PRC train: 0.888523	val: 0.550516	test: 0.582319

Epoch: 56
Loss: 0.13160158628595112
ROC train: 0.977674	val: 0.656931	test: 0.802838
PRC train: 0.884133	val: 0.554779	test: 0.588224

Epoch: 57
Loss: 0.12378731414978128
ROC train: 0.980059	val: 0.643367	test: 0.787027
PRC train: 0.894036	val: 0.550764	test: 0.576581

Epoch: 58
Loss: 0.12272272043037837
ROC train: 0.979531	val: 0.645107	test: 0.799905
PRC train: 0.897170	val: 0.553903	test: 0.584163

Epoch: 59
Loss: 0.14273288161489178
ROC train: 0.980458	val: 0.638406	test: 0.804365
PRC train: 0.900360	val: 0.555755	test: 0.588365

Epoch: 60
Loss: 0.14924144890731075
ROC train: 0.978893	val: 0.637754	test: 0.809368
PRC train: 0.897189	val: 0.554319	test: 0.586293

Epoch: 61
Loss: 0.13282956369970728
ROC train: 0.978885	val: 0.661841	test: 0.834037
PRC train: 0.895544	val: 0.554819	test: 0.600584

Epoch: 62
Loss: 0.12696461205872894
ROC train: 0.979743	val: 0.663821	test: 0.827896
PRC train: 0.897645	val: 0.554247	test: 0.594509

Epoch: 63
Loss: 0.12718607368554574
ROC train: 0.979455	val: 0.663237	test: 0.803831
PRC train: 0.899538	val: 0.553362	test: 0.581774

Epoch: 64
Loss: 0.13063016099675484
ROC train: 0.981362	val: 0.677784	test: 0.795013
PRC train: 0.903834	val: 0.560037	test: 0.585184

Epoch: 65
Loss: 0.12202120084009682
ROC train: 0.980418	val: 0.681993	test: 0.803689
PRC train: 0.894233	val: 0.561374	test: 0.599883

Epoch: 66
Loss: 0.12231298679563546
ROC train: 0.981442	val: 0.660460	test: 0.793611
PRC train: 0.901665	val: 0.561046	test: 0.581868

Epoch: 67
Loss: 0.1150738967662187
ROC train: 0.978491	val: 0.646371	test: 0.768200
PRC train: 0.898765	val: 0.560700	test: 0.562178

Epoch: 68
Loss: 0.12614709313187333
ROC train: 0.981075	val: 0.658530	test: 0.793291
PRC train: 0.900558	val: 0.553060	test: 0.568758

Epoch: 69
Loss: 0.14031681176144326
ROC train: 0.981863	val: 0.676194	test: 0.798376
PRC train: 0.902864	val: 0.555976	test: 0.579948

Epoch: 70
Loss: 0.12131214250718549
ROC train: 0.981989	val: 0.689575	test: 0.801051
PRC train: 0.902105	val: 0.559319	test: 0.584433

Epoch: 71
Loss: 0.12719854454162474
ROC train: 0.980329	val: 0.685755	test: 0.800194
PRC train: 0.900932	val: 0.564113	test: 0.577744

Epoch: 72
Loss: 0.13822246220921017
ROC train: 0.979041	val: 0.695109	test: 0.811794
PRC train: 0.894828	val: 0.568649	test: 0.578403

Epoch: 73
Loss: 0.12941593771179555
ROC train: 0.981101	val: 0.705255	test: 0.827093
PRC train: 0.898771	val: 0.565924	test: 0.586195

Epoch: 74
Loss: 0.11094710633245033
ROC train: 0.981296	val: 0.696509	test: 0.834910
PRC train: 0.900497	val: 0.563845	test: 0.588105

Epoch: 75
Loss: 0.13765892833171745
ROC train: 0.981400	val: 0.673868	test: 0.824891
PRC train: 0.905886	val: 0.559794	test: 0.585129

Epoch: 76
Loss: 0.11454869921556621
ROC train: 0.981512	val: 0.685878	test: 0.834899
PRC train: 0.896845	val: 0.564216	test: 0.603983

Epoch: 77
Loss: 0.11285313070692007
ROC train: 0.982862	val: 0.682826	test: 0.815537
PRC train: 0.905700	val: 0.563534	test: 0.599696

Epoch: 78
Loss: 0.12472820993880102
ROC train: 0.983299	val: 0.678498	test: 0.803032
PRC train: 0.912985	val: 0.560835	test: 0.588066

Epoch: 79
Loss: 0.12049678226071825
ROC train: 0.982635	val: 0.689445	test: 0.807552
PRC train: 0.908081	val: 0.561856	test: 0.592456

Epoch: 80
Loss: 0.12831756828097773
ROC train: 0.981138	val: 0.693935	test: 0.812397
PRC train: 0.897349	val: 0.564757	test: 0.605813

Epoch: 81
Loss: 0.09985955477291165
ROC train: 0.982275	val: 0.673224	test: 0.795418
PRC train: 0.900936	val: 0.558990	test: 0.594728

Epoch: 82
Loss: 0.10900453643513794
ROC train: 0.983111	val: 0.668729	test: 0.783194
PRC train: 0.910362	val: 0.560436	test: 0.584566

Epoch: 83
Loss: 0.10559259552995279
ROC train: 0.982722	val: 0.668296	test: 0.777847
PRC train: 0.911967	val: 0.562405	test: 0.584039

Epoch: 84
Loss: 0.11322653259135727
ROC train: 0.983642	val: 0.687875	test: 0.801648
PRC train: 0.912782	val: 0.568146	test: 0.588194

Epoch: 85
Loss: 0.11484577851268563
ROC train: 0.984042	val: 0.690729	test: 0.812433
PRC train: 0.913429	val: 0.568298	test: 0.591744

Epoch: 86
Loss: 0.10715884783059823
ROC train: 0.984344	val: 0.681909	test: 0.813024
PRC train: 0.919472	val: 0.562240	test: 0.586060

Epoch: 87
Loss: 0.09834613595745495
ROC train: 0.984087	val: 0.682359	test: 0.831412
PRC train: 0.915344	val: 0.562721	test: 0.597377

Epoch: 88
Loss: 0.10762804334851069
ROC train: 0.984161	val: 0.682743	test: 0.836965
PRC train: 0.911812	val: 0.563370	test: 0.595830

Epoch: 89
Loss: 0.11928545462249349
ROC train: 0.984275	val: 0.674632	test: 0.832821
PRC train: 0.914247	val: 0.562915	test: 0.597047

Epoch: 90
Loss: 0.11845354640709707
ROC train: 0.984772	val: 0.671201	test: 0.828406
PRC train: 0.918005	val: 0.565293	test: 0.602762

Epoch: 91
Loss: 0.10944651106960394
ROC train: 0.983327	val: 0.670404	test: 0.828420
PRC train: 0.906747	val: 0.562163	test: 0.607097

Epoch: 92
Loss: 0.10115925880247109
ROC train: 0.984364	val: 0.675464	test: 0.833985
PRC train: 0.915476	val: 0.561826	test: 0.610325

Epoch: 93
Loss: 0.11395935352208095
ROC train: 0.984429	val: 0.667454	test: 0.834717
PRC train: 0.916650	val: 0.558454	test: 0.600466
ROC train: 0.956067	val: 0.664988	test: 0.798473
PRC train: 0.857781	val: 0.565094	test: 0.582751

Epoch: 34
Loss: 0.16597767679617212
ROC train: 0.957793	val: 0.645487	test: 0.762997
PRC train: 0.866343	val: 0.559813	test: 0.567060

Epoch: 35
Loss: 0.15613669031410127
ROC train: 0.962928	val: 0.683819	test: 0.804048
PRC train: 0.866086	val: 0.564007	test: 0.586346

Epoch: 36
Loss: 0.14634316480319598
ROC train: 0.966802	val: 0.676756	test: 0.798359
PRC train: 0.871133	val: 0.560275	test: 0.575526

Epoch: 37
Loss: 0.14945238963457738
ROC train: 0.963889	val: 0.641367	test: 0.774253
PRC train: 0.864909	val: 0.550216	test: 0.555586

Epoch: 38
Loss: 0.1495229355076034
ROC train: 0.968851	val: 0.672590	test: 0.802345
PRC train: 0.869734	val: 0.557084	test: 0.570541

Epoch: 39
Loss: 0.15687229998022212
ROC train: 0.970411	val: 0.683821	test: 0.805756
PRC train: 0.870503	val: 0.559117	test: 0.576256

Epoch: 40
Loss: 0.14187102204015586
ROC train: 0.970308	val: 0.685347	test: 0.806657
PRC train: 0.871827	val: 0.558814	test: 0.578765

Epoch: 41
Loss: 0.16586061206002625
ROC train: 0.972558	val: 0.688541	test: 0.811023
PRC train: 0.880233	val: 0.559848	test: 0.577437

Epoch: 42
Loss: 0.15402232260309742
ROC train: 0.971441	val: 0.679342	test: 0.808035
PRC train: 0.880357	val: 0.559997	test: 0.575147

Epoch: 43
Loss: 0.13777493489822865
ROC train: 0.968052	val: 0.664983	test: 0.790910
PRC train: 0.874569	val: 0.562740	test: 0.586359

Epoch: 44
Loss: 0.15648102458973398
ROC train: 0.971223	val: 0.649013	test: 0.774792
PRC train: 0.884539	val: 0.559080	test: 0.560715

Epoch: 45
Loss: 0.13799195958711336
ROC train: 0.973667	val: 0.686957	test: 0.777594
PRC train: 0.884211	val: 0.566453	test: 0.577196

Epoch: 46
Loss: 0.15660758288535104
ROC train: 0.971396	val: 0.693644	test: 0.773415
PRC train: 0.875648	val: 0.569070	test: 0.582427

Epoch: 47
Loss: 0.14220773155598962
ROC train: 0.972985	val: 0.674710	test: 0.762542
PRC train: 0.888398	val: 0.567672	test: 0.563067

Epoch: 48
Loss: 0.13601451807987774
ROC train: 0.972866	val: 0.668103	test: 0.747764
PRC train: 0.885330	val: 0.562229	test: 0.560851

Epoch: 49
Loss: 0.13176972056888397
ROC train: 0.974439	val: 0.679437	test: 0.767404
PRC train: 0.884896	val: 0.565614	test: 0.570410

Epoch: 50
Loss: 0.13500485932000228
ROC train: 0.976790	val: 0.689800	test: 0.776285
PRC train: 0.886616	val: 0.565531	test: 0.578277

Epoch: 51
Loss: 0.1213681688163936
ROC train: 0.978098	val: 0.692198	test: 0.779371
PRC train: 0.889633	val: 0.565073	test: 0.581691

Epoch: 52
Loss: 0.13509223042515223
ROC train: 0.976575	val: 0.681464	test: 0.761691
PRC train: 0.885692	val: 0.566293	test: 0.577126

Epoch: 53
Loss: 0.13471078590078914
ROC train: 0.974281	val: 0.678187	test: 0.759485
PRC train: 0.879891	val: 0.565978	test: 0.571066

Epoch: 54
Loss: 0.1415421380729346
ROC train: 0.978082	val: 0.691906	test: 0.791268
PRC train: 0.892695	val: 0.571597	test: 0.579818

Epoch: 55
Loss: 0.1276138471334472
ROC train: 0.979206	val: 0.690692	test: 0.793067
PRC train: 0.894748	val: 0.570561	test: 0.582370

Epoch: 56
Loss: 0.12109481891674743
ROC train: 0.980352	val: 0.678265	test: 0.786258
PRC train: 0.899679	val: 0.561708	test: 0.580254

Epoch: 57
Loss: 0.1357193580084634
ROC train: 0.979743	val: 0.682844	test: 0.781746
PRC train: 0.896672	val: 0.562551	test: 0.578853

Epoch: 58
Loss: 0.1243182872448092
ROC train: 0.980135	val: 0.689821	test: 0.790344
PRC train: 0.897878	val: 0.564456	test: 0.590736

Epoch: 59
Loss: 0.11447538537175267
ROC train: 0.979987	val: 0.684085	test: 0.768359
PRC train: 0.899119	val: 0.564458	test: 0.589362

Epoch: 60
Loss: 0.13038570536113134
ROC train: 0.980360	val: 0.693482	test: 0.767884
PRC train: 0.899287	val: 0.568660	test: 0.594490

Epoch: 61
Loss: 0.11896963175353951
ROC train: 0.981234	val: 0.703348	test: 0.787475
PRC train: 0.900803	val: 0.573486	test: 0.598476

Epoch: 62
Loss: 0.12316585259445345
ROC train: 0.981007	val: 0.703863	test: 0.794662
PRC train: 0.902814	val: 0.571589	test: 0.604324

Epoch: 63
Loss: 0.11884337366852692
ROC train: 0.979601	val: 0.704470	test: 0.796152
PRC train: 0.897006	val: 0.570689	test: 0.605664

Epoch: 64
Loss: 0.11489916020021704
ROC train: 0.982140	val: 0.696713	test: 0.793564
PRC train: 0.906978	val: 0.566300	test: 0.606912

Epoch: 65
Loss: 0.12281122326686722
ROC train: 0.982267	val: 0.690507	test: 0.790668
PRC train: 0.907842	val: 0.563947	test: 0.598593

Epoch: 66
Loss: 0.11581465742944627
ROC train: 0.982073	val: 0.688233	test: 0.782070
PRC train: 0.907153	val: 0.565054	test: 0.591753

Epoch: 67
Loss: 0.1147670815113093
ROC train: 0.982857	val: 0.682453	test: 0.764710
PRC train: 0.910773	val: 0.560467	test: 0.587108

Epoch: 68
Loss: 0.1072914380077383
ROC train: 0.983424	val: 0.688519	test: 0.767762
PRC train: 0.913333	val: 0.562944	test: 0.595575

Epoch: 69
Loss: 0.15245537777720022
ROC train: 0.981997	val: 0.691161	test: 0.783632
PRC train: 0.905065	val: 0.562502	test: 0.600701

Epoch: 70
Loss: 0.11494196721617425
ROC train: 0.979866	val: 0.675381	test: 0.788848
PRC train: 0.896878	val: 0.564160	test: 0.595117

Epoch: 71
Loss: 0.11774128387686952
ROC train: 0.980941	val: 0.669359	test: 0.779659
PRC train: 0.899803	val: 0.563287	test: 0.583683

Epoch: 72
Loss: 0.13172374165626072
ROC train: 0.981572	val: 0.674642	test: 0.765437
PRC train: 0.901361	val: 0.571560	test: 0.581782

Epoch: 73
Loss: 0.12938294396745084
ROC train: 0.979462	val: 0.678232	test: 0.768158
PRC train: 0.894640	val: 0.573098	test: 0.580254

Epoch: 74
Loss: 0.12865263825509565
ROC train: 0.978130	val: 0.667964	test: 0.755312
PRC train: 0.901738	val: 0.567586	test: 0.571240

Epoch: 75
Loss: 0.10874564619212292
ROC train: 0.981088	val: 0.678425	test: 0.762280
PRC train: 0.906832	val: 0.570376	test: 0.581823

Epoch: 76
Loss: 0.12388740045587085
ROC train: 0.982377	val: 0.688681	test: 0.779537
PRC train: 0.905037	val: 0.570392	test: 0.584922

Epoch: 77
Loss: 0.120876346412346
ROC train: 0.983177	val: 0.696109	test: 0.778547
PRC train: 0.907385	val: 0.568379	test: 0.588347

Epoch: 78
Loss: 0.12183316295243313
ROC train: 0.983699	val: 0.687823	test: 0.776814
PRC train: 0.911953	val: 0.562475	test: 0.592610

Epoch: 79
Loss: 0.11965204892805434
ROC train: 0.982933	val: 0.683099	test: 0.783885
PRC train: 0.902844	val: 0.565076	test: 0.603449

Epoch: 80
Loss: 0.10463775930704072
ROC train: 0.983003	val: 0.675958	test: 0.781430
PRC train: 0.903690	val: 0.566749	test: 0.600556

Epoch: 81
Loss: 0.12592233761580163
ROC train: 0.983245	val: 0.671943	test: 0.777962
PRC train: 0.905448	val: 0.566975	test: 0.595947

Epoch: 82
Loss: 0.10523669851258628
ROC train: 0.981995	val: 0.674674	test: 0.779048
PRC train: 0.905636	val: 0.568276	test: 0.594226

Epoch: 83
Loss: 0.11813810210883571
ROC train: 0.980694	val: 0.684713	test: 0.774461
PRC train: 0.902407	val: 0.570675	test: 0.591122

Epoch: 84
Loss: 0.11641448853141019
ROC train: 0.982811	val: 0.694721	test: 0.792061
PRC train: 0.912633	val: 0.570803	test: 0.606509

Epoch: 85
Loss: 0.10865284186879419
ROC train: 0.984976	val: 0.697626	test: 0.802305
PRC train: 0.920948	val: 0.572456	test: 0.612552

Epoch: 86
Loss: 0.11534600007971117
ROC train: 0.985300	val: 0.685242	test: 0.798115
PRC train: 0.922211	val: 0.566363	test: 0.601834

Epoch: 87
Loss: 0.1109615798825673
ROC train: 0.985074	val: 0.677829	test: 0.796375
PRC train: 0.921359	val: 0.563155	test: 0.597836

Epoch: 88
Loss: 0.10673529131765477
ROC train: 0.985552	val: 0.687056	test: 0.810765
PRC train: 0.923075	val: 0.564776	test: 0.618728

Epoch: 89
Loss: 0.13393438967053134
ROC train: 0.985777	val: 0.696810	test: 0.824354
PRC train: 0.923855	val: 0.567066	test: 0.627828

Epoch: 90
Loss: 0.100517895871515
ROC train: 0.985688	val: 0.700444	test: 0.824465
PRC train: 0.920422	val: 0.571556	test: 0.633898

Epoch: 91
Loss: 0.10615144846860394
ROC train: 0.986341	val: 0.696825	test: 0.810486
PRC train: 0.924110	val: 0.570291	test: 0.626909

Epoch: 92
Loss: 0.11109276999481757
ROC train: 0.986069	val: 0.702958	test: 0.794248
PRC train: 0.924506	val: 0.575292	test: 0.623968

Epoch: 93
Loss: 0.1038562178043804
ROC train: 0.985754	val: 0.704323	test: 0.781330
PRC train: 0.922261	val: 0.577921	test: 0.633620

Epoch: 94
Loss: 0.11822939642100883
ROC train: 0.967131	val: 0.698421	test: 0.786945
PRC train: 0.852300	val: 0.565393	test: 0.577656

Epoch: 34
Loss: 0.1546110583128311
ROC train: 0.965574	val: 0.701875	test: 0.786588
PRC train: 0.847639	val: 0.568382	test: 0.578491

Epoch: 35
Loss: 0.16271734790097028
ROC train: 0.965781	val: 0.690686	test: 0.787504
PRC train: 0.851591	val: 0.566793	test: 0.568897

Epoch: 36
Loss: 0.15355215630576025
ROC train: 0.966020	val: 0.683527	test: 0.794113
PRC train: 0.845292	val: 0.565195	test: 0.577526

Epoch: 37
Loss: 0.14420004124519498
ROC train: 0.969662	val: 0.680582	test: 0.795609
PRC train: 0.862598	val: 0.564530	test: 0.579250

Epoch: 38
Loss: 0.16323402782327798
ROC train: 0.971695	val: 0.676030	test: 0.788103
PRC train: 0.873069	val: 0.560541	test: 0.585551

Epoch: 39
Loss: 0.15383230982367396
ROC train: 0.971237	val: 0.660221	test: 0.780327
PRC train: 0.870035	val: 0.551387	test: 0.583386

Epoch: 40
Loss: 0.14368015898456132
ROC train: 0.967981	val: 0.669046	test: 0.776220
PRC train: 0.857386	val: 0.555144	test: 0.592939

Epoch: 41
Loss: 0.15079022157464106
ROC train: 0.966586	val: 0.665227	test: 0.768789
PRC train: 0.847290	val: 0.558538	test: 0.581175

Epoch: 42
Loss: 0.13683970057115347
ROC train: 0.969075	val: 0.666211	test: 0.754319
PRC train: 0.865563	val: 0.560624	test: 0.578887

Epoch: 43
Loss: 0.1447732550110569
ROC train: 0.971934	val: 0.672286	test: 0.754203
PRC train: 0.878097	val: 0.557142	test: 0.572305

Epoch: 44
Loss: 0.14360371561652868
ROC train: 0.973169	val: 0.696729	test: 0.777816
PRC train: 0.881404	val: 0.563929	test: 0.590726

Epoch: 45
Loss: 0.15120676921094217
ROC train: 0.973903	val: 0.692034	test: 0.775395
PRC train: 0.879071	val: 0.561992	test: 0.587111

Epoch: 46
Loss: 0.14262685023744948
ROC train: 0.974313	val: 0.674259	test: 0.755804
PRC train: 0.878420	val: 0.563641	test: 0.578472

Epoch: 47
Loss: 0.14132336533949752
ROC train: 0.977242	val: 0.669264	test: 0.742754
PRC train: 0.891392	val: 0.566208	test: 0.572294

Epoch: 48
Loss: 0.1586265445717243
ROC train: 0.977310	val: 0.675794	test: 0.751764
PRC train: 0.885572	val: 0.568333	test: 0.571281

Epoch: 49
Loss: 0.1307172210916552
ROC train: 0.976293	val: 0.676793	test: 0.776006
PRC train: 0.880926	val: 0.566240	test: 0.580347

Epoch: 50
Loss: 0.1309110187563675
ROC train: 0.977681	val: 0.672541	test: 0.783108
PRC train: 0.886694	val: 0.565106	test: 0.575631

Epoch: 51
Loss: 0.14553008571076145
ROC train: 0.978274	val: 0.663859	test: 0.776142
PRC train: 0.888722	val: 0.565493	test: 0.573406

Epoch: 52
Loss: 0.12363923819553911
ROC train: 0.976861	val: 0.683508	test: 0.793231
PRC train: 0.884981	val: 0.574418	test: 0.580329

Epoch: 53
Loss: 0.12653873002558952
ROC train: 0.974945	val: 0.687955	test: 0.798284
PRC train: 0.879411	val: 0.571920	test: 0.583067

Epoch: 54
Loss: 0.12532487493322733
ROC train: 0.977352	val: 0.681313	test: 0.806689
PRC train: 0.882087	val: 0.567757	test: 0.591331

Epoch: 55
Loss: 0.12478440592013654
ROC train: 0.978331	val: 0.676074	test: 0.804753
PRC train: 0.885652	val: 0.563779	test: 0.589482

Epoch: 56
Loss: 0.12976576028117054
ROC train: 0.978439	val: 0.676760	test: 0.795297
PRC train: 0.888280	val: 0.565631	test: 0.587604

Epoch: 57
Loss: 0.12052364398294807
ROC train: 0.979770	val: 0.678648	test: 0.786171
PRC train: 0.894910	val: 0.572735	test: 0.586365

Epoch: 58
Loss: 0.13444503764935445
ROC train: 0.978396	val: 0.682586	test: 0.785667
PRC train: 0.888787	val: 0.571807	test: 0.591149

Epoch: 59
Loss: 0.14531139895358056
ROC train: 0.977738	val: 0.684728	test: 0.780367
PRC train: 0.888145	val: 0.567248	test: 0.585241

Epoch: 60
Loss: 0.12481328623307662
ROC train: 0.976144	val: 0.689080	test: 0.786940
PRC train: 0.883089	val: 0.565500	test: 0.585936

Epoch: 61
Loss: 0.12795108382594936
ROC train: 0.973764	val: 0.675030	test: 0.780553
PRC train: 0.879247	val: 0.560371	test: 0.574299

Epoch: 62
Loss: 0.13728129260196908
ROC train: 0.973412	val: 0.671729	test: 0.775560
PRC train: 0.879849	val: 0.558478	test: 0.570330

Epoch: 63
Loss: 0.12016235238793627
ROC train: 0.978556	val: 0.672259	test: 0.782089
PRC train: 0.891863	val: 0.557516	test: 0.570632

Epoch: 64
Loss: 0.126048284670188
ROC train: 0.981634	val: 0.665892	test: 0.792588
PRC train: 0.900324	val: 0.555974	test: 0.575688

Epoch: 65
Loss: 0.12572085012708759
ROC train: 0.981438	val: 0.663073	test: 0.783733
PRC train: 0.900435	val: 0.555043	test: 0.575446

Epoch: 66
Loss: 0.11616989303804838
ROC train: 0.980904	val: 0.673556	test: 0.787206
PRC train: 0.897271	val: 0.557650	test: 0.585336

Epoch: 67
Loss: 0.11643273802480755
ROC train: 0.980495	val: 0.681213	test: 0.795073
PRC train: 0.895895	val: 0.564134	test: 0.586525

Epoch: 68
Loss: 0.13402419848817151
ROC train: 0.982590	val: 0.665609	test: 0.801357
PRC train: 0.906999	val: 0.564525	test: 0.578932

Epoch: 69
Loss: 0.1258152906905784
ROC train: 0.982968	val: 0.651561	test: 0.802400
PRC train: 0.912115	val: 0.564592	test: 0.575298

Epoch: 70
Loss: 0.12309116078883514
ROC train: 0.983474	val: 0.652930	test: 0.807529
PRC train: 0.909465	val: 0.564227	test: 0.582715

Epoch: 71
Loss: 0.1195971304495749
ROC train: 0.982706	val: 0.659593	test: 0.809919
PRC train: 0.901435	val: 0.558668	test: 0.594803

Epoch: 72
Loss: 0.1184796709359287
ROC train: 0.981663	val: 0.662113	test: 0.799739
PRC train: 0.899091	val: 0.560019	test: 0.584941

Epoch: 73
Loss: 0.11107915142015587
ROC train: 0.981825	val: 0.675874	test: 0.797646
PRC train: 0.899603	val: 0.565719	test: 0.578253

Epoch: 74
Loss: 0.11464527727338421
ROC train: 0.981960	val: 0.679495	test: 0.792486
PRC train: 0.901074	val: 0.566748	test: 0.575538

Epoch: 75
Loss: 0.11448400961823674
ROC train: 0.980741	val: 0.676581	test: 0.784774
PRC train: 0.898048	val: 0.565960	test: 0.570035

Epoch: 76
Loss: 0.11148340065774767
ROC train: 0.982281	val: 0.668927	test: 0.801342
PRC train: 0.899611	val: 0.565598	test: 0.580553

Epoch: 77
Loss: 0.11137703250463865
ROC train: 0.982493	val: 0.657721	test: 0.812594
PRC train: 0.898342	val: 0.565606	test: 0.580945

Epoch: 78
Loss: 0.11825936192544187
ROC train: 0.983069	val: 0.645949	test: 0.809318
PRC train: 0.902333	val: 0.561365	test: 0.576607

Epoch: 79
Loss: 0.11248935067326035
ROC train: 0.983882	val: 0.645556	test: 0.817744
PRC train: 0.904659	val: 0.562838	test: 0.582839

Epoch: 80
Loss: 0.11762854440356146
ROC train: 0.982493	val: 0.649771	test: 0.814519
PRC train: 0.900815	val: 0.563247	test: 0.596344

Epoch: 81
Loss: 0.10308669492727088
ROC train: 0.982096	val: 0.662315	test: 0.804893
PRC train: 0.898005	val: 0.567585	test: 0.596590

Epoch: 82
Loss: 0.1013829265744546
ROC train: 0.981733	val: 0.658977	test: 0.789230
PRC train: 0.896145	val: 0.566332	test: 0.588462

Epoch: 83
Loss: 0.1175409587384456
ROC train: 0.983207	val: 0.659219	test: 0.784085
PRC train: 0.901272	val: 0.562509	test: 0.589398

Epoch: 84
Loss: 0.10164519696887565
ROC train: 0.983631	val: 0.652853	test: 0.804195
PRC train: 0.905683	val: 0.557088	test: 0.595233

Epoch: 85
Loss: 0.10368673854370006
ROC train: 0.981788	val: 0.643848	test: 0.801055
PRC train: 0.905374	val: 0.559168	test: 0.589631

Epoch: 86
Loss: 0.10704582233561637
ROC train: 0.983119	val: 0.649485	test: 0.810712
PRC train: 0.913067	val: 0.555104	test: 0.592289

Epoch: 87
Loss: 0.113756678583182
ROC train: 0.984046	val: 0.658836	test: 0.816271
PRC train: 0.910762	val: 0.558927	test: 0.601204

Epoch: 88
Loss: 0.11515298317616827
ROC train: 0.983081	val: 0.664185	test: 0.806023
PRC train: 0.907032	val: 0.557283	test: 0.604851

Epoch: 89
Loss: 0.11251068570279402
ROC train: 0.984690	val: 0.668055	test: 0.802597
PRC train: 0.913653	val: 0.558850	test: 0.610044

Epoch: 90
Loss: 0.10582704155214784
ROC train: 0.985736	val: 0.659126	test: 0.802300
PRC train: 0.921493	val: 0.561166	test: 0.603942

Epoch: 91
Loss: 0.1172478118925194
ROC train: 0.985738	val: 0.664289	test: 0.804886
PRC train: 0.920403	val: 0.564484	test: 0.607568

Epoch: 92
Loss: 0.10998623511058438
ROC train: 0.985515	val: 0.667084	test: 0.800070
PRC train: 0.919186	val: 0.564534	test: 0.600455

Epoch: 93
Loss: 0.10057525914925423
ROC train: 0.986039	val: 0.649279	test: 0.783209
PRC train: 0.922285	val: 0.560392	test: 0.592573

Epoch: 94
Loss: 0.12517334342371708
ROC train: 0.929677	val: 0.718210	test: 0.763991
PRC train: 0.753747	val: 0.589235	test: 0.593164

Epoch: 34
Loss: 0.1630863762808094
ROC train: 0.935377	val: 0.716229	test: 0.771466
PRC train: 0.766131	val: 0.586037	test: 0.591682

Epoch: 35
Loss: 0.1644791494708401
ROC train: 0.940698	val: 0.709046	test: 0.762444
PRC train: 0.787419	val: 0.583384	test: 0.587988

Epoch: 36
Loss: 0.22340636418897378
ROC train: 0.934311	val: 0.684268	test: 0.719960
PRC train: 0.782141	val: 0.566939	test: 0.546563

Epoch: 37
Loss: 0.15804486787758826
ROC train: 0.911234	val: 0.683196	test: 0.685680
PRC train: 0.746640	val: 0.575779	test: 0.536222

Epoch: 38
Loss: 0.16748795171270472
ROC train: 0.925274	val: 0.718909	test: 0.708815
PRC train: 0.771016	val: 0.590640	test: 0.544953

Epoch: 39
Loss: 0.16553085097468517
ROC train: 0.936924	val: 0.734324	test: 0.710878
PRC train: 0.769307	val: 0.599692	test: 0.554854

Epoch: 40
Loss: 0.15418184357085635
ROC train: 0.938353	val: 0.686783	test: 0.698707
PRC train: 0.768277	val: 0.579759	test: 0.566177

Epoch: 41
Loss: 0.1506749011881249
ROC train: 0.935017	val: 0.661930	test: 0.701746
PRC train: 0.763042	val: 0.572656	test: 0.551005

Epoch: 42
Loss: 0.14469791824460992
ROC train: 0.934253	val: 0.664692	test: 0.707120
PRC train: 0.756131	val: 0.567976	test: 0.557415

Epoch: 43
Loss: 0.16530879199293294
ROC train: 0.937615	val: 0.681743	test: 0.697193
PRC train: 0.773978	val: 0.575051	test: 0.571461

Epoch: 44
Loss: 0.1738217015333415
ROC train: 0.930782	val: 0.696122	test: 0.704492
PRC train: 0.761694	val: 0.572988	test: 0.570552

Epoch: 45
Loss: 0.22257587035382423
ROC train: 0.929481	val: 0.721025	test: 0.727029
PRC train: 0.753611	val: 0.580029	test: 0.567971

Epoch: 46
Loss: 0.15969288877016125
ROC train: 0.930475	val: 0.741121	test: 0.748073
PRC train: 0.764270	val: 0.586325	test: 0.556310

Epoch: 47
Loss: 0.2176131207832314
ROC train: 0.919673	val: 0.753962	test: 0.765369
PRC train: 0.736721	val: 0.581946	test: 0.561112

Epoch: 48
Loss: 0.1599219379582383
ROC train: 0.918996	val: 0.753344	test: 0.754626
PRC train: 0.729673	val: 0.582197	test: 0.572128

Epoch: 49
Loss: 0.163737311681651
ROC train: 0.930254	val: 0.760080	test: 0.757738
PRC train: 0.754123	val: 0.593667	test: 0.606111

Epoch: 50
Loss: 0.23021954480919132
ROC train: 0.933385	val: 0.761690	test: 0.766117
PRC train: 0.764790	val: 0.603630	test: 0.635090

Epoch: 51
Loss: 0.20360284181878102
ROC train: 0.928657	val: 0.758656	test: 0.776868
PRC train: 0.745605	val: 0.599044	test: 0.600234

Epoch: 52
Loss: 0.1637646176485382
ROC train: 0.915885	val: 0.750770	test: 0.812464
PRC train: 0.736357	val: 0.621324	test: 0.601377

Epoch: 53
Loss: 0.17912746106396882
ROC train: 0.917826	val: 0.747242	test: 0.810888
PRC train: 0.754837	val: 0.592718	test: 0.576178

Epoch: 54
Loss: 0.21147345032834863
ROC train: 0.922838	val: 0.744629	test: 0.809706
PRC train: 0.765370	val: 0.590129	test: 0.598478

Epoch: 55
Loss: 0.17399216544517687
ROC train: 0.911677	val: 0.718513	test: 0.758399
PRC train: 0.748117	val: 0.565907	test: 0.577468

Epoch: 56
Loss: 0.15771135818733018
ROC train: 0.917036	val: 0.697275	test: 0.723146
PRC train: 0.753179	val: 0.557831	test: 0.561933

Epoch: 57
Loss: 0.24366878309875123
ROC train: 0.933273	val: 0.711960	test: 0.731190
PRC train: 0.771206	val: 0.570384	test: 0.561331

Epoch: 58
Loss: 0.15502224118945004
ROC train: 0.940456	val: 0.720678	test: 0.742523
PRC train: 0.789626	val: 0.577590	test: 0.595840

Epoch: 59
Loss: 0.14730904278824858
ROC train: 0.947219	val: 0.711897	test: 0.740643
PRC train: 0.800447	val: 0.579413	test: 0.590109

Epoch: 60
Loss: 0.15549511241102076
ROC train: 0.953167	val: 0.699075	test: 0.719994
PRC train: 0.809836	val: 0.575490	test: 0.556227

Epoch: 61
Loss: 0.1399054136308315
ROC train: 0.953746	val: 0.678067	test: 0.681618
PRC train: 0.811444	val: 0.564337	test: 0.545164

Epoch: 62
Loss: 0.23157497966458457
ROC train: 0.953489	val: 0.669782	test: 0.668321
PRC train: 0.815280	val: 0.558134	test: 0.544789

Epoch: 63
Loss: 0.19302251297682224
ROC train: 0.949701	val: 0.664383	test: 0.668330
PRC train: 0.799210	val: 0.556408	test: 0.541091

Epoch: 64
Loss: 0.20876471802126795
ROC train: 0.949411	val: 0.661146	test: 0.672976
PRC train: 0.791564	val: 0.556828	test: 0.541579

Epoch: 65
Loss: 0.20723036368618714
ROC train: 0.948195	val: 0.659629	test: 0.669228
PRC train: 0.789330	val: 0.563909	test: 0.547625

Epoch: 66
Loss: 0.22588556452306996
ROC train: 0.949660	val: 0.706929	test: 0.698265
PRC train: 0.794575	val: 0.596594	test: 0.558004

Epoch: 67
Loss: 0.1565347909306971
ROC train: 0.947426	val: 0.729170	test: 0.665742
PRC train: 0.795653	val: 0.614895	test: 0.538889

Epoch: 68
Loss: 0.1501694748073885
ROC train: 0.944865	val: 0.730136	test: 0.664619
PRC train: 0.787908	val: 0.604518	test: 0.540897

Epoch: 69
Loss: 0.16980258341172777
ROC train: 0.946378	val: 0.727480	test: 0.692653
PRC train: 0.794497	val: 0.597546	test: 0.540800

Epoch: 70
Loss: 0.17085923440393208
ROC train: 0.947564	val: 0.712269	test: 0.650487
PRC train: 0.797984	val: 0.594468	test: 0.545155

Epoch: 71
Loss: 0.14915324015031003
ROC train: 0.949769	val: 0.695835	test: 0.648684
PRC train: 0.804425	val: 0.590362	test: 0.567228

Epoch: 72
Loss: 0.14230874235010335
ROC train: 0.952229	val: 0.701011	test: 0.688018
PRC train: 0.808145	val: 0.587684	test: 0.554983

Epoch: 73
Loss: 0.14742645203458715
ROC train: 0.951676	val: 0.713383	test: 0.699328
PRC train: 0.809633	val: 0.589042	test: 0.551248

Epoch: 74
Loss: 0.14056560282376884
ROC train: 0.943012	val: 0.710078	test: 0.720272
PRC train: 0.807831	val: 0.595042	test: 0.556659

Epoch: 75
Loss: 0.1606553798904627
ROC train: 0.955434	val: 0.720243	test: 0.708259
PRC train: 0.822677	val: 0.593613	test: 0.551308

Epoch: 76
Loss: 0.18298908466343522
ROC train: 0.956346	val: 0.717877	test: 0.695050
PRC train: 0.821036	val: 0.597009	test: 0.541307

Epoch: 77
Loss: 0.14684436998396283
ROC train: 0.954498	val: 0.714460	test: 0.705873
PRC train: 0.813897	val: 0.591241	test: 0.542794

Epoch: 78
Loss: 0.1347199316907359
ROC train: 0.954653	val: 0.714126	test: 0.704421
PRC train: 0.815174	val: 0.581227	test: 0.540347

Epoch: 79
Loss: 0.18416811901365565
ROC train: 0.955994	val: 0.711600	test: 0.705561
PRC train: 0.819619	val: 0.578349	test: 0.538435

Epoch: 80
Loss: 0.14622391157515963
ROC train: 0.954179	val: 0.716455	test: 0.713874
PRC train: 0.822995	val: 0.580885	test: 0.541826

Epoch: 81
Loss: 0.16265198582078227
ROC train: 0.952013	val: 0.717173	test: 0.727015
PRC train: 0.822508	val: 0.583559	test: 0.551000

Epoch: 82
Loss: 0.1295149098444586
ROC train: 0.943393	val: 0.717073	test: 0.738685
PRC train: 0.798882	val: 0.589044	test: 0.561604

Epoch: 83
Loss: 0.14851876140371378
ROC train: 0.955602	val: 0.702212	test: 0.717012
PRC train: 0.832112	val: 0.585585	test: 0.549213

Epoch: 84
Loss: 0.1380326750882185
ROC train: 0.959564	val: 0.671118	test: 0.676819
PRC train: 0.838359	val: 0.574231	test: 0.537130

Epoch: 85
Loss: 0.13604459498922492
ROC train: 0.957966	val: 0.659305	test: 0.693075
PRC train: 0.816850	val: 0.566158	test: 0.542812

Epoch: 86
Loss: 0.18850712321884294
ROC train: 0.957553	val: 0.672494	test: 0.712341
PRC train: 0.813602	val: 0.571508	test: 0.546268

Epoch: 87
Loss: 0.12532406063572207
ROC train: 0.962110	val: 0.690004	test: 0.716542
PRC train: 0.832893	val: 0.594269	test: 0.548744

Epoch: 88
Loss: 0.1273848924661288
ROC train: 0.961500	val: 0.703142	test: 0.710221
PRC train: 0.834066	val: 0.598098	test: 0.546301

Epoch: 89
Loss: 0.1890889098404843
ROC train: 0.958988	val: 0.707600	test: 0.694433
PRC train: 0.831039	val: 0.597800	test: 0.543347

Epoch: 90
Loss: 0.20055210210153876
ROC train: 0.945381	val: 0.692347	test: 0.670717
PRC train: 0.809272	val: 0.585284	test: 0.537562

Epoch: 91
Loss: 0.15672955448844098
ROC train: 0.914826	val: 0.676324	test: 0.661774
PRC train: 0.787169	val: 0.583406	test: 0.532663

Epoch: 92
Loss: 0.15612881411705412
ROC train: 0.949237	val: 0.735056	test: 0.701196
PRC train: 0.816424	val: 0.600876	test: 0.547950

Epoch: 93
Loss: 0.14116782243655293
ROC train: 0.951206	val: 0.749600	test: 0.705884
PRC train: 0.806479	val: 0.591915	test: 0.553389

Epoch: 94
Loss: 0.15325399531836448
ROC train: 0.921043	val: 0.650513	test: 0.726649
PRC train: 0.757568	val: 0.557084	test: 0.550248

Epoch: 34
Loss: 0.25523982427359976
ROC train: 0.919312	val: 0.653970	test: 0.744121
PRC train: 0.765489	val: 0.550031	test: 0.549495

Epoch: 35
Loss: 0.20236322950007762
ROC train: 0.910359	val: 0.649364	test: 0.732217
PRC train: 0.757408	val: 0.552874	test: 0.547320

Epoch: 36
Loss: 0.17072237022429335
ROC train: 0.911077	val: 0.635272	test: 0.680090
PRC train: 0.755363	val: 0.544745	test: 0.536233

Epoch: 37
Loss: 0.16708856024365465
ROC train: 0.923194	val: 0.658143	test: 0.685419
PRC train: 0.766566	val: 0.548177	test: 0.537540

Epoch: 38
Loss: 0.21707322015171376
ROC train: 0.926144	val: 0.681901	test: 0.714113
PRC train: 0.762146	val: 0.553876	test: 0.544659

Epoch: 39
Loss: 0.16225434602758745
ROC train: 0.895230	val: 0.691580	test: 0.689330
PRC train: 0.734030	val: 0.556359	test: 0.542844

Epoch: 40
Loss: 0.16694617360396055
ROC train: 0.900286	val: 0.701599	test: 0.706159
PRC train: 0.741815	val: 0.557629	test: 0.548209

Epoch: 41
Loss: 0.19057953835270106
ROC train: 0.926615	val: 0.707258	test: 0.736689
PRC train: 0.770762	val: 0.565264	test: 0.562667

Epoch: 42
Loss: 0.174521864176729
ROC train: 0.929927	val: 0.697075	test: 0.777171
PRC train: 0.773412	val: 0.566600	test: 0.567937

Epoch: 43
Loss: 0.17902319641367329
ROC train: 0.924164	val: 0.681830	test: 0.772874
PRC train: 0.757849	val: 0.565375	test: 0.563648

Epoch: 44
Loss: 0.17644625520883994
ROC train: 0.920970	val: 0.658797	test: 0.717245
PRC train: 0.745165	val: 0.555219	test: 0.545554

Epoch: 45
Loss: 0.14788880228845275
ROC train: 0.931179	val: 0.676208	test: 0.746375
PRC train: 0.774037	val: 0.561524	test: 0.561457

Epoch: 46
Loss: 0.17092565533621873
ROC train: 0.925580	val: 0.688147	test: 0.733282
PRC train: 0.774676	val: 0.567304	test: 0.547770

Epoch: 47
Loss: 0.18012278594312547
ROC train: 0.924046	val: 0.691679	test: 0.727064
PRC train: 0.741025	val: 0.578258	test: 0.538951

Epoch: 48
Loss: 0.1843687465401043
ROC train: 0.928540	val: 0.697720	test: 0.705249
PRC train: 0.758403	val: 0.585382	test: 0.534799

Epoch: 49
Loss: 0.19764220640414848
ROC train: 0.929151	val: 0.700307	test: 0.711924
PRC train: 0.765443	val: 0.569701	test: 0.536817

Epoch: 50
Loss: 0.20877921617950745
ROC train: 0.931456	val: 0.713346	test: 0.752245
PRC train: 0.770140	val: 0.582932	test: 0.553859

Epoch: 51
Loss: 0.1556161441058568
ROC train: 0.929238	val: 0.713087	test: 0.753237
PRC train: 0.775154	val: 0.581103	test: 0.559130

Epoch: 52
Loss: 0.14278400463081858
ROC train: 0.931035	val: 0.702623	test: 0.757659
PRC train: 0.788708	val: 0.581446	test: 0.560819

Epoch: 53
Loss: 0.15201154198545047
ROC train: 0.934101	val: 0.711179	test: 0.744198
PRC train: 0.800778	val: 0.584507	test: 0.553838

Epoch: 54
Loss: 0.1598617370784485
ROC train: 0.938701	val: 0.720466	test: 0.740947
PRC train: 0.807349	val: 0.590768	test: 0.550041

Epoch: 55
Loss: 0.14605435433289457
ROC train: 0.938556	val: 0.713777	test: 0.730981
PRC train: 0.800268	val: 0.584420	test: 0.544526

Epoch: 56
Loss: 0.17198189959070664
ROC train: 0.939651	val: 0.718024	test: 0.738503
PRC train: 0.806069	val: 0.589242	test: 0.547644

Epoch: 57
Loss: 0.1493180073827512
ROC train: 0.932456	val: 0.718704	test: 0.728841
PRC train: 0.776930	val: 0.602517	test: 0.546431

Epoch: 58
Loss: 0.14499518369922001
ROC train: 0.940246	val: 0.712884	test: 0.748560
PRC train: 0.795682	val: 0.596361	test: 0.550913

Epoch: 59
Loss: 0.1406893586141739
ROC train: 0.944690	val: 0.700935	test: 0.754014
PRC train: 0.815251	val: 0.590497	test: 0.548751

Epoch: 60
Loss: 0.18178795295373035
ROC train: 0.947189	val: 0.701964	test: 0.758736
PRC train: 0.820639	val: 0.590926	test: 0.549520

Epoch: 61
Loss: 0.1428028345209194
ROC train: 0.951030	val: 0.704441	test: 0.755953
PRC train: 0.820796	val: 0.592458	test: 0.551050

Epoch: 62
Loss: 0.14154636167027768
ROC train: 0.953530	val: 0.706818	test: 0.754178
PRC train: 0.824113	val: 0.593180	test: 0.551999

Epoch: 63
Loss: 0.19124979093419273
ROC train: 0.956623	val: 0.702743	test: 0.735142
PRC train: 0.830591	val: 0.593073	test: 0.549757

Epoch: 64
Loss: 0.16421452292172173
ROC train: 0.951877	val: 0.688454	test: 0.708061
PRC train: 0.824581	val: 0.581440	test: 0.541918

Epoch: 65
Loss: 0.13501615324196684
ROC train: 0.955484	val: 0.703326	test: 0.738209
PRC train: 0.829387	val: 0.586568	test: 0.555570

Epoch: 66
Loss: 0.16798686035381702
ROC train: 0.956434	val: 0.708069	test: 0.735261
PRC train: 0.827313	val: 0.583541	test: 0.566568

Epoch: 67
Loss: 0.12855903483348047
ROC train: 0.955095	val: 0.689766	test: 0.693310
PRC train: 0.823509	val: 0.571289	test: 0.548110

Epoch: 68
Loss: 0.13414937632475593
ROC train: 0.948435	val: 0.670412	test: 0.674376
PRC train: 0.821247	val: 0.559484	test: 0.535988

Epoch: 69
Loss: 0.1737147349497526
ROC train: 0.951673	val: 0.683427	test: 0.707505
PRC train: 0.826359	val: 0.570131	test: 0.540815

Epoch: 70
Loss: 0.16041519208742344
ROC train: 0.956756	val: 0.695762	test: 0.742387
PRC train: 0.831507	val: 0.580423	test: 0.545688

Epoch: 71
Loss: 0.1506194152241302
ROC train: 0.950758	val: 0.704208	test: 0.755527
PRC train: 0.821951	val: 0.601903	test: 0.550072

Epoch: 72
Loss: 0.13340712619258033
ROC train: 0.948929	val: 0.706820	test: 0.726100
PRC train: 0.827592	val: 0.601782	test: 0.542543

Epoch: 73
Loss: 0.13201843066430116
ROC train: 0.946946	val: 0.704096	test: 0.694552
PRC train: 0.831296	val: 0.592194	test: 0.535067

Epoch: 74
Loss: 0.13533623896324748
ROC train: 0.954061	val: 0.711178	test: 0.715164
PRC train: 0.840582	val: 0.598654	test: 0.538909

Epoch: 75
Loss: 0.12505224737011927
ROC train: 0.957128	val: 0.716676	test: 0.725459
PRC train: 0.835184	val: 0.594552	test: 0.542757

Epoch: 76
Loss: 0.20974236062452833
ROC train: 0.957861	val: 0.732198	test: 0.738192
PRC train: 0.832531	val: 0.603523	test: 0.549612

Epoch: 77
Loss: 0.15528048268012584
ROC train: 0.946886	val: 0.749850	test: 0.726978
PRC train: 0.807352	val: 0.601146	test: 0.547178

Epoch: 78
Loss: 0.21504369478365065
ROC train: 0.947292	val: 0.744241	test: 0.716652
PRC train: 0.803598	val: 0.601523	test: 0.541635

Epoch: 79
Loss: 0.1321514303968479
ROC train: 0.948755	val: 0.722373	test: 0.690192
PRC train: 0.807607	val: 0.587952	test: 0.535333

Epoch: 80
Loss: 0.23445972441869975
ROC train: 0.946628	val: 0.716851	test: 0.702245
PRC train: 0.799516	val: 0.600598	test: 0.535719

Epoch: 81
Loss: 0.21638454340698368
ROC train: 0.946373	val: 0.726059	test: 0.727228
PRC train: 0.814029	val: 0.585610	test: 0.545891

Epoch: 82
Loss: 0.14537535611214839
ROC train: 0.935606	val: 0.739263	test: 0.719864
PRC train: 0.791821	val: 0.590711	test: 0.553357

Epoch: 83
Loss: 0.21283060715642615
ROC train: 0.918386	val: 0.721617	test: 0.698633
PRC train: 0.733352	val: 0.583190	test: 0.542111

Epoch: 84
Loss: 0.17677250358670954
ROC train: 0.889119	val: 0.668259	test: 0.652017
PRC train: 0.675452	val: 0.558145	test: 0.525665

Epoch: 85
Loss: 0.1756593254894448
ROC train: 0.920901	val: 0.669498	test: 0.705567
PRC train: 0.744593	val: 0.568249	test: 0.538089

Epoch: 86
Loss: 0.1525797771508347
ROC train: 0.935936	val: 0.675033	test: 0.702591
PRC train: 0.769554	val: 0.581449	test: 0.540504

Epoch: 87
Loss: 0.14178924679418942
ROC train: 0.944996	val: 0.683800	test: 0.694450
PRC train: 0.794017	val: 0.587773	test: 0.542452

Epoch: 88
Loss: 0.164032172106585
ROC train: 0.949884	val: 0.684605	test: 0.710652
PRC train: 0.807782	val: 0.591711	test: 0.551428

Epoch: 89
Loss: 0.16524545283472453
ROC train: 0.945707	val: 0.674277	test: 0.739071
PRC train: 0.777284	val: 0.600358	test: 0.561590

Epoch: 90
Loss: 0.16632795116667956
ROC train: 0.920346	val: 0.621239	test: 0.635657
PRC train: 0.760043	val: 0.557652	test: 0.523971

Epoch: 91
Loss: 0.20847263461576215
ROC train: 0.858962	val: 0.571425	test: 0.551285
PRC train: 0.673202	val: 0.530919	test: 0.513433

Epoch: 92
Loss: 0.17703899111549232
ROC train: 0.881735	val: 0.604661	test: 0.586197
PRC train: 0.693324	val: 0.538699	test: 0.517032

Epoch: 93
Loss: 0.24100127475492045
ROC train: 0.946941	val: 0.692567	test: 0.721536
PRC train: 0.796670	val: 0.587673	test: 0.539819

Epoch: 94
Loss: 0.17804420661219716
ROC train: 0.932250	val: 0.704804	test: 0.695119
PRC train: 0.769800	val: 0.608372	test: 0.544966

Epoch: 34
Loss: 0.1736944824668927
ROC train: 0.934791	val: 0.692022	test: 0.698174
PRC train: 0.774301	val: 0.596127	test: 0.540160

Epoch: 35
Loss: 0.17834735246652084
ROC train: 0.930587	val: 0.687899	test: 0.725127
PRC train: 0.753016	val: 0.592993	test: 0.545524

Epoch: 36
Loss: 0.25842329611615833
ROC train: 0.916692	val: 0.684744	test: 0.713906
PRC train: 0.734280	val: 0.583677	test: 0.548426

Epoch: 37
Loss: 0.26331068154531406
ROC train: 0.930749	val: 0.664101	test: 0.711689
PRC train: 0.754769	val: 0.576942	test: 0.542319

Epoch: 38
Loss: 0.16398090472722354
ROC train: 0.921019	val: 0.664843	test: 0.707227
PRC train: 0.746113	val: 0.583829	test: 0.550495

Epoch: 39
Loss: 0.16111663679397542
ROC train: 0.911097	val: 0.667729	test: 0.695595
PRC train: 0.733361	val: 0.586868	test: 0.562182

Epoch: 40
Loss: 0.20290450751020428
ROC train: 0.920239	val: 0.675828	test: 0.693282
PRC train: 0.744054	val: 0.587029	test: 0.555789

Epoch: 41
Loss: 0.2509769907682705
ROC train: 0.925187	val: 0.700666	test: 0.683367
PRC train: 0.755314	val: 0.603644	test: 0.557559

Epoch: 42
Loss: 0.18373716744223817
ROC train: 0.904251	val: 0.709084	test: 0.670294
PRC train: 0.726730	val: 0.585406	test: 0.535483

Epoch: 43
Loss: 0.24838441970184427
ROC train: 0.901218	val: 0.693903	test: 0.640313
PRC train: 0.735072	val: 0.580636	test: 0.528249

Epoch: 44
Loss: 0.16862214541190224
ROC train: 0.923536	val: 0.704427	test: 0.639035
PRC train: 0.770727	val: 0.600678	test: 0.537220

Epoch: 45
Loss: 0.1594515230241088
ROC train: 0.927183	val: 0.712105	test: 0.654954
PRC train: 0.783688	val: 0.625400	test: 0.539484

Epoch: 46
Loss: 0.1546813442371437
ROC train: 0.930917	val: 0.716094	test: 0.663542
PRC train: 0.782529	val: 0.621227	test: 0.557191

Epoch: 47
Loss: 0.1596008096714619
ROC train: 0.936511	val: 0.713289	test: 0.672766
PRC train: 0.785790	val: 0.606233	test: 0.560781

Epoch: 48
Loss: 0.17979527510707194
ROC train: 0.941139	val: 0.711141	test: 0.673077
PRC train: 0.790413	val: 0.593552	test: 0.545570

Epoch: 49
Loss: 0.14970949270293094
ROC train: 0.934984	val: 0.698918	test: 0.666598
PRC train: 0.759568	val: 0.588009	test: 0.535745

Epoch: 50
Loss: 0.15738650259361334
ROC train: 0.944324	val: 0.683447	test: 0.659642
PRC train: 0.789254	val: 0.582912	test: 0.543946

Epoch: 51
Loss: 0.19385666635877047
ROC train: 0.948240	val: 0.681124	test: 0.663908
PRC train: 0.804260	val: 0.585086	test: 0.555620

Epoch: 52
Loss: 0.15308526982621834
ROC train: 0.939089	val: 0.677954	test: 0.651195
PRC train: 0.791432	val: 0.580143	test: 0.536648

Epoch: 53
Loss: 0.19600077184882853
ROC train: 0.940294	val: 0.672951	test: 0.673409
PRC train: 0.791272	val: 0.573825	test: 0.543062

Epoch: 54
Loss: 0.1534344771448932
ROC train: 0.875060	val: 0.684096	test: 0.713990
PRC train: 0.722774	val: 0.567415	test: 0.559167

Epoch: 55
Loss: 0.15938913178824038
ROC train: 0.935503	val: 0.684950	test: 0.723446
PRC train: 0.778919	val: 0.575057	test: 0.560651

Epoch: 56
Loss: 0.18981800347399352
ROC train: 0.956475	val: 0.685633	test: 0.735363
PRC train: 0.809707	val: 0.586797	test: 0.573049

Epoch: 57
Loss: 0.2596983170974258
ROC train: 0.948998	val: 0.682377	test: 0.731749
PRC train: 0.799279	val: 0.594446	test: 0.575512

Epoch: 58
Loss: 0.14163671078915635
ROC train: 0.950219	val: 0.687317	test: 0.715737
PRC train: 0.814264	val: 0.603872	test: 0.547810

Epoch: 59
Loss: 0.20811007188860567
ROC train: 0.947253	val: 0.694486	test: 0.713758
PRC train: 0.802718	val: 0.602041	test: 0.551025

Epoch: 60
Loss: 0.15788185716093975
ROC train: 0.940674	val: 0.714930	test: 0.713469
PRC train: 0.774737	val: 0.588639	test: 0.561526

Epoch: 61
Loss: 0.18294327687762527
ROC train: 0.953451	val: 0.708120	test: 0.721723
PRC train: 0.805952	val: 0.598521	test: 0.575374

Epoch: 62
Loss: 0.17147332756746314
ROC train: 0.935183	val: 0.703862	test: 0.731604
PRC train: 0.773521	val: 0.597649	test: 0.570676

Epoch: 63
Loss: 0.23366155242552056
ROC train: 0.942244	val: 0.704514	test: 0.727233
PRC train: 0.782786	val: 0.601070	test: 0.570974

Epoch: 64
Loss: 0.1484395226585568
ROC train: 0.937926	val: 0.689908	test: 0.710266
PRC train: 0.779019	val: 0.581339	test: 0.561732

Epoch: 65
Loss: 0.15008037062884033
ROC train: 0.934541	val: 0.687938	test: 0.710482
PRC train: 0.785602	val: 0.577526	test: 0.552150

Epoch: 66
Loss: 0.158488107563885
ROC train: 0.941711	val: 0.704901	test: 0.704172
PRC train: 0.799529	val: 0.584967	test: 0.542438

Epoch: 67
Loss: 0.16669789392687942
ROC train: 0.951629	val: 0.721221	test: 0.682885
PRC train: 0.809270	val: 0.589768	test: 0.537344

Epoch: 68
Loss: 0.14696445755037446
ROC train: 0.916440	val: 0.696109	test: 0.660107
PRC train: 0.755456	val: 0.574128	test: 0.530932

Epoch: 69
Loss: 0.18924466340900972
ROC train: 0.934033	val: 0.709829	test: 0.676462
PRC train: 0.783124	val: 0.590640	test: 0.536636

Epoch: 70
Loss: 0.14828552747289395
ROC train: 0.949407	val: 0.718673	test: 0.696207
PRC train: 0.802017	val: 0.589625	test: 0.550200

Epoch: 71
Loss: 0.15729737320713785
ROC train: 0.950925	val: 0.711838	test: 0.701037
PRC train: 0.803398	val: 0.573197	test: 0.554914

Epoch: 72
Loss: 0.18273051729016945
ROC train: 0.951598	val: 0.702800	test: 0.702236
PRC train: 0.808367	val: 0.569571	test: 0.550176

Epoch: 73
Loss: 0.13967046295511615
ROC train: 0.949611	val: 0.693141	test: 0.694393
PRC train: 0.807105	val: 0.568174	test: 0.547866

Epoch: 74
Loss: 0.14118192496160215
ROC train: 0.950231	val: 0.697896	test: 0.684693
PRC train: 0.806775	val: 0.571453	test: 0.542373

Epoch: 75
Loss: 0.1862322502607563
ROC train: 0.949830	val: 0.699691	test: 0.682114
PRC train: 0.803938	val: 0.573811	test: 0.542084

Epoch: 76
Loss: 0.14360742374341476
ROC train: 0.948870	val: 0.689523	test: 0.693718
PRC train: 0.806909	val: 0.571712	test: 0.546175

Epoch: 77
Loss: 0.13114037742981105
ROC train: 0.949953	val: 0.694413	test: 0.709832
PRC train: 0.812281	val: 0.578211	test: 0.547592

Epoch: 78
Loss: 0.13208823068466627
ROC train: 0.953724	val: 0.698461	test: 0.732778
PRC train: 0.815580	val: 0.603258	test: 0.547466

Epoch: 79
Loss: 0.1753204137943391
ROC train: 0.956766	val: 0.700053	test: 0.738529
PRC train: 0.821568	val: 0.612352	test: 0.550872

Epoch: 80
Loss: 0.19936559160445863
ROC train: 0.944067	val: 0.690857	test: 0.723622
PRC train: 0.800873	val: 0.607126	test: 0.571175

Epoch: 81
Loss: 0.15040767252144663
ROC train: 0.936830	val: 0.681211	test: 0.727925
PRC train: 0.789443	val: 0.607199	test: 0.578027

Epoch: 82
Loss: 0.13805785851146302
ROC train: 0.949243	val: 0.694856	test: 0.742806
PRC train: 0.808025	val: 0.606892	test: 0.575922

Epoch: 83
Loss: 0.14027139326910001
ROC train: 0.957714	val: 0.706608	test: 0.743407
PRC train: 0.823709	val: 0.608383	test: 0.564295

Epoch: 84
Loss: 0.1746744569908092
ROC train: 0.959782	val: 0.703129	test: 0.733124
PRC train: 0.836938	val: 0.602432	test: 0.556936

Epoch: 85
Loss: 0.1852736034157382
ROC train: 0.949477	val: 0.667309	test: 0.737415
PRC train: 0.819206	val: 0.598220	test: 0.562136

Epoch: 86
Loss: 0.17481808343327204
ROC train: 0.938335	val: 0.658271	test: 0.739354
PRC train: 0.798429	val: 0.596382	test: 0.576360

Epoch: 87
Loss: 0.13551367824725719
ROC train: 0.953616	val: 0.674120	test: 0.731825
PRC train: 0.821638	val: 0.585754	test: 0.569710

Epoch: 88
Loss: 0.13449840706173488
ROC train: 0.956027	val: 0.680904	test: 0.697879
PRC train: 0.827919	val: 0.585566	test: 0.567415

Epoch: 89
Loss: 0.13793075354112158
ROC train: 0.958939	val: 0.680210	test: 0.685881
PRC train: 0.836783	val: 0.590396	test: 0.573278

Epoch: 90
Loss: 0.1402716534967415
ROC train: 0.962759	val: 0.684798	test: 0.675793
PRC train: 0.840977	val: 0.597884	test: 0.559488

Epoch: 91
Loss: 0.17041865880087426
ROC train: 0.963942	val: 0.685015	test: 0.675773
PRC train: 0.843253	val: 0.595439	test: 0.546129

Epoch: 92
Loss: 0.1639780232427236
ROC train: 0.958385	val: 0.673523	test: 0.664778
PRC train: 0.829182	val: 0.575606	test: 0.535946

Epoch: 93
Loss: 0.15343091784613683
ROC train: 0.961115	val: 0.690390	test: 0.690226
PRC train: 0.823696	val: 0.580390	test: 0.543372

Epoch: 94
Loss: 0.12993421345728123
ROC train: 0.958197	val: 0.787735	test: 0.772514
PRC train: 0.827562	val: 0.644048	test: 0.568562

Epoch: 34
Loss: 0.15406902342108938
ROC train: 0.961540	val: 0.817180	test: 0.762432
PRC train: 0.842160	val: 0.634139	test: 0.562716

Epoch: 35
Loss: 0.16260158094640403
ROC train: 0.960511	val: 0.888979	test: 0.747816
PRC train: 0.838465	val: 0.654064	test: 0.560694

Epoch: 36
Loss: 0.15281073080595775
ROC train: 0.962516	val: 0.884896	test: 0.769589
PRC train: 0.845481	val: 0.640386	test: 0.572674

Epoch: 37
Loss: 0.15620559390189453
ROC train: 0.959473	val: 0.883385	test: 0.774710
PRC train: 0.829928	val: 0.621641	test: 0.565226

Epoch: 38
Loss: 0.1510689309643347
ROC train: 0.961374	val: 0.848434	test: 0.794804
PRC train: 0.840984	val: 0.621352	test: 0.581459

Epoch: 39
Loss: 0.14713278653653805
ROC train: 0.966675	val: 0.793892	test: 0.789976
PRC train: 0.856664	val: 0.595187	test: 0.582043

Epoch: 40
Loss: 0.14228196950306687
ROC train: 0.969071	val: 0.773225	test: 0.799901
PRC train: 0.858712	val: 0.607430	test: 0.594781

Epoch: 41
Loss: 0.1554663219157811
ROC train: 0.970796	val: 0.765284	test: 0.793611
PRC train: 0.863029	val: 0.595469	test: 0.594544

Epoch: 42
Loss: 0.14774305213859057
ROC train: 0.971359	val: 0.751136	test: 0.800906
PRC train: 0.865249	val: 0.652856	test: 0.613838

Epoch: 43
Loss: 0.14428928972493008
ROC train: 0.967700	val: 0.763186	test: 0.801231
PRC train: 0.864138	val: 0.668743	test: 0.592455

Epoch: 44
Loss: 0.13353383974731492
ROC train: 0.964850	val: 0.823972	test: 0.784840
PRC train: 0.859255	val: 0.604550	test: 0.571586

Epoch: 45
Loss: 0.13759423716075725
ROC train: 0.971059	val: 0.851207	test: 0.802023
PRC train: 0.874005	val: 0.641255	test: 0.579335

Epoch: 46
Loss: 0.14329381016514153
ROC train: 0.972743	val: 0.844189	test: 0.811223
PRC train: 0.871521	val: 0.620474	test: 0.602171

Epoch: 47
Loss: 0.1319583126719929
ROC train: 0.971891	val: 0.821238	test: 0.794309
PRC train: 0.865753	val: 0.591647	test: 0.578133

Epoch: 48
Loss: 0.1442073586145637
ROC train: 0.972540	val: 0.827132	test: 0.780425
PRC train: 0.869243	val: 0.608445	test: 0.581133

Epoch: 49
Loss: 0.13465662039693801
ROC train: 0.972420	val: 0.779431	test: 0.787317
PRC train: 0.872959	val: 0.624515	test: 0.589535

Epoch: 50
Loss: 0.14693896466276724
ROC train: 0.975841	val: 0.795652	test: 0.786316
PRC train: 0.876734	val: 0.603214	test: 0.583134

Epoch: 51
Loss: 0.14304415140023755
ROC train: 0.976807	val: 0.804069	test: 0.803730
PRC train: 0.881495	val: 0.614543	test: 0.598005

Epoch: 52
Loss: 0.134450683941575
ROC train: 0.976615	val: 0.809238	test: 0.826377
PRC train: 0.877280	val: 0.606069	test: 0.598706

Epoch: 53
Loss: 0.13528356377350423
ROC train: 0.976878	val: 0.779495	test: 0.823385
PRC train: 0.885416	val: 0.646876	test: 0.610570

Epoch: 54
Loss: 0.13557649736415728
ROC train: 0.977178	val: 0.811873	test: 0.831647
PRC train: 0.885497	val: 0.616785	test: 0.613643

Epoch: 55
Loss: 0.12938626503886835
ROC train: 0.977557	val: 0.818079	test: 0.818394
PRC train: 0.881982	val: 0.602893	test: 0.607783

Epoch: 56
Loss: 0.12308213804371722
ROC train: 0.976444	val: 0.831777	test: 0.825902
PRC train: 0.876164	val: 0.614293	test: 0.618188

Epoch: 57
Loss: 0.139624333699502
ROC train: 0.976465	val: 0.759141	test: 0.848475
PRC train: 0.879361	val: 0.592157	test: 0.634538

Epoch: 58
Loss: 0.1252349826340666
ROC train: 0.971516	val: 0.716336	test: 0.837900
PRC train: 0.851100	val: 0.574427	test: 0.626394

Epoch: 59
Loss: 0.1393383016432757
ROC train: 0.979775	val: 0.731394	test: 0.872608
PRC train: 0.887209	val: 0.609239	test: 0.656213

Epoch: 60
Loss: 0.1275459740768184
ROC train: 0.979487	val: 0.756193	test: 0.858855
PRC train: 0.890536	val: 0.627987	test: 0.627425

Epoch: 61
Loss: 0.13012546668968672
ROC train: 0.974918	val: 0.791369	test: 0.793872
PRC train: 0.872146	val: 0.644099	test: 0.578745

Epoch: 62
Loss: 0.11954001832995484
ROC train: 0.978440	val: 0.798924	test: 0.788038
PRC train: 0.885558	val: 0.636249	test: 0.583212

Epoch: 63
Loss: 0.11484428804274378
ROC train: 0.977042	val: 0.814108	test: 0.797021
PRC train: 0.876301	val: 0.631325	test: 0.606843

Epoch: 64
Loss: 0.13496322763373153
ROC train: 0.975878	val: 0.833875	test: 0.809056
PRC train: 0.868076	val: 0.654299	test: 0.597003

Epoch: 65
Loss: 0.12186492980784865
ROC train: 0.978397	val: 0.860073	test: 0.826713
PRC train: 0.885517	val: 0.665030	test: 0.603577

Epoch: 66
Loss: 0.1501659468263985
ROC train: 0.981553	val: 0.837421	test: 0.852796
PRC train: 0.903198	val: 0.663628	test: 0.612072

Epoch: 67
Loss: 0.11534306465282221
ROC train: 0.981286	val: 0.818153	test: 0.857944
PRC train: 0.899239	val: 0.634894	test: 0.619412

Epoch: 68
Loss: 0.1163930951728545
ROC train: 0.980969	val: 0.807389	test: 0.845389
PRC train: 0.895871	val: 0.636413	test: 0.648857

Epoch: 69
Loss: 0.1224142165292377
ROC train: 0.980835	val: 0.801184	test: 0.839730
PRC train: 0.897050	val: 0.643357	test: 0.628086

Epoch: 70
Loss: 0.13591151511564661
ROC train: 0.979914	val: 0.811810	test: 0.841247
PRC train: 0.887173	val: 0.629043	test: 0.604537

Epoch: 71
Loss: 0.1233849020640773
ROC train: 0.979574	val: 0.796577	test: 0.846600
PRC train: 0.888891	val: 0.639088	test: 0.610863

Epoch: 72
Loss: 0.11865296447587707
ROC train: 0.980482	val: 0.845001	test: 0.837082
PRC train: 0.886799	val: 0.667223	test: 0.599932

Epoch: 73
Loss: 0.1091924598290068
ROC train: 0.979003	val: 0.875781	test: 0.825902
PRC train: 0.881357	val: 0.639939	test: 0.592079

Epoch: 74
Loss: 0.1327304333523524
ROC train: 0.981725	val: 0.850620	test: 0.833283
PRC train: 0.896795	val: 0.645603	test: 0.608761

Epoch: 75
Loss: 0.1312872396339675
ROC train: 0.982958	val: 0.822412	test: 0.820460
PRC train: 0.905047	val: 0.684302	test: 0.633034

Epoch: 76
Loss: 0.10783871773467957
ROC train: 0.983401	val: 0.809551	test: 0.815970
PRC train: 0.909135	val: 0.665022	test: 0.632807

Epoch: 77
Loss: 0.11949903494939432
ROC train: 0.981766	val: 0.842678	test: 0.812960
PRC train: 0.902989	val: 0.654108	test: 0.607059

Epoch: 78
Loss: 0.11004022390190053
ROC train: 0.979979	val: 0.869575	test: 0.821805
PRC train: 0.896570	val: 0.629142	test: 0.605721

Epoch: 79
Loss: 0.11565011362364044
ROC train: 0.982542	val: 0.838032	test: 0.856883
PRC train: 0.906130	val: 0.645978	test: 0.625181

Epoch: 80
Loss: 0.10699756725715115
ROC train: 0.985067	val: 0.749126	test: 0.881267
PRC train: 0.916778	val: 0.589935	test: 0.641569

Epoch: 81
Loss: 0.11168962706767278
ROC train: 0.984927	val: 0.743257	test: 0.875795
PRC train: 0.916788	val: 0.582584	test: 0.638071

Epoch: 82
Loss: 0.11480496350131512
ROC train: 0.984172	val: 0.786449	test: 0.840604
PRC train: 0.914118	val: 0.612950	test: 0.630807

Epoch: 83
Loss: 0.11079249531869698
ROC train: 0.984030	val: 0.809962	test: 0.809512
PRC train: 0.914405	val: 0.640772	test: 0.622676

Epoch: 84
Loss: 0.11673638445109562
ROC train: 0.984731	val: 0.805991	test: 0.805041
PRC train: 0.918053	val: 0.648937	test: 0.624046

Epoch: 85
Loss: 0.1054969677936711
ROC train: 0.985283	val: 0.817204	test: 0.812448
PRC train: 0.919410	val: 0.663357	test: 0.623273

Epoch: 86
Loss: 0.10466252938534806
ROC train: 0.985673	val: 0.830628	test: 0.812792
PRC train: 0.921712	val: 0.626095	test: 0.619362

Epoch: 87
Loss: 0.11111206256145509
ROC train: 0.985134	val: 0.827718	test: 0.854608
PRC train: 0.917702	val: 0.624356	test: 0.646106

Epoch: 88
Loss: 0.10572458026406946
ROC train: 0.982573	val: 0.792606	test: 0.869448
PRC train: 0.907627	val: 0.602875	test: 0.649931

Epoch: 89
Loss: 0.10618958186891062
ROC train: 0.983916	val: 0.780443	test: 0.870248
PRC train: 0.913308	val: 0.608425	test: 0.701857

Epoch: 90
Loss: 0.11498981213394174
ROC train: 0.984703	val: 0.793804	test: 0.857749
PRC train: 0.917234	val: 0.643863	test: 0.709325

Epoch: 91
Loss: 0.10476024990809725
ROC train: 0.985021	val: 0.825371	test: 0.842566
PRC train: 0.921347	val: 0.682704	test: 0.693863

Epoch: 92
Loss: 0.11051914034685884
ROC train: 0.984958	val: 0.815556	test: 0.850548
PRC train: 0.922328	val: 0.653883	test: 0.697503

Epoch: 93
Loss: 0.1040689393832233
ROC train: 0.984716	val: 0.792405	test: 0.862964
PRC train: 0.920178	val: 0.658444	test: 0.712404

Epoch: 94
Loss: 0.11061602895949083
ROC train: 0.964414	val: 0.886969	test: 0.781732
PRC train: 0.841561	val: 0.607127	test: 0.574738

Epoch: 34
Loss: 0.1542546749699351
ROC train: 0.962724	val: 0.868865	test: 0.758010
PRC train: 0.840957	val: 0.573531	test: 0.560037

Epoch: 35
Loss: 0.156458628410371
ROC train: 0.967186	val: 0.869613	test: 0.759765
PRC train: 0.848543	val: 0.608101	test: 0.566351

Epoch: 36
Loss: 0.16049360976964872
ROC train: 0.967810	val: 0.889854	test: 0.757472
PRC train: 0.854003	val: 0.634610	test: 0.568185

Epoch: 37
Loss: 0.1526223270054016
ROC train: 0.964677	val: 0.860810	test: 0.762481
PRC train: 0.849101	val: 0.597268	test: 0.567346

Epoch: 38
Loss: 0.14822464284108433
ROC train: 0.969853	val: 0.815707	test: 0.798582
PRC train: 0.850031	val: 0.593767	test: 0.589587

Epoch: 39
Loss: 0.1442192724596954
ROC train: 0.969863	val: 0.823449	test: 0.817782
PRC train: 0.848061	val: 0.591188	test: 0.590925

Epoch: 40
Loss: 0.1423319416837729
ROC train: 0.972049	val: 0.832339	test: 0.789001
PRC train: 0.861228	val: 0.602253	test: 0.575440

Epoch: 41
Loss: 0.1463168906170264
ROC train: 0.969744	val: 0.788698	test: 0.796771
PRC train: 0.864953	val: 0.561623	test: 0.579650

Epoch: 42
Loss: 0.14273242868539462
ROC train: 0.972627	val: 0.840619	test: 0.784579
PRC train: 0.865218	val: 0.570831	test: 0.576530

Epoch: 43
Loss: 0.15075253479922018
ROC train: 0.972651	val: 0.793006	test: 0.784104
PRC train: 0.865478	val: 0.575295	test: 0.574415

Epoch: 44
Loss: 0.13998391388431264
ROC train: 0.974358	val: 0.829156	test: 0.767509
PRC train: 0.870699	val: 0.579663	test: 0.567401

Epoch: 45
Loss: 0.13751470090669954
ROC train: 0.971437	val: 0.835748	test: 0.768002
PRC train: 0.862570	val: 0.606297	test: 0.567763

Epoch: 46
Loss: 0.14647326374802228
ROC train: 0.972675	val: 0.812548	test: 0.780007
PRC train: 0.867519	val: 0.581102	test: 0.577828

Epoch: 47
Loss: 0.13777413156883708
ROC train: 0.974773	val: 0.803770	test: 0.780007
PRC train: 0.876412	val: 0.569525	test: 0.578063

Epoch: 48
Loss: 0.1358319243118875
ROC train: 0.975712	val: 0.850208	test: 0.794810
PRC train: 0.877550	val: 0.579247	test: 0.588647

Epoch: 49
Loss: 0.13820921194232386
ROC train: 0.975674	val: 0.855627	test: 0.821379
PRC train: 0.876834	val: 0.606727	test: 0.601850

Epoch: 50
Loss: 0.13139745423236832
ROC train: 0.975142	val: 0.846399	test: 0.845038
PRC train: 0.874896	val: 0.662765	test: 0.615152

Epoch: 51
Loss: 0.1373325186142529
ROC train: 0.977671	val: 0.855965	test: 0.811010
PRC train: 0.885765	val: 0.594448	test: 0.590383

Epoch: 52
Loss: 0.14066276314079532
ROC train: 0.976381	val: 0.889204	test: 0.786402
PRC train: 0.882711	val: 0.612225	test: 0.577265

Epoch: 53
Loss: 0.13152310470651166
ROC train: 0.972252	val: 0.835611	test: 0.758932
PRC train: 0.871567	val: 0.599816	test: 0.563621

Epoch: 54
Loss: 0.14492837421038735
ROC train: 0.978326	val: 0.811599	test: 0.771300
PRC train: 0.888730	val: 0.608893	test: 0.571138

Epoch: 55
Loss: 0.13155447285144767
ROC train: 0.977413	val: 0.793730	test: 0.813897
PRC train: 0.880913	val: 0.630790	test: 0.593508

Epoch: 56
Loss: 0.13380111332697214
ROC train: 0.975175	val: 0.796914	test: 0.817745
PRC train: 0.872956	val: 0.631927	test: 0.594102

Epoch: 57
Loss: 0.12792728681661875
ROC train: 0.977183	val: 0.815082	test: 0.824771
PRC train: 0.881489	val: 0.601256	test: 0.600408

Epoch: 58
Loss: 0.13066679711833873
ROC train: 0.979511	val: 0.745830	test: 0.822429
PRC train: 0.890887	val: 0.572207	test: 0.598848

Epoch: 59
Loss: 0.13939545017275007
ROC train: 0.978251	val: 0.786786	test: 0.844302
PRC train: 0.885382	val: 0.598268	test: 0.623644

Epoch: 60
Loss: 0.1291000459013263
ROC train: 0.979778	val: 0.839831	test: 0.843103
PRC train: 0.891793	val: 0.582314	test: 0.623255

Epoch: 61
Loss: 0.1214080534311617
ROC train: 0.978831	val: 0.824872	test: 0.840829
PRC train: 0.887103	val: 0.566559	test: 0.615418

Epoch: 62
Loss: 0.12400918505427157
ROC train: 0.979251	val: 0.831977	test: 0.854089
PRC train: 0.890878	val: 0.572350	test: 0.644610

Epoch: 63
Loss: 0.1309402022794132
ROC train: 0.980578	val: 0.794816	test: 0.852445
PRC train: 0.896123	val: 0.593875	test: 0.627598

Epoch: 64
Loss: 0.11345539265549412
ROC train: 0.979556	val: 0.764036	test: 0.843152
PRC train: 0.896127	val: 0.560211	test: 0.609888

Epoch: 65
Loss: 0.12384933496368992
ROC train: 0.978677	val: 0.760339	test: 0.842328
PRC train: 0.893601	val: 0.568939	test: 0.614918

Epoch: 66
Loss: 0.13749390475801965
ROC train: 0.979881	val: 0.789896	test: 0.855893
PRC train: 0.894005	val: 0.578276	test: 0.609637

Epoch: 67
Loss: 0.1241536437241512
ROC train: 0.978875	val: 0.826833	test: 0.848374
PRC train: 0.888201	val: 0.604011	test: 0.605604

Epoch: 68
Loss: 0.12062565731431776
ROC train: 0.978458	val: 0.778409	test: 0.878604
PRC train: 0.884636	val: 0.576198	test: 0.627860

Epoch: 69
Loss: 0.12251000832503647
ROC train: 0.980607	val: 0.810612	test: 0.873807
PRC train: 0.893052	val: 0.605365	test: 0.630221

Epoch: 70
Loss: 0.12292778663314403
ROC train: 0.981527	val: 0.825034	test: 0.831685
PRC train: 0.898170	val: 0.559082	test: 0.598457

Epoch: 71
Loss: 0.12282308869871565
ROC train: 0.982098	val: 0.787261	test: 0.831453
PRC train: 0.902680	val: 0.551885	test: 0.599454

Epoch: 72
Loss: 0.12435207858364854
ROC train: 0.980550	val: 0.728347	test: 0.859591
PRC train: 0.900833	val: 0.599351	test: 0.610182

Epoch: 73
Loss: 0.11180541091083018
ROC train: 0.982378	val: 0.740685	test: 0.864850
PRC train: 0.905788	val: 0.586727	test: 0.620501

Epoch: 74
Loss: 0.10852107449945783
ROC train: 0.982922	val: 0.749389	test: 0.851190
PRC train: 0.908572	val: 0.562399	test: 0.615705

Epoch: 75
Loss: 0.11662102585065004
ROC train: 0.983358	val: 0.772726	test: 0.855381
PRC train: 0.907476	val: 0.568288	test: 0.623506

Epoch: 76
Loss: 0.12233516491479177
ROC train: 0.980751	val: 0.758354	test: 0.846237
PRC train: 0.898866	val: 0.563921	test: 0.611165

Epoch: 77
Loss: 0.11619459493890236
ROC train: 0.980532	val: 0.716585	test: 0.855419
PRC train: 0.895871	val: 0.560424	test: 0.617803

Epoch: 78
Loss: 0.11179629757686904
ROC train: 0.983671	val: 0.730484	test: 0.859953
PRC train: 0.907802	val: 0.555243	test: 0.622516

Epoch: 79
Loss: 0.12339651076200267
ROC train: 0.984639	val: 0.757943	test: 0.853633
PRC train: 0.914569	val: 0.561792	test: 0.620865

Epoch: 80
Loss: 0.1207551441736823
ROC train: 0.981974	val: 0.730571	test: 0.847537
PRC train: 0.903817	val: 0.587537	test: 0.613062

Epoch: 81
Loss: 0.10417411953047011
ROC train: 0.983803	val: 0.753297	test: 0.827919
PRC train: 0.908607	val: 0.625230	test: 0.614656

Epoch: 82
Loss: 0.11393255314628577
ROC train: 0.984418	val: 0.762051	test: 0.821879
PRC train: 0.914713	val: 0.577334	test: 0.611287

Epoch: 83
Loss: 0.11200839815941452
ROC train: 0.985097	val: 0.763361	test: 0.830299
PRC train: 0.920932	val: 0.572632	test: 0.610522

Epoch: 84
Loss: 0.11160999501130506
ROC train: 0.985004	val: 0.781705	test: 0.861178
PRC train: 0.921309	val: 0.580655	test: 0.621676

Epoch: 85
Loss: 0.1121062342625154
ROC train: 0.983819	val: 0.768257	test: 0.860984
PRC train: 0.916988	val: 0.564832	test: 0.624583

Epoch: 86
Loss: 0.11834254392451497
ROC train: 0.982993	val: 0.760902	test: 0.865388
PRC train: 0.913238	val: 0.575640	test: 0.635756

Epoch: 87
Loss: 0.1190133466869637
ROC train: 0.984264	val: 0.750725	test: 0.861003
PRC train: 0.915817	val: 0.595575	test: 0.628051

Epoch: 88
Loss: 0.10470809960480065
ROC train: 0.985087	val: 0.764398	test: 0.854694
PRC train: 0.919551	val: 0.605247	test: 0.617752

Epoch: 89
Loss: 0.11144168085968373
ROC train: 0.985472	val: 0.756344	test: 0.855419
PRC train: 0.919132	val: 0.600510	test: 0.618916

Epoch: 90
Loss: 0.11547272916673398
ROC train: 0.985309	val: 0.757405	test: 0.865000
PRC train: 0.916512	val: 0.604470	test: 0.620973

Epoch: 91
Loss: 0.10875711510405028
ROC train: 0.986080	val: 0.743932	test: 0.853458
PRC train: 0.922672	val: 0.585210	test: 0.620460

Epoch: 92
Loss: 0.11325984180571007
ROC train: 0.985672	val: 0.774687	test: 0.866049
PRC train: 0.918948	val: 0.593986	test: 0.619303

Epoch: 93
Loss: 0.10986814834578626
ROC train: 0.985035	val: 0.800909	test: 0.868772
PRC train: 0.913178	val: 0.631769	test: 0.622157

Epoch: 94
Loss: 0.10058642040602825
ROC train: 0.964179	val: 0.864767	test: 0.747883
PRC train: 0.838229	val: 0.627070	test: 0.565433

Epoch: 34
Loss: 0.14909810626214562
ROC train: 0.965773	val: 0.877404	test: 0.734111
PRC train: 0.847693	val: 0.626900	test: 0.566561

Epoch: 35
Loss: 0.1554991116948956
ROC train: 0.967810	val: 0.848859	test: 0.737522
PRC train: 0.853838	val: 0.603193	test: 0.562045

Epoch: 36
Loss: 0.15191320991293597
ROC train: 0.968668	val: 0.836697	test: 0.732550
PRC train: 0.861080	val: 0.593816	test: 0.566589

Epoch: 37
Loss: 0.16084546071108333
ROC train: 0.967649	val: 0.749013	test: 0.753031
PRC train: 0.859139	val: 0.584189	test: 0.566044

Epoch: 38
Loss: 0.14739571674540303
ROC train: 0.968071	val: 0.692423	test: 0.785602
PRC train: 0.860658	val: 0.580703	test: 0.579172

Epoch: 39
Loss: 0.14845621850634855
ROC train: 0.963639	val: 0.655349	test: 0.801604
PRC train: 0.845244	val: 0.606610	test: 0.578454

Epoch: 40
Loss: 0.14504976879096979
ROC train: 0.969338	val: 0.754270	test: 0.780593
PRC train: 0.859119	val: 0.629102	test: 0.574800

Epoch: 41
Loss: 0.14058493846609782
ROC train: 0.971035	val: 0.779519	test: 0.780956
PRC train: 0.867258	val: 0.634232	test: 0.582836

Epoch: 42
Loss: 0.13997807967526005
ROC train: 0.970369	val: 0.831777	test: 0.776802
PRC train: 0.861917	val: 0.637414	test: 0.580121

Epoch: 43
Loss: 0.13920395629752222
ROC train: 0.968931	val: 0.855652	test: 0.766104
PRC train: 0.859346	val: 0.639161	test: 0.566224

Epoch: 44
Loss: 0.1440286601901199
ROC train: 0.969539	val: 0.839181	test: 0.773750
PRC train: 0.863170	val: 0.625703	test: 0.570796

Epoch: 45
Loss: 0.1399030052982832
ROC train: 0.971772	val: 0.812397	test: 0.803214
PRC train: 0.868410	val: 0.621276	test: 0.591533

Epoch: 46
Loss: 0.13732391545233846
ROC train: 0.975050	val: 0.831552	test: 0.791564
PRC train: 0.884439	val: 0.610433	test: 0.580584

Epoch: 47
Loss: 0.13699427504509004
ROC train: 0.974122	val: 0.820676	test: 0.815922
PRC train: 0.880299	val: 0.618423	test: 0.596135

Epoch: 48
Loss: 0.13299125867894657
ROC train: 0.968633	val: 0.844663	test: 0.821099
PRC train: 0.866458	val: 0.623656	test: 0.601325

Epoch: 49
Loss: 0.13948052321765542
ROC train: 0.974316	val: 0.823698	test: 0.802729
PRC train: 0.880238	val: 0.634052	test: 0.588410

Epoch: 50
Loss: 0.12487090951391688
ROC train: 0.973892	val: 0.800572	test: 0.784941
PRC train: 0.872401	val: 0.654539	test: 0.587396

Epoch: 51
Loss: 0.1451569851827667
ROC train: 0.975618	val: 0.803057	test: 0.765342
PRC train: 0.877666	val: 0.631665	test: 0.578034

Epoch: 52
Loss: 0.13220832876384164
ROC train: 0.973074	val: 0.836497	test: 0.758036
PRC train: 0.874372	val: 0.621020	test: 0.568049

Epoch: 53
Loss: 0.12879125680780618
ROC train: 0.975228	val: 0.822324	test: 0.767479
PRC train: 0.884217	val: 0.609615	test: 0.567786

Epoch: 54
Loss: 0.13919962659678872
ROC train: 0.974430	val: 0.808064	test: 0.771651
PRC train: 0.881985	val: 0.586296	test: 0.563528

Epoch: 55
Loss: 0.12487453595469056
ROC train: 0.977041	val: 0.794078	test: 0.822369
PRC train: 0.889414	val: 0.606356	test: 0.584720

Epoch: 56
Loss: 0.13474874856116442
ROC train: 0.977367	val: 0.795702	test: 0.813774
PRC train: 0.891281	val: 0.606946	test: 0.583839

Epoch: 57
Loss: 0.12890299714828607
ROC train: 0.979923	val: 0.773700	test: 0.821767
PRC train: 0.895313	val: 0.585928	test: 0.592959

Epoch: 58
Loss: 0.12541343003942435
ROC train: 0.979668	val: 0.777333	test: 0.842917
PRC train: 0.893775	val: 0.594226	test: 0.606687

Epoch: 59
Loss: 0.1314150408418672
ROC train: 0.979981	val: 0.770316	test: 0.822242
PRC train: 0.899035	val: 0.616099	test: 0.593084

Epoch: 60
Loss: 0.13895578386365065
ROC train: 0.979286	val: 0.788459	test: 0.798863
PRC train: 0.898313	val: 0.628689	test: 0.586230

Epoch: 61
Loss: 0.1385460059708763
ROC train: 0.980534	val: 0.783427	test: 0.817707
PRC train: 0.898439	val: 0.620151	test: 0.606232

Epoch: 62
Loss: 0.13014443524478136
ROC train: 0.978835	val: 0.825171	test: 0.811398
PRC train: 0.893626	val: 0.643654	test: 0.611152

Epoch: 63
Loss: 0.12342068716166854
ROC train: 0.980742	val: 0.827943	test: 0.817356
PRC train: 0.898856	val: 0.630765	test: 0.600408

Epoch: 64
Loss: 0.12217943035374686
ROC train: 0.978560	val: 0.849246	test: 0.816882
PRC train: 0.885149	val: 0.638052	test: 0.603038

Epoch: 65
Loss: 0.11902470441779138
ROC train: 0.977297	val: 0.862195	test: 0.792199
PRC train: 0.884185	val: 0.631954	test: 0.589642

Epoch: 66
Loss: 0.12170476984390585
ROC train: 0.979412	val: 0.830379	test: 0.784771
PRC train: 0.893056	val: 0.614817	test: 0.590930

Epoch: 67
Loss: 0.11723709142321226
ROC train: 0.983271	val: 0.778595	test: 0.785427
PRC train: 0.908072	val: 0.621386	test: 0.604261

Epoch: 68
Loss: 0.10385805971949388
ROC train: 0.981943	val: 0.760677	test: 0.773123
PRC train: 0.904944	val: 0.598297	test: 0.596936

Epoch: 69
Loss: 0.11323819306920886
ROC train: 0.982321	val: 0.764359	test: 0.762455
PRC train: 0.905902	val: 0.624390	test: 0.585748

Epoch: 70
Loss: 0.12076532982303738
ROC train: 0.981917	val: 0.797438	test: 0.788038
PRC train: 0.907608	val: 0.640414	test: 0.584032

Epoch: 71
Loss: 0.11410640731925534
ROC train: 0.981424	val: 0.805267	test: 0.810898
PRC train: 0.906695	val: 0.645507	test: 0.593965

Epoch: 72
Loss: 0.12271358171795906
ROC train: 0.982187	val: 0.798587	test: 0.815432
PRC train: 0.906398	val: 0.625771	test: 0.604840

Epoch: 73
Loss: 0.10804778656123584
ROC train: 0.981577	val: 0.780356	test: 0.819056
PRC train: 0.901575	val: 0.614875	test: 0.610415

Epoch: 74
Loss: 0.11263128089762538
ROC train: 0.981162	val: 0.795540	test: 0.781142
PRC train: 0.900144	val: 0.622527	test: 0.584207

Epoch: 75
Loss: 0.1221173722829276
ROC train: 0.979704	val: 0.853779	test: 0.778520
PRC train: 0.897048	val: 0.645727	test: 0.576751

Epoch: 76
Loss: 0.12121598381617257
ROC train: 0.980867	val: 0.809101	test: 0.785091
PRC train: 0.904408	val: 0.637114	test: 0.580229

Epoch: 77
Loss: 0.11448323226575793
ROC train: 0.982911	val: 0.784913	test: 0.788538
PRC train: 0.909209	val: 0.620077	test: 0.594973

Epoch: 78
Loss: 0.11369132439413573
ROC train: 0.983863	val: 0.785163	test: 0.805172
PRC train: 0.912361	val: 0.642789	test: 0.608136

Epoch: 79
Loss: 0.12981686590133398
ROC train: 0.983696	val: 0.801633	test: 0.808537
PRC train: 0.914388	val: 0.642307	test: 0.595711

Epoch: 80
Loss: 0.1104897000639368
ROC train: 0.984132	val: 0.781368	test: 0.851385
PRC train: 0.915054	val: 0.623633	test: 0.620231

Epoch: 81
Loss: 0.11256648565009848
ROC train: 0.984908	val: 0.791594	test: 0.836544
PRC train: 0.918192	val: 0.635156	test: 0.611770

Epoch: 82
Loss: 0.12122378646302616
ROC train: 0.985169	val: 0.790107	test: 0.820307
PRC train: 0.921418	val: 0.644183	test: 0.636948

Epoch: 83
Loss: 0.11583545420478147
ROC train: 0.985191	val: 0.778982	test: 0.834071
PRC train: 0.922233	val: 0.634998	test: 0.620650

Epoch: 84
Loss: 0.11276942887135326
ROC train: 0.984069	val: 0.785388	test: 0.859673
PRC train: 0.918384	val: 0.631126	test: 0.623196

Epoch: 85
Loss: 0.11219250560575098
ROC train: 0.982894	val: 0.807751	test: 0.876631
PRC train: 0.912280	val: 0.644519	test: 0.622791

Epoch: 86
Loss: 0.10998601097993452
ROC train: 0.981259	val: 0.804842	test: 0.870349
PRC train: 0.901303	val: 0.646455	test: 0.625051

Epoch: 87
Loss: 0.1147311003338461
ROC train: 0.984145	val: 0.792318	test: 0.848702
PRC train: 0.917076	val: 0.640779	test: 0.631419

Epoch: 88
Loss: 0.110752753623378
ROC train: 0.984523	val: 0.777671	test: 0.827583
PRC train: 0.915682	val: 0.617642	test: 0.601547

Epoch: 89
Loss: 0.10298678391381652
ROC train: 0.984223	val: 0.771964	test: 0.847653
PRC train: 0.908363	val: 0.613378	test: 0.616355

Epoch: 90
Loss: 0.11535257572199006
ROC train: 0.984285	val: 0.776634	test: 0.850551
PRC train: 0.910269	val: 0.601828	test: 0.616643

Epoch: 91
Loss: 0.10347852252108927
ROC train: 0.984394	val: 0.787011	test: 0.797959
PRC train: 0.915057	val: 0.604038	test: 0.589196

Epoch: 92
Loss: 0.12376163657156358
ROC train: 0.984481	val: 0.821400	test: 0.799845
PRC train: 0.911981	val: 0.627675	test: 0.585903

Epoch: 93
Loss: 0.11575549170325614
ROC train: 0.983687	val: 0.844076	test: 0.784478
PRC train: 0.906703	val: 0.617794	test: 0.579368

Epoch: 94
Loss: 0.10625055548694187
ROC train: 0.985671	val: 0.702001	test: 0.766721
PRC train: 0.920351	val: 0.577343	test: 0.631306

Epoch: 95
Loss: 0.1102365566738018
ROC train: 0.985259	val: 0.688350	test: 0.751230
PRC train: 0.920708	val: 0.571172	test: 0.611654

Epoch: 96
Loss: 0.12505781750117417
ROC train: 0.984111	val: 0.681683	test: 0.756890
PRC train: 0.914444	val: 0.565709	test: 0.606804

Epoch: 97
Loss: 0.10301222660547797
ROC train: 0.984555	val: 0.690065	test: 0.776880
PRC train: 0.915495	val: 0.568421	test: 0.625740

Epoch: 98
Loss: 0.10931639830828734
ROC train: 0.984975	val: 0.704869	test: 0.793103
PRC train: 0.917417	val: 0.575248	test: 0.631005

Epoch: 99
Loss: 0.112004278217793
ROC train: 0.985646	val: 0.702009	test: 0.778947
PRC train: 0.923660	val: 0.575320	test: 0.615384

Epoch: 100
Loss: 0.09906917161316162
ROC train: 0.984721	val: 0.698114	test: 0.787715
PRC train: 0.918200	val: 0.571620	test: 0.621842

Epoch: 101
Loss: 0.09919518688822569
ROC train: 0.984598	val: 0.687335	test: 0.790490
PRC train: 0.919083	val: 0.565890	test: 0.622981

Epoch: 102
Loss: 0.1150246124135479
ROC train: 0.984627	val: 0.678966	test: 0.795838
PRC train: 0.918317	val: 0.558654	test: 0.616188

Epoch: 103
Loss: 0.1159790786379999
ROC train: 0.984476	val: 0.677844	test: 0.805948
PRC train: 0.916182	val: 0.559095	test: 0.618700

Epoch: 104
Loss: 0.10438836644773106
ROC train: 0.985814	val: 0.678900	test: 0.805717
PRC train: 0.922889	val: 0.561353	test: 0.627254

Epoch: 105
Loss: 0.12169802288732333
ROC train: 0.985673	val: 0.677291	test: 0.788819
PRC train: 0.922777	val: 0.560100	test: 0.621025

Epoch: 106
Loss: 0.10671133245834208
ROC train: 0.985372	val: 0.683289	test: 0.776789
PRC train: 0.921138	val: 0.567962	test: 0.616604

Epoch: 107
Loss: 0.10518574300704599
ROC train: 0.985414	val: 0.692655	test: 0.784238
PRC train: 0.919819	val: 0.572806	test: 0.629482

Epoch: 108
Loss: 0.11224889098227919
ROC train: 0.985725	val: 0.694089	test: 0.788115
PRC train: 0.919247	val: 0.569436	test: 0.627751

Epoch: 109
Loss: 0.10764911801267535
ROC train: 0.985442	val: 0.685310	test: 0.790326
PRC train: 0.920587	val: 0.566004	test: 0.621063

Epoch: 110
Loss: 0.10581090487228666
ROC train: 0.986058	val: 0.698760	test: 0.777148
PRC train: 0.926294	val: 0.563928	test: 0.611633

Epoch: 111
Loss: 0.10808637952594972
ROC train: 0.987078	val: 0.701298	test: 0.773827
PRC train: 0.930878	val: 0.570738	test: 0.616402

Epoch: 112
Loss: 0.09990218300227868
ROC train: 0.986319	val: 0.698893	test: 0.785049
PRC train: 0.925487	val: 0.579061	test: 0.626745

Epoch: 113
Loss: 0.10654902814598301
ROC train: 0.985587	val: 0.707250	test: 0.789962
PRC train: 0.924347	val: 0.575230	test: 0.640704

Epoch: 114
Loss: 0.1013548714281639
ROC train: 0.985373	val: 0.700952	test: 0.791383
PRC train: 0.925128	val: 0.568000	test: 0.623741

Epoch: 115
Loss: 0.09223799828578252
ROC train: 0.987309	val: 0.693189	test: 0.795611
PRC train: 0.932065	val: 0.568358	test: 0.629871

Epoch: 116
Loss: 0.09684257087494304
ROC train: 0.987304	val: 0.689211	test: 0.791316
PRC train: 0.934326	val: 0.573329	test: 0.626848

Epoch: 117
Loss: 0.10910351022451825
ROC train: 0.986577	val: 0.690186	test: 0.797092
PRC train: 0.928782	val: 0.573785	test: 0.637628

Epoch: 118
Loss: 0.09657435287837997
ROC train: 0.986150	val: 0.697682	test: 0.801225
PRC train: 0.926796	val: 0.575286	test: 0.638705

Epoch: 119
Loss: 0.10240183029005825
ROC train: 0.985769	val: 0.686108	test: 0.784482
PRC train: 0.926903	val: 0.570489	test: 0.615239

Epoch: 120
Loss: 0.1025597645012418
ROC train: 0.986911	val: 0.681480	test: 0.769813
PRC train: 0.928824	val: 0.568292	test: 0.614976

Early stopping
Best (ROC):	 train: 0.930704	val: 0.707495	test: 0.747117
Best (PRC):	 train: 0.768700	val: 0.558424	test: 0.579163


Epoch: 94
Loss: 0.1179059640795804
ROC train: 0.984628	val: 0.664486	test: 0.837823
PRC train: 0.918494	val: 0.560158	test: 0.615246

Epoch: 95
Loss: 0.1026533712906296
ROC train: 0.984909	val: 0.658427	test: 0.831162
PRC train: 0.921598	val: 0.560878	test: 0.607267

Epoch: 96
Loss: 0.10843960856022333
ROC train: 0.984298	val: 0.655972	test: 0.824245
PRC train: 0.919718	val: 0.558689	test: 0.600904

Epoch: 97
Loss: 0.10690080445843479
ROC train: 0.985577	val: 0.667106	test: 0.820090
PRC train: 0.924363	val: 0.560571	test: 0.615012

Epoch: 98
Loss: 0.105925056099371
ROC train: 0.985659	val: 0.668977	test: 0.826801
PRC train: 0.924109	val: 0.560324	test: 0.626505

Epoch: 99
Loss: 0.10540635270373445
ROC train: 0.986477	val: 0.648686	test: 0.827449
PRC train: 0.930133	val: 0.557197	test: 0.626053

Epoch: 100
Loss: 0.10175475854531241
ROC train: 0.983130	val: 0.653044	test: 0.833188
PRC train: 0.910348	val: 0.557153	test: 0.631339

Epoch: 101
Loss: 0.11568700025197189
ROC train: 0.982606	val: 0.650414	test: 0.816364
PRC train: 0.914348	val: 0.561306	test: 0.628671

Epoch: 102
Loss: 0.11324080925917752
ROC train: 0.984262	val: 0.662534	test: 0.812113
PRC train: 0.915739	val: 0.556030	test: 0.627756

Epoch: 103
Loss: 0.0972613341508964
ROC train: 0.984514	val: 0.663103	test: 0.798113
PRC train: 0.923225	val: 0.558908	test: 0.618893

Epoch: 104
Loss: 0.10592764522577908
ROC train: 0.985198	val: 0.667080	test: 0.804992
PRC train: 0.923280	val: 0.559813	test: 0.618733

Epoch: 105
Loss: 0.09567140386819467
ROC train: 0.985450	val: 0.666609	test: 0.807135
PRC train: 0.923137	val: 0.560327	test: 0.615815

Epoch: 106
Loss: 0.09557278918078237
ROC train: 0.985383	val: 0.658718	test: 0.811418
PRC train: 0.924015	val: 0.557949	test: 0.612479

Epoch: 107
Loss: 0.10500103494142321
ROC train: 0.985340	val: 0.645230	test: 0.811807
PRC train: 0.923184	val: 0.553684	test: 0.610208

Epoch: 108
Loss: 0.099051346736263
ROC train: 0.985379	val: 0.637567	test: 0.811158
PRC train: 0.919718	val: 0.549326	test: 0.615370

Epoch: 109
Loss: 0.10282469849594028
ROC train: 0.986523	val: 0.627761	test: 0.801435
PRC train: 0.924122	val: 0.544128	test: 0.606418

Epoch: 110
Loss: 0.11055915235714092
ROC train: 0.985953	val: 0.636465	test: 0.803723
PRC train: 0.920702	val: 0.550896	test: 0.609814

Epoch: 111
Loss: 0.101706446707909
ROC train: 0.982426	val: 0.645994	test: 0.812538
PRC train: 0.905134	val: 0.554938	test: 0.616231

Epoch: 112
Loss: 0.10864749639955058
ROC train: 0.982895	val: 0.646701	test: 0.819990
PRC train: 0.907967	val: 0.556519	test: 0.618863

Epoch: 113
Loss: 0.1013253601978033
ROC train: 0.984790	val: 0.639812	test: 0.820121
PRC train: 0.918668	val: 0.557709	test: 0.611160

Epoch: 114
Loss: 0.10961792956757065
ROC train: 0.986586	val: 0.637260	test: 0.816476
PRC train: 0.928917	val: 0.556409	test: 0.603152

Epoch: 115
Loss: 0.09524207979367587
ROC train: 0.986658	val: 0.650122	test: 0.826463
PRC train: 0.926372	val: 0.553007	test: 0.620008

Epoch: 116
Loss: 0.0952304181967192
ROC train: 0.985259	val: 0.659390	test: 0.827549
PRC train: 0.917250	val: 0.553738	test: 0.626164

Epoch: 117
Loss: 0.09863675132029624
ROC train: 0.986407	val: 0.659151	test: 0.821575
PRC train: 0.927647	val: 0.552709	test: 0.619171

Epoch: 118
Loss: 0.10640796414977627
ROC train: 0.986142	val: 0.653584	test: 0.807327
PRC train: 0.929238	val: 0.550261	test: 0.613014

Epoch: 119
Loss: 0.11035325543085794
ROC train: 0.985421	val: 0.657777	test: 0.799407
PRC train: 0.924719	val: 0.553022	test: 0.610825

Epoch: 120
Loss: 0.09637876733542547
ROC train: 0.985531	val: 0.661514	test: 0.794652
PRC train: 0.924606	val: 0.558949	test: 0.612186

Early stopping
Best (ROC):	 train: 0.937601	val: 0.709246	test: 0.771608
Best (PRC):	 train: 0.768801	val: 0.554674	test: 0.567145

ROC train: 0.986804	val: 0.656391	test: 0.788985
PRC train: 0.925266	val: 0.565077	test: 0.592601

Epoch: 95
Loss: 0.10679136568802614
ROC train: 0.986023	val: 0.679653	test: 0.784407
PRC train: 0.920716	val: 0.569630	test: 0.589216

Epoch: 96
Loss: 0.10365572809814733
ROC train: 0.985492	val: 0.682194	test: 0.784338
PRC train: 0.916875	val: 0.573665	test: 0.595591

Epoch: 97
Loss: 0.09789908032183427
ROC train: 0.985861	val: 0.671666	test: 0.790277
PRC train: 0.918889	val: 0.567226	test: 0.615805

Epoch: 98
Loss: 0.11258632725910869
ROC train: 0.985556	val: 0.671901	test: 0.797998
PRC train: 0.918484	val: 0.570435	test: 0.620805

Epoch: 99
Loss: 0.10638150192530389
ROC train: 0.984629	val: 0.675658	test: 0.799234
PRC train: 0.917130	val: 0.570593	test: 0.625926

Epoch: 100
Loss: 0.10754524992018677
ROC train: 0.985621	val: 0.668760	test: 0.793353
PRC train: 0.923318	val: 0.571028	test: 0.617726

Epoch: 101
Loss: 0.10247433902606483
ROC train: 0.984818	val: 0.669897	test: 0.784672
PRC train: 0.920430	val: 0.569330	test: 0.616668

Epoch: 102
Loss: 0.10799372425831019
ROC train: 0.984619	val: 0.666696	test: 0.791574
PRC train: 0.917860	val: 0.566497	test: 0.623192

Epoch: 103
Loss: 0.10323838043524552
ROC train: 0.985296	val: 0.655045	test: 0.793151
PRC train: 0.920024	val: 0.564360	test: 0.629806

Epoch: 104
Loss: 0.1093444163671478
ROC train: 0.986126	val: 0.638836	test: 0.779653
PRC train: 0.926615	val: 0.558614	test: 0.603563

Epoch: 105
Loss: 0.11145533733772697
ROC train: 0.986535	val: 0.630172	test: 0.779867
PRC train: 0.927491	val: 0.556409	test: 0.595031

Epoch: 106
Loss: 0.10085110205895129
ROC train: 0.986318	val: 0.645048	test: 0.801361
PRC train: 0.919009	val: 0.560466	test: 0.606437

Epoch: 107
Loss: 0.10051069274314497
ROC train: 0.985720	val: 0.659755	test: 0.806283
PRC train: 0.915523	val: 0.561261	test: 0.608215

Epoch: 108
Loss: 0.09491861660824709
ROC train: 0.986654	val: 0.654033	test: 0.793446
PRC train: 0.922140	val: 0.559208	test: 0.596558

Epoch: 109
Loss: 0.1156221903908091
ROC train: 0.987241	val: 0.648446	test: 0.788545
PRC train: 0.927789	val: 0.556853	test: 0.591968

Epoch: 110
Loss: 0.10744720473508082
ROC train: 0.987123	val: 0.651347	test: 0.804482
PRC train: 0.925865	val: 0.557864	test: 0.606424

Epoch: 111
Loss: 0.09118478856792134
ROC train: 0.986779	val: 0.653116	test: 0.808800
PRC train: 0.923838	val: 0.563276	test: 0.611336

Epoch: 112
Loss: 0.09984302531952396
ROC train: 0.987272	val: 0.653408	test: 0.803036
PRC train: 0.928213	val: 0.561169	test: 0.607698

Epoch: 113
Loss: 0.10474870909958302
ROC train: 0.987027	val: 0.641268	test: 0.793078
PRC train: 0.930471	val: 0.555326	test: 0.595542

Epoch: 114
Loss: 0.11233760927262317
ROC train: 0.986982	val: 0.652253	test: 0.806285
PRC train: 0.927115	val: 0.564179	test: 0.609678

Epoch: 115
Loss: 0.10186127041893363
ROC train: 0.986304	val: 0.659406	test: 0.816861
PRC train: 0.921368	val: 0.566262	test: 0.631163

Epoch: 116
Loss: 0.0894658206007412
ROC train: 0.986623	val: 0.658132	test: 0.815493
PRC train: 0.921181	val: 0.560824	test: 0.629054

Epoch: 117
Loss: 0.0895085680584221
ROC train: 0.987129	val: 0.651431	test: 0.804744
PRC train: 0.927226	val: 0.565065	test: 0.614434

Epoch: 118
Loss: 0.09816180550783947
ROC train: 0.986608	val: 0.654669	test: 0.802666
PRC train: 0.923705	val: 0.566374	test: 0.616371

Epoch: 119
Loss: 0.09128094565082995
ROC train: 0.987156	val: 0.655844	test: 0.807470
PRC train: 0.928051	val: 0.561500	test: 0.611806

Epoch: 120
Loss: 0.08266078122275344
ROC train: 0.986798	val: 0.665217	test: 0.822493
PRC train: 0.924325	val: 0.564882	test: 0.623660

Early stopping
Best (ROC):	 train: 0.947424	val: 0.709826	test: 0.758997
Best (PRC):	 train: 0.801468	val: 0.557547	test: 0.562946
All runs completed.

ROC train: 0.955701	val: 0.743030	test: 0.705005
PRC train: 0.808293	val: 0.594608	test: 0.556463

Epoch: 95
Loss: 0.17384168295466482
ROC train: 0.960497	val: 0.713061	test: 0.658486
PRC train: 0.826870	val: 0.591516	test: 0.545966

Epoch: 96
Loss: 0.15280476714447194
ROC train: 0.957644	val: 0.706979	test: 0.678361
PRC train: 0.835017	val: 0.590094	test: 0.540000

Epoch: 97
Loss: 0.13403289211746544
ROC train: 0.958012	val: 0.711363	test: 0.712537
PRC train: 0.829019	val: 0.587500	test: 0.552233

Epoch: 98
Loss: 0.13206449267500095
ROC train: 0.960793	val: 0.720377	test: 0.712806
PRC train: 0.833440	val: 0.592633	test: 0.550897

Epoch: 99
Loss: 0.1663590233394218
ROC train: 0.964311	val: 0.712551	test: 0.686910
PRC train: 0.849304	val: 0.603126	test: 0.541273

Epoch: 100
Loss: 0.15182632568692117
ROC train: 0.964592	val: 0.706992	test: 0.679753
PRC train: 0.848172	val: 0.589999	test: 0.543471

Epoch: 101
Loss: 0.13486322146595991
ROC train: 0.965672	val: 0.724409	test: 0.709659
PRC train: 0.846195	val: 0.594469	test: 0.556085

Epoch: 102
Loss: 0.11758043818427044
ROC train: 0.963211	val: 0.734693	test: 0.707599
PRC train: 0.833833	val: 0.593041	test: 0.565375

Epoch: 103
Loss: 0.12249391549389146
ROC train: 0.963536	val: 0.727833	test: 0.707366
PRC train: 0.840496	val: 0.594248	test: 0.557584

Epoch: 104
Loss: 0.1829879716440535
ROC train: 0.967555	val: 0.709034	test: 0.696507
PRC train: 0.853291	val: 0.589799	test: 0.550944

Epoch: 105
Loss: 0.13330289133999812
ROC train: 0.962430	val: 0.694520	test: 0.640861
PRC train: 0.839668	val: 0.598531	test: 0.541388

Epoch: 106
Loss: 0.1509752037469341
ROC train: 0.959474	val: 0.683102	test: 0.620180
PRC train: 0.834783	val: 0.601138	test: 0.553280

Epoch: 107
Loss: 0.1538495044864907
ROC train: 0.965580	val: 0.697058	test: 0.686870
PRC train: 0.853077	val: 0.599811	test: 0.559223

Epoch: 108
Loss: 0.11519819854426876
ROC train: 0.963119	val: 0.699847	test: 0.724921
PRC train: 0.838199	val: 0.597230	test: 0.577056

Epoch: 109
Loss: 0.14871332431939138
ROC train: 0.957353	val: 0.693755	test: 0.724617
PRC train: 0.827436	val: 0.595624	test: 0.569347

Epoch: 110
Loss: 0.14181829696965503
ROC train: 0.960666	val: 0.705593	test: 0.724994
PRC train: 0.832318	val: 0.595973	test: 0.567371

Epoch: 111
Loss: 0.182491324495277
ROC train: 0.965266	val: 0.722384	test: 0.730918
PRC train: 0.844606	val: 0.603891	test: 0.580029

Epoch: 112
Loss: 0.11862944169323493
ROC train: 0.962425	val: 0.712403	test: 0.711757
PRC train: 0.841593	val: 0.598502	test: 0.573526

Epoch: 113
Loss: 0.213503757910723
ROC train: 0.964795	val: 0.723685	test: 0.720011
PRC train: 0.847049	val: 0.600081	test: 0.580583

Epoch: 114
Loss: 0.12435223177801517
ROC train: 0.960053	val: 0.749216	test: 0.679245
PRC train: 0.837884	val: 0.622397	test: 0.559594

Epoch: 115
Loss: 0.16745722882649217
ROC train: 0.961117	val: 0.753414	test: 0.654200
PRC train: 0.839404	val: 0.625506	test: 0.558377

Epoch: 116
Loss: 0.14651258883306695
ROC train: 0.964061	val: 0.735484	test: 0.747200
PRC train: 0.837649	val: 0.611412	test: 0.568652

Epoch: 117
Loss: 0.1357674865530582
ROC train: 0.962790	val: 0.715844	test: 0.781755
PRC train: 0.830658	val: 0.587095	test: 0.566159

Epoch: 118
Loss: 0.22116247570322828
ROC train: 0.961546	val: 0.690671	test: 0.760970
PRC train: 0.827307	val: 0.575174	test: 0.549528

Epoch: 119
Loss: 0.23344568340278782
ROC train: 0.939712	val: 0.654527	test: 0.684115
PRC train: 0.782520	val: 0.556181	test: 0.533906

Epoch: 120
Loss: 0.1448452779448058
ROC train: 0.933448	val: 0.645052	test: 0.698679
PRC train: 0.775204	val: 0.552548	test: 0.539356

Early stopping
Best (ROC):	 train: 0.933385	val: 0.761690	test: 0.766117
Best (PRC):	 train: 0.764790	val: 0.603630	test: 0.635090

ROC train: 0.930860	val: 0.704650	test: 0.755831
PRC train: 0.765087	val: 0.597100	test: 0.555200

Epoch: 95
Loss: 0.15910415583011525
ROC train: 0.901039	val: 0.698545	test: 0.752999
PRC train: 0.747543	val: 0.595500	test: 0.555114

Epoch: 96
Loss: 0.16029063334176638
ROC train: 0.904436	val: 0.686819	test: 0.763240
PRC train: 0.758648	val: 0.590153	test: 0.555731

Epoch: 97
Loss: 0.15927048694387008
ROC train: 0.923166	val: 0.693953	test: 0.782478
PRC train: 0.776429	val: 0.587666	test: 0.559985

Epoch: 98
Loss: 0.15769247512233195
ROC train: 0.938265	val: 0.695340	test: 0.776438
PRC train: 0.794068	val: 0.603787	test: 0.559538

Epoch: 99
Loss: 0.15063061306212963
ROC train: 0.948225	val: 0.687550	test: 0.769947
PRC train: 0.805068	val: 0.601942	test: 0.558562

Epoch: 100
Loss: 0.20675667379265752
ROC train: 0.950752	val: 0.668630	test: 0.731106
PRC train: 0.808223	val: 0.579476	test: 0.543368

Epoch: 101
Loss: 0.27889689291311937
ROC train: 0.946433	val: 0.667146	test: 0.698333
PRC train: 0.794165	val: 0.577044	test: 0.537021

Epoch: 102
Loss: 0.20072351089559076
ROC train: 0.927696	val: 0.668534	test: 0.714444
PRC train: 0.771976	val: 0.573073	test: 0.549305

Epoch: 103
Loss: 0.23727072471527338
ROC train: 0.924961	val: 0.647359	test: 0.731072
PRC train: 0.769925	val: 0.571995	test: 0.552890

Epoch: 104
Loss: 0.15069268548693673
ROC train: 0.916934	val: 0.616677	test: 0.745369
PRC train: 0.756803	val: 0.561413	test: 0.562954

Epoch: 105
Loss: 0.156397831192085
ROC train: 0.920731	val: 0.615500	test: 0.735148
PRC train: 0.762413	val: 0.557271	test: 0.565799

Epoch: 106
Loss: 0.17831536405617351
ROC train: 0.935754	val: 0.620277	test: 0.714972
PRC train: 0.790190	val: 0.550071	test: 0.558014

Epoch: 107
Loss: 0.14867243783621725
ROC train: 0.941772	val: 0.655083	test: 0.705867
PRC train: 0.789478	val: 0.561467	test: 0.543915

Epoch: 108
Loss: 0.18378972435558097
ROC train: 0.949696	val: 0.689831	test: 0.707335
PRC train: 0.801972	val: 0.586610	test: 0.547573

Epoch: 109
Loss: 0.20512313040904492
ROC train: 0.924115	val: 0.716416	test: 0.689223
PRC train: 0.768190	val: 0.598994	test: 0.542788

Epoch: 110
Loss: 0.1552200391850484
ROC train: 0.923836	val: 0.720264	test: 0.707806
PRC train: 0.781393	val: 0.598303	test: 0.544247

Epoch: 111
Loss: 0.18355010534615834
ROC train: 0.931317	val: 0.717540	test: 0.717902
PRC train: 0.798527	val: 0.597305	test: 0.549499

Epoch: 112
Loss: 0.1688157622829884
ROC train: 0.933918	val: 0.710446	test: 0.717613
PRC train: 0.794936	val: 0.610999	test: 0.551645

Epoch: 113
Loss: 0.14680384101939722
ROC train: 0.945571	val: 0.699858	test: 0.710363
PRC train: 0.811021	val: 0.610867	test: 0.543773

Epoch: 114
Loss: 0.15209828882762616
ROC train: 0.953737	val: 0.696379	test: 0.691723
PRC train: 0.827118	val: 0.589974	test: 0.535290

Epoch: 115
Loss: 0.19079438836294843
ROC train: 0.955561	val: 0.686478	test: 0.694050
PRC train: 0.827299	val: 0.581134	test: 0.541138

Epoch: 116
Loss: 0.1374324257377412
ROC train: 0.954184	val: 0.693158	test: 0.708801
PRC train: 0.819883	val: 0.582211	test: 0.546416

Epoch: 117
Loss: 0.14518728519759524
ROC train: 0.955624	val: 0.706124	test: 0.722624
PRC train: 0.823408	val: 0.589262	test: 0.549147

Epoch: 118
Loss: 0.21811508310173142
ROC train: 0.962084	val: 0.714556	test: 0.712154
PRC train: 0.835094	val: 0.600530	test: 0.544331

Epoch: 119
Loss: 0.13609490305452668
ROC train: 0.957562	val: 0.695860	test: 0.660373
PRC train: 0.830738	val: 0.601591	test: 0.527910

Epoch: 120
Loss: 0.13775934946477514
ROC train: 0.953986	val: 0.681336	test: 0.665300
PRC train: 0.827377	val: 0.592281	test: 0.528096

Early stopping
Best (ROC):	 train: 0.946886	val: 0.749850	test: 0.726978
Best (PRC):	 train: 0.807352	val: 0.601146	test: 0.547178

ROC train: 0.955902	val: 0.681561	test: 0.683007
PRC train: 0.816354	val: 0.576627	test: 0.537246

Epoch: 95
Loss: 0.13444009066437718
ROC train: 0.958496	val: 0.677709	test: 0.689291
PRC train: 0.827444	val: 0.597352	test: 0.540123

Epoch: 96
Loss: 0.13273734188301442
ROC train: 0.960732	val: 0.677237	test: 0.694149
PRC train: 0.837630	val: 0.603881	test: 0.541430

Epoch: 97
Loss: 0.13708020402219281
ROC train: 0.962554	val: 0.680036	test: 0.712993
PRC train: 0.838721	val: 0.598858	test: 0.549196

Epoch: 98
Loss: 0.12888023605896298
ROC train: 0.959239	val: 0.693373	test: 0.737335
PRC train: 0.811721	val: 0.595619	test: 0.557002

Epoch: 99
Loss: 0.1343435114834044
ROC train: 0.962185	val: 0.699590	test: 0.739405
PRC train: 0.815685	val: 0.594553	test: 0.556871

Epoch: 100
Loss: 0.12465754133293268
ROC train: 0.966327	val: 0.703316	test: 0.732012
PRC train: 0.837253	val: 0.595600	test: 0.549762

Epoch: 101
Loss: 0.23668219776623306
ROC train: 0.968193	val: 0.700357	test: 0.712602
PRC train: 0.841953	val: 0.601669	test: 0.547223

Epoch: 102
Loss: 0.11925475451289029
ROC train: 0.960588	val: 0.686440	test: 0.707233
PRC train: 0.817609	val: 0.574875	test: 0.549942

Epoch: 103
Loss: 0.16560626498354297
ROC train: 0.957829	val: 0.687975	test: 0.716723
PRC train: 0.811915	val: 0.574407	test: 0.551509

Epoch: 104
Loss: 0.15030944603326551
ROC train: 0.959296	val: 0.696419	test: 0.709835
PRC train: 0.820612	val: 0.580451	test: 0.541121

Epoch: 105
Loss: 0.20469399416974982
ROC train: 0.959270	val: 0.707773	test: 0.718381
PRC train: 0.823971	val: 0.587893	test: 0.541477

Epoch: 106
Loss: 0.13582043769191463
ROC train: 0.955718	val: 0.714165	test: 0.719824
PRC train: 0.822732	val: 0.586456	test: 0.582059

Epoch: 107
Loss: 0.13742320097821836
ROC train: 0.950832	val: 0.695057	test: 0.717273
PRC train: 0.813617	val: 0.577110	test: 0.577213

Epoch: 108
Loss: 0.1353042386373247
ROC train: 0.967317	val: 0.677374	test: 0.741514
PRC train: 0.843323	val: 0.573158	test: 0.568020

Epoch: 109
Loss: 0.13266174279419546
ROC train: 0.963933	val: 0.650331	test: 0.700663
PRC train: 0.844510	val: 0.558677	test: 0.547693

Epoch: 110
Loss: 0.1319662391856777
ROC train: 0.962557	val: 0.652807	test: 0.695870
PRC train: 0.841469	val: 0.558499	test: 0.547097

Epoch: 111
Loss: 0.1309817517431163
ROC train: 0.966399	val: 0.682091	test: 0.713126
PRC train: 0.848079	val: 0.571222	test: 0.555929

Epoch: 112
Loss: 0.18543609813228618
ROC train: 0.963697	val: 0.692900	test: 0.697959
PRC train: 0.837545	val: 0.576879	test: 0.568721

Epoch: 113
Loss: 0.1407836588307566
ROC train: 0.954927	val: 0.662834	test: 0.676436
PRC train: 0.815235	val: 0.564809	test: 0.548182

Epoch: 114
Loss: 0.13083619387843065
ROC train: 0.956599	val: 0.639577	test: 0.675611
PRC train: 0.815398	val: 0.558341	test: 0.552327

Epoch: 115
Loss: 0.1304446074838504
ROC train: 0.960159	val: 0.613438	test: 0.658998
PRC train: 0.820077	val: 0.544422	test: 0.544753

Epoch: 116
Loss: 0.13566930581703854
ROC train: 0.961848	val: 0.619766	test: 0.646252
PRC train: 0.825245	val: 0.546387	test: 0.539905

Epoch: 117
Loss: 0.17136787199927578
ROC train: 0.961270	val: 0.623419	test: 0.662493
PRC train: 0.828749	val: 0.551614	test: 0.540447

Epoch: 118
Loss: 0.12571181275048077
ROC train: 0.958983	val: 0.639653	test: 0.707029
PRC train: 0.824246	val: 0.574652	test: 0.575805

Epoch: 119
Loss: 0.14104819716870048
ROC train: 0.959623	val: 0.656519	test: 0.724319
PRC train: 0.823463	val: 0.585686	test: 0.630096

Epoch: 120
Loss: 0.12622862846316305
ROC train: 0.960935	val: 0.666661	test: 0.726457
PRC train: 0.826648	val: 0.587840	test: 0.585827

Early stopping
Best (ROC):	 train: 0.855853	val: 0.758048	test: 0.673990
Best (PRC):	 train: 0.670704	val: 0.604167	test: 0.554869
All runs completed.

ROC train: 0.984972	val: 0.778370	test: 0.871615
PRC train: 0.918570	val: 0.594109	test: 0.723166

Epoch: 95
Loss: 0.11414453319838269
ROC train: 0.984979	val: 0.811248	test: 0.860342
PRC train: 0.914881	val: 0.636938	test: 0.711722

Epoch: 96
Loss: 0.10917971247514366
ROC train: 0.983867	val: 0.818266	test: 0.857731
PRC train: 0.909460	val: 0.637950	test: 0.691540

Epoch: 97
Loss: 0.1101593197788795
ROC train: 0.985788	val: 0.796313	test: 0.859180
PRC train: 0.919036	val: 0.641599	test: 0.656875

Epoch: 98
Loss: 0.10543639171659062
ROC train: 0.986634	val: 0.802607	test: 0.856319
PRC train: 0.920752	val: 0.658783	test: 0.650438

Epoch: 99
Loss: 0.10306692719794372
ROC train: 0.986301	val: 0.809737	test: 0.846775
PRC train: 0.920348	val: 0.665983	test: 0.638101

Epoch: 100
Loss: 0.10150593189788384
ROC train: 0.985112	val: 0.835460	test: 0.825914
PRC train: 0.920484	val: 0.706313	test: 0.619943

Epoch: 101
Loss: 0.10793865721617106
ROC train: 0.984748	val: 0.843539	test: 0.826351
PRC train: 0.915010	val: 0.694674	test: 0.640504

Epoch: 102
Loss: 0.11656891545270884
ROC train: 0.986023	val: 0.797149	test: 0.853271
PRC train: 0.921331	val: 0.653499	test: 0.651937

Epoch: 103
Loss: 0.09356873156619774
ROC train: 0.986800	val: 0.729433	test: 0.843003
PRC train: 0.925198	val: 0.617369	test: 0.648858

Epoch: 104
Loss: 0.10464129186706335
ROC train: 0.986104	val: 0.783427	test: 0.843171
PRC train: 0.923761	val: 0.623532	test: 0.651486

Epoch: 105
Loss: 0.09532911752796533
ROC train: 0.986524	val: 0.855951	test: 0.851736
PRC train: 0.923942	val: 0.693583	test: 0.652875

Epoch: 106
Loss: 0.12321535930584016
ROC train: 0.983202	val: 0.825645	test: 0.830060
PRC train: 0.909569	val: 0.663704	test: 0.641866

Epoch: 107
Loss: 0.11170394308487679
ROC train: 0.976202	val: 0.792792	test: 0.820341
PRC train: 0.882068	val: 0.676083	test: 0.616766

Epoch: 108
Loss: 0.11915256329470043
ROC train: 0.976842	val: 0.798161	test: 0.808074
PRC train: 0.889556	val: 0.675146	test: 0.612796

Epoch: 109
Loss: 0.1191633555209416
ROC train: 0.980559	val: 0.802407	test: 0.819866
PRC train: 0.903396	val: 0.660904	test: 0.616932

Epoch: 110
Loss: 0.10717170274955963
ROC train: 0.983533	val: 0.770727	test: 0.846611
PRC train: 0.913253	val: 0.648350	test: 0.634569

Epoch: 111
Loss: 0.1126400315074857
ROC train: 0.984192	val: 0.762037	test: 0.865112
PRC train: 0.915396	val: 0.633685	test: 0.647507

Epoch: 112
Loss: 0.10106810732449518
ROC train: 0.984411	val: 0.784601	test: 0.864637
PRC train: 0.916800	val: 0.669013	test: 0.647986

Epoch: 113
Loss: 0.10768062167926566
ROC train: 0.984541	val: 0.797100	test: 0.858243
PRC train: 0.914796	val: 0.642580	test: 0.674050

Epoch: 114
Loss: 0.10269135061504435
ROC train: 0.985727	val: 0.794278	test: 0.848848
PRC train: 0.919870	val: 0.633835	test: 0.657589

Epoch: 115
Loss: 0.09909041469567087
ROC train: 0.987601	val: 0.790195	test: 0.854294
PRC train: 0.931369	val: 0.690086	test: 0.663367

Epoch: 116
Loss: 0.106974121170697
ROC train: 0.987182	val: 0.784801	test: 0.844119
PRC train: 0.932656	val: 0.667296	test: 0.654327

Epoch: 117
Loss: 0.10492116171542365
ROC train: 0.986911	val: 0.764584	test: 0.863039
PRC train: 0.928708	val: 0.632094	test: 0.663206

Epoch: 118
Loss: 0.09421057407256267
ROC train: 0.986889	val: 0.773001	test: 0.862676
PRC train: 0.930340	val: 0.637797	test: 0.667480

Epoch: 119
Loss: 0.0920998478487376
ROC train: 0.985679	val: 0.737326	test: 0.856868
PRC train: 0.923310	val: 0.621732	test: 0.656343

Epoch: 120
Loss: 0.09012672369397505
ROC train: 0.987248	val: 0.735727	test: 0.862127
PRC train: 0.928839	val: 0.628172	test: 0.652827

Early stopping
Best (ROC):	 train: 0.960511	val: 0.888979	test: 0.747816
Best (PRC):	 train: 0.838465	val: 0.654064	test: 0.560694

ROC train: 0.986034	val: 0.778409	test: 0.866449
PRC train: 0.920390	val: 0.607752	test: 0.638678

Epoch: 95
Loss: 0.1127156230612831
ROC train: 0.985856	val: 0.763899	test: 0.852995
PRC train: 0.923754	val: 0.619659	test: 0.640528

Epoch: 96
Loss: 0.10949247287317805
ROC train: 0.984900	val: 0.764149	test: 0.880378
PRC train: 0.916419	val: 0.626505	test: 0.640897

Epoch: 97
Loss: 0.11652227773438924
ROC train: 0.982842	val: 0.736127	test: 0.889597
PRC train: 0.906306	val: 0.584270	test: 0.643082

Epoch: 98
Loss: 0.10810460838343257
ROC train: 0.978705	val: 0.632824	test: 0.888872
PRC train: 0.880100	val: 0.530963	test: 0.673432

Epoch: 99
Loss: 0.10446255842245744
ROC train: 0.985069	val: 0.681497	test: 0.885600
PRC train: 0.915534	val: 0.566863	test: 0.675981

Epoch: 100
Loss: 0.10838099634971979
ROC train: 0.985176	val: 0.752510	test: 0.876949
PRC train: 0.915982	val: 0.589268	test: 0.657993

Epoch: 101
Loss: 0.09754293368143205
ROC train: 0.985911	val: 0.757830	test: 0.864451
PRC train: 0.921144	val: 0.587127	test: 0.648679

Epoch: 102
Loss: 0.10116238182473292
ROC train: 0.986740	val: 0.774687	test: 0.864200
PRC train: 0.926168	val: 0.596733	test: 0.647959

Epoch: 103
Loss: 0.10396186806974658
ROC train: 0.987335	val: 0.795965	test: 0.871127
PRC train: 0.924262	val: 0.599882	test: 0.642726

Epoch: 104
Loss: 0.10307241821731114
ROC train: 0.987664	val: 0.777260	test: 0.869135
PRC train: 0.928105	val: 0.610207	test: 0.647118

Epoch: 105
Loss: 0.09894210203743818
ROC train: 0.986293	val: 0.748490	test: 0.853495
PRC train: 0.920792	val: 0.591710	test: 0.648476

Epoch: 106
Loss: 0.1079278256137944
ROC train: 0.985974	val: 0.772589	test: 0.875593
PRC train: 0.917820	val: 0.616681	test: 0.652277

Epoch: 107
Loss: 0.10453386251275185
ROC train: 0.986787	val: 0.799100	test: 0.853570
PRC train: 0.925072	val: 0.603711	test: 0.632621

Epoch: 108
Loss: 0.08557042112221196
ROC train: 0.987243	val: 0.808465	test: 0.852920
PRC train: 0.926855	val: 0.610310	test: 0.632908

Epoch: 109
Loss: 0.10012148849059495
ROC train: 0.987102	val: 0.835112	test: 0.867461
PRC train: 0.927859	val: 0.599142	test: 0.648976

Epoch: 110
Loss: 0.09647968643084058
ROC train: 0.986447	val: 0.846687	test: 0.873520
PRC train: 0.924576	val: 0.608603	test: 0.641618

Epoch: 111
Loss: 0.1075548419609034
ROC train: 0.986757	val: 0.829518	test: 0.872414
PRC train: 0.925500	val: 0.595757	test: 0.638935

Epoch: 112
Loss: 0.10324811268334548
ROC train: 0.986756	val: 0.821801	test: 0.886623
PRC train: 0.925115	val: 0.593084	test: 0.646495

Epoch: 113
Loss: 0.10022030180031712
ROC train: 0.983523	val: 0.788048	test: 0.874431
PRC train: 0.915519	val: 0.589078	test: 0.675656

Epoch: 114
Loss: 0.09628982461351672
ROC train: 0.985000	val: 0.731794	test: 0.866236
PRC train: 0.919661	val: 0.580062	test: 0.657326

Epoch: 115
Loss: 0.10842591806828643
ROC train: 0.987508	val: 0.704760	test: 0.857167
PRC train: 0.930081	val: 0.614282	test: 0.646298

Epoch: 116
Loss: 0.10480297507897998
ROC train: 0.988108	val: 0.703474	test: 0.838554
PRC train: 0.936587	val: 0.576410	test: 0.638819

Epoch: 117
Loss: 0.09555470857450754
ROC train: 0.988129	val: 0.713651	test: 0.855519
PRC train: 0.935919	val: 0.589983	test: 0.691651

Epoch: 118
Loss: 0.09676705375414991
ROC train: 0.988097	val: 0.723691	test: 0.866049
PRC train: 0.935592	val: 0.596386	test: 0.669784

Epoch: 119
Loss: 0.10097469455497414
ROC train: 0.987754	val: 0.726014	test: 0.847661
PRC train: 0.933967	val: 0.582118	test: 0.688516

Epoch: 120
Loss: 0.10812494276079909
ROC train: 0.986191	val: 0.725364	test: 0.857966
PRC train: 0.924361	val: 0.592188	test: 0.670638

Early stopping
Best (ROC):	 train: 0.934036	val: 0.904902	test: 0.644924
Best (PRC):	 train: 0.777690	val: 0.637873	test: 0.543485

ROC train: 0.981912	val: 0.835024	test: 0.785277
PRC train: 0.902635	val: 0.590180	test: 0.586624

Epoch: 95
Loss: 0.1192113545840803
ROC train: 0.984368	val: 0.834599	test: 0.807088
PRC train: 0.911978	val: 0.615722	test: 0.603669

Epoch: 96
Loss: 0.11621740369388271
ROC train: 0.983871	val: 0.800122	test: 0.820180
PRC train: 0.908864	val: 0.627684	test: 0.605602

Epoch: 97
Loss: 0.10711539316243904
ROC train: 0.985496	val: 0.774037	test: 0.809549
PRC train: 0.918661	val: 0.621552	test: 0.606509

Epoch: 98
Loss: 0.11610277055651515
ROC train: 0.985167	val: 0.768756	test: 0.799199
PRC train: 0.921255	val: 0.608584	test: 0.600239

Epoch: 99
Loss: 0.09693046929203353
ROC train: 0.984810	val: 0.789833	test: 0.831472
PRC train: 0.921128	val: 0.638996	test: 0.610247

Epoch: 100
Loss: 0.11817973238265615
ROC train: 0.986331	val: 0.788572	test: 0.860428
PRC train: 0.928696	val: 0.640822	test: 0.619644

Epoch: 101
Loss: 0.09781479629308376
ROC train: 0.986758	val: 0.788459	test: 0.867573
PRC train: 0.931972	val: 0.643495	test: 0.620385

Epoch: 102
Loss: 0.10977420540827583
ROC train: 0.986905	val: 0.780855	test: 0.877580
PRC train: 0.929848	val: 0.632974	test: 0.629000

Epoch: 103
Loss: 0.10765301119205975
ROC train: 0.986539	val: 0.776859	test: 0.866337
PRC train: 0.928976	val: 0.618837	test: 0.622620

Epoch: 104
Loss: 0.10772301302273082
ROC train: 0.984664	val: 0.785388	test: 0.854070
PRC train: 0.921137	val: 0.616450	test: 0.625083

Epoch: 105
Loss: 0.10900287887045904
ROC train: 0.984368	val: 0.774150	test: 0.862053
PRC train: 0.919364	val: 0.614616	test: 0.666433

Epoch: 106
Loss: 0.10402223725709159
ROC train: 0.985886	val: 0.760339	test: 0.852882
PRC train: 0.923900	val: 0.591511	test: 0.664866

Epoch: 107
Loss: 0.10028981108300199
ROC train: 0.986924	val: 0.763748	test: 0.856349
PRC train: 0.929456	val: 0.591958	test: 0.661750

Epoch: 108
Loss: 0.09918058081095486
ROC train: 0.985800	val: 0.789721	test: 0.855968
PRC train: 0.924367	val: 0.591577	test: 0.654814

Epoch: 109
Loss: 0.14262127095289698
ROC train: 0.984853	val: 0.785212	test: 0.879743
PRC train: 0.918172	val: 0.625616	test: 0.661350

Epoch: 110
Loss: 0.10964796732900314
ROC train: 0.980202	val: 0.783202	test: 0.809078
PRC train: 0.897706	val: 0.629772	test: 0.642064

Epoch: 111
Loss: 0.12068412158187207
ROC train: 0.979839	val: 0.784376	test: 0.807943
PRC train: 0.901876	val: 0.642354	test: 0.640869

Epoch: 112
Loss: 0.10893336939462832
ROC train: 0.984342	val: 0.780292	test: 0.846614
PRC train: 0.911933	val: 0.637086	test: 0.613237

Epoch: 113
Loss: 0.1059172216721486
ROC train: 0.984538	val: 0.810187	test: 0.806083
PRC train: 0.918378	val: 0.609447	test: 0.583878

Epoch: 114
Loss: 0.09582845797549824
ROC train: 0.981334	val: 0.821762	test: 0.766851
PRC train: 0.911109	val: 0.585733	test: 0.567798

Epoch: 115
Loss: 0.11104696887405636
ROC train: 0.986493	val: 0.793941	test: 0.807401
PRC train: 0.927141	val: 0.607819	test: 0.590086

Epoch: 116
Loss: 0.10041476336188673
ROC train: 0.986009	val: 0.777583	test: 0.835771
PRC train: 0.921933	val: 0.625571	test: 0.623916

Epoch: 117
Loss: 0.10246077692225478
ROC train: 0.986284	val: 0.771377	test: 0.832947
PRC train: 0.923492	val: 0.617568	test: 0.599252

Epoch: 118
Loss: 0.10119048325875972
ROC train: 0.986303	val: 0.790669	test: 0.851160
PRC train: 0.924757	val: 0.643713	test: 0.643829

Epoch: 119
Loss: 0.10132755563458473
ROC train: 0.986024	val: 0.800621	test: 0.838143
PRC train: 0.925136	val: 0.661481	test: 0.641393

Epoch: 120
Loss: 0.09072463303853823
ROC train: 0.985534	val: 0.809375	test: 0.833358
PRC train: 0.924210	val: 0.661741	test: 0.643494

Early stopping
Best (ROC):	 train: 0.954111	val: 0.901616	test: 0.709044
Best (PRC):	 train: 0.817975	val: 0.613226	test: 0.572035
All runs completed.
