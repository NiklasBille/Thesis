>>> Starting run for dataset: hiv
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running RANDOM configs_static_noise_experiments/GraphCL/hiv/noise=0.0.yml on cuda:0
Running RANDOM configs_static_noise_experiments/GraphCL/hiv/noise=0.05.yml on cuda:1
Running RANDOM configs_static_noise_experiments/GraphCL/hiv/noise=0.1.yml on cuda:2
Running RANDOM configs_static_noise_experiments/GraphCL/hiv/noise=0.2.yml on cuda:3
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.2.yml --runseed 1 --device cuda:3
Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.2.yml --runseed 2 --device cuda:3
Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.2.yml --runseed 3 --device cuda:3
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.05.yml --runseed 1 --device cuda:1
Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.05.yml --runseed 2 --device cuda:1
Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.05.yml --runseed 3 --device cuda:1
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.1.yml --runseed 1 --device cuda:2
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.0.yml --runseed 1 --device cuda:0
Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.1.yml --runseed 2 --device cuda:2
Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.0.yml --runseed 2 --device cuda:0
Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.1.yml --runseed 3 --device cuda:2
Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.0.yml --runseed 3 --device cuda:0
[15:07:17] WARNING: not removing hydrogen atom without neighbors
[15:07:17] WARNING: not removing hydrogen atom without neighbors
[15:07:17] WARNING: not removing hydrogen atom without neighbors
[15:07:17] WARNING: not removing hydrogen atom without neighbors
[15:07:17] WARNING: not removing hydrogen atom without neighbors
[15:07:17] WARNING: not removing hydrogen atom without neighbors
[15:07:19] WARNING: not removing hydrogen atom without neighbors
[15:07:19] WARNING: not removing hydrogen atom without neighbors
[15:07:20] WARNING: not removing hydrogen atom without neighbors
[15:07:20] WARNING: not removing hydrogen atom without neighbors
[15:07:20] WARNING: not removing hydrogen atom without neighbors
[15:07:20] WARNING: not removing hydrogen atom without neighbors
[15:07:22] WARNING: not removing hydrogen atom without neighbors
[15:07:22] WARNING: not removing hydrogen atom without neighbors
[15:07:22] WARNING: not removing hydrogen atom without neighbors
[15:07:22] WARNING: not removing hydrogen atom without neighbors
[15:07:22] WARNING: not removing hydrogen atom without neighbors
[15:07:22] WARNING: not removing hydrogen atom without neighbors
[15:07:26] WARNING: not removing hydrogen atom without neighbors
[15:07:26] WARNING: not removing hydrogen atom without neighbors
[15:07:26] WARNING: not removing hydrogen atom without neighbors
[15:07:26] WARNING: not removing hydrogen atom without neighbors
[15:07:27] WARNING: not removing hydrogen atom without neighbors
[15:07:27] WARNING: not removing hydrogen atom without neighbors
[15:07:34] WARNING: not removing hydrogen atom without neighbors
[15:07:34] WARNING: not removing hydrogen atom without neighbors
[15:07:34] WARNING: not removing hydrogen atom without neighbors
[15:07:34] WARNING: not removing hydrogen atom without neighbors
[15:07:35] WARNING: not removing hydrogen atom without neighbors
[15:07:35] WARNING: not removing hydrogen atom without neighbors
[15:07:36] WARNING: not removing hydrogen atom without neighbors
[15:07:36] WARNING: not removing hydrogen atom without neighbors
[15:07:36] WARNING: not removing hydrogen atom without neighbors
[15:07:36] WARNING: not removing hydrogen atom without neighbors
[15:07:36] WARNING: not removing hydrogen atom without neighbors
[15:07:36] WARNING: not removing hydrogen atom without neighbors
[15:07:40] WARNING: not removing hydrogen atom without neighbors
[15:07:40] WARNING: not removing hydrogen atom without neighbors
[15:07:41] WARNING: not removing hydrogen atom without neighbors
[15:07:41] WARNING: not removing hydrogen atom without neighbors
[15:07:41] WARNING: not removing hydrogen atom without neighbors
[15:07:41] WARNING: not removing hydrogen atom without neighbors
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.0.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:0
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/hiv/noise=0.0
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/hiv/noise=0.0/hiv_scaff_2_20-05_15-07-05  ]
[ Using Seed :  2  ]
[ Using device :  cuda:0  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.24962795221310138
ROC train: 0.768160	val: 0.761608	test: 0.667848
PRC train: 0.218841	val: 0.230777	test: 0.140888

Epoch: 2
Loss: 0.14038131068062465
ROC train: 0.791523	val: 0.759207	test: 0.715261
PRC train: 0.307013	val: 0.316303	test: 0.169260

Epoch: 3
Loss: 0.1353611088687001
ROC train: 0.800868	val: 0.737725	test: 0.685614
PRC train: 0.317761	val: 0.252709	test: 0.141676

Epoch: 4
Loss: 0.1313770720940985
ROC train: 0.810107	val: 0.786553	test: 0.733044
PRC train: 0.333717	val: 0.324494	test: 0.215287

Epoch: 5
Loss: 0.1284987623126898
ROC train: 0.826103	val: 0.785154	test: 0.725203
PRC train: 0.382088	val: 0.350828	test: 0.207225

Epoch: 6
Loss: 0.12671657883144252
ROC train: 0.826330	val: 0.787986	test: 0.744213
PRC train: 0.384352	val: 0.338468	test: 0.234282

Epoch: 7
Loss: 0.12416653403300493
ROC train: 0.834774	val: 0.785047	test: 0.735331
PRC train: 0.420024	val: 0.300914	test: 0.173428

Epoch: 8
Loss: 0.12168376214068938
ROC train: 0.834739	val: 0.754507	test: 0.745504
PRC train: 0.371450	val: 0.233531	test: 0.112391

Epoch: 9
Loss: 0.123198956562249
ROC train: 0.844874	val: 0.783020	test: 0.727614
PRC train: 0.422725	val: 0.322330	test: 0.160334

Epoch: 10
Loss: 0.1190513115557834
ROC train: 0.852072	val: 0.787276	test: 0.727325
PRC train: 0.429154	val: 0.374018	test: 0.220683

Epoch: 11
Loss: 0.12058452131790452
ROC train: 0.851864	val: 0.773641	test: 0.754022
PRC train: 0.463701	val: 0.368717	test: 0.195265

Epoch: 12
Loss: 0.11782202094988997
ROC train: 0.856524	val: 0.748644	test: 0.758249
PRC train: 0.469573	val: 0.344374	test: 0.162500

Epoch: 13
Loss: 0.1164097998326471
ROC train: 0.858369	val: 0.720645	test: 0.739784
PRC train: 0.449989	val: 0.338380	test: 0.125578

Epoch: 14
Loss: 0.11631876063295278
ROC train: 0.862306	val: 0.786905	test: 0.759115
PRC train: 0.469387	val: 0.352788	test: 0.246042

Epoch: 15
Loss: 0.11391523726460642
ROC train: 0.870417	val: 0.784343	test: 0.752374
PRC train: 0.487531	val: 0.332860	test: 0.147695

Epoch: 16
Loss: 0.11264338091520748
ROC train: 0.870453	val: 0.756360	test: 0.772348
PRC train: 0.496961	val: 0.350662	test: 0.163519

Epoch: 17
Loss: 0.11233875366475816
ROC train: 0.876046	val: 0.764213	test: 0.747956
PRC train: 0.494074	val: 0.362427	test: 0.122051

Epoch: 18
Loss: 0.11233399751730908
ROC train: 0.871410	val: 0.778779	test: 0.737969
PRC train: 0.489158	val: 0.306464	test: 0.123227

Epoch: 19
Loss: 0.11093002853659098
ROC train: 0.885577	val: 0.767040	test: 0.762058
PRC train: 0.513764	val: 0.343848	test: 0.188347

Epoch: 20
Loss: 0.11009220863405178
ROC train: 0.879686	val: 0.756344	test: 0.772881
PRC train: 0.519097	val: 0.330386	test: 0.176975

Epoch: 21
Loss: 0.1088702328758974
ROC train: 0.888000	val: 0.778721	test: 0.754146
PRC train: 0.508915	val: 0.372674	test: 0.155441

Epoch: 22
Loss: 0.10786132547847352
ROC train: 0.894369	val: 0.750514	test: 0.744765
PRC train: 0.535095	val: 0.349426	test: 0.181575

Epoch: 23
Loss: 0.10843122891051876
ROC train: 0.890298	val: 0.764740	test: 0.760584
PRC train: 0.529412	val: 0.307933	test: 0.128430

Epoch: 24
Loss: 0.10845473594460737
ROC train: 0.894284	val: 0.748111	test: 0.746693
PRC train: 0.537266	val: 0.326763	test: 0.164204

Epoch: 25
Loss: 0.10601941976798172
ROC train: 0.896592	val: 0.741044	test: 0.749845
PRC train: 0.538884	val: 0.299462	test: 0.139080

Epoch: 26
Loss: 0.10592833224641925
ROC train: 0.889909	val: 0.778782	test: 0.744549
PRC train: 0.534956	val: 0.341743	test: 0.199844

Epoch: 27
Loss: 0.10612917326938615
ROC train: 0.898224	val: 0.760227	test: 0.724709
PRC train: 0.546079	val: 0.317005	test: 0.129688

Epoch: 28
Loss: 0.10487245370588336
ROC train: 0.898335	val: 0.771801	test: 0.765892
PRC train: 0.540332	val: 0.353237	test: 0.189000

Epoch: 29
Loss: 0.10576416999508796
ROC train: 0.903063	val: 0.786164	test: 0.737484
PRC train: 0.552723	val: 0.299981	test: 0.117814

Epoch: 30
Loss: 0.10489556331305686
ROC train: 0.901533	val: 0.759388	test: 0.767305
PRC train: 0.540763	val: 0.350627	test: 0.192637

Epoch: 31
Loss: 0.10372564391929817
ROC train: 0.906281	val: 0.781354	test: 0.768311
PRC train: 0.551677	val: 0.383098	test: 0.197195

Epoch: 32
Loss: 0.10375427681503939
ROC train: 0.915787	val: 0.780968	test: 0.775280
PRC train: 0.576192	val: 0.345539	test: 0.145472

Epoch: 33
Loss: 0.10303402349493836Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.0.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:0
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/hiv/noise=0.0
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/hiv/noise=0.0/hiv_scaff_1_20-05_15-07-05  ]
[ Using Seed :  1  ]
[ Using device :  cuda:0  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.25488527102093916
ROC train: 0.742670	val: 0.725152	test: 0.677947
PRC train: 0.188789	val: 0.183169	test: 0.180477

Epoch: 2
Loss: 0.14118429467581886
ROC train: 0.768971	val: 0.724176	test: 0.727969
PRC train: 0.284545	val: 0.244391	test: 0.197184

Epoch: 3
Loss: 0.1362819405992362
ROC train: 0.795235	val: 0.754829	test: 0.733330
PRC train: 0.321153	val: 0.311152	test: 0.211490

Epoch: 4
Loss: 0.13188402734386792
ROC train: 0.811950	val: 0.757434	test: 0.710168
PRC train: 0.370377	val: 0.290229	test: 0.210732

Epoch: 5
Loss: 0.1287421093716967
ROC train: 0.822410	val: 0.765463	test: 0.684725
PRC train: 0.363498	val: 0.297676	test: 0.153107

Epoch: 6
Loss: 0.1265897294201639
ROC train: 0.820819	val: 0.742011	test: 0.725275
PRC train: 0.359244	val: 0.343931	test: 0.260176

Epoch: 7
Loss: 0.12494528397474669
ROC train: 0.837224	val: 0.782735	test: 0.728917
PRC train: 0.413912	val: 0.351189	test: 0.209629

Epoch: 8
Loss: 0.12476949479712082
ROC train: 0.838894	val: 0.759810	test: 0.715620
PRC train: 0.417630	val: 0.337275	test: 0.188761

Epoch: 9
Loss: 0.12246990039774824
ROC train: 0.846763	val: 0.784128	test: 0.712640
PRC train: 0.442178	val: 0.371276	test: 0.172827

Epoch: 10
Loss: 0.12017475038460163
ROC train: 0.853167	val: 0.769425	test: 0.744126
PRC train: 0.444196	val: 0.339629	test: 0.155921

Epoch: 11
Loss: 0.11957218930154896
ROC train: 0.852843	val: 0.769031	test: 0.715808
PRC train: 0.450850	val: 0.357835	test: 0.210562

Epoch: 12
Loss: 0.1158882966433104
ROC train: 0.849111	val: 0.780589	test: 0.726229
PRC train: 0.444285	val: 0.320235	test: 0.195953

Epoch: 13
Loss: 0.11585599170383538
ROC train: 0.862730	val: 0.757416	test: 0.736567
PRC train: 0.460811	val: 0.326328	test: 0.204150

Epoch: 14
Loss: 0.11476488150562872
ROC train: 0.862489	val: 0.748787	test: 0.742745
PRC train: 0.436220	val: 0.331014	test: 0.225060

Epoch: 15
Loss: 0.11339070901289437
ROC train: 0.870064	val: 0.782074	test: 0.737919
PRC train: 0.481286	val: 0.353152	test: 0.172583

Epoch: 16
Loss: 0.11185338659148172
ROC train: 0.873320	val: 0.768427	test: 0.725750
PRC train: 0.473678	val: 0.357113	test: 0.158255

Epoch: 17
Loss: 0.1126493140027037
ROC train: 0.871944	val: 0.777704	test: 0.745271
PRC train: 0.483423	val: 0.329897	test: 0.232855

Epoch: 18
Loss: 0.11126798733152587
ROC train: 0.877369	val: 0.771752	test: 0.736538
PRC train: 0.489024	val: 0.356915	test: 0.189381

Epoch: 19
Loss: 0.1109687657339261
ROC train: 0.887897	val: 0.773754	test: 0.742102
PRC train: 0.526192	val: 0.363766	test: 0.188405

Epoch: 20
Loss: 0.10918411551652228
ROC train: 0.883730	val: 0.758237	test: 0.741808
PRC train: 0.520119	val: 0.298400	test: 0.186416

Epoch: 21
Loss: 0.10903598160658722
ROC train: 0.895170	val: 0.769143	test: 0.764082
PRC train: 0.534101	val: 0.363868	test: 0.195971

Epoch: 22
Loss: 0.10854532789503092
ROC train: 0.890505	val: 0.769961	test: 0.755832
PRC train: 0.518589	val: 0.339735	test: 0.213678

Epoch: 23
Loss: 0.10824321478173826
ROC train: 0.896803	val: 0.795445	test: 0.755916
PRC train: 0.525009	val: 0.371282	test: 0.184059

Epoch: 24
Loss: 0.10537001807447902
ROC train: 0.899765	val: 0.771375	test: 0.751384
PRC train: 0.543294	val: 0.347616	test: 0.205305

Epoch: 25
Loss: 0.10705676275119985
ROC train: 0.892018	val: 0.767986	test: 0.737467
PRC train: 0.522900	val: 0.344772	test: 0.191784

Epoch: 26
Loss: 0.10531662703276293
ROC train: 0.903501	val: 0.778262	test: 0.759356
PRC train: 0.555317	val: 0.334723	test: 0.161406

Epoch: 27
Loss: 0.10446795935003778
ROC train: 0.903253	val: 0.764964	test: 0.763576
PRC train: 0.551055	val: 0.359788	test: 0.208138

Epoch: 28
Loss: 0.1047480294322568
ROC train: 0.914317	val: 0.771124	test: 0.731389
PRC train: 0.579653	val: 0.330230	test: 0.156043

Epoch: 29
Loss: 0.10381560668131218
ROC train: 0.903640	val: 0.744424	test: 0.753939
PRC train: 0.553028	val: 0.371292	test: 0.169178

Epoch: 30
Loss: 0.10210147819912958
ROC train: 0.912291	val: 0.784385	test: 0.744893
PRC train: 0.561364	val: 0.349970	test: 0.177822

Epoch: 31
Loss: 0.10266368667760149
ROC train: 0.906843	val: 0.759428	test: 0.723834
PRC train: 0.551593	val: 0.303708	test: 0.238000

Epoch: 32
Loss: 0.10334517313470033
ROC train: 0.913400	val: 0.771703	test: 0.744644
PRC train: 0.575244	val: 0.383912	test: 0.207437

Epoch: 33
Loss: 0.1006911767931211Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.0.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:0
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/hiv/noise=0.0
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/hiv/noise=0.0/hiv_scaff_3_20-05_15-07-05  ]
[ Using Seed :  3  ]
[ Using device :  cuda:0  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.25645571639236786
ROC train: 0.763602	val: 0.758082	test: 0.712824
PRC train: 0.246973	val: 0.205863	test: 0.198879

Epoch: 2
Loss: 0.1391355448440591
ROC train: 0.768297	val: 0.748781	test: 0.745671
PRC train: 0.253662	val: 0.269329	test: 0.255193

Epoch: 3
Loss: 0.13332922902693947
ROC train: 0.795960	val: 0.787968	test: 0.705628
PRC train: 0.319765	val: 0.260422	test: 0.172865

Epoch: 4
Loss: 0.13214331110211314
ROC train: 0.799198	val: 0.755309	test: 0.711188
PRC train: 0.357726	val: 0.266386	test: 0.219327

Epoch: 5
Loss: 0.13005156262651055
ROC train: 0.822364	val: 0.769612	test: 0.724527
PRC train: 0.384939	val: 0.264588	test: 0.140239

Epoch: 6
Loss: 0.12750836191489887
ROC train: 0.818680	val: 0.778938	test: 0.725070
PRC train: 0.374249	val: 0.345339	test: 0.239632

Epoch: 7
Loss: 0.1257729882498389
ROC train: 0.827692	val: 0.780448	test: 0.719273
PRC train: 0.399324	val: 0.306475	test: 0.202783

Epoch: 8
Loss: 0.1237370975834029
ROC train: 0.839712	val: 0.758328	test: 0.701348
PRC train: 0.404592	val: 0.258294	test: 0.122051

Epoch: 9
Loss: 0.12149261014728485
ROC train: 0.836303	val: 0.773601	test: 0.719149
PRC train: 0.420452	val: 0.318048	test: 0.208412

Epoch: 10
Loss: 0.12210886827766196
ROC train: 0.843534	val: 0.766899	test: 0.737125
PRC train: 0.446031	val: 0.304169	test: 0.200278

Epoch: 11
Loss: 0.11863737145851301
ROC train: 0.859400	val: 0.789976	test: 0.742467
PRC train: 0.469112	val: 0.354484	test: 0.217710

Epoch: 12
Loss: 0.11711176072908501
ROC train: 0.857458	val: 0.798519	test: 0.747815
PRC train: 0.449621	val: 0.385226	test: 0.222596

Epoch: 13
Loss: 0.11667614646319197
ROC train: 0.866281	val: 0.763525	test: 0.736395
PRC train: 0.457531	val: 0.328759	test: 0.160793

Epoch: 14
Loss: 0.11488066281666107
ROC train: 0.865785	val: 0.783004	test: 0.736526
PRC train: 0.455571	val: 0.323072	test: 0.179967

Epoch: 15
Loss: 0.11567517869502247
ROC train: 0.873950	val: 0.777502	test: 0.750578
PRC train: 0.487950	val: 0.339072	test: 0.171577

Epoch: 16
Loss: 0.1135932968947737
ROC train: 0.868867	val: 0.770389	test: 0.770488
PRC train: 0.494906	val: 0.329923	test: 0.231537

Epoch: 17
Loss: 0.11337746515235833
ROC train: 0.877824	val: 0.805632	test: 0.754551
PRC train: 0.500520	val: 0.353137	test: 0.203575

Epoch: 18
Loss: 0.11204938262616662
ROC train: 0.879236	val: 0.782444	test: 0.740163
PRC train: 0.483703	val: 0.336307	test: 0.136577

Epoch: 19
Loss: 0.11121540599949044
ROC train: 0.882488	val: 0.778807	test: 0.748875
PRC train: 0.488798	val: 0.378534	test: 0.222661

Epoch: 20
Loss: 0.10974517060352758
ROC train: 0.877630	val: 0.763175	test: 0.718996
PRC train: 0.511976	val: 0.345577	test: 0.207448

Epoch: 21
Loss: 0.10863393674333498
ROC train: 0.886327	val: 0.808810	test: 0.727718
PRC train: 0.526863	val: 0.339296	test: 0.200876

Epoch: 22
Loss: 0.10948455606413092
ROC train: 0.896774	val: 0.763540	test: 0.763632
PRC train: 0.540977	val: 0.345804	test: 0.188346

Epoch: 23
Loss: 0.10949025251686836
ROC train: 0.895664	val: 0.783617	test: 0.744843
PRC train: 0.530746	val: 0.353110	test: 0.170561

Epoch: 24
Loss: 0.10723885662669387
ROC train: 0.897461	val: 0.754614	test: 0.746179
PRC train: 0.530070	val: 0.339858	test: 0.221048

Epoch: 25
Loss: 0.10638637088357128
ROC train: 0.900508	val: 0.770616	test: 0.753742
PRC train: 0.532606	val: 0.323118	test: 0.207457

Epoch: 26
Loss: 0.10629764291565423
ROC train: 0.900682	val: 0.776939	test: 0.755405
PRC train: 0.540795	val: 0.357110	test: 0.184701

Epoch: 27
Loss: 0.10518878501256938
ROC train: 0.905941	val: 0.798979	test: 0.755482
PRC train: 0.555783	val: 0.320939	test: 0.193055

Epoch: 28
Loss: 0.10452313732271289
ROC train: 0.907895	val: 0.789903	test: 0.749225
PRC train: 0.556466	val: 0.323769	test: 0.172765

Epoch: 29
Loss: 0.10390368327485
ROC train: 0.908016	val: 0.788243	test: 0.742598
PRC train: 0.567878	val: 0.357202	test: 0.165431

Epoch: 30
Loss: 0.10344495114998091
ROC train: 0.910620	val: 0.788798	test: 0.762344
PRC train: 0.564095	val: 0.351820	test: 0.209987

Epoch: 31
Loss: 0.10187669677758995
ROC train: 0.910712	val: 0.806541	test: 0.755175
PRC train: 0.574506	val: 0.324177	test: 0.152951

Epoch: 32
Loss: 0.10244131011490969
ROC train: 0.911623	val: 0.781688	test: 0.757705
PRC train: 0.571795	val: 0.335560	test: 0.181193

Epoch: 33
Loss: 0.10184342944803627Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.05.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:1
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.05
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/hiv/noise=0.05
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/hiv/noise=0.05/hiv_scaff_2_20-05_15-07-05  ]
[ Using Seed :  2  ]
[ Using device :  cuda:1  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.26001961320147143
ROC train: 0.739095	val: 0.701107	test: 0.650383
PRC train: 0.177919	val: 0.171581	test: 0.178064

Epoch: 2
Loss: 0.14457966224794974
ROC train: 0.768230	val: 0.784535	test: 0.697589
PRC train: 0.260578	val: 0.228601	test: 0.166245

Epoch: 3
Loss: 0.13978953879804135
ROC train: 0.776221	val: 0.777805	test: 0.721625
PRC train: 0.278857	val: 0.257343	test: 0.214755

Epoch: 4
Loss: 0.13681570176783364
ROC train: 0.801538	val: 0.754241	test: 0.730454
PRC train: 0.303299	val: 0.257392	test: 0.205915

Epoch: 5
Loss: 0.13465993560587505
ROC train: 0.808968	val: 0.757309	test: 0.731117
PRC train: 0.322672	val: 0.271676	test: 0.228822

Epoch: 6
Loss: 0.13087337673160324
ROC train: 0.803720	val: 0.750046	test: 0.736837
PRC train: 0.304146	val: 0.279346	test: 0.275988

Epoch: 7
Loss: 0.1297996565056834
ROC train: 0.826819	val: 0.791186	test: 0.763674
PRC train: 0.348636	val: 0.307353	test: 0.296724

Epoch: 8
Loss: 0.12669536302149317
ROC train: 0.840467	val: 0.758586	test: 0.731723
PRC train: 0.389660	val: 0.307333	test: 0.216621

Epoch: 9
Loss: 0.12528005613649965
ROC train: 0.840855	val: 0.768381	test: 0.734178
PRC train: 0.385773	val: 0.337594	test: 0.241471

Epoch: 10
Loss: 0.12311107372192409
ROC train: 0.854142	val: 0.795512	test: 0.740752
PRC train: 0.429382	val: 0.316716	test: 0.187004

Epoch: 11
Loss: 0.12110190672269965
ROC train: 0.844693	val: 0.777465	test: 0.738778
PRC train: 0.380372	val: 0.359258	test: 0.198076

Epoch: 12
Loss: 0.12120735424899881
ROC train: 0.859010	val: 0.787285	test: 0.751025
PRC train: 0.417128	val: 0.376665	test: 0.262079

Epoch: 13
Loss: 0.12046706675247142
ROC train: 0.851676	val: 0.759777	test: 0.694060
PRC train: 0.401481	val: 0.263771	test: 0.178325

Epoch: 14
Loss: 0.11886413790114712
ROC train: 0.858634	val: 0.759562	test: 0.742092
PRC train: 0.451796	val: 0.378795	test: 0.261457

Epoch: 15
Loss: 0.11765494348474455
ROC train: 0.870235	val: 0.789600	test: 0.749789
PRC train: 0.478453	val: 0.384844	test: 0.213232

Epoch: 16
Loss: 0.11484082355690285
ROC train: 0.876951	val: 0.791994	test: 0.752759
PRC train: 0.490044	val: 0.337721	test: 0.185282

Epoch: 17
Loss: 0.11462948636133265
ROC train: 0.864308	val: 0.772046	test: 0.735142
PRC train: 0.436719	val: 0.391531	test: 0.191491

Epoch: 18
Loss: 0.11384912671307613
ROC train: 0.890763	val: 0.779927	test: 0.730512
PRC train: 0.502319	val: 0.326962	test: 0.149026

Epoch: 19
Loss: 0.11227576387561299
ROC train: 0.887526	val: 0.805308	test: 0.759746
PRC train: 0.508114	val: 0.397334	test: 0.207062

Epoch: 20
Loss: 0.11235230920543737
ROC train: 0.893462	val: 0.795733	test: 0.751121
PRC train: 0.525460	val: 0.374025	test: 0.211299

Epoch: 21
Loss: 0.11016060818058088
ROC train: 0.894625	val: 0.800001	test: 0.750101
PRC train: 0.536946	val: 0.383966	test: 0.185986

Epoch: 22
Loss: 0.11008969783653973
ROC train: 0.899345	val: 0.794416	test: 0.741311
PRC train: 0.540801	val: 0.336734	test: 0.156535

Epoch: 23
Loss: 0.10878909852799348
ROC train: 0.898286	val: 0.778608	test: 0.752796
PRC train: 0.538358	val: 0.374159	test: 0.217526

Epoch: 24
Loss: 0.10773107419640159
ROC train: 0.913129	val: 0.789738	test: 0.747349
PRC train: 0.560641	val: 0.347044	test: 0.177583

Epoch: 25
Loss: 0.10494495212932606
ROC train: 0.903412	val: 0.768105	test: 0.758224
PRC train: 0.553444	val: 0.394524	test: 0.236948

Epoch: 26
Loss: 0.10649672927853399
ROC train: 0.904456	val: 0.796514	test: 0.742193
PRC train: 0.559810	val: 0.376218	test: 0.209416

Epoch: 27
Loss: 0.10512985632256552
ROC train: 0.919731	val: 0.811943	test: 0.761394
PRC train: 0.602487	val: 0.382147	test: 0.209635

Epoch: 28
Loss: 0.10037371665542433
ROC train: 0.913552	val: 0.791878	test: 0.744555
PRC train: 0.574796	val: 0.316106	test: 0.171097

Epoch: 29
Loss: 0.10430300452316464
ROC train: 0.915626	val: 0.792037	test: 0.763852
PRC train: 0.601267	val: 0.378042	test: 0.184057

Epoch: 30
Loss: 0.10058630360686094
ROC train: 0.924066	val: 0.815525	test: 0.747112
PRC train: 0.624398	val: 0.367231	test: 0.192857

Epoch: 31
Loss: 0.09920085714140621
ROC train: 0.922778	val: 0.815243	test: 0.741737
PRC train: 0.617226	val: 0.390545	test: 0.167332

Epoch: 32
Loss: 0.09924588813077463
ROC train: 0.929904	val: 0.793917	test: 0.751791Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.05.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:1
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.05
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/hiv/noise=0.05
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/hiv/noise=0.05/hiv_scaff_1_20-05_15-07-05  ]
[ Using Seed :  1  ]
[ Using device :  cuda:1  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.256591818780807
ROC train: 0.737677	val: 0.724699	test: 0.650291
PRC train: 0.194469	val: 0.139170	test: 0.160480

Epoch: 2
Loss: 0.14325555664077672
ROC train: 0.768682	val: 0.732137	test: 0.716103
PRC train: 0.259102	val: 0.246857	test: 0.202695

Epoch: 3
Loss: 0.1375792225554918
ROC train: 0.795452	val: 0.770849	test: 0.713824
PRC train: 0.312063	val: 0.232420	test: 0.170783

Epoch: 4
Loss: 0.13481165973055018
ROC train: 0.808364	val: 0.740257	test: 0.712362
PRC train: 0.336594	val: 0.254508	test: 0.142656

Epoch: 5
Loss: 0.13153663660514436
ROC train: 0.792068	val: 0.768439	test: 0.726491
PRC train: 0.282594	val: 0.305818	test: 0.215152

Epoch: 6
Loss: 0.1304473169564018
ROC train: 0.815522	val: 0.761908	test: 0.744479
PRC train: 0.325154	val: 0.268870	test: 0.232805

Epoch: 7
Loss: 0.12707874851219203
ROC train: 0.834776	val: 0.762937	test: 0.740482
PRC train: 0.393724	val: 0.309878	test: 0.201064

Epoch: 8
Loss: 0.12526576148936638
ROC train: 0.846167	val: 0.767680	test: 0.736241
PRC train: 0.385368	val: 0.246814	test: 0.161516

Epoch: 9
Loss: 0.12395319653782176
ROC train: 0.851004	val: 0.757523	test: 0.721968
PRC train: 0.413605	val: 0.251990	test: 0.129565

Epoch: 10
Loss: 0.12216383365409657
ROC train: 0.849986	val: 0.780631	test: 0.748742
PRC train: 0.402865	val: 0.373960	test: 0.226323

Epoch: 11
Loss: 0.12103468211977456
ROC train: 0.844672	val: 0.776841	test: 0.725929
PRC train: 0.400233	val: 0.349944	test: 0.259390

Epoch: 12
Loss: 0.11993983972023231
ROC train: 0.863719	val: 0.789110	test: 0.738431
PRC train: 0.444698	val: 0.359895	test: 0.203786

Epoch: 13
Loss: 0.1172191279452523
ROC train: 0.872200	val: 0.785206	test: 0.741882
PRC train: 0.481661	val: 0.352933	test: 0.228157

Epoch: 14
Loss: 0.11703041441298508
ROC train: 0.877407	val: 0.793712	test: 0.752589
PRC train: 0.483109	val: 0.356352	test: 0.177720

Epoch: 15
Loss: 0.1162040972670819
ROC train: 0.876060	val: 0.763546	test: 0.750663
PRC train: 0.473789	val: 0.303240	test: 0.196354

Epoch: 16
Loss: 0.11493354831232433
ROC train: 0.885420	val: 0.781406	test: 0.758537
PRC train: 0.494091	val: 0.318056	test: 0.192842

Epoch: 17
Loss: 0.11306289184403974
ROC train: 0.884980	val: 0.789343	test: 0.756851
PRC train: 0.492814	val: 0.338463	test: 0.236221

Epoch: 18
Loss: 0.11111893670194557
ROC train: 0.883854	val: 0.768470	test: 0.732484
PRC train: 0.484996	val: 0.327661	test: 0.287459

Epoch: 19
Loss: 0.11043529103083097
ROC train: 0.889888	val: 0.767606	test: 0.741414
PRC train: 0.531261	val: 0.313033	test: 0.219295

Epoch: 20
Loss: 0.11043026934522208
ROC train: 0.885005	val: 0.768797	test: 0.728139
PRC train: 0.505404	val: 0.302374	test: 0.216907

Epoch: 21
Loss: 0.10769564031638862
ROC train: 0.901838	val: 0.781783	test: 0.758885
PRC train: 0.493674	val: 0.356568	test: 0.227557

Epoch: 22
Loss: 0.10708529502662653
ROC train: 0.905960	val: 0.785895	test: 0.732102
PRC train: 0.528706	val: 0.223475	test: 0.139491

Epoch: 23
Loss: 0.10620636084791431
ROC train: 0.912469	val: 0.790791	test: 0.745677
PRC train: 0.571688	val: 0.295817	test: 0.155864

Epoch: 24
Loss: 0.10300541221624047
ROC train: 0.908039	val: 0.760435	test: 0.743755
PRC train: 0.561342	val: 0.295498	test: 0.159793

Epoch: 25
Loss: 0.1062315085026652
ROC train: 0.912226	val: 0.808979	test: 0.750970
PRC train: 0.549979	val: 0.376839	test: 0.213051

Epoch: 26
Loss: 0.10335093998328036
ROC train: 0.911523	val: 0.785534	test: 0.705290
PRC train: 0.576028	val: 0.332045	test: 0.116767

Epoch: 27
Loss: 0.1027298992733437
ROC train: 0.917361	val: 0.776437	test: 0.740008
PRC train: 0.568377	val: 0.336825	test: 0.230823

Epoch: 28
Loss: 0.10175160906874137
ROC train: 0.929621	val: 0.808250	test: 0.750445
PRC train: 0.605500	val: 0.367096	test: 0.213941

Epoch: 29
Loss: 0.10097292728531167
ROC train: 0.928087	val: 0.806676	test: 0.743935
PRC train: 0.604605	val: 0.310719	test: 0.155837

Epoch: 30
Loss: 0.09908227007212689
ROC train: 0.933308	val: 0.806517	test: 0.742965
PRC train: 0.626084	val: 0.336097	test: 0.231336

Epoch: 31
Loss: 0.09835560867113743
ROC train: 0.927026	val: 0.807335	test: 0.759148
PRC train: 0.613066	val: 0.313985	test: 0.188648

Epoch: 32
Loss: 0.0970592151808753
ROC train: 0.935983	val: 0.803819	test: 0.739120Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.1.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:2
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.1
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/hiv/noise=0.1
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/hiv/noise=0.1/hiv_scaff_2_20-05_15-07-05  ]
[ Using Seed :  2  ]
[ Using device :  cuda:2  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.2605715940782716
ROC train: 0.731950	val: 0.728086	test: 0.645233
PRC train: 0.158466	val: 0.157360	test: 0.157439

Epoch: 2
Loss: 0.14718237662490316
ROC train: 0.747807	val: 0.782564	test: 0.677029
PRC train: 0.209837	val: 0.215485	test: 0.189270

Epoch: 3
Loss: 0.14278775373251634
ROC train: 0.773455	val: 0.769211	test: 0.733720
PRC train: 0.251070	val: 0.261626	test: 0.214104

Epoch: 4
Loss: 0.14008139819457568
ROC train: 0.798974	val: 0.775295	test: 0.706912
PRC train: 0.285776	val: 0.285623	test: 0.184600

Epoch: 5
Loss: 0.13680332631003866
ROC train: 0.802430	val: 0.765628	test: 0.742579
PRC train: 0.308274	val: 0.259415	test: 0.236012

Epoch: 6
Loss: 0.13290543363979695
ROC train: 0.815480	val: 0.786161	test: 0.712650
PRC train: 0.337539	val: 0.284287	test: 0.194630

Epoch: 7
Loss: 0.13259436430925506
ROC train: 0.810808	val: 0.774021	test: 0.715081
PRC train: 0.325764	val: 0.280663	test: 0.197475

Epoch: 8
Loss: 0.13020912964130993
ROC train: 0.825440	val: 0.768969	test: 0.722430
PRC train: 0.350281	val: 0.292645	test: 0.171504

Epoch: 9
Loss: 0.1289944850279404
ROC train: 0.836482	val: 0.783075	test: 0.719576
PRC train: 0.380225	val: 0.325675	test: 0.248971

Epoch: 10
Loss: 0.12587595121636733
ROC train: 0.843071	val: 0.779295	test: 0.727791
PRC train: 0.396270	val: 0.325878	test: 0.215829

Epoch: 11
Loss: 0.1250425519269221
ROC train: 0.843668	val: 0.776829	test: 0.718606
PRC train: 0.349238	val: 0.322337	test: 0.207991

Epoch: 12
Loss: 0.12377273997126703
ROC train: 0.857905	val: 0.780537	test: 0.719326
PRC train: 0.428328	val: 0.335528	test: 0.255576

Epoch: 13
Loss: 0.12388148445470225
ROC train: 0.863851	val: 0.758154	test: 0.664250
PRC train: 0.432687	val: 0.294858	test: 0.201732

Epoch: 14
Loss: 0.12053583727279372
ROC train: 0.863746	val: 0.775613	test: 0.704430
PRC train: 0.441110	val: 0.359609	test: 0.250251

Epoch: 15
Loss: 0.11995738627313948
ROC train: 0.873810	val: 0.776602	test: 0.686832
PRC train: 0.443900	val: 0.322562	test: 0.156867

Epoch: 16
Loss: 0.1184291261566335
ROC train: 0.875031	val: 0.790056	test: 0.710290
PRC train: 0.481299	val: 0.367991	test: 0.162475

Epoch: 17
Loss: 0.11575229040073139
ROC train: 0.871632	val: 0.786171	test: 0.710759
PRC train: 0.449059	val: 0.355809	test: 0.195527

Epoch: 18
Loss: 0.11612052664285645
ROC train: 0.887254	val: 0.789713	test: 0.712930
PRC train: 0.499410	val: 0.330970	test: 0.184905

Epoch: 19
Loss: 0.11467957092241914
ROC train: 0.890032	val: 0.783770	test: 0.709465
PRC train: 0.505829	val: 0.356551	test: 0.191271

Epoch: 20
Loss: 0.11227195539710415
ROC train: 0.888896	val: 0.776939	test: 0.715139
PRC train: 0.491616	val: 0.347579	test: 0.209080

Epoch: 21
Loss: 0.11220930306328125
ROC train: 0.902277	val: 0.783623	test: 0.698571
PRC train: 0.528461	val: 0.326578	test: 0.174119

Epoch: 22
Loss: 0.1118931296229402
ROC train: 0.903159	val: 0.798936	test: 0.677835
PRC train: 0.498939	val: 0.283710	test: 0.092344

Epoch: 23
Loss: 0.11122127139419644
ROC train: 0.912509	val: 0.775549	test: 0.708322
PRC train: 0.552404	val: 0.350659	test: 0.219143

Epoch: 24
Loss: 0.10718931460815535
ROC train: 0.912200	val: 0.788694	test: 0.711812
PRC train: 0.568782	val: 0.373173	test: 0.190064

Epoch: 25
Loss: 0.10661080148355852
ROC train: 0.924791	val: 0.787812	test: 0.710394
PRC train: 0.594722	val: 0.353209	test: 0.187999

Epoch: 26
Loss: 0.10573511729838939
ROC train: 0.911103	val: 0.763378	test: 0.708683
PRC train: 0.562818	val: 0.303037	test: 0.205674

Epoch: 27
Loss: 0.1030546612417729
ROC train: 0.927447	val: 0.784548	test: 0.706024
PRC train: 0.612713	val: 0.359153	test: 0.168487

Epoch: 28
Loss: 0.10297161685477198
ROC train: 0.929820	val: 0.788271	test: 0.702916
PRC train: 0.604269	val: 0.318476	test: 0.137146

Epoch: 29
Loss: 0.10174900381487777
ROC train: 0.927746	val: 0.776936	test: 0.716451
PRC train: 0.604263	val: 0.311185	test: 0.157818

Epoch: 30
Loss: 0.10056246914857304
ROC train: 0.934054	val: 0.797873	test: 0.705873
PRC train: 0.631762	val: 0.330905	test: 0.163432

Epoch: 31
Loss: 0.099237265662093
ROC train: 0.944465	val: 0.788302	test: 0.688070
PRC train: 0.659750	val: 0.343599	test: 0.134901

Epoch: 32
Loss: 0.09812380265233027
ROC train: 0.939885	val: 0.788446	test: 0.707432Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.05.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:1
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.05
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/hiv/noise=0.05
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/hiv/noise=0.05/hiv_scaff_3_20-05_15-07-05  ]
[ Using Seed :  3  ]
[ Using device :  cuda:1  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.26124816287475566
ROC train: 0.738640	val: 0.731485	test: 0.722928
PRC train: 0.206449	val: 0.222427	test: 0.182760

Epoch: 2
Loss: 0.14503715006999124
ROC train: 0.764969	val: 0.747388	test: 0.723303
PRC train: 0.251666	val: 0.300062	test: 0.208604

Epoch: 3
Loss: 0.13937385615311035
ROC train: 0.780398	val: 0.749360	test: 0.744588
PRC train: 0.287968	val: 0.281738	test: 0.224785

Epoch: 4
Loss: 0.13594510388423578
ROC train: 0.794859	val: 0.771440	test: 0.729862
PRC train: 0.317572	val: 0.299432	test: 0.206145

Epoch: 5
Loss: 0.13319631287807995
ROC train: 0.805992	val: 0.778292	test: 0.745420
PRC train: 0.321424	val: 0.289724	test: 0.241413

Epoch: 6
Loss: 0.1295452358075148
ROC train: 0.809379	val: 0.760092	test: 0.781579
PRC train: 0.318148	val: 0.313244	test: 0.276271

Epoch: 7
Loss: 0.12936605353279332
ROC train: 0.831273	val: 0.783929	test: 0.734132
PRC train: 0.365692	val: 0.251049	test: 0.164755

Epoch: 8
Loss: 0.12620888872021832
ROC train: 0.835771	val: 0.773317	test: 0.730086
PRC train: 0.386177	val: 0.362866	test: 0.199914

Epoch: 9
Loss: 0.1251989283678507
ROC train: 0.834707	val: 0.759725	test: 0.741299
PRC train: 0.405731	val: 0.332122	test: 0.192555

Epoch: 10
Loss: 0.12445362586679716
ROC train: 0.842122	val: 0.752140	test: 0.738645
PRC train: 0.419039	val: 0.325901	test: 0.196376

Epoch: 11
Loss: 0.12186090297675908
ROC train: 0.848690	val: 0.790546	test: 0.723791
PRC train: 0.419412	val: 0.270957	test: 0.223929

Epoch: 12
Loss: 0.12002091916684522
ROC train: 0.854801	val: 0.788559	test: 0.737202
PRC train: 0.434845	val: 0.327896	test: 0.208817

Epoch: 13
Loss: 0.12109442057008751
ROC train: 0.853112	val: 0.768384	test: 0.765612
PRC train: 0.411401	val: 0.302134	test: 0.250153

Epoch: 14
Loss: 0.11908209086202201
ROC train: 0.859472	val: 0.779538	test: 0.738427
PRC train: 0.440660	val: 0.277329	test: 0.200650

Epoch: 15
Loss: 0.11728189773321877
ROC train: 0.866530	val: 0.782305	test: 0.733438
PRC train: 0.456211	val: 0.332258	test: 0.211984

Epoch: 16
Loss: 0.11583205496505788
ROC train: 0.871974	val: 0.804227	test: 0.750938
PRC train: 0.446699	val: 0.349389	test: 0.190859

Epoch: 17
Loss: 0.11460649783873719
ROC train: 0.883634	val: 0.775745	test: 0.714933
PRC train: 0.464329	val: 0.250479	test: 0.104854

Epoch: 18
Loss: 0.11505945735582229
ROC train: 0.879575	val: 0.779915	test: 0.746503
PRC train: 0.471383	val: 0.266471	test: 0.204329

Epoch: 19
Loss: 0.11251657638430225
ROC train: 0.884144	val: 0.777181	test: 0.753182
PRC train: 0.514354	val: 0.369250	test: 0.184380

Epoch: 20
Loss: 0.11129092248480148
ROC train: 0.878019	val: 0.761693	test: 0.723517
PRC train: 0.490657	val: 0.338815	test: 0.193543

Epoch: 21
Loss: 0.10955973335835315
ROC train: 0.893063	val: 0.771078	test: 0.745766
PRC train: 0.535843	val: 0.300459	test: 0.238099

Epoch: 22
Loss: 0.10817482351500951
ROC train: 0.890448	val: 0.733404	test: 0.732273
PRC train: 0.495252	val: 0.270281	test: 0.126995

Epoch: 23
Loss: 0.10752789218417116
ROC train: 0.909975	val: 0.772113	test: 0.747940
PRC train: 0.569670	val: 0.329638	test: 0.182696

Epoch: 24
Loss: 0.10448108448238677
ROC train: 0.915168	val: 0.771896	test: 0.737216
PRC train: 0.581060	val: 0.304636	test: 0.173514

Epoch: 25
Loss: 0.10550915619698907
ROC train: 0.914839	val: 0.751644	test: 0.739136
PRC train: 0.576923	val: 0.336198	test: 0.180409

Epoch: 26
Loss: 0.10318903601084879
ROC train: 0.920200	val: 0.760404	test: 0.732278
PRC train: 0.605253	val: 0.333789	test: 0.158181

Epoch: 27
Loss: 0.10235511080878192
ROC train: 0.917330	val: 0.775968	test: 0.726377
PRC train: 0.607057	val: 0.312383	test: 0.151293

Epoch: 28
Loss: 0.10228399063498879
ROC train: 0.930040	val: 0.775830	test: 0.761643
PRC train: 0.606200	val: 0.365896	test: 0.216379

Epoch: 29
Loss: 0.10074310847282096
ROC train: 0.924548	val: 0.730450	test: 0.728104
PRC train: 0.597792	val: 0.276395	test: 0.123561

Epoch: 30
Loss: 0.09824713348152134
ROC train: 0.936521	val: 0.773840	test: 0.729054
PRC train: 0.649869	val: 0.383377	test: 0.197623

Epoch: 31
Loss: 0.09871273642779467
ROC train: 0.939107	val: 0.765757	test: 0.740186
PRC train: 0.648150	val: 0.347890	test: 0.179576

Epoch: 32
Loss: 0.09650403220052271
ROC train: 0.938488	val: 0.775987	test: 0.750826Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.1.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:2
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.1
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/hiv/noise=0.1
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/hiv/noise=0.1/hiv_scaff_1_20-05_15-07-05  ]
[ Using Seed :  1  ]
[ Using device :  cuda:2  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.2585747964561953
ROC train: 0.718002	val: 0.751797	test: 0.717338
PRC train: 0.154533	val: 0.174654	test: 0.203276

Epoch: 2
Loss: 0.14745957294503514
ROC train: 0.753224	val: 0.740820	test: 0.739999
PRC train: 0.197664	val: 0.187840	test: 0.198500

Epoch: 3
Loss: 0.14291485460166362
ROC train: 0.773483	val: 0.750612	test: 0.693733
PRC train: 0.238492	val: 0.245828	test: 0.181169

Epoch: 4
Loss: 0.1398379561338672
ROC train: 0.800231	val: 0.742171	test: 0.722613
PRC train: 0.281909	val: 0.251282	test: 0.186353

Epoch: 5
Loss: 0.13623143792242576
ROC train: 0.807064	val: 0.776170	test: 0.727776
PRC train: 0.318651	val: 0.301330	test: 0.230262

Epoch: 6
Loss: 0.13459628032584778
ROC train: 0.806795	val: 0.764097	test: 0.753201
PRC train: 0.282563	val: 0.266516	test: 0.216726

Epoch: 7
Loss: 0.1323528373766636
ROC train: 0.816804	val: 0.773454	test: 0.743230
PRC train: 0.348899	val: 0.289869	test: 0.220380

Epoch: 8
Loss: 0.13006070551446292
ROC train: 0.834058	val: 0.755946	test: 0.724705
PRC train: 0.345396	val: 0.226777	test: 0.155099

Epoch: 9
Loss: 0.12781343425796207
ROC train: 0.830319	val: 0.748343	test: 0.717447
PRC train: 0.371975	val: 0.278463	test: 0.163657

Epoch: 10
Loss: 0.1267912759945049
ROC train: 0.845321	val: 0.765845	test: 0.743900
PRC train: 0.364440	val: 0.363087	test: 0.245470

Epoch: 11
Loss: 0.12491663131600213
ROC train: 0.841112	val: 0.778421	test: 0.730870
PRC train: 0.382373	val: 0.305356	test: 0.217502

Epoch: 12
Loss: 0.12441988722114534
ROC train: 0.858255	val: 0.789934	test: 0.742647
PRC train: 0.419676	val: 0.295229	test: 0.181709

Epoch: 13
Loss: 0.1224296758087323
ROC train: 0.858479	val: 0.788914	test: 0.737289
PRC train: 0.419682	val: 0.289735	test: 0.214600

Epoch: 14
Loss: 0.1213187428886651
ROC train: 0.869267	val: 0.803544	test: 0.711190
PRC train: 0.447983	val: 0.333757	test: 0.199321

Epoch: 15
Loss: 0.11956471063749187
ROC train: 0.873066	val: 0.790280	test: 0.740010
PRC train: 0.455875	val: 0.344939	test: 0.199494

Epoch: 16
Loss: 0.11762374100027521
ROC train: 0.868191	val: 0.782022	test: 0.738979
PRC train: 0.453901	val: 0.356375	test: 0.237742

Epoch: 17
Loss: 0.11659171683343056
ROC train: 0.882124	val: 0.767762	test: 0.733770
PRC train: 0.477874	val: 0.328060	test: 0.168778

Epoch: 18
Loss: 0.11477260534908193
ROC train: 0.887893	val: 0.773188	test: 0.730935
PRC train: 0.486624	val: 0.313281	test: 0.174802

Epoch: 19
Loss: 0.11422910336330167
ROC train: 0.887321	val: 0.772707	test: 0.733118
PRC train: 0.494563	val: 0.355443	test: 0.246440

Epoch: 20
Loss: 0.11298243050277557
ROC train: 0.892375	val: 0.766372	test: 0.725039
PRC train: 0.527251	val: 0.298575	test: 0.176441

Epoch: 21
Loss: 0.11109507947515528
ROC train: 0.897136	val: 0.786409	test: 0.723772
PRC train: 0.517083	val: 0.394138	test: 0.186228

Epoch: 22
Loss: 0.11231988919173426
ROC train: 0.905909	val: 0.774370	test: 0.713297
PRC train: 0.561490	val: 0.317522	test: 0.118808

Epoch: 23
Loss: 0.11034683447555127
ROC train: 0.906613	val: 0.806116	test: 0.752626
PRC train: 0.557843	val: 0.341451	test: 0.201718

Epoch: 24
Loss: 0.10690807121339439
ROC train: 0.903041	val: 0.793470	test: 0.739126
PRC train: 0.563372	val: 0.335179	test: 0.173970

Epoch: 25
Loss: 0.10824373531680993
ROC train: 0.914739	val: 0.764936	test: 0.712451
PRC train: 0.575348	val: 0.310957	test: 0.139340

Epoch: 26
Loss: 0.10516132626765454
ROC train: 0.911426	val: 0.755446	test: 0.683117
PRC train: 0.575185	val: 0.314313	test: 0.099520

Epoch: 27
Loss: 0.10504693568713107
ROC train: 0.924328	val: 0.776085	test: 0.706194
PRC train: 0.605153	val: 0.296277	test: 0.168689

Epoch: 28
Loss: 0.103228064948424
ROC train: 0.923285	val: 0.776868	test: 0.706060
PRC train: 0.605430	val: 0.342806	test: 0.119768

Epoch: 29
Loss: 0.10168328807773079
ROC train: 0.929320	val: 0.783494	test: 0.730769
PRC train: 0.626026	val: 0.334428	test: 0.141534

Epoch: 30
Loss: 0.10182346471466476
ROC train: 0.935902	val: 0.782407	test: 0.738643
PRC train: 0.641554	val: 0.329224	test: 0.172143

Epoch: 31
Loss: 0.1005654073672458
ROC train: 0.925935	val: 0.789851	test: 0.733981
PRC train: 0.600310	val: 0.315145	test: 0.203982

Epoch: 32
Loss: 0.09731823868373124
ROC train: 0.933472	val: 0.821569	test: 0.714249Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.1.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:2
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.1
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/hiv/noise=0.1
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/hiv/noise=0.1/hiv_scaff_3_20-05_15-07-05  ]
[ Using Seed :  3  ]
[ Using device :  cuda:2  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.2623580253831221
ROC train: 0.731595	val: 0.732146	test: 0.726592
PRC train: 0.157489	val: 0.188497	test: 0.184070

Epoch: 2
Loss: 0.14703518772765042
ROC train: 0.755045	val: 0.700957	test: 0.715796
PRC train: 0.209239	val: 0.188243	test: 0.230578

Epoch: 3
Loss: 0.1427334438800313
ROC train: 0.770506	val: 0.740756	test: 0.729031
PRC train: 0.244681	val: 0.267020	test: 0.162840

Epoch: 4
Loss: 0.13962894305969842
ROC train: 0.787945	val: 0.755233	test: 0.736366
PRC train: 0.280161	val: 0.281085	test: 0.237134

Epoch: 5
Loss: 0.13670171522451183
ROC train: 0.786812	val: 0.763779	test: 0.749339
PRC train: 0.279767	val: 0.291070	test: 0.245696

Epoch: 6
Loss: 0.13404661624968545
ROC train: 0.779429	val: 0.736757	test: 0.755992
PRC train: 0.254707	val: 0.280581	test: 0.301262

Epoch: 7
Loss: 0.1330830785952794
ROC train: 0.814054	val: 0.788002	test: 0.725754
PRC train: 0.331159	val: 0.262788	test: 0.163083

Epoch: 8
Loss: 0.1286703144587744
ROC train: 0.821278	val: 0.775160	test: 0.696956
PRC train: 0.362424	val: 0.344457	test: 0.176819

Epoch: 9
Loss: 0.12773454878354687
ROC train: 0.833374	val: 0.777119	test: 0.749456
PRC train: 0.393754	val: 0.314902	test: 0.224706

Epoch: 10
Loss: 0.12622133077133738
ROC train: 0.838588	val: 0.783151	test: 0.733255
PRC train: 0.398207	val: 0.356365	test: 0.228255

Epoch: 11
Loss: 0.12556491470979103
ROC train: 0.834687	val: 0.783219	test: 0.732502
PRC train: 0.376591	val: 0.341735	test: 0.228623

Epoch: 12
Loss: 0.12622360004983738
ROC train: 0.849449	val: 0.777181	test: 0.735443
PRC train: 0.401721	val: 0.285937	test: 0.180891

Epoch: 13
Loss: 0.12289278453643544
ROC train: 0.836962	val: 0.761721	test: 0.735694
PRC train: 0.382043	val: 0.285441	test: 0.253914

Epoch: 14
Loss: 0.12145569074305208
ROC train: 0.863558	val: 0.786183	test: 0.736389
PRC train: 0.443098	val: 0.346004	test: 0.254543

Epoch: 15
Loss: 0.12284717838860251
ROC train: 0.856241	val: 0.755668	test: 0.733819
PRC train: 0.465653	val: 0.310094	test: 0.192563

Epoch: 16
Loss: 0.11834964478774951
ROC train: 0.869955	val: 0.765242	test: 0.744875
PRC train: 0.472109	val: 0.365644	test: 0.211439

Epoch: 17
Loss: 0.11913828998225418
ROC train: 0.869516	val: 0.778157	test: 0.717552
PRC train: 0.454447	val: 0.274216	test: 0.120037

Epoch: 18
Loss: 0.11796043801591086
ROC train: 0.882659	val: 0.774508	test: 0.733027
PRC train: 0.486625	val: 0.280157	test: 0.186870

Epoch: 19
Loss: 0.11609231617669886
ROC train: 0.884090	val: 0.781376	test: 0.730016
PRC train: 0.505543	val: 0.376213	test: 0.167644

Epoch: 20
Loss: 0.11361521349766732
ROC train: 0.887190	val: 0.741323	test: 0.733521
PRC train: 0.504361	val: 0.382576	test: 0.242545

Epoch: 21
Loss: 0.11292681397998641
ROC train: 0.895740	val: 0.778767	test: 0.741598
PRC train: 0.535300	val: 0.361415	test: 0.199670

Epoch: 22
Loss: 0.11219776144144733
ROC train: 0.899180	val: 0.771620	test: 0.724900
PRC train: 0.547151	val: 0.324193	test: 0.176594

Epoch: 23
Loss: 0.1106962613133783
ROC train: 0.907912	val: 0.783213	test: 0.702186
PRC train: 0.573108	val: 0.367681	test: 0.209982

Epoch: 24
Loss: 0.10824884885121161
ROC train: 0.906764	val: 0.766335	test: 0.731679
PRC train: 0.568235	val: 0.370009	test: 0.212225

Epoch: 25
Loss: 0.1094124491089109
ROC train: 0.908227	val: 0.775099	test: 0.724469
PRC train: 0.562577	val: 0.354317	test: 0.142966

Epoch: 26
Loss: 0.10296079167188127
ROC train: 0.913796	val: 0.788504	test: 0.722735
PRC train: 0.588746	val: 0.335608	test: 0.229275

Epoch: 27
Loss: 0.1057086261946725
ROC train: 0.914196	val: 0.793635	test: 0.712213
PRC train: 0.571440	val: 0.316127	test: 0.152296

Epoch: 28
Loss: 0.10474352538808869
ROC train: 0.914480	val: 0.769039	test: 0.728299
PRC train: 0.543717	val: 0.376199	test: 0.228717

Epoch: 29
Loss: 0.10391421014095091
ROC train: 0.921640	val: 0.785828	test: 0.712206
PRC train: 0.591176	val: 0.318387	test: 0.159798

Epoch: 30
Loss: 0.10231882954210114
ROC train: 0.924227	val: 0.790733	test: 0.703469
PRC train: 0.622900	val: 0.348366	test: 0.161146

Epoch: 31
Loss: 0.09970278135123666
ROC train: 0.934786	val: 0.799735	test: 0.715976
PRC train: 0.655947	val: 0.384845	test: 0.204890

Epoch: 32
Loss: 0.10005412474253986
ROC train: 0.926171	val: 0.764174	test: 0.726934Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.2.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:3
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.2
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/hiv/noise=0.2
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/hiv/noise=0.2/hiv_scaff_2_20-05_15-07-05  ]
[ Using Seed :  2  ]
[ Using device :  cuda:3  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.2621668037184673
ROC train: 0.695467	val: 0.700164	test: 0.609216
PRC train: 0.134571	val: 0.155375	test: 0.184111

Epoch: 2
Loss: 0.1519050173350172
ROC train: 0.734482	val: 0.740379	test: 0.725437
PRC train: 0.164409	val: 0.192831	test: 0.175985

Epoch: 3
Loss: 0.14831179254257024
ROC train: 0.747492	val: 0.741298	test: 0.755202
PRC train: 0.181186	val: 0.222450	test: 0.195084

Epoch: 4
Loss: 0.1456242301888842
ROC train: 0.771301	val: 0.759786	test: 0.711837
PRC train: 0.194052	val: 0.240344	test: 0.182600

Epoch: 5
Loss: 0.14350742110330184
ROC train: 0.794250	val: 0.776201	test: 0.726729
PRC train: 0.244158	val: 0.281144	test: 0.185831

Epoch: 6
Loss: 0.13981550933592954
ROC train: 0.784459	val: 0.752385	test: 0.718500
PRC train: 0.236949	val: 0.255107	test: 0.202331

Epoch: 7
Loss: 0.13813420868389717
ROC train: 0.789271	val: 0.760986	test: 0.736287
PRC train: 0.236453	val: 0.193624	test: 0.231628

Epoch: 8
Loss: 0.13659426531201102
ROC train: 0.812279	val: 0.772854	test: 0.741465
PRC train: 0.298733	val: 0.271169	test: 0.232227

Epoch: 9
Loss: 0.13371184660380545
ROC train: 0.820293	val: 0.762511	test: 0.719759
PRC train: 0.320302	val: 0.305903	test: 0.222199

Epoch: 10
Loss: 0.1325805764560904
ROC train: 0.834242	val: 0.783623	test: 0.733935
PRC train: 0.350435	val: 0.304817	test: 0.228047

Epoch: 11
Loss: 0.13063572656155814
ROC train: 0.821479	val: 0.771755	test: 0.742085
PRC train: 0.292604	val: 0.287713	test: 0.258522

Epoch: 12
Loss: 0.12888827861294125
ROC train: 0.841044	val: 0.779722	test: 0.762881
PRC train: 0.374046	val: 0.292980	test: 0.258577

Epoch: 13
Loss: 0.1289704070208819
ROC train: 0.843755	val: 0.761871	test: 0.722268
PRC train: 0.355943	val: 0.255088	test: 0.218660

Epoch: 14
Loss: 0.12627203549648902
ROC train: 0.865024	val: 0.766736	test: 0.744416
PRC train: 0.412297	val: 0.301999	test: 0.250661

Epoch: 15
Loss: 0.12361266998046175
ROC train: 0.867244	val: 0.779872	test: 0.730559
PRC train: 0.425252	val: 0.269086	test: 0.229874

Epoch: 16
Loss: 0.12384533843333954
ROC train: 0.873648	val: 0.789802	test: 0.751181
PRC train: 0.433129	val: 0.294297	test: 0.217412

Epoch: 17
Loss: 0.12158838450954033
ROC train: 0.882417	val: 0.789116	test: 0.752653
PRC train: 0.457505	val: 0.325897	test: 0.242135

Epoch: 18
Loss: 0.12030256275437184
ROC train: 0.889098	val: 0.785325	test: 0.730288
PRC train: 0.462711	val: 0.295958	test: 0.246816

Epoch: 19
Loss: 0.11819483199496211
ROC train: 0.894829	val: 0.773751	test: 0.753298
PRC train: 0.470359	val: 0.342477	test: 0.244136

Epoch: 20
Loss: 0.11918582709190247
ROC train: 0.896463	val: 0.779860	test: 0.750360
PRC train: 0.490729	val: 0.324546	test: 0.261669

Epoch: 21
Loss: 0.11682739085993235
ROC train: 0.891911	val: 0.766237	test: 0.743238
PRC train: 0.457106	val: 0.319397	test: 0.262325

Epoch: 22
Loss: 0.11386869505635028
ROC train: 0.913925	val: 0.771761	test: 0.713932
PRC train: 0.529254	val: 0.276120	test: 0.186455

Epoch: 23
Loss: 0.11365808524559355
ROC train: 0.920793	val: 0.792034	test: 0.725920
PRC train: 0.549137	val: 0.318317	test: 0.204831

Epoch: 24
Loss: 0.11034372224458762
ROC train: 0.925009	val: 0.795610	test: 0.728745
PRC train: 0.572720	val: 0.314691	test: 0.249570

Epoch: 25
Loss: 0.1103263497650177
ROC train: 0.927931	val: 0.776216	test: 0.736065
PRC train: 0.576747	val: 0.342949	test: 0.261766

Epoch: 26
Loss: 0.1087963862450236
ROC train: 0.918242	val: 0.768956	test: 0.711951
PRC train: 0.534656	val: 0.325255	test: 0.219052

Epoch: 27
Loss: 0.10500146267607557
ROC train: 0.935247	val: 0.789526	test: 0.751198
PRC train: 0.619819	val: 0.343327	test: 0.263276

Epoch: 28
Loss: 0.1048651339058549
ROC train: 0.933711	val: 0.760726	test: 0.700456
PRC train: 0.603907	val: 0.303070	test: 0.222467

Epoch: 29
Loss: 0.10553850786140771
ROC train: 0.937936	val: 0.753310	test: 0.712928
PRC train: 0.627995	val: 0.279890	test: 0.207805

Epoch: 30
Loss: 0.1013264207004223
ROC train: 0.938965	val: 0.773062	test: 0.739116
PRC train: 0.645109	val: 0.303254	test: 0.255395

Epoch: 31
Loss: 0.10170153836366827
ROC train: 0.946744	val: 0.758273	test: 0.714653
PRC train: 0.655985	val: 0.337745	test: 0.256856

Epoch: 32
Loss: 0.09780154126284066
ROC train: 0.949868	val: 0.773081	test: 0.705002Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.2.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:3
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.2
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/hiv/noise=0.2
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/hiv/noise=0.2/hiv_scaff_1_20-05_15-07-05  ]
[ Using Seed :  1  ]
[ Using device :  cuda:3  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.26038442135126044
ROC train: 0.673282	val: 0.674355	test: 0.664746
PRC train: 0.100990	val: 0.120112	test: 0.180161

Epoch: 2
Loss: 0.15331010412096344
ROC train: 0.734932	val: 0.675157	test: 0.679594
PRC train: 0.146966	val: 0.123547	test: 0.153093

Epoch: 3
Loss: 0.14877922611516825
ROC train: 0.745046	val: 0.694365	test: 0.623975
PRC train: 0.166535	val: 0.138380	test: 0.148020

Epoch: 4
Loss: 0.14549968109435618
ROC train: 0.768846	val: 0.742869	test: 0.682020
PRC train: 0.179644	val: 0.180631	test: 0.165234

Epoch: 5
Loss: 0.14278330406141204
ROC train: 0.788125	val: 0.748668	test: 0.723181
PRC train: 0.218880	val: 0.228199	test: 0.189017

Epoch: 6
Loss: 0.1411699978772236
ROC train: 0.796617	val: 0.754198	test: 0.734448
PRC train: 0.236655	val: 0.235468	test: 0.206855

Epoch: 7
Loss: 0.13949582365027066
ROC train: 0.789044	val: 0.742400	test: 0.750947
PRC train: 0.254852	val: 0.230804	test: 0.228108

Epoch: 8
Loss: 0.13745029083234003
ROC train: 0.823702	val: 0.768053	test: 0.735010
PRC train: 0.295508	val: 0.248682	test: 0.178255

Epoch: 9
Loss: 0.1353711590381028
ROC train: 0.819309	val: 0.730716	test: 0.701178
PRC train: 0.302637	val: 0.251795	test: 0.184569

Epoch: 10
Loss: 0.13251629262373327
ROC train: 0.831098	val: 0.759605	test: 0.728228
PRC train: 0.326030	val: 0.279905	test: 0.218656

Epoch: 11
Loss: 0.13169407471130334
ROC train: 0.832001	val: 0.733153	test: 0.715732
PRC train: 0.305817	val: 0.276185	test: 0.175860

Epoch: 12
Loss: 0.13159867680895743
ROC train: 0.843374	val: 0.749602	test: 0.739468
PRC train: 0.369745	val: 0.302675	test: 0.217992

Epoch: 13
Loss: 0.13040998622738273
ROC train: 0.838758	val: 0.762934	test: 0.750420
PRC train: 0.357490	val: 0.307446	test: 0.253604

Epoch: 14
Loss: 0.12848649526386488
ROC train: 0.854656	val: 0.754624	test: 0.704249
PRC train: 0.391257	val: 0.281524	test: 0.151801

Epoch: 15
Loss: 0.12488941470903246
ROC train: 0.870070	val: 0.760276	test: 0.737309
PRC train: 0.410054	val: 0.305546	test: 0.248763

Epoch: 16
Loss: 0.1251439053912908
ROC train: 0.872703	val: 0.767998	test: 0.726068
PRC train: 0.418098	val: 0.271105	test: 0.227449

Epoch: 17
Loss: 0.122915553417935
ROC train: 0.873030	val: 0.767542	test: 0.719655
PRC train: 0.421604	val: 0.307268	test: 0.221952

Epoch: 18
Loss: 0.12244507062237461
ROC train: 0.877161	val: 0.779162	test: 0.751793
PRC train: 0.455801	val: 0.286319	test: 0.250450

Epoch: 19
Loss: 0.12003578949638373
ROC train: 0.882090	val: 0.783412	test: 0.742090
PRC train: 0.462607	val: 0.310403	test: 0.222760

Epoch: 20
Loss: 0.11952445898341713
ROC train: 0.883963	val: 0.774456	test: 0.739051
PRC train: 0.478388	val: 0.299627	test: 0.228448

Epoch: 21
Loss: 0.11929078358468137
ROC train: 0.870711	val: 0.749577	test: 0.733361
PRC train: 0.426213	val: 0.276221	test: 0.210406

Epoch: 22
Loss: 0.11654463925252266
ROC train: 0.896278	val: 0.776859	test: 0.707644
PRC train: 0.521931	val: 0.314930	test: 0.244590

Epoch: 23
Loss: 0.11494675013973112
ROC train: 0.909105	val: 0.783182	test: 0.759858
PRC train: 0.514989	val: 0.314004	test: 0.257479

Epoch: 24
Loss: 0.11258798755949989
ROC train: 0.912402	val: 0.774596	test: 0.706483
PRC train: 0.541568	val: 0.323919	test: 0.164209

Epoch: 25
Loss: 0.11125078132307145
ROC train: 0.911922	val: 0.771216	test: 0.719722
PRC train: 0.547300	val: 0.293800	test: 0.174951

Epoch: 26
Loss: 0.11065725752329969
ROC train: 0.920725	val: 0.779055	test: 0.686168
PRC train: 0.585239	val: 0.318603	test: 0.167786

Epoch: 27
Loss: 0.107596595609633
ROC train: 0.926592	val: 0.776639	test: 0.727926
PRC train: 0.578915	val: 0.323744	test: 0.224540

Epoch: 28
Loss: 0.10855244284201811
ROC train: 0.923213	val: 0.777202	test: 0.732963
PRC train: 0.590606	val: 0.275775	test: 0.222112

Epoch: 29
Loss: 0.10490756498210702
ROC train: 0.926244	val: 0.772775	test: 0.725365
PRC train: 0.566825	val: 0.223637	test: 0.145536

Epoch: 30
Loss: 0.10329307340156943
ROC train: 0.934792	val: 0.755775	test: 0.730937
PRC train: 0.614809	val: 0.314683	test: 0.272748

Epoch: 31
Loss: 0.10303883934152773
ROC train: 0.945640	val: 0.767254	test: 0.731401
PRC train: 0.667480	val: 0.353652	test: 0.248076

Epoch: 32
Loss: 0.10202785054102609
ROC train: 0.944105	val: 0.773209	test: 0.721787Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.2.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:3
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.2
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/hiv/noise=0.2
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/hiv/noise=0.2/hiv_scaff_3_20-05_15-07-05  ]
[ Using Seed :  3  ]
[ Using device :  cuda:3  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.26463496227743144
ROC train: 0.713311	val: 0.728441	test: 0.645540
PRC train: 0.132411	val: 0.146839	test: 0.106178

Epoch: 2
Loss: 0.15142056823114336
ROC train: 0.718243	val: 0.697800	test: 0.738755
PRC train: 0.144511	val: 0.160832	test: 0.192492

Epoch: 3
Loss: 0.1492338358170146
ROC train: 0.757857	val: 0.714035	test: 0.750907
PRC train: 0.182047	val: 0.199970	test: 0.203166

Epoch: 4
Loss: 0.14582133410594472
ROC train: 0.775952	val: 0.740341	test: 0.741270
PRC train: 0.213078	val: 0.204541	test: 0.185711

Epoch: 5
Loss: 0.14292147903652364
ROC train: 0.781495	val: 0.752251	test: 0.750354
PRC train: 0.223006	val: 0.222820	test: 0.185191

Epoch: 6
Loss: 0.1396115201071155
ROC train: 0.767852	val: 0.742278	test: 0.767178
PRC train: 0.197088	val: 0.215059	test: 0.244459

Epoch: 7
Loss: 0.13976641328029218
ROC train: 0.802635	val: 0.762012	test: 0.762357
PRC train: 0.299611	val: 0.257475	test: 0.211666

Epoch: 8
Loss: 0.13479846126440212
ROC train: 0.791957	val: 0.758947	test: 0.730111
PRC train: 0.280241	val: 0.275403	test: 0.192090

Epoch: 9
Loss: 0.13425444585494248
ROC train: 0.813500	val: 0.754225	test: 0.753856
PRC train: 0.311564	val: 0.264529	test: 0.193762

Epoch: 10
Loss: 0.1330287304541614
ROC train: 0.822698	val: 0.753393	test: 0.750913
PRC train: 0.312530	val: 0.282879	test: 0.259118

Epoch: 11
Loss: 0.13074525697440148
ROC train: 0.835764	val: 0.764027	test: 0.751025
PRC train: 0.353215	val: 0.278094	test: 0.218083

Epoch: 12
Loss: 0.1297254850819502
ROC train: 0.841635	val: 0.767548	test: 0.770816
PRC train: 0.355739	val: 0.318201	test: 0.225726

Epoch: 13
Loss: 0.12739071274157662
ROC train: 0.839684	val: 0.770402	test: 0.767614
PRC train: 0.362902	val: 0.297359	test: 0.263363

Epoch: 14
Loss: 0.12680725974220955
ROC train: 0.844924	val: 0.777459	test: 0.767000
PRC train: 0.370282	val: 0.321744	test: 0.264765

Epoch: 15
Loss: 0.12636004236313916
ROC train: 0.857629	val: 0.773586	test: 0.760998
PRC train: 0.394346	val: 0.309202	test: 0.245893

Epoch: 16
Loss: 0.12286179398924042
ROC train: 0.873660	val: 0.777141	test: 0.763340
PRC train: 0.417530	val: 0.342488	test: 0.265672

Epoch: 17
Loss: 0.12285818846063873
ROC train: 0.871764	val: 0.763889	test: 0.743046
PRC train: 0.440594	val: 0.284691	test: 0.195881

Epoch: 18
Loss: 0.11962621627181036
ROC train: 0.885653	val: 0.765276	test: 0.725964
PRC train: 0.487570	val: 0.315374	test: 0.228848

Epoch: 19
Loss: 0.11947860637916079
ROC train: 0.889710	val: 0.767131	test: 0.738099
PRC train: 0.461703	val: 0.304935	test: 0.202825

Epoch: 20
Loss: 0.11771257235994503
ROC train: 0.888589	val: 0.744776	test: 0.735682
PRC train: 0.485221	val: 0.320744	test: 0.245206

Epoch: 21
Loss: 0.11472999553765838
ROC train: 0.895805	val: 0.751194	test: 0.741897
PRC train: 0.497673	val: 0.308424	test: 0.280829

Epoch: 22
Loss: 0.11475369766104604
ROC train: 0.899359	val: 0.756923	test: 0.730478
PRC train: 0.505900	val: 0.315282	test: 0.240680

Epoch: 23
Loss: 0.11107378983878789
ROC train: 0.912269	val: 0.779523	test: 0.742691
PRC train: 0.564020	val: 0.315249	test: 0.279251

Epoch: 24
Loss: 0.10922796171813254
ROC train: 0.918787	val: 0.758772	test: 0.738645
PRC train: 0.589331	val: 0.311223	test: 0.233055

Epoch: 25
Loss: 0.10929561003028038
ROC train: 0.918154	val: 0.771054	test: 0.737297
PRC train: 0.570502	val: 0.354633	test: 0.259823

Epoch: 26
Loss: 0.10693670433857914
ROC train: 0.920411	val: 0.752235	test: 0.725070
PRC train: 0.579715	val: 0.313272	test: 0.230293

Epoch: 27
Loss: 0.10719062804907156
ROC train: 0.933146	val: 0.747805	test: 0.713032
PRC train: 0.620367	val: 0.311601	test: 0.295210

Epoch: 28
Loss: 0.10324487094152082
ROC train: 0.926379	val: 0.751118	test: 0.724485
PRC train: 0.555863	val: 0.337013	test: 0.257776

Epoch: 29
Loss: 0.10464701562510229
ROC train: 0.935080	val: 0.757009	test: 0.715624
PRC train: 0.638949	val: 0.286884	test: 0.234554

Epoch: 30
Loss: 0.10099596519741881
ROC train: 0.922411	val: 0.769373	test: 0.737695
PRC train: 0.570440	val: 0.357546	test: 0.259538

Epoch: 31
Loss: 0.09835425302566024
ROC train: 0.944564	val: 0.746127	test: 0.727996
PRC train: 0.627390	val: 0.329100	test: 0.298513

Epoch: 32
Loss: 0.0989381400929829
ROC train: 0.951894	val: 0.753451	test: 0.731521
ROC train: 0.917223	val: 0.772003	test: 0.756351
PRC train: 0.570661	val: 0.339409	test: 0.192821

Epoch: 34
Loss: 0.10117492819298338
ROC train: 0.913508	val: 0.762738	test: 0.753856
PRC train: 0.573129	val: 0.347940	test: 0.189493

Epoch: 35
Loss: 0.10020080410914732
ROC train: 0.922962	val: 0.796413	test: 0.745211
PRC train: 0.575681	val: 0.364709	test: 0.210851

Epoch: 36
Loss: 0.09969536293773325
ROC train: 0.922556	val: 0.773610	test: 0.756156
PRC train: 0.599254	val: 0.324990	test: 0.196079

Epoch: 37
Loss: 0.09863795951314144
ROC train: 0.908489	val: 0.753481	test: 0.751413
PRC train: 0.545270	val: 0.337942	test: 0.209799

Epoch: 38
Loss: 0.10036509724486305
ROC train: 0.926311	val: 0.777349	test: 0.754045
PRC train: 0.600127	val: 0.323132	test: 0.164296

Epoch: 39
Loss: 0.09834021772097262
ROC train: 0.928006	val: 0.776911	test: 0.758027
PRC train: 0.603458	val: 0.345177	test: 0.190489

Epoch: 40
Loss: 0.096977943880486
ROC train: 0.930474	val: 0.785727	test: 0.753195
PRC train: 0.603421	val: 0.345726	test: 0.198131

Epoch: 41
Loss: 0.09677055090743364
ROC train: 0.919643	val: 0.750634	test: 0.762471
PRC train: 0.591060	val: 0.335397	test: 0.213280

Epoch: 42
Loss: 0.09619349388347874
ROC train: 0.934583	val: 0.781308	test: 0.741405
PRC train: 0.629657	val: 0.333516	test: 0.179570

Epoch: 43
Loss: 0.09604729223907851
ROC train: 0.927481	val: 0.762591	test: 0.742927
PRC train: 0.619126	val: 0.325599	test: 0.175542

Epoch: 44
Loss: 0.09540940759772552
ROC train: 0.933999	val: 0.775821	test: 0.756529
PRC train: 0.621223	val: 0.326103	test: 0.163970

Epoch: 45
Loss: 0.09541106490530875
ROC train: 0.929907	val: 0.763359	test: 0.768630
PRC train: 0.616882	val: 0.293109	test: 0.154377

Epoch: 46
Loss: 0.0944257427753145
ROC train: 0.937494	val: 0.773513	test: 0.742336
PRC train: 0.641734	val: 0.312333	test: 0.181431

Epoch: 47
Loss: 0.09494007788678778
ROC train: 0.928803	val: 0.756626	test: 0.759345
PRC train: 0.615626	val: 0.325464	test: 0.175983

Epoch: 48
Loss: 0.09642552983792801
ROC train: 0.938826	val: 0.756053	test: 0.740625
PRC train: 0.631518	val: 0.341398	test: 0.191901

Epoch: 49
Loss: 0.09407960094432503
ROC train: 0.940696	val: 0.767162	test: 0.752268
PRC train: 0.634308	val: 0.347665	test: 0.196900

Epoch: 50
Loss: 0.09253439950396909
ROC train: 0.937361	val: 0.762122	test: 0.749889
PRC train: 0.633937	val: 0.319715	test: 0.193173

Epoch: 51
Loss: 0.0930884662702487
ROC train: 0.934264	val: 0.771715	test: 0.742654
PRC train: 0.625211	val: 0.334202	test: 0.196576

Epoch: 52
Loss: 0.09348468885461665
ROC train: 0.946772	val: 0.768953	test: 0.756859
PRC train: 0.652392	val: 0.337649	test: 0.195854

Epoch: 53
Loss: 0.09261433150559083
ROC train: 0.946349	val: 0.775080	test: 0.758611
PRC train: 0.656147	val: 0.332841	test: 0.188973

Epoch: 54
Loss: 0.09077717164744838
ROC train: 0.940064	val: 0.763240	test: 0.748659
PRC train: 0.650261	val: 0.317618	test: 0.157630

Epoch: 55
Loss: 0.09165784367475412
ROC train: 0.949027	val: 0.773702	test: 0.743172
PRC train: 0.665542	val: 0.314615	test: 0.166226

Epoch: 56
Loss: 0.0891088725578497
ROC train: 0.944971	val: 0.780527	test: 0.727320
PRC train: 0.658784	val: 0.309639	test: 0.173090

Epoch: 57
Loss: 0.09092281705891489
ROC train: 0.947797	val: 0.778730	test: 0.740103
PRC train: 0.657297	val: 0.352591	test: 0.164233

Epoch: 58
Loss: 0.09052423983259163
ROC train: 0.951988	val: 0.770380	test: 0.741658
PRC train: 0.663403	val: 0.325587	test: 0.170431

Epoch: 59
Loss: 0.08976303299300184
ROC train: 0.952291	val: 0.758677	test: 0.742324
PRC train: 0.674839	val: 0.320878	test: 0.170801

Epoch: 60
Loss: 0.08822724333613381
ROC train: 0.950818	val: 0.772429	test: 0.738809
PRC train: 0.670940	val: 0.319968	test: 0.161849

Epoch: 61
Loss: 0.08937845205328526
ROC train: 0.956773	val: 0.775671	test: 0.746532
PRC train: 0.675112	val: 0.336412	test: 0.168353

Epoch: 62
Loss: 0.08830624942362994
ROC train: 0.953748	val: 0.764584	test: 0.739555
PRC train: 0.681570	val: 0.334970	test: 0.160360

Epoch: 63
Loss: 0.08902469772286398
ROC train: 0.952353	val: 0.762597	test: 0.754283
PRC train: 0.672623	val: 0.338620	test: 0.175587

Epoch: 64
Loss: 0.08953524281515657
ROC train: 0.951092	val: 0.778856	test: 0.748257
PRC train: 0.664750	val: 0.328681	test: 0.155728

Epoch: 65
Loss: 0.08666026071390809
ROC train: 0.959417	val: 0.779159	test: 0.759851
PRC train: 0.688281	val: 0.330536	test: 0.185868

Epoch: 66
Loss: 0.08603264190469039
ROC train: 0.957310	val: 0.763280	test: 0.753448
PRC train: 0.683124	val: 0.307701	test: 0.184542

Epoch: 67
Loss: 0.08551295998671939
ROC train: 0.952667	val: 0.761470	test: 0.757091
PRC train: 0.682430	val: 0.305726	test: 0.192103

Epoch: 68
Loss: 0.08584058503509975
ROC train: 0.953818	val: 0.779799	test: 0.739978
PRC train: 0.682837	val: 0.315565	test: 0.171237

Epoch: 69
Loss: 0.08627884792091786
ROC train: 0.961709	val: 0.768433	test: 0.757904
PRC train: 0.701200	val: 0.302029	test: 0.180663

Epoch: 70
Loss: 0.08450286111482873
ROC train: 0.961159	val: 0.783810	test: 0.757073
PRC train: 0.704084	val: 0.294938	test: 0.160102

Epoch: 71
Loss: 0.08533538464961878
ROC train: 0.959724	val: 0.764942	test: 0.763707
PRC train: 0.696009	val: 0.324509	test: 0.207302

Epoch: 72
Loss: 0.08368374312734526
ROC train: 0.959769	val: 0.800219	test: 0.742090
PRC train: 0.692610	val: 0.304646	test: 0.172457

Epoch: 73
Loss: 0.08299633497649093
ROC train: 0.960100	val: 0.741228	test: 0.737129
PRC train: 0.703143	val: 0.289672	test: 0.167420

Epoch: 74
Loss: 0.08404510657124972
ROC train: 0.964670	val: 0.763929	test: 0.750623
PRC train: 0.703771	val: 0.301971	test: 0.203460

Epoch: 75
Loss: 0.08259408143571852
ROC train: 0.964517	val: 0.783595	test: 0.769613
PRC train: 0.703809	val: 0.303377	test: 0.202965

Epoch: 76
Loss: 0.0824266012217664
ROC train: 0.964630	val: 0.763834	test: 0.736609
PRC train: 0.705931	val: 0.306806	test: 0.188255

Epoch: 77
Loss: 0.08284056432307106
ROC train: 0.964612	val: 0.778436	test: 0.753877
PRC train: 0.714474	val: 0.334661	test: 0.193925

Epoch: 78
Loss: 0.08309888072572794
ROC train: 0.966618	val: 0.791621	test: 0.759885
PRC train: 0.725112	val: 0.332489	test: 0.209142

Epoch: 79
Loss: 0.08119350597414665
ROC train: 0.968158	val: 0.780399	test: 0.761788
PRC train: 0.734981	val: 0.307860	test: 0.165142

Epoch: 80
Loss: 0.08144183083544557
ROC train: 0.965906	val: 0.767049	test: 0.745829
PRC train: 0.722298	val: 0.276729	test: 0.176308

Epoch: 81
Loss: 0.07997075738875288
ROC train: 0.969102	val: 0.757290	test: 0.757604
PRC train: 0.740320	val: 0.270513	test: 0.158139

Epoch: 82
Loss: 0.08143949253055331
ROC train: 0.966331	val: 0.800421	test: 0.746359
PRC train: 0.726148	val: 0.299458	test: 0.176023

Epoch: 83
Loss: 0.07953987112341691
ROC train: 0.969145	val: 0.789401	test: 0.756459
PRC train: 0.737421	val: 0.304067	test: 0.197004

Epoch: 84
Loss: 0.08109399348435087
ROC train: 0.968303	val: 0.774737	test: 0.763093
PRC train: 0.730143	val: 0.295901	test: 0.160541

Epoch: 85
Loss: 0.08013478952267139
ROC train: 0.972061	val: 0.779186	test: 0.758022
PRC train: 0.743578	val: 0.297288	test: 0.165736

Epoch: 86
Loss: 0.07903988107197941
ROC train: 0.968681	val: 0.772429	test: 0.765492
PRC train: 0.743029	val: 0.284111	test: 0.178303

Epoch: 87
Loss: 0.07899093126884403
ROC train: 0.975625	val: 0.766051	test: 0.747411
PRC train: 0.756982	val: 0.264999	test: 0.154174

Epoch: 88
Loss: 0.07872688706256688
ROC train: 0.974173	val: 0.768326	test: 0.759012
PRC train: 0.759664	val: 0.297879	test: 0.167032

Epoch: 89
Loss: 0.07649490837537402
ROC train: 0.973747	val: 0.771094	test: 0.740362
PRC train: 0.750978	val: 0.288132	test: 0.153025

Epoch: 90
Loss: 0.07662986403348343
ROC train: 0.973089	val: 0.765689	test: 0.758446
PRC train: 0.752935	val: 0.302248	test: 0.189370

Epoch: 91
Loss: 0.07766678503374648
ROC train: 0.974111	val: 0.781428	test: 0.754568
PRC train: 0.749120	val: 0.316223	test: 0.172684

Epoch: 92
Loss: 0.07729036452494678
ROC train: 0.974495	val: 0.785022	test: 0.757574
PRC train: 0.762793	val: 0.283847	test: 0.159584

Epoch: 93
Loss: 0.07877767538542373
ROC train: 0.975232	val: 0.778559	test: 0.760038
PRC train: 0.766340	val: 0.303646	test: 0.177239

ROC train: 0.913992	val: 0.751457	test: 0.750306
PRC train: 0.568247	val: 0.321174	test: 0.179077

Epoch: 34
Loss: 0.10217126068510984
ROC train: 0.916495	val: 0.789312	test: 0.761355
PRC train: 0.574878	val: 0.356598	test: 0.191826

Epoch: 35
Loss: 0.10177265687185802
ROC train: 0.918717	val: 0.767441	test: 0.764667
PRC train: 0.585297	val: 0.367991	test: 0.180000

Epoch: 36
Loss: 0.10081579527068882
ROC train: 0.915449	val: 0.797053	test: 0.756094
PRC train: 0.579002	val: 0.349682	test: 0.169233

Epoch: 37
Loss: 0.10084810811006525
ROC train: 0.921192	val: 0.786284	test: 0.772199
PRC train: 0.583892	val: 0.331608	test: 0.138728

Epoch: 38
Loss: 0.09919891607331617
ROC train: 0.920227	val: 0.773555	test: 0.766481
PRC train: 0.594055	val: 0.326730	test: 0.150615

Epoch: 39
Loss: 0.09901805970753211
ROC train: 0.924190	val: 0.744164	test: 0.734882
PRC train: 0.592235	val: 0.332210	test: 0.134844

Epoch: 40
Loss: 0.09910754632221495
ROC train: 0.926867	val: 0.785503	test: 0.733268
PRC train: 0.596763	val: 0.333778	test: 0.155872

Epoch: 41
Loss: 0.09836646390729843
ROC train: 0.929162	val: 0.765567	test: 0.756890
PRC train: 0.614517	val: 0.327445	test: 0.174741

Epoch: 42
Loss: 0.09730416884550538
ROC train: 0.924855	val: 0.754712	test: 0.748514
PRC train: 0.600508	val: 0.331976	test: 0.113382

Epoch: 43
Loss: 0.09685130753427827
ROC train: 0.928925	val: 0.768396	test: 0.763080
PRC train: 0.610966	val: 0.335535	test: 0.154066

Epoch: 44
Loss: 0.09610441149677838
ROC train: 0.928822	val: 0.765475	test: 0.755783
PRC train: 0.613220	val: 0.349321	test: 0.165387

Epoch: 45
Loss: 0.09566146425341245
ROC train: 0.929352	val: 0.778102	test: 0.764283
PRC train: 0.605904	val: 0.312539	test: 0.159136

Epoch: 46
Loss: 0.09455108830367022
ROC train: 0.928882	val: 0.773791	test: 0.743276
PRC train: 0.618140	val: 0.315383	test: 0.143072

Epoch: 47
Loss: 0.09561640657225799
ROC train: 0.930429	val: 0.762431	test: 0.762699
PRC train: 0.611538	val: 0.291598	test: 0.161212

Epoch: 48
Loss: 0.09421901606151131
ROC train: 0.936332	val: 0.751653	test: 0.760787
PRC train: 0.630591	val: 0.304119	test: 0.159593

Epoch: 49
Loss: 0.09324093689266963
ROC train: 0.937210	val: 0.782365	test: 0.761932
PRC train: 0.622201	val: 0.319313	test: 0.152507

Epoch: 50
Loss: 0.09348170831867773
ROC train: 0.939280	val: 0.789860	test: 0.770870
PRC train: 0.632646	val: 0.378086	test: 0.206986

Epoch: 51
Loss: 0.09300081929282618
ROC train: 0.943077	val: 0.779814	test: 0.750389
PRC train: 0.644208	val: 0.311666	test: 0.152290

Epoch: 52
Loss: 0.09304616370347397
ROC train: 0.943376	val: 0.790016	test: 0.759196
PRC train: 0.654095	val: 0.342507	test: 0.167025

Epoch: 53
Loss: 0.09293762173971937
ROC train: 0.940824	val: 0.756274	test: 0.755333
PRC train: 0.621476	val: 0.290712	test: 0.131711

Epoch: 54
Loss: 0.09174470352453995
ROC train: 0.944779	val: 0.787392	test: 0.753321
PRC train: 0.646054	val: 0.332266	test: 0.135350

Epoch: 55
Loss: 0.09200543063016789
ROC train: 0.934009	val: 0.780313	test: 0.773502
PRC train: 0.602969	val: 0.280130	test: 0.187010

Epoch: 56
Loss: 0.09048022498487653
ROC train: 0.947062	val: 0.779244	test: 0.774242
PRC train: 0.651962	val: 0.314568	test: 0.155350

Epoch: 57
Loss: 0.0907334888682559
ROC train: 0.944468	val: 0.783773	test: 0.788013
PRC train: 0.644939	val: 0.328941	test: 0.182579

Epoch: 58
Loss: 0.09119235005962543
ROC train: 0.952249	val: 0.794239	test: 0.769787
PRC train: 0.670167	val: 0.311319	test: 0.158976

Epoch: 59
Loss: 0.09000539835695198
ROC train: 0.946621	val: 0.788611	test: 0.751594
PRC train: 0.648393	val: 0.315636	test: 0.194162

Epoch: 60
Loss: 0.08898403441337367
ROC train: 0.954791	val: 0.786311	test: 0.777159
PRC train: 0.674959	val: 0.333603	test: 0.180375

Epoch: 61
Loss: 0.08826303244913941
ROC train: 0.955383	val: 0.771712	test: 0.749765
PRC train: 0.678591	val: 0.298573	test: 0.172777

Epoch: 62
Loss: 0.08814397327898564
ROC train: 0.957200	val: 0.787251	test: 0.777394
PRC train: 0.685254	val: 0.291713	test: 0.160092

Epoch: 63
Loss: 0.08860853969696997
ROC train: 0.958528	val: 0.781109	test: 0.760005
PRC train: 0.688571	val: 0.322169	test: 0.202326

Epoch: 64
Loss: 0.08883912516881946
ROC train: 0.957701	val: 0.765842	test: 0.756291
PRC train: 0.690632	val: 0.329180	test: 0.170334

Epoch: 65
Loss: 0.08663791760662051
ROC train: 0.956856	val: 0.774609	test: 0.772976
PRC train: 0.673050	val: 0.298617	test: 0.203367

Epoch: 66
Loss: 0.08578618482516948
ROC train: 0.961516	val: 0.787570	test: 0.766579
PRC train: 0.697972	val: 0.308153	test: 0.178869

Epoch: 67
Loss: 0.08594491471818759
ROC train: 0.960816	val: 0.782916	test: 0.770932
PRC train: 0.696829	val: 0.324938	test: 0.175650

Epoch: 68
Loss: 0.08702230342960156
ROC train: 0.959823	val: 0.783761	test: 0.767811
PRC train: 0.701004	val: 0.307562	test: 0.196201

Epoch: 69
Loss: 0.08566832293582939
ROC train: 0.960660	val: 0.785154	test: 0.767410
PRC train: 0.695805	val: 0.320188	test: 0.191786

Epoch: 70
Loss: 0.08493004030082113
ROC train: 0.962114	val: 0.779101	test: 0.757149
PRC train: 0.692350	val: 0.308766	test: 0.140975

Epoch: 71
Loss: 0.0840306717210787
ROC train: 0.962293	val: 0.773424	test: 0.743340
PRC train: 0.707507	val: 0.309169	test: 0.160698

Epoch: 72
Loss: 0.08452986667666981
ROC train: 0.963684	val: 0.790632	test: 0.772489
PRC train: 0.710813	val: 0.303837	test: 0.188014

Epoch: 73
Loss: 0.08293160086477996
ROC train: 0.963976	val: 0.791112	test: 0.770160
PRC train: 0.705076	val: 0.313314	test: 0.173782

Epoch: 74
Loss: 0.08237579324321676
ROC train: 0.967194	val: 0.773828	test: 0.754920
PRC train: 0.710859	val: 0.300027	test: 0.173848

Epoch: 75
Loss: 0.08417758462489555
ROC train: 0.966046	val: 0.777909	test: 0.765364
PRC train: 0.717989	val: 0.310703	test: 0.153692

Epoch: 76
Loss: 0.08255841921895549
ROC train: 0.966702	val: 0.788093	test: 0.754675
PRC train: 0.715799	val: 0.316884	test: 0.200488

Epoch: 77
Loss: 0.08343831287230961
ROC train: 0.967003	val: 0.761173	test: 0.768317
PRC train: 0.720819	val: 0.318010	test: 0.189999

Epoch: 78
Loss: 0.08342093810303687
ROC train: 0.965129	val: 0.771051	test: 0.745702
PRC train: 0.707241	val: 0.311277	test: 0.151923

Epoch: 79
Loss: 0.08399297771606105
ROC train: 0.969274	val: 0.788476	test: 0.745800
PRC train: 0.727279	val: 0.336370	test: 0.158501

Epoch: 80
Loss: 0.08059189908116043
ROC train: 0.968571	val: 0.771795	test: 0.755604
PRC train: 0.721617	val: 0.303892	test: 0.200739

Epoch: 81
Loss: 0.08016574792063545
ROC train: 0.969942	val: 0.793786	test: 0.756749
PRC train: 0.731723	val: 0.336667	test: 0.184990

Epoch: 82
Loss: 0.08045962449032083
ROC train: 0.965626	val: 0.770392	test: 0.734083
PRC train: 0.715955	val: 0.287561	test: 0.116482

Epoch: 83
Loss: 0.07947213183184046
ROC train: 0.970223	val: 0.755943	test: 0.758504
PRC train: 0.734464	val: 0.292859	test: 0.196394

Epoch: 84
Loss: 0.07894060931064847
ROC train: 0.970667	val: 0.771305	test: 0.758601
PRC train: 0.742664	val: 0.322419	test: 0.176733

Epoch: 85
Loss: 0.07790978862488332
ROC train: 0.969278	val: 0.753040	test: 0.747160
PRC train: 0.715900	val: 0.286240	test: 0.137092

Epoch: 86
Loss: 0.08093373274737257
ROC train: 0.968845	val: 0.762637	test: 0.747456
PRC train: 0.729490	val: 0.288211	test: 0.155278

Epoch: 87
Loss: 0.07879222095987672
ROC train: 0.971681	val: 0.784689	test: 0.759661
PRC train: 0.739966	val: 0.298770	test: 0.151738

Epoch: 88
Loss: 0.07807631724626335
ROC train: 0.973455	val: 0.780898	test: 0.767782
PRC train: 0.745230	val: 0.303322	test: 0.153324

Epoch: 89
Loss: 0.07903001092973826
ROC train: 0.974463	val: 0.777597	test: 0.774982
PRC train: 0.749182	val: 0.304890	test: 0.141141

Epoch: 90
Loss: 0.07788147571510637
ROC train: 0.973166	val: 0.783761	test: 0.766510
PRC train: 0.756487	val: 0.319744	test: 0.174441

Epoch: 91
Loss: 0.07715068427804701
ROC train: 0.970372	val: 0.770809	test: 0.754485
PRC train: 0.746396	val: 0.305061	test: 0.170276

Epoch: 92
Loss: 0.07663493241580145
ROC train: 0.976057	val: 0.782622	test: 0.763943
PRC train: 0.766968	val: 0.298924	test: 0.159736

Epoch: 93
Loss: 0.07742584415432965
ROC train: 0.974470	val: 0.767655	test: 0.754487
PRC train: 0.760823	val: 0.298972	test: 0.162778
PRC train: 0.635058	val: 0.344925	test: 0.153163

Epoch: 33
Loss: 0.09555936005776842
ROC train: 0.935816	val: 0.780114	test: 0.689693
PRC train: 0.600402	val: 0.385848	test: 0.215226

Epoch: 34
Loss: 0.09560591983278412
ROC train: 0.948307	val: 0.769223	test: 0.683010
PRC train: 0.681964	val: 0.331885	test: 0.157719

Epoch: 35
Loss: 0.09425371215683576
ROC train: 0.943735	val: 0.783332	test: 0.699828
PRC train: 0.669651	val: 0.348664	test: 0.169705

Epoch: 36
Loss: 0.0936016966766894
ROC train: 0.939348	val: 0.765206	test: 0.695433
PRC train: 0.649351	val: 0.306940	test: 0.128620

Epoch: 37
Loss: 0.09570517616665128
ROC train: 0.950669	val: 0.785874	test: 0.698356
PRC train: 0.689236	val: 0.376345	test: 0.184053

Epoch: 38
Loss: 0.0920451974964386
ROC train: 0.944948	val: 0.783755	test: 0.687725
PRC train: 0.681492	val: 0.329047	test: 0.148779

Epoch: 39
Loss: 0.08929246239376577
ROC train: 0.959037	val: 0.786651	test: 0.713104
PRC train: 0.719836	val: 0.350801	test: 0.215064

Epoch: 40
Loss: 0.09003070726972094
ROC train: 0.961797	val: 0.787380	test: 0.710498
PRC train: 0.751249	val: 0.338824	test: 0.174616

Epoch: 41
Loss: 0.08772224490403438
ROC train: 0.959279	val: 0.788577	test: 0.681133
PRC train: 0.730155	val: 0.346760	test: 0.166244

Epoch: 42
Loss: 0.08499658391442348
ROC train: 0.959973	val: 0.796808	test: 0.702109
PRC train: 0.735478	val: 0.315821	test: 0.156134

Epoch: 43
Loss: 0.08435197333553734
ROC train: 0.961064	val: 0.801875	test: 0.709691
PRC train: 0.740074	val: 0.341006	test: 0.143179

Epoch: 44
Loss: 0.08387120146279564
ROC train: 0.964825	val: 0.788657	test: 0.700267
PRC train: 0.730552	val: 0.334493	test: 0.184400

Epoch: 45
Loss: 0.0843094748515495
ROC train: 0.968276	val: 0.797625	test: 0.712368
PRC train: 0.772078	val: 0.332377	test: 0.159856

Epoch: 46
Loss: 0.08172108884525604
ROC train: 0.971579	val: 0.794906	test: 0.718214
PRC train: 0.771151	val: 0.277368	test: 0.147748

Epoch: 47
Loss: 0.07996404936925271
ROC train: 0.976210	val: 0.777034	test: 0.717107
PRC train: 0.813951	val: 0.339193	test: 0.201665

Epoch: 48
Loss: 0.0787033327179268
ROC train: 0.974254	val: 0.797757	test: 0.716682
PRC train: 0.789482	val: 0.318753	test: 0.179937

Epoch: 49
Loss: 0.07795157649739151
ROC train: 0.973319	val: 0.782959	test: 0.688683
PRC train: 0.785428	val: 0.277302	test: 0.124212

Epoch: 50
Loss: 0.07663343746770682
ROC train: 0.972839	val: 0.799171	test: 0.702038
PRC train: 0.778037	val: 0.348609	test: 0.161540

Epoch: 51
Loss: 0.07615384945421454
ROC train: 0.978286	val: 0.802509	test: 0.711416
PRC train: 0.820146	val: 0.324129	test: 0.179320

Epoch: 52
Loss: 0.0738580207122063
ROC train: 0.978401	val: 0.786933	test: 0.709212
PRC train: 0.819656	val: 0.332807	test: 0.176109

Epoch: 53
Loss: 0.07416988573227348
ROC train: 0.977522	val: 0.788100	test: 0.688379
PRC train: 0.824228	val: 0.326804	test: 0.151887

Epoch: 54
Loss: 0.07320534066737697
ROC train: 0.981035	val: 0.791146	test: 0.704092
PRC train: 0.836850	val: 0.344147	test: 0.166537

Epoch: 55
Loss: 0.07223061233309676
ROC train: 0.982124	val: 0.777196	test: 0.695195
PRC train: 0.849739	val: 0.338475	test: 0.143656

Epoch: 56
Loss: 0.07020644470147169
ROC train: 0.983284	val: 0.797111	test: 0.704401
PRC train: 0.855808	val: 0.320544	test: 0.156353

Epoch: 57
Loss: 0.07020059855510766
ROC train: 0.983275	val: 0.791768	test: 0.710522
PRC train: 0.855321	val: 0.307568	test: 0.205419

Epoch: 58
Loss: 0.06907191435301886
ROC train: 0.979469	val: 0.773136	test: 0.701253
PRC train: 0.827395	val: 0.320604	test: 0.196634

Epoch: 59
Loss: 0.06845150608183814
ROC train: 0.984945	val: 0.775331	test: 0.698285
PRC train: 0.861237	val: 0.319810	test: 0.153476

Epoch: 60
Loss: 0.06611909962664374
ROC train: 0.984353	val: 0.777931	test: 0.709129
PRC train: 0.851226	val: 0.325263	test: 0.188231

Epoch: 61
Loss: 0.06672770834701684
ROC train: 0.986050	val: 0.781930	test: 0.699386
PRC train: 0.864283	val: 0.358101	test: 0.154598

Epoch: 62
Loss: 0.0691404131898773
ROC train: 0.985709	val: 0.807224	test: 0.716370
PRC train: 0.857905	val: 0.332438	test: 0.153184

Epoch: 63
Loss: 0.06652818473154054
ROC train: 0.988005	val: 0.800020	test: 0.705769
PRC train: 0.884829	val: 0.290028	test: 0.154580

Epoch: 64
Loss: 0.0633119614475407
ROC train: 0.986077	val: 0.783249	test: 0.710549
PRC train: 0.859021	val: 0.280618	test: 0.131357

Epoch: 65
Loss: 0.0639839394739196
ROC train: 0.991935	val: 0.791416	test: 0.708579
PRC train: 0.905135	val: 0.368114	test: 0.188863

Epoch: 66
Loss: 0.06094914057972837
ROC train: 0.991343	val: 0.799839	test: 0.716806
PRC train: 0.907065	val: 0.347649	test: 0.164276

Epoch: 67
Loss: 0.06273326507286132
ROC train: 0.987860	val: 0.794805	test: 0.717864
PRC train: 0.866478	val: 0.355346	test: 0.171597

Epoch: 68
Loss: 0.059922410160403124
ROC train: 0.988189	val: 0.782763	test: 0.699479
PRC train: 0.884321	val: 0.349337	test: 0.192479

Epoch: 69
Loss: 0.05969207987256203
ROC train: 0.993835	val: 0.793531	test: 0.715707
PRC train: 0.928625	val: 0.341258	test: 0.196894

Epoch: 70
Loss: 0.05734765236381665
ROC train: 0.992529	val: 0.787720	test: 0.713668
PRC train: 0.912413	val: 0.338973	test: 0.139520

Epoch: 71
Loss: 0.05876719454289727
ROC train: 0.990789	val: 0.802610	test: 0.717555
PRC train: 0.898373	val: 0.362059	test: 0.162533

Epoch: 72
Loss: 0.057600673112088836
ROC train: 0.990269	val: 0.779756	test: 0.711333
PRC train: 0.891726	val: 0.331969	test: 0.184065

Epoch: 73
Loss: 0.05784330932269878
ROC train: 0.994118	val: 0.792236	test: 0.702632
PRC train: 0.931866	val: 0.357785	test: 0.142431

Epoch: 74
Loss: 0.05488245471349344
ROC train: 0.995151	val: 0.790212	test: 0.692758
PRC train: 0.938081	val: 0.347129	test: 0.156663

Epoch: 75
Loss: 0.05625584772785247
ROC train: 0.994883	val: 0.794637	test: 0.711924
PRC train: 0.936101	val: 0.345138	test: 0.157668

Epoch: 76
Loss: 0.056798948261605677
ROC train: 0.994275	val: 0.793100	test: 0.709203
PRC train: 0.931686	val: 0.356616	test: 0.159792

Epoch: 77
Loss: 0.05369504107838242
ROC train: 0.994916	val: 0.801422	test: 0.717795
PRC train: 0.941940	val: 0.316364	test: 0.156182

Epoch: 78
Loss: 0.05477477880376086
ROC train: 0.995633	val: 0.796532	test: 0.709249
PRC train: 0.942222	val: 0.321867	test: 0.122465

Epoch: 79
Loss: 0.0516994453627046
ROC train: 0.995578	val: 0.797524	test: 0.698329
PRC train: 0.945005	val: 0.305276	test: 0.117300

Epoch: 80
Loss: 0.05134600558375516
ROC train: 0.995911	val: 0.774489	test: 0.706057
PRC train: 0.946939	val: 0.322174	test: 0.154172

Epoch: 81
Loss: 0.0512820039272023
ROC train: 0.994966	val: 0.772484	test: 0.697879
PRC train: 0.938393	val: 0.316475	test: 0.175551

Epoch: 82
Loss: 0.05057533217065222
ROC train: 0.996122	val: 0.791247	test: 0.695033
PRC train: 0.949693	val: 0.273889	test: 0.112969

Epoch: 83
Loss: 0.048412190192433355
ROC train: 0.996953	val: 0.792705	test: 0.711206
PRC train: 0.960275	val: 0.325773	test: 0.141930

Epoch: 84
Loss: 0.049322256794609526
ROC train: 0.995100	val: 0.774857	test: 0.719641
PRC train: 0.936645	val: 0.333000	test: 0.208002

Epoch: 85
Loss: 0.05362408427739342
ROC train: 0.995134	val: 0.781887	test: 0.713268
PRC train: 0.935781	val: 0.332931	test: 0.169909

Epoch: 86
Loss: 0.046974746020479546
ROC train: 0.996896	val: 0.786933	test: 0.713308
PRC train: 0.953887	val: 0.290449	test: 0.127415

Epoch: 87
Loss: 0.04833943774453821
ROC train: 0.996900	val: 0.790910	test: 0.710624
PRC train: 0.958809	val: 0.290802	test: 0.139501

Epoch: 88
Loss: 0.044755957796308095
ROC train: 0.997127	val: 0.782215	test: 0.722461
PRC train: 0.961891	val: 0.332334	test: 0.144264

Epoch: 89
Loss: 0.04790023895242947
ROC train: 0.996938	val: 0.803755	test: 0.712209
PRC train: 0.958098	val: 0.336398	test: 0.149442

Epoch: 90
Loss: 0.04472048574526751
ROC train: 0.997580	val: 0.787362	test: 0.705854
PRC train: 0.971599	val: 0.326990	test: 0.159843

Epoch: 91
Loss: 0.04614606350237661
ROC train: 0.998064	val: 0.812298	test: 0.725145
PRC train: 0.971309	val: 0.341723	test: 0.153156

Epoch: 92
Loss: 0.04277173869053732
ROC train: 0.998344	val: 0.790228	test: 0.703861
PRC train: 0.974651	val: 0.318252	test: 0.155577

Epoch: 93
Loss: 0.0442768287328634
ROC train: 0.997690	val: 0.790319	test: 0.693142
PRC train: 0.617814	val: 0.395079	test: 0.196457

Epoch: 33
Loss: 0.09927162305307816
ROC train: 0.925882	val: 0.799110	test: 0.763947
PRC train: 0.617307	val: 0.395532	test: 0.216681

Epoch: 34
Loss: 0.09760281425490838
ROC train: 0.935559	val: 0.786712	test: 0.740918
PRC train: 0.634043	val: 0.343711	test: 0.196958

Epoch: 35
Loss: 0.09690984490226266
ROC train: 0.935048	val: 0.811673	test: 0.770652
PRC train: 0.645504	val: 0.390483	test: 0.209307

Epoch: 36
Loss: 0.09679364463840678
ROC train: 0.937115	val: 0.818250	test: 0.762117
PRC train: 0.670589	val: 0.368665	test: 0.147474

Epoch: 37
Loss: 0.0942665081964567
ROC train: 0.946328	val: 0.805898	test: 0.761081
PRC train: 0.676683	val: 0.401061	test: 0.179716

Epoch: 38
Loss: 0.09338023289171796
ROC train: 0.945257	val: 0.810142	test: 0.753452
PRC train: 0.672651	val: 0.387916	test: 0.196716

Epoch: 39
Loss: 0.09190895397994402
ROC train: 0.943179	val: 0.805118	test: 0.761415
PRC train: 0.682206	val: 0.401173	test: 0.181734

Epoch: 40
Loss: 0.09332276277501145
ROC train: 0.948317	val: 0.807420	test: 0.761589
PRC train: 0.691290	val: 0.378246	test: 0.179509

Epoch: 41
Loss: 0.09145244547015291
ROC train: 0.929651	val: 0.766182	test: 0.739412
PRC train: 0.627944	val: 0.307386	test: 0.198701

Epoch: 42
Loss: 0.09049650185680731
ROC train: 0.949527	val: 0.808014	test: 0.759955
PRC train: 0.696101	val: 0.349793	test: 0.183801

Epoch: 43
Loss: 0.08859423740256742
ROC train: 0.943200	val: 0.787708	test: 0.750420
PRC train: 0.666825	val: 0.369476	test: 0.163572

Epoch: 44
Loss: 0.08731485482292069
ROC train: 0.958814	val: 0.808697	test: 0.746882
PRC train: 0.727088	val: 0.355934	test: 0.183307

Epoch: 45
Loss: 0.08975163684606174
ROC train: 0.960173	val: 0.822886	test: 0.737565
PRC train: 0.740439	val: 0.367823	test: 0.155171

Epoch: 46
Loss: 0.087144184783891
ROC train: 0.959091	val: 0.809864	test: 0.753081
PRC train: 0.711259	val: 0.358905	test: 0.158103

Epoch: 47
Loss: 0.08593918296418324
ROC train: 0.961043	val: 0.812218	test: 0.772085
PRC train: 0.711775	val: 0.396948	test: 0.221909

Epoch: 48
Loss: 0.08561698409979258
ROC train: 0.962573	val: 0.808418	test: 0.747081
PRC train: 0.734155	val: 0.391482	test: 0.163371

Epoch: 49
Loss: 0.08332642270195612
ROC train: 0.965490	val: 0.797184	test: 0.750295
PRC train: 0.747586	val: 0.332919	test: 0.145684

Epoch: 50
Loss: 0.08314279090947199
ROC train: 0.964096	val: 0.813682	test: 0.754341
PRC train: 0.748390	val: 0.403099	test: 0.198956

Epoch: 51
Loss: 0.08334123621355155
ROC train: 0.969609	val: 0.811591	test: 0.754729
PRC train: 0.764229	val: 0.390707	test: 0.196529

Epoch: 52
Loss: 0.08042373378933519
ROC train: 0.963022	val: 0.809487	test: 0.758779
PRC train: 0.729203	val: 0.394705	test: 0.193146

Epoch: 53
Loss: 0.08066548308957966
ROC train: 0.969715	val: 0.814653	test: 0.754941
PRC train: 0.765858	val: 0.404099	test: 0.189820

Epoch: 54
Loss: 0.07867346882395562
ROC train: 0.969285	val: 0.799514	test: 0.760739
PRC train: 0.772497	val: 0.383506	test: 0.161904

Epoch: 55
Loss: 0.07881809733034868
ROC train: 0.973107	val: 0.803871	test: 0.766946
PRC train: 0.784197	val: 0.357957	test: 0.176934

Epoch: 56
Loss: 0.07899171871556752
ROC train: 0.976527	val: 0.826450	test: 0.759399
PRC train: 0.800738	val: 0.398706	test: 0.174560

Epoch: 57
Loss: 0.07957261994749558
ROC train: 0.971163	val: 0.808186	test: 0.754441
PRC train: 0.776327	val: 0.377946	test: 0.184516

Epoch: 58
Loss: 0.07785422893944792
ROC train: 0.975594	val: 0.817436	test: 0.756477
PRC train: 0.801441	val: 0.395218	test: 0.185943

Epoch: 59
Loss: 0.07563444424031966
ROC train: 0.980710	val: 0.811039	test: 0.738382
PRC train: 0.819754	val: 0.399530	test: 0.180489

Epoch: 60
Loss: 0.0751011449793371
ROC train: 0.978320	val: 0.815433	test: 0.742156
PRC train: 0.801873	val: 0.352675	test: 0.135912

Epoch: 61
Loss: 0.0750545780992849
ROC train: 0.978434	val: 0.816857	test: 0.753247
PRC train: 0.824290	val: 0.375566	test: 0.177912

Epoch: 62
Loss: 0.0744634448720181
ROC train: 0.980444	val: 0.803241	test: 0.742612
PRC train: 0.819464	val: 0.355814	test: 0.173079

Epoch: 63
Loss: 0.0717614795032726
ROC train: 0.983086	val: 0.813024	test: 0.742370
PRC train: 0.833770	val: 0.377928	test: 0.154464

Epoch: 64
Loss: 0.07249548528887996
ROC train: 0.984936	val: 0.809876	test: 0.757782
PRC train: 0.847804	val: 0.376167	test: 0.181852

Epoch: 65
Loss: 0.06900875809147727
ROC train: 0.981878	val: 0.811260	test: 0.750619
PRC train: 0.815317	val: 0.411293	test: 0.183853

Epoch: 66
Loss: 0.06993530256380069
ROC train: 0.985740	val: 0.821177	test: 0.766508
PRC train: 0.854760	val: 0.421576	test: 0.192180

Epoch: 67
Loss: 0.06885506637696565
ROC train: 0.975229	val: 0.807233	test: 0.749586
PRC train: 0.793633	val: 0.366220	test: 0.149466

Epoch: 68
Loss: 0.06999639489573531
ROC train: 0.984766	val: 0.809634	test: 0.764151
PRC train: 0.841853	val: 0.385583	test: 0.180296

Epoch: 69
Loss: 0.06675104237278748
ROC train: 0.980464	val: 0.803875	test: 0.755206
PRC train: 0.831370	val: 0.333555	test: 0.149535

Epoch: 70
Loss: 0.06765694132222748
ROC train: 0.983375	val: 0.808474	test: 0.775063
PRC train: 0.843089	val: 0.387177	test: 0.179639

Epoch: 71
Loss: 0.06638292235132884
ROC train: 0.985217	val: 0.809986	test: 0.752867
PRC train: 0.855328	val: 0.371010	test: 0.177204

Epoch: 72
Loss: 0.06542725591660088
ROC train: 0.986412	val: 0.805947	test: 0.758373
PRC train: 0.868119	val: 0.351316	test: 0.196798

Epoch: 73
Loss: 0.06516536311120931
ROC train: 0.989005	val: 0.804202	test: 0.752871
PRC train: 0.878602	val: 0.363996	test: 0.171908

Epoch: 74
Loss: 0.06450106324087866
ROC train: 0.989848	val: 0.807451	test: 0.744354
PRC train: 0.886633	val: 0.364297	test: 0.147987

Epoch: 75
Loss: 0.06520163792120398
ROC train: 0.988360	val: 0.821177	test: 0.770142
PRC train: 0.880481	val: 0.398980	test: 0.178752

Epoch: 76
Loss: 0.06409703276890757
ROC train: 0.987047	val: 0.810240	test: 0.756706
PRC train: 0.867465	val: 0.392417	test: 0.175223

Epoch: 77
Loss: 0.06211830646132147
ROC train: 0.990598	val: 0.823143	test: 0.770305
PRC train: 0.890096	val: 0.372109	test: 0.176373

Epoch: 78
Loss: 0.06246706274157554
ROC train: 0.990843	val: 0.823896	test: 0.749547
PRC train: 0.885747	val: 0.357325	test: 0.162159

Epoch: 79
Loss: 0.060886025780520166
ROC train: 0.990368	val: 0.824200	test: 0.758551
PRC train: 0.888922	val: 0.388945	test: 0.156243

Epoch: 80
Loss: 0.05950538531891788
ROC train: 0.990944	val: 0.806790	test: 0.762848
PRC train: 0.884183	val: 0.350142	test: 0.166754

Epoch: 81
Loss: 0.05994490919954526
ROC train: 0.990296	val: 0.815308	test: 0.790823
PRC train: 0.891152	val: 0.378925	test: 0.193964

Epoch: 82
Loss: 0.06018572384284771
ROC train: 0.990026	val: 0.816119	test: 0.761330
PRC train: 0.892447	val: 0.389395	test: 0.173752

Epoch: 83
Loss: 0.059046748399439714
ROC train: 0.992039	val: 0.819463	test: 0.742851
PRC train: 0.903012	val: 0.402406	test: 0.190325

Epoch: 84
Loss: 0.05908451383002831
ROC train: 0.991184	val: 0.802757	test: 0.759576
PRC train: 0.896002	val: 0.319708	test: 0.173718

Epoch: 85
Loss: 0.0571337725786897
ROC train: 0.989846	val: 0.834730	test: 0.759740
PRC train: 0.887859	val: 0.394345	test: 0.177490

Epoch: 86
Loss: 0.05743078127366671
ROC train: 0.994767	val: 0.832066	test: 0.768690
PRC train: 0.934576	val: 0.352296	test: 0.172778

Epoch: 87
Loss: 0.05594090967883148
ROC train: 0.992732	val: 0.833373	test: 0.745455
PRC train: 0.914883	val: 0.365101	test: 0.129405

Epoch: 88
Loss: 0.057042407023283795
ROC train: 0.991840	val: 0.818713	test: 0.760051
PRC train: 0.903004	val: 0.382639	test: 0.167831

Epoch: 89
Loss: 0.054615778920164386
ROC train: 0.991879	val: 0.829236	test: 0.766150
PRC train: 0.910634	val: 0.400272	test: 0.185725

Epoch: 90
Loss: 0.055746959911568826
ROC train: 0.994522	val: 0.813593	test: 0.756815
PRC train: 0.928195	val: 0.393881	test: 0.173558

Epoch: 91
Loss: 0.05594162111170975
ROC train: 0.993818	val: 0.816086	test: 0.754972
PRC train: 0.921262	val: 0.373533	test: 0.144845

Epoch: 92
Loss: 0.05390510174660397
ROC train: 0.991541	val: 0.818605	test: 0.765727
PRC train: 0.905962	val: 0.377949	test: 0.140196

Epoch: 93
Loss: 0.05281759235969472
ROC train: 0.995854	val: 0.812013	test: 0.764928
ROC train: 0.915954	val: 0.787245	test: 0.760405
PRC train: 0.575718	val: 0.302113	test: 0.148023

Epoch: 34
Loss: 0.1015293621886682
ROC train: 0.912246	val: 0.793813	test: 0.726399
PRC train: 0.542222	val: 0.308075	test: 0.142447

Epoch: 35
Loss: 0.10045781042985072
ROC train: 0.916383	val: 0.772857	test: 0.729970
PRC train: 0.588152	val: 0.343859	test: 0.166549

Epoch: 36
Loss: 0.09930676983866979
ROC train: 0.919817	val: 0.793538	test: 0.764244
PRC train: 0.582766	val: 0.358607	test: 0.196886

Epoch: 37
Loss: 0.09939887944977735
ROC train: 0.922537	val: 0.788124	test: 0.748448
PRC train: 0.591311	val: 0.351220	test: 0.212270

Epoch: 38
Loss: 0.09824544590156273
ROC train: 0.923659	val: 0.777086	test: 0.752933
PRC train: 0.593102	val: 0.321455	test: 0.188590

Epoch: 39
Loss: 0.09776710449257296
ROC train: 0.926875	val: 0.809037	test: 0.763951
PRC train: 0.594920	val: 0.347126	test: 0.194321

Epoch: 40
Loss: 0.09659944765958241
ROC train: 0.929008	val: 0.769468	test: 0.769005
PRC train: 0.604587	val: 0.356007	test: 0.205239

Epoch: 41
Loss: 0.09787316161516484
ROC train: 0.931971	val: 0.812298	test: 0.746625
PRC train: 0.615324	val: 0.348166	test: 0.176300

Epoch: 42
Loss: 0.09605387740102841
ROC train: 0.932573	val: 0.807971	test: 0.764451
PRC train: 0.599954	val: 0.349188	test: 0.191262

Epoch: 43
Loss: 0.09625370295126319
ROC train: 0.925129	val: 0.799272	test: 0.745501
PRC train: 0.606731	val: 0.362318	test: 0.197641

Epoch: 44
Loss: 0.0972751043745745
ROC train: 0.937158	val: 0.800953	test: 0.756708
PRC train: 0.614948	val: 0.317384	test: 0.204533

Epoch: 45
Loss: 0.09548793142467916
ROC train: 0.937127	val: 0.786722	test: 0.756162
PRC train: 0.628028	val: 0.345469	test: 0.184048

Epoch: 46
Loss: 0.0960522665873565
ROC train: 0.935221	val: 0.784811	test: 0.753970
PRC train: 0.590786	val: 0.334152	test: 0.214263

Epoch: 47
Loss: 0.09461222474544718
ROC train: 0.932666	val: 0.784682	test: 0.747498
PRC train: 0.615095	val: 0.362311	test: 0.164942

Epoch: 48
Loss: 0.0940647933964394
ROC train: 0.936146	val: 0.794848	test: 0.756795
PRC train: 0.619350	val: 0.320959	test: 0.196869

Epoch: 49
Loss: 0.09131813778166087
ROC train: 0.942615	val: 0.783246	test: 0.748935
PRC train: 0.639867	val: 0.318571	test: 0.129397

Epoch: 50
Loss: 0.0930849782610036
ROC train: 0.944329	val: 0.807769	test: 0.759980
PRC train: 0.645312	val: 0.340652	test: 0.167973

Epoch: 51
Loss: 0.09387302916309129
ROC train: 0.944355	val: 0.796930	test: 0.770689
PRC train: 0.647515	val: 0.362053	test: 0.238134

Epoch: 52
Loss: 0.09323202716070994
ROC train: 0.942291	val: 0.792594	test: 0.770063
PRC train: 0.634067	val: 0.338094	test: 0.199717

Epoch: 53
Loss: 0.09212253504896202
ROC train: 0.940609	val: 0.775497	test: 0.765783
PRC train: 0.637014	val: 0.298227	test: 0.160558

Epoch: 54
Loss: 0.09212434246991758
ROC train: 0.947672	val: 0.800099	test: 0.752767
PRC train: 0.655980	val: 0.371226	test: 0.205857

Epoch: 55
Loss: 0.09011731470212853
ROC train: 0.947618	val: 0.784303	test: 0.738848
PRC train: 0.662089	val: 0.306762	test: 0.161206

Epoch: 56
Loss: 0.09019140899194149
ROC train: 0.946291	val: 0.807855	test: 0.756998
PRC train: 0.653128	val: 0.346852	test: 0.176356

Epoch: 57
Loss: 0.08984829829898536
ROC train: 0.946586	val: 0.776427	test: 0.740379
PRC train: 0.656608	val: 0.301991	test: 0.157422

Epoch: 58
Loss: 0.09179877800407227
ROC train: 0.950265	val: 0.803498	test: 0.753313
PRC train: 0.662654	val: 0.355373	test: 0.211139

Epoch: 59
Loss: 0.08800951333090394
ROC train: 0.944543	val: 0.782150	test: 0.751583
PRC train: 0.643725	val: 0.321649	test: 0.165294

Epoch: 60
Loss: 0.08780045744561082
ROC train: 0.949851	val: 0.788948	test: 0.741024
PRC train: 0.663858	val: 0.324175	test: 0.143489

Epoch: 61
Loss: 0.08809014714292934
ROC train: 0.950290	val: 0.797552	test: 0.739775
PRC train: 0.658665	val: 0.342351	test: 0.167197

Epoch: 62
Loss: 0.08886560808532398
ROC train: 0.953757	val: 0.811885	test: 0.771585
PRC train: 0.660767	val: 0.329987	test: 0.193034

Epoch: 63
Loss: 0.0875611789341148
ROC train: 0.946610	val: 0.801511	test: 0.746017
PRC train: 0.644418	val: 0.361010	test: 0.207354

Epoch: 64
Loss: 0.08821781608106975
ROC train: 0.956817	val: 0.808823	test: 0.748504
PRC train: 0.679632	val: 0.316260	test: 0.178719

Epoch: 65
Loss: 0.0860883085956028
ROC train: 0.957273	val: 0.803210	test: 0.740563
PRC train: 0.686208	val: 0.330961	test: 0.184344

Epoch: 66
Loss: 0.08578659812466238
ROC train: 0.960993	val: 0.793103	test: 0.751110
PRC train: 0.687462	val: 0.341501	test: 0.202279

Epoch: 67
Loss: 0.08550278759661066
ROC train: 0.957889	val: 0.801832	test: 0.756730
PRC train: 0.681697	val: 0.314468	test: 0.150749

Epoch: 68
Loss: 0.08717981511068143
ROC train: 0.957903	val: 0.796866	test: 0.748570
PRC train: 0.684751	val: 0.324361	test: 0.146614

Epoch: 69
Loss: 0.08496275750882436
ROC train: 0.955317	val: 0.796572	test: 0.746928
PRC train: 0.672472	val: 0.352077	test: 0.168424

Epoch: 70
Loss: 0.08433625429539413
ROC train: 0.962479	val: 0.784214	test: 0.729560
PRC train: 0.704280	val: 0.328424	test: 0.178738

Epoch: 71
Loss: 0.0866361437592085
ROC train: 0.964096	val: 0.795739	test: 0.736795
PRC train: 0.705234	val: 0.338112	test: 0.151590

Epoch: 72
Loss: 0.08477876298594547
ROC train: 0.965216	val: 0.799964	test: 0.764671
PRC train: 0.721376	val: 0.339572	test: 0.172746

Epoch: 73
Loss: 0.0846908917388506
ROC train: 0.962725	val: 0.804747	test: 0.752884
PRC train: 0.706739	val: 0.304971	test: 0.183549

Epoch: 74
Loss: 0.08263183303432661
ROC train: 0.958771	val: 0.789095	test: 0.738465
PRC train: 0.684902	val: 0.345423	test: 0.192727

Epoch: 75
Loss: 0.08260060196329272
ROC train: 0.963995	val: 0.799597	test: 0.749945
PRC train: 0.719838	val: 0.321261	test: 0.184508

Epoch: 76
Loss: 0.08355995994022557
ROC train: 0.964362	val: 0.801878	test: 0.757927
PRC train: 0.720461	val: 0.300147	test: 0.158163

Epoch: 77
Loss: 0.08318290417099825
ROC train: 0.965150	val: 0.810326	test: 0.762054
PRC train: 0.708080	val: 0.337177	test: 0.170266

Epoch: 78
Loss: 0.08145700376468104
ROC train: 0.968488	val: 0.805715	test: 0.763825
PRC train: 0.726297	val: 0.316364	test: 0.191681

Epoch: 79
Loss: 0.08072896642149624
ROC train: 0.965571	val: 0.809322	test: 0.754039
PRC train: 0.706349	val: 0.328823	test: 0.163875

Epoch: 80
Loss: 0.08059160305575246
ROC train: 0.968663	val: 0.798899	test: 0.746834
PRC train: 0.732373	val: 0.342325	test: 0.182630

Epoch: 81
Loss: 0.0799254893889909
ROC train: 0.970291	val: 0.783948	test: 0.738359
PRC train: 0.727206	val: 0.314334	test: 0.173147

Epoch: 82
Loss: 0.0807019464475377
ROC train: 0.969807	val: 0.810577	test: 0.754961
PRC train: 0.734836	val: 0.318032	test: 0.154832

Epoch: 83
Loss: 0.08178367542350613
ROC train: 0.971660	val: 0.809527	test: 0.746936
PRC train: 0.739321	val: 0.329967	test: 0.171486

Epoch: 84
Loss: 0.07859786918161045
ROC train: 0.970552	val: 0.812178	test: 0.747114
PRC train: 0.734843	val: 0.317436	test: 0.145062

Epoch: 85
Loss: 0.07970425060753733
ROC train: 0.970496	val: 0.805329	test: 0.741548
PRC train: 0.721510	val: 0.316786	test: 0.162380

Epoch: 86
Loss: 0.07969371218478184
ROC train: 0.970672	val: 0.807261	test: 0.771701
PRC train: 0.744263	val: 0.330916	test: 0.185103

Epoch: 87
Loss: 0.07837457002628172
ROC train: 0.971998	val: 0.816076	test: 0.737565
PRC train: 0.744994	val: 0.330889	test: 0.156497

Epoch: 88
Loss: 0.08051078387994547
ROC train: 0.972523	val: 0.803265	test: 0.741455
PRC train: 0.745442	val: 0.330969	test: 0.180638

Epoch: 89
Loss: 0.07776308175923748
ROC train: 0.971452	val: 0.787594	test: 0.743066
PRC train: 0.738888	val: 0.318467	test: 0.180899

Epoch: 90
Loss: 0.07784414701830952
ROC train: 0.974510	val: 0.805938	test: 0.761023
PRC train: 0.757779	val: 0.315134	test: 0.168177

Epoch: 91
Loss: 0.07763251913809033
ROC train: 0.973534	val: 0.809802	test: 0.745408
PRC train: 0.752638	val: 0.327771	test: 0.162945

Epoch: 92
Loss: 0.07838112085802922
ROC train: 0.973535	val: 0.813244	test: 0.752037
PRC train: 0.752880	val: 0.297411	test: 0.155242

Epoch: 93
Loss: 0.079270060279761
ROC train: 0.975841	val: 0.788216	test: 0.751052
PRC train: 0.770976	val: 0.319604	test: 0.180217

Epoch: 94
Loss: 0.07577493900644769
PRC train: 0.660364	val: 0.303613	test: 0.126267

Epoch: 33
Loss: 0.09799535189434178
ROC train: 0.931122	val: 0.781118	test: 0.722967
PRC train: 0.639401	val: 0.306826	test: 0.135184

Epoch: 34
Loss: 0.09605732620299022
ROC train: 0.925615	val: 0.771351	test: 0.731864
PRC train: 0.587169	val: 0.317350	test: 0.165831

Epoch: 35
Loss: 0.09611215452820629
ROC train: 0.947441	val: 0.781645	test: 0.733450
PRC train: 0.695118	val: 0.328036	test: 0.174680

Epoch: 36
Loss: 0.09241631812918859
ROC train: 0.946492	val: 0.789300	test: 0.721609
PRC train: 0.670131	val: 0.350375	test: 0.152973

Epoch: 37
Loss: 0.09469025513067612
ROC train: 0.950744	val: 0.784943	test: 0.739869
PRC train: 0.681374	val: 0.353878	test: 0.190906

Epoch: 38
Loss: 0.09061946498810944
ROC train: 0.956002	val: 0.783378	test: 0.737336
PRC train: 0.712855	val: 0.296104	test: 0.187356

Epoch: 39
Loss: 0.0898698687211105
ROC train: 0.954360	val: 0.785188	test: 0.737801
PRC train: 0.729968	val: 0.340739	test: 0.141301

Epoch: 40
Loss: 0.09004033904308593
ROC train: 0.944599	val: 0.778583	test: 0.730510
PRC train: 0.692835	val: 0.276199	test: 0.126708

Epoch: 41
Loss: 0.08896107963636883
ROC train: 0.960761	val: 0.770735	test: 0.701458
PRC train: 0.743161	val: 0.292297	test: 0.102455

Epoch: 42
Loss: 0.08727973001776497
ROC train: 0.962549	val: 0.790038	test: 0.739989
PRC train: 0.757908	val: 0.297572	test: 0.176514

Epoch: 43
Loss: 0.0858171356443341
ROC train: 0.963054	val: 0.765503	test: 0.735379
PRC train: 0.761671	val: 0.295587	test: 0.195532

Epoch: 44
Loss: 0.0838736404639685
ROC train: 0.965335	val: 0.773859	test: 0.752610
PRC train: 0.764193	val: 0.363634	test: 0.213836

Epoch: 45
Loss: 0.08272880959185622
ROC train: 0.957810	val: 0.745425	test: 0.707157
PRC train: 0.738957	val: 0.308504	test: 0.167507

Epoch: 46
Loss: 0.08372047613181259
ROC train: 0.968546	val: 0.755083	test: 0.704608
PRC train: 0.752555	val: 0.269171	test: 0.094985

Epoch: 47
Loss: 0.08056159349899841
ROC train: 0.969154	val: 0.780993	test: 0.716078
PRC train: 0.793521	val: 0.311527	test: 0.177514

Epoch: 48
Loss: 0.08023020814347798
ROC train: 0.968018	val: 0.769651	test: 0.715139
PRC train: 0.776925	val: 0.323261	test: 0.129641

Epoch: 49
Loss: 0.07849389169537226
ROC train: 0.972599	val: 0.787374	test: 0.749393
PRC train: 0.798917	val: 0.335219	test: 0.191535

Epoch: 50
Loss: 0.07803271871583761
ROC train: 0.967335	val: 0.774376	test: 0.717878
PRC train: 0.796967	val: 0.330671	test: 0.175201

Epoch: 51
Loss: 0.0781750594645354
ROC train: 0.973589	val: 0.765720	test: 0.739904
PRC train: 0.810335	val: 0.329792	test: 0.148795

Epoch: 52
Loss: 0.07626696517528929
ROC train: 0.978417	val: 0.736996	test: 0.700597
PRC train: 0.832185	val: 0.281073	test: 0.136075

Epoch: 53
Loss: 0.07654655952022119
ROC train: 0.977975	val: 0.792686	test: 0.716684
PRC train: 0.833516	val: 0.287083	test: 0.101888

Epoch: 54
Loss: 0.07434330560494215
ROC train: 0.977992	val: 0.799331	test: 0.735744
PRC train: 0.839229	val: 0.337287	test: 0.213414

Epoch: 55
Loss: 0.07168560256103709
ROC train: 0.982774	val: 0.782968	test: 0.739051
PRC train: 0.853564	val: 0.323243	test: 0.164360

Epoch: 56
Loss: 0.07350077572921364
ROC train: 0.979337	val: 0.773418	test: 0.713608
PRC train: 0.831873	val: 0.307244	test: 0.147519

Epoch: 57
Loss: 0.07245880957625739
ROC train: 0.979799	val: 0.763828	test: 0.734249
PRC train: 0.839276	val: 0.318450	test: 0.195832

Epoch: 58
Loss: 0.07076407486198195
ROC train: 0.982991	val: 0.777064	test: 0.732086
PRC train: 0.871002	val: 0.317122	test: 0.142700

Epoch: 59
Loss: 0.06956655003442427
ROC train: 0.986534	val: 0.769195	test: 0.723392
PRC train: 0.881103	val: 0.325401	test: 0.213012

Epoch: 60
Loss: 0.06780718344664231
ROC train: 0.985166	val: 0.787227	test: 0.702213
PRC train: 0.882437	val: 0.259837	test: 0.093682

Epoch: 61
Loss: 0.06520894624043372
ROC train: 0.984823	val: 0.792515	test: 0.725159
PRC train: 0.874377	val: 0.268733	test: 0.128402

Epoch: 62
Loss: 0.06715340535396723
ROC train: 0.986198	val: 0.778219	test: 0.755814
PRC train: 0.869320	val: 0.299340	test: 0.224369

Epoch: 63
Loss: 0.06503551725185684
ROC train: 0.986656	val: 0.784734	test: 0.735785
PRC train: 0.878561	val: 0.311066	test: 0.146687

Epoch: 64
Loss: 0.06440998874650174
ROC train: 0.988678	val: 0.766412	test: 0.720298
PRC train: 0.881494	val: 0.258288	test: 0.106538

Epoch: 65
Loss: 0.06299057141362079
ROC train: 0.988489	val: 0.777444	test: 0.704405
PRC train: 0.888551	val: 0.231570	test: 0.086303

Epoch: 66
Loss: 0.061380670547961765
ROC train: 0.987895	val: 0.776789	test: 0.725501
PRC train: 0.890748	val: 0.256717	test: 0.110214

Epoch: 67
Loss: 0.06311342439706841
ROC train: 0.988820	val: 0.765775	test: 0.725819
PRC train: 0.890931	val: 0.289644	test: 0.130861

Epoch: 68
Loss: 0.06279010129958103
ROC train: 0.988922	val: 0.778690	test: 0.724091
PRC train: 0.896299	val: 0.284370	test: 0.184661

Epoch: 69
Loss: 0.060824711907244526
ROC train: 0.991048	val: 0.763809	test: 0.690396
PRC train: 0.905379	val: 0.255041	test: 0.096549

Epoch: 70
Loss: 0.061391972656347896
ROC train: 0.991557	val: 0.759927	test: 0.710889
PRC train: 0.911469	val: 0.256276	test: 0.096903

Epoch: 71
Loss: 0.061176281982796885
ROC train: 0.991981	val: 0.754186	test: 0.732133
PRC train: 0.916246	val: 0.285639	test: 0.165369

Epoch: 72
Loss: 0.05859925766253507
ROC train: 0.991496	val: 0.770451	test: 0.743085
PRC train: 0.911598	val: 0.348054	test: 0.186524

Epoch: 73
Loss: 0.0571907793360891
ROC train: 0.991953	val: 0.764149	test: 0.716767
PRC train: 0.916250	val: 0.304969	test: 0.188458

Epoch: 74
Loss: 0.05663785214410506
ROC train: 0.994285	val: 0.767572	test: 0.700977
PRC train: 0.931191	val: 0.255742	test: 0.110468

Epoch: 75
Loss: 0.05714959233019104
ROC train: 0.993681	val: 0.754078	test: 0.714112
PRC train: 0.928326	val: 0.284175	test: 0.130054

Epoch: 76
Loss: 0.05687152861542108
ROC train: 0.990804	val: 0.764345	test: 0.740279
PRC train: 0.896423	val: 0.306675	test: 0.230460

Epoch: 77
Loss: 0.05469550890895367
ROC train: 0.991861	val: 0.758117	test: 0.729139
PRC train: 0.914211	val: 0.284661	test: 0.137774

Epoch: 78
Loss: 0.05459852851770207
ROC train: 0.991254	val: 0.783185	test: 0.726936
PRC train: 0.917760	val: 0.350757	test: 0.238927

Epoch: 79
Loss: 0.054348342557875635
ROC train: 0.993291	val: 0.794410	test: 0.733264
PRC train: 0.926183	val: 0.299201	test: 0.144123

Epoch: 80
Loss: 0.05309718517870446
ROC train: 0.992438	val: 0.762318	test: 0.716250
PRC train: 0.915236	val: 0.279568	test: 0.153783

Epoch: 81
Loss: 0.05456853451435527
ROC train: 0.993882	val: 0.782377	test: 0.720989
PRC train: 0.932408	val: 0.302959	test: 0.129100

Epoch: 82
Loss: 0.05408523984746276
ROC train: 0.994324	val: 0.757444	test: 0.728280
PRC train: 0.939631	val: 0.265999	test: 0.129985

Epoch: 83
Loss: 0.05071059902654583
ROC train: 0.995367	val: 0.755496	test: 0.723652
PRC train: 0.950397	val: 0.290295	test: 0.143348

Epoch: 84
Loss: 0.05178319331336448
ROC train: 0.995435	val: 0.766883	test: 0.732347
PRC train: 0.943485	val: 0.256588	test: 0.122317

Epoch: 85
Loss: 0.05046235044810365
ROC train: 0.995712	val: 0.770420	test: 0.728276
PRC train: 0.947836	val: 0.275499	test: 0.117797

Epoch: 86
Loss: 0.04844807877220339
ROC train: 0.996236	val: 0.757110	test: 0.702099
PRC train: 0.951613	val: 0.244431	test: 0.088051

Epoch: 87
Loss: 0.04766763518417947
ROC train: 0.994381	val: 0.757489	test: 0.714585
PRC train: 0.939725	val: 0.285191	test: 0.156189

Epoch: 88
Loss: 0.04843378698476229
ROC train: 0.994681	val: 0.763574	test: 0.739806
PRC train: 0.936958	val: 0.304866	test: 0.169677

Epoch: 89
Loss: 0.047051836182225755
ROC train: 0.997155	val: 0.765248	test: 0.693436
PRC train: 0.962662	val: 0.270366	test: 0.088339

Epoch: 90
Loss: 0.04458637473505267
ROC train: 0.995682	val: 0.780506	test: 0.705406
PRC train: 0.953428	val: 0.300509	test: 0.147326

Epoch: 91
Loss: 0.04679122799433261
ROC train: 0.997241	val: 0.752930	test: 0.725196
PRC train: 0.961400	val: 0.298400	test: 0.160394

Epoch: 92
Loss: 0.0485851669556548
ROC train: 0.996358	val: 0.753549	test: 0.721065
PRC train: 0.959837	val: 0.278102	test: 0.164884

Epoch: 93
Loss: 0.04345710900089255
ROC train: 0.997741	val: 0.765668	test: 0.723936
PRC train: 0.664123	val: 0.324671	test: 0.277523

Epoch: 33
Loss: 0.09745762876135412
ROC train: 0.953885	val: 0.766593	test: 0.737108
PRC train: 0.673165	val: 0.322125	test: 0.228635

Epoch: 34
Loss: 0.09528028593961982
ROC train: 0.950253	val: 0.733389	test: 0.742436
PRC train: 0.671795	val: 0.315521	test: 0.253468

Epoch: 35
Loss: 0.09235134366291899
ROC train: 0.955509	val: 0.763696	test: 0.725750
PRC train: 0.693950	val: 0.318673	test: 0.207455

Epoch: 36
Loss: 0.09287682980653733
ROC train: 0.959680	val: 0.738386	test: 0.730644
PRC train: 0.722715	val: 0.297532	test: 0.209819

Epoch: 37
Loss: 0.09150250300277818
ROC train: 0.960807	val: 0.769106	test: 0.703387
PRC train: 0.724771	val: 0.341796	test: 0.199353

Epoch: 38
Loss: 0.087510407518996
ROC train: 0.967804	val: 0.765065	test: 0.717980
PRC train: 0.758282	val: 0.346925	test: 0.250016

Epoch: 39
Loss: 0.08862589287054828
ROC train: 0.959467	val: 0.774100	test: 0.743811
PRC train: 0.720091	val: 0.350653	test: 0.238066

Epoch: 40
Loss: 0.08578643712798144
ROC train: 0.962409	val: 0.741197	test: 0.754358
PRC train: 0.735733	val: 0.302473	test: 0.246446

Epoch: 41
Loss: 0.08682443206754456
ROC train: 0.970670	val: 0.773761	test: 0.730895
PRC train: 0.788642	val: 0.347719	test: 0.217488

Epoch: 42
Loss: 0.08334243177093717
ROC train: 0.970177	val: 0.750187	test: 0.758601
PRC train: 0.759413	val: 0.357862	test: 0.263506

Epoch: 43
Loss: 0.08321975266848268
ROC train: 0.970033	val: 0.766167	test: 0.730802
PRC train: 0.748675	val: 0.323285	test: 0.143734

Epoch: 44
Loss: 0.08061978732500648
ROC train: 0.977811	val: 0.769183	test: 0.726252
PRC train: 0.832568	val: 0.327964	test: 0.248180

Epoch: 45
Loss: 0.08082953390145631
ROC train: 0.978465	val: 0.755260	test: 0.726260
PRC train: 0.812400	val: 0.321884	test: 0.237079

Epoch: 46
Loss: 0.07549419565408004
ROC train: 0.975625	val: 0.739029	test: 0.718762
PRC train: 0.811308	val: 0.358676	test: 0.222314

Epoch: 47
Loss: 0.07679176981696281
ROC train: 0.975178	val: 0.749731	test: 0.728421
PRC train: 0.818998	val: 0.357711	test: 0.233806

Epoch: 48
Loss: 0.07367521168117779
ROC train: 0.982717	val: 0.770836	test: 0.707557
PRC train: 0.845010	val: 0.325298	test: 0.166986

Epoch: 49
Loss: 0.07270754452178498
ROC train: 0.983196	val: 0.770533	test: 0.712754
PRC train: 0.851031	val: 0.332380	test: 0.199470

Epoch: 50
Loss: 0.07247601807593942
ROC train: 0.987435	val: 0.794582	test: 0.707824
PRC train: 0.883340	val: 0.351000	test: 0.158603

Epoch: 51
Loss: 0.07135703214261475
ROC train: 0.982523	val: 0.779747	test: 0.736248
PRC train: 0.846884	val: 0.340334	test: 0.223958

Epoch: 52
Loss: 0.06873252958320317
ROC train: 0.984220	val: 0.774431	test: 0.714854
PRC train: 0.856885	val: 0.335898	test: 0.161824

Epoch: 53
Loss: 0.06765206193447237
ROC train: 0.986040	val: 0.767676	test: 0.730211
PRC train: 0.871344	val: 0.304411	test: 0.176350

Epoch: 54
Loss: 0.06831964569285028
ROC train: 0.986738	val: 0.766767	test: 0.710524
PRC train: 0.878099	val: 0.340927	test: 0.203474

Epoch: 55
Loss: 0.06597034921262876
ROC train: 0.991470	val: 0.780564	test: 0.720251
PRC train: 0.908998	val: 0.309491	test: 0.190049

Epoch: 56
Loss: 0.06585193988596487
ROC train: 0.988024	val: 0.783314	test: 0.715920
PRC train: 0.891819	val: 0.363574	test: 0.188322

Epoch: 57
Loss: 0.06316649290316836
ROC train: 0.990953	val: 0.756305	test: 0.725837
PRC train: 0.908372	val: 0.354649	test: 0.242416

Epoch: 58
Loss: 0.06097000370712757
ROC train: 0.991676	val: 0.764912	test: 0.701043
PRC train: 0.921429	val: 0.325524	test: 0.159439

Epoch: 59
Loss: 0.05903972990283891
ROC train: 0.992936	val: 0.770959	test: 0.730329
PRC train: 0.918361	val: 0.359312	test: 0.216426

Epoch: 60
Loss: 0.06098647493803527
ROC train: 0.989429	val: 0.771617	test: 0.722484
PRC train: 0.907830	val: 0.323573	test: 0.213814

Epoch: 61
Loss: 0.059517403244483666
ROC train: 0.991012	val: 0.775227	test: 0.728660
PRC train: 0.916797	val: 0.323877	test: 0.236568

Epoch: 62
Loss: 0.0596944714403162
ROC train: 0.992972	val: 0.792809	test: 0.708683
PRC train: 0.927630	val: 0.356683	test: 0.203432

Epoch: 63
Loss: 0.05584380825850725
ROC train: 0.993310	val: 0.765864	test: 0.722650
PRC train: 0.931074	val: 0.336948	test: 0.252231

Epoch: 64
Loss: 0.05553589505940686
ROC train: 0.995191	val: 0.756666	test: 0.715346
PRC train: 0.941203	val: 0.276704	test: 0.196318

Epoch: 65
Loss: 0.05575478159385271
ROC train: 0.994244	val: 0.771161	test: 0.706383
PRC train: 0.942890	val: 0.317110	test: 0.211163

Epoch: 66
Loss: 0.05137433210003866
ROC train: 0.995110	val: 0.774566	test: 0.732152
PRC train: 0.942138	val: 0.350685	test: 0.259326

Epoch: 67
Loss: 0.05572872366963886
ROC train: 0.993766	val: 0.766770	test: 0.737563
PRC train: 0.930876	val: 0.342499	test: 0.253593

Epoch: 68
Loss: 0.05245913234428724
ROC train: 0.992997	val: 0.764722	test: 0.728185
PRC train: 0.923293	val: 0.330267	test: 0.206744

Epoch: 69
Loss: 0.0503077847444018
ROC train: 0.995606	val: 0.759005	test: 0.721630
PRC train: 0.944927	val: 0.313180	test: 0.250251

Epoch: 70
Loss: 0.054786369483047846
ROC train: 0.996166	val: 0.770723	test: 0.704457
PRC train: 0.954929	val: 0.335736	test: 0.201710

Epoch: 71
Loss: 0.049195750078777085
ROC train: 0.995583	val: 0.747988	test: 0.723201
PRC train: 0.950897	val: 0.333398	test: 0.245473

Epoch: 72
Loss: 0.04758758052602934
ROC train: 0.996411	val: 0.757232	test: 0.730219
PRC train: 0.954496	val: 0.346090	test: 0.255382

Epoch: 73
Loss: 0.04770483710144012
ROC train: 0.997304	val: 0.759869	test: 0.720080
PRC train: 0.964783	val: 0.316635	test: 0.220049

Epoch: 74
Loss: 0.04686284001281918
ROC train: 0.997292	val: 0.779915	test: 0.722069
PRC train: 0.965196	val: 0.348695	test: 0.231836

Epoch: 75
Loss: 0.04704071319866849
ROC train: 0.998524	val: 0.783834	test: 0.727171
PRC train: 0.979220	val: 0.333276	test: 0.222160

Epoch: 76
Loss: 0.04793656314816404
ROC train: 0.996383	val: 0.788822	test: 0.745347
PRC train: 0.950916	val: 0.329510	test: 0.205179

Epoch: 77
Loss: 0.04620906239253546
ROC train: 0.995905	val: 0.762165	test: 0.737067
PRC train: 0.950427	val: 0.276959	test: 0.234770

Epoch: 78
Loss: 0.04677659594275989
ROC train: 0.997064	val: 0.786526	test: 0.764389
PRC train: 0.957612	val: 0.353394	test: 0.240460

Epoch: 79
Loss: 0.04389291721227102
ROC train: 0.998518	val: 0.771669	test: 0.714048
PRC train: 0.978544	val: 0.288746	test: 0.159554

Epoch: 80
Loss: 0.04278581698822572
ROC train: 0.998510	val: 0.773849	test: 0.742282
PRC train: 0.980690	val: 0.344050	test: 0.270728

Epoch: 81
Loss: 0.04252858939693367
ROC train: 0.996478	val: 0.769073	test: 0.744221
PRC train: 0.952885	val: 0.352707	test: 0.270973

Epoch: 82
Loss: 0.04344328637187575
ROC train: 0.998472	val: 0.781801	test: 0.746002
PRC train: 0.976281	val: 0.362451	test: 0.220461

Epoch: 83
Loss: 0.04100408694604175
ROC train: 0.998520	val: 0.795822	test: 0.765894
PRC train: 0.979269	val: 0.373018	test: 0.265242

Epoch: 84
Loss: 0.04112232304026579
ROC train: 0.998615	val: 0.790145	test: 0.735665
PRC train: 0.979331	val: 0.356927	test: 0.287128

Epoch: 85
Loss: 0.036439134645356495
ROC train: 0.998336	val: 0.764584	test: 0.723100
PRC train: 0.977505	val: 0.351515	test: 0.225174

Epoch: 86
Loss: 0.03766850441365671
ROC train: 0.998910	val: 0.772585	test: 0.722509
PRC train: 0.983934	val: 0.342251	test: 0.243878

Epoch: 87
Loss: 0.03713945257201999
ROC train: 0.998807	val: 0.769048	test: 0.751461
PRC train: 0.980615	val: 0.387505	test: 0.255545

Epoch: 88
Loss: 0.038347458507838446
ROC train: 0.998123	val: 0.771455	test: 0.757284
PRC train: 0.973232	val: 0.381297	test: 0.277819

Epoch: 89
Loss: 0.03624513030409472
ROC train: 0.999443	val: 0.786936	test: 0.744022
PRC train: 0.988088	val: 0.298880	test: 0.193636

Epoch: 90
Loss: 0.03673465936721432
ROC train: 0.998749	val: 0.760071	test: 0.744532
PRC train: 0.981627	val: 0.379613	test: 0.273068

Epoch: 91
Loss: 0.03561524054895476
ROC train: 0.998456	val: 0.773029	test: 0.748193
PRC train: 0.976184	val: 0.347617	test: 0.263170

Epoch: 92
Loss: 0.035628703268784104
ROC train: 0.998751	val: 0.753668	test: 0.725924
PRC train: 0.982600	val: 0.348728	test: 0.236548

Epoch: 93
Loss: 0.037762482085621496
ROC train: 0.999125	val: 0.775016	test: 0.750266
PRC train: 0.664952	val: 0.326008	test: 0.240043

Epoch: 33
Loss: 0.0970087987330552
ROC train: 0.950152	val: 0.761938	test: 0.709338
PRC train: 0.669385	val: 0.313075	test: 0.203270

Epoch: 34
Loss: 0.09597218229040835
ROC train: 0.950628	val: 0.748441	test: 0.727445
PRC train: 0.667694	val: 0.294388	test: 0.235167

Epoch: 35
Loss: 0.09463910522366886
ROC train: 0.950925	val: 0.789441	test: 0.754360
PRC train: 0.665036	val: 0.331983	test: 0.238339

Epoch: 36
Loss: 0.09253693900402209
ROC train: 0.961706	val: 0.798731	test: 0.731590
PRC train: 0.730471	val: 0.372870	test: 0.233237

Epoch: 37
Loss: 0.09034226112124351
ROC train: 0.964550	val: 0.782389	test: 0.742660
PRC train: 0.744750	val: 0.333606	test: 0.241356

Epoch: 38
Loss: 0.08938888199505494
ROC train: 0.964739	val: 0.760695	test: 0.721507
PRC train: 0.748349	val: 0.338499	test: 0.242150

Epoch: 39
Loss: 0.08813335747458674
ROC train: 0.968899	val: 0.791970	test: 0.749989
PRC train: 0.753029	val: 0.344270	test: 0.264944

Epoch: 40
Loss: 0.08810772893348358
ROC train: 0.971215	val: 0.789134	test: 0.738334
PRC train: 0.786333	val: 0.353129	test: 0.267914

Epoch: 41
Loss: 0.08604729182923836
ROC train: 0.973164	val: 0.777900	test: 0.717642
PRC train: 0.786717	val: 0.330061	test: 0.262549

Epoch: 42
Loss: 0.08447620197979397
ROC train: 0.969858	val: 0.751081	test: 0.711047
PRC train: 0.779046	val: 0.302897	test: 0.187490

Epoch: 43
Loss: 0.08103558898154861
ROC train: 0.973639	val: 0.780699	test: 0.722127
PRC train: 0.789392	val: 0.275630	test: 0.216425

Epoch: 44
Loss: 0.0826812100183899
ROC train: 0.976576	val: 0.754614	test: 0.708237
PRC train: 0.810290	val: 0.320532	test: 0.272636

Epoch: 45
Loss: 0.07941345188684475
ROC train: 0.981370	val: 0.770812	test: 0.710626
PRC train: 0.849173	val: 0.314243	test: 0.236010

Epoch: 46
Loss: 0.07706909401814958
ROC train: 0.979083	val: 0.789431	test: 0.742002
PRC train: 0.826724	val: 0.324589	test: 0.197618

Epoch: 47
Loss: 0.07904785000864796
ROC train: 0.979705	val: 0.804756	test: 0.748384
PRC train: 0.822399	val: 0.369020	test: 0.273310

Epoch: 48
Loss: 0.07453181406386711
ROC train: 0.985734	val: 0.776219	test: 0.719388
PRC train: 0.875195	val: 0.314250	test: 0.207517

Epoch: 49
Loss: 0.07231435939713636
ROC train: 0.988957	val: 0.787175	test: 0.709989
PRC train: 0.897861	val: 0.298011	test: 0.202202

Epoch: 50
Loss: 0.06963273800869381
ROC train: 0.985174	val: 0.801756	test: 0.707115
PRC train: 0.868427	val: 0.329049	test: 0.181043

Epoch: 51
Loss: 0.07166304887083734
ROC train: 0.982790	val: 0.770873	test: 0.721215
PRC train: 0.850643	val: 0.303454	test: 0.208172

Epoch: 52
Loss: 0.06926944765535216
ROC train: 0.986038	val: 0.788641	test: 0.725078
PRC train: 0.864272	val: 0.357310	test: 0.210312

Epoch: 53
Loss: 0.06847652411631443
ROC train: 0.988919	val: 0.783219	test: 0.703252
PRC train: 0.891797	val: 0.265767	test: 0.163069

Epoch: 54
Loss: 0.0657827805122088
ROC train: 0.989376	val: 0.800724	test: 0.745719
PRC train: 0.890922	val: 0.318721	test: 0.205163

Epoch: 55
Loss: 0.06546193258029226
ROC train: 0.986891	val: 0.798409	test: 0.730561
PRC train: 0.874113	val: 0.335913	test: 0.208630

Epoch: 56
Loss: 0.06342128640848936
ROC train: 0.991812	val: 0.786321	test: 0.727472
PRC train: 0.918367	val: 0.298116	test: 0.190776

Epoch: 57
Loss: 0.062375914678216904
ROC train: 0.988830	val: 0.795629	test: 0.729612
PRC train: 0.886460	val: 0.345759	test: 0.225843

Epoch: 58
Loss: 0.06144785460054452
ROC train: 0.992041	val: 0.782337	test: 0.706823
PRC train: 0.916156	val: 0.332209	test: 0.175824

Epoch: 59
Loss: 0.06006287596396481
ROC train: 0.994321	val: 0.781636	test: 0.724933
PRC train: 0.941875	val: 0.337902	test: 0.183389

Epoch: 60
Loss: 0.05986215541938396
ROC train: 0.991799	val: 0.784695	test: 0.740273
PRC train: 0.903416	val: 0.343825	test: 0.212284

Epoch: 61
Loss: 0.05939223358419925
ROC train: 0.993016	val: 0.784682	test: 0.698768
PRC train: 0.920662	val: 0.313031	test: 0.163135

Epoch: 62
Loss: 0.056336688836755563
ROC train: 0.993126	val: 0.767955	test: 0.728931
PRC train: 0.924785	val: 0.329375	test: 0.179089

Epoch: 63
Loss: 0.05716839508297085
ROC train: 0.996048	val: 0.786330	test: 0.729514
PRC train: 0.953518	val: 0.341050	test: 0.173214

Epoch: 64
Loss: 0.05476774244401638
ROC train: 0.995634	val: 0.780432	test: 0.743983
PRC train: 0.950257	val: 0.360145	test: 0.255484

Epoch: 65
Loss: 0.05353998010186405
ROC train: 0.996238	val: 0.777444	test: 0.737755
PRC train: 0.952106	val: 0.349128	test: 0.204957

Epoch: 66
Loss: 0.052129778320791076
ROC train: 0.996198	val: 0.765515	test: 0.720562
PRC train: 0.952854	val: 0.301451	test: 0.190761

Epoch: 67
Loss: 0.054938575294653
ROC train: 0.992938	val: 0.798936	test: 0.749039
PRC train: 0.918745	val: 0.349115	test: 0.210989

Epoch: 68
Loss: 0.050560083099049094
ROC train: 0.997002	val: 0.783666	test: 0.735582
PRC train: 0.963721	val: 0.342130	test: 0.188987

Epoch: 69
Loss: 0.05120025205360869
ROC train: 0.996194	val: 0.791994	test: 0.731677
PRC train: 0.956122	val: 0.350989	test: 0.223117

Epoch: 70
Loss: 0.051108703065974814
ROC train: 0.997519	val: 0.768724	test: 0.729220
PRC train: 0.967053	val: 0.282958	test: 0.204352

Epoch: 71
Loss: 0.050956240884514385
ROC train: 0.997750	val: 0.790427	test: 0.719653
PRC train: 0.970358	val: 0.333821	test: 0.191847

Epoch: 72
Loss: 0.0472871451915172
ROC train: 0.995920	val: 0.777664	test: 0.711030
PRC train: 0.954005	val: 0.330877	test: 0.197504

Epoch: 73
Loss: 0.049685315251097366
ROC train: 0.998257	val: 0.809065	test: 0.720705
PRC train: 0.977728	val: 0.335787	test: 0.193766

Epoch: 74
Loss: 0.04948620954341438
ROC train: 0.997888	val: 0.802089	test: 0.721249
PRC train: 0.972532	val: 0.284488	test: 0.195624

Epoch: 75
Loss: 0.042426943157466396
ROC train: 0.998292	val: 0.805969	test: 0.740107
PRC train: 0.978750	val: 0.330781	test: 0.177509

Epoch: 76
Loss: 0.04541417113563151
ROC train: 0.995467	val: 0.781305	test: 0.725931
PRC train: 0.944640	val: 0.313264	test: 0.222493

Epoch: 77
Loss: 0.04546300886421614
ROC train: 0.996865	val: 0.817225	test: 0.725609
PRC train: 0.962921	val: 0.319210	test: 0.174922

Epoch: 78
Loss: 0.04627406157588772
ROC train: 0.998647	val: 0.784992	test: 0.716947
PRC train: 0.978604	val: 0.286133	test: 0.162561

Epoch: 79
Loss: 0.04397283056197189
ROC train: 0.997710	val: 0.798905	test: 0.724720
PRC train: 0.967096	val: 0.307935	test: 0.164965

Epoch: 80
Loss: 0.042388937647879016
ROC train: 0.997198	val: 0.785111	test: 0.738626
PRC train: 0.964762	val: 0.318941	test: 0.197993

Epoch: 81
Loss: 0.04068343732064683
ROC train: 0.998555	val: 0.813569	test: 0.720458
PRC train: 0.980621	val: 0.338046	test: 0.184396

Epoch: 82
Loss: 0.04302127821600234
ROC train: 0.997274	val: 0.780705	test: 0.718279
PRC train: 0.968366	val: 0.309817	test: 0.152212

Epoch: 83
Loss: 0.041764438315915454
ROC train: 0.999086	val: 0.807460	test: 0.729390
PRC train: 0.986508	val: 0.301554	test: 0.183309

Epoch: 84
Loss: 0.04147804279836699
ROC train: 0.998391	val: 0.792800	test: 0.709293
PRC train: 0.978991	val: 0.315965	test: 0.170130

Epoch: 85
Loss: 0.038145171285409354
ROC train: 0.997053	val: 0.797353	test: 0.715103
PRC train: 0.960616	val: 0.317444	test: 0.206836

Epoch: 86
Loss: 0.037451888980994386
ROC train: 0.999138	val: 0.772719	test: 0.714703
PRC train: 0.988131	val: 0.282598	test: 0.179260

Epoch: 87
Loss: 0.035554983178017224
ROC train: 0.999179	val: 0.804028	test: 0.710240
PRC train: 0.986559	val: 0.337791	test: 0.189464

Epoch: 88
Loss: 0.03711382217372014
ROC train: 0.997914	val: 0.809429	test: 0.719139
PRC train: 0.969166	val: 0.353665	test: 0.208653

Epoch: 89
Loss: 0.0382532457791318
ROC train: 0.999119	val: 0.799462	test: 0.727670
PRC train: 0.985778	val: 0.318655	test: 0.183388

Epoch: 90
Loss: 0.03723573055390787
ROC train: 0.999495	val: 0.795623	test: 0.722532
PRC train: 0.992695	val: 0.349501	test: 0.209347

Epoch: 91
Loss: 0.03461522427825548
ROC train: 0.999623	val: 0.790261	test: 0.724608
PRC train: 0.991655	val: 0.241874	test: 0.138589

Epoch: 92
Loss: 0.0345452371164474
ROC train: 0.999610	val: 0.802693	test: 0.720725
PRC train: 0.993045	val: 0.336638	test: 0.182095

Epoch: 93
Loss: 0.034724974171006104

PRC train: 0.631367	val: 0.375644	test: 0.178997

Epoch: 33
Loss: 0.09775293332646039
ROC train: 0.937893	val: 0.789232	test: 0.750300
PRC train: 0.652153	val: 0.343930	test: 0.201417

Epoch: 34
Loss: 0.09722257035385747
ROC train: 0.933953	val: 0.767615	test: 0.718689
PRC train: 0.642490	val: 0.365757	test: 0.179584

Epoch: 35
Loss: 0.09454628098449372
ROC train: 0.945978	val: 0.787894	test: 0.707636
PRC train: 0.687744	val: 0.349244	test: 0.141484

Epoch: 36
Loss: 0.09338290037179724
ROC train: 0.948387	val: 0.805966	test: 0.735750
PRC train: 0.688733	val: 0.365907	test: 0.192049

Epoch: 37
Loss: 0.09554237189303814
ROC train: 0.941779	val: 0.791801	test: 0.729655
PRC train: 0.684804	val: 0.356103	test: 0.208431

Epoch: 38
Loss: 0.0919593152933404
ROC train: 0.945477	val: 0.794496	test: 0.698897
PRC train: 0.693716	val: 0.344583	test: 0.169070

Epoch: 39
Loss: 0.09643929407622352
ROC train: 0.952244	val: 0.786391	test: 0.728768
PRC train: 0.703216	val: 0.352220	test: 0.218499

Epoch: 40
Loss: 0.09129935976054737
ROC train: 0.955635	val: 0.797506	test: 0.726142
PRC train: 0.722969	val: 0.316413	test: 0.169164

Epoch: 41
Loss: 0.08822938040154041
ROC train: 0.955886	val: 0.784150	test: 0.717362
PRC train: 0.732498	val: 0.382063	test: 0.166129

Epoch: 42
Loss: 0.08893421183407589
ROC train: 0.953650	val: 0.765368	test: 0.715970
PRC train: 0.722267	val: 0.381350	test: 0.220884

Epoch: 43
Loss: 0.08774898869076331
ROC train: 0.963701	val: 0.795816	test: 0.716466
PRC train: 0.757236	val: 0.342774	test: 0.193868

Epoch: 44
Loss: 0.08571773167912237
ROC train: 0.958204	val: 0.772230	test: 0.709767
PRC train: 0.754080	val: 0.327480	test: 0.119636

Epoch: 45
Loss: 0.08454721192750934
ROC train: 0.967540	val: 0.786875	test: 0.709749
PRC train: 0.773449	val: 0.376493	test: 0.167679

Epoch: 46
Loss: 0.08514563748629998
ROC train: 0.962734	val: 0.758491	test: 0.731893
PRC train: 0.746862	val: 0.377143	test: 0.263753

Epoch: 47
Loss: 0.08248327907504782
ROC train: 0.968661	val: 0.773252	test: 0.739887
PRC train: 0.782663	val: 0.388150	test: 0.190183

Epoch: 48
Loss: 0.08203778377960422
ROC train: 0.973332	val: 0.780126	test: 0.709697
PRC train: 0.791063	val: 0.340216	test: 0.155199

Epoch: 49
Loss: 0.07976079414813533
ROC train: 0.972044	val: 0.804518	test: 0.724753
PRC train: 0.791487	val: 0.362351	test: 0.189656

Epoch: 50
Loss: 0.0805391559430052
ROC train: 0.975727	val: 0.790117	test: 0.713730
PRC train: 0.811650	val: 0.357488	test: 0.145863

Epoch: 51
Loss: 0.07781914388603471
ROC train: 0.971818	val: 0.774186	test: 0.699117
PRC train: 0.781611	val: 0.344844	test: 0.109274

Epoch: 52
Loss: 0.07606817796460276
ROC train: 0.974751	val: 0.787408	test: 0.725562
PRC train: 0.804671	val: 0.327407	test: 0.146751

Epoch: 53
Loss: 0.07678015759713568
ROC train: 0.973524	val: 0.780255	test: 0.747595
PRC train: 0.795317	val: 0.319488	test: 0.125526

Epoch: 54
Loss: 0.0758127806680973
ROC train: 0.979667	val: 0.748974	test: 0.712376
PRC train: 0.830142	val: 0.351824	test: 0.159142

Epoch: 55
Loss: 0.07364723637120778
ROC train: 0.982321	val: 0.761286	test: 0.729338
PRC train: 0.844331	val: 0.365970	test: 0.159015

Epoch: 56
Loss: 0.07186764875977034
ROC train: 0.982394	val: 0.777383	test: 0.706346
PRC train: 0.849360	val: 0.356286	test: 0.161255

Epoch: 57
Loss: 0.0731426338080524
ROC train: 0.979027	val: 0.751191	test: 0.736383
PRC train: 0.830245	val: 0.334480	test: 0.190487

Epoch: 58
Loss: 0.07122373786019082
ROC train: 0.981970	val: 0.768656	test: 0.724541
PRC train: 0.844837	val: 0.327212	test: 0.157298

Epoch: 59
Loss: 0.06985505744203323
ROC train: 0.979075	val: 0.771531	test: 0.723666
PRC train: 0.826274	val: 0.361009	test: 0.170905

Epoch: 60
Loss: 0.06764107419695481
ROC train: 0.983997	val: 0.757104	test: 0.714612
PRC train: 0.859605	val: 0.340487	test: 0.173373

Epoch: 61
Loss: 0.07066449032741054
ROC train: 0.984216	val: 0.783473	test: 0.727783
PRC train: 0.857040	val: 0.359226	test: 0.189046

Epoch: 62
Loss: 0.06989391250623511
ROC train: 0.982511	val: 0.770448	test: 0.710554
PRC train: 0.845959	val: 0.338234	test: 0.129360

Epoch: 63
Loss: 0.06710783526961402
ROC train: 0.986963	val: 0.789107	test: 0.724985
PRC train: 0.865340	val: 0.352106	test: 0.148218

Epoch: 64
Loss: 0.06576936452589355
ROC train: 0.981988	val: 0.754608	test: 0.717094
PRC train: 0.856119	val: 0.342073	test: 0.150615

Epoch: 65
Loss: 0.0643948549761718
ROC train: 0.983436	val: 0.744158	test: 0.694890
PRC train: 0.833691	val: 0.280558	test: 0.091834

Epoch: 66
Loss: 0.06311614632990072
ROC train: 0.986722	val: 0.778663	test: 0.738324
PRC train: 0.877363	val: 0.344977	test: 0.167815

Epoch: 67
Loss: 0.06526897135110014
ROC train: 0.987131	val: 0.772380	test: 0.731088
PRC train: 0.878775	val: 0.337401	test: 0.166629

Epoch: 68
Loss: 0.06257376206061661
ROC train: 0.987236	val: 0.795537	test: 0.729773
PRC train: 0.875575	val: 0.318803	test: 0.148746

Epoch: 69
Loss: 0.0643285389614042
ROC train: 0.992750	val: 0.784339	test: 0.725051
PRC train: 0.913988	val: 0.341935	test: 0.153785

Epoch: 70
Loss: 0.05847964099497342
ROC train: 0.991741	val: 0.779737	test: 0.705751
PRC train: 0.905985	val: 0.356062	test: 0.159754

Epoch: 71
Loss: 0.0604655578720702
ROC train: 0.992146	val: 0.758047	test: 0.738958
PRC train: 0.920684	val: 0.335375	test: 0.177637

Epoch: 72
Loss: 0.06165971875564556
ROC train: 0.988743	val: 0.794153	test: 0.720725
PRC train: 0.879052	val: 0.309485	test: 0.128467

Epoch: 73
Loss: 0.05715861307058513
ROC train: 0.994223	val: 0.780968	test: 0.713811
PRC train: 0.928850	val: 0.275906	test: 0.128407

Epoch: 74
Loss: 0.0595820553556303
ROC train: 0.993934	val: 0.774578	test: 0.730636
PRC train: 0.931366	val: 0.340683	test: 0.182433

Epoch: 75
Loss: 0.057689918057792416
ROC train: 0.994798	val: 0.789098	test: 0.722192
PRC train: 0.930068	val: 0.345157	test: 0.164711

Epoch: 76
Loss: 0.0578532970506241
ROC train: 0.992450	val: 0.778559	test: 0.715655
PRC train: 0.909271	val: 0.295125	test: 0.124487

Epoch: 77
Loss: 0.058626054762847137
ROC train: 0.990933	val: 0.760968	test: 0.732003
PRC train: 0.901090	val: 0.326904	test: 0.195604

Epoch: 78
Loss: 0.05254837105802833
ROC train: 0.994121	val: 0.748460	test: 0.720180
PRC train: 0.930405	val: 0.353191	test: 0.147192

Epoch: 79
Loss: 0.05593921999935214
ROC train: 0.994518	val: 0.770463	test: 0.707310
PRC train: 0.934939	val: 0.246192	test: 0.126368

Epoch: 80
Loss: 0.05181388411115101
ROC train: 0.995382	val: 0.768904	test: 0.715746
PRC train: 0.944861	val: 0.346901	test: 0.178404

Epoch: 81
Loss: 0.05122138087445737
ROC train: 0.991070	val: 0.774817	test: 0.734458
PRC train: 0.888268	val: 0.323304	test: 0.186717

Epoch: 82
Loss: 0.05216966870310866
ROC train: 0.994704	val: 0.802154	test: 0.719614
PRC train: 0.935519	val: 0.326414	test: 0.153440

Epoch: 83
Loss: 0.05269797563420292
ROC train: 0.996849	val: 0.798776	test: 0.707014
PRC train: 0.958641	val: 0.285698	test: 0.145914

Epoch: 84
Loss: 0.05151196732532516
ROC train: 0.996139	val: 0.771550	test: 0.689380
PRC train: 0.950481	val: 0.320032	test: 0.113294

Epoch: 85
Loss: 0.04958389751262456
ROC train: 0.996126	val: 0.750655	test: 0.702686
PRC train: 0.947789	val: 0.335911	test: 0.146243

Epoch: 86
Loss: 0.04937509413659388
ROC train: 0.995440	val: 0.797549	test: 0.721335
PRC train: 0.941860	val: 0.319719	test: 0.166691

Epoch: 87
Loss: 0.04875795033792598
ROC train: 0.997071	val: 0.805087	test: 0.739054
PRC train: 0.958725	val: 0.347963	test: 0.166649

Epoch: 88
Loss: 0.04864151166488971
ROC train: 0.997083	val: 0.802613	test: 0.735596
PRC train: 0.957429	val: 0.318506	test: 0.219411

Epoch: 89
Loss: 0.0477629287050999
ROC train: 0.995787	val: 0.793002	test: 0.714628
PRC train: 0.943706	val: 0.311059	test: 0.141185

Epoch: 90
Loss: 0.04843627935505859
ROC train: 0.996929	val: 0.788182	test: 0.732268
PRC train: 0.959752	val: 0.333123	test: 0.140268

Epoch: 91
Loss: 0.04494654494424808
ROC train: 0.997816	val: 0.772692	test: 0.711014
PRC train: 0.967939	val: 0.293981	test: 0.105964

Epoch: 92
Loss: 0.04614643428913211
ROC train: 0.997503	val: 0.755934	test: 0.707661
PRC train: 0.968384	val: 0.298939	test: 0.160132

Epoch: 93
Loss: 0.0430489421054914
ROC train: 0.997789	val: 0.774067	test: 0.722812
PRC train: 0.633823	val: 0.357016	test: 0.176466

Epoch: 33
Loss: 0.09597883473494793
ROC train: 0.941085	val: 0.807598	test: 0.744267
PRC train: 0.657441	val: 0.369370	test: 0.204348

Epoch: 34
Loss: 0.09444881173957528
ROC train: 0.936449	val: 0.797117	test: 0.748516
PRC train: 0.644856	val: 0.364619	test: 0.195070

Epoch: 35
Loss: 0.09221681936149567
ROC train: 0.940585	val: 0.796826	test: 0.746824
PRC train: 0.653233	val: 0.338012	test: 0.222115

Epoch: 36
Loss: 0.09287761908339495
ROC train: 0.947375	val: 0.806894	test: 0.744833
PRC train: 0.672630	val: 0.337330	test: 0.217787

Epoch: 37
Loss: 0.09240408573269708
ROC train: 0.938054	val: 0.782104	test: 0.738230
PRC train: 0.654099	val: 0.332379	test: 0.174326

Epoch: 38
Loss: 0.09340127718184403
ROC train: 0.950661	val: 0.779903	test: 0.725792
PRC train: 0.687043	val: 0.316518	test: 0.165735

Epoch: 39
Loss: 0.08960583341118471
ROC train: 0.943165	val: 0.808057	test: 0.770482
PRC train: 0.668283	val: 0.357102	test: 0.198776

Epoch: 40
Loss: 0.0900245557020044
ROC train: 0.953936	val: 0.813192	test: 0.745795
PRC train: 0.702518	val: 0.344710	test: 0.187227

Epoch: 41
Loss: 0.08972956421298907
ROC train: 0.948909	val: 0.802797	test: 0.751888
PRC train: 0.694433	val: 0.332819	test: 0.166518

Epoch: 42
Loss: 0.08883399596020712
ROC train: 0.954895	val: 0.809392	test: 0.746235
PRC train: 0.711949	val: 0.270951	test: 0.135350

Epoch: 43
Loss: 0.08531124269832589
ROC train: 0.962498	val: 0.811134	test: 0.745733
PRC train: 0.730365	val: 0.353767	test: 0.181092

Epoch: 44
Loss: 0.0835763412995021
ROC train: 0.952615	val: 0.803443	test: 0.749649
PRC train: 0.697486	val: 0.308474	test: 0.238408

Epoch: 45
Loss: 0.08591902079231693
ROC train: 0.958794	val: 0.805834	test: 0.749729
PRC train: 0.725531	val: 0.320238	test: 0.187305

Epoch: 46
Loss: 0.0821552592626474
ROC train: 0.966496	val: 0.796186	test: 0.735062
PRC train: 0.754795	val: 0.306609	test: 0.159162

Epoch: 47
Loss: 0.08279357037678989
ROC train: 0.965599	val: 0.815051	test: 0.751527
PRC train: 0.760951	val: 0.373055	test: 0.185534

Epoch: 48
Loss: 0.08232340845822061
ROC train: 0.966673	val: 0.811277	test: 0.741082
PRC train: 0.754508	val: 0.352152	test: 0.187087

Epoch: 49
Loss: 0.08112604288192565
ROC train: 0.970429	val: 0.784805	test: 0.761162
PRC train: 0.760052	val: 0.347830	test: 0.188062

Epoch: 50
Loss: 0.08065571040307987
ROC train: 0.970740	val: 0.781057	test: 0.760521
PRC train: 0.785615	val: 0.321790	test: 0.191246

Epoch: 51
Loss: 0.07902248220178597
ROC train: 0.967998	val: 0.796774	test: 0.750538
PRC train: 0.759359	val: 0.305900	test: 0.185240

Epoch: 52
Loss: 0.07822059841018675
ROC train: 0.974966	val: 0.814089	test: 0.730159
PRC train: 0.797973	val: 0.264225	test: 0.134415

Epoch: 53
Loss: 0.07773674963534964
ROC train: 0.974808	val: 0.794765	test: 0.747168
PRC train: 0.800275	val: 0.317655	test: 0.147556

Epoch: 54
Loss: 0.0791794373113719
ROC train: 0.973268	val: 0.808458	test: 0.753510
PRC train: 0.801186	val: 0.304923	test: 0.150955

Epoch: 55
Loss: 0.07497374443674965
ROC train: 0.970488	val: 0.795246	test: 0.738747
PRC train: 0.772567	val: 0.287988	test: 0.190365

Epoch: 56
Loss: 0.07492775706599232
ROC train: 0.977113	val: 0.797726	test: 0.738973
PRC train: 0.815519	val: 0.348150	test: 0.161865

Epoch: 57
Loss: 0.07418457048194312
ROC train: 0.974562	val: 0.789079	test: 0.758495
PRC train: 0.812272	val: 0.351106	test: 0.208050

Epoch: 58
Loss: 0.07423112577747602
ROC train: 0.978647	val: 0.812837	test: 0.759314
PRC train: 0.823261	val: 0.309634	test: 0.211820

Epoch: 59
Loss: 0.07369974901717458
ROC train: 0.978728	val: 0.809407	test: 0.747859
PRC train: 0.810404	val: 0.324369	test: 0.189139

Epoch: 60
Loss: 0.07306723978959977
ROC train: 0.981673	val: 0.814803	test: 0.749308
PRC train: 0.832497	val: 0.274811	test: 0.119405

Epoch: 61
Loss: 0.06965521145924278
ROC train: 0.979788	val: 0.821034	test: 0.730084
PRC train: 0.835204	val: 0.305858	test: 0.144029

Epoch: 62
Loss: 0.07071230854495916
ROC train: 0.979075	val: 0.804885	test: 0.752147
PRC train: 0.825409	val: 0.306033	test: 0.182898

Epoch: 63
Loss: 0.0705189976701263
ROC train: 0.980232	val: 0.819248	test: 0.746422
PRC train: 0.826392	val: 0.306160	test: 0.181917

Epoch: 64
Loss: 0.06932746504126966
ROC train: 0.980516	val: 0.816309	test: 0.732249
PRC train: 0.833993	val: 0.328498	test: 0.144946

Epoch: 65
Loss: 0.06670347555738018
ROC train: 0.983336	val: 0.802307	test: 0.735497
PRC train: 0.845194	val: 0.275753	test: 0.120101

Epoch: 66
Loss: 0.07142271777252121
ROC train: 0.982484	val: 0.778543	test: 0.734394
PRC train: 0.850749	val: 0.323890	test: 0.127642

Epoch: 67
Loss: 0.06639901032638387
ROC train: 0.986398	val: 0.791853	test: 0.752583
PRC train: 0.856050	val: 0.289649	test: 0.133671

Epoch: 68
Loss: 0.06660644225079299
ROC train: 0.986714	val: 0.788271	test: 0.735723
PRC train: 0.873957	val: 0.311064	test: 0.176800

Epoch: 69
Loss: 0.06249366609364941
ROC train: 0.986859	val: 0.813021	test: 0.749377
PRC train: 0.866851	val: 0.321905	test: 0.179109

Epoch: 70
Loss: 0.06699788708373824
ROC train: 0.987626	val: 0.810926	test: 0.731714
PRC train: 0.874485	val: 0.294137	test: 0.124840

Epoch: 71
Loss: 0.06308155155687664
ROC train: 0.988474	val: 0.820329	test: 0.741818
PRC train: 0.879970	val: 0.337808	test: 0.163565

Epoch: 72
Loss: 0.06368332362230517
ROC train: 0.988193	val: 0.820124	test: 0.756944
PRC train: 0.877111	val: 0.348799	test: 0.189916

Epoch: 73
Loss: 0.06224246663520849
ROC train: 0.988998	val: 0.789082	test: 0.733235
PRC train: 0.893263	val: 0.316233	test: 0.182878

Epoch: 74
Loss: 0.0636579127813861
ROC train: 0.989038	val: 0.805736	test: 0.745416
PRC train: 0.892029	val: 0.312087	test: 0.185446

Epoch: 75
Loss: 0.06436813512696324
ROC train: 0.989055	val: 0.816435	test: 0.740567
PRC train: 0.888803	val: 0.388832	test: 0.173871

Epoch: 76
Loss: 0.05996711813183618
ROC train: 0.990828	val: 0.794533	test: 0.740362
PRC train: 0.892862	val: 0.278253	test: 0.184022

Epoch: 77
Loss: 0.060765286440662404
ROC train: 0.988798	val: 0.815926	test: 0.733235
PRC train: 0.893651	val: 0.314732	test: 0.172387

Epoch: 78
Loss: 0.05887012880585114
ROC train: 0.991774	val: 0.806685	test: 0.743400
PRC train: 0.908175	val: 0.361860	test: 0.240026

Epoch: 79
Loss: 0.05960945984266261
ROC train: 0.988465	val: 0.817718	test: 0.749480
PRC train: 0.886402	val: 0.309166	test: 0.192601

Epoch: 80
Loss: 0.05790521347911333
ROC train: 0.992735	val: 0.800029	test: 0.742764
PRC train: 0.918849	val: 0.283624	test: 0.191293

Epoch: 81
Loss: 0.05715786103318646
ROC train: 0.991790	val: 0.809469	test: 0.759312
PRC train: 0.910643	val: 0.348654	test: 0.225139

Epoch: 82
Loss: 0.05754528972708589
ROC train: 0.989165	val: 0.807628	test: 0.760246
PRC train: 0.889599	val: 0.358983	test: 0.201776

Epoch: 83
Loss: 0.059417267601847276
ROC train: 0.992944	val: 0.818578	test: 0.729887
PRC train: 0.918844	val: 0.311363	test: 0.169771

Epoch: 84
Loss: 0.05473624960684057
ROC train: 0.992520	val: 0.817577	test: 0.750745
PRC train: 0.915392	val: 0.333363	test: 0.188536

Epoch: 85
Loss: 0.057122041404499835
ROC train: 0.990006	val: 0.804763	test: 0.724763
PRC train: 0.885195	val: 0.319511	test: 0.129338

Epoch: 86
Loss: 0.05289935839548738
ROC train: 0.993334	val: 0.817751	test: 0.748551
PRC train: 0.925248	val: 0.335634	test: 0.155347

Epoch: 87
Loss: 0.05259564265711511
ROC train: 0.993177	val: 0.785325	test: 0.735679
PRC train: 0.924454	val: 0.311053	test: 0.176206

Epoch: 88
Loss: 0.05267819591412029
ROC train: 0.994681	val: 0.795966	test: 0.738651
PRC train: 0.935918	val: 0.284615	test: 0.147605

Epoch: 89
Loss: 0.051486895457717015
ROC train: 0.994965	val: 0.793452	test: 0.746223
PRC train: 0.934992	val: 0.293093	test: 0.185670

Epoch: 90
Loss: 0.05224886533375043
ROC train: 0.992495	val: 0.830620	test: 0.748950
PRC train: 0.916387	val: 0.291788	test: 0.149060

Epoch: 91
Loss: 0.050741744510509015
ROC train: 0.994269	val: 0.804968	test: 0.755244
PRC train: 0.922990	val: 0.313581	test: 0.209696

Epoch: 92
Loss: 0.05088934088798395
ROC train: 0.994633	val: 0.805396	test: 0.742616
PRC train: 0.929017	val: 0.329198	test: 0.194647

Epoch: 93
Loss: 0.04970767508721987
ROC train: 0.996108	val: 0.798593	test: 0.743666
PRC train: 0.650837	val: 0.381603	test: 0.188929

Epoch: 33
Loss: 0.09516643714947465
ROC train: 0.941829	val: 0.773268	test: 0.769490
PRC train: 0.654663	val: 0.327428	test: 0.169426

Epoch: 34
Loss: 0.09547560153508043
ROC train: 0.941952	val: 0.762554	test: 0.746218
PRC train: 0.661390	val: 0.319737	test: 0.133227

Epoch: 35
Loss: 0.09261480509963105
ROC train: 0.941247	val: 0.769964	test: 0.759542
PRC train: 0.664211	val: 0.358892	test: 0.185274

Epoch: 36
Loss: 0.09532078054851324
ROC train: 0.947457	val: 0.754382	test: 0.749481
PRC train: 0.677453	val: 0.351676	test: 0.195857

Epoch: 37
Loss: 0.0924168939568794
ROC train: 0.946062	val: 0.736172	test: 0.749018
PRC train: 0.663111	val: 0.303424	test: 0.168432

Epoch: 38
Loss: 0.08884548107717716
ROC train: 0.955776	val: 0.781957	test: 0.741751
PRC train: 0.701680	val: 0.354345	test: 0.176197

Epoch: 39
Loss: 0.09094411212310284
ROC train: 0.958246	val: 0.777110	test: 0.742747
PRC train: 0.708957	val: 0.362755	test: 0.213836

Epoch: 40
Loss: 0.08844531042331637
ROC train: 0.949834	val: 0.768528	test: 0.736573
PRC train: 0.686297	val: 0.326834	test: 0.135631

Epoch: 41
Loss: 0.08720090955494703
ROC train: 0.949015	val: 0.758527	test: 0.731115
PRC train: 0.684623	val: 0.321726	test: 0.188737

Epoch: 42
Loss: 0.0887197437531031
ROC train: 0.962184	val: 0.769431	test: 0.746735
PRC train: 0.729783	val: 0.362218	test: 0.187616

Epoch: 43
Loss: 0.0855429475975806
ROC train: 0.961312	val: 0.769008	test: 0.735669
PRC train: 0.730862	val: 0.363749	test: 0.219367

Epoch: 44
Loss: 0.08473492253502202
ROC train: 0.942255	val: 0.771969	test: 0.734734
PRC train: 0.607875	val: 0.211153	test: 0.130903

Epoch: 45
Loss: 0.08553768785055411
ROC train: 0.967694	val: 0.783960	test: 0.738122
PRC train: 0.761345	val: 0.331222	test: 0.186113

Epoch: 46
Loss: 0.08390348360299157
ROC train: 0.966441	val: 0.778360	test: 0.732697
PRC train: 0.756935	val: 0.369956	test: 0.190009

Epoch: 47
Loss: 0.08450750801734994
ROC train: 0.966066	val: 0.759226	test: 0.731140
PRC train: 0.743788	val: 0.388118	test: 0.204369

Epoch: 48
Loss: 0.08098504660991204
ROC train: 0.970051	val: 0.794799	test: 0.737693
PRC train: 0.776626	val: 0.327119	test: 0.172040

Epoch: 49
Loss: 0.07893049507177245
ROC train: 0.972493	val: 0.757982	test: 0.734748
PRC train: 0.784294	val: 0.369677	test: 0.164447

Epoch: 50
Loss: 0.07676905778695237
ROC train: 0.973870	val: 0.786131	test: 0.729276
PRC train: 0.784411	val: 0.395050	test: 0.187399

Epoch: 51
Loss: 0.079116926454938
ROC train: 0.971642	val: 0.787163	test: 0.751198
PRC train: 0.786791	val: 0.357309	test: 0.196333

Epoch: 52
Loss: 0.07690816879943246
ROC train: 0.973267	val: 0.767456	test: 0.739985
PRC train: 0.792062	val: 0.371773	test: 0.135012

Epoch: 53
Loss: 0.07582934998381347
ROC train: 0.975905	val: 0.779085	test: 0.733687
PRC train: 0.798717	val: 0.336241	test: 0.156271

Epoch: 54
Loss: 0.07270181011010128
ROC train: 0.974514	val: 0.779413	test: 0.734844
PRC train: 0.776900	val: 0.360981	test: 0.209613

Epoch: 55
Loss: 0.07840326352249553
ROC train: 0.977233	val: 0.760802	test: 0.722857
PRC train: 0.810135	val: 0.350134	test: 0.178621

Epoch: 56
Loss: 0.07570854356254587
ROC train: 0.980300	val: 0.774152	test: 0.734226
PRC train: 0.829128	val: 0.342325	test: 0.157875

Epoch: 57
Loss: 0.07023005039948263
ROC train: 0.979042	val: 0.769817	test: 0.733100
PRC train: 0.816377	val: 0.321617	test: 0.184059

Epoch: 58
Loss: 0.0735612714227524
ROC train: 0.979007	val: 0.808057	test: 0.753526
PRC train: 0.823422	val: 0.336521	test: 0.195950

Epoch: 59
Loss: 0.07118851068556199
ROC train: 0.980994	val: 0.788574	test: 0.748388
PRC train: 0.828667	val: 0.375480	test: 0.216355

Epoch: 60
Loss: 0.07213557988033595
ROC train: 0.978050	val: 0.754418	test: 0.729732
PRC train: 0.821091	val: 0.335741	test: 0.174264

Epoch: 61
Loss: 0.07060360224637441
ROC train: 0.981113	val: 0.758861	test: 0.720172
PRC train: 0.842151	val: 0.333167	test: 0.190963

Epoch: 62
Loss: 0.070248401773756
ROC train: 0.982888	val: 0.796948	test: 0.737560
PRC train: 0.846954	val: 0.358096	test: 0.181918

Epoch: 63
Loss: 0.06686800297432764
ROC train: 0.985433	val: 0.769223	test: 0.740231
PRC train: 0.861718	val: 0.377843	test: 0.163891

Epoch: 64
Loss: 0.06698472240901031
ROC train: 0.985467	val: 0.758512	test: 0.706205
PRC train: 0.857270	val: 0.345337	test: 0.147808

Epoch: 65
Loss: 0.06643254316525786
ROC train: 0.987527	val: 0.771651	test: 0.722615
PRC train: 0.870764	val: 0.355313	test: 0.140560

Epoch: 66
Loss: 0.06585583845487611
ROC train: 0.986380	val: 0.789986	test: 0.746212
PRC train: 0.870184	val: 0.372570	test: 0.204032

Epoch: 67
Loss: 0.06706147105414986
ROC train: 0.985403	val: 0.780478	test: 0.727733
PRC train: 0.865549	val: 0.347032	test: 0.180292

Epoch: 68
Loss: 0.06612045962826364
ROC train: 0.988026	val: 0.786694	test: 0.724780
PRC train: 0.886267	val: 0.375062	test: 0.192834

Epoch: 69
Loss: 0.062820238621151
ROC train: 0.990212	val: 0.789404	test: 0.733029
PRC train: 0.900959	val: 0.353485	test: 0.186109

Epoch: 70
Loss: 0.06088900028940682
ROC train: 0.987893	val: 0.779731	test: 0.719073
PRC train: 0.876353	val: 0.322867	test: 0.162499

Epoch: 71
Loss: 0.061306680489589094
ROC train: 0.989569	val: 0.789477	test: 0.722470
PRC train: 0.898187	val: 0.360035	test: 0.165013

Epoch: 72
Loss: 0.0624983352687869
ROC train: 0.988128	val: 0.780359	test: 0.728201
PRC train: 0.884341	val: 0.385513	test: 0.161578

Epoch: 73
Loss: 0.06128835813524217
ROC train: 0.989920	val: 0.787864	test: 0.728562
PRC train: 0.896921	val: 0.380688	test: 0.168345

Epoch: 74
Loss: 0.060572500778382415
ROC train: 0.989428	val: 0.756182	test: 0.734331
PRC train: 0.885423	val: 0.330491	test: 0.181765

Epoch: 75
Loss: 0.0594518784928927
ROC train: 0.992091	val: 0.783188	test: 0.736513
PRC train: 0.909746	val: 0.395586	test: 0.203907

Epoch: 76
Loss: 0.05972338598341718
ROC train: 0.992911	val: 0.787490	test: 0.709927
PRC train: 0.921837	val: 0.336978	test: 0.151812

Epoch: 77
Loss: 0.05910075696974336
ROC train: 0.989667	val: 0.796621	test: 0.716868
PRC train: 0.887243	val: 0.383236	test: 0.203884

Epoch: 78
Loss: 0.058832880365265516
ROC train: 0.990053	val: 0.771345	test: 0.729242
PRC train: 0.904881	val: 0.343689	test: 0.170964

Epoch: 79
Loss: 0.055422638074823616
ROC train: 0.992393	val: 0.798761	test: 0.710056
PRC train: 0.917561	val: 0.303704	test: 0.163347

Epoch: 80
Loss: 0.05814394840137288
ROC train: 0.990738	val: 0.779823	test: 0.720228
PRC train: 0.900634	val: 0.359468	test: 0.189671

Epoch: 81
Loss: 0.05596503385339181
ROC train: 0.991165	val: 0.785518	test: 0.727285
PRC train: 0.897153	val: 0.379281	test: 0.231321

Epoch: 82
Loss: 0.0556269813410916
ROC train: 0.994161	val: 0.790237	test: 0.707897
PRC train: 0.929491	val: 0.354304	test: 0.152624

Epoch: 83
Loss: 0.0542315692991601
ROC train: 0.995026	val: 0.796388	test: 0.722969
PRC train: 0.938056	val: 0.359736	test: 0.162409

Epoch: 84
Loss: 0.05439537341626486
ROC train: 0.993576	val: 0.785797	test: 0.714091
PRC train: 0.927348	val: 0.347467	test: 0.152684

Epoch: 85
Loss: 0.051353213698387475
ROC train: 0.992351	val: 0.792037	test: 0.714448
PRC train: 0.911669	val: 0.380433	test: 0.200122

Epoch: 86
Loss: 0.054928543445788076
ROC train: 0.993115	val: 0.780129	test: 0.731799
PRC train: 0.909098	val: 0.333021	test: 0.179057

Epoch: 87
Loss: 0.0523717750518042
ROC train: 0.993935	val: 0.787870	test: 0.723612
PRC train: 0.925724	val: 0.383267	test: 0.170872

Epoch: 88
Loss: 0.05385076590856515
ROC train: 0.993064	val: 0.774119	test: 0.736509
PRC train: 0.916494	val: 0.375993	test: 0.193531

Epoch: 89
Loss: 0.051360707082332424
ROC train: 0.995833	val: 0.800225	test: 0.752923
PRC train: 0.945454	val: 0.394454	test: 0.181304

Epoch: 90
Loss: 0.049790794829546126
ROC train: 0.995725	val: 0.781173	test: 0.725564
PRC train: 0.944813	val: 0.381192	test: 0.193002

Epoch: 91
Loss: 0.051360028331752176
ROC train: 0.995079	val: 0.784165	test: 0.733395
PRC train: 0.939177	val: 0.378357	test: 0.168157

Epoch: 92
Loss: 0.05050564050993516
ROC train: 0.995578	val: 0.779906	test: 0.698866
PRC train: 0.945761	val: 0.359757	test: 0.154374

Epoch: 93
Loss: 0.048652032084150275
ROC train: 0.995191	val: 0.778078	test: 0.715825
PRC train: 0.662881	val: 0.322384	test: 0.184072

Epoch: 33
Loss: 0.10044586756922219
ROC train: 0.950332	val: 0.783148	test: 0.715417
PRC train: 0.685961	val: 0.282462	test: 0.155472

Epoch: 34
Loss: 0.09774323684960953
ROC train: 0.947941	val: 0.766057	test: 0.711918
PRC train: 0.678996	val: 0.306928	test: 0.192426

Epoch: 35
Loss: 0.09566674210604778
ROC train: 0.953614	val: 0.768509	test: 0.740908
PRC train: 0.682239	val: 0.348137	test: 0.253262

Epoch: 36
Loss: 0.09498072980164486
ROC train: 0.959208	val: 0.776893	test: 0.720922
PRC train: 0.724177	val: 0.259471	test: 0.191654

Epoch: 37
Loss: 0.09513731034710676
ROC train: 0.959135	val: 0.771084	test: 0.714749
PRC train: 0.720668	val: 0.348406	test: 0.245882

Epoch: 38
Loss: 0.09161914691071411
ROC train: 0.951638	val: 0.777208	test: 0.739054
PRC train: 0.698637	val: 0.322132	test: 0.200840

Epoch: 39
Loss: 0.09030906123779768
ROC train: 0.959851	val: 0.773485	test: 0.724073
PRC train: 0.733613	val: 0.302024	test: 0.201304

Epoch: 40
Loss: 0.08707213277427732
ROC train: 0.960486	val: 0.771764	test: 0.742683
PRC train: 0.734216	val: 0.325313	test: 0.250335

Epoch: 41
Loss: 0.08820211303250562
ROC train: 0.967590	val: 0.761008	test: 0.707113
PRC train: 0.770502	val: 0.281771	test: 0.196206

Epoch: 42
Loss: 0.08506683527217741
ROC train: 0.970337	val: 0.766182	test: 0.721675
PRC train: 0.787604	val: 0.307685	test: 0.209970

Epoch: 43
Loss: 0.08608387823079378
ROC train: 0.972691	val: 0.772574	test: 0.721580
PRC train: 0.796227	val: 0.333290	test: 0.234968

Epoch: 44
Loss: 0.08261249296046087
ROC train: 0.965243	val: 0.773494	test: 0.736662
PRC train: 0.725960	val: 0.342327	test: 0.226673

Epoch: 45
Loss: 0.08213650055821495
ROC train: 0.975994	val: 0.772049	test: 0.716916
PRC train: 0.817256	val: 0.339696	test: 0.255808

Epoch: 46
Loss: 0.08091328348832993
ROC train: 0.975407	val: 0.757226	test: 0.728272
PRC train: 0.794557	val: 0.249538	test: 0.191530

Epoch: 47
Loss: 0.08052741308837791
ROC train: 0.976511	val: 0.772591	test: 0.737507
PRC train: 0.799073	val: 0.326658	test: 0.250311

Epoch: 48
Loss: 0.07679477772370853
ROC train: 0.982910	val: 0.758990	test: 0.719784
PRC train: 0.849487	val: 0.333287	test: 0.202566

Epoch: 49
Loss: 0.07640449577593797
ROC train: 0.982932	val: 0.766972	test: 0.707190
PRC train: 0.845335	val: 0.316018	test: 0.273181

Epoch: 50
Loss: 0.07493810059839628
ROC train: 0.982199	val: 0.767707	test: 0.736837
PRC train: 0.843898	val: 0.325546	test: 0.220713

Epoch: 51
Loss: 0.07307403276901858
ROC train: 0.983872	val: 0.782965	test: 0.714216
PRC train: 0.851522	val: 0.346019	test: 0.175960

Epoch: 52
Loss: 0.07089501110455221
ROC train: 0.987097	val: 0.756516	test: 0.713990
PRC train: 0.882849	val: 0.358847	test: 0.200134

Epoch: 53
Loss: 0.07311967438511353
ROC train: 0.985543	val: 0.774566	test: 0.720091
PRC train: 0.862316	val: 0.323349	test: 0.221617

Epoch: 54
Loss: 0.0688133374939973
ROC train: 0.988447	val: 0.751583	test: 0.698629
PRC train: 0.888052	val: 0.245295	test: 0.148860

Epoch: 55
Loss: 0.06927318337752636
ROC train: 0.987111	val: 0.770806	test: 0.730402
PRC train: 0.877353	val: 0.338520	test: 0.251551

Epoch: 56
Loss: 0.0685863385356624
ROC train: 0.990397	val: 0.772058	test: 0.703260
PRC train: 0.900489	val: 0.306804	test: 0.179948

Epoch: 57
Loss: 0.06630576557645905
ROC train: 0.986291	val: 0.758347	test: 0.730464
PRC train: 0.874875	val: 0.315258	test: 0.201301

Epoch: 58
Loss: 0.068329207302618
ROC train: 0.988852	val: 0.760757	test: 0.717667
PRC train: 0.899676	val: 0.323430	test: 0.235294

Epoch: 59
Loss: 0.06437711836496911
ROC train: 0.991538	val: 0.759746	test: 0.712426
PRC train: 0.917456	val: 0.282250	test: 0.204403

Epoch: 60
Loss: 0.06284323190238307
ROC train: 0.992887	val: 0.755417	test: 0.723606
PRC train: 0.925965	val: 0.308513	test: 0.184757

Epoch: 61
Loss: 0.061710064411624056
ROC train: 0.991469	val: 0.767523	test: 0.704417
PRC train: 0.915391	val: 0.301318	test: 0.182902

Epoch: 62
Loss: 0.0604600611647159
ROC train: 0.991679	val: 0.770971	test: 0.721565
PRC train: 0.912178	val: 0.324898	test: 0.231042

Epoch: 63
Loss: 0.05985328558623794
ROC train: 0.993919	val: 0.776786	test: 0.721068
PRC train: 0.921972	val: 0.338123	test: 0.262850

Epoch: 64
Loss: 0.05902219990485298
ROC train: 0.993267	val: 0.757780	test: 0.722160
PRC train: 0.920984	val: 0.339888	test: 0.254376

Epoch: 65
Loss: 0.059052106478921285
ROC train: 0.992343	val: 0.743111	test: 0.736718
PRC train: 0.918824	val: 0.323252	test: 0.235504

Epoch: 66
Loss: 0.05462798174161899
ROC train: 0.994497	val: 0.752855	test: 0.706153
PRC train: 0.940159	val: 0.335496	test: 0.185735

Epoch: 67
Loss: 0.05760571316440814
ROC train: 0.993233	val: 0.744804	test: 0.709172
PRC train: 0.915831	val: 0.319611	test: 0.190450

Epoch: 68
Loss: 0.05486097680407962
ROC train: 0.995481	val: 0.769912	test: 0.706238
PRC train: 0.950852	val: 0.343722	test: 0.160456

Epoch: 69
Loss: 0.05294732146060696
ROC train: 0.993624	val: 0.771743	test: 0.728133
PRC train: 0.926370	val: 0.320503	test: 0.201711

Epoch: 70
Loss: 0.052235208563754305
ROC train: 0.996081	val: 0.770898	test: 0.712818
PRC train: 0.947208	val: 0.312791	test: 0.165916

Epoch: 71
Loss: 0.05352935132780961
ROC train: 0.996934	val: 0.760074	test: 0.725499
PRC train: 0.961352	val: 0.325261	test: 0.202067

Epoch: 72
Loss: 0.05112101413374281
ROC train: 0.996966	val: 0.784881	test: 0.695042
PRC train: 0.960359	val: 0.327892	test: 0.163469

Epoch: 73
Loss: 0.04859902742567525
ROC train: 0.998546	val: 0.782805	test: 0.717434
PRC train: 0.978215	val: 0.302828	test: 0.185567

Epoch: 74
Loss: 0.05112038692159564
ROC train: 0.997656	val: 0.759290	test: 0.718739
PRC train: 0.972947	val: 0.331593	test: 0.172202

Epoch: 75
Loss: 0.04860699172108994
ROC train: 0.997597	val: 0.769728	test: 0.721545
PRC train: 0.964949	val: 0.361879	test: 0.185660

Epoch: 76
Loss: 0.04686233429816062
ROC train: 0.998081	val: 0.765888	test: 0.713077
PRC train: 0.969552	val: 0.323564	test: 0.185616

Epoch: 77
Loss: 0.04631604653049637
ROC train: 0.996884	val: 0.758604	test: 0.727944
PRC train: 0.959404	val: 0.341552	test: 0.183913

Epoch: 78
Loss: 0.04848378368269585
ROC train: 0.997076	val: 0.767683	test: 0.718179
PRC train: 0.955412	val: 0.350445	test: 0.201779

Epoch: 79
Loss: 0.04328437015339896
ROC train: 0.997755	val: 0.770843	test: 0.715441
PRC train: 0.972592	val: 0.350693	test: 0.199685

Epoch: 80
Loss: 0.04447051074401254
ROC train: 0.997996	val: 0.798020	test: 0.692076
PRC train: 0.975406	val: 0.343231	test: 0.196827

Epoch: 81
Loss: 0.043092691166656524
ROC train: 0.998335	val: 0.795001	test: 0.693617
PRC train: 0.979940	val: 0.251708	test: 0.129625

Epoch: 82
Loss: 0.041965124402978504
ROC train: 0.997384	val: 0.768466	test: 0.729178
PRC train: 0.970614	val: 0.335504	test: 0.201311

Epoch: 83
Loss: 0.044247311441025665
ROC train: 0.998704	val: 0.765656	test: 0.727052
PRC train: 0.980522	val: 0.308911	test: 0.181695

Epoch: 84
Loss: 0.04215226260173402
ROC train: 0.998505	val: 0.774125	test: 0.741623
PRC train: 0.979031	val: 0.320070	test: 0.196669

Epoch: 85
Loss: 0.04114439230086168
ROC train: 0.998967	val: 0.757422	test: 0.720528
PRC train: 0.983458	val: 0.323940	test: 0.178626

Epoch: 86
Loss: 0.0425618949499917
ROC train: 0.998796	val: 0.761063	test: 0.707698
PRC train: 0.979258	val: 0.298296	test: 0.145733

Epoch: 87
Loss: 0.04134541458485026
ROC train: 0.998412	val: 0.755818	test: 0.728013
PRC train: 0.979068	val: 0.335379	test: 0.179539

Epoch: 88
Loss: 0.03939234349066465
ROC train: 0.999114	val: 0.772851	test: 0.722814
PRC train: 0.984567	val: 0.302063	test: 0.151637

Epoch: 89
Loss: 0.03789217909134723
ROC train: 0.999431	val: 0.758531	test: 0.709873
PRC train: 0.990177	val: 0.322676	test: 0.143870

Epoch: 90
Loss: 0.03812856668776808
ROC train: 0.997630	val: 0.764125	test: 0.722030
PRC train: 0.966594	val: 0.318635	test: 0.192349

Epoch: 91
Loss: 0.03711018498710519
ROC train: 0.999074	val: 0.764817	test: 0.718525
PRC train: 0.984992	val: 0.337502	test: 0.207066

Epoch: 92
Loss: 0.03749073512285872
ROC train: 0.999264	val: 0.774939	test: 0.694629
PRC train: 0.987938	val: 0.336287	test: 0.153399

Epoch: 93
Loss: 0.037355023978843424
ROC train: 0.999058	val: 0.755766	test: 0.706553
Epoch: 94
Loss: 0.07697391639717245
ROC train: 0.973726	val: 0.783718	test: 0.753454
PRC train: 0.753178	val: 0.302638	test: 0.178432

Epoch: 95
Loss: 0.07496008283594606
ROC train: 0.973399	val: 0.783020	test: 0.745096
PRC train: 0.755306	val: 0.309494	test: 0.155413

Epoch: 96
Loss: 0.07573172155843239
ROC train: 0.974948	val: 0.786140	test: 0.731990
PRC train: 0.751604	val: 0.239999	test: 0.131544

Epoch: 97
Loss: 0.07471850641968188
ROC train: 0.977585	val: 0.779388	test: 0.746212
PRC train: 0.778519	val: 0.292774	test: 0.141465

Epoch: 98
Loss: 0.07612859312113014
ROC train: 0.976831	val: 0.799129	test: 0.745735
PRC train: 0.772008	val: 0.294402	test: 0.163727

Epoch: 99
Loss: 0.07454663070829631
ROC train: 0.976650	val: 0.774428	test: 0.750264
PRC train: 0.774368	val: 0.303445	test: 0.161502

Epoch: 100
Loss: 0.07345965991204649
ROC train: 0.970791	val: 0.771746	test: 0.750009
PRC train: 0.742980	val: 0.297629	test: 0.156876

Epoch: 101
Loss: 0.07530257522146874
ROC train: 0.980434	val: 0.783828	test: 0.757280
PRC train: 0.788659	val: 0.307868	test: 0.170006

Epoch: 102
Loss: 0.07464402358191354
ROC train: 0.980249	val: 0.784814	test: 0.752023
PRC train: 0.793023	val: 0.291002	test: 0.163013

Epoch: 103
Loss: 0.07317554318369687
ROC train: 0.978184	val: 0.795347	test: 0.752218
PRC train: 0.783137	val: 0.353848	test: 0.187845

Epoch: 104
Loss: 0.07426644474161916
ROC train: 0.979312	val: 0.785932	test: 0.750121
PRC train: 0.777744	val: 0.269803	test: 0.169830

Epoch: 105
Loss: 0.07287102366381598
ROC train: 0.977982	val: 0.780748	test: 0.736505
PRC train: 0.773863	val: 0.294073	test: 0.161012

Epoch: 106
Loss: 0.0734578469715496
ROC train: 0.982987	val: 0.793632	test: 0.749064
PRC train: 0.805981	val: 0.282949	test: 0.160567

Epoch: 107
Loss: 0.07065780852580934
ROC train: 0.981186	val: 0.779018	test: 0.757029
PRC train: 0.787908	val: 0.279489	test: 0.136792

Epoch: 108
Loss: 0.07350680102504295
ROC train: 0.979314	val: 0.786192	test: 0.757421
PRC train: 0.790314	val: 0.324322	test: 0.180395

Epoch: 109
Loss: 0.07216077078281334
ROC train: 0.981654	val: 0.767839	test: 0.768553
PRC train: 0.805479	val: 0.306621	test: 0.179923

Epoch: 110
Loss: 0.07200595320852761
ROC train: 0.982673	val: 0.781789	test: 0.756320
PRC train: 0.809166	val: 0.261090	test: 0.152665

Epoch: 111
Loss: 0.07179171589551793
ROC train: 0.977484	val: 0.769434	test: 0.744910
PRC train: 0.775351	val: 0.297801	test: 0.178804

Epoch: 112
Loss: 0.07083261143221381
ROC train: 0.981970	val: 0.786024	test: 0.759760
PRC train: 0.807430	val: 0.314467	test: 0.191727

Epoch: 113
Loss: 0.07049536604650947
ROC train: 0.983677	val: 0.783099	test: 0.768715
PRC train: 0.818408	val: 0.279557	test: 0.169968

Epoch: 114
Loss: 0.07037039508341582
ROC train: 0.980452	val: 0.787649	test: 0.763313
PRC train: 0.798366	val: 0.288694	test: 0.146488

Epoch: 115
Loss: 0.06957772814667622
ROC train: 0.983419	val: 0.785071	test: 0.753854
PRC train: 0.812577	val: 0.298065	test: 0.156762

Epoch: 116
Loss: 0.06929510511242451
ROC train: 0.981861	val: 0.793516	test: 0.738378
PRC train: 0.804933	val: 0.279923	test: 0.160157

Epoch: 117
Loss: 0.06873748824708503
ROC train: 0.984679	val: 0.778314	test: 0.744549
PRC train: 0.821058	val: 0.297883	test: 0.161621

Epoch: 118
Loss: 0.07051556295841782
ROC train: 0.984607	val: 0.785420	test: 0.747766
PRC train: 0.818723	val: 0.310490	test: 0.176458

Epoch: 119
Loss: 0.06916247148139378
ROC train: 0.984001	val: 0.785292	test: 0.748421
PRC train: 0.821045	val: 0.301044	test: 0.166058

Epoch: 120
Loss: 0.06852702981924112
ROC train: 0.983891	val: 0.786244	test: 0.727926
PRC train: 0.805200	val: 0.263617	test: 0.128137

Early stopping
Best (ROC):	 train: 0.966331	val: 0.800421	test: 0.746359
Best (PRC):	 train: 0.726148	val: 0.299458	test: 0.176023


Epoch: 94
Loss: 0.07599289113832754
ROC train: 0.972959	val: 0.782184	test: 0.748502
PRC train: 0.760799	val: 0.309716	test: 0.156004

Epoch: 95
Loss: 0.07625195314569243
ROC train: 0.973209	val: 0.778347	test: 0.778364
PRC train: 0.758608	val: 0.287467	test: 0.166139

Epoch: 96
Loss: 0.07730861428694966
ROC train: 0.978935	val: 0.794468	test: 0.772605
PRC train: 0.773123	val: 0.318210	test: 0.182220

Epoch: 97
Loss: 0.07672510978967974
ROC train: 0.977810	val: 0.776333	test: 0.774300
PRC train: 0.775748	val: 0.313342	test: 0.181481

Epoch: 98
Loss: 0.07396248908007147
ROC train: 0.976309	val: 0.786630	test: 0.747017
PRC train: 0.761208	val: 0.279692	test: 0.138910

Epoch: 99
Loss: 0.0745711905326872
ROC train: 0.979511	val: 0.781844	test: 0.779057
PRC train: 0.777353	val: 0.299473	test: 0.203795

Epoch: 100
Loss: 0.07481136346812918
ROC train: 0.979546	val: 0.781474	test: 0.762711
PRC train: 0.781535	val: 0.306856	test: 0.151602

Epoch: 101
Loss: 0.0738209191502054
ROC train: 0.979650	val: 0.776250	test: 0.755345
PRC train: 0.780172	val: 0.298081	test: 0.143662

Epoch: 102
Loss: 0.07422338556262535
ROC train: 0.980625	val: 0.784796	test: 0.765760
PRC train: 0.786898	val: 0.293374	test: 0.153551

Epoch: 103
Loss: 0.07198248390375966
ROC train: 0.978883	val: 0.792389	test: 0.752174
PRC train: 0.774641	val: 0.271638	test: 0.134056

Epoch: 104
Loss: 0.07336936861445438
ROC train: 0.981172	val: 0.783559	test: 0.767473
PRC train: 0.797485	val: 0.294765	test: 0.172882

Epoch: 105
Loss: 0.07185509164626605
ROC train: 0.983586	val: 0.782230	test: 0.746250
PRC train: 0.807898	val: 0.291963	test: 0.158252

Epoch: 106
Loss: 0.07429997011826327
ROC train: 0.982039	val: 0.783736	test: 0.774248
PRC train: 0.789914	val: 0.300618	test: 0.155486

Epoch: 107
Loss: 0.07283301986352819
ROC train: 0.980594	val: 0.792898	test: 0.770494
PRC train: 0.783650	val: 0.291068	test: 0.194824

Epoch: 108
Loss: 0.07119275237894908
ROC train: 0.983399	val: 0.767900	test: 0.753792
PRC train: 0.803796	val: 0.271784	test: 0.157953

Epoch: 109
Loss: 0.07199762214200363
ROC train: 0.981328	val: 0.779241	test: 0.757369
PRC train: 0.785975	val: 0.265208	test: 0.129203

Epoch: 110
Loss: 0.07155164108683282
ROC train: 0.982636	val: 0.782365	test: 0.772255
PRC train: 0.791527	val: 0.281768	test: 0.164154

Epoch: 111
Loss: 0.07078750801037922
ROC train: 0.982356	val: 0.792751	test: 0.767522
PRC train: 0.802045	val: 0.309793	test: 0.205225

Epoch: 112
Loss: 0.07085744781833152
ROC train: 0.983514	val: 0.761791	test: 0.770673
PRC train: 0.808540	val: 0.278250	test: 0.170850

Epoch: 113
Loss: 0.07050211477584202
ROC train: 0.984600	val: 0.757140	test: 0.756959
PRC train: 0.818662	val: 0.277215	test: 0.143109

Epoch: 114
Loss: 0.06896059150416319
ROC train: 0.982911	val: 0.779465	test: 0.777883
PRC train: 0.801089	val: 0.309884	test: 0.170049

Epoch: 115
Loss: 0.07012397559171597
ROC train: 0.983191	val: 0.759069	test: 0.763358
PRC train: 0.800683	val: 0.254538	test: 0.134742

Epoch: 116
Loss: 0.06842886666507295
ROC train: 0.983565	val: 0.780090	test: 0.770295
PRC train: 0.809060	val: 0.288973	test: 0.148648

Epoch: 117
Loss: 0.06992004914656991
ROC train: 0.985588	val: 0.770913	test: 0.772974
PRC train: 0.827184	val: 0.289609	test: 0.169206

Epoch: 118
Loss: 0.06851691099487862
ROC train: 0.985825	val: 0.783657	test: 0.764545
PRC train: 0.826292	val: 0.278686	test: 0.145165

Epoch: 119
Loss: 0.06718266680146906
ROC train: 0.984710	val: 0.776366	test: 0.763856
PRC train: 0.819633	val: 0.283188	test: 0.157332

Epoch: 120
Loss: 0.0682297159285585
ROC train: 0.986067	val: 0.782622	test: 0.774459
PRC train: 0.822543	val: 0.275618	test: 0.156574

Early stopping
Best (ROC):	 train: 0.915449	val: 0.797053	test: 0.756094
Best (PRC):	 train: 0.579002	val: 0.349682	test: 0.169233

PRC train: 0.986932	val: 0.370688	test: 0.267313

Epoch: 94
Loss: 0.032498761741322484
ROC train: 0.999177	val: 0.786302	test: 0.725309
PRC train: 0.985895	val: 0.358906	test: 0.222793

Epoch: 95
Loss: 0.03461673424656101
ROC train: 0.999631	val: 0.784689	test: 0.735590
PRC train: 0.993177	val: 0.355358	test: 0.207133

Epoch: 96
Loss: 0.03568041311760258
ROC train: 0.999238	val: 0.764887	test: 0.740273
PRC train: 0.988294	val: 0.356619	test: 0.243565

Epoch: 97
Loss: 0.033991313490486175
ROC train: 0.999504	val: 0.765845	test: 0.746490
PRC train: 0.991862	val: 0.361202	test: 0.229318

Epoch: 98
Loss: 0.03239369927801416
ROC train: 0.999330	val: 0.772919	test: 0.738143
PRC train: 0.986444	val: 0.395495	test: 0.215974

Epoch: 99
Loss: 0.03526476741039001
ROC train: 0.999666	val: 0.776256	test: 0.736327
PRC train: 0.993554	val: 0.311858	test: 0.175111

Epoch: 100
Loss: 0.0325614681810226
ROC train: 0.999512	val: 0.791645	test: 0.734273
PRC train: 0.991473	val: 0.341971	test: 0.215923

Epoch: 101
Loss: 0.030961511797904018
ROC train: 0.999453	val: 0.789679	test: 0.744887
PRC train: 0.990394	val: 0.377169	test: 0.257564

Epoch: 102
Loss: 0.031415376820777115
ROC train: 0.999255	val: 0.762946	test: 0.751453
PRC train: 0.986895	val: 0.341778	test: 0.226710

Epoch: 103
Loss: 0.03247718976160192
ROC train: 0.999719	val: 0.774110	test: 0.744916
PRC train: 0.994281	val: 0.390953	test: 0.244004

Epoch: 104
Loss: 0.03272102996957623
ROC train: 0.999809	val: 0.781189	test: 0.729497
PRC train: 0.996042	val: 0.327367	test: 0.167402

Epoch: 105
Loss: 0.026522454014053197
ROC train: 0.999437	val: 0.781519	test: 0.729037
PRC train: 0.991034	val: 0.346545	test: 0.204298

Epoch: 106
Loss: 0.03115448870659255
ROC train: 0.999301	val: 0.771078	test: 0.735375
PRC train: 0.986890	val: 0.349830	test: 0.243903

Epoch: 107
Loss: 0.03063303882157564
ROC train: 0.999532	val: 0.742373	test: 0.724160
PRC train: 0.991690	val: 0.325934	test: 0.217653

Epoch: 108
Loss: 0.030907536439290388
ROC train: 0.999575	val: 0.767401	test: 0.739595
PRC train: 0.991627	val: 0.358218	test: 0.195674

Epoch: 109
Loss: 0.029354428540533287
ROC train: 0.999803	val: 0.781177	test: 0.765274
PRC train: 0.995954	val: 0.371279	test: 0.230728

Epoch: 110
Loss: 0.02525352030911743
ROC train: 0.999757	val: 0.791905	test: 0.741519
PRC train: 0.994799	val: 0.381534	test: 0.206946

Epoch: 111
Loss: 0.028121715070456774
ROC train: 0.999802	val: 0.789240	test: 0.744226
PRC train: 0.996104	val: 0.382363	test: 0.249427

Epoch: 112
Loss: 0.028637913121419382
ROC train: 0.999717	val: 0.786777	test: 0.740599
PRC train: 0.994549	val: 0.385982	test: 0.210650

Epoch: 113
Loss: 0.026594678314931133
ROC train: 0.999350	val: 0.773372	test: 0.739655
PRC train: 0.988190	val: 0.362199	test: 0.239860

Epoch: 114
Loss: 0.02920590360530011
ROC train: 0.999836	val: 0.764909	test: 0.734674
PRC train: 0.995729	val: 0.315008	test: 0.195173

Epoch: 115
Loss: 0.027296986107814555
ROC train: 0.999760	val: 0.772723	test: 0.744802
PRC train: 0.994467	val: 0.351526	test: 0.210931

Epoch: 116
Loss: 0.02671135752212803
ROC train: 0.999832	val: 0.779214	test: 0.741872
PRC train: 0.996336	val: 0.349181	test: 0.234045

Epoch: 117
Loss: 0.02684595243021571
ROC train: 0.999719	val: 0.762373	test: 0.765480
PRC train: 0.994276	val: 0.361753	test: 0.274316

Epoch: 118
Loss: 0.026487777274314728
ROC train: 0.999370	val: 0.780420	test: 0.741778
PRC train: 0.987835	val: 0.400619	test: 0.220322

Epoch: 119
Loss: 0.02805463541256811
ROC train: 0.999883	val: 0.785071	test: 0.740248
PRC train: 0.997308	val: 0.358920	test: 0.216402

Epoch: 120
Loss: 0.02821463907080209
ROC train: 0.999847	val: 0.761963	test: 0.731978
PRC train: 0.996758	val: 0.359933	test: 0.250941

Early stopping
Best (ROC):	 train: 0.998520	val: 0.795822	test: 0.765894
Best (PRC):	 train: 0.979269	val: 0.373018	test: 0.265242

PRC train: 0.968624	val: 0.285388	test: 0.183231

Epoch: 94
Loss: 0.04749462391497767
ROC train: 0.997629	val: 0.783295	test: 0.716482
PRC train: 0.964721	val: 0.345047	test: 0.193337

Epoch: 95
Loss: 0.04304215374357457
ROC train: 0.998460	val: 0.783130	test: 0.711379
PRC train: 0.975337	val: 0.320346	test: 0.143261

Epoch: 96
Loss: 0.046408124643485725
ROC train: 0.997555	val: 0.768402	test: 0.705612
PRC train: 0.969886	val: 0.369238	test: 0.156482

Epoch: 97
Loss: 0.04750625149656309
ROC train: 0.996124	val: 0.763788	test: 0.727005
PRC train: 0.952549	val: 0.306314	test: 0.134818

Epoch: 98
Loss: 0.043454284442730556
ROC train: 0.997175	val: 0.771939	test: 0.729863
PRC train: 0.958768	val: 0.333122	test: 0.149748

Epoch: 99
Loss: 0.04263130814331131
ROC train: 0.998937	val: 0.771259	test: 0.711364
PRC train: 0.980847	val: 0.336660	test: 0.129686

Epoch: 100
Loss: 0.04154470834949278
ROC train: 0.998783	val: 0.788632	test: 0.724349
PRC train: 0.977257	val: 0.329406	test: 0.139603

Epoch: 101
Loss: 0.04056068961698427
ROC train: 0.997770	val: 0.772205	test: 0.722013
PRC train: 0.968258	val: 0.325731	test: 0.185837

Epoch: 102
Loss: 0.04307060093881662
ROC train: 0.998652	val: 0.797637	test: 0.708471
PRC train: 0.978209	val: 0.281931	test: 0.117981

Epoch: 103
Loss: 0.04014316685433409
ROC train: 0.999023	val: 0.773960	test: 0.728168
PRC train: 0.982735	val: 0.322324	test: 0.134223

Epoch: 104
Loss: 0.040256642109558975
ROC train: 0.999012	val: 0.789131	test: 0.717223
PRC train: 0.983125	val: 0.339314	test: 0.119801

Epoch: 105
Loss: 0.04003213646720978
ROC train: 0.999331	val: 0.767037	test: 0.720363
PRC train: 0.986462	val: 0.314103	test: 0.180326

Epoch: 106
Loss: 0.039421765536031474
ROC train: 0.998880	val: 0.765267	test: 0.742396
PRC train: 0.980644	val: 0.343679	test: 0.207059

Epoch: 107
Loss: 0.039220813596032314
ROC train: 0.999391	val: 0.783121	test: 0.738454
PRC train: 0.988500	val: 0.276813	test: 0.142380

Epoch: 108
Loss: 0.039617461792267536
ROC train: 0.998407	val: 0.786210	test: 0.714456
PRC train: 0.976476	val: 0.323824	test: 0.125512

Epoch: 109
Loss: 0.03865025897301791
ROC train: 0.999032	val: 0.794974	test: 0.729657
PRC train: 0.983067	val: 0.332951	test: 0.153324

Epoch: 110
Loss: 0.03722237769128724
ROC train: 0.998606	val: 0.773904	test: 0.723614
PRC train: 0.976442	val: 0.360081	test: 0.182309

Epoch: 111
Loss: 0.036276171333079005
ROC train: 0.999094	val: 0.787613	test: 0.736310
PRC train: 0.983990	val: 0.346149	test: 0.183708

Epoch: 112
Loss: 0.03478102119557325
ROC train: 0.999235	val: 0.786734	test: 0.723119
PRC train: 0.986548	val: 0.335528	test: 0.179202

Epoch: 113
Loss: 0.03750308344489095
ROC train: 0.998467	val: 0.791517	test: 0.705684
PRC train: 0.975130	val: 0.303152	test: 0.167115

Epoch: 114
Loss: 0.039481874545153194
ROC train: 0.998771	val: 0.773421	test: 0.705129
PRC train: 0.979427	val: 0.322056	test: 0.150957

Epoch: 115
Loss: 0.03451005268510238
ROC train: 0.998634	val: 0.768763	test: 0.712123
PRC train: 0.977575	val: 0.347755	test: 0.175293

Epoch: 116
Loss: 0.03635152966744271
ROC train: 0.999148	val: 0.787435	test: 0.726422
PRC train: 0.985488	val: 0.301211	test: 0.178950

Epoch: 117
Loss: 0.034735654731700503
ROC train: 0.999565	val: 0.792894	test: 0.734095
PRC train: 0.991830	val: 0.316203	test: 0.161246

Epoch: 118
Loss: 0.03370302428752171
ROC train: 0.998869	val: 0.791486	test: 0.738531
PRC train: 0.977564	val: 0.332331	test: 0.167201

Epoch: 119
Loss: 0.035197629814990604
ROC train: 0.999511	val: 0.800415	test: 0.718500
PRC train: 0.991116	val: 0.329350	test: 0.130691

Epoch: 120
Loss: 0.0324572283778307
ROC train: 0.999530	val: 0.766054	test: 0.729159
PRC train: 0.991914	val: 0.313803	test: 0.163398

Early stopping
Best (ROC):	 train: 0.948387	val: 0.805966	test: 0.735750
Best (PRC):	 train: 0.688733	val: 0.365907	test: 0.192049

PRC train: 0.967233	val: 0.290140	test: 0.171589

Epoch: 94
Loss: 0.04391587944421117
ROC train: 0.997372	val: 0.762808	test: 0.723139
PRC train: 0.962939	val: 0.293845	test: 0.144073

Epoch: 95
Loss: 0.0444137304793618
ROC train: 0.997828	val: 0.765628	test: 0.742270
PRC train: 0.968351	val: 0.312610	test: 0.195146

Epoch: 96
Loss: 0.04815619150657179
ROC train: 0.997601	val: 0.746620	test: 0.721617
PRC train: 0.965602	val: 0.256504	test: 0.135195

Epoch: 97
Loss: 0.04376689268427
ROC train: 0.997459	val: 0.764223	test: 0.724413
PRC train: 0.964445	val: 0.309500	test: 0.170326

Epoch: 98
Loss: 0.046701621690711355
ROC train: 0.997301	val: 0.755857	test: 0.722088
PRC train: 0.970340	val: 0.262113	test: 0.150240

Epoch: 99
Loss: 0.041637985621050935
ROC train: 0.996781	val: 0.771185	test: 0.731364
PRC train: 0.961819	val: 0.320540	test: 0.215965

Epoch: 100
Loss: 0.04253552374725633
ROC train: 0.997868	val: 0.770867	test: 0.718262
PRC train: 0.974979	val: 0.295127	test: 0.137452

Epoch: 101
Loss: 0.0426390904114702
ROC train: 0.998748	val: 0.768173	test: 0.706777
PRC train: 0.980668	val: 0.274748	test: 0.147660

Epoch: 102
Loss: 0.03912240972892142
ROC train: 0.998211	val: 0.771461	test: 0.712895
PRC train: 0.971111	val: 0.291266	test: 0.128118

Epoch: 103
Loss: 0.0437833643365098
ROC train: 0.998046	val: 0.769841	test: 0.715972
PRC train: 0.973271	val: 0.273795	test: 0.111029

Epoch: 104
Loss: 0.04182901882316972
ROC train: 0.998145	val: 0.763861	test: 0.705317
PRC train: 0.973770	val: 0.257749	test: 0.112089

Epoch: 105
Loss: 0.039660292861381403
ROC train: 0.998625	val: 0.763123	test: 0.719006
PRC train: 0.979114	val: 0.274559	test: 0.171383

Epoch: 106
Loss: 0.04005659885938207
ROC train: 0.998824	val: 0.739807	test: 0.727496
PRC train: 0.981101	val: 0.279745	test: 0.160489

Epoch: 107
Loss: 0.0398645166462314
ROC train: 0.998662	val: 0.749868	test: 0.730816
PRC train: 0.981343	val: 0.294405	test: 0.209223

Epoch: 108
Loss: 0.03745647726316304
ROC train: 0.998818	val: 0.743230	test: 0.700070
PRC train: 0.979873	val: 0.242627	test: 0.095547

Epoch: 109
Loss: 0.03637349223380186
ROC train: 0.999030	val: 0.732397	test: 0.714938
PRC train: 0.983466	val: 0.266578	test: 0.126945

Epoch: 110
Loss: 0.03907167358585491
ROC train: 0.998416	val: 0.762808	test: 0.735918
PRC train: 0.975449	val: 0.300510	test: 0.185790

Epoch: 111
Loss: 0.03726661721769159
ROC train: 0.997890	val: 0.755585	test: 0.727760
PRC train: 0.975067	val: 0.290454	test: 0.156650

Epoch: 112
Loss: 0.0356112728772321
ROC train: 0.999043	val: 0.763344	test: 0.726984
PRC train: 0.983342	val: 0.287774	test: 0.157447

Epoch: 113
Loss: 0.03876556852425428
ROC train: 0.998786	val: 0.748592	test: 0.726040
PRC train: 0.981407	val: 0.287312	test: 0.141705

Epoch: 114
Loss: 0.0372999466529267
ROC train: 0.999371	val: 0.763035	test: 0.722472
PRC train: 0.989906	val: 0.290317	test: 0.145839

Epoch: 115
Loss: 0.0372480210166229
ROC train: 0.999144	val: 0.751026	test: 0.729147
PRC train: 0.985680	val: 0.253525	test: 0.195996

Epoch: 116
Loss: 0.03605104769016007
ROC train: 0.999154	val: 0.754792	test: 0.731084
PRC train: 0.987130	val: 0.275291	test: 0.166324

Epoch: 117
Loss: 0.03530639435198786
ROC train: 0.999107	val: 0.747952	test: 0.722395
PRC train: 0.986550	val: 0.258683	test: 0.119970

Epoch: 118
Loss: 0.03558069762199756
ROC train: 0.998867	val: 0.775974	test: 0.729085
PRC train: 0.983952	val: 0.292205	test: 0.122123

Epoch: 119
Loss: 0.0353207144445718
ROC train: 0.999169	val: 0.753775	test: 0.735429
PRC train: 0.986119	val: 0.273615	test: 0.190818

Epoch: 120
Loss: 0.03528046534245042
ROC train: 0.999036	val: 0.762312	test: 0.724070
PRC train: 0.987969	val: 0.265939	test: 0.144765

Early stopping
Best (ROC):	 train: 0.933472	val: 0.821569	test: 0.714249
Best (PRC):	 train: 0.660364	val: 0.303613	test: 0.126267

PRC train: 0.941152	val: 0.356090	test: 0.150322

Epoch: 94
Loss: 0.05048732334630281
ROC train: 0.996129	val: 0.785809	test: 0.734414
PRC train: 0.950166	val: 0.381293	test: 0.186718

Epoch: 95
Loss: 0.048786386233598746
ROC train: 0.995819	val: 0.783329	test: 0.732195
PRC train: 0.944716	val: 0.364889	test: 0.179212

Epoch: 96
Loss: 0.046386336085796114
ROC train: 0.996300	val: 0.773883	test: 0.728264
PRC train: 0.950734	val: 0.349782	test: 0.196290

Epoch: 97
Loss: 0.04748732756650549
ROC train: 0.996720	val: 0.794294	test: 0.734012
PRC train: 0.958437	val: 0.398239	test: 0.205888

Epoch: 98
Loss: 0.048032714998442194
ROC train: 0.994526	val: 0.790782	test: 0.711364
PRC train: 0.932113	val: 0.369486	test: 0.174177

Epoch: 99
Loss: 0.04738118455771911
ROC train: 0.996942	val: 0.779897	test: 0.710400
PRC train: 0.955650	val: 0.378954	test: 0.185747

Epoch: 100
Loss: 0.04524682021451396
ROC train: 0.997053	val: 0.795923	test: 0.737117
PRC train: 0.964166	val: 0.389657	test: 0.188223

Epoch: 101
Loss: 0.04585151213001382
ROC train: 0.995818	val: 0.789756	test: 0.719077
PRC train: 0.943901	val: 0.392910	test: 0.217945

Epoch: 102
Loss: 0.04709830026533714
ROC train: 0.996506	val: 0.785420	test: 0.690612
PRC train: 0.954555	val: 0.354372	test: 0.142408

Epoch: 103
Loss: 0.0460067947082968
ROC train: 0.997265	val: 0.788164	test: 0.726638
PRC train: 0.961906	val: 0.353318	test: 0.164168

Epoch: 104
Loss: 0.046168578282137565
ROC train: 0.996065	val: 0.798084	test: 0.735472
PRC train: 0.937890	val: 0.330616	test: 0.181876

Epoch: 105
Loss: 0.04266064222788992
ROC train: 0.996982	val: 0.797634	test: 0.724719
PRC train: 0.957414	val: 0.337509	test: 0.187976

Epoch: 106
Loss: 0.046325995983828215
ROC train: 0.997617	val: 0.797411	test: 0.728060
PRC train: 0.965106	val: 0.361064	test: 0.200442

Epoch: 107
Loss: 0.040750909324998974
ROC train: 0.996779	val: 0.794462	test: 0.699480
PRC train: 0.956060	val: 0.268795	test: 0.129862

Epoch: 108
Loss: 0.04512152896896776
ROC train: 0.997640	val: 0.794833	test: 0.725750
PRC train: 0.962486	val: 0.358965	test: 0.168058

Epoch: 109
Loss: 0.043261264504321835
ROC train: 0.997827	val: 0.789931	test: 0.712391
PRC train: 0.966716	val: 0.389171	test: 0.140189

Epoch: 110
Loss: 0.04345633411541413
ROC train: 0.997898	val: 0.778920	test: 0.718268
PRC train: 0.967879	val: 0.355393	test: 0.146606

Epoch: 111
Loss: 0.04041271606925081
ROC train: 0.997933	val: 0.805531	test: 0.731673
PRC train: 0.969230	val: 0.372738	test: 0.176244

Epoch: 112
Loss: 0.04205735988522521
ROC train: 0.997912	val: 0.787904	test: 0.730111
PRC train: 0.968724	val: 0.346981	test: 0.190944

Epoch: 113
Loss: 0.039482175907133245
ROC train: 0.998572	val: 0.803982	test: 0.721043
PRC train: 0.977031	val: 0.351953	test: 0.169718

Epoch: 114
Loss: 0.04201056362924382
ROC train: 0.998236	val: 0.783357	test: 0.706906
PRC train: 0.973203	val: 0.341001	test: 0.153446

Epoch: 115
Loss: 0.04154329841921062
ROC train: 0.998346	val: 0.795871	test: 0.716961
PRC train: 0.974489	val: 0.321401	test: 0.167875

Epoch: 116
Loss: 0.043178959644269606
ROC train: 0.998317	val: 0.778356	test: 0.734427
PRC train: 0.972622	val: 0.350204	test: 0.165393

Epoch: 117
Loss: 0.04066348234292483
ROC train: 0.998578	val: 0.792034	test: 0.727053
PRC train: 0.978940	val: 0.375037	test: 0.187506

Epoch: 118
Loss: 0.038761384053793035
ROC train: 0.998760	val: 0.797362	test: 0.714419
PRC train: 0.978876	val: 0.306216	test: 0.143470

Epoch: 119
Loss: 0.04138423596159553
ROC train: 0.998578	val: 0.803121	test: 0.728245
PRC train: 0.978772	val: 0.373858	test: 0.173803

Epoch: 120
Loss: 0.041728271861507904
ROC train: 0.998832	val: 0.783262	test: 0.720622
PRC train: 0.981012	val: 0.351894	test: 0.144337

Early stopping
Best (ROC):	 train: 0.979007	val: 0.808057	test: 0.753526
Best (PRC):	 train: 0.823422	val: 0.336521	test: 0.195950

PRC train: 0.982368	val: 0.315441	test: 0.158438

Epoch: 94
Loss: 0.037247327583302244
ROC train: 0.999603	val: 0.770852	test: 0.699506
PRC train: 0.992053	val: 0.317371	test: 0.135099

Epoch: 95
Loss: 0.03781696410031546
ROC train: 0.999726	val: 0.766390	test: 0.720881
PRC train: 0.995449	val: 0.315744	test: 0.196188

Epoch: 96
Loss: 0.03734386474931564
ROC train: 0.999704	val: 0.780457	test: 0.704125
PRC train: 0.994983	val: 0.360356	test: 0.182976

Epoch: 97
Loss: 0.03398747839606235
ROC train: 0.999484	val: 0.764308	test: 0.725933
PRC train: 0.991633	val: 0.372066	test: 0.219323

Epoch: 98
Loss: 0.03462985241541595
ROC train: 0.999743	val: 0.778173	test: 0.693393
PRC train: 0.995556	val: 0.331944	test: 0.145831

Epoch: 99
Loss: 0.03247071788761309
ROC train: 0.998493	val: 0.775466	test: 0.714548
PRC train: 0.975999	val: 0.343525	test: 0.199749

Epoch: 100
Loss: 0.03614552195343646
ROC train: 0.999153	val: 0.744415	test: 0.702648
PRC train: 0.987052	val: 0.354211	test: 0.141773

Epoch: 101
Loss: 0.03498876434794685
ROC train: 0.999605	val: 0.777475	test: 0.705707
PRC train: 0.993688	val: 0.346794	test: 0.167935

Epoch: 102
Loss: 0.033187931135843673
ROC train: 0.999538	val: 0.779349	test: 0.708341
PRC train: 0.992070	val: 0.323302	test: 0.140543

Epoch: 103
Loss: 0.03359952030315471
ROC train: 0.999406	val: 0.752251	test: 0.725899
PRC train: 0.989472	val: 0.330779	test: 0.178866

Epoch: 104
Loss: 0.03055639380947964
ROC train: 0.999483	val: 0.772952	test: 0.710958
PRC train: 0.991946	val: 0.285943	test: 0.135890

Epoch: 105
Loss: 0.03394785539247218
ROC train: 0.999654	val: 0.776314	test: 0.736393
PRC train: 0.994365	val: 0.327852	test: 0.180226

Epoch: 106
Loss: 0.0303825736837524
ROC train: 0.999810	val: 0.751366	test: 0.736845
PRC train: 0.996215	val: 0.301500	test: 0.161641

Epoch: 107
Loss: 0.031439894513045005
ROC train: 0.999577	val: 0.781434	test: 0.719127
PRC train: 0.992769	val: 0.310691	test: 0.156915

Epoch: 108
Loss: 0.036032120557695314
ROC train: 0.999799	val: 0.782916	test: 0.700398
PRC train: 0.996017	val: 0.319779	test: 0.149613

Epoch: 109
Loss: 0.031506503849381834
ROC train: 0.999503	val: 0.772621	test: 0.714226
PRC train: 0.991214	val: 0.332107	test: 0.202339

Epoch: 110
Loss: 0.028052119722877956
ROC train: 0.999435	val: 0.775463	test: 0.740360
PRC train: 0.991113	val: 0.358221	test: 0.213650

Epoch: 111
Loss: 0.031507663456283024
ROC train: 0.999386	val: 0.779566	test: 0.721980
PRC train: 0.989323	val: 0.337417	test: 0.204147

Epoch: 112
Loss: 0.030578546572151297
ROC train: 0.999579	val: 0.740888	test: 0.726528
PRC train: 0.994035	val: 0.343359	test: 0.172054

Epoch: 113
Loss: 0.030169915135270176
ROC train: 0.999848	val: 0.750821	test: 0.722814
PRC train: 0.996748	val: 0.325566	test: 0.215414

Epoch: 114
Loss: 0.026520597202144006
ROC train: 0.999902	val: 0.766761	test: 0.726264
PRC train: 0.997910	val: 0.345267	test: 0.193890

Epoch: 115
Loss: 0.025083684300638846
ROC train: 0.999856	val: 0.765919	test: 0.718056
PRC train: 0.997113	val: 0.299367	test: 0.181876

Epoch: 116
Loss: 0.034265127022237406
ROC train: 0.999741	val: 0.771225	test: 0.712397
PRC train: 0.994274	val: 0.278809	test: 0.176567

Epoch: 117
Loss: 0.03050257436860866
ROC train: 0.999919	val: 0.750098	test: 0.723513
PRC train: 0.998270	val: 0.313682	test: 0.179879

Epoch: 118
Loss: 0.025428061077820415
ROC train: 0.999904	val: 0.769214	test: 0.729473
PRC train: 0.997797	val: 0.296699	test: 0.188723

Epoch: 119
Loss: 0.03178056617980988
ROC train: 0.999409	val: 0.775494	test: 0.729124
PRC train: 0.989913	val: 0.324697	test: 0.178198

Epoch: 120
Loss: 0.02724515325552878
ROC train: 0.999708	val: 0.756672	test: 0.723647
PRC train: 0.995033	val: 0.322867	test: 0.177309

Early stopping
Best (ROC):	 train: 0.997996	val: 0.798020	test: 0.692076
Best (PRC):	 train: 0.975406	val: 0.343231	test: 0.196827

PRC train: 0.970300	val: 0.333996	test: 0.144455

Epoch: 94
Loss: 0.04455949403016971
ROC train: 0.998018	val: 0.794006	test: 0.699728
PRC train: 0.972475	val: 0.345567	test: 0.141800

Epoch: 95
Loss: 0.042158045208149024
ROC train: 0.997834	val: 0.798449	test: 0.709971
PRC train: 0.969441	val: 0.343989	test: 0.164597

Epoch: 96
Loss: 0.0408988354387072
ROC train: 0.998255	val: 0.791419	test: 0.729081
PRC train: 0.970607	val: 0.337123	test: 0.186279

Epoch: 97
Loss: 0.042619460916456076
ROC train: 0.997292	val: 0.789842	test: 0.718845
PRC train: 0.957339	val: 0.331124	test: 0.158645

Epoch: 98
Loss: 0.041565525895506064
ROC train: 0.997162	val: 0.783773	test: 0.720781
PRC train: 0.962752	val: 0.327706	test: 0.179000

Epoch: 99
Loss: 0.039649347949192254
ROC train: 0.998514	val: 0.787934	test: 0.723639
PRC train: 0.975336	val: 0.328195	test: 0.162923

Epoch: 100
Loss: 0.040896721309752034
ROC train: 0.998718	val: 0.798280	test: 0.712161
PRC train: 0.979052	val: 0.340610	test: 0.130951

Epoch: 101
Loss: 0.039846855060065724
ROC train: 0.998674	val: 0.787980	test: 0.733942
PRC train: 0.979958	val: 0.339327	test: 0.184155

Epoch: 102
Loss: 0.039244883288279034
ROC train: 0.998068	val: 0.781516	test: 0.730605
PRC train: 0.968870	val: 0.331352	test: 0.191503

Epoch: 103
Loss: 0.03941866128951489
ROC train: 0.998409	val: 0.781862	test: 0.712121
PRC train: 0.980520	val: 0.350139	test: 0.156024

Epoch: 104
Loss: 0.037585239833032774
ROC train: 0.998935	val: 0.797619	test: 0.718562
PRC train: 0.981304	val: 0.338442	test: 0.147656

Epoch: 105
Loss: 0.03798251526695264
ROC train: 0.998804	val: 0.789542	test: 0.710074
PRC train: 0.979683	val: 0.311685	test: 0.120683

Epoch: 106
Loss: 0.03868781622953495
ROC train: 0.998608	val: 0.793688	test: 0.700025
PRC train: 0.978091	val: 0.320100	test: 0.128374

Epoch: 107
Loss: 0.03886561453318214
ROC train: 0.998730	val: 0.789110	test: 0.704896
PRC train: 0.978878	val: 0.301051	test: 0.136587

Epoch: 108
Loss: 0.039607596963084274
ROC train: 0.999148	val: 0.791593	test: 0.724773
PRC train: 0.983651	val: 0.367556	test: 0.157698

Epoch: 109
Loss: 0.036243256415293065
ROC train: 0.998752	val: 0.810550	test: 0.712329
PRC train: 0.980732	val: 0.321405	test: 0.151734

Epoch: 110
Loss: 0.03600006264264467
ROC train: 0.998728	val: 0.804260	test: 0.717080
PRC train: 0.977752	val: 0.334852	test: 0.151348

Epoch: 111
Loss: 0.03608751042809154
ROC train: 0.998850	val: 0.797873	test: 0.709879
PRC train: 0.981833	val: 0.305056	test: 0.156434

Epoch: 112
Loss: 0.0334167733794888
ROC train: 0.998273	val: 0.781746	test: 0.708486
PRC train: 0.975111	val: 0.351098	test: 0.170860

Epoch: 113
Loss: 0.035029108658348615
ROC train: 0.999346	val: 0.802524	test: 0.729694
PRC train: 0.989942	val: 0.318709	test: 0.148124

Epoch: 114
Loss: 0.03565890255762962
ROC train: 0.998131	val: 0.785840	test: 0.703555
PRC train: 0.977611	val: 0.303430	test: 0.144134

Epoch: 115
Loss: 0.036428414874866935
ROC train: 0.999081	val: 0.801884	test: 0.707223
PRC train: 0.986289	val: 0.316099	test: 0.155954

Epoch: 116
Loss: 0.034302428391073135
ROC train: 0.999079	val: 0.792193	test: 0.719108
PRC train: 0.983716	val: 0.275855	test: 0.117256

Epoch: 117
Loss: 0.03639815350182703
ROC train: 0.999393	val: 0.797472	test: 0.722430
PRC train: 0.989121	val: 0.354059	test: 0.160280

Epoch: 118
Loss: 0.03236593261442611
ROC train: 0.998867	val: 0.791948	test: 0.717412
PRC train: 0.979839	val: 0.346320	test: 0.163649

Epoch: 119
Loss: 0.03434772918302152
ROC train: 0.999177	val: 0.801492	test: 0.725987
PRC train: 0.986454	val: 0.324262	test: 0.138312

Epoch: 120
Loss: 0.03106306414917903
ROC train: 0.999241	val: 0.791602	test: 0.709438
PRC train: 0.987565	val: 0.335836	test: 0.156271

Epoch: 121
Loss: 0.03276049344108447
ROC train: 0.999498	val: 0.806529	test: 0.710220
PRC train: 0.990519	val: 0.303391	test: 0.131126

Epoch: 122
Loss: 0.03161229901084786
ROC train: 0.999413	val: 0.797135	test: 0.728952
PRC train: 0.989403	val: 0.367016	test: 0.173079

Epoch: 123
Loss: 0.035106464053962214
ROC train: 0.999492	val: 0.805562	test: 0.731461
PRC train: 0.989593	val: 0.322798	test: 0.134638

Epoch: 124
Loss: 0.03206615956065773
ROC train: 0.999551	val: 0.803991	test: 0.723407
PRC train: 0.992221	val: 0.339462	test: 0.161859

Epoch: 125
Loss: 0.030888430499916956
ROC train: 0.999047	val: 0.789741	test: 0.707225
PRC train: 0.985219	val: 0.328074	test: 0.138912

Epoch: 126
Loss: 0.03331988080286074
ROC train: 0.999383	val: 0.801128	test: 0.725900
PRC train: 0.987848	val: 0.338108	test: 0.161770

Early stopping
Best (ROC):	 train: 0.998064	val: 0.812298	test: 0.725145
Best (PRC):	 train: 0.971309	val: 0.341723	test: 0.153156
All runs completed.

PRC train: 0.944945	val: 0.337434	test: 0.157063

Epoch: 94
Loss: 0.049977897435248865
ROC train: 0.995888	val: 0.812626	test: 0.718527
PRC train: 0.938352	val: 0.308298	test: 0.131056

Epoch: 95
Loss: 0.05079171317710185
ROC train: 0.995991	val: 0.782398	test: 0.729948
PRC train: 0.946877	val: 0.286960	test: 0.163008

Epoch: 96
Loss: 0.05049672933515581
ROC train: 0.997001	val: 0.812295	test: 0.749997
PRC train: 0.957573	val: 0.338213	test: 0.165398

Epoch: 97
Loss: 0.04742976833134507
ROC train: 0.997494	val: 0.805461	test: 0.742635
PRC train: 0.962572	val: 0.359852	test: 0.188089

Epoch: 98
Loss: 0.049540782412089215
ROC train: 0.995342	val: 0.808011	test: 0.745244
PRC train: 0.945191	val: 0.286165	test: 0.161324

Epoch: 99
Loss: 0.047579078034122826
ROC train: 0.996597	val: 0.820583	test: 0.734387
PRC train: 0.951238	val: 0.310076	test: 0.148006

Epoch: 100
Loss: 0.04776628669069721
ROC train: 0.995893	val: 0.795105	test: 0.734259
PRC train: 0.954114	val: 0.318535	test: 0.175128

Epoch: 101
Loss: 0.04733594904979965
ROC train: 0.997103	val: 0.808872	test: 0.727838
PRC train: 0.959807	val: 0.335056	test: 0.144486

Epoch: 102
Loss: 0.046224219478142536
ROC train: 0.997580	val: 0.817981	test: 0.743759
PRC train: 0.964021	val: 0.335400	test: 0.184159

Epoch: 103
Loss: 0.04762695309756759
ROC train: 0.996914	val: 0.825829	test: 0.753916
PRC train: 0.958205	val: 0.308828	test: 0.194481

Epoch: 104
Loss: 0.045620368819865136
ROC train: 0.997412	val: 0.803813	test: 0.734578
PRC train: 0.961962	val: 0.314036	test: 0.167179

Epoch: 105
Loss: 0.04423353277934522
ROC train: 0.997024	val: 0.805170	test: 0.734591
PRC train: 0.960759	val: 0.302948	test: 0.138096

Epoch: 106
Loss: 0.04523794901115174
ROC train: 0.997223	val: 0.809034	test: 0.726685
PRC train: 0.958915	val: 0.313723	test: 0.154735

Epoch: 107
Loss: 0.044409512121155355
ROC train: 0.996656	val: 0.800164	test: 0.720587
PRC train: 0.955993	val: 0.311422	test: 0.155530

Epoch: 108
Loss: 0.044982821248555814
ROC train: 0.997907	val: 0.833661	test: 0.744309
PRC train: 0.967156	val: 0.293602	test: 0.156806

Epoch: 109
Loss: 0.041846090519413265
ROC train: 0.997270	val: 0.802775	test: 0.717878
PRC train: 0.963402	val: 0.282366	test: 0.152194

Epoch: 110
Loss: 0.04353907951852451
ROC train: 0.997912	val: 0.798253	test: 0.717268
PRC train: 0.964614	val: 0.269317	test: 0.141937

Epoch: 111
Loss: 0.04476837154231427
ROC train: 0.997068	val: 0.811934	test: 0.733815
PRC train: 0.962711	val: 0.317646	test: 0.160591

Epoch: 112
Loss: 0.04233347264445559
ROC train: 0.998115	val: 0.786960	test: 0.719323
PRC train: 0.969329	val: 0.285175	test: 0.166766

Epoch: 113
Loss: 0.042639276080063314
ROC train: 0.997670	val: 0.812919	test: 0.743726
PRC train: 0.964545	val: 0.315762	test: 0.199163

Epoch: 114
Loss: 0.04399688026503366
ROC train: 0.997691	val: 0.793939	test: 0.751247
PRC train: 0.964559	val: 0.310581	test: 0.180022

Epoch: 115
Loss: 0.03845569097397391
ROC train: 0.998014	val: 0.808768	test: 0.744055
PRC train: 0.969221	val: 0.316714	test: 0.200677

Epoch: 116
Loss: 0.03992103116679707
ROC train: 0.998393	val: 0.793014	test: 0.740460
PRC train: 0.971438	val: 0.307417	test: 0.153290

Epoch: 117
Loss: 0.03975388662756306
ROC train: 0.998435	val: 0.799034	test: 0.745924
PRC train: 0.972905	val: 0.315558	test: 0.169814

Epoch: 118
Loss: 0.03974499557488853
ROC train: 0.998543	val: 0.802705	test: 0.731573
PRC train: 0.980814	val: 0.321783	test: 0.174542

Epoch: 119
Loss: 0.04155518308855996
ROC train: 0.998167	val: 0.776679	test: 0.742766
PRC train: 0.969472	val: 0.321633	test: 0.180802

Epoch: 120
Loss: 0.03792475756937827
ROC train: 0.997452	val: 0.810599	test: 0.753081
PRC train: 0.958940	val: 0.323225	test: 0.189837

Epoch: 121
Loss: 0.039797574771478585
ROC train: 0.998908	val: 0.797937	test: 0.738371
PRC train: 0.982141	val: 0.332793	test: 0.170511

Epoch: 122
Loss: 0.03906520336204896
ROC train: 0.998988	val: 0.792604	test: 0.741154
PRC train: 0.983086	val: 0.305435	test: 0.147446

Epoch: 123
Loss: 0.035985229383439184
ROC train: 0.998758	val: 0.801529	test: 0.733703
PRC train: 0.980832	val: 0.354315	test: 0.172265

Epoch: 124
Loss: 0.03850262718898294
ROC train: 0.998347	val: 0.789539	test: 0.742355
PRC train: 0.971747	val: 0.331502	test: 0.167816

Epoch: 125
Loss: 0.036710922299502846
ROC train: 0.998848	val: 0.796948	test: 0.754395
PRC train: 0.980508	val: 0.342487	test: 0.189016

Epoch: 126
Loss: 0.03791917746426152
ROC train: 0.998205	val: 0.776385	test: 0.751055
PRC train: 0.978489	val: 0.279531	test: 0.186248

Epoch: 127
Loss: 0.036901712226566026
ROC train: 0.999191	val: 0.794952	test: 0.736911
PRC train: 0.984889	val: 0.314857	test: 0.186245

Epoch: 128
Loss: 0.035617038382241825
ROC train: 0.998773	val: 0.794361	test: 0.732297
PRC train: 0.981073	val: 0.357622	test: 0.158847

Epoch: 129
Loss: 0.03710182190676202
ROC train: 0.998509	val: 0.777603	test: 0.739277
PRC train: 0.976411	val: 0.308259	test: 0.185424

Epoch: 130
Loss: 0.034883723324726654
ROC train: 0.999260	val: 0.797356	test: 0.743583
PRC train: 0.987222	val: 0.333682	test: 0.180888

Epoch: 131
Loss: 0.034398508178104185
ROC train: 0.998133	val: 0.794980	test: 0.723000
PRC train: 0.971161	val: 0.385067	test: 0.188165

Epoch: 132
Loss: 0.036569193341668034
ROC train: 0.998630	val: 0.789830	test: 0.730201
PRC train: 0.976142	val: 0.251929	test: 0.147776

Epoch: 133
Loss: 0.03718927729485984
ROC train: 0.998562	val: 0.785874	test: 0.733079
PRC train: 0.977753	val: 0.319308	test: 0.166927

Epoch: 134
Loss: 0.033565196166823304
ROC train: 0.999424	val: 0.802892	test: 0.747006
PRC train: 0.989482	val: 0.297047	test: 0.187185

Epoch: 135
Loss: 0.03283515794284618
ROC train: 0.998903	val: 0.783049	test: 0.739495
PRC train: 0.981267	val: 0.303759	test: 0.196376

Epoch: 136
Loss: 0.036423568216305914
ROC train: 0.999200	val: 0.790225	test: 0.721949
PRC train: 0.986112	val: 0.300083	test: 0.161426

Epoch: 137
Loss: 0.03385869746039907
ROC train: 0.999477	val: 0.804493	test: 0.736524
PRC train: 0.989643	val: 0.293519	test: 0.183995

Epoch: 138
Loss: 0.034183293138876976
ROC train: 0.999344	val: 0.804116	test: 0.730236
PRC train: 0.987367	val: 0.307114	test: 0.174320

Epoch: 139
Loss: 0.033737512165798025
ROC train: 0.999166	val: 0.813057	test: 0.727225
PRC train: 0.983975	val: 0.341243	test: 0.170686

Epoch: 140
Loss: 0.033377566427239685
ROC train: 0.998016	val: 0.805004	test: 0.739674
PRC train: 0.978453	val: 0.323301	test: 0.184593

Epoch: 141
Loss: 0.033456327173798844
ROC train: 0.999425	val: 0.795090	test: 0.738102
PRC train: 0.988494	val: 0.309287	test: 0.171109

Epoch: 142
Loss: 0.034122551083100104
ROC train: 0.999640	val: 0.800874	test: 0.717584
PRC train: 0.992787	val: 0.346300	test: 0.168705

Epoch: 143
Loss: 0.03248908446121611
ROC train: 0.999647	val: 0.808948	test: 0.726472
PRC train: 0.992740	val: 0.275797	test: 0.187828

Early stopping
Best (ROC):	 train: 0.997907	val: 0.833661	test: 0.744309
Best (PRC):	 train: 0.967156	val: 0.293602	test: 0.156806

PRC train: 0.942370	val: 0.334792	test: 0.172689

Epoch: 94
Loss: 0.05341991500276791
ROC train: 0.995195	val: 0.818878	test: 0.762764
PRC train: 0.937052	val: 0.368057	test: 0.163901

Epoch: 95
Loss: 0.052843349861136264
ROC train: 0.994777	val: 0.814374	test: 0.758367
PRC train: 0.931240	val: 0.376231	test: 0.176527

Epoch: 96
Loss: 0.053026343668874584
ROC train: 0.992963	val: 0.793596	test: 0.756965
PRC train: 0.919348	val: 0.341789	test: 0.158761

Epoch: 97
Loss: 0.052210060067977196
ROC train: 0.995035	val: 0.806220	test: 0.748676
PRC train: 0.938161	val: 0.384977	test: 0.180640

Epoch: 98
Loss: 0.049011820171785174
ROC train: 0.996417	val: 0.825939	test: 0.765380
PRC train: 0.943575	val: 0.383240	test: 0.143543

Epoch: 99
Loss: 0.05412585978493526
ROC train: 0.995604	val: 0.814071	test: 0.757956
PRC train: 0.943101	val: 0.376974	test: 0.177344

Epoch: 100
Loss: 0.047931295256361285
ROC train: 0.995492	val: 0.816710	test: 0.771351
PRC train: 0.938920	val: 0.364043	test: 0.157150

Epoch: 101
Loss: 0.04882346931063868
ROC train: 0.995837	val: 0.819898	test: 0.779181
PRC train: 0.943748	val: 0.381614	test: 0.177322

Epoch: 102
Loss: 0.04848767595053499
ROC train: 0.995526	val: 0.812910	test: 0.777367
PRC train: 0.934245	val: 0.331306	test: 0.192194

Epoch: 103
Loss: 0.05102981726767608
ROC train: 0.995981	val: 0.819463	test: 0.763655
PRC train: 0.944300	val: 0.386612	test: 0.187255

Epoch: 104
Loss: 0.04676754046247048
ROC train: 0.996601	val: 0.824227	test: 0.754835
PRC train: 0.952912	val: 0.387442	test: 0.171031

Epoch: 105
Loss: 0.04795836416446636
ROC train: 0.996299	val: 0.819414	test: 0.766031
PRC train: 0.946638	val: 0.339631	test: 0.171963

Epoch: 106
Loss: 0.05043872032149924
ROC train: 0.997515	val: 0.810580	test: 0.755808
PRC train: 0.960151	val: 0.336489	test: 0.151513

Epoch: 107
Loss: 0.04583122734879921
ROC train: 0.997268	val: 0.815084	test: 0.745986
PRC train: 0.959747	val: 0.322921	test: 0.137786

Epoch: 108
Loss: 0.04728628351411951
ROC train: 0.997705	val: 0.818927	test: 0.750461
PRC train: 0.962720	val: 0.383569	test: 0.123905

Epoch: 109
Loss: 0.04600112663473441
ROC train: 0.997751	val: 0.823290	test: 0.780235
PRC train: 0.967275	val: 0.358109	test: 0.184400

Epoch: 110
Loss: 0.04467806998028306
ROC train: 0.998180	val: 0.833881	test: 0.766780
PRC train: 0.970457	val: 0.391074	test: 0.186051

Epoch: 111
Loss: 0.043535065830288745
ROC train: 0.998169	val: 0.810886	test: 0.757821
PRC train: 0.968430	val: 0.337072	test: 0.197582

Epoch: 112
Loss: 0.04541784033088717
ROC train: 0.997141	val: 0.816110	test: 0.762377
PRC train: 0.958808	val: 0.372741	test: 0.178326

Epoch: 113
Loss: 0.04437999120427183
ROC train: 0.997138	val: 0.819567	test: 0.745978
PRC train: 0.955569	val: 0.318887	test: 0.141221

Epoch: 114
Loss: 0.044651784316872535
ROC train: 0.997556	val: 0.844858	test: 0.756517
PRC train: 0.961329	val: 0.380624	test: 0.171963

Epoch: 115
Loss: 0.04527220565349984
ROC train: 0.997917	val: 0.831689	test: 0.738512
PRC train: 0.967671	val: 0.341798	test: 0.122036

Epoch: 116
Loss: 0.040245431690347805
ROC train: 0.998409	val: 0.813532	test: 0.755428
PRC train: 0.972374	val: 0.317806	test: 0.134286

Epoch: 117
Loss: 0.043329952767884365
ROC train: 0.998384	val: 0.819674	test: 0.746386
PRC train: 0.971380	val: 0.388114	test: 0.139220

Epoch: 118
Loss: 0.04100519271432846
ROC train: 0.998248	val: 0.818553	test: 0.756086
PRC train: 0.972140	val: 0.345983	test: 0.138198

Epoch: 119
Loss: 0.041318477928557876
ROC train: 0.998745	val: 0.818091	test: 0.755886
PRC train: 0.975920	val: 0.365057	test: 0.166268

Epoch: 120
Loss: 0.03921426704678939
ROC train: 0.998150	val: 0.818189	test: 0.755179
PRC train: 0.969003	val: 0.379748	test: 0.169128

Epoch: 121
Loss: 0.04076306624045048
ROC train: 0.998682	val: 0.819594	test: 0.738998
PRC train: 0.977239	val: 0.339101	test: 0.150344

Epoch: 122
Loss: 0.04320829419970193
ROC train: 0.997765	val: 0.832785	test: 0.785054
PRC train: 0.960399	val: 0.373500	test: 0.185490

Epoch: 123
Loss: 0.039772698342264025
ROC train: 0.998229	val: 0.831426	test: 0.768199
PRC train: 0.971645	val: 0.368203	test: 0.155305

Epoch: 124
Loss: 0.04048695185248877
ROC train: 0.998959	val: 0.838208	test: 0.756824
PRC train: 0.980432	val: 0.346844	test: 0.145496

Epoch: 125
Loss: 0.041186048184862226
ROC train: 0.998901	val: 0.831254	test: 0.771853
PRC train: 0.980169	val: 0.365880	test: 0.164401

Epoch: 126
Loss: 0.03884523904866108
ROC train: 0.997893	val: 0.814138	test: 0.740652
PRC train: 0.964639	val: 0.343639	test: 0.125818

Epoch: 127
Loss: 0.03852566037728987
ROC train: 0.998520	val: 0.814913	test: 0.756245
PRC train: 0.975323	val: 0.360068	test: 0.157774

Epoch: 128
Loss: 0.04165078015778845
ROC train: 0.998032	val: 0.817421	test: 0.752064
PRC train: 0.967055	val: 0.356247	test: 0.142826

Epoch: 129
Loss: 0.0393110634889787
ROC train: 0.998421	val: 0.833459	test: 0.745179
PRC train: 0.975174	val: 0.336985	test: 0.132986

Epoch: 130
Loss: 0.03841335727933255
ROC train: 0.998493	val: 0.818553	test: 0.734976
PRC train: 0.976053	val: 0.339972	test: 0.129859

Epoch: 131
Loss: 0.040944068169155315
ROC train: 0.998975	val: 0.828162	test: 0.768779
PRC train: 0.980819	val: 0.383270	test: 0.141443

Epoch: 132
Loss: 0.03969996352905254
ROC train: 0.998668	val: 0.820568	test: 0.763690
PRC train: 0.976839	val: 0.385111	test: 0.150782

Epoch: 133
Loss: 0.037032197029123984
ROC train: 0.999126	val: 0.819794	test: 0.762751
PRC train: 0.983169	val: 0.374559	test: 0.136553

Epoch: 134
Loss: 0.03967575344497001
ROC train: 0.998967	val: 0.828437	test: 0.766400
PRC train: 0.981712	val: 0.373849	test: 0.153890

Epoch: 135
Loss: 0.03438616356452827
ROC train: 0.998838	val: 0.807549	test: 0.783182
PRC train: 0.979901	val: 0.359770	test: 0.192470

Epoch: 136
Loss: 0.03252955022046511
ROC train: 0.999187	val: 0.818483	test: 0.754068
PRC train: 0.984466	val: 0.371307	test: 0.158602

Epoch: 137
Loss: 0.03664642496524585
ROC train: 0.999088	val: 0.814313	test: 0.753435
PRC train: 0.983986	val: 0.320825	test: 0.161661

Epoch: 138
Loss: 0.03778478921131879
ROC train: 0.998175	val: 0.818685	test: 0.749736
PRC train: 0.969005	val: 0.345454	test: 0.171385

Epoch: 139
Loss: 0.03709464361247258
ROC train: 0.998344	val: 0.806940	test: 0.777070
PRC train: 0.973818	val: 0.347811	test: 0.176547

Epoch: 140
Loss: 0.03527543937810025
ROC train: 0.999446	val: 0.823982	test: 0.771019
PRC train: 0.989022	val: 0.345954	test: 0.171568

Epoch: 141
Loss: 0.03219855219211674
ROC train: 0.999473	val: 0.813014	test: 0.778068
PRC train: 0.990043	val: 0.340511	test: 0.166105

Epoch: 142
Loss: 0.03557115967256043
ROC train: 0.999254	val: 0.810586	test: 0.761861
PRC train: 0.987262	val: 0.359117	test: 0.165708

Epoch: 143
Loss: 0.034879170719750684
ROC train: 0.999462	val: 0.811508	test: 0.770260
PRC train: 0.989789	val: 0.330615	test: 0.184994

Epoch: 144
Loss: 0.035206347420168475
ROC train: 0.999069	val: 0.803118	test: 0.770446
PRC train: 0.982177	val: 0.370095	test: 0.186201

Epoch: 145
Loss: 0.033682988641132734
ROC train: 0.999489	val: 0.822724	test: 0.769582
PRC train: 0.989169	val: 0.379838	test: 0.160527

Epoch: 146
Loss: 0.03523259737973482
ROC train: 0.999134	val: 0.812972	test: 0.776415
PRC train: 0.985220	val: 0.349983	test: 0.183610

Epoch: 147
Loss: 0.031679210603716146
ROC train: 0.999483	val: 0.809806	test: 0.768095
PRC train: 0.989403	val: 0.362375	test: 0.169839

Epoch: 148
Loss: 0.03134174240159287
ROC train: 0.999437	val: 0.808703	test: 0.761869
PRC train: 0.987876	val: 0.319087	test: 0.143742

Epoch: 149
Loss: 0.0328287826348756
ROC train: 0.999598	val: 0.807286	test: 0.756171
PRC train: 0.991412	val: 0.300088	test: 0.151181

Early stopping
Best (ROC):	 train: 0.997556	val: 0.844858	test: 0.756517
Best (PRC):	 train: 0.961329	val: 0.380624	test: 0.171963
All runs completed.

ROC train: 0.973073	val: 0.810081	test: 0.743448
PRC train: 0.749764	val: 0.341797	test: 0.167692

Epoch: 95
Loss: 0.076691442338024
ROC train: 0.975904	val: 0.786976	test: 0.748869
PRC train: 0.765128	val: 0.318430	test: 0.187717

Epoch: 96
Loss: 0.07743389460304356
ROC train: 0.972752	val: 0.775334	test: 0.748384
PRC train: 0.736356	val: 0.303909	test: 0.187685

Epoch: 97
Loss: 0.07587796089540474
ROC train: 0.977175	val: 0.788047	test: 0.732859
PRC train: 0.767952	val: 0.317727	test: 0.139999

Epoch: 98
Loss: 0.0758133249858692
ROC train: 0.977017	val: 0.789581	test: 0.733666
PRC train: 0.777211	val: 0.310391	test: 0.170488

Epoch: 99
Loss: 0.07529567656400789
ROC train: 0.975059	val: 0.790589	test: 0.736364
PRC train: 0.753784	val: 0.290484	test: 0.156453

Epoch: 100
Loss: 0.07527543060820274
ROC train: 0.977973	val: 0.792552	test: 0.759159
PRC train: 0.775722	val: 0.335472	test: 0.199095

Epoch: 101
Loss: 0.07416507783908803
ROC train: 0.979749	val: 0.795424	test: 0.748035
PRC train: 0.791195	val: 0.327133	test: 0.179647

Epoch: 102
Loss: 0.07253930028366158
ROC train: 0.978028	val: 0.798192	test: 0.736864
PRC train: 0.776321	val: 0.281749	test: 0.163275

Epoch: 103
Loss: 0.07199032481500243
ROC train: 0.980411	val: 0.784205	test: 0.738977
PRC train: 0.787753	val: 0.313086	test: 0.186566

Epoch: 104
Loss: 0.07386542842351733
ROC train: 0.978414	val: 0.798580	test: 0.751240
PRC train: 0.780947	val: 0.318092	test: 0.208455

Epoch: 105
Loss: 0.07286161164716466
ROC train: 0.979747	val: 0.801388	test: 0.734392
PRC train: 0.786626	val: 0.284173	test: 0.127558

Epoch: 106
Loss: 0.07299342218780301
ROC train: 0.979453	val: 0.797662	test: 0.750492
PRC train: 0.785644	val: 0.301185	test: 0.193633

Epoch: 107
Loss: 0.07196249693461194
ROC train: 0.981523	val: 0.800066	test: 0.747869
PRC train: 0.801283	val: 0.324147	test: 0.177770

Epoch: 108
Loss: 0.07281950760168725
ROC train: 0.981553	val: 0.799842	test: 0.762807
PRC train: 0.796103	val: 0.313910	test: 0.167306

Epoch: 109
Loss: 0.07204037018702411
ROC train: 0.982134	val: 0.808807	test: 0.754702
PRC train: 0.801668	val: 0.302248	test: 0.153899

Epoch: 110
Loss: 0.07051609075729366
ROC train: 0.980661	val: 0.792861	test: 0.752021
PRC train: 0.793959	val: 0.282666	test: 0.188029

Epoch: 111
Loss: 0.07044337088563103
ROC train: 0.981692	val: 0.802218	test: 0.748933
PRC train: 0.797322	val: 0.293032	test: 0.188404

Epoch: 112
Loss: 0.07102132289649662
ROC train: 0.980122	val: 0.821530	test: 0.737629
PRC train: 0.784456	val: 0.316565	test: 0.171812

Epoch: 113
Loss: 0.07169683272332598
ROC train: 0.983203	val: 0.814711	test: 0.754680
PRC train: 0.807710	val: 0.264559	test: 0.177756

Epoch: 114
Loss: 0.07011769256225563
ROC train: 0.983984	val: 0.809683	test: 0.744684
PRC train: 0.807543	val: 0.317609	test: 0.175620

Epoch: 115
Loss: 0.07171900946824408
ROC train: 0.982210	val: 0.810929	test: 0.754026
PRC train: 0.804480	val: 0.297117	test: 0.178232

Epoch: 116
Loss: 0.07001799311924596
ROC train: 0.983685	val: 0.823162	test: 0.751222
PRC train: 0.817465	val: 0.289461	test: 0.158377

Epoch: 117
Loss: 0.06888059398360376
ROC train: 0.984988	val: 0.814371	test: 0.746011
PRC train: 0.820956	val: 0.320624	test: 0.178407

Epoch: 118
Loss: 0.0685533072219614
ROC train: 0.983160	val: 0.807001	test: 0.760922
PRC train: 0.802255	val: 0.296493	test: 0.183593

Epoch: 119
Loss: 0.0690504628606005
ROC train: 0.983384	val: 0.795166	test: 0.765969
PRC train: 0.810179	val: 0.335208	test: 0.188703

Epoch: 120
Loss: 0.06892903039128861
ROC train: 0.983361	val: 0.800059	test: 0.755219
PRC train: 0.808475	val: 0.290657	test: 0.152254

Epoch: 121
Loss: 0.06697391976621626
ROC train: 0.983872	val: 0.803887	test: 0.752519
PRC train: 0.805404	val: 0.320541	test: 0.172832

Epoch: 122
Loss: 0.06662066131751167
ROC train: 0.986669	val: 0.809610	test: 0.746187
PRC train: 0.829646	val: 0.312965	test: 0.187421

Epoch: 123
Loss: 0.06854558756892858
ROC train: 0.984816	val: 0.811888	test: 0.750676
PRC train: 0.817391	val: 0.332484	test: 0.150932

Epoch: 124
Loss: 0.06750860681824532
ROC train: 0.986015	val: 0.813811	test: 0.738857
PRC train: 0.824258	val: 0.295142	test: 0.170595

Epoch: 125
Loss: 0.06630152883261231
ROC train: 0.984938	val: 0.804609	test: 0.753358
PRC train: 0.816282	val: 0.309936	test: 0.166185

Epoch: 126
Loss: 0.06705101232281735
ROC train: 0.983047	val: 0.804211	test: 0.752722
PRC train: 0.806519	val: 0.296939	test: 0.165018

Epoch: 127
Loss: 0.06758118221083438
ROC train: 0.985789	val: 0.801250	test: 0.734186
PRC train: 0.823261	val: 0.307793	test: 0.172432

Epoch: 128
Loss: 0.06616917725061902
ROC train: 0.987364	val: 0.788246	test: 0.736105
PRC train: 0.835939	val: 0.295577	test: 0.157415

Epoch: 129
Loss: 0.06614403402543906
ROC train: 0.986073	val: 0.801388	test: 0.733838
PRC train: 0.822407	val: 0.286357	test: 0.153625

Epoch: 130
Loss: 0.06581822879497651
ROC train: 0.987736	val: 0.807564	test: 0.734883
PRC train: 0.840736	val: 0.291378	test: 0.143924

Epoch: 131
Loss: 0.06433845099168556
ROC train: 0.986845	val: 0.805690	test: 0.747558
PRC train: 0.836731	val: 0.334834	test: 0.190090

Epoch: 132
Loss: 0.06556045169733006
ROC train: 0.986738	val: 0.792922	test: 0.733850
PRC train: 0.834047	val: 0.282619	test: 0.150295

Epoch: 133
Loss: 0.06639884656990934
ROC train: 0.987615	val: 0.803522	test: 0.747875
PRC train: 0.841167	val: 0.312400	test: 0.190001

Epoch: 134
Loss: 0.06699483088454501
ROC train: 0.986106	val: 0.810029	test: 0.731864
PRC train: 0.828706	val: 0.312659	test: 0.180062

Epoch: 135
Loss: 0.0660402829597694
ROC train: 0.985973	val: 0.802129	test: 0.737923
PRC train: 0.831387	val: 0.330641	test: 0.171916

Epoch: 136
Loss: 0.06463393599537276
ROC train: 0.987905	val: 0.810164	test: 0.737815
PRC train: 0.843900	val: 0.282538	test: 0.172516

Epoch: 137
Loss: 0.062235054768740375
ROC train: 0.988903	val: 0.803195	test: 0.743672
PRC train: 0.851753	val: 0.302157	test: 0.189514

Epoch: 138
Loss: 0.06285563499420438
ROC train: 0.989327	val: 0.806845	test: 0.747994
PRC train: 0.849637	val: 0.316725	test: 0.198637

Epoch: 139
Loss: 0.06287574811095668
ROC train: 0.988966	val: 0.796967	test: 0.755030
PRC train: 0.855599	val: 0.299514	test: 0.155432

Epoch: 140
Loss: 0.06353062951207093
ROC train: 0.988825	val: 0.808409	test: 0.744825
PRC train: 0.852178	val: 0.304466	test: 0.146907

Epoch: 141
Loss: 0.06576839041542752
ROC train: 0.989019	val: 0.795929	test: 0.756652
PRC train: 0.850261	val: 0.300757	test: 0.199664

Epoch: 142
Loss: 0.06432562780903532
ROC train: 0.988672	val: 0.807148	test: 0.743543
PRC train: 0.846931	val: 0.304701	test: 0.181501

Epoch: 143
Loss: 0.06172589670961719
ROC train: 0.989538	val: 0.817427	test: 0.763253
PRC train: 0.854767	val: 0.344181	test: 0.221399

Epoch: 144
Loss: 0.062154523692669904
ROC train: 0.987751	val: 0.809888	test: 0.756619
PRC train: 0.835493	val: 0.305763	test: 0.193840

Epoch: 145
Loss: 0.06241249594750283
ROC train: 0.989000	val: 0.805246	test: 0.742197
PRC train: 0.850822	val: 0.287499	test: 0.162512

Epoch: 146
Loss: 0.06262373257490052
ROC train: 0.990797	val: 0.806437	test: 0.755387
PRC train: 0.869200	val: 0.326452	test: 0.186636

Epoch: 147
Loss: 0.060638050621939436
ROC train: 0.990100	val: 0.820972	test: 0.757616
PRC train: 0.861787	val: 0.289602	test: 0.159478

Epoch: 148
Loss: 0.06119745086884861
ROC train: 0.989112	val: 0.815286	test: 0.733096
PRC train: 0.851442	val: 0.286363	test: 0.155453

Epoch: 149
Loss: 0.061541882502901456
ROC train: 0.990364	val: 0.812534	test: 0.730037
PRC train: 0.863755	val: 0.333452	test: 0.151811

Epoch: 150
Loss: 0.06101258950562632
ROC train: 0.989566	val: 0.826839	test: 0.715383
PRC train: 0.859541	val: 0.319777	test: 0.155203

Epoch: 151
Loss: 0.06123417058780464
ROC train: 0.989548	val: 0.825339	test: 0.748520
PRC train: 0.857998	val: 0.351899	test: 0.169300

Epoch: 152
Loss: 0.061642579277058275
ROC train: 0.990334	val: 0.807763	test: 0.732366
PRC train: 0.862408	val: 0.308749	test: 0.165883

Epoch: 153
Loss: 0.06055810798642242
ROC train: 0.991313	val: 0.801728	test: 0.730084
PRC train: 0.871053	val: 0.302338	test: 0.157537

Epoch: 154
Loss: 0.0604665193715778
ROC train: 0.990588	val: 0.804854	test: 0.729184ROC train: 0.999663	val: 0.787607	test: 0.715798
PRC train: 0.994557	val: 0.227794	test: 0.130093

Epoch: 94
Loss: 0.0347461104063161
ROC train: 0.999379	val: 0.795261	test: 0.706889
PRC train: 0.989653	val: 0.342065	test: 0.193854

Epoch: 95
Loss: 0.032470464132125974
ROC train: 0.999728	val: 0.807356	test: 0.742177
PRC train: 0.995381	val: 0.303608	test: 0.179655

Epoch: 96
Loss: 0.03659632888196681
ROC train: 0.999726	val: 0.796921	test: 0.733405
PRC train: 0.995257	val: 0.297669	test: 0.169434

Epoch: 97
Loss: 0.03423708386196534
ROC train: 0.999644	val: 0.811891	test: 0.717424
PRC train: 0.993731	val: 0.315768	test: 0.157879

Epoch: 98
Loss: 0.03201470831760636
ROC train: 0.999697	val: 0.806355	test: 0.736704
PRC train: 0.994224	val: 0.297971	test: 0.172714

Epoch: 99
Loss: 0.03258010554106274
ROC train: 0.999249	val: 0.785555	test: 0.724705
PRC train: 0.987271	val: 0.283995	test: 0.151216

Epoch: 100
Loss: 0.030834108438931373
ROC train: 0.999882	val: 0.799055	test: 0.705004
PRC train: 0.997572	val: 0.290820	test: 0.099986

Epoch: 101
Loss: 0.0328802900147932
ROC train: 0.999728	val: 0.795757	test: 0.745103
PRC train: 0.994603	val: 0.289014	test: 0.162604

Epoch: 102
Loss: 0.031323222767847665
ROC train: 0.999743	val: 0.795485	test: 0.734823
PRC train: 0.994752	val: 0.326003	test: 0.159996

Epoch: 103
Loss: 0.03191133756442723
ROC train: 0.999782	val: 0.803219	test: 0.727415
PRC train: 0.995932	val: 0.281234	test: 0.145244

Epoch: 104
Loss: 0.03212059265522485
ROC train: 0.999735	val: 0.802683	test: 0.742537
PRC train: 0.994286	val: 0.343621	test: 0.184865

Epoch: 105
Loss: 0.031054467177843215
ROC train: 0.999802	val: 0.796639	test: 0.738481
PRC train: 0.995404	val: 0.268013	test: 0.171745

Epoch: 106
Loss: 0.02943334593810921
ROC train: 0.999847	val: 0.788259	test: 0.725617
PRC train: 0.997322	val: 0.228959	test: 0.134512

Epoch: 107
Loss: 0.028963858167618522
ROC train: 0.999872	val: 0.783378	test: 0.719491
PRC train: 0.997512	val: 0.274287	test: 0.131315

Epoch: 108
Loss: 0.030210803051108088
ROC train: 0.999736	val: 0.780766	test: 0.722318
PRC train: 0.996045	val: 0.305255	test: 0.156211

Epoch: 109
Loss: 0.026963510270920508
ROC train: 0.999944	val: 0.799328	test: 0.738037
PRC train: 0.998853	val: 0.278039	test: 0.175310

Epoch: 110
Loss: 0.027842773556322274
ROC train: 0.999847	val: 0.785028	test: 0.733021
PRC train: 0.996650	val: 0.322968	test: 0.185195

Epoch: 111
Loss: 0.030869330746564488
ROC train: 0.999805	val: 0.804560	test: 0.753966
PRC train: 0.996354	val: 0.346976	test: 0.252021

Epoch: 112
Loss: 0.029102900937145678
ROC train: 0.999866	val: 0.812068	test: 0.729626
PRC train: 0.997235	val: 0.314294	test: 0.203819

Epoch: 113
Loss: 0.029914765937053174
ROC train: 0.999794	val: 0.817947	test: 0.722262
PRC train: 0.996519	val: 0.332378	test: 0.194510

Epoch: 114
Loss: 0.028819375700035035
ROC train: 0.999677	val: 0.808428	test: 0.733102
PRC train: 0.993827	val: 0.307149	test: 0.176365

Epoch: 115
Loss: 0.03009398579850733
ROC train: 0.999922	val: 0.803721	test: 0.736532
PRC train: 0.998128	val: 0.279167	test: 0.170774

Epoch: 116
Loss: 0.02707087969962839
ROC train: 0.999913	val: 0.798626	test: 0.739703
PRC train: 0.998106	val: 0.321705	test: 0.222241

Epoch: 117
Loss: 0.02560146110646593
ROC train: 0.999925	val: 0.788580	test: 0.734396
PRC train: 0.998142	val: 0.320671	test: 0.186521

Epoch: 118
Loss: 0.02467659522990609
ROC train: 0.999817	val: 0.780711	test: 0.730578
PRC train: 0.996163	val: 0.308756	test: 0.204446

Epoch: 119
Loss: 0.02738469176409349
ROC train: 0.999970	val: 0.807705	test: 0.753087
PRC train: 0.999292	val: 0.304847	test: 0.195248

Epoch: 120
Loss: 0.02302578995877534
ROC train: 0.999912	val: 0.821585	test: 0.730070
PRC train: 0.998088	val: 0.327077	test: 0.186937

Epoch: 121
Loss: 0.031119330112787974
ROC train: 0.999849	val: 0.772551	test: 0.724914
PRC train: 0.996703	val: 0.275833	test: 0.192926

Epoch: 122
Loss: 0.02831119531486871
ROC train: 0.999792	val: 0.792947	test: 0.729479
PRC train: 0.995189	val: 0.313147	test: 0.206831

Epoch: 123
Loss: 0.025499395042698082
ROC train: 0.999952	val: 0.804784	test: 0.741909
PRC train: 0.998917	val: 0.305384	test: 0.187013

Epoch: 124
Loss: 0.024931847973618252
ROC train: 0.999920	val: 0.820479	test: 0.739752
PRC train: 0.998155	val: 0.337625	test: 0.191555

Epoch: 125
Loss: 0.025132520121113125
ROC train: 0.999173	val: 0.806098	test: 0.740012
PRC train: 0.997491	val: 0.312661	test: 0.183928

Epoch: 126
Loss: 0.0270104645683012
ROC train: 0.999889	val: 0.801195	test: 0.716443
PRC train: 0.997226	val: 0.296794	test: 0.165907

Epoch: 127
Loss: 0.024228100087283835
ROC train: 0.999981	val: 0.811413	test: 0.737585
PRC train: 0.999534	val: 0.352055	test: 0.180415

Epoch: 128
Loss: 0.024938821324584727
ROC train: 0.999939	val: 0.800461	test: 0.730242
PRC train: 0.998514	val: 0.297502	test: 0.145601

Epoch: 129
Loss: 0.023183944938212697
ROC train: 0.999807	val: 0.795828	test: 0.727828
PRC train: 0.996269	val: 0.318778	test: 0.238148

Epoch: 130
Loss: 0.026509500394825917
ROC train: 0.999866	val: 0.791608	test: 0.740364
PRC train: 0.996696	val: 0.333786	test: 0.245080

Epoch: 131
Loss: 0.022611572037466297
ROC train: 0.999924	val: 0.791667	test: 0.740795
PRC train: 0.998157	val: 0.343101	test: 0.197448

Epoch: 132
Loss: 0.022230072877084013
ROC train: 0.999995	val: 0.798440	test: 0.741138
PRC train: 0.999860	val: 0.287972	test: 0.154610

Epoch: 133
Loss: 0.022805421019922823
ROC train: 0.999983	val: 0.785922	test: 0.742334
PRC train: 0.999559	val: 0.301547	test: 0.188247

Epoch: 134
Loss: 0.020919091873372885
ROC train: 0.999962	val: 0.812598	test: 0.751641
PRC train: 0.999078	val: 0.375925	test: 0.202174

Epoch: 135
Loss: 0.02461272869885474
ROC train: 0.999992	val: 0.780439	test: 0.738330
PRC train: 0.999811	val: 0.311785	test: 0.195753

Epoch: 136
Loss: 0.020201876550614964
ROC train: 0.999968	val: 0.796887	test: 0.743456
PRC train: 0.999184	val: 0.320629	test: 0.197686

Epoch: 137
Loss: 0.02108777533984189
ROC train: 0.999992	val: 0.809524	test: 0.743722
PRC train: 0.999795	val: 0.316749	test: 0.191514

Epoch: 138
Loss: 0.02156187262372732
ROC train: 0.999995	val: 0.827522	test: 0.748514
PRC train: 0.999876	val: 0.352066	test: 0.183822

Epoch: 139
Loss: 0.02143245246018713
ROC train: 0.999981	val: 0.802298	test: 0.736105
PRC train: 0.999531	val: 0.306454	test: 0.176277

Epoch: 140
Loss: 0.023391147148772187
ROC train: 0.999886	val: 0.789609	test: 0.733616
PRC train: 0.997878	val: 0.326660	test: 0.241017

Epoch: 141
Loss: 0.0213021961500558
ROC train: 0.999967	val: 0.795148	test: 0.715684
PRC train: 0.999382	val: 0.291087	test: 0.169420

Epoch: 142
Loss: 0.020999077619429634
ROC train: 0.999975	val: 0.795907	test: 0.756704
PRC train: 0.999423	val: 0.320120	test: 0.219395

Epoch: 143
Loss: 0.02193752310893015
ROC train: 0.999987	val: 0.783243	test: 0.743921
PRC train: 0.999679	val: 0.286126	test: 0.210844

Epoch: 144
Loss: 0.020758096728142165
ROC train: 0.999996	val: 0.796422	test: 0.731862
PRC train: 0.999908	val: 0.335462	test: 0.186288

Epoch: 145
Loss: 0.019367110342472946
ROC train: 0.999979	val: 0.821168	test: 0.725615
PRC train: 0.999470	val: 0.314692	test: 0.222097

Epoch: 146
Loss: 0.020542633236541697
ROC train: 0.999967	val: 0.800871	test: 0.741532
PRC train: 0.999166	val: 0.332905	test: 0.212614

Epoch: 147
Loss: 0.021435131641109436
ROC train: 0.999988	val: 0.814870	test: 0.729265
PRC train: 0.999691	val: 0.324839	test: 0.198042

Epoch: 148
Loss: 0.020896861720381646
ROC train: 0.999963	val: 0.798881	test: 0.742432
PRC train: 0.999030	val: 0.325099	test: 0.200613

Epoch: 149
Loss: 0.01886669266814261
ROC train: 0.999971	val: 0.786308	test: 0.729970
PRC train: 0.999215	val: 0.251262	test: 0.180168

Epoch: 150
Loss: 0.021533273366376535
ROC train: 0.999986	val: 0.821876	test: 0.736536
PRC train: 0.999651	val: 0.333494	test: 0.188792

Epoch: 151
Loss: 0.020543092650191646
ROC train: 0.999952	val: 0.810014	test: 0.728065
PRC train: 0.998984	val: 0.338661	test: 0.185257

Epoch: 152
Loss: 0.01941856744646961
ROC train: 0.999995	val: 0.802601	test: 0.745049
PRC train: 0.999875	val: 0.367509	test: 0.184366

Epoch: 153
Loss: 0.020330115486655382
ROC train: 1.000000	val: 0.797200	test: 0.737104
PRC train: 0.999989	val: 0.295115	test: 0.175839

Epoch: 154
Loss: 0.017933376382770348
ROC train: 0.999987	val: 0.795240	test: 0.740034
PRC train: 0.999668	val: 0.341752	test: 0.195358

Epoch: 155
Loss: 0.020481490698196287
ROC train: 0.999994	val: 0.801113	test: 0.735818
PRC train: 0.999843	val: 0.306161	test: 0.179295

Epoch: 156
Loss: 0.021674504041739838
ROC train: 0.999988	val: 0.823955	test: 0.755020
PRC train: 0.999702	val: 0.349420	test: 0.208248

Epoch: 157
Loss: 0.017317262807858235
ROC train: 0.999981	val: 0.814132	test: 0.747537
PRC train: 0.999516	val: 0.350770	test: 0.174451

Epoch: 158
Loss: 0.020080043234914562
ROC train: 0.999986	val: 0.813948	test: 0.751135
PRC train: 0.999645	val: 0.350938	test: 0.200817

Epoch: 159
Loss: 0.019145992985443366
ROC train: 0.999997	val: 0.793831	test: 0.740480
PRC train: 0.999929	val: 0.326506	test: 0.198813

Epoch: 160
Loss: 0.018389477280030143
ROC train: 0.999890	val: 0.796250	test: 0.737502
PRC train: 0.996777	val: 0.321152	test: 0.190449

Epoch: 161
Loss: 0.017243770424458175
ROC train: 0.999995	val: 0.816514	test: 0.755277
PRC train: 0.999865	val: 0.391549	test: 0.231021

Epoch: 162
Loss: 0.020374716619256474
ROC train: 0.999979	val: 0.814205	test: 0.748792
PRC train: 0.999403	val: 0.351676	test: 0.212074

Epoch: 163
Loss: 0.019564121721023644
ROC train: 0.999996	val: 0.807927	test: 0.730586
PRC train: 0.999896	val: 0.349751	test: 0.208926

Epoch: 164
Loss: 0.016594431713525464
ROC train: 0.999997	val: 0.808308	test: 0.745542
PRC train: 0.999916	val: 0.307622	test: 0.171897

Epoch: 165
Loss: 0.017444458685903646
ROC train: 0.999972	val: 0.799928	test: 0.735402
PRC train: 0.999478	val: 0.328688	test: 0.153392

Epoch: 166
Loss: 0.01707747753574349
ROC train: 0.999998	val: 0.795849	test: 0.731325
PRC train: 0.999938	val: 0.331623	test: 0.173130

Epoch: 167
Loss: 0.01928381806616441
ROC train: 0.999995	val: 0.789134	test: 0.742604
PRC train: 0.999883	val: 0.346041	test: 0.243057

Epoch: 168
Loss: 0.017805748822174894
ROC train: 0.999990	val: 0.814564	test: 0.735673
PRC train: 0.999689	val: 0.305968	test: 0.193430

Epoch: 169
Loss: 0.019439604753354798
ROC train: 0.999993	val: 0.808559	test: 0.731366
PRC train: 0.999855	val: 0.322810	test: 0.168685

Epoch: 170
Loss: 0.016920581667075045
ROC train: 0.999994	val: 0.822258	test: 0.735756
PRC train: 0.999842	val: 0.318307	test: 0.171117

Epoch: 171
Loss: 0.0161711482020334
ROC train: 1.000000	val: 0.799453	test: 0.739813
PRC train: 0.999993	val: 0.291785	test: 0.157346

Epoch: 172
Loss: 0.01624612551233367
ROC train: 0.999994	val: 0.797353	test: 0.738913
PRC train: 0.999835	val: 0.323887	test: 0.203933

Epoch: 173
Loss: 0.017401189307666043
ROC train: 0.999988	val: 0.814334	test: 0.731130
PRC train: 0.999695	val: 0.355167	test: 0.188514

Early stopping
Best (ROC):	 train: 0.999995	val: 0.827522	test: 0.748514
Best (PRC):	 train: 0.999876	val: 0.352066	test: 0.183822
All runs completed.

PRC train: 0.871230	val: 0.301717	test: 0.171999

Epoch: 155
Loss: 0.061117900092372925
ROC train: 0.990531	val: 0.814992	test: 0.729981
PRC train: 0.865889	val: 0.312438	test: 0.166837

Epoch: 156
Loss: 0.05813451692460929
ROC train: 0.990412	val: 0.816768	test: 0.753651
PRC train: 0.860729	val: 0.315298	test: 0.169911

Epoch: 157
Loss: 0.059697186152626196
ROC train: 0.991218	val: 0.826104	test: 0.751324
PRC train: 0.872297	val: 0.284504	test: 0.142370

Epoch: 158
Loss: 0.058443475682334114
ROC train: 0.991310	val: 0.807096	test: 0.748751
PRC train: 0.878037	val: 0.295038	test: 0.189120

Epoch: 159
Loss: 0.060431926105700924
ROC train: 0.990483	val: 0.801024	test: 0.759140
PRC train: 0.865629	val: 0.304710	test: 0.168264

Epoch: 160
Loss: 0.05892217453209609
ROC train: 0.990925	val: 0.799634	test: 0.759055
PRC train: 0.869681	val: 0.291937	test: 0.200639

Epoch: 161
Loss: 0.0588533803734848
ROC train: 0.992065	val: 0.819273	test: 0.746049
PRC train: 0.879742	val: 0.301727	test: 0.175921

Epoch: 162
Loss: 0.057873978052852985
ROC train: 0.992866	val: 0.811263	test: 0.742355
PRC train: 0.892770	val: 0.300667	test: 0.145731

Epoch: 163
Loss: 0.05795939217477655
ROC train: 0.991847	val: 0.813755	test: 0.745117
PRC train: 0.880506	val: 0.295762	test: 0.150807

Epoch: 164
Loss: 0.05704275772831459
ROC train: 0.992014	val: 0.811058	test: 0.748412
PRC train: 0.881789	val: 0.306827	test: 0.157586

Epoch: 165
Loss: 0.05778232991876958
ROC train: 0.989883	val: 0.806878	test: 0.735242
PRC train: 0.860825	val: 0.274105	test: 0.159521

Epoch: 166
Loss: 0.05905346371126592
ROC train: 0.991917	val: 0.813985	test: 0.747786
PRC train: 0.879884	val: 0.290150	test: 0.143974

Epoch: 167
Loss: 0.05919062834034546
ROC train: 0.990384	val: 0.805038	test: 0.743408
PRC train: 0.864901	val: 0.305319	test: 0.148465

Epoch: 168
Loss: 0.05761984982188294
ROC train: 0.992710	val: 0.814417	test: 0.752006
PRC train: 0.882913	val: 0.327283	test: 0.158278

Epoch: 169
Loss: 0.05632959509668773
ROC train: 0.993369	val: 0.808584	test: 0.747079
PRC train: 0.896423	val: 0.298103	test: 0.158342

Epoch: 170
Loss: 0.057701636759638145
ROC train: 0.991365	val: 0.809845	test: 0.750169
PRC train: 0.876035	val: 0.322906	test: 0.181436

Epoch: 171
Loss: 0.05529715673014184
ROC train: 0.990378	val: 0.805047	test: 0.746069
PRC train: 0.867540	val: 0.283476	test: 0.130097

Epoch: 172
Loss: 0.058607697800672306
ROC train: 0.992328	val: 0.795586	test: 0.743643
PRC train: 0.887925	val: 0.316549	test: 0.163040

Epoch: 173
Loss: 0.05682270402484468
ROC train: 0.992475	val: 0.796731	test: 0.737604
PRC train: 0.883318	val: 0.304996	test: 0.138808

Epoch: 174
Loss: 0.0571246242555478
ROC train: 0.992253	val: 0.797484	test: 0.733205
PRC train: 0.884662	val: 0.319677	test: 0.168130

Epoch: 175
Loss: 0.05501067537753028
ROC train: 0.993856	val: 0.801211	test: 0.729039
PRC train: 0.899675	val: 0.311679	test: 0.174952

Epoch: 176
Loss: 0.0556824320029415
ROC train: 0.993589	val: 0.813321	test: 0.735881
PRC train: 0.898782	val: 0.300369	test: 0.145723

Epoch: 177
Loss: 0.05523676616257065
ROC train: 0.993230	val: 0.817607	test: 0.739530
PRC train: 0.892090	val: 0.285067	test: 0.174628

Epoch: 178
Loss: 0.054995896651474425
ROC train: 0.993647	val: 0.812604	test: 0.744066
PRC train: 0.896578	val: 0.298914	test: 0.163126

Epoch: 179
Loss: 0.054435755604831076
ROC train: 0.993325	val: 0.804906	test: 0.750387
PRC train: 0.891976	val: 0.296348	test: 0.187594

Epoch: 180
Loss: 0.054454900883352454
ROC train: 0.993668	val: 0.805617	test: 0.760384
PRC train: 0.901755	val: 0.288704	test: 0.202105

Epoch: 181
Loss: 0.05386969439122949
ROC train: 0.994246	val: 0.805075	test: 0.750208
PRC train: 0.902149	val: 0.302767	test: 0.179111

Epoch: 182
Loss: 0.05472506963840871
ROC train: 0.994316	val: 0.810951	test: 0.740121
PRC train: 0.905204	val: 0.286503	test: 0.158084

Epoch: 183
Loss: 0.052876763230610184
ROC train: 0.993617	val: 0.814879	test: 0.753331
PRC train: 0.899161	val: 0.298551	test: 0.185798

Epoch: 184
Loss: 0.054990870276493305
ROC train: 0.993837	val: 0.799560	test: 0.765308
PRC train: 0.898138	val: 0.285655	test: 0.220714

Epoch: 185
Loss: 0.05206684198674188
ROC train: 0.994612	val: 0.789180	test: 0.751529
PRC train: 0.908467	val: 0.281052	test: 0.188533

Early stopping
Best (ROC):	 train: 0.989566	val: 0.826839	test: 0.715383
Best (PRC):	 train: 0.859541	val: 0.319777	test: 0.155203
All runs completed.
