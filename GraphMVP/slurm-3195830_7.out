>>> Starting run for dataset: sider
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running RANDOM configs_static_noise_experiments/GraphCL/sider/noise=0.0.yml on cuda:0
Running RANDOM configs_static_noise_experiments/GraphCL/sider/noise=0.05.yml on cuda:1
Running RANDOM configs_static_noise_experiments/GraphCL/sider/noise=0.1.yml on cuda:2
Running RANDOM configs_static_noise_experiments/GraphCL/sider/noise=0.2.yml on cuda:3
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.1.yml --runseed 1 --device cuda:2
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.0.yml --runseed 1 --device cuda:0
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.2.yml --runseed 1 --device cuda:3
Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.1.yml --runseed 2 --device cuda:2
Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.0.yml --runseed 2 --device cuda:0
Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.2.yml --runseed 2 --device cuda:3
Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.1.yml --runseed 3 --device cuda:2
Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.2.yml --runseed 3 --device cuda:3
Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.0.yml --runseed 3 --device cuda:0
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.05.yml --runseed 1 --device cuda:1
Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.05.yml --runseed 2 --device cuda:1
Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.05.yml --runseed 3 --device cuda:1
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:36] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
[14:43:37] WARNING: not removing hydrogen atom without neighbors
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.0.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:0
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/sider/noise=0.0
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/sider/noise=0.0/sider_scaff_2_20-05_14-43-32  ]
[ Using Seed :  2  ]
[ Using device :  cuda:0  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.690003087572989
ROC train: 0.557576	val: 0.497122	test: 0.524852
PRC train: 0.590367	val: 0.605007	test: 0.582491

Epoch: 2
Loss: 0.6431854506260486
ROC train: 0.572310	val: 0.505041	test: 0.517012
PRC train: 0.601222	val: 0.600576	test: 0.584974

Epoch: 3
Loss: 0.6058324283168763
ROC train: 0.574471	val: 0.506878	test: 0.502801
PRC train: 0.607970	val: 0.600978	test: 0.581698

Epoch: 4
Loss: 0.5777015468097166
ROC train: 0.590582	val: 0.514835	test: 0.504772
PRC train: 0.620924	val: 0.610440	test: 0.586416

Epoch: 5
Loss: 0.5589923144443907
ROC train: 0.626847	val: 0.549369	test: 0.552240
PRC train: 0.639757	val: 0.629421	test: 0.611647

Epoch: 6
Loss: 0.5425780885344724
ROC train: 0.641723	val: 0.555062	test: 0.565122
PRC train: 0.650189	val: 0.631778	test: 0.614419

Epoch: 7
Loss: 0.5354652732619035
ROC train: 0.652173	val: 0.560532	test: 0.574189
PRC train: 0.656613	val: 0.634221	test: 0.617650

Epoch: 8
Loss: 0.523872866213723
ROC train: 0.670832	val: 0.583006	test: 0.600472
PRC train: 0.667701	val: 0.640149	test: 0.628479

Epoch: 9
Loss: 0.5167251757868321
ROC train: 0.679254	val: 0.598014	test: 0.602017
PRC train: 0.674196	val: 0.646921	test: 0.628328

Epoch: 10
Loss: 0.5077282097194092
ROC train: 0.685428	val: 0.601914	test: 0.593587
PRC train: 0.677814	val: 0.653327	test: 0.621227

Epoch: 11
Loss: 0.5024747824564061
ROC train: 0.695166	val: 0.606795	test: 0.604488
PRC train: 0.684679	val: 0.654830	test: 0.625836

Epoch: 12
Loss: 0.49543943220528963
ROC train: 0.699926	val: 0.606668	test: 0.604994
PRC train: 0.688131	val: 0.654180	test: 0.627276

Epoch: 13
Loss: 0.49341348323174844
ROC train: 0.704771	val: 0.602886	test: 0.604754
PRC train: 0.692462	val: 0.652784	test: 0.632334

Epoch: 14
Loss: 0.49105249205765167
ROC train: 0.712003	val: 0.608944	test: 0.606476
PRC train: 0.698126	val: 0.658585	test: 0.634412

Epoch: 15
Loss: 0.4843322930612931
ROC train: 0.717662	val: 0.601426	test: 0.608086
PRC train: 0.702536	val: 0.653587	test: 0.637293

Epoch: 16
Loss: 0.48100172440099226
ROC train: 0.725655	val: 0.603384	test: 0.606156
PRC train: 0.709198	val: 0.652936	test: 0.634246

Epoch: 17
Loss: 0.47868940346310085
ROC train: 0.732577	val: 0.606100	test: 0.603759
PRC train: 0.714551	val: 0.652442	test: 0.633100

Epoch: 18
Loss: 0.4765099573892736
ROC train: 0.737064	val: 0.607847	test: 0.609533
PRC train: 0.716430	val: 0.658894	test: 0.632263

Epoch: 19
Loss: 0.4755327896740944
ROC train: 0.740611	val: 0.618120	test: 0.603324
PRC train: 0.717112	val: 0.663442	test: 0.626731

Epoch: 20
Loss: 0.47302252309423576
ROC train: 0.747426	val: 0.623692	test: 0.615774
PRC train: 0.722530	val: 0.661518	test: 0.632114

Epoch: 21
Loss: 0.47521607964654883
ROC train: 0.751410	val: 0.620463	test: 0.621500
PRC train: 0.726843	val: 0.660048	test: 0.633946

Epoch: 22
Loss: 0.46701326728181236
ROC train: 0.758117	val: 0.614894	test: 0.622285
PRC train: 0.731581	val: 0.657466	test: 0.630532

Epoch: 23
Loss: 0.46137712182665985
ROC train: 0.763033	val: 0.615477	test: 0.615750
PRC train: 0.735726	val: 0.656734	test: 0.628496

Epoch: 24
Loss: 0.4639562756642638
ROC train: 0.762042	val: 0.612579	test: 0.604999
PRC train: 0.737750	val: 0.656578	test: 0.629281

Epoch: 25
Loss: 0.46488369437294513
ROC train: 0.770782	val: 0.632238	test: 0.605059
PRC train: 0.742805	val: 0.666847	test: 0.626990

Epoch: 26
Loss: 0.45770736066508116
ROC train: 0.770493	val: 0.624179	test: 0.598187
PRC train: 0.741981	val: 0.663782	test: 0.625058

Epoch: 27
Loss: 0.45756009373363515
ROC train: 0.772309	val: 0.630897	test: 0.594617
PRC train: 0.741689	val: 0.668099	test: 0.627870

Epoch: 28
Loss: 0.456338839242846
ROC train: 0.776601	val: 0.629403	test: 0.605718
PRC train: 0.745338	val: 0.670158	test: 0.628188

Epoch: 29
Loss: 0.453896971699436
ROC train: 0.775316	val: 0.621467	test: 0.607399
PRC train: 0.746492	val: 0.664873	test: 0.627774

Epoch: 30
Loss: 0.4523144878771489
ROC train: 0.778566	val: 0.621990	test: 0.607132
PRC train: 0.749252	val: 0.663250	test: 0.628801

Epoch: 31
Loss: 0.4530593404653712
ROC train: 0.779296	val: 0.617705	test: 0.608199
PRC train: 0.747408	val: 0.662521	test: 0.634150

Epoch: 32
Loss: 0.44868369194590363
ROC train: 0.787708	val: 0.618687	test: 0.613588
PRC train: 0.755908	val: 0.662877	test: 0.631584

Epoch: 33
Loss: 0.4493423007608133
ROC train: 0.784918	val: 0.604477	test: 0.618790Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.0.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:0
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/sider/noise=0.0
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/sider/noise=0.0/sider_scaff_1_20-05_14-43-32  ]
[ Using Seed :  1  ]
[ Using device :  cuda:0  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6899386372436999
ROC train: 0.541373	val: 0.509047	test: 0.503200
PRC train: 0.583508	val: 0.603514	test: 0.583713

Epoch: 2
Loss: 0.6387446410700726
ROC train: 0.560615	val: 0.508898	test: 0.500312
PRC train: 0.600520	val: 0.599934	test: 0.581242

Epoch: 3
Loss: 0.6039274607196338
ROC train: 0.569954	val: 0.505863	test: 0.498638
PRC train: 0.609353	val: 0.597454	test: 0.583305

Epoch: 4
Loss: 0.5739596372950597
ROC train: 0.594288	val: 0.518900	test: 0.510341
PRC train: 0.626231	val: 0.609457	test: 0.589427

Epoch: 5
Loss: 0.5579243937827065
ROC train: 0.629949	val: 0.552245	test: 0.543187
PRC train: 0.646439	val: 0.633472	test: 0.604768

Epoch: 6
Loss: 0.5442029408520401
ROC train: 0.643794	val: 0.553576	test: 0.565386
PRC train: 0.652872	val: 0.631984	test: 0.615233

Epoch: 7
Loss: 0.5309724743961939
ROC train: 0.651763	val: 0.557374	test: 0.571974
PRC train: 0.657415	val: 0.630858	test: 0.619637

Epoch: 8
Loss: 0.5338128064947338
ROC train: 0.662331	val: 0.565996	test: 0.578832
PRC train: 0.664566	val: 0.634826	test: 0.624509

Epoch: 9
Loss: 0.514904937257662
ROC train: 0.678299	val: 0.575761	test: 0.588779
PRC train: 0.675875	val: 0.638751	test: 0.631962

Epoch: 10
Loss: 0.505681690197096
ROC train: 0.687523	val: 0.586375	test: 0.588825
PRC train: 0.682496	val: 0.643733	test: 0.629272

Epoch: 11
Loss: 0.504560842365209
ROC train: 0.697128	val: 0.595338	test: 0.593731
PRC train: 0.692733	val: 0.647988	test: 0.633856

Epoch: 12
Loss: 0.4956616293549483
ROC train: 0.708590	val: 0.601443	test: 0.597496
PRC train: 0.700066	val: 0.651583	test: 0.636870

Epoch: 13
Loss: 0.49200761013760824
ROC train: 0.716018	val: 0.605153	test: 0.602427
PRC train: 0.704805	val: 0.655615	test: 0.638585

Epoch: 14
Loss: 0.48653979836608424
ROC train: 0.718794	val: 0.602883	test: 0.601055
PRC train: 0.707105	val: 0.648495	test: 0.633886

Epoch: 15
Loss: 0.48919904467677355
ROC train: 0.722048	val: 0.608591	test: 0.602799
PRC train: 0.709680	val: 0.649202	test: 0.630922

Epoch: 16
Loss: 0.4829727478045548
ROC train: 0.734451	val: 0.594623	test: 0.604852
PRC train: 0.717016	val: 0.648263	test: 0.633095

Epoch: 17
Loss: 0.4769457525958776
ROC train: 0.740039	val: 0.593075	test: 0.608651
PRC train: 0.721449	val: 0.649364	test: 0.636080

Epoch: 18
Loss: 0.4764651565404888
ROC train: 0.742950	val: 0.597624	test: 0.603516
PRC train: 0.722944	val: 0.648698	test: 0.629752

Epoch: 19
Loss: 0.473094517730184
ROC train: 0.744809	val: 0.597125	test: 0.601334
PRC train: 0.725717	val: 0.649312	test: 0.630006

Epoch: 20
Loss: 0.46944648943309997
ROC train: 0.748158	val: 0.598302	test: 0.607197
PRC train: 0.729977	val: 0.652367	test: 0.635565

Epoch: 21
Loss: 0.46512968270834276
ROC train: 0.757715	val: 0.610378	test: 0.601244
PRC train: 0.735796	val: 0.654630	test: 0.634366

Epoch: 22
Loss: 0.46910065664993084
ROC train: 0.762790	val: 0.610693	test: 0.600418
PRC train: 0.739582	val: 0.655178	test: 0.632087

Epoch: 23
Loss: 0.463885734277937
ROC train: 0.767693	val: 0.609522	test: 0.606006
PRC train: 0.743885	val: 0.654107	test: 0.632667

Epoch: 24
Loss: 0.4626506409163481
ROC train: 0.772334	val: 0.614084	test: 0.603056
PRC train: 0.744734	val: 0.657849	test: 0.627345

Epoch: 25
Loss: 0.46160546645461853
ROC train: 0.773168	val: 0.617030	test: 0.608301
PRC train: 0.745808	val: 0.662677	test: 0.631070

Epoch: 26
Loss: 0.4588224869565514
ROC train: 0.777014	val: 0.621046	test: 0.609757
PRC train: 0.750152	val: 0.660978	test: 0.634604

Epoch: 27
Loss: 0.45932095558398406
ROC train: 0.779563	val: 0.614241	test: 0.615479
PRC train: 0.751700	val: 0.660616	test: 0.634998

Epoch: 28
Loss: 0.4595248952261688
ROC train: 0.778112	val: 0.599918	test: 0.613915
PRC train: 0.751558	val: 0.654632	test: 0.637025

Epoch: 29
Loss: 0.45031923511668615
ROC train: 0.783056	val: 0.613661	test: 0.614889
PRC train: 0.754909	val: 0.658629	test: 0.639048

Epoch: 30
Loss: 0.4485716825383966
ROC train: 0.784247	val: 0.614816	test: 0.614149
PRC train: 0.756186	val: 0.659840	test: 0.636146

Epoch: 31
Loss: 0.4486954049766959
ROC train: 0.786990	val: 0.616742	test: 0.612997
PRC train: 0.758894	val: 0.658317	test: 0.640909

Epoch: 32
Loss: 0.448805896099335
ROC train: 0.791823	val: 0.621634	test: 0.614660
PRC train: 0.763628	val: 0.663499	test: 0.641367

Epoch: 33
Loss: 0.44427748169196646
ROC train: 0.794030	val: 0.619168	test: 0.604536Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.0.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:0
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/sider/noise=0.0
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/sider/noise=0.0/sider_scaff_3_20-05_14-43-32  ]
[ Using Seed :  3  ]
[ Using device :  cuda:0  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6808410676374506
ROC train: 0.550017	val: 0.522736	test: 0.497522
PRC train: 0.589430	val: 0.612325	test: 0.577526

Epoch: 2
Loss: 0.636516682562358
ROC train: 0.572848	val: 0.519392	test: 0.506679
PRC train: 0.608628	val: 0.604510	test: 0.586792

Epoch: 3
Loss: 0.5933544234468977
ROC train: 0.575419	val: 0.511343	test: 0.500947
PRC train: 0.613911	val: 0.602880	test: 0.588147

Epoch: 4
Loss: 0.5790159258675768
ROC train: 0.590825	val: 0.525102	test: 0.510329
PRC train: 0.626869	val: 0.616797	test: 0.592286

Epoch: 5
Loss: 0.5533673992276243
ROC train: 0.623157	val: 0.551092	test: 0.537279
PRC train: 0.642760	val: 0.626298	test: 0.603698

Epoch: 6
Loss: 0.5393238698151672
ROC train: 0.642605	val: 0.553937	test: 0.561968
PRC train: 0.651657	val: 0.627503	test: 0.615758

Epoch: 7
Loss: 0.5312027162566313
ROC train: 0.657547	val: 0.569528	test: 0.579207
PRC train: 0.661819	val: 0.629492	test: 0.621004

Epoch: 8
Loss: 0.5191414687919365
ROC train: 0.667655	val: 0.574740	test: 0.578766
PRC train: 0.668863	val: 0.635061	test: 0.618524

Epoch: 9
Loss: 0.5082731671815863
ROC train: 0.679503	val: 0.583625	test: 0.584687
PRC train: 0.676470	val: 0.641608	test: 0.620303

Epoch: 10
Loss: 0.5034347023815245
ROC train: 0.691212	val: 0.594274	test: 0.595447
PRC train: 0.684353	val: 0.647020	test: 0.623955

Epoch: 11
Loss: 0.49732818501314713
ROC train: 0.697989	val: 0.593966	test: 0.598221
PRC train: 0.690572	val: 0.650817	test: 0.624634

Epoch: 12
Loss: 0.4943306747130921
ROC train: 0.704499	val: 0.597553	test: 0.593816
PRC train: 0.692783	val: 0.651190	test: 0.625354

Epoch: 13
Loss: 0.49261256744740056
ROC train: 0.716624	val: 0.602575	test: 0.598885
PRC train: 0.701665	val: 0.654464	test: 0.629759

Epoch: 14
Loss: 0.4813520969750389
ROC train: 0.718175	val: 0.600526	test: 0.595757
PRC train: 0.702317	val: 0.656824	test: 0.629053

Epoch: 15
Loss: 0.4828989196734149
ROC train: 0.725137	val: 0.589041	test: 0.599225
PRC train: 0.710379	val: 0.649574	test: 0.630323

Epoch: 16
Loss: 0.48133651410887807
ROC train: 0.725643	val: 0.590322	test: 0.597414
PRC train: 0.712205	val: 0.650052	test: 0.632141

Epoch: 17
Loss: 0.4797573054216791
ROC train: 0.737642	val: 0.596689	test: 0.606187
PRC train: 0.719785	val: 0.657515	test: 0.631601

Epoch: 18
Loss: 0.47559906910337135
ROC train: 0.739410	val: 0.606462	test: 0.611367
PRC train: 0.720458	val: 0.656468	test: 0.634579

Epoch: 19
Loss: 0.4743349399379998
ROC train: 0.741388	val: 0.602495	test: 0.610162
PRC train: 0.723167	val: 0.651507	test: 0.637198

Epoch: 20
Loss: 0.46719196000564234
ROC train: 0.749858	val: 0.601615	test: 0.605150
PRC train: 0.729667	val: 0.656276	test: 0.631463

Epoch: 21
Loss: 0.46662936312244163
ROC train: 0.755172	val: 0.607738	test: 0.609091
PRC train: 0.733959	val: 0.661344	test: 0.630187

Epoch: 22
Loss: 0.46182741301550756
ROC train: 0.759565	val: 0.615059	test: 0.610752
PRC train: 0.737371	val: 0.662035	test: 0.634761

Epoch: 23
Loss: 0.4645435242233674
ROC train: 0.762993	val: 0.618726	test: 0.609263
PRC train: 0.737383	val: 0.660858	test: 0.637628

Epoch: 24
Loss: 0.46269368941554745
ROC train: 0.768307	val: 0.612891	test: 0.607236
PRC train: 0.743775	val: 0.655235	test: 0.629111

Epoch: 25
Loss: 0.45689788475114435
ROC train: 0.769448	val: 0.602315	test: 0.606950
PRC train: 0.743231	val: 0.650124	test: 0.631861

Epoch: 26
Loss: 0.45980953451722073
ROC train: 0.774955	val: 0.608469	test: 0.601090
PRC train: 0.746103	val: 0.653957	test: 0.632605

Epoch: 27
Loss: 0.45369572676683667
ROC train: 0.780498	val: 0.610325	test: 0.608692
PRC train: 0.750961	val: 0.659616	test: 0.636008

Epoch: 28
Loss: 0.45957898845102874
ROC train: 0.782968	val: 0.619701	test: 0.611624
PRC train: 0.753116	val: 0.664731	test: 0.635410

Epoch: 29
Loss: 0.4538670432389928
ROC train: 0.788502	val: 0.632672	test: 0.604549
PRC train: 0.757872	val: 0.674262	test: 0.633204

Epoch: 30
Loss: 0.4520852686802141
ROC train: 0.787857	val: 0.617830	test: 0.610639
PRC train: 0.759259	val: 0.662402	test: 0.634327

Epoch: 31
Loss: 0.44953389624093687
ROC train: 0.789587	val: 0.612182	test: 0.614638
PRC train: 0.759731	val: 0.659262	test: 0.637212

Epoch: 32
Loss: 0.44622215876050975
ROC train: 0.793411	val: 0.619804	test: 0.617217
PRC train: 0.761717	val: 0.664968	test: 0.640434

Epoch: 33
Loss: 0.444406542632341
ROC train: 0.798408	val: 0.629888	test: 0.617247Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.1.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:2
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.1
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/sider/noise=0.1
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/sider/noise=0.1/sider_scaff_1_20-05_14-43-32  ]
[ Using Seed :  1  ]
[ Using device :  cuda:2  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6897664070815942
ROC train: 0.545855	val: 0.529216	test: 0.514039
PRC train: 0.582396	val: 0.612970	test: 0.589995

Epoch: 2
Loss: 0.6471890425650008
ROC train: 0.564513	val: 0.510433	test: 0.515019
PRC train: 0.593476	val: 0.601387	test: 0.587528

Epoch: 3
Loss: 0.6106661756351226
ROC train: 0.554562	val: 0.500442	test: 0.500231
PRC train: 0.595249	val: 0.595916	test: 0.582838

Epoch: 4
Loss: 0.5777589869046926
ROC train: 0.566195	val: 0.506930	test: 0.502278
PRC train: 0.604293	val: 0.600611	test: 0.582617

Epoch: 5
Loss: 0.5637583567059864
ROC train: 0.589658	val: 0.519978	test: 0.516758
PRC train: 0.617555	val: 0.605725	test: 0.588723

Epoch: 6
Loss: 0.5503052316676718
ROC train: 0.622226	val: 0.537100	test: 0.540739
PRC train: 0.635150	val: 0.610271	test: 0.598198

Epoch: 7
Loss: 0.5377496280760123
ROC train: 0.638530	val: 0.542998	test: 0.552609
PRC train: 0.644821	val: 0.615080	test: 0.605476

Epoch: 8
Loss: 0.5270465698593814
ROC train: 0.650221	val: 0.548064	test: 0.562128
PRC train: 0.651492	val: 0.620026	test: 0.610446

Epoch: 9
Loss: 0.5201201278180652
ROC train: 0.656402	val: 0.545524	test: 0.565412
PRC train: 0.656355	val: 0.620120	test: 0.612054

Epoch: 10
Loss: 0.5111464183401812
ROC train: 0.669832	val: 0.551512	test: 0.568853
PRC train: 0.665964	val: 0.626593	test: 0.610937

Epoch: 11
Loss: 0.5067295144443922
ROC train: 0.686706	val: 0.563507	test: 0.574227
PRC train: 0.676950	val: 0.630674	test: 0.610876

Epoch: 12
Loss: 0.5007398334620611
ROC train: 0.698211	val: 0.567795	test: 0.574515
PRC train: 0.684257	val: 0.631925	test: 0.610252

Epoch: 13
Loss: 0.49630414852067267
ROC train: 0.712199	val: 0.570603	test: 0.576922
PRC train: 0.694248	val: 0.632064	test: 0.610822

Epoch: 14
Loss: 0.49276296195264546
ROC train: 0.720043	val: 0.574658	test: 0.576287
PRC train: 0.700809	val: 0.634611	test: 0.610688

Epoch: 15
Loss: 0.487983125470017
ROC train: 0.726271	val: 0.584129	test: 0.572618
PRC train: 0.706663	val: 0.645067	test: 0.609885

Epoch: 16
Loss: 0.48505681995042804
ROC train: 0.736417	val: 0.590326	test: 0.573048
PRC train: 0.714319	val: 0.649731	test: 0.612695

Epoch: 17
Loss: 0.4742041416749486
ROC train: 0.748405	val: 0.604114	test: 0.578946
PRC train: 0.723785	val: 0.658117	test: 0.615128

Epoch: 18
Loss: 0.47477642016806854
ROC train: 0.760202	val: 0.602215	test: 0.575516
PRC train: 0.729834	val: 0.653519	test: 0.613046

Epoch: 19
Loss: 0.4694365500319477
ROC train: 0.771756	val: 0.583709	test: 0.577963
PRC train: 0.739107	val: 0.649967	test: 0.609888

Epoch: 20
Loss: 0.4663768443542532
ROC train: 0.774410	val: 0.589140	test: 0.576186
PRC train: 0.739718	val: 0.651520	test: 0.614073

Epoch: 21
Loss: 0.46662481795736205
ROC train: 0.774802	val: 0.603510	test: 0.569320
PRC train: 0.741635	val: 0.651045	test: 0.614004

Epoch: 22
Loss: 0.45827539745216583
ROC train: 0.787107	val: 0.602700	test: 0.573150
PRC train: 0.751499	val: 0.649920	test: 0.615760

Epoch: 23
Loss: 0.4513146153340413
ROC train: 0.799131	val: 0.592081	test: 0.571109
PRC train: 0.760071	val: 0.646419	test: 0.612857

Epoch: 24
Loss: 0.4503937744316139
ROC train: 0.800471	val: 0.591269	test: 0.566128
PRC train: 0.762296	val: 0.647679	test: 0.607949

Epoch: 25
Loss: 0.44412466799165917
ROC train: 0.804514	val: 0.592654	test: 0.579224
PRC train: 0.767307	val: 0.644834	test: 0.619101

Epoch: 26
Loss: 0.4384227526524386
ROC train: 0.813995	val: 0.596884	test: 0.583902
PRC train: 0.774594	val: 0.648922	test: 0.618967

Epoch: 27
Loss: 0.4378477872706396
ROC train: 0.814375	val: 0.607418	test: 0.582336
PRC train: 0.774838	val: 0.659980	test: 0.615104

Epoch: 28
Loss: 0.43461773656007263
ROC train: 0.821259	val: 0.605244	test: 0.589760
PRC train: 0.780271	val: 0.658650	test: 0.616542

Epoch: 29
Loss: 0.43329394381680864
ROC train: 0.828796	val: 0.605413	test: 0.587331
PRC train: 0.784590	val: 0.655506	test: 0.619223

Epoch: 30
Loss: 0.42462695291508856
ROC train: 0.826734	val: 0.605619	test: 0.585912
PRC train: 0.783798	val: 0.656286	test: 0.616293

Epoch: 31
Loss: 0.4232320948526658
ROC train: 0.832735	val: 0.606200	test: 0.582006
PRC train: 0.788574	val: 0.656509	test: 0.614788

Epoch: 32
Loss: 0.42204391883152753
ROC train: 0.838605	val: 0.601082	test: 0.589824Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.05.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:1
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.05
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/sider/noise=0.05
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/sider/noise=0.05/sider_scaff_3_20-05_14-43-32  ]
[ Using Seed :  3  ]
[ Using device :  cuda:1  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.693124552023128
ROC train: 0.544498	val: 0.512612	test: 0.520667
PRC train: 0.584841	val: 0.605592	test: 0.587483

Epoch: 2
Loss: 0.6451217783180644
ROC train: 0.556734	val: 0.499962	test: 0.521100
PRC train: 0.598208	val: 0.603706	test: 0.585399

Epoch: 3
Loss: 0.6064620366288394
ROC train: 0.559179	val: 0.495658	test: 0.510420
PRC train: 0.603921	val: 0.604733	test: 0.584297

Epoch: 4
Loss: 0.5875721260948733
ROC train: 0.579910	val: 0.509431	test: 0.522223
PRC train: 0.616865	val: 0.611783	test: 0.591316

Epoch: 5
Loss: 0.5596558091054759
ROC train: 0.618605	val: 0.536759	test: 0.557265
PRC train: 0.638187	val: 0.623606	test: 0.606874

Epoch: 6
Loss: 0.5433427716681978
ROC train: 0.641653	val: 0.548090	test: 0.582483
PRC train: 0.653068	val: 0.626264	test: 0.619410

Epoch: 7
Loss: 0.5333712217908155
ROC train: 0.658166	val: 0.558903	test: 0.585188
PRC train: 0.662636	val: 0.628465	test: 0.623796

Epoch: 8
Loss: 0.5235651113506965
ROC train: 0.675343	val: 0.570292	test: 0.598468
PRC train: 0.672614	val: 0.630663	test: 0.627479

Epoch: 9
Loss: 0.5131014690857635
ROC train: 0.684792	val: 0.579365	test: 0.601128
PRC train: 0.677081	val: 0.637190	test: 0.627628

Epoch: 10
Loss: 0.5047297792358987
ROC train: 0.696507	val: 0.588860	test: 0.599996
PRC train: 0.684005	val: 0.637137	test: 0.624148

Epoch: 11
Loss: 0.5007206847937369
ROC train: 0.707283	val: 0.591802	test: 0.601187
PRC train: 0.690945	val: 0.639449	test: 0.625071

Epoch: 12
Loss: 0.4933690898582161
ROC train: 0.717577	val: 0.591797	test: 0.601116
PRC train: 0.697996	val: 0.638848	test: 0.632555

Epoch: 13
Loss: 0.4892373992989619
ROC train: 0.722763	val: 0.588625	test: 0.603327
PRC train: 0.702974	val: 0.637879	test: 0.633706

Epoch: 14
Loss: 0.4850897944282881
ROC train: 0.731641	val: 0.580395	test: 0.589823
PRC train: 0.708467	val: 0.636198	test: 0.623072

Epoch: 15
Loss: 0.4786257262791592
ROC train: 0.738526	val: 0.573863	test: 0.588028
PRC train: 0.710962	val: 0.636063	test: 0.623314

Epoch: 16
Loss: 0.47422186498353847
ROC train: 0.745325	val: 0.587619	test: 0.586577
PRC train: 0.720351	val: 0.644214	test: 0.634400

Epoch: 17
Loss: 0.47445378976782876
ROC train: 0.757201	val: 0.593621	test: 0.591896
PRC train: 0.728611	val: 0.647400	test: 0.627263

Epoch: 18
Loss: 0.4664230626619353
ROC train: 0.749594	val: 0.579788	test: 0.583927
PRC train: 0.721595	val: 0.641908	test: 0.611691

Epoch: 19
Loss: 0.4616255758820145
ROC train: 0.770052	val: 0.572914	test: 0.597091
PRC train: 0.737014	val: 0.644617	test: 0.621436

Epoch: 20
Loss: 0.4615193229957
ROC train: 0.776118	val: 0.589746	test: 0.592216
PRC train: 0.741486	val: 0.650366	test: 0.629440

Epoch: 21
Loss: 0.45793412870721883
ROC train: 0.781900	val: 0.613542	test: 0.592599
PRC train: 0.747236	val: 0.659652	test: 0.625455

Epoch: 22
Loss: 0.45552942470859276
ROC train: 0.787413	val: 0.605070	test: 0.604196
PRC train: 0.750754	val: 0.656071	test: 0.623084

Epoch: 23
Loss: 0.44916024681452893
ROC train: 0.786838	val: 0.603350	test: 0.612639
PRC train: 0.751281	val: 0.651845	test: 0.629290

Epoch: 24
Loss: 0.45034481999138193
ROC train: 0.788387	val: 0.604152	test: 0.619142
PRC train: 0.753431	val: 0.656431	test: 0.631041

Epoch: 25
Loss: 0.4493537403401861
ROC train: 0.800804	val: 0.616552	test: 0.619852
PRC train: 0.762651	val: 0.658272	test: 0.630119

Epoch: 26
Loss: 0.4403006689511774
ROC train: 0.798601	val: 0.620056	test: 0.599052
PRC train: 0.762514	val: 0.659776	test: 0.620954

Epoch: 27
Loss: 0.44484403885186985
ROC train: 0.811427	val: 0.615547	test: 0.598270
PRC train: 0.772350	val: 0.657557	test: 0.623479

Epoch: 28
Loss: 0.43950414810772365
ROC train: 0.808767	val: 0.614056	test: 0.613834
PRC train: 0.769809	val: 0.656893	test: 0.625175

Epoch: 29
Loss: 0.4376210880064004
ROC train: 0.808659	val: 0.606122	test: 0.608587
PRC train: 0.769217	val: 0.657395	test: 0.624415

Epoch: 30
Loss: 0.43685380258783446
ROC train: 0.822616	val: 0.622162	test: 0.598846
PRC train: 0.777374	val: 0.661770	test: 0.621568

Epoch: 31
Loss: 0.42916945163211195
ROC train: 0.814574	val: 0.628045	test: 0.593648
PRC train: 0.773151	val: 0.668290	test: 0.619962

Epoch: 32
Loss: 0.42874920991276044
ROC train: 0.827339	val: 0.621461	test: 0.608939Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.1.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:2
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.1
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/sider/noise=0.1
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/sider/noise=0.1/sider_scaff_2_20-05_14-43-32  ]
[ Using Seed :  2  ]
[ Using device :  cuda:2  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6829462659858436
ROC train: 0.539459	val: 0.522144	test: 0.493028
PRC train: 0.583474	val: 0.599222	test: 0.577296

Epoch: 2
Loss: 0.6440386611620614
ROC train: 0.554301	val: 0.507604	test: 0.490137
PRC train: 0.596269	val: 0.591571	test: 0.576435

Epoch: 3
Loss: 0.6101581618181227
ROC train: 0.552545	val: 0.503841	test: 0.484500
PRC train: 0.600624	val: 0.596620	test: 0.575666

Epoch: 4
Loss: 0.5865010629124148
ROC train: 0.564375	val: 0.513487	test: 0.494075
PRC train: 0.609584	val: 0.604488	test: 0.575924

Epoch: 5
Loss: 0.5572668441509189
ROC train: 0.598672	val: 0.534625	test: 0.526118
PRC train: 0.625016	val: 0.614894	test: 0.589323

Epoch: 6
Loss: 0.5478892326818061
ROC train: 0.620625	val: 0.546334	test: 0.549195
PRC train: 0.635644	val: 0.621062	test: 0.601043

Epoch: 7
Loss: 0.5345975438636169
ROC train: 0.635386	val: 0.557406	test: 0.560733
PRC train: 0.645251	val: 0.623381	test: 0.609033

Epoch: 8
Loss: 0.526573740005666
ROC train: 0.651621	val: 0.553090	test: 0.566054
PRC train: 0.654600	val: 0.621162	test: 0.614057

Epoch: 9
Loss: 0.5188218075067709
ROC train: 0.666872	val: 0.556770	test: 0.571313
PRC train: 0.664491	val: 0.624632	test: 0.616357

Epoch: 10
Loss: 0.5112248541326683
ROC train: 0.682781	val: 0.565163	test: 0.574534
PRC train: 0.674978	val: 0.628497	test: 0.616446

Epoch: 11
Loss: 0.5014872389406815
ROC train: 0.696831	val: 0.560874	test: 0.573182
PRC train: 0.685878	val: 0.623638	test: 0.613619

Epoch: 12
Loss: 0.5030581915505419
ROC train: 0.708249	val: 0.560769	test: 0.571322
PRC train: 0.694340	val: 0.621364	test: 0.613578

Epoch: 13
Loss: 0.49463486884201197
ROC train: 0.717537	val: 0.569456	test: 0.567153
PRC train: 0.702463	val: 0.625342	test: 0.612499

Epoch: 14
Loss: 0.486137275155852
ROC train: 0.728477	val: 0.581551	test: 0.569028
PRC train: 0.711288	val: 0.632649	test: 0.614267

Epoch: 15
Loss: 0.48202144128001556
ROC train: 0.741805	val: 0.597874	test: 0.563167
PRC train: 0.723074	val: 0.642597	test: 0.616110

Epoch: 16
Loss: 0.48073369152978485
ROC train: 0.745728	val: 0.593477	test: 0.561577
PRC train: 0.728057	val: 0.639747	test: 0.618555

Epoch: 17
Loss: 0.4713025776392555
ROC train: 0.753783	val: 0.564179	test: 0.576751
PRC train: 0.732934	val: 0.623553	test: 0.620825

Epoch: 18
Loss: 0.4747712142973345
ROC train: 0.764516	val: 0.587471	test: 0.567855
PRC train: 0.740871	val: 0.634097	test: 0.622426

Epoch: 19
Loss: 0.46361920489220754
ROC train: 0.755002	val: 0.607235	test: 0.554507
PRC train: 0.733424	val: 0.643744	test: 0.620177

Epoch: 20
Loss: 0.46550290818475154
ROC train: 0.775422	val: 0.584678	test: 0.571652
PRC train: 0.748534	val: 0.632334	test: 0.624929

Epoch: 21
Loss: 0.4589779238503236
ROC train: 0.787605	val: 0.579720	test: 0.567122
PRC train: 0.759786	val: 0.630464	test: 0.619586

Epoch: 22
Loss: 0.45119041312300256
ROC train: 0.791229	val: 0.586252	test: 0.542325
PRC train: 0.765764	val: 0.634807	test: 0.612339

Epoch: 23
Loss: 0.44768797891491074
ROC train: 0.799772	val: 0.576393	test: 0.559526
PRC train: 0.771374	val: 0.627343	test: 0.618225

Epoch: 24
Loss: 0.4523384854424096
ROC train: 0.807439	val: 0.568430	test: 0.565194
PRC train: 0.777599	val: 0.624576	test: 0.616698

Epoch: 25
Loss: 0.451756410610768
ROC train: 0.817367	val: 0.585699	test: 0.554033
PRC train: 0.782247	val: 0.635214	test: 0.612792

Epoch: 26
Loss: 0.440409019898533
ROC train: 0.817612	val: 0.578394	test: 0.558772
PRC train: 0.783566	val: 0.633039	test: 0.616138

Epoch: 27
Loss: 0.44250522297014017
ROC train: 0.819278	val: 0.585117	test: 0.533787
PRC train: 0.788069	val: 0.637854	test: 0.602978

Epoch: 28
Loss: 0.4338314171961025
ROC train: 0.819188	val: 0.599235	test: 0.529862
PRC train: 0.787228	val: 0.642823	test: 0.596550

Epoch: 29
Loss: 0.42719568096217453
ROC train: 0.824287	val: 0.570025	test: 0.552504
PRC train: 0.791864	val: 0.626761	test: 0.608663

Epoch: 30
Loss: 0.4295696080516624
ROC train: 0.831804	val: 0.559194	test: 0.551424
PRC train: 0.794629	val: 0.620875	test: 0.609481

Epoch: 31
Loss: 0.4193945631997317
ROC train: 0.839671	val: 0.571457	test: 0.544176
PRC train: 0.802922	val: 0.627465	test: 0.605130

Epoch: 32
Loss: 0.41519577167659866
ROC train: 0.845517	val: 0.589439	test: 0.527489Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.1.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:2
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.1
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/sider/noise=0.1
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/sider/noise=0.1/sider_scaff_3_20-05_14-43-32  ]
[ Using Seed :  3  ]
[ Using device :  cuda:2  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6935613284873151
ROC train: 0.547440	val: 0.509541	test: 0.524599
PRC train: 0.586625	val: 0.607758	test: 0.588914

Epoch: 2
Loss: 0.6484098621388517
ROC train: 0.567119	val: 0.506617	test: 0.524626
PRC train: 0.603179	val: 0.607554	test: 0.588527

Epoch: 3
Loss: 0.6121096329548651
ROC train: 0.561962	val: 0.505223	test: 0.511766
PRC train: 0.604851	val: 0.608239	test: 0.584716

Epoch: 4
Loss: 0.5915336998069753
ROC train: 0.577274	val: 0.516015	test: 0.528379
PRC train: 0.616258	val: 0.612605	test: 0.594386

Epoch: 5
Loss: 0.563478716895701
ROC train: 0.613647	val: 0.540496	test: 0.555978
PRC train: 0.634655	val: 0.623013	test: 0.605982

Epoch: 6
Loss: 0.5455314933427525
ROC train: 0.637234	val: 0.560482	test: 0.574787
PRC train: 0.647069	val: 0.630466	test: 0.612549

Epoch: 7
Loss: 0.5354246083600469
ROC train: 0.647779	val: 0.565873	test: 0.576007
PRC train: 0.653206	val: 0.635032	test: 0.615212

Epoch: 8
Loss: 0.5253514313434462
ROC train: 0.662216	val: 0.567188	test: 0.585051
PRC train: 0.663069	val: 0.634427	test: 0.618745

Epoch: 9
Loss: 0.5148604955422159
ROC train: 0.676916	val: 0.577151	test: 0.598459
PRC train: 0.671271	val: 0.638428	test: 0.623246

Epoch: 10
Loss: 0.5059257678204172
ROC train: 0.690168	val: 0.591346	test: 0.598819
PRC train: 0.680427	val: 0.645362	test: 0.624149

Epoch: 11
Loss: 0.5020267724036687
ROC train: 0.700683	val: 0.600205	test: 0.607349
PRC train: 0.686160	val: 0.650944	test: 0.627126

Epoch: 12
Loss: 0.497974245833323
ROC train: 0.713264	val: 0.596975	test: 0.613018
PRC train: 0.695571	val: 0.648276	test: 0.634720

Epoch: 13
Loss: 0.4912863401269047
ROC train: 0.723759	val: 0.594377	test: 0.613707
PRC train: 0.705652	val: 0.646941	test: 0.640386

Epoch: 14
Loss: 0.4882680048058246
ROC train: 0.734298	val: 0.592484	test: 0.608378
PRC train: 0.713287	val: 0.644937	test: 0.636811

Epoch: 15
Loss: 0.4813978818885218
ROC train: 0.742527	val: 0.597118	test: 0.605698
PRC train: 0.718422	val: 0.647870	test: 0.632277

Epoch: 16
Loss: 0.4795630305311498
ROC train: 0.751586	val: 0.597786	test: 0.611255
PRC train: 0.724774	val: 0.649769	test: 0.639508

Epoch: 17
Loss: 0.4791463243354023
ROC train: 0.761756	val: 0.596889	test: 0.610656
PRC train: 0.731829	val: 0.652861	test: 0.641354

Epoch: 18
Loss: 0.4710661442743104
ROC train: 0.767491	val: 0.595971	test: 0.609964
PRC train: 0.735757	val: 0.656874	test: 0.636054

Epoch: 19
Loss: 0.4679872447348788
ROC train: 0.768439	val: 0.591486	test: 0.611021
PRC train: 0.736344	val: 0.658563	test: 0.629660

Epoch: 20
Loss: 0.4681918722387876
ROC train: 0.779335	val: 0.598097	test: 0.619171
PRC train: 0.745547	val: 0.658527	test: 0.641971

Epoch: 21
Loss: 0.46367337432916544
ROC train: 0.783877	val: 0.609566	test: 0.617463
PRC train: 0.750292	val: 0.658938	test: 0.644409

Epoch: 22
Loss: 0.45371873592251727
ROC train: 0.792337	val: 0.611298	test: 0.619395
PRC train: 0.755374	val: 0.660259	test: 0.637839

Epoch: 23
Loss: 0.45300869489082335
ROC train: 0.795971	val: 0.610251	test: 0.608901
PRC train: 0.758920	val: 0.662010	test: 0.636351

Epoch: 24
Loss: 0.449222530512571
ROC train: 0.803396	val: 0.607642	test: 0.612560
PRC train: 0.767031	val: 0.660232	test: 0.640995

Epoch: 25
Loss: 0.4477832154669511
ROC train: 0.805914	val: 0.608069	test: 0.610115
PRC train: 0.768134	val: 0.660832	test: 0.635725

Epoch: 26
Loss: 0.4386451616456647
ROC train: 0.804488	val: 0.612777	test: 0.607483
PRC train: 0.765234	val: 0.665642	test: 0.637498

Epoch: 27
Loss: 0.4391678663837227
ROC train: 0.821043	val: 0.616164	test: 0.607213
PRC train: 0.781578	val: 0.662621	test: 0.640007

Epoch: 28
Loss: 0.4353989863996712
ROC train: 0.824117	val: 0.611778	test: 0.609252
PRC train: 0.782992	val: 0.662668	test: 0.638414

Epoch: 29
Loss: 0.43123083714175703
ROC train: 0.825872	val: 0.597564	test: 0.605153
PRC train: 0.783671	val: 0.658073	test: 0.633614

Epoch: 30
Loss: 0.4286560564237224
ROC train: 0.832546	val: 0.605132	test: 0.606898
PRC train: 0.789152	val: 0.670845	test: 0.633900

Epoch: 31
Loss: 0.4261390460374502
ROC train: 0.835388	val: 0.612606	test: 0.617668
PRC train: 0.790492	val: 0.671461	test: 0.639402

Epoch: 32
Loss: 0.420723952036251
ROC train: 0.839034	val: 0.608412	test: 0.613708Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.05.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:1
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.05
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/sider/noise=0.05
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/sider/noise=0.05/sider_scaff_1_20-05_14-43-32  ]
[ Using Seed :  1  ]
[ Using device :  cuda:1  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6899979128446775
ROC train: 0.548898	val: 0.534366	test: 0.519688
PRC train: 0.586032	val: 0.612456	test: 0.588513

Epoch: 2
Loss: 0.6451822870350623
ROC train: 0.559710	val: 0.508412	test: 0.512299
PRC train: 0.596159	val: 0.598169	test: 0.585285

Epoch: 3
Loss: 0.6073918054000786
ROC train: 0.548255	val: 0.494589	test: 0.496542
PRC train: 0.595496	val: 0.596312	test: 0.578531

Epoch: 4
Loss: 0.576494466804178
ROC train: 0.564506	val: 0.503092	test: 0.506403
PRC train: 0.606451	val: 0.600454	test: 0.584099

Epoch: 5
Loss: 0.5607259127480978
ROC train: 0.589654	val: 0.519820	test: 0.526842
PRC train: 0.619707	val: 0.606537	test: 0.592146

Epoch: 6
Loss: 0.5489472831992994
ROC train: 0.623664	val: 0.539200	test: 0.559942
PRC train: 0.637116	val: 0.613065	test: 0.607026

Epoch: 7
Loss: 0.535508332323744
ROC train: 0.642805	val: 0.554058	test: 0.575621
PRC train: 0.650023	val: 0.623421	test: 0.617990

Epoch: 8
Loss: 0.5244989039343269
ROC train: 0.654977	val: 0.570422	test: 0.582410
PRC train: 0.658239	val: 0.631672	test: 0.622629

Epoch: 9
Loss: 0.5168132936595843
ROC train: 0.664161	val: 0.580051	test: 0.582882
PRC train: 0.665580	val: 0.634403	test: 0.624736

Epoch: 10
Loss: 0.5074419843519837
ROC train: 0.681025	val: 0.584186	test: 0.592415
PRC train: 0.676869	val: 0.636712	test: 0.629133

Epoch: 11
Loss: 0.502905310727861
ROC train: 0.695467	val: 0.589794	test: 0.589147
PRC train: 0.688080	val: 0.638458	test: 0.625479

Epoch: 12
Loss: 0.5001466442030472
ROC train: 0.707748	val: 0.588497	test: 0.586728
PRC train: 0.695032	val: 0.638715	test: 0.622061

Epoch: 13
Loss: 0.492099094043491
ROC train: 0.720165	val: 0.588711	test: 0.591454
PRC train: 0.703668	val: 0.636929	test: 0.623804

Epoch: 14
Loss: 0.48862812063118843
ROC train: 0.724750	val: 0.583265	test: 0.595310
PRC train: 0.709470	val: 0.638377	test: 0.623966

Epoch: 15
Loss: 0.4842316784607812
ROC train: 0.736426	val: 0.590272	test: 0.598953
PRC train: 0.717853	val: 0.651222	test: 0.629564

Epoch: 16
Loss: 0.48152702765812777
ROC train: 0.746537	val: 0.595403	test: 0.608737
PRC train: 0.722195	val: 0.651664	test: 0.632848

Epoch: 17
Loss: 0.47437637849645736
ROC train: 0.754999	val: 0.580525	test: 0.600428
PRC train: 0.726947	val: 0.641423	test: 0.627095

Epoch: 18
Loss: 0.46968524274768014
ROC train: 0.764928	val: 0.597039	test: 0.589913
PRC train: 0.734158	val: 0.650526	test: 0.625829

Epoch: 19
Loss: 0.469928858145005
ROC train: 0.768575	val: 0.619125	test: 0.593470
PRC train: 0.737582	val: 0.662134	test: 0.627027

Epoch: 20
Loss: 0.45765369926976013
ROC train: 0.776701	val: 0.608799	test: 0.599110
PRC train: 0.743130	val: 0.651248	test: 0.632073

Epoch: 21
Loss: 0.4610684036125291
ROC train: 0.780735	val: 0.621136	test: 0.609850
PRC train: 0.744739	val: 0.656533	test: 0.638967

Epoch: 22
Loss: 0.45770431523165184
ROC train: 0.785416	val: 0.616561	test: 0.608923
PRC train: 0.747477	val: 0.652851	test: 0.630762

Epoch: 23
Loss: 0.454635250934445
ROC train: 0.794603	val: 0.611723	test: 0.607020
PRC train: 0.758623	val: 0.654570	test: 0.626725

Epoch: 24
Loss: 0.4538165033686493
ROC train: 0.796194	val: 0.623984	test: 0.602315
PRC train: 0.757252	val: 0.667462	test: 0.630182

Epoch: 25
Loss: 0.4432881909398291
ROC train: 0.799779	val: 0.610627	test: 0.604842
PRC train: 0.761999	val: 0.657617	test: 0.634198

Epoch: 26
Loss: 0.4457526512376284
ROC train: 0.807838	val: 0.612216	test: 0.599541
PRC train: 0.768303	val: 0.652638	test: 0.631305

Epoch: 27
Loss: 0.44418584708776077
ROC train: 0.811006	val: 0.622652	test: 0.584776
PRC train: 0.770169	val: 0.661478	test: 0.617683

Epoch: 28
Loss: 0.43829675206072205
ROC train: 0.815736	val: 0.610185	test: 0.596837
PRC train: 0.774712	val: 0.652189	test: 0.622040

Epoch: 29
Loss: 0.43691347372782674
ROC train: 0.817373	val: 0.616711	test: 0.596158
PRC train: 0.775380	val: 0.656864	test: 0.628134

Epoch: 30
Loss: 0.4323811411034065
ROC train: 0.820245	val: 0.617870	test: 0.604291
PRC train: 0.779515	val: 0.658403	test: 0.629961

Epoch: 31
Loss: 0.43231332079444806
ROC train: 0.824908	val: 0.618337	test: 0.601636
PRC train: 0.785055	val: 0.652190	test: 0.624357

Epoch: 32
Loss: 0.4258311743354685
ROC train: 0.820340	val: 0.614582	test: 0.590633Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.05.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:1
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.05
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/sider/noise=0.05
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/sider/noise=0.05/sider_scaff_2_20-05_14-43-32  ]
[ Using Seed :  2  ]
[ Using device :  cuda:1  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6826677158622418
ROC train: 0.542504	val: 0.522873	test: 0.488325
PRC train: 0.584265	val: 0.598957	test: 0.573372

Epoch: 2
Loss: 0.6425095099082958
ROC train: 0.560598	val: 0.509540	test: 0.500761
PRC train: 0.598552	val: 0.594860	test: 0.582977

Epoch: 3
Loss: 0.6048103126279223
ROC train: 0.565022	val: 0.501717	test: 0.497853
PRC train: 0.603961	val: 0.589684	test: 0.579127

Epoch: 4
Loss: 0.5854729079422322
ROC train: 0.583215	val: 0.510682	test: 0.507521
PRC train: 0.615343	val: 0.597629	test: 0.582912

Epoch: 5
Loss: 0.5535721980926889
ROC train: 0.612031	val: 0.533861	test: 0.537291
PRC train: 0.630470	val: 0.611194	test: 0.592988

Epoch: 6
Loss: 0.5452874531698572
ROC train: 0.628401	val: 0.546238	test: 0.555741
PRC train: 0.640493	val: 0.618277	test: 0.603220

Epoch: 7
Loss: 0.534311905919723
ROC train: 0.639917	val: 0.550496	test: 0.563087
PRC train: 0.648434	val: 0.623209	test: 0.607369

Epoch: 8
Loss: 0.5268421739664024
ROC train: 0.655924	val: 0.553248	test: 0.576181
PRC train: 0.659457	val: 0.628708	test: 0.614434

Epoch: 9
Loss: 0.5162243945169995
ROC train: 0.671891	val: 0.564449	test: 0.592490
PRC train: 0.670036	val: 0.638723	test: 0.627927

Epoch: 10
Loss: 0.5085908478830831
ROC train: 0.684615	val: 0.575007	test: 0.584590
PRC train: 0.677921	val: 0.644421	test: 0.616220

Epoch: 11
Loss: 0.5002698408710864
ROC train: 0.697386	val: 0.580817	test: 0.586889
PRC train: 0.687789	val: 0.647638	test: 0.617445

Epoch: 12
Loss: 0.500086977220532
ROC train: 0.711825	val: 0.592291	test: 0.585828
PRC train: 0.700987	val: 0.651417	test: 0.621096

Epoch: 13
Loss: 0.4955131102818549
ROC train: 0.720067	val: 0.600521	test: 0.584806
PRC train: 0.708073	val: 0.656401	test: 0.624709

Epoch: 14
Loss: 0.4858521266708517
ROC train: 0.728676	val: 0.598818	test: 0.588413
PRC train: 0.712711	val: 0.655014	test: 0.622346

Epoch: 15
Loss: 0.4825103349147676
ROC train: 0.729006	val: 0.603523	test: 0.579689
PRC train: 0.713430	val: 0.653343	test: 0.621399

Epoch: 16
Loss: 0.4821313142085958
ROC train: 0.749446	val: 0.616140	test: 0.591396
PRC train: 0.729464	val: 0.667994	test: 0.624203

Epoch: 17
Loss: 0.471811567338195
ROC train: 0.748855	val: 0.602745	test: 0.593568
PRC train: 0.731882	val: 0.664179	test: 0.623060

Epoch: 18
Loss: 0.4767307349852666
ROC train: 0.751178	val: 0.617136	test: 0.586161
PRC train: 0.728661	val: 0.664570	test: 0.625680

Epoch: 19
Loss: 0.46732271040940343
ROC train: 0.763261	val: 0.623827	test: 0.591053
PRC train: 0.738846	val: 0.665315	test: 0.623966

Epoch: 20
Loss: 0.46209414154922157
ROC train: 0.772963	val: 0.613319	test: 0.593166
PRC train: 0.748695	val: 0.657463	test: 0.624736

Epoch: 21
Loss: 0.4633445615764648
ROC train: 0.788386	val: 0.622596	test: 0.587125
PRC train: 0.759347	val: 0.666530	test: 0.618963

Epoch: 22
Loss: 0.45344144216447446
ROC train: 0.791174	val: 0.632949	test: 0.575817
PRC train: 0.760608	val: 0.679520	test: 0.614055

Epoch: 23
Loss: 0.4460256049552632
ROC train: 0.794071	val: 0.620898	test: 0.590675
PRC train: 0.764945	val: 0.668672	test: 0.620470

Epoch: 24
Loss: 0.4560987647806133
ROC train: 0.796972	val: 0.602453	test: 0.594114
PRC train: 0.768595	val: 0.656157	test: 0.621593

Epoch: 25
Loss: 0.4526124936770147
ROC train: 0.805456	val: 0.613031	test: 0.593248
PRC train: 0.770675	val: 0.663349	test: 0.619016

Epoch: 26
Loss: 0.4393572456988871
ROC train: 0.806870	val: 0.601967	test: 0.598821
PRC train: 0.775481	val: 0.657402	test: 0.623069

Epoch: 27
Loss: 0.4445937788889502
ROC train: 0.807416	val: 0.624454	test: 0.577293
PRC train: 0.776363	val: 0.676375	test: 0.619185

Epoch: 28
Loss: 0.43771899974320905
ROC train: 0.811481	val: 0.623088	test: 0.579538
PRC train: 0.779855	val: 0.676385	test: 0.613816

Epoch: 29
Loss: 0.4290900306462578
ROC train: 0.817262	val: 0.615008	test: 0.587429
PRC train: 0.785963	val: 0.664810	test: 0.618280

Epoch: 30
Loss: 0.4288878908803298
ROC train: 0.822040	val: 0.605456	test: 0.594081
PRC train: 0.789048	val: 0.659060	test: 0.622590

Epoch: 31
Loss: 0.4258507891667446
ROC train: 0.830584	val: 0.608882	test: 0.594055
PRC train: 0.795074	val: 0.665202	test: 0.623663

Epoch: 32
Loss: 0.4255177476173272
ROC train: 0.832206	val: 0.616421	test: 0.587084Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.2.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:3
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.2
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/sider/noise=0.2
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/sider/noise=0.2/sider_scaff_2_20-05_14-43-32  ]
[ Using Seed :  2  ]
[ Using device :  cuda:3  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6828234235374457
ROC train: 0.543322	val: 0.515304	test: 0.502372
PRC train: 0.584496	val: 0.601791	test: 0.577595

Epoch: 2
Loss: 0.6465463397999347
ROC train: 0.567709	val: 0.500333	test: 0.520439
PRC train: 0.603216	val: 0.588876	test: 0.584014

Epoch: 3
Loss: 0.61581356991303
ROC train: 0.571055	val: 0.500500	test: 0.515324
PRC train: 0.609490	val: 0.589528	test: 0.584902

Epoch: 4
Loss: 0.5911491532183901
ROC train: 0.572119	val: 0.505997	test: 0.502162
PRC train: 0.613596	val: 0.600208	test: 0.581682

Epoch: 5
Loss: 0.5637843848673241
ROC train: 0.597241	val: 0.524299	test: 0.508392
PRC train: 0.629047	val: 0.614627	test: 0.584505

Epoch: 6
Loss: 0.5486063693573917
ROC train: 0.621897	val: 0.537816	test: 0.525013
PRC train: 0.643576	val: 0.620764	test: 0.591863

Epoch: 7
Loss: 0.5351316013032354
ROC train: 0.640339	val: 0.552189	test: 0.538873
PRC train: 0.654909	val: 0.625741	test: 0.599087

Epoch: 8
Loss: 0.5247934195657734
ROC train: 0.658469	val: 0.558082	test: 0.545040
PRC train: 0.664994	val: 0.625075	test: 0.603628

Epoch: 9
Loss: 0.5147815662320623
ROC train: 0.674285	val: 0.558004	test: 0.552868
PRC train: 0.675241	val: 0.623663	test: 0.611782

Epoch: 10
Loss: 0.5091931446281486
ROC train: 0.687051	val: 0.557593	test: 0.555317
PRC train: 0.684649	val: 0.623572	test: 0.614025

Epoch: 11
Loss: 0.5000441924170334
ROC train: 0.701270	val: 0.569489	test: 0.558304
PRC train: 0.694382	val: 0.628804	test: 0.612839

Epoch: 12
Loss: 0.49853155831218154
ROC train: 0.715257	val: 0.570401	test: 0.558576
PRC train: 0.702026	val: 0.632152	test: 0.611367

Epoch: 13
Loss: 0.4931160704974894
ROC train: 0.727463	val: 0.574735	test: 0.559076
PRC train: 0.711445	val: 0.633495	test: 0.613854

Epoch: 14
Loss: 0.48423409815981844
ROC train: 0.734683	val: 0.585505	test: 0.561378
PRC train: 0.719315	val: 0.639631	test: 0.618805

Epoch: 15
Loss: 0.48175961325819905
ROC train: 0.743377	val: 0.599662	test: 0.564350
PRC train: 0.722998	val: 0.650796	test: 0.621987

Epoch: 16
Loss: 0.4838601920967246
ROC train: 0.755467	val: 0.601079	test: 0.551939
PRC train: 0.731422	val: 0.652822	test: 0.617472

Epoch: 17
Loss: 0.4738208596756898
ROC train: 0.765807	val: 0.571937	test: 0.548742
PRC train: 0.740578	val: 0.632848	test: 0.618083

Epoch: 18
Loss: 0.4750653452266807
ROC train: 0.776062	val: 0.568111	test: 0.549643
PRC train: 0.747410	val: 0.631599	test: 0.618985

Epoch: 19
Loss: 0.46678258849682486
ROC train: 0.772699	val: 0.605849	test: 0.563140
PRC train: 0.741962	val: 0.650860	test: 0.616317

Epoch: 20
Loss: 0.46263490419007514
ROC train: 0.779558	val: 0.592105	test: 0.571423
PRC train: 0.747196	val: 0.645544	test: 0.624275

Epoch: 21
Loss: 0.4598584602036885
ROC train: 0.789714	val: 0.592172	test: 0.557613
PRC train: 0.754668	val: 0.649034	test: 0.629631

Epoch: 22
Loss: 0.4541406609312818
ROC train: 0.796634	val: 0.603833	test: 0.567623
PRC train: 0.762699	val: 0.652983	test: 0.625494

Epoch: 23
Loss: 0.44725210401342086
ROC train: 0.801341	val: 0.592179	test: 0.575248
PRC train: 0.765899	val: 0.647972	test: 0.623857

Epoch: 24
Loss: 0.4501001881595245
ROC train: 0.811422	val: 0.595037	test: 0.576155
PRC train: 0.775390	val: 0.646993	test: 0.628516

Epoch: 25
Loss: 0.44799454023111174
ROC train: 0.815482	val: 0.594090	test: 0.573329
PRC train: 0.775673	val: 0.645237	test: 0.630813

Epoch: 26
Loss: 0.4385479170880203
ROC train: 0.821121	val: 0.572326	test: 0.568197
PRC train: 0.784215	val: 0.636433	test: 0.621795

Epoch: 27
Loss: 0.4431531715768159
ROC train: 0.823757	val: 0.579807	test: 0.562078
PRC train: 0.782100	val: 0.641848	test: 0.619944

Epoch: 28
Loss: 0.4285596629438741
ROC train: 0.827884	val: 0.589561	test: 0.558904
PRC train: 0.786215	val: 0.645565	test: 0.616966

Epoch: 29
Loss: 0.4314900647210303
ROC train: 0.836454	val: 0.586023	test: 0.532875
PRC train: 0.796317	val: 0.643736	test: 0.614939

Epoch: 30
Loss: 0.42835608191530355
ROC train: 0.838482	val: 0.574759	test: 0.543008
PRC train: 0.797365	val: 0.637047	test: 0.617516

Epoch: 31
Loss: 0.4239029920063354
ROC train: 0.839627	val: 0.585644	test: 0.540875
PRC train: 0.799355	val: 0.641882	test: 0.616793

Epoch: 32
Loss: 0.41749497342446756
ROC train: 0.842843	val: 0.603701	test: 0.517303Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.2.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:3
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.2
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/sider/noise=0.2
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/sider/noise=0.2/sider_scaff_3_20-05_14-43-32  ]
[ Using Seed :  3  ]
[ Using device :  cuda:3  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6942397272616354
ROC train: 0.536549	val: 0.517036	test: 0.523082
PRC train: 0.578872	val: 0.610963	test: 0.585647

Epoch: 2
Loss: 0.653441035149845
ROC train: 0.569440	val: 0.509409	test: 0.536869
PRC train: 0.599063	val: 0.603130	test: 0.595076

Epoch: 3
Loss: 0.6201922216642052
ROC train: 0.578799	val: 0.507477	test: 0.528845
PRC train: 0.608540	val: 0.601151	test: 0.591199

Epoch: 4
Loss: 0.595554285626109
ROC train: 0.581547	val: 0.508745	test: 0.520414
PRC train: 0.614868	val: 0.604062	test: 0.587073

Epoch: 5
Loss: 0.571143102204312
ROC train: 0.600371	val: 0.524668	test: 0.518589
PRC train: 0.628588	val: 0.610609	test: 0.590069

Epoch: 6
Loss: 0.5514662561366174
ROC train: 0.622400	val: 0.544493	test: 0.534921
PRC train: 0.641890	val: 0.620039	test: 0.600634

Epoch: 7
Loss: 0.5393920769692411
ROC train: 0.642789	val: 0.552473	test: 0.554414
PRC train: 0.653320	val: 0.623921	test: 0.611270

Epoch: 8
Loss: 0.5272970336910912
ROC train: 0.663193	val: 0.557714	test: 0.572543
PRC train: 0.667356	val: 0.623963	test: 0.617653

Epoch: 9
Loss: 0.5158021344470285
ROC train: 0.678177	val: 0.573283	test: 0.581199
PRC train: 0.678333	val: 0.630515	test: 0.620655

Epoch: 10
Loss: 0.505839168677119
ROC train: 0.688021	val: 0.581612	test: 0.579025
PRC train: 0.685390	val: 0.635649	test: 0.617076

Epoch: 11
Loss: 0.5021344706432203
ROC train: 0.699394	val: 0.590987	test: 0.581374
PRC train: 0.693360	val: 0.641213	test: 0.617748

Epoch: 12
Loss: 0.4958839960850959
ROC train: 0.708916	val: 0.589377	test: 0.585574
PRC train: 0.701415	val: 0.639461	test: 0.624754

Epoch: 13
Loss: 0.49144776124695166
ROC train: 0.719008	val: 0.580820	test: 0.583796
PRC train: 0.709626	val: 0.635535	test: 0.621925

Epoch: 14
Loss: 0.48850680774840416
ROC train: 0.731734	val: 0.584984	test: 0.579713
PRC train: 0.718296	val: 0.637408	test: 0.617421

Epoch: 15
Loss: 0.47818647242273754
ROC train: 0.741780	val: 0.596817	test: 0.571264
PRC train: 0.723671	val: 0.643808	test: 0.615277

Epoch: 16
Loss: 0.48088167895706146
ROC train: 0.754374	val: 0.603190	test: 0.571370
PRC train: 0.732842	val: 0.649106	test: 0.619098

Epoch: 17
Loss: 0.4756967864568666
ROC train: 0.766557	val: 0.595285	test: 0.572032
PRC train: 0.742609	val: 0.645254	test: 0.615923

Epoch: 18
Loss: 0.4721631497200615
ROC train: 0.770371	val: 0.588388	test: 0.574324
PRC train: 0.744015	val: 0.644410	test: 0.612273

Epoch: 19
Loss: 0.46756533305527836
ROC train: 0.778377	val: 0.589406	test: 0.582669
PRC train: 0.753614	val: 0.640902	test: 0.614687

Epoch: 20
Loss: 0.46717043773128364
ROC train: 0.786470	val: 0.600875	test: 0.578978
PRC train: 0.757137	val: 0.649835	test: 0.616520

Epoch: 21
Loss: 0.4584011501555757
ROC train: 0.792556	val: 0.606769	test: 0.573804
PRC train: 0.762607	val: 0.652808	test: 0.614409

Epoch: 22
Loss: 0.45917315344614495
ROC train: 0.800777	val: 0.602961	test: 0.574748
PRC train: 0.767988	val: 0.650119	test: 0.611882

Epoch: 23
Loss: 0.4491206019785509
ROC train: 0.809256	val: 0.596392	test: 0.577429
PRC train: 0.774002	val: 0.652912	test: 0.612166

Epoch: 24
Loss: 0.4474591473800233
ROC train: 0.813302	val: 0.596727	test: 0.578305
PRC train: 0.776374	val: 0.656395	test: 0.616428

Epoch: 25
Loss: 0.4410438990741482
ROC train: 0.813619	val: 0.591136	test: 0.585568
PRC train: 0.778526	val: 0.652877	test: 0.618645

Epoch: 26
Loss: 0.4366504386656743
ROC train: 0.819686	val: 0.582510	test: 0.583403
PRC train: 0.785364	val: 0.650019	test: 0.615489

Epoch: 27
Loss: 0.43270642415368704
ROC train: 0.826641	val: 0.582037	test: 0.574832
PRC train: 0.790055	val: 0.647991	test: 0.608805

Epoch: 28
Loss: 0.43071109706691646
ROC train: 0.831388	val: 0.573484	test: 0.567292
PRC train: 0.791190	val: 0.641083	test: 0.607147

Epoch: 29
Loss: 0.42891618062404674
ROC train: 0.833395	val: 0.571875	test: 0.568016
PRC train: 0.795053	val: 0.642215	test: 0.607413

Epoch: 30
Loss: 0.4289753251768862
ROC train: 0.837853	val: 0.582690	test: 0.573295
PRC train: 0.798212	val: 0.642573	test: 0.613273

Epoch: 31
Loss: 0.4269013151072241
ROC train: 0.835115	val: 0.592224	test: 0.580486
PRC train: 0.798203	val: 0.646973	test: 0.617954

Epoch: 32
Loss: 0.42103075253026223
ROC train: 0.844969	val: 0.577955	test: 0.575173Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.2.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:3
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.2
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/sider/noise=0.2
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/sider/noise=0.2/sider_scaff_1_20-05_14-43-32  ]
[ Using Seed :  1  ]
[ Using device :  cuda:3  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6895090208430932
ROC train: 0.540523	val: 0.530134	test: 0.515844
PRC train: 0.578745	val: 0.614715	test: 0.587463

Epoch: 2
Loss: 0.6490323765264385
ROC train: 0.567796	val: 0.528316	test: 0.529775
PRC train: 0.597332	val: 0.610686	test: 0.590949

Epoch: 3
Loss: 0.6157689605634303
ROC train: 0.567679	val: 0.513535	test: 0.521973
PRC train: 0.603319	val: 0.596811	test: 0.590346

Epoch: 4
Loss: 0.5831173413603394
ROC train: 0.561091	val: 0.506504	test: 0.513035
PRC train: 0.604687	val: 0.596254	test: 0.590178

Epoch: 5
Loss: 0.5675875063898945
ROC train: 0.570543	val: 0.510112	test: 0.506937
PRC train: 0.614426	val: 0.605019	test: 0.589728

Epoch: 6
Loss: 0.5512134428568765
ROC train: 0.609621	val: 0.534162	test: 0.525630
PRC train: 0.635026	val: 0.620081	test: 0.594988

Epoch: 7
Loss: 0.5368088022786781
ROC train: 0.638081	val: 0.557757	test: 0.538925
PRC train: 0.650493	val: 0.630156	test: 0.601990

Epoch: 8
Loss: 0.5244531581585111
ROC train: 0.657771	val: 0.573478	test: 0.547523
PRC train: 0.659967	val: 0.634840	test: 0.609659

Epoch: 9
Loss: 0.5162962357028668
ROC train: 0.665218	val: 0.571621	test: 0.544187
PRC train: 0.663448	val: 0.635364	test: 0.609417

Epoch: 10
Loss: 0.5067859289594997
ROC train: 0.678803	val: 0.577601	test: 0.545560
PRC train: 0.673371	val: 0.637294	test: 0.610267

Epoch: 11
Loss: 0.5015790288861288
ROC train: 0.694102	val: 0.583352	test: 0.550881
PRC train: 0.684560	val: 0.636961	test: 0.613537

Epoch: 12
Loss: 0.49644132275482633
ROC train: 0.710423	val: 0.586865	test: 0.559464
PRC train: 0.697577	val: 0.637738	test: 0.616479

Epoch: 13
Loss: 0.49227986265181595
ROC train: 0.725426	val: 0.586024	test: 0.573228
PRC train: 0.707888	val: 0.637674	test: 0.619110

Epoch: 14
Loss: 0.49092742300407677
ROC train: 0.723708	val: 0.575274	test: 0.569224
PRC train: 0.708993	val: 0.631375	test: 0.619253

Epoch: 15
Loss: 0.48515926471540405
ROC train: 0.739811	val: 0.594330	test: 0.560908
PRC train: 0.721654	val: 0.644399	test: 0.615923

Epoch: 16
Loss: 0.48150717854275304
ROC train: 0.748321	val: 0.598210	test: 0.572882
PRC train: 0.727721	val: 0.650865	test: 0.622145

Epoch: 17
Loss: 0.47466145289045947
ROC train: 0.759046	val: 0.589887	test: 0.585179
PRC train: 0.734928	val: 0.647311	test: 0.631210

Epoch: 18
Loss: 0.4717344647040148
ROC train: 0.767561	val: 0.585161	test: 0.580494
PRC train: 0.739860	val: 0.649503	test: 0.630803

Epoch: 19
Loss: 0.4680842112697878
ROC train: 0.768694	val: 0.591960	test: 0.575394
PRC train: 0.744196	val: 0.654262	test: 0.622847

Epoch: 20
Loss: 0.46295651816748107
ROC train: 0.776498	val: 0.591993	test: 0.574878
PRC train: 0.751685	val: 0.650980	test: 0.620710

Epoch: 21
Loss: 0.46316065868734146
ROC train: 0.781675	val: 0.593130	test: 0.573735
PRC train: 0.756244	val: 0.652461	test: 0.618095

Epoch: 22
Loss: 0.4572796090209389
ROC train: 0.788341	val: 0.587063	test: 0.570863
PRC train: 0.759475	val: 0.653507	test: 0.616152

Epoch: 23
Loss: 0.45118537011492704
ROC train: 0.796799	val: 0.583117	test: 0.572890
PRC train: 0.763021	val: 0.649669	test: 0.621490

Epoch: 24
Loss: 0.44677602766132163
ROC train: 0.806173	val: 0.585983	test: 0.581864
PRC train: 0.771349	val: 0.655277	test: 0.625164

Epoch: 25
Loss: 0.4490865530733836
ROC train: 0.808794	val: 0.596421	test: 0.573738
PRC train: 0.772403	val: 0.659781	test: 0.622396

Epoch: 26
Loss: 0.44511504202593455
ROC train: 0.815180	val: 0.597270	test: 0.576786
PRC train: 0.776204	val: 0.655627	test: 0.624152

Epoch: 27
Loss: 0.4403031363334411
ROC train: 0.818748	val: 0.604542	test: 0.581249
PRC train: 0.779974	val: 0.658989	test: 0.623443

Epoch: 28
Loss: 0.43824303434200473
ROC train: 0.823855	val: 0.603246	test: 0.585297
PRC train: 0.785216	val: 0.658139	test: 0.626730

Epoch: 29
Loss: 0.43038278634061394
ROC train: 0.827220	val: 0.595535	test: 0.577302
PRC train: 0.785050	val: 0.654141	test: 0.621944

Epoch: 30
Loss: 0.4278834663466434
ROC train: 0.828977	val: 0.598384	test: 0.571332
PRC train: 0.788450	val: 0.658719	test: 0.618915

Epoch: 31
Loss: 0.4302912186223805
ROC train: 0.838878	val: 0.587491	test: 0.581126
PRC train: 0.796923	val: 0.652681	test: 0.629360

Epoch: 32
Loss: 0.4207647756785723
ROC train: 0.840135	val: 0.576111	test: 0.575790
PRC train: 0.754159	val: 0.654803	test: 0.631587

Epoch: 34
Loss: 0.44629155873382614
ROC train: 0.779874	val: 0.602650	test: 0.618413
PRC train: 0.750443	val: 0.656280	test: 0.633192

Epoch: 35
Loss: 0.45189206536549226
ROC train: 0.790727	val: 0.618461	test: 0.621307
PRC train: 0.758866	val: 0.663938	test: 0.636663

Epoch: 36
Loss: 0.44687440566239
ROC train: 0.794255	val: 0.628321	test: 0.606504
PRC train: 0.761743	val: 0.668908	test: 0.630209

Epoch: 37
Loss: 0.4416030384485052
ROC train: 0.798289	val: 0.621538	test: 0.609085
PRC train: 0.766387	val: 0.666236	test: 0.628562

Epoch: 38
Loss: 0.44266521384162616
ROC train: 0.797271	val: 0.618791	test: 0.604746
PRC train: 0.764961	val: 0.665614	test: 0.626096

Epoch: 39
Loss: 0.44299607385409673
ROC train: 0.801818	val: 0.626891	test: 0.605659
PRC train: 0.766269	val: 0.665284	test: 0.627742

Epoch: 40
Loss: 0.43561647453776614
ROC train: 0.800683	val: 0.621869	test: 0.607440
PRC train: 0.768369	val: 0.663221	test: 0.631631

Epoch: 41
Loss: 0.4331719253602725
ROC train: 0.804796	val: 0.617246	test: 0.612100
PRC train: 0.773267	val: 0.664436	test: 0.632935

Epoch: 42
Loss: 0.43783167834706405
ROC train: 0.810782	val: 0.627096	test: 0.608816
PRC train: 0.776352	val: 0.670159	test: 0.634681

Epoch: 43
Loss: 0.43764390659329244
ROC train: 0.812076	val: 0.626030	test: 0.604815
PRC train: 0.776612	val: 0.672992	test: 0.630706

Epoch: 44
Loss: 0.4349562340236325
ROC train: 0.812067	val: 0.617831	test: 0.600739
PRC train: 0.774946	val: 0.672893	test: 0.628716

Epoch: 45
Loss: 0.43121300862538375
ROC train: 0.814826	val: 0.612922	test: 0.609210
PRC train: 0.782860	val: 0.666762	test: 0.632845

Epoch: 46
Loss: 0.4317642511018914
ROC train: 0.820289	val: 0.617975	test: 0.605832
PRC train: 0.786895	val: 0.670666	test: 0.629085

Epoch: 47
Loss: 0.4298482352622524
ROC train: 0.823724	val: 0.629181	test: 0.600420
PRC train: 0.787865	val: 0.673151	test: 0.627092

Epoch: 48
Loss: 0.41885648368157025
ROC train: 0.821578	val: 0.609510	test: 0.606143
PRC train: 0.787163	val: 0.666417	test: 0.630506

Epoch: 49
Loss: 0.42640278516458796
ROC train: 0.818120	val: 0.607314	test: 0.603805
PRC train: 0.786819	val: 0.663986	test: 0.632504

Epoch: 50
Loss: 0.4214245851377635
ROC train: 0.831237	val: 0.621352	test: 0.600522
PRC train: 0.794756	val: 0.672563	test: 0.627262

Epoch: 51
Loss: 0.41634181091942224
ROC train: 0.831211	val: 0.617809	test: 0.600772
PRC train: 0.792940	val: 0.666828	test: 0.627063

Epoch: 52
Loss: 0.4178504449116177
ROC train: 0.830453	val: 0.610963	test: 0.605210
PRC train: 0.793356	val: 0.662755	test: 0.629569

Epoch: 53
Loss: 0.4168649711667952
ROC train: 0.827759	val: 0.606298	test: 0.614807
PRC train: 0.791915	val: 0.663381	test: 0.633130

Epoch: 54
Loss: 0.41318884267743766
ROC train: 0.836937	val: 0.627882	test: 0.615252
PRC train: 0.798931	val: 0.671761	test: 0.636483

Epoch: 55
Loss: 0.41677791140062226
ROC train: 0.836105	val: 0.619459	test: 0.604055
PRC train: 0.798539	val: 0.669025	test: 0.633853

Epoch: 56
Loss: 0.4118813605399746
ROC train: 0.835591	val: 0.605951	test: 0.595333
PRC train: 0.799997	val: 0.667323	test: 0.628363

Epoch: 57
Loss: 0.4105530163294248
ROC train: 0.843211	val: 0.637939	test: 0.586384
PRC train: 0.805185	val: 0.681101	test: 0.624997

Epoch: 58
Loss: 0.4105034755302815
ROC train: 0.843113	val: 0.635921	test: 0.594149
PRC train: 0.803921	val: 0.679030	test: 0.628576

Epoch: 59
Loss: 0.41748353021214124
ROC train: 0.844466	val: 0.631202	test: 0.590170
PRC train: 0.805966	val: 0.675024	test: 0.624817

Epoch: 60
Loss: 0.40939326365093287
ROC train: 0.846653	val: 0.624942	test: 0.593388
PRC train: 0.807312	val: 0.674610	test: 0.622698

Epoch: 61
Loss: 0.40802153347217107
ROC train: 0.849001	val: 0.633176	test: 0.591934
PRC train: 0.807654	val: 0.679497	test: 0.623109

Epoch: 62
Loss: 0.4074445833112813
ROC train: 0.850593	val: 0.646640	test: 0.593629
PRC train: 0.809699	val: 0.682736	test: 0.628464

Epoch: 63
Loss: 0.40871273740515424
ROC train: 0.853353	val: 0.647725	test: 0.600115
PRC train: 0.811945	val: 0.681411	test: 0.627963

Epoch: 64
Loss: 0.40796513830655234
ROC train: 0.853974	val: 0.634942	test: 0.595088
PRC train: 0.814105	val: 0.673378	test: 0.623015

Epoch: 65
Loss: 0.3986065517163483
ROC train: 0.854473	val: 0.627218	test: 0.598351
PRC train: 0.815551	val: 0.671667	test: 0.626959

Epoch: 66
Loss: 0.4004921467862349
ROC train: 0.854915	val: 0.624550	test: 0.597933
PRC train: 0.817104	val: 0.671901	test: 0.627680

Epoch: 67
Loss: 0.39699956573715767
ROC train: 0.857755	val: 0.627564	test: 0.604092
PRC train: 0.819509	val: 0.673214	test: 0.633003

Epoch: 68
Loss: 0.39603310791135027
ROC train: 0.860364	val: 0.630227	test: 0.604195
PRC train: 0.818566	val: 0.673722	test: 0.632904

Epoch: 69
Loss: 0.3939157341538544
ROC train: 0.864257	val: 0.642112	test: 0.596566
PRC train: 0.821845	val: 0.676774	test: 0.625468

Epoch: 70
Loss: 0.39199555938676484
ROC train: 0.864345	val: 0.652052	test: 0.596340
PRC train: 0.821064	val: 0.683559	test: 0.625382

Epoch: 71
Loss: 0.39378759906050564
ROC train: 0.865926	val: 0.643370	test: 0.593317
PRC train: 0.823581	val: 0.677984	test: 0.625568

Epoch: 72
Loss: 0.3929912632174557
ROC train: 0.863110	val: 0.621146	test: 0.602966
PRC train: 0.824404	val: 0.671295	test: 0.629879

Epoch: 73
Loss: 0.3867398314970108
ROC train: 0.866615	val: 0.625182	test: 0.604710
PRC train: 0.826757	val: 0.670379	test: 0.631868

Epoch: 74
Loss: 0.38884143333417265
ROC train: 0.870407	val: 0.633921	test: 0.607211
PRC train: 0.829281	val: 0.675924	test: 0.630575

Epoch: 75
Loss: 0.38440216836585744
ROC train: 0.867795	val: 0.626497	test: 0.603669
PRC train: 0.829315	val: 0.671258	test: 0.635162

Epoch: 76
Loss: 0.39198228954170744
ROC train: 0.865548	val: 0.618418	test: 0.593541
PRC train: 0.826794	val: 0.673879	test: 0.624659

Epoch: 77
Loss: 0.38526135998738287
ROC train: 0.870014	val: 0.630085	test: 0.591849
PRC train: 0.829256	val: 0.676468	test: 0.625153

Epoch: 78
Loss: 0.3819513166563297
ROC train: 0.873452	val: 0.636560	test: 0.608491
PRC train: 0.832671	val: 0.675030	test: 0.632366

Epoch: 79
Loss: 0.38556315900558713
ROC train: 0.873197	val: 0.645871	test: 0.599027
PRC train: 0.834147	val: 0.678077	test: 0.632632

Epoch: 80
Loss: 0.3850704200936904
ROC train: 0.873680	val: 0.631138	test: 0.603795
PRC train: 0.833549	val: 0.673292	test: 0.633543

Epoch: 81
Loss: 0.38772527386235767
ROC train: 0.873159	val: 0.634184	test: 0.602365
PRC train: 0.832896	val: 0.677651	test: 0.629547

Epoch: 82
Loss: 0.38337096238017393
ROC train: 0.875773	val: 0.636113	test: 0.598591
PRC train: 0.835328	val: 0.677984	test: 0.626173

Epoch: 83
Loss: 0.37815625969114297
ROC train: 0.879684	val: 0.643167	test: 0.596651
PRC train: 0.840215	val: 0.681604	test: 0.626981

Epoch: 84
Loss: 0.3778033868228269
ROC train: 0.883586	val: 0.632581	test: 0.586274
PRC train: 0.842208	val: 0.676118	test: 0.620813

Epoch: 85
Loss: 0.37239693864815376
ROC train: 0.882407	val: 0.610481	test: 0.589640
PRC train: 0.840441	val: 0.669166	test: 0.622172

Epoch: 86
Loss: 0.37399102199251216
ROC train: 0.884503	val: 0.624656	test: 0.590246
PRC train: 0.842946	val: 0.670828	test: 0.625429

Epoch: 87
Loss: 0.3785373857021848
ROC train: 0.883712	val: 0.641696	test: 0.594369
PRC train: 0.840765	val: 0.677133	test: 0.627764

Epoch: 88
Loss: 0.37569306166951916
ROC train: 0.884259	val: 0.638829	test: 0.589048
PRC train: 0.843144	val: 0.676584	test: 0.624175

Epoch: 89
Loss: 0.374605867727986
ROC train: 0.884517	val: 0.637489	test: 0.590579
PRC train: 0.844547	val: 0.680071	test: 0.622865

Epoch: 90
Loss: 0.38070307835380474
ROC train: 0.887040	val: 0.633783	test: 0.611768
PRC train: 0.846340	val: 0.674206	test: 0.630586

Epoch: 91
Loss: 0.369263946427556
ROC train: 0.889510	val: 0.628431	test: 0.606849
PRC train: 0.847808	val: 0.670195	test: 0.631862

Epoch: 92
Loss: 0.37588310613868026
ROC train: 0.891710	val: 0.627217	test: 0.605313
PRC train: 0.851558	val: 0.668738	test: 0.633366

Epoch: 93
Loss: 0.36877965761608344
ROC train: 0.890422	val: 0.628744	test: 0.596718
PRC train: 0.852339	val: 0.670609	test: 0.632325

Epoch: 94
Loss: 0.367314469351174
ROC train: 0.892575	val: 0.633122	test: 0.595842
PRC train: 0.765866	val: 0.666139	test: 0.638401

Epoch: 34
Loss: 0.44575069381736565
ROC train: 0.798188	val: 0.621166	test: 0.604213
PRC train: 0.768691	val: 0.663100	test: 0.641531

Epoch: 35
Loss: 0.4445533654998237
ROC train: 0.797287	val: 0.619382	test: 0.600963
PRC train: 0.767656	val: 0.664547	test: 0.639632

Epoch: 36
Loss: 0.4390592713634035
ROC train: 0.800113	val: 0.611795	test: 0.612848
PRC train: 0.770272	val: 0.662155	test: 0.640802

Epoch: 37
Loss: 0.44169394913039806
ROC train: 0.797746	val: 0.608713	test: 0.614123
PRC train: 0.766563	val: 0.657656	test: 0.639622

Epoch: 38
Loss: 0.44174633520197376
ROC train: 0.805514	val: 0.612194	test: 0.614520
PRC train: 0.773556	val: 0.656598	test: 0.642511

Epoch: 39
Loss: 0.435770058037037
ROC train: 0.808255	val: 0.613192	test: 0.605656
PRC train: 0.775828	val: 0.661434	test: 0.634960

Epoch: 40
Loss: 0.440363430110531
ROC train: 0.810286	val: 0.613359	test: 0.606912
PRC train: 0.774105	val: 0.662775	test: 0.634866

Epoch: 41
Loss: 0.4292656840169461
ROC train: 0.814666	val: 0.602221	test: 0.609714
PRC train: 0.780368	val: 0.654559	test: 0.638548

Epoch: 42
Loss: 0.4263143283696236
ROC train: 0.816392	val: 0.600776	test: 0.611464
PRC train: 0.783843	val: 0.653711	test: 0.641427

Epoch: 43
Loss: 0.43219799822710153
ROC train: 0.819632	val: 0.616102	test: 0.600577
PRC train: 0.785855	val: 0.661050	test: 0.638370

Epoch: 44
Loss: 0.4319505154048877
ROC train: 0.821931	val: 0.627133	test: 0.603465
PRC train: 0.787479	val: 0.667311	test: 0.639890

Epoch: 45
Loss: 0.4257459272546523
ROC train: 0.818943	val: 0.615481	test: 0.611070
PRC train: 0.787220	val: 0.661119	test: 0.639124

Epoch: 46
Loss: 0.4269009303351111
ROC train: 0.824838	val: 0.620110	test: 0.610908
PRC train: 0.789641	val: 0.661180	test: 0.638937

Epoch: 47
Loss: 0.42791138631805625
ROC train: 0.829569	val: 0.622859	test: 0.606947
PRC train: 0.793573	val: 0.663532	test: 0.640614

Epoch: 48
Loss: 0.42565056711245236
ROC train: 0.831849	val: 0.603173	test: 0.613318
PRC train: 0.797077	val: 0.660469	test: 0.642034

Epoch: 49
Loss: 0.41830605516241154
ROC train: 0.831290	val: 0.601701	test: 0.615708
PRC train: 0.793780	val: 0.657838	test: 0.642355

Epoch: 50
Loss: 0.42035943199010645
ROC train: 0.830446	val: 0.613367	test: 0.611177
PRC train: 0.792379	val: 0.657881	test: 0.639651

Epoch: 51
Loss: 0.42349291302047154
ROC train: 0.829602	val: 0.609272	test: 0.617610
PRC train: 0.792750	val: 0.656118	test: 0.644388

Epoch: 52
Loss: 0.4163641444999538
ROC train: 0.835414	val: 0.615294	test: 0.601453
PRC train: 0.797807	val: 0.664190	test: 0.635398

Epoch: 53
Loss: 0.4195927426390448
ROC train: 0.841096	val: 0.610213	test: 0.605609
PRC train: 0.805026	val: 0.664794	test: 0.636302

Epoch: 54
Loss: 0.4180602233477173
ROC train: 0.839949	val: 0.604133	test: 0.610350
PRC train: 0.803944	val: 0.659890	test: 0.636270

Epoch: 55
Loss: 0.41435819170318827
ROC train: 0.840483	val: 0.612173	test: 0.605787
PRC train: 0.802927	val: 0.662765	test: 0.634540

Epoch: 56
Loss: 0.4119055902477333
ROC train: 0.844556	val: 0.612226	test: 0.607344
PRC train: 0.806984	val: 0.664205	test: 0.635992

Epoch: 57
Loss: 0.4138181102488911
ROC train: 0.848750	val: 0.623142	test: 0.611747
PRC train: 0.808590	val: 0.666736	test: 0.635842

Epoch: 58
Loss: 0.4094745657153142
ROC train: 0.849679	val: 0.622219	test: 0.601622
PRC train: 0.808704	val: 0.669177	test: 0.632638

Epoch: 59
Loss: 0.40675391797606536
ROC train: 0.849054	val: 0.604990	test: 0.601712
PRC train: 0.811459	val: 0.661741	test: 0.634047

Epoch: 60
Loss: 0.410442423566975
ROC train: 0.852653	val: 0.601645	test: 0.599011
PRC train: 0.812775	val: 0.659178	test: 0.631344

Epoch: 61
Loss: 0.4080672874146408
ROC train: 0.851411	val: 0.608542	test: 0.600606
PRC train: 0.810707	val: 0.662134	test: 0.632544

Epoch: 62
Loss: 0.40791730302533374
ROC train: 0.853569	val: 0.621394	test: 0.605754
PRC train: 0.812189	val: 0.669719	test: 0.633937

Epoch: 63
Loss: 0.4018287624998266
ROC train: 0.860066	val: 0.623816	test: 0.612296
PRC train: 0.818922	val: 0.669863	test: 0.636812

Epoch: 64
Loss: 0.40423417735112094
ROC train: 0.859672	val: 0.618223	test: 0.610024
PRC train: 0.816333	val: 0.667034	test: 0.635793

Epoch: 65
Loss: 0.4000758508260504
ROC train: 0.861392	val: 0.621137	test: 0.593768
PRC train: 0.820302	val: 0.669880	test: 0.631990

Epoch: 66
Loss: 0.4038151562113222
ROC train: 0.861305	val: 0.622025	test: 0.600877
PRC train: 0.824743	val: 0.669378	test: 0.636171

Epoch: 67
Loss: 0.4020570976487952
ROC train: 0.861401	val: 0.613694	test: 0.607841
PRC train: 0.823137	val: 0.663251	test: 0.635229

Epoch: 68
Loss: 0.3924931994266215
ROC train: 0.864984	val: 0.619787	test: 0.600420
PRC train: 0.823348	val: 0.668259	test: 0.634085

Epoch: 69
Loss: 0.39695037423451085
ROC train: 0.866491	val: 0.614197	test: 0.601732
PRC train: 0.824027	val: 0.668985	test: 0.634284

Epoch: 70
Loss: 0.3975604839298095
ROC train: 0.864213	val: 0.612124	test: 0.602741
PRC train: 0.820445	val: 0.661168	test: 0.632506

Epoch: 71
Loss: 0.3882621823158908
ROC train: 0.871126	val: 0.618600	test: 0.606090
PRC train: 0.830009	val: 0.666605	test: 0.635003

Epoch: 72
Loss: 0.39203414604364484
ROC train: 0.868121	val: 0.620469	test: 0.593062
PRC train: 0.828194	val: 0.665606	test: 0.629969

Epoch: 73
Loss: 0.3856780654112864
ROC train: 0.870735	val: 0.612574	test: 0.603686
PRC train: 0.832371	val: 0.661288	test: 0.633424

Epoch: 74
Loss: 0.38225927581984304
ROC train: 0.869366	val: 0.604514	test: 0.614904
PRC train: 0.833516	val: 0.658373	test: 0.637445

Epoch: 75
Loss: 0.3854682038720854
ROC train: 0.876263	val: 0.629524	test: 0.595567
PRC train: 0.839251	val: 0.676860	test: 0.628312

Epoch: 76
Loss: 0.39000240733214514
ROC train: 0.876197	val: 0.634989	test: 0.601565
PRC train: 0.837989	val: 0.677972	test: 0.630388

Epoch: 77
Loss: 0.3882813487962151
ROC train: 0.878187	val: 0.625294	test: 0.606121
PRC train: 0.840874	val: 0.669505	test: 0.632020

Epoch: 78
Loss: 0.3834675393674932
ROC train: 0.876615	val: 0.620729	test: 0.594714
PRC train: 0.837981	val: 0.668348	test: 0.628762

Epoch: 79
Loss: 0.384279689676879
ROC train: 0.877795	val: 0.612489	test: 0.602088
PRC train: 0.840309	val: 0.664832	test: 0.634920

Epoch: 80
Loss: 0.38661412888415303
ROC train: 0.879696	val: 0.617560	test: 0.594636
PRC train: 0.842646	val: 0.664779	test: 0.630103

Epoch: 81
Loss: 0.3809566084546017
ROC train: 0.883971	val: 0.624488	test: 0.592977
PRC train: 0.845505	val: 0.670534	test: 0.630603

Epoch: 82
Loss: 0.38030333096981805
ROC train: 0.884365	val: 0.618286	test: 0.593876
PRC train: 0.844880	val: 0.667262	test: 0.631291

Epoch: 83
Loss: 0.3749666457757055
ROC train: 0.887884	val: 0.628071	test: 0.590213
PRC train: 0.848327	val: 0.670712	test: 0.629080

Epoch: 84
Loss: 0.3749313042968928
ROC train: 0.886980	val: 0.628104	test: 0.605899
PRC train: 0.848145	val: 0.673416	test: 0.636104

Epoch: 85
Loss: 0.3787546355839687
ROC train: 0.886948	val: 0.629518	test: 0.596239
PRC train: 0.848396	val: 0.673576	test: 0.632653

Epoch: 86
Loss: 0.37246801906531596
ROC train: 0.889883	val: 0.632643	test: 0.588595
PRC train: 0.851460	val: 0.674427	test: 0.628225

Epoch: 87
Loss: 0.3730515127430079
ROC train: 0.888193	val: 0.622806	test: 0.595117
PRC train: 0.850842	val: 0.669444	test: 0.631541

Epoch: 88
Loss: 0.36934516684230995
ROC train: 0.890919	val: 0.618727	test: 0.600302
PRC train: 0.851900	val: 0.670093	test: 0.634179

Epoch: 89
Loss: 0.3707423840909222
ROC train: 0.888591	val: 0.618448	test: 0.605340
PRC train: 0.850422	val: 0.670849	test: 0.635610

Epoch: 90
Loss: 0.37440346914655137
ROC train: 0.895155	val: 0.629781	test: 0.600004
PRC train: 0.856509	val: 0.673368	test: 0.629629

Epoch: 91
Loss: 0.3633829065457789
ROC train: 0.893962	val: 0.631613	test: 0.591269
PRC train: 0.856634	val: 0.676400	test: 0.624184

Epoch: 92
Loss: 0.3713126431678278
ROC train: 0.895940	val: 0.625240	test: 0.595064
PRC train: 0.859501	val: 0.672726	test: 0.626761

Epoch: 93
Loss: 0.3683134829587675
ROC train: 0.896968	val: 0.625833	test: 0.598085
PRC train: 0.859992	val: 0.674195	test: 0.628443

Epoch: 94
Loss: 0.36275775317471687
ROC train: 0.896979	val: 0.631663	test: 0.596151
PRC train: 0.767318	val: 0.669301	test: 0.637078

Epoch: 34
Loss: 0.44669028539466893
ROC train: 0.800532	val: 0.625283	test: 0.614281
PRC train: 0.769682	val: 0.665500	test: 0.631459

Epoch: 35
Loss: 0.444345807707192
ROC train: 0.806661	val: 0.622026	test: 0.616541
PRC train: 0.772882	val: 0.663932	test: 0.630882

Epoch: 36
Loss: 0.44278035732134724
ROC train: 0.802765	val: 0.610661	test: 0.608992
PRC train: 0.767496	val: 0.659548	test: 0.630173

Epoch: 37
Loss: 0.4346890991815505
ROC train: 0.807043	val: 0.618130	test: 0.605382
PRC train: 0.773030	val: 0.659683	test: 0.629816

Epoch: 38
Loss: 0.4355341858389573
ROC train: 0.808401	val: 0.620769	test: 0.602459
PRC train: 0.776118	val: 0.660677	test: 0.626436

Epoch: 39
Loss: 0.4409866243045192
ROC train: 0.813894	val: 0.618927	test: 0.597833
PRC train: 0.780042	val: 0.663154	test: 0.625321

Epoch: 40
Loss: 0.44413981833409516
ROC train: 0.811413	val: 0.607686	test: 0.601489
PRC train: 0.776544	val: 0.654418	test: 0.627677

Epoch: 41
Loss: 0.4301842242669752
ROC train: 0.814325	val: 0.608113	test: 0.609541
PRC train: 0.777998	val: 0.656527	test: 0.628194

Epoch: 42
Loss: 0.4351239624026668
ROC train: 0.820410	val: 0.611877	test: 0.614448
PRC train: 0.783366	val: 0.658549	test: 0.630796

Epoch: 43
Loss: 0.42772018884515794
ROC train: 0.823044	val: 0.615678	test: 0.607007
PRC train: 0.789030	val: 0.663360	test: 0.631884

Epoch: 44
Loss: 0.4279537637391333
ROC train: 0.824131	val: 0.614990	test: 0.600479
PRC train: 0.792563	val: 0.660793	test: 0.629875

Epoch: 45
Loss: 0.42772736569716374
ROC train: 0.824698	val: 0.623008	test: 0.599077
PRC train: 0.792471	val: 0.667547	test: 0.629414

Epoch: 46
Loss: 0.428289210299105
ROC train: 0.827802	val: 0.625302	test: 0.602091
PRC train: 0.793878	val: 0.668121	test: 0.629719

Epoch: 47
Loss: 0.4276482148002317
ROC train: 0.829715	val: 0.630953	test: 0.600630
PRC train: 0.795962	val: 0.672191	test: 0.628536

Epoch: 48
Loss: 0.4227260692673278
ROC train: 0.831287	val: 0.629216	test: 0.600230
PRC train: 0.796656	val: 0.670854	test: 0.624212

Epoch: 49
Loss: 0.4213262670204612
ROC train: 0.827918	val: 0.609263	test: 0.604094
PRC train: 0.793633	val: 0.659822	test: 0.624029

Epoch: 50
Loss: 0.4180853795761895
ROC train: 0.833342	val: 0.601419	test: 0.601340
PRC train: 0.795709	val: 0.655891	test: 0.622845

Epoch: 51
Loss: 0.4172592576806594
ROC train: 0.830914	val: 0.595772	test: 0.591473
PRC train: 0.792547	val: 0.651645	test: 0.618242

Epoch: 52
Loss: 0.4156089638285135
ROC train: 0.842385	val: 0.623108	test: 0.594334
PRC train: 0.806314	val: 0.667027	test: 0.621684

Epoch: 53
Loss: 0.41250437124366945
ROC train: 0.841757	val: 0.631527	test: 0.594414
PRC train: 0.803428	val: 0.670216	test: 0.620610

Epoch: 54
Loss: 0.4120679096333177
ROC train: 0.840410	val: 0.608903	test: 0.590721
PRC train: 0.800961	val: 0.659031	test: 0.623200

Epoch: 55
Loss: 0.4139394037544858
ROC train: 0.843642	val: 0.613298	test: 0.600952
PRC train: 0.805654	val: 0.663074	test: 0.625124

Epoch: 56
Loss: 0.4146669647980315
ROC train: 0.847690	val: 0.630534	test: 0.595319
PRC train: 0.809602	val: 0.673006	test: 0.622258

Epoch: 57
Loss: 0.40597617029534794
ROC train: 0.849478	val: 0.626043	test: 0.596257
PRC train: 0.811308	val: 0.671321	test: 0.624621

Epoch: 58
Loss: 0.4078219265275882
ROC train: 0.847854	val: 0.621776	test: 0.592327
PRC train: 0.810614	val: 0.667553	test: 0.624723

Epoch: 59
Loss: 0.40390609174948205
ROC train: 0.853042	val: 0.622526	test: 0.587480
PRC train: 0.816752	val: 0.668869	test: 0.622028

Epoch: 60
Loss: 0.4096585870093235
ROC train: 0.855605	val: 0.622455	test: 0.577510
PRC train: 0.817978	val: 0.664848	test: 0.621596

Epoch: 61
Loss: 0.4001632377306139
ROC train: 0.857196	val: 0.631405	test: 0.585816
PRC train: 0.819133	val: 0.668973	test: 0.625411

Epoch: 62
Loss: 0.40923901542794566
ROC train: 0.858885	val: 0.621792	test: 0.596558
PRC train: 0.821722	val: 0.665246	test: 0.628521

Epoch: 63
Loss: 0.40784411858247277
ROC train: 0.860297	val: 0.612754	test: 0.595876
PRC train: 0.822250	val: 0.661838	test: 0.626324

Epoch: 64
Loss: 0.3993267720763134
ROC train: 0.861717	val: 0.618215	test: 0.594455
PRC train: 0.824117	val: 0.668665	test: 0.624709

Epoch: 65
Loss: 0.39995507816925613
ROC train: 0.861750	val: 0.614960	test: 0.603772
PRC train: 0.822988	val: 0.667381	test: 0.625921

Epoch: 66
Loss: 0.40072350646236987
ROC train: 0.863773	val: 0.621328	test: 0.593341
PRC train: 0.826038	val: 0.670018	test: 0.622750

Epoch: 67
Loss: 0.3982166281606926
ROC train: 0.863156	val: 0.618952	test: 0.594491
PRC train: 0.825239	val: 0.668550	test: 0.624292

Epoch: 68
Loss: 0.3922783954990936
ROC train: 0.863828	val: 0.609031	test: 0.596290
PRC train: 0.824528	val: 0.666548	test: 0.624802

Epoch: 69
Loss: 0.3975294707409807
ROC train: 0.866013	val: 0.607680	test: 0.585363
PRC train: 0.826694	val: 0.662819	test: 0.620619

Epoch: 70
Loss: 0.39815219547567676
ROC train: 0.873004	val: 0.621994	test: 0.585099
PRC train: 0.830880	val: 0.666340	test: 0.621503

Epoch: 71
Loss: 0.3880732122604099
ROC train: 0.870068	val: 0.619850	test: 0.580240
PRC train: 0.831204	val: 0.667900	test: 0.620109

Epoch: 72
Loss: 0.38835120963355163
ROC train: 0.872378	val: 0.616006	test: 0.586446
PRC train: 0.833582	val: 0.668296	test: 0.625909

Epoch: 73
Loss: 0.38520430313522
ROC train: 0.869304	val: 0.594899	test: 0.585524
PRC train: 0.829053	val: 0.656001	test: 0.623369

Epoch: 74
Loss: 0.3901280133353981
ROC train: 0.873488	val: 0.614736	test: 0.582472
PRC train: 0.834936	val: 0.667027	test: 0.623597

Epoch: 75
Loss: 0.39471249777053863
ROC train: 0.872646	val: 0.625807	test: 0.584056
PRC train: 0.835453	val: 0.676903	test: 0.626048

Epoch: 76
Loss: 0.3912262532730469
ROC train: 0.872967	val: 0.625469	test: 0.595053
PRC train: 0.835387	val: 0.669531	test: 0.631335

Epoch: 77
Loss: 0.3838527781687911
ROC train: 0.875068	val: 0.618224	test: 0.594903
PRC train: 0.836110	val: 0.663044	test: 0.635632

Epoch: 78
Loss: 0.3853785369891872
ROC train: 0.877349	val: 0.627298	test: 0.600426
PRC train: 0.841685	val: 0.668177	test: 0.634701

Epoch: 79
Loss: 0.3879402172381218
ROC train: 0.878058	val: 0.635335	test: 0.603261
PRC train: 0.842591	val: 0.669552	test: 0.635787

Epoch: 80
Loss: 0.37987703805656503
ROC train: 0.880507	val: 0.619517	test: 0.603127
PRC train: 0.843993	val: 0.665916	test: 0.635631

Epoch: 81
Loss: 0.38198007709778425
ROC train: 0.880633	val: 0.611760	test: 0.587658
PRC train: 0.843399	val: 0.661473	test: 0.629469

Epoch: 82
Loss: 0.3809907645805393
ROC train: 0.883521	val: 0.619198	test: 0.582918
PRC train: 0.844883	val: 0.669870	test: 0.623617

Epoch: 83
Loss: 0.3779688105395914
ROC train: 0.878445	val: 0.622693	test: 0.580521
PRC train: 0.842085	val: 0.676031	test: 0.624622

Epoch: 84
Loss: 0.38031943666366635
ROC train: 0.882941	val: 0.618523	test: 0.587874
PRC train: 0.847284	val: 0.670171	test: 0.632755

Epoch: 85
Loss: 0.38176597773291754
ROC train: 0.887932	val: 0.634570	test: 0.587842
PRC train: 0.850303	val: 0.676153	test: 0.630049

Epoch: 86
Loss: 0.37633789406140766
ROC train: 0.886678	val: 0.634795	test: 0.583378
PRC train: 0.848174	val: 0.673891	test: 0.629911

Epoch: 87
Loss: 0.36771263085653805
ROC train: 0.886098	val: 0.617998	test: 0.575448
PRC train: 0.848195	val: 0.663903	test: 0.623859

Epoch: 88
Loss: 0.37415252133304777
ROC train: 0.887623	val: 0.611815	test: 0.581706
PRC train: 0.848995	val: 0.661581	test: 0.625535

Epoch: 89
Loss: 0.3744452484282902
ROC train: 0.891904	val: 0.615624	test: 0.584205
PRC train: 0.854115	val: 0.666438	test: 0.625032

Epoch: 90
Loss: 0.3707647048570092
ROC train: 0.883791	val: 0.616062	test: 0.567908
PRC train: 0.845987	val: 0.663586	test: 0.618763

Epoch: 91
Loss: 0.37038819942965395
ROC train: 0.893789	val: 0.612746	test: 0.570076
PRC train: 0.856270	val: 0.660178	test: 0.619429

Epoch: 92
Loss: 0.3630580795343166
ROC train: 0.896837	val: 0.638163	test: 0.572105
PRC train: 0.859071	val: 0.672975	test: 0.618574

Epoch: 93
Loss: 0.3645016790727053
ROC train: 0.893849	val: 0.627879	test: 0.580712
PRC train: 0.855091	val: 0.671054	test: 0.623477

Epoch: 94
Loss: 0.36618369622340374
ROC train: 0.890899	val: 0.621924	test: 0.575387
PRC train: 0.783824	val: 0.663114	test: 0.623360

Epoch: 33
Loss: 0.4208296516077509
ROC train: 0.827738	val: 0.623556	test: 0.606655
PRC train: 0.783158	val: 0.663325	test: 0.628378

Epoch: 34
Loss: 0.42322994459897023
ROC train: 0.833625	val: 0.619720	test: 0.594116
PRC train: 0.790278	val: 0.658493	test: 0.621489

Epoch: 35
Loss: 0.4162935802758582
ROC train: 0.839748	val: 0.606590	test: 0.585854
PRC train: 0.796335	val: 0.654503	test: 0.622771

Epoch: 36
Loss: 0.418030648248122
ROC train: 0.835029	val: 0.615339	test: 0.587374
PRC train: 0.790602	val: 0.657803	test: 0.628014

Epoch: 37
Loss: 0.4158956094613969
ROC train: 0.845003	val: 0.619424	test: 0.599938
PRC train: 0.799602	val: 0.658466	test: 0.630192

Epoch: 38
Loss: 0.40751511980477345
ROC train: 0.848037	val: 0.620366	test: 0.583461
PRC train: 0.801851	val: 0.656272	test: 0.621221

Epoch: 39
Loss: 0.4120251017464902
ROC train: 0.848775	val: 0.625328	test: 0.581514
PRC train: 0.802645	val: 0.660283	test: 0.619507

Epoch: 40
Loss: 0.4054290690207222
ROC train: 0.853814	val: 0.629506	test: 0.603403
PRC train: 0.807217	val: 0.662943	test: 0.626580

Epoch: 41
Loss: 0.4048332203305741
ROC train: 0.854257	val: 0.633771	test: 0.608573
PRC train: 0.808275	val: 0.667474	test: 0.625592

Epoch: 42
Loss: 0.40735441071301726
ROC train: 0.858428	val: 0.642529	test: 0.596538
PRC train: 0.810013	val: 0.663909	test: 0.621638

Epoch: 43
Loss: 0.4034516577801379
ROC train: 0.861584	val: 0.648203	test: 0.600324
PRC train: 0.812789	val: 0.666463	test: 0.622604

Epoch: 44
Loss: 0.3988876483311681
ROC train: 0.863962	val: 0.642063	test: 0.599921
PRC train: 0.816126	val: 0.669700	test: 0.618418

Epoch: 45
Loss: 0.3993450462238237
ROC train: 0.865707	val: 0.639711	test: 0.592349
PRC train: 0.818059	val: 0.668372	test: 0.617205

Epoch: 46
Loss: 0.39794177680458515
ROC train: 0.860479	val: 0.641204	test: 0.590431
PRC train: 0.814077	val: 0.668143	test: 0.620682

Epoch: 47
Loss: 0.3957206297364647
ROC train: 0.864738	val: 0.637738	test: 0.596143
PRC train: 0.817638	val: 0.666762	test: 0.622218

Epoch: 48
Loss: 0.39127325576680255
ROC train: 0.868418	val: 0.631987	test: 0.603972
PRC train: 0.822503	val: 0.663454	test: 0.624877

Epoch: 49
Loss: 0.39114941868479636
ROC train: 0.872370	val: 0.638509	test: 0.602176
PRC train: 0.825236	val: 0.662614	test: 0.627584

Epoch: 50
Loss: 0.3878753936331748
ROC train: 0.872861	val: 0.634489	test: 0.597567
PRC train: 0.826201	val: 0.660204	test: 0.624717

Epoch: 51
Loss: 0.38373700650738274
ROC train: 0.875001	val: 0.624308	test: 0.599792
PRC train: 0.828272	val: 0.662780	test: 0.620806

Epoch: 52
Loss: 0.38220251688144946
ROC train: 0.877733	val: 0.629935	test: 0.596873
PRC train: 0.831547	val: 0.662526	test: 0.624436

Epoch: 53
Loss: 0.381884110013463
ROC train: 0.876721	val: 0.629173	test: 0.588407
PRC train: 0.830449	val: 0.662005	test: 0.619915

Epoch: 54
Loss: 0.3795149713465863
ROC train: 0.878149	val: 0.636660	test: 0.589986
PRC train: 0.832262	val: 0.663088	test: 0.621288

Epoch: 55
Loss: 0.382117527275245
ROC train: 0.879407	val: 0.639754	test: 0.588388
PRC train: 0.835130	val: 0.666458	test: 0.624543

Epoch: 56
Loss: 0.3785791359136697
ROC train: 0.883555	val: 0.639162	test: 0.588737
PRC train: 0.837360	val: 0.666421	test: 0.622591

Epoch: 57
Loss: 0.3699592431509618
ROC train: 0.884774	val: 0.631999	test: 0.595545
PRC train: 0.840547	val: 0.663997	test: 0.622792

Epoch: 58
Loss: 0.37505476173879193
ROC train: 0.883740	val: 0.629209	test: 0.597505
PRC train: 0.839316	val: 0.662448	test: 0.627094

Epoch: 59
Loss: 0.37282761102348133
ROC train: 0.887682	val: 0.625377	test: 0.586832
PRC train: 0.840057	val: 0.659955	test: 0.620617

Epoch: 60
Loss: 0.3720451359338315
ROC train: 0.888475	val: 0.627168	test: 0.587600
PRC train: 0.842831	val: 0.657511	test: 0.620541

Epoch: 61
Loss: 0.36527429021638413
ROC train: 0.892993	val: 0.632910	test: 0.590515
PRC train: 0.849999	val: 0.663015	test: 0.620029

Epoch: 62
Loss: 0.3677726648701872
ROC train: 0.892223	val: 0.634000	test: 0.578707
PRC train: 0.848066	val: 0.665036	test: 0.615784

Epoch: 63
Loss: 0.3686383308797814
ROC train: 0.895652	val: 0.635660	test: 0.577928
PRC train: 0.852040	val: 0.664769	test: 0.611435

Epoch: 64
Loss: 0.36410561304345446
ROC train: 0.892905	val: 0.640563	test: 0.577956
PRC train: 0.851135	val: 0.665924	test: 0.617427

Epoch: 65
Loss: 0.35842931847589315
ROC train: 0.896423	val: 0.644191	test: 0.591092
PRC train: 0.852037	val: 0.665664	test: 0.621105

Epoch: 66
Loss: 0.35714651167856254
ROC train: 0.899852	val: 0.647913	test: 0.601144
PRC train: 0.856345	val: 0.669173	test: 0.622891

Epoch: 67
Loss: 0.35611398547945217
ROC train: 0.900120	val: 0.652419	test: 0.594635
PRC train: 0.857428	val: 0.672202	test: 0.619525

Epoch: 68
Loss: 0.35584098183190827
ROC train: 0.901239	val: 0.645718	test: 0.588814
PRC train: 0.857638	val: 0.668550	test: 0.621351

Epoch: 69
Loss: 0.35374096381327946
ROC train: 0.902537	val: 0.640398	test: 0.588615
PRC train: 0.859838	val: 0.666039	test: 0.624414

Epoch: 70
Loss: 0.35413004675777976
ROC train: 0.904097	val: 0.640355	test: 0.590072
PRC train: 0.861990	val: 0.667229	test: 0.626586

Epoch: 71
Loss: 0.3514067689900336
ROC train: 0.904261	val: 0.633270	test: 0.595808
PRC train: 0.861727	val: 0.665977	test: 0.625057

Epoch: 72
Loss: 0.3561993790770317
ROC train: 0.900602	val: 0.635063	test: 0.582910
PRC train: 0.858287	val: 0.666520	test: 0.620475

Epoch: 73
Loss: 0.3505933673432662
ROC train: 0.907255	val: 0.637039	test: 0.584066
PRC train: 0.865233	val: 0.666396	test: 0.621635

Epoch: 74
Loss: 0.35297108470874566
ROC train: 0.908009	val: 0.635621	test: 0.585967
PRC train: 0.865912	val: 0.665456	test: 0.622968

Epoch: 75
Loss: 0.34697142859134633
ROC train: 0.910390	val: 0.628551	test: 0.584430
PRC train: 0.869557	val: 0.659212	test: 0.617624

Epoch: 76
Loss: 0.345545628411311
ROC train: 0.911404	val: 0.629711	test: 0.589735
PRC train: 0.872028	val: 0.656175	test: 0.620174

Epoch: 77
Loss: 0.345754051039339
ROC train: 0.913474	val: 0.634931	test: 0.588095
PRC train: 0.874813	val: 0.661280	test: 0.617542

Epoch: 78
Loss: 0.34053040419228553
ROC train: 0.913334	val: 0.635960	test: 0.580004
PRC train: 0.874181	val: 0.662925	test: 0.616139

Epoch: 79
Loss: 0.34114037846990275
ROC train: 0.914243	val: 0.633867	test: 0.581255
PRC train: 0.872476	val: 0.662158	test: 0.624849

Epoch: 80
Loss: 0.33255348475637114
ROC train: 0.913716	val: 0.635255	test: 0.589056
PRC train: 0.875021	val: 0.664288	test: 0.627660

Epoch: 81
Loss: 0.334247454230598
ROC train: 0.919612	val: 0.633175	test: 0.586920
PRC train: 0.881129	val: 0.662372	test: 0.622242

Epoch: 82
Loss: 0.33176194305233325
ROC train: 0.919557	val: 0.632042	test: 0.582456
PRC train: 0.881465	val: 0.661222	test: 0.616158

Epoch: 83
Loss: 0.3352563551144024
ROC train: 0.921043	val: 0.622296	test: 0.588471
PRC train: 0.883580	val: 0.657568	test: 0.625452

Epoch: 84
Loss: 0.3326487412242865
ROC train: 0.921779	val: 0.622360	test: 0.598641
PRC train: 0.883983	val: 0.657197	test: 0.631615

Epoch: 85
Loss: 0.32873032799619945
ROC train: 0.922384	val: 0.623391	test: 0.598127
PRC train: 0.884636	val: 0.656975	test: 0.627098

Epoch: 86
Loss: 0.3310468434907242
ROC train: 0.922521	val: 0.621231	test: 0.596020
PRC train: 0.884947	val: 0.657350	test: 0.622156

Epoch: 87
Loss: 0.3294209542097931
ROC train: 0.924428	val: 0.630696	test: 0.591032
PRC train: 0.885473	val: 0.659330	test: 0.625017

Epoch: 88
Loss: 0.3315315195578238
ROC train: 0.925973	val: 0.636814	test: 0.588114
PRC train: 0.887166	val: 0.661948	test: 0.622387

Epoch: 89
Loss: 0.3221947882200066
ROC train: 0.926468	val: 0.634095	test: 0.584741
PRC train: 0.889662	val: 0.660707	test: 0.624539

Epoch: 90
Loss: 0.32077605232398004
ROC train: 0.928623	val: 0.630180	test: 0.587361
PRC train: 0.892404	val: 0.659995	test: 0.626252

Epoch: 91
Loss: 0.3202853010937469
ROC train: 0.929256	val: 0.628147	test: 0.583369
PRC train: 0.893669	val: 0.659533	test: 0.620706

Epoch: 92
Loss: 0.3157772096960398
ROC train: 0.931316	val: 0.630012	test: 0.586668
PRC train: 0.895684	val: 0.659288	test: 0.622729

Epoch: 93
Loss: 0.3145736258901749
ROC train: 0.934231	val: 0.630445	test: 0.581596
PRC train: 0.795207	val: 0.665140	test: 0.614116

Epoch: 33
Loss: 0.41678598143937196
ROC train: 0.833632	val: 0.604521	test: 0.583035
PRC train: 0.797862	val: 0.653238	test: 0.617598

Epoch: 34
Loss: 0.42200586986513366
ROC train: 0.834159	val: 0.605410	test: 0.582044
PRC train: 0.799138	val: 0.654336	test: 0.616401

Epoch: 35
Loss: 0.4189216276204458
ROC train: 0.837827	val: 0.615922	test: 0.590574
PRC train: 0.801096	val: 0.671250	test: 0.620843

Epoch: 36
Loss: 0.42676679793621536
ROC train: 0.843510	val: 0.604895	test: 0.578685
PRC train: 0.807161	val: 0.658951	test: 0.611556

Epoch: 37
Loss: 0.4185645518535274
ROC train: 0.843769	val: 0.602752	test: 0.569745
PRC train: 0.810793	val: 0.657243	test: 0.607734

Epoch: 38
Loss: 0.412362314230858
ROC train: 0.848835	val: 0.605022	test: 0.584616
PRC train: 0.814588	val: 0.659078	test: 0.615031

Epoch: 39
Loss: 0.4127474662660641
ROC train: 0.845946	val: 0.620172	test: 0.584638
PRC train: 0.808286	val: 0.666695	test: 0.614349

Epoch: 40
Loss: 0.40879900152587273
ROC train: 0.852321	val: 0.616869	test: 0.575034
PRC train: 0.816041	val: 0.659218	test: 0.612078

Epoch: 41
Loss: 0.40890718012600547
ROC train: 0.852316	val: 0.621273	test: 0.581645
PRC train: 0.816714	val: 0.661934	test: 0.612782

Epoch: 42
Loss: 0.4026738946906093
ROC train: 0.856141	val: 0.616556	test: 0.580383
PRC train: 0.820777	val: 0.662347	test: 0.612809

Epoch: 43
Loss: 0.4078715049489059
ROC train: 0.859363	val: 0.609131	test: 0.576190
PRC train: 0.822624	val: 0.659503	test: 0.615419

Epoch: 44
Loss: 0.39658969792493887
ROC train: 0.867685	val: 0.616817	test: 0.585683
PRC train: 0.830529	val: 0.663785	test: 0.614384

Epoch: 45
Loss: 0.3941950783686926
ROC train: 0.865914	val: 0.625225	test: 0.586957
PRC train: 0.825950	val: 0.668713	test: 0.612718

Epoch: 46
Loss: 0.39074723229394664
ROC train: 0.867819	val: 0.622905	test: 0.588289
PRC train: 0.827595	val: 0.665754	test: 0.620162

Epoch: 47
Loss: 0.3931291533418101
ROC train: 0.868162	val: 0.607359	test: 0.582438
PRC train: 0.830065	val: 0.654848	test: 0.618034

Epoch: 48
Loss: 0.39359431616114027
ROC train: 0.872328	val: 0.607747	test: 0.584552
PRC train: 0.833830	val: 0.655979	test: 0.616373

Epoch: 49
Loss: 0.3920583804937197
ROC train: 0.873046	val: 0.618287	test: 0.590626
PRC train: 0.834028	val: 0.663115	test: 0.620358

Epoch: 50
Loss: 0.3893306785498908
ROC train: 0.874636	val: 0.616008	test: 0.598316
PRC train: 0.833630	val: 0.661695	test: 0.625110

Epoch: 51
Loss: 0.38377359676090184
ROC train: 0.875087	val: 0.623563	test: 0.592765
PRC train: 0.834499	val: 0.666104	test: 0.619137

Epoch: 52
Loss: 0.3900768620396746
ROC train: 0.879531	val: 0.611633	test: 0.585740
PRC train: 0.841151	val: 0.657585	test: 0.615888

Epoch: 53
Loss: 0.38270046321178175
ROC train: 0.871024	val: 0.612095	test: 0.580009
PRC train: 0.830109	val: 0.662617	test: 0.613463

Epoch: 54
Loss: 0.37880098170558674
ROC train: 0.879125	val: 0.594285	test: 0.591646
PRC train: 0.843521	val: 0.653823	test: 0.621669

Epoch: 55
Loss: 0.37795297472256945
ROC train: 0.883448	val: 0.620514	test: 0.588464
PRC train: 0.846625	val: 0.666181	test: 0.617442

Epoch: 56
Loss: 0.3780683299307137
ROC train: 0.883120	val: 0.641314	test: 0.576758
PRC train: 0.845305	val: 0.676276	test: 0.613411

Epoch: 57
Loss: 0.3786093868309911
ROC train: 0.879993	val: 0.624290	test: 0.587898
PRC train: 0.842193	val: 0.663267	test: 0.620318

Epoch: 58
Loss: 0.37262364363996847
ROC train: 0.884576	val: 0.628457	test: 0.592212
PRC train: 0.844098	val: 0.666407	test: 0.622878

Epoch: 59
Loss: 0.3736052015791334
ROC train: 0.888663	val: 0.618081	test: 0.606290
PRC train: 0.849735	val: 0.660626	test: 0.631218

Epoch: 60
Loss: 0.3744179932693806
ROC train: 0.890022	val: 0.624840	test: 0.602145
PRC train: 0.850323	val: 0.671228	test: 0.627069

Epoch: 61
Loss: 0.37192898609900404
ROC train: 0.894566	val: 0.624223	test: 0.596161
PRC train: 0.856516	val: 0.665035	test: 0.627776

Epoch: 62
Loss: 0.36692546108347557
ROC train: 0.894634	val: 0.622545	test: 0.587161
PRC train: 0.857547	val: 0.663634	test: 0.619977

Epoch: 63
Loss: 0.3618326674781426
ROC train: 0.893838	val: 0.616448	test: 0.579646
PRC train: 0.857501	val: 0.662955	test: 0.608801

Epoch: 64
Loss: 0.3639664852161798
ROC train: 0.893535	val: 0.615203	test: 0.575382
PRC train: 0.855382	val: 0.658955	test: 0.607491

Epoch: 65
Loss: 0.35887426218645074
ROC train: 0.895028	val: 0.622874	test: 0.574273
PRC train: 0.856577	val: 0.662420	test: 0.610428

Epoch: 66
Loss: 0.3655239810323423
ROC train: 0.899354	val: 0.614483	test: 0.583765
PRC train: 0.863453	val: 0.656244	test: 0.617414

Epoch: 67
Loss: 0.36034063863839305
ROC train: 0.899317	val: 0.627394	test: 0.582062
PRC train: 0.863491	val: 0.667727	test: 0.615937

Epoch: 68
Loss: 0.3570301541468565
ROC train: 0.901625	val: 0.619783	test: 0.593847
PRC train: 0.869964	val: 0.662460	test: 0.619167

Epoch: 69
Loss: 0.3541029906960964
ROC train: 0.903974	val: 0.616213	test: 0.600270
PRC train: 0.870453	val: 0.659649	test: 0.624846

Epoch: 70
Loss: 0.3525332752600554
ROC train: 0.900970	val: 0.624249	test: 0.594903
PRC train: 0.864818	val: 0.661979	test: 0.623930

Epoch: 71
Loss: 0.34690570791113245
ROC train: 0.894847	val: 0.610835	test: 0.590508
PRC train: 0.858154	val: 0.655948	test: 0.623885

Epoch: 72
Loss: 0.3564620129678555
ROC train: 0.905032	val: 0.621410	test: 0.583589
PRC train: 0.871673	val: 0.668191	test: 0.617690

Epoch: 73
Loss: 0.3509087513314581
ROC train: 0.906781	val: 0.613138	test: 0.589339
PRC train: 0.872872	val: 0.661999	test: 0.620883

Epoch: 74
Loss: 0.34547277889291383
ROC train: 0.906578	val: 0.595904	test: 0.602941
PRC train: 0.871954	val: 0.652759	test: 0.633469

Epoch: 75
Loss: 0.3445946301496961
ROC train: 0.907540	val: 0.609663	test: 0.593827
PRC train: 0.877553	val: 0.657971	test: 0.620839

Epoch: 76
Loss: 0.3441076568731512
ROC train: 0.909117	val: 0.619495	test: 0.584907
PRC train: 0.877639	val: 0.660312	test: 0.616942

Epoch: 77
Loss: 0.3387950772772429
ROC train: 0.909121	val: 0.606802	test: 0.599517
PRC train: 0.875866	val: 0.653234	test: 0.630159

Epoch: 78
Loss: 0.34241206802396684
ROC train: 0.910367	val: 0.600776	test: 0.596343
PRC train: 0.878465	val: 0.653639	test: 0.629785

Epoch: 79
Loss: 0.34478642577165675
ROC train: 0.916452	val: 0.630304	test: 0.588824
PRC train: 0.882543	val: 0.665737	test: 0.628840

Epoch: 80
Loss: 0.33905799261394115
ROC train: 0.917528	val: 0.626127	test: 0.594979
PRC train: 0.882642	val: 0.666562	test: 0.632432

Epoch: 81
Loss: 0.33892132567288014
ROC train: 0.914620	val: 0.599627	test: 0.603064
PRC train: 0.880864	val: 0.651390	test: 0.635290

Epoch: 82
Loss: 0.3332119205642722
ROC train: 0.916816	val: 0.617656	test: 0.605091
PRC train: 0.882434	val: 0.662527	test: 0.631864

Epoch: 83
Loss: 0.3454144492441296
ROC train: 0.919597	val: 0.629710	test: 0.598727
PRC train: 0.888661	val: 0.671043	test: 0.629219

Epoch: 84
Loss: 0.33884204272378876
ROC train: 0.919499	val: 0.610305	test: 0.600956
PRC train: 0.887338	val: 0.660125	test: 0.637757

Epoch: 85
Loss: 0.33445292575399094
ROC train: 0.921172	val: 0.607013	test: 0.606927
PRC train: 0.889779	val: 0.660329	test: 0.638242

Epoch: 86
Loss: 0.3295835823465577
ROC train: 0.921608	val: 0.613696	test: 0.605784
PRC train: 0.889708	val: 0.661126	test: 0.634294

Epoch: 87
Loss: 0.32988331137273874
ROC train: 0.922445	val: 0.608501	test: 0.604631
PRC train: 0.889851	val: 0.656699	test: 0.633062

Epoch: 88
Loss: 0.32702189670860066
ROC train: 0.924995	val: 0.622550	test: 0.590307
PRC train: 0.893271	val: 0.664633	test: 0.627948

Epoch: 89
Loss: 0.32778968440557116
ROC train: 0.924464	val: 0.623542	test: 0.600297
PRC train: 0.895850	val: 0.667659	test: 0.630153

Epoch: 90
Loss: 0.3234215154698942
ROC train: 0.927417	val: 0.622710	test: 0.612915
PRC train: 0.898971	val: 0.669648	test: 0.634932

Epoch: 91
Loss: 0.32969879355821846
ROC train: 0.925723	val: 0.620536	test: 0.601922
PRC train: 0.896829	val: 0.664671	test: 0.627511

Epoch: 92
Loss: 0.3211533621816539
ROC train: 0.930479	val: 0.613161	test: 0.595108
PRC train: 0.900137	val: 0.659373	test: 0.623557

Epoch: 93
Loss: 0.3217115859495913
ROC train: 0.929965	val: 0.608596	test: 0.596284
PRC train: 0.794907	val: 0.649539	test: 0.618642

Epoch: 33
Loss: 0.42402167989062906
ROC train: 0.840970	val: 0.601998	test: 0.588121
PRC train: 0.798182	val: 0.650073	test: 0.618250

Epoch: 34
Loss: 0.4130173355319151
ROC train: 0.838322	val: 0.600838	test: 0.575912
PRC train: 0.794334	val: 0.650624	test: 0.610552

Epoch: 35
Loss: 0.4170986321347767
ROC train: 0.843838	val: 0.607199	test: 0.580323
PRC train: 0.796559	val: 0.658171	test: 0.610664

Epoch: 36
Loss: 0.41427718849934037
ROC train: 0.850272	val: 0.609213	test: 0.585869
PRC train: 0.803320	val: 0.656292	test: 0.614835

Epoch: 37
Loss: 0.41107876753254197
ROC train: 0.852209	val: 0.598209	test: 0.588864
PRC train: 0.805552	val: 0.653336	test: 0.614740

Epoch: 38
Loss: 0.4165438757073402
ROC train: 0.854564	val: 0.598216	test: 0.584684
PRC train: 0.809441	val: 0.652095	test: 0.615359

Epoch: 39
Loss: 0.4106983995358358
ROC train: 0.849357	val: 0.612151	test: 0.568216
PRC train: 0.805616	val: 0.652230	test: 0.615588

Epoch: 40
Loss: 0.4001726813698195
ROC train: 0.861021	val: 0.606909	test: 0.592386
PRC train: 0.815076	val: 0.652793	test: 0.620363

Epoch: 41
Loss: 0.40054257978286395
ROC train: 0.864771	val: 0.605729	test: 0.589470
PRC train: 0.816947	val: 0.652626	test: 0.614943

Epoch: 42
Loss: 0.40158170034538304
ROC train: 0.867410	val: 0.599432	test: 0.583934
PRC train: 0.819373	val: 0.650003	test: 0.613001

Epoch: 43
Loss: 0.4004032543852357
ROC train: 0.867522	val: 0.617251	test: 0.579956
PRC train: 0.819316	val: 0.658986	test: 0.612263

Epoch: 44
Loss: 0.3984217323723606
ROC train: 0.868700	val: 0.618760	test: 0.580656
PRC train: 0.820396	val: 0.658207	test: 0.615114

Epoch: 45
Loss: 0.39273721156908303
ROC train: 0.870575	val: 0.620462	test: 0.577887
PRC train: 0.823968	val: 0.659329	test: 0.614141

Epoch: 46
Loss: 0.3881206208085991
ROC train: 0.870106	val: 0.618450	test: 0.571138
PRC train: 0.823029	val: 0.657746	test: 0.609428

Epoch: 47
Loss: 0.39036637756920756
ROC train: 0.874322	val: 0.620148	test: 0.581428
PRC train: 0.827805	val: 0.658608	test: 0.612393

Epoch: 48
Loss: 0.3861216495607311
ROC train: 0.877874	val: 0.616656	test: 0.588854
PRC train: 0.831899	val: 0.657998	test: 0.616698

Epoch: 49
Loss: 0.38081394030702015
ROC train: 0.879861	val: 0.625340	test: 0.579945
PRC train: 0.833881	val: 0.660138	test: 0.616705

Epoch: 50
Loss: 0.3840999981483967
ROC train: 0.879552	val: 0.629176	test: 0.579271
PRC train: 0.833646	val: 0.662318	test: 0.619934

Epoch: 51
Loss: 0.38455235971518636
ROC train: 0.884981	val: 0.625989	test: 0.577400
PRC train: 0.836896	val: 0.661141	test: 0.615126

Epoch: 52
Loss: 0.38135406978832886
ROC train: 0.883272	val: 0.621445	test: 0.580480
PRC train: 0.835158	val: 0.660241	test: 0.613440

Epoch: 53
Loss: 0.38283596443786894
ROC train: 0.883884	val: 0.616987	test: 0.574939
PRC train: 0.836428	val: 0.655739	test: 0.613876

Epoch: 54
Loss: 0.37840913906763973
ROC train: 0.888669	val: 0.622716	test: 0.573742
PRC train: 0.840809	val: 0.659777	test: 0.611548

Epoch: 55
Loss: 0.37387306772466716
ROC train: 0.883247	val: 0.616591	test: 0.562882
PRC train: 0.837998	val: 0.656022	test: 0.610717

Epoch: 56
Loss: 0.3711459485892476
ROC train: 0.890843	val: 0.623445	test: 0.566351
PRC train: 0.844163	val: 0.660951	test: 0.609747

Epoch: 57
Loss: 0.36864012585106204
ROC train: 0.891144	val: 0.615146	test: 0.571688
PRC train: 0.843816	val: 0.655905	test: 0.611627

Epoch: 58
Loss: 0.36549660996502886
ROC train: 0.891570	val: 0.610767	test: 0.582549
PRC train: 0.844831	val: 0.654280	test: 0.615864

Epoch: 59
Loss: 0.377383448489804
ROC train: 0.892890	val: 0.623302	test: 0.582017
PRC train: 0.847262	val: 0.659108	test: 0.616593

Epoch: 60
Loss: 0.3677826115278915
ROC train: 0.892425	val: 0.613717	test: 0.579106
PRC train: 0.846677	val: 0.652872	test: 0.617851

Epoch: 61
Loss: 0.3646826164704833
ROC train: 0.894980	val: 0.611522	test: 0.576981
PRC train: 0.848969	val: 0.656049	test: 0.615910

Epoch: 62
Loss: 0.35935871616754206
ROC train: 0.895791	val: 0.620598	test: 0.579944
PRC train: 0.850542	val: 0.658968	test: 0.618481

Epoch: 63
Loss: 0.3626719776004992
ROC train: 0.895341	val: 0.619619	test: 0.585788
PRC train: 0.852485	val: 0.657596	test: 0.619649

Epoch: 64
Loss: 0.35745776544064756
ROC train: 0.896813	val: 0.613101	test: 0.578904
PRC train: 0.852628	val: 0.656014	test: 0.616101

Epoch: 65
Loss: 0.35665068635510355
ROC train: 0.898196	val: 0.604870	test: 0.579803
PRC train: 0.853509	val: 0.655358	test: 0.618337

Epoch: 66
Loss: 0.3586092638874926
ROC train: 0.899603	val: 0.616485	test: 0.581090
PRC train: 0.854583	val: 0.656300	test: 0.615665

Epoch: 67
Loss: 0.3576931719099211
ROC train: 0.899735	val: 0.623324	test: 0.577106
PRC train: 0.854516	val: 0.658758	test: 0.615367

Epoch: 68
Loss: 0.35759183347432194
ROC train: 0.902278	val: 0.622378	test: 0.581828
PRC train: 0.856950	val: 0.660481	test: 0.615925

Epoch: 69
Loss: 0.35519683746629643
ROC train: 0.904548	val: 0.617789	test: 0.583954
PRC train: 0.858095	val: 0.658938	test: 0.617318

Epoch: 70
Loss: 0.3528637949581079
ROC train: 0.906339	val: 0.624172	test: 0.584156
PRC train: 0.860682	val: 0.663473	test: 0.617506

Epoch: 71
Loss: 0.3475173129842703
ROC train: 0.905903	val: 0.626521	test: 0.582613
PRC train: 0.862501	val: 0.661421	test: 0.619533

Epoch: 72
Loss: 0.3490119871380889
ROC train: 0.905153	val: 0.622479	test: 0.587143
PRC train: 0.860606	val: 0.660919	test: 0.616324

Epoch: 73
Loss: 0.3510241511771185
ROC train: 0.907328	val: 0.601521	test: 0.577933
PRC train: 0.863347	val: 0.648088	test: 0.611229

Epoch: 74
Loss: 0.3430829658035689
ROC train: 0.908432	val: 0.616013	test: 0.585723
PRC train: 0.863874	val: 0.657666	test: 0.617643

Epoch: 75
Loss: 0.346443003086628
ROC train: 0.909729	val: 0.619140	test: 0.591157
PRC train: 0.864180	val: 0.655544	test: 0.622833

Epoch: 76
Loss: 0.34073062648969554
ROC train: 0.913271	val: 0.622793	test: 0.585201
PRC train: 0.868731	val: 0.665187	test: 0.618116

Epoch: 77
Loss: 0.3399324758727327
ROC train: 0.915521	val: 0.622218	test: 0.588191
PRC train: 0.871412	val: 0.664074	test: 0.619968

Epoch: 78
Loss: 0.3378415337355903
ROC train: 0.914383	val: 0.621989	test: 0.580924
PRC train: 0.870755	val: 0.659845	test: 0.617384

Epoch: 79
Loss: 0.3403156213333031
ROC train: 0.916923	val: 0.624174	test: 0.581295
PRC train: 0.873815	val: 0.661621	test: 0.615247

Epoch: 80
Loss: 0.33435902573201426
ROC train: 0.919366	val: 0.625836	test: 0.577661
PRC train: 0.875390	val: 0.661097	test: 0.616296

Epoch: 81
Loss: 0.3288253381054188
ROC train: 0.919591	val: 0.621355	test: 0.577905
PRC train: 0.877115	val: 0.657746	test: 0.620422

Epoch: 82
Loss: 0.33391483921240084
ROC train: 0.919581	val: 0.612891	test: 0.578870
PRC train: 0.877161	val: 0.656155	test: 0.616377

Epoch: 83
Loss: 0.3332837091329405
ROC train: 0.921382	val: 0.612063	test: 0.580559
PRC train: 0.878773	val: 0.657158	test: 0.616145

Epoch: 84
Loss: 0.3255164428125268
ROC train: 0.921145	val: 0.621799	test: 0.584116
PRC train: 0.877600	val: 0.664549	test: 0.618535

Epoch: 85
Loss: 0.3312141268049864
ROC train: 0.924555	val: 0.625488	test: 0.584662
PRC train: 0.880703	val: 0.666523	test: 0.618923

Epoch: 86
Loss: 0.32797601432996
ROC train: 0.922717	val: 0.619515	test: 0.583766
PRC train: 0.880498	val: 0.662056	test: 0.618857

Epoch: 87
Loss: 0.32640089944024864
ROC train: 0.925722	val: 0.622981	test: 0.589554
PRC train: 0.884776	val: 0.664118	test: 0.621441

Epoch: 88
Loss: 0.32523209595923575
ROC train: 0.923491	val: 0.621075	test: 0.593103
PRC train: 0.880120	val: 0.659238	test: 0.624442

Epoch: 89
Loss: 0.32486355231644326
ROC train: 0.924792	val: 0.633354	test: 0.589714
PRC train: 0.881533	val: 0.666792	test: 0.623913

Epoch: 90
Loss: 0.32273650209763094
ROC train: 0.927842	val: 0.630644	test: 0.590148
PRC train: 0.885617	val: 0.666456	test: 0.622933

Epoch: 91
Loss: 0.32065786481449665
ROC train: 0.927471	val: 0.626182	test: 0.586875
PRC train: 0.885908	val: 0.664544	test: 0.620422

Epoch: 92
Loss: 0.3217608752590929
ROC train: 0.931773	val: 0.623461	test: 0.587285
PRC train: 0.890014	val: 0.661348	test: 0.620130

Epoch: 93
Loss: 0.3207517726714682
ROC train: 0.931703	val: 0.625129	test: 0.589223
PRC train: 0.801650	val: 0.653387	test: 0.599769

Epoch: 33
Loss: 0.4163885179719734
ROC train: 0.849225	val: 0.590580	test: 0.535816
PRC train: 0.805760	val: 0.646181	test: 0.610266

Epoch: 34
Loss: 0.41556234044441787
ROC train: 0.844928	val: 0.607869	test: 0.537249
PRC train: 0.802141	val: 0.655548	test: 0.616637

Epoch: 35
Loss: 0.41657375736951907
ROC train: 0.850144	val: 0.605506	test: 0.547420
PRC train: 0.809314	val: 0.654828	test: 0.619220

Epoch: 36
Loss: 0.4149938016782193
ROC train: 0.860415	val: 0.604308	test: 0.530563
PRC train: 0.818129	val: 0.652740	test: 0.614508

Epoch: 37
Loss: 0.4093761491005288
ROC train: 0.855975	val: 0.604816	test: 0.518119
PRC train: 0.814210	val: 0.653106	test: 0.604266

Epoch: 38
Loss: 0.403637015471238
ROC train: 0.863421	val: 0.602285	test: 0.512100
PRC train: 0.821913	val: 0.653467	test: 0.607155

Epoch: 39
Loss: 0.4090791821135105
ROC train: 0.866050	val: 0.590057	test: 0.538157
PRC train: 0.826028	val: 0.643055	test: 0.613400

Epoch: 40
Loss: 0.40516233682700176
ROC train: 0.865341	val: 0.610162	test: 0.557535
PRC train: 0.820702	val: 0.652365	test: 0.617212

Epoch: 41
Loss: 0.40129637916412203
ROC train: 0.863126	val: 0.607380	test: 0.550740
PRC train: 0.817401	val: 0.655275	test: 0.621251

Epoch: 42
Loss: 0.3945605870679024
ROC train: 0.871448	val: 0.613050	test: 0.536412
PRC train: 0.830008	val: 0.659141	test: 0.616501

Epoch: 43
Loss: 0.39390039824171474
ROC train: 0.873636	val: 0.613835	test: 0.540039
PRC train: 0.833064	val: 0.658469	test: 0.614737

Epoch: 44
Loss: 0.395503625439778
ROC train: 0.873195	val: 0.612452	test: 0.554034
PRC train: 0.833968	val: 0.655983	test: 0.616233

Epoch: 45
Loss: 0.3912331076239425
ROC train: 0.876080	val: 0.608094	test: 0.548359
PRC train: 0.833348	val: 0.654806	test: 0.621279

Epoch: 46
Loss: 0.39553529588316066
ROC train: 0.873004	val: 0.628878	test: 0.537862
PRC train: 0.831087	val: 0.669432	test: 0.613438

Epoch: 47
Loss: 0.3912165665536097
ROC train: 0.879809	val: 0.624534	test: 0.536739
PRC train: 0.842050	val: 0.667368	test: 0.613179

Epoch: 48
Loss: 0.3873019801411237
ROC train: 0.880057	val: 0.624390	test: 0.526888
PRC train: 0.840459	val: 0.663732	test: 0.609151

Epoch: 49
Loss: 0.38704681166046295
ROC train: 0.882293	val: 0.626331	test: 0.528094
PRC train: 0.844877	val: 0.666494	test: 0.608719

Epoch: 50
Loss: 0.3796303200852432
ROC train: 0.880647	val: 0.613707	test: 0.522010
PRC train: 0.843889	val: 0.663560	test: 0.602363

Epoch: 51
Loss: 0.38198968554643953
ROC train: 0.882861	val: 0.607543	test: 0.531083
PRC train: 0.843271	val: 0.661516	test: 0.607327

Epoch: 52
Loss: 0.3775480509551431
ROC train: 0.885393	val: 0.612817	test: 0.540016
PRC train: 0.845314	val: 0.662202	test: 0.620554

Epoch: 53
Loss: 0.37931030334389665
ROC train: 0.881029	val: 0.623894	test: 0.533535
PRC train: 0.838199	val: 0.667852	test: 0.610993

Epoch: 54
Loss: 0.3773294201692673
ROC train: 0.889541	val: 0.616491	test: 0.532580
PRC train: 0.849119	val: 0.661888	test: 0.608298

Epoch: 55
Loss: 0.3731445454110787
ROC train: 0.891301	val: 0.615895	test: 0.529189
PRC train: 0.851105	val: 0.663073	test: 0.605066

Epoch: 56
Loss: 0.37206494282059765
ROC train: 0.892516	val: 0.615854	test: 0.532929
PRC train: 0.854806	val: 0.665568	test: 0.613362

Epoch: 57
Loss: 0.3690824030752201
ROC train: 0.892388	val: 0.610342	test: 0.534688
PRC train: 0.854345	val: 0.662090	test: 0.616824

Epoch: 58
Loss: 0.36528241926334215
ROC train: 0.893356	val: 0.604929	test: 0.538664
PRC train: 0.855199	val: 0.659254	test: 0.618060

Epoch: 59
Loss: 0.3694027054843687
ROC train: 0.892100	val: 0.609679	test: 0.536028
PRC train: 0.854923	val: 0.663661	test: 0.608207

Epoch: 60
Loss: 0.37083340735466636
ROC train: 0.895236	val: 0.605444	test: 0.523643
PRC train: 0.855941	val: 0.659209	test: 0.599197

Epoch: 61
Loss: 0.3640847223615239
ROC train: 0.900002	val: 0.603486	test: 0.539027
PRC train: 0.861669	val: 0.656148	test: 0.605872

Epoch: 62
Loss: 0.359053622768977
ROC train: 0.901800	val: 0.606678	test: 0.541774
PRC train: 0.863338	val: 0.658801	test: 0.609175

Epoch: 63
Loss: 0.3600982670946463
ROC train: 0.900374	val: 0.612258	test: 0.542751
PRC train: 0.861325	val: 0.662732	test: 0.610527

Epoch: 64
Loss: 0.3512007135987979
ROC train: 0.900385	val: 0.618547	test: 0.554457
PRC train: 0.860224	val: 0.666296	test: 0.624262

Epoch: 65
Loss: 0.35846348074026047
ROC train: 0.898484	val: 0.619505	test: 0.551016
PRC train: 0.860443	val: 0.671072	test: 0.613107

Epoch: 66
Loss: 0.35390430636391235
ROC train: 0.902818	val: 0.621218	test: 0.544535
PRC train: 0.864849	val: 0.669297	test: 0.609145

Epoch: 67
Loss: 0.35867573171699085
ROC train: 0.905728	val: 0.618562	test: 0.538808
PRC train: 0.868743	val: 0.667292	test: 0.612232

Epoch: 68
Loss: 0.35727733620688196
ROC train: 0.906891	val: 0.618116	test: 0.539291
PRC train: 0.869877	val: 0.669464	test: 0.606290

Epoch: 69
Loss: 0.3507274522653607
ROC train: 0.910846	val: 0.611191	test: 0.543773
PRC train: 0.873122	val: 0.664599	test: 0.610772

Epoch: 70
Loss: 0.3548214589751625
ROC train: 0.910974	val: 0.611265	test: 0.536412
PRC train: 0.872831	val: 0.661970	test: 0.605864

Epoch: 71
Loss: 0.3524707098822367
ROC train: 0.909269	val: 0.614143	test: 0.532900
PRC train: 0.871270	val: 0.662062	test: 0.605239

Epoch: 72
Loss: 0.35073520182816276
ROC train: 0.910214	val: 0.616823	test: 0.530663
PRC train: 0.872586	val: 0.663344	test: 0.604924

Epoch: 73
Loss: 0.3461619822682511
ROC train: 0.909437	val: 0.614038	test: 0.531344
PRC train: 0.869007	val: 0.663531	test: 0.603235

Epoch: 74
Loss: 0.33841837139170233
ROC train: 0.909776	val: 0.615105	test: 0.540268
PRC train: 0.873120	val: 0.664087	test: 0.606071

Epoch: 75
Loss: 0.3413293669521751
ROC train: 0.910889	val: 0.618835	test: 0.539743
PRC train: 0.875387	val: 0.664231	test: 0.603738

Epoch: 76
Loss: 0.341696385655719
ROC train: 0.914250	val: 0.616815	test: 0.545508
PRC train: 0.878851	val: 0.662512	test: 0.608577

Epoch: 77
Loss: 0.33517331593162963
ROC train: 0.915995	val: 0.612951	test: 0.541935
PRC train: 0.880763	val: 0.663336	test: 0.610676

Epoch: 78
Loss: 0.34051833070139087
ROC train: 0.917456	val: 0.611673	test: 0.546553
PRC train: 0.881629	val: 0.662486	test: 0.616576

Epoch: 79
Loss: 0.3373220224470358
ROC train: 0.918213	val: 0.616031	test: 0.560288
PRC train: 0.880930	val: 0.664715	test: 0.623332

Epoch: 80
Loss: 0.3345086056900878
ROC train: 0.917417	val: 0.620616	test: 0.558547
PRC train: 0.879951	val: 0.667856	test: 0.618075

Epoch: 81
Loss: 0.33126104220715336
ROC train: 0.919848	val: 0.611761	test: 0.548553
PRC train: 0.884890	val: 0.662627	test: 0.615706

Epoch: 82
Loss: 0.3284031194129925
ROC train: 0.922288	val: 0.612792	test: 0.537585
PRC train: 0.886375	val: 0.661412	test: 0.611559

Epoch: 83
Loss: 0.3363739109059214
ROC train: 0.921078	val: 0.618196	test: 0.539596
PRC train: 0.885976	val: 0.664333	test: 0.613054

Epoch: 84
Loss: 0.33007858352353425
ROC train: 0.919971	val: 0.622471	test: 0.542705
PRC train: 0.885670	val: 0.668837	test: 0.613548

Epoch: 85
Loss: 0.3265422957141396
ROC train: 0.924776	val: 0.612257	test: 0.536407
PRC train: 0.893666	val: 0.663666	test: 0.608097

Epoch: 86
Loss: 0.32591158495724865
ROC train: 0.926174	val: 0.612361	test: 0.535101
PRC train: 0.894284	val: 0.664036	test: 0.608252

Epoch: 87
Loss: 0.32774201041190343
ROC train: 0.923965	val: 0.613234	test: 0.539915
PRC train: 0.888171	val: 0.664327	test: 0.610451

Epoch: 88
Loss: 0.3252099509337005
ROC train: 0.922905	val: 0.617215	test: 0.550278
PRC train: 0.887637	val: 0.664114	test: 0.612825

Epoch: 89
Loss: 0.32274942193598066
ROC train: 0.925221	val: 0.609870	test: 0.550731
PRC train: 0.891412	val: 0.658866	test: 0.622103

Epoch: 90
Loss: 0.3235967597047836
ROC train: 0.930788	val: 0.607051	test: 0.545867
PRC train: 0.899746	val: 0.658177	test: 0.616697

Epoch: 91
Loss: 0.32434758957297116
ROC train: 0.932877	val: 0.612938	test: 0.543836
PRC train: 0.902495	val: 0.661638	test: 0.610696

Epoch: 92
Loss: 0.31791736762312856
ROC train: 0.931325	val: 0.616289	test: 0.541426
PRC train: 0.896200	val: 0.667769	test: 0.605418

Epoch: 93
Loss: 0.31667982357658103
ROC train: 0.933001	val: 0.619070	test: 0.534033
PRC train: 0.781407	val: 0.656540	test: 0.627547

Epoch: 33
Loss: 0.4344018790606706
ROC train: 0.831488	val: 0.605779	test: 0.608024
PRC train: 0.789316	val: 0.654480	test: 0.630432

Epoch: 34
Loss: 0.42470818959976075
ROC train: 0.834432	val: 0.622208	test: 0.603758
PRC train: 0.789843	val: 0.662415	test: 0.627514

Epoch: 35
Loss: 0.42757545425111576
ROC train: 0.836472	val: 0.610022	test: 0.588749
PRC train: 0.791936	val: 0.654931	test: 0.627426

Epoch: 36
Loss: 0.42206980666161453
ROC train: 0.842982	val: 0.629624	test: 0.578110
PRC train: 0.797865	val: 0.666618	test: 0.622538

Epoch: 37
Loss: 0.4235079098072855
ROC train: 0.847315	val: 0.612012	test: 0.585621
PRC train: 0.803828	val: 0.656933	test: 0.626177

Epoch: 38
Loss: 0.41323303456503185
ROC train: 0.849782	val: 0.627708	test: 0.591077
PRC train: 0.806229	val: 0.661651	test: 0.628433

Epoch: 39
Loss: 0.41812346553397706
ROC train: 0.850725	val: 0.630402	test: 0.589779
PRC train: 0.805559	val: 0.660407	test: 0.627427

Epoch: 40
Loss: 0.40427033688743197
ROC train: 0.853103	val: 0.623051	test: 0.586338
PRC train: 0.807169	val: 0.657351	test: 0.621868

Epoch: 41
Loss: 0.4083587392991708
ROC train: 0.852867	val: 0.627998	test: 0.590263
PRC train: 0.804799	val: 0.664346	test: 0.623569

Epoch: 42
Loss: 0.41065644218009023
ROC train: 0.853767	val: 0.621696	test: 0.598881
PRC train: 0.808724	val: 0.661315	test: 0.627453

Epoch: 43
Loss: 0.4065277692131861
ROC train: 0.857721	val: 0.631695	test: 0.597048
PRC train: 0.811190	val: 0.663760	test: 0.627439

Epoch: 44
Loss: 0.408383897196246
ROC train: 0.860450	val: 0.615233	test: 0.588170
PRC train: 0.813221	val: 0.651755	test: 0.624679

Epoch: 45
Loss: 0.39463248314740074
ROC train: 0.860337	val: 0.609922	test: 0.597819
PRC train: 0.812524	val: 0.649469	test: 0.630468

Epoch: 46
Loss: 0.39625289602957725
ROC train: 0.854743	val: 0.625833	test: 0.594687
PRC train: 0.806251	val: 0.659300	test: 0.632329

Epoch: 47
Loss: 0.40105424574280646
ROC train: 0.861824	val: 0.607731	test: 0.585265
PRC train: 0.817640	val: 0.650567	test: 0.627711

Epoch: 48
Loss: 0.39895258278319595
ROC train: 0.860463	val: 0.638910	test: 0.588786
PRC train: 0.816261	val: 0.671778	test: 0.625153

Epoch: 49
Loss: 0.3980877559733086
ROC train: 0.868677	val: 0.640495	test: 0.594218
PRC train: 0.824232	val: 0.670505	test: 0.622074

Epoch: 50
Loss: 0.3914339146270394
ROC train: 0.866697	val: 0.621880	test: 0.583004
PRC train: 0.820958	val: 0.657679	test: 0.623489

Epoch: 51
Loss: 0.39537872937650725
ROC train: 0.874273	val: 0.629864	test: 0.591585
PRC train: 0.828332	val: 0.660722	test: 0.624071

Epoch: 52
Loss: 0.38745983358614844
ROC train: 0.876535	val: 0.632170	test: 0.594763
PRC train: 0.831766	val: 0.661896	test: 0.624436

Epoch: 53
Loss: 0.3913771532235766
ROC train: 0.871310	val: 0.636118	test: 0.572030
PRC train: 0.826309	val: 0.664495	test: 0.619219

Epoch: 54
Loss: 0.38658516605810894
ROC train: 0.872998	val: 0.650786	test: 0.576917
PRC train: 0.826802	val: 0.671425	test: 0.623431

Epoch: 55
Loss: 0.38358358926947894
ROC train: 0.869932	val: 0.656061	test: 0.574496
PRC train: 0.827186	val: 0.675222	test: 0.618761

Epoch: 56
Loss: 0.3827803944800462
ROC train: 0.881088	val: 0.623579	test: 0.580510
PRC train: 0.835058	val: 0.656607	test: 0.614190

Epoch: 57
Loss: 0.374826451571254
ROC train: 0.881190	val: 0.625923	test: 0.581375
PRC train: 0.838748	val: 0.659598	test: 0.619737

Epoch: 58
Loss: 0.3715571040594073
ROC train: 0.883966	val: 0.628913	test: 0.582489
PRC train: 0.841252	val: 0.663429	test: 0.622109

Epoch: 59
Loss: 0.37667712683029864
ROC train: 0.888591	val: 0.625914	test: 0.576126
PRC train: 0.844196	val: 0.660199	test: 0.621667

Epoch: 60
Loss: 0.3736719491414521
ROC train: 0.886900	val: 0.625039	test: 0.566585
PRC train: 0.842655	val: 0.658560	test: 0.618146

Epoch: 61
Loss: 0.3701507756792068
ROC train: 0.886969	val: 0.636404	test: 0.570647
PRC train: 0.843327	val: 0.662512	test: 0.615139

Epoch: 62
Loss: 0.37033929499759777
ROC train: 0.888140	val: 0.635652	test: 0.580661
PRC train: 0.843929	val: 0.662247	test: 0.620938

Epoch: 63
Loss: 0.375626172147195
ROC train: 0.892074	val: 0.630457	test: 0.580100
PRC train: 0.849296	val: 0.664585	test: 0.621733

Epoch: 64
Loss: 0.36794590030861213
ROC train: 0.888072	val: 0.617465	test: 0.578427
PRC train: 0.847238	val: 0.662948	test: 0.620798

Epoch: 65
Loss: 0.36842917079910525
ROC train: 0.896838	val: 0.632682	test: 0.588128
PRC train: 0.852306	val: 0.662635	test: 0.625108

Epoch: 66
Loss: 0.3670353236262363
ROC train: 0.897440	val: 0.623023	test: 0.577320
PRC train: 0.851615	val: 0.659240	test: 0.620335

Epoch: 67
Loss: 0.36056811210880235
ROC train: 0.898520	val: 0.621622	test: 0.581833
PRC train: 0.854039	val: 0.660492	test: 0.621229

Epoch: 68
Loss: 0.3659318133423876
ROC train: 0.900283	val: 0.628508	test: 0.592426
PRC train: 0.859247	val: 0.662999	test: 0.627660

Epoch: 69
Loss: 0.361222358955283
ROC train: 0.902667	val: 0.619521	test: 0.580100
PRC train: 0.864077	val: 0.659747	test: 0.618465

Epoch: 70
Loss: 0.3584669297048661
ROC train: 0.903493	val: 0.620361	test: 0.590510
PRC train: 0.863559	val: 0.656332	test: 0.622896

Epoch: 71
Loss: 0.3554191417076775
ROC train: 0.901147	val: 0.626193	test: 0.587666
PRC train: 0.863353	val: 0.662700	test: 0.622781

Epoch: 72
Loss: 0.35481772573370585
ROC train: 0.902033	val: 0.622238	test: 0.579372
PRC train: 0.860369	val: 0.661171	test: 0.619429

Epoch: 73
Loss: 0.35592262565328275
ROC train: 0.898850	val: 0.643121	test: 0.579287
PRC train: 0.857207	val: 0.670846	test: 0.622195

Epoch: 74
Loss: 0.3553742496652701
ROC train: 0.901845	val: 0.611323	test: 0.587982
PRC train: 0.864935	val: 0.654175	test: 0.619510

Epoch: 75
Loss: 0.3533891081016176
ROC train: 0.904072	val: 0.627941	test: 0.586616
PRC train: 0.868291	val: 0.662169	test: 0.622108

Epoch: 76
Loss: 0.35066562021109315
ROC train: 0.906973	val: 0.637114	test: 0.587863
PRC train: 0.869724	val: 0.661886	test: 0.622716

Epoch: 77
Loss: 0.35070670657765146
ROC train: 0.908056	val: 0.630323	test: 0.582048
PRC train: 0.870029	val: 0.662654	test: 0.614932

Epoch: 78
Loss: 0.34947282258939716
ROC train: 0.909280	val: 0.644480	test: 0.575231
PRC train: 0.871235	val: 0.674029	test: 0.608970

Epoch: 79
Loss: 0.3474321567582495
ROC train: 0.910378	val: 0.639542	test: 0.575004
PRC train: 0.874882	val: 0.670904	test: 0.610240

Epoch: 80
Loss: 0.3461962231201651
ROC train: 0.912852	val: 0.634585	test: 0.574776
PRC train: 0.876547	val: 0.665054	test: 0.614153

Epoch: 81
Loss: 0.3420103563119115
ROC train: 0.913844	val: 0.620785	test: 0.577627
PRC train: 0.877937	val: 0.660094	test: 0.615994

Epoch: 82
Loss: 0.3391594785391316
ROC train: 0.912567	val: 0.605100	test: 0.577289
PRC train: 0.876866	val: 0.653518	test: 0.611730

Epoch: 83
Loss: 0.3438428296347221
ROC train: 0.910695	val: 0.632132	test: 0.578510
PRC train: 0.876224	val: 0.665906	test: 0.616171

Epoch: 84
Loss: 0.3333726595939397
ROC train: 0.914978	val: 0.639216	test: 0.587199
PRC train: 0.877969	val: 0.667244	test: 0.618319

Epoch: 85
Loss: 0.34324659497651133
ROC train: 0.916860	val: 0.635560	test: 0.577159
PRC train: 0.881055	val: 0.668387	test: 0.613564

Epoch: 86
Loss: 0.3357409258338282
ROC train: 0.918046	val: 0.618255	test: 0.587669
PRC train: 0.881956	val: 0.656612	test: 0.620527

Epoch: 87
Loss: 0.3362522413074592
ROC train: 0.921363	val: 0.617135	test: 0.590098
PRC train: 0.888960	val: 0.654159	test: 0.622486

Epoch: 88
Loss: 0.33466201417791375
ROC train: 0.915048	val: 0.622999	test: 0.577202
PRC train: 0.877241	val: 0.660814	test: 0.620392

Epoch: 89
Loss: 0.3331298093058647
ROC train: 0.918850	val: 0.609773	test: 0.577831
PRC train: 0.885362	val: 0.662416	test: 0.614901

Epoch: 90
Loss: 0.3284922979909602
ROC train: 0.919964	val: 0.621485	test: 0.574376
PRC train: 0.887747	val: 0.667918	test: 0.613333

Epoch: 91
Loss: 0.3285863560852989
ROC train: 0.925936	val: 0.622278	test: 0.576056
PRC train: 0.892580	val: 0.661509	test: 0.615749

Epoch: 92
Loss: 0.3307740137711047
ROC train: 0.926369	val: 0.624883	test: 0.577485
PRC train: 0.891346	val: 0.663748	test: 0.619713

Epoch: 93
Loss: 0.32880678089032417
ROC train: 0.925624	val: 0.623403	test: 0.579431
PRC train: 0.803761	val: 0.641203	test: 0.615557

Epoch: 33
Loss: 0.4143009148265436
ROC train: 0.845209	val: 0.580137	test: 0.572691
PRC train: 0.801988	val: 0.645192	test: 0.620692

Epoch: 34
Loss: 0.4193889539739854
ROC train: 0.848939	val: 0.583120	test: 0.557541
PRC train: 0.812527	val: 0.645045	test: 0.609913

Epoch: 35
Loss: 0.41359830914400153
ROC train: 0.851130	val: 0.586699	test: 0.561253
PRC train: 0.815113	val: 0.643472	test: 0.611905

Epoch: 36
Loss: 0.4137899448451866
ROC train: 0.855028	val: 0.581036	test: 0.574763
PRC train: 0.817454	val: 0.641741	test: 0.611435

Epoch: 37
Loss: 0.40970415566265717
ROC train: 0.859347	val: 0.578048	test: 0.587439
PRC train: 0.820425	val: 0.641147	test: 0.617927

Epoch: 38
Loss: 0.4116995833415119
ROC train: 0.855674	val: 0.589106	test: 0.578466
PRC train: 0.816610	val: 0.647601	test: 0.616257

Epoch: 39
Loss: 0.40771008352982385
ROC train: 0.859551	val: 0.596349	test: 0.579335
PRC train: 0.821638	val: 0.651418	test: 0.618339

Epoch: 40
Loss: 0.4041691484076673
ROC train: 0.861218	val: 0.570297	test: 0.579853
PRC train: 0.819398	val: 0.641356	test: 0.615106

Epoch: 41
Loss: 0.4037216400349197
ROC train: 0.865450	val: 0.581690	test: 0.586013
PRC train: 0.821544	val: 0.648681	test: 0.622106

Epoch: 42
Loss: 0.3995223904277208
ROC train: 0.865487	val: 0.595426	test: 0.588316
PRC train: 0.821649	val: 0.652717	test: 0.631005

Epoch: 43
Loss: 0.3995911457187728
ROC train: 0.865834	val: 0.592240	test: 0.583783
PRC train: 0.821937	val: 0.650063	test: 0.625590

Epoch: 44
Loss: 0.3933552644023447
ROC train: 0.869876	val: 0.570704	test: 0.598577
PRC train: 0.827594	val: 0.641929	test: 0.629991

Epoch: 45
Loss: 0.39535028728731436
ROC train: 0.872082	val: 0.577311	test: 0.599470
PRC train: 0.829691	val: 0.641475	test: 0.628233

Epoch: 46
Loss: 0.38791617589550975
ROC train: 0.871365	val: 0.588257	test: 0.589004
PRC train: 0.830666	val: 0.642694	test: 0.625840

Epoch: 47
Loss: 0.38444465054564947
ROC train: 0.870309	val: 0.588642	test: 0.586783
PRC train: 0.828513	val: 0.644977	test: 0.628207

Epoch: 48
Loss: 0.38957822375851114
ROC train: 0.879344	val: 0.583720	test: 0.589105
PRC train: 0.835990	val: 0.643789	test: 0.626320

Epoch: 49
Loss: 0.3827149089696822
ROC train: 0.879590	val: 0.586735	test: 0.587978
PRC train: 0.836649	val: 0.647083	test: 0.622975

Epoch: 50
Loss: 0.3816000745308684
ROC train: 0.879674	val: 0.587351	test: 0.595573
PRC train: 0.835564	val: 0.645499	test: 0.632961

Epoch: 51
Loss: 0.37659782655274904
ROC train: 0.883475	val: 0.582138	test: 0.592900
PRC train: 0.840248	val: 0.639002	test: 0.632588

Epoch: 52
Loss: 0.37518877917212495
ROC train: 0.883259	val: 0.578890	test: 0.588619
PRC train: 0.842560	val: 0.636347	test: 0.629501

Epoch: 53
Loss: 0.37532144235255444
ROC train: 0.884121	val: 0.586646	test: 0.588390
PRC train: 0.843767	val: 0.641037	test: 0.632685

Epoch: 54
Loss: 0.3700702404559194
ROC train: 0.888106	val: 0.590375	test: 0.587786
PRC train: 0.847540	val: 0.643712	test: 0.632530

Epoch: 55
Loss: 0.36995323326324525
ROC train: 0.888100	val: 0.579084	test: 0.585355
PRC train: 0.842464	val: 0.642395	test: 0.630861

Epoch: 56
Loss: 0.3718400757911435
ROC train: 0.887412	val: 0.570160	test: 0.596901
PRC train: 0.843479	val: 0.636852	test: 0.634067

Epoch: 57
Loss: 0.36775703126841863
ROC train: 0.890514	val: 0.569485	test: 0.593338
PRC train: 0.847260	val: 0.634454	test: 0.632715

Epoch: 58
Loss: 0.3634956449315103
ROC train: 0.891347	val: 0.576682	test: 0.586304
PRC train: 0.848372	val: 0.640273	test: 0.627316

Epoch: 59
Loss: 0.35979834159664925
ROC train: 0.895416	val: 0.576694	test: 0.586050
PRC train: 0.853363	val: 0.641365	test: 0.628798

Epoch: 60
Loss: 0.3626359841125072
ROC train: 0.898167	val: 0.572265	test: 0.586746
PRC train: 0.858874	val: 0.639432	test: 0.627844

Epoch: 61
Loss: 0.3618219958472363
ROC train: 0.898608	val: 0.580926	test: 0.577794
PRC train: 0.859250	val: 0.639994	test: 0.624701

Epoch: 62
Loss: 0.36093450851146625
ROC train: 0.898582	val: 0.578093	test: 0.577733
PRC train: 0.858869	val: 0.642627	test: 0.625308

Epoch: 63
Loss: 0.359234588751454
ROC train: 0.901433	val: 0.566092	test: 0.586860
PRC train: 0.860879	val: 0.636769	test: 0.629598

Epoch: 64
Loss: 0.35495434728517805
ROC train: 0.902209	val: 0.571049	test: 0.579565
PRC train: 0.859002	val: 0.637368	test: 0.629274

Epoch: 65
Loss: 0.35115687003634827
ROC train: 0.902908	val: 0.569214	test: 0.579155
PRC train: 0.862004	val: 0.633006	test: 0.627080

Epoch: 66
Loss: 0.3567886895742322
ROC train: 0.906027	val: 0.562935	test: 0.587279
PRC train: 0.866365	val: 0.629790	test: 0.626832

Epoch: 67
Loss: 0.3526721234848216
ROC train: 0.907493	val: 0.571817	test: 0.591166
PRC train: 0.869026	val: 0.637839	test: 0.629770

Epoch: 68
Loss: 0.34702766499204774
ROC train: 0.906512	val: 0.573922	test: 0.588432
PRC train: 0.869537	val: 0.638334	test: 0.629326

Epoch: 69
Loss: 0.35004679276302014
ROC train: 0.909596	val: 0.575863	test: 0.589274
PRC train: 0.872170	val: 0.635173	test: 0.630072

Epoch: 70
Loss: 0.34638351698811
ROC train: 0.907322	val: 0.596386	test: 0.579297
PRC train: 0.868471	val: 0.644546	test: 0.629231

Epoch: 71
Loss: 0.3433106582710806
ROC train: 0.909839	val: 0.589986	test: 0.579043
PRC train: 0.870252	val: 0.643565	test: 0.625591

Epoch: 72
Loss: 0.34754294622051224
ROC train: 0.911746	val: 0.581524	test: 0.577000
PRC train: 0.875276	val: 0.643655	test: 0.626192

Epoch: 73
Loss: 0.34308760074208644
ROC train: 0.912551	val: 0.577267	test: 0.579892
PRC train: 0.875383	val: 0.640051	test: 0.626102

Epoch: 74
Loss: 0.34396307879908194
ROC train: 0.914110	val: 0.577768	test: 0.583903
PRC train: 0.877469	val: 0.637842	test: 0.627388

Epoch: 75
Loss: 0.3405888930467392
ROC train: 0.914764	val: 0.585041	test: 0.578023
PRC train: 0.879437	val: 0.640883	test: 0.623970

Epoch: 76
Loss: 0.3367746567133312
ROC train: 0.916698	val: 0.583835	test: 0.580505
PRC train: 0.880135	val: 0.642229	test: 0.626516

Epoch: 77
Loss: 0.3433522286340617
ROC train: 0.915974	val: 0.587752	test: 0.585401
PRC train: 0.880353	val: 0.650866	test: 0.628165

Epoch: 78
Loss: 0.33602188252436604
ROC train: 0.916926	val: 0.580302	test: 0.581362
PRC train: 0.880206	val: 0.644162	test: 0.628703

Epoch: 79
Loss: 0.3361133024221421
ROC train: 0.917785	val: 0.577591	test: 0.586199
PRC train: 0.879936	val: 0.638742	test: 0.634725

Epoch: 80
Loss: 0.33052169770174616
ROC train: 0.921298	val: 0.577251	test: 0.588841
PRC train: 0.882857	val: 0.638295	test: 0.632573

Epoch: 81
Loss: 0.3319856888858944
ROC train: 0.922146	val: 0.582571	test: 0.587034
PRC train: 0.886985	val: 0.644450	test: 0.628019

Epoch: 82
Loss: 0.32649639625505406
ROC train: 0.922031	val: 0.590570	test: 0.578277
PRC train: 0.886573	val: 0.647052	test: 0.627296

Epoch: 83
Loss: 0.33150564187587633
ROC train: 0.924722	val: 0.587506	test: 0.578961
PRC train: 0.886909	val: 0.645038	test: 0.628861

Epoch: 84
Loss: 0.32285804905709686
ROC train: 0.925493	val: 0.587214	test: 0.574931
PRC train: 0.889015	val: 0.642690	test: 0.627884

Epoch: 85
Loss: 0.32316388950551783
ROC train: 0.925765	val: 0.584936	test: 0.571971
PRC train: 0.891566	val: 0.638115	test: 0.622198

Epoch: 86
Loss: 0.3196757629492173
ROC train: 0.927490	val: 0.583407	test: 0.576195
PRC train: 0.891835	val: 0.637793	test: 0.624672

Epoch: 87
Loss: 0.32620377359245645
ROC train: 0.929156	val: 0.572141	test: 0.588815
PRC train: 0.891979	val: 0.643396	test: 0.630801

Epoch: 88
Loss: 0.3247937411176031
ROC train: 0.931079	val: 0.570913	test: 0.583565
PRC train: 0.896680	val: 0.640067	test: 0.626066

Epoch: 89
Loss: 0.3205676344283794
ROC train: 0.929235	val: 0.582792	test: 0.571388
PRC train: 0.898187	val: 0.645743	test: 0.620818

Epoch: 90
Loss: 0.31760706203204586
ROC train: 0.929942	val: 0.572372	test: 0.578690
PRC train: 0.898191	val: 0.643348	test: 0.625878

Epoch: 91
Loss: 0.3171714196339389
ROC train: 0.932184	val: 0.562635	test: 0.582968
PRC train: 0.897258	val: 0.638799	test: 0.629185

Epoch: 92
Loss: 0.314190708991724
ROC train: 0.932653	val: 0.565913	test: 0.573804
PRC train: 0.894572	val: 0.636791	test: 0.624722

Epoch: 93
Loss: 0.31600267436184576
ROC train: 0.933554	val: 0.575203	test: 0.563949
PRC train: 0.809951	val: 0.641812	test: 0.597430

Epoch: 33
Loss: 0.4166418207081312
ROC train: 0.846314	val: 0.580387	test: 0.529208
PRC train: 0.812132	val: 0.637422	test: 0.596338

Epoch: 34
Loss: 0.40988621600635905
ROC train: 0.844659	val: 0.573007	test: 0.535103
PRC train: 0.810003	val: 0.629568	test: 0.599252

Epoch: 35
Loss: 0.41133645758305726
ROC train: 0.848336	val: 0.564969	test: 0.528579
PRC train: 0.813796	val: 0.626354	test: 0.597046

Epoch: 36
Loss: 0.410762144048475
ROC train: 0.851654	val: 0.556846	test: 0.537691
PRC train: 0.816927	val: 0.621312	test: 0.599708

Epoch: 37
Loss: 0.41201410191754884
ROC train: 0.856518	val: 0.562162	test: 0.534924
PRC train: 0.821285	val: 0.628029	test: 0.595287

Epoch: 38
Loss: 0.40508341852912483
ROC train: 0.855887	val: 0.571328	test: 0.540539
PRC train: 0.817322	val: 0.631404	test: 0.600074

Epoch: 39
Loss: 0.403401977806457
ROC train: 0.859094	val: 0.573497	test: 0.537901
PRC train: 0.823449	val: 0.633362	test: 0.598208

Epoch: 40
Loss: 0.40474099889155235
ROC train: 0.859334	val: 0.566412	test: 0.532320
PRC train: 0.824617	val: 0.628752	test: 0.594284

Epoch: 41
Loss: 0.40221608012562715
ROC train: 0.861614	val: 0.552333	test: 0.537031
PRC train: 0.825072	val: 0.619520	test: 0.596748

Epoch: 42
Loss: 0.3952928338724012
ROC train: 0.864205	val: 0.556793	test: 0.534019
PRC train: 0.828905	val: 0.624729	test: 0.596380

Epoch: 43
Loss: 0.39672949391439233
ROC train: 0.867218	val: 0.546190	test: 0.538896
PRC train: 0.831161	val: 0.628733	test: 0.599931

Epoch: 44
Loss: 0.38964456147304305
ROC train: 0.865998	val: 0.547396	test: 0.550260
PRC train: 0.832037	val: 0.629977	test: 0.607155

Epoch: 45
Loss: 0.38958941047616147
ROC train: 0.872197	val: 0.569401	test: 0.544122
PRC train: 0.835873	val: 0.636904	test: 0.602680

Epoch: 46
Loss: 0.3844497786955792
ROC train: 0.873030	val: 0.592700	test: 0.552260
PRC train: 0.839934	val: 0.644851	test: 0.603917

Epoch: 47
Loss: 0.38605645598149974
ROC train: 0.875178	val: 0.591388	test: 0.537842
PRC train: 0.838022	val: 0.645745	test: 0.599596

Epoch: 48
Loss: 0.3848551857864986
ROC train: 0.876137	val: 0.580396	test: 0.519004
PRC train: 0.836691	val: 0.642629	test: 0.591627

Epoch: 49
Loss: 0.3799889123581659
ROC train: 0.875813	val: 0.564828	test: 0.542499
PRC train: 0.838776	val: 0.635902	test: 0.602107

Epoch: 50
Loss: 0.38076026816061226
ROC train: 0.877180	val: 0.565644	test: 0.546041
PRC train: 0.841763	val: 0.630251	test: 0.606227

Epoch: 51
Loss: 0.3758572960569102
ROC train: 0.881226	val: 0.575383	test: 0.544557
PRC train: 0.845790	val: 0.636639	test: 0.603863

Epoch: 52
Loss: 0.36988399721844456
ROC train: 0.883936	val: 0.571544	test: 0.555028
PRC train: 0.848054	val: 0.635807	test: 0.608818

Epoch: 53
Loss: 0.37215900937457447
ROC train: 0.884770	val: 0.583700	test: 0.551570
PRC train: 0.847758	val: 0.639147	test: 0.606688

Epoch: 54
Loss: 0.3677088834617007
ROC train: 0.888667	val: 0.581128	test: 0.549547
PRC train: 0.853210	val: 0.638833	test: 0.605761

Epoch: 55
Loss: 0.3686831915362373
ROC train: 0.889374	val: 0.577713	test: 0.549640
PRC train: 0.854002	val: 0.640299	test: 0.606458

Epoch: 56
Loss: 0.366298525956568
ROC train: 0.890382	val: 0.565327	test: 0.546789
PRC train: 0.852159	val: 0.636010	test: 0.602709

Epoch: 57
Loss: 0.3698301821764205
ROC train: 0.892477	val: 0.570420	test: 0.547692
PRC train: 0.854807	val: 0.635582	test: 0.602161

Epoch: 58
Loss: 0.3651190669540151
ROC train: 0.891614	val: 0.572527	test: 0.552234
PRC train: 0.854050	val: 0.636646	test: 0.607130

Epoch: 59
Loss: 0.36927040217801743
ROC train: 0.895706	val: 0.585943	test: 0.555632
PRC train: 0.860154	val: 0.644920	test: 0.610464

Epoch: 60
Loss: 0.3647702328590212
ROC train: 0.895270	val: 0.562846	test: 0.560028
PRC train: 0.858116	val: 0.640838	test: 0.613459

Epoch: 61
Loss: 0.35954210221176697
ROC train: 0.897515	val: 0.569119	test: 0.552171
PRC train: 0.862154	val: 0.643345	test: 0.609196

Epoch: 62
Loss: 0.3644344848809288
ROC train: 0.897345	val: 0.584690	test: 0.546202
PRC train: 0.862466	val: 0.644034	test: 0.603957

Epoch: 63
Loss: 0.3537577541576791
ROC train: 0.901124	val: 0.572142	test: 0.552659
PRC train: 0.864959	val: 0.635894	test: 0.606829

Epoch: 64
Loss: 0.3538183524850096
ROC train: 0.900299	val: 0.565560	test: 0.542109
PRC train: 0.858217	val: 0.632041	test: 0.606307

Epoch: 65
Loss: 0.35332905012154314
ROC train: 0.900489	val: 0.569510	test: 0.563374
PRC train: 0.861499	val: 0.632852	test: 0.611258

Epoch: 66
Loss: 0.35427918698993865
ROC train: 0.904780	val: 0.564767	test: 0.558755
PRC train: 0.864463	val: 0.633711	test: 0.614035

Epoch: 67
Loss: 0.35111023007712283
ROC train: 0.905502	val: 0.561336	test: 0.555253
PRC train: 0.866795	val: 0.634391	test: 0.609295

Epoch: 68
Loss: 0.35101547876377
ROC train: 0.907960	val: 0.576779	test: 0.544448
PRC train: 0.873978	val: 0.645870	test: 0.603685

Epoch: 69
Loss: 0.347090857227979
ROC train: 0.908747	val: 0.576972	test: 0.546255
PRC train: 0.867461	val: 0.643936	test: 0.610228

Epoch: 70
Loss: 0.34306911018602293
ROC train: 0.908625	val: 0.583899	test: 0.541568
PRC train: 0.870343	val: 0.648668	test: 0.603061

Epoch: 71
Loss: 0.3428881442066275
ROC train: 0.909730	val: 0.563540	test: 0.567620
PRC train: 0.874050	val: 0.638336	test: 0.615278

Epoch: 72
Loss: 0.3463684940632747
ROC train: 0.913147	val: 0.569107	test: 0.560565
PRC train: 0.876291	val: 0.646663	test: 0.609419

Epoch: 73
Loss: 0.3474047229980405
ROC train: 0.912833	val: 0.563896	test: 0.550345
PRC train: 0.873436	val: 0.641024	test: 0.604740

Epoch: 74
Loss: 0.3416620693862092
ROC train: 0.914266	val: 0.579080	test: 0.542945
PRC train: 0.876552	val: 0.645241	test: 0.601766

Epoch: 75
Loss: 0.3297759649737119
ROC train: 0.917313	val: 0.583423	test: 0.534019
PRC train: 0.881252	val: 0.648157	test: 0.597463

Epoch: 76
Loss: 0.3401656600811811
ROC train: 0.918738	val: 0.571084	test: 0.531653
PRC train: 0.876371	val: 0.639628	test: 0.600056

Epoch: 77
Loss: 0.33197343992093586
ROC train: 0.919376	val: 0.558587	test: 0.542362
PRC train: 0.877829	val: 0.636552	test: 0.601740

Epoch: 78
Loss: 0.3336694387735094
ROC train: 0.920400	val: 0.576347	test: 0.558372
PRC train: 0.883952	val: 0.639007	test: 0.604355

Epoch: 79
Loss: 0.3321431090093972
ROC train: 0.920148	val: 0.575605	test: 0.557648
PRC train: 0.881321	val: 0.637049	test: 0.609358

Epoch: 80
Loss: 0.3276280302529023
ROC train: 0.921581	val: 0.579509	test: 0.548834
PRC train: 0.884000	val: 0.640167	test: 0.605305

Epoch: 81
Loss: 0.33095625948476615
ROC train: 0.923844	val: 0.560029	test: 0.548349
PRC train: 0.885722	val: 0.639695	test: 0.603908

Epoch: 82
Loss: 0.326727597965431
ROC train: 0.926142	val: 0.572303	test: 0.548427
PRC train: 0.889017	val: 0.648827	test: 0.605416

Epoch: 83
Loss: 0.3295380502057277
ROC train: 0.926631	val: 0.579650	test: 0.555106
PRC train: 0.890516	val: 0.651752	test: 0.607887

Epoch: 84
Loss: 0.3259582177760869
ROC train: 0.927795	val: 0.575525	test: 0.551005
PRC train: 0.890551	val: 0.643123	test: 0.603322

Epoch: 85
Loss: 0.3220222870793791
ROC train: 0.928255	val: 0.570871	test: 0.550862
PRC train: 0.890053	val: 0.644306	test: 0.604139

Epoch: 86
Loss: 0.32255097552579787
ROC train: 0.929611	val: 0.576845	test: 0.547356
PRC train: 0.892023	val: 0.649440	test: 0.601858

Epoch: 87
Loss: 0.32369196125740063
ROC train: 0.929869	val: 0.568054	test: 0.552641
PRC train: 0.894196	val: 0.639994	test: 0.608291

Epoch: 88
Loss: 0.32046223549900843
ROC train: 0.925750	val: 0.577976	test: 0.537098
PRC train: 0.891966	val: 0.645363	test: 0.598093

Epoch: 89
Loss: 0.31720091415924595
ROC train: 0.931816	val: 0.575087	test: 0.541893
PRC train: 0.893105	val: 0.646878	test: 0.604409

Epoch: 90
Loss: 0.31394106568680313
ROC train: 0.932479	val: 0.571870	test: 0.551338
PRC train: 0.895381	val: 0.642816	test: 0.606434

Epoch: 91
Loss: 0.3223997768676465
ROC train: 0.931333	val: 0.577573	test: 0.555277
PRC train: 0.892084	val: 0.642218	test: 0.608509

Epoch: 92
Loss: 0.31481663209253724
ROC train: 0.933890	val: 0.567547	test: 0.543965
PRC train: 0.896486	val: 0.640112	test: 0.602523

Epoch: 93
Loss: 0.3147437813535957
ROC train: 0.937015	val: 0.574663	test: 0.538394
PRC train: 0.793689	val: 0.667511	test: 0.637901

Epoch: 33
Loss: 0.4161144464101305
ROC train: 0.840906	val: 0.611192	test: 0.606779
PRC train: 0.795725	val: 0.664785	test: 0.639268

Epoch: 34
Loss: 0.41465803699993026
ROC train: 0.840201	val: 0.624941	test: 0.600692
PRC train: 0.794595	val: 0.673286	test: 0.641493

Epoch: 35
Loss: 0.41351335025349734
ROC train: 0.848801	val: 0.624003	test: 0.604509
PRC train: 0.801020	val: 0.672236	test: 0.637874

Epoch: 36
Loss: 0.41075973881608274
ROC train: 0.848021	val: 0.620973	test: 0.616638
PRC train: 0.800971	val: 0.667699	test: 0.635086

Epoch: 37
Loss: 0.4101178311926009
ROC train: 0.855474	val: 0.605739	test: 0.617643
PRC train: 0.808253	val: 0.666162	test: 0.637079

Epoch: 38
Loss: 0.40707750244071284
ROC train: 0.858934	val: 0.610592	test: 0.616446
PRC train: 0.812632	val: 0.669839	test: 0.638642

Epoch: 39
Loss: 0.40231162135745846
ROC train: 0.858933	val: 0.617703	test: 0.620535
PRC train: 0.811440	val: 0.674161	test: 0.644069

Epoch: 40
Loss: 0.3981271509618877
ROC train: 0.861834	val: 0.613264	test: 0.617796
PRC train: 0.814135	val: 0.670610	test: 0.636320

Epoch: 41
Loss: 0.4017305971714942
ROC train: 0.862475	val: 0.605901	test: 0.614383
PRC train: 0.813821	val: 0.664870	test: 0.633498

Epoch: 42
Loss: 0.40018611147862215
ROC train: 0.863002	val: 0.623633	test: 0.609773
PRC train: 0.815160	val: 0.673872	test: 0.633399

Epoch: 43
Loss: 0.401141142104336
ROC train: 0.865013	val: 0.625170	test: 0.610492
PRC train: 0.818423	val: 0.673246	test: 0.634044

Epoch: 44
Loss: 0.39250410072467823
ROC train: 0.868019	val: 0.621609	test: 0.613760
PRC train: 0.821530	val: 0.669446	test: 0.630729

Epoch: 45
Loss: 0.3903889568564004
ROC train: 0.870022	val: 0.627305	test: 0.609830
PRC train: 0.822335	val: 0.669292	test: 0.636119

Epoch: 46
Loss: 0.3903786513472264
ROC train: 0.865824	val: 0.640520	test: 0.617290
PRC train: 0.815431	val: 0.677177	test: 0.644422

Epoch: 47
Loss: 0.39093865668837796
ROC train: 0.875046	val: 0.622563	test: 0.620178
PRC train: 0.826117	val: 0.668062	test: 0.646485

Epoch: 48
Loss: 0.3808397345647424
ROC train: 0.878338	val: 0.617025	test: 0.618534
PRC train: 0.832120	val: 0.670068	test: 0.640615

Epoch: 49
Loss: 0.3866659301977881
ROC train: 0.879394	val: 0.619765	test: 0.611698
PRC train: 0.831850	val: 0.673200	test: 0.639129

Epoch: 50
Loss: 0.3787737321561324
ROC train: 0.882119	val: 0.618755	test: 0.607298
PRC train: 0.835317	val: 0.668440	test: 0.641018

Epoch: 51
Loss: 0.3816481044132835
ROC train: 0.884023	val: 0.627610	test: 0.604571
PRC train: 0.836901	val: 0.669859	test: 0.639232

Epoch: 52
Loss: 0.37490868961536034
ROC train: 0.884909	val: 0.631218	test: 0.600004
PRC train: 0.837647	val: 0.670995	test: 0.631268

Epoch: 53
Loss: 0.381017194678154
ROC train: 0.884605	val: 0.628585	test: 0.592087
PRC train: 0.836155	val: 0.670408	test: 0.632742

Epoch: 54
Loss: 0.3718477672205013
ROC train: 0.886346	val: 0.621018	test: 0.584997
PRC train: 0.837532	val: 0.667603	test: 0.633462

Epoch: 55
Loss: 0.3689100732834163
ROC train: 0.886692	val: 0.629699	test: 0.584502
PRC train: 0.837437	val: 0.669704	test: 0.634297

Epoch: 56
Loss: 0.370932742290369
ROC train: 0.890523	val: 0.621549	test: 0.599418
PRC train: 0.843052	val: 0.670435	test: 0.636268

Epoch: 57
Loss: 0.3681745524821576
ROC train: 0.891367	val: 0.627851	test: 0.608634
PRC train: 0.843610	val: 0.668428	test: 0.641678

Epoch: 58
Loss: 0.3667760483099286
ROC train: 0.892926	val: 0.625720	test: 0.606942
PRC train: 0.845847	val: 0.665946	test: 0.645164

Epoch: 59
Loss: 0.36159221821635745
ROC train: 0.897545	val: 0.625619	test: 0.604145
PRC train: 0.851206	val: 0.663137	test: 0.642807

Epoch: 60
Loss: 0.3626890230812771
ROC train: 0.895426	val: 0.632394	test: 0.597585
PRC train: 0.848890	val: 0.664865	test: 0.639162

Epoch: 61
Loss: 0.35644266620714715
ROC train: 0.896764	val: 0.621540	test: 0.594195
PRC train: 0.848512	val: 0.660016	test: 0.639160

Epoch: 62
Loss: 0.3565007768069798
ROC train: 0.896939	val: 0.620926	test: 0.588716
PRC train: 0.847805	val: 0.660160	test: 0.638549

Epoch: 63
Loss: 0.3599310910258052
ROC train: 0.901243	val: 0.614319	test: 0.587875
PRC train: 0.855191	val: 0.658657	test: 0.635323

Epoch: 64
Loss: 0.3555104535013595
ROC train: 0.897856	val: 0.627623	test: 0.586995
PRC train: 0.853636	val: 0.666136	test: 0.635897

Epoch: 65
Loss: 0.3507449765084056
ROC train: 0.901560	val: 0.618212	test: 0.598278
PRC train: 0.857301	val: 0.663999	test: 0.635279

Epoch: 66
Loss: 0.3503613736701393
ROC train: 0.903434	val: 0.615397	test: 0.597590
PRC train: 0.858748	val: 0.662519	test: 0.637083

Epoch: 67
Loss: 0.3535373462420666
ROC train: 0.902920	val: 0.631183	test: 0.588985
PRC train: 0.857317	val: 0.667292	test: 0.638473

Epoch: 68
Loss: 0.34745121241429616
ROC train: 0.904780	val: 0.621710	test: 0.588917
PRC train: 0.859927	val: 0.665582	test: 0.637934

Epoch: 69
Loss: 0.34978256474052893
ROC train: 0.904662	val: 0.617455	test: 0.585973
PRC train: 0.862447	val: 0.660203	test: 0.634336

Epoch: 70
Loss: 0.34621382556598157
ROC train: 0.907630	val: 0.618451	test: 0.588390
PRC train: 0.865206	val: 0.656674	test: 0.639009

Epoch: 71
Loss: 0.3440341198681121
ROC train: 0.908579	val: 0.606380	test: 0.598610
PRC train: 0.867743	val: 0.656539	test: 0.639265

Epoch: 72
Loss: 0.34484039148764867
ROC train: 0.910451	val: 0.612920	test: 0.600012
PRC train: 0.868642	val: 0.663425	test: 0.641212

Epoch: 73
Loss: 0.3374415392692229
ROC train: 0.910618	val: 0.620700	test: 0.605155
PRC train: 0.866462	val: 0.667027	test: 0.647509

Epoch: 74
Loss: 0.3436972989712869
ROC train: 0.912637	val: 0.620139	test: 0.602606
PRC train: 0.870306	val: 0.663771	test: 0.646782

Epoch: 75
Loss: 0.3421686331817771
ROC train: 0.914216	val: 0.626270	test: 0.586404
PRC train: 0.872805	val: 0.664331	test: 0.633957

Epoch: 76
Loss: 0.33622218429248807
ROC train: 0.914169	val: 0.618974	test: 0.589885
PRC train: 0.874331	val: 0.657939	test: 0.634733

Epoch: 77
Loss: 0.3410951562906848
ROC train: 0.917835	val: 0.619768	test: 0.584568
PRC train: 0.877003	val: 0.659164	test: 0.635061

Epoch: 78
Loss: 0.33401080742136197
ROC train: 0.918734	val: 0.604150	test: 0.586175
PRC train: 0.876509	val: 0.654400	test: 0.637287

Epoch: 79
Loss: 0.3355647225443001
ROC train: 0.918324	val: 0.609348	test: 0.586158
PRC train: 0.879932	val: 0.656874	test: 0.637190

Epoch: 80
Loss: 0.32727227035432704
ROC train: 0.918109	val: 0.623570	test: 0.590932
PRC train: 0.878492	val: 0.662179	test: 0.639431

Epoch: 81
Loss: 0.32939477637964976
ROC train: 0.919061	val: 0.625265	test: 0.590399
PRC train: 0.879416	val: 0.662532	test: 0.641390

Epoch: 82
Loss: 0.3253836111811565
ROC train: 0.920587	val: 0.616145	test: 0.594926
PRC train: 0.882695	val: 0.661832	test: 0.642461

Epoch: 83
Loss: 0.3261556765551664
ROC train: 0.922881	val: 0.621465	test: 0.587275
PRC train: 0.885068	val: 0.664442	test: 0.636912

Epoch: 84
Loss: 0.327003114597394
ROC train: 0.921342	val: 0.616117	test: 0.587791
PRC train: 0.883354	val: 0.660526	test: 0.635932

Epoch: 85
Loss: 0.32669155973346353
ROC train: 0.924700	val: 0.617595	test: 0.591574
PRC train: 0.887270	val: 0.662508	test: 0.641384

Epoch: 86
Loss: 0.322674561690941
ROC train: 0.926751	val: 0.626632	test: 0.587677
PRC train: 0.886833	val: 0.662630	test: 0.639219

Epoch: 87
Loss: 0.32228159270936585
ROC train: 0.926805	val: 0.626776	test: 0.587386
PRC train: 0.886310	val: 0.663350	test: 0.635232

Epoch: 88
Loss: 0.32485463401902137
ROC train: 0.927705	val: 0.621811	test: 0.587585
PRC train: 0.891884	val: 0.661281	test: 0.634651

Epoch: 89
Loss: 0.31689720962644957
ROC train: 0.926142	val: 0.623672	test: 0.581815
PRC train: 0.892071	val: 0.668730	test: 0.631994

Epoch: 90
Loss: 0.3149378542182682
ROC train: 0.930098	val: 0.610280	test: 0.584464
PRC train: 0.894936	val: 0.662242	test: 0.637550

Epoch: 91
Loss: 0.31165326713336494
ROC train: 0.930213	val: 0.614981	test: 0.581218
PRC train: 0.893392	val: 0.657811	test: 0.636144

Epoch: 92
Loss: 0.3116981146697788
ROC train: 0.930188	val: 0.613445	test: 0.584283
PRC train: 0.895464	val: 0.655532	test: 0.638211

Epoch: 93
Loss: 0.31123308794824417
ROC train: 0.930917	val: 0.613497	test: 0.577658
PRC train: 0.798407	val: 0.646455	test: 0.628804

Epoch: 33
Loss: 0.4218183289209512
ROC train: 0.844297	val: 0.576234	test: 0.566329
PRC train: 0.801796	val: 0.649151	test: 0.620758

Epoch: 34
Loss: 0.4144202399734388
ROC train: 0.847516	val: 0.583699	test: 0.571466
PRC train: 0.805081	val: 0.657167	test: 0.621626

Epoch: 35
Loss: 0.4144015632255802
ROC train: 0.850127	val: 0.582676	test: 0.560871
PRC train: 0.807166	val: 0.654635	test: 0.614793

Epoch: 36
Loss: 0.41918738769452285
ROC train: 0.853254	val: 0.592166	test: 0.556323
PRC train: 0.809232	val: 0.656525	test: 0.603477

Epoch: 37
Loss: 0.41273036196381635
ROC train: 0.852501	val: 0.594328	test: 0.576221
PRC train: 0.810113	val: 0.660545	test: 0.621126

Epoch: 38
Loss: 0.4110119401995562
ROC train: 0.853735	val: 0.599758	test: 0.573493
PRC train: 0.810320	val: 0.664081	test: 0.618096

Epoch: 39
Loss: 0.4073660076089459
ROC train: 0.856270	val: 0.594755	test: 0.577843
PRC train: 0.815360	val: 0.659991	test: 0.622702

Epoch: 40
Loss: 0.4002727597514365
ROC train: 0.862011	val: 0.591223	test: 0.580236
PRC train: 0.819990	val: 0.655150	test: 0.625469

Epoch: 41
Loss: 0.4020170245281892
ROC train: 0.865024	val: 0.593896	test: 0.578799
PRC train: 0.821851	val: 0.656665	test: 0.626716

Epoch: 42
Loss: 0.39441676707459983
ROC train: 0.866380	val: 0.593223	test: 0.587021
PRC train: 0.823849	val: 0.658317	test: 0.632477

Epoch: 43
Loss: 0.4001297582168098
ROC train: 0.868508	val: 0.600354	test: 0.582005
PRC train: 0.825818	val: 0.664971	test: 0.629966

Epoch: 44
Loss: 0.39426151010391786
ROC train: 0.871173	val: 0.600991	test: 0.574244
PRC train: 0.827899	val: 0.666432	test: 0.622482

Epoch: 45
Loss: 0.39149804297630375
ROC train: 0.875384	val: 0.607342	test: 0.572419
PRC train: 0.833677	val: 0.666057	test: 0.619307

Epoch: 46
Loss: 0.3907572103025347
ROC train: 0.875438	val: 0.606232	test: 0.575136
PRC train: 0.836726	val: 0.665917	test: 0.620054

Epoch: 47
Loss: 0.38833847649221975
ROC train: 0.875208	val: 0.607118	test: 0.559706
PRC train: 0.839210	val: 0.666320	test: 0.611466

Epoch: 48
Loss: 0.3881645481948867
ROC train: 0.875102	val: 0.598905	test: 0.561576
PRC train: 0.838254	val: 0.660362	test: 0.610607

Epoch: 49
Loss: 0.3878205148061792
ROC train: 0.879409	val: 0.594104	test: 0.582351
PRC train: 0.841535	val: 0.665354	test: 0.621680

Epoch: 50
Loss: 0.3817272334104885
ROC train: 0.882032	val: 0.599870	test: 0.581629
PRC train: 0.843404	val: 0.666408	test: 0.621818

Epoch: 51
Loss: 0.3835271889061075
ROC train: 0.882986	val: 0.598081	test: 0.583422
PRC train: 0.843766	val: 0.662062	test: 0.627636

Epoch: 52
Loss: 0.3812671981680614
ROC train: 0.882846	val: 0.608390	test: 0.581667
PRC train: 0.845290	val: 0.672602	test: 0.622708

Epoch: 53
Loss: 0.3819693862737735
ROC train: 0.885284	val: 0.607826	test: 0.582177
PRC train: 0.847415	val: 0.670100	test: 0.626350

Epoch: 54
Loss: 0.37547842581004376
ROC train: 0.885137	val: 0.594261	test: 0.594243
PRC train: 0.851906	val: 0.662591	test: 0.635332

Epoch: 55
Loss: 0.3728495272511804
ROC train: 0.887122	val: 0.613118	test: 0.570539
PRC train: 0.848654	val: 0.669721	test: 0.617106

Epoch: 56
Loss: 0.37110486306986096
ROC train: 0.888600	val: 0.614024	test: 0.581605
PRC train: 0.848666	val: 0.675526	test: 0.625631

Epoch: 57
Loss: 0.36770521178613
ROC train: 0.891356	val: 0.611917	test: 0.583699
PRC train: 0.852711	val: 0.672956	test: 0.624030

Epoch: 58
Loss: 0.36655598255212823
ROC train: 0.891750	val: 0.601070	test: 0.584097
PRC train: 0.853058	val: 0.670489	test: 0.620711

Epoch: 59
Loss: 0.36680819719160007
ROC train: 0.895566	val: 0.599635	test: 0.586991
PRC train: 0.859358	val: 0.669078	test: 0.628774

Epoch: 60
Loss: 0.3668896769866772
ROC train: 0.897835	val: 0.608070	test: 0.585034
PRC train: 0.859220	val: 0.672475	test: 0.631149

Epoch: 61
Loss: 0.3661984498588956
ROC train: 0.898179	val: 0.608986	test: 0.578506
PRC train: 0.861275	val: 0.672989	test: 0.624788

Epoch: 62
Loss: 0.3621207136762534
ROC train: 0.899762	val: 0.606843	test: 0.582697
PRC train: 0.865352	val: 0.668400	test: 0.626840

Epoch: 63
Loss: 0.35731385148621814
ROC train: 0.900450	val: 0.611737	test: 0.574422
PRC train: 0.865128	val: 0.672575	test: 0.620409

Epoch: 64
Loss: 0.35725011677149165
ROC train: 0.901304	val: 0.616163	test: 0.581471
PRC train: 0.863094	val: 0.674155	test: 0.621555

Epoch: 65
Loss: 0.35726653310347245
ROC train: 0.903360	val: 0.619818	test: 0.588408
PRC train: 0.865973	val: 0.674610	test: 0.633029

Epoch: 66
Loss: 0.35821101620244533
ROC train: 0.902903	val: 0.611495	test: 0.589050
PRC train: 0.869191	val: 0.669223	test: 0.635075

Epoch: 67
Loss: 0.35037986078338623
ROC train: 0.903429	val: 0.614395	test: 0.584120
PRC train: 0.870495	val: 0.670800	test: 0.629644

Epoch: 68
Loss: 0.3533206150110716
ROC train: 0.906530	val: 0.613853	test: 0.585089
PRC train: 0.873799	val: 0.670621	test: 0.630323

Epoch: 69
Loss: 0.35252583593021686
ROC train: 0.909201	val: 0.612632	test: 0.587312
PRC train: 0.874669	val: 0.669154	test: 0.633718

Epoch: 70
Loss: 0.34896434801027076
ROC train: 0.908807	val: 0.613073	test: 0.588948
PRC train: 0.875933	val: 0.672402	test: 0.628682

Epoch: 71
Loss: 0.3473691260901469
ROC train: 0.910768	val: 0.611162	test: 0.585893
PRC train: 0.876922	val: 0.676788	test: 0.625845

Epoch: 72
Loss: 0.3469390215430481
ROC train: 0.909101	val: 0.617574	test: 0.571714
PRC train: 0.876677	val: 0.672048	test: 0.618043

Epoch: 73
Loss: 0.3501401112040353
ROC train: 0.909737	val: 0.615275	test: 0.556281
PRC train: 0.878767	val: 0.672518	test: 0.604917

Epoch: 74
Loss: 0.3443378273495517
ROC train: 0.913055	val: 0.613517	test: 0.582470
PRC train: 0.883017	val: 0.671822	test: 0.627356

Epoch: 75
Loss: 0.3417347094846686
ROC train: 0.917556	val: 0.617692	test: 0.580530
PRC train: 0.885210	val: 0.676936	test: 0.626597

Epoch: 76
Loss: 0.3414441869762407
ROC train: 0.918468	val: 0.617458	test: 0.578901
PRC train: 0.887691	val: 0.681951	test: 0.623427

Epoch: 77
Loss: 0.33971795772545504
ROC train: 0.917901	val: 0.605981	test: 0.578904
PRC train: 0.887293	val: 0.667770	test: 0.624818

Epoch: 78
Loss: 0.3380043034215202
ROC train: 0.917023	val: 0.604450	test: 0.574909
PRC train: 0.884060	val: 0.662437	test: 0.623907

Epoch: 79
Loss: 0.3394740303308815
ROC train: 0.918816	val: 0.603492	test: 0.581416
PRC train: 0.891360	val: 0.660740	test: 0.625549

Epoch: 80
Loss: 0.34055209444384327
ROC train: 0.921407	val: 0.604862	test: 0.577966
PRC train: 0.894816	val: 0.658185	test: 0.624059

Epoch: 81
Loss: 0.3362469087098751
ROC train: 0.920805	val: 0.599536	test: 0.587425
PRC train: 0.894906	val: 0.664231	test: 0.625218

Epoch: 82
Loss: 0.3340860183580623
ROC train: 0.923379	val: 0.595050	test: 0.593426
PRC train: 0.899691	val: 0.663455	test: 0.627433

Epoch: 83
Loss: 0.32851367325301456
ROC train: 0.925371	val: 0.599711	test: 0.584673
PRC train: 0.902714	val: 0.667121	test: 0.624218

Epoch: 84
Loss: 0.3265285584400136
ROC train: 0.927439	val: 0.605394	test: 0.582003
PRC train: 0.904762	val: 0.668296	test: 0.623443

Epoch: 85
Loss: 0.32868416417511165
ROC train: 0.926918	val: 0.604157	test: 0.580120
PRC train: 0.903496	val: 0.665863	test: 0.625071

Epoch: 86
Loss: 0.3270575364152319
ROC train: 0.926619	val: 0.606827	test: 0.567805
PRC train: 0.902695	val: 0.667927	test: 0.619432

Epoch: 87
Loss: 0.3232677243394615
ROC train: 0.928524	val: 0.609719	test: 0.573824
PRC train: 0.906689	val: 0.670019	test: 0.623208

Epoch: 88
Loss: 0.3202474380548931
ROC train: 0.929703	val: 0.611833	test: 0.573243
PRC train: 0.907138	val: 0.668597	test: 0.622713

Epoch: 89
Loss: 0.3203103438094744
ROC train: 0.932565	val: 0.610025	test: 0.566347
PRC train: 0.909153	val: 0.668289	test: 0.620444

Epoch: 90
Loss: 0.317958464313306
ROC train: 0.934006	val: 0.603169	test: 0.576078
PRC train: 0.912530	val: 0.666770	test: 0.621162

Epoch: 91
Loss: 0.321379660113131
ROC train: 0.934780	val: 0.601543	test: 0.582188
PRC train: 0.914124	val: 0.666379	test: 0.620879

Epoch: 92
Loss: 0.3154035363064819
ROC train: 0.934507	val: 0.600541	test: 0.586661
PRC train: 0.912920	val: 0.663471	test: 0.624996

Epoch: 93
Loss: 0.31952898249760625
ROC train: 0.936025	val: 0.605191	test: 0.581852

PRC train: 0.852937	val: 0.672115	test: 0.630760

Epoch: 95
Loss: 0.3649944138222106
ROC train: 0.896124	val: 0.636249	test: 0.594721
PRC train: 0.853064	val: 0.671331	test: 0.627423

Epoch: 96
Loss: 0.36281322711248865
ROC train: 0.895336	val: 0.631846	test: 0.597931
PRC train: 0.852636	val: 0.669456	test: 0.629157

Epoch: 97
Loss: 0.36797190357423154
ROC train: 0.896487	val: 0.627721	test: 0.599855
PRC train: 0.855321	val: 0.669193	test: 0.629107

Epoch: 98
Loss: 0.36345247780923673
ROC train: 0.892685	val: 0.640278	test: 0.597550
PRC train: 0.851859	val: 0.671649	test: 0.630879

Epoch: 99
Loss: 0.3605289623456377
ROC train: 0.898527	val: 0.636559	test: 0.603361
PRC train: 0.858969	val: 0.670074	test: 0.632201

Epoch: 100
Loss: 0.36161177176038484
ROC train: 0.895931	val: 0.631155	test: 0.612216
PRC train: 0.853551	val: 0.670429	test: 0.634906

Epoch: 101
Loss: 0.3634331047218032
ROC train: 0.898826	val: 0.641990	test: 0.603748
PRC train: 0.855727	val: 0.676884	test: 0.632219

Epoch: 102
Loss: 0.3584716815015002
ROC train: 0.901904	val: 0.645559	test: 0.589935
PRC train: 0.860416	val: 0.678378	test: 0.624879

Epoch: 103
Loss: 0.36232903201959965
ROC train: 0.904758	val: 0.635007	test: 0.596013
PRC train: 0.863126	val: 0.673650	test: 0.626206

Epoch: 104
Loss: 0.3577254430248169
ROC train: 0.903826	val: 0.623493	test: 0.605166
PRC train: 0.860992	val: 0.670662	test: 0.631784

Epoch: 105
Loss: 0.35146141098893463
ROC train: 0.905566	val: 0.628458	test: 0.598927
PRC train: 0.862794	val: 0.671537	test: 0.631521

Epoch: 106
Loss: 0.3545967304453345
ROC train: 0.905309	val: 0.637005	test: 0.590157
PRC train: 0.863650	val: 0.677045	test: 0.627485

Epoch: 107
Loss: 0.3479822675027695
ROC train: 0.906799	val: 0.640334	test: 0.593907
PRC train: 0.867299	val: 0.678446	test: 0.625795

Epoch: 108
Loss: 0.3534047418090921
ROC train: 0.907331	val: 0.637079	test: 0.600049
PRC train: 0.869536	val: 0.675205	test: 0.626486

Epoch: 109
Loss: 0.3506360054668224
ROC train: 0.909975	val: 0.641094	test: 0.597453
PRC train: 0.871679	val: 0.672698	test: 0.627163

Epoch: 110
Loss: 0.3479717104047572
ROC train: 0.911307	val: 0.636328	test: 0.597741
PRC train: 0.872041	val: 0.670523	test: 0.628127

Epoch: 111
Loss: 0.34465995026200813
ROC train: 0.908039	val: 0.624086	test: 0.608547
PRC train: 0.868474	val: 0.667109	test: 0.629645

Epoch: 112
Loss: 0.3485055904804818
ROC train: 0.909508	val: 0.628855	test: 0.596091
PRC train: 0.868848	val: 0.672808	test: 0.626995

Epoch: 113
Loss: 0.3511243848360128
ROC train: 0.911546	val: 0.628470	test: 0.586889
PRC train: 0.869942	val: 0.674913	test: 0.623380

Epoch: 114
Loss: 0.3443531796877135
ROC train: 0.914628	val: 0.634347	test: 0.593335
PRC train: 0.872831	val: 0.673978	test: 0.627901

Epoch: 115
Loss: 0.3451749943037138
ROC train: 0.912198	val: 0.636502	test: 0.603362
PRC train: 0.871575	val: 0.675101	test: 0.627752

Epoch: 116
Loss: 0.34398365833051386
ROC train: 0.912975	val: 0.634126	test: 0.595112
PRC train: 0.871008	val: 0.672457	test: 0.624308

Epoch: 117
Loss: 0.34283314701521966
ROC train: 0.914755	val: 0.629909	test: 0.582516
PRC train: 0.872507	val: 0.670152	test: 0.621058

Epoch: 118
Loss: 0.3440401036388001
ROC train: 0.916247	val: 0.624396	test: 0.593862
PRC train: 0.877018	val: 0.668543	test: 0.624551

Epoch: 119
Loss: 0.34510592950730623
ROC train: 0.916647	val: 0.623133	test: 0.600675
PRC train: 0.879558	val: 0.671518	test: 0.628158

Epoch: 120
Loss: 0.3443212333878513
ROC train: 0.917151	val: 0.625384	test: 0.596901
PRC train: 0.879666	val: 0.669342	test: 0.625915

Early stopping
Best (ROC):	 train: 0.864345	val: 0.652052	test: 0.596340
Best (PRC):	 train: 0.821064	val: 0.683559	test: 0.625382

PRC train: 0.899032	val: 0.659623	test: 0.620971

Epoch: 94
Loss: 0.3196118481863203
ROC train: 0.934072	val: 0.629803	test: 0.588641
PRC train: 0.898408	val: 0.662862	test: 0.625610

Epoch: 95
Loss: 0.3143124478476285
ROC train: 0.932424	val: 0.625090	test: 0.592379
PRC train: 0.895100	val: 0.661822	test: 0.625983

Epoch: 96
Loss: 0.3165481793508177
ROC train: 0.935704	val: 0.632500	test: 0.582742
PRC train: 0.898372	val: 0.660822	test: 0.621815

Epoch: 97
Loss: 0.31617530667256133
ROC train: 0.938127	val: 0.632896	test: 0.582792
PRC train: 0.903256	val: 0.660644	test: 0.621009

Epoch: 98
Loss: 0.30972489962886024
ROC train: 0.937473	val: 0.629063	test: 0.591494
PRC train: 0.904030	val: 0.659614	test: 0.624706

Epoch: 99
Loss: 0.3110615304354003
ROC train: 0.934753	val: 0.625964	test: 0.591447
PRC train: 0.901695	val: 0.657006	test: 0.623055

Epoch: 100
Loss: 0.30649811273056615
ROC train: 0.934038	val: 0.623436	test: 0.583650
PRC train: 0.899610	val: 0.656162	test: 0.621716

Epoch: 101
Loss: 0.3075901068647401
ROC train: 0.940467	val: 0.630529	test: 0.587597
PRC train: 0.907194	val: 0.661552	test: 0.624424

Epoch: 102
Loss: 0.30793022287374283
ROC train: 0.941485	val: 0.624730	test: 0.592828
PRC train: 0.908049	val: 0.661782	test: 0.629957

Epoch: 103
Loss: 0.2994499620505468
ROC train: 0.941399	val: 0.627283	test: 0.580741
PRC train: 0.907218	val: 0.660211	test: 0.622239

Epoch: 104
Loss: 0.30081520695251046
ROC train: 0.944331	val: 0.634917	test: 0.585186
PRC train: 0.912437	val: 0.659876	test: 0.617661

Epoch: 105
Loss: 0.29810653279289545
ROC train: 0.944524	val: 0.633823	test: 0.585829
PRC train: 0.912811	val: 0.659735	test: 0.619833

Epoch: 106
Loss: 0.29787705623785277
ROC train: 0.944487	val: 0.624703	test: 0.585943
PRC train: 0.910967	val: 0.653554	test: 0.621687

Epoch: 107
Loss: 0.2965906225825453
ROC train: 0.945286	val: 0.627907	test: 0.588904
PRC train: 0.913509	val: 0.657557	test: 0.627539

Epoch: 108
Loss: 0.301726683461843
ROC train: 0.947900	val: 0.633895	test: 0.589540
PRC train: 0.919470	val: 0.662685	test: 0.629277

Epoch: 109
Loss: 0.3022229183993996
ROC train: 0.945806	val: 0.622444	test: 0.577823
PRC train: 0.917889	val: 0.657000	test: 0.620544

Epoch: 110
Loss: 0.29965063412829573
ROC train: 0.947279	val: 0.620309	test: 0.576664
PRC train: 0.916132	val: 0.653780	test: 0.618466

Epoch: 111
Loss: 0.3012039690235303
ROC train: 0.949412	val: 0.626792	test: 0.585410
PRC train: 0.916331	val: 0.656069	test: 0.623325

Epoch: 112
Loss: 0.2906418461094159
ROC train: 0.949070	val: 0.629970	test: 0.584154
PRC train: 0.918687	val: 0.660362	test: 0.622641

Epoch: 113
Loss: 0.28987677433005243
ROC train: 0.951894	val: 0.635606	test: 0.587572
PRC train: 0.921491	val: 0.660870	test: 0.624074

Epoch: 114
Loss: 0.2904027379963568
ROC train: 0.951539	val: 0.631673	test: 0.591211
PRC train: 0.924531	val: 0.663124	test: 0.626168

Epoch: 115
Loss: 0.2853320817342709
ROC train: 0.952897	val: 0.631284	test: 0.592655
PRC train: 0.924829	val: 0.661537	test: 0.626066

Epoch: 116
Loss: 0.2825403803234317
ROC train: 0.953517	val: 0.630206	test: 0.591746
PRC train: 0.926226	val: 0.659509	test: 0.628164

Epoch: 117
Loss: 0.2827625032453367
ROC train: 0.952051	val: 0.627245	test: 0.586924
PRC train: 0.927459	val: 0.659822	test: 0.624480

Epoch: 118
Loss: 0.28336463456994876
ROC train: 0.952779	val: 0.629740	test: 0.583542
PRC train: 0.926872	val: 0.661218	test: 0.622890

Epoch: 119
Loss: 0.2780492254173091
ROC train: 0.956654	val: 0.637815	test: 0.580248
PRC train: 0.930278	val: 0.661293	test: 0.623815

Epoch: 120
Loss: 0.27869171948954635
ROC train: 0.958544	val: 0.638237	test: 0.588009
PRC train: 0.933146	val: 0.662321	test: 0.625316

Early stopping
Best (ROC):	 train: 0.900120	val: 0.652419	test: 0.594635
Best (PRC):	 train: 0.857428	val: 0.672202	test: 0.619525

PRC train: 0.899860	val: 0.668031	test: 0.602177

Epoch: 94
Loss: 0.3141318277967444
ROC train: 0.936174	val: 0.621883	test: 0.536546
PRC train: 0.903808	val: 0.669800	test: 0.603191

Epoch: 95
Loss: 0.3131245614407009
ROC train: 0.937046	val: 0.620002	test: 0.547307
PRC train: 0.901420	val: 0.668490	test: 0.611051

Epoch: 96
Loss: 0.30928283999072737
ROC train: 0.937734	val: 0.612790	test: 0.546445
PRC train: 0.903884	val: 0.662931	test: 0.610323

Epoch: 97
Loss: 0.30780046249076026
ROC train: 0.938531	val: 0.612225	test: 0.542254
PRC train: 0.907835	val: 0.660064	test: 0.604926

Epoch: 98
Loss: 0.31016739432766033
ROC train: 0.939625	val: 0.612989	test: 0.544574
PRC train: 0.907987	val: 0.662853	test: 0.606444

Epoch: 99
Loss: 0.30568363037247775
ROC train: 0.938585	val: 0.612159	test: 0.550372
PRC train: 0.907284	val: 0.664802	test: 0.610563

Epoch: 100
Loss: 0.3052226305399127
ROC train: 0.940426	val: 0.608093	test: 0.556338
PRC train: 0.909030	val: 0.664245	test: 0.611622

Epoch: 101
Loss: 0.3046766681351326
ROC train: 0.941006	val: 0.610632	test: 0.553078
PRC train: 0.910340	val: 0.664455	test: 0.608359

Epoch: 102
Loss: 0.30318760105315445
ROC train: 0.943747	val: 0.607674	test: 0.549017
PRC train: 0.915192	val: 0.665041	test: 0.605715

Epoch: 103
Loss: 0.29685709732448573
ROC train: 0.944582	val: 0.605780	test: 0.553578
PRC train: 0.915942	val: 0.658910	test: 0.610839

Epoch: 104
Loss: 0.30264781758779435
ROC train: 0.943911	val: 0.614268	test: 0.557675
PRC train: 0.914800	val: 0.663168	test: 0.616492

Epoch: 105
Loss: 0.29729578787846583
ROC train: 0.943507	val: 0.612134	test: 0.561537
PRC train: 0.911880	val: 0.663567	test: 0.618208

Epoch: 106
Loss: 0.29376212880281977
ROC train: 0.945550	val: 0.611544	test: 0.551118
PRC train: 0.917645	val: 0.664183	test: 0.611581

Epoch: 107
Loss: 0.29619998357953337
ROC train: 0.948305	val: 0.608832	test: 0.549568
PRC train: 0.919528	val: 0.660469	test: 0.610825

Epoch: 108
Loss: 0.29549129477128744
ROC train: 0.949286	val: 0.604617	test: 0.554186
PRC train: 0.920749	val: 0.657936	test: 0.612719

Epoch: 109
Loss: 0.2940286387936222
ROC train: 0.948974	val: 0.606730	test: 0.554041
PRC train: 0.918534	val: 0.658531	test: 0.614377

Epoch: 110
Loss: 0.2888402626004935
ROC train: 0.949143	val: 0.607568	test: 0.550336
PRC train: 0.917981	val: 0.658564	test: 0.614235

Epoch: 111
Loss: 0.29034867949191107
ROC train: 0.951089	val: 0.612619	test: 0.552813
PRC train: 0.924099	val: 0.663165	test: 0.613599

Epoch: 112
Loss: 0.28604798037170837
ROC train: 0.951183	val: 0.612272	test: 0.559498
PRC train: 0.923809	val: 0.662347	test: 0.613844

Epoch: 113
Loss: 0.28945031461369103
ROC train: 0.952586	val: 0.598545	test: 0.556157
PRC train: 0.923882	val: 0.654325	test: 0.618684

Epoch: 114
Loss: 0.2836207966205927
ROC train: 0.952643	val: 0.606935	test: 0.558184
PRC train: 0.922988	val: 0.662107	test: 0.615949

Epoch: 115
Loss: 0.2896779238186607
ROC train: 0.955542	val: 0.601565	test: 0.554337
PRC train: 0.926970	val: 0.657285	test: 0.613224

Epoch: 116
Loss: 0.28264504749881064
ROC train: 0.955462	val: 0.607344	test: 0.550095
PRC train: 0.929649	val: 0.660616	test: 0.607355

Epoch: 117
Loss: 0.2782131793252408
ROC train: 0.958147	val: 0.600162	test: 0.557532
PRC train: 0.933139	val: 0.657302	test: 0.614889

Epoch: 118
Loss: 0.27932297562922526
ROC train: 0.959399	val: 0.601100	test: 0.557797
PRC train: 0.936031	val: 0.659219	test: 0.617304

Epoch: 119
Loss: 0.27691623709641344
ROC train: 0.958058	val: 0.604808	test: 0.551069
PRC train: 0.935077	val: 0.660914	test: 0.613544

Epoch: 120
Loss: 0.27039686405728064
ROC train: 0.957873	val: 0.604871	test: 0.551177
PRC train: 0.935447	val: 0.662221	test: 0.612627

Early stopping
Best (ROC):	 train: 0.873004	val: 0.628878	test: 0.537862
Best (PRC):	 train: 0.831087	val: 0.669432	test: 0.613438

PRC train: 0.904049	val: 0.657242	test: 0.626712

Epoch: 94
Loss: 0.3178339805657381
ROC train: 0.927166	val: 0.604817	test: 0.605343
PRC train: 0.901165	val: 0.655934	test: 0.629256

Epoch: 95
Loss: 0.3153376391250639
ROC train: 0.931385	val: 0.603085	test: 0.610116
PRC train: 0.902722	val: 0.656244	test: 0.634255

Epoch: 96
Loss: 0.31522417559819227
ROC train: 0.932503	val: 0.610040	test: 0.607377
PRC train: 0.905722	val: 0.658971	test: 0.634500

Epoch: 97
Loss: 0.31571726045957305
ROC train: 0.935403	val: 0.605302	test: 0.609654
PRC train: 0.910006	val: 0.656892	test: 0.631859

Epoch: 98
Loss: 0.3126793216229404
ROC train: 0.933094	val: 0.598078	test: 0.606884
PRC train: 0.905833	val: 0.652358	test: 0.635997

Epoch: 99
Loss: 0.3125603975567973
ROC train: 0.934404	val: 0.614430	test: 0.602889
PRC train: 0.908728	val: 0.662688	test: 0.633222

Epoch: 100
Loss: 0.3115391410740066
ROC train: 0.934710	val: 0.607209	test: 0.604053
PRC train: 0.909633	val: 0.660743	test: 0.629134

Epoch: 101
Loss: 0.3123599969935994
ROC train: 0.935149	val: 0.592414	test: 0.604921
PRC train: 0.907753	val: 0.655641	test: 0.628907

Epoch: 102
Loss: 0.30997084764051847
ROC train: 0.939556	val: 0.615125	test: 0.602571
PRC train: 0.913298	val: 0.662253	test: 0.629729

Epoch: 103
Loss: 0.3038081559453864
ROC train: 0.937328	val: 0.617911	test: 0.608358
PRC train: 0.912054	val: 0.660037	test: 0.634349

Epoch: 104
Loss: 0.3069916288129865
ROC train: 0.939592	val: 0.604989	test: 0.610159
PRC train: 0.915332	val: 0.657407	test: 0.634635

Epoch: 105
Loss: 0.29850514840495246
ROC train: 0.938816	val: 0.592888	test: 0.603949
PRC train: 0.912538	val: 0.649502	test: 0.633381

Epoch: 106
Loss: 0.3062813527498186
ROC train: 0.941713	val: 0.609249	test: 0.601983
PRC train: 0.918117	val: 0.660415	test: 0.631805

Epoch: 107
Loss: 0.30033115698000595
ROC train: 0.942334	val: 0.617882	test: 0.606392
PRC train: 0.921480	val: 0.664662	test: 0.634125

Epoch: 108
Loss: 0.30190955417658516
ROC train: 0.940779	val: 0.614717	test: 0.603356
PRC train: 0.918412	val: 0.662397	test: 0.631259

Epoch: 109
Loss: 0.3023404113631083
ROC train: 0.942852	val: 0.618119	test: 0.600290
PRC train: 0.919944	val: 0.668028	test: 0.626712

Epoch: 110
Loss: 0.29665670734816113
ROC train: 0.946813	val: 0.608680	test: 0.612156
PRC train: 0.921551	val: 0.660939	test: 0.639794

Epoch: 111
Loss: 0.30045355183746314
ROC train: 0.946559	val: 0.607172	test: 0.612994
PRC train: 0.920479	val: 0.658848	test: 0.637569

Epoch: 112
Loss: 0.29589950416576816
ROC train: 0.945801	val: 0.614145	test: 0.604461
PRC train: 0.920658	val: 0.664550	test: 0.632951

Epoch: 113
Loss: 0.297345503264284
ROC train: 0.949442	val: 0.610841	test: 0.610572
PRC train: 0.925655	val: 0.661774	test: 0.635401

Epoch: 114
Loss: 0.29522656622907334
ROC train: 0.950750	val: 0.609049	test: 0.609732
PRC train: 0.927428	val: 0.658885	test: 0.634391

Epoch: 115
Loss: 0.2958925477707839
ROC train: 0.951401	val: 0.607812	test: 0.601776
PRC train: 0.930244	val: 0.655222	test: 0.632846

Epoch: 116
Loss: 0.2889156721313533
ROC train: 0.950766	val: 0.610156	test: 0.591938
PRC train: 0.927063	val: 0.663582	test: 0.627596

Epoch: 117
Loss: 0.2838781718052449
ROC train: 0.950318	val: 0.609169	test: 0.596716
PRC train: 0.927329	val: 0.662937	test: 0.633024

Epoch: 118
Loss: 0.2831125377523339
ROC train: 0.950732	val: 0.609909	test: 0.615599
PRC train: 0.930637	val: 0.659859	test: 0.644969

Epoch: 119
Loss: 0.28627925397693854
ROC train: 0.951886	val: 0.598926	test: 0.611666
PRC train: 0.929600	val: 0.654234	test: 0.645295

Epoch: 120
Loss: 0.28991339451668835
ROC train: 0.953750	val: 0.609763	test: 0.605967
PRC train: 0.933077	val: 0.661163	test: 0.638402

Early stopping
Best (ROC):	 train: 0.883120	val: 0.641314	test: 0.576758
Best (PRC):	 train: 0.845305	val: 0.676276	test: 0.613411

PRC train: 0.905955	val: 0.636051	test: 0.617408

Epoch: 94
Loss: 0.31466187943791807
ROC train: 0.934604	val: 0.580268	test: 0.570035
PRC train: 0.907127	val: 0.642052	test: 0.626196

Epoch: 95
Loss: 0.3116380391373915
ROC train: 0.936306	val: 0.581042	test: 0.576844
PRC train: 0.906831	val: 0.643286	test: 0.629322

Epoch: 96
Loss: 0.3129013888729177
ROC train: 0.939392	val: 0.573905	test: 0.576797
PRC train: 0.909221	val: 0.639611	test: 0.625814

Epoch: 97
Loss: 0.3082994140184881
ROC train: 0.939424	val: 0.566674	test: 0.572300
PRC train: 0.910534	val: 0.633425	test: 0.620157

Epoch: 98
Loss: 0.30738008141906425
ROC train: 0.940867	val: 0.569689	test: 0.572392
PRC train: 0.912247	val: 0.633847	test: 0.619269

Epoch: 99
Loss: 0.3065513657881482
ROC train: 0.943517	val: 0.569158	test: 0.580419
PRC train: 0.913726	val: 0.635525	test: 0.626990

Epoch: 100
Loss: 0.3045074560100062
ROC train: 0.943897	val: 0.567213	test: 0.582004
PRC train: 0.914672	val: 0.634596	test: 0.631692

Epoch: 101
Loss: 0.30268536614158154
ROC train: 0.944576	val: 0.570876	test: 0.576728
PRC train: 0.915943	val: 0.638153	test: 0.628172

Epoch: 102
Loss: 0.30307634804778594
ROC train: 0.946694	val: 0.571352	test: 0.576421
PRC train: 0.916406	val: 0.640421	test: 0.621744

Epoch: 103
Loss: 0.2987760855277436
ROC train: 0.947674	val: 0.582316	test: 0.571465
PRC train: 0.915885	val: 0.638667	test: 0.618230

Epoch: 104
Loss: 0.2948148864597035
ROC train: 0.947142	val: 0.573859	test: 0.572974
PRC train: 0.916992	val: 0.634038	test: 0.623402

Epoch: 105
Loss: 0.295579788868572
ROC train: 0.947864	val: 0.569886	test: 0.572928
PRC train: 0.918603	val: 0.636723	test: 0.622838

Epoch: 106
Loss: 0.291019436838302
ROC train: 0.948509	val: 0.566996	test: 0.573359
PRC train: 0.918884	val: 0.637573	test: 0.621391

Epoch: 107
Loss: 0.29356127749805944
ROC train: 0.950095	val: 0.571014	test: 0.572081
PRC train: 0.921558	val: 0.639174	test: 0.620681

Epoch: 108
Loss: 0.2952633476387848
ROC train: 0.952197	val: 0.568175	test: 0.575476
PRC train: 0.922599	val: 0.637158	test: 0.623798

Epoch: 109
Loss: 0.28996132992091195
ROC train: 0.953541	val: 0.571339	test: 0.571303
PRC train: 0.926724	val: 0.637177	test: 0.620277

Epoch: 110
Loss: 0.2894421833230844
ROC train: 0.954575	val: 0.566338	test: 0.567925
PRC train: 0.928335	val: 0.638575	test: 0.620460

Epoch: 111
Loss: 0.2899075157728408
ROC train: 0.954468	val: 0.569540	test: 0.565807
PRC train: 0.924182	val: 0.636755	test: 0.625134

Epoch: 112
Loss: 0.2876869041886284
ROC train: 0.955793	val: 0.570065	test: 0.577903
PRC train: 0.930663	val: 0.637546	test: 0.633128

Epoch: 113
Loss: 0.2844368146080468
ROC train: 0.957575	val: 0.572551	test: 0.577954
PRC train: 0.933956	val: 0.637727	test: 0.629772

Epoch: 114
Loss: 0.27557033311629625
ROC train: 0.956866	val: 0.578464	test: 0.574762
PRC train: 0.932580	val: 0.639996	test: 0.629732

Epoch: 115
Loss: 0.2732827739641687
ROC train: 0.957750	val: 0.572172	test: 0.580023
PRC train: 0.934380	val: 0.638806	test: 0.632801

Epoch: 116
Loss: 0.2728903100307133
ROC train: 0.959365	val: 0.570378	test: 0.584812
PRC train: 0.935365	val: 0.637008	test: 0.631258

Epoch: 117
Loss: 0.27424872363088737
ROC train: 0.960252	val: 0.572464	test: 0.577331
PRC train: 0.936096	val: 0.637313	test: 0.628242

Epoch: 118
Loss: 0.2737716289227969
ROC train: 0.961304	val: 0.560526	test: 0.572500
PRC train: 0.934112	val: 0.634769	test: 0.628316

Epoch: 119
Loss: 0.27059080633306054
ROC train: 0.963277	val: 0.568693	test: 0.572537
PRC train: 0.939924	val: 0.638023	test: 0.626440

Epoch: 120
Loss: 0.2723839327918244
ROC train: 0.963233	val: 0.574611	test: 0.571156
PRC train: 0.943291	val: 0.638950	test: 0.624719

Early stopping
Best (ROC):	 train: 0.792556	val: 0.606769	test: 0.573804
Best (PRC):	 train: 0.762607	val: 0.652808	test: 0.614409

PRC train: 0.889820	val: 0.664658	test: 0.619167

Epoch: 94
Loss: 0.3264148756303912
ROC train: 0.927052	val: 0.629603	test: 0.583949
PRC train: 0.896871	val: 0.665379	test: 0.618141

Epoch: 95
Loss: 0.3247965467598669
ROC train: 0.921526	val: 0.641499	test: 0.572676
PRC train: 0.892560	val: 0.672428	test: 0.610152

Epoch: 96
Loss: 0.3267312588317506
ROC train: 0.929511	val: 0.630091	test: 0.575176
PRC train: 0.898761	val: 0.669036	test: 0.616148

Epoch: 97
Loss: 0.32178923647528
ROC train: 0.929875	val: 0.622955	test: 0.578487
PRC train: 0.900766	val: 0.667375	test: 0.618174

Epoch: 98
Loss: 0.3212742471043807
ROC train: 0.928212	val: 0.618811	test: 0.568977
PRC train: 0.897175	val: 0.665812	test: 0.618426

Epoch: 99
Loss: 0.3173843944440481
ROC train: 0.931542	val: 0.630682	test: 0.592039
PRC train: 0.901034	val: 0.666921	test: 0.624294

Epoch: 100
Loss: 0.32065633559416157
ROC train: 0.932036	val: 0.639622	test: 0.599744
PRC train: 0.902363	val: 0.669569	test: 0.632413

Epoch: 101
Loss: 0.3153266381574097
ROC train: 0.935957	val: 0.641105	test: 0.590133
PRC train: 0.904035	val: 0.669959	test: 0.623158

Epoch: 102
Loss: 0.31144050995578204
ROC train: 0.934839	val: 0.626842	test: 0.581274
PRC train: 0.905550	val: 0.666102	test: 0.620838

Epoch: 103
Loss: 0.31188480627833093
ROC train: 0.935952	val: 0.635678	test: 0.582492
PRC train: 0.908415	val: 0.669587	test: 0.628772

Epoch: 104
Loss: 0.30684213579214864
ROC train: 0.936522	val: 0.639291	test: 0.578573
PRC train: 0.908433	val: 0.669411	test: 0.624097

Epoch: 105
Loss: 0.31007257975993735
ROC train: 0.937706	val: 0.637370	test: 0.584689
PRC train: 0.905483	val: 0.667545	test: 0.629816

Epoch: 106
Loss: 0.3089369310522375
ROC train: 0.938400	val: 0.630633	test: 0.583362
PRC train: 0.908914	val: 0.666485	test: 0.627335

Epoch: 107
Loss: 0.3127846748561702
ROC train: 0.939569	val: 0.617534	test: 0.578821
PRC train: 0.908362	val: 0.660460	test: 0.620384

Epoch: 108
Loss: 0.30576242218144206
ROC train: 0.936870	val: 0.626224	test: 0.572610
PRC train: 0.906801	val: 0.666039	test: 0.623123

Epoch: 109
Loss: 0.2999847400777329
ROC train: 0.940368	val: 0.623312	test: 0.586381
PRC train: 0.907024	val: 0.662085	test: 0.627596

Epoch: 110
Loss: 0.30196035616771805
ROC train: 0.940870	val: 0.631253	test: 0.589854
PRC train: 0.911102	val: 0.672026	test: 0.627713

Epoch: 111
Loss: 0.30381679761752506
ROC train: 0.944929	val: 0.626313	test: 0.590989
PRC train: 0.915737	val: 0.669523	test: 0.629469

Epoch: 112
Loss: 0.29779555107419187
ROC train: 0.945209	val: 0.639148	test: 0.579922
PRC train: 0.916986	val: 0.673530	test: 0.627393

Epoch: 113
Loss: 0.30140176812001174
ROC train: 0.944990	val: 0.632908	test: 0.575223
PRC train: 0.917474	val: 0.670801	test: 0.624647

Epoch: 114
Loss: 0.29837721975087894
ROC train: 0.945500	val: 0.621381	test: 0.577409
PRC train: 0.918490	val: 0.664342	test: 0.625744

Epoch: 115
Loss: 0.29858142740197763
ROC train: 0.946976	val: 0.628054	test: 0.584984
PRC train: 0.918762	val: 0.665731	test: 0.627583

Epoch: 116
Loss: 0.2966725388996999
ROC train: 0.948451	val: 0.630791	test: 0.594351
PRC train: 0.919106	val: 0.667335	test: 0.633710

Epoch: 117
Loss: 0.29306183826896715
ROC train: 0.950124	val: 0.631456	test: 0.592568
PRC train: 0.923149	val: 0.667147	test: 0.633198

Epoch: 118
Loss: 0.2931572347399255
ROC train: 0.950507	val: 0.624541	test: 0.586768
PRC train: 0.923296	val: 0.666229	test: 0.629643

Epoch: 119
Loss: 0.2837472159157054
ROC train: 0.948090	val: 0.631824	test: 0.578357
PRC train: 0.921041	val: 0.667361	test: 0.629017

Epoch: 120
Loss: 0.2874203039873581
ROC train: 0.952361	val: 0.643883	test: 0.586537
PRC train: 0.924799	val: 0.671244	test: 0.630923

Early stopping
Best (ROC):	 train: 0.869932	val: 0.656061	test: 0.574496
Best (PRC):	 train: 0.827186	val: 0.675222	test: 0.618761
PRC train: 0.914514	val: 0.659173	test: 0.625030

Epoch: 94
Loss: 0.3172000032044364
ROC train: 0.938017	val: 0.606216	test: 0.579364
PRC train: 0.917871	val: 0.666670	test: 0.621851

Epoch: 95
Loss: 0.3147158413763451
ROC train: 0.937512	val: 0.610779	test: 0.577166
PRC train: 0.918309	val: 0.668056	test: 0.623815

Epoch: 96
Loss: 0.31642383785375083
ROC train: 0.938348	val: 0.606806	test: 0.574368
PRC train: 0.919716	val: 0.664889	test: 0.627680

Epoch: 97
Loss: 0.3085814573491153
ROC train: 0.939550	val: 0.604078	test: 0.577724
PRC train: 0.919615	val: 0.665829	test: 0.626791

Epoch: 98
Loss: 0.31059711113131294
ROC train: 0.940369	val: 0.612048	test: 0.577903
PRC train: 0.921132	val: 0.665502	test: 0.621979

Epoch: 99
Loss: 0.30552967189861036
ROC train: 0.942398	val: 0.607762	test: 0.583489
PRC train: 0.923965	val: 0.661746	test: 0.623928

Epoch: 100
Loss: 0.3118711984622233
ROC train: 0.941859	val: 0.607832	test: 0.584743
PRC train: 0.922839	val: 0.660526	test: 0.627233

Epoch: 101
Loss: 0.30546154566361705
ROC train: 0.942765	val: 0.612183	test: 0.585059
PRC train: 0.926342	val: 0.662662	test: 0.630701

Epoch: 102
Loss: 0.30153809637566187
ROC train: 0.944820	val: 0.615194	test: 0.584717
PRC train: 0.929635	val: 0.669497	test: 0.628583

Epoch: 103
Loss: 0.3041867706642502
ROC train: 0.944451	val: 0.610766	test: 0.569383
PRC train: 0.925821	val: 0.667819	test: 0.611825

Epoch: 104
Loss: 0.3024390443135999
ROC train: 0.946020	val: 0.609981	test: 0.577930
PRC train: 0.929312	val: 0.667372	test: 0.622564

Epoch: 105
Loss: 0.3019761794736832
ROC train: 0.946718	val: 0.612866	test: 0.577586
PRC train: 0.930373	val: 0.665394	test: 0.625506

Epoch: 106
Loss: 0.3000520133584414
ROC train: 0.946663	val: 0.615228	test: 0.575231
PRC train: 0.929500	val: 0.668585	test: 0.622881

Epoch: 107
Loss: 0.29536185456002223
ROC train: 0.946880	val: 0.612272	test: 0.577978
PRC train: 0.932613	val: 0.668204	test: 0.621686

Epoch: 108
Loss: 0.29398835634535914
ROC train: 0.950620	val: 0.606559	test: 0.576231
PRC train: 0.936936	val: 0.666227	test: 0.622029

Epoch: 109
Loss: 0.2927261804578365
ROC train: 0.950382	val: 0.603546	test: 0.573988
PRC train: 0.936114	val: 0.662519	test: 0.622726

Epoch: 110
Loss: 0.2907029658774013
ROC train: 0.952331	val: 0.606618	test: 0.572651
PRC train: 0.938705	val: 0.662821	test: 0.622164

Epoch: 111
Loss: 0.2911852726760125
ROC train: 0.953821	val: 0.607155	test: 0.567247
PRC train: 0.939142	val: 0.661944	test: 0.619302

Epoch: 112
Loss: 0.2868430251901812
ROC train: 0.954196	val: 0.601008	test: 0.563096
PRC train: 0.939993	val: 0.661652	test: 0.615217

Epoch: 113
Loss: 0.28608028682192055
ROC train: 0.954467	val: 0.595803	test: 0.566747
PRC train: 0.940566	val: 0.658788	test: 0.613860

Epoch: 114
Loss: 0.287945864995083
ROC train: 0.953351	val: 0.586187	test: 0.561724
PRC train: 0.939603	val: 0.653862	test: 0.610310

Epoch: 115
Loss: 0.2856207639659395
ROC train: 0.956190	val: 0.600633	test: 0.557644
PRC train: 0.942469	val: 0.657776	test: 0.609539

Epoch: 116
Loss: 0.2842518291709971
ROC train: 0.958415	val: 0.606989	test: 0.564084
PRC train: 0.945002	val: 0.663328	test: 0.612527

Epoch: 117
Loss: 0.2810252925666438
ROC train: 0.959060	val: 0.604115	test: 0.570751
PRC train: 0.946728	val: 0.662626	test: 0.618623

Epoch: 118
Loss: 0.2801695591515435
ROC train: 0.957640	val: 0.606826	test: 0.569158
PRC train: 0.944118	val: 0.663571	test: 0.619184

Epoch: 119
Loss: 0.2728869368713142
ROC train: 0.954449	val: 0.600128	test: 0.567855
PRC train: 0.941399	val: 0.658369	test: 0.618486

Epoch: 120
Loss: 0.2816715679477995
ROC train: 0.957793	val: 0.608995	test: 0.566337
PRC train: 0.944814	val: 0.664823	test: 0.617124

Early stopping
Best (ROC):	 train: 0.903360	val: 0.619818	test: 0.588408
Best (PRC):	 train: 0.865973	val: 0.674610	test: 0.633029

PRC train: 0.891254	val: 0.655583	test: 0.638596

Epoch: 94
Loss: 0.312207296090382
ROC train: 0.933783	val: 0.620238	test: 0.577514
PRC train: 0.897803	val: 0.658795	test: 0.635468

Epoch: 95
Loss: 0.30874067908102465
ROC train: 0.935519	val: 0.626741	test: 0.582071
PRC train: 0.900261	val: 0.665996	test: 0.629754

Epoch: 96
Loss: 0.30825094017080756
ROC train: 0.937776	val: 0.617447	test: 0.579312
PRC train: 0.899654	val: 0.660895	test: 0.632828

Epoch: 97
Loss: 0.3074481073380387
ROC train: 0.939574	val: 0.615450	test: 0.575927
PRC train: 0.904307	val: 0.656979	test: 0.633465

Epoch: 98
Loss: 0.30545677989522996
ROC train: 0.937803	val: 0.617092	test: 0.563963
PRC train: 0.901324	val: 0.656545	test: 0.623240

Epoch: 99
Loss: 0.3054764342672962
ROC train: 0.940441	val: 0.617820	test: 0.566202
PRC train: 0.904200	val: 0.657704	test: 0.622686

Epoch: 100
Loss: 0.301794703731626
ROC train: 0.940685	val: 0.617168	test: 0.572074
PRC train: 0.903010	val: 0.658392	test: 0.628234

Epoch: 101
Loss: 0.3019884958613098
ROC train: 0.942147	val: 0.613028	test: 0.575200
PRC train: 0.906029	val: 0.654928	test: 0.628876

Epoch: 102
Loss: 0.302247700056186
ROC train: 0.941587	val: 0.617612	test: 0.570071
PRC train: 0.909528	val: 0.658253	test: 0.624717

Epoch: 103
Loss: 0.29811996025941834
ROC train: 0.944915	val: 0.616613	test: 0.581764
PRC train: 0.910224	val: 0.659544	test: 0.633035

Epoch: 104
Loss: 0.2952907391935233
ROC train: 0.945084	val: 0.614434	test: 0.582957
PRC train: 0.908733	val: 0.660522	test: 0.634730

Epoch: 105
Loss: 0.2973200721959023
ROC train: 0.946231	val: 0.625934	test: 0.579419
PRC train: 0.912051	val: 0.665999	test: 0.633054

Epoch: 106
Loss: 0.2946298312010163
ROC train: 0.947610	val: 0.628653	test: 0.579948
PRC train: 0.914010	val: 0.663718	test: 0.633644

Epoch: 107
Loss: 0.2889278108153343
ROC train: 0.944835	val: 0.621785	test: 0.579540
PRC train: 0.913538	val: 0.658263	test: 0.635579

Epoch: 108
Loss: 0.2960950331598722
ROC train: 0.947211	val: 0.621165	test: 0.568311
PRC train: 0.917174	val: 0.658188	test: 0.630670

Epoch: 109
Loss: 0.2895545812415931
ROC train: 0.948130	val: 0.628467	test: 0.565605
PRC train: 0.917723	val: 0.661975	test: 0.628113

Epoch: 110
Loss: 0.29030036346862775
ROC train: 0.950838	val: 0.614323	test: 0.582535
PRC train: 0.926322	val: 0.656374	test: 0.636063

Epoch: 111
Loss: 0.29236301951820354
ROC train: 0.951109	val: 0.608570	test: 0.587816
PRC train: 0.925160	val: 0.657110	test: 0.637793

Epoch: 112
Loss: 0.2847051145254055
ROC train: 0.951583	val: 0.624378	test: 0.578335
PRC train: 0.920756	val: 0.662137	test: 0.631627

Epoch: 113
Loss: 0.2830420322075048
ROC train: 0.953642	val: 0.622014	test: 0.583898
PRC train: 0.922633	val: 0.660016	test: 0.631975

Epoch: 114
Loss: 0.284824572488663
ROC train: 0.949832	val: 0.623757	test: 0.583310
PRC train: 0.922170	val: 0.666051	test: 0.629158

Epoch: 115
Loss: 0.27797685444181736
ROC train: 0.954085	val: 0.614032	test: 0.573132
PRC train: 0.926003	val: 0.660300	test: 0.635445

Epoch: 116
Loss: 0.2832798188923184
ROC train: 0.952848	val: 0.609680	test: 0.579920
PRC train: 0.925673	val: 0.656272	test: 0.640813

Epoch: 117
Loss: 0.2785199746288434
ROC train: 0.954923	val: 0.605081	test: 0.586656
PRC train: 0.926884	val: 0.654479	test: 0.640945

Epoch: 118
Loss: 0.2767172631228358
ROC train: 0.955974	val: 0.591265	test: 0.584996
PRC train: 0.928849	val: 0.647546	test: 0.639682

Epoch: 119
Loss: 0.2766717468213126
ROC train: 0.958927	val: 0.614096	test: 0.580468
PRC train: 0.931155	val: 0.655859	test: 0.632359

Epoch: 120
Loss: 0.27729140926274487
ROC train: 0.959938	val: 0.620009	test: 0.573838
PRC train: 0.931785	val: 0.658321	test: 0.624796

Early stopping
Best (ROC):	 train: 0.865824	val: 0.640520	test: 0.617290
Best (PRC):	 train: 0.815431	val: 0.677177	test: 0.644422

PRC train: 0.902511	val: 0.645861	test: 0.598527

Epoch: 94
Loss: 0.3117946752837456
ROC train: 0.936560	val: 0.573641	test: 0.546481
PRC train: 0.903348	val: 0.640898	test: 0.601690

Epoch: 95
Loss: 0.3108933143299271
ROC train: 0.935467	val: 0.578616	test: 0.548020
PRC train: 0.903560	val: 0.643074	test: 0.605422

Epoch: 96
Loss: 0.30706484035893444
ROC train: 0.936877	val: 0.580709	test: 0.548293
PRC train: 0.904331	val: 0.647001	test: 0.607899

Epoch: 97
Loss: 0.3041525176875368
ROC train: 0.941406	val: 0.585530	test: 0.550005
PRC train: 0.907105	val: 0.658973	test: 0.610681

Epoch: 98
Loss: 0.3079791633079456
ROC train: 0.939503	val: 0.575874	test: 0.552196
PRC train: 0.904625	val: 0.650162	test: 0.607875

Epoch: 99
Loss: 0.304594406340847
ROC train: 0.941553	val: 0.573610	test: 0.542748
PRC train: 0.906351	val: 0.642695	test: 0.600964

Epoch: 100
Loss: 0.30152573105306113
ROC train: 0.943813	val: 0.567438	test: 0.540104
PRC train: 0.909667	val: 0.639400	test: 0.602985

Epoch: 101
Loss: 0.30504009516943886
ROC train: 0.944605	val: 0.572451	test: 0.546997
PRC train: 0.911627	val: 0.642054	test: 0.609540

Epoch: 102
Loss: 0.2982934316847518
ROC train: 0.945752	val: 0.569001	test: 0.540620
PRC train: 0.914873	val: 0.641410	test: 0.602957

Epoch: 103
Loss: 0.29769747786284145
ROC train: 0.945475	val: 0.567282	test: 0.555928
PRC train: 0.915264	val: 0.639059	test: 0.606192

Epoch: 104
Loss: 0.30265077644475735
ROC train: 0.943953	val: 0.578625	test: 0.558278
PRC train: 0.914093	val: 0.646582	test: 0.607103

Epoch: 105
Loss: 0.2904662960030811
ROC train: 0.945779	val: 0.571749	test: 0.557896
PRC train: 0.912808	val: 0.642272	test: 0.609704

Epoch: 106
Loss: 0.28840724386557054
ROC train: 0.948935	val: 0.581624	test: 0.538262
PRC train: 0.915545	val: 0.656442	test: 0.602506

Epoch: 107
Loss: 0.29204701580779163
ROC train: 0.949963	val: 0.578948	test: 0.540548
PRC train: 0.920029	val: 0.648072	test: 0.605432

Epoch: 108
Loss: 0.2931026773829699
ROC train: 0.950258	val: 0.575976	test: 0.556692
PRC train: 0.918957	val: 0.642795	test: 0.613633

Epoch: 109
Loss: 0.2871832471700826
ROC train: 0.951773	val: 0.585130	test: 0.549711
PRC train: 0.920194	val: 0.649202	test: 0.606846

Epoch: 110
Loss: 0.28553992297010244
ROC train: 0.952889	val: 0.573908	test: 0.554584
PRC train: 0.923628	val: 0.645795	test: 0.613190

Epoch: 111
Loss: 0.28234641913627384
ROC train: 0.951704	val: 0.576424	test: 0.554982
PRC train: 0.922703	val: 0.645298	test: 0.610950

Epoch: 112
Loss: 0.27956369635485245
ROC train: 0.952037	val: 0.585373	test: 0.540521
PRC train: 0.920709	val: 0.653313	test: 0.603531

Epoch: 113
Loss: 0.28573678056254337
ROC train: 0.956049	val: 0.583021	test: 0.544264
PRC train: 0.925552	val: 0.650414	test: 0.603960

Epoch: 114
Loss: 0.28061252718908924
ROC train: 0.954423	val: 0.573236	test: 0.556487
PRC train: 0.922992	val: 0.637998	test: 0.611058

Epoch: 115
Loss: 0.2838729739611102
ROC train: 0.956177	val: 0.576217	test: 0.550161
PRC train: 0.927486	val: 0.643012	test: 0.604086

Epoch: 116
Loss: 0.2782018613795603
ROC train: 0.956973	val: 0.570707	test: 0.542498
PRC train: 0.927773	val: 0.646724	test: 0.598061

Epoch: 117
Loss: 0.2739694041620062
ROC train: 0.956850	val: 0.573729	test: 0.543518
PRC train: 0.926703	val: 0.644827	test: 0.602773

Epoch: 118
Loss: 0.2749604147978967
ROC train: 0.958321	val: 0.576463	test: 0.542926
PRC train: 0.932597	val: 0.646517	test: 0.604628

Epoch: 119
Loss: 0.27456761287750153
ROC train: 0.959186	val: 0.573267	test: 0.538182
PRC train: 0.933392	val: 0.642686	test: 0.601054

Epoch: 120
Loss: 0.27191282284633045
ROC train: 0.959928	val: 0.567181	test: 0.539383
PRC train: 0.933464	val: 0.642351	test: 0.601819

Early stopping
Best (ROC):	 train: 0.755002	val: 0.607235	test: 0.554507
Best (PRC):	 train: 0.733424	val: 0.643744	test: 0.620177
All runs completed.
All runs completed.

PRC train: 0.852861	val: 0.675769	test: 0.620145

Epoch: 95
Loss: 0.36336865712395006
ROC train: 0.898807	val: 0.637877	test: 0.576987
PRC train: 0.863746	val: 0.681111	test: 0.619706

Epoch: 96
Loss: 0.36418666533309957
ROC train: 0.899301	val: 0.634953	test: 0.580629
PRC train: 0.861694	val: 0.674261	test: 0.622255

Epoch: 97
Loss: 0.3679436341769796
ROC train: 0.901697	val: 0.626450	test: 0.576586
PRC train: 0.864108	val: 0.675218	test: 0.622056

Epoch: 98
Loss: 0.3668683466521457
ROC train: 0.903430	val: 0.623617	test: 0.586804
PRC train: 0.868515	val: 0.678798	test: 0.623527

Epoch: 99
Loss: 0.36321361736463587
ROC train: 0.895728	val: 0.626265	test: 0.570515
PRC train: 0.856367	val: 0.676334	test: 0.615719

Epoch: 100
Loss: 0.3583142288685299
ROC train: 0.901079	val: 0.625905	test: 0.587345
PRC train: 0.865901	val: 0.668818	test: 0.633244

Epoch: 101
Loss: 0.3657630449618251
ROC train: 0.903072	val: 0.614743	test: 0.595155
PRC train: 0.866663	val: 0.664613	test: 0.628500

Epoch: 102
Loss: 0.3592959957863559
ROC train: 0.905954	val: 0.617910	test: 0.592400
PRC train: 0.869350	val: 0.668082	test: 0.624681

Epoch: 103
Loss: 0.3574336627314041
ROC train: 0.902771	val: 0.612614	test: 0.583667
PRC train: 0.864019	val: 0.665593	test: 0.627118

Epoch: 104
Loss: 0.35208081281779585
ROC train: 0.906624	val: 0.614092	test: 0.585451
PRC train: 0.871788	val: 0.666783	test: 0.629994

Epoch: 105
Loss: 0.3621624950353873
ROC train: 0.909231	val: 0.625590	test: 0.590206
PRC train: 0.872982	val: 0.671012	test: 0.630258

Epoch: 106
Loss: 0.3580399179464312
ROC train: 0.909771	val: 0.633952	test: 0.586791
PRC train: 0.874454	val: 0.673071	test: 0.625899

Epoch: 107
Loss: 0.35568635013205957
ROC train: 0.909331	val: 0.621381	test: 0.582877
PRC train: 0.875562	val: 0.667512	test: 0.623647

Epoch: 108
Loss: 0.35007937633640374
ROC train: 0.910555	val: 0.636672	test: 0.575690
PRC train: 0.876416	val: 0.680547	test: 0.618987

Epoch: 109
Loss: 0.3540428214322915
ROC train: 0.911065	val: 0.636256	test: 0.578963
PRC train: 0.874605	val: 0.677776	test: 0.624103

Epoch: 110
Loss: 0.3531628159570065
ROC train: 0.913142	val: 0.639906	test: 0.580947
PRC train: 0.878764	val: 0.679902	test: 0.626603

Epoch: 111
Loss: 0.34428309422057
ROC train: 0.915679	val: 0.624183	test: 0.581863
PRC train: 0.883740	val: 0.673197	test: 0.627895

Epoch: 112
Loss: 0.34693112793108083
ROC train: 0.914256	val: 0.615581	test: 0.576318
PRC train: 0.881588	val: 0.670203	test: 0.624676

Epoch: 113
Loss: 0.34695003662173296
ROC train: 0.915482	val: 0.617150	test: 0.583190
PRC train: 0.882838	val: 0.664995	test: 0.626595

Epoch: 114
Loss: 0.3476325380946706
ROC train: 0.917977	val: 0.626426	test: 0.585920
PRC train: 0.885239	val: 0.673046	test: 0.627456

Epoch: 115
Loss: 0.3437131647424704
ROC train: 0.918281	val: 0.616648	test: 0.586948
PRC train: 0.884863	val: 0.672038	test: 0.624794

Epoch: 116
Loss: 0.33994889225692254
ROC train: 0.918131	val: 0.615453	test: 0.579895
PRC train: 0.884700	val: 0.667684	test: 0.619696

Epoch: 117
Loss: 0.34402867031321704
ROC train: 0.920029	val: 0.623843	test: 0.579811
PRC train: 0.886932	val: 0.673478	test: 0.621932

Epoch: 118
Loss: 0.33571843883635355
ROC train: 0.917180	val: 0.615126	test: 0.591198
PRC train: 0.885234	val: 0.667317	test: 0.628831

Epoch: 119
Loss: 0.3387197360563412
ROC train: 0.918966	val: 0.619632	test: 0.586138
PRC train: 0.887273	val: 0.667070	test: 0.629820

Epoch: 120
Loss: 0.3396759703661621
ROC train: 0.921776	val: 0.617363	test: 0.582521
PRC train: 0.890645	val: 0.670607	test: 0.627636

Epoch: 121
Loss: 0.32996316247592433
ROC train: 0.922425	val: 0.623749	test: 0.572548
PRC train: 0.889485	val: 0.673983	test: 0.627380

Epoch: 122
Loss: 0.33965251200378493
ROC train: 0.923621	val: 0.619363	test: 0.583275
PRC train: 0.893503	val: 0.673563	test: 0.630373

Epoch: 123
Loss: 0.33312617247217996
ROC train: 0.924102	val: 0.615693	test: 0.576692
PRC train: 0.893216	val: 0.673770	test: 0.627070

Epoch: 124
Loss: 0.3414686685840972
ROC train: 0.923642	val: 0.618752	test: 0.564304
PRC train: 0.891561	val: 0.674326	test: 0.622861

Epoch: 125
Loss: 0.3374674138349116
ROC train: 0.925559	val: 0.625523	test: 0.565280
PRC train: 0.895562	val: 0.674753	test: 0.621518

Epoch: 126
Loss: 0.33052581245322576
ROC train: 0.925732	val: 0.627570	test: 0.579804
PRC train: 0.895622	val: 0.673197	test: 0.625668

Epoch: 127
Loss: 0.33507506793485026
ROC train: 0.927141	val: 0.620773	test: 0.592140
PRC train: 0.895119	val: 0.673785	test: 0.632837

Epoch: 128
Loss: 0.32724517278309473
ROC train: 0.928087	val: 0.626083	test: 0.593949
PRC train: 0.896475	val: 0.675681	test: 0.637328

Epoch: 129
Loss: 0.32758835720595836
ROC train: 0.927050	val: 0.620506	test: 0.596358
PRC train: 0.894851	val: 0.672901	test: 0.637349

Epoch: 130
Loss: 0.32640959740367526
ROC train: 0.929810	val: 0.634068	test: 0.593227
PRC train: 0.900873	val: 0.681272	test: 0.634328

Epoch: 131
Loss: 0.32828314514630225
ROC train: 0.929421	val: 0.626342	test: 0.593589
PRC train: 0.899893	val: 0.675661	test: 0.636703

Epoch: 132
Loss: 0.3212719961792533
ROC train: 0.928161	val: 0.618461	test: 0.589622
PRC train: 0.899498	val: 0.669097	test: 0.635793

Epoch: 133
Loss: 0.3235459821529848
ROC train: 0.930083	val: 0.629851	test: 0.583497
PRC train: 0.902829	val: 0.678128	test: 0.629915

Epoch: 134
Loss: 0.3273940237224214
ROC train: 0.930445	val: 0.627611	test: 0.590482
PRC train: 0.901600	val: 0.670566	test: 0.630017

Epoch: 135
Loss: 0.3256440162021024
ROC train: 0.934084	val: 0.627367	test: 0.599853
PRC train: 0.903330	val: 0.672377	test: 0.635452

Epoch: 136
Loss: 0.32363757462482223
ROC train: 0.933955	val: 0.631530	test: 0.588385
PRC train: 0.902279	val: 0.680246	test: 0.631188

Epoch: 137
Loss: 0.325897226117021
ROC train: 0.932170	val: 0.629669	test: 0.584873
PRC train: 0.901610	val: 0.676886	test: 0.631379

Epoch: 138
Loss: 0.32029939664646834
ROC train: 0.933674	val: 0.624911	test: 0.586194
PRC train: 0.905194	val: 0.672379	test: 0.633328

Epoch: 139
Loss: 0.31724393210500257
ROC train: 0.936171	val: 0.625345	test: 0.583574
PRC train: 0.910683	val: 0.671724	test: 0.627847

Epoch: 140
Loss: 0.3161113755617238
ROC train: 0.936949	val: 0.622222	test: 0.591843
PRC train: 0.912224	val: 0.674304	test: 0.631692

Epoch: 141
Loss: 0.31317301018417754
ROC train: 0.937735	val: 0.623468	test: 0.584893
PRC train: 0.912680	val: 0.671225	test: 0.627996

Epoch: 142
Loss: 0.31826318233073236
ROC train: 0.938700	val: 0.629153	test: 0.593397
PRC train: 0.911870	val: 0.670532	test: 0.633081

Epoch: 143
Loss: 0.3183488963432154
ROC train: 0.937651	val: 0.619833	test: 0.593647
PRC train: 0.909348	val: 0.666924	test: 0.628201

Epoch: 144
Loss: 0.31951481792435377
ROC train: 0.940200	val: 0.630608	test: 0.585941
PRC train: 0.914852	val: 0.677456	test: 0.624299

Epoch: 145
Loss: 0.31485177343465665
ROC train: 0.940190	val: 0.619552	test: 0.581683
PRC train: 0.915639	val: 0.670246	test: 0.624178

Early stopping
Best (ROC):	 train: 0.913142	val: 0.639906	test: 0.580947
Best (PRC):	 train: 0.878764	val: 0.679902	test: 0.626603

PRC train: 0.860563	val: 0.679856	test: 0.626744

Epoch: 95
Loss: 0.36073144706491467
ROC train: 0.896747	val: 0.636295	test: 0.604481
PRC train: 0.859525	val: 0.676213	test: 0.628006

Epoch: 96
Loss: 0.361518348055596
ROC train: 0.897629	val: 0.636584	test: 0.607985
PRC train: 0.860886	val: 0.669834	test: 0.630915

Epoch: 97
Loss: 0.3605880727721895
ROC train: 0.901479	val: 0.642149	test: 0.602594
PRC train: 0.863073	val: 0.677945	test: 0.632901

Epoch: 98
Loss: 0.3564480680670423
ROC train: 0.901854	val: 0.635084	test: 0.604230
PRC train: 0.865573	val: 0.675233	test: 0.635035

Epoch: 99
Loss: 0.355663861517523
ROC train: 0.901003	val: 0.627828	test: 0.596585
PRC train: 0.862632	val: 0.670618	test: 0.633547

Epoch: 100
Loss: 0.35801374456330803
ROC train: 0.902305	val: 0.627945	test: 0.593548
PRC train: 0.865015	val: 0.670051	test: 0.629861

Epoch: 101
Loss: 0.3530798929210917
ROC train: 0.904902	val: 0.630572	test: 0.593585
PRC train: 0.868455	val: 0.669798	test: 0.630071

Epoch: 102
Loss: 0.35302731904129797
ROC train: 0.907793	val: 0.635318	test: 0.587864
PRC train: 0.872434	val: 0.674901	test: 0.631756

Epoch: 103
Loss: 0.3522244297944548
ROC train: 0.908294	val: 0.630784	test: 0.593713
PRC train: 0.873475	val: 0.672408	test: 0.633322

Epoch: 104
Loss: 0.3565281235833911
ROC train: 0.908605	val: 0.625710	test: 0.600629
PRC train: 0.872724	val: 0.670673	test: 0.636565

Epoch: 105
Loss: 0.35094384433150505
ROC train: 0.909979	val: 0.632015	test: 0.594203
PRC train: 0.873552	val: 0.672985	test: 0.632953

Epoch: 106
Loss: 0.35401532550017895
ROC train: 0.911774	val: 0.637121	test: 0.588967
PRC train: 0.876448	val: 0.671992	test: 0.628754

Epoch: 107
Loss: 0.3535157391946423
ROC train: 0.909387	val: 0.626520	test: 0.588491
PRC train: 0.875519	val: 0.666158	test: 0.627795

Epoch: 108
Loss: 0.3469333867431615
ROC train: 0.909767	val: 0.622985	test: 0.594935
PRC train: 0.876788	val: 0.665721	test: 0.629345

Epoch: 109
Loss: 0.348487668947682
ROC train: 0.913272	val: 0.625889	test: 0.590356
PRC train: 0.883606	val: 0.668163	test: 0.630325

Epoch: 110
Loss: 0.3423083178648644
ROC train: 0.914694	val: 0.635222	test: 0.572587
PRC train: 0.882973	val: 0.673065	test: 0.625227

Epoch: 111
Loss: 0.34467731235855215
ROC train: 0.916385	val: 0.637262	test: 0.581553
PRC train: 0.885487	val: 0.672456	test: 0.628781

Epoch: 112
Loss: 0.3429348237593179
ROC train: 0.916045	val: 0.632554	test: 0.591781
PRC train: 0.884322	val: 0.669759	test: 0.635592

Epoch: 113
Loss: 0.3439774431718471
ROC train: 0.916308	val: 0.626881	test: 0.583465
PRC train: 0.886103	val: 0.666064	test: 0.630520

Epoch: 114
Loss: 0.34036245054773806
ROC train: 0.918122	val: 0.633356	test: 0.602251
PRC train: 0.888899	val: 0.670123	test: 0.637150

Epoch: 115
Loss: 0.3443705330406801
ROC train: 0.913428	val: 0.642956	test: 0.608845
PRC train: 0.880057	val: 0.673491	test: 0.642117

Epoch: 116
Loss: 0.33836250251342037
ROC train: 0.917432	val: 0.639582	test: 0.601606
PRC train: 0.884282	val: 0.670537	test: 0.639213

Epoch: 117
Loss: 0.33516798135138454
ROC train: 0.920764	val: 0.633318	test: 0.596416
PRC train: 0.888624	val: 0.666976	test: 0.635101

Epoch: 118
Loss: 0.3327548287303802
ROC train: 0.919794	val: 0.628471	test: 0.600429
PRC train: 0.887390	val: 0.666348	test: 0.636565

Epoch: 119
Loss: 0.3317296667860162
ROC train: 0.920912	val: 0.633063	test: 0.596192
PRC train: 0.889372	val: 0.668991	test: 0.633948

Epoch: 120
Loss: 0.3346442848597833
ROC train: 0.920224	val: 0.634032	test: 0.589527
PRC train: 0.889776	val: 0.668799	test: 0.633075

Epoch: 121
Loss: 0.3345436156925913
ROC train: 0.923293	val: 0.628459	test: 0.583819
PRC train: 0.895855	val: 0.667518	test: 0.632103

Epoch: 122
Loss: 0.336957646118145
ROC train: 0.924113	val: 0.637734	test: 0.580026
PRC train: 0.895257	val: 0.671355	test: 0.634584

Epoch: 123
Loss: 0.33686399106747744
ROC train: 0.924742	val: 0.640453	test: 0.598537
PRC train: 0.895099	val: 0.671366	test: 0.643497

Epoch: 124
Loss: 0.33277115040691335
ROC train: 0.926611	val: 0.647800	test: 0.610207
PRC train: 0.896116	val: 0.674178	test: 0.642861

Epoch: 125
Loss: 0.3293032196356261
ROC train: 0.925260	val: 0.651217	test: 0.595300
PRC train: 0.894709	val: 0.677698	test: 0.636686

Epoch: 126
Loss: 0.33417067138708706
ROC train: 0.925032	val: 0.640207	test: 0.579191
PRC train: 0.893892	val: 0.673078	test: 0.632766

Epoch: 127
Loss: 0.33062892976486336
ROC train: 0.928652	val: 0.639180	test: 0.597616
PRC train: 0.900094	val: 0.674414	test: 0.641360

Epoch: 128
Loss: 0.3249851684014935
ROC train: 0.928113	val: 0.637220	test: 0.608919
PRC train: 0.897379	val: 0.672922	test: 0.644676

Epoch: 129
Loss: 0.3258477037663047
ROC train: 0.928709	val: 0.638063	test: 0.604956
PRC train: 0.899605	val: 0.673584	test: 0.641368

Epoch: 130
Loss: 0.33068426205560586
ROC train: 0.929653	val: 0.646073	test: 0.594023
PRC train: 0.901628	val: 0.676012	test: 0.637539

Epoch: 131
Loss: 0.3264134886588738
ROC train: 0.929712	val: 0.647139	test: 0.609701
PRC train: 0.902227	val: 0.678009	test: 0.645627

Epoch: 132
Loss: 0.33227244939025935
ROC train: 0.930449	val: 0.638976	test: 0.597156
PRC train: 0.901825	val: 0.671767	test: 0.637721

Epoch: 133
Loss: 0.3266236406514108
ROC train: 0.930360	val: 0.641444	test: 0.587204
PRC train: 0.898997	val: 0.669389	test: 0.632744

Epoch: 134
Loss: 0.3200580667626892
ROC train: 0.932879	val: 0.644524	test: 0.602853
PRC train: 0.905987	val: 0.673342	test: 0.642590

Epoch: 135
Loss: 0.3215288874839188
ROC train: 0.932975	val: 0.643784	test: 0.604394
PRC train: 0.907321	val: 0.677408	test: 0.645448

Epoch: 136
Loss: 0.323970085813885
ROC train: 0.935832	val: 0.647135	test: 0.589984
PRC train: 0.910762	val: 0.679537	test: 0.638656

Epoch: 137
Loss: 0.3131385767538754
ROC train: 0.936287	val: 0.639230	test: 0.578731
PRC train: 0.911904	val: 0.674233	test: 0.633794

Epoch: 138
Loss: 0.3159986498652332
ROC train: 0.934744	val: 0.628498	test: 0.591556
PRC train: 0.910488	val: 0.669152	test: 0.639154

Epoch: 139
Loss: 0.3172751375380218
ROC train: 0.935644	val: 0.637874	test: 0.607287
PRC train: 0.911235	val: 0.673817	test: 0.644377

Epoch: 140
Loss: 0.3149808209179746
ROC train: 0.937820	val: 0.642691	test: 0.596403
PRC train: 0.913896	val: 0.674607	test: 0.638123

Epoch: 141
Loss: 0.31202625188438293
ROC train: 0.939637	val: 0.640604	test: 0.591646
PRC train: 0.915944	val: 0.670538	test: 0.636720

Epoch: 142
Loss: 0.3139648260299448
ROC train: 0.938491	val: 0.638624	test: 0.584746
PRC train: 0.916386	val: 0.667724	test: 0.632884

Epoch: 143
Loss: 0.3088516987241682
ROC train: 0.939393	val: 0.639767	test: 0.584437
PRC train: 0.916900	val: 0.670102	test: 0.636190

Epoch: 144
Loss: 0.3156128250450879
ROC train: 0.940143	val: 0.640077	test: 0.583311
PRC train: 0.918029	val: 0.672637	test: 0.635001

Epoch: 145
Loss: 0.30772473886809987
ROC train: 0.939810	val: 0.639022	test: 0.589250
PRC train: 0.918191	val: 0.674059	test: 0.633404

Epoch: 146
Loss: 0.31119751167719134
ROC train: 0.941732	val: 0.644281	test: 0.593671
PRC train: 0.917679	val: 0.673272	test: 0.639952

Epoch: 147
Loss: 0.3076688744562139
ROC train: 0.942647	val: 0.637858	test: 0.580361
PRC train: 0.918883	val: 0.669956	test: 0.633284

Epoch: 148
Loss: 0.3056308635924846
ROC train: 0.942924	val: 0.642012	test: 0.580939
PRC train: 0.918875	val: 0.673883	test: 0.634790

Epoch: 149
Loss: 0.30752344866042625
ROC train: 0.943990	val: 0.638670	test: 0.592414
PRC train: 0.921700	val: 0.671747	test: 0.640259

Epoch: 150
Loss: 0.3010760648554949
ROC train: 0.942990	val: 0.634924	test: 0.598679
PRC train: 0.920939	val: 0.670744	test: 0.643056

Epoch: 151
Loss: 0.30291716241562183
ROC train: 0.944978	val: 0.639014	test: 0.599010
PRC train: 0.924035	val: 0.676648	test: 0.641550

Epoch: 152
Loss: 0.302049411955209
ROC train: 0.944449	val: 0.641293	test: 0.592119
PRC train: 0.923084	val: 0.675497	test: 0.638217

Epoch: 153
Loss: 0.3001278535486863
ROC train: 0.944475	val: 0.641902	test: 0.589320
PRC train: 0.921814	val: 0.673118	test: 0.637486

Epoch: 154
Loss: 0.3034397956177347
ROC train: 0.944969	val: 0.648059	test: 0.588008
PRC train: 0.922234	val: 0.675596	test: 0.637697

Epoch: 155
Loss: 0.2979920744663193
ROC train: 0.948831	val: 0.647078	test: 0.582180
PRC train: 0.927930	val: 0.673351	test: 0.632903

Epoch: 156
Loss: 0.3032940476364754
ROC train: 0.947536	val: 0.648738	test: 0.587001
PRC train: 0.925338	val: 0.675485	test: 0.636495

Epoch: 157
Loss: 0.3013944040268959
ROC train: 0.946637	val: 0.640027	test: 0.598116
PRC train: 0.925488	val: 0.673893	test: 0.642641

Epoch: 158
Loss: 0.30339082739702417
ROC train: 0.948600	val: 0.638137	test: 0.596995
PRC train: 0.927369	val: 0.673157	test: 0.640765

Epoch: 159
Loss: 0.2989267048316607
ROC train: 0.949280	val: 0.631701	test: 0.587877
PRC train: 0.927893	val: 0.670781	test: 0.636808

Epoch: 160
Loss: 0.30157227038268314
ROC train: 0.948470	val: 0.619490	test: 0.591762
PRC train: 0.926583	val: 0.667560	test: 0.640546

Early stopping
Best (ROC):	 train: 0.925260	val: 0.651217	test: 0.595300
Best (PRC):	 train: 0.894709	val: 0.677698	test: 0.636686
All runs completed.

PRC train: 0.890323	val: 0.662862	test: 0.621336

Epoch: 94
Loss: 0.31243603979427437
ROC train: 0.932113	val: 0.617161	test: 0.591910
PRC train: 0.891610	val: 0.661353	test: 0.620429

Epoch: 95
Loss: 0.3151911500072234
ROC train: 0.931407	val: 0.623199	test: 0.581713
PRC train: 0.889984	val: 0.660944	test: 0.617452

Epoch: 96
Loss: 0.31451596797666354
ROC train: 0.934673	val: 0.635433	test: 0.587698
PRC train: 0.893847	val: 0.671272	test: 0.620789

Epoch: 97
Loss: 0.31009125240809216
ROC train: 0.935133	val: 0.622985	test: 0.593799
PRC train: 0.895859	val: 0.664051	test: 0.623446

Epoch: 98
Loss: 0.3092825029058783
ROC train: 0.936269	val: 0.620977	test: 0.592251
PRC train: 0.895301	val: 0.666172	test: 0.621498

Epoch: 99
Loss: 0.31217519041270936
ROC train: 0.937963	val: 0.624152	test: 0.587129
PRC train: 0.900012	val: 0.664082	test: 0.618461

Epoch: 100
Loss: 0.31078068010744836
ROC train: 0.937118	val: 0.620329	test: 0.583836
PRC train: 0.896860	val: 0.660341	test: 0.617787

Epoch: 101
Loss: 0.3095491027698325
ROC train: 0.939216	val: 0.623322	test: 0.578453
PRC train: 0.898215	val: 0.666915	test: 0.613822

Epoch: 102
Loss: 0.30583642538064915
ROC train: 0.939507	val: 0.613451	test: 0.582321
PRC train: 0.901128	val: 0.664746	test: 0.616674

Epoch: 103
Loss: 0.30378357203008466
ROC train: 0.941450	val: 0.614607	test: 0.584427
PRC train: 0.904080	val: 0.662045	test: 0.617613

Epoch: 104
Loss: 0.29666637809941127
ROC train: 0.940278	val: 0.627380	test: 0.583160
PRC train: 0.903296	val: 0.664713	test: 0.617026

Epoch: 105
Loss: 0.3053041052765142
ROC train: 0.942421	val: 0.627941	test: 0.582047
PRC train: 0.907194	val: 0.664556	test: 0.618321

Epoch: 106
Loss: 0.3004979911507184
ROC train: 0.944204	val: 0.624054	test: 0.582985
PRC train: 0.906428	val: 0.670198	test: 0.617305

Epoch: 107
Loss: 0.30144233195992426
ROC train: 0.943867	val: 0.622186	test: 0.586365
PRC train: 0.905802	val: 0.663297	test: 0.617662

Epoch: 108
Loss: 0.29347504664014556
ROC train: 0.942767	val: 0.619354	test: 0.581076
PRC train: 0.906976	val: 0.660195	test: 0.616723

Epoch: 109
Loss: 0.2960400850526781
ROC train: 0.944778	val: 0.613838	test: 0.580606
PRC train: 0.910319	val: 0.659579	test: 0.616416

Epoch: 110
Loss: 0.29424602577714437
ROC train: 0.945348	val: 0.617300	test: 0.580736
PRC train: 0.912959	val: 0.662893	test: 0.619102

Epoch: 111
Loss: 0.2984415631424712
ROC train: 0.948242	val: 0.624283	test: 0.584772
PRC train: 0.918038	val: 0.669591	test: 0.619507

Epoch: 112
Loss: 0.29210742989380173
ROC train: 0.948798	val: 0.609484	test: 0.590159
PRC train: 0.919957	val: 0.655634	test: 0.621534

Epoch: 113
Loss: 0.29479402388906845
ROC train: 0.950976	val: 0.614830	test: 0.587761
PRC train: 0.919638	val: 0.662169	test: 0.621895

Epoch: 114
Loss: 0.2890650743749103
ROC train: 0.951740	val: 0.620329	test: 0.585929
PRC train: 0.917024	val: 0.668216	test: 0.622009

Epoch: 115
Loss: 0.2897292719317208
ROC train: 0.951563	val: 0.620614	test: 0.588926
PRC train: 0.921699	val: 0.664154	test: 0.623079

Epoch: 116
Loss: 0.28465180350829866
ROC train: 0.952874	val: 0.625540	test: 0.587840
PRC train: 0.923975	val: 0.669299	test: 0.621331

Epoch: 117
Loss: 0.28554929343296614
ROC train: 0.953695	val: 0.624764	test: 0.580161
PRC train: 0.924551	val: 0.669081	test: 0.617367

Epoch: 118
Loss: 0.28317913327264826
ROC train: 0.954565	val: 0.614172	test: 0.587237
PRC train: 0.927657	val: 0.662146	test: 0.617697

Epoch: 119
Loss: 0.2801306450564369
ROC train: 0.954563	val: 0.623608	test: 0.582950
PRC train: 0.926428	val: 0.665658	test: 0.619693

Epoch: 120
Loss: 0.28399345560807965
ROC train: 0.954955	val: 0.636405	test: 0.583279
PRC train: 0.926514	val: 0.672253	test: 0.622749

Epoch: 121
Loss: 0.27813199453255477
ROC train: 0.956411	val: 0.626808	test: 0.587966
PRC train: 0.928876	val: 0.668214	test: 0.620966

Epoch: 122
Loss: 0.28325116182563986
ROC train: 0.958090	val: 0.621805	test: 0.591465
PRC train: 0.931568	val: 0.670126	test: 0.618897

Epoch: 123
Loss: 0.27584591316870366
ROC train: 0.958892	val: 0.618722	test: 0.587296
PRC train: 0.929603	val: 0.670799	test: 0.619677

Epoch: 124
Loss: 0.2776344770958807
ROC train: 0.959977	val: 0.619628	test: 0.581241
PRC train: 0.934286	val: 0.667959	test: 0.617286

Epoch: 125
Loss: 0.2780699954234354
ROC train: 0.961635	val: 0.626846	test: 0.581836
PRC train: 0.938567	val: 0.667180	test: 0.618391

Epoch: 126
Loss: 0.2763181883226979
ROC train: 0.960726	val: 0.621135	test: 0.574474
PRC train: 0.937849	val: 0.663198	test: 0.616051

Epoch: 127
Loss: 0.26934270825452666
ROC train: 0.961340	val: 0.622304	test: 0.570873
PRC train: 0.939329	val: 0.664530	test: 0.615222

Epoch: 128
Loss: 0.267853860381233
ROC train: 0.962474	val: 0.626060	test: 0.576133
PRC train: 0.939884	val: 0.665980	test: 0.615312

Epoch: 129
Loss: 0.2669122464698155
ROC train: 0.964792	val: 0.630615	test: 0.580340
PRC train: 0.941644	val: 0.672769	test: 0.617314

Epoch: 130
Loss: 0.2614160617914884
ROC train: 0.964605	val: 0.628820	test: 0.579294
PRC train: 0.942744	val: 0.670055	test: 0.615703

Epoch: 131
Loss: 0.2609449875894629
ROC train: 0.962902	val: 0.633233	test: 0.575000
PRC train: 0.942621	val: 0.671691	test: 0.614114

Epoch: 132
Loss: 0.26143868160003836
ROC train: 0.966117	val: 0.628749	test: 0.571440
PRC train: 0.946300	val: 0.679031	test: 0.611188

Epoch: 133
Loss: 0.2602764386619268
ROC train: 0.966128	val: 0.617649	test: 0.568172
PRC train: 0.945697	val: 0.665464	test: 0.609750

Epoch: 134
Loss: 0.2562465881948241
ROC train: 0.967491	val: 0.624104	test: 0.574162
PRC train: 0.947344	val: 0.671434	test: 0.614157

Epoch: 135
Loss: 0.25623762715210247
ROC train: 0.969346	val: 0.629550	test: 0.576591
PRC train: 0.950181	val: 0.676542	test: 0.615827

Epoch: 136
Loss: 0.25658416340365475
ROC train: 0.969121	val: 0.622672	test: 0.577012
PRC train: 0.948887	val: 0.668247	test: 0.614808

Epoch: 137
Loss: 0.2550586673549077
ROC train: 0.969428	val: 0.625425	test: 0.579595
PRC train: 0.949983	val: 0.670216	test: 0.616540

Epoch: 138
Loss: 0.25274508084272834
ROC train: 0.969361	val: 0.621088	test: 0.576864
PRC train: 0.952089	val: 0.667914	test: 0.615992

Epoch: 139
Loss: 0.25049089323707247
ROC train: 0.970287	val: 0.614015	test: 0.582656
PRC train: 0.950137	val: 0.664796	test: 0.614329

Epoch: 140
Loss: 0.25228122995736857
ROC train: 0.971528	val: 0.621281	test: 0.579113
PRC train: 0.952812	val: 0.669851	test: 0.615574

Epoch: 141
Loss: 0.2506355222661513
ROC train: 0.971750	val: 0.625553	test: 0.575263
PRC train: 0.956654	val: 0.667873	test: 0.614541

Epoch: 142
Loss: 0.2476309329718404
ROC train: 0.972277	val: 0.625945	test: 0.577447
PRC train: 0.954846	val: 0.667876	test: 0.615958

Epoch: 143
Loss: 0.24629142535578136
ROC train: 0.971427	val: 0.622128	test: 0.569359
PRC train: 0.952430	val: 0.666689	test: 0.610646

Epoch: 144
Loss: 0.24476022812345927
ROC train: 0.972978	val: 0.623321	test: 0.572875
PRC train: 0.955146	val: 0.666849	test: 0.612035

Epoch: 145
Loss: 0.23944682314286886
ROC train: 0.975221	val: 0.617305	test: 0.577140
PRC train: 0.960657	val: 0.667381	test: 0.611600

Epoch: 146
Loss: 0.24391554849807115
ROC train: 0.974989	val: 0.620032	test: 0.574294
PRC train: 0.958310	val: 0.665351	test: 0.611895

Epoch: 147
Loss: 0.2450619376850045
ROC train: 0.975329	val: 0.623817	test: 0.574841
PRC train: 0.960736	val: 0.666836	test: 0.611820

Epoch: 148
Loss: 0.24540370953871382
ROC train: 0.975348	val: 0.625079	test: 0.575883
PRC train: 0.961062	val: 0.668370	test: 0.609192

Epoch: 149
Loss: 0.23918213701867677
ROC train: 0.976324	val: 0.613665	test: 0.578859
PRC train: 0.960155	val: 0.659201	test: 0.613170

Epoch: 150
Loss: 0.2402674670839148
ROC train: 0.977591	val: 0.626311	test: 0.579622
PRC train: 0.964818	val: 0.673010	test: 0.618499

Epoch: 151
Loss: 0.23455014369654306
ROC train: 0.976081	val: 0.618741	test: 0.580204
PRC train: 0.963422	val: 0.667470	test: 0.616809

Epoch: 152
Loss: 0.23518748049961732
ROC train: 0.977581	val: 0.619500	test: 0.572392
PRC train: 0.962617	val: 0.664506	test: 0.610132

Epoch: 153
Loss: 0.23408911735889032
ROC train: 0.977986	val: 0.612208	test: 0.572345
PRC train: 0.961900	val: 0.660632	test: 0.609750

Epoch: 154
Loss: 0.2339218625446252
ROC train: 0.979362	val: 0.615506	test: 0.580803
PRC train: 0.967559	val: 0.664023	test: 0.615020

Epoch: 155
Loss: 0.23245659853310108
ROC train: 0.980085	val: 0.616183	test: 0.577891
PRC train: 0.968074	val: 0.665548	test: 0.615702

Early stopping
Best (ROC):	 train: 0.954955	val: 0.636405	test: 0.583279
Best (PRC):	 train: 0.926514	val: 0.672253	test: 0.622749
All runs completed.
