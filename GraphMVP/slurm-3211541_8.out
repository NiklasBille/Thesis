>>> Starting run for dataset: sider
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running SCAFF configs_split_experiments/GraphMVP/sider/scaff/train_prop=0.6.yml on cuda:0
Running SCAFF configs_split_experiments/GraphMVP/sider/scaff/train_prop=0.7.yml on cuda:1
Running SCAFF configs_split_experiments/GraphMVP/sider/scaff/train_prop=0.8.yml on cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/sider/scaff/train_prop=0.8.yml --runseed 4 --device cuda:2
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/sider/scaff/train_prop=0.8.yml --runseed 5 --device cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/sider/scaff/train_prop=0.6.yml --runseed 4 --device cuda:0
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/sider/scaff/train_prop=0.8.yml --runseed 6 --device cuda:2
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/sider/scaff/train_prop=0.6.yml --runseed 5 --device cuda:0
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/sider/scaff/train_prop=0.7.yml --runseed 4 --device cuda:1
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/sider/scaff/train_prop=0.6.yml --runseed 6 --device cuda:0
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/sider/scaff/train_prop=0.7.yml --runseed 5 --device cuda:1
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/sider/scaff/train_prop=0.7.yml --runseed 6 --device cuda:1
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] [11:13:32] WARNING: not removing hydrogen atom without neighborsWARNING: not removing hydrogen atom without neighbors

[11:13:32] WARNING: not removing hydrogen atom without neighbors[11:13:32] 
WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:32] WARNING: not removing hydrogen atom without neighbors
[11:13:33] WARNING: not removing hydrogen atom without neighbors
[11:13:33] WARNING: not removing hydrogen atom without neighbors
[11:13:33] WARNING: not removing hydrogen atom without neighbors
[11:13:33] WARNING: not removing hydrogen atom without neighbors
[11:13:33] WARNING: not removing hydrogen atom without neighbors
[11:13:33] WARNING: not removing hydrogen atom without neighbors
[11:13:33] WARNING: not removing hydrogen atom without neighbors
[11:13:33] WARNING: not removing hydrogen atom without neighbors
[11:13:33] WARNING: not removing hydrogen atom without neighbors
[11:13:33] WARNING: not removing hydrogen atom without neighbors
[11:13:33] WARNING: not removing hydrogen atom without neighbors
[11:13:33] WARNING: not removing hydrogen atom without neighbors
[11:13:33] WARNING: not removing hydrogen atom without neighbors
[11:13:33] WARNING: not removing hydrogen atom without neighbors
[11:13:33] WARNING: not removing hydrogen atom without neighbors
[11:13:33] WARNING: not removing hydrogen atom without neighbors
[11:13:33] WARNING: not removing hydrogen atom without neighbors
[11:13:33] WARNING: not removing hydrogen atom without neighbors
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/sider/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/sider/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/sider/scaff/train_prop=0.6/sider_scaff_5_26-05_11-13-31  ]
[ Using Seed :  5  ]
[ Using device :  cuda:0  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6893669982792631
ROC train: 0.523615	val: 0.490533	test: 0.486763
PRC train: 0.562826	val: 0.592088	test: 0.581157

Epoch: 2
Loss: 0.6567003430793205
ROC train: 0.554626	val: 0.503950	test: 0.500594
PRC train: 0.587279	val: 0.600308	test: 0.587635

Epoch: 3
Loss: 0.6276346298365549
ROC train: 0.578288	val: 0.509719	test: 0.509389
PRC train: 0.606458	val: 0.603070	test: 0.591329

Epoch: 4
Loss: 0.602131332198264
ROC train: 0.596805	val: 0.513414	test: 0.517030
PRC train: 0.618130	val: 0.603471	test: 0.591409

Epoch: 5
Loss: 0.582957614016963
ROC train: 0.611309	val: 0.521736	test: 0.524296
PRC train: 0.627880	val: 0.606357	test: 0.594395

Epoch: 6
Loss: 0.5687420244664007
ROC train: 0.630462	val: 0.529239	test: 0.538305
PRC train: 0.638265	val: 0.610541	test: 0.601861

Epoch: 7
Loss: 0.5446023459145324
ROC train: 0.643148	val: 0.536467	test: 0.553555
PRC train: 0.644213	val: 0.613274	test: 0.611830

Epoch: 8
Loss: 0.5402423556930553
ROC train: 0.658679	val: 0.541061	test: 0.564372
PRC train: 0.652852	val: 0.618411	test: 0.617089

Epoch: 9
Loss: 0.5387510409909544
ROC train: 0.672458	val: 0.547855	test: 0.576167
PRC train: 0.660331	val: 0.622063	test: 0.621139

Epoch: 10
Loss: 0.5171389298247057
ROC train: 0.684812	val: 0.557401	test: 0.581255
PRC train: 0.667204	val: 0.626294	test: 0.622262

Epoch: 11
Loss: 0.5168756972512258
ROC train: 0.691457	val: 0.568676	test: 0.582111
PRC train: 0.673319	val: 0.629136	test: 0.621832

Epoch: 12
Loss: 0.5105191520891071
ROC train: 0.698963	val: 0.572231	test: 0.580027
PRC train: 0.680413	val: 0.630412	test: 0.621216

Epoch: 13
Loss: 0.5005114078339413
ROC train: 0.707436	val: 0.572224	test: 0.582592
PRC train: 0.684855	val: 0.628956	test: 0.621869

Epoch: 14
Loss: 0.4979331028734821
ROC train: 0.715056	val: 0.567268	test: 0.583988
PRC train: 0.688731	val: 0.628092	test: 0.624023

Epoch: 15
Loss: 0.4928413101788696
ROC train: 0.720670	val: 0.564498	test: 0.581289
PRC train: 0.692912	val: 0.628131	test: 0.624731

Epoch: 16
Loss: 0.4939720702475374
ROC train: 0.726636	val: 0.561770	test: 0.584075
PRC train: 0.696129	val: 0.629371	test: 0.626376

Epoch: 17
Loss: 0.4892897929228336
ROC train: 0.724523	val: 0.559477	test: 0.584858
PRC train: 0.696348	val: 0.626085	test: 0.625987

Epoch: 18
Loss: 0.4852601810649081
ROC train: 0.730163	val: 0.564857	test: 0.587624
PRC train: 0.701689	val: 0.626717	test: 0.627580

Epoch: 19
Loss: 0.48037181966044995
ROC train: 0.738348	val: 0.571519	test: 0.586739
PRC train: 0.708192	val: 0.630047	test: 0.626823

Epoch: 20
Loss: 0.4721949581169683
ROC train: 0.736341	val: 0.568266	test: 0.584209
PRC train: 0.708143	val: 0.625539	test: 0.625744

Epoch: 21
Loss: 0.4762550767560787
ROC train: 0.745066	val: 0.567491	test: 0.588352
PRC train: 0.712624	val: 0.627246	test: 0.627202

Epoch: 22
Loss: 0.47074177627265396
ROC train: 0.753572	val: 0.567122	test: 0.592605
PRC train: 0.716805	val: 0.629808	test: 0.629727

Epoch: 23
Loss: 0.46962699586649775
ROC train: 0.756147	val: 0.565120	test: 0.588475
PRC train: 0.718677	val: 0.628624	test: 0.630573

Epoch: 24
Loss: 0.4700789875815828
ROC train: 0.761004	val: 0.562485	test: 0.588793
PRC train: 0.722524	val: 0.630877	test: 0.630043

Epoch: 25
Loss: 0.46095473842138945
ROC train: 0.764113	val: 0.558410	test: 0.590994
PRC train: 0.725488	val: 0.628445	test: 0.631841

Epoch: 26
Loss: 0.46525783302414037
ROC train: 0.760221	val: 0.554585	test: 0.593203
PRC train: 0.723389	val: 0.622687	test: 0.632626

Epoch: 27
Loss: 0.4571313556611817
ROC train: 0.767053	val: 0.560514	test: 0.597568
PRC train: 0.728545	val: 0.624812	test: 0.632843

Epoch: 28
Loss: 0.45428467250262383
ROC train: 0.771918	val: 0.559536	test: 0.596470
PRC train: 0.732088	val: 0.624682	test: 0.633037

Epoch: 29
Loss: 0.4592574919270421
ROC train: 0.774978	val: 0.556255	test: 0.593157
PRC train: 0.735605	val: 0.621859	test: 0.631940

Epoch: 30
Loss: 0.45567051943764797
ROC train: 0.779472	val: 0.554714	test: 0.589599
PRC train: 0.738652	val: 0.623030	test: 0.630152

Epoch: 31
Loss: 0.4574694921748826
ROC train: 0.782963	val: 0.556952	test: 0.588636
PRC train: 0.741151	val: 0.627984	test: 0.630863

Epoch: 32
Loss: 0.4464398473354023
ROC train: 0.785069	val: 0.560604	test: 0.589198
PRC train: 0.742904	val: 0.634731	test: 0.630785

Epoch: 33
Loss: 0.4523957827281925Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/sider/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/sider/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/sider/scaff/train_prop=0.6/sider_scaff_4_26-05_11-13-31  ]
[ Using Seed :  4  ]
[ Using device :  cuda:0  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6860530810671597
ROC train: 0.528820	val: 0.495615	test: 0.509191
PRC train: 0.577606	val: 0.597918	test: 0.590375

Epoch: 2
Loss: 0.6527170300926418
ROC train: 0.562050	val: 0.502398	test: 0.514060
PRC train: 0.597813	val: 0.599136	test: 0.591585

Epoch: 3
Loss: 0.6240068693957591
ROC train: 0.575512	val: 0.503952	test: 0.514956
PRC train: 0.607989	val: 0.599279	test: 0.592013

Epoch: 4
Loss: 0.5992540912864315
ROC train: 0.588813	val: 0.504091	test: 0.515706
PRC train: 0.615904	val: 0.598764	test: 0.592954

Epoch: 5
Loss: 0.5855807023217872
ROC train: 0.612371	val: 0.508566	test: 0.523905
PRC train: 0.628469	val: 0.601171	test: 0.597168

Epoch: 6
Loss: 0.5663849150183222
ROC train: 0.637270	val: 0.515063	test: 0.536781
PRC train: 0.642023	val: 0.604941	test: 0.604543

Epoch: 7
Loss: 0.5548734056244548
ROC train: 0.650564	val: 0.521925	test: 0.555058
PRC train: 0.650429	val: 0.608219	test: 0.615542

Epoch: 8
Loss: 0.5381097888422335
ROC train: 0.662337	val: 0.534793	test: 0.568621
PRC train: 0.658423	val: 0.613088	test: 0.622136

Epoch: 9
Loss: 0.5334287165325587
ROC train: 0.675399	val: 0.549489	test: 0.577649
PRC train: 0.667205	val: 0.618858	test: 0.624185

Epoch: 10
Loss: 0.5205216735837705
ROC train: 0.687962	val: 0.559139	test: 0.582113
PRC train: 0.674084	val: 0.620560	test: 0.625145

Epoch: 11
Loss: 0.5171632713961488
ROC train: 0.696127	val: 0.561892	test: 0.583953
PRC train: 0.679045	val: 0.621191	test: 0.627042

Epoch: 12
Loss: 0.5081189118690741
ROC train: 0.704185	val: 0.564173	test: 0.583815
PRC train: 0.684735	val: 0.621384	test: 0.626799

Epoch: 13
Loss: 0.502298130637103
ROC train: 0.710091	val: 0.563560	test: 0.583161
PRC train: 0.689082	val: 0.621163	test: 0.625869

Epoch: 14
Loss: 0.49507404984471615
ROC train: 0.719056	val: 0.563775	test: 0.585942
PRC train: 0.693688	val: 0.619403	test: 0.628360

Epoch: 15
Loss: 0.4931226776807579
ROC train: 0.725149	val: 0.560291	test: 0.588312
PRC train: 0.696973	val: 0.617288	test: 0.628766

Epoch: 16
Loss: 0.4867782048762565
ROC train: 0.726293	val: 0.559604	test: 0.586340
PRC train: 0.697538	val: 0.617216	test: 0.628068

Epoch: 17
Loss: 0.4802036665298628
ROC train: 0.737070	val: 0.568613	test: 0.588219
PRC train: 0.705698	val: 0.622934	test: 0.626938

Epoch: 18
Loss: 0.4802620938359508
ROC train: 0.739029	val: 0.565182	test: 0.589156
PRC train: 0.707055	val: 0.621336	test: 0.627724

Epoch: 19
Loss: 0.4758598600396976
ROC train: 0.746656	val: 0.566296	test: 0.590602
PRC train: 0.712991	val: 0.621900	test: 0.628989

Epoch: 20
Loss: 0.4795450660958914
ROC train: 0.751319	val: 0.561412	test: 0.592988
PRC train: 0.715196	val: 0.621196	test: 0.630304

Epoch: 21
Loss: 0.46714553044010404
ROC train: 0.752807	val: 0.562045	test: 0.593373
PRC train: 0.718495	val: 0.623765	test: 0.629911

Epoch: 22
Loss: 0.4686942726543184
ROC train: 0.755126	val: 0.567342	test: 0.599461
PRC train: 0.720008	val: 0.627445	test: 0.634180

Epoch: 23
Loss: 0.4669146962475558
ROC train: 0.757201	val: 0.567480	test: 0.596830
PRC train: 0.721005	val: 0.625188	test: 0.634101

Epoch: 24
Loss: 0.45621376788348167
ROC train: 0.762095	val: 0.562351	test: 0.594034
PRC train: 0.725108	val: 0.622712	test: 0.631684

Epoch: 25
Loss: 0.4596733987546266
ROC train: 0.768004	val: 0.571865	test: 0.595531
PRC train: 0.730573	val: 0.627612	test: 0.631238

Epoch: 26
Loss: 0.45633403825406327
ROC train: 0.770617	val: 0.578934	test: 0.593132
PRC train: 0.731552	val: 0.630299	test: 0.631464

Epoch: 27
Loss: 0.46475244008607897
ROC train: 0.761884	val: 0.570988	test: 0.586813
PRC train: 0.724468	val: 0.623695	test: 0.631532

Epoch: 28
Loss: 0.45736291094250364
ROC train: 0.770568	val: 0.570191	test: 0.590386
PRC train: 0.730915	val: 0.624677	test: 0.632284

Epoch: 29
Loss: 0.45147693374401116
ROC train: 0.776448	val: 0.564697	test: 0.592045
PRC train: 0.735511	val: 0.623718	test: 0.631836

Epoch: 30
Loss: 0.45005237197312953
ROC train: 0.779367	val: 0.556205	test: 0.593409
PRC train: 0.735909	val: 0.618412	test: 0.630922

Epoch: 31
Loss: 0.44892496174269425
ROC train: 0.776375	val: 0.549809	test: 0.591688
PRC train: 0.732462	val: 0.613845	test: 0.630137

Epoch: 32
Loss: 0.4494859413200104
ROC train: 0.786929	val: 0.558803	test: 0.590860
PRC train: 0.742990	val: 0.623987	test: 0.632013

Epoch: 33
Loss: 0.4436448893500814Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/sider/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/sider/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/sider/scaff/train_prop=0.6/sider_scaff_6_26-05_11-13-31  ]
[ Using Seed :  6  ]
[ Using device :  cuda:0  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6900630293367592
ROC train: 0.527886	val: 0.501715	test: 0.510183
PRC train: 0.572423	val: 0.593967	test: 0.597012

Epoch: 2
Loss: 0.659099316722612
ROC train: 0.553579	val: 0.509170	test: 0.508788
PRC train: 0.591719	val: 0.598786	test: 0.596355

Epoch: 3
Loss: 0.6320087576843234
ROC train: 0.569560	val: 0.506217	test: 0.509321
PRC train: 0.602811	val: 0.599220	test: 0.592760

Epoch: 4
Loss: 0.6020051962544323
ROC train: 0.587977	val: 0.504473	test: 0.515079
PRC train: 0.613551	val: 0.595899	test: 0.593444

Epoch: 5
Loss: 0.5829085909145042
ROC train: 0.606564	val: 0.504644	test: 0.519985
PRC train: 0.624589	val: 0.595476	test: 0.595082

Epoch: 6
Loss: 0.5621556477596079
ROC train: 0.623656	val: 0.510937	test: 0.528608
PRC train: 0.634162	val: 0.599254	test: 0.599683

Epoch: 7
Loss: 0.5581724867070462
ROC train: 0.639160	val: 0.522988	test: 0.540150
PRC train: 0.643529	val: 0.605097	test: 0.604697

Epoch: 8
Loss: 0.5532001696021542
ROC train: 0.659841	val: 0.532786	test: 0.557970
PRC train: 0.654884	val: 0.610653	test: 0.611426

Epoch: 9
Loss: 0.530944089365287
ROC train: 0.675685	val: 0.542874	test: 0.572188
PRC train: 0.663723	val: 0.613872	test: 0.616118

Epoch: 10
Loss: 0.5276508042110712
ROC train: 0.688073	val: 0.549212	test: 0.575924
PRC train: 0.671621	val: 0.617543	test: 0.620119

Epoch: 11
Loss: 0.5178449404430141
ROC train: 0.692184	val: 0.551572	test: 0.573743
PRC train: 0.675261	val: 0.620367	test: 0.621082

Epoch: 12
Loss: 0.5148956145233705
ROC train: 0.700639	val: 0.554250	test: 0.580321
PRC train: 0.680129	val: 0.622103	test: 0.623530

Epoch: 13
Loss: 0.5069224496501799
ROC train: 0.704331	val: 0.556833	test: 0.582229
PRC train: 0.683906	val: 0.623358	test: 0.624015

Epoch: 14
Loss: 0.5018000782959072
ROC train: 0.713641	val: 0.559933	test: 0.587262
PRC train: 0.689379	val: 0.625491	test: 0.626916

Epoch: 15
Loss: 0.4939860550921132
ROC train: 0.720733	val: 0.554714	test: 0.594344
PRC train: 0.692013	val: 0.622925	test: 0.631847

Epoch: 16
Loss: 0.49051937702058246
ROC train: 0.728116	val: 0.563714	test: 0.598014
PRC train: 0.697656	val: 0.629052	test: 0.632708

Epoch: 17
Loss: 0.4812973666746291
ROC train: 0.733122	val: 0.566005	test: 0.599920
PRC train: 0.701461	val: 0.632038	test: 0.633334

Epoch: 18
Loss: 0.48099661198895194
ROC train: 0.736682	val: 0.563384	test: 0.597913
PRC train: 0.703747	val: 0.630438	test: 0.632249

Epoch: 19
Loss: 0.4736334625409799
ROC train: 0.738276	val: 0.561585	test: 0.597051
PRC train: 0.704549	val: 0.626002	test: 0.633323

Epoch: 20
Loss: 0.4750114875865045
ROC train: 0.747400	val: 0.568777	test: 0.600110
PRC train: 0.711652	val: 0.629491	test: 0.633297

Epoch: 21
Loss: 0.4700360546861753
ROC train: 0.754076	val: 0.570691	test: 0.600380
PRC train: 0.716661	val: 0.632507	test: 0.632557

Epoch: 22
Loss: 0.47321108829902886
ROC train: 0.756434	val: 0.562470	test: 0.599172
PRC train: 0.719820	val: 0.630365	test: 0.631519

Epoch: 23
Loss: 0.46368942208113384
ROC train: 0.758950	val: 0.560869	test: 0.598653
PRC train: 0.722593	val: 0.630544	test: 0.631870

Epoch: 24
Loss: 0.4683347625787892
ROC train: 0.762638	val: 0.553696	test: 0.600929
PRC train: 0.725988	val: 0.627677	test: 0.635847

Epoch: 25
Loss: 0.46465719607738976
ROC train: 0.766591	val: 0.554694	test: 0.601920
PRC train: 0.728705	val: 0.628487	test: 0.635802

Epoch: 26
Loss: 0.45982334428374627
ROC train: 0.770878	val: 0.564533	test: 0.601040
PRC train: 0.732096	val: 0.632355	test: 0.635434

Epoch: 27
Loss: 0.4561328281890413
ROC train: 0.773953	val: 0.566242	test: 0.598135
PRC train: 0.734153	val: 0.632367	test: 0.633284

Epoch: 28
Loss: 0.4534847342250512
ROC train: 0.778396	val: 0.559645	test: 0.597567
PRC train: 0.738151	val: 0.628900	test: 0.633071

Epoch: 29
Loss: 0.45180271059150967
ROC train: 0.776496	val: 0.555864	test: 0.596542
PRC train: 0.737871	val: 0.630169	test: 0.635687

Epoch: 30
Loss: 0.4522305347218793
ROC train: 0.782974	val: 0.557038	test: 0.600859
PRC train: 0.743396	val: 0.630540	test: 0.640041

Epoch: 31
Loss: 0.4449899207304751
ROC train: 0.781664	val: 0.556463	test: 0.598156
PRC train: 0.741645	val: 0.625972	test: 0.636723

Epoch: 32
Loss: 0.44481050054373006
ROC train: 0.777545	val: 0.554152	test: 0.593969
PRC train: 0.738462	val: 0.628075	test: 0.635409

Epoch: 33
Loss: 0.44629970684402964Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/sider/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/sider/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/sider/scaff/train_prop=0.7/sider_scaff_5_26-05_11-13-31  ]
[ Using Seed :  5  ]
[ Using device :  cuda:1  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6900525346553781
ROC train: 0.518619	val: 0.496610	test: 0.485816
PRC train: 0.564905	val: 0.606518	test: 0.567672

Epoch: 2
Loss: 0.6562336149924427
ROC train: 0.550984	val: 0.513419	test: 0.508529
PRC train: 0.589343	val: 0.614467	test: 0.578781

Epoch: 3
Loss: 0.6282667353173144
ROC train: 0.567891	val: 0.512144	test: 0.516988
PRC train: 0.603504	val: 0.615425	test: 0.581459

Epoch: 4
Loss: 0.6000077938579557
ROC train: 0.583128	val: 0.502463	test: 0.523893
PRC train: 0.614144	val: 0.612657	test: 0.584403

Epoch: 5
Loss: 0.5794257116708674
ROC train: 0.605802	val: 0.506816	test: 0.544399
PRC train: 0.626238	val: 0.614223	test: 0.594801

Epoch: 6
Loss: 0.562164007750886
ROC train: 0.622268	val: 0.513004	test: 0.565743
PRC train: 0.635433	val: 0.621243	test: 0.604715

Epoch: 7
Loss: 0.5488420749605111
ROC train: 0.637497	val: 0.534249	test: 0.581283
PRC train: 0.642998	val: 0.633572	test: 0.611213

Epoch: 8
Loss: 0.5394865041118486
ROC train: 0.653797	val: 0.551573	test: 0.591754
PRC train: 0.652297	val: 0.639897	test: 0.616562

Epoch: 9
Loss: 0.5357901882567775
ROC train: 0.664694	val: 0.559207	test: 0.596012
PRC train: 0.661718	val: 0.639649	test: 0.618287

Epoch: 10
Loss: 0.5239640719520674
ROC train: 0.674698	val: 0.573965	test: 0.597466
PRC train: 0.667940	val: 0.642443	test: 0.620131

Epoch: 11
Loss: 0.516312431389743
ROC train: 0.683040	val: 0.584819	test: 0.600282
PRC train: 0.673145	val: 0.645753	test: 0.621492

Epoch: 12
Loss: 0.5086177557988829
ROC train: 0.689963	val: 0.592917	test: 0.600605
PRC train: 0.678560	val: 0.649738	test: 0.620732

Epoch: 13
Loss: 0.5025056518182935
ROC train: 0.696780	val: 0.597346	test: 0.602577
PRC train: 0.683056	val: 0.651848	test: 0.620430

Epoch: 14
Loss: 0.4977362736664229
ROC train: 0.704096	val: 0.597741	test: 0.601683
PRC train: 0.687396	val: 0.652555	test: 0.621376

Epoch: 15
Loss: 0.495759528876652
ROC train: 0.713352	val: 0.594250	test: 0.611153
PRC train: 0.691812	val: 0.649927	test: 0.625724

Epoch: 16
Loss: 0.4907838786212098
ROC train: 0.717468	val: 0.588316	test: 0.610230
PRC train: 0.696419	val: 0.649076	test: 0.626151

Epoch: 17
Loss: 0.48332749662601837
ROC train: 0.721446	val: 0.584010	test: 0.606143
PRC train: 0.700495	val: 0.650778	test: 0.624274

Epoch: 18
Loss: 0.48271997587264664
ROC train: 0.725234	val: 0.584268	test: 0.604255
PRC train: 0.703756	val: 0.651465	test: 0.625239

Epoch: 19
Loss: 0.48143431473460485
ROC train: 0.727052	val: 0.587875	test: 0.601327
PRC train: 0.705296	val: 0.653351	test: 0.622869

Epoch: 20
Loss: 0.47787535556203065
ROC train: 0.731246	val: 0.594399	test: 0.598248
PRC train: 0.708332	val: 0.654142	test: 0.620604

Epoch: 21
Loss: 0.4753650988265377
ROC train: 0.739099	val: 0.589413	test: 0.598123
PRC train: 0.712346	val: 0.650694	test: 0.622169

Epoch: 22
Loss: 0.4678749993556149
ROC train: 0.745726	val: 0.595415	test: 0.601999
PRC train: 0.718405	val: 0.652979	test: 0.623392

Epoch: 23
Loss: 0.4685783878653053
ROC train: 0.748934	val: 0.602640	test: 0.599688
PRC train: 0.722928	val: 0.657427	test: 0.622893

Epoch: 24
Loss: 0.46525460828595194
ROC train: 0.749191	val: 0.592164	test: 0.599820
PRC train: 0.723976	val: 0.654117	test: 0.622799

Epoch: 25
Loss: 0.46627134446948054
ROC train: 0.750936	val: 0.588351	test: 0.598270
PRC train: 0.722608	val: 0.653868	test: 0.624415

Epoch: 26
Loss: 0.45948544627707355
ROC train: 0.757810	val: 0.599338	test: 0.597582
PRC train: 0.730140	val: 0.654037	test: 0.620871

Epoch: 27
Loss: 0.4576479968665897
ROC train: 0.762515	val: 0.592885	test: 0.603175
PRC train: 0.733263	val: 0.652405	test: 0.625005

Epoch: 28
Loss: 0.45479222384667783
ROC train: 0.764101	val: 0.591928	test: 0.600557
PRC train: 0.736156	val: 0.651974	test: 0.623394

Epoch: 29
Loss: 0.45665995390803854
ROC train: 0.770817	val: 0.601496	test: 0.595969
PRC train: 0.740984	val: 0.656658	test: 0.621335

Epoch: 30
Loss: 0.45351103812155247
ROC train: 0.773607	val: 0.601234	test: 0.598476
PRC train: 0.742171	val: 0.656575	test: 0.622808

Epoch: 31
Loss: 0.4532311097338493
ROC train: 0.774157	val: 0.591983	test: 0.604430
PRC train: 0.742957	val: 0.654916	test: 0.622771

Epoch: 32
Loss: 0.4536641405705065
ROC train: 0.777592	val: 0.587753	test: 0.604689
PRC train: 0.745610	val: 0.652695	test: 0.624511

Epoch: 33
Loss: 0.4522445026654826Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/sider/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/sider/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/sider/scaff/train_prop=0.7/sider_scaff_4_26-05_11-13-31  ]
[ Using Seed :  4  ]
[ Using device :  cuda:1  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6872689682665183
ROC train: 0.526261	val: 0.507869	test: 0.520093
PRC train: 0.581083	val: 0.611778	test: 0.584526

Epoch: 2
Loss: 0.6545665164728386
ROC train: 0.554847	val: 0.518711	test: 0.527213
PRC train: 0.598858	val: 0.616553	test: 0.589475

Epoch: 3
Loss: 0.6268834486635694
ROC train: 0.563297	val: 0.518699	test: 0.522045
PRC train: 0.606065	val: 0.616544	test: 0.584370

Epoch: 4
Loss: 0.5994179647680637
ROC train: 0.575440	val: 0.512860	test: 0.522991
PRC train: 0.614428	val: 0.614622	test: 0.586471

Epoch: 5
Loss: 0.5810075474099652
ROC train: 0.595674	val: 0.512938	test: 0.534057
PRC train: 0.625880	val: 0.614440	test: 0.593677

Epoch: 6
Loss: 0.5635587941481643
ROC train: 0.620248	val: 0.518120	test: 0.556863
PRC train: 0.638170	val: 0.618151	test: 0.605491

Epoch: 7
Loss: 0.5511339576877354
ROC train: 0.642657	val: 0.531845	test: 0.584070
PRC train: 0.648212	val: 0.626434	test: 0.617576

Epoch: 8
Loss: 0.5389761642546771
ROC train: 0.655584	val: 0.546151	test: 0.591644
PRC train: 0.657474	val: 0.635340	test: 0.619846

Epoch: 9
Loss: 0.5309646716298343
ROC train: 0.668405	val: 0.559827	test: 0.591277
PRC train: 0.666088	val: 0.641937	test: 0.617908

Epoch: 10
Loss: 0.522393207288959
ROC train: 0.681272	val: 0.570092	test: 0.598690
PRC train: 0.673586	val: 0.644843	test: 0.622139

Epoch: 11
Loss: 0.51246177714987
ROC train: 0.689097	val: 0.578786	test: 0.603166
PRC train: 0.678978	val: 0.648125	test: 0.624395

Epoch: 12
Loss: 0.5067497151261134
ROC train: 0.696751	val: 0.582772	test: 0.606675
PRC train: 0.682861	val: 0.650423	test: 0.626773

Epoch: 13
Loss: 0.5020420250116409
ROC train: 0.703661	val: 0.588546	test: 0.603789
PRC train: 0.687511	val: 0.651872	test: 0.624740

Epoch: 14
Loss: 0.49929004840312297
ROC train: 0.712576	val: 0.589668	test: 0.602983
PRC train: 0.694587	val: 0.651492	test: 0.622748

Epoch: 15
Loss: 0.495390829363832
ROC train: 0.717588	val: 0.588293	test: 0.603156
PRC train: 0.697485	val: 0.649224	test: 0.623509

Epoch: 16
Loss: 0.48889681516582617
ROC train: 0.724439	val: 0.589852	test: 0.605663
PRC train: 0.701470	val: 0.652175	test: 0.624676

Epoch: 17
Loss: 0.48128159306720303
ROC train: 0.728539	val: 0.600020	test: 0.605901
PRC train: 0.702789	val: 0.654953	test: 0.623738

Epoch: 18
Loss: 0.48212107915500846
ROC train: 0.732823	val: 0.602948	test: 0.605900
PRC train: 0.707402	val: 0.654064	test: 0.623939

Epoch: 19
Loss: 0.47457126575388614
ROC train: 0.740380	val: 0.590756	test: 0.606521
PRC train: 0.715572	val: 0.646980	test: 0.623296

Epoch: 20
Loss: 0.4800181138561932
ROC train: 0.746460	val: 0.577684	test: 0.614275
PRC train: 0.721552	val: 0.645291	test: 0.627918

Epoch: 21
Loss: 0.4709389401006769
ROC train: 0.744269	val: 0.570587	test: 0.617249
PRC train: 0.717734	val: 0.646834	test: 0.633389

Epoch: 22
Loss: 0.46649330007077794
ROC train: 0.754116	val: 0.591641	test: 0.608612
PRC train: 0.725066	val: 0.650938	test: 0.625780

Epoch: 23
Loss: 0.46515409629847165
ROC train: 0.759499	val: 0.596411	test: 0.603876
PRC train: 0.730017	val: 0.651457	test: 0.622349

Epoch: 24
Loss: 0.4659622833439302
ROC train: 0.761194	val: 0.581200	test: 0.611131
PRC train: 0.732276	val: 0.646493	test: 0.625338

Epoch: 25
Loss: 0.45909718808322764
ROC train: 0.764934	val: 0.575700	test: 0.612958
PRC train: 0.735063	val: 0.644566	test: 0.625100

Epoch: 26
Loss: 0.4607308489360636
ROC train: 0.766029	val: 0.584314	test: 0.607580
PRC train: 0.736530	val: 0.645711	test: 0.623199

Epoch: 27
Loss: 0.4589778481603881
ROC train: 0.776073	val: 0.585874	test: 0.609795
PRC train: 0.742983	val: 0.648643	test: 0.624350

Epoch: 28
Loss: 0.45608355700802805
ROC train: 0.774151	val: 0.586451	test: 0.613648
PRC train: 0.741627	val: 0.649613	test: 0.627396

Epoch: 29
Loss: 0.4531993949939541
ROC train: 0.779156	val: 0.586706	test: 0.610315
PRC train: 0.746514	val: 0.648583	test: 0.625523

Epoch: 30
Loss: 0.45299708802159755
ROC train: 0.784258	val: 0.579539	test: 0.614536
PRC train: 0.748996	val: 0.645589	test: 0.625794

Epoch: 31
Loss: 0.4496879688726156
ROC train: 0.778904	val: 0.574758	test: 0.614620
PRC train: 0.743376	val: 0.645515	test: 0.632247

Epoch: 32
Loss: 0.44748589071750067
ROC train: 0.786915	val: 0.578538	test: 0.616528
PRC train: 0.751182	val: 0.652340	test: 0.632097

Epoch: 33
Loss: 0.4467087506536701Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/sider/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/sider/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/sider/scaff/train_prop=0.7/sider_scaff_6_26-05_11-13-31  ]
[ Using Seed :  6  ]
[ Using device :  cuda:1  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6895469309093386
ROC train: 0.526562	val: 0.502736	test: 0.520376
PRC train: 0.574929	val: 0.610670	test: 0.590456

Epoch: 2
Loss: 0.6583049966460477
ROC train: 0.548603	val: 0.506455	test: 0.522867
PRC train: 0.591196	val: 0.623247	test: 0.590437

Epoch: 3
Loss: 0.6286304324492135
ROC train: 0.565385	val: 0.502587	test: 0.518442
PRC train: 0.602781	val: 0.614887	test: 0.587206

Epoch: 4
Loss: 0.6065043365550058
ROC train: 0.581375	val: 0.497904	test: 0.517646
PRC train: 0.613185	val: 0.609502	test: 0.587552

Epoch: 5
Loss: 0.5810237992475635
ROC train: 0.601874	val: 0.502606	test: 0.530366
PRC train: 0.626050	val: 0.610684	test: 0.593199

Epoch: 6
Loss: 0.5692094574029654
ROC train: 0.624479	val: 0.513173	test: 0.558082
PRC train: 0.638312	val: 0.616318	test: 0.605832

Epoch: 7
Loss: 0.5514888567804658
ROC train: 0.643562	val: 0.527549	test: 0.585694
PRC train: 0.648780	val: 0.626439	test: 0.617552

Epoch: 8
Loss: 0.5381372929437207
ROC train: 0.657899	val: 0.545008	test: 0.601357
PRC train: 0.657255	val: 0.633081	test: 0.623253

Epoch: 9
Loss: 0.5347724445499408
ROC train: 0.670108	val: 0.557816	test: 0.604286
PRC train: 0.665092	val: 0.640341	test: 0.623772

Epoch: 10
Loss: 0.5229219536176746
ROC train: 0.682493	val: 0.564182	test: 0.603480
PRC train: 0.673765	val: 0.644345	test: 0.621790

Epoch: 11
Loss: 0.515618916992743
ROC train: 0.684508	val: 0.565196	test: 0.598208
PRC train: 0.676575	val: 0.642608	test: 0.619746

Epoch: 12
Loss: 0.5120462028201347
ROC train: 0.693641	val: 0.573925	test: 0.605822
PRC train: 0.682090	val: 0.648467	test: 0.623104

Epoch: 13
Loss: 0.5058344209989648
ROC train: 0.697282	val: 0.579386	test: 0.608588
PRC train: 0.684312	val: 0.649831	test: 0.624346

Epoch: 14
Loss: 0.4977548839727859
ROC train: 0.704844	val: 0.577892	test: 0.607046
PRC train: 0.689711	val: 0.649560	test: 0.624601

Epoch: 15
Loss: 0.49149011331618137
ROC train: 0.710920	val: 0.575471	test: 0.605607
PRC train: 0.694172	val: 0.647187	test: 0.623071

Epoch: 16
Loss: 0.489989748260772
ROC train: 0.720485	val: 0.580397	test: 0.609810
PRC train: 0.700528	val: 0.648308	test: 0.622505

Epoch: 17
Loss: 0.48427518864517005
ROC train: 0.726774	val: 0.583653	test: 0.611992
PRC train: 0.705404	val: 0.650223	test: 0.622397

Epoch: 18
Loss: 0.48161820961721646
ROC train: 0.731489	val: 0.582149	test: 0.606254
PRC train: 0.709805	val: 0.648828	test: 0.619331

Epoch: 19
Loss: 0.47855778552341033
ROC train: 0.738215	val: 0.583785	test: 0.607230
PRC train: 0.713688	val: 0.648541	test: 0.621413

Epoch: 20
Loss: 0.4769194492267041
ROC train: 0.740655	val: 0.582836	test: 0.611775
PRC train: 0.714373	val: 0.649569	test: 0.626122

Epoch: 21
Loss: 0.4723356856939982
ROC train: 0.747110	val: 0.585841	test: 0.613463
PRC train: 0.721091	val: 0.649127	test: 0.624288

Epoch: 22
Loss: 0.47049464035835564
ROC train: 0.745964	val: 0.582597	test: 0.608510
PRC train: 0.721259	val: 0.648046	test: 0.621744

Epoch: 23
Loss: 0.46831898929762755
ROC train: 0.752568	val: 0.578433	test: 0.610006
PRC train: 0.723115	val: 0.649190	test: 0.625140

Epoch: 24
Loss: 0.4627896880612797
ROC train: 0.757890	val: 0.578131	test: 0.612768
PRC train: 0.728821	val: 0.647240	test: 0.624035

Epoch: 25
Loss: 0.46230589745974976
ROC train: 0.763601	val: 0.586725	test: 0.617425
PRC train: 0.735342	val: 0.649819	test: 0.624667

Epoch: 26
Loss: 0.46268514659196047
ROC train: 0.767351	val: 0.590783	test: 0.617395
PRC train: 0.737984	val: 0.650422	test: 0.624838

Epoch: 27
Loss: 0.4571024431975711
ROC train: 0.770855	val: 0.585033	test: 0.613398
PRC train: 0.737836	val: 0.650202	test: 0.624540

Epoch: 28
Loss: 0.45735677005443504
ROC train: 0.771644	val: 0.576766	test: 0.609346
PRC train: 0.739081	val: 0.649220	test: 0.624074

Epoch: 29
Loss: 0.4556630328176571
ROC train: 0.776077	val: 0.574446	test: 0.611780
PRC train: 0.745103	val: 0.646967	test: 0.624356

Epoch: 30
Loss: 0.4476356002551699
ROC train: 0.779625	val: 0.574816	test: 0.613104
PRC train: 0.746962	val: 0.645700	test: 0.626578

Epoch: 31
Loss: 0.4522891464590412
ROC train: 0.781561	val: 0.570203	test: 0.613101
PRC train: 0.748486	val: 0.645282	test: 0.626370

Epoch: 32
Loss: 0.449189909925957
ROC train: 0.786116	val: 0.569657	test: 0.609912
PRC train: 0.752486	val: 0.645368	test: 0.622618

Epoch: 33
Loss: 0.4483500300326263Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/sider/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/sider/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/sider/scaff/train_prop=0.8/sider_scaff_6_26-05_11-13-31  ]
[ Using Seed :  6  ]
[ Using device :  cuda:2  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6859446071021369
ROC train: 0.529605	val: 0.520903	test: 0.506435
PRC train: 0.579506	val: 0.610383	test: 0.596199

Epoch: 2
Loss: 0.6502736178981614
ROC train: 0.551240	val: 0.512832	test: 0.513757
PRC train: 0.595311	val: 0.605572	test: 0.594306

Epoch: 3
Loss: 0.6142090992837679
ROC train: 0.573413	val: 0.505301	test: 0.526645
PRC train: 0.607448	val: 0.601787	test: 0.600478

Epoch: 4
Loss: 0.5855916315103521
ROC train: 0.594183	val: 0.509476	test: 0.539531
PRC train: 0.619366	val: 0.603904	test: 0.607003

Epoch: 5
Loss: 0.5655715632211884
ROC train: 0.618727	val: 0.534735	test: 0.559462
PRC train: 0.635353	val: 0.617446	test: 0.612995

Epoch: 6
Loss: 0.5500734805599758
ROC train: 0.644056	val: 0.573000	test: 0.593924
PRC train: 0.647946	val: 0.633851	test: 0.624201

Epoch: 7
Loss: 0.541958245803473
ROC train: 0.659491	val: 0.578292	test: 0.604971
PRC train: 0.658726	val: 0.636694	test: 0.625851

Epoch: 8
Loss: 0.5266178424661925
ROC train: 0.672876	val: 0.582453	test: 0.608727
PRC train: 0.666705	val: 0.640391	test: 0.628687

Epoch: 9
Loss: 0.518710546383873
ROC train: 0.681425	val: 0.591988	test: 0.601567
PRC train: 0.671934	val: 0.644294	test: 0.626759

Epoch: 10
Loss: 0.5119277315763555
ROC train: 0.685750	val: 0.601365	test: 0.599123
PRC train: 0.675801	val: 0.646172	test: 0.625464

Epoch: 11
Loss: 0.5042022100001944
ROC train: 0.692054	val: 0.608546	test: 0.597365
PRC train: 0.680804	val: 0.649775	test: 0.623247

Epoch: 12
Loss: 0.4970383946534168
ROC train: 0.701757	val: 0.607989	test: 0.603588
PRC train: 0.686074	val: 0.648491	test: 0.623746

Epoch: 13
Loss: 0.4932443957066651
ROC train: 0.707293	val: 0.599620	test: 0.601112
PRC train: 0.690780	val: 0.646554	test: 0.623733

Epoch: 14
Loss: 0.4902496928397371
ROC train: 0.713249	val: 0.598040	test: 0.604274
PRC train: 0.694794	val: 0.647093	test: 0.624874

Epoch: 15
Loss: 0.4854300163743643
ROC train: 0.716273	val: 0.588727	test: 0.610018
PRC train: 0.697121	val: 0.644405	test: 0.628582

Epoch: 16
Loss: 0.4802203482176616
ROC train: 0.720696	val: 0.613422	test: 0.601296
PRC train: 0.700965	val: 0.655852	test: 0.625159

Epoch: 17
Loss: 0.4789604738781222
ROC train: 0.728228	val: 0.607277	test: 0.609629
PRC train: 0.705959	val: 0.653369	test: 0.626854

Epoch: 18
Loss: 0.47795722799836254
ROC train: 0.729415	val: 0.599811	test: 0.609133
PRC train: 0.707332	val: 0.652045	test: 0.627613

Epoch: 19
Loss: 0.4717728568566043
ROC train: 0.735247	val: 0.603862	test: 0.609725
PRC train: 0.712846	val: 0.654282	test: 0.626466

Epoch: 20
Loss: 0.47125241774754034
ROC train: 0.731563	val: 0.607499	test: 0.609166
PRC train: 0.710704	val: 0.656404	test: 0.626920

Epoch: 21
Loss: 0.4675149537262578
ROC train: 0.741084	val: 0.602280	test: 0.618352
PRC train: 0.718950	val: 0.650490	test: 0.634250

Epoch: 22
Loss: 0.462943587354055
ROC train: 0.748591	val: 0.608703	test: 0.618098
PRC train: 0.723374	val: 0.653042	test: 0.627699

Epoch: 23
Loss: 0.4640264528175049
ROC train: 0.753056	val: 0.606037	test: 0.619489
PRC train: 0.726169	val: 0.652727	test: 0.629381

Epoch: 24
Loss: 0.4639432332026562
ROC train: 0.753300	val: 0.601584	test: 0.621856
PRC train: 0.728147	val: 0.651141	test: 0.633921

Epoch: 25
Loss: 0.4665960781578077
ROC train: 0.755578	val: 0.606276	test: 0.614262
PRC train: 0.729784	val: 0.654087	test: 0.631449

Epoch: 26
Loss: 0.4598227655095194
ROC train: 0.757422	val: 0.613767	test: 0.613240
PRC train: 0.728720	val: 0.657484	test: 0.630283

Epoch: 27
Loss: 0.4592589108140913
ROC train: 0.765470	val: 0.612571	test: 0.620195
PRC train: 0.739467	val: 0.656280	test: 0.633780

Epoch: 28
Loss: 0.4592883252186931
ROC train: 0.764287	val: 0.601393	test: 0.616797
PRC train: 0.740213	val: 0.651639	test: 0.634367

Epoch: 29
Loss: 0.4565445204670236
ROC train: 0.767697	val: 0.606721	test: 0.624236
PRC train: 0.742774	val: 0.652628	test: 0.635299

Epoch: 30
Loss: 0.453656704720441
ROC train: 0.771622	val: 0.602564	test: 0.629623
PRC train: 0.747128	val: 0.651626	test: 0.637609

Epoch: 31
Loss: 0.45357413028929994
ROC train: 0.776999	val: 0.604713	test: 0.617227
PRC train: 0.748670	val: 0.653635	test: 0.631600

Epoch: 32
Loss: 0.44852503395753995
ROC train: 0.777580	val: 0.614240	test: 0.619586
PRC train: 0.748857	val: 0.656475	test: 0.631394

Epoch: 33
Loss: 0.4461723570699318Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/sider/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/sider/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/sider/scaff/train_prop=0.8/sider_scaff_4_26-05_11-13-31  ]
[ Using Seed :  4  ]
[ Using device :  cuda:2  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6835653400430666
ROC train: 0.532263	val: 0.526422	test: 0.497913
PRC train: 0.585948	val: 0.614650	test: 0.584264

Epoch: 2
Loss: 0.6442384954583125
ROC train: 0.558129	val: 0.516998	test: 0.511281
PRC train: 0.602606	val: 0.607429	test: 0.592911

Epoch: 3
Loss: 0.6103294308198292
ROC train: 0.569384	val: 0.505027	test: 0.521947
PRC train: 0.609897	val: 0.601225	test: 0.596729

Epoch: 4
Loss: 0.5836344099573731
ROC train: 0.591346	val: 0.511627	test: 0.528590
PRC train: 0.621867	val: 0.604848	test: 0.600166

Epoch: 5
Loss: 0.5632085398953677
ROC train: 0.619275	val: 0.540700	test: 0.550060
PRC train: 0.636162	val: 0.623584	test: 0.607094

Epoch: 6
Loss: 0.551798446585607
ROC train: 0.641301	val: 0.562907	test: 0.563684
PRC train: 0.647712	val: 0.633824	test: 0.617018

Epoch: 7
Loss: 0.5395869606526176
ROC train: 0.656783	val: 0.575755	test: 0.580302
PRC train: 0.657887	val: 0.638627	test: 0.624743

Epoch: 8
Loss: 0.5246848095071387
ROC train: 0.670568	val: 0.582238	test: 0.590682
PRC train: 0.667655	val: 0.642086	test: 0.624271

Epoch: 9
Loss: 0.51541891394708
ROC train: 0.674867	val: 0.581139	test: 0.581560
PRC train: 0.671193	val: 0.641459	test: 0.621072

Epoch: 10
Loss: 0.5082521648422318
ROC train: 0.687052	val: 0.590712	test: 0.592969
PRC train: 0.676727	val: 0.644247	test: 0.624895

Epoch: 11
Loss: 0.5037352916553337
ROC train: 0.701112	val: 0.608734	test: 0.599681
PRC train: 0.684452	val: 0.651065	test: 0.623105

Epoch: 12
Loss: 0.4991706805897853
ROC train: 0.704949	val: 0.596804	test: 0.592914
PRC train: 0.687577	val: 0.645462	test: 0.618706

Epoch: 13
Loss: 0.4881783739817143
ROC train: 0.709439	val: 0.596884	test: 0.594390
PRC train: 0.693113	val: 0.648751	test: 0.620222

Epoch: 14
Loss: 0.4885360226106611
ROC train: 0.715462	val: 0.605964	test: 0.593161
PRC train: 0.697766	val: 0.652814	test: 0.620529

Epoch: 15
Loss: 0.4855126030046669
ROC train: 0.721233	val: 0.609410	test: 0.597706
PRC train: 0.701878	val: 0.654376	test: 0.623259

Epoch: 16
Loss: 0.4804413213243447
ROC train: 0.724553	val: 0.604456	test: 0.593145
PRC train: 0.704022	val: 0.653701	test: 0.621738

Epoch: 17
Loss: 0.4735544196093734
ROC train: 0.729623	val: 0.599584	test: 0.599933
PRC train: 0.707153	val: 0.652663	test: 0.622437

Epoch: 18
Loss: 0.4755824930929258
ROC train: 0.735600	val: 0.601510	test: 0.609853
PRC train: 0.711262	val: 0.651005	test: 0.628004

Epoch: 19
Loss: 0.47414869600325105
ROC train: 0.739213	val: 0.606773	test: 0.614953
PRC train: 0.712948	val: 0.654328	test: 0.629468

Epoch: 20
Loss: 0.4692469733316223
ROC train: 0.741307	val: 0.607860	test: 0.614756
PRC train: 0.717234	val: 0.654342	test: 0.634193

Epoch: 21
Loss: 0.47095179410399285
ROC train: 0.741496	val: 0.606957	test: 0.612446
PRC train: 0.721756	val: 0.653701	test: 0.635706

Epoch: 22
Loss: 0.4695649987017325
ROC train: 0.747834	val: 0.621301	test: 0.614223
PRC train: 0.723601	val: 0.663704	test: 0.632582

Epoch: 23
Loss: 0.46664495578698684
ROC train: 0.751766	val: 0.607907	test: 0.612461
PRC train: 0.726321	val: 0.657335	test: 0.637710

Epoch: 24
Loss: 0.46438851257445624
ROC train: 0.750400	val: 0.603274	test: 0.607609
PRC train: 0.728234	val: 0.655873	test: 0.634333

Epoch: 25
Loss: 0.4603336813876898
ROC train: 0.756682	val: 0.612508	test: 0.609613
PRC train: 0.732091	val: 0.661608	test: 0.629044

Epoch: 26
Loss: 0.46416999595882513
ROC train: 0.760680	val: 0.616041	test: 0.608673
PRC train: 0.734589	val: 0.665393	test: 0.631527

Epoch: 27
Loss: 0.4611415782977827
ROC train: 0.763572	val: 0.616041	test: 0.606753
PRC train: 0.735733	val: 0.664553	test: 0.628651

Epoch: 28
Loss: 0.4592226313250737
ROC train: 0.762576	val: 0.618417	test: 0.613056
PRC train: 0.735299	val: 0.663073	test: 0.632859

Epoch: 29
Loss: 0.4568568413434989
ROC train: 0.763732	val: 0.611594	test: 0.614571
PRC train: 0.734635	val: 0.661893	test: 0.637926

Epoch: 30
Loss: 0.45547108421432847
ROC train: 0.771663	val: 0.613987	test: 0.609430
PRC train: 0.741980	val: 0.663729	test: 0.636857

Epoch: 31
Loss: 0.457496466612746
ROC train: 0.770395	val: 0.608502	test: 0.619473
PRC train: 0.744101	val: 0.663966	test: 0.637752

Epoch: 32
Loss: 0.4511717137347211
ROC train: 0.775493	val: 0.617886	test: 0.612859
PRC train: 0.746240	val: 0.664968	test: 0.637921

Epoch: 33
Loss: 0.44614770694530204Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/sider/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/sider/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/sider/scaff/train_prop=0.8/sider_scaff_5_26-05_11-13-31  ]
[ Using Seed :  5  ]
[ Using device :  cuda:2  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6859732102183317
ROC train: 0.528346	val: 0.491905	test: 0.492869
PRC train: 0.575483	val: 0.600101	test: 0.579897

Epoch: 2
Loss: 0.6460577924162046
ROC train: 0.557044	val: 0.497411	test: 0.515171
PRC train: 0.597486	val: 0.604213	test: 0.588453

Epoch: 3
Loss: 0.6115454624554522
ROC train: 0.575056	val: 0.495512	test: 0.533768
PRC train: 0.610600	val: 0.600377	test: 0.596316

Epoch: 4
Loss: 0.584952224303912
ROC train: 0.596913	val: 0.505785	test: 0.543850
PRC train: 0.622051	val: 0.605678	test: 0.604992

Epoch: 5
Loss: 0.5629732970293456
ROC train: 0.621652	val: 0.540275	test: 0.564048
PRC train: 0.636870	val: 0.621765	test: 0.610107

Epoch: 6
Loss: 0.5469087442400017
ROC train: 0.639956	val: 0.560131	test: 0.580667
PRC train: 0.645090	val: 0.632205	test: 0.613053

Epoch: 7
Loss: 0.5348654175733148
ROC train: 0.654236	val: 0.569540	test: 0.586132
PRC train: 0.656273	val: 0.636316	test: 0.616103

Epoch: 8
Loss: 0.5256541502970108
ROC train: 0.662247	val: 0.572947	test: 0.591185
PRC train: 0.662596	val: 0.637325	test: 0.619121

Epoch: 9
Loss: 0.5186391094754667
ROC train: 0.674769	val: 0.583360	test: 0.598779
PRC train: 0.669327	val: 0.641620	test: 0.622315

Epoch: 10
Loss: 0.5128441661759421
ROC train: 0.681919	val: 0.585742	test: 0.593384
PRC train: 0.674308	val: 0.641099	test: 0.619274

Epoch: 11
Loss: 0.5044943677734519
ROC train: 0.694131	val: 0.594368	test: 0.596598
PRC train: 0.678957	val: 0.645064	test: 0.621869

Epoch: 12
Loss: 0.4984343568504118
ROC train: 0.700583	val: 0.605406	test: 0.604068
PRC train: 0.683508	val: 0.650575	test: 0.626281

Epoch: 13
Loss: 0.4943643126421627
ROC train: 0.702246	val: 0.604857	test: 0.595007
PRC train: 0.685800	val: 0.649933	test: 0.623839

Epoch: 14
Loss: 0.4882768459222403
ROC train: 0.709648	val: 0.613461	test: 0.598815
PRC train: 0.691146	val: 0.653451	test: 0.625420

Epoch: 15
Loss: 0.48907611139138113
ROC train: 0.719439	val: 0.610449	test: 0.609148
PRC train: 0.698009	val: 0.652754	test: 0.629824

Epoch: 16
Loss: 0.48571766002892913
ROC train: 0.718539	val: 0.597613	test: 0.605930
PRC train: 0.699261	val: 0.649424	test: 0.628207

Epoch: 17
Loss: 0.4775572806695868
ROC train: 0.724557	val: 0.615260	test: 0.604077
PRC train: 0.701158	val: 0.655521	test: 0.628830

Epoch: 18
Loss: 0.47519837025774103
ROC train: 0.730094	val: 0.614430	test: 0.599620
PRC train: 0.708118	val: 0.656204	test: 0.623948

Epoch: 19
Loss: 0.4686796487449662
ROC train: 0.732389	val: 0.606149	test: 0.599686
PRC train: 0.710673	val: 0.653368	test: 0.623880

Epoch: 20
Loss: 0.47452917411902157
ROC train: 0.737373	val: 0.605858	test: 0.603213
PRC train: 0.713797	val: 0.654073	test: 0.628852

Epoch: 21
Loss: 0.46864483296325526
ROC train: 0.743531	val: 0.608256	test: 0.609097
PRC train: 0.720067	val: 0.656009	test: 0.627590

Epoch: 22
Loss: 0.46796179713305125
ROC train: 0.736610	val: 0.599344	test: 0.605361
PRC train: 0.718691	val: 0.653665	test: 0.628705

Epoch: 23
Loss: 0.4698795196720379
ROC train: 0.749422	val: 0.614235	test: 0.605540
PRC train: 0.724559	val: 0.660226	test: 0.631732

Epoch: 24
Loss: 0.46444853484514825
ROC train: 0.751354	val: 0.618788	test: 0.603688
PRC train: 0.725989	val: 0.659154	test: 0.628735

Epoch: 25
Loss: 0.46393037736665316
ROC train: 0.752265	val: 0.602322	test: 0.609781
PRC train: 0.729263	val: 0.651504	test: 0.628327

Epoch: 26
Loss: 0.4610051629901456
ROC train: 0.756107	val: 0.595781	test: 0.608449
PRC train: 0.731406	val: 0.649705	test: 0.631676

Epoch: 27
Loss: 0.4613252536629434
ROC train: 0.760426	val: 0.599685	test: 0.609036
PRC train: 0.734050	val: 0.652204	test: 0.629893

Epoch: 28
Loss: 0.45791090896414044
ROC train: 0.760772	val: 0.593763	test: 0.608069
PRC train: 0.733502	val: 0.654192	test: 0.632662

Epoch: 29
Loss: 0.4563975203574396
ROC train: 0.764085	val: 0.600900	test: 0.595165
PRC train: 0.737001	val: 0.653915	test: 0.625621

Epoch: 30
Loss: 0.4538879205592926
ROC train: 0.768309	val: 0.597952	test: 0.599752
PRC train: 0.740232	val: 0.651150	test: 0.626685

Epoch: 31
Loss: 0.4519853009054217
ROC train: 0.770957	val: 0.594523	test: 0.609635
PRC train: 0.741507	val: 0.652410	test: 0.625301

Epoch: 32
Loss: 0.4527069295125076
ROC train: 0.770361	val: 0.592906	test: 0.602846
PRC train: 0.742789	val: 0.651334	test: 0.622526

Epoch: 33
Loss: 0.45220422165879787
ROC train: 0.787988	val: 0.556529	test: 0.592026
PRC train: 0.745272	val: 0.628229	test: 0.632961

Epoch: 34
Loss: 0.4404273325312813
ROC train: 0.783620	val: 0.553632	test: 0.590500
PRC train: 0.744084	val: 0.627673	test: 0.630127

Epoch: 35
Loss: 0.43946043306935606
ROC train: 0.786420	val: 0.564049	test: 0.590690
PRC train: 0.747046	val: 0.636661	test: 0.627580

Epoch: 36
Loss: 0.4376778293998617
ROC train: 0.790459	val: 0.562006	test: 0.588455
PRC train: 0.749522	val: 0.635711	test: 0.629301

Epoch: 37
Loss: 0.43738677383911306
ROC train: 0.794281	val: 0.559130	test: 0.588910
PRC train: 0.751193	val: 0.631158	test: 0.631220

Epoch: 38
Loss: 0.442196999988043
ROC train: 0.798974	val: 0.551606	test: 0.587074
PRC train: 0.755758	val: 0.623914	test: 0.629086

Epoch: 39
Loss: 0.4402156730405341
ROC train: 0.801572	val: 0.544247	test: 0.587887
PRC train: 0.757707	val: 0.624357	test: 0.627537

Epoch: 40
Loss: 0.43249374339695557
ROC train: 0.798076	val: 0.549435	test: 0.582560
PRC train: 0.754986	val: 0.627722	test: 0.625671

Epoch: 41
Loss: 0.43672932254516217
ROC train: 0.807287	val: 0.555483	test: 0.590614
PRC train: 0.761912	val: 0.634309	test: 0.632265

Epoch: 42
Loss: 0.43451679316245384
ROC train: 0.809611	val: 0.552037	test: 0.592148
PRC train: 0.763888	val: 0.632527	test: 0.632983

Epoch: 43
Loss: 0.42999692567897296
ROC train: 0.807824	val: 0.544891	test: 0.587959
PRC train: 0.763643	val: 0.626737	test: 0.630718

Epoch: 44
Loss: 0.425639385309735
ROC train: 0.811693	val: 0.544770	test: 0.588736
PRC train: 0.766604	val: 0.624066	test: 0.629395

Epoch: 45
Loss: 0.4243323309290972
ROC train: 0.812151	val: 0.546987	test: 0.586649
PRC train: 0.768741	val: 0.623638	test: 0.628539

Epoch: 46
Loss: 0.4313033386864941
ROC train: 0.817764	val: 0.546124	test: 0.582325
PRC train: 0.773020	val: 0.625098	test: 0.628753

Epoch: 47
Loss: 0.4346961684589767
ROC train: 0.820573	val: 0.555743	test: 0.588913
PRC train: 0.775692	val: 0.630218	test: 0.631571

Epoch: 48
Loss: 0.42112975144854115
ROC train: 0.820197	val: 0.559030	test: 0.590618
PRC train: 0.774348	val: 0.632162	test: 0.633604

Epoch: 49
Loss: 0.42380053389413536
ROC train: 0.818891	val: 0.555809	test: 0.592203
PRC train: 0.772052	val: 0.629549	test: 0.633934

Epoch: 50
Loss: 0.4289973355120903
ROC train: 0.825550	val: 0.555339	test: 0.589823
PRC train: 0.776285	val: 0.629757	test: 0.633073

Epoch: 51
Loss: 0.43232784407425945
ROC train: 0.821443	val: 0.554207	test: 0.585945
PRC train: 0.772689	val: 0.632616	test: 0.631080

Epoch: 52
Loss: 0.42842015788423415
ROC train: 0.823011	val: 0.552319	test: 0.590493
PRC train: 0.774162	val: 0.630363	test: 0.629037

Epoch: 53
Loss: 0.4188196813490126
ROC train: 0.825100	val: 0.554022	test: 0.590108
PRC train: 0.776126	val: 0.627418	test: 0.628621

Epoch: 54
Loss: 0.4257022092682109
ROC train: 0.828110	val: 0.557967	test: 0.586540
PRC train: 0.780904	val: 0.629537	test: 0.629640

Epoch: 55
Loss: 0.4179658920960128
ROC train: 0.835035	val: 0.556052	test: 0.584330
PRC train: 0.787961	val: 0.633334	test: 0.631405

Epoch: 56
Loss: 0.4238155280392741
ROC train: 0.831240	val: 0.557397	test: 0.583406
PRC train: 0.782528	val: 0.638198	test: 0.631114

Epoch: 57
Loss: 0.4174566717189475
ROC train: 0.835275	val: 0.557130	test: 0.592955
PRC train: 0.784493	val: 0.636249	test: 0.637048

Epoch: 58
Loss: 0.41269860376651707
ROC train: 0.829034	val: 0.546293	test: 0.591724
PRC train: 0.776652	val: 0.624061	test: 0.633208

Epoch: 59
Loss: 0.4132201751168545
ROC train: 0.840255	val: 0.547111	test: 0.594479
PRC train: 0.790709	val: 0.625859	test: 0.634185

Epoch: 60
Loss: 0.4091668844207163
ROC train: 0.836803	val: 0.541889	test: 0.592120
PRC train: 0.790044	val: 0.622718	test: 0.632235

Epoch: 61
Loss: 0.41162018384586857
ROC train: 0.836667	val: 0.543139	test: 0.589004
PRC train: 0.788781	val: 0.622151	test: 0.630032

Epoch: 62
Loss: 0.4058344077172913
ROC train: 0.840587	val: 0.557728	test: 0.583029
PRC train: 0.793614	val: 0.630316	test: 0.629245

Epoch: 63
Loss: 0.41017102469601135
ROC train: 0.841748	val: 0.570608	test: 0.579374
PRC train: 0.793305	val: 0.641823	test: 0.628526

Epoch: 64
Loss: 0.4132446978363969
ROC train: 0.848431	val: 0.565390	test: 0.581033
PRC train: 0.797381	val: 0.637819	test: 0.631381

Epoch: 65
Loss: 0.40842291606147874
ROC train: 0.850493	val: 0.561926	test: 0.592206
PRC train: 0.799950	val: 0.635906	test: 0.636637

Epoch: 66
Loss: 0.4019345902616434
ROC train: 0.847737	val: 0.559341	test: 0.602960
PRC train: 0.798371	val: 0.635814	test: 0.642244

Epoch: 67
Loss: 0.40805501011727496
ROC train: 0.850353	val: 0.558778	test: 0.599667
PRC train: 0.800493	val: 0.635704	test: 0.640906

Epoch: 68
Loss: 0.40684288998042534
ROC train: 0.850929	val: 0.558250	test: 0.591154
PRC train: 0.799113	val: 0.632879	test: 0.635987

Epoch: 69
Loss: 0.40426875304126614
ROC train: 0.854879	val: 0.556650	test: 0.591060
PRC train: 0.802303	val: 0.634585	test: 0.635131

Epoch: 70
Loss: 0.4068590212527649
ROC train: 0.853872	val: 0.547117	test: 0.586730
PRC train: 0.803148	val: 0.631166	test: 0.632028

Epoch: 71
Loss: 0.4103932922365009
ROC train: 0.852922	val: 0.549439	test: 0.586226
PRC train: 0.800491	val: 0.632546	test: 0.630510

Epoch: 72
Loss: 0.3988253605331272
ROC train: 0.852434	val: 0.556125	test: 0.584769
PRC train: 0.799708	val: 0.635850	test: 0.635504

Epoch: 73
Loss: 0.3949450028939655
ROC train: 0.851616	val: 0.565364	test: 0.587465
PRC train: 0.800613	val: 0.640029	test: 0.639694

Epoch: 74
Loss: 0.4023088524808262
ROC train: 0.860882	val: 0.558085	test: 0.584136
PRC train: 0.806644	val: 0.633791	test: 0.636208

Epoch: 75
Loss: 0.3955844649332311
ROC train: 0.859285	val: 0.555909	test: 0.586891
PRC train: 0.803860	val: 0.633192	test: 0.632101

Epoch: 76
Loss: 0.3996525848470224
ROC train: 0.860584	val: 0.558845	test: 0.595209
PRC train: 0.809128	val: 0.637602	test: 0.636703

Epoch: 77
Loss: 0.395803791314586
ROC train: 0.860839	val: 0.560428	test: 0.595913
PRC train: 0.811031	val: 0.636301	test: 0.638504

Epoch: 78
Loss: 0.39352971663674474
ROC train: 0.863954	val: 0.558730	test: 0.593140
PRC train: 0.811541	val: 0.632887	test: 0.638148

Epoch: 79
Loss: 0.3958670900812547
ROC train: 0.864049	val: 0.551523	test: 0.590914
PRC train: 0.811201	val: 0.628046	test: 0.637617

Epoch: 80
Loss: 0.39088200119080907
ROC train: 0.868033	val: 0.550695	test: 0.584732
PRC train: 0.817103	val: 0.628416	test: 0.637252

Epoch: 81
Loss: 0.3891810326010683
ROC train: 0.870836	val: 0.565290	test: 0.583264
PRC train: 0.818621	val: 0.638992	test: 0.637364

Epoch: 82
Loss: 0.39018497401868424
ROC train: 0.868755	val: 0.566387	test: 0.582123
PRC train: 0.816508	val: 0.637901	test: 0.634116

Epoch: 83
Loss: 0.38962162219217855
ROC train: 0.867671	val: 0.555372	test: 0.581437
PRC train: 0.815076	val: 0.629003	test: 0.631005

Epoch: 84
Loss: 0.38686317644635654
ROC train: 0.870810	val: 0.557909	test: 0.595786
PRC train: 0.819232	val: 0.630969	test: 0.638614

Epoch: 85
Loss: 0.38622015367812607
ROC train: 0.871066	val: 0.557457	test: 0.598975
PRC train: 0.820076	val: 0.633298	test: 0.643168

Epoch: 86
Loss: 0.3868409300049652
ROC train: 0.872269	val: 0.553228	test: 0.601109
PRC train: 0.822599	val: 0.628225	test: 0.643924

Epoch: 87
Loss: 0.3953248658086855
ROC train: 0.874087	val: 0.551706	test: 0.597206
PRC train: 0.823012	val: 0.626743	test: 0.640628

Epoch: 88
Loss: 0.38630892955558926
ROC train: 0.870438	val: 0.551598	test: 0.582017
PRC train: 0.818831	val: 0.626492	test: 0.632416

Epoch: 89
Loss: 0.38383309795612447
ROC train: 0.874477	val: 0.567318	test: 0.576267
PRC train: 0.824438	val: 0.639354	test: 0.634247

Epoch: 90
Loss: 0.38148740337632
ROC train: 0.877571	val: 0.563199	test: 0.585147
PRC train: 0.826554	val: 0.636525	test: 0.637339

Epoch: 91
Loss: 0.3818233617955834
ROC train: 0.877092	val: 0.554884	test: 0.598911
PRC train: 0.826634	val: 0.630917	test: 0.643903

Epoch: 92
Loss: 0.38155764853203095
ROC train: 0.878809	val: 0.557039	test: 0.599602
PRC train: 0.826685	val: 0.632410	test: 0.643699

Epoch: 93
Loss: 0.38412233957771763
ROC train: 0.882991	val: 0.567578	test: 0.588872
PRC train: 0.830958	val: 0.640298	test: 0.638785

Epoch: 94
Loss: 0.3777526314067234
ROC train: 0.785958	val: 0.563123	test: 0.594406
PRC train: 0.744188	val: 0.628830	test: 0.632497

Epoch: 34
Loss: 0.44997261410382783
ROC train: 0.792528	val: 0.562337	test: 0.601471
PRC train: 0.749360	val: 0.625173	test: 0.637632

Epoch: 35
Loss: 0.44452255164897214
ROC train: 0.785284	val: 0.547420	test: 0.597457
PRC train: 0.742988	val: 0.616322	test: 0.636261

Epoch: 36
Loss: 0.44719568099254703
ROC train: 0.792321	val: 0.550545	test: 0.591062
PRC train: 0.747820	val: 0.616706	test: 0.630570

Epoch: 37
Loss: 0.43561102388569417
ROC train: 0.802621	val: 0.570801	test: 0.596411
PRC train: 0.757788	val: 0.629610	test: 0.633023

Epoch: 38
Loss: 0.4364235435746027
ROC train: 0.800731	val: 0.575333	test: 0.597596
PRC train: 0.757318	val: 0.632128	test: 0.634884

Epoch: 39
Loss: 0.44049339013726374
ROC train: 0.805384	val: 0.565809	test: 0.597262
PRC train: 0.761064	val: 0.626392	test: 0.635100

Epoch: 40
Loss: 0.4385031478346744
ROC train: 0.810227	val: 0.564303	test: 0.593916
PRC train: 0.764077	val: 0.625797	test: 0.632444

Epoch: 41
Loss: 0.43111451164238057
ROC train: 0.811575	val: 0.567896	test: 0.596796
PRC train: 0.763871	val: 0.629344	test: 0.632901

Epoch: 42
Loss: 0.4413391601301488
ROC train: 0.810101	val: 0.576052	test: 0.600261
PRC train: 0.761304	val: 0.634771	test: 0.634929

Epoch: 43
Loss: 0.4275696623142811
ROC train: 0.812926	val: 0.572375	test: 0.606314
PRC train: 0.765641	val: 0.631491	test: 0.636090

Epoch: 44
Loss: 0.4288918530938973
ROC train: 0.813734	val: 0.564860	test: 0.602056
PRC train: 0.768948	val: 0.627098	test: 0.634271

Epoch: 45
Loss: 0.4303319626541604
ROC train: 0.819591	val: 0.557523	test: 0.593828
PRC train: 0.773094	val: 0.623288	test: 0.627868

Epoch: 46
Loss: 0.4276819125774754
ROC train: 0.819504	val: 0.546971	test: 0.583968
PRC train: 0.772209	val: 0.616820	test: 0.625509

Epoch: 47
Loss: 0.4272128083153572
ROC train: 0.818772	val: 0.551412	test: 0.580316
PRC train: 0.772247	val: 0.618991	test: 0.628092

Epoch: 48
Loss: 0.42334142874000963
ROC train: 0.820343	val: 0.563290	test: 0.580924
PRC train: 0.774564	val: 0.630183	test: 0.629260

Epoch: 49
Loss: 0.41745405895265014
ROC train: 0.824993	val: 0.562888	test: 0.587137
PRC train: 0.778130	val: 0.627515	test: 0.630977

Epoch: 50
Loss: 0.42138039062621674
ROC train: 0.820151	val: 0.558067	test: 0.587012
PRC train: 0.773006	val: 0.623852	test: 0.629262

Epoch: 51
Loss: 0.4291989672850379
ROC train: 0.826814	val: 0.564351	test: 0.580351
PRC train: 0.776128	val: 0.629424	test: 0.625309

Epoch: 52
Loss: 0.41967165673242607
ROC train: 0.825187	val: 0.565104	test: 0.581986
PRC train: 0.775950	val: 0.635147	test: 0.629963

Epoch: 53
Loss: 0.42546701786260754
ROC train: 0.821728	val: 0.563512	test: 0.581610
PRC train: 0.776110	val: 0.632629	test: 0.627607

Epoch: 54
Loss: 0.41747992568044023
ROC train: 0.832088	val: 0.566546	test: 0.593688
PRC train: 0.784388	val: 0.629579	test: 0.633383

Epoch: 55
Loss: 0.4207545429884709
ROC train: 0.825747	val: 0.566839	test: 0.596085
PRC train: 0.777043	val: 0.631099	test: 0.634097

Epoch: 56
Loss: 0.4134914299949383
ROC train: 0.832936	val: 0.562723	test: 0.597188
PRC train: 0.785720	val: 0.630278	test: 0.635239

Epoch: 57
Loss: 0.4109738870594832
ROC train: 0.837000	val: 0.560503	test: 0.594099
PRC train: 0.789897	val: 0.628052	test: 0.631719

Epoch: 58
Loss: 0.41698015565513813
ROC train: 0.837078	val: 0.559141	test: 0.601967
PRC train: 0.790480	val: 0.627189	test: 0.635213

Epoch: 59
Loss: 0.4147230018899499
ROC train: 0.838616	val: 0.556521	test: 0.599484
PRC train: 0.790856	val: 0.626000	test: 0.639865

Epoch: 60
Loss: 0.4187362924626826
ROC train: 0.841344	val: 0.561171	test: 0.590701
PRC train: 0.793843	val: 0.629721	test: 0.632879

Epoch: 61
Loss: 0.41492326193069157
ROC train: 0.842628	val: 0.559589	test: 0.585141
PRC train: 0.794846	val: 0.628302	test: 0.629805

Epoch: 62
Loss: 0.4108908979958664
ROC train: 0.844027	val: 0.553886	test: 0.585125
PRC train: 0.794973	val: 0.624111	test: 0.631989

Epoch: 63
Loss: 0.4088556312347201
ROC train: 0.848720	val: 0.558454	test: 0.596910
PRC train: 0.802653	val: 0.626403	test: 0.637344

Epoch: 64
Loss: 0.4044449834985342
ROC train: 0.844421	val: 0.564032	test: 0.601122
PRC train: 0.798831	val: 0.629500	test: 0.637450

Epoch: 65
Loss: 0.4035383959747009
ROC train: 0.848048	val: 0.559270	test: 0.601625
PRC train: 0.799947	val: 0.623910	test: 0.639871

Epoch: 66
Loss: 0.4027545759018346
ROC train: 0.852468	val: 0.561506	test: 0.596335
PRC train: 0.804617	val: 0.625244	test: 0.638874

Epoch: 67
Loss: 0.3974564907450513
ROC train: 0.852402	val: 0.567485	test: 0.587775
PRC train: 0.804204	val: 0.631902	test: 0.634818

Epoch: 68
Loss: 0.40313772283693844
ROC train: 0.853936	val: 0.566419	test: 0.587114
PRC train: 0.805018	val: 0.632773	test: 0.635770

Epoch: 69
Loss: 0.4055601177818813
ROC train: 0.852305	val: 0.557687	test: 0.584888
PRC train: 0.804586	val: 0.627862	test: 0.636523

Epoch: 70
Loss: 0.4087679777000231
ROC train: 0.854210	val: 0.560075	test: 0.581331
PRC train: 0.807407	val: 0.626306	test: 0.633650

Epoch: 71
Loss: 0.40179719990612073
ROC train: 0.853262	val: 0.565981	test: 0.592711
PRC train: 0.807682	val: 0.628894	test: 0.636859

Epoch: 72
Loss: 0.4082248729539354
ROC train: 0.859411	val: 0.553960	test: 0.590420
PRC train: 0.811220	val: 0.619235	test: 0.637009

Epoch: 73
Loss: 0.40530584335776226
ROC train: 0.860675	val: 0.548256	test: 0.579956
PRC train: 0.810785	val: 0.617499	test: 0.629280

Epoch: 74
Loss: 0.40131384048595836
ROC train: 0.857583	val: 0.555653	test: 0.585166
PRC train: 0.808055	val: 0.626080	test: 0.633132

Epoch: 75
Loss: 0.39068444792487833
ROC train: 0.860747	val: 0.563125	test: 0.579749
PRC train: 0.811517	val: 0.634165	test: 0.635269

Epoch: 76
Loss: 0.391333929640774
ROC train: 0.860164	val: 0.568074	test: 0.578315
PRC train: 0.812786	val: 0.636993	test: 0.633345

Epoch: 77
Loss: 0.3970965825116092
ROC train: 0.862042	val: 0.566830	test: 0.586431
PRC train: 0.812399	val: 0.631145	test: 0.632702

Epoch: 78
Loss: 0.3926095559376058
ROC train: 0.865204	val: 0.561190	test: 0.592933
PRC train: 0.816673	val: 0.626311	test: 0.636528

Epoch: 79
Loss: 0.38757534681915573
ROC train: 0.867421	val: 0.563051	test: 0.586745
PRC train: 0.817510	val: 0.630256	test: 0.635848

Epoch: 80
Loss: 0.3916347529742113
ROC train: 0.863629	val: 0.558789	test: 0.583324
PRC train: 0.815614	val: 0.630820	test: 0.633084

Epoch: 81
Loss: 0.3881721675696979
ROC train: 0.865332	val: 0.560141	test: 0.584767
PRC train: 0.818738	val: 0.630715	test: 0.636000

Epoch: 82
Loss: 0.3861892191192814
ROC train: 0.866882	val: 0.560384	test: 0.589646
PRC train: 0.818394	val: 0.628477	test: 0.638002

Epoch: 83
Loss: 0.38266716520022614
ROC train: 0.866706	val: 0.565560	test: 0.588804
PRC train: 0.817906	val: 0.630846	test: 0.638068

Epoch: 84
Loss: 0.3841279350420721
ROC train: 0.869280	val: 0.563853	test: 0.587004
PRC train: 0.820589	val: 0.629774	test: 0.636129

Epoch: 85
Loss: 0.3867131997245757
ROC train: 0.873355	val: 0.557202	test: 0.587567
PRC train: 0.824075	val: 0.626905	test: 0.636269

Epoch: 86
Loss: 0.3807329155191273
ROC train: 0.877657	val: 0.557050	test: 0.587635
PRC train: 0.827043	val: 0.625166	test: 0.635863

Epoch: 87
Loss: 0.3809725781735711
ROC train: 0.877587	val: 0.558148	test: 0.591820
PRC train: 0.828944	val: 0.626331	test: 0.635124

Epoch: 88
Loss: 0.38228845835187036
ROC train: 0.876225	val: 0.561915	test: 0.587558
PRC train: 0.829837	val: 0.631391	test: 0.631537

Epoch: 89
Loss: 0.37896697974744137
ROC train: 0.875109	val: 0.564640	test: 0.587845
PRC train: 0.827278	val: 0.630713	test: 0.633489

Epoch: 90
Loss: 0.3855324605667701
ROC train: 0.876693	val: 0.569263	test: 0.594644
PRC train: 0.827453	val: 0.632403	test: 0.639615

Epoch: 91
Loss: 0.3784832427686581
ROC train: 0.877632	val: 0.570476	test: 0.598986
PRC train: 0.828780	val: 0.634593	test: 0.644059

Epoch: 92
Loss: 0.3831280101943357
ROC train: 0.881447	val: 0.567605	test: 0.591508
PRC train: 0.835732	val: 0.631926	test: 0.639159

Epoch: 93
Loss: 0.37338210030673835
ROC train: 0.882201	val: 0.563586	test: 0.580276
PRC train: 0.838034	val: 0.629345	test: 0.632471

Epoch: 94
Loss: 0.37900469497806816
ROC train: 0.785813	val: 0.553137	test: 0.596482
PRC train: 0.746586	val: 0.630962	test: 0.632861

Epoch: 34
Loss: 0.44612103709221823
ROC train: 0.788703	val: 0.551627	test: 0.596960
PRC train: 0.750206	val: 0.627052	test: 0.632128

Epoch: 35
Loss: 0.44508404854235967
ROC train: 0.796000	val: 0.564115	test: 0.600213
PRC train: 0.756221	val: 0.634853	test: 0.635843

Epoch: 36
Loss: 0.4401583741558345
ROC train: 0.785629	val: 0.568733	test: 0.600140
PRC train: 0.748819	val: 0.641593	test: 0.634680

Epoch: 37
Loss: 0.44756685561277143
ROC train: 0.795170	val: 0.565903	test: 0.597858
PRC train: 0.756593	val: 0.638708	test: 0.635194

Epoch: 38
Loss: 0.4401153566223345
ROC train: 0.801609	val: 0.560497	test: 0.592517
PRC train: 0.761028	val: 0.630669	test: 0.633387

Epoch: 39
Loss: 0.43864490335462514
ROC train: 0.796876	val: 0.565773	test: 0.592947
PRC train: 0.757950	val: 0.635561	test: 0.631632

Epoch: 40
Loss: 0.4371322549194804
ROC train: 0.803501	val: 0.558712	test: 0.594787
PRC train: 0.762772	val: 0.632635	test: 0.632805

Epoch: 41
Loss: 0.4332837164180562
ROC train: 0.803239	val: 0.552657	test: 0.584341
PRC train: 0.761424	val: 0.627133	test: 0.631548

Epoch: 42
Loss: 0.431640496584576
ROC train: 0.807755	val: 0.556165	test: 0.587868
PRC train: 0.764934	val: 0.625755	test: 0.631679

Epoch: 43
Loss: 0.43653341661321643
ROC train: 0.800910	val: 0.567887	test: 0.598293
PRC train: 0.761410	val: 0.635007	test: 0.632690

Epoch: 44
Loss: 0.4395723021271901
ROC train: 0.810393	val: 0.562748	test: 0.595473
PRC train: 0.769350	val: 0.634508	test: 0.637229

Epoch: 45
Loss: 0.4315462792419783
ROC train: 0.813738	val: 0.560143	test: 0.590483
PRC train: 0.771241	val: 0.636613	test: 0.637100

Epoch: 46
Loss: 0.4264861401781768
ROC train: 0.817206	val: 0.561036	test: 0.591959
PRC train: 0.775160	val: 0.640299	test: 0.634165

Epoch: 47
Loss: 0.4260338196838383
ROC train: 0.819212	val: 0.555904	test: 0.594473
PRC train: 0.776542	val: 0.634923	test: 0.636597

Epoch: 48
Loss: 0.42730259615192334
ROC train: 0.823679	val: 0.555394	test: 0.594540
PRC train: 0.778935	val: 0.630309	test: 0.638657

Epoch: 49
Loss: 0.41891250145521175
ROC train: 0.825796	val: 0.565254	test: 0.596106
PRC train: 0.781108	val: 0.636824	test: 0.638398

Epoch: 50
Loss: 0.42132138837012667
ROC train: 0.824683	val: 0.570002	test: 0.598458
PRC train: 0.779738	val: 0.641401	test: 0.636917

Epoch: 51
Loss: 0.416230328419168
ROC train: 0.829613	val: 0.563797	test: 0.597119
PRC train: 0.785730	val: 0.637546	test: 0.636408

Epoch: 52
Loss: 0.4242858398146017
ROC train: 0.827895	val: 0.559345	test: 0.593841
PRC train: 0.782851	val: 0.634143	test: 0.636679

Epoch: 53
Loss: 0.4197443710446098
ROC train: 0.831663	val: 0.564190	test: 0.597943
PRC train: 0.786712	val: 0.639916	test: 0.639867

Epoch: 54
Loss: 0.42036708646351734
ROC train: 0.831179	val: 0.562773	test: 0.597515
PRC train: 0.787698	val: 0.642621	test: 0.640182

Epoch: 55
Loss: 0.4192675132033927
ROC train: 0.832070	val: 0.557258	test: 0.592320
PRC train: 0.788348	val: 0.637030	test: 0.640908

Epoch: 56
Loss: 0.4152315041601884
ROC train: 0.835936	val: 0.565675	test: 0.595779
PRC train: 0.792328	val: 0.641165	test: 0.640765

Epoch: 57
Loss: 0.4177687851184205
ROC train: 0.837874	val: 0.565681	test: 0.595959
PRC train: 0.791679	val: 0.639268	test: 0.641009

Epoch: 58
Loss: 0.41442041939276986
ROC train: 0.836746	val: 0.561060	test: 0.587597
PRC train: 0.793214	val: 0.636424	test: 0.638238

Epoch: 59
Loss: 0.4139725592383156
ROC train: 0.838885	val: 0.564246	test: 0.585028
PRC train: 0.794574	val: 0.636336	test: 0.636222

Epoch: 60
Loss: 0.411046894545095
ROC train: 0.843046	val: 0.565823	test: 0.586918
PRC train: 0.797811	val: 0.636792	test: 0.635373

Epoch: 61
Loss: 0.4023276944141051
ROC train: 0.843883	val: 0.559828	test: 0.586970
PRC train: 0.798108	val: 0.635405	test: 0.635520

Epoch: 62
Loss: 0.40693220904930044
ROC train: 0.842697	val: 0.550269	test: 0.582396
PRC train: 0.796392	val: 0.628745	test: 0.634071

Epoch: 63
Loss: 0.40952083301233316
ROC train: 0.844803	val: 0.555885	test: 0.584848
PRC train: 0.798473	val: 0.631588	test: 0.633750

Epoch: 64
Loss: 0.40697646636881424
ROC train: 0.846524	val: 0.558869	test: 0.586249
PRC train: 0.799938	val: 0.633481	test: 0.637538

Epoch: 65
Loss: 0.4110297344408852
ROC train: 0.845248	val: 0.560607	test: 0.591235
PRC train: 0.797192	val: 0.632952	test: 0.640342

Epoch: 66
Loss: 0.40656930884177955
ROC train: 0.846897	val: 0.558093	test: 0.594842
PRC train: 0.799584	val: 0.632310	test: 0.643894

Epoch: 67
Loss: 0.40174205535825114
ROC train: 0.850777	val: 0.557308	test: 0.600358
PRC train: 0.804178	val: 0.631199	test: 0.647328

Epoch: 68
Loss: 0.4083133075694084
ROC train: 0.853748	val: 0.560520	test: 0.593952
PRC train: 0.805200	val: 0.630412	test: 0.643059

Epoch: 69
Loss: 0.39897582764953243
ROC train: 0.852302	val: 0.564121	test: 0.594930
PRC train: 0.804895	val: 0.635542	test: 0.643857

Epoch: 70
Loss: 0.40179749196798964
ROC train: 0.854101	val: 0.560744	test: 0.591359
PRC train: 0.807239	val: 0.634477	test: 0.641682

Epoch: 71
Loss: 0.3995003922207643
ROC train: 0.856723	val: 0.554539	test: 0.585340
PRC train: 0.806934	val: 0.628695	test: 0.636133

Epoch: 72
Loss: 0.3961071145241529
ROC train: 0.857070	val: 0.554451	test: 0.583046
PRC train: 0.808314	val: 0.629436	test: 0.636318

Epoch: 73
Loss: 0.4015830279473619
ROC train: 0.856404	val: 0.554065	test: 0.574787
PRC train: 0.808285	val: 0.628785	test: 0.630932

Epoch: 74
Loss: 0.39534266888635305
ROC train: 0.852945	val: 0.550112	test: 0.567798
PRC train: 0.801294	val: 0.626175	test: 0.627039

Epoch: 75
Loss: 0.3904491476181433
ROC train: 0.857369	val: 0.551504	test: 0.572566
PRC train: 0.806736	val: 0.632461	test: 0.631371

Epoch: 76
Loss: 0.3914604349939521
ROC train: 0.862172	val: 0.555188	test: 0.590293
PRC train: 0.811239	val: 0.633471	test: 0.641411

Epoch: 77
Loss: 0.39221116892837127
ROC train: 0.863494	val: 0.557117	test: 0.592219
PRC train: 0.815542	val: 0.630511	test: 0.641886

Epoch: 78
Loss: 0.389451682663538
ROC train: 0.860953	val: 0.560180	test: 0.589281
PRC train: 0.813794	val: 0.630186	test: 0.636220

Epoch: 79
Loss: 0.3952526494278996
ROC train: 0.863036	val: 0.565312	test: 0.592855
PRC train: 0.817151	val: 0.636533	test: 0.636569

Epoch: 80
Loss: 0.39063621645097424
ROC train: 0.867119	val: 0.565965	test: 0.592709
PRC train: 0.820264	val: 0.639062	test: 0.637890

Epoch: 81
Loss: 0.3903813881554022
ROC train: 0.871529	val: 0.561936	test: 0.586916
PRC train: 0.827008	val: 0.635326	test: 0.637057

Epoch: 82
Loss: 0.38862162779981074
ROC train: 0.868318	val: 0.558458	test: 0.585038
PRC train: 0.822593	val: 0.634430	test: 0.635145

Epoch: 83
Loss: 0.3848258104231951
ROC train: 0.872217	val: 0.558865	test: 0.585256
PRC train: 0.825465	val: 0.635294	test: 0.637983

Epoch: 84
Loss: 0.37910051300797487
ROC train: 0.872480	val: 0.565998	test: 0.591189
PRC train: 0.825277	val: 0.638060	test: 0.639540

Epoch: 85
Loss: 0.38772355534437936
ROC train: 0.872133	val: 0.564787	test: 0.584476
PRC train: 0.822670	val: 0.638382	test: 0.636088

Epoch: 86
Loss: 0.3831603542159979
ROC train: 0.871985	val: 0.557953	test: 0.580737
PRC train: 0.823189	val: 0.633520	test: 0.635974

Epoch: 87
Loss: 0.386597285603152
ROC train: 0.873436	val: 0.562275	test: 0.591559
PRC train: 0.824936	val: 0.633766	test: 0.640275

Epoch: 88
Loss: 0.38429238004572
ROC train: 0.874840	val: 0.560360	test: 0.593794
PRC train: 0.826063	val: 0.632162	test: 0.642897

Epoch: 89
Loss: 0.38230942336902546
ROC train: 0.874434	val: 0.558319	test: 0.589842
PRC train: 0.825258	val: 0.630796	test: 0.642004

Epoch: 90
Loss: 0.37740425038438374
ROC train: 0.878140	val: 0.560850	test: 0.587955
PRC train: 0.831809	val: 0.631401	test: 0.639651

Epoch: 91
Loss: 0.37615294455634085
ROC train: 0.877533	val: 0.563308	test: 0.587009
PRC train: 0.831606	val: 0.633999	test: 0.637163

Epoch: 92
Loss: 0.3802485811139706
ROC train: 0.879589	val: 0.555171	test: 0.580207
PRC train: 0.831657	val: 0.629341	test: 0.633946

Epoch: 93
Loss: 0.378729670640204
ROC train: 0.883553	val: 0.555074	test: 0.585004
PRC train: 0.835149	val: 0.629603	test: 0.635986

Epoch: 94
Loss: 0.38264876656311597
ROC train: 0.780258	val: 0.594746	test: 0.595822
PRC train: 0.747967	val: 0.654888	test: 0.619461

Epoch: 34
Loss: 0.45055354851192364
ROC train: 0.779457	val: 0.582123	test: 0.598642
PRC train: 0.746165	val: 0.648336	test: 0.624883

Epoch: 35
Loss: 0.45093861390557893
ROC train: 0.785246	val: 0.583790	test: 0.605366
PRC train: 0.751053	val: 0.650478	test: 0.628421

Epoch: 36
Loss: 0.4475081276908108
ROC train: 0.785265	val: 0.593862	test: 0.609396
PRC train: 0.752847	val: 0.656599	test: 0.628310

Epoch: 37
Loss: 0.44284657876135997
ROC train: 0.792547	val: 0.591040	test: 0.621662
PRC train: 0.756496	val: 0.655271	test: 0.636063

Epoch: 38
Loss: 0.44242040168718955
ROC train: 0.791582	val: 0.602777	test: 0.611286
PRC train: 0.756312	val: 0.660298	test: 0.626841

Epoch: 39
Loss: 0.44429306924712686
ROC train: 0.791595	val: 0.592893	test: 0.606266
PRC train: 0.756098	val: 0.654446	test: 0.625745

Epoch: 40
Loss: 0.4432653328998782
ROC train: 0.792989	val: 0.579495	test: 0.606023
PRC train: 0.759187	val: 0.649640	test: 0.628705

Epoch: 41
Loss: 0.44495611650936584
ROC train: 0.802630	val: 0.590663	test: 0.608743
PRC train: 0.765712	val: 0.655203	test: 0.626540

Epoch: 42
Loss: 0.43949919127335857
ROC train: 0.802595	val: 0.586043	test: 0.616265
PRC train: 0.766070	val: 0.652892	test: 0.632331

Epoch: 43
Loss: 0.43529789932790813
ROC train: 0.808860	val: 0.591732	test: 0.611565
PRC train: 0.770126	val: 0.657170	test: 0.635127

Epoch: 44
Loss: 0.43547939309008116
ROC train: 0.806218	val: 0.592405	test: 0.604502
PRC train: 0.769061	val: 0.657730	test: 0.631501

Epoch: 45
Loss: 0.43473128055265137
ROC train: 0.809999	val: 0.583559	test: 0.598156
PRC train: 0.773110	val: 0.653880	test: 0.631279

Epoch: 46
Loss: 0.43171672844595593
ROC train: 0.812631	val: 0.579719	test: 0.606145
PRC train: 0.774735	val: 0.648483	test: 0.632154

Epoch: 47
Loss: 0.42860240899905244
ROC train: 0.815044	val: 0.586612	test: 0.604747
PRC train: 0.775868	val: 0.649715	test: 0.628927

Epoch: 48
Loss: 0.4322273652156624
ROC train: 0.811592	val: 0.587995	test: 0.604082
PRC train: 0.772500	val: 0.654196	test: 0.625969

Epoch: 49
Loss: 0.42478099019933385
ROC train: 0.816372	val: 0.585637	test: 0.619190
PRC train: 0.777220	val: 0.654167	test: 0.639230

Epoch: 50
Loss: 0.42711689067593356
ROC train: 0.818783	val: 0.580951	test: 0.622011
PRC train: 0.780148	val: 0.649959	test: 0.641205

Epoch: 51
Loss: 0.4240481957828702
ROC train: 0.818067	val: 0.589177	test: 0.611911
PRC train: 0.778106	val: 0.652191	test: 0.636468

Epoch: 52
Loss: 0.42520934795798043
ROC train: 0.822101	val: 0.592737	test: 0.605293
PRC train: 0.779317	val: 0.660042	test: 0.634951

Epoch: 53
Loss: 0.42321071797733384
ROC train: 0.826865	val: 0.581358	test: 0.607473
PRC train: 0.784874	val: 0.658058	test: 0.635463

Epoch: 54
Loss: 0.42072298736290115
ROC train: 0.821076	val: 0.571571	test: 0.609852
PRC train: 0.781267	val: 0.648876	test: 0.634081

Epoch: 55
Loss: 0.41954557438504514
ROC train: 0.827765	val: 0.582669	test: 0.611725
PRC train: 0.786349	val: 0.652168	test: 0.634156

Epoch: 56
Loss: 0.4187434586017658
ROC train: 0.834292	val: 0.587026	test: 0.616839
PRC train: 0.791439	val: 0.654851	test: 0.640619

Epoch: 57
Loss: 0.41972567118373355
ROC train: 0.834487	val: 0.573669	test: 0.624309
PRC train: 0.791146	val: 0.645908	test: 0.642849

Epoch: 58
Loss: 0.41541193965968726
ROC train: 0.836671	val: 0.580519	test: 0.621650
PRC train: 0.793697	val: 0.646730	test: 0.641100

Epoch: 59
Loss: 0.4123870961977507
ROC train: 0.835394	val: 0.576239	test: 0.616188
PRC train: 0.792522	val: 0.646272	test: 0.642087

Epoch: 60
Loss: 0.4137458357976318
ROC train: 0.838755	val: 0.578770	test: 0.620237
PRC train: 0.795668	val: 0.648400	test: 0.643511

Epoch: 61
Loss: 0.4146194100674274
ROC train: 0.838226	val: 0.579899	test: 0.618379
PRC train: 0.795299	val: 0.650172	test: 0.639598

Epoch: 62
Loss: 0.4142084310009627
ROC train: 0.840699	val: 0.583063	test: 0.606833
PRC train: 0.796616	val: 0.653676	test: 0.632647

Epoch: 63
Loss: 0.41107738907028335
ROC train: 0.843348	val: 0.576300	test: 0.610199
PRC train: 0.798492	val: 0.649300	test: 0.638142

Epoch: 64
Loss: 0.409275327397317
ROC train: 0.841104	val: 0.582121	test: 0.611508
PRC train: 0.798092	val: 0.651389	test: 0.644759

Epoch: 65
Loss: 0.4053736020608005
ROC train: 0.845190	val: 0.585019	test: 0.612376
PRC train: 0.800368	val: 0.651710	test: 0.641849

Epoch: 66
Loss: 0.4094708426683252
ROC train: 0.848434	val: 0.589494	test: 0.617826
PRC train: 0.803693	val: 0.650831	test: 0.641945

Epoch: 67
Loss: 0.40643704354683186
ROC train: 0.848645	val: 0.583230	test: 0.609579
PRC train: 0.804291	val: 0.649961	test: 0.636935

Epoch: 68
Loss: 0.4067296890448721
ROC train: 0.847298	val: 0.573715	test: 0.605093
PRC train: 0.803770	val: 0.648919	test: 0.641999

Epoch: 69
Loss: 0.4075564403817735
ROC train: 0.850717	val: 0.573682	test: 0.606833
PRC train: 0.805564	val: 0.648150	test: 0.642118

Epoch: 70
Loss: 0.4027162890059844
ROC train: 0.850071	val: 0.578581	test: 0.618194
PRC train: 0.804166	val: 0.648681	test: 0.644201

Epoch: 71
Loss: 0.4032382334255753
ROC train: 0.850767	val: 0.579566	test: 0.624051
PRC train: 0.806192	val: 0.650098	test: 0.651316

Epoch: 72
Loss: 0.4023770323113501
ROC train: 0.856507	val: 0.589435	test: 0.623042
PRC train: 0.809279	val: 0.657405	test: 0.646028

Epoch: 73
Loss: 0.398297134638276
ROC train: 0.854557	val: 0.586253	test: 0.615505
PRC train: 0.811179	val: 0.653094	test: 0.645216

Epoch: 74
Loss: 0.4005839990180993
ROC train: 0.854785	val: 0.575347	test: 0.623863
PRC train: 0.809830	val: 0.647830	test: 0.651765

Epoch: 75
Loss: 0.39649129909499675
ROC train: 0.860794	val: 0.575824	test: 0.617520
PRC train: 0.814485	val: 0.651296	test: 0.642859

Epoch: 76
Loss: 0.3944359114522946
ROC train: 0.863062	val: 0.575604	test: 0.622137
PRC train: 0.816346	val: 0.651337	test: 0.645730

Epoch: 77
Loss: 0.39600129972880643
ROC train: 0.862477	val: 0.574603	test: 0.629781
PRC train: 0.817164	val: 0.647017	test: 0.650675

Epoch: 78
Loss: 0.3954424127660085
ROC train: 0.865118	val: 0.575718	test: 0.637430
PRC train: 0.821295	val: 0.645900	test: 0.661531

Epoch: 79
Loss: 0.3956194107000284
ROC train: 0.864274	val: 0.576045	test: 0.629673
PRC train: 0.819265	val: 0.647274	test: 0.657032

Epoch: 80
Loss: 0.3989094639023429
ROC train: 0.866019	val: 0.580317	test: 0.621588
PRC train: 0.820139	val: 0.652395	test: 0.646689

Epoch: 81
Loss: 0.39043067157298483
ROC train: 0.864331	val: 0.569857	test: 0.623174
PRC train: 0.818210	val: 0.647068	test: 0.652881

Epoch: 82
Loss: 0.388246942234564
ROC train: 0.871527	val: 0.570863	test: 0.629722
PRC train: 0.824867	val: 0.646947	test: 0.655615

Epoch: 83
Loss: 0.38651452273625425
ROC train: 0.873644	val: 0.575512	test: 0.620785
PRC train: 0.827916	val: 0.652463	test: 0.654310

Epoch: 84
Loss: 0.3884604002170258
ROC train: 0.866537	val: 0.577045	test: 0.608776
PRC train: 0.821387	val: 0.651582	test: 0.641462

Epoch: 85
Loss: 0.3885348281065566
ROC train: 0.870543	val: 0.572737	test: 0.611431
PRC train: 0.824473	val: 0.648228	test: 0.644481

Epoch: 86
Loss: 0.3909607623017454
ROC train: 0.870091	val: 0.574758	test: 0.616427
PRC train: 0.825458	val: 0.646633	test: 0.647603

Epoch: 87
Loss: 0.3911440709389371
ROC train: 0.875155	val: 0.569202	test: 0.615541
PRC train: 0.829040	val: 0.648233	test: 0.646526

Epoch: 88
Loss: 0.38307778204534493
ROC train: 0.874053	val: 0.571233	test: 0.603403
PRC train: 0.828727	val: 0.652002	test: 0.640550

Epoch: 89
Loss: 0.3849518923431996
ROC train: 0.876260	val: 0.569329	test: 0.612280
PRC train: 0.830313	val: 0.649646	test: 0.641975

Epoch: 90
Loss: 0.38348880355934695
ROC train: 0.875341	val: 0.559663	test: 0.630567
PRC train: 0.827906	val: 0.641534	test: 0.654929

Epoch: 91
Loss: 0.385705394950738
ROC train: 0.877359	val: 0.568461	test: 0.626088
PRC train: 0.833619	val: 0.647244	test: 0.655224

Epoch: 92
Loss: 0.3772879278705229
ROC train: 0.880430	val: 0.573214	test: 0.619384
PRC train: 0.837185	val: 0.650314	test: 0.651329

Epoch: 93
Loss: 0.3804455450083727
ROC train: 0.885080	val: 0.579591	test: 0.620631
PRC train: 0.841468	val: 0.652849	test: 0.648244

Epoch: 94
Loss: 0.3771880907658387
ROC train: 0.782370	val: 0.577351	test: 0.600276
PRC train: 0.748845	val: 0.645371	test: 0.619397

Epoch: 34
Loss: 0.44828601747374675
ROC train: 0.787066	val: 0.569986	test: 0.615731
PRC train: 0.751567	val: 0.646489	test: 0.627348

Epoch: 35
Loss: 0.44651575436599356
ROC train: 0.789096	val: 0.571781	test: 0.620045
PRC train: 0.753987	val: 0.647716	test: 0.628532

Epoch: 36
Loss: 0.44521584291903044
ROC train: 0.794284	val: 0.582414	test: 0.625383
PRC train: 0.757449	val: 0.647210	test: 0.631441

Epoch: 37
Loss: 0.4409714472284463
ROC train: 0.793416	val: 0.568832	test: 0.623105
PRC train: 0.755393	val: 0.644642	test: 0.631363

Epoch: 38
Loss: 0.4413955096179885
ROC train: 0.798071	val: 0.568240	test: 0.618605
PRC train: 0.760177	val: 0.645439	test: 0.627144

Epoch: 39
Loss: 0.43892215753671315
ROC train: 0.803043	val: 0.568993	test: 0.615241
PRC train: 0.766078	val: 0.646211	test: 0.624588

Epoch: 40
Loss: 0.43650473549916
ROC train: 0.798971	val: 0.560827	test: 0.615618
PRC train: 0.762774	val: 0.643208	test: 0.628842

Epoch: 41
Loss: 0.4384903646534709
ROC train: 0.805056	val: 0.559450	test: 0.621502
PRC train: 0.766952	val: 0.644406	test: 0.632143

Epoch: 42
Loss: 0.43297109500498476
ROC train: 0.807269	val: 0.556411	test: 0.623355
PRC train: 0.769193	val: 0.643463	test: 0.632458

Epoch: 43
Loss: 0.42877179712740043
ROC train: 0.809121	val: 0.554439	test: 0.623027
PRC train: 0.770851	val: 0.641024	test: 0.632612

Epoch: 44
Loss: 0.43007497719372445
ROC train: 0.807801	val: 0.563114	test: 0.617749
PRC train: 0.769581	val: 0.641905	test: 0.629087

Epoch: 45
Loss: 0.4286416378681589
ROC train: 0.811571	val: 0.572234	test: 0.614781
PRC train: 0.773524	val: 0.647612	test: 0.632168

Epoch: 46
Loss: 0.428044720597223
ROC train: 0.815152	val: 0.561350	test: 0.617542
PRC train: 0.776894	val: 0.647361	test: 0.637750

Epoch: 47
Loss: 0.4287974248057894
ROC train: 0.818973	val: 0.558511	test: 0.614189
PRC train: 0.777932	val: 0.643931	test: 0.631498

Epoch: 48
Loss: 0.4291202354760603
ROC train: 0.819358	val: 0.563031	test: 0.611451
PRC train: 0.781771	val: 0.643747	test: 0.629806

Epoch: 49
Loss: 0.42790781293774405
ROC train: 0.823411	val: 0.561087	test: 0.615757
PRC train: 0.785639	val: 0.643577	test: 0.633512

Epoch: 50
Loss: 0.42326776336750926
ROC train: 0.823308	val: 0.556150	test: 0.616343
PRC train: 0.784534	val: 0.643487	test: 0.634199

Epoch: 51
Loss: 0.42326857279162866
ROC train: 0.824534	val: 0.563415	test: 0.624682
PRC train: 0.784741	val: 0.646859	test: 0.634597

Epoch: 52
Loss: 0.4273139602448581
ROC train: 0.831452	val: 0.563760	test: 0.628836
PRC train: 0.787731	val: 0.647125	test: 0.636806

Epoch: 53
Loss: 0.4228103448997417
ROC train: 0.831205	val: 0.563376	test: 0.624571
PRC train: 0.787901	val: 0.647280	test: 0.634321

Epoch: 54
Loss: 0.41699891826984276
ROC train: 0.834467	val: 0.559638	test: 0.620090
PRC train: 0.791747	val: 0.645241	test: 0.636079

Epoch: 55
Loss: 0.4150619422707499
ROC train: 0.833696	val: 0.557731	test: 0.625737
PRC train: 0.792264	val: 0.644420	test: 0.639592

Epoch: 56
Loss: 0.41819674844033294
ROC train: 0.836922	val: 0.561753	test: 0.623050
PRC train: 0.793218	val: 0.644876	test: 0.637463

Epoch: 57
Loss: 0.40918683174781084
ROC train: 0.836465	val: 0.565322	test: 0.616569
PRC train: 0.793399	val: 0.646013	test: 0.633212

Epoch: 58
Loss: 0.4139486192537679
ROC train: 0.823213	val: 0.563360	test: 0.610016
PRC train: 0.780141	val: 0.643093	test: 0.630876

Epoch: 59
Loss: 0.41079861074944346
ROC train: 0.833873	val: 0.567686	test: 0.626657
PRC train: 0.790813	val: 0.647131	test: 0.639809

Epoch: 60
Loss: 0.40632270080697136
ROC train: 0.838880	val: 0.565216	test: 0.628756
PRC train: 0.793913	val: 0.647557	test: 0.641484

Epoch: 61
Loss: 0.41284048873243145
ROC train: 0.839082	val: 0.551936	test: 0.611805
PRC train: 0.795524	val: 0.643572	test: 0.635677

Epoch: 62
Loss: 0.40771318008371515
ROC train: 0.843402	val: 0.558367	test: 0.614592
PRC train: 0.800390	val: 0.645897	test: 0.636942

Epoch: 63
Loss: 0.40987290746508587
ROC train: 0.847368	val: 0.557445	test: 0.630568
PRC train: 0.803036	val: 0.643485	test: 0.643101

Epoch: 64
Loss: 0.4025483756505086
ROC train: 0.849668	val: 0.551384	test: 0.628612
PRC train: 0.805851	val: 0.642335	test: 0.645491

Epoch: 65
Loss: 0.4079970531332642
ROC train: 0.846044	val: 0.554476	test: 0.605863
PRC train: 0.804225	val: 0.645373	test: 0.630237

Epoch: 66
Loss: 0.4050065735411237
ROC train: 0.852731	val: 0.557403	test: 0.616120
PRC train: 0.808087	val: 0.644572	test: 0.632714

Epoch: 67
Loss: 0.4049824488092752
ROC train: 0.854343	val: 0.557826	test: 0.622728
PRC train: 0.806667	val: 0.643173	test: 0.637515

Epoch: 68
Loss: 0.4008303855015893
ROC train: 0.853393	val: 0.558194	test: 0.623000
PRC train: 0.806895	val: 0.642768	test: 0.636910

Epoch: 69
Loss: 0.3973486280732034
ROC train: 0.853604	val: 0.557159	test: 0.622545
PRC train: 0.809481	val: 0.645724	test: 0.639598

Epoch: 70
Loss: 0.40048017232631394
ROC train: 0.857523	val: 0.546454	test: 0.611368
PRC train: 0.812310	val: 0.642804	test: 0.633840

Epoch: 71
Loss: 0.3998945856423839
ROC train: 0.855771	val: 0.546878	test: 0.619659
PRC train: 0.812219	val: 0.640109	test: 0.635282

Epoch: 72
Loss: 0.3923618358124698
ROC train: 0.862939	val: 0.545083	test: 0.616846
PRC train: 0.814264	val: 0.639345	test: 0.635587

Epoch: 73
Loss: 0.39826418729352003
ROC train: 0.865004	val: 0.552415	test: 0.616126
PRC train: 0.817919	val: 0.643907	test: 0.637725

Epoch: 74
Loss: 0.39429218700568497
ROC train: 0.863954	val: 0.557084	test: 0.621207
PRC train: 0.819779	val: 0.646529	test: 0.641072

Epoch: 75
Loss: 0.4021537372863876
ROC train: 0.862730	val: 0.552305	test: 0.624801
PRC train: 0.815399	val: 0.643737	test: 0.646798

Epoch: 76
Loss: 0.39352307856241164
ROC train: 0.864084	val: 0.563952	test: 0.616560
PRC train: 0.819582	val: 0.649669	test: 0.637200

Epoch: 77
Loss: 0.3987993676450506
ROC train: 0.865157	val: 0.562530	test: 0.633540
PRC train: 0.821013	val: 0.650180	test: 0.650140

Epoch: 78
Loss: 0.3929870903733107
ROC train: 0.866913	val: 0.552269	test: 0.631795
PRC train: 0.826156	val: 0.646256	test: 0.647730

Epoch: 79
Loss: 0.3932950498247405
ROC train: 0.868253	val: 0.549118	test: 0.625885
PRC train: 0.825963	val: 0.642242	test: 0.643727

Epoch: 80
Loss: 0.3892407134432509
ROC train: 0.870272	val: 0.551155	test: 0.627232
PRC train: 0.825533	val: 0.643259	test: 0.643175

Epoch: 81
Loss: 0.3914439212558135
ROC train: 0.868042	val: 0.554798	test: 0.628851
PRC train: 0.825542	val: 0.645026	test: 0.643186

Epoch: 82
Loss: 0.38717169057528655
ROC train: 0.870882	val: 0.554270	test: 0.620791
PRC train: 0.824904	val: 0.648494	test: 0.643617

Epoch: 83
Loss: 0.3871795027395881
ROC train: 0.874192	val: 0.555083	test: 0.617983
PRC train: 0.830178	val: 0.648814	test: 0.641703

Epoch: 84
Loss: 0.3819700514309209
ROC train: 0.871564	val: 0.558288	test: 0.610475
PRC train: 0.825790	val: 0.646621	test: 0.631113

Epoch: 85
Loss: 0.38429323432812246
ROC train: 0.872021	val: 0.540795	test: 0.612331
PRC train: 0.825938	val: 0.639733	test: 0.634746

Epoch: 86
Loss: 0.38444686400771005
ROC train: 0.876181	val: 0.544859	test: 0.621081
PRC train: 0.832375	val: 0.642183	test: 0.636843

Epoch: 87
Loss: 0.38492762825082977
ROC train: 0.873815	val: 0.560008	test: 0.623749
PRC train: 0.832730	val: 0.645215	test: 0.638671

Epoch: 88
Loss: 0.3837063868987421
ROC train: 0.874367	val: 0.553467	test: 0.625672
PRC train: 0.832392	val: 0.642891	test: 0.638973

Epoch: 89
Loss: 0.38362307482912095
ROC train: 0.880517	val: 0.545095	test: 0.627440
PRC train: 0.837867	val: 0.643728	test: 0.639669

Epoch: 90
Loss: 0.3754793392749736
ROC train: 0.880329	val: 0.542582	test: 0.628614
PRC train: 0.837479	val: 0.642450	test: 0.644312

Epoch: 91
Loss: 0.37872400442154613
ROC train: 0.880250	val: 0.549423	test: 0.616857
PRC train: 0.838599	val: 0.642960	test: 0.637219

Epoch: 92
Loss: 0.3761534167045145
ROC train: 0.879829	val: 0.551926	test: 0.615440
PRC train: 0.839332	val: 0.642407	test: 0.634388

Epoch: 93
Loss: 0.3796591896478533
ROC train: 0.883381	val: 0.547596	test: 0.627376
PRC train: 0.840461	val: 0.643107	test: 0.644199

Epoch: 94
Loss: 0.3717953999169439
ROC train: 0.789644	val: 0.586543	test: 0.610937
PRC train: 0.753263	val: 0.655178	test: 0.625609

Epoch: 34
Loss: 0.44723830043229285
ROC train: 0.793328	val: 0.578806	test: 0.606295
PRC train: 0.755644	val: 0.652595	test: 0.626146

Epoch: 35
Loss: 0.44361929063963
ROC train: 0.794942	val: 0.572235	test: 0.604977
PRC train: 0.757509	val: 0.647719	test: 0.626984

Epoch: 36
Loss: 0.44240727298669275
ROC train: 0.796733	val: 0.576368	test: 0.613734
PRC train: 0.761003	val: 0.648334	test: 0.628162

Epoch: 37
Loss: 0.43958572038090954
ROC train: 0.801598	val: 0.572922	test: 0.615807
PRC train: 0.764814	val: 0.649366	test: 0.630322

Epoch: 38
Loss: 0.43765315737844995
ROC train: 0.803780	val: 0.567282	test: 0.611894
PRC train: 0.765144	val: 0.649226	test: 0.630239

Epoch: 39
Loss: 0.43644185130771856
ROC train: 0.810108	val: 0.570976	test: 0.615632
PRC train: 0.768430	val: 0.647480	test: 0.630404

Epoch: 40
Loss: 0.4354528733524607
ROC train: 0.812187	val: 0.573657	test: 0.619274
PRC train: 0.771282	val: 0.648015	test: 0.633109

Epoch: 41
Loss: 0.43927904333709694
ROC train: 0.805188	val: 0.572556	test: 0.614867
PRC train: 0.765045	val: 0.645665	test: 0.633507

Epoch: 42
Loss: 0.4340518340173773
ROC train: 0.814085	val: 0.570386	test: 0.621871
PRC train: 0.773074	val: 0.647877	test: 0.636144

Epoch: 43
Loss: 0.4319679605952016
ROC train: 0.811853	val: 0.574425	test: 0.622610
PRC train: 0.771892	val: 0.652031	test: 0.632927

Epoch: 44
Loss: 0.43318791532665457
ROC train: 0.822108	val: 0.568579	test: 0.621324
PRC train: 0.780152	val: 0.646857	test: 0.636305

Epoch: 45
Loss: 0.4235483873934162
ROC train: 0.822478	val: 0.573454	test: 0.609752
PRC train: 0.781124	val: 0.650133	test: 0.633399

Epoch: 46
Loss: 0.4256676926285435
ROC train: 0.823177	val: 0.577824	test: 0.610442
PRC train: 0.781690	val: 0.654737	test: 0.633868

Epoch: 47
Loss: 0.42086814657823995
ROC train: 0.821317	val: 0.569170	test: 0.608877
PRC train: 0.780616	val: 0.651015	test: 0.633872

Epoch: 48
Loss: 0.42186837252169374
ROC train: 0.819380	val: 0.565969	test: 0.608556
PRC train: 0.777753	val: 0.646747	test: 0.633256

Epoch: 49
Loss: 0.419684823428559
ROC train: 0.823400	val: 0.575522	test: 0.613942
PRC train: 0.780970	val: 0.649485	test: 0.631420

Epoch: 50
Loss: 0.4260926276539691
ROC train: 0.822855	val: 0.568462	test: 0.624693
PRC train: 0.781130	val: 0.646872	test: 0.641569

Epoch: 51
Loss: 0.4197538703827586
ROC train: 0.831334	val: 0.556437	test: 0.624112
PRC train: 0.787090	val: 0.641735	test: 0.643899

Epoch: 52
Loss: 0.4123200004191285
ROC train: 0.836460	val: 0.559887	test: 0.622470
PRC train: 0.791209	val: 0.644356	test: 0.638006

Epoch: 53
Loss: 0.4165867167627012
ROC train: 0.836611	val: 0.568608	test: 0.618140
PRC train: 0.792166	val: 0.647661	test: 0.632738

Epoch: 54
Loss: 0.41675002279386064
ROC train: 0.836682	val: 0.567309	test: 0.618224
PRC train: 0.791717	val: 0.647587	test: 0.637661

Epoch: 55
Loss: 0.4131873812248514
ROC train: 0.837790	val: 0.568252	test: 0.612108
PRC train: 0.792856	val: 0.648507	test: 0.632729

Epoch: 56
Loss: 0.41355848313764476
ROC train: 0.839951	val: 0.562144	test: 0.611787
PRC train: 0.795113	val: 0.646703	test: 0.635427

Epoch: 57
Loss: 0.41277350854926764
ROC train: 0.844972	val: 0.563532	test: 0.624375
PRC train: 0.798566	val: 0.647540	test: 0.641370

Epoch: 58
Loss: 0.4137041180748414
ROC train: 0.845077	val: 0.563452	test: 0.625937
PRC train: 0.798089	val: 0.643648	test: 0.640926

Epoch: 59
Loss: 0.4091356117580615
ROC train: 0.846536	val: 0.562463	test: 0.618137
PRC train: 0.800225	val: 0.643276	test: 0.642900

Epoch: 60
Loss: 0.4054015617649001
ROC train: 0.852040	val: 0.565009	test: 0.609019
PRC train: 0.805233	val: 0.646266	test: 0.636675

Epoch: 61
Loss: 0.40601338619975935
ROC train: 0.852952	val: 0.562868	test: 0.612889
PRC train: 0.804975	val: 0.644030	test: 0.633870

Epoch: 62
Loss: 0.40696133644830357
ROC train: 0.853091	val: 0.561587	test: 0.609443
PRC train: 0.805633	val: 0.644716	test: 0.638670

Epoch: 63
Loss: 0.4032394038492997
ROC train: 0.848583	val: 0.557170	test: 0.594552
PRC train: 0.800499	val: 0.645005	test: 0.630331

Epoch: 64
Loss: 0.40725911350448357
ROC train: 0.846180	val: 0.564688	test: 0.595427
PRC train: 0.799534	val: 0.649682	test: 0.629775

Epoch: 65
Loss: 0.40414424160218326
ROC train: 0.855041	val: 0.564705	test: 0.610653
PRC train: 0.809141	val: 0.650425	test: 0.635343

Epoch: 66
Loss: 0.397537422939316
ROC train: 0.857571	val: 0.562936	test: 0.620306
PRC train: 0.812590	val: 0.647456	test: 0.643346

Epoch: 67
Loss: 0.4021406829597508
ROC train: 0.858570	val: 0.562185	test: 0.621791
PRC train: 0.814140	val: 0.647069	test: 0.643673

Epoch: 68
Loss: 0.39742510081239735
ROC train: 0.859484	val: 0.558567	test: 0.620085
PRC train: 0.813165	val: 0.644527	test: 0.643117

Epoch: 69
Loss: 0.40061427946923867
ROC train: 0.858265	val: 0.559655	test: 0.616828
PRC train: 0.811420	val: 0.645165	test: 0.641429

Epoch: 70
Loss: 0.3964688722270857
ROC train: 0.862279	val: 0.561773	test: 0.608008
PRC train: 0.817018	val: 0.647928	test: 0.638380

Epoch: 71
Loss: 0.39460926513514744
ROC train: 0.862469	val: 0.558924	test: 0.618619
PRC train: 0.816932	val: 0.645358	test: 0.647678

Epoch: 72
Loss: 0.3987099184137475
ROC train: 0.866017	val: 0.563071	test: 0.619528
PRC train: 0.819819	val: 0.646157	test: 0.640880

Epoch: 73
Loss: 0.39167892690909895
ROC train: 0.867787	val: 0.557821	test: 0.612977
PRC train: 0.821683	val: 0.644720	test: 0.641486

Epoch: 74
Loss: 0.39687868336733556
ROC train: 0.867833	val: 0.560774	test: 0.614981
PRC train: 0.822169	val: 0.646734	test: 0.637080

Epoch: 75
Loss: 0.395130110892653
ROC train: 0.868455	val: 0.559698	test: 0.619076
PRC train: 0.820978	val: 0.644532	test: 0.637547

Epoch: 76
Loss: 0.39156090405323807
ROC train: 0.868582	val: 0.556978	test: 0.627517
PRC train: 0.820018	val: 0.643612	test: 0.648466

Epoch: 77
Loss: 0.3946237221923824
ROC train: 0.866204	val: 0.559731	test: 0.624276
PRC train: 0.818035	val: 0.646391	test: 0.644839

Epoch: 78
Loss: 0.3912674961637995
ROC train: 0.868661	val: 0.570952	test: 0.605013
PRC train: 0.821786	val: 0.650078	test: 0.630629

Epoch: 79
Loss: 0.38932981420504886
ROC train: 0.872141	val: 0.564836	test: 0.603276
PRC train: 0.826950	val: 0.646913	test: 0.631044

Epoch: 80
Loss: 0.38963813685871995
ROC train: 0.871701	val: 0.560084	test: 0.622800
PRC train: 0.826636	val: 0.647230	test: 0.646023

Epoch: 81
Loss: 0.3874981141291184
ROC train: 0.873408	val: 0.558763	test: 0.628885
PRC train: 0.826831	val: 0.645625	test: 0.645196

Epoch: 82
Loss: 0.38325589125654935
ROC train: 0.869880	val: 0.555144	test: 0.616622
PRC train: 0.824131	val: 0.642130	test: 0.643074

Epoch: 83
Loss: 0.38433018428087323
ROC train: 0.876865	val: 0.560960	test: 0.612761
PRC train: 0.833064	val: 0.646462	test: 0.639360

Epoch: 84
Loss: 0.3819488272622062
ROC train: 0.879423	val: 0.559879	test: 0.615128
PRC train: 0.833274	val: 0.643629	test: 0.640407

Epoch: 85
Loss: 0.3806896790902158
ROC train: 0.880124	val: 0.547172	test: 0.604654
PRC train: 0.834075	val: 0.638839	test: 0.637348

Epoch: 86
Loss: 0.38221765853591494
ROC train: 0.876818	val: 0.551575	test: 0.610027
PRC train: 0.830579	val: 0.643466	test: 0.640441

Epoch: 87
Loss: 0.38171299217040033
ROC train: 0.877123	val: 0.552397	test: 0.598896
PRC train: 0.829823	val: 0.646401	test: 0.637818

Epoch: 88
Loss: 0.37930809387914394
ROC train: 0.881154	val: 0.560418	test: 0.602091
PRC train: 0.835812	val: 0.647118	test: 0.635320

Epoch: 89
Loss: 0.3771576467462695
ROC train: 0.881276	val: 0.558976	test: 0.612628
PRC train: 0.835232	val: 0.643913	test: 0.641511

Epoch: 90
Loss: 0.3738934520907593
ROC train: 0.881753	val: 0.553208	test: 0.619265
PRC train: 0.835685	val: 0.641616	test: 0.648165

Epoch: 91
Loss: 0.3765371428175126
ROC train: 0.886220	val: 0.560101	test: 0.615601
PRC train: 0.841082	val: 0.648749	test: 0.642769

Epoch: 92
Loss: 0.3723314594766596
ROC train: 0.887795	val: 0.565632	test: 0.615424
PRC train: 0.844175	val: 0.650787	test: 0.642903

Epoch: 93
Loss: 0.373226546686055
ROC train: 0.886397	val: 0.565268	test: 0.615939
PRC train: 0.840752	val: 0.645046	test: 0.644584

Epoch: 94
Loss: 0.3696652926470164
ROC train: 0.779236	val: 0.610844	test: 0.621483
PRC train: 0.750883	val: 0.657266	test: 0.638640

Epoch: 34
Loss: 0.44529494298030176
ROC train: 0.781063	val: 0.601880	test: 0.625083
PRC train: 0.752928	val: 0.654991	test: 0.637616

Epoch: 35
Loss: 0.44549940017699824
ROC train: 0.785766	val: 0.611894	test: 0.627782
PRC train: 0.755539	val: 0.658656	test: 0.639463

Epoch: 36
Loss: 0.44179792434383014
ROC train: 0.789303	val: 0.608871	test: 0.627672
PRC train: 0.759127	val: 0.657924	test: 0.640099

Epoch: 37
Loss: 0.4413988479928726
ROC train: 0.790616	val: 0.603536	test: 0.623221
PRC train: 0.760780	val: 0.654650	test: 0.641745

Epoch: 38
Loss: 0.44391628397679306
ROC train: 0.790984	val: 0.615026	test: 0.619591
PRC train: 0.758786	val: 0.663587	test: 0.636110

Epoch: 39
Loss: 0.4470077421912867
ROC train: 0.792364	val: 0.606258	test: 0.629606
PRC train: 0.760843	val: 0.660933	test: 0.637106

Epoch: 40
Loss: 0.4442680946673704
ROC train: 0.797436	val: 0.608818	test: 0.632360
PRC train: 0.765721	val: 0.654673	test: 0.643798

Epoch: 41
Loss: 0.43450826640072
ROC train: 0.801489	val: 0.608373	test: 0.632441
PRC train: 0.768569	val: 0.656453	test: 0.641113

Epoch: 42
Loss: 0.4376232867400283
ROC train: 0.798751	val: 0.600931	test: 0.621333
PRC train: 0.765067	val: 0.655771	test: 0.633162

Epoch: 43
Loss: 0.4313738305217343
ROC train: 0.801637	val: 0.602672	test: 0.620911
PRC train: 0.767919	val: 0.658377	test: 0.636981

Epoch: 44
Loss: 0.4313467638717493
ROC train: 0.802739	val: 0.602596	test: 0.626619
PRC train: 0.771466	val: 0.657099	test: 0.641926

Epoch: 45
Loss: 0.43620269112555315
ROC train: 0.810573	val: 0.611712	test: 0.631447
PRC train: 0.774958	val: 0.661569	test: 0.639980

Epoch: 46
Loss: 0.43413671078621024
ROC train: 0.806511	val: 0.622506	test: 0.621955
PRC train: 0.771226	val: 0.664347	test: 0.640411

Epoch: 47
Loss: 0.4294842958223832
ROC train: 0.806589	val: 0.616886	test: 0.636069
PRC train: 0.774571	val: 0.658993	test: 0.644586

Epoch: 48
Loss: 0.4325507924716373
ROC train: 0.810010	val: 0.611385	test: 0.628185
PRC train: 0.775867	val: 0.661912	test: 0.641470

Epoch: 49
Loss: 0.42883219456460997
ROC train: 0.816127	val: 0.611660	test: 0.627014
PRC train: 0.779931	val: 0.663526	test: 0.640218

Epoch: 50
Loss: 0.43031043086144516
ROC train: 0.820218	val: 0.607185	test: 0.632495
PRC train: 0.783748	val: 0.659801	test: 0.643623

Epoch: 51
Loss: 0.42913703376207923
ROC train: 0.820038	val: 0.605131	test: 0.615848
PRC train: 0.783948	val: 0.658330	test: 0.634550

Epoch: 52
Loss: 0.4228002988263129
ROC train: 0.823438	val: 0.613607	test: 0.624998
PRC train: 0.787747	val: 0.659654	test: 0.639187

Epoch: 53
Loss: 0.4215817730031855
ROC train: 0.822087	val: 0.606763	test: 0.633622
PRC train: 0.785845	val: 0.659174	test: 0.642785

Epoch: 54
Loss: 0.42353353340157185
ROC train: 0.822419	val: 0.605623	test: 0.636556
PRC train: 0.786830	val: 0.657790	test: 0.643740

Epoch: 55
Loss: 0.41988360422204823
ROC train: 0.823612	val: 0.615493	test: 0.625199
PRC train: 0.788240	val: 0.661657	test: 0.643068

Epoch: 56
Loss: 0.41830445354105406
ROC train: 0.825327	val: 0.594028	test: 0.643418
PRC train: 0.790146	val: 0.656352	test: 0.649568

Epoch: 57
Loss: 0.4134479197600559
ROC train: 0.828309	val: 0.596728	test: 0.628820
PRC train: 0.789646	val: 0.655587	test: 0.642599

Epoch: 58
Loss: 0.4135487173711561
ROC train: 0.833463	val: 0.607271	test: 0.624325
PRC train: 0.792359	val: 0.656578	test: 0.645979

Epoch: 59
Loss: 0.4174779592813481
ROC train: 0.830233	val: 0.606772	test: 0.633723
PRC train: 0.791203	val: 0.652558	test: 0.649105

Epoch: 60
Loss: 0.41571559148980564
ROC train: 0.828572	val: 0.603754	test: 0.616348
PRC train: 0.788880	val: 0.658425	test: 0.640096

Epoch: 61
Loss: 0.4160117375684432
ROC train: 0.832446	val: 0.598743	test: 0.616188
PRC train: 0.792792	val: 0.656236	test: 0.640420

Epoch: 62
Loss: 0.41339495409764443
ROC train: 0.836252	val: 0.600180	test: 0.628564
PRC train: 0.798679	val: 0.656251	test: 0.648637

Epoch: 63
Loss: 0.4159378445020865
ROC train: 0.840925	val: 0.608480	test: 0.624562
PRC train: 0.803751	val: 0.662584	test: 0.640364

Epoch: 64
Loss: 0.4140979125278205
ROC train: 0.839693	val: 0.605480	test: 0.616982
PRC train: 0.799732	val: 0.659467	test: 0.636418

Epoch: 65
Loss: 0.40927818204250954
ROC train: 0.844681	val: 0.617604	test: 0.628428
PRC train: 0.803160	val: 0.662795	test: 0.644080

Epoch: 66
Loss: 0.40665497637410536
ROC train: 0.842324	val: 0.606640	test: 0.622485
PRC train: 0.801764	val: 0.658018	test: 0.638287

Epoch: 67
Loss: 0.41167578025545104
ROC train: 0.843552	val: 0.609984	test: 0.613504
PRC train: 0.801820	val: 0.662429	test: 0.636550

Epoch: 68
Loss: 0.40891092760124803
ROC train: 0.841177	val: 0.603821	test: 0.620275
PRC train: 0.798048	val: 0.660507	test: 0.646818

Epoch: 69
Loss: 0.4006359256696278
ROC train: 0.847516	val: 0.610748	test: 0.611581
PRC train: 0.807147	val: 0.661809	test: 0.640402

Epoch: 70
Loss: 0.40420821404116525
ROC train: 0.849082	val: 0.609375	test: 0.615691
PRC train: 0.811766	val: 0.664034	test: 0.640094

Epoch: 71
Loss: 0.40034815588999273
ROC train: 0.851066	val: 0.602830	test: 0.605853
PRC train: 0.809661	val: 0.660053	test: 0.635252

Epoch: 72
Loss: 0.3998065178299499
ROC train: 0.852995	val: 0.602289	test: 0.604500
PRC train: 0.811701	val: 0.660217	test: 0.634954

Epoch: 73
Loss: 0.39874652721099096
ROC train: 0.854775	val: 0.616721	test: 0.613818
PRC train: 0.815376	val: 0.663595	test: 0.638351

Epoch: 74
Loss: 0.4033262137814428
ROC train: 0.855079	val: 0.625309	test: 0.613748
PRC train: 0.813200	val: 0.670046	test: 0.638827

Epoch: 75
Loss: 0.3992963812689078
ROC train: 0.853796	val: 0.600022	test: 0.623288
PRC train: 0.813219	val: 0.662204	test: 0.641181

Epoch: 76
Loss: 0.39936573841135015
ROC train: 0.859311	val: 0.604641	test: 0.618132
PRC train: 0.817668	val: 0.663125	test: 0.642498

Epoch: 77
Loss: 0.3950701631323826
ROC train: 0.856979	val: 0.597444	test: 0.632882
PRC train: 0.815646	val: 0.660701	test: 0.646655

Epoch: 78
Loss: 0.39815241866377277
ROC train: 0.860090	val: 0.601371	test: 0.628947
PRC train: 0.818522	val: 0.661382	test: 0.642954

Epoch: 79
Loss: 0.39658723704501353
ROC train: 0.863151	val: 0.615827	test: 0.609656
PRC train: 0.820791	val: 0.665863	test: 0.634707

Epoch: 80
Loss: 0.3955959082956855
ROC train: 0.863442	val: 0.605502	test: 0.621852
PRC train: 0.822263	val: 0.660941	test: 0.639952

Epoch: 81
Loss: 0.3944432602831341
ROC train: 0.861910	val: 0.614909	test: 0.598343
PRC train: 0.819348	val: 0.661964	test: 0.631917

Epoch: 82
Loss: 0.3954793218262815
ROC train: 0.865680	val: 0.612159	test: 0.609781
PRC train: 0.824252	val: 0.661802	test: 0.639511

Epoch: 83
Loss: 0.3925026318062538
ROC train: 0.865051	val: 0.609009	test: 0.607917
PRC train: 0.826552	val: 0.657455	test: 0.642473

Epoch: 84
Loss: 0.39137700029299366
ROC train: 0.865225	val: 0.599591	test: 0.595659
PRC train: 0.825444	val: 0.656941	test: 0.635955

Epoch: 85
Loss: 0.3910814315519186
ROC train: 0.868489	val: 0.603877	test: 0.607344
PRC train: 0.826529	val: 0.658582	test: 0.636387

Epoch: 86
Loss: 0.3859626857393992
ROC train: 0.870159	val: 0.605754	test: 0.608533
PRC train: 0.827815	val: 0.658722	test: 0.636698

Epoch: 87
Loss: 0.3909846605021679
ROC train: 0.872405	val: 0.602642	test: 0.616397
PRC train: 0.832630	val: 0.660476	test: 0.641546

Epoch: 88
Loss: 0.3895670315375126
ROC train: 0.873261	val: 0.612586	test: 0.605921
PRC train: 0.833208	val: 0.665402	test: 0.640500

Epoch: 89
Loss: 0.38567573697743573
ROC train: 0.871551	val: 0.610143	test: 0.609538
PRC train: 0.833013	val: 0.665278	test: 0.641120

Epoch: 90
Loss: 0.3850383775810965
ROC train: 0.874372	val: 0.611136	test: 0.616939
PRC train: 0.835181	val: 0.662035	test: 0.644682

Epoch: 91
Loss: 0.3831428714944551
ROC train: 0.873800	val: 0.624754	test: 0.618175
PRC train: 0.833107	val: 0.660848	test: 0.643502

Epoch: 92
Loss: 0.3873468200458342
ROC train: 0.876795	val: 0.611761	test: 0.614637
PRC train: 0.839077	val: 0.663353	test: 0.639004

Epoch: 93
Loss: 0.3847221797635946
ROC train: 0.871453	val: 0.599890	test: 0.613522
PRC train: 0.832990	val: 0.660464	test: 0.639592

Epoch: 94
Loss: 0.3830427110141526
ROC train: 0.779335	val: 0.618965	test: 0.618021
PRC train: 0.750388	val: 0.661839	test: 0.639884

Epoch: 34
Loss: 0.44845102862767383
ROC train: 0.784538	val: 0.615281	test: 0.627752
PRC train: 0.752975	val: 0.660792	test: 0.642077

Epoch: 35
Loss: 0.4441611640191884
ROC train: 0.785470	val: 0.615917	test: 0.617182
PRC train: 0.751559	val: 0.663309	test: 0.634957

Epoch: 36
Loss: 0.44536241769324897
ROC train: 0.789550	val: 0.620930	test: 0.609578
PRC train: 0.756154	val: 0.664972	test: 0.629489

Epoch: 37
Loss: 0.4459598264127912
ROC train: 0.789447	val: 0.625331	test: 0.616664
PRC train: 0.757793	val: 0.663198	test: 0.638584

Epoch: 38
Loss: 0.4430600955322281
ROC train: 0.791903	val: 0.633041	test: 0.615866
PRC train: 0.758317	val: 0.671387	test: 0.643910

Epoch: 39
Loss: 0.44083504149855274
ROC train: 0.793505	val: 0.621250	test: 0.611352
PRC train: 0.760278	val: 0.668044	test: 0.636595

Epoch: 40
Loss: 0.4379698361925781
ROC train: 0.796086	val: 0.629887	test: 0.603785
PRC train: 0.761510	val: 0.668736	test: 0.629866

Epoch: 41
Loss: 0.4441245592050933
ROC train: 0.798975	val: 0.629849	test: 0.610666
PRC train: 0.764177	val: 0.665902	test: 0.636736

Epoch: 42
Loss: 0.4373406206014317
ROC train: 0.800467	val: 0.622588	test: 0.622630
PRC train: 0.767702	val: 0.665609	test: 0.639752

Epoch: 43
Loss: 0.4404516105459571
ROC train: 0.804836	val: 0.622942	test: 0.636382
PRC train: 0.771439	val: 0.669765	test: 0.640729

Epoch: 44
Loss: 0.43178641784842586
ROC train: 0.798993	val: 0.617111	test: 0.629509
PRC train: 0.763974	val: 0.667966	test: 0.644527

Epoch: 45
Loss: 0.432287259090869
ROC train: 0.801339	val: 0.619548	test: 0.621243
PRC train: 0.766031	val: 0.663914	test: 0.637469

Epoch: 46
Loss: 0.4345538685360153
ROC train: 0.808910	val: 0.623159	test: 0.611177
PRC train: 0.771544	val: 0.665832	test: 0.638052

Epoch: 47
Loss: 0.4335035692269453
ROC train: 0.810445	val: 0.622510	test: 0.608828
PRC train: 0.774549	val: 0.667680	test: 0.633471

Epoch: 48
Loss: 0.42480378717240574
ROC train: 0.814563	val: 0.627818	test: 0.612168
PRC train: 0.776855	val: 0.670359	test: 0.630366

Epoch: 49
Loss: 0.42711385823159487
ROC train: 0.815927	val: 0.621766	test: 0.610431
PRC train: 0.778323	val: 0.669551	test: 0.629261

Epoch: 50
Loss: 0.43215787003290007
ROC train: 0.812023	val: 0.612158	test: 0.616348
PRC train: 0.774706	val: 0.662039	test: 0.635433

Epoch: 51
Loss: 0.42576754341882017
ROC train: 0.816683	val: 0.615960	test: 0.616537
PRC train: 0.778349	val: 0.665080	test: 0.635735

Epoch: 52
Loss: 0.42342866058962497
ROC train: 0.814308	val: 0.605916	test: 0.613431
PRC train: 0.780213	val: 0.666273	test: 0.635673

Epoch: 53
Loss: 0.4275967107261044
ROC train: 0.818178	val: 0.613477	test: 0.633708
PRC train: 0.784144	val: 0.666095	test: 0.648299

Epoch: 54
Loss: 0.4315476088605119
ROC train: 0.821279	val: 0.630238	test: 0.634672
PRC train: 0.785900	val: 0.671007	test: 0.646468

Epoch: 55
Loss: 0.42091275151847746
ROC train: 0.817297	val: 0.620516	test: 0.618621
PRC train: 0.781305	val: 0.668217	test: 0.637801

Epoch: 56
Loss: 0.4204795191305267
ROC train: 0.818672	val: 0.616944	test: 0.608242
PRC train: 0.782079	val: 0.664218	test: 0.633017

Epoch: 57
Loss: 0.42282901288191743
ROC train: 0.824128	val: 0.629761	test: 0.603227
PRC train: 0.785222	val: 0.673594	test: 0.631605

Epoch: 58
Loss: 0.41629402791353637
ROC train: 0.826571	val: 0.621932	test: 0.609778
PRC train: 0.786637	val: 0.669206	test: 0.635870

Epoch: 59
Loss: 0.41883987666594197
ROC train: 0.832332	val: 0.621673	test: 0.608748
PRC train: 0.791975	val: 0.669785	test: 0.637362

Epoch: 60
Loss: 0.41657957339011353
ROC train: 0.834939	val: 0.619638	test: 0.608540
PRC train: 0.793753	val: 0.665557	test: 0.637241

Epoch: 61
Loss: 0.41556783085204296
ROC train: 0.831797	val: 0.627748	test: 0.610796
PRC train: 0.793212	val: 0.672315	test: 0.639416

Epoch: 62
Loss: 0.41015433342374463
ROC train: 0.837976	val: 0.645272	test: 0.620059
PRC train: 0.797219	val: 0.678873	test: 0.642903

Epoch: 63
Loss: 0.4100640466569104
ROC train: 0.838927	val: 0.632873	test: 0.636731
PRC train: 0.797945	val: 0.671584	test: 0.648326

Epoch: 64
Loss: 0.41202668789770724
ROC train: 0.832402	val: 0.629466	test: 0.604971
PRC train: 0.793321	val: 0.669230	test: 0.638210

Epoch: 65
Loss: 0.40956265246417534
ROC train: 0.837274	val: 0.631359	test: 0.611975
PRC train: 0.798075	val: 0.669535	test: 0.636879

Epoch: 66
Loss: 0.41524708936818505
ROC train: 0.842395	val: 0.624724	test: 0.618880
PRC train: 0.803146	val: 0.669911	test: 0.638766

Epoch: 67
Loss: 0.4115310899806047
ROC train: 0.840698	val: 0.627235	test: 0.597660
PRC train: 0.800951	val: 0.674621	test: 0.633474

Epoch: 68
Loss: 0.4080415933445856
ROC train: 0.847709	val: 0.625912	test: 0.596713
PRC train: 0.805366	val: 0.672200	test: 0.632013

Epoch: 69
Loss: 0.41090447230859295
ROC train: 0.847821	val: 0.620831	test: 0.609887
PRC train: 0.805485	val: 0.669915	test: 0.640364

Epoch: 70
Loss: 0.39857896563905193
ROC train: 0.850073	val: 0.627798	test: 0.605107
PRC train: 0.808324	val: 0.670344	test: 0.637989

Epoch: 71
Loss: 0.40433302082936773
ROC train: 0.852828	val: 0.632093	test: 0.610232
PRC train: 0.810120	val: 0.671502	test: 0.638952

Epoch: 72
Loss: 0.4029960052965169
ROC train: 0.854090	val: 0.627207	test: 0.621551
PRC train: 0.811473	val: 0.670788	test: 0.646584

Epoch: 73
Loss: 0.4010246763319613
ROC train: 0.855981	val: 0.621886	test: 0.616690
PRC train: 0.813988	val: 0.665972	test: 0.642940

Epoch: 74
Loss: 0.40114158698101543
ROC train: 0.853560	val: 0.620134	test: 0.607272
PRC train: 0.809828	val: 0.669791	test: 0.641946

Epoch: 75
Loss: 0.4008852726546726
ROC train: 0.855406	val: 0.604842	test: 0.610747
PRC train: 0.813926	val: 0.668899	test: 0.640602

Epoch: 76
Loss: 0.40565819532455416
ROC train: 0.856652	val: 0.612015	test: 0.602301
PRC train: 0.812839	val: 0.664971	test: 0.640477

Epoch: 77
Loss: 0.39803033415796424
ROC train: 0.857069	val: 0.616126	test: 0.601575
PRC train: 0.814622	val: 0.668395	test: 0.641341

Epoch: 78
Loss: 0.39836392276807475
ROC train: 0.861765	val: 0.619142	test: 0.619789
PRC train: 0.821107	val: 0.668701	test: 0.647205

Epoch: 79
Loss: 0.3943006781411943
ROC train: 0.863009	val: 0.621411	test: 0.613386
PRC train: 0.821474	val: 0.671286	test: 0.641742

Epoch: 80
Loss: 0.3941129710857947
ROC train: 0.864001	val: 0.610971	test: 0.609485
PRC train: 0.823419	val: 0.670688	test: 0.641129

Epoch: 81
Loss: 0.3945251599723135
ROC train: 0.866041	val: 0.614015	test: 0.599881
PRC train: 0.824688	val: 0.666664	test: 0.639434

Epoch: 82
Loss: 0.39358646430606997
ROC train: 0.864976	val: 0.620945	test: 0.583002
PRC train: 0.822919	val: 0.669178	test: 0.631197

Epoch: 83
Loss: 0.39208589753981393
ROC train: 0.862842	val: 0.612416	test: 0.605584
PRC train: 0.820054	val: 0.668179	test: 0.639273

Epoch: 84
Loss: 0.39673736097243045
ROC train: 0.868980	val: 0.609920	test: 0.591618
PRC train: 0.826746	val: 0.667393	test: 0.628125

Epoch: 85
Loss: 0.3913570931116338
ROC train: 0.870764	val: 0.617579	test: 0.593382
PRC train: 0.829680	val: 0.672766	test: 0.635725

Epoch: 86
Loss: 0.3873540694397373
ROC train: 0.870012	val: 0.622409	test: 0.599171
PRC train: 0.828481	val: 0.673681	test: 0.640120

Epoch: 87
Loss: 0.38875087216236104
ROC train: 0.868599	val: 0.634229	test: 0.590741
PRC train: 0.825765	val: 0.679776	test: 0.637910

Epoch: 88
Loss: 0.38896672233591423
ROC train: 0.874861	val: 0.614206	test: 0.607312
PRC train: 0.832510	val: 0.671140	test: 0.640939

Epoch: 89
Loss: 0.38516179920413673
ROC train: 0.872699	val: 0.614491	test: 0.602246
PRC train: 0.829342	val: 0.668770	test: 0.639393

Epoch: 90
Loss: 0.3817227623229087
ROC train: 0.873861	val: 0.623621	test: 0.598385
PRC train: 0.830646	val: 0.669463	test: 0.637361

Epoch: 91
Loss: 0.3817629068173326
ROC train: 0.877421	val: 0.626943	test: 0.625421
PRC train: 0.836199	val: 0.674194	test: 0.649940

Epoch: 92
Loss: 0.38171243539271404
ROC train: 0.880070	val: 0.627505	test: 0.614296
PRC train: 0.837096	val: 0.676317	test: 0.645130

Epoch: 93
Loss: 0.38098560095748757
ROC train: 0.880605	val: 0.630868	test: 0.578401
PRC train: 0.837599	val: 0.676861	test: 0.631036

Epoch: 94
Loss: 0.37974320686476337
ROC train: 0.772345	val: 0.609177	test: 0.597000
PRC train: 0.745034	val: 0.653209	test: 0.623631

Epoch: 34
Loss: 0.4503297703531075
ROC train: 0.782240	val: 0.618060	test: 0.596885
PRC train: 0.750403	val: 0.658564	test: 0.626193

Epoch: 35
Loss: 0.4465979714197828
ROC train: 0.780386	val: 0.604472	test: 0.606778
PRC train: 0.750607	val: 0.654564	test: 0.629999

Epoch: 36
Loss: 0.4478845089024621
ROC train: 0.784757	val: 0.600360	test: 0.608570
PRC train: 0.751827	val: 0.650756	test: 0.626935

Epoch: 37
Loss: 0.44673449428823064
ROC train: 0.788273	val: 0.601527	test: 0.614615
PRC train: 0.754355	val: 0.656533	test: 0.631698

Epoch: 38
Loss: 0.44248761522738966
ROC train: 0.792312	val: 0.595643	test: 0.617865
PRC train: 0.758589	val: 0.653771	test: 0.636241

Epoch: 39
Loss: 0.43831342006224716
ROC train: 0.796338	val: 0.607074	test: 0.613320
PRC train: 0.763559	val: 0.656810	test: 0.638838

Epoch: 40
Loss: 0.4440311777873417
ROC train: 0.794008	val: 0.605825	test: 0.611692
PRC train: 0.760445	val: 0.656832	test: 0.635074

Epoch: 41
Loss: 0.4342527483225246
ROC train: 0.786610	val: 0.613397	test: 0.589086
PRC train: 0.752190	val: 0.662354	test: 0.625498

Epoch: 42
Loss: 0.437159455265585
ROC train: 0.794104	val: 0.613839	test: 0.602326
PRC train: 0.757981	val: 0.659718	test: 0.630921

Epoch: 43
Loss: 0.4390822432981524
ROC train: 0.800105	val: 0.613401	test: 0.603076
PRC train: 0.763130	val: 0.661813	test: 0.633487

Epoch: 44
Loss: 0.42981663960182814
ROC train: 0.804740	val: 0.603265	test: 0.611547
PRC train: 0.767692	val: 0.656329	test: 0.632358

Epoch: 45
Loss: 0.4344159248692785
ROC train: 0.808340	val: 0.601780	test: 0.620858
PRC train: 0.772147	val: 0.661133	test: 0.638574

Epoch: 46
Loss: 0.4319723260559979
ROC train: 0.812419	val: 0.609757	test: 0.617866
PRC train: 0.775962	val: 0.664505	test: 0.640935

Epoch: 47
Loss: 0.43352592461554507
ROC train: 0.812755	val: 0.608728	test: 0.613284
PRC train: 0.778646	val: 0.660480	test: 0.639049

Epoch: 48
Loss: 0.43277705037374314
ROC train: 0.812739	val: 0.607719	test: 0.612755
PRC train: 0.776633	val: 0.658035	test: 0.638139

Epoch: 49
Loss: 0.42678189901713254
ROC train: 0.809722	val: 0.594885	test: 0.619383
PRC train: 0.772664	val: 0.657380	test: 0.640445

Epoch: 50
Loss: 0.42561393999109487
ROC train: 0.815490	val: 0.596216	test: 0.623057
PRC train: 0.779039	val: 0.654189	test: 0.641142

Epoch: 51
Loss: 0.4242405162743495
ROC train: 0.808862	val: 0.589673	test: 0.623563
PRC train: 0.772690	val: 0.650334	test: 0.638349

Epoch: 52
Loss: 0.42590337439880344
ROC train: 0.824226	val: 0.596407	test: 0.616558
PRC train: 0.784069	val: 0.656584	test: 0.641045

Epoch: 53
Loss: 0.4249506164756253
ROC train: 0.822366	val: 0.587937	test: 0.611609
PRC train: 0.786522	val: 0.654174	test: 0.635116

Epoch: 54
Loss: 0.42159607521018616
ROC train: 0.823323	val: 0.597990	test: 0.609842
PRC train: 0.786059	val: 0.659012	test: 0.642227

Epoch: 55
Loss: 0.4275113575437435
ROC train: 0.824754	val: 0.611396	test: 0.601497
PRC train: 0.786672	val: 0.664355	test: 0.632941

Epoch: 56
Loss: 0.4178720514911749
ROC train: 0.826946	val: 0.597810	test: 0.605562
PRC train: 0.789830	val: 0.660456	test: 0.637476

Epoch: 57
Loss: 0.418121776393094
ROC train: 0.826408	val: 0.605923	test: 0.596865
PRC train: 0.788689	val: 0.663816	test: 0.634995

Epoch: 58
Loss: 0.41756995886717113
ROC train: 0.833936	val: 0.609711	test: 0.607753
PRC train: 0.794195	val: 0.665364	test: 0.642615

Epoch: 59
Loss: 0.41703248544678406
ROC train: 0.827104	val: 0.596987	test: 0.610720
PRC train: 0.787976	val: 0.656665	test: 0.643259

Epoch: 60
Loss: 0.42151615056622366
ROC train: 0.837583	val: 0.599703	test: 0.593396
PRC train: 0.796813	val: 0.660089	test: 0.634622

Epoch: 61
Loss: 0.414066967070978
ROC train: 0.831913	val: 0.603825	test: 0.599616
PRC train: 0.791953	val: 0.660204	test: 0.639016

Epoch: 62
Loss: 0.41641452065840234
ROC train: 0.838662	val: 0.593218	test: 0.612198
PRC train: 0.798194	val: 0.656537	test: 0.649864

Epoch: 63
Loss: 0.4084387986597566
ROC train: 0.840538	val: 0.602910	test: 0.600922
PRC train: 0.799908	val: 0.664609	test: 0.636919

Epoch: 64
Loss: 0.4086583378702316
ROC train: 0.836171	val: 0.600820	test: 0.610094
PRC train: 0.798993	val: 0.661625	test: 0.637063

Epoch: 65
Loss: 0.4072945690819928
ROC train: 0.841920	val: 0.612703	test: 0.593888
PRC train: 0.801402	val: 0.664469	test: 0.635814

Epoch: 66
Loss: 0.4069456509639993
ROC train: 0.842248	val: 0.603321	test: 0.598023
PRC train: 0.802638	val: 0.661008	test: 0.640862

Epoch: 67
Loss: 0.41111353781262067
ROC train: 0.846832	val: 0.590195	test: 0.601724
PRC train: 0.805333	val: 0.663029	test: 0.638427

Epoch: 68
Loss: 0.407238316540551
ROC train: 0.847279	val: 0.606658	test: 0.607317
PRC train: 0.806057	val: 0.668012	test: 0.644363

Epoch: 69
Loss: 0.4107357726404081
ROC train: 0.845189	val: 0.595311	test: 0.615066
PRC train: 0.807382	val: 0.659713	test: 0.646847

Epoch: 70
Loss: 0.40711486436370503
ROC train: 0.846099	val: 0.613967	test: 0.615551
PRC train: 0.804602	val: 0.671099	test: 0.650500

Epoch: 71
Loss: 0.40730919755573697
ROC train: 0.847546	val: 0.606853	test: 0.608726
PRC train: 0.805537	val: 0.670680	test: 0.647463

Epoch: 72
Loss: 0.4067562305454019
ROC train: 0.846313	val: 0.592876	test: 0.603545
PRC train: 0.807913	val: 0.664005	test: 0.639375

Epoch: 73
Loss: 0.4029770832310014
ROC train: 0.851465	val: 0.611015	test: 0.599495
PRC train: 0.813450	val: 0.669380	test: 0.640150

Epoch: 74
Loss: 0.4002777450349041
ROC train: 0.856133	val: 0.607015	test: 0.608763
PRC train: 0.818504	val: 0.661582	test: 0.644029

Epoch: 75
Loss: 0.4046144543196151
ROC train: 0.856680	val: 0.595110	test: 0.607537
PRC train: 0.818861	val: 0.658192	test: 0.644060

Epoch: 76
Loss: 0.396905871228443
ROC train: 0.856828	val: 0.603311	test: 0.600068
PRC train: 0.812873	val: 0.663650	test: 0.638515

Epoch: 77
Loss: 0.39290263711545803
ROC train: 0.855536	val: 0.606486	test: 0.600642
PRC train: 0.813540	val: 0.662635	test: 0.644133

Epoch: 78
Loss: 0.3963649753432586
ROC train: 0.859010	val: 0.608153	test: 0.591718
PRC train: 0.818441	val: 0.665892	test: 0.640802

Epoch: 79
Loss: 0.3938917341801865
ROC train: 0.859660	val: 0.589387	test: 0.609387
PRC train: 0.819767	val: 0.660007	test: 0.647664

Epoch: 80
Loss: 0.39417030402875747
ROC train: 0.861011	val: 0.591012	test: 0.598480
PRC train: 0.816655	val: 0.661304	test: 0.642586

Epoch: 81
Loss: 0.3951121955547124
ROC train: 0.866588	val: 0.611660	test: 0.590190
PRC train: 0.824955	val: 0.671161	test: 0.635228

Epoch: 82
Loss: 0.39442168949156964
ROC train: 0.866062	val: 0.612348	test: 0.606793
PRC train: 0.826090	val: 0.667767	test: 0.647257

Epoch: 83
Loss: 0.3882467043671166
ROC train: 0.867968	val: 0.597328	test: 0.598438
PRC train: 0.828133	val: 0.664141	test: 0.643374

Epoch: 84
Loss: 0.39457721256822165
ROC train: 0.868463	val: 0.595224	test: 0.603480
PRC train: 0.827901	val: 0.664321	test: 0.640364

Epoch: 85
Loss: 0.39069296913812845
ROC train: 0.865386	val: 0.605666	test: 0.611710
PRC train: 0.825193	val: 0.668589	test: 0.644413

Epoch: 86
Loss: 0.3898765163498954
ROC train: 0.870755	val: 0.600285	test: 0.618247
PRC train: 0.829634	val: 0.663037	test: 0.647260

Epoch: 87
Loss: 0.3853890650290913
ROC train: 0.873746	val: 0.611831	test: 0.601257
PRC train: 0.832211	val: 0.671943	test: 0.639337

Epoch: 88
Loss: 0.3895489897129808
ROC train: 0.873953	val: 0.616416	test: 0.606375
PRC train: 0.833881	val: 0.675007	test: 0.639716

Epoch: 89
Loss: 0.387606476544732
ROC train: 0.874425	val: 0.607755	test: 0.603385
PRC train: 0.834541	val: 0.671045	test: 0.639507

Epoch: 90
Loss: 0.3843166788063628
ROC train: 0.873447	val: 0.612688	test: 0.588596
PRC train: 0.833789	val: 0.671048	test: 0.634044

Epoch: 91
Loss: 0.3855902453789057
ROC train: 0.875078	val: 0.606122	test: 0.608348
PRC train: 0.835761	val: 0.670283	test: 0.647579

Epoch: 92
Loss: 0.3840852172054817
ROC train: 0.877292	val: 0.600309	test: 0.609529
PRC train: 0.836890	val: 0.670636	test: 0.642465

Epoch: 93
Loss: 0.3839797521294285
ROC train: 0.877800	val: 0.602598	test: 0.601773
PRC train: 0.836564	val: 0.673509	test: 0.636561

Epoch: 94
Loss: 0.38006952539016414
ROC train: 0.878151	val: 0.609788	test: 0.592966
ROC train: 0.880662	val: 0.563943	test: 0.573782
PRC train: 0.831618	val: 0.633685	test: 0.631232

Epoch: 95
Loss: 0.376359207585505
ROC train: 0.880866	val: 0.564238	test: 0.577296
PRC train: 0.830556	val: 0.631453	test: 0.633048

Epoch: 96
Loss: 0.36705789011264
ROC train: 0.882051	val: 0.562969	test: 0.582516
PRC train: 0.833001	val: 0.627151	test: 0.633424

Epoch: 97
Loss: 0.3718069038579948
ROC train: 0.887832	val: 0.568493	test: 0.577447
PRC train: 0.839336	val: 0.629789	test: 0.628755

Epoch: 98
Loss: 0.3721174508853226
ROC train: 0.886716	val: 0.572640	test: 0.575586
PRC train: 0.839391	val: 0.635202	test: 0.628110

Epoch: 99
Loss: 0.37188397015127217
ROC train: 0.886492	val: 0.565800	test: 0.577809
PRC train: 0.837206	val: 0.632545	test: 0.632032

Epoch: 100
Loss: 0.37623495058724266
ROC train: 0.885629	val: 0.563199	test: 0.578949
PRC train: 0.837842	val: 0.632109	test: 0.632415

Epoch: 101
Loss: 0.37371456198392455
ROC train: 0.888241	val: 0.559365	test: 0.581549
PRC train: 0.842062	val: 0.627713	test: 0.630210

Epoch: 102
Loss: 0.36755712400982377
ROC train: 0.889150	val: 0.551714	test: 0.582281
PRC train: 0.846094	val: 0.622240	test: 0.631018

Epoch: 103
Loss: 0.36925238318490017
ROC train: 0.891159	val: 0.549566	test: 0.583863
PRC train: 0.841312	val: 0.620664	test: 0.634218

Epoch: 104
Loss: 0.36931435730573026
ROC train: 0.889770	val: 0.556453	test: 0.581552
PRC train: 0.836934	val: 0.626092	test: 0.633032

Epoch: 105
Loss: 0.3650364103820992
ROC train: 0.891790	val: 0.559686	test: 0.582241
PRC train: 0.840376	val: 0.628197	test: 0.633932

Epoch: 106
Loss: 0.3746028405689924
ROC train: 0.890916	val: 0.555988	test: 0.582412
PRC train: 0.848895	val: 0.627684	test: 0.635041

Epoch: 107
Loss: 0.3635089361464653
ROC train: 0.895522	val: 0.560153	test: 0.579532
PRC train: 0.853132	val: 0.631012	test: 0.633544

Epoch: 108
Loss: 0.36234222799805904
ROC train: 0.892575	val: 0.565098	test: 0.583725
PRC train: 0.851377	val: 0.633318	test: 0.636609

Epoch: 109
Loss: 0.363308269651387
ROC train: 0.897013	val: 0.566897	test: 0.592880
PRC train: 0.850141	val: 0.632668	test: 0.643216

Epoch: 110
Loss: 0.3717243781888063
ROC train: 0.892342	val: 0.565725	test: 0.596077
PRC train: 0.846531	val: 0.630915	test: 0.642186

Epoch: 111
Loss: 0.3610602153064054
ROC train: 0.895488	val: 0.563038	test: 0.586964
PRC train: 0.847928	val: 0.628695	test: 0.636434

Epoch: 112
Loss: 0.3615779129490272
ROC train: 0.897268	val: 0.558821	test: 0.578650
PRC train: 0.850564	val: 0.627743	test: 0.634805

Epoch: 113
Loss: 0.3651182142441007
ROC train: 0.900577	val: 0.559002	test: 0.579038
PRC train: 0.855297	val: 0.629663	test: 0.634783

Epoch: 114
Loss: 0.36349450378532294
ROC train: 0.900407	val: 0.558711	test: 0.583587
PRC train: 0.854320	val: 0.627858	test: 0.635576

Epoch: 115
Loss: 0.3567060529356167
ROC train: 0.902741	val: 0.562441	test: 0.584179
PRC train: 0.859412	val: 0.628092	test: 0.634476

Epoch: 116
Loss: 0.35408119634578106
ROC train: 0.902373	val: 0.563084	test: 0.577933
PRC train: 0.857810	val: 0.630396	test: 0.630402

Epoch: 117
Loss: 0.35774354286326404
ROC train: 0.904333	val: 0.565225	test: 0.574075
PRC train: 0.860357	val: 0.633041	test: 0.629655

Epoch: 118
Loss: 0.35530965809294784
ROC train: 0.905209	val: 0.565717	test: 0.577065
PRC train: 0.863911	val: 0.633441	test: 0.632089

Epoch: 119
Loss: 0.3552723550070222
ROC train: 0.907288	val: 0.566167	test: 0.584024
PRC train: 0.864047	val: 0.631131	test: 0.635927

Epoch: 120
Loss: 0.35036252488902764
ROC train: 0.907294	val: 0.565835	test: 0.594024
PRC train: 0.862326	val: 0.630206	test: 0.640976

Early stopping
Best (ROC):	 train: 0.770617	val: 0.578934	test: 0.593132
Best (PRC):	 train: 0.731552	val: 0.630299	test: 0.631464

ROC train: 0.879997	val: 0.553315	test: 0.587033
PRC train: 0.833641	val: 0.630029	test: 0.636110

Epoch: 95
Loss: 0.37626559818318406
ROC train: 0.883452	val: 0.556224	test: 0.593961
PRC train: 0.837515	val: 0.630654	test: 0.639926

Epoch: 96
Loss: 0.37373241120472
ROC train: 0.886852	val: 0.561126	test: 0.595513
PRC train: 0.839135	val: 0.631644	test: 0.639764

Epoch: 97
Loss: 0.3793404135256255
ROC train: 0.883205	val: 0.560118	test: 0.589713
PRC train: 0.834641	val: 0.631369	test: 0.635972

Epoch: 98
Loss: 0.3731916427608604
ROC train: 0.884722	val: 0.556210	test: 0.583319
PRC train: 0.835835	val: 0.629449	test: 0.634154

Epoch: 99
Loss: 0.3681077851077039
ROC train: 0.886848	val: 0.550581	test: 0.585515
PRC train: 0.837818	val: 0.626911	test: 0.635022

Epoch: 100
Loss: 0.36915866180525503
ROC train: 0.888813	val: 0.551817	test: 0.587782
PRC train: 0.840939	val: 0.628349	test: 0.637277

Epoch: 101
Loss: 0.3670475934702969
ROC train: 0.886109	val: 0.558065	test: 0.589292
PRC train: 0.839194	val: 0.631190	test: 0.637901

Epoch: 102
Loss: 0.3627126330850807
ROC train: 0.880946	val: 0.558317	test: 0.586828
PRC train: 0.831962	val: 0.630698	test: 0.634649

Epoch: 103
Loss: 0.36791853219643667
ROC train: 0.886443	val: 0.551646	test: 0.584140
PRC train: 0.839656	val: 0.627092	test: 0.635613

Epoch: 104
Loss: 0.36537811418270116
ROC train: 0.888826	val: 0.550768	test: 0.590621
PRC train: 0.845233	val: 0.627543	test: 0.637161

Epoch: 105
Loss: 0.3739351772795032
ROC train: 0.891451	val: 0.552704	test: 0.588135
PRC train: 0.845311	val: 0.628327	test: 0.638537

Epoch: 106
Loss: 0.36051634925490544
ROC train: 0.889667	val: 0.557149	test: 0.587363
PRC train: 0.845606	val: 0.631719	test: 0.638059

Epoch: 107
Loss: 0.37002246369204583
ROC train: 0.896226	val: 0.556390	test: 0.594703
PRC train: 0.854674	val: 0.631882	test: 0.641944

Epoch: 108
Loss: 0.3641986735608702
ROC train: 0.893774	val: 0.553092	test: 0.598365
PRC train: 0.847135	val: 0.631332	test: 0.644638

Epoch: 109
Loss: 0.358078439378604
ROC train: 0.893284	val: 0.549401	test: 0.590377
PRC train: 0.845348	val: 0.627358	test: 0.642112

Epoch: 110
Loss: 0.3650089447449325
ROC train: 0.892874	val: 0.556529	test: 0.582617
PRC train: 0.847052	val: 0.630245	test: 0.637309

Epoch: 111
Loss: 0.36537006054948773
ROC train: 0.888860	val: 0.563650	test: 0.578007
PRC train: 0.843338	val: 0.633769	test: 0.634583

Epoch: 112
Loss: 0.3611449866575067
ROC train: 0.891887	val: 0.558215	test: 0.579636
PRC train: 0.847040	val: 0.628267	test: 0.635102

Epoch: 113
Loss: 0.3617467673773713
ROC train: 0.897282	val: 0.558450	test: 0.589999
PRC train: 0.850855	val: 0.631597	test: 0.639997

Epoch: 114
Loss: 0.3586449113230918
ROC train: 0.897032	val: 0.561272	test: 0.594166
PRC train: 0.852592	val: 0.634231	test: 0.640383

Epoch: 115
Loss: 0.3532371201667993
ROC train: 0.900879	val: 0.550565	test: 0.591129
PRC train: 0.858061	val: 0.627276	test: 0.640571

Epoch: 116
Loss: 0.3503943070636617
ROC train: 0.901536	val: 0.555424	test: 0.588273
PRC train: 0.859911	val: 0.630829	test: 0.637203

Epoch: 117
Loss: 0.36056522658775314
ROC train: 0.899389	val: 0.561778	test: 0.584123
PRC train: 0.858185	val: 0.635692	test: 0.633573

Epoch: 118
Loss: 0.355196495270954
ROC train: 0.903620	val: 0.552256	test: 0.579684
PRC train: 0.859864	val: 0.629567	test: 0.633329

Epoch: 119
Loss: 0.35809863764244465
ROC train: 0.904034	val: 0.547407	test: 0.578186
PRC train: 0.860409	val: 0.626432	test: 0.633676

Epoch: 120
Loss: 0.3505224718827912
ROC train: 0.903263	val: 0.556074	test: 0.588209
PRC train: 0.861686	val: 0.630600	test: 0.634527

Early stopping
Best (ROC):	 train: 0.754076	val: 0.570691	test: 0.600380
Best (PRC):	 train: 0.716661	val: 0.632507	test: 0.632557

ROC train: 0.885712	val: 0.573389	test: 0.628380
PRC train: 0.840206	val: 0.649315	test: 0.656365

Epoch: 95
Loss: 0.37745839837982076
ROC train: 0.884610	val: 0.573411	test: 0.639564
PRC train: 0.838995	val: 0.647912	test: 0.659306

Epoch: 96
Loss: 0.37404017771959164
ROC train: 0.885800	val: 0.574930	test: 0.630524
PRC train: 0.842421	val: 0.651396	test: 0.656718

Epoch: 97
Loss: 0.37878837057719617
ROC train: 0.885699	val: 0.571630	test: 0.619197
PRC train: 0.844630	val: 0.652864	test: 0.647405

Epoch: 98
Loss: 0.3800324091704268
ROC train: 0.883707	val: 0.571667	test: 0.620026
PRC train: 0.843210	val: 0.650050	test: 0.646616

Epoch: 99
Loss: 0.37734988405138936
ROC train: 0.890324	val: 0.573447	test: 0.617577
PRC train: 0.847492	val: 0.648917	test: 0.648002

Epoch: 100
Loss: 0.37757948868816893
ROC train: 0.886716	val: 0.577171	test: 0.601493
PRC train: 0.846876	val: 0.653098	test: 0.638008

Epoch: 101
Loss: 0.3758145163643289
ROC train: 0.883283	val: 0.576554	test: 0.620472
PRC train: 0.842931	val: 0.652461	test: 0.648253

Epoch: 102
Loss: 0.37331259622064855
ROC train: 0.886911	val: 0.574032	test: 0.637959
PRC train: 0.843301	val: 0.646451	test: 0.653764

Epoch: 103
Loss: 0.3754353181265645
ROC train: 0.888792	val: 0.565585	test: 0.624747
PRC train: 0.846126	val: 0.643980	test: 0.652009

Epoch: 104
Loss: 0.37387435452176376
ROC train: 0.889354	val: 0.566497	test: 0.619723
PRC train: 0.849822	val: 0.644714	test: 0.647375

Epoch: 105
Loss: 0.36393881751635687
ROC train: 0.889727	val: 0.571053	test: 0.620470
PRC train: 0.847553	val: 0.646302	test: 0.643448

Epoch: 106
Loss: 0.36501397848117995
ROC train: 0.891666	val: 0.574552	test: 0.627659
PRC train: 0.849430	val: 0.648031	test: 0.649863

Epoch: 107
Loss: 0.3607543358914202
ROC train: 0.894364	val: 0.567255	test: 0.622647
PRC train: 0.855485	val: 0.646921	test: 0.650826

Epoch: 108
Loss: 0.36748752491151676
ROC train: 0.897127	val: 0.568514	test: 0.615031
PRC train: 0.860243	val: 0.650615	test: 0.649593

Epoch: 109
Loss: 0.3652541154787443
ROC train: 0.895351	val: 0.570749	test: 0.613925
PRC train: 0.857545	val: 0.648688	test: 0.646265

Epoch: 110
Loss: 0.3584818116026239
ROC train: 0.895169	val: 0.566761	test: 0.620066
PRC train: 0.855292	val: 0.644183	test: 0.649306

Epoch: 111
Loss: 0.3646411072897199
ROC train: 0.898368	val: 0.571323	test: 0.622015
PRC train: 0.861478	val: 0.645220	test: 0.645557

Epoch: 112
Loss: 0.3586702425999617
ROC train: 0.901035	val: 0.570808	test: 0.616614
PRC train: 0.861057	val: 0.650723	test: 0.642235

Epoch: 113
Loss: 0.36101259758119664
ROC train: 0.901158	val: 0.566444	test: 0.629446
PRC train: 0.861830	val: 0.646137	test: 0.653554

Epoch: 114
Loss: 0.36440417717843493
ROC train: 0.903701	val: 0.581811	test: 0.630845
PRC train: 0.867080	val: 0.654066	test: 0.650004

Epoch: 115
Loss: 0.35735107941071487
ROC train: 0.904595	val: 0.582201	test: 0.633084
PRC train: 0.866885	val: 0.654441	test: 0.652316

Epoch: 116
Loss: 0.3573977414381267
ROC train: 0.903483	val: 0.571992	test: 0.624250
PRC train: 0.866424	val: 0.650101	test: 0.651056

Epoch: 117
Loss: 0.3585789495956115
ROC train: 0.905110	val: 0.574446	test: 0.630669
PRC train: 0.863734	val: 0.650381	test: 0.651108

Epoch: 118
Loss: 0.3565804996373688
ROC train: 0.905062	val: 0.572080	test: 0.632555
PRC train: 0.864339	val: 0.650892	test: 0.653832

Epoch: 119
Loss: 0.35338405730454325
ROC train: 0.905511	val: 0.569678	test: 0.613065
PRC train: 0.866469	val: 0.650785	test: 0.646241

Epoch: 120
Loss: 0.3547762081993473
ROC train: 0.908143	val: 0.569010	test: 0.616451
PRC train: 0.871741	val: 0.646099	test: 0.648362

Early stopping
Best (ROC):	 train: 0.791582	val: 0.602777	test: 0.611286
Best (PRC):	 train: 0.756312	val: 0.660298	test: 0.626841

ROC train: 0.885520	val: 0.547814	test: 0.635070
PRC train: 0.844223	val: 0.644625	test: 0.649667

Epoch: 95
Loss: 0.37370837733410905
ROC train: 0.886218	val: 0.545944	test: 0.632924
PRC train: 0.844862	val: 0.644441	test: 0.647696

Epoch: 96
Loss: 0.3751289138777781
ROC train: 0.888609	val: 0.548247	test: 0.633478
PRC train: 0.846300	val: 0.646627	test: 0.645042

Epoch: 97
Loss: 0.3774015954915695
ROC train: 0.889055	val: 0.553307	test: 0.636695
PRC train: 0.846767	val: 0.649990	test: 0.649861

Epoch: 98
Loss: 0.376549875211237
ROC train: 0.886661	val: 0.556017	test: 0.628848
PRC train: 0.848077	val: 0.652393	test: 0.642550

Epoch: 99
Loss: 0.37621223997319303
ROC train: 0.886400	val: 0.545883	test: 0.617920
PRC train: 0.845659	val: 0.643556	test: 0.640103

Epoch: 100
Loss: 0.37285025755680573
ROC train: 0.891861	val: 0.553992	test: 0.628583
PRC train: 0.853603	val: 0.644503	test: 0.643889

Epoch: 101
Loss: 0.366595109707608
ROC train: 0.888716	val: 0.550769	test: 0.624382
PRC train: 0.850349	val: 0.642306	test: 0.645404

Epoch: 102
Loss: 0.36876381555847887
ROC train: 0.893174	val: 0.547266	test: 0.619506
PRC train: 0.851649	val: 0.641670	test: 0.644296

Epoch: 103
Loss: 0.37015756004551115
ROC train: 0.893255	val: 0.552204	test: 0.625678
PRC train: 0.851653	val: 0.643630	test: 0.647319

Epoch: 104
Loss: 0.36531000729061724
ROC train: 0.887801	val: 0.553684	test: 0.626752
PRC train: 0.844375	val: 0.643284	test: 0.647488

Epoch: 105
Loss: 0.362690575153942
ROC train: 0.892494	val: 0.552269	test: 0.625769
PRC train: 0.850662	val: 0.643517	test: 0.648179

Epoch: 106
Loss: 0.3684138805719642
ROC train: 0.897252	val: 0.552293	test: 0.630201
PRC train: 0.859248	val: 0.643844	test: 0.646591

Epoch: 107
Loss: 0.3644326509755658
ROC train: 0.898710	val: 0.554161	test: 0.628887
PRC train: 0.860859	val: 0.648001	test: 0.647794

Epoch: 108
Loss: 0.3643036525475355
ROC train: 0.898592	val: 0.555617	test: 0.635105
PRC train: 0.858797	val: 0.647616	test: 0.648941

Epoch: 109
Loss: 0.36122544212722313
ROC train: 0.899954	val: 0.558515	test: 0.637188
PRC train: 0.861299	val: 0.647753	test: 0.648894

Epoch: 110
Loss: 0.35909590177982054
ROC train: 0.902071	val: 0.555620	test: 0.630952
PRC train: 0.862829	val: 0.645259	test: 0.645603

Epoch: 111
Loss: 0.35834256408316023
ROC train: 0.901976	val: 0.558399	test: 0.638697
PRC train: 0.862719	val: 0.643166	test: 0.648233

Epoch: 112
Loss: 0.3644698385676343
ROC train: 0.902796	val: 0.557890	test: 0.629421
PRC train: 0.864619	val: 0.648402	test: 0.643955

Epoch: 113
Loss: 0.3540073112992381
ROC train: 0.901948	val: 0.549577	test: 0.622795
PRC train: 0.865902	val: 0.649784	test: 0.647245

Epoch: 114
Loss: 0.3564698412313545
ROC train: 0.902071	val: 0.554053	test: 0.630702
PRC train: 0.868485	val: 0.650138	test: 0.651363

Epoch: 115
Loss: 0.35458049483824716
ROC train: 0.905571	val: 0.555511	test: 0.632499
PRC train: 0.869738	val: 0.650216	test: 0.651713

Epoch: 116
Loss: 0.35617206752732844
ROC train: 0.907762	val: 0.558414	test: 0.628604
PRC train: 0.870081	val: 0.649160	test: 0.646406

Epoch: 117
Loss: 0.35420968085907567
ROC train: 0.903578	val: 0.562532	test: 0.621767
PRC train: 0.865874	val: 0.650776	test: 0.637361

Epoch: 118
Loss: 0.35546361032929086
ROC train: 0.903399	val: 0.556882	test: 0.625378
PRC train: 0.867671	val: 0.647836	test: 0.642761

Epoch: 119
Loss: 0.35372350076775466
ROC train: 0.907843	val: 0.557640	test: 0.625615
PRC train: 0.872362	val: 0.647795	test: 0.644294

Epoch: 120
Loss: 0.3509999597997958
ROC train: 0.906642	val: 0.548675	test: 0.616794
PRC train: 0.871524	val: 0.644251	test: 0.642774

Early stopping
Best (ROC):	 train: 0.767351	val: 0.590783	test: 0.617395
Best (PRC):	 train: 0.737984	val: 0.650422	test: 0.624838

ROC train: 0.885675	val: 0.556987	test: 0.617183
PRC train: 0.839170	val: 0.639182	test: 0.645902

Epoch: 95
Loss: 0.3727594970852479
ROC train: 0.891806	val: 0.549218	test: 0.611847
PRC train: 0.846081	val: 0.638503	test: 0.637734

Epoch: 96
Loss: 0.3658670498867774
ROC train: 0.884534	val: 0.558316	test: 0.606070
PRC train: 0.840136	val: 0.643356	test: 0.638696

Epoch: 97
Loss: 0.3684478533070008
ROC train: 0.890193	val: 0.558620	test: 0.616955
PRC train: 0.844149	val: 0.645140	test: 0.648124

Epoch: 98
Loss: 0.3708360488200693
ROC train: 0.891854	val: 0.560874	test: 0.614351
PRC train: 0.848304	val: 0.648261	test: 0.641421

Epoch: 99
Loss: 0.36805975146193026
ROC train: 0.893055	val: 0.563794	test: 0.617381
PRC train: 0.847629	val: 0.646481	test: 0.644416

Epoch: 100
Loss: 0.3648373091957296
ROC train: 0.895348	val: 0.563920	test: 0.621031
PRC train: 0.849743	val: 0.646285	test: 0.648489

Epoch: 101
Loss: 0.37025099931062894
ROC train: 0.892276	val: 0.568067	test: 0.615470
PRC train: 0.847032	val: 0.646442	test: 0.642036

Epoch: 102
Loss: 0.366472244053273
ROC train: 0.894905	val: 0.567570	test: 0.612101
PRC train: 0.848834	val: 0.647333	test: 0.646489

Epoch: 103
Loss: 0.3623720800101138
ROC train: 0.895292	val: 0.569882	test: 0.616265
PRC train: 0.850777	val: 0.652236	test: 0.644483

Epoch: 104
Loss: 0.36659130500568177
ROC train: 0.895017	val: 0.571610	test: 0.627140
PRC train: 0.849661	val: 0.649556	test: 0.643844

Epoch: 105
Loss: 0.36228952431473727
ROC train: 0.899417	val: 0.561397	test: 0.629530
PRC train: 0.857899	val: 0.646334	test: 0.651734

Epoch: 106
Loss: 0.36012321284614346
ROC train: 0.900697	val: 0.561139	test: 0.627086
PRC train: 0.857488	val: 0.647280	test: 0.648054

Epoch: 107
Loss: 0.36050257645475603
ROC train: 0.899828	val: 0.558885	test: 0.623563
PRC train: 0.855625	val: 0.647661	test: 0.648552

Epoch: 108
Loss: 0.35864552665904026
ROC train: 0.901767	val: 0.564840	test: 0.621902
PRC train: 0.858756	val: 0.648855	test: 0.649326

Epoch: 109
Loss: 0.36004174695409474
ROC train: 0.902988	val: 0.566931	test: 0.622012
PRC train: 0.861923	val: 0.650051	test: 0.647401

Epoch: 110
Loss: 0.3599587305544213
ROC train: 0.905749	val: 0.556533	test: 0.625653
PRC train: 0.864173	val: 0.643245	test: 0.648673

Epoch: 111
Loss: 0.3559324897268533
ROC train: 0.907512	val: 0.548782	test: 0.629347
PRC train: 0.864639	val: 0.639614	test: 0.652301

Epoch: 112
Loss: 0.35537956530646053
ROC train: 0.907752	val: 0.550345	test: 0.625505
PRC train: 0.864776	val: 0.638585	test: 0.649172

Epoch: 113
Loss: 0.35588545001055577
ROC train: 0.902266	val: 0.553611	test: 0.607502
PRC train: 0.860310	val: 0.642094	test: 0.635786

Epoch: 114
Loss: 0.34964433674223433
ROC train: 0.905689	val: 0.557170	test: 0.619744
PRC train: 0.866562	val: 0.643773	test: 0.642039

Epoch: 115
Loss: 0.34850730593373724
ROC train: 0.909894	val: 0.553771	test: 0.624086
PRC train: 0.868833	val: 0.642207	test: 0.649086

Epoch: 116
Loss: 0.3524493058133428
ROC train: 0.906240	val: 0.553095	test: 0.609055
PRC train: 0.867267	val: 0.641974	test: 0.643564

Epoch: 117
Loss: 0.3536468995392998
ROC train: 0.907722	val: 0.552879	test: 0.597598
PRC train: 0.871702	val: 0.644103	test: 0.644678

Epoch: 118
Loss: 0.351235433648004
ROC train: 0.908485	val: 0.554475	test: 0.604936
PRC train: 0.872178	val: 0.646067	test: 0.643026

Epoch: 119
Loss: 0.3498611384227849
ROC train: 0.908710	val: 0.567923	test: 0.614792
PRC train: 0.871362	val: 0.648162	test: 0.643190

Epoch: 120
Loss: 0.3515107535409206
ROC train: 0.913093	val: 0.568805	test: 0.631715
PRC train: 0.871203	val: 0.645133	test: 0.651245

Early stopping
Best (ROC):	 train: 0.732823	val: 0.602948	test: 0.605900
Best (PRC):	 train: 0.707402	val: 0.654064	test: 0.623939
All runs completed.

ROC train: 0.880272	val: 0.622032	test: 0.607499
PRC train: 0.837973	val: 0.677619	test: 0.643232

Epoch: 95
Loss: 0.3778664995330262
ROC train: 0.883914	val: 0.621506	test: 0.615587
PRC train: 0.842393	val: 0.674123	test: 0.649386

Epoch: 96
Loss: 0.37076381895191524
ROC train: 0.885684	val: 0.613303	test: 0.588369
PRC train: 0.843931	val: 0.667386	test: 0.637068

Epoch: 97
Loss: 0.37548023691787485
ROC train: 0.886747	val: 0.614896	test: 0.590361
PRC train: 0.845449	val: 0.669968	test: 0.633547

Epoch: 98
Loss: 0.3792701642341183
ROC train: 0.885921	val: 0.624928	test: 0.612317
PRC train: 0.845341	val: 0.669682	test: 0.642557

Epoch: 99
Loss: 0.37689284680800783
ROC train: 0.888764	val: 0.621777	test: 0.604766
PRC train: 0.845787	val: 0.668973	test: 0.643002

Epoch: 100
Loss: 0.3685162114606066
ROC train: 0.885561	val: 0.607105	test: 0.593576
PRC train: 0.843600	val: 0.667820	test: 0.637306

Epoch: 101
Loss: 0.3733174142394175
ROC train: 0.888156	val: 0.613351	test: 0.584767
PRC train: 0.846427	val: 0.670588	test: 0.633503

Epoch: 102
Loss: 0.37256281003442693
ROC train: 0.886636	val: 0.613002	test: 0.599028
PRC train: 0.846560	val: 0.666486	test: 0.638572

Epoch: 103
Loss: 0.37405396428134335
ROC train: 0.888476	val: 0.609783	test: 0.597965
PRC train: 0.847733	val: 0.664343	test: 0.636206

Epoch: 104
Loss: 0.37594959531448235
ROC train: 0.893255	val: 0.627683	test: 0.601685
PRC train: 0.851246	val: 0.676304	test: 0.635637

Epoch: 105
Loss: 0.37349276519801816
ROC train: 0.891260	val: 0.626141	test: 0.622016
PRC train: 0.848651	val: 0.674330	test: 0.646059

Epoch: 106
Loss: 0.37301569456341893
ROC train: 0.891479	val: 0.624114	test: 0.603491
PRC train: 0.850679	val: 0.677095	test: 0.638685

Epoch: 107
Loss: 0.3681005698045832
ROC train: 0.891369	val: 0.608600	test: 0.594786
PRC train: 0.848056	val: 0.670542	test: 0.632927

Epoch: 108
Loss: 0.3644109903763849
ROC train: 0.896046	val: 0.612425	test: 0.596350
PRC train: 0.854265	val: 0.669155	test: 0.634938

Epoch: 109
Loss: 0.3662317388725935
ROC train: 0.898517	val: 0.628582	test: 0.595427
PRC train: 0.856330	val: 0.673182	test: 0.636884

Epoch: 110
Loss: 0.36846900940149735
ROC train: 0.898311	val: 0.628996	test: 0.606791
PRC train: 0.857583	val: 0.675078	test: 0.640916

Epoch: 111
Loss: 0.3628870817147085
ROC train: 0.897772	val: 0.625204	test: 0.601831
PRC train: 0.857094	val: 0.676591	test: 0.640344

Epoch: 112
Loss: 0.3589747577268207
ROC train: 0.898446	val: 0.613599	test: 0.606017
PRC train: 0.857890	val: 0.668735	test: 0.647078

Epoch: 113
Loss: 0.36251307061008997
ROC train: 0.899963	val: 0.612411	test: 0.587915
PRC train: 0.858495	val: 0.669461	test: 0.639218

Epoch: 114
Loss: 0.3600371268451051
ROC train: 0.901768	val: 0.615491	test: 0.590448
PRC train: 0.862198	val: 0.674047	test: 0.632641

Epoch: 115
Loss: 0.35759588955412547
ROC train: 0.899553	val: 0.626249	test: 0.609653
PRC train: 0.861175	val: 0.675881	test: 0.638348

Epoch: 116
Loss: 0.3586161509569626
ROC train: 0.904754	val: 0.634261	test: 0.617021
PRC train: 0.863855	val: 0.680463	test: 0.648691

Epoch: 117
Loss: 0.3617129568782129
ROC train: 0.903797	val: 0.621829	test: 0.594200
PRC train: 0.862979	val: 0.677550	test: 0.636073

Epoch: 118
Loss: 0.35811292416906393
ROC train: 0.899184	val: 0.616040	test: 0.594577
PRC train: 0.858737	val: 0.676633	test: 0.633998

Epoch: 119
Loss: 0.352953520736431
ROC train: 0.906499	val: 0.623123	test: 0.604424
PRC train: 0.866252	val: 0.678338	test: 0.639318

Epoch: 120
Loss: 0.35797754799739917
ROC train: 0.899018	val: 0.632117	test: 0.602863
PRC train: 0.860006	val: 0.679171	test: 0.643315

Early stopping
Best (ROC):	 train: 0.837976	val: 0.645272	test: 0.620059
Best (PRC):	 train: 0.797219	val: 0.678873	test: 0.642903

ROC train: 0.883445	val: 0.567603	test: 0.593842
PRC train: 0.833914	val: 0.638150	test: 0.640680

Epoch: 95
Loss: 0.3834398377705017
ROC train: 0.880691	val: 0.565425	test: 0.602701
PRC train: 0.833860	val: 0.636138	test: 0.643619

Epoch: 96
Loss: 0.3749572040887212
ROC train: 0.882578	val: 0.564145	test: 0.599212
PRC train: 0.833005	val: 0.635843	test: 0.641954

Epoch: 97
Loss: 0.3814729421942043
ROC train: 0.882924	val: 0.565747	test: 0.592132
PRC train: 0.831465	val: 0.637382	test: 0.639340

Epoch: 98
Loss: 0.3687113787673807
ROC train: 0.882162	val: 0.564643	test: 0.594960
PRC train: 0.835526	val: 0.637676	test: 0.638310

Epoch: 99
Loss: 0.37049332205104046
ROC train: 0.884301	val: 0.556934	test: 0.596154
PRC train: 0.836643	val: 0.633179	test: 0.638085

Epoch: 100
Loss: 0.37903992725014246
ROC train: 0.887416	val: 0.554034	test: 0.593721
PRC train: 0.836507	val: 0.631196	test: 0.638519

Epoch: 101
Loss: 0.3756840624148314
ROC train: 0.886539	val: 0.555038	test: 0.599057
PRC train: 0.834099	val: 0.630651	test: 0.639975

Epoch: 102
Loss: 0.36957602635421305
ROC train: 0.889040	val: 0.554321	test: 0.595688
PRC train: 0.840207	val: 0.633383	test: 0.639805

Epoch: 103
Loss: 0.3661298229029183
ROC train: 0.888353	val: 0.559108	test: 0.589125
PRC train: 0.844310	val: 0.636073	test: 0.635815

Epoch: 104
Loss: 0.3700529015739425
ROC train: 0.888748	val: 0.566941	test: 0.587134
PRC train: 0.841051	val: 0.640678	test: 0.633578

Epoch: 105
Loss: 0.36553050676903376
ROC train: 0.877123	val: 0.561941	test: 0.573260
PRC train: 0.827025	val: 0.637536	test: 0.624769

Epoch: 106
Loss: 0.3724642654703528
ROC train: 0.887993	val: 0.563807	test: 0.581217
PRC train: 0.839204	val: 0.637385	test: 0.632022

Epoch: 107
Loss: 0.37094440714399
ROC train: 0.886289	val: 0.568835	test: 0.588995
PRC train: 0.842001	val: 0.641575	test: 0.636864

Epoch: 108
Loss: 0.3668545618760721
ROC train: 0.893721	val: 0.574005	test: 0.591572
PRC train: 0.849646	val: 0.642542	test: 0.640566

Epoch: 109
Loss: 0.3682417879989887
ROC train: 0.895309	val: 0.571159	test: 0.597700
PRC train: 0.850403	val: 0.641023	test: 0.640221

Epoch: 110
Loss: 0.366710835008852
ROC train: 0.894847	val: 0.562030	test: 0.606763
PRC train: 0.849146	val: 0.634374	test: 0.641710

Epoch: 111
Loss: 0.3683748114333182
ROC train: 0.899860	val: 0.562177	test: 0.602336
PRC train: 0.850257	val: 0.636444	test: 0.639065

Epoch: 112
Loss: 0.362387049526978
ROC train: 0.899211	val: 0.561007	test: 0.602574
PRC train: 0.848636	val: 0.634012	test: 0.641266

Epoch: 113
Loss: 0.36454685578221613
ROC train: 0.897002	val: 0.557249	test: 0.600430
PRC train: 0.846292	val: 0.628912	test: 0.640466

Epoch: 114
Loss: 0.36787610412988697
ROC train: 0.897149	val: 0.550513	test: 0.595366
PRC train: 0.847005	val: 0.625313	test: 0.636135

Epoch: 115
Loss: 0.353260461344043
ROC train: 0.902575	val: 0.551103	test: 0.593167
PRC train: 0.852533	val: 0.627268	test: 0.635499

Epoch: 116
Loss: 0.3611643471395855
ROC train: 0.904058	val: 0.559526	test: 0.591096
PRC train: 0.855745	val: 0.632932	test: 0.634768

Epoch: 117
Loss: 0.356044000384928
ROC train: 0.900248	val: 0.558917	test: 0.593093
PRC train: 0.854034	val: 0.631741	test: 0.635995

Epoch: 118
Loss: 0.35709612722927464
ROC train: 0.900801	val: 0.561444	test: 0.596259
PRC train: 0.854005	val: 0.632946	test: 0.638968

Epoch: 119
Loss: 0.356236987832243
ROC train: 0.903376	val: 0.569647	test: 0.593674
PRC train: 0.854911	val: 0.639006	test: 0.639797

Epoch: 120
Loss: 0.35411405385604094
ROC train: 0.905246	val: 0.569743	test: 0.598816
PRC train: 0.859318	val: 0.638266	test: 0.640918

Epoch: 121
Loss: 0.35988152523604316
ROC train: 0.902298	val: 0.564169	test: 0.601569
PRC train: 0.860558	val: 0.634167	test: 0.642999

Epoch: 122
Loss: 0.34600544148583035
ROC train: 0.906902	val: 0.561308	test: 0.595826
PRC train: 0.863674	val: 0.633867	test: 0.640989

Epoch: 123
Loss: 0.3513545432806513
ROC train: 0.907974	val: 0.561934	test: 0.593864
PRC train: 0.859518	val: 0.635036	test: 0.640046

Epoch: 124
Loss: 0.35080147549295443
ROC train: 0.904921	val: 0.560789	test: 0.601426
PRC train: 0.857198	val: 0.632491	test: 0.640845

Epoch: 125
Loss: 0.35828787873932344
ROC train: 0.905434	val: 0.561928	test: 0.592140
PRC train: 0.861759	val: 0.635028	test: 0.633442

Epoch: 126
Loss: 0.3542938466055918
ROC train: 0.908621	val: 0.572496	test: 0.584456
PRC train: 0.864223	val: 0.642006	test: 0.631215

Epoch: 127
Loss: 0.3453634913344583
ROC train: 0.911405	val: 0.573544	test: 0.585713
PRC train: 0.866917	val: 0.640876	test: 0.633843

Epoch: 128
Loss: 0.3419979408677703
ROC train: 0.911330	val: 0.565816	test: 0.595627
PRC train: 0.865184	val: 0.635995	test: 0.638945

Epoch: 129
Loss: 0.3528333000678624
ROC train: 0.910069	val: 0.560680	test: 0.600720
PRC train: 0.862468	val: 0.634473	test: 0.641721

Epoch: 130
Loss: 0.345426377547486
ROC train: 0.911450	val: 0.566441	test: 0.594194
PRC train: 0.865164	val: 0.640458	test: 0.641373

Epoch: 131
Loss: 0.34114634944826405
ROC train: 0.913346	val: 0.574763	test: 0.594035
PRC train: 0.870105	val: 0.645075	test: 0.642106

Epoch: 132
Loss: 0.3420306473706639
ROC train: 0.913042	val: 0.575031	test: 0.599657
PRC train: 0.871500	val: 0.644759	test: 0.643759

Epoch: 133
Loss: 0.34730191119780346
ROC train: 0.916430	val: 0.567680	test: 0.597700
PRC train: 0.872451	val: 0.640619	test: 0.642308

Epoch: 134
Loss: 0.3433784405910598
ROC train: 0.913992	val: 0.564516	test: 0.601489
PRC train: 0.869082	val: 0.636483	test: 0.643351

Epoch: 135
Loss: 0.3453892140300472
ROC train: 0.913926	val: 0.573711	test: 0.607972
PRC train: 0.871104	val: 0.641163	test: 0.644759

Epoch: 136
Loss: 0.34085895875763206
ROC train: 0.917745	val: 0.575728	test: 0.606900
PRC train: 0.875259	val: 0.641978	test: 0.643839

Epoch: 137
Loss: 0.3399499958526888
ROC train: 0.919332	val: 0.570199	test: 0.599148
PRC train: 0.877110	val: 0.639434	test: 0.639628

Epoch: 138
Loss: 0.3383290496524207
ROC train: 0.917829	val: 0.564232	test: 0.590669
PRC train: 0.873107	val: 0.636919	test: 0.636245

Epoch: 139
Loss: 0.3442320998125903
ROC train: 0.913640	val: 0.559556	test: 0.602245
PRC train: 0.870103	val: 0.631067	test: 0.642925

Epoch: 140
Loss: 0.34401211388912656
ROC train: 0.917529	val: 0.551908	test: 0.602721
PRC train: 0.877233	val: 0.627742	test: 0.644187

Epoch: 141
Loss: 0.34047876699548785
ROC train: 0.917116	val: 0.556334	test: 0.602452
PRC train: 0.878643	val: 0.631927	test: 0.643329

Epoch: 142
Loss: 0.33543870513448354
ROC train: 0.915608	val: 0.561261	test: 0.601984
PRC train: 0.878839	val: 0.634451	test: 0.642199

Epoch: 143
Loss: 0.32886473941966643
ROC train: 0.921032	val: 0.568654	test: 0.608364
PRC train: 0.882030	val: 0.636155	test: 0.643877

Epoch: 144
Loss: 0.33572112079207567
ROC train: 0.918840	val: 0.569638	test: 0.606770
PRC train: 0.878221	val: 0.635600	test: 0.641223

Epoch: 145
Loss: 0.3294970545248962
ROC train: 0.921502	val: 0.565813	test: 0.602542
PRC train: 0.879934	val: 0.637000	test: 0.642342

Epoch: 146
Loss: 0.34103004594780056
ROC train: 0.917850	val: 0.573957	test: 0.599678
PRC train: 0.876300	val: 0.641243	test: 0.644646

Epoch: 147
Loss: 0.32808333435530873
ROC train: 0.920084	val: 0.569247	test: 0.597498
PRC train: 0.879875	val: 0.636014	test: 0.644900

Epoch: 148
Loss: 0.3360376768153366
ROC train: 0.924062	val: 0.569041	test: 0.602095
PRC train: 0.884996	val: 0.636284	test: 0.645180

Epoch: 149
Loss: 0.3358155727351805
ROC train: 0.917895	val: 0.564113	test: 0.596176
PRC train: 0.878786	val: 0.635575	test: 0.638140

Epoch: 150
Loss: 0.3344844392887876
ROC train: 0.924302	val: 0.566248	test: 0.590086
PRC train: 0.884432	val: 0.636270	test: 0.635278

Epoch: 151
Loss: 0.33205087845729564
ROC train: 0.926712	val: 0.569963	test: 0.590436
PRC train: 0.886768	val: 0.635825	test: 0.637171

Epoch: 152
Loss: 0.33274963927703943
ROC train: 0.925576	val: 0.581752	test: 0.592533
PRC train: 0.884626	val: 0.645168	test: 0.637422

Epoch: 153
Loss: 0.3263496721724922
ROC train: 0.928463	val: 0.574222	test: 0.594022
PRC train: 0.887502	val: 0.641799	test: 0.638149

Epoch: 154
Loss: 0.3284316517309468
ROC train: 0.926011	val: 0.560718	test: 0.592566
PRC train: 0.887154	val: 0.634854	test: 0.638237
ROC train: 0.872297	val: 0.606176	test: 0.602075
PRC train: 0.830061	val: 0.658211	test: 0.636676

Epoch: 95
Loss: 0.3819808765069191
ROC train: 0.875166	val: 0.617061	test: 0.598104
PRC train: 0.833703	val: 0.663441	test: 0.636353

Epoch: 96
Loss: 0.3882261950556193
ROC train: 0.874136	val: 0.616641	test: 0.618817
PRC train: 0.834934	val: 0.665840	test: 0.639912

Epoch: 97
Loss: 0.3784817251484448
ROC train: 0.880912	val: 0.616101	test: 0.599421
PRC train: 0.836616	val: 0.666851	test: 0.632051

Epoch: 98
Loss: 0.37330823825023074
ROC train: 0.866980	val: 0.593885	test: 0.620622
PRC train: 0.822862	val: 0.657705	test: 0.646989

Epoch: 99
Loss: 0.37528936234648486
ROC train: 0.880301	val: 0.605479	test: 0.601685
PRC train: 0.840154	val: 0.661986	test: 0.638743

Epoch: 100
Loss: 0.3739693705014733
ROC train: 0.882442	val: 0.605485	test: 0.594458
PRC train: 0.841410	val: 0.662662	test: 0.631761

Epoch: 101
Loss: 0.37434446193542126
ROC train: 0.884846	val: 0.606717	test: 0.611358
PRC train: 0.843231	val: 0.658792	test: 0.638062

Epoch: 102
Loss: 0.3782590685531205
ROC train: 0.886306	val: 0.620237	test: 0.617694
PRC train: 0.848203	val: 0.663340	test: 0.643635

Epoch: 103
Loss: 0.3731723290782757
ROC train: 0.887430	val: 0.629247	test: 0.606177
PRC train: 0.850002	val: 0.667354	test: 0.637934

Epoch: 104
Loss: 0.3740880726434784
ROC train: 0.886100	val: 0.618914	test: 0.628095
PRC train: 0.851579	val: 0.664519	test: 0.649254

Epoch: 105
Loss: 0.37731916528460785
ROC train: 0.890436	val: 0.629105	test: 0.615443
PRC train: 0.852879	val: 0.667096	test: 0.647035

Epoch: 106
Loss: 0.37802549488473763
ROC train: 0.887827	val: 0.629947	test: 0.603112
PRC train: 0.848929	val: 0.665974	test: 0.640404

Epoch: 107
Loss: 0.37243597507861537
ROC train: 0.886472	val: 0.606987	test: 0.622442
PRC train: 0.850770	val: 0.664031	test: 0.646927

Epoch: 108
Loss: 0.36815721092386633
ROC train: 0.889378	val: 0.599455	test: 0.600933
PRC train: 0.852284	val: 0.659480	test: 0.638255

Epoch: 109
Loss: 0.36762644893650703
ROC train: 0.888506	val: 0.604447	test: 0.590060
PRC train: 0.851603	val: 0.661121	test: 0.634127

Epoch: 110
Loss: 0.3705114784224371
ROC train: 0.890412	val: 0.602894	test: 0.609236
PRC train: 0.852496	val: 0.662691	test: 0.639864

Epoch: 111
Loss: 0.3693768233407022
ROC train: 0.894409	val: 0.606954	test: 0.593490
PRC train: 0.854506	val: 0.662832	test: 0.634569

Epoch: 112
Loss: 0.3646068604414603
ROC train: 0.894665	val: 0.612661	test: 0.598898
PRC train: 0.857263	val: 0.666599	test: 0.637094

Epoch: 113
Loss: 0.3618030312248721
ROC train: 0.891050	val: 0.607696	test: 0.609063
PRC train: 0.856246	val: 0.665437	test: 0.640097

Epoch: 114
Loss: 0.3640773711651326
ROC train: 0.894706	val: 0.612259	test: 0.623532
PRC train: 0.857099	val: 0.664910	test: 0.644357

Epoch: 115
Loss: 0.3624819785170344
ROC train: 0.897655	val: 0.614085	test: 0.624912
PRC train: 0.855420	val: 0.665889	test: 0.647359

Epoch: 116
Loss: 0.36236125986557577
ROC train: 0.899163	val: 0.624960	test: 0.613056
PRC train: 0.862430	val: 0.672692	test: 0.645627

Epoch: 117
Loss: 0.3624220859399167
ROC train: 0.897590	val: 0.624142	test: 0.618650
PRC train: 0.861273	val: 0.671126	test: 0.646546

Epoch: 118
Loss: 0.3616780715383691
ROC train: 0.899297	val: 0.627253	test: 0.604950
PRC train: 0.860244	val: 0.667540	test: 0.638504

Epoch: 119
Loss: 0.35774259139705394
ROC train: 0.902027	val: 0.619752	test: 0.623864
PRC train: 0.862380	val: 0.669084	test: 0.646714

Epoch: 120
Loss: 0.3571672950145495
ROC train: 0.904517	val: 0.624177	test: 0.610448
PRC train: 0.865545	val: 0.672939	test: 0.641229

Epoch: 121
Loss: 0.35854713332792343
ROC train: 0.905208	val: 0.630477	test: 0.600289
PRC train: 0.868063	val: 0.672362	test: 0.637647

Epoch: 122
Loss: 0.35352888199662724
ROC train: 0.904170	val: 0.618192	test: 0.608354
PRC train: 0.867766	val: 0.670256	test: 0.638152

Epoch: 123
Loss: 0.35554406867653976
ROC train: 0.906799	val: 0.618854	test: 0.605260
PRC train: 0.868844	val: 0.672205	test: 0.638232

Epoch: 124
Loss: 0.35114522811826643
ROC train: 0.907330	val: 0.617439	test: 0.610748
PRC train: 0.872661	val: 0.668429	test: 0.640175

Epoch: 125
Loss: 0.3532731835964566
ROC train: 0.907120	val: 0.621101	test: 0.606964
PRC train: 0.871197	val: 0.667080	test: 0.636801

Epoch: 126
Loss: 0.35011345024738333
ROC train: 0.910450	val: 0.621737	test: 0.601894
PRC train: 0.874547	val: 0.668071	test: 0.634454

Epoch: 127
Loss: 0.3512346068339396
ROC train: 0.910673	val: 0.618585	test: 0.604356
PRC train: 0.870926	val: 0.670183	test: 0.636629

Epoch: 128
Loss: 0.3551456367068842
ROC train: 0.911299	val: 0.610500	test: 0.604105
PRC train: 0.872504	val: 0.666508	test: 0.634424

Epoch: 129
Loss: 0.35042261619283166
ROC train: 0.903816	val: 0.617744	test: 0.593572
PRC train: 0.863401	val: 0.668314	test: 0.633393

Epoch: 130
Loss: 0.35105021820017734
ROC train: 0.908790	val: 0.617284	test: 0.607467
PRC train: 0.870948	val: 0.665555	test: 0.640836

Epoch: 131
Loss: 0.34664181072279765
ROC train: 0.914407	val: 0.618159	test: 0.600620
PRC train: 0.876721	val: 0.666799	test: 0.637064

Epoch: 132
Loss: 0.3474011950886988
ROC train: 0.914369	val: 0.613065	test: 0.604833
PRC train: 0.877226	val: 0.667242	test: 0.636577

Epoch: 133
Loss: 0.3456738014656594
ROC train: 0.909513	val: 0.619296	test: 0.606545
PRC train: 0.871665	val: 0.669626	test: 0.641688

Epoch: 134
Loss: 0.3456717068325818
ROC train: 0.910713	val: 0.619850	test: 0.600031
PRC train: 0.874528	val: 0.669178	test: 0.637644

Epoch: 135
Loss: 0.3420465551560952
ROC train: 0.916066	val: 0.618861	test: 0.603868
PRC train: 0.881112	val: 0.668525	test: 0.641751

Epoch: 136
Loss: 0.3382637455893642
ROC train: 0.916469	val: 0.622992	test: 0.605476
PRC train: 0.878441	val: 0.671020	test: 0.635931

Epoch: 137
Loss: 0.3403081746078537
ROC train: 0.914032	val: 0.615442	test: 0.605635
PRC train: 0.875084	val: 0.666879	test: 0.632958

Epoch: 138
Loss: 0.33698720102695523
ROC train: 0.918313	val: 0.618520	test: 0.612867
PRC train: 0.880686	val: 0.665785	test: 0.641886

Epoch: 139
Loss: 0.3367239253019464
ROC train: 0.918267	val: 0.627472	test: 0.610390
PRC train: 0.880265	val: 0.668919	test: 0.645013

Epoch: 140
Loss: 0.3344563956364167
ROC train: 0.921297	val: 0.630373	test: 0.596657
PRC train: 0.883535	val: 0.676869	test: 0.635678

Epoch: 141
Loss: 0.33513476572884954
ROC train: 0.920877	val: 0.618418	test: 0.606957
PRC train: 0.882739	val: 0.672087	test: 0.640401

Epoch: 142
Loss: 0.33952211613288913
ROC train: 0.919980	val: 0.616050	test: 0.606555
PRC train: 0.880760	val: 0.670528	test: 0.639345

Epoch: 143
Loss: 0.3390986051884003
ROC train: 0.921406	val: 0.619769	test: 0.610476
PRC train: 0.887492	val: 0.669867	test: 0.640560

Epoch: 144
Loss: 0.336612128501056
ROC train: 0.921332	val: 0.624610	test: 0.598112
PRC train: 0.885255	val: 0.672514	test: 0.635768

Epoch: 145
Loss: 0.33545177879036603
ROC train: 0.919206	val: 0.617734	test: 0.591977
PRC train: 0.880872	val: 0.672419	test: 0.632431

Epoch: 146
Loss: 0.33666801300107957
ROC train: 0.924942	val: 0.614717	test: 0.619806
PRC train: 0.888025	val: 0.668010	test: 0.643555

Epoch: 147
Loss: 0.32705435168297653
ROC train: 0.922421	val: 0.616154	test: 0.607358
PRC train: 0.883251	val: 0.666616	test: 0.638591

Epoch: 148
Loss: 0.33126603270647575
ROC train: 0.924368	val: 0.614184	test: 0.606432
PRC train: 0.885626	val: 0.666874	test: 0.637820

Epoch: 149
Loss: 0.33205977116490215
ROC train: 0.924710	val: 0.613958	test: 0.591384
PRC train: 0.887646	val: 0.669497	test: 0.633125

Epoch: 150
Loss: 0.33359937370508097
ROC train: 0.923951	val: 0.611296	test: 0.597566
PRC train: 0.888695	val: 0.666155	test: 0.633842

Epoch: 151
Loss: 0.32865729823740136
ROC train: 0.926291	val: 0.611237	test: 0.609554
PRC train: 0.892748	val: 0.667304	test: 0.639782

Epoch: 152
Loss: 0.3266734460675244
ROC train: 0.928117	val: 0.613669	test: 0.606884
PRC train: 0.893165	val: 0.670714	test: 0.637704

Epoch: 153
Loss: 0.3261574815947892
ROC train: 0.926720	val: 0.621873	test: 0.599564
PRC train: 0.893281	val: 0.670893	test: 0.634932

Epoch: 154
Loss: 0.3211335026321019
ROC train: 0.929626	val: 0.623279	test: 0.598904
PRC train: 0.896729	val: 0.671174	test: 0.633558
PRC train: 0.839116	val: 0.670324	test: 0.633159

Epoch: 95
Loss: 0.3829237825182918
ROC train: 0.882550	val: 0.613475	test: 0.580699
PRC train: 0.841156	val: 0.670612	test: 0.630240

Epoch: 96
Loss: 0.38284945949319377
ROC train: 0.874559	val: 0.607402	test: 0.597792
PRC train: 0.832415	val: 0.667560	test: 0.638272

Epoch: 97
Loss: 0.3796355661510141
ROC train: 0.884141	val: 0.609943	test: 0.597959
PRC train: 0.843781	val: 0.671409	test: 0.633391

Epoch: 98
Loss: 0.37935242445419226
ROC train: 0.885000	val: 0.614645	test: 0.593297
PRC train: 0.842790	val: 0.670270	test: 0.629529

Epoch: 99
Loss: 0.37566164061470814
ROC train: 0.883890	val: 0.613829	test: 0.600929
PRC train: 0.842832	val: 0.670475	test: 0.633787

Epoch: 100
Loss: 0.3786003260087165
ROC train: 0.883683	val: 0.614233	test: 0.592207
PRC train: 0.842993	val: 0.673881	test: 0.631113

Epoch: 101
Loss: 0.3723902320158582
ROC train: 0.884876	val: 0.613017	test: 0.593975
PRC train: 0.844650	val: 0.672256	test: 0.634176

Epoch: 102
Loss: 0.37167115399401585
ROC train: 0.879647	val: 0.613917	test: 0.580028
PRC train: 0.837946	val: 0.666357	test: 0.627046

Epoch: 103
Loss: 0.37072510278214443
ROC train: 0.889574	val: 0.623234	test: 0.599809
PRC train: 0.850269	val: 0.670141	test: 0.638154

Epoch: 104
Loss: 0.3789480182536626
ROC train: 0.884881	val: 0.616832	test: 0.591965
PRC train: 0.845611	val: 0.673292	test: 0.629406

Epoch: 105
Loss: 0.37800033504752095
ROC train: 0.888349	val: 0.611758	test: 0.594290
PRC train: 0.848649	val: 0.671316	test: 0.635923

Epoch: 106
Loss: 0.3776815127897855
ROC train: 0.890105	val: 0.602367	test: 0.588467
PRC train: 0.850076	val: 0.667853	test: 0.630852

Epoch: 107
Loss: 0.37442866804818303
ROC train: 0.887929	val: 0.613551	test: 0.586814
PRC train: 0.849329	val: 0.672735	test: 0.633670

Epoch: 108
Loss: 0.36946349046709215
ROC train: 0.890143	val: 0.613895	test: 0.602311
PRC train: 0.853515	val: 0.670191	test: 0.642739

Epoch: 109
Loss: 0.3698267564563572
ROC train: 0.892405	val: 0.612452	test: 0.583953
PRC train: 0.852896	val: 0.676497	test: 0.625253

Epoch: 110
Loss: 0.367561208231478
ROC train: 0.889709	val: 0.604635	test: 0.586663
PRC train: 0.850231	val: 0.675391	test: 0.626365

Epoch: 111
Loss: 0.3734651085585357
ROC train: 0.894793	val: 0.613096	test: 0.592019
PRC train: 0.857937	val: 0.674987	test: 0.635361

Epoch: 112
Loss: 0.3660141900785975
ROC train: 0.895006	val: 0.620254	test: 0.585687
PRC train: 0.857007	val: 0.674922	test: 0.635756

Epoch: 113
Loss: 0.36101725337352236
ROC train: 0.896061	val: 0.608296	test: 0.599793
PRC train: 0.857114	val: 0.666928	test: 0.647584

Epoch: 114
Loss: 0.3585951905718975
ROC train: 0.897455	val: 0.616359	test: 0.591995
PRC train: 0.861745	val: 0.671107	test: 0.633848

Epoch: 115
Loss: 0.3705103553682611
ROC train: 0.899287	val: 0.620700	test: 0.591294
PRC train: 0.863579	val: 0.676178	test: 0.630815

Epoch: 116
Loss: 0.3562971597051396
ROC train: 0.899941	val: 0.624177	test: 0.592441
PRC train: 0.862594	val: 0.680451	test: 0.630896

Epoch: 117
Loss: 0.36077661231341257
ROC train: 0.901021	val: 0.621354	test: 0.589954
PRC train: 0.863510	val: 0.675024	test: 0.631306

Epoch: 118
Loss: 0.3636420115515833
ROC train: 0.899688	val: 0.620112	test: 0.599046
PRC train: 0.861209	val: 0.675714	test: 0.634549

Epoch: 119
Loss: 0.3564140340885648
ROC train: 0.904032	val: 0.628676	test: 0.595726
PRC train: 0.868123	val: 0.676708	test: 0.634281

Epoch: 120
Loss: 0.3570864555521559
ROC train: 0.904513	val: 0.619893	test: 0.601436
PRC train: 0.869786	val: 0.672814	test: 0.643058

Epoch: 121
Loss: 0.3532196329845404
ROC train: 0.906677	val: 0.616900	test: 0.586593
PRC train: 0.872505	val: 0.676425	test: 0.629378

Epoch: 122
Loss: 0.35177486580489303
ROC train: 0.905391	val: 0.610682	test: 0.588643
PRC train: 0.870422	val: 0.673470	test: 0.625274

Epoch: 123
Loss: 0.3526969027263277
ROC train: 0.898534	val: 0.615603	test: 0.591276
PRC train: 0.861983	val: 0.677271	test: 0.630712

Epoch: 124
Loss: 0.3524796059834301
ROC train: 0.897260	val: 0.610490	test: 0.597134
PRC train: 0.861568	val: 0.670785	test: 0.632719

Epoch: 125
Loss: 0.35562912284207077
ROC train: 0.902970	val: 0.602727	test: 0.597634
PRC train: 0.869046	val: 0.666676	test: 0.636893

Epoch: 126
Loss: 0.35701516087537216
ROC train: 0.904039	val: 0.616550	test: 0.595858
PRC train: 0.869724	val: 0.674046	test: 0.632643

Epoch: 127
Loss: 0.3521276010145435
ROC train: 0.909710	val: 0.612746	test: 0.609091
PRC train: 0.876475	val: 0.674322	test: 0.643403

Epoch: 128
Loss: 0.35646699774777535
ROC train: 0.903888	val: 0.614638	test: 0.583799
PRC train: 0.869277	val: 0.674330	test: 0.632465

Epoch: 129
Loss: 0.3460258126440497
ROC train: 0.903467	val: 0.609247	test: 0.593485
PRC train: 0.868425	val: 0.672145	test: 0.636060

Epoch: 130
Loss: 0.3491587119991674
ROC train: 0.910200	val: 0.602036	test: 0.583483
PRC train: 0.875694	val: 0.667079	test: 0.630359

Epoch: 131
Loss: 0.345569566079274
ROC train: 0.914049	val: 0.615968	test: 0.586767
PRC train: 0.881165	val: 0.669482	test: 0.628574

Epoch: 132
Loss: 0.3488720774513058
ROC train: 0.909884	val: 0.625493	test: 0.587406
PRC train: 0.873975	val: 0.677967	test: 0.626039

Epoch: 133
Loss: 0.3487683992268772
ROC train: 0.913787	val: 0.621264	test: 0.575152
PRC train: 0.879641	val: 0.673217	test: 0.622658

Epoch: 134
Loss: 0.34086870756961807
ROC train: 0.914565	val: 0.628138	test: 0.592773
PRC train: 0.882848	val: 0.675217	test: 0.639594

Epoch: 135
Loss: 0.34307655319188995
ROC train: 0.915996	val: 0.625556	test: 0.602979
PRC train: 0.884618	val: 0.679561	test: 0.639512

Epoch: 136
Loss: 0.3415538461807925
ROC train: 0.914288	val: 0.607180	test: 0.592698
PRC train: 0.881347	val: 0.671239	test: 0.629487

Epoch: 137
Loss: 0.3413714280243394
ROC train: 0.916384	val: 0.612758	test: 0.587941
PRC train: 0.882752	val: 0.671648	test: 0.627547

Epoch: 138
Loss: 0.3398828177606851
ROC train: 0.918293	val: 0.616094	test: 0.582622
PRC train: 0.887312	val: 0.675312	test: 0.628535

Epoch: 139
Loss: 0.3360336347229629
ROC train: 0.917827	val: 0.613920	test: 0.566248
PRC train: 0.886573	val: 0.674475	test: 0.619623

Epoch: 140
Loss: 0.3421529496825797
ROC train: 0.918612	val: 0.611139	test: 0.573815
PRC train: 0.887746	val: 0.673148	test: 0.624190

Epoch: 141
Loss: 0.33302277209825437
ROC train: 0.916830	val: 0.617597	test: 0.581655
PRC train: 0.886401	val: 0.672165	test: 0.625797

Epoch: 142
Loss: 0.33886752247623086
ROC train: 0.919659	val: 0.614667	test: 0.603853
PRC train: 0.890189	val: 0.671000	test: 0.637349

Epoch: 143
Loss: 0.3372945174126588
ROC train: 0.919486	val: 0.603880	test: 0.588900
PRC train: 0.890406	val: 0.672225	test: 0.628982

Epoch: 144
Loss: 0.33670624058028625
ROC train: 0.923292	val: 0.609252	test: 0.589164
PRC train: 0.894023	val: 0.673285	test: 0.629237

Epoch: 145
Loss: 0.33680743037335825
ROC train: 0.921679	val: 0.610003	test: 0.595990
PRC train: 0.892618	val: 0.677617	test: 0.633525

Epoch: 146
Loss: 0.3316950035353807
ROC train: 0.922688	val: 0.617661	test: 0.585334
PRC train: 0.889001	val: 0.680049	test: 0.624485

Epoch: 147
Loss: 0.3367907906162268
ROC train: 0.918214	val: 0.620624	test: 0.576832
PRC train: 0.885563	val: 0.678417	test: 0.620001

Epoch: 148
Loss: 0.3340274086407941
ROC train: 0.921973	val: 0.629958	test: 0.588892
PRC train: 0.888095	val: 0.681671	test: 0.630784

Epoch: 149
Loss: 0.32800715445714584
ROC train: 0.923630	val: 0.628508	test: 0.600371
PRC train: 0.892069	val: 0.677018	test: 0.639661

Epoch: 150
Loss: 0.32951842920397334
ROC train: 0.922105	val: 0.622159	test: 0.582119
PRC train: 0.889687	val: 0.680768	test: 0.625810

Epoch: 151
Loss: 0.3315773469615433
ROC train: 0.922817	val: 0.603176	test: 0.593680
PRC train: 0.895768	val: 0.672566	test: 0.632296

Epoch: 152
Loss: 0.32840245416223673
ROC train: 0.923638	val: 0.595807	test: 0.584346
PRC train: 0.894313	val: 0.666926	test: 0.626051

Epoch: 153
Loss: 0.32710866387412335
ROC train: 0.929833	val: 0.605288	test: 0.579019
PRC train: 0.900084	val: 0.671333	test: 0.622275

Epoch: 154
Loss: 0.3246409197665444
ROC train: 0.925994	val: 0.602732	test: 0.596961
PRC train: 0.896398	val: 0.668018	test: 0.631181

Epoch: 155
Loss: 0.3232350990013043

Epoch: 155
Loss: 0.3247243954420171
ROC train: 0.929620	val: 0.610488	test: 0.597914
PRC train: 0.894992	val: 0.667291	test: 0.631256

Epoch: 156
Loss: 0.3237252656374426
ROC train: 0.930422	val: 0.610279	test: 0.600725
PRC train: 0.896508	val: 0.667271	test: 0.641191

Early stopping
Best (ROC):	 train: 0.905208	val: 0.630477	test: 0.600289
Best (PRC):	 train: 0.868063	val: 0.672362	test: 0.637647


Epoch: 155
Loss: 0.3269920560529823
ROC train: 0.928318	val: 0.558271	test: 0.593340
PRC train: 0.887035	val: 0.630800	test: 0.638877

Epoch: 156
Loss: 0.3289525624550347
ROC train: 0.928386	val: 0.562831	test: 0.591566
PRC train: 0.886936	val: 0.631725	test: 0.637285

Epoch: 157
Loss: 0.31641846552312614
ROC train: 0.925787	val: 0.569847	test: 0.592956
PRC train: 0.887111	val: 0.635298	test: 0.636524

Epoch: 158
Loss: 0.32748611737575617
ROC train: 0.928066	val: 0.578379	test: 0.599380
PRC train: 0.888739	val: 0.641381	test: 0.638556

Epoch: 159
Loss: 0.3238003777093988
ROC train: 0.930901	val: 0.572461	test: 0.600537
PRC train: 0.893253	val: 0.640168	test: 0.641630

Epoch: 160
Loss: 0.3257999127029718
ROC train: 0.928742	val: 0.564716	test: 0.596580
PRC train: 0.891280	val: 0.635579	test: 0.639775

Epoch: 161
Loss: 0.3180318341998916
ROC train: 0.932059	val: 0.562866	test: 0.595096
PRC train: 0.895751	val: 0.635167	test: 0.639387

Epoch: 162
Loss: 0.3158080296511151
ROC train: 0.934421	val: 0.557361	test: 0.594710
PRC train: 0.897620	val: 0.630579	test: 0.641348

Epoch: 163
Loss: 0.32013657869971074
ROC train: 0.932310	val: 0.561890	test: 0.599986
PRC train: 0.894806	val: 0.631545	test: 0.644427

Epoch: 164
Loss: 0.32089370624929453
ROC train: 0.933997	val: 0.565167	test: 0.594442
PRC train: 0.896797	val: 0.635049	test: 0.641785

Epoch: 165
Loss: 0.3331192825493719
ROC train: 0.935901	val: 0.566867	test: 0.587391
PRC train: 0.902148	val: 0.638567	test: 0.637438

Epoch: 166
Loss: 0.3131129967645491
ROC train: 0.935529	val: 0.562957	test: 0.590184
PRC train: 0.900486	val: 0.632929	test: 0.639098

Epoch: 167
Loss: 0.31811890920072505
ROC train: 0.933722	val: 0.562633	test: 0.596197
PRC train: 0.897527	val: 0.632434	test: 0.639941

Epoch: 168
Loss: 0.3146591531753877
ROC train: 0.934159	val: 0.561526	test: 0.588989
PRC train: 0.898798	val: 0.633624	test: 0.637140

Epoch: 169
Loss: 0.3119517383971545
ROC train: 0.936719	val: 0.560963	test: 0.585610
PRC train: 0.903586	val: 0.634168	test: 0.637295

Epoch: 170
Loss: 0.3134635110516582
ROC train: 0.938032	val: 0.559539	test: 0.596866
PRC train: 0.905945	val: 0.632197	test: 0.642510

Epoch: 171
Loss: 0.3072256990099477
ROC train: 0.937823	val: 0.560620	test: 0.601107
PRC train: 0.905739	val: 0.633847	test: 0.644827

Epoch: 172
Loss: 0.3106179772030162
ROC train: 0.938724	val: 0.571331	test: 0.604803
PRC train: 0.907900	val: 0.638001	test: 0.644800

Epoch: 173
Loss: 0.3129272455873672
ROC train: 0.939889	val: 0.576290	test: 0.597979
PRC train: 0.909536	val: 0.641291	test: 0.641132

Epoch: 174
Loss: 0.3080480899497331
ROC train: 0.939937	val: 0.579378	test: 0.591713
PRC train: 0.905226	val: 0.644230	test: 0.638319

Epoch: 175
Loss: 0.3148331237432549
ROC train: 0.940942	val: 0.572183	test: 0.590823
PRC train: 0.903631	val: 0.639431	test: 0.642503

Epoch: 176
Loss: 0.3099550382596036
ROC train: 0.937868	val: 0.561566	test: 0.593686
PRC train: 0.903787	val: 0.635578	test: 0.641790

Epoch: 177
Loss: 0.30824307738797707
ROC train: 0.940901	val: 0.566935	test: 0.599712
PRC train: 0.910159	val: 0.638234	test: 0.643171

Epoch: 178
Loss: 0.3033333468076959
ROC train: 0.940458	val: 0.568492	test: 0.607883
PRC train: 0.909394	val: 0.636586	test: 0.646663

Epoch: 179
Loss: 0.30717269841657474
ROC train: 0.942192	val: 0.566700	test: 0.604275
PRC train: 0.908869	val: 0.636255	test: 0.646055

Epoch: 180
Loss: 0.29960851734632943
ROC train: 0.943569	val: 0.565005	test: 0.599456
PRC train: 0.908370	val: 0.635076	test: 0.644132

Epoch: 181
Loss: 0.3013813607605685
ROC train: 0.942732	val: 0.569533	test: 0.601223
PRC train: 0.912490	val: 0.638495	test: 0.644511

Epoch: 182
Loss: 0.2986603041426537
ROC train: 0.945066	val: 0.570427	test: 0.592287
PRC train: 0.911847	val: 0.641741	test: 0.642057

Epoch: 183
Loss: 0.2982516382519545
ROC train: 0.946289	val: 0.565779	test: 0.595231
PRC train: 0.912709	val: 0.635248	test: 0.643476

Epoch: 184
Loss: 0.29953544168490837
ROC train: 0.944306	val: 0.568935	test: 0.606463
PRC train: 0.908081	val: 0.634369	test: 0.652680

Epoch: 185
Loss: 0.29867111863713425
ROC train: 0.945256	val: 0.575341	test: 0.603713
PRC train: 0.912119	val: 0.637445	test: 0.652737

Epoch: 186
Loss: 0.3012575274799603
ROC train: 0.947960	val: 0.580045	test: 0.603128
PRC train: 0.915667	val: 0.643087	test: 0.648247

Epoch: 187
Loss: 0.3044866121199964
ROC train: 0.947115	val: 0.574623	test: 0.600930
PRC train: 0.916436	val: 0.641915	test: 0.645278

Early stopping
Best (ROC):	 train: 0.925576	val: 0.581752	test: 0.592533
Best (PRC):	 train: 0.884626	val: 0.645168	test: 0.637422
All runs completed.

ROC train: 0.929542	val: 0.610019	test: 0.606212
PRC train: 0.899443	val: 0.670732	test: 0.637293

Epoch: 156
Loss: 0.329049266886427
ROC train: 0.931340	val: 0.610701	test: 0.594400
PRC train: 0.900898	val: 0.675463	test: 0.628769

Epoch: 157
Loss: 0.3242995524983546
ROC train: 0.930706	val: 0.605573	test: 0.598863
PRC train: 0.901765	val: 0.675508	test: 0.633476

Epoch: 158
Loss: 0.3207445536742125
ROC train: 0.926781	val: 0.603347	test: 0.591367
PRC train: 0.898205	val: 0.668732	test: 0.632934

Epoch: 159
Loss: 0.3205444241155914
ROC train: 0.931656	val: 0.617916	test: 0.601860
PRC train: 0.902773	val: 0.676458	test: 0.635958

Epoch: 160
Loss: 0.32172523858108787
ROC train: 0.932681	val: 0.628586	test: 0.599229
PRC train: 0.901216	val: 0.683591	test: 0.638052

Epoch: 161
Loss: 0.32741092887285184
ROC train: 0.934141	val: 0.632449	test: 0.589792
PRC train: 0.903261	val: 0.685140	test: 0.631541

Epoch: 162
Loss: 0.32053667521767426
ROC train: 0.932725	val: 0.613251	test: 0.594560
PRC train: 0.903514	val: 0.678518	test: 0.631271

Epoch: 163
Loss: 0.32284755678480814
ROC train: 0.932811	val: 0.604386	test: 0.588556
PRC train: 0.903356	val: 0.674377	test: 0.631438

Epoch: 164
Loss: 0.32419642707413854
ROC train: 0.933692	val: 0.604639	test: 0.585800
PRC train: 0.904131	val: 0.673626	test: 0.633577

Epoch: 165
Loss: 0.31509946197969785
ROC train: 0.936432	val: 0.612060	test: 0.589476
PRC train: 0.908173	val: 0.676315	test: 0.633779

Epoch: 166
Loss: 0.3113376593441647
ROC train: 0.936384	val: 0.595592	test: 0.584498
PRC train: 0.907358	val: 0.670798	test: 0.634146

Epoch: 167
Loss: 0.31792743796236195
ROC train: 0.935225	val: 0.591630	test: 0.589460
PRC train: 0.907049	val: 0.666910	test: 0.634146

Epoch: 168
Loss: 0.30991706364469784
ROC train: 0.936246	val: 0.608835	test: 0.582914
PRC train: 0.906974	val: 0.676037	test: 0.622366

Epoch: 169
Loss: 0.31775862435262237
ROC train: 0.938820	val: 0.616519	test: 0.581969
PRC train: 0.910067	val: 0.677055	test: 0.627412

Epoch: 170
Loss: 0.31017246166806556
ROC train: 0.938616	val: 0.607886	test: 0.597207
PRC train: 0.910964	val: 0.674509	test: 0.636283

Epoch: 171
Loss: 0.31232705819654044
ROC train: 0.934714	val: 0.607748	test: 0.588995
PRC train: 0.906537	val: 0.674141	test: 0.631347

Epoch: 172
Loss: 0.3061143091027453
ROC train: 0.940678	val: 0.616725	test: 0.592014
PRC train: 0.911713	val: 0.678114	test: 0.631491

Epoch: 173
Loss: 0.31258989970770423
ROC train: 0.941871	val: 0.618056	test: 0.590131
PRC train: 0.915473	val: 0.677250	test: 0.627376

Epoch: 174
Loss: 0.308096264404881
ROC train: 0.940461	val: 0.623204	test: 0.591923
PRC train: 0.913125	val: 0.680283	test: 0.629520

Epoch: 175
Loss: 0.3057836042904706
ROC train: 0.941127	val: 0.618685	test: 0.593351
PRC train: 0.914812	val: 0.680790	test: 0.631325

Epoch: 176
Loss: 0.3112106618296342
ROC train: 0.942068	val: 0.615088	test: 0.579016
PRC train: 0.916892	val: 0.676467	test: 0.621971

Epoch: 177
Loss: 0.2995403776994626
ROC train: 0.943094	val: 0.619145	test: 0.588938
PRC train: 0.919307	val: 0.677355	test: 0.624077

Epoch: 178
Loss: 0.30927748293651547
ROC train: 0.940924	val: 0.620561	test: 0.600446
PRC train: 0.912462	val: 0.681130	test: 0.635092

Epoch: 179
Loss: 0.29812413203654453
ROC train: 0.945027	val: 0.615197	test: 0.588240
PRC train: 0.920058	val: 0.679189	test: 0.627444

Epoch: 180
Loss: 0.30054733353571006
ROC train: 0.945871	val: 0.611076	test: 0.590516
PRC train: 0.921508	val: 0.673883	test: 0.626412

Epoch: 181
Loss: 0.30024767736593927
ROC train: 0.945951	val: 0.616649	test: 0.600513
PRC train: 0.922713	val: 0.673768	test: 0.631546

Epoch: 182
Loss: 0.3087440740486633
ROC train: 0.947314	val: 0.612897	test: 0.591585
PRC train: 0.923437	val: 0.676520	test: 0.628933

Epoch: 183
Loss: 0.3012319934681167
ROC train: 0.943687	val: 0.618475	test: 0.566030
PRC train: 0.917960	val: 0.677879	test: 0.619199

Epoch: 184
Loss: 0.30523870674522946
ROC train: 0.943661	val: 0.627773	test: 0.595159
PRC train: 0.917104	val: 0.679339	test: 0.630144

Epoch: 185
Loss: 0.2996006578411359
ROC train: 0.943487	val: 0.618280	test: 0.599979
PRC train: 0.920227	val: 0.674459	test: 0.635735

Epoch: 186
Loss: 0.2986360694951976
ROC train: 0.945394	val: 0.612412	test: 0.582501
PRC train: 0.922384	val: 0.673220	test: 0.621794

Epoch: 187
Loss: 0.2996921964282467
ROC train: 0.949023	val: 0.610156	test: 0.592054
PRC train: 0.926078	val: 0.672192	test: 0.626291

Epoch: 188
Loss: 0.2962545353268977
ROC train: 0.947622	val: 0.618762	test: 0.602481
PRC train: 0.925049	val: 0.675103	test: 0.633073

Epoch: 189
Loss: 0.3005560518314182
ROC train: 0.948492	val: 0.605407	test: 0.574266
PRC train: 0.927477	val: 0.670156	test: 0.619342

Epoch: 190
Loss: 0.29402036507515267
ROC train: 0.944971	val: 0.600412	test: 0.570073
PRC train: 0.922812	val: 0.673264	test: 0.618500

Epoch: 191
Loss: 0.2943044025825303
ROC train: 0.945227	val: 0.618931	test: 0.586764
PRC train: 0.921945	val: 0.677829	test: 0.633382

Epoch: 192
Loss: 0.29604749090899707
ROC train: 0.951620	val: 0.629409	test: 0.593401
PRC train: 0.926720	val: 0.680307	test: 0.630873

Epoch: 193
Loss: 0.2905547093136716
ROC train: 0.951539	val: 0.616135	test: 0.593187
PRC train: 0.924537	val: 0.674156	test: 0.627249

Epoch: 194
Loss: 0.2957320701435864
ROC train: 0.951070	val: 0.611977	test: 0.587102
PRC train: 0.925764	val: 0.674860	test: 0.623412

Epoch: 195
Loss: 0.2924772319198783
ROC train: 0.951234	val: 0.615992	test: 0.593647
PRC train: 0.928786	val: 0.674829	test: 0.628578

Epoch: 196
Loss: 0.28790477922043684
ROC train: 0.954109	val: 0.621797	test: 0.591463
PRC train: 0.931652	val: 0.678261	test: 0.628357

Early stopping
Best (ROC):	 train: 0.934141	val: 0.632449	test: 0.589792
Best (PRC):	 train: 0.903261	val: 0.685140	test: 0.631541
All runs completed.
