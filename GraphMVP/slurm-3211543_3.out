>>> Starting run for dataset: bbbp
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running RANDOM configs_static_noise_experiments/GraphMVP/bbbp/noise=0.0.yml on cuda:0
Running RANDOM configs_static_noise_experiments/GraphMVP/bbbp/noise=0.05.yml on cuda:1
Running RANDOM configs_static_noise_experiments/GraphMVP/bbbp/noise=0.1.yml on cuda:2
Running RANDOM configs_static_noise_experiments/GraphMVP/bbbp/noise=0.2.yml on cuda:3
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/bbbp/noise=0.1.yml --runseed 4 --device cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/bbbp/noise=0.05.yml --runseed 4 --device cuda:1
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/bbbp/noise=0.0.yml --runseed 4 --device cuda:0
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/bbbp/noise=0.1.yml --runseed 5 --device cuda:2
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/bbbp/noise=0.05.yml --runseed 5 --device cuda:1
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/bbbp/noise=0.0.yml --runseed 5 --device cuda:0
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/bbbp/noise=0.1.yml --runseed 6 --device cuda:2
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/bbbp/noise=0.0.yml --runseed 6 --device cuda:0
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/bbbp/noise=0.05.yml --runseed 6 --device cuda:1
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/bbbp/noise=0.2.yml --runseed 4 --device cuda:3
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/bbbp/noise=0.2.yml --runseed 5 --device cuda:3
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/bbbp/noise=0.2.yml --runseed 6 --device cuda:3
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:34] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:35] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
[11:17:36] WARNING: not removing hydrogen atom without neighbors
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/bbbp/noise=0.0.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/bbbp/noise=0.0
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/bbbp/noise=0.0/bbbp_scaff_4_26-05_11-17-34  ]
[ Using Seed :  4  ]
[ Using device :  cuda:0  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6152157946725746
ROC train: 0.817329	val: 0.905149	test: 0.617670
PRC train: 0.952673	val: 0.855874	test: 0.665991

Epoch: 2
Loss: 0.5009290880757644
ROC train: 0.854226	val: 0.911171	test: 0.626736
PRC train: 0.960888	val: 0.854596	test: 0.650248

Epoch: 3
Loss: 0.4142883663635157
ROC train: 0.881172	val: 0.909967	test: 0.652488
PRC train: 0.970463	val: 0.845280	test: 0.680374

Epoch: 4
Loss: 0.3613914912332129
ROC train: 0.903928	val: 0.901134	test: 0.654032
PRC train: 0.975813	val: 0.802139	test: 0.681712

Epoch: 5
Loss: 0.3171227435623517
ROC train: 0.910753	val: 0.920305	test: 0.642265
PRC train: 0.977452	val: 0.846199	test: 0.669275

Epoch: 6
Loss: 0.28712539894875316
ROC train: 0.926710	val: 0.918097	test: 0.684221
PRC train: 0.982498	val: 0.839004	test: 0.734254

Epoch: 7
Loss: 0.28451647170407346
ROC train: 0.922781	val: 0.916792	test: 0.674383
PRC train: 0.980714	val: 0.835219	test: 0.719573

Epoch: 8
Loss: 0.2622790932066463
ROC train: 0.933265	val: 0.917796	test: 0.672068
PRC train: 0.983396	val: 0.845742	test: 0.715179

Epoch: 9
Loss: 0.24518611803335963
ROC train: 0.933409	val: 0.929439	test: 0.662905
PRC train: 0.983091	val: 0.876113	test: 0.701591

Epoch: 10
Loss: 0.22402849322821114
ROC train: 0.942334	val: 0.935361	test: 0.666184
PRC train: 0.986306	val: 0.897138	test: 0.723050

Epoch: 11
Loss: 0.23283768751932912
ROC train: 0.948066	val: 0.934759	test: 0.679109
PRC train: 0.987441	val: 0.902140	test: 0.737115

Epoch: 12
Loss: 0.2209356467371751
ROC train: 0.950617	val: 0.933153	test: 0.663002
PRC train: 0.988635	val: 0.895300	test: 0.713152

Epoch: 13
Loss: 0.2105805073998058
ROC train: 0.955211	val: 0.938773	test: 0.684799
PRC train: 0.989066	val: 0.894979	test: 0.730279

Epoch: 14
Loss: 0.21412483460225737
ROC train: 0.958921	val: 0.932651	test: 0.704861
PRC train: 0.989454	val: 0.870166	test: 0.749791

Epoch: 15
Loss: 0.19796580914777268
ROC train: 0.956872	val: 0.928435	test: 0.687018
PRC train: 0.989736	val: 0.871644	test: 0.717428

Epoch: 16
Loss: 0.21914512651550958
ROC train: 0.962710	val: 0.934257	test: 0.689815
PRC train: 0.991455	val: 0.904346	test: 0.732440

Epoch: 17
Loss: 0.200913293103295
ROC train: 0.963428	val: 0.927030	test: 0.689043
PRC train: 0.991158	val: 0.899268	test: 0.741427

Epoch: 18
Loss: 0.20579928593338317
ROC train: 0.966564	val: 0.927632	test: 0.682099
PRC train: 0.991856	val: 0.884975	test: 0.732515

Epoch: 19
Loss: 0.19063017418809022
ROC train: 0.960895	val: 0.919301	test: 0.675829
PRC train: 0.990752	val: 0.862723	test: 0.708172

Epoch: 20
Loss: 0.19570050002143788
ROC train: 0.967121	val: 0.931948	test: 0.679688
PRC train: 0.991916	val: 0.901399	test: 0.704556

Epoch: 21
Loss: 0.18456672245281847
ROC train: 0.968715	val: 0.927632	test: 0.694252
PRC train: 0.992324	val: 0.888692	test: 0.725393

Epoch: 22
Loss: 0.18267490368794517
ROC train: 0.970145	val: 0.928435	test: 0.710455
PRC train: 0.992283	val: 0.894289	test: 0.748683

Epoch: 23
Loss: 0.17962132209788054
ROC train: 0.971067	val: 0.929640	test: 0.688850
PRC train: 0.993429	val: 0.899260	test: 0.714350

Epoch: 24
Loss: 0.1888619835283107
ROC train: 0.971310	val: 0.925123	test: 0.686439
PRC train: 0.993246	val: 0.878863	test: 0.707748

Epoch: 25
Loss: 0.17279202099358007
ROC train: 0.970941	val: 0.928937	test: 0.684221
PRC train: 0.992969	val: 0.893741	test: 0.712028

Epoch: 26
Loss: 0.17646773994388193
ROC train: 0.975079	val: 0.928736	test: 0.699846
PRC train: 0.994078	val: 0.894635	test: 0.730695

Epoch: 27
Loss: 0.15968311349189981
ROC train: 0.975628	val: 0.938472	test: 0.707465
PRC train: 0.993987	val: 0.912535	test: 0.746684

Epoch: 28
Loss: 0.17102864584846467
ROC train: 0.978285	val: 0.930342	test: 0.688079
PRC train: 0.994988	val: 0.892333	test: 0.706617

Epoch: 29
Loss: 0.16092076909579833
ROC train: 0.978453	val: 0.935060	test: 0.675154
PRC train: 0.995209	val: 0.896792	test: 0.696645

Epoch: 30
Loss: 0.1750313402414621
ROC train: 0.974571	val: 0.911874	test: 0.696856
PRC train: 0.994336	val: 0.844637	test: 0.720349

Epoch: 31
Loss: 0.16211390803707224
ROC train: 0.977936	val: 0.929439	test: 0.679784
PRC train: 0.995238	val: 0.894424	test: 0.699580

Epoch: 32
Loss: 0.16781453304034827
ROC train: 0.977602	val: 0.925625	test: 0.674286
PRC train: 0.995363	val: 0.892768	test: 0.683094

Epoch: 33
Loss: 0.16452813563751056Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/bbbp/noise=0.0.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/bbbp/noise=0.0
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/bbbp/noise=0.0/bbbp_scaff_5_26-05_11-17-34  ]
[ Using Seed :  5  ]
[ Using device :  cuda:0  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6417144789888746
ROC train: 0.801420	val: 0.908762	test: 0.595486
PRC train: 0.939963	val: 0.819310	test: 0.637751

Epoch: 2
Loss: 0.5235916656608355
ROC train: 0.840595	val: 0.914684	test: 0.600984
PRC train: 0.950645	val: 0.846064	test: 0.640212

Epoch: 3
Loss: 0.43629257114702497
ROC train: 0.862000	val: 0.904748	test: 0.634742
PRC train: 0.961903	val: 0.830067	test: 0.665253

Epoch: 4
Loss: 0.35762928718665327
ROC train: 0.877606	val: 0.904045	test: 0.637635
PRC train: 0.966896	val: 0.811722	test: 0.653855

Epoch: 5
Loss: 0.323535660834336
ROC train: 0.897896	val: 0.898826	test: 0.672840
PRC train: 0.974280	val: 0.801009	test: 0.725010

Epoch: 6
Loss: 0.30805415563535565
ROC train: 0.913910	val: 0.909565	test: 0.685185
PRC train: 0.978233	val: 0.809769	test: 0.734282

Epoch: 7
Loss: 0.28819602518577503
ROC train: 0.921708	val: 0.910669	test: 0.683256
PRC train: 0.979875	val: 0.809904	test: 0.726545

Epoch: 8
Loss: 0.25643581408798993
ROC train: 0.925191	val: 0.912577	test: 0.696952
PRC train: 0.980899	val: 0.823802	test: 0.744827

Epoch: 9
Loss: 0.2512151750266954
ROC train: 0.935806	val: 0.932651	test: 0.695891
PRC train: 0.984000	val: 0.894249	test: 0.750715

Epoch: 10
Loss: 0.25702745603786037
ROC train: 0.936430	val: 0.924320	test: 0.695988
PRC train: 0.983802	val: 0.881248	test: 0.751380

Epoch: 11
Loss: 0.23908708411188723
ROC train: 0.947209	val: 0.930543	test: 0.701775
PRC train: 0.986913	val: 0.902064	test: 0.766287

Epoch: 12
Loss: 0.2270689135080531
ROC train: 0.949136	val: 0.928234	test: 0.709298
PRC train: 0.986884	val: 0.903157	test: 0.774467

Epoch: 13
Loss: 0.2163372458407596
ROC train: 0.951077	val: 0.931145	test: 0.707658
PRC train: 0.987338	val: 0.911022	test: 0.765770

Epoch: 14
Loss: 0.2120815708357839
ROC train: 0.956751	val: 0.923818	test: 0.720293
PRC train: 0.988748	val: 0.889696	test: 0.777120

Epoch: 15
Loss: 0.21500705780401672
ROC train: 0.955609	val: 0.922011	test: 0.708912
PRC train: 0.988577	val: 0.870502	test: 0.761547

Epoch: 16
Loss: 0.2183721338529591
ROC train: 0.959354	val: 0.919301	test: 0.702932
PRC train: 0.989427	val: 0.885067	test: 0.750071

Epoch: 17
Loss: 0.20546407436566141
ROC train: 0.954256	val: 0.936164	test: 0.695312
PRC train: 0.987998	val: 0.909330	test: 0.732552

Epoch: 18
Loss: 0.18700546832785875
ROC train: 0.962648	val: 0.933353	test: 0.715085
PRC train: 0.990245	val: 0.903806	test: 0.764450

Epoch: 19
Loss: 0.19548921353624357
ROC train: 0.967731	val: 0.926227	test: 0.717689
PRC train: 0.991636	val: 0.890572	test: 0.768910

Epoch: 20
Loss: 0.18157359898196498
ROC train: 0.968290	val: 0.932651	test: 0.705922
PRC train: 0.992237	val: 0.895390	test: 0.746873

Epoch: 21
Loss: 0.19099013962680625
ROC train: 0.970357	val: 0.924420	test: 0.707465
PRC train: 0.993079	val: 0.886868	test: 0.743903

Epoch: 22
Loss: 0.18282327203155888
ROC train: 0.969360	val: 0.927030	test: 0.679880
PRC train: 0.992885	val: 0.885205	test: 0.705089

Epoch: 23
Loss: 0.18888872372177554
ROC train: 0.969631	val: 0.904246	test: 0.692805
PRC train: 0.992885	val: 0.834178	test: 0.729633

Epoch: 24
Loss: 0.18632645931950145
ROC train: 0.970077	val: 0.929640	test: 0.702160
PRC train: 0.992912	val: 0.890598	test: 0.713167

Epoch: 25
Loss: 0.17803406168958597
ROC train: 0.974161	val: 0.914684	test: 0.709298
PRC train: 0.994310	val: 0.853947	test: 0.729436

Epoch: 26
Loss: 0.17272670424656303
ROC train: 0.975767	val: 0.912175	test: 0.716146
PRC train: 0.994779	val: 0.847397	test: 0.744325

Epoch: 27
Loss: 0.17418862444584107
ROC train: 0.975028	val: 0.927733	test: 0.703897
PRC train: 0.994250	val: 0.893144	test: 0.733014

Epoch: 28
Loss: 0.17063699653410364
ROC train: 0.976672	val: 0.928837	test: 0.705826
PRC train: 0.994127	val: 0.891714	test: 0.752055

Epoch: 29
Loss: 0.15724034246102297
ROC train: 0.977500	val: 0.929840	test: 0.704282
PRC train: 0.994598	val: 0.890748	test: 0.739041

Epoch: 30
Loss: 0.1682706824036579
ROC train: 0.976770	val: 0.927331	test: 0.694252
PRC train: 0.994647	val: 0.883187	test: 0.704531

Epoch: 31
Loss: 0.16403632152319253
ROC train: 0.979174	val: 0.926528	test: 0.709201
PRC train: 0.995317	val: 0.880877	test: 0.733429

Epoch: 32
Loss: 0.15481411137897627
ROC train: 0.981747	val: 0.933956	test: 0.710455
PRC train: 0.995919	val: 0.888363	test: 0.737689

Epoch: 33
Loss: 0.15298701513587482Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/bbbp/noise=0.0.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/bbbp/noise=0.0
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/bbbp/noise=0.0/bbbp_scaff_6_26-05_11-17-34  ]
[ Using Seed :  6  ]
[ Using device :  cuda:0  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6474954316931323
ROC train: 0.789826	val: 0.897922	test: 0.591242
PRC train: 0.942371	val: 0.854602	test: 0.604373

Epoch: 2
Loss: 0.53155395438968
ROC train: 0.833270	val: 0.918498	test: 0.628858
PRC train: 0.953618	val: 0.886763	test: 0.672007

Epoch: 3
Loss: 0.4407680317983882
ROC train: 0.860785	val: 0.913380	test: 0.642843
PRC train: 0.962962	val: 0.860497	test: 0.668065

Epoch: 4
Loss: 0.3952490740826132
ROC train: 0.880975	val: 0.899428	test: 0.653646
PRC train: 0.967532	val: 0.826090	test: 0.672898

Epoch: 5
Loss: 0.33739954124773514
ROC train: 0.904821	val: 0.894510	test: 0.672647
PRC train: 0.976042	val: 0.806821	test: 0.718622

Epoch: 6
Loss: 0.30693698989100904
ROC train: 0.921551	val: 0.894911	test: 0.690104
PRC train: 0.980061	val: 0.801163	test: 0.744454

Epoch: 7
Loss: 0.28808635676515515
ROC train: 0.924568	val: 0.900130	test: 0.692805
PRC train: 0.980709	val: 0.812855	test: 0.748483

Epoch: 8
Loss: 0.266807189222145
ROC train: 0.930118	val: 0.912978	test: 0.695698
PRC train: 0.982377	val: 0.844032	test: 0.752721

Epoch: 9
Loss: 0.2684546875430045
ROC train: 0.929003	val: 0.920305	test: 0.689429
PRC train: 0.981552	val: 0.857391	test: 0.734086

Epoch: 10
Loss: 0.24940491301313555
ROC train: 0.936686	val: 0.920907	test: 0.693094
PRC train: 0.983818	val: 0.865784	test: 0.755365

Epoch: 11
Loss: 0.24184301721472043
ROC train: 0.936689	val: 0.915186	test: 0.696373
PRC train: 0.983845	val: 0.872103	test: 0.756774

Epoch: 12
Loss: 0.22951282938998271
ROC train: 0.944224	val: 0.910168	test: 0.694541
PRC train: 0.985798	val: 0.852327	test: 0.761855

Epoch: 13
Loss: 0.23548517247315495
ROC train: 0.943058	val: 0.917394	test: 0.700521
PRC train: 0.984935	val: 0.863290	test: 0.754154

Epoch: 14
Loss: 0.23057947945232113
ROC train: 0.945865	val: 0.931346	test: 0.682581
PRC train: 0.986252	val: 0.902922	test: 0.734968

Epoch: 15
Loss: 0.228473259570461
ROC train: 0.954177	val: 0.924822	test: 0.705054
PRC train: 0.987783	val: 0.888447	test: 0.766579

Epoch: 16
Loss: 0.2103632259967389
ROC train: 0.954622	val: 0.929339	test: 0.705922
PRC train: 0.987980	val: 0.898928	test: 0.763681

Epoch: 17
Loss: 0.1961589221072515
ROC train: 0.945934	val: 0.932550	test: 0.676119
PRC train: 0.986424	val: 0.898599	test: 0.719282

Epoch: 18
Loss: 0.19945846146499208
ROC train: 0.957509	val: 0.921610	test: 0.701292
PRC train: 0.988907	val: 0.892123	test: 0.761829

Epoch: 19
Loss: 0.1979466430113575
ROC train: 0.962529	val: 0.929840	test: 0.708140
PRC train: 0.990613	val: 0.911195	test: 0.768467

Epoch: 20
Loss: 0.1943767505972143
ROC train: 0.965142	val: 0.907357	test: 0.699749
PRC train: 0.992248	val: 0.862059	test: 0.745891

Epoch: 21
Loss: 0.18405278099153047
ROC train: 0.959554	val: 0.933052	test: 0.701582
PRC train: 0.989661	val: 0.908844	test: 0.756382

Epoch: 22
Loss: 0.1965821327739119
ROC train: 0.966434	val: 0.921911	test: 0.715181
PRC train: 0.991649	val: 0.887574	test: 0.766342

Epoch: 23
Loss: 0.18745042111631732
ROC train: 0.966403	val: 0.910368	test: 0.705922
PRC train: 0.992088	val: 0.863312	test: 0.748149

Epoch: 24
Loss: 0.18487817360315686
ROC train: 0.969395	val: 0.923918	test: 0.705536
PRC train: 0.992416	val: 0.888018	test: 0.757908

Epoch: 25
Loss: 0.18708682510204686
ROC train: 0.966246	val: 0.927532	test: 0.708237
PRC train: 0.991156	val: 0.887443	test: 0.757071

Epoch: 26
Loss: 0.17995593490704853
ROC train: 0.968569	val: 0.920506	test: 0.710841
PRC train: 0.992451	val: 0.888770	test: 0.758566

Epoch: 27
Loss: 0.18116985570858626
ROC train: 0.972470	val: 0.934457	test: 0.711709
PRC train: 0.993769	val: 0.913320	test: 0.764648

Epoch: 28
Loss: 0.17773086085596318
ROC train: 0.966200	val: 0.929941	test: 0.706983
PRC train: 0.991849	val: 0.908365	test: 0.760289

Epoch: 29
Loss: 0.17818116977837226
ROC train: 0.971858	val: 0.919803	test: 0.698302
PRC train: 0.993667	val: 0.880225	test: 0.740073

Epoch: 30
Loss: 0.17644685561163195
ROC train: 0.974820	val: 0.922714	test: 0.714217
PRC train: 0.994193	val: 0.893340	test: 0.767875

Epoch: 31
Loss: 0.17096321645867937
ROC train: 0.973763	val: 0.924521	test: 0.693576
PRC train: 0.993968	val: 0.892076	test: 0.727319

Epoch: 32
Loss: 0.16218291944031876
ROC train: 0.975206	val: 0.926227	test: 0.704765
PRC train: 0.994260	val: 0.898229	test: 0.728493

Epoch: 33
Loss: 0.16042287890346318
ROC train: 0.976453	val: 0.921208	test: 0.708044Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/bbbp/noise=0.05.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.05
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/bbbp/noise=0.05
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/bbbp/noise=0.05/bbbp_scaff_4_26-05_11-17-34  ]
[ Using Seed :  4  ]
[ Using device :  cuda:1  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6074649253099513
ROC train: 0.796987	val: 0.905149	test: 0.581694
PRC train: 0.940489	val: 0.865558	test: 0.650459

Epoch: 2
Loss: 0.5095401697671188
ROC train: 0.826943	val: 0.917695	test: 0.604745
PRC train: 0.950169	val: 0.883629	test: 0.653460

Epoch: 3
Loss: 0.43262660644425166
ROC train: 0.859387	val: 0.911372	test: 0.607157
PRC train: 0.960941	val: 0.855731	test: 0.639391

Epoch: 4
Loss: 0.36822293763511194
ROC train: 0.884829	val: 0.891599	test: 0.637731
PRC train: 0.970907	val: 0.786112	test: 0.669789

Epoch: 5
Loss: 0.3397452991625721
ROC train: 0.900771	val: 0.898525	test: 0.630208
PRC train: 0.975543	val: 0.805041	test: 0.667172

Epoch: 6
Loss: 0.30798603511078576
ROC train: 0.917463	val: 0.886681	test: 0.648245
PRC train: 0.980950	val: 0.783445	test: 0.689000

Epoch: 7
Loss: 0.2873523926651945
ROC train: 0.917851	val: 0.897621	test: 0.633777
PRC train: 0.981320	val: 0.826134	test: 0.654591

Epoch: 8
Loss: 0.26772156049260465
ROC train: 0.929958	val: 0.899227	test: 0.657118
PRC train: 0.984216	val: 0.825161	test: 0.694157

Epoch: 9
Loss: 0.236516254683728
ROC train: 0.940852	val: 0.905551	test: 0.662905
PRC train: 0.987015	val: 0.830654	test: 0.712590

Epoch: 10
Loss: 0.23799126297378173
ROC train: 0.941792	val: 0.916993	test: 0.649113
PRC train: 0.986436	val: 0.856843	test: 0.672464

Epoch: 11
Loss: 0.24292151869618656
ROC train: 0.949795	val: 0.923417	test: 0.646701
PRC train: 0.988799	val: 0.881922	test: 0.692878

Epoch: 12
Loss: 0.21738984735767972
ROC train: 0.956231	val: 0.915638	test: 0.651910
PRC train: 0.990444	val: 0.871913	test: 0.699117

Epoch: 13
Loss: 0.2123014478364209
ROC train: 0.954929	val: 0.922614	test: 0.648052
PRC train: 0.990061	val: 0.865253	test: 0.676796

Epoch: 14
Loss: 0.21565566438440165
ROC train: 0.965682	val: 0.896216	test: 0.675444
PRC train: 0.992394	val: 0.821428	test: 0.723150

Epoch: 15
Loss: 0.2033960017110612
ROC train: 0.969699	val: 0.914985	test: 0.682388
PRC train: 0.993467	val: 0.867155	test: 0.726094

Epoch: 16
Loss: 0.18938534405379734
ROC train: 0.972103	val: 0.924521	test: 0.666763
PRC train: 0.993987	val: 0.886037	test: 0.707879

Epoch: 17
Loss: 0.18360521303265426
ROC train: 0.977798	val: 0.909666	test: 0.677180
PRC train: 0.995346	val: 0.856186	test: 0.724719

Epoch: 18
Loss: 0.1750509902393535
ROC train: 0.976289	val: 0.892402	test: 0.671875
PRC train: 0.994994	val: 0.814674	test: 0.713335

Epoch: 19
Loss: 0.1729621143197758
ROC train: 0.979602	val: 0.897220	test: 0.655189
PRC train: 0.995743	val: 0.836797	test: 0.694180

Epoch: 20
Loss: 0.17843066235801425
ROC train: 0.981370	val: 0.908461	test: 0.644001
PRC train: 0.996048	val: 0.867931	test: 0.678107

Epoch: 21
Loss: 0.16704854881734255
ROC train: 0.977566	val: 0.908762	test: 0.678916
PRC train: 0.995159	val: 0.837749	test: 0.729424

Epoch: 22
Loss: 0.17277945801376157
ROC train: 0.983283	val: 0.908662	test: 0.659047
PRC train: 0.996440	val: 0.868762	test: 0.681716

Epoch: 23
Loss: 0.15312923101869375
ROC train: 0.985162	val: 0.911372	test: 0.657504
PRC train: 0.996921	val: 0.874766	test: 0.691492

Epoch: 24
Loss: 0.15938108497013206
ROC train: 0.984562	val: 0.897320	test: 0.674961
PRC train: 0.996818	val: 0.822979	test: 0.724859

Epoch: 25
Loss: 0.1566366233940851
ROC train: 0.987471	val: 0.894710	test: 0.688465
PRC train: 0.997473	val: 0.818351	test: 0.734337

Epoch: 26
Loss: 0.15130813647823685
ROC train: 0.987715	val: 0.908160	test: 0.673225
PRC train: 0.997404	val: 0.853808	test: 0.719051

Epoch: 27
Loss: 0.14635083276330493
ROC train: 0.979905	val: 0.899729	test: 0.657890
PRC train: 0.995687	val: 0.835207	test: 0.705546

Epoch: 28
Loss: 0.1401898756784656
ROC train: 0.990737	val: 0.910469	test: 0.668113
PRC train: 0.998131	val: 0.871882	test: 0.719304

Epoch: 29
Loss: 0.12927127503416475
ROC train: 0.990610	val: 0.902138	test: 0.648341
PRC train: 0.998021	val: 0.859647	test: 0.683219

Epoch: 30
Loss: 0.1242255861778645
ROC train: 0.988060	val: 0.907458	test: 0.659915
PRC train: 0.997449	val: 0.859423	test: 0.697725

Epoch: 31
Loss: 0.12201535946563401
ROC train: 0.992347	val: 0.887684	test: 0.658275
PRC train: 0.998432	val: 0.795584	test: 0.690582

Epoch: 32
Loss: 0.12249340816477224
ROC train: 0.993974	val: 0.904246	test: 0.665413Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/bbbp/noise=0.05.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.05
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/bbbp/noise=0.05
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/bbbp/noise=0.05/bbbp_scaff_6_26-05_11-17-34  ]
[ Using Seed :  6  ]
[ Using device :  cuda:1  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6128223068399435
ROC train: 0.793012	val: 0.886681	test: 0.586516
PRC train: 0.941804	val: 0.841396	test: 0.614406

Epoch: 2
Loss: 0.5189555846030516
ROC train: 0.826923	val: 0.910268	test: 0.599055
PRC train: 0.952109	val: 0.869933	test: 0.637177

Epoch: 3
Loss: 0.4463408629362501
ROC train: 0.856335	val: 0.903844	test: 0.612944
PRC train: 0.963920	val: 0.830315	test: 0.646774

Epoch: 4
Loss: 0.38617322682917793
ROC train: 0.891073	val: 0.904446	test: 0.633488
PRC train: 0.973476	val: 0.824707	test: 0.682458

Epoch: 5
Loss: 0.33926109595807097
ROC train: 0.906848	val: 0.906052	test: 0.653164
PRC train: 0.977810	val: 0.811986	test: 0.671726

Epoch: 6
Loss: 0.31631634670423203
ROC train: 0.914476	val: 0.900733	test: 0.640046
PRC train: 0.980167	val: 0.805100	test: 0.653969

Epoch: 7
Loss: 0.2952562705482556
ROC train: 0.927145	val: 0.897722	test: 0.647859
PRC train: 0.984021	val: 0.793934	test: 0.680640

Epoch: 8
Loss: 0.2724328388421747
ROC train: 0.932329	val: 0.914082	test: 0.657215
PRC train: 0.985231	val: 0.823523	test: 0.709014

Epoch: 9
Loss: 0.25812222492343373
ROC train: 0.942967	val: 0.908762	test: 0.657215
PRC train: 0.987784	val: 0.811582	test: 0.699108

Epoch: 10
Loss: 0.24009169678382386
ROC train: 0.946460	val: 0.914684	test: 0.657600
PRC train: 0.988483	val: 0.828072	test: 0.692977

Epoch: 11
Loss: 0.23834136155397556
ROC train: 0.952890	val: 0.906354	test: 0.659433
PRC train: 0.990021	val: 0.821461	test: 0.695814

Epoch: 12
Loss: 0.235805707716841
ROC train: 0.956977	val: 0.913781	test: 0.660783
PRC train: 0.990942	val: 0.838880	test: 0.696540

Epoch: 13
Loss: 0.21195394779725424
ROC train: 0.956486	val: 0.916391	test: 0.657118
PRC train: 0.990610	val: 0.851459	test: 0.711560

Epoch: 14
Loss: 0.2177902191529111
ROC train: 0.968715	val: 0.908963	test: 0.664641
PRC train: 0.993697	val: 0.833082	test: 0.719616

Epoch: 15
Loss: 0.1961246946017094
ROC train: 0.968529	val: 0.915788	test: 0.654996
PRC train: 0.993526	val: 0.848412	test: 0.698881

Epoch: 16
Loss: 0.19791284939273668
ROC train: 0.970906	val: 0.906354	test: 0.658179
PRC train: 0.994018	val: 0.819914	test: 0.713289

Epoch: 17
Loss: 0.1856734765312644
ROC train: 0.976401	val: 0.905049	test: 0.665895
PRC train: 0.995267	val: 0.835454	test: 0.716335

Epoch: 18
Loss: 0.1833480428113056
ROC train: 0.980595	val: 0.908963	test: 0.677180
PRC train: 0.996162	val: 0.831576	test: 0.727630

Epoch: 19
Loss: 0.1876077509524611
ROC train: 0.980730	val: 0.910971	test: 0.660783
PRC train: 0.996199	val: 0.833251	test: 0.697450

Epoch: 20
Loss: 0.18482840848745494
ROC train: 0.980839	val: 0.904848	test: 0.655768
PRC train: 0.996157	val: 0.840970	test: 0.686512

Epoch: 21
Loss: 0.18808307668403415
ROC train: 0.979852	val: 0.921710	test: 0.675058
PRC train: 0.995942	val: 0.852427	test: 0.700748

Epoch: 22
Loss: 0.1647037509264563
ROC train: 0.983751	val: 0.901636	test: 0.678337
PRC train: 0.996760	val: 0.823057	test: 0.724132

Epoch: 23
Loss: 0.16951129784380442
ROC train: 0.983720	val: 0.909164	test: 0.672743
PRC train: 0.996693	val: 0.847258	test: 0.727985

Epoch: 24
Loss: 0.15382253846924196
ROC train: 0.987014	val: 0.904045	test: 0.670332
PRC train: 0.997434	val: 0.813046	test: 0.717339

Epoch: 25
Loss: 0.15938999181155872
ROC train: 0.989079	val: 0.914082	test: 0.686150
PRC train: 0.997868	val: 0.827028	test: 0.732301

Epoch: 26
Loss: 0.14021210506189602
ROC train: 0.987802	val: 0.912476	test: 0.657793
PRC train: 0.997546	val: 0.846672	test: 0.689589

Epoch: 27
Loss: 0.1503078023433391
ROC train: 0.985676	val: 0.903342	test: 0.646123
PRC train: 0.997160	val: 0.787958	test: 0.692729

Epoch: 28
Loss: 0.16072351815028302
ROC train: 0.982475	val: 0.899227	test: 0.645062
PRC train: 0.996358	val: 0.825007	test: 0.667609

Epoch: 29
Loss: 0.14300968579605997
ROC train: 0.990352	val: 0.902740	test: 0.665027
PRC train: 0.998081	val: 0.830024	test: 0.701349

Epoch: 30
Loss: 0.1356009925055122
ROC train: 0.993130	val: 0.912878	test: 0.672261
PRC train: 0.998683	val: 0.824422	test: 0.706103

Epoch: 31
Loss: 0.13273684585307158
ROC train: 0.993960	val: 0.917896	test: 0.673322
PRC train: 0.998829	val: 0.842983	test: 0.700307

Epoch: 32
Loss: 0.12998991160461446
ROC train: 0.993276	val: 0.924019	test: 0.674961Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/bbbp/noise=0.05.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.05
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/bbbp/noise=0.05
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/bbbp/noise=0.05/bbbp_scaff_5_26-05_11-17-34  ]
[ Using Seed :  5  ]
[ Using device :  cuda:1  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6292661708232682
ROC train: 0.790829	val: 0.878551	test: 0.567998
PRC train: 0.939889	val: 0.811422	test: 0.633209

Epoch: 2
Loss: 0.5182268708365243
ROC train: 0.826323	val: 0.906855	test: 0.592689
PRC train: 0.950435	val: 0.861510	test: 0.649652

Epoch: 3
Loss: 0.4534727832329319
ROC train: 0.855027	val: 0.907257	test: 0.604649
PRC train: 0.958169	val: 0.857484	test: 0.652531

Epoch: 4
Loss: 0.38696890169468584
ROC train: 0.881092	val: 0.904948	test: 0.622589
PRC train: 0.967562	val: 0.834087	test: 0.652991

Epoch: 5
Loss: 0.34352456602263926
ROC train: 0.898050	val: 0.893305	test: 0.649981
PRC train: 0.973835	val: 0.799714	test: 0.695978

Epoch: 6
Loss: 0.3244145021817115
ROC train: 0.908770	val: 0.895513	test: 0.643904
PRC train: 0.976681	val: 0.800960	test: 0.694516

Epoch: 7
Loss: 0.29360292037027463
ROC train: 0.913205	val: 0.902539	test: 0.640625
PRC train: 0.977914	val: 0.817199	test: 0.681530

Epoch: 8
Loss: 0.29003509053015664
ROC train: 0.921399	val: 0.905551	test: 0.657022
PRC train: 0.980908	val: 0.843864	test: 0.700609

Epoch: 9
Loss: 0.2691134167004677
ROC train: 0.929066	val: 0.910368	test: 0.664834
PRC train: 0.983058	val: 0.863005	test: 0.720312

Epoch: 10
Loss: 0.27763725903766084
ROC train: 0.935681	val: 0.913781	test: 0.664255
PRC train: 0.984522	val: 0.868759	test: 0.708448

Epoch: 11
Loss: 0.24153234097636522
ROC train: 0.937940	val: 0.910870	test: 0.654900
PRC train: 0.985270	val: 0.853086	test: 0.689437

Epoch: 12
Loss: 0.23114586380315252
ROC train: 0.946028	val: 0.911573	test: 0.677662
PRC train: 0.987275	val: 0.849466	test: 0.730172

Epoch: 13
Loss: 0.24332107309372747
ROC train: 0.947932	val: 0.900331	test: 0.678144
PRC train: 0.987170	val: 0.828257	test: 0.725639

Epoch: 14
Loss: 0.23927632802331722
ROC train: 0.954315	val: 0.912577	test: 0.663966
PRC train: 0.989205	val: 0.871985	test: 0.714632

Epoch: 15
Loss: 0.21971038463540116
ROC train: 0.957182	val: 0.921510	test: 0.678048
PRC train: 0.990136	val: 0.880595	test: 0.736179

Epoch: 16
Loss: 0.212084770454126
ROC train: 0.956278	val: 0.907257	test: 0.687404
PRC train: 0.989733	val: 0.848036	test: 0.729567

Epoch: 17
Loss: 0.20194498543824208
ROC train: 0.963979	val: 0.919904	test: 0.684703
PRC train: 0.991896	val: 0.880177	test: 0.736030

Epoch: 18
Loss: 0.20467804295162664
ROC train: 0.964448	val: 0.900933	test: 0.674576
PRC train: 0.991320	val: 0.817263	test: 0.708444

Epoch: 19
Loss: 0.20896683162748467
ROC train: 0.969259	val: 0.917796	test: 0.679495
PRC train: 0.992879	val: 0.872825	test: 0.734869

Epoch: 20
Loss: 0.18742061101379157
ROC train: 0.973049	val: 0.913179	test: 0.681038
PRC train: 0.994060	val: 0.851222	test: 0.715145

Epoch: 21
Loss: 0.18602425949135307
ROC train: 0.972011	val: 0.915487	test: 0.667921
PRC train: 0.993562	val: 0.865954	test: 0.689306

Epoch: 22
Loss: 0.1816512045271339
ROC train: 0.979139	val: 0.917495	test: 0.695891
PRC train: 0.995481	val: 0.880651	test: 0.739468

Epoch: 23
Loss: 0.18442365621211682
ROC train: 0.979821	val: 0.914484	test: 0.692708
PRC train: 0.995659	val: 0.861190	test: 0.733638

Epoch: 24
Loss: 0.1686383061112231
ROC train: 0.984091	val: 0.913078	test: 0.682002
PRC train: 0.996714	val: 0.848530	test: 0.700590

Epoch: 25
Loss: 0.15499880898042204
ROC train: 0.984228	val: 0.915788	test: 0.694927
PRC train: 0.996610	val: 0.869945	test: 0.726440

Epoch: 26
Loss: 0.16226729391125577
ROC train: 0.986529	val: 0.919201	test: 0.698110
PRC train: 0.997205	val: 0.883002	test: 0.736273

Epoch: 27
Loss: 0.16456007101629164
ROC train: 0.984234	val: 0.910870	test: 0.672936
PRC train: 0.996747	val: 0.850052	test: 0.689560

Epoch: 28
Loss: 0.14986427602729482
ROC train: 0.988700	val: 0.911774	test: 0.684510
PRC train: 0.997740	val: 0.858128	test: 0.715448

Epoch: 29
Loss: 0.140922476313662
ROC train: 0.988414	val: 0.910168	test: 0.690104
PRC train: 0.997639	val: 0.862957	test: 0.716819

Epoch: 30
Loss: 0.1475238678719504
ROC train: 0.986105	val: 0.912978	test: 0.677276
PRC train: 0.997060	val: 0.868041	test: 0.686552

Epoch: 31
Loss: 0.12935805181641546
ROC train: 0.990086	val: 0.904045	test: 0.682099
PRC train: 0.997956	val: 0.860311	test: 0.703937

Epoch: 32
Loss: 0.1262711280514816
ROC train: 0.991099	val: 0.902038	test: 0.670235Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/bbbp/noise=0.1.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.1
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/bbbp/noise=0.1
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/bbbp/noise=0.1/bbbp_scaff_6_26-05_11-17-34  ]
[ Using Seed :  6  ]
[ Using device :  cuda:2  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6151314708175768
ROC train: 0.768381	val: 0.885978	test: 0.602334
PRC train: 0.933760	val: 0.839957	test: 0.621409

Epoch: 2
Loss: 0.5311172128285931
ROC train: 0.810677	val: 0.911372	test: 0.615837
PRC train: 0.947215	val: 0.870061	test: 0.643753

Epoch: 3
Loss: 0.45992174478337017
ROC train: 0.840142	val: 0.905450	test: 0.625000
PRC train: 0.957543	val: 0.858639	test: 0.653664

Epoch: 4
Loss: 0.4044093169116554
ROC train: 0.870482	val: 0.904748	test: 0.638310
PRC train: 0.965550	val: 0.843321	test: 0.697573

Epoch: 5
Loss: 0.3647438246961996
ROC train: 0.891399	val: 0.906153	test: 0.649595
PRC train: 0.973412	val: 0.827768	test: 0.677899

Epoch: 6
Loss: 0.33587639723042434
ROC train: 0.902601	val: 0.903242	test: 0.649498
PRC train: 0.976836	val: 0.814654	test: 0.671418

Epoch: 7
Loss: 0.31292875537974946
ROC train: 0.920892	val: 0.891398	test: 0.658951
PRC train: 0.981900	val: 0.767489	test: 0.699868

Epoch: 8
Loss: 0.2883557761419942
ROC train: 0.928012	val: 0.903242	test: 0.662230
PRC train: 0.983784	val: 0.791142	test: 0.704884

Epoch: 9
Loss: 0.2665937210859898
ROC train: 0.934607	val: 0.906554	test: 0.664641
PRC train: 0.985213	val: 0.808873	test: 0.707760

Epoch: 10
Loss: 0.26009155165286457
ROC train: 0.937654	val: 0.913781	test: 0.655575
PRC train: 0.985837	val: 0.822134	test: 0.674449

Epoch: 11
Loss: 0.25654280920907546
ROC train: 0.946488	val: 0.904647	test: 0.673032
PRC train: 0.988453	val: 0.813397	test: 0.703823

Epoch: 12
Loss: 0.2505550984727315
ROC train: 0.947890	val: 0.898826	test: 0.664255
PRC train: 0.988568	val: 0.803681	test: 0.680196

Epoch: 13
Loss: 0.22604333804134408
ROC train: 0.956332	val: 0.897320	test: 0.665895
PRC train: 0.990751	val: 0.787384	test: 0.708967

Epoch: 14
Loss: 0.2257349853601129
ROC train: 0.961696	val: 0.891800	test: 0.668885
PRC train: 0.991912	val: 0.778788	test: 0.712033

Epoch: 15
Loss: 0.20241957200081576
ROC train: 0.965177	val: 0.899227	test: 0.659819
PRC train: 0.992638	val: 0.794872	test: 0.696611

Epoch: 16
Loss: 0.20964490704527222
ROC train: 0.968184	val: 0.889893	test: 0.662230
PRC train: 0.993260	val: 0.774292	test: 0.706601

Epoch: 17
Loss: 0.19875796118440436
ROC train: 0.968642	val: 0.897320	test: 0.674865
PRC train: 0.993354	val: 0.811461	test: 0.719586

Epoch: 18
Loss: 0.19574466171904667
ROC train: 0.978121	val: 0.892302	test: 0.680266
PRC train: 0.995556	val: 0.808854	test: 0.731769

Epoch: 19
Loss: 0.1889672626332526
ROC train: 0.978068	val: 0.896617	test: 0.665509
PRC train: 0.995566	val: 0.798236	test: 0.711727

Epoch: 20
Loss: 0.19760062755524319
ROC train: 0.982974	val: 0.899930	test: 0.673900
PRC train: 0.996615	val: 0.807163	test: 0.729299

Epoch: 21
Loss: 0.18146794471047917
ROC train: 0.981877	val: 0.895313	test: 0.673997
PRC train: 0.996283	val: 0.820989	test: 0.726798

Epoch: 22
Loss: 0.17027018532681093
ROC train: 0.984506	val: 0.890595	test: 0.664834
PRC train: 0.996855	val: 0.798909	test: 0.719370

Epoch: 23
Loss: 0.17807340586472606
ROC train: 0.978146	val: 0.899930	test: 0.667631
PRC train: 0.995375	val: 0.815663	test: 0.717605

Epoch: 24
Loss: 0.15526417684444974
ROC train: 0.984478	val: 0.859781	test: 0.653260
PRC train: 0.996853	val: 0.738524	test: 0.700824

Epoch: 25
Loss: 0.1579643249346551
ROC train: 0.987163	val: 0.894008	test: 0.665992
PRC train: 0.997466	val: 0.796365	test: 0.725216

Epoch: 26
Loss: 0.14293759675303458
ROC train: 0.988220	val: 0.894811	test: 0.667438
PRC train: 0.997665	val: 0.803473	test: 0.716057

Epoch: 27
Loss: 0.15508709052544087
ROC train: 0.993435	val: 0.885276	test: 0.661555
PRC train: 0.998742	val: 0.802889	test: 0.695836

Epoch: 28
Loss: 0.14309043323691426
ROC train: 0.990798	val: 0.886279	test: 0.679012
PRC train: 0.998206	val: 0.786724	test: 0.720272

Epoch: 29
Loss: 0.11964242781118505
ROC train: 0.991188	val: 0.885376	test: 0.646701
PRC train: 0.998244	val: 0.800713	test: 0.677449

Epoch: 30
Loss: 0.13432628093495586
ROC train: 0.992442	val: 0.890595	test: 0.650945
PRC train: 0.998531	val: 0.800677	test: 0.700238

Epoch: 31
Loss: 0.14060594764326584
ROC train: 0.992462	val: 0.888588	test: 0.662037
PRC train: 0.998510	val: 0.809330	test: 0.704430

Epoch: 32
Loss: 0.1376531590391907
ROC train: 0.991340	val: 0.887785	test: 0.674865Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/bbbp/noise=0.2.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:3
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.2
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/bbbp/noise=0.2
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/bbbp/noise=0.2/bbbp_scaff_5_26-05_11-17-34  ]
[ Using Seed :  5  ]
[ Using device :  cuda:3  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6343760041320381
ROC train: 0.741881	val: 0.854261	test: 0.572434
PRC train: 0.927471	val: 0.815084	test: 0.637485

Epoch: 2
Loss: 0.5471883189803941
ROC train: 0.779686	val: 0.896417	test: 0.592882
PRC train: 0.941085	val: 0.847139	test: 0.654323

Epoch: 3
Loss: 0.48896013766382873
ROC train: 0.819963	val: 0.900030	test: 0.610147
PRC train: 0.952101	val: 0.849313	test: 0.669784

Epoch: 4
Loss: 0.431561477030136
ROC train: 0.854472	val: 0.881261	test: 0.624228
PRC train: 0.961869	val: 0.824256	test: 0.670508

Epoch: 5
Loss: 0.38921139696021434
ROC train: 0.867261	val: 0.896919	test: 0.625386
PRC train: 0.966147	val: 0.833480	test: 0.668609

Epoch: 6
Loss: 0.3564184752286343
ROC train: 0.891340	val: 0.892603	test: 0.600309
PRC train: 0.972630	val: 0.823462	test: 0.643384

Epoch: 7
Loss: 0.3311254327308642
ROC train: 0.898614	val: 0.896818	test: 0.606481
PRC train: 0.973721	val: 0.821784	test: 0.636148

Epoch: 8
Loss: 0.31508063874313713
ROC train: 0.911808	val: 0.892502	test: 0.618345
PRC train: 0.979560	val: 0.816529	test: 0.643354

Epoch: 9
Loss: 0.2993881692113601
ROC train: 0.927860	val: 0.885075	test: 0.620081
PRC train: 0.982777	val: 0.813441	test: 0.656572

Epoch: 10
Loss: 0.2897479020248802
ROC train: 0.933100	val: 0.900733	test: 0.622685
PRC train: 0.982908	val: 0.828838	test: 0.647720

Epoch: 11
Loss: 0.2564913912665065
ROC train: 0.946280	val: 0.900231	test: 0.614776
PRC train: 0.986547	val: 0.823778	test: 0.648624

Epoch: 12
Loss: 0.24853165492178855
ROC train: 0.954169	val: 0.914584	test: 0.625000
PRC train: 0.989105	val: 0.833525	test: 0.643059

Epoch: 13
Loss: 0.2552334591536618
ROC train: 0.956803	val: 0.904145	test: 0.630305
PRC train: 0.989354	val: 0.817969	test: 0.657758

Epoch: 14
Loss: 0.23817155367887896
ROC train: 0.964669	val: 0.900331	test: 0.611690
PRC train: 0.991799	val: 0.818666	test: 0.637810

Epoch: 15
Loss: 0.2186526418484606
ROC train: 0.965873	val: 0.900532	test: 0.614005
PRC train: 0.992150	val: 0.817457	test: 0.636868

Epoch: 16
Loss: 0.22357746712783605
ROC train: 0.972465	val: 0.897822	test: 0.615258
PRC train: 0.993522	val: 0.821063	test: 0.633859

Epoch: 17
Loss: 0.20118476479284358
ROC train: 0.978354	val: 0.887383	test: 0.620177
PRC train: 0.994957	val: 0.805621	test: 0.654743

Epoch: 18
Loss: 0.2173143235849377
ROC train: 0.979355	val: 0.894710	test: 0.627990
PRC train: 0.995043	val: 0.802503	test: 0.651738

Epoch: 19
Loss: 0.20632349451511672
ROC train: 0.978062	val: 0.880960	test: 0.631655
PRC train: 0.994860	val: 0.781653	test: 0.637625

Epoch: 20
Loss: 0.1953691431522324
ROC train: 0.983810	val: 0.868313	test: 0.622878
PRC train: 0.996078	val: 0.777480	test: 0.651877

Epoch: 21
Loss: 0.18692753531616266
ROC train: 0.985468	val: 0.900733	test: 0.633005
PRC train: 0.996367	val: 0.818046	test: 0.659401

Epoch: 22
Loss: 0.1780861390715544
ROC train: 0.989048	val: 0.872227	test: 0.642843
PRC train: 0.997354	val: 0.784031	test: 0.680234

Epoch: 23
Loss: 0.17486470700557868
ROC train: 0.990305	val: 0.858376	test: 0.624035
PRC train: 0.997554	val: 0.767021	test: 0.632220

Epoch: 24
Loss: 0.16586574372828336
ROC train: 0.994544	val: 0.885376	test: 0.648052
PRC train: 0.998768	val: 0.803757	test: 0.675771

Epoch: 25
Loss: 0.13884249151711106
ROC train: 0.991309	val: 0.899227	test: 0.654803
PRC train: 0.998107	val: 0.831385	test: 0.666285

Epoch: 26
Loss: 0.1523365353816693
ROC train: 0.994297	val: 0.894409	test: 0.656732
PRC train: 0.998698	val: 0.828297	test: 0.685939

Epoch: 27
Loss: 0.13172311609645887
ROC train: 0.993823	val: 0.885476	test: 0.640239
PRC train: 0.998693	val: 0.810109	test: 0.654064

Epoch: 28
Loss: 0.13155840875545238
ROC train: 0.995119	val: 0.886681	test: 0.652488
PRC train: 0.998914	val: 0.806970	test: 0.690331

Epoch: 29
Loss: 0.11290374818267382
ROC train: 0.996064	val: 0.889391	test: 0.637924
PRC train: 0.999109	val: 0.799854	test: 0.666181

Epoch: 30
Loss: 0.12708344909523786
ROC train: 0.997256	val: 0.886781	test: 0.634066
PRC train: 0.999395	val: 0.797942	test: 0.656219

Epoch: 31
Loss: 0.1272800021223478
ROC train: 0.997798	val: 0.868614	test: 0.622782
PRC train: 0.999552	val: 0.767308	test: 0.629883

Epoch: 32
Loss: 0.09977121503933441
ROC train: 0.997363	val: 0.866305	test: 0.627797Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/bbbp/noise=0.2.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:3
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.2
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/bbbp/noise=0.2
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/bbbp/noise=0.2/bbbp_scaff_6_26-05_11-17-34  ]
[ Using Seed :  6  ]
[ Using device :  cuda:3  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6202736061490602
ROC train: 0.740047	val: 0.854462	test: 0.602623
PRC train: 0.930985	val: 0.799318	test: 0.618012

Epoch: 2
Loss: 0.5423704133900579
ROC train: 0.775950	val: 0.897621	test: 0.589603
PRC train: 0.936591	val: 0.852937	test: 0.636760

Epoch: 3
Loss: 0.48320092589641117
ROC train: 0.792717	val: 0.900532	test: 0.601852
PRC train: 0.942921	val: 0.839156	test: 0.647418

Epoch: 4
Loss: 0.43356993821730366
ROC train: 0.823573	val: 0.884974	test: 0.589024
PRC train: 0.949667	val: 0.819571	test: 0.650548

Epoch: 5
Loss: 0.39102181158644617
ROC train: 0.852396	val: 0.885476	test: 0.599344
PRC train: 0.961440	val: 0.810940	test: 0.658734

Epoch: 6
Loss: 0.3634576962748051
ROC train: 0.873644	val: 0.884774	test: 0.616030
PRC train: 0.968844	val: 0.778871	test: 0.637978

Epoch: 7
Loss: 0.3388095409179536
ROC train: 0.894403	val: 0.870922	test: 0.616802
PRC train: 0.974709	val: 0.763284	test: 0.651380

Epoch: 8
Loss: 0.317689457349157
ROC train: 0.905981	val: 0.862592	test: 0.617766
PRC train: 0.977720	val: 0.750544	test: 0.662033

Epoch: 9
Loss: 0.3008002323734725
ROC train: 0.919595	val: 0.891097	test: 0.627411
PRC train: 0.981582	val: 0.791841	test: 0.671932

Epoch: 10
Loss: 0.27876779575089794
ROC train: 0.925966	val: 0.897621	test: 0.612172
PRC train: 0.982965	val: 0.800314	test: 0.640668

Epoch: 11
Loss: 0.27770418594651425
ROC train: 0.937502	val: 0.889290	test: 0.614680
PRC train: 0.985810	val: 0.781481	test: 0.645686

Epoch: 12
Loss: 0.2685602610033933
ROC train: 0.937948	val: 0.886179	test: 0.618441
PRC train: 0.985802	val: 0.775735	test: 0.641307

Epoch: 13
Loss: 0.2521376668821676
ROC train: 0.945671	val: 0.886781	test: 0.609568
PRC train: 0.987734	val: 0.781792	test: 0.643146

Epoch: 14
Loss: 0.2537836665588198
ROC train: 0.961718	val: 0.874435	test: 0.600212
PRC train: 0.991426	val: 0.771872	test: 0.634515

Epoch: 15
Loss: 0.21525615252336672
ROC train: 0.963617	val: 0.888688	test: 0.608603
PRC train: 0.991990	val: 0.789440	test: 0.645371

Epoch: 16
Loss: 0.2265747695520925
ROC train: 0.959698	val: 0.872930	test: 0.616223
PRC train: 0.991045	val: 0.759040	test: 0.654737

Epoch: 17
Loss: 0.21184672202535698
ROC train: 0.970210	val: 0.867911	test: 0.599537
PRC train: 0.993462	val: 0.774707	test: 0.625692

Epoch: 18
Loss: 0.2164887377166629
ROC train: 0.974757	val: 0.855164	test: 0.592593
PRC train: 0.994617	val: 0.756761	test: 0.611622

Epoch: 19
Loss: 0.19745037092576836
ROC train: 0.976407	val: 0.877848	test: 0.610725
PRC train: 0.994945	val: 0.792245	test: 0.641343

Epoch: 20
Loss: 0.19556796403033921
ROC train: 0.980924	val: 0.861488	test: 0.616898
PRC train: 0.996088	val: 0.761073	test: 0.645286

Epoch: 21
Loss: 0.1830260074832514
ROC train: 0.983179	val: 0.866908	test: 0.613715
PRC train: 0.996509	val: 0.778754	test: 0.660727

Epoch: 22
Loss: 0.172206118491026
ROC train: 0.990588	val: 0.824952	test: 0.613715
PRC train: 0.998103	val: 0.714538	test: 0.656549

Epoch: 23
Loss: 0.17180417472698523
ROC train: 0.989463	val: 0.861488	test: 0.632041
PRC train: 0.997806	val: 0.750078	test: 0.674936

Epoch: 24
Loss: 0.16063815437137688
ROC train: 0.990784	val: 0.843421	test: 0.621335
PRC train: 0.998139	val: 0.722570	test: 0.651861

Epoch: 25
Loss: 0.15847192701950272
ROC train: 0.995469	val: 0.833082	test: 0.616609
PRC train: 0.999139	val: 0.728541	test: 0.639127

Epoch: 26
Loss: 0.15128245868496154
ROC train: 0.994398	val: 0.829971	test: 0.627604
PRC train: 0.998881	val: 0.715785	test: 0.643328

Epoch: 27
Loss: 0.14488575748057145
ROC train: 0.995228	val: 0.836897	test: 0.630787
PRC train: 0.999057	val: 0.728646	test: 0.652535

Epoch: 28
Loss: 0.1459332134293275
ROC train: 0.994095	val: 0.843220	test: 0.610629
PRC train: 0.998788	val: 0.762382	test: 0.631782

Epoch: 29
Loss: 0.13399923660138433
ROC train: 0.996608	val: 0.820235	test: 0.620563
PRC train: 0.999339	val: 0.735249	test: 0.638516

Epoch: 30
Loss: 0.1379718846191998
ROC train: 0.996072	val: 0.865302	test: 0.649691
PRC train: 0.999241	val: 0.776037	test: 0.672757

Epoch: 31
Loss: 0.12619294790662489
ROC train: 0.995820	val: 0.859781	test: 0.637635
PRC train: 0.999143	val: 0.785517	test: 0.660084

Epoch: 32
Loss: 0.133649951350982
ROC train: 0.998162	val: 0.826759	test: 0.614873Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/bbbp/noise=0.1.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.1
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/bbbp/noise=0.1
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/bbbp/noise=0.1/bbbp_scaff_5_26-05_11-17-34  ]
[ Using Seed :  5  ]
[ Using device :  cuda:2  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6300789085383667
ROC train: 0.774715	val: 0.865703	test: 0.551312
PRC train: 0.939339	val: 0.813453	test: 0.618522

Epoch: 2
Loss: 0.5245804204492946
ROC train: 0.814212	val: 0.909967	test: 0.578511
PRC train: 0.950831	val: 0.866670	test: 0.645596

Epoch: 3
Loss: 0.46777795303303293
ROC train: 0.849503	val: 0.912677	test: 0.583623
PRC train: 0.958835	val: 0.877877	test: 0.639900

Epoch: 4
Loss: 0.39559529763761875
ROC train: 0.877083	val: 0.903643	test: 0.601466
PRC train: 0.970463	val: 0.832206	test: 0.639361

Epoch: 5
Loss: 0.3584956234367523
ROC train: 0.898207	val: 0.905049	test: 0.615644
PRC train: 0.976169	val: 0.828884	test: 0.656031

Epoch: 6
Loss: 0.33397223951540694
ROC train: 0.912403	val: 0.897119	test: 0.621528
PRC train: 0.979744	val: 0.800425	test: 0.637805

Epoch: 7
Loss: 0.2984044026438329
ROC train: 0.925950	val: 0.900231	test: 0.640239
PRC train: 0.983307	val: 0.815525	test: 0.690372

Epoch: 8
Loss: 0.2941246483154866
ROC train: 0.932537	val: 0.902339	test: 0.638792
PRC train: 0.984828	val: 0.819159	test: 0.672006

Epoch: 9
Loss: 0.26818833042958234
ROC train: 0.942998	val: 0.911071	test: 0.632041
PRC train: 0.986841	val: 0.850991	test: 0.684592

Epoch: 10
Loss: 0.27943965777703833
ROC train: 0.943991	val: 0.915889	test: 0.623746
PRC train: 0.987164	val: 0.858310	test: 0.670458

Epoch: 11
Loss: 0.23631957245665944
ROC train: 0.943096	val: 0.911171	test: 0.621238
PRC train: 0.987085	val: 0.837973	test: 0.646780

Epoch: 12
Loss: 0.23076209189040123
ROC train: 0.953100	val: 0.909164	test: 0.640625
PRC train: 0.989234	val: 0.824173	test: 0.698454

Epoch: 13
Loss: 0.24108837346052894
ROC train: 0.957521	val: 0.896718	test: 0.653549
PRC train: 0.990273	val: 0.793146	test: 0.701716

Epoch: 14
Loss: 0.22038925919614102
ROC train: 0.963087	val: 0.901837	test: 0.646412
PRC train: 0.991614	val: 0.831252	test: 0.678971

Epoch: 15
Loss: 0.22108208310324154
ROC train: 0.966728	val: 0.913078	test: 0.653549
PRC train: 0.992345	val: 0.835194	test: 0.710422

Epoch: 16
Loss: 0.21367242827891655
ROC train: 0.964852	val: 0.894409	test: 0.642843
PRC train: 0.992136	val: 0.794779	test: 0.682615

Epoch: 17
Loss: 0.2060838762862098
ROC train: 0.968563	val: 0.908060	test: 0.639564
PRC train: 0.992878	val: 0.825090	test: 0.676167

Epoch: 18
Loss: 0.20434551922156227
ROC train: 0.974536	val: 0.905450	test: 0.644772
PRC train: 0.994317	val: 0.813864	test: 0.682348

Epoch: 19
Loss: 0.19981266346275617
ROC train: 0.976749	val: 0.890997	test: 0.652681
PRC train: 0.994948	val: 0.765272	test: 0.710508

Epoch: 20
Loss: 0.1933196850980661
ROC train: 0.979880	val: 0.899428	test: 0.641975
PRC train: 0.995696	val: 0.809604	test: 0.687931

Epoch: 21
Loss: 0.1672223683837883
ROC train: 0.978926	val: 0.880157	test: 0.629823
PRC train: 0.995553	val: 0.769681	test: 0.641151

Epoch: 22
Loss: 0.16376405002378475
ROC train: 0.985718	val: 0.912677	test: 0.653356
PRC train: 0.996957	val: 0.844285	test: 0.707701

Epoch: 23
Loss: 0.1669732760051303
ROC train: 0.987676	val: 0.892603	test: 0.653453
PRC train: 0.997465	val: 0.796991	test: 0.680268

Epoch: 24
Loss: 0.16616787378417588
ROC train: 0.989048	val: 0.886580	test: 0.638696
PRC train: 0.997821	val: 0.770865	test: 0.665184

Epoch: 25
Loss: 0.15461715077685848
ROC train: 0.989284	val: 0.900632	test: 0.650559
PRC train: 0.997782	val: 0.808467	test: 0.693712

Epoch: 26
Loss: 0.15589826925528993
ROC train: 0.990422	val: 0.898525	test: 0.659819
PRC train: 0.998049	val: 0.820984	test: 0.701165

Epoch: 27
Loss: 0.1577002029684966
ROC train: 0.991676	val: 0.876041	test: 0.643036
PRC train: 0.998346	val: 0.785492	test: 0.665658

Epoch: 28
Loss: 0.13840519668767554
ROC train: 0.992316	val: 0.879554	test: 0.650174
PRC train: 0.998390	val: 0.782190	test: 0.699214

Epoch: 29
Loss: 0.1378310609398018
ROC train: 0.992490	val: 0.892000	test: 0.625579
PRC train: 0.998383	val: 0.796791	test: 0.630662

Epoch: 30
Loss: 0.13865977040267968
ROC train: 0.992075	val: 0.884473	test: 0.624614
PRC train: 0.998371	val: 0.795961	test: 0.657265

Epoch: 31
Loss: 0.12983661786610462
ROC train: 0.995447	val: 0.887082	test: 0.624614
PRC train: 0.999090	val: 0.792238	test: 0.642905

Epoch: 32
Loss: 0.11675431143761283
ROC train: 0.996260	val: 0.899629	test: 0.633970Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/bbbp/noise=0.1.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.1
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/bbbp/noise=0.1
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/bbbp/noise=0.1/bbbp_scaff_4_26-05_11-17-34  ]
[ Using Seed :  4  ]
[ Using device :  cuda:2  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.61420557919691
ROC train: 0.775801	val: 0.904547	test: 0.584973
PRC train: 0.940208	val: 0.862684	test: 0.652198

Epoch: 2
Loss: 0.5265302530806679
ROC train: 0.815211	val: 0.915287	test: 0.606481
PRC train: 0.952736	val: 0.877517	test: 0.665904

Epoch: 3
Loss: 0.45291598668305355
ROC train: 0.846841	val: 0.915788	test: 0.609086
PRC train: 0.958898	val: 0.886111	test: 0.656158

Epoch: 4
Loss: 0.3922318797880351
ROC train: 0.871775	val: 0.912577	test: 0.637924
PRC train: 0.968132	val: 0.863733	test: 0.676360

Epoch: 5
Loss: 0.363247235903679
ROC train: 0.889452	val: 0.917695	test: 0.634838
PRC train: 0.972974	val: 0.868041	test: 0.679929

Epoch: 6
Loss: 0.33150910089104046
ROC train: 0.905243	val: 0.909164	test: 0.654803
PRC train: 0.977841	val: 0.838218	test: 0.697554

Epoch: 7
Loss: 0.3045057538715669
ROC train: 0.919012	val: 0.902339	test: 0.649113
PRC train: 0.981575	val: 0.818617	test: 0.694811

Epoch: 8
Loss: 0.2868822614173507
ROC train: 0.930200	val: 0.911774	test: 0.651524
PRC train: 0.984491	val: 0.829628	test: 0.720378

Epoch: 9
Loss: 0.2614273206573285
ROC train: 0.935970	val: 0.931547	test: 0.648823
PRC train: 0.986103	val: 0.877604	test: 0.703424

Epoch: 10
Loss: 0.2535435955558724
ROC train: 0.941581	val: 0.936063	test: 0.654996
PRC train: 0.987384	val: 0.881180	test: 0.694531

Epoch: 11
Loss: 0.25853491358465414
ROC train: 0.950979	val: 0.940078	test: 0.653935
PRC train: 0.989706	val: 0.879433	test: 0.705500

Epoch: 12
Loss: 0.24813858511985637
ROC train: 0.955653	val: 0.926227	test: 0.644097
PRC train: 0.990666	val: 0.856723	test: 0.672915

Epoch: 13
Loss: 0.22751240012248508
ROC train: 0.954688	val: 0.931346	test: 0.670910
PRC train: 0.990238	val: 0.874017	test: 0.716387

Epoch: 14
Loss: 0.2273071974191053
ROC train: 0.967160	val: 0.922915	test: 0.686728
PRC train: 0.993355	val: 0.850933	test: 0.748539

Epoch: 15
Loss: 0.21744201329527404
ROC train: 0.970591	val: 0.923316	test: 0.684703
PRC train: 0.994149	val: 0.848266	test: 0.742107

Epoch: 16
Loss: 0.20059345860376454
ROC train: 0.971526	val: 0.942286	test: 0.674190
PRC train: 0.994001	val: 0.879156	test: 0.738435

Epoch: 17
Loss: 0.20298369850787976
ROC train: 0.975924	val: 0.923015	test: 0.678723
PRC train: 0.995176	val: 0.833095	test: 0.722456

Epoch: 18
Loss: 0.19277755467886312
ROC train: 0.980082	val: 0.913078	test: 0.676215
PRC train: 0.996065	val: 0.823900	test: 0.729284

Epoch: 19
Loss: 0.1794588125215028
ROC train: 0.981022	val: 0.922313	test: 0.673129
PRC train: 0.996246	val: 0.847907	test: 0.713986

Epoch: 20
Loss: 0.17866504465339636
ROC train: 0.988840	val: 0.933755	test: 0.682677
PRC train: 0.997822	val: 0.864966	test: 0.735392

Epoch: 21
Loss: 0.1709079069093964
ROC train: 0.983507	val: 0.925023	test: 0.677373
PRC train: 0.996634	val: 0.847702	test: 0.725751

Epoch: 22
Loss: 0.17803553683323506
ROC train: 0.987137	val: 0.936264	test: 0.658372
PRC train: 0.997482	val: 0.872637	test: 0.683373

Epoch: 23
Loss: 0.17294213854462365
ROC train: 0.990639	val: 0.932350	test: 0.671971
PRC train: 0.998138	val: 0.880249	test: 0.713005

Epoch: 24
Loss: 0.15563224901240608
ROC train: 0.988725	val: 0.921911	test: 0.684028
PRC train: 0.997763	val: 0.856884	test: 0.734592

Epoch: 25
Loss: 0.15437883825509752
ROC train: 0.991629	val: 0.920907	test: 0.686728
PRC train: 0.998353	val: 0.854154	test: 0.741839

Epoch: 26
Loss: 0.1457554470402603
ROC train: 0.992821	val: 0.916190	test: 0.684703
PRC train: 0.998604	val: 0.846197	test: 0.744180

Epoch: 27
Loss: 0.15461749321148105
ROC train: 0.991208	val: 0.918298	test: 0.679880
PRC train: 0.998310	val: 0.852177	test: 0.734848

Epoch: 28
Loss: 0.145947728152538
ROC train: 0.995085	val: 0.921008	test: 0.684992
PRC train: 0.999061	val: 0.857578	test: 0.743287

Epoch: 29
Loss: 0.13522775805394108
ROC train: 0.994681	val: 0.920205	test: 0.672261
PRC train: 0.998964	val: 0.860400	test: 0.732345

Epoch: 30
Loss: 0.12423160292892044
ROC train: 0.995904	val: 0.924420	test: 0.674286
PRC train: 0.999204	val: 0.875099	test: 0.741911

Epoch: 31
Loss: 0.12531055824008272
ROC train: 0.995820	val: 0.914885	test: 0.673804
PRC train: 0.999195	val: 0.855924	test: 0.733119

Epoch: 32
Loss: 0.11995448808233992
ROC train: 0.995461	val: 0.922714	test: 0.687982Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/bbbp/noise=0.2.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:3
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.2
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/bbbp/noise=0.2
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/bbbp/noise=0.2/bbbp_scaff_4_26-05_11-17-34  ]
[ Using Seed :  4  ]
[ Using device :  cuda:3  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6228905333292627
ROC train: 0.722148	val: 0.892201	test: 0.579090
PRC train: 0.922635	val: 0.852603	test: 0.641114

Epoch: 2
Loss: 0.5433441574887342
ROC train: 0.753010	val: 0.910368	test: 0.606289
PRC train: 0.933483	val: 0.857575	test: 0.654704

Epoch: 3
Loss: 0.4842031988432686
ROC train: 0.775574	val: 0.907759	test: 0.595968
PRC train: 0.939260	val: 0.869709	test: 0.644247

Epoch: 4
Loss: 0.4337329368792559
ROC train: 0.810369	val: 0.913681	test: 0.626833
PRC train: 0.949641	val: 0.869062	test: 0.674476

Epoch: 5
Loss: 0.4005419935994719
ROC train: 0.836080	val: 0.914283	test: 0.635995
PRC train: 0.956807	val: 0.862997	test: 0.687809

Epoch: 6
Loss: 0.37474512713001384
ROC train: 0.863485	val: 0.909766	test: 0.651042
PRC train: 0.965215	val: 0.839668	test: 0.682941

Epoch: 7
Loss: 0.34277004731771826
ROC train: 0.875206	val: 0.906454	test: 0.638600
PRC train: 0.968303	val: 0.832633	test: 0.666255

Epoch: 8
Loss: 0.32228271073780695
ROC train: 0.889157	val: 0.912275	test: 0.654707
PRC train: 0.972465	val: 0.830965	test: 0.684999

Epoch: 9
Loss: 0.29307419482130054
ROC train: 0.903361	val: 0.913681	test: 0.642072
PRC train: 0.977079	val: 0.846093	test: 0.685141

Epoch: 10
Loss: 0.2942671837333513
ROC train: 0.922698	val: 0.915186	test: 0.653742
PRC train: 0.981923	val: 0.837530	test: 0.682999

Epoch: 11
Loss: 0.29139975921457467
ROC train: 0.929021	val: 0.917495	test: 0.644097
PRC train: 0.983441	val: 0.840476	test: 0.680115

Epoch: 12
Loss: 0.2774700763461437
ROC train: 0.932063	val: 0.917896	test: 0.639468
PRC train: 0.983940	val: 0.838825	test: 0.674039

Epoch: 13
Loss: 0.2795219988113569
ROC train: 0.938989	val: 0.916591	test: 0.638021
PRC train: 0.985992	val: 0.841246	test: 0.674109

Epoch: 14
Loss: 0.2603626472108538
ROC train: 0.951234	val: 0.909967	test: 0.650559
PRC train: 0.989442	val: 0.829432	test: 0.680586

Epoch: 15
Loss: 0.24182142482107985
ROC train: 0.956363	val: 0.920205	test: 0.656346
PRC train: 0.990522	val: 0.848257	test: 0.694017

Epoch: 16
Loss: 0.23531338776060648
ROC train: 0.957159	val: 0.932350	test: 0.657022
PRC train: 0.990620	val: 0.855506	test: 0.711112

Epoch: 17
Loss: 0.22219107803766766
ROC train: 0.968602	val: 0.933353	test: 0.655671
PRC train: 0.993481	val: 0.851968	test: 0.707328

Epoch: 18
Loss: 0.22022969023863165
ROC train: 0.972628	val: 0.929539	test: 0.649884
PRC train: 0.994431	val: 0.853336	test: 0.692312

Epoch: 19
Loss: 0.20368741547283922
ROC train: 0.971554	val: 0.924320	test: 0.665027
PRC train: 0.993974	val: 0.847976	test: 0.698694

Epoch: 20
Loss: 0.20120570928700873
ROC train: 0.985272	val: 0.932350	test: 0.656829
PRC train: 0.997031	val: 0.852302	test: 0.708342

Epoch: 21
Loss: 0.20000809904166159
ROC train: 0.983241	val: 0.930142	test: 0.663002
PRC train: 0.996607	val: 0.863892	test: 0.702765

Epoch: 22
Loss: 0.20747436644123715
ROC train: 0.985729	val: 0.928736	test: 0.642747
PRC train: 0.997189	val: 0.868268	test: 0.679163

Epoch: 23
Loss: 0.1918253278072683
ROC train: 0.988731	val: 0.915688	test: 0.656732
PRC train: 0.997742	val: 0.856373	test: 0.699999

Epoch: 24
Loss: 0.18357006892902986
ROC train: 0.983417	val: 0.924119	test: 0.663387
PRC train: 0.996661	val: 0.868929	test: 0.706524

Epoch: 25
Loss: 0.17790032875636846
ROC train: 0.990829	val: 0.919201	test: 0.665992
PRC train: 0.998219	val: 0.847665	test: 0.706887

Epoch: 26
Loss: 0.1535765722337914
ROC train: 0.992490	val: 0.927733	test: 0.675444
PRC train: 0.998563	val: 0.870353	test: 0.724838

Epoch: 27
Loss: 0.1651467344753623
ROC train: 0.995152	val: 0.929138	test: 0.663580
PRC train: 0.999077	val: 0.873086	test: 0.709528

Epoch: 28
Loss: 0.15806838550157454
ROC train: 0.993292	val: 0.939576	test: 0.656057
PRC train: 0.998708	val: 0.875457	test: 0.704806

Epoch: 29
Loss: 0.1497087453996079
ROC train: 0.996967	val: 0.936365	test: 0.646701
PRC train: 0.999429	val: 0.864600	test: 0.699050

Epoch: 30
Loss: 0.1464013625552234
ROC train: 0.996000	val: 0.928034	test: 0.638985
PRC train: 0.999228	val: 0.856194	test: 0.696509

Epoch: 31
Loss: 0.1344272747546884
ROC train: 0.995228	val: 0.918599	test: 0.627604
PRC train: 0.999061	val: 0.855426	test: 0.684739

Epoch: 32
Loss: 0.12012057677250786
ROC train: 0.998115	val: 0.934457	test: 0.644001
ROC train: 0.982464	val: 0.934959	test: 0.703221
PRC train: 0.996190	val: 0.906707	test: 0.727286

Epoch: 34
Loss: 0.15427495271541117
ROC train: 0.976400	val: 0.943491	test: 0.707851
PRC train: 0.994203	val: 0.930135	test: 0.752096

Epoch: 35
Loss: 0.14175506959470274
ROC train: 0.983109	val: 0.919803	test: 0.679302
PRC train: 0.996496	val: 0.892286	test: 0.700485

Epoch: 36
Loss: 0.15565565588642108
ROC train: 0.985552	val: 0.928536	test: 0.668789
PRC train: 0.997089	val: 0.898424	test: 0.688576

Epoch: 37
Loss: 0.1448642664927041
ROC train: 0.982200	val: 0.930744	test: 0.699556
PRC train: 0.996146	val: 0.899466	test: 0.736027

Epoch: 38
Loss: 0.13481891168898744
ROC train: 0.985976	val: 0.925826	test: 0.686343
PRC train: 0.997097	val: 0.886282	test: 0.692915

Epoch: 39
Loss: 0.1459421325661514
ROC train: 0.981947	val: 0.930543	test: 0.696663
PRC train: 0.996107	val: 0.900447	test: 0.714219

Epoch: 40
Loss: 0.14876045810948937
ROC train: 0.983851	val: 0.915889	test: 0.684028
PRC train: 0.996633	val: 0.857261	test: 0.714209

Epoch: 41
Loss: 0.14336242837176508
ROC train: 0.986596	val: 0.919603	test: 0.668885
PRC train: 0.997308	val: 0.872636	test: 0.688008

Epoch: 42
Loss: 0.14042251442907866
ROC train: 0.985663	val: 0.912075	test: 0.678048
PRC train: 0.997126	val: 0.842984	test: 0.692026

Epoch: 43
Loss: 0.16108971361409755
ROC train: 0.987839	val: 0.921710	test: 0.691840
PRC train: 0.997502	val: 0.887637	test: 0.726492

Epoch: 44
Loss: 0.1557399051453234
ROC train: 0.988477	val: 0.927030	test: 0.706983
PRC train: 0.997617	val: 0.873352	test: 0.734396

Epoch: 45
Loss: 0.1441219810536285
ROC train: 0.987519	val: 0.931246	test: 0.690490
PRC train: 0.997486	val: 0.892324	test: 0.698841

Epoch: 46
Loss: 0.12272827041593591
ROC train: 0.988697	val: 0.927231	test: 0.693673
PRC train: 0.997704	val: 0.895049	test: 0.717572

Epoch: 47
Loss: 0.12575965170528627
ROC train: 0.990068	val: 0.934156	test: 0.679302
PRC train: 0.997995	val: 0.905166	test: 0.677886

Epoch: 48
Loss: 0.12057684293383204
ROC train: 0.989658	val: 0.920406	test: 0.676505
PRC train: 0.997959	val: 0.884134	test: 0.692350

Epoch: 49
Loss: 0.1374371389452554
ROC train: 0.991632	val: 0.916491	test: 0.690972
PRC train: 0.998373	val: 0.870556	test: 0.699438

Epoch: 50
Loss: 0.1206799170921865
ROC train: 0.992982	val: 0.922513	test: 0.709298
PRC train: 0.998647	val: 0.877457	test: 0.705643

Epoch: 51
Loss: 0.13213483717480684
ROC train: 0.992803	val: 0.921008	test: 0.708140
PRC train: 0.998598	val: 0.866179	test: 0.710475

Epoch: 52
Loss: 0.1270105518177708
ROC train: 0.993297	val: 0.921309	test: 0.698978
PRC train: 0.998697	val: 0.868544	test: 0.702979

Epoch: 53
Loss: 0.11914199047908318
ROC train: 0.992695	val: 0.919502	test: 0.700617
PRC train: 0.998585	val: 0.865696	test: 0.679994

Epoch: 54
Loss: 0.12780636085990857
ROC train: 0.992075	val: 0.929238	test: 0.680941
PRC train: 0.998452	val: 0.888049	test: 0.679207

Epoch: 55
Loss: 0.127188915349191
ROC train: 0.993726	val: 0.918097	test: 0.703993
PRC train: 0.998770	val: 0.867702	test: 0.710414

Epoch: 56
Loss: 0.1283070260976715
ROC train: 0.993008	val: 0.929941	test: 0.701003
PRC train: 0.998631	val: 0.885733	test: 0.710681

Epoch: 57
Loss: 0.12650652007079488
ROC train: 0.992400	val: 0.922011	test: 0.702353
PRC train: 0.998499	val: 0.884077	test: 0.719933

Epoch: 58
Loss: 0.11575012829882521
ROC train: 0.993417	val: 0.923818	test: 0.699749
PRC train: 0.998716	val: 0.889239	test: 0.721668

Epoch: 59
Loss: 0.11633571286041787
ROC train: 0.994318	val: 0.917093	test: 0.681713
PRC train: 0.998881	val: 0.864267	test: 0.679807

Epoch: 60
Loss: 0.11280914932484838
ROC train: 0.994737	val: 0.926829	test: 0.694927
PRC train: 0.998969	val: 0.892103	test: 0.703479

Epoch: 61
Loss: 0.10982567405633718
ROC train: 0.994096	val: 0.925826	test: 0.703897
PRC train: 0.998824	val: 0.891536	test: 0.711389

Epoch: 62
Loss: 0.12066826491016869
ROC train: 0.994854	val: 0.902740	test: 0.671586
PRC train: 0.998987	val: 0.848314	test: 0.681529

Epoch: 63
Loss: 0.10513298472925725
ROC train: 0.994451	val: 0.918599	test: 0.688561
PRC train: 0.998917	val: 0.869923	test: 0.706270

Epoch: 64
Loss: 0.11103445460955409
ROC train: 0.994955	val: 0.903342	test: 0.665606
PRC train: 0.999032	val: 0.840242	test: 0.688076

Epoch: 65
Loss: 0.10483500789537885
ROC train: 0.992135	val: 0.925424	test: 0.680073
PRC train: 0.998487	val: 0.888369	test: 0.702264

Epoch: 66
Loss: 0.10316349365706788
ROC train: 0.995694	val: 0.930543	test: 0.673997
PRC train: 0.999179	val: 0.894310	test: 0.678449

Epoch: 67
Loss: 0.11253076628596599
ROC train: 0.994842	val: 0.918398	test: 0.706983
PRC train: 0.998992	val: 0.868040	test: 0.721358

Epoch: 68
Loss: 0.1111246473000089
ROC train: 0.993072	val: 0.925424	test: 0.663484
PRC train: 0.998653	val: 0.879665	test: 0.687372

Epoch: 69
Loss: 0.10250171604004828
ROC train: 0.995197	val: 0.908060	test: 0.639853
PRC train: 0.999074	val: 0.833937	test: 0.637183

Epoch: 70
Loss: 0.10414676473224962
ROC train: 0.995952	val: 0.913078	test: 0.698688
PRC train: 0.999223	val: 0.867772	test: 0.698673

Epoch: 71
Loss: 0.11292254496508011
ROC train: 0.996203	val: 0.916792	test: 0.697145
PRC train: 0.999268	val: 0.884908	test: 0.708881

Epoch: 72
Loss: 0.11472680752494961
ROC train: 0.996154	val: 0.909666	test: 0.694252
PRC train: 0.999250	val: 0.868403	test: 0.712448

Epoch: 73
Loss: 0.08859965024003628
ROC train: 0.996252	val: 0.924521	test: 0.686825
PRC train: 0.999245	val: 0.881055	test: 0.681534

Epoch: 74
Loss: 0.09727016205673474
ROC train: 0.995457	val: 0.929037	test: 0.690779
PRC train: 0.999067	val: 0.898310	test: 0.693747

Epoch: 75
Loss: 0.1053771232835923
ROC train: 0.996806	val: 0.921409	test: 0.686053
PRC train: 0.999379	val: 0.882314	test: 0.695500

Epoch: 76
Loss: 0.10757603652644164
ROC train: 0.997621	val: 0.922212	test: 0.686535
PRC train: 0.999547	val: 0.875041	test: 0.696003

Epoch: 77
Loss: 0.08929131658551745
ROC train: 0.997085	val: 0.918599	test: 0.703704
PRC train: 0.999447	val: 0.869717	test: 0.721217

Epoch: 78
Loss: 0.10681585518618344
ROC train: 0.996615	val: 0.912978	test: 0.705054
PRC train: 0.999349	val: 0.864042	test: 0.719440

Epoch: 79
Loss: 0.10242127110608364
ROC train: 0.997442	val: 0.920305	test: 0.700328
PRC train: 0.999511	val: 0.885073	test: 0.711505

Epoch: 80
Loss: 0.07585276223212892
ROC train: 0.997398	val: 0.905751	test: 0.690008
PRC train: 0.999507	val: 0.864739	test: 0.694535

Epoch: 81
Loss: 0.09196651004725245
ROC train: 0.996468	val: 0.916290	test: 0.669174
PRC train: 0.999298	val: 0.881196	test: 0.671931

Epoch: 82
Loss: 0.09359066617346623
ROC train: 0.994988	val: 0.910368	test: 0.664255
PRC train: 0.999011	val: 0.867172	test: 0.671021

Epoch: 83
Loss: 0.10000429904514244
ROC train: 0.996370	val: 0.889491	test: 0.681617
PRC train: 0.999304	val: 0.834773	test: 0.687861

Epoch: 84
Loss: 0.08903379537110105
ROC train: 0.996437	val: 0.909264	test: 0.726755
PRC train: 0.999289	val: 0.876901	test: 0.727152

Epoch: 85
Loss: 0.08524004062833443
ROC train: 0.996754	val: 0.917997	test: 0.707851
PRC train: 0.999371	val: 0.878942	test: 0.692181

Epoch: 86
Loss: 0.10033833265468894
ROC train: 0.997785	val: 0.902941	test: 0.702932
PRC train: 0.999575	val: 0.824822	test: 0.713960

Epoch: 87
Loss: 0.08688127616912823
ROC train: 0.997517	val: 0.911272	test: 0.695795
PRC train: 0.999531	val: 0.844780	test: 0.697088

Epoch: 88
Loss: 0.0924608694618485
ROC train: 0.997632	val: 0.912777	test: 0.681520
PRC train: 0.999552	val: 0.860534	test: 0.678382

Epoch: 89
Loss: 0.09367532786496284
ROC train: 0.997436	val: 0.899127	test: 0.667631
PRC train: 0.999511	val: 0.815423	test: 0.668442

Epoch: 90
Loss: 0.09157597746520159
ROC train: 0.996719	val: 0.916491	test: 0.690008
PRC train: 0.999366	val: 0.858320	test: 0.683561

Epoch: 91
Loss: 0.08594917583525212
ROC train: 0.997590	val: 0.920104	test: 0.688850
PRC train: 0.999539	val: 0.855783	test: 0.669947

Epoch: 92
Loss: 0.08714806413488059
ROC train: 0.997700	val: 0.912275	test: 0.686246
PRC train: 0.999563	val: 0.840746	test: 0.691305

Epoch: 93
Loss: 0.09032813923418805
ROC train: 0.997874	val: 0.905049	test: 0.677276
PRC train: 0.999594	val: 0.847761	test: 0.687600

Epoch: 94
Loss: 0.07098819388764525
PRC train: 0.994833	val: 0.880776	test: 0.737104

Epoch: 34
Loss: 0.16057805444773027
ROC train: 0.977591	val: 0.931948	test: 0.710841
PRC train: 0.995279	val: 0.893285	test: 0.748403

Epoch: 35
Loss: 0.1592708519056409
ROC train: 0.974895	val: 0.906253	test: 0.700424
PRC train: 0.994599	val: 0.853508	test: 0.737711

Epoch: 36
Loss: 0.15689538866786992
ROC train: 0.979719	val: 0.913078	test: 0.695023
PRC train: 0.995697	val: 0.872591	test: 0.722847

Epoch: 37
Loss: 0.1489714543311345
ROC train: 0.981928	val: 0.925324	test: 0.693191
PRC train: 0.996281	val: 0.889203	test: 0.709991

Epoch: 38
Loss: 0.171563983136441
ROC train: 0.981152	val: 0.913881	test: 0.707079
PRC train: 0.996105	val: 0.863268	test: 0.723471

Epoch: 39
Loss: 0.1624761954916947
ROC train: 0.975498	val: 0.920907	test: 0.675926
PRC train: 0.994820	val: 0.870398	test: 0.693761

Epoch: 40
Loss: 0.16410771404184457
ROC train: 0.980200	val: 0.920205	test: 0.700907
PRC train: 0.995606	val: 0.889417	test: 0.732846

Epoch: 41
Loss: 0.14867457164300601
ROC train: 0.981239	val: 0.917194	test: 0.686921
PRC train: 0.996042	val: 0.865751	test: 0.699298

Epoch: 42
Loss: 0.14979239165509575
ROC train: 0.984749	val: 0.901435	test: 0.677855
PRC train: 0.996838	val: 0.827800	test: 0.686495

Epoch: 43
Loss: 0.15152558954205694
ROC train: 0.982910	val: 0.893907	test: 0.691069
PRC train: 0.996444	val: 0.830975	test: 0.714366

Epoch: 44
Loss: 0.1368093422474196
ROC train: 0.984137	val: 0.926729	test: 0.698978
PRC train: 0.996602	val: 0.887498	test: 0.710314

Epoch: 45
Loss: 0.14258552556330115
ROC train: 0.983225	val: 0.900933	test: 0.680170
PRC train: 0.996489	val: 0.814529	test: 0.679573

Epoch: 46
Loss: 0.133224753362791
ROC train: 0.986896	val: 0.906454	test: 0.706887
PRC train: 0.997400	val: 0.826986	test: 0.740482

Epoch: 47
Loss: 0.14800201177595995
ROC train: 0.983460	val: 0.919904	test: 0.703704
PRC train: 0.996592	val: 0.859059	test: 0.718395

Epoch: 48
Loss: 0.1499818632401725
ROC train: 0.986299	val: 0.914584	test: 0.696373
PRC train: 0.997221	val: 0.854032	test: 0.725066

Epoch: 49
Loss: 0.1314184431525269
ROC train: 0.986903	val: 0.906956	test: 0.687596
PRC train: 0.997374	val: 0.855073	test: 0.722981

Epoch: 50
Loss: 0.1332375402431592
ROC train: 0.987095	val: 0.913580	test: 0.698785
PRC train: 0.997341	val: 0.861632	test: 0.739167

Epoch: 51
Loss: 0.1368690889750539
ROC train: 0.986451	val: 0.925123	test: 0.710262
PRC train: 0.997196	val: 0.866203	test: 0.743545

Epoch: 52
Loss: 0.1288209229736803
ROC train: 0.989810	val: 0.910971	test: 0.702932
PRC train: 0.998007	val: 0.841052	test: 0.733645

Epoch: 53
Loss: 0.12134630560804383
ROC train: 0.989044	val: 0.909365	test: 0.704090
PRC train: 0.997820	val: 0.853274	test: 0.714110

Epoch: 54
Loss: 0.13269069372769474
ROC train: 0.988311	val: 0.915889	test: 0.713927
PRC train: 0.997647	val: 0.870282	test: 0.743923

Epoch: 55
Loss: 0.13455633197469083
ROC train: 0.991815	val: 0.908762	test: 0.709201
PRC train: 0.998390	val: 0.836859	test: 0.733235

Epoch: 56
Loss: 0.1115525506173846
ROC train: 0.991003	val: 0.899829	test: 0.683160
PRC train: 0.998206	val: 0.820298	test: 0.698489

Epoch: 57
Loss: 0.1265795706255434
ROC train: 0.990233	val: 0.903342	test: 0.690876
PRC train: 0.998050	val: 0.849073	test: 0.717706

Epoch: 58
Loss: 0.11312350787138681
ROC train: 0.993047	val: 0.908361	test: 0.684992
PRC train: 0.998633	val: 0.843051	test: 0.696351

Epoch: 59
Loss: 0.11146858522547455
ROC train: 0.992498	val: 0.917194	test: 0.697338
PRC train: 0.998530	val: 0.866802	test: 0.728944

Epoch: 60
Loss: 0.13387682145903837
ROC train: 0.993326	val: 0.903443	test: 0.702064
PRC train: 0.998693	val: 0.838363	test: 0.714383

Epoch: 61
Loss: 0.12161575393552505
ROC train: 0.993882	val: 0.906354	test: 0.696470
PRC train: 0.998815	val: 0.838022	test: 0.712990

Epoch: 62
Loss: 0.12145219599090351
ROC train: 0.992515	val: 0.914182	test: 0.701485
PRC train: 0.998541	val: 0.868050	test: 0.708057

Epoch: 63
Loss: 0.11232107607826003
ROC train: 0.993543	val: 0.914584	test: 0.711227
PRC train: 0.998749	val: 0.858195	test: 0.713133

Epoch: 64
Loss: 0.12742941767873586
ROC train: 0.993346	val: 0.912577	test: 0.705150
PRC train: 0.998718	val: 0.864824	test: 0.716938

Epoch: 65
Loss: 0.1145782775779025
ROC train: 0.992877	val: 0.917595	test: 0.696566
PRC train: 0.998614	val: 0.864871	test: 0.718206

Epoch: 66
Loss: 0.11238444598064386
ROC train: 0.994201	val: 0.904547	test: 0.705633
PRC train: 0.998871	val: 0.839374	test: 0.725877

Epoch: 67
Loss: 0.11204473805114554
ROC train: 0.990993	val: 0.885175	test: 0.667438
PRC train: 0.998236	val: 0.805494	test: 0.689248

Epoch: 68
Loss: 0.10144413066109716
ROC train: 0.993245	val: 0.896316	test: 0.688368
PRC train: 0.998704	val: 0.825138	test: 0.709265

Epoch: 69
Loss: 0.11406251146334997
ROC train: 0.994666	val: 0.899227	test: 0.685475
PRC train: 0.998974	val: 0.836733	test: 0.694350

Epoch: 70
Loss: 0.11148780694138218
ROC train: 0.995022	val: 0.892803	test: 0.666667
PRC train: 0.999047	val: 0.825492	test: 0.702701

Epoch: 71
Loss: 0.11320203155382703
ROC train: 0.994661	val: 0.896316	test: 0.685282
PRC train: 0.998966	val: 0.823591	test: 0.707684

Epoch: 72
Loss: 0.10375411856332904
ROC train: 0.994194	val: 0.908361	test: 0.694252
PRC train: 0.998868	val: 0.828360	test: 0.715910

Epoch: 73
Loss: 0.1079363332373093
ROC train: 0.993694	val: 0.897119	test: 0.706404
PRC train: 0.998746	val: 0.818156	test: 0.717651

Epoch: 74
Loss: 0.09392687454023539
ROC train: 0.995042	val: 0.911673	test: 0.678048
PRC train: 0.999044	val: 0.841830	test: 0.694539

Epoch: 75
Loss: 0.10089372525040392
ROC train: 0.996112	val: 0.907257	test: 0.696759
PRC train: 0.999249	val: 0.827962	test: 0.726944

Epoch: 76
Loss: 0.08791042887280018
ROC train: 0.996714	val: 0.905249	test: 0.705536
PRC train: 0.999366	val: 0.829835	test: 0.717967

Epoch: 77
Loss: 0.09729713677435337
ROC train: 0.995953	val: 0.904346	test: 0.674769
PRC train: 0.999221	val: 0.851476	test: 0.693596

Epoch: 78
Loss: 0.1145505036493356
ROC train: 0.997016	val: 0.902138	test: 0.691165
PRC train: 0.999425	val: 0.841666	test: 0.692391

Epoch: 79
Loss: 0.10009465014285499
ROC train: 0.995858	val: 0.908361	test: 0.684221
PRC train: 0.999200	val: 0.809514	test: 0.689961

Epoch: 80
Loss: 0.10332571719994059
ROC train: 0.995180	val: 0.913480	test: 0.693673
PRC train: 0.999065	val: 0.832154	test: 0.728431

Epoch: 81
Loss: 0.0999850785491079
ROC train: 0.996859	val: 0.901636	test: 0.678144
PRC train: 0.999391	val: 0.834070	test: 0.698896

Epoch: 82
Loss: 0.10799095595862403
ROC train: 0.996903	val: 0.896919	test: 0.667535
PRC train: 0.999405	val: 0.826753	test: 0.677487

Epoch: 83
Loss: 0.0994053838549336
ROC train: 0.997165	val: 0.905249	test: 0.676698
PRC train: 0.999461	val: 0.825693	test: 0.674256

Epoch: 84
Loss: 0.09859861129571222
ROC train: 0.996869	val: 0.900833	test: 0.679495
PRC train: 0.999399	val: 0.801391	test: 0.682026

Epoch: 85
Loss: 0.1096077037690203
ROC train: 0.995461	val: 0.900432	test: 0.686246
PRC train: 0.999118	val: 0.797620	test: 0.703251

Epoch: 86
Loss: 0.09299301608807843
ROC train: 0.997513	val: 0.898424	test: 0.676312
PRC train: 0.999524	val: 0.811305	test: 0.675836

Epoch: 87
Loss: 0.09269829496097008
ROC train: 0.997454	val: 0.892502	test: 0.673997
PRC train: 0.999510	val: 0.832848	test: 0.669578

Epoch: 88
Loss: 0.08412477503731461
ROC train: 0.996664	val: 0.903744	test: 0.691069
PRC train: 0.999369	val: 0.832630	test: 0.701496

Epoch: 89
Loss: 0.10512015035544084
ROC train: 0.997569	val: 0.911472	test: 0.717978
PRC train: 0.999535	val: 0.836074	test: 0.738309

Epoch: 90
Loss: 0.08461483198500475
ROC train: 0.996458	val: 0.893205	test: 0.682099
PRC train: 0.999319	val: 0.811208	test: 0.689473

Epoch: 91
Loss: 0.08304184668965132
ROC train: 0.995984	val: 0.904647	test: 0.681520
PRC train: 0.999233	val: 0.812494	test: 0.701016

Epoch: 92
Loss: 0.07932400168468061
ROC train: 0.997471	val: 0.897922	test: 0.679109
PRC train: 0.999516	val: 0.794588	test: 0.669225

Epoch: 93
Loss: 0.08244271576052797
ROC train: 0.993870	val: 0.880458	test: 0.643615
PRC train: 0.998820	val: 0.760608	test: 0.649061

Epoch: 94
Loss: 0.09549556128823114
ROC train: 0.997945	val: 0.885677	test: 0.674479
ROC train: 0.981994	val: 0.928837	test: 0.704282
PRC train: 0.996164	val: 0.889950	test: 0.722889

Epoch: 34
Loss: 0.1480077607778161
ROC train: 0.982619	val: 0.916491	test: 0.682870
PRC train: 0.996421	val: 0.861645	test: 0.689011

Epoch: 35
Loss: 0.15424076781712306
ROC train: 0.976411	val: 0.915186	test: 0.666570
PRC train: 0.994587	val: 0.838529	test: 0.671396

Epoch: 36
Loss: 0.1538266958637017
ROC train: 0.982286	val: 0.921610	test: 0.707465
PRC train: 0.995913	val: 0.876765	test: 0.739888

Epoch: 37
Loss: 0.14190174142780182
ROC train: 0.984810	val: 0.920506	test: 0.715953
PRC train: 0.996662	val: 0.875611	test: 0.745622

Epoch: 38
Loss: 0.15273532855554822
ROC train: 0.986770	val: 0.919301	test: 0.703993
PRC train: 0.997200	val: 0.881587	test: 0.720889

Epoch: 39
Loss: 0.15587627806791637
ROC train: 0.987129	val: 0.927933	test: 0.694637
PRC train: 0.997319	val: 0.887740	test: 0.703566

Epoch: 40
Loss: 0.14079927867783268
ROC train: 0.988025	val: 0.917997	test: 0.709877
PRC train: 0.997578	val: 0.867035	test: 0.726017

Epoch: 41
Loss: 0.14734035700645795
ROC train: 0.988342	val: 0.915989	test: 0.728106
PRC train: 0.997587	val: 0.863972	test: 0.747884

Epoch: 42
Loss: 0.1462834538644884
ROC train: 0.988550	val: 0.925123	test: 0.707851
PRC train: 0.997673	val: 0.873052	test: 0.722886

Epoch: 43
Loss: 0.15104962523013526
ROC train: 0.986912	val: 0.897822	test: 0.691647
PRC train: 0.997366	val: 0.839413	test: 0.687151

Epoch: 44
Loss: 0.13464963878600414
ROC train: 0.986606	val: 0.912577	test: 0.682774
PRC train: 0.997190	val: 0.865681	test: 0.692435

Epoch: 45
Loss: 0.13214057996844977
ROC train: 0.989622	val: 0.921108	test: 0.690683
PRC train: 0.997834	val: 0.883223	test: 0.704119

Epoch: 46
Loss: 0.13951213491520492
ROC train: 0.988924	val: 0.921108	test: 0.696952
PRC train: 0.997666	val: 0.872416	test: 0.719008

Epoch: 47
Loss: 0.1250759046140948
ROC train: 0.988492	val: 0.926528	test: 0.697242
PRC train: 0.997553	val: 0.879174	test: 0.711353

Epoch: 48
Loss: 0.14334154236506116
ROC train: 0.986874	val: 0.917997	test: 0.680266
PRC train: 0.997158	val: 0.865941	test: 0.678437

Epoch: 49
Loss: 0.1295225244454343
ROC train: 0.990037	val: 0.921008	test: 0.694444
PRC train: 0.997873	val: 0.866194	test: 0.724061

Epoch: 50
Loss: 0.13003043532832884
ROC train: 0.989306	val: 0.903543	test: 0.678627
PRC train: 0.997808	val: 0.833285	test: 0.702151

Epoch: 51
Loss: 0.1326629925748349
ROC train: 0.991856	val: 0.886078	test: 0.671875
PRC train: 0.998378	val: 0.814409	test: 0.691632

Epoch: 52
Loss: 0.1176453736386079
ROC train: 0.990456	val: 0.909666	test: 0.692515
PRC train: 0.998011	val: 0.837677	test: 0.719572

Epoch: 53
Loss: 0.11347685177186603
ROC train: 0.987790	val: 0.904045	test: 0.689236
PRC train: 0.997384	val: 0.824694	test: 0.709950

Epoch: 54
Loss: 0.10969570814915322
ROC train: 0.990989	val: 0.911272	test: 0.673900
PRC train: 0.998131	val: 0.855080	test: 0.686321

Epoch: 55
Loss: 0.12082896416578023
ROC train: 0.993886	val: 0.910368	test: 0.695216
PRC train: 0.998737	val: 0.864485	test: 0.708300

Epoch: 56
Loss: 0.11991737700489029
ROC train: 0.993668	val: 0.911071	test: 0.712577
PRC train: 0.998745	val: 0.859921	test: 0.721762

Epoch: 57
Loss: 0.10731624128966251
ROC train: 0.992486	val: 0.905852	test: 0.687211
PRC train: 0.998505	val: 0.851242	test: 0.695160

Epoch: 58
Loss: 0.11038198819644943
ROC train: 0.993538	val: 0.901937	test: 0.685475
PRC train: 0.998743	val: 0.840877	test: 0.704777

Epoch: 59
Loss: 0.10945028336550915
ROC train: 0.993023	val: 0.897621	test: 0.713638
PRC train: 0.998618	val: 0.828285	test: 0.731983

Epoch: 60
Loss: 0.12377832156360351
ROC train: 0.992167	val: 0.902339	test: 0.708719
PRC train: 0.998458	val: 0.831610	test: 0.713015

Epoch: 61
Loss: 0.11949866372185688
ROC train: 0.993161	val: 0.893907	test: 0.689043
PRC train: 0.998638	val: 0.827712	test: 0.696281

Epoch: 62
Loss: 0.12063701239900806
ROC train: 0.992974	val: 0.884774	test: 0.662616
PRC train: 0.998620	val: 0.809120	test: 0.678918

Epoch: 63
Loss: 0.11154818737895007
ROC train: 0.993665	val: 0.905551	test: 0.690104
PRC train: 0.998765	val: 0.844147	test: 0.697275

Epoch: 64
Loss: 0.11623429271838637
ROC train: 0.993699	val: 0.902640	test: 0.718075
PRC train: 0.998736	val: 0.836617	test: 0.734306

Epoch: 65
Loss: 0.10173607912089369
ROC train: 0.994175	val: 0.907156	test: 0.693866
PRC train: 0.998831	val: 0.837630	test: 0.713778

Epoch: 66
Loss: 0.11569005450948623
ROC train: 0.995618	val: 0.909867	test: 0.696856
PRC train: 0.999149	val: 0.840861	test: 0.705944

Epoch: 67
Loss: 0.11103487888792414
ROC train: 0.994015	val: 0.898826	test: 0.688657
PRC train: 0.998852	val: 0.832260	test: 0.701896

Epoch: 68
Loss: 0.11186850636842474
ROC train: 0.996126	val: 0.907658	test: 0.704186
PRC train: 0.999260	val: 0.830513	test: 0.714806

Epoch: 69
Loss: 0.09996362938669959
ROC train: 0.991674	val: 0.901636	test: 0.698399
PRC train: 0.998309	val: 0.804161	test: 0.709850

Epoch: 70
Loss: 0.11242289957567239
ROC train: 0.996354	val: 0.874134	test: 0.688368
PRC train: 0.999304	val: 0.771667	test: 0.689101

Epoch: 71
Loss: 0.10580384331755155
ROC train: 0.995359	val: 0.895313	test: 0.698592
PRC train: 0.999103	val: 0.821680	test: 0.703621

Epoch: 72
Loss: 0.10603079103806042
ROC train: 0.996151	val: 0.906153	test: 0.703125
PRC train: 0.999264	val: 0.843817	test: 0.723155

Epoch: 73
Loss: 0.09383738901909641
ROC train: 0.996340	val: 0.887584	test: 0.705729
PRC train: 0.999306	val: 0.808863	test: 0.714644

Epoch: 74
Loss: 0.09127224257272237
ROC train: 0.997108	val: 0.899127	test: 0.687789
PRC train: 0.999442	val: 0.839569	test: 0.689014

Epoch: 75
Loss: 0.09121212757996121
ROC train: 0.997251	val: 0.900130	test: 0.674093
PRC train: 0.999476	val: 0.830614	test: 0.674819

Epoch: 76
Loss: 0.08693581960293637
ROC train: 0.997736	val: 0.899829	test: 0.679977
PRC train: 0.999570	val: 0.807775	test: 0.670965

Epoch: 77
Loss: 0.08645667245019573
ROC train: 0.996965	val: 0.908361	test: 0.688175
PRC train: 0.999422	val: 0.816193	test: 0.691762

Epoch: 78
Loss: 0.09783144385579133
ROC train: 0.997319	val: 0.902539	test: 0.699074
PRC train: 0.999485	val: 0.812890	test: 0.710434

Epoch: 79
Loss: 0.09434768578029559
ROC train: 0.997160	val: 0.895513	test: 0.691454
PRC train: 0.999453	val: 0.799564	test: 0.696851

Epoch: 80
Loss: 0.09548015147932763
ROC train: 0.997611	val: 0.895915	test: 0.692901
PRC train: 0.999547	val: 0.821087	test: 0.695743

Epoch: 81
Loss: 0.09059579037917584
ROC train: 0.997871	val: 0.899127	test: 0.677469
PRC train: 0.999591	val: 0.829788	test: 0.672769

Epoch: 82
Loss: 0.1050757994733645
ROC train: 0.997851	val: 0.893004	test: 0.684221
PRC train: 0.999587	val: 0.818401	test: 0.687350

Epoch: 83
Loss: 0.08832778891969957
ROC train: 0.997809	val: 0.899428	test: 0.695312
PRC train: 0.999580	val: 0.855330	test: 0.701549

Epoch: 84
Loss: 0.08922514968945308
ROC train: 0.997810	val: 0.894108	test: 0.680941
PRC train: 0.999587	val: 0.828603	test: 0.672802

Epoch: 85
Loss: 0.08975383465665213
ROC train: 0.996855	val: 0.888487	test: 0.682099
PRC train: 0.999399	val: 0.796682	test: 0.694160

Epoch: 86
Loss: 0.08422428731020438
ROC train: 0.996994	val: 0.889993	test: 0.687404
PRC train: 0.999419	val: 0.805495	test: 0.688631

Epoch: 87
Loss: 0.08242707460891248
ROC train: 0.998212	val: 0.892703	test: 0.693383
PRC train: 0.999657	val: 0.816414	test: 0.681481

Epoch: 88
Loss: 0.09097892059373591
ROC train: 0.997631	val: 0.893104	test: 0.685475
PRC train: 0.999550	val: 0.833377	test: 0.693479

Epoch: 89
Loss: 0.08593933027648372
ROC train: 0.997436	val: 0.878651	test: 0.670621
PRC train: 0.999514	val: 0.790447	test: 0.671426

Epoch: 90
Loss: 0.08189119060145471
ROC train: 0.998104	val: 0.892502	test: 0.667728
PRC train: 0.999640	val: 0.812803	test: 0.661702

Epoch: 91
Loss: 0.09777467315930768
ROC train: 0.997655	val: 0.902740	test: 0.691165
PRC train: 0.999551	val: 0.851167	test: 0.698759

Epoch: 92
Loss: 0.08387495690551298
ROC train: 0.995904	val: 0.888889	test: 0.695216
PRC train: 0.999206	val: 0.795768	test: 0.710659

Epoch: 93
Loss: 0.10856852524841301
ROC train: 0.997237	val: 0.897922	test: 0.689236
PRC train: 0.999466	val: 0.789512	test: 0.702329

Epoch: 94
Loss: 0.08003596841194498
PRC train: 0.998825	val: 0.852522	test: 0.703604

Epoch: 33
Loss: 0.1279274723540614
ROC train: 0.994384	val: 0.904446	test: 0.679495
PRC train: 0.998921	val: 0.858022	test: 0.720369

Epoch: 34
Loss: 0.11235379411030903
ROC train: 0.993259	val: 0.885376	test: 0.668306
PRC train: 0.998669	val: 0.835755	test: 0.715492

Epoch: 35
Loss: 0.13411425603897256
ROC train: 0.995301	val: 0.884974	test: 0.649595
PRC train: 0.999100	val: 0.823936	test: 0.678196

Epoch: 36
Loss: 0.11704392135070364
ROC train: 0.995194	val: 0.912075	test: 0.677566
PRC train: 0.999076	val: 0.875146	test: 0.721916

Epoch: 37
Loss: 0.10859534787551568
ROC train: 0.996981	val: 0.903643	test: 0.643229
PRC train: 0.999420	val: 0.855410	test: 0.684298

Epoch: 38
Loss: 0.11219243685607931
ROC train: 0.993607	val: 0.891699	test: 0.633777
PRC train: 0.998720	val: 0.810421	test: 0.682542

Epoch: 39
Loss: 0.1060167774175993
ROC train: 0.996914	val: 0.906956	test: 0.681424
PRC train: 0.999398	val: 0.866313	test: 0.732668

Epoch: 40
Loss: 0.10589029760249878
ROC train: 0.996002	val: 0.905852	test: 0.657407
PRC train: 0.999175	val: 0.863452	test: 0.679220

Epoch: 41
Loss: 0.0984616049026927
ROC train: 0.997223	val: 0.894209	test: 0.675347
PRC train: 0.999444	val: 0.849037	test: 0.718225

Epoch: 42
Loss: 0.09721297127688398
ROC train: 0.995966	val: 0.899328	test: 0.663773
PRC train: 0.999200	val: 0.855305	test: 0.710383

Epoch: 43
Loss: 0.09663556772966807
ROC train: 0.997419	val: 0.882465	test: 0.653164
PRC train: 0.999498	val: 0.814583	test: 0.691321

Epoch: 44
Loss: 0.09811712620671811
ROC train: 0.997767	val: 0.921610	test: 0.684992
PRC train: 0.999559	val: 0.889130	test: 0.735003

Epoch: 45
Loss: 0.09426119623794661
ROC train: 0.996541	val: 0.896818	test: 0.660880
PRC train: 0.999322	val: 0.870936	test: 0.704143

Epoch: 46
Loss: 0.09286437340959097
ROC train: 0.998460	val: 0.926729	test: 0.673418
PRC train: 0.999708	val: 0.901218	test: 0.715878

Epoch: 47
Loss: 0.09718970861522482
ROC train: 0.997963	val: 0.926629	test: 0.692805
PRC train: 0.999611	val: 0.890993	test: 0.737341

Epoch: 48
Loss: 0.10244771045182603
ROC train: 0.997705	val: 0.886480	test: 0.634259
PRC train: 0.999558	val: 0.827446	test: 0.670664

Epoch: 49
Loss: 0.09328955145152214
ROC train: 0.999094	val: 0.905952	test: 0.656925
PRC train: 0.999828	val: 0.851513	test: 0.696145

Epoch: 50
Loss: 0.08524913593155571
ROC train: 0.999344	val: 0.894409	test: 0.667824
PRC train: 0.999875	val: 0.820223	test: 0.709550

Epoch: 51
Loss: 0.08058237644338284
ROC train: 0.997773	val: 0.898725	test: 0.648148
PRC train: 0.999559	val: 0.829174	test: 0.689806

Epoch: 52
Loss: 0.07516206163323846
ROC train: 0.999846	val: 0.895212	test: 0.670718
PRC train: 0.999971	val: 0.843267	test: 0.713861

Epoch: 53
Loss: 0.06668581548273575
ROC train: 0.999666	val: 0.902339	test: 0.683931
PRC train: 0.999937	val: 0.855082	test: 0.735296

Epoch: 54
Loss: 0.07936920530928988
ROC train: 0.999815	val: 0.890595	test: 0.665123
PRC train: 0.999965	val: 0.847723	test: 0.715212

Epoch: 55
Loss: 0.06715389658141402
ROC train: 0.999891	val: 0.908963	test: 0.657311
PRC train: 0.999979	val: 0.873800	test: 0.716438

Epoch: 56
Loss: 0.06894324731087238
ROC train: 0.999868	val: 0.907859	test: 0.673129
PRC train: 0.999975	val: 0.865289	test: 0.712625

Epoch: 57
Loss: 0.06992086379789429
ROC train: 0.999773	val: 0.888989	test: 0.654321
PRC train: 0.999957	val: 0.830797	test: 0.703602

Epoch: 58
Loss: 0.0784429806957061
ROC train: 0.999927	val: 0.911974	test: 0.659915
PRC train: 0.999986	val: 0.866757	test: 0.707427

Epoch: 59
Loss: 0.08193548227401751
ROC train: 0.999863	val: 0.904948	test: 0.661555
PRC train: 0.999974	val: 0.856534	test: 0.706586

Epoch: 60
Loss: 0.06341937708342613
ROC train: 0.999579	val: 0.887082	test: 0.677951
PRC train: 0.999921	val: 0.806819	test: 0.714869

Epoch: 61
Loss: 0.07408789438251508
ROC train: 0.999683	val: 0.895714	test: 0.690876
PRC train: 0.999940	val: 0.838497	test: 0.744304

Epoch: 62
Loss: 0.07971992674195312
ROC train: 1.000000	val: 0.893907	test: 0.673515
PRC train: 1.000000	val: 0.847403	test: 0.719661

Epoch: 63
Loss: 0.07219750365235608
ROC train: 0.999930	val: 0.903242	test: 0.679109
PRC train: 0.999987	val: 0.861982	test: 0.728870

Epoch: 64
Loss: 0.06415044821092965
ROC train: 0.999907	val: 0.907959	test: 0.664931
PRC train: 0.999983	val: 0.861542	test: 0.714388

Epoch: 65
Loss: 0.06024579006317525
ROC train: 0.999924	val: 0.899930	test: 0.659144
PRC train: 0.999986	val: 0.851999	test: 0.720879

Epoch: 66
Loss: 0.06881616500904597
ROC train: 0.999910	val: 0.883971	test: 0.649788
PRC train: 0.999983	val: 0.823664	test: 0.685695

Epoch: 67
Loss: 0.055049674949706175
ROC train: 0.999818	val: 0.884774	test: 0.640143
PRC train: 0.999965	val: 0.809509	test: 0.670723

Epoch: 68
Loss: 0.0556875064028297
ROC train: 0.999992	val: 0.891900	test: 0.666377
PRC train: 0.999998	val: 0.815103	test: 0.729351

Epoch: 69
Loss: 0.05959110960192781
ROC train: 0.999826	val: 0.890093	test: 0.670718
PRC train: 0.999967	val: 0.819754	test: 0.723495

Epoch: 70
Loss: 0.04445136758405351
ROC train: 0.999989	val: 0.907859	test: 0.671296
PRC train: 0.999998	val: 0.861624	test: 0.718005

Epoch: 71
Loss: 0.06342039109887432
ROC train: 0.999879	val: 0.881461	test: 0.657697
PRC train: 0.999977	val: 0.801109	test: 0.693093

Epoch: 72
Loss: 0.0701167440448727
ROC train: 0.999537	val: 0.901536	test: 0.681906
PRC train: 0.999915	val: 0.846741	test: 0.741349

Epoch: 73
Loss: 0.058715965138293906
ROC train: 0.999950	val: 0.904246	test: 0.671296
PRC train: 0.999990	val: 0.856623	test: 0.712531

Epoch: 74
Loss: 0.054173588305527064
ROC train: 0.999899	val: 0.895413	test: 0.653164
PRC train: 0.999981	val: 0.844709	test: 0.695446

Epoch: 75
Loss: 0.05220333482918962
ROC train: 0.999961	val: 0.893807	test: 0.669657
PRC train: 0.999993	val: 0.839770	test: 0.717382

Epoch: 76
Loss: 0.05073442767148988
ROC train: 0.999778	val: 0.882064	test: 0.667728
PRC train: 0.999958	val: 0.800093	test: 0.729217

Epoch: 77
Loss: 0.06857563293777813
ROC train: 0.999978	val: 0.901937	test: 0.667245
PRC train: 0.999996	val: 0.849212	test: 0.705376

Epoch: 78
Loss: 0.05814161505959759
ROC train: 0.999921	val: 0.895313	test: 0.676119
PRC train: 0.999985	val: 0.844374	test: 0.719134

Epoch: 79
Loss: 0.056882046470187256
ROC train: 0.999582	val: 0.894510	test: 0.671489
PRC train: 0.999920	val: 0.813847	test: 0.714444

Epoch: 80
Loss: 0.05237933195767343
ROC train: 0.999776	val: 0.889792	test: 0.643422
PRC train: 0.999957	val: 0.820778	test: 0.687904

Epoch: 81
Loss: 0.05684333320678812
ROC train: 1.000000	val: 0.897420	test: 0.659819
PRC train: 1.000000	val: 0.850452	test: 0.714503

Epoch: 82
Loss: 0.04765229415102976
ROC train: 0.999865	val: 0.900331	test: 0.675829
PRC train: 0.999974	val: 0.859725	test: 0.708202

Epoch: 83
Loss: 0.06212750913656889
ROC train: 0.999961	val: 0.901435	test: 0.665509
PRC train: 0.999993	val: 0.853470	test: 0.695754

Epoch: 84
Loss: 0.05578911562287609
ROC train: 0.999980	val: 0.883870	test: 0.662423
PRC train: 0.999996	val: 0.819388	test: 0.705624

Epoch: 85
Loss: 0.057979202851003206
ROC train: 0.999849	val: 0.905751	test: 0.664834
PRC train: 0.999971	val: 0.850577	test: 0.718184

Epoch: 86
Loss: 0.0388859440096605
ROC train: 0.999910	val: 0.907458	test: 0.657504
PRC train: 0.999983	val: 0.846174	test: 0.706080

Epoch: 87
Loss: 0.053618140204129194
ROC train: 0.999997	val: 0.889792	test: 0.659433
PRC train: 0.999999	val: 0.828163	test: 0.712947

Epoch: 88
Loss: 0.03998036575855564
ROC train: 1.000000	val: 0.883469	test: 0.651427
PRC train: 1.000000	val: 0.804282	test: 0.700265

Epoch: 89
Loss: 0.030527845857873936
ROC train: 1.000000	val: 0.888387	test: 0.680556
PRC train: 1.000000	val: 0.823015	test: 0.727612

Epoch: 90
Loss: 0.041319602889325506
ROC train: 0.999992	val: 0.890595	test: 0.678241
PRC train: 0.999998	val: 0.840966	test: 0.726835

Epoch: 91
Loss: 0.032809026636838066
ROC train: 0.999770	val: 0.891298	test: 0.676890
PRC train: 0.999956	val: 0.848805	test: 0.713235

Epoch: 92
Loss: 0.03824350096454539
ROC train: 1.000000	val: 0.897420	test: 0.679398
PRC train: 1.000000	val: 0.850086	test: 0.720888

Epoch: 93
Loss: 0.03805501096706241
ROC train: 0.999820	val: 0.889993	test: 0.643133
PRC train: 0.998703	val: 0.871565	test: 0.701257

Epoch: 33
Loss: 0.13382921556401345
ROC train: 0.992498	val: 0.919000	test: 0.661651
PRC train: 0.998495	val: 0.849282	test: 0.689927

Epoch: 34
Loss: 0.13946036276563645
ROC train: 0.992678	val: 0.923617	test: 0.661748
PRC train: 0.998577	val: 0.855540	test: 0.687131

Epoch: 35
Loss: 0.12412239854148323
ROC train: 0.988919	val: 0.891197	test: 0.656636
PRC train: 0.997775	val: 0.811571	test: 0.698967

Epoch: 36
Loss: 0.13173446181800313
ROC train: 0.994473	val: 0.908261	test: 0.659819
PRC train: 0.998921	val: 0.826496	test: 0.696448

Epoch: 37
Loss: 0.12193701142164226
ROC train: 0.996465	val: 0.914082	test: 0.660012
PRC train: 0.999317	val: 0.818860	test: 0.675365

Epoch: 38
Loss: 0.11930414672441894
ROC train: 0.994291	val: 0.906554	test: 0.668210
PRC train: 0.998902	val: 0.827103	test: 0.709348

Epoch: 39
Loss: 0.12573904907935782
ROC train: 0.996471	val: 0.886380	test: 0.652488
PRC train: 0.999317	val: 0.779348	test: 0.688378

Epoch: 40
Loss: 0.09437727755739653
ROC train: 0.996634	val: 0.878852	test: 0.637442
PRC train: 0.999338	val: 0.757212	test: 0.665520

Epoch: 41
Loss: 0.10088422017232727
ROC train: 0.996331	val: 0.901937	test: 0.656636
PRC train: 0.999268	val: 0.822371	test: 0.681630

Epoch: 42
Loss: 0.12296483435341059
ROC train: 0.996897	val: 0.899428	test: 0.655864
PRC train: 0.999376	val: 0.826332	test: 0.677448

Epoch: 43
Loss: 0.10397573424118038
ROC train: 0.997896	val: 0.900130	test: 0.652874
PRC train: 0.999592	val: 0.802015	test: 0.672023

Epoch: 44
Loss: 0.09939370198852386
ROC train: 0.997680	val: 0.893606	test: 0.652585
PRC train: 0.999542	val: 0.793656	test: 0.663181

Epoch: 45
Loss: 0.0958117564507471
ROC train: 0.998334	val: 0.899227	test: 0.659433
PRC train: 0.999670	val: 0.798245	test: 0.674391

Epoch: 46
Loss: 0.11202941349560987
ROC train: 0.996799	val: 0.913881	test: 0.652006
PRC train: 0.999363	val: 0.834580	test: 0.660667

Epoch: 47
Loss: 0.10524438937929094
ROC train: 0.998132	val: 0.894008	test: 0.656154
PRC train: 0.999643	val: 0.789854	test: 0.675395

Epoch: 48
Loss: 0.0897904258340145
ROC train: 0.998314	val: 0.890696	test: 0.644869
PRC train: 0.999670	val: 0.809033	test: 0.689061

Epoch: 49
Loss: 0.08832853921746156
ROC train: 0.996513	val: 0.896417	test: 0.640721
PRC train: 0.999323	val: 0.804941	test: 0.649151

Epoch: 50
Loss: 0.09233590359082676
ROC train: 0.998945	val: 0.913982	test: 0.657022
PRC train: 0.999793	val: 0.832836	test: 0.671146

Epoch: 51
Loss: 0.099094321105505
ROC train: 0.997531	val: 0.890294	test: 0.640239
PRC train: 0.999518	val: 0.810617	test: 0.664016

Epoch: 52
Loss: 0.08113466145514885
ROC train: 0.998822	val: 0.895012	test: 0.641879
PRC train: 0.999769	val: 0.823654	test: 0.673308

Epoch: 53
Loss: 0.0918665964813304
ROC train: 0.998811	val: 0.921409	test: 0.648438
PRC train: 0.999763	val: 0.845198	test: 0.672034

Epoch: 54
Loss: 0.09431049390612418
ROC train: 0.999447	val: 0.903945	test: 0.641011
PRC train: 0.999894	val: 0.812547	test: 0.661303

Epoch: 55
Loss: 0.08075806483744714
ROC train: 0.999094	val: 0.922313	test: 0.638985
PRC train: 0.999827	val: 0.843193	test: 0.637198

Epoch: 56
Loss: 0.08013235847480356
ROC train: 0.999203	val: 0.900130	test: 0.637635
PRC train: 0.999847	val: 0.814354	test: 0.653867

Epoch: 57
Loss: 0.06973150627494999
ROC train: 0.999128	val: 0.898424	test: 0.634934
PRC train: 0.999830	val: 0.820407	test: 0.666376

Epoch: 58
Loss: 0.07398726437847888
ROC train: 0.998724	val: 0.906253	test: 0.648052
PRC train: 0.999753	val: 0.801632	test: 0.678894

Epoch: 59
Loss: 0.07834518779138033
ROC train: 0.999332	val: 0.883670	test: 0.650174
PRC train: 0.999873	val: 0.770844	test: 0.690951

Epoch: 60
Loss: 0.06883092271482348
ROC train: 0.999372	val: 0.911171	test: 0.654032
PRC train: 0.999879	val: 0.833371	test: 0.670062

Epoch: 61
Loss: 0.08189941575717631
ROC train: 0.999717	val: 0.912075	test: 0.648052
PRC train: 0.999946	val: 0.835465	test: 0.678436

Epoch: 62
Loss: 0.07141291424216335
ROC train: 0.998903	val: 0.905551	test: 0.625868
PRC train: 0.999790	val: 0.806992	test: 0.662840

Epoch: 63
Loss: 0.07342347407706738
ROC train: 0.999473	val: 0.885476	test: 0.624518
PRC train: 0.999896	val: 0.776743	test: 0.650542

Epoch: 64
Loss: 0.0639109418335304
ROC train: 0.998855	val: 0.918900	test: 0.644001
PRC train: 0.999772	val: 0.848073	test: 0.663614

Epoch: 65
Loss: 0.08359470008684887
ROC train: 0.999358	val: 0.883469	test: 0.642168
PRC train: 0.999877	val: 0.770894	test: 0.656599

Epoch: 66
Loss: 0.0712257397957967
ROC train: 0.999590	val: 0.886681	test: 0.631559
PRC train: 0.999921	val: 0.791529	test: 0.656371

Epoch: 67
Loss: 0.07431362872547612
ROC train: 0.999529	val: 0.876844	test: 0.652874
PRC train: 0.999909	val: 0.813660	test: 0.686544

Epoch: 68
Loss: 0.08240982974185561
ROC train: 0.998171	val: 0.883569	test: 0.639564
PRC train: 0.999648	val: 0.794234	test: 0.651717

Epoch: 69
Loss: 0.06221736513828592
ROC train: 0.999851	val: 0.894209	test: 0.643229
PRC train: 0.999972	val: 0.794698	test: 0.679994

Epoch: 70
Loss: 0.06324106564411833
ROC train: 0.999910	val: 0.913982	test: 0.617284
PRC train: 0.999983	val: 0.824096	test: 0.647990

Epoch: 71
Loss: 0.06700142483408156
ROC train: 0.999804	val: 0.915387	test: 0.644869
PRC train: 0.999962	val: 0.833939	test: 0.686780

Epoch: 72
Loss: 0.06313554420591545
ROC train: 0.999896	val: 0.898324	test: 0.660783
PRC train: 0.999980	val: 0.788544	test: 0.707064

Epoch: 73
Loss: 0.05405815395893256
ROC train: 0.999851	val: 0.924420	test: 0.658275
PRC train: 0.999972	val: 0.854527	test: 0.696119

Epoch: 74
Loss: 0.06217843056159979
ROC train: 0.999941	val: 0.908261	test: 0.647473
PRC train: 0.999989	val: 0.833081	test: 0.696418

Epoch: 75
Loss: 0.05985883332555016
ROC train: 0.999924	val: 0.894209	test: 0.624711
PRC train: 0.999986	val: 0.781693	test: 0.651967

Epoch: 76
Loss: 0.052558209573256076
ROC train: 0.999846	val: 0.912476	test: 0.632234
PRC train: 0.999971	val: 0.832651	test: 0.635673

Epoch: 77
Loss: 0.048115124745121196
ROC train: 0.999857	val: 0.914985	test: 0.651138
PRC train: 0.999973	val: 0.854110	test: 0.670449

Epoch: 78
Loss: 0.06190731744982042
ROC train: 0.999784	val: 0.881662	test: 0.651620
PRC train: 0.999959	val: 0.805411	test: 0.683769

Epoch: 79
Loss: 0.05353428898935071
ROC train: 0.999930	val: 0.870521	test: 0.644772
PRC train: 0.999987	val: 0.759183	test: 0.699841

Epoch: 80
Loss: 0.049290977463388105
ROC train: 0.999950	val: 0.882666	test: 0.642554
PRC train: 0.999990	val: 0.780153	test: 0.684809

Epoch: 81
Loss: 0.04459958572070178
ROC train: 0.999907	val: 0.911673	test: 0.638600
PRC train: 0.999983	val: 0.833974	test: 0.672310

Epoch: 82
Loss: 0.05726498199579364
ROC train: 0.999950	val: 0.901435	test: 0.642361
PRC train: 0.999990	val: 0.800101	test: 0.649025

Epoch: 83
Loss: 0.04764869751236922
ROC train: 0.999955	val: 0.919502	test: 0.650270
PRC train: 0.999991	val: 0.853385	test: 0.663825

Epoch: 84
Loss: 0.05948421599854011
ROC train: 0.999978	val: 0.912175	test: 0.646026
PRC train: 0.999996	val: 0.844164	test: 0.652805

Epoch: 85
Loss: 0.05391080973195835
ROC train: 0.999952	val: 0.898424	test: 0.634549
PRC train: 0.999991	val: 0.805204	test: 0.643345

Epoch: 86
Loss: 0.06481927042000894
ROC train: 0.999832	val: 0.885376	test: 0.625096
PRC train: 0.999968	val: 0.805187	test: 0.654214

Epoch: 87
Loss: 0.053980791994816535
ROC train: 0.999905	val: 0.898223	test: 0.642458
PRC train: 0.999982	val: 0.848009	test: 0.683068

Epoch: 88
Loss: 0.04832586890936148
ROC train: 0.999952	val: 0.909766	test: 0.647377
PRC train: 0.999991	val: 0.838108	test: 0.682516

Epoch: 89
Loss: 0.04814619966455585
ROC train: 0.999980	val: 0.873030	test: 0.638696
PRC train: 0.999996	val: 0.763743	test: 0.680675

Epoch: 90
Loss: 0.047823826835987474
ROC train: 0.999994	val: 0.878450	test: 0.641011
PRC train: 0.999999	val: 0.772886	test: 0.685534

Epoch: 91
Loss: 0.040524351134466605
ROC train: 0.999992	val: 0.896116	test: 0.630691
PRC train: 0.999998	val: 0.826635	test: 0.667713

Epoch: 92
Loss: 0.03873883539552831
ROC train: 0.999992	val: 0.888688	test: 0.635706
PRC train: 0.999998	val: 0.789093	test: 0.662112

Epoch: 93
Loss: 0.039240445949650184
ROC train: 0.999992	val: 0.888889	test: 0.649209
PRC train: 0.998169	val: 0.850727	test: 0.715332

Epoch: 33
Loss: 0.1309554886895607
ROC train: 0.992953	val: 0.898826	test: 0.647859
PRC train: 0.998613	val: 0.796340	test: 0.647968

Epoch: 34
Loss: 0.14819788342130466
ROC train: 0.994981	val: 0.914684	test: 0.681038
PRC train: 0.999010	val: 0.865165	test: 0.713524

Epoch: 35
Loss: 0.13380836847076755
ROC train: 0.995618	val: 0.912476	test: 0.690297
PRC train: 0.999143	val: 0.861646	test: 0.725264

Epoch: 36
Loss: 0.12420250339583469
ROC train: 0.992613	val: 0.915387	test: 0.673900
PRC train: 0.998453	val: 0.872363	test: 0.693625

Epoch: 37
Loss: 0.12454418672038317
ROC train: 0.995896	val: 0.899729	test: 0.665702
PRC train: 0.999205	val: 0.843788	test: 0.678672

Epoch: 38
Loss: 0.11024874975355936
ROC train: 0.991834	val: 0.909766	test: 0.671971
PRC train: 0.998309	val: 0.870310	test: 0.697651

Epoch: 39
Loss: 0.11407648498486696
ROC train: 0.996030	val: 0.897019	test: 0.657697
PRC train: 0.999203	val: 0.846162	test: 0.667322

Epoch: 40
Loss: 0.1128515662454623
ROC train: 0.996162	val: 0.897722	test: 0.659336
PRC train: 0.999240	val: 0.827481	test: 0.663815

Epoch: 41
Loss: 0.10232321287248171
ROC train: 0.994659	val: 0.893707	test: 0.658275
PRC train: 0.998951	val: 0.813477	test: 0.683059

Epoch: 42
Loss: 0.10110481039420251
ROC train: 0.997655	val: 0.893205	test: 0.665606
PRC train: 0.999535	val: 0.815158	test: 0.681525

Epoch: 43
Loss: 0.10881978115878375
ROC train: 0.998160	val: 0.912275	test: 0.653356
PRC train: 0.999636	val: 0.863748	test: 0.670815

Epoch: 44
Loss: 0.09898599088757314
ROC train: 0.995335	val: 0.921008	test: 0.651331
PRC train: 0.998915	val: 0.867352	test: 0.624557

Epoch: 45
Loss: 0.10011245627297452
ROC train: 0.995060	val: 0.914182	test: 0.642072
PRC train: 0.998999	val: 0.858554	test: 0.625883

Epoch: 46
Loss: 0.09760417338567204
ROC train: 0.997708	val: 0.870019	test: 0.657986
PRC train: 0.999558	val: 0.796949	test: 0.676119

Epoch: 47
Loss: 0.0984330340253327
ROC train: 0.998833	val: 0.893104	test: 0.650559
PRC train: 0.999776	val: 0.810079	test: 0.655742

Epoch: 48
Loss: 0.08955712765542263
ROC train: 0.998886	val: 0.885978	test: 0.646701
PRC train: 0.999785	val: 0.829222	test: 0.654679

Epoch: 49
Loss: 0.09658828932730891
ROC train: 0.998600	val: 0.901134	test: 0.659626
PRC train: 0.999733	val: 0.853280	test: 0.665188

Epoch: 50
Loss: 0.08773742476429344
ROC train: 0.999195	val: 0.889591	test: 0.644676
PRC train: 0.999845	val: 0.804445	test: 0.626736

Epoch: 51
Loss: 0.08493179681420361
ROC train: 0.999596	val: 0.896216	test: 0.661555
PRC train: 0.999924	val: 0.831846	test: 0.667129

Epoch: 52
Loss: 0.07980962824742524
ROC train: 0.998390	val: 0.896517	test: 0.671875
PRC train: 0.999702	val: 0.837609	test: 0.694657

Epoch: 53
Loss: 0.08783947579254678
ROC train: 0.999509	val: 0.883569	test: 0.674190
PRC train: 0.999908	val: 0.809424	test: 0.695698

Epoch: 54
Loss: 0.07374350303816879
ROC train: 0.999206	val: 0.892201	test: 0.693866
PRC train: 0.999851	val: 0.836934	test: 0.730261

Epoch: 55
Loss: 0.07585355640355708
ROC train: 0.999128	val: 0.901435	test: 0.682870
PRC train: 0.999830	val: 0.855316	test: 0.692087

Epoch: 56
Loss: 0.09222655835917833
ROC train: 0.999540	val: 0.891398	test: 0.658179
PRC train: 0.999911	val: 0.835924	test: 0.675693

Epoch: 57
Loss: 0.07421263667666178
ROC train: 0.999251	val: 0.897119	test: 0.677276
PRC train: 0.999855	val: 0.830073	test: 0.681919

Epoch: 58
Loss: 0.06913480604132265
ROC train: 0.999661	val: 0.884372	test: 0.681327
PRC train: 0.999936	val: 0.827941	test: 0.696976

Epoch: 59
Loss: 0.08516576196551225
ROC train: 0.999015	val: 0.894710	test: 0.671296
PRC train: 0.999807	val: 0.831959	test: 0.690901

Epoch: 60
Loss: 0.0898950692434809
ROC train: 0.999128	val: 0.903543	test: 0.669850
PRC train: 0.999834	val: 0.830326	test: 0.691930

Epoch: 61
Loss: 0.07284961258929022
ROC train: 0.999231	val: 0.885878	test: 0.671393
PRC train: 0.999853	val: 0.789496	test: 0.675884

Epoch: 62
Loss: 0.07451553794854224
ROC train: 0.999820	val: 0.903443	test: 0.652778
PRC train: 0.999966	val: 0.840173	test: 0.652495

Epoch: 63
Loss: 0.08096075061514073
ROC train: 0.998740	val: 0.900733	test: 0.639757
PRC train: 0.999757	val: 0.822987	test: 0.624275

Epoch: 64
Loss: 0.07037178332572189
ROC train: 0.999456	val: 0.906454	test: 0.644869
PRC train: 0.999897	val: 0.840606	test: 0.635365

Epoch: 65
Loss: 0.07554941722527606
ROC train: 0.999394	val: 0.906755	test: 0.629437
PRC train: 0.999885	val: 0.837015	test: 0.631262

Epoch: 66
Loss: 0.06714328790244252
ROC train: 0.999290	val: 0.886380	test: 0.640143
PRC train: 0.999865	val: 0.792073	test: 0.633766

Epoch: 67
Loss: 0.05750763979762471
ROC train: 0.999790	val: 0.911071	test: 0.675540
PRC train: 0.999960	val: 0.859176	test: 0.694793

Epoch: 68
Loss: 0.060145624069590835
ROC train: 0.999576	val: 0.915788	test: 0.676890
PRC train: 0.999918	val: 0.871820	test: 0.678789

Epoch: 69
Loss: 0.06709122689851006
ROC train: 0.999599	val: 0.893807	test: 0.656154
PRC train: 0.999923	val: 0.821431	test: 0.650096

Epoch: 70
Loss: 0.05502202751277774
ROC train: 0.999007	val: 0.888889	test: 0.645833
PRC train: 0.999811	val: 0.788574	test: 0.647657

Epoch: 71
Loss: 0.055446881303592536
ROC train: 0.999961	val: 0.899328	test: 0.667342
PRC train: 0.999993	val: 0.829877	test: 0.659666

Epoch: 72
Loss: 0.05184236535049539
ROC train: 0.999686	val: 0.897420	test: 0.663677
PRC train: 0.999941	val: 0.837833	test: 0.666522

Epoch: 73
Loss: 0.05418158136092658
ROC train: 0.999809	val: 0.904246	test: 0.691262
PRC train: 0.999964	val: 0.860937	test: 0.707412

Epoch: 74
Loss: 0.049945586737676094
ROC train: 0.999955	val: 0.910368	test: 0.677855
PRC train: 0.999991	val: 0.868402	test: 0.670781

Epoch: 75
Loss: 0.04973944586651245
ROC train: 0.999978	val: 0.903543	test: 0.656346
PRC train: 0.999996	val: 0.840592	test: 0.641186

Epoch: 76
Loss: 0.05088008563052272
ROC train: 0.999944	val: 0.890796	test: 0.667342
PRC train: 0.999989	val: 0.816340	test: 0.659094

Epoch: 77
Loss: 0.04222804864864886
ROC train: 0.999966	val: 0.881662	test: 0.673515
PRC train: 0.999994	val: 0.811730	test: 0.670021

Epoch: 78
Loss: 0.04506906018608346
ROC train: 0.999969	val: 0.880357	test: 0.681424
PRC train: 0.999994	val: 0.807295	test: 0.680787

Epoch: 79
Loss: 0.05669830109951345
ROC train: 0.999910	val: 0.886279	test: 0.644001
PRC train: 0.999983	val: 0.817108	test: 0.619536

Epoch: 80
Loss: 0.05459642733354553
ROC train: 0.999557	val: 0.907257	test: 0.651524
PRC train: 0.999913	val: 0.847254	test: 0.632344

Epoch: 81
Loss: 0.04561196115943517
ROC train: 0.999924	val: 0.910669	test: 0.649884
PRC train: 0.999986	val: 0.859109	test: 0.657470

Epoch: 82
Loss: 0.033946449873629374
ROC train: 0.999944	val: 0.896919	test: 0.662230
PRC train: 0.999989	val: 0.831910	test: 0.678876

Epoch: 83
Loss: 0.04426232549594209
ROC train: 0.999767	val: 0.886681	test: 0.649981
PRC train: 0.999956	val: 0.811073	test: 0.670462

Epoch: 84
Loss: 0.04458112113743899
ROC train: 0.999874	val: 0.905350	test: 0.655671
PRC train: 0.999976	val: 0.854427	test: 0.664862

Epoch: 85
Loss: 0.04769588942446651
ROC train: 1.000000	val: 0.877748	test: 0.666281
PRC train: 1.000000	val: 0.815569	test: 0.668682

Epoch: 86
Loss: 0.039649096547338766
ROC train: 0.999994	val: 0.882264	test: 0.679302
PRC train: 0.999999	val: 0.816463	test: 0.663615

Epoch: 87
Loss: 0.04587510230151583
ROC train: 0.999672	val: 0.901837	test: 0.667631
PRC train: 0.999936	val: 0.844796	test: 0.652888

Epoch: 88
Loss: 0.03408765619325988
ROC train: 0.999964	val: 0.890796	test: 0.635224
PRC train: 0.999993	val: 0.832281	test: 0.637455

Epoch: 89
Loss: 0.0443672640654754
ROC train: 0.999997	val: 0.888186	test: 0.662905
PRC train: 0.999999	val: 0.814950	test: 0.659010

Epoch: 90
Loss: 0.03893338954269523
ROC train: 0.999992	val: 0.903543	test: 0.645544
PRC train: 0.999998	val: 0.830057	test: 0.634487

Epoch: 91
Loss: 0.04015514791957158
ROC train: 1.000000	val: 0.892302	test: 0.657600
PRC train: 1.000000	val: 0.809492	test: 0.653676

Epoch: 92
Loss: 0.03584300431802407
ROC train: 1.000000	val: 0.898625	test: 0.666377
PRC train: 1.000000	val: 0.823826	test: 0.663700

Epoch: 93
Loss: 0.03933044980023144
ROC train: 0.999986	val: 0.893305	test: 0.662133
PRC train: 0.999428	val: 0.763777	test: 0.643729

Epoch: 33
Loss: 0.12014670789692601
ROC train: 0.997747	val: 0.872629	test: 0.636960
PRC train: 0.999514	val: 0.793835	test: 0.662040

Epoch: 34
Loss: 0.11640732067026138
ROC train: 0.997649	val: 0.874636	test: 0.635802
PRC train: 0.999474	val: 0.789102	test: 0.653285

Epoch: 35
Loss: 0.11965160189953457
ROC train: 0.998855	val: 0.889792	test: 0.650270
PRC train: 0.999759	val: 0.815366	test: 0.667580

Epoch: 36
Loss: 0.11437992292235391
ROC train: 0.998081	val: 0.907257	test: 0.668596
PRC train: 0.999593	val: 0.848864	test: 0.711537

Epoch: 37
Loss: 0.11512265415611625
ROC train: 0.991264	val: 0.865402	test: 0.645640
PRC train: 0.998241	val: 0.754356	test: 0.671644

Epoch: 38
Loss: 0.09608113350700595
ROC train: 0.997568	val: 0.884272	test: 0.647473
PRC train: 0.999494	val: 0.804180	test: 0.671610

Epoch: 39
Loss: 0.09968584083936127
ROC train: 0.998965	val: 0.875238	test: 0.654514
PRC train: 0.999788	val: 0.783127	test: 0.658074

Epoch: 40
Loss: 0.1051072250488745
ROC train: 0.999066	val: 0.839004	test: 0.630208
PRC train: 0.999818	val: 0.752589	test: 0.647452

Epoch: 41
Loss: 0.09283405301863579
ROC train: 0.999506	val: 0.888688	test: 0.642554
PRC train: 0.999904	val: 0.793729	test: 0.642294

Epoch: 42
Loss: 0.08741842601493291
ROC train: 0.999700	val: 0.902740	test: 0.625386
PRC train: 0.999943	val: 0.847607	test: 0.642969

Epoch: 43
Loss: 0.08210655886805965
ROC train: 0.999843	val: 0.877045	test: 0.607157
PRC train: 0.999970	val: 0.797930	test: 0.614815

Epoch: 44
Loss: 0.07103089840160402
ROC train: 0.999790	val: 0.879454	test: 0.642940
PRC train: 0.999960	val: 0.781330	test: 0.636559

Epoch: 45
Loss: 0.06633706612955088
ROC train: 0.999893	val: 0.888688	test: 0.646412
PRC train: 0.999980	val: 0.792230	test: 0.647625

Epoch: 46
Loss: 0.08039688406621814
ROC train: 0.999961	val: 0.875841	test: 0.640432
PRC train: 0.999993	val: 0.786630	test: 0.648739

Epoch: 47
Loss: 0.07025544135755599
ROC train: 0.999860	val: 0.875539	test: 0.632041
PRC train: 0.999973	val: 0.795417	test: 0.663136

Epoch: 48
Loss: 0.08100264095038555
ROC train: 0.998014	val: 0.898324	test: 0.627218
PRC train: 0.999622	val: 0.794196	test: 0.632751

Epoch: 49
Loss: 0.0878471380692484
ROC train: 0.999994	val: 0.886380	test: 0.651620
PRC train: 0.999999	val: 0.785457	test: 0.663866

Epoch: 50
Loss: 0.07524765993989231
ROC train: 0.999652	val: 0.880257	test: 0.635127
PRC train: 0.999934	val: 0.772779	test: 0.634668

Epoch: 51
Loss: 0.06531328937916032
ROC train: 0.999983	val: 0.889692	test: 0.645930
PRC train: 0.999997	val: 0.822193	test: 0.685242

Epoch: 52
Loss: 0.06319104330684668
ROC train: 1.000000	val: 0.868212	test: 0.648052
PRC train: 1.000000	val: 0.774980	test: 0.668775

Epoch: 53
Loss: 0.05981112435101555
ROC train: 0.999961	val: 0.872930	test: 0.654996
PRC train: 0.999993	val: 0.771030	test: 0.661379

Epoch: 54
Loss: 0.059996169529183185
ROC train: 0.999983	val: 0.858978	test: 0.640143
PRC train: 0.999997	val: 0.733636	test: 0.635900

Epoch: 55
Loss: 0.05120557663336713
ROC train: 0.999997	val: 0.850146	test: 0.619792
PRC train: 0.999999	val: 0.747796	test: 0.644290

Epoch: 56
Loss: 0.05333007488442224
ROC train: 1.000000	val: 0.865302	test: 0.624035
PRC train: 1.000000	val: 0.757614	test: 0.646966

Epoch: 57
Loss: 0.04755779683387516
ROC train: 0.999994	val: 0.868112	test: 0.626833
PRC train: 0.999999	val: 0.742289	test: 0.626872

Epoch: 58
Loss: 0.05529562592986449
ROC train: 1.000000	val: 0.878149	test: 0.632234
PRC train: 1.000000	val: 0.787935	test: 0.654945

Epoch: 59
Loss: 0.04920615135696487
ROC train: 0.999989	val: 0.891699	test: 0.647666
PRC train: 0.999998	val: 0.829055	test: 0.678222

Epoch: 60
Loss: 0.04647743711821922
ROC train: 0.999809	val: 0.879956	test: 0.630401
PRC train: 0.999964	val: 0.809628	test: 0.644835

Epoch: 61
Loss: 0.06333244448599722
ROC train: 1.000000	val: 0.869417	test: 0.626640
PRC train: 1.000000	val: 0.796161	test: 0.652746

Epoch: 62
Loss: 0.04345300712850797
ROC train: 0.999997	val: 0.883268	test: 0.649884
PRC train: 0.999999	val: 0.766059	test: 0.657478

Epoch: 63
Loss: 0.050138543529944346
ROC train: 1.000000	val: 0.879153	test: 0.645640
PRC train: 1.000000	val: 0.774530	test: 0.648626

Epoch: 64
Loss: 0.04885949236234396
ROC train: 1.000000	val: 0.874335	test: 0.615258
PRC train: 1.000000	val: 0.780078	test: 0.616379

Epoch: 65
Loss: 0.05053015211865793
ROC train: 0.999997	val: 0.851952	test: 0.597608
PRC train: 0.999999	val: 0.767692	test: 0.614872

Epoch: 66
Loss: 0.03830816398937651
ROC train: 0.999947	val: 0.891197	test: 0.629147
PRC train: 0.999990	val: 0.806133	test: 0.636591

Epoch: 67
Loss: 0.04069781494838754
ROC train: 1.000000	val: 0.908060	test: 0.628472
PRC train: 1.000000	val: 0.838460	test: 0.655173

Epoch: 68
Loss: 0.03663176581804112
ROC train: 0.999955	val: 0.865803	test: 0.619309
PRC train: 0.999991	val: 0.762584	test: 0.640201

Epoch: 69
Loss: 0.04172620418493334
ROC train: 1.000000	val: 0.839305	test: 0.607446
PRC train: 1.000000	val: 0.713079	test: 0.622791

Epoch: 70
Loss: 0.04869278476835159
ROC train: 0.999978	val: 0.840309	test: 0.611208
PRC train: 0.999996	val: 0.687838	test: 0.607696

Epoch: 71
Loss: 0.04281663577075368
ROC train: 1.000000	val: 0.877346	test: 0.596258
PRC train: 1.000000	val: 0.750638	test: 0.602606

Epoch: 72
Loss: 0.035575916781993136
ROC train: 1.000000	val: 0.881461	test: 0.593557
PRC train: 1.000000	val: 0.766386	test: 0.599752

Epoch: 73
Loss: 0.03629688288418248
ROC train: 1.000000	val: 0.860484	test: 0.594039
PRC train: 1.000000	val: 0.728107	test: 0.595185

Epoch: 74
Loss: 0.03812015102714077
ROC train: 1.000000	val: 0.860082	test: 0.616705
PRC train: 1.000000	val: 0.753032	test: 0.633522

Epoch: 75
Loss: 0.02949099362440057
ROC train: 1.000000	val: 0.863294	test: 0.615837
PRC train: 1.000000	val: 0.761842	test: 0.626927

Epoch: 76
Loss: 0.047666829848586355
ROC train: 1.000000	val: 0.825253	test: 0.605131
PRC train: 1.000000	val: 0.692134	test: 0.598610

Epoch: 77
Loss: 0.0336789110261095
ROC train: 1.000000	val: 0.840008	test: 0.608121
PRC train: 1.000000	val: 0.711184	test: 0.601201

Epoch: 78
Loss: 0.03240681672669662
ROC train: 1.000000	val: 0.842919	test: 0.600887
PRC train: 1.000000	val: 0.730175	test: 0.609305

Epoch: 79
Loss: 0.038475794906113935
ROC train: 1.000000	val: 0.854261	test: 0.584298
PRC train: 1.000000	val: 0.744972	test: 0.606189

Epoch: 80
Loss: 0.03616400146978586
ROC train: 1.000000	val: 0.856469	test: 0.589313
PRC train: 1.000000	val: 0.761902	test: 0.609953

Epoch: 81
Loss: 0.03979584327938349
ROC train: 1.000000	val: 0.860986	test: 0.609182
PRC train: 1.000000	val: 0.769933	test: 0.625504

Epoch: 82
Loss: 0.033828013477886935
ROC train: 0.999997	val: 0.864599	test: 0.622106
PRC train: 0.999999	val: 0.778358	test: 0.637062

Epoch: 83
Loss: 0.03764051348630935
ROC train: 0.999994	val: 0.869316	test: 0.612751
PRC train: 0.999999	val: 0.783481	test: 0.651449

Epoch: 84
Loss: 0.03582708293769103
ROC train: 0.999997	val: 0.856268	test: 0.605131
PRC train: 0.999999	val: 0.761039	test: 0.619234

Epoch: 85
Loss: 0.03113263090230158
ROC train: 1.000000	val: 0.859279	test: 0.614390
PRC train: 1.000000	val: 0.761866	test: 0.633910

Epoch: 86
Loss: 0.03299594043767221
ROC train: 1.000000	val: 0.879253	test: 0.643133
PRC train: 1.000000	val: 0.788835	test: 0.692592

Epoch: 87
Loss: 0.028715267726283335
ROC train: 0.999515	val: 0.880458	test: 0.659915
PRC train: 0.999902	val: 0.785337	test: 0.701319

Epoch: 88
Loss: 0.0372271327750396
ROC train: 0.999997	val: 0.886781	test: 0.663002
PRC train: 0.999999	val: 0.803898	test: 0.709042

Epoch: 89
Loss: 0.031114760539482443
ROC train: 1.000000	val: 0.883168	test: 0.639082
PRC train: 1.000000	val: 0.793775	test: 0.677634

Epoch: 90
Loss: 0.039951674602907036
ROC train: 1.000000	val: 0.861989	test: 0.626640
PRC train: 1.000000	val: 0.747996	test: 0.645218

Epoch: 91
Loss: 0.028168381176499953
ROC train: 0.999896	val: 0.871123	test: 0.632716
PRC train: 0.999980	val: 0.809999	test: 0.680809

Epoch: 92
Loss: 0.04614165688320211
ROC train: 1.000000	val: 0.878651	test: 0.629919
PRC train: 1.000000	val: 0.788800	test: 0.648185

Epoch: 93
Loss: 0.025378195390702008
PRC train: 0.999635	val: 0.773838	test: 0.633805

Epoch: 33
Loss: 0.11428763350935205
ROC train: 0.998311	val: 0.855867	test: 0.638310
PRC train: 0.999669	val: 0.763905	test: 0.682904

Epoch: 34
Loss: 0.12247448464881579
ROC train: 0.999411	val: 0.835792	test: 0.617766
PRC train: 0.999887	val: 0.738468	test: 0.638904

Epoch: 35
Loss: 0.10882770067006077
ROC train: 0.997643	val: 0.859079	test: 0.622782
PRC train: 0.999547	val: 0.794238	test: 0.650540

Epoch: 36
Loss: 0.11722913996097936
ROC train: 0.999254	val: 0.800161	test: 0.635031
PRC train: 0.999860	val: 0.698129	test: 0.643977

Epoch: 37
Loss: 0.11749465834577091
ROC train: 0.999647	val: 0.844123	test: 0.640336
PRC train: 0.999933	val: 0.759629	test: 0.657737

Epoch: 38
Loss: 0.09601985681296231
ROC train: 0.999456	val: 0.834287	test: 0.618538
PRC train: 0.999895	val: 0.765321	test: 0.626326

Epoch: 39
Loss: 0.10498611046873112
ROC train: 0.999593	val: 0.788919	test: 0.600791
PRC train: 0.999924	val: 0.688110	test: 0.595887

Epoch: 40
Loss: 0.08378041736755282
ROC train: 0.999832	val: 0.808190	test: 0.597994
PRC train: 0.999968	val: 0.713453	test: 0.613178

Epoch: 41
Loss: 0.08142615760419002
ROC train: 0.999590	val: 0.801867	test: 0.622878
PRC train: 0.999922	val: 0.698905	test: 0.634876

Epoch: 42
Loss: 0.09378752361356625
ROC train: 0.999863	val: 0.852354	test: 0.623843
PRC train: 0.999974	val: 0.770205	test: 0.644617

Epoch: 43
Loss: 0.08487347298335828
ROC train: 0.998721	val: 0.845227	test: 0.615548
PRC train: 0.999745	val: 0.753777	test: 0.636028

Epoch: 44
Loss: 0.0921129535702162
ROC train: 0.999467	val: 0.837097	test: 0.594907
PRC train: 0.999897	val: 0.772805	test: 0.619502

Epoch: 45
Loss: 0.09425828264023874
ROC train: 0.999293	val: 0.783399	test: 0.629147
PRC train: 0.999861	val: 0.716184	test: 0.645888

Epoch: 46
Loss: 0.0927763632395148
ROC train: 0.999829	val: 0.819030	test: 0.641590
PRC train: 0.999968	val: 0.741202	test: 0.676899

Epoch: 47
Loss: 0.10726405257962757
ROC train: 0.999495	val: 0.825555	test: 0.655671
PRC train: 0.999902	val: 0.724589	test: 0.671091

Epoch: 48
Loss: 0.07125737082143714
ROC train: 0.999955	val: 0.804175	test: 0.633777
PRC train: 0.999991	val: 0.709242	test: 0.639778

Epoch: 49
Loss: 0.07074480828814765
ROC train: 0.999818	val: 0.807889	test: 0.625096
PRC train: 0.999966	val: 0.715960	test: 0.625443

Epoch: 50
Loss: 0.07059691135832662
ROC train: 1.000000	val: 0.773763	test: 0.624614
PRC train: 1.000000	val: 0.666799	test: 0.625508

Epoch: 51
Loss: 0.06628360363860245
ROC train: 0.999823	val: 0.819532	test: 0.608218
PRC train: 0.999966	val: 0.719207	test: 0.621208

Epoch: 52
Loss: 0.06303159834129819
ROC train: 0.999994	val: 0.829469	test: 0.619502
PRC train: 0.999999	val: 0.756201	test: 0.614390

Epoch: 53
Loss: 0.0598972119044161
ROC train: 0.999997	val: 0.820837	test: 0.602141
PRC train: 0.999999	val: 0.748464	test: 0.593102

Epoch: 54
Loss: 0.06639907019355273
ROC train: 1.000000	val: 0.809596	test: 0.613137
PRC train: 1.000000	val: 0.725209	test: 0.617909

Epoch: 55
Loss: 0.05442357058680183
ROC train: 0.999851	val: 0.850848	test: 0.627508
PRC train: 0.999972	val: 0.753089	test: 0.658951

Epoch: 56
Loss: 0.06959572663755151
ROC train: 0.999992	val: 0.846833	test: 0.617284
PRC train: 0.999998	val: 0.760401	test: 0.635539

Epoch: 57
Loss: 0.04886092829643555
ROC train: 0.999992	val: 0.837699	test: 0.609182
PRC train: 0.999998	val: 0.762239	test: 0.617667

Epoch: 58
Loss: 0.06589675309057892
ROC train: 0.999994	val: 0.819934	test: 0.625675
PRC train: 0.999999	val: 0.730437	test: 0.623559

Epoch: 59
Loss: 0.049670100537840614
ROC train: 1.000000	val: 0.834086	test: 0.643422
PRC train: 1.000000	val: 0.730956	test: 0.664987

Epoch: 60
Loss: 0.06373419035345902
ROC train: 0.999992	val: 0.868413	test: 0.652778
PRC train: 0.999998	val: 0.779422	test: 0.669582

Epoch: 61
Loss: 0.05343409266233654
ROC train: 0.999978	val: 0.859681	test: 0.640239
PRC train: 0.999996	val: 0.767096	test: 0.645218

Epoch: 62
Loss: 0.05162642872303165
ROC train: 0.999989	val: 0.856369	test: 0.639371
PRC train: 0.999998	val: 0.757843	test: 0.666381

Epoch: 63
Loss: 0.053316278113446726
ROC train: 1.000000	val: 0.841313	test: 0.614198
PRC train: 1.000000	val: 0.754062	test: 0.624672

Epoch: 64
Loss: 0.05238042111504858
ROC train: 0.999994	val: 0.805681	test: 0.580440
PRC train: 0.999999	val: 0.716231	test: 0.574312

Epoch: 65
Loss: 0.05935936582020051
ROC train: 0.999966	val: 0.802068	test: 0.609086
PRC train: 0.999994	val: 0.704097	test: 0.591630

Epoch: 66
Loss: 0.05592596147267026
ROC train: 0.999992	val: 0.849142	test: 0.640818
PRC train: 0.999998	val: 0.746053	test: 0.645124

Epoch: 67
Loss: 0.06273944933618476
ROC train: 1.000000	val: 0.798354	test: 0.635706
PRC train: 1.000000	val: 0.688433	test: 0.639436

Epoch: 68
Loss: 0.06447282747048558
ROC train: 0.999994	val: 0.808793	test: 0.633873
PRC train: 0.999999	val: 0.724972	test: 0.667122

Epoch: 69
Loss: 0.047417966475714675
ROC train: 1.000000	val: 0.834387	test: 0.630112
PRC train: 1.000000	val: 0.762189	test: 0.639357

Epoch: 70
Loss: 0.0538023481575214
ROC train: 1.000000	val: 0.818227	test: 0.643711
PRC train: 1.000000	val: 0.736047	test: 0.655368

Epoch: 71
Loss: 0.046131928747952466
ROC train: 0.999955	val: 0.790023	test: 0.647569
PRC train: 0.999991	val: 0.685522	test: 0.635385

Epoch: 72
Loss: 0.04447770302674677
ROC train: 1.000000	val: 0.828566	test: 0.637828
PRC train: 1.000000	val: 0.747231	test: 0.633684

Epoch: 73
Loss: 0.05079346096700179
ROC train: 0.999994	val: 0.792633	test: 0.623553
PRC train: 0.999999	val: 0.737718	test: 0.620279

Epoch: 74
Loss: 0.044908849684921114
ROC train: 1.000000	val: 0.774064	test: 0.618441
PRC train: 1.000000	val: 0.681879	test: 0.617155

Epoch: 75
Loss: 0.0506780804377397
ROC train: 1.000000	val: 0.803372	test: 0.642554
PRC train: 1.000000	val: 0.709769	test: 0.657868

Epoch: 76
Loss: 0.04063893750751839
ROC train: 1.000000	val: 0.833986	test: 0.667921
PRC train: 1.000000	val: 0.725188	test: 0.692906

Epoch: 77
Loss: 0.028881441085292777
ROC train: 1.000000	val: 0.836495	test: 0.652874
PRC train: 1.000000	val: 0.724593	test: 0.665631

Epoch: 78
Loss: 0.042583326945859694
ROC train: 1.000000	val: 0.847536	test: 0.649788
PRC train: 1.000000	val: 0.754071	test: 0.686441

Epoch: 79
Loss: 0.035645114616489344
ROC train: 1.000000	val: 0.804878	test: 0.635224
PRC train: 1.000000	val: 0.690168	test: 0.658278

Epoch: 80
Loss: 0.028064341322358584
ROC train: 1.000000	val: 0.798454	test: 0.636863
PRC train: 1.000000	val: 0.686378	test: 0.658030

Epoch: 81
Loss: 0.03505726699711676
ROC train: 1.000000	val: 0.815819	test: 0.639660
PRC train: 1.000000	val: 0.730331	test: 0.648341

Epoch: 82
Loss: 0.042997080068829505
ROC train: 0.999992	val: 0.830372	test: 0.626061
PRC train: 0.999998	val: 0.751923	test: 0.631396

Epoch: 83
Loss: 0.04168233386438858
ROC train: 1.000000	val: 0.824149	test: 0.630015
PRC train: 1.000000	val: 0.723608	test: 0.643654

Epoch: 84
Loss: 0.032168499915183016
ROC train: 1.000000	val: 0.823045	test: 0.639660
PRC train: 1.000000	val: 0.722260	test: 0.643294

Epoch: 85
Loss: 0.046492992442048284
ROC train: 1.000000	val: 0.837900	test: 0.631655
PRC train: 1.000000	val: 0.761876	test: 0.635474

Epoch: 86
Loss: 0.04523785125902141
ROC train: 1.000000	val: 0.792231	test: 0.648148
PRC train: 1.000000	val: 0.692115	test: 0.648882

Epoch: 87
Loss: 0.036563930296221625
ROC train: 0.999997	val: 0.841815	test: 0.659433
PRC train: 0.999999	val: 0.764326	test: 0.662316

Epoch: 88
Loss: 0.036868769775786396
ROC train: 1.000000	val: 0.829268	test: 0.640432
PRC train: 1.000000	val: 0.755364	test: 0.646554

Epoch: 89
Loss: 0.037308747023055346
ROC train: 1.000000	val: 0.804577	test: 0.635899
PRC train: 1.000000	val: 0.710805	test: 0.637166

Epoch: 90
Loss: 0.033779698096579505
ROC train: 1.000000	val: 0.840108	test: 0.628954
PRC train: 1.000000	val: 0.750001	test: 0.632742

Epoch: 91
Loss: 0.02854158578605966
ROC train: 1.000000	val: 0.836395	test: 0.643133
PRC train: 1.000000	val: 0.739558	test: 0.650196

Epoch: 92
Loss: 0.02712598831464812
ROC train: 1.000000	val: 0.813911	test: 0.641204
PRC train: 1.000000	val: 0.709358	test: 0.646251

Epoch: 93
Loss: 0.03235802634829653
PRC train: 0.998290	val: 0.823907	test: 0.710529

Epoch: 33
Loss: 0.1177685904337437
ROC train: 0.996353	val: 0.891097	test: 0.665799
PRC train: 0.999289	val: 0.812389	test: 0.707123

Epoch: 34
Loss: 0.12390839223649479
ROC train: 0.994849	val: 0.894610	test: 0.649209
PRC train: 0.998978	val: 0.810838	test: 0.687852

Epoch: 35
Loss: 0.11582185983546718
ROC train: 0.995615	val: 0.899528	test: 0.666667
PRC train: 0.999160	val: 0.834261	test: 0.711280

Epoch: 36
Loss: 0.10531213792582425
ROC train: 0.996482	val: 0.869517	test: 0.650463
PRC train: 0.999316	val: 0.774565	test: 0.685680

Epoch: 37
Loss: 0.10864537309949666
ROC train: 0.996976	val: 0.905249	test: 0.663773
PRC train: 0.999398	val: 0.834472	test: 0.707305

Epoch: 38
Loss: 0.11464454561115803
ROC train: 0.997761	val: 0.891298	test: 0.662616
PRC train: 0.999567	val: 0.812941	test: 0.673240

Epoch: 39
Loss: 0.11345882773710125
ROC train: 0.998008	val: 0.862893	test: 0.655093
PRC train: 0.999624	val: 0.753446	test: 0.670016

Epoch: 40
Loss: 0.09652231244653776
ROC train: 0.997801	val: 0.908361	test: 0.664738
PRC train: 0.999580	val: 0.849886	test: 0.709584

Epoch: 41
Loss: 0.11005771901803225
ROC train: 0.998157	val: 0.897420	test: 0.658758
PRC train: 0.999638	val: 0.845984	test: 0.685976

Epoch: 42
Loss: 0.09524596253886859
ROC train: 0.998530	val: 0.874937	test: 0.671103
PRC train: 0.999716	val: 0.781114	test: 0.688184

Epoch: 43
Loss: 0.10114634809488962
ROC train: 0.998258	val: 0.882264	test: 0.664448
PRC train: 0.999661	val: 0.787802	test: 0.704432

Epoch: 44
Loss: 0.08512456032967862
ROC train: 0.997778	val: 0.881160	test: 0.667631
PRC train: 0.999564	val: 0.804202	test: 0.703300

Epoch: 45
Loss: 0.08508186278029688
ROC train: 0.999184	val: 0.883870	test: 0.670621
PRC train: 0.999841	val: 0.793393	test: 0.703578

Epoch: 46
Loss: 0.10931286314511791
ROC train: 0.999523	val: 0.896015	test: 0.671200
PRC train: 0.999907	val: 0.813771	test: 0.701338

Epoch: 47
Loss: 0.08383938027098936
ROC train: 0.998791	val: 0.871424	test: 0.666763
PRC train: 0.999761	val: 0.786934	test: 0.699359

Epoch: 48
Loss: 0.07894348521456207
ROC train: 0.999498	val: 0.884974	test: 0.664931
PRC train: 0.999904	val: 0.794456	test: 0.702351

Epoch: 49
Loss: 0.06916738484056395
ROC train: 0.999613	val: 0.877748	test: 0.676505
PRC train: 0.999927	val: 0.781741	test: 0.687789

Epoch: 50
Loss: 0.07650118562149602
ROC train: 0.999686	val: 0.885075	test: 0.667438
PRC train: 0.999940	val: 0.818552	test: 0.686186

Epoch: 51
Loss: 0.0848810203312396
ROC train: 0.999882	val: 0.898926	test: 0.683256
PRC train: 0.999978	val: 0.848984	test: 0.717367

Epoch: 52
Loss: 0.07408571448822963
ROC train: 0.998976	val: 0.869818	test: 0.660204
PRC train: 0.999801	val: 0.777084	test: 0.676047

Epoch: 53
Loss: 0.08666167816648573
ROC train: 0.999784	val: 0.875238	test: 0.661169
PRC train: 0.999959	val: 0.761748	test: 0.683100

Epoch: 54
Loss: 0.08227247403975636
ROC train: 0.998996	val: 0.896919	test: 0.689429
PRC train: 0.999810	val: 0.819134	test: 0.734889

Epoch: 55
Loss: 0.07394958107148426
ROC train: 0.999851	val: 0.888387	test: 0.667535
PRC train: 0.999972	val: 0.801562	test: 0.691710

Epoch: 56
Loss: 0.06770748735917867
ROC train: 0.999854	val: 0.903744	test: 0.670718
PRC train: 0.999972	val: 0.826068	test: 0.685513

Epoch: 57
Loss: 0.05815894236456916
ROC train: 0.999781	val: 0.890394	test: 0.658951
PRC train: 0.999959	val: 0.821683	test: 0.695010

Epoch: 58
Loss: 0.06909732266666736
ROC train: 0.999489	val: 0.893205	test: 0.666763
PRC train: 0.999901	val: 0.826426	test: 0.711082

Epoch: 59
Loss: 0.06381298957960112
ROC train: 0.999921	val: 0.887684	test: 0.668789
PRC train: 0.999985	val: 0.805845	test: 0.707873

Epoch: 60
Loss: 0.0660679288335934
ROC train: 0.999964	val: 0.881261	test: 0.651813
PRC train: 0.999993	val: 0.790386	test: 0.679584

Epoch: 61
Loss: 0.062280285198432914
ROC train: 0.999899	val: 0.881461	test: 0.671296
PRC train: 0.999981	val: 0.802383	test: 0.704040

Epoch: 62
Loss: 0.050993408353937876
ROC train: 0.999994	val: 0.878149	test: 0.682967
PRC train: 0.999999	val: 0.804115	test: 0.714765

Epoch: 63
Loss: 0.057066848214402326
ROC train: 0.999992	val: 0.884573	test: 0.668210
PRC train: 0.999998	val: 0.813982	test: 0.712841

Epoch: 64
Loss: 0.05524430594822457
ROC train: 0.999913	val: 0.876142	test: 0.671393
PRC train: 0.999984	val: 0.803729	test: 0.701987

Epoch: 65
Loss: 0.0530340133146905
ROC train: 0.999820	val: 0.863997	test: 0.690104
PRC train: 0.999966	val: 0.789387	test: 0.714247

Epoch: 66
Loss: 0.06018623707039158
ROC train: 0.999888	val: 0.891699	test: 0.691647
PRC train: 0.999979	val: 0.811996	test: 0.711538

Epoch: 67
Loss: 0.06408861696641925
ROC train: 0.999950	val: 0.879755	test: 0.668306
PRC train: 0.999990	val: 0.816122	test: 0.701562

Epoch: 68
Loss: 0.06512865456889591
ROC train: 0.999966	val: 0.887383	test: 0.673708
PRC train: 0.999994	val: 0.830778	test: 0.702186

Epoch: 69
Loss: 0.053880926915719315
ROC train: 0.999947	val: 0.903142	test: 0.695602
PRC train: 0.999990	val: 0.848357	test: 0.722998

Epoch: 70
Loss: 0.06758799648862474
ROC train: 1.000000	val: 0.901536	test: 0.686825
PRC train: 1.000000	val: 0.827937	test: 0.702777

Epoch: 71
Loss: 0.045693966639986164
ROC train: 0.999997	val: 0.880759	test: 0.673129
PRC train: 0.999999	val: 0.791272	test: 0.700241

Epoch: 72
Loss: 0.04728070171752371
ROC train: 1.000000	val: 0.874536	test: 0.667245
PRC train: 1.000000	val: 0.774378	test: 0.687734

Epoch: 73
Loss: 0.04546113755751076
ROC train: 0.999947	val: 0.885276	test: 0.670332
PRC train: 0.999990	val: 0.806422	test: 0.703229

Epoch: 74
Loss: 0.03665139405159742
ROC train: 1.000000	val: 0.883971	test: 0.683256
PRC train: 1.000000	val: 0.815637	test: 0.718972

Epoch: 75
Loss: 0.054637556787834766
ROC train: 1.000000	val: 0.898625	test: 0.701292
PRC train: 1.000000	val: 0.823760	test: 0.741244

Epoch: 76
Loss: 0.0383447767185629
ROC train: 0.999997	val: 0.898826	test: 0.691840
PRC train: 0.999999	val: 0.828861	test: 0.733613

Epoch: 77
Loss: 0.044981181366883005
ROC train: 0.999994	val: 0.904848	test: 0.679880
PRC train: 0.999999	val: 0.845114	test: 0.719494

Epoch: 78
Loss: 0.05758095004494031
ROC train: 1.000000	val: 0.886881	test: 0.654707
PRC train: 1.000000	val: 0.819896	test: 0.689311

Epoch: 79
Loss: 0.05244551130044611
ROC train: 1.000000	val: 0.865402	test: 0.661748
PRC train: 1.000000	val: 0.792343	test: 0.680329

Epoch: 80
Loss: 0.05452559122960635
ROC train: 0.999997	val: 0.895714	test: 0.672068
PRC train: 0.999999	val: 0.834625	test: 0.682724

Epoch: 81
Loss: 0.06213299447669972
ROC train: 0.999992	val: 0.890595	test: 0.669850
PRC train: 0.999998	val: 0.833899	test: 0.684336

Epoch: 82
Loss: 0.06850566844068133
ROC train: 0.999784	val: 0.897822	test: 0.684799
PRC train: 0.999959	val: 0.849619	test: 0.689156

Epoch: 83
Loss: 0.06107723703504855
ROC train: 0.999950	val: 0.874435	test: 0.666667
PRC train: 0.999990	val: 0.787199	test: 0.671193

Epoch: 84
Loss: 0.05395197030391772
ROC train: 0.999778	val: 0.877145	test: 0.691165
PRC train: 0.999958	val: 0.801861	test: 0.717709

Epoch: 85
Loss: 0.049657665436954206
ROC train: 0.999978	val: 0.865001	test: 0.680266
PRC train: 0.999996	val: 0.776144	test: 0.692481

Epoch: 86
Loss: 0.04664017086895962
ROC train: 1.000000	val: 0.858376	test: 0.665606
PRC train: 1.000000	val: 0.765850	test: 0.674385

Epoch: 87
Loss: 0.03753049124015238
ROC train: 1.000000	val: 0.876443	test: 0.684992
PRC train: 1.000000	val: 0.809233	test: 0.713782

Epoch: 88
Loss: 0.03331701385879772
ROC train: 1.000000	val: 0.872528	test: 0.679784
PRC train: 1.000000	val: 0.794531	test: 0.702477

Epoch: 89
Loss: 0.040827224990794796
ROC train: 1.000000	val: 0.882967	test: 0.665509
PRC train: 1.000000	val: 0.797720	test: 0.689283

Epoch: 90
Loss: 0.04331139381703874
ROC train: 1.000000	val: 0.882565	test: 0.681424
PRC train: 1.000000	val: 0.792100	test: 0.694565

Epoch: 91
Loss: 0.04397607017400473
ROC train: 1.000000	val: 0.880357	test: 0.667824
PRC train: 1.000000	val: 0.804079	test: 0.680628

Epoch: 92
Loss: 0.0337541052597312
ROC train: 1.000000	val: 0.858577	test: 0.656829
PRC train: 1.000000	val: 0.783408	test: 0.671064

Epoch: 93
Loss: 0.03355327577146013
ROC train: 0.999994	val: 0.877848	test: 0.688465
PRC train: 0.999644	val: 0.886341	test: 0.708318

Epoch: 33
Loss: 0.14272940871115455
ROC train: 0.998597	val: 0.942688	test: 0.662712
PRC train: 0.999736	val: 0.901154	test: 0.728856

Epoch: 34
Loss: 0.12467512339010733
ROC train: 0.998227	val: 0.947405	test: 0.642650
PRC train: 0.999664	val: 0.904138	test: 0.708050

Epoch: 35
Loss: 0.1282519401333434
ROC train: 0.999189	val: 0.932049	test: 0.647569
PRC train: 0.999852	val: 0.874201	test: 0.714346

Epoch: 36
Loss: 0.09620981241400993
ROC train: 0.998780	val: 0.933353	test: 0.652103
PRC train: 0.999772	val: 0.881114	test: 0.729009

Epoch: 37
Loss: 0.09408264826569293
ROC train: 0.999223	val: 0.931547	test: 0.673032
PRC train: 0.999850	val: 0.882742	test: 0.725803

Epoch: 38
Loss: 0.0994871068273127
ROC train: 0.999680	val: 0.933956	test: 0.665895
PRC train: 0.999940	val: 0.882083	test: 0.725651

Epoch: 39
Loss: 0.10731385067334619
ROC train: 0.998942	val: 0.932651	test: 0.639178
PRC train: 0.999792	val: 0.873856	test: 0.693829

Epoch: 40
Loss: 0.10759365786828848
ROC train: 0.998853	val: 0.922112	test: 0.654803
PRC train: 0.999771	val: 0.848395	test: 0.714412

Epoch: 41
Loss: 0.11427765515915216
ROC train: 0.999907	val: 0.930844	test: 0.669464
PRC train: 0.999982	val: 0.881412	test: 0.731194

Epoch: 42
Loss: 0.09296645698906172
ROC train: 0.998595	val: 0.936565	test: 0.648052
PRC train: 0.999734	val: 0.891497	test: 0.710749

Epoch: 43
Loss: 0.09333364759882268
ROC train: 0.999618	val: 0.930342	test: 0.645737
PRC train: 0.999928	val: 0.878344	test: 0.707380

Epoch: 44
Loss: 0.0845373687380269
ROC train: 0.999851	val: 0.923718	test: 0.658179
PRC train: 0.999972	val: 0.870516	test: 0.716424

Epoch: 45
Loss: 0.08431960768741333
ROC train: 0.999394	val: 0.933153	test: 0.655093
PRC train: 0.999883	val: 0.878496	test: 0.713103

Epoch: 46
Loss: 0.07337416429056118
ROC train: 0.999759	val: 0.923517	test: 0.654900
PRC train: 0.999954	val: 0.873194	test: 0.709820

Epoch: 47
Loss: 0.09231112299265871
ROC train: 0.999966	val: 0.934156	test: 0.649402
PRC train: 0.999994	val: 0.882856	test: 0.716699

Epoch: 48
Loss: 0.0755745132174185
ROC train: 0.999762	val: 0.917896	test: 0.636863
PRC train: 0.999955	val: 0.860598	test: 0.700489

Epoch: 49
Loss: 0.07072760274915739
ROC train: 0.999882	val: 0.911372	test: 0.628665
PRC train: 0.999978	val: 0.854971	test: 0.694339

Epoch: 50
Loss: 0.0711387160548227
ROC train: 0.999986	val: 0.927130	test: 0.659915
PRC train: 0.999997	val: 0.882994	test: 0.730348

Epoch: 51
Loss: 0.07023750223569637
ROC train: 0.999955	val: 0.928435	test: 0.654032
PRC train: 0.999991	val: 0.864319	test: 0.717124

Epoch: 52
Loss: 0.06592630646970168
ROC train: 0.999994	val: 0.932350	test: 0.646508
PRC train: 0.999999	val: 0.878744	test: 0.705739

Epoch: 53
Loss: 0.0741992645069024
ROC train: 0.999983	val: 0.929941	test: 0.645448
PRC train: 0.999997	val: 0.877482	test: 0.714379

Epoch: 54
Loss: 0.07564007304053995
ROC train: 1.000000	val: 0.928736	test: 0.646219
PRC train: 1.000000	val: 0.884995	test: 0.724147

Epoch: 55
Loss: 0.05840672269956716
ROC train: 0.999994	val: 0.925625	test: 0.637442
PRC train: 0.999999	val: 0.880227	test: 0.719429

Epoch: 56
Loss: 0.061709867935241816
ROC train: 0.999994	val: 0.931446	test: 0.636574
PRC train: 0.999999	val: 0.877627	test: 0.716027

Epoch: 57
Loss: 0.054094904040909365
ROC train: 1.000000	val: 0.925625	test: 0.653549
PRC train: 1.000000	val: 0.862462	test: 0.728701

Epoch: 58
Loss: 0.058848340760608256
ROC train: 0.999902	val: 0.922413	test: 0.663484
PRC train: 0.999982	val: 0.864929	test: 0.736932

Epoch: 59
Loss: 0.06300268069543973
ROC train: 0.999975	val: 0.927431	test: 0.665220
PRC train: 0.999995	val: 0.884376	test: 0.733582

Epoch: 60
Loss: 0.07593838665357804
ROC train: 0.999986	val: 0.932149	test: 0.658275
PRC train: 0.999997	val: 0.902193	test: 0.733950

Epoch: 61
Loss: 0.05031339920480956
ROC train: 0.999792	val: 0.921911	test: 0.662423
PRC train: 0.999960	val: 0.866391	test: 0.717654

Epoch: 62
Loss: 0.06268946685522843
ROC train: 0.999969	val: 0.929640	test: 0.654610
PRC train: 0.999994	val: 0.883584	test: 0.720260

Epoch: 63
Loss: 0.04905881246862089
ROC train: 1.000000	val: 0.932852	test: 0.676987
PRC train: 1.000000	val: 0.896860	test: 0.750223

Epoch: 64
Loss: 0.05309677065163464
ROC train: 1.000000	val: 0.927331	test: 0.676022
PRC train: 1.000000	val: 0.884988	test: 0.749288

Epoch: 65
Loss: 0.04194431535423572
ROC train: 0.999905	val: 0.917394	test: 0.662133
PRC train: 0.999982	val: 0.877993	test: 0.734932

Epoch: 66
Loss: 0.045124399412361064
ROC train: 1.000000	val: 0.935863	test: 0.682967
PRC train: 1.000000	val: 0.902462	test: 0.755251

Epoch: 67
Loss: 0.035227249340736795
ROC train: 1.000000	val: 0.928937	test: 0.678048
PRC train: 1.000000	val: 0.886080	test: 0.756076

Epoch: 68
Loss: 0.04217347689829991
ROC train: 1.000000	val: 0.928234	test: 0.665992
PRC train: 1.000000	val: 0.892904	test: 0.737749

Epoch: 69
Loss: 0.04804678518411861
ROC train: 1.000000	val: 0.930443	test: 0.665413
PRC train: 1.000000	val: 0.891123	test: 0.740288

Epoch: 70
Loss: 0.04949753322054622
ROC train: 1.000000	val: 0.922814	test: 0.650270
PRC train: 1.000000	val: 0.868927	test: 0.728805

Epoch: 71
Loss: 0.04806882986261058
ROC train: 0.999958	val: 0.933855	test: 0.651524
PRC train: 0.999992	val: 0.879925	test: 0.728604

Epoch: 72
Loss: 0.049647263543326374
ROC train: 1.000000	val: 0.935060	test: 0.674479
PRC train: 1.000000	val: 0.895967	test: 0.745564

Epoch: 73
Loss: 0.04059146274272522
ROC train: 0.999933	val: 0.924220	test: 0.651331
PRC train: 0.999987	val: 0.866752	test: 0.716022

Epoch: 74
Loss: 0.04182398926032348
ROC train: 0.999997	val: 0.932751	test: 0.645062
PRC train: 0.999999	val: 0.884871	test: 0.720160

Epoch: 75
Loss: 0.0438547099959025
ROC train: 1.000000	val: 0.922513	test: 0.639757
PRC train: 1.000000	val: 0.865854	test: 0.707276

Epoch: 76
Loss: 0.048618754727164135
ROC train: 1.000000	val: 0.920707	test: 0.638889
PRC train: 1.000000	val: 0.858889	test: 0.713236

Epoch: 77
Loss: 0.06108435067386179
ROC train: 0.999992	val: 0.916591	test: 0.646219
PRC train: 0.999998	val: 0.870558	test: 0.718239

Epoch: 78
Loss: 0.050432302794665325
ROC train: 0.999992	val: 0.916290	test: 0.669078
PRC train: 0.999998	val: 0.861636	test: 0.740023

Epoch: 79
Loss: 0.041258609390204
ROC train: 1.000000	val: 0.910469	test: 0.664448
PRC train: 1.000000	val: 0.854849	test: 0.743677

Epoch: 80
Loss: 0.03816476853440287
ROC train: 1.000000	val: 0.916090	test: 0.651042
PRC train: 1.000000	val: 0.868472	test: 0.730240

Epoch: 81
Loss: 0.030612306428778262
ROC train: 1.000000	val: 0.929339	test: 0.637153
PRC train: 1.000000	val: 0.883647	test: 0.713343

Epoch: 82
Loss: 0.03691513241559478
ROC train: 1.000000	val: 0.934056	test: 0.659722
PRC train: 1.000000	val: 0.891511	test: 0.742402

Epoch: 83
Loss: 0.05450854184849043
ROC train: 1.000000	val: 0.933153	test: 0.671489
PRC train: 1.000000	val: 0.888544	test: 0.746726

Epoch: 84
Loss: 0.03330122056818655
ROC train: 1.000000	val: 0.933554	test: 0.680556
PRC train: 1.000000	val: 0.891135	test: 0.760888

Epoch: 85
Loss: 0.02676841128328327
ROC train: 1.000000	val: 0.931848	test: 0.661458
PRC train: 1.000000	val: 0.887916	test: 0.740780

Epoch: 86
Loss: 0.026487271190188604
ROC train: 1.000000	val: 0.928234	test: 0.658661
PRC train: 1.000000	val: 0.875487	test: 0.735476

Epoch: 87
Loss: 0.025055537405114507
ROC train: 1.000000	val: 0.928937	test: 0.648727
PRC train: 1.000000	val: 0.878786	test: 0.725092

Epoch: 88
Loss: 0.029947787469971673
ROC train: 1.000000	val: 0.934257	test: 0.647955
PRC train: 1.000000	val: 0.892989	test: 0.731386

Epoch: 89
Loss: 0.030412276289618883
ROC train: 1.000000	val: 0.936264	test: 0.648341
PRC train: 1.000000	val: 0.888425	test: 0.732723

Epoch: 90
Loss: 0.026992613129771154
ROC train: 1.000000	val: 0.932149	test: 0.640143
PRC train: 1.000000	val: 0.877630	test: 0.722461

Epoch: 91
Loss: 0.029080489427014543
ROC train: 1.000000	val: 0.938071	test: 0.648823
PRC train: 1.000000	val: 0.894145	test: 0.732190

Epoch: 92
Loss: 0.030722664775549968
ROC train: 1.000000	val: 0.934959	test: 0.648534
PRC train: 1.000000	val: 0.893522	test: 0.725766

Epoch: 93
Loss: 0.032376045111659035
PRC train: 0.999264	val: 0.829018	test: 0.658939

Epoch: 33
Loss: 0.12343653019536098
ROC train: 0.997256	val: 0.890394	test: 0.634645
PRC train: 0.999443	val: 0.791621	test: 0.662749

Epoch: 34
Loss: 0.12489755085825695
ROC train: 0.997991	val: 0.891599	test: 0.632812
PRC train: 0.999617	val: 0.797985	test: 0.640950

Epoch: 35
Loss: 0.11241298841883698
ROC train: 0.998900	val: 0.878250	test: 0.635417
PRC train: 0.999791	val: 0.783886	test: 0.672001

Epoch: 36
Loss: 0.10946992349153198
ROC train: 0.998014	val: 0.878952	test: 0.634259
PRC train: 0.999616	val: 0.790614	test: 0.665632

Epoch: 37
Loss: 0.10504833311208268
ROC train: 0.998693	val: 0.881461	test: 0.648823
PRC train: 0.999751	val: 0.783837	test: 0.671443

Epoch: 38
Loss: 0.10179446388373466
ROC train: 0.997997	val: 0.883870	test: 0.627315
PRC train: 0.999617	val: 0.796487	test: 0.653746

Epoch: 39
Loss: 0.11065935820790615
ROC train: 0.998721	val: 0.857975	test: 0.625386
PRC train: 0.999753	val: 0.750321	test: 0.618106

Epoch: 40
Loss: 0.11831539436922947
ROC train: 0.998151	val: 0.856369	test: 0.636285
PRC train: 0.999641	val: 0.743908	test: 0.659795

Epoch: 41
Loss: 0.09738727613228391
ROC train: 0.996838	val: 0.853960	test: 0.627025
PRC train: 0.999382	val: 0.750290	test: 0.640932

Epoch: 42
Loss: 0.0910167051557794
ROC train: 0.998387	val: 0.885777	test: 0.632330
PRC train: 0.999689	val: 0.793201	test: 0.689080

Epoch: 43
Loss: 0.08903277317297346
ROC train: 0.998766	val: 0.876945	test: 0.651910
PRC train: 0.999766	val: 0.766178	test: 0.697075

Epoch: 44
Loss: 0.08668807079146106
ROC train: 0.999697	val: 0.893004	test: 0.634934
PRC train: 0.999944	val: 0.805942	test: 0.640438

Epoch: 45
Loss: 0.10119179032528727
ROC train: 0.999731	val: 0.882867	test: 0.617188
PRC train: 0.999948	val: 0.798037	test: 0.632660

Epoch: 46
Loss: 0.08110026051084515
ROC train: 0.999902	val: 0.853257	test: 0.635417
PRC train: 0.999981	val: 0.751718	test: 0.663381

Epoch: 47
Loss: 0.08334637251449625
ROC train: 0.999599	val: 0.888989	test: 0.647569
PRC train: 0.999924	val: 0.805163	test: 0.672567

Epoch: 48
Loss: 0.07072315867890026
ROC train: 0.999921	val: 0.885276	test: 0.624228
PRC train: 0.999985	val: 0.804965	test: 0.638824

Epoch: 49
Loss: 0.07894378339959916
ROC train: 0.999798	val: 0.876342	test: 0.629051
PRC train: 0.999962	val: 0.772291	test: 0.656558

Epoch: 50
Loss: 0.06607180919586034
ROC train: 0.999675	val: 0.873934	test: 0.630691
PRC train: 0.999937	val: 0.764535	test: 0.656726

Epoch: 51
Loss: 0.06885574212289343
ROC train: 0.999969	val: 0.862290	test: 0.630883
PRC train: 0.999994	val: 0.747712	test: 0.671273

Epoch: 52
Loss: 0.07397586525283868
ROC train: 0.999691	val: 0.874335	test: 0.627701
PRC train: 0.999941	val: 0.786508	test: 0.632651

Epoch: 53
Loss: 0.07594426752119061
ROC train: 0.999703	val: 0.866406	test: 0.639853
PRC train: 0.999943	val: 0.775828	test: 0.655293

Epoch: 54
Loss: 0.07028831826096835
ROC train: 0.999978	val: 0.849041	test: 0.650656
PRC train: 0.999996	val: 0.751971	test: 0.675359

Epoch: 55
Loss: 0.060056389150623925
ROC train: 0.999969	val: 0.835692	test: 0.600405
PRC train: 0.999994	val: 0.727362	test: 0.602526

Epoch: 56
Loss: 0.07435281449436773
ROC train: 0.999950	val: 0.878250	test: 0.633970
PRC train: 0.999990	val: 0.763795	test: 0.656100

Epoch: 57
Loss: 0.06218995683898475
ROC train: 0.999546	val: 0.872227	test: 0.640625
PRC train: 0.999914	val: 0.757278	test: 0.655956

Epoch: 58
Loss: 0.049871052749576296
ROC train: 0.999930	val: 0.869517	test: 0.605517
PRC train: 0.999987	val: 0.757071	test: 0.612759

Epoch: 59
Loss: 0.04859386537206971
ROC train: 0.999961	val: 0.878651	test: 0.609279
PRC train: 0.999993	val: 0.776008	test: 0.637866

Epoch: 60
Loss: 0.05690537514966005
ROC train: 0.999964	val: 0.874235	test: 0.649113
PRC train: 0.999993	val: 0.745750	test: 0.675081

Epoch: 61
Loss: 0.06716035089688618
ROC train: 0.999994	val: 0.851751	test: 0.632909
PRC train: 0.999999	val: 0.736836	test: 0.638860

Epoch: 62
Loss: 0.053383411649762534
ROC train: 0.999989	val: 0.886480	test: 0.634645
PRC train: 0.999998	val: 0.795400	test: 0.661325

Epoch: 63
Loss: 0.056705415799394567
ROC train: 0.999983	val: 0.886078	test: 0.629823
PRC train: 0.999997	val: 0.786147	test: 0.635016

Epoch: 64
Loss: 0.06107522106348627
ROC train: 1.000000	val: 0.868815	test: 0.631173
PRC train: 1.000000	val: 0.750629	test: 0.646920

Epoch: 65
Loss: 0.06636553989601401
ROC train: 1.000000	val: 0.879855	test: 0.643615
PRC train: 1.000000	val: 0.786127	test: 0.675748

Epoch: 66
Loss: 0.06153329093991149
ROC train: 0.999972	val: 0.881361	test: 0.623071
PRC train: 0.999995	val: 0.781845	test: 0.647935

Epoch: 67
Loss: 0.0667635918061773
ROC train: 0.999978	val: 0.859079	test: 0.647955
PRC train: 0.999996	val: 0.762322	test: 0.676307

Epoch: 68
Loss: 0.05387456795291291
ROC train: 0.999994	val: 0.876041	test: 0.621335
PRC train: 0.999999	val: 0.781790	test: 0.625867

Epoch: 69
Loss: 0.0515189833069297
ROC train: 0.999408	val: 0.879354	test: 0.615451
PRC train: 0.999879	val: 0.790678	test: 0.648427

Epoch: 70
Loss: 0.047109850015744324
ROC train: 0.999997	val: 0.871926	test: 0.613426
PRC train: 0.999999	val: 0.756213	test: 0.605804

Epoch: 71
Loss: 0.046852071050278866
ROC train: 0.999989	val: 0.869116	test: 0.611979
PRC train: 0.999998	val: 0.754787	test: 0.604221

Epoch: 72
Loss: 0.04682738242015443
ROC train: 0.999986	val: 0.885476	test: 0.621238
PRC train: 0.999997	val: 0.782279	test: 0.640440

Epoch: 73
Loss: 0.049843903417611565
ROC train: 1.000000	val: 0.878049	test: 0.630787
PRC train: 1.000000	val: 0.774023	test: 0.657033

Epoch: 74
Loss: 0.03808900755554228
ROC train: 1.000000	val: 0.889290	test: 0.639757
PRC train: 1.000000	val: 0.805404	test: 0.668853

Epoch: 75
Loss: 0.040095297535600795
ROC train: 0.999989	val: 0.847134	test: 0.604842
PRC train: 0.999998	val: 0.741590	test: 0.609478

Epoch: 76
Loss: 0.048150332708580344
ROC train: 0.999997	val: 0.846833	test: 0.617573
PRC train: 0.999999	val: 0.732267	test: 0.619079

Epoch: 77
Loss: 0.038957559115721345
ROC train: 1.000000	val: 0.855967	test: 0.629533
PRC train: 1.000000	val: 0.736476	test: 0.643997

Epoch: 78
Loss: 0.04865301396748166
ROC train: 0.999955	val: 0.844023	test: 0.658951
PRC train: 0.999991	val: 0.724893	test: 0.694809

Epoch: 79
Loss: 0.052305229095887605
ROC train: 1.000000	val: 0.852956	test: 0.641204
PRC train: 1.000000	val: 0.716803	test: 0.666740

Epoch: 80
Loss: 0.03412620386733557
ROC train: 0.999958	val: 0.869818	test: 0.604842
PRC train: 0.999992	val: 0.761556	test: 0.591900

Epoch: 81
Loss: 0.052102667298792135
ROC train: 1.000000	val: 0.859380	test: 0.619985
PRC train: 1.000000	val: 0.725438	test: 0.612614

Epoch: 82
Loss: 0.028089974410603877
ROC train: 1.000000	val: 0.867711	test: 0.638021
PRC train: 1.000000	val: 0.739769	test: 0.663227

Epoch: 83
Loss: 0.04157374150464964
ROC train: 1.000000	val: 0.892302	test: 0.620756
PRC train: 1.000000	val: 0.787167	test: 0.639511

Epoch: 84
Loss: 0.03452705673050516
ROC train: 1.000000	val: 0.877346	test: 0.628858
PRC train: 1.000000	val: 0.759258	test: 0.642436

Epoch: 85
Loss: 0.03435732987420275
ROC train: 1.000000	val: 0.838302	test: 0.640914
PRC train: 1.000000	val: 0.703722	test: 0.665220

Epoch: 86
Loss: 0.026232155969522688
ROC train: 1.000000	val: 0.841012	test: 0.623167
PRC train: 1.000000	val: 0.716041	test: 0.637914

Epoch: 87
Loss: 0.03363882010495502
ROC train: 0.999975	val: 0.856971	test: 0.638889
PRC train: 0.999995	val: 0.723766	test: 0.630321

Epoch: 88
Loss: 0.04426991876309364
ROC train: 1.000000	val: 0.885175	test: 0.647473
PRC train: 1.000000	val: 0.772308	test: 0.666878

Epoch: 89
Loss: 0.043729107687315624
ROC train: 0.999997	val: 0.862190	test: 0.621335
PRC train: 0.999999	val: 0.752282	test: 0.654271

Epoch: 90
Loss: 0.03259173086420206
ROC train: 1.000000	val: 0.856971	test: 0.602816
PRC train: 1.000000	val: 0.738286	test: 0.629673

Epoch: 91
Loss: 0.038323415571720254
ROC train: 1.000000	val: 0.868012	test: 0.625096
PRC train: 1.000000	val: 0.747111	test: 0.636676

Epoch: 92
Loss: 0.032401644657883394
ROC train: 1.000000	val: 0.877145	test: 0.625675
PRC train: 1.000000	val: 0.757481	test: 0.631844

Epoch: 93
Loss: 0.0316998421112076
PRC train: 0.999112	val: 0.874821	test: 0.751995

Epoch: 33
Loss: 0.11155200390133099
ROC train: 0.996911	val: 0.918197	test: 0.681520
PRC train: 0.999394	val: 0.862388	test: 0.744720

Epoch: 34
Loss: 0.10079655535555203
ROC train: 0.996451	val: 0.905249	test: 0.664159
PRC train: 0.999301	val: 0.846677	test: 0.712473

Epoch: 35
Loss: 0.11682235795898609
ROC train: 0.997116	val: 0.924922	test: 0.677083
PRC train: 0.999423	val: 0.878388	test: 0.735341

Epoch: 36
Loss: 0.11453987410633579
ROC train: 0.997470	val: 0.924019	test: 0.674383
PRC train: 0.999512	val: 0.878497	test: 0.732234

Epoch: 37
Loss: 0.09646224642666708
ROC train: 0.998547	val: 0.923015	test: 0.665702
PRC train: 0.999726	val: 0.866549	test: 0.690207

Epoch: 38
Loss: 0.09891035965405677
ROC train: 0.996566	val: 0.907859	test: 0.661651
PRC train: 0.999323	val: 0.816084	test: 0.704206

Epoch: 39
Loss: 0.10700901594141059
ROC train: 0.998191	val: 0.916692	test: 0.689333
PRC train: 0.999652	val: 0.851666	test: 0.751899

Epoch: 40
Loss: 0.09352103750230681
ROC train: 0.995640	val: 0.908963	test: 0.666763
PRC train: 0.999178	val: 0.837356	test: 0.710084

Epoch: 41
Loss: 0.09919576998061608
ROC train: 0.999032	val: 0.934357	test: 0.715278
PRC train: 0.999820	val: 0.889603	test: 0.778076

Epoch: 42
Loss: 0.10315244989770542
ROC train: 0.998853	val: 0.926930	test: 0.684896
PRC train: 0.999782	val: 0.882788	test: 0.743235

Epoch: 43
Loss: 0.08536139808405209
ROC train: 0.997411	val: 0.869818	test: 0.641397
PRC train: 0.999510	val: 0.799996	test: 0.693258

Epoch: 44
Loss: 0.08519325083832742
ROC train: 0.997848	val: 0.911673	test: 0.657986
PRC train: 0.999579	val: 0.849080	test: 0.723754

Epoch: 45
Loss: 0.10437531949754589
ROC train: 0.999554	val: 0.902841	test: 0.684703
PRC train: 0.999915	val: 0.819048	test: 0.739112

Epoch: 46
Loss: 0.08544446447873276
ROC train: 0.999276	val: 0.916792	test: 0.696663
PRC train: 0.999864	val: 0.866030	test: 0.748899

Epoch: 47
Loss: 0.09244950600339216
ROC train: 0.999074	val: 0.922915	test: 0.688465
PRC train: 0.999829	val: 0.874840	test: 0.741196

Epoch: 48
Loss: 0.07487629419238319
ROC train: 0.999492	val: 0.897119	test: 0.669753
PRC train: 0.999903	val: 0.818021	test: 0.716412

Epoch: 49
Loss: 0.07577332713693741
ROC train: 0.998987	val: 0.916893	test: 0.665606
PRC train: 0.999803	val: 0.865624	test: 0.714417

Epoch: 50
Loss: 0.08452847915832641
ROC train: 0.999722	val: 0.905651	test: 0.666088
PRC train: 0.999947	val: 0.827796	test: 0.716385

Epoch: 51
Loss: 0.08114641817356819
ROC train: 0.999823	val: 0.902138	test: 0.659144
PRC train: 0.999966	val: 0.839751	test: 0.701177

Epoch: 52
Loss: 0.0769382207198431
ROC train: 0.999315	val: 0.902539	test: 0.665123
PRC train: 0.999873	val: 0.846829	test: 0.710374

Epoch: 53
Loss: 0.06107883324817435
ROC train: 0.999686	val: 0.911171	test: 0.682774
PRC train: 0.999940	val: 0.865817	test: 0.742768

Epoch: 54
Loss: 0.06947285777195082
ROC train: 0.999114	val: 0.897722	test: 0.647473
PRC train: 0.999832	val: 0.823559	test: 0.693017

Epoch: 55
Loss: 0.060232003582206824
ROC train: 0.999907	val: 0.906253	test: 0.656925
PRC train: 0.999982	val: 0.842111	test: 0.717641

Epoch: 56
Loss: 0.056280305113160685
ROC train: 0.999899	val: 0.910569	test: 0.698785
PRC train: 0.999981	val: 0.836786	test: 0.755150

Epoch: 57
Loss: 0.06600163001203711
ROC train: 0.999632	val: 0.916391	test: 0.707948
PRC train: 0.999932	val: 0.855186	test: 0.761135

Epoch: 58
Loss: 0.05505922217780777
ROC train: 0.999885	val: 0.902539	test: 0.698206
PRC train: 0.999978	val: 0.826316	test: 0.749639

Epoch: 59
Loss: 0.08107679636215832
ROC train: 0.999759	val: 0.912777	test: 0.719907
PRC train: 0.999954	val: 0.852894	test: 0.772041

Epoch: 60
Loss: 0.06758347764810459
ROC train: 0.999955	val: 0.911573	test: 0.681713
PRC train: 0.999991	val: 0.852902	test: 0.733150

Epoch: 61
Loss: 0.06894487057011846
ROC train: 0.999893	val: 0.904145	test: 0.659336
PRC train: 0.999980	val: 0.844262	test: 0.719306

Epoch: 62
Loss: 0.07186690879363068
ROC train: 0.999961	val: 0.913078	test: 0.680266
PRC train: 0.999993	val: 0.864114	test: 0.737669

Epoch: 63
Loss: 0.05152832376065963
ROC train: 0.999994	val: 0.905149	test: 0.711516
PRC train: 0.999999	val: 0.835520	test: 0.777123

Epoch: 64
Loss: 0.07019858358339025
ROC train: 0.999683	val: 0.897019	test: 0.713542
PRC train: 0.999941	val: 0.805646	test: 0.777712

Epoch: 65
Loss: 0.062463580000602925
ROC train: 0.999644	val: 0.917495	test: 0.707658
PRC train: 0.999931	val: 0.856473	test: 0.770890

Epoch: 66
Loss: 0.06151486996082999
ROC train: 0.999992	val: 0.902439	test: 0.673225
PRC train: 0.999998	val: 0.832346	test: 0.713098

Epoch: 67
Loss: 0.05359206062501741
ROC train: 0.999964	val: 0.897119	test: 0.666184
PRC train: 0.999993	val: 0.819417	test: 0.717504

Epoch: 68
Loss: 0.053416488557436026
ROC train: 0.999907	val: 0.900130	test: 0.696181
PRC train: 0.999983	val: 0.824348	test: 0.760247

Epoch: 69
Loss: 0.0408823064384664
ROC train: 0.999969	val: 0.903242	test: 0.705150
PRC train: 0.999994	val: 0.831615	test: 0.760148

Epoch: 70
Loss: 0.04611713401499696
ROC train: 0.999978	val: 0.893807	test: 0.676698
PRC train: 0.999996	val: 0.820753	test: 0.718875

Epoch: 71
Loss: 0.0470294484629651
ROC train: 0.999975	val: 0.897420	test: 0.649691
PRC train: 0.999995	val: 0.836303	test: 0.693694

Epoch: 72
Loss: 0.05012472141541822
ROC train: 1.000000	val: 0.902841	test: 0.688465
PRC train: 1.000000	val: 0.845126	test: 0.742463

Epoch: 73
Loss: 0.06329657784659762
ROC train: 0.999989	val: 0.907257	test: 0.701292
PRC train: 0.999998	val: 0.842195	test: 0.756317

Epoch: 74
Loss: 0.04532621781264463
ROC train: 0.999560	val: 0.893004	test: 0.671296
PRC train: 0.999917	val: 0.798222	test: 0.720937

Epoch: 75
Loss: 0.04873135111471695
ROC train: 0.999966	val: 0.914082	test: 0.678434
PRC train: 0.999994	val: 0.867911	test: 0.739267

Epoch: 76
Loss: 0.049098401536752136
ROC train: 0.999989	val: 0.900331	test: 0.693383
PRC train: 0.999998	val: 0.828342	test: 0.735788

Epoch: 77
Loss: 0.049154152637937064
ROC train: 1.000000	val: 0.894209	test: 0.695505
PRC train: 1.000000	val: 0.801699	test: 0.750164

Epoch: 78
Loss: 0.04031794584034387
ROC train: 0.999994	val: 0.895614	test: 0.711516
PRC train: 0.999999	val: 0.831106	test: 0.760520

Epoch: 79
Loss: 0.04876654321446705
ROC train: 0.999919	val: 0.903844	test: 0.718075
PRC train: 0.999985	val: 0.858526	test: 0.769684

Epoch: 80
Loss: 0.03907397816587924
ROC train: 0.999815	val: 0.903945	test: 0.711034
PRC train: 0.999965	val: 0.856625	test: 0.761301

Epoch: 81
Loss: 0.03803261495256375
ROC train: 1.000000	val: 0.905651	test: 0.694252
PRC train: 1.000000	val: 0.850786	test: 0.742094

Epoch: 82
Loss: 0.055060908149720346
ROC train: 0.999994	val: 0.904145	test: 0.705150
PRC train: 0.999999	val: 0.838668	test: 0.761323

Epoch: 83
Loss: 0.05043173795001501
ROC train: 1.000000	val: 0.891197	test: 0.680652
PRC train: 1.000000	val: 0.832999	test: 0.731885

Epoch: 84
Loss: 0.03741637534426502
ROC train: 0.999989	val: 0.905751	test: 0.660301
PRC train: 0.999998	val: 0.849680	test: 0.696252

Epoch: 85
Loss: 0.04134342526026703
ROC train: 1.000000	val: 0.914684	test: 0.686343
PRC train: 1.000000	val: 0.880394	test: 0.745706

Epoch: 86
Loss: 0.027494167125589948
ROC train: 1.000000	val: 0.912075	test: 0.706308
PRC train: 1.000000	val: 0.867278	test: 0.765639

Epoch: 87
Loss: 0.031183461013716506
ROC train: 1.000000	val: 0.907056	test: 0.701196
PRC train: 1.000000	val: 0.842168	test: 0.748016

Epoch: 88
Loss: 0.031298465840087046
ROC train: 1.000000	val: 0.908762	test: 0.689333
PRC train: 1.000000	val: 0.856156	test: 0.731544

Epoch: 89
Loss: 0.0304935200160921
ROC train: 1.000000	val: 0.920606	test: 0.681809
PRC train: 1.000000	val: 0.875864	test: 0.732076

Epoch: 90
Loss: 0.02373591104212098
ROC train: 1.000000	val: 0.925926	test: 0.689815
PRC train: 1.000000	val: 0.879324	test: 0.740855

Epoch: 91
Loss: 0.025387058229912152
ROC train: 1.000000	val: 0.910368	test: 0.689815
PRC train: 1.000000	val: 0.856346	test: 0.743032

Epoch: 92
Loss: 0.033117459600620326
ROC train: 1.000000	val: 0.900933	test: 0.706115
PRC train: 1.000000	val: 0.847929	test: 0.760988

Epoch: 93
Loss: 0.029261778811034422
ROC train: 0.997951	val: 0.910168	test: 0.672357
PRC train: 0.999602	val: 0.849891	test: 0.667979

Epoch: 95
Loss: 0.09289278272669407
ROC train: 0.996871	val: 0.908762	test: 0.682774
PRC train: 0.999407	val: 0.855570	test: 0.673035

Epoch: 96
Loss: 0.08967754234801366
ROC train: 0.994151	val: 0.893104	test: 0.665992
PRC train: 0.998828	val: 0.822594	test: 0.667562

Epoch: 97
Loss: 0.07817999672840989
ROC train: 0.997493	val: 0.894911	test: 0.655768
PRC train: 0.999518	val: 0.801011	test: 0.653422

Epoch: 98
Loss: 0.09149999945464825
ROC train: 0.997885	val: 0.909766	test: 0.692708
PRC train: 0.999587	val: 0.869771	test: 0.703824

Epoch: 99
Loss: 0.08267524372767092
ROC train: 0.996137	val: 0.906755	test: 0.677662
PRC train: 0.999241	val: 0.838018	test: 0.662984

Epoch: 100
Loss: 0.07967859517559091
ROC train: 0.997534	val: 0.908662	test: 0.692708
PRC train: 0.999518	val: 0.850479	test: 0.679989

Epoch: 101
Loss: 0.076219761111547
ROC train: 0.997534	val: 0.906655	test: 0.681713
PRC train: 0.999526	val: 0.850894	test: 0.691506

Epoch: 102
Loss: 0.07499755150179464
ROC train: 0.998261	val: 0.904145	test: 0.677373
PRC train: 0.999667	val: 0.852810	test: 0.684865

Epoch: 103
Loss: 0.0796558989634047
ROC train: 0.998582	val: 0.910669	test: 0.674190
PRC train: 0.999727	val: 0.867796	test: 0.673470

Epoch: 104
Loss: 0.08140405625760991
ROC train: 0.998505	val: 0.913781	test: 0.688850
PRC train: 0.999713	val: 0.873427	test: 0.689366

Epoch: 105
Loss: 0.07256603089011525
ROC train: 0.997196	val: 0.893205	test: 0.685860
PRC train: 0.999455	val: 0.852366	test: 0.687857

Epoch: 106
Loss: 0.08778449074149462
ROC train: 0.997261	val: 0.908662	test: 0.681231
PRC train: 0.999467	val: 0.858889	test: 0.684231

Epoch: 107
Loss: 0.0739011779220429
ROC train: 0.998740	val: 0.903844	test: 0.678337
PRC train: 0.999757	val: 0.837222	test: 0.687149

Epoch: 108
Loss: 0.07860335787215456
ROC train: 0.998587	val: 0.899629	test: 0.646316
PRC train: 0.999730	val: 0.823695	test: 0.648597

Epoch: 109
Loss: 0.0716369377432771
ROC train: 0.995847	val: 0.903643	test: 0.638696
PRC train: 0.999203	val: 0.846454	test: 0.629347

Epoch: 110
Loss: 0.06953615100766228
ROC train: 0.998286	val: 0.901435	test: 0.668403
PRC train: 0.999672	val: 0.859879	test: 0.665544

Epoch: 111
Loss: 0.06914640731941088
ROC train: 0.998969	val: 0.905751	test: 0.678819
PRC train: 0.999802	val: 0.863854	test: 0.675032

Epoch: 112
Loss: 0.06592024395535662
ROC train: 0.998696	val: 0.915387	test: 0.676601
PRC train: 0.999747	val: 0.871905	test: 0.659981

Epoch: 113
Loss: 0.06289628316003565
ROC train: 0.998861	val: 0.908963	test: 0.670332
PRC train: 0.999782	val: 0.860101	test: 0.661718

Epoch: 114
Loss: 0.07516651908223984
ROC train: 0.998882	val: 0.908762	test: 0.674672
PRC train: 0.999786	val: 0.848827	test: 0.671812

Epoch: 115
Loss: 0.08146865200530037
ROC train: 0.999200	val: 0.916591	test: 0.674576
PRC train: 0.999846	val: 0.862794	test: 0.678148

Epoch: 116
Loss: 0.06983903829897052
ROC train: 0.998868	val: 0.916792	test: 0.686053
PRC train: 0.999782	val: 0.872059	test: 0.701543

Epoch: 117
Loss: 0.06723386965931606
ROC train: 0.998853	val: 0.911974	test: 0.695023
PRC train: 0.999780	val: 0.862159	test: 0.694371

Epoch: 118
Loss: 0.08963942282372898
ROC train: 0.999135	val: 0.908662	test: 0.685667
PRC train: 0.999835	val: 0.850358	test: 0.685329

Epoch: 119
Loss: 0.06529587849903977
ROC train: 0.998122	val: 0.909766	test: 0.664545
PRC train: 0.999644	val: 0.868756	test: 0.678758

Epoch: 120
Loss: 0.07466670989670329
ROC train: 0.998454	val: 0.906855	test: 0.679688
PRC train: 0.999706	val: 0.851947	test: 0.675424

Early stopping
Best (ROC):	 train: 0.976400	val: 0.943491	test: 0.707851
Best (PRC):	 train: 0.994203	val: 0.930135	test: 0.752096

PRC train: 0.999609	val: 0.804555	test: 0.664875

Epoch: 95
Loss: 0.09628138312033319
ROC train: 0.997761	val: 0.904346	test: 0.691069
PRC train: 0.999573	val: 0.845428	test: 0.685343

Epoch: 96
Loss: 0.08214811946430219
ROC train: 0.998258	val: 0.891398	test: 0.674672
PRC train: 0.999667	val: 0.814151	test: 0.674290

Epoch: 97
Loss: 0.0860483105385047
ROC train: 0.998349	val: 0.893907	test: 0.673225
PRC train: 0.999683	val: 0.828752	test: 0.670450

Epoch: 98
Loss: 0.08696329672302375
ROC train: 0.998234	val: 0.897019	test: 0.688657
PRC train: 0.999661	val: 0.837382	test: 0.674829

Epoch: 99
Loss: 0.0776811556150223
ROC train: 0.997151	val: 0.896116	test: 0.678627
PRC train: 0.999455	val: 0.819609	test: 0.658717

Epoch: 100
Loss: 0.08735210102370503
ROC train: 0.998265	val: 0.904948	test: 0.674286
PRC train: 0.999669	val: 0.823317	test: 0.663218

Epoch: 101
Loss: 0.08258017399494466
ROC train: 0.997976	val: 0.901837	test: 0.671489
PRC train: 0.999615	val: 0.818687	test: 0.671468

Epoch: 102
Loss: 0.08884622851594466
ROC train: 0.997989	val: 0.892904	test: 0.679688
PRC train: 0.999617	val: 0.799664	test: 0.678951

Epoch: 103
Loss: 0.09072704380621069
ROC train: 0.997419	val: 0.893807	test: 0.678530
PRC train: 0.999505	val: 0.806913	test: 0.679191

Epoch: 104
Loss: 0.08345428791525555
ROC train: 0.998299	val: 0.894911	test: 0.704765
PRC train: 0.999672	val: 0.813682	test: 0.703671

Epoch: 105
Loss: 0.08485536096789167
ROC train: 0.998129	val: 0.908461	test: 0.692130
PRC train: 0.999640	val: 0.835449	test: 0.683280

Epoch: 106
Loss: 0.08183604992504487
ROC train: 0.997300	val: 0.894409	test: 0.667245
PRC train: 0.999471	val: 0.819393	test: 0.644710

Epoch: 107
Loss: 0.0823393359383269
ROC train: 0.998484	val: 0.881562	test: 0.677662
PRC train: 0.999706	val: 0.795081	test: 0.657321

Epoch: 108
Loss: 0.08496305622359375
ROC train: 0.998430	val: 0.897019	test: 0.681809
PRC train: 0.999700	val: 0.820058	test: 0.670859

Epoch: 109
Loss: 0.07278060139929032
ROC train: 0.998007	val: 0.906655	test: 0.679688
PRC train: 0.999622	val: 0.832929	test: 0.678670

Epoch: 110
Loss: 0.08526824102616233
ROC train: 0.998780	val: 0.887584	test: 0.678434
PRC train: 0.999767	val: 0.792092	test: 0.663270

Epoch: 111
Loss: 0.0928856186651511
ROC train: 0.998196	val: 0.887082	test: 0.685378
PRC train: 0.999653	val: 0.805597	test: 0.670985

Epoch: 112
Loss: 0.0905575363591004
ROC train: 0.998314	val: 0.895614	test: 0.683063
PRC train: 0.999678	val: 0.827176	test: 0.675770

Epoch: 113
Loss: 0.07729881029644704
ROC train: 0.997827	val: 0.892502	test: 0.682677
PRC train: 0.999589	val: 0.815732	test: 0.677626

Epoch: 114
Loss: 0.08445858558311167
ROC train: 0.997728	val: 0.899829	test: 0.694637
PRC train: 0.999565	val: 0.821173	test: 0.679553

Epoch: 115
Loss: 0.07266482204563618
ROC train: 0.996802	val: 0.888186	test: 0.709780
PRC train: 0.999384	val: 0.818887	test: 0.707333

Epoch: 116
Loss: 0.08891943660588285
ROC train: 0.998527	val: 0.900632	test: 0.655189
PRC train: 0.999717	val: 0.844390	test: 0.658831

Epoch: 117
Loss: 0.07097866483943335
ROC train: 0.998296	val: 0.900030	test: 0.649884
PRC train: 0.999676	val: 0.845432	test: 0.660979

Epoch: 118
Loss: 0.07081552262184324
ROC train: 0.998809	val: 0.897822	test: 0.670235
PRC train: 0.999773	val: 0.834009	test: 0.670070

Epoch: 119
Loss: 0.06691045737511181
ROC train: 0.998404	val: 0.893707	test: 0.670332
PRC train: 0.999695	val: 0.810665	test: 0.658683

Epoch: 120
Loss: 0.06815503625117994
ROC train: 0.998637	val: 0.893707	test: 0.654128
PRC train: 0.999741	val: 0.816871	test: 0.649110

Early stopping
Best (ROC):	 train: 0.972470	val: 0.934457	test: 0.711709
Best (PRC):	 train: 0.993769	val: 0.913320	test: 0.764648

ROC train: 0.998254	val: 0.879956	test: 0.693383
PRC train: 0.999668	val: 0.784776	test: 0.703037

Epoch: 95
Loss: 0.09067740314964574
ROC train: 0.998213	val: 0.898324	test: 0.676698
PRC train: 0.999661	val: 0.821804	test: 0.684656

Epoch: 96
Loss: 0.08188307483288872
ROC train: 0.998056	val: 0.897320	test: 0.700907
PRC train: 0.999625	val: 0.808952	test: 0.715673

Epoch: 97
Loss: 0.08572380969453686
ROC train: 0.997498	val: 0.889190	test: 0.698881
PRC train: 0.999516	val: 0.805883	test: 0.708383

Epoch: 98
Loss: 0.08834661185059489
ROC train: 0.998140	val: 0.888588	test: 0.675347
PRC train: 0.999642	val: 0.791585	test: 0.682723

Epoch: 99
Loss: 0.08436038839768727
ROC train: 0.998433	val: 0.889090	test: 0.680363
PRC train: 0.999699	val: 0.797289	test: 0.667176

Epoch: 100
Loss: 0.08978191925655346
ROC train: 0.998172	val: 0.888588	test: 0.664738
PRC train: 0.999649	val: 0.804540	test: 0.656872

Epoch: 101
Loss: 0.07991108887246368
ROC train: 0.997817	val: 0.882967	test: 0.667824
PRC train: 0.999582	val: 0.792567	test: 0.660809

Epoch: 102
Loss: 0.0835868581609538
ROC train: 0.997788	val: 0.893807	test: 0.688079
PRC train: 0.999575	val: 0.793880	test: 0.669283

Epoch: 103
Loss: 0.09123671654717347
ROC train: 0.999018	val: 0.873331	test: 0.682677
PRC train: 0.999814	val: 0.774462	test: 0.677673

Epoch: 104
Loss: 0.08030521790389714
ROC train: 0.998467	val: 0.889391	test: 0.669753
PRC train: 0.999708	val: 0.829924	test: 0.674265

Epoch: 105
Loss: 0.08323291208556026
ROC train: 0.998276	val: 0.888186	test: 0.663580
PRC train: 0.999671	val: 0.817484	test: 0.659193

Epoch: 106
Loss: 0.0774034365744857
ROC train: 0.998482	val: 0.877246	test: 0.679688
PRC train: 0.999714	val: 0.773165	test: 0.681604

Epoch: 107
Loss: 0.07511260759898566
ROC train: 0.998116	val: 0.893807	test: 0.685571
PRC train: 0.999647	val: 0.782851	test: 0.685733

Epoch: 108
Loss: 0.07802810569561976
ROC train: 0.998984	val: 0.878049	test: 0.681327
PRC train: 0.999807	val: 0.766329	test: 0.676582

Epoch: 109
Loss: 0.076453990636471
ROC train: 0.998299	val: 0.875238	test: 0.650367
PRC train: 0.999674	val: 0.777150	test: 0.645854

Epoch: 110
Loss: 0.07958114115768312
ROC train: 0.998725	val: 0.896015	test: 0.677566
PRC train: 0.999756	val: 0.819610	test: 0.660144

Epoch: 111
Loss: 0.07981287559249205
ROC train: 0.998167	val: 0.870421	test: 0.666763
PRC train: 0.999652	val: 0.782810	test: 0.671651

Epoch: 112
Loss: 0.08177359159531321
ROC train: 0.999104	val: 0.875941	test: 0.663291
PRC train: 0.999829	val: 0.775281	test: 0.663209

Epoch: 113
Loss: 0.06655203706653781
ROC train: 0.998812	val: 0.878952	test: 0.675926
PRC train: 0.999772	val: 0.766069	test: 0.669116

Epoch: 114
Loss: 0.07122867920308215
ROC train: 0.998886	val: 0.866606	test: 0.681906
PRC train: 0.999786	val: 0.755068	test: 0.680398

Epoch: 115
Loss: 0.06918267407966967
ROC train: 0.999101	val: 0.868915	test: 0.673418
PRC train: 0.999829	val: 0.760703	test: 0.671469

Epoch: 116
Loss: 0.0805038668684069
ROC train: 0.999101	val: 0.889190	test: 0.684510
PRC train: 0.999830	val: 0.800904	test: 0.680902

Epoch: 117
Loss: 0.08303169643609631
ROC train: 0.998137	val: 0.886982	test: 0.676408
PRC train: 0.999647	val: 0.797550	test: 0.678322

Epoch: 118
Loss: 0.07298796451433638
ROC train: 0.998054	val: 0.905751	test: 0.693094
PRC train: 0.999630	val: 0.836906	test: 0.692433

Epoch: 119
Loss: 0.07804157974117076
ROC train: 0.998941	val: 0.896116	test: 0.702836
PRC train: 0.999798	val: 0.800630	test: 0.690114

Epoch: 120
Loss: 0.07596297519558881
ROC train: 0.998982	val: 0.882967	test: 0.679495
PRC train: 0.999804	val: 0.766649	test: 0.666636

Early stopping
Best (ROC):	 train: 0.954256	val: 0.936164	test: 0.695312
Best (PRC):	 train: 0.987998	val: 0.909330	test: 0.732552
All runs completed.

PRC train: 0.999966	val: 0.788082	test: 0.699974

Epoch: 94
Loss: 0.0352765082817927
ROC train: 0.999986	val: 0.893506	test: 0.656346
PRC train: 0.999997	val: 0.805315	test: 0.711011

Epoch: 95
Loss: 0.03361948361310377
ROC train: 1.000000	val: 0.906755	test: 0.676987
PRC train: 1.000000	val: 0.856799	test: 0.737243

Epoch: 96
Loss: 0.027038776962407692
ROC train: 0.999983	val: 0.908361	test: 0.671296
PRC train: 0.999997	val: 0.850892	test: 0.734939

Epoch: 97
Loss: 0.05301471823513616
ROC train: 1.000000	val: 0.879755	test: 0.647762
PRC train: 1.000000	val: 0.821068	test: 0.709644

Epoch: 98
Loss: 0.04338471328924818
ROC train: 1.000000	val: 0.897420	test: 0.662133
PRC train: 1.000000	val: 0.848359	test: 0.710996

Epoch: 99
Loss: 0.029964559823712933
ROC train: 0.999989	val: 0.912777	test: 0.680941
PRC train: 0.999998	val: 0.865416	test: 0.736468

Epoch: 100
Loss: 0.037019081669867435
ROC train: 1.000000	val: 0.901636	test: 0.663870
PRC train: 1.000000	val: 0.849671	test: 0.709904

Epoch: 101
Loss: 0.035575826243709203
ROC train: 0.999997	val: 0.895513	test: 0.650077
PRC train: 0.999999	val: 0.846005	test: 0.680948

Epoch: 102
Loss: 0.03360984106733261
ROC train: 1.000000	val: 0.909365	test: 0.674576
PRC train: 1.000000	val: 0.859491	test: 0.724815

Epoch: 103
Loss: 0.02793090408708797
ROC train: 0.999983	val: 0.904346	test: 0.681134
PRC train: 0.999997	val: 0.846392	test: 0.743842

Epoch: 104
Loss: 0.05747707738339277
ROC train: 1.000000	val: 0.880658	test: 0.642554
PRC train: 1.000000	val: 0.808605	test: 0.696050

Epoch: 105
Loss: 0.03781479978000775
ROC train: 0.999986	val: 0.891398	test: 0.676408
PRC train: 0.999997	val: 0.809617	test: 0.720012

Epoch: 106
Loss: 0.027779861745174567
ROC train: 0.999902	val: 0.905249	test: 0.685571
PRC train: 0.999981	val: 0.842130	test: 0.710507

Epoch: 107
Loss: 0.04847621022903903
ROC train: 0.999840	val: 0.859882	test: 0.656250
PRC train: 0.999970	val: 0.787363	test: 0.692795

Epoch: 108
Loss: 0.04832364592017353
ROC train: 0.999938	val: 0.892904	test: 0.685571
PRC train: 0.999988	val: 0.827513	test: 0.743405

Epoch: 109
Loss: 0.032471676670627204
ROC train: 0.999950	val: 0.889491	test: 0.648534
PRC train: 0.999991	val: 0.824533	test: 0.701719

Epoch: 110
Loss: 0.026340347696610616
ROC train: 1.000000	val: 0.902640	test: 0.670332
PRC train: 1.000000	val: 0.856155	test: 0.715870

Epoch: 111
Loss: 0.03136182338192639
ROC train: 1.000000	val: 0.913380	test: 0.680748
PRC train: 1.000000	val: 0.871187	test: 0.734018

Epoch: 112
Loss: 0.027994265872455577
ROC train: 0.999983	val: 0.891197	test: 0.639950
PRC train: 0.999997	val: 0.820716	test: 0.711734

Epoch: 113
Loss: 0.0325541773229797
ROC train: 1.000000	val: 0.893606	test: 0.663580
PRC train: 1.000000	val: 0.844811	test: 0.730708

Epoch: 114
Loss: 0.023473508289998248
ROC train: 1.000000	val: 0.891398	test: 0.657890
PRC train: 1.000000	val: 0.828138	test: 0.707656

Epoch: 115
Loss: 0.03236956635680882
ROC train: 1.000000	val: 0.899227	test: 0.660494
PRC train: 1.000000	val: 0.840610	test: 0.715402

Epoch: 116
Loss: 0.021948951196872696
ROC train: 1.000000	val: 0.870521	test: 0.667631
PRC train: 1.000000	val: 0.765428	test: 0.720974

Epoch: 117
Loss: 0.035342868824973325
ROC train: 0.999989	val: 0.884573	test: 0.657407
PRC train: 0.999998	val: 0.779098	test: 0.720750

Epoch: 118
Loss: 0.027315837947023105
ROC train: 1.000000	val: 0.898123	test: 0.676119
PRC train: 1.000000	val: 0.830625	test: 0.732751

Epoch: 119
Loss: 0.027061111165475105
ROC train: 1.000000	val: 0.892703	test: 0.685185
PRC train: 1.000000	val: 0.839713	test: 0.723092

Epoch: 120
Loss: 0.03506327591194659
ROC train: 1.000000	val: 0.890896	test: 0.682581
PRC train: 1.000000	val: 0.823316	test: 0.716926

Early stopping
Best (ROC):	 train: 0.998460	val: 0.926729	test: 0.673418
Best (PRC):	 train: 0.999708	val: 0.901218	test: 0.715878

PRC train: 0.999998	val: 0.791860	test: 0.670099

Epoch: 94
Loss: 0.03891636954205279
ROC train: 0.999989	val: 0.876844	test: 0.647473
PRC train: 0.999998	val: 0.741038	test: 0.662611

Epoch: 95
Loss: 0.045357650993838386
ROC train: 0.999997	val: 0.898525	test: 0.649306
PRC train: 0.999999	val: 0.798132	test: 0.660105

Epoch: 96
Loss: 0.03819422971235848
ROC train: 0.999989	val: 0.899930	test: 0.646894
PRC train: 0.999998	val: 0.833226	test: 0.659800

Epoch: 97
Loss: 0.04025848870296562
ROC train: 0.999815	val: 0.913881	test: 0.625386
PRC train: 0.999965	val: 0.853675	test: 0.661293

Epoch: 98
Loss: 0.045699188700709346
ROC train: 0.999978	val: 0.897220	test: 0.652006
PRC train: 0.999996	val: 0.829143	test: 0.672397

Epoch: 99
Loss: 0.03972787027502143
ROC train: 0.999983	val: 0.890696	test: 0.674769
PRC train: 0.999997	val: 0.798341	test: 0.674908

Epoch: 100
Loss: 0.052875298364816074
ROC train: 0.999992	val: 0.903142	test: 0.657118
PRC train: 0.999998	val: 0.789914	test: 0.670108

Epoch: 101
Loss: 0.044994116894179925
ROC train: 1.000000	val: 0.896015	test: 0.619020
PRC train: 1.000000	val: 0.804526	test: 0.647802

Epoch: 102
Loss: 0.03368412407837922
ROC train: 0.999972	val: 0.894409	test: 0.635127
PRC train: 0.999995	val: 0.810685	test: 0.651832

Epoch: 103
Loss: 0.040528529011484675
ROC train: 0.999986	val: 0.910168	test: 0.654321
PRC train: 0.999997	val: 0.834410	test: 0.683958

Epoch: 104
Loss: 0.042337991106361286
ROC train: 1.000000	val: 0.912275	test: 0.650559
PRC train: 1.000000	val: 0.808013	test: 0.658873

Epoch: 105
Loss: 0.021366220983776225
ROC train: 1.000000	val: 0.910268	test: 0.646798
PRC train: 1.000000	val: 0.801778	test: 0.636972

Epoch: 106
Loss: 0.03128259032143118
ROC train: 1.000000	val: 0.903945	test: 0.644772
PRC train: 1.000000	val: 0.813353	test: 0.657154

Epoch: 107
Loss: 0.0418183565722536
ROC train: 0.999935	val: 0.898223	test: 0.643615
PRC train: 0.999988	val: 0.795156	test: 0.661705

Epoch: 108
Loss: 0.03807019965668239
ROC train: 0.999972	val: 0.886480	test: 0.650656
PRC train: 0.999995	val: 0.781399	test: 0.687094

Epoch: 109
Loss: 0.048699518010991004
ROC train: 0.999961	val: 0.859580	test: 0.628472
PRC train: 0.999993	val: 0.720439	test: 0.637135

Epoch: 110
Loss: 0.042721318190725964
ROC train: 0.999992	val: 0.881863	test: 0.642168
PRC train: 0.999998	val: 0.761470	test: 0.635066

Epoch: 111
Loss: 0.037986726956078
ROC train: 0.999961	val: 0.887183	test: 0.641300
PRC train: 0.999993	val: 0.802331	test: 0.648246

Epoch: 112
Loss: 0.03200498478171015
ROC train: 0.999986	val: 0.882867	test: 0.625965
PRC train: 0.999997	val: 0.800311	test: 0.629242

Epoch: 113
Loss: 0.04511538129105802
ROC train: 1.000000	val: 0.897521	test: 0.636285
PRC train: 1.000000	val: 0.848715	test: 0.671557

Epoch: 114
Loss: 0.033276726576436676
ROC train: 0.999868	val: 0.889591	test: 0.631848
PRC train: 0.999975	val: 0.824733	test: 0.647997

Epoch: 115
Loss: 0.04534348046144713
ROC train: 0.999997	val: 0.901335	test: 0.628086
PRC train: 0.999999	val: 0.838794	test: 0.670103

Epoch: 116
Loss: 0.04073967520875359
ROC train: 0.999644	val: 0.891699	test: 0.635610
PRC train: 0.999935	val: 0.817746	test: 0.686986

Epoch: 117
Loss: 0.042494383824331926
ROC train: 0.999997	val: 0.873532	test: 0.637924
PRC train: 0.999999	val: 0.754039	test: 0.674503

Epoch: 118
Loss: 0.030333197233884463
ROC train: 0.999997	val: 0.867711	test: 0.643904
PRC train: 0.999999	val: 0.746803	test: 0.673825

Epoch: 119
Loss: 0.03648190009373081
ROC train: 0.999944	val: 0.868012	test: 0.606674
PRC train: 0.999989	val: 0.745912	test: 0.635719

Epoch: 120
Loss: 0.045218390968129754
ROC train: 1.000000	val: 0.892101	test: 0.629244
PRC train: 1.000000	val: 0.790811	test: 0.639653

Early stopping
Best (ROC):	 train: 0.999851	val: 0.924420	test: 0.658275
Best (PRC):	 train: 0.999972	val: 0.854527	test: 0.696119

PRC train: 0.999997	val: 0.832247	test: 0.653655

Epoch: 94
Loss: 0.035401164493166944
ROC train: 0.999947	val: 0.909264	test: 0.669560
PRC train: 0.999990	val: 0.858872	test: 0.680568

Epoch: 95
Loss: 0.028438953468382884
ROC train: 0.999972	val: 0.901937	test: 0.654610
PRC train: 0.999995	val: 0.843065	test: 0.652192

Epoch: 96
Loss: 0.03338669930829137
ROC train: 0.999997	val: 0.890696	test: 0.639660
PRC train: 0.999999	val: 0.824510	test: 0.629436

Epoch: 97
Loss: 0.028678117868193763
ROC train: 1.000000	val: 0.893305	test: 0.647859
PRC train: 1.000000	val: 0.839264	test: 0.643001

Epoch: 98
Loss: 0.030676865325675175
ROC train: 0.999997	val: 0.904547	test: 0.663773
PRC train: 0.999999	val: 0.858078	test: 0.662110

Epoch: 99
Loss: 0.03615970246747202
ROC train: 0.999997	val: 0.886982	test: 0.657890
PRC train: 0.999999	val: 0.834770	test: 0.651290

Epoch: 100
Loss: 0.046086834380751784
ROC train: 1.000000	val: 0.889993	test: 0.657986
PRC train: 1.000000	val: 0.835584	test: 0.660912

Epoch: 101
Loss: 0.036984866938256464
ROC train: 0.999997	val: 0.898926	test: 0.675444
PRC train: 0.999999	val: 0.840674	test: 0.686299

Epoch: 102
Loss: 0.028866447300057163
ROC train: 0.999992	val: 0.905350	test: 0.634163
PRC train: 0.999998	val: 0.840377	test: 0.638880

Epoch: 103
Loss: 0.033549116342809056
ROC train: 0.999997	val: 0.892803	test: 0.638600
PRC train: 0.999999	val: 0.812482	test: 0.646495

Epoch: 104
Loss: 0.02182636703224238
ROC train: 0.999997	val: 0.885476	test: 0.629533
PRC train: 0.999999	val: 0.788055	test: 0.636559

Epoch: 105
Loss: 0.033925064835251185
ROC train: 1.000000	val: 0.889491	test: 0.639468
PRC train: 1.000000	val: 0.818084	test: 0.628228

Epoch: 106
Loss: 0.032597007355902353
ROC train: 1.000000	val: 0.895614	test: 0.657215
PRC train: 1.000000	val: 0.825820	test: 0.645398

Epoch: 107
Loss: 0.03318720433030291
ROC train: 0.999994	val: 0.896718	test: 0.661748
PRC train: 0.999999	val: 0.835321	test: 0.660665

Epoch: 108
Loss: 0.030228296468320873
ROC train: 0.999986	val: 0.895513	test: 0.657215
PRC train: 0.999997	val: 0.815555	test: 0.661912

Epoch: 109
Loss: 0.033776166093436845
ROC train: 0.999978	val: 0.895815	test: 0.642361
PRC train: 0.999996	val: 0.809563	test: 0.637476

Epoch: 110
Loss: 0.021085264483024307
ROC train: 0.999461	val: 0.897420	test: 0.642361
PRC train: 0.999890	val: 0.825775	test: 0.622060

Epoch: 111
Loss: 0.04824626030451383
ROC train: 1.000000	val: 0.894610	test: 0.651717
PRC train: 1.000000	val: 0.817157	test: 0.648574

Epoch: 112
Loss: 0.049650500180979565
ROC train: 1.000000	val: 0.891699	test: 0.659144
PRC train: 1.000000	val: 0.823429	test: 0.666192

Epoch: 113
Loss: 0.042505433242548074
ROC train: 0.996956	val: 0.909365	test: 0.636960
PRC train: 0.999069	val: 0.858276	test: 0.628179

Epoch: 114
Loss: 0.04872022160643574
ROC train: 0.999661	val: 0.878551	test: 0.641397
PRC train: 0.999938	val: 0.836772	test: 0.652993

Epoch: 115
Loss: 0.0305593797769683
ROC train: 0.999470	val: 0.882867	test: 0.668210
PRC train: 0.999899	val: 0.851081	test: 0.693226

Epoch: 116
Loss: 0.041756028209076944
ROC train: 0.998522	val: 0.880157	test: 0.629726
PRC train: 0.999685	val: 0.818362	test: 0.654104

Epoch: 117
Loss: 0.04638425524738649
ROC train: 0.999997	val: 0.882264	test: 0.646316
PRC train: 0.999999	val: 0.823404	test: 0.674543

Epoch: 118
Loss: 0.029444561300790234
ROC train: 0.999994	val: 0.904647	test: 0.670718
PRC train: 0.999999	val: 0.863365	test: 0.690631

Epoch: 119
Loss: 0.03319808953977664
ROC train: 0.999992	val: 0.901435	test: 0.673418
PRC train: 0.999998	val: 0.853404	test: 0.704140

Epoch: 120
Loss: 0.022917522772397884
ROC train: 0.999997	val: 0.889391	test: 0.673225
PRC train: 0.999999	val: 0.838180	test: 0.688578

Early stopping
Best (ROC):	 train: 0.957182	val: 0.921510	test: 0.678048
Best (PRC):	 train: 0.990136	val: 0.880595	test: 0.736179

PRC train: 0.999999	val: 0.797472	test: 0.712375

Epoch: 94
Loss: 0.04364669395424598
ROC train: 1.000000	val: 0.891900	test: 0.701775
PRC train: 1.000000	val: 0.823841	test: 0.736290

Epoch: 95
Loss: 0.02418998681078816
ROC train: 1.000000	val: 0.898424	test: 0.680170
PRC train: 1.000000	val: 0.829076	test: 0.700290

Epoch: 96
Loss: 0.027006618264646957
ROC train: 1.000000	val: 0.900432	test: 0.684124
PRC train: 1.000000	val: 0.843683	test: 0.717470

Epoch: 97
Loss: 0.040355112862689335
ROC train: 1.000000	val: 0.898625	test: 0.691069
PRC train: 1.000000	val: 0.841549	test: 0.716766

Epoch: 98
Loss: 0.03806411924788548
ROC train: 1.000000	val: 0.873331	test: 0.688850
PRC train: 1.000000	val: 0.779957	test: 0.687154

Epoch: 99
Loss: 0.03688038002601944
ROC train: 1.000000	val: 0.862993	test: 0.686439
PRC train: 1.000000	val: 0.757797	test: 0.694609

Epoch: 100
Loss: 0.030934148854065653
ROC train: 1.000000	val: 0.893104	test: 0.686825
PRC train: 1.000000	val: 0.815230	test: 0.699605

Epoch: 101
Loss: 0.03244717046561708
ROC train: 1.000000	val: 0.878751	test: 0.682099
PRC train: 1.000000	val: 0.798649	test: 0.688439

Epoch: 102
Loss: 0.024198019927233964
ROC train: 1.000000	val: 0.885376	test: 0.696663
PRC train: 1.000000	val: 0.810178	test: 0.702982

Epoch: 103
Loss: 0.023594784210694216
ROC train: 1.000000	val: 0.903945	test: 0.680266
PRC train: 1.000000	val: 0.837791	test: 0.687722

Epoch: 104
Loss: 0.03162651509451502
ROC train: 1.000000	val: 0.893506	test: 0.681038
PRC train: 1.000000	val: 0.816201	test: 0.683765

Epoch: 105
Loss: 0.018765455497477435
ROC train: 1.000000	val: 0.878852	test: 0.687789
PRC train: 1.000000	val: 0.786701	test: 0.687060

Epoch: 106
Loss: 0.025537059540855833
ROC train: 1.000000	val: 0.882565	test: 0.676601
PRC train: 1.000000	val: 0.806416	test: 0.681217

Epoch: 107
Loss: 0.0313327772030571
ROC train: 1.000000	val: 0.883770	test: 0.668113
PRC train: 1.000000	val: 0.806794	test: 0.673727

Epoch: 108
Loss: 0.031604394739642105
ROC train: 1.000000	val: 0.869216	test: 0.669753
PRC train: 1.000000	val: 0.787797	test: 0.670222

Epoch: 109
Loss: 0.03156953231537566
ROC train: 1.000000	val: 0.873532	test: 0.689140
PRC train: 1.000000	val: 0.811047	test: 0.709588

Epoch: 110
Loss: 0.02123710197259155
ROC train: 1.000000	val: 0.883971	test: 0.692612
PRC train: 1.000000	val: 0.814357	test: 0.716738

Epoch: 111
Loss: 0.037984468896296676
ROC train: 1.000000	val: 0.879855	test: 0.692805
PRC train: 1.000000	val: 0.808397	test: 0.703653

Epoch: 112
Loss: 0.033942162919780874
ROC train: 1.000000	val: 0.882867	test: 0.686246
PRC train: 1.000000	val: 0.823335	test: 0.695781

Epoch: 113
Loss: 0.02595804100892354
ROC train: 1.000000	val: 0.869618	test: 0.684606
PRC train: 1.000000	val: 0.816228	test: 0.703531

Epoch: 114
Loss: 0.020560767665960076
ROC train: 1.000000	val: 0.888186	test: 0.675251
PRC train: 1.000000	val: 0.820140	test: 0.680270

Epoch: 115
Loss: 0.03250051044991171
ROC train: 1.000000	val: 0.897019	test: 0.686825
PRC train: 1.000000	val: 0.825765	test: 0.695152

Epoch: 116
Loss: 0.025365483080348163
ROC train: 0.999994	val: 0.879855	test: 0.679688
PRC train: 0.999999	val: 0.822086	test: 0.700513

Epoch: 117
Loss: 0.026806736230007316
ROC train: 0.999986	val: 0.892201	test: 0.686343
PRC train: 0.999997	val: 0.836701	test: 0.711400

Epoch: 118
Loss: 0.026191985931025136
ROC train: 1.000000	val: 0.889792	test: 0.692515
PRC train: 1.000000	val: 0.818322	test: 0.704311

Epoch: 119
Loss: 0.026176619851671374
ROC train: 1.000000	val: 0.882264	test: 0.679784
PRC train: 1.000000	val: 0.798655	test: 0.676279

Epoch: 120
Loss: 0.025253250547914358
ROC train: 1.000000	val: 0.874134	test: 0.687500
PRC train: 1.000000	val: 0.797076	test: 0.699420

Early stopping
Best (ROC):	 train: 0.937654	val: 0.913781	test: 0.655575
Best (PRC):	 train: 0.985837	val: 0.822134	test: 0.674449

ROC train: 1.000000	val: 0.853759	test: 0.626157
PRC train: 1.000000	val: 0.755158	test: 0.651569

Epoch: 94
Loss: 0.019310821388463118
ROC train: 1.000000	val: 0.871023	test: 0.628762
PRC train: 1.000000	val: 0.780966	test: 0.647545

Epoch: 95
Loss: 0.028213506768350077
ROC train: 1.000000	val: 0.873833	test: 0.619695
PRC train: 1.000000	val: 0.787824	test: 0.651010

Epoch: 96
Loss: 0.03757368054627155
ROC train: 1.000000	val: 0.841012	test: 0.618345
PRC train: 1.000000	val: 0.721870	test: 0.641096

Epoch: 97
Loss: 0.029222701701849287
ROC train: 1.000000	val: 0.838603	test: 0.627604
PRC train: 1.000000	val: 0.736631	test: 0.654902

Epoch: 98
Loss: 0.03999864676044851
ROC train: 0.999837	val: 0.855867	test: 0.643036
PRC train: 0.999969	val: 0.766767	test: 0.671611

Epoch: 99
Loss: 0.032747170496219925
ROC train: 0.999994	val: 0.820937	test: 0.616609
PRC train: 0.999999	val: 0.671791	test: 0.627908

Epoch: 100
Loss: 0.0326968548561097
ROC train: 1.000000	val: 0.839807	test: 0.607060
PRC train: 1.000000	val: 0.750401	test: 0.653232

Epoch: 101
Loss: 0.02645585191822664
ROC train: 1.000000	val: 0.870922	test: 0.624711
PRC train: 1.000000	val: 0.795978	test: 0.678267

Epoch: 102
Loss: 0.03708058992434478
ROC train: 1.000000	val: 0.853257	test: 0.605710
PRC train: 1.000000	val: 0.775858	test: 0.663688

Epoch: 103
Loss: 0.026248487474550494
ROC train: 1.000000	val: 0.840008	test: 0.588735
PRC train: 1.000000	val: 0.754415	test: 0.635949

Epoch: 104
Loss: 0.026832715778869743
ROC train: 1.000000	val: 0.850346	test: 0.586034
PRC train: 1.000000	val: 0.760402	test: 0.619846

Epoch: 105
Loss: 0.02763504670867134
ROC train: 1.000000	val: 0.826458	test: 0.593846
PRC train: 1.000000	val: 0.710849	test: 0.615184

Epoch: 106
Loss: 0.028762518349875026
ROC train: 1.000000	val: 0.824551	test: 0.588638
PRC train: 1.000000	val: 0.736058	test: 0.626382

Epoch: 107
Loss: 0.022349111532888728
ROC train: 1.000000	val: 0.853960	test: 0.591917
PRC train: 1.000000	val: 0.768730	test: 0.617356

Epoch: 108
Loss: 0.02190965269218121
ROC train: 1.000000	val: 0.866506	test: 0.617959
PRC train: 1.000000	val: 0.767966	test: 0.656630

Epoch: 109
Loss: 0.022446618579475212
ROC train: 1.000000	val: 0.862893	test: 0.623939
PRC train: 1.000000	val: 0.769470	test: 0.680359

Epoch: 110
Loss: 0.02379936223963059
ROC train: 1.000000	val: 0.880458	test: 0.633681
PRC train: 1.000000	val: 0.830825	test: 0.697873

Epoch: 111
Loss: 0.02236175762488435
ROC train: 1.000000	val: 0.877346	test: 0.619117
PRC train: 1.000000	val: 0.823867	test: 0.681504

Epoch: 112
Loss: 0.01888389298410258
ROC train: 1.000000	val: 0.865803	test: 0.613329
PRC train: 1.000000	val: 0.804358	test: 0.668211

Epoch: 113
Loss: 0.028663111090218553
ROC train: 1.000000	val: 0.827863	test: 0.598958
PRC train: 1.000000	val: 0.740702	test: 0.638730

Epoch: 114
Loss: 0.02515004443386584
ROC train: 1.000000	val: 0.871424	test: 0.613619
PRC train: 1.000000	val: 0.791406	test: 0.683896

Epoch: 115
Loss: 0.018162092571888753
ROC train: 1.000000	val: 0.882064	test: 0.605806
PRC train: 1.000000	val: 0.794722	test: 0.668759

Epoch: 116
Loss: 0.022684650172538134
ROC train: 1.000000	val: 0.851350	test: 0.597512
PRC train: 1.000000	val: 0.752010	test: 0.629740

Epoch: 117
Loss: 0.019731770342223953
ROC train: 1.000000	val: 0.856971	test: 0.616995
PRC train: 1.000000	val: 0.763249	test: 0.650590

Epoch: 118
Loss: 0.018055927715664825
ROC train: 1.000000	val: 0.872127	test: 0.644579
PRC train: 1.000000	val: 0.801024	test: 0.712244

Epoch: 119
Loss: 0.018868716732534905
ROC train: 1.000000	val: 0.872428	test: 0.641204
PRC train: 1.000000	val: 0.804085	test: 0.704946

Epoch: 120
Loss: 0.018445036568329794
ROC train: 1.000000	val: 0.875238	test: 0.638407
PRC train: 1.000000	val: 0.798364	test: 0.682857

Early stopping
Best (ROC):	 train: 0.954169	val: 0.914584	test: 0.625000
Best (PRC):	 train: 0.989105	val: 0.833525	test: 0.643059

ROC train: 1.000000	val: 0.782294	test: 0.640432
PRC train: 1.000000	val: 0.686506	test: 0.644825

Epoch: 94
Loss: 0.035999104680868865
ROC train: 1.000000	val: 0.765834	test: 0.644869
PRC train: 1.000000	val: 0.671314	test: 0.635748

Epoch: 95
Loss: 0.030728164729669504
ROC train: 1.000000	val: 0.811904	test: 0.630787
PRC train: 1.000000	val: 0.731747	test: 0.624787

Epoch: 96
Loss: 0.028379491667238823
ROC train: 0.999961	val: 0.829569	test: 0.640046
PRC train: 0.999993	val: 0.779127	test: 0.629434

Epoch: 97
Loss: 0.03193146323762861
ROC train: 1.000000	val: 0.809596	test: 0.641107
PRC train: 1.000000	val: 0.721848	test: 0.637785

Epoch: 98
Loss: 0.04131778849867934
ROC train: 1.000000	val: 0.787413	test: 0.621721
PRC train: 1.000000	val: 0.688919	test: 0.610969

Epoch: 99
Loss: 0.0348215427447999
ROC train: 0.999916	val: 0.833484	test: 0.644869
PRC train: 0.999984	val: 0.731659	test: 0.654956

Epoch: 100
Loss: 0.03716287768159682
ROC train: 1.000000	val: 0.840410	test: 0.642747
PRC train: 1.000000	val: 0.741408	test: 0.649833

Epoch: 101
Loss: 0.030130192958514733
ROC train: 0.999992	val: 0.827562	test: 0.651331
PRC train: 0.999998	val: 0.725108	test: 0.670388

Epoch: 102
Loss: 0.04002891157673479
ROC train: 1.000000	val: 0.831376	test: 0.636960
PRC train: 1.000000	val: 0.732299	test: 0.654173

Epoch: 103
Loss: 0.033907042819901735
ROC train: 1.000000	val: 0.831376	test: 0.629533
PRC train: 1.000000	val: 0.760740	test: 0.632714

Epoch: 104
Loss: 0.03467410460292474
ROC train: 1.000000	val: 0.805179	test: 0.588445
PRC train: 1.000000	val: 0.752885	test: 0.596508

Epoch: 105
Loss: 0.04813665471117275
ROC train: 1.000000	val: 0.804477	test: 0.632234
PRC train: 1.000000	val: 0.718563	test: 0.630138

Epoch: 106
Loss: 0.04485041028755781
ROC train: 0.999994	val: 0.817023	test: 0.641397
PRC train: 0.999999	val: 0.737533	test: 0.639096

Epoch: 107
Loss: 0.040155961470038096
ROC train: 0.999989	val: 0.809997	test: 0.617670
PRC train: 0.999998	val: 0.727547	test: 0.628763

Epoch: 108
Loss: 0.04572262367416626
ROC train: 1.000000	val: 0.801767	test: 0.631655
PRC train: 1.000000	val: 0.697341	test: 0.645825

Epoch: 109
Loss: 0.026456291174488784
ROC train: 1.000000	val: 0.793737	test: 0.626350
PRC train: 1.000000	val: 0.707439	test: 0.623222

Epoch: 110
Loss: 0.02337651367499526
ROC train: 1.000000	val: 0.833183	test: 0.622203
PRC train: 1.000000	val: 0.769639	test: 0.618765

Epoch: 111
Loss: 0.020913790688478973
ROC train: 1.000000	val: 0.833082	test: 0.649595
PRC train: 1.000000	val: 0.742652	test: 0.658591

Epoch: 112
Loss: 0.026139083405271664
ROC train: 1.000000	val: 0.807990	test: 0.658565
PRC train: 1.000000	val: 0.706947	test: 0.671526

Epoch: 113
Loss: 0.021796654328970398
ROC train: 1.000000	val: 0.815016	test: 0.665027
PRC train: 1.000000	val: 0.716395	test: 0.686321

Epoch: 114
Loss: 0.025986200521126362
ROC train: 1.000000	val: 0.799659	test: 0.647762
PRC train: 1.000000	val: 0.693918	test: 0.655690

Epoch: 115
Loss: 0.03677611927351699
ROC train: 1.000000	val: 0.820937	test: 0.624132
PRC train: 1.000000	val: 0.726231	test: 0.618562

Epoch: 116
Loss: 0.027235869986540633
ROC train: 1.000000	val: 0.839205	test: 0.608796
PRC train: 1.000000	val: 0.777591	test: 0.599679

Epoch: 117
Loss: 0.020980520738043604
ROC train: 1.000000	val: 0.794239	test: 0.605324
PRC train: 1.000000	val: 0.726289	test: 0.587169

Epoch: 118
Loss: 0.018707602958350132
ROC train: 1.000000	val: 0.768845	test: 0.596354
PRC train: 1.000000	val: 0.677332	test: 0.595569

Epoch: 119
Loss: 0.033377573039885575
ROC train: 1.000000	val: 0.787815	test: 0.597897
PRC train: 1.000000	val: 0.693710	test: 0.596930

Epoch: 120
Loss: 0.015981449059869614
ROC train: 0.999978	val: 0.773261	test: 0.584394
PRC train: 0.999996	val: 0.683037	test: 0.588026

Early stopping
Best (ROC):	 train: 0.792717	val: 0.900532	test: 0.601852
Best (PRC):	 train: 0.942921	val: 0.839156	test: 0.647418
All runs completed.

ROC train: 1.000000	val: 0.917194	test: 0.608314
PRC train: 1.000000	val: 0.835828	test: 0.669784

Epoch: 94
Loss: 0.030881631839456504
ROC train: 1.000000	val: 0.901736	test: 0.601755
PRC train: 1.000000	val: 0.811040	test: 0.649970

Epoch: 95
Loss: 0.03510292736618273
ROC train: 1.000000	val: 0.927632	test: 0.648052
PRC train: 1.000000	val: 0.878974	test: 0.716410

Epoch: 96
Loss: 0.029554039490392984
ROC train: 1.000000	val: 0.930041	test: 0.660976
PRC train: 1.000000	val: 0.896085	test: 0.743556

Epoch: 97
Loss: 0.04279696438777346
ROC train: 1.000000	val: 0.928234	test: 0.670621
PRC train: 1.000000	val: 0.883482	test: 0.748480

Epoch: 98
Loss: 0.023616928876980654
ROC train: 1.000000	val: 0.931145	test: 0.668210
PRC train: 1.000000	val: 0.885603	test: 0.736283

Epoch: 99
Loss: 0.028597388444759297
ROC train: 1.000000	val: 0.932952	test: 0.656732
PRC train: 1.000000	val: 0.888596	test: 0.727493

Epoch: 100
Loss: 0.023648832544355798
ROC train: 0.999947	val: 0.928736	test: 0.666281
PRC train: 0.999990	val: 0.874976	test: 0.724658

Epoch: 101
Loss: 0.027770583763557538
ROC train: 1.000000	val: 0.932550	test: 0.643519
PRC train: 1.000000	val: 0.891017	test: 0.716959

Epoch: 102
Loss: 0.020157948655164286
ROC train: 1.000000	val: 0.924119	test: 0.618152
PRC train: 1.000000	val: 0.862845	test: 0.696427

Epoch: 103
Loss: 0.03692925191406456
ROC train: 1.000000	val: 0.920907	test: 0.643036
PRC train: 1.000000	val: 0.866282	test: 0.719530

Epoch: 104
Loss: 0.03964856131949628
ROC train: 1.000000	val: 0.928435	test: 0.662133
PRC train: 1.000000	val: 0.885716	test: 0.733161

Epoch: 105
Loss: 0.026783985960834807
ROC train: 1.000000	val: 0.914684	test: 0.652874
PRC train: 1.000000	val: 0.846505	test: 0.725301

Epoch: 106
Loss: 0.03508697439759108
ROC train: 1.000000	val: 0.908461	test: 0.637249
PRC train: 1.000000	val: 0.834340	test: 0.702775

Epoch: 107
Loss: 0.02873413165296482
ROC train: 0.999986	val: 0.925123	test: 0.643133
PRC train: 0.999997	val: 0.878739	test: 0.709713

Epoch: 108
Loss: 0.0376647163292168
ROC train: 1.000000	val: 0.929640	test: 0.655382
PRC train: 1.000000	val: 0.882077	test: 0.736488

Epoch: 109
Loss: 0.029703710678671915
ROC train: 0.999972	val: 0.919201	test: 0.643615
PRC train: 0.999995	val: 0.861255	test: 0.715848

Epoch: 110
Loss: 0.015631535135244685
ROC train: 1.000000	val: 0.923417	test: 0.654610
PRC train: 1.000000	val: 0.873550	test: 0.733407

Epoch: 111
Loss: 0.026549985738474797
ROC train: 1.000000	val: 0.926729	test: 0.646991
PRC train: 1.000000	val: 0.882567	test: 0.728646

Epoch: 112
Loss: 0.02345984981532864
ROC train: 1.000000	val: 0.917796	test: 0.639275
PRC train: 1.000000	val: 0.856098	test: 0.706232

Epoch: 113
Loss: 0.02796519318352242
ROC train: 1.000000	val: 0.901134	test: 0.642458
PRC train: 1.000000	val: 0.830174	test: 0.700612

Epoch: 114
Loss: 0.03484746907695718
ROC train: 0.999994	val: 0.925023	test: 0.619117
PRC train: 0.999999	val: 0.883516	test: 0.714447

Epoch: 115
Loss: 0.026626113843928146
ROC train: 1.000000	val: 0.923818	test: 0.628569
PRC train: 1.000000	val: 0.882755	test: 0.707995

Epoch: 116
Loss: 0.021455894033025093
ROC train: 1.000000	val: 0.920205	test: 0.647280
PRC train: 1.000000	val: 0.877027	test: 0.724449

Epoch: 117
Loss: 0.02021056327492194
ROC train: 1.000000	val: 0.915989	test: 0.640143
PRC train: 1.000000	val: 0.862470	test: 0.719495

Epoch: 118
Loss: 0.02077364691697861
ROC train: 1.000000	val: 0.927331	test: 0.643615
PRC train: 1.000000	val: 0.871471	test: 0.725479

Epoch: 119
Loss: 0.01616159396834419
ROC train: 1.000000	val: 0.925826	test: 0.646798
PRC train: 1.000000	val: 0.873428	test: 0.717535

Epoch: 120
Loss: 0.02072790339454331
ROC train: 1.000000	val: 0.924220	test: 0.648341
PRC train: 1.000000	val: 0.868748	test: 0.717496

Early stopping
Best (ROC):	 train: 0.998227	val: 0.947405	test: 0.642650
Best (PRC):	 train: 0.999664	val: 0.904138	test: 0.708050

ROC train: 0.999919	val: 0.906655	test: 0.699749
PRC train: 0.999985	val: 0.859430	test: 0.754133

Epoch: 94
Loss: 0.0325039723061951
ROC train: 0.999997	val: 0.901335	test: 0.683931
PRC train: 0.999999	val: 0.842123	test: 0.725627

Epoch: 95
Loss: 0.0300260697149898
ROC train: 1.000000	val: 0.911272	test: 0.678530
PRC train: 1.000000	val: 0.851180	test: 0.718847

Epoch: 96
Loss: 0.03742269637175427
ROC train: 1.000000	val: 0.920406	test: 0.673804
PRC train: 1.000000	val: 0.869036	test: 0.715668

Epoch: 97
Loss: 0.05624104498169409
ROC train: 1.000000	val: 0.901536	test: 0.667728
PRC train: 1.000000	val: 0.844860	test: 0.721137

Epoch: 98
Loss: 0.04012474282049886
ROC train: 1.000000	val: 0.926528	test: 0.703125
PRC train: 1.000000	val: 0.887906	test: 0.745794

Epoch: 99
Loss: 0.04396992299599638
ROC train: 1.000000	val: 0.913480	test: 0.713156
PRC train: 1.000000	val: 0.870402	test: 0.744017

Epoch: 100
Loss: 0.028251575246862188
ROC train: 0.999997	val: 0.913179	test: 0.697820
PRC train: 0.999999	val: 0.869008	test: 0.756463

Epoch: 101
Loss: 0.03910751282411906
ROC train: 1.000000	val: 0.910168	test: 0.685764
PRC train: 1.000000	val: 0.851852	test: 0.743662

Epoch: 102
Loss: 0.03442057397672892
ROC train: 1.000000	val: 0.895815	test: 0.672357
PRC train: 1.000000	val: 0.808370	test: 0.723493

Epoch: 103
Loss: 0.03722451626752016
ROC train: 0.999972	val: 0.904145	test: 0.685764
PRC train: 0.999995	val: 0.816045	test: 0.744335

Epoch: 104
Loss: 0.03703068496522451
ROC train: 0.999860	val: 0.901837	test: 0.690490
PRC train: 0.999973	val: 0.827703	test: 0.753601

Epoch: 105
Loss: 0.028629242770855497
ROC train: 1.000000	val: 0.906554	test: 0.701582
PRC train: 1.000000	val: 0.854233	test: 0.764655

Epoch: 106
Loss: 0.038358485349386344
ROC train: 1.000000	val: 0.915287	test: 0.698688
PRC train: 1.000000	val: 0.876262	test: 0.758467

Epoch: 107
Loss: 0.030538163858030164
ROC train: 1.000000	val: 0.913279	test: 0.691069
PRC train: 1.000000	val: 0.868478	test: 0.747169

Epoch: 108
Loss: 0.03046851389433265
ROC train: 0.999972	val: 0.897420	test: 0.700424
PRC train: 0.999995	val: 0.837636	test: 0.754854

Epoch: 109
Loss: 0.028370213441011292
ROC train: 0.999994	val: 0.900432	test: 0.691744
PRC train: 0.999999	val: 0.832166	test: 0.756587

Epoch: 110
Loss: 0.032374834530339305
ROC train: 0.999964	val: 0.911673	test: 0.688465
PRC train: 0.999993	val: 0.849984	test: 0.755992

Epoch: 111
Loss: 0.03031689615239075
ROC train: 1.000000	val: 0.901536	test: 0.679495
PRC train: 1.000000	val: 0.840795	test: 0.726819

Epoch: 112
Loss: 0.024782787746057622
ROC train: 1.000000	val: 0.904446	test: 0.671007
PRC train: 1.000000	val: 0.855577	test: 0.717853

Epoch: 113
Loss: 0.025659807250237608
ROC train: 1.000000	val: 0.912376	test: 0.680363
PRC train: 1.000000	val: 0.863138	test: 0.731290

Epoch: 114
Loss: 0.0331186754810827
ROC train: 1.000000	val: 0.891599	test: 0.680363
PRC train: 1.000000	val: 0.822563	test: 0.727508

Epoch: 115
Loss: 0.02965446364511436
ROC train: 1.000000	val: 0.890194	test: 0.680459
PRC train: 1.000000	val: 0.832521	test: 0.735881

Epoch: 116
Loss: 0.028468589731984736
ROC train: 1.000000	val: 0.907156	test: 0.685764
PRC train: 1.000000	val: 0.859846	test: 0.738445

Epoch: 117
Loss: 0.02045542473997674
ROC train: 1.000000	val: 0.896316	test: 0.693576
PRC train: 1.000000	val: 0.842297	test: 0.737521

Epoch: 118
Loss: 0.029237307282659043
ROC train: 1.000000	val: 0.896216	test: 0.683931
PRC train: 1.000000	val: 0.841121	test: 0.737282

Epoch: 119
Loss: 0.01721830747647967
ROC train: 1.000000	val: 0.898223	test: 0.663387
PRC train: 1.000000	val: 0.850298	test: 0.722219

Epoch: 120
Loss: 0.024118645405605522
ROC train: 1.000000	val: 0.893807	test: 0.681134
PRC train: 1.000000	val: 0.840739	test: 0.739746

Early stopping
Best (ROC):	 train: 0.971526	val: 0.942286	test: 0.674190
Best (PRC):	 train: 0.994001	val: 0.879156	test: 0.738435

ROC train: 0.999983	val: 0.849343	test: 0.636671
PRC train: 0.999997	val: 0.714839	test: 0.637778

Epoch: 94
Loss: 0.02867378856871971
ROC train: 1.000000	val: 0.857573	test: 0.629244
PRC train: 1.000000	val: 0.736841	test: 0.658912

Epoch: 95
Loss: 0.026605995254936027
ROC train: 1.000000	val: 0.866908	test: 0.642747
PRC train: 1.000000	val: 0.754078	test: 0.659577

Epoch: 96
Loss: 0.026780793962640943
ROC train: 1.000000	val: 0.851450	test: 0.629919
PRC train: 1.000000	val: 0.734936	test: 0.637314

Epoch: 97
Loss: 0.02867547406206008
ROC train: 1.000000	val: 0.868413	test: 0.661941
PRC train: 1.000000	val: 0.751508	test: 0.677023

Epoch: 98
Loss: 0.0381176069032873
ROC train: 0.999994	val: 0.874837	test: 0.663773
PRC train: 0.999999	val: 0.747823	test: 0.645042

Epoch: 99
Loss: 0.031151258337778792
ROC train: 1.000000	val: 0.855465	test: 0.628569
PRC train: 1.000000	val: 0.733664	test: 0.621408

Epoch: 100
Loss: 0.031728572843732344
ROC train: 1.000000	val: 0.862893	test: 0.625965
PRC train: 1.000000	val: 0.753852	test: 0.646228

Epoch: 101
Loss: 0.0421217865913628
ROC train: 1.000000	val: 0.898223	test: 0.662905
PRC train: 1.000000	val: 0.809918	test: 0.700434

Epoch: 102
Loss: 0.03005279507069949
ROC train: 1.000000	val: 0.902439	test: 0.661265
PRC train: 1.000000	val: 0.811342	test: 0.685451

Epoch: 103
Loss: 0.031408887153580166
ROC train: 0.999992	val: 0.864800	test: 0.651331
PRC train: 0.999998	val: 0.746667	test: 0.632851

Epoch: 104
Loss: 0.024625695465557478
ROC train: 1.000000	val: 0.867008	test: 0.638696
PRC train: 1.000000	val: 0.758760	test: 0.629061

Epoch: 105
Loss: 0.019936894378628313
ROC train: 1.000000	val: 0.847335	test: 0.629437
PRC train: 1.000000	val: 0.735798	test: 0.618332

Epoch: 106
Loss: 0.031157741660983788
ROC train: 1.000000	val: 0.857975	test: 0.643615
PRC train: 1.000000	val: 0.741427	test: 0.643362

Epoch: 107
Loss: 0.02864870129905971
ROC train: 1.000000	val: 0.892101	test: 0.650752
PRC train: 1.000000	val: 0.785722	test: 0.679656

Epoch: 108
Loss: 0.036227814739054155
ROC train: 0.999986	val: 0.868815	test: 0.648534
PRC train: 0.999997	val: 0.775592	test: 0.649364

Epoch: 109
Loss: 0.027810424902364874
ROC train: 1.000000	val: 0.854963	test: 0.627411
PRC train: 1.000000	val: 0.755046	test: 0.632730

Epoch: 110
Loss: 0.02235222717351259
ROC train: 1.000000	val: 0.865402	test: 0.621431
PRC train: 1.000000	val: 0.754262	test: 0.620742

Epoch: 111
Loss: 0.02505195114170467
ROC train: 1.000000	val: 0.866205	test: 0.613426
PRC train: 1.000000	val: 0.757618	test: 0.600012

Epoch: 112
Loss: 0.01984866054645834
ROC train: 1.000000	val: 0.861488	test: 0.596933
PRC train: 1.000000	val: 0.752537	test: 0.603479

Epoch: 113
Loss: 0.03071587991584219
ROC train: 1.000000	val: 0.862592	test: 0.605999
PRC train: 1.000000	val: 0.737338	test: 0.635656

Epoch: 114
Loss: 0.024290726005275542
ROC train: 1.000000	val: 0.869316	test: 0.596933
PRC train: 1.000000	val: 0.759227	test: 0.635412

Epoch: 115
Loss: 0.025890669373814647
ROC train: 1.000000	val: 0.880759	test: 0.593943
PRC train: 1.000000	val: 0.788305	test: 0.627835

Epoch: 116
Loss: 0.021422417162466564
ROC train: 1.000000	val: 0.860785	test: 0.619985
PRC train: 1.000000	val: 0.749815	test: 0.635012

Epoch: 117
Loss: 0.03679662265512983
ROC train: 1.000000	val: 0.848740	test: 0.613137
PRC train: 1.000000	val: 0.726851	test: 0.606675

Epoch: 118
Loss: 0.031229165896573936
ROC train: 1.000000	val: 0.874235	test: 0.622396
PRC train: 1.000000	val: 0.775036	test: 0.620902

Epoch: 119
Loss: 0.03028927226641784
ROC train: 0.999980	val: 0.838302	test: 0.557002
PRC train: 0.999996	val: 0.753864	test: 0.564470

Epoch: 120
Loss: 0.02832456791500384
ROC train: 1.000000	val: 0.863595	test: 0.621046
PRC train: 1.000000	val: 0.764374	test: 0.611669

Early stopping
Best (ROC):	 train: 0.943991	val: 0.915889	test: 0.623746
Best (PRC):	 train: 0.987164	val: 0.858310	test: 0.670458
All runs completed.
All runs completed.
