>>> Starting run for dataset: sider
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running RANDOM configs_split_experiments/GraphCL/sider/random/train_prop=0.6.yml on cuda:0
Running RANDOM configs_split_experiments/GraphCL/sider/random/train_prop=0.7.yml on cuda:1
Running RANDOM configs_split_experiments/GraphCL/sider/random/train_prop=0.8.yml on cuda:2
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.7.yml --runseed 1 --device cuda:1
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.8.yml --runseed 1 --device cuda:2
Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.8.yml --runseed 2 --device cuda:2
Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.7.yml --runseed 2 --device cuda:1
Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.8.yml --runseed 3 --device cuda:2
Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.7.yml --runseed 3 --device cuda:1
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.6.yml --runseed 1 --device cuda:0
Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.6.yml --runseed 2 --device cuda:0
Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.6.yml --runseed 3 --device cuda:0
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:0
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/random/train_prop=0.6/sider_random_1_20-05_14-43-16  ]
[ Using Seed :  1  ]
[ Using device :  cuda:0  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
randomly split
Data(edge_attr=[38, 2], edge_index=[2, 38], id=[1], x=[18, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6894059279976267
ROC train: 0.536540	val: 0.529236	test: 0.516814
PRC train: 0.579203	val: 0.599038	test: 0.563192

Epoch: 2
Loss: 0.6407996118373016
ROC train: 0.552284	val: 0.535911	test: 0.514136
PRC train: 0.594271	val: 0.607030	test: 0.570622

Epoch: 3
Loss: 0.6105677464934702
ROC train: 0.560670	val: 0.541002	test: 0.517566
PRC train: 0.603475	val: 0.608991	test: 0.577355

Epoch: 4
Loss: 0.5797286103200758
ROC train: 0.574819	val: 0.549785	test: 0.524306
PRC train: 0.614351	val: 0.610515	test: 0.579383

Epoch: 5
Loss: 0.5652219930494251
ROC train: 0.599069	val: 0.570066	test: 0.540038
PRC train: 0.631485	val: 0.621222	test: 0.586704

Epoch: 6
Loss: 0.5490590881419812
ROC train: 0.617643	val: 0.588672	test: 0.557635
PRC train: 0.642094	val: 0.631304	test: 0.592752

Epoch: 7
Loss: 0.5458837370920187
ROC train: 0.629290	val: 0.595655	test: 0.563931
PRC train: 0.648574	val: 0.636534	test: 0.596105

Epoch: 8
Loss: 0.5280084364279912
ROC train: 0.641188	val: 0.602480	test: 0.568393
PRC train: 0.654077	val: 0.642690	test: 0.599273

Epoch: 9
Loss: 0.5275470177683246
ROC train: 0.651495	val: 0.608100	test: 0.570712
PRC train: 0.659316	val: 0.645933	test: 0.600797

Epoch: 10
Loss: 0.5216517272494602
ROC train: 0.662950	val: 0.613781	test: 0.580411
PRC train: 0.666211	val: 0.652193	test: 0.608036

Epoch: 11
Loss: 0.5144998758530692
ROC train: 0.675467	val: 0.627254	test: 0.597719
PRC train: 0.672102	val: 0.657171	test: 0.613748

Epoch: 12
Loss: 0.5060346406294942
ROC train: 0.686094	val: 0.631176	test: 0.602047
PRC train: 0.679355	val: 0.659330	test: 0.614809

Epoch: 13
Loss: 0.5002915051236667
ROC train: 0.694261	val: 0.630097	test: 0.600413
PRC train: 0.686548	val: 0.661818	test: 0.613641

Epoch: 14
Loss: 0.49592339261901436
ROC train: 0.705636	val: 0.629835	test: 0.598785
PRC train: 0.694955	val: 0.666068	test: 0.614474

Epoch: 15
Loss: 0.49551278418103273
ROC train: 0.708790	val: 0.628111	test: 0.591143
PRC train: 0.697253	val: 0.663674	test: 0.613455

Epoch: 16
Loss: 0.4883487214680847
ROC train: 0.714119	val: 0.629381	test: 0.597383
PRC train: 0.701523	val: 0.666824	test: 0.612419

Epoch: 17
Loss: 0.4871279764197767
ROC train: 0.722654	val: 0.628455	test: 0.602919
PRC train: 0.707255	val: 0.665447	test: 0.611626

Epoch: 18
Loss: 0.47434362500387944
ROC train: 0.728177	val: 0.629544	test: 0.603597
PRC train: 0.711269	val: 0.662854	test: 0.613314

Epoch: 19
Loss: 0.474527021585158
ROC train: 0.733057	val: 0.631016	test: 0.601601
PRC train: 0.713264	val: 0.659302	test: 0.611581

Epoch: 20
Loss: 0.47284808862212235
ROC train: 0.740646	val: 0.628478	test: 0.601237
PRC train: 0.718089	val: 0.657674	test: 0.610385

Epoch: 21
Loss: 0.47169838232656214
ROC train: 0.739419	val: 0.626538	test: 0.601585
PRC train: 0.715873	val: 0.659284	test: 0.610982

Epoch: 22
Loss: 0.46469040296432695
ROC train: 0.747371	val: 0.628350	test: 0.603019
PRC train: 0.724531	val: 0.665229	test: 0.610770

Epoch: 23
Loss: 0.4676326637023832
ROC train: 0.755332	val: 0.631768	test: 0.599010
PRC train: 0.730505	val: 0.668192	test: 0.609252

Epoch: 24
Loss: 0.4575617956376955
ROC train: 0.757106	val: 0.638044	test: 0.597695
PRC train: 0.731971	val: 0.673243	test: 0.611455

Epoch: 25
Loss: 0.45764866324816267
ROC train: 0.758178	val: 0.645686	test: 0.596714
PRC train: 0.732657	val: 0.679426	test: 0.609975

Epoch: 26
Loss: 0.45010808107380085
ROC train: 0.758913	val: 0.643561	test: 0.596039
PRC train: 0.732804	val: 0.676576	test: 0.611240

Epoch: 27
Loss: 0.4576607617535677
ROC train: 0.770234	val: 0.642363	test: 0.604000
PRC train: 0.738770	val: 0.673196	test: 0.614360

Epoch: 28
Loss: 0.4506262785650409
ROC train: 0.764729	val: 0.633154	test: 0.599285
PRC train: 0.732755	val: 0.662140	test: 0.610966

Epoch: 29
Loss: 0.4482029674177277
ROC train: 0.770842	val: 0.633810	test: 0.603298
PRC train: 0.739304	val: 0.662472	test: 0.610896

Epoch: 30
Loss: 0.4507685841405279
ROC train: 0.776797	val: 0.633003	test: 0.598424
PRC train: 0.744261	val: 0.665935	test: 0.612792

Epoch: 31
Loss: 0.4447719980318119
ROC train: 0.773115	val: 0.631076	test: 0.601500
PRC train: 0.742063	val: 0.669632	test: 0.617442

Epoch: 32
Loss: 0.4473869128862474
ROC train: 0.780992	val: 0.633983	test: 0.607593
PRC train: 0.747991	val: 0.672889	test: 0.619536

Epoch: 33
Loss: 0.4442887232491147Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:0
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/random/train_prop=0.6/sider_random_3_20-05_14-43-16  ]
[ Using Seed :  3  ]
[ Using device :  cuda:0  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
randomly split
Data(edge_attr=[38, 2], edge_index=[2, 38], id=[1], x=[18, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6846457115359119
ROC train: 0.528225	val: 0.548543	test: 0.531631
PRC train: 0.581409	val: 0.609052	test: 0.567153

Epoch: 2
Loss: 0.6408303257604365
ROC train: 0.547957	val: 0.550719	test: 0.529425
PRC train: 0.596230	val: 0.615489	test: 0.571792

Epoch: 3
Loss: 0.6045085675522706
ROC train: 0.553548	val: 0.540750	test: 0.521710
PRC train: 0.602369	val: 0.612576	test: 0.568601

Epoch: 4
Loss: 0.5746316380406464
ROC train: 0.567542	val: 0.542129	test: 0.529298
PRC train: 0.611467	val: 0.612544	test: 0.573867

Epoch: 5
Loss: 0.5573056427292218
ROC train: 0.588424	val: 0.551146	test: 0.541238
PRC train: 0.623006	val: 0.615169	test: 0.580656

Epoch: 6
Loss: 0.5518279706383283
ROC train: 0.615687	val: 0.573251	test: 0.556281
PRC train: 0.637498	val: 0.625822	test: 0.589189

Epoch: 7
Loss: 0.5402064604979846
ROC train: 0.633536	val: 0.584960	test: 0.567843
PRC train: 0.646816	val: 0.629726	test: 0.595023

Epoch: 8
Loss: 0.5344183679058756
ROC train: 0.640713	val: 0.591578	test: 0.572384
PRC train: 0.651174	val: 0.630068	test: 0.597548

Epoch: 9
Loss: 0.522192307568045
ROC train: 0.655788	val: 0.602296	test: 0.578871
PRC train: 0.660022	val: 0.637463	test: 0.602454

Epoch: 10
Loss: 0.5167331552512227
ROC train: 0.670696	val: 0.610621	test: 0.589483
PRC train: 0.669104	val: 0.647375	test: 0.606778

Epoch: 11
Loss: 0.506062534959041
ROC train: 0.675853	val: 0.615593	test: 0.593625
PRC train: 0.671122	val: 0.653462	test: 0.607996

Epoch: 12
Loss: 0.5081075937066573
ROC train: 0.688989	val: 0.619672	test: 0.602095
PRC train: 0.680201	val: 0.654650	test: 0.611096

Epoch: 13
Loss: 0.4993614201046177
ROC train: 0.698914	val: 0.621635	test: 0.606958
PRC train: 0.688013	val: 0.657012	test: 0.615341

Epoch: 14
Loss: 0.49253061909876594
ROC train: 0.704604	val: 0.616582	test: 0.594692
PRC train: 0.690592	val: 0.654447	test: 0.608590

Epoch: 15
Loss: 0.48410249981458026
ROC train: 0.711977	val: 0.616779	test: 0.593009
PRC train: 0.696827	val: 0.656546	test: 0.607873

Epoch: 16
Loss: 0.479881727553073
ROC train: 0.723052	val: 0.623357	test: 0.599208
PRC train: 0.706074	val: 0.660656	test: 0.609535

Epoch: 17
Loss: 0.4739891338308898
ROC train: 0.732787	val: 0.625712	test: 0.604990
PRC train: 0.711742	val: 0.660636	test: 0.612340

Epoch: 18
Loss: 0.4765562122787254
ROC train: 0.738275	val: 0.619157	test: 0.599781
PRC train: 0.715988	val: 0.657476	test: 0.613249

Epoch: 19
Loss: 0.47103226978179236
ROC train: 0.738785	val: 0.611836	test: 0.597824
PRC train: 0.718285	val: 0.654166	test: 0.611619

Epoch: 20
Loss: 0.4661305253883348
ROC train: 0.747481	val: 0.612083	test: 0.605373
PRC train: 0.723058	val: 0.654720	test: 0.612363

Epoch: 21
Loss: 0.46796374805284985
ROC train: 0.748171	val: 0.614297	test: 0.600571
PRC train: 0.723765	val: 0.659938	test: 0.611313

Epoch: 22
Loss: 0.46549108427843255
ROC train: 0.750340	val: 0.612434	test: 0.591364
PRC train: 0.728291	val: 0.655788	test: 0.611500

Epoch: 23
Loss: 0.4620036150721658
ROC train: 0.757257	val: 0.613944	test: 0.586531
PRC train: 0.734430	val: 0.654428	test: 0.610754

Epoch: 24
Loss: 0.4600086033151295
ROC train: 0.762957	val: 0.622901	test: 0.595852
PRC train: 0.736063	val: 0.661062	test: 0.615284

Epoch: 25
Loss: 0.4534319812698552
ROC train: 0.769100	val: 0.622778	test: 0.598270
PRC train: 0.739750	val: 0.663302	test: 0.613051

Epoch: 26
Loss: 0.44967201709578497
ROC train: 0.774495	val: 0.617022	test: 0.599026
PRC train: 0.741749	val: 0.656743	test: 0.610657

Epoch: 27
Loss: 0.46067932198045786
ROC train: 0.773307	val: 0.616626	test: 0.596821
PRC train: 0.742032	val: 0.657030	test: 0.609028

Epoch: 28
Loss: 0.4520961459080732
ROC train: 0.778359	val: 0.615570	test: 0.592236
PRC train: 0.744942	val: 0.657741	test: 0.609289

Epoch: 29
Loss: 0.45715397818540243
ROC train: 0.777273	val: 0.616138	test: 0.591666
PRC train: 0.746780	val: 0.659558	test: 0.608905

Epoch: 30
Loss: 0.4503150252979156
ROC train: 0.772425	val: 0.618094	test: 0.595613
PRC train: 0.745435	val: 0.658439	test: 0.608617

Epoch: 31
Loss: 0.44739973968360236
ROC train: 0.781133	val: 0.618605	test: 0.596528
PRC train: 0.749242	val: 0.659679	test: 0.610822

Epoch: 32
Loss: 0.4428342162965629
ROC train: 0.786735	val: 0.609493	test: 0.590957
PRC train: 0.754316	val: 0.658244	test: 0.611826

Epoch: 33
Loss: 0.44232223079320243Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:0
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/random/train_prop=0.6/sider_random_2_20-05_14-43-16  ]
[ Using Seed :  2  ]
[ Using device :  cuda:0  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
randomly split
Data(edge_attr=[38, 2], edge_index=[2, 38], id=[1], x=[18, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6966843235524304
ROC train: 0.537061	val: 0.550527	test: 0.519265
PRC train: 0.583162	val: 0.612053	test: 0.565064

Epoch: 2
Loss: 0.6510849654913722
ROC train: 0.558834	val: 0.554302	test: 0.523229
PRC train: 0.597284	val: 0.613733	test: 0.565956

Epoch: 3
Loss: 0.6172562562829108
ROC train: 0.564870	val: 0.552987	test: 0.521598
PRC train: 0.604602	val: 0.616189	test: 0.565995

Epoch: 4
Loss: 0.5932352616010957
ROC train: 0.574545	val: 0.558059	test: 0.522916
PRC train: 0.611280	val: 0.620267	test: 0.568449

Epoch: 5
Loss: 0.5600055665658505
ROC train: 0.593658	val: 0.568465	test: 0.527088
PRC train: 0.623617	val: 0.627078	test: 0.570904

Epoch: 6
Loss: 0.5550208936034969
ROC train: 0.615862	val: 0.589046	test: 0.538058
PRC train: 0.637179	val: 0.638969	test: 0.579303

Epoch: 7
Loss: 0.5394410305504099
ROC train: 0.633368	val: 0.604224	test: 0.551957
PRC train: 0.644284	val: 0.643450	test: 0.587942

Epoch: 8
Loss: 0.5359134885432305
ROC train: 0.643951	val: 0.605760	test: 0.555836
PRC train: 0.651867	val: 0.644309	test: 0.590265

Epoch: 9
Loss: 0.5268376400995063
ROC train: 0.655427	val: 0.610937	test: 0.559595
PRC train: 0.659806	val: 0.646839	test: 0.591107

Epoch: 10
Loss: 0.5197156203162616
ROC train: 0.668407	val: 0.618177	test: 0.567760
PRC train: 0.668734	val: 0.651076	test: 0.594228

Epoch: 11
Loss: 0.5112413678954019
ROC train: 0.678847	val: 0.624761	test: 0.575639
PRC train: 0.674969	val: 0.655755	test: 0.597255

Epoch: 12
Loss: 0.5036464323065519
ROC train: 0.685742	val: 0.625448	test: 0.579268
PRC train: 0.678583	val: 0.657332	test: 0.600591

Epoch: 13
Loss: 0.4935538016502858
ROC train: 0.690222	val: 0.622593	test: 0.575868
PRC train: 0.680290	val: 0.656709	test: 0.598076

Epoch: 14
Loss: 0.4941464034365781
ROC train: 0.696845	val: 0.620881	test: 0.573626
PRC train: 0.684642	val: 0.656482	test: 0.596668

Epoch: 15
Loss: 0.48756821597791067
ROC train: 0.707228	val: 0.624994	test: 0.573501
PRC train: 0.693646	val: 0.660866	test: 0.595380

Epoch: 16
Loss: 0.48429417705648575
ROC train: 0.714851	val: 0.633117	test: 0.573623
PRC train: 0.699378	val: 0.664529	test: 0.595858

Epoch: 17
Loss: 0.4774624035397197
ROC train: 0.719594	val: 0.637506	test: 0.578212
PRC train: 0.704863	val: 0.666585	test: 0.599188

Epoch: 18
Loss: 0.4792749131089829
ROC train: 0.727757	val: 0.640151	test: 0.585212
PRC train: 0.708838	val: 0.666360	test: 0.604413

Epoch: 19
Loss: 0.4735988062877768
ROC train: 0.731933	val: 0.638526	test: 0.587644
PRC train: 0.713547	val: 0.670371	test: 0.605087

Epoch: 20
Loss: 0.47165365905609924
ROC train: 0.734318	val: 0.634468	test: 0.584051
PRC train: 0.715264	val: 0.671319	test: 0.605419

Epoch: 21
Loss: 0.46945960273557824
ROC train: 0.734174	val: 0.628819	test: 0.580166
PRC train: 0.714584	val: 0.662602	test: 0.603862

Epoch: 22
Loss: 0.4738450040762375
ROC train: 0.741855	val: 0.629480	test: 0.581011
PRC train: 0.719942	val: 0.661289	test: 0.603327

Epoch: 23
Loss: 0.4693356247489675
ROC train: 0.749084	val: 0.632881	test: 0.586860
PRC train: 0.723745	val: 0.666537	test: 0.605710

Epoch: 24
Loss: 0.4637996270283168
ROC train: 0.756293	val: 0.640199	test: 0.589063
PRC train: 0.728236	val: 0.671597	test: 0.604405

Epoch: 25
Loss: 0.46361195609174466
ROC train: 0.759043	val: 0.639237	test: 0.590153
PRC train: 0.729743	val: 0.668921	test: 0.605808

Epoch: 26
Loss: 0.4534962468002969
ROC train: 0.762247	val: 0.633464	test: 0.588275
PRC train: 0.731197	val: 0.664950	test: 0.603883

Epoch: 27
Loss: 0.452758332558849
ROC train: 0.763356	val: 0.633805	test: 0.591211
PRC train: 0.732776	val: 0.665900	test: 0.602439

Epoch: 28
Loss: 0.44873584448444237
ROC train: 0.768549	val: 0.637044	test: 0.594761
PRC train: 0.737203	val: 0.665954	test: 0.605174

Epoch: 29
Loss: 0.4506828017540566
ROC train: 0.773096	val: 0.635920	test: 0.593510
PRC train: 0.740112	val: 0.665397	test: 0.607399

Epoch: 30
Loss: 0.4450443242017624
ROC train: 0.770934	val: 0.637944	test: 0.592105
PRC train: 0.738915	val: 0.662186	test: 0.608543

Epoch: 31
Loss: 0.4530804928219984
ROC train: 0.772724	val: 0.637731	test: 0.593345
PRC train: 0.738631	val: 0.663630	test: 0.609925

Epoch: 32
Loss: 0.44736851280132495
ROC train: 0.777658	val: 0.636939	test: 0.593424
PRC train: 0.743087	val: 0.669083	test: 0.607123

Epoch: 33
Loss: 0.4486167272035748Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:1
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/random/train_prop=0.7/sider_random_3_20-05_14-43-16  ]
[ Using Seed :  3  ]
[ Using device :  cuda:1  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
randomly split
Data(edge_attr=[38, 2], edge_index=[2, 38], id=[1], x=[18, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6836125709139669
ROC train: 0.534858	val: 0.538257	test: 0.530213
PRC train: 0.584070	val: 0.618114	test: 0.558902

Epoch: 2
Loss: 0.6434966144259713
ROC train: 0.555114	val: 0.538874	test: 0.533413
PRC train: 0.598289	val: 0.617613	test: 0.566237

Epoch: 3
Loss: 0.6021355420696832
ROC train: 0.564787	val: 0.534703	test: 0.532991
PRC train: 0.607998	val: 0.617975	test: 0.569830

Epoch: 4
Loss: 0.5715514086565564
ROC train: 0.582582	val: 0.535911	test: 0.537636
PRC train: 0.618731	val: 0.619828	test: 0.572588

Epoch: 5
Loss: 0.553748097230434
ROC train: 0.612605	val: 0.556634	test: 0.551692
PRC train: 0.635431	val: 0.630914	test: 0.577947

Epoch: 6
Loss: 0.542382532082128
ROC train: 0.635873	val: 0.578095	test: 0.561971
PRC train: 0.647416	val: 0.638495	test: 0.582700

Epoch: 7
Loss: 0.5325347373674817
ROC train: 0.646251	val: 0.581792	test: 0.568707
PRC train: 0.652855	val: 0.636978	test: 0.587412

Epoch: 8
Loss: 0.5256187613634928
ROC train: 0.657135	val: 0.586282	test: 0.571471
PRC train: 0.659140	val: 0.641581	test: 0.588931

Epoch: 9
Loss: 0.520988401204266
ROC train: 0.672532	val: 0.598543	test: 0.577903
PRC train: 0.669263	val: 0.654022	test: 0.590066

Epoch: 10
Loss: 0.5127258725764903
ROC train: 0.682295	val: 0.602399	test: 0.581282
PRC train: 0.675053	val: 0.654931	test: 0.590694

Epoch: 11
Loss: 0.5050938167568635
ROC train: 0.691821	val: 0.602373	test: 0.580089
PRC train: 0.680386	val: 0.652315	test: 0.589496

Epoch: 12
Loss: 0.4999027438613205
ROC train: 0.702922	val: 0.608725	test: 0.587692
PRC train: 0.688696	val: 0.663663	test: 0.594908

Epoch: 13
Loss: 0.4912773626484315
ROC train: 0.709584	val: 0.611193	test: 0.590330
PRC train: 0.693040	val: 0.665044	test: 0.596011

Epoch: 14
Loss: 0.4888179732573559
ROC train: 0.716344	val: 0.608371	test: 0.591779
PRC train: 0.696562	val: 0.664465	test: 0.596544

Epoch: 15
Loss: 0.482273876839397
ROC train: 0.724146	val: 0.608960	test: 0.598430
PRC train: 0.702481	val: 0.668494	test: 0.601452

Epoch: 16
Loss: 0.4802067692924322
ROC train: 0.729693	val: 0.610393	test: 0.606851
PRC train: 0.706046	val: 0.669546	test: 0.605239

Epoch: 17
Loss: 0.47559235672590244
ROC train: 0.731831	val: 0.611139	test: 0.603066
PRC train: 0.708511	val: 0.669064	test: 0.603682

Epoch: 18
Loss: 0.4738214148796106
ROC train: 0.738843	val: 0.612053	test: 0.605724
PRC train: 0.712275	val: 0.672033	test: 0.605034

Epoch: 19
Loss: 0.46638509256042804
ROC train: 0.743898	val: 0.612224	test: 0.612147
PRC train: 0.715432	val: 0.675230	test: 0.607899

Epoch: 20
Loss: 0.46438177973261247
ROC train: 0.749866	val: 0.615745	test: 0.612277
PRC train: 0.719969	val: 0.675706	test: 0.608909

Epoch: 21
Loss: 0.46318902276933377
ROC train: 0.755048	val: 0.611879	test: 0.611140
PRC train: 0.724116	val: 0.670930	test: 0.608881

Epoch: 22
Loss: 0.457876743809294
ROC train: 0.758230	val: 0.612811	test: 0.614201
PRC train: 0.725559	val: 0.673442	test: 0.609557

Epoch: 23
Loss: 0.45778988368762213
ROC train: 0.761601	val: 0.611542	test: 0.609505
PRC train: 0.728287	val: 0.671365	test: 0.610664

Epoch: 24
Loss: 0.4559250892238163
ROC train: 0.765626	val: 0.612988	test: 0.604254
PRC train: 0.732347	val: 0.671389	test: 0.610129

Epoch: 25
Loss: 0.4525296119835457
ROC train: 0.766472	val: 0.619011	test: 0.595028
PRC train: 0.734364	val: 0.676027	test: 0.606834

Epoch: 26
Loss: 0.45137233154951434
ROC train: 0.771594	val: 0.625859	test: 0.595937
PRC train: 0.736625	val: 0.682696	test: 0.602655

Epoch: 27
Loss: 0.44743581364745294
ROC train: 0.780397	val: 0.624369	test: 0.610306
PRC train: 0.741500	val: 0.684268	test: 0.610970

Epoch: 28
Loss: 0.44667761033923975
ROC train: 0.781887	val: 0.621303	test: 0.615450
PRC train: 0.743425	val: 0.684668	test: 0.614231

Epoch: 29
Loss: 0.4423824638973188
ROC train: 0.781862	val: 0.618195	test: 0.610393
PRC train: 0.744219	val: 0.684171	test: 0.613147

Epoch: 30
Loss: 0.43975590978155854
ROC train: 0.786123	val: 0.617725	test: 0.610814
PRC train: 0.747507	val: 0.683662	test: 0.613993

Epoch: 31
Loss: 0.43796733884850286
ROC train: 0.791858	val: 0.614181	test: 0.607122
PRC train: 0.751599	val: 0.682799	test: 0.611631

Epoch: 32
Loss: 0.43811441726956124
ROC train: 0.791763	val: 0.609211	test: 0.602925
PRC train: 0.752454	val: 0.677885	test: 0.608601

Epoch: 33
Loss: 0.4347590928838068Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:1
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/random/train_prop=0.7/sider_random_1_20-05_14-43-16  ]
[ Using Seed :  1  ]
[ Using device :  cuda:1  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
randomly split
Data(edge_attr=[38, 2], edge_index=[2, 38], id=[1], x=[18, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6891562073905874
ROC train: 0.537061	val: 0.505043	test: 0.518614
PRC train: 0.580127	val: 0.597096	test: 0.555637

Epoch: 2
Loss: 0.6421806817186477
ROC train: 0.547021	val: 0.520011	test: 0.513318
PRC train: 0.592818	val: 0.607466	test: 0.563121

Epoch: 3
Loss: 0.6043864169888333
ROC train: 0.558014	val: 0.521159	test: 0.514586
PRC train: 0.602448	val: 0.608285	test: 0.566486

Epoch: 4
Loss: 0.5823995393778272
ROC train: 0.573197	val: 0.525817	test: 0.514618
PRC train: 0.614290	val: 0.612840	test: 0.569526

Epoch: 5
Loss: 0.5630952052688768
ROC train: 0.599545	val: 0.542785	test: 0.527482
PRC train: 0.630690	val: 0.622308	test: 0.577592

Epoch: 6
Loss: 0.5509133347411949
ROC train: 0.624306	val: 0.561275	test: 0.548820
PRC train: 0.644386	val: 0.630847	test: 0.588940

Epoch: 7
Loss: 0.5402500171250789
ROC train: 0.638465	val: 0.572546	test: 0.567018
PRC train: 0.653093	val: 0.636656	test: 0.598218

Epoch: 8
Loss: 0.5331128691591843
ROC train: 0.650580	val: 0.575877	test: 0.578073
PRC train: 0.659946	val: 0.640813	test: 0.604337

Epoch: 9
Loss: 0.5237152555040807
ROC train: 0.661799	val: 0.578341	test: 0.584590
PRC train: 0.666451	val: 0.642143	test: 0.606747

Epoch: 10
Loss: 0.5173387024734969
ROC train: 0.675390	val: 0.580088	test: 0.589933
PRC train: 0.672800	val: 0.642055	test: 0.604340

Epoch: 11
Loss: 0.5092537791690858
ROC train: 0.688683	val: 0.588322	test: 0.596426
PRC train: 0.679588	val: 0.649974	test: 0.605068

Epoch: 12
Loss: 0.5002777969361946
ROC train: 0.693232	val: 0.588211	test: 0.592688
PRC train: 0.683163	val: 0.650275	test: 0.602557

Epoch: 13
Loss: 0.49674456696294567
ROC train: 0.701746	val: 0.587900	test: 0.590940
PRC train: 0.691176	val: 0.653700	test: 0.601935

Epoch: 14
Loss: 0.4958925277944066
ROC train: 0.715346	val: 0.593080	test: 0.593074
PRC train: 0.700813	val: 0.659744	test: 0.603218

Epoch: 15
Loss: 0.4858369809264077
ROC train: 0.719144	val: 0.594359	test: 0.590441
PRC train: 0.704402	val: 0.657204	test: 0.601754

Epoch: 16
Loss: 0.4808473990039147
ROC train: 0.729528	val: 0.600664	test: 0.592940
PRC train: 0.710668	val: 0.663224	test: 0.604366

Epoch: 17
Loss: 0.475386826877733
ROC train: 0.736787	val: 0.608698	test: 0.596935
PRC train: 0.715396	val: 0.669583	test: 0.609601

Epoch: 18
Loss: 0.471759222752333
ROC train: 0.740317	val: 0.608666	test: 0.591279
PRC train: 0.718449	val: 0.670778	test: 0.606513

Epoch: 19
Loss: 0.4677939870178906
ROC train: 0.750934	val: 0.601260	test: 0.590705
PRC train: 0.725015	val: 0.672428	test: 0.604194

Epoch: 20
Loss: 0.46715926435501065
ROC train: 0.754678	val: 0.596608	test: 0.591838
PRC train: 0.727360	val: 0.662863	test: 0.601320

Epoch: 21
Loss: 0.46574281016671026
ROC train: 0.759368	val: 0.597198	test: 0.589217
PRC train: 0.729914	val: 0.659733	test: 0.599115

Epoch: 22
Loss: 0.46230574323204365
ROC train: 0.764084	val: 0.603815	test: 0.587730
PRC train: 0.733182	val: 0.663172	test: 0.600261

Epoch: 23
Loss: 0.45512193423469355
ROC train: 0.770750	val: 0.612930	test: 0.593970
PRC train: 0.736783	val: 0.670931	test: 0.601955

Epoch: 24
Loss: 0.45518340158944254
ROC train: 0.772022	val: 0.618031	test: 0.598612
PRC train: 0.739234	val: 0.682657	test: 0.606118

Epoch: 25
Loss: 0.4514808625295833
ROC train: 0.777016	val: 0.610617	test: 0.604556
PRC train: 0.745317	val: 0.684014	test: 0.608770

Epoch: 26
Loss: 0.4520223419559036
ROC train: 0.781788	val: 0.604863	test: 0.599693
PRC train: 0.748140	val: 0.680923	test: 0.604539

Epoch: 27
Loss: 0.45025534019543817
ROC train: 0.783394	val: 0.602400	test: 0.590879
PRC train: 0.748809	val: 0.672492	test: 0.594870

Epoch: 28
Loss: 0.44495522053718506
ROC train: 0.782322	val: 0.601113	test: 0.583472
PRC train: 0.749114	val: 0.673027	test: 0.593511

Epoch: 29
Loss: 0.44286209690675804
ROC train: 0.785196	val: 0.603789	test: 0.591655
PRC train: 0.752184	val: 0.678327	test: 0.597530

Epoch: 30
Loss: 0.4472334172549623
ROC train: 0.788008	val: 0.608985	test: 0.601920
PRC train: 0.753885	val: 0.686991	test: 0.600395

Epoch: 31
Loss: 0.445649803790517
ROC train: 0.793744	val: 0.611888	test: 0.598757
PRC train: 0.758779	val: 0.684034	test: 0.600493

Epoch: 32
Loss: 0.43978884261022
ROC train: 0.797382	val: 0.610662	test: 0.591793
PRC train: 0.761255	val: 0.679992	test: 0.597727

Epoch: 33
Loss: 0.438031095254682
ROC train: 0.802575	val: 0.608602	test: 0.595796Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:1
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/random/train_prop=0.7/sider_random_2_20-05_14-43-16  ]
[ Using Seed :  2  ]
[ Using device :  cuda:1  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
randomly split
Data(edge_attr=[38, 2], edge_index=[2, 38], id=[1], x=[18, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6948819439832838
ROC train: 0.546666	val: 0.543182	test: 0.516648
PRC train: 0.588847	val: 0.608717	test: 0.552940

Epoch: 2
Loss: 0.6531667323350182
ROC train: 0.555000	val: 0.549169	test: 0.519967
PRC train: 0.597135	val: 0.617771	test: 0.559025

Epoch: 3
Loss: 0.6166073537404623
ROC train: 0.560069	val: 0.541278	test: 0.519114
PRC train: 0.600035	val: 0.616058	test: 0.556165

Epoch: 4
Loss: 0.5896864778677191
ROC train: 0.570930	val: 0.545717	test: 0.522714
PRC train: 0.608139	val: 0.619196	test: 0.561734

Epoch: 5
Loss: 0.5610894217600032
ROC train: 0.594473	val: 0.555746	test: 0.531139
PRC train: 0.620770	val: 0.622613	test: 0.569586

Epoch: 6
Loss: 0.5483446031161409
ROC train: 0.621807	val: 0.578777	test: 0.553544
PRC train: 0.637247	val: 0.637005	test: 0.584481

Epoch: 7
Loss: 0.5364428243244672
ROC train: 0.642847	val: 0.594513	test: 0.570175
PRC train: 0.648687	val: 0.646091	test: 0.594419

Epoch: 8
Loss: 0.5304181657753412
ROC train: 0.650062	val: 0.594645	test: 0.571526
PRC train: 0.653957	val: 0.645954	test: 0.592727

Epoch: 9
Loss: 0.519398831781901
ROC train: 0.663093	val: 0.601609	test: 0.578408
PRC train: 0.661427	val: 0.650574	test: 0.595526

Epoch: 10
Loss: 0.5163036195028385
ROC train: 0.678499	val: 0.607047	test: 0.586730
PRC train: 0.670806	val: 0.653868	test: 0.600055

Epoch: 11
Loss: 0.5060758457874527
ROC train: 0.685627	val: 0.603499	test: 0.585878
PRC train: 0.676673	val: 0.652920	test: 0.598449

Epoch: 12
Loss: 0.49996466361217073
ROC train: 0.694587	val: 0.604866	test: 0.589767
PRC train: 0.682749	val: 0.655559	test: 0.598891

Epoch: 13
Loss: 0.4966561470231027
ROC train: 0.700901	val: 0.604935	test: 0.582416
PRC train: 0.687170	val: 0.658266	test: 0.592524

Epoch: 14
Loss: 0.4911726850133112
ROC train: 0.708968	val: 0.612558	test: 0.589592
PRC train: 0.694099	val: 0.666154	test: 0.597027

Epoch: 15
Loss: 0.4845603123709987
ROC train: 0.716506	val: 0.619497	test: 0.598294
PRC train: 0.699072	val: 0.671981	test: 0.599526

Epoch: 16
Loss: 0.47865693412970894
ROC train: 0.719037	val: 0.625121	test: 0.601417
PRC train: 0.700433	val: 0.672235	test: 0.603059

Epoch: 17
Loss: 0.479414115978527
ROC train: 0.724145	val: 0.620994	test: 0.592844
PRC train: 0.704379	val: 0.671136	test: 0.599645

Epoch: 18
Loss: 0.4755782954055846
ROC train: 0.734038	val: 0.621190	test: 0.592101
PRC train: 0.711115	val: 0.672225	test: 0.598888

Epoch: 19
Loss: 0.47112687019062
ROC train: 0.741407	val: 0.625709	test: 0.598092
PRC train: 0.715701	val: 0.677568	test: 0.602567

Epoch: 20
Loss: 0.47045543181342336
ROC train: 0.746166	val: 0.627249	test: 0.601233
PRC train: 0.718881	val: 0.678012	test: 0.604775

Epoch: 21
Loss: 0.46893217839296897
ROC train: 0.745306	val: 0.620964	test: 0.589975
PRC train: 0.719636	val: 0.674553	test: 0.600804

Epoch: 22
Loss: 0.4618061832736144
ROC train: 0.751615	val: 0.621463	test: 0.588824
PRC train: 0.722144	val: 0.671555	test: 0.598532

Epoch: 23
Loss: 0.4618539746452933
ROC train: 0.758248	val: 0.619533	test: 0.592872
PRC train: 0.726013	val: 0.673881	test: 0.598910

Epoch: 24
Loss: 0.4571093642421282
ROC train: 0.760632	val: 0.618795	test: 0.598612
PRC train: 0.728311	val: 0.674765	test: 0.598453

Epoch: 25
Loss: 0.456982197984217
ROC train: 0.764237	val: 0.615783	test: 0.595458
PRC train: 0.730550	val: 0.671293	test: 0.595753

Epoch: 26
Loss: 0.45325160000958964
ROC train: 0.773775	val: 0.614203	test: 0.596555
PRC train: 0.738394	val: 0.669087	test: 0.595085

Epoch: 27
Loss: 0.4484798137711378
ROC train: 0.777702	val: 0.628295	test: 0.597972
PRC train: 0.741203	val: 0.674196	test: 0.595450

Epoch: 28
Loss: 0.4471016816420462
ROC train: 0.781489	val: 0.633916	test: 0.597908
PRC train: 0.743208	val: 0.678516	test: 0.598393

Epoch: 29
Loss: 0.4433171330283458
ROC train: 0.784512	val: 0.624991	test: 0.596149
PRC train: 0.744464	val: 0.676882	test: 0.598377

Epoch: 30
Loss: 0.4445838791492326
ROC train: 0.787013	val: 0.623314	test: 0.597233
PRC train: 0.747421	val: 0.680504	test: 0.601432

Epoch: 31
Loss: 0.44225973944084274
ROC train: 0.788013	val: 0.619461	test: 0.594487
PRC train: 0.751749	val: 0.679474	test: 0.597228

Epoch: 32
Loss: 0.4377222268458857
ROC train: 0.791730	val: 0.618833	test: 0.594250
PRC train: 0.754689	val: 0.678898	test: 0.601042

Epoch: 33
Loss: 0.44366396810326403
ROC train: 0.792825	val: 0.618836	test: 0.603970Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:2
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/random/train_prop=0.8/sider_random_3_20-05_14-43-16  ]
[ Using Seed :  3  ]
[ Using device :  cuda:2  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
randomly split
Data(edge_attr=[38, 2], edge_index=[2, 38], id=[1], x=[18, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6800118324796102
ROC train: 0.541989	val: 0.554606	test: 0.526148
PRC train: 0.593068	val: 0.605485	test: 0.560100

Epoch: 2
Loss: 0.6256385567521188
ROC train: 0.548369	val: 0.536117	test: 0.520666
PRC train: 0.601294	val: 0.598935	test: 0.564572

Epoch: 3
Loss: 0.5838757042631398
ROC train: 0.557229	val: 0.534306	test: 0.514778
PRC train: 0.609384	val: 0.599785	test: 0.560378

Epoch: 4
Loss: 0.5747389298353789
ROC train: 0.586140	val: 0.548373	test: 0.527673
PRC train: 0.626725	val: 0.606125	test: 0.566276

Epoch: 5
Loss: 0.5471664011360192
ROC train: 0.623317	val: 0.579918	test: 0.545395
PRC train: 0.646654	val: 0.621881	test: 0.573386

Epoch: 6
Loss: 0.5317240102323668
ROC train: 0.632008	val: 0.585564	test: 0.550300
PRC train: 0.650834	val: 0.623285	test: 0.576722

Epoch: 7
Loss: 0.5231112257853987
ROC train: 0.645017	val: 0.588412	test: 0.554939
PRC train: 0.657260	val: 0.624219	test: 0.578301

Epoch: 8
Loss: 0.517510946222776
ROC train: 0.662515	val: 0.600469	test: 0.560789
PRC train: 0.667674	val: 0.635317	test: 0.582710

Epoch: 9
Loss: 0.507986249921509
ROC train: 0.677976	val: 0.609769	test: 0.566498
PRC train: 0.676476	val: 0.643397	test: 0.588712

Epoch: 10
Loss: 0.5020815258129968
ROC train: 0.689545	val: 0.605017	test: 0.565000
PRC train: 0.685604	val: 0.636711	test: 0.586295

Epoch: 11
Loss: 0.49670096093553634
ROC train: 0.696183	val: 0.597307	test: 0.564610
PRC train: 0.689844	val: 0.627736	test: 0.589899

Epoch: 12
Loss: 0.49170127536238406
ROC train: 0.705959	val: 0.612794	test: 0.573797
PRC train: 0.696518	val: 0.641017	test: 0.591655

Epoch: 13
Loss: 0.48471224065815477
ROC train: 0.711947	val: 0.603911	test: 0.565342
PRC train: 0.701134	val: 0.635098	test: 0.590597

Epoch: 14
Loss: 0.47584267288559434
ROC train: 0.715175	val: 0.604280	test: 0.554303
PRC train: 0.703888	val: 0.633537	test: 0.587999

Epoch: 15
Loss: 0.4778085997831524
ROC train: 0.723702	val: 0.610304	test: 0.560050
PRC train: 0.707731	val: 0.639401	test: 0.590958

Epoch: 16
Loss: 0.47469308878222805
ROC train: 0.730802	val: 0.607758	test: 0.566535
PRC train: 0.711666	val: 0.641961	test: 0.593076

Epoch: 17
Loss: 0.4723086318498163
ROC train: 0.727817	val: 0.620943	test: 0.562664
PRC train: 0.710001	val: 0.650032	test: 0.593241

Epoch: 18
Loss: 0.46879375246410326
ROC train: 0.737392	val: 0.611583	test: 0.571627
PRC train: 0.718353	val: 0.646783	test: 0.593829

Epoch: 19
Loss: 0.46346005364438836
ROC train: 0.744060	val: 0.603643	test: 0.576759
PRC train: 0.724993	val: 0.640065	test: 0.594225

Epoch: 20
Loss: 0.46386889031150663
ROC train: 0.747207	val: 0.593649	test: 0.573666
PRC train: 0.728420	val: 0.633007	test: 0.594190

Epoch: 21
Loss: 0.4603619004435779
ROC train: 0.748809	val: 0.595372	test: 0.565094
PRC train: 0.731095	val: 0.635483	test: 0.588565

Epoch: 22
Loss: 0.45750051913356915
ROC train: 0.752100	val: 0.619075	test: 0.563198
PRC train: 0.731902	val: 0.647429	test: 0.585018

Epoch: 23
Loss: 0.45824806295656934
ROC train: 0.757509	val: 0.601689	test: 0.569732
PRC train: 0.737937	val: 0.637790	test: 0.592999

Epoch: 24
Loss: 0.4566295831371486
ROC train: 0.760557	val: 0.598686	test: 0.571691
PRC train: 0.739183	val: 0.637488	test: 0.590929

Epoch: 25
Loss: 0.45665832347387375
ROC train: 0.766761	val: 0.612430	test: 0.576136
PRC train: 0.741520	val: 0.651105	test: 0.593229

Epoch: 26
Loss: 0.45160362080306476
ROC train: 0.766917	val: 0.600558	test: 0.570591
PRC train: 0.744446	val: 0.642147	test: 0.590562

Epoch: 27
Loss: 0.4516885948505275
ROC train: 0.766738	val: 0.597993	test: 0.576381
PRC train: 0.744490	val: 0.633884	test: 0.595102

Epoch: 28
Loss: 0.4477305975951789
ROC train: 0.774712	val: 0.605614	test: 0.574135
PRC train: 0.748646	val: 0.641902	test: 0.593640

Epoch: 29
Loss: 0.4420099703370111
ROC train: 0.779273	val: 0.601112	test: 0.578119
PRC train: 0.750954	val: 0.641444	test: 0.596977

Epoch: 30
Loss: 0.4444004320182251
ROC train: 0.779204	val: 0.600191	test: 0.582305
PRC train: 0.751776	val: 0.645480	test: 0.598138

Epoch: 31
Loss: 0.44313597445132
ROC train: 0.784294	val: 0.611916	test: 0.588193
PRC train: 0.755021	val: 0.655525	test: 0.597578

Epoch: 32
Loss: 0.44259920994492036
ROC train: 0.786225	val: 0.605690	test: 0.589566
PRC train: 0.756593	val: 0.652078	test: 0.597712

Epoch: 33
Loss: 0.44150645392818066Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:2
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/random/train_prop=0.8/sider_random_1_20-05_14-43-16  ]
[ Using Seed :  1  ]
[ Using device :  cuda:2  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
randomly split
Data(edge_attr=[38, 2], edge_index=[2, 38], id=[1], x=[18, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6836229206574299
ROC train: 0.536467	val: 0.508854	test: 0.511727
PRC train: 0.584870	val: 0.584364	test: 0.558214

Epoch: 2
Loss: 0.6239186202696215
ROC train: 0.546517	val: 0.504175	test: 0.506607
PRC train: 0.597164	val: 0.582661	test: 0.562937

Epoch: 3
Loss: 0.5833279720153517
ROC train: 0.560841	val: 0.515339	test: 0.510648
PRC train: 0.610327	val: 0.589201	test: 0.572109

Epoch: 4
Loss: 0.5641395175416837
ROC train: 0.588688	val: 0.535366	test: 0.528358
PRC train: 0.625446	val: 0.598609	test: 0.580649

Epoch: 5
Loss: 0.548420420321283
ROC train: 0.615893	val: 0.563448	test: 0.554668
PRC train: 0.640569	val: 0.616951	test: 0.591928

Epoch: 6
Loss: 0.5387085845631556
ROC train: 0.629460	val: 0.571394	test: 0.568001
PRC train: 0.650086	val: 0.626058	test: 0.599326

Epoch: 7
Loss: 0.5290019819436768
ROC train: 0.643562	val: 0.576441	test: 0.578636
PRC train: 0.657433	val: 0.628867	test: 0.605682

Epoch: 8
Loss: 0.5208438024148199
ROC train: 0.659416	val: 0.588931	test: 0.585328
PRC train: 0.667104	val: 0.636115	test: 0.610151

Epoch: 9
Loss: 0.5139725202627343
ROC train: 0.674714	val: 0.606412	test: 0.590974
PRC train: 0.675726	val: 0.641989	test: 0.605214

Epoch: 10
Loss: 0.5054079288704574
ROC train: 0.682020	val: 0.603025	test: 0.595301
PRC train: 0.681216	val: 0.637607	test: 0.604935

Epoch: 11
Loss: 0.49650728063222144
ROC train: 0.692469	val: 0.606767	test: 0.601962
PRC train: 0.691625	val: 0.642439	test: 0.614880

Epoch: 12
Loss: 0.49430579569471994
ROC train: 0.703773	val: 0.610659	test: 0.600317
PRC train: 0.699076	val: 0.644463	test: 0.609033

Epoch: 13
Loss: 0.48635264766870784
ROC train: 0.711168	val: 0.603946	test: 0.599522
PRC train: 0.702113	val: 0.641853	test: 0.607705

Epoch: 14
Loss: 0.48420258530291055
ROC train: 0.715249	val: 0.601911	test: 0.607299
PRC train: 0.704121	val: 0.638400	test: 0.612998

Epoch: 15
Loss: 0.4770806724616202
ROC train: 0.719653	val: 0.600404	test: 0.602496
PRC train: 0.710795	val: 0.640160	test: 0.614678

Epoch: 16
Loss: 0.47906803754956845
ROC train: 0.725332	val: 0.611293	test: 0.601523
PRC train: 0.713941	val: 0.647681	test: 0.618679

Epoch: 17
Loss: 0.4701501402019905
ROC train: 0.726932	val: 0.613774	test: 0.596829
PRC train: 0.714472	val: 0.651982	test: 0.610884

Epoch: 18
Loss: 0.47022334200654614
ROC train: 0.729737	val: 0.603947	test: 0.590475
PRC train: 0.716564	val: 0.650092	test: 0.612557

Epoch: 19
Loss: 0.4705463718209376
ROC train: 0.741587	val: 0.607678	test: 0.595780
PRC train: 0.724378	val: 0.650867	test: 0.614173

Epoch: 20
Loss: 0.46692061930195383
ROC train: 0.746840	val: 0.621786	test: 0.595751
PRC train: 0.728439	val: 0.653457	test: 0.605653

Epoch: 21
Loss: 0.46284360050446
ROC train: 0.748754	val: 0.623304	test: 0.593282
PRC train: 0.731249	val: 0.647845	test: 0.601055

Epoch: 22
Loss: 0.46110987843085144
ROC train: 0.745080	val: 0.611873	test: 0.597061
PRC train: 0.726657	val: 0.644440	test: 0.607289

Epoch: 23
Loss: 0.4555516463543947
ROC train: 0.753943	val: 0.614826	test: 0.600023
PRC train: 0.732444	val: 0.654052	test: 0.609905

Epoch: 24
Loss: 0.45701306032116273
ROC train: 0.755449	val: 0.623610	test: 0.602169
PRC train: 0.733446	val: 0.663837	test: 0.610103

Epoch: 25
Loss: 0.4555173699065481
ROC train: 0.753572	val: 0.622443	test: 0.599785
PRC train: 0.729803	val: 0.660738	test: 0.611802

Epoch: 26
Loss: 0.45330791410556587
ROC train: 0.761336	val: 0.614904	test: 0.595315
PRC train: 0.736576	val: 0.653940	test: 0.606769

Epoch: 27
Loss: 0.4517997208407024
ROC train: 0.763925	val: 0.597207	test: 0.593934
PRC train: 0.740067	val: 0.642949	test: 0.604547

Epoch: 28
Loss: 0.45314195312274314
ROC train: 0.773127	val: 0.601080	test: 0.598425
PRC train: 0.750671	val: 0.646859	test: 0.605451

Epoch: 29
Loss: 0.4517312840220339
ROC train: 0.779109	val: 0.607921	test: 0.609739
PRC train: 0.751770	val: 0.652808	test: 0.616684

Epoch: 30
Loss: 0.44774418190497
ROC train: 0.781614	val: 0.605961	test: 0.613952
PRC train: 0.754753	val: 0.652685	test: 0.617208

Epoch: 31
Loss: 0.4468921144930705
ROC train: 0.780749	val: 0.609606	test: 0.615945
PRC train: 0.754941	val: 0.657183	test: 0.618668

Epoch: 32
Loss: 0.44442567581277215
ROC train: 0.786465	val: 0.618815	test: 0.614436
PRC train: 0.757429	val: 0.654226	test: 0.616875

Epoch: 33
Loss: 0.440843254789963Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:2
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/random/train_prop=0.8/sider_random_2_20-05_14-43-16  ]
[ Using Seed :  2  ]
[ Using device :  cuda:2  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
randomly split
Data(edge_attr=[38, 2], edge_index=[2, 38], id=[1], x=[18, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6903599163124017
ROC train: 0.552167	val: 0.529769	test: 0.510905
PRC train: 0.594738	val: 0.587513	test: 0.558335

Epoch: 2
Loss: 0.6375510735021572
ROC train: 0.561063	val: 0.541878	test: 0.511258
PRC train: 0.605090	val: 0.602285	test: 0.556776

Epoch: 3
Loss: 0.5936182926927425
ROC train: 0.569015	val: 0.536055	test: 0.513081
PRC train: 0.613261	val: 0.603735	test: 0.558897

Epoch: 4
Loss: 0.5642202441892986
ROC train: 0.591080	val: 0.542137	test: 0.514409
PRC train: 0.624973	val: 0.601194	test: 0.560851

Epoch: 5
Loss: 0.5513636987545061
ROC train: 0.629039	val: 0.570454	test: 0.537453
PRC train: 0.638237	val: 0.603559	test: 0.576728

Epoch: 6
Loss: 0.5398819939400219
ROC train: 0.640887	val: 0.563536	test: 0.541394
PRC train: 0.648437	val: 0.601539	test: 0.580518

Epoch: 7
Loss: 0.5269848370409775
ROC train: 0.653013	val: 0.570552	test: 0.549939
PRC train: 0.659145	val: 0.606616	test: 0.584258

Epoch: 8
Loss: 0.5165045262648945
ROC train: 0.667842	val: 0.588337	test: 0.567558
PRC train: 0.668129	val: 0.613855	test: 0.598584

Epoch: 9
Loss: 0.5097488806528505
ROC train: 0.678553	val: 0.588885	test: 0.569333
PRC train: 0.676057	val: 0.615535	test: 0.598206

Epoch: 10
Loss: 0.5010085503287465
ROC train: 0.685296	val: 0.588259	test: 0.567504
PRC train: 0.680462	val: 0.615137	test: 0.593596

Epoch: 11
Loss: 0.49819292466942794
ROC train: 0.694117	val: 0.601578	test: 0.576417
PRC train: 0.687843	val: 0.625518	test: 0.596839

Epoch: 12
Loss: 0.4921028111988794
ROC train: 0.699882	val: 0.611966	test: 0.579695
PRC train: 0.691860	val: 0.629939	test: 0.599103

Epoch: 13
Loss: 0.48559964299978675
ROC train: 0.703688	val: 0.603736	test: 0.570178
PRC train: 0.695577	val: 0.627824	test: 0.593028

Epoch: 14
Loss: 0.47952447954850924
ROC train: 0.711198	val: 0.603631	test: 0.569638
PRC train: 0.700219	val: 0.628661	test: 0.594281

Epoch: 15
Loss: 0.47836546155813753
ROC train: 0.720020	val: 0.610154	test: 0.578666
PRC train: 0.705947	val: 0.635796	test: 0.600953

Epoch: 16
Loss: 0.4709145554454868
ROC train: 0.725478	val: 0.607076	test: 0.577771
PRC train: 0.710099	val: 0.629970	test: 0.598903

Epoch: 17
Loss: 0.47113558890718527
ROC train: 0.728352	val: 0.603225	test: 0.578030
PRC train: 0.712087	val: 0.623393	test: 0.602364

Epoch: 18
Loss: 0.4733558869994979
ROC train: 0.731587	val: 0.603388	test: 0.581717
PRC train: 0.714501	val: 0.628391	test: 0.602491

Epoch: 19
Loss: 0.4683174608121748
ROC train: 0.741873	val: 0.610221	test: 0.581109
PRC train: 0.720206	val: 0.631665	test: 0.599171

Epoch: 20
Loss: 0.4648450272103486
ROC train: 0.741283	val: 0.627854	test: 0.574366
PRC train: 0.719590	val: 0.645526	test: 0.594164

Epoch: 21
Loss: 0.4629922632950141
ROC train: 0.746984	val: 0.625903	test: 0.572052
PRC train: 0.723720	val: 0.645245	test: 0.594927

Epoch: 22
Loss: 0.4593076990767407
ROC train: 0.750292	val: 0.624086	test: 0.572154
PRC train: 0.726114	val: 0.645769	test: 0.597005

Epoch: 23
Loss: 0.4517132301095977
ROC train: 0.751754	val: 0.623769	test: 0.570750
PRC train: 0.727204	val: 0.644964	test: 0.596549

Epoch: 24
Loss: 0.455462317556061
ROC train: 0.760594	val: 0.614270	test: 0.580349
PRC train: 0.734564	val: 0.636442	test: 0.600855

Epoch: 25
Loss: 0.45299775541935466
ROC train: 0.765345	val: 0.611038	test: 0.591162
PRC train: 0.737613	val: 0.631822	test: 0.606670

Epoch: 26
Loss: 0.4514906475357813
ROC train: 0.767456	val: 0.608487	test: 0.587390
PRC train: 0.739611	val: 0.638546	test: 0.608310

Epoch: 27
Loss: 0.4518216165797799
ROC train: 0.770154	val: 0.618396	test: 0.586675
PRC train: 0.743712	val: 0.646577	test: 0.601625

Epoch: 28
Loss: 0.4517728576887629
ROC train: 0.778497	val: 0.613875	test: 0.580866
PRC train: 0.750035	val: 0.640860	test: 0.598874

Epoch: 29
Loss: 0.45004487259394493
ROC train: 0.781080	val: 0.608207	test: 0.580420
PRC train: 0.751075	val: 0.639965	test: 0.597777

Epoch: 30
Loss: 0.44588430022909387
ROC train: 0.782155	val: 0.618045	test: 0.589429
PRC train: 0.750814	val: 0.649119	test: 0.594526

Epoch: 31
Loss: 0.4490010307642166
ROC train: 0.786501	val: 0.613364	test: 0.586800
PRC train: 0.752519	val: 0.648202	test: 0.593272

Epoch: 32
Loss: 0.44664849479408275
ROC train: 0.786480	val: 0.600511	test: 0.575204
PRC train: 0.755051	val: 0.634357	test: 0.589033

Epoch: 33
Loss: 0.44175128753870296
ROC train: 0.790488	val: 0.612253	test: 0.596449
PRC train: 0.756161	val: 0.657403	test: 0.614441

Epoch: 34
Loss: 0.4382973302039931
ROC train: 0.793083	val: 0.614835	test: 0.596999
PRC train: 0.757851	val: 0.660993	test: 0.611899

Epoch: 35
Loss: 0.4438175238680237
ROC train: 0.799747	val: 0.621891	test: 0.596474
PRC train: 0.764613	val: 0.662898	test: 0.610060

Epoch: 36
Loss: 0.43246834413284285
ROC train: 0.796754	val: 0.612635	test: 0.591908
PRC train: 0.764152	val: 0.655740	test: 0.610369

Epoch: 37
Loss: 0.43519198676333004
ROC train: 0.803899	val: 0.617700	test: 0.601116
PRC train: 0.769468	val: 0.660079	test: 0.617796

Epoch: 38
Loss: 0.43092513814241495
ROC train: 0.802049	val: 0.625690	test: 0.613719
PRC train: 0.765095	val: 0.663987	test: 0.626367

Epoch: 39
Loss: 0.4342213000378879
ROC train: 0.806223	val: 0.627478	test: 0.615587
PRC train: 0.767465	val: 0.660170	test: 0.625949

Epoch: 40
Loss: 0.438351209099791
ROC train: 0.812232	val: 0.622499	test: 0.609946
PRC train: 0.776443	val: 0.661012	test: 0.624986

Epoch: 41
Loss: 0.4299720965670893
ROC train: 0.816214	val: 0.624680	test: 0.610969
PRC train: 0.781958	val: 0.664562	test: 0.627059

Epoch: 42
Loss: 0.42850233037162244
ROC train: 0.814701	val: 0.627678	test: 0.614386
PRC train: 0.780590	val: 0.665038	test: 0.632497

Epoch: 43
Loss: 0.4292751011991367
ROC train: 0.814800	val: 0.630497	test: 0.617000
PRC train: 0.779555	val: 0.668503	test: 0.633742

Epoch: 44
Loss: 0.42827597684023894
ROC train: 0.819228	val: 0.629247	test: 0.615725
PRC train: 0.782118	val: 0.670005	test: 0.627845

Epoch: 45
Loss: 0.42062264197134647
ROC train: 0.817340	val: 0.624820	test: 0.614777
PRC train: 0.779637	val: 0.658220	test: 0.628294

Epoch: 46
Loss: 0.42222933873030993
ROC train: 0.825852	val: 0.626203	test: 0.614743
PRC train: 0.791592	val: 0.660360	test: 0.626398

Epoch: 47
Loss: 0.4251840554593129
ROC train: 0.826449	val: 0.623426	test: 0.616273
PRC train: 0.789461	val: 0.661519	test: 0.631202

Epoch: 48
Loss: 0.42275089933242876
ROC train: 0.816915	val: 0.619873	test: 0.618039
PRC train: 0.777957	val: 0.654273	test: 0.634629

Epoch: 49
Loss: 0.4194244820121481
ROC train: 0.822549	val: 0.619254	test: 0.614058
PRC train: 0.785696	val: 0.658428	test: 0.627369

Epoch: 50
Loss: 0.409032242141402
ROC train: 0.829233	val: 0.618586	test: 0.606437
PRC train: 0.793904	val: 0.658127	test: 0.624491

Epoch: 51
Loss: 0.4199204722443891
ROC train: 0.832709	val: 0.617430	test: 0.603156
PRC train: 0.797626	val: 0.657111	test: 0.622844

Epoch: 52
Loss: 0.4134099366541485
ROC train: 0.830022	val: 0.611822	test: 0.599411
PRC train: 0.793702	val: 0.651872	test: 0.621653

Epoch: 53
Loss: 0.41868604085255756
ROC train: 0.837290	val: 0.622443	test: 0.606795
PRC train: 0.800168	val: 0.658879	test: 0.625608

Epoch: 54
Loss: 0.4156698386840026
ROC train: 0.840851	val: 0.628590	test: 0.609192
PRC train: 0.806223	val: 0.662823	test: 0.625656

Epoch: 55
Loss: 0.40891552463167113
ROC train: 0.844086	val: 0.616707	test: 0.605266
PRC train: 0.807030	val: 0.655899	test: 0.623538

Epoch: 56
Loss: 0.4052116671340519
ROC train: 0.841260	val: 0.615905	test: 0.599354
PRC train: 0.802523	val: 0.653550	test: 0.622866

Epoch: 57
Loss: 0.4031223587091381
ROC train: 0.842357	val: 0.628147	test: 0.598150
PRC train: 0.802995	val: 0.659438	test: 0.621983

Epoch: 58
Loss: 0.40996537159254265
ROC train: 0.844533	val: 0.634275	test: 0.603134
PRC train: 0.803791	val: 0.662996	test: 0.622781

Epoch: 59
Loss: 0.40365505446313155
ROC train: 0.847645	val: 0.630714	test: 0.603008
PRC train: 0.808352	val: 0.658900	test: 0.615877

Epoch: 60
Loss: 0.40005346849828116
ROC train: 0.852300	val: 0.635832	test: 0.605779
PRC train: 0.813364	val: 0.662256	test: 0.617110

Epoch: 61
Loss: 0.40334170904668903
ROC train: 0.852438	val: 0.629916	test: 0.608890
PRC train: 0.815368	val: 0.659646	test: 0.622144

Epoch: 62
Loss: 0.4023003737058364
ROC train: 0.848893	val: 0.634168	test: 0.610230
PRC train: 0.814513	val: 0.659350	test: 0.623908

Epoch: 63
Loss: 0.40445056507960087
ROC train: 0.853329	val: 0.641693	test: 0.611500
PRC train: 0.817111	val: 0.670323	test: 0.623324

Epoch: 64
Loss: 0.3972993128525576
ROC train: 0.856775	val: 0.634775	test: 0.613011
PRC train: 0.817003	val: 0.666655	test: 0.628957

Epoch: 65
Loss: 0.39515944330677577
ROC train: 0.861269	val: 0.626507	test: 0.613576
PRC train: 0.822688	val: 0.657990	test: 0.629093

Epoch: 66
Loss: 0.39319033881481624
ROC train: 0.862484	val: 0.620121	test: 0.608310
PRC train: 0.825748	val: 0.654027	test: 0.628352

Epoch: 67
Loss: 0.3932362933596003
ROC train: 0.864814	val: 0.624695	test: 0.609422
PRC train: 0.826088	val: 0.659455	test: 0.632683

Epoch: 68
Loss: 0.39346784904188814
ROC train: 0.867076	val: 0.627843	test: 0.608417
PRC train: 0.827106	val: 0.661935	test: 0.632039

Epoch: 69
Loss: 0.39480357157755996
ROC train: 0.855623	val: 0.615824	test: 0.600571
PRC train: 0.815843	val: 0.653160	test: 0.627839

Epoch: 70
Loss: 0.38825525161804986
ROC train: 0.864516	val: 0.625460	test: 0.603396
PRC train: 0.825309	val: 0.660655	test: 0.627860

Epoch: 71
Loss: 0.3882521425098459
ROC train: 0.867425	val: 0.628534	test: 0.607295
PRC train: 0.831473	val: 0.661783	test: 0.631309

Epoch: 72
Loss: 0.3876184322826397
ROC train: 0.871762	val: 0.633820	test: 0.610741
PRC train: 0.837140	val: 0.664612	test: 0.632832

Epoch: 73
Loss: 0.3838774783313859
ROC train: 0.873834	val: 0.633752	test: 0.611937
PRC train: 0.835909	val: 0.666851	test: 0.631519

Epoch: 74
Loss: 0.3853602412663831
ROC train: 0.875755	val: 0.630057	test: 0.612883
PRC train: 0.837380	val: 0.662619	test: 0.631223

Epoch: 75
Loss: 0.38420685640996566
ROC train: 0.875603	val: 0.630461	test: 0.614868
PRC train: 0.838674	val: 0.662879	test: 0.632290

Epoch: 76
Loss: 0.3826763894099042
ROC train: 0.874550	val: 0.631395	test: 0.613771
PRC train: 0.836446	val: 0.659798	test: 0.631486

Epoch: 77
Loss: 0.3825767504386151
ROC train: 0.874158	val: 0.633369	test: 0.606976
PRC train: 0.835777	val: 0.658328	test: 0.628863

Epoch: 78
Loss: 0.3726653618578115
ROC train: 0.877748	val: 0.639455	test: 0.612559
PRC train: 0.839002	val: 0.662556	test: 0.631562

Epoch: 79
Loss: 0.3765480690509294
ROC train: 0.880533	val: 0.643012	test: 0.621492
PRC train: 0.843430	val: 0.664797	test: 0.634305

Epoch: 80
Loss: 0.372788394071051
ROC train: 0.881524	val: 0.634953	test: 0.618452
PRC train: 0.844968	val: 0.663612	test: 0.632881

Epoch: 81
Loss: 0.3807089921567345
ROC train: 0.881306	val: 0.630244	test: 0.610960
PRC train: 0.845918	val: 0.659282	test: 0.629011

Epoch: 82
Loss: 0.37815129084795707
ROC train: 0.882794	val: 0.637256	test: 0.610337
PRC train: 0.847864	val: 0.661348	test: 0.630973

Epoch: 83
Loss: 0.3651034935069602
ROC train: 0.883838	val: 0.647333	test: 0.613396
PRC train: 0.848729	val: 0.668449	test: 0.631521

Epoch: 84
Loss: 0.3691509656035505
ROC train: 0.885437	val: 0.643775	test: 0.615624
PRC train: 0.849359	val: 0.667786	test: 0.634399

Epoch: 85
Loss: 0.36948036934134654
ROC train: 0.884746	val: 0.626334	test: 0.612340
PRC train: 0.849763	val: 0.655805	test: 0.633214

Epoch: 86
Loss: 0.36737016794449
ROC train: 0.886250	val: 0.629677	test: 0.610519
PRC train: 0.847865	val: 0.658195	test: 0.632573

Epoch: 87
Loss: 0.3670502722752647
ROC train: 0.889557	val: 0.636881	test: 0.613400
PRC train: 0.852002	val: 0.664624	test: 0.634383

Epoch: 88
Loss: 0.3724478929971652
ROC train: 0.889486	val: 0.629339	test: 0.612165
PRC train: 0.850958	val: 0.659931	test: 0.634547

Epoch: 89
Loss: 0.3691687644808889
ROC train: 0.890763	val: 0.621800	test: 0.607714
PRC train: 0.854754	val: 0.655482	test: 0.632767

Epoch: 90
Loss: 0.36234860319986084
ROC train: 0.891750	val: 0.626889	test: 0.617678
PRC train: 0.856218	val: 0.661911	test: 0.639533

Epoch: 91
Loss: 0.3612461533205741
ROC train: 0.891662	val: 0.626582	test: 0.622385
PRC train: 0.857974	val: 0.657830	test: 0.643131

Epoch: 92
Loss: 0.3683737541464051
ROC train: 0.891109	val: 0.626300	test: 0.621893
PRC train: 0.857430	val: 0.654803	test: 0.643279

Epoch: 93
Loss: 0.35743927712990575
ROC train: 0.896303	val: 0.632786	test: 0.620323
PRC train: 0.863871	val: 0.661300	test: 0.640718

Epoch: 94
Loss: 0.36128175746059493
ROC train: 0.782058	val: 0.637580	test: 0.592397
PRC train: 0.747069	val: 0.672084	test: 0.604194

Epoch: 34
Loss: 0.4419660089187687
ROC train: 0.788436	val: 0.628611	test: 0.590492
PRC train: 0.751104	val: 0.666091	test: 0.603229

Epoch: 35
Loss: 0.4424108665372265
ROC train: 0.791716	val: 0.623807	test: 0.591821
PRC train: 0.754221	val: 0.661641	test: 0.604801

Epoch: 36
Loss: 0.4359265339053452
ROC train: 0.799886	val: 0.635074	test: 0.593742
PRC train: 0.759794	val: 0.670092	test: 0.602180

Epoch: 37
Loss: 0.442239047156643
ROC train: 0.800753	val: 0.643033	test: 0.591040
PRC train: 0.759144	val: 0.671617	test: 0.600212

Epoch: 38
Loss: 0.4331158938766382
ROC train: 0.797219	val: 0.641958	test: 0.588723
PRC train: 0.756520	val: 0.667282	test: 0.600499

Epoch: 39
Loss: 0.4300791198413762
ROC train: 0.802787	val: 0.643914	test: 0.596129
PRC train: 0.763366	val: 0.669703	test: 0.605078

Epoch: 40
Loss: 0.4299086953890871
ROC train: 0.808583	val: 0.643925	test: 0.597708
PRC train: 0.769752	val: 0.671646	test: 0.609039

Epoch: 41
Loss: 0.4319253212137436
ROC train: 0.813158	val: 0.643872	test: 0.596093
PRC train: 0.774108	val: 0.672499	test: 0.609394

Epoch: 42
Loss: 0.424068309280816
ROC train: 0.812275	val: 0.635678	test: 0.592061
PRC train: 0.774428	val: 0.667429	test: 0.605981

Epoch: 43
Loss: 0.4219129341664606
ROC train: 0.810936	val: 0.631972	test: 0.589601
PRC train: 0.771773	val: 0.662678	test: 0.607714

Epoch: 44
Loss: 0.42543602313320683
ROC train: 0.819062	val: 0.633717	test: 0.590867
PRC train: 0.777642	val: 0.666858	test: 0.606898

Epoch: 45
Loss: 0.4252307505156452
ROC train: 0.822502	val: 0.635856	test: 0.593463
PRC train: 0.779490	val: 0.669503	test: 0.606115

Epoch: 46
Loss: 0.42191391731326555
ROC train: 0.824941	val: 0.638336	test: 0.597565
PRC train: 0.779410	val: 0.665628	test: 0.605788

Epoch: 47
Loss: 0.41946586010724907
ROC train: 0.824783	val: 0.648297	test: 0.596789
PRC train: 0.781351	val: 0.664861	test: 0.603082

Epoch: 48
Loss: 0.41621211742806274
ROC train: 0.824291	val: 0.653951	test: 0.594936
PRC train: 0.782533	val: 0.666182	test: 0.600902

Epoch: 49
Loss: 0.41971636297915405
ROC train: 0.828673	val: 0.654202	test: 0.595437
PRC train: 0.786889	val: 0.666470	test: 0.602166

Epoch: 50
Loss: 0.4177946174075901
ROC train: 0.827681	val: 0.636399	test: 0.593639
PRC train: 0.785664	val: 0.658599	test: 0.603493

Epoch: 51
Loss: 0.42706852755673114
ROC train: 0.829706	val: 0.627331	test: 0.588134
PRC train: 0.786189	val: 0.654855	test: 0.602435

Epoch: 52
Loss: 0.4082347097578896
ROC train: 0.834875	val: 0.632635	test: 0.590137
PRC train: 0.793388	val: 0.662398	test: 0.602297

Epoch: 53
Loss: 0.4140513822192228
ROC train: 0.838820	val: 0.638366	test: 0.597331
PRC train: 0.797249	val: 0.669495	test: 0.606717

Epoch: 54
Loss: 0.4101616958187919
ROC train: 0.843285	val: 0.645212	test: 0.599077
PRC train: 0.799088	val: 0.673948	test: 0.606799

Epoch: 55
Loss: 0.4045667344245577
ROC train: 0.843248	val: 0.642890	test: 0.598542
PRC train: 0.798910	val: 0.667273	test: 0.608146

Epoch: 56
Loss: 0.40441744047271727
ROC train: 0.841412	val: 0.638435	test: 0.592767
PRC train: 0.798736	val: 0.660403	test: 0.605049

Epoch: 57
Loss: 0.4168024254113318
ROC train: 0.843478	val: 0.632554	test: 0.591450
PRC train: 0.801840	val: 0.657702	test: 0.602187

Epoch: 58
Loss: 0.4107644165961467
ROC train: 0.843650	val: 0.628935	test: 0.589536
PRC train: 0.801671	val: 0.657475	test: 0.599728

Epoch: 59
Loss: 0.3951273970353696
ROC train: 0.849790	val: 0.629100	test: 0.587894
PRC train: 0.806359	val: 0.657457	test: 0.599343

Epoch: 60
Loss: 0.4032310560629272
ROC train: 0.851186	val: 0.631099	test: 0.588557
PRC train: 0.806691	val: 0.663180	test: 0.603278

Epoch: 61
Loss: 0.4009005870480437
ROC train: 0.849910	val: 0.638888	test: 0.593454
PRC train: 0.803624	val: 0.670224	test: 0.606157

Epoch: 62
Loss: 0.3932561956986342
ROC train: 0.852263	val: 0.633521	test: 0.588345
PRC train: 0.805462	val: 0.662447	test: 0.605390

Epoch: 63
Loss: 0.40153827220425986
ROC train: 0.854027	val: 0.630222	test: 0.583783
PRC train: 0.809467	val: 0.659847	test: 0.601694

Epoch: 64
Loss: 0.39965584209614397
ROC train: 0.853982	val: 0.631348	test: 0.583822
PRC train: 0.810287	val: 0.662714	test: 0.600969

Epoch: 65
Loss: 0.3874734755008179
ROC train: 0.856214	val: 0.635219	test: 0.586912
PRC train: 0.815979	val: 0.665027	test: 0.604654

Epoch: 66
Loss: 0.3955814962947885
ROC train: 0.859261	val: 0.637252	test: 0.590327
PRC train: 0.819110	val: 0.667305	test: 0.605735

Epoch: 67
Loss: 0.3939049454843938
ROC train: 0.864822	val: 0.642495	test: 0.594629
PRC train: 0.823420	val: 0.670272	test: 0.607612

Epoch: 68
Loss: 0.38610147337475775
ROC train: 0.866346	val: 0.642676	test: 0.594287
PRC train: 0.823417	val: 0.668220	test: 0.607587

Epoch: 69
Loss: 0.3934254132275082
ROC train: 0.864052	val: 0.634963	test: 0.594352
PRC train: 0.821255	val: 0.661751	test: 0.610505

Epoch: 70
Loss: 0.39254653202344236
ROC train: 0.862611	val: 0.631977	test: 0.597491
PRC train: 0.821942	val: 0.658562	test: 0.614407

Epoch: 71
Loss: 0.39018240734995124
ROC train: 0.867884	val: 0.629573	test: 0.607752
PRC train: 0.825587	val: 0.659895	test: 0.619020

Epoch: 72
Loss: 0.38571437942418546
ROC train: 0.867888	val: 0.633153	test: 0.605743
PRC train: 0.824191	val: 0.664077	test: 0.618096

Epoch: 73
Loss: 0.3856353259566692
ROC train: 0.869291	val: 0.633673	test: 0.602480
PRC train: 0.826388	val: 0.663392	test: 0.615685

Epoch: 74
Loss: 0.37218047078873373
ROC train: 0.866477	val: 0.630728	test: 0.594929
PRC train: 0.822187	val: 0.660157	test: 0.611148

Epoch: 75
Loss: 0.38764228884355856
ROC train: 0.870835	val: 0.628955	test: 0.595703
PRC train: 0.827268	val: 0.656759	test: 0.611187

Epoch: 76
Loss: 0.38011123556858234
ROC train: 0.873282	val: 0.632863	test: 0.597240
PRC train: 0.831389	val: 0.661653	test: 0.614557

Epoch: 77
Loss: 0.3793441390419111
ROC train: 0.871834	val: 0.628460	test: 0.599465
PRC train: 0.828542	val: 0.658635	test: 0.617464

Epoch: 78
Loss: 0.38218539998307327
ROC train: 0.876961	val: 0.628956	test: 0.608342
PRC train: 0.833262	val: 0.659949	test: 0.620206

Epoch: 79
Loss: 0.3715956271850444
ROC train: 0.877274	val: 0.631698	test: 0.608771
PRC train: 0.835067	val: 0.661945	test: 0.619406

Epoch: 80
Loss: 0.3817145693516857
ROC train: 0.875323	val: 0.634374	test: 0.596350
PRC train: 0.833199	val: 0.661894	test: 0.614645

Epoch: 81
Loss: 0.37319076825178904
ROC train: 0.876799	val: 0.637558	test: 0.593134
PRC train: 0.835472	val: 0.666030	test: 0.613909

Epoch: 82
Loss: 0.37423860555826316
ROC train: 0.880304	val: 0.639576	test: 0.600493
PRC train: 0.837579	val: 0.670207	test: 0.617663

Epoch: 83
Loss: 0.37606516401997714
ROC train: 0.885564	val: 0.633811	test: 0.600265
PRC train: 0.844347	val: 0.665113	test: 0.616260

Epoch: 84
Loss: 0.3729496281552749
ROC train: 0.888591	val: 0.630162	test: 0.597428
PRC train: 0.846943	val: 0.661099	test: 0.616669

Epoch: 85
Loss: 0.36888538519329633
ROC train: 0.888424	val: 0.634987	test: 0.597223
PRC train: 0.845559	val: 0.661637	test: 0.618638

Epoch: 86
Loss: 0.3708824029321286
ROC train: 0.886331	val: 0.636694	test: 0.601839
PRC train: 0.843973	val: 0.662957	test: 0.620831

Epoch: 87
Loss: 0.3658718020911875
ROC train: 0.887445	val: 0.637351	test: 0.604251
PRC train: 0.845275	val: 0.661879	test: 0.621068

Epoch: 88
Loss: 0.36671052846775365
ROC train: 0.891004	val: 0.630435	test: 0.602067
PRC train: 0.851954	val: 0.656938	test: 0.616301

Epoch: 89
Loss: 0.3653956738560063
ROC train: 0.892108	val: 0.626900	test: 0.599343
PRC train: 0.851665	val: 0.656154	test: 0.614292

Epoch: 90
Loss: 0.36328670494188264
ROC train: 0.895425	val: 0.631353	test: 0.597926
PRC train: 0.855624	val: 0.659773	test: 0.615863

Epoch: 91
Loss: 0.3628811747616849
ROC train: 0.895975	val: 0.633814	test: 0.596815
PRC train: 0.854970	val: 0.660574	test: 0.614808

Epoch: 92
Loss: 0.3593320018945084
ROC train: 0.897094	val: 0.633259	test: 0.594649
PRC train: 0.856720	val: 0.662206	test: 0.615908

Epoch: 93
Loss: 0.3527068827331753
ROC train: 0.892865	val: 0.622395	test: 0.590670
PRC train: 0.853812	val: 0.655305	test: 0.614903

Epoch: 94
Loss: 0.3579403067211406
ROC train: 0.791766	val: 0.631920	test: 0.605866
PRC train: 0.754030	val: 0.675580	test: 0.615067

Epoch: 34
Loss: 0.4444465757409949
ROC train: 0.790881	val: 0.628715	test: 0.599206
PRC train: 0.752002	val: 0.668750	test: 0.611280

Epoch: 35
Loss: 0.43938237584506656
ROC train: 0.795228	val: 0.632904	test: 0.601810
PRC train: 0.756929	val: 0.671581	test: 0.611966

Epoch: 36
Loss: 0.43349059370813775
ROC train: 0.797976	val: 0.633739	test: 0.605930
PRC train: 0.760272	val: 0.668230	test: 0.612809

Epoch: 37
Loss: 0.43383955121814555
ROC train: 0.798258	val: 0.628600	test: 0.595256
PRC train: 0.760219	val: 0.661636	test: 0.607700

Epoch: 38
Loss: 0.432275342392445
ROC train: 0.804784	val: 0.629724	test: 0.592564
PRC train: 0.764759	val: 0.664251	test: 0.607130

Epoch: 39
Loss: 0.43200991899116686
ROC train: 0.810584	val: 0.632464	test: 0.596898
PRC train: 0.771366	val: 0.668313	test: 0.606810

Epoch: 40
Loss: 0.4237372960970438
ROC train: 0.810968	val: 0.628331	test: 0.601795
PRC train: 0.770536	val: 0.669164	test: 0.609036

Epoch: 41
Loss: 0.43409638051050187
ROC train: 0.813636	val: 0.628355	test: 0.602596
PRC train: 0.773799	val: 0.671175	test: 0.613562

Epoch: 42
Loss: 0.43737881659049266
ROC train: 0.817627	val: 0.631811	test: 0.598159
PRC train: 0.775411	val: 0.667539	test: 0.612765

Epoch: 43
Loss: 0.42994845499234624
ROC train: 0.820045	val: 0.634130	test: 0.602315
PRC train: 0.773068	val: 0.664951	test: 0.613050

Epoch: 44
Loss: 0.43376185100597425
ROC train: 0.818607	val: 0.631290	test: 0.608594
PRC train: 0.774333	val: 0.663415	test: 0.614006

Epoch: 45
Loss: 0.4263666803545012
ROC train: 0.810953	val: 0.620065	test: 0.598670
PRC train: 0.770562	val: 0.654944	test: 0.613122

Epoch: 46
Loss: 0.42177917936887493
ROC train: 0.816286	val: 0.624486	test: 0.596608
PRC train: 0.776328	val: 0.660588	test: 0.611480

Epoch: 47
Loss: 0.4145389791983935
ROC train: 0.829524	val: 0.632825	test: 0.600363
PRC train: 0.787230	val: 0.669896	test: 0.612839

Epoch: 48
Loss: 0.42636493769957584
ROC train: 0.833823	val: 0.626319	test: 0.598092
PRC train: 0.787146	val: 0.663205	test: 0.610572

Epoch: 49
Loss: 0.43134624566162266
ROC train: 0.832686	val: 0.621085	test: 0.598117
PRC train: 0.785740	val: 0.656356	test: 0.614040

Epoch: 50
Loss: 0.41705608728992405
ROC train: 0.829731	val: 0.624546	test: 0.591419
PRC train: 0.785523	val: 0.661061	test: 0.611848

Epoch: 51
Loss: 0.41761894371685493
ROC train: 0.832499	val: 0.626398	test: 0.592087
PRC train: 0.789869	val: 0.661845	test: 0.610340

Epoch: 52
Loss: 0.4213442003412782
ROC train: 0.831111	val: 0.626179	test: 0.595951
PRC train: 0.787321	val: 0.659391	test: 0.614642

Epoch: 53
Loss: 0.41487481620923927
ROC train: 0.834001	val: 0.629115	test: 0.601159
PRC train: 0.790517	val: 0.663312	test: 0.621004

Epoch: 54
Loss: 0.41916239195574584
ROC train: 0.833237	val: 0.628025	test: 0.601603
PRC train: 0.789010	val: 0.665794	test: 0.616344

Epoch: 55
Loss: 0.4129634538960828
ROC train: 0.839383	val: 0.630238	test: 0.603647
PRC train: 0.795282	val: 0.668428	test: 0.613515

Epoch: 56
Loss: 0.41168042173116004
ROC train: 0.845023	val: 0.631940	test: 0.604145
PRC train: 0.799722	val: 0.666716	test: 0.618593

Epoch: 57
Loss: 0.4152932946475181
ROC train: 0.840702	val: 0.626869	test: 0.599216
PRC train: 0.795364	val: 0.660256	test: 0.618529

Epoch: 58
Loss: 0.4022983397020064
ROC train: 0.841189	val: 0.624450	test: 0.602459
PRC train: 0.797399	val: 0.660545	test: 0.619186

Epoch: 59
Loss: 0.40860849863902354
ROC train: 0.848934	val: 0.625598	test: 0.604029
PRC train: 0.804637	val: 0.662156	test: 0.617464

Epoch: 60
Loss: 0.4040669636787792
ROC train: 0.854026	val: 0.625960	test: 0.597155
PRC train: 0.808810	val: 0.663380	test: 0.612269

Epoch: 61
Loss: 0.4029994324337936
ROC train: 0.853424	val: 0.611213	test: 0.593114
PRC train: 0.806747	val: 0.651221	test: 0.609087

Epoch: 62
Loss: 0.4152519509063472
ROC train: 0.854567	val: 0.615664	test: 0.600309
PRC train: 0.808835	val: 0.650254	test: 0.616591

Epoch: 63
Loss: 0.4053522425078133
ROC train: 0.849220	val: 0.630151	test: 0.614896
PRC train: 0.807099	val: 0.659943	test: 0.629621

Epoch: 64
Loss: 0.40826833584430755
ROC train: 0.851883	val: 0.634654	test: 0.612239
PRC train: 0.809613	val: 0.662854	test: 0.630424

Epoch: 65
Loss: 0.39521013645779046
ROC train: 0.858292	val: 0.631922	test: 0.606028
PRC train: 0.811942	val: 0.664465	test: 0.626006

Epoch: 66
Loss: 0.3996769867287433
ROC train: 0.861376	val: 0.631199	test: 0.600947
PRC train: 0.815223	val: 0.665659	test: 0.622393

Epoch: 67
Loss: 0.3941810401968958
ROC train: 0.861056	val: 0.630283	test: 0.601486
PRC train: 0.815200	val: 0.665484	test: 0.618800

Epoch: 68
Loss: 0.38953942913097167
ROC train: 0.863012	val: 0.631765	test: 0.607472
PRC train: 0.819251	val: 0.665787	test: 0.621195

Epoch: 69
Loss: 0.3837219728798964
ROC train: 0.867140	val: 0.630054	test: 0.609971
PRC train: 0.825478	val: 0.663178	test: 0.623432

Epoch: 70
Loss: 0.39494462789558094
ROC train: 0.867551	val: 0.627985	test: 0.611522
PRC train: 0.826772	val: 0.661748	test: 0.626466

Epoch: 71
Loss: 0.3902399178849959
ROC train: 0.872322	val: 0.632824	test: 0.609575
PRC train: 0.832098	val: 0.665400	test: 0.625847

Epoch: 72
Loss: 0.3842851988432454
ROC train: 0.873721	val: 0.638287	test: 0.603425
PRC train: 0.835318	val: 0.668300	test: 0.622519

Epoch: 73
Loss: 0.3794479647274124
ROC train: 0.872959	val: 0.636883	test: 0.603587
PRC train: 0.831381	val: 0.664983	test: 0.622438

Epoch: 74
Loss: 0.4027185450289268
ROC train: 0.874291	val: 0.636572	test: 0.605366
PRC train: 0.830625	val: 0.666914	test: 0.621627

Epoch: 75
Loss: 0.3877721373510894
ROC train: 0.874137	val: 0.633030	test: 0.600163
PRC train: 0.828734	val: 0.668091	test: 0.617288

Epoch: 76
Loss: 0.3829839286546464
ROC train: 0.877846	val: 0.625264	test: 0.598339
PRC train: 0.830099	val: 0.661656	test: 0.622428

Epoch: 77
Loss: 0.38241504846656277
ROC train: 0.880916	val: 0.627599	test: 0.599682
PRC train: 0.836067	val: 0.660594	test: 0.625423

Epoch: 78
Loss: 0.373268341229114
ROC train: 0.880586	val: 0.640082	test: 0.607485
PRC train: 0.834685	val: 0.669819	test: 0.630508

Epoch: 79
Loss: 0.38215645287862066
ROC train: 0.884279	val: 0.643561	test: 0.611606
PRC train: 0.838017	val: 0.670612	test: 0.630895

Epoch: 80
Loss: 0.37315964726607526
ROC train: 0.883385	val: 0.637050	test: 0.606452
PRC train: 0.837779	val: 0.666684	test: 0.626216

Epoch: 81
Loss: 0.37549763398369307
ROC train: 0.884679	val: 0.640914	test: 0.603445
PRC train: 0.839675	val: 0.673908	test: 0.622521

Epoch: 82
Loss: 0.37514595966869346
ROC train: 0.883865	val: 0.641749	test: 0.602394
PRC train: 0.839868	val: 0.673098	test: 0.621941

Epoch: 83
Loss: 0.37108423983381145
ROC train: 0.882698	val: 0.637715	test: 0.597943
PRC train: 0.837708	val: 0.666297	test: 0.619297

Epoch: 84
Loss: 0.3744424515407793
ROC train: 0.889142	val: 0.634737	test: 0.599492
PRC train: 0.842424	val: 0.664077	test: 0.619125

Epoch: 85
Loss: 0.37495572876762007
ROC train: 0.892765	val: 0.632509	test: 0.600899
PRC train: 0.848493	val: 0.663485	test: 0.620317

Epoch: 86
Loss: 0.37042317157302407
ROC train: 0.884327	val: 0.628737	test: 0.601568
PRC train: 0.838153	val: 0.659647	test: 0.620875

Epoch: 87
Loss: 0.3773404984921782
ROC train: 0.890833	val: 0.637768	test: 0.605669
PRC train: 0.845619	val: 0.670490	test: 0.624760

Epoch: 88
Loss: 0.3686926635735148
ROC train: 0.891857	val: 0.635568	test: 0.598949
PRC train: 0.847176	val: 0.672486	test: 0.622389

Epoch: 89
Loss: 0.3660693098309622
ROC train: 0.888085	val: 0.630764	test: 0.597422
PRC train: 0.846165	val: 0.670199	test: 0.619587

Epoch: 90
Loss: 0.3639791960645235
ROC train: 0.894519	val: 0.633252	test: 0.600479
PRC train: 0.850879	val: 0.670325	test: 0.623853

Epoch: 91
Loss: 0.36206558848148246
ROC train: 0.898092	val: 0.635521	test: 0.601547
PRC train: 0.853370	val: 0.667199	test: 0.627894

Epoch: 92
Loss: 0.36588983135228503
ROC train: 0.895408	val: 0.638061	test: 0.600390
PRC train: 0.847422	val: 0.663624	test: 0.628633

Epoch: 93
Loss: 0.3674520534966464
ROC train: 0.899017	val: 0.644994	test: 0.601601
PRC train: 0.854430	val: 0.670178	test: 0.623566

Epoch: 94
Loss: 0.355472688602133
ROC train: 0.795677	val: 0.608547	test: 0.606495
PRC train: 0.758003	val: 0.676760	test: 0.610188

Epoch: 34
Loss: 0.4349994863069796
ROC train: 0.798463	val: 0.614265	test: 0.603047
PRC train: 0.760479	val: 0.683506	test: 0.610092

Epoch: 35
Loss: 0.43115552084966224
ROC train: 0.800500	val: 0.614897	test: 0.607958
PRC train: 0.761744	val: 0.691779	test: 0.611993

Epoch: 36
Loss: 0.4302225648734196
ROC train: 0.804503	val: 0.621006	test: 0.613746
PRC train: 0.764210	val: 0.693858	test: 0.614735

Epoch: 37
Loss: 0.4292675135885442
ROC train: 0.807524	val: 0.606291	test: 0.606867
PRC train: 0.767600	val: 0.680180	test: 0.610378

Epoch: 38
Loss: 0.43009223925977574
ROC train: 0.805142	val: 0.602073	test: 0.598363
PRC train: 0.766909	val: 0.672345	test: 0.606624

Epoch: 39
Loss: 0.4280286295854478
ROC train: 0.813215	val: 0.607223	test: 0.609023
PRC train: 0.773055	val: 0.678544	test: 0.613664

Epoch: 40
Loss: 0.4234537106919792
ROC train: 0.819317	val: 0.613233	test: 0.615266
PRC train: 0.777001	val: 0.682503	test: 0.618715

Epoch: 41
Loss: 0.4270067187057132
ROC train: 0.818462	val: 0.612775	test: 0.610637
PRC train: 0.776466	val: 0.679823	test: 0.616767

Epoch: 42
Loss: 0.4225368231337112
ROC train: 0.820381	val: 0.615125	test: 0.610401
PRC train: 0.777806	val: 0.680000	test: 0.614853

Epoch: 43
Loss: 0.42253574805461835
ROC train: 0.826564	val: 0.613268	test: 0.613162
PRC train: 0.783462	val: 0.679401	test: 0.616993

Epoch: 44
Loss: 0.41893211375055434
ROC train: 0.829146	val: 0.614118	test: 0.610793
PRC train: 0.787781	val: 0.685170	test: 0.617080

Epoch: 45
Loss: 0.4184197880574576
ROC train: 0.827889	val: 0.611599	test: 0.606397
PRC train: 0.788063	val: 0.688388	test: 0.617178

Epoch: 46
Loss: 0.41672072811849104
ROC train: 0.831127	val: 0.611656	test: 0.606000
PRC train: 0.790288	val: 0.687584	test: 0.616297

Epoch: 47
Loss: 0.41246345178625954
ROC train: 0.835078	val: 0.614828	test: 0.607879
PRC train: 0.792325	val: 0.686862	test: 0.616305

Epoch: 48
Loss: 0.41506796521157924
ROC train: 0.835506	val: 0.616212	test: 0.605105
PRC train: 0.793320	val: 0.686004	test: 0.615760

Epoch: 49
Loss: 0.4117871716139845
ROC train: 0.838928	val: 0.616920	test: 0.604716
PRC train: 0.798651	val: 0.691176	test: 0.614126

Epoch: 50
Loss: 0.41107647600005764
ROC train: 0.843212	val: 0.614129	test: 0.604448
PRC train: 0.802132	val: 0.684672	test: 0.614218

Epoch: 51
Loss: 0.4048309631527274
ROC train: 0.845927	val: 0.605967	test: 0.609616
PRC train: 0.802895	val: 0.678419	test: 0.617851

Epoch: 52
Loss: 0.4071538071318491
ROC train: 0.847109	val: 0.612208	test: 0.615690
PRC train: 0.804016	val: 0.684059	test: 0.624205

Epoch: 53
Loss: 0.4062759296947537
ROC train: 0.848872	val: 0.613755	test: 0.614749
PRC train: 0.807157	val: 0.684355	test: 0.623940

Epoch: 54
Loss: 0.4013865956354122
ROC train: 0.849476	val: 0.619662	test: 0.617135
PRC train: 0.808917	val: 0.690755	test: 0.626901

Epoch: 55
Loss: 0.4002495526468875
ROC train: 0.850324	val: 0.621436	test: 0.617899
PRC train: 0.809744	val: 0.688540	test: 0.625220

Epoch: 56
Loss: 0.4021402390116125
ROC train: 0.852671	val: 0.624031	test: 0.610606
PRC train: 0.812404	val: 0.689163	test: 0.618809

Epoch: 57
Loss: 0.3970085801252756
ROC train: 0.852715	val: 0.618304	test: 0.601213
PRC train: 0.812705	val: 0.683661	test: 0.614051

Epoch: 58
Loss: 0.40044107103533644
ROC train: 0.853511	val: 0.614285	test: 0.607314
PRC train: 0.811191	val: 0.682417	test: 0.617922

Epoch: 59
Loss: 0.39782387854257883
ROC train: 0.855659	val: 0.612440	test: 0.616276
PRC train: 0.811829	val: 0.686700	test: 0.623121

Epoch: 60
Loss: 0.3907824441364508
ROC train: 0.861364	val: 0.618836	test: 0.619192
PRC train: 0.818017	val: 0.693100	test: 0.626491

Epoch: 61
Loss: 0.39545717816124976
ROC train: 0.862096	val: 0.618710	test: 0.614289
PRC train: 0.820340	val: 0.689313	test: 0.623278

Epoch: 62
Loss: 0.38900459069999527
ROC train: 0.863277	val: 0.616325	test: 0.610418
PRC train: 0.820562	val: 0.684882	test: 0.620844

Epoch: 63
Loss: 0.3900173310553916
ROC train: 0.867267	val: 0.616763	test: 0.617134
PRC train: 0.821847	val: 0.690041	test: 0.625824

Epoch: 64
Loss: 0.3938783810830507
ROC train: 0.867079	val: 0.615222	test: 0.612034
PRC train: 0.821378	val: 0.689997	test: 0.623995

Epoch: 65
Loss: 0.3940335305219536
ROC train: 0.868666	val: 0.621344	test: 0.608158
PRC train: 0.824509	val: 0.695321	test: 0.620379

Epoch: 66
Loss: 0.38597292653582826
ROC train: 0.869095	val: 0.620589	test: 0.599965
PRC train: 0.826199	val: 0.691164	test: 0.616362

Epoch: 67
Loss: 0.38545121566821483
ROC train: 0.872401	val: 0.620031	test: 0.601351
PRC train: 0.830313	val: 0.687788	test: 0.618629

Epoch: 68
Loss: 0.38171861839500754
ROC train: 0.874578	val: 0.621233	test: 0.613076
PRC train: 0.831410	val: 0.692478	test: 0.626872

Epoch: 69
Loss: 0.3776626687842484
ROC train: 0.874495	val: 0.621805	test: 0.614112
PRC train: 0.830536	val: 0.692739	test: 0.626212

Epoch: 70
Loss: 0.37998147628589984
ROC train: 0.879659	val: 0.619836	test: 0.614705
PRC train: 0.834735	val: 0.691823	test: 0.626937

Epoch: 71
Loss: 0.3810843783414141
ROC train: 0.880620	val: 0.619663	test: 0.618664
PRC train: 0.835124	val: 0.690772	test: 0.629922

Epoch: 72
Loss: 0.37899975564079724
ROC train: 0.877799	val: 0.619685	test: 0.617937
PRC train: 0.832795	val: 0.691422	test: 0.630471

Epoch: 73
Loss: 0.3776239352310211
ROC train: 0.882542	val: 0.623295	test: 0.614199
PRC train: 0.839293	val: 0.688892	test: 0.628339

Epoch: 74
Loss: 0.3745049921850624
ROC train: 0.886060	val: 0.629956	test: 0.613054
PRC train: 0.841907	val: 0.688622	test: 0.625055

Epoch: 75
Loss: 0.36972703824454195
ROC train: 0.886653	val: 0.630679	test: 0.615681
PRC train: 0.842578	val: 0.692257	test: 0.626660

Epoch: 76
Loss: 0.3708947725344645
ROC train: 0.886535	val: 0.626474	test: 0.614302
PRC train: 0.842032	val: 0.692679	test: 0.625648

Epoch: 77
Loss: 0.37209748529752684
ROC train: 0.886527	val: 0.624364	test: 0.612615
PRC train: 0.845687	val: 0.691143	test: 0.626212

Epoch: 78
Loss: 0.3717169003879161
ROC train: 0.889341	val: 0.622454	test: 0.612215
PRC train: 0.849487	val: 0.688483	test: 0.628814

Epoch: 79
Loss: 0.37124190292120296
ROC train: 0.887773	val: 0.624023	test: 0.614645
PRC train: 0.847013	val: 0.691229	test: 0.630016

Epoch: 80
Loss: 0.370048347084101
ROC train: 0.891763	val: 0.625900	test: 0.617573
PRC train: 0.850230	val: 0.695524	test: 0.631667

Epoch: 81
Loss: 0.36336961039405485
ROC train: 0.891217	val: 0.622999	test: 0.615256
PRC train: 0.848389	val: 0.687537	test: 0.628142

Epoch: 82
Loss: 0.36519753211381856
ROC train: 0.893757	val: 0.625230	test: 0.609856
PRC train: 0.851467	val: 0.687056	test: 0.623887

Epoch: 83
Loss: 0.362531569631964
ROC train: 0.896136	val: 0.630755	test: 0.607098
PRC train: 0.853822	val: 0.693586	test: 0.621926

Epoch: 84
Loss: 0.36284844469660077
ROC train: 0.897359	val: 0.632151	test: 0.608958
PRC train: 0.855112	val: 0.695296	test: 0.623403

Epoch: 85
Loss: 0.3609100975788135
ROC train: 0.897076	val: 0.629241	test: 0.603241
PRC train: 0.855672	val: 0.690716	test: 0.622053

Epoch: 86
Loss: 0.3610105981940629
ROC train: 0.899403	val: 0.627141	test: 0.604930
PRC train: 0.859258	val: 0.688564	test: 0.623058

Epoch: 87
Loss: 0.3595777973604063
ROC train: 0.900322	val: 0.621766	test: 0.608264
PRC train: 0.860676	val: 0.682175	test: 0.627370

Epoch: 88
Loss: 0.35738339866259294
ROC train: 0.903107	val: 0.620385	test: 0.615150
PRC train: 0.863898	val: 0.684237	test: 0.632363

Epoch: 89
Loss: 0.3532494977635367
ROC train: 0.902197	val: 0.623466	test: 0.618313
PRC train: 0.860980	val: 0.688836	test: 0.634090

Epoch: 90
Loss: 0.35258928361916
ROC train: 0.902488	val: 0.625708	test: 0.617026
PRC train: 0.862397	val: 0.689172	test: 0.633071

Epoch: 91
Loss: 0.3507151466745164
ROC train: 0.902078	val: 0.615279	test: 0.615237
PRC train: 0.864381	val: 0.683914	test: 0.630074

Epoch: 92
Loss: 0.3514496598655572
ROC train: 0.904242	val: 0.619066	test: 0.617339
PRC train: 0.865364	val: 0.687050	test: 0.630990

Epoch: 93
Loss: 0.3492646317646948
ROC train: 0.906627	val: 0.623911	test: 0.613356
PRC train: 0.868954	val: 0.687923	test: 0.627979

Epoch: 94
Loss: 0.3461905365310596
PRC train: 0.754955	val: 0.684362	test: 0.605219

Epoch: 34
Loss: 0.43985856681466395
ROC train: 0.795654	val: 0.619989	test: 0.603604
PRC train: 0.756843	val: 0.683369	test: 0.606813

Epoch: 35
Loss: 0.4389751231281871
ROC train: 0.803258	val: 0.626463	test: 0.607961
PRC train: 0.763166	val: 0.686813	test: 0.607710

Epoch: 36
Loss: 0.4346822790502417
ROC train: 0.806550	val: 0.627847	test: 0.603022
PRC train: 0.765992	val: 0.685687	test: 0.603077

Epoch: 37
Loss: 0.43089461499669834
ROC train: 0.806737	val: 0.624729	test: 0.599284
PRC train: 0.768724	val: 0.688105	test: 0.598789

Epoch: 38
Loss: 0.4292540211777425
ROC train: 0.806729	val: 0.618691	test: 0.592167
PRC train: 0.768664	val: 0.682503	test: 0.595070

Epoch: 39
Loss: 0.42918873310800343
ROC train: 0.812008	val: 0.617862	test: 0.595300
PRC train: 0.771821	val: 0.678244	test: 0.595628

Epoch: 40
Loss: 0.42557464257931166
ROC train: 0.814481	val: 0.616919	test: 0.597219
PRC train: 0.773446	val: 0.676799	test: 0.601177

Epoch: 41
Loss: 0.4258877590784979
ROC train: 0.816425	val: 0.619362	test: 0.603272
PRC train: 0.774063	val: 0.680469	test: 0.605443

Epoch: 42
Loss: 0.4251393800875684
ROC train: 0.821731	val: 0.613726	test: 0.609626
PRC train: 0.779245	val: 0.677173	test: 0.609381

Epoch: 43
Loss: 0.42072737913685576
ROC train: 0.824345	val: 0.611183	test: 0.610026
PRC train: 0.782426	val: 0.676104	test: 0.609558

Epoch: 44
Loss: 0.4173284498998151
ROC train: 0.823272	val: 0.612736	test: 0.606613
PRC train: 0.782931	val: 0.675992	test: 0.607131

Epoch: 45
Loss: 0.4199461224331425
ROC train: 0.824367	val: 0.614236	test: 0.609170
PRC train: 0.783678	val: 0.679900	test: 0.609419

Epoch: 46
Loss: 0.41050457839679616
ROC train: 0.831320	val: 0.616955	test: 0.607641
PRC train: 0.789676	val: 0.681655	test: 0.607805

Epoch: 47
Loss: 0.42127808006326745
ROC train: 0.833755	val: 0.619803	test: 0.609190
PRC train: 0.790754	val: 0.686031	test: 0.611026

Epoch: 48
Loss: 0.41100392906928085
ROC train: 0.833851	val: 0.614769	test: 0.607781
PRC train: 0.791813	val: 0.680782	test: 0.611864

Epoch: 49
Loss: 0.4147300579214628
ROC train: 0.838936	val: 0.616904	test: 0.610151
PRC train: 0.796860	val: 0.680237	test: 0.613082

Epoch: 50
Loss: 0.40706206068832146
ROC train: 0.841099	val: 0.618493	test: 0.609248
PRC train: 0.797803	val: 0.680486	test: 0.612068

Epoch: 51
Loss: 0.41262803554092997
ROC train: 0.842293	val: 0.615946	test: 0.612666
PRC train: 0.799898	val: 0.682760	test: 0.608908

Epoch: 52
Loss: 0.4080115163270704
ROC train: 0.846685	val: 0.619930	test: 0.614907
PRC train: 0.805838	val: 0.683795	test: 0.613772

Epoch: 53
Loss: 0.40947844340316825
ROC train: 0.846743	val: 0.620151	test: 0.611928
PRC train: 0.805928	val: 0.683005	test: 0.617579

Epoch: 54
Loss: 0.4065868243881954
ROC train: 0.847815	val: 0.627523	test: 0.609083
PRC train: 0.805025	val: 0.684276	test: 0.610083

Epoch: 55
Loss: 0.4058952830493424
ROC train: 0.847468	val: 0.625581	test: 0.604731
PRC train: 0.806089	val: 0.685184	test: 0.608123

Epoch: 56
Loss: 0.39986854587218473
ROC train: 0.846243	val: 0.618529	test: 0.602860
PRC train: 0.805788	val: 0.677852	test: 0.605338

Epoch: 57
Loss: 0.4063214839714807
ROC train: 0.850044	val: 0.614159	test: 0.606262
PRC train: 0.811761	val: 0.675967	test: 0.609276

Epoch: 58
Loss: 0.4035961804714955
ROC train: 0.852086	val: 0.612894	test: 0.605393
PRC train: 0.812332	val: 0.674188	test: 0.610184

Epoch: 59
Loss: 0.40049346455403523
ROC train: 0.851252	val: 0.614688	test: 0.604058
PRC train: 0.807306	val: 0.675923	test: 0.608180

Epoch: 60
Loss: 0.3970909055559506
ROC train: 0.854236	val: 0.619525	test: 0.602869
PRC train: 0.810385	val: 0.676977	test: 0.607920

Epoch: 61
Loss: 0.3952221729061406
ROC train: 0.860186	val: 0.621153	test: 0.607553
PRC train: 0.817444	val: 0.681399	test: 0.612986

Epoch: 62
Loss: 0.3958524769915085
ROC train: 0.862695	val: 0.626034	test: 0.611362
PRC train: 0.819281	val: 0.685044	test: 0.617832

Epoch: 63
Loss: 0.3918313684028798
ROC train: 0.860932	val: 0.623380	test: 0.605997
PRC train: 0.817840	val: 0.686050	test: 0.616929

Epoch: 64
Loss: 0.3923294313851322
ROC train: 0.863433	val: 0.620733	test: 0.604649
PRC train: 0.821273	val: 0.685039	test: 0.614007

Epoch: 65
Loss: 0.39319787192894695
ROC train: 0.860327	val: 0.610109	test: 0.598557
PRC train: 0.816618	val: 0.673597	test: 0.607850

Epoch: 66
Loss: 0.38274637210527834
ROC train: 0.863223	val: 0.610584	test: 0.601378
PRC train: 0.820735	val: 0.672187	test: 0.608415

Epoch: 67
Loss: 0.38998007239232463
ROC train: 0.864182	val: 0.612120	test: 0.606668
PRC train: 0.823677	val: 0.671140	test: 0.610614

Epoch: 68
Loss: 0.3905399237188878
ROC train: 0.866031	val: 0.616727	test: 0.610855
PRC train: 0.823970	val: 0.683386	test: 0.609574

Epoch: 69
Loss: 0.38593388804939754
ROC train: 0.870078	val: 0.615782	test: 0.607108
PRC train: 0.829322	val: 0.684968	test: 0.605748

Epoch: 70
Loss: 0.38758419663221994
ROC train: 0.873047	val: 0.617835	test: 0.607146
PRC train: 0.833833	val: 0.675664	test: 0.610055

Epoch: 71
Loss: 0.3824862963921851
ROC train: 0.871257	val: 0.618243	test: 0.606631
PRC train: 0.832052	val: 0.671066	test: 0.612291

Epoch: 72
Loss: 0.3834040452214662
ROC train: 0.871407	val: 0.620189	test: 0.612453
PRC train: 0.832385	val: 0.679275	test: 0.618423

Epoch: 73
Loss: 0.3821930644754963
ROC train: 0.873731	val: 0.620033	test: 0.613618
PRC train: 0.832793	val: 0.679842	test: 0.620911

Epoch: 74
Loss: 0.3780493777317554
ROC train: 0.877684	val: 0.622664	test: 0.608930
PRC train: 0.835289	val: 0.677641	test: 0.616851

Epoch: 75
Loss: 0.37602365853873587
ROC train: 0.879668	val: 0.620756	test: 0.603222
PRC train: 0.839803	val: 0.676522	test: 0.613237

Epoch: 76
Loss: 0.376125759503641
ROC train: 0.880057	val: 0.617780	test: 0.601427
PRC train: 0.839390	val: 0.675691	test: 0.611831

Epoch: 77
Loss: 0.37262364831637446
ROC train: 0.878816	val: 0.617774	test: 0.602371
PRC train: 0.836019	val: 0.678876	test: 0.615038

Epoch: 78
Loss: 0.3746059018007776
ROC train: 0.882090	val: 0.620461	test: 0.609458
PRC train: 0.839041	val: 0.684632	test: 0.618956

Epoch: 79
Loss: 0.37139468929487435
ROC train: 0.885680	val: 0.622368	test: 0.609302
PRC train: 0.843700	val: 0.680829	test: 0.622413

Epoch: 80
Loss: 0.3709413516800681
ROC train: 0.884502	val: 0.616518	test: 0.606288
PRC train: 0.838210	val: 0.673205	test: 0.620710

Epoch: 81
Loss: 0.37042115959002575
ROC train: 0.888737	val: 0.617650	test: 0.611796
PRC train: 0.845915	val: 0.677493	test: 0.622441

Epoch: 82
Loss: 0.37380389579669726
ROC train: 0.887226	val: 0.620688	test: 0.613773
PRC train: 0.847748	val: 0.682122	test: 0.619418

Epoch: 83
Loss: 0.3692441939674464
ROC train: 0.888024	val: 0.615416	test: 0.603769
PRC train: 0.850700	val: 0.681763	test: 0.613203

Epoch: 84
Loss: 0.3693171930142629
ROC train: 0.887668	val: 0.611488	test: 0.598152
PRC train: 0.851021	val: 0.673815	test: 0.611561

Epoch: 85
Loss: 0.36656565429955845
ROC train: 0.889565	val: 0.617985	test: 0.605382
PRC train: 0.853286	val: 0.675929	test: 0.618356

Epoch: 86
Loss: 0.36348733635172475
ROC train: 0.891159	val: 0.621130	test: 0.602402
PRC train: 0.853982	val: 0.680845	test: 0.619818

Epoch: 87
Loss: 0.355314471426906
ROC train: 0.893446	val: 0.621167	test: 0.599768
PRC train: 0.855808	val: 0.680964	test: 0.616519

Epoch: 88
Loss: 0.3637539022166141
ROC train: 0.892371	val: 0.611818	test: 0.605508
PRC train: 0.855658	val: 0.677310	test: 0.618210

Epoch: 89
Loss: 0.359994264205746
ROC train: 0.894608	val: 0.606569	test: 0.609534
PRC train: 0.858486	val: 0.674304	test: 0.620717

Epoch: 90
Loss: 0.35993485656241286
ROC train: 0.894242	val: 0.610107	test: 0.604256
PRC train: 0.857528	val: 0.675115	test: 0.619873

Epoch: 91
Loss: 0.352619960200411
ROC train: 0.895313	val: 0.619828	test: 0.605639
PRC train: 0.858207	val: 0.679539	test: 0.618122

Epoch: 92
Loss: 0.3574370357171518
ROC train: 0.899051	val: 0.621685	test: 0.610116
PRC train: 0.861840	val: 0.680333	test: 0.618686

Epoch: 93
Loss: 0.3510689875452383
ROC train: 0.903576	val: 0.614010	test: 0.610280
PRC train: 0.866862	val: 0.676879	test: 0.620797

Epoch: 94
Loss: 0.35194033434133504
ROC train: 0.904513	val: 0.613070	test: 0.610355
PRC train: 0.765771	val: 0.675915	test: 0.599591

Epoch: 34
Loss: 0.43412111349966226
ROC train: 0.804475	val: 0.609487	test: 0.606568
PRC train: 0.767628	val: 0.687665	test: 0.605436

Epoch: 35
Loss: 0.4333773252255754
ROC train: 0.799948	val: 0.605797	test: 0.605455
PRC train: 0.764565	val: 0.689017	test: 0.604298

Epoch: 36
Loss: 0.4330346239745177
ROC train: 0.802528	val: 0.602021	test: 0.604200
PRC train: 0.766265	val: 0.683059	test: 0.602015

Epoch: 37
Loss: 0.4331627764445014
ROC train: 0.810050	val: 0.602252	test: 0.602610
PRC train: 0.772250	val: 0.679157	test: 0.605890

Epoch: 38
Loss: 0.42810109385796474
ROC train: 0.811535	val: 0.607826	test: 0.599359
PRC train: 0.774966	val: 0.678887	test: 0.606003

Epoch: 39
Loss: 0.43037416489337715
ROC train: 0.814520	val: 0.604436	test: 0.602826
PRC train: 0.778164	val: 0.679419	test: 0.606120

Epoch: 40
Loss: 0.41917717355365136
ROC train: 0.813487	val: 0.599877	test: 0.606801
PRC train: 0.776276	val: 0.678615	test: 0.607863

Epoch: 41
Loss: 0.4243380128118094
ROC train: 0.815438	val: 0.605842	test: 0.601973
PRC train: 0.778560	val: 0.677709	test: 0.607351

Epoch: 42
Loss: 0.4233559335138224
ROC train: 0.815378	val: 0.609700	test: 0.596266
PRC train: 0.778758	val: 0.675949	test: 0.605635

Epoch: 43
Loss: 0.4229092193117063
ROC train: 0.821354	val: 0.616664	test: 0.606841
PRC train: 0.783987	val: 0.684729	test: 0.611491

Epoch: 44
Loss: 0.4256880165945119
ROC train: 0.820476	val: 0.613938	test: 0.608858
PRC train: 0.783118	val: 0.689384	test: 0.613254

Epoch: 45
Loss: 0.4147453742838197
ROC train: 0.815870	val: 0.612446	test: 0.605559
PRC train: 0.779595	val: 0.689840	test: 0.609266

Epoch: 46
Loss: 0.4190266955163818
ROC train: 0.829335	val: 0.614272	test: 0.600979
PRC train: 0.791207	val: 0.692695	test: 0.607174

Epoch: 47
Loss: 0.41780873854681694
ROC train: 0.828348	val: 0.613665	test: 0.598644
PRC train: 0.789294	val: 0.683918	test: 0.604104

Epoch: 48
Loss: 0.4123523345125243
ROC train: 0.824915	val: 0.604431	test: 0.595153
PRC train: 0.785109	val: 0.675559	test: 0.604174

Epoch: 49
Loss: 0.4127065975002336
ROC train: 0.833066	val: 0.609053	test: 0.603895
PRC train: 0.793737	val: 0.679221	test: 0.610804

Epoch: 50
Loss: 0.4037059711540272
ROC train: 0.836216	val: 0.611893	test: 0.607556
PRC train: 0.796985	val: 0.685185	test: 0.615891

Epoch: 51
Loss: 0.4137121455868458
ROC train: 0.838557	val: 0.615063	test: 0.608301
PRC train: 0.799122	val: 0.685907	test: 0.616226

Epoch: 52
Loss: 0.41068748774403707
ROC train: 0.845371	val: 0.620515	test: 0.611201
PRC train: 0.809707	val: 0.686118	test: 0.617759

Epoch: 53
Loss: 0.40587564535234905
ROC train: 0.842553	val: 0.623446	test: 0.603855
PRC train: 0.805299	val: 0.685383	test: 0.614850

Epoch: 54
Loss: 0.40819009687851754
ROC train: 0.840539	val: 0.623369	test: 0.604470
PRC train: 0.803323	val: 0.687247	test: 0.614096

Epoch: 55
Loss: 0.40644887424438136
ROC train: 0.840697	val: 0.618133	test: 0.606093
PRC train: 0.803812	val: 0.688778	test: 0.614265

Epoch: 56
Loss: 0.40478249616088396
ROC train: 0.848578	val: 0.610352	test: 0.608449
PRC train: 0.811058	val: 0.682263	test: 0.614144

Epoch: 57
Loss: 0.40096952769882055
ROC train: 0.850874	val: 0.610849	test: 0.605766
PRC train: 0.810677	val: 0.684423	test: 0.612169

Epoch: 58
Loss: 0.4053618371506633
ROC train: 0.852135	val: 0.614116	test: 0.601799
PRC train: 0.811771	val: 0.683073	test: 0.610237

Epoch: 59
Loss: 0.3990199519403743
ROC train: 0.853463	val: 0.616649	test: 0.602639
PRC train: 0.811496	val: 0.683442	test: 0.611441

Epoch: 60
Loss: 0.39425773200843073
ROC train: 0.857431	val: 0.612623	test: 0.603696
PRC train: 0.817058	val: 0.687867	test: 0.614255

Epoch: 61
Loss: 0.3939346646574134
ROC train: 0.861883	val: 0.614014	test: 0.608532
PRC train: 0.822283	val: 0.690998	test: 0.618311

Epoch: 62
Loss: 0.3905230070198375
ROC train: 0.861796	val: 0.610831	test: 0.609089
PRC train: 0.824446	val: 0.685493	test: 0.618984

Epoch: 63
Loss: 0.39148864341998457
ROC train: 0.861620	val: 0.605774	test: 0.609621
PRC train: 0.823833	val: 0.680383	test: 0.620373

Epoch: 64
Loss: 0.39036637704403315
ROC train: 0.867774	val: 0.607254	test: 0.610561
PRC train: 0.829044	val: 0.682964	test: 0.620722

Epoch: 65
Loss: 0.3946383023318295
ROC train: 0.865888	val: 0.609893	test: 0.606849
PRC train: 0.825229	val: 0.681986	test: 0.620719

Epoch: 66
Loss: 0.38603556310897946
ROC train: 0.863251	val: 0.618077	test: 0.608176
PRC train: 0.823148	val: 0.684832	test: 0.621508

Epoch: 67
Loss: 0.3912716971295897
ROC train: 0.866461	val: 0.623880	test: 0.614669
PRC train: 0.825384	val: 0.693414	test: 0.624516

Epoch: 68
Loss: 0.3852824945173551
ROC train: 0.863528	val: 0.618641	test: 0.609842
PRC train: 0.820457	val: 0.684906	test: 0.619409

Epoch: 69
Loss: 0.38678228583828006
ROC train: 0.866773	val: 0.610638	test: 0.600244
PRC train: 0.824674	val: 0.683369	test: 0.613538

Epoch: 70
Loss: 0.38684859951929035
ROC train: 0.874485	val: 0.607647	test: 0.605724
PRC train: 0.835020	val: 0.682689	test: 0.615356

Epoch: 71
Loss: 0.3817330047604306
ROC train: 0.872637	val: 0.608748	test: 0.606390
PRC train: 0.833400	val: 0.686045	test: 0.615890

Epoch: 72
Loss: 0.3802757248407156
ROC train: 0.872408	val: 0.616146	test: 0.604849
PRC train: 0.832764	val: 0.693591	test: 0.616037

Epoch: 73
Loss: 0.38099650422148923
ROC train: 0.876750	val: 0.617964	test: 0.605318
PRC train: 0.837757	val: 0.692557	test: 0.615836

Epoch: 74
Loss: 0.3779924638932774
ROC train: 0.874284	val: 0.615008	test: 0.599770
PRC train: 0.831771	val: 0.686660	test: 0.617102

Epoch: 75
Loss: 0.3769585024574252
ROC train: 0.877119	val: 0.606017	test: 0.598706
PRC train: 0.840245	val: 0.675856	test: 0.616323

Epoch: 76
Loss: 0.37307444073391133
ROC train: 0.879647	val: 0.609323	test: 0.601715
PRC train: 0.841693	val: 0.675118	test: 0.614070

Epoch: 77
Loss: 0.37251073888555647
ROC train: 0.882429	val: 0.612807	test: 0.604307
PRC train: 0.845028	val: 0.682590	test: 0.618243

Epoch: 78
Loss: 0.374613743576467
ROC train: 0.882062	val: 0.613561	test: 0.609062
PRC train: 0.844053	val: 0.689494	test: 0.621438

Epoch: 79
Loss: 0.3698415627424938
ROC train: 0.881234	val: 0.607540	test: 0.606431
PRC train: 0.843976	val: 0.684092	test: 0.621395

Epoch: 80
Loss: 0.3739623864180518
ROC train: 0.882800	val: 0.610562	test: 0.599188
PRC train: 0.846451	val: 0.680943	test: 0.618300

Epoch: 81
Loss: 0.37064774435243436
ROC train: 0.885766	val: 0.615342	test: 0.593736
PRC train: 0.846882	val: 0.684146	test: 0.617250

Epoch: 82
Loss: 0.367869010826084
ROC train: 0.886389	val: 0.605806	test: 0.595839
PRC train: 0.847879	val: 0.673966	test: 0.618475

Epoch: 83
Loss: 0.3629694009487662
ROC train: 0.884441	val: 0.599464	test: 0.592738
PRC train: 0.848043	val: 0.668443	test: 0.613092

Epoch: 84
Loss: 0.366605105210522
ROC train: 0.890164	val: 0.607087	test: 0.600382
PRC train: 0.851658	val: 0.670956	test: 0.615883

Epoch: 85
Loss: 0.36453997389676573
ROC train: 0.888409	val: 0.617340	test: 0.592894
PRC train: 0.848225	val: 0.681205	test: 0.612558

Epoch: 86
Loss: 0.36577759841576596
ROC train: 0.893755	val: 0.614197	test: 0.590549
PRC train: 0.852628	val: 0.685054	test: 0.609573

Epoch: 87
Loss: 0.3619100772344451
ROC train: 0.896917	val: 0.608425	test: 0.597003
PRC train: 0.859728	val: 0.682647	test: 0.610923

Epoch: 88
Loss: 0.36431730843353005
ROC train: 0.896243	val: 0.611171	test: 0.594725
PRC train: 0.858569	val: 0.682107	test: 0.612348

Epoch: 89
Loss: 0.3571274921924771
ROC train: 0.897131	val: 0.611094	test: 0.597115
PRC train: 0.857955	val: 0.684741	test: 0.614559

Epoch: 90
Loss: 0.3633710218286881
ROC train: 0.895968	val: 0.608602	test: 0.602050
PRC train: 0.856478	val: 0.685055	test: 0.619017

Epoch: 91
Loss: 0.3573566567218075
ROC train: 0.900105	val: 0.606189	test: 0.610407
PRC train: 0.864440	val: 0.676154	test: 0.622165

Epoch: 92
Loss: 0.357795050313107
ROC train: 0.901241	val: 0.606292	test: 0.599661
PRC train: 0.865673	val: 0.676134	test: 0.619121

Epoch: 93
Loss: 0.35550378530841564
ROC train: 0.898690	val: 0.611095	test: 0.591534
PRC train: 0.862573	val: 0.681846	test: 0.611384

Epoch: 94
Loss: 0.35664884423369625
ROC train: 0.902871	val: 0.617601	test: 0.596601
ROC train: 0.789631	val: 0.601927	test: 0.593619
PRC train: 0.759763	val: 0.641671	test: 0.601102

Epoch: 34
Loss: 0.4441716599032969
ROC train: 0.792902	val: 0.611009	test: 0.592158
PRC train: 0.760835	val: 0.649795	test: 0.603396

Epoch: 35
Loss: 0.44055564382308476
ROC train: 0.796341	val: 0.620041	test: 0.588008
PRC train: 0.764511	val: 0.659125	test: 0.601801

Epoch: 36
Loss: 0.43729486866039186
ROC train: 0.797814	val: 0.624376	test: 0.588743
PRC train: 0.762986	val: 0.662980	test: 0.598172

Epoch: 37
Loss: 0.43332267018541887
ROC train: 0.799031	val: 0.625825	test: 0.591199
PRC train: 0.767016	val: 0.663844	test: 0.600444

Epoch: 38
Loss: 0.4377428622388194
ROC train: 0.802470	val: 0.620674	test: 0.586247
PRC train: 0.769280	val: 0.654062	test: 0.598282

Epoch: 39
Loss: 0.4324644983145105
ROC train: 0.801722	val: 0.631421	test: 0.572353
PRC train: 0.767451	val: 0.661712	test: 0.589753

Epoch: 40
Loss: 0.4306732702021227
ROC train: 0.812232	val: 0.623686	test: 0.577985
PRC train: 0.778219	val: 0.655070	test: 0.591140

Epoch: 41
Loss: 0.4277268569803819
ROC train: 0.811913	val: 0.619066	test: 0.586546
PRC train: 0.780914	val: 0.651578	test: 0.598069

Epoch: 42
Loss: 0.4294892190299411
ROC train: 0.815249	val: 0.625199	test: 0.583499
PRC train: 0.781043	val: 0.654931	test: 0.596995

Epoch: 43
Loss: 0.422774803789937
ROC train: 0.818535	val: 0.626270	test: 0.581300
PRC train: 0.784381	val: 0.659123	test: 0.592740

Epoch: 44
Loss: 0.4201960199262631
ROC train: 0.818288	val: 0.624715	test: 0.577441
PRC train: 0.785421	val: 0.661087	test: 0.589811

Epoch: 45
Loss: 0.42165653564460737
ROC train: 0.820739	val: 0.636421	test: 0.567816
PRC train: 0.787432	val: 0.665188	test: 0.583406

Epoch: 46
Loss: 0.42012599659764155
ROC train: 0.825226	val: 0.637395	test: 0.562651
PRC train: 0.788756	val: 0.663674	test: 0.581269

Epoch: 47
Loss: 0.4205990024992975
ROC train: 0.826667	val: 0.637494	test: 0.574129
PRC train: 0.788244	val: 0.665799	test: 0.585614

Epoch: 48
Loss: 0.4133815224108006
ROC train: 0.826511	val: 0.639224	test: 0.578298
PRC train: 0.790872	val: 0.669019	test: 0.591504

Epoch: 49
Loss: 0.41929938629261426
ROC train: 0.829936	val: 0.628381	test: 0.575027
PRC train: 0.791271	val: 0.664039	test: 0.596775

Epoch: 50
Loss: 0.4161969404759406
ROC train: 0.835769	val: 0.621883	test: 0.582958
PRC train: 0.796982	val: 0.661952	test: 0.594703

Epoch: 51
Loss: 0.40828418648401305
ROC train: 0.830925	val: 0.610016	test: 0.583292
PRC train: 0.796040	val: 0.654363	test: 0.593571

Epoch: 52
Loss: 0.42162499389293095
ROC train: 0.830469	val: 0.628643	test: 0.570634
PRC train: 0.793951	val: 0.669297	test: 0.588543

Epoch: 53
Loss: 0.41536232247863014
ROC train: 0.837463	val: 0.632030	test: 0.571015
PRC train: 0.798557	val: 0.662962	test: 0.590563

Epoch: 54
Loss: 0.40448794533044746
ROC train: 0.839012	val: 0.617390	test: 0.568709
PRC train: 0.800394	val: 0.656048	test: 0.586735

Epoch: 55
Loss: 0.40888275884725783
ROC train: 0.837782	val: 0.616183	test: 0.564064
PRC train: 0.797327	val: 0.653199	test: 0.580978

Epoch: 56
Loss: 0.40793877834404285
ROC train: 0.841333	val: 0.621699	test: 0.571254
PRC train: 0.799677	val: 0.655162	test: 0.585902

Epoch: 57
Loss: 0.4085930102978149
ROC train: 0.844419	val: 0.636198	test: 0.583880
PRC train: 0.803529	val: 0.666839	test: 0.594464

Epoch: 58
Loss: 0.40291202429623335
ROC train: 0.848184	val: 0.638992	test: 0.584694
PRC train: 0.805748	val: 0.666193	test: 0.594043

Epoch: 59
Loss: 0.40769829686452985
ROC train: 0.848906	val: 0.631853	test: 0.573087
PRC train: 0.806269	val: 0.661396	test: 0.588985

Epoch: 60
Loss: 0.39986373116057816
ROC train: 0.846534	val: 0.623799	test: 0.572100
PRC train: 0.808097	val: 0.657557	test: 0.589099

Epoch: 61
Loss: 0.4053050144363072
ROC train: 0.849498	val: 0.613856	test: 0.579649
PRC train: 0.808576	val: 0.653974	test: 0.589508

Epoch: 62
Loss: 0.4008400377035768
ROC train: 0.853537	val: 0.615121	test: 0.581983
PRC train: 0.812175	val: 0.656347	test: 0.590474

Epoch: 63
Loss: 0.39350649066416243
ROC train: 0.858314	val: 0.624213	test: 0.581936
PRC train: 0.816531	val: 0.671946	test: 0.596078

Epoch: 64
Loss: 0.39766117447908483
ROC train: 0.855925	val: 0.637516	test: 0.579926
PRC train: 0.815040	val: 0.680498	test: 0.596762

Epoch: 65
Loss: 0.3945539780086276
ROC train: 0.857987	val: 0.626591	test: 0.580672
PRC train: 0.817028	val: 0.670269	test: 0.593279

Epoch: 66
Loss: 0.39715401170319886
ROC train: 0.861275	val: 0.622975	test: 0.580604
PRC train: 0.818340	val: 0.663392	test: 0.590523

Epoch: 67
Loss: 0.3921878881492456
ROC train: 0.860834	val: 0.625429	test: 0.591653
PRC train: 0.818225	val: 0.665142	test: 0.601288

Epoch: 68
Loss: 0.39047384048970274
ROC train: 0.861294	val: 0.633076	test: 0.587757
PRC train: 0.823317	val: 0.672879	test: 0.601377

Epoch: 69
Loss: 0.3895569441024731
ROC train: 0.862464	val: 0.638557	test: 0.590441
PRC train: 0.825584	val: 0.676048	test: 0.606576

Epoch: 70
Loss: 0.3915585107498959
ROC train: 0.863103	val: 0.631788	test: 0.588879
PRC train: 0.825523	val: 0.662599	test: 0.605714

Epoch: 71
Loss: 0.3858196421087667
ROC train: 0.866890	val: 0.617818	test: 0.591477
PRC train: 0.825680	val: 0.662976	test: 0.601475

Epoch: 72
Loss: 0.3912439137043332
ROC train: 0.870110	val: 0.628110	test: 0.579646
PRC train: 0.828921	val: 0.667532	test: 0.591205

Epoch: 73
Loss: 0.39068109257909234
ROC train: 0.866826	val: 0.616548	test: 0.580827
PRC train: 0.823117	val: 0.665419	test: 0.592820

Epoch: 74
Loss: 0.3888585476682834
ROC train: 0.873797	val: 0.630491	test: 0.586580
PRC train: 0.835803	val: 0.676059	test: 0.599543

Epoch: 75
Loss: 0.3780287022738638
ROC train: 0.872192	val: 0.635385	test: 0.591436
PRC train: 0.835461	val: 0.678941	test: 0.602533

Epoch: 76
Loss: 0.38293069387174217
ROC train: 0.875532	val: 0.631812	test: 0.590688
PRC train: 0.832799	val: 0.677962	test: 0.606529

Epoch: 77
Loss: 0.38192458104520016
ROC train: 0.875922	val: 0.622396	test: 0.595044
PRC train: 0.834479	val: 0.680399	test: 0.610737

Epoch: 78
Loss: 0.3726674073516862
ROC train: 0.876961	val: 0.620117	test: 0.587920
PRC train: 0.836619	val: 0.673242	test: 0.603344

Epoch: 79
Loss: 0.38354842805956846
ROC train: 0.880768	val: 0.620786	test: 0.580317
PRC train: 0.839265	val: 0.677528	test: 0.595675

Epoch: 80
Loss: 0.3737774413233955
ROC train: 0.881050	val: 0.627903	test: 0.580947
PRC train: 0.839712	val: 0.681506	test: 0.592999

Epoch: 81
Loss: 0.37130266134082374
ROC train: 0.883644	val: 0.629950	test: 0.589458
PRC train: 0.842681	val: 0.674653	test: 0.603991

Epoch: 82
Loss: 0.38337826135968406
ROC train: 0.884329	val: 0.641127	test: 0.589555
PRC train: 0.840847	val: 0.676536	test: 0.603418

Epoch: 83
Loss: 0.378269236468607
ROC train: 0.881736	val: 0.639582	test: 0.591466
PRC train: 0.840480	val: 0.680512	test: 0.600896

Epoch: 84
Loss: 0.3703904368583319
ROC train: 0.884316	val: 0.638713	test: 0.588458
PRC train: 0.843076	val: 0.684363	test: 0.598184

Epoch: 85
Loss: 0.3704524773312392
ROC train: 0.884554	val: 0.639580	test: 0.578519
PRC train: 0.842680	val: 0.683636	test: 0.589106

Epoch: 86
Loss: 0.37315441841512664
ROC train: 0.886892	val: 0.634971	test: 0.579798
PRC train: 0.845633	val: 0.682996	test: 0.593784

Epoch: 87
Loss: 0.36958342014322476
ROC train: 0.886650	val: 0.638949	test: 0.588358
PRC train: 0.844958	val: 0.687583	test: 0.599641

Epoch: 88
Loss: 0.37260320066282515
ROC train: 0.889975	val: 0.640143	test: 0.590562
PRC train: 0.847693	val: 0.683431	test: 0.603053

Epoch: 89
Loss: 0.36527707156500727
ROC train: 0.892076	val: 0.641500	test: 0.587949
PRC train: 0.848973	val: 0.677353	test: 0.601749

Epoch: 90
Loss: 0.36561991166166463
ROC train: 0.890970	val: 0.641328	test: 0.591476
PRC train: 0.849157	val: 0.679949	test: 0.604942

Epoch: 91
Loss: 0.36521595576588084
ROC train: 0.892811	val: 0.634212	test: 0.589369
PRC train: 0.851071	val: 0.675918	test: 0.604916

Epoch: 92
Loss: 0.36458116455827577
ROC train: 0.895735	val: 0.636550	test: 0.586322
PRC train: 0.854874	val: 0.682919	test: 0.598542

Epoch: 93
Loss: 0.36623437787932484
ROC train: 0.898470	val: 0.639767	test: 0.587174
PRC train: 0.858227	val: 0.684850	test: 0.597530

Epoch: 94
Loss: 0.35782520866156065
ROC train: 0.787837	val: 0.604281	test: 0.612520
PRC train: 0.758336	val: 0.651522	test: 0.616473

Epoch: 34
Loss: 0.44651799323841185
ROC train: 0.791457	val: 0.608574	test: 0.606770
PRC train: 0.761959	val: 0.652860	test: 0.615001

Epoch: 35
Loss: 0.4367182452458331
ROC train: 0.793111	val: 0.610448	test: 0.599427
PRC train: 0.763177	val: 0.650840	test: 0.609501

Epoch: 36
Loss: 0.4365982257759587
ROC train: 0.793890	val: 0.605827	test: 0.604168
PRC train: 0.763516	val: 0.648157	test: 0.613288

Epoch: 37
Loss: 0.44163676725382495
ROC train: 0.798290	val: 0.606446	test: 0.608086
PRC train: 0.765155	val: 0.654124	test: 0.613820

Epoch: 38
Loss: 0.43424180483357644
ROC train: 0.800102	val: 0.612564	test: 0.606041
PRC train: 0.766810	val: 0.655759	test: 0.616948

Epoch: 39
Loss: 0.4326875869187695
ROC train: 0.797397	val: 0.613899	test: 0.605193
PRC train: 0.765549	val: 0.656510	test: 0.616309

Epoch: 40
Loss: 0.43600137654847815
ROC train: 0.804812	val: 0.605859	test: 0.606879
PRC train: 0.771843	val: 0.651658	test: 0.614754

Epoch: 41
Loss: 0.43268025000281674
ROC train: 0.802386	val: 0.606259	test: 0.614246
PRC train: 0.770140	val: 0.656205	test: 0.620620

Epoch: 42
Loss: 0.42537472928766623
ROC train: 0.810970	val: 0.614478	test: 0.618742
PRC train: 0.777158	val: 0.658641	test: 0.619923

Epoch: 43
Loss: 0.42925557031091727
ROC train: 0.813524	val: 0.605325	test: 0.618796
PRC train: 0.777265	val: 0.653579	test: 0.620644

Epoch: 44
Loss: 0.4223023169859431
ROC train: 0.814022	val: 0.603622	test: 0.613630
PRC train: 0.779731	val: 0.657144	test: 0.620930

Epoch: 45
Loss: 0.42532318472232034
ROC train: 0.818322	val: 0.622986	test: 0.615867
PRC train: 0.782997	val: 0.672189	test: 0.620046

Epoch: 46
Loss: 0.42454308114538586
ROC train: 0.816040	val: 0.630721	test: 0.613410
PRC train: 0.779887	val: 0.679423	test: 0.621864

Epoch: 47
Loss: 0.42622409431444563
ROC train: 0.824423	val: 0.623725	test: 0.609740
PRC train: 0.786938	val: 0.673404	test: 0.618040

Epoch: 48
Loss: 0.42204846173721444
ROC train: 0.817593	val: 0.608926	test: 0.607499
PRC train: 0.781572	val: 0.665712	test: 0.615369

Epoch: 49
Loss: 0.4191775177637889
ROC train: 0.820545	val: 0.610955	test: 0.605254
PRC train: 0.784769	val: 0.668670	test: 0.612359

Epoch: 50
Loss: 0.41758956033074945
ROC train: 0.824905	val: 0.616471	test: 0.601142
PRC train: 0.787043	val: 0.670872	test: 0.613835

Epoch: 51
Loss: 0.41800542991987866
ROC train: 0.830463	val: 0.613685	test: 0.626479
PRC train: 0.792016	val: 0.666656	test: 0.632736

Epoch: 52
Loss: 0.4166327987197718
ROC train: 0.834299	val: 0.612636	test: 0.625930
PRC train: 0.795933	val: 0.666749	test: 0.632714

Epoch: 53
Loss: 0.40961539016974013
ROC train: 0.836804	val: 0.609715	test: 0.617139
PRC train: 0.796752	val: 0.661054	test: 0.624181

Epoch: 54
Loss: 0.41211198527324033
ROC train: 0.837315	val: 0.615132	test: 0.617174
PRC train: 0.797622	val: 0.666274	test: 0.622795

Epoch: 55
Loss: 0.4067255595623716
ROC train: 0.836524	val: 0.615593	test: 0.613534
PRC train: 0.797170	val: 0.667700	test: 0.619155

Epoch: 56
Loss: 0.4129191836241285
ROC train: 0.842729	val: 0.614202	test: 0.616963
PRC train: 0.801767	val: 0.664558	test: 0.620776

Epoch: 57
Loss: 0.40558157824921015
ROC train: 0.843923	val: 0.614816	test: 0.622305
PRC train: 0.800303	val: 0.663129	test: 0.620495

Epoch: 58
Loss: 0.4044685782126548
ROC train: 0.843468	val: 0.612487	test: 0.624583
PRC train: 0.799498	val: 0.662156	test: 0.623102

Epoch: 59
Loss: 0.4047592397816131
ROC train: 0.840774	val: 0.613026	test: 0.623484
PRC train: 0.798287	val: 0.663800	test: 0.624372

Epoch: 60
Loss: 0.4067085199363746
ROC train: 0.846720	val: 0.615914	test: 0.623407
PRC train: 0.803894	val: 0.663315	test: 0.629226

Epoch: 61
Loss: 0.40199103885561344
ROC train: 0.846306	val: 0.612904	test: 0.628508
PRC train: 0.807199	val: 0.662195	test: 0.634692

Epoch: 62
Loss: 0.40220491002020653
ROC train: 0.847241	val: 0.614036	test: 0.621282
PRC train: 0.806457	val: 0.663003	test: 0.632271

Epoch: 63
Loss: 0.40675340152272554
ROC train: 0.849301	val: 0.609377	test: 0.614227
PRC train: 0.808679	val: 0.658376	test: 0.625685

Epoch: 64
Loss: 0.40457930851421314
ROC train: 0.848548	val: 0.606675	test: 0.617130
PRC train: 0.807037	val: 0.661970	test: 0.625654

Epoch: 65
Loss: 0.40125211891818974
ROC train: 0.847969	val: 0.608426	test: 0.616003
PRC train: 0.807661	val: 0.663519	test: 0.625916

Epoch: 66
Loss: 0.39943456389873966
ROC train: 0.849038	val: 0.608921	test: 0.615890
PRC train: 0.807561	val: 0.663217	test: 0.624775

Epoch: 67
Loss: 0.39397283388784843
ROC train: 0.858682	val: 0.623431	test: 0.622667
PRC train: 0.817151	val: 0.668117	test: 0.631028

Epoch: 68
Loss: 0.3958206132918419
ROC train: 0.859260	val: 0.627151	test: 0.620445
PRC train: 0.818418	val: 0.671155	test: 0.632133

Epoch: 69
Loss: 0.39179444238419087
ROC train: 0.855845	val: 0.621125	test: 0.623943
PRC train: 0.813498	val: 0.670852	test: 0.633165

Epoch: 70
Loss: 0.39474980867142123
ROC train: 0.855364	val: 0.619675	test: 0.622327
PRC train: 0.815361	val: 0.670046	test: 0.626062

Epoch: 71
Loss: 0.3955824018203156
ROC train: 0.861903	val: 0.623744	test: 0.622402
PRC train: 0.819323	val: 0.673858	test: 0.625097

Epoch: 72
Loss: 0.3881754868463839
ROC train: 0.859033	val: 0.616769	test: 0.615460
PRC train: 0.817129	val: 0.675983	test: 0.625012

Epoch: 73
Loss: 0.38601433283527775
ROC train: 0.866844	val: 0.625641	test: 0.613821
PRC train: 0.823739	val: 0.679422	test: 0.625049

Epoch: 74
Loss: 0.388332013692893
ROC train: 0.869256	val: 0.626965	test: 0.613776
PRC train: 0.826661	val: 0.680656	test: 0.625902

Epoch: 75
Loss: 0.38913324218922407
ROC train: 0.867226	val: 0.628419	test: 0.616667
PRC train: 0.826245	val: 0.680995	test: 0.627451

Epoch: 76
Loss: 0.38822675661179584
ROC train: 0.868022	val: 0.616533	test: 0.620468
PRC train: 0.826193	val: 0.672687	test: 0.630398

Epoch: 77
Loss: 0.38599758095786646
ROC train: 0.870501	val: 0.619956	test: 0.621579
PRC train: 0.828738	val: 0.671672	test: 0.635885

Epoch: 78
Loss: 0.38395048666903475
ROC train: 0.872954	val: 0.627726	test: 0.616480
PRC train: 0.829255	val: 0.679538	test: 0.629256

Epoch: 79
Loss: 0.38317126950331004
ROC train: 0.868631	val: 0.625907	test: 0.621201
PRC train: 0.824159	val: 0.685693	test: 0.630934

Epoch: 80
Loss: 0.38505214016677386
ROC train: 0.873057	val: 0.620763	test: 0.616382
PRC train: 0.829159	val: 0.678485	test: 0.631639

Epoch: 81
Loss: 0.3813256124170482
ROC train: 0.878032	val: 0.614805	test: 0.625259
PRC train: 0.837333	val: 0.674776	test: 0.638954

Epoch: 82
Loss: 0.37596999216400845
ROC train: 0.876998	val: 0.622884	test: 0.622851
PRC train: 0.835988	val: 0.678869	test: 0.637491

Epoch: 83
Loss: 0.37253079623890584
ROC train: 0.874851	val: 0.619452	test: 0.627709
PRC train: 0.834261	val: 0.680934	test: 0.637073

Epoch: 84
Loss: 0.38341649944787626
ROC train: 0.881690	val: 0.621489	test: 0.628392
PRC train: 0.841163	val: 0.676748	test: 0.635988

Epoch: 85
Loss: 0.3787364410791925
ROC train: 0.879672	val: 0.627106	test: 0.624412
PRC train: 0.839714	val: 0.674753	test: 0.633682

Epoch: 86
Loss: 0.3713819822264473
ROC train: 0.880670	val: 0.627409	test: 0.622971
PRC train: 0.839161	val: 0.683537	test: 0.634481

Epoch: 87
Loss: 0.3792378432738894
ROC train: 0.884626	val: 0.628763	test: 0.625707
PRC train: 0.844493	val: 0.680200	test: 0.633489

Epoch: 88
Loss: 0.37531508976323535
ROC train: 0.883773	val: 0.624187	test: 0.620362
PRC train: 0.844016	val: 0.670574	test: 0.628543

Epoch: 89
Loss: 0.37267877443541386
ROC train: 0.886978	val: 0.618220	test: 0.627201
PRC train: 0.848904	val: 0.677603	test: 0.633843

Epoch: 90
Loss: 0.3687321363512065
ROC train: 0.887099	val: 0.630737	test: 0.626892
PRC train: 0.849064	val: 0.692430	test: 0.634113

Epoch: 91
Loss: 0.37057953104556673
ROC train: 0.886782	val: 0.631776	test: 0.626387
PRC train: 0.850272	val: 0.685810	test: 0.632568

Epoch: 92
Loss: 0.36373246603224896
ROC train: 0.887857	val: 0.621231	test: 0.625446
PRC train: 0.847803	val: 0.680781	test: 0.632305

Epoch: 93
Loss: 0.3676049576134557
ROC train: 0.888207	val: 0.622519	test: 0.615285
PRC train: 0.848268	val: 0.679885	test: 0.626910

Epoch: 94
Loss: 0.3644197529143054
ROC train: 0.784585	val: 0.613938	test: 0.577207
PRC train: 0.753741	val: 0.646427	test: 0.594661

Epoch: 34
Loss: 0.4395472874816915
ROC train: 0.790498	val: 0.617617	test: 0.580240
PRC train: 0.758494	val: 0.646726	test: 0.596901

Epoch: 35
Loss: 0.44139656167477426
ROC train: 0.793664	val: 0.612125	test: 0.585315
PRC train: 0.760995	val: 0.643643	test: 0.597374

Epoch: 36
Loss: 0.4395532317064334
ROC train: 0.795416	val: 0.613305	test: 0.587373
PRC train: 0.762071	val: 0.645859	test: 0.596728

Epoch: 37
Loss: 0.4380691777871217
ROC train: 0.802707	val: 0.622499	test: 0.589065
PRC train: 0.767118	val: 0.655157	test: 0.598083

Epoch: 38
Loss: 0.4308874500836321
ROC train: 0.805433	val: 0.625945	test: 0.584188
PRC train: 0.769934	val: 0.662922	test: 0.596292

Epoch: 39
Loss: 0.4238071491203407
ROC train: 0.804921	val: 0.618792	test: 0.566882
PRC train: 0.769687	val: 0.662275	test: 0.585067

Epoch: 40
Loss: 0.43159227538324607
ROC train: 0.810102	val: 0.624941	test: 0.571027
PRC train: 0.773327	val: 0.662276	test: 0.586261

Epoch: 41
Loss: 0.4265072747922316
ROC train: 0.813136	val: 0.629888	test: 0.583867
PRC train: 0.776283	val: 0.667627	test: 0.593916

Epoch: 42
Loss: 0.4281826738750046
ROC train: 0.816575	val: 0.635191	test: 0.586113
PRC train: 0.779903	val: 0.667475	test: 0.595037

Epoch: 43
Loss: 0.4283298046311799
ROC train: 0.814762	val: 0.634272	test: 0.583579
PRC train: 0.778368	val: 0.666924	test: 0.594469

Epoch: 44
Loss: 0.4232306524159483
ROC train: 0.812015	val: 0.630966	test: 0.585024
PRC train: 0.776546	val: 0.663981	test: 0.594994

Epoch: 45
Loss: 0.4242867194024565
ROC train: 0.819130	val: 0.613390	test: 0.588463
PRC train: 0.782567	val: 0.655207	test: 0.597730

Epoch: 46
Loss: 0.4207190397539061
ROC train: 0.823396	val: 0.607436	test: 0.593254
PRC train: 0.784468	val: 0.655475	test: 0.600151

Epoch: 47
Loss: 0.4204283475408013
ROC train: 0.825405	val: 0.629160	test: 0.595457
PRC train: 0.787129	val: 0.668696	test: 0.601806

Epoch: 48
Loss: 0.4125740812244847
ROC train: 0.829871	val: 0.639153	test: 0.597468
PRC train: 0.790126	val: 0.677415	test: 0.603066

Epoch: 49
Loss: 0.4164710949629404
ROC train: 0.832752	val: 0.643549	test: 0.596595
PRC train: 0.791496	val: 0.679063	test: 0.601975

Epoch: 50
Loss: 0.4146029279011202
ROC train: 0.831836	val: 0.638450	test: 0.594239
PRC train: 0.791911	val: 0.676800	test: 0.602626

Epoch: 51
Loss: 0.4120734487841945
ROC train: 0.835617	val: 0.629066	test: 0.600041
PRC train: 0.795502	val: 0.670556	test: 0.606045

Epoch: 52
Loss: 0.41067611612494914
ROC train: 0.839313	val: 0.631417	test: 0.605301
PRC train: 0.798582	val: 0.670294	test: 0.607978

Epoch: 53
Loss: 0.4137014925814718
ROC train: 0.838946	val: 0.640539	test: 0.602197
PRC train: 0.800024	val: 0.680238	test: 0.605305

Epoch: 54
Loss: 0.41176567785908896
ROC train: 0.840846	val: 0.635297	test: 0.600050
PRC train: 0.801205	val: 0.675927	test: 0.604150

Epoch: 55
Loss: 0.4061667661462243
ROC train: 0.844795	val: 0.624382	test: 0.600272
PRC train: 0.802670	val: 0.670077	test: 0.604000

Epoch: 56
Loss: 0.40903552511013486
ROC train: 0.847043	val: 0.631023	test: 0.593560
PRC train: 0.804911	val: 0.677006	test: 0.597251

Epoch: 57
Loss: 0.40020594552345534
ROC train: 0.847162	val: 0.629690	test: 0.591308
PRC train: 0.805460	val: 0.680046	test: 0.597718

Epoch: 58
Loss: 0.3981782988515651
ROC train: 0.850395	val: 0.622997	test: 0.593492
PRC train: 0.808417	val: 0.677132	test: 0.601940

Epoch: 59
Loss: 0.40321267480107836
ROC train: 0.850819	val: 0.625430	test: 0.591262
PRC train: 0.809461	val: 0.670630	test: 0.596465

Epoch: 60
Loss: 0.3972981207054486
ROC train: 0.851274	val: 0.625144	test: 0.589259
PRC train: 0.809124	val: 0.668413	test: 0.594836

Epoch: 61
Loss: 0.4038290741492177
ROC train: 0.853226	val: 0.626440	test: 0.586220
PRC train: 0.810024	val: 0.660191	test: 0.591846

Epoch: 62
Loss: 0.39913620557199436
ROC train: 0.858102	val: 0.632294	test: 0.588681
PRC train: 0.814928	val: 0.667840	test: 0.592941

Epoch: 63
Loss: 0.4034717933236137
ROC train: 0.857161	val: 0.630345	test: 0.587556
PRC train: 0.815182	val: 0.669754	test: 0.593345

Epoch: 64
Loss: 0.3926815081346916
ROC train: 0.859465	val: 0.624553	test: 0.599593
PRC train: 0.815894	val: 0.665831	test: 0.600351

Epoch: 65
Loss: 0.394703890949593
ROC train: 0.862706	val: 0.628377	test: 0.600665
PRC train: 0.817500	val: 0.674995	test: 0.603175

Epoch: 66
Loss: 0.39676036869163045
ROC train: 0.858609	val: 0.629782	test: 0.606829
PRC train: 0.815209	val: 0.677752	test: 0.605611

Epoch: 67
Loss: 0.3924195165154635
ROC train: 0.857338	val: 0.626154	test: 0.606751
PRC train: 0.812462	val: 0.663984	test: 0.604712

Epoch: 68
Loss: 0.3942888368508745
ROC train: 0.862487	val: 0.620330	test: 0.602330
PRC train: 0.817379	val: 0.659997	test: 0.599344

Epoch: 69
Loss: 0.3854956868199139
ROC train: 0.869123	val: 0.627242	test: 0.603392
PRC train: 0.826122	val: 0.672872	test: 0.605682

Epoch: 70
Loss: 0.39072159880332646
ROC train: 0.869725	val: 0.623490	test: 0.605108
PRC train: 0.827308	val: 0.674565	test: 0.611932

Epoch: 71
Loss: 0.3910838330093438
ROC train: 0.867569	val: 0.622258	test: 0.605077
PRC train: 0.824994	val: 0.673298	test: 0.611859

Epoch: 72
Loss: 0.3897266073148771
ROC train: 0.868982	val: 0.617731	test: 0.604363
PRC train: 0.826814	val: 0.667624	test: 0.607511

Epoch: 73
Loss: 0.38115241838982944
ROC train: 0.872792	val: 0.619111	test: 0.600199
PRC train: 0.829105	val: 0.670426	test: 0.601338

Epoch: 74
Loss: 0.39090450204263516
ROC train: 0.874540	val: 0.622050	test: 0.598151
PRC train: 0.831740	val: 0.672869	test: 0.601021

Epoch: 75
Loss: 0.38578956342569903
ROC train: 0.874299	val: 0.629220	test: 0.597837
PRC train: 0.834087	val: 0.672709	test: 0.602360

Epoch: 76
Loss: 0.37685388826060434
ROC train: 0.875030	val: 0.628374	test: 0.600642
PRC train: 0.832767	val: 0.672282	test: 0.604231

Epoch: 77
Loss: 0.37235374307599833
ROC train: 0.874458	val: 0.630152	test: 0.600543
PRC train: 0.832706	val: 0.674044	test: 0.605479

Epoch: 78
Loss: 0.38136528982268275
ROC train: 0.877814	val: 0.635227	test: 0.603690
PRC train: 0.834235	val: 0.680815	test: 0.608708

Epoch: 79
Loss: 0.37891370343358916
ROC train: 0.876167	val: 0.630891	test: 0.596107
PRC train: 0.833104	val: 0.678530	test: 0.602441

Epoch: 80
Loss: 0.3765617179565047
ROC train: 0.878658	val: 0.617446	test: 0.595445
PRC train: 0.837123	val: 0.665926	test: 0.606195

Epoch: 81
Loss: 0.37540714258844743
ROC train: 0.880687	val: 0.613727	test: 0.594377
PRC train: 0.837126	val: 0.660177	test: 0.608236

Epoch: 82
Loss: 0.37600217502584143
ROC train: 0.883350	val: 0.621910	test: 0.602309
PRC train: 0.839152	val: 0.669997	test: 0.615176

Epoch: 83
Loss: 0.37049372221351895
ROC train: 0.886190	val: 0.633003	test: 0.605170
PRC train: 0.843179	val: 0.684595	test: 0.615710

Epoch: 84
Loss: 0.3673051164309644
ROC train: 0.885280	val: 0.633296	test: 0.603510
PRC train: 0.841616	val: 0.685713	test: 0.614095

Epoch: 85
Loss: 0.37877928703803787
ROC train: 0.886638	val: 0.625579	test: 0.598960
PRC train: 0.843570	val: 0.676877	test: 0.605761

Epoch: 86
Loss: 0.3679255735688539
ROC train: 0.887792	val: 0.619944	test: 0.594873
PRC train: 0.846060	val: 0.667981	test: 0.601760

Epoch: 87
Loss: 0.36565361907315835
ROC train: 0.888465	val: 0.619447	test: 0.593585
PRC train: 0.846604	val: 0.677411	test: 0.603986

Epoch: 88
Loss: 0.36865131023285624
ROC train: 0.891970	val: 0.621269	test: 0.600940
PRC train: 0.848848	val: 0.680834	test: 0.613502

Epoch: 89
Loss: 0.3690542855221109
ROC train: 0.893732	val: 0.619911	test: 0.609210
PRC train: 0.851088	val: 0.681254	test: 0.618206

Epoch: 90
Loss: 0.3677657294264901
ROC train: 0.891122	val: 0.618680	test: 0.606417
PRC train: 0.849069	val: 0.677918	test: 0.615961

Epoch: 91
Loss: 0.3614394687561744
ROC train: 0.890948	val: 0.620332	test: 0.595545
PRC train: 0.849662	val: 0.675351	test: 0.614574

Epoch: 92
Loss: 0.3626998023312152
ROC train: 0.894498	val: 0.624236	test: 0.600777
PRC train: 0.855274	val: 0.680208	test: 0.613473

Epoch: 93
Loss: 0.36379611450601174
ROC train: 0.897261	val: 0.627119	test: 0.606247
PRC train: 0.856322	val: 0.680052	test: 0.619186

Epoch: 94
Loss: 0.360595918893351
ROC train: 0.897344	val: 0.633586	test: 0.619785
PRC train: 0.866994	val: 0.659438	test: 0.640000

Epoch: 95
Loss: 0.3598463688797757
ROC train: 0.891276	val: 0.628893	test: 0.613369
PRC train: 0.860362	val: 0.653711	test: 0.637747

Epoch: 96
Loss: 0.36892820452981445
ROC train: 0.898821	val: 0.631167	test: 0.616642
PRC train: 0.866430	val: 0.659710	test: 0.637290

Epoch: 97
Loss: 0.3571499382832573
ROC train: 0.898880	val: 0.636967	test: 0.613486
PRC train: 0.866213	val: 0.664658	test: 0.633497

Epoch: 98
Loss: 0.3587307184235133
ROC train: 0.901828	val: 0.638961	test: 0.610318
PRC train: 0.869487	val: 0.663609	test: 0.629991

Epoch: 99
Loss: 0.35397729719528204
ROC train: 0.904351	val: 0.629461	test: 0.614110
PRC train: 0.870205	val: 0.655917	test: 0.632166

Epoch: 100
Loss: 0.3530081988482556
ROC train: 0.905451	val: 0.622186	test: 0.619482
PRC train: 0.873353	val: 0.655319	test: 0.637361

Epoch: 101
Loss: 0.3478132313211794
ROC train: 0.904547	val: 0.622555	test: 0.614885
PRC train: 0.872433	val: 0.655832	test: 0.636271

Epoch: 102
Loss: 0.3517281110973701
ROC train: 0.905378	val: 0.627595	test: 0.609729
PRC train: 0.872628	val: 0.658405	test: 0.634928

Epoch: 103
Loss: 0.34483353137220213
ROC train: 0.906633	val: 0.637918	test: 0.606314
PRC train: 0.871771	val: 0.665707	test: 0.632545

Epoch: 104
Loss: 0.35048715185394225
ROC train: 0.905867	val: 0.640635	test: 0.607957
PRC train: 0.873816	val: 0.666953	test: 0.631464

Epoch: 105
Loss: 0.34555534712400426
ROC train: 0.909409	val: 0.636344	test: 0.612627
PRC train: 0.878975	val: 0.662993	test: 0.635243

Epoch: 106
Loss: 0.3449399556011346
ROC train: 0.911215	val: 0.635170	test: 0.614335
PRC train: 0.878857	val: 0.666179	test: 0.638806

Epoch: 107
Loss: 0.3478815112244426
ROC train: 0.910858	val: 0.630334	test: 0.616800
PRC train: 0.876618	val: 0.663567	test: 0.640703

Epoch: 108
Loss: 0.33432217930246694
ROC train: 0.908690	val: 0.630810	test: 0.623781
PRC train: 0.875427	val: 0.662423	test: 0.641961

Epoch: 109
Loss: 0.33795908722645307
ROC train: 0.909308	val: 0.632849	test: 0.622487
PRC train: 0.877116	val: 0.659567	test: 0.643239

Epoch: 110
Loss: 0.3462630110380639
ROC train: 0.909550	val: 0.631350	test: 0.617501
PRC train: 0.878096	val: 0.655063	test: 0.641442

Epoch: 111
Loss: 0.33597950354622286
ROC train: 0.912501	val: 0.635144	test: 0.617334
PRC train: 0.880816	val: 0.659665	test: 0.640291

Epoch: 112
Loss: 0.33879414650109047
ROC train: 0.915245	val: 0.633765	test: 0.610482
PRC train: 0.882331	val: 0.660480	test: 0.638322

Epoch: 113
Loss: 0.34051399499459906
ROC train: 0.913724	val: 0.623514	test: 0.606428
PRC train: 0.880591	val: 0.653703	test: 0.636221

Epoch: 114
Loss: 0.3379128523006695
ROC train: 0.916536	val: 0.625762	test: 0.609193
PRC train: 0.884058	val: 0.655249	test: 0.636777

Epoch: 115
Loss: 0.3356475360124709
ROC train: 0.918988	val: 0.632082	test: 0.619811
PRC train: 0.887150	val: 0.661346	test: 0.638789

Epoch: 116
Loss: 0.33872752767889497
ROC train: 0.920317	val: 0.630065	test: 0.616495
PRC train: 0.887763	val: 0.657914	test: 0.635137

Epoch: 117
Loss: 0.3314415934782076
ROC train: 0.917213	val: 0.627377	test: 0.614031
PRC train: 0.886509	val: 0.657844	test: 0.636860

Epoch: 118
Loss: 0.33618097266243796
ROC train: 0.920641	val: 0.634658	test: 0.619051
PRC train: 0.890378	val: 0.663529	test: 0.640052

Epoch: 119
Loss: 0.32523660844677305
ROC train: 0.919031	val: 0.631575	test: 0.618353
PRC train: 0.888950	val: 0.662756	test: 0.639718

Epoch: 120
Loss: 0.33886336036167386
ROC train: 0.923259	val: 0.633754	test: 0.618896
PRC train: 0.894694	val: 0.662870	test: 0.643018

Early stopping
Best (ROC):	 train: 0.883838	val: 0.647333	test: 0.613396
Best (PRC):	 train: 0.848729	val: 0.668449	test: 0.631521

ROC train: 0.893042	val: 0.617062	test: 0.588989
PRC train: 0.854416	val: 0.653549	test: 0.614479

Epoch: 95
Loss: 0.3632184925380447
ROC train: 0.900851	val: 0.623503	test: 0.598567
PRC train: 0.861956	val: 0.658412	test: 0.620126

Epoch: 96
Loss: 0.3486898951592079
ROC train: 0.901829	val: 0.629488	test: 0.603888
PRC train: 0.861943	val: 0.659641	test: 0.622326

Epoch: 97
Loss: 0.35456369936803345
ROC train: 0.903325	val: 0.631672	test: 0.608325
PRC train: 0.864710	val: 0.659824	test: 0.624650

Epoch: 98
Loss: 0.34902039255860356
ROC train: 0.901770	val: 0.624799	test: 0.604998
PRC train: 0.860995	val: 0.653399	test: 0.621787

Epoch: 99
Loss: 0.3480490676948871
ROC train: 0.900139	val: 0.624199	test: 0.600190
PRC train: 0.863550	val: 0.655796	test: 0.621974

Epoch: 100
Loss: 0.36011210600915783
ROC train: 0.903849	val: 0.636879	test: 0.607057
PRC train: 0.867437	val: 0.663878	test: 0.628562

Epoch: 101
Loss: 0.3525118779983496
ROC train: 0.908316	val: 0.644670	test: 0.610048
PRC train: 0.870592	val: 0.668126	test: 0.629357

Epoch: 102
Loss: 0.3498983262802945
ROC train: 0.907188	val: 0.638312	test: 0.604532
PRC train: 0.869203	val: 0.663310	test: 0.625126

Epoch: 103
Loss: 0.34988665503272454
ROC train: 0.907212	val: 0.638190	test: 0.606601
PRC train: 0.872551	val: 0.662108	test: 0.624198

Epoch: 104
Loss: 0.34505779920245483
ROC train: 0.908726	val: 0.640110	test: 0.606810
PRC train: 0.875202	val: 0.666805	test: 0.624418

Epoch: 105
Loss: 0.34059868379607183
ROC train: 0.906979	val: 0.636424	test: 0.607514
PRC train: 0.875533	val: 0.665618	test: 0.626299

Epoch: 106
Loss: 0.3483036103214598
ROC train: 0.907250	val: 0.629486	test: 0.605070
PRC train: 0.872147	val: 0.661006	test: 0.624164

Epoch: 107
Loss: 0.34841179367308606
ROC train: 0.910449	val: 0.632144	test: 0.612326
PRC train: 0.874698	val: 0.664107	test: 0.626264

Epoch: 108
Loss: 0.34440814995354674
ROC train: 0.908572	val: 0.628342	test: 0.609322
PRC train: 0.871822	val: 0.660672	test: 0.626581

Epoch: 109
Loss: 0.3410842876191467
ROC train: 0.909472	val: 0.628102	test: 0.607647
PRC train: 0.873347	val: 0.661292	test: 0.626330

Epoch: 110
Loss: 0.33463359074105703
ROC train: 0.915949	val: 0.633681	test: 0.612508
PRC train: 0.877992	val: 0.660905	test: 0.626611

Epoch: 111
Loss: 0.34072061451946695
ROC train: 0.915368	val: 0.632018	test: 0.607192
PRC train: 0.877697	val: 0.658141	test: 0.627195

Epoch: 112
Loss: 0.34060861189180425
ROC train: 0.916769	val: 0.628590	test: 0.600499
PRC train: 0.881030	val: 0.655922	test: 0.625053

Epoch: 113
Loss: 0.339460967801156
ROC train: 0.913654	val: 0.616220	test: 0.597344
PRC train: 0.875889	val: 0.647190	test: 0.621013

Epoch: 114
Loss: 0.3274668170458272
ROC train: 0.912058	val: 0.614081	test: 0.601510
PRC train: 0.875169	val: 0.647473	test: 0.623364

Epoch: 115
Loss: 0.33408022982311836
ROC train: 0.913251	val: 0.619008	test: 0.607125
PRC train: 0.876840	val: 0.651399	test: 0.628148

Epoch: 116
Loss: 0.3369220709061902
ROC train: 0.917879	val: 0.621423	test: 0.605399
PRC train: 0.884621	val: 0.659425	test: 0.627805

Epoch: 117
Loss: 0.3298184548081117
ROC train: 0.916084	val: 0.617755	test: 0.603269
PRC train: 0.882812	val: 0.657589	test: 0.626208

Epoch: 118
Loss: 0.33045713369523816
ROC train: 0.920187	val: 0.625874	test: 0.607712
PRC train: 0.883338	val: 0.659575	test: 0.627110

Epoch: 119
Loss: 0.33293783901424645
ROC train: 0.919440	val: 0.632618	test: 0.605981
PRC train: 0.884364	val: 0.661774	test: 0.627465

Epoch: 120
Loss: 0.3289519623095507
ROC train: 0.922570	val: 0.637322	test: 0.605266
PRC train: 0.890451	val: 0.666251	test: 0.626799

Early stopping
Best (ROC):	 train: 0.828673	val: 0.654202	test: 0.595437
Best (PRC):	 train: 0.786889	val: 0.666470	test: 0.602166

PRC train: 0.866620	val: 0.673437	test: 0.619699

Epoch: 95
Loss: 0.35302582076724637
ROC train: 0.905723	val: 0.620056	test: 0.610240
PRC train: 0.868919	val: 0.674896	test: 0.619100

Epoch: 96
Loss: 0.3599089278952227
ROC train: 0.906735	val: 0.616603	test: 0.609885
PRC train: 0.871343	val: 0.675630	test: 0.621499

Epoch: 97
Loss: 0.349436003326803
ROC train: 0.904694	val: 0.615457	test: 0.608206
PRC train: 0.869602	val: 0.675867	test: 0.618306

Epoch: 98
Loss: 0.35165703085279554
ROC train: 0.908008	val: 0.619060	test: 0.604265
PRC train: 0.874159	val: 0.682586	test: 0.616603

Epoch: 99
Loss: 0.3502351522877172
ROC train: 0.909394	val: 0.619227	test: 0.601504
PRC train: 0.874258	val: 0.682159	test: 0.616166

Epoch: 100
Loss: 0.3446783962061314
ROC train: 0.909685	val: 0.615065	test: 0.602511
PRC train: 0.876781	val: 0.677925	test: 0.618322

Epoch: 101
Loss: 0.34346011420339284
ROC train: 0.909455	val: 0.609055	test: 0.612618
PRC train: 0.873268	val: 0.671206	test: 0.626864

Epoch: 102
Loss: 0.3411588454856282
ROC train: 0.910652	val: 0.606981	test: 0.607411
PRC train: 0.875337	val: 0.667426	test: 0.621352

Epoch: 103
Loss: 0.3414196279639885
ROC train: 0.911090	val: 0.602363	test: 0.600015
PRC train: 0.876101	val: 0.665572	test: 0.617022

Epoch: 104
Loss: 0.3370714041266906
ROC train: 0.914339	val: 0.609406	test: 0.602881
PRC train: 0.880666	val: 0.671086	test: 0.619204

Epoch: 105
Loss: 0.33971286432040537
ROC train: 0.914205	val: 0.615665	test: 0.602900
PRC train: 0.879634	val: 0.675843	test: 0.620091

Epoch: 106
Loss: 0.33714498065063214
ROC train: 0.918105	val: 0.618678	test: 0.605025
PRC train: 0.884017	val: 0.677928	test: 0.622753

Epoch: 107
Loss: 0.3394994056002097
ROC train: 0.919720	val: 0.623682	test: 0.612061
PRC train: 0.886934	val: 0.678921	test: 0.624086

Epoch: 108
Loss: 0.33481798324074835
ROC train: 0.917872	val: 0.613669	test: 0.607307
PRC train: 0.885898	val: 0.671785	test: 0.623733

Epoch: 109
Loss: 0.3348879518907199
ROC train: 0.918655	val: 0.607506	test: 0.599530
PRC train: 0.884887	val: 0.670171	test: 0.618146

Epoch: 110
Loss: 0.3321143157911864
ROC train: 0.920311	val: 0.608174	test: 0.604143
PRC train: 0.886834	val: 0.670181	test: 0.620026

Epoch: 111
Loss: 0.3323684566361239
ROC train: 0.922748	val: 0.613582	test: 0.607086
PRC train: 0.890315	val: 0.674940	test: 0.621416

Epoch: 112
Loss: 0.3274573985045884
ROC train: 0.924328	val: 0.621321	test: 0.605076
PRC train: 0.894570	val: 0.676289	test: 0.620836

Epoch: 113
Loss: 0.33030280720276983
ROC train: 0.924646	val: 0.616766	test: 0.606003
PRC train: 0.894486	val: 0.671722	test: 0.622442

Epoch: 114
Loss: 0.32889192448305143
ROC train: 0.925090	val: 0.617936	test: 0.613060
PRC train: 0.895238	val: 0.673107	test: 0.623000

Epoch: 115
Loss: 0.3254982833707809
ROC train: 0.927263	val: 0.615655	test: 0.609997
PRC train: 0.897241	val: 0.673372	test: 0.623659

Epoch: 116
Loss: 0.32433405193456855
ROC train: 0.926323	val: 0.604889	test: 0.605134
PRC train: 0.894698	val: 0.665562	test: 0.619494

Epoch: 117
Loss: 0.33031808733119294
ROC train: 0.926047	val: 0.605058	test: 0.601235
PRC train: 0.893912	val: 0.670118	test: 0.620897

Epoch: 118
Loss: 0.32479199540468945
ROC train: 0.924817	val: 0.606554	test: 0.604834
PRC train: 0.891514	val: 0.671916	test: 0.620474

Epoch: 119
Loss: 0.3212074778425753
ROC train: 0.926030	val: 0.610808	test: 0.614646
PRC train: 0.892919	val: 0.670310	test: 0.627169

Epoch: 120
Loss: 0.32583587839406314
ROC train: 0.931418	val: 0.619334	test: 0.619709
PRC train: 0.900036	val: 0.671725	test: 0.633139

Early stopping
Best (ROC):	 train: 0.781489	val: 0.633916	test: 0.597908
Best (PRC):	 train: 0.743208	val: 0.678516	test: 0.598393

PRC train: 0.866268	val: 0.680068	test: 0.616216

Epoch: 95
Loss: 0.3525739842262608
ROC train: 0.904031	val: 0.610880	test: 0.604261
PRC train: 0.867290	val: 0.676706	test: 0.620546

Epoch: 96
Loss: 0.35195070864569533
ROC train: 0.897717	val: 0.605658	test: 0.607575
PRC train: 0.860315	val: 0.679218	test: 0.621811

Epoch: 97
Loss: 0.35638778796063275
ROC train: 0.903753	val: 0.604076	test: 0.597466
PRC train: 0.866370	val: 0.675580	test: 0.617109

Epoch: 98
Loss: 0.35358896408748025
ROC train: 0.906657	val: 0.602428	test: 0.593014
PRC train: 0.868992	val: 0.671141	test: 0.615119

Epoch: 99
Loss: 0.3491354525066362
ROC train: 0.906231	val: 0.601523	test: 0.595294
PRC train: 0.869087	val: 0.668508	test: 0.619437

Epoch: 100
Loss: 0.3489495961227229
ROC train: 0.904799	val: 0.602110	test: 0.595109
PRC train: 0.868424	val: 0.669689	test: 0.621066

Epoch: 101
Loss: 0.3460291379919455
ROC train: 0.908110	val: 0.606858	test: 0.600539
PRC train: 0.872652	val: 0.672437	test: 0.621458

Epoch: 102
Loss: 0.3431990924872073
ROC train: 0.910359	val: 0.605177	test: 0.600630
PRC train: 0.873876	val: 0.670380	test: 0.623521

Epoch: 103
Loss: 0.3432214637257955
ROC train: 0.910327	val: 0.602955	test: 0.595224
PRC train: 0.873717	val: 0.665591	test: 0.619558

Epoch: 104
Loss: 0.3439473358704165
ROC train: 0.911177	val: 0.609865	test: 0.601932
PRC train: 0.876858	val: 0.668306	test: 0.618213

Epoch: 105
Loss: 0.3418081093745633
ROC train: 0.912917	val: 0.613613	test: 0.604960
PRC train: 0.878142	val: 0.675412	test: 0.622185

Epoch: 106
Loss: 0.3420688057736959
ROC train: 0.912444	val: 0.608276	test: 0.599152
PRC train: 0.878584	val: 0.674813	test: 0.619738

Epoch: 107
Loss: 0.33945020238569434
ROC train: 0.913202	val: 0.600452	test: 0.597451
PRC train: 0.878647	val: 0.666724	test: 0.618826

Epoch: 108
Loss: 0.3333973564730287
ROC train: 0.914129	val: 0.600919	test: 0.599554
PRC train: 0.880140	val: 0.666846	test: 0.617734

Epoch: 109
Loss: 0.3354740061615066
ROC train: 0.916038	val: 0.610251	test: 0.598088
PRC train: 0.882002	val: 0.673334	test: 0.620790

Epoch: 110
Loss: 0.3392297079018439
ROC train: 0.919631	val: 0.611799	test: 0.601075
PRC train: 0.884389	val: 0.673481	test: 0.623767

Epoch: 111
Loss: 0.33612820196865556
ROC train: 0.919720	val: 0.601135	test: 0.598857
PRC train: 0.883377	val: 0.663427	test: 0.615929

Epoch: 112
Loss: 0.3346676966126048
ROC train: 0.917388	val: 0.597399	test: 0.596395
PRC train: 0.880740	val: 0.656700	test: 0.613200

Epoch: 113
Loss: 0.3312948283671317
ROC train: 0.921156	val: 0.605371	test: 0.593750
PRC train: 0.887446	val: 0.663272	test: 0.614092

Epoch: 114
Loss: 0.3315494801481113
ROC train: 0.921733	val: 0.611972	test: 0.600296
PRC train: 0.886646	val: 0.671007	test: 0.618968

Epoch: 115
Loss: 0.32857828105747533
ROC train: 0.920144	val: 0.615127	test: 0.597224
PRC train: 0.886628	val: 0.674590	test: 0.618093

Epoch: 116
Loss: 0.32688571303105524
ROC train: 0.920035	val: 0.616021	test: 0.599332
PRC train: 0.885391	val: 0.674837	test: 0.616274

Epoch: 117
Loss: 0.3258685615049244
ROC train: 0.924572	val: 0.616421	test: 0.598474
PRC train: 0.889024	val: 0.672834	test: 0.615327

Epoch: 118
Loss: 0.3241314610651899
ROC train: 0.926826	val: 0.611586	test: 0.595969
PRC train: 0.894189	val: 0.671488	test: 0.614134

Epoch: 119
Loss: 0.32041163779649773
ROC train: 0.927507	val: 0.611088	test: 0.596036
PRC train: 0.895533	val: 0.670264	test: 0.614165

Epoch: 120
Loss: 0.316453116319486
ROC train: 0.925621	val: 0.607498	test: 0.595796
PRC train: 0.892192	val: 0.667818	test: 0.610966

Early stopping
Best (ROC):	 train: 0.866461	val: 0.623880	test: 0.614669
Best (PRC):	 train: 0.825384	val: 0.693414	test: 0.624516

ROC train: 0.907914	val: 0.619215	test: 0.608647
PRC train: 0.869722	val: 0.685526	test: 0.626631

Epoch: 95
Loss: 0.35240290684655134
ROC train: 0.910418	val: 0.619175	test: 0.613535
PRC train: 0.872915	val: 0.685430	test: 0.630388

Epoch: 96
Loss: 0.34867693887582474
ROC train: 0.908939	val: 0.619830	test: 0.617251
PRC train: 0.871899	val: 0.683154	test: 0.632173

Epoch: 97
Loss: 0.34468110020950377
ROC train: 0.910625	val: 0.623011	test: 0.610670
PRC train: 0.871101	val: 0.686766	test: 0.627082

Epoch: 98
Loss: 0.35079469091314713
ROC train: 0.908190	val: 0.626349	test: 0.603140
PRC train: 0.869208	val: 0.687319	test: 0.623486

Epoch: 99
Loss: 0.3417180488416877
ROC train: 0.909200	val: 0.626232	test: 0.603224
PRC train: 0.871173	val: 0.687544	test: 0.622100

Epoch: 100
Loss: 0.3416331423347476
ROC train: 0.912222	val: 0.630614	test: 0.608748
PRC train: 0.875061	val: 0.688264	test: 0.624168

Epoch: 101
Loss: 0.34179958053373494
ROC train: 0.910282	val: 0.624731	test: 0.609148
PRC train: 0.873172	val: 0.683384	test: 0.625450

Epoch: 102
Loss: 0.34277219879674364
ROC train: 0.912600	val: 0.616189	test: 0.603150
PRC train: 0.878920	val: 0.684826	test: 0.626948

Epoch: 103
Loss: 0.34400774020692426
ROC train: 0.917684	val: 0.619566	test: 0.607144
PRC train: 0.883514	val: 0.688219	test: 0.626767

Epoch: 104
Loss: 0.33402942525478296
ROC train: 0.919363	val: 0.624427	test: 0.613327
PRC train: 0.882136	val: 0.689000	test: 0.628010

Epoch: 105
Loss: 0.33768613526945523
ROC train: 0.916363	val: 0.622844	test: 0.615833
PRC train: 0.878872	val: 0.681601	test: 0.630329

Epoch: 106
Loss: 0.3371362657309265
ROC train: 0.914763	val: 0.620593	test: 0.615134
PRC train: 0.877393	val: 0.679289	test: 0.631544

Epoch: 107
Loss: 0.33218240136902477
ROC train: 0.917044	val: 0.618519	test: 0.607186
PRC train: 0.882083	val: 0.681560	test: 0.626182

Epoch: 108
Loss: 0.333234945748713
ROC train: 0.916597	val: 0.617982	test: 0.603091
PRC train: 0.880790	val: 0.684652	test: 0.625711

Epoch: 109
Loss: 0.33018559595885777
ROC train: 0.917309	val: 0.617721	test: 0.602154
PRC train: 0.882459	val: 0.686692	test: 0.627531

Epoch: 110
Loss: 0.33084004163089253
ROC train: 0.922674	val: 0.622640	test: 0.607470
PRC train: 0.888360	val: 0.686059	test: 0.628023

Epoch: 111
Loss: 0.3281129237641738
ROC train: 0.923516	val: 0.614450	test: 0.615170
PRC train: 0.890079	val: 0.680517	test: 0.627981

Epoch: 112
Loss: 0.3321330664740846
ROC train: 0.924802	val: 0.608289	test: 0.607338
PRC train: 0.890496	val: 0.679528	test: 0.625263

Epoch: 113
Loss: 0.323640970527006
ROC train: 0.926181	val: 0.610110	test: 0.605382
PRC train: 0.892772	val: 0.681780	test: 0.625355

Epoch: 114
Loss: 0.326082980736549
ROC train: 0.926145	val: 0.613545	test: 0.607403
PRC train: 0.893521	val: 0.685059	test: 0.628669

Epoch: 115
Loss: 0.3278360232168782
ROC train: 0.928089	val: 0.618583	test: 0.611247
PRC train: 0.895357	val: 0.686466	test: 0.630168

Epoch: 116
Loss: 0.32521388348796865
ROC train: 0.929110	val: 0.618405	test: 0.614528
PRC train: 0.893098	val: 0.685257	test: 0.630483

Epoch: 117
Loss: 0.3200874257624703
ROC train: 0.929538	val: 0.617280	test: 0.619471
PRC train: 0.894283	val: 0.683613	test: 0.635619

Epoch: 118
Loss: 0.32407322237917213
ROC train: 0.929280	val: 0.614706	test: 0.614986
PRC train: 0.895559	val: 0.682560	test: 0.632196

Epoch: 119
Loss: 0.32257992721708084
ROC train: 0.929697	val: 0.608601	test: 0.607751
PRC train: 0.895961	val: 0.679471	test: 0.627786

Epoch: 120
Loss: 0.3205230217919457
ROC train: 0.930167	val: 0.610761	test: 0.605464
PRC train: 0.896995	val: 0.677573	test: 0.627251

Early stopping
Best (ROC):	 train: 0.897359	val: 0.632151	test: 0.608958
Best (PRC):	 train: 0.855112	val: 0.695296	test: 0.623403

ROC train: 0.901842	val: 0.646662	test: 0.600682
PRC train: 0.860541	val: 0.677127	test: 0.622943

Epoch: 95
Loss: 0.3570442025310857
ROC train: 0.902446	val: 0.639112	test: 0.601377
PRC train: 0.860103	val: 0.672735	test: 0.624089

Epoch: 96
Loss: 0.36732183350219705
ROC train: 0.899456	val: 0.631711	test: 0.600266
PRC train: 0.853105	val: 0.669114	test: 0.623663

Epoch: 97
Loss: 0.3564203232976585
ROC train: 0.906757	val: 0.636334	test: 0.602504
PRC train: 0.862850	val: 0.672462	test: 0.622313

Epoch: 98
Loss: 0.3535399121315412
ROC train: 0.908388	val: 0.631928	test: 0.602230
PRC train: 0.864325	val: 0.668924	test: 0.621101

Epoch: 99
Loss: 0.3501039736261939
ROC train: 0.908984	val: 0.637543	test: 0.606763
PRC train: 0.863385	val: 0.670926	test: 0.625277

Epoch: 100
Loss: 0.34859961404474415
ROC train: 0.908470	val: 0.639702	test: 0.611030
PRC train: 0.861215	val: 0.669287	test: 0.627003

Epoch: 101
Loss: 0.35430284196878875
ROC train: 0.910921	val: 0.638123	test: 0.605674
PRC train: 0.866983	val: 0.667270	test: 0.623007

Epoch: 102
Loss: 0.3480182920064362
ROC train: 0.909479	val: 0.625651	test: 0.599651
PRC train: 0.870478	val: 0.660660	test: 0.619497

Epoch: 103
Loss: 0.3489651696723316
ROC train: 0.907768	val: 0.618512	test: 0.598616
PRC train: 0.868020	val: 0.659063	test: 0.618518

Epoch: 104
Loss: 0.3517796349095339
ROC train: 0.912022	val: 0.628732	test: 0.604949
PRC train: 0.873559	val: 0.668739	test: 0.624266

Epoch: 105
Loss: 0.34415432262320467
ROC train: 0.910404	val: 0.633792	test: 0.599693
PRC train: 0.870959	val: 0.672078	test: 0.622226

Epoch: 106
Loss: 0.3509033742969393
ROC train: 0.913628	val: 0.621618	test: 0.599194
PRC train: 0.873721	val: 0.665178	test: 0.622633

Epoch: 107
Loss: 0.33555231184329826
ROC train: 0.912142	val: 0.613547	test: 0.604215
PRC train: 0.871243	val: 0.659809	test: 0.624580

Epoch: 108
Loss: 0.343860758309554
ROC train: 0.912940	val: 0.625110	test: 0.610502
PRC train: 0.872321	val: 0.664440	test: 0.631275

Epoch: 109
Loss: 0.34502892259845785
ROC train: 0.917053	val: 0.632560	test: 0.611516
PRC train: 0.876619	val: 0.666475	test: 0.632544

Epoch: 110
Loss: 0.3363618674163901
ROC train: 0.915721	val: 0.626202	test: 0.612220
PRC train: 0.876502	val: 0.663939	test: 0.629396

Epoch: 111
Loss: 0.33570638002103015
ROC train: 0.916433	val: 0.626441	test: 0.613960
PRC train: 0.875297	val: 0.664549	test: 0.625878

Epoch: 112
Loss: 0.3438008686674669
ROC train: 0.917211	val: 0.626166	test: 0.613717
PRC train: 0.875421	val: 0.666851	test: 0.627184

Epoch: 113
Loss: 0.3348495136569462
ROC train: 0.917503	val: 0.628715	test: 0.613600
PRC train: 0.874848	val: 0.666137	test: 0.626973

Epoch: 114
Loss: 0.3411188142053987
ROC train: 0.917809	val: 0.630577	test: 0.611845
PRC train: 0.874461	val: 0.668139	test: 0.627117

Epoch: 115
Loss: 0.33120604084190153
ROC train: 0.921679	val: 0.628458	test: 0.615492
PRC train: 0.879037	val: 0.668159	test: 0.629999

Epoch: 116
Loss: 0.33775687557363987
ROC train: 0.924039	val: 0.629323	test: 0.617416
PRC train: 0.881073	val: 0.666460	test: 0.631839

Epoch: 117
Loss: 0.3335557077500107
ROC train: 0.921906	val: 0.630729	test: 0.612811
PRC train: 0.880799	val: 0.665093	test: 0.628973

Epoch: 118
Loss: 0.32732605852151897
ROC train: 0.921414	val: 0.633958	test: 0.613552
PRC train: 0.879981	val: 0.667692	test: 0.628172

Epoch: 119
Loss: 0.3274983460212258
ROC train: 0.924167	val: 0.632034	test: 0.618389
PRC train: 0.882382	val: 0.673215	test: 0.630506

Epoch: 120
Loss: 0.3304756699010613
ROC train: 0.924801	val: 0.632945	test: 0.619324
PRC train: 0.885214	val: 0.674894	test: 0.631836

Epoch: 121
Loss: 0.3289001762233491
ROC train: 0.924764	val: 0.630295	test: 0.617489
PRC train: 0.887051	val: 0.671779	test: 0.633759

Epoch: 122
Loss: 0.32546626055932115
ROC train: 0.926573	val: 0.633823	test: 0.617059
PRC train: 0.890504	val: 0.671535	test: 0.632684

Epoch: 123
Loss: 0.3231979479333709
ROC train: 0.926102	val: 0.640499	test: 0.613472
PRC train: 0.889016	val: 0.673493	test: 0.631772

Epoch: 124
Loss: 0.33023935004580107
ROC train: 0.925729	val: 0.638452	test: 0.606909
PRC train: 0.890761	val: 0.670495	test: 0.630048

Epoch: 125
Loss: 0.32571811086893365
ROC train: 0.926069	val: 0.631703	test: 0.609493
PRC train: 0.892013	val: 0.667191	test: 0.629318

Epoch: 126
Loss: 0.3388433705180604
ROC train: 0.929502	val: 0.627904	test: 0.608015
PRC train: 0.896418	val: 0.667668	test: 0.626225

Epoch: 127
Loss: 0.3262286228880658
ROC train: 0.931070	val: 0.628872	test: 0.615124
PRC train: 0.897559	val: 0.669233	test: 0.628458

Epoch: 128
Loss: 0.3206118457988509
ROC train: 0.931166	val: 0.632589	test: 0.620460
PRC train: 0.895759	val: 0.671737	test: 0.633237

Epoch: 129
Loss: 0.3243736280218976
ROC train: 0.932133	val: 0.637472	test: 0.619583
PRC train: 0.897239	val: 0.670657	test: 0.636035

Early stopping
Best (ROC):	 train: 0.901842	val: 0.646662	test: 0.600682
Best (PRC):	 train: 0.860541	val: 0.677127	test: 0.622943
All runs completed.
All runs completed.

ROC train: 0.897852	val: 0.635567	test: 0.608096
PRC train: 0.858836	val: 0.681856	test: 0.621075

Epoch: 95
Loss: 0.35559629048966024
ROC train: 0.898421	val: 0.633670	test: 0.610907
PRC train: 0.858924	val: 0.682147	test: 0.624033

Epoch: 96
Loss: 0.36525387311419255
ROC train: 0.900718	val: 0.624054	test: 0.608450
PRC train: 0.861704	val: 0.670796	test: 0.621793

Epoch: 97
Loss: 0.36174116487205293
ROC train: 0.902132	val: 0.614996	test: 0.610995
PRC train: 0.864816	val: 0.667221	test: 0.622239

Epoch: 98
Loss: 0.356447496356464
ROC train: 0.900334	val: 0.612986	test: 0.613412
PRC train: 0.860314	val: 0.670793	test: 0.622586

Epoch: 99
Loss: 0.35774709656664216
ROC train: 0.900224	val: 0.626323	test: 0.619617
PRC train: 0.862240	val: 0.679650	test: 0.625370

Epoch: 100
Loss: 0.35104134803188936
ROC train: 0.903280	val: 0.622159	test: 0.617255
PRC train: 0.864144	val: 0.676073	test: 0.624807

Epoch: 101
Loss: 0.350273736435539
ROC train: 0.904512	val: 0.629894	test: 0.612478
PRC train: 0.866668	val: 0.679025	test: 0.620115

Epoch: 102
Loss: 0.3541631177869964
ROC train: 0.905140	val: 0.632338	test: 0.601414
PRC train: 0.866267	val: 0.680544	test: 0.613055

Epoch: 103
Loss: 0.3544681503795138
ROC train: 0.904475	val: 0.625293	test: 0.601573
PRC train: 0.864813	val: 0.673925	test: 0.614234

Epoch: 104
Loss: 0.34607261631554886
ROC train: 0.903272	val: 0.623891	test: 0.614567
PRC train: 0.864138	val: 0.672618	test: 0.620697

Epoch: 105
Loss: 0.35207277452277724
ROC train: 0.908276	val: 0.625613	test: 0.611809
PRC train: 0.872503	val: 0.681298	test: 0.619552

Epoch: 106
Loss: 0.35300877577561185
ROC train: 0.911059	val: 0.637148	test: 0.611418
PRC train: 0.874034	val: 0.691206	test: 0.621630

Epoch: 107
Loss: 0.3468102100816105
ROC train: 0.910847	val: 0.633054	test: 0.609467
PRC train: 0.875851	val: 0.680789	test: 0.621226

Epoch: 108
Loss: 0.3454272303813114
ROC train: 0.910047	val: 0.628690	test: 0.607848
PRC train: 0.875672	val: 0.672424	test: 0.618395

Epoch: 109
Loss: 0.3440092047270976
ROC train: 0.910977	val: 0.625864	test: 0.603567
PRC train: 0.875941	val: 0.673418	test: 0.609575

Epoch: 110
Loss: 0.3399919357868283
ROC train: 0.914199	val: 0.628601	test: 0.601706
PRC train: 0.880129	val: 0.682861	test: 0.613164

Epoch: 111
Loss: 0.34333270677894545
ROC train: 0.914983	val: 0.618703	test: 0.608434
PRC train: 0.881020	val: 0.675229	test: 0.621131

Epoch: 112
Loss: 0.3368323727216409
ROC train: 0.915159	val: 0.619261	test: 0.606860
PRC train: 0.880010	val: 0.674204	test: 0.619459

Epoch: 113
Loss: 0.341833241676125
ROC train: 0.914791	val: 0.633792	test: 0.610917
PRC train: 0.878947	val: 0.682934	test: 0.620738

Epoch: 114
Loss: 0.33998776240479256
ROC train: 0.916814	val: 0.634664	test: 0.605887
PRC train: 0.880554	val: 0.681565	test: 0.623676

Epoch: 115
Loss: 0.3318390733810995
ROC train: 0.913632	val: 0.627092	test: 0.612621
PRC train: 0.877780	val: 0.671885	test: 0.632352

Epoch: 116
Loss: 0.336300069569262
ROC train: 0.917415	val: 0.634905	test: 0.617002
PRC train: 0.881526	val: 0.677146	test: 0.630487

Epoch: 117
Loss: 0.3374139252529386
ROC train: 0.918817	val: 0.630504	test: 0.603228
PRC train: 0.883436	val: 0.676290	test: 0.618537

Epoch: 118
Loss: 0.3344484474357351
ROC train: 0.919185	val: 0.625788	test: 0.600390
PRC train: 0.884638	val: 0.673316	test: 0.616832

Epoch: 119
Loss: 0.3282241543906854
ROC train: 0.920056	val: 0.635505	test: 0.602378
PRC train: 0.885942	val: 0.680702	test: 0.615306

Epoch: 120
Loss: 0.33875571500563456
ROC train: 0.920513	val: 0.635625	test: 0.601689
PRC train: 0.885520	val: 0.685791	test: 0.613879

Early stopping
Best (ROC):	 train: 0.832752	val: 0.643549	test: 0.596595
Best (PRC):	 train: 0.791496	val: 0.679063	test: 0.601975

ROC train: 0.897417	val: 0.638668	test: 0.589261
PRC train: 0.858267	val: 0.687249	test: 0.598538

Epoch: 95
Loss: 0.35638369234826195
ROC train: 0.898256	val: 0.637850	test: 0.591424
PRC train: 0.858528	val: 0.686153	test: 0.606038

Epoch: 96
Loss: 0.35506388271144174
ROC train: 0.900252	val: 0.647286	test: 0.595852
PRC train: 0.859196	val: 0.684278	test: 0.605520

Epoch: 97
Loss: 0.35740456724615227
ROC train: 0.899988	val: 0.641695	test: 0.592727
PRC train: 0.859281	val: 0.679913	test: 0.604578

Epoch: 98
Loss: 0.3585034786778124
ROC train: 0.899302	val: 0.628481	test: 0.585243
PRC train: 0.857053	val: 0.675494	test: 0.604702

Epoch: 99
Loss: 0.3554472098975968
ROC train: 0.900804	val: 0.630237	test: 0.584759
PRC train: 0.858692	val: 0.674151	test: 0.603735

Epoch: 100
Loss: 0.35001001436255297
ROC train: 0.902986	val: 0.636936	test: 0.589499
PRC train: 0.862980	val: 0.680910	test: 0.603053

Epoch: 101
Loss: 0.3485777927580645
ROC train: 0.902769	val: 0.637037	test: 0.585827
PRC train: 0.861949	val: 0.680179	test: 0.598992

Epoch: 102
Loss: 0.3484244427056661
ROC train: 0.906327	val: 0.634661	test: 0.589234
PRC train: 0.867324	val: 0.682191	test: 0.603448

Epoch: 103
Loss: 0.3571406239374781
ROC train: 0.907146	val: 0.633510	test: 0.587886
PRC train: 0.867256	val: 0.680318	test: 0.599018

Epoch: 104
Loss: 0.3481623180803267
ROC train: 0.906466	val: 0.621344	test: 0.582356
PRC train: 0.868361	val: 0.674662	test: 0.594074

Epoch: 105
Loss: 0.34910060092349177
ROC train: 0.909902	val: 0.633995	test: 0.585309
PRC train: 0.872649	val: 0.680159	test: 0.592103

Epoch: 106
Loss: 0.34770695383251954
ROC train: 0.909275	val: 0.632396	test: 0.589609
PRC train: 0.871940	val: 0.680332	test: 0.598114

Epoch: 107
Loss: 0.3403309857931325
ROC train: 0.909026	val: 0.626782	test: 0.596295
PRC train: 0.873162	val: 0.676146	test: 0.598669

Epoch: 108
Loss: 0.3374282780624707
ROC train: 0.909535	val: 0.640329	test: 0.589049
PRC train: 0.872422	val: 0.683275	test: 0.592166

Epoch: 109
Loss: 0.3500956218899952
ROC train: 0.912401	val: 0.651298	test: 0.591834
PRC train: 0.873366	val: 0.690389	test: 0.599918

Epoch: 110
Loss: 0.34545047686701286
ROC train: 0.911811	val: 0.629398	test: 0.600681
PRC train: 0.876314	val: 0.680962	test: 0.610466

Epoch: 111
Loss: 0.34013441395215704
ROC train: 0.909158	val: 0.634108	test: 0.593500
PRC train: 0.870429	val: 0.677327	test: 0.603661

Epoch: 112
Loss: 0.3436789752158839
ROC train: 0.914470	val: 0.636223	test: 0.586108
PRC train: 0.875962	val: 0.678198	test: 0.597795

Epoch: 113
Loss: 0.34261014963127084
ROC train: 0.916084	val: 0.642514	test: 0.589630
PRC train: 0.876849	val: 0.686079	test: 0.598530

Epoch: 114
Loss: 0.3386008099479588
ROC train: 0.915134	val: 0.646081	test: 0.600234
PRC train: 0.877465	val: 0.688146	test: 0.602196

Epoch: 115
Loss: 0.3362890736002153
ROC train: 0.915282	val: 0.644267	test: 0.599170
PRC train: 0.880765	val: 0.686739	test: 0.600711

Epoch: 116
Loss: 0.3371348667277915
ROC train: 0.918796	val: 0.636809	test: 0.601611
PRC train: 0.884852	val: 0.678519	test: 0.603357

Epoch: 117
Loss: 0.3381671458449874
ROC train: 0.917026	val: 0.634581	test: 0.604629
PRC train: 0.882823	val: 0.672376	test: 0.608707

Epoch: 118
Loss: 0.3329355704497062
ROC train: 0.919349	val: 0.637424	test: 0.605921
PRC train: 0.886212	val: 0.677709	test: 0.608437

Epoch: 119
Loss: 0.3335387227410386
ROC train: 0.916454	val: 0.636397	test: 0.596541
PRC train: 0.882176	val: 0.672365	test: 0.603664

Epoch: 120
Loss: 0.33097018065816664
ROC train: 0.919456	val: 0.638482	test: 0.595828
PRC train: 0.885185	val: 0.674619	test: 0.603015

Epoch: 121
Loss: 0.32494775700262857
ROC train: 0.923238	val: 0.638765	test: 0.599253
PRC train: 0.887092	val: 0.681867	test: 0.607347

Epoch: 122
Loss: 0.33462677919438716
ROC train: 0.921649	val: 0.636922	test: 0.599197
PRC train: 0.886574	val: 0.682222	test: 0.606546

Epoch: 123
Loss: 0.3286400039293905
ROC train: 0.923703	val: 0.643592	test: 0.599763
PRC train: 0.889290	val: 0.681986	test: 0.607405

Epoch: 124
Loss: 0.3225076771046209
ROC train: 0.925379	val: 0.647838	test: 0.596067
PRC train: 0.890225	val: 0.688334	test: 0.604624

Epoch: 125
Loss: 0.3256547636642592
ROC train: 0.927568	val: 0.642975	test: 0.595493
PRC train: 0.894781	val: 0.686632	test: 0.600602

Epoch: 126
Loss: 0.32240319189537636
ROC train: 0.928084	val: 0.636375	test: 0.598511
PRC train: 0.897252	val: 0.686318	test: 0.604680

Epoch: 127
Loss: 0.3293500179596882
ROC train: 0.924872	val: 0.630722	test: 0.598356
PRC train: 0.891829	val: 0.681646	test: 0.605671

Epoch: 128
Loss: 0.32002245316948535
ROC train: 0.928629	val: 0.640446	test: 0.591974
PRC train: 0.895619	val: 0.688849	test: 0.600820

Epoch: 129
Loss: 0.3235693360666064
ROC train: 0.927546	val: 0.645137	test: 0.593012
PRC train: 0.893949	val: 0.690010	test: 0.599271

Epoch: 130
Loss: 0.3184734950530535
ROC train: 0.929197	val: 0.644186	test: 0.595364
PRC train: 0.896043	val: 0.687593	test: 0.600955

Epoch: 131
Loss: 0.31673674418337094
ROC train: 0.930626	val: 0.644057	test: 0.593432
PRC train: 0.899463	val: 0.684035	test: 0.600868

Epoch: 132
Loss: 0.3179533903863998
ROC train: 0.931890	val: 0.641810	test: 0.598226
PRC train: 0.900441	val: 0.684839	test: 0.601189

Epoch: 133
Loss: 0.31620569586177655
ROC train: 0.931912	val: 0.647618	test: 0.601248
PRC train: 0.898368	val: 0.686432	test: 0.601045

Epoch: 134
Loss: 0.31742621256874975
ROC train: 0.932843	val: 0.645946	test: 0.599910
PRC train: 0.900706	val: 0.681161	test: 0.601003

Epoch: 135
Loss: 0.31350521550510285
ROC train: 0.932015	val: 0.645664	test: 0.602841
PRC train: 0.899731	val: 0.682914	test: 0.602982

Epoch: 136
Loss: 0.3177279185886933
ROC train: 0.934794	val: 0.638335	test: 0.602060
PRC train: 0.901672	val: 0.682287	test: 0.605318

Epoch: 137
Loss: 0.3150045967307475
ROC train: 0.935102	val: 0.637698	test: 0.596795
PRC train: 0.901865	val: 0.679542	test: 0.607063

Epoch: 138
Loss: 0.31134337820986674
ROC train: 0.935292	val: 0.635272	test: 0.600736
PRC train: 0.904098	val: 0.679063	test: 0.607171

Epoch: 139
Loss: 0.312881983074281
ROC train: 0.934938	val: 0.634105	test: 0.599233
PRC train: 0.901709	val: 0.679916	test: 0.603426

Epoch: 140
Loss: 0.31224990212020753
ROC train: 0.934287	val: 0.634434	test: 0.600529
PRC train: 0.901864	val: 0.679369	test: 0.605088

Epoch: 141
Loss: 0.3090506435803395
ROC train: 0.935537	val: 0.637294	test: 0.606841
PRC train: 0.902429	val: 0.681478	test: 0.612783

Epoch: 142
Loss: 0.3017904390679755
ROC train: 0.940484	val: 0.636793	test: 0.607946
PRC train: 0.910423	val: 0.681982	test: 0.616217

Epoch: 143
Loss: 0.30579209118445294
ROC train: 0.941316	val: 0.639289	test: 0.601258
PRC train: 0.909549	val: 0.683984	test: 0.613519

Epoch: 144
Loss: 0.30742244381604095
ROC train: 0.941058	val: 0.641534	test: 0.600145
PRC train: 0.910389	val: 0.680017	test: 0.612956

Early stopping
Best (ROC):	 train: 0.912401	val: 0.651298	test: 0.591834
Best (PRC):	 train: 0.873366	val: 0.690389	test: 0.599918

ROC train: 0.888864	val: 0.622775	test: 0.617710
PRC train: 0.851499	val: 0.678702	test: 0.628504

Epoch: 95
Loss: 0.3613962628217833
ROC train: 0.893041	val: 0.623166	test: 0.624949
PRC train: 0.856333	val: 0.677689	test: 0.632601

Epoch: 96
Loss: 0.36508112361628003
ROC train: 0.892306	val: 0.624023	test: 0.629474
PRC train: 0.856280	val: 0.676842	test: 0.636380

Epoch: 97
Loss: 0.3553538723287823
ROC train: 0.895870	val: 0.623939	test: 0.624825
PRC train: 0.861329	val: 0.675588	test: 0.637599

Epoch: 98
Loss: 0.3641024327006884
ROC train: 0.894878	val: 0.625397	test: 0.618214
PRC train: 0.858853	val: 0.678565	test: 0.634270

Epoch: 99
Loss: 0.36425346027936617
ROC train: 0.893654	val: 0.632900	test: 0.619141
PRC train: 0.859317	val: 0.681724	test: 0.632463

Epoch: 100
Loss: 0.37088322491383363
ROC train: 0.893904	val: 0.632938	test: 0.629579
PRC train: 0.858401	val: 0.675924	test: 0.634834

Epoch: 101
Loss: 0.35902223176341463
ROC train: 0.898286	val: 0.627606	test: 0.631616
PRC train: 0.864726	val: 0.678668	test: 0.636321

Epoch: 102
Loss: 0.3606578814734419
ROC train: 0.897644	val: 0.635164	test: 0.624238
PRC train: 0.863982	val: 0.683139	test: 0.634010

Epoch: 103
Loss: 0.35626496278573727
ROC train: 0.899561	val: 0.626856	test: 0.627449
PRC train: 0.866433	val: 0.678043	test: 0.638259

Epoch: 104
Loss: 0.35048078097693935
ROC train: 0.903087	val: 0.629034	test: 0.631334
PRC train: 0.870206	val: 0.678186	test: 0.643041

Epoch: 105
Loss: 0.3516743037540064
ROC train: 0.904561	val: 0.636447	test: 0.637255
PRC train: 0.870750	val: 0.683770	test: 0.648452

Epoch: 106
Loss: 0.35073509710430895
ROC train: 0.905188	val: 0.637069	test: 0.635825
PRC train: 0.872228	val: 0.687853	test: 0.643337

Epoch: 107
Loss: 0.34957877802288506
ROC train: 0.907916	val: 0.629411	test: 0.625707
PRC train: 0.875180	val: 0.675429	test: 0.636012

Epoch: 108
Loss: 0.35502860657698143
ROC train: 0.904456	val: 0.625934	test: 0.619350
PRC train: 0.872786	val: 0.674127	test: 0.626935

Epoch: 109
Loss: 0.3460915552676059
ROC train: 0.907883	val: 0.631816	test: 0.618496
PRC train: 0.876109	val: 0.681040	test: 0.631559

Epoch: 110
Loss: 0.34536337825758306
ROC train: 0.907161	val: 0.630473	test: 0.622393
PRC train: 0.874305	val: 0.681402	test: 0.634009

Epoch: 111
Loss: 0.3487092864234168
ROC train: 0.909722	val: 0.629837	test: 0.626317
PRC train: 0.877160	val: 0.683480	test: 0.635646

Epoch: 112
Loss: 0.3396585157762679
ROC train: 0.908889	val: 0.626451	test: 0.633529
PRC train: 0.875450	val: 0.682824	test: 0.642754

Epoch: 113
Loss: 0.34190769665793874
ROC train: 0.909752	val: 0.629860	test: 0.623837
PRC train: 0.873560	val: 0.685650	test: 0.634042

Epoch: 114
Loss: 0.34173977388334337
ROC train: 0.915238	val: 0.628613	test: 0.629159
PRC train: 0.884219	val: 0.682433	test: 0.638348

Epoch: 115
Loss: 0.3444955995799854
ROC train: 0.913234	val: 0.624492	test: 0.619400
PRC train: 0.882712	val: 0.681959	test: 0.633988

Epoch: 116
Loss: 0.3408089999118074
ROC train: 0.911566	val: 0.627273	test: 0.615542
PRC train: 0.878622	val: 0.679019	test: 0.632728

Epoch: 117
Loss: 0.33586545540579643
ROC train: 0.914756	val: 0.635949	test: 0.622587
PRC train: 0.880672	val: 0.674776	test: 0.635581

Epoch: 118
Loss: 0.3374540010691541
ROC train: 0.916266	val: 0.634527	test: 0.628024
PRC train: 0.882689	val: 0.680995	test: 0.640823

Epoch: 119
Loss: 0.338878388807217
ROC train: 0.916178	val: 0.632955	test: 0.626253
PRC train: 0.880638	val: 0.689707	test: 0.635909

Epoch: 120
Loss: 0.3378155530378142
ROC train: 0.918395	val: 0.630950	test: 0.625127
PRC train: 0.887986	val: 0.687486	test: 0.635487

Epoch: 121
Loss: 0.3377468242718467
ROC train: 0.916932	val: 0.623565	test: 0.619594
PRC train: 0.884211	val: 0.675425	test: 0.629883

Epoch: 122
Loss: 0.3281377686606998
ROC train: 0.921201	val: 0.631586	test: 0.629681
PRC train: 0.889992	val: 0.680533	test: 0.634808

Epoch: 123
Loss: 0.33118310775059817
ROC train: 0.922339	val: 0.640225	test: 0.631854
PRC train: 0.890980	val: 0.689824	test: 0.638096

Epoch: 124
Loss: 0.3317996881949745
ROC train: 0.922457	val: 0.634006	test: 0.630009
PRC train: 0.892400	val: 0.682380	test: 0.642956

Epoch: 125
Loss: 0.3387225621405254
ROC train: 0.922896	val: 0.626259	test: 0.626229
PRC train: 0.894007	val: 0.683090	test: 0.638274

Epoch: 126
Loss: 0.32700997421756484
ROC train: 0.921776	val: 0.631071	test: 0.623190
PRC train: 0.891112	val: 0.690729	test: 0.636085

Epoch: 127
Loss: 0.3260151230688991
ROC train: 0.925626	val: 0.633571	test: 0.627507
PRC train: 0.897555	val: 0.686100	test: 0.637675

Epoch: 128
Loss: 0.32568662231195605
ROC train: 0.926614	val: 0.631598	test: 0.627477
PRC train: 0.898676	val: 0.682440	test: 0.634721

Epoch: 129
Loss: 0.3234328232090381
ROC train: 0.926286	val: 0.638708	test: 0.623115
PRC train: 0.898983	val: 0.691963	test: 0.633773

Epoch: 130
Loss: 0.31990214321307264
ROC train: 0.927142	val: 0.639535	test: 0.622235
PRC train: 0.895509	val: 0.694082	test: 0.630335

Epoch: 131
Loss: 0.32131253656078884
ROC train: 0.929285	val: 0.636972	test: 0.618333
PRC train: 0.899329	val: 0.683348	test: 0.626551

Epoch: 132
Loss: 0.32185703787322745
ROC train: 0.929567	val: 0.636494	test: 0.620865
PRC train: 0.900977	val: 0.681043	test: 0.634181

Epoch: 133
Loss: 0.3170398784276397
ROC train: 0.930513	val: 0.639181	test: 0.622631
PRC train: 0.899980	val: 0.690418	test: 0.635896

Epoch: 134
Loss: 0.3145405791948577
ROC train: 0.930344	val: 0.643048	test: 0.622959
PRC train: 0.901109	val: 0.690031	test: 0.634915

Epoch: 135
Loss: 0.31654045122612023
ROC train: 0.932226	val: 0.643270	test: 0.626262
PRC train: 0.904294	val: 0.690565	test: 0.637606

Epoch: 136
Loss: 0.3173894165306415
ROC train: 0.931437	val: 0.644397	test: 0.627285
PRC train: 0.904751	val: 0.692582	test: 0.637615

Epoch: 137
Loss: 0.31957805044262316
ROC train: 0.932898	val: 0.640020	test: 0.623752
PRC train: 0.907043	val: 0.691323	test: 0.637385

Epoch: 138
Loss: 0.3166505809229142
ROC train: 0.931741	val: 0.636744	test: 0.622989
PRC train: 0.905203	val: 0.691306	test: 0.636231

Epoch: 139
Loss: 0.31409730515876416
ROC train: 0.931990	val: 0.633979	test: 0.620804
PRC train: 0.904546	val: 0.687142	test: 0.633014

Epoch: 140
Loss: 0.3193732492839468
ROC train: 0.935428	val: 0.634645	test: 0.617125
PRC train: 0.911367	val: 0.686200	test: 0.630459

Epoch: 141
Loss: 0.30831551788130074
ROC train: 0.937190	val: 0.640706	test: 0.613349
PRC train: 0.912573	val: 0.693554	test: 0.625735

Epoch: 142
Loss: 0.3179170233709367
ROC train: 0.935749	val: 0.644787	test: 0.615975
PRC train: 0.910478	val: 0.693559	test: 0.626262

Epoch: 143
Loss: 0.3139598547171678
ROC train: 0.938003	val: 0.634621	test: 0.621905
PRC train: 0.913716	val: 0.687125	test: 0.634230

Epoch: 144
Loss: 0.3098790825218655
ROC train: 0.936514	val: 0.632104	test: 0.629141
PRC train: 0.910977	val: 0.683590	test: 0.642022

Epoch: 145
Loss: 0.3078309953981499
ROC train: 0.938413	val: 0.637429	test: 0.616716
PRC train: 0.913085	val: 0.683916	test: 0.629202

Epoch: 146
Loss: 0.31024661437584616
ROC train: 0.937480	val: 0.635412	test: 0.606956
PRC train: 0.911115	val: 0.685669	test: 0.618197

Epoch: 147
Loss: 0.30398780510539614
ROC train: 0.937982	val: 0.635964	test: 0.619774
PRC train: 0.912409	val: 0.680974	test: 0.626394

Epoch: 148
Loss: 0.30292019157557315
ROC train: 0.939034	val: 0.627616	test: 0.616868
PRC train: 0.913684	val: 0.677012	test: 0.628025

Epoch: 149
Loss: 0.3089197431123799
ROC train: 0.941029	val: 0.627687	test: 0.617878
PRC train: 0.914539	val: 0.681539	test: 0.627347

Epoch: 150
Loss: 0.3077704898940042
ROC train: 0.942284	val: 0.628231	test: 0.620151
PRC train: 0.914239	val: 0.680947	test: 0.630250

Epoch: 151
Loss: 0.30761914555629566
ROC train: 0.944560	val: 0.628449	test: 0.617506
PRC train: 0.919055	val: 0.684413	test: 0.631484

Epoch: 152
Loss: 0.29865686727905205
ROC train: 0.942208	val: 0.628450	test: 0.612999
PRC train: 0.915068	val: 0.678229	test: 0.627887

Epoch: 153
Loss: 0.30096927172071936
ROC train: 0.942291	val: 0.629561	test: 0.613455
PRC train: 0.917627	val: 0.681174	test: 0.627235

Epoch: 154
Loss: 0.3031389987926415
ROC train: 0.942818	val: 0.640787	test: 0.614195
PRC train: 0.918595	val: 0.690609	test: 0.625075

Epoch: 155
Loss: 0.2940703293530228
ROC train: 0.944738	val: 0.640974	test: 0.617282
PRC train: 0.921708	val: 0.687991	test: 0.629596

Epoch: 156
Loss: 0.29583241910523894
ROC train: 0.942063	val: 0.629082	test: 0.617604
PRC train: 0.919342	val: 0.678174	test: 0.627919

Epoch: 157
Loss: 0.298450916295559
ROC train: 0.946204	val: 0.637060	test: 0.611791
PRC train: 0.920892	val: 0.683533	test: 0.617494

Epoch: 158
Loss: 0.30598953923018557
ROC train: 0.945300	val: 0.638834	test: 0.605302
PRC train: 0.918438	val: 0.681964	test: 0.612534

Epoch: 159
Loss: 0.29698059328125026
ROC train: 0.947638	val: 0.638642	test: 0.611756
PRC train: 0.927350	val: 0.690091	test: 0.619954

Epoch: 160
Loss: 0.2925195998256095
ROC train: 0.948438	val: 0.639364	test: 0.615963
PRC train: 0.926606	val: 0.689480	test: 0.621903

Epoch: 161
Loss: 0.2867116654037605
ROC train: 0.949431	val: 0.639444	test: 0.618082
PRC train: 0.927292	val: 0.685306	test: 0.620381

Epoch: 162
Loss: 0.29428500015173814
ROC train: 0.948653	val: 0.634484	test: 0.621578
PRC train: 0.928152	val: 0.683399	test: 0.625680

Epoch: 163
Loss: 0.2920368921502742
ROC train: 0.948942	val: 0.630411	test: 0.617740
PRC train: 0.928713	val: 0.679801	test: 0.626756

Epoch: 164
Loss: 0.29745152809632847
ROC train: 0.951544	val: 0.625831	test: 0.616326
PRC train: 0.930199	val: 0.676504	test: 0.626787

Epoch: 165
Loss: 0.29022239615733814
ROC train: 0.952540	val: 0.623596	test: 0.619077
PRC train: 0.931637	val: 0.676346	test: 0.629223

Epoch: 166
Loss: 0.2898857320304253
ROC train: 0.952027	val: 0.631086	test: 0.621593
PRC train: 0.929403	val: 0.683529	test: 0.628606

Epoch: 167
Loss: 0.2937776944999738
ROC train: 0.951792	val: 0.632026	test: 0.622395
PRC train: 0.927134	val: 0.681922	test: 0.624264

Epoch: 168
Loss: 0.2918928722596833
ROC train: 0.953100	val: 0.622486	test: 0.615793
PRC train: 0.930296	val: 0.678778	test: 0.618538

Epoch: 169
Loss: 0.28868469517163586
ROC train: 0.954626	val: 0.630349	test: 0.615669
PRC train: 0.934412	val: 0.686601	test: 0.623130

Epoch: 170
Loss: 0.2853586864632617
ROC train: 0.956246	val: 0.642493	test: 0.609489
PRC train: 0.937616	val: 0.692332	test: 0.619577

Epoch: 171
Loss: 0.2806312456401227
ROC train: 0.956093	val: 0.636686	test: 0.613130
PRC train: 0.936412	val: 0.686348	test: 0.621458

Epoch: 172
Loss: 0.2856098065306176
ROC train: 0.956409	val: 0.632053	test: 0.615341
PRC train: 0.936240	val: 0.681282	test: 0.625756

Epoch: 173
Loss: 0.2768720887596752
ROC train: 0.956665	val: 0.632274	test: 0.611727
PRC train: 0.938104	val: 0.682545	test: 0.621346

Epoch: 174
Loss: 0.2859336950697031
ROC train: 0.958475	val: 0.632806	test: 0.614331
PRC train: 0.940936	val: 0.679962	test: 0.620002

Epoch: 175
Loss: 0.28187955011559146
ROC train: 0.956836	val: 0.631692	test: 0.613726
PRC train: 0.938425	val: 0.680755	test: 0.621818

Epoch: 176
Loss: 0.27807726589727544
ROC train: 0.957425	val: 0.632641	test: 0.611568
PRC train: 0.938962	val: 0.679443	test: 0.622153

Epoch: 177
Loss: 0.2748161795980009
ROC train: 0.957545	val: 0.635410	test: 0.611563
PRC train: 0.937506	val: 0.681503	test: 0.620938

Early stopping
Best (ROC):	 train: 0.935749	val: 0.644787	test: 0.615975
Best (PRC):	 train: 0.910478	val: 0.693559	test: 0.626262
All runs completed.
