>>> Starting run for dataset: sider
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running RANDOM configs_static_noise_experiments/GraphMVP/sider/noise=0.0.yml on cuda:0
Running RANDOM configs_static_noise_experiments/GraphMVP/sider/noise=0.05.yml on cuda:1
Running RANDOM configs_static_noise_experiments/GraphMVP/sider/noise=0.1.yml on cuda:2
Running RANDOM configs_static_noise_experiments/GraphMVP/sider/noise=0.2.yml on cuda:3
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/sider/noise=0.0.yml --runseed 4 --device cuda:0
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/sider/noise=0.0.yml --runseed 5 --device cuda:0
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/sider/noise=0.0.yml --runseed 6 --device cuda:0
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/sider/noise=0.2.yml --runseed 4 --device cuda:3
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/sider/noise=0.05.yml --runseed 4 --device cuda:1
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/sider/noise=0.2.yml --runseed 5 --device cuda:3
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/sider/noise=0.05.yml --runseed 5 --device cuda:1
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/sider/noise=0.1.yml --runseed 4 --device cuda:2
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/sider/noise=0.05.yml --runseed 6 --device cuda:1
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/sider/noise=0.2.yml --runseed 6 --device cuda:3
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/sider/noise=0.1.yml --runseed 5 --device cuda:2
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/sider/noise=0.1.yml --runseed 6 --device cuda:2
[11:20:03] WARNING: not removing hydrogen atom without neighbors
[11:20:03] WARNING: not removing hydrogen atom without neighbors
[11:20:03] WARNING: not removing hydrogen atom without neighbors
[11:20:03] WARNING: not removing hydrogen atom without neighbors
[11:20:03] WARNING: not removing hydrogen atom without neighbors
[11:20:03] WARNING: not removing hydrogen atom without neighbors
[11:20:03] WARNING: not removing hydrogen atom without neighbors
[11:20:03] WARNING: not removing hydrogen atom without neighbors
[11:20:03] WARNING: not removing hydrogen atom without neighbors
[11:20:03] WARNING: not removing hydrogen atom without neighbors
[11:20:03] WARNING: not removing hydrogen atom without neighbors
[11:20:03] WARNING: not removing hydrogen atom without neighbors
[11:20:03] WARNING: not removing hydrogen atom without neighbors
[11:20:03] WARNING: not removing hydrogen atom without neighbors
[11:20:03] WARNING: not removing hydrogen atom without neighbors
[11:20:03] WARNING: not removing hydrogen atom without neighbors
[11:20:03] WARNING: not removing hydrogen atom without neighbors
[11:20:03] WARNING: not removing hydrogen atom without neighbors
[11:20:03] WARNING: not removing hydrogen atom without neighbors
[11:20:03] WARNING: not removing hydrogen atom without neighbors
[11:20:03] WARNING: not removing hydrogen atom without neighbors
[11:20:03] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:04] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:05] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:06] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:07] WARNING: not removing hydrogen atom without neighbors
[11:20:08] WARNING: not removing hydrogen atom without neighbors
[11:20:08] WARNING: not removing hydrogen atom without neighbors
[11:20:08] WARNING: not removing hydrogen atom without neighbors
[11:20:08] WARNING: not removing hydrogen atom without neighbors
[11:20:08] WARNING: not removing hydrogen atom without neighbors
[11:20:08] WARNING: not removing hydrogen atom without neighbors
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/sider/noise=0.0.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/sider/noise=0.0
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/sider/noise=0.0/sider_scaff_5_26-05_11-20-03  ]
[ Using Seed :  5  ]
[ Using device :  cuda:0  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6859728953156055
ROC train: 0.528355	val: 0.491872	test: 0.492807
PRC train: 0.575482	val: 0.600114	test: 0.579849

Epoch: 2
Loss: 0.6460583905415593
ROC train: 0.557026	val: 0.497434	test: 0.515312
PRC train: 0.597472	val: 0.604253	test: 0.588540

Epoch: 3
Loss: 0.6115477407754782
ROC train: 0.575048	val: 0.495590	test: 0.533891
PRC train: 0.610584	val: 0.600343	test: 0.596354

Epoch: 4
Loss: 0.5849514012308312
ROC train: 0.596828	val: 0.506022	test: 0.543971
PRC train: 0.622143	val: 0.605797	test: 0.604798

Epoch: 5
Loss: 0.5630048068077498
ROC train: 0.621540	val: 0.540394	test: 0.563467
PRC train: 0.636977	val: 0.621706	test: 0.609656

Epoch: 6
Loss: 0.5468913285895445
ROC train: 0.640073	val: 0.560899	test: 0.580637
PRC train: 0.645235	val: 0.632368	test: 0.612761

Epoch: 7
Loss: 0.5349273104913393
ROC train: 0.654453	val: 0.569447	test: 0.586280
PRC train: 0.656370	val: 0.636661	test: 0.615882

Epoch: 8
Loss: 0.5256212394434476
ROC train: 0.662270	val: 0.573724	test: 0.591345
PRC train: 0.662616	val: 0.637746	test: 0.618918

Epoch: 9
Loss: 0.5186715139223056
ROC train: 0.674856	val: 0.583908	test: 0.598481
PRC train: 0.669417	val: 0.641827	test: 0.622147

Epoch: 10
Loss: 0.5128048308029557
ROC train: 0.682127	val: 0.585981	test: 0.593633
PRC train: 0.674400	val: 0.640991	test: 0.619136

Epoch: 11
Loss: 0.5045957880607728
ROC train: 0.694417	val: 0.594345	test: 0.596956
PRC train: 0.679051	val: 0.644964	test: 0.621772

Epoch: 12
Loss: 0.4983114511119794
ROC train: 0.700562	val: 0.604994	test: 0.603558
PRC train: 0.683276	val: 0.650351	test: 0.626798

Epoch: 13
Loss: 0.4943900778293296
ROC train: 0.702287	val: 0.606456	test: 0.594852
PRC train: 0.685815	val: 0.650076	test: 0.623235

Epoch: 14
Loss: 0.488250008562457
ROC train: 0.709153	val: 0.614901	test: 0.599146
PRC train: 0.690769	val: 0.654158	test: 0.625745

Epoch: 15
Loss: 0.48894693295849245
ROC train: 0.719555	val: 0.611148	test: 0.608736
PRC train: 0.698048	val: 0.653120	test: 0.629801

Epoch: 16
Loss: 0.4856699697888923
ROC train: 0.719496	val: 0.597578	test: 0.606125
PRC train: 0.699571	val: 0.649544	test: 0.628625

Epoch: 17
Loss: 0.4775783969455719
ROC train: 0.723775	val: 0.613881	test: 0.604378
PRC train: 0.700480	val: 0.655163	test: 0.629309

Epoch: 18
Loss: 0.4751527215633555
ROC train: 0.730181	val: 0.613280	test: 0.599344
PRC train: 0.708645	val: 0.655857	test: 0.623496

Epoch: 19
Loss: 0.468550690443824
ROC train: 0.732125	val: 0.606343	test: 0.599484
PRC train: 0.710971	val: 0.653823	test: 0.623785

Epoch: 20
Loss: 0.47434679899114957
ROC train: 0.738981	val: 0.605578	test: 0.604760
PRC train: 0.715526	val: 0.654327	test: 0.629591

Epoch: 21
Loss: 0.46844692898259355
ROC train: 0.743753	val: 0.609033	test: 0.609221
PRC train: 0.720244	val: 0.656025	test: 0.627469

Epoch: 22
Loss: 0.46804744016035105
ROC train: 0.737557	val: 0.599224	test: 0.605122
PRC train: 0.718908	val: 0.652827	test: 0.628111

Epoch: 23
Loss: 0.46957975577687944
ROC train: 0.749396	val: 0.614193	test: 0.604781
PRC train: 0.724488	val: 0.659748	test: 0.631063

Epoch: 24
Loss: 0.4646507181034071
ROC train: 0.752240	val: 0.619273	test: 0.605932
PRC train: 0.726751	val: 0.659132	test: 0.629938

Epoch: 25
Loss: 0.4639790626068246
ROC train: 0.752473	val: 0.602590	test: 0.610781
PRC train: 0.729574	val: 0.651645	test: 0.628588

Epoch: 26
Loss: 0.4613325228762619
ROC train: 0.755734	val: 0.595821	test: 0.607887
PRC train: 0.731277	val: 0.649392	test: 0.631217

Epoch: 27
Loss: 0.461512459135323
ROC train: 0.759685	val: 0.599163	test: 0.610332
PRC train: 0.733584	val: 0.652231	test: 0.631538

Epoch: 28
Loss: 0.45784894365643086
ROC train: 0.760800	val: 0.593046	test: 0.609934
PRC train: 0.733286	val: 0.653523	test: 0.632477

Epoch: 29
Loss: 0.4566430530243819
ROC train: 0.763893	val: 0.601951	test: 0.596084
PRC train: 0.736831	val: 0.654740	test: 0.625144

Epoch: 30
Loss: 0.45400718679111857
ROC train: 0.767492	val: 0.599107	test: 0.599894
PRC train: 0.739829	val: 0.651728	test: 0.628031

Epoch: 31
Loss: 0.45196448369192355
ROC train: 0.771949	val: 0.597112	test: 0.610027
PRC train: 0.742281	val: 0.653142	test: 0.626639

Epoch: 32
Loss: 0.4527031923750644
ROC train: 0.770984	val: 0.592953	test: 0.601916
PRC train: 0.743510	val: 0.651599	test: 0.623085

Epoch: 33
Loss: 0.4523007594657348
ROC train: 0.774302	val: 0.610928	test: 0.596987Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/sider/noise=0.0.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/sider/noise=0.0
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/sider/noise=0.0/sider_scaff_6_26-05_11-20-03  ]
[ Using Seed :  6  ]
[ Using device :  cuda:0  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6859444663245495
ROC train: 0.529622	val: 0.520970	test: 0.506475
PRC train: 0.579506	val: 0.610395	test: 0.596205

Epoch: 2
Loss: 0.6502739611567753
ROC train: 0.551290	val: 0.512911	test: 0.513861
PRC train: 0.595344	val: 0.605398	test: 0.594359

Epoch: 3
Loss: 0.6142157380623341
ROC train: 0.573363	val: 0.505449	test: 0.526669
PRC train: 0.607376	val: 0.601846	test: 0.600460

Epoch: 4
Loss: 0.5856061016627785
ROC train: 0.594103	val: 0.509004	test: 0.539540
PRC train: 0.619268	val: 0.603612	test: 0.606943

Epoch: 5
Loss: 0.5655854750983391
ROC train: 0.618897	val: 0.535015	test: 0.559455
PRC train: 0.635362	val: 0.617655	test: 0.613055

Epoch: 6
Loss: 0.5500903734089939
ROC train: 0.644224	val: 0.573480	test: 0.594017
PRC train: 0.647879	val: 0.633928	test: 0.624150

Epoch: 7
Loss: 0.5419490071153398
ROC train: 0.659638	val: 0.579333	test: 0.605550
PRC train: 0.658613	val: 0.637152	test: 0.626249

Epoch: 8
Loss: 0.5265851815963034
ROC train: 0.672954	val: 0.582713	test: 0.609618
PRC train: 0.666682	val: 0.640593	test: 0.629045

Epoch: 9
Loss: 0.518745055444666
ROC train: 0.681397	val: 0.592054	test: 0.601464
PRC train: 0.671950	val: 0.644235	test: 0.627076

Epoch: 10
Loss: 0.5119478879249098
ROC train: 0.685737	val: 0.601067	test: 0.598601
PRC train: 0.675734	val: 0.646061	test: 0.625672

Epoch: 11
Loss: 0.5041493839823094
ROC train: 0.691918	val: 0.608442	test: 0.596356
PRC train: 0.680714	val: 0.649696	test: 0.623242

Epoch: 12
Loss: 0.49708252276546183
ROC train: 0.701584	val: 0.608151	test: 0.603383
PRC train: 0.685892	val: 0.648999	test: 0.623752

Epoch: 13
Loss: 0.493255634446837
ROC train: 0.707150	val: 0.600086	test: 0.600533
PRC train: 0.690548	val: 0.646703	test: 0.623481

Epoch: 14
Loss: 0.4903392784531892
ROC train: 0.713326	val: 0.597387	test: 0.604442
PRC train: 0.694717	val: 0.647030	test: 0.625147

Epoch: 15
Loss: 0.4854834268010634
ROC train: 0.716206	val: 0.587902	test: 0.609805
PRC train: 0.696972	val: 0.643771	test: 0.628606

Epoch: 16
Loss: 0.480202382769107
ROC train: 0.719775	val: 0.613850	test: 0.600090
PRC train: 0.700248	val: 0.656288	test: 0.624889

Epoch: 17
Loss: 0.4790250444046885
ROC train: 0.727960	val: 0.606998	test: 0.608977
PRC train: 0.705747	val: 0.653555	test: 0.626228

Epoch: 18
Loss: 0.4778703261614914
ROC train: 0.729562	val: 0.599928	test: 0.608473
PRC train: 0.707533	val: 0.652191	test: 0.627320

Epoch: 19
Loss: 0.47157628668026985
ROC train: 0.735745	val: 0.603565	test: 0.610280
PRC train: 0.713273	val: 0.653757	test: 0.626854

Epoch: 20
Loss: 0.4711954556987769
ROC train: 0.733106	val: 0.606330	test: 0.610220
PRC train: 0.711787	val: 0.656076	test: 0.627166

Epoch: 21
Loss: 0.4676128555566573
ROC train: 0.741267	val: 0.600927	test: 0.618772
PRC train: 0.718899	val: 0.649733	test: 0.634397

Epoch: 22
Loss: 0.462799269388592
ROC train: 0.748973	val: 0.607245	test: 0.618050
PRC train: 0.723816	val: 0.652330	test: 0.627362

Epoch: 23
Loss: 0.46391897098345225
ROC train: 0.753497	val: 0.605332	test: 0.619713
PRC train: 0.726727	val: 0.652384	test: 0.629629

Epoch: 24
Loss: 0.46399324449577073
ROC train: 0.753269	val: 0.601858	test: 0.622473
PRC train: 0.728374	val: 0.651787	test: 0.634075

Epoch: 25
Loss: 0.4666816534811072
ROC train: 0.754711	val: 0.607734	test: 0.615015
PRC train: 0.729938	val: 0.654020	test: 0.632735

Epoch: 26
Loss: 0.4596874382296419
ROC train: 0.758017	val: 0.614246	test: 0.614077
PRC train: 0.729454	val: 0.658306	test: 0.630818

Epoch: 27
Loss: 0.4595018518507664
ROC train: 0.765345	val: 0.612026	test: 0.619877
PRC train: 0.739233	val: 0.656373	test: 0.633024

Epoch: 28
Loss: 0.45944721251920073
ROC train: 0.763296	val: 0.601212	test: 0.615342
PRC train: 0.739179	val: 0.651623	test: 0.633630

Epoch: 29
Loss: 0.45654082096453064
ROC train: 0.766975	val: 0.606785	test: 0.621649
PRC train: 0.741910	val: 0.653056	test: 0.634112

Epoch: 30
Loss: 0.45372891774989865
ROC train: 0.771301	val: 0.603377	test: 0.628837
PRC train: 0.746817	val: 0.652253	test: 0.636589

Epoch: 31
Loss: 0.45364523062169243
ROC train: 0.776219	val: 0.604515	test: 0.617516
PRC train: 0.748031	val: 0.654332	test: 0.632866

Epoch: 32
Loss: 0.4486707598426829
ROC train: 0.777794	val: 0.613092	test: 0.618980
PRC train: 0.749081	val: 0.656908	test: 0.631141

Epoch: 33
Loss: 0.4464365713269817
ROC train: 0.779241	val: 0.609944	test: 0.621873Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/sider/noise=0.0.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/sider/noise=0.0
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/sider/noise=0.0/sider_scaff_4_26-05_11-20-03  ]
[ Using Seed :  4  ]
[ Using device :  cuda:0  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6835657679399227
ROC train: 0.532257	val: 0.526524	test: 0.497869
PRC train: 0.585938	val: 0.614671	test: 0.584260

Epoch: 2
Loss: 0.6442413373954478
ROC train: 0.558103	val: 0.516957	test: 0.511220
PRC train: 0.602601	val: 0.607485	test: 0.592872

Epoch: 3
Loss: 0.6103346001422392
ROC train: 0.569383	val: 0.505023	test: 0.521884
PRC train: 0.609824	val: 0.601232	test: 0.596644

Epoch: 4
Loss: 0.5836380198532238
ROC train: 0.591308	val: 0.511541	test: 0.528849
PRC train: 0.621822	val: 0.604864	test: 0.600137

Epoch: 5
Loss: 0.5632081701110048
ROC train: 0.619211	val: 0.540428	test: 0.549822
PRC train: 0.636093	val: 0.623479	test: 0.606801

Epoch: 6
Loss: 0.5518019966632897
ROC train: 0.641322	val: 0.562955	test: 0.563867
PRC train: 0.647772	val: 0.633925	test: 0.616820

Epoch: 7
Loss: 0.5395522283103515
ROC train: 0.656823	val: 0.575642	test: 0.580616
PRC train: 0.657809	val: 0.638828	test: 0.624909

Epoch: 8
Loss: 0.5246859121110073
ROC train: 0.670662	val: 0.582201	test: 0.590816
PRC train: 0.667652	val: 0.642188	test: 0.624317

Epoch: 9
Loss: 0.5154248834863322
ROC train: 0.674565	val: 0.580624	test: 0.581215
PRC train: 0.671016	val: 0.641348	test: 0.620554

Epoch: 10
Loss: 0.5083415148300413
ROC train: 0.686971	val: 0.589925	test: 0.592736
PRC train: 0.676657	val: 0.643951	test: 0.624785

Epoch: 11
Loss: 0.5037364851751057
ROC train: 0.700647	val: 0.609394	test: 0.597807
PRC train: 0.684284	val: 0.650849	test: 0.622370

Epoch: 12
Loss: 0.49925982001356994
ROC train: 0.704867	val: 0.597934	test: 0.592882
PRC train: 0.687763	val: 0.645824	test: 0.617356

Epoch: 13
Loss: 0.48817604612299953
ROC train: 0.709497	val: 0.597677	test: 0.593653
PRC train: 0.693368	val: 0.648554	test: 0.619807

Epoch: 14
Loss: 0.4885432952584421
ROC train: 0.715447	val: 0.607082	test: 0.591698
PRC train: 0.697981	val: 0.652970	test: 0.619860

Epoch: 15
Loss: 0.485568438706023
ROC train: 0.721150	val: 0.609799	test: 0.596912
PRC train: 0.701738	val: 0.653686	test: 0.623514

Epoch: 16
Loss: 0.4806617911024225
ROC train: 0.724076	val: 0.603858	test: 0.592500
PRC train: 0.703911	val: 0.652594	test: 0.622059

Epoch: 17
Loss: 0.4734771866301292
ROC train: 0.729067	val: 0.598595	test: 0.601859
PRC train: 0.706979	val: 0.651490	test: 0.623991

Epoch: 18
Loss: 0.47563400557994007
ROC train: 0.734848	val: 0.602508	test: 0.610571
PRC train: 0.710866	val: 0.650620	test: 0.629064

Epoch: 19
Loss: 0.47419394550424776
ROC train: 0.738824	val: 0.606066	test: 0.615479
PRC train: 0.712690	val: 0.653407	test: 0.629742

Epoch: 20
Loss: 0.4691656633026394
ROC train: 0.740665	val: 0.608347	test: 0.614472
PRC train: 0.716633	val: 0.653703	test: 0.634049

Epoch: 21
Loss: 0.4708677204726287
ROC train: 0.741436	val: 0.606620	test: 0.612232
PRC train: 0.721562	val: 0.653164	test: 0.635493

Epoch: 22
Loss: 0.46966170523865464
ROC train: 0.748582	val: 0.619731	test: 0.614899
PRC train: 0.724074	val: 0.662581	test: 0.632568

Epoch: 23
Loss: 0.4664535822092593
ROC train: 0.751722	val: 0.607771	test: 0.613744
PRC train: 0.726082	val: 0.657248	test: 0.639010

Epoch: 24
Loss: 0.4644397607606134
ROC train: 0.750243	val: 0.602487	test: 0.608373
PRC train: 0.728107	val: 0.655189	test: 0.634779

Epoch: 25
Loss: 0.46015588624550857
ROC train: 0.755484	val: 0.611638	test: 0.609130
PRC train: 0.731460	val: 0.660637	test: 0.629684

Epoch: 26
Loss: 0.46424588184551296
ROC train: 0.759839	val: 0.614378	test: 0.609598
PRC train: 0.733728	val: 0.664704	test: 0.631933

Epoch: 27
Loss: 0.4609788604008182
ROC train: 0.763425	val: 0.615387	test: 0.607851
PRC train: 0.735724	val: 0.664188	test: 0.629849

Epoch: 28
Loss: 0.45906602762564663
ROC train: 0.763842	val: 0.617113	test: 0.614504
PRC train: 0.736160	val: 0.663213	test: 0.633267

Epoch: 29
Loss: 0.45647912120402623
ROC train: 0.764121	val: 0.611317	test: 0.615188
PRC train: 0.735123	val: 0.662191	test: 0.638938

Epoch: 30
Loss: 0.45531051943992856
ROC train: 0.771660	val: 0.614028	test: 0.608091
PRC train: 0.741683	val: 0.663511	test: 0.636110

Epoch: 31
Loss: 0.457428461462179
ROC train: 0.771191	val: 0.609163	test: 0.616849
PRC train: 0.744421	val: 0.663701	test: 0.636939

Epoch: 32
Loss: 0.4511252287120465
ROC train: 0.775687	val: 0.617304	test: 0.612714
PRC train: 0.746175	val: 0.665929	test: 0.638176

Epoch: 33
Loss: 0.44577750969340596
ROC train: 0.780916	val: 0.619355	test: 0.619331Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/sider/noise=0.05.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.05
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/sider/noise=0.05
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/sider/noise=0.05/sider_scaff_4_26-05_11-20-03  ]
[ Using Seed :  4  ]
[ Using device :  cuda:1  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.686040847618927
ROC train: 0.530344	val: 0.505439	test: 0.498871
PRC train: 0.573202	val: 0.602424	test: 0.585643

Epoch: 2
Loss: 0.6500726175809476
ROC train: 0.566647	val: 0.507489	test: 0.520257
PRC train: 0.599948	val: 0.605870	test: 0.598910

Epoch: 3
Loss: 0.6174238447624116
ROC train: 0.583082	val: 0.499796	test: 0.529488
PRC train: 0.613007	val: 0.610168	test: 0.601224

Epoch: 4
Loss: 0.5894123884919504
ROC train: 0.601257	val: 0.501217	test: 0.539287
PRC train: 0.622793	val: 0.608362	test: 0.607448

Epoch: 5
Loss: 0.570623195974095
ROC train: 0.615405	val: 0.509847	test: 0.549117
PRC train: 0.631534	val: 0.611833	test: 0.612847

Epoch: 6
Loss: 0.55291286643491
ROC train: 0.636537	val: 0.520547	test: 0.571247
PRC train: 0.641892	val: 0.615418	test: 0.619583

Epoch: 7
Loss: 0.5345424305095604
ROC train: 0.656025	val: 0.547281	test: 0.591054
PRC train: 0.653602	val: 0.627424	test: 0.624958

Epoch: 8
Loss: 0.528633241367964
ROC train: 0.670715	val: 0.564631	test: 0.594258
PRC train: 0.663174	val: 0.636492	test: 0.624347

Epoch: 9
Loss: 0.5169033920560164
ROC train: 0.680602	val: 0.566131	test: 0.602371
PRC train: 0.669323	val: 0.637461	test: 0.627092

Epoch: 10
Loss: 0.506357926149625
ROC train: 0.686656	val: 0.564478	test: 0.602780
PRC train: 0.673555	val: 0.637008	test: 0.627631

Epoch: 11
Loss: 0.4978241128201851
ROC train: 0.691752	val: 0.570095	test: 0.603829
PRC train: 0.677076	val: 0.639769	test: 0.627007

Epoch: 12
Loss: 0.4918722481935383
ROC train: 0.703546	val: 0.577286	test: 0.606174
PRC train: 0.686072	val: 0.642166	test: 0.625180

Epoch: 13
Loss: 0.48676135501970175
ROC train: 0.713186	val: 0.580981	test: 0.609359
PRC train: 0.692536	val: 0.641889	test: 0.624260

Epoch: 14
Loss: 0.48540285656340226
ROC train: 0.717168	val: 0.581655	test: 0.615637
PRC train: 0.696097	val: 0.641400	test: 0.633354

Epoch: 15
Loss: 0.48168986385296436
ROC train: 0.721896	val: 0.584563	test: 0.614032
PRC train: 0.698315	val: 0.643028	test: 0.634588

Epoch: 16
Loss: 0.4743078303499481
ROC train: 0.725415	val: 0.594384	test: 0.594638
PRC train: 0.702014	val: 0.647236	test: 0.627816

Epoch: 17
Loss: 0.47550626740794755
ROC train: 0.732305	val: 0.586367	test: 0.599423
PRC train: 0.708283	val: 0.645650	test: 0.628800

Epoch: 18
Loss: 0.47183732933352107
ROC train: 0.744597	val: 0.582754	test: 0.610665
PRC train: 0.716350	val: 0.643887	test: 0.633038

Epoch: 19
Loss: 0.46887418216376836
ROC train: 0.749668	val: 0.594823	test: 0.613914
PRC train: 0.719334	val: 0.648397	test: 0.631405

Epoch: 20
Loss: 0.46412077673379537
ROC train: 0.753413	val: 0.591331	test: 0.611543
PRC train: 0.723564	val: 0.648824	test: 0.630366

Epoch: 21
Loss: 0.46121919884317586
ROC train: 0.755563	val: 0.603837	test: 0.620022
PRC train: 0.725160	val: 0.653991	test: 0.634208

Epoch: 22
Loss: 0.4607497040847638
ROC train: 0.763802	val: 0.595171	test: 0.615891
PRC train: 0.733297	val: 0.651857	test: 0.635893

Epoch: 23
Loss: 0.45558374148781766
ROC train: 0.767724	val: 0.591961	test: 0.602371
PRC train: 0.735837	val: 0.651740	test: 0.629624

Epoch: 24
Loss: 0.4604155643352148
ROC train: 0.770072	val: 0.581684	test: 0.606244
PRC train: 0.739379	val: 0.648687	test: 0.632304

Epoch: 25
Loss: 0.4517693994811428
ROC train: 0.778369	val: 0.600910	test: 0.606619
PRC train: 0.745808	val: 0.657880	test: 0.630414

Epoch: 26
Loss: 0.44821904221305786
ROC train: 0.781509	val: 0.601137	test: 0.598429
PRC train: 0.747934	val: 0.657172	test: 0.626940

Epoch: 27
Loss: 0.44493046348664034
ROC train: 0.780165	val: 0.606642	test: 0.585298
PRC train: 0.747123	val: 0.657719	test: 0.623921

Epoch: 28
Loss: 0.44458259135444866
ROC train: 0.790251	val: 0.599884	test: 0.595443
PRC train: 0.753933	val: 0.657487	test: 0.624143

Epoch: 29
Loss: 0.4494175223225597
ROC train: 0.793294	val: 0.599836	test: 0.609493
PRC train: 0.757811	val: 0.657725	test: 0.635051

Epoch: 30
Loss: 0.4376278453774266
ROC train: 0.785146	val: 0.602083	test: 0.589581
PRC train: 0.750232	val: 0.661532	test: 0.626145

Epoch: 31
Loss: 0.4331958281199966
ROC train: 0.798997	val: 0.599905	test: 0.597460
PRC train: 0.761014	val: 0.656763	test: 0.626913

Epoch: 32
Loss: 0.4363186258590326
ROC train: 0.798247	val: 0.597069	test: 0.589367Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/sider/noise=0.05.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.05
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/sider/noise=0.05
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/sider/noise=0.05/sider_scaff_5_26-05_11-20-03  ]
[ Using Seed :  5  ]
[ Using device :  cuda:1  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6904198315536847
ROC train: 0.541082	val: 0.522307	test: 0.499171
PRC train: 0.590507	val: 0.617210	test: 0.589406

Epoch: 2
Loss: 0.6533188966961647
ROC train: 0.565965	val: 0.518891	test: 0.501329
PRC train: 0.607781	val: 0.610648	test: 0.597120

Epoch: 3
Loss: 0.6216795053146749
ROC train: 0.576298	val: 0.512242	test: 0.507389
PRC train: 0.613966	val: 0.608022	test: 0.592308

Epoch: 4
Loss: 0.5882188054047861
ROC train: 0.592379	val: 0.511788	test: 0.517798
PRC train: 0.624654	val: 0.607543	test: 0.596336

Epoch: 5
Loss: 0.5682044672153312
ROC train: 0.613620	val: 0.521227	test: 0.533754
PRC train: 0.635592	val: 0.612887	test: 0.604512

Epoch: 6
Loss: 0.5472557949630212
ROC train: 0.638496	val: 0.546238	test: 0.554190
PRC train: 0.648130	val: 0.627760	test: 0.616891

Epoch: 7
Loss: 0.542302195913353
ROC train: 0.655563	val: 0.572003	test: 0.566668
PRC train: 0.658627	val: 0.641404	test: 0.620921

Epoch: 8
Loss: 0.5288765098785899
ROC train: 0.669468	val: 0.575573	test: 0.579415
PRC train: 0.666290	val: 0.642455	test: 0.623783

Epoch: 9
Loss: 0.517747172481798
ROC train: 0.680456	val: 0.573567	test: 0.577603
PRC train: 0.672849	val: 0.638381	test: 0.620854

Epoch: 10
Loss: 0.5110418327903602
ROC train: 0.691104	val: 0.580294	test: 0.587107
PRC train: 0.679450	val: 0.640462	test: 0.623141

Epoch: 11
Loss: 0.5067615142519669
ROC train: 0.701054	val: 0.591179	test: 0.588710
PRC train: 0.686410	val: 0.644030	test: 0.623972

Epoch: 12
Loss: 0.49145237400437447
ROC train: 0.707080	val: 0.598620	test: 0.589692
PRC train: 0.690207	val: 0.648912	test: 0.622464

Epoch: 13
Loss: 0.4937156582961325
ROC train: 0.715085	val: 0.595055	test: 0.593126
PRC train: 0.693851	val: 0.648310	test: 0.621424

Epoch: 14
Loss: 0.48309892184621994
ROC train: 0.723298	val: 0.585352	test: 0.594211
PRC train: 0.700009	val: 0.643521	test: 0.622479

Epoch: 15
Loss: 0.48289123817529955
ROC train: 0.727241	val: 0.599405	test: 0.591144
PRC train: 0.702240	val: 0.647694	test: 0.625064

Epoch: 16
Loss: 0.4780984853221547
ROC train: 0.727111	val: 0.590648	test: 0.594818
PRC train: 0.703337	val: 0.646366	test: 0.625258

Epoch: 17
Loss: 0.4722886473935938
ROC train: 0.734661	val: 0.587494	test: 0.595507
PRC train: 0.709562	val: 0.646672	test: 0.626500

Epoch: 18
Loss: 0.4664992322900807
ROC train: 0.741239	val: 0.595061	test: 0.594581
PRC train: 0.715266	val: 0.649000	test: 0.623156

Epoch: 19
Loss: 0.4671535025778395
ROC train: 0.749568	val: 0.606171	test: 0.587760
PRC train: 0.721106	val: 0.653236	test: 0.619038

Epoch: 20
Loss: 0.4641442116660223
ROC train: 0.753231	val: 0.613364	test: 0.582767
PRC train: 0.723143	val: 0.657541	test: 0.618227

Epoch: 21
Loss: 0.46471492242743573
ROC train: 0.757945	val: 0.596832	test: 0.593517
PRC train: 0.724329	val: 0.652493	test: 0.619959

Epoch: 22
Loss: 0.45921839625688354
ROC train: 0.763681	val: 0.597722	test: 0.594082
PRC train: 0.729907	val: 0.653624	test: 0.622252

Epoch: 23
Loss: 0.45684002965354964
ROC train: 0.769557	val: 0.599342	test: 0.594060
PRC train: 0.735970	val: 0.653879	test: 0.619040

Epoch: 24
Loss: 0.45549302723914564
ROC train: 0.774711	val: 0.599241	test: 0.587503
PRC train: 0.740498	val: 0.656057	test: 0.615723

Epoch: 25
Loss: 0.45347471774741804
ROC train: 0.776848	val: 0.596598	test: 0.588133
PRC train: 0.739981	val: 0.654345	test: 0.615677

Epoch: 26
Loss: 0.4471171399138578
ROC train: 0.778760	val: 0.606746	test: 0.581870
PRC train: 0.741625	val: 0.655691	test: 0.620598

Epoch: 27
Loss: 0.44893366376284616
ROC train: 0.778849	val: 0.602024	test: 0.589588
PRC train: 0.743305	val: 0.652989	test: 0.624697

Epoch: 28
Loss: 0.4480239831333
ROC train: 0.785130	val: 0.591922	test: 0.594078
PRC train: 0.747264	val: 0.649736	test: 0.622832

Epoch: 29
Loss: 0.4471661638544696
ROC train: 0.793108	val: 0.596575	test: 0.592742
PRC train: 0.753431	val: 0.649871	test: 0.621657

Epoch: 30
Loss: 0.4399325681382645
ROC train: 0.792364	val: 0.606134	test: 0.578026
PRC train: 0.754781	val: 0.655762	test: 0.617603

Epoch: 31
Loss: 0.4384276186735492
ROC train: 0.800183	val: 0.592818	test: 0.595132
PRC train: 0.759378	val: 0.651840	test: 0.617187

Epoch: 32
Loss: 0.435887988163606
ROC train: 0.795042	val: 0.598827	test: 0.591742Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/sider/noise=0.1.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.1
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/sider/noise=0.1
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/sider/noise=0.1/sider_scaff_5_26-05_11-20-03  ]
[ Using Seed :  5  ]
[ Using device :  cuda:2  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6898343677647907
ROC train: 0.547140	val: 0.521866	test: 0.502163
PRC train: 0.593774	val: 0.615941	test: 0.589185

Epoch: 2
Loss: 0.6539166225312786
ROC train: 0.571542	val: 0.521445	test: 0.510579
PRC train: 0.612194	val: 0.615853	test: 0.599882

Epoch: 3
Loss: 0.6237440783396243
ROC train: 0.579319	val: 0.511053	test: 0.518537
PRC train: 0.617796	val: 0.609185	test: 0.594813

Epoch: 4
Loss: 0.5912330480474571
ROC train: 0.588667	val: 0.505529	test: 0.522091
PRC train: 0.624490	val: 0.607521	test: 0.594691

Epoch: 5
Loss: 0.5724227948482604
ROC train: 0.605944	val: 0.511116	test: 0.529901
PRC train: 0.633795	val: 0.609608	test: 0.600169

Epoch: 6
Loss: 0.5507376675039583
ROC train: 0.631981	val: 0.534232	test: 0.549971
PRC train: 0.646663	val: 0.623482	test: 0.611361

Epoch: 7
Loss: 0.5439613535703723
ROC train: 0.652494	val: 0.561093	test: 0.565511
PRC train: 0.658351	val: 0.637324	test: 0.617646

Epoch: 8
Loss: 0.5293950613915843
ROC train: 0.669560	val: 0.568973	test: 0.578459
PRC train: 0.667857	val: 0.641551	test: 0.621224

Epoch: 9
Loss: 0.5189732755964236
ROC train: 0.680466	val: 0.567531	test: 0.576507
PRC train: 0.674596	val: 0.640574	test: 0.619932

Epoch: 10
Loss: 0.5101885519394724
ROC train: 0.689724	val: 0.564603	test: 0.580811
PRC train: 0.680485	val: 0.639353	test: 0.623635

Epoch: 11
Loss: 0.5061311049412204
ROC train: 0.697316	val: 0.572586	test: 0.583708
PRC train: 0.686173	val: 0.643883	test: 0.623313

Epoch: 12
Loss: 0.4910220150916821
ROC train: 0.705692	val: 0.595539	test: 0.583965
PRC train: 0.690443	val: 0.656261	test: 0.619788

Epoch: 13
Loss: 0.4929952063304389
ROC train: 0.712148	val: 0.604694	test: 0.587597
PRC train: 0.694206	val: 0.660235	test: 0.618571

Epoch: 14
Loss: 0.4818138142562648
ROC train: 0.720489	val: 0.592886	test: 0.595764
PRC train: 0.700987	val: 0.654209	test: 0.623087

Epoch: 15
Loss: 0.48275286899953596
ROC train: 0.724569	val: 0.600384	test: 0.588427
PRC train: 0.702887	val: 0.657049	test: 0.620460

Epoch: 16
Loss: 0.4774147620066877
ROC train: 0.726354	val: 0.599852	test: 0.579559
PRC train: 0.704676	val: 0.655503	test: 0.617749

Epoch: 17
Loss: 0.46981163900580025
ROC train: 0.744083	val: 0.594071	test: 0.595167
PRC train: 0.719113	val: 0.651883	test: 0.622785

Epoch: 18
Loss: 0.4641957792187058
ROC train: 0.748052	val: 0.598242	test: 0.601619
PRC train: 0.723343	val: 0.652366	test: 0.624819

Epoch: 19
Loss: 0.4667915812052418
ROC train: 0.756481	val: 0.610999	test: 0.596770
PRC train: 0.728843	val: 0.657550	test: 0.621396

Epoch: 20
Loss: 0.46121374111857627
ROC train: 0.755184	val: 0.625050	test: 0.592317
PRC train: 0.727099	val: 0.662086	test: 0.621016

Epoch: 21
Loss: 0.46373460684178874
ROC train: 0.760394	val: 0.619815	test: 0.600750
PRC train: 0.730284	val: 0.661170	test: 0.623599

Epoch: 22
Loss: 0.45891405494260723
ROC train: 0.769586	val: 0.613283	test: 0.604478
PRC train: 0.736286	val: 0.660665	test: 0.625666

Epoch: 23
Loss: 0.4524957900783135
ROC train: 0.778526	val: 0.598256	test: 0.610349
PRC train: 0.743539	val: 0.655270	test: 0.627875

Epoch: 24
Loss: 0.4538768636430078
ROC train: 0.779841	val: 0.609366	test: 0.601814
PRC train: 0.745547	val: 0.657422	test: 0.625670

Epoch: 25
Loss: 0.4518448291361891
ROC train: 0.777975	val: 0.616248	test: 0.595866
PRC train: 0.745350	val: 0.657758	test: 0.623873

Epoch: 26
Loss: 0.4455784372339881
ROC train: 0.786737	val: 0.612161	test: 0.583926
PRC train: 0.750742	val: 0.657488	test: 0.618762

Epoch: 27
Loss: 0.4438930356040638
ROC train: 0.793011	val: 0.613200	test: 0.592460
PRC train: 0.756484	val: 0.657987	test: 0.623441

Epoch: 28
Loss: 0.4422192177106967
ROC train: 0.799591	val: 0.607424	test: 0.590472
PRC train: 0.762718	val: 0.658288	test: 0.620378

Epoch: 29
Loss: 0.443420408994471
ROC train: 0.798870	val: 0.611992	test: 0.591954
PRC train: 0.762151	val: 0.659778	test: 0.620646

Epoch: 30
Loss: 0.43597615279244073
ROC train: 0.797955	val: 0.615330	test: 0.581843
PRC train: 0.760881	val: 0.659673	test: 0.616821

Epoch: 31
Loss: 0.4339229789648396
ROC train: 0.811114	val: 0.618969	test: 0.579333
PRC train: 0.770445	val: 0.661325	test: 0.616757

Epoch: 32
Loss: 0.4297619334395512
ROC train: 0.816597	val: 0.612087	test: 0.588454Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/sider/noise=0.2.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:3
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.2
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/sider/noise=0.2
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/sider/noise=0.2/sider_scaff_6_26-05_11-20-03  ]
[ Using Seed :  6  ]
[ Using device :  cuda:3  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6805847137818565
ROC train: 0.525697	val: 0.528086	test: 0.508154
PRC train: 0.581154	val: 0.618185	test: 0.588630

Epoch: 2
Loss: 0.6458613334035832
ROC train: 0.553134	val: 0.529116	test: 0.506406
PRC train: 0.601897	val: 0.614494	test: 0.590286

Epoch: 3
Loss: 0.6212478336289193
ROC train: 0.568697	val: 0.509270	test: 0.511654
PRC train: 0.610706	val: 0.605251	test: 0.594068

Epoch: 4
Loss: 0.5928360698994369
ROC train: 0.577180	val: 0.510743	test: 0.513650
PRC train: 0.617473	val: 0.602691	test: 0.596271

Epoch: 5
Loss: 0.5727476637900192
ROC train: 0.587530	val: 0.514556	test: 0.520189
PRC train: 0.625998	val: 0.603487	test: 0.600439

Epoch: 6
Loss: 0.5561971253052616
ROC train: 0.610834	val: 0.535462	test: 0.536974
PRC train: 0.639682	val: 0.612528	test: 0.607470

Epoch: 7
Loss: 0.5412703110470609
ROC train: 0.633414	val: 0.558396	test: 0.560583
PRC train: 0.651435	val: 0.622539	test: 0.615758

Epoch: 8
Loss: 0.530722794230589
ROC train: 0.649717	val: 0.565932	test: 0.560277
PRC train: 0.660174	val: 0.627657	test: 0.617787

Epoch: 9
Loss: 0.5225340105361794
ROC train: 0.663883	val: 0.562273	test: 0.559329
PRC train: 0.667251	val: 0.627873	test: 0.616963

Epoch: 10
Loss: 0.5114215383145647
ROC train: 0.674918	val: 0.564135	test: 0.569823
PRC train: 0.673036	val: 0.630271	test: 0.622175

Epoch: 11
Loss: 0.5053289963694587
ROC train: 0.683746	val: 0.562114	test: 0.576088
PRC train: 0.680442	val: 0.631592	test: 0.622926

Epoch: 12
Loss: 0.4943365039187178
ROC train: 0.694988	val: 0.560961	test: 0.572996
PRC train: 0.686788	val: 0.633300	test: 0.622694

Epoch: 13
Loss: 0.49157161536783656
ROC train: 0.704892	val: 0.577325	test: 0.565551
PRC train: 0.694617	val: 0.638694	test: 0.616736

Epoch: 14
Loss: 0.4905418287077293
ROC train: 0.711259	val: 0.570481	test: 0.570567
PRC train: 0.701302	val: 0.634722	test: 0.616129

Epoch: 15
Loss: 0.4847890857252521
ROC train: 0.719711	val: 0.585200	test: 0.575348
PRC train: 0.706455	val: 0.638961	test: 0.621342

Epoch: 16
Loss: 0.47979909874395676
ROC train: 0.727977	val: 0.574715	test: 0.570861
PRC train: 0.713414	val: 0.637773	test: 0.621859

Epoch: 17
Loss: 0.4745686697309249
ROC train: 0.737171	val: 0.564741	test: 0.567397
PRC train: 0.720966	val: 0.635611	test: 0.620511

Epoch: 18
Loss: 0.4702375879138027
ROC train: 0.746006	val: 0.571909	test: 0.570395
PRC train: 0.724040	val: 0.638605	test: 0.623483

Epoch: 19
Loss: 0.4662287445803138
ROC train: 0.753282	val: 0.592489	test: 0.572514
PRC train: 0.730924	val: 0.644784	test: 0.625038

Epoch: 20
Loss: 0.4635715947390883
ROC train: 0.755458	val: 0.588509	test: 0.574811
PRC train: 0.732945	val: 0.643365	test: 0.628415

Epoch: 21
Loss: 0.45686953913594125
ROC train: 0.762473	val: 0.582598	test: 0.574637
PRC train: 0.738760	val: 0.644975	test: 0.626666

Epoch: 22
Loss: 0.458353269296326
ROC train: 0.771884	val: 0.585442	test: 0.575201
PRC train: 0.745206	val: 0.647196	test: 0.622874

Epoch: 23
Loss: 0.45677394495782153
ROC train: 0.780269	val: 0.566574	test: 0.571155
PRC train: 0.751339	val: 0.638995	test: 0.620396

Epoch: 24
Loss: 0.44866268005024124
ROC train: 0.783372	val: 0.558759	test: 0.578006
PRC train: 0.754571	val: 0.636528	test: 0.630520

Epoch: 25
Loss: 0.44993420410429374
ROC train: 0.787678	val: 0.579847	test: 0.574707
PRC train: 0.757847	val: 0.644236	test: 0.625901

Epoch: 26
Loss: 0.4399840358602661
ROC train: 0.793532	val: 0.569212	test: 0.577792
PRC train: 0.761902	val: 0.643385	test: 0.624869

Epoch: 27
Loss: 0.43952984064747425
ROC train: 0.801903	val: 0.558412	test: 0.573703
PRC train: 0.767088	val: 0.639413	test: 0.622372

Epoch: 28
Loss: 0.44099468722640883
ROC train: 0.808248	val: 0.569329	test: 0.561068
PRC train: 0.772152	val: 0.647643	test: 0.616295

Epoch: 29
Loss: 0.4335234472105478
ROC train: 0.813227	val: 0.579588	test: 0.546763
PRC train: 0.777044	val: 0.647868	test: 0.609424

Epoch: 30
Loss: 0.43217431115199006
ROC train: 0.816842	val: 0.577550	test: 0.557682
PRC train: 0.779430	val: 0.639305	test: 0.621353

Epoch: 31
Loss: 0.42913086999543043
ROC train: 0.819962	val: 0.586291	test: 0.557918
PRC train: 0.781030	val: 0.642730	test: 0.620820

Epoch: 32
Loss: 0.4296780100367993
ROC train: 0.825622	val: 0.586310	test: 0.556924Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/sider/noise=0.1.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.1
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/sider/noise=0.1
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/sider/noise=0.1/sider_scaff_6_26-05_11-20-03  ]
[ Using Seed :  6  ]
[ Using device :  cuda:2  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6799046618176456
ROC train: 0.530099	val: 0.529134	test: 0.506122
PRC train: 0.581550	val: 0.621692	test: 0.585096

Epoch: 2
Loss: 0.6443265842018293
ROC train: 0.553378	val: 0.524894	test: 0.509225
PRC train: 0.600002	val: 0.616383	test: 0.590906

Epoch: 3
Loss: 0.6179106827424645
ROC train: 0.567605	val: 0.508173	test: 0.520732
PRC train: 0.610128	val: 0.607395	test: 0.595195

Epoch: 4
Loss: 0.5894881193380807
ROC train: 0.578043	val: 0.509386	test: 0.528641
PRC train: 0.620046	val: 0.604614	test: 0.599659

Epoch: 5
Loss: 0.5687705115727695
ROC train: 0.593831	val: 0.516592	test: 0.539052
PRC train: 0.632058	val: 0.608395	test: 0.604215

Epoch: 6
Loss: 0.5510548672868041
ROC train: 0.625278	val: 0.539319	test: 0.561766
PRC train: 0.649048	val: 0.622230	test: 0.614303

Epoch: 7
Loss: 0.5380875743293551
ROC train: 0.647025	val: 0.563191	test: 0.577609
PRC train: 0.657885	val: 0.632634	test: 0.621490

Epoch: 8
Loss: 0.5293864987388635
ROC train: 0.660679	val: 0.563592	test: 0.576449
PRC train: 0.664697	val: 0.632396	test: 0.620158

Epoch: 9
Loss: 0.5197701042153
ROC train: 0.669223	val: 0.558667	test: 0.578252
PRC train: 0.669826	val: 0.630319	test: 0.621233

Epoch: 10
Loss: 0.5097239727702809
ROC train: 0.677273	val: 0.565854	test: 0.587396
PRC train: 0.674921	val: 0.634013	test: 0.625639

Epoch: 11
Loss: 0.5029386678982181
ROC train: 0.686117	val: 0.569242	test: 0.589435
PRC train: 0.680221	val: 0.635881	test: 0.627354

Epoch: 12
Loss: 0.49356435231017237
ROC train: 0.698525	val: 0.571809	test: 0.589327
PRC train: 0.687653	val: 0.635360	test: 0.623872

Epoch: 13
Loss: 0.48904252814347415
ROC train: 0.707693	val: 0.579977	test: 0.588805
PRC train: 0.692056	val: 0.638226	test: 0.625872

Epoch: 14
Loss: 0.48880719285128027
ROC train: 0.714149	val: 0.576202	test: 0.594184
PRC train: 0.696585	val: 0.636711	test: 0.630588

Epoch: 15
Loss: 0.4834641811120998
ROC train: 0.721711	val: 0.579709	test: 0.594926
PRC train: 0.702095	val: 0.638955	test: 0.628357

Epoch: 16
Loss: 0.4789038180395987
ROC train: 0.727153	val: 0.567184	test: 0.588926
PRC train: 0.707057	val: 0.633202	test: 0.624574

Epoch: 17
Loss: 0.4724913452119578
ROC train: 0.738507	val: 0.579003	test: 0.585824
PRC train: 0.713746	val: 0.638943	test: 0.625678

Epoch: 18
Loss: 0.4682986779330537
ROC train: 0.743781	val: 0.573218	test: 0.585652
PRC train: 0.718187	val: 0.635573	test: 0.630636

Epoch: 19
Loss: 0.4665122934513227
ROC train: 0.745762	val: 0.571345	test: 0.587887
PRC train: 0.720156	val: 0.630918	test: 0.628005

Epoch: 20
Loss: 0.46747717364314667
ROC train: 0.752615	val: 0.580604	test: 0.585232
PRC train: 0.726497	val: 0.637856	test: 0.625581

Epoch: 21
Loss: 0.4604505171005747
ROC train: 0.760629	val: 0.580281	test: 0.587431
PRC train: 0.732127	val: 0.639348	test: 0.627382

Epoch: 22
Loss: 0.4613320823051664
ROC train: 0.768815	val: 0.574315	test: 0.589046
PRC train: 0.737404	val: 0.636463	test: 0.631264

Epoch: 23
Loss: 0.4605899820208889
ROC train: 0.772947	val: 0.579391	test: 0.592189
PRC train: 0.740535	val: 0.638341	test: 0.632229

Epoch: 24
Loss: 0.45172399269942876
ROC train: 0.774404	val: 0.576597	test: 0.588455
PRC train: 0.740520	val: 0.634943	test: 0.628098

Epoch: 25
Loss: 0.4487611770877297
ROC train: 0.773318	val: 0.587453	test: 0.556730
PRC train: 0.740218	val: 0.640360	test: 0.612576

Epoch: 26
Loss: 0.4450825121388565
ROC train: 0.789370	val: 0.587602	test: 0.566148
PRC train: 0.752645	val: 0.640368	test: 0.618583

Epoch: 27
Loss: 0.44820598470170214
ROC train: 0.794009	val: 0.588991	test: 0.580884
PRC train: 0.758595	val: 0.641410	test: 0.626449

Epoch: 28
Loss: 0.4480896485937813
ROC train: 0.796533	val: 0.596450	test: 0.582005
PRC train: 0.758306	val: 0.645236	test: 0.629798

Epoch: 29
Loss: 0.4406146042601623
ROC train: 0.799523	val: 0.598252	test: 0.559832
PRC train: 0.759836	val: 0.644104	test: 0.622214

Epoch: 30
Loss: 0.43780935200589804
ROC train: 0.806943	val: 0.594563	test: 0.566622
PRC train: 0.765632	val: 0.642372	test: 0.625370

Epoch: 31
Loss: 0.432999843301132
ROC train: 0.811255	val: 0.589499	test: 0.581770
PRC train: 0.771486	val: 0.642039	test: 0.629337

Epoch: 32
Loss: 0.4333640952555916
ROC train: 0.809677	val: 0.594938	test: 0.590093Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/sider/noise=0.05.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.05
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/sider/noise=0.05
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/sider/noise=0.05/sider_scaff_6_26-05_11-20-03  ]
[ Using Seed :  6  ]
[ Using device :  cuda:1  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6800555874276035
ROC train: 0.529500	val: 0.530577	test: 0.505934
PRC train: 0.580700	val: 0.619822	test: 0.583633

Epoch: 2
Loss: 0.642824735308739
ROC train: 0.556327	val: 0.527692	test: 0.505791
PRC train: 0.600450	val: 0.618004	test: 0.588731

Epoch: 3
Loss: 0.6164462658973758
ROC train: 0.572201	val: 0.510603	test: 0.518265
PRC train: 0.610050	val: 0.606871	test: 0.593266

Epoch: 4
Loss: 0.5881099874331676
ROC train: 0.585318	val: 0.514501	test: 0.524789
PRC train: 0.620938	val: 0.608077	test: 0.598710

Epoch: 5
Loss: 0.5659674517213895
ROC train: 0.599043	val: 0.527535	test: 0.533852
PRC train: 0.632272	val: 0.617410	test: 0.602011

Epoch: 6
Loss: 0.5494600142134923
ROC train: 0.630185	val: 0.552809	test: 0.556351
PRC train: 0.647626	val: 0.631233	test: 0.610173

Epoch: 7
Loss: 0.5376250746483294
ROC train: 0.649525	val: 0.571791	test: 0.577436
PRC train: 0.656579	val: 0.639691	test: 0.619187

Epoch: 8
Loss: 0.5276345093313066
ROC train: 0.662652	val: 0.575021	test: 0.577278
PRC train: 0.664300	val: 0.640270	test: 0.618951

Epoch: 9
Loss: 0.5195035169566193
ROC train: 0.673455	val: 0.573151	test: 0.584850
PRC train: 0.671844	val: 0.639496	test: 0.621046

Epoch: 10
Loss: 0.5090722629031565
ROC train: 0.685458	val: 0.583785	test: 0.591072
PRC train: 0.677749	val: 0.642937	test: 0.623544

Epoch: 11
Loss: 0.5033657895080952
ROC train: 0.692661	val: 0.583458	test: 0.590897
PRC train: 0.681972	val: 0.642648	test: 0.622271

Epoch: 12
Loss: 0.4919242684036658
ROC train: 0.701303	val: 0.577433	test: 0.586610
PRC train: 0.686716	val: 0.641094	test: 0.619802

Epoch: 13
Loss: 0.49043714448811115
ROC train: 0.712574	val: 0.582731	test: 0.596405
PRC train: 0.695493	val: 0.643661	test: 0.624858

Epoch: 14
Loss: 0.49041818520072367
ROC train: 0.718703	val: 0.573913	test: 0.604217
PRC train: 0.699525	val: 0.640286	test: 0.628543

Epoch: 15
Loss: 0.4850202819249164
ROC train: 0.721731	val: 0.577382	test: 0.601105
PRC train: 0.701791	val: 0.643761	test: 0.623739

Epoch: 16
Loss: 0.4776149043115362
ROC train: 0.724808	val: 0.571292	test: 0.594397
PRC train: 0.705788	val: 0.639519	test: 0.622084

Epoch: 17
Loss: 0.4744438128567836
ROC train: 0.737022	val: 0.582435	test: 0.599840
PRC train: 0.712139	val: 0.644989	test: 0.624439

Epoch: 18
Loss: 0.47181633784675503
ROC train: 0.744358	val: 0.576836	test: 0.610646
PRC train: 0.718344	val: 0.642178	test: 0.631948

Epoch: 19
Loss: 0.46904710818167394
ROC train: 0.746206	val: 0.582530	test: 0.611945
PRC train: 0.722469	val: 0.642647	test: 0.629966

Epoch: 20
Loss: 0.4653489726975388
ROC train: 0.751876	val: 0.588784	test: 0.602286
PRC train: 0.724642	val: 0.645056	test: 0.625685

Epoch: 21
Loss: 0.4618306614194328
ROC train: 0.757148	val: 0.578710	test: 0.592872
PRC train: 0.726681	val: 0.643019	test: 0.624618

Epoch: 22
Loss: 0.462789907550031
ROC train: 0.758555	val: 0.589931	test: 0.582496
PRC train: 0.728948	val: 0.645932	test: 0.624676

Epoch: 23
Loss: 0.4619579531358031
ROC train: 0.771498	val: 0.587325	test: 0.601399
PRC train: 0.739596	val: 0.645638	test: 0.631898

Epoch: 24
Loss: 0.4509540881925842
ROC train: 0.775020	val: 0.588311	test: 0.595620
PRC train: 0.741959	val: 0.648220	test: 0.624739

Epoch: 25
Loss: 0.45441367573761793
ROC train: 0.768126	val: 0.610189	test: 0.579755
PRC train: 0.738402	val: 0.658267	test: 0.623148

Epoch: 26
Loss: 0.4516768875821297
ROC train: 0.776317	val: 0.596590	test: 0.584167
PRC train: 0.743534	val: 0.651035	test: 0.627011

Epoch: 27
Loss: 0.4484922056697041
ROC train: 0.781885	val: 0.598014	test: 0.574911
PRC train: 0.749405	val: 0.651010	test: 0.622702

Epoch: 28
Loss: 0.4476850046423551
ROC train: 0.790580	val: 0.592411	test: 0.611281
PRC train: 0.755537	val: 0.650179	test: 0.635271

Epoch: 29
Loss: 0.4443621706825279
ROC train: 0.787395	val: 0.601166	test: 0.591789
PRC train: 0.751381	val: 0.654762	test: 0.623090

Epoch: 30
Loss: 0.4410771398794278
ROC train: 0.798263	val: 0.592805	test: 0.608224
PRC train: 0.759766	val: 0.651682	test: 0.626147

Epoch: 31
Loss: 0.43695945943383396
ROC train: 0.800210	val: 0.598790	test: 0.622489
PRC train: 0.762325	val: 0.652621	test: 0.634529

Epoch: 32
Loss: 0.4378868676438056
ROC train: 0.800261	val: 0.605159	test: 0.598741Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/sider/noise=0.1.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.1
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/sider/noise=0.1
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/sider/noise=0.1/sider_scaff_4_26-05_11-20-03  ]
[ Using Seed :  4  ]
[ Using device :  cuda:2  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6865288482598462
ROC train: 0.530462	val: 0.503193	test: 0.496771
PRC train: 0.574033	val: 0.601324	test: 0.586803

Epoch: 2
Loss: 0.6509511461531877
ROC train: 0.564370	val: 0.505935	test: 0.510673
PRC train: 0.600423	val: 0.604456	test: 0.595671

Epoch: 3
Loss: 0.6194654401892197
ROC train: 0.577613	val: 0.494870	test: 0.517421
PRC train: 0.611518	val: 0.603911	test: 0.595769

Epoch: 4
Loss: 0.5919124396025327
ROC train: 0.591902	val: 0.494711	test: 0.521244
PRC train: 0.620316	val: 0.603353	test: 0.598637

Epoch: 5
Loss: 0.5729313043093127
ROC train: 0.609094	val: 0.511504	test: 0.531084
PRC train: 0.632851	val: 0.610874	test: 0.605199

Epoch: 6
Loss: 0.5541359379521292
ROC train: 0.629901	val: 0.530305	test: 0.551188
PRC train: 0.645828	val: 0.619742	test: 0.613209

Epoch: 7
Loss: 0.5375584901035186
ROC train: 0.646774	val: 0.553314	test: 0.573100
PRC train: 0.655440	val: 0.630566	test: 0.617797

Epoch: 8
Loss: 0.5310526772615146
ROC train: 0.658949	val: 0.564438	test: 0.580828
PRC train: 0.662740	val: 0.635408	test: 0.619329

Epoch: 9
Loss: 0.5183533983122517
ROC train: 0.670924	val: 0.565205	test: 0.587858
PRC train: 0.670347	val: 0.638020	test: 0.623626

Epoch: 10
Loss: 0.5062727109172628
ROC train: 0.682787	val: 0.570534	test: 0.594348
PRC train: 0.677734	val: 0.638253	test: 0.626029

Epoch: 11
Loss: 0.49751923287443417
ROC train: 0.689444	val: 0.577387	test: 0.595055
PRC train: 0.682198	val: 0.641387	test: 0.624430

Epoch: 12
Loss: 0.4935608269172582
ROC train: 0.703900	val: 0.589010	test: 0.592947
PRC train: 0.690888	val: 0.647381	test: 0.619635

Epoch: 13
Loss: 0.4862979953992309
ROC train: 0.715579	val: 0.592958	test: 0.597421
PRC train: 0.698978	val: 0.649005	test: 0.620000

Epoch: 14
Loss: 0.48453938694951926
ROC train: 0.721045	val: 0.595420	test: 0.599507
PRC train: 0.702176	val: 0.647763	test: 0.623149

Epoch: 15
Loss: 0.4792878368910671
ROC train: 0.729507	val: 0.592616	test: 0.603611
PRC train: 0.705683	val: 0.646753	test: 0.623590

Epoch: 16
Loss: 0.470615782859218
ROC train: 0.736826	val: 0.591457	test: 0.592414
PRC train: 0.711104	val: 0.646284	test: 0.623090

Epoch: 17
Loss: 0.4707233945972852
ROC train: 0.743698	val: 0.588679	test: 0.597037
PRC train: 0.717459	val: 0.646565	test: 0.624390

Epoch: 18
Loss: 0.46839087003223917
ROC train: 0.757052	val: 0.591238	test: 0.599447
PRC train: 0.727868	val: 0.646863	test: 0.626340

Epoch: 19
Loss: 0.4633488579991549
ROC train: 0.762434	val: 0.593451	test: 0.604802
PRC train: 0.733635	val: 0.648554	test: 0.629514

Epoch: 20
Loss: 0.4584538436208949
ROC train: 0.762639	val: 0.599204	test: 0.600521
PRC train: 0.734206	val: 0.651999	test: 0.623279

Epoch: 21
Loss: 0.4540248988233331
ROC train: 0.765717	val: 0.617652	test: 0.591395
PRC train: 0.735680	val: 0.666376	test: 0.624314

Epoch: 22
Loss: 0.45557534224573526
ROC train: 0.773803	val: 0.606725	test: 0.589802
PRC train: 0.743015	val: 0.658318	test: 0.622603

Epoch: 23
Loss: 0.44753277237223477
ROC train: 0.773205	val: 0.604534	test: 0.585709
PRC train: 0.742577	val: 0.662889	test: 0.621220

Epoch: 24
Loss: 0.45174206435622766
ROC train: 0.782306	val: 0.603158	test: 0.587673
PRC train: 0.751225	val: 0.662229	test: 0.623162

Epoch: 25
Loss: 0.4414720610927841
ROC train: 0.790511	val: 0.611378	test: 0.593340
PRC train: 0.756226	val: 0.664780	test: 0.623018

Epoch: 26
Loss: 0.4373377547372329
ROC train: 0.787863	val: 0.595157	test: 0.609696
PRC train: 0.754940	val: 0.649811	test: 0.628997

Epoch: 27
Loss: 0.43420541880474495
ROC train: 0.801848	val: 0.618191	test: 0.598963
PRC train: 0.761963	val: 0.667813	test: 0.627090

Epoch: 28
Loss: 0.4362043022686336
ROC train: 0.806373	val: 0.617957	test: 0.604858
PRC train: 0.766065	val: 0.668226	test: 0.626804

Epoch: 29
Loss: 0.4443822249539897
ROC train: 0.803936	val: 0.609419	test: 0.611407
PRC train: 0.767623	val: 0.661454	test: 0.632386

Epoch: 30
Loss: 0.42875339785639993
ROC train: 0.804934	val: 0.617463	test: 0.596262
PRC train: 0.767450	val: 0.670538	test: 0.631301

Epoch: 31
Loss: 0.4243893811256723
ROC train: 0.816323	val: 0.607969	test: 0.610378
PRC train: 0.777118	val: 0.658344	test: 0.630860

Epoch: 32
Loss: 0.42611431909081254
ROC train: 0.820990	val: 0.619594	test: 0.597818Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/sider/noise=0.2.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:3
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.2
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/sider/noise=0.2
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/sider/noise=0.2/sider_scaff_5_26-05_11-20-03  ]
[ Using Seed :  5  ]
[ Using device :  cuda:3  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6912764153537173
ROC train: 0.540290	val: 0.517060	test: 0.493319
PRC train: 0.588811	val: 0.616398	test: 0.583086

Epoch: 2
Loss: 0.656978261796254
ROC train: 0.563857	val: 0.517917	test: 0.497382
PRC train: 0.606023	val: 0.611377	test: 0.589466

Epoch: 3
Loss: 0.6285176642855262
ROC train: 0.571443	val: 0.514060	test: 0.504978
PRC train: 0.614040	val: 0.606447	test: 0.589847

Epoch: 4
Loss: 0.5962649285190607
ROC train: 0.580845	val: 0.511635	test: 0.509853
PRC train: 0.620383	val: 0.602801	test: 0.591028

Epoch: 5
Loss: 0.5775602396528384
ROC train: 0.593339	val: 0.504553	test: 0.509193
PRC train: 0.627730	val: 0.601775	test: 0.593310

Epoch: 6
Loss: 0.5558226744666903
ROC train: 0.616798	val: 0.508902	test: 0.515584
PRC train: 0.641254	val: 0.606454	test: 0.596591

Epoch: 7
Loss: 0.5484482793121858
ROC train: 0.639007	val: 0.528355	test: 0.528133
PRC train: 0.652825	val: 0.618781	test: 0.603235

Epoch: 8
Loss: 0.53599249086648
ROC train: 0.654921	val: 0.544946	test: 0.544628
PRC train: 0.662184	val: 0.626194	test: 0.610162

Epoch: 9
Loss: 0.5244073709935895
ROC train: 0.670260	val: 0.542679	test: 0.550601
PRC train: 0.670509	val: 0.624824	test: 0.608395

Epoch: 10
Loss: 0.5142620627037522
ROC train: 0.681944	val: 0.550113	test: 0.556551
PRC train: 0.676135	val: 0.625960	test: 0.610164

Epoch: 11
Loss: 0.5087295260557486
ROC train: 0.690962	val: 0.554610	test: 0.563075
PRC train: 0.681562	val: 0.625598	test: 0.611729

Epoch: 12
Loss: 0.4938004436048378
ROC train: 0.700187	val: 0.567123	test: 0.571945
PRC train: 0.686247	val: 0.634278	test: 0.616330

Epoch: 13
Loss: 0.4980789203965535
ROC train: 0.709468	val: 0.572385	test: 0.572777
PRC train: 0.694261	val: 0.638333	test: 0.616662

Epoch: 14
Loss: 0.48532418725780324
ROC train: 0.716516	val: 0.551010	test: 0.571753
PRC train: 0.699125	val: 0.627960	test: 0.617689

Epoch: 15
Loss: 0.4849186168591375
ROC train: 0.723471	val: 0.561873	test: 0.582048
PRC train: 0.703654	val: 0.631472	test: 0.619676

Epoch: 16
Loss: 0.4803102049585216
ROC train: 0.728255	val: 0.572486	test: 0.582976
PRC train: 0.706965	val: 0.637321	test: 0.617859

Epoch: 17
Loss: 0.47228999315504927
ROC train: 0.741861	val: 0.569043	test: 0.578548
PRC train: 0.716288	val: 0.636964	test: 0.618123

Epoch: 18
Loss: 0.4686637532058132
ROC train: 0.749421	val: 0.564511	test: 0.577995
PRC train: 0.721233	val: 0.633479	test: 0.616706

Epoch: 19
Loss: 0.4671187482045478
ROC train: 0.756680	val: 0.576573	test: 0.581099
PRC train: 0.725660	val: 0.639888	test: 0.614754

Epoch: 20
Loss: 0.4614444464708038
ROC train: 0.763867	val: 0.594520	test: 0.583459
PRC train: 0.730815	val: 0.646240	test: 0.619050

Epoch: 21
Loss: 0.46359650493116356
ROC train: 0.765844	val: 0.585762	test: 0.578995
PRC train: 0.733185	val: 0.643035	test: 0.616896

Epoch: 22
Loss: 0.4543780212016376
ROC train: 0.778930	val: 0.595452	test: 0.577597
PRC train: 0.743258	val: 0.647128	test: 0.614559

Epoch: 23
Loss: 0.4530796277694786
ROC train: 0.776970	val: 0.578735	test: 0.571289
PRC train: 0.742397	val: 0.642377	test: 0.615509

Epoch: 24
Loss: 0.44889632745694535
ROC train: 0.788640	val: 0.594599	test: 0.568260
PRC train: 0.751046	val: 0.648589	test: 0.613573

Epoch: 25
Loss: 0.4497907892340334
ROC train: 0.793048	val: 0.595204	test: 0.571792
PRC train: 0.756496	val: 0.646123	test: 0.611815

Epoch: 26
Loss: 0.444327988916638
ROC train: 0.795886	val: 0.597736	test: 0.572347
PRC train: 0.759616	val: 0.646596	test: 0.608012

Epoch: 27
Loss: 0.4418960823500875
ROC train: 0.801183	val: 0.611902	test: 0.581484
PRC train: 0.762726	val: 0.654864	test: 0.618477

Epoch: 28
Loss: 0.4361866741289327
ROC train: 0.800845	val: 0.614237	test: 0.588876
PRC train: 0.761057	val: 0.655699	test: 0.623205

Epoch: 29
Loss: 0.43946927589148943
ROC train: 0.809240	val: 0.611290	test: 0.583190
PRC train: 0.767714	val: 0.656114	test: 0.622739

Epoch: 30
Loss: 0.4327127749207319
ROC train: 0.816611	val: 0.612414	test: 0.561768
PRC train: 0.776355	val: 0.656215	test: 0.613854

Epoch: 31
Loss: 0.4314816095047512
ROC train: 0.816547	val: 0.618458	test: 0.564875
PRC train: 0.776356	val: 0.656647	test: 0.614230

Epoch: 32
Loss: 0.42520434209242347
ROC train: 0.824501	val: 0.606671	test: 0.565915Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/sider/noise=0.2.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:3
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.2
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/sider/noise=0.2
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/sider/noise=0.2/sider_scaff_4_26-05_11-20-03  ]
[ Using Seed :  4  ]
[ Using device :  cuda:3  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.686428055550822
ROC train: 0.532977	val: 0.501552	test: 0.487473
PRC train: 0.574346	val: 0.600537	test: 0.583416

Epoch: 2
Loss: 0.6522218044153346
ROC train: 0.563583	val: 0.499083	test: 0.499240
PRC train: 0.598516	val: 0.599152	test: 0.592132

Epoch: 3
Loss: 0.621016821068825
ROC train: 0.577358	val: 0.492211	test: 0.514311
PRC train: 0.611102	val: 0.602524	test: 0.594021

Epoch: 4
Loss: 0.5954799015777165
ROC train: 0.591951	val: 0.491865	test: 0.518049
PRC train: 0.619111	val: 0.600775	test: 0.597268

Epoch: 5
Loss: 0.5759195532608669
ROC train: 0.606113	val: 0.504064	test: 0.520011
PRC train: 0.629781	val: 0.606173	test: 0.603916

Epoch: 6
Loss: 0.5582271961456999
ROC train: 0.625911	val: 0.519695	test: 0.529431
PRC train: 0.642318	val: 0.615157	test: 0.606631

Epoch: 7
Loss: 0.5416086756105767
ROC train: 0.643410	val: 0.529473	test: 0.544827
PRC train: 0.652189	val: 0.620533	test: 0.610780

Epoch: 8
Loss: 0.53213880236293
ROC train: 0.657770	val: 0.532382	test: 0.558709
PRC train: 0.659623	val: 0.618572	test: 0.614030

Epoch: 9
Loss: 0.5210247070051084
ROC train: 0.670303	val: 0.530716	test: 0.570515
PRC train: 0.665218	val: 0.615062	test: 0.616902

Epoch: 10
Loss: 0.5085812198396553
ROC train: 0.677970	val: 0.532046	test: 0.573176
PRC train: 0.669011	val: 0.615238	test: 0.617106

Epoch: 11
Loss: 0.5009920025245709
ROC train: 0.688196	val: 0.540489	test: 0.568116
PRC train: 0.676707	val: 0.619414	test: 0.616649

Epoch: 12
Loss: 0.49725223486753106
ROC train: 0.696108	val: 0.540371	test: 0.570202
PRC train: 0.681687	val: 0.617179	test: 0.617408

Epoch: 13
Loss: 0.49054042280102916
ROC train: 0.709452	val: 0.550758	test: 0.579343
PRC train: 0.690078	val: 0.623282	test: 0.621090

Epoch: 14
Loss: 0.48557264643261683
ROC train: 0.717558	val: 0.566246	test: 0.589377
PRC train: 0.695270	val: 0.630660	test: 0.621538

Epoch: 15
Loss: 0.4805799714984872
ROC train: 0.723688	val: 0.562572	test: 0.595169
PRC train: 0.699691	val: 0.629883	test: 0.624085

Epoch: 16
Loss: 0.47566150840393895
ROC train: 0.728487	val: 0.568639	test: 0.573161
PRC train: 0.702380	val: 0.634946	test: 0.614381

Epoch: 17
Loss: 0.47207241987616577
ROC train: 0.730965	val: 0.568481	test: 0.573524
PRC train: 0.705793	val: 0.635259	test: 0.614274

Epoch: 18
Loss: 0.47149412777672406
ROC train: 0.745384	val: 0.563731	test: 0.597137
PRC train: 0.715933	val: 0.631009	test: 0.627285

Epoch: 19
Loss: 0.46896735745761314
ROC train: 0.752023	val: 0.561810	test: 0.596803
PRC train: 0.718404	val: 0.632730	test: 0.622976

Epoch: 20
Loss: 0.4634986567664667
ROC train: 0.763560	val: 0.558358	test: 0.596563
PRC train: 0.726601	val: 0.634905	test: 0.620791

Epoch: 21
Loss: 0.45520544986881645
ROC train: 0.772804	val: 0.565821	test: 0.593112
PRC train: 0.734677	val: 0.637067	test: 0.621062

Epoch: 22
Loss: 0.4578478532978039
ROC train: 0.775836	val: 0.564472	test: 0.598713
PRC train: 0.736446	val: 0.633531	test: 0.628932

Epoch: 23
Loss: 0.4493073388776601
ROC train: 0.779152	val: 0.563389	test: 0.583367
PRC train: 0.736574	val: 0.635605	test: 0.619398

Epoch: 24
Loss: 0.4500261022059462
ROC train: 0.787155	val: 0.568625	test: 0.588216
PRC train: 0.742997	val: 0.637390	test: 0.621124

Epoch: 25
Loss: 0.4461457683664172
ROC train: 0.786723	val: 0.581751	test: 0.576413
PRC train: 0.746012	val: 0.640802	test: 0.614591

Epoch: 26
Loss: 0.442154855610824
ROC train: 0.792594	val: 0.578978	test: 0.593258
PRC train: 0.750673	val: 0.642624	test: 0.622474

Epoch: 27
Loss: 0.43635141175590497
ROC train: 0.796047	val: 0.578686	test: 0.600968
PRC train: 0.752701	val: 0.642277	test: 0.627507

Epoch: 28
Loss: 0.4385592498119634
ROC train: 0.807970	val: 0.583162	test: 0.592366
PRC train: 0.761812	val: 0.642599	test: 0.620406

Epoch: 29
Loss: 0.4413791594390525
ROC train: 0.809509	val: 0.576204	test: 0.603851
PRC train: 0.767060	val: 0.639578	test: 0.624801

Epoch: 30
Loss: 0.4325721587208612
ROC train: 0.813293	val: 0.583333	test: 0.588781
PRC train: 0.768543	val: 0.643537	test: 0.616246

Epoch: 31
Loss: 0.4286825331549875
ROC train: 0.819469	val: 0.582338	test: 0.603431
PRC train: 0.774042	val: 0.643692	test: 0.622018

Epoch: 32
Loss: 0.42448081389068404
ROC train: 0.824905	val: 0.578779	test: 0.592363
PRC train: 0.746609	val: 0.654045	test: 0.625547

Epoch: 34
Loss: 0.45026507397944615
ROC train: 0.781153	val: 0.617917	test: 0.594266
PRC train: 0.749432	val: 0.658622	test: 0.625223

Epoch: 35
Loss: 0.4464928107774174
ROC train: 0.779845	val: 0.603612	test: 0.607415
PRC train: 0.750508	val: 0.653151	test: 0.630394

Epoch: 36
Loss: 0.4481385129685968
ROC train: 0.785740	val: 0.599955	test: 0.607700
PRC train: 0.753033	val: 0.651291	test: 0.627147

Epoch: 37
Loss: 0.4466956276501392
ROC train: 0.789048	val: 0.602645	test: 0.612241
PRC train: 0.755397	val: 0.657993	test: 0.631101

Epoch: 38
Loss: 0.4423678371597707
ROC train: 0.792378	val: 0.596596	test: 0.615192
PRC train: 0.758829	val: 0.654972	test: 0.634932

Epoch: 39
Loss: 0.4384615424034168
ROC train: 0.796790	val: 0.604838	test: 0.611026
PRC train: 0.763800	val: 0.656278	test: 0.636953

Epoch: 40
Loss: 0.44354558991239046
ROC train: 0.795112	val: 0.605929	test: 0.610895
PRC train: 0.762383	val: 0.657558	test: 0.632776

Epoch: 41
Loss: 0.43411126619389667
ROC train: 0.791254	val: 0.613362	test: 0.589683
PRC train: 0.757125	val: 0.661576	test: 0.627029

Epoch: 42
Loss: 0.4364960200297337
ROC train: 0.797545	val: 0.614306	test: 0.604103
PRC train: 0.761623	val: 0.659611	test: 0.631356

Epoch: 43
Loss: 0.43887188091086715
ROC train: 0.799354	val: 0.614480	test: 0.603447
PRC train: 0.762434	val: 0.661309	test: 0.634068

Epoch: 44
Loss: 0.43013705534036123
ROC train: 0.805870	val: 0.602822	test: 0.611442
PRC train: 0.769006	val: 0.655554	test: 0.632119

Epoch: 45
Loss: 0.43432572797978
ROC train: 0.808995	val: 0.600114	test: 0.620406
PRC train: 0.772934	val: 0.658444	test: 0.640913

Epoch: 46
Loss: 0.4320614099163155
ROC train: 0.811905	val: 0.609686	test: 0.616731
PRC train: 0.775827	val: 0.664105	test: 0.642595

Epoch: 47
Loss: 0.43359032680466003
ROC train: 0.813163	val: 0.612630	test: 0.614963
PRC train: 0.779077	val: 0.660433	test: 0.640783

Epoch: 48
Loss: 0.4324314562326309
ROC train: 0.812515	val: 0.610488	test: 0.613503
PRC train: 0.776686	val: 0.660056	test: 0.638083

Epoch: 49
Loss: 0.42697674581200856
ROC train: 0.811674	val: 0.594003	test: 0.619824
PRC train: 0.775199	val: 0.657165	test: 0.641787

Epoch: 50
Loss: 0.4253528085185743
ROC train: 0.814018	val: 0.591497	test: 0.620830
PRC train: 0.778743	val: 0.652454	test: 0.641756

Epoch: 51
Loss: 0.42418919041144443
ROC train: 0.808320	val: 0.589738	test: 0.621950
PRC train: 0.773037	val: 0.650424	test: 0.639443

Epoch: 52
Loss: 0.42631165953031297
ROC train: 0.824135	val: 0.595591	test: 0.614290
PRC train: 0.784958	val: 0.656885	test: 0.639655

Epoch: 53
Loss: 0.42552136510406724
ROC train: 0.820979	val: 0.588363	test: 0.609604
PRC train: 0.786217	val: 0.655357	test: 0.633943

Epoch: 54
Loss: 0.42200810340281797
ROC train: 0.823503	val: 0.600791	test: 0.608520
PRC train: 0.786453	val: 0.660588	test: 0.640146

Epoch: 55
Loss: 0.42727313942189477
ROC train: 0.826159	val: 0.613310	test: 0.601269
PRC train: 0.788492	val: 0.663716	test: 0.634375

Epoch: 56
Loss: 0.4179555192641228
ROC train: 0.826251	val: 0.600587	test: 0.603578
PRC train: 0.790316	val: 0.660278	test: 0.637406

Epoch: 57
Loss: 0.41813374759955346
ROC train: 0.823490	val: 0.606034	test: 0.593120
PRC train: 0.786215	val: 0.666551	test: 0.634757

Epoch: 58
Loss: 0.41700270850474325
ROC train: 0.832951	val: 0.608059	test: 0.607306
PRC train: 0.793424	val: 0.666173	test: 0.642701

Epoch: 59
Loss: 0.41668555697031345
ROC train: 0.830268	val: 0.601609	test: 0.613201
PRC train: 0.790781	val: 0.659168	test: 0.644547

Epoch: 60
Loss: 0.42113111701662237
ROC train: 0.837823	val: 0.602371	test: 0.596429
PRC train: 0.797177	val: 0.661120	test: 0.636218

Epoch: 61
Loss: 0.41342918083631897
ROC train: 0.836691	val: 0.605191	test: 0.606942
PRC train: 0.795714	val: 0.661772	test: 0.642009

Epoch: 62
Loss: 0.41596473075202267
ROC train: 0.839649	val: 0.594744	test: 0.618297
PRC train: 0.799168	val: 0.657281	test: 0.654028

Epoch: 63
Loss: 0.4079605405348944
ROC train: 0.841614	val: 0.601899	test: 0.606356
PRC train: 0.801601	val: 0.662467	test: 0.640266

Epoch: 64
Loss: 0.40844013571198473
ROC train: 0.838243	val: 0.601498	test: 0.612977
PRC train: 0.800663	val: 0.661106	test: 0.639866

Epoch: 65
Loss: 0.40720797245548973
ROC train: 0.844263	val: 0.612686	test: 0.598243
PRC train: 0.803482	val: 0.664324	test: 0.637985

Epoch: 66
Loss: 0.40759562129490295
ROC train: 0.842210	val: 0.603279	test: 0.602421
PRC train: 0.801692	val: 0.660731	test: 0.642363

Epoch: 67
Loss: 0.41123173879236596
ROC train: 0.846876	val: 0.592060	test: 0.601762
PRC train: 0.805163	val: 0.663743	test: 0.638160

Epoch: 68
Loss: 0.4078087037319862
ROC train: 0.848826	val: 0.603222	test: 0.608777
PRC train: 0.807546	val: 0.665718	test: 0.643965

Epoch: 69
Loss: 0.4109299949798448
ROC train: 0.843250	val: 0.590478	test: 0.613143
PRC train: 0.806316	val: 0.657114	test: 0.643832

Epoch: 70
Loss: 0.40791230619955465
ROC train: 0.848979	val: 0.605094	test: 0.614276
PRC train: 0.807981	val: 0.666437	test: 0.648823

Epoch: 71
Loss: 0.40776401937334705
ROC train: 0.849620	val: 0.596246	test: 0.609669
PRC train: 0.808491	val: 0.664407	test: 0.646789

Epoch: 72
Loss: 0.40639508497708265
ROC train: 0.847670	val: 0.588843	test: 0.604889
PRC train: 0.809295	val: 0.661349	test: 0.640006

Epoch: 73
Loss: 0.40310380313999816
ROC train: 0.848060	val: 0.609191	test: 0.599006
PRC train: 0.809846	val: 0.669110	test: 0.638503

Epoch: 74
Loss: 0.4001878456651422
ROC train: 0.856443	val: 0.602812	test: 0.609256
PRC train: 0.817951	val: 0.661348	test: 0.644605

Epoch: 75
Loss: 0.40378906920307206
ROC train: 0.856120	val: 0.594973	test: 0.608405
PRC train: 0.817626	val: 0.658851	test: 0.642008

Epoch: 76
Loss: 0.3971991230830431
ROC train: 0.857765	val: 0.605278	test: 0.602362
PRC train: 0.814751	val: 0.664481	test: 0.637232

Epoch: 77
Loss: 0.3932734838219609
ROC train: 0.859258	val: 0.607327	test: 0.604693
PRC train: 0.818305	val: 0.663471	test: 0.641011

Epoch: 78
Loss: 0.3968952914981413
ROC train: 0.860029	val: 0.607321	test: 0.593169
PRC train: 0.820997	val: 0.665319	test: 0.641466

Epoch: 79
Loss: 0.3937397246645375
ROC train: 0.858831	val: 0.586148	test: 0.609077
PRC train: 0.819539	val: 0.658124	test: 0.648858

Epoch: 80
Loss: 0.39379119940936114
ROC train: 0.861635	val: 0.588738	test: 0.598687
PRC train: 0.817841	val: 0.662034	test: 0.641421

Epoch: 81
Loss: 0.3960424492935048
ROC train: 0.867765	val: 0.613308	test: 0.600528
PRC train: 0.825904	val: 0.671802	test: 0.639818

Epoch: 82
Loss: 0.3951373924954544
ROC train: 0.864667	val: 0.615854	test: 0.615716
PRC train: 0.825332	val: 0.669324	test: 0.651485

Epoch: 83
Loss: 0.38915382734191717
ROC train: 0.866696	val: 0.600315	test: 0.607023
PRC train: 0.827456	val: 0.664727	test: 0.647242

Epoch: 84
Loss: 0.3949653432213166
ROC train: 0.866438	val: 0.594290	test: 0.614029
PRC train: 0.826128	val: 0.663388	test: 0.645523

Epoch: 85
Loss: 0.3909910377903567
ROC train: 0.865502	val: 0.604285	test: 0.618440
PRC train: 0.825573	val: 0.667747	test: 0.647018

Epoch: 86
Loss: 0.39010469801864217
ROC train: 0.869315	val: 0.594021	test: 0.623145
PRC train: 0.828972	val: 0.659519	test: 0.650336

Epoch: 87
Loss: 0.3856568898492568
ROC train: 0.872253	val: 0.604565	test: 0.604864
PRC train: 0.831772	val: 0.669652	test: 0.640151

Epoch: 88
Loss: 0.3885925590406981
ROC train: 0.873492	val: 0.610113	test: 0.607624
PRC train: 0.834458	val: 0.673122	test: 0.639867

Epoch: 89
Loss: 0.3877200520944123
ROC train: 0.873874	val: 0.601213	test: 0.608978
PRC train: 0.834983	val: 0.668556	test: 0.641915

Epoch: 90
Loss: 0.384333097057942
ROC train: 0.875269	val: 0.607684	test: 0.593646
PRC train: 0.835493	val: 0.670338	test: 0.636037

Epoch: 91
Loss: 0.3839366953311264
ROC train: 0.875809	val: 0.602272	test: 0.615464
PRC train: 0.836813	val: 0.670725	test: 0.650258

Epoch: 92
Loss: 0.3842373780999636
ROC train: 0.876269	val: 0.596846	test: 0.612943
PRC train: 0.836501	val: 0.668676	test: 0.643019

Epoch: 93
Loss: 0.38412497611941465
ROC train: 0.876469	val: 0.599681	test: 0.603238
PRC train: 0.835608	val: 0.671053	test: 0.639805

Epoch: 94
Loss: 0.3806010687020385
ROC train: 0.875631	val: 0.604521	test: 0.596419
PRC train: 0.751325	val: 0.657223	test: 0.638623

Epoch: 34
Loss: 0.44549448991807267
ROC train: 0.780967	val: 0.601712	test: 0.624841
PRC train: 0.752974	val: 0.655347	test: 0.637753

Epoch: 35
Loss: 0.4455970309704302
ROC train: 0.785773	val: 0.612545	test: 0.626290
PRC train: 0.755035	val: 0.658735	test: 0.638685

Epoch: 36
Loss: 0.44219657857281514
ROC train: 0.788683	val: 0.608575	test: 0.626722
PRC train: 0.758818	val: 0.657937	test: 0.640520

Epoch: 37
Loss: 0.4417871689769604
ROC train: 0.790062	val: 0.602710	test: 0.622715
PRC train: 0.760696	val: 0.654733	test: 0.641850

Epoch: 38
Loss: 0.44404053296387236
ROC train: 0.790928	val: 0.614822	test: 0.618006
PRC train: 0.758532	val: 0.663211	test: 0.635879

Epoch: 39
Loss: 0.44716765839218076
ROC train: 0.792082	val: 0.607232	test: 0.627585
PRC train: 0.760739	val: 0.661381	test: 0.636792

Epoch: 40
Loss: 0.44431933562144954
ROC train: 0.797434	val: 0.609010	test: 0.632155
PRC train: 0.765911	val: 0.654632	test: 0.644260

Epoch: 41
Loss: 0.43468185314099755
ROC train: 0.800932	val: 0.607168	test: 0.631460
PRC train: 0.768198	val: 0.656950	test: 0.641603

Epoch: 42
Loss: 0.43776152461188095
ROC train: 0.797132	val: 0.598967	test: 0.619830
PRC train: 0.763411	val: 0.654937	test: 0.631732

Epoch: 43
Loss: 0.4312397161207245
ROC train: 0.800007	val: 0.602492	test: 0.619246
PRC train: 0.766057	val: 0.658291	test: 0.636215

Epoch: 44
Loss: 0.4311995310403046
ROC train: 0.803191	val: 0.603522	test: 0.626814
PRC train: 0.771709	val: 0.657919	test: 0.642188

Epoch: 45
Loss: 0.43620601370418555
ROC train: 0.809635	val: 0.610223	test: 0.630674
PRC train: 0.773925	val: 0.661179	test: 0.638172

Epoch: 46
Loss: 0.4338961876271551
ROC train: 0.807437	val: 0.621820	test: 0.621895
PRC train: 0.772620	val: 0.664347	test: 0.639614

Epoch: 47
Loss: 0.42971985292872167
ROC train: 0.806259	val: 0.615478	test: 0.634968
PRC train: 0.773840	val: 0.658550	test: 0.643650

Epoch: 48
Loss: 0.43235595034000457
ROC train: 0.808379	val: 0.608418	test: 0.625124
PRC train: 0.774362	val: 0.661088	test: 0.641117

Epoch: 49
Loss: 0.428725315421839
ROC train: 0.816574	val: 0.610934	test: 0.627570
PRC train: 0.779916	val: 0.663177	test: 0.640630

Epoch: 50
Loss: 0.4305203759968782
ROC train: 0.820129	val: 0.607821	test: 0.637787
PRC train: 0.783924	val: 0.659761	test: 0.645331

Epoch: 51
Loss: 0.42931327973703637
ROC train: 0.819420	val: 0.601626	test: 0.619819
PRC train: 0.783742	val: 0.657330	test: 0.635463

Epoch: 52
Loss: 0.4228075469900876
ROC train: 0.823139	val: 0.608559	test: 0.626575
PRC train: 0.787826	val: 0.657998	test: 0.639964

Epoch: 53
Loss: 0.4215653176356023
ROC train: 0.821803	val: 0.604105	test: 0.633442
PRC train: 0.785089	val: 0.658664	test: 0.642945

Epoch: 54
Loss: 0.4237594658211827
ROC train: 0.822185	val: 0.603659	test: 0.636188
PRC train: 0.786482	val: 0.658444	test: 0.643321

Epoch: 55
Loss: 0.42049490248131977
ROC train: 0.821863	val: 0.612355	test: 0.622454
PRC train: 0.787348	val: 0.660009	test: 0.642411

Epoch: 56
Loss: 0.4182272845849078
ROC train: 0.824814	val: 0.593720	test: 0.641951
PRC train: 0.789716	val: 0.655858	test: 0.650301

Epoch: 57
Loss: 0.4136410907554847
ROC train: 0.827704	val: 0.595375	test: 0.628526
PRC train: 0.789046	val: 0.655124	test: 0.643454

Epoch: 58
Loss: 0.4134289956029956
ROC train: 0.833002	val: 0.608629	test: 0.622581
PRC train: 0.791946	val: 0.658100	test: 0.644563

Epoch: 59
Loss: 0.41764513498981837
ROC train: 0.831074	val: 0.605724	test: 0.631945
PRC train: 0.792270	val: 0.654017	test: 0.647934

Epoch: 60
Loss: 0.4158250440036603
ROC train: 0.827966	val: 0.602368	test: 0.614144
PRC train: 0.788413	val: 0.658659	test: 0.638605

Epoch: 61
Loss: 0.41599513976957586
ROC train: 0.830357	val: 0.598503	test: 0.613653
PRC train: 0.790687	val: 0.656498	test: 0.638384

Epoch: 62
Loss: 0.4135467141072132
ROC train: 0.836061	val: 0.599207	test: 0.626142
PRC train: 0.798926	val: 0.656335	test: 0.646330

Epoch: 63
Loss: 0.41631257667067273
ROC train: 0.840743	val: 0.611096	test: 0.628695
PRC train: 0.803957	val: 0.663651	test: 0.642245

Epoch: 64
Loss: 0.4133826634216023
ROC train: 0.838697	val: 0.605005	test: 0.622745
PRC train: 0.800228	val: 0.660573	test: 0.639613

Epoch: 65
Loss: 0.4095775154048395
ROC train: 0.844365	val: 0.617662	test: 0.626122
PRC train: 0.802599	val: 0.663392	test: 0.645840

Epoch: 66
Loss: 0.4060507437415434
ROC train: 0.841153	val: 0.602037	test: 0.619640
PRC train: 0.801182	val: 0.656593	test: 0.637243

Epoch: 67
Loss: 0.4118022369940415
ROC train: 0.842786	val: 0.608623	test: 0.612267
PRC train: 0.800635	val: 0.662393	test: 0.636225

Epoch: 68
Loss: 0.4093585370314353
ROC train: 0.840505	val: 0.606171	test: 0.624165
PRC train: 0.799256	val: 0.660894	test: 0.648559

Epoch: 69
Loss: 0.40030208841108506
ROC train: 0.846148	val: 0.612947	test: 0.615762
PRC train: 0.806587	val: 0.662035	test: 0.641556

Epoch: 70
Loss: 0.40383250521858044
ROC train: 0.850006	val: 0.608298	test: 0.612752
PRC train: 0.812262	val: 0.662007	test: 0.640143

Epoch: 71
Loss: 0.4004925416997855
ROC train: 0.850889	val: 0.599043	test: 0.600429
PRC train: 0.809396	val: 0.657960	test: 0.634400

Epoch: 72
Loss: 0.40019418946230434
ROC train: 0.851067	val: 0.594115	test: 0.599109
PRC train: 0.809758	val: 0.657378	test: 0.634643

Epoch: 73
Loss: 0.3991948259973895
ROC train: 0.854747	val: 0.612708	test: 0.614340
PRC train: 0.816302	val: 0.662749	test: 0.639350

Epoch: 74
Loss: 0.4037181391580136
ROC train: 0.854090	val: 0.625597	test: 0.609871
PRC train: 0.812273	val: 0.670494	test: 0.637329

Epoch: 75
Loss: 0.3993863383809143
ROC train: 0.852200	val: 0.602776	test: 0.621150
PRC train: 0.810593	val: 0.662208	test: 0.641024

Epoch: 76
Loss: 0.4003251688713731
ROC train: 0.859036	val: 0.606792	test: 0.619383
PRC train: 0.817255	val: 0.663803	test: 0.644758

Epoch: 77
Loss: 0.3952698972361338
ROC train: 0.857840	val: 0.597701	test: 0.633485
PRC train: 0.816680	val: 0.661450	test: 0.647619

Epoch: 78
Loss: 0.39763812767639195
ROC train: 0.859750	val: 0.599649	test: 0.626982
PRC train: 0.819048	val: 0.662485	test: 0.642665

Epoch: 79
Loss: 0.3967012159903132
ROC train: 0.861677	val: 0.613729	test: 0.608559
PRC train: 0.820229	val: 0.665249	test: 0.635540

Epoch: 80
Loss: 0.3948670212214829
ROC train: 0.863412	val: 0.603115	test: 0.618106
PRC train: 0.822102	val: 0.661165	test: 0.639608

Epoch: 81
Loss: 0.395001587888852
ROC train: 0.862159	val: 0.613601	test: 0.593235
PRC train: 0.819758	val: 0.663350	test: 0.630566

Epoch: 82
Loss: 0.3950539225163797
ROC train: 0.865767	val: 0.612235	test: 0.610640
PRC train: 0.824497	val: 0.665390	test: 0.640673

Epoch: 83
Loss: 0.3924087457395874
ROC train: 0.865223	val: 0.612715	test: 0.613558
PRC train: 0.826723	val: 0.661074	test: 0.645719

Epoch: 84
Loss: 0.39086586627018705
ROC train: 0.866968	val: 0.605186	test: 0.599027
PRC train: 0.827202	val: 0.661416	test: 0.638494

Epoch: 85
Loss: 0.3910589463201483
ROC train: 0.868489	val: 0.606719	test: 0.608357
PRC train: 0.826233	val: 0.661180	test: 0.638334

Epoch: 86
Loss: 0.38539070865351777
ROC train: 0.869696	val: 0.603041	test: 0.608017
PRC train: 0.827389	val: 0.659531	test: 0.638166

Epoch: 87
Loss: 0.3900439888387564
ROC train: 0.871938	val: 0.599256	test: 0.617712
PRC train: 0.832210	val: 0.659193	test: 0.643336

Epoch: 88
Loss: 0.38798187759411074
ROC train: 0.873912	val: 0.609132	test: 0.608738
PRC train: 0.833741	val: 0.663977	test: 0.640706

Epoch: 89
Loss: 0.3858004716241067
ROC train: 0.872434	val: 0.607597	test: 0.609343
PRC train: 0.836662	val: 0.664007	test: 0.640739

Epoch: 90
Loss: 0.38506907009900754
ROC train: 0.874662	val: 0.609552	test: 0.617151
PRC train: 0.836453	val: 0.662563	test: 0.644588

Epoch: 91
Loss: 0.3821375278485488
ROC train: 0.874359	val: 0.624721	test: 0.616822
PRC train: 0.834064	val: 0.661892	test: 0.642575

Epoch: 92
Loss: 0.3867829630546675
ROC train: 0.877935	val: 0.612962	test: 0.614341
PRC train: 0.839835	val: 0.664188	test: 0.639182

Epoch: 93
Loss: 0.38461166442442796
ROC train: 0.874982	val: 0.602149	test: 0.613654
PRC train: 0.837679	val: 0.660754	test: 0.640696

Epoch: 94
Loss: 0.3838385555866772
ROC train: 0.874810	val: 0.603004	test: 0.602621
PRC train: 0.751270	val: 0.662097	test: 0.640626

Epoch: 34
Loss: 0.44850852491161214
ROC train: 0.785200	val: 0.614838	test: 0.629068
PRC train: 0.753599	val: 0.661184	test: 0.643722

Epoch: 35
Loss: 0.4439666346792629
ROC train: 0.786343	val: 0.616223	test: 0.616989
PRC train: 0.752424	val: 0.664137	test: 0.635026

Epoch: 36
Loss: 0.4448284713834266
ROC train: 0.789665	val: 0.620229	test: 0.608173
PRC train: 0.755896	val: 0.664007	test: 0.629025

Epoch: 37
Loss: 0.44567829257560154
ROC train: 0.789896	val: 0.623323	test: 0.615736
PRC train: 0.757937	val: 0.663773	test: 0.639088

Epoch: 38
Loss: 0.44291078582509635
ROC train: 0.792207	val: 0.629124	test: 0.616752
PRC train: 0.758285	val: 0.669601	test: 0.645270

Epoch: 39
Loss: 0.4406009022863187
ROC train: 0.794619	val: 0.619412	test: 0.610620
PRC train: 0.760591	val: 0.666392	test: 0.638832

Epoch: 40
Loss: 0.43782026623326614
ROC train: 0.796361	val: 0.628839	test: 0.602530
PRC train: 0.761113	val: 0.667770	test: 0.628952

Epoch: 41
Loss: 0.4433640105801217
ROC train: 0.798588	val: 0.628604	test: 0.610094
PRC train: 0.763864	val: 0.665176	test: 0.637460

Epoch: 42
Loss: 0.43738308481618987
ROC train: 0.801454	val: 0.620901	test: 0.618459
PRC train: 0.768123	val: 0.666928	test: 0.638828

Epoch: 43
Loss: 0.44083406720675544
ROC train: 0.804481	val: 0.620031	test: 0.633687
PRC train: 0.770154	val: 0.668295	test: 0.639603

Epoch: 44
Loss: 0.431550828684012
ROC train: 0.797572	val: 0.616285	test: 0.629747
PRC train: 0.762533	val: 0.667561	test: 0.644898

Epoch: 45
Loss: 0.4325825139342524
ROC train: 0.800782	val: 0.619226	test: 0.619919
PRC train: 0.765371	val: 0.663113	test: 0.637342

Epoch: 46
Loss: 0.43467922122952585
ROC train: 0.810209	val: 0.621105	test: 0.612962
PRC train: 0.773142	val: 0.665903	test: 0.637876

Epoch: 47
Loss: 0.43424236423292506
ROC train: 0.811043	val: 0.621323	test: 0.611101
PRC train: 0.775004	val: 0.667682	test: 0.634972

Epoch: 48
Loss: 0.4244834246080445
ROC train: 0.816201	val: 0.628160	test: 0.614490
PRC train: 0.778250	val: 0.671154	test: 0.632579

Epoch: 49
Loss: 0.42655135539552236
ROC train: 0.817183	val: 0.621650	test: 0.612943
PRC train: 0.779152	val: 0.667879	test: 0.630975

Epoch: 50
Loss: 0.4318238434803129
ROC train: 0.814611	val: 0.610193	test: 0.616642
PRC train: 0.776716	val: 0.659088	test: 0.635896

Epoch: 51
Loss: 0.42520790806125736
ROC train: 0.817301	val: 0.611543	test: 0.613985
PRC train: 0.778821	val: 0.663415	test: 0.634614

Epoch: 52
Loss: 0.4231292604316952
ROC train: 0.812075	val: 0.602360	test: 0.609794
PRC train: 0.778445	val: 0.666028	test: 0.635465

Epoch: 53
Loss: 0.4279338565355527
ROC train: 0.819186	val: 0.614871	test: 0.632978
PRC train: 0.785179	val: 0.666682	test: 0.648764

Epoch: 54
Loss: 0.43135789258669677
ROC train: 0.819983	val: 0.630910	test: 0.635054
PRC train: 0.785359	val: 0.671535	test: 0.645638

Epoch: 55
Loss: 0.42044325364326685
ROC train: 0.816888	val: 0.622518	test: 0.618614
PRC train: 0.780850	val: 0.669105	test: 0.637325

Epoch: 56
Loss: 0.42022202412354465
ROC train: 0.818569	val: 0.618727	test: 0.605782
PRC train: 0.782478	val: 0.664783	test: 0.632508

Epoch: 57
Loss: 0.4221654725851354
ROC train: 0.821775	val: 0.630000	test: 0.599988
PRC train: 0.783535	val: 0.673418	test: 0.630001

Epoch: 58
Loss: 0.41646254425717844
ROC train: 0.825749	val: 0.621675	test: 0.605733
PRC train: 0.786279	val: 0.670812	test: 0.634258

Epoch: 59
Loss: 0.4179900720181732
ROC train: 0.830892	val: 0.618978	test: 0.604370
PRC train: 0.791028	val: 0.669405	test: 0.635501

Epoch: 60
Loss: 0.41634003779428763
ROC train: 0.834561	val: 0.616375	test: 0.605933
PRC train: 0.793850	val: 0.664765	test: 0.635628

Epoch: 61
Loss: 0.4156140946511151
ROC train: 0.830585	val: 0.624435	test: 0.608333
PRC train: 0.792818	val: 0.672118	test: 0.638456

Epoch: 62
Loss: 0.410440975412104
ROC train: 0.838003	val: 0.646917	test: 0.618534
PRC train: 0.797894	val: 0.680681	test: 0.640464

Epoch: 63
Loss: 0.4092969272817789
ROC train: 0.838953	val: 0.633089	test: 0.638869
PRC train: 0.798602	val: 0.672940	test: 0.648307

Epoch: 64
Loss: 0.4120560236824945
ROC train: 0.835176	val: 0.630360	test: 0.605280
PRC train: 0.795900	val: 0.670466	test: 0.637676

Epoch: 65
Loss: 0.40888331009552425
ROC train: 0.837058	val: 0.632473	test: 0.611434
PRC train: 0.797690	val: 0.670251	test: 0.637103

Epoch: 66
Loss: 0.41561157964504447
ROC train: 0.843418	val: 0.627906	test: 0.618508
PRC train: 0.804245	val: 0.672524	test: 0.639430

Epoch: 67
Loss: 0.41157958529028926
ROC train: 0.841623	val: 0.630179	test: 0.599452
PRC train: 0.801814	val: 0.675732	test: 0.635685

Epoch: 68
Loss: 0.4079369593707291
ROC train: 0.848432	val: 0.631997	test: 0.599414
PRC train: 0.805797	val: 0.675209	test: 0.632159

Epoch: 69
Loss: 0.4110441381265198
ROC train: 0.846708	val: 0.623778	test: 0.611643
PRC train: 0.804867	val: 0.671346	test: 0.640463

Epoch: 70
Loss: 0.398466423492463
ROC train: 0.850048	val: 0.632440	test: 0.605608
PRC train: 0.808538	val: 0.670814	test: 0.636724

Epoch: 71
Loss: 0.4041747488078733
ROC train: 0.853626	val: 0.633549	test: 0.609952
PRC train: 0.811494	val: 0.672650	test: 0.639033

Epoch: 72
Loss: 0.4026211192745997
ROC train: 0.853450	val: 0.627492	test: 0.621952
PRC train: 0.811635	val: 0.670416	test: 0.646257

Epoch: 73
Loss: 0.400289518074755
ROC train: 0.856109	val: 0.624044	test: 0.614851
PRC train: 0.814213	val: 0.667658	test: 0.640350

Epoch: 74
Loss: 0.4017226099826132
ROC train: 0.853307	val: 0.619437	test: 0.604650
PRC train: 0.809212	val: 0.669535	test: 0.640305

Epoch: 75
Loss: 0.4006626904048434
ROC train: 0.854534	val: 0.604637	test: 0.608023
PRC train: 0.812846	val: 0.669623	test: 0.639022

Epoch: 76
Loss: 0.4066689784481664
ROC train: 0.854910	val: 0.610316	test: 0.597889
PRC train: 0.811342	val: 0.665898	test: 0.637472

Epoch: 77
Loss: 0.3977929903953329
ROC train: 0.855503	val: 0.613788	test: 0.596857
PRC train: 0.813835	val: 0.668864	test: 0.638621

Epoch: 78
Loss: 0.3989892452647883
ROC train: 0.861172	val: 0.619610	test: 0.613096
PRC train: 0.820513	val: 0.669258	test: 0.643703

Epoch: 79
Loss: 0.39400249192567005
ROC train: 0.863588	val: 0.621077	test: 0.607374
PRC train: 0.822034	val: 0.672726	test: 0.639201

Epoch: 80
Loss: 0.3943376238163804
ROC train: 0.864364	val: 0.611827	test: 0.612788
PRC train: 0.823709	val: 0.669542	test: 0.641719

Epoch: 81
Loss: 0.3947502494117456
ROC train: 0.865891	val: 0.614352	test: 0.604718
PRC train: 0.826303	val: 0.667415	test: 0.640605

Epoch: 82
Loss: 0.39426145189173695
ROC train: 0.864395	val: 0.621653	test: 0.586987
PRC train: 0.824101	val: 0.670191	test: 0.631392

Epoch: 83
Loss: 0.39137941852017605
ROC train: 0.862210	val: 0.612596	test: 0.604103
PRC train: 0.820843	val: 0.669235	test: 0.638799

Epoch: 84
Loss: 0.39645786369597447
ROC train: 0.868498	val: 0.614048	test: 0.587544
PRC train: 0.825863	val: 0.668426	test: 0.627940

Epoch: 85
Loss: 0.39129191782860456
ROC train: 0.869604	val: 0.616542	test: 0.590941
PRC train: 0.828299	val: 0.672643	test: 0.632998

Epoch: 86
Loss: 0.38709519448484886
ROC train: 0.869625	val: 0.616743	test: 0.596158
PRC train: 0.828499	val: 0.671707	test: 0.637518

Epoch: 87
Loss: 0.3891195574081635
ROC train: 0.867542	val: 0.632232	test: 0.587573
PRC train: 0.825201	val: 0.678772	test: 0.634503

Epoch: 88
Loss: 0.3887522080756588
ROC train: 0.873666	val: 0.615079	test: 0.602469
PRC train: 0.830347	val: 0.671918	test: 0.638203

Epoch: 89
Loss: 0.38561448504501994
ROC train: 0.869518	val: 0.615767	test: 0.595879
PRC train: 0.825647	val: 0.670520	test: 0.635253

Epoch: 90
Loss: 0.3814927685547542
ROC train: 0.873637	val: 0.625506	test: 0.595592
PRC train: 0.830943	val: 0.672533	test: 0.635101

Epoch: 91
Loss: 0.3820460823372968
ROC train: 0.877414	val: 0.625101	test: 0.624979
PRC train: 0.836306	val: 0.673861	test: 0.648243

Epoch: 92
Loss: 0.3813858897062769
ROC train: 0.881116	val: 0.625350	test: 0.614597
PRC train: 0.838446	val: 0.675855	test: 0.643634

Epoch: 93
Loss: 0.38135168189507074
ROC train: 0.879971	val: 0.626778	test: 0.576010
PRC train: 0.836696	val: 0.674454	test: 0.628895

Epoch: 94
Loss: 0.37920245352916665
ROC train: 0.880681	val: 0.622472	test: 0.604999
PRC train: 0.762298	val: 0.654835	test: 0.623719

Epoch: 33
Loss: 0.43905006719959816
ROC train: 0.800928	val: 0.593294	test: 0.583789
PRC train: 0.763442	val: 0.657870	test: 0.624776

Epoch: 34
Loss: 0.4402699945905102
ROC train: 0.810876	val: 0.600856	test: 0.594962
PRC train: 0.773461	val: 0.660857	test: 0.631176

Epoch: 35
Loss: 0.4305437511898246
ROC train: 0.818418	val: 0.606300	test: 0.605190
PRC train: 0.778776	val: 0.661237	test: 0.634172

Epoch: 36
Loss: 0.42545187737820706
ROC train: 0.818389	val: 0.604767	test: 0.615263
PRC train: 0.779230	val: 0.658569	test: 0.633316

Epoch: 37
Loss: 0.4281673354937096
ROC train: 0.819535	val: 0.614035	test: 0.599624
PRC train: 0.778971	val: 0.663221	test: 0.629148

Epoch: 38
Loss: 0.42399448797545025
ROC train: 0.815318	val: 0.603014	test: 0.608530
PRC train: 0.775562	val: 0.658586	test: 0.632848

Epoch: 39
Loss: 0.4288668620318126
ROC train: 0.824359	val: 0.603210	test: 0.604849
PRC train: 0.783232	val: 0.657799	test: 0.628952

Epoch: 40
Loss: 0.41676317856647704
ROC train: 0.831070	val: 0.613688	test: 0.589269
PRC train: 0.789131	val: 0.660651	test: 0.628105

Epoch: 41
Loss: 0.4173255803749436
ROC train: 0.826944	val: 0.610565	test: 0.595010
PRC train: 0.785121	val: 0.661764	test: 0.630870

Epoch: 42
Loss: 0.42041751230721464
ROC train: 0.833710	val: 0.600946	test: 0.602690
PRC train: 0.790156	val: 0.652936	test: 0.638654

Epoch: 43
Loss: 0.41221076133860174
ROC train: 0.839861	val: 0.596004	test: 0.593395
PRC train: 0.797168	val: 0.656751	test: 0.625950

Epoch: 44
Loss: 0.4168883825436741
ROC train: 0.838315	val: 0.598483	test: 0.591178
PRC train: 0.792996	val: 0.656054	test: 0.625819

Epoch: 45
Loss: 0.4105151814620445
ROC train: 0.827517	val: 0.602246	test: 0.575529
PRC train: 0.784629	val: 0.660217	test: 0.622308

Epoch: 46
Loss: 0.4090236793729548
ROC train: 0.837489	val: 0.600073	test: 0.586133
PRC train: 0.793400	val: 0.657956	test: 0.626066

Epoch: 47
Loss: 0.405000691137351
ROC train: 0.849808	val: 0.619248	test: 0.594672
PRC train: 0.807101	val: 0.664214	test: 0.637380

Epoch: 48
Loss: 0.40419461014619895
ROC train: 0.846848	val: 0.618212	test: 0.595076
PRC train: 0.804463	val: 0.664762	test: 0.634891

Epoch: 49
Loss: 0.4068676055503757
ROC train: 0.848389	val: 0.612507	test: 0.605727
PRC train: 0.804769	val: 0.664182	test: 0.633892

Epoch: 50
Loss: 0.39794929056448114
ROC train: 0.853046	val: 0.600410	test: 0.593388
PRC train: 0.808827	val: 0.660424	test: 0.624379

Epoch: 51
Loss: 0.39583892146696653
ROC train: 0.853452	val: 0.606554	test: 0.585817
PRC train: 0.810197	val: 0.658050	test: 0.627170

Epoch: 52
Loss: 0.3994704498546787
ROC train: 0.856569	val: 0.617756	test: 0.594305
PRC train: 0.811754	val: 0.668206	test: 0.630799

Epoch: 53
Loss: 0.40147299782690393
ROC train: 0.857891	val: 0.605974	test: 0.590478
PRC train: 0.811736	val: 0.664387	test: 0.623766

Epoch: 54
Loss: 0.3978794142611265
ROC train: 0.859352	val: 0.622223	test: 0.574163
PRC train: 0.815050	val: 0.669624	test: 0.624261

Epoch: 55
Loss: 0.4016007710182176
ROC train: 0.858998	val: 0.609681	test: 0.592032
PRC train: 0.811493	val: 0.668794	test: 0.628950

Epoch: 56
Loss: 0.3927301270386719
ROC train: 0.856588	val: 0.588448	test: 0.591277
PRC train: 0.811257	val: 0.662734	test: 0.624625

Epoch: 57
Loss: 0.3926547298896118
ROC train: 0.857474	val: 0.612379	test: 0.573590
PRC train: 0.811355	val: 0.664558	test: 0.620496

Epoch: 58
Loss: 0.3916662942767355
ROC train: 0.868887	val: 0.617922	test: 0.594539
PRC train: 0.821344	val: 0.665306	test: 0.630065

Epoch: 59
Loss: 0.3872992372708414
ROC train: 0.868102	val: 0.619710	test: 0.614134
PRC train: 0.823133	val: 0.668252	test: 0.641316

Epoch: 60
Loss: 0.3861901806691804
ROC train: 0.865603	val: 0.610937	test: 0.589822
PRC train: 0.820509	val: 0.662545	test: 0.635194

Epoch: 61
Loss: 0.38396189658768404
ROC train: 0.869120	val: 0.600708	test: 0.587893
PRC train: 0.824229	val: 0.659415	test: 0.631165

Epoch: 62
Loss: 0.3814861479445034
ROC train: 0.875271	val: 0.606603	test: 0.598288
PRC train: 0.830380	val: 0.666479	test: 0.634938

Epoch: 63
Loss: 0.3806637893845858
ROC train: 0.877610	val: 0.610531	test: 0.593151
PRC train: 0.831373	val: 0.663790	test: 0.631401

Epoch: 64
Loss: 0.3812456972147626
ROC train: 0.878808	val: 0.620867	test: 0.577550
PRC train: 0.832812	val: 0.668505	test: 0.623374

Epoch: 65
Loss: 0.3774027402232132
ROC train: 0.880431	val: 0.610646	test: 0.584449
PRC train: 0.834652	val: 0.666117	test: 0.626857

Epoch: 66
Loss: 0.3794455286677441
ROC train: 0.879936	val: 0.609613	test: 0.592162
PRC train: 0.833282	val: 0.665890	test: 0.631289

Epoch: 67
Loss: 0.3741433962278908
ROC train: 0.882598	val: 0.600747	test: 0.602275
PRC train: 0.836862	val: 0.661717	test: 0.635062

Epoch: 68
Loss: 0.3664735471809892
ROC train: 0.881209	val: 0.611820	test: 0.602698
PRC train: 0.837912	val: 0.663928	test: 0.633249

Epoch: 69
Loss: 0.3722220944237066
ROC train: 0.884005	val: 0.619937	test: 0.599594
PRC train: 0.838860	val: 0.665829	test: 0.636196

Epoch: 70
Loss: 0.37595313935781427
ROC train: 0.885243	val: 0.608968	test: 0.600721
PRC train: 0.838168	val: 0.662339	test: 0.637273

Epoch: 71
Loss: 0.3730086191931289
ROC train: 0.886012	val: 0.614523	test: 0.590448
PRC train: 0.839982	val: 0.664693	test: 0.630735

Epoch: 72
Loss: 0.37207766884021215
ROC train: 0.885773	val: 0.617473	test: 0.600615
PRC train: 0.840705	val: 0.663473	test: 0.640190

Epoch: 73
Loss: 0.3711057001077036
ROC train: 0.887318	val: 0.618978	test: 0.575744
PRC train: 0.840262	val: 0.670527	test: 0.631473

Epoch: 74
Loss: 0.3636279125684003
ROC train: 0.885775	val: 0.599088	test: 0.574610
PRC train: 0.837391	val: 0.665939	test: 0.628001

Epoch: 75
Loss: 0.3696516076727041
ROC train: 0.880926	val: 0.597426	test: 0.599175
PRC train: 0.832019	val: 0.659309	test: 0.633824

Epoch: 76
Loss: 0.3670986551456605
ROC train: 0.889680	val: 0.610927	test: 0.583304
PRC train: 0.843772	val: 0.664110	test: 0.631494

Epoch: 77
Loss: 0.3630856968087809
ROC train: 0.892140	val: 0.618236	test: 0.593184
PRC train: 0.846646	val: 0.670225	test: 0.639888

Epoch: 78
Loss: 0.3665663790707034
ROC train: 0.888681	val: 0.599900	test: 0.603912
PRC train: 0.842778	val: 0.662842	test: 0.636423

Epoch: 79
Loss: 0.3620676268807296
ROC train: 0.891961	val: 0.609690	test: 0.582717
PRC train: 0.843547	val: 0.664333	test: 0.630663

Epoch: 80
Loss: 0.36457583233319946
ROC train: 0.896667	val: 0.619156	test: 0.604614
PRC train: 0.849810	val: 0.672369	test: 0.643485

Epoch: 81
Loss: 0.3581605909089098
ROC train: 0.895335	val: 0.611266	test: 0.604754
PRC train: 0.851339	val: 0.668866	test: 0.638733

Epoch: 82
Loss: 0.3591809045086926
ROC train: 0.897831	val: 0.621324	test: 0.585488
PRC train: 0.850678	val: 0.668264	test: 0.633179

Epoch: 83
Loss: 0.3539521576747872
ROC train: 0.900042	val: 0.614995	test: 0.595702
PRC train: 0.851573	val: 0.664731	test: 0.635569

Epoch: 84
Loss: 0.351479780350627
ROC train: 0.899827	val: 0.622039	test: 0.591399
PRC train: 0.856967	val: 0.667353	test: 0.638908

Epoch: 85
Loss: 0.35115641306764633
ROC train: 0.902136	val: 0.619778	test: 0.589599
PRC train: 0.857365	val: 0.666007	test: 0.634008

Epoch: 86
Loss: 0.3506990689141031
ROC train: 0.901615	val: 0.609704	test: 0.583070
PRC train: 0.855061	val: 0.665485	test: 0.625428

Epoch: 87
Loss: 0.3498728657397537
ROC train: 0.905367	val: 0.604189	test: 0.578715
PRC train: 0.859035	val: 0.662292	test: 0.627620

Epoch: 88
Loss: 0.3487082023447827
ROC train: 0.907278	val: 0.608290	test: 0.582307
PRC train: 0.861627	val: 0.663574	test: 0.634111

Epoch: 89
Loss: 0.3459630866787403
ROC train: 0.908317	val: 0.607430	test: 0.579909
PRC train: 0.864244	val: 0.668170	test: 0.628170

Epoch: 90
Loss: 0.3489858943940665
ROC train: 0.909915	val: 0.618915	test: 0.596326
PRC train: 0.867626	val: 0.669231	test: 0.636499

Epoch: 91
Loss: 0.3427727663416216
ROC train: 0.909253	val: 0.614080	test: 0.593786
PRC train: 0.866661	val: 0.670707	test: 0.635363

Epoch: 92
Loss: 0.346210826756725
ROC train: 0.910672	val: 0.615375	test: 0.576279
PRC train: 0.865447	val: 0.672137	test: 0.628527

Epoch: 93
Loss: 0.3408745659641264
ROC train: 0.909151	val: 0.597488	test: 0.584177
PRC train: 0.863805	val: 0.665473	test: 0.627484
PRC train: 0.752815	val: 0.654456	test: 0.620351

Epoch: 33
Loss: 0.43586822489041505
ROC train: 0.799111	val: 0.607028	test: 0.577567
PRC train: 0.757054	val: 0.660432	test: 0.619673

Epoch: 34
Loss: 0.43385341433130764
ROC train: 0.807696	val: 0.595009	test: 0.588059
PRC train: 0.764283	val: 0.653158	test: 0.617394

Epoch: 35
Loss: 0.4344141427513744
ROC train: 0.809131	val: 0.598448	test: 0.591041
PRC train: 0.767193	val: 0.655731	test: 0.617447

Epoch: 36
Loss: 0.4328202011005825
ROC train: 0.816977	val: 0.588914	test: 0.591297
PRC train: 0.772777	val: 0.648260	test: 0.621166

Epoch: 37
Loss: 0.4374703010986666
ROC train: 0.818546	val: 0.598739	test: 0.592220
PRC train: 0.774008	val: 0.651693	test: 0.627807

Epoch: 38
Loss: 0.42685547732185414
ROC train: 0.816121	val: 0.600018	test: 0.591355
PRC train: 0.772690	val: 0.651477	test: 0.618099

Epoch: 39
Loss: 0.41974500889145705
ROC train: 0.818603	val: 0.607720	test: 0.589853
PRC train: 0.774315	val: 0.659012	test: 0.619661

Epoch: 40
Loss: 0.4220698749407446
ROC train: 0.824088	val: 0.610040	test: 0.585594
PRC train: 0.780180	val: 0.658354	test: 0.619066

Epoch: 41
Loss: 0.4252671864937816
ROC train: 0.830004	val: 0.604214	test: 0.584667
PRC train: 0.782599	val: 0.653623	test: 0.618617

Epoch: 42
Loss: 0.4180419021576524
ROC train: 0.828438	val: 0.596803	test: 0.591601
PRC train: 0.782615	val: 0.656543	test: 0.620206

Epoch: 43
Loss: 0.4192243634618865
ROC train: 0.834780	val: 0.606584	test: 0.583086
PRC train: 0.786885	val: 0.655755	test: 0.622394

Epoch: 44
Loss: 0.41847617171745116
ROC train: 0.827204	val: 0.602719	test: 0.584643
PRC train: 0.780378	val: 0.650777	test: 0.618035

Epoch: 45
Loss: 0.4109461607905721
ROC train: 0.834870	val: 0.595705	test: 0.599045
PRC train: 0.787650	val: 0.648184	test: 0.627472

Epoch: 46
Loss: 0.4094040666370284
ROC train: 0.841834	val: 0.606679	test: 0.593584
PRC train: 0.795208	val: 0.657762	test: 0.624722

Epoch: 47
Loss: 0.40504691235655166
ROC train: 0.842099	val: 0.601182	test: 0.597118
PRC train: 0.795739	val: 0.653467	test: 0.624017

Epoch: 48
Loss: 0.41242815851668774
ROC train: 0.839920	val: 0.589744	test: 0.601666
PRC train: 0.794709	val: 0.652092	test: 0.630721

Epoch: 49
Loss: 0.40320458941662657
ROC train: 0.850200	val: 0.593315	test: 0.588002
PRC train: 0.804957	val: 0.654762	test: 0.625310

Epoch: 50
Loss: 0.39823948021796196
ROC train: 0.855304	val: 0.591735	test: 0.593236
PRC train: 0.808710	val: 0.653985	test: 0.623305

Epoch: 51
Loss: 0.40172299893334384
ROC train: 0.847639	val: 0.598781	test: 0.594109
PRC train: 0.800519	val: 0.653854	test: 0.624553

Epoch: 52
Loss: 0.3987582525436674
ROC train: 0.844522	val: 0.594323	test: 0.579013
PRC train: 0.797120	val: 0.654426	test: 0.619947

Epoch: 53
Loss: 0.39844847681551887
ROC train: 0.857460	val: 0.606549	test: 0.571327
PRC train: 0.810075	val: 0.659036	test: 0.621775

Epoch: 54
Loss: 0.40029056057258006
ROC train: 0.858688	val: 0.594649	test: 0.590699
PRC train: 0.813602	val: 0.653402	test: 0.629665

Epoch: 55
Loss: 0.39786322564331633
ROC train: 0.861783	val: 0.593450	test: 0.602818
PRC train: 0.815969	val: 0.654121	test: 0.632396

Epoch: 56
Loss: 0.39298551827335587
ROC train: 0.860973	val: 0.611605	test: 0.598106
PRC train: 0.813567	val: 0.665998	test: 0.630232

Epoch: 57
Loss: 0.3917618145181055
ROC train: 0.865626	val: 0.599289	test: 0.611713
PRC train: 0.819085	val: 0.658100	test: 0.635641

Epoch: 58
Loss: 0.3894643762379696
ROC train: 0.869584	val: 0.592909	test: 0.602005
PRC train: 0.821599	val: 0.652093	test: 0.633169

Epoch: 59
Loss: 0.38817460059743036
ROC train: 0.870295	val: 0.600800	test: 0.589474
PRC train: 0.820038	val: 0.656615	test: 0.625560

Epoch: 60
Loss: 0.38993442879608925
ROC train: 0.866701	val: 0.607922	test: 0.572865
PRC train: 0.817425	val: 0.656518	test: 0.619771

Epoch: 61
Loss: 0.3803025817511106
ROC train: 0.864934	val: 0.599452	test: 0.583612
PRC train: 0.816797	val: 0.652801	test: 0.624272

Epoch: 62
Loss: 0.3829115722281685
ROC train: 0.876327	val: 0.591899	test: 0.590328
PRC train: 0.830059	val: 0.652262	test: 0.630633

Epoch: 63
Loss: 0.3791830329740477
ROC train: 0.876415	val: 0.591912	test: 0.595882
PRC train: 0.830392	val: 0.656445	test: 0.627604

Epoch: 64
Loss: 0.37643449914964155
ROC train: 0.873973	val: 0.589102	test: 0.600344
PRC train: 0.826454	val: 0.651562	test: 0.627343

Epoch: 65
Loss: 0.3768091837346093
ROC train: 0.880100	val: 0.606421	test: 0.589439
PRC train: 0.831454	val: 0.656805	test: 0.626596

Epoch: 66
Loss: 0.3799354254498429
ROC train: 0.880050	val: 0.597709	test: 0.598252
PRC train: 0.832000	val: 0.653564	test: 0.635086

Epoch: 67
Loss: 0.38014774378491856
ROC train: 0.880274	val: 0.599498	test: 0.590882
PRC train: 0.832860	val: 0.657149	test: 0.625665

Epoch: 68
Loss: 0.3747826063994554
ROC train: 0.879849	val: 0.585219	test: 0.602759
PRC train: 0.834545	val: 0.650747	test: 0.631782

Epoch: 69
Loss: 0.379202368793197
ROC train: 0.885869	val: 0.594903	test: 0.604644
PRC train: 0.837752	val: 0.655739	test: 0.628836

Epoch: 70
Loss: 0.3721204575728369
ROC train: 0.884590	val: 0.577108	test: 0.598440
PRC train: 0.840641	val: 0.647877	test: 0.623634

Epoch: 71
Loss: 0.3704089125016663
ROC train: 0.884074	val: 0.575408	test: 0.582122
PRC train: 0.837260	val: 0.645333	test: 0.623676

Epoch: 72
Loss: 0.3684988673214105
ROC train: 0.886546	val: 0.597631	test: 0.583179
PRC train: 0.838229	val: 0.651950	test: 0.626513

Epoch: 73
Loss: 0.3672593702383651
ROC train: 0.890483	val: 0.593360	test: 0.590377
PRC train: 0.844547	val: 0.648485	test: 0.631230

Epoch: 74
Loss: 0.3633774551872852
ROC train: 0.891354	val: 0.585650	test: 0.596700
PRC train: 0.845248	val: 0.648859	test: 0.633889

Epoch: 75
Loss: 0.36670160691062204
ROC train: 0.892837	val: 0.587734	test: 0.590352
PRC train: 0.846551	val: 0.653071	test: 0.630673

Epoch: 76
Loss: 0.36262995802348386
ROC train: 0.895643	val: 0.603638	test: 0.586412
PRC train: 0.849845	val: 0.660911	test: 0.627839

Epoch: 77
Loss: 0.36095763693049643
ROC train: 0.894760	val: 0.589334	test: 0.611539
PRC train: 0.849953	val: 0.649766	test: 0.634126

Epoch: 78
Loss: 0.368292437263669
ROC train: 0.896385	val: 0.578918	test: 0.602847
PRC train: 0.851344	val: 0.647484	test: 0.630872

Epoch: 79
Loss: 0.36264482912279317
ROC train: 0.890964	val: 0.589792	test: 0.580466
PRC train: 0.846741	val: 0.652909	test: 0.626049

Epoch: 80
Loss: 0.3607613958611216
ROC train: 0.899627	val: 0.578381	test: 0.591095
PRC train: 0.856814	val: 0.642184	test: 0.631403

Epoch: 81
Loss: 0.3583772670713038
ROC train: 0.900763	val: 0.597886	test: 0.578535
PRC train: 0.855348	val: 0.652598	test: 0.629700

Epoch: 82
Loss: 0.3594145753920357
ROC train: 0.900434	val: 0.603856	test: 0.587039
PRC train: 0.855593	val: 0.656923	test: 0.629554

Epoch: 83
Loss: 0.35689026370672283
ROC train: 0.901497	val: 0.595667	test: 0.576570
PRC train: 0.856259	val: 0.660918	test: 0.624929

Epoch: 84
Loss: 0.349015687691928
ROC train: 0.899126	val: 0.578000	test: 0.588941
PRC train: 0.856048	val: 0.647911	test: 0.631265

Epoch: 85
Loss: 0.35562612284742245
ROC train: 0.903130	val: 0.588650	test: 0.578500
PRC train: 0.858351	val: 0.655798	test: 0.625503

Epoch: 86
Loss: 0.34792679396574355
ROC train: 0.903364	val: 0.569716	test: 0.577963
PRC train: 0.861785	val: 0.646739	test: 0.619648

Epoch: 87
Loss: 0.3451220392255506
ROC train: 0.906969	val: 0.589609	test: 0.574293
PRC train: 0.861806	val: 0.649944	test: 0.624341

Epoch: 88
Loss: 0.349213878310338
ROC train: 0.909275	val: 0.582141	test: 0.591345
PRC train: 0.864622	val: 0.644351	test: 0.628206

Epoch: 89
Loss: 0.34826049926208374
ROC train: 0.908436	val: 0.587527	test: 0.592770
PRC train: 0.863360	val: 0.656115	test: 0.627517

Epoch: 90
Loss: 0.34158277828209893
ROC train: 0.907976	val: 0.578763	test: 0.575779
PRC train: 0.866636	val: 0.648104	test: 0.622508

Epoch: 91
Loss: 0.3408626313514317
ROC train: 0.908901	val: 0.592307	test: 0.567363
PRC train: 0.865545	val: 0.658303	test: 0.621496

Epoch: 92
Loss: 0.34687051620760895
ROC train: 0.909317	val: 0.583761	test: 0.586783
PRC train: 0.867352	val: 0.650598	test: 0.627301

Epoch: 93
Loss: 0.3436358674773199
ROC train: 0.912069	val: 0.586687	test: 0.592195
PRC train: 0.762299	val: 0.659108	test: 0.624346

Epoch: 33
Loss: 0.43743826849212464
ROC train: 0.810380	val: 0.596138	test: 0.600941
PRC train: 0.770340	val: 0.656225	test: 0.624112

Epoch: 34
Loss: 0.44042486393223285
ROC train: 0.815459	val: 0.606409	test: 0.597515
PRC train: 0.774543	val: 0.658723	test: 0.629446

Epoch: 35
Loss: 0.4325318323778335
ROC train: 0.807042	val: 0.589323	test: 0.626151
PRC train: 0.767510	val: 0.651226	test: 0.644695

Epoch: 36
Loss: 0.43073556192001206
ROC train: 0.815394	val: 0.615720	test: 0.590747
PRC train: 0.773435	val: 0.665876	test: 0.626392

Epoch: 37
Loss: 0.43150572439956314
ROC train: 0.816687	val: 0.605102	test: 0.593145
PRC train: 0.774024	val: 0.659635	test: 0.620759

Epoch: 38
Loss: 0.43034638336135994
ROC train: 0.815611	val: 0.590399	test: 0.628221
PRC train: 0.775446	val: 0.652083	test: 0.633428

Epoch: 39
Loss: 0.42351997862558904
ROC train: 0.822401	val: 0.612228	test: 0.600120
PRC train: 0.776532	val: 0.660161	test: 0.626900

Epoch: 40
Loss: 0.42399875551140553
ROC train: 0.825091	val: 0.607559	test: 0.607539
PRC train: 0.780404	val: 0.653780	test: 0.628241

Epoch: 41
Loss: 0.4148928485886706
ROC train: 0.817056	val: 0.612449	test: 0.575926
PRC train: 0.775475	val: 0.662805	test: 0.615905

Epoch: 42
Loss: 0.42188825511721806
ROC train: 0.831277	val: 0.608724	test: 0.604332
PRC train: 0.788156	val: 0.661733	test: 0.626908

Epoch: 43
Loss: 0.41293340922798477
ROC train: 0.824692	val: 0.590585	test: 0.572711
PRC train: 0.780960	val: 0.657928	test: 0.617360

Epoch: 44
Loss: 0.41119261042015254
ROC train: 0.832028	val: 0.605713	test: 0.576294
PRC train: 0.785634	val: 0.662091	test: 0.621483

Epoch: 45
Loss: 0.4106333906535628
ROC train: 0.839429	val: 0.617363	test: 0.581156
PRC train: 0.792283	val: 0.663722	test: 0.621117

Epoch: 46
Loss: 0.41067944114930865
ROC train: 0.846293	val: 0.617704	test: 0.590937
PRC train: 0.800570	val: 0.665733	test: 0.627489

Epoch: 47
Loss: 0.4113972390873955
ROC train: 0.846407	val: 0.617607	test: 0.574679
PRC train: 0.798783	val: 0.667229	test: 0.617386

Epoch: 48
Loss: 0.40856014774939764
ROC train: 0.845014	val: 0.601244	test: 0.564178
PRC train: 0.797562	val: 0.659205	test: 0.610205

Epoch: 49
Loss: 0.41211024662841106
ROC train: 0.848738	val: 0.606788	test: 0.583357
PRC train: 0.801549	val: 0.663003	test: 0.620546

Epoch: 50
Loss: 0.40895610809382266
ROC train: 0.843757	val: 0.632311	test: 0.593536
PRC train: 0.797253	val: 0.671196	test: 0.630902

Epoch: 51
Loss: 0.40247667077509036
ROC train: 0.850050	val: 0.612362	test: 0.595500
PRC train: 0.803119	val: 0.663564	test: 0.627911

Epoch: 52
Loss: 0.3990204113300607
ROC train: 0.854698	val: 0.589166	test: 0.599730
PRC train: 0.807880	val: 0.656246	test: 0.625954

Epoch: 53
Loss: 0.40279015983012345
ROC train: 0.851855	val: 0.590318	test: 0.593570
PRC train: 0.807164	val: 0.653470	test: 0.620970

Epoch: 54
Loss: 0.3973884150475704
ROC train: 0.860967	val: 0.626001	test: 0.574687
PRC train: 0.813587	val: 0.664992	test: 0.618592

Epoch: 55
Loss: 0.3988697822494052
ROC train: 0.860451	val: 0.620453	test: 0.604435
PRC train: 0.814830	val: 0.664109	test: 0.627545

Epoch: 56
Loss: 0.4019404876064823
ROC train: 0.858903	val: 0.610823	test: 0.606000
PRC train: 0.814052	val: 0.663240	test: 0.627577

Epoch: 57
Loss: 0.3952415894393504
ROC train: 0.862007	val: 0.610246	test: 0.591888
PRC train: 0.814465	val: 0.665445	test: 0.627705

Epoch: 58
Loss: 0.39505487750594653
ROC train: 0.859745	val: 0.598770	test: 0.596024
PRC train: 0.814146	val: 0.656833	test: 0.627809

Epoch: 59
Loss: 0.3924235060214333
ROC train: 0.859536	val: 0.586574	test: 0.588530
PRC train: 0.813115	val: 0.653212	test: 0.623790

Epoch: 60
Loss: 0.3864103979302266
ROC train: 0.868634	val: 0.589449	test: 0.602199
PRC train: 0.820258	val: 0.654142	test: 0.626730

Epoch: 61
Loss: 0.3888123978263628
ROC train: 0.868649	val: 0.617365	test: 0.597799
PRC train: 0.819379	val: 0.662428	test: 0.633319

Epoch: 62
Loss: 0.3857301052747243
ROC train: 0.874141	val: 0.610274	test: 0.592555
PRC train: 0.826485	val: 0.665820	test: 0.623154

Epoch: 63
Loss: 0.3850745424874917
ROC train: 0.871076	val: 0.609667	test: 0.572090
PRC train: 0.827254	val: 0.662770	test: 0.613380

Epoch: 64
Loss: 0.3859896258389107
ROC train: 0.873289	val: 0.609105	test: 0.585966
PRC train: 0.828714	val: 0.660672	test: 0.625880

Epoch: 65
Loss: 0.3818831226534864
ROC train: 0.877441	val: 0.605983	test: 0.594457
PRC train: 0.833680	val: 0.659187	test: 0.629200

Epoch: 66
Loss: 0.3830262009467428
ROC train: 0.873891	val: 0.597676	test: 0.562185
PRC train: 0.831176	val: 0.656440	test: 0.610955

Epoch: 67
Loss: 0.3842136619401935
ROC train: 0.874070	val: 0.604738	test: 0.565051
PRC train: 0.830736	val: 0.657935	test: 0.615444

Epoch: 68
Loss: 0.3774582274464176
ROC train: 0.876914	val: 0.605462	test: 0.564019
PRC train: 0.833440	val: 0.661395	test: 0.617361

Epoch: 69
Loss: 0.3786205266200462
ROC train: 0.881105	val: 0.609126	test: 0.604231
PRC train: 0.836750	val: 0.663897	test: 0.633277

Epoch: 70
Loss: 0.3704802285832837
ROC train: 0.883150	val: 0.613753	test: 0.607505
PRC train: 0.840019	val: 0.662870	test: 0.634616

Epoch: 71
Loss: 0.376127150843412
ROC train: 0.884048	val: 0.593532	test: 0.604327
PRC train: 0.840194	val: 0.656803	test: 0.630179

Epoch: 72
Loss: 0.3705311088969796
ROC train: 0.889673	val: 0.601237	test: 0.592310
PRC train: 0.844575	val: 0.660142	test: 0.627147

Epoch: 73
Loss: 0.36949565932986594
ROC train: 0.887462	val: 0.601000	test: 0.576739
PRC train: 0.842916	val: 0.660913	test: 0.623804

Epoch: 74
Loss: 0.36920727255436014
ROC train: 0.886703	val: 0.613410	test: 0.581536
PRC train: 0.844070	val: 0.668196	test: 0.626810

Epoch: 75
Loss: 0.3735250076422824
ROC train: 0.886338	val: 0.603747	test: 0.577636
PRC train: 0.843799	val: 0.665622	test: 0.622672

Epoch: 76
Loss: 0.370521787841771
ROC train: 0.889819	val: 0.591571	test: 0.619131
PRC train: 0.844795	val: 0.659301	test: 0.636484

Epoch: 77
Loss: 0.36659706998231684
ROC train: 0.891984	val: 0.611972	test: 0.608396
PRC train: 0.847329	val: 0.666607	test: 0.634099

Epoch: 78
Loss: 0.36741984636767727
ROC train: 0.895024	val: 0.608787	test: 0.569015
PRC train: 0.851821	val: 0.664219	test: 0.618365

Epoch: 79
Loss: 0.36264310398013977
ROC train: 0.891506	val: 0.601223	test: 0.573566
PRC train: 0.848954	val: 0.662556	test: 0.616963

Epoch: 80
Loss: 0.36793370571538436
ROC train: 0.895204	val: 0.603008	test: 0.579762
PRC train: 0.854703	val: 0.660268	test: 0.622141

Epoch: 81
Loss: 0.36196251677738484
ROC train: 0.898773	val: 0.612624	test: 0.589070
PRC train: 0.856881	val: 0.660237	test: 0.625483

Epoch: 82
Loss: 0.36265482060762627
ROC train: 0.896356	val: 0.601021	test: 0.577635
PRC train: 0.857409	val: 0.661726	test: 0.618343

Epoch: 83
Loss: 0.356386475209074
ROC train: 0.895952	val: 0.605936	test: 0.599082
PRC train: 0.856291	val: 0.663199	test: 0.631311

Epoch: 84
Loss: 0.3619937733024794
ROC train: 0.896621	val: 0.609268	test: 0.605722
PRC train: 0.853707	val: 0.662393	test: 0.632680

Epoch: 85
Loss: 0.3598963718532926
ROC train: 0.902440	val: 0.599403	test: 0.604726
PRC train: 0.861226	val: 0.663031	test: 0.630803

Epoch: 86
Loss: 0.35402719180607034
ROC train: 0.902688	val: 0.606869	test: 0.604232
PRC train: 0.863709	val: 0.665683	test: 0.632714

Epoch: 87
Loss: 0.3566968812478627
ROC train: 0.901193	val: 0.613968	test: 0.601589
PRC train: 0.861304	val: 0.666147	test: 0.630750

Epoch: 88
Loss: 0.3545096603605714
ROC train: 0.894965	val: 0.596697	test: 0.609168
PRC train: 0.854405	val: 0.662562	test: 0.628866

Epoch: 89
Loss: 0.34717845886986465
ROC train: 0.902511	val: 0.607932	test: 0.597410
PRC train: 0.859261	val: 0.667016	test: 0.628522

Epoch: 90
Loss: 0.3560258979951394
ROC train: 0.908829	val: 0.612183	test: 0.613276
PRC train: 0.870147	val: 0.667507	test: 0.632653

Epoch: 91
Loss: 0.3496294000543053
ROC train: 0.908438	val: 0.613539	test: 0.613011
PRC train: 0.871017	val: 0.671009	test: 0.629831

Epoch: 92
Loss: 0.3557024675312771
ROC train: 0.903982	val: 0.610591	test: 0.590422
PRC train: 0.866109	val: 0.665571	test: 0.625173

Epoch: 93
Loss: 0.3471998394551215
ROC train: 0.907097	val: 0.599368	test: 0.583881
PRC train: 0.776056	val: 0.656004	test: 0.618786

Epoch: 33
Loss: 0.4220080583542324
ROC train: 0.819932	val: 0.609152	test: 0.583644
PRC train: 0.778800	val: 0.657659	test: 0.617026

Epoch: 34
Loss: 0.42449050915752784
ROC train: 0.820455	val: 0.600349	test: 0.586912
PRC train: 0.779724	val: 0.651654	test: 0.620916

Epoch: 35
Loss: 0.42400455208153537
ROC train: 0.828054	val: 0.612771	test: 0.579022
PRC train: 0.783841	val: 0.656722	test: 0.618477

Epoch: 36
Loss: 0.4205147667266408
ROC train: 0.833140	val: 0.601859	test: 0.575304
PRC train: 0.786989	val: 0.651818	test: 0.614479

Epoch: 37
Loss: 0.42358666995368577
ROC train: 0.827677	val: 0.612119	test: 0.559133
PRC train: 0.782991	val: 0.665586	test: 0.611718

Epoch: 38
Loss: 0.4136132499345234
ROC train: 0.834722	val: 0.612870	test: 0.572391
PRC train: 0.788440	val: 0.663964	test: 0.615504

Epoch: 39
Loss: 0.41235194593403957
ROC train: 0.837561	val: 0.608972	test: 0.580935
PRC train: 0.791379	val: 0.658641	test: 0.619460

Epoch: 40
Loss: 0.4103420287994853
ROC train: 0.838260	val: 0.611376	test: 0.582340
PRC train: 0.794377	val: 0.658938	test: 0.618251

Epoch: 41
Loss: 0.4114194470341822
ROC train: 0.842410	val: 0.618222	test: 0.575490
PRC train: 0.796030	val: 0.661306	test: 0.616779

Epoch: 42
Loss: 0.40633703288407846
ROC train: 0.852882	val: 0.623170	test: 0.567280
PRC train: 0.802234	val: 0.666002	test: 0.616657

Epoch: 43
Loss: 0.40484324384813786
ROC train: 0.852349	val: 0.618182	test: 0.570014
PRC train: 0.802401	val: 0.665940	test: 0.616021

Epoch: 44
Loss: 0.4086987681604559
ROC train: 0.849350	val: 0.621729	test: 0.583752
PRC train: 0.802148	val: 0.663142	test: 0.617310

Epoch: 45
Loss: 0.3985228830876393
ROC train: 0.857229	val: 0.615316	test: 0.562458
PRC train: 0.808815	val: 0.659987	test: 0.615585

Epoch: 46
Loss: 0.39540444290880883
ROC train: 0.855140	val: 0.601349	test: 0.574161
PRC train: 0.810197	val: 0.657643	test: 0.621215

Epoch: 47
Loss: 0.3914151795719959
ROC train: 0.855483	val: 0.613361	test: 0.569870
PRC train: 0.812227	val: 0.662764	test: 0.614928

Epoch: 48
Loss: 0.39684003888890473
ROC train: 0.859783	val: 0.620874	test: 0.567833
PRC train: 0.809621	val: 0.662428	test: 0.614104

Epoch: 49
Loss: 0.3903031687699411
ROC train: 0.860968	val: 0.620374	test: 0.555971
PRC train: 0.808964	val: 0.663694	test: 0.611575

Epoch: 50
Loss: 0.38765163738022895
ROC train: 0.858571	val: 0.617022	test: 0.552149
PRC train: 0.806421	val: 0.662641	test: 0.612873

Epoch: 51
Loss: 0.3934264585660251
ROC train: 0.864349	val: 0.599660	test: 0.591648
PRC train: 0.817053	val: 0.653447	test: 0.620414

Epoch: 52
Loss: 0.3878845475812601
ROC train: 0.869495	val: 0.603879	test: 0.582974
PRC train: 0.822426	val: 0.655092	test: 0.620990

Epoch: 53
Loss: 0.3835401922356159
ROC train: 0.871325	val: 0.623006	test: 0.564466
PRC train: 0.821930	val: 0.668426	test: 0.611683

Epoch: 54
Loss: 0.3814135708556899
ROC train: 0.871908	val: 0.619556	test: 0.553226
PRC train: 0.825107	val: 0.664278	test: 0.605815

Epoch: 55
Loss: 0.38340023476689755
ROC train: 0.870890	val: 0.600605	test: 0.567180
PRC train: 0.826047	val: 0.656649	test: 0.611653

Epoch: 56
Loss: 0.3767038487066007
ROC train: 0.868141	val: 0.612563	test: 0.563891
PRC train: 0.820646	val: 0.661416	test: 0.614324

Epoch: 57
Loss: 0.37308489540389445
ROC train: 0.877636	val: 0.613455	test: 0.574183
PRC train: 0.828739	val: 0.658088	test: 0.615507

Epoch: 58
Loss: 0.37944544575420924
ROC train: 0.880231	val: 0.607814	test: 0.579894
PRC train: 0.831894	val: 0.652877	test: 0.617458

Epoch: 59
Loss: 0.3787201168217057
ROC train: 0.879510	val: 0.610481	test: 0.576615
PRC train: 0.829418	val: 0.655271	test: 0.620662

Epoch: 60
Loss: 0.3755697172458244
ROC train: 0.880843	val: 0.602398	test: 0.575864
PRC train: 0.835070	val: 0.654455	test: 0.616488

Epoch: 61
Loss: 0.3701469803353767
ROC train: 0.882698	val: 0.611711	test: 0.570003
PRC train: 0.834159	val: 0.659409	test: 0.614036

Epoch: 62
Loss: 0.37475812392786856
ROC train: 0.887859	val: 0.616294	test: 0.566504
PRC train: 0.837792	val: 0.661349	test: 0.609680

Epoch: 63
Loss: 0.36471255076508674
ROC train: 0.888115	val: 0.618902	test: 0.570168
PRC train: 0.839910	val: 0.664513	test: 0.612685

Epoch: 64
Loss: 0.36599262601733706
ROC train: 0.887934	val: 0.612297	test: 0.579531
PRC train: 0.839795	val: 0.662455	test: 0.619458

Epoch: 65
Loss: 0.3628540182417511
ROC train: 0.887087	val: 0.619284	test: 0.569366
PRC train: 0.840720	val: 0.664278	test: 0.619164

Epoch: 66
Loss: 0.3680751061354012
ROC train: 0.889618	val: 0.617217	test: 0.579902
PRC train: 0.842358	val: 0.660289	test: 0.619239

Epoch: 67
Loss: 0.3657415706352664
ROC train: 0.893531	val: 0.622669	test: 0.569112
PRC train: 0.844040	val: 0.660887	test: 0.614671

Epoch: 68
Loss: 0.3622191624251495
ROC train: 0.894278	val: 0.620253	test: 0.575932
PRC train: 0.845937	val: 0.662848	test: 0.619835

Epoch: 69
Loss: 0.367704656863432
ROC train: 0.894815	val: 0.615809	test: 0.591414
PRC train: 0.847143	val: 0.667001	test: 0.623651

Epoch: 70
Loss: 0.3606114425948342
ROC train: 0.897753	val: 0.615421	test: 0.585170
PRC train: 0.849982	val: 0.664173	test: 0.626734

Epoch: 71
Loss: 0.35375360974094305
ROC train: 0.894548	val: 0.609458	test: 0.562823
PRC train: 0.846046	val: 0.660695	test: 0.619460

Epoch: 72
Loss: 0.35346795410180587
ROC train: 0.895535	val: 0.611295	test: 0.584109
PRC train: 0.847957	val: 0.660012	test: 0.622490

Epoch: 73
Loss: 0.3507469624133145
ROC train: 0.898437	val: 0.610627	test: 0.577819
PRC train: 0.850253	val: 0.659559	test: 0.619662

Epoch: 74
Loss: 0.346625368982051
ROC train: 0.899665	val: 0.610031	test: 0.577607
PRC train: 0.855185	val: 0.660465	test: 0.619694

Epoch: 75
Loss: 0.35285108692879535
ROC train: 0.899802	val: 0.602389	test: 0.595119
PRC train: 0.855824	val: 0.654257	test: 0.622092

Epoch: 76
Loss: 0.3499658209149743
ROC train: 0.897808	val: 0.618198	test: 0.566180
PRC train: 0.850974	val: 0.660666	test: 0.614653

Epoch: 77
Loss: 0.3476217779939258
ROC train: 0.902604	val: 0.602643	test: 0.583209
PRC train: 0.855169	val: 0.657065	test: 0.619736

Epoch: 78
Loss: 0.3475557279920192
ROC train: 0.907084	val: 0.608499	test: 0.583025
PRC train: 0.861992	val: 0.656535	test: 0.620713

Epoch: 79
Loss: 0.3472183282464625
ROC train: 0.908670	val: 0.612491	test: 0.576255
PRC train: 0.862111	val: 0.660105	test: 0.618921

Epoch: 80
Loss: 0.3389423882938741
ROC train: 0.905540	val: 0.601581	test: 0.580123
PRC train: 0.860170	val: 0.660845	test: 0.621767

Epoch: 81
Loss: 0.34676172821397555
ROC train: 0.907991	val: 0.608440	test: 0.577847
PRC train: 0.864132	val: 0.660719	test: 0.620370

Epoch: 82
Loss: 0.34120337280380275
ROC train: 0.904606	val: 0.599656	test: 0.582513
PRC train: 0.861189	val: 0.651035	test: 0.621178

Epoch: 83
Loss: 0.3376598497908106
ROC train: 0.909518	val: 0.603957	test: 0.574546
PRC train: 0.865545	val: 0.653347	test: 0.622556

Epoch: 84
Loss: 0.3335685748571702
ROC train: 0.910724	val: 0.605199	test: 0.592814
PRC train: 0.867166	val: 0.655893	test: 0.625327

Epoch: 85
Loss: 0.337622799232128
ROC train: 0.911144	val: 0.611680	test: 0.583940
PRC train: 0.867553	val: 0.665621	test: 0.621185

Epoch: 86
Loss: 0.33176590858558325
ROC train: 0.908190	val: 0.603725	test: 0.586800
PRC train: 0.866973	val: 0.660229	test: 0.620813

Epoch: 87
Loss: 0.32995616700211255
ROC train: 0.914130	val: 0.613266	test: 0.564432
PRC train: 0.869354	val: 0.663872	test: 0.612893

Epoch: 88
Loss: 0.33526800279721986
ROC train: 0.915792	val: 0.610633	test: 0.580556
PRC train: 0.869511	val: 0.661578	test: 0.617082

Epoch: 89
Loss: 0.33634354496428265
ROC train: 0.918309	val: 0.608097	test: 0.573003
PRC train: 0.872907	val: 0.658691	test: 0.615580

Epoch: 90
Loss: 0.3224027080022389
ROC train: 0.918717	val: 0.614504	test: 0.564666
PRC train: 0.875836	val: 0.660166	test: 0.613555

Epoch: 91
Loss: 0.32600433423727787
ROC train: 0.915821	val: 0.611202	test: 0.570038
PRC train: 0.872695	val: 0.662953	test: 0.612902

Epoch: 92
Loss: 0.32927265000854516
ROC train: 0.915634	val: 0.599182	test: 0.576832
PRC train: 0.872393	val: 0.660509	test: 0.614474

Epoch: 93
Loss: 0.3334679347964438
ROC train: 0.920864	val: 0.610254	test: 0.569226
PRC train: 0.785562	val: 0.650439	test: 0.615116

Epoch: 33
Loss: 0.4212654732948879
ROC train: 0.832673	val: 0.583260	test: 0.557889
PRC train: 0.788565	val: 0.652872	test: 0.614404

Epoch: 34
Loss: 0.41852721049782604
ROC train: 0.832746	val: 0.586229	test: 0.557590
PRC train: 0.788353	val: 0.650934	test: 0.611696

Epoch: 35
Loss: 0.42214791957696
ROC train: 0.833469	val: 0.582814	test: 0.560081
PRC train: 0.791011	val: 0.656057	test: 0.616166

Epoch: 36
Loss: 0.4196129744026906
ROC train: 0.833996	val: 0.591743	test: 0.546549
PRC train: 0.789407	val: 0.661910	test: 0.606179

Epoch: 37
Loss: 0.41934503860699446
ROC train: 0.841741	val: 0.591792	test: 0.566465
PRC train: 0.796254	val: 0.654140	test: 0.623029

Epoch: 38
Loss: 0.4128478823936289
ROC train: 0.842667	val: 0.582507	test: 0.560018
PRC train: 0.797541	val: 0.646627	test: 0.618319

Epoch: 39
Loss: 0.40935412777035296
ROC train: 0.847292	val: 0.588705	test: 0.548078
PRC train: 0.799846	val: 0.654119	test: 0.608247

Epoch: 40
Loss: 0.4073902357583449
ROC train: 0.853542	val: 0.605008	test: 0.560970
PRC train: 0.805872	val: 0.662402	test: 0.614423

Epoch: 41
Loss: 0.40656674689737793
ROC train: 0.849689	val: 0.601464	test: 0.560723
PRC train: 0.803120	val: 0.658091	test: 0.617702

Epoch: 42
Loss: 0.4065632291569027
ROC train: 0.850844	val: 0.593951	test: 0.534852
PRC train: 0.803312	val: 0.654387	test: 0.597905

Epoch: 43
Loss: 0.4022537232241
ROC train: 0.856632	val: 0.584014	test: 0.545481
PRC train: 0.808135	val: 0.653261	test: 0.607811

Epoch: 44
Loss: 0.40035262117903353
ROC train: 0.861292	val: 0.585437	test: 0.549336
PRC train: 0.813445	val: 0.653565	test: 0.608461

Epoch: 45
Loss: 0.3944351883615059
ROC train: 0.864881	val: 0.613464	test: 0.550520
PRC train: 0.814801	val: 0.664095	test: 0.603731

Epoch: 46
Loss: 0.3937085792082339
ROC train: 0.866465	val: 0.610649	test: 0.560354
PRC train: 0.819454	val: 0.664289	test: 0.608980

Epoch: 47
Loss: 0.39629740991482215
ROC train: 0.868677	val: 0.606208	test: 0.547577
PRC train: 0.822235	val: 0.661706	test: 0.602886

Epoch: 48
Loss: 0.3896004510893952
ROC train: 0.868752	val: 0.601381	test: 0.544911
PRC train: 0.821665	val: 0.661829	test: 0.607648

Epoch: 49
Loss: 0.3900298221851044
ROC train: 0.868591	val: 0.617840	test: 0.556434
PRC train: 0.821797	val: 0.668918	test: 0.612485

Epoch: 50
Loss: 0.3885510426692193
ROC train: 0.871864	val: 0.618642	test: 0.554052
PRC train: 0.823854	val: 0.671598	test: 0.609946

Epoch: 51
Loss: 0.3870472722074692
ROC train: 0.875033	val: 0.615467	test: 0.550046
PRC train: 0.827193	val: 0.672532	test: 0.603999

Epoch: 52
Loss: 0.38213144608006394
ROC train: 0.871756	val: 0.607080	test: 0.559784
PRC train: 0.826415	val: 0.665895	test: 0.608177

Epoch: 53
Loss: 0.38356768850351786
ROC train: 0.874261	val: 0.609954	test: 0.553184
PRC train: 0.828507	val: 0.666466	test: 0.609083

Epoch: 54
Loss: 0.37955324630814535
ROC train: 0.877375	val: 0.607648	test: 0.552689
PRC train: 0.831577	val: 0.662796	test: 0.606361

Epoch: 55
Loss: 0.37828794677600674
ROC train: 0.878086	val: 0.612451	test: 0.553082
PRC train: 0.831442	val: 0.666490	test: 0.605403

Epoch: 56
Loss: 0.37772786260772795
ROC train: 0.880793	val: 0.612580	test: 0.546337
PRC train: 0.834138	val: 0.668068	test: 0.602627

Epoch: 57
Loss: 0.37724799995416836
ROC train: 0.884768	val: 0.619403	test: 0.561034
PRC train: 0.837657	val: 0.667573	test: 0.606469

Epoch: 58
Loss: 0.3749417877207243
ROC train: 0.879508	val: 0.610125	test: 0.566915
PRC train: 0.833784	val: 0.661421	test: 0.617704

Epoch: 59
Loss: 0.37475961711697653
ROC train: 0.884193	val: 0.596841	test: 0.548879
PRC train: 0.837278	val: 0.657011	test: 0.602849

Epoch: 60
Loss: 0.37012896714352655
ROC train: 0.886110	val: 0.600489	test: 0.548070
PRC train: 0.840097	val: 0.663642	test: 0.605046

Epoch: 61
Loss: 0.3730449847811629
ROC train: 0.885293	val: 0.612993	test: 0.560426
PRC train: 0.838745	val: 0.668668	test: 0.610738

Epoch: 62
Loss: 0.3701493509852972
ROC train: 0.889260	val: 0.596519	test: 0.564439
PRC train: 0.843577	val: 0.664834	test: 0.607793

Epoch: 63
Loss: 0.36364701092327073
ROC train: 0.889791	val: 0.595277	test: 0.553048
PRC train: 0.843251	val: 0.661240	test: 0.604171

Epoch: 64
Loss: 0.36605902783837985
ROC train: 0.891856	val: 0.616045	test: 0.554610
PRC train: 0.844893	val: 0.670405	test: 0.606774

Epoch: 65
Loss: 0.3683231012476619
ROC train: 0.889428	val: 0.618395	test: 0.555224
PRC train: 0.842194	val: 0.665944	test: 0.609975

Epoch: 66
Loss: 0.36677134505608977
ROC train: 0.892594	val: 0.619404	test: 0.558850
PRC train: 0.846627	val: 0.665587	test: 0.609174

Epoch: 67
Loss: 0.36258021125929046
ROC train: 0.896987	val: 0.609844	test: 0.552101
PRC train: 0.850930	val: 0.659945	test: 0.602652

Epoch: 68
Loss: 0.3631531596430637
ROC train: 0.896736	val: 0.607113	test: 0.555947
PRC train: 0.851690	val: 0.661430	test: 0.607529

Epoch: 69
Loss: 0.3616390124886543
ROC train: 0.896243	val: 0.623483	test: 0.564181
PRC train: 0.849372	val: 0.670953	test: 0.614631

Epoch: 70
Loss: 0.3546316524915384
ROC train: 0.891312	val: 0.622179	test: 0.555563
PRC train: 0.845085	val: 0.669731	test: 0.606353

Epoch: 71
Loss: 0.3594374811569179
ROC train: 0.895951	val: 0.617615	test: 0.570665
PRC train: 0.851572	val: 0.670548	test: 0.613425

Epoch: 72
Loss: 0.3533616561483733
ROC train: 0.900021	val: 0.627876	test: 0.560191
PRC train: 0.855638	val: 0.668484	test: 0.606221

Epoch: 73
Loss: 0.35599128119699336
ROC train: 0.902174	val: 0.616916	test: 0.563628
PRC train: 0.856646	val: 0.661412	test: 0.608950

Epoch: 74
Loss: 0.3533790203193704
ROC train: 0.900668	val: 0.599197	test: 0.565045
PRC train: 0.856208	val: 0.656610	test: 0.608300

Epoch: 75
Loss: 0.3514358014532246
ROC train: 0.903670	val: 0.614077	test: 0.568078
PRC train: 0.858308	val: 0.665802	test: 0.611853

Epoch: 76
Loss: 0.34608756814167024
ROC train: 0.901736	val: 0.617104	test: 0.574723
PRC train: 0.855288	val: 0.668230	test: 0.619331

Epoch: 77
Loss: 0.34456886313754653
ROC train: 0.904316	val: 0.616760	test: 0.567144
PRC train: 0.857893	val: 0.665194	test: 0.611784

Epoch: 78
Loss: 0.3484362774349888
ROC train: 0.906800	val: 0.629029	test: 0.563847
PRC train: 0.860509	val: 0.668096	test: 0.611159

Epoch: 79
Loss: 0.34804465081030217
ROC train: 0.907251	val: 0.628238	test: 0.574630
PRC train: 0.860667	val: 0.667661	test: 0.621375

Epoch: 80
Loss: 0.34634342954719377
ROC train: 0.908963	val: 0.618629	test: 0.569544
PRC train: 0.867162	val: 0.668152	test: 0.612069

Epoch: 81
Loss: 0.3403595530368406
ROC train: 0.908393	val: 0.622516	test: 0.555662
PRC train: 0.867869	val: 0.667811	test: 0.600452

Epoch: 82
Loss: 0.34529622075215916
ROC train: 0.909119	val: 0.622519	test: 0.563841
PRC train: 0.866263	val: 0.670757	test: 0.609016

Epoch: 83
Loss: 0.33776255900476315
ROC train: 0.911977	val: 0.632119	test: 0.572144
PRC train: 0.870152	val: 0.672045	test: 0.612513

Epoch: 84
Loss: 0.3386609736476375
ROC train: 0.912425	val: 0.621837	test: 0.570529
PRC train: 0.870269	val: 0.663788	test: 0.607978

Epoch: 85
Loss: 0.3437754650018727
ROC train: 0.910702	val: 0.606428	test: 0.581733
PRC train: 0.869493	val: 0.657975	test: 0.615539

Epoch: 86
Loss: 0.34097961607846106
ROC train: 0.915464	val: 0.615548	test: 0.562149
PRC train: 0.872209	val: 0.659747	test: 0.604377

Epoch: 87
Loss: 0.33690502479185613
ROC train: 0.915937	val: 0.611922	test: 0.548629
PRC train: 0.872736	val: 0.663391	test: 0.600983

Epoch: 88
Loss: 0.3408486887322743
ROC train: 0.915983	val: 0.610820	test: 0.554738
PRC train: 0.874714	val: 0.668342	test: 0.603130

Epoch: 89
Loss: 0.33043722475555226
ROC train: 0.917360	val: 0.602950	test: 0.562773
PRC train: 0.876875	val: 0.653578	test: 0.600937

Epoch: 90
Loss: 0.338027540660474
ROC train: 0.919268	val: 0.607900	test: 0.572456
PRC train: 0.879452	val: 0.658211	test: 0.607166

Epoch: 91
Loss: 0.3263610709142726
ROC train: 0.919342	val: 0.608326	test: 0.560408
PRC train: 0.882064	val: 0.662790	test: 0.602399

Epoch: 92
Loss: 0.33024274392131125
ROC train: 0.918815	val: 0.608420	test: 0.558104
PRC train: 0.878393	val: 0.661389	test: 0.603302

Epoch: 93
Loss: 0.3267388143083203
ROC train: 0.921229	val: 0.600412	test: 0.558639
PRC train: 0.776707	val: 0.641358	test: 0.617237

Epoch: 33
Loss: 0.42456825133125076
ROC train: 0.826103	val: 0.577093	test: 0.600000
PRC train: 0.777268	val: 0.638864	test: 0.624211

Epoch: 34
Loss: 0.4233401932654212
ROC train: 0.831226	val: 0.582446	test: 0.608830
PRC train: 0.782431	val: 0.643132	test: 0.629244

Epoch: 35
Loss: 0.4191724974938344
ROC train: 0.835922	val: 0.566600	test: 0.596601
PRC train: 0.786763	val: 0.635928	test: 0.617897

Epoch: 36
Loss: 0.41638389414940935
ROC train: 0.838927	val: 0.571310	test: 0.593335
PRC train: 0.791292	val: 0.635916	test: 0.619887

Epoch: 37
Loss: 0.4085356929572769
ROC train: 0.842751	val: 0.578933	test: 0.584698
PRC train: 0.798242	val: 0.638628	test: 0.617741

Epoch: 38
Loss: 0.41124039254680483
ROC train: 0.844578	val: 0.575668	test: 0.600395
PRC train: 0.799973	val: 0.637603	test: 0.623849

Epoch: 39
Loss: 0.4110839396811891
ROC train: 0.842512	val: 0.562242	test: 0.607803
PRC train: 0.799447	val: 0.631256	test: 0.619782

Epoch: 40
Loss: 0.40510267471224903
ROC train: 0.850054	val: 0.561014	test: 0.599521
PRC train: 0.806388	val: 0.630146	test: 0.618700

Epoch: 41
Loss: 0.4080172306433383
ROC train: 0.845680	val: 0.573746	test: 0.584837
PRC train: 0.803056	val: 0.639301	test: 0.614851

Epoch: 42
Loss: 0.40767507976436484
ROC train: 0.854069	val: 0.561529	test: 0.589595
PRC train: 0.810594	val: 0.631075	test: 0.619900

Epoch: 43
Loss: 0.3943309823691429
ROC train: 0.851512	val: 0.568233	test: 0.603097
PRC train: 0.806915	val: 0.638866	test: 0.628333

Epoch: 44
Loss: 0.3996222771520984
ROC train: 0.856929	val: 0.575048	test: 0.603347
PRC train: 0.813444	val: 0.641216	test: 0.625503

Epoch: 45
Loss: 0.40067788008537253
ROC train: 0.860036	val: 0.560677	test: 0.597297
PRC train: 0.815138	val: 0.631057	test: 0.622991

Epoch: 46
Loss: 0.39953391059693966
ROC train: 0.843504	val: 0.561255	test: 0.590777
PRC train: 0.798468	val: 0.637234	test: 0.616970

Epoch: 47
Loss: 0.38937561059758463
ROC train: 0.859414	val: 0.547230	test: 0.594294
PRC train: 0.815316	val: 0.624630	test: 0.622262

Epoch: 48
Loss: 0.38774883987492603
ROC train: 0.861342	val: 0.570694	test: 0.599267
PRC train: 0.815988	val: 0.637373	test: 0.624188

Epoch: 49
Loss: 0.39002254429087996
ROC train: 0.868637	val: 0.566364	test: 0.601506
PRC train: 0.825788	val: 0.631458	test: 0.624930

Epoch: 50
Loss: 0.3866969433660671
ROC train: 0.871903	val: 0.576071	test: 0.599035
PRC train: 0.828874	val: 0.636186	test: 0.623900

Epoch: 51
Loss: 0.3813746988481591
ROC train: 0.873130	val: 0.570975	test: 0.586845
PRC train: 0.829910	val: 0.631287	test: 0.619225

Epoch: 52
Loss: 0.38393761107458657
ROC train: 0.873986	val: 0.565841	test: 0.585007
PRC train: 0.830310	val: 0.631442	test: 0.618455

Epoch: 53
Loss: 0.38741666085785814
ROC train: 0.875329	val: 0.572067	test: 0.597021
PRC train: 0.832055	val: 0.637253	test: 0.623048

Epoch: 54
Loss: 0.37749772084660493
ROC train: 0.878104	val: 0.557252	test: 0.601979
PRC train: 0.836142	val: 0.629568	test: 0.625475

Epoch: 55
Loss: 0.3837224778529801
ROC train: 0.878042	val: 0.566560	test: 0.586660
PRC train: 0.835265	val: 0.636773	test: 0.613106

Epoch: 56
Loss: 0.3783145865232681
ROC train: 0.879479	val: 0.563272	test: 0.588233
PRC train: 0.838379	val: 0.627634	test: 0.619851

Epoch: 57
Loss: 0.37960190706778035
ROC train: 0.883026	val: 0.575952	test: 0.585607
PRC train: 0.842148	val: 0.639044	test: 0.622421

Epoch: 58
Loss: 0.37226450554550977
ROC train: 0.884626	val: 0.577712	test: 0.589122
PRC train: 0.840555	val: 0.643167	test: 0.619235

Epoch: 59
Loss: 0.37186648086488405
ROC train: 0.883551	val: 0.569327	test: 0.599178
PRC train: 0.842635	val: 0.637220	test: 0.621762

Epoch: 60
Loss: 0.37436530748496905
ROC train: 0.880007	val: 0.576909	test: 0.607865
PRC train: 0.838365	val: 0.643985	test: 0.628659

Epoch: 61
Loss: 0.3681067778873231
ROC train: 0.880220	val: 0.584461	test: 0.591178
PRC train: 0.835632	val: 0.649249	test: 0.625647

Epoch: 62
Loss: 0.3708903694643847
ROC train: 0.888619	val: 0.574179	test: 0.591272
PRC train: 0.845809	val: 0.640819	test: 0.623255

Epoch: 63
Loss: 0.368807721529204
ROC train: 0.887432	val: 0.575349	test: 0.596243
PRC train: 0.845643	val: 0.641625	test: 0.623730

Epoch: 64
Loss: 0.3636140524513484
ROC train: 0.891200	val: 0.574043	test: 0.580755
PRC train: 0.849593	val: 0.639687	test: 0.617288

Epoch: 65
Loss: 0.3607680250574921
ROC train: 0.889845	val: 0.553228	test: 0.595279
PRC train: 0.845073	val: 0.626932	test: 0.627589

Epoch: 66
Loss: 0.36196291411934756
ROC train: 0.896679	val: 0.556214	test: 0.597171
PRC train: 0.855921	val: 0.630961	test: 0.624426

Epoch: 67
Loss: 0.3557869590341344
ROC train: 0.897324	val: 0.552912	test: 0.591552
PRC train: 0.857741	val: 0.632202	test: 0.621809

Epoch: 68
Loss: 0.35550977597126543
ROC train: 0.894543	val: 0.548091	test: 0.577169
PRC train: 0.855170	val: 0.633810	test: 0.613717

Epoch: 69
Loss: 0.3533500732084486
ROC train: 0.900447	val: 0.560003	test: 0.582521
PRC train: 0.860522	val: 0.634133	test: 0.622440

Epoch: 70
Loss: 0.3556704593848275
ROC train: 0.901284	val: 0.557110	test: 0.591069
PRC train: 0.861387	val: 0.631171	test: 0.626318

Epoch: 71
Loss: 0.35534169831430706
ROC train: 0.903625	val: 0.556267	test: 0.590664
PRC train: 0.862645	val: 0.632020	test: 0.622356

Epoch: 72
Loss: 0.3515003625507342
ROC train: 0.902223	val: 0.554076	test: 0.591738
PRC train: 0.864429	val: 0.631976	test: 0.619002

Epoch: 73
Loss: 0.35436945047751245
ROC train: 0.902813	val: 0.555835	test: 0.591579
PRC train: 0.866444	val: 0.631698	test: 0.621205

Epoch: 74
Loss: 0.3449193764943536
ROC train: 0.904257	val: 0.554705	test: 0.592444
PRC train: 0.865374	val: 0.627484	test: 0.624227

Epoch: 75
Loss: 0.35311241752108946
ROC train: 0.902604	val: 0.566280	test: 0.604142
PRC train: 0.864885	val: 0.636698	test: 0.625424

Epoch: 76
Loss: 0.3509708841014808
ROC train: 0.906826	val: 0.554456	test: 0.599612
PRC train: 0.866380	val: 0.631431	test: 0.625091

Epoch: 77
Loss: 0.3471657730209555
ROC train: 0.906744	val: 0.562231	test: 0.584753
PRC train: 0.868406	val: 0.641595	test: 0.621695

Epoch: 78
Loss: 0.3479643446236013
ROC train: 0.906055	val: 0.560815	test: 0.598215
PRC train: 0.866236	val: 0.639194	test: 0.625245

Epoch: 79
Loss: 0.34334925203974836
ROC train: 0.907079	val: 0.548080	test: 0.604457
PRC train: 0.872137	val: 0.629227	test: 0.625644

Epoch: 80
Loss: 0.3457503781905467
ROC train: 0.909384	val: 0.570100	test: 0.594595
PRC train: 0.873404	val: 0.643138	test: 0.623200

Epoch: 81
Loss: 0.3420292249448821
ROC train: 0.907602	val: 0.562443	test: 0.583109
PRC train: 0.867489	val: 0.636765	test: 0.620306

Epoch: 82
Loss: 0.33913635607826825
ROC train: 0.912768	val: 0.560480	test: 0.581485
PRC train: 0.869719	val: 0.636679	test: 0.622227

Epoch: 83
Loss: 0.3361605971148456
ROC train: 0.913870	val: 0.556989	test: 0.599985
PRC train: 0.875253	val: 0.631139	test: 0.625218

Epoch: 84
Loss: 0.3346768465759413
ROC train: 0.913222	val: 0.562793	test: 0.605870
PRC train: 0.875621	val: 0.633480	test: 0.628635

Epoch: 85
Loss: 0.33642511209280046
ROC train: 0.918532	val: 0.556579	test: 0.591238
PRC train: 0.881881	val: 0.634135	test: 0.624494

Epoch: 86
Loss: 0.3319556706109267
ROC train: 0.917221	val: 0.560852	test: 0.586269
PRC train: 0.878782	val: 0.639302	test: 0.625127

Epoch: 87
Loss: 0.33637071461648704
ROC train: 0.916901	val: 0.562058	test: 0.597681
PRC train: 0.880192	val: 0.637382	test: 0.628663

Epoch: 88
Loss: 0.3314611726173554
ROC train: 0.918347	val: 0.554361	test: 0.597185
PRC train: 0.883721	val: 0.631179	test: 0.626370

Epoch: 89
Loss: 0.3291413368068291
ROC train: 0.919606	val: 0.570862	test: 0.588082
PRC train: 0.886713	val: 0.639850	test: 0.625411

Epoch: 90
Loss: 0.33580411931208076
ROC train: 0.922635	val: 0.562885	test: 0.592729
PRC train: 0.888698	val: 0.633112	test: 0.627967

Epoch: 91
Loss: 0.3266663909431225
ROC train: 0.923022	val: 0.566824	test: 0.591560
PRC train: 0.887860	val: 0.639970	test: 0.626989

Epoch: 92
Loss: 0.3256807679934183
ROC train: 0.923470	val: 0.569163	test: 0.595621
PRC train: 0.888278	val: 0.644302	test: 0.628015

Epoch: 93
Loss: 0.3239985399598758
ROC train: 0.922037	val: 0.555340	test: 0.596146
PRC train: 0.779094	val: 0.668539	test: 0.624796

Epoch: 33
Loss: 0.42556686759302326
ROC train: 0.818078	val: 0.616346	test: 0.587754
PRC train: 0.779916	val: 0.672092	test: 0.626060

Epoch: 34
Loss: 0.4309628548916452
ROC train: 0.817232	val: 0.611391	test: 0.595154
PRC train: 0.776539	val: 0.667806	test: 0.629390

Epoch: 35
Loss: 0.42079755121471607
ROC train: 0.828281	val: 0.611684	test: 0.585198
PRC train: 0.787639	val: 0.669984	test: 0.623533

Epoch: 36
Loss: 0.418670559399667
ROC train: 0.832954	val: 0.610870	test: 0.592003
PRC train: 0.792402	val: 0.668946	test: 0.623778

Epoch: 37
Loss: 0.4107800877107935
ROC train: 0.836207	val: 0.618814	test: 0.601637
PRC train: 0.793624	val: 0.669955	test: 0.628092

Epoch: 38
Loss: 0.413898404094149
ROC train: 0.839232	val: 0.614371	test: 0.604375
PRC train: 0.796333	val: 0.669283	test: 0.631237

Epoch: 39
Loss: 0.4147619296410426
ROC train: 0.842128	val: 0.605424	test: 0.595859
PRC train: 0.801549	val: 0.667495	test: 0.625078

Epoch: 40
Loss: 0.4093046074249016
ROC train: 0.844136	val: 0.610960	test: 0.599453
PRC train: 0.802423	val: 0.672112	test: 0.625493

Epoch: 41
Loss: 0.4046294289109511
ROC train: 0.847258	val: 0.608716	test: 0.596872
PRC train: 0.804637	val: 0.672570	test: 0.623925

Epoch: 42
Loss: 0.4066240326167052
ROC train: 0.845910	val: 0.605051	test: 0.580411
PRC train: 0.801037	val: 0.671016	test: 0.623197

Epoch: 43
Loss: 0.39990277915773265
ROC train: 0.852355	val: 0.610992	test: 0.596611
PRC train: 0.807585	val: 0.668159	test: 0.632695

Epoch: 44
Loss: 0.4035541119337817
ROC train: 0.853430	val: 0.624323	test: 0.595383
PRC train: 0.810528	val: 0.670662	test: 0.632330

Epoch: 45
Loss: 0.4001648929230135
ROC train: 0.855688	val: 0.626204	test: 0.596872
PRC train: 0.811483	val: 0.669028	test: 0.629998

Epoch: 46
Loss: 0.39517873119764685
ROC train: 0.854274	val: 0.622357	test: 0.617079
PRC train: 0.806854	val: 0.666842	test: 0.632701

Epoch: 47
Loss: 0.3922014193259431
ROC train: 0.861700	val: 0.626780	test: 0.608000
PRC train: 0.816726	val: 0.674378	test: 0.631887

Epoch: 48
Loss: 0.3896471671305863
ROC train: 0.862839	val: 0.618361	test: 0.592326
PRC train: 0.816417	val: 0.670907	test: 0.626445

Epoch: 49
Loss: 0.3896495301855115
ROC train: 0.863905	val: 0.614888	test: 0.587425
PRC train: 0.816614	val: 0.669265	test: 0.627925

Epoch: 50
Loss: 0.3834906757655422
ROC train: 0.867478	val: 0.619887	test: 0.601817
PRC train: 0.821154	val: 0.672223	test: 0.628150

Epoch: 51
Loss: 0.3847155978857405
ROC train: 0.866071	val: 0.618451	test: 0.575604
PRC train: 0.818469	val: 0.671626	test: 0.618307

Epoch: 52
Loss: 0.3875532477218503
ROC train: 0.870436	val: 0.613303	test: 0.583726
PRC train: 0.821398	val: 0.671542	test: 0.626349

Epoch: 53
Loss: 0.3872535054255421
ROC train: 0.873495	val: 0.624239	test: 0.607067
PRC train: 0.830297	val: 0.663774	test: 0.632478

Epoch: 54
Loss: 0.3787640664585907
ROC train: 0.874485	val: 0.635785	test: 0.590489
PRC train: 0.830401	val: 0.672514	test: 0.624615

Epoch: 55
Loss: 0.384784112324919
ROC train: 0.877450	val: 0.633303	test: 0.594096
PRC train: 0.833900	val: 0.675138	test: 0.624340

Epoch: 56
Loss: 0.3786874159889044
ROC train: 0.876299	val: 0.626791	test: 0.590854
PRC train: 0.832194	val: 0.673868	test: 0.626793

Epoch: 57
Loss: 0.381701516079212
ROC train: 0.873424	val: 0.611834	test: 0.574887
PRC train: 0.826390	val: 0.663032	test: 0.621370

Epoch: 58
Loss: 0.37887297182698404
ROC train: 0.873696	val: 0.619658	test: 0.594296
PRC train: 0.825077	val: 0.668677	test: 0.623178

Epoch: 59
Loss: 0.3738239028934866
ROC train: 0.881778	val: 0.621893	test: 0.606701
PRC train: 0.835778	val: 0.672198	test: 0.624702

Epoch: 60
Loss: 0.37579308855215465
ROC train: 0.883107	val: 0.625334	test: 0.589149
PRC train: 0.837264	val: 0.673745	test: 0.621954

Epoch: 61
Loss: 0.37246496069619783
ROC train: 0.881651	val: 0.624692	test: 0.587474
PRC train: 0.836764	val: 0.672591	test: 0.619376

Epoch: 62
Loss: 0.36755215714050954
ROC train: 0.885230	val: 0.620850	test: 0.571573
PRC train: 0.840914	val: 0.672191	test: 0.612485

Epoch: 63
Loss: 0.3677083998625633
ROC train: 0.886494	val: 0.620873	test: 0.584172
PRC train: 0.841085	val: 0.672496	test: 0.620401

Epoch: 64
Loss: 0.37080788042443197
ROC train: 0.884276	val: 0.616958	test: 0.573791
PRC train: 0.838805	val: 0.668084	test: 0.621355

Epoch: 65
Loss: 0.3640042143444841
ROC train: 0.887296	val: 0.625202	test: 0.583919
PRC train: 0.842114	val: 0.667360	test: 0.621748

Epoch: 66
Loss: 0.3630298562293778
ROC train: 0.890680	val: 0.627148	test: 0.580100
PRC train: 0.846829	val: 0.676682	test: 0.621035

Epoch: 67
Loss: 0.3591808587509098
ROC train: 0.891225	val: 0.619931	test: 0.579296
PRC train: 0.843913	val: 0.672308	test: 0.619679

Epoch: 68
Loss: 0.3568973783950776
ROC train: 0.891003	val: 0.631607	test: 0.586488
PRC train: 0.845939	val: 0.678443	test: 0.623965

Epoch: 69
Loss: 0.35562381887421635
ROC train: 0.892055	val: 0.622838	test: 0.595954
PRC train: 0.850703	val: 0.672251	test: 0.627560

Epoch: 70
Loss: 0.35756126337210276
ROC train: 0.896283	val: 0.622024	test: 0.583971
PRC train: 0.850599	val: 0.674223	test: 0.620073

Epoch: 71
Loss: 0.3554504023580232
ROC train: 0.893251	val: 0.621917	test: 0.583652
PRC train: 0.849164	val: 0.668900	test: 0.612225

Epoch: 72
Loss: 0.35392761008249324
ROC train: 0.890384	val: 0.616728	test: 0.593426
PRC train: 0.849957	val: 0.660190	test: 0.621507

Epoch: 73
Loss: 0.35200932775226934
ROC train: 0.897478	val: 0.619723	test: 0.574208
PRC train: 0.856550	val: 0.667280	test: 0.618121

Epoch: 74
Loss: 0.3526976444486799
ROC train: 0.900375	val: 0.621515	test: 0.584331
PRC train: 0.858211	val: 0.669431	test: 0.622035

Epoch: 75
Loss: 0.3522728566767926
ROC train: 0.900730	val: 0.621092	test: 0.580407
PRC train: 0.857214	val: 0.675806	test: 0.618179

Epoch: 76
Loss: 0.34920525259081814
ROC train: 0.903097	val: 0.621638	test: 0.574560
PRC train: 0.859360	val: 0.676112	test: 0.620453

Epoch: 77
Loss: 0.3457647718445285
ROC train: 0.901179	val: 0.625960	test: 0.564567
PRC train: 0.857447	val: 0.674813	test: 0.619324

Epoch: 78
Loss: 0.34996601028541124
ROC train: 0.904729	val: 0.621464	test: 0.572527
PRC train: 0.862163	val: 0.673976	test: 0.619050

Epoch: 79
Loss: 0.3397764541357735
ROC train: 0.905489	val: 0.624356	test: 0.577236
PRC train: 0.864600	val: 0.673148	test: 0.621469

Epoch: 80
Loss: 0.34606888771134253
ROC train: 0.907233	val: 0.629227	test: 0.585015
PRC train: 0.865428	val: 0.674420	test: 0.625574

Epoch: 81
Loss: 0.34123900997272455
ROC train: 0.905523	val: 0.616186	test: 0.592780
PRC train: 0.862572	val: 0.669013	test: 0.622954

Epoch: 82
Loss: 0.3464690937316969
ROC train: 0.907078	val: 0.616694	test: 0.577179
PRC train: 0.863408	val: 0.671190	test: 0.618663

Epoch: 83
Loss: 0.338882693228699
ROC train: 0.907816	val: 0.618972	test: 0.570348
PRC train: 0.865014	val: 0.666658	test: 0.622147

Epoch: 84
Loss: 0.338104724910511
ROC train: 0.911447	val: 0.629112	test: 0.568572
PRC train: 0.872236	val: 0.669091	test: 0.622088

Epoch: 85
Loss: 0.3402456732428451
ROC train: 0.909679	val: 0.608941	test: 0.577234
PRC train: 0.869454	val: 0.660974	test: 0.618720

Epoch: 86
Loss: 0.3347532281744117
ROC train: 0.909531	val: 0.610915	test: 0.575690
PRC train: 0.866965	val: 0.667747	test: 0.615150

Epoch: 87
Loss: 0.34129994211836345
ROC train: 0.914873	val: 0.625025	test: 0.579927
PRC train: 0.872080	val: 0.672629	test: 0.622839

Epoch: 88
Loss: 0.3314810149762438
ROC train: 0.913573	val: 0.629216	test: 0.579096
PRC train: 0.869171	val: 0.676049	test: 0.621316

Epoch: 89
Loss: 0.32792451071303585
ROC train: 0.916993	val: 0.628298	test: 0.572973
PRC train: 0.875249	val: 0.675146	test: 0.618033

Epoch: 90
Loss: 0.3348847591068038
ROC train: 0.918348	val: 0.629459	test: 0.571457
PRC train: 0.875524	val: 0.673323	test: 0.617283

Epoch: 91
Loss: 0.3256895037975611
ROC train: 0.919266	val: 0.626066	test: 0.560204
PRC train: 0.878562	val: 0.673478	test: 0.612768

Epoch: 92
Loss: 0.33157939606325915
ROC train: 0.920099	val: 0.621552	test: 0.573252
PRC train: 0.881977	val: 0.675742	test: 0.620333

Epoch: 93
Loss: 0.3294588898924754
ROC train: 0.919149	val: 0.621954	test: 0.587206
PRC train: 0.881627	val: 0.674107	test: 0.626469
PRC train: 0.771404	val: 0.643412	test: 0.629970

Epoch: 33
Loss: 0.4314686963962835
ROC train: 0.819374	val: 0.597737	test: 0.567188
PRC train: 0.778271	val: 0.648866	test: 0.621095

Epoch: 34
Loss: 0.43085454543566293
ROC train: 0.819106	val: 0.598986	test: 0.549844
PRC train: 0.776720	val: 0.643995	test: 0.613875

Epoch: 35
Loss: 0.42773079630972505
ROC train: 0.816659	val: 0.584643	test: 0.569397
PRC train: 0.774190	val: 0.638823	test: 0.619050

Epoch: 36
Loss: 0.4235858775628879
ROC train: 0.819471	val: 0.602802	test: 0.566257
PRC train: 0.776835	val: 0.647807	test: 0.619773

Epoch: 37
Loss: 0.4186568701777575
ROC train: 0.828100	val: 0.592683	test: 0.576393
PRC train: 0.783264	val: 0.641935	test: 0.621403

Epoch: 38
Loss: 0.41971006962924706
ROC train: 0.830566	val: 0.594161	test: 0.577043
PRC train: 0.786018	val: 0.647158	test: 0.620321

Epoch: 39
Loss: 0.41264585342069743
ROC train: 0.831953	val: 0.596417	test: 0.567626
PRC train: 0.787869	val: 0.645433	test: 0.615653

Epoch: 40
Loss: 0.4190151476569233
ROC train: 0.838102	val: 0.595755	test: 0.556775
PRC train: 0.792867	val: 0.645467	test: 0.611220

Epoch: 41
Loss: 0.407235855154153
ROC train: 0.838935	val: 0.604088	test: 0.554839
PRC train: 0.794411	val: 0.649707	test: 0.611289

Epoch: 42
Loss: 0.4178202292374148
ROC train: 0.840562	val: 0.599944	test: 0.567544
PRC train: 0.797757	val: 0.646380	test: 0.618011

Epoch: 43
Loss: 0.40615187603261954
ROC train: 0.841191	val: 0.596465	test: 0.562321
PRC train: 0.797960	val: 0.645343	test: 0.616610

Epoch: 44
Loss: 0.40254502811134324
ROC train: 0.845762	val: 0.583065	test: 0.574158
PRC train: 0.800122	val: 0.642499	test: 0.622022

Epoch: 45
Loss: 0.40659687137404454
ROC train: 0.849581	val: 0.599998	test: 0.572667
PRC train: 0.805620	val: 0.647427	test: 0.622075

Epoch: 46
Loss: 0.4061271099745916
ROC train: 0.851906	val: 0.589777	test: 0.583983
PRC train: 0.809030	val: 0.641630	test: 0.626765

Epoch: 47
Loss: 0.4046017668789392
ROC train: 0.852643	val: 0.578490	test: 0.571759
PRC train: 0.809263	val: 0.632210	test: 0.618301

Epoch: 48
Loss: 0.4001103969148157
ROC train: 0.852442	val: 0.573290	test: 0.559418
PRC train: 0.809722	val: 0.629982	test: 0.609948

Epoch: 49
Loss: 0.3958064565201825
ROC train: 0.854295	val: 0.591031	test: 0.567273
PRC train: 0.811474	val: 0.640337	test: 0.617890

Epoch: 50
Loss: 0.3970851869927337
ROC train: 0.862189	val: 0.591447	test: 0.581257
PRC train: 0.816465	val: 0.640824	test: 0.625018

Epoch: 51
Loss: 0.3935742906771229
ROC train: 0.862191	val: 0.588390	test: 0.550305
PRC train: 0.813244	val: 0.644720	test: 0.613934

Epoch: 52
Loss: 0.39134890780338416
ROC train: 0.868443	val: 0.577855	test: 0.570986
PRC train: 0.821544	val: 0.634291	test: 0.617696

Epoch: 53
Loss: 0.39288253067372664
ROC train: 0.867657	val: 0.589553	test: 0.575144
PRC train: 0.821489	val: 0.639333	test: 0.616744

Epoch: 54
Loss: 0.3962109806887596
ROC train: 0.869385	val: 0.600150	test: 0.577521
PRC train: 0.823126	val: 0.646240	test: 0.619983

Epoch: 55
Loss: 0.3880549747577897
ROC train: 0.872308	val: 0.599953	test: 0.599438
PRC train: 0.828436	val: 0.646400	test: 0.631729

Epoch: 56
Loss: 0.389052442131202
ROC train: 0.874452	val: 0.607968	test: 0.589366
PRC train: 0.828326	val: 0.648990	test: 0.630317

Epoch: 57
Loss: 0.3836586023745741
ROC train: 0.873151	val: 0.600122	test: 0.602072
PRC train: 0.827038	val: 0.645781	test: 0.637983

Epoch: 58
Loss: 0.37900119233896856
ROC train: 0.874315	val: 0.592015	test: 0.577804
PRC train: 0.828837	val: 0.638693	test: 0.627044

Epoch: 59
Loss: 0.3806535332089162
ROC train: 0.878292	val: 0.590547	test: 0.574448
PRC train: 0.831872	val: 0.639903	test: 0.625326

Epoch: 60
Loss: 0.3751780962541774
ROC train: 0.881366	val: 0.588865	test: 0.561155
PRC train: 0.833528	val: 0.640668	test: 0.616534

Epoch: 61
Loss: 0.381188369449688
ROC train: 0.882732	val: 0.586109	test: 0.549455
PRC train: 0.835985	val: 0.636579	test: 0.607935

Epoch: 62
Loss: 0.37945859429996975
ROC train: 0.883927	val: 0.602230	test: 0.572446
PRC train: 0.839277	val: 0.647606	test: 0.621508

Epoch: 63
Loss: 0.37586699292993153
ROC train: 0.884025	val: 0.603433	test: 0.571205
PRC train: 0.840018	val: 0.649568	test: 0.625048

Epoch: 64
Loss: 0.37596988716216684
ROC train: 0.885068	val: 0.589266	test: 0.568247
PRC train: 0.840132	val: 0.640949	test: 0.619545

Epoch: 65
Loss: 0.37174424420089547
ROC train: 0.880466	val: 0.581500	test: 0.564434
PRC train: 0.834957	val: 0.638933	test: 0.621373

Epoch: 66
Loss: 0.3751529836124744
ROC train: 0.888618	val: 0.577142	test: 0.569424
PRC train: 0.844735	val: 0.637370	test: 0.619453

Epoch: 67
Loss: 0.3761166642351804
ROC train: 0.889005	val: 0.591426	test: 0.591253
PRC train: 0.846845	val: 0.639318	test: 0.631840

Epoch: 68
Loss: 0.371179283289209
ROC train: 0.890892	val: 0.586161	test: 0.578926
PRC train: 0.847507	val: 0.637263	test: 0.626446

Epoch: 69
Loss: 0.3676098463348768
ROC train: 0.889138	val: 0.564633	test: 0.565703
PRC train: 0.846403	val: 0.628237	test: 0.619086

Epoch: 70
Loss: 0.36419925995278535
ROC train: 0.885338	val: 0.578642	test: 0.567652
PRC train: 0.840858	val: 0.638084	test: 0.619550

Epoch: 71
Loss: 0.36860842583223363
ROC train: 0.894237	val: 0.605283	test: 0.595239
PRC train: 0.850531	val: 0.652020	test: 0.634190

Epoch: 72
Loss: 0.3643585321882401
ROC train: 0.897555	val: 0.605662	test: 0.586940
PRC train: 0.852923	val: 0.650543	test: 0.631688

Epoch: 73
Loss: 0.3593510066289608
ROC train: 0.900736	val: 0.594084	test: 0.578383
PRC train: 0.856635	val: 0.643047	test: 0.625589

Epoch: 74
Loss: 0.36007381457551496
ROC train: 0.896985	val: 0.571278	test: 0.575906
PRC train: 0.852764	val: 0.631381	test: 0.622867

Epoch: 75
Loss: 0.35829586962378057
ROC train: 0.896719	val: 0.576952	test: 0.569837
PRC train: 0.851667	val: 0.637815	test: 0.621810

Epoch: 76
Loss: 0.35804857738282536
ROC train: 0.903161	val: 0.586620	test: 0.576429
PRC train: 0.860108	val: 0.640122	test: 0.627144

Epoch: 77
Loss: 0.35217327735246695
ROC train: 0.900570	val: 0.597500	test: 0.607665
PRC train: 0.858952	val: 0.645314	test: 0.636298

Epoch: 78
Loss: 0.3569414747663441
ROC train: 0.901739	val: 0.602920	test: 0.582203
PRC train: 0.856017	val: 0.646570	test: 0.627346

Epoch: 79
Loss: 0.35411365601848377
ROC train: 0.899297	val: 0.570505	test: 0.571430
PRC train: 0.854521	val: 0.631908	test: 0.623677

Epoch: 80
Loss: 0.3508054959588979
ROC train: 0.904555	val: 0.592993	test: 0.565528
PRC train: 0.861068	val: 0.643370	test: 0.624285

Epoch: 81
Loss: 0.35356978996439903
ROC train: 0.906991	val: 0.611663	test: 0.568316
PRC train: 0.865351	val: 0.649460	test: 0.624030

Epoch: 82
Loss: 0.34969386414445836
ROC train: 0.906738	val: 0.610934	test: 0.580008
PRC train: 0.865244	val: 0.647930	test: 0.624258

Epoch: 83
Loss: 0.34223398531350246
ROC train: 0.909577	val: 0.604075	test: 0.573897
PRC train: 0.867243	val: 0.647362	test: 0.624435

Epoch: 84
Loss: 0.3495157180500388
ROC train: 0.909910	val: 0.593926	test: 0.578939
PRC train: 0.867647	val: 0.646699	test: 0.627781

Epoch: 85
Loss: 0.3495498028338314
ROC train: 0.910096	val: 0.589868	test: 0.571336
PRC train: 0.869577	val: 0.642719	test: 0.622571

Epoch: 86
Loss: 0.3460522333939028
ROC train: 0.913287	val: 0.607598	test: 0.561029
PRC train: 0.871961	val: 0.651589	test: 0.622825

Epoch: 87
Loss: 0.3421466634027547
ROC train: 0.909967	val: 0.593334	test: 0.572135
PRC train: 0.871196	val: 0.642613	test: 0.627218

Epoch: 88
Loss: 0.34366885103590783
ROC train: 0.908830	val: 0.585249	test: 0.569632
PRC train: 0.868673	val: 0.637943	test: 0.619093

Epoch: 89
Loss: 0.3380419980741414
ROC train: 0.910002	val: 0.597929	test: 0.577148
PRC train: 0.869772	val: 0.645134	test: 0.625717

Epoch: 90
Loss: 0.3427497076079573
ROC train: 0.910800	val: 0.596392	test: 0.579149
PRC train: 0.874618	val: 0.642991	test: 0.625438

Epoch: 91
Loss: 0.3392026674396932
ROC train: 0.916549	val: 0.626736	test: 0.599567
PRC train: 0.879894	val: 0.658957	test: 0.634305

Epoch: 92
Loss: 0.3351986095583085
ROC train: 0.913883	val: 0.629014	test: 0.586785
PRC train: 0.874430	val: 0.659417	test: 0.634110

Epoch: 93
Loss: 0.33471349709564746
ROC train: 0.917197	val: 0.595828	test: 0.570192
PRC train: 0.782355	val: 0.652902	test: 0.614563

Epoch: 33
Loss: 0.4239406845462481
ROC train: 0.830834	val: 0.602399	test: 0.562920
PRC train: 0.787076	val: 0.655735	test: 0.614779

Epoch: 34
Loss: 0.4175469113403654
ROC train: 0.836974	val: 0.615640	test: 0.563209
PRC train: 0.792302	val: 0.659363	test: 0.611480

Epoch: 35
Loss: 0.42127358411434807
ROC train: 0.836420	val: 0.623650	test: 0.568462
PRC train: 0.794426	val: 0.661157	test: 0.611808

Epoch: 36
Loss: 0.4143983003637722
ROC train: 0.832401	val: 0.614530	test: 0.570899
PRC train: 0.792326	val: 0.657427	test: 0.616272

Epoch: 37
Loss: 0.416336863656502
ROC train: 0.834592	val: 0.605489	test: 0.553334
PRC train: 0.792327	val: 0.658787	test: 0.610641

Epoch: 38
Loss: 0.41163984057915126
ROC train: 0.842018	val: 0.604656	test: 0.563051
PRC train: 0.798521	val: 0.657637	test: 0.614018

Epoch: 39
Loss: 0.4078753358821734
ROC train: 0.848416	val: 0.610090	test: 0.570369
PRC train: 0.804193	val: 0.654103	test: 0.616851

Epoch: 40
Loss: 0.40825981585966076
ROC train: 0.848597	val: 0.611054	test: 0.561411
PRC train: 0.803190	val: 0.652780	test: 0.619330

Epoch: 41
Loss: 0.40464653872369993
ROC train: 0.852321	val: 0.613412	test: 0.565434
PRC train: 0.806915	val: 0.655445	test: 0.614346

Epoch: 42
Loss: 0.4015015790729777
ROC train: 0.855656	val: 0.609609	test: 0.567664
PRC train: 0.810898	val: 0.656028	test: 0.609931

Epoch: 43
Loss: 0.4006739318995007
ROC train: 0.856514	val: 0.618242	test: 0.557610
PRC train: 0.809291	val: 0.658212	test: 0.610744

Epoch: 44
Loss: 0.40481980965112074
ROC train: 0.850637	val: 0.610724	test: 0.553760
PRC train: 0.803792	val: 0.659287	test: 0.607761

Epoch: 45
Loss: 0.39706034438044524
ROC train: 0.854617	val: 0.620375	test: 0.558229
PRC train: 0.810217	val: 0.662567	test: 0.611287

Epoch: 46
Loss: 0.38969696351134725
ROC train: 0.857287	val: 0.627990	test: 0.562260
PRC train: 0.816206	val: 0.665428	test: 0.613954

Epoch: 47
Loss: 0.39192881124872414
ROC train: 0.862798	val: 0.623617	test: 0.571060
PRC train: 0.819345	val: 0.662715	test: 0.617756

Epoch: 48
Loss: 0.3925789336214941
ROC train: 0.859113	val: 0.614994	test: 0.566692
PRC train: 0.814440	val: 0.660641	test: 0.615069

Epoch: 49
Loss: 0.390690466626181
ROC train: 0.860183	val: 0.610454	test: 0.556879
PRC train: 0.816702	val: 0.664053	test: 0.611356

Epoch: 50
Loss: 0.3821880516302939
ROC train: 0.867767	val: 0.617727	test: 0.555033
PRC train: 0.821974	val: 0.663620	test: 0.609890

Epoch: 51
Loss: 0.3849170402140266
ROC train: 0.869826	val: 0.617313	test: 0.563514
PRC train: 0.825593	val: 0.664527	test: 0.615878

Epoch: 52
Loss: 0.3856564319676198
ROC train: 0.869198	val: 0.620603	test: 0.551258
PRC train: 0.825564	val: 0.664758	test: 0.609125

Epoch: 53
Loss: 0.38473222451821754
ROC train: 0.871919	val: 0.615737	test: 0.558813
PRC train: 0.828395	val: 0.663176	test: 0.608507

Epoch: 54
Loss: 0.3844504838865647
ROC train: 0.874061	val: 0.612910	test: 0.567227
PRC train: 0.831845	val: 0.664459	test: 0.610988

Epoch: 55
Loss: 0.38002579143586934
ROC train: 0.878550	val: 0.616451	test: 0.554013
PRC train: 0.834865	val: 0.666522	test: 0.609703

Epoch: 56
Loss: 0.37460909993243513
ROC train: 0.879386	val: 0.615107	test: 0.562400
PRC train: 0.835028	val: 0.665892	test: 0.610264

Epoch: 57
Loss: 0.3732032543733614
ROC train: 0.879907	val: 0.612188	test: 0.567467
PRC train: 0.835876	val: 0.659268	test: 0.612199

Epoch: 58
Loss: 0.3738429214951092
ROC train: 0.879165	val: 0.618867	test: 0.568832
PRC train: 0.833748	val: 0.661297	test: 0.618779

Epoch: 59
Loss: 0.3783316881955044
ROC train: 0.882116	val: 0.612836	test: 0.558416
PRC train: 0.836118	val: 0.662968	test: 0.616988

Epoch: 60
Loss: 0.3709453416669233
ROC train: 0.884833	val: 0.615943	test: 0.550564
PRC train: 0.840927	val: 0.664139	test: 0.611893

Epoch: 61
Loss: 0.3688086297761311
ROC train: 0.885592	val: 0.611675	test: 0.555429
PRC train: 0.842922	val: 0.665527	test: 0.607376

Epoch: 62
Loss: 0.3620104224420195
ROC train: 0.888449	val: 0.606165	test: 0.555607
PRC train: 0.845243	val: 0.666804	test: 0.609383

Epoch: 63
Loss: 0.3659637187801388
ROC train: 0.889470	val: 0.600599	test: 0.556745
PRC train: 0.846953	val: 0.664318	test: 0.608855

Epoch: 64
Loss: 0.3652538570963869
ROC train: 0.892241	val: 0.607665	test: 0.539320
PRC train: 0.849374	val: 0.664227	test: 0.602727

Epoch: 65
Loss: 0.36636046501437586
ROC train: 0.892449	val: 0.604778	test: 0.536272
PRC train: 0.848626	val: 0.663105	test: 0.599523

Epoch: 66
Loss: 0.36401726688036107
ROC train: 0.894773	val: 0.602139	test: 0.551075
PRC train: 0.850081	val: 0.662743	test: 0.607822

Epoch: 67
Loss: 0.36477299174882893
ROC train: 0.895897	val: 0.599932	test: 0.552479
PRC train: 0.851510	val: 0.662830	test: 0.609761

Epoch: 68
Loss: 0.35790018744733665
ROC train: 0.895697	val: 0.602508	test: 0.550419
PRC train: 0.851802	val: 0.667215	test: 0.605258

Epoch: 69
Loss: 0.3581646371158393
ROC train: 0.898873	val: 0.601731	test: 0.554405
PRC train: 0.855184	val: 0.660343	test: 0.608887

Epoch: 70
Loss: 0.3557779536491917
ROC train: 0.899217	val: 0.606634	test: 0.550417
PRC train: 0.856790	val: 0.661150	test: 0.604228

Epoch: 71
Loss: 0.3542914067222698
ROC train: 0.896735	val: 0.618750	test: 0.539531
PRC train: 0.853855	val: 0.670176	test: 0.604932

Epoch: 72
Loss: 0.3538463920663592
ROC train: 0.897911	val: 0.612084	test: 0.543953
PRC train: 0.855683	val: 0.669343	test: 0.605495

Epoch: 73
Loss: 0.34905081980013053
ROC train: 0.902291	val: 0.623628	test: 0.553452
PRC train: 0.859069	val: 0.669858	test: 0.612969

Epoch: 74
Loss: 0.3545481594337501
ROC train: 0.905307	val: 0.621221	test: 0.555528
PRC train: 0.861753	val: 0.668245	test: 0.614018

Epoch: 75
Loss: 0.35279952523768954
ROC train: 0.905021	val: 0.608384	test: 0.551191
PRC train: 0.860904	val: 0.662667	test: 0.608545

Epoch: 76
Loss: 0.3448503203332414
ROC train: 0.903628	val: 0.605493	test: 0.544954
PRC train: 0.859934	val: 0.664998	test: 0.606022

Epoch: 77
Loss: 0.3457439076840648
ROC train: 0.907609	val: 0.608584	test: 0.553648
PRC train: 0.863380	val: 0.665005	test: 0.611626

Epoch: 78
Loss: 0.34975067465559384
ROC train: 0.908776	val: 0.609600	test: 0.561784
PRC train: 0.864906	val: 0.662762	test: 0.610645

Epoch: 79
Loss: 0.34262545513239706
ROC train: 0.909656	val: 0.616322	test: 0.551024
PRC train: 0.865680	val: 0.665121	test: 0.608370

Epoch: 80
Loss: 0.34665771579890486
ROC train: 0.909137	val: 0.603307	test: 0.547967
PRC train: 0.865627	val: 0.662410	test: 0.605271

Epoch: 81
Loss: 0.34619637159615596
ROC train: 0.906958	val: 0.601445	test: 0.538508
PRC train: 0.862172	val: 0.665697	test: 0.602389

Epoch: 82
Loss: 0.3431868824278103
ROC train: 0.911903	val: 0.608383	test: 0.553766
PRC train: 0.867834	val: 0.664950	test: 0.606557

Epoch: 83
Loss: 0.3376819340729117
ROC train: 0.913778	val: 0.616537	test: 0.552230
PRC train: 0.870573	val: 0.671748	test: 0.608983

Epoch: 84
Loss: 0.3337589741126704
ROC train: 0.914981	val: 0.613581	test: 0.550080
PRC train: 0.870733	val: 0.672872	test: 0.607415

Epoch: 85
Loss: 0.3361089869377215
ROC train: 0.916643	val: 0.615030	test: 0.539881
PRC train: 0.873676	val: 0.668964	test: 0.605925

Epoch: 86
Loss: 0.32821865143219503
ROC train: 0.918222	val: 0.610175	test: 0.552215
PRC train: 0.875860	val: 0.667269	test: 0.609552

Epoch: 87
Loss: 0.33001492246747827
ROC train: 0.918919	val: 0.617760	test: 0.556457
PRC train: 0.877108	val: 0.669055	test: 0.614852

Epoch: 88
Loss: 0.33307389908996426
ROC train: 0.919079	val: 0.611663	test: 0.556446
PRC train: 0.876946	val: 0.670006	test: 0.613327

Epoch: 89
Loss: 0.33569274092567924
ROC train: 0.917606	val: 0.600306	test: 0.552162
PRC train: 0.875488	val: 0.665385	test: 0.608336

Epoch: 90
Loss: 0.3255773414999266
ROC train: 0.919784	val: 0.604594	test: 0.528356
PRC train: 0.876388	val: 0.667520	test: 0.600450

Epoch: 91
Loss: 0.3281679146961459
ROC train: 0.918939	val: 0.600851	test: 0.544285
PRC train: 0.874616	val: 0.666435	test: 0.603434

Epoch: 92
Loss: 0.3334347787311992
ROC train: 0.923339	val: 0.611392	test: 0.551208
PRC train: 0.880627	val: 0.670997	test: 0.608026

Epoch: 93
Loss: 0.3355997125675677
ROC train: 0.923122	val: 0.611274	test: 0.545073
PRC train: 0.838337	val: 0.677314	test: 0.640642

Epoch: 95
Loss: 0.3765352753749953
ROC train: 0.884030	val: 0.624293	test: 0.617293
PRC train: 0.842910	val: 0.675548	test: 0.648679

Epoch: 96
Loss: 0.3694352292267115
ROC train: 0.885206	val: 0.616447	test: 0.588997
PRC train: 0.843293	val: 0.668619	test: 0.636579

Epoch: 97
Loss: 0.37551097702297254
ROC train: 0.885873	val: 0.614778	test: 0.588020
PRC train: 0.844539	val: 0.669610	test: 0.630174

Epoch: 98
Loss: 0.37894079358187904
ROC train: 0.886184	val: 0.623374	test: 0.609658
PRC train: 0.845445	val: 0.668726	test: 0.640748

Epoch: 99
Loss: 0.37650138413229145
ROC train: 0.890059	val: 0.620020	test: 0.604388
PRC train: 0.847246	val: 0.669230	test: 0.641051

Epoch: 100
Loss: 0.3674527853305902
ROC train: 0.887390	val: 0.602157	test: 0.593440
PRC train: 0.845231	val: 0.666140	test: 0.636988

Epoch: 101
Loss: 0.372231923004599
ROC train: 0.889803	val: 0.608699	test: 0.583589
PRC train: 0.849186	val: 0.668112	test: 0.631955

Epoch: 102
Loss: 0.3716444628689105
ROC train: 0.889344	val: 0.614971	test: 0.601249
PRC train: 0.849915	val: 0.668071	test: 0.639606

Epoch: 103
Loss: 0.37335262193641167
ROC train: 0.890200	val: 0.613690	test: 0.603215
PRC train: 0.850555	val: 0.667504	test: 0.637169

Epoch: 104
Loss: 0.37531419388663345
ROC train: 0.893972	val: 0.627486	test: 0.599467
PRC train: 0.852951	val: 0.675497	test: 0.634842

Epoch: 105
Loss: 0.3737853031993922
ROC train: 0.892409	val: 0.628295	test: 0.620218
PRC train: 0.850510	val: 0.674918	test: 0.646750

Epoch: 106
Loss: 0.3727486778654103
ROC train: 0.891437	val: 0.624355	test: 0.609581
PRC train: 0.850769	val: 0.677487	test: 0.641630

Epoch: 107
Loss: 0.3678135163569862
ROC train: 0.891688	val: 0.613092	test: 0.600506
PRC train: 0.849549	val: 0.671086	test: 0.634656

Epoch: 108
Loss: 0.3631330876234593
ROC train: 0.896625	val: 0.616478	test: 0.598782
PRC train: 0.854837	val: 0.670413	test: 0.636721

Epoch: 109
Loss: 0.3647150398200753
ROC train: 0.900435	val: 0.627533	test: 0.602047
PRC train: 0.857897	val: 0.672969	test: 0.640159

Epoch: 110
Loss: 0.36822602482779276
ROC train: 0.898147	val: 0.624785	test: 0.604719
PRC train: 0.857206	val: 0.671929	test: 0.638809

Epoch: 111
Loss: 0.362490769715035
ROC train: 0.898776	val: 0.624109	test: 0.599702
PRC train: 0.857991	val: 0.677534	test: 0.638831

Epoch: 112
Loss: 0.3595338517362131
ROC train: 0.894443	val: 0.608608	test: 0.606047
PRC train: 0.854587	val: 0.667128	test: 0.645639

Epoch: 113
Loss: 0.36292808417052175
ROC train: 0.896164	val: 0.612543	test: 0.587179
PRC train: 0.855050	val: 0.669672	test: 0.638337

Epoch: 114
Loss: 0.36137264089784427
ROC train: 0.900887	val: 0.616490	test: 0.588373
PRC train: 0.861867	val: 0.674007	test: 0.632809

Epoch: 115
Loss: 0.35710306605528563
ROC train: 0.896816	val: 0.624186	test: 0.605223
PRC train: 0.857754	val: 0.674020	test: 0.634897

Epoch: 116
Loss: 0.35837165820161276
ROC train: 0.904438	val: 0.631031	test: 0.614750
PRC train: 0.863240	val: 0.677589	test: 0.644776

Epoch: 117
Loss: 0.36220413721736
ROC train: 0.904018	val: 0.619698	test: 0.594125
PRC train: 0.862617	val: 0.675456	test: 0.637123

Epoch: 118
Loss: 0.3578436813590359
ROC train: 0.899838	val: 0.615351	test: 0.592738
PRC train: 0.858251	val: 0.674131	test: 0.634551

Epoch: 119
Loss: 0.35295894166410025
ROC train: 0.907455	val: 0.623824	test: 0.599723
PRC train: 0.866970	val: 0.676774	test: 0.638127

Epoch: 120
Loss: 0.35682042453225027
ROC train: 0.899983	val: 0.634942	test: 0.593999
PRC train: 0.861792	val: 0.679974	test: 0.638247

Early stopping
Best (ROC):	 train: 0.838003	val: 0.646917	test: 0.618534
Best (PRC):	 train: 0.797894	val: 0.680681	test: 0.640464

PRC train: 0.870738	val: 0.657040	test: 0.627141

Epoch: 94
Loss: 0.34128616909413745
ROC train: 0.910016	val: 0.596644	test: 0.589339
PRC train: 0.867520	val: 0.657565	test: 0.628306

Epoch: 95
Loss: 0.3441007523383225
ROC train: 0.914838	val: 0.590943	test: 0.572611
PRC train: 0.874003	val: 0.652331	test: 0.624749

Epoch: 96
Loss: 0.3360783674566526
ROC train: 0.910883	val: 0.581415	test: 0.582594
PRC train: 0.865972	val: 0.647359	test: 0.623091

Epoch: 97
Loss: 0.3363417631066191
ROC train: 0.914540	val: 0.590209	test: 0.587467
PRC train: 0.872981	val: 0.654305	test: 0.627151

Epoch: 98
Loss: 0.33954066280934325
ROC train: 0.915666	val: 0.602506	test: 0.598386
PRC train: 0.876924	val: 0.657355	test: 0.636288

Epoch: 99
Loss: 0.3361216609094385
ROC train: 0.911869	val: 0.592615	test: 0.586706
PRC train: 0.873008	val: 0.657090	test: 0.634014

Epoch: 100
Loss: 0.3422922305728064
ROC train: 0.919157	val: 0.590268	test: 0.583760
PRC train: 0.878014	val: 0.657950	test: 0.628217

Epoch: 101
Loss: 0.3324499277899487
ROC train: 0.916435	val: 0.580900	test: 0.583781
PRC train: 0.877247	val: 0.649881	test: 0.624220

Epoch: 102
Loss: 0.3294280887014246
ROC train: 0.917562	val: 0.595083	test: 0.566305
PRC train: 0.875599	val: 0.659250	test: 0.615558

Epoch: 103
Loss: 0.3342178955934824
ROC train: 0.922204	val: 0.596027	test: 0.577593
PRC train: 0.879469	val: 0.653591	test: 0.626455

Epoch: 104
Loss: 0.3280289537622562
ROC train: 0.919515	val: 0.597632	test: 0.580038
PRC train: 0.878480	val: 0.656509	test: 0.629849

Epoch: 105
Loss: 0.3313066434767323
ROC train: 0.919996	val: 0.580082	test: 0.583595
PRC train: 0.884583	val: 0.646838	test: 0.631287

Epoch: 106
Loss: 0.33092083393716754
ROC train: 0.918582	val: 0.589620	test: 0.585303
PRC train: 0.880758	val: 0.652983	test: 0.628376

Epoch: 107
Loss: 0.3256161624317039
ROC train: 0.922134	val: 0.591953	test: 0.591185
PRC train: 0.884704	val: 0.658198	test: 0.626426

Epoch: 108
Loss: 0.31973827803279214
ROC train: 0.927442	val: 0.586819	test: 0.587534
PRC train: 0.890616	val: 0.650878	test: 0.630687

Epoch: 109
Loss: 0.3188062151090268
ROC train: 0.927566	val: 0.595378	test: 0.577257
PRC train: 0.890479	val: 0.657570	test: 0.625323

Epoch: 110
Loss: 0.3214950096203856
ROC train: 0.926153	val: 0.594024	test: 0.573255
PRC train: 0.891549	val: 0.656702	test: 0.621562

Epoch: 111
Loss: 0.3215134404530997
ROC train: 0.923238	val: 0.592209	test: 0.584117
PRC train: 0.890305	val: 0.659391	test: 0.625185

Epoch: 112
Loss: 0.3220990271324086
ROC train: 0.927506	val: 0.598060	test: 0.581026
PRC train: 0.892308	val: 0.659241	test: 0.626747

Epoch: 113
Loss: 0.3145645046505763
ROC train: 0.931352	val: 0.603177	test: 0.575475
PRC train: 0.894168	val: 0.660553	test: 0.623805

Epoch: 114
Loss: 0.31410935532809015
ROC train: 0.930157	val: 0.593399	test: 0.577782
PRC train: 0.893380	val: 0.655547	test: 0.623465

Epoch: 115
Loss: 0.31822068147308896
ROC train: 0.932741	val: 0.591253	test: 0.573633
PRC train: 0.896398	val: 0.653948	test: 0.626439

Epoch: 116
Loss: 0.3096885468462044
ROC train: 0.930230	val: 0.591380	test: 0.570615
PRC train: 0.890612	val: 0.653302	test: 0.627621

Epoch: 117
Loss: 0.3115146246264394
ROC train: 0.933859	val: 0.596005	test: 0.574442
PRC train: 0.899153	val: 0.661079	test: 0.624589

Epoch: 118
Loss: 0.309517865260152
ROC train: 0.933092	val: 0.594220	test: 0.577634
PRC train: 0.898023	val: 0.656985	test: 0.627906

Epoch: 119
Loss: 0.3121526137542539
ROC train: 0.932587	val: 0.598632	test: 0.593688
PRC train: 0.894824	val: 0.668058	test: 0.639658

Epoch: 120
Loss: 0.3097178122941302
ROC train: 0.937152	val: 0.586790	test: 0.573692
PRC train: 0.901889	val: 0.654462	test: 0.627812

Early stopping
Best (ROC):	 train: 0.753231	val: 0.613364	test: 0.582767
Best (PRC):	 train: 0.723143	val: 0.657541	test: 0.618227

PRC train: 0.870576	val: 0.664245	test: 0.626807

Epoch: 94
Loss: 0.34994375007338835
ROC train: 0.907901	val: 0.601735	test: 0.596948
PRC train: 0.869378	val: 0.664969	test: 0.627266

Epoch: 95
Loss: 0.3466229581791883
ROC train: 0.908867	val: 0.601368	test: 0.589838
PRC train: 0.872776	val: 0.657955	test: 0.623985

Epoch: 96
Loss: 0.3485562948236688
ROC train: 0.910929	val: 0.594448	test: 0.599528
PRC train: 0.875464	val: 0.662624	test: 0.625814

Epoch: 97
Loss: 0.3430496066262904
ROC train: 0.910449	val: 0.604206	test: 0.602962
PRC train: 0.874405	val: 0.665575	test: 0.628453

Epoch: 98
Loss: 0.3384785830096947
ROC train: 0.912336	val: 0.600181	test: 0.607640
PRC train: 0.874113	val: 0.659724	test: 0.628723

Epoch: 99
Loss: 0.3448669549374549
ROC train: 0.913662	val: 0.596945	test: 0.596696
PRC train: 0.874534	val: 0.659696	test: 0.621551

Epoch: 100
Loss: 0.3383223278771005
ROC train: 0.916056	val: 0.600809	test: 0.579195
PRC train: 0.879617	val: 0.661307	test: 0.620261

Epoch: 101
Loss: 0.33944524919979774
ROC train: 0.913870	val: 0.606839	test: 0.570751
PRC train: 0.878168	val: 0.659917	test: 0.620980

Epoch: 102
Loss: 0.34032799492738447
ROC train: 0.913713	val: 0.603045	test: 0.586519
PRC train: 0.877790	val: 0.662757	test: 0.622906

Epoch: 103
Loss: 0.3351616912157374
ROC train: 0.918286	val: 0.601656	test: 0.597326
PRC train: 0.883610	val: 0.664907	test: 0.628573

Epoch: 104
Loss: 0.3383757916625184
ROC train: 0.920153	val: 0.613049	test: 0.599511
PRC train: 0.882320	val: 0.670165	test: 0.635069

Epoch: 105
Loss: 0.3348628153782786
ROC train: 0.921504	val: 0.605782	test: 0.589192
PRC train: 0.881408	val: 0.662682	test: 0.626976

Epoch: 106
Loss: 0.33108332887266434
ROC train: 0.920235	val: 0.594633	test: 0.596137
PRC train: 0.881325	val: 0.658241	test: 0.628486

Epoch: 107
Loss: 0.3317563388255459
ROC train: 0.922064	val: 0.600211	test: 0.571966
PRC train: 0.884627	val: 0.657763	test: 0.621152

Epoch: 108
Loss: 0.3307771522842913
ROC train: 0.922518	val: 0.597895	test: 0.579329
PRC train: 0.888383	val: 0.659065	test: 0.621835

Epoch: 109
Loss: 0.32762806006526524
ROC train: 0.924642	val: 0.598150	test: 0.607082
PRC train: 0.891733	val: 0.659719	test: 0.630856

Epoch: 110
Loss: 0.3275886236206865
ROC train: 0.921617	val: 0.599501	test: 0.596782
PRC train: 0.885646	val: 0.660362	test: 0.628065

Epoch: 111
Loss: 0.32384639222747624
ROC train: 0.920402	val: 0.600046	test: 0.584575
PRC train: 0.884535	val: 0.663695	test: 0.620923

Epoch: 112
Loss: 0.3265760858840328
ROC train: 0.925717	val: 0.599667	test: 0.575792
PRC train: 0.890868	val: 0.666290	test: 0.620708

Epoch: 113
Loss: 0.31853228315618687
ROC train: 0.926487	val: 0.604308	test: 0.604538
PRC train: 0.890208	val: 0.664326	test: 0.629217

Epoch: 114
Loss: 0.32436669089423914
ROC train: 0.926192	val: 0.601991	test: 0.595741
PRC train: 0.889708	val: 0.663465	test: 0.628325

Epoch: 115
Loss: 0.32819272699211155
ROC train: 0.926690	val: 0.592920	test: 0.562578
PRC train: 0.890772	val: 0.660539	test: 0.619688

Epoch: 116
Loss: 0.3219606624904917
ROC train: 0.930214	val: 0.597937	test: 0.603117
PRC train: 0.894815	val: 0.666336	test: 0.629601

Epoch: 117
Loss: 0.3198958514702032
ROC train: 0.930265	val: 0.603023	test: 0.595418
PRC train: 0.896815	val: 0.659904	test: 0.627301

Epoch: 118
Loss: 0.31867571193187316
ROC train: 0.916071	val: 0.587401	test: 0.613241
PRC train: 0.883261	val: 0.653132	test: 0.640626

Epoch: 119
Loss: 0.3187649145024162
ROC train: 0.930657	val: 0.604887	test: 0.581493
PRC train: 0.894108	val: 0.660819	test: 0.629089

Epoch: 120
Loss: 0.3213023368681664
ROC train: 0.931300	val: 0.603272	test: 0.582027
PRC train: 0.896225	val: 0.661827	test: 0.623395

Early stopping
Best (ROC):	 train: 0.843757	val: 0.632311	test: 0.593536
Best (PRC):	 train: 0.797253	val: 0.671196	test: 0.630902

PRC train: 0.876751	val: 0.659726	test: 0.615865

Epoch: 94
Loss: 0.3239799521190459
ROC train: 0.920944	val: 0.604432	test: 0.579760
PRC train: 0.878932	val: 0.654050	test: 0.622679

Epoch: 95
Loss: 0.3263992519642155
ROC train: 0.925464	val: 0.609401	test: 0.576330
PRC train: 0.883266	val: 0.660345	test: 0.622118

Epoch: 96
Loss: 0.32055050560090004
ROC train: 0.925564	val: 0.614946	test: 0.584955
PRC train: 0.883793	val: 0.663602	test: 0.623032

Epoch: 97
Loss: 0.3216609394491699
ROC train: 0.925144	val: 0.608272	test: 0.592165
PRC train: 0.885478	val: 0.660124	test: 0.622625

Epoch: 98
Loss: 0.32102760407411857
ROC train: 0.923346	val: 0.607992	test: 0.593427
PRC train: 0.881501	val: 0.657461	test: 0.622236

Epoch: 99
Loss: 0.32025811412885424
ROC train: 0.923837	val: 0.616628	test: 0.576106
PRC train: 0.878432	val: 0.664515	test: 0.618430

Epoch: 100
Loss: 0.32168896237933187
ROC train: 0.926266	val: 0.611874	test: 0.576056
PRC train: 0.884804	val: 0.665885	test: 0.618886

Epoch: 101
Loss: 0.3175366609121558
ROC train: 0.927656	val: 0.609463	test: 0.587837
PRC train: 0.887953	val: 0.661401	test: 0.625786

Epoch: 102
Loss: 0.31494060153010023
ROC train: 0.929428	val: 0.607353	test: 0.580371
PRC train: 0.887051	val: 0.659524	test: 0.625745

Epoch: 103
Loss: 0.31528240271060926
ROC train: 0.930529	val: 0.607568	test: 0.580548
PRC train: 0.889466	val: 0.656657	test: 0.623818

Epoch: 104
Loss: 0.312141535272516
ROC train: 0.928369	val: 0.605865	test: 0.583161
PRC train: 0.890202	val: 0.657988	test: 0.622279

Epoch: 105
Loss: 0.3092419483523043
ROC train: 0.929439	val: 0.615003	test: 0.560325
PRC train: 0.889831	val: 0.663418	test: 0.619690

Epoch: 106
Loss: 0.3144063021748162
ROC train: 0.932458	val: 0.611604	test: 0.575820
PRC train: 0.892930	val: 0.665558	test: 0.623585

Epoch: 107
Loss: 0.3089961354919079
ROC train: 0.931381	val: 0.610825	test: 0.602994
PRC train: 0.894647	val: 0.659452	test: 0.628577

Epoch: 108
Loss: 0.3045953976795358
ROC train: 0.936462	val: 0.613594	test: 0.584203
PRC train: 0.900907	val: 0.658279	test: 0.620860

Epoch: 109
Loss: 0.3021609012176552
ROC train: 0.936191	val: 0.616826	test: 0.568115
PRC train: 0.899818	val: 0.658974	test: 0.617594

Epoch: 110
Loss: 0.30078707415809997
ROC train: 0.935794	val: 0.609736	test: 0.571010
PRC train: 0.901933	val: 0.659618	test: 0.618957

Epoch: 111
Loss: 0.3033143169049415
ROC train: 0.934892	val: 0.610833	test: 0.580402
PRC train: 0.899023	val: 0.664046	test: 0.621300

Epoch: 112
Loss: 0.3035305118412128
ROC train: 0.936065	val: 0.611612	test: 0.573452
PRC train: 0.900076	val: 0.661738	test: 0.620205

Epoch: 113
Loss: 0.30040257461851805
ROC train: 0.939322	val: 0.608764	test: 0.581061
PRC train: 0.902914	val: 0.655323	test: 0.620920

Epoch: 114
Loss: 0.2959582114832709
ROC train: 0.938507	val: 0.618268	test: 0.569702
PRC train: 0.901645	val: 0.662774	test: 0.616478

Epoch: 115
Loss: 0.2999653684117808
ROC train: 0.939644	val: 0.606016	test: 0.578580
PRC train: 0.905134	val: 0.658026	test: 0.615701

Epoch: 116
Loss: 0.2966263155133517
ROC train: 0.941454	val: 0.608610	test: 0.579606
PRC train: 0.905295	val: 0.663268	test: 0.616633

Epoch: 117
Loss: 0.2938003855026855
ROC train: 0.941745	val: 0.615839	test: 0.585173
PRC train: 0.906553	val: 0.668291	test: 0.622338

Epoch: 118
Loss: 0.2910595128581706
ROC train: 0.943686	val: 0.604730	test: 0.584376
PRC train: 0.910096	val: 0.664577	test: 0.623129

Epoch: 119
Loss: 0.28939537267681004
ROC train: 0.941208	val: 0.603401	test: 0.587987
PRC train: 0.909997	val: 0.653007	test: 0.623703

Epoch: 120
Loss: 0.2925641700249553
ROC train: 0.944104	val: 0.607804	test: 0.578017
PRC train: 0.913277	val: 0.658559	test: 0.618551

Early stopping
Best (ROC):	 train: 0.755184	val: 0.625050	test: 0.592317
Best (PRC):	 train: 0.727099	val: 0.662086	test: 0.621016

PRC train: 0.881043	val: 0.658104	test: 0.605085

Epoch: 94
Loss: 0.32787671191339385
ROC train: 0.922477	val: 0.607141	test: 0.564086
PRC train: 0.882384	val: 0.657727	test: 0.607695

Epoch: 95
Loss: 0.32602264442269635
ROC train: 0.922672	val: 0.603442	test: 0.559172
PRC train: 0.884161	val: 0.656406	test: 0.605816

Epoch: 96
Loss: 0.329458393863917
ROC train: 0.922538	val: 0.614146	test: 0.557520
PRC train: 0.883583	val: 0.660974	test: 0.604620

Epoch: 97
Loss: 0.3257535334148646
ROC train: 0.922056	val: 0.628701	test: 0.568318
PRC train: 0.881252	val: 0.670901	test: 0.614236

Epoch: 98
Loss: 0.3228377362646775
ROC train: 0.923166	val: 0.614438	test: 0.570723
PRC train: 0.884388	val: 0.657598	test: 0.606905

Epoch: 99
Loss: 0.3216217233362879
ROC train: 0.924921	val: 0.610183	test: 0.566164
PRC train: 0.887012	val: 0.660758	test: 0.603676

Epoch: 100
Loss: 0.3238590568205136
ROC train: 0.923074	val: 0.611052	test: 0.561076
PRC train: 0.884234	val: 0.662688	test: 0.603721

Epoch: 101
Loss: 0.3225271356384913
ROC train: 0.923621	val: 0.601035	test: 0.569309
PRC train: 0.884064	val: 0.650297	test: 0.605967

Epoch: 102
Loss: 0.32078484483978603
ROC train: 0.925876	val: 0.596819	test: 0.565409
PRC train: 0.887612	val: 0.653564	test: 0.606289

Epoch: 103
Loss: 0.31187752493749443
ROC train: 0.929529	val: 0.614416	test: 0.566476
PRC train: 0.894215	val: 0.662438	test: 0.609076

Epoch: 104
Loss: 0.3152234765279994
ROC train: 0.930687	val: 0.615909	test: 0.570952
PRC train: 0.895051	val: 0.664096	test: 0.610283

Epoch: 105
Loss: 0.31269527916425616
ROC train: 0.931286	val: 0.604445	test: 0.566198
PRC train: 0.895085	val: 0.657199	test: 0.605054

Epoch: 106
Loss: 0.3107699851336184
ROC train: 0.931654	val: 0.620962	test: 0.570705
PRC train: 0.896003	val: 0.663936	test: 0.612853

Epoch: 107
Loss: 0.3098358021846921
ROC train: 0.932374	val: 0.621061	test: 0.571311
PRC train: 0.896872	val: 0.667165	test: 0.612880

Epoch: 108
Loss: 0.3121719598802317
ROC train: 0.934275	val: 0.613071	test: 0.563418
PRC train: 0.899022	val: 0.663020	test: 0.605408

Epoch: 109
Loss: 0.3017766883442659
ROC train: 0.935357	val: 0.612981	test: 0.559729
PRC train: 0.900566	val: 0.662932	test: 0.602496

Epoch: 110
Loss: 0.31134480543888604
ROC train: 0.934440	val: 0.618687	test: 0.571258
PRC train: 0.900152	val: 0.667286	test: 0.612867

Epoch: 111
Loss: 0.30537419456070614
ROC train: 0.936864	val: 0.615371	test: 0.567487
PRC train: 0.903175	val: 0.664780	test: 0.610243

Epoch: 112
Loss: 0.3051328402579836
ROC train: 0.938498	val: 0.612033	test: 0.561017
PRC train: 0.906186	val: 0.664662	test: 0.603796

Epoch: 113
Loss: 0.3006849696804572
ROC train: 0.938893	val: 0.612132	test: 0.562824
PRC train: 0.905185	val: 0.663591	test: 0.602746

Epoch: 114
Loss: 0.30353614602560236
ROC train: 0.936746	val: 0.626745	test: 0.561374
PRC train: 0.903138	val: 0.671191	test: 0.607296

Epoch: 115
Loss: 0.30747669526427807
ROC train: 0.938069	val: 0.624900	test: 0.558845
PRC train: 0.903669	val: 0.669277	test: 0.607153

Epoch: 116
Loss: 0.3051063590562547
ROC train: 0.940140	val: 0.609811	test: 0.562059
PRC train: 0.905875	val: 0.660903	test: 0.603445

Epoch: 117
Loss: 0.29679332616842224
ROC train: 0.941648	val: 0.611956	test: 0.562901
PRC train: 0.908382	val: 0.659965	test: 0.602652

Epoch: 118
Loss: 0.2972854859330991
ROC train: 0.941868	val: 0.607848	test: 0.574476
PRC train: 0.908559	val: 0.657924	test: 0.605241

Epoch: 119
Loss: 0.2931930522569218
ROC train: 0.943422	val: 0.612612	test: 0.572576
PRC train: 0.912884	val: 0.662538	test: 0.607935

Epoch: 120
Loss: 0.2947261729321199
ROC train: 0.942375	val: 0.610656	test: 0.562351
PRC train: 0.912031	val: 0.661326	test: 0.608418

Early stopping
Best (ROC):	 train: 0.911977	val: 0.632119	test: 0.572144
Best (PRC):	 train: 0.870152	val: 0.672045	test: 0.612513

PRC train: 0.886857	val: 0.632239	test: 0.625369

Epoch: 94
Loss: 0.32481815289683047
ROC train: 0.926251	val: 0.561776	test: 0.587582
PRC train: 0.894600	val: 0.634657	test: 0.622367

Epoch: 95
Loss: 0.32386499028502536
ROC train: 0.925699	val: 0.561214	test: 0.596905
PRC train: 0.893710	val: 0.634051	test: 0.627159

Epoch: 96
Loss: 0.320540561826134
ROC train: 0.928435	val: 0.553307	test: 0.591336
PRC train: 0.894496	val: 0.628598	test: 0.625446

Epoch: 97
Loss: 0.3173468051938397
ROC train: 0.925555	val: 0.566385	test: 0.582944
PRC train: 0.892544	val: 0.640286	test: 0.621891

Epoch: 98
Loss: 0.3206223947683348
ROC train: 0.926663	val: 0.560765	test: 0.577695
PRC train: 0.897509	val: 0.637379	test: 0.622132

Epoch: 99
Loss: 0.32014413017595184
ROC train: 0.929371	val: 0.555136	test: 0.589480
PRC train: 0.899537	val: 0.635001	test: 0.627338

Epoch: 100
Loss: 0.31768581200754953
ROC train: 0.930835	val: 0.555366	test: 0.587832
PRC train: 0.898427	val: 0.632505	test: 0.627828

Epoch: 101
Loss: 0.3111874164188668
ROC train: 0.932097	val: 0.558402	test: 0.580858
PRC train: 0.897824	val: 0.634236	test: 0.633215

Epoch: 102
Loss: 0.3094259921764935
ROC train: 0.932032	val: 0.563340	test: 0.584648
PRC train: 0.897211	val: 0.636671	test: 0.628868

Epoch: 103
Loss: 0.3118679551199205
ROC train: 0.927973	val: 0.563385	test: 0.590296
PRC train: 0.895306	val: 0.636307	test: 0.627259

Epoch: 104
Loss: 0.3116834514254955
ROC train: 0.931934	val: 0.568308	test: 0.595748
PRC train: 0.904288	val: 0.641931	test: 0.631216

Epoch: 105
Loss: 0.30665051967363
ROC train: 0.936412	val: 0.568497	test: 0.594603
PRC train: 0.904485	val: 0.642785	test: 0.630666

Epoch: 106
Loss: 0.31088576227050785
ROC train: 0.937587	val: 0.555050	test: 0.592669
PRC train: 0.909074	val: 0.632034	test: 0.628675

Epoch: 107
Loss: 0.3087469407369088
ROC train: 0.938004	val: 0.561952	test: 0.582409
PRC train: 0.910429	val: 0.631353	test: 0.627943

Epoch: 108
Loss: 0.30427647355691045
ROC train: 0.938180	val: 0.552871	test: 0.579116
PRC train: 0.912258	val: 0.625219	test: 0.624355

Epoch: 109
Loss: 0.30656432207548756
ROC train: 0.938370	val: 0.548253	test: 0.593220
PRC train: 0.914924	val: 0.628734	test: 0.623949

Epoch: 110
Loss: 0.30825992107017297
ROC train: 0.939021	val: 0.552571	test: 0.581556
PRC train: 0.913405	val: 0.632837	test: 0.621631

Epoch: 111
Loss: 0.3048544235060947
ROC train: 0.940412	val: 0.560481	test: 0.583395
PRC train: 0.914366	val: 0.633133	test: 0.623799

Epoch: 112
Loss: 0.3009690413929512
ROC train: 0.943027	val: 0.547600	test: 0.586144
PRC train: 0.917148	val: 0.624946	test: 0.621049

Epoch: 113
Loss: 0.2978215616704659
ROC train: 0.944895	val: 0.551476	test: 0.597449
PRC train: 0.922894	val: 0.630973	test: 0.629329

Epoch: 114
Loss: 0.3012115452117468
ROC train: 0.943172	val: 0.550965	test: 0.588868
PRC train: 0.919056	val: 0.629584	test: 0.629994

Epoch: 115
Loss: 0.2912889237734217
ROC train: 0.944648	val: 0.560082	test: 0.580968
PRC train: 0.922854	val: 0.638960	test: 0.625056

Epoch: 116
Loss: 0.29785489344589
ROC train: 0.945202	val: 0.555571	test: 0.590552
PRC train: 0.921541	val: 0.633044	test: 0.626227

Epoch: 117
Loss: 0.2963251968476666
ROC train: 0.946403	val: 0.554395	test: 0.591200
PRC train: 0.921394	val: 0.631036	test: 0.629669

Epoch: 118
Loss: 0.2896964307988906
ROC train: 0.942522	val: 0.556637	test: 0.590034
PRC train: 0.918538	val: 0.631513	test: 0.628854

Epoch: 119
Loss: 0.288203725258721
ROC train: 0.947530	val: 0.554417	test: 0.578652
PRC train: 0.923308	val: 0.632446	test: 0.622320

Epoch: 120
Loss: 0.2908680397717255
ROC train: 0.949833	val: 0.562295	test: 0.572390
PRC train: 0.925142	val: 0.635852	test: 0.622517

Early stopping
Best (ROC):	 train: 0.880220	val: 0.584461	test: 0.591178
Best (PRC):	 train: 0.835632	val: 0.649249	test: 0.625647

PRC train: 0.885286	val: 0.669762	test: 0.610825

Epoch: 94
Loss: 0.32414116811223626
ROC train: 0.925512	val: 0.610773	test: 0.559418
PRC train: 0.886941	val: 0.666891	test: 0.615747

Epoch: 95
Loss: 0.32363033033093475
ROC train: 0.923984	val: 0.617795	test: 0.556159
PRC train: 0.879918	val: 0.669101	test: 0.614324

Epoch: 96
Loss: 0.32012168954367054
ROC train: 0.921178	val: 0.610392	test: 0.546240
PRC train: 0.875464	val: 0.669349	test: 0.609513

Epoch: 97
Loss: 0.3178572393203508
ROC train: 0.924647	val: 0.612812	test: 0.551250
PRC train: 0.884723	val: 0.669079	test: 0.609892

Epoch: 98
Loss: 0.32019043296982186
ROC train: 0.928745	val: 0.609007	test: 0.549195
PRC train: 0.888505	val: 0.665569	test: 0.609802

Epoch: 99
Loss: 0.31979499673643386
ROC train: 0.929729	val: 0.604793	test: 0.554294
PRC train: 0.891627	val: 0.663528	test: 0.610889

Epoch: 100
Loss: 0.32033602250625043
ROC train: 0.928618	val: 0.616931	test: 0.553050
PRC train: 0.889132	val: 0.669371	test: 0.614593

Epoch: 101
Loss: 0.310356923926315
ROC train: 0.930933	val: 0.619670	test: 0.538027
PRC train: 0.891654	val: 0.671798	test: 0.608078

Epoch: 102
Loss: 0.31195773131236154
ROC train: 0.931927	val: 0.612741	test: 0.545912
PRC train: 0.893659	val: 0.669095	test: 0.608581

Epoch: 103
Loss: 0.3126602581057993
ROC train: 0.931934	val: 0.617252	test: 0.547127
PRC train: 0.892435	val: 0.670702	test: 0.607956

Epoch: 104
Loss: 0.3109913208157857
ROC train: 0.933920	val: 0.622383	test: 0.543999
PRC train: 0.895011	val: 0.674862	test: 0.611780

Epoch: 105
Loss: 0.31255395431196253
ROC train: 0.934228	val: 0.616398	test: 0.536357
PRC train: 0.894637	val: 0.670221	test: 0.607789

Epoch: 106
Loss: 0.3121602279580361
ROC train: 0.931832	val: 0.617200	test: 0.536155
PRC train: 0.893372	val: 0.666780	test: 0.604200

Epoch: 107
Loss: 0.30716079793080364
ROC train: 0.935941	val: 0.611631	test: 0.556596
PRC train: 0.897955	val: 0.663672	test: 0.607485

Epoch: 108
Loss: 0.3066330722300652
ROC train: 0.939596	val: 0.599274	test: 0.552695
PRC train: 0.902000	val: 0.660997	test: 0.608478

Epoch: 109
Loss: 0.30019213538704437
ROC train: 0.939450	val: 0.588837	test: 0.544203
PRC train: 0.901120	val: 0.659897	test: 0.606097

Epoch: 110
Loss: 0.2998069280795324
ROC train: 0.940976	val: 0.597000	test: 0.536577
PRC train: 0.902310	val: 0.664917	test: 0.603971

Epoch: 111
Loss: 0.30211880289887616
ROC train: 0.940104	val: 0.599649	test: 0.546363
PRC train: 0.903945	val: 0.663765	test: 0.605805

Epoch: 112
Loss: 0.3032779582333757
ROC train: 0.940487	val: 0.602692	test: 0.560256
PRC train: 0.903699	val: 0.665393	test: 0.612990

Epoch: 113
Loss: 0.29791407667815156
ROC train: 0.942482	val: 0.609810	test: 0.553742
PRC train: 0.906985	val: 0.671041	test: 0.613705

Epoch: 114
Loss: 0.29403287155933855
ROC train: 0.943468	val: 0.613181	test: 0.535304
PRC train: 0.910686	val: 0.671052	test: 0.607972

Epoch: 115
Loss: 0.2987826825830052
ROC train: 0.943669	val: 0.604328	test: 0.542865
PRC train: 0.910534	val: 0.667058	test: 0.606044

Epoch: 116
Loss: 0.2977539761659341
ROC train: 0.944069	val: 0.602451	test: 0.549504
PRC train: 0.908284	val: 0.664651	test: 0.607325

Epoch: 117
Loss: 0.2909273795588626
ROC train: 0.946479	val: 0.600678	test: 0.539410
PRC train: 0.911573	val: 0.666633	test: 0.606359

Epoch: 118
Loss: 0.29174592000389976
ROC train: 0.947375	val: 0.599590	test: 0.539628
PRC train: 0.913834	val: 0.663796	test: 0.605718

Epoch: 119
Loss: 0.2925417026760021
ROC train: 0.946788	val: 0.608774	test: 0.550576
PRC train: 0.910810	val: 0.664163	test: 0.606438

Epoch: 120
Loss: 0.289150666595114
ROC train: 0.946519	val: 0.616504	test: 0.544863
PRC train: 0.908731	val: 0.669364	test: 0.606007

Early stopping
Best (ROC):	 train: 0.857287	val: 0.627990	test: 0.562260
Best (PRC):	 train: 0.816206	val: 0.665428	test: 0.613954
All runs completed.

PRC train: 0.879717	val: 0.644113	test: 0.624458

Epoch: 94
Loss: 0.33636515956762997
ROC train: 0.917367	val: 0.593024	test: 0.571511
PRC train: 0.882516	val: 0.643319	test: 0.622223

Epoch: 95
Loss: 0.3293513304113543
ROC train: 0.918650	val: 0.602086	test: 0.579850
PRC train: 0.881972	val: 0.645677	test: 0.628541

Epoch: 96
Loss: 0.33386884738646777
ROC train: 0.918541	val: 0.604206	test: 0.575284
PRC train: 0.880135	val: 0.648757	test: 0.627300

Epoch: 97
Loss: 0.33223952124520545
ROC train: 0.921399	val: 0.608201	test: 0.571784
PRC train: 0.884942	val: 0.650828	test: 0.622731

Epoch: 98
Loss: 0.3249512398268768
ROC train: 0.923212	val: 0.600979	test: 0.583729
PRC train: 0.883551	val: 0.646988	test: 0.626500

Epoch: 99
Loss: 0.32720786742303043
ROC train: 0.924135	val: 0.595007	test: 0.584776
PRC train: 0.886746	val: 0.643251	test: 0.628046

Epoch: 100
Loss: 0.32581945007859925
ROC train: 0.925109	val: 0.600928	test: 0.588762
PRC train: 0.889769	val: 0.648087	test: 0.632545

Epoch: 101
Loss: 0.32926902379810585
ROC train: 0.926524	val: 0.603544	test: 0.588452
PRC train: 0.889377	val: 0.647274	test: 0.630503

Epoch: 102
Loss: 0.32815660851205797
ROC train: 0.927443	val: 0.612644	test: 0.602159
PRC train: 0.891520	val: 0.652479	test: 0.635590

Epoch: 103
Loss: 0.3194519987327901
ROC train: 0.928714	val: 0.591841	test: 0.588586
PRC train: 0.897664	val: 0.644829	test: 0.632030

Epoch: 104
Loss: 0.3225447576789218
ROC train: 0.926785	val: 0.585437	test: 0.572326
PRC train: 0.894856	val: 0.637391	test: 0.626753

Epoch: 105
Loss: 0.3204634773165651
ROC train: 0.929736	val: 0.599758	test: 0.577412
PRC train: 0.897570	val: 0.644411	test: 0.627014

Epoch: 106
Loss: 0.3155619101173061
ROC train: 0.931219	val: 0.612398	test: 0.583749
PRC train: 0.898925	val: 0.653241	test: 0.629878

Epoch: 107
Loss: 0.3163120723619719
ROC train: 0.932944	val: 0.609219	test: 0.588378
PRC train: 0.900520	val: 0.652752	test: 0.629147

Epoch: 108
Loss: 0.3174600210619037
ROC train: 0.933216	val: 0.608975	test: 0.582771
PRC train: 0.900051	val: 0.650030	test: 0.627062

Epoch: 109
Loss: 0.3115298345668595
ROC train: 0.933997	val: 0.608535	test: 0.590046
PRC train: 0.900696	val: 0.647539	test: 0.631231

Epoch: 110
Loss: 0.3144530236565183
ROC train: 0.932952	val: 0.593891	test: 0.582667
PRC train: 0.900609	val: 0.645357	test: 0.632530

Epoch: 111
Loss: 0.31274164107220115
ROC train: 0.931476	val: 0.594853	test: 0.577854
PRC train: 0.899723	val: 0.644037	test: 0.627665

Epoch: 112
Loss: 0.3122240534507644
ROC train: 0.934713	val: 0.592996	test: 0.580316
PRC train: 0.902692	val: 0.645282	test: 0.627721

Epoch: 113
Loss: 0.30826621172402097
ROC train: 0.934341	val: 0.608653	test: 0.578579
PRC train: 0.899897	val: 0.648878	test: 0.628349

Epoch: 114
Loss: 0.3113326585433563
ROC train: 0.937003	val: 0.605865	test: 0.581317
PRC train: 0.903777	val: 0.650020	test: 0.628411

Epoch: 115
Loss: 0.3110439123808486
ROC train: 0.937431	val: 0.580308	test: 0.570453
PRC train: 0.907050	val: 0.643230	test: 0.622843

Epoch: 116
Loss: 0.3079525696201395
ROC train: 0.936973	val: 0.584137	test: 0.566779
PRC train: 0.909632	val: 0.639410	test: 0.618502

Epoch: 117
Loss: 0.30554914306766834
ROC train: 0.940852	val: 0.603674	test: 0.580717
PRC train: 0.913863	val: 0.648379	test: 0.628116

Epoch: 118
Loss: 0.30515722178566645
ROC train: 0.941453	val: 0.600358	test: 0.590163
PRC train: 0.912303	val: 0.646771	test: 0.632539

Epoch: 119
Loss: 0.30381651899364304
ROC train: 0.940941	val: 0.605837	test: 0.603937
PRC train: 0.911938	val: 0.651011	test: 0.637000

Epoch: 120
Loss: 0.305276120143127
ROC train: 0.939490	val: 0.585514	test: 0.589814
PRC train: 0.910317	val: 0.644895	test: 0.625300

Epoch: 121
Loss: 0.3014271191545562
ROC train: 0.942011	val: 0.606648	test: 0.573449
PRC train: 0.912932	val: 0.650736	test: 0.623657

Epoch: 122
Loss: 0.30065014507343274
ROC train: 0.944727	val: 0.605700	test: 0.579580
PRC train: 0.916182	val: 0.651608	test: 0.629552

Epoch: 123
Loss: 0.29585013238507385
ROC train: 0.945868	val: 0.606352	test: 0.589000
PRC train: 0.918964	val: 0.651752	test: 0.630526

Epoch: 124
Loss: 0.29666196572248504
ROC train: 0.944480	val: 0.607272	test: 0.589667
PRC train: 0.915989	val: 0.652609	test: 0.633926

Epoch: 125
Loss: 0.29550624291831085
ROC train: 0.945225	val: 0.606405	test: 0.587894
PRC train: 0.917059	val: 0.650258	test: 0.631085

Epoch: 126
Loss: 0.29674813305024544
ROC train: 0.945895	val: 0.595517	test: 0.580428
PRC train: 0.922327	val: 0.647807	test: 0.628196

Epoch: 127
Loss: 0.2975098230153463
ROC train: 0.945739	val: 0.594501	test: 0.583912
PRC train: 0.920577	val: 0.645107	test: 0.630905

Early stopping
Best (ROC):	 train: 0.913883	val: 0.629014	test: 0.586785
Best (PRC):	 train: 0.874430	val: 0.659417	test: 0.634110

PRC train: 0.832712	val: 0.659289	test: 0.636849

Epoch: 95
Loss: 0.3814919257091817
ROC train: 0.874598	val: 0.612485	test: 0.597605
PRC train: 0.834846	val: 0.662309	test: 0.634293

Epoch: 96
Loss: 0.38891994149443043
ROC train: 0.874297	val: 0.612314	test: 0.617150
PRC train: 0.834855	val: 0.664919	test: 0.638365

Epoch: 97
Loss: 0.37876250657624155
ROC train: 0.879867	val: 0.609988	test: 0.594124
PRC train: 0.835750	val: 0.665130	test: 0.630791

Epoch: 98
Loss: 0.3732357917093063
ROC train: 0.867954	val: 0.587964	test: 0.619393
PRC train: 0.825142	val: 0.656458	test: 0.643991

Epoch: 99
Loss: 0.37534287103048675
ROC train: 0.880713	val: 0.604713	test: 0.601024
PRC train: 0.841722	val: 0.660657	test: 0.639395

Epoch: 100
Loss: 0.3738844406423184
ROC train: 0.883541	val: 0.605867	test: 0.596986
PRC train: 0.842274	val: 0.662408	test: 0.633878

Epoch: 101
Loss: 0.3734827191399702
ROC train: 0.885387	val: 0.607275	test: 0.617673
PRC train: 0.844872	val: 0.661895	test: 0.640213

Epoch: 102
Loss: 0.37736995432840204
ROC train: 0.887568	val: 0.615032	test: 0.619861
PRC train: 0.848174	val: 0.662902	test: 0.644864

Epoch: 103
Loss: 0.3731425564831431
ROC train: 0.887629	val: 0.622325	test: 0.603601
PRC train: 0.850187	val: 0.664997	test: 0.637409

Epoch: 104
Loss: 0.3736863384746588
ROC train: 0.885760	val: 0.617584	test: 0.627126
PRC train: 0.849809	val: 0.665480	test: 0.647299

Epoch: 105
Loss: 0.3758803698660366
ROC train: 0.890463	val: 0.629054	test: 0.619211
PRC train: 0.852407	val: 0.668575	test: 0.647809

Epoch: 106
Loss: 0.37805520159245304
ROC train: 0.886812	val: 0.631218	test: 0.602589
PRC train: 0.847931	val: 0.667409	test: 0.638879

Epoch: 107
Loss: 0.3726333404369452
ROC train: 0.888336	val: 0.603702	test: 0.618611
PRC train: 0.853652	val: 0.662992	test: 0.644688

Epoch: 108
Loss: 0.36788659987660643
ROC train: 0.888493	val: 0.594958	test: 0.598893
PRC train: 0.851571	val: 0.659048	test: 0.636795

Epoch: 109
Loss: 0.3667047611109506
ROC train: 0.888580	val: 0.604002	test: 0.587667
PRC train: 0.852761	val: 0.661545	test: 0.633912

Epoch: 110
Loss: 0.37102662455787777
ROC train: 0.891063	val: 0.604917	test: 0.612427
PRC train: 0.854225	val: 0.664247	test: 0.642782

Epoch: 111
Loss: 0.368919922617199
ROC train: 0.896223	val: 0.609952	test: 0.597332
PRC train: 0.856146	val: 0.664901	test: 0.635844

Epoch: 112
Loss: 0.3645269284918632
ROC train: 0.895556	val: 0.610166	test: 0.599781
PRC train: 0.856876	val: 0.665853	test: 0.636695

Epoch: 113
Loss: 0.36209466384824435
ROC train: 0.894350	val: 0.607968	test: 0.609323
PRC train: 0.859440	val: 0.666736	test: 0.639564

Epoch: 114
Loss: 0.36319649561604184
ROC train: 0.896237	val: 0.611979	test: 0.625104
PRC train: 0.860209	val: 0.665406	test: 0.644834

Epoch: 115
Loss: 0.3618374315952836
ROC train: 0.898260	val: 0.614798	test: 0.626039
PRC train: 0.857772	val: 0.666839	test: 0.647522

Epoch: 116
Loss: 0.36213367247495204
ROC train: 0.899389	val: 0.623217	test: 0.613091
PRC train: 0.862392	val: 0.674280	test: 0.641673

Epoch: 117
Loss: 0.36277024223007154
ROC train: 0.898663	val: 0.620095	test: 0.619387
PRC train: 0.862917	val: 0.669888	test: 0.647424

Epoch: 118
Loss: 0.36125984953098234
ROC train: 0.901022	val: 0.624706	test: 0.606945
PRC train: 0.862803	val: 0.667473	test: 0.640515

Epoch: 119
Loss: 0.3573424412970668
ROC train: 0.902953	val: 0.617737	test: 0.623938
PRC train: 0.864129	val: 0.669875	test: 0.646573

Epoch: 120
Loss: 0.3578560236789635
ROC train: 0.904262	val: 0.622396	test: 0.612720
PRC train: 0.865863	val: 0.673699	test: 0.642235

Epoch: 121
Loss: 0.35736439453813773
ROC train: 0.906496	val: 0.630295	test: 0.602594
PRC train: 0.868088	val: 0.674667	test: 0.636077

Epoch: 122
Loss: 0.35428410180156356
ROC train: 0.904882	val: 0.610322	test: 0.606005
PRC train: 0.867634	val: 0.668244	test: 0.635033

Epoch: 123
Loss: 0.355904590409487
ROC train: 0.904942	val: 0.610734	test: 0.600009
PRC train: 0.865734	val: 0.668966	test: 0.632457

Epoch: 124
Loss: 0.35166326182365476
ROC train: 0.908617	val: 0.611849	test: 0.613630
PRC train: 0.872664	val: 0.668751	test: 0.642137

Epoch: 125
Loss: 0.35337673509070333
ROC train: 0.908053	val: 0.619212	test: 0.613562
PRC train: 0.872451	val: 0.668375	test: 0.640740

Epoch: 126
Loss: 0.34924801676279416
ROC train: 0.911515	val: 0.621417	test: 0.601040
PRC train: 0.874886	val: 0.669273	test: 0.635939

Epoch: 127
Loss: 0.35003656898072216
ROC train: 0.911401	val: 0.619826	test: 0.603926
PRC train: 0.873386	val: 0.671899	test: 0.638747

Epoch: 128
Loss: 0.35418662759177455
ROC train: 0.911549	val: 0.613291	test: 0.601187
PRC train: 0.873441	val: 0.668342	test: 0.634025

Epoch: 129
Loss: 0.349742929154204
ROC train: 0.904218	val: 0.619249	test: 0.592912
PRC train: 0.864956	val: 0.669343	test: 0.632653

Epoch: 130
Loss: 0.3505669995565309
ROC train: 0.909385	val: 0.615509	test: 0.613648
PRC train: 0.872288	val: 0.664105	test: 0.642936

Epoch: 131
Loss: 0.3459130646824361
ROC train: 0.915190	val: 0.615445	test: 0.605002
PRC train: 0.877984	val: 0.667234	test: 0.636554

Epoch: 132
Loss: 0.34846494649238313
ROC train: 0.914617	val: 0.612286	test: 0.607502
PRC train: 0.876782	val: 0.668665	test: 0.637290

Epoch: 133
Loss: 0.34540799542592876
ROC train: 0.910557	val: 0.621153	test: 0.613626
PRC train: 0.873544	val: 0.671032	test: 0.644735

Epoch: 134
Loss: 0.34372440807620286
ROC train: 0.912344	val: 0.622297	test: 0.608914
PRC train: 0.877398	val: 0.671704	test: 0.643252

Epoch: 135
Loss: 0.3415313676660081
ROC train: 0.916514	val: 0.620637	test: 0.607415
PRC train: 0.881208	val: 0.669474	test: 0.642964

Epoch: 136
Loss: 0.33808903886531017
ROC train: 0.917394	val: 0.622758	test: 0.605483
PRC train: 0.879551	val: 0.670368	test: 0.638179

Epoch: 137
Loss: 0.34028405662125405
ROC train: 0.914155	val: 0.614613	test: 0.603342
PRC train: 0.876369	val: 0.668979	test: 0.634121

Epoch: 138
Loss: 0.3365749965649691
ROC train: 0.918337	val: 0.618595	test: 0.618436
PRC train: 0.880974	val: 0.667042	test: 0.645808

Epoch: 139
Loss: 0.33698376196982593
ROC train: 0.918964	val: 0.628247	test: 0.615999
PRC train: 0.882037	val: 0.669653	test: 0.648364

Epoch: 140
Loss: 0.3341473040570938
ROC train: 0.920788	val: 0.627589	test: 0.591920
PRC train: 0.882490	val: 0.677372	test: 0.632449

Epoch: 141
Loss: 0.3335596358957892
ROC train: 0.919241	val: 0.616453	test: 0.606680
PRC train: 0.881973	val: 0.671066	test: 0.639141

Early stopping
Best (ROC):	 train: 0.886812	val: 0.631218	test: 0.602589
Best (PRC):	 train: 0.847931	val: 0.667409	test: 0.638879

PRC train: 0.837034	val: 0.669146	test: 0.640711

Epoch: 95
Loss: 0.38340414389596666
ROC train: 0.882047	val: 0.607274	test: 0.586540
PRC train: 0.840669	val: 0.669627	test: 0.633240

Epoch: 96
Loss: 0.38261424291936846
ROC train: 0.878221	val: 0.603886	test: 0.597696
PRC train: 0.837684	val: 0.667756	test: 0.637649

Epoch: 97
Loss: 0.3801028291944157
ROC train: 0.884502	val: 0.604770	test: 0.601209
PRC train: 0.844778	val: 0.667870	test: 0.634887

Epoch: 98
Loss: 0.37968761737182155
ROC train: 0.884845	val: 0.608612	test: 0.594631
PRC train: 0.843515	val: 0.666598	test: 0.629160

Epoch: 99
Loss: 0.37549788269988216
ROC train: 0.884226	val: 0.608651	test: 0.604977
PRC train: 0.844565	val: 0.667898	test: 0.636604

Epoch: 100
Loss: 0.37833567276186914
ROC train: 0.881224	val: 0.614491	test: 0.595503
PRC train: 0.840551	val: 0.673435	test: 0.632764

Epoch: 101
Loss: 0.3717140611401805
ROC train: 0.886721	val: 0.612093	test: 0.596178
PRC train: 0.846803	val: 0.670272	test: 0.638331

Epoch: 102
Loss: 0.3721515055304246
ROC train: 0.879951	val: 0.611300	test: 0.582612
PRC train: 0.838678	val: 0.665671	test: 0.627841

Epoch: 103
Loss: 0.37131974917355465
ROC train: 0.889688	val: 0.621467	test: 0.597322
PRC train: 0.850580	val: 0.668953	test: 0.636992

Epoch: 104
Loss: 0.37983165346395614
ROC train: 0.881951	val: 0.612879	test: 0.591338
PRC train: 0.843285	val: 0.672076	test: 0.628181

Epoch: 105
Loss: 0.3786589018418726
ROC train: 0.885896	val: 0.611085	test: 0.595517
PRC train: 0.846255	val: 0.670387	test: 0.636619

Epoch: 106
Loss: 0.3770524499423047
ROC train: 0.890283	val: 0.604663	test: 0.587587
PRC train: 0.850474	val: 0.670016	test: 0.633572

Epoch: 107
Loss: 0.3749493379213789
ROC train: 0.886637	val: 0.610888	test: 0.583967
PRC train: 0.849162	val: 0.673892	test: 0.631216

Epoch: 108
Loss: 0.36849057994809187
ROC train: 0.889637	val: 0.608675	test: 0.605153
PRC train: 0.853642	val: 0.669801	test: 0.643696

Epoch: 109
Loss: 0.36956684735063694
ROC train: 0.891875	val: 0.607614	test: 0.585480
PRC train: 0.852728	val: 0.673642	test: 0.626799

Epoch: 110
Loss: 0.36835802106642623
ROC train: 0.890689	val: 0.608103	test: 0.581836
PRC train: 0.851482	val: 0.677111	test: 0.625439

Epoch: 111
Loss: 0.374058564225867
ROC train: 0.893960	val: 0.619214	test: 0.592916
PRC train: 0.856334	val: 0.676819	test: 0.639440

Epoch: 112
Loss: 0.36603954173257935
ROC train: 0.894170	val: 0.623259	test: 0.591256
PRC train: 0.855092	val: 0.677415	test: 0.639907

Epoch: 113
Loss: 0.36142409244098117
ROC train: 0.895570	val: 0.607796	test: 0.606487
PRC train: 0.855933	val: 0.668440	test: 0.652340

Epoch: 114
Loss: 0.35830090949182464
ROC train: 0.898443	val: 0.615658	test: 0.598528
PRC train: 0.861480	val: 0.671576	test: 0.640858

Epoch: 115
Loss: 0.3712365487580783
ROC train: 0.899138	val: 0.617124	test: 0.594664
PRC train: 0.862852	val: 0.674451	test: 0.636215

Epoch: 116
Loss: 0.3559210020624424
ROC train: 0.897624	val: 0.619055	test: 0.592063
PRC train: 0.860118	val: 0.676485	test: 0.633180

Epoch: 117
Loss: 0.360865509963216
ROC train: 0.899961	val: 0.616829	test: 0.593934
PRC train: 0.862998	val: 0.672955	test: 0.634506

Epoch: 118
Loss: 0.3623576762176269
ROC train: 0.901255	val: 0.615203	test: 0.602627
PRC train: 0.864124	val: 0.673345	test: 0.636079

Epoch: 119
Loss: 0.3562451149313676
ROC train: 0.902038	val: 0.629754	test: 0.597348
PRC train: 0.866016	val: 0.675947	test: 0.634381

Epoch: 120
Loss: 0.3582798279799118
ROC train: 0.905081	val: 0.627700	test: 0.609387
PRC train: 0.869627	val: 0.674914	test: 0.645427

Epoch: 121
Loss: 0.3527581279277235
ROC train: 0.906464	val: 0.616384	test: 0.592476
PRC train: 0.870760	val: 0.675426	test: 0.632554

Epoch: 122
Loss: 0.3519081236001568
ROC train: 0.904639	val: 0.607919	test: 0.592828
PRC train: 0.870350	val: 0.672418	test: 0.628789

Epoch: 123
Loss: 0.35341589737221435
ROC train: 0.900977	val: 0.610401	test: 0.598179
PRC train: 0.864893	val: 0.675494	test: 0.637580

Epoch: 124
Loss: 0.35321148233627964
ROC train: 0.903732	val: 0.608641	test: 0.606446
PRC train: 0.869655	val: 0.670664	test: 0.642704

Epoch: 125
Loss: 0.3539874389957215
ROC train: 0.903699	val: 0.608580	test: 0.610600
PRC train: 0.870743	val: 0.667376	test: 0.642478

Epoch: 126
Loss: 0.3574313177265166
ROC train: 0.908701	val: 0.618774	test: 0.595500
PRC train: 0.874658	val: 0.675558	test: 0.636110

Epoch: 127
Loss: 0.35226577449526564
ROC train: 0.908519	val: 0.605646	test: 0.609821
PRC train: 0.875898	val: 0.671377	test: 0.644715

Epoch: 128
Loss: 0.3565324906123042
ROC train: 0.903406	val: 0.617535	test: 0.585237
PRC train: 0.870223	val: 0.675250	test: 0.632680

Epoch: 129
Loss: 0.3462812158666938
ROC train: 0.905832	val: 0.611062	test: 0.603136
PRC train: 0.872419	val: 0.671892	test: 0.639475

Epoch: 130
Loss: 0.34864899287383067
ROC train: 0.911195	val: 0.602950	test: 0.592932
PRC train: 0.877297	val: 0.666817	test: 0.636641

Epoch: 131
Loss: 0.3453916217010683
ROC train: 0.913324	val: 0.614947	test: 0.592105
PRC train: 0.879148	val: 0.669062	test: 0.632934

Epoch: 132
Loss: 0.34830337889110813
ROC train: 0.909941	val: 0.620117	test: 0.589034
PRC train: 0.875687	val: 0.675175	test: 0.628045

Epoch: 133
Loss: 0.348202942552321
ROC train: 0.911195	val: 0.614824	test: 0.571375
PRC train: 0.876241	val: 0.670286	test: 0.622737

Epoch: 134
Loss: 0.34033716999766483
ROC train: 0.913376	val: 0.622834	test: 0.591394
PRC train: 0.881232	val: 0.673320	test: 0.641238

Epoch: 135
Loss: 0.343303809917074
ROC train: 0.916460	val: 0.622272	test: 0.606986
PRC train: 0.884860	val: 0.678962	test: 0.643429

Epoch: 136
Loss: 0.3423939280339945
ROC train: 0.915859	val: 0.611423	test: 0.594366
PRC train: 0.881689	val: 0.673837	test: 0.631693

Epoch: 137
Loss: 0.3418600203943767
ROC train: 0.916751	val: 0.617869	test: 0.598071
PRC train: 0.883556	val: 0.673285	test: 0.635546

Epoch: 138
Loss: 0.341309335294249
ROC train: 0.917478	val: 0.624239	test: 0.588592
PRC train: 0.885617	val: 0.677984	test: 0.634076

Epoch: 139
Loss: 0.33636621583016096
ROC train: 0.918057	val: 0.621595	test: 0.579651
PRC train: 0.887963	val: 0.674730	test: 0.626297

Epoch: 140
Loss: 0.3431563741078489
ROC train: 0.917959	val: 0.619019	test: 0.587783
PRC train: 0.885837	val: 0.674565	test: 0.629293

Epoch: 141
Loss: 0.33307759280353444
ROC train: 0.917356	val: 0.626325	test: 0.590780
PRC train: 0.884746	val: 0.675848	test: 0.631390

Epoch: 142
Loss: 0.33904897533115147
ROC train: 0.919754	val: 0.617701	test: 0.609957
PRC train: 0.891225	val: 0.672684	test: 0.642635

Epoch: 143
Loss: 0.33887192422247353
ROC train: 0.919649	val: 0.603606	test: 0.589216
PRC train: 0.891188	val: 0.668824	test: 0.632632

Epoch: 144
Loss: 0.3368615098275118
ROC train: 0.921980	val: 0.607854	test: 0.584451
PRC train: 0.893076	val: 0.671719	test: 0.625747

Epoch: 145
Loss: 0.3382734226186357
ROC train: 0.919834	val: 0.612432	test: 0.597494
PRC train: 0.891142	val: 0.677005	test: 0.633999

Epoch: 146
Loss: 0.33337184911572215
ROC train: 0.922355	val: 0.621899	test: 0.591328
PRC train: 0.889719	val: 0.682410	test: 0.630761

Epoch: 147
Loss: 0.3369165660985592
ROC train: 0.914596	val: 0.623947	test: 0.588002
PRC train: 0.882542	val: 0.677232	test: 0.628021

Epoch: 148
Loss: 0.3346806090582982
ROC train: 0.922099	val: 0.632478	test: 0.601923
PRC train: 0.887853	val: 0.681198	test: 0.638298

Epoch: 149
Loss: 0.327828121344771
ROC train: 0.923538	val: 0.626495	test: 0.602313
PRC train: 0.889358	val: 0.677397	test: 0.640412

Epoch: 150
Loss: 0.3308321791172825
ROC train: 0.920859	val: 0.619310	test: 0.590680
PRC train: 0.887392	val: 0.678691	test: 0.630120

Epoch: 151
Loss: 0.331445250575319
ROC train: 0.921022	val: 0.608979	test: 0.598956
PRC train: 0.892743	val: 0.674673	test: 0.635868

Epoch: 152
Loss: 0.3282004551464304
ROC train: 0.922692	val: 0.600999	test: 0.586326
PRC train: 0.892644	val: 0.669199	test: 0.628478

Epoch: 153
Loss: 0.327065036475408
ROC train: 0.929014	val: 0.606201	test: 0.578191
PRC train: 0.897847	val: 0.670135	test: 0.622951

Epoch: 154
Loss: 0.32420973359349087
ROC train: 0.925453	val: 0.606746	test: 0.600193
PRC train: 0.894319	val: 0.668099	test: 0.635105

Epoch: 155
Loss: 0.3230836160461941

Epoch: 94
Loss: 0.3231869452190364
ROC train: 0.918231	val: 0.607855	test: 0.569793
PRC train: 0.878462	val: 0.669732	test: 0.614393

Epoch: 95
Loss: 0.32640643067391595
ROC train: 0.917729	val: 0.610412	test: 0.586150
PRC train: 0.879249	val: 0.663627	test: 0.617161

Epoch: 96
Loss: 0.32531920050320656
ROC train: 0.922166	val: 0.618705	test: 0.591460
PRC train: 0.886673	val: 0.671085	test: 0.621221

Epoch: 97
Loss: 0.32132704561858993
ROC train: 0.922779	val: 0.627516	test: 0.570200
PRC train: 0.881845	val: 0.681172	test: 0.617994

Epoch: 98
Loss: 0.3250664247272879
ROC train: 0.923506	val: 0.629247	test: 0.567964
PRC train: 0.880611	val: 0.673727	test: 0.621708

Epoch: 99
Loss: 0.3208142560208524
ROC train: 0.927471	val: 0.631156	test: 0.573735
PRC train: 0.889889	val: 0.678967	test: 0.619436

Epoch: 100
Loss: 0.3213741636964639
ROC train: 0.926255	val: 0.621812	test: 0.574326
PRC train: 0.889741	val: 0.674776	test: 0.615503

Epoch: 101
Loss: 0.31518373416438733
ROC train: 0.926084	val: 0.613499	test: 0.579335
PRC train: 0.892104	val: 0.669350	test: 0.620963

Epoch: 102
Loss: 0.31885530678264684
ROC train: 0.929581	val: 0.617723	test: 0.566002
PRC train: 0.892877	val: 0.670972	test: 0.619080

Epoch: 103
Loss: 0.3121726129568452
ROC train: 0.928876	val: 0.617635	test: 0.568728
PRC train: 0.887649	val: 0.669967	test: 0.616379

Epoch: 104
Loss: 0.314254380723191
ROC train: 0.929777	val: 0.614694	test: 0.572904
PRC train: 0.889190	val: 0.669278	test: 0.615943

Epoch: 105
Loss: 0.31200084164887654
ROC train: 0.929975	val: 0.620857	test: 0.574794
PRC train: 0.892483	val: 0.673981	test: 0.620448

Epoch: 106
Loss: 0.30954182286343185
ROC train: 0.933616	val: 0.631244	test: 0.564042
PRC train: 0.893414	val: 0.679015	test: 0.619883

Epoch: 107
Loss: 0.3134871153591202
ROC train: 0.933257	val: 0.623361	test: 0.579845
PRC train: 0.894697	val: 0.674235	test: 0.618370

Epoch: 108
Loss: 0.3062338056854097
ROC train: 0.933323	val: 0.619464	test: 0.578668
PRC train: 0.897054	val: 0.675909	test: 0.616162

Epoch: 109
Loss: 0.3083682926804184
ROC train: 0.928926	val: 0.610786	test: 0.572656
PRC train: 0.891432	val: 0.669077	test: 0.614906

Epoch: 110
Loss: 0.3157511521180894
ROC train: 0.933422	val: 0.641500	test: 0.575733
PRC train: 0.899616	val: 0.674348	test: 0.621916

Epoch: 111
Loss: 0.30182401572359
ROC train: 0.934133	val: 0.638221	test: 0.574350
PRC train: 0.899138	val: 0.670960	test: 0.618403

Epoch: 112
Loss: 0.30559269956783164
ROC train: 0.937277	val: 0.624583	test: 0.564894
PRC train: 0.896310	val: 0.672113	test: 0.615167

Epoch: 113
Loss: 0.30052784372537483
ROC train: 0.939044	val: 0.613797	test: 0.567622
PRC train: 0.903901	val: 0.670523	test: 0.612435

Epoch: 114
Loss: 0.30092346156135247
ROC train: 0.938332	val: 0.618199	test: 0.561322
PRC train: 0.905695	val: 0.672042	test: 0.610842

Epoch: 115
Loss: 0.29495549170008817
ROC train: 0.940560	val: 0.627753	test: 0.569180
PRC train: 0.905227	val: 0.675578	test: 0.616087

Epoch: 116
Loss: 0.30219480497717627
ROC train: 0.941949	val: 0.637779	test: 0.581523
PRC train: 0.906150	val: 0.677851	test: 0.624129

Epoch: 117
Loss: 0.2961418696783556
ROC train: 0.940697	val: 0.627937	test: 0.577879
PRC train: 0.906276	val: 0.671211	test: 0.621185

Epoch: 118
Loss: 0.2915831957813567
ROC train: 0.942231	val: 0.630971	test: 0.565370
PRC train: 0.907962	val: 0.677844	test: 0.615184

Epoch: 119
Loss: 0.2930315499587933
ROC train: 0.944100	val: 0.633562	test: 0.561527
PRC train: 0.909628	val: 0.672733	test: 0.616411

Epoch: 120
Loss: 0.2940624703330017
ROC train: 0.942561	val: 0.630067	test: 0.558920
PRC train: 0.907330	val: 0.670264	test: 0.610737

Epoch: 121
Loss: 0.28930067465159437
ROC train: 0.945002	val: 0.627367	test: 0.574181
PRC train: 0.913230	val: 0.674866	test: 0.613288

Epoch: 122
Loss: 0.2923988101357641
ROC train: 0.945581	val: 0.621315	test: 0.568810
PRC train: 0.910882	val: 0.674188	test: 0.615292

Epoch: 123
Loss: 0.29254476875104796
ROC train: 0.944031	val: 0.622073	test: 0.568604
PRC train: 0.909149	val: 0.668237	test: 0.615863

Epoch: 124
Loss: 0.2850931309895413
ROC train: 0.947186	val: 0.627570	test: 0.570706
PRC train: 0.916540	val: 0.675208	test: 0.620234

Epoch: 125
Loss: 0.28715203956810614
ROC train: 0.946948	val: 0.616844	test: 0.562437
PRC train: 0.913962	val: 0.668196	test: 0.618635

Epoch: 126
Loss: 0.28158674489435015
ROC train: 0.949813	val: 0.622624	test: 0.578653
PRC train: 0.919116	val: 0.676516	test: 0.618998

Epoch: 127
Loss: 0.2852982887497121
ROC train: 0.951552	val: 0.633550	test: 0.571724
PRC train: 0.921532	val: 0.678100	test: 0.615337

Epoch: 128
Loss: 0.2903693115091233
ROC train: 0.951606	val: 0.636623	test: 0.566391
PRC train: 0.921279	val: 0.678990	test: 0.619625

Epoch: 129
Loss: 0.2829199136693398
ROC train: 0.953346	val: 0.623679	test: 0.575048
PRC train: 0.922118	val: 0.675171	test: 0.621347

Epoch: 130
Loss: 0.27836639746947245
ROC train: 0.953184	val: 0.619276	test: 0.573762
PRC train: 0.917881	val: 0.671876	test: 0.621081

Epoch: 131
Loss: 0.28148696658297506
ROC train: 0.951766	val: 0.626320	test: 0.555557
PRC train: 0.917310	val: 0.674972	test: 0.614530

Epoch: 132
Loss: 0.278187788163565
ROC train: 0.952474	val: 0.627390	test: 0.571395
PRC train: 0.923861	val: 0.671588	test: 0.622988

Epoch: 133
Loss: 0.28157249368451875
ROC train: 0.952381	val: 0.609125	test: 0.573170
PRC train: 0.921483	val: 0.665799	test: 0.615839

Epoch: 134
Loss: 0.2770829594703808
ROC train: 0.953956	val: 0.616791	test: 0.576893
PRC train: 0.923389	val: 0.671059	test: 0.619954

Epoch: 135
Loss: 0.2807357000641966
ROC train: 0.957876	val: 0.610630	test: 0.573462
PRC train: 0.928795	val: 0.669059	test: 0.626728

Epoch: 136
Loss: 0.26988560721810656
ROC train: 0.959076	val: 0.621433	test: 0.570390
PRC train: 0.930873	val: 0.672928	test: 0.623670

Epoch: 137
Loss: 0.26906969949440374
ROC train: 0.958704	val: 0.628244	test: 0.567596
PRC train: 0.928940	val: 0.674415	test: 0.618360

Epoch: 138
Loss: 0.27547899615562843
ROC train: 0.958181	val: 0.619895	test: 0.552638
PRC train: 0.928778	val: 0.670783	test: 0.614131

Epoch: 139
Loss: 0.26463339683643683
ROC train: 0.959039	val: 0.613564	test: 0.579473
PRC train: 0.929318	val: 0.667459	test: 0.624503

Epoch: 140
Loss: 0.27180496945661015
ROC train: 0.960581	val: 0.611792	test: 0.574256
PRC train: 0.930606	val: 0.667436	test: 0.621811

Epoch: 141
Loss: 0.2672186977644115
ROC train: 0.959382	val: 0.615160	test: 0.572872
PRC train: 0.932010	val: 0.669175	test: 0.625882

Epoch: 142
Loss: 0.2670440881445109
ROC train: 0.960621	val: 0.625700	test: 0.568368
PRC train: 0.936569	val: 0.674996	test: 0.622017

Epoch: 143
Loss: 0.26445925741663834
ROC train: 0.959590	val: 0.598401	test: 0.567099
PRC train: 0.932332	val: 0.658103	test: 0.616021

Epoch: 144
Loss: 0.2678982609506454
ROC train: 0.962776	val: 0.611699	test: 0.551997
PRC train: 0.935328	val: 0.668242	test: 0.609049

Epoch: 145
Loss: 0.2613197763987681
ROC train: 0.963501	val: 0.620781	test: 0.559330
PRC train: 0.937558	val: 0.670272	test: 0.617840

Early stopping
Best (ROC):	 train: 0.933422	val: 0.641500	test: 0.575733
Best (PRC):	 train: 0.899616	val: 0.674348	test: 0.621916


Epoch: 94
Loss: 0.3394276046410082
ROC train: 0.910454	val: 0.597338	test: 0.593324
PRC train: 0.869486	val: 0.661022	test: 0.628900

Epoch: 95
Loss: 0.34398552896706913
ROC train: 0.910858	val: 0.616014	test: 0.606825
PRC train: 0.872055	val: 0.664960	test: 0.639954

Epoch: 96
Loss: 0.3368261830478995
ROC train: 0.913312	val: 0.614444	test: 0.596249
PRC train: 0.871235	val: 0.666850	test: 0.637768

Epoch: 97
Loss: 0.3353587866194088
ROC train: 0.915257	val: 0.600164	test: 0.574142
PRC train: 0.870281	val: 0.662116	test: 0.625805

Epoch: 98
Loss: 0.33796652313693726
ROC train: 0.912125	val: 0.597482	test: 0.574705
PRC train: 0.867768	val: 0.659368	test: 0.621731

Epoch: 99
Loss: 0.3413255056705918
ROC train: 0.917431	val: 0.615381	test: 0.580981
PRC train: 0.875069	val: 0.667532	test: 0.632167

Epoch: 100
Loss: 0.3354006778342591
ROC train: 0.919469	val: 0.616218	test: 0.591332
PRC train: 0.879298	val: 0.665528	test: 0.635342

Epoch: 101
Loss: 0.32973940118415357
ROC train: 0.920066	val: 0.610565	test: 0.578161
PRC train: 0.879504	val: 0.669150	test: 0.632756

Epoch: 102
Loss: 0.3339232216194735
ROC train: 0.918761	val: 0.610621	test: 0.585522
PRC train: 0.875530	val: 0.667545	test: 0.631744

Epoch: 103
Loss: 0.33091537112191866
ROC train: 0.920746	val: 0.624356	test: 0.568424
PRC train: 0.878278	val: 0.671710	test: 0.628733

Epoch: 104
Loss: 0.33593196405357806
ROC train: 0.920251	val: 0.609942	test: 0.581893
PRC train: 0.880113	val: 0.668582	test: 0.633550

Epoch: 105
Loss: 0.3277789852825463
ROC train: 0.919616	val: 0.595130	test: 0.593392
PRC train: 0.875805	val: 0.664069	test: 0.634146

Epoch: 106
Loss: 0.3253132648780569
ROC train: 0.919560	val: 0.610636	test: 0.591007
PRC train: 0.878215	val: 0.663863	test: 0.632034

Epoch: 107
Loss: 0.3269012439009913
ROC train: 0.923040	val: 0.604596	test: 0.582366
PRC train: 0.883538	val: 0.662554	test: 0.627423

Epoch: 108
Loss: 0.319557362144531
ROC train: 0.917080	val: 0.591937	test: 0.571683
PRC train: 0.877120	val: 0.659548	test: 0.620443

Epoch: 109
Loss: 0.3215519442619047
ROC train: 0.924123	val: 0.615192	test: 0.571669
PRC train: 0.885754	val: 0.665411	test: 0.625611

Epoch: 110
Loss: 0.3267229099348239
ROC train: 0.923701	val: 0.626554	test: 0.574345
PRC train: 0.886722	val: 0.671949	test: 0.628242

Epoch: 111
Loss: 0.3222176488885101
ROC train: 0.927312	val: 0.628323	test: 0.594404
PRC train: 0.889878	val: 0.670389	test: 0.634987

Epoch: 112
Loss: 0.3248282351875265
ROC train: 0.924543	val: 0.624239	test: 0.586418
PRC train: 0.884482	val: 0.668407	test: 0.633986

Epoch: 113
Loss: 0.3207613203458143
ROC train: 0.929641	val: 0.621155	test: 0.586064
PRC train: 0.890343	val: 0.668923	test: 0.633849

Epoch: 114
Loss: 0.32034243775460725
ROC train: 0.928119	val: 0.621094	test: 0.560200
PRC train: 0.887342	val: 0.672086	test: 0.624435

Epoch: 115
Loss: 0.31624735983045255
ROC train: 0.928512	val: 0.618812	test: 0.564855
PRC train: 0.888126	val: 0.667355	test: 0.625780

Epoch: 116
Loss: 0.3180777454699527
ROC train: 0.931545	val: 0.619156	test: 0.577952
PRC train: 0.892495	val: 0.667365	test: 0.629429

Epoch: 117
Loss: 0.3151154322382463
ROC train: 0.933540	val: 0.621801	test: 0.595370
PRC train: 0.896169	val: 0.669701	test: 0.636009

Epoch: 118
Loss: 0.3128354879963158
ROC train: 0.931592	val: 0.637006	test: 0.590859
PRC train: 0.894145	val: 0.674264	test: 0.638052

Epoch: 119
Loss: 0.31409647718554456
ROC train: 0.935828	val: 0.628297	test: 0.581204
PRC train: 0.899196	val: 0.670603	test: 0.631910

Epoch: 120
Loss: 0.308606379969419
ROC train: 0.934639	val: 0.623986	test: 0.576607
PRC train: 0.895920	val: 0.662840	test: 0.630795

Epoch: 121
Loss: 0.3132393718836216
ROC train: 0.936605	val: 0.621801	test: 0.584647
PRC train: 0.900335	val: 0.663454	test: 0.630657

Epoch: 122
Loss: 0.30558526743032915
ROC train: 0.937226	val: 0.609953	test: 0.592728
PRC train: 0.902311	val: 0.661521	test: 0.631979

Epoch: 123
Loss: 0.3060061877199322
ROC train: 0.938955	val: 0.615693	test: 0.582891
PRC train: 0.905129	val: 0.666921	test: 0.632596

Epoch: 124
Loss: 0.3039729715037463
ROC train: 0.937554	val: 0.624621	test: 0.591967
PRC train: 0.904008	val: 0.670214	test: 0.638422

Epoch: 125
Loss: 0.3043716626648612
ROC train: 0.937148	val: 0.618893	test: 0.577813
PRC train: 0.902530	val: 0.666282	test: 0.630860

Epoch: 126
Loss: 0.3040131702662238
ROC train: 0.939203	val: 0.612217	test: 0.571781
PRC train: 0.905161	val: 0.661711	test: 0.624851

Epoch: 127
Loss: 0.30034009489542945
ROC train: 0.938650	val: 0.610065	test: 0.578752
PRC train: 0.905956	val: 0.663926	test: 0.624244

Epoch: 128
Loss: 0.3091541383633478
ROC train: 0.939845	val: 0.604109	test: 0.587471
PRC train: 0.904067	val: 0.661843	test: 0.635462

Epoch: 129
Loss: 0.30054079095305203
ROC train: 0.938201	val: 0.601060	test: 0.582432
PRC train: 0.900671	val: 0.655811	test: 0.635978

Epoch: 130
Loss: 0.3000466469890521
ROC train: 0.941706	val: 0.615017	test: 0.596174
PRC train: 0.909349	val: 0.663099	test: 0.640203

Epoch: 131
Loss: 0.3038039468538853
ROC train: 0.941828	val: 0.619027	test: 0.589711
PRC train: 0.913139	val: 0.667165	test: 0.633593

Epoch: 132
Loss: 0.3012445225955313
ROC train: 0.944555	val: 0.625920	test: 0.593214
PRC train: 0.915831	val: 0.668338	test: 0.639325

Epoch: 133
Loss: 0.3020633478396187
ROC train: 0.944200	val: 0.626695	test: 0.587260
PRC train: 0.914321	val: 0.666898	test: 0.640878

Epoch: 134
Loss: 0.29645294093184266
ROC train: 0.945994	val: 0.612684	test: 0.576249
PRC train: 0.917769	val: 0.664840	test: 0.634661

Epoch: 135
Loss: 0.2939559757077174
ROC train: 0.946473	val: 0.615949	test: 0.579484
PRC train: 0.915715	val: 0.665852	test: 0.636570

Epoch: 136
Loss: 0.28904117200013973
ROC train: 0.946009	val: 0.614766	test: 0.597916
PRC train: 0.915403	val: 0.662298	test: 0.638778

Epoch: 137
Loss: 0.29040124008453466
ROC train: 0.949960	val: 0.615920	test: 0.596550
PRC train: 0.921786	val: 0.665488	test: 0.643510

Epoch: 138
Loss: 0.29803885820219045
ROC train: 0.948159	val: 0.612610	test: 0.580090
PRC train: 0.921223	val: 0.662639	test: 0.632992

Epoch: 139
Loss: 0.28550696148301874
ROC train: 0.947638	val: 0.606732	test: 0.586475
PRC train: 0.922057	val: 0.662802	test: 0.634814

Epoch: 140
Loss: 0.2855898362313275
ROC train: 0.949961	val: 0.615430	test: 0.582670
PRC train: 0.926038	val: 0.661538	test: 0.631415

Epoch: 141
Loss: 0.2860423326000753
ROC train: 0.952205	val: 0.621138	test: 0.577754
PRC train: 0.928326	val: 0.666427	test: 0.631369

Epoch: 142
Loss: 0.2855163397742747
ROC train: 0.951740	val: 0.614332	test: 0.585541
PRC train: 0.925697	val: 0.660126	test: 0.636439

Epoch: 143
Loss: 0.29065847284831825
ROC train: 0.953124	val: 0.607452	test: 0.585819
PRC train: 0.927289	val: 0.658897	test: 0.635622

Epoch: 144
Loss: 0.28322547171825596
ROC train: 0.952030	val: 0.610242	test: 0.582662
PRC train: 0.927677	val: 0.659766	test: 0.628917

Epoch: 145
Loss: 0.27912876018829774
ROC train: 0.952473	val: 0.621550	test: 0.589044
PRC train: 0.926598	val: 0.664198	test: 0.637504

Epoch: 146
Loss: 0.28596552626532035
ROC train: 0.955954	val: 0.622388	test: 0.583280
PRC train: 0.930029	val: 0.666244	test: 0.634749

Epoch: 147
Loss: 0.2769372098175985
ROC train: 0.956400	val: 0.625364	test: 0.597355
PRC train: 0.933614	val: 0.667949	test: 0.640959

Epoch: 148
Loss: 0.27951991191195996
ROC train: 0.954227	val: 0.626084	test: 0.583825
PRC train: 0.929284	val: 0.672180	test: 0.638644

Epoch: 149
Loss: 0.2769623402372058
ROC train: 0.954447	val: 0.621474	test: 0.590356
PRC train: 0.929231	val: 0.666090	test: 0.633917

Epoch: 150
Loss: 0.2761930571108279
ROC train: 0.956764	val: 0.625307	test: 0.588552
PRC train: 0.933128	val: 0.667896	test: 0.635703

Epoch: 151
Loss: 0.2745064084327947
ROC train: 0.957771	val: 0.623916	test: 0.585005
PRC train: 0.931575	val: 0.667389	test: 0.639173

Epoch: 152
Loss: 0.2763384178094329
ROC train: 0.952640	val: 0.606796	test: 0.594250
PRC train: 0.925101	val: 0.661382	test: 0.632550

Epoch: 153
Loss: 0.27391352821093967
ROC train: 0.960353	val: 0.613636	test: 0.581999
PRC train: 0.937961	val: 0.666926	test: 0.633314

Early stopping
Best (ROC):	 train: 0.931592	val: 0.637006	test: 0.590859
Best (PRC):	 train: 0.894145	val: 0.674264	test: 0.638052
All runs completed.
All runs completed.

ROC train: 0.929309	val: 0.615045	test: 0.614121
PRC train: 0.899020	val: 0.671663	test: 0.644488

Epoch: 156
Loss: 0.328931751184567
ROC train: 0.931555	val: 0.614476	test: 0.602531
PRC train: 0.901229	val: 0.677987	test: 0.635224

Epoch: 157
Loss: 0.3248123204315557
ROC train: 0.930002	val: 0.608586	test: 0.605156
PRC train: 0.900832	val: 0.677332	test: 0.638416

Epoch: 158
Loss: 0.3202646613382748
ROC train: 0.929333	val: 0.605356	test: 0.598895
PRC train: 0.900597	val: 0.670201	test: 0.636367

Epoch: 159
Loss: 0.3222584309882571
ROC train: 0.929603	val: 0.616507	test: 0.610368
PRC train: 0.901200	val: 0.674413	test: 0.642524

Epoch: 160
Loss: 0.32443136608672224
ROC train: 0.931451	val: 0.624986	test: 0.604819
PRC train: 0.900164	val: 0.678012	test: 0.646045

Epoch: 161
Loss: 0.3269165810442856
ROC train: 0.934717	val: 0.625651	test: 0.594703
PRC train: 0.904634	val: 0.678622	test: 0.635704

Epoch: 162
Loss: 0.3214335377622349
ROC train: 0.933903	val: 0.608011	test: 0.591292
PRC train: 0.905613	val: 0.676095	test: 0.629694

Epoch: 163
Loss: 0.3226016234536628
ROC train: 0.934905	val: 0.604423	test: 0.593870
PRC train: 0.905251	val: 0.673818	test: 0.634903

Epoch: 164
Loss: 0.32138426847006807
ROC train: 0.934163	val: 0.604053	test: 0.590800
PRC train: 0.902706	val: 0.671423	test: 0.639697

Epoch: 165
Loss: 0.3139328190492054
ROC train: 0.936955	val: 0.613658	test: 0.592381
PRC train: 0.908194	val: 0.677107	test: 0.639395

Epoch: 166
Loss: 0.30955659345227826
ROC train: 0.937197	val: 0.602606	test: 0.592241
PRC train: 0.907878	val: 0.675081	test: 0.641242

Epoch: 167
Loss: 0.3177629084758914
ROC train: 0.937078	val: 0.603012	test: 0.598389
PRC train: 0.909766	val: 0.672511	test: 0.640514

Epoch: 168
Loss: 0.30980073745221404
ROC train: 0.937881	val: 0.614510	test: 0.592555
PRC train: 0.910131	val: 0.677498	test: 0.630587

Epoch: 169
Loss: 0.31768406017744677
ROC train: 0.939706	val: 0.622783	test: 0.589911
PRC train: 0.911733	val: 0.678845	test: 0.631889

Epoch: 170
Loss: 0.3112264338711942
ROC train: 0.939289	val: 0.615559	test: 0.606363
PRC train: 0.913295	val: 0.675547	test: 0.641122

Epoch: 171
Loss: 0.3125993563360349
ROC train: 0.935201	val: 0.615010	test: 0.596724
PRC train: 0.906252	val: 0.676509	test: 0.636784

Epoch: 172
Loss: 0.3078043844900968
ROC train: 0.940702	val: 0.629480	test: 0.605325
PRC train: 0.912553	val: 0.682467	test: 0.643812

Epoch: 173
Loss: 0.311406570053414
ROC train: 0.941503	val: 0.632133	test: 0.600900
PRC train: 0.916085	val: 0.683015	test: 0.636986

Epoch: 174
Loss: 0.3094324081018246
ROC train: 0.939262	val: 0.626682	test: 0.599953
PRC train: 0.912380	val: 0.679608	test: 0.636789

Epoch: 175
Loss: 0.3080689663502341
ROC train: 0.939488	val: 0.615108	test: 0.596019
PRC train: 0.914952	val: 0.674342	test: 0.637659

Epoch: 176
Loss: 0.3117183086736368
ROC train: 0.941322	val: 0.615366	test: 0.578428
PRC train: 0.918136	val: 0.675627	test: 0.622519

Epoch: 177
Loss: 0.30006965445504175
ROC train: 0.942243	val: 0.618204	test: 0.586948
PRC train: 0.918881	val: 0.676093	test: 0.626171

Epoch: 178
Loss: 0.3094544519807406
ROC train: 0.939621	val: 0.619729	test: 0.602965
PRC train: 0.913215	val: 0.678068	test: 0.638242

Epoch: 179
Loss: 0.29687666120194817
ROC train: 0.944279	val: 0.613881	test: 0.595040
PRC train: 0.919987	val: 0.675620	test: 0.633217

Epoch: 180
Loss: 0.2999669589917715
ROC train: 0.946421	val: 0.611804	test: 0.597261
PRC train: 0.923326	val: 0.674502	test: 0.631748

Epoch: 181
Loss: 0.2987440474122366
ROC train: 0.945796	val: 0.615270	test: 0.604115
PRC train: 0.922930	val: 0.672973	test: 0.637581

Epoch: 182
Loss: 0.30851976560086447
ROC train: 0.945458	val: 0.608470	test: 0.592193
PRC train: 0.922411	val: 0.672493	test: 0.632336

Epoch: 183
Loss: 0.30265710668074286
ROC train: 0.942699	val: 0.626145	test: 0.571040
PRC train: 0.918444	val: 0.679229	test: 0.623347

Early stopping
Best (ROC):	 train: 0.922099	val: 0.632478	test: 0.601923
Best (PRC):	 train: 0.887853	val: 0.681198	test: 0.638298
All runs completed.
