>>> Starting run for dataset: hiv
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running RANDOM configs_split_experiments/GraphMVP/hiv/random/train_prop=0.6.yml on cuda:0
Running RANDOM configs_split_experiments/GraphMVP/hiv/random/train_prop=0.7.yml on cuda:1
Running RANDOM configs_split_experiments/GraphMVP/hiv/random/train_prop=0.8.yml on cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/hiv/random/train_prop=0.8.yml --runseed 4 --device cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/hiv/random/train_prop=0.6.yml --runseed 4 --device cuda:0
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/hiv/random/train_prop=0.8.yml --runseed 5 --device cuda:2
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/hiv/random/train_prop=0.6.yml --runseed 5 --device cuda:0
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/hiv/random/train_prop=0.8.yml --runseed 6 --device cuda:2
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/hiv/random/train_prop=0.6.yml --runseed 6 --device cuda:0
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/hiv/random/train_prop=0.7.yml --runseed 4 --device cuda:1
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/hiv/random/train_prop=0.7.yml --runseed 5 --device cuda:1
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/hiv/random/train_prop=0.7.yml --runseed 6 --device cuda:1
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/hiv/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/hiv/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/hiv/random/train_prop=0.6/hiv_random_6_26-05_11-07-15  ]
[ Using Seed :  6  ]
[ Using device :  cuda:0  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
randomly split
Data(edge_attr=[84, 2], edge_index=[2, 84], id=[1], x=[39, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.3028433877785036
ROC train: 0.743300	val: 0.723486	test: 0.734267
PRC train: 0.186557	val: 0.194165	test: 0.223406

Epoch: 2
Loss: 0.13610499415518917
ROC train: 0.788230	val: 0.742378	test: 0.783919
PRC train: 0.257441	val: 0.263135	test: 0.279659

Epoch: 3
Loss: 0.13028652593488482
ROC train: 0.797937	val: 0.743511	test: 0.778085
PRC train: 0.277613	val: 0.250238	test: 0.321053

Epoch: 4
Loss: 0.1257121954247694
ROC train: 0.812054	val: 0.762018	test: 0.806231
PRC train: 0.311197	val: 0.283416	test: 0.335950

Epoch: 5
Loss: 0.12379238276461543
ROC train: 0.823559	val: 0.762956	test: 0.800391
PRC train: 0.345736	val: 0.313085	test: 0.371923

Epoch: 6
Loss: 0.12145960143280009
ROC train: 0.821693	val: 0.756054	test: 0.801318
PRC train: 0.329483	val: 0.279366	test: 0.356260

Epoch: 7
Loss: 0.11812189945082427
ROC train: 0.834544	val: 0.771904	test: 0.813498
PRC train: 0.354428	val: 0.287435	test: 0.363963

Epoch: 8
Loss: 0.11847771052697699
ROC train: 0.825825	val: 0.767995	test: 0.800261
PRC train: 0.352754	val: 0.283922	test: 0.343841

Epoch: 9
Loss: 0.11593721545233318
ROC train: 0.843607	val: 0.786286	test: 0.823906
PRC train: 0.402540	val: 0.336726	test: 0.410956

Epoch: 10
Loss: 0.113935017744837
ROC train: 0.843328	val: 0.760425	test: 0.809810
PRC train: 0.408612	val: 0.352358	test: 0.411251

Epoch: 11
Loss: 0.11420576762579927
ROC train: 0.854427	val: 0.784082	test: 0.812303
PRC train: 0.389658	val: 0.320004	test: 0.383265

Epoch: 12
Loss: 0.11574683532744946
ROC train: 0.854396	val: 0.775749	test: 0.813089
PRC train: 0.411925	val: 0.329421	test: 0.410325

Epoch: 13
Loss: 0.11182561091258922
ROC train: 0.860896	val: 0.779691	test: 0.827831
PRC train: 0.408776	val: 0.307641	test: 0.417041

Epoch: 14
Loss: 0.10981471053622971
ROC train: 0.867742	val: 0.766734	test: 0.822681
PRC train: 0.448478	val: 0.347935	test: 0.431049

Epoch: 15
Loss: 0.1094166881801862
ROC train: 0.873622	val: 0.774949	test: 0.815706
PRC train: 0.463748	val: 0.378960	test: 0.438352

Epoch: 16
Loss: 0.10984579096911389
ROC train: 0.872737	val: 0.791874	test: 0.817365
PRC train: 0.458217	val: 0.358019	test: 0.419433

Epoch: 17
Loss: 0.10864747978377766
ROC train: 0.884594	val: 0.786568	test: 0.816871
PRC train: 0.482128	val: 0.352054	test: 0.445085

Epoch: 18
Loss: 0.10938995602207657
ROC train: 0.882251	val: 0.783614	test: 0.828134
PRC train: 0.466658	val: 0.346442	test: 0.426450

Epoch: 19
Loss: 0.10804043275163776
ROC train: 0.882532	val: 0.778699	test: 0.817188
PRC train: 0.468517	val: 0.339160	test: 0.431591

Epoch: 20
Loss: 0.10727469640509785
ROC train: 0.885527	val: 0.789402	test: 0.818526
PRC train: 0.464572	val: 0.343706	test: 0.416905

Epoch: 21
Loss: 0.10639895123074941
ROC train: 0.891372	val: 0.772977	test: 0.820525
PRC train: 0.482752	val: 0.338172	test: 0.436536

Epoch: 22
Loss: 0.10406953173690633
ROC train: 0.891869	val: 0.784594	test: 0.818426
PRC train: 0.499286	val: 0.359359	test: 0.440854

Epoch: 23
Loss: 0.10334568567579015
ROC train: 0.898041	val: 0.784174	test: 0.827394
PRC train: 0.510937	val: 0.359467	test: 0.439709

Epoch: 24
Loss: 0.10323739045406267
ROC train: 0.896380	val: 0.784954	test: 0.826559
PRC train: 0.487065	val: 0.324433	test: 0.439373

Epoch: 25
Loss: 0.1021784294824377
ROC train: 0.881946	val: 0.787328	test: 0.810674
PRC train: 0.467009	val: 0.330837	test: 0.395668

Epoch: 26
Loss: 0.10336796904688204
ROC train: 0.896625	val: 0.784425	test: 0.826768
PRC train: 0.521546	val: 0.375814	test: 0.454891

Epoch: 27
Loss: 0.10180533193385866
ROC train: 0.909288	val: 0.779187	test: 0.821996
PRC train: 0.543558	val: 0.393761	test: 0.460822

Epoch: 28
Loss: 0.10049709252169574
ROC train: 0.900477	val: 0.779967	test: 0.820302
PRC train: 0.543520	val: 0.365196	test: 0.466218

Epoch: 29
Loss: 0.10279713772553851
ROC train: 0.905435	val: 0.793022	test: 0.831287
PRC train: 0.517629	val: 0.370218	test: 0.459515

Epoch: 30
Loss: 0.09936530501107484
ROC train: 0.904858	val: 0.782388	test: 0.824432
PRC train: 0.521495	val: 0.347896	test: 0.440320

Epoch: 31
Loss: 0.09732300081699974
ROC train: 0.908452	val: 0.781887	test: 0.824865
PRC train: 0.546044	val: 0.350683	test: 0.434080

Epoch: 32
Loss: 0.10016286847121542
ROC train: 0.914515	val: 0.787480	test: 0.837745
PRC train: 0.554950	val: 0.358862	test: 0.466454

Epoch: 33
Loss: 0.10032401804028361Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/hiv/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/hiv/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/hiv/random/train_prop=0.6/hiv_random_4_26-05_11-07-15  ]
[ Using Seed :  4  ]
[ Using device :  cuda:0  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
randomly split
Data(edge_attr=[84, 2], edge_index=[2, 84], id=[1], x=[39, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.32201327905798277
ROC train: 0.689853	val: 0.661007	test: 0.700112
PRC train: 0.130407	val: 0.147660	test: 0.151600

Epoch: 2
Loss: 0.1369807853597508
ROC train: 0.764021	val: 0.707184	test: 0.763600
PRC train: 0.203454	val: 0.201812	test: 0.244878

Epoch: 3
Loss: 0.12853518863889232
ROC train: 0.792225	val: 0.754464	test: 0.768054
PRC train: 0.264206	val: 0.237784	test: 0.294657

Epoch: 4
Loss: 0.12733963825147993
ROC train: 0.814558	val: 0.760128	test: 0.785538
PRC train: 0.337860	val: 0.291886	test: 0.360039

Epoch: 5
Loss: 0.12308305826102878
ROC train: 0.834431	val: 0.757872	test: 0.791067
PRC train: 0.361314	val: 0.305588	test: 0.374256

Epoch: 6
Loss: 0.12022303285465398
ROC train: 0.825244	val: 0.771019	test: 0.791744
PRC train: 0.349738	val: 0.317533	test: 0.337424

Epoch: 7
Loss: 0.11821658486650401
ROC train: 0.835248	val: 0.755978	test: 0.805372
PRC train: 0.392764	val: 0.323126	test: 0.373438

Epoch: 8
Loss: 0.11822809103887397
ROC train: 0.830842	val: 0.753581	test: 0.800925
PRC train: 0.384769	val: 0.298095	test: 0.382049

Epoch: 9
Loss: 0.1171941561190473
ROC train: 0.833576	val: 0.773848	test: 0.802430
PRC train: 0.369700	val: 0.304976	test: 0.365398

Epoch: 10
Loss: 0.11496694971778373
ROC train: 0.852793	val: 0.765002	test: 0.799312
PRC train: 0.406137	val: 0.322672	test: 0.387720

Epoch: 11
Loss: 0.11519137712150261
ROC train: 0.852264	val: 0.774445	test: 0.812833
PRC train: 0.425505	val: 0.337660	test: 0.410667

Epoch: 12
Loss: 0.11268745299174161
ROC train: 0.851179	val: 0.774338	test: 0.809506
PRC train: 0.430201	val: 0.335773	test: 0.398504

Epoch: 13
Loss: 0.11247333212904925
ROC train: 0.866699	val: 0.766937	test: 0.809338
PRC train: 0.447879	val: 0.327616	test: 0.425270

Epoch: 14
Loss: 0.11205697809727622
ROC train: 0.869101	val: 0.779753	test: 0.816173
PRC train: 0.458375	val: 0.328307	test: 0.418688

Epoch: 15
Loss: 0.11123215252787326
ROC train: 0.869615	val: 0.764146	test: 0.804410
PRC train: 0.448310	val: 0.329325	test: 0.422429

Epoch: 16
Loss: 0.11052679014139136
ROC train: 0.872271	val: 0.774963	test: 0.811821
PRC train: 0.471440	val: 0.344725	test: 0.427172

Epoch: 17
Loss: 0.10906401341214118
ROC train: 0.866493	val: 0.772462	test: 0.806702
PRC train: 0.461240	val: 0.344761	test: 0.429543

Epoch: 18
Loss: 0.10948150324724268
ROC train: 0.875547	val: 0.781503	test: 0.821363
PRC train: 0.483248	val: 0.362662	test: 0.444507

Epoch: 19
Loss: 0.1066872320156013
ROC train: 0.877890	val: 0.770676	test: 0.811113
PRC train: 0.483364	val: 0.347946	test: 0.427265

Epoch: 20
Loss: 0.1061365045767546
ROC train: 0.881054	val: 0.780316	test: 0.825310
PRC train: 0.491967	val: 0.362662	test: 0.433579

Epoch: 21
Loss: 0.10645804151938486
ROC train: 0.879649	val: 0.766003	test: 0.818993
PRC train: 0.496333	val: 0.358332	test: 0.445348

Epoch: 22
Loss: 0.10531851895902296
ROC train: 0.881642	val: 0.768105	test: 0.815798
PRC train: 0.485773	val: 0.357690	test: 0.429119

Epoch: 23
Loss: 0.1054543813930722
ROC train: 0.888231	val: 0.785281	test: 0.813183
PRC train: 0.493344	val: 0.352706	test: 0.414226

Epoch: 24
Loss: 0.10502255151523711
ROC train: 0.894139	val: 0.782897	test: 0.829933
PRC train: 0.506570	val: 0.363429	test: 0.437148

Epoch: 25
Loss: 0.10226084070326155
ROC train: 0.898591	val: 0.777601	test: 0.813968
PRC train: 0.528547	val: 0.369563	test: 0.450143

Epoch: 26
Loss: 0.10311638025261388
ROC train: 0.901181	val: 0.769061	test: 0.823683
PRC train: 0.517170	val: 0.335864	test: 0.440629

Epoch: 27
Loss: 0.10154372205886358
ROC train: 0.895417	val: 0.781300	test: 0.821526
PRC train: 0.524763	val: 0.365703	test: 0.433701

Epoch: 28
Loss: 0.10089798157340998
ROC train: 0.910711	val: 0.780012	test: 0.831733
PRC train: 0.549311	val: 0.376734	test: 0.456798

Epoch: 29
Loss: 0.10031659430718926
ROC train: 0.904013	val: 0.773746	test: 0.818344
PRC train: 0.511662	val: 0.377642	test: 0.423363

Epoch: 30
Loss: 0.10116764922270938
ROC train: 0.912398	val: 0.788887	test: 0.825298
PRC train: 0.559012	val: 0.383306	test: 0.444576

Epoch: 31
Loss: 0.10123553755670937
ROC train: 0.907545	val: 0.778125	test: 0.826330
PRC train: 0.536727	val: 0.369745	test: 0.434046

Epoch: 32
Loss: 0.0992586883842744
ROC train: 0.910258	val: 0.781200	test: 0.826904
PRC train: 0.543331	val: 0.368302	test: 0.433684

Epoch: 33
Loss: 0.09946205705915451Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/hiv/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/hiv/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/hiv/random/train_prop=0.6/hiv_random_5_26-05_11-07-15  ]
[ Using Seed :  5  ]
[ Using device :  cuda:0  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
randomly split
Data(edge_attr=[84, 2], edge_index=[2, 84], id=[1], x=[39, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.30783002494738676
ROC train: 0.760932	val: 0.731730	test: 0.756689
PRC train: 0.206142	val: 0.216200	test: 0.225929

Epoch: 2
Loss: 0.1371900859575456
ROC train: 0.765169	val: 0.705275	test: 0.749446
PRC train: 0.189563	val: 0.191829	test: 0.229724

Epoch: 3
Loss: 0.12822864375004758
ROC train: 0.781590	val: 0.762158	test: 0.767817
PRC train: 0.262078	val: 0.267251	test: 0.276288

Epoch: 4
Loss: 0.12606744414315196
ROC train: 0.802296	val: 0.748983	test: 0.783606
PRC train: 0.324909	val: 0.297615	test: 0.336706

Epoch: 5
Loss: 0.12354882304422823
ROC train: 0.818500	val: 0.757745	test: 0.788620
PRC train: 0.346103	val: 0.306416	test: 0.356980

Epoch: 6
Loss: 0.12119947048227828
ROC train: 0.799520	val: 0.740719	test: 0.781825
PRC train: 0.297762	val: 0.259431	test: 0.328539

Epoch: 7
Loss: 0.12016795264737279
ROC train: 0.827279	val: 0.756900	test: 0.791195
PRC train: 0.359574	val: 0.318712	test: 0.359465

Epoch: 8
Loss: 0.11836613119408952
ROC train: 0.839592	val: 0.776114	test: 0.798454
PRC train: 0.378374	val: 0.326887	test: 0.361674

Epoch: 9
Loss: 0.11616145981830198
ROC train: 0.838930	val: 0.769570	test: 0.803527
PRC train: 0.385260	val: 0.328931	test: 0.371528

Epoch: 10
Loss: 0.1150909210467606
ROC train: 0.839217	val: 0.769085	test: 0.807853
PRC train: 0.376472	val: 0.311040	test: 0.376972

Epoch: 11
Loss: 0.11643867287588362
ROC train: 0.852688	val: 0.765245	test: 0.816944
PRC train: 0.417021	val: 0.330727	test: 0.430437

Epoch: 12
Loss: 0.11306070930319698
ROC train: 0.854680	val: 0.763453	test: 0.801157
PRC train: 0.442231	val: 0.350421	test: 0.407513

Epoch: 13
Loss: 0.11231329605637569
ROC train: 0.857407	val: 0.781581	test: 0.815239
PRC train: 0.423663	val: 0.345970	test: 0.406344

Epoch: 14
Loss: 0.11096244129933133
ROC train: 0.862657	val: 0.772347	test: 0.807754
PRC train: 0.446825	val: 0.355402	test: 0.418271

Epoch: 15
Loss: 0.11030787936629846
ROC train: 0.869932	val: 0.770752	test: 0.813330
PRC train: 0.460737	val: 0.341112	test: 0.419677

Epoch: 16
Loss: 0.11042909138963919
ROC train: 0.871130	val: 0.771876	test: 0.816889
PRC train: 0.453438	val: 0.340850	test: 0.434153

Epoch: 17
Loss: 0.10864530830156653
ROC train: 0.876209	val: 0.794483	test: 0.820818
PRC train: 0.458121	val: 0.357517	test: 0.431601

Epoch: 18
Loss: 0.10792063838241477
ROC train: 0.872169	val: 0.783156	test: 0.818906
PRC train: 0.451689	val: 0.345755	test: 0.417838

Epoch: 19
Loss: 0.1072698929401823
ROC train: 0.877523	val: 0.778699	test: 0.815861
PRC train: 0.480190	val: 0.344467	test: 0.439690

Epoch: 20
Loss: 0.10650573653121738
ROC train: 0.878354	val: 0.786495	test: 0.817305
PRC train: 0.473187	val: 0.339291	test: 0.404316

Epoch: 21
Loss: 0.10503144147603109
ROC train: 0.885191	val: 0.773825	test: 0.819672
PRC train: 0.489814	val: 0.376924	test: 0.421793

Epoch: 22
Loss: 0.10688802556922937
ROC train: 0.890865	val: 0.790967	test: 0.822047
PRC train: 0.508745	val: 0.370681	test: 0.449911

Epoch: 23
Loss: 0.10342820448897735
ROC train: 0.895561	val: 0.792147	test: 0.824560
PRC train: 0.490350	val: 0.354470	test: 0.424729

Epoch: 24
Loss: 0.10282995142822737
ROC train: 0.896115	val: 0.778857	test: 0.820178
PRC train: 0.509185	val: 0.363734	test: 0.448719

Epoch: 25
Loss: 0.10524167288380389
ROC train: 0.888328	val: 0.778680	test: 0.814546
PRC train: 0.492290	val: 0.357071	test: 0.436164

Epoch: 26
Loss: 0.10298257606412424
ROC train: 0.905850	val: 0.787113	test: 0.817393
PRC train: 0.529697	val: 0.373523	test: 0.436780

Epoch: 27
Loss: 0.10180192999137597
ROC train: 0.908727	val: 0.779873	test: 0.825116
PRC train: 0.528143	val: 0.364581	test: 0.446068

Epoch: 28
Loss: 0.10132435875441738
ROC train: 0.898430	val: 0.792133	test: 0.819145
PRC train: 0.504976	val: 0.342863	test: 0.420084

Epoch: 29
Loss: 0.10072028905841378
ROC train: 0.904730	val: 0.781562	test: 0.828641
PRC train: 0.514149	val: 0.360494	test: 0.443151

Epoch: 30
Loss: 0.09891961705338606
ROC train: 0.914629	val: 0.790881	test: 0.837270
PRC train: 0.549257	val: 0.372296	test: 0.449060

Epoch: 31
Loss: 0.10052640787488937
ROC train: 0.915668	val: 0.784078	test: 0.820265
PRC train: 0.562989	val: 0.371339	test: 0.443898

Epoch: 32
Loss: 0.10013648588591763
ROC train: 0.914585	val: 0.785034	test: 0.831233
PRC train: 0.560831	val: 0.370699	test: 0.460683

Epoch: 33
Loss: 0.0972017811909962Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/hiv/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/hiv/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/hiv/random/train_prop=0.7/hiv_random_6_26-05_11-07-15  ]
[ Using Seed :  6  ]
[ Using device :  cuda:1  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
randomly split
Data(edge_attr=[84, 2], edge_index=[2, 84], id=[1], x=[39, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.2795657317490289
ROC train: 0.748896	val: 0.734600	test: 0.769166
PRC train: 0.200952	val: 0.236901	test: 0.265301

Epoch: 2
Loss: 0.13329497786829586
ROC train: 0.776981	val: 0.750911	test: 0.795579
PRC train: 0.245000	val: 0.289533	test: 0.315868

Epoch: 3
Loss: 0.12665981987596253
ROC train: 0.781774	val: 0.768656	test: 0.786476
PRC train: 0.276423	val: 0.357369	test: 0.305460

Epoch: 4
Loss: 0.12334764729448587
ROC train: 0.801308	val: 0.760268	test: 0.797381
PRC train: 0.294957	val: 0.356020	test: 0.307111

Epoch: 5
Loss: 0.1222726371454986
ROC train: 0.808246	val: 0.771647	test: 0.815692
PRC train: 0.302472	val: 0.312047	test: 0.341501

Epoch: 6
Loss: 0.12003075156392069
ROC train: 0.831654	val: 0.786988	test: 0.825172
PRC train: 0.369608	val: 0.388395	test: 0.398566

Epoch: 7
Loss: 0.11929360657873904
ROC train: 0.812399	val: 0.780900	test: 0.805239
PRC train: 0.331978	val: 0.341666	test: 0.361529

Epoch: 8
Loss: 0.1179316014944352
ROC train: 0.819494	val: 0.784645	test: 0.800430
PRC train: 0.330569	val: 0.309580	test: 0.338081

Epoch: 9
Loss: 0.11645922205806379
ROC train: 0.839983	val: 0.792324	test: 0.822665
PRC train: 0.397639	val: 0.362946	test: 0.393942

Epoch: 10
Loss: 0.11431765901401292
ROC train: 0.845158	val: 0.796938	test: 0.830823
PRC train: 0.392147	val: 0.401301	test: 0.398152

Epoch: 11
Loss: 0.11446526628064345
ROC train: 0.857822	val: 0.795949	test: 0.832549
PRC train: 0.449372	val: 0.407293	test: 0.419112

Epoch: 12
Loss: 0.11246290852702949
ROC train: 0.853614	val: 0.794300	test: 0.836329
PRC train: 0.410234	val: 0.379109	test: 0.429263

Epoch: 13
Loss: 0.11243432085586837
ROC train: 0.852115	val: 0.801702	test: 0.833228
PRC train: 0.412356	val: 0.380917	test: 0.385658

Epoch: 14
Loss: 0.1097314889613399
ROC train: 0.870223	val: 0.801394	test: 0.836391
PRC train: 0.444869	val: 0.411865	test: 0.420128

Epoch: 15
Loss: 0.10772844677728974
ROC train: 0.873474	val: 0.799220	test: 0.846582
PRC train: 0.460649	val: 0.406075	test: 0.429340

Epoch: 16
Loss: 0.10811922406183382
ROC train: 0.870683	val: 0.796322	test: 0.846369
PRC train: 0.453193	val: 0.390044	test: 0.421777

Epoch: 17
Loss: 0.10821040779543176
ROC train: 0.880049	val: 0.792605	test: 0.838544
PRC train: 0.489565	val: 0.414427	test: 0.448610

Epoch: 18
Loss: 0.10676208891238781
ROC train: 0.879930	val: 0.793437	test: 0.840417
PRC train: 0.470776	val: 0.408945	test: 0.441966

Epoch: 19
Loss: 0.10574138232222204
ROC train: 0.884604	val: 0.786295	test: 0.850802
PRC train: 0.486622	val: 0.406182	test: 0.452635

Epoch: 20
Loss: 0.10498253459610742
ROC train: 0.884330	val: 0.801355	test: 0.853213
PRC train: 0.484902	val: 0.377625	test: 0.448295

Epoch: 21
Loss: 0.1049067367359771
ROC train: 0.871834	val: 0.784022	test: 0.848146
PRC train: 0.453423	val: 0.377336	test: 0.430595

Epoch: 22
Loss: 0.10402376346175495
ROC train: 0.892681	val: 0.803916	test: 0.836142
PRC train: 0.505880	val: 0.400776	test: 0.447412

Epoch: 23
Loss: 0.10386232733352244
ROC train: 0.888489	val: 0.794662	test: 0.824616
PRC train: 0.486006	val: 0.412061	test: 0.427795

Epoch: 24
Loss: 0.10157475375229869
ROC train: 0.887804	val: 0.807343	test: 0.843644
PRC train: 0.450445	val: 0.378960	test: 0.365963

Epoch: 25
Loss: 0.10168940954563671
ROC train: 0.894529	val: 0.804354	test: 0.838639
PRC train: 0.499714	val: 0.415895	test: 0.436149

Epoch: 26
Loss: 0.10147361983845071
ROC train: 0.894764	val: 0.793065	test: 0.844759
PRC train: 0.511389	val: 0.410074	test: 0.458578

Epoch: 27
Loss: 0.10094000494284751
ROC train: 0.906593	val: 0.807549	test: 0.846829
PRC train: 0.525395	val: 0.429917	test: 0.458378

Epoch: 28
Loss: 0.10083510496665293
ROC train: 0.902222	val: 0.802180	test: 0.846911
PRC train: 0.526656	val: 0.423500	test: 0.455446

Epoch: 29
Loss: 0.10059679818325776
ROC train: 0.910080	val: 0.815058	test: 0.848951
PRC train: 0.550105	val: 0.425450	test: 0.461922

Epoch: 30
Loss: 0.0976944122196218
ROC train: 0.905957	val: 0.817244	test: 0.852193
PRC train: 0.547624	val: 0.439876	test: 0.448112

Epoch: 31
Loss: 0.09855846299716772
ROC train: 0.915029	val: 0.802439	test: 0.845388
PRC train: 0.548872	val: 0.410603	test: 0.454140

Epoch: 32
Loss: 0.09789377326391242
ROC train: 0.917701	val: 0.810086	test: 0.846231
PRC train: 0.563555	val: 0.439005	test: 0.445810

Epoch: 33
Loss: 0.0968224843212228Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/hiv/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/hiv/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/hiv/random/train_prop=0.7/hiv_random_5_26-05_11-07-15  ]
[ Using Seed :  5  ]
[ Using device :  cuda:1  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
randomly split
Data(edge_attr=[84, 2], edge_index=[2, 84], id=[1], x=[39, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.2815760402024017
ROC train: 0.756786	val: 0.751347	test: 0.768043
PRC train: 0.205877	val: 0.269415	test: 0.241867

Epoch: 2
Loss: 0.13420356833132022
ROC train: 0.771479	val: 0.752075	test: 0.768208
PRC train: 0.213416	val: 0.253724	test: 0.231902

Epoch: 3
Loss: 0.1281748899173289
ROC train: 0.801497	val: 0.771595	test: 0.813573
PRC train: 0.294256	val: 0.339145	test: 0.343050

Epoch: 4
Loss: 0.12481925325632269
ROC train: 0.813539	val: 0.778493	test: 0.811650
PRC train: 0.313982	val: 0.369395	test: 0.336438

Epoch: 5
Loss: 0.12116374117349907
ROC train: 0.824746	val: 0.780047	test: 0.813426
PRC train: 0.338613	val: 0.372587	test: 0.377771

Epoch: 6
Loss: 0.12141457315325625
ROC train: 0.832855	val: 0.798026	test: 0.823972
PRC train: 0.361578	val: 0.405106	test: 0.386797

Epoch: 7
Loss: 0.1188961273804888
ROC train: 0.833054	val: 0.788773	test: 0.821930
PRC train: 0.355431	val: 0.374953	test: 0.362179

Epoch: 8
Loss: 0.1167700914798592
ROC train: 0.847060	val: 0.791809	test: 0.828721
PRC train: 0.398442	val: 0.400763	test: 0.394829

Epoch: 9
Loss: 0.11599235736430888
ROC train: 0.830419	val: 0.776489	test: 0.827470
PRC train: 0.363857	val: 0.345094	test: 0.385752

Epoch: 10
Loss: 0.11549981300021592
ROC train: 0.845279	val: 0.786402	test: 0.833341
PRC train: 0.393354	val: 0.392928	test: 0.394662

Epoch: 11
Loss: 0.11334583754178026
ROC train: 0.856307	val: 0.802793	test: 0.839087
PRC train: 0.423599	val: 0.408756	test: 0.415200

Epoch: 12
Loss: 0.11300439461624733
ROC train: 0.859249	val: 0.795428	test: 0.838823
PRC train: 0.418147	val: 0.407736	test: 0.423561

Epoch: 13
Loss: 0.11125252134681494
ROC train: 0.861782	val: 0.809625	test: 0.819934
PRC train: 0.407722	val: 0.380848	test: 0.355694

Epoch: 14
Loss: 0.11181846907682325
ROC train: 0.860268	val: 0.797100	test: 0.842605
PRC train: 0.431034	val: 0.413184	test: 0.413438

Epoch: 15
Loss: 0.1091005478499458
ROC train: 0.872310	val: 0.794578	test: 0.844722
PRC train: 0.443936	val: 0.421520	test: 0.424729

Epoch: 16
Loss: 0.1079638030620992
ROC train: 0.871173	val: 0.801428	test: 0.843953
PRC train: 0.453202	val: 0.429106	test: 0.422719

Epoch: 17
Loss: 0.10736791511978239
ROC train: 0.875942	val: 0.791792	test: 0.834970
PRC train: 0.466819	val: 0.402340	test: 0.424528

Epoch: 18
Loss: 0.1049667746004469
ROC train: 0.888077	val: 0.810660	test: 0.848258
PRC train: 0.491082	val: 0.414476	test: 0.452904

Epoch: 19
Loss: 0.10598060641232342
ROC train: 0.887443	val: 0.802089	test: 0.853027
PRC train: 0.466949	val: 0.420708	test: 0.429451

Epoch: 20
Loss: 0.10624343219490191
ROC train: 0.881772	val: 0.801319	test: 0.835532
PRC train: 0.470153	val: 0.407267	test: 0.428611

Epoch: 21
Loss: 0.10450748564650567
ROC train: 0.879224	val: 0.797599	test: 0.825344
PRC train: 0.471230	val: 0.408492	test: 0.424668

Epoch: 22
Loss: 0.10467880466109629
ROC train: 0.898038	val: 0.807120	test: 0.843563
PRC train: 0.502169	val: 0.407723	test: 0.413292

Epoch: 23
Loss: 0.10325614718686586
ROC train: 0.877226	val: 0.793063	test: 0.814291
PRC train: 0.468967	val: 0.375342	test: 0.415725

Epoch: 24
Loss: 0.10159900037367024
ROC train: 0.907115	val: 0.796306	test: 0.846774
PRC train: 0.521875	val: 0.421004	test: 0.455925

Epoch: 25
Loss: 0.10263248977849883
ROC train: 0.905329	val: 0.799536	test: 0.850649
PRC train: 0.522630	val: 0.424539	test: 0.458518

Epoch: 26
Loss: 0.100196195747354
ROC train: 0.900776	val: 0.802044	test: 0.847919
PRC train: 0.497616	val: 0.403938	test: 0.398957

Epoch: 27
Loss: 0.10193463048721314
ROC train: 0.906729	val: 0.803049	test: 0.841587
PRC train: 0.530947	val: 0.431708	test: 0.457155

Epoch: 28
Loss: 0.09928547377370064
ROC train: 0.908147	val: 0.802831	test: 0.837450
PRC train: 0.550642	val: 0.416620	test: 0.446345

Epoch: 29
Loss: 0.0985066185611719
ROC train: 0.903917	val: 0.808224	test: 0.843611
PRC train: 0.533169	val: 0.442529	test: 0.446709

Epoch: 30
Loss: 0.09711827569408149
ROC train: 0.919508	val: 0.812188	test: 0.844770
PRC train: 0.564265	val: 0.457264	test: 0.444443

Epoch: 31
Loss: 0.09719836415531029
ROC train: 0.907270	val: 0.802682	test: 0.839698
PRC train: 0.519907	val: 0.391815	test: 0.424993

Epoch: 32
Loss: 0.0978441129559966
ROC train: 0.917497	val: 0.799813	test: 0.849482
PRC train: 0.568878	val: 0.435879	test: 0.470455

Epoch: 33
Loss: 0.09698185746501241Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/hiv/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/hiv/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/hiv/random/train_prop=0.7/hiv_random_4_26-05_11-07-15  ]
[ Using Seed :  4  ]
[ Using device :  cuda:1  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
randomly split
Data(edge_attr=[84, 2], edge_index=[2, 84], id=[1], x=[39, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.29857527421520164
ROC train: 0.731726	val: 0.724334	test: 0.732583
PRC train: 0.192499	val: 0.261920	test: 0.219880

Epoch: 2
Loss: 0.13388779919465138
ROC train: 0.773422	val: 0.754376	test: 0.792754
PRC train: 0.257995	val: 0.299338	test: 0.305924

Epoch: 3
Loss: 0.12779342308658864
ROC train: 0.790210	val: 0.765126	test: 0.800107
PRC train: 0.282511	val: 0.346064	test: 0.306844

Epoch: 4
Loss: 0.12534337574113494
ROC train: 0.812034	val: 0.777438	test: 0.806298
PRC train: 0.329029	val: 0.379247	test: 0.350190

Epoch: 5
Loss: 0.12291294814465312
ROC train: 0.813154	val: 0.768492	test: 0.818933
PRC train: 0.349967	val: 0.386777	test: 0.396640

Epoch: 6
Loss: 0.12104316780336989
ROC train: 0.820609	val: 0.761167	test: 0.801905
PRC train: 0.364089	val: 0.365940	test: 0.370263

Epoch: 7
Loss: 0.12018797066283646
ROC train: 0.828303	val: 0.786144	test: 0.823311
PRC train: 0.381972	val: 0.395276	test: 0.395114

Epoch: 8
Loss: 0.11731032180068
ROC train: 0.829220	val: 0.773643	test: 0.832126
PRC train: 0.386933	val: 0.408469	test: 0.406330

Epoch: 9
Loss: 0.11663417022220846
ROC train: 0.842166	val: 0.784095	test: 0.833097
PRC train: 0.381011	val: 0.397862	test: 0.389804

Epoch: 10
Loss: 0.11433291046686934
ROC train: 0.835282	val: 0.788815	test: 0.810155
PRC train: 0.380439	val: 0.375576	test: 0.383324

Epoch: 11
Loss: 0.1122878540257492
ROC train: 0.847641	val: 0.775003	test: 0.825300
PRC train: 0.420825	val: 0.406913	test: 0.415175

Epoch: 12
Loss: 0.11352843781375307
ROC train: 0.860244	val: 0.795993	test: 0.842053
PRC train: 0.445200	val: 0.428984	test: 0.431280

Epoch: 13
Loss: 0.11214856372706641
ROC train: 0.847349	val: 0.781807	test: 0.812986
PRC train: 0.400283	val: 0.369678	test: 0.384993

Epoch: 14
Loss: 0.11102706278875629
ROC train: 0.857058	val: 0.789065	test: 0.842759
PRC train: 0.438507	val: 0.411426	test: 0.413713

Epoch: 15
Loss: 0.10944225237071876
ROC train: 0.849614	val: 0.774564	test: 0.816550
PRC train: 0.419172	val: 0.382486	test: 0.354542

Epoch: 16
Loss: 0.11008539782085067
ROC train: 0.867316	val: 0.782135	test: 0.838995
PRC train: 0.456734	val: 0.424014	test: 0.435797

Epoch: 17
Loss: 0.10735410510956614
ROC train: 0.871482	val: 0.804569	test: 0.836022
PRC train: 0.461489	val: 0.428058	test: 0.431518

Epoch: 18
Loss: 0.10676273597343279
ROC train: 0.872348	val: 0.801885	test: 0.835499
PRC train: 0.466464	val: 0.398015	test: 0.414577

Epoch: 19
Loss: 0.10636999973592526
ROC train: 0.877998	val: 0.807886	test: 0.839256
PRC train: 0.487560	val: 0.442575	test: 0.439062

Epoch: 20
Loss: 0.10701691927549416
ROC train: 0.883385	val: 0.802858	test: 0.841147
PRC train: 0.500301	val: 0.425616	test: 0.448898

Epoch: 21
Loss: 0.10445822432228574
ROC train: 0.883874	val: 0.789757	test: 0.839645
PRC train: 0.478200	val: 0.408000	test: 0.438468

Epoch: 22
Loss: 0.10613812151235219
ROC train: 0.884103	val: 0.797718	test: 0.834633
PRC train: 0.495107	val: 0.416257	test: 0.446624

Epoch: 23
Loss: 0.10443476300037398
ROC train: 0.896263	val: 0.790968	test: 0.836395
PRC train: 0.502671	val: 0.417068	test: 0.446622

Epoch: 24
Loss: 0.1030769795996351
ROC train: 0.894083	val: 0.801264	test: 0.846766
PRC train: 0.509302	val: 0.427566	test: 0.459660

Epoch: 25
Loss: 0.10189171367821
ROC train: 0.897029	val: 0.804983	test: 0.848629
PRC train: 0.526264	val: 0.444833	test: 0.436670

Epoch: 26
Loss: 0.10293254669181481
ROC train: 0.894747	val: 0.800623	test: 0.835198
PRC train: 0.501827	val: 0.418175	test: 0.435309

Epoch: 27
Loss: 0.10233175174269275
ROC train: 0.898705	val: 0.791177	test: 0.847082
PRC train: 0.532148	val: 0.421905	test: 0.442066

Epoch: 28
Loss: 0.10011088714937609
ROC train: 0.902192	val: 0.802076	test: 0.842726
PRC train: 0.539834	val: 0.444309	test: 0.465266

Epoch: 29
Loss: 0.10102778181565338
ROC train: 0.909323	val: 0.791890	test: 0.845675
PRC train: 0.528493	val: 0.415420	test: 0.455088

Epoch: 30
Loss: 0.10065062901796568
ROC train: 0.909770	val: 0.795939	test: 0.839685
PRC train: 0.553871	val: 0.442363	test: 0.454492

Epoch: 31
Loss: 0.09837261146791497
ROC train: 0.904427	val: 0.803206	test: 0.838325
PRC train: 0.507772	val: 0.401408	test: 0.439085

Epoch: 32
Loss: 0.09813484304792092
ROC train: 0.912124	val: 0.809982	test: 0.853680
PRC train: 0.553034	val: 0.422435	test: 0.455633

Epoch: 33
Loss: 0.09767689565342864Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/hiv/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/hiv/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/hiv/random/train_prop=0.8/hiv_random_5_26-05_11-07-15  ]
[ Using Seed :  5  ]
[ Using device :  cuda:2  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
randomly split
Data(edge_attr=[84, 2], edge_index=[2, 84], id=[1], x=[39, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.2663808679966101
ROC train: 0.757913	val: 0.736873	test: 0.743876
PRC train: 0.216036	val: 0.216419	test: 0.266694

Epoch: 2
Loss: 0.1337278864577663
ROC train: 0.767371	val: 0.740956	test: 0.792515
PRC train: 0.224985	val: 0.253245	test: 0.275703

Epoch: 3
Loss: 0.12920742554443626
ROC train: 0.794326	val: 0.769662	test: 0.816908
PRC train: 0.279870	val: 0.299429	test: 0.363579

Epoch: 4
Loss: 0.12425698638226544
ROC train: 0.817378	val: 0.788022	test: 0.830664
PRC train: 0.330831	val: 0.319752	test: 0.393741

Epoch: 5
Loss: 0.1232249064510082
ROC train: 0.811540	val: 0.787158	test: 0.804320
PRC train: 0.307376	val: 0.274411	test: 0.342725

Epoch: 6
Loss: 0.12047310998467263
ROC train: 0.811783	val: 0.762705	test: 0.809411
PRC train: 0.291451	val: 0.271940	test: 0.355485

Epoch: 7
Loss: 0.11732402660676644
ROC train: 0.829547	val: 0.817225	test: 0.827976
PRC train: 0.362081	val: 0.366560	test: 0.387628

Epoch: 8
Loss: 0.11780068840569634
ROC train: 0.840307	val: 0.806789	test: 0.845556
PRC train: 0.386999	val: 0.381219	test: 0.418626

Epoch: 9
Loss: 0.11601428950813987
ROC train: 0.844325	val: 0.799906	test: 0.847388
PRC train: 0.389782	val: 0.366500	test: 0.410738

Epoch: 10
Loss: 0.1145042276152891
ROC train: 0.843195	val: 0.796214	test: 0.836523
PRC train: 0.411530	val: 0.357959	test: 0.439099

Epoch: 11
Loss: 0.11494226644225289
ROC train: 0.857238	val: 0.810287	test: 0.857182
PRC train: 0.397648	val: 0.367703	test: 0.443152

Epoch: 12
Loss: 0.11244753741626036
ROC train: 0.861239	val: 0.792363	test: 0.850785
PRC train: 0.453234	val: 0.412586	test: 0.472438

Epoch: 13
Loss: 0.113079392990895
ROC train: 0.856529	val: 0.814314	test: 0.849517
PRC train: 0.434108	val: 0.365282	test: 0.431576

Epoch: 14
Loss: 0.10982952703857439
ROC train: 0.856080	val: 0.802437	test: 0.830598
PRC train: 0.437761	val: 0.371028	test: 0.408549

Epoch: 15
Loss: 0.1102978063697792
ROC train: 0.869207	val: 0.792287	test: 0.863175
PRC train: 0.457701	val: 0.391084	test: 0.486382

Epoch: 16
Loss: 0.10888485492006551
ROC train: 0.869556	val: 0.805420	test: 0.857644
PRC train: 0.459813	val: 0.403556	test: 0.475867

Epoch: 17
Loss: 0.10793728624485696
ROC train: 0.873578	val: 0.819353	test: 0.859421
PRC train: 0.480182	val: 0.430657	test: 0.484704

Epoch: 18
Loss: 0.10812096637287656
ROC train: 0.876709	val: 0.822176	test: 0.836953
PRC train: 0.483739	val: 0.435290	test: 0.477186

Epoch: 19
Loss: 0.10580658172821134
ROC train: 0.885803	val: 0.825547	test: 0.857009
PRC train: 0.480474	val: 0.417930	test: 0.472462

Epoch: 20
Loss: 0.10628391414863786
ROC train: 0.889980	val: 0.822417	test: 0.853686
PRC train: 0.492665	val: 0.420071	test: 0.473493

Epoch: 21
Loss: 0.10595640605476137
ROC train: 0.888936	val: 0.825096	test: 0.844610
PRC train: 0.504264	val: 0.438014	test: 0.487757

Epoch: 22
Loss: 0.10458928295338774
ROC train: 0.881517	val: 0.821036	test: 0.841276
PRC train: 0.464887	val: 0.407087	test: 0.440659

Epoch: 23
Loss: 0.10424853906841218
ROC train: 0.893523	val: 0.809510	test: 0.856271
PRC train: 0.512886	val: 0.412782	test: 0.503695

Epoch: 24
Loss: 0.10403294321865843
ROC train: 0.897578	val: 0.820101	test: 0.871315
PRC train: 0.507615	val: 0.437758	test: 0.496661

Epoch: 25
Loss: 0.10254142966226004
ROC train: 0.900942	val: 0.815317	test: 0.867918
PRC train: 0.524004	val: 0.419588	test: 0.498913

Epoch: 26
Loss: 0.10429349621040554
ROC train: 0.896738	val: 0.821663	test: 0.843942
PRC train: 0.492799	val: 0.382013	test: 0.471241

Epoch: 27
Loss: 0.10108642817645526
ROC train: 0.905004	val: 0.826398	test: 0.865188
PRC train: 0.535688	val: 0.406244	test: 0.473848

Epoch: 28
Loss: 0.10146797745424334
ROC train: 0.906514	val: 0.822086	test: 0.859392
PRC train: 0.547312	val: 0.428264	test: 0.499873

Epoch: 29
Loss: 0.10073158109945828
ROC train: 0.907542	val: 0.820791	test: 0.871957
PRC train: 0.535695	val: 0.431283	test: 0.498200

Epoch: 30
Loss: 0.09859965456205345
ROC train: 0.902843	val: 0.826625	test: 0.860802
PRC train: 0.531704	val: 0.409583	test: 0.505503

Epoch: 31
Loss: 0.09994511361387357
ROC train: 0.902053	val: 0.822395	test: 0.858151
PRC train: 0.522129	val: 0.429448	test: 0.476209

Epoch: 32
Loss: 0.09860010065728338
ROC train: 0.916412	val: 0.816748	test: 0.864760
PRC train: 0.541176	val: 0.396538	test: 0.489359

Epoch: 33
Loss: 0.09753024221640154Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/hiv/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/hiv/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/hiv/random/train_prop=0.8/hiv_random_6_26-05_11-07-15  ]
[ Using Seed :  6  ]
[ Using device :  cuda:2  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
randomly split
Data(edge_attr=[84, 2], edge_index=[2, 84], id=[1], x=[39, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.2626815308273512
ROC train: 0.760821	val: 0.743387	test: 0.778500
PRC train: 0.217250	val: 0.233957	test: 0.256457

Epoch: 2
Loss: 0.13441998856573475
ROC train: 0.786420	val: 0.774057	test: 0.801242
PRC train: 0.284841	val: 0.289814	test: 0.348443

Epoch: 3
Loss: 0.12864823560107122
ROC train: 0.788551	val: 0.759586	test: 0.809985
PRC train: 0.304352	val: 0.337109	test: 0.376557

Epoch: 4
Loss: 0.12454516652740337
ROC train: 0.811129	val: 0.795496	test: 0.816618
PRC train: 0.302386	val: 0.346372	test: 0.365216

Epoch: 5
Loss: 0.12205252425980634
ROC train: 0.812708	val: 0.770850	test: 0.829368
PRC train: 0.342712	val: 0.358249	test: 0.395960

Epoch: 6
Loss: 0.11932970335893198
ROC train: 0.819902	val: 0.789216	test: 0.817463
PRC train: 0.371322	val: 0.353984	test: 0.404038

Epoch: 7
Loss: 0.11941135354635618
ROC train: 0.831497	val: 0.792731	test: 0.844326
PRC train: 0.395227	val: 0.387287	test: 0.447676

Epoch: 8
Loss: 0.11802212166265168
ROC train: 0.837214	val: 0.804890	test: 0.830273
PRC train: 0.388171	val: 0.366953	test: 0.408694

Epoch: 9
Loss: 0.11679856437103651
ROC train: 0.841394	val: 0.805133	test: 0.831624
PRC train: 0.377028	val: 0.351993	test: 0.411609

Epoch: 10
Loss: 0.11450615419617073
ROC train: 0.844921	val: 0.804867	test: 0.822672
PRC train: 0.400089	val: 0.352112	test: 0.452497

Epoch: 11
Loss: 0.1132683418033795
ROC train: 0.848913	val: 0.802335	test: 0.853111
PRC train: 0.441954	val: 0.413942	test: 0.460479

Epoch: 12
Loss: 0.1123631535748209
ROC train: 0.853552	val: 0.812510	test: 0.833251
PRC train: 0.444906	val: 0.425703	test: 0.457272

Epoch: 13
Loss: 0.11107874636017853
ROC train: 0.862009	val: 0.819938	test: 0.842019
PRC train: 0.445664	val: 0.394930	test: 0.443251

Epoch: 14
Loss: 0.11136060488380785
ROC train: 0.865035	val: 0.811250	test: 0.842520
PRC train: 0.458643	val: 0.407629	test: 0.452949

Epoch: 15
Loss: 0.10988942988389425
ROC train: 0.864402	val: 0.813120	test: 0.830283
PRC train: 0.445360	val: 0.405441	test: 0.472720

Epoch: 16
Loss: 0.10967767219871145
ROC train: 0.869522	val: 0.812255	test: 0.842095
PRC train: 0.447063	val: 0.396974	test: 0.466453

Epoch: 17
Loss: 0.10843025235811117
ROC train: 0.871099	val: 0.805552	test: 0.840483
PRC train: 0.473716	val: 0.418460	test: 0.471771

Epoch: 18
Loss: 0.10791163464288052
ROC train: 0.880199	val: 0.806261	test: 0.845673
PRC train: 0.462979	val: 0.376271	test: 0.463094

Epoch: 19
Loss: 0.1071392286290869
ROC train: 0.879623	val: 0.805782	test: 0.853813
PRC train: 0.487393	val: 0.422169	test: 0.478282

Epoch: 20
Loss: 0.10827097325443578
ROC train: 0.882482	val: 0.831822	test: 0.840180
PRC train: 0.507730	val: 0.436879	test: 0.475267

Epoch: 21
Loss: 0.10734405030266092
ROC train: 0.884233	val: 0.826798	test: 0.842672
PRC train: 0.482005	val: 0.389562	test: 0.449340

Epoch: 22
Loss: 0.10488019271026135
ROC train: 0.885923	val: 0.811832	test: 0.830602
PRC train: 0.512011	val: 0.427554	test: 0.471766

Epoch: 23
Loss: 0.10379114903766455
ROC train: 0.897187	val: 0.826140	test: 0.823134
PRC train: 0.522033	val: 0.431844	test: 0.446874

Epoch: 24
Loss: 0.10490639028547531
ROC train: 0.887713	val: 0.822618	test: 0.841789
PRC train: 0.502556	val: 0.435703	test: 0.462240

Epoch: 25
Loss: 0.10291545645755472
ROC train: 0.897245	val: 0.808946	test: 0.852693
PRC train: 0.510431	val: 0.423217	test: 0.461501

Epoch: 26
Loss: 0.10295981034316969
ROC train: 0.895961	val: 0.826380	test: 0.837256
PRC train: 0.506764	val: 0.408464	test: 0.460338

Epoch: 27
Loss: 0.10255015188364423
ROC train: 0.884660	val: 0.804807	test: 0.821512
PRC train: 0.466098	val: 0.365151	test: 0.459715

Epoch: 28
Loss: 0.1013169648176203
ROC train: 0.899029	val: 0.809187	test: 0.850399
PRC train: 0.518364	val: 0.392463	test: 0.460802

Epoch: 29
Loss: 0.10181800932961863
ROC train: 0.909358	val: 0.834807	test: 0.852178
PRC train: 0.539845	val: 0.426072	test: 0.484312

Epoch: 30
Loss: 0.10093667436261161
ROC train: 0.908669	val: 0.816984	test: 0.847278
PRC train: 0.546674	val: 0.426867	test: 0.452351

Epoch: 31
Loss: 0.10079588160155863
ROC train: 0.902177	val: 0.810350	test: 0.827826
PRC train: 0.535593	val: 0.419994	test: 0.488825

Epoch: 32
Loss: 0.09957850367482553
ROC train: 0.911432	val: 0.809684	test: 0.857603
PRC train: 0.556098	val: 0.432623	test: 0.506290

Epoch: 33
Loss: 0.09825510345871143Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/hiv/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/hiv/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/hiv/random/train_prop=0.8/hiv_random_4_26-05_11-07-15  ]
[ Using Seed :  4  ]
[ Using device :  cuda:2  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
randomly split
Data(edge_attr=[84, 2], edge_index=[2, 84], id=[1], x=[39, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.27970162108044827
ROC train: 0.769389	val: 0.758591	test: 0.779458
PRC train: 0.226669	val: 0.264031	test: 0.296278

Epoch: 2
Loss: 0.13338013228454795
ROC train: 0.788012	val: 0.781869	test: 0.795144
PRC train: 0.269773	val: 0.293845	test: 0.336569

Epoch: 3
Loss: 0.12830469493580166
ROC train: 0.802559	val: 0.794252	test: 0.821585
PRC train: 0.284734	val: 0.319868	test: 0.335504

Epoch: 4
Loss: 0.12473002269721789
ROC train: 0.803655	val: 0.796267	test: 0.807795
PRC train: 0.307052	val: 0.317029	test: 0.335759

Epoch: 5
Loss: 0.123279359796117
ROC train: 0.812665	val: 0.773526	test: 0.822221
PRC train: 0.348931	val: 0.343662	test: 0.434522

Epoch: 6
Loss: 0.11958934879023092
ROC train: 0.815911	val: 0.777572	test: 0.828835
PRC train: 0.352843	val: 0.370687	test: 0.408732

Epoch: 7
Loss: 0.11974833550071844
ROC train: 0.829092	val: 0.781871	test: 0.830955
PRC train: 0.363434	val: 0.365605	test: 0.397282

Epoch: 8
Loss: 0.11927708392554141
ROC train: 0.833501	val: 0.767155	test: 0.835620
PRC train: 0.385378	val: 0.370126	test: 0.451271

Epoch: 9
Loss: 0.1164922213571648
ROC train: 0.840053	val: 0.777813	test: 0.844534
PRC train: 0.381148	val: 0.357211	test: 0.417213

Epoch: 10
Loss: 0.1144889782093195
ROC train: 0.839053	val: 0.772217	test: 0.828589
PRC train: 0.387621	val: 0.343098	test: 0.424349

Epoch: 11
Loss: 0.11431738170202567
ROC train: 0.851013	val: 0.795788	test: 0.840753
PRC train: 0.405412	val: 0.404110	test: 0.427946

Epoch: 12
Loss: 0.11285862104891048
ROC train: 0.857169	val: 0.804865	test: 0.843928
PRC train: 0.439622	val: 0.395978	test: 0.436726

Epoch: 13
Loss: 0.11148926514706413
ROC train: 0.855557	val: 0.787417	test: 0.842327
PRC train: 0.448341	val: 0.407605	test: 0.479988

Epoch: 14
Loss: 0.1118676085602723
ROC train: 0.857571	val: 0.792830	test: 0.836000
PRC train: 0.439981	val: 0.400346	test: 0.463821

Epoch: 15
Loss: 0.10979862093157686
ROC train: 0.873575	val: 0.801599	test: 0.848021
PRC train: 0.462126	val: 0.418571	test: 0.472010

Epoch: 16
Loss: 0.11018748004693464
ROC train: 0.858962	val: 0.783916	test: 0.841768
PRC train: 0.451649	val: 0.402089	test: 0.452561

Epoch: 17
Loss: 0.10721325731808515
ROC train: 0.873251	val: 0.778113	test: 0.828828
PRC train: 0.476549	val: 0.411620	test: 0.465053

Epoch: 18
Loss: 0.10814863952950819
ROC train: 0.876174	val: 0.809203	test: 0.840842
PRC train: 0.452817	val: 0.407234	test: 0.424098

Epoch: 19
Loss: 0.10654698036833882
ROC train: 0.878577	val: 0.797328	test: 0.847620
PRC train: 0.481535	val: 0.413953	test: 0.468972

Epoch: 20
Loss: 0.10701266083989716
ROC train: 0.884940	val: 0.807487	test: 0.844422
PRC train: 0.486389	val: 0.407114	test: 0.461699

Epoch: 21
Loss: 0.10633673796537985
ROC train: 0.875576	val: 0.801423	test: 0.843708
PRC train: 0.455629	val: 0.382269	test: 0.419737

Epoch: 22
Loss: 0.10605459753780226
ROC train: 0.886414	val: 0.811735	test: 0.841401
PRC train: 0.482710	val: 0.403925	test: 0.441661

Epoch: 23
Loss: 0.10526577193723695
ROC train: 0.894879	val: 0.798739	test: 0.847520
PRC train: 0.511596	val: 0.416832	test: 0.480219

Epoch: 24
Loss: 0.10341057794464378
ROC train: 0.891650	val: 0.804615	test: 0.840218
PRC train: 0.503401	val: 0.413983	test: 0.445349

Epoch: 25
Loss: 0.10293229278219537
ROC train: 0.896374	val: 0.805190	test: 0.844674
PRC train: 0.513784	val: 0.426008	test: 0.465102

Epoch: 26
Loss: 0.10328831464747178
ROC train: 0.893639	val: 0.810047	test: 0.856188
PRC train: 0.521282	val: 0.436049	test: 0.493975

Epoch: 27
Loss: 0.10186311718940906
ROC train: 0.895560	val: 0.821033	test: 0.842877
PRC train: 0.508053	val: 0.444184	test: 0.462150

Epoch: 28
Loss: 0.10168962583599814
ROC train: 0.907851	val: 0.816076	test: 0.853229
PRC train: 0.542268	val: 0.426523	test: 0.484834

Epoch: 29
Loss: 0.100616419312218
ROC train: 0.903251	val: 0.811245	test: 0.859111
PRC train: 0.532761	val: 0.425397	test: 0.481039

Epoch: 30
Loss: 0.10002190012522418
ROC train: 0.909467	val: 0.815259	test: 0.858700
PRC train: 0.554815	val: 0.426070	test: 0.490291

Epoch: 31
Loss: 0.09984780638589141
ROC train: 0.910737	val: 0.797328	test: 0.848012
PRC train: 0.556365	val: 0.440369	test: 0.469787

Epoch: 32
Loss: 0.09764275407922011
ROC train: 0.904639	val: 0.804842	test: 0.837274
PRC train: 0.532335	val: 0.401910	test: 0.472039

Epoch: 33
Loss: 0.09946522812519858
ROC train: 0.914946	val: 0.792656	test: 0.821879
PRC train: 0.563979	val: 0.376714	test: 0.447210

Epoch: 34
Loss: 0.09968224510938307
ROC train: 0.914055	val: 0.792269	test: 0.826703
PRC train: 0.562818	val: 0.381036	test: 0.448165

Epoch: 35
Loss: 0.09718665799279698
ROC train: 0.922159	val: 0.793483	test: 0.827866
PRC train: 0.573193	val: 0.365607	test: 0.461165

Epoch: 36
Loss: 0.09767593727053725
ROC train: 0.921535	val: 0.793248	test: 0.828496
PRC train: 0.581480	val: 0.380276	test: 0.447005

Epoch: 37
Loss: 0.0970056225441928
ROC train: 0.923281	val: 0.780212	test: 0.821702
PRC train: 0.559161	val: 0.389957	test: 0.452366

Epoch: 38
Loss: 0.09654774127591557
ROC train: 0.925216	val: 0.801626	test: 0.829435
PRC train: 0.564051	val: 0.393653	test: 0.452687

Epoch: 39
Loss: 0.09588345350306204
ROC train: 0.931872	val: 0.783386	test: 0.833961
PRC train: 0.588544	val: 0.388819	test: 0.467554

Epoch: 40
Loss: 0.0950102944243821
ROC train: 0.927267	val: 0.787849	test: 0.828774
PRC train: 0.582491	val: 0.358096	test: 0.456929

Epoch: 41
Loss: 0.09479735425358485
ROC train: 0.934065	val: 0.790652	test: 0.826627
PRC train: 0.605658	val: 0.406476	test: 0.474339

Epoch: 42
Loss: 0.09181848173869035
ROC train: 0.923805	val: 0.794354	test: 0.814796
PRC train: 0.580107	val: 0.354815	test: 0.433932

Epoch: 43
Loss: 0.09542154874889534
ROC train: 0.933117	val: 0.801304	test: 0.839344
PRC train: 0.591923	val: 0.384079	test: 0.459545

Epoch: 44
Loss: 0.09219556148776979
ROC train: 0.933744	val: 0.783396	test: 0.823105
PRC train: 0.600009	val: 0.350527	test: 0.457782

Epoch: 45
Loss: 0.09105411178244174
ROC train: 0.934066	val: 0.790695	test: 0.825280
PRC train: 0.597399	val: 0.366414	test: 0.472937

Epoch: 46
Loss: 0.0921664545810155
ROC train: 0.935267	val: 0.785859	test: 0.818877
PRC train: 0.600091	val: 0.359373	test: 0.451505

Epoch: 47
Loss: 0.09117082247867657
ROC train: 0.928460	val: 0.784775	test: 0.816085
PRC train: 0.590078	val: 0.366666	test: 0.426560

Epoch: 48
Loss: 0.0917446609208684
ROC train: 0.932469	val: 0.796343	test: 0.832898
PRC train: 0.574288	val: 0.340167	test: 0.440804

Epoch: 49
Loss: 0.09170827641812393
ROC train: 0.938630	val: 0.804414	test: 0.818347
PRC train: 0.595955	val: 0.374675	test: 0.431463

Epoch: 50
Loss: 0.08988561797937202
ROC train: 0.942226	val: 0.790576	test: 0.821772
PRC train: 0.615881	val: 0.361275	test: 0.439055

Epoch: 51
Loss: 0.09050367005266484
ROC train: 0.939018	val: 0.790237	test: 0.824488
PRC train: 0.611517	val: 0.376139	test: 0.434869

Epoch: 52
Loss: 0.0907161940130937
ROC train: 0.944991	val: 0.797583	test: 0.827559
PRC train: 0.625333	val: 0.358889	test: 0.458058

Epoch: 53
Loss: 0.08895053818891141
ROC train: 0.947003	val: 0.788082	test: 0.825142
PRC train: 0.650787	val: 0.400516	test: 0.460215

Epoch: 54
Loss: 0.08987442904284577
ROC train: 0.930912	val: 0.795469	test: 0.811254
PRC train: 0.595270	val: 0.372024	test: 0.432483

Epoch: 55
Loss: 0.0877469047607995
ROC train: 0.950525	val: 0.799826	test: 0.816182
PRC train: 0.651676	val: 0.377729	test: 0.452983

Epoch: 56
Loss: 0.08832771496511568
ROC train: 0.949465	val: 0.789912	test: 0.816750
PRC train: 0.653878	val: 0.391073	test: 0.458834

Epoch: 57
Loss: 0.08757886513816474
ROC train: 0.949435	val: 0.795572	test: 0.829036
PRC train: 0.631091	val: 0.389587	test: 0.446618

Epoch: 58
Loss: 0.08801293373439402
ROC train: 0.944182	val: 0.787504	test: 0.821288
PRC train: 0.627304	val: 0.383097	test: 0.436967

Epoch: 59
Loss: 0.08684869676868293
ROC train: 0.953128	val: 0.784494	test: 0.828086
PRC train: 0.651579	val: 0.368822	test: 0.446859

Epoch: 60
Loss: 0.08704780786256501
ROC train: 0.954773	val: 0.792939	test: 0.825062
PRC train: 0.665066	val: 0.371975	test: 0.456475

Epoch: 61
Loss: 0.08601873532323857
ROC train: 0.955047	val: 0.798317	test: 0.827664
PRC train: 0.668019	val: 0.382916	test: 0.452131

Epoch: 62
Loss: 0.08578105077906568
ROC train: 0.961053	val: 0.804898	test: 0.823034
PRC train: 0.682340	val: 0.400170	test: 0.456384

Epoch: 63
Loss: 0.08482229403495939
ROC train: 0.954518	val: 0.792635	test: 0.817047
PRC train: 0.649976	val: 0.397225	test: 0.464198

Epoch: 64
Loss: 0.08580659938847306
ROC train: 0.961623	val: 0.793221	test: 0.820994
PRC train: 0.682522	val: 0.394275	test: 0.442379

Epoch: 65
Loss: 0.08349255062065354
ROC train: 0.955458	val: 0.783393	test: 0.816912
PRC train: 0.650924	val: 0.361119	test: 0.436462

Epoch: 66
Loss: 0.08409958965461928
ROC train: 0.960674	val: 0.792696	test: 0.819807
PRC train: 0.689035	val: 0.392053	test: 0.438845

Epoch: 67
Loss: 0.08312036022770196
ROC train: 0.956785	val: 0.795419	test: 0.816188
PRC train: 0.668823	val: 0.394209	test: 0.425827

Epoch: 68
Loss: 0.08252331711972832
ROC train: 0.961254	val: 0.782933	test: 0.808173
PRC train: 0.674935	val: 0.377777	test: 0.412277

Epoch: 69
Loss: 0.0835132012974991
ROC train: 0.963260	val: 0.795810	test: 0.813221
PRC train: 0.694086	val: 0.391734	test: 0.449059

Epoch: 70
Loss: 0.08174003209065918
ROC train: 0.964208	val: 0.787219	test: 0.823554
PRC train: 0.694208	val: 0.398690	test: 0.457053

Epoch: 71
Loss: 0.08100457048209754
ROC train: 0.963434	val: 0.795904	test: 0.810487
PRC train: 0.690017	val: 0.373633	test: 0.425644

Epoch: 72
Loss: 0.08116063190607588
ROC train: 0.962182	val: 0.787716	test: 0.811815
PRC train: 0.686295	val: 0.393087	test: 0.447855

Epoch: 73
Loss: 0.0788954362016771
ROC train: 0.965156	val: 0.799475	test: 0.816767
PRC train: 0.701467	val: 0.387651	test: 0.426115

Epoch: 74
Loss: 0.08163454595719095
ROC train: 0.964609	val: 0.798576	test: 0.815662
PRC train: 0.684834	val: 0.376602	test: 0.431791

Epoch: 75
Loss: 0.08099692785407782
ROC train: 0.969615	val: 0.807262	test: 0.818084
PRC train: 0.725148	val: 0.400752	test: 0.439372

Epoch: 76
Loss: 0.07855852273854266
ROC train: 0.962151	val: 0.796070	test: 0.816369
PRC train: 0.686272	val: 0.398194	test: 0.432057

Epoch: 77
Loss: 0.0804884640312131
ROC train: 0.963519	val: 0.802634	test: 0.816435
PRC train: 0.687210	val: 0.389352	test: 0.409474

Epoch: 78
Loss: 0.08098506336335887
ROC train: 0.968847	val: 0.804198	test: 0.811333
PRC train: 0.706631	val: 0.385889	test: 0.423444

Epoch: 79
Loss: 0.07904642705531484
ROC train: 0.969182	val: 0.801044	test: 0.819437
PRC train: 0.708202	val: 0.395499	test: 0.433620

Epoch: 80
Loss: 0.07982928424233315
ROC train: 0.971411	val: 0.798523	test: 0.822451
PRC train: 0.718839	val: 0.404665	test: 0.438199

Epoch: 81
Loss: 0.07726126120530448
ROC train: 0.970734	val: 0.796640	test: 0.818600
PRC train: 0.728614	val: 0.405183	test: 0.451095

Epoch: 82
Loss: 0.07963049038264274
ROC train: 0.973507	val: 0.801307	test: 0.817830
PRC train: 0.731237	val: 0.401395	test: 0.438639

Epoch: 83
Loss: 0.07789090173729894
ROC train: 0.966615	val: 0.799075	test: 0.820903
PRC train: 0.693926	val: 0.400406	test: 0.423011

Epoch: 84
Loss: 0.07568589675496257
ROC train: 0.968945	val: 0.804657	test: 0.818745
PRC train: 0.722264	val: 0.408522	test: 0.431239

Epoch: 85
Loss: 0.07475410177827219
ROC train: 0.971242	val: 0.795341	test: 0.809558
PRC train: 0.706767	val: 0.388825	test: 0.415978

Epoch: 86
Loss: 0.07715177464381756
ROC train: 0.972781	val: 0.791531	test: 0.813366
PRC train: 0.731989	val: 0.390369	test: 0.424995

Epoch: 87
Loss: 0.07451777568298049
ROC train: 0.973515	val: 0.799323	test: 0.816103
PRC train: 0.732156	val: 0.381468	test: 0.437765

Epoch: 88
Loss: 0.07487528317368153
ROC train: 0.974736	val: 0.787775	test: 0.811549
PRC train: 0.741634	val: 0.394750	test: 0.429735

Epoch: 89
Loss: 0.07469635099886435
ROC train: 0.975706	val: 0.792399	test: 0.818704
PRC train: 0.746192	val: 0.390536	test: 0.427478

Epoch: 90
Loss: 0.07505624830027562
ROC train: 0.974353	val: 0.797680	test: 0.820306
PRC train: 0.750284	val: 0.408873	test: 0.446603

Epoch: 91
Loss: 0.07392532532897397
ROC train: 0.971522	val: 0.796907	test: 0.814653
PRC train: 0.713664	val: 0.389388	test: 0.400387

Epoch: 92
Loss: 0.07342351452411958
ROC train: 0.973915	val: 0.798192	test: 0.815712
PRC train: 0.741279	val: 0.401952	test: 0.434829

Epoch: 93
Loss: 0.0732449538254317
ROC train: 0.978293	val: 0.797676	test: 0.817739
PRC train: 0.769182	val: 0.404918	test: 0.439899

Epoch: 94
Loss: 0.0738787648877487
ROC train: 0.913253	val: 0.790936	test: 0.821711
PRC train: 0.549836	val: 0.370305	test: 0.431718

Epoch: 34
Loss: 0.09866105357550502
ROC train: 0.910251	val: 0.793120	test: 0.819144
PRC train: 0.527573	val: 0.362515	test: 0.422619

Epoch: 35
Loss: 0.09739401099082567
ROC train: 0.922536	val: 0.773322	test: 0.825233
PRC train: 0.577251	val: 0.382833	test: 0.464117

Epoch: 36
Loss: 0.096504502829566
ROC train: 0.921167	val: 0.795552	test: 0.828195
PRC train: 0.569525	val: 0.376090	test: 0.445707

Epoch: 37
Loss: 0.09528396143485059
ROC train: 0.922072	val: 0.761603	test: 0.810977
PRC train: 0.562305	val: 0.344877	test: 0.425390

Epoch: 38
Loss: 0.09661893923374668
ROC train: 0.913530	val: 0.795443	test: 0.820957
PRC train: 0.546108	val: 0.357145	test: 0.427178

Epoch: 39
Loss: 0.09568720849660972
ROC train: 0.921969	val: 0.779515	test: 0.832322
PRC train: 0.569653	val: 0.353601	test: 0.451618

Epoch: 40
Loss: 0.09609350599379568
ROC train: 0.929066	val: 0.778914	test: 0.824872
PRC train: 0.584640	val: 0.364231	test: 0.452061

Epoch: 41
Loss: 0.09401061818600077
ROC train: 0.915477	val: 0.776294	test: 0.814221
PRC train: 0.534881	val: 0.333797	test: 0.425229

Epoch: 42
Loss: 0.09476732776766175
ROC train: 0.935710	val: 0.778815	test: 0.816213
PRC train: 0.600387	val: 0.382172	test: 0.421723

Epoch: 43
Loss: 0.09217700416043403
ROC train: 0.936192	val: 0.776356	test: 0.825301
PRC train: 0.574690	val: 0.353036	test: 0.436652

Epoch: 44
Loss: 0.09287881001309096
ROC train: 0.936060	val: 0.789183	test: 0.831545
PRC train: 0.597545	val: 0.380502	test: 0.455413

Epoch: 45
Loss: 0.09342270864684557
ROC train: 0.936308	val: 0.772201	test: 0.829080
PRC train: 0.604911	val: 0.380035	test: 0.442027

Epoch: 46
Loss: 0.09326805654634504
ROC train: 0.939021	val: 0.778765	test: 0.827980
PRC train: 0.619682	val: 0.372456	test: 0.457677

Epoch: 47
Loss: 0.09003612351033785
ROC train: 0.940162	val: 0.778319	test: 0.828057
PRC train: 0.616089	val: 0.362894	test: 0.453660

Epoch: 48
Loss: 0.09149179883216055
ROC train: 0.940167	val: 0.785400	test: 0.830295
PRC train: 0.599595	val: 0.395952	test: 0.438315

Epoch: 49
Loss: 0.09086809259873878
ROC train: 0.936716	val: 0.778571	test: 0.824495
PRC train: 0.589751	val: 0.385324	test: 0.423486

Epoch: 50
Loss: 0.09078270698981916
ROC train: 0.948109	val: 0.785068	test: 0.831094
PRC train: 0.639783	val: 0.382996	test: 0.448891

Epoch: 51
Loss: 0.08984754209457298
ROC train: 0.945785	val: 0.773642	test: 0.820899
PRC train: 0.629165	val: 0.367645	test: 0.420765

Epoch: 52
Loss: 0.08890020827988049
ROC train: 0.941008	val: 0.777323	test: 0.828529
PRC train: 0.607379	val: 0.358611	test: 0.444306

Epoch: 53
Loss: 0.08799065759894342
ROC train: 0.948743	val: 0.779134	test: 0.828872
PRC train: 0.634452	val: 0.382383	test: 0.437973

Epoch: 54
Loss: 0.08944730896715408
ROC train: 0.944739	val: 0.789194	test: 0.828384
PRC train: 0.631879	val: 0.383030	test: 0.444610

Epoch: 55
Loss: 0.08859531932258655
ROC train: 0.952027	val: 0.776822	test: 0.820660
PRC train: 0.649884	val: 0.390163	test: 0.440005

Epoch: 56
Loss: 0.08468095075341149
ROC train: 0.949435	val: 0.790806	test: 0.819943
PRC train: 0.633765	val: 0.367945	test: 0.444376

Epoch: 57
Loss: 0.08702700229205484
ROC train: 0.954153	val: 0.789164	test: 0.822175
PRC train: 0.651797	val: 0.400222	test: 0.435021

Epoch: 58
Loss: 0.08634581351821465
ROC train: 0.949570	val: 0.772773	test: 0.825187
PRC train: 0.644443	val: 0.392536	test: 0.446910

Epoch: 59
Loss: 0.08685525350283393
ROC train: 0.949468	val: 0.783432	test: 0.823283
PRC train: 0.638600	val: 0.371681	test: 0.430800

Epoch: 60
Loss: 0.08667622343889785
ROC train: 0.954063	val: 0.785448	test: 0.827271
PRC train: 0.655284	val: 0.398707	test: 0.428617

Epoch: 61
Loss: 0.08510066516876025
ROC train: 0.957223	val: 0.762238	test: 0.816746
PRC train: 0.663399	val: 0.381009	test: 0.429214

Epoch: 62
Loss: 0.08542200698959275
ROC train: 0.946500	val: 0.776635	test: 0.824569
PRC train: 0.633153	val: 0.365095	test: 0.440727

Epoch: 63
Loss: 0.08364235948338045
ROC train: 0.960937	val: 0.784963	test: 0.825674
PRC train: 0.687147	val: 0.401714	test: 0.448370

Epoch: 64
Loss: 0.08302642029022927
ROC train: 0.957690	val: 0.778817	test: 0.828901
PRC train: 0.667628	val: 0.392925	test: 0.445731

Epoch: 65
Loss: 0.08372163684199521
ROC train: 0.954520	val: 0.787475	test: 0.821528
PRC train: 0.656378	val: 0.375155	test: 0.451747

Epoch: 66
Loss: 0.08291351548705699
ROC train: 0.963180	val: 0.793509	test: 0.830095
PRC train: 0.697562	val: 0.389950	test: 0.444609

Epoch: 67
Loss: 0.08165906712855037
ROC train: 0.962398	val: 0.787479	test: 0.821366
PRC train: 0.696809	val: 0.385458	test: 0.435510

Epoch: 68
Loss: 0.08267398716556185
ROC train: 0.956309	val: 0.779767	test: 0.820391
PRC train: 0.670147	val: 0.367226	test: 0.436969

Epoch: 69
Loss: 0.08059603327775888
ROC train: 0.958095	val: 0.781624	test: 0.817627
PRC train: 0.658249	val: 0.348744	test: 0.435642

Epoch: 70
Loss: 0.08092260527987322
ROC train: 0.963330	val: 0.794719	test: 0.818929
PRC train: 0.700164	val: 0.402645	test: 0.432473

Epoch: 71
Loss: 0.08241336637307797
ROC train: 0.967881	val: 0.790907	test: 0.825032
PRC train: 0.702209	val: 0.396015	test: 0.434072

Epoch: 72
Loss: 0.0810193830690186
ROC train: 0.967148	val: 0.790058	test: 0.827302
PRC train: 0.706199	val: 0.388112	test: 0.433032

Epoch: 73
Loss: 0.07959107693796008
ROC train: 0.967421	val: 0.781295	test: 0.826352
PRC train: 0.713388	val: 0.385564	test: 0.431881

Epoch: 74
Loss: 0.07849342894635115
ROC train: 0.964129	val: 0.779784	test: 0.822247
PRC train: 0.685607	val: 0.382511	test: 0.434329

Epoch: 75
Loss: 0.07892932021376561
ROC train: 0.964355	val: 0.787859	test: 0.822543
PRC train: 0.700736	val: 0.394565	test: 0.417611

Epoch: 76
Loss: 0.07918614062944097
ROC train: 0.971930	val: 0.789008	test: 0.819428
PRC train: 0.728818	val: 0.404098	test: 0.446432

Epoch: 77
Loss: 0.07824419172747307
ROC train: 0.971601	val: 0.782838	test: 0.834627
PRC train: 0.723112	val: 0.398219	test: 0.459459

Epoch: 78
Loss: 0.07810701545302505
ROC train: 0.970933	val: 0.783199	test: 0.824733
PRC train: 0.712824	val: 0.385426	test: 0.426357

Epoch: 79
Loss: 0.07938600615128177
ROC train: 0.970751	val: 0.794089	test: 0.827057
PRC train: 0.718535	val: 0.402856	test: 0.434998

Epoch: 80
Loss: 0.07874228400821282
ROC train: 0.965004	val: 0.787492	test: 0.821427
PRC train: 0.700236	val: 0.404660	test: 0.425785

Epoch: 81
Loss: 0.07569739103187696
ROC train: 0.970492	val: 0.789431	test: 0.822969
PRC train: 0.730508	val: 0.402856	test: 0.427217

Epoch: 82
Loss: 0.07376774316544042
ROC train: 0.975732	val: 0.793353	test: 0.827766
PRC train: 0.758003	val: 0.403207	test: 0.437843

Epoch: 83
Loss: 0.0763145892350847
ROC train: 0.974862	val: 0.787687	test: 0.823362
PRC train: 0.742945	val: 0.401372	test: 0.445587

Epoch: 84
Loss: 0.07765431452878568
ROC train: 0.972462	val: 0.793370	test: 0.819674
PRC train: 0.728747	val: 0.396147	test: 0.433063

Epoch: 85
Loss: 0.07440885734910467
ROC train: 0.967997	val: 0.775073	test: 0.815040
PRC train: 0.702645	val: 0.353937	test: 0.420847

Epoch: 86
Loss: 0.07584831734025595
ROC train: 0.976813	val: 0.787469	test: 0.823322
PRC train: 0.752438	val: 0.402011	test: 0.453572

Epoch: 87
Loss: 0.0755368138977626
ROC train: 0.974672	val: 0.778642	test: 0.821089
PRC train: 0.752351	val: 0.388354	test: 0.425346

Epoch: 88
Loss: 0.07396920743884565
ROC train: 0.972882	val: 0.792169	test: 0.821879
PRC train: 0.731337	val: 0.386409	test: 0.419861

Epoch: 89
Loss: 0.0729165942428514
ROC train: 0.977223	val: 0.780833	test: 0.824495
PRC train: 0.753191	val: 0.398131	test: 0.434541

Epoch: 90
Loss: 0.07497443182092356
ROC train: 0.972523	val: 0.782365	test: 0.813817
PRC train: 0.732963	val: 0.388283	test: 0.444117

Epoch: 91
Loss: 0.07270127327582868
ROC train: 0.978713	val: 0.787579	test: 0.823183
PRC train: 0.771116	val: 0.397949	test: 0.414235

Epoch: 92
Loss: 0.071593298244849
ROC train: 0.978899	val: 0.783573	test: 0.828525
PRC train: 0.768326	val: 0.409496	test: 0.432153

Epoch: 93
Loss: 0.06933225532691324
ROC train: 0.978374	val: 0.790969	test: 0.824717
PRC train: 0.768201	val: 0.404538	test: 0.434116

Epoch: 94
Loss: 0.07128957017764935
ROC train: 0.920346	val: 0.794557	test: 0.825617
PRC train: 0.570618	val: 0.389111	test: 0.430914

Epoch: 34
Loss: 0.09727101429751986
ROC train: 0.916683	val: 0.796745	test: 0.821251
PRC train: 0.542201	val: 0.359333	test: 0.433567

Epoch: 35
Loss: 0.09719953884924597
ROC train: 0.908184	val: 0.783582	test: 0.811975
PRC train: 0.525303	val: 0.388671	test: 0.441594

Epoch: 36
Loss: 0.09655509426786861
ROC train: 0.922245	val: 0.794159	test: 0.816388
PRC train: 0.556794	val: 0.377270	test: 0.441677

Epoch: 37
Loss: 0.0953326544054671
ROC train: 0.912477	val: 0.784645	test: 0.814657
PRC train: 0.511540	val: 0.346180	test: 0.423887

Epoch: 38
Loss: 0.0952509613145242
ROC train: 0.918636	val: 0.790631	test: 0.819952
PRC train: 0.560425	val: 0.371887	test: 0.416535

Epoch: 39
Loss: 0.09343801114709283
ROC train: 0.923420	val: 0.788934	test: 0.820981
PRC train: 0.574579	val: 0.387662	test: 0.439731

Epoch: 40
Loss: 0.09515018865399304
ROC train: 0.935860	val: 0.789776	test: 0.828342
PRC train: 0.602956	val: 0.373011	test: 0.463994

Epoch: 41
Loss: 0.09410646394553863
ROC train: 0.934944	val: 0.800835	test: 0.823172
PRC train: 0.609544	val: 0.392963	test: 0.442509

Epoch: 42
Loss: 0.09411375410748922
ROC train: 0.940444	val: 0.802666	test: 0.827167
PRC train: 0.614328	val: 0.395901	test: 0.447688

Epoch: 43
Loss: 0.09140509140009177
ROC train: 0.937525	val: 0.802256	test: 0.826186
PRC train: 0.598706	val: 0.379300	test: 0.436186

Epoch: 44
Loss: 0.09344305223535868
ROC train: 0.933200	val: 0.791080	test: 0.823187
PRC train: 0.566909	val: 0.342960	test: 0.429079

Epoch: 45
Loss: 0.09353565993181982
ROC train: 0.935952	val: 0.792306	test: 0.834597
PRC train: 0.600501	val: 0.390519	test: 0.428327

Epoch: 46
Loss: 0.08990620405066883
ROC train: 0.936136	val: 0.793068	test: 0.826024
PRC train: 0.604982	val: 0.379270	test: 0.420615

Epoch: 47
Loss: 0.09051302916878555
ROC train: 0.941347	val: 0.797749	test: 0.829838
PRC train: 0.615560	val: 0.381841	test: 0.444838

Epoch: 48
Loss: 0.0890255384282891
ROC train: 0.935189	val: 0.796037	test: 0.825721
PRC train: 0.598132	val: 0.369658	test: 0.449687

Epoch: 49
Loss: 0.08768772850567591
ROC train: 0.944846	val: 0.796346	test: 0.828795
PRC train: 0.632429	val: 0.398095	test: 0.448106

Epoch: 50
Loss: 0.09074586127633263
ROC train: 0.948593	val: 0.788978	test: 0.820397
PRC train: 0.656310	val: 0.394710	test: 0.447757

Epoch: 51
Loss: 0.08805117197802674
ROC train: 0.945584	val: 0.792583	test: 0.822712
PRC train: 0.646327	val: 0.397861	test: 0.455689

Epoch: 52
Loss: 0.0881755562094428
ROC train: 0.950847	val: 0.804435	test: 0.833045
PRC train: 0.637989	val: 0.395374	test: 0.429799

Epoch: 53
Loss: 0.08746783025650043
ROC train: 0.948927	val: 0.792101	test: 0.822149
PRC train: 0.639104	val: 0.392366	test: 0.437587

Epoch: 54
Loss: 0.08693228621419613
ROC train: 0.951778	val: 0.793216	test: 0.828309
PRC train: 0.657681	val: 0.397341	test: 0.445796

Epoch: 55
Loss: 0.08833518280532192
ROC train: 0.942282	val: 0.794512	test: 0.823370
PRC train: 0.617120	val: 0.387168	test: 0.409619

Epoch: 56
Loss: 0.0867844660268312
ROC train: 0.952264	val: 0.796237	test: 0.824660
PRC train: 0.658134	val: 0.410920	test: 0.451132

Epoch: 57
Loss: 0.08614684996896745
ROC train: 0.953431	val: 0.794363	test: 0.822646
PRC train: 0.670322	val: 0.400409	test: 0.447652

Epoch: 58
Loss: 0.08721896344958024
ROC train: 0.954635	val: 0.786712	test: 0.822298
PRC train: 0.667174	val: 0.402926	test: 0.426396

Epoch: 59
Loss: 0.08594899817850837
ROC train: 0.939207	val: 0.790401	test: 0.805930
PRC train: 0.558513	val: 0.374038	test: 0.396801

Epoch: 60
Loss: 0.08582614574153645
ROC train: 0.954487	val: 0.789767	test: 0.818961
PRC train: 0.657247	val: 0.393410	test: 0.452835

Epoch: 61
Loss: 0.08343351365647168
ROC train: 0.954301	val: 0.788718	test: 0.814153
PRC train: 0.668746	val: 0.382422	test: 0.436389

Epoch: 62
Loss: 0.08360481876982764
ROC train: 0.954390	val: 0.786012	test: 0.827475
PRC train: 0.675065	val: 0.393600	test: 0.447362

Epoch: 63
Loss: 0.08360338205507578
ROC train: 0.955231	val: 0.788255	test: 0.827400
PRC train: 0.669297	val: 0.371597	test: 0.441494

Epoch: 64
Loss: 0.08429090738111096
ROC train: 0.963458	val: 0.793557	test: 0.821813
PRC train: 0.689793	val: 0.388330	test: 0.455741

Epoch: 65
Loss: 0.08452916653908833
ROC train: 0.958477	val: 0.789414	test: 0.819948
PRC train: 0.681192	val: 0.377910	test: 0.436775

Epoch: 66
Loss: 0.08220017423077326
ROC train: 0.962135	val: 0.803022	test: 0.826083
PRC train: 0.690808	val: 0.399421	test: 0.462472

Epoch: 67
Loss: 0.08225948046725147
ROC train: 0.960974	val: 0.798685	test: 0.825784
PRC train: 0.694722	val: 0.409209	test: 0.457097

Epoch: 68
Loss: 0.08095709426596982
ROC train: 0.958872	val: 0.792222	test: 0.819090
PRC train: 0.686793	val: 0.401380	test: 0.447596

Epoch: 69
Loss: 0.08086979480049988
ROC train: 0.964526	val: 0.798578	test: 0.829565
PRC train: 0.691937	val: 0.392798	test: 0.453698

Epoch: 70
Loss: 0.08052389404881423
ROC train: 0.964862	val: 0.791421	test: 0.825505
PRC train: 0.702381	val: 0.381968	test: 0.448223

Epoch: 71
Loss: 0.08239544400613993
ROC train: 0.960333	val: 0.800179	test: 0.820733
PRC train: 0.693640	val: 0.390076	test: 0.425617

Epoch: 72
Loss: 0.07931805520505554
ROC train: 0.968205	val: 0.795977	test: 0.821524
PRC train: 0.722946	val: 0.403540	test: 0.452164

Epoch: 73
Loss: 0.07899457763980622
ROC train: 0.969507	val: 0.792983	test: 0.816932
PRC train: 0.725462	val: 0.409158	test: 0.440621

Epoch: 74
Loss: 0.07934418379786867
ROC train: 0.970311	val: 0.797624	test: 0.822188
PRC train: 0.723945	val: 0.411421	test: 0.444341

Epoch: 75
Loss: 0.07799743406434491
ROC train: 0.962362	val: 0.795062	test: 0.823174
PRC train: 0.696440	val: 0.378462	test: 0.412013

Epoch: 76
Loss: 0.0775408118928923
ROC train: 0.963211	val: 0.800631	test: 0.814712
PRC train: 0.692864	val: 0.391189	test: 0.419952

Epoch: 77
Loss: 0.07736518966617116
ROC train: 0.970220	val: 0.797131	test: 0.821301
PRC train: 0.722097	val: 0.396944	test: 0.434581

Epoch: 78
Loss: 0.07847787680812983
ROC train: 0.972646	val: 0.792116	test: 0.818921
PRC train: 0.731628	val: 0.404465	test: 0.438016

Epoch: 79
Loss: 0.07867281878690818
ROC train: 0.972576	val: 0.800094	test: 0.820719
PRC train: 0.741109	val: 0.424823	test: 0.452161

Epoch: 80
Loss: 0.07595473276538617
ROC train: 0.971912	val: 0.793885	test: 0.823812
PRC train: 0.736051	val: 0.411004	test: 0.450535

Epoch: 81
Loss: 0.07662143191819752
ROC train: 0.970038	val: 0.786881	test: 0.811322
PRC train: 0.740034	val: 0.404962	test: 0.428698

Epoch: 82
Loss: 0.0757726469606744
ROC train: 0.964326	val: 0.793171	test: 0.818511
PRC train: 0.683193	val: 0.359134	test: 0.425438

Epoch: 83
Loss: 0.07609153471207561
ROC train: 0.972883	val: 0.798792	test: 0.814595
PRC train: 0.727012	val: 0.401436	test: 0.420583

Epoch: 84
Loss: 0.07732068764212222
ROC train: 0.975265	val: 0.797910	test: 0.817417
PRC train: 0.753014	val: 0.392665	test: 0.448207

Epoch: 85
Loss: 0.07497716085777581
ROC train: 0.975718	val: 0.792336	test: 0.814111
PRC train: 0.752683	val: 0.406062	test: 0.432065

Epoch: 86
Loss: 0.07418188379166049
ROC train: 0.976542	val: 0.796555	test: 0.817248
PRC train: 0.757294	val: 0.415791	test: 0.426516

Epoch: 87
Loss: 0.07370677564260426
ROC train: 0.975251	val: 0.797579	test: 0.812532
PRC train: 0.755583	val: 0.407493	test: 0.425314

Epoch: 88
Loss: 0.07364941755204893
ROC train: 0.976857	val: 0.801195	test: 0.811748
PRC train: 0.758407	val: 0.407993	test: 0.429681

Epoch: 89
Loss: 0.07389857219129617
ROC train: 0.977629	val: 0.803907	test: 0.826625
PRC train: 0.770323	val: 0.417735	test: 0.434084

Epoch: 90
Loss: 0.07382476219767685
ROC train: 0.976875	val: 0.794494	test: 0.815688
PRC train: 0.753197	val: 0.405563	test: 0.423078

Epoch: 91
Loss: 0.0732634509437667
ROC train: 0.978374	val: 0.799064	test: 0.818969
PRC train: 0.772459	val: 0.407520	test: 0.419420

Epoch: 92
Loss: 0.07357519493013531
ROC train: 0.976434	val: 0.804548	test: 0.815153
PRC train: 0.752339	val: 0.405114	test: 0.434580

Epoch: 93
Loss: 0.07246413841003436
ROC train: 0.979053	val: 0.797384	test: 0.816119
PRC train: 0.773039	val: 0.392050	test: 0.434132

Epoch: 94
Loss: 0.07404740283831913
ROC train: 0.907574	val: 0.792336	test: 0.850529
PRC train: 0.536546	val: 0.436435	test: 0.438355

Epoch: 34
Loss: 0.09563471227022861
ROC train: 0.922110	val: 0.811384	test: 0.854930
PRC train: 0.587467	val: 0.446288	test: 0.448054

Epoch: 35
Loss: 0.09630499282558062
ROC train: 0.920331	val: 0.806434	test: 0.870212
PRC train: 0.564565	val: 0.437644	test: 0.441385

Epoch: 36
Loss: 0.09619748798669303
ROC train: 0.925336	val: 0.798894	test: 0.854419
PRC train: 0.580939	val: 0.442899	test: 0.468913

Epoch: 37
Loss: 0.0950875774277485
ROC train: 0.920918	val: 0.809532	test: 0.848412
PRC train: 0.569845	val: 0.416866	test: 0.466834

Epoch: 38
Loss: 0.09463602813212701
ROC train: 0.918167	val: 0.807535	test: 0.838582
PRC train: 0.555517	val: 0.421759	test: 0.406471

Epoch: 39
Loss: 0.09403252167190505
ROC train: 0.919302	val: 0.806654	test: 0.833038
PRC train: 0.572048	val: 0.435311	test: 0.425850

Epoch: 40
Loss: 0.09426991383281366
ROC train: 0.923045	val: 0.817466	test: 0.858785
PRC train: 0.565916	val: 0.419117	test: 0.454900

Epoch: 41
Loss: 0.09422713146044337
ROC train: 0.928882	val: 0.815527	test: 0.850981
PRC train: 0.595071	val: 0.433757	test: 0.454837

Epoch: 42
Loss: 0.09204817738658233
ROC train: 0.931714	val: 0.811271	test: 0.862660
PRC train: 0.598386	val: 0.425602	test: 0.468369

Epoch: 43
Loss: 0.09147673036656617
ROC train: 0.932717	val: 0.807604	test: 0.858179
PRC train: 0.608515	val: 0.439635	test: 0.449396

Epoch: 44
Loss: 0.09285869272764868
ROC train: 0.932302	val: 0.809542	test: 0.859424
PRC train: 0.592655	val: 0.434496	test: 0.454667

Epoch: 45
Loss: 0.0913647417380676
ROC train: 0.928075	val: 0.805865	test: 0.839214
PRC train: 0.593510	val: 0.419089	test: 0.441957

Epoch: 46
Loss: 0.08932570531294112
ROC train: 0.933388	val: 0.810279	test: 0.841258
PRC train: 0.598795	val: 0.430327	test: 0.432303

Epoch: 47
Loss: 0.0903298038250287
ROC train: 0.943176	val: 0.812085	test: 0.852223
PRC train: 0.636571	val: 0.433205	test: 0.452178

Epoch: 48
Loss: 0.08926311173500931
ROC train: 0.943336	val: 0.806479	test: 0.855214
PRC train: 0.633144	val: 0.426153	test: 0.460869

Epoch: 49
Loss: 0.08903679399863419
ROC train: 0.943015	val: 0.817190	test: 0.842490
PRC train: 0.622573	val: 0.442137	test: 0.449148

Epoch: 50
Loss: 0.08966685009462994
ROC train: 0.940829	val: 0.819591	test: 0.849321
PRC train: 0.638250	val: 0.457794	test: 0.458559

Epoch: 51
Loss: 0.08836938683890323
ROC train: 0.938199	val: 0.811280	test: 0.838577
PRC train: 0.612867	val: 0.435816	test: 0.434711

Epoch: 52
Loss: 0.08779953130163738
ROC train: 0.950134	val: 0.811766	test: 0.853286
PRC train: 0.651282	val: 0.450684	test: 0.459191

Epoch: 53
Loss: 0.08737899872095113
ROC train: 0.948455	val: 0.796198	test: 0.841274
PRC train: 0.643247	val: 0.430443	test: 0.449663

Epoch: 54
Loss: 0.08734205729500269
ROC train: 0.953758	val: 0.817516	test: 0.858433
PRC train: 0.659402	val: 0.443536	test: 0.461641

Epoch: 55
Loss: 0.08714157940833708
ROC train: 0.947961	val: 0.805400	test: 0.848752
PRC train: 0.623683	val: 0.430425	test: 0.433065

Epoch: 56
Loss: 0.08473478295841204
ROC train: 0.951319	val: 0.808187	test: 0.846969
PRC train: 0.652539	val: 0.445554	test: 0.462917

Epoch: 57
Loss: 0.08588841124349392
ROC train: 0.938657	val: 0.807620	test: 0.829886
PRC train: 0.610487	val: 0.416142	test: 0.406616

Epoch: 58
Loss: 0.08633496138939116
ROC train: 0.946640	val: 0.809744	test: 0.838187
PRC train: 0.636984	val: 0.407861	test: 0.437617

Epoch: 59
Loss: 0.08431520781934188
ROC train: 0.954760	val: 0.816675	test: 0.843913
PRC train: 0.659903	val: 0.414146	test: 0.440645

Epoch: 60
Loss: 0.08432986100554798
ROC train: 0.955096	val: 0.810000	test: 0.850326
PRC train: 0.670458	val: 0.444164	test: 0.451533

Epoch: 61
Loss: 0.08415221828605424
ROC train: 0.953208	val: 0.812245	test: 0.846064
PRC train: 0.668092	val: 0.446816	test: 0.441954

Epoch: 62
Loss: 0.08541295285159761
ROC train: 0.945576	val: 0.808373	test: 0.831992
PRC train: 0.621746	val: 0.409700	test: 0.429721

Epoch: 63
Loss: 0.08326767919846556
ROC train: 0.959627	val: 0.815104	test: 0.844763
PRC train: 0.676266	val: 0.447987	test: 0.444638

Epoch: 64
Loss: 0.08353585230714965
ROC train: 0.960074	val: 0.822144	test: 0.845852
PRC train: 0.670106	val: 0.418828	test: 0.437290

Epoch: 65
Loss: 0.08279137035225548
ROC train: 0.949720	val: 0.812927	test: 0.832994
PRC train: 0.656887	val: 0.420621	test: 0.444143

Epoch: 66
Loss: 0.08273402597819865
ROC train: 0.961713	val: 0.821175	test: 0.853672
PRC train: 0.699757	val: 0.435257	test: 0.447279

Epoch: 67
Loss: 0.08251482993609464
ROC train: 0.958848	val: 0.811979	test: 0.847734
PRC train: 0.677719	val: 0.453894	test: 0.425424

Epoch: 68
Loss: 0.08123218121862213
ROC train: 0.955805	val: 0.812215	test: 0.848111
PRC train: 0.664487	val: 0.456600	test: 0.451199

Epoch: 69
Loss: 0.0811658422269979
ROC train: 0.961527	val: 0.820328	test: 0.841231
PRC train: 0.693442	val: 0.447336	test: 0.428902

Epoch: 70
Loss: 0.0797264950784642
ROC train: 0.968582	val: 0.804901	test: 0.843200
PRC train: 0.713300	val: 0.450361	test: 0.445519

Epoch: 71
Loss: 0.08106738519514733
ROC train: 0.964296	val: 0.826806	test: 0.837396
PRC train: 0.703251	val: 0.450002	test: 0.433101

Epoch: 72
Loss: 0.07979559561524519
ROC train: 0.964942	val: 0.812864	test: 0.839816
PRC train: 0.704456	val: 0.443478	test: 0.444258

Epoch: 73
Loss: 0.07857817388463541
ROC train: 0.967233	val: 0.816058	test: 0.848268
PRC train: 0.703922	val: 0.448566	test: 0.444888

Epoch: 74
Loss: 0.0788254190466602
ROC train: 0.969683	val: 0.820460	test: 0.853846
PRC train: 0.712889	val: 0.426254	test: 0.431879

Epoch: 75
Loss: 0.07857124319405165
ROC train: 0.964053	val: 0.803563	test: 0.844659
PRC train: 0.705300	val: 0.439112	test: 0.413478

Epoch: 76
Loss: 0.0781193197018793
ROC train: 0.968396	val: 0.812274	test: 0.853843
PRC train: 0.713839	val: 0.463615	test: 0.426261

Epoch: 77
Loss: 0.07727504404606755
ROC train: 0.972907	val: 0.818638	test: 0.855907
PRC train: 0.739130	val: 0.441265	test: 0.432638

Epoch: 78
Loss: 0.07560438933996169
ROC train: 0.970303	val: 0.806411	test: 0.842946
PRC train: 0.728031	val: 0.425309	test: 0.438332

Epoch: 79
Loss: 0.0756568978853506
ROC train: 0.970620	val: 0.816137	test: 0.845540
PRC train: 0.723880	val: 0.429559	test: 0.426341

Epoch: 80
Loss: 0.07835583387565506
ROC train: 0.968837	val: 0.802687	test: 0.840014
PRC train: 0.719870	val: 0.443351	test: 0.436144

Epoch: 81
Loss: 0.0781110562213106
ROC train: 0.969167	val: 0.813633	test: 0.847190
PRC train: 0.731056	val: 0.435103	test: 0.417840

Epoch: 82
Loss: 0.07565826347182782
ROC train: 0.971373	val: 0.811615	test: 0.844044
PRC train: 0.739930	val: 0.431638	test: 0.423156

Epoch: 83
Loss: 0.0757300119454379
ROC train: 0.974789	val: 0.815170	test: 0.849329
PRC train: 0.751146	val: 0.437939	test: 0.430564

Epoch: 84
Loss: 0.07586236645754273
ROC train: 0.974258	val: 0.821402	test: 0.837705
PRC train: 0.742313	val: 0.434613	test: 0.423779

Epoch: 85
Loss: 0.07125553448369494
ROC train: 0.975469	val: 0.803115	test: 0.846051
PRC train: 0.750884	val: 0.424011	test: 0.405744

Epoch: 86
Loss: 0.07273249872308296
ROC train: 0.969974	val: 0.821522	test: 0.833214
PRC train: 0.727212	val: 0.455565	test: 0.392250

Epoch: 87
Loss: 0.07566999392047882
ROC train: 0.976465	val: 0.817914	test: 0.845788
PRC train: 0.755438	val: 0.436475	test: 0.407259

Epoch: 88
Loss: 0.07444316342751074
ROC train: 0.978160	val: 0.818679	test: 0.847210
PRC train: 0.768956	val: 0.441779	test: 0.422730

Epoch: 89
Loss: 0.07291420922766771
ROC train: 0.979849	val: 0.822175	test: 0.843249
PRC train: 0.774433	val: 0.443310	test: 0.406428

Epoch: 90
Loss: 0.07424297249037333
ROC train: 0.969935	val: 0.801449	test: 0.847522
PRC train: 0.701184	val: 0.419077	test: 0.411290

Epoch: 91
Loss: 0.07244909798896186
ROC train: 0.977650	val: 0.811956	test: 0.847426
PRC train: 0.762478	val: 0.440514	test: 0.429127

Epoch: 92
Loss: 0.07193912197235403
ROC train: 0.978415	val: 0.817563	test: 0.849428
PRC train: 0.770574	val: 0.444096	test: 0.414025

Epoch: 93
Loss: 0.07141753888767192
ROC train: 0.977757	val: 0.815271	test: 0.843419
PRC train: 0.767664	val: 0.429172	test: 0.425685

Epoch: 94
Loss: 0.07188572578992224
ROC train: 0.914045	val: 0.801454	test: 0.832096
PRC train: 0.536105	val: 0.395081	test: 0.417257

Epoch: 34
Loss: 0.0958230170701093
ROC train: 0.921941	val: 0.805435	test: 0.844168
PRC train: 0.569246	val: 0.426771	test: 0.443624

Epoch: 35
Loss: 0.09445330105418799
ROC train: 0.921015	val: 0.795845	test: 0.840693
PRC train: 0.559219	val: 0.414892	test: 0.447940

Epoch: 36
Loss: 0.0948122747657279
ROC train: 0.924433	val: 0.809777	test: 0.833219
PRC train: 0.573546	val: 0.427519	test: 0.427262

Epoch: 37
Loss: 0.09552098737730767
ROC train: 0.928210	val: 0.802628	test: 0.846950
PRC train: 0.584492	val: 0.437950	test: 0.466571

Epoch: 38
Loss: 0.09437504213171431
ROC train: 0.927316	val: 0.794897	test: 0.825686
PRC train: 0.576164	val: 0.420295	test: 0.437285

Epoch: 39
Loss: 0.09282300916064383
ROC train: 0.930234	val: 0.803199	test: 0.844405
PRC train: 0.580945	val: 0.426133	test: 0.436236

Epoch: 40
Loss: 0.09330412758611795
ROC train: 0.937559	val: 0.797142	test: 0.839177
PRC train: 0.605351	val: 0.441412	test: 0.459431

Epoch: 41
Loss: 0.09271214402708629
ROC train: 0.935064	val: 0.799332	test: 0.837508
PRC train: 0.607230	val: 0.452299	test: 0.455362

Epoch: 42
Loss: 0.0919189801923907
ROC train: 0.932570	val: 0.799641	test: 0.839208
PRC train: 0.609252	val: 0.457358	test: 0.453612

Epoch: 43
Loss: 0.0913485396623011
ROC train: 0.917785	val: 0.789794	test: 0.830142
PRC train: 0.533053	val: 0.384022	test: 0.347866

Epoch: 44
Loss: 0.09151355138003081
ROC train: 0.940123	val: 0.786492	test: 0.835405
PRC train: 0.606335	val: 0.444181	test: 0.457295

Epoch: 45
Loss: 0.09103780057480726
ROC train: 0.941961	val: 0.788271	test: 0.834070
PRC train: 0.610437	val: 0.444833	test: 0.428224

Epoch: 46
Loss: 0.09061929372233993
ROC train: 0.937109	val: 0.799510	test: 0.831715
PRC train: 0.611426	val: 0.440461	test: 0.436658

Epoch: 47
Loss: 0.08835259950149021
ROC train: 0.948504	val: 0.806727	test: 0.844330
PRC train: 0.647331	val: 0.461551	test: 0.460387

Epoch: 48
Loss: 0.08834397637783872
ROC train: 0.948060	val: 0.801428	test: 0.842358
PRC train: 0.637590	val: 0.441619	test: 0.445355

Epoch: 49
Loss: 0.0887574011073994
ROC train: 0.949778	val: 0.803716	test: 0.852204
PRC train: 0.651936	val: 0.435014	test: 0.449708

Epoch: 50
Loss: 0.0870095335223448
ROC train: 0.952274	val: 0.804148	test: 0.843473
PRC train: 0.649749	val: 0.446085	test: 0.441879

Epoch: 51
Loss: 0.08641503185789802
ROC train: 0.943664	val: 0.808948	test: 0.851130
PRC train: 0.635627	val: 0.431849	test: 0.426820

Epoch: 52
Loss: 0.0872129241584734
ROC train: 0.948937	val: 0.811651	test: 0.829590
PRC train: 0.647414	val: 0.453209	test: 0.438604

Epoch: 53
Loss: 0.08724392338221666
ROC train: 0.947003	val: 0.798553	test: 0.830016
PRC train: 0.640519	val: 0.428925	test: 0.412363

Epoch: 54
Loss: 0.08657314604180473
ROC train: 0.955631	val: 0.803227	test: 0.845229
PRC train: 0.659291	val: 0.454698	test: 0.431897

Epoch: 55
Loss: 0.0859779601869567
ROC train: 0.945505	val: 0.814475	test: 0.833718
PRC train: 0.616256	val: 0.434019	test: 0.415305

Epoch: 56
Loss: 0.0858177083014923
ROC train: 0.956239	val: 0.809743	test: 0.845646
PRC train: 0.657809	val: 0.447426	test: 0.430021

Epoch: 57
Loss: 0.08480616083306292
ROC train: 0.955928	val: 0.793313	test: 0.835254
PRC train: 0.662149	val: 0.434887	test: 0.440422

Epoch: 58
Loss: 0.08449892927652072
ROC train: 0.952735	val: 0.796243	test: 0.829026
PRC train: 0.635235	val: 0.423161	test: 0.428084

Epoch: 59
Loss: 0.08494586958548295
ROC train: 0.957808	val: 0.805987	test: 0.831754
PRC train: 0.671330	val: 0.434822	test: 0.442841

Epoch: 60
Loss: 0.0829048969581765
ROC train: 0.959806	val: 0.791344	test: 0.835563
PRC train: 0.682142	val: 0.440120	test: 0.453156

Epoch: 61
Loss: 0.08325053257178297
ROC train: 0.955737	val: 0.793594	test: 0.835263
PRC train: 0.667716	val: 0.445173	test: 0.448717

Epoch: 62
Loss: 0.083504018267773
ROC train: 0.960403	val: 0.812464	test: 0.854463
PRC train: 0.677917	val: 0.453924	test: 0.450148

Epoch: 63
Loss: 0.08317354571072964
ROC train: 0.958591	val: 0.797521	test: 0.844347
PRC train: 0.676955	val: 0.438409	test: 0.450259

Epoch: 64
Loss: 0.08005375642452489
ROC train: 0.961960	val: 0.803293	test: 0.833229
PRC train: 0.687755	val: 0.426043	test: 0.446016

Epoch: 65
Loss: 0.08140014075352353
ROC train: 0.963228	val: 0.788362	test: 0.840408
PRC train: 0.692227	val: 0.438549	test: 0.452656

Epoch: 66
Loss: 0.08057616538737314
ROC train: 0.966751	val: 0.801365	test: 0.834215
PRC train: 0.710983	val: 0.441727	test: 0.438638

Epoch: 67
Loss: 0.08032261265429866
ROC train: 0.963071	val: 0.808404	test: 0.838229
PRC train: 0.694507	val: 0.443415	test: 0.435782

Epoch: 68
Loss: 0.07998530268262803
ROC train: 0.959512	val: 0.796438	test: 0.826786
PRC train: 0.687194	val: 0.440825	test: 0.445328

Epoch: 69
Loss: 0.07917708100849405
ROC train: 0.969078	val: 0.792704	test: 0.835659
PRC train: 0.712415	val: 0.449246	test: 0.451822

Epoch: 70
Loss: 0.08021930361460233
ROC train: 0.964121	val: 0.801144	test: 0.822813
PRC train: 0.702760	val: 0.420564	test: 0.444624

Epoch: 71
Loss: 0.07976240558006552
ROC train: 0.962873	val: 0.797881	test: 0.834534
PRC train: 0.686764	val: 0.439062	test: 0.430262

Epoch: 72
Loss: 0.07899073021986373
ROC train: 0.966064	val: 0.795244	test: 0.828033
PRC train: 0.699890	val: 0.447963	test: 0.437974

Epoch: 73
Loss: 0.07854212312357112
ROC train: 0.968805	val: 0.793276	test: 0.838525
PRC train: 0.715620	val: 0.441860	test: 0.455668

Epoch: 74
Loss: 0.07903206652065975
ROC train: 0.969655	val: 0.801482	test: 0.841308
PRC train: 0.722580	val: 0.436427	test: 0.434818

Epoch: 75
Loss: 0.07762922249324282
ROC train: 0.969555	val: 0.801872	test: 0.835185
PRC train: 0.728308	val: 0.444110	test: 0.456458

Epoch: 76
Loss: 0.07795799297892544
ROC train: 0.972245	val: 0.801832	test: 0.839724
PRC train: 0.730464	val: 0.444397	test: 0.430303

Epoch: 77
Loss: 0.07702627901264544
ROC train: 0.971446	val: 0.797606	test: 0.835711
PRC train: 0.741504	val: 0.443746	test: 0.431844

Epoch: 78
Loss: 0.0753736042182027
ROC train: 0.970447	val: 0.808478	test: 0.830832
PRC train: 0.729732	val: 0.444708	test: 0.421303

Epoch: 79
Loss: 0.07576420975292379
ROC train: 0.966290	val: 0.795280	test: 0.824727
PRC train: 0.716007	val: 0.418583	test: 0.416129

Epoch: 80
Loss: 0.07683267054244344
ROC train: 0.972446	val: 0.800723	test: 0.832999
PRC train: 0.741343	val: 0.434168	test: 0.415608

Epoch: 81
Loss: 0.07654659051818788
ROC train: 0.965363	val: 0.798467	test: 0.844945
PRC train: 0.703970	val: 0.438961	test: 0.430564

Epoch: 82
Loss: 0.07523791857623652
ROC train: 0.970520	val: 0.797844	test: 0.837231
PRC train: 0.719933	val: 0.423414	test: 0.425659

Epoch: 83
Loss: 0.0754607823541465
ROC train: 0.971586	val: 0.791190	test: 0.845452
PRC train: 0.726880	val: 0.424250	test: 0.441852

Epoch: 84
Loss: 0.0755805256568748
ROC train: 0.972313	val: 0.801324	test: 0.833506
PRC train: 0.728854	val: 0.445808	test: 0.424577

Epoch: 85
Loss: 0.07418798809058814
ROC train: 0.978399	val: 0.799832	test: 0.836571
PRC train: 0.765079	val: 0.428785	test: 0.431992

Epoch: 86
Loss: 0.07341495167536752
ROC train: 0.977819	val: 0.797818	test: 0.830865
PRC train: 0.762758	val: 0.438719	test: 0.435264

Epoch: 87
Loss: 0.07411660426279663
ROC train: 0.976709	val: 0.796375	test: 0.837870
PRC train: 0.755804	val: 0.442031	test: 0.437807

Epoch: 88
Loss: 0.07073249138131167
ROC train: 0.977957	val: 0.793417	test: 0.826681
PRC train: 0.757181	val: 0.412990	test: 0.419328

Epoch: 89
Loss: 0.07322184665658275
ROC train: 0.977897	val: 0.801748	test: 0.838277
PRC train: 0.763873	val: 0.458556	test: 0.433499

Epoch: 90
Loss: 0.07303423871968055
ROC train: 0.980297	val: 0.794518	test: 0.837047
PRC train: 0.777579	val: 0.433229	test: 0.436100

Epoch: 91
Loss: 0.07228372747710134
ROC train: 0.916868	val: 0.770341	test: 0.773967
PRC train: 0.496303	val: 0.298211	test: 0.245581

Epoch: 92
Loss: 0.07237117216323775
ROC train: 0.980342	val: 0.798917	test: 0.825851
PRC train: 0.778282	val: 0.440112	test: 0.431692

Epoch: 93
Loss: 0.07048327806038128
ROC train: 0.979287	val: 0.806362	test: 0.824974
PRC train: 0.776003	val: 0.433006	test: 0.423000

Epoch: 94
Loss: 0.0711166211404721
ROC train: 0.905302	val: 0.802631	test: 0.846845
PRC train: 0.533672	val: 0.451269	test: 0.441615

Epoch: 34
Loss: 0.09822623076183892
ROC train: 0.908068	val: 0.796895	test: 0.835460
PRC train: 0.538548	val: 0.427994	test: 0.426034

Epoch: 35
Loss: 0.09767954176626317
ROC train: 0.920740	val: 0.804256	test: 0.853363
PRC train: 0.569741	val: 0.444105	test: 0.448837

Epoch: 36
Loss: 0.09766160015974429
ROC train: 0.913953	val: 0.809973	test: 0.844350
PRC train: 0.549995	val: 0.438721	test: 0.436123

Epoch: 37
Loss: 0.09474515025004909
ROC train: 0.915893	val: 0.801750	test: 0.842135
PRC train: 0.538066	val: 0.437813	test: 0.443631

Epoch: 38
Loss: 0.0958800210605443
ROC train: 0.930435	val: 0.799948	test: 0.848615
PRC train: 0.584312	val: 0.448929	test: 0.474161

Epoch: 39
Loss: 0.09603242718875603
ROC train: 0.917152	val: 0.803309	test: 0.832840
PRC train: 0.552410	val: 0.438506	test: 0.419496

Epoch: 40
Loss: 0.0944046234075124
ROC train: 0.925485	val: 0.789896	test: 0.843942
PRC train: 0.577823	val: 0.430633	test: 0.439071

Epoch: 41
Loss: 0.09340683935320014
ROC train: 0.927556	val: 0.789943	test: 0.843775
PRC train: 0.595421	val: 0.432344	test: 0.451479

Epoch: 42
Loss: 0.0946385841750038
ROC train: 0.925563	val: 0.788836	test: 0.844922
PRC train: 0.588208	val: 0.444585	test: 0.470825

Epoch: 43
Loss: 0.09335254804603621
ROC train: 0.928923	val: 0.804873	test: 0.848120
PRC train: 0.614997	val: 0.443640	test: 0.464764

Epoch: 44
Loss: 0.09126963651979562
ROC train: 0.931445	val: 0.807912	test: 0.837807
PRC train: 0.592148	val: 0.415846	test: 0.441697

Epoch: 45
Loss: 0.09231269172538518
ROC train: 0.934394	val: 0.809230	test: 0.828535
PRC train: 0.604379	val: 0.440957	test: 0.432013

Epoch: 46
Loss: 0.0914667062382131
ROC train: 0.937716	val: 0.794505	test: 0.834998
PRC train: 0.612032	val: 0.455270	test: 0.440558

Epoch: 47
Loss: 0.09088913653753994
ROC train: 0.932174	val: 0.806860	test: 0.835873
PRC train: 0.598601	val: 0.427370	test: 0.424704

Epoch: 48
Loss: 0.09099729217830589
ROC train: 0.940291	val: 0.795890	test: 0.842381
PRC train: 0.610216	val: 0.438516	test: 0.454479

Epoch: 49
Loss: 0.09059851966088006
ROC train: 0.940243	val: 0.796268	test: 0.836530
PRC train: 0.622033	val: 0.446045	test: 0.448110

Epoch: 50
Loss: 0.08924514754728506
ROC train: 0.941420	val: 0.807382	test: 0.844936
PRC train: 0.622617	val: 0.451697	test: 0.448565

Epoch: 51
Loss: 0.08995117764874291
ROC train: 0.940818	val: 0.806890	test: 0.836858
PRC train: 0.619962	val: 0.443125	test: 0.459089

Epoch: 52
Loss: 0.08881732794907786
ROC train: 0.926225	val: 0.780145	test: 0.835778
PRC train: 0.545016	val: 0.339603	test: 0.400202

Epoch: 53
Loss: 0.08794928474215734
ROC train: 0.938394	val: 0.796102	test: 0.827034
PRC train: 0.617159	val: 0.430422	test: 0.458920

Epoch: 54
Loss: 0.08648613882849496
ROC train: 0.946355	val: 0.810332	test: 0.841285
PRC train: 0.645673	val: 0.451052	test: 0.464125

Epoch: 55
Loss: 0.08818351729314364
ROC train: 0.932982	val: 0.804408	test: 0.821895
PRC train: 0.594768	val: 0.434834	test: 0.400778

Epoch: 56
Loss: 0.08691551896259374
ROC train: 0.947387	val: 0.804438	test: 0.840852
PRC train: 0.634048	val: 0.428143	test: 0.462805

Epoch: 57
Loss: 0.08623476785949508
ROC train: 0.941941	val: 0.808839	test: 0.843535
PRC train: 0.623594	val: 0.424932	test: 0.436094

Epoch: 58
Loss: 0.08659565146030594
ROC train: 0.954476	val: 0.812585	test: 0.847832
PRC train: 0.658189	val: 0.459428	test: 0.454357

Epoch: 59
Loss: 0.08699832580306392
ROC train: 0.958351	val: 0.801838	test: 0.848269
PRC train: 0.663609	val: 0.457470	test: 0.454859

Epoch: 60
Loss: 0.08553552936899528
ROC train: 0.954711	val: 0.811489	test: 0.850292
PRC train: 0.672362	val: 0.452098	test: 0.459667

Epoch: 61
Loss: 0.08684875651471959
ROC train: 0.951350	val: 0.808765	test: 0.862576
PRC train: 0.664505	val: 0.456783	test: 0.479835

Epoch: 62
Loss: 0.0839706199960155
ROC train: 0.953326	val: 0.798329	test: 0.844071
PRC train: 0.664100	val: 0.423184	test: 0.431561

Epoch: 63
Loss: 0.08371892634878564
ROC train: 0.953965	val: 0.802415	test: 0.847792
PRC train: 0.652611	val: 0.416388	test: 0.434689

Epoch: 64
Loss: 0.0835513547582489
ROC train: 0.953612	val: 0.801021	test: 0.849240
PRC train: 0.658349	val: 0.452615	test: 0.465084

Epoch: 65
Loss: 0.08124815478975457
ROC train: 0.935307	val: 0.774541	test: 0.811382
PRC train: 0.552160	val: 0.330132	test: 0.401243

Epoch: 66
Loss: 0.08274337717907661
ROC train: 0.951657	val: 0.794441	test: 0.838369
PRC train: 0.661172	val: 0.414280	test: 0.441498

Epoch: 67
Loss: 0.08221054420699891
ROC train: 0.964432	val: 0.798588	test: 0.838129
PRC train: 0.687122	val: 0.439973	test: 0.460701

Epoch: 68
Loss: 0.08253788760523173
ROC train: 0.962288	val: 0.800548	test: 0.847704
PRC train: 0.683761	val: 0.454004	test: 0.470191

Epoch: 69
Loss: 0.08283807965032655
ROC train: 0.960527	val: 0.799835	test: 0.846615
PRC train: 0.683921	val: 0.442976	test: 0.438736

Epoch: 70
Loss: 0.08198839561015499
ROC train: 0.962193	val: 0.807640	test: 0.839311
PRC train: 0.693652	val: 0.450264	test: 0.440489

Epoch: 71
Loss: 0.08085424802282304
ROC train: 0.962488	val: 0.793722	test: 0.840339
PRC train: 0.698107	val: 0.445831	test: 0.457413

Epoch: 72
Loss: 0.07949574189616411
ROC train: 0.966113	val: 0.794312	test: 0.844311
PRC train: 0.706583	val: 0.443546	test: 0.447612

Epoch: 73
Loss: 0.07948396415530487
ROC train: 0.967322	val: 0.798189	test: 0.843532
PRC train: 0.704641	val: 0.447208	test: 0.475088

Epoch: 74
Loss: 0.07982124769696262
ROC train: 0.968432	val: 0.797241	test: 0.833373
PRC train: 0.718611	val: 0.445736	test: 0.437702

Epoch: 75
Loss: 0.07982930151105438
ROC train: 0.966296	val: 0.811122	test: 0.835503
PRC train: 0.712623	val: 0.455497	test: 0.439464

Epoch: 76
Loss: 0.07851806923336559
ROC train: 0.965772	val: 0.803128	test: 0.834230
PRC train: 0.697375	val: 0.440519	test: 0.442786

Epoch: 77
Loss: 0.07656583866052682
ROC train: 0.966788	val: 0.807775	test: 0.839223
PRC train: 0.714422	val: 0.429719	test: 0.432050

Epoch: 78
Loss: 0.0773720606828325
ROC train: 0.961365	val: 0.798876	test: 0.826456
PRC train: 0.694343	val: 0.440967	test: 0.417535

Epoch: 79
Loss: 0.07730664397366861
ROC train: 0.970281	val: 0.804147	test: 0.849835
PRC train: 0.726723	val: 0.445059	test: 0.454705

Epoch: 80
Loss: 0.07722691985724144
ROC train: 0.961911	val: 0.797173	test: 0.831873
PRC train: 0.676052	val: 0.426750	test: 0.409175

Epoch: 81
Loss: 0.07857006604408194
ROC train: 0.972944	val: 0.791116	test: 0.828591
PRC train: 0.736175	val: 0.440447	test: 0.434164

Epoch: 82
Loss: 0.07500744708687827
ROC train: 0.975579	val: 0.803225	test: 0.843676
PRC train: 0.746399	val: 0.451202	test: 0.441048

Epoch: 83
Loss: 0.07716320047382305
ROC train: 0.972712	val: 0.809035	test: 0.836682
PRC train: 0.736912	val: 0.427582	test: 0.431127

Epoch: 84
Loss: 0.07647850579296807
ROC train: 0.972529	val: 0.807304	test: 0.841839
PRC train: 0.739526	val: 0.437536	test: 0.435571

Epoch: 85
Loss: 0.07417557161223648
ROC train: 0.974857	val: 0.811328	test: 0.837661
PRC train: 0.752521	val: 0.442253	test: 0.446953

Epoch: 86
Loss: 0.076164584885386
ROC train: 0.976071	val: 0.803844	test: 0.848121
PRC train: 0.750429	val: 0.434592	test: 0.427488

Epoch: 87
Loss: 0.07507336786732781
ROC train: 0.970810	val: 0.804920	test: 0.834804
PRC train: 0.731933	val: 0.453920	test: 0.438615

Epoch: 88
Loss: 0.07489521834206031
ROC train: 0.972124	val: 0.807942	test: 0.842831
PRC train: 0.736634	val: 0.439616	test: 0.442393

Epoch: 89
Loss: 0.07250937947436052
ROC train: 0.974285	val: 0.793511	test: 0.842479
PRC train: 0.753610	val: 0.430130	test: 0.424162

Epoch: 90
Loss: 0.07420233511749252
ROC train: 0.969174	val: 0.798374	test: 0.838615
PRC train: 0.726713	val: 0.446347	test: 0.435392

Epoch: 91
Loss: 0.07445378086884714
ROC train: 0.977727	val: 0.790337	test: 0.830457
PRC train: 0.770623	val: 0.435176	test: 0.435023

Epoch: 92
Loss: 0.07450028840965263
ROC train: 0.975283	val: 0.791001	test: 0.839724
PRC train: 0.750798	val: 0.460083	test: 0.429348

Epoch: 93
Loss: 0.07210980206365458
ROC train: 0.969512	val: 0.795786	test: 0.839002
PRC train: 0.716403	val: 0.390445	test: 0.412615

Epoch: 94
Loss: 0.07249900581507342
ROC train: 0.912843	val: 0.827259	test: 0.839756
PRC train: 0.558988	val: 0.422371	test: 0.482821

Epoch: 34
Loss: 0.09716613590155744
ROC train: 0.915546	val: 0.817907	test: 0.848842
PRC train: 0.555534	val: 0.433735	test: 0.480261

Epoch: 35
Loss: 0.09839064310492336
ROC train: 0.919975	val: 0.835119	test: 0.851537
PRC train: 0.569843	val: 0.429912	test: 0.504118

Epoch: 36
Loss: 0.09682606452463352
ROC train: 0.926825	val: 0.842154	test: 0.861818
PRC train: 0.579875	val: 0.440757	test: 0.499932

Epoch: 37
Loss: 0.09536723729295676
ROC train: 0.920346	val: 0.836483	test: 0.861899
PRC train: 0.569678	val: 0.449205	test: 0.502814

Epoch: 38
Loss: 0.09413509351655198
ROC train: 0.923614	val: 0.811236	test: 0.849148
PRC train: 0.568424	val: 0.426117	test: 0.456749

Epoch: 39
Loss: 0.0967327780209015
ROC train: 0.923959	val: 0.814114	test: 0.848952
PRC train: 0.578552	val: 0.434070	test: 0.494930

Epoch: 40
Loss: 0.09591657469204165
ROC train: 0.927283	val: 0.825150	test: 0.851645
PRC train: 0.591091	val: 0.425373	test: 0.486361

Epoch: 41
Loss: 0.09448767561576954
ROC train: 0.928775	val: 0.818774	test: 0.853683
PRC train: 0.601144	val: 0.422230	test: 0.506124

Epoch: 42
Loss: 0.095043112556021
ROC train: 0.933955	val: 0.837149	test: 0.858536
PRC train: 0.612833	val: 0.443636	test: 0.492518

Epoch: 43
Loss: 0.09276076021648058
ROC train: 0.917365	val: 0.812968	test: 0.819274
PRC train: 0.568349	val: 0.402811	test: 0.428739

Epoch: 44
Loss: 0.09197405329812643
ROC train: 0.925277	val: 0.830656	test: 0.846140
PRC train: 0.594758	val: 0.425859	test: 0.454739

Epoch: 45
Loss: 0.09161910776694546
ROC train: 0.936889	val: 0.836197	test: 0.854697
PRC train: 0.615446	val: 0.443438	test: 0.499685

Epoch: 46
Loss: 0.09157830879187166
ROC train: 0.935478	val: 0.825754	test: 0.845633
PRC train: 0.592744	val: 0.426964	test: 0.476868

Epoch: 47
Loss: 0.09230316535455788
ROC train: 0.933052	val: 0.827372	test: 0.851531
PRC train: 0.599147	val: 0.437489	test: 0.491763

Epoch: 48
Loss: 0.09065114925948982
ROC train: 0.940754	val: 0.839029	test: 0.858983
PRC train: 0.624335	val: 0.432739	test: 0.475268

Epoch: 49
Loss: 0.09112365215901233
ROC train: 0.946729	val: 0.844314	test: 0.863471
PRC train: 0.639041	val: 0.451570	test: 0.506597

Epoch: 50
Loss: 0.08960773955905871
ROC train: 0.935527	val: 0.826500	test: 0.848556
PRC train: 0.601913	val: 0.436293	test: 0.450951

Epoch: 51
Loss: 0.09009550956358821
ROC train: 0.941533	val: 0.818895	test: 0.847709
PRC train: 0.625280	val: 0.424213	test: 0.500564

Epoch: 52
Loss: 0.0896775355729088
ROC train: 0.944646	val: 0.832377	test: 0.851709
PRC train: 0.632320	val: 0.431838	test: 0.503019

Epoch: 53
Loss: 0.0887690892401123
ROC train: 0.946368	val: 0.836585	test: 0.838621
PRC train: 0.640622	val: 0.438255	test: 0.468731

Epoch: 54
Loss: 0.08963932180619616
ROC train: 0.943016	val: 0.828501	test: 0.824201
PRC train: 0.625545	val: 0.425637	test: 0.475839

Epoch: 55
Loss: 0.08886824786530445
ROC train: 0.947459	val: 0.819461	test: 0.848525
PRC train: 0.632619	val: 0.439317	test: 0.484926

Epoch: 56
Loss: 0.08811600903369939
ROC train: 0.946999	val: 0.831419	test: 0.850650
PRC train: 0.639033	val: 0.433197	test: 0.470197

Epoch: 57
Loss: 0.08923524956495975
ROC train: 0.954375	val: 0.822835	test: 0.863086
PRC train: 0.663983	val: 0.433575	test: 0.484811

Epoch: 58
Loss: 0.0860702303964908
ROC train: 0.952979	val: 0.831639	test: 0.867938
PRC train: 0.664301	val: 0.428783	test: 0.497974

Epoch: 59
Loss: 0.08607857431188888
ROC train: 0.957021	val: 0.832661	test: 0.860658
PRC train: 0.666740	val: 0.428335	test: 0.482145

Epoch: 60
Loss: 0.08609569224807964
ROC train: 0.948573	val: 0.815320	test: 0.843882
PRC train: 0.639259	val: 0.397173	test: 0.461649

Epoch: 61
Loss: 0.08435967194888527
ROC train: 0.952405	val: 0.819114	test: 0.847389
PRC train: 0.649957	val: 0.425331	test: 0.467960

Epoch: 62
Loss: 0.0833389766254607
ROC train: 0.949411	val: 0.825425	test: 0.859336
PRC train: 0.661976	val: 0.409046	test: 0.443337

Epoch: 63
Loss: 0.08469432240257987
ROC train: 0.954026	val: 0.832633	test: 0.851748
PRC train: 0.666771	val: 0.429173	test: 0.483286

Epoch: 64
Loss: 0.08547239464395459
ROC train: 0.955272	val: 0.827492	test: 0.854724
PRC train: 0.665092	val: 0.427482	test: 0.466892

Epoch: 65
Loss: 0.08397556467152982
ROC train: 0.959201	val: 0.836137	test: 0.848187
PRC train: 0.683499	val: 0.448075	test: 0.476182

Epoch: 66
Loss: 0.08242690655838872
ROC train: 0.951267	val: 0.812186	test: 0.840125
PRC train: 0.659056	val: 0.411146	test: 0.474241

Epoch: 67
Loss: 0.083243933699255
ROC train: 0.960166	val: 0.845111	test: 0.841499
PRC train: 0.690955	val: 0.448170	test: 0.480045

Epoch: 68
Loss: 0.08248728156282753
ROC train: 0.957368	val: 0.813552	test: 0.829104
PRC train: 0.672593	val: 0.394532	test: 0.443761

Epoch: 69
Loss: 0.0827446222775613
ROC train: 0.962344	val: 0.832744	test: 0.846139
PRC train: 0.688115	val: 0.439842	test: 0.479401

Epoch: 70
Loss: 0.08223727867985005
ROC train: 0.965754	val: 0.834654	test: 0.838542
PRC train: 0.697963	val: 0.422123	test: 0.470300

Epoch: 71
Loss: 0.08126171735616605
ROC train: 0.961859	val: 0.831098	test: 0.852185
PRC train: 0.692338	val: 0.419654	test: 0.467091

Epoch: 72
Loss: 0.07961272016278412
ROC train: 0.963850	val: 0.831639	test: 0.852557
PRC train: 0.698827	val: 0.430168	test: 0.476042

Epoch: 73
Loss: 0.08012056882925522
ROC train: 0.966390	val: 0.837313	test: 0.856796
PRC train: 0.717793	val: 0.428700	test: 0.492518

Epoch: 74
Loss: 0.0783871701678946
ROC train: 0.964080	val: 0.811650	test: 0.848476
PRC train: 0.704715	val: 0.388416	test: 0.448572

Epoch: 75
Loss: 0.07943768005725617
ROC train: 0.966513	val: 0.826503	test: 0.850042
PRC train: 0.701259	val: 0.405185	test: 0.469974

Epoch: 76
Loss: 0.07904335753820341
ROC train: 0.966801	val: 0.822208	test: 0.853273
PRC train: 0.714806	val: 0.425954	test: 0.458580

Epoch: 77
Loss: 0.0788673138387663
ROC train: 0.971771	val: 0.826172	test: 0.855179
PRC train: 0.728308	val: 0.434212	test: 0.468415

Epoch: 78
Loss: 0.07862830276095871
ROC train: 0.969018	val: 0.835993	test: 0.838693
PRC train: 0.720535	val: 0.442028	test: 0.462535

Epoch: 79
Loss: 0.07822061550785996
ROC train: 0.966988	val: 0.815648	test: 0.858541
PRC train: 0.721542	val: 0.421582	test: 0.446102

Epoch: 80
Loss: 0.07848127429334593
ROC train: 0.967494	val: 0.812974	test: 0.859930
PRC train: 0.719016	val: 0.423204	test: 0.464614

Epoch: 81
Loss: 0.07594965807133502
ROC train: 0.974931	val: 0.824202	test: 0.865000
PRC train: 0.750521	val: 0.423795	test: 0.489212

Epoch: 82
Loss: 0.07683467496879877
ROC train: 0.971482	val: 0.822296	test: 0.849284
PRC train: 0.736563	val: 0.427197	test: 0.488563

Epoch: 83
Loss: 0.07841155346404348
ROC train: 0.965717	val: 0.826746	test: 0.851933
PRC train: 0.706793	val: 0.427107	test: 0.477499

Epoch: 84
Loss: 0.0774295745483441
ROC train: 0.974895	val: 0.838668	test: 0.854524
PRC train: 0.751055	val: 0.435957	test: 0.460439

Epoch: 85
Loss: 0.07559045378471652
ROC train: 0.972772	val: 0.806865	test: 0.840989
PRC train: 0.749903	val: 0.404420	test: 0.457723

Epoch: 86
Loss: 0.07415256760461962
ROC train: 0.973634	val: 0.824044	test: 0.851416
PRC train: 0.750686	val: 0.405125	test: 0.452290

Epoch: 87
Loss: 0.07407434994209841
ROC train: 0.975120	val: 0.825848	test: 0.845939
PRC train: 0.751934	val: 0.395659	test: 0.458241

Epoch: 88
Loss: 0.0745669957583486
ROC train: 0.971350	val: 0.832089	test: 0.852444
PRC train: 0.742607	val: 0.431663	test: 0.471450

Epoch: 89
Loss: 0.07387649103385553
ROC train: 0.973324	val: 0.837522	test: 0.847466
PRC train: 0.752171	val: 0.442318	test: 0.478137

Epoch: 90
Loss: 0.07460514387510186
ROC train: 0.976715	val: 0.827756	test: 0.854580
PRC train: 0.773247	val: 0.401849	test: 0.463275

Epoch: 91
Loss: 0.07398507487912795
ROC train: 0.975995	val: 0.838990	test: 0.854028
PRC train: 0.760061	val: 0.433484	test: 0.467188

Epoch: 92
Loss: 0.07372391289688665
ROC train: 0.978227	val: 0.823506	test: 0.847687
PRC train: 0.770667	val: 0.425304	test: 0.470170

Epoch: 93
Loss: 0.07333775575041318
ROC train: 0.979104	val: 0.825737	test: 0.849893
PRC train: 0.779559	val: 0.423022	test: 0.461759

Epoch: 94
Loss: 0.07152781200815754
ROC train: 0.907333	val: 0.825659	test: 0.860973
PRC train: 0.549247	val: 0.420005	test: 0.493881

Epoch: 34
Loss: 0.09878746248495868
ROC train: 0.912484	val: 0.831119	test: 0.833527
PRC train: 0.563047	val: 0.418816	test: 0.454029

Epoch: 35
Loss: 0.0981474066458545
ROC train: 0.915810	val: 0.826262	test: 0.844495
PRC train: 0.562408	val: 0.446683	test: 0.484735

Epoch: 36
Loss: 0.09515393130612627
ROC train: 0.914338	val: 0.818272	test: 0.855106
PRC train: 0.556075	val: 0.414269	test: 0.489186

Epoch: 37
Loss: 0.0966316766788098
ROC train: 0.927387	val: 0.827434	test: 0.861066
PRC train: 0.580492	val: 0.443991	test: 0.497904

Epoch: 38
Loss: 0.09638810491672013
ROC train: 0.920776	val: 0.829666	test: 0.840890
PRC train: 0.571611	val: 0.432490	test: 0.452360

Epoch: 39
Loss: 0.09553654642317802
ROC train: 0.929279	val: 0.825282	test: 0.861613
PRC train: 0.590124	val: 0.418618	test: 0.478592

Epoch: 40
Loss: 0.09462591403334258
ROC train: 0.925989	val: 0.824278	test: 0.856422
PRC train: 0.589416	val: 0.401561	test: 0.481097

Epoch: 41
Loss: 0.0933500325083464
ROC train: 0.929659	val: 0.823159	test: 0.852269
PRC train: 0.602553	val: 0.452944	test: 0.503537

Epoch: 42
Loss: 0.09433766015035869
ROC train: 0.930780	val: 0.838602	test: 0.841524
PRC train: 0.596144	val: 0.453491	test: 0.466948

Epoch: 43
Loss: 0.09407570618240424
ROC train: 0.935497	val: 0.836268	test: 0.842772
PRC train: 0.608355	val: 0.423216	test: 0.470018

Epoch: 44
Loss: 0.09373912152479054
ROC train: 0.932812	val: 0.828579	test: 0.854500
PRC train: 0.602397	val: 0.425712	test: 0.485479

Epoch: 45
Loss: 0.09312169157243362
ROC train: 0.930694	val: 0.826054	test: 0.843308
PRC train: 0.593157	val: 0.431697	test: 0.455301

Epoch: 46
Loss: 0.09263736030694619
ROC train: 0.931234	val: 0.820312	test: 0.819965
PRC train: 0.574514	val: 0.396492	test: 0.458888

Epoch: 47
Loss: 0.0914023783390571
ROC train: 0.937380	val: 0.835003	test: 0.861203
PRC train: 0.603876	val: 0.429340	test: 0.480259

Epoch: 48
Loss: 0.0912925269447537
ROC train: 0.942240	val: 0.836950	test: 0.859402
PRC train: 0.627652	val: 0.437153	test: 0.484967

Epoch: 49
Loss: 0.09215744787150178
ROC train: 0.932754	val: 0.847153	test: 0.844671
PRC train: 0.585938	val: 0.453878	test: 0.484722

Epoch: 50
Loss: 0.09092454099708427
ROC train: 0.939259	val: 0.830779	test: 0.845130
PRC train: 0.607789	val: 0.437339	test: 0.498029

Epoch: 51
Loss: 0.09028404903070662
ROC train: 0.943381	val: 0.809371	test: 0.852977
PRC train: 0.643885	val: 0.420466	test: 0.476825

Epoch: 52
Loss: 0.08927883925120442
ROC train: 0.943375	val: 0.827106	test: 0.850841
PRC train: 0.647664	val: 0.418559	test: 0.469647

Epoch: 53
Loss: 0.08794676350326087
ROC train: 0.948623	val: 0.837991	test: 0.853700
PRC train: 0.650733	val: 0.427955	test: 0.495748

Epoch: 54
Loss: 0.08931020632182296
ROC train: 0.943184	val: 0.828103	test: 0.853475
PRC train: 0.631164	val: 0.409993	test: 0.456346

Epoch: 55
Loss: 0.08842101670009768
ROC train: 0.945543	val: 0.851397	test: 0.867128
PRC train: 0.638639	val: 0.415766	test: 0.476304

Epoch: 56
Loss: 0.08737837736004263
ROC train: 0.947863	val: 0.829608	test: 0.855123
PRC train: 0.637156	val: 0.411076	test: 0.472947

Epoch: 57
Loss: 0.08738109796691063
ROC train: 0.947909	val: 0.831051	test: 0.850509
PRC train: 0.643189	val: 0.435095	test: 0.480436

Epoch: 58
Loss: 0.08628519762694596
ROC train: 0.953369	val: 0.828611	test: 0.845726
PRC train: 0.670156	val: 0.430176	test: 0.483412

Epoch: 59
Loss: 0.08916188095399452
ROC train: 0.949774	val: 0.806597	test: 0.843226
PRC train: 0.666149	val: 0.394880	test: 0.454456

Epoch: 60
Loss: 0.08636957712916779
ROC train: 0.955552	val: 0.822083	test: 0.858781
PRC train: 0.671148	val: 0.426172	test: 0.477590

Epoch: 61
Loss: 0.08522666229535786
ROC train: 0.950754	val: 0.820930	test: 0.829303
PRC train: 0.645284	val: 0.423328	test: 0.489601

Epoch: 62
Loss: 0.08543624237922604
ROC train: 0.956785	val: 0.836400	test: 0.862564
PRC train: 0.670781	val: 0.410332	test: 0.469953

Epoch: 63
Loss: 0.08384924436390478
ROC train: 0.959188	val: 0.831652	test: 0.856110
PRC train: 0.697579	val: 0.411581	test: 0.478652

Epoch: 64
Loss: 0.08298876798305226
ROC train: 0.956770	val: 0.824008	test: 0.852236
PRC train: 0.669577	val: 0.438316	test: 0.495254

Epoch: 65
Loss: 0.0857137025624702
ROC train: 0.957792	val: 0.833653	test: 0.845433
PRC train: 0.681678	val: 0.415629	test: 0.467011

Epoch: 66
Loss: 0.08533971047234401
ROC train: 0.960849	val: 0.839189	test: 0.850306
PRC train: 0.695325	val: 0.435992	test: 0.471733

Epoch: 67
Loss: 0.08207918046366598
ROC train: 0.952217	val: 0.831715	test: 0.831798
PRC train: 0.651331	val: 0.406116	test: 0.434537

Epoch: 68
Loss: 0.08065144367728036
ROC train: 0.959509	val: 0.823126	test: 0.851509
PRC train: 0.694477	val: 0.423467	test: 0.472000

Epoch: 69
Loss: 0.08170283707494887
ROC train: 0.949494	val: 0.819912	test: 0.849145
PRC train: 0.650483	val: 0.394257	test: 0.429349

Epoch: 70
Loss: 0.08164905995309181
ROC train: 0.963434	val: 0.839358	test: 0.844725
PRC train: 0.701084	val: 0.432604	test: 0.452090

Epoch: 71
Loss: 0.08190050433203232
ROC train: 0.964996	val: 0.829904	test: 0.843664
PRC train: 0.703049	val: 0.419002	test: 0.457751

Epoch: 72
Loss: 0.0802302169795046
ROC train: 0.959662	val: 0.840629	test: 0.847257
PRC train: 0.699128	val: 0.423765	test: 0.451437

Epoch: 73
Loss: 0.08260879724782191
ROC train: 0.970009	val: 0.831861	test: 0.854130
PRC train: 0.731597	val: 0.429612	test: 0.484266

Epoch: 74
Loss: 0.07824319880968687
ROC train: 0.966410	val: 0.827641	test: 0.856181
PRC train: 0.717548	val: 0.402030	test: 0.469534

Epoch: 75
Loss: 0.08058976513869058
ROC train: 0.967525	val: 0.809402	test: 0.854394
PRC train: 0.727894	val: 0.383546	test: 0.440520

Epoch: 76
Loss: 0.07889924691792774
ROC train: 0.968998	val: 0.827920	test: 0.856912
PRC train: 0.736561	val: 0.416898	test: 0.457379

Epoch: 77
Loss: 0.07800793180835738
ROC train: 0.967549	val: 0.833976	test: 0.853211
PRC train: 0.727091	val: 0.432035	test: 0.453729

Epoch: 78
Loss: 0.07759209387883086
ROC train: 0.966258	val: 0.823672	test: 0.849622
PRC train: 0.721923	val: 0.409296	test: 0.474978

Epoch: 79
Loss: 0.0773706652802309
ROC train: 0.969252	val: 0.838366	test: 0.856002
PRC train: 0.716811	val: 0.416519	test: 0.467724

Epoch: 80
Loss: 0.07912548116703855
ROC train: 0.969689	val: 0.822069	test: 0.851682
PRC train: 0.728969	val: 0.402507	test: 0.460934

Epoch: 81
Loss: 0.07783315927950114
ROC train: 0.970435	val: 0.826419	test: 0.853227
PRC train: 0.741815	val: 0.431664	test: 0.467055

Epoch: 82
Loss: 0.07642394717859845
ROC train: 0.970890	val: 0.820952	test: 0.856039
PRC train: 0.742105	val: 0.408958	test: 0.454298

Epoch: 83
Loss: 0.07562606236117021
ROC train: 0.970948	val: 0.825256	test: 0.853778
PRC train: 0.750081	val: 0.404560	test: 0.437605

Epoch: 84
Loss: 0.0774965086942253
ROC train: 0.966277	val: 0.816522	test: 0.833818
PRC train: 0.717921	val: 0.370326	test: 0.412348

Epoch: 85
Loss: 0.0752893430802523
ROC train: 0.973021	val: 0.821413	test: 0.846244
PRC train: 0.750903	val: 0.413087	test: 0.475052

Epoch: 86
Loss: 0.07617667604152609
ROC train: 0.971334	val: 0.832059	test: 0.841001
PRC train: 0.739861	val: 0.407520	test: 0.426322

Epoch: 87
Loss: 0.07393761823826508
ROC train: 0.974970	val: 0.826940	test: 0.861582
PRC train: 0.762909	val: 0.404482	test: 0.471434

Epoch: 88
Loss: 0.07502863836396745
ROC train: 0.975686	val: 0.825612	test: 0.847107
PRC train: 0.765842	val: 0.432817	test: 0.477006

Epoch: 89
Loss: 0.0731464363824535
ROC train: 0.970865	val: 0.825851	test: 0.848673
PRC train: 0.729793	val: 0.425166	test: 0.460491

Epoch: 90
Loss: 0.07387420841096434
ROC train: 0.976530	val: 0.823136	test: 0.864558
PRC train: 0.770256	val: 0.425889	test: 0.495608

Epoch: 91
Loss: 0.07329873186715673
ROC train: 0.974264	val: 0.820377	test: 0.837679
PRC train: 0.753928	val: 0.415378	test: 0.464979

Epoch: 92
Loss: 0.07284268090228586
ROC train: 0.971847	val: 0.815979	test: 0.845741
PRC train: 0.734442	val: 0.394270	test: 0.452851

Epoch: 93
Loss: 0.07405837075316661
ROC train: 0.970428	val: 0.806654	test: 0.860455
PRC train: 0.732563	val: 0.394976	test: 0.440876

Epoch: 94
Loss: 0.07456184025394552
ROC train: 0.913547	val: 0.805145	test: 0.856246
PRC train: 0.563340	val: 0.404411	test: 0.464196

Epoch: 34
Loss: 0.09828541449535072
ROC train: 0.912177	val: 0.799937	test: 0.853221
PRC train: 0.545295	val: 0.421506	test: 0.466830

Epoch: 35
Loss: 0.09787152309418573
ROC train: 0.914552	val: 0.815037	test: 0.851501
PRC train: 0.567274	val: 0.418007	test: 0.458792

Epoch: 36
Loss: 0.09713640914938469
ROC train: 0.914648	val: 0.812283	test: 0.862864
PRC train: 0.556496	val: 0.427533	test: 0.465143

Epoch: 37
Loss: 0.09612306659489743
ROC train: 0.919268	val: 0.813479	test: 0.852743
PRC train: 0.567029	val: 0.430747	test: 0.479011

Epoch: 38
Loss: 0.09623783755936069
ROC train: 0.911525	val: 0.799305	test: 0.847511
PRC train: 0.536597	val: 0.415397	test: 0.445080

Epoch: 39
Loss: 0.09649144198695049
ROC train: 0.923918	val: 0.820656	test: 0.850392
PRC train: 0.576677	val: 0.440116	test: 0.488441

Epoch: 40
Loss: 0.09583680884278846
ROC train: 0.930116	val: 0.823601	test: 0.844443
PRC train: 0.600449	val: 0.434369	test: 0.478951

Epoch: 41
Loss: 0.09239682470818952
ROC train: 0.923786	val: 0.808076	test: 0.837340
PRC train: 0.558627	val: 0.381889	test: 0.434359

Epoch: 42
Loss: 0.09439424477029719
ROC train: 0.927423	val: 0.827636	test: 0.843141
PRC train: 0.598964	val: 0.443650	test: 0.469876

Epoch: 43
Loss: 0.09372790732311874
ROC train: 0.929417	val: 0.808687	test: 0.861220
PRC train: 0.602372	val: 0.424898	test: 0.489430

Epoch: 44
Loss: 0.09439177697265694
ROC train: 0.934649	val: 0.814395	test: 0.860120
PRC train: 0.607648	val: 0.444273	test: 0.494646

Epoch: 45
Loss: 0.091151015947427
ROC train: 0.925202	val: 0.806670	test: 0.856499
PRC train: 0.596733	val: 0.437291	test: 0.463322

Epoch: 46
Loss: 0.09284337897081132
ROC train: 0.930754	val: 0.812089	test: 0.858720
PRC train: 0.594457	val: 0.391064	test: 0.444214

Epoch: 47
Loss: 0.09168190467077143
ROC train: 0.932007	val: 0.815030	test: 0.852151
PRC train: 0.606528	val: 0.404978	test: 0.465426

Epoch: 48
Loss: 0.0908563119657161
ROC train: 0.935828	val: 0.801845	test: 0.882565
PRC train: 0.613530	val: 0.427469	test: 0.491215

Epoch: 49
Loss: 0.09055645882813562
ROC train: 0.929537	val: 0.809163	test: 0.853502
PRC train: 0.597222	val: 0.429096	test: 0.484443

Epoch: 50
Loss: 0.0924563973113479
ROC train: 0.934901	val: 0.803512	test: 0.848813
PRC train: 0.607403	val: 0.410684	test: 0.452566

Epoch: 51
Loss: 0.09053240071222145
ROC train: 0.926979	val: 0.799983	test: 0.839647
PRC train: 0.575634	val: 0.404578	test: 0.422140

Epoch: 52
Loss: 0.0906406624562199
ROC train: 0.942766	val: 0.827226	test: 0.856020
PRC train: 0.628592	val: 0.419161	test: 0.456786

Epoch: 53
Loss: 0.09045929310285274
ROC train: 0.948905	val: 0.820194	test: 0.851784
PRC train: 0.648921	val: 0.422691	test: 0.486350

Epoch: 54
Loss: 0.0885937113961769
ROC train: 0.940350	val: 0.821212	test: 0.838559
PRC train: 0.639573	val: 0.417468	test: 0.456181

Epoch: 55
Loss: 0.08834852815602597
ROC train: 0.948111	val: 0.819519	test: 0.848363
PRC train: 0.656274	val: 0.426977	test: 0.450413

Epoch: 56
Loss: 0.08749170770023937
ROC train: 0.944393	val: 0.823871	test: 0.851812
PRC train: 0.628562	val: 0.424203	test: 0.469452

Epoch: 57
Loss: 0.08796312519786266
ROC train: 0.949684	val: 0.815069	test: 0.863382
PRC train: 0.646532	val: 0.418455	test: 0.503090

Epoch: 58
Loss: 0.08740144473398478
ROC train: 0.948713	val: 0.819043	test: 0.860741
PRC train: 0.650408	val: 0.422027	test: 0.480064

Epoch: 59
Loss: 0.08557272818322861
ROC train: 0.948550	val: 0.811693	test: 0.850362
PRC train: 0.652289	val: 0.396969	test: 0.449468

Epoch: 60
Loss: 0.08592525594791636
ROC train: 0.947495	val: 0.796516	test: 0.844402
PRC train: 0.643320	val: 0.428899	test: 0.461143

Epoch: 61
Loss: 0.0870890544122728
ROC train: 0.955543	val: 0.806816	test: 0.850929
PRC train: 0.674488	val: 0.410067	test: 0.483063

Epoch: 62
Loss: 0.08571225444913597
ROC train: 0.948540	val: 0.808033	test: 0.858133
PRC train: 0.650900	val: 0.412698	test: 0.460719

Epoch: 63
Loss: 0.08577639412906879
ROC train: 0.958451	val: 0.810518	test: 0.853271
PRC train: 0.689475	val: 0.404106	test: 0.458801

Epoch: 64
Loss: 0.08463796235780248
ROC train: 0.956556	val: 0.801833	test: 0.849466
PRC train: 0.674578	val: 0.415069	test: 0.451044

Epoch: 65
Loss: 0.0846892591308254
ROC train: 0.956998	val: 0.810451	test: 0.856621
PRC train: 0.677847	val: 0.413426	test: 0.454571

Epoch: 66
Loss: 0.08317107815042236
ROC train: 0.953914	val: 0.809867	test: 0.858527
PRC train: 0.656349	val: 0.413414	test: 0.482355

Epoch: 67
Loss: 0.08391754385005815
ROC train: 0.955291	val: 0.815853	test: 0.848148
PRC train: 0.680956	val: 0.420740	test: 0.448246

Epoch: 68
Loss: 0.08244400725186103
ROC train: 0.957765	val: 0.799113	test: 0.861075
PRC train: 0.688647	val: 0.408828	test: 0.461904

Epoch: 69
Loss: 0.08249448750447451
ROC train: 0.955624	val: 0.801738	test: 0.845409
PRC train: 0.675933	val: 0.403654	test: 0.437306

Epoch: 70
Loss: 0.08227971601840872
ROC train: 0.954153	val: 0.803288	test: 0.846853
PRC train: 0.663980	val: 0.393709	test: 0.449482

Epoch: 71
Loss: 0.08097469842591558
ROC train: 0.961630	val: 0.802684	test: 0.862475
PRC train: 0.687666	val: 0.421115	test: 0.468086

Epoch: 72
Loss: 0.08148472123142705
ROC train: 0.950484	val: 0.806178	test: 0.846540
PRC train: 0.658205	val: 0.399814	test: 0.442039

Epoch: 73
Loss: 0.08196673270730247
ROC train: 0.959142	val: 0.808865	test: 0.856645
PRC train: 0.688804	val: 0.402544	test: 0.439194

Epoch: 74
Loss: 0.08068787953243625
ROC train: 0.966473	val: 0.815458	test: 0.847257
PRC train: 0.714592	val: 0.434542	test: 0.459908

Epoch: 75
Loss: 0.08000640793699251
ROC train: 0.967462	val: 0.812320	test: 0.851530
PRC train: 0.718378	val: 0.408813	test: 0.464972

Epoch: 76
Loss: 0.08104784604692346
ROC train: 0.966798	val: 0.814112	test: 0.851008
PRC train: 0.725401	val: 0.430229	test: 0.470444

Epoch: 77
Loss: 0.07917187699882823
ROC train: 0.968914	val: 0.809496	test: 0.846588
PRC train: 0.728941	val: 0.417365	test: 0.445205

Epoch: 78
Loss: 0.07736100598515701
ROC train: 0.962745	val: 0.811192	test: 0.855108
PRC train: 0.698630	val: 0.396317	test: 0.435385

Epoch: 79
Loss: 0.07689083043377025
ROC train: 0.968558	val: 0.808370	test: 0.849614
PRC train: 0.721512	val: 0.408981	test: 0.452677

Epoch: 80
Loss: 0.07686675595080432
ROC train: 0.972305	val: 0.807836	test: 0.836545
PRC train: 0.745709	val: 0.397986	test: 0.438991

Epoch: 81
Loss: 0.07902094340396955
ROC train: 0.968339	val: 0.817942	test: 0.844571
PRC train: 0.727076	val: 0.422819	test: 0.447038

Epoch: 82
Loss: 0.07664908936433251
ROC train: 0.966726	val: 0.800901	test: 0.848082
PRC train: 0.706348	val: 0.406281	test: 0.436015

Epoch: 83
Loss: 0.07816235029804613
ROC train: 0.972418	val: 0.798352	test: 0.856454
PRC train: 0.749558	val: 0.411328	test: 0.459967

Epoch: 84
Loss: 0.0760442670702659
ROC train: 0.969953	val: 0.803919	test: 0.843551
PRC train: 0.731940	val: 0.407189	test: 0.449476

Epoch: 85
Loss: 0.07579801663428475
ROC train: 0.974400	val: 0.808694	test: 0.843652
PRC train: 0.744217	val: 0.415991	test: 0.460905

Epoch: 86
Loss: 0.07577464929522774
ROC train: 0.974144	val: 0.809693	test: 0.841626
PRC train: 0.746811	val: 0.405587	test: 0.449531

Epoch: 87
Loss: 0.07657937770774179
ROC train: 0.977259	val: 0.810755	test: 0.857911
PRC train: 0.771037	val: 0.405967	test: 0.473286

Epoch: 88
Loss: 0.07412568833382688
ROC train: 0.975137	val: 0.805487	test: 0.853911
PRC train: 0.757514	val: 0.411808	test: 0.460347

Epoch: 89
Loss: 0.0738203949072953
ROC train: 0.975390	val: 0.802649	test: 0.848287
PRC train: 0.755764	val: 0.410023	test: 0.465831

Epoch: 90
Loss: 0.07445191759021311
ROC train: 0.973982	val: 0.813763	test: 0.845382
PRC train: 0.756831	val: 0.425226	test: 0.444175

Epoch: 91
Loss: 0.07379933853424159
ROC train: 0.976395	val: 0.814693	test: 0.841120
PRC train: 0.761638	val: 0.413167	test: 0.472569

Epoch: 92
Loss: 0.07440728877866316
ROC train: 0.977643	val: 0.807320	test: 0.848441
PRC train: 0.766465	val: 0.412597	test: 0.483642

Epoch: 93
Loss: 0.07419028448524653
ROC train: 0.975412	val: 0.814373	test: 0.840751
PRC train: 0.758940	val: 0.411726	test: 0.479551

Epoch: 94
Loss: 0.07240280329495254
ROC train: 0.978470	val: 0.798488	test: 0.829775
PRC train: 0.770180	val: 0.407099	test: 0.440254

Epoch: 95
Loss: 0.07274203996730011
ROC train: 0.977657	val: 0.793816	test: 0.816028
PRC train: 0.755810	val: 0.399934	test: 0.434156

Epoch: 96
Loss: 0.07167260041682547
ROC train: 0.981093	val: 0.793126	test: 0.814929
PRC train: 0.788299	val: 0.405787	test: 0.435005

Epoch: 97
Loss: 0.07174368210803277
ROC train: 0.977762	val: 0.788526	test: 0.811760
PRC train: 0.769385	val: 0.400480	test: 0.430463

Epoch: 98
Loss: 0.07445214911010159
ROC train: 0.978251	val: 0.797900	test: 0.821377
PRC train: 0.757812	val: 0.375345	test: 0.435030

Epoch: 99
Loss: 0.07152448692078489
ROC train: 0.979420	val: 0.799464	test: 0.812457
PRC train: 0.776605	val: 0.414725	test: 0.419231

Epoch: 100
Loss: 0.07178441782585535
ROC train: 0.982275	val: 0.801645	test: 0.821927
PRC train: 0.789933	val: 0.393612	test: 0.441930

Epoch: 101
Loss: 0.07177258438802742
ROC train: 0.979840	val: 0.796508	test: 0.821226
PRC train: 0.771093	val: 0.402893	test: 0.429301

Epoch: 102
Loss: 0.07208214351835963
ROC train: 0.979811	val: 0.804926	test: 0.817048
PRC train: 0.772833	val: 0.399496	test: 0.411399

Epoch: 103
Loss: 0.07070282493112573
ROC train: 0.981239	val: 0.800521	test: 0.819969
PRC train: 0.786129	val: 0.399207	test: 0.421348

Epoch: 104
Loss: 0.07015504664496859
ROC train: 0.982791	val: 0.792654	test: 0.820470
PRC train: 0.787824	val: 0.395209	test: 0.435259

Epoch: 105
Loss: 0.0681542038705236
ROC train: 0.981007	val: 0.799707	test: 0.813199
PRC train: 0.788789	val: 0.385789	test: 0.406017

Epoch: 106
Loss: 0.06893331317417625
ROC train: 0.983412	val: 0.796848	test: 0.820035
PRC train: 0.795425	val: 0.398527	test: 0.437703

Epoch: 107
Loss: 0.06762875392744129
ROC train: 0.983190	val: 0.796386	test: 0.813956
PRC train: 0.798013	val: 0.398962	test: 0.416327

Epoch: 108
Loss: 0.06777067805565995
ROC train: 0.986166	val: 0.790879	test: 0.814085
PRC train: 0.816896	val: 0.400920	test: 0.409884

Epoch: 109
Loss: 0.06673946390400914
ROC train: 0.985625	val: 0.796944	test: 0.825051
PRC train: 0.809125	val: 0.390666	test: 0.427149

Epoch: 110
Loss: 0.06912921412741804
ROC train: 0.982913	val: 0.799223	test: 0.816629
PRC train: 0.793410	val: 0.377460	test: 0.415474

Epoch: 111
Loss: 0.06701508764375091
ROC train: 0.981983	val: 0.792596	test: 0.817064
PRC train: 0.793871	val: 0.394371	test: 0.425081

Epoch: 112
Loss: 0.06758440763732294
ROC train: 0.985918	val: 0.799549	test: 0.822390
PRC train: 0.821323	val: 0.412699	test: 0.434888

Epoch: 113
Loss: 0.06684047487287541
ROC train: 0.986606	val: 0.784983	test: 0.815298
PRC train: 0.820315	val: 0.401811	test: 0.428365

Epoch: 114
Loss: 0.06543353912800313
ROC train: 0.984546	val: 0.798229	test: 0.817594
PRC train: 0.810182	val: 0.398806	test: 0.419603

Epoch: 115
Loss: 0.06503335468229103
ROC train: 0.984844	val: 0.792446	test: 0.807705
PRC train: 0.814659	val: 0.389553	test: 0.417724

Epoch: 116
Loss: 0.0653010770905087
ROC train: 0.986074	val: 0.791429	test: 0.809585
PRC train: 0.818526	val: 0.384532	test: 0.393596

Epoch: 117
Loss: 0.06502723410824998
ROC train: 0.986392	val: 0.797175	test: 0.815551
PRC train: 0.815388	val: 0.375487	test: 0.418904

Epoch: 118
Loss: 0.06691715782646326
ROC train: 0.985313	val: 0.797490	test: 0.821110
PRC train: 0.818432	val: 0.373004	test: 0.405888

Epoch: 119
Loss: 0.06469287118213174
ROC train: 0.984082	val: 0.799552	test: 0.819437
PRC train: 0.810546	val: 0.394751	test: 0.426255

Epoch: 120
Loss: 0.06342457607802676
ROC train: 0.985141	val: 0.798509	test: 0.817262
PRC train: 0.820265	val: 0.394176	test: 0.413096

Early stopping
Best (ROC):	 train: 0.969615	val: 0.807262	test: 0.818084
Best (PRC):	 train: 0.725148	val: 0.400752	test: 0.439372

ROC train: 0.980761	val: 0.786476	test: 0.822730
PRC train: 0.784236	val: 0.393908	test: 0.431841

Epoch: 95
Loss: 0.0732483238336677
ROC train: 0.979947	val: 0.787521	test: 0.823862
PRC train: 0.772162	val: 0.392129	test: 0.453102

Epoch: 96
Loss: 0.07143837959954683
ROC train: 0.975707	val: 0.783899	test: 0.814631
PRC train: 0.743055	val: 0.400981	test: 0.413371

Epoch: 97
Loss: 0.0719161802233899
ROC train: 0.981644	val: 0.781055	test: 0.814497
PRC train: 0.790108	val: 0.415839	test: 0.422103

Epoch: 98
Loss: 0.07182681760842408
ROC train: 0.980824	val: 0.790498	test: 0.828887
PRC train: 0.783024	val: 0.398284	test: 0.444297

Epoch: 99
Loss: 0.06934520823218142
ROC train: 0.980318	val: 0.778460	test: 0.817494
PRC train: 0.781510	val: 0.379458	test: 0.431948

Epoch: 100
Loss: 0.07005270503189248
ROC train: 0.982996	val: 0.784671	test: 0.827618
PRC train: 0.802011	val: 0.398034	test: 0.431531

Epoch: 101
Loss: 0.0680440937247732
ROC train: 0.984464	val: 0.779317	test: 0.820800
PRC train: 0.805850	val: 0.397713	test: 0.448281

Epoch: 102
Loss: 0.06896261773046976
ROC train: 0.983397	val: 0.782700	test: 0.806207
PRC train: 0.793138	val: 0.398550	test: 0.416450

Epoch: 103
Loss: 0.06978160419325992
ROC train: 0.982791	val: 0.779231	test: 0.826789
PRC train: 0.791806	val: 0.391303	test: 0.416108

Epoch: 104
Loss: 0.06974796034386867
ROC train: 0.983424	val: 0.790762	test: 0.826949
PRC train: 0.810211	val: 0.411647	test: 0.432733

Epoch: 105
Loss: 0.06762987062464154
ROC train: 0.985727	val: 0.776887	test: 0.813891
PRC train: 0.817388	val: 0.393929	test: 0.433204

Epoch: 106
Loss: 0.06758351231124723
ROC train: 0.983043	val: 0.791169	test: 0.829569
PRC train: 0.803060	val: 0.382486	test: 0.421591

Epoch: 107
Loss: 0.06629354969775096
ROC train: 0.979224	val: 0.779951	test: 0.802610
PRC train: 0.773515	val: 0.390151	test: 0.388339

Epoch: 108
Loss: 0.06568880893810516
ROC train: 0.984388	val: 0.787548	test: 0.820017
PRC train: 0.807639	val: 0.387360	test: 0.412186

Epoch: 109
Loss: 0.06809210644669327
ROC train: 0.985642	val: 0.787565	test: 0.819635
PRC train: 0.820363	val: 0.404475	test: 0.407285

Epoch: 110
Loss: 0.06611245495534965
ROC train: 0.984654	val: 0.784768	test: 0.820603
PRC train: 0.805268	val: 0.389860	test: 0.417028

Epoch: 111
Loss: 0.06529282812367114
ROC train: 0.987332	val: 0.790517	test: 0.823994
PRC train: 0.833516	val: 0.407707	test: 0.421661

Epoch: 112
Loss: 0.06635468449626221
ROC train: 0.986996	val: 0.784697	test: 0.816784
PRC train: 0.820018	val: 0.387144	test: 0.414709

Epoch: 113
Loss: 0.06694165289313869
ROC train: 0.987538	val: 0.783915	test: 0.817367
PRC train: 0.826876	val: 0.385616	test: 0.417500

Epoch: 114
Loss: 0.0635757132074579
ROC train: 0.990246	val: 0.785958	test: 0.817211
PRC train: 0.841959	val: 0.393536	test: 0.416694

Epoch: 115
Loss: 0.0638139739882874
ROC train: 0.987325	val: 0.787554	test: 0.822625
PRC train: 0.829533	val: 0.402744	test: 0.434273

Epoch: 116
Loss: 0.06456730921881636
ROC train: 0.989529	val: 0.787284	test: 0.810850
PRC train: 0.843114	val: 0.393262	test: 0.389697

Epoch: 117
Loss: 0.06701979679108215
ROC train: 0.986696	val: 0.783012	test: 0.824260
PRC train: 0.820840	val: 0.391995	test: 0.411102

Epoch: 118
Loss: 0.06462426489698006
ROC train: 0.986489	val: 0.785473	test: 0.822887
PRC train: 0.821470	val: 0.395728	test: 0.410799

Epoch: 119
Loss: 0.06364916269126918
ROC train: 0.985655	val: 0.784341	test: 0.817027
PRC train: 0.822104	val: 0.376236	test: 0.386062

Epoch: 120
Loss: 0.061840478700699204
ROC train: 0.989938	val: 0.793159	test: 0.817824
PRC train: 0.844278	val: 0.387207	test: 0.396938

Early stopping
Best (ROC):	 train: 0.921167	val: 0.795552	test: 0.828195
Best (PRC):	 train: 0.569525	val: 0.376090	test: 0.445707

ROC train: 0.981388	val: 0.822120	test: 0.837489
PRC train: 0.787100	val: 0.440472	test: 0.434157

Epoch: 95
Loss: 0.07082946098788236
ROC train: 0.979809	val: 0.812034	test: 0.853458
PRC train: 0.781486	val: 0.431871	test: 0.429570

Epoch: 96
Loss: 0.07031423310541217
ROC train: 0.980000	val: 0.818972	test: 0.848775
PRC train: 0.777142	val: 0.444612	test: 0.428035

Epoch: 97
Loss: 0.06880196471280414
ROC train: 0.976321	val: 0.816577	test: 0.851274
PRC train: 0.761051	val: 0.429243	test: 0.422684

Epoch: 98
Loss: 0.06972797733378813
ROC train: 0.976780	val: 0.813835	test: 0.847826
PRC train: 0.756088	val: 0.428070	test: 0.424558

Epoch: 99
Loss: 0.07073771962045895
ROC train: 0.979238	val: 0.816081	test: 0.851401
PRC train: 0.776976	val: 0.429442	test: 0.439437

Epoch: 100
Loss: 0.06904383727322722
ROC train: 0.980519	val: 0.813890	test: 0.846960
PRC train: 0.778401	val: 0.419598	test: 0.402488

Epoch: 101
Loss: 0.06938733124764407
ROC train: 0.981621	val: 0.813269	test: 0.845800
PRC train: 0.793513	val: 0.418999	test: 0.397693

Epoch: 102
Loss: 0.06986768590408607
ROC train: 0.984190	val: 0.814788	test: 0.862749
PRC train: 0.804408	val: 0.440271	test: 0.426548

Epoch: 103
Loss: 0.07017758127843998
ROC train: 0.983313	val: 0.800628	test: 0.841833
PRC train: 0.805810	val: 0.436891	test: 0.404834

Epoch: 104
Loss: 0.06894065212923307
ROC train: 0.983211	val: 0.807730	test: 0.861059
PRC train: 0.801007	val: 0.459025	test: 0.419704

Epoch: 105
Loss: 0.06518209713830028
ROC train: 0.984670	val: 0.814648	test: 0.849543
PRC train: 0.808291	val: 0.442511	test: 0.403054

Epoch: 106
Loss: 0.0666254738000645
ROC train: 0.983917	val: 0.811830	test: 0.842093
PRC train: 0.800692	val: 0.418297	test: 0.404075

Epoch: 107
Loss: 0.0671757140125646
ROC train: 0.984907	val: 0.808096	test: 0.839490
PRC train: 0.813433	val: 0.425351	test: 0.416462

Epoch: 108
Loss: 0.06678342122289094
ROC train: 0.984031	val: 0.811871	test: 0.835403
PRC train: 0.808126	val: 0.422430	test: 0.402047

Epoch: 109
Loss: 0.06627402426272226
ROC train: 0.986913	val: 0.800521	test: 0.838477
PRC train: 0.817281	val: 0.433819	test: 0.400391

Epoch: 110
Loss: 0.06556263909591159
ROC train: 0.985251	val: 0.811457	test: 0.850141
PRC train: 0.812929	val: 0.428062	test: 0.400028

Epoch: 111
Loss: 0.06636542370942798
ROC train: 0.983528	val: 0.803768	test: 0.852021
PRC train: 0.808370	val: 0.436247	test: 0.416697

Epoch: 112
Loss: 0.06695323518015646
ROC train: 0.986192	val: 0.810869	test: 0.850505
PRC train: 0.813014	val: 0.434551	test: 0.429220

Epoch: 113
Loss: 0.06538101334229185
ROC train: 0.985918	val: 0.803023	test: 0.842717
PRC train: 0.816585	val: 0.444911	test: 0.406273

Epoch: 114
Loss: 0.06558916222549363
ROC train: 0.987709	val: 0.803882	test: 0.836885
PRC train: 0.833543	val: 0.445676	test: 0.409111

Epoch: 115
Loss: 0.06505401972530112
ROC train: 0.984389	val: 0.803485	test: 0.841194
PRC train: 0.807952	val: 0.435419	test: 0.405880

Epoch: 116
Loss: 0.06434044664561796
ROC train: 0.986328	val: 0.812184	test: 0.838314
PRC train: 0.820625	val: 0.431725	test: 0.403533

Epoch: 117
Loss: 0.06477445460831861
ROC train: 0.986763	val: 0.793749	test: 0.834739
PRC train: 0.824116	val: 0.423728	test: 0.416626

Epoch: 118
Loss: 0.06583245493238507
ROC train: 0.984737	val: 0.813420	test: 0.835832
PRC train: 0.813353	val: 0.414748	test: 0.400788

Epoch: 119
Loss: 0.06218998631134562
ROC train: 0.987575	val: 0.811360	test: 0.837484
PRC train: 0.832935	val: 0.432837	test: 0.400353

Epoch: 120
Loss: 0.0640514615260345
ROC train: 0.987435	val: 0.818835	test: 0.829821
PRC train: 0.830547	val: 0.414802	test: 0.401216

Early stopping
Best (ROC):	 train: 0.964296	val: 0.826806	test: 0.837396
Best (PRC):	 train: 0.703251	val: 0.450002	test: 0.433101

ROC train: 0.979756	val: 0.806158	test: 0.829202
PRC train: 0.782994	val: 0.431336	test: 0.426591

Epoch: 95
Loss: 0.06956037538414486
ROC train: 0.978924	val: 0.802254	test: 0.834243
PRC train: 0.774481	val: 0.424715	test: 0.427735

Epoch: 96
Loss: 0.06928964910962032
ROC train: 0.980254	val: 0.803878	test: 0.826093
PRC train: 0.781944	val: 0.429537	test: 0.414733

Epoch: 97
Loss: 0.0701104481878325
ROC train: 0.982767	val: 0.798269	test: 0.846978
PRC train: 0.793902	val: 0.428629	test: 0.451013

Epoch: 98
Loss: 0.06778013451162285
ROC train: 0.979110	val: 0.801473	test: 0.834126
PRC train: 0.774635	val: 0.429289	test: 0.429302

Epoch: 99
Loss: 0.07016954798099186
ROC train: 0.983182	val: 0.805171	test: 0.844349
PRC train: 0.785637	val: 0.450749	test: 0.449745

Epoch: 100
Loss: 0.07041060141402529
ROC train: 0.982708	val: 0.803801	test: 0.835655
PRC train: 0.790580	val: 0.428170	test: 0.428909

Epoch: 101
Loss: 0.07012392303326985
ROC train: 0.982363	val: 0.792738	test: 0.822591
PRC train: 0.786699	val: 0.398826	test: 0.422613

Epoch: 102
Loss: 0.06991889738454374
ROC train: 0.984475	val: 0.798079	test: 0.831108
PRC train: 0.798031	val: 0.428147	test: 0.431953

Epoch: 103
Loss: 0.06832108967101964
ROC train: 0.982052	val: 0.807543	test: 0.837369
PRC train: 0.797975	val: 0.421436	test: 0.423869

Epoch: 104
Loss: 0.06698880435072198
ROC train: 0.982187	val: 0.792023	test: 0.825293
PRC train: 0.790087	val: 0.431645	test: 0.400297

Epoch: 105
Loss: 0.06633544935790092
ROC train: 0.981102	val: 0.794918	test: 0.843009
PRC train: 0.781491	val: 0.422972	test: 0.458541

Epoch: 106
Loss: 0.0680052314841166
ROC train: 0.985052	val: 0.800713	test: 0.838977
PRC train: 0.808193	val: 0.425227	test: 0.452482

Epoch: 107
Loss: 0.06692147069507261
ROC train: 0.972452	val: 0.790785	test: 0.830197
PRC train: 0.739738	val: 0.398745	test: 0.384208

Epoch: 108
Loss: 0.06814641903593555
ROC train: 0.983835	val: 0.797280	test: 0.831162
PRC train: 0.797820	val: 0.428574	test: 0.428785

Epoch: 109
Loss: 0.06576773834023035
ROC train: 0.982788	val: 0.801654	test: 0.834386
PRC train: 0.790079	val: 0.421650	test: 0.411986

Epoch: 110
Loss: 0.06538709909599023
ROC train: 0.983622	val: 0.802065	test: 0.836973
PRC train: 0.803120	val: 0.435798	test: 0.437966

Epoch: 111
Loss: 0.0655437373321226
ROC train: 0.987446	val: 0.801105	test: 0.846527
PRC train: 0.823468	val: 0.432390	test: 0.438894

Epoch: 112
Loss: 0.06490925333077838
ROC train: 0.987015	val: 0.801893	test: 0.844014
PRC train: 0.823138	val: 0.444232	test: 0.449680

Epoch: 113
Loss: 0.0634744644893968
ROC train: 0.987495	val: 0.809182	test: 0.844762
PRC train: 0.825174	val: 0.437871	test: 0.438922

Epoch: 114
Loss: 0.06386540126669377
ROC train: 0.985496	val: 0.804930	test: 0.824003
PRC train: 0.823660	val: 0.427871	test: 0.409534

Epoch: 115
Loss: 0.0639908842308378
ROC train: 0.985514	val: 0.802843	test: 0.825411
PRC train: 0.811290	val: 0.424144	test: 0.416729

Epoch: 116
Loss: 0.06354751131057783
ROC train: 0.988935	val: 0.806176	test: 0.835763
PRC train: 0.840162	val: 0.432168	test: 0.437909

Epoch: 117
Loss: 0.06378364363124128
ROC train: 0.988222	val: 0.800399	test: 0.834512
PRC train: 0.834252	val: 0.414787	test: 0.421251

Epoch: 118
Loss: 0.06252666038407263
ROC train: 0.989379	val: 0.798209	test: 0.839275
PRC train: 0.841271	val: 0.422599	test: 0.432650

Epoch: 119
Loss: 0.06304945384362354
ROC train: 0.985191	val: 0.799634	test: 0.829340
PRC train: 0.811334	val: 0.414269	test: 0.393681

Epoch: 120
Loss: 0.06260067102057527
ROC train: 0.987488	val: 0.805131	test: 0.837302
PRC train: 0.827844	val: 0.413877	test: 0.423643

Early stopping
Best (ROC):	 train: 0.945505	val: 0.814475	test: 0.833718
Best (PRC):	 train: 0.616256	val: 0.434019	test: 0.415305

ROC train: 0.977403	val: 0.787974	test: 0.835050
PRC train: 0.768941	val: 0.419094	test: 0.433752

Epoch: 95
Loss: 0.0710666009472226
ROC train: 0.977501	val: 0.794774	test: 0.838670
PRC train: 0.774285	val: 0.431842	test: 0.441383

Epoch: 96
Loss: 0.07243983317267993
ROC train: 0.975741	val: 0.805675	test: 0.828227
PRC train: 0.762178	val: 0.426122	test: 0.453134

Epoch: 97
Loss: 0.07238859247346278
ROC train: 0.978756	val: 0.799958	test: 0.832150
PRC train: 0.772551	val: 0.429394	test: 0.431188

Epoch: 98
Loss: 0.07070468124690608
ROC train: 0.982866	val: 0.790848	test: 0.842663
PRC train: 0.792155	val: 0.436960	test: 0.440951

Epoch: 99
Loss: 0.07046200273144618
ROC train: 0.975331	val: 0.790566	test: 0.826547
PRC train: 0.747372	val: 0.418514	test: 0.407128

Epoch: 100
Loss: 0.07068411123789416
ROC train: 0.980979	val: 0.794474	test: 0.828931
PRC train: 0.779139	val: 0.418707	test: 0.437327

Epoch: 101
Loss: 0.07032215276412579
ROC train: 0.979027	val: 0.803519	test: 0.844235
PRC train: 0.767906	val: 0.437897	test: 0.442491

Epoch: 102
Loss: 0.06950778733145986
ROC train: 0.981999	val: 0.804293	test: 0.837211
PRC train: 0.790699	val: 0.437310	test: 0.429414

Epoch: 103
Loss: 0.06944554921994904
ROC train: 0.977619	val: 0.791122	test: 0.830962
PRC train: 0.763485	val: 0.440483	test: 0.425729

Epoch: 104
Loss: 0.06952252421632103
ROC train: 0.983868	val: 0.793313	test: 0.837396
PRC train: 0.806355	val: 0.422765	test: 0.424418

Epoch: 105
Loss: 0.06919623968457556
ROC train: 0.978717	val: 0.798640	test: 0.841599
PRC train: 0.775477	val: 0.437347	test: 0.431203

Epoch: 106
Loss: 0.06915833581281504
ROC train: 0.981305	val: 0.797340	test: 0.837404
PRC train: 0.786639	val: 0.451823	test: 0.431048

Epoch: 107
Loss: 0.06739628511881214
ROC train: 0.979562	val: 0.794129	test: 0.833620
PRC train: 0.777061	val: 0.423503	test: 0.405710

Epoch: 108
Loss: 0.06738950362277632
ROC train: 0.977982	val: 0.792964	test: 0.835174
PRC train: 0.770312	val: 0.425297	test: 0.433288

Epoch: 109
Loss: 0.06807126789891015
ROC train: 0.981697	val: 0.794513	test: 0.836429
PRC train: 0.793970	val: 0.429197	test: 0.417964

Epoch: 110
Loss: 0.06614893147232599
ROC train: 0.984715	val: 0.801191	test: 0.839078
PRC train: 0.815202	val: 0.448765	test: 0.440194

Epoch: 111
Loss: 0.06590723943744792
ROC train: 0.984908	val: 0.802483	test: 0.843362
PRC train: 0.815009	val: 0.445273	test: 0.436103

Epoch: 112
Loss: 0.06481776226684438
ROC train: 0.983781	val: 0.794274	test: 0.840327
PRC train: 0.804457	val: 0.452494	test: 0.438276

Epoch: 113
Loss: 0.06505209313876889
ROC train: 0.983797	val: 0.796106	test: 0.833777
PRC train: 0.797937	val: 0.434855	test: 0.418220

Epoch: 114
Loss: 0.0681882837954618
ROC train: 0.984628	val: 0.794435	test: 0.843348
PRC train: 0.804871	val: 0.429116	test: 0.417897

Epoch: 115
Loss: 0.06659552186716372
ROC train: 0.985437	val: 0.800069	test: 0.841318
PRC train: 0.817342	val: 0.418716	test: 0.431698

Epoch: 116
Loss: 0.06487789688214146
ROC train: 0.985673	val: 0.796455	test: 0.836779
PRC train: 0.819317	val: 0.450741	test: 0.432612

Epoch: 117
Loss: 0.06390001998404264
ROC train: 0.986568	val: 0.800967	test: 0.840116
PRC train: 0.818771	val: 0.447566	test: 0.421402

Epoch: 118
Loss: 0.06532527232349905
ROC train: 0.985408	val: 0.802531	test: 0.827459
PRC train: 0.815286	val: 0.429401	test: 0.412083

Epoch: 119
Loss: 0.06457804505790485
ROC train: 0.985209	val: 0.791344	test: 0.821423
PRC train: 0.812838	val: 0.429766	test: 0.396300

Epoch: 120
Loss: 0.06515554749524148
ROC train: 0.986902	val: 0.806437	test: 0.836218
PRC train: 0.816492	val: 0.433715	test: 0.414668

Early stopping
Best (ROC):	 train: 0.954476	val: 0.812585	test: 0.847832
Best (PRC):	 train: 0.658189	val: 0.459428	test: 0.454357
All runs completed.

ROC train: 0.977233	val: 0.803813	test: 0.838787
PRC train: 0.770044	val: 0.414708	test: 0.463388

Epoch: 95
Loss: 0.07392935710652722
ROC train: 0.979855	val: 0.822789	test: 0.845164
PRC train: 0.786059	val: 0.415671	test: 0.463477

Epoch: 96
Loss: 0.07114599899701254
ROC train: 0.977665	val: 0.816734	test: 0.825681
PRC train: 0.774465	val: 0.417479	test: 0.444344

Epoch: 97
Loss: 0.07142321548868309
ROC train: 0.980584	val: 0.818439	test: 0.852134
PRC train: 0.781705	val: 0.407079	test: 0.471018

Epoch: 98
Loss: 0.07169013933597347
ROC train: 0.983383	val: 0.811041	test: 0.846020
PRC train: 0.798389	val: 0.433798	test: 0.470873

Epoch: 99
Loss: 0.07082208994826543
ROC train: 0.981066	val: 0.820146	test: 0.837663
PRC train: 0.794151	val: 0.408358	test: 0.458718

Epoch: 100
Loss: 0.07003730035823724
ROC train: 0.981315	val: 0.829742	test: 0.845167
PRC train: 0.794593	val: 0.421582	test: 0.431273

Epoch: 101
Loss: 0.06941078585834652
ROC train: 0.981699	val: 0.814498	test: 0.838454
PRC train: 0.794966	val: 0.412657	test: 0.452426

Epoch: 102
Loss: 0.06976712783543956
ROC train: 0.977967	val: 0.821230	test: 0.858756
PRC train: 0.775394	val: 0.414666	test: 0.480373

Epoch: 103
Loss: 0.06815600963927462
ROC train: 0.981042	val: 0.812523	test: 0.843124
PRC train: 0.792393	val: 0.409600	test: 0.435296

Epoch: 104
Loss: 0.06815145532756067
ROC train: 0.980341	val: 0.834906	test: 0.833520
PRC train: 0.793664	val: 0.406850	test: 0.427941

Epoch: 105
Loss: 0.06968788954220707
ROC train: 0.981983	val: 0.824999	test: 0.850074
PRC train: 0.798586	val: 0.421170	test: 0.474121

Epoch: 106
Loss: 0.06761619941473478
ROC train: 0.981389	val: 0.808195	test: 0.847979
PRC train: 0.804116	val: 0.398354	test: 0.472521

Epoch: 107
Loss: 0.06585056516881875
ROC train: 0.983971	val: 0.818141	test: 0.832787
PRC train: 0.812384	val: 0.419601	test: 0.458763

Epoch: 108
Loss: 0.06691445868588919
ROC train: 0.983295	val: 0.820781	test: 0.847078
PRC train: 0.812315	val: 0.419660	test: 0.456042

Epoch: 109
Loss: 0.06692219533985874
ROC train: 0.981367	val: 0.808238	test: 0.828110
PRC train: 0.794541	val: 0.370338	test: 0.414508

Epoch: 110
Loss: 0.06722318419753857
ROC train: 0.983147	val: 0.822416	test: 0.834796
PRC train: 0.817464	val: 0.372899	test: 0.438113

Epoch: 111
Loss: 0.06831008528294265
ROC train: 0.980157	val: 0.828699	test: 0.847215
PRC train: 0.794078	val: 0.401931	test: 0.424392

Epoch: 112
Loss: 0.06588590893452925
ROC train: 0.984504	val: 0.817882	test: 0.851699
PRC train: 0.812480	val: 0.413371	test: 0.446794

Epoch: 113
Loss: 0.06472068159396593
ROC train: 0.984876	val: 0.810017	test: 0.854345
PRC train: 0.812548	val: 0.374612	test: 0.416147

Epoch: 114
Loss: 0.06612921547486121
ROC train: 0.985491	val: 0.831303	test: 0.838234
PRC train: 0.818510	val: 0.419509	test: 0.450294

Epoch: 115
Loss: 0.06571955578215978
ROC train: 0.987018	val: 0.821010	test: 0.849559
PRC train: 0.828050	val: 0.410030	test: 0.451611

Epoch: 116
Loss: 0.06597532903960243
ROC train: 0.987471	val: 0.811291	test: 0.840179
PRC train: 0.834440	val: 0.410278	test: 0.459514

Epoch: 117
Loss: 0.065407515178324
ROC train: 0.986607	val: 0.827515	test: 0.845529
PRC train: 0.831134	val: 0.388750	test: 0.445201

Epoch: 118
Loss: 0.06388844140554718
ROC train: 0.986464	val: 0.815544	test: 0.842029
PRC train: 0.824156	val: 0.396253	test: 0.429801

Epoch: 119
Loss: 0.06590587908958864
ROC train: 0.987565	val: 0.815847	test: 0.838488
PRC train: 0.835995	val: 0.401603	test: 0.446066

Epoch: 120
Loss: 0.06392846458518799
ROC train: 0.985246	val: 0.820530	test: 0.841386
PRC train: 0.816868	val: 0.408847	test: 0.457932

Early stopping
Best (ROC):	 train: 0.960166	val: 0.845111	test: 0.841499
Best (PRC):	 train: 0.690955	val: 0.448170	test: 0.480045

ROC train: 0.976524	val: 0.830845	test: 0.854609
PRC train: 0.765251	val: 0.418979	test: 0.473339

Epoch: 95
Loss: 0.07146667820006672
ROC train: 0.980198	val: 0.816201	test: 0.864924
PRC train: 0.793362	val: 0.422721	test: 0.480515

Epoch: 96
Loss: 0.07194482759630234
ROC train: 0.978626	val: 0.811924	test: 0.846592
PRC train: 0.778553	val: 0.390903	test: 0.443281

Epoch: 97
Loss: 0.06890960169321421
ROC train: 0.981139	val: 0.805764	test: 0.853715
PRC train: 0.801599	val: 0.381990	test: 0.441727

Epoch: 98
Loss: 0.0712420707817761
ROC train: 0.979452	val: 0.808727	test: 0.852982
PRC train: 0.789135	val: 0.409403	test: 0.454403

Epoch: 99
Loss: 0.06995645193772697
ROC train: 0.980281	val: 0.812840	test: 0.850805
PRC train: 0.788792	val: 0.376578	test: 0.452734

Epoch: 100
Loss: 0.07071274856335497
ROC train: 0.981813	val: 0.809767	test: 0.843031
PRC train: 0.799676	val: 0.404000	test: 0.445446

Epoch: 101
Loss: 0.06897050861329834
ROC train: 0.978064	val: 0.812010	test: 0.854485
PRC train: 0.776302	val: 0.404465	test: 0.444352

Epoch: 102
Loss: 0.07025036542118122
ROC train: 0.980852	val: 0.816815	test: 0.855299
PRC train: 0.794543	val: 0.429352	test: 0.474878

Epoch: 103
Loss: 0.0688306689276641
ROC train: 0.979105	val: 0.806652	test: 0.854690
PRC train: 0.785597	val: 0.409374	test: 0.472131

Epoch: 104
Loss: 0.06874045012386547
ROC train: 0.984750	val: 0.815974	test: 0.852991
PRC train: 0.818137	val: 0.421063	test: 0.471025

Epoch: 105
Loss: 0.06975318473527133
ROC train: 0.982269	val: 0.789581	test: 0.851428
PRC train: 0.799133	val: 0.389586	test: 0.456392

Epoch: 106
Loss: 0.06759992216858113
ROC train: 0.982279	val: 0.818330	test: 0.852295
PRC train: 0.804481	val: 0.416422	test: 0.464745

Epoch: 107
Loss: 0.06933692971109506
ROC train: 0.982638	val: 0.808331	test: 0.852869
PRC train: 0.802232	val: 0.416889	test: 0.464669

Epoch: 108
Loss: 0.06692542392079268
ROC train: 0.983449	val: 0.812516	test: 0.847679
PRC train: 0.807704	val: 0.408473	test: 0.465699

Epoch: 109
Loss: 0.06734660671351514
ROC train: 0.985276	val: 0.813120	test: 0.853615
PRC train: 0.824315	val: 0.401118	test: 0.454645

Epoch: 110
Loss: 0.06665376413487181
ROC train: 0.984397	val: 0.804035	test: 0.860819
PRC train: 0.818221	val: 0.388750	test: 0.465464

Epoch: 111
Loss: 0.06664865267356297
ROC train: 0.984764	val: 0.826309	test: 0.861215
PRC train: 0.815174	val: 0.403166	test: 0.464658

Epoch: 112
Loss: 0.06555282816560226
ROC train: 0.983187	val: 0.812479	test: 0.852440
PRC train: 0.810932	val: 0.403676	test: 0.463611

Epoch: 113
Loss: 0.06566451868249881
ROC train: 0.984092	val: 0.803939	test: 0.845631
PRC train: 0.824248	val: 0.404306	test: 0.456186

Epoch: 114
Loss: 0.06550651451467276
ROC train: 0.984713	val: 0.803743	test: 0.854270
PRC train: 0.829196	val: 0.404930	test: 0.436451

Epoch: 115
Loss: 0.06372015664438924
ROC train: 0.986381	val: 0.798448	test: 0.854048
PRC train: 0.831872	val: 0.400388	test: 0.465270

Epoch: 116
Loss: 0.06630591239458823
ROC train: 0.985031	val: 0.810514	test: 0.846205
PRC train: 0.825168	val: 0.393445	test: 0.420510

Epoch: 117
Loss: 0.06625558840026513
ROC train: 0.984146	val: 0.814381	test: 0.858619
PRC train: 0.825524	val: 0.415166	test: 0.456892

Epoch: 118
Loss: 0.06348641290616056
ROC train: 0.986924	val: 0.796107	test: 0.851922
PRC train: 0.839182	val: 0.407219	test: 0.456721

Epoch: 119
Loss: 0.06364238532007069
ROC train: 0.985301	val: 0.804111	test: 0.854780
PRC train: 0.824577	val: 0.387919	test: 0.448195

Epoch: 120
Loss: 0.06458812308671144
ROC train: 0.986814	val: 0.807614	test: 0.862023
PRC train: 0.834138	val: 0.395047	test: 0.459227

Early stopping
Best (ROC):	 train: 0.945543	val: 0.851397	test: 0.867128
Best (PRC):	 train: 0.638639	val: 0.415766	test: 0.476304

ROC train: 0.978495	val: 0.831447	test: 0.844327
PRC train: 0.773162	val: 0.415093	test: 0.441966

Epoch: 95
Loss: 0.07211729207312177
ROC train: 0.979427	val: 0.805677	test: 0.849856
PRC train: 0.776747	val: 0.402217	test: 0.458573

Epoch: 96
Loss: 0.07439336580393996
ROC train: 0.975288	val: 0.790583	test: 0.844065
PRC train: 0.764251	val: 0.399290	test: 0.461423

Epoch: 97
Loss: 0.07193623240034619
ROC train: 0.980179	val: 0.798085	test: 0.853678
PRC train: 0.785893	val: 0.397167	test: 0.459205

Epoch: 98
Loss: 0.07322548491610106
ROC train: 0.981418	val: 0.817207	test: 0.852373
PRC train: 0.791619	val: 0.406204	test: 0.456517

Epoch: 99
Loss: 0.07228148291031693
ROC train: 0.978909	val: 0.816237	test: 0.865220
PRC train: 0.778603	val: 0.445702	test: 0.475532

Epoch: 100
Loss: 0.0704808512236908
ROC train: 0.979610	val: 0.812295	test: 0.852699
PRC train: 0.784279	val: 0.411056	test: 0.441270

Epoch: 101
Loss: 0.06996780455211794
ROC train: 0.979047	val: 0.809029	test: 0.855034
PRC train: 0.786743	val: 0.411066	test: 0.434550

Epoch: 102
Loss: 0.06808853990504311
ROC train: 0.980910	val: 0.805087	test: 0.846059
PRC train: 0.791026	val: 0.390109	test: 0.430219

Epoch: 103
Loss: 0.06943583884326399
ROC train: 0.978393	val: 0.807906	test: 0.827892
PRC train: 0.779787	val: 0.409802	test: 0.457165

Epoch: 104
Loss: 0.06947420155916184
ROC train: 0.982120	val: 0.816448	test: 0.847684
PRC train: 0.795427	val: 0.417749	test: 0.444211

Epoch: 105
Loss: 0.06857297898112598
ROC train: 0.983866	val: 0.816075	test: 0.852281
PRC train: 0.808041	val: 0.409809	test: 0.457657

Epoch: 106
Loss: 0.07012954143667068
ROC train: 0.979322	val: 0.793751	test: 0.845927
PRC train: 0.775255	val: 0.378735	test: 0.439745

Epoch: 107
Loss: 0.06763402130933364
ROC train: 0.982979	val: 0.801632	test: 0.838525
PRC train: 0.803406	val: 0.409595	test: 0.465055

Epoch: 108
Loss: 0.06786705226817945
ROC train: 0.983597	val: 0.812406	test: 0.847235
PRC train: 0.810304	val: 0.388701	test: 0.436529

Epoch: 109
Loss: 0.06553393440797899
ROC train: 0.984496	val: 0.812100	test: 0.847511
PRC train: 0.808800	val: 0.410254	test: 0.447668

Epoch: 110
Loss: 0.06685663240489674
ROC train: 0.982553	val: 0.795020	test: 0.840268
PRC train: 0.801437	val: 0.392475	test: 0.434692

Epoch: 111
Loss: 0.06674510220379673
ROC train: 0.980562	val: 0.809984	test: 0.850358
PRC train: 0.785427	val: 0.372389	test: 0.424001

Epoch: 112
Loss: 0.06697156362688658
ROC train: 0.983372	val: 0.811524	test: 0.860936
PRC train: 0.811250	val: 0.393951	test: 0.446211

Epoch: 113
Loss: 0.06721464728543866
ROC train: 0.984846	val: 0.812942	test: 0.849101
PRC train: 0.815322	val: 0.413621	test: 0.444710

Epoch: 114
Loss: 0.06710015822935332
ROC train: 0.986105	val: 0.798776	test: 0.849135
PRC train: 0.827361	val: 0.396228	test: 0.423804

Epoch: 115
Loss: 0.06666658709430966
ROC train: 0.984615	val: 0.808558	test: 0.846924
PRC train: 0.815398	val: 0.386271	test: 0.413319

Epoch: 116
Loss: 0.0642747736745303
ROC train: 0.984379	val: 0.790407	test: 0.854038
PRC train: 0.814407	val: 0.379999	test: 0.436921

Epoch: 117
Loss: 0.06462738067503011
ROC train: 0.986891	val: 0.807381	test: 0.845099
PRC train: 0.831023	val: 0.405469	test: 0.455957

Epoch: 118
Loss: 0.06408743230602149
ROC train: 0.985847	val: 0.811798	test: 0.855308
PRC train: 0.830921	val: 0.414796	test: 0.461593

Epoch: 119
Loss: 0.06384583525232866
ROC train: 0.987661	val: 0.814071	test: 0.859050
PRC train: 0.832578	val: 0.414435	test: 0.461580

Epoch: 120
Loss: 0.06399166966113326
ROC train: 0.987830	val: 0.810604	test: 0.851604
PRC train: 0.841325	val: 0.400460	test: 0.446699

Epoch: 121
Loss: 0.06299083006201685
ROC train: 0.987959	val: 0.806011	test: 0.853116
PRC train: 0.836259	val: 0.391818	test: 0.436895

Epoch: 122
Loss: 0.06275014577013563
ROC train: 0.988730	val: 0.813012	test: 0.855330
PRC train: 0.849110	val: 0.401366	test: 0.436266

Epoch: 123
Loss: 0.06300418888154025
ROC train: 0.989036	val: 0.809663	test: 0.839827
PRC train: 0.848654	val: 0.388937	test: 0.433213

Epoch: 124
Loss: 0.06360363346552929
ROC train: 0.986705	val: 0.790344	test: 0.846909
PRC train: 0.834335	val: 0.399234	test: 0.432774

Epoch: 125
Loss: 0.0632366171935709
ROC train: 0.988630	val: 0.820788	test: 0.852598
PRC train: 0.847224	val: 0.410772	test: 0.449539

Epoch: 126
Loss: 0.062197911034807325
ROC train: 0.990092	val: 0.818310	test: 0.845795
PRC train: 0.858277	val: 0.416007	test: 0.436197

Epoch: 127
Loss: 0.062244238348146845
ROC train: 0.988202	val: 0.810451	test: 0.848513
PRC train: 0.839215	val: 0.405534	test: 0.437702

Epoch: 128
Loss: 0.06160302184203293
ROC train: 0.989219	val: 0.806436	test: 0.856347
PRC train: 0.858776	val: 0.392438	test: 0.429729

Epoch: 129
Loss: 0.06260778306387493
ROC train: 0.988781	val: 0.807688	test: 0.847332
PRC train: 0.851217	val: 0.400644	test: 0.445255

Early stopping
Best (ROC):	 train: 0.978495	val: 0.831447	test: 0.844327
Best (PRC):	 train: 0.773162	val: 0.415093	test: 0.441966
All runs completed.

ROC train: 0.981155	val: 0.800668	test: 0.817904
PRC train: 0.777844	val: 0.403536	test: 0.430583

Epoch: 95
Loss: 0.06973048600789963
ROC train: 0.980177	val: 0.790936	test: 0.816340
PRC train: 0.771362	val: 0.396568	test: 0.414787

Epoch: 96
Loss: 0.07071365392422292
ROC train: 0.978365	val: 0.797442	test: 0.819742
PRC train: 0.766160	val: 0.414019	test: 0.415674

Epoch: 97
Loss: 0.07172016030501946
ROC train: 0.981254	val: 0.799873	test: 0.810957
PRC train: 0.782833	val: 0.408373	test: 0.419328

Epoch: 98
Loss: 0.07148183152113641
ROC train: 0.981820	val: 0.798762	test: 0.812219
PRC train: 0.786286	val: 0.398053	test: 0.434570

Epoch: 99
Loss: 0.069266333968266
ROC train: 0.982529	val: 0.799622	test: 0.821023
PRC train: 0.791834	val: 0.407468	test: 0.445979

Epoch: 100
Loss: 0.06697334552480501
ROC train: 0.977261	val: 0.793741	test: 0.818734
PRC train: 0.766867	val: 0.389812	test: 0.432124

Epoch: 101
Loss: 0.07105143225861106
ROC train: 0.979759	val: 0.794152	test: 0.811420
PRC train: 0.774832	val: 0.405680	test: 0.436241

Epoch: 102
Loss: 0.06946876837067735
ROC train: 0.984550	val: 0.805084	test: 0.822364
PRC train: 0.806978	val: 0.415290	test: 0.433957

Epoch: 103
Loss: 0.06999501207492592
ROC train: 0.981581	val: 0.798568	test: 0.823404
PRC train: 0.774841	val: 0.405383	test: 0.430941

Epoch: 104
Loss: 0.06751598186488625
ROC train: 0.985343	val: 0.802435	test: 0.813780
PRC train: 0.803128	val: 0.417334	test: 0.443341

Epoch: 105
Loss: 0.0677509487705179
ROC train: 0.985207	val: 0.807946	test: 0.815011
PRC train: 0.814733	val: 0.429333	test: 0.429464

Epoch: 106
Loss: 0.06722203004299981
ROC train: 0.985421	val: 0.803989	test: 0.812429
PRC train: 0.807030	val: 0.412008	test: 0.439625

Epoch: 107
Loss: 0.06939279293731246
ROC train: 0.984944	val: 0.809080	test: 0.814271
PRC train: 0.815995	val: 0.427150	test: 0.436215

Epoch: 108
Loss: 0.0661183215894441
ROC train: 0.984252	val: 0.807244	test: 0.804416
PRC train: 0.809283	val: 0.405394	test: 0.423102

Epoch: 109
Loss: 0.06797566724823026
ROC train: 0.983879	val: 0.802188	test: 0.809994
PRC train: 0.798477	val: 0.418088	test: 0.404627

Epoch: 110
Loss: 0.06588818739129569
ROC train: 0.986554	val: 0.798786	test: 0.809799
PRC train: 0.821199	val: 0.423507	test: 0.432290

Epoch: 111
Loss: 0.06366649658009214
ROC train: 0.984546	val: 0.798925	test: 0.814306
PRC train: 0.820984	val: 0.408452	test: 0.418113

Epoch: 112
Loss: 0.064715813074238
ROC train: 0.978480	val: 0.808351	test: 0.815063
PRC train: 0.743465	val: 0.407365	test: 0.423113

Epoch: 113
Loss: 0.06590804525408503
ROC train: 0.986998	val: 0.802595	test: 0.811583
PRC train: 0.824145	val: 0.405043	test: 0.431275

Epoch: 114
Loss: 0.06533276636840561
ROC train: 0.985010	val: 0.804727	test: 0.807875
PRC train: 0.816199	val: 0.406646	test: 0.441095

Epoch: 115
Loss: 0.06637818732540259
ROC train: 0.981248	val: 0.798308	test: 0.812074
PRC train: 0.792612	val: 0.401445	test: 0.413261

Epoch: 116
Loss: 0.06509607487749507
ROC train: 0.984638	val: 0.793922	test: 0.815733
PRC train: 0.809722	val: 0.406181	test: 0.415584

Epoch: 117
Loss: 0.06491498806058571
ROC train: 0.989659	val: 0.806148	test: 0.809862
PRC train: 0.846899	val: 0.417217	test: 0.421377

Epoch: 118
Loss: 0.06357114775365798
ROC train: 0.987881	val: 0.788793	test: 0.816613
PRC train: 0.838356	val: 0.404336	test: 0.410030

Epoch: 119
Loss: 0.06533174057527472
ROC train: 0.986501	val: 0.813141	test: 0.809711
PRC train: 0.824403	val: 0.402157	test: 0.411020

Epoch: 120
Loss: 0.06366314621197543
ROC train: 0.986551	val: 0.797763	test: 0.814119
PRC train: 0.811449	val: 0.403016	test: 0.407011

Epoch: 121
Loss: 0.06443612382565053
ROC train: 0.988709	val: 0.807362	test: 0.817097
PRC train: 0.845348	val: 0.405977	test: 0.415115

Epoch: 122
Loss: 0.06036252246746031
ROC train: 0.988137	val: 0.806877	test: 0.815356
PRC train: 0.833937	val: 0.401764	test: 0.406320

Epoch: 123
Loss: 0.06193186209046199
ROC train: 0.990245	val: 0.802809	test: 0.805487
PRC train: 0.847687	val: 0.431230	test: 0.424262

Epoch: 124
Loss: 0.0639956766370168
ROC train: 0.987508	val: 0.801570	test: 0.808516
PRC train: 0.837116	val: 0.405369	test: 0.421817

Epoch: 125
Loss: 0.06353142430160551
ROC train: 0.990578	val: 0.803153	test: 0.806450
PRC train: 0.860212	val: 0.415970	test: 0.423346

Epoch: 126
Loss: 0.059870301828418834
ROC train: 0.989473	val: 0.798838	test: 0.809135
PRC train: 0.843267	val: 0.409344	test: 0.422673

Epoch: 127
Loss: 0.058930345396741614
ROC train: 0.990972	val: 0.806512	test: 0.806670
PRC train: 0.862734	val: 0.408945	test: 0.403253

Epoch: 128
Loss: 0.06095439966405218
ROC train: 0.991325	val: 0.804326	test: 0.807946
PRC train: 0.859003	val: 0.419220	test: 0.419267

Epoch: 129
Loss: 0.061229004588445955
ROC train: 0.989218	val: 0.793869	test: 0.808023
PRC train: 0.847088	val: 0.397809	test: 0.391862

Epoch: 130
Loss: 0.058574254767492714
ROC train: 0.989493	val: 0.803815	test: 0.813512
PRC train: 0.853698	val: 0.415845	test: 0.404668

Epoch: 131
Loss: 0.05982549996916364
ROC train: 0.992081	val: 0.806613	test: 0.817828
PRC train: 0.866692	val: 0.412591	test: 0.410407

Epoch: 132
Loss: 0.06049901564934123
ROC train: 0.990537	val: 0.810729	test: 0.814310
PRC train: 0.853903	val: 0.430761	test: 0.411872

Epoch: 133
Loss: 0.05882214939383878
ROC train: 0.990628	val: 0.806074	test: 0.804686
PRC train: 0.857906	val: 0.403945	test: 0.394639

Epoch: 134
Loss: 0.05805144139648469
ROC train: 0.990707	val: 0.802479	test: 0.815077
PRC train: 0.852112	val: 0.402371	test: 0.420953

Epoch: 135
Loss: 0.060203288570605376
ROC train: 0.991833	val: 0.798172	test: 0.821988
PRC train: 0.865432	val: 0.416963	test: 0.431992

Epoch: 136
Loss: 0.05985805975152778
ROC train: 0.991331	val: 0.793639	test: 0.814760
PRC train: 0.870150	val: 0.404041	test: 0.404551

Epoch: 137
Loss: 0.05741033967709472
ROC train: 0.991463	val: 0.810239	test: 0.812092
PRC train: 0.870900	val: 0.418343	test: 0.400309

Epoch: 138
Loss: 0.05621844041478442
ROC train: 0.991083	val: 0.804501	test: 0.808246
PRC train: 0.858249	val: 0.417400	test: 0.405281

Epoch: 139
Loss: 0.05853220745021794
ROC train: 0.987995	val: 0.798134	test: 0.801894
PRC train: 0.819376	val: 0.389929	test: 0.400665

Epoch: 140
Loss: 0.05726707394036844
ROC train: 0.992986	val: 0.797497	test: 0.801148
PRC train: 0.870601	val: 0.417037	test: 0.417693

Epoch: 141
Loss: 0.05772052840054314
ROC train: 0.992525	val: 0.798632	test: 0.805183
PRC train: 0.877314	val: 0.412224	test: 0.394909

Epoch: 142
Loss: 0.0568758509695409
ROC train: 0.993446	val: 0.804693	test: 0.806489
PRC train: 0.877787	val: 0.417426	test: 0.399545

Epoch: 143
Loss: 0.05629394361651628
ROC train: 0.993251	val: 0.804025	test: 0.811020
PRC train: 0.891555	val: 0.408573	test: 0.400803

Epoch: 144
Loss: 0.05380677479845899
ROC train: 0.993229	val: 0.810371	test: 0.808315
PRC train: 0.884950	val: 0.429513	test: 0.409565

Epoch: 145
Loss: 0.055531976059235065
ROC train: 0.992459	val: 0.795293	test: 0.801868
PRC train: 0.878888	val: 0.399696	test: 0.395695

Epoch: 146
Loss: 0.055636919602509695
ROC train: 0.991482	val: 0.802271	test: 0.814119
PRC train: 0.863780	val: 0.405715	test: 0.409124

Epoch: 147
Loss: 0.054089378087413785
ROC train: 0.990848	val: 0.800252	test: 0.802255
PRC train: 0.862994	val: 0.404038	test: 0.390304

Epoch: 148
Loss: 0.0560771285203399
ROC train: 0.992853	val: 0.806315	test: 0.802714
PRC train: 0.882327	val: 0.418678	test: 0.401469

Epoch: 149
Loss: 0.05652313460416435
ROC train: 0.992830	val: 0.806399	test: 0.806099
PRC train: 0.888502	val: 0.414349	test: 0.406161

Epoch: 150
Loss: 0.05368852326162183
ROC train: 0.992481	val: 0.801721	test: 0.805059
PRC train: 0.868800	val: 0.411146	test: 0.382836

Epoch: 151
Loss: 0.05488532903414864
ROC train: 0.992290	val: 0.795135	test: 0.809149
PRC train: 0.868443	val: 0.400607	test: 0.380386

Epoch: 152
Loss: 0.055562211129398145
ROC train: 0.991750	val: 0.795659	test: 0.811888
PRC train: 0.877139	val: 0.400863	test: 0.415665

Epoch: 153
Loss: 0.05578177481223886
ROC train: 0.993408	val: 0.802421	test: 0.804581
PRC train: 0.883121	val: 0.419650	test: 0.392633

Epoch: 154
Loss: 0.0565557567663605
ROC train: 0.993520	val: 0.802672	test: 0.809209
PRC train: 0.884985	val: 0.379839	test: 0.372901

Early stopping
Best (ROC):	 train: 0.986501	val: 0.813141	test: 0.809711
Best (PRC):	 train: 0.824403	val: 0.402157	test: 0.411020
All runs completed.
