>>> Starting run for dataset: bace
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running SCAFF configs_split_experiments/GraphCL/bace/scaff/train_prop=0.6.yml on cuda:0
Running SCAFF configs_split_experiments/GraphCL/bace/scaff/train_prop=0.7.yml on cuda:1
Running SCAFF configs_split_experiments/GraphCL/bace/scaff/train_prop=0.8.yml on cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.7.yml --runseed 4 --device cuda:1
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.7.yml --runseed 5 --device cuda:1
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.7.yml --runseed 6 --device cuda:1
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.6.yml --runseed 4 --device cuda:0
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.6.yml --runseed 5 --device cuda:0
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.6.yml --runseed 6 --device cuda:0
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.8.yml --runseed 4 --device cuda:2
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.8.yml --runseed 5 --device cuda:2
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.8.yml --runseed 6 --device cuda:2
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/scaff/train_prop=0.6/bace_scaff_5_26-05_10-20-35  ]
[ Using Seed :  5  ]
[ Using device :  cuda:0  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
split via scaffold
Data(edge_attr=[66, 2], edge_index=[2, 66], id=[1], x=[31, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.696447196005777
ROC train: 0.690335	val: 0.551962	test: 0.630795
PRC train: 0.660117	val: 0.154203	test: 0.779608

Epoch: 2
Loss: 0.6602341746811206
ROC train: 0.779150	val: 0.571387	test: 0.649547
PRC train: 0.728341	val: 0.168709	test: 0.810456

Epoch: 3
Loss: 0.6221620567798583
ROC train: 0.804439	val: 0.635781	test: 0.663559
PRC train: 0.755098	val: 0.214255	test: 0.816680

Epoch: 4
Loss: 0.5843084895805241
ROC train: 0.821032	val: 0.645591	test: 0.678240
PRC train: 0.786500	val: 0.208289	test: 0.829534

Epoch: 5
Loss: 0.5653222035074941
ROC train: 0.833207	val: 0.692308	test: 0.693849
PRC train: 0.802981	val: 0.227541	test: 0.836132

Epoch: 6
Loss: 0.5397571944213906
ROC train: 0.846569	val: 0.735820	test: 0.706213
PRC train: 0.820152	val: 0.262453	test: 0.840033

Epoch: 7
Loss: 0.5152030289142905
ROC train: 0.862992	val: 0.742327	test: 0.701061
PRC train: 0.837389	val: 0.328321	test: 0.839523

Epoch: 8
Loss: 0.4814048962022725
ROC train: 0.873415	val: 0.757576	test: 0.701885
PRC train: 0.847344	val: 0.325157	test: 0.840401

Epoch: 9
Loss: 0.4557074709052482
ROC train: 0.882213	val: 0.831294	test: 0.714610
PRC train: 0.859530	val: 0.380768	test: 0.850315

Epoch: 10
Loss: 0.46556015943332535
ROC train: 0.887127	val: 0.852564	test: 0.716979
PRC train: 0.866642	val: 0.413305	test: 0.854432

Epoch: 11
Loss: 0.44070117974152906
ROC train: 0.895833	val: 0.848970	test: 0.727231
PRC train: 0.876142	val: 0.415468	test: 0.860575

Epoch: 12
Loss: 0.44305358939771966
ROC train: 0.900178	val: 0.838481	test: 0.708737
PRC train: 0.879007	val: 0.412804	test: 0.843657

Epoch: 13
Loss: 0.4348453440252521
ROC train: 0.905326	val: 0.831391	test: 0.735370
PRC train: 0.883969	val: 0.402448	test: 0.852797

Epoch: 14
Loss: 0.43946447228392216
ROC train: 0.910655	val: 0.832556	test: 0.749948
PRC train: 0.891341	val: 0.392133	test: 0.860252

Epoch: 15
Loss: 0.42830206178177743
ROC train: 0.910436	val: 0.833819	test: 0.742582
PRC train: 0.894410	val: 0.388714	test: 0.859210

Epoch: 16
Loss: 0.412456344136997
ROC train: 0.910587	val: 0.846057	test: 0.738718
PRC train: 0.896966	val: 0.403729	test: 0.854425

Epoch: 17
Loss: 0.39925225643999585
ROC train: 0.915915	val: 0.845474	test: 0.750979
PRC train: 0.902862	val: 0.402097	test: 0.862599

Epoch: 18
Loss: 0.3974874664705273
ROC train: 0.916679	val: 0.849845	test: 0.750567
PRC train: 0.904176	val: 0.408620	test: 0.861379

Epoch: 19
Loss: 0.3917770660904572
ROC train: 0.918898	val: 0.871795	test: 0.749433
PRC train: 0.906462	val: 0.436854	test: 0.857715

Epoch: 20
Loss: 0.39709223066150684
ROC train: 0.919384	val: 0.869949	test: 0.739233
PRC train: 0.908589	val: 0.431487	test: 0.853993

Epoch: 21
Loss: 0.4044999318854322
ROC train: 0.919662	val: 0.861500	test: 0.736194
PRC train: 0.909358	val: 0.421920	test: 0.854201

Epoch: 22
Loss: 0.39778937645603946
ROC train: 0.922285	val: 0.855381	test: 0.744746
PRC train: 0.911372	val: 0.421281	test: 0.861874

Epoch: 23
Loss: 0.3835730033572015
ROC train: 0.925014	val: 0.862082	test: 0.742633
PRC train: 0.916810	val: 0.431321	test: 0.859476

Epoch: 24
Loss: 0.3877802184105984
ROC train: 0.928391	val: 0.856643	test: 0.750824
PRC train: 0.920598	val: 0.422287	test: 0.859721

Epoch: 25
Loss: 0.3774080941500009
ROC train: 0.929822	val: 0.861694	test: 0.750515
PRC train: 0.922984	val: 0.425173	test: 0.858312

Epoch: 26
Loss: 0.3895388442222747
ROC train: 0.931433	val: 0.860237	test: 0.743200
PRC train: 0.924444	val: 0.427532	test: 0.854696

Epoch: 27
Loss: 0.3851677771688405
ROC train: 0.931768	val: 0.864899	test: 0.734958
PRC train: 0.923834	val: 0.438695	test: 0.849756

Epoch: 28
Loss: 0.3712843067761087
ROC train: 0.933277	val: 0.872086	test: 0.735730
PRC train: 0.925526	val: 0.440250	test: 0.850538

Epoch: 29
Loss: 0.3582593735350158
ROC train: 0.936464	val: 0.863151	test: 0.742376
PRC train: 0.928312	val: 0.428164	test: 0.854139

Epoch: 30
Loss: 0.3611820808194127
ROC train: 0.938459	val: 0.848776	test: 0.753400
PRC train: 0.931710	val: 0.408226	test: 0.855883

Epoch: 31
Loss: 0.3729869936197808
ROC train: 0.938411	val: 0.857615	test: 0.746445
PRC train: 0.932128	val: 0.418365	test: 0.853734

Epoch: 32
Loss: 0.35314695528395657
ROC train: 0.939501	val: 0.850622	test: 0.739955
PRC train: 0.934431	val: 0.413608	test: 0.852374

Epoch: 33
Loss: 0.35294381845799006
ROC train: 0.937705	val: 0.852467	test: 0.729858Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/scaff/train_prop=0.6/bace_scaff_6_26-05_10-20-35  ]
[ Using Seed :  6  ]
[ Using device :  cuda:0  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
split via scaffold
Data(edge_attr=[66, 2], edge_index=[2, 66], id=[1], x=[31, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6892615182942251
ROC train: 0.708987	val: 0.533314	test: 0.634247
PRC train: 0.654748	val: 0.134052	test: 0.747471

Epoch: 2
Loss: 0.6532452769008548
ROC train: 0.736217	val: 0.605963	test: 0.650783
PRC train: 0.682531	val: 0.155604	test: 0.773139

Epoch: 3
Loss: 0.6090351670588511
ROC train: 0.774649	val: 0.649767	test: 0.660210
PRC train: 0.724067	val: 0.170434	test: 0.791608

Epoch: 4
Loss: 0.5804915060708007
ROC train: 0.817713	val: 0.677059	test: 0.710025
PRC train: 0.775604	val: 0.195852	test: 0.826165

Epoch: 5
Loss: 0.5516463183193493
ROC train: 0.836131	val: 0.692599	test: 0.719040
PRC train: 0.796979	val: 0.207673	test: 0.824867

Epoch: 6
Loss: 0.5508644205991864
ROC train: 0.850311	val: 0.697164	test: 0.731094
PRC train: 0.818326	val: 0.204698	test: 0.836142

Epoch: 7
Loss: 0.5008207218761653
ROC train: 0.865250	val: 0.727370	test: 0.725170
PRC train: 0.834592	val: 0.219316	test: 0.842000

Epoch: 8
Loss: 0.4927829287948564
ROC train: 0.873863	val: 0.768260	test: 0.714558
PRC train: 0.844039	val: 0.257396	test: 0.834587

Epoch: 9
Loss: 0.4788037683827879
ROC train: 0.877171	val: 0.793318	test: 0.711519
PRC train: 0.847409	val: 0.290717	test: 0.835498

Epoch: 10
Loss: 0.4563366879594495
ROC train: 0.884485	val: 0.801088	test: 0.735421
PRC train: 0.855853	val: 0.317792	test: 0.848334

Epoch: 11
Loss: 0.4526106990788762
ROC train: 0.890607	val: 0.802933	test: 0.736812
PRC train: 0.861805	val: 0.312235	test: 0.848463

Epoch: 12
Loss: 0.4385880858614942
ROC train: 0.894568	val: 0.793512	test: 0.753555
PRC train: 0.870640	val: 0.319878	test: 0.859882

Epoch: 13
Loss: 0.4486935442519159
ROC train: 0.899662	val: 0.802933	test: 0.755873
PRC train: 0.876046	val: 0.337471	test: 0.864058

Epoch: 14
Loss: 0.4525613532433316
ROC train: 0.900538	val: 0.794289	test: 0.737894
PRC train: 0.877060	val: 0.337245	test: 0.857405

Epoch: 15
Loss: 0.4382269300364996
ROC train: 0.905151	val: 0.808372	test: 0.736864
PRC train: 0.884169	val: 0.357924	test: 0.857174

Epoch: 16
Loss: 0.4237171188409833
ROC train: 0.908285	val: 0.797786	test: 0.737688
PRC train: 0.889859	val: 0.340256	test: 0.854313

Epoch: 17
Loss: 0.4049359205478392
ROC train: 0.910961	val: 0.793609	test: 0.727231
PRC train: 0.889151	val: 0.347882	test: 0.851196

Epoch: 18
Loss: 0.4067704407130035
ROC train: 0.910368	val: 0.814103	test: 0.720122
PRC train: 0.889537	val: 0.368936	test: 0.848267

Epoch: 19
Loss: 0.42385706032541315
ROC train: 0.910509	val: 0.822455	test: 0.724552
PRC train: 0.890140	val: 0.375514	test: 0.855175

Epoch: 20
Loss: 0.3867784624807923
ROC train: 0.914241	val: 0.843046	test: 0.747527
PRC train: 0.901177	val: 0.393831	test: 0.868435

Epoch: 21
Loss: 0.3969942982694777
ROC train: 0.916372	val: 0.829157	test: 0.755976
PRC train: 0.903861	val: 0.384225	test: 0.866327

Epoch: 22
Loss: 0.4200438360224182
ROC train: 0.919813	val: 0.833333	test: 0.753400
PRC train: 0.906548	val: 0.384861	test: 0.864638

Epoch: 23
Loss: 0.4017000718810655
ROC train: 0.919749	val: 0.850330	test: 0.735112
PRC train: 0.906879	val: 0.402993	test: 0.858742

Epoch: 24
Loss: 0.40734822883151595
ROC train: 0.922980	val: 0.848970	test: 0.729343
PRC train: 0.911204	val: 0.417080	test: 0.857468

Epoch: 25
Loss: 0.3818642176702836
ROC train: 0.925919	val: 0.838384	test: 0.734340
PRC train: 0.914485	val: 0.413485	test: 0.857926

Epoch: 26
Loss: 0.3941597911891759
ROC train: 0.928542	val: 0.839841	test: 0.737791
PRC train: 0.919740	val: 0.419783	test: 0.858976

Epoch: 27
Loss: 0.38667036999308935
ROC train: 0.927793	val: 0.862762	test: 0.733721
PRC train: 0.919119	val: 0.432994	test: 0.857850

Epoch: 28
Loss: 0.38153997240175286
ROC train: 0.931798	val: 0.850039	test: 0.743200
PRC train: 0.922189	val: 0.433601	test: 0.861122

Epoch: 29
Loss: 0.36973663154434055
ROC train: 0.932508	val: 0.829060	test: 0.740573
PRC train: 0.923091	val: 0.424157	test: 0.860102

Epoch: 30
Loss: 0.38056450574108297
ROC train: 0.934357	val: 0.841200	test: 0.746858
PRC train: 0.924043	val: 0.416301	test: 0.863999

Epoch: 31
Loss: 0.37922675382370863
ROC train: 0.930995	val: 0.857226	test: 0.731043
PRC train: 0.920577	val: 0.427712	test: 0.857735

Epoch: 32
Loss: 0.36280189039390137
ROC train: 0.931136	val: 0.863054	test: 0.727385
PRC train: 0.920772	val: 0.445621	test: 0.856779

Epoch: 33
Loss: 0.3510943511049486
ROC train: 0.936484	val: 0.862082	test: 0.724964Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/scaff/train_prop=0.6/bace_scaff_4_26-05_10-20-35  ]
[ Using Seed :  4  ]
[ Using device :  cuda:0  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
split via scaffold
Data(edge_attr=[66, 2], edge_index=[2, 66], id=[1], x=[31, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6883386780645218
ROC train: 0.716928	val: 0.595280	test: 0.625798
PRC train: 0.656132	val: 0.158704	test: 0.741909

Epoch: 2
Loss: 0.6551152932177916
ROC train: 0.770849	val: 0.574689	test: 0.660056
PRC train: 0.702279	val: 0.167836	test: 0.787655

Epoch: 3
Loss: 0.6184761732834415
ROC train: 0.808838	val: 0.665404	test: 0.693643
PRC train: 0.744280	val: 0.189118	test: 0.811264

Epoch: 4
Loss: 0.5674152690201839
ROC train: 0.830307	val: 0.696775	test: 0.728776
PRC train: 0.770173	val: 0.204300	test: 0.834662

Epoch: 5
Loss: 0.5344494860283642
ROC train: 0.842885	val: 0.714161	test: 0.744539
PRC train: 0.782459	val: 0.214079	test: 0.845548

Epoch: 6
Loss: 0.5091653642249071
ROC train: 0.852749	val: 0.713384	test: 0.728828
PRC train: 0.793068	val: 0.244464	test: 0.831449

Epoch: 7
Loss: 0.47328024059219326
ROC train: 0.865133	val: 0.726496	test: 0.714610
PRC train: 0.809954	val: 0.272430	test: 0.819138

Epoch: 8
Loss: 0.5024991667508404
ROC train: 0.878013	val: 0.770008	test: 0.747270
PRC train: 0.835338	val: 0.324301	test: 0.848602

Epoch: 9
Loss: 0.4801455353055807
ROC train: 0.886451	val: 0.792735	test: 0.752730
PRC train: 0.851141	val: 0.338831	test: 0.856188

Epoch: 10
Loss: 0.45491421617074856
ROC train: 0.889789	val: 0.813714	test: 0.746033
PRC train: 0.857021	val: 0.358000	test: 0.858663

Epoch: 11
Loss: 0.4560810985610906
ROC train: 0.893633	val: 0.830808	test: 0.744024
PRC train: 0.865385	val: 0.387181	test: 0.865128

Epoch: 12
Loss: 0.4303321199187389
ROC train: 0.896465	val: 0.849359	test: 0.756285
PRC train: 0.871173	val: 0.417133	test: 0.874141

Epoch: 13
Loss: 0.4321641734105591
ROC train: 0.899161	val: 0.851496	test: 0.763085
PRC train: 0.874463	val: 0.439167	test: 0.876325

Epoch: 14
Loss: 0.4377120420306502
ROC train: 0.900913	val: 0.834887	test: 0.749279
PRC train: 0.877948	val: 0.437286	test: 0.869166

Epoch: 15
Loss: 0.4346507746308421
ROC train: 0.900801	val: 0.823912	test: 0.740933
PRC train: 0.879195	val: 0.440764	test: 0.865277

Epoch: 16
Loss: 0.4208845687410737
ROC train: 0.905497	val: 0.831099	test: 0.747527
PRC train: 0.886291	val: 0.444344	test: 0.869229

Epoch: 17
Loss: 0.42561995778257694
ROC train: 0.910844	val: 0.854021	test: 0.762930
PRC train: 0.892253	val: 0.459014	test: 0.877804

Epoch: 18
Loss: 0.411313037334039
ROC train: 0.914825	val: 0.871018	test: 0.757264
PRC train: 0.897670	val: 0.472726	test: 0.873976

Epoch: 19
Loss: 0.40174811324661985
ROC train: 0.919696	val: 0.871795	test: 0.756027
PRC train: 0.903787	val: 0.477539	test: 0.872840

Epoch: 20
Loss: 0.40486844828633417
ROC train: 0.922849	val: 0.859946	test: 0.767927
PRC train: 0.907674	val: 0.465538	test: 0.878169

Epoch: 21
Loss: 0.39528405867623356
ROC train: 0.925165	val: 0.864219	test: 0.759839
PRC train: 0.910484	val: 0.462529	test: 0.873979

Epoch: 22
Loss: 0.4008935576575213
ROC train: 0.923233	val: 0.857129	test: 0.740470
PRC train: 0.909453	val: 0.454102	test: 0.862559

Epoch: 23
Loss: 0.4012222662717533
ROC train: 0.925550	val: 0.854701	test: 0.740676
PRC train: 0.912262	val: 0.446386	test: 0.861672

Epoch: 24
Loss: 0.3844327241158919
ROC train: 0.929438	val: 0.848873	test: 0.741500
PRC train: 0.916974	val: 0.434647	test: 0.863242

Epoch: 25
Loss: 0.38491307622153703
ROC train: 0.933442	val: 0.845960	test: 0.751855
PRC train: 0.921542	val: 0.433829	test: 0.869817

Epoch: 26
Loss: 0.37438999617079427
ROC train: 0.934138	val: 0.854409	test: 0.757779
PRC train: 0.922979	val: 0.422672	test: 0.873077

Epoch: 27
Loss: 0.371700770186922
ROC train: 0.935243	val: 0.854992	test: 0.749948
PRC train: 0.924656	val: 0.421222	test: 0.868716

Epoch: 28
Loss: 0.3715322391807427
ROC train: 0.936352	val: 0.842172	test: 0.742015
PRC train: 0.925634	val: 0.413060	test: 0.866178

Epoch: 29
Loss: 0.37022283500829034
ROC train: 0.932892	val: 0.835276	test: 0.734340
PRC train: 0.922761	val: 0.388287	test: 0.861393

Epoch: 30
Loss: 0.37590287575215964
ROC train: 0.937252	val: 0.854409	test: 0.733361
PRC train: 0.927769	val: 0.416644	test: 0.861127

Epoch: 31
Loss: 0.37011085870817306
ROC train: 0.938542	val: 0.850913	test: 0.744333
PRC train: 0.929822	val: 0.416879	test: 0.867555

Epoch: 32
Loss: 0.37589285907719816
ROC train: 0.939720	val: 0.843629	test: 0.751855
PRC train: 0.931125	val: 0.408942	test: 0.870934

Epoch: 33
Loss: 0.3443158536307744
ROC train: 0.940883	val: 0.841977	test: 0.753709Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/scaff/train_prop=0.8/bace_scaff_5_26-05_10-20-35  ]
[ Using Seed :  5  ]
[ Using device :  cuda:2  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
split via scaffold
Data(edge_attr=[66, 2], edge_index=[2, 66], id=[1], x=[31, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6902852089663893
ROC train: 0.672489	val: 0.682784	test: 0.519040
PRC train: 0.562278	val: 0.925215	test: 0.531792

Epoch: 2
Loss: 0.6424834964216041
ROC train: 0.755049	val: 0.712821	test: 0.588246
PRC train: 0.641850	val: 0.931363	test: 0.585296

Epoch: 3
Loss: 0.5849132348030082
ROC train: 0.820126	val: 0.676557	test: 0.639193
PRC train: 0.722682	val: 0.930357	test: 0.623753

Epoch: 4
Loss: 0.5336219086845986
ROC train: 0.844683	val: 0.678388	test: 0.669797
PRC train: 0.748773	val: 0.928485	test: 0.657587

Epoch: 5
Loss: 0.5191366962560766
ROC train: 0.853964	val: 0.678022	test: 0.677447
PRC train: 0.770143	val: 0.925358	test: 0.673482

Epoch: 6
Loss: 0.4794849822873964
ROC train: 0.867774	val: 0.676557	test: 0.700226
PRC train: 0.797093	val: 0.930078	test: 0.691991

Epoch: 7
Loss: 0.4678527107747509
ROC train: 0.883011	val: 0.666300	test: 0.733090
PRC train: 0.813797	val: 0.933311	test: 0.727011

Epoch: 8
Loss: 0.46078362395130956
ROC train: 0.890334	val: 0.675824	test: 0.744914
PRC train: 0.821608	val: 0.936184	test: 0.745290

Epoch: 9
Loss: 0.4310657511025113
ROC train: 0.892497	val: 0.693407	test: 0.741436
PRC train: 0.825512	val: 0.938801	test: 0.756934

Epoch: 10
Loss: 0.43807411991955447
ROC train: 0.898893	val: 0.687912	test: 0.755695
PRC train: 0.832163	val: 0.938865	test: 0.765549

Epoch: 11
Loss: 0.43399207008325796
ROC train: 0.901550	val: 0.678755	test: 0.758825
PRC train: 0.838038	val: 0.937361	test: 0.780350

Epoch: 12
Loss: 0.4226046119661809
ROC train: 0.905397	val: 0.694505	test: 0.752913
PRC train: 0.844471	val: 0.940036	test: 0.771847

Epoch: 13
Loss: 0.41497593087641105
ROC train: 0.908291	val: 0.686813	test: 0.761085
PRC train: 0.850401	val: 0.937845	test: 0.774899

Epoch: 14
Loss: 0.3942786436435769
ROC train: 0.912785	val: 0.687912	test: 0.768214
PRC train: 0.852379	val: 0.938601	test: 0.775633

Epoch: 15
Loss: 0.40393494423892734
ROC train: 0.916196	val: 0.669597	test: 0.776561
PRC train: 0.859203	val: 0.934311	test: 0.786331

Epoch: 16
Loss: 0.3918579212954679
ROC train: 0.917534	val: 0.673993	test: 0.779690
PRC train: 0.862026	val: 0.934551	test: 0.785183

Epoch: 17
Loss: 0.3692360080110577
ROC train: 0.917215	val: 0.686447	test: 0.766475
PRC train: 0.862275	val: 0.935319	test: 0.775991

Epoch: 18
Loss: 0.3962244759058172
ROC train: 0.919304	val: 0.676557	test: 0.760042
PRC train: 0.867807	val: 0.933768	test: 0.770159

Epoch: 19
Loss: 0.3678446559732999
ROC train: 0.922483	val: 0.660806	test: 0.775865
PRC train: 0.874326	val: 0.928901	test: 0.781872

Epoch: 20
Loss: 0.3932030523621238
ROC train: 0.925205	val: 0.652015	test: 0.769605
PRC train: 0.878666	val: 0.927002	test: 0.779320

Epoch: 21
Loss: 0.3835067081505403
ROC train: 0.925999	val: 0.665201	test: 0.775343
PRC train: 0.881870	val: 0.929498	test: 0.786062

Epoch: 22
Loss: 0.36171144135468253
ROC train: 0.927805	val: 0.668132	test: 0.777082
PRC train: 0.883968	val: 0.930607	test: 0.790879

Epoch: 23
Loss: 0.3758164157608027
ROC train: 0.931170	val: 0.676557	test: 0.786298
PRC train: 0.887332	val: 0.932985	test: 0.798690

Epoch: 24
Loss: 0.3688026610055344
ROC train: 0.932934	val: 0.662637	test: 0.782473
PRC train: 0.888897	val: 0.927409	test: 0.781507

Epoch: 25
Loss: 0.35815935162910206
ROC train: 0.932566	val: 0.683150	test: 0.764389
PRC train: 0.888729	val: 0.932335	test: 0.771040

Epoch: 26
Loss: 0.3600341645464776
ROC train: 0.933496	val: 0.678755	test: 0.768040
PRC train: 0.892744	val: 0.929307	test: 0.771098

Epoch: 27
Loss: 0.36238720985552103
ROC train: 0.937808	val: 0.657509	test: 0.777082
PRC train: 0.900468	val: 0.920408	test: 0.769495

Epoch: 28
Loss: 0.36136387197865194
ROC train: 0.938650	val: 0.663004	test: 0.767866
PRC train: 0.902798	val: 0.920310	test: 0.760085

Epoch: 29
Loss: 0.3449770924679643
ROC train: 0.939757	val: 0.668132	test: 0.749087
PRC train: 0.904398	val: 0.921674	test: 0.736436

Epoch: 30
Loss: 0.3448673019260233
ROC train: 0.941724	val: 0.634066	test: 0.766823
PRC train: 0.906841	val: 0.913098	test: 0.758136

Epoch: 31
Loss: 0.33908363371690164
ROC train: 0.943236	val: 0.640659	test: 0.778647
PRC train: 0.908456	val: 0.913962	test: 0.763725

Epoch: 32
Loss: 0.34200711613514667
ROC train: 0.942466	val: 0.668864	test: 0.760389
PRC train: 0.906897	val: 0.921728	test: 0.739287

Epoch: 33
Loss: 0.33239790604131325
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/scaff/train_prop=0.7/bace_scaff_6_26-05_10-20-35  ]
[ Using Seed :  6  ]
[ Using device :  cuda:1  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
split via scaffold
Data(edge_attr=[66, 2], edge_index=[2, 66], id=[1], x=[31, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6777927608917249
ROC train: 0.674723	val: 0.515328	test: 0.680841
PRC train: 0.618640	val: 0.255037	test: 0.803426

Epoch: 2
Loss: 0.6327947253094044
ROC train: 0.780919	val: 0.569767	test: 0.730228
PRC train: 0.702776	val: 0.264920	test: 0.822038

Epoch: 3
Loss: 0.6085805008324949
ROC train: 0.803368	val: 0.650740	test: 0.785843
PRC train: 0.731205	val: 0.349193	test: 0.872550

Epoch: 4
Loss: 0.5610855613652537
ROC train: 0.846949	val: 0.655391	test: 0.745395
PRC train: 0.777236	val: 0.321959	test: 0.839514

Epoch: 5
Loss: 0.5496944539988631
ROC train: 0.850245	val: 0.627907	test: 0.721380
PRC train: 0.782840	val: 0.305164	test: 0.826151

Epoch: 6
Loss: 0.5065272411190733
ROC train: 0.858006	val: 0.615011	test: 0.722012
PRC train: 0.794575	val: 0.305478	test: 0.819090

Epoch: 7
Loss: 0.5057655679792269
ROC train: 0.877112	val: 0.641438	test: 0.768870
PRC train: 0.818500	val: 0.346951	test: 0.852195

Epoch: 8
Loss: 0.48542785074373507
ROC train: 0.881135	val: 0.647886	test: 0.802636
PRC train: 0.825976	val: 0.378422	test: 0.885854

Epoch: 9
Loss: 0.44371918720995857
ROC train: 0.882470	val: 0.673362	test: 0.765349
PRC train: 0.835315	val: 0.400342	test: 0.862228

Epoch: 10
Loss: 0.47442733641463625
ROC train: 0.889432	val: 0.665645	test: 0.778711
PRC train: 0.845627	val: 0.409891	test: 0.871283

Epoch: 11
Loss: 0.4801908801598844
ROC train: 0.893664	val: 0.653805	test: 0.788462
PRC train: 0.844063	val: 0.402056	test: 0.881825

Epoch: 12
Loss: 0.4399322732710222
ROC train: 0.893419	val: 0.663319	test: 0.796316
PRC train: 0.854583	val: 0.403860	test: 0.889544

Epoch: 13
Loss: 0.41751914411063923
ROC train: 0.900828	val: 0.670190	test: 0.799115
PRC train: 0.863387	val: 0.414166	test: 0.890650

Epoch: 14
Loss: 0.44544099223342276
ROC train: 0.902994	val: 0.676004	test: 0.783767
PRC train: 0.866941	val: 0.425152	test: 0.882381

Epoch: 15
Loss: 0.4576139467709351
ROC train: 0.899392	val: 0.675476	test: 0.820242
PRC train: 0.862387	val: 0.414462	test: 0.897425

Epoch: 16
Loss: 0.415953553406535
ROC train: 0.897614	val: 0.660254	test: 0.827465
PRC train: 0.864723	val: 0.373307	test: 0.905464

Epoch: 17
Loss: 0.3988576814144032
ROC train: 0.911636	val: 0.681290	test: 0.811123
PRC train: 0.876535	val: 0.404369	test: 0.895291

Epoch: 18
Loss: 0.40262243129208236
ROC train: 0.913507	val: 0.686258	test: 0.816631
PRC train: 0.879681	val: 0.413416	test: 0.898143

Epoch: 19
Loss: 0.44230135258285647
ROC train: 0.912608	val: 0.677484	test: 0.819971
PRC train: 0.879044	val: 0.407661	test: 0.902036

Epoch: 20
Loss: 0.4009490463103882
ROC train: 0.914763	val: 0.682770	test: 0.814915
PRC train: 0.881015	val: 0.416483	test: 0.897294

Epoch: 21
Loss: 0.41697435046026676
ROC train: 0.916875	val: 0.693552	test: 0.793698
PRC train: 0.884564	val: 0.436067	test: 0.885518

Epoch: 22
Loss: 0.38931368714917947
ROC train: 0.919660	val: 0.694820	test: 0.811123
PRC train: 0.888133	val: 0.429317	test: 0.895004

Epoch: 23
Loss: 0.3739059235385437
ROC train: 0.919229	val: 0.692178	test: 0.822319
PRC train: 0.889418	val: 0.412196	test: 0.901841

Epoch: 24
Loss: 0.37232852599514077
ROC train: 0.920527	val: 0.693658	test: 0.815367
PRC train: 0.890469	val: 0.419767	test: 0.897881

Epoch: 25
Loss: 0.37408295760049903
ROC train: 0.923287	val: 0.697674	test: 0.818346
PRC train: 0.894478	val: 0.414011	test: 0.899659

Epoch: 26
Loss: 0.40687779648780226
ROC train: 0.927166	val: 0.691755	test: 0.831166
PRC train: 0.900443	val: 0.397543	test: 0.906565

Epoch: 27
Loss: 0.41761349913746815
ROC train: 0.928379	val: 0.690803	test: 0.833153
PRC train: 0.904768	val: 0.397837	test: 0.906262

Epoch: 28
Loss: 0.3761785551498895
ROC train: 0.928443	val: 0.703488	test: 0.798664
PRC train: 0.904265	val: 0.410165	test: 0.889007

Epoch: 29
Loss: 0.37889831601182195
ROC train: 0.930045	val: 0.716279	test: 0.776183
PRC train: 0.907383	val: 0.423872	test: 0.875784

Epoch: 30
Loss: 0.39184299226239283
ROC train: 0.926241	val: 0.716702	test: 0.797941
PRC train: 0.900439	val: 0.422093	test: 0.886994

Epoch: 31
Loss: 0.39300049953638816
ROC train: 0.928886	val: 0.713742	test: 0.818075
PRC train: 0.902072	val: 0.412468	test: 0.898343

Epoch: 32
Loss: 0.4185580274722856
ROC train: 0.929980	val: 0.697992	test: 0.811213
PRC train: 0.904844	val: 0.394815	test: 0.896542

Epoch: 33
Loss: 0.3650240737181594Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/scaff/train_prop=0.7/bace_scaff_5_26-05_10-20-35  ]
[ Using Seed :  5  ]
[ Using device :  cuda:1  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
split via scaffold
Data(edge_attr=[66, 2], edge_index=[2, 66], id=[1], x=[31, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6943710580479705
ROC train: 0.716749	val: 0.654228	test: 0.658812
PRC train: 0.649037	val: 0.389163	test: 0.782660

Epoch: 2
Loss: 0.6520569689001122
ROC train: 0.793390	val: 0.688266	test: 0.710274
PRC train: 0.726385	val: 0.404541	test: 0.836907

Epoch: 3
Loss: 0.616591770989268
ROC train: 0.822420	val: 0.680338	test: 0.718942
PRC train: 0.753407	val: 0.404507	test: 0.846495

Epoch: 4
Loss: 0.5553849925469454
ROC train: 0.839047	val: 0.680867	test: 0.709642
PRC train: 0.769921	val: 0.394376	test: 0.839105

Epoch: 5
Loss: 0.5716268027642007
ROC train: 0.853105	val: 0.666490	test: 0.710365
PRC train: 0.789009	val: 0.379980	test: 0.828228

Epoch: 6
Loss: 0.5061895881179536
ROC train: 0.861478	val: 0.650740	test: 0.747472
PRC train: 0.814779	val: 0.375243	test: 0.850983

Epoch: 7
Loss: 0.46668636763765886
ROC train: 0.877465	val: 0.645666	test: 0.771668
PRC train: 0.840898	val: 0.398289	test: 0.879568

Epoch: 8
Loss: 0.4637390032370572
ROC train: 0.887442	val: 0.641543	test: 0.775460
PRC train: 0.853822	val: 0.400276	test: 0.886179

Epoch: 9
Loss: 0.47761867281933307
ROC train: 0.893099	val: 0.640275	test: 0.779884
PRC train: 0.860993	val: 0.403553	test: 0.886183

Epoch: 10
Loss: 0.4602145357127709
ROC train: 0.897524	val: 0.647040	test: 0.783315
PRC train: 0.867281	val: 0.410209	test: 0.887741

Epoch: 11
Loss: 0.4705961010717571
ROC train: 0.899547	val: 0.651163	test: 0.773384
PRC train: 0.872340	val: 0.383572	test: 0.878844

Epoch: 12
Loss: 0.40820191280986917
ROC train: 0.901360	val: 0.636047	test: 0.766883
PRC train: 0.876271	val: 0.371191	test: 0.871717

Epoch: 13
Loss: 0.4641488308674261
ROC train: 0.901443	val: 0.646934	test: 0.746479
PRC train: 0.875591	val: 0.388329	test: 0.859148

Epoch: 14
Loss: 0.4511224737991363
ROC train: 0.909154	val: 0.670507	test: 0.779252
PRC train: 0.883784	val: 0.385664	test: 0.880585

Epoch: 15
Loss: 0.4078382425192316
ROC train: 0.910838	val: 0.670190	test: 0.798483
PRC train: 0.886578	val: 0.371915	test: 0.893644

Epoch: 16
Loss: 0.44016246441214857
ROC train: 0.916782	val: 0.669239	test: 0.797309
PRC train: 0.892971	val: 0.379821	test: 0.891502

Epoch: 17
Loss: 0.39968073611836064
ROC train: 0.912399	val: 0.671776	test: 0.769953
PRC train: 0.889656	val: 0.400708	test: 0.875598

Epoch: 18
Loss: 0.39901635276164926
ROC train: 0.914875	val: 0.680973	test: 0.773384
PRC train: 0.890365	val: 0.405729	test: 0.874975

Epoch: 19
Loss: 0.42869051636606725
ROC train: 0.922931	val: 0.689958	test: 0.784399
PRC train: 0.899183	val: 0.408528	test: 0.879810

Epoch: 20
Loss: 0.3768447731610477
ROC train: 0.925640	val: 0.696617	test: 0.786114
PRC train: 0.902420	val: 0.403527	test: 0.879030

Epoch: 21
Loss: 0.3975595197653394
ROC train: 0.925201	val: 0.700000	test: 0.784399
PRC train: 0.901513	val: 0.406127	test: 0.878329

Epoch: 22
Loss: 0.44380432394244096
ROC train: 0.924280	val: 0.699260	test: 0.796768
PRC train: 0.901783	val: 0.410448	test: 0.889165

Epoch: 23
Loss: 0.4066002940982246
ROC train: 0.925511	val: 0.693975	test: 0.814373
PRC train: 0.902043	val: 0.397049	test: 0.900737

Epoch: 24
Loss: 0.3661972256511804
ROC train: 0.926058	val: 0.684038	test: 0.801101
PRC train: 0.903858	val: 0.391004	test: 0.892851

Epoch: 25
Loss: 0.3785978788838631
ROC train: 0.928206	val: 0.693446	test: 0.780878
PRC train: 0.905396	val: 0.399992	test: 0.881288

Epoch: 26
Loss: 0.37906062002284624
ROC train: 0.927216	val: 0.701163	test: 0.787830
PRC train: 0.901764	val: 0.425648	test: 0.884122

Epoch: 27
Loss: 0.3899379446159114
ROC train: 0.929440	val: 0.706448	test: 0.794059
PRC train: 0.905138	val: 0.419411	test: 0.884749

Epoch: 28
Loss: 0.3526326824261973
ROC train: 0.932851	val: 0.693763	test: 0.788371
PRC train: 0.910674	val: 0.402522	test: 0.882595

Epoch: 29
Loss: 0.357988726510177
ROC train: 0.935194	val: 0.683087	test: 0.786295
PRC train: 0.916103	val: 0.395803	test: 0.883102

Epoch: 30
Loss: 0.34593238456010494
ROC train: 0.935435	val: 0.690909	test: 0.793879
PRC train: 0.915989	val: 0.404283	test: 0.887794

Epoch: 31
Loss: 0.34525750556757445
ROC train: 0.937284	val: 0.699471	test: 0.801192
PRC train: 0.918738	val: 0.399153	test: 0.889131

Epoch: 32
Loss: 0.34663152700614025
ROC train: 0.936953	val: 0.703805	test: 0.805977
PRC train: 0.918758	val: 0.396514	test: 0.892068

Epoch: 33
Loss: 0.37399310768455607
ROC train: 0.936169	val: 0.710782	test: 0.787830Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/scaff/train_prop=0.7/bace_scaff_4_26-05_10-20-35  ]
[ Using Seed :  4  ]
[ Using device :  cuda:1  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
split via scaffold
Data(edge_attr=[66, 2], edge_index=[2, 66], id=[1], x=[31, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6863451177294937
ROC train: 0.705149	val: 0.524736	test: 0.615114
PRC train: 0.639806	val: 0.295676	test: 0.722094

Epoch: 2
Loss: 0.6442883945427067
ROC train: 0.747506	val: 0.517759	test: 0.649061
PRC train: 0.670879	val: 0.250300	test: 0.769475

Epoch: 3
Loss: 0.6133764026534648
ROC train: 0.834661	val: 0.641015	test: 0.728151
PRC train: 0.757918	val: 0.309412	test: 0.825008

Epoch: 4
Loss: 0.5642237201131624
ROC train: 0.839785	val: 0.644820	test: 0.723366
PRC train: 0.760833	val: 0.313374	test: 0.822035

Epoch: 5
Loss: 0.5409530812800163
ROC train: 0.854721	val: 0.648943	test: 0.748375
PRC train: 0.779497	val: 0.318425	test: 0.838912

Epoch: 6
Loss: 0.5192730316181539
ROC train: 0.866343	val: 0.652008	test: 0.763182
PRC train: 0.796627	val: 0.329127	test: 0.857963

Epoch: 7
Loss: 0.4933869919353476
ROC train: 0.867109	val: 0.641755	test: 0.780246
PRC train: 0.794599	val: 0.317450	test: 0.862854

Epoch: 8
Loss: 0.47636225824711975
ROC train: 0.873197	val: 0.651163	test: 0.806157
PRC train: 0.807123	val: 0.333745	test: 0.883735

Epoch: 9
Loss: 0.48632775098644065
ROC train: 0.888061	val: 0.681501	test: 0.789545
PRC train: 0.832395	val: 0.387562	test: 0.879935

Epoch: 10
Loss: 0.42578410429601216
ROC train: 0.890213	val: 0.695560	test: 0.773745
PRC train: 0.842135	val: 0.436425	test: 0.872100

Epoch: 11
Loss: 0.46031037995046303
ROC train: 0.892573	val: 0.704545	test: 0.776363
PRC train: 0.850631	val: 0.444567	test: 0.877498

Epoch: 12
Loss: 0.4444516562071478
ROC train: 0.898395	val: 0.691438	test: 0.806970
PRC train: 0.863410	val: 0.427020	test: 0.897235

Epoch: 13
Loss: 0.4112411551046794
ROC train: 0.894236	val: 0.676216	test: 0.800831
PRC train: 0.858685	val: 0.378557	test: 0.889677

Epoch: 14
Loss: 0.43159129879170194
ROC train: 0.901954	val: 0.681818	test: 0.781961
PRC train: 0.865930	val: 0.404719	test: 0.879250

Epoch: 15
Loss: 0.4515136377760142
ROC train: 0.910032	val: 0.700423	test: 0.787378
PRC train: 0.878131	val: 0.417411	test: 0.884731

Epoch: 16
Loss: 0.4144142212566678
ROC train: 0.906696	val: 0.697780	test: 0.819881
PRC train: 0.874523	val: 0.419933	test: 0.901825

Epoch: 17
Loss: 0.3976540622640901
ROC train: 0.911108	val: 0.692706	test: 0.817172
PRC train: 0.881449	val: 0.420307	test: 0.901195

Epoch: 18
Loss: 0.3907365977837597
ROC train: 0.916415	val: 0.684144	test: 0.779433
PRC train: 0.886164	val: 0.427039	test: 0.880562

Epoch: 19
Loss: 0.4089276122177722
ROC train: 0.915181	val: 0.697674	test: 0.780787
PRC train: 0.884218	val: 0.440384	test: 0.882620

Epoch: 20
Loss: 0.38874829789927545
ROC train: 0.916005	val: 0.705708	test: 0.812658
PRC train: 0.885819	val: 0.450339	test: 0.901405

Epoch: 21
Loss: 0.3986243966267248
ROC train: 0.919441	val: 0.707822	test: 0.805525
PRC train: 0.890697	val: 0.455069	test: 0.896757

Epoch: 22
Loss: 0.3778797876696608
ROC train: 0.919462	val: 0.717019	test: 0.789635
PRC train: 0.890794	val: 0.444826	test: 0.887469

Epoch: 23
Loss: 0.36730355877614546
ROC train: 0.922273	val: 0.708668	test: 0.773384
PRC train: 0.894917	val: 0.431502	test: 0.878718

Epoch: 24
Loss: 0.37866127751879636
ROC train: 0.927904	val: 0.710465	test: 0.781780
PRC train: 0.902339	val: 0.425652	test: 0.882937

Epoch: 25
Loss: 0.3851843074139693
ROC train: 0.930343	val: 0.697886	test: 0.797129
PRC train: 0.905494	val: 0.412620	test: 0.889738

Epoch: 26
Loss: 0.3909127870543463
ROC train: 0.932434	val: 0.699154	test: 0.784489
PRC train: 0.907995	val: 0.418835	test: 0.881755

Epoch: 27
Loss: 0.365376518692567
ROC train: 0.932607	val: 0.706342	test: 0.779884
PRC train: 0.909223	val: 0.422809	test: 0.879023

Epoch: 28
Loss: 0.3484963124835371
ROC train: 0.934272	val: 0.733192	test: 0.785211
PRC train: 0.910551	val: 0.433689	test: 0.880748

Epoch: 29
Loss: 0.3512829563653209
ROC train: 0.933452	val: 0.732241	test: 0.772481
PRC train: 0.909574	val: 0.435400	test: 0.874710

Epoch: 30
Loss: 0.3526625304724867
ROC train: 0.933297	val: 0.717970	test: 0.779162
PRC train: 0.912349	val: 0.410599	test: 0.882262

Epoch: 31
Loss: 0.3988716472581763
ROC train: 0.935255	val: 0.710994	test: 0.784760
PRC train: 0.916170	val: 0.401006	test: 0.885680

Epoch: 32
Loss: 0.41896597991763385
ROC train: 0.929501	val: 0.705603	test: 0.788913
PRC train: 0.907086	val: 0.393277	test: 0.886027

Epoch: 33
Loss: 0.353927259084341
ROC train: 0.928595	val: 0.719450	test: 0.791983Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/scaff/train_prop=0.8/bace_scaff_4_26-05_10-20-35  ]
[ Using Seed :  4  ]
[ Using device :  cuda:2  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
split via scaffold
Data(edge_attr=[66, 2], edge_index=[2, 66], id=[1], x=[31, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6808841723163771
ROC train: 0.700945	val: 0.602930	test: 0.633455
PRC train: 0.600619	val: 0.895016	test: 0.583957

Epoch: 2
Loss: 0.6264719397289398
ROC train: 0.795733	val: 0.678022	test: 0.669970
PRC train: 0.693797	val: 0.925926	test: 0.619404

Epoch: 3
Loss: 0.5704448929066253
ROC train: 0.823639	val: 0.682051	test: 0.691010
PRC train: 0.721614	val: 0.929386	test: 0.660969

Epoch: 4
Loss: 0.525535037824754
ROC train: 0.854053	val: 0.667399	test: 0.709790
PRC train: 0.747218	val: 0.919799	test: 0.696236

Epoch: 5
Loss: 0.4931146906501641
ROC train: 0.863884	val: 0.667766	test: 0.724570
PRC train: 0.755251	val: 0.919786	test: 0.701640

Epoch: 6
Loss: 0.47908129606332067
ROC train: 0.875614	val: 0.668864	test: 0.742827
PRC train: 0.772815	val: 0.924044	test: 0.722223

Epoch: 7
Loss: 0.46097182443792306
ROC train: 0.886142	val: 0.663370	test: 0.729960
PRC train: 0.791666	val: 0.927120	test: 0.720761

Epoch: 8
Loss: 0.4320536349981012
ROC train: 0.895297	val: 0.689011	test: 0.720570
PRC train: 0.806417	val: 0.938049	test: 0.725577

Epoch: 9
Loss: 0.4276166920621381
ROC train: 0.901624	val: 0.703663	test: 0.720570
PRC train: 0.827475	val: 0.943444	test: 0.735369

Epoch: 10
Loss: 0.41848522813839206
ROC train: 0.908159	val: 0.693407	test: 0.723005
PRC train: 0.842822	val: 0.941791	test: 0.733825

Epoch: 11
Loss: 0.4152373902780182
ROC train: 0.909706	val: 0.652015	test: 0.731699
PRC train: 0.851776	val: 0.933841	test: 0.738205

Epoch: 12
Loss: 0.4121261499520246
ROC train: 0.910853	val: 0.680586	test: 0.723005
PRC train: 0.848379	val: 0.938524	test: 0.728756

Epoch: 13
Loss: 0.4080415335618198
ROC train: 0.916561	val: 0.700366	test: 0.720744
PRC train: 0.859691	val: 0.943153	test: 0.728269

Epoch: 14
Loss: 0.40272427889916973
ROC train: 0.916601	val: 0.696337	test: 0.735872
PRC train: 0.859987	val: 0.942896	test: 0.736533

Epoch: 15
Loss: 0.38363632136547243
ROC train: 0.918887	val: 0.692308	test: 0.727178
PRC train: 0.867692	val: 0.942670	test: 0.716467

Epoch: 16
Loss: 0.3990402970662929
ROC train: 0.922266	val: 0.691209	test: 0.735350
PRC train: 0.873605	val: 0.942079	test: 0.725081

Epoch: 17
Loss: 0.38674369877957393
ROC train: 0.925468	val: 0.679853	test: 0.727178
PRC train: 0.876033	val: 0.939997	test: 0.714430

Epoch: 18
Loss: 0.3817196432053666
ROC train: 0.923978	val: 0.696703	test: 0.707529
PRC train: 0.870900	val: 0.943856	test: 0.698569

Epoch: 19
Loss: 0.3842535362450888
ROC train: 0.927862	val: 0.704762	test: 0.718310
PRC train: 0.878023	val: 0.945240	test: 0.703025

Epoch: 20
Loss: 0.36466439393926564
ROC train: 0.927354	val: 0.709158	test: 0.732742
PRC train: 0.882576	val: 0.942881	test: 0.716401

Epoch: 21
Loss: 0.35133913296668196
ROC train: 0.930451	val: 0.716117	test: 0.716571
PRC train: 0.886867	val: 0.943906	test: 0.702718

Epoch: 22
Loss: 0.3627977042275149
ROC train: 0.935402	val: 0.689744	test: 0.715354
PRC train: 0.893714	val: 0.938650	test: 0.709345

Epoch: 23
Loss: 0.34889885781858093
ROC train: 0.938114	val: 0.662637	test: 0.713963
PRC train: 0.898725	val: 0.931326	test: 0.714449

Epoch: 24
Loss: 0.3652073420773321
ROC train: 0.938516	val: 0.680952	test: 0.699878
PRC train: 0.900304	val: 0.935614	test: 0.701190

Epoch: 25
Loss: 0.35546238151803383
ROC train: 0.937957	val: 0.702930	test: 0.701617
PRC train: 0.900618	val: 0.940173	test: 0.707488

Epoch: 26
Loss: 0.3389469309421069
ROC train: 0.942052	val: 0.695971	test: 0.716745
PRC train: 0.906223	val: 0.940337	test: 0.724240

Epoch: 27
Loss: 0.36385020567171683
ROC train: 0.943975	val: 0.672161	test: 0.711007
PRC train: 0.910027	val: 0.934009	test: 0.727269

Epoch: 28
Loss: 0.3403705704108223
ROC train: 0.944706	val: 0.681685	test: 0.708399
PRC train: 0.911876	val: 0.933882	test: 0.713260

Epoch: 29
Loss: 0.34625394451531005
ROC train: 0.944124	val: 0.699267	test: 0.709094
PRC train: 0.911344	val: 0.937508	test: 0.709855

Epoch: 30
Loss: 0.3316617705334156
ROC train: 0.946553	val: 0.694872	test: 0.712398
PRC train: 0.915557	val: 0.937085	test: 0.711555

Epoch: 31
Loss: 0.3274213460873427
ROC train: 0.948268	val: 0.686447	test: 0.701791
PRC train: 0.918876	val: 0.937198	test: 0.695848

Epoch: 32
Loss: 0.33582383143616445
ROC train: 0.946535	val: 0.674725	test: 0.684403
PRC train: 0.916750	val: 0.933775	test: 0.688419

Epoch: 33
Loss: 0.33493017777414924Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/scaff/train_prop=0.8/bace_scaff_6_26-05_10-20-35  ]
[ Using Seed :  6  ]
[ Using device :  cuda:2  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
split via scaffold
Data(edge_attr=[66, 2], edge_index=[2, 66], id=[1], x=[31, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6856955946274725
ROC train: 0.674038	val: 0.616484	test: 0.596070
PRC train: 0.585284	val: 0.912572	test: 0.569621

Epoch: 2
Loss: 0.6363310878357159
ROC train: 0.737009	val: 0.591575	test: 0.609285
PRC train: 0.642183	val: 0.904547	test: 0.593000

Epoch: 3
Loss: 0.5875016415043034
ROC train: 0.811724	val: 0.590110	test: 0.675882
PRC train: 0.712181	val: 0.904818	test: 0.654850

Epoch: 4
Loss: 0.5588898163399115
ROC train: 0.846207	val: 0.620147	test: 0.724744
PRC train: 0.757053	val: 0.910385	test: 0.721859

Epoch: 5
Loss: 0.5041237287955076
ROC train: 0.866787	val: 0.596703	test: 0.755173
PRC train: 0.781057	val: 0.908736	test: 0.739068

Epoch: 6
Loss: 0.47930794381725905
ROC train: 0.876361	val: 0.635531	test: 0.722309
PRC train: 0.792063	val: 0.918931	test: 0.713774

Epoch: 7
Loss: 0.46212722527314065
ROC train: 0.882831	val: 0.651648	test: 0.738654
PRC train: 0.805878	val: 0.923640	test: 0.723221

Epoch: 8
Loss: 0.4500302711721755
ROC train: 0.894974	val: 0.670330	test: 0.779517
PRC train: 0.825402	val: 0.929966	test: 0.773702

Epoch: 9
Loss: 0.444652465687732
ROC train: 0.901093	val: 0.679121	test: 0.800730
PRC train: 0.827326	val: 0.931004	test: 0.778009

Epoch: 10
Loss: 0.41775125631221444
ROC train: 0.903662	val: 0.683883	test: 0.797948
PRC train: 0.834812	val: 0.936504	test: 0.792190

Epoch: 11
Loss: 0.4159976499943555
ROC train: 0.908793	val: 0.690476	test: 0.781777
PRC train: 0.841580	val: 0.940043	test: 0.785921

Epoch: 12
Loss: 0.4037166319916638
ROC train: 0.913059	val: 0.676190	test: 0.782125
PRC train: 0.851281	val: 0.936782	test: 0.780858

Epoch: 13
Loss: 0.3874462557609409
ROC train: 0.914301	val: 0.693773	test: 0.791688
PRC train: 0.850648	val: 0.940743	test: 0.775938

Epoch: 14
Loss: 0.3915086657354653
ROC train: 0.918114	val: 0.701832	test: 0.791515
PRC train: 0.857337	val: 0.942610	test: 0.773637

Epoch: 15
Loss: 0.3934536752583355
ROC train: 0.920890	val: 0.695604	test: 0.773605
PRC train: 0.862002	val: 0.941195	test: 0.755906

Epoch: 16
Loss: 0.39340452365895456
ROC train: 0.919963	val: 0.689011	test: 0.773083
PRC train: 0.864130	val: 0.937921	test: 0.743699

Epoch: 17
Loss: 0.38248967862827044
ROC train: 0.923967	val: 0.709524	test: 0.756390
PRC train: 0.873433	val: 0.942679	test: 0.736991

Epoch: 18
Loss: 0.3832030868890317
ROC train: 0.924378	val: 0.694872	test: 0.752217
PRC train: 0.876117	val: 0.940015	test: 0.747443

Epoch: 19
Loss: 0.369332490242955
ROC train: 0.927369	val: 0.701832	test: 0.775343
PRC train: 0.879817	val: 0.940742	test: 0.759461

Epoch: 20
Loss: 0.37911590998124367
ROC train: 0.926478	val: 0.699267	test: 0.774300
PRC train: 0.878111	val: 0.940232	test: 0.751907

Epoch: 21
Loss: 0.3647692198262901
ROC train: 0.928827	val: 0.702930	test: 0.759868
PRC train: 0.884218	val: 0.941162	test: 0.739867

Epoch: 22
Loss: 0.3680263012016892
ROC train: 0.931458	val: 0.705495	test: 0.753086
PRC train: 0.889737	val: 0.939728	test: 0.729567

Epoch: 23
Loss: 0.3738540787482141
ROC train: 0.932837	val: 0.698901	test: 0.751869
PRC train: 0.892261	val: 0.938120	test: 0.718680

Epoch: 24
Loss: 0.3446688065828848
ROC train: 0.935091	val: 0.694139	test: 0.765084
PRC train: 0.897764	val: 0.933741	test: 0.728160

Epoch: 25
Loss: 0.35771848668472045
ROC train: 0.940225	val: 0.683516	test: 0.779864
PRC train: 0.906361	val: 0.933317	test: 0.745546

Epoch: 26
Loss: 0.3382886292368997
ROC train: 0.941795	val: 0.677289	test: 0.780038
PRC train: 0.906428	val: 0.933541	test: 0.755078

Epoch: 27
Loss: 0.3447169267353793
ROC train: 0.942683	val: 0.689011	test: 0.779864
PRC train: 0.907784	val: 0.934375	test: 0.764174

Epoch: 28
Loss: 0.33075934940866986
ROC train: 0.943610	val: 0.679487	test: 0.773257
PRC train: 0.909424	val: 0.930728	test: 0.755433

Epoch: 29
Loss: 0.3511158328868952
ROC train: 0.944775	val: 0.684615	test: 0.759694
PRC train: 0.910309	val: 0.933242	test: 0.752156

Epoch: 30
Loss: 0.3466465525236998
ROC train: 0.942292	val: 0.693773	test: 0.739002
PRC train: 0.908684	val: 0.935490	test: 0.740351

Epoch: 31
Loss: 0.35438530759296094
ROC train: 0.943933	val: 0.669231	test: 0.765084
PRC train: 0.910212	val: 0.928080	test: 0.752751

Epoch: 32
Loss: 0.3365764956250297
ROC train: 0.946333	val: 0.667399	test: 0.780386
PRC train: 0.914505	val: 0.927940	test: 0.755115

Epoch: 33
Loss: 0.34454509430828983
ROC train: 0.947902	val: 0.677289	test: 0.758651
PRC train: 0.934974	val: 0.417018	test: 0.848141

Epoch: 34
Loss: 0.35283899246222356
ROC train: 0.939856	val: 0.853244	test: 0.736555
PRC train: 0.936478	val: 0.419711	test: 0.854129

Epoch: 35
Loss: 0.3477754799647004
ROC train: 0.943019	val: 0.858294	test: 0.754842
PRC train: 0.938423	val: 0.424192	test: 0.865924

Epoch: 36
Loss: 0.3606072522303116
ROC train: 0.944615	val: 0.862859	test: 0.754842
PRC train: 0.938782	val: 0.430773	test: 0.858976

Epoch: 37
Loss: 0.3554665800547539
ROC train: 0.943987	val: 0.868201	test: 0.744127
PRC train: 0.937845	val: 0.442118	test: 0.851417

Epoch: 38
Loss: 0.3258443464042532
ROC train: 0.944425	val: 0.870047	test: 0.742273
PRC train: 0.938468	val: 0.450976	test: 0.848936

Epoch: 39
Loss: 0.36635222872909534
ROC train: 0.948225	val: 0.869270	test: 0.749588
PRC train: 0.943270	val: 0.440736	test: 0.853850

Epoch: 40
Loss: 0.3434723758493168
ROC train: 0.952177	val: 0.852855	test: 0.761230
PRC train: 0.947279	val: 0.422865	test: 0.863186

Epoch: 41
Loss: 0.33290936343075933
ROC train: 0.951846	val: 0.840909	test: 0.763857
PRC train: 0.945509	val: 0.409547	test: 0.866253

Epoch: 42
Loss: 0.3437322237339502
ROC train: 0.950717	val: 0.840812	test: 0.762621
PRC train: 0.944786	val: 0.391320	test: 0.867379

Epoch: 43
Loss: 0.3345832800370273
ROC train: 0.952021	val: 0.841686	test: 0.759221
PRC train: 0.946754	val: 0.386615	test: 0.864195

Epoch: 44
Loss: 0.33074469758135755
ROC train: 0.953072	val: 0.859169	test: 0.753451
PRC train: 0.947943	val: 0.417290	test: 0.854434

Epoch: 45
Loss: 0.3298185300866639
ROC train: 0.953923	val: 0.867036	test: 0.756336
PRC train: 0.949616	val: 0.434751	test: 0.855707

Epoch: 46
Loss: 0.32248731055703483
ROC train: 0.952795	val: 0.872766	test: 0.754482
PRC train: 0.948929	val: 0.452446	test: 0.856156

Epoch: 47
Loss: 0.3329736271642649
ROC train: 0.952478	val: 0.871892	test: 0.754121
PRC train: 0.948421	val: 0.456979	test: 0.858934

Epoch: 48
Loss: 0.32736608661873556
ROC train: 0.956653	val: 0.863248	test: 0.752679
PRC train: 0.953074	val: 0.433489	test: 0.863145

Epoch: 49
Loss: 0.3356213846144969
ROC train: 0.957646	val: 0.858100	test: 0.756336
PRC train: 0.953463	val: 0.424698	test: 0.870681

Epoch: 50
Loss: 0.32398569006319566
ROC train: 0.956712	val: 0.857712	test: 0.752833
PRC train: 0.952042	val: 0.427051	test: 0.868510

Epoch: 51
Loss: 0.3373571436669903
ROC train: 0.957889	val: 0.864608	test: 0.751545
PRC train: 0.953425	val: 0.430755	test: 0.863745

Epoch: 52
Loss: 0.3116923246480492
ROC train: 0.957724	val: 0.854021	test: 0.749021
PRC train: 0.953663	val: 0.415777	test: 0.858041

Epoch: 53
Loss: 0.30140107692135865
ROC train: 0.958050	val: 0.859169	test: 0.744127
PRC train: 0.954344	val: 0.430488	test: 0.854915

Epoch: 54
Loss: 0.3082618158437296
ROC train: 0.959354	val: 0.859169	test: 0.746909
PRC train: 0.955582	val: 0.439560	test: 0.860105

Epoch: 55
Loss: 0.28937666736548995
ROC train: 0.957675	val: 0.856546	test: 0.743458
PRC train: 0.954258	val: 0.439982	test: 0.857329

Epoch: 56
Loss: 0.32012689509116476
ROC train: 0.959709	val: 0.863345	test: 0.726200
PRC train: 0.956310	val: 0.452415	test: 0.846436

Epoch: 57
Loss: 0.32001977850413843
ROC train: 0.962892	val: 0.865870	test: 0.728467
PRC train: 0.959537	val: 0.454556	test: 0.846833

Epoch: 58
Loss: 0.30979184674286037
ROC train: 0.963729	val: 0.857129	test: 0.754533
PRC train: 0.959617	val: 0.441163	test: 0.870516

Epoch: 59
Loss: 0.28584101194473
ROC train: 0.964702	val: 0.842852	test: 0.750361
PRC train: 0.961813	val: 0.424843	test: 0.868480

Epoch: 60
Loss: 0.30983999037862897
ROC train: 0.964069	val: 0.853147	test: 0.732949
PRC train: 0.962737	val: 0.436305	test: 0.854774

Epoch: 61
Loss: 0.29035395091059907
ROC train: 0.964731	val: 0.854507	test: 0.743303
PRC train: 0.963121	val: 0.442261	test: 0.857719

Epoch: 62
Loss: 0.3039302009628329
ROC train: 0.963072	val: 0.835082	test: 0.761333
PRC train: 0.961658	val: 0.397940	test: 0.871539

Epoch: 63
Loss: 0.3088637473678051
ROC train: 0.961038	val: 0.822067	test: 0.761900
PRC train: 0.960204	val: 0.387822	test: 0.871210

Epoch: 64
Loss: 0.28499178506499173
ROC train: 0.964137	val: 0.834110	test: 0.764836
PRC train: 0.962819	val: 0.398737	test: 0.872042

Epoch: 65
Loss: 0.3099339887773914
ROC train: 0.964381	val: 0.844794	test: 0.758603
PRC train: 0.961693	val: 0.404900	test: 0.865818

Epoch: 66
Loss: 0.3055656305189978
ROC train: 0.965865	val: 0.854992	test: 0.748352
PRC train: 0.962811	val: 0.417519	test: 0.859222

Epoch: 67
Loss: 0.30584623892971785
ROC train: 0.967232	val: 0.863831	test: 0.732691
PRC train: 0.964789	val: 0.441992	test: 0.851289

Epoch: 68
Loss: 0.27830074257849363
ROC train: 0.966935	val: 0.876166	test: 0.718473
PRC train: 0.965381	val: 0.482592	test: 0.841389

Epoch: 69
Loss: 0.2878164872772921
ROC train: 0.969315	val: 0.876068	test: 0.718113
PRC train: 0.967672	val: 0.494372	test: 0.841094

Epoch: 70
Loss: 0.279688367934668
ROC train: 0.970901	val: 0.871212	test: 0.733206
PRC train: 0.969399	val: 0.467440	test: 0.851058

Epoch: 71
Loss: 0.29121562613482016
ROC train: 0.970512	val: 0.860917	test: 0.749124
PRC train: 0.968906	val: 0.444556	test: 0.863433

Epoch: 72
Loss: 0.294970752420095
ROC train: 0.969952	val: 0.861111	test: 0.752524
PRC train: 0.968159	val: 0.444783	test: 0.863052

Epoch: 73
Loss: 0.27988729394851275
ROC train: 0.968074	val: 0.861985	test: 0.750052
PRC train: 0.966132	val: 0.455232	test: 0.860632

Epoch: 74
Loss: 0.28370359712587434
ROC train: 0.970069	val: 0.863345	test: 0.736452
PRC train: 0.968067	val: 0.455012	test: 0.850525

Epoch: 75
Loss: 0.28018562411304293
ROC train: 0.972137	val: 0.874223	test: 0.723779
PRC train: 0.970215	val: 0.485090	test: 0.840924

Epoch: 76
Loss: 0.28009385066783005
ROC train: 0.971952	val: 0.872378	test: 0.717906
PRC train: 0.970343	val: 0.483983	test: 0.835712

Epoch: 77
Loss: 0.27274358599817355
ROC train: 0.971845	val: 0.868590	test: 0.712085
PRC train: 0.970386	val: 0.485099	test: 0.834317

Epoch: 78
Loss: 0.275231391569825
ROC train: 0.971422	val: 0.865093	test: 0.715022
PRC train: 0.969525	val: 0.477870	test: 0.839649

Epoch: 79
Loss: 0.284206139315646
ROC train: 0.972483	val: 0.865967	test: 0.722955
PRC train: 0.970513	val: 0.465707	test: 0.842555

Epoch: 80
Loss: 0.2616677769919359
ROC train: 0.973071	val: 0.868298	test: 0.724294
PRC train: 0.971316	val: 0.469682	test: 0.835961

Epoch: 81
Loss: 0.25584778375314365
ROC train: 0.975368	val: 0.867230	test: 0.718473
PRC train: 0.974234	val: 0.483687	test: 0.826303

Epoch: 82
Loss: 0.2651730892308132
ROC train: 0.973772	val: 0.859946	test: 0.715794
PRC train: 0.972153	val: 0.481491	test: 0.824588

Epoch: 83
Loss: 0.25251817099640606
ROC train: 0.971378	val: 0.859946	test: 0.726509
PRC train: 0.970857	val: 0.446013	test: 0.833573

Epoch: 84
Loss: 0.29052308673759397
ROC train: 0.969568	val: 0.855478	test: 0.731764
PRC train: 0.968852	val: 0.434918	test: 0.845121

Epoch: 85
Loss: 0.27032566418644693
ROC train: 0.974307	val: 0.861208	test: 0.726818
PRC train: 0.972843	val: 0.450591	test: 0.841214

Epoch: 86
Loss: 0.2562845994982461
ROC train: 0.974945	val: 0.854798	test: 0.718988
PRC train: 0.973103	val: 0.469661	test: 0.831590

Epoch: 87
Loss: 0.2601516800557517
ROC train: 0.973723	val: 0.848582	test: 0.717082
PRC train: 0.971774	val: 0.463958	test: 0.823989

Epoch: 88
Loss: 0.27988961014822417
ROC train: 0.974526	val: 0.856255	test: 0.730528
PRC train: 0.972501	val: 0.455777	test: 0.843481

Epoch: 89
Loss: 0.2487063481966203
ROC train: 0.975032	val: 0.860625	test: 0.737533
PRC train: 0.972888	val: 0.428298	test: 0.850892

Epoch: 90
Loss: 0.2470628620843433
ROC train: 0.975937	val: 0.852078	test: 0.730888
PRC train: 0.974050	val: 0.421303	test: 0.847847

Epoch: 91
Loss: 0.2624765607532225
ROC train: 0.976336	val: 0.849456	test: 0.724294
PRC train: 0.975200	val: 0.420218	test: 0.843791

Epoch: 92
Loss: 0.25845822945586705
ROC train: 0.975748	val: 0.845474	test: 0.725170
PRC train: 0.974839	val: 0.421888	test: 0.842989

Epoch: 93
Loss: 0.26471776922085627
ROC train: 0.977071	val: 0.854215	test: 0.732227
PRC train: 0.976548	val: 0.429288	test: 0.836140

Epoch: 94
Loss: 0.2660152263945811
ROC train: 0.978443	val: 0.850039	test: 0.722697
PRC train: 0.932784	val: 0.406199	test: 0.871397

Epoch: 34
Loss: 0.37772931588352443
ROC train: 0.941549	val: 0.841492	test: 0.747167
PRC train: 0.934145	val: 0.399476	test: 0.867441

Epoch: 35
Loss: 0.3598613607158193
ROC train: 0.942221	val: 0.844697	test: 0.737121
PRC train: 0.935225	val: 0.406544	test: 0.859895

Epoch: 36
Loss: 0.36587750452126216
ROC train: 0.942809	val: 0.844308	test: 0.732794
PRC train: 0.936952	val: 0.407019	test: 0.856423

Epoch: 37
Loss: 0.33201160898805837
ROC train: 0.939900	val: 0.833819	test: 0.723831
PRC train: 0.934743	val: 0.396108	test: 0.851465

Epoch: 38
Loss: 0.34524068991127554
ROC train: 0.942668	val: 0.837704	test: 0.729085
PRC train: 0.937147	val: 0.401139	test: 0.852276

Epoch: 39
Loss: 0.3372325398589484
ROC train: 0.947885	val: 0.857032	test: 0.743252
PRC train: 0.941337	val: 0.427127	test: 0.859567

Epoch: 40
Loss: 0.3587163439726848
ROC train: 0.948605	val: 0.866744	test: 0.735885
PRC train: 0.943247	val: 0.452703	test: 0.854917

Epoch: 41
Loss: 0.3258498841043695
ROC train: 0.945189	val: 0.863442	test: 0.720740
PRC train: 0.940178	val: 0.446314	test: 0.845087

Epoch: 42
Loss: 0.32729925094951984
ROC train: 0.948975	val: 0.856449	test: 0.734134
PRC train: 0.944085	val: 0.438921	test: 0.851472

Epoch: 43
Loss: 0.3265714988170476
ROC train: 0.950980	val: 0.850913	test: 0.741912
PRC train: 0.945357	val: 0.441157	test: 0.859254

Epoch: 44
Loss: 0.3280026127799426
ROC train: 0.948897	val: 0.834984	test: 0.732382
PRC train: 0.942038	val: 0.419800	test: 0.858275

Epoch: 45
Loss: 0.32888630076986103
ROC train: 0.949374	val: 0.843726	test: 0.727746
PRC train: 0.941997	val: 0.430175	test: 0.854362

Epoch: 46
Loss: 0.3253413755822506
ROC train: 0.950109	val: 0.842366	test: 0.730115
PRC train: 0.943601	val: 0.409677	test: 0.849205

Epoch: 47
Loss: 0.3197218990164612
ROC train: 0.949447	val: 0.831974	test: 0.730940
PRC train: 0.943779	val: 0.392620	test: 0.851778

Epoch: 48
Loss: 0.3104972207138557
ROC train: 0.954795	val: 0.829643	test: 0.737894
PRC train: 0.949848	val: 0.386242	test: 0.851777

Epoch: 49
Loss: 0.3263234673312593
ROC train: 0.956848	val: 0.839161	test: 0.744024
PRC train: 0.951528	val: 0.401251	test: 0.854607

Epoch: 50
Loss: 0.3281644386114032
ROC train: 0.955286	val: 0.839841	test: 0.735164
PRC train: 0.950068	val: 0.415984	test: 0.850229

Epoch: 51
Loss: 0.3285597146433431
ROC train: 0.955101	val: 0.837898	test: 0.733052
PRC train: 0.949374	val: 0.418270	test: 0.850236

Epoch: 52
Loss: 0.30911815021119304
ROC train: 0.956955	val: 0.834402	test: 0.734855
PRC train: 0.952166	val: 0.410994	test: 0.847812

Epoch: 53
Loss: 0.3216806002535848
ROC train: 0.955388	val: 0.842172	test: 0.730373
PRC train: 0.951035	val: 0.412687	test: 0.845738

Epoch: 54
Loss: 0.3177493561966659
ROC train: 0.955447	val: 0.850427	test: 0.729343
PRC train: 0.951008	val: 0.432530	test: 0.848966

Epoch: 55
Loss: 0.311514098736278
ROC train: 0.952186	val: 0.840909	test: 0.728312
PRC train: 0.946650	val: 0.412831	test: 0.850554

Epoch: 56
Loss: 0.3226140925897302
ROC train: 0.953369	val: 0.843726	test: 0.729446
PRC train: 0.947541	val: 0.411221	test: 0.849950

Epoch: 57
Loss: 0.30064637297709024
ROC train: 0.957802	val: 0.847611	test: 0.730528
PRC train: 0.953482	val: 0.419442	test: 0.846895

Epoch: 58
Loss: 0.30892635713957717
ROC train: 0.958877	val: 0.849359	test: 0.720997
PRC train: 0.955222	val: 0.427468	test: 0.839454

Epoch: 59
Loss: 0.31075485410193543
ROC train: 0.956308	val: 0.850622	test: 0.717494
PRC train: 0.952116	val: 0.431913	test: 0.836244

Epoch: 60
Loss: 0.309146898121738
ROC train: 0.957816	val: 0.857906	test: 0.720585
PRC train: 0.953768	val: 0.439819	test: 0.837639

Epoch: 61
Loss: 0.30549154569392295
ROC train: 0.961369	val: 0.858780	test: 0.731609
PRC train: 0.957838	val: 0.445665	test: 0.845361

Epoch: 62
Loss: 0.30712478700046447
ROC train: 0.963193	val: 0.850427	test: 0.742221
PRC train: 0.959813	val: 0.415625	test: 0.850839

Epoch: 63
Loss: 0.32455357429334847
ROC train: 0.963242	val: 0.851399	test: 0.746909
PRC train: 0.959971	val: 0.416907	test: 0.852570

Epoch: 64
Loss: 0.31794445071465743
ROC train: 0.962171	val: 0.854701	test: 0.746188
PRC train: 0.959084	val: 0.414372	test: 0.849743

Epoch: 65
Loss: 0.3019284762686472
ROC train: 0.964415	val: 0.847708	test: 0.743252
PRC train: 0.960948	val: 0.408148	test: 0.844489

Epoch: 66
Loss: 0.299857813346474
ROC train: 0.963544	val: 0.841880	test: 0.734494
PRC train: 0.959860	val: 0.405226	test: 0.839185

Epoch: 67
Loss: 0.2917099128209013
ROC train: 0.964609	val: 0.838481	test: 0.733412
PRC train: 0.960913	val: 0.396470	test: 0.841711

Epoch: 68
Loss: 0.28428009978454366
ROC train: 0.963339	val: 0.826535	test: 0.737173
PRC train: 0.959472	val: 0.387855	test: 0.849954

Epoch: 69
Loss: 0.3007424103823482
ROC train: 0.963101	val: 0.821970	test: 0.739233
PRC train: 0.959541	val: 0.385172	test: 0.855345

Epoch: 70
Loss: 0.2963467662402558
ROC train: 0.962502	val: 0.838675	test: 0.737637
PRC train: 0.958604	val: 0.402089	test: 0.850793

Epoch: 71
Loss: 0.2999989586392167
ROC train: 0.964108	val: 0.858489	test: 0.724758
PRC train: 0.960066	val: 0.432018	test: 0.841388

Epoch: 72
Loss: 0.3048794164009462
ROC train: 0.961894	val: 0.851787	test: 0.713167
PRC train: 0.958094	val: 0.429402	test: 0.839478

Epoch: 73
Loss: 0.30583914145849156
ROC train: 0.957821	val: 0.820416	test: 0.711467
PRC train: 0.955194	val: 0.390479	test: 0.842553

Epoch: 74
Loss: 0.3076553894754893
ROC train: 0.962400	val: 0.826632	test: 0.721719
PRC train: 0.959808	val: 0.385298	test: 0.846307

Epoch: 75
Loss: 0.287843917579097
ROC train: 0.965587	val: 0.841880	test: 0.728570
PRC train: 0.962597	val: 0.402086	test: 0.839581

Epoch: 76
Loss: 0.28168812038242896
ROC train: 0.966638	val: 0.840812	test: 0.732227
PRC train: 0.963905	val: 0.399576	test: 0.836799

Epoch: 77
Loss: 0.2939347265081787
ROC train: 0.968069	val: 0.834790	test: 0.737533
PRC train: 0.965307	val: 0.392066	test: 0.839839

Epoch: 78
Loss: 0.274197749368437
ROC train: 0.968337	val: 0.825078	test: 0.733567
PRC train: 0.965770	val: 0.381336	test: 0.836289

Epoch: 79
Loss: 0.2801518193423992
ROC train: 0.968561	val: 0.821678	test: 0.740830
PRC train: 0.966122	val: 0.386920	test: 0.844551

Epoch: 80
Loss: 0.25762933467996624
ROC train: 0.969441	val: 0.838869	test: 0.745518
PRC train: 0.966934	val: 0.407092	test: 0.844949

Epoch: 81
Loss: 0.27763137889406647
ROC train: 0.966239	val: 0.851204	test: 0.739182
PRC train: 0.963221	val: 0.425722	test: 0.837587

Epoch: 82
Loss: 0.28073884319593595
ROC train: 0.967631	val: 0.847708	test: 0.731197
PRC train: 0.964959	val: 0.418937	test: 0.827540

Epoch: 83
Loss: 0.28159504851472883
ROC train: 0.970536	val: 0.835276	test: 0.737276
PRC train: 0.968469	val: 0.417183	test: 0.831924

Epoch: 84
Loss: 0.27775563352726823
ROC train: 0.970848	val: 0.831682	test: 0.736040
PRC train: 0.968971	val: 0.401522	test: 0.837567

Epoch: 85
Loss: 0.28546464931620114
ROC train: 0.971573	val: 0.835761	test: 0.734030
PRC train: 0.969899	val: 0.413199	test: 0.837650

Epoch: 86
Loss: 0.2817716528915116
ROC train: 0.970857	val: 0.850913	test: 0.716464
PRC train: 0.968627	val: 0.438959	test: 0.817162

Epoch: 87
Loss: 0.2771093773145421
ROC train: 0.970113	val: 0.840812	test: 0.716206
PRC train: 0.967838	val: 0.434504	test: 0.813280

Epoch: 88
Loss: 0.27717530562562326
ROC train: 0.971164	val: 0.831585	test: 0.728931
PRC train: 0.968689	val: 0.413237	test: 0.828795

Epoch: 89
Loss: 0.2757292992926622
ROC train: 0.968595	val: 0.826243	test: 0.737791
PRC train: 0.966430	val: 0.407834	test: 0.840061

Epoch: 90
Loss: 0.27835499832541954
ROC train: 0.972049	val: 0.837413	test: 0.733412
PRC train: 0.970408	val: 0.415626	test: 0.836166

Epoch: 91
Loss: 0.2652175062971659
ROC train: 0.975305	val: 0.840521	test: 0.718679
PRC train: 0.974018	val: 0.421039	test: 0.822072

Epoch: 92
Loss: 0.2732311574794364
ROC train: 0.976001	val: 0.854798	test: 0.700340
PRC train: 0.974877	val: 0.448523	test: 0.803844

Epoch: 93
Loss: 0.2608492451434472
ROC train: 0.976570	val: 0.857615	test: 0.708119
PRC train: 0.975257	val: 0.464018	test: 0.809479

Epoch: 94
Loss: 0.29600321226581566
ROC train: 0.975538	val: 0.853730	test: 0.711776
PRC train: 0.926709	val: 0.453812	test: 0.855152

Epoch: 34
Loss: 0.34796885359410257
ROC train: 0.940775	val: 0.855963	test: 0.732794
PRC train: 0.931878	val: 0.446834	test: 0.857250

Epoch: 35
Loss: 0.3673067604803578
ROC train: 0.942517	val: 0.858003	test: 0.738667
PRC train: 0.933353	val: 0.455343	test: 0.858186

Epoch: 36
Loss: 0.35121393264163014
ROC train: 0.942766	val: 0.860625	test: 0.747321
PRC train: 0.935127	val: 0.454874	test: 0.860975

Epoch: 37
Loss: 0.3595022679025166
ROC train: 0.942654	val: 0.861597	test: 0.748145
PRC train: 0.935673	val: 0.450908	test: 0.863901

Epoch: 38
Loss: 0.3631321612876319
ROC train: 0.943204	val: 0.853050	test: 0.746858
PRC train: 0.936622	val: 0.432643	test: 0.861738

Epoch: 39
Loss: 0.344600482606903
ROC train: 0.946673	val: 0.848193	test: 0.754379
PRC train: 0.940226	val: 0.426704	test: 0.864049

Epoch: 40
Loss: 0.3443542335364288
ROC train: 0.945646	val: 0.833236	test: 0.753245
PRC train: 0.939382	val: 0.420571	test: 0.863501

Epoch: 41
Loss: 0.3439100172442249
ROC train: 0.948649	val: 0.846737	test: 0.752627
PRC train: 0.942571	val: 0.432251	test: 0.864281

Epoch: 42
Loss: 0.32493288079151095
ROC train: 0.949242	val: 0.858294	test: 0.751494
PRC train: 0.943829	val: 0.435015	test: 0.865707

Epoch: 43
Loss: 0.3330350642130676
ROC train: 0.950512	val: 0.853827	test: 0.750670
PRC train: 0.945542	val: 0.430323	test: 0.866797

Epoch: 44
Loss: 0.31631464805535164
ROC train: 0.950624	val: 0.840521	test: 0.743406
PRC train: 0.946149	val: 0.420794	test: 0.863494

Epoch: 45
Loss: 0.33578375701870067
ROC train: 0.952571	val: 0.842366	test: 0.744849
PRC train: 0.948240	val: 0.418028	test: 0.866289

Epoch: 46
Loss: 0.33025088917348944
ROC train: 0.951534	val: 0.839161	test: 0.745673
PRC train: 0.947481	val: 0.404778	test: 0.867867

Epoch: 47
Loss: 0.329284960638652
ROC train: 0.951962	val: 0.839841	test: 0.753348
PRC train: 0.947333	val: 0.397614	test: 0.870845

Epoch: 48
Loss: 0.32339843114683486
ROC train: 0.953471	val: 0.845862	test: 0.751597
PRC train: 0.948171	val: 0.422173	test: 0.868613

Epoch: 49
Loss: 0.3162533695308797
ROC train: 0.950707	val: 0.839355	test: 0.748197
PRC train: 0.945571	val: 0.430550	test: 0.862836

Epoch: 50
Loss: 0.31999760529288485
ROC train: 0.954211	val: 0.846057	test: 0.745879
PRC train: 0.948348	val: 0.436798	test: 0.861963

Epoch: 51
Loss: 0.3269500087436114
ROC train: 0.956352	val: 0.841200	test: 0.749279
PRC train: 0.950236	val: 0.431738	test: 0.866255

Epoch: 52
Loss: 0.3062295789973235
ROC train: 0.957860	val: 0.840132	test: 0.750258
PRC train: 0.953043	val: 0.433336	test: 0.867004

Epoch: 53
Loss: 0.3164381698866876
ROC train: 0.957695	val: 0.819736	test: 0.754327
PRC train: 0.953577	val: 0.413593	test: 0.867513

Epoch: 54
Loss: 0.31195869942135834
ROC train: 0.960098	val: 0.828574	test: 0.755306
PRC train: 0.955613	val: 0.418858	test: 0.871518

Epoch: 55
Loss: 0.29558703162469807
ROC train: 0.961553	val: 0.835956	test: 0.753245
PRC train: 0.957346	val: 0.429531	test: 0.869486

Epoch: 56
Loss: 0.3341490701962975
ROC train: 0.962697	val: 0.846834	test: 0.743561
PRC train: 0.959110	val: 0.444241	test: 0.864687

Epoch: 57
Loss: 0.3035303635485731
ROC train: 0.963184	val: 0.832848	test: 0.747218
PRC train: 0.959937	val: 0.447818	test: 0.860602

Epoch: 58
Loss: 0.3173370093032545
ROC train: 0.961928	val: 0.822261	test: 0.742582
PRC train: 0.958437	val: 0.402218	test: 0.863563

Epoch: 59
Loss: 0.29235649304745753
ROC train: 0.961714	val: 0.830225	test: 0.738615
PRC train: 0.957931	val: 0.392294	test: 0.866292

Epoch: 60
Loss: 0.29450225166449207
ROC train: 0.958361	val: 0.827894	test: 0.734597
PRC train: 0.954421	val: 0.381048	test: 0.862820

Epoch: 61
Loss: 0.308831670059876
ROC train: 0.959714	val: 0.821290	test: 0.724706
PRC train: 0.955558	val: 0.378570	test: 0.854843

Epoch: 62
Loss: 0.2964336244390037
ROC train: 0.961466	val: 0.831294	test: 0.730940
PRC train: 0.957340	val: 0.394458	test: 0.858431

Epoch: 63
Loss: 0.29392245634302916
ROC train: 0.964147	val: 0.842172	test: 0.731867
PRC train: 0.959923	val: 0.412049	test: 0.856537

Epoch: 64
Loss: 0.3050383192113576
ROC train: 0.964264	val: 0.835082	test: 0.724706
PRC train: 0.960708	val: 0.418978	test: 0.848125

Epoch: 65
Loss: 0.2858917606773987
ROC train: 0.965816	val: 0.832265	test: 0.726046
PRC train: 0.962343	val: 0.436653	test: 0.847685

Epoch: 66
Loss: 0.3062550224614122
ROC train: 0.966697	val: 0.821873	test: 0.734185
PRC train: 0.963950	val: 0.426431	test: 0.853769

Epoch: 67
Loss: 0.2906020381331904
ROC train: 0.965874	val: 0.830128	test: 0.718319
PRC train: 0.962818	val: 0.426322	test: 0.837546

Epoch: 68
Loss: 0.3006373564535471
ROC train: 0.964911	val: 0.847999	test: 0.714197
PRC train: 0.961788	val: 0.448162	test: 0.835792

Epoch: 69
Loss: 0.29007166512517346
ROC train: 0.965553	val: 0.847902	test: 0.722697
PRC train: 0.961747	val: 0.432532	test: 0.845170

Epoch: 70
Loss: 0.2900731416555616
ROC train: 0.967675	val: 0.850622	test: 0.718267
PRC train: 0.964689	val: 0.434917	test: 0.842582

Epoch: 71
Loss: 0.2833274880877639
ROC train: 0.968346	val: 0.832071	test: 0.712291
PRC train: 0.965952	val: 0.419729	test: 0.836909

Epoch: 72
Loss: 0.2938946657437289
ROC train: 0.969777	val: 0.832848	test: 0.719091
PRC train: 0.967565	val: 0.418277	test: 0.842847

Epoch: 73
Loss: 0.27548227356080474
ROC train: 0.969412	val: 0.831488	test: 0.731712
PRC train: 0.966812	val: 0.432829	test: 0.856283

Epoch: 74
Loss: 0.2759951546036128
ROC train: 0.970191	val: 0.827797	test: 0.727540
PRC train: 0.967995	val: 0.432430	test: 0.851727

Epoch: 75
Loss: 0.28966590889215604
ROC train: 0.969237	val: 0.811189	test: 0.716876
PRC train: 0.966985	val: 0.404460	test: 0.840418

Epoch: 76
Loss: 0.29641641418379844
ROC train: 0.971694	val: 0.823232	test: 0.717391
PRC train: 0.969696	val: 0.404836	test: 0.838206

Epoch: 77
Loss: 0.26860304312734656
ROC train: 0.971865	val: 0.834596	test: 0.719503
PRC train: 0.969766	val: 0.424290	test: 0.841343

Epoch: 78
Loss: 0.2813823740773784
ROC train: 0.971957	val: 0.830517	test: 0.721873
PRC train: 0.969608	val: 0.418394	test: 0.849478

Epoch: 79
Loss: 0.2768285870353432
ROC train: 0.968288	val: 0.806818	test: 0.721152
PRC train: 0.966193	val: 0.374996	test: 0.853165

Epoch: 80
Loss: 0.28356651473699984
ROC train: 0.967592	val: 0.798465	test: 0.723006
PRC train: 0.965482	val: 0.377463	test: 0.850622

Epoch: 81
Loss: 0.26808044973405315
ROC train: 0.971582	val: 0.829157	test: 0.715691
PRC train: 0.970032	val: 0.416434	test: 0.835533

Epoch: 82
Loss: 0.27346592879456955
ROC train: 0.972507	val: 0.846445	test: 0.713888
PRC train: 0.971428	val: 0.440217	test: 0.826587

Epoch: 83
Loss: 0.2820661549913018
ROC train: 0.973217	val: 0.838384	test: 0.719349
PRC train: 0.972222	val: 0.415815	test: 0.828732

Epoch: 84
Loss: 0.2726143477490134
ROC train: 0.975300	val: 0.833333	test: 0.730631
PRC train: 0.973517	val: 0.414711	test: 0.846623

Epoch: 85
Loss: 0.2692110654500316
ROC train: 0.974585	val: 0.832556	test: 0.733824
PRC train: 0.973038	val: 0.420663	test: 0.852210

Epoch: 86
Loss: 0.2937319986882938
ROC train: 0.975660	val: 0.833916	test: 0.729085
PRC train: 0.974023	val: 0.403582	test: 0.846602

Epoch: 87
Loss: 0.2731335879565685
ROC train: 0.976711	val: 0.835470	test: 0.716155
PRC train: 0.975249	val: 0.423652	test: 0.836213

Epoch: 88
Loss: 0.26497232362420897
ROC train: 0.977504	val: 0.830322	test: 0.715073
PRC train: 0.975964	val: 0.405607	test: 0.837888

Epoch: 89
Loss: 0.25246713752602606
ROC train: 0.977149	val: 0.827117	test: 0.719143
PRC train: 0.975591	val: 0.417969	test: 0.844403

Epoch: 90
Loss: 0.25226327910110197
ROC train: 0.975680	val: 0.831002	test: 0.709304
PRC train: 0.973874	val: 0.423942	test: 0.836314

Epoch: 91
Loss: 0.2553157291402888
ROC train: 0.976643	val: 0.830031	test: 0.705079
PRC train: 0.974765	val: 0.398432	test: 0.829682

Epoch: 92
Loss: 0.25734702047000857
ROC train: 0.977991	val: 0.828574	test: 0.706110
PRC train: 0.976273	val: 0.391376	test: 0.821560

Epoch: 93
Loss: 0.2601601192466745
ROC train: 0.975319	val: 0.831488	test: 0.695292
PRC train: 0.973825	val: 0.399660	test: 0.811506

Epoch: 94
Loss: 0.25523576109918616
ROC train: 0.974054	val: 0.827700	test: 0.695755
PRC train: 0.900156	val: 0.447205	test: 0.889810

Epoch: 34
Loss: 0.3600131270688521
ROC train: 0.929685	val: 0.734989	test: 0.766883
PRC train: 0.902920	val: 0.458662	test: 0.875086

Epoch: 35
Loss: 0.36001342680844506
ROC train: 0.931772	val: 0.737209	test: 0.770946
PRC train: 0.907684	val: 0.451958	test: 0.878532

Epoch: 36
Loss: 0.35507232915599707
ROC train: 0.935827	val: 0.730761	test: 0.774106
PRC train: 0.914810	val: 0.437926	test: 0.880281

Epoch: 37
Loss: 0.33774563390511936
ROC train: 0.939583	val: 0.726216	test: 0.782774
PRC train: 0.920925	val: 0.421320	test: 0.882543

Epoch: 38
Loss: 0.37234354622774657
ROC train: 0.940735	val: 0.722093	test: 0.785843
PRC train: 0.922341	val: 0.418374	test: 0.883841

Epoch: 39
Loss: 0.34836386781399425
ROC train: 0.941886	val: 0.726216	test: 0.799837
PRC train: 0.923460	val: 0.419946	test: 0.894515

Epoch: 40
Loss: 0.33972642215768356
ROC train: 0.940706	val: 0.720507	test: 0.827284
PRC train: 0.921691	val: 0.415737	test: 0.912376

Epoch: 41
Loss: 0.37282429130655836
ROC train: 0.943135	val: 0.723573	test: 0.824756
PRC train: 0.924724	val: 0.419541	test: 0.913758

Epoch: 42
Loss: 0.3402187898072219
ROC train: 0.943113	val: 0.718499	test: 0.806248
PRC train: 0.924500	val: 0.404576	test: 0.902549

Epoch: 43
Loss: 0.3793757444516541
ROC train: 0.944308	val: 0.713848	test: 0.810401
PRC train: 0.927522	val: 0.388651	test: 0.903830

Epoch: 44
Loss: 0.367082734815539
ROC train: 0.944822	val: 0.717019	test: 0.829451
PRC train: 0.928911	val: 0.391951	test: 0.912769

Epoch: 45
Loss: 0.3750675921507093
ROC train: 0.943844	val: 0.723256	test: 0.830625
PRC train: 0.927924	val: 0.401024	test: 0.910719

Epoch: 46
Loss: 0.3333481916820255
ROC train: 0.948888	val: 0.735729	test: 0.821687
PRC train: 0.933718	val: 0.415182	test: 0.904159

Epoch: 47
Loss: 0.33542848416719656
ROC train: 0.946798	val: 0.738478	test: 0.802546
PRC train: 0.930774	val: 0.419262	test: 0.894237

Epoch: 48
Loss: 0.3775156440896018
ROC train: 0.945974	val: 0.740592	test: 0.797941
PRC train: 0.930135	val: 0.421698	test: 0.890904

Epoch: 49
Loss: 0.311345755443872
ROC train: 0.948068	val: 0.730655	test: 0.799296
PRC train: 0.932373	val: 0.423213	test: 0.895630

Epoch: 50
Loss: 0.32193818478286895
ROC train: 0.947802	val: 0.724841	test: 0.802365
PRC train: 0.932160	val: 0.415594	test: 0.899417

Epoch: 51
Loss: 0.31823675141751784
ROC train: 0.951083	val: 0.719556	test: 0.805435
PRC train: 0.935552	val: 0.416562	test: 0.900423

Epoch: 52
Loss: 0.33633185023538165
ROC train: 0.951011	val: 0.716913	test: 0.815728
PRC train: 0.936842	val: 0.412266	test: 0.907004

Epoch: 53
Loss: 0.3533298375325976
ROC train: 0.951630	val: 0.726638	test: 0.818617
PRC train: 0.938349	val: 0.404887	test: 0.906432

Epoch: 54
Loss: 0.3413598953426445
ROC train: 0.952166	val: 0.736364	test: 0.802817
PRC train: 0.938770	val: 0.413018	test: 0.898129

Epoch: 55
Loss: 0.3395692665292648
ROC train: 0.953314	val: 0.738584	test: 0.798032
PRC train: 0.940401	val: 0.415927	test: 0.894351

Epoch: 56
Loss: 0.3220000345530162
ROC train: 0.953796	val: 0.741332	test: 0.775280
PRC train: 0.940257	val: 0.426504	test: 0.879073

Epoch: 57
Loss: 0.3371130980260914
ROC train: 0.952080	val: 0.732452	test: 0.768418
PRC train: 0.938091	val: 0.420465	test: 0.874338

Epoch: 58
Loss: 0.30529609485287856
ROC train: 0.954203	val: 0.732452	test: 0.773926
PRC train: 0.942107	val: 0.421018	test: 0.874340

Epoch: 59
Loss: 0.3005565663455566
ROC train: 0.952601	val: 0.732664	test: 0.782232
PRC train: 0.941100	val: 0.416496	test: 0.880898

Epoch: 60
Loss: 0.3555267336621181
ROC train: 0.955408	val: 0.734672	test: 0.806157
PRC train: 0.943398	val: 0.414571	test: 0.897606

Epoch: 61
Loss: 0.330613703999891
ROC train: 0.953440	val: 0.724101	test: 0.794150
PRC train: 0.941196	val: 0.410447	test: 0.889562

Epoch: 62
Loss: 0.34841203892478373
ROC train: 0.954678	val: 0.710148	test: 0.772932
PRC train: 0.943268	val: 0.409926	test: 0.873939

Epoch: 63
Loss: 0.2892946904562407
ROC train: 0.956595	val: 0.716808	test: 0.765258
PRC train: 0.944959	val: 0.411105	test: 0.873128

Epoch: 64
Loss: 0.3235179575402086
ROC train: 0.957549	val: 0.721776	test: 0.792254
PRC train: 0.946173	val: 0.402752	test: 0.893690

Epoch: 65
Loss: 0.3293940518088344
ROC train: 0.957581	val: 0.722939	test: 0.811304
PRC train: 0.945223	val: 0.400812	test: 0.906000

Epoch: 66
Loss: 0.28366866043431804
ROC train: 0.959945	val: 0.731924	test: 0.815457
PRC train: 0.947406	val: 0.413685	test: 0.906907

Epoch: 67
Loss: 0.2978703333381872
ROC train: 0.961341	val: 0.740063	test: 0.799476
PRC train: 0.949583	val: 0.415700	test: 0.894240

Epoch: 68
Loss: 0.3281585940753738
ROC train: 0.960575	val: 0.743340	test: 0.792795
PRC train: 0.949920	val: 0.423853	test: 0.892070

Epoch: 69
Loss: 0.2942055792748527
ROC train: 0.958463	val: 0.737104	test: 0.786927
PRC train: 0.948416	val: 0.415644	test: 0.887299

Epoch: 70
Loss: 0.30658325419724297
ROC train: 0.959956	val: 0.737844	test: 0.782232
PRC train: 0.950323	val: 0.418995	test: 0.884291

Epoch: 71
Loss: 0.317989346635952
ROC train: 0.957948	val: 0.730867	test: 0.792615
PRC train: 0.946328	val: 0.427804	test: 0.891737

Epoch: 72
Loss: 0.3152817860876334
ROC train: 0.960050	val: 0.732347	test: 0.793247
PRC train: 0.948809	val: 0.422947	test: 0.891964

Epoch: 73
Loss: 0.2981015198499071
ROC train: 0.961309	val: 0.727167	test: 0.799386
PRC train: 0.951223	val: 0.411806	test: 0.894073

Epoch: 74
Loss: 0.29857295835199815
ROC train: 0.961647	val: 0.724419	test: 0.793066
PRC train: 0.952196	val: 0.403204	test: 0.888781

Epoch: 75
Loss: 0.3029104490877044
ROC train: 0.963022	val: 0.734989	test: 0.793247
PRC train: 0.954759	val: 0.405953	test: 0.892421

Epoch: 76
Loss: 0.28500333800220445
ROC train: 0.964767	val: 0.736469	test: 0.793247
PRC train: 0.957067	val: 0.408085	test: 0.889266

Epoch: 77
Loss: 0.274838459834561
ROC train: 0.966213	val: 0.732347	test: 0.783857
PRC train: 0.958178	val: 0.411753	test: 0.879165

Epoch: 78
Loss: 0.32421309433007817
ROC train: 0.965580	val: 0.738372	test: 0.776454
PRC train: 0.957341	val: 0.421099	test: 0.870821

Epoch: 79
Loss: 0.3128980953164163
ROC train: 0.960111	val: 0.740698	test: 0.761286
PRC train: 0.950673	val: 0.427044	test: 0.860557

Epoch: 80
Loss: 0.3044231604612854
ROC train: 0.957578	val: 0.746089	test: 0.767876
PRC train: 0.948473	val: 0.429826	test: 0.853719

Epoch: 81
Loss: 0.30534020225436775
ROC train: 0.959107	val: 0.750317	test: 0.799025
PRC train: 0.951913	val: 0.431264	test: 0.883837

Epoch: 82
Loss: 0.29316641913684804
ROC train: 0.962576	val: 0.748309	test: 0.801463
PRC train: 0.954997	val: 0.440902	test: 0.889894

Epoch: 83
Loss: 0.3163678493685017
ROC train: 0.965004	val: 0.747992	test: 0.788552
PRC train: 0.956572	val: 0.442883	test: 0.880686

Epoch: 84
Loss: 0.3253239292408501
ROC train: 0.965127	val: 0.743340	test: 0.756591
PRC train: 0.956563	val: 0.436618	test: 0.851535

Epoch: 85
Loss: 0.2605884593384641
ROC train: 0.965753	val: 0.745032	test: 0.778079
PRC train: 0.957541	val: 0.426135	test: 0.873747

Epoch: 86
Loss: 0.28958075166716835
ROC train: 0.966688	val: 0.749894	test: 0.803449
PRC train: 0.957749	val: 0.428248	test: 0.896621

Epoch: 87
Loss: 0.29206382804816167
ROC train: 0.968293	val: 0.755497	test: 0.801101
PRC train: 0.959849	val: 0.429956	test: 0.895776

Epoch: 88
Loss: 0.2677273139549635
ROC train: 0.966246	val: 0.749789	test: 0.793788
PRC train: 0.957128	val: 0.423363	test: 0.892275

Epoch: 89
Loss: 0.28655567243750324
ROC train: 0.966987	val: 0.737844	test: 0.782051
PRC train: 0.958053	val: 0.416037	test: 0.881047

Epoch: 90
Loss: 0.2639818676290832
ROC train: 0.967016	val: 0.726850	test: 0.771578
PRC train: 0.958158	val: 0.411319	test: 0.869834

Epoch: 91
Loss: 0.2905160041571651
ROC train: 0.969056	val: 0.724101	test: 0.778620
PRC train: 0.961331	val: 0.409434	test: 0.869882

Epoch: 92
Loss: 0.2706757228035978
ROC train: 0.968653	val: 0.726110	test: 0.774828
PRC train: 0.961135	val: 0.416938	test: 0.867137

Epoch: 93
Loss: 0.32545424773883835
ROC train: 0.968959	val: 0.730973	test: 0.778530
PRC train: 0.961235	val: 0.416658	test: 0.871441

Epoch: 94
Loss: 0.29651271137709373
ROC train: 0.969804	val: 0.730127	test: 0.777086
ROC train: 0.930257	val: 0.673467	test: 0.782864
PRC train: 0.906528	val: 0.370453	test: 0.878630

Epoch: 34
Loss: 0.3755746182212928
ROC train: 0.938889	val: 0.708351	test: 0.793518
PRC train: 0.915408	val: 0.400258	test: 0.887550

Epoch: 35
Loss: 0.34006260380981496
ROC train: 0.934823	val: 0.729810	test: 0.808595
PRC train: 0.909888	val: 0.418532	test: 0.894757

Epoch: 36
Loss: 0.3891175944779605
ROC train: 0.932265	val: 0.729493	test: 0.806699
PRC train: 0.908734	val: 0.424521	test: 0.894749

Epoch: 37
Loss: 0.3874981469751712
ROC train: 0.934060	val: 0.712368	test: 0.811033
PRC train: 0.912392	val: 0.407982	test: 0.895427

Epoch: 38
Loss: 0.33868963708527844
ROC train: 0.934136	val: 0.704228	test: 0.803268
PRC train: 0.912460	val: 0.405765	test: 0.888334

Epoch: 39
Loss: 0.3386682116903005
ROC train: 0.938338	val: 0.711839	test: 0.785302
PRC train: 0.919555	val: 0.419572	test: 0.880307

Epoch: 40
Loss: 0.35646860859264795
ROC train: 0.940853	val: 0.717442	test: 0.792073
PRC train: 0.922562	val: 0.422848	test: 0.884542

Epoch: 41
Loss: 0.35911904455972676
ROC train: 0.940746	val: 0.721353	test: 0.806338
PRC train: 0.922329	val: 0.427455	test: 0.886831

Epoch: 42
Loss: 0.340645269342937
ROC train: 0.940163	val: 0.729810	test: 0.807963
PRC train: 0.921362	val: 0.437391	test: 0.888862

Epoch: 43
Loss: 0.34985408261644985
ROC train: 0.941721	val: 0.719556	test: 0.821506
PRC train: 0.923224	val: 0.422721	test: 0.900573

Epoch: 44
Loss: 0.3501254303200497
ROC train: 0.941231	val: 0.718816	test: 0.835681
PRC train: 0.924653	val: 0.415144	test: 0.908985

Epoch: 45
Loss: 0.34184376455196225
ROC train: 0.944858	val: 0.722516	test: 0.830625
PRC train: 0.930330	val: 0.409694	test: 0.906176

Epoch: 46
Loss: 0.3692792253011386
ROC train: 0.945679	val: 0.727696	test: 0.819520
PRC train: 0.931016	val: 0.411725	test: 0.902836

Epoch: 47
Loss: 0.3336217415839966
ROC train: 0.942930	val: 0.723890	test: 0.799205
PRC train: 0.927717	val: 0.423167	test: 0.890106

Epoch: 48
Loss: 0.34836509919079195
ROC train: 0.948241	val: 0.717442	test: 0.803449
PRC train: 0.933424	val: 0.419792	test: 0.892196

Epoch: 49
Loss: 0.31289376884182396
ROC train: 0.948874	val: 0.720085	test: 0.822770
PRC train: 0.933334	val: 0.405401	test: 0.903319

Epoch: 50
Loss: 0.3303346358282414
ROC train: 0.952515	val: 0.716490	test: 0.820061
PRC train: 0.939034	val: 0.393580	test: 0.901895

Epoch: 51
Loss: 0.33199056614798683
ROC train: 0.952037	val: 0.721142	test: 0.832250
PRC train: 0.938807	val: 0.407570	test: 0.909120

Epoch: 52
Loss: 0.3482302148634881
ROC train: 0.950957	val: 0.730233	test: 0.833965
PRC train: 0.937736	val: 0.419193	test: 0.907088

Epoch: 53
Loss: 0.3819197751155975
ROC train: 0.952767	val: 0.725476	test: 0.829902
PRC train: 0.939242	val: 0.414206	test: 0.900069

Epoch: 54
Loss: 0.3372317340842589
ROC train: 0.952911	val: 0.715962	test: 0.832340
PRC train: 0.939655	val: 0.398989	test: 0.898865

Epoch: 55
Loss: 0.31318478419861756
ROC train: 0.954210	val: 0.713742	test: 0.837486
PRC train: 0.942068	val: 0.398440	test: 0.904973

Epoch: 56
Loss: 0.3289848840974076
ROC train: 0.947481	val: 0.713953	test: 0.825659
PRC train: 0.932372	val: 0.395706	test: 0.899918

Epoch: 57
Loss: 0.3265564064145578
ROC train: 0.949863	val: 0.724841	test: 0.815096
PRC train: 0.935444	val: 0.406724	test: 0.894825

Epoch: 58
Loss: 0.33456805642375265
ROC train: 0.954228	val: 0.731078	test: 0.804893
PRC train: 0.943480	val: 0.417851	test: 0.888785

Epoch: 59
Loss: 0.3430971622842388
ROC train: 0.955340	val: 0.724841	test: 0.811845
PRC train: 0.944276	val: 0.398982	test: 0.891302

Epoch: 60
Loss: 0.3435118883963819
ROC train: 0.952530	val: 0.722939	test: 0.829993
PRC train: 0.940833	val: 0.393820	test: 0.903029

Epoch: 61
Loss: 0.35693628220525336
ROC train: 0.952371	val: 0.720402	test: 0.795052
PRC train: 0.941717	val: 0.392370	test: 0.886146

Epoch: 62
Loss: 0.3240088102491595
ROC train: 0.954494	val: 0.723996	test: 0.782864
PRC train: 0.943631	val: 0.411546	test: 0.876901

Epoch: 63
Loss: 0.28635785216114773
ROC train: 0.954872	val: 0.725581	test: 0.798122
PRC train: 0.944179	val: 0.417823	test: 0.884128

Epoch: 64
Loss: 0.305699052944041
ROC train: 0.954746	val: 0.729493	test: 0.813561
PRC train: 0.942981	val: 0.418969	test: 0.892304

Epoch: 65
Loss: 0.3175490745395962
ROC train: 0.957117	val: 0.718288	test: 0.808776
PRC train: 0.946631	val: 0.408529	test: 0.891483

Epoch: 66
Loss: 0.29910751409852454
ROC train: 0.960078	val: 0.718710	test: 0.808505
PRC train: 0.950546	val: 0.410674	test: 0.891187

Epoch: 67
Loss: 0.2937497864218387
ROC train: 0.962666	val: 0.727484	test: 0.799205
PRC train: 0.954338	val: 0.416259	test: 0.886089

Epoch: 68
Loss: 0.3143210403077864
ROC train: 0.960485	val: 0.736575	test: 0.794150
PRC train: 0.951484	val: 0.423565	test: 0.882967

Epoch: 69
Loss: 0.3202256259695348
ROC train: 0.960910	val: 0.737315	test: 0.794601
PRC train: 0.951965	val: 0.423568	test: 0.881370

Epoch: 70
Loss: 0.3135061402027776
ROC train: 0.960312	val: 0.735518	test: 0.813561
PRC train: 0.950920	val: 0.426376	test: 0.891079

Epoch: 71
Loss: 0.29028913798020983
ROC train: 0.963230	val: 0.717865	test: 0.810401
PRC train: 0.954941	val: 0.405811	test: 0.880696

Epoch: 72
Loss: 0.36842194755622254
ROC train: 0.960823	val: 0.713953	test: 0.804532
PRC train: 0.952321	val: 0.406675	test: 0.878997

Epoch: 73
Loss: 0.31124564894536105
ROC train: 0.960341	val: 0.726744	test: 0.808505
PRC train: 0.951837	val: 0.413095	test: 0.885943

Epoch: 74
Loss: 0.2842114225954139
ROC train: 0.963051	val: 0.730973	test: 0.809137
PRC train: 0.953560	val: 0.424496	test: 0.880830

Epoch: 75
Loss: 0.27926809338979125
ROC train: 0.966803	val: 0.719662	test: 0.801914
PRC train: 0.957903	val: 0.429340	test: 0.875409

Epoch: 76
Loss: 0.2751035688486939
ROC train: 0.967048	val: 0.713848	test: 0.791080
PRC train: 0.958604	val: 0.422435	test: 0.870764

Epoch: 77
Loss: 0.27468997607449197
ROC train: 0.964630	val: 0.703488	test: 0.799115
PRC train: 0.955944	val: 0.406808	test: 0.880165

Epoch: 78
Loss: 0.3295753762973203
ROC train: 0.967088	val: 0.699366	test: 0.801372
PRC train: 0.959381	val: 0.400504	test: 0.880565

Epoch: 79
Loss: 0.27554259793608943
ROC train: 0.965954	val: 0.710465	test: 0.804893
PRC train: 0.958513	val: 0.413338	test: 0.883899

Epoch: 80
Loss: 0.28433452862852493
ROC train: 0.967782	val: 0.707188	test: 0.822951
PRC train: 0.960183	val: 0.402681	test: 0.894064

Epoch: 81
Loss: 0.270140726362312
ROC train: 0.965030	val: 0.706554	test: 0.824937
PRC train: 0.956649	val: 0.403530	test: 0.894278

Epoch: 82
Loss: 0.2876005829446797
ROC train: 0.966566	val: 0.717548	test: 0.813380
PRC train: 0.959011	val: 0.413519	test: 0.888090

Epoch: 83
Loss: 0.29130694096872156
ROC train: 0.967501	val: 0.730867	test: 0.800831
PRC train: 0.961028	val: 0.424574	test: 0.875818

Epoch: 84
Loss: 0.30328731045536533
ROC train: 0.968120	val: 0.732030	test: 0.776092
PRC train: 0.961485	val: 0.429717	test: 0.860859

Epoch: 85
Loss: 0.28433834559276305
ROC train: 0.966973	val: 0.740169	test: 0.787468
PRC train: 0.958769	val: 0.434253	test: 0.869476

Epoch: 86
Loss: 0.2895998320394705
ROC train: 0.967901	val: 0.739535	test: 0.790448
PRC train: 0.960690	val: 0.432213	test: 0.873973

Epoch: 87
Loss: 0.2811516010339505
ROC train: 0.970103	val: 0.725793	test: 0.782232
PRC train: 0.963959	val: 0.414836	test: 0.866486

Epoch: 88
Loss: 0.2979701531485881
ROC train: 0.969549	val: 0.732135	test: 0.789184
PRC train: 0.963581	val: 0.425041	test: 0.878257

Epoch: 89
Loss: 0.29093709781023447
ROC train: 0.965285	val: 0.735307	test: 0.801733
PRC train: 0.955420	val: 0.435008	test: 0.889311

Epoch: 90
Loss: 0.2744481652583567
ROC train: 0.966904	val: 0.734989	test: 0.820513
PRC train: 0.958708	val: 0.428500	test: 0.896555

Epoch: 91
Loss: 0.30308677133059725
ROC train: 0.968311	val: 0.724101	test: 0.804713
PRC train: 0.961300	val: 0.409224	test: 0.886887

Epoch: 92
Loss: 0.2712210396361374
ROC train: 0.968602	val: 0.726110	test: 0.797129
PRC train: 0.962246	val: 0.425237	test: 0.885764

Epoch: 93
Loss: 0.2982228845507538
ROC train: 0.966847	val: 0.735095	test: 0.796226
PRC train: 0.959756	val: 0.435401	test: 0.889053

Epoch: 94
Loss: 0.32851413450703415
PRC train: 0.918348	val: 0.411556	test: 0.884179

Epoch: 34
Loss: 0.32165171723232067
ROC train: 0.934726	val: 0.718605	test: 0.764807
PRC train: 0.915777	val: 0.421154	test: 0.875183

Epoch: 35
Loss: 0.3677704969505735
ROC train: 0.939932	val: 0.721882	test: 0.776724
PRC train: 0.922323	val: 0.414078	test: 0.877696

Epoch: 36
Loss: 0.3351088847634158
ROC train: 0.943887	val: 0.723467	test: 0.807512
PRC train: 0.928258	val: 0.411812	test: 0.890430

Epoch: 37
Loss: 0.3294976101896148
ROC train: 0.943833	val: 0.727590	test: 0.815457
PRC train: 0.928306	val: 0.412197	test: 0.894063

Epoch: 38
Loss: 0.36140609840318627
ROC train: 0.943012	val: 0.719767	test: 0.800921
PRC train: 0.927711	val: 0.409342	test: 0.885086

Epoch: 39
Loss: 0.3537280688593973
ROC train: 0.943156	val: 0.709514	test: 0.779614
PRC train: 0.929485	val: 0.404928	test: 0.874318

Epoch: 40
Loss: 0.32842409286529045
ROC train: 0.945060	val: 0.715222	test: 0.780336
PRC train: 0.932209	val: 0.399367	test: 0.876008

Epoch: 41
Loss: 0.3265250734747275
ROC train: 0.948244	val: 0.715116	test: 0.795143
PRC train: 0.935238	val: 0.395380	test: 0.885579

Epoch: 42
Loss: 0.3442598120124559
ROC train: 0.946427	val: 0.711628	test: 0.797761
PRC train: 0.932476	val: 0.405946	test: 0.888277

Epoch: 43
Loss: 0.3523822819718838
ROC train: 0.945394	val: 0.710359	test: 0.794962
PRC train: 0.931055	val: 0.409946	test: 0.891881

Epoch: 44
Loss: 0.3502997257290974
ROC train: 0.944937	val: 0.713636	test: 0.784399
PRC train: 0.928928	val: 0.415325	test: 0.886002

Epoch: 45
Loss: 0.3394709744606049
ROC train: 0.947467	val: 0.725581	test: 0.793788
PRC train: 0.933313	val: 0.412186	test: 0.885950

Epoch: 46
Loss: 0.3370363809925247
ROC train: 0.945801	val: 0.720296	test: 0.786114
PRC train: 0.931874	val: 0.388397	test: 0.875755

Epoch: 47
Loss: 0.3185123701953571
ROC train: 0.946456	val: 0.719450	test: 0.775460
PRC train: 0.931356	val: 0.385521	test: 0.867361

Epoch: 48
Loss: 0.36201976103597794
ROC train: 0.949924	val: 0.722093	test: 0.763182
PRC train: 0.936935	val: 0.397256	test: 0.865355

Epoch: 49
Loss: 0.33702129689161786
ROC train: 0.950439	val: 0.713636	test: 0.754514
PRC train: 0.938434	val: 0.391572	test: 0.864693

Epoch: 50
Loss: 0.3414394099773973
ROC train: 0.949414	val: 0.706554	test: 0.773113
PRC train: 0.937677	val: 0.385076	test: 0.877126

Epoch: 51
Loss: 0.3262746365470062
ROC train: 0.945243	val: 0.713953	test: 0.794601
PRC train: 0.931506	val: 0.394977	test: 0.887417

Epoch: 52
Loss: 0.3345844238547493
ROC train: 0.949208	val: 0.725053	test: 0.798483
PRC train: 0.934839	val: 0.396315	test: 0.888927

Epoch: 53
Loss: 0.32492659103514954
ROC train: 0.955275	val: 0.720507	test: 0.794962
PRC train: 0.944507	val: 0.390382	test: 0.888945

Epoch: 54
Loss: 0.33335858570102445
ROC train: 0.956491	val: 0.705391	test: 0.792976
PRC train: 0.947022	val: 0.378235	test: 0.889671

Epoch: 55
Loss: 0.30951996607248755
ROC train: 0.957394	val: 0.705074	test: 0.796046
PRC train: 0.948281	val: 0.388070	test: 0.889514

Epoch: 56
Loss: 0.3410896045918877
ROC train: 0.958387	val: 0.718605	test: 0.792976
PRC train: 0.948834	val: 0.400518	test: 0.884446

Epoch: 57
Loss: 0.29320088993840193
ROC train: 0.958654	val: 0.734038	test: 0.788100
PRC train: 0.948170	val: 0.414501	test: 0.879539

Epoch: 58
Loss: 0.2891509017885781
ROC train: 0.958045	val: 0.740592	test: 0.788913
PRC train: 0.947356	val: 0.413638	test: 0.879566

Epoch: 59
Loss: 0.31503125986764047
ROC train: 0.958161	val: 0.739429	test: 0.793247
PRC train: 0.947527	val: 0.418716	test: 0.878459

Epoch: 60
Loss: 0.27853677088377726
ROC train: 0.960834	val: 0.734249	test: 0.782774
PRC train: 0.950547	val: 0.417377	test: 0.873703

Epoch: 61
Loss: 0.3279921877316581
ROC train: 0.957034	val: 0.726533	test: 0.767064
PRC train: 0.945826	val: 0.400405	test: 0.866402

Epoch: 62
Loss: 0.28429021664850646
ROC train: 0.954343	val: 0.724524	test: 0.757765
PRC train: 0.940898	val: 0.386566	test: 0.858420

Epoch: 63
Loss: 0.30914338000170555
ROC train: 0.953030	val: 0.723362	test: 0.751986
PRC train: 0.941100	val: 0.383246	test: 0.854689

Epoch: 64
Loss: 0.30599811302902896
ROC train: 0.955919	val: 0.725053	test: 0.756139
PRC train: 0.948143	val: 0.389397	test: 0.858213

Epoch: 65
Loss: 0.3420326820680683
ROC train: 0.962043	val: 0.735095	test: 0.780697
PRC train: 0.953750	val: 0.399704	test: 0.872924

Epoch: 66
Loss: 0.3140053461335881
ROC train: 0.962165	val: 0.737421	test: 0.790267
PRC train: 0.952286	val: 0.409294	test: 0.873387

Epoch: 67
Loss: 0.2995422340662131
ROC train: 0.959370	val: 0.727273	test: 0.771036
PRC train: 0.949969	val: 0.400221	test: 0.854517

Epoch: 68
Loss: 0.3022257582486005
ROC train: 0.957074	val: 0.727696	test: 0.767967
PRC train: 0.946506	val: 0.399586	test: 0.852068

Epoch: 69
Loss: 0.30247266229996217
ROC train: 0.959942	val: 0.731078	test: 0.778169
PRC train: 0.948435	val: 0.402142	test: 0.862985

Epoch: 70
Loss: 0.2915213826120568
ROC train: 0.960881	val: 0.731290	test: 0.768328
PRC train: 0.948501	val: 0.408782	test: 0.860262

Epoch: 71
Loss: 0.3105591187055161
ROC train: 0.962101	val: 0.737844	test: 0.762189
PRC train: 0.950163	val: 0.416387	test: 0.854312

Epoch: 72
Loss: 0.2977127308926622
ROC train: 0.962698	val: 0.739958	test: 0.777266
PRC train: 0.952876	val: 0.413649	test: 0.861787

Epoch: 73
Loss: 0.334731660454299
ROC train: 0.961370	val: 0.734461	test: 0.761286
PRC train: 0.952059	val: 0.408195	test: 0.852953

Epoch: 74
Loss: 0.2969944976295335
ROC train: 0.960298	val: 0.726110	test: 0.776273
PRC train: 0.949971	val: 0.402930	test: 0.863047

Epoch: 75
Loss: 0.2918886267636576
ROC train: 0.960812	val: 0.729070	test: 0.774558
PRC train: 0.950489	val: 0.411860	test: 0.866157

Epoch: 76
Loss: 0.27608985395765
ROC train: 0.960323	val: 0.725159	test: 0.765890
PRC train: 0.949811	val: 0.421723	test: 0.863672

Epoch: 77
Loss: 0.28033389303634176
ROC train: 0.965666	val: 0.733404	test: 0.784489
PRC train: 0.956191	val: 0.424969	test: 0.865196

Epoch: 78
Loss: 0.3048889587842843
ROC train: 0.965576	val: 0.731078	test: 0.778350
PRC train: 0.957016	val: 0.400494	test: 0.855693

Epoch: 79
Loss: 0.2886110635144434
ROC train: 0.964889	val: 0.733932	test: 0.784670
PRC train: 0.957149	val: 0.406041	test: 0.863203

Epoch: 80
Loss: 0.27544397649844765
ROC train: 0.962284	val: 0.735518	test: 0.790899
PRC train: 0.952767	val: 0.413795	test: 0.871055

Epoch: 81
Loss: 0.27007409415077543
ROC train: 0.962349	val: 0.734461	test: 0.786295
PRC train: 0.953717	val: 0.411389	test: 0.873685

Epoch: 82
Loss: 0.2751917862250236
ROC train: 0.963302	val: 0.733298	test: 0.787559
PRC train: 0.955008	val: 0.412007	test: 0.874988

Epoch: 83
Loss: 0.2930304429218092
ROC train: 0.966559	val: 0.735835	test: 0.780878
PRC train: 0.958730	val: 0.409177	test: 0.869062

Epoch: 84
Loss: 0.2424477711499438
ROC train: 0.965648	val: 0.741966	test: 0.778350
PRC train: 0.957371	val: 0.419018	test: 0.869326

Epoch: 85
Loss: 0.26691687326865765
ROC train: 0.966426	val: 0.739006	test: 0.769231
PRC train: 0.958347	val: 0.410996	test: 0.863664

Epoch: 86
Loss: 0.29016642901474293
ROC train: 0.968516	val: 0.733298	test: 0.773926
PRC train: 0.961782	val: 0.405452	test: 0.864928

Epoch: 87
Loss: 0.2979452431113662
ROC train: 0.969840	val: 0.729070	test: 0.757133
PRC train: 0.962937	val: 0.397490	test: 0.852444

Epoch: 88
Loss: 0.2607829044839488
ROC train: 0.969387	val: 0.731501	test: 0.780968
PRC train: 0.962880	val: 0.407949	test: 0.868858

Epoch: 89
Loss: 0.28063492878454177
ROC train: 0.969545	val: 0.731924	test: 0.786927
PRC train: 0.962630	val: 0.414089	test: 0.873486

Epoch: 90
Loss: 0.2681294133756903
ROC train: 0.968448	val: 0.742283	test: 0.782954
PRC train: 0.960381	val: 0.417560	test: 0.868181

Epoch: 91
Loss: 0.317316422161704
ROC train: 0.966246	val: 0.745137	test: 0.765800
PRC train: 0.958055	val: 0.426242	test: 0.856897

Epoch: 92
Loss: 0.25337113652052684
ROC train: 0.967073	val: 0.739006	test: 0.746930
PRC train: 0.960027	val: 0.423528	test: 0.851595

Epoch: 93
Loss: 0.28491852062897927
ROC train: 0.970880	val: 0.744397	test: 0.766883
PRC train: 0.964373	val: 0.419904	test: 0.866960

Epoch: 94
Loss: 0.27929799139426287
ROC train: 0.971769	val: 0.743129	test: 0.773113ROC train: 0.943710	val: 0.667033	test: 0.758825
PRC train: 0.908262	val: 0.922125	test: 0.734560

Epoch: 34
Loss: 0.322715586693362
ROC train: 0.945103	val: 0.673260	test: 0.770127
PRC train: 0.910641	val: 0.922134	test: 0.742446

Epoch: 35
Loss: 0.3372013777675443
ROC train: 0.947620	val: 0.673260	test: 0.771866
PRC train: 0.915355	val: 0.921768	test: 0.743511

Epoch: 36
Loss: 0.34729638906330523
ROC train: 0.949161	val: 0.657509	test: 0.771518
PRC train: 0.919866	val: 0.918514	test: 0.746034

Epoch: 37
Loss: 0.31880075615530423
ROC train: 0.946678	val: 0.663736	test: 0.772040
PRC train: 0.916414	val: 0.920359	test: 0.754179

Epoch: 38
Loss: 0.32632267024725914
ROC train: 0.951193	val: 0.658608	test: 0.778126
PRC train: 0.923020	val: 0.919474	test: 0.764383

Epoch: 39
Loss: 0.33127249265680697
ROC train: 0.951658	val: 0.663370	test: 0.780212
PRC train: 0.923336	val: 0.919830	test: 0.763356

Epoch: 40
Loss: 0.31928662880241965
ROC train: 0.950471	val: 0.660073	test: 0.764737
PRC train: 0.922230	val: 0.918726	test: 0.743419

Epoch: 41
Loss: 0.3505123356888124
ROC train: 0.952783	val: 0.643590	test: 0.756564
PRC train: 0.926455	val: 0.912832	test: 0.739665

Epoch: 42
Loss: 0.3141199008559089
ROC train: 0.953924	val: 0.648352	test: 0.770996
PRC train: 0.928671	val: 0.914963	test: 0.757327

Epoch: 43
Loss: 0.3159297815777609
ROC train: 0.953493	val: 0.639927	test: 0.789602
PRC train: 0.926891	val: 0.912843	test: 0.772892

Epoch: 44
Loss: 0.3173525117317806
ROC train: 0.955177	val: 0.642491	test: 0.785776
PRC train: 0.929796	val: 0.915648	test: 0.768967

Epoch: 45
Loss: 0.3070355515646518
ROC train: 0.954501	val: 0.669231	test: 0.769431
PRC train: 0.928963	val: 0.924600	test: 0.751680

Epoch: 46
Loss: 0.30552598886296467
ROC train: 0.954315	val: 0.677656	test: 0.764041
PRC train: 0.928892	val: 0.924063	test: 0.758451

Epoch: 47
Loss: 0.3170431518407038
ROC train: 0.955551	val: 0.681319	test: 0.772040
PRC train: 0.932128	val: 0.923959	test: 0.751043

Epoch: 48
Loss: 0.30894917059036725
ROC train: 0.957880	val: 0.659707	test: 0.761607
PRC train: 0.935521	val: 0.917458	test: 0.737761

Epoch: 49
Loss: 0.29922664479806976
ROC train: 0.957608	val: 0.647619	test: 0.764910
PRC train: 0.935767	val: 0.908206	test: 0.750170

Epoch: 50
Loss: 0.29803698690977454
ROC train: 0.958422	val: 0.638828	test: 0.753608
PRC train: 0.936736	val: 0.908820	test: 0.735436

Epoch: 51
Loss: 0.3137869922545497
ROC train: 0.958134	val: 0.638462	test: 0.743523
PRC train: 0.936622	val: 0.909894	test: 0.733187

Epoch: 52
Loss: 0.29689904048323246
ROC train: 0.961281	val: 0.628571	test: 0.766823
PRC train: 0.941836	val: 0.910124	test: 0.759770

Epoch: 53
Loss: 0.2874877461234124
ROC train: 0.963296	val: 0.638828	test: 0.753434
PRC train: 0.944707	val: 0.915551	test: 0.752069

Epoch: 54
Loss: 0.2872444786075663
ROC train: 0.964212	val: 0.635165	test: 0.761085
PRC train: 0.944946	val: 0.913646	test: 0.754518

Epoch: 55
Loss: 0.28880335975357074
ROC train: 0.963342	val: 0.651648	test: 0.761781
PRC train: 0.943923	val: 0.917823	test: 0.753573

Epoch: 56
Loss: 0.271307960393301
ROC train: 0.963787	val: 0.657875	test: 0.758303
PRC train: 0.945027	val: 0.919686	test: 0.751308

Epoch: 57
Loss: 0.28500514779164754
ROC train: 0.964883	val: 0.662271	test: 0.746653
PRC train: 0.946807	val: 0.920560	test: 0.746716

Epoch: 58
Loss: 0.2797421869567236
ROC train: 0.968325	val: 0.654579	test: 0.753782
PRC train: 0.952872	val: 0.916769	test: 0.742785

Epoch: 59
Loss: 0.2747996004571748
ROC train: 0.970134	val: 0.650549	test: 0.763867
PRC train: 0.955958	val: 0.913762	test: 0.763566

Epoch: 60
Loss: 0.2837025797243194
ROC train: 0.967292	val: 0.649451	test: 0.752217
PRC train: 0.950730	val: 0.913660	test: 0.754505

Epoch: 61
Loss: 0.27929406584018646
ROC train: 0.967303	val: 0.659341	test: 0.745957
PRC train: 0.950812	val: 0.919633	test: 0.743960

Epoch: 62
Loss: 0.2763833137444592
ROC train: 0.967922	val: 0.618315	test: 0.749261
PRC train: 0.952002	val: 0.906064	test: 0.745410

Epoch: 63
Loss: 0.28341843555270463
ROC train: 0.969181	val: 0.627473	test: 0.740219
PRC train: 0.953386	val: 0.905693	test: 0.744228

Epoch: 64
Loss: 0.27916820368006345
ROC train: 0.968904	val: 0.645788	test: 0.728221
PRC train: 0.953320	val: 0.911762	test: 0.731222

Epoch: 65
Loss: 0.2730573005983748
ROC train: 0.971498	val: 0.641026	test: 0.736915
PRC train: 0.958203	val: 0.914326	test: 0.744879

Epoch: 66
Loss: 0.2692193950292874
ROC train: 0.972314	val: 0.612088	test: 0.742480
PRC train: 0.959834	val: 0.908699	test: 0.755172

Epoch: 67
Loss: 0.2605227795631279
ROC train: 0.971809	val: 0.650549	test: 0.727700
PRC train: 0.958641	val: 0.915820	test: 0.740042

Epoch: 68
Loss: 0.2661006940341156
ROC train: 0.969689	val: 0.646520	test: 0.736568
PRC train: 0.955065	val: 0.912385	test: 0.744932

Epoch: 69
Loss: 0.26235071906314805
ROC train: 0.970950	val: 0.612821	test: 0.734133
PRC train: 0.956888	val: 0.907100	test: 0.730429

Epoch: 70
Loss: 0.270654616088253
ROC train: 0.970537	val: 0.623810	test: 0.737263
PRC train: 0.954542	val: 0.908734	test: 0.737344

Epoch: 71
Loss: 0.2658757509363503
ROC train: 0.970576	val: 0.643590	test: 0.732916
PRC train: 0.954640	val: 0.915742	test: 0.734656

Epoch: 72
Loss: 0.2814441169133494
ROC train: 0.971826	val: 0.650549	test: 0.735003
PRC train: 0.958387	val: 0.913202	test: 0.737688

Epoch: 73
Loss: 0.25819337933102465
ROC train: 0.968553	val: 0.624542	test: 0.722483
PRC train: 0.953276	val: 0.908934	test: 0.718424

Epoch: 74
Loss: 0.2526143542855378
ROC train: 0.971738	val: 0.613919	test: 0.722657
PRC train: 0.957489	val: 0.909027	test: 0.722663

Epoch: 75
Loss: 0.2578396328564661
ROC train: 0.972971	val: 0.620513	test: 0.726135
PRC train: 0.960963	val: 0.908637	test: 0.727089

Epoch: 76
Loss: 0.27361884421803906
ROC train: 0.975805	val: 0.616484	test: 0.712919
PRC train: 0.964766	val: 0.907478	test: 0.713319

Epoch: 77
Loss: 0.2599460837046882
ROC train: 0.974755	val: 0.606960	test: 0.720396
PRC train: 0.963642	val: 0.905215	test: 0.713483

Epoch: 78
Loss: 0.23263809323545365
ROC train: 0.975205	val: 0.627106	test: 0.738654
PRC train: 0.963893	val: 0.908914	test: 0.722852

Epoch: 79
Loss: 0.25993680291483817
ROC train: 0.975197	val: 0.634799	test: 0.743697
PRC train: 0.963671	val: 0.907601	test: 0.727271

Epoch: 80
Loss: 0.2570690408878892
ROC train: 0.973005	val: 0.640293	test: 0.721961
PRC train: 0.960042	val: 0.913876	test: 0.725736

Epoch: 81
Loss: 0.259842618682278
ROC train: 0.974672	val: 0.634066	test: 0.730656
PRC train: 0.962442	val: 0.912273	test: 0.738108

Epoch: 82
Loss: 0.24343639405086312
ROC train: 0.977697	val: 0.625275	test: 0.730829
PRC train: 0.966337	val: 0.905688	test: 0.739846

Epoch: 83
Loss: 0.2583527522984383
ROC train: 0.975086	val: 0.627839	test: 0.716049
PRC train: 0.962739	val: 0.908633	test: 0.712131

Epoch: 84
Loss: 0.2491787080869443
ROC train: 0.977414	val: 0.638828	test: 0.717267
PRC train: 0.967348	val: 0.911015	test: 0.715446

Epoch: 85
Loss: 0.2572683743361993
ROC train: 0.978622	val: 0.634799	test: 0.700052
PRC train: 0.969525	val: 0.910121	test: 0.701655

Epoch: 86
Loss: 0.2470222717857628
ROC train: 0.978479	val: 0.643590	test: 0.703878
PRC train: 0.969293	val: 0.911807	test: 0.711618

Epoch: 87
Loss: 0.23288067299567783
ROC train: 0.980083	val: 0.634799	test: 0.723700
PRC train: 0.971201	val: 0.908246	test: 0.722936

Epoch: 88
Loss: 0.2419269868583808
ROC train: 0.980225	val: 0.630403	test: 0.723874
PRC train: 0.971665	val: 0.911946	test: 0.720431

Epoch: 89
Loss: 0.23248494781870538
ROC train: 0.979121	val: 0.646886	test: 0.716049
PRC train: 0.969346	val: 0.919266	test: 0.718871

Epoch: 90
Loss: 0.23098418985074498
ROC train: 0.979740	val: 0.650549	test: 0.708746
PRC train: 0.970966	val: 0.913192	test: 0.711709

Epoch: 91
Loss: 0.24256555770157825
ROC train: 0.983154	val: 0.609890	test: 0.725787
PRC train: 0.976195	val: 0.898104	test: 0.731550

Epoch: 92
Loss: 0.24102274476257404
ROC train: 0.981912	val: 0.613553	test: 0.730656
PRC train: 0.974269	val: 0.896336	test: 0.730121

Epoch: 93
Loss: 0.22723361543489165
ROC train: 0.980303	val: 0.621612	test: 0.715528
PRC train: 0.971764	val: 0.894360	test: 0.717427

Epoch: 94
Loss: 0.23100994049757637
PRC train: 0.917321	val: 0.928705	test: 0.732175

Epoch: 34
Loss: 0.3312140099382639
ROC train: 0.947220	val: 0.679487	test: 0.762650
PRC train: 0.915724	val: 0.929864	test: 0.742861

Epoch: 35
Loss: 0.34063347484293666
ROC train: 0.947868	val: 0.656410	test: 0.755347
PRC train: 0.915745	val: 0.926637	test: 0.742921

Epoch: 36
Loss: 0.32832201656350773
ROC train: 0.949498	val: 0.669597	test: 0.757260
PRC train: 0.918305	val: 0.928635	test: 0.742170

Epoch: 37
Loss: 0.3387869237948936
ROC train: 0.949241	val: 0.683150	test: 0.756738
PRC train: 0.920043	val: 0.929126	test: 0.739970

Epoch: 38
Loss: 0.3297404551573238
ROC train: 0.951764	val: 0.675458	test: 0.772387
PRC train: 0.925063	val: 0.928886	test: 0.757649

Epoch: 39
Loss: 0.32683787106936624
ROC train: 0.954889	val: 0.655311	test: 0.758303
PRC train: 0.929577	val: 0.924396	test: 0.743817

Epoch: 40
Loss: 0.3165357711068909
ROC train: 0.954971	val: 0.643956	test: 0.751695
PRC train: 0.928517	val: 0.923434	test: 0.715952

Epoch: 41
Loss: 0.3393942182405302
ROC train: 0.952454	val: 0.672894	test: 0.777256
PRC train: 0.926331	val: 0.931314	test: 0.760047

Epoch: 42
Loss: 0.32877695971154314
ROC train: 0.957474	val: 0.682784	test: 0.773952
PRC train: 0.933234	val: 0.932084	test: 0.756720

Epoch: 43
Loss: 0.318931862252824
ROC train: 0.958873	val: 0.658974	test: 0.777952
PRC train: 0.935456	val: 0.924580	test: 0.757546

Epoch: 44
Loss: 0.3154840054824567
ROC train: 0.959578	val: 0.644689	test: 0.768736
PRC train: 0.936749	val: 0.922132	test: 0.749724

Epoch: 45
Loss: 0.2819885652521633
ROC train: 0.960491	val: 0.658242	test: 0.755869
PRC train: 0.938735	val: 0.926112	test: 0.741024

Epoch: 46
Loss: 0.3070082364106395
ROC train: 0.960459	val: 0.668498	test: 0.752913
PRC train: 0.939147	val: 0.928556	test: 0.744735

Epoch: 47
Loss: 0.29874847967958107
ROC train: 0.962229	val: 0.655311	test: 0.751174
PRC train: 0.942156	val: 0.924610	test: 0.740315

Epoch: 48
Loss: 0.29268171647631824
ROC train: 0.963199	val: 0.645788	test: 0.753434
PRC train: 0.944495	val: 0.920648	test: 0.745161

Epoch: 49
Loss: 0.30837105783223995
ROC train: 0.964098	val: 0.648718	test: 0.750826
PRC train: 0.945987	val: 0.921265	test: 0.743973

Epoch: 50
Loss: 0.29219625203367305
ROC train: 0.960656	val: 0.664835	test: 0.728395
PRC train: 0.940436	val: 0.923109	test: 0.721543

Epoch: 51
Loss: 0.28793715800414155
ROC train: 0.964152	val: 0.657143	test: 0.737959
PRC train: 0.946481	val: 0.922047	test: 0.735960

Epoch: 52
Loss: 0.28821005496700114
ROC train: 0.967460	val: 0.652381	test: 0.751000
PRC train: 0.950503	val: 0.921867	test: 0.752609

Epoch: 53
Loss: 0.2881526997257991
ROC train: 0.967115	val: 0.657143	test: 0.757086
PRC train: 0.950100	val: 0.924866	test: 0.756857

Epoch: 54
Loss: 0.29503429221758715
ROC train: 0.967857	val: 0.663004	test: 0.767345
PRC train: 0.950293	val: 0.926317	test: 0.759029

Epoch: 55
Loss: 0.2861555714739733
ROC train: 0.967486	val: 0.645788	test: 0.766475
PRC train: 0.949659	val: 0.923775	test: 0.754507

Epoch: 56
Loss: 0.2974056796380403
ROC train: 0.968265	val: 0.650183	test: 0.745088
PRC train: 0.951407	val: 0.922281	test: 0.733101

Epoch: 57
Loss: 0.29893361203193597
ROC train: 0.969503	val: 0.652747	test: 0.739350
PRC train: 0.952743	val: 0.925272	test: 0.717139

Epoch: 58
Loss: 0.28188002456691313
ROC train: 0.966027	val: 0.676557	test: 0.725613
PRC train: 0.948346	val: 0.931235	test: 0.713220

Epoch: 59
Loss: 0.27030513467124967
ROC train: 0.967432	val: 0.668864	test: 0.722483
PRC train: 0.950560	val: 0.929719	test: 0.706907

Epoch: 60
Loss: 0.2695000395182946
ROC train: 0.969235	val: 0.669231	test: 0.717614
PRC train: 0.954230	val: 0.927632	test: 0.705841

Epoch: 61
Loss: 0.28302515787422455
ROC train: 0.970568	val: 0.664835	test: 0.723352
PRC train: 0.956160	val: 0.926835	test: 0.710319

Epoch: 62
Loss: 0.27581488579573504
ROC train: 0.971787	val: 0.657875	test: 0.742480
PRC train: 0.956839	val: 0.925933	test: 0.736909

Epoch: 63
Loss: 0.2694152396677789
ROC train: 0.971481	val: 0.657875	test: 0.735003
PRC train: 0.956677	val: 0.926268	test: 0.736426

Epoch: 64
Loss: 0.277527382012582
ROC train: 0.972608	val: 0.678388	test: 0.736220
PRC train: 0.959026	val: 0.930830	test: 0.736476

Epoch: 65
Loss: 0.27038333253030267
ROC train: 0.971584	val: 0.694139	test: 0.748913
PRC train: 0.956773	val: 0.934265	test: 0.752294

Epoch: 66
Loss: 0.26806529564403386
ROC train: 0.973131	val: 0.683516	test: 0.735176
PRC train: 0.958604	val: 0.933303	test: 0.729892

Epoch: 67
Loss: 0.26057274863623797
ROC train: 0.973913	val: 0.665201	test: 0.726135
PRC train: 0.959561	val: 0.930803	test: 0.717626

Epoch: 68
Loss: 0.27584539987997425
ROC train: 0.973202	val: 0.687546	test: 0.731525
PRC train: 0.959160	val: 0.933550	test: 0.738206

Epoch: 69
Loss: 0.26511696477047386
ROC train: 0.974561	val: 0.674725	test: 0.742132
PRC train: 0.961234	val: 0.931752	test: 0.740976

Epoch: 70
Loss: 0.26746138867301106
ROC train: 0.973602	val: 0.672527	test: 0.729091
PRC train: 0.959823	val: 0.931883	test: 0.725902

Epoch: 71
Loss: 0.2458490641762557
ROC train: 0.972902	val: 0.658242	test: 0.717440
PRC train: 0.958728	val: 0.929925	test: 0.723287

Epoch: 72
Loss: 0.25418767601904696
ROC train: 0.977323	val: 0.665568	test: 0.741958
PRC train: 0.965098	val: 0.930834	test: 0.746157

Epoch: 73
Loss: 0.2561887718517061
ROC train: 0.976221	val: 0.668132	test: 0.736568
PRC train: 0.964176	val: 0.928550	test: 0.745793

Epoch: 74
Loss: 0.2545701557149417
ROC train: 0.977754	val: 0.675824	test: 0.732220
PRC train: 0.966903	val: 0.926738	test: 0.729035

Epoch: 75
Loss: 0.2544783951451695
ROC train: 0.976518	val: 0.664469	test: 0.733612
PRC train: 0.964243	val: 0.928062	test: 0.727863

Epoch: 76
Loss: 0.26397604723920814
ROC train: 0.975668	val: 0.664835	test: 0.752217
PRC train: 0.962829	val: 0.930908	test: 0.750818

Epoch: 77
Loss: 0.26802785609888924
ROC train: 0.977158	val: 0.657143	test: 0.752043
PRC train: 0.965732	val: 0.927760	test: 0.753293

Epoch: 78
Loss: 0.23610892323520413
ROC train: 0.979178	val: 0.657875	test: 0.732394
PRC train: 0.969336	val: 0.925714	test: 0.739135

Epoch: 79
Loss: 0.26530040065944516
ROC train: 0.979538	val: 0.651648	test: 0.716397
PRC train: 0.969644	val: 0.926995	test: 0.718732

Epoch: 80
Loss: 0.24833328483045108
ROC train: 0.978545	val: 0.657875	test: 0.717788
PRC train: 0.967044	val: 0.924764	test: 0.716867

Epoch: 81
Loss: 0.23680655783214172
ROC train: 0.977309	val: 0.664469	test: 0.710137
PRC train: 0.965655	val: 0.929961	test: 0.709971

Epoch: 82
Loss: 0.24674510135404154
ROC train: 0.978108	val: 0.676557	test: 0.695879
PRC train: 0.967657	val: 0.930941	test: 0.699330

Epoch: 83
Loss: 0.24773409966045207
ROC train: 0.979426	val: 0.673626	test: 0.719875
PRC train: 0.969521	val: 0.928731	test: 0.721484

Epoch: 84
Loss: 0.24869372395219055
ROC train: 0.980117	val: 0.648352	test: 0.720396
PRC train: 0.971313	val: 0.920147	test: 0.717103

Epoch: 85
Loss: 0.261729807491832
ROC train: 0.979355	val: 0.657143	test: 0.706312
PRC train: 0.969808	val: 0.923379	test: 0.701605

Epoch: 86
Loss: 0.24384889205271937
ROC train: 0.980234	val: 0.674725	test: 0.721961
PRC train: 0.970914	val: 0.929006	test: 0.722807

Epoch: 87
Loss: 0.2235562360538649
ROC train: 0.980217	val: 0.663736	test: 0.728047
PRC train: 0.970350	val: 0.928816	test: 0.725442

Epoch: 88
Loss: 0.24124276941830441
ROC train: 0.979991	val: 0.656044	test: 0.724396
PRC train: 0.970418	val: 0.929700	test: 0.718819

Epoch: 89
Loss: 0.2276031729769338
ROC train: 0.981749	val: 0.663736	test: 0.739002
PRC train: 0.972086	val: 0.928961	test: 0.750275

Epoch: 90
Loss: 0.24558068367126268
ROC train: 0.980097	val: 0.674359	test: 0.746653
PRC train: 0.969744	val: 0.929042	test: 0.763655

Epoch: 91
Loss: 0.23153869756241682
ROC train: 0.980736	val: 0.664103	test: 0.737437
PRC train: 0.970957	val: 0.928272	test: 0.736181

Epoch: 92
Loss: 0.23334037148058062
ROC train: 0.980576	val: 0.657875	test: 0.732047
PRC train: 0.970715	val: 0.926208	test: 0.730207

Epoch: 93
Loss: 0.23849095203404022
ROC train: 0.982041	val: 0.661172	test: 0.736568
PRC train: 0.973105	val: 0.924921	test: 0.747292

Epoch: 94
Loss: 0.226212492270163
ROC train: 0.980143	val: 0.663370	test: 0.730308
ROC train: 0.951835	val: 0.697070	test: 0.700922
PRC train: 0.926448	val: 0.939252	test: 0.705477

Epoch: 34
Loss: 0.3200136206631621
ROC train: 0.952997	val: 0.686813	test: 0.701095
PRC train: 0.928684	val: 0.936486	test: 0.704729

Epoch: 35
Loss: 0.31638264122961895
ROC train: 0.953239	val: 0.686447	test: 0.707877
PRC train: 0.927785	val: 0.935713	test: 0.709682

Epoch: 36
Loss: 0.310916115363673
ROC train: 0.951227	val: 0.688278	test: 0.705790
PRC train: 0.923893	val: 0.936951	test: 0.715512

Epoch: 37
Loss: 0.31895462275854125
ROC train: 0.951675	val: 0.688645	test: 0.699183
PRC train: 0.923497	val: 0.936329	test: 0.707671

Epoch: 38
Loss: 0.31933871934184294
ROC train: 0.951809	val: 0.689744	test: 0.692227
PRC train: 0.924522	val: 0.937171	test: 0.706130

Epoch: 39
Loss: 0.3181634317620744
ROC train: 0.950830	val: 0.678755	test: 0.692054
PRC train: 0.925064	val: 0.934297	test: 0.699059

Epoch: 40
Loss: 0.30812986508506013
ROC train: 0.950263	val: 0.684615	test: 0.680056
PRC train: 0.924898	val: 0.935570	test: 0.685673

Epoch: 41
Loss: 0.29759073340219044
ROC train: 0.953553	val: 0.681685	test: 0.692401
PRC train: 0.926545	val: 0.934529	test: 0.692359

Epoch: 42
Loss: 0.3170925555927311
ROC train: 0.957651	val: 0.671795	test: 0.716049
PRC train: 0.933088	val: 0.932068	test: 0.719248

Epoch: 43
Loss: 0.30354083138258137
ROC train: 0.957083	val: 0.654579	test: 0.724570
PRC train: 0.932979	val: 0.928829	test: 0.716832

Epoch: 44
Loss: 0.30584527318185256
ROC train: 0.957120	val: 0.655678	test: 0.712746
PRC train: 0.934004	val: 0.927274	test: 0.710526

Epoch: 45
Loss: 0.31665558745434186
ROC train: 0.959053	val: 0.658242	test: 0.691532
PRC train: 0.937315	val: 0.928233	test: 0.700488

Epoch: 46
Loss: 0.3021848321160634
ROC train: 0.953525	val: 0.656410	test: 0.664058
PRC train: 0.929084	val: 0.928647	test: 0.672721

Epoch: 47
Loss: 0.2983836537861323
ROC train: 0.961393	val: 0.682784	test: 0.686142
PRC train: 0.940721	val: 0.934031	test: 0.694104

Epoch: 48
Loss: 0.2895999373513399
ROC train: 0.953576	val: 0.669963	test: 0.687880
PRC train: 0.929023	val: 0.930494	test: 0.687135

Epoch: 49
Loss: 0.29619703394179026
ROC train: 0.958019	val: 0.660440	test: 0.682142
PRC train: 0.934748	val: 0.928556	test: 0.689832

Epoch: 50
Loss: 0.30954060330901567
ROC train: 0.961156	val: 0.677289	test: 0.689619
PRC train: 0.938002	val: 0.930171	test: 0.693200

Epoch: 51
Loss: 0.2907380921259201
ROC train: 0.957169	val: 0.678755	test: 0.667710
PRC train: 0.933311	val: 0.929928	test: 0.685564

Epoch: 52
Loss: 0.30026150314149613
ROC train: 0.960819	val: 0.682784	test: 0.669797
PRC train: 0.940513	val: 0.933023	test: 0.693021

Epoch: 53
Loss: 0.2946087522847042
ROC train: 0.964201	val: 0.682784	test: 0.700226
PRC train: 0.945808	val: 0.933071	test: 0.719426

Epoch: 54
Loss: 0.3118948133793523
ROC train: 0.965959	val: 0.664835	test: 0.701965
PRC train: 0.947337	val: 0.927479	test: 0.707216

Epoch: 55
Loss: 0.28081183420698563
ROC train: 0.965340	val: 0.685348	test: 0.683012
PRC train: 0.945729	val: 0.933259	test: 0.685585

Epoch: 56
Loss: 0.2776514884806198
ROC train: 0.967788	val: 0.682051	test: 0.673970
PRC train: 0.949315	val: 0.931892	test: 0.676279

Epoch: 57
Loss: 0.27385675599348186
ROC train: 0.969501	val: 0.671795	test: 0.684229
PRC train: 0.953078	val: 0.931576	test: 0.689380

Epoch: 58
Loss: 0.26836740192758823
ROC train: 0.967623	val: 0.668864	test: 0.675709
PRC train: 0.949297	val: 0.931386	test: 0.684278

Epoch: 59
Loss: 0.27134905745876264
ROC train: 0.967743	val: 0.677289	test: 0.670492
PRC train: 0.949547	val: 0.933008	test: 0.674487

Epoch: 60
Loss: 0.2755743525767197
ROC train: 0.970605	val: 0.686081	test: 0.693619
PRC train: 0.954584	val: 0.934799	test: 0.686344

Epoch: 61
Loss: 0.2647996681686725
ROC train: 0.970428	val: 0.689744	test: 0.689793
PRC train: 0.954265	val: 0.935103	test: 0.686454

Epoch: 62
Loss: 0.26727289108150737
ROC train: 0.968059	val: 0.686447	test: 0.698487
PRC train: 0.951109	val: 0.934533	test: 0.699496

Epoch: 63
Loss: 0.2774319602082008
ROC train: 0.965177	val: 0.671062	test: 0.703182
PRC train: 0.947844	val: 0.929198	test: 0.715427

Epoch: 64
Loss: 0.2746008625179533
ROC train: 0.970996	val: 0.673626	test: 0.697618
PRC train: 0.956759	val: 0.929648	test: 0.715725

Epoch: 65
Loss: 0.27440611465705655
ROC train: 0.971655	val: 0.675092	test: 0.698487
PRC train: 0.955919	val: 0.928258	test: 0.707742

Epoch: 66
Loss: 0.2653170257570388
ROC train: 0.972403	val: 0.660440	test: 0.707007
PRC train: 0.957663	val: 0.926279	test: 0.716544

Epoch: 67
Loss: 0.265963536375068
ROC train: 0.971233	val: 0.681685	test: 0.706312
PRC train: 0.955455	val: 0.930684	test: 0.715610

Epoch: 68
Loss: 0.25845044529622546
ROC train: 0.969903	val: 0.700000	test: 0.680751
PRC train: 0.952673	val: 0.936453	test: 0.691451

Epoch: 69
Loss: 0.2550716966738745
ROC train: 0.972745	val: 0.699634	test: 0.685446
PRC train: 0.957931	val: 0.938796	test: 0.696960

Epoch: 70
Loss: 0.2615052663817235
ROC train: 0.973502	val: 0.687912	test: 0.707007
PRC train: 0.959806	val: 0.934209	test: 0.714044

Epoch: 71
Loss: 0.2713151389522126
ROC train: 0.974178	val: 0.690842	test: 0.709094
PRC train: 0.960582	val: 0.930897	test: 0.719271

Epoch: 72
Loss: 0.2599890706017113
ROC train: 0.974324	val: 0.686081	test: 0.710311
PRC train: 0.961344	val: 0.928915	test: 0.720576

Epoch: 73
Loss: 0.2653341334197533
ROC train: 0.971604	val: 0.682784	test: 0.694836
PRC train: 0.955298	val: 0.927622	test: 0.703223

Epoch: 74
Loss: 0.2585644907940461
ROC train: 0.973094	val: 0.670696	test: 0.714311
PRC train: 0.958761	val: 0.923324	test: 0.727062

Epoch: 75
Loss: 0.2610604600715302
ROC train: 0.975788	val: 0.669963	test: 0.704921
PRC train: 0.962404	val: 0.925123	test: 0.713584

Epoch: 76
Loss: 0.25420053317146674
ROC train: 0.971612	val: 0.676923	test: 0.692575
PRC train: 0.956420	val: 0.928358	test: 0.695999

Epoch: 77
Loss: 0.24070508374507177
ROC train: 0.974301	val: 0.685714	test: 0.697444
PRC train: 0.960299	val: 0.930856	test: 0.701302

Epoch: 78
Loss: 0.2534771732664102
ROC train: 0.977620	val: 0.669963	test: 0.699878
PRC train: 0.965408	val: 0.927232	test: 0.692328

Epoch: 79
Loss: 0.2697318549764863
ROC train: 0.978642	val: 0.675458	test: 0.700748
PRC train: 0.966583	val: 0.926938	test: 0.700440

Epoch: 80
Loss: 0.24898406739790452
ROC train: 0.976361	val: 0.670696	test: 0.698661
PRC train: 0.963933	val: 0.924937	test: 0.698560

Epoch: 81
Loss: 0.2523550542805703
ROC train: 0.975186	val: 0.678022	test: 0.691706
PRC train: 0.962674	val: 0.927978	test: 0.693756

Epoch: 82
Loss: 0.2335504511768433
ROC train: 0.976045	val: 0.691575	test: 0.695183
PRC train: 0.963601	val: 0.929572	test: 0.703299

Epoch: 83
Loss: 0.25128624866196814
ROC train: 0.979800	val: 0.694139	test: 0.700748
PRC train: 0.968481	val: 0.931660	test: 0.712336

Epoch: 84
Loss: 0.24958441511721657
ROC train: 0.979849	val: 0.690110	test: 0.699704
PRC train: 0.969206	val: 0.930547	test: 0.707815

Epoch: 85
Loss: 0.2396201578076437
ROC train: 0.976924	val: 0.686081	test: 0.693097
PRC train: 0.964742	val: 0.929378	test: 0.704752

Epoch: 86
Loss: 0.26200471604704084
ROC train: 0.977654	val: 0.685348	test: 0.704051
PRC train: 0.965826	val: 0.929971	test: 0.725704

Epoch: 87
Loss: 0.23792207952637182
ROC train: 0.979110	val: 0.683883	test: 0.709790
PRC train: 0.968365	val: 0.929365	test: 0.731749

Epoch: 88
Loss: 0.2360479241002657
ROC train: 0.979889	val: 0.668864	test: 0.697966
PRC train: 0.969588	val: 0.928153	test: 0.710660

Epoch: 89
Loss: 0.2504739357307877
ROC train: 0.980479	val: 0.681319	test: 0.695879
PRC train: 0.969938	val: 0.931208	test: 0.692731

Epoch: 90
Loss: 0.23006969612396216
ROC train: 0.978479	val: 0.667033	test: 0.705616
PRC train: 0.965914	val: 0.925406	test: 0.699087

Epoch: 91
Loss: 0.2194596002216213
ROC train: 0.978770	val: 0.664835	test: 0.713615
PRC train: 0.966854	val: 0.923224	test: 0.716023

Epoch: 92
Loss: 0.233196402878335
ROC train: 0.979443	val: 0.674359	test: 0.708399
PRC train: 0.968442	val: 0.922506	test: 0.705690

Epoch: 93
Loss: 0.22742598211695403
ROC train: 0.978622	val: 0.679487	test: 0.684750
PRC train: 0.968036	val: 0.923126	test: 0.683642

Epoch: 94
Loss: 0.24458707867593246
PRC train: 0.973624	val: 0.448983	test: 0.811302

Epoch: 95
Loss: 0.26278868603891314
ROC train: 0.974930	val: 0.851884	test: 0.712446
PRC train: 0.972265	val: 0.432190	test: 0.811623

Epoch: 96
Loss: 0.2777707754657622
ROC train: 0.974045	val: 0.848096	test: 0.718473
PRC train: 0.971387	val: 0.416640	test: 0.815271

Epoch: 97
Loss: 0.27257868813080416
ROC train: 0.974560	val: 0.835470	test: 0.721512
PRC train: 0.972600	val: 0.406266	test: 0.818788

Epoch: 98
Loss: 0.27141917773970636
ROC train: 0.974322	val: 0.831002	test: 0.722285
PRC train: 0.972302	val: 0.417251	test: 0.822689

Epoch: 99
Loss: 0.27035775275297425
ROC train: 0.976833	val: 0.835082	test: 0.718319
PRC train: 0.975019	val: 0.413951	test: 0.818318

Epoch: 100
Loss: 0.2620926472264499
ROC train: 0.977957	val: 0.841200	test: 0.722852
PRC train: 0.976353	val: 0.417914	test: 0.821654

Epoch: 101
Loss: 0.24918093805560668
ROC train: 0.979144	val: 0.842075	test: 0.723006
PRC train: 0.977696	val: 0.418800	test: 0.819294

Epoch: 102
Loss: 0.2691170415186843
ROC train: 0.975743	val: 0.834790	test: 0.716258
PRC train: 0.974389	val: 0.407009	test: 0.820303

Epoch: 103
Loss: 0.2529557507411766
ROC train: 0.972225	val: 0.831099	test: 0.712034
PRC train: 0.970872	val: 0.396990	test: 0.820404

Epoch: 104
Loss: 0.2525003230707238
ROC train: 0.973826	val: 0.838481	test: 0.714197
PRC train: 0.971361	val: 0.398801	test: 0.824960

Epoch: 105
Loss: 0.2500006184922133
ROC train: 0.976877	val: 0.846445	test: 0.734185
PRC train: 0.974199	val: 0.405639	test: 0.834618

Epoch: 106
Loss: 0.24044197669577322
ROC train: 0.976327	val: 0.849845	test: 0.740264
PRC train: 0.974046	val: 0.430549	test: 0.836567

Epoch: 107
Loss: 0.2637107706895443
ROC train: 0.977324	val: 0.854895	test: 0.724243
PRC train: 0.975374	val: 0.449404	test: 0.824023

Epoch: 108
Loss: 0.23875393035137962
ROC train: 0.979115	val: 0.858877	test: 0.703019
PRC train: 0.977677	val: 0.439308	test: 0.809263

Epoch: 109
Loss: 0.228612609692981
ROC train: 0.978380	val: 0.854215	test: 0.694931
PRC train: 0.977245	val: 0.431978	test: 0.805084

Epoch: 110
Loss: 0.2523629698102853
ROC train: 0.980176	val: 0.857615	test: 0.688440
PRC train: 0.979136	val: 0.456834	test: 0.796496

Epoch: 111
Loss: 0.2361417976754372
ROC train: 0.980945	val: 0.850816	test: 0.715949
PRC train: 0.979476	val: 0.442175	test: 0.821291

Epoch: 112
Loss: 0.2390647552706834
ROC train: 0.979431	val: 0.853050	test: 0.717443
PRC train: 0.978128	val: 0.440239	test: 0.824439

Epoch: 113
Loss: 0.23625298834171082
ROC train: 0.980254	val: 0.846931	test: 0.720688
PRC train: 0.979183	val: 0.413380	test: 0.825513

Epoch: 114
Loss: 0.23685644731442995
ROC train: 0.981091	val: 0.849456	test: 0.717906
PRC train: 0.980147	val: 0.425005	test: 0.820448

Epoch: 115
Loss: 0.25559482032141184
ROC train: 0.982351	val: 0.854409	test: 0.728158
PRC train: 0.981679	val: 0.435376	test: 0.826232

Epoch: 116
Loss: 0.24143600043349958
ROC train: 0.981597	val: 0.859266	test: 0.731764
PRC train: 0.980831	val: 0.445501	test: 0.828004

Epoch: 117
Loss: 0.24513284954409414
ROC train: 0.979937	val: 0.856546	test: 0.721564
PRC train: 0.978756	val: 0.448560	test: 0.817058

Epoch: 118
Loss: 0.22152627053121718
ROC train: 0.981154	val: 0.842657	test: 0.728261
PRC train: 0.980081	val: 0.438756	test: 0.820749

Epoch: 119
Loss: 0.24690048534478853
ROC train: 0.981417	val: 0.837995	test: 0.733927
PRC train: 0.980223	val: 0.417970	test: 0.830119

Epoch: 120
Loss: 0.23677884784646824
ROC train: 0.980838	val: 0.847902	test: 0.736812
PRC train: 0.979430	val: 0.427584	test: 0.835188

Early stopping
Best (ROC):	 train: 0.919696	val: 0.871795	test: 0.756027
Best (PRC):	 train: 0.903787	val: 0.477539	test: 0.872840

PRC train: 0.972966	val: 0.404918	test: 0.811171

Epoch: 95
Loss: 0.25043499401811387
ROC train: 0.975008	val: 0.820416	test: 0.720534
PRC train: 0.974151	val: 0.392772	test: 0.840744

Epoch: 96
Loss: 0.273210959067531
ROC train: 0.976083	val: 0.827603	test: 0.731970
PRC train: 0.974962	val: 0.439292	test: 0.850728

Epoch: 97
Loss: 0.260206552361938
ROC train: 0.977407	val: 0.843920	test: 0.739852
PRC train: 0.976458	val: 0.476417	test: 0.853803

Epoch: 98
Loss: 0.25171807795426815
ROC train: 0.980575	val: 0.834110	test: 0.736503
PRC train: 0.979813	val: 0.452978	test: 0.848577

Epoch: 99
Loss: 0.24563806753954825
ROC train: 0.980589	val: 0.837315	test: 0.723109
PRC train: 0.979648	val: 0.461521	test: 0.833070

Epoch: 100
Loss: 0.2517679303352175
ROC train: 0.978434	val: 0.835179	test: 0.711931
PRC train: 0.977201	val: 0.438288	test: 0.822673

Epoch: 101
Loss: 0.25184544203997333
ROC train: 0.981679	val: 0.845183	test: 0.700134
PRC train: 0.980586	val: 0.440586	test: 0.815787

Epoch: 102
Loss: 0.23977533044245003
ROC train: 0.981976	val: 0.839938	test: 0.696064
PRC train: 0.980721	val: 0.439736	test: 0.817564

Epoch: 103
Loss: 0.24325665516364992
ROC train: 0.981519	val: 0.826632	test: 0.709304
PRC train: 0.980405	val: 0.438568	test: 0.828969

Epoch: 104
Loss: 0.23939933697881807
ROC train: 0.982993	val: 0.826826	test: 0.716619
PRC train: 0.982283	val: 0.424343	test: 0.832777

Epoch: 105
Loss: 0.22147189377694732
ROC train: 0.982049	val: 0.817405	test: 0.717700
PRC train: 0.981191	val: 0.416179	test: 0.832132

Epoch: 106
Loss: 0.24157865952129148
ROC train: 0.981120	val: 0.827409	test: 0.703637
PRC train: 0.980538	val: 0.434537	test: 0.822093

Epoch: 107
Loss: 0.23332204818204133
ROC train: 0.983611	val: 0.834693	test: 0.686740
PRC train: 0.983095	val: 0.446162	test: 0.802835

Epoch: 108
Loss: 0.2412864833757276
ROC train: 0.984677	val: 0.821484	test: 0.694261
PRC train: 0.983813	val: 0.424771	test: 0.806107

Epoch: 109
Loss: 0.23830695084843528
ROC train: 0.981772	val: 0.805264	test: 0.703173
PRC train: 0.980822	val: 0.402899	test: 0.822260

Epoch: 110
Loss: 0.24549917437291996
ROC train: 0.981134	val: 0.802739	test: 0.697507
PRC train: 0.980224	val: 0.382936	test: 0.820633

Epoch: 111
Loss: 0.2617587472355317
ROC train: 0.981884	val: 0.820124	test: 0.693179
PRC train: 0.981110	val: 0.396707	test: 0.816920

Epoch: 112
Loss: 0.22158107967836366
ROC train: 0.983558	val: 0.834207	test: 0.706625
PRC train: 0.982577	val: 0.445668	test: 0.825425

Epoch: 113
Loss: 0.2346386082458272
ROC train: 0.983991	val: 0.829837	test: 0.709922
PRC train: 0.983165	val: 0.411227	test: 0.829052

Epoch: 114
Loss: 0.24540936382020534
ROC train: 0.984988	val: 0.822552	test: 0.718061
PRC train: 0.984360	val: 0.398952	test: 0.837652

Epoch: 115
Loss: 0.23522771297290693
ROC train: 0.984794	val: 0.833042	test: 0.710900
PRC train: 0.984282	val: 0.425644	test: 0.836378

Epoch: 116
Loss: 0.23194292609078718
ROC train: 0.985061	val: 0.840423	test: 0.701782
PRC train: 0.984767	val: 0.446021	test: 0.820909

Epoch: 117
Loss: 0.24354226963951325
ROC train: 0.985577	val: 0.847125	test: 0.699361
PRC train: 0.985329	val: 0.451663	test: 0.817220

Epoch: 118
Loss: 0.22175274108974996
ROC train: 0.986443	val: 0.843046	test: 0.703019
PRC train: 0.986095	val: 0.432284	test: 0.818508

Epoch: 119
Loss: 0.237517433028225
ROC train: 0.986078	val: 0.833042	test: 0.715176
PRC train: 0.985472	val: 0.435682	test: 0.830013

Epoch: 120
Loss: 0.24433459752001158
ROC train: 0.986477	val: 0.838384	test: 0.722852
PRC train: 0.985990	val: 0.432476	test: 0.839296

Early stopping
Best (ROC):	 train: 0.931136	val: 0.863054	test: 0.727385
Best (PRC):	 train: 0.920772	val: 0.445621	test: 0.856779

PRC train: 0.963028	val: 0.410194	test: 0.872703

Epoch: 95
Loss: 0.2546870805608699
ROC train: 0.967951	val: 0.736998	test: 0.766522
PRC train: 0.961039	val: 0.417459	test: 0.862236

Epoch: 96
Loss: 0.2638599736619491
ROC train: 0.969297	val: 0.736152	test: 0.786024
PRC train: 0.962909	val: 0.412605	test: 0.881438

Epoch: 97
Loss: 0.2559481358480734
ROC train: 0.972517	val: 0.742389	test: 0.794691
PRC train: 0.966511	val: 0.416664	test: 0.888694

Epoch: 98
Loss: 0.28533540449100636
ROC train: 0.974032	val: 0.746512	test: 0.785663
PRC train: 0.967774	val: 0.420008	test: 0.877945

Epoch: 99
Loss: 0.2888608167219131
ROC train: 0.972712	val: 0.745983	test: 0.789094
PRC train: 0.965956	val: 0.417094	test: 0.876597

Epoch: 100
Loss: 0.249239133518951
ROC train: 0.971823	val: 0.737315	test: 0.787739
PRC train: 0.965103	val: 0.414271	test: 0.876092

Epoch: 101
Loss: 0.2797165263733533
ROC train: 0.970020	val: 0.735412	test: 0.789364
PRC train: 0.963516	val: 0.409720	test: 0.880103

Epoch: 102
Loss: 0.2637320299375318
ROC train: 0.970085	val: 0.735941	test: 0.791802
PRC train: 0.963652	val: 0.407864	test: 0.875790

Epoch: 103
Loss: 0.3238315441351471
ROC train: 0.965450	val: 0.735941	test: 0.797400
PRC train: 0.958292	val: 0.401865	test: 0.886771

Epoch: 104
Loss: 0.2733780870539121
ROC train: 0.969786	val: 0.748837	test: 0.808053
PRC train: 0.961199	val: 0.413014	test: 0.895369

Epoch: 105
Loss: 0.26025000132629084
ROC train: 0.971236	val: 0.748943	test: 0.777447
PRC train: 0.964125	val: 0.421507	test: 0.867905

Epoch: 106
Loss: 0.2629824028258574
ROC train: 0.970992	val: 0.741438	test: 0.795594
PRC train: 0.964697	val: 0.417849	test: 0.889243

Epoch: 107
Loss: 0.2679503284706371
ROC train: 0.968685	val: 0.749577	test: 0.799837
PRC train: 0.961540	val: 0.429666	test: 0.893445

Epoch: 108
Loss: 0.3015180114293558
ROC train: 0.969966	val: 0.742495	test: 0.776183
PRC train: 0.962756	val: 0.422534	test: 0.874719

Epoch: 109
Loss: 0.255820743247856
ROC train: 0.970258	val: 0.732981	test: 0.758758
PRC train: 0.962851	val: 0.414951	test: 0.859201

Epoch: 110
Loss: 0.24131985405094633
ROC train: 0.971913	val: 0.731290	test: 0.758577
PRC train: 0.964673	val: 0.409606	test: 0.858509

Epoch: 111
Loss: 0.26089976607774185
ROC train: 0.974888	val: 0.735941	test: 0.776002
PRC train: 0.968534	val: 0.413801	test: 0.875193

Epoch: 112
Loss: 0.2616935968308124
ROC train: 0.975515	val: 0.745455	test: 0.781961
PRC train: 0.969534	val: 0.422411	test: 0.878031

Epoch: 113
Loss: 0.2606658165748641
ROC train: 0.974928	val: 0.753171	test: 0.779884
PRC train: 0.969211	val: 0.431991	test: 0.875697

Epoch: 114
Loss: 0.2782503671857945
ROC train: 0.975018	val: 0.753277	test: 0.779975
PRC train: 0.969434	val: 0.428153	test: 0.875970

Epoch: 115
Loss: 0.23324957088802298
ROC train: 0.973554	val: 0.742389	test: 0.804081
PRC train: 0.966945	val: 0.410460	test: 0.897742

Epoch: 116
Loss: 0.26604869781040025
ROC train: 0.975187	val: 0.736152	test: 0.806880
PRC train: 0.968874	val: 0.401176	test: 0.899580

Epoch: 117
Loss: 0.25668789355310295
ROC train: 0.976087	val: 0.729810	test: 0.800018
PRC train: 0.970743	val: 0.398670	test: 0.893360

Epoch: 118
Loss: 0.27298817894060845
ROC train: 0.976918	val: 0.725264	test: 0.778801
PRC train: 0.971974	val: 0.394391	test: 0.874866

Epoch: 119
Loss: 0.2856164858613151
ROC train: 0.977378	val: 0.735835	test: 0.774738
PRC train: 0.972294	val: 0.405345	test: 0.867099

Epoch: 120
Loss: 0.27507596827958397
ROC train: 0.978098	val: 0.745455	test: 0.768870
PRC train: 0.973002	val: 0.422582	test: 0.860252

Epoch: 121
Loss: 0.2714939511175935
ROC train: 0.976648	val: 0.748097	test: 0.754875
PRC train: 0.971627	val: 0.425828	test: 0.850017

Epoch: 122
Loss: 0.24311768880584855
ROC train: 0.975457	val: 0.744080	test: 0.768418
PRC train: 0.970332	val: 0.422722	test: 0.862135

Early stopping
Best (ROC):	 train: 0.968293	val: 0.755497	test: 0.801101
Best (PRC):	 train: 0.959849	val: 0.429956	test: 0.895776

ROC train: 0.982486	val: 0.629304	test: 0.716571
PRC train: 0.975457	val: 0.901963	test: 0.725284

Epoch: 95
Loss: 0.23920754948551792
ROC train: 0.981219	val: 0.634799	test: 0.724396
PRC train: 0.973234	val: 0.905935	test: 0.733299

Epoch: 96
Loss: 0.22173534425296748
ROC train: 0.981804	val: 0.626007	test: 0.727700
PRC train: 0.973679	val: 0.903199	test: 0.729910

Epoch: 97
Loss: 0.22175741930287649
ROC train: 0.982046	val: 0.631502	test: 0.724222
PRC train: 0.974146	val: 0.904855	test: 0.720888

Epoch: 98
Loss: 0.22998734851235153
ROC train: 0.982985	val: 0.621978	test: 0.721614
PRC train: 0.975977	val: 0.905238	test: 0.710837

Epoch: 99
Loss: 0.22202265261660808
ROC train: 0.983134	val: 0.624176	test: 0.721092
PRC train: 0.975800	val: 0.900278	test: 0.716272

Epoch: 100
Loss: 0.23079204068259931
ROC train: 0.982925	val: 0.635165	test: 0.719875
PRC train: 0.975890	val: 0.905115	test: 0.719124

Epoch: 101
Loss: 0.2352826716945043
ROC train: 0.983761	val: 0.640293	test: 0.719005
PRC train: 0.977369	val: 0.909356	test: 0.715338

Epoch: 102
Loss: 0.22185735094949285
ROC train: 0.984235	val: 0.625641	test: 0.716049
PRC train: 0.977889	val: 0.909388	test: 0.710801

Epoch: 103
Loss: 0.22844171957553466
ROC train: 0.982257	val: 0.640659	test: 0.730829
PRC train: 0.975009	val: 0.911763	test: 0.714129

Epoch: 104
Loss: 0.22122394082922936
ROC train: 0.982229	val: 0.654945	test: 0.714658
PRC train: 0.974005	val: 0.914838	test: 0.696695

Epoch: 105
Loss: 0.21417368416361446
ROC train: 0.982480	val: 0.636630	test: 0.710137
PRC train: 0.974837	val: 0.911542	test: 0.694405

Epoch: 106
Loss: 0.22639570514261598
ROC train: 0.985442	val: 0.614286	test: 0.721614
PRC train: 0.979427	val: 0.903119	test: 0.697154

Epoch: 107
Loss: 0.23173878094301853
ROC train: 0.983741	val: 0.608425	test: 0.728395
PRC train: 0.977189	val: 0.900484	test: 0.701864

Epoch: 108
Loss: 0.20868791715324378
ROC train: 0.984289	val: 0.622344	test: 0.716223
PRC train: 0.977687	val: 0.898523	test: 0.699526

Epoch: 109
Loss: 0.2105591274519861
ROC train: 0.983231	val: 0.621978	test: 0.693271
PRC train: 0.975963	val: 0.902739	test: 0.685609

Epoch: 110
Loss: 0.23660735787055373
ROC train: 0.986073	val: 0.616484	test: 0.698661
PRC train: 0.980294	val: 0.905885	test: 0.693442

Epoch: 111
Loss: 0.2128579904009678
ROC train: 0.985751	val: 0.643956	test: 0.713267
PRC train: 0.980184	val: 0.911981	test: 0.704867

Epoch: 112
Loss: 0.2114044481617799
ROC train: 0.985385	val: 0.650916	test: 0.710659
PRC train: 0.979217	val: 0.911758	test: 0.704893

Epoch: 113
Loss: 0.20196243226784527
ROC train: 0.985083	val: 0.618681	test: 0.705443
PRC train: 0.978403	val: 0.902586	test: 0.700107

Epoch: 114
Loss: 0.21093204941520605
ROC train: 0.986844	val: 0.624542	test: 0.706660
PRC train: 0.981508	val: 0.902359	test: 0.705908

Epoch: 115
Loss: 0.22076627248628067
ROC train: 0.986353	val: 0.651282	test: 0.707529
PRC train: 0.980863	val: 0.907807	test: 0.698357

Epoch: 116
Loss: 0.19733718776019898
ROC train: 0.987366	val: 0.635165	test: 0.697618
PRC train: 0.982163	val: 0.902012	test: 0.686905

Epoch: 117
Loss: 0.2051091211666618
ROC train: 0.986732	val: 0.617216	test: 0.693097
PRC train: 0.980925	val: 0.901160	test: 0.678487

Epoch: 118
Loss: 0.20080388731768672
ROC train: 0.985742	val: 0.632234	test: 0.684055
PRC train: 0.979896	val: 0.903595	test: 0.674997

Epoch: 119
Loss: 0.2118600342467621
ROC train: 0.988185	val: 0.630403	test: 0.703008
PRC train: 0.983334	val: 0.907439	test: 0.688699

Epoch: 120
Loss: 0.19736637704338184
ROC train: 0.987463	val: 0.626374	test: 0.706660
PRC train: 0.982020	val: 0.906549	test: 0.694417

Early stopping
Best (ROC):	 train: 0.755049	val: 0.712821	test: 0.588246
Best (PRC):	 train: 0.641850	val: 0.931363	test: 0.585296

PRC train: 0.969310	val: 0.927737	test: 0.738064

Epoch: 95
Loss: 0.24074067949134226
ROC train: 0.981721	val: 0.643590	test: 0.738654
PRC train: 0.972242	val: 0.921667	test: 0.736944

Epoch: 96
Loss: 0.23689969272188657
ROC train: 0.984152	val: 0.649817	test: 0.719179
PRC train: 0.976687	val: 0.921492	test: 0.721549

Epoch: 97
Loss: 0.21889720645763405
ROC train: 0.984566	val: 0.667399	test: 0.721788
PRC train: 0.977066	val: 0.925359	test: 0.724424

Epoch: 98
Loss: 0.2187404560869207
ROC train: 0.983733	val: 0.671795	test: 0.731699
PRC train: 0.975659	val: 0.926663	test: 0.728098

Epoch: 99
Loss: 0.20035870487125568
ROC train: 0.984977	val: 0.663736	test: 0.723179
PRC train: 0.977955	val: 0.926785	test: 0.721823

Epoch: 100
Loss: 0.22312165166881776
ROC train: 0.982743	val: 0.689011	test: 0.715180
PRC train: 0.974960	val: 0.935086	test: 0.713625

Epoch: 101
Loss: 0.2262720753725683
ROC train: 0.984081	val: 0.683883	test: 0.728047
PRC train: 0.976259	val: 0.933052	test: 0.725905

Epoch: 102
Loss: 0.2187113421189554
ROC train: 0.986484	val: 0.671429	test: 0.718484
PRC train: 0.980087	val: 0.930711	test: 0.713641

Epoch: 103
Loss: 0.20639955260089876
ROC train: 0.986099	val: 0.667033	test: 0.713963
PRC train: 0.979671	val: 0.927852	test: 0.698052

Epoch: 104
Loss: 0.21195290325020175
ROC train: 0.983984	val: 0.673993	test: 0.727004
PRC train: 0.976372	val: 0.931204	test: 0.722464

Epoch: 105
Loss: 0.22857863049943533
ROC train: 0.984686	val: 0.675092	test: 0.736915
PRC train: 0.977254	val: 0.931019	test: 0.735861

Epoch: 106
Loss: 0.21994664226956634
ROC train: 0.985551	val: 0.666667	test: 0.728395
PRC train: 0.978449	val: 0.924111	test: 0.718072

Epoch: 107
Loss: 0.22020675657275873
ROC train: 0.985782	val: 0.651648	test: 0.721266
PRC train: 0.979003	val: 0.917564	test: 0.698460

Epoch: 108
Loss: 0.22591277297100065
ROC train: 0.985414	val: 0.666667	test: 0.721092
PRC train: 0.978405	val: 0.921783	test: 0.693909

Epoch: 109
Loss: 0.20468383639827636
ROC train: 0.985157	val: 0.699267	test: 0.731177
PRC train: 0.978743	val: 0.933998	test: 0.724220

Epoch: 110
Loss: 0.24062719921458237
ROC train: 0.986321	val: 0.689744	test: 0.748044
PRC train: 0.979315	val: 0.928739	test: 0.752961

Epoch: 111
Loss: 0.21909675262041003
ROC train: 0.982857	val: 0.667033	test: 0.730308
PRC train: 0.974026	val: 0.922319	test: 0.728211

Epoch: 112
Loss: 0.20143181460489284
ROC train: 0.988145	val: 0.691941	test: 0.727352
PRC train: 0.982226	val: 0.932773	test: 0.717365

Epoch: 113
Loss: 0.2041543681954075
ROC train: 0.986821	val: 0.696703	test: 0.734133
PRC train: 0.980338	val: 0.937257	test: 0.723511

Epoch: 114
Loss: 0.21243985574539398
ROC train: 0.986864	val: 0.696703	test: 0.725961
PRC train: 0.981099	val: 0.934207	test: 0.721410

Epoch: 115
Loss: 0.20870510276670023
ROC train: 0.987286	val: 0.673626	test: 0.721092
PRC train: 0.981746	val: 0.927161	test: 0.715909

Epoch: 116
Loss: 0.20452712362723408
ROC train: 0.988345	val: 0.678388	test: 0.736394
PRC train: 0.983103	val: 0.928322	test: 0.735038

Epoch: 117
Loss: 0.21466300035090136
ROC train: 0.988719	val: 0.682051	test: 0.738654
PRC train: 0.983105	val: 0.931485	test: 0.745840

Epoch: 118
Loss: 0.2154577037569684
ROC train: 0.986438	val: 0.655678	test: 0.709442
PRC train: 0.979874	val: 0.920778	test: 0.709260

Epoch: 119
Loss: 0.1912968935948233
ROC train: 0.986618	val: 0.659707	test: 0.736568
PRC train: 0.980173	val: 0.917356	test: 0.739142

Epoch: 120
Loss: 0.21381859721053864
ROC train: 0.989201	val: 0.674725	test: 0.736741
PRC train: 0.984290	val: 0.928754	test: 0.726284

Early stopping
Best (ROC):	 train: 0.923967	val: 0.709524	test: 0.756390
Best (PRC):	 train: 0.873433	val: 0.942679	test: 0.736991

ROC train: 0.980719	val: 0.671795	test: 0.683359
PRC train: 0.971274	val: 0.924177	test: 0.682622

Epoch: 95
Loss: 0.22471088226251493
ROC train: 0.981407	val: 0.679853	test: 0.699878
PRC train: 0.972065	val: 0.927959	test: 0.702917

Epoch: 96
Loss: 0.21955424170324145
ROC train: 0.979050	val: 0.683150	test: 0.682838
PRC train: 0.968485	val: 0.929049	test: 0.688905

Epoch: 97
Loss: 0.23631736571936374
ROC train: 0.982140	val: 0.680952	test: 0.677621
PRC train: 0.973622	val: 0.928232	test: 0.677760

Epoch: 98
Loss: 0.228073095747113
ROC train: 0.979757	val: 0.680586	test: 0.690836
PRC train: 0.969920	val: 0.928741	test: 0.686314

Epoch: 99
Loss: 0.23573089660768592
ROC train: 0.980890	val: 0.686813	test: 0.696575
PRC train: 0.970955	val: 0.930934	test: 0.689071

Epoch: 100
Loss: 0.23506485722436826
ROC train: 0.979620	val: 0.682051	test: 0.715354
PRC train: 0.968781	val: 0.931953	test: 0.708178

Epoch: 101
Loss: 0.21135302625317065
ROC train: 0.980648	val: 0.674725	test: 0.722135
PRC train: 0.970865	val: 0.928706	test: 0.725560

Epoch: 102
Loss: 0.23311550041620369
ROC train: 0.981630	val: 0.671429	test: 0.717093
PRC train: 0.972367	val: 0.927201	test: 0.723164

Epoch: 103
Loss: 0.23192991789073872
ROC train: 0.983433	val: 0.665201	test: 0.722309
PRC train: 0.974949	val: 0.920620	test: 0.724843

Epoch: 104
Loss: 0.2298666841541709
ROC train: 0.983051	val: 0.661172	test: 0.715702
PRC train: 0.974037	val: 0.919192	test: 0.723599

Epoch: 105
Loss: 0.21292175429698776
ROC train: 0.981732	val: 0.666300	test: 0.720396
PRC train: 0.972088	val: 0.923428	test: 0.735295

Epoch: 106
Loss: 0.21240566048102597
ROC train: 0.983393	val: 0.664469	test: 0.706138
PRC train: 0.975358	val: 0.921605	test: 0.713238

Epoch: 107
Loss: 0.2263054632568126
ROC train: 0.984061	val: 0.673993	test: 0.699183
PRC train: 0.976045	val: 0.924844	test: 0.689562

Epoch: 108
Loss: 0.22575222801667497
ROC train: 0.984489	val: 0.672527	test: 0.695183
PRC train: 0.977019	val: 0.926613	test: 0.684492

Epoch: 109
Loss: 0.20220941817681415
ROC train: 0.985354	val: 0.685714	test: 0.696053
PRC train: 0.978259	val: 0.932920	test: 0.685181

Epoch: 110
Loss: 0.2208438949971579
ROC train: 0.985308	val: 0.692674	test: 0.703182
PRC train: 0.977826	val: 0.936417	test: 0.697503

Epoch: 111
Loss: 0.21927464912187436
ROC train: 0.987001	val: 0.686081	test: 0.697792
PRC train: 0.980443	val: 0.932874	test: 0.684626

Epoch: 112
Loss: 0.21988501514453862
ROC train: 0.986632	val: 0.691209	test: 0.693966
PRC train: 0.979876	val: 0.932233	test: 0.670837

Epoch: 113
Loss: 0.22278320705807983
ROC train: 0.984863	val: 0.666667	test: 0.684750
PRC train: 0.977352	val: 0.924497	test: 0.666063

Epoch: 114
Loss: 0.20095878473793558
ROC train: 0.986918	val: 0.658242	test: 0.686663
PRC train: 0.980567	val: 0.921414	test: 0.677309

Epoch: 115
Loss: 0.22404854800671808
ROC train: 0.987083	val: 0.684615	test: 0.688750
PRC train: 0.980907	val: 0.930411	test: 0.683378

Epoch: 116
Loss: 0.20538301258576297
ROC train: 0.984726	val: 0.706593	test: 0.676230
PRC train: 0.977404	val: 0.936143	test: 0.670193

Epoch: 117
Loss: 0.21005088459855709
ROC train: 0.985117	val: 0.701099	test: 0.675882
PRC train: 0.977775	val: 0.933321	test: 0.666518

Epoch: 118
Loss: 0.22051559985848943
ROC train: 0.984926	val: 0.686447	test: 0.698835
PRC train: 0.977326	val: 0.930917	test: 0.693774

Epoch: 119
Loss: 0.20978361009950436
ROC train: 0.985614	val: 0.700733	test: 0.702313
PRC train: 0.978511	val: 0.935605	test: 0.692105

Epoch: 120
Loss: 0.21945394722147665
ROC train: 0.987380	val: 0.699634	test: 0.709963
PRC train: 0.981480	val: 0.936757	test: 0.697951

Early stopping
Best (ROC):	 train: 0.930451	val: 0.716117	test: 0.716571
Best (PRC):	 train: 0.886867	val: 0.943906	test: 0.702718
All runs completed.

PRC train: 0.978168	val: 0.448021	test: 0.825380

Epoch: 95
Loss: 0.2500138999462459
ROC train: 0.976920	val: 0.842269	test: 0.724861
PRC train: 0.976016	val: 0.445958	test: 0.839554

Epoch: 96
Loss: 0.2444685152052246
ROC train: 0.974770	val: 0.845668	test: 0.726046
PRC train: 0.973800	val: 0.437926	test: 0.844807

Epoch: 97
Loss: 0.2707068755534364
ROC train: 0.976575	val: 0.861208	test: 0.722388
PRC train: 0.975519	val: 0.448571	test: 0.840631

Epoch: 98
Loss: 0.2636523179603048
ROC train: 0.979120	val: 0.862956	test: 0.725325
PRC train: 0.978159	val: 0.464131	test: 0.845832

Epoch: 99
Loss: 0.240214896644583
ROC train: 0.977499	val: 0.850816	test: 0.723934
PRC train: 0.976744	val: 0.450606	test: 0.849329

Epoch: 100
Loss: 0.2453516306726895
ROC train: 0.979869	val: 0.852758	test: 0.722903
PRC train: 0.979076	val: 0.460428	test: 0.849454

Epoch: 101
Loss: 0.2416563522132278
ROC train: 0.980813	val: 0.852467	test: 0.717082
PRC train: 0.980222	val: 0.469687	test: 0.834636

Epoch: 102
Loss: 0.24566805900247737
ROC train: 0.979879	val: 0.845183	test: 0.700855
PRC train: 0.979618	val: 0.474381	test: 0.820456

Epoch: 103
Loss: 0.24355286444246813
ROC train: 0.977981	val: 0.835373	test: 0.698279
PRC train: 0.977807	val: 0.443508	test: 0.818655

Epoch: 104
Loss: 0.24664258915545517
ROC train: 0.979606	val: 0.847416	test: 0.716773
PRC train: 0.979084	val: 0.462684	test: 0.833804

Epoch: 105
Loss: 0.2544982026746268
ROC train: 0.980633	val: 0.852953	test: 0.727900
PRC train: 0.979706	val: 0.465179	test: 0.838100

Epoch: 106
Loss: 0.25903274216292493
ROC train: 0.980619	val: 0.851204	test: 0.730321
PRC train: 0.979771	val: 0.459958	test: 0.841958

Epoch: 107
Loss: 0.24815906553864503
ROC train: 0.982268	val: 0.853632	test: 0.717082
PRC train: 0.982003	val: 0.482419	test: 0.824239

Epoch: 108
Loss: 0.23246171514752517
ROC train: 0.982112	val: 0.860140	test: 0.709304
PRC train: 0.982035	val: 0.475781	test: 0.811916

Epoch: 109
Loss: 0.23986946052961383
ROC train: 0.982030	val: 0.862471	test: 0.718009
PRC train: 0.981770	val: 0.469962	test: 0.815857

Epoch: 110
Loss: 0.23194195790277325
ROC train: 0.981928	val: 0.852370	test: 0.724037
PRC train: 0.981387	val: 0.467820	test: 0.821896

Epoch: 111
Loss: 0.24083156555415486
ROC train: 0.983514	val: 0.845862	test: 0.729394
PRC train: 0.983139	val: 0.465509	test: 0.834126

Epoch: 112
Loss: 0.24453258744030543
ROC train: 0.983455	val: 0.850039	test: 0.732485
PRC train: 0.982803	val: 0.454696	test: 0.841803

Epoch: 113
Loss: 0.23668524835088742
ROC train: 0.983387	val: 0.848193	test: 0.731867
PRC train: 0.982895	val: 0.453174	test: 0.847485

Epoch: 114
Loss: 0.2458720816729695
ROC train: 0.982132	val: 0.856449	test: 0.727179
PRC train: 0.981443	val: 0.457769	test: 0.846749

Epoch: 115
Loss: 0.2157926891056548
ROC train: 0.982468	val: 0.863442	test: 0.725118
PRC train: 0.981924	val: 0.457997	test: 0.843631

Epoch: 116
Loss: 0.22987802392333806
ROC train: 0.984954	val: 0.870241	test: 0.720173
PRC train: 0.984660	val: 0.496828	test: 0.840148

Epoch: 117
Loss: 0.2129043690954152
ROC train: 0.985689	val: 0.866841	test: 0.710179
PRC train: 0.985611	val: 0.485796	test: 0.832502

Epoch: 118
Loss: 0.22157522427102982
ROC train: 0.987699	val: 0.871309	test: 0.707552
PRC train: 0.987570	val: 0.473272	test: 0.829074

Epoch: 119
Loss: 0.20886798582171343
ROC train: 0.986750	val: 0.871892	test: 0.716464
PRC train: 0.986261	val: 0.473771	test: 0.838965

Epoch: 120
Loss: 0.23110376175136216
ROC train: 0.985090	val: 0.879371	test: 0.718113
PRC train: 0.984524	val: 0.492736	test: 0.831677

Epoch: 121
Loss: 0.23380073218131603
ROC train: 0.983022	val: 0.864122	test: 0.717649
PRC train: 0.982471	val: 0.464724	test: 0.834471

Epoch: 122
Loss: 0.2165225310481057
ROC train: 0.984867	val: 0.867133	test: 0.721564
PRC train: 0.984218	val: 0.478425	test: 0.838524

Epoch: 123
Loss: 0.23982472133828242
ROC train: 0.987193	val: 0.873834	test: 0.734494
PRC train: 0.986792	val: 0.475376	test: 0.849488

Epoch: 124
Loss: 0.22802963275207028
ROC train: 0.986910	val: 0.859654	test: 0.729240
PRC train: 0.986382	val: 0.456389	test: 0.846344

Epoch: 125
Loss: 0.214742894514328
ROC train: 0.986015	val: 0.857226	test: 0.711931
PRC train: 0.985572	val: 0.478906	test: 0.828046

Epoch: 126
Loss: 0.227636712604229
ROC train: 0.986132	val: 0.859557	test: 0.712600
PRC train: 0.985939	val: 0.483101	test: 0.829422

Epoch: 127
Loss: 0.2104661485496502
ROC train: 0.986721	val: 0.855672	test: 0.730321
PRC train: 0.986214	val: 0.478672	test: 0.846963

Epoch: 128
Loss: 0.23825682953253474
ROC train: 0.985835	val: 0.852176	test: 0.728415
PRC train: 0.985153	val: 0.467360	test: 0.848816

Epoch: 129
Loss: 0.22653158135466747
ROC train: 0.983879	val: 0.852078	test: 0.728518
PRC train: 0.983631	val: 0.445569	test: 0.848746

Epoch: 130
Loss: 0.22833070737759198
ROC train: 0.983640	val: 0.848776	test: 0.730837
PRC train: 0.983457	val: 0.453527	test: 0.849446

Epoch: 131
Loss: 0.21990145308447018
ROC train: 0.984210	val: 0.851981	test: 0.725737
PRC train: 0.984158	val: 0.467797	test: 0.838771

Epoch: 132
Loss: 0.2400886308399003
ROC train: 0.987528	val: 0.861888	test: 0.714919
PRC train: 0.987449	val: 0.476901	test: 0.831901

Epoch: 133
Loss: 0.2183544876506637
ROC train: 0.987738	val: 0.862471	test: 0.710488
PRC train: 0.987365	val: 0.456751	test: 0.828469

Epoch: 134
Loss: 0.21157650332577876
ROC train: 0.987815	val: 0.867424	test: 0.710025
PRC train: 0.987497	val: 0.460013	test: 0.818897

Epoch: 135
Loss: 0.19996373648610738
ROC train: 0.989047	val: 0.874320	test: 0.715022
PRC train: 0.989140	val: 0.472818	test: 0.829396

Epoch: 136
Loss: 0.20669622666189813
ROC train: 0.988555	val: 0.874126	test: 0.723264
PRC train: 0.988642	val: 0.487036	test: 0.838662

Epoch: 137
Loss: 0.197032630600578
ROC train: 0.988370	val: 0.872766	test: 0.727179
PRC train: 0.988452	val: 0.490683	test: 0.843012

Epoch: 138
Loss: 0.22708459787421537
ROC train: 0.989076	val: 0.867327	test: 0.735421
PRC train: 0.989104	val: 0.470566	test: 0.849528

Epoch: 139
Loss: 0.2028631272795306
ROC train: 0.989285	val: 0.858003	test: 0.737173
PRC train: 0.989342	val: 0.451324	test: 0.852137

Epoch: 140
Loss: 0.21775632891427094
ROC train: 0.989786	val: 0.855089	test: 0.730631
PRC train: 0.989859	val: 0.450228	test: 0.846931

Epoch: 141
Loss: 0.21466342181289655
ROC train: 0.989431	val: 0.856546	test: 0.716206
PRC train: 0.989303	val: 0.454497	test: 0.836131

Epoch: 142
Loss: 0.22461740922077902
ROC train: 0.990273	val: 0.864413	test: 0.706728
PRC train: 0.990203	val: 0.473093	test: 0.824174

Epoch: 143
Loss: 0.1990185654922801
ROC train: 0.990224	val: 0.865482	test: 0.704461
PRC train: 0.990026	val: 0.476987	test: 0.828276

Epoch: 144
Loss: 0.22150678746744487
ROC train: 0.988837	val: 0.861791	test: 0.701061
PRC train: 0.988518	val: 0.467738	test: 0.831297

Epoch: 145
Loss: 0.20811125682227458
ROC train: 0.986940	val: 0.851301	test: 0.693489
PRC train: 0.986689	val: 0.440610	test: 0.823604

Epoch: 146
Loss: 0.20110990520051436
ROC train: 0.989017	val: 0.835859	test: 0.697558
PRC train: 0.988539	val: 0.406638	test: 0.810230

Epoch: 147
Loss: 0.2135206578847265
ROC train: 0.990584	val: 0.855575	test: 0.712858
PRC train: 0.990515	val: 0.455629	test: 0.825361

Epoch: 148
Loss: 0.20113660513081993
ROC train: 0.988467	val: 0.858586	test: 0.722388
PRC train: 0.988087	val: 0.464825	test: 0.832437

Epoch: 149
Loss: 0.20865288451109673
ROC train: 0.989168	val: 0.867133	test: 0.710694
PRC train: 0.988909	val: 0.477162	test: 0.811521

Epoch: 150
Loss: 0.21381139488400897
ROC train: 0.988312	val: 0.864219	test: 0.713940
PRC train: 0.988121	val: 0.467844	test: 0.813096

Epoch: 151
Loss: 0.17719800799043844
ROC train: 0.988589	val: 0.867327	test: 0.728467
PRC train: 0.988155	val: 0.474689	test: 0.841230

Epoch: 152
Loss: 0.18087915025994156
ROC train: 0.988896	val: 0.870047	test: 0.735164
PRC train: 0.988117	val: 0.469425	test: 0.849048

Epoch: 153
Loss: 0.20194890333663673
ROC train: 0.990920	val: 0.871406	test: 0.731918
PRC train: 0.990549	val: 0.476451	test: 0.843895

Epoch: 154
Loss: 0.17947044794269207
ROC train: 0.991601	val: 0.868881	test: 0.730167
PRC train: 0.991448	val: 0.472081	test: 0.841302

Epoch: 155
Loss: 0.21392721327131387
ROC train: 0.989956	val: 0.850427	test: 0.717752
PRC train: 0.989725	val: 0.433366	test: 0.839483

Early stopping
Best (ROC):	 train: 0.985090	val: 0.879371	test: 0.718113
Best (PRC):	 train: 0.984524	val: 0.492736	test: 0.831677
All runs completed.

ROC train: 0.970902	val: 0.737421	test: 0.778801
PRC train: 0.964748	val: 0.443771	test: 0.872839

Epoch: 95
Loss: 0.3049358383753123
ROC train: 0.972240	val: 0.738584	test: 0.770404
PRC train: 0.965981	val: 0.424994	test: 0.863559

Epoch: 96
Loss: 0.30824321511454583
ROC train: 0.968833	val: 0.751374	test: 0.772662
PRC train: 0.962022	val: 0.427681	test: 0.861948

Epoch: 97
Loss: 0.314109798463449
ROC train: 0.965702	val: 0.749683	test: 0.779072
PRC train: 0.958294	val: 0.423285	test: 0.868639

Epoch: 98
Loss: 0.2839126300872564
ROC train: 0.965871	val: 0.754228	test: 0.797671
PRC train: 0.959334	val: 0.431387	test: 0.880700

Epoch: 99
Loss: 0.2836295496634097
ROC train: 0.967811	val: 0.751374	test: 0.811304
PRC train: 0.960720	val: 0.433702	test: 0.888946

Epoch: 100
Loss: 0.28381543894447775
ROC train: 0.971596	val: 0.753488	test: 0.827916
PRC train: 0.964954	val: 0.451735	test: 0.901692

Epoch: 101
Loss: 0.24129911779477053
ROC train: 0.971690	val: 0.749366	test: 0.821235
PRC train: 0.964762	val: 0.442977	test: 0.902804

Epoch: 102
Loss: 0.30857644322555416
ROC train: 0.972715	val: 0.744503	test: 0.788913
PRC train: 0.966153	val: 0.430622	test: 0.882112

Epoch: 103
Loss: 0.29698374687871343
ROC train: 0.973399	val: 0.750106	test: 0.776092
PRC train: 0.967276	val: 0.430170	test: 0.866202

Epoch: 104
Loss: 0.25428864047405775
ROC train: 0.974252	val: 0.755708	test: 0.789094
PRC train: 0.968012	val: 0.428296	test: 0.872448

Epoch: 105
Loss: 0.25939846027840063
ROC train: 0.975579	val: 0.753700	test: 0.806067
PRC train: 0.969940	val: 0.434488	test: 0.880376

Epoch: 106
Loss: 0.2900307686058846
ROC train: 0.973500	val: 0.748414	test: 0.824034
PRC train: 0.967535	val: 0.442670	test: 0.893336

Epoch: 107
Loss: 0.282166439566622
ROC train: 0.972902	val: 0.736469	test: 0.824124
PRC train: 0.966854	val: 0.428416	test: 0.895210

Epoch: 108
Loss: 0.24863197201253429
ROC train: 0.973895	val: 0.734461	test: 0.813109
PRC train: 0.968611	val: 0.438852	test: 0.889851

Epoch: 109
Loss: 0.26181374199740315
ROC train: 0.972103	val: 0.737209	test: 0.802727
PRC train: 0.966894	val: 0.425780	test: 0.882155

Epoch: 110
Loss: 0.2780985454420458
ROC train: 0.973543	val: 0.747674	test: 0.795143
PRC train: 0.968004	val: 0.428290	test: 0.874343

Epoch: 111
Loss: 0.23580863948181535
ROC train: 0.975522	val: 0.748626	test: 0.805164
PRC train: 0.970219	val: 0.433822	test: 0.879184

Epoch: 112
Loss: 0.2816024923646266
ROC train: 0.975443	val: 0.739006	test: 0.810491
PRC train: 0.970085	val: 0.423496	test: 0.884094

Epoch: 113
Loss: 0.22896376876813002
ROC train: 0.973712	val: 0.740063	test: 0.801372
PRC train: 0.968012	val: 0.424872	test: 0.884137

Epoch: 114
Loss: 0.22192288529021104
ROC train: 0.974626	val: 0.741332	test: 0.793788
PRC train: 0.969286	val: 0.419716	test: 0.880401

Epoch: 115
Loss: 0.25227189029528607
ROC train: 0.976231	val: 0.733510	test: 0.794782
PRC train: 0.971475	val: 0.406965	test: 0.882702

Epoch: 116
Loss: 0.3010614415099826
ROC train: 0.976803	val: 0.735624	test: 0.791983
PRC train: 0.971614	val: 0.423572	test: 0.876937

Epoch: 117
Loss: 0.25199533658329243
ROC train: 0.977328	val: 0.733298	test: 0.764626
PRC train: 0.972936	val: 0.417561	test: 0.848317

Epoch: 118
Loss: 0.25821195581259726
ROC train: 0.976562	val: 0.731501	test: 0.745666
PRC train: 0.972634	val: 0.403700	test: 0.834927

Epoch: 119
Loss: 0.28989668088147524
ROC train: 0.975604	val: 0.744715	test: 0.757674
PRC train: 0.971186	val: 0.426633	test: 0.848460

Epoch: 120
Loss: 0.27567683756181743
ROC train: 0.973053	val: 0.753700	test: 0.780697
PRC train: 0.967823	val: 0.448689	test: 0.868177

Epoch: 121
Loss: 0.2405202922736253
ROC train: 0.975536	val: 0.750529	test: 0.784218
PRC train: 0.971348	val: 0.440009	test: 0.874455

Epoch: 122
Loss: 0.2899126238108315
ROC train: 0.978350	val: 0.741438	test: 0.779162
PRC train: 0.974986	val: 0.417834	test: 0.863991

Epoch: 123
Loss: 0.27446385308232574
ROC train: 0.975633	val: 0.735201	test: 0.774648
PRC train: 0.971409	val: 0.420112	test: 0.862324

Epoch: 124
Loss: 0.24947783191983977
ROC train: 0.974496	val: 0.732241	test: 0.786927
PRC train: 0.969314	val: 0.426757	test: 0.878740

Epoch: 125
Loss: 0.26893268927284275
ROC train: 0.974946	val: 0.727484	test: 0.794601
PRC train: 0.968301	val: 0.419374	test: 0.882783

Epoch: 126
Loss: 0.2749333145864302
ROC train: 0.976076	val: 0.727590	test: 0.783496
PRC train: 0.971428	val: 0.411114	test: 0.874413

Epoch: 127
Loss: 0.2656477042135303
ROC train: 0.972992	val: 0.707822	test: 0.761105
PRC train: 0.968640	val: 0.395098	test: 0.851983

Epoch: 128
Loss: 0.26807962016109005
ROC train: 0.976742	val: 0.730444	test: 0.791531
PRC train: 0.973066	val: 0.407436	test: 0.870088

Epoch: 129
Loss: 0.22616671329957386
ROC train: 0.978577	val: 0.728964	test: 0.797671
PRC train: 0.974878	val: 0.407396	test: 0.869312

Epoch: 130
Loss: 0.2463756454522045
ROC train: 0.979786	val: 0.726638	test: 0.785753
PRC train: 0.975564	val: 0.407670	test: 0.858172

Epoch: 131
Loss: 0.29783582828391575
ROC train: 0.978353	val: 0.723679	test: 0.761195
PRC train: 0.973674	val: 0.404937	test: 0.834467

Epoch: 132
Loss: 0.2534133322875053
ROC train: 0.980923	val: 0.737844	test: 0.762098
PRC train: 0.977189	val: 0.423387	test: 0.829183

Epoch: 133
Loss: 0.2685840044369676
ROC train: 0.980933	val: 0.745455	test: 0.790448
PRC train: 0.977588	val: 0.453062	test: 0.864623

Epoch: 134
Loss: 0.2515690015317509
ROC train: 0.979303	val: 0.747040	test: 0.776273
PRC train: 0.975687	val: 0.446986	test: 0.863916

Epoch: 135
Loss: 0.25633782531380284
ROC train: 0.979379	val: 0.750529	test: 0.782864
PRC train: 0.975986	val: 0.433945	test: 0.871653

Epoch: 136
Loss: 0.2508402603883106
ROC train: 0.977997	val: 0.745032	test: 0.781419
PRC train: 0.974118	val: 0.424684	test: 0.870304

Epoch: 137
Loss: 0.2540083321692188
ROC train: 0.979897	val: 0.750846	test: 0.766342
PRC train: 0.976047	val: 0.435958	test: 0.854020

Epoch: 138
Loss: 0.23331286923669334
ROC train: 0.978944	val: 0.755814	test: 0.758667
PRC train: 0.975108	val: 0.444761	test: 0.853648

Epoch: 139
Loss: 0.24103361117874722
ROC train: 0.978040	val: 0.757822	test: 0.739346
PRC train: 0.974360	val: 0.442846	test: 0.841584

Epoch: 140
Loss: 0.25851559960058024
ROC train: 0.977583	val: 0.754968	test: 0.770495
PRC train: 0.973741	val: 0.453199	test: 0.868634

Epoch: 141
Loss: 0.24986592984630773
ROC train: 0.976220	val: 0.749049	test: 0.784579
PRC train: 0.971540	val: 0.475786	test: 0.884722

Epoch: 142
Loss: 0.24272470245481376
ROC train: 0.980685	val: 0.754123	test: 0.773564
PRC train: 0.977436	val: 0.445759	test: 0.873254

Epoch: 143
Loss: 0.2344919335136253
ROC train: 0.981775	val: 0.745455	test: 0.766612
PRC train: 0.979006	val: 0.422193	test: 0.850541

Epoch: 144
Loss: 0.23551974412690657
ROC train: 0.980120	val: 0.751903	test: 0.758487
PRC train: 0.976760	val: 0.425061	test: 0.831816

Epoch: 145
Loss: 0.21830624901677384
ROC train: 0.982610	val: 0.739641	test: 0.754605
PRC train: 0.979205	val: 0.412494	test: 0.829565

Epoch: 146
Loss: 0.22020703130267155
ROC train: 0.980847	val: 0.722516	test: 0.733749
PRC train: 0.976841	val: 0.404598	test: 0.821059

Epoch: 147
Loss: 0.23487028911849112
ROC train: 0.981243	val: 0.729387	test: 0.742416
PRC train: 0.977378	val: 0.427663	test: 0.834495

Epoch: 148
Loss: 0.21263817708579552
ROC train: 0.982052	val: 0.737421	test: 0.768238
PRC train: 0.978285	val: 0.458567	test: 0.856255

Epoch: 149
Loss: 0.21906262181100128
ROC train: 0.982247	val: 0.738901	test: 0.777086
PRC train: 0.978615	val: 0.463015	test: 0.868146

Epoch: 150
Loss: 0.2504459677390229
ROC train: 0.982088	val: 0.745137	test: 0.773294
PRC train: 0.978517	val: 0.454786	test: 0.867426

Epoch: 151
Loss: 0.20557459410899867
ROC train: 0.980926	val: 0.735518	test: 0.774738
PRC train: 0.977320	val: 0.449844	test: 0.869778

Epoch: 152
Loss: 0.2054219163956678
ROC train: 0.983448	val: 0.738161	test: 0.772210
PRC train: 0.980672	val: 0.428183	test: 0.864527

Epoch: 153
Loss: 0.23276685309770134
ROC train: 0.983819	val: 0.742495	test: 0.775912
PRC train: 0.981028	val: 0.441030	test: 0.861062

Epoch: 154
Loss: 0.20568377058467768
ROC train: 0.985068	val: 0.747886	test: 0.766612
PRC train: 0.982695	val: 0.446414	test: 0.851351
PRC train: 0.966191	val: 0.418718	test: 0.868984

Epoch: 95
Loss: 0.24102131548345773
ROC train: 0.970027	val: 0.730550	test: 0.760834
PRC train: 0.963839	val: 0.404999	test: 0.859939

Epoch: 96
Loss: 0.29816417471214257
ROC train: 0.972715	val: 0.737632	test: 0.765439
PRC train: 0.967455	val: 0.405907	test: 0.857725

Epoch: 97
Loss: 0.27765844778334314
ROC train: 0.967728	val: 0.728436	test: 0.754966
PRC train: 0.961965	val: 0.384320	test: 0.844901

Epoch: 98
Loss: 0.2724844145018826
ROC train: 0.967023	val: 0.741015	test: 0.761827
PRC train: 0.960148	val: 0.401345	test: 0.851062

Epoch: 99
Loss: 0.2808114074030203
ROC train: 0.969441	val: 0.739218	test: 0.763814
PRC train: 0.961932	val: 0.404734	test: 0.862915

Epoch: 100
Loss: 0.24988345256127326
ROC train: 0.966987	val: 0.725581	test: 0.758577
PRC train: 0.958536	val: 0.414915	test: 0.859977

Epoch: 101
Loss: 0.27378600338622505
ROC train: 0.969067	val: 0.728964	test: 0.755146
PRC train: 0.960863	val: 0.420723	test: 0.851893

Epoch: 102
Loss: 0.310749847834115
ROC train: 0.969247	val: 0.732030	test: 0.762640
PRC train: 0.962253	val: 0.414075	test: 0.850190

Epoch: 103
Loss: 0.28768601364666824
ROC train: 0.972085	val: 0.736786	test: 0.758216
PRC train: 0.966450	val: 0.413093	test: 0.847006

Epoch: 104
Loss: 0.2728698694100203
ROC train: 0.969603	val: 0.732664	test: 0.767967
PRC train: 0.962926	val: 0.417809	test: 0.858936

Epoch: 105
Loss: 0.24477638498892335
ROC train: 0.970819	val: 0.735835	test: 0.766522
PRC train: 0.964614	val: 0.418623	test: 0.857478

Epoch: 106
Loss: 0.26835661100120173
ROC train: 0.974180	val: 0.737632	test: 0.761557
PRC train: 0.969009	val: 0.417284	test: 0.848789

Epoch: 107
Loss: 0.26647423360684286
ROC train: 0.974863	val: 0.741015	test: 0.756681
PRC train: 0.969805	val: 0.418309	test: 0.842932

Epoch: 108
Loss: 0.2600655516809147
ROC train: 0.973298	val: 0.747146	test: 0.758035
PRC train: 0.967871	val: 0.435220	test: 0.849655

Epoch: 109
Loss: 0.2623719780537751
ROC train: 0.970668	val: 0.748732	test: 0.766342
PRC train: 0.964223	val: 0.441136	test: 0.863912

Epoch: 110
Loss: 0.28093756958437377
ROC train: 0.970053	val: 0.735307	test: 0.768328
PRC train: 0.963807	val: 0.420959	test: 0.871992

Epoch: 111
Loss: 0.303676604251806
ROC train: 0.970966	val: 0.732558	test: 0.769050
PRC train: 0.964114	val: 0.428127	test: 0.873545

Epoch: 112
Loss: 0.2715654421920689
ROC train: 0.971765	val: 0.726744	test: 0.751806
PRC train: 0.964620	val: 0.439075	test: 0.855191

Epoch: 113
Loss: 0.24321917630267556
ROC train: 0.974669	val: 0.737632	test: 0.722012
PRC train: 0.968530	val: 0.425304	test: 0.820256

Epoch: 114
Loss: 0.25434917439001226
ROC train: 0.971751	val: 0.743763	test: 0.730228
PRC train: 0.964596	val: 0.418840	test: 0.824513

Epoch: 115
Loss: 0.23310387333031665
ROC train: 0.972960	val: 0.737315	test: 0.742958
PRC train: 0.965819	val: 0.409739	test: 0.834086

Epoch: 116
Loss: 0.2577987097542317
ROC train: 0.975004	val: 0.734989	test: 0.756320
PRC train: 0.968953	val: 0.408505	test: 0.848791

Epoch: 117
Loss: 0.24152040327963836
ROC train: 0.975828	val: 0.729387	test: 0.762279
PRC train: 0.970302	val: 0.413187	test: 0.856786

Epoch: 118
Loss: 0.2588189559856436
ROC train: 0.974975	val: 0.728224	test: 0.760925
PRC train: 0.970173	val: 0.416589	test: 0.851837

Epoch: 119
Loss: 0.2838417817578624
ROC train: 0.973438	val: 0.732452	test: 0.762008
PRC train: 0.968299	val: 0.413093	test: 0.849952

Epoch: 120
Loss: 0.24681386391973112
ROC train: 0.972582	val: 0.729281	test: 0.745576
PRC train: 0.967294	val: 0.408287	test: 0.837067

Epoch: 121
Loss: 0.30482944013562896
ROC train: 0.972028	val: 0.725899	test: 0.717588
PRC train: 0.966451	val: 0.406575	test: 0.808067

Epoch: 122
Loss: 0.25600864358501907
ROC train: 0.972640	val: 0.739746	test: 0.733839
PRC train: 0.967161	val: 0.412496	test: 0.822779

Epoch: 123
Loss: 0.2709586872095764
ROC train: 0.975712	val: 0.738689	test: 0.755598
PRC train: 0.970501	val: 0.410370	test: 0.845650

Epoch: 124
Loss: 0.2463054382673855
ROC train: 0.976788	val: 0.742812	test: 0.774467
PRC train: 0.971563	val: 0.414315	test: 0.859075

Epoch: 125
Loss: 0.25407652465681696
ROC train: 0.976148	val: 0.742918	test: 0.774016
PRC train: 0.971338	val: 0.407720	test: 0.856848

Epoch: 126
Loss: 0.29030727182152516
ROC train: 0.976572	val: 0.743129	test: 0.766703
PRC train: 0.972085	val: 0.408293	test: 0.851530

Epoch: 127
Loss: 0.2610881330753759
ROC train: 0.978911	val: 0.740909	test: 0.755598
PRC train: 0.974457	val: 0.408807	test: 0.841200

Epoch: 128
Loss: 0.24287950837092653
ROC train: 0.978735	val: 0.737632	test: 0.764987
PRC train: 0.973480	val: 0.410454	test: 0.853003

Epoch: 129
Loss: 0.2653991551019361
ROC train: 0.977418	val: 0.732558	test: 0.763633
PRC train: 0.971592	val: 0.407763	test: 0.853265

Epoch: 130
Loss: 0.2564493544223282
ROC train: 0.976706	val: 0.727590	test: 0.752257
PRC train: 0.970931	val: 0.401760	test: 0.842854

Epoch: 131
Loss: 0.24715158812486493
ROC train: 0.979019	val: 0.731501	test: 0.775912
PRC train: 0.974285	val: 0.406402	test: 0.854679

Epoch: 132
Loss: 0.24837170544520867
ROC train: 0.977314	val: 0.736152	test: 0.779884
PRC train: 0.971943	val: 0.413752	test: 0.859092

Epoch: 133
Loss: 0.2477365438196323
ROC train: 0.977702	val: 0.740486	test: 0.760563
PRC train: 0.972468	val: 0.424466	test: 0.845646

Epoch: 134
Loss: 0.25094711036506856
ROC train: 0.977846	val: 0.756342	test: 0.756230
PRC train: 0.972374	val: 0.444941	test: 0.845650

Epoch: 135
Loss: 0.22637570651923838
ROC train: 0.975612	val: 0.754651	test: 0.749368
PRC train: 0.970106	val: 0.436829	test: 0.844043

Epoch: 136
Loss: 0.2575465027046174
ROC train: 0.978307	val: 0.752008	test: 0.749549
PRC train: 0.973829	val: 0.426855	test: 0.846470

Epoch: 137
Loss: 0.24760008929265212
ROC train: 0.978346	val: 0.738584	test: 0.747201
PRC train: 0.973638	val: 0.409446	test: 0.844471

Epoch: 138
Loss: 0.2934750654138761
ROC train: 0.979523	val: 0.740592	test: 0.762459
PRC train: 0.975704	val: 0.416117	test: 0.853407

Epoch: 139
Loss: 0.279028496554471
ROC train: 0.978767	val: 0.728436	test: 0.763001
PRC train: 0.974812	val: 0.406245	test: 0.849542

Epoch: 140
Loss: 0.24875571709514904
ROC train: 0.978030	val: 0.734144	test: 0.754785
PRC train: 0.973876	val: 0.393075	test: 0.850974

Epoch: 141
Loss: 0.28116663903048544
ROC train: 0.979519	val: 0.736681	test: 0.783406
PRC train: 0.975691	val: 0.395787	test: 0.868798

Epoch: 142
Loss: 0.25279639817940514
ROC train: 0.979573	val: 0.732664	test: 0.783315
PRC train: 0.976007	val: 0.407684	test: 0.867942

Epoch: 143
Loss: 0.251097539501391
ROC train: 0.976903	val: 0.726321	test: 0.765078
PRC train: 0.972063	val: 0.409441	test: 0.859506

Epoch: 144
Loss: 0.2412972807935705
ROC train: 0.979141	val: 0.740063	test: 0.754153
PRC train: 0.974194	val: 0.413170	test: 0.853098

Epoch: 145
Loss: 0.2266899155689702
ROC train: 0.980048	val: 0.737632	test: 0.760022
PRC train: 0.974970	val: 0.422187	test: 0.855619

Epoch: 146
Loss: 0.22336809527717846
ROC train: 0.980804	val: 0.725581	test: 0.774738
PRC train: 0.976477	val: 0.401161	test: 0.862181

Epoch: 147
Loss: 0.2236192255614417
ROC train: 0.979667	val: 0.728647	test: 0.772300
PRC train: 0.975395	val: 0.412178	test: 0.856228

Epoch: 148
Loss: 0.23928354305063326
ROC train: 0.980426	val: 0.721142	test: 0.759661
PRC train: 0.976773	val: 0.411940	test: 0.843036

Epoch: 149
Loss: 0.2386056359797252
ROC train: 0.979591	val: 0.711945	test: 0.750993
PRC train: 0.975236	val: 0.405608	test: 0.840691

Epoch: 150
Loss: 0.24537268972148635
ROC train: 0.982362	val: 0.726110	test: 0.750271
PRC train: 0.978889	val: 0.404187	test: 0.841528

Epoch: 151
Loss: 0.22765971794410386
ROC train: 0.981581	val: 0.738584	test: 0.727880
PRC train: 0.978253	val: 0.404332	test: 0.821176

Epoch: 152
Loss: 0.2304861179730006
ROC train: 0.981545	val: 0.745666	test: 0.728241
PRC train: 0.978547	val: 0.402822	test: 0.823340

Epoch: 153
Loss: 0.22631881221451255
ROC train: 0.980861	val: 0.747357	test: 0.749278
PRC train: 0.977599	val: 0.404978	test: 0.836447

Epoch: 154
Loss: 0.23732636896601708
ROC train: 0.982092	val: 0.749260	test: 0.767606
PRC train: 0.978699	val: 0.409573	test: 0.853820

Epoch: 155
Loss: 0.20579420740753732
ROC train: 0.980476	val: 0.735941	test: 0.769772
PRC train: 0.977295	val: 0.406578	test: 0.857974

Epoch: 156
Loss: 0.2470086425728283
ROC train: 0.982722	val: 0.732664	test: 0.755598
PRC train: 0.979631	val: 0.406233	test: 0.846871

Epoch: 157
Loss: 0.23352052333213918
ROC train: 0.982887	val: 0.739112	test: 0.750903
PRC train: 0.979601	val: 0.424399	test: 0.842399

Epoch: 158
Loss: 0.21352297238157053
ROC train: 0.982301	val: 0.743763	test: 0.754605
PRC train: 0.978465	val: 0.431158	test: 0.848929

Epoch: 159
Loss: 0.2159858658134232
ROC train: 0.981808	val: 0.748626	test: 0.763453
PRC train: 0.977902	val: 0.428045	test: 0.855998

Epoch: 160
Loss: 0.22709286769415646
ROC train: 0.981743	val: 0.741332	test: 0.771036
PRC train: 0.978265	val: 0.417693	test: 0.859210

Epoch: 161
Loss: 0.23986471269662282
ROC train: 0.982275	val: 0.736681	test: 0.759931
PRC train: 0.978978	val: 0.404269	test: 0.846048

Epoch: 162
Loss: 0.2290790638336425
ROC train: 0.982804	val: 0.736892	test: 0.747201
PRC train: 0.979790	val: 0.406297	test: 0.833871

Epoch: 163
Loss: 0.24256238489709014
ROC train: 0.980117	val: 0.739535	test: 0.734832
PRC train: 0.975964	val: 0.417368	test: 0.834043

Epoch: 164
Loss: 0.25079348239490706
ROC train: 0.979559	val: 0.726216	test: 0.727700
PRC train: 0.975459	val: 0.416701	test: 0.831092

Epoch: 165
Loss: 0.2264262759288534
ROC train: 0.980689	val: 0.720825	test: 0.746750
PRC train: 0.977263	val: 0.403425	test: 0.848683

Epoch: 166
Loss: 0.24808578548091448
ROC train: 0.983877	val: 0.722833	test: 0.746208
PRC train: 0.980788	val: 0.398776	test: 0.842713

Epoch: 167
Loss: 0.23251648593450608
ROC train: 0.984564	val: 0.727590	test: 0.725172
PRC train: 0.981626	val: 0.399127	test: 0.813453

Epoch: 168
Loss: 0.23241459654930902
ROC train: 0.985114	val: 0.728224	test: 0.736367
PRC train: 0.982418	val: 0.389244	test: 0.816718

Epoch: 169
Loss: 0.22786449177439883
ROC train: 0.984071	val: 0.733615	test: 0.752438
PRC train: 0.980971	val: 0.390221	test: 0.832508

Early stopping
Best (ROC):	 train: 0.977846	val: 0.756342	test: 0.756230
Best (PRC):	 train: 0.972374	val: 0.444941	test: 0.845650


Epoch: 155
Loss: 0.23957714578944192
ROC train: 0.983128	val: 0.748097	test: 0.772932
PRC train: 0.980349	val: 0.452499	test: 0.859914

Epoch: 156
Loss: 0.24425864727895336
ROC train: 0.979433	val: 0.733404	test: 0.777808
PRC train: 0.975455	val: 0.435040	test: 0.868159

Epoch: 157
Loss: 0.2782615549274408
ROC train: 0.981811	val: 0.723784	test: 0.782503
PRC train: 0.978696	val: 0.425184	test: 0.871784

Epoch: 158
Loss: 0.2638423477019927
ROC train: 0.980401	val: 0.717759	test: 0.766342
PRC train: 0.977192	val: 0.404621	test: 0.860269

Epoch: 159
Loss: 0.24255024347662557
ROC train: 0.979832	val: 0.715645	test: 0.749278
PRC train: 0.976521	val: 0.394060	test: 0.847732

Epoch: 160
Loss: 0.25085101040962626
ROC train: 0.982355	val: 0.728964	test: 0.744763
PRC train: 0.979229	val: 0.404743	test: 0.839611

Epoch: 161
Loss: 0.24442757841301307
ROC train: 0.980289	val: 0.735624	test: 0.755056
PRC train: 0.976102	val: 0.420663	test: 0.850653

Epoch: 162
Loss: 0.2806459957985032
ROC train: 0.982999	val: 0.732347	test: 0.771488
PRC train: 0.979846	val: 0.420676	test: 0.864442

Epoch: 163
Loss: 0.2294870727872529
ROC train: 0.986341	val: 0.731924	test: 0.786114
PRC train: 0.984055	val: 0.439081	test: 0.868899

Epoch: 164
Loss: 0.22667360522391405
ROC train: 0.985431	val: 0.739006	test: 0.778982
PRC train: 0.982699	val: 0.453863	test: 0.859569

Epoch: 165
Loss: 0.25334712038029694
ROC train: 0.982779	val: 0.734567	test: 0.772030
PRC train: 0.979299	val: 0.440706	test: 0.847794

Epoch: 166
Loss: 0.2202073263656911
ROC train: 0.983096	val: 0.720825	test: 0.758397
PRC train: 0.980136	val: 0.419327	test: 0.835463

Epoch: 167
Loss: 0.24958544679780906
ROC train: 0.983866	val: 0.731184	test: 0.764446
PRC train: 0.981311	val: 0.421739	test: 0.838751

Epoch: 168
Loss: 0.25546352004293643
ROC train: 0.984841	val: 0.743552	test: 0.793156
PRC train: 0.982232	val: 0.431711	test: 0.870456

Epoch: 169
Loss: 0.20686218736234227
ROC train: 0.983977	val: 0.739958	test: 0.813832
PRC train: 0.981235	val: 0.431277	test: 0.887362

Epoch: 170
Loss: 0.215058554599326
ROC train: 0.984967	val: 0.721564	test: 0.796407
PRC train: 0.982349	val: 0.406622	test: 0.874643

Epoch: 171
Loss: 0.2394326855885191
ROC train: 0.986457	val: 0.716596	test: 0.781148
PRC train: 0.984295	val: 0.404787	test: 0.863994

Epoch: 172
Loss: 0.22465834835232198
ROC train: 0.985535	val: 0.715116	test: 0.747201
PRC train: 0.983086	val: 0.406492	test: 0.830848

Epoch: 173
Loss: 0.21304594501154103
ROC train: 0.983330	val: 0.728647	test: 0.754605
PRC train: 0.979710	val: 0.423007	test: 0.836234

Epoch: 174
Loss: 0.227014898833531
ROC train: 0.985237	val: 0.732875	test: 0.774648
PRC train: 0.982450	val: 0.419582	test: 0.856172

Early stopping
Best (ROC):	 train: 0.978040	val: 0.757822	test: 0.739346
Best (PRC):	 train: 0.974360	val: 0.442846	test: 0.841584
All runs completed.
