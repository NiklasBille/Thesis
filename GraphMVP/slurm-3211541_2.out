>>> Starting run for dataset: bace
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running SCAFF configs_split_experiments/GraphMVP/bace/scaff/train_prop=0.6.yml on cuda:0
Running SCAFF configs_split_experiments/GraphMVP/bace/scaff/train_prop=0.7.yml on cuda:1
Running SCAFF configs_split_experiments/GraphMVP/bace/scaff/train_prop=0.8.yml on cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/bace/scaff/train_prop=0.8.yml --runseed 4 --device cuda:2
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/bace/scaff/train_prop=0.8.yml --runseed 5 --device cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/bace/scaff/train_prop=0.6.yml --runseed 4 --device cuda:0
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/bace/scaff/train_prop=0.6.yml --runseed 5 --device cuda:0
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/bace/scaff/train_prop=0.8.yml --runseed 6 --device cuda:2
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/bace/scaff/train_prop=0.6.yml --runseed 6 --device cuda:0
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/bace/scaff/train_prop=0.7.yml --runseed 4 --device cuda:1
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/bace/scaff/train_prop=0.7.yml --runseed 5 --device cuda:1
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/bace/scaff/train_prop=0.7.yml --runseed 6 --device cuda:1
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/bace/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/bace/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/bace/scaff/train_prop=0.6/bace_scaff_4_26-05_11-11-03  ]
[ Using Seed :  4  ]
[ Using device :  cuda:0  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
split via scaffold
Data(edge_attr=[66, 2], edge_index=[2, 66], id=[1], x=[31, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6833164652867895
ROC train: 0.698145	val: 0.640054	test: 0.618483
PRC train: 0.652629	val: 0.182371	test: 0.785334

Epoch: 2
Loss: 0.6436110956909736
ROC train: 0.734572	val: 0.656663	test: 0.656347
PRC train: 0.681653	val: 0.197904	test: 0.799312

Epoch: 3
Loss: 0.6056295633502171
ROC train: 0.771982	val: 0.683469	test: 0.689676
PRC train: 0.713321	val: 0.214892	test: 0.809178

Epoch: 4
Loss: 0.5607061555051945
ROC train: 0.801164	val: 0.704448	test: 0.714919
PRC train: 0.740033	val: 0.237745	test: 0.822285

Epoch: 5
Loss: 0.5492853469689027
ROC train: 0.825776	val: 0.721251	test: 0.720379
PRC train: 0.767035	val: 0.248561	test: 0.824615

Epoch: 6
Loss: 0.5230338023311334
ROC train: 0.846365	val: 0.742716	test: 0.738821
PRC train: 0.798975	val: 0.283302	test: 0.839854

Epoch: 7
Loss: 0.49913073702996663
ROC train: 0.861011	val: 0.768454	test: 0.737946
PRC train: 0.821583	val: 0.287547	test: 0.843299

Epoch: 8
Loss: 0.48017746377118475
ROC train: 0.878437	val: 0.762529	test: 0.743046
PRC train: 0.849681	val: 0.295606	test: 0.857442

Epoch: 9
Loss: 0.45910594380995023
ROC train: 0.883677	val: 0.745241	test: 0.749227
PRC train: 0.865398	val: 0.310607	test: 0.852556

Epoch: 10
Loss: 0.46148075254959586
ROC train: 0.888675	val: 0.773504	test: 0.763085
PRC train: 0.870228	val: 0.337564	test: 0.862357

Epoch: 11
Loss: 0.45069342281560093
ROC train: 0.898757	val: 0.798563	test: 0.764888
PRC train: 0.880990	val: 0.347697	test: 0.869105

Epoch: 12
Loss: 0.44696829602116755
ROC train: 0.899453	val: 0.800505	test: 0.772615
PRC train: 0.882715	val: 0.337397	test: 0.869661

Epoch: 13
Loss: 0.435688038219349
ROC train: 0.902198	val: 0.795357	test: 0.769318
PRC train: 0.885427	val: 0.333843	test: 0.865820

Epoch: 14
Loss: 0.43743950120382413
ROC train: 0.900592	val: 0.793221	test: 0.754688
PRC train: 0.883446	val: 0.350165	test: 0.853656

Epoch: 15
Loss: 0.4215006625240161
ROC train: 0.904373	val: 0.814103	test: 0.753503
PRC train: 0.889047	val: 0.373297	test: 0.859371

Epoch: 16
Loss: 0.42328301585467754
ROC train: 0.909365	val: 0.811772	test: 0.754070
PRC train: 0.894389	val: 0.358078	test: 0.865012

Epoch: 17
Loss: 0.42428502789781103
ROC train: 0.910095	val: 0.816919	test: 0.768494
PRC train: 0.894823	val: 0.349300	test: 0.870771

Epoch: 18
Loss: 0.4126135988798422
ROC train: 0.913526	val: 0.807207	test: 0.769885
PRC train: 0.896205	val: 0.337295	test: 0.873298

Epoch: 19
Loss: 0.4171576841167871
ROC train: 0.917180	val: 0.796814	test: 0.759839
PRC train: 0.899424	val: 0.340947	test: 0.865056

Epoch: 20
Loss: 0.4019098289424166
ROC train: 0.919652	val: 0.795746	test: 0.764527
PRC train: 0.903371	val: 0.364512	test: 0.861227

Epoch: 21
Loss: 0.39925526697527836
ROC train: 0.919613	val: 0.805556	test: 0.763703
PRC train: 0.904020	val: 0.364107	test: 0.862519

Epoch: 22
Loss: 0.41280221885893315
ROC train: 0.921725	val: 0.820998	test: 0.759685
PRC train: 0.907961	val: 0.369438	test: 0.865981

Epoch: 23
Loss: 0.4132825079451864
ROC train: 0.922411	val: 0.839744	test: 0.762415
PRC train: 0.908732	val: 0.389215	test: 0.871731

Epoch: 24
Loss: 0.3882748493191041
ROC train: 0.925910	val: 0.830711	test: 0.763188
PRC train: 0.912071	val: 0.382194	test: 0.870348

Epoch: 25
Loss: 0.39507203208509645
ROC train: 0.926046	val: 0.805847	test: 0.761282
PRC train: 0.915177	val: 0.365075	test: 0.861572

Epoch: 26
Loss: 0.4083808166278209
ROC train: 0.916051	val: 0.786519	test: 0.756079
PRC train: 0.906464	val: 0.344327	test: 0.857103

Epoch: 27
Loss: 0.3874319758565874
ROC train: 0.914460	val: 0.773116	test: 0.753245
PRC train: 0.903208	val: 0.327371	test: 0.856625

Epoch: 28
Loss: 0.3852299733344996
ROC train: 0.931584	val: 0.812160	test: 0.772924
PRC train: 0.917680	val: 0.384542	test: 0.870724

Epoch: 29
Loss: 0.3593358594073002
ROC train: 0.933000	val: 0.806818	test: 0.764012
PRC train: 0.920889	val: 0.370041	test: 0.861540

Epoch: 30
Loss: 0.3743767469596304
ROC train: 0.932605	val: 0.820221	test: 0.765248
PRC train: 0.922435	val: 0.388148	test: 0.865082

Epoch: 31
Loss: 0.37150893824375886
ROC train: 0.931515	val: 0.844114	test: 0.774985
PRC train: 0.920224	val: 0.442346	test: 0.873332

Epoch: 32
Loss: 0.36465132837303194
ROC train: 0.929102	val: 0.843046	test: 0.768700
PRC train: 0.917657	val: 0.429574	test: 0.874715

Epoch: 33
Loss: 0.35199809831766615Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/bace/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/bace/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/bace/scaff/train_prop=0.6/bace_scaff_6_26-05_11-11-03  ]
[ Using Seed :  6  ]
[ Using device :  cuda:0  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
split via scaffold
Data(edge_attr=[66, 2], edge_index=[2, 66], id=[1], x=[31, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6828434034978719
ROC train: 0.667635	val: 0.634518	test: 0.589326
PRC train: 0.638128	val: 0.176621	test: 0.755555

Epoch: 2
Loss: 0.636608465688026
ROC train: 0.743312	val: 0.651127	test: 0.668916
PRC train: 0.695388	val: 0.195207	test: 0.802102

Epoch: 3
Loss: 0.5940900401561635
ROC train: 0.790590	val: 0.654138	test: 0.714455
PRC train: 0.729497	val: 0.204746	test: 0.819138

Epoch: 4
Loss: 0.5576718961372972
ROC train: 0.826701	val: 0.670940	test: 0.753194
PRC train: 0.761481	val: 0.226112	test: 0.841550

Epoch: 5
Loss: 0.5351413852910789
ROC train: 0.844053	val: 0.692211	test: 0.759839
PRC train: 0.784057	val: 0.238976	test: 0.845768

Epoch: 6
Loss: 0.5224402013434271
ROC train: 0.857629	val: 0.738733	test: 0.765609
PRC train: 0.805674	val: 0.259235	test: 0.850259

Epoch: 7
Loss: 0.49696119542587786
ROC train: 0.866821	val: 0.768357	test: 0.770400
PRC train: 0.821899	val: 0.272488	test: 0.854452

Epoch: 8
Loss: 0.4754128456541692
ROC train: 0.874082	val: 0.780983	test: 0.765145
PRC train: 0.829633	val: 0.284540	test: 0.856104

Epoch: 9
Loss: 0.468927664010786
ROC train: 0.878412	val: 0.809343	test: 0.764424
PRC train: 0.838444	val: 0.298291	test: 0.858507

Epoch: 10
Loss: 0.46623825627985066
ROC train: 0.885507	val: 0.797203	test: 0.773594
PRC train: 0.856238	val: 0.294777	test: 0.874237

Epoch: 11
Loss: 0.445407550122158
ROC train: 0.895040	val: 0.807304	test: 0.771533
PRC train: 0.867050	val: 0.315177	test: 0.874407

Epoch: 12
Loss: 0.4419113990131688
ROC train: 0.892246	val: 0.807498	test: 0.769782
PRC train: 0.862211	val: 0.318317	test: 0.871227

Epoch: 13
Loss: 0.434903155185759
ROC train: 0.898602	val: 0.809635	test: 0.777715
PRC train: 0.873136	val: 0.318771	test: 0.874047

Epoch: 14
Loss: 0.4527608684526826
ROC train: 0.904738	val: 0.815754	test: 0.772924
PRC train: 0.882791	val: 0.330425	test: 0.872160

Epoch: 15
Loss: 0.44676257589713864
ROC train: 0.909263	val: 0.817793	test: 0.766021
PRC train: 0.890744	val: 0.347757	test: 0.868973

Epoch: 16
Loss: 0.4362167251189858
ROC train: 0.912265	val: 0.822747	test: 0.760560
PRC train: 0.895327	val: 0.350955	test: 0.866695

Epoch: 17
Loss: 0.4026548678378719
ROC train: 0.912368	val: 0.820901	test: 0.759427
PRC train: 0.894651	val: 0.355367	test: 0.865595

Epoch: 18
Loss: 0.41692250718084223
ROC train: 0.915326	val: 0.823912	test: 0.759170
PRC train: 0.897837	val: 0.334819	test: 0.868267

Epoch: 19
Loss: 0.4285377139225376
ROC train: 0.917243	val: 0.819542	test: 0.764991
PRC train: 0.899257	val: 0.329936	test: 0.869103

Epoch: 20
Loss: 0.3965392988313774
ROC train: 0.917715	val: 0.827797	test: 0.772409
PRC train: 0.900109	val: 0.369362	test: 0.870888

Epoch: 21
Loss: 0.3978524097651907
ROC train: 0.919730	val: 0.843531	test: 0.770657
PRC train: 0.903206	val: 0.380776	test: 0.874229

Epoch: 22
Loss: 0.40295128218571885
ROC train: 0.919126	val: 0.839355	test: 0.756388
PRC train: 0.904857	val: 0.372122	test: 0.868925

Epoch: 23
Loss: 0.37824528137098096
ROC train: 0.924255	val: 0.835664	test: 0.753967
PRC train: 0.910237	val: 0.366068	test: 0.867639

Epoch: 24
Loss: 0.3723648083846237
ROC train: 0.928542	val: 0.840423	test: 0.755873
PRC train: 0.913299	val: 0.375148	test: 0.868628

Epoch: 25
Loss: 0.4003920015659703
ROC train: 0.923817	val: 0.826729	test: 0.750927
PRC train: 0.910199	val: 0.364971	test: 0.863223

Epoch: 26
Loss: 0.392957936972923
ROC train: 0.930017	val: 0.839549	test: 0.763394
PRC train: 0.916256	val: 0.375359	test: 0.871057

Epoch: 27
Loss: 0.3722846547705148
ROC train: 0.931559	val: 0.851301	test: 0.769679
PRC train: 0.918356	val: 0.386379	test: 0.876213

Epoch: 28
Loss: 0.3858659342407267
ROC train: 0.932781	val: 0.853535	test: 0.770966
PRC train: 0.920976	val: 0.424082	test: 0.874896

Epoch: 29
Loss: 0.36587247472837453
ROC train: 0.934902	val: 0.854507	test: 0.757676
PRC train: 0.924315	val: 0.420171	test: 0.869143

Epoch: 30
Loss: 0.35871956836879726
ROC train: 0.934099	val: 0.852467	test: 0.757057
PRC train: 0.921949	val: 0.386672	test: 0.870119

Epoch: 31
Loss: 0.3690772983130473
ROC train: 0.932635	val: 0.848193	test: 0.757830
PRC train: 0.916997	val: 0.374699	test: 0.870563

Epoch: 32
Loss: 0.36429821901911835
ROC train: 0.932099	val: 0.861305	test: 0.755461
PRC train: 0.917179	val: 0.392370	test: 0.868908

Epoch: 33
Loss: 0.3571749600517831
ROC train: 0.935141	val: 0.861888	test: 0.748455Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/bace/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/bace/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/bace/scaff/train_prop=0.6/bace_scaff_5_26-05_11-11-03  ]
[ Using Seed :  5  ]
[ Using device :  cuda:0  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
split via scaffold
Data(edge_attr=[66, 2], edge_index=[2, 66], id=[1], x=[31, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6763511357143104
ROC train: 0.704340	val: 0.619949	test: 0.654956
PRC train: 0.642783	val: 0.169173	test: 0.790249

Epoch: 2
Loss: 0.6319944040028105
ROC train: 0.739326	val: 0.641317	test: 0.680095
PRC train: 0.679702	val: 0.188172	test: 0.804379

Epoch: 3
Loss: 0.597446565620379
ROC train: 0.777062	val: 0.663170	test: 0.712394
PRC train: 0.715256	val: 0.206202	test: 0.821748

Epoch: 4
Loss: 0.5586859537455926
ROC train: 0.809976	val: 0.682401	test: 0.731764
PRC train: 0.747105	val: 0.226007	test: 0.834393

Epoch: 5
Loss: 0.5344395496721985
ROC train: 0.836302	val: 0.708430	test: 0.740521
PRC train: 0.777840	val: 0.251719	test: 0.839751

Epoch: 6
Loss: 0.5131327130882142
ROC train: 0.858608	val: 0.740093	test: 0.743509
PRC train: 0.804487	val: 0.269930	test: 0.840765

Epoch: 7
Loss: 0.4863772119983888
ROC train: 0.866617	val: 0.750000	test: 0.742067
PRC train: 0.815410	val: 0.269944	test: 0.844328

Epoch: 8
Loss: 0.46727918822558245
ROC train: 0.871293	val: 0.739705	test: 0.744282
PRC train: 0.823920	val: 0.261716	test: 0.853537

Epoch: 9
Loss: 0.46004172977087043
ROC train: 0.877011	val: 0.772824	test: 0.768854
PRC train: 0.847863	val: 0.300038	test: 0.870440

Epoch: 10
Loss: 0.465268763705721
ROC train: 0.880081	val: 0.793318	test: 0.765454
PRC train: 0.857205	val: 0.333427	test: 0.868963

Epoch: 11
Loss: 0.4530505644369509
ROC train: 0.889512	val: 0.818376	test: 0.765866
PRC train: 0.870513	val: 0.368457	test: 0.865378

Epoch: 12
Loss: 0.46106577926184766
ROC train: 0.897361	val: 0.810897	test: 0.755564
PRC train: 0.880259	val: 0.374159	test: 0.858968

Epoch: 13
Loss: 0.44609793449082324
ROC train: 0.901122	val: 0.804487	test: 0.754636
PRC train: 0.878842	val: 0.346026	test: 0.865664

Epoch: 14
Loss: 0.4489402648864998
ROC train: 0.896495	val: 0.802059	test: 0.742788
PRC train: 0.870164	val: 0.316300	test: 0.864413

Epoch: 15
Loss: 0.43071554680861857
ROC train: 0.889230	val: 0.780109	test: 0.730476
PRC train: 0.864573	val: 0.300280	test: 0.861012

Epoch: 16
Loss: 0.41466076921334083
ROC train: 0.901468	val: 0.786325	test: 0.745776
PRC train: 0.877801	val: 0.305850	test: 0.867959

Epoch: 17
Loss: 0.41132824772265175
ROC train: 0.914679	val: 0.800699	test: 0.772615
PRC train: 0.897999	val: 0.348053	test: 0.874078

Epoch: 18
Loss: 0.42314331153253804
ROC train: 0.918401	val: 0.813131	test: 0.771894
PRC train: 0.905717	val: 0.383163	test: 0.873834

Epoch: 19
Loss: 0.4122721296560867
ROC train: 0.919545	val: 0.823232	test: 0.764630
PRC train: 0.908080	val: 0.386087	test: 0.867462

Epoch: 20
Loss: 0.39521516917016136
ROC train: 0.919345	val: 0.828768	test: 0.768185
PRC train: 0.905629	val: 0.380037	test: 0.870232

Epoch: 21
Loss: 0.3905814185313799
ROC train: 0.924231	val: 0.829837	test: 0.773748
PRC train: 0.907972	val: 0.361997	test: 0.876557

Epoch: 22
Loss: 0.3987003474193973
ROC train: 0.924396	val: 0.828283	test: 0.773645
PRC train: 0.905531	val: 0.367044	test: 0.880186

Epoch: 23
Loss: 0.396030728220637
ROC train: 0.927160	val: 0.821775	test: 0.768082
PRC train: 0.910806	val: 0.374091	test: 0.880909

Epoch: 24
Loss: 0.4170475931129886
ROC train: 0.926377	val: 0.814491	test: 0.762724
PRC train: 0.912088	val: 0.355264	test: 0.880958

Epoch: 25
Loss: 0.3772779227176946
ROC train: 0.918499	val: 0.824204	test: 0.752112
PRC train: 0.901537	val: 0.359153	test: 0.876893

Epoch: 26
Loss: 0.3874408302570401
ROC train: 0.927248	val: 0.843240	test: 0.769318
PRC train: 0.911751	val: 0.392789	test: 0.880497

Epoch: 27
Loss: 0.38121957380402915
ROC train: 0.929944	val: 0.845668	test: 0.763342
PRC train: 0.914167	val: 0.398220	test: 0.877088

Epoch: 28
Loss: 0.38030830876165644
ROC train: 0.932138	val: 0.844406	test: 0.760406
PRC train: 0.919147	val: 0.397798	test: 0.875117

Epoch: 29
Loss: 0.3813666039693344
ROC train: 0.935939	val: 0.846445	test: 0.769679
PRC train: 0.924666	val: 0.405307	test: 0.880130

Epoch: 30
Loss: 0.372799844770218
ROC train: 0.937622	val: 0.841200	test: 0.777406
PRC train: 0.925336	val: 0.404828	test: 0.879992

Epoch: 31
Loss: 0.3709707744273063
ROC train: 0.935204	val: 0.829934	test: 0.766845
PRC train: 0.924741	val: 0.420172	test: 0.867244

Epoch: 32
Loss: 0.35241846355491974
ROC train: 0.934464	val: 0.821678	test: 0.751648
PRC train: 0.924234	val: 0.359237	test: 0.862762

Epoch: 33
Loss: 0.3574512934789306
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/bace/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/bace/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/bace/scaff/train_prop=0.7/bace_scaff_6_26-05_11-11-03  ]
[ Using Seed :  6  ]
[ Using device :  cuda:1  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
split via scaffold
Data(edge_attr=[66, 2], edge_index=[2, 66], id=[1], x=[31, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6710757635792796
ROC train: 0.701702	val: 0.531712	test: 0.666125
PRC train: 0.639765	val: 0.282240	test: 0.823565

Epoch: 2
Loss: 0.6201770223897057
ROC train: 0.773795	val: 0.598837	test: 0.755869
PRC train: 0.696078	val: 0.311982	test: 0.860013

Epoch: 3
Loss: 0.5835635632705335
ROC train: 0.807729	val: 0.654968	test: 0.786204
PRC train: 0.724911	val: 0.335866	test: 0.869260

Epoch: 4
Loss: 0.5323132595344051
ROC train: 0.838677	val: 0.704545	test: 0.809859
PRC train: 0.751005	val: 0.376378	test: 0.876105

Epoch: 5
Loss: 0.5185924509561725
ROC train: 0.854631	val: 0.689746	test: 0.827736
PRC train: 0.775428	val: 0.369189	test: 0.879467

Epoch: 6
Loss: 0.4852936499846285
ROC train: 0.866454	val: 0.673890	test: 0.837667
PRC train: 0.802984	val: 0.356336	test: 0.901782

Epoch: 7
Loss: 0.47608753177894697
ROC train: 0.873305	val: 0.683721	test: 0.844619
PRC train: 0.810252	val: 0.362111	test: 0.914711

Epoch: 8
Loss: 0.47222531692804415
ROC train: 0.881919	val: 0.691860	test: 0.843806
PRC train: 0.826086	val: 0.379677	test: 0.920838

Epoch: 9
Loss: 0.4313935981742915
ROC train: 0.883945	val: 0.685729	test: 0.828458
PRC train: 0.821967	val: 0.370138	test: 0.916056

Epoch: 10
Loss: 0.46456848535234735
ROC train: 0.883855	val: 0.673150	test: 0.827284
PRC train: 0.820524	val: 0.361280	test: 0.913140

Epoch: 11
Loss: 0.44186134484114276
ROC train: 0.895369	val: 0.674207	test: 0.839924
PRC train: 0.847639	val: 0.356158	test: 0.916950

Epoch: 12
Loss: 0.42019547954541264
ROC train: 0.898978	val: 0.678964	test: 0.842542
PRC train: 0.860280	val: 0.410078	test: 0.909406

Epoch: 13
Loss: 0.3994215969408988
ROC train: 0.909445	val: 0.697886	test: 0.833333
PRC train: 0.874838	val: 0.438563	test: 0.915640

Epoch: 14
Loss: 0.43615717916528335
ROC train: 0.909949	val: 0.713002	test: 0.816089
PRC train: 0.878668	val: 0.468756	test: 0.905124

Epoch: 15
Loss: 0.4616891465022718
ROC train: 0.907394	val: 0.710465	test: 0.832701
PRC train: 0.876816	val: 0.456006	test: 0.906868

Epoch: 16
Loss: 0.4158379111918065
ROC train: 0.919301	val: 0.722516	test: 0.845702
PRC train: 0.891398	val: 0.432981	test: 0.915623

Epoch: 17
Loss: 0.42050081270170087
ROC train: 0.914882	val: 0.711945	test: 0.842542
PRC train: 0.881251	val: 0.386959	test: 0.913471

Epoch: 18
Loss: 0.3818627486960469
ROC train: 0.917422	val: 0.711416	test: 0.839112
PRC train: 0.886019	val: 0.386312	test: 0.909152

Epoch: 19
Loss: 0.45238012443301423
ROC train: 0.915810	val: 0.705391	test: 0.832160
PRC train: 0.885507	val: 0.397185	test: 0.904870

Epoch: 20
Loss: 0.4248872113038923
ROC train: 0.916847	val: 0.712579	test: 0.836674
PRC train: 0.885509	val: 0.425245	test: 0.907053

Epoch: 21
Loss: 0.40313236720211754
ROC train: 0.915976	val: 0.711416	test: 0.817263
PRC train: 0.884939	val: 0.427278	test: 0.905843

Epoch: 22
Loss: 0.3986424448569268
ROC train: 0.910924	val: 0.715222	test: 0.806970
PRC train: 0.884170	val: 0.452525	test: 0.896176

Epoch: 23
Loss: 0.3659834312490093
ROC train: 0.924978	val: 0.731078	test: 0.830805
PRC train: 0.901442	val: 0.470019	test: 0.908173

Epoch: 24
Loss: 0.38735028630539314
ROC train: 0.928512	val: 0.724630	test: 0.839744
PRC train: 0.905556	val: 0.466101	test: 0.913847

Epoch: 25
Loss: 0.3866041310582583
ROC train: 0.930422	val: 0.731395	test: 0.838841
PRC train: 0.906644	val: 0.485983	test: 0.913841

Epoch: 26
Loss: 0.3908997610934283
ROC train: 0.932952	val: 0.727378	test: 0.854731
PRC train: 0.910383	val: 0.465687	test: 0.919508

Epoch: 27
Loss: 0.417497130250552
ROC train: 0.932506	val: 0.731501	test: 0.860599
PRC train: 0.911087	val: 0.443976	test: 0.919481

Epoch: 28
Loss: 0.3736430580465805
ROC train: 0.930361	val: 0.743340	test: 0.847598
PRC train: 0.909507	val: 0.428722	test: 0.909652

Epoch: 29
Loss: 0.391563655952162
ROC train: 0.930250	val: 0.743975	test: 0.856266
PRC train: 0.908369	val: 0.433324	test: 0.923754

Epoch: 30
Loss: 0.3840254828286028
ROC train: 0.923647	val: 0.725159	test: 0.854731
PRC train: 0.898923	val: 0.401017	test: 0.924638

Epoch: 31
Loss: 0.3793552763855782
ROC train: 0.927706	val: 0.723573	test: 0.858613
PRC train: 0.902559	val: 0.429720	test: 0.924127

Epoch: 32
Loss: 0.4177770681243854
ROC train: 0.930951	val: 0.722093	test: 0.849494
PRC train: 0.908458	val: 0.432305	test: 0.920306

Epoch: 33
Loss: 0.33435261200381466Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/bace/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/bace/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/bace/scaff/train_prop=0.7/bace_scaff_5_26-05_11-11-03  ]
[ Using Seed :  5  ]
[ Using device :  cuda:1  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
split via scaffold
Data(edge_attr=[66, 2], edge_index=[2, 66], id=[1], x=[31, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6676643806274682
ROC train: 0.705059	val: 0.567336	test: 0.696009
PRC train: 0.617950	val: 0.308030	test: 0.817495

Epoch: 2
Loss: 0.6155942855415846
ROC train: 0.738194	val: 0.596089	test: 0.743409
PRC train: 0.656529	val: 0.315320	test: 0.846973

Epoch: 3
Loss: 0.5799173886450357
ROC train: 0.796913	val: 0.629598	test: 0.763994
PRC train: 0.709934	val: 0.319219	test: 0.847313

Epoch: 4
Loss: 0.5324485484035119
ROC train: 0.833546	val: 0.700106	test: 0.772571
PRC train: 0.745935	val: 0.371924	test: 0.852617

Epoch: 5
Loss: 0.5334705331005841
ROC train: 0.856642	val: 0.728858	test: 0.795865
PRC train: 0.773494	val: 0.407752	test: 0.867748

Epoch: 6
Loss: 0.47637473467756164
ROC train: 0.870124	val: 0.707717	test: 0.805616
PRC train: 0.803307	val: 0.396184	test: 0.869992

Epoch: 7
Loss: 0.4962577848491604
ROC train: 0.875025	val: 0.702748	test: 0.799205
PRC train: 0.816401	val: 0.392678	test: 0.868689

Epoch: 8
Loss: 0.4694814412230972
ROC train: 0.884240	val: 0.695772	test: 0.815367
PRC train: 0.836475	val: 0.376221	test: 0.895143

Epoch: 9
Loss: 0.4695391478682788
ROC train: 0.888140	val: 0.684778	test: 0.816631
PRC train: 0.842566	val: 0.371018	test: 0.891749

Epoch: 10
Loss: 0.44211544530230135
ROC train: 0.888234	val: 0.698203	test: 0.815818
PRC train: 0.842833	val: 0.357715	test: 0.880923

Epoch: 11
Loss: 0.45561353817894
ROC train: 0.901421	val: 0.707188	test: 0.829812
PRC train: 0.869444	val: 0.382740	test: 0.902459

Epoch: 12
Loss: 0.4324832513192794
ROC train: 0.905710	val: 0.689852	test: 0.846966
PRC train: 0.877392	val: 0.401836	test: 0.916131

Epoch: 13
Loss: 0.46651003993648904
ROC train: 0.899230	val: 0.684778	test: 0.830534
PRC train: 0.857434	val: 0.362585	test: 0.917240

Epoch: 14
Loss: 0.43475116259486757
ROC train: 0.890857	val: 0.686469	test: 0.810401
PRC train: 0.842296	val: 0.363384	test: 0.908598

Epoch: 15
Loss: 0.4023568927740849
ROC train: 0.902958	val: 0.688795	test: 0.819971
PRC train: 0.866647	val: 0.390499	test: 0.914385

Epoch: 16
Loss: 0.4438207813175909
ROC train: 0.910892	val: 0.679915	test: 0.823673
PRC train: 0.883339	val: 0.387584	test: 0.907443

Epoch: 17
Loss: 0.4054816108447484
ROC train: 0.916818	val: 0.699894	test: 0.822951
PRC train: 0.888297	val: 0.412316	test: 0.906388

Epoch: 18
Loss: 0.40027210431390775
ROC train: 0.919718	val: 0.716596	test: 0.825569
PRC train: 0.891942	val: 0.430730	test: 0.904121

Epoch: 19
Loss: 0.40273892655113047
ROC train: 0.923661	val: 0.732770	test: 0.827465
PRC train: 0.899441	val: 0.437931	test: 0.904237

Epoch: 20
Loss: 0.3720435526250866
ROC train: 0.923899	val: 0.743552	test: 0.836313
PRC train: 0.900117	val: 0.417757	test: 0.906284

Epoch: 21
Loss: 0.3886564328549804
ROC train: 0.917879	val: 0.721036	test: 0.838480
PRC train: 0.892439	val: 0.408766	test: 0.910636

Epoch: 22
Loss: 0.42836591388712375
ROC train: 0.913277	val: 0.711628	test: 0.836313
PRC train: 0.887750	val: 0.414355	test: 0.912881

Epoch: 23
Loss: 0.40227821818237447
ROC train: 0.924971	val: 0.720825	test: 0.836854
PRC train: 0.904768	val: 0.425684	test: 0.913057

Epoch: 24
Loss: 0.3725671992467586
ROC train: 0.918905	val: 0.711945	test: 0.801463
PRC train: 0.900030	val: 0.430944	test: 0.889458

Epoch: 25
Loss: 0.38526908922159586
ROC train: 0.928814	val: 0.734038	test: 0.812387
PRC train: 0.908882	val: 0.468638	test: 0.904838

Epoch: 26
Loss: 0.39166358265954726
ROC train: 0.929149	val: 0.733404	test: 0.830354
PRC train: 0.901536	val: 0.461574	test: 0.907969

Epoch: 27
Loss: 0.39319132950754376
ROC train: 0.931833	val: 0.736786	test: 0.837848
PRC train: 0.908311	val: 0.429524	test: 0.911119

Epoch: 28
Loss: 0.34757587025524717
ROC train: 0.931790	val: 0.732875	test: 0.825569
PRC train: 0.914173	val: 0.406664	test: 0.896390

Epoch: 29
Loss: 0.3692940725698226
ROC train: 0.936964	val: 0.740381	test: 0.831528
PRC train: 0.920294	val: 0.413571	test: 0.902128

Epoch: 30
Loss: 0.36530448938263216
ROC train: 0.934643	val: 0.739218	test: 0.817533
PRC train: 0.918247	val: 0.422598	test: 0.895780

Epoch: 31
Loss: 0.3551641103705865
ROC train: 0.937435	val: 0.728436	test: 0.813651
PRC train: 0.920221	val: 0.411661	test: 0.894749

Epoch: 32
Loss: 0.3525245697617284
ROC train: 0.939900	val: 0.725159	test: 0.826562
PRC train: 0.918961	val: 0.425365	test: 0.906197

Epoch: 33
Loss: 0.36154481053500853Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/bace/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/bace/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/bace/scaff/train_prop=0.8/bace_scaff_4_26-05_11-11-03  ]
[ Using Seed :  4  ]
[ Using device :  cuda:2  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
split via scaffold
Data(edge_attr=[66, 2], edge_index=[2, 66], id=[1], x=[31, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6783183839165985
ROC train: 0.702894	val: 0.508791	test: 0.635020
PRC train: 0.584159	val: 0.889263	test: 0.669513

Epoch: 2
Loss: 0.6227187609474722
ROC train: 0.744994	val: 0.543223	test: 0.683359
PRC train: 0.621344	val: 0.889410	test: 0.696456

Epoch: 3
Loss: 0.5743560432922721
ROC train: 0.799943	val: 0.568864	test: 0.725265
PRC train: 0.680523	val: 0.893750	test: 0.715425

Epoch: 4
Loss: 0.5256654045096785
ROC train: 0.846470	val: 0.630769	test: 0.779169
PRC train: 0.732711	val: 0.911186	test: 0.749937

Epoch: 5
Loss: 0.4940767557425034
ROC train: 0.851767	val: 0.649817	test: 0.770301
PRC train: 0.737348	val: 0.917533	test: 0.750281

Epoch: 6
Loss: 0.4888608365884675
ROC train: 0.863967	val: 0.672161	test: 0.741784
PRC train: 0.757023	val: 0.923648	test: 0.729226

Epoch: 7
Loss: 0.47367755823491997
ROC train: 0.877771	val: 0.690476	test: 0.751521
PRC train: 0.795209	val: 0.935993	test: 0.746376

Epoch: 8
Loss: 0.43948957431197344
ROC train: 0.878410	val: 0.696703	test: 0.759346
PRC train: 0.816161	val: 0.936779	test: 0.744774

Epoch: 9
Loss: 0.4376069938166001
ROC train: 0.896413	val: 0.701832	test: 0.787515
PRC train: 0.833187	val: 0.938551	test: 0.793425

Epoch: 10
Loss: 0.4143488681686226
ROC train: 0.902965	val: 0.692674	test: 0.806642
PRC train: 0.844957	val: 0.936519	test: 0.812423

Epoch: 11
Loss: 0.40792807252091345
ROC train: 0.907988	val: 0.659707	test: 0.810816
PRC train: 0.852549	val: 0.928362	test: 0.800540

Epoch: 12
Loss: 0.42285471468308683
ROC train: 0.907178	val: 0.651282	test: 0.800209
PRC train: 0.853279	val: 0.925154	test: 0.810953

Epoch: 13
Loss: 0.4076808074806305
ROC train: 0.913990	val: 0.675092	test: 0.816554
PRC train: 0.864899	val: 0.932593	test: 0.812592

Epoch: 14
Loss: 0.4082327300629499
ROC train: 0.917195	val: 0.693773	test: 0.812728
PRC train: 0.869587	val: 0.936967	test: 0.810485

Epoch: 15
Loss: 0.3943167267938693
ROC train: 0.919509	val: 0.687179	test: 0.793079
PRC train: 0.873828	val: 0.932077	test: 0.799443

Epoch: 16
Loss: 0.4108893670270454
ROC train: 0.922394	val: 0.687546	test: 0.800383
PRC train: 0.873982	val: 0.932849	test: 0.795352

Epoch: 17
Loss: 0.40214650240182914
ROC train: 0.921864	val: 0.675092	test: 0.805773
PRC train: 0.874104	val: 0.929649	test: 0.788081

Epoch: 18
Loss: 0.39052320779310506
ROC train: 0.919600	val: 0.656410	test: 0.802643
PRC train: 0.871434	val: 0.926421	test: 0.798582

Epoch: 19
Loss: 0.39049888821923384
ROC train: 0.927517	val: 0.678388	test: 0.807686
PRC train: 0.884321	val: 0.931630	test: 0.801630

Epoch: 20
Loss: 0.3793274784178496
ROC train: 0.927329	val: 0.699634	test: 0.800035
PRC train: 0.881629	val: 0.936649	test: 0.799052

Epoch: 21
Loss: 0.37935921622508195
ROC train: 0.932443	val: 0.674359	test: 0.803339
PRC train: 0.889775	val: 0.930506	test: 0.810248

Epoch: 22
Loss: 0.3670677416077302
ROC train: 0.936127	val: 0.668864	test: 0.806642
PRC train: 0.897233	val: 0.929912	test: 0.814398

Epoch: 23
Loss: 0.3664716918656057
ROC train: 0.938011	val: 0.682784	test: 0.812902
PRC train: 0.900589	val: 0.931837	test: 0.820174

Epoch: 24
Loss: 0.3530289289744518
ROC train: 0.937103	val: 0.696337	test: 0.801774
PRC train: 0.898601	val: 0.934354	test: 0.807724

Epoch: 25
Loss: 0.36341865125791106
ROC train: 0.934846	val: 0.679121	test: 0.802991
PRC train: 0.894942	val: 0.931302	test: 0.815464

Epoch: 26
Loss: 0.349065574340823
ROC train: 0.937289	val: 0.668498	test: 0.813772
PRC train: 0.899245	val: 0.932053	test: 0.817193

Epoch: 27
Loss: 0.3457989392112535
ROC train: 0.937917	val: 0.661905	test: 0.803339
PRC train: 0.898444	val: 0.925618	test: 0.814834

Epoch: 28
Loss: 0.34475080742677405
ROC train: 0.938818	val: 0.667766	test: 0.802295
PRC train: 0.901784	val: 0.927365	test: 0.811311

Epoch: 29
Loss: 0.3265023011577566
ROC train: 0.943017	val: 0.665201	test: 0.801600
PRC train: 0.910809	val: 0.927301	test: 0.805747

Epoch: 30
Loss: 0.34803014289148815
ROC train: 0.944649	val: 0.668498	test: 0.787863
PRC train: 0.912460	val: 0.929332	test: 0.803763

Epoch: 31
Loss: 0.3477973337653709
ROC train: 0.944589	val: 0.673626	test: 0.791688
PRC train: 0.911555	val: 0.929364	test: 0.803561

Epoch: 32
Loss: 0.33849726108722133
ROC train: 0.943362	val: 0.661172	test: 0.795688
PRC train: 0.912371	val: 0.928136	test: 0.800327

Epoch: 33
Loss: 0.3372628406793584Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/bace/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/bace/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/bace/scaff/train_prop=0.8/bace_scaff_6_26-05_11-11-03  ]
[ Using Seed :  6  ]
[ Using device :  cuda:2  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
split via scaffold
Data(edge_attr=[66, 2], edge_index=[2, 66], id=[1], x=[31, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6711906516086756
ROC train: 0.702977	val: 0.510989	test: 0.650496
PRC train: 0.593615	val: 0.884632	test: 0.712680

Epoch: 2
Loss: 0.6107536009615403
ROC train: 0.769783	val: 0.582418	test: 0.712572
PRC train: 0.650194	val: 0.892858	test: 0.729945

Epoch: 3
Loss: 0.564428742471645
ROC train: 0.810922	val: 0.635165	test: 0.744740
PRC train: 0.683958	val: 0.895792	test: 0.734083

Epoch: 4
Loss: 0.512662190523986
ROC train: 0.842286	val: 0.658974	test: 0.774996
PRC train: 0.713534	val: 0.899820	test: 0.749008

Epoch: 5
Loss: 0.49233839629665166
ROC train: 0.860294	val: 0.665201	test: 0.788037
PRC train: 0.738769	val: 0.904597	test: 0.759256

Epoch: 6
Loss: 0.4602293425049221
ROC train: 0.867523	val: 0.663736	test: 0.781951
PRC train: 0.754573	val: 0.907755	test: 0.769163

Epoch: 7
Loss: 0.4543581693441614
ROC train: 0.887072	val: 0.702564	test: 0.789080
PRC train: 0.806075	val: 0.933650	test: 0.765823

Epoch: 8
Loss: 0.4513747734798761
ROC train: 0.888533	val: 0.722344	test: 0.781951
PRC train: 0.820557	val: 0.940009	test: 0.775002

Epoch: 9
Loss: 0.4285177459815136
ROC train: 0.906581	val: 0.696703	test: 0.790819
PRC train: 0.845322	val: 0.931816	test: 0.799499

Epoch: 10
Loss: 0.4230491661715538
ROC train: 0.908159	val: 0.669597	test: 0.799513
PRC train: 0.847778	val: 0.925452	test: 0.795323

Epoch: 11
Loss: 0.4036704762714211
ROC train: 0.904809	val: 0.631868	test: 0.797427
PRC train: 0.843360	val: 0.914591	test: 0.805104

Epoch: 12
Loss: 0.39962609651835057
ROC train: 0.905123	val: 0.646154	test: 0.782473
PRC train: 0.843155	val: 0.922091	test: 0.789537

Epoch: 13
Loss: 0.40515412928942124
ROC train: 0.917069	val: 0.684249	test: 0.800556
PRC train: 0.866805	val: 0.929850	test: 0.793243

Epoch: 14
Loss: 0.3865827205402347
ROC train: 0.922617	val: 0.694505	test: 0.808381
PRC train: 0.875341	val: 0.933201	test: 0.803196

Epoch: 15
Loss: 0.38425558922677083
ROC train: 0.921227	val: 0.675458	test: 0.810294
PRC train: 0.870086	val: 0.930910	test: 0.817672

Epoch: 16
Loss: 0.3887683641040114
ROC train: 0.926156	val: 0.685714	test: 0.802643
PRC train: 0.880757	val: 0.932506	test: 0.807430

Epoch: 17
Loss: 0.37854458760491483
ROC train: 0.927631	val: 0.671429	test: 0.789950
PRC train: 0.882651	val: 0.927314	test: 0.813209

Epoch: 18
Loss: 0.3763168637553659
ROC train: 0.929392	val: 0.653480	test: 0.794123
PRC train: 0.884781	val: 0.921482	test: 0.822644

Epoch: 19
Loss: 0.36045463495259206
ROC train: 0.931470	val: 0.656410	test: 0.816206
PRC train: 0.885846	val: 0.921638	test: 0.830090

Epoch: 20
Loss: 0.37033441118368127
ROC train: 0.930294	val: 0.651648	test: 0.797253
PRC train: 0.883266	val: 0.923438	test: 0.819275

Epoch: 21
Loss: 0.36479013004368827
ROC train: 0.929897	val: 0.655311	test: 0.771170
PRC train: 0.884064	val: 0.923999	test: 0.801520

Epoch: 22
Loss: 0.3612472389446708
ROC train: 0.936792	val: 0.681685	test: 0.793427
PRC train: 0.897311	val: 0.925938	test: 0.807708

Epoch: 23
Loss: 0.3682776673082303
ROC train: 0.935445	val: 0.671062	test: 0.808207
PRC train: 0.894426	val: 0.927345	test: 0.829535

Epoch: 24
Loss: 0.34620513609150955
ROC train: 0.935588	val: 0.699267	test: 0.802295
PRC train: 0.891517	val: 0.932314	test: 0.822117

Epoch: 25
Loss: 0.35146040967731784
ROC train: 0.936033	val: 0.708425	test: 0.801774
PRC train: 0.895420	val: 0.932303	test: 0.818238

Epoch: 26
Loss: 0.34774130499723654
ROC train: 0.941846	val: 0.676190	test: 0.804382
PRC train: 0.904564	val: 0.927281	test: 0.827533

Epoch: 27
Loss: 0.34342582114386444
ROC train: 0.938918	val: 0.656777	test: 0.805599
PRC train: 0.902830	val: 0.921918	test: 0.817045

Epoch: 28
Loss: 0.3395015961970335
ROC train: 0.934629	val: 0.668864	test: 0.794992
PRC train: 0.899216	val: 0.926362	test: 0.804313

Epoch: 29
Loss: 0.3397546480316863
ROC train: 0.942406	val: 0.679487	test: 0.787167
PRC train: 0.906558	val: 0.928675	test: 0.801987

Epoch: 30
Loss: 0.3442832431373647
ROC train: 0.941667	val: 0.660440	test: 0.778126
PRC train: 0.907890	val: 0.924477	test: 0.793291

Epoch: 31
Loss: 0.3503659686997909
ROC train: 0.944769	val: 0.654579	test: 0.794644
PRC train: 0.912207	val: 0.923418	test: 0.810039

Epoch: 32
Loss: 0.32730133826870234
ROC train: 0.945836	val: 0.657143	test: 0.798818
PRC train: 0.911837	val: 0.926570	test: 0.822779

Epoch: 33
Loss: 0.32785289014002583Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/bace/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/bace/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/bace/scaff/train_prop=0.7/bace_scaff_4_26-05_11-11-03  ]
[ Using Seed :  4  ]
[ Using device :  cuda:1  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
split via scaffold
Data(edge_attr=[66, 2], edge_index=[2, 66], id=[1], x=[31, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6805539585302587
ROC train: 0.711068	val: 0.557717	test: 0.678404
PRC train: 0.637436	val: 0.335881	test: 0.818687

Epoch: 2
Loss: 0.6364354867404373
ROC train: 0.752105	val: 0.617230	test: 0.728422
PRC train: 0.675923	val: 0.341178	test: 0.839193

Epoch: 3
Loss: 0.6077846645680807
ROC train: 0.794829	val: 0.643869	test: 0.753341
PRC train: 0.717249	val: 0.341287	test: 0.844788

Epoch: 4
Loss: 0.5633102765816369
ROC train: 0.830523	val: 0.662156	test: 0.771217
PRC train: 0.743553	val: 0.351278	test: 0.858402

Epoch: 5
Loss: 0.5575395672159411
ROC train: 0.857574	val: 0.675581	test: 0.808415
PRC train: 0.778459	val: 0.364587	test: 0.880202

Epoch: 6
Loss: 0.5283439750428338
ROC train: 0.862356	val: 0.688372	test: 0.811665
PRC train: 0.816165	val: 0.377019	test: 0.885876

Epoch: 7
Loss: 0.5013339780199892
ROC train: 0.859960	val: 0.679810	test: 0.799928
PRC train: 0.801592	val: 0.364571	test: 0.873293

Epoch: 8
Loss: 0.4675115289682233
ROC train: 0.879242	val: 0.685624	test: 0.820964
PRC train: 0.828437	val: 0.369997	test: 0.894901

Epoch: 9
Loss: 0.4763592475086825
ROC train: 0.891865	val: 0.697992	test: 0.831528
PRC train: 0.850845	val: 0.378659	test: 0.907194

Epoch: 10
Loss: 0.4477938083330349
ROC train: 0.889637	val: 0.711522	test: 0.825930
PRC train: 0.842851	val: 0.375571	test: 0.908608

Epoch: 11
Loss: 0.474419547727008
ROC train: 0.886151	val: 0.711734	test: 0.826923
PRC train: 0.837131	val: 0.371794	test: 0.906114

Epoch: 12
Loss: 0.46210716136372765
ROC train: 0.899417	val: 0.709619	test: 0.843355
PRC train: 0.866344	val: 0.372550	test: 0.912759

Epoch: 13
Loss: 0.4035094730584986
ROC train: 0.902389	val: 0.701797	test: 0.850758
PRC train: 0.869463	val: 0.383910	test: 0.907607

Epoch: 14
Loss: 0.41530375373460104
ROC train: 0.907362	val: 0.707611	test: 0.859516
PRC train: 0.874529	val: 0.372073	test: 0.920901

Epoch: 15
Loss: 0.4478436872788607
ROC train: 0.909625	val: 0.722093	test: 0.861231
PRC train: 0.879702	val: 0.408093	test: 0.921545

Epoch: 16
Loss: 0.4125290904710571
ROC train: 0.895527	val: 0.700423	test: 0.850939
PRC train: 0.862068	val: 0.418216	test: 0.910822

Epoch: 17
Loss: 0.4150977391978553
ROC train: 0.912705	val: 0.721036	test: 0.857981
PRC train: 0.887840	val: 0.418697	test: 0.920050

Epoch: 18
Loss: 0.3912955967229696
ROC train: 0.908060	val: 0.715645	test: 0.833243
PRC train: 0.876876	val: 0.395790	test: 0.912157

Epoch: 19
Loss: 0.430484937343496
ROC train: 0.914853	val: 0.714905	test: 0.842452
PRC train: 0.886487	val: 0.412139	test: 0.918473

Epoch: 20
Loss: 0.40887519865707117
ROC train: 0.911856	val: 0.696300	test: 0.843355
PRC train: 0.883289	val: 0.422631	test: 0.914787

Epoch: 21
Loss: 0.4103659882128493
ROC train: 0.920747	val: 0.702854	test: 0.841910
PRC train: 0.895640	val: 0.429279	test: 0.918443

Epoch: 22
Loss: 0.37746656917034765
ROC train: 0.921783	val: 0.708668	test: 0.834507
PRC train: 0.898997	val: 0.416818	test: 0.911523

Epoch: 23
Loss: 0.38848936344700397
ROC train: 0.925360	val: 0.725053	test: 0.836674
PRC train: 0.903048	val: 0.432085	test: 0.912168

Epoch: 24
Loss: 0.36726116158360994
ROC train: 0.925892	val: 0.731607	test: 0.833243
PRC train: 0.902746	val: 0.426690	test: 0.911640

Epoch: 25
Loss: 0.38556860873224985
ROC train: 0.924352	val: 0.738689	test: 0.825298
PRC train: 0.899674	val: 0.444949	test: 0.910439

Epoch: 26
Loss: 0.42041555551468335
ROC train: 0.927393	val: 0.743129	test: 0.824395
PRC train: 0.901033	val: 0.463464	test: 0.907102

Epoch: 27
Loss: 0.36489508796603
ROC train: 0.928242	val: 0.746512	test: 0.828819
PRC train: 0.901827	val: 0.466617	test: 0.904595

Epoch: 28
Loss: 0.3535527562111082
ROC train: 0.931844	val: 0.748097	test: 0.835771
PRC train: 0.910380	val: 0.433970	test: 0.914254

Epoch: 29
Loss: 0.38123185030463
ROC train: 0.930246	val: 0.737632	test: 0.835952
PRC train: 0.910594	val: 0.420227	test: 0.916663

Epoch: 30
Loss: 0.3703269211501999
ROC train: 0.932034	val: 0.737104	test: 0.837216
PRC train: 0.913315	val: 0.429001	test: 0.913890

Epoch: 31
Loss: 0.40280560552689704
ROC train: 0.934182	val: 0.734567	test: 0.853377
PRC train: 0.914011	val: 0.436036	test: 0.921229

Epoch: 32
Loss: 0.4219094583532029
ROC train: 0.935697	val: 0.735518	test: 0.858884
PRC train: 0.917130	val: 0.437556	test: 0.926041

Epoch: 33
Loss: 0.3483698267773149
ROC train: 0.933574	val: 0.742600	test: 0.830173Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/bace/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/bace/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/bace/scaff/train_prop=0.8/bace_scaff_5_26-05_11-11-03  ]
[ Using Seed :  5  ]
[ Using device :  cuda:2  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
split via scaffold
Data(edge_attr=[66, 2], edge_index=[2, 66], id=[1], x=[31, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6605677580932388
ROC train: 0.712500	val: 0.566667	test: 0.654495
PRC train: 0.578319	val: 0.892133	test: 0.662610

Epoch: 2
Loss: 0.6035709348143644
ROC train: 0.752491	val: 0.550916	test: 0.700226
PRC train: 0.624832	val: 0.886545	test: 0.691249

Epoch: 3
Loss: 0.5536979218077065
ROC train: 0.809067	val: 0.595238	test: 0.768736
PRC train: 0.687961	val: 0.897468	test: 0.747498

Epoch: 4
Loss: 0.5125954875808091
ROC train: 0.850870	val: 0.624908	test: 0.789950
PRC train: 0.734023	val: 0.904081	test: 0.762613

Epoch: 5
Loss: 0.4739431834494221
ROC train: 0.866236	val: 0.627106	test: 0.766823
PRC train: 0.750912	val: 0.903589	test: 0.763333

Epoch: 6
Loss: 0.4705763558794206
ROC train: 0.869920	val: 0.621245	test: 0.742306
PRC train: 0.762689	val: 0.902098	test: 0.750382

Epoch: 7
Loss: 0.44191927977139744
ROC train: 0.888682	val: 0.635165	test: 0.795166
PRC train: 0.811964	val: 0.923689	test: 0.786118

Epoch: 8
Loss: 0.42858419288602717
ROC train: 0.896184	val: 0.659707	test: 0.792732
PRC train: 0.830874	val: 0.922153	test: 0.781286

Epoch: 9
Loss: 0.432269683516178
ROC train: 0.903131	val: 0.695604	test: 0.783864
PRC train: 0.843830	val: 0.929940	test: 0.792598

Epoch: 10
Loss: 0.4199570497188506
ROC train: 0.899324	val: 0.695604	test: 0.797427
PRC train: 0.837684	val: 0.932348	test: 0.803321

Epoch: 11
Loss: 0.4221729157338186
ROC train: 0.913567	val: 0.667399	test: 0.813250
PRC train: 0.862160	val: 0.927392	test: 0.828466

Epoch: 12
Loss: 0.4018344268382797
ROC train: 0.918696	val: 0.656777	test: 0.821075
PRC train: 0.869144	val: 0.925002	test: 0.834696

Epoch: 13
Loss: 0.4116734671857897
ROC train: 0.916137	val: 0.654212	test: 0.827682
PRC train: 0.866356	val: 0.924158	test: 0.832834

Epoch: 14
Loss: 0.40181636740045634
ROC train: 0.916612	val: 0.646886	test: 0.819510
PRC train: 0.867008	val: 0.922907	test: 0.816606

Epoch: 15
Loss: 0.3911922730542564
ROC train: 0.920505	val: 0.668864	test: 0.803165
PRC train: 0.873677	val: 0.928192	test: 0.818110

Epoch: 16
Loss: 0.37296052005325986
ROC train: 0.928276	val: 0.665201	test: 0.819857
PRC train: 0.885087	val: 0.923865	test: 0.829616

Epoch: 17
Loss: 0.3735269092837597
ROC train: 0.925468	val: 0.662637	test: 0.816206
PRC train: 0.879384	val: 0.923434	test: 0.825959

Epoch: 18
Loss: 0.3897569148242617
ROC train: 0.922363	val: 0.646154	test: 0.805773
PRC train: 0.877255	val: 0.920854	test: 0.808314

Epoch: 19
Loss: 0.3699928803918894
ROC train: 0.929720	val: 0.638828	test: 0.816380
PRC train: 0.891035	val: 0.920025	test: 0.823330

Epoch: 20
Loss: 0.37121000636407
ROC train: 0.928616	val: 0.636630	test: 0.785429
PRC train: 0.887303	val: 0.920463	test: 0.822941

Epoch: 21
Loss: 0.364261950332757
ROC train: 0.934038	val: 0.674359	test: 0.802817
PRC train: 0.893652	val: 0.927178	test: 0.814326

Epoch: 22
Loss: 0.3678970640005984
ROC train: 0.935522	val: 0.657875	test: 0.811511
PRC train: 0.896541	val: 0.925052	test: 0.825928

Epoch: 23
Loss: 0.35200175771555503
ROC train: 0.932697	val: 0.662637	test: 0.806295
PRC train: 0.893698	val: 0.926031	test: 0.815438

Epoch: 24
Loss: 0.36208486250404426
ROC train: 0.936102	val: 0.664103	test: 0.789950
PRC train: 0.896071	val: 0.926159	test: 0.792291

Epoch: 25
Loss: 0.3559184670485382
ROC train: 0.937531	val: 0.670330	test: 0.766302
PRC train: 0.898309	val: 0.924155	test: 0.794031

Epoch: 26
Loss: 0.3651641274368432
ROC train: 0.940839	val: 0.657509	test: 0.799165
PRC train: 0.904719	val: 0.923335	test: 0.817510

Epoch: 27
Loss: 0.3448293013657006
ROC train: 0.932828	val: 0.647985	test: 0.793427
PRC train: 0.894981	val: 0.918879	test: 0.787702

Epoch: 28
Loss: 0.36067005551233344
ROC train: 0.934309	val: 0.662271	test: 0.803339
PRC train: 0.895556	val: 0.921461	test: 0.801346

Epoch: 29
Loss: 0.33854101914075985
ROC train: 0.939592	val: 0.662637	test: 0.811511
PRC train: 0.904208	val: 0.922102	test: 0.824147

Epoch: 30
Loss: 0.33080323914674625
ROC train: 0.945671	val: 0.671062	test: 0.814989
PRC train: 0.913381	val: 0.924417	test: 0.827096

Epoch: 31
Loss: 0.33364719679718824
ROC train: 0.947326	val: 0.664835	test: 0.811337
PRC train: 0.916471	val: 0.922515	test: 0.823650

Epoch: 32
Loss: 0.33267312469780763
ROC train: 0.946555	val: 0.650183	test: 0.803165
PRC train: 0.915764	val: 0.916374	test: 0.818286

Epoch: 33
Loss: 0.3361185286830962
ROC train: 0.948824	val: 0.670696	test: 0.801426
ROC train: 0.932187	val: 0.842075	test: 0.767051
PRC train: 0.919481	val: 0.400743	test: 0.875731

Epoch: 34
Loss: 0.3755078757948218
ROC train: 0.937505	val: 0.843629	test: 0.765351
PRC train: 0.923100	val: 0.406605	test: 0.872933

Epoch: 35
Loss: 0.3591270057853245
ROC train: 0.938552	val: 0.841589	test: 0.768030
PRC train: 0.924639	val: 0.436200	test: 0.869396

Epoch: 36
Loss: 0.3720638837447191
ROC train: 0.940250	val: 0.834693	test: 0.770812
PRC train: 0.929507	val: 0.424961	test: 0.866306

Epoch: 37
Loss: 0.36270727998414903
ROC train: 0.939199	val: 0.829060	test: 0.761642
PRC train: 0.929433	val: 0.385362	test: 0.863314

Epoch: 38
Loss: 0.3595020433859349
ROC train: 0.939715	val: 0.828963	test: 0.766794
PRC train: 0.931714	val: 0.393415	test: 0.857708

Epoch: 39
Loss: 0.36341222875484047
ROC train: 0.942245	val: 0.849165	test: 0.781115
PRC train: 0.932883	val: 0.423652	test: 0.874874

Epoch: 40
Loss: 0.3630512279816413
ROC train: 0.941223	val: 0.856546	test: 0.780857
PRC train: 0.930207	val: 0.414662	test: 0.882121

Epoch: 41
Loss: 0.32797829073999285
ROC train: 0.942498	val: 0.849747	test: 0.766124
PRC train: 0.933044	val: 0.418510	test: 0.873137

Epoch: 42
Loss: 0.34761538712775664
ROC train: 0.942445	val: 0.844697	test: 0.758654
PRC train: 0.933547	val: 0.409413	test: 0.863421

Epoch: 43
Loss: 0.34867902354218006
ROC train: 0.943783	val: 0.850816	test: 0.765403
PRC train: 0.933889	val: 0.404968	test: 0.869523

Epoch: 44
Loss: 0.3353001869452513
ROC train: 0.945194	val: 0.842366	test: 0.765454
PRC train: 0.934737	val: 0.393633	test: 0.868686

Epoch: 45
Loss: 0.35242155754725585
ROC train: 0.944440	val: 0.845280	test: 0.773027
PRC train: 0.934135	val: 0.383518	test: 0.879299

Epoch: 46
Loss: 0.3372058232231635
ROC train: 0.945009	val: 0.846348	test: 0.775448
PRC train: 0.935318	val: 0.388354	test: 0.880744

Epoch: 47
Loss: 0.3536353672466016
ROC train: 0.945933	val: 0.846154	test: 0.774624
PRC train: 0.938167	val: 0.415136	test: 0.876026

Epoch: 48
Loss: 0.3452525655003862
ROC train: 0.948284	val: 0.848291	test: 0.760973
PRC train: 0.942392	val: 0.417161	test: 0.856717

Epoch: 49
Loss: 0.3294171564804188
ROC train: 0.952503	val: 0.851593	test: 0.754070
PRC train: 0.945882	val: 0.422739	test: 0.856441

Epoch: 50
Loss: 0.3483938760577419
ROC train: 0.953763	val: 0.849942	test: 0.757470
PRC train: 0.945645	val: 0.419228	test: 0.865095

Epoch: 51
Loss: 0.3426247336744487
ROC train: 0.952400	val: 0.839549	test: 0.761488
PRC train: 0.944397	val: 0.401978	test: 0.870656

Epoch: 52
Loss: 0.32873011516882306
ROC train: 0.951948	val: 0.836247	test: 0.759994
PRC train: 0.944371	val: 0.408901	test: 0.873025

Epoch: 53
Loss: 0.31211137192422267
ROC train: 0.950138	val: 0.839744	test: 0.762054
PRC train: 0.943059	val: 0.422441	test: 0.870578

Epoch: 54
Loss: 0.3350848108326379
ROC train: 0.951237	val: 0.848291	test: 0.762673
PRC train: 0.943867	val: 0.413016	test: 0.874017

Epoch: 55
Loss: 0.3506698769092369
ROC train: 0.953072	val: 0.828768	test: 0.749176
PRC train: 0.944772	val: 0.368357	test: 0.869346

Epoch: 56
Loss: 0.3302324048648815
ROC train: 0.953437	val: 0.837315	test: 0.763754
PRC train: 0.945568	val: 0.386770	test: 0.876486

Epoch: 57
Loss: 0.324809877524301
ROC train: 0.949943	val: 0.851399	test: 0.770966
PRC train: 0.941583	val: 0.414860	test: 0.878455

Epoch: 58
Loss: 0.32911877936489137
ROC train: 0.953369	val: 0.850816	test: 0.762930
PRC train: 0.944980	val: 0.405511	test: 0.873491

Epoch: 59
Loss: 0.3366242072737132
ROC train: 0.954902	val: 0.848485	test: 0.771327
PRC train: 0.946759	val: 0.396014	test: 0.880402

Epoch: 60
Loss: 0.30050411384336273
ROC train: 0.953870	val: 0.852176	test: 0.773903
PRC train: 0.946221	val: 0.399397	test: 0.883156

Epoch: 61
Loss: 0.33900538250438883
ROC train: 0.955675	val: 0.849359	test: 0.759736
PRC train: 0.949663	val: 0.406831	test: 0.870160

Epoch: 62
Loss: 0.3164047467812693
ROC train: 0.956648	val: 0.847805	test: 0.761848
PRC train: 0.951526	val: 0.426080	test: 0.866679

Epoch: 63
Loss: 0.3257932898181953
ROC train: 0.958361	val: 0.838772	test: 0.758551
PRC train: 0.954748	val: 0.402993	test: 0.863744

Epoch: 64
Loss: 0.3211750362292871
ROC train: 0.958794	val: 0.842075	test: 0.760148
PRC train: 0.954964	val: 0.407154	test: 0.868528

Epoch: 65
Loss: 0.31778209912212335
ROC train: 0.959510	val: 0.844503	test: 0.761230
PRC train: 0.954702	val: 0.411795	test: 0.871140

Epoch: 66
Loss: 0.318396848538301
ROC train: 0.956259	val: 0.856061	test: 0.771997
PRC train: 0.949399	val: 0.413702	test: 0.881682

Epoch: 67
Loss: 0.29868153968150224
ROC train: 0.955661	val: 0.859557	test: 0.774521
PRC train: 0.949327	val: 0.427450	test: 0.880502

Epoch: 68
Loss: 0.3050451910245795
ROC train: 0.958055	val: 0.853924	test: 0.767463
PRC train: 0.952875	val: 0.431835	test: 0.873463

Epoch: 69
Loss: 0.29974056942514715
ROC train: 0.961261	val: 0.845183	test: 0.749124
PRC train: 0.956634	val: 0.424464	test: 0.862370

Epoch: 70
Loss: 0.29283944673760104
ROC train: 0.960960	val: 0.841395	test: 0.746445
PRC train: 0.956231	val: 0.418608	test: 0.855992

Epoch: 71
Loss: 0.2917231452177133
ROC train: 0.960191	val: 0.856352	test: 0.760148
PRC train: 0.954118	val: 0.420466	test: 0.872063

Epoch: 72
Loss: 0.31491889029988496
ROC train: 0.962176	val: 0.849165	test: 0.753709
PRC train: 0.957709	val: 0.407266	test: 0.864921

Epoch: 73
Loss: 0.3222385142661461
ROC train: 0.962308	val: 0.844017	test: 0.752885
PRC train: 0.958228	val: 0.400792	test: 0.864308

Epoch: 74
Loss: 0.3128918756811438
ROC train: 0.962721	val: 0.847416	test: 0.757315
PRC train: 0.958563	val: 0.400261	test: 0.868540

Epoch: 75
Loss: 0.3123453260967674
ROC train: 0.961738	val: 0.856838	test: 0.775654
PRC train: 0.955496	val: 0.398606	test: 0.884946

Epoch: 76
Loss: 0.2898862721900821
ROC train: 0.961991	val: 0.850136	test: 0.769163
PRC train: 0.954818	val: 0.384002	test: 0.882733

Epoch: 77
Loss: 0.296347910216591
ROC train: 0.959928	val: 0.840423	test: 0.752885
PRC train: 0.953153	val: 0.363386	test: 0.873617

Epoch: 78
Loss: 0.285039024564813
ROC train: 0.965660	val: 0.835859	test: 0.746549
PRC train: 0.959725	val: 0.369395	test: 0.864854

Epoch: 79
Loss: 0.29437075221203957
ROC train: 0.964371	val: 0.830808	test: 0.754739
PRC train: 0.959942	val: 0.375622	test: 0.859425

Epoch: 80
Loss: 0.2875777128868073
ROC train: 0.965855	val: 0.834499	test: 0.759891
PRC train: 0.961548	val: 0.372955	test: 0.864236

Epoch: 81
Loss: 0.30993867755693655
ROC train: 0.962921	val: 0.842269	test: 0.768236
PRC train: 0.957541	val: 0.374232	test: 0.876595

Epoch: 82
Loss: 0.28766315485984534
ROC train: 0.964128	val: 0.858197	test: 0.780084
PRC train: 0.959315	val: 0.410040	test: 0.882417

Epoch: 83
Loss: 0.28510066144474655
ROC train: 0.965500	val: 0.854604	test: 0.771894
PRC train: 0.961709	val: 0.408335	test: 0.880704

Epoch: 84
Loss: 0.2905739020015831
ROC train: 0.966682	val: 0.860237	test: 0.766073
PRC train: 0.962688	val: 0.420931	test: 0.879275

Epoch: 85
Loss: 0.283923003906823
ROC train: 0.966862	val: 0.875486	test: 0.764218
PRC train: 0.963768	val: 0.464351	test: 0.874374

Epoch: 86
Loss: 0.3022464935792747
ROC train: 0.966663	val: 0.868687	test: 0.758706
PRC train: 0.963518	val: 0.466117	test: 0.865489

Epoch: 87
Loss: 0.2801800436578783
ROC train: 0.963325	val: 0.848388	test: 0.750206
PRC train: 0.959535	val: 0.421795	test: 0.855543

Epoch: 88
Loss: 0.31041462323550345
ROC train: 0.966454	val: 0.856643	test: 0.757367
PRC train: 0.962661	val: 0.438724	test: 0.866067

Epoch: 89
Loss: 0.29231667099977204
ROC train: 0.962580	val: 0.863636	test: 0.760921
PRC train: 0.957671	val: 0.448945	test: 0.866222

Epoch: 90
Loss: 0.2826805110265289
ROC train: 0.966580	val: 0.849553	test: 0.754945
PRC train: 0.963260	val: 0.409936	test: 0.865984

Epoch: 91
Loss: 0.2705849309968056
ROC train: 0.971349	val: 0.842949	test: 0.749176
PRC train: 0.968781	val: 0.391244	test: 0.864747

Epoch: 92
Loss: 0.2911638013605654
ROC train: 0.966794	val: 0.859266	test: 0.770400
PRC train: 0.961397	val: 0.415565	test: 0.880671

Epoch: 93
Loss: 0.28901523690274816
ROC train: 0.966400	val: 0.866162	test: 0.763342
PRC train: 0.960826	val: 0.430860	test: 0.878759

Epoch: 94
Loss: 0.2994412223773062
ROC train: 0.938941	val: 0.831779	test: 0.759685
PRC train: 0.929391	val: 0.371221	test: 0.869979

Epoch: 34
Loss: 0.3661243969601106
ROC train: 0.941836	val: 0.852758	test: 0.773130
PRC train: 0.931815	val: 0.420452	test: 0.876657

Epoch: 35
Loss: 0.36812939655494087
ROC train: 0.940011	val: 0.853147	test: 0.780857
PRC train: 0.927793	val: 0.405579	test: 0.882598

Epoch: 36
Loss: 0.3610267698529054
ROC train: 0.940863	val: 0.844697	test: 0.776272
PRC train: 0.929533	val: 0.383852	test: 0.882040

Epoch: 37
Loss: 0.3503860757550556
ROC train: 0.940771	val: 0.838384	test: 0.773697
PRC train: 0.930593	val: 0.393555	test: 0.879479

Epoch: 38
Loss: 0.3490395562071136
ROC train: 0.942099	val: 0.842560	test: 0.771482
PRC train: 0.932622	val: 0.425845	test: 0.878829

Epoch: 39
Loss: 0.35633428206453466
ROC train: 0.941865	val: 0.847028	test: 0.767669
PRC train: 0.932272	val: 0.386505	test: 0.879239

Epoch: 40
Loss: 0.34680777669325463
ROC train: 0.942114	val: 0.845474	test: 0.770606
PRC train: 0.932512	val: 0.388378	test: 0.882451

Epoch: 41
Loss: 0.3280645065662621
ROC train: 0.945184	val: 0.847611	test: 0.776633
PRC train: 0.934831	val: 0.399368	test: 0.883039

Epoch: 42
Loss: 0.34648598584328855
ROC train: 0.946352	val: 0.857615	test: 0.777097
PRC train: 0.936849	val: 0.414120	test: 0.882225

Epoch: 43
Loss: 0.34645243298093625
ROC train: 0.945500	val: 0.849650	test: 0.763754
PRC train: 0.936822	val: 0.412446	test: 0.874143

Epoch: 44
Loss: 0.33838905970734984
ROC train: 0.948517	val: 0.847999	test: 0.751442
PRC train: 0.942106	val: 0.423514	test: 0.865449

Epoch: 45
Loss: 0.34093774339583005
ROC train: 0.948240	val: 0.846057	test: 0.762570
PRC train: 0.940469	val: 0.408361	test: 0.874230

Epoch: 46
Loss: 0.3354313716135536
ROC train: 0.948809	val: 0.844600	test: 0.770194
PRC train: 0.940741	val: 0.409514	test: 0.879224

Epoch: 47
Loss: 0.338806204216524
ROC train: 0.950517	val: 0.844503	test: 0.773697
PRC train: 0.942597	val: 0.405059	test: 0.881967

Epoch: 48
Loss: 0.34775720565403523
ROC train: 0.952838	val: 0.843337	test: 0.775345
PRC train: 0.944202	val: 0.404250	test: 0.885321

Epoch: 49
Loss: 0.332641516323811
ROC train: 0.951875	val: 0.837121	test: 0.768906
PRC train: 0.942862	val: 0.395699	test: 0.883910

Epoch: 50
Loss: 0.3371280680889203
ROC train: 0.950731	val: 0.844600	test: 0.766021
PRC train: 0.942206	val: 0.398601	test: 0.882684

Epoch: 51
Loss: 0.3460174608636523
ROC train: 0.949272	val: 0.854507	test: 0.762673
PRC train: 0.941723	val: 0.409091	test: 0.878864

Epoch: 52
Loss: 0.34401245673685127
ROC train: 0.952960	val: 0.850427	test: 0.759221
PRC train: 0.945976	val: 0.397477	test: 0.874883

Epoch: 53
Loss: 0.30073107533452614
ROC train: 0.954488	val: 0.843240	test: 0.749073
PRC train: 0.949052	val: 0.406559	test: 0.864969

Epoch: 54
Loss: 0.3135278831994319
ROC train: 0.956108	val: 0.841298	test: 0.755615
PRC train: 0.948908	val: 0.422221	test: 0.870487

Epoch: 55
Loss: 0.2962073498562866
ROC train: 0.956274	val: 0.840909	test: 0.759582
PRC train: 0.950235	val: 0.423007	test: 0.874751

Epoch: 56
Loss: 0.3410824511106393
ROC train: 0.954250	val: 0.844017	test: 0.748403
PRC train: 0.947525	val: 0.409904	test: 0.867823

Epoch: 57
Loss: 0.32128520854631626
ROC train: 0.952872	val: 0.856935	test: 0.758551
PRC train: 0.946453	val: 0.415061	test: 0.870163

Epoch: 58
Loss: 0.3289173488689092
ROC train: 0.955724	val: 0.856061	test: 0.752112
PRC train: 0.950217	val: 0.445451	test: 0.864160

Epoch: 59
Loss: 0.3236229674868953
ROC train: 0.954206	val: 0.846931	test: 0.735730
PRC train: 0.947484	val: 0.441147	test: 0.853567

Epoch: 60
Loss: 0.3284506271592985
ROC train: 0.955612	val: 0.846931	test: 0.743870
PRC train: 0.948596	val: 0.434046	test: 0.863549

Epoch: 61
Loss: 0.30834569046043564
ROC train: 0.957393	val: 0.854409	test: 0.757624
PRC train: 0.951014	val: 0.475844	test: 0.870460

Epoch: 62
Loss: 0.32076938205527206
ROC train: 0.957972	val: 0.853438	test: 0.746239
PRC train: 0.951907	val: 0.445657	test: 0.868601

Epoch: 63
Loss: 0.3211025619952979
ROC train: 0.956147	val: 0.840909	test: 0.735730
PRC train: 0.950261	val: 0.407671	test: 0.864780

Epoch: 64
Loss: 0.3147250507465134
ROC train: 0.959481	val: 0.845960	test: 0.743406
PRC train: 0.953206	val: 0.423200	test: 0.866661

Epoch: 65
Loss: 0.30213798455184937
ROC train: 0.960381	val: 0.839355	test: 0.747218
PRC train: 0.953561	val: 0.421978	test: 0.865892

Epoch: 66
Loss: 0.31287582324035434
ROC train: 0.961446	val: 0.838967	test: 0.753142
PRC train: 0.956531	val: 0.411101	test: 0.872335

Epoch: 67
Loss: 0.3255290508131586
ROC train: 0.958478	val: 0.832168	test: 0.752215
PRC train: 0.953857	val: 0.394530	test: 0.872878

Epoch: 68
Loss: 0.29857205191547104
ROC train: 0.959174	val: 0.843143	test: 0.759376
PRC train: 0.954541	val: 0.404266	test: 0.874304

Epoch: 69
Loss: 0.295066019100675
ROC train: 0.963252	val: 0.846542	test: 0.755718
PRC train: 0.958835	val: 0.414470	test: 0.866470

Epoch: 70
Loss: 0.2963127949240289
ROC train: 0.964269	val: 0.851884	test: 0.757057
PRC train: 0.960614	val: 0.414509	test: 0.866996

Epoch: 71
Loss: 0.30798124468009735
ROC train: 0.964804	val: 0.859557	test: 0.751494
PRC train: 0.961423	val: 0.419421	test: 0.862890

Epoch: 72
Loss: 0.2729124207769559
ROC train: 0.964064	val: 0.861111	test: 0.741500
PRC train: 0.959996	val: 0.425603	test: 0.861851

Epoch: 73
Loss: 0.29033745683944734
ROC train: 0.966308	val: 0.853827	test: 0.744024
PRC train: 0.961321	val: 0.428908	test: 0.865605

Epoch: 74
Loss: 0.2904265302167961
ROC train: 0.965772	val: 0.844211	test: 0.737430
PRC train: 0.961268	val: 0.428752	test: 0.861438

Epoch: 75
Loss: 0.2822138163788362
ROC train: 0.959412	val: 0.842657	test: 0.726767
PRC train: 0.953305	val: 0.422361	test: 0.861022

Epoch: 76
Loss: 0.29418361260143777
ROC train: 0.962205	val: 0.850524	test: 0.737997
PRC train: 0.956722	val: 0.431247	test: 0.867210

Epoch: 77
Loss: 0.323873006104269
ROC train: 0.965952	val: 0.855478	test: 0.729858
PRC train: 0.961482	val: 0.427256	test: 0.854360

Epoch: 78
Loss: 0.29810318647430356
ROC train: 0.964561	val: 0.846542	test: 0.722749
PRC train: 0.960010	val: 0.414150	test: 0.849862

Epoch: 79
Loss: 0.311627297243713
ROC train: 0.967174	val: 0.839549	test: 0.730167
PRC train: 0.963769	val: 0.403545	test: 0.852460

Epoch: 80
Loss: 0.2972373906159832
ROC train: 0.959159	val: 0.834013	test: 0.744179
PRC train: 0.956586	val: 0.394425	test: 0.846800

Epoch: 81
Loss: 0.28321330754913043
ROC train: 0.961879	val: 0.859363	test: 0.764733
PRC train: 0.957796	val: 0.426842	test: 0.866555

Epoch: 82
Loss: 0.28118280033732906
ROC train: 0.964006	val: 0.859363	test: 0.769266
PRC train: 0.959903	val: 0.423194	test: 0.868123

Epoch: 83
Loss: 0.27685211958288347
ROC train: 0.965714	val: 0.857226	test: 0.766176
PRC train: 0.961366	val: 0.418302	test: 0.871576

Epoch: 84
Loss: 0.2714498938126976
ROC train: 0.967801	val: 0.854507	test: 0.758139
PRC train: 0.963636	val: 0.421143	test: 0.870854

Epoch: 85
Loss: 0.2956894809415622
ROC train: 0.968449	val: 0.857420	test: 0.746549
PRC train: 0.964349	val: 0.427931	test: 0.864865

Epoch: 86
Loss: 0.268884636982672
ROC train: 0.971665	val: 0.856838	test: 0.743767
PRC train: 0.968154	val: 0.429585	test: 0.854348

Epoch: 87
Loss: 0.2769182025135878
ROC train: 0.970745	val: 0.851010	test: 0.742943
PRC train: 0.967155	val: 0.422964	test: 0.848475

Epoch: 88
Loss: 0.2823216615459955
ROC train: 0.971996	val: 0.849165	test: 0.743046
PRC train: 0.968427	val: 0.418309	test: 0.856934

Epoch: 89
Loss: 0.2696378955332711
ROC train: 0.969865	val: 0.840132	test: 0.726818
PRC train: 0.966769	val: 0.409766	test: 0.846424

Epoch: 90
Loss: 0.2595187051004816
ROC train: 0.972356	val: 0.839258	test: 0.727179
PRC train: 0.970056	val: 0.406165	test: 0.844344

Epoch: 91
Loss: 0.27480059607435625
ROC train: 0.970351	val: 0.855769	test: 0.739388
PRC train: 0.966674	val: 0.428118	test: 0.851384

Epoch: 92
Loss: 0.28492335273819125
ROC train: 0.969154	val: 0.849942	test: 0.742273
PRC train: 0.965537	val: 0.429719	test: 0.849832

Epoch: 93
Loss: 0.28811258952050167
ROC train: 0.972551	val: 0.843726	test: 0.742324
PRC train: 0.970601	val: 0.425665	test: 0.865022

Epoch: 94
Loss: 0.2875189095638817
PRC train: 0.922087	val: 0.406356	test: 0.864573

Epoch: 34
Loss: 0.3681877216918731
ROC train: 0.938547	val: 0.866647	test: 0.749639
PRC train: 0.925934	val: 0.437581	test: 0.865578

Epoch: 35
Loss: 0.35137025408093764
ROC train: 0.939530	val: 0.867618	test: 0.753297
PRC train: 0.926437	val: 0.455784	test: 0.865234

Epoch: 36
Loss: 0.35944538874436244
ROC train: 0.939914	val: 0.858974	test: 0.760354
PRC train: 0.929360	val: 0.442162	test: 0.864748

Epoch: 37
Loss: 0.3394082879190738
ROC train: 0.941593	val: 0.857032	test: 0.754533
PRC train: 0.932681	val: 0.436566	test: 0.864243

Epoch: 38
Loss: 0.3296815242775665
ROC train: 0.943092	val: 0.851981	test: 0.753812
PRC train: 0.932368	val: 0.419755	test: 0.866626

Epoch: 39
Loss: 0.35222264823898697
ROC train: 0.933077	val: 0.840423	test: 0.757521
PRC train: 0.922765	val: 0.406906	test: 0.863091

Epoch: 40
Loss: 0.3509271343452499
ROC train: 0.946581	val: 0.860043	test: 0.766073
PRC train: 0.934862	val: 0.430099	test: 0.876528

Epoch: 41
Loss: 0.33745672077135536
ROC train: 0.942566	val: 0.850913	test: 0.753555
PRC train: 0.929652	val: 0.386241	test: 0.871772

Epoch: 42
Loss: 0.34579371540931547
ROC train: 0.944014	val: 0.852564	test: 0.752061
PRC train: 0.931339	val: 0.399105	test: 0.869825

Epoch: 43
Loss: 0.35056104031111046
ROC train: 0.947826	val: 0.851593	test: 0.756903
PRC train: 0.938536	val: 0.409086	test: 0.867706

Epoch: 44
Loss: 0.34797982330734417
ROC train: 0.946031	val: 0.839646	test: 0.758860
PRC train: 0.936976	val: 0.392586	test: 0.864839

Epoch: 45
Loss: 0.3309104115448568
ROC train: 0.946420	val: 0.850913	test: 0.765609
PRC train: 0.936880	val: 0.402572	test: 0.873592

Epoch: 46
Loss: 0.3477026966490633
ROC train: 0.946284	val: 0.847319	test: 0.772666
PRC train: 0.937257	val: 0.397183	test: 0.878121

Epoch: 47
Loss: 0.32042732084874137
ROC train: 0.947539	val: 0.851690	test: 0.770091
PRC train: 0.937394	val: 0.382254	test: 0.880360

Epoch: 48
Loss: 0.35282836360285474
ROC train: 0.947792	val: 0.845765	test: 0.757109
PRC train: 0.936837	val: 0.376607	test: 0.873323

Epoch: 49
Loss: 0.33945928094045735
ROC train: 0.945218	val: 0.845377	test: 0.760406
PRC train: 0.934580	val: 0.391763	test: 0.872864

Epoch: 50
Loss: 0.31835783087235114
ROC train: 0.949398	val: 0.849165	test: 0.751958
PRC train: 0.941092	val: 0.401467	test: 0.869073

Epoch: 51
Loss: 0.32524367720250263
ROC train: 0.950600	val: 0.859363	test: 0.749485
PRC train: 0.941334	val: 0.388070	test: 0.868714

Epoch: 52
Loss: 0.3342649440881755
ROC train: 0.952313	val: 0.861888	test: 0.753658
PRC train: 0.942550	val: 0.390017	test: 0.871052

Epoch: 53
Loss: 0.3130021341595986
ROC train: 0.954795	val: 0.856352	test: 0.755718
PRC train: 0.945817	val: 0.409140	test: 0.869603

Epoch: 54
Loss: 0.32892962959620214
ROC train: 0.955471	val: 0.853924	test: 0.749794
PRC train: 0.947139	val: 0.410816	test: 0.866255

Epoch: 55
Loss: 0.3148336823373245
ROC train: 0.957914	val: 0.863345	test: 0.750258
PRC train: 0.950598	val: 0.421023	test: 0.866088

Epoch: 56
Loss: 0.3130008040910627
ROC train: 0.954050	val: 0.863733	test: 0.747115
PRC train: 0.946172	val: 0.420607	test: 0.864135

Epoch: 57
Loss: 0.3200657906935068
ROC train: 0.957471	val: 0.868493	test: 0.753864
PRC train: 0.949007	val: 0.453745	test: 0.868105

Epoch: 58
Loss: 0.299110279571126
ROC train: 0.955155	val: 0.861111	test: 0.753091
PRC train: 0.947998	val: 0.430764	test: 0.870109

Epoch: 59
Loss: 0.30838217702553306
ROC train: 0.956965	val: 0.871212	test: 0.758345
PRC train: 0.950471	val: 0.446003	test: 0.873372

Epoch: 60
Loss: 0.31613014811401047
ROC train: 0.958366	val: 0.874029	test: 0.757985
PRC train: 0.953515	val: 0.445766	test: 0.870246

Epoch: 61
Loss: 0.34001869968400955
ROC train: 0.958663	val: 0.856158	test: 0.756542
PRC train: 0.953343	val: 0.409126	test: 0.870558

Epoch: 62
Loss: 0.31218199878853403
ROC train: 0.959038	val: 0.851204	test: 0.747733
PRC train: 0.953373	val: 0.403653	test: 0.865347

Epoch: 63
Loss: 0.3073078419741286
ROC train: 0.960658	val: 0.858294	test: 0.741397
PRC train: 0.952352	val: 0.418211	test: 0.860661

Epoch: 64
Loss: 0.30529338899985625
ROC train: 0.960094	val: 0.858683	test: 0.741088
PRC train: 0.951380	val: 0.450593	test: 0.858737

Epoch: 65
Loss: 0.3090138098410427
ROC train: 0.960970	val: 0.853050	test: 0.747424
PRC train: 0.953903	val: 0.448410	test: 0.862257

Epoch: 66
Loss: 0.3084187800567755
ROC train: 0.963928	val: 0.848873	test: 0.757418
PRC train: 0.959484	val: 0.417156	test: 0.869805

Epoch: 67
Loss: 0.30258479009971917
ROC train: 0.962342	val: 0.850136	test: 0.751700
PRC train: 0.957811	val: 0.415614	test: 0.863457

Epoch: 68
Loss: 0.3023128940155033
ROC train: 0.960060	val: 0.863831	test: 0.744539
PRC train: 0.954796	val: 0.437954	test: 0.854233

Epoch: 69
Loss: 0.29188593621993403
ROC train: 0.965111	val: 0.871212	test: 0.750464
PRC train: 0.960111	val: 0.471979	test: 0.859134

Epoch: 70
Loss: 0.3003359491079909
ROC train: 0.964911	val: 0.876263	test: 0.749845
PRC train: 0.959534	val: 0.500242	test: 0.859858

Epoch: 71
Loss: 0.28418335684915785
ROC train: 0.959344	val: 0.860334	test: 0.742943
PRC train: 0.952045	val: 0.458071	test: 0.854657

Epoch: 72
Loss: 0.3103662668503849
ROC train: 0.965354	val: 0.858100	test: 0.745776
PRC train: 0.960847	val: 0.460340	test: 0.861485

Epoch: 73
Loss: 0.30537566109536246
ROC train: 0.965952	val: 0.860140	test: 0.741964
PRC train: 0.959859	val: 0.453621	test: 0.863197

Epoch: 74
Loss: 0.2817693485137697
ROC train: 0.963495	val: 0.862471	test: 0.744539
PRC train: 0.956080	val: 0.431742	test: 0.869169

Epoch: 75
Loss: 0.3069384449675441
ROC train: 0.965621	val: 0.861985	test: 0.743355
PRC train: 0.959493	val: 0.434328	test: 0.864008

Epoch: 76
Loss: 0.30335899590525706
ROC train: 0.968098	val: 0.862568	test: 0.739233
PRC train: 0.964088	val: 0.445020	test: 0.857627

Epoch: 77
Loss: 0.29539592062091535
ROC train: 0.967762	val: 0.864122	test: 0.733721
PRC train: 0.964614	val: 0.466386	test: 0.851153

Epoch: 78
Loss: 0.30463116899600495
ROC train: 0.969470	val: 0.866550	test: 0.738461
PRC train: 0.966335	val: 0.464653	test: 0.849941

Epoch: 79
Loss: 0.31066982523336556
ROC train: 0.969247	val: 0.863831	test: 0.742530
PRC train: 0.965616	val: 0.459897	test: 0.854537

Epoch: 80
Loss: 0.2785164693004786
ROC train: 0.968254	val: 0.856643	test: 0.747064
PRC train: 0.963289	val: 0.442454	test: 0.863296

Epoch: 81
Loss: 0.2746100389802346
ROC train: 0.969602	val: 0.870435	test: 0.743355
PRC train: 0.965110	val: 0.453446	test: 0.865326

Epoch: 82
Loss: 0.2872487647048674
ROC train: 0.970147	val: 0.868978	test: 0.749536
PRC train: 0.965892	val: 0.453128	test: 0.869509

Epoch: 83
Loss: 0.2679538798570392
ROC train: 0.969777	val: 0.869464	test: 0.750773
PRC train: 0.965798	val: 0.464408	test: 0.867259

Epoch: 84
Loss: 0.2605218658927828
ROC train: 0.970663	val: 0.864316	test: 0.736297
PRC train: 0.967250	val: 0.448707	test: 0.855309

Epoch: 85
Loss: 0.28083535134848736
ROC train: 0.971057	val: 0.862762	test: 0.731094
PRC train: 0.967971	val: 0.467153	test: 0.857184

Epoch: 86
Loss: 0.2810805668653934
ROC train: 0.972604	val: 0.859557	test: 0.723522
PRC train: 0.969189	val: 0.453926	test: 0.851780

Epoch: 87
Loss: 0.29619666637985
ROC train: 0.972789	val: 0.867910	test: 0.723573
PRC train: 0.969267	val: 0.479261	test: 0.847392

Epoch: 88
Loss: 0.2787901456686251
ROC train: 0.971349	val: 0.861597	test: 0.737637
PRC train: 0.968077	val: 0.451861	test: 0.859144

Epoch: 89
Loss: 0.2760609864174912
ROC train: 0.966483	val: 0.850524	test: 0.747836
PRC train: 0.961418	val: 0.410038	test: 0.865094

Epoch: 90
Loss: 0.2687630801462454
ROC train: 0.964011	val: 0.850330	test: 0.753967
PRC train: 0.959038	val: 0.409363	test: 0.865002

Epoch: 91
Loss: 0.27286900766094657
ROC train: 0.969135	val: 0.851593	test: 0.755461
PRC train: 0.965698	val: 0.431196	test: 0.864374

Epoch: 92
Loss: 0.27513731468998404
ROC train: 0.974701	val: 0.867327	test: 0.738976
PRC train: 0.972536	val: 0.454186	test: 0.857632

Epoch: 93
Loss: 0.2680264341359466
ROC train: 0.976195	val: 0.873057	test: 0.727540
PRC train: 0.974205	val: 0.484236	test: 0.851517

Epoch: 94
Loss: 0.25732310815565634
ROC train: 0.972687	val: 0.868687	test: 0.736297
ROC train: 0.935345	val: 0.730233	test: 0.842813
PRC train: 0.911781	val: 0.431627	test: 0.918967

Epoch: 34
Loss: 0.3861306553965346
ROC train: 0.939256	val: 0.734144	test: 0.835500
PRC train: 0.917550	val: 0.434335	test: 0.915344

Epoch: 35
Loss: 0.3475484039136932
ROC train: 0.935100	val: 0.740063	test: 0.844890
PRC train: 0.915422	val: 0.462802	test: 0.918620

Epoch: 36
Loss: 0.3683731423715919
ROC train: 0.939295	val: 0.747146	test: 0.851300
PRC train: 0.919176	val: 0.458322	test: 0.922116

Epoch: 37
Loss: 0.4165955498622938
ROC train: 0.937392	val: 0.740381	test: 0.859606
PRC train: 0.917414	val: 0.445412	test: 0.924720

Epoch: 38
Loss: 0.3573667515828891
ROC train: 0.933621	val: 0.737526	test: 0.855092
PRC train: 0.913721	val: 0.464203	test: 0.922161

Epoch: 39
Loss: 0.349911941046845
ROC train: 0.939249	val: 0.739112	test: 0.848140
PRC train: 0.916469	val: 0.454290	test: 0.921160

Epoch: 40
Loss: 0.35412284696175994
ROC train: 0.938648	val: 0.734567	test: 0.840195
PRC train: 0.915237	val: 0.456005	test: 0.914960

Epoch: 41
Loss: 0.3504708812732998
ROC train: 0.940929	val: 0.739218	test: 0.841730
PRC train: 0.920149	val: 0.456790	test: 0.914522

Epoch: 42
Loss: 0.3369578562485293
ROC train: 0.942505	val: 0.737104	test: 0.842723
PRC train: 0.923630	val: 0.451238	test: 0.914959

Epoch: 43
Loss: 0.33852672677005125
ROC train: 0.940476	val: 0.731395	test: 0.846966
PRC train: 0.920897	val: 0.450291	test: 0.918393

Epoch: 44
Loss: 0.3605550777610713
ROC train: 0.936982	val: 0.732875	test: 0.842362
PRC train: 0.918265	val: 0.468726	test: 0.913711

Epoch: 45
Loss: 0.32997651968910713
ROC train: 0.942725	val: 0.744503	test: 0.834868
PRC train: 0.925220	val: 0.456393	test: 0.906324

Epoch: 46
Loss: 0.3927510886192701
ROC train: 0.942278	val: 0.740063	test: 0.839653
PRC train: 0.923736	val: 0.440806	test: 0.908542

Epoch: 47
Loss: 0.3464168771354651
ROC train: 0.941483	val: 0.737632	test: 0.841640
PRC train: 0.922230	val: 0.431983	test: 0.917408

Epoch: 48
Loss: 0.3468259277263484
ROC train: 0.941843	val: 0.734249	test: 0.848501
PRC train: 0.922017	val: 0.441639	test: 0.921249

Epoch: 49
Loss: 0.33677299314778686
ROC train: 0.946294	val: 0.741543	test: 0.848682
PRC train: 0.924822	val: 0.442386	test: 0.919420

Epoch: 50
Loss: 0.338239545003698
ROC train: 0.949565	val: 0.738372	test: 0.838841
PRC train: 0.931843	val: 0.425573	test: 0.911734

Epoch: 51
Loss: 0.3291755736106563
ROC train: 0.946848	val: 0.734989	test: 0.836313
PRC train: 0.929006	val: 0.433631	test: 0.909136

Epoch: 52
Loss: 0.3307088156593229
ROC train: 0.945405	val: 0.741755	test: 0.830173
PRC train: 0.927534	val: 0.449511	test: 0.907806

Epoch: 53
Loss: 0.3568349140447894
ROC train: 0.948726	val: 0.749366	test: 0.836764
PRC train: 0.932028	val: 0.445127	test: 0.912964

Epoch: 54
Loss: 0.34458752288307004
ROC train: 0.946244	val: 0.754334	test: 0.843174
PRC train: 0.929008	val: 0.449286	test: 0.913977

Epoch: 55
Loss: 0.3257450568325113
ROC train: 0.952141	val: 0.758034	test: 0.852745
PRC train: 0.937974	val: 0.465421	test: 0.921322

Epoch: 56
Loss: 0.3576349872988403
ROC train: 0.950968	val: 0.759091	test: 0.846876
PRC train: 0.937128	val: 0.463100	test: 0.919906

Epoch: 57
Loss: 0.33185485495688427
ROC train: 0.948406	val: 0.755920	test: 0.829722
PRC train: 0.932327	val: 0.466131	test: 0.911476

Epoch: 58
Loss: 0.31487686408373733
ROC train: 0.947323	val: 0.752960	test: 0.826472
PRC train: 0.929831	val: 0.471297	test: 0.909668

Epoch: 59
Loss: 0.3201656223816988
ROC train: 0.950928	val: 0.751163	test: 0.831257
PRC train: 0.935092	val: 0.448796	test: 0.910083

Epoch: 60
Loss: 0.34744244503162036
ROC train: 0.952127	val: 0.744397	test: 0.838570
PRC train: 0.937833	val: 0.435964	test: 0.911898

Epoch: 61
Loss: 0.34896750084650696
ROC train: 0.951659	val: 0.748203	test: 0.831437
PRC train: 0.937995	val: 0.444141	test: 0.905578

Epoch: 62
Loss: 0.31968621607595804
ROC train: 0.950068	val: 0.740592	test: 0.829812
PRC train: 0.938470	val: 0.444728	test: 0.905601

Epoch: 63
Loss: 0.3174086965959001
ROC train: 0.952875	val: 0.741121	test: 0.845251
PRC train: 0.939957	val: 0.449074	test: 0.914931

Epoch: 64
Loss: 0.30487871620074763
ROC train: 0.952807	val: 0.746829	test: 0.843174
PRC train: 0.939143	val: 0.446765	test: 0.912677

Epoch: 65
Loss: 0.3305807751093338
ROC train: 0.956840	val: 0.751691	test: 0.835771
PRC train: 0.942754	val: 0.448688	test: 0.906595

Epoch: 66
Loss: 0.31488269596563373
ROC train: 0.955232	val: 0.752220	test: 0.835410
PRC train: 0.939329	val: 0.463950	test: 0.904417

Epoch: 67
Loss: 0.3188162215905378
ROC train: 0.951292	val: 0.753700	test: 0.825479
PRC train: 0.934175	val: 0.489690	test: 0.900107

Epoch: 68
Loss: 0.3348260079158599
ROC train: 0.954368	val: 0.747780	test: 0.834326
PRC train: 0.941382	val: 0.470157	test: 0.909123

Epoch: 69
Loss: 0.3033713720553169
ROC train: 0.957182	val: 0.740803	test: 0.837486
PRC train: 0.945029	val: 0.471095	test: 0.910521

Epoch: 70
Loss: 0.3152709636931942
ROC train: 0.956196	val: 0.745349	test: 0.825298
PRC train: 0.943244	val: 0.475074	test: 0.902906

Epoch: 71
Loss: 0.3030450284035186
ROC train: 0.956912	val: 0.740803	test: 0.809679
PRC train: 0.946063	val: 0.453961	test: 0.890948

Epoch: 72
Loss: 0.33475012654235714
ROC train: 0.954865	val: 0.748520	test: 0.814464
PRC train: 0.944605	val: 0.468107	test: 0.893778

Epoch: 73
Loss: 0.3016701147327824
ROC train: 0.957088	val: 0.753488	test: 0.829812
PRC train: 0.945550	val: 0.480060	test: 0.904934

Epoch: 74
Loss: 0.2993668047383939
ROC train: 0.957639	val: 0.744503	test: 0.842272
PRC train: 0.944488	val: 0.455619	test: 0.916842

Epoch: 75
Loss: 0.29879941557539524
ROC train: 0.956577	val: 0.731078	test: 0.836945
PRC train: 0.941602	val: 0.442331	test: 0.912498

Epoch: 76
Loss: 0.29280418862452134
ROC train: 0.957085	val: 0.729175	test: 0.835590
PRC train: 0.943044	val: 0.445724	test: 0.911611

Epoch: 77
Loss: 0.3081545238975053
ROC train: 0.956876	val: 0.732030	test: 0.819249
PRC train: 0.944421	val: 0.449479	test: 0.899155

Epoch: 78
Loss: 0.3330495072784271
ROC train: 0.955185	val: 0.727061	test: 0.796678
PRC train: 0.943253	val: 0.452590	test: 0.878391

Epoch: 79
Loss: 0.31219272347059784
ROC train: 0.951270	val: 0.712368	test: 0.789906
PRC train: 0.938303	val: 0.449433	test: 0.872409

Epoch: 80
Loss: 0.29573686799268895
ROC train: 0.959388	val: 0.729070	test: 0.820423
PRC train: 0.947713	val: 0.446380	test: 0.895998

Epoch: 81
Loss: 0.28836833029017894
ROC train: 0.961511	val: 0.729070	test: 0.835410
PRC train: 0.949935	val: 0.449268	test: 0.909457

Epoch: 82
Loss: 0.29236516531157625
ROC train: 0.961000	val: 0.745243	test: 0.835861
PRC train: 0.948816	val: 0.477678	test: 0.910193

Epoch: 83
Loss: 0.3060044626733075
ROC train: 0.959819	val: 0.755074	test: 0.827826
PRC train: 0.946055	val: 0.495605	test: 0.903635

Epoch: 84
Loss: 0.32176425050301594
ROC train: 0.959524	val: 0.746934	test: 0.808956
PRC train: 0.946552	val: 0.512917	test: 0.888915

Epoch: 85
Loss: 0.31990526069619013
ROC train: 0.959647	val: 0.740803	test: 0.810401
PRC train: 0.946713	val: 0.502189	test: 0.887418

Epoch: 86
Loss: 0.32251042400625585
ROC train: 0.961500	val: 0.732875	test: 0.809679
PRC train: 0.949614	val: 0.477891	test: 0.884872

Epoch: 87
Loss: 0.2883768693916135
ROC train: 0.959888	val: 0.735412	test: 0.808324
PRC train: 0.946692	val: 0.462805	test: 0.883011

Epoch: 88
Loss: 0.3296762851130326
ROC train: 0.959744	val: 0.734989	test: 0.807060
PRC train: 0.949457	val: 0.452533	test: 0.891070

Epoch: 89
Loss: 0.3187454572275828
ROC train: 0.957941	val: 0.743975	test: 0.806970
PRC train: 0.945135	val: 0.462939	test: 0.894421

Epoch: 90
Loss: 0.29947952001025013
ROC train: 0.961079	val: 0.745666	test: 0.817082
PRC train: 0.949025	val: 0.464856	test: 0.899307

Epoch: 91
Loss: 0.2985695967598495
ROC train: 0.961860	val: 0.745877	test: 0.824395
PRC train: 0.951027	val: 0.451760	test: 0.902747

Epoch: 92
Loss: 0.27962132604701356
ROC train: 0.959082	val: 0.730973	test: 0.835320
PRC train: 0.947769	val: 0.436018	test: 0.909868

Epoch: 93
Loss: 0.2902711242643633
ROC train: 0.958067	val: 0.725159	test: 0.837125
PRC train: 0.947768	val: 0.440096	test: 0.912843

Epoch: 94
Loss: 0.3415905099210108
ROC train: 0.938108	val: 0.721670	test: 0.832701
PRC train: 0.913491	val: 0.431965	test: 0.910789

Epoch: 34
Loss: 0.31467914226683513
ROC train: 0.936046	val: 0.721882	test: 0.836132
PRC train: 0.911402	val: 0.438514	test: 0.912004

Epoch: 35
Loss: 0.3728330382981449
ROC train: 0.939047	val: 0.736575	test: 0.838570
PRC train: 0.919659	val: 0.434841	test: 0.919409

Epoch: 36
Loss: 0.3524223564750369
ROC train: 0.939119	val: 0.742495	test: 0.849404
PRC train: 0.920488	val: 0.431903	test: 0.924817

Epoch: 37
Loss: 0.3285230774630884
ROC train: 0.935960	val: 0.735624	test: 0.847779
PRC train: 0.914285	val: 0.415937	test: 0.924170

Epoch: 38
Loss: 0.38035355900246326
ROC train: 0.935665	val: 0.733827	test: 0.837125
PRC train: 0.914257	val: 0.427062	test: 0.919542

Epoch: 39
Loss: 0.36686030452456964
ROC train: 0.938839	val: 0.716173	test: 0.830715
PRC train: 0.920019	val: 0.408179	test: 0.912124

Epoch: 40
Loss: 0.3292908437590699
ROC train: 0.945326	val: 0.723044	test: 0.831618
PRC train: 0.927550	val: 0.406079	test: 0.907223

Epoch: 41
Loss: 0.3446541838388517
ROC train: 0.945107	val: 0.738161	test: 0.835320
PRC train: 0.927779	val: 0.430858	test: 0.909377

Epoch: 42
Loss: 0.34681490146319666
ROC train: 0.945297	val: 0.739006	test: 0.835410
PRC train: 0.926348	val: 0.455435	test: 0.914095

Epoch: 43
Loss: 0.3629158955107964
ROC train: 0.930473	val: 0.726956	test: 0.806067
PRC train: 0.909397	val: 0.471605	test: 0.895997

Epoch: 44
Loss: 0.34786333268001646
ROC train: 0.945013	val: 0.741121	test: 0.828097
PRC train: 0.927559	val: 0.480769	test: 0.912183

Epoch: 45
Loss: 0.3528041910858871
ROC train: 0.940742	val: 0.730655	test: 0.845161
PRC train: 0.923293	val: 0.444117	test: 0.918427

Epoch: 46
Loss: 0.36687929553679216
ROC train: 0.938921	val: 0.713742	test: 0.831889
PRC train: 0.922040	val: 0.411123	test: 0.911793

Epoch: 47
Loss: 0.30095996117862184
ROC train: 0.941426	val: 0.712156	test: 0.838209
PRC train: 0.923032	val: 0.409504	test: 0.913103

Epoch: 48
Loss: 0.35769207516399354
ROC train: 0.944808	val: 0.725370	test: 0.839021
PRC train: 0.926401	val: 0.436471	test: 0.915514

Epoch: 49
Loss: 0.36366398297451574
ROC train: 0.946909	val: 0.735729	test: 0.844077
PRC train: 0.927839	val: 0.439932	test: 0.918442

Epoch: 50
Loss: 0.3532413735321255
ROC train: 0.945063	val: 0.733721	test: 0.842272
PRC train: 0.927853	val: 0.420774	test: 0.913703

Epoch: 51
Loss: 0.3211095644337141
ROC train: 0.947442	val: 0.732347	test: 0.848682
PRC train: 0.931638	val: 0.431196	test: 0.918362

Epoch: 52
Loss: 0.31634193098910945
ROC train: 0.947237	val: 0.729704	test: 0.833333
PRC train: 0.933943	val: 0.440185	test: 0.910171

Epoch: 53
Loss: 0.33430580680983824
ROC train: 0.940947	val: 0.726638	test: 0.798393
PRC train: 0.928630	val: 0.438758	test: 0.885890

Epoch: 54
Loss: 0.3419941199683577
ROC train: 0.951414	val: 0.742706	test: 0.820242
PRC train: 0.940004	val: 0.446207	test: 0.904850

Epoch: 55
Loss: 0.3344791720688379
ROC train: 0.948205	val: 0.733510	test: 0.839563
PRC train: 0.930495	val: 0.444980	test: 0.915856

Epoch: 56
Loss: 0.3368670761174227
ROC train: 0.941836	val: 0.723256	test: 0.823944
PRC train: 0.925066	val: 0.426646	test: 0.906426

Epoch: 57
Loss: 0.31375929186070933
ROC train: 0.950148	val: 0.747674	test: 0.829902
PRC train: 0.935605	val: 0.421637	test: 0.908855

Epoch: 58
Loss: 0.3106858853905994
ROC train: 0.950579	val: 0.761311	test: 0.834507
PRC train: 0.937613	val: 0.432483	test: 0.906717

Epoch: 59
Loss: 0.32706872162518674
ROC train: 0.952371	val: 0.757611	test: 0.846334
PRC train: 0.938896	val: 0.440366	test: 0.920127

Epoch: 60
Loss: 0.3149304877574687
ROC train: 0.953598	val: 0.747886	test: 0.845702
PRC train: 0.940676	val: 0.435897	test: 0.920590

Epoch: 61
Loss: 0.34631208253545287
ROC train: 0.953177	val: 0.734778	test: 0.842091
PRC train: 0.940942	val: 0.424330	test: 0.919822

Epoch: 62
Loss: 0.32177182005006866
ROC train: 0.954361	val: 0.735201	test: 0.840285
PRC train: 0.943225	val: 0.426595	test: 0.913070

Epoch: 63
Loss: 0.3051141087326345
ROC train: 0.949554	val: 0.733087	test: 0.815908
PRC train: 0.937110	val: 0.428003	test: 0.893048

Epoch: 64
Loss: 0.3210598984405511
ROC train: 0.956344	val: 0.742706	test: 0.825388
PRC train: 0.944849	val: 0.434881	test: 0.908034

Epoch: 65
Loss: 0.3076171542739815
ROC train: 0.956880	val: 0.738901	test: 0.830805
PRC train: 0.944601	val: 0.428713	test: 0.914921

Epoch: 66
Loss: 0.29394302405569434
ROC train: 0.956606	val: 0.737632	test: 0.835320
PRC train: 0.943407	val: 0.433293	test: 0.916320

Epoch: 67
Loss: 0.3128932270214332
ROC train: 0.956847	val: 0.725370	test: 0.809137
PRC train: 0.945598	val: 0.413486	test: 0.902381

Epoch: 68
Loss: 0.3050514611304984
ROC train: 0.957103	val: 0.727167	test: 0.810040
PRC train: 0.946271	val: 0.416769	test: 0.906845

Epoch: 69
Loss: 0.32387133393235346
ROC train: 0.956210	val: 0.728647	test: 0.835139
PRC train: 0.945229	val: 0.420023	test: 0.917727

Epoch: 70
Loss: 0.2982668227577899
ROC train: 0.950335	val: 0.719133	test: 0.834146
PRC train: 0.938536	val: 0.401056	test: 0.911523

Epoch: 71
Loss: 0.325957515743722
ROC train: 0.952029	val: 0.730021	test: 0.839924
PRC train: 0.940513	val: 0.415559	test: 0.913882

Epoch: 72
Loss: 0.3284211148544113
ROC train: 0.952278	val: 0.744503	test: 0.842994
PRC train: 0.939393	val: 0.421074	test: 0.917027

Epoch: 73
Loss: 0.31438239916591165
ROC train: 0.956516	val: 0.758985	test: 0.840195
PRC train: 0.945350	val: 0.450583	test: 0.915950

Epoch: 74
Loss: 0.32086920610630487
ROC train: 0.960492	val: 0.756131	test: 0.839473
PRC train: 0.950512	val: 0.458331	test: 0.916545

Epoch: 75
Loss: 0.29473059970943066
ROC train: 0.959747	val: 0.742495	test: 0.835500
PRC train: 0.949355	val: 0.446747	test: 0.912311

Epoch: 76
Loss: 0.29497676744350215
ROC train: 0.958992	val: 0.726533	test: 0.827375
PRC train: 0.948658	val: 0.426798	test: 0.905648

Epoch: 77
Loss: 0.30175132959961337
ROC train: 0.960212	val: 0.719767	test: 0.820061
PRC train: 0.951238	val: 0.418797	test: 0.900903

Epoch: 78
Loss: 0.30259820141015553
ROC train: 0.960377	val: 0.727273	test: 0.819610
PRC train: 0.951821	val: 0.438476	test: 0.905559

Epoch: 79
Loss: 0.3041867139080914
ROC train: 0.959147	val: 0.721882	test: 0.830625
PRC train: 0.949223	val: 0.436293	test: 0.914830

Epoch: 80
Loss: 0.275705707681725
ROC train: 0.954501	val: 0.715645	test: 0.828638
PRC train: 0.942615	val: 0.432496	test: 0.911020

Epoch: 81
Loss: 0.28102567693069214
ROC train: 0.957016	val: 0.719450	test: 0.833604
PRC train: 0.945304	val: 0.428894	test: 0.913199

Epoch: 82
Loss: 0.3100580046641809
ROC train: 0.959071	val: 0.709197	test: 0.837396
PRC train: 0.948533	val: 0.421300	test: 0.909239

Epoch: 83
Loss: 0.28721447344971496
ROC train: 0.952440	val: 0.702643	test: 0.807783
PRC train: 0.941936	val: 0.395646	test: 0.874741

Epoch: 84
Loss: 0.28385531918355855
ROC train: 0.956095	val: 0.712685	test: 0.822589
PRC train: 0.947728	val: 0.416209	test: 0.899296

Epoch: 85
Loss: 0.2793297828213144
ROC train: 0.959863	val: 0.715116	test: 0.831166
PRC train: 0.949732	val: 0.449639	test: 0.915524

Epoch: 86
Loss: 0.3324984541556238
ROC train: 0.958931	val: 0.731924	test: 0.836132
PRC train: 0.947966	val: 0.460875	test: 0.915980

Epoch: 87
Loss: 0.3477091461245044
ROC train: 0.958517	val: 0.744186	test: 0.837396
PRC train: 0.948631	val: 0.449710	test: 0.908277

Epoch: 88
Loss: 0.2802216237185737
ROC train: 0.958355	val: 0.757822	test: 0.834958
PRC train: 0.948683	val: 0.464983	test: 0.911848

Epoch: 89
Loss: 0.29544135518960885
ROC train: 0.961000	val: 0.749049	test: 0.836132
PRC train: 0.952070	val: 0.459726	test: 0.916568

Epoch: 90
Loss: 0.329832471368254
ROC train: 0.961683	val: 0.739112	test: 0.835229
PRC train: 0.953233	val: 0.454859	test: 0.915483

Epoch: 91
Loss: 0.3003310583153588
ROC train: 0.963454	val: 0.740063	test: 0.820242
PRC train: 0.957211	val: 0.461425	test: 0.903579

Epoch: 92
Loss: 0.2965219655064778
ROC train: 0.963277	val: 0.743869	test: 0.813741
PRC train: 0.955868	val: 0.479781	test: 0.905883

Epoch: 93
Loss: 0.30581716114626
ROC train: 0.961586	val: 0.741332	test: 0.820423
PRC train: 0.948963	val: 0.482175	test: 0.906696

Epoch: 94
Loss: 0.3091272721181516
PRC train: 0.915756	val: 0.464226	test: 0.911610

Epoch: 34
Loss: 0.3689759367673001
ROC train: 0.935201	val: 0.736681	test: 0.840917
PRC train: 0.915202	val: 0.459560	test: 0.919817

Epoch: 35
Loss: 0.3569994631828081
ROC train: 0.933502	val: 0.726004	test: 0.842001
PRC train: 0.914142	val: 0.446292	test: 0.918166

Epoch: 36
Loss: 0.3688876371957994
ROC train: 0.931128	val: 0.717442	test: 0.827826
PRC train: 0.913711	val: 0.424668	test: 0.906275

Epoch: 37
Loss: 0.3393243618877822
ROC train: 0.928379	val: 0.718393	test: 0.819610
PRC train: 0.913306	val: 0.406936	test: 0.891222

Epoch: 38
Loss: 0.3908886114106693
ROC train: 0.936878	val: 0.730444	test: 0.834688
PRC train: 0.919123	val: 0.423863	test: 0.909471

Epoch: 39
Loss: 0.3514569746928744
ROC train: 0.934834	val: 0.740698	test: 0.845793
PRC train: 0.911926	val: 0.439198	test: 0.916531

Epoch: 40
Loss: 0.365910164652992
ROC train: 0.937860	val: 0.754123	test: 0.850036
PRC train: 0.918944	val: 0.440493	test: 0.922196

Epoch: 41
Loss: 0.3619158908435306
ROC train: 0.936140	val: 0.750846	test: 0.842091
PRC train: 0.917991	val: 0.429614	test: 0.919153

Epoch: 42
Loss: 0.34756199195960635
ROC train: 0.933035	val: 0.750000	test: 0.833424
PRC train: 0.913526	val: 0.432615	test: 0.912724

Epoch: 43
Loss: 0.36548326497223643
ROC train: 0.939277	val: 0.760465	test: 0.845432
PRC train: 0.919574	val: 0.433642	test: 0.913256

Epoch: 44
Loss: 0.36217610386106136
ROC train: 0.942286	val: 0.749577	test: 0.838570
PRC train: 0.924221	val: 0.407137	test: 0.908371

Epoch: 45
Loss: 0.36611530814063886
ROC train: 0.942271	val: 0.740381	test: 0.832972
PRC train: 0.925110	val: 0.426396	test: 0.910546

Epoch: 46
Loss: 0.3561878105324216
ROC train: 0.945434	val: 0.730761	test: 0.832792
PRC train: 0.928389	val: 0.436811	test: 0.912531

Epoch: 47
Loss: 0.34435192601796666
ROC train: 0.941454	val: 0.721036	test: 0.828277
PRC train: 0.924653	val: 0.418385	test: 0.908121

Epoch: 48
Loss: 0.3914727882514713
ROC train: 0.931372	val: 0.708245	test: 0.809679
PRC train: 0.912977	val: 0.384230	test: 0.880667

Epoch: 49
Loss: 0.3509364901622522
ROC train: 0.939709	val: 0.717230	test: 0.802636
PRC train: 0.922077	val: 0.384517	test: 0.888889

Epoch: 50
Loss: 0.33261941279593393
ROC train: 0.945959	val: 0.717230	test: 0.823312
PRC train: 0.928590	val: 0.405038	test: 0.911293

Epoch: 51
Loss: 0.35802848792674236
ROC train: 0.943977	val: 0.721882	test: 0.831618
PRC train: 0.924964	val: 0.422363	test: 0.914120

Epoch: 52
Loss: 0.3551433154592498
ROC train: 0.948622	val: 0.733510	test: 0.833333
PRC train: 0.931547	val: 0.453395	test: 0.915666

Epoch: 53
Loss: 0.351535933176261
ROC train: 0.947902	val: 0.739641	test: 0.834507
PRC train: 0.930332	val: 0.452305	test: 0.917445

Epoch: 54
Loss: 0.378864538952101
ROC train: 0.949126	val: 0.740169	test: 0.836132
PRC train: 0.929639	val: 0.435849	test: 0.919528

Epoch: 55
Loss: 0.35702464262562883
ROC train: 0.942070	val: 0.739006	test: 0.832069
PRC train: 0.919243	val: 0.436219	test: 0.917186

Epoch: 56
Loss: 0.3440849917936589
ROC train: 0.940958	val: 0.736469	test: 0.825569
PRC train: 0.921180	val: 0.437125	test: 0.910244

Epoch: 57
Loss: 0.3612307619383842
ROC train: 0.947564	val: 0.743869	test: 0.827736
PRC train: 0.932594	val: 0.450360	test: 0.908248

Epoch: 58
Loss: 0.3094719609738451
ROC train: 0.949140	val: 0.746617	test: 0.830625
PRC train: 0.934843	val: 0.444077	test: 0.912494

Epoch: 59
Loss: 0.3169366925396792
ROC train: 0.950414	val: 0.748943	test: 0.845251
PRC train: 0.935145	val: 0.456489	test: 0.920568

Epoch: 60
Loss: 0.32701188301186357
ROC train: 0.946366	val: 0.749789	test: 0.838931
PRC train: 0.928973	val: 0.466697	test: 0.916320

Epoch: 61
Loss: 0.33057555843663133
ROC train: 0.950112	val: 0.747674	test: 0.821325
PRC train: 0.933860	val: 0.468886	test: 0.910869

Epoch: 62
Loss: 0.36573199185378025
ROC train: 0.952630	val: 0.743235	test: 0.816631
PRC train: 0.939844	val: 0.458473	test: 0.909169

Epoch: 63
Loss: 0.308132066563204
ROC train: 0.954807	val: 0.753277	test: 0.822680
PRC train: 0.942358	val: 0.471027	test: 0.908994

Epoch: 64
Loss: 0.35441172091013157
ROC train: 0.954926	val: 0.738795	test: 0.838209
PRC train: 0.939911	val: 0.456224	test: 0.916105

Epoch: 65
Loss: 0.3365042832055986
ROC train: 0.952324	val: 0.725370	test: 0.841188
PRC train: 0.935012	val: 0.420105	test: 0.918253

Epoch: 66
Loss: 0.3014411639891855
ROC train: 0.951270	val: 0.725793	test: 0.831798
PRC train: 0.936081	val: 0.407398	test: 0.915047

Epoch: 67
Loss: 0.3345119064337564
ROC train: 0.951882	val: 0.739958	test: 0.828097
PRC train: 0.938765	val: 0.409431	test: 0.915291

Epoch: 68
Loss: 0.34284202400643043
ROC train: 0.952591	val: 0.749260	test: 0.816811
PRC train: 0.940768	val: 0.424274	test: 0.907750

Epoch: 69
Loss: 0.31087449245323356
ROC train: 0.953699	val: 0.752643	test: 0.810040
PRC train: 0.941619	val: 0.438015	test: 0.903672

Epoch: 70
Loss: 0.3060430712026988
ROC train: 0.956498	val: 0.740381	test: 0.816721
PRC train: 0.944371	val: 0.427507	test: 0.908028

Epoch: 71
Loss: 0.3130140119948498
ROC train: 0.955012	val: 0.725793	test: 0.824485
PRC train: 0.941443	val: 0.421558	test: 0.907230

Epoch: 72
Loss: 0.32145625602448374
ROC train: 0.955487	val: 0.727061	test: 0.829361
PRC train: 0.941590	val: 0.435196	test: 0.912277

Epoch: 73
Loss: 0.31942248127946726
ROC train: 0.956631	val: 0.745455	test: 0.829000
PRC train: 0.945825	val: 0.451281	test: 0.913420

Epoch: 74
Loss: 0.31859895010950584
ROC train: 0.954721	val: 0.770190	test: 0.825659
PRC train: 0.944481	val: 0.461009	test: 0.909424

Epoch: 75
Loss: 0.32385276795351947
ROC train: 0.952979	val: 0.767548	test: 0.823673
PRC train: 0.941922	val: 0.451663	test: 0.908818

Epoch: 76
Loss: 0.3127596320526717
ROC train: 0.951792	val: 0.756131	test: 0.813561
PRC train: 0.940261	val: 0.447167	test: 0.904873

Epoch: 77
Loss: 0.2872201106006039
ROC train: 0.953174	val: 0.740486	test: 0.816540
PRC train: 0.940056	val: 0.433317	test: 0.907971

Epoch: 78
Loss: 0.30886277909091553
ROC train: 0.957614	val: 0.736575	test: 0.828368
PRC train: 0.945090	val: 0.429501	test: 0.912589

Epoch: 79
Loss: 0.3124076486616746
ROC train: 0.955721	val: 0.746617	test: 0.810852
PRC train: 0.943368	val: 0.425532	test: 0.897431

Epoch: 80
Loss: 0.30877104542352746
ROC train: 0.956315	val: 0.740909	test: 0.800379
PRC train: 0.945113	val: 0.417398	test: 0.889278

Epoch: 81
Loss: 0.3334665451011647
ROC train: 0.960643	val: 0.747357	test: 0.813380
PRC train: 0.950592	val: 0.430892	test: 0.902087

Epoch: 82
Loss: 0.2915446297813401
ROC train: 0.958243	val: 0.750000	test: 0.814554
PRC train: 0.946592	val: 0.442370	test: 0.905532

Epoch: 83
Loss: 0.320495630683468
ROC train: 0.960197	val: 0.750211	test: 0.823763
PRC train: 0.947596	val: 0.452026	test: 0.911541

Epoch: 84
Loss: 0.305865376450576
ROC train: 0.961352	val: 0.744186	test: 0.824485
PRC train: 0.948065	val: 0.445722	test: 0.910838

Epoch: 85
Loss: 0.27751742462029266
ROC train: 0.958844	val: 0.735307	test: 0.828007
PRC train: 0.946576	val: 0.443290	test: 0.911663

Epoch: 86
Loss: 0.3049815101454719
ROC train: 0.958276	val: 0.733087	test: 0.824576
PRC train: 0.946023	val: 0.441142	test: 0.910046

Epoch: 87
Loss: 0.27891752346047227
ROC train: 0.959683	val: 0.738161	test: 0.808866
PRC train: 0.948821	val: 0.429461	test: 0.899682

Epoch: 88
Loss: 0.30788335799708877
ROC train: 0.959848	val: 0.739429	test: 0.817443
PRC train: 0.949804	val: 0.415083	test: 0.901998

Epoch: 89
Loss: 0.3106318649840458
ROC train: 0.960517	val: 0.741015	test: 0.829902
PRC train: 0.949239	val: 0.421478	test: 0.913373

Epoch: 90
Loss: 0.28197245792562886
ROC train: 0.964842	val: 0.743763	test: 0.820603
PRC train: 0.954731	val: 0.446081	test: 0.908595

Epoch: 91
Loss: 0.3255492254746265
ROC train: 0.962881	val: 0.747992	test: 0.813109
PRC train: 0.952945	val: 0.445213	test: 0.903593

Epoch: 92
Loss: 0.2718514444957318
ROC train: 0.956131	val: 0.743658	test: 0.794330
PRC train: 0.943524	val: 0.448588	test: 0.889811

Epoch: 93
Loss: 0.3217046562014795
ROC train: 0.954055	val: 0.739218	test: 0.790177
PRC train: 0.940857	val: 0.446803	test: 0.888791

Epoch: 94
Loss: 0.3137922252970363
ROC train: 0.964515	val: 0.741438	test: 0.802546

ROC train: 0.946895	val: 0.652381	test: 0.792036
PRC train: 0.914268	val: 0.923829	test: 0.807829

Epoch: 34
Loss: 0.3423376640135875
ROC train: 0.947115	val: 0.657509	test: 0.793949
PRC train: 0.915752	val: 0.924181	test: 0.813283

Epoch: 35
Loss: 0.3341317067489191
ROC train: 0.946538	val: 0.662637	test: 0.794123
PRC train: 0.914845	val: 0.924033	test: 0.808517

Epoch: 36
Loss: 0.3355141713221773
ROC train: 0.946604	val: 0.642491	test: 0.792906
PRC train: 0.915514	val: 0.919328	test: 0.807724

Epoch: 37
Loss: 0.3271197269812401
ROC train: 0.948667	val: 0.651648	test: 0.794644
PRC train: 0.919381	val: 0.920690	test: 0.806185

Epoch: 38
Loss: 0.32387420826136715
ROC train: 0.948573	val: 0.679487	test: 0.801600
PRC train: 0.918784	val: 0.927368	test: 0.806578

Epoch: 39
Loss: 0.32093947532711564
ROC train: 0.943428	val: 0.682784	test: 0.799861
PRC train: 0.910802	val: 0.929266	test: 0.794744

Epoch: 40
Loss: 0.32381129448944984
ROC train: 0.952280	val: 0.680220	test: 0.807512
PRC train: 0.923081	val: 0.929685	test: 0.815955

Epoch: 41
Loss: 0.3214996121730085
ROC train: 0.955825	val: 0.673993	test: 0.791167
PRC train: 0.929567	val: 0.925246	test: 0.812568

Epoch: 42
Loss: 0.3138541950744361
ROC train: 0.957503	val: 0.653114	test: 0.776387
PRC train: 0.933111	val: 0.921512	test: 0.798709

Epoch: 43
Loss: 0.3146808152606548
ROC train: 0.958055	val: 0.659341	test: 0.799165
PRC train: 0.932730	val: 0.922415	test: 0.813919

Epoch: 44
Loss: 0.3243644674269264
ROC train: 0.957432	val: 0.666300	test: 0.812902
PRC train: 0.931715	val: 0.928781	test: 0.827793

Epoch: 45
Loss: 0.3197733331333647
ROC train: 0.954883	val: 0.671062	test: 0.807686
PRC train: 0.927047	val: 0.928122	test: 0.833006

Epoch: 46
Loss: 0.3122779363469491
ROC train: 0.955856	val: 0.672527	test: 0.783516
PRC train: 0.929168	val: 0.924183	test: 0.815493

Epoch: 47
Loss: 0.32918170529192425
ROC train: 0.957072	val: 0.668864	test: 0.778126
PRC train: 0.930241	val: 0.921334	test: 0.801807

Epoch: 48
Loss: 0.31877039694328607
ROC train: 0.960865	val: 0.634799	test: 0.797600
PRC train: 0.937874	val: 0.912133	test: 0.819926

Epoch: 49
Loss: 0.3107695352208219
ROC train: 0.959686	val: 0.639927	test: 0.799861
PRC train: 0.937377	val: 0.918622	test: 0.808262

Epoch: 50
Loss: 0.30676504685551353
ROC train: 0.958253	val: 0.660806	test: 0.794471
PRC train: 0.934294	val: 0.919967	test: 0.797603

Epoch: 51
Loss: 0.3057785532390075
ROC train: 0.962269	val: 0.643956	test: 0.794644
PRC train: 0.940301	val: 0.916072	test: 0.802035

Epoch: 52
Loss: 0.3006302398308217
ROC train: 0.962791	val: 0.644322	test: 0.801252
PRC train: 0.941366	val: 0.914874	test: 0.821621

Epoch: 53
Loss: 0.31011690356888366
ROC train: 0.959355	val: 0.643956	test: 0.788037
PRC train: 0.936495	val: 0.920071	test: 0.811239

Epoch: 54
Loss: 0.3156368973929776
ROC train: 0.960696	val: 0.654212	test: 0.786124
PRC train: 0.937722	val: 0.927787	test: 0.808882

Epoch: 55
Loss: 0.283318012285325
ROC train: 0.959803	val: 0.661172	test: 0.783342
PRC train: 0.938131	val: 0.925167	test: 0.795928

Epoch: 56
Loss: 0.2934950103592408
ROC train: 0.960128	val: 0.623810	test: 0.769258
PRC train: 0.938209	val: 0.915619	test: 0.779269

Epoch: 57
Loss: 0.291953407497077
ROC train: 0.961353	val: 0.671062	test: 0.774822
PRC train: 0.940536	val: 0.924163	test: 0.783440

Epoch: 58
Loss: 0.2776471489512821
ROC train: 0.961998	val: 0.679853	test: 0.768040
PRC train: 0.941576	val: 0.922185	test: 0.777149

Epoch: 59
Loss: 0.2912288661719072
ROC train: 0.965962	val: 0.660806	test: 0.769779
PRC train: 0.945722	val: 0.921334	test: 0.782591

Epoch: 60
Loss: 0.28254953381284076
ROC train: 0.966310	val: 0.639560	test: 0.779517
PRC train: 0.947019	val: 0.919016	test: 0.793237

Epoch: 61
Loss: 0.2868243557672868
ROC train: 0.968858	val: 0.617949	test: 0.780038
PRC train: 0.953105	val: 0.906363	test: 0.786535

Epoch: 62
Loss: 0.27126149025772095
ROC train: 0.966627	val: 0.605495	test: 0.773083
PRC train: 0.950393	val: 0.900882	test: 0.783035

Epoch: 63
Loss: 0.2834994415720861
ROC train: 0.963633	val: 0.626007	test: 0.774996
PRC train: 0.945247	val: 0.910360	test: 0.775224

Epoch: 64
Loss: 0.2827431232575663
ROC train: 0.966638	val: 0.650916	test: 0.785603
PRC train: 0.947253	val: 0.923309	test: 0.801421

Epoch: 65
Loss: 0.28081301402877573
ROC train: 0.966493	val: 0.660806	test: 0.774996
PRC train: 0.947132	val: 0.924586	test: 0.791487

Epoch: 66
Loss: 0.27389290801786254
ROC train: 0.966455	val: 0.652381	test: 0.767866
PRC train: 0.946385	val: 0.920756	test: 0.784373

Epoch: 67
Loss: 0.2566308805581608
ROC train: 0.969289	val: 0.645421	test: 0.777952
PRC train: 0.951125	val: 0.919243	test: 0.790152

Epoch: 68
Loss: 0.25681693842188735
ROC train: 0.971190	val: 0.639194	test: 0.775865
PRC train: 0.954354	val: 0.918055	test: 0.796642

Epoch: 69
Loss: 0.269713711193179
ROC train: 0.972354	val: 0.630403	test: 0.771866
PRC train: 0.958089	val: 0.922483	test: 0.778403

Epoch: 70
Loss: 0.26498333087277587
ROC train: 0.972317	val: 0.662271	test: 0.760042
PRC train: 0.956612	val: 0.924450	test: 0.768143

Epoch: 71
Loss: 0.2774670588501672
ROC train: 0.972215	val: 0.647253	test: 0.760911
PRC train: 0.957168	val: 0.918662	test: 0.769435

Epoch: 72
Loss: 0.2563545601125562
ROC train: 0.970405	val: 0.658242	test: 0.778647
PRC train: 0.953860	val: 0.920320	test: 0.794630

Epoch: 73
Loss: 0.2667493819630238
ROC train: 0.972115	val: 0.646886	test: 0.778126
PRC train: 0.955990	val: 0.924167	test: 0.788258

Epoch: 74
Loss: 0.2702269578457192
ROC train: 0.972309	val: 0.648718	test: 0.751348
PRC train: 0.957223	val: 0.923901	test: 0.763246

Epoch: 75
Loss: 0.2692274618240035
ROC train: 0.974301	val: 0.651282	test: 0.764041
PRC train: 0.960738	val: 0.921709	test: 0.776218

Epoch: 76
Loss: 0.2563026652834278
ROC train: 0.973707	val: 0.651282	test: 0.763172
PRC train: 0.958898	val: 0.919064	test: 0.784497

Epoch: 77
Loss: 0.266094598192705
ROC train: 0.971553	val: 0.674359	test: 0.763867
PRC train: 0.955129	val: 0.923380	test: 0.776970

Epoch: 78
Loss: 0.261796371837253
ROC train: 0.973262	val: 0.630769	test: 0.761607
PRC train: 0.958436	val: 0.914234	test: 0.764692

Epoch: 79
Loss: 0.24267667298552223
ROC train: 0.974812	val: 0.612088	test: 0.767171
PRC train: 0.962020	val: 0.907758	test: 0.765989

Epoch: 80
Loss: 0.25787863349190526
ROC train: 0.975899	val: 0.631136	test: 0.760389
PRC train: 0.964193	val: 0.916009	test: 0.758910

Epoch: 81
Loss: 0.24809108130946605
ROC train: 0.974797	val: 0.661172	test: 0.759520
PRC train: 0.962138	val: 0.927176	test: 0.750042

Epoch: 82
Loss: 0.24096377160396956
ROC train: 0.975548	val: 0.676557	test: 0.753608
PRC train: 0.962967	val: 0.924356	test: 0.750094

Epoch: 83
Loss: 0.2614004959950426
ROC train: 0.978513	val: 0.664835	test: 0.758651
PRC train: 0.967214	val: 0.925359	test: 0.762620

Epoch: 84
Loss: 0.22709853476819147
ROC train: 0.977075	val: 0.650916	test: 0.762998
PRC train: 0.964133	val: 0.924454	test: 0.775694

Epoch: 85
Loss: 0.25166593301622675
ROC train: 0.977229	val: 0.635897	test: 0.765258
PRC train: 0.965553	val: 0.923392	test: 0.782760

Epoch: 86
Loss: 0.24821420639937491
ROC train: 0.978593	val: 0.646154	test: 0.759694
PRC train: 0.968409	val: 0.920953	test: 0.774148

Epoch: 87
Loss: 0.23750557554267507
ROC train: 0.980377	val: 0.648352	test: 0.751000
PRC train: 0.971094	val: 0.920122	test: 0.764425

Epoch: 88
Loss: 0.24914301920267268
ROC train: 0.981173	val: 0.633333	test: 0.758303
PRC train: 0.972387	val: 0.917955	test: 0.762961

Epoch: 89
Loss: 0.24274293745753778
ROC train: 0.981732	val: 0.644322	test: 0.757955
PRC train: 0.972496	val: 0.920591	test: 0.771035

Epoch: 90
Loss: 0.25139706711976795
ROC train: 0.979943	val: 0.663736	test: 0.755695
PRC train: 0.969094	val: 0.926836	test: 0.781046

Epoch: 91
Loss: 0.23929652528669149
ROC train: 0.979446	val: 0.646520	test: 0.752217
PRC train: 0.968874	val: 0.920649	test: 0.778889

Epoch: 92
Loss: 0.2438976001589844
ROC train: 0.977814	val: 0.640293	test: 0.757086
PRC train: 0.966515	val: 0.918305	test: 0.777564

Epoch: 93
Loss: 0.22958504181887038
ROC train: 0.981193	val: 0.647985	test: 0.758477
PRC train: 0.971725	val: 0.924075	test: 0.779581

Epoch: 94
Loss: 0.24693882504837172
ROC train: 0.948356	val: 0.683150	test: 0.780212
PRC train: 0.914085	val: 0.929948	test: 0.793193

Epoch: 34
Loss: 0.34648131378588454
ROC train: 0.948365	val: 0.684982	test: 0.788559
PRC train: 0.914273	val: 0.927005	test: 0.805348

Epoch: 35
Loss: 0.3360840030837145
ROC train: 0.947854	val: 0.676190	test: 0.803686
PRC train: 0.915063	val: 0.926869	test: 0.828725

Epoch: 36
Loss: 0.32580134712193
ROC train: 0.946087	val: 0.686813	test: 0.801252
PRC train: 0.914488	val: 0.929687	test: 0.829431

Epoch: 37
Loss: 0.33416541963720453
ROC train: 0.951350	val: 0.691575	test: 0.805599
PRC train: 0.921209	val: 0.928911	test: 0.827302

Epoch: 38
Loss: 0.3329174415566678
ROC train: 0.953193	val: 0.676557	test: 0.809946
PRC train: 0.924057	val: 0.925271	test: 0.829636

Epoch: 39
Loss: 0.31387232738583354
ROC train: 0.951838	val: 0.670696	test: 0.801252
PRC train: 0.921149	val: 0.927866	test: 0.817053

Epoch: 40
Loss: 0.33206376158260437
ROC train: 0.951190	val: 0.664835	test: 0.799861
PRC train: 0.919836	val: 0.929108	test: 0.817034

Epoch: 41
Loss: 0.32722875122469053
ROC train: 0.953462	val: 0.672894	test: 0.796731
PRC train: 0.925403	val: 0.927172	test: 0.812286

Epoch: 42
Loss: 0.3230628815943054
ROC train: 0.953114	val: 0.683150	test: 0.815858
PRC train: 0.925454	val: 0.928266	test: 0.838367

Epoch: 43
Loss: 0.3161523282930257
ROC train: 0.955736	val: 0.676557	test: 0.825422
PRC train: 0.928517	val: 0.926936	test: 0.847585

Epoch: 44
Loss: 0.3114182707208816
ROC train: 0.957066	val: 0.668864	test: 0.816554
PRC train: 0.930465	val: 0.925970	test: 0.840507

Epoch: 45
Loss: 0.2989735262879937
ROC train: 0.956687	val: 0.678388	test: 0.801252
PRC train: 0.930750	val: 0.927859	test: 0.827558

Epoch: 46
Loss: 0.307211172152113
ROC train: 0.957469	val: 0.686081	test: 0.797774
PRC train: 0.931955	val: 0.928894	test: 0.824028

Epoch: 47
Loss: 0.31343871964195213
ROC train: 0.956199	val: 0.676557	test: 0.793601
PRC train: 0.931129	val: 0.927877	test: 0.813712

Epoch: 48
Loss: 0.30835074851083405
ROC train: 0.959335	val: 0.672894	test: 0.800730
PRC train: 0.936200	val: 0.928214	test: 0.810136

Epoch: 49
Loss: 0.31131134103377944
ROC train: 0.959620	val: 0.654945	test: 0.789254
PRC train: 0.937499	val: 0.923873	test: 0.797021

Epoch: 50
Loss: 0.3116753324691689
ROC train: 0.959783	val: 0.683516	test: 0.781951
PRC train: 0.937698	val: 0.926633	test: 0.790176

Epoch: 51
Loss: 0.29980386722844055
ROC train: 0.961590	val: 0.663370	test: 0.781082
PRC train: 0.939776	val: 0.925985	test: 0.784651

Epoch: 52
Loss: 0.30837560497768896
ROC train: 0.962015	val: 0.663370	test: 0.789602
PRC train: 0.937772	val: 0.928425	test: 0.797360

Epoch: 53
Loss: 0.3069648541545136
ROC train: 0.962377	val: 0.677656	test: 0.803860
PRC train: 0.938845	val: 0.930151	test: 0.814829

Epoch: 54
Loss: 0.2925584024919948
ROC train: 0.961932	val: 0.686081	test: 0.811511
PRC train: 0.938964	val: 0.929217	test: 0.824012

Epoch: 55
Loss: 0.29156510661491436
ROC train: 0.960505	val: 0.681319	test: 0.805947
PRC train: 0.937690	val: 0.928578	test: 0.819752

Epoch: 56
Loss: 0.3136497054210415
ROC train: 0.964780	val: 0.677656	test: 0.797427
PRC train: 0.942957	val: 0.927346	test: 0.813001

Epoch: 57
Loss: 0.2863314161781688
ROC train: 0.964372	val: 0.651648	test: 0.793079
PRC train: 0.942014	val: 0.924047	test: 0.803065

Epoch: 58
Loss: 0.2984818906520811
ROC train: 0.963550	val: 0.670330	test: 0.788906
PRC train: 0.942078	val: 0.930793	test: 0.792055

Epoch: 59
Loss: 0.27947066733831233
ROC train: 0.961858	val: 0.648352	test: 0.783864
PRC train: 0.939237	val: 0.923675	test: 0.797908

Epoch: 60
Loss: 0.2930822763469504
ROC train: 0.962003	val: 0.662271	test: 0.794644
PRC train: 0.942046	val: 0.923190	test: 0.806550

Epoch: 61
Loss: 0.2853798661261578
ROC train: 0.962954	val: 0.646520	test: 0.790297
PRC train: 0.942614	val: 0.920246	test: 0.788423

Epoch: 62
Loss: 0.28326946495920435
ROC train: 0.968108	val: 0.658242	test: 0.776387
PRC train: 0.950873	val: 0.926061	test: 0.771504

Epoch: 63
Loss: 0.28601334295445513
ROC train: 0.965619	val: 0.678022	test: 0.753956
PRC train: 0.946920	val: 0.926706	test: 0.764952

Epoch: 64
Loss: 0.2917069937727243
ROC train: 0.968821	val: 0.664835	test: 0.778821
PRC train: 0.951515	val: 0.922939	test: 0.791688

Epoch: 65
Loss: 0.27733589971740635
ROC train: 0.968590	val: 0.647253	test: 0.779864
PRC train: 0.951075	val: 0.921053	test: 0.793577

Epoch: 66
Loss: 0.2836346619452759
ROC train: 0.965451	val: 0.640659	test: 0.784733
PRC train: 0.947770	val: 0.920722	test: 0.790979

Epoch: 67
Loss: 0.2757104980106576
ROC train: 0.966898	val: 0.664103	test: 0.785776
PRC train: 0.949651	val: 0.925501	test: 0.792307

Epoch: 68
Loss: 0.2936393049423844
ROC train: 0.969446	val: 0.667033	test: 0.789428
PRC train: 0.951677	val: 0.927766	test: 0.803264

Epoch: 69
Loss: 0.2699912665548854
ROC train: 0.969997	val: 0.678022	test: 0.778821
PRC train: 0.953895	val: 0.928393	test: 0.785433

Epoch: 70
Loss: 0.26587077286943106
ROC train: 0.971535	val: 0.681685	test: 0.771344
PRC train: 0.955834	val: 0.929590	test: 0.775992

Epoch: 71
Loss: 0.2726716616748118
ROC train: 0.972075	val: 0.664835	test: 0.770475
PRC train: 0.956665	val: 0.926040	test: 0.775108

Epoch: 72
Loss: 0.2891010895410212
ROC train: 0.972951	val: 0.654212	test: 0.780560
PRC train: 0.957214	val: 0.924065	test: 0.782620

Epoch: 73
Loss: 0.2806669676075903
ROC train: 0.972451	val: 0.662637	test: 0.785255
PRC train: 0.955766	val: 0.925816	test: 0.778843

Epoch: 74
Loss: 0.27001626539595525
ROC train: 0.971273	val: 0.663004	test: 0.774474
PRC train: 0.953457	val: 0.928414	test: 0.768955

Epoch: 75
Loss: 0.27172402493017284
ROC train: 0.971384	val: 0.657143	test: 0.800209
PRC train: 0.953918	val: 0.924427	test: 0.795108

Epoch: 76
Loss: 0.26931373678461584
ROC train: 0.973279	val: 0.648718	test: 0.804208
PRC train: 0.958149	val: 0.922651	test: 0.792465

Epoch: 77
Loss: 0.2737080618883599
ROC train: 0.972900	val: 0.652015	test: 0.787167
PRC train: 0.958055	val: 0.925360	test: 0.794646

Epoch: 78
Loss: 0.25230584242883963
ROC train: 0.968975	val: 0.668864	test: 0.776039
PRC train: 0.951680	val: 0.928740	test: 0.776665

Epoch: 79
Loss: 0.2727556440309384
ROC train: 0.973065	val: 0.669597	test: 0.786124
PRC train: 0.957920	val: 0.925857	test: 0.788265

Epoch: 80
Loss: 0.25634764314164593
ROC train: 0.976761	val: 0.663370	test: 0.786646
PRC train: 0.964904	val: 0.925637	test: 0.790984

Epoch: 81
Loss: 0.26303664077637
ROC train: 0.976239	val: 0.646154	test: 0.787689
PRC train: 0.964441	val: 0.923852	test: 0.790681

Epoch: 82
Loss: 0.2614591111045451
ROC train: 0.975245	val: 0.664835	test: 0.769605
PRC train: 0.962123	val: 0.927270	test: 0.776768

Epoch: 83
Loss: 0.26253854182563113
ROC train: 0.974130	val: 0.656777	test: 0.759868
PRC train: 0.959576	val: 0.923399	test: 0.777196

Epoch: 84
Loss: 0.2621469000616258
ROC train: 0.977172	val: 0.658242	test: 0.761954
PRC train: 0.964117	val: 0.926596	test: 0.775100

Epoch: 85
Loss: 0.25384857963144053
ROC train: 0.977471	val: 0.681685	test: 0.779517
PRC train: 0.964793	val: 0.929489	test: 0.789149

Epoch: 86
Loss: 0.25213188609663006
ROC train: 0.973604	val: 0.676923	test: 0.783516
PRC train: 0.958608	val: 0.927575	test: 0.793451

Epoch: 87
Loss: 0.2286772768728166
ROC train: 0.976906	val: 0.638462	test: 0.774126
PRC train: 0.964281	val: 0.922082	test: 0.783614

Epoch: 88
Loss: 0.25215993791240987
ROC train: 0.976370	val: 0.621245	test: 0.794123
PRC train: 0.964487	val: 0.915437	test: 0.793355

Epoch: 89
Loss: 0.24698489039122923
ROC train: 0.976430	val: 0.633700	test: 0.787515
PRC train: 0.962990	val: 0.916441	test: 0.776890

Epoch: 90
Loss: 0.24894631988350321
ROC train: 0.975548	val: 0.657509	test: 0.774126
PRC train: 0.963561	val: 0.921966	test: 0.761692

Epoch: 91
Loss: 0.24815545476081224
ROC train: 0.976259	val: 0.668132	test: 0.780908
PRC train: 0.964272	val: 0.926977	test: 0.782155

Epoch: 92
Loss: 0.2540656012743391
ROC train: 0.978430	val: 0.677289	test: 0.794992
PRC train: 0.967422	val: 0.930624	test: 0.800171

Epoch: 93
Loss: 0.23516447620631498
ROC train: 0.979795	val: 0.688645	test: 0.795862
PRC train: 0.969670	val: 0.930788	test: 0.805792

Epoch: 94
Loss: 0.22721419093169107
PRC train: 0.916404	val: 0.923990	test: 0.817243

Epoch: 34
Loss: 0.3219122361050175
ROC train: 0.950825	val: 0.654945	test: 0.811337
PRC train: 0.921840	val: 0.922300	test: 0.825936

Epoch: 35
Loss: 0.3379162978422676
ROC train: 0.950853	val: 0.661172	test: 0.798470
PRC train: 0.922715	val: 0.923484	test: 0.818218

Epoch: 36
Loss: 0.3406540035498152
ROC train: 0.951473	val: 0.680220	test: 0.794644
PRC train: 0.923229	val: 0.925887	test: 0.825014

Epoch: 37
Loss: 0.33095064197474505
ROC train: 0.950137	val: 0.683516	test: 0.777952
PRC train: 0.922862	val: 0.928458	test: 0.808050

Epoch: 38
Loss: 0.3199280076304536
ROC train: 0.950930	val: 0.666300	test: 0.802991
PRC train: 0.924122	val: 0.928387	test: 0.823606

Epoch: 39
Loss: 0.32506449550292205
ROC train: 0.951210	val: 0.679487	test: 0.810294
PRC train: 0.923539	val: 0.927297	test: 0.814468

Epoch: 40
Loss: 0.31956566433216116
ROC train: 0.953128	val: 0.683516	test: 0.805599
PRC train: 0.925800	val: 0.925277	test: 0.810850

Epoch: 41
Loss: 0.3312551698848937
ROC train: 0.957483	val: 0.672527	test: 0.808033
PRC train: 0.933568	val: 0.924797	test: 0.818498

Epoch: 42
Loss: 0.3066143033603969
ROC train: 0.957129	val: 0.668132	test: 0.809946
PRC train: 0.931902	val: 0.922986	test: 0.826368

Epoch: 43
Loss: 0.3170685293627725
ROC train: 0.955868	val: 0.667766	test: 0.803165
PRC train: 0.931278	val: 0.924007	test: 0.817492

Epoch: 44
Loss: 0.31047550865886187
ROC train: 0.957725	val: 0.668498	test: 0.797253
PRC train: 0.933187	val: 0.924207	test: 0.815239

Epoch: 45
Loss: 0.29240454901876733
ROC train: 0.957038	val: 0.680952	test: 0.815336
PRC train: 0.932715	val: 0.928516	test: 0.833285

Epoch: 46
Loss: 0.29781900947154616
ROC train: 0.960985	val: 0.667399	test: 0.814641
PRC train: 0.937459	val: 0.927861	test: 0.831175

Epoch: 47
Loss: 0.32459992576139574
ROC train: 0.957674	val: 0.672527	test: 0.793427
PRC train: 0.933894	val: 0.929924	test: 0.814037

Epoch: 48
Loss: 0.3166497399076391
ROC train: 0.960368	val: 0.658974	test: 0.795340
PRC train: 0.937117	val: 0.926651	test: 0.825910

Epoch: 49
Loss: 0.30199766561259855
ROC train: 0.962931	val: 0.657509	test: 0.808033
PRC train: 0.942589	val: 0.925611	test: 0.837675

Epoch: 50
Loss: 0.28457236291010835
ROC train: 0.961353	val: 0.668864	test: 0.809946
PRC train: 0.938279	val: 0.925468	test: 0.825866

Epoch: 51
Loss: 0.2970528360505365
ROC train: 0.962209	val: 0.639194	test: 0.816206
PRC train: 0.940696	val: 0.919690	test: 0.836108

Epoch: 52
Loss: 0.2980042014541068
ROC train: 0.960811	val: 0.649451	test: 0.829769
PRC train: 0.938792	val: 0.920703	test: 0.846491

Epoch: 53
Loss: 0.28628900245944594
ROC train: 0.960197	val: 0.666300	test: 0.811337
PRC train: 0.938467	val: 0.923394	test: 0.828251

Epoch: 54
Loss: 0.29467357840512537
ROC train: 0.962837	val: 0.647253	test: 0.794644
PRC train: 0.941527	val: 0.922746	test: 0.813986

Epoch: 55
Loss: 0.29880780176868893
ROC train: 0.965154	val: 0.659707	test: 0.800209
PRC train: 0.946701	val: 0.928222	test: 0.813993

Epoch: 56
Loss: 0.27609387228125676
ROC train: 0.957517	val: 0.675824	test: 0.775865
PRC train: 0.935865	val: 0.929658	test: 0.796352

Epoch: 57
Loss: 0.29531219835754463
ROC train: 0.965291	val: 0.659707	test: 0.762824
PRC train: 0.946533	val: 0.927401	test: 0.798210

Epoch: 58
Loss: 0.28796473250695903
ROC train: 0.964027	val: 0.651282	test: 0.776734
PRC train: 0.945247	val: 0.925970	test: 0.797177

Epoch: 59
Loss: 0.2903774270151854
ROC train: 0.963045	val: 0.656777	test: 0.795688
PRC train: 0.940897	val: 0.923618	test: 0.812714

Epoch: 60
Loss: 0.28002125843764497
ROC train: 0.965822	val: 0.641392	test: 0.804556
PRC train: 0.945831	val: 0.921980	test: 0.815496

Epoch: 61
Loss: 0.2774503692975296
ROC train: 0.968955	val: 0.670696	test: 0.783342
PRC train: 0.951959	val: 0.932064	test: 0.791929

Epoch: 62
Loss: 0.2709539056590121
ROC train: 0.968348	val: 0.688645	test: 0.751695
PRC train: 0.952065	val: 0.937216	test: 0.770087

Epoch: 63
Loss: 0.2796154674047682
ROC train: 0.968185	val: 0.686081	test: 0.778821
PRC train: 0.950869	val: 0.930248	test: 0.791650

Epoch: 64
Loss: 0.28804232149998227
ROC train: 0.967697	val: 0.672894	test: 0.814641
PRC train: 0.950404	val: 0.927451	test: 0.832999

Epoch: 65
Loss: 0.30572416804706304
ROC train: 0.968470	val: 0.676923	test: 0.817597
PRC train: 0.952042	val: 0.929090	test: 0.845267

Epoch: 66
Loss: 0.26801845894079945
ROC train: 0.970271	val: 0.657143	test: 0.805077
PRC train: 0.954149	val: 0.925054	test: 0.837626

Epoch: 67
Loss: 0.2511305382271677
ROC train: 0.970431	val: 0.683883	test: 0.797079
PRC train: 0.953523	val: 0.932707	test: 0.815168

Epoch: 68
Loss: 0.27573202441222133
ROC train: 0.973830	val: 0.679487	test: 0.792558
PRC train: 0.959793	val: 0.934756	test: 0.813124

Epoch: 69
Loss: 0.25676465652841296
ROC train: 0.972197	val: 0.653480	test: 0.789602
PRC train: 0.955135	val: 0.929214	test: 0.803811

Epoch: 70
Loss: 0.2910297986107449
ROC train: 0.973693	val: 0.658608	test: 0.796557
PRC train: 0.959093	val: 0.927054	test: 0.811693

Epoch: 71
Loss: 0.27011619719755714
ROC train: 0.974409	val: 0.656777	test: 0.797600
PRC train: 0.961168	val: 0.923544	test: 0.814368

Epoch: 72
Loss: 0.2991542765052516
ROC train: 0.973907	val: 0.650549	test: 0.804903
PRC train: 0.960652	val: 0.924514	test: 0.823013

Epoch: 73
Loss: 0.2625526913919075
ROC train: 0.973941	val: 0.650549	test: 0.778821
PRC train: 0.961046	val: 0.928529	test: 0.797902

Epoch: 74
Loss: 0.2755023963106892
ROC train: 0.973562	val: 0.631136	test: 0.760737
PRC train: 0.960292	val: 0.920781	test: 0.778045

Epoch: 75
Loss: 0.2827320606861124
ROC train: 0.975890	val: 0.657143	test: 0.800730
PRC train: 0.963622	val: 0.925802	test: 0.825234

Epoch: 76
Loss: 0.2672039262251064
ROC train: 0.970345	val: 0.694872	test: 0.789602
PRC train: 0.955217	val: 0.932839	test: 0.808994

Epoch: 77
Loss: 0.2616535845291089
ROC train: 0.972848	val: 0.698168	test: 0.775343
PRC train: 0.957582	val: 0.934461	test: 0.793883

Epoch: 78
Loss: 0.24948543245715754
ROC train: 0.975873	val: 0.680220	test: 0.777952
PRC train: 0.963538	val: 0.930574	test: 0.799240

Epoch: 79
Loss: 0.2704014327331131
ROC train: 0.977688	val: 0.651282	test: 0.769431
PRC train: 0.966076	val: 0.926252	test: 0.781138

Epoch: 80
Loss: 0.2626166033627104
ROC train: 0.978987	val: 0.657143	test: 0.770475
PRC train: 0.969146	val: 0.929217	test: 0.780967

Epoch: 81
Loss: 0.26566568503906063
ROC train: 0.977337	val: 0.672894	test: 0.773605
PRC train: 0.966269	val: 0.930617	test: 0.783367

Epoch: 82
Loss: 0.25939497544969137
ROC train: 0.978958	val: 0.665201	test: 0.781255
PRC train: 0.967722	val: 0.927798	test: 0.789968

Epoch: 83
Loss: 0.2503484821940693
ROC train: 0.976104	val: 0.675458	test: 0.759868
PRC train: 0.962480	val: 0.928790	test: 0.766112

Epoch: 84
Loss: 0.25682115384828896
ROC train: 0.978804	val: 0.684615	test: 0.769258
PRC train: 0.968158	val: 0.930353	test: 0.774976

Epoch: 85
Loss: 0.26245561578892185
ROC train: 0.976801	val: 0.680586	test: 0.763172
PRC train: 0.965467	val: 0.929692	test: 0.772439

Epoch: 86
Loss: 0.25749526171781645
ROC train: 0.975696	val: 0.670330	test: 0.766649
PRC train: 0.963563	val: 0.928682	test: 0.779809

Epoch: 87
Loss: 0.24886131534365846
ROC train: 0.979064	val: 0.663370	test: 0.770649
PRC train: 0.968808	val: 0.927592	test: 0.778261

Epoch: 88
Loss: 0.23620893301663917
ROC train: 0.978990	val: 0.671062	test: 0.751521
PRC train: 0.967526	val: 0.927237	test: 0.756326

Epoch: 89
Loss: 0.2521738355307951
ROC train: 0.981692	val: 0.669231	test: 0.762476
PRC train: 0.971956	val: 0.933044	test: 0.774026

Epoch: 90
Loss: 0.23373423670962853
ROC train: 0.978927	val: 0.678022	test: 0.748044
PRC train: 0.968606	val: 0.935501	test: 0.764512

Epoch: 91
Loss: 0.24743294694074938
ROC train: 0.978930	val: 0.668132	test: 0.753782
PRC train: 0.968486	val: 0.931289	test: 0.769707

Epoch: 92
Loss: 0.22843312677277705
ROC train: 0.982880	val: 0.660806	test: 0.776387
PRC train: 0.974728	val: 0.930729	test: 0.790744

Epoch: 93
Loss: 0.2390198041203319
ROC train: 0.975668	val: 0.664103	test: 0.766475
PRC train: 0.962823	val: 0.924227	test: 0.778678

Epoch: 94
Loss: 0.22852525292419434
ROC train: 0.976821	val: 0.675458	test: 0.772040
ROC train: 0.965291	val: 0.851399	test: 0.752679
PRC train: 0.962380	val: 0.440802	test: 0.870905

Epoch: 95
Loss: 0.2952459419356592
ROC train: 0.969256	val: 0.855672	test: 0.740882
PRC train: 0.966419	val: 0.427209	test: 0.864736

Epoch: 96
Loss: 0.2797309013088715
ROC train: 0.970079	val: 0.844600	test: 0.732124
PRC train: 0.966666	val: 0.411260	test: 0.858410

Epoch: 97
Loss: 0.26642630222091856
ROC train: 0.972273	val: 0.840229	test: 0.739130
PRC train: 0.969294	val: 0.411577	test: 0.860571

Epoch: 98
Loss: 0.27855200881277414
ROC train: 0.973680	val: 0.839161	test: 0.733361
PRC train: 0.971018	val: 0.423504	test: 0.858266

Epoch: 99
Loss: 0.2735256011782732
ROC train: 0.974147	val: 0.839646	test: 0.738873
PRC train: 0.972128	val: 0.430809	test: 0.861945

Epoch: 100
Loss: 0.2575477108985392
ROC train: 0.973271	val: 0.846542	test: 0.743973
PRC train: 0.970758	val: 0.426127	test: 0.870617

Epoch: 101
Loss: 0.2754358361931182
ROC train: 0.976531	val: 0.842657	test: 0.733206
PRC train: 0.974698	val: 0.409061	test: 0.861964

Epoch: 102
Loss: 0.2648593753968278
ROC train: 0.978074	val: 0.847805	test: 0.722182
PRC train: 0.976802	val: 0.423454	test: 0.848424

Epoch: 103
Loss: 0.26621167341589175
ROC train: 0.974132	val: 0.847708	test: 0.733155
PRC train: 0.972044	val: 0.444329	test: 0.842045

Epoch: 104
Loss: 0.24478963952622732
ROC train: 0.975592	val: 0.853341	test: 0.755151
PRC train: 0.973287	val: 0.453216	test: 0.858873

Epoch: 105
Loss: 0.25709641331720384
ROC train: 0.977456	val: 0.859654	test: 0.750412
PRC train: 0.975567	val: 0.465565	test: 0.866403

Epoch: 106
Loss: 0.2572306581525753
ROC train: 0.977091	val: 0.863054	test: 0.728879
PRC train: 0.975729	val: 0.459809	test: 0.858302

Epoch: 107
Loss: 0.2815590069901065
ROC train: 0.976585	val: 0.848776	test: 0.709046
PRC train: 0.975206	val: 0.441561	test: 0.845997

Epoch: 108
Loss: 0.2445950184516385
ROC train: 0.974843	val: 0.848485	test: 0.721358
PRC train: 0.973032	val: 0.435546	test: 0.850127

Epoch: 109
Loss: 0.2676834507157552
ROC train: 0.970998	val: 0.835859	test: 0.719246
PRC train: 0.968587	val: 0.453069	test: 0.843745

Epoch: 110
Loss: 0.2685010999352855
ROC train: 0.974838	val: 0.838190	test: 0.726509
PRC train: 0.972404	val: 0.461735	test: 0.851567

Epoch: 111
Loss: 0.25093607707599414
ROC train: 0.980176	val: 0.844114	test: 0.733618
PRC train: 0.978688	val: 0.434751	test: 0.860216

Epoch: 112
Loss: 0.24226436421366726
ROC train: 0.976877	val: 0.836830	test: 0.744076
PRC train: 0.974879	val: 0.398934	test: 0.867229

Epoch: 113
Loss: 0.23343848685915647
ROC train: 0.973597	val: 0.836733	test: 0.736503
PRC train: 0.970732	val: 0.387004	test: 0.862183

Epoch: 114
Loss: 0.2582697670101434
ROC train: 0.972259	val: 0.827991	test: 0.730734
PRC train: 0.969893	val: 0.388568	test: 0.854896

Epoch: 115
Loss: 0.2275784919581001
ROC train: 0.967918	val: 0.816725	test: 0.737688
PRC train: 0.966127	val: 0.396790	test: 0.844394

Epoch: 116
Loss: 0.26004180610251115
ROC train: 0.979037	val: 0.831391	test: 0.722697
PRC train: 0.977756	val: 0.413752	test: 0.842379

Epoch: 117
Loss: 0.24026306265509584
ROC train: 0.981348	val: 0.841103	test: 0.688543
PRC train: 0.980493	val: 0.422682	test: 0.832747

Epoch: 118
Loss: 0.2602231815528572
ROC train: 0.979168	val: 0.844503	test: 0.694467
PRC train: 0.978530	val: 0.408648	test: 0.840409

Epoch: 119
Loss: 0.24042346202468293
ROC train: 0.978030	val: 0.850136	test: 0.709355
PRC train: 0.977229	val: 0.403556	test: 0.848319

Epoch: 120
Loss: 0.24648808347142492
ROC train: 0.980448	val: 0.858100	test: 0.721667
PRC train: 0.979092	val: 0.443290	test: 0.846271

Epoch: 121
Loss: 0.2538047592577671
ROC train: 0.981606	val: 0.855769	test: 0.723676
PRC train: 0.980346	val: 0.451301	test: 0.842372

Epoch: 122
Loss: 0.2488524633708012
ROC train: 0.983407	val: 0.852758	test: 0.718267
PRC train: 0.982114	val: 0.434593	test: 0.838785

Epoch: 123
Loss: 0.24389634195200188
ROC train: 0.981509	val: 0.849456	test: 0.715434
PRC train: 0.980170	val: 0.420842	test: 0.839091

Epoch: 124
Loss: 0.23758716719105846
ROC train: 0.984103	val: 0.845668	test: 0.715279
PRC train: 0.982858	val: 0.417232	test: 0.846069

Epoch: 125
Loss: 0.22112605921014375
ROC train: 0.985397	val: 0.846737	test: 0.713682
PRC train: 0.984572	val: 0.423709	test: 0.849202

Epoch: 126
Loss: 0.21181431017377317
ROC train: 0.984594	val: 0.844017	test: 0.710797
PRC train: 0.983984	val: 0.411198	test: 0.846926

Epoch: 127
Loss: 0.2502027572471395
ROC train: 0.984419	val: 0.850427	test: 0.725325
PRC train: 0.983745	val: 0.430433	test: 0.853200

Epoch: 128
Loss: 0.23360068601738365
ROC train: 0.983105	val: 0.848679	test: 0.727076
PRC train: 0.981749	val: 0.425486	test: 0.855568

Epoch: 129
Loss: 0.2393245137718905
ROC train: 0.981767	val: 0.841395	test: 0.719812
PRC train: 0.980756	val: 0.409856	test: 0.846500

Epoch: 130
Loss: 0.25368359364260556
ROC train: 0.981095	val: 0.847805	test: 0.702504
PRC train: 0.979790	val: 0.432861	test: 0.828265

Epoch: 131
Loss: 0.21266799269584571
ROC train: 0.980263	val: 0.862471	test: 0.696373
PRC train: 0.978892	val: 0.457914	test: 0.832777

Epoch: 132
Loss: 0.22136092154156362
ROC train: 0.978964	val: 0.856255	test: 0.691273
PRC train: 0.976871	val: 0.448157	test: 0.827612

Epoch: 133
Loss: 0.2183249979308064
ROC train: 0.984502	val: 0.845668	test: 0.697146
PRC train: 0.983492	val: 0.446270	test: 0.822723

Epoch: 134
Loss: 0.22489504181163683
ROC train: 0.986760	val: 0.831779	test: 0.707449
PRC train: 0.985821	val: 0.412512	test: 0.836455

Epoch: 135
Loss: 0.24581585325559177
ROC train: 0.983976	val: 0.824592	test: 0.713888
PRC train: 0.982572	val: 0.390773	test: 0.837238

Epoch: 136
Loss: 0.23765275359594715
ROC train: 0.983947	val: 0.828380	test: 0.709097
PRC train: 0.982821	val: 0.397774	test: 0.837009

Epoch: 137
Loss: 0.23466003127394314
ROC train: 0.985567	val: 0.826729	test: 0.706367
PRC train: 0.985037	val: 0.394026	test: 0.835597

Epoch: 138
Loss: 0.22734132290213413
ROC train: 0.985932	val: 0.836927	test: 0.712652
PRC train: 0.985364	val: 0.418743	test: 0.832917

Epoch: 139
Loss: 0.2187754111439874
ROC train: 0.982219	val: 0.841006	test: 0.719194
PRC train: 0.980962	val: 0.423821	test: 0.827584

Epoch: 140
Loss: 0.22501255427698652
ROC train: 0.984706	val: 0.842560	test: 0.708376
PRC train: 0.983394	val: 0.404543	test: 0.833010

Epoch: 141
Loss: 0.2304571664637825
ROC train: 0.987037	val: 0.846057	test: 0.704307
PRC train: 0.986359	val: 0.410598	test: 0.831596

Early stopping
Best (ROC):	 train: 0.977091	val: 0.863054	test: 0.728879
Best (PRC):	 train: 0.975729	val: 0.459809	test: 0.858302

ROC train: 0.961284	val: 0.723362	test: 0.807060
PRC train: 0.948806	val: 0.463705	test: 0.897488

Epoch: 95
Loss: 0.27346626247507866
ROC train: 0.951551	val: 0.685835	test: 0.785121
PRC train: 0.938248	val: 0.392726	test: 0.872256

Epoch: 96
Loss: 0.2771456243297393
ROC train: 0.955455	val: 0.697146	test: 0.787107
PRC train: 0.943811	val: 0.394749	test: 0.861981

Epoch: 97
Loss: 0.3083182203206127
ROC train: 0.957380	val: 0.731501	test: 0.799025
PRC train: 0.947330	val: 0.433931	test: 0.881574

Epoch: 98
Loss: 0.25887676353469813
ROC train: 0.957362	val: 0.747780	test: 0.818707
PRC train: 0.947077	val: 0.453690	test: 0.902451

Epoch: 99
Loss: 0.2899625000284975
ROC train: 0.961410	val: 0.743129	test: 0.836132
PRC train: 0.950905	val: 0.455538	test: 0.910978

Epoch: 100
Loss: 0.26833252573530986
ROC train: 0.962604	val: 0.737421	test: 0.845251
PRC train: 0.951589	val: 0.447922	test: 0.916316

Epoch: 101
Loss: 0.24962220780241712
ROC train: 0.964680	val: 0.739006	test: 0.848501
PRC train: 0.954275	val: 0.456743	test: 0.919591

Epoch: 102
Loss: 0.28398762507737585
ROC train: 0.960492	val: 0.731501	test: 0.843445
PRC train: 0.948429	val: 0.459162	test: 0.916047

Epoch: 103
Loss: 0.3237115206932171
ROC train: 0.962291	val: 0.724313	test: 0.833965
PRC train: 0.952525	val: 0.456660	test: 0.908111

Epoch: 104
Loss: 0.2815076605741846
ROC train: 0.966292	val: 0.733087	test: 0.824395
PRC train: 0.958797	val: 0.432256	test: 0.902016

Epoch: 105
Loss: 0.26987697686918205
ROC train: 0.968041	val: 0.743975	test: 0.815276
PRC train: 0.962821	val: 0.444472	test: 0.891417

Epoch: 106
Loss: 0.2815131366405624
ROC train: 0.964468	val: 0.747569	test: 0.820603
PRC train: 0.956888	val: 0.455689	test: 0.896800

Epoch: 107
Loss: 0.2997260776409061
ROC train: 0.968077	val: 0.751480	test: 0.822499
PRC train: 0.961125	val: 0.482238	test: 0.901376

Epoch: 108
Loss: 0.2733579130761421
ROC train: 0.970617	val: 0.750106	test: 0.815186
PRC train: 0.964821	val: 0.493054	test: 0.899701

Epoch: 109
Loss: 0.2912746343787706
ROC train: 0.970265	val: 0.752114	test: 0.817533
PRC train: 0.963388	val: 0.469443	test: 0.903162

Epoch: 110
Loss: 0.28353780504977333
ROC train: 0.960575	val: 0.739323	test: 0.816901
PRC train: 0.950234	val: 0.455471	test: 0.902250

Epoch: 111
Loss: 0.31280326540769376
ROC train: 0.958301	val: 0.730973	test: 0.813109
PRC train: 0.945850	val: 0.429220	test: 0.893588

Epoch: 112
Loss: 0.3082009009774086
ROC train: 0.965911	val: 0.737738	test: 0.809949
PRC train: 0.956371	val: 0.434443	test: 0.897079

Epoch: 113
Loss: 0.2865568576641314
ROC train: 0.967584	val: 0.733404	test: 0.804713
PRC train: 0.958510	val: 0.417942	test: 0.892887

Epoch: 114
Loss: 0.280468605870298
ROC train: 0.971064	val: 0.735412	test: 0.794150
PRC train: 0.964697	val: 0.420226	test: 0.891753

Epoch: 115
Loss: 0.25590788047629076
ROC train: 0.968520	val: 0.741332	test: 0.802095
PRC train: 0.961400	val: 0.427855	test: 0.892601

Epoch: 116
Loss: 0.29030614840229196
ROC train: 0.963234	val: 0.746934	test: 0.810672
PRC train: 0.954410	val: 0.431202	test: 0.886545

Epoch: 117
Loss: 0.2555756002035294
ROC train: 0.952353	val: 0.752854	test: 0.801914
PRC train: 0.942935	val: 0.439536	test: 0.871100

Epoch: 118
Loss: 0.28151722194532364
ROC train: 0.964821	val: 0.746089	test: 0.802636
PRC train: 0.957737	val: 0.440551	test: 0.880180

Epoch: 119
Loss: 0.3321274468467754
ROC train: 0.967631	val: 0.728647	test: 0.811123
PRC train: 0.959694	val: 0.428288	test: 0.896230

Epoch: 120
Loss: 0.27477412830995906
ROC train: 0.961752	val: 0.719450	test: 0.808505
PRC train: 0.952497	val: 0.408671	test: 0.892057

Early stopping
Best (ROC):	 train: 0.950579	val: 0.761311	test: 0.834507
Best (PRC):	 train: 0.937613	val: 0.432483	test: 0.906717

ROC train: 0.980237	val: 0.649084	test: 0.740915
PRC train: 0.969492	val: 0.926244	test: 0.762316

Epoch: 95
Loss: 0.23420618996451217
ROC train: 0.979523	val: 0.641026	test: 0.756042
PRC train: 0.968703	val: 0.924966	test: 0.779251

Epoch: 96
Loss: 0.23153451825701285
ROC train: 0.983071	val: 0.649451	test: 0.756912
PRC train: 0.974760	val: 0.927133	test: 0.766104

Epoch: 97
Loss: 0.25592342225837594
ROC train: 0.981464	val: 0.658608	test: 0.732742
PRC train: 0.971101	val: 0.923076	test: 0.741049

Epoch: 98
Loss: 0.23156827209766254
ROC train: 0.977032	val: 0.651648	test: 0.744218
PRC train: 0.963920	val: 0.918266	test: 0.768757

Epoch: 99
Loss: 0.23963160519454182
ROC train: 0.981484	val: 0.664469	test: 0.737785
PRC train: 0.973125	val: 0.923626	test: 0.766455

Epoch: 100
Loss: 0.24739238402116737
ROC train: 0.980776	val: 0.668132	test: 0.738654
PRC train: 0.970466	val: 0.926244	test: 0.765786

Epoch: 101
Loss: 0.2273136402305262
ROC train: 0.983402	val: 0.642491	test: 0.758651
PRC train: 0.974402	val: 0.923084	test: 0.785074

Epoch: 102
Loss: 0.22566136223231484
ROC train: 0.982994	val: 0.671429	test: 0.760216
PRC train: 0.974980	val: 0.931420	test: 0.779342

Epoch: 103
Loss: 0.2458887241305146
ROC train: 0.985811	val: 0.659341	test: 0.762650
PRC train: 0.979270	val: 0.929678	test: 0.777698

Epoch: 104
Loss: 0.2346030849245743
ROC train: 0.983308	val: 0.646520	test: 0.737089
PRC train: 0.976219	val: 0.927546	test: 0.748440

Epoch: 105
Loss: 0.23369666132630518
ROC train: 0.980240	val: 0.682784	test: 0.740393
PRC train: 0.970121	val: 0.937320	test: 0.743947

Epoch: 106
Loss: 0.21977595684612386
ROC train: 0.982957	val: 0.649817	test: 0.733612
PRC train: 0.975137	val: 0.927615	test: 0.743202

Epoch: 107
Loss: 0.23012261498042602
ROC train: 0.983119	val: 0.641026	test: 0.734481
PRC train: 0.974676	val: 0.919546	test: 0.752378

Epoch: 108
Loss: 0.21992310339513113
ROC train: 0.979335	val: 0.633700	test: 0.739176
PRC train: 0.969090	val: 0.917899	test: 0.758183

Epoch: 109
Loss: 0.22058001709232716
ROC train: 0.983051	val: 0.660073	test: 0.741089
PRC train: 0.974322	val: 0.922068	test: 0.767836

Epoch: 110
Loss: 0.22226777195433609
ROC train: 0.985568	val: 0.661172	test: 0.741610
PRC train: 0.978256	val: 0.925032	test: 0.762171

Epoch: 111
Loss: 0.2093766213593992
ROC train: 0.985365	val: 0.671429	test: 0.733264
PRC train: 0.978066	val: 0.927222	test: 0.753883

Epoch: 112
Loss: 0.21561656739854698
ROC train: 0.985756	val: 0.657875	test: 0.734133
PRC train: 0.979078	val: 0.925751	test: 0.760291

Epoch: 113
Loss: 0.21297653386250653
ROC train: 0.986047	val: 0.667766	test: 0.729264
PRC train: 0.979284	val: 0.929941	test: 0.756514

Epoch: 114
Loss: 0.20249254284064605
ROC train: 0.983918	val: 0.679121	test: 0.742480
PRC train: 0.975331	val: 0.929391	test: 0.768667

Epoch: 115
Loss: 0.21823749634232104
ROC train: 0.986541	val: 0.670330	test: 0.749435
PRC train: 0.979903	val: 0.926069	test: 0.770838

Epoch: 116
Loss: 0.21789392721173179
ROC train: 0.986752	val: 0.645421	test: 0.745262
PRC train: 0.980387	val: 0.922962	test: 0.770699

Epoch: 117
Loss: 0.21380714434779075
ROC train: 0.988704	val: 0.641026	test: 0.748044
PRC train: 0.983441	val: 0.921533	test: 0.767926

Epoch: 118
Loss: 0.21632186038578305
ROC train: 0.988265	val: 0.647619	test: 0.723526
PRC train: 0.982746	val: 0.925812	test: 0.750166

Epoch: 119
Loss: 0.21654166416754306
ROC train: 0.985385	val: 0.681685	test: 0.715528
PRC train: 0.976435	val: 0.930426	test: 0.746568

Epoch: 120
Loss: 0.21028352796208746
ROC train: 0.987934	val: 0.669231	test: 0.735003
PRC train: 0.981648	val: 0.928784	test: 0.756657

Early stopping
Best (ROC):	 train: 0.896413	val: 0.701832	test: 0.787515
Best (PRC):	 train: 0.833187	val: 0.938551	test: 0.793425

ROC train: 0.979050	val: 0.676923	test: 0.786646
PRC train: 0.968825	val: 0.929921	test: 0.801895

Epoch: 95
Loss: 0.24523169763870442
ROC train: 0.978299	val: 0.661905	test: 0.795166
PRC train: 0.967523	val: 0.927951	test: 0.797886

Epoch: 96
Loss: 0.24858606971574396
ROC train: 0.978901	val: 0.672161	test: 0.788037
PRC train: 0.968510	val: 0.928481	test: 0.785085

Epoch: 97
Loss: 0.23668259272862663
ROC train: 0.979489	val: 0.667766	test: 0.773952
PRC train: 0.968564	val: 0.928132	test: 0.768413

Epoch: 98
Loss: 0.23552418113744297
ROC train: 0.980394	val: 0.660073	test: 0.779169
PRC train: 0.969099	val: 0.924706	test: 0.771975

Epoch: 99
Loss: 0.22595992558276326
ROC train: 0.980713	val: 0.655678	test: 0.779169
PRC train: 0.970283	val: 0.923215	test: 0.777351

Epoch: 100
Loss: 0.2516762282900228
ROC train: 0.976042	val: 0.656044	test: 0.770301
PRC train: 0.963995	val: 0.925547	test: 0.765283

Epoch: 101
Loss: 0.24020094925703997
ROC train: 0.978028	val: 0.671062	test: 0.786124
PRC train: 0.966729	val: 0.927503	test: 0.778048

Epoch: 102
Loss: 0.2439552431894909
ROC train: 0.982172	val: 0.661905	test: 0.786472
PRC train: 0.973592	val: 0.930708	test: 0.781396

Epoch: 103
Loss: 0.22331359389766553
ROC train: 0.976153	val: 0.666300	test: 0.772214
PRC train: 0.964345	val: 0.929907	test: 0.774590

Epoch: 104
Loss: 0.23837942171937643
ROC train: 0.982460	val: 0.660806	test: 0.765432
PRC train: 0.974424	val: 0.925613	test: 0.762266

Epoch: 105
Loss: 0.22663563652149937
ROC train: 0.982423	val: 0.658242	test: 0.768214
PRC train: 0.973360	val: 0.925546	test: 0.764566

Epoch: 106
Loss: 0.23420084738552505
ROC train: 0.978716	val: 0.654945	test: 0.765606
PRC train: 0.967982	val: 0.923640	test: 0.771759

Epoch: 107
Loss: 0.2318682336692696
ROC train: 0.979521	val: 0.649817	test: 0.766997
PRC train: 0.968442	val: 0.922435	test: 0.776641

Epoch: 108
Loss: 0.23530009566467952
ROC train: 0.984432	val: 0.653480	test: 0.769605
PRC train: 0.976293	val: 0.926410	test: 0.766530

Epoch: 109
Loss: 0.21441824328494624
ROC train: 0.983465	val: 0.661905	test: 0.769779
PRC train: 0.975477	val: 0.928004	test: 0.752536

Epoch: 110
Loss: 0.2447625870945807
ROC train: 0.985186	val: 0.667033	test: 0.776561
PRC train: 0.977641	val: 0.926724	test: 0.755490

Epoch: 111
Loss: 0.2323148773970491
ROC train: 0.984580	val: 0.679853	test: 0.775865
PRC train: 0.976683	val: 0.929596	test: 0.758770

Epoch: 112
Loss: 0.20671244100465502
ROC train: 0.981761	val: 0.684982	test: 0.785255
PRC train: 0.971649	val: 0.931449	test: 0.768529

Epoch: 113
Loss: 0.2336704487231592
ROC train: 0.985143	val: 0.669231	test: 0.782125
PRC train: 0.977739	val: 0.929398	test: 0.778417

Epoch: 114
Loss: 0.22176686433721676
ROC train: 0.984700	val: 0.636630	test: 0.779517
PRC train: 0.977705	val: 0.921071	test: 0.780872

Epoch: 115
Loss: 0.22502126165941308
ROC train: 0.984872	val: 0.627839	test: 0.777430
PRC train: 0.978221	val: 0.919583	test: 0.778446

Epoch: 116
Loss: 0.21137685926199534
ROC train: 0.982597	val: 0.664835	test: 0.765432
PRC train: 0.974753	val: 0.927898	test: 0.766196

Epoch: 117
Loss: 0.2244217069349502
ROC train: 0.982657	val: 0.664469	test: 0.761781
PRC train: 0.974446	val: 0.926250	test: 0.772504

Epoch: 118
Loss: 0.22809793428252645
ROC train: 0.986201	val: 0.649084	test: 0.767171
PRC train: 0.979663	val: 0.924299	test: 0.770822

Epoch: 119
Loss: 0.23243264674695405
ROC train: 0.987055	val: 0.656410	test: 0.775170
PRC train: 0.981009	val: 0.926627	test: 0.773622

Epoch: 120
Loss: 0.20968784546945826
ROC train: 0.985026	val: 0.656044	test: 0.772214
PRC train: 0.978389	val: 0.924798	test: 0.766481

Early stopping
Best (ROC):	 train: 0.888533	val: 0.722344	test: 0.781951
Best (PRC):	 train: 0.820557	val: 0.940009	test: 0.775002

PRC train: 0.964632	val: 0.927961	test: 0.779977

Epoch: 95
Loss: 0.22335378992477645
ROC train: 0.982503	val: 0.662637	test: 0.753782
PRC train: 0.972869	val: 0.925818	test: 0.764735

Epoch: 96
Loss: 0.23795645426066142
ROC train: 0.982951	val: 0.660440	test: 0.754825
PRC train: 0.973919	val: 0.925366	test: 0.764292

Epoch: 97
Loss: 0.22115167104995623
ROC train: 0.980548	val: 0.664835	test: 0.769953
PRC train: 0.970607	val: 0.926002	test: 0.787392

Epoch: 98
Loss: 0.23188535727935572
ROC train: 0.983416	val: 0.668132	test: 0.767171
PRC train: 0.975414	val: 0.928766	test: 0.782561

Epoch: 99
Loss: 0.22473910118741863
ROC train: 0.984546	val: 0.671062	test: 0.765084
PRC train: 0.977073	val: 0.928669	test: 0.779802

Epoch: 100
Loss: 0.22845924893879982
ROC train: 0.978690	val: 0.664103	test: 0.754304
PRC train: 0.967662	val: 0.923534	test: 0.749270

Epoch: 101
Loss: 0.22017828923533161
ROC train: 0.979652	val: 0.673260	test: 0.778995
PRC train: 0.969638	val: 0.926583	test: 0.780184

Epoch: 102
Loss: 0.22641620766173537
ROC train: 0.980345	val: 0.660806	test: 0.768562
PRC train: 0.971013	val: 0.928286	test: 0.779074

Epoch: 103
Loss: 0.23666266116075327
ROC train: 0.979740	val: 0.663370	test: 0.736046
PRC train: 0.969074	val: 0.928716	test: 0.746542

Epoch: 104
Loss: 0.21802666058536513
ROC train: 0.984326	val: 0.665568	test: 0.737785
PRC train: 0.976838	val: 0.926953	test: 0.751979

Epoch: 105
Loss: 0.21907488112969556
ROC train: 0.980171	val: 0.664469	test: 0.735176
PRC train: 0.971648	val: 0.923881	test: 0.752180

Epoch: 106
Loss: 0.21419723755738737
ROC train: 0.982360	val: 0.692308	test: 0.751348
PRC train: 0.973037	val: 0.930146	test: 0.769921

Epoch: 107
Loss: 0.23601438166197716
ROC train: 0.983082	val: 0.665201	test: 0.763346
PRC train: 0.974163	val: 0.928822	test: 0.776192

Epoch: 108
Loss: 0.20954768817980324
ROC train: 0.987063	val: 0.658242	test: 0.758998
PRC train: 0.980490	val: 0.930370	test: 0.769865

Epoch: 109
Loss: 0.23042063120291761
ROC train: 0.984572	val: 0.676190	test: 0.750478
PRC train: 0.976591	val: 0.932266	test: 0.750522

Epoch: 110
Loss: 0.2115183891185281
ROC train: 0.983213	val: 0.684615	test: 0.739350
PRC train: 0.974162	val: 0.933143	test: 0.748423

Epoch: 111
Loss: 0.22537316612411903
ROC train: 0.984506	val: 0.666300	test: 0.754304
PRC train: 0.976771	val: 0.930974	test: 0.769784

Epoch: 112
Loss: 0.20837976141235331
ROC train: 0.984626	val: 0.675458	test: 0.758303
PRC train: 0.977829	val: 0.932541	test: 0.770599

Epoch: 113
Loss: 0.21126898028165622
ROC train: 0.987654	val: 0.664835	test: 0.764041
PRC train: 0.982005	val: 0.926357	test: 0.772626

Epoch: 114
Loss: 0.21126682090899535
ROC train: 0.984723	val: 0.653114	test: 0.762476
PRC train: 0.977077	val: 0.921584	test: 0.767903

Epoch: 115
Loss: 0.21008827040428582
ROC train: 0.987828	val: 0.654579	test: 0.760216
PRC train: 0.982460	val: 0.926128	test: 0.772165

Epoch: 116
Loss: 0.21048668511028817
ROC train: 0.985930	val: 0.654945	test: 0.738828
PRC train: 0.978988	val: 0.925812	test: 0.768333

Epoch: 117
Loss: 0.21703759902213
ROC train: 0.983850	val: 0.661905	test: 0.742132
PRC train: 0.975348	val: 0.926071	test: 0.763820

Epoch: 118
Loss: 0.21283435255477187
ROC train: 0.981244	val: 0.665934	test: 0.723005
PRC train: 0.970883	val: 0.928874	test: 0.719166

Epoch: 119
Loss: 0.22298086527388375
ROC train: 0.987577	val: 0.670330	test: 0.749609
PRC train: 0.981295	val: 0.931423	test: 0.756561

Epoch: 120
Loss: 0.20102236696242853
ROC train: 0.986824	val: 0.665934	test: 0.736046
PRC train: 0.980923	val: 0.927754	test: 0.742348

Early stopping
Best (ROC):	 train: 0.972848	val: 0.698168	test: 0.775343
Best (PRC):	 train: 0.957582	val: 0.934461	test: 0.793883
All runs completed.
ROC train: 0.968950	val: 0.854701	test: 0.756336
PRC train: 0.965546	val: 0.422660	test: 0.870666

Epoch: 95
Loss: 0.28215870391744174
ROC train: 0.967529	val: 0.853924	test: 0.755976
PRC train: 0.964422	val: 0.423977	test: 0.864676

Epoch: 96
Loss: 0.30647025434061476
ROC train: 0.969539	val: 0.857032	test: 0.757676
PRC train: 0.966465	val: 0.415087	test: 0.868209

Epoch: 97
Loss: 0.26888456942717404
ROC train: 0.969719	val: 0.854798	test: 0.753812
PRC train: 0.966926	val: 0.401184	test: 0.869286

Epoch: 98
Loss: 0.27192424807313126
ROC train: 0.969704	val: 0.867716	test: 0.762570
PRC train: 0.966227	val: 0.438516	test: 0.872539

Epoch: 99
Loss: 0.2741492902226405
ROC train: 0.964809	val: 0.859848	test: 0.761745
PRC train: 0.960852	val: 0.444110	test: 0.862276

Epoch: 100
Loss: 0.2695853635416528
ROC train: 0.971032	val: 0.869949	test: 0.761333
PRC train: 0.967685	val: 0.449638	test: 0.869768

Epoch: 101
Loss: 0.2559268826096912
ROC train: 0.971962	val: 0.864413	test: 0.751494
PRC train: 0.968475	val: 0.436027	test: 0.865265

Epoch: 102
Loss: 0.2555649783715538
ROC train: 0.973003	val: 0.852855	test: 0.743200
PRC train: 0.970123	val: 0.419877	test: 0.862313

Epoch: 103
Loss: 0.2806001554429464
ROC train: 0.975753	val: 0.844308	test: 0.740315
PRC train: 0.974184	val: 0.411478	test: 0.844455

Epoch: 104
Loss: 0.2696040807919549
ROC train: 0.964911	val: 0.824301	test: 0.734855
PRC train: 0.962830	val: 0.366331	test: 0.829932

Epoch: 105
Loss: 0.2762449219885137
ROC train: 0.969217	val: 0.842754	test: 0.751803
PRC train: 0.966715	val: 0.407552	test: 0.856836

Epoch: 106
Loss: 0.25605049603536306
ROC train: 0.972118	val: 0.856158	test: 0.762673
PRC train: 0.969650	val: 0.429649	test: 0.873518

Epoch: 107
Loss: 0.25590420741311215
ROC train: 0.973728	val: 0.854507	test: 0.754585
PRC train: 0.972044	val: 0.422752	test: 0.863147

Epoch: 108
Loss: 0.27051924166752833
ROC train: 0.977339	val: 0.858100	test: 0.746961
PRC train: 0.976081	val: 0.430149	test: 0.856147

Epoch: 109
Loss: 0.24781833946054613
ROC train: 0.974186	val: 0.858392	test: 0.744900
PRC train: 0.971819	val: 0.429339	test: 0.854767

Epoch: 110
Loss: 0.267076167527562
ROC train: 0.971378	val: 0.861014	test: 0.749433
PRC train: 0.968690	val: 0.457191	test: 0.861370

Epoch: 111
Loss: 0.26379287168655274
ROC train: 0.964497	val: 0.863831	test: 0.754842
PRC train: 0.959527	val: 0.468842	test: 0.867975

Epoch: 112
Loss: 0.241892854176739
ROC train: 0.976371	val: 0.863442	test: 0.759582
PRC train: 0.973499	val: 0.438000	test: 0.871430

Epoch: 113
Loss: 0.24112990917895283
ROC train: 0.979052	val: 0.853632	test: 0.751288
PRC train: 0.977593	val: 0.420306	test: 0.858426

Epoch: 114
Loss: 0.2502346900784113
ROC train: 0.979373	val: 0.847416	test: 0.750000
PRC train: 0.978141	val: 0.427831	test: 0.855100

Epoch: 115
Loss: 0.26040503324811076
ROC train: 0.978507	val: 0.851593	test: 0.749691
PRC train: 0.978045	val: 0.454511	test: 0.856388

Epoch: 116
Loss: 0.25590560729233297
ROC train: 0.981845	val: 0.862859	test: 0.755203
PRC train: 0.981266	val: 0.459497	test: 0.867753

Epoch: 117
Loss: 0.23870058005701705
ROC train: 0.981183	val: 0.865287	test: 0.746806
PRC train: 0.980477	val: 0.462213	test: 0.863204

Epoch: 118
Loss: 0.23947750990066113
ROC train: 0.980516	val: 0.870241	test: 0.751958
PRC train: 0.979361	val: 0.477880	test: 0.859053

Epoch: 119
Loss: 0.24321128419494425
ROC train: 0.976920	val: 0.876943	test: 0.766227
PRC train: 0.975205	val: 0.499291	test: 0.869276

Epoch: 120
Loss: 0.2588559643848408
ROC train: 0.978015	val: 0.873932	test: 0.760509
PRC train: 0.976481	val: 0.504243	test: 0.876185

Epoch: 121
Loss: 0.23068882507971683
ROC train: 0.980949	val: 0.857809	test: 0.749897
PRC train: 0.979761	val: 0.481024	test: 0.867439

Epoch: 122
Loss: 0.2334688186786163
ROC train: 0.979368	val: 0.854895	test: 0.747991
PRC train: 0.977950	val: 0.476181	test: 0.859361

Epoch: 123
Loss: 0.2345021577891379
ROC train: 0.981645	val: 0.853438	test: 0.746755
PRC train: 0.981047	val: 0.455193	test: 0.857876

Epoch: 124
Loss: 0.23495820679286705
ROC train: 0.980210	val: 0.853827	test: 0.748455
PRC train: 0.978940	val: 0.425229	test: 0.864630

Epoch: 125
Loss: 0.2554118468454251
ROC train: 0.980254	val: 0.861888	test: 0.770194
PRC train: 0.979142	val: 0.439293	test: 0.876360

Epoch: 126
Loss: 0.2429765504941941
ROC train: 0.981134	val: 0.844891	test: 0.764373
PRC train: 0.979443	val: 0.408265	test: 0.872183

Epoch: 127
Loss: 0.2360481868025291
ROC train: 0.965797	val: 0.830905	test: 0.713631
PRC train: 0.963862	val: 0.373233	test: 0.846241

Epoch: 128
Loss: 0.25183183141678817
ROC train: 0.981631	val: 0.865579	test: 0.747167
PRC train: 0.980548	val: 0.469326	test: 0.862276

Epoch: 129
Loss: 0.2294013774927451
ROC train: 0.969110	val: 0.837510	test: 0.758088
PRC train: 0.967659	val: 0.416284	test: 0.856073

Epoch: 130
Loss: 0.23526884844565638
ROC train: 0.939067	val: 0.816531	test: 0.740882
PRC train: 0.936034	val: 0.394462	test: 0.853023

Epoch: 131
Loss: 0.23877486984074803
ROC train: 0.967767	val: 0.841686	test: 0.753039
PRC train: 0.965641	val: 0.439309	test: 0.868528

Epoch: 132
Loss: 0.24035027792736693
ROC train: 0.980599	val: 0.860431	test: 0.749897
PRC train: 0.979836	val: 0.464109	test: 0.870497

Epoch: 133
Loss: 0.23463920430235782
ROC train: 0.981728	val: 0.850622	test: 0.746858
PRC train: 0.981207	val: 0.426028	test: 0.866641

Epoch: 134
Loss: 0.23832733603727382
ROC train: 0.982069	val: 0.855186	test: 0.761179
PRC train: 0.980716	val: 0.428832	test: 0.876033

Epoch: 135
Loss: 0.25398439669949346
ROC train: 0.980195	val: 0.866162	test: 0.758345
PRC train: 0.978694	val: 0.434560	test: 0.866972

Epoch: 136
Loss: 0.23839653860643922
ROC train: 0.977529	val: 0.867813	test: 0.753555
PRC train: 0.975820	val: 0.463952	test: 0.868609

Epoch: 137
Loss: 0.23428980327424345
ROC train: 0.978414	val: 0.875291	test: 0.755203
PRC train: 0.977465	val: 0.469790	test: 0.872650

Epoch: 138
Loss: 0.2274985014773852
ROC train: 0.983198	val: 0.876263	test: 0.750103
PRC train: 0.982543	val: 0.479421	test: 0.870000

Epoch: 139
Loss: 0.2168538357437087
ROC train: 0.986307	val: 0.867230	test: 0.744488
PRC train: 0.985731	val: 0.466714	test: 0.863576

Epoch: 140
Loss: 0.21380368584981643
ROC train: 0.981733	val: 0.846154	test: 0.746755
PRC train: 0.981228	val: 0.434750	test: 0.861740

Epoch: 141
Loss: 0.23057733696002664
ROC train: 0.981485	val: 0.847028	test: 0.747939
PRC train: 0.981063	val: 0.441916	test: 0.862311

Epoch: 142
Loss: 0.22288530297907477
ROC train: 0.984458	val: 0.854798	test: 0.749948
PRC train: 0.984001	val: 0.448928	test: 0.862141

Epoch: 143
Loss: 0.23121491850073625
ROC train: 0.986142	val: 0.862956	test: 0.758448
PRC train: 0.985450	val: 0.457112	test: 0.868037

Epoch: 144
Loss: 0.22034756416866286
ROC train: 0.986404	val: 0.873543	test: 0.753194
PRC train: 0.985998	val: 0.481358	test: 0.865563

Epoch: 145
Loss: 0.22714776185196273
ROC train: 0.986258	val: 0.871503	test: 0.734391
PRC train: 0.986039	val: 0.488746	test: 0.850974

Epoch: 146
Loss: 0.20461360989234076
ROC train: 0.987329	val: 0.869658	test: 0.739749
PRC train: 0.986937	val: 0.488952	test: 0.849445

Epoch: 147
Loss: 0.20851657505293153
ROC train: 0.987115	val: 0.863636	test: 0.756285
PRC train: 0.986318	val: 0.469461	test: 0.863413

Epoch: 148
Loss: 0.24863491106564473
ROC train: 0.986088	val: 0.852953	test: 0.759530
PRC train: 0.984926	val: 0.428221	test: 0.868817

Epoch: 149
Loss: 0.20956264238595176
ROC train: 0.983519	val: 0.853050	test: 0.768339
PRC train: 0.982726	val: 0.421414	test: 0.878265

Epoch: 150
Loss: 0.2053395683698812
ROC train: 0.984434	val: 0.868201	test: 0.773800
PRC train: 0.983871	val: 0.452596	test: 0.886110

Epoch: 151
Loss: 0.18782676640711143
ROC train: 0.986322	val: 0.877720	test: 0.761488
PRC train: 0.985996	val: 0.465513	test: 0.880474

Epoch: 152
Loss: 0.2380479201593695
ROC train: 0.987300	val: 0.874903	test: 0.752730
PRC train: 0.986803	val: 0.464126	test: 0.863003

Epoch: 153
Loss: 0.23930039384718677
ROC train: 0.985290	val: 0.861208	test: 0.735782
PRC train: 0.984248	val: 0.445721	test: 0.844431

Epoch: 154
Loss: 0.19892197827219268
ROC train: 0.985047	val: 0.865287	test: 0.736091
PRC train: 0.983439	val: 0.468260	test: 0.849782
PRC train: 0.970211	val: 0.472818	test: 0.860146

Epoch: 95
Loss: 0.278886577592085
ROC train: 0.970862	val: 0.868395	test: 0.742994
PRC train: 0.968242	val: 0.452450	test: 0.869064

Epoch: 96
Loss: 0.2905118455827851
ROC train: 0.972487	val: 0.864510	test: 0.741655
PRC train: 0.969738	val: 0.446293	test: 0.866868

Epoch: 97
Loss: 0.25797233624246535
ROC train: 0.974205	val: 0.862568	test: 0.735834
PRC train: 0.971834	val: 0.451302	test: 0.862805

Epoch: 98
Loss: 0.2728360406076327
ROC train: 0.975144	val: 0.855769	test: 0.742685
PRC train: 0.972760	val: 0.437166	test: 0.864010

Epoch: 99
Loss: 0.25689374188528835
ROC train: 0.976920	val: 0.860625	test: 0.738667
PRC train: 0.974845	val: 0.444960	test: 0.857533

Epoch: 100
Loss: 0.2526485113628954
ROC train: 0.977047	val: 0.873446	test: 0.732949
PRC train: 0.974155	val: 0.481835	test: 0.854185

Epoch: 101
Loss: 0.2504731593623365
ROC train: 0.977499	val: 0.878982	test: 0.729703
PRC train: 0.974696	val: 0.486579	test: 0.854289

Epoch: 102
Loss: 0.2567880115115622
ROC train: 0.978054	val: 0.870047	test: 0.732897
PRC train: 0.975109	val: 0.475622	test: 0.859870

Epoch: 103
Loss: 0.2535994572906442
ROC train: 0.976551	val: 0.858877	test: 0.739440
PRC train: 0.973570	val: 0.455391	test: 0.862984

Epoch: 104
Loss: 0.2617537805170477
ROC train: 0.976098	val: 0.854992	test: 0.741088
PRC train: 0.973631	val: 0.439858	test: 0.864413

Epoch: 105
Loss: 0.2583464919381737
ROC train: 0.976872	val: 0.851399	test: 0.741140
PRC train: 0.974671	val: 0.433673	test: 0.863031

Epoch: 106
Loss: 0.2648797833245532
ROC train: 0.978151	val: 0.867327	test: 0.744900
PRC train: 0.976183	val: 0.469282	test: 0.865261

Epoch: 107
Loss: 0.2674553799445524
ROC train: 0.977324	val: 0.866647	test: 0.741346
PRC train: 0.975355	val: 0.473165	test: 0.861569

Epoch: 108
Loss: 0.2725817693742066
ROC train: 0.976117	val: 0.855963	test: 0.721152
PRC train: 0.975289	val: 0.449023	test: 0.852205

Epoch: 109
Loss: 0.24724838225731094
ROC train: 0.979417	val: 0.856449	test: 0.715588
PRC train: 0.978491	val: 0.466813	test: 0.844147

Epoch: 110
Loss: 0.23708288834226535
ROC train: 0.979568	val: 0.859557	test: 0.729703
PRC train: 0.977097	val: 0.465734	test: 0.851112

Epoch: 111
Loss: 0.26989797813995525
ROC train: 0.975636	val: 0.835179	test: 0.752833
PRC train: 0.972825	val: 0.412066	test: 0.868411

Epoch: 112
Loss: 0.2550301352114125
ROC train: 0.957335	val: 0.807498	test: 0.754688
PRC train: 0.952478	val: 0.370391	test: 0.866036

Epoch: 113
Loss: 0.2410209574341094
ROC train: 0.955933	val: 0.806138	test: 0.740830
PRC train: 0.951576	val: 0.365083	test: 0.856771

Epoch: 114
Loss: 0.26089038825288985
ROC train: 0.975198	val: 0.845085	test: 0.732485
PRC train: 0.972995	val: 0.421363	test: 0.854817

Epoch: 115
Loss: 0.2308579180339701
ROC train: 0.981329	val: 0.864705	test: 0.722903
PRC train: 0.980176	val: 0.456852	test: 0.844906

Epoch: 116
Loss: 0.2279650163001923
ROC train: 0.973650	val: 0.854798	test: 0.713476
PRC train: 0.972398	val: 0.440121	test: 0.836689

Epoch: 117
Loss: 0.2433880799347476
ROC train: 0.971120	val: 0.862665	test: 0.720379
PRC train: 0.968332	val: 0.465104	test: 0.835029

Epoch: 118
Loss: 0.2480358985852763
ROC train: 0.978078	val: 0.867716	test: 0.732743
PRC train: 0.975095	val: 0.464502	test: 0.845338

Epoch: 119
Loss: 0.21989015151304575
ROC train: 0.980726	val: 0.862665	test: 0.736143
PRC train: 0.978698	val: 0.473798	test: 0.847731

Epoch: 120
Loss: 0.23527165375170814
ROC train: 0.981957	val: 0.861111	test: 0.733155
PRC train: 0.980408	val: 0.481058	test: 0.846773

Epoch: 121
Loss: 0.22477010516658677
ROC train: 0.983494	val: 0.856838	test: 0.732537
PRC train: 0.982144	val: 0.460628	test: 0.851502

Epoch: 122
Loss: 0.23440260114570483
ROC train: 0.979203	val: 0.843046	test: 0.739130
PRC train: 0.977684	val: 0.448452	test: 0.860591

Epoch: 123
Loss: 0.24144897394464881
ROC train: 0.973247	val: 0.836344	test: 0.752267
PRC train: 0.970520	val: 0.436610	test: 0.866134

Epoch: 124
Loss: 0.23745860177619907
ROC train: 0.978278	val: 0.846348	test: 0.743252
PRC train: 0.976768	val: 0.447153	test: 0.862650

Epoch: 125
Loss: 0.2307160910364348
ROC train: 0.981421	val: 0.854215	test: 0.732021
PRC train: 0.980358	val: 0.443168	test: 0.855774

Epoch: 126
Loss: 0.2504497471272301
ROC train: 0.985154	val: 0.860625	test: 0.724500
PRC train: 0.984282	val: 0.497522	test: 0.844654

Epoch: 127
Loss: 0.24419956884875577
ROC train: 0.984215	val: 0.859848	test: 0.725634
PRC train: 0.982666	val: 0.501476	test: 0.845163

Epoch: 128
Loss: 0.24344944173258373
ROC train: 0.984760	val: 0.863248	test: 0.712703
PRC train: 0.983559	val: 0.491391	test: 0.837279

Epoch: 129
Loss: 0.23960482905972552
ROC train: 0.984399	val: 0.858100	test: 0.716206
PRC train: 0.983603	val: 0.482025	test: 0.837244

Epoch: 130
Loss: 0.2259584609334337
ROC train: 0.983942	val: 0.847999	test: 0.734906
PRC train: 0.983204	val: 0.477435	test: 0.851025

Epoch: 131
Loss: 0.22344379178446344
ROC train: 0.982195	val: 0.845377	test: 0.741758
PRC train: 0.981611	val: 0.473022	test: 0.860905

Epoch: 132
Loss: 0.21986076666919568
ROC train: 0.983003	val: 0.861694	test: 0.741243
PRC train: 0.981861	val: 0.472171	test: 0.864604

Epoch: 133
Loss: 0.22322672855008216
ROC train: 0.984482	val: 0.879565	test: 0.738152
PRC train: 0.983520	val: 0.490468	test: 0.860770

Epoch: 134
Loss: 0.2266802271775692
ROC train: 0.984166	val: 0.882867	test: 0.727488
PRC train: 0.983279	val: 0.510231	test: 0.847952

Epoch: 135
Loss: 0.22645817554021283
ROC train: 0.985241	val: 0.867036	test: 0.723264
PRC train: 0.984176	val: 0.486500	test: 0.846446

Epoch: 136
Loss: 0.2251075021530613
ROC train: 0.977879	val: 0.849747	test: 0.697764
PRC train: 0.974351	val: 0.420127	test: 0.824164

Epoch: 137
Loss: 0.23787131983714277
ROC train: 0.979164	val: 0.837218	test: 0.704616
PRC train: 0.976135	val: 0.408890	test: 0.827868

Epoch: 138
Loss: 0.22114526656502048
ROC train: 0.983923	val: 0.837315	test: 0.718422
PRC train: 0.982867	val: 0.408946	test: 0.836946

Epoch: 139
Loss: 0.22733896698747585
ROC train: 0.986862	val: 0.847028	test: 0.725634
PRC train: 0.985991	val: 0.435172	test: 0.846756

Epoch: 140
Loss: 0.21195226801162267
ROC train: 0.987295	val: 0.867424	test: 0.721203
PRC train: 0.986302	val: 0.490193	test: 0.840335

Epoch: 141
Loss: 0.21442972620126832
ROC train: 0.985198	val: 0.870921	test: 0.725222
PRC train: 0.984182	val: 0.493417	test: 0.847261

Epoch: 142
Loss: 0.2355066933103747
ROC train: 0.983392	val: 0.862374	test: 0.738255
PRC train: 0.982291	val: 0.453165	test: 0.862433

Epoch: 143
Loss: 0.1969819133745422
ROC train: 0.985446	val: 0.858294	test: 0.733979
PRC train: 0.984777	val: 0.443676	test: 0.861376

Epoch: 144
Loss: 0.22077214964758116
ROC train: 0.987567	val: 0.861791	test: 0.730218
PRC train: 0.986924	val: 0.464423	test: 0.856838

Epoch: 145
Loss: 0.22024749904851396
ROC train: 0.986219	val: 0.871018	test: 0.733155
PRC train: 0.985338	val: 0.498076	test: 0.849737

Epoch: 146
Loss: 0.20539040638925316
ROC train: 0.986034	val: 0.872086	test: 0.726715
PRC train: 0.985169	val: 0.492218	test: 0.846902

Epoch: 147
Loss: 0.22175135879505015
ROC train: 0.986244	val: 0.868298	test: 0.720740
PRC train: 0.985657	val: 0.486616	test: 0.846720

Epoch: 148
Loss: 0.21946368626751037
ROC train: 0.986774	val: 0.859266	test: 0.734546
PRC train: 0.986229	val: 0.463731	test: 0.857327

Epoch: 149
Loss: 0.2076158734231967
ROC train: 0.984487	val: 0.856546	test: 0.737018
PRC train: 0.983829	val: 0.464425	test: 0.854070

Epoch: 150
Loss: 0.192868402185751
ROC train: 0.987582	val: 0.869367	test: 0.724809
PRC train: 0.986693	val: 0.470810	test: 0.846883

Epoch: 151
Loss: 0.1943195138517861
ROC train: 0.988477	val: 0.872475	test: 0.725788
PRC train: 0.987944	val: 0.455953	test: 0.851738

Epoch: 152
Loss: 0.21329400952378202
ROC train: 0.989548	val: 0.866841	test: 0.731558
PRC train: 0.989157	val: 0.449940	test: 0.856252

Epoch: 153
Loss: 0.20917605827220676
ROC train: 0.990409	val: 0.872086	test: 0.727179
PRC train: 0.989949	val: 0.486987	test: 0.852123

Epoch: 154
Loss: 0.20508131839250948
ROC train: 0.987801	val: 0.868201	test: 0.724346
PRC train: 0.987150	val: 0.488350	test: 0.847797

Epoch: 155
Loss: 0.21004120998220607PRC train: 0.954684	val: 0.460105	test: 0.897261

Epoch: 95
Loss: 0.26994742876355937
ROC train: 0.963810	val: 0.730444	test: 0.803449
PRC train: 0.953229	val: 0.438463	test: 0.900281

Epoch: 96
Loss: 0.3003384753300201
ROC train: 0.964990	val: 0.742706	test: 0.803900
PRC train: 0.954419	val: 0.442789	test: 0.899114

Epoch: 97
Loss: 0.2850497364268369
ROC train: 0.960679	val: 0.749683	test: 0.794782
PRC train: 0.949967	val: 0.436885	test: 0.889855

Epoch: 98
Loss: 0.28525127201824135
ROC train: 0.962147	val: 0.758985	test: 0.797219
PRC train: 0.951197	val: 0.445978	test: 0.885432

Epoch: 99
Loss: 0.2889491413782871
ROC train: 0.966328	val: 0.755285	test: 0.804442
PRC train: 0.955834	val: 0.463230	test: 0.896906

Epoch: 100
Loss: 0.2591933875540592
ROC train: 0.965332	val: 0.741015	test: 0.807602
PRC train: 0.954547	val: 0.433173	test: 0.901842

Epoch: 101
Loss: 0.27643759614407387
ROC train: 0.964716	val: 0.731924	test: 0.811575
PRC train: 0.955111	val: 0.424684	test: 0.904603

Epoch: 102
Loss: 0.304938876702957
ROC train: 0.965821	val: 0.741860	test: 0.819971
PRC train: 0.956779	val: 0.440957	test: 0.906145

Epoch: 103
Loss: 0.31061077165098055
ROC train: 0.965325	val: 0.757400	test: 0.820513
PRC train: 0.956067	val: 0.457687	test: 0.907464

Epoch: 104
Loss: 0.3029205608082354
ROC train: 0.966872	val: 0.775053	test: 0.827284
PRC train: 0.958594	val: 0.475881	test: 0.911345

Epoch: 105
Loss: 0.27123032399213604
ROC train: 0.969704	val: 0.762896	test: 0.828729
PRC train: 0.962394	val: 0.460951	test: 0.913686

Epoch: 106
Loss: 0.2566999682863924
ROC train: 0.967951	val: 0.753066	test: 0.827013
PRC train: 0.960633	val: 0.440289	test: 0.914024

Epoch: 107
Loss: 0.27386814260481906
ROC train: 0.967124	val: 0.750846	test: 0.830986
PRC train: 0.958821	val: 0.444639	test: 0.916265

Epoch: 108
Loss: 0.28335190785296405
ROC train: 0.967325	val: 0.747252	test: 0.834326
PRC train: 0.959335	val: 0.450291	test: 0.919570

Epoch: 109
Loss: 0.2658483180956338
ROC train: 0.967343	val: 0.730127	test: 0.823402
PRC train: 0.959911	val: 0.445078	test: 0.911227

Epoch: 110
Loss: 0.251929707500859
ROC train: 0.961046	val: 0.705285	test: 0.788913
PRC train: 0.952147	val: 0.413090	test: 0.884935

Epoch: 111
Loss: 0.26543570662575683
ROC train: 0.967188	val: 0.715539	test: 0.800379
PRC train: 0.959330	val: 0.421707	test: 0.895835

Epoch: 112
Loss: 0.27777979061893593
ROC train: 0.968059	val: 0.756448	test: 0.822499
PRC train: 0.960306	val: 0.448575	test: 0.907065

Epoch: 113
Loss: 0.25420661370827846
ROC train: 0.951439	val: 0.753488	test: 0.817714
PRC train: 0.939524	val: 0.426412	test: 0.901711

Epoch: 114
Loss: 0.28293395922873554
ROC train: 0.962813	val: 0.760677	test: 0.825298
PRC train: 0.953986	val: 0.427602	test: 0.906266

Epoch: 115
Loss: 0.26456426826019885
ROC train: 0.967048	val: 0.759831	test: 0.833333
PRC train: 0.959493	val: 0.447838	test: 0.914409

Epoch: 116
Loss: 0.2886327878331989
ROC train: 0.971265	val: 0.765433	test: 0.820423
PRC train: 0.964888	val: 0.503934	test: 0.909248

Epoch: 117
Loss: 0.28454566263137965
ROC train: 0.970466	val: 0.767653	test: 0.820513
PRC train: 0.964007	val: 0.516947	test: 0.909650

Epoch: 118
Loss: 0.2762618359489517
ROC train: 0.966156	val: 0.757717	test: 0.811484
PRC train: 0.957067	val: 0.495345	test: 0.883850

Epoch: 119
Loss: 0.30931732460391737
ROC train: 0.966332	val: 0.751374	test: 0.801553
PRC train: 0.959468	val: 0.484228	test: 0.882166

Epoch: 120
Loss: 0.30552360582359717
ROC train: 0.971420	val: 0.758351	test: 0.813741
PRC train: 0.966287	val: 0.507930	test: 0.902871

Epoch: 121
Loss: 0.2763687316314993
ROC train: 0.971499	val: 0.756131	test: 0.817985
PRC train: 0.964149	val: 0.514782	test: 0.905368

Epoch: 122
Loss: 0.2766868043009379
ROC train: 0.969376	val: 0.735624	test: 0.800740
PRC train: 0.961918	val: 0.487034	test: 0.893196

Epoch: 123
Loss: 0.29157075310247377
ROC train: 0.967832	val: 0.743446	test: 0.799747
PRC train: 0.961480	val: 0.488975	test: 0.892069

Epoch: 124
Loss: 0.3031697556155225
ROC train: 0.964044	val: 0.747146	test: 0.798483
PRC train: 0.956599	val: 0.448404	test: 0.885347

Epoch: 125
Loss: 0.28651743009100306
ROC train: 0.969034	val: 0.746829	test: 0.795594
PRC train: 0.961796	val: 0.457797	test: 0.889222

Epoch: 126
Loss: 0.2749607113902182
ROC train: 0.968696	val: 0.755708	test: 0.797671
PRC train: 0.960526	val: 0.449778	test: 0.890312

Epoch: 127
Loss: 0.24346242835046214
ROC train: 0.970581	val: 0.764905	test: 0.800018
PRC train: 0.963443	val: 0.462861	test: 0.886240

Epoch: 128
Loss: 0.3066972637622642
ROC train: 0.967591	val: 0.773996	test: 0.814735
PRC train: 0.956931	val: 0.479792	test: 0.894377

Epoch: 129
Loss: 0.2767510153272378
ROC train: 0.937453	val: 0.748097	test: 0.795143
PRC train: 0.915204	val: 0.443914	test: 0.878651

Epoch: 130
Loss: 0.29740236995301206
ROC train: 0.949525	val: 0.752326	test: 0.773655
PRC train: 0.936489	val: 0.451574	test: 0.864888

Epoch: 131
Loss: 0.2598704733421354
ROC train: 0.969221	val: 0.749683	test: 0.780155
PRC train: 0.961318	val: 0.422135	test: 0.879047

Epoch: 132
Loss: 0.2458420833550774
ROC train: 0.969689	val: 0.752748	test: 0.790899
PRC train: 0.963113	val: 0.450067	test: 0.886836

Epoch: 133
Loss: 0.2988643971913221
ROC train: 0.973424	val: 0.758985	test: 0.804352
PRC train: 0.967935	val: 0.488938	test: 0.897932

Epoch: 134
Loss: 0.27799496661814393
ROC train: 0.967800	val: 0.742072	test: 0.774287
PRC train: 0.959777	val: 0.499934	test: 0.882655

Epoch: 135
Loss: 0.26186751305878386
ROC train: 0.959474	val: 0.715116	test: 0.754875
PRC train: 0.951929	val: 0.458177	test: 0.860363

Epoch: 136
Loss: 0.2451420077194207
ROC train: 0.968052	val: 0.724841	test: 0.791892
PRC train: 0.960995	val: 0.453207	test: 0.887077

Epoch: 137
Loss: 0.2625994708176802
ROC train: 0.972902	val: 0.740381	test: 0.815276
PRC train: 0.965866	val: 0.447098	test: 0.901301

Epoch: 138
Loss: 0.2528527056218758
ROC train: 0.959406	val: 0.737526	test: 0.791983
PRC train: 0.950354	val: 0.420050	test: 0.881099

Epoch: 139
Loss: 0.25136739213431614
ROC train: 0.970614	val: 0.736364	test: 0.792524
PRC train: 0.964058	val: 0.407552	test: 0.881708

Early stopping
Best (ROC):	 train: 0.966872	val: 0.775053	test: 0.827284
Best (PRC):	 train: 0.958594	val: 0.475881	test: 0.911345

ROC train: 0.985154	val: 0.862374	test: 0.726406
PRC train: 0.984070	val: 0.484335	test: 0.851569

Epoch: 156
Loss: 0.19062863268810976
ROC train: 0.987704	val: 0.869755	test: 0.721925
PRC train: 0.986997	val: 0.490825	test: 0.851507

Epoch: 157
Loss: 0.2172962045264977
ROC train: 0.990346	val: 0.878885	test: 0.726252
PRC train: 0.990152	val: 0.495645	test: 0.852575

Epoch: 158
Loss: 0.227652185014203
ROC train: 0.985314	val: 0.861888	test: 0.729291
PRC train: 0.984402	val: 0.448044	test: 0.849603

Epoch: 159
Loss: 0.20807282620964163
ROC train: 0.973543	val: 0.849845	test: 0.692922
PRC train: 0.974125	val: 0.419831	test: 0.828928

Epoch: 160
Loss: 0.20344124516903145
ROC train: 0.975869	val: 0.838578	test: 0.682619
PRC train: 0.975202	val: 0.424840	test: 0.821004

Epoch: 161
Loss: 0.2051658096595379
ROC train: 0.990195	val: 0.859751	test: 0.731764
PRC train: 0.989512	val: 0.466460	test: 0.847978

Epoch: 162
Loss: 0.20653239737302742
ROC train: 0.987241	val: 0.863054	test: 0.744849
PRC train: 0.986666	val: 0.490052	test: 0.859152

Epoch: 163
Loss: 0.1958509514591302
ROC train: 0.986205	val: 0.869270	test: 0.737585
PRC train: 0.985428	val: 0.489822	test: 0.856665

Epoch: 164
Loss: 0.21995248264098058
ROC train: 0.987382	val: 0.872766	test: 0.738203
PRC train: 0.986727	val: 0.490620	test: 0.857361

Epoch: 165
Loss: 0.20216615634122534
ROC train: 0.984988	val: 0.872766	test: 0.741603
PRC train: 0.984004	val: 0.487671	test: 0.857991

Epoch: 166
Loss: 0.19925501180781643
ROC train: 0.985850	val: 0.867618	test: 0.743458
PRC train: 0.984926	val: 0.471510	test: 0.857312

Epoch: 167
Loss: 0.21946917902995022
ROC train: 0.991066	val: 0.862665	test: 0.738924
PRC train: 0.990694	val: 0.471155	test: 0.853834

Epoch: 168
Loss: 0.20129260494510004
ROC train: 0.991514	val: 0.871018	test: 0.739182
PRC train: 0.991551	val: 0.488616	test: 0.851111

Epoch: 169
Loss: 0.19396245718791166
ROC train: 0.990793	val: 0.870532	test: 0.724140
PRC train: 0.990916	val: 0.484155	test: 0.840481

Early stopping
Best (ROC):	 train: 0.984166	val: 0.882867	test: 0.727488
Best (PRC):	 train: 0.983279	val: 0.510231	test: 0.847952

ROC train: 0.960269	val: 0.725053	test: 0.835771
PRC train: 0.950133	val: 0.438040	test: 0.910002

Epoch: 95
Loss: 0.32455749115726445
ROC train: 0.961784	val: 0.725793	test: 0.826562
PRC train: 0.952047	val: 0.438998	test: 0.893617

Epoch: 96
Loss: 0.3359463176870666
ROC train: 0.966127	val: 0.747463	test: 0.819520
PRC train: 0.957806	val: 0.460393	test: 0.895568

Epoch: 97
Loss: 0.29923378838453757
ROC train: 0.959125	val: 0.754863	test: 0.808234
PRC train: 0.950125	val: 0.449539	test: 0.888072

Epoch: 98
Loss: 0.31114217062959904
ROC train: 0.958916	val: 0.758034	test: 0.809137
PRC train: 0.949541	val: 0.460931	test: 0.891401

Epoch: 99
Loss: 0.27392315375527576
ROC train: 0.964321	val: 0.764165	test: 0.823402
PRC train: 0.954984	val: 0.485765	test: 0.900760

Epoch: 100
Loss: 0.30247208963223454
ROC train: 0.964680	val: 0.756025	test: 0.830625
PRC train: 0.954822	val: 0.483509	test: 0.909946

Epoch: 101
Loss: 0.27608729897548084
ROC train: 0.964295	val: 0.740381	test: 0.824937
PRC train: 0.954148	val: 0.448962	test: 0.910378

Epoch: 102
Loss: 0.3313786291734841
ROC train: 0.964943	val: 0.736892	test: 0.824576
PRC train: 0.956303	val: 0.445621	test: 0.907008

Epoch: 103
Loss: 0.28600252672249904
ROC train: 0.955278	val: 0.737844	test: 0.825027
PRC train: 0.942441	val: 0.458665	test: 0.904116

Epoch: 104
Loss: 0.3080599364966722
ROC train: 0.963702	val: 0.747463	test: 0.825569
PRC train: 0.952596	val: 0.484031	test: 0.904905

Epoch: 105
Loss: 0.30010441869841725
ROC train: 0.958020	val: 0.758034	test: 0.812026
PRC train: 0.940507	val: 0.517672	test: 0.898662

Epoch: 106
Loss: 0.3560806473078039
ROC train: 0.962101	val: 0.752008	test: 0.814464
PRC train: 0.948019	val: 0.499194	test: 0.897472

Epoch: 107
Loss: 0.2984049630262731
ROC train: 0.966555	val: 0.742600	test: 0.819068
PRC train: 0.958952	val: 0.475847	test: 0.896506

Epoch: 108
Loss: 0.2716242580984891
ROC train: 0.964832	val: 0.726638	test: 0.818436
PRC train: 0.957842	val: 0.460220	test: 0.893105

Epoch: 109
Loss: 0.2921071245956622
ROC train: 0.965663	val: 0.730550	test: 0.816721
PRC train: 0.958340	val: 0.451968	test: 0.893679

Epoch: 110
Loss: 0.3118520783281166
ROC train: 0.966541	val: 0.745137	test: 0.818797
PRC train: 0.958680	val: 0.456901	test: 0.894661

Epoch: 111
Loss: 0.2619340239050841
ROC train: 0.966559	val: 0.759408	test: 0.824305
PRC train: 0.957976	val: 0.477160	test: 0.900715

Epoch: 112
Loss: 0.29494327164603895
ROC train: 0.967156	val: 0.762685	test: 0.837216
PRC train: 0.957914	val: 0.497772	test: 0.911888

Epoch: 113
Loss: 0.2665803141649727
ROC train: 0.964270	val: 0.764271	test: 0.838028
PRC train: 0.954462	val: 0.501145	test: 0.912301

Epoch: 114
Loss: 0.2671480687195447
ROC train: 0.966350	val: 0.759831	test: 0.835500
PRC train: 0.956722	val: 0.502849	test: 0.911014

Epoch: 115
Loss: 0.2578664076769279
ROC train: 0.969624	val: 0.749154	test: 0.829632
PRC train: 0.961855	val: 0.479418	test: 0.906208

Epoch: 116
Loss: 0.31877899903579354
ROC train: 0.967973	val: 0.765222	test: 0.825388
PRC train: 0.960101	val: 0.487067	test: 0.904970

Epoch: 117
Loss: 0.2614172865962268
ROC train: 0.956142	val: 0.763636	test: 0.809047
PRC train: 0.948021	val: 0.495487	test: 0.896286

Epoch: 118
Loss: 0.3001332414297338
ROC train: 0.956934	val: 0.742600	test: 0.810040
PRC train: 0.948048	val: 0.481573	test: 0.893641

Epoch: 119
Loss: 0.3157745436311518
ROC train: 0.968020	val: 0.733932	test: 0.832792
PRC train: 0.960835	val: 0.460167	test: 0.912056

Epoch: 120
Loss: 0.27915355295591715
ROC train: 0.963162	val: 0.708245	test: 0.825117
PRC train: 0.950170	val: 0.411921	test: 0.902942

Epoch: 121
Loss: 0.28842864516460376
ROC train: 0.967656	val: 0.706237	test: 0.817985
PRC train: 0.958551	val: 0.408812	test: 0.896987

Epoch: 122
Loss: 0.2834374219454078
ROC train: 0.967304	val: 0.729175	test: 0.814103
PRC train: 0.959408	val: 0.436039	test: 0.895959

Epoch: 123
Loss: 0.29598038939155497
ROC train: 0.967757	val: 0.756237	test: 0.827736
PRC train: 0.959769	val: 0.487324	test: 0.904225

Epoch: 124
Loss: 0.285796017619508
ROC train: 0.969617	val: 0.760042	test: 0.830986
PRC train: 0.962145	val: 0.495601	test: 0.906170

Epoch: 125
Loss: 0.29097792728815414
ROC train: 0.971420	val: 0.755814	test: 0.829180
PRC train: 0.963417	val: 0.477690	test: 0.906915

Epoch: 126
Loss: 0.273547938557697
ROC train: 0.971355	val: 0.747252	test: 0.816450
PRC train: 0.964464	val: 0.471914	test: 0.896043

Epoch: 127
Loss: 0.28330892372533006
ROC train: 0.972992	val: 0.746829	test: 0.825569
PRC train: 0.967012	val: 0.454059	test: 0.903233

Epoch: 128
Loss: 0.28093064862276435
ROC train: 0.970909	val: 0.760571	test: 0.834056
PRC train: 0.963701	val: 0.461615	test: 0.910101

Epoch: 129
Loss: 0.2419789546358587
ROC train: 0.970326	val: 0.764271	test: 0.844258
PRC train: 0.963603	val: 0.466771	test: 0.912892

Epoch: 130
Loss: 0.2959721845596953
ROC train: 0.970492	val: 0.754228	test: 0.838570
PRC train: 0.963042	val: 0.459836	test: 0.906811

Epoch: 131
Loss: 0.2847774748665956
ROC train: 0.967264	val: 0.743763	test: 0.823312
PRC train: 0.957861	val: 0.435247	test: 0.892372

Epoch: 132
Loss: 0.2721268594503412
ROC train: 0.969635	val: 0.752960	test: 0.816450
PRC train: 0.962020	val: 0.440459	test: 0.894185

Epoch: 133
Loss: 0.3205880030008029
ROC train: 0.968930	val: 0.762051	test: 0.809859
PRC train: 0.962013	val: 0.465876	test: 0.892534

Epoch: 134
Loss: 0.2783941680607587
ROC train: 0.974928	val: 0.759619	test: 0.804623
PRC train: 0.970040	val: 0.487285	test: 0.887398

Epoch: 135
Loss: 0.299446817399031
ROC train: 0.973453	val: 0.752748	test: 0.809047
PRC train: 0.966947	val: 0.501221	test: 0.891960

Epoch: 136
Loss: 0.3035880222705153
ROC train: 0.967253	val: 0.727167	test: 0.808415
PRC train: 0.959968	val: 0.454485	test: 0.895776

Epoch: 137
Loss: 0.3115049214146455
ROC train: 0.962737	val: 0.694397	test: 0.795775
PRC train: 0.952909	val: 0.421294	test: 0.888518

Epoch: 138
Loss: 0.25499142020631715
ROC train: 0.962676	val: 0.714271	test: 0.811575
PRC train: 0.952249	val: 0.437651	test: 0.895465

Epoch: 139
Loss: 0.28784664556768014
ROC train: 0.966555	val: 0.737104	test: 0.821957
PRC train: 0.958220	val: 0.450505	test: 0.900569

Epoch: 140
Loss: 0.269274099863416
ROC train: 0.972981	val: 0.742495	test: 0.820061
PRC train: 0.967002	val: 0.464713	test: 0.902220

Epoch: 141
Loss: 0.24676362621126563
ROC train: 0.974705	val: 0.746406	test: 0.816089
PRC train: 0.968731	val: 0.457251	test: 0.898997

Epoch: 142
Loss: 0.2617261842647583
ROC train: 0.975025	val: 0.748203	test: 0.820964
PRC train: 0.969214	val: 0.462167	test: 0.898066

Epoch: 143
Loss: 0.25166939734567595
ROC train: 0.976169	val: 0.738372	test: 0.825117
PRC train: 0.971331	val: 0.450839	test: 0.896702

Epoch: 144
Loss: 0.2734968543991602
ROC train: 0.975817	val: 0.740381	test: 0.823853
PRC train: 0.970829	val: 0.438024	test: 0.892818

Epoch: 145
Loss: 0.25722675640508713
ROC train: 0.977979	val: 0.750423	test: 0.838931
PRC train: 0.973933	val: 0.453565	test: 0.909316

Epoch: 146
Loss: 0.23262260907701876
ROC train: 0.976533	val: 0.748309	test: 0.837667
PRC train: 0.971996	val: 0.458601	test: 0.913668

Epoch: 147
Loss: 0.26004207963807946
ROC train: 0.977368	val: 0.751480	test: 0.835049
PRC train: 0.973436	val: 0.459775	test: 0.912688

Epoch: 148
Loss: 0.24972505716795862
ROC train: 0.974575	val: 0.756977	test: 0.834236
PRC train: 0.969268	val: 0.472283	test: 0.909898

Epoch: 149
Loss: 0.2597514729157021
ROC train: 0.977368	val: 0.759514	test: 0.834236
PRC train: 0.972439	val: 0.471746	test: 0.909277

Epoch: 150
Loss: 0.2439519693452424
ROC train: 0.976684	val: 0.735095	test: 0.818617
PRC train: 0.971252	val: 0.430152	test: 0.891078

Epoch: 151
Loss: 0.2582670470745062
ROC train: 0.977220	val: 0.726956	test: 0.815096
PRC train: 0.972462	val: 0.433120	test: 0.888484

Early stopping
Best (ROC):	 train: 0.967973	val: 0.765222	test: 0.825388
Best (PRC):	 train: 0.960101	val: 0.487067	test: 0.904970
All runs completed.


Epoch: 155
Loss: 0.22282329651424676
ROC train: 0.987879	val: 0.868298	test: 0.752730
PRC train: 0.986916	val: 0.460569	test: 0.864359

Epoch: 156
Loss: 0.23054769300115016
ROC train: 0.984677	val: 0.871115	test: 0.753451
PRC train: 0.983640	val: 0.467310	test: 0.864568

Epoch: 157
Loss: 0.22040907900527906
ROC train: 0.988171	val: 0.872766	test: 0.746239
PRC train: 0.987541	val: 0.463913	test: 0.863266

Epoch: 158
Loss: 0.22607574771684683
ROC train: 0.988117	val: 0.855284	test: 0.708737
PRC train: 0.987704	val: 0.449762	test: 0.828479

Epoch: 159
Loss: 0.22850634614317616
ROC train: 0.988570	val: 0.853147	test: 0.713631
PRC train: 0.988342	val: 0.454604	test: 0.831092

Epoch: 160
Loss: 0.18474371577138715
ROC train: 0.987402	val: 0.856935	test: 0.735061
PRC train: 0.987301	val: 0.445588	test: 0.853128

Epoch: 161
Loss: 0.21327455989963037
ROC train: 0.987704	val: 0.850719	test: 0.737791
PRC train: 0.987347	val: 0.434425	test: 0.858681

Epoch: 162
Loss: 0.22311625514561745
ROC train: 0.986336	val: 0.846737	test: 0.735267
PRC train: 0.985685	val: 0.402576	test: 0.856195

Epoch: 163
Loss: 0.21413295035737157
ROC train: 0.987256	val: 0.863831	test: 0.747321
PRC train: 0.986835	val: 0.449047	test: 0.865519

Epoch: 164
Loss: 0.19796075751860323
ROC train: 0.988808	val: 0.856935	test: 0.750309
PRC train: 0.988426	val: 0.443872	test: 0.869943

Epoch: 165
Loss: 0.2203761346224717
ROC train: 0.989742	val: 0.859654	test: 0.744230
PRC train: 0.989304	val: 0.449543	test: 0.871187

Epoch: 166
Loss: 0.1886397967355177
ROC train: 0.988798	val: 0.866064	test: 0.742273
PRC train: 0.988258	val: 0.442675	test: 0.869421

Epoch: 167
Loss: 0.1975676344764607
ROC train: 0.988609	val: 0.859751	test: 0.739079
PRC train: 0.987911	val: 0.446785	test: 0.861467

Epoch: 168
Loss: 0.21215888718933126
ROC train: 0.986828	val: 0.866259	test: 0.747115
PRC train: 0.986043	val: 0.455614	test: 0.865340

Epoch: 169
Loss: 0.19050016411693638
ROC train: 0.985918	val: 0.871309	test: 0.767103
PRC train: 0.984978	val: 0.457801	test: 0.879157

Epoch: 170
Loss: 0.19949180989578041
ROC train: 0.986502	val: 0.870629	test: 0.760560
PRC train: 0.985574	val: 0.450422	test: 0.873513

Epoch: 171
Loss: 0.19467258832952403
ROC train: 0.991368	val: 0.864899	test: 0.745776
PRC train: 0.990946	val: 0.444922	test: 0.859535

Epoch: 172
Loss: 0.2092830361442513
ROC train: 0.990025	val: 0.862374	test: 0.749330
PRC train: 0.989352	val: 0.439121	test: 0.847911

Epoch: 173
Loss: 0.2048443978133206
ROC train: 0.987086	val: 0.856935	test: 0.719916
PRC train: 0.986703	val: 0.424403	test: 0.835450

Epoch: 174
Loss: 0.1942174043550638
ROC train: 0.990536	val: 0.866356	test: 0.733412
PRC train: 0.990266	val: 0.444508	test: 0.855125

Epoch: 175
Loss: 0.198097774587881
ROC train: 0.990180	val: 0.871601	test: 0.750155
PRC train: 0.989958	val: 0.462350	test: 0.868161

Epoch: 176
Loss: 0.19841128165285754
ROC train: 0.989314	val: 0.852661	test: 0.741397
PRC train: 0.989271	val: 0.450123	test: 0.858321

Epoch: 177
Loss: 0.20043483031969264
ROC train: 0.985256	val: 0.836344	test: 0.735215
PRC train: 0.984794	val: 0.432899	test: 0.855462

Epoch: 178
Loss: 0.2000840182126899
ROC train: 0.987660	val: 0.852370	test: 0.752061
PRC train: 0.987162	val: 0.445464	test: 0.871741

Epoch: 179
Loss: 0.21289345412317393
ROC train: 0.988409	val: 0.860334	test: 0.758551
PRC train: 0.987972	val: 0.462632	test: 0.874116

Epoch: 180
Loss: 0.19277883424946993
ROC train: 0.991012	val: 0.848873	test: 0.746291
PRC train: 0.990617	val: 0.428121	test: 0.863844

Epoch: 181
Loss: 0.20684490635726496
ROC train: 0.991441	val: 0.845960	test: 0.733155
PRC train: 0.991010	val: 0.428858	test: 0.850278

Epoch: 182
Loss: 0.1884552207313717
ROC train: 0.992866	val: 0.855478	test: 0.736091
PRC train: 0.992572	val: 0.454542	test: 0.850704

Epoch: 183
Loss: 0.2048067065520774
ROC train: 0.991869	val: 0.858003	test: 0.740058
PRC train: 0.991576	val: 0.473971	test: 0.851052

Epoch: 184
Loss: 0.20574337829642364
ROC train: 0.989650	val: 0.864219	test: 0.749330
PRC train: 0.989169	val: 0.469469	test: 0.860670

Epoch: 185
Loss: 0.20541780899009998
ROC train: 0.988492	val: 0.866744	test: 0.741294
PRC train: 0.987900	val: 0.466200	test: 0.863119

Epoch: 186
Loss: 0.19190126785251538
ROC train: 0.988750	val: 0.860528	test: 0.726715
PRC train: 0.988171	val: 0.460782	test: 0.846940

Early stopping
Best (ROC):	 train: 0.986322	val: 0.877720	test: 0.761488
Best (PRC):	 train: 0.985996	val: 0.465513	test: 0.880474
All runs completed.
