>>> Starting run for dataset: bbbp
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running RANDOM configs_static_noise_experiments/GraphCL/bbbp/noise=0.0.yml on cuda:0
Running RANDOM configs_static_noise_experiments/GraphCL/bbbp/noise=0.05.yml on cuda:1
Running RANDOM configs_static_noise_experiments/GraphCL/bbbp/noise=0.1.yml on cuda:2
Running RANDOM configs_static_noise_experiments/GraphCL/bbbp/noise=0.2.yml on cuda:3
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.05.yml --runseed 1 --device cuda:1
Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.05.yml --runseed 2 --device cuda:1
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.2.yml --runseed 1 --device cuda:3
Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.05.yml --runseed 3 --device cuda:1
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.0.yml --runseed 1 --device cuda:0Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.2.yml --runseed 2 --device cuda:3

Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.2.yml --runseed 3 --device cuda:3
Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.0.yml --runseed 2 --device cuda:0
Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.0.yml --runseed 3 --device cuda:0
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.1.yml --runseed 1 --device cuda:2
Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.1.yml --runseed 2 --device cuda:2
Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.1.yml --runseed 3 --device cuda:2
[14:43:32] WARNING: not removing hydrogen atom without neighbors
[14:43:32] WARNING: not removing hydrogen atom without neighbors
[14:43:32] WARNING: not removing hydrogen atom without neighbors
[14:43:32] WARNING: not removing hydrogen atom without neighbors
[14:43:32] WARNING: not removing hydrogen atom without neighbors
[14:43:32] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:33] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:34] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
[14:43:35] WARNING: not removing hydrogen atom without neighbors
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.0.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:0
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/bbbp/noise=0.0
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/bbbp/noise=0.0/bbbp_scaff_2_20-05_14-43-32  ]
[ Using Seed :  2  ]
[ Using device :  cuda:0  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.638995471668793
ROC train: 0.801334	val: 0.861588	test: 0.601273
PRC train: 0.947294	val: 0.748820	test: 0.645042

Epoch: 2
Loss: 0.49741356449216606
ROC train: 0.831946	val: 0.882365	test: 0.623167
PRC train: 0.957278	val: 0.780823	test: 0.670029

Epoch: 3
Loss: 0.4197411875372605
ROC train: 0.857388	val: 0.884372	test: 0.645448
PRC train: 0.964207	val: 0.734885	test: 0.689110

Epoch: 4
Loss: 0.36934517841727393
ROC train: 0.867894	val: 0.892402	test: 0.640529
PRC train: 0.967319	val: 0.750918	test: 0.672599

Epoch: 5
Loss: 0.3353862496786597
ROC train: 0.886120	val: 0.897019	test: 0.639275
PRC train: 0.971158	val: 0.764706	test: 0.669949

Epoch: 6
Loss: 0.3015411847335588
ROC train: 0.919509	val: 0.898826	test: 0.649209
PRC train: 0.980588	val: 0.766287	test: 0.679601

Epoch: 7
Loss: 0.2904520206269509
ROC train: 0.930064	val: 0.897420	test: 0.655093
PRC train: 0.983638	val: 0.769606	test: 0.686450

Epoch: 8
Loss: 0.2847744003826983
ROC train: 0.932751	val: 0.895212	test: 0.658758
PRC train: 0.984300	val: 0.772240	test: 0.692666

Epoch: 9
Loss: 0.25387578285729784
ROC train: 0.935322	val: 0.897521	test: 0.676794
PRC train: 0.984382	val: 0.763249	test: 0.732710

Epoch: 10
Loss: 0.2483286784117625
ROC train: 0.945597	val: 0.894008	test: 0.673997
PRC train: 0.986851	val: 0.751936	test: 0.737782

Epoch: 11
Loss: 0.22258248252734508
ROC train: 0.946998	val: 0.880157	test: 0.652199
PRC train: 0.987623	val: 0.768796	test: 0.717026

Epoch: 12
Loss: 0.2346973509184877
ROC train: 0.949710	val: 0.900331	test: 0.674093
PRC train: 0.988076	val: 0.812826	test: 0.727857

Epoch: 13
Loss: 0.2149480479339898
ROC train: 0.953369	val: 0.897119	test: 0.679495
PRC train: 0.989072	val: 0.801576	test: 0.723745

Epoch: 14
Loss: 0.2280451715045634
ROC train: 0.961477	val: 0.886380	test: 0.685475
PRC train: 0.991259	val: 0.777675	test: 0.716738

Epoch: 15
Loss: 0.21667871904694969
ROC train: 0.962292	val: 0.880658	test: 0.706597
PRC train: 0.991426	val: 0.755267	test: 0.722189

Epoch: 16
Loss: 0.20392524638048745
ROC train: 0.965042	val: 0.882766	test: 0.686632
PRC train: 0.992026	val: 0.802490	test: 0.715322

Epoch: 17
Loss: 0.20054092251925054
ROC train: 0.961227	val: 0.894911	test: 0.680941
PRC train: 0.990704	val: 0.806329	test: 0.675232

Epoch: 18
Loss: 0.2018526788983204
ROC train: 0.967489	val: 0.887684	test: 0.702353
PRC train: 0.992635	val: 0.804604	test: 0.727934

Epoch: 19
Loss: 0.21373667653088763
ROC train: 0.970586	val: 0.881060	test: 0.708333
PRC train: 0.993446	val: 0.772597	test: 0.722850

Epoch: 20
Loss: 0.18906883630948326
ROC train: 0.970709	val: 0.880357	test: 0.698495
PRC train: 0.993237	val: 0.804753	test: 0.696503

Epoch: 21
Loss: 0.18613604987680257
ROC train: 0.971914	val: 0.896818	test: 0.697531
PRC train: 0.993540	val: 0.821589	test: 0.703033

Epoch: 22
Loss: 0.18205335601181646
ROC train: 0.974844	val: 0.887986	test: 0.711130
PRC train: 0.993769	val: 0.803323	test: 0.723842

Epoch: 23
Loss: 0.17860001605802664
ROC train: 0.975034	val: 0.889792	test: 0.702836
PRC train: 0.993146	val: 0.816587	test: 0.714111

Epoch: 24
Loss: 0.19434789604238015
ROC train: 0.971235	val: 0.889190	test: 0.689815
PRC train: 0.993271	val: 0.818223	test: 0.691532

Epoch: 25
Loss: 0.18460573260790042
ROC train: 0.976537	val: 0.894209	test: 0.691262
PRC train: 0.994019	val: 0.848913	test: 0.733760

Epoch: 26
Loss: 0.1832067822263281
ROC train: 0.974815	val: 0.897521	test: 0.710359
PRC train: 0.993306	val: 0.845971	test: 0.757490

Epoch: 27
Loss: 0.17142405725750456
ROC train: 0.978371	val: 0.894510	test: 0.705054
PRC train: 0.994291	val: 0.824834	test: 0.735970

Epoch: 28
Loss: 0.1783975764936378
ROC train: 0.977542	val: 0.890595	test: 0.697627
PRC train: 0.994546	val: 0.826584	test: 0.735716

Epoch: 29
Loss: 0.17543776163008376
ROC train: 0.978261	val: 0.885978	test: 0.684028
PRC train: 0.995252	val: 0.809555	test: 0.677333

Epoch: 30
Loss: 0.16391592309391118
ROC train: 0.980017	val: 0.891599	test: 0.687693
PRC train: 0.995342	val: 0.826729	test: 0.713796

Epoch: 31
Loss: 0.15793286125657832
ROC train: 0.979971	val: 0.887484	test: 0.682581
PRC train: 0.995620	val: 0.818975	test: 0.699292

Epoch: 32
Loss: 0.15213786223512488
ROC train: 0.983200	val: 0.892101	test: 0.687693
PRC train: 0.996487	val: 0.812010	test: 0.694807

Epoch: 33
Loss: 0.15978574188746403
ROC train: 0.982527	val: 0.891097	test: 0.696566Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.0.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:0
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/bbbp/noise=0.0
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/bbbp/noise=0.0/bbbp_scaff_3_20-05_14-43-32  ]
[ Using Seed :  3  ]
[ Using device :  cuda:0  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6245412798730304
ROC train: 0.800318	val: 0.887183	test: 0.628086
PRC train: 0.949343	val: 0.810176	test: 0.686802

Epoch: 2
Loss: 0.5127842404319816
ROC train: 0.833603	val: 0.886380	test: 0.622878
PRC train: 0.955579	val: 0.817555	test: 0.663108

Epoch: 3
Loss: 0.4168656206099492
ROC train: 0.841080	val: 0.904547	test: 0.618056
PRC train: 0.958035	val: 0.824983	test: 0.655520

Epoch: 4
Loss: 0.3520150184238306
ROC train: 0.852960	val: 0.903744	test: 0.611497
PRC train: 0.963322	val: 0.805935	test: 0.663963

Epoch: 5
Loss: 0.3219363930148979
ROC train: 0.882281	val: 0.910770	test: 0.630691
PRC train: 0.970409	val: 0.825886	test: 0.681805

Epoch: 6
Loss: 0.30767198904825005
ROC train: 0.894882	val: 0.904145	test: 0.649402
PRC train: 0.973796	val: 0.812382	test: 0.710844

Epoch: 7
Loss: 0.31537512817240115
ROC train: 0.915312	val: 0.909064	test: 0.657504
PRC train: 0.978985	val: 0.823687	test: 0.718919

Epoch: 8
Loss: 0.2709800315577972
ROC train: 0.926755	val: 0.892000	test: 0.669271
PRC train: 0.981676	val: 0.760621	test: 0.741506

Epoch: 9
Loss: 0.27134967408454147
ROC train: 0.927996	val: 0.905450	test: 0.685957
PRC train: 0.982865	val: 0.810132	test: 0.749489

Epoch: 10
Loss: 0.2579560207730952
ROC train: 0.938331	val: 0.903443	test: 0.683931
PRC train: 0.985175	val: 0.811981	test: 0.754631

Epoch: 11
Loss: 0.2533403876570985
ROC train: 0.946704	val: 0.903643	test: 0.692033
PRC train: 0.987266	val: 0.826442	test: 0.765242

Epoch: 12
Loss: 0.232795419856396
ROC train: 0.948813	val: 0.887986	test: 0.710552
PRC train: 0.987772	val: 0.785851	test: 0.773404

Epoch: 13
Loss: 0.22281555713889517
ROC train: 0.954104	val: 0.863997	test: 0.705729
PRC train: 0.988937	val: 0.774285	test: 0.770051

Epoch: 14
Loss: 0.21561536027528933
ROC train: 0.952961	val: 0.873432	test: 0.702064
PRC train: 0.988809	val: 0.794413	test: 0.761481

Epoch: 15
Loss: 0.21279949001369575
ROC train: 0.957570	val: 0.886781	test: 0.707465
PRC train: 0.989750	val: 0.804184	test: 0.770070

Epoch: 16
Loss: 0.2177975931565356
ROC train: 0.960857	val: 0.896919	test: 0.711516
PRC train: 0.990650	val: 0.819679	test: 0.760014

Epoch: 17
Loss: 0.20402525234503374
ROC train: 0.962952	val: 0.893907	test: 0.720775
PRC train: 0.991278	val: 0.811205	test: 0.777861

Epoch: 18
Loss: 0.1956998618336971
ROC train: 0.960028	val: 0.894510	test: 0.724151
PRC train: 0.990810	val: 0.816210	test: 0.788833

Epoch: 19
Loss: 0.19356117175562434
ROC train: 0.962115	val: 0.872729	test: 0.708237
PRC train: 0.991549	val: 0.827205	test: 0.775243

Epoch: 20
Loss: 0.19748143794749534
ROC train: 0.968581	val: 0.893004	test: 0.706501
PRC train: 0.992991	val: 0.852135	test: 0.759691

Epoch: 21
Loss: 0.19322537549850546
ROC train: 0.963867	val: 0.896417	test: 0.705633
PRC train: 0.992024	val: 0.852784	test: 0.757444

Epoch: 22
Loss: 0.18015338105376402
ROC train: 0.973721	val: 0.897822	test: 0.722319
PRC train: 0.994322	val: 0.857354	test: 0.778587

Epoch: 23
Loss: 0.18557011384150873
ROC train: 0.972425	val: 0.882565	test: 0.719039
PRC train: 0.994032	val: 0.834833	test: 0.775178

Epoch: 24
Loss: 0.18138708561737513
ROC train: 0.973879	val: 0.882465	test: 0.708816
PRC train: 0.994245	val: 0.813289	test: 0.750757

Epoch: 25
Loss: 0.17020868869478936
ROC train: 0.977574	val: 0.889391	test: 0.719232
PRC train: 0.995051	val: 0.833981	test: 0.772812

Epoch: 26
Loss: 0.17096427232174974
ROC train: 0.975913	val: 0.873331	test: 0.723187
PRC train: 0.994770	val: 0.808111	test: 0.784554

Epoch: 27
Loss: 0.17513958026364443
ROC train: 0.977264	val: 0.872328	test: 0.723958
PRC train: 0.995226	val: 0.759119	test: 0.776961

Epoch: 28
Loss: 0.17213767802855734
ROC train: 0.977610	val: 0.879253	test: 0.715856
PRC train: 0.995362	val: 0.811292	test: 0.767842

Epoch: 29
Loss: 0.16819088009641295
ROC train: 0.978288	val: 0.890696	test: 0.703125
PRC train: 0.995437	val: 0.824788	test: 0.760703

Epoch: 30
Loss: 0.1546382435170605
ROC train: 0.980848	val: 0.881662	test: 0.707948
PRC train: 0.995973	val: 0.810726	test: 0.753521

Epoch: 31
Loss: 0.1442287447746535
ROC train: 0.981133	val: 0.891398	test: 0.696663
PRC train: 0.996005	val: 0.825338	test: 0.728555

Epoch: 32
Loss: 0.14875591992768103
ROC train: 0.983439	val: 0.877547	test: 0.713445
PRC train: 0.996559	val: 0.797909	test: 0.749450

Epoch: 33
Loss: 0.15894138612534253
ROC train: 0.983517	val: 0.885476	test: 0.706790Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.0.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:0
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/bbbp/noise=0.0
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/bbbp/noise=0.0/bbbp_scaff_1_20-05_14-43-32  ]
[ Using Seed :  1  ]
[ Using device :  cuda:0  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6228255050974367
ROC train: 0.794290	val: 0.880458	test: 0.630594
PRC train: 0.940008	val: 0.808107	test: 0.667388

Epoch: 2
Loss: 0.5036679828171925
ROC train: 0.835310	val: 0.907458	test: 0.635224
PRC train: 0.955967	val: 0.867596	test: 0.689140

Epoch: 3
Loss: 0.41059317265516737
ROC train: 0.871460	val: 0.917997	test: 0.670814
PRC train: 0.966772	val: 0.858361	test: 0.725010

Epoch: 4
Loss: 0.3613435961365911
ROC train: 0.885450	val: 0.919101	test: 0.688465
PRC train: 0.969860	val: 0.812304	test: 0.747713

Epoch: 5
Loss: 0.3319592470743868
ROC train: 0.908507	val: 0.917294	test: 0.678434
PRC train: 0.976419	val: 0.826001	test: 0.726332

Epoch: 6
Loss: 0.3003154212671424
ROC train: 0.915731	val: 0.912476	test: 0.660590
PRC train: 0.977868	val: 0.843730	test: 0.694019

Epoch: 7
Loss: 0.27221647592324844
ROC train: 0.909537	val: 0.917997	test: 0.659240
PRC train: 0.976307	val: 0.836833	test: 0.680047

Epoch: 8
Loss: 0.2583098796536118
ROC train: 0.933070	val: 0.915086	test: 0.674383
PRC train: 0.983438	val: 0.836316	test: 0.700054

Epoch: 9
Loss: 0.25649169569857533
ROC train: 0.935256	val: 0.916893	test: 0.682485
PRC train: 0.983516	val: 0.845525	test: 0.720086

Epoch: 10
Loss: 0.22385348312125436
ROC train: 0.936255	val: 0.914684	test: 0.692130
PRC train: 0.983930	val: 0.856487	test: 0.730808

Epoch: 11
Loss: 0.22810876406947284
ROC train: 0.947791	val: 0.916190	test: 0.684992
PRC train: 0.986725	val: 0.864842	test: 0.723587

Epoch: 12
Loss: 0.2565995886854126
ROC train: 0.953682	val: 0.914484	test: 0.697531
PRC train: 0.988520	val: 0.851401	test: 0.735979

Epoch: 13
Loss: 0.2197513867507949
ROC train: 0.958108	val: 0.907759	test: 0.703511
PRC train: 0.989884	val: 0.849353	test: 0.743681

Epoch: 14
Loss: 0.2128374294238377
ROC train: 0.955998	val: 0.911472	test: 0.695988
PRC train: 0.989482	val: 0.864532	test: 0.726539

Epoch: 15
Loss: 0.20573146774541826
ROC train: 0.959750	val: 0.900432	test: 0.690586
PRC train: 0.990660	val: 0.841851	test: 0.728305

Epoch: 16
Loss: 0.19824770016046145
ROC train: 0.963849	val: 0.905952	test: 0.698495
PRC train: 0.991240	val: 0.853191	test: 0.744617

Epoch: 17
Loss: 0.19679093403108985
ROC train: 0.966013	val: 0.914182	test: 0.693191
PRC train: 0.991628	val: 0.859646	test: 0.738987

Epoch: 18
Loss: 0.190072721997592
ROC train: 0.965797	val: 0.907257	test: 0.712577
PRC train: 0.991765	val: 0.839381	test: 0.763368

Epoch: 19
Loss: 0.18737194670447602
ROC train: 0.968284	val: 0.895313	test: 0.725598
PRC train: 0.992498	val: 0.808774	test: 0.761706

Epoch: 20
Loss: 0.20254246343939422
ROC train: 0.973328	val: 0.904446	test: 0.731578
PRC train: 0.993641	val: 0.820432	test: 0.769459

Epoch: 21
Loss: 0.1935213180515111
ROC train: 0.971535	val: 0.899629	test: 0.720775
PRC train: 0.993484	val: 0.800162	test: 0.741549

Epoch: 22
Loss: 0.1726347691451258
ROC train: 0.973235	val: 0.886982	test: 0.717496
PRC train: 0.993993	val: 0.784207	test: 0.748564

Epoch: 23
Loss: 0.16438342675667988
ROC train: 0.974954	val: 0.901837	test: 0.713156
PRC train: 0.994300	val: 0.811303	test: 0.734741

Epoch: 24
Loss: 0.1586257829955824
ROC train: 0.975978	val: 0.905952	test: 0.714217
PRC train: 0.994333	val: 0.824665	test: 0.749650

Epoch: 25
Loss: 0.16684300420670836
ROC train: 0.973789	val: 0.895513	test: 0.698592
PRC train: 0.993888	val: 0.803812	test: 0.720479

Epoch: 26
Loss: 0.1623601387528327
ROC train: 0.976644	val: 0.905551	test: 0.695795
PRC train: 0.994604	val: 0.826437	test: 0.719285

Epoch: 27
Loss: 0.15826491189610967
ROC train: 0.979567	val: 0.912878	test: 0.711516
PRC train: 0.995368	val: 0.841716	test: 0.734892

Epoch: 28
Loss: 0.16623695300816568
ROC train: 0.979233	val: 0.904246	test: 0.708816
PRC train: 0.995292	val: 0.828785	test: 0.718527

Epoch: 29
Loss: 0.16418413027728174
ROC train: 0.978765	val: 0.909465	test: 0.699556
PRC train: 0.995334	val: 0.841454	test: 0.710019

Epoch: 30
Loss: 0.16118949432725752
ROC train: 0.981574	val: 0.906956	test: 0.702160
PRC train: 0.995870	val: 0.835622	test: 0.715083

Epoch: 31
Loss: 0.1606035857298921
ROC train: 0.982553	val: 0.904647	test: 0.708816
PRC train: 0.996144	val: 0.838384	test: 0.728215

Epoch: 32
Loss: 0.14842961707484817
ROC train: 0.981740	val: 0.899829	test: 0.682195
PRC train: 0.996052	val: 0.810895	test: 0.677225

Epoch: 33
Loss: 0.15865066602875302
ROC train: 0.981832	val: 0.892201	test: 0.692708Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.1.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:2
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.1
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/bbbp/noise=0.1
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/bbbp/noise=0.1/bbbp_scaff_3_20-05_14-43-32  ]
[ Using Seed :  3  ]
[ Using device :  cuda:2  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6135629000335492
ROC train: 0.716035	val: 0.873131	test: 0.616512
PRC train: 0.917503	val: 0.819220	test: 0.672900

Epoch: 2
Loss: 0.5147886592529828
ROC train: 0.775989	val: 0.888889	test: 0.617188
PRC train: 0.938494	val: 0.838340	test: 0.665947

Epoch: 3
Loss: 0.45860499618693196
ROC train: 0.809569	val: 0.889090	test: 0.624518
PRC train: 0.946737	val: 0.835922	test: 0.664522

Epoch: 4
Loss: 0.3849675784035823
ROC train: 0.845666	val: 0.894510	test: 0.642168
PRC train: 0.960761	val: 0.831048	test: 0.658164

Epoch: 5
Loss: 0.36795516466834555
ROC train: 0.871786	val: 0.909465	test: 0.632523
PRC train: 0.967916	val: 0.837865	test: 0.642181

Epoch: 6
Loss: 0.34063942671387953
ROC train: 0.882416	val: 0.916391	test: 0.628183
PRC train: 0.969540	val: 0.847952	test: 0.638389

Epoch: 7
Loss: 0.3124200537911773
ROC train: 0.903409	val: 0.912878	test: 0.639178
PRC train: 0.975583	val: 0.839355	test: 0.643607

Epoch: 8
Loss: 0.2913827489853102
ROC train: 0.914557	val: 0.906354	test: 0.646316
PRC train: 0.978954	val: 0.816017	test: 0.666033

Epoch: 9
Loss: 0.27507147854354885
ROC train: 0.929872	val: 0.910368	test: 0.654128
PRC train: 0.983369	val: 0.825307	test: 0.677535

Epoch: 10
Loss: 0.2677797476192706
ROC train: 0.934935	val: 0.911472	test: 0.658661
PRC train: 0.984752	val: 0.826090	test: 0.678701

Epoch: 11
Loss: 0.26248625766203876
ROC train: 0.947702	val: 0.911974	test: 0.646798
PRC train: 0.987972	val: 0.823528	test: 0.668828

Epoch: 12
Loss: 0.24310747621253445
ROC train: 0.957392	val: 0.905049	test: 0.646123
PRC train: 0.990551	val: 0.806173	test: 0.673513

Epoch: 13
Loss: 0.23731371814527516
ROC train: 0.958699	val: 0.903844	test: 0.633777
PRC train: 0.991051	val: 0.824517	test: 0.666533

Epoch: 14
Loss: 0.2307171321987623
ROC train: 0.961336	val: 0.909565	test: 0.640432
PRC train: 0.991650	val: 0.835495	test: 0.671315

Epoch: 15
Loss: 0.22482169407762825
ROC train: 0.964857	val: 0.912577	test: 0.652199
PRC train: 0.992418	val: 0.836886	test: 0.687874

Epoch: 16
Loss: 0.20486362828084
ROC train: 0.966409	val: 0.900432	test: 0.663484
PRC train: 0.992832	val: 0.787054	test: 0.725157

Epoch: 17
Loss: 0.20512318386369469
ROC train: 0.970662	val: 0.894309	test: 0.669850
PRC train: 0.993905	val: 0.781981	test: 0.727671

Epoch: 18
Loss: 0.21582796999214
ROC train: 0.977467	val: 0.905049	test: 0.665316
PRC train: 0.995386	val: 0.808270	test: 0.713381

Epoch: 19
Loss: 0.1966430844807831
ROC train: 0.977874	val: 0.903844	test: 0.652585
PRC train: 0.995426	val: 0.817965	test: 0.695555

Epoch: 20
Loss: 0.1884158308186335
ROC train: 0.985617	val: 0.900933	test: 0.661651
PRC train: 0.997129	val: 0.814797	test: 0.720626

Epoch: 21
Loss: 0.17353827340142294
ROC train: 0.985673	val: 0.898223	test: 0.662616
PRC train: 0.997152	val: 0.802043	test: 0.716436

Epoch: 22
Loss: 0.18402460389426814
ROC train: 0.988086	val: 0.899026	test: 0.643229
PRC train: 0.997641	val: 0.804166	test: 0.690430

Epoch: 23
Loss: 0.17182221688929378
ROC train: 0.990027	val: 0.899528	test: 0.650945
PRC train: 0.997968	val: 0.800761	test: 0.699045

Epoch: 24
Loss: 0.17015711823748633
ROC train: 0.991828	val: 0.901435	test: 0.662616
PRC train: 0.998369	val: 0.815925	test: 0.713702

Epoch: 25
Loss: 0.14904179854358787
ROC train: 0.993688	val: 0.907959	test: 0.651524
PRC train: 0.998760	val: 0.831480	test: 0.698034

Epoch: 26
Loss: 0.14514961218578995
ROC train: 0.994493	val: 0.905952	test: 0.658565
PRC train: 0.998890	val: 0.828401	test: 0.698603

Epoch: 27
Loss: 0.1364105413861915
ROC train: 0.993584	val: 0.894710	test: 0.647473
PRC train: 0.998711	val: 0.823413	test: 0.678418

Epoch: 28
Loss: 0.14610618162499897
ROC train: 0.993570	val: 0.912677	test: 0.651813
PRC train: 0.998743	val: 0.842365	test: 0.673510

Epoch: 29
Loss: 0.14292324360235645
ROC train: 0.996622	val: 0.900833	test: 0.632137
PRC train: 0.999344	val: 0.830056	test: 0.683544

Epoch: 30
Loss: 0.14539297975727253
ROC train: 0.996549	val: 0.894409	test: 0.645062
PRC train: 0.999320	val: 0.797868	test: 0.712883

Epoch: 31
Loss: 0.12308992373215637
ROC train: 0.997122	val: 0.900933	test: 0.646123
PRC train: 0.999446	val: 0.822850	test: 0.692557

Epoch: 32
Loss: 0.10767343087895982
ROC train: 0.998558	val: 0.905751	test: 0.653260Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.05.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:1
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.05
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/bbbp/noise=0.05
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/bbbp/noise=0.05/bbbp_scaff_1_20-05_14-43-32  ]
[ Using Seed :  1  ]
[ Using device :  cuda:1  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6292222238137828
ROC train: 0.750673	val: 0.887684	test: 0.647955
PRC train: 0.932392	val: 0.820277	test: 0.691408

Epoch: 2
Loss: 0.5204245016039718
ROC train: 0.787216	val: 0.889993	test: 0.655478
PRC train: 0.941584	val: 0.837676	test: 0.693276

Epoch: 3
Loss: 0.4500424394215287
ROC train: 0.832638	val: 0.904547	test: 0.655768
PRC train: 0.955456	val: 0.867149	test: 0.697401

Epoch: 4
Loss: 0.3814460108095026
ROC train: 0.867270	val: 0.908060	test: 0.663580
PRC train: 0.966276	val: 0.827681	test: 0.700018

Epoch: 5
Loss: 0.34936980259969236
ROC train: 0.874993	val: 0.906956	test: 0.662423
PRC train: 0.968759	val: 0.795090	test: 0.697213

Epoch: 6
Loss: 0.33795129927155715
ROC train: 0.893466	val: 0.921108	test: 0.665413
PRC train: 0.973873	val: 0.829962	test: 0.687897

Epoch: 7
Loss: 0.30193709625077
ROC train: 0.907877	val: 0.907357	test: 0.660012
PRC train: 0.977687	val: 0.813436	test: 0.686776

Epoch: 8
Loss: 0.287412028698839
ROC train: 0.918538	val: 0.905651	test: 0.672164
PRC train: 0.979831	val: 0.828895	test: 0.699800

Epoch: 9
Loss: 0.2625778823037746
ROC train: 0.929333	val: 0.908662	test: 0.669850
PRC train: 0.983209	val: 0.807256	test: 0.706083

Epoch: 10
Loss: 0.2515352136692444
ROC train: 0.939721	val: 0.898324	test: 0.673032
PRC train: 0.985367	val: 0.808042	test: 0.711034

Epoch: 11
Loss: 0.23995028295208942
ROC train: 0.947868	val: 0.888086	test: 0.670332
PRC train: 0.987944	val: 0.772351	test: 0.702680

Epoch: 12
Loss: 0.23705721025776125
ROC train: 0.952390	val: 0.887283	test: 0.666763
PRC train: 0.989161	val: 0.753201	test: 0.705094

Epoch: 13
Loss: 0.232152426521164
ROC train: 0.955552	val: 0.882264	test: 0.660012
PRC train: 0.989954	val: 0.780557	test: 0.701611

Epoch: 14
Loss: 0.23628311831944135
ROC train: 0.956567	val: 0.886380	test: 0.687982
PRC train: 0.989805	val: 0.779828	test: 0.744386

Epoch: 15
Loss: 0.21989679812369106
ROC train: 0.961359	val: 0.873934	test: 0.686632
PRC train: 0.991121	val: 0.738918	test: 0.741117

Epoch: 16
Loss: 0.22004833128944368
ROC train: 0.970213	val: 0.872127	test: 0.701292
PRC train: 0.993438	val: 0.733571	test: 0.750747

Epoch: 17
Loss: 0.20302610756814848
ROC train: 0.969719	val: 0.897019	test: 0.710166
PRC train: 0.993172	val: 0.803216	test: 0.754259

Epoch: 18
Loss: 0.17870562754889616
ROC train: 0.971624	val: 0.875439	test: 0.703704
PRC train: 0.993768	val: 0.744250	test: 0.759497

Epoch: 19
Loss: 0.172668135481649
ROC train: 0.977891	val: 0.871023	test: 0.695795
PRC train: 0.995246	val: 0.722805	test: 0.752345

Epoch: 20
Loss: 0.18657441760470675
ROC train: 0.976946	val: 0.868614	test: 0.690779
PRC train: 0.995098	val: 0.728375	test: 0.729836

Epoch: 21
Loss: 0.17987798036019617
ROC train: 0.982691	val: 0.878149	test: 0.686343
PRC train: 0.996231	val: 0.751931	test: 0.724502

Epoch: 22
Loss: 0.1756437603978716
ROC train: 0.980823	val: 0.882666	test: 0.686632
PRC train: 0.995752	val: 0.755371	test: 0.715755

Epoch: 23
Loss: 0.1805960217302261
ROC train: 0.983878	val: 0.889090	test: 0.674286
PRC train: 0.996466	val: 0.781749	test: 0.705924

Epoch: 24
Loss: 0.16517161557012824
ROC train: 0.980494	val: 0.867008	test: 0.673225
PRC train: 0.995759	val: 0.757491	test: 0.695946

Epoch: 25
Loss: 0.16490663799242297
ROC train: 0.987003	val: 0.885175	test: 0.710745
PRC train: 0.997164	val: 0.768343	test: 0.761434

Epoch: 26
Loss: 0.14457974752960226
ROC train: 0.987895	val: 0.879052	test: 0.692226
PRC train: 0.997402	val: 0.754577	test: 0.735438

Epoch: 27
Loss: 0.14573097372301522
ROC train: 0.989845	val: 0.890796	test: 0.683449
PRC train: 0.997904	val: 0.781968	test: 0.725589

Epoch: 28
Loss: 0.1332544535289234
ROC train: 0.991197	val: 0.894610	test: 0.684703
PRC train: 0.998196	val: 0.803384	test: 0.729103

Epoch: 29
Loss: 0.12791990332952058
ROC train: 0.991230	val: 0.879354	test: 0.685185
PRC train: 0.998157	val: 0.751813	test: 0.747432

Epoch: 30
Loss: 0.12775107858100007
ROC train: 0.992807	val: 0.872127	test: 0.691647
PRC train: 0.998537	val: 0.743217	test: 0.752643

Epoch: 31
Loss: 0.12262270883631855
ROC train: 0.993853	val: 0.868614	test: 0.686053
PRC train: 0.998785	val: 0.730567	test: 0.745451

Epoch: 32
Loss: 0.11568741314165301
ROC train: 0.995559	val: 0.885175	test: 0.665220Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.05.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:1
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.05
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/bbbp/noise=0.05
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/bbbp/noise=0.05/bbbp_scaff_2_20-05_14-43-32  ]
[ Using Seed :  2  ]
[ Using device :  cuda:1  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6289268678943143
ROC train: 0.742748	val: 0.857272	test: 0.627122
PRC train: 0.933130	val: 0.772892	test: 0.660064

Epoch: 2
Loss: 0.5303301014505865
ROC train: 0.777989	val: 0.877447	test: 0.636863
PRC train: 0.943037	val: 0.808735	test: 0.678867

Epoch: 3
Loss: 0.4388576973412091
ROC train: 0.827100	val: 0.892302	test: 0.679977
PRC train: 0.956221	val: 0.818072	test: 0.728730

Epoch: 4
Loss: 0.38035890101914954
ROC train: 0.851324	val: 0.895915	test: 0.671296
PRC train: 0.962189	val: 0.821065	test: 0.725149

Epoch: 5
Loss: 0.3327120595912298
ROC train: 0.866908	val: 0.918097	test: 0.660012
PRC train: 0.966547	val: 0.869002	test: 0.697899

Epoch: 6
Loss: 0.3134167917615619
ROC train: 0.892510	val: 0.906153	test: 0.668017
PRC train: 0.973479	val: 0.832799	test: 0.710467

Epoch: 7
Loss: 0.2997633928650546
ROC train: 0.907816	val: 0.898725	test: 0.666667
PRC train: 0.977578	val: 0.813274	test: 0.711910

Epoch: 8
Loss: 0.2849487239978698
ROC train: 0.918269	val: 0.886881	test: 0.657793
PRC train: 0.980506	val: 0.792449	test: 0.713531

Epoch: 9
Loss: 0.2759506157321522
ROC train: 0.930991	val: 0.896216	test: 0.687500
PRC train: 0.983373	val: 0.796887	test: 0.746765

Epoch: 10
Loss: 0.2686516278109089
ROC train: 0.934823	val: 0.877447	test: 0.687500
PRC train: 0.984985	val: 0.763071	test: 0.725283

Epoch: 11
Loss: 0.2423501108793156
ROC train: 0.950480	val: 0.874837	test: 0.696181
PRC train: 0.988589	val: 0.760413	test: 0.723268

Epoch: 12
Loss: 0.23885981276114512
ROC train: 0.948586	val: 0.879052	test: 0.681424
PRC train: 0.987600	val: 0.788674	test: 0.696954

Epoch: 13
Loss: 0.2546429775013102
ROC train: 0.951779	val: 0.871525	test: 0.670042
PRC train: 0.988432	val: 0.770399	test: 0.695005

Epoch: 14
Loss: 0.21829427648573427
ROC train: 0.961390	val: 0.873632	test: 0.680748
PRC train: 0.991013	val: 0.760779	test: 0.710976

Epoch: 15
Loss: 0.22271525988718927
ROC train: 0.966198	val: 0.879655	test: 0.675540
PRC train: 0.991963	val: 0.787553	test: 0.707393

Epoch: 16
Loss: 0.1946657467201937
ROC train: 0.967825	val: 0.895614	test: 0.692419
PRC train: 0.991812	val: 0.826069	test: 0.745881

Epoch: 17
Loss: 0.19506776758675734
ROC train: 0.970002	val: 0.908762	test: 0.689815
PRC train: 0.992428	val: 0.849739	test: 0.736807

Epoch: 18
Loss: 0.19892102960245955
ROC train: 0.973949	val: 0.888889	test: 0.677469
PRC train: 0.993704	val: 0.800603	test: 0.724934

Epoch: 19
Loss: 0.18739183738940254
ROC train: 0.977436	val: 0.882264	test: 0.693094
PRC train: 0.994803	val: 0.780940	test: 0.739389

Epoch: 20
Loss: 0.18487599616134937
ROC train: 0.977049	val: 0.888387	test: 0.677083
PRC train: 0.994659	val: 0.809526	test: 0.716973

Epoch: 21
Loss: 0.17350222701465962
ROC train: 0.980851	val: 0.898223	test: 0.688754
PRC train: 0.995548	val: 0.833537	test: 0.733052

Epoch: 22
Loss: 0.1833083674126565
ROC train: 0.984733	val: 0.907759	test: 0.683642
PRC train: 0.996171	val: 0.837367	test: 0.730885

Epoch: 23
Loss: 0.17403582831713552
ROC train: 0.984758	val: 0.904647	test: 0.690008
PRC train: 0.996342	val: 0.842880	test: 0.745055

Epoch: 24
Loss: 0.1609016738213869
ROC train: 0.985982	val: 0.881160	test: 0.672647
PRC train: 0.996931	val: 0.800986	test: 0.719195

Epoch: 25
Loss: 0.15581604944880853
ROC train: 0.988338	val: 0.898926	test: 0.692805
PRC train: 0.997523	val: 0.828225	test: 0.744729

Epoch: 26
Loss: 0.1574143345085625
ROC train: 0.989003	val: 0.911272	test: 0.676698
PRC train: 0.997624	val: 0.859771	test: 0.710819

Epoch: 27
Loss: 0.14624936814662284
ROC train: 0.989154	val: 0.914484	test: 0.672743
PRC train: 0.997544	val: 0.873904	test: 0.699713

Epoch: 28
Loss: 0.1384947997672387
ROC train: 0.991054	val: 0.907458	test: 0.701775
PRC train: 0.997983	val: 0.847997	test: 0.741653

Epoch: 29
Loss: 0.1333960500163883
ROC train: 0.991208	val: 0.890595	test: 0.717110
PRC train: 0.998109	val: 0.794323	test: 0.763253

Epoch: 30
Loss: 0.13280232209208795
ROC train: 0.992594	val: 0.901335	test: 0.700714
PRC train: 0.998461	val: 0.823942	test: 0.730175

Epoch: 31
Loss: 0.1343737843094198
ROC train: 0.990855	val: 0.892402	test: 0.676601
PRC train: 0.998053	val: 0.803132	test: 0.713094

Epoch: 32
Loss: 0.12172105686723962
ROC train: 0.993716	val: 0.895112	test: 0.671296Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.1.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:2
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.1
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/bbbp/noise=0.1
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/bbbp/noise=0.1/bbbp_scaff_2_20-05_14-43-32  ]
[ Using Seed :  2  ]
[ Using device :  cuda:2  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6379134541378555
ROC train: 0.741542	val: 0.854763	test: 0.659240
PRC train: 0.931942	val: 0.744332	test: 0.694875

Epoch: 2
Loss: 0.5488326183264857
ROC train: 0.782203	val: 0.870320	test: 0.656925
PRC train: 0.944997	val: 0.793486	test: 0.695969

Epoch: 3
Loss: 0.4647883344776092
ROC train: 0.807653	val: 0.877145	test: 0.676119
PRC train: 0.953181	val: 0.796623	test: 0.717547

Epoch: 4
Loss: 0.4095737526202824
ROC train: 0.824050	val: 0.895012	test: 0.674865
PRC train: 0.957953	val: 0.827120	test: 0.727679

Epoch: 5
Loss: 0.3753312010372535
ROC train: 0.854057	val: 0.884473	test: 0.656250
PRC train: 0.964343	val: 0.813473	test: 0.699324

Epoch: 6
Loss: 0.3352137296546798
ROC train: 0.885033	val: 0.890194	test: 0.662519
PRC train: 0.972986	val: 0.815171	test: 0.712281

Epoch: 7
Loss: 0.314281372290873
ROC train: 0.904292	val: 0.886078	test: 0.671007
PRC train: 0.978115	val: 0.801817	test: 0.724981

Epoch: 8
Loss: 0.2980395103730408
ROC train: 0.918204	val: 0.880658	test: 0.679109
PRC train: 0.981428	val: 0.795827	test: 0.737708

Epoch: 9
Loss: 0.279963789234685
ROC train: 0.929720	val: 0.879655	test: 0.688272
PRC train: 0.983997	val: 0.772683	test: 0.745997

Epoch: 10
Loss: 0.2770902066123112
ROC train: 0.941037	val: 0.869818	test: 0.685667
PRC train: 0.987062	val: 0.748859	test: 0.743963

Epoch: 11
Loss: 0.24680503202310788
ROC train: 0.939241	val: 0.905651	test: 0.705826
PRC train: 0.986386	val: 0.809732	test: 0.752906

Epoch: 12
Loss: 0.2508953561853838
ROC train: 0.951206	val: 0.881662	test: 0.687886
PRC train: 0.989533	val: 0.789259	test: 0.734235

Epoch: 13
Loss: 0.25281717342668875
ROC train: 0.965107	val: 0.892502	test: 0.699267
PRC train: 0.992688	val: 0.796178	test: 0.758383

Epoch: 14
Loss: 0.2134553793402536
ROC train: 0.968591	val: 0.901034	test: 0.698495
PRC train: 0.993326	val: 0.819178	test: 0.762788

Epoch: 15
Loss: 0.20249864883138094
ROC train: 0.970356	val: 0.889290	test: 0.688175
PRC train: 0.993828	val: 0.811012	test: 0.755014

Epoch: 16
Loss: 0.19921027108598466
ROC train: 0.979280	val: 0.884272	test: 0.696856
PRC train: 0.995616	val: 0.788697	test: 0.764268

Epoch: 17
Loss: 0.19474822466864278
ROC train: 0.976584	val: 0.879052	test: 0.696277
PRC train: 0.995039	val: 0.790509	test: 0.774067

Epoch: 18
Loss: 0.18854934208730142
ROC train: 0.981210	val: 0.851952	test: 0.672743
PRC train: 0.996022	val: 0.753378	test: 0.748167

Epoch: 19
Loss: 0.1802961940069579
ROC train: 0.986313	val: 0.884171	test: 0.700521
PRC train: 0.997146	val: 0.797149	test: 0.771055

Epoch: 20
Loss: 0.18403016918676798
ROC train: 0.984223	val: 0.887684	test: 0.695120
PRC train: 0.996800	val: 0.825625	test: 0.769842

Epoch: 21
Loss: 0.18560874534483338
ROC train: 0.986503	val: 0.879956	test: 0.677083
PRC train: 0.997227	val: 0.776114	test: 0.765538

Epoch: 22
Loss: 0.18222283083603666
ROC train: 0.989845	val: 0.894008	test: 0.693576
PRC train: 0.997982	val: 0.791283	test: 0.770809

Epoch: 23
Loss: 0.17802148464088763
ROC train: 0.990754	val: 0.907056	test: 0.699074
PRC train: 0.998154	val: 0.849015	test: 0.768934

Epoch: 24
Loss: 0.15951344198704917
ROC train: 0.993214	val: 0.906956	test: 0.699653
PRC train: 0.998613	val: 0.840016	test: 0.774639

Epoch: 25
Loss: 0.14609535747727773
ROC train: 0.993399	val: 0.904346	test: 0.706404
PRC train: 0.998660	val: 0.851592	test: 0.780018

Epoch: 26
Loss: 0.13642511956062103
ROC train: 0.993912	val: 0.908461	test: 0.705826
PRC train: 0.998792	val: 0.868386	test: 0.772644

Epoch: 27
Loss: 0.1367378030662506
ROC train: 0.995150	val: 0.881863	test: 0.690683
PRC train: 0.999051	val: 0.833647	test: 0.765867

Epoch: 28
Loss: 0.13780507804305203
ROC train: 0.996232	val: 0.892101	test: 0.691937
PRC train: 0.999244	val: 0.846257	test: 0.770503

Epoch: 29
Loss: 0.12332927702416827
ROC train: 0.996373	val: 0.898023	test: 0.681713
PRC train: 0.999277	val: 0.832157	test: 0.762159

Epoch: 30
Loss: 0.12314853489020113
ROC train: 0.996440	val: 0.895915	test: 0.680073
PRC train: 0.999301	val: 0.831725	test: 0.757801

Epoch: 31
Loss: 0.1220541022551246
ROC train: 0.997500	val: 0.903643	test: 0.707465
PRC train: 0.999506	val: 0.851571	test: 0.772249

Epoch: 32
Loss: 0.11116259850503675
ROC train: 0.998934	val: 0.904547	test: 0.699653Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.1.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:2
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.1
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/bbbp/noise=0.1
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/bbbp/noise=0.1/bbbp_scaff_1_20-05_14-43-32  ]
[ Using Seed :  1  ]
[ Using device :  cuda:2  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6352870312069804
ROC train: 0.733123	val: 0.888889	test: 0.643519
PRC train: 0.923963	val: 0.846372	test: 0.693921

Epoch: 2
Loss: 0.531372973672567
ROC train: 0.771531	val: 0.896116	test: 0.631462
PRC train: 0.934599	val: 0.860715	test: 0.666421

Epoch: 3
Loss: 0.468134336865697
ROC train: 0.807889	val: 0.905952	test: 0.631269
PRC train: 0.945347	val: 0.878725	test: 0.675079

Epoch: 4
Loss: 0.4029708147050357
ROC train: 0.838880	val: 0.912878	test: 0.659529
PRC train: 0.958252	val: 0.877641	test: 0.712541

Epoch: 5
Loss: 0.3826708418214193
ROC train: 0.865550	val: 0.904948	test: 0.642361
PRC train: 0.966799	val: 0.859966	test: 0.690526

Epoch: 6
Loss: 0.3470575030430059
ROC train: 0.868333	val: 0.915186	test: 0.645062
PRC train: 0.967110	val: 0.869227	test: 0.694059

Epoch: 7
Loss: 0.3118325440717048
ROC train: 0.889101	val: 0.903945	test: 0.646123
PRC train: 0.971748	val: 0.849843	test: 0.697886

Epoch: 8
Loss: 0.29687743870563044
ROC train: 0.908453	val: 0.893807	test: 0.640432
PRC train: 0.976995	val: 0.842411	test: 0.691849

Epoch: 9
Loss: 0.2827575910786486
ROC train: 0.920221	val: 0.895012	test: 0.646412
PRC train: 0.980993	val: 0.798089	test: 0.687670

Epoch: 10
Loss: 0.2670405151430974
ROC train: 0.932489	val: 0.881562	test: 0.624807
PRC train: 0.983747	val: 0.787298	test: 0.667767

Epoch: 11
Loss: 0.25621783023179595
ROC train: 0.946005	val: 0.876644	test: 0.638310
PRC train: 0.987618	val: 0.765749	test: 0.680136

Epoch: 12
Loss: 0.2594965533912833
ROC train: 0.952292	val: 0.872428	test: 0.655189
PRC train: 0.989516	val: 0.739604	test: 0.696268

Epoch: 13
Loss: 0.23541555852240173
ROC train: 0.962891	val: 0.870521	test: 0.657793
PRC train: 0.992176	val: 0.737417	test: 0.710073

Epoch: 14
Loss: 0.23369933198298382
ROC train: 0.962966	val: 0.874636	test: 0.656829
PRC train: 0.992134	val: 0.754494	test: 0.709742

Epoch: 15
Loss: 0.22909410401267663
ROC train: 0.967764	val: 0.871525	test: 0.658758
PRC train: 0.993045	val: 0.763793	test: 0.701646

Epoch: 16
Loss: 0.209106898173576
ROC train: 0.973579	val: 0.879755	test: 0.661265
PRC train: 0.994364	val: 0.799379	test: 0.706321

Epoch: 17
Loss: 0.20221347631757894
ROC train: 0.979754	val: 0.865201	test: 0.646991
PRC train: 0.995494	val: 0.788870	test: 0.700061

Epoch: 18
Loss: 0.18561452574685897
ROC train: 0.980334	val: 0.840209	test: 0.651620
PRC train: 0.995713	val: 0.724016	test: 0.717441

Epoch: 19
Loss: 0.17733369496999898
ROC train: 0.983622	val: 0.861789	test: 0.661265
PRC train: 0.996437	val: 0.768300	test: 0.711698

Epoch: 20
Loss: 0.19325194282792427
ROC train: 0.984517	val: 0.854662	test: 0.657793
PRC train: 0.996798	val: 0.715975	test: 0.703288

Epoch: 21
Loss: 0.1776942527239839
ROC train: 0.988983	val: 0.826960	test: 0.653549
PRC train: 0.997756	val: 0.659874	test: 0.707480

Epoch: 22
Loss: 0.17216193626277101
ROC train: 0.988462	val: 0.853859	test: 0.655189
PRC train: 0.997602	val: 0.696942	test: 0.700797

Epoch: 23
Loss: 0.1657715907437354
ROC train: 0.988355	val: 0.858978	test: 0.635127
PRC train: 0.997478	val: 0.730904	test: 0.658995

Epoch: 24
Loss: 0.16515294191385124
ROC train: 0.987337	val: 0.859982	test: 0.645640
PRC train: 0.997146	val: 0.725779	test: 0.670706

Epoch: 25
Loss: 0.18373056758023232
ROC train: 0.993500	val: 0.861588	test: 0.668596
PRC train: 0.998679	val: 0.704065	test: 0.728057

Epoch: 26
Loss: 0.15220341799674317
ROC train: 0.994642	val: 0.856770	test: 0.661073
PRC train: 0.998885	val: 0.714726	test: 0.703928

Epoch: 27
Loss: 0.14955129571167075
ROC train: 0.992560	val: 0.880357	test: 0.649306
PRC train: 0.998098	val: 0.778366	test: 0.667783

Epoch: 28
Loss: 0.15104244069273004
ROC train: 0.994159	val: 0.856469	test: 0.638503
PRC train: 0.998708	val: 0.717544	test: 0.668366

Epoch: 29
Loss: 0.14080726159292856
ROC train: 0.995503	val: 0.854763	test: 0.670235
PRC train: 0.999103	val: 0.712922	test: 0.722604

Epoch: 30
Loss: 0.12449246449263074
ROC train: 0.991648	val: 0.873733	test: 0.669753
PRC train: 0.998264	val: 0.769793	test: 0.715816

Epoch: 31
Loss: 0.1271749922090288
ROC train: 0.997074	val: 0.866406	test: 0.668692
PRC train: 0.999413	val: 0.722035	test: 0.706109

Epoch: 32
Loss: 0.10731451758232094
ROC train: 0.998623	val: 0.848740	test: 0.651042Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.05.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:1
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.05
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/bbbp/noise=0.05
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/bbbp/noise=0.05/bbbp_scaff_3_20-05_14-43-32  ]
[ Using Seed :  3  ]
[ Using device :  cuda:1  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6084009281717117
ROC train: 0.751091	val: 0.874536	test: 0.645640
PRC train: 0.931827	val: 0.814880	test: 0.693082

Epoch: 2
Loss: 0.5018405895468718
ROC train: 0.813603	val: 0.873231	test: 0.624518
PRC train: 0.951109	val: 0.820592	test: 0.677141

Epoch: 3
Loss: 0.4400168051552829
ROC train: 0.850555	val: 0.896818	test: 0.653356
PRC train: 0.961147	val: 0.830927	test: 0.685133

Epoch: 4
Loss: 0.36362725893376463
ROC train: 0.881897	val: 0.892502	test: 0.661169
PRC train: 0.970433	val: 0.823898	test: 0.697477

Epoch: 5
Loss: 0.3275514707253892
ROC train: 0.907838	val: 0.877246	test: 0.653935
PRC train: 0.977274	val: 0.742955	test: 0.688870

Epoch: 6
Loss: 0.29630438326909697
ROC train: 0.917121	val: 0.883067	test: 0.645737
PRC train: 0.979602	val: 0.767896	test: 0.679121

Epoch: 7
Loss: 0.27878184276369666
ROC train: 0.929675	val: 0.886982	test: 0.678337
PRC train: 0.982960	val: 0.776742	test: 0.709464

Epoch: 8
Loss: 0.26460067557303074
ROC train: 0.941208	val: 0.902339	test: 0.689622
PRC train: 0.985714	val: 0.796107	test: 0.732708

Epoch: 9
Loss: 0.25332068735604063
ROC train: 0.944330	val: 0.895915	test: 0.685378
PRC train: 0.986422	val: 0.784100	test: 0.731043

Epoch: 10
Loss: 0.2489284729513049
ROC train: 0.945767	val: 0.894510	test: 0.686632
PRC train: 0.986950	val: 0.771892	test: 0.733179

Epoch: 11
Loss: 0.23799462677544447
ROC train: 0.958826	val: 0.877045	test: 0.667631
PRC train: 0.990284	val: 0.747704	test: 0.723159

Epoch: 12
Loss: 0.22217793895876609
ROC train: 0.962262	val: 0.883268	test: 0.670910
PRC train: 0.990821	val: 0.758542	test: 0.716991

Epoch: 13
Loss: 0.22012964806224442
ROC train: 0.963143	val: 0.872528	test: 0.668981
PRC train: 0.991050	val: 0.734336	test: 0.714355

Epoch: 14
Loss: 0.21357747595431853
ROC train: 0.966821	val: 0.879354	test: 0.658179
PRC train: 0.992059	val: 0.764785	test: 0.696278

Epoch: 15
Loss: 0.20342867186472643
ROC train: 0.967475	val: 0.897320	test: 0.657890
PRC train: 0.992221	val: 0.800318	test: 0.680432

Epoch: 16
Loss: 0.1927989969285033
ROC train: 0.972883	val: 0.880056	test: 0.655285
PRC train: 0.993512	val: 0.758980	test: 0.687085

Epoch: 17
Loss: 0.18851321960297127
ROC train: 0.973994	val: 0.867711	test: 0.654803
PRC train: 0.993886	val: 0.715958	test: 0.673278

Epoch: 18
Loss: 0.1931057467979123
ROC train: 0.976429	val: 0.880558	test: 0.668596
PRC train: 0.994293	val: 0.744789	test: 0.703145

Epoch: 19
Loss: 0.18078670690258408
ROC train: 0.975700	val: 0.876443	test: 0.652778
PRC train: 0.993812	val: 0.748269	test: 0.678874

Epoch: 20
Loss: 0.18458566310374191
ROC train: 0.982102	val: 0.869517	test: 0.648245
PRC train: 0.995847	val: 0.739327	test: 0.653116

Epoch: 21
Loss: 0.16337364672853255
ROC train: 0.981883	val: 0.881662	test: 0.641204
PRC train: 0.995901	val: 0.755835	test: 0.641939

Epoch: 22
Loss: 0.1752083073061028
ROC train: 0.984057	val: 0.891097	test: 0.658758
PRC train: 0.996327	val: 0.773054	test: 0.657447

Epoch: 23
Loss: 0.15983696042877119
ROC train: 0.986983	val: 0.877346	test: 0.650752
PRC train: 0.997067	val: 0.759640	test: 0.671290

Epoch: 24
Loss: 0.15168591234862913
ROC train: 0.989087	val: 0.882666	test: 0.651910
PRC train: 0.997452	val: 0.777015	test: 0.664937

Epoch: 25
Loss: 0.16064734336409398
ROC train: 0.989216	val: 0.890696	test: 0.635513
PRC train: 0.997455	val: 0.786324	test: 0.638967

Epoch: 26
Loss: 0.1482061692130871
ROC train: 0.988268	val: 0.893205	test: 0.636285
PRC train: 0.997297	val: 0.781270	test: 0.660036

Epoch: 27
Loss: 0.13788804464619114
ROC train: 0.991183	val: 0.880157	test: 0.648438
PRC train: 0.997886	val: 0.766232	test: 0.681818

Epoch: 28
Loss: 0.1404985631266931
ROC train: 0.991275	val: 0.887684	test: 0.633488
PRC train: 0.998103	val: 0.763581	test: 0.626338

Epoch: 29
Loss: 0.13978288609265527
ROC train: 0.993104	val: 0.890896	test: 0.630305
PRC train: 0.998515	val: 0.777425	test: 0.677751

Epoch: 30
Loss: 0.1543195764565091
ROC train: 0.993966	val: 0.899829	test: 0.633102
PRC train: 0.998728	val: 0.794502	test: 0.682888

Epoch: 31
Loss: 0.13715517331448526
ROC train: 0.994614	val: 0.902640	test: 0.658565
PRC train: 0.998840	val: 0.801664	test: 0.695487

Epoch: 32
Loss: 0.11640580499310116
ROC train: 0.993295	val: 0.892904	test: 0.675829Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.2.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:3
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.2
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/bbbp/noise=0.2
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/bbbp/noise=0.2/bbbp_scaff_1_20-05_14-43-32  ]
[ Using Seed :  1  ]
[ Using device :  cuda:3  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6452141532658598
ROC train: 0.682879	val: 0.863696	test: 0.639564
PRC train: 0.905593	val: 0.843082	test: 0.674085

Epoch: 2
Loss: 0.5496622144366808
ROC train: 0.736857	val: 0.892803	test: 0.648052
PRC train: 0.924539	val: 0.862612	test: 0.681955

Epoch: 3
Loss: 0.48690173331745684
ROC train: 0.771758	val: 0.881963	test: 0.599826
PRC train: 0.938067	val: 0.842851	test: 0.627250

Epoch: 4
Loss: 0.4321247194857857
ROC train: 0.801655	val: 0.880458	test: 0.597512
PRC train: 0.947237	val: 0.838279	test: 0.631322

Epoch: 5
Loss: 0.4036737521958326
ROC train: 0.833193	val: 0.879755	test: 0.622106
PRC train: 0.956460	val: 0.837494	test: 0.662339

Epoch: 6
Loss: 0.3692647915033019
ROC train: 0.846662	val: 0.900833	test: 0.611786
PRC train: 0.959872	val: 0.859925	test: 0.653727

Epoch: 7
Loss: 0.34166181092398384
ROC train: 0.869183	val: 0.908562	test: 0.597897
PRC train: 0.965731	val: 0.877871	test: 0.634085

Epoch: 8
Loss: 0.3329775543667579
ROC train: 0.886711	val: 0.895815	test: 0.572627
PRC train: 0.969690	val: 0.865369	test: 0.616433

Epoch: 9
Loss: 0.3115693735579676
ROC train: 0.904721	val: 0.880458	test: 0.551312
PRC train: 0.974470	val: 0.841530	test: 0.594340

Epoch: 10
Loss: 0.29688059814480416
ROC train: 0.922945	val: 0.875138	test: 0.552276
PRC train: 0.980168	val: 0.830709	test: 0.593650

Epoch: 11
Loss: 0.28100824987876477
ROC train: 0.936332	val: 0.875038	test: 0.548997
PRC train: 0.983346	val: 0.818450	test: 0.583517

Epoch: 12
Loss: 0.28745737780116204
ROC train: 0.943660	val: 0.882867	test: 0.591821
PRC train: 0.985669	val: 0.808639	test: 0.623699

Epoch: 13
Loss: 0.26902239088511787
ROC train: 0.953218	val: 0.873131	test: 0.594715
PRC train: 0.988480	val: 0.803738	test: 0.640377

Epoch: 14
Loss: 0.26139439452432367
ROC train: 0.952760	val: 0.858476	test: 0.560378
PRC train: 0.988725	val: 0.806262	test: 0.610770

Epoch: 15
Loss: 0.2666301169681825
ROC train: 0.961409	val: 0.876242	test: 0.584201
PRC train: 0.990874	val: 0.818660	test: 0.631478

Epoch: 16
Loss: 0.2451532377406959
ROC train: 0.954348	val: 0.891599	test: 0.596354
PRC train: 0.989725	val: 0.836041	test: 0.636161

Epoch: 17
Loss: 0.22091428209633876
ROC train: 0.968611	val: 0.891499	test: 0.578800
PRC train: 0.992717	val: 0.840741	test: 0.616596

Epoch: 18
Loss: 0.21430189985194997
ROC train: 0.972883	val: 0.883268	test: 0.568769
PRC train: 0.993786	val: 0.828182	test: 0.607363

Epoch: 19
Loss: 0.1902346315064908
ROC train: 0.978845	val: 0.874235	test: 0.575617
PRC train: 0.995284	val: 0.823381	test: 0.601883

Epoch: 20
Loss: 0.21291148875683133
ROC train: 0.977493	val: 0.893707	test: 0.600694
PRC train: 0.994652	val: 0.846569	test: 0.620371

Epoch: 21
Loss: 0.20160036810628798
ROC train: 0.982259	val: 0.876443	test: 0.569059
PRC train: 0.995891	val: 0.817413	test: 0.615447

Epoch: 22
Loss: 0.20538889184203807
ROC train: 0.983920	val: 0.875138	test: 0.544367
PRC train: 0.996381	val: 0.821987	test: 0.580670

Epoch: 23
Loss: 0.19029683793640137
ROC train: 0.988832	val: 0.883770	test: 0.567515
PRC train: 0.997580	val: 0.826062	test: 0.588750

Epoch: 24
Loss: 0.16656917912974992
ROC train: 0.990944	val: 0.869718	test: 0.556809
PRC train: 0.998131	val: 0.814241	test: 0.592050

Epoch: 25
Loss: 0.17940249157775298
ROC train: 0.992179	val: 0.881160	test: 0.566551
PRC train: 0.998309	val: 0.833827	test: 0.604158

Epoch: 26
Loss: 0.15840589806041416
ROC train: 0.995483	val: 0.874536	test: 0.567998
PRC train: 0.999052	val: 0.822068	test: 0.607417

Epoch: 27
Loss: 0.1519206858461976
ROC train: 0.995741	val: 0.880960	test: 0.576485
PRC train: 0.999051	val: 0.824973	test: 0.611785

Epoch: 28
Loss: 0.14832058563806422
ROC train: 0.996260	val: 0.881562	test: 0.568769
PRC train: 0.999189	val: 0.833010	test: 0.603776

Epoch: 29
Loss: 0.14815845771246466
ROC train: 0.995963	val: 0.891398	test: 0.570891
PRC train: 0.999156	val: 0.840670	test: 0.626701

Epoch: 30
Loss: 0.15149302746849277
ROC train: 0.995040	val: 0.879956	test: 0.561439
PRC train: 0.998933	val: 0.831585	test: 0.626617

Epoch: 31
Loss: 0.1287940881191393
ROC train: 0.996266	val: 0.881662	test: 0.548032
PRC train: 0.999157	val: 0.822695	test: 0.577454

Epoch: 32
Loss: 0.1058147338390135
ROC train: 0.998025	val: 0.879554	test: 0.540702Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.2.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:3
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.2
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/bbbp/noise=0.2
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/bbbp/noise=0.2/bbbp_scaff_2_20-05_14-43-32  ]
[ Using Seed :  2  ]
[ Using device :  cuda:3  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6450178349705536
ROC train: 0.703394	val: 0.839607	test: 0.643229
PRC train: 0.918069	val: 0.783194	test: 0.666628

Epoch: 2
Loss: 0.5663069759203488
ROC train: 0.754954	val: 0.862592	test: 0.664641
PRC train: 0.934570	val: 0.792258	test: 0.701813

Epoch: 3
Loss: 0.49730170066410256
ROC train: 0.787194	val: 0.852153	test: 0.656443
PRC train: 0.943003	val: 0.782639	test: 0.695875

Epoch: 4
Loss: 0.4386286129018767
ROC train: 0.801111	val: 0.885978	test: 0.668596
PRC train: 0.947818	val: 0.826708	test: 0.719094

Epoch: 5
Loss: 0.4073239643070145
ROC train: 0.827554	val: 0.892402	test: 0.668885
PRC train: 0.956236	val: 0.833075	test: 0.726656

Epoch: 6
Loss: 0.37408136210633397
ROC train: 0.852435	val: 0.880257	test: 0.657311
PRC train: 0.962942	val: 0.819399	test: 0.728126

Epoch: 7
Loss: 0.35323504855742044
ROC train: 0.873871	val: 0.872428	test: 0.649498
PRC train: 0.968834	val: 0.805123	test: 0.715904

Epoch: 8
Loss: 0.3270120048855295
ROC train: 0.888952	val: 0.856670	test: 0.633873
PRC train: 0.973641	val: 0.794354	test: 0.703366

Epoch: 9
Loss: 0.3232889607346888
ROC train: 0.898987	val: 0.882264	test: 0.637442
PRC train: 0.976326	val: 0.810559	test: 0.703461

Epoch: 10
Loss: 0.3114507882883743
ROC train: 0.915421	val: 0.880157	test: 0.635127
PRC train: 0.980377	val: 0.807493	test: 0.699850

Epoch: 11
Loss: 0.28639643296913425
ROC train: 0.928354	val: 0.884573	test: 0.617959
PRC train: 0.983468	val: 0.813661	test: 0.677767

Epoch: 12
Loss: 0.29059318635266707
ROC train: 0.938097	val: 0.881763	test: 0.607928
PRC train: 0.985981	val: 0.804332	test: 0.663538

Epoch: 13
Loss: 0.2746518643984944
ROC train: 0.942658	val: 0.833484	test: 0.618152
PRC train: 0.987382	val: 0.755539	test: 0.670952

Epoch: 14
Loss: 0.25485067826522084
ROC train: 0.955532	val: 0.870320	test: 0.613522
PRC train: 0.990348	val: 0.788827	test: 0.660734

Epoch: 15
Loss: 0.23935391728762498
ROC train: 0.966193	val: 0.876543	test: 0.596161
PRC train: 0.992794	val: 0.810839	test: 0.640208

Epoch: 16
Loss: 0.2274910457519204
ROC train: 0.972895	val: 0.886380	test: 0.599344
PRC train: 0.994239	val: 0.813130	test: 0.627660

Epoch: 17
Loss: 0.2248264148313863
ROC train: 0.977498	val: 0.876443	test: 0.612076
PRC train: 0.995401	val: 0.793865	test: 0.640297

Epoch: 18
Loss: 0.21602549432282483
ROC train: 0.979824	val: 0.858075	test: 0.621817
PRC train: 0.995986	val: 0.763304	test: 0.670764

Epoch: 19
Loss: 0.19562605160273902
ROC train: 0.987693	val: 0.844123	test: 0.612269
PRC train: 0.997534	val: 0.747545	test: 0.644953

Epoch: 20
Loss: 0.21703245698378928
ROC train: 0.986776	val: 0.847636	test: 0.575328
PRC train: 0.997386	val: 0.757320	test: 0.605904

Epoch: 21
Loss: 0.18360698342759632
ROC train: 0.990998	val: 0.864298	test: 0.627894
PRC train: 0.998226	val: 0.769965	test: 0.668674

Epoch: 22
Loss: 0.19970122575823274
ROC train: 0.992734	val: 0.855666	test: 0.618538
PRC train: 0.998568	val: 0.777427	test: 0.653258

Epoch: 23
Loss: 0.179986550453545
ROC train: 0.994246	val: 0.877145	test: 0.631269
PRC train: 0.998879	val: 0.786463	test: 0.660997

Epoch: 24
Loss: 0.16828966166547857
ROC train: 0.996507	val: 0.836696	test: 0.631848
PRC train: 0.999330	val: 0.741517	test: 0.649931

Epoch: 25
Loss: 0.15819965119963927
ROC train: 0.995767	val: 0.837599	test: 0.616319
PRC train: 0.999175	val: 0.773649	test: 0.633704

Epoch: 26
Loss: 0.14533557876134592
ROC train: 0.996807	val: 0.897220	test: 0.635320
PRC train: 0.999363	val: 0.843893	test: 0.657467

Epoch: 27
Loss: 0.1630938083840831
ROC train: 0.997290	val: 0.877346	test: 0.626061
PRC train: 0.999462	val: 0.825051	test: 0.642093

Epoch: 28
Loss: 0.14319324945215164
ROC train: 0.997955	val: 0.836294	test: 0.654321
PRC train: 0.999601	val: 0.756419	test: 0.682373

Epoch: 29
Loss: 0.15050468882235218
ROC train: 0.998084	val: 0.855766	test: 0.649788
PRC train: 0.999628	val: 0.775111	test: 0.687572

Epoch: 30
Loss: 0.12633757684654554
ROC train: 0.998799	val: 0.823447	test: 0.632330
PRC train: 0.999773	val: 0.729245	test: 0.668277

Epoch: 31
Loss: 0.12353360842093127
ROC train: 0.999574	val: 0.850547	test: 0.638696
PRC train: 0.999919	val: 0.745607	test: 0.671182

Epoch: 32
Loss: 0.12525545176864009
ROC train: 0.999778	val: 0.855666	test: 0.649595Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.2.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:3
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.2
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/bbbp/noise=0.2
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/bbbp/noise=0.2/bbbp_scaff_3_20-05_14-43-32  ]
[ Using Seed :  3  ]
[ Using device :  cuda:3  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6201391481028554
ROC train: 0.661693	val: 0.834387	test: 0.606867
PRC train: 0.899826	val: 0.793883	test: 0.658580

Epoch: 2
Loss: 0.53588548241276
ROC train: 0.730301	val: 0.865302	test: 0.606192
PRC train: 0.922436	val: 0.800791	test: 0.663399

Epoch: 3
Loss: 0.47358815215028033
ROC train: 0.765971	val: 0.869618	test: 0.578029
PRC train: 0.931243	val: 0.815634	test: 0.627098

Epoch: 4
Loss: 0.4212397320803768
ROC train: 0.796838	val: 0.892402	test: 0.582369
PRC train: 0.945084	val: 0.846243	test: 0.628583

Epoch: 5
Loss: 0.4029417192882521
ROC train: 0.829591	val: 0.888086	test: 0.586227
PRC train: 0.955418	val: 0.830793	test: 0.620052

Epoch: 6
Loss: 0.3729476456768116
ROC train: 0.850797	val: 0.880357	test: 0.581501
PRC train: 0.962434	val: 0.820038	test: 0.613231

Epoch: 7
Loss: 0.354231175076511
ROC train: 0.864902	val: 0.878852	test: 0.589892
PRC train: 0.966564	val: 0.813051	test: 0.613482

Epoch: 8
Loss: 0.33351331738216405
ROC train: 0.877967	val: 0.873331	test: 0.575328
PRC train: 0.969244	val: 0.795919	test: 0.601536

Epoch: 9
Loss: 0.30843868801311747
ROC train: 0.894159	val: 0.875038	test: 0.565394
PRC train: 0.974093	val: 0.808281	test: 0.597019

Epoch: 10
Loss: 0.29996971462912636
ROC train: 0.901767	val: 0.880257	test: 0.549383
PRC train: 0.976027	val: 0.805452	test: 0.570350

Epoch: 11
Loss: 0.2991580958925614
ROC train: 0.913875	val: 0.890896	test: 0.551601
PRC train: 0.978941	val: 0.809473	test: 0.557865

Epoch: 12
Loss: 0.2684597347134104
ROC train: 0.934228	val: 0.866406	test: 0.561439
PRC train: 0.984457	val: 0.774265	test: 0.571748

Epoch: 13
Loss: 0.26709237062533553
ROC train: 0.945099	val: 0.873030	test: 0.585166
PRC train: 0.987694	val: 0.780310	test: 0.600315

Epoch: 14
Loss: 0.2552055668183026
ROC train: 0.947262	val: 0.889290	test: 0.607832
PRC train: 0.988739	val: 0.806169	test: 0.630245

Epoch: 15
Loss: 0.2507733144009479
ROC train: 0.956029	val: 0.869818	test: 0.619695
PRC train: 0.990686	val: 0.782440	test: 0.648940

Epoch: 16
Loss: 0.23071748156381328
ROC train: 0.963390	val: 0.872328	test: 0.597319
PRC train: 0.992296	val: 0.789800	test: 0.621311

Epoch: 17
Loss: 0.22733227008033455
ROC train: 0.975386	val: 0.840309	test: 0.576100
PRC train: 0.995107	val: 0.750013	test: 0.608480

Epoch: 18
Loss: 0.2604043564630697
ROC train: 0.979597	val: 0.875038	test: 0.602527
PRC train: 0.995961	val: 0.785922	test: 0.625814

Epoch: 19
Loss: 0.21080896378840452
ROC train: 0.966061	val: 0.855566	test: 0.628472
PRC train: 0.993098	val: 0.768000	test: 0.664501

Epoch: 20
Loss: 0.22097446583289596
ROC train: 0.986105	val: 0.888387	test: 0.615934
PRC train: 0.997161	val: 0.812663	test: 0.634987

Epoch: 21
Loss: 0.20950399514939383
ROC train: 0.989211	val: 0.898123	test: 0.617863
PRC train: 0.997914	val: 0.837292	test: 0.625505

Epoch: 22
Loss: 0.21857656101274822
ROC train: 0.992613	val: 0.896216	test: 0.610725
PRC train: 0.998598	val: 0.843326	test: 0.616669

Epoch: 23
Loss: 0.1943810342849727
ROC train: 0.992501	val: 0.893205	test: 0.613137
PRC train: 0.998550	val: 0.833130	test: 0.625723

Epoch: 24
Loss: 0.17995097105946203
ROC train: 0.987460	val: 0.881060	test: 0.601562
PRC train: 0.997557	val: 0.817365	test: 0.599195

Epoch: 25
Loss: 0.18140769328763764
ROC train: 0.992700	val: 0.839506	test: 0.556617
PRC train: 0.998581	val: 0.751713	test: 0.597249

Epoch: 26
Loss: 0.16935789608450813
ROC train: 0.994112	val: 0.859781	test: 0.587963
PRC train: 0.998858	val: 0.760585	test: 0.619976

Epoch: 27
Loss: 0.17202359339737489
ROC train: 0.996213	val: 0.872428	test: 0.613522
PRC train: 0.999285	val: 0.803060	test: 0.643534

Epoch: 28
Loss: 0.1600304089116751
ROC train: 0.995907	val: 0.896617	test: 0.629051
PRC train: 0.999219	val: 0.846373	test: 0.640537

Epoch: 29
Loss: 0.1469494379022774
ROC train: 0.997902	val: 0.873532	test: 0.594715
PRC train: 0.999585	val: 0.814896	test: 0.619415

Epoch: 30
Loss: 0.15272595250843474
ROC train: 0.998308	val: 0.871625	test: 0.577353
PRC train: 0.999662	val: 0.811008	test: 0.590926

Epoch: 31
Loss: 0.125832203731119
ROC train: 0.998485	val: 0.891398	test: 0.605999
PRC train: 0.999714	val: 0.831113	test: 0.607485

Epoch: 32
Loss: 0.1216518715405759
ROC train: 0.999296	val: 0.898926	test: 0.633005
PRC train: 0.996147	val: 0.821245	test: 0.726690

Epoch: 34
Loss: 0.16279767391597108
ROC train: 0.983453	val: 0.886881	test: 0.691262
PRC train: 0.996331	val: 0.812226	test: 0.704661

Epoch: 35
Loss: 0.15038491213340105
ROC train: 0.983566	val: 0.892402	test: 0.678916
PRC train: 0.996470	val: 0.826549	test: 0.680027

Epoch: 36
Loss: 0.15036423554946396
ROC train: 0.984317	val: 0.886480	test: 0.672261
PRC train: 0.996701	val: 0.815897	test: 0.681647

Epoch: 37
Loss: 0.16330357220847208
ROC train: 0.985739	val: 0.891197	test: 0.687404
PRC train: 0.997074	val: 0.810559	test: 0.702016

Epoch: 38
Loss: 0.1523832231086526
ROC train: 0.987426	val: 0.879153	test: 0.682195
PRC train: 0.997414	val: 0.799621	test: 0.687143

Epoch: 39
Loss: 0.14263676056809935
ROC train: 0.983148	val: 0.889090	test: 0.679977
PRC train: 0.996304	val: 0.798443	test: 0.677078

Epoch: 40
Loss: 0.15780372229661283
ROC train: 0.987000	val: 0.884874	test: 0.688175
PRC train: 0.997245	val: 0.822141	test: 0.709375

Epoch: 41
Loss: 0.1434374350802091
ROC train: 0.987317	val: 0.879153	test: 0.658565
PRC train: 0.997405	val: 0.800683	test: 0.666165

Epoch: 42
Loss: 0.13280859036949885
ROC train: 0.988915	val: 0.888086	test: 0.683256
PRC train: 0.997711	val: 0.803544	test: 0.706006

Epoch: 43
Loss: 0.13410550569115073
ROC train: 0.988382	val: 0.885878	test: 0.695505
PRC train: 0.997559	val: 0.799308	test: 0.715290

Epoch: 44
Loss: 0.13070451466986227
ROC train: 0.989640	val: 0.903443	test: 0.692805
PRC train: 0.997925	val: 0.821890	test: 0.707679

Epoch: 45
Loss: 0.13404801889832288
ROC train: 0.991388	val: 0.895313	test: 0.682195
PRC train: 0.998326	val: 0.815123	test: 0.698502

Epoch: 46
Loss: 0.14720094753012122
ROC train: 0.990387	val: 0.882465	test: 0.689043
PRC train: 0.998110	val: 0.797972	test: 0.705094

Epoch: 47
Loss: 0.13931674386024637
ROC train: 0.989738	val: 0.880458	test: 0.681713
PRC train: 0.997965	val: 0.800665	test: 0.684656

Epoch: 48
Loss: 0.12998242690245762
ROC train: 0.991915	val: 0.886179	test: 0.651427
PRC train: 0.998413	val: 0.818716	test: 0.644453

Epoch: 49
Loss: 0.13313414608659985
ROC train: 0.992263	val: 0.872127	test: 0.646412
PRC train: 0.998486	val: 0.790243	test: 0.635556

Epoch: 50
Loss: 0.1172137085254888
ROC train: 0.992330	val: 0.878651	test: 0.680363
PRC train: 0.998487	val: 0.786888	test: 0.698279

Epoch: 51
Loss: 0.12363501929307316
ROC train: 0.992411	val: 0.883268	test: 0.689815
PRC train: 0.998517	val: 0.784184	test: 0.715219

Epoch: 52
Loss: 0.1351031845062271
ROC train: 0.992837	val: 0.883569	test: 0.678337
PRC train: 0.998594	val: 0.796419	test: 0.705485

Epoch: 53
Loss: 0.1180787092356872
ROC train: 0.992925	val: 0.893506	test: 0.680459
PRC train: 0.998610	val: 0.810798	test: 0.699811

Epoch: 54
Loss: 0.11178294149377492
ROC train: 0.993926	val: 0.890796	test: 0.673997
PRC train: 0.998825	val: 0.798712	test: 0.698068

Epoch: 55
Loss: 0.12770556699982002
ROC train: 0.994221	val: 0.890194	test: 0.666474
PRC train: 0.998880	val: 0.801772	test: 0.680336

Epoch: 56
Loss: 0.12064812311825994
ROC train: 0.990585	val: 0.875539	test: 0.658854
PRC train: 0.997993	val: 0.811285	test: 0.681681

Epoch: 57
Loss: 0.11846419342898572
ROC train: 0.994851	val: 0.897220	test: 0.676505
PRC train: 0.999005	val: 0.805549	test: 0.693819

Epoch: 58
Loss: 0.11514321955568452
ROC train: 0.995026	val: 0.886179	test: 0.664255
PRC train: 0.999033	val: 0.802969	test: 0.662109

Epoch: 59
Loss: 0.11137724350886306
ROC train: 0.994722	val: 0.873632	test: 0.664738
PRC train: 0.998981	val: 0.793898	test: 0.675912

Epoch: 60
Loss: 0.12575181557012968
ROC train: 0.993665	val: 0.884171	test: 0.683835
PRC train: 0.998737	val: 0.795123	test: 0.705346

Epoch: 61
Loss: 0.11403692461203045
ROC train: 0.994921	val: 0.883268	test: 0.671875
PRC train: 0.998999	val: 0.791538	test: 0.690038

Epoch: 62
Loss: 0.11426594537474336
ROC train: 0.995255	val: 0.881261	test: 0.653742
PRC train: 0.999083	val: 0.785415	test: 0.664808

Epoch: 63
Loss: 0.12516103394137046
ROC train: 0.995883	val: 0.886982	test: 0.666570
PRC train: 0.999199	val: 0.779295	test: 0.675471

Epoch: 64
Loss: 0.11099398221202274
ROC train: 0.995157	val: 0.889792	test: 0.659722
PRC train: 0.999057	val: 0.802545	test: 0.688200

Epoch: 65
Loss: 0.10636668799057201
ROC train: 0.995053	val: 0.881562	test: 0.670042
PRC train: 0.999050	val: 0.792768	test: 0.678354

Epoch: 66
Loss: 0.0993587813895642
ROC train: 0.996418	val: 0.871826	test: 0.666763
PRC train: 0.999316	val: 0.781566	test: 0.673994

Epoch: 67
Loss: 0.10711409750123792
ROC train: 0.995600	val: 0.878350	test: 0.659047
PRC train: 0.999148	val: 0.781905	test: 0.666884

Epoch: 68
Loss: 0.10742526070689411
ROC train: 0.996248	val: 0.891097	test: 0.662712
PRC train: 0.999263	val: 0.791478	test: 0.663795

Epoch: 69
Loss: 0.10758714728238637
ROC train: 0.995963	val: 0.885878	test: 0.660494
PRC train: 0.999230	val: 0.801975	test: 0.653369

Epoch: 70
Loss: 0.09943683803935807
ROC train: 0.996514	val: 0.883268	test: 0.639178
PRC train: 0.999331	val: 0.788960	test: 0.638299

Epoch: 71
Loss: 0.10922573621129253
ROC train: 0.996692	val: 0.885075	test: 0.658661
PRC train: 0.999369	val: 0.789715	test: 0.675937

Epoch: 72
Loss: 0.0878194365745215
ROC train: 0.997702	val: 0.877748	test: 0.664931
PRC train: 0.999564	val: 0.782552	test: 0.672940

Epoch: 73
Loss: 0.10037957378901839
ROC train: 0.997935	val: 0.867711	test: 0.650077
PRC train: 0.999609	val: 0.764280	test: 0.651424

Epoch: 74
Loss: 0.0892098926410841
ROC train: 0.996050	val: 0.868714	test: 0.651524
PRC train: 0.999232	val: 0.772493	test: 0.642493

Epoch: 75
Loss: 0.09145319226157178
ROC train: 0.997636	val: 0.868513	test: 0.656250
PRC train: 0.999548	val: 0.773739	test: 0.651455

Epoch: 76
Loss: 0.08673607299193567
ROC train: 0.997782	val: 0.881562	test: 0.659626
PRC train: 0.999580	val: 0.786455	test: 0.659881

Epoch: 77
Loss: 0.09348539728249554
ROC train: 0.997397	val: 0.882164	test: 0.647955
PRC train: 0.999499	val: 0.797353	test: 0.662346

Epoch: 78
Loss: 0.10330076319316395
ROC train: 0.997359	val: 0.880357	test: 0.652585
PRC train: 0.999480	val: 0.789314	test: 0.659733

Epoch: 79
Loss: 0.08996562873773048
ROC train: 0.996729	val: 0.876945	test: 0.657504
PRC train: 0.999368	val: 0.789335	test: 0.648546

Epoch: 80
Loss: 0.08277202359066049
ROC train: 0.996573	val: 0.871424	test: 0.661555
PRC train: 0.999342	val: 0.797934	test: 0.657188

Epoch: 81
Loss: 0.09940663242328149
ROC train: 0.997810	val: 0.870220	test: 0.641975
PRC train: 0.999580	val: 0.790381	test: 0.653569

Epoch: 82
Loss: 0.09624460029146505
ROC train: 0.998362	val: 0.871424	test: 0.644869
PRC train: 0.999688	val: 0.777690	test: 0.651636

Epoch: 83
Loss: 0.08099158420248546
ROC train: 0.998059	val: 0.868714	test: 0.649016
PRC train: 0.999630	val: 0.767962	test: 0.663474

Epoch: 84
Loss: 0.0984269876644558
ROC train: 0.997976	val: 0.878952	test: 0.663870
PRC train: 0.999615	val: 0.774085	test: 0.673086

Epoch: 85
Loss: 0.08786476200700592
ROC train: 0.996956	val: 0.881863	test: 0.673418
PRC train: 0.999417	val: 0.767970	test: 0.680075

Epoch: 86
Loss: 0.09238208258417566
ROC train: 0.997681	val: 0.882867	test: 0.682292
PRC train: 0.999556	val: 0.777505	test: 0.694380

Epoch: 87
Loss: 0.08375265655788186
ROC train: 0.998275	val: 0.871224	test: 0.652392
PRC train: 0.999672	val: 0.773049	test: 0.670120

Epoch: 88
Loss: 0.08238347936975729
ROC train: 0.997477	val: 0.874235	test: 0.645640
PRC train: 0.999519	val: 0.788302	test: 0.663832

Epoch: 89
Loss: 0.08024022369260778
ROC train: 0.998186	val: 0.874034	test: 0.636092
PRC train: 0.999652	val: 0.795099	test: 0.652127

Epoch: 90
Loss: 0.08251434089021285
ROC train: 0.998258	val: 0.884473	test: 0.652199
PRC train: 0.999668	val: 0.797833	test: 0.661098

Epoch: 91
Loss: 0.093986251293607
ROC train: 0.998366	val: 0.884473	test: 0.661169
PRC train: 0.999691	val: 0.790720	test: 0.663539

Epoch: 92
Loss: 0.1007020321706563
ROC train: 0.998366	val: 0.880558	test: 0.648630
PRC train: 0.999691	val: 0.784365	test: 0.659883

Epoch: 93
Loss: 0.08249084954130904
ROC train: 0.997325	val: 0.885677	test: 0.650752
PRC train: 0.999492	val: 0.795979	test: 0.666762

Epoch: 94
Loss: 0.06829779960162079
ROC train: 0.997467	val: 0.881963	test: 0.661941
PRC train: 0.996445	val: 0.806460	test: 0.750598

Epoch: 34
Loss: 0.15465814444718282
ROC train: 0.983206	val: 0.893305	test: 0.686246
PRC train: 0.996596	val: 0.839038	test: 0.754695

Epoch: 35
Loss: 0.16769763999137868
ROC train: 0.984934	val: 0.879554	test: 0.709587
PRC train: 0.996938	val: 0.805604	test: 0.764098

Epoch: 36
Loss: 0.14974169399075515
ROC train: 0.984383	val: 0.893807	test: 0.731771
PRC train: 0.996802	val: 0.809038	test: 0.790697

Epoch: 37
Loss: 0.15971446434691575
ROC train: 0.984558	val: 0.880056	test: 0.692998
PRC train: 0.996818	val: 0.811953	test: 0.736410

Epoch: 38
Loss: 0.15131879568859333
ROC train: 0.987677	val: 0.877045	test: 0.693866
PRC train: 0.997555	val: 0.805044	test: 0.743566

Epoch: 39
Loss: 0.1431378797803056
ROC train: 0.987327	val: 0.878049	test: 0.705054
PRC train: 0.997505	val: 0.782936	test: 0.757496

Epoch: 40
Loss: 0.14672933419234102
ROC train: 0.986111	val: 0.881261	test: 0.710938
PRC train: 0.997251	val: 0.771060	test: 0.774537

Epoch: 41
Loss: 0.16051340268578837
ROC train: 0.986132	val: 0.885175	test: 0.703704
PRC train: 0.997242	val: 0.813418	test: 0.750176

Epoch: 42
Loss: 0.13618921477880977
ROC train: 0.986724	val: 0.887082	test: 0.696566
PRC train: 0.997394	val: 0.811506	test: 0.747787

Epoch: 43
Loss: 0.14091113367230695
ROC train: 0.986273	val: 0.891599	test: 0.707851
PRC train: 0.997291	val: 0.798854	test: 0.744543

Epoch: 44
Loss: 0.14399564782792978
ROC train: 0.989399	val: 0.890796	test: 0.707755
PRC train: 0.997916	val: 0.812064	test: 0.753717

Epoch: 45
Loss: 0.14758066233639353
ROC train: 0.988205	val: 0.886982	test: 0.717496
PRC train: 0.997660	val: 0.797458	test: 0.768263

Epoch: 46
Loss: 0.13784972600552223
ROC train: 0.988715	val: 0.884071	test: 0.689718
PRC train: 0.997747	val: 0.781967	test: 0.724114

Epoch: 47
Loss: 0.1447313168226543
ROC train: 0.990399	val: 0.887484	test: 0.701775
PRC train: 0.998093	val: 0.800189	test: 0.760560

Epoch: 48
Loss: 0.12781373221724135
ROC train: 0.984753	val: 0.890997	test: 0.701678
PRC train: 0.996981	val: 0.795647	test: 0.761456

Epoch: 49
Loss: 0.11952903925519351
ROC train: 0.990180	val: 0.890997	test: 0.710745
PRC train: 0.998042	val: 0.815886	test: 0.765708

Epoch: 50
Loss: 0.1369725735744179
ROC train: 0.990602	val: 0.900632	test: 0.724826
PRC train: 0.998137	val: 0.827354	test: 0.773528

Epoch: 51
Loss: 0.12301052286564572
ROC train: 0.989554	val: 0.907759	test: 0.711998
PRC train: 0.997922	val: 0.825833	test: 0.730070

Epoch: 52
Loss: 0.1233716441923821
ROC train: 0.990713	val: 0.897922	test: 0.697820
PRC train: 0.998145	val: 0.819599	test: 0.722481

Epoch: 53
Loss: 0.11029191276895868
ROC train: 0.989765	val: 0.899729	test: 0.702546
PRC train: 0.997951	val: 0.813788	test: 0.717487

Epoch: 54
Loss: 0.12544453164638586
ROC train: 0.992179	val: 0.893406	test: 0.701582
PRC train: 0.998430	val: 0.786779	test: 0.708740

Epoch: 55
Loss: 0.12255445044131116
ROC train: 0.993438	val: 0.888889	test: 0.712577
PRC train: 0.998713	val: 0.777834	test: 0.725172

Epoch: 56
Loss: 0.12594437159158134
ROC train: 0.993591	val: 0.878450	test: 0.718075
PRC train: 0.998743	val: 0.773541	test: 0.740583

Epoch: 57
Loss: 0.12346886785521749
ROC train: 0.992895	val: 0.891699	test: 0.719329
PRC train: 0.998630	val: 0.793806	test: 0.742170

Epoch: 58
Loss: 0.10615479495858317
ROC train: 0.992006	val: 0.875539	test: 0.699846
PRC train: 0.998462	val: 0.761063	test: 0.704782

Epoch: 59
Loss: 0.09652785653820896
ROC train: 0.992898	val: 0.884071	test: 0.702932
PRC train: 0.998625	val: 0.782941	test: 0.712694

Epoch: 60
Loss: 0.1126367745994649
ROC train: 0.992448	val: 0.896517	test: 0.694155
PRC train: 0.998481	val: 0.805451	test: 0.699053

Epoch: 61
Loss: 0.11358396111824597
ROC train: 0.994503	val: 0.893707	test: 0.700521
PRC train: 0.998916	val: 0.772427	test: 0.706075

Epoch: 62
Loss: 0.11024073483565723
ROC train: 0.994744	val: 0.893305	test: 0.693191
PRC train: 0.998976	val: 0.794363	test: 0.712190

Epoch: 63
Loss: 0.11139662559700596
ROC train: 0.993421	val: 0.893807	test: 0.691551
PRC train: 0.998707	val: 0.793909	test: 0.723056

Epoch: 64
Loss: 0.10677486649865664
ROC train: 0.993072	val: 0.881763	test: 0.694830
PRC train: 0.998630	val: 0.779426	test: 0.705921

Epoch: 65
Loss: 0.12130995779474876
ROC train: 0.994214	val: 0.884774	test: 0.695312
PRC train: 0.998880	val: 0.788531	test: 0.722967

Epoch: 66
Loss: 0.10831711770418158
ROC train: 0.994977	val: 0.881562	test: 0.704186
PRC train: 0.999023	val: 0.767096	test: 0.731392

Epoch: 67
Loss: 0.09990473094132066
ROC train: 0.993464	val: 0.879052	test: 0.719715
PRC train: 0.998728	val: 0.773733	test: 0.746208

Epoch: 68
Loss: 0.11204556747153045
ROC train: 0.993535	val: 0.884272	test: 0.714988
PRC train: 0.998738	val: 0.774498	test: 0.716138

Epoch: 69
Loss: 0.11067935031780533
ROC train: 0.994416	val: 0.874034	test: 0.707658
PRC train: 0.998899	val: 0.773294	test: 0.710949

Epoch: 70
Loss: 0.09910504943989569
ROC train: 0.994926	val: 0.877748	test: 0.715278
PRC train: 0.999012	val: 0.778813	test: 0.737939

Epoch: 71
Loss: 0.10431453552466483
ROC train: 0.996207	val: 0.888789	test: 0.708816
PRC train: 0.999264	val: 0.820273	test: 0.745509

Epoch: 72
Loss: 0.09533397019528693
ROC train: 0.996286	val: 0.888989	test: 0.709105
PRC train: 0.999285	val: 0.808272	test: 0.729032

Epoch: 73
Loss: 0.09193271580433027
ROC train: 0.996666	val: 0.885476	test: 0.706597
PRC train: 0.999361	val: 0.796049	test: 0.722417

Epoch: 74
Loss: 0.08893862003199995
ROC train: 0.996859	val: 0.884171	test: 0.696084
PRC train: 0.999400	val: 0.775491	test: 0.717244

Epoch: 75
Loss: 0.08819834547921332
ROC train: 0.996580	val: 0.888487	test: 0.698592
PRC train: 0.999348	val: 0.799159	test: 0.714143

Epoch: 76
Loss: 0.10319369991716974
ROC train: 0.995497	val: 0.893506	test: 0.704861
PRC train: 0.999121	val: 0.815656	test: 0.722411

Epoch: 77
Loss: 0.10102453616885623
ROC train: 0.996092	val: 0.884473	test: 0.718364
PRC train: 0.999241	val: 0.792019	test: 0.744211

Epoch: 78
Loss: 0.0841827877177075
ROC train: 0.997363	val: 0.884573	test: 0.725694
PRC train: 0.999496	val: 0.802373	test: 0.762428

Epoch: 79
Loss: 0.09337427784061755
ROC train: 0.996298	val: 0.889391	test: 0.714988
PRC train: 0.999288	val: 0.822489	test: 0.746241

Epoch: 80
Loss: 0.08719026292747552
ROC train: 0.996450	val: 0.900231	test: 0.685957
PRC train: 0.999322	val: 0.828657	test: 0.705329

Epoch: 81
Loss: 0.08442870233097514
ROC train: 0.996986	val: 0.885075	test: 0.696566
PRC train: 0.999426	val: 0.802004	test: 0.706942

Epoch: 82
Loss: 0.09087458548793045
ROC train: 0.997225	val: 0.879052	test: 0.702932
PRC train: 0.999472	val: 0.790477	test: 0.719171

Epoch: 83
Loss: 0.09704196933200734
ROC train: 0.997715	val: 0.865703	test: 0.697917
PRC train: 0.999566	val: 0.765013	test: 0.712496

Epoch: 84
Loss: 0.09810425180814453
ROC train: 0.996880	val: 0.885376	test: 0.698110
PRC train: 0.999406	val: 0.803515	test: 0.722009

Epoch: 85
Loss: 0.08239262065364658
ROC train: 0.997538	val: 0.884171	test: 0.697434
PRC train: 0.999534	val: 0.785980	test: 0.719903

Epoch: 86
Loss: 0.08814371188907341
ROC train: 0.997641	val: 0.882365	test: 0.671971
PRC train: 0.999551	val: 0.782005	test: 0.687310

Epoch: 87
Loss: 0.07917099708650667
ROC train: 0.997951	val: 0.881963	test: 0.691551
PRC train: 0.999610	val: 0.789908	test: 0.705512

Epoch: 88
Loss: 0.09092504422834342
ROC train: 0.997787	val: 0.871424	test: 0.699363
PRC train: 0.999578	val: 0.783811	test: 0.711298

Epoch: 89
Loss: 0.0769067266455322
ROC train: 0.997819	val: 0.875138	test: 0.700617
PRC train: 0.999585	val: 0.791032	test: 0.713530

Epoch: 90
Loss: 0.07577569609193001
ROC train: 0.997833	val: 0.878751	test: 0.692612
PRC train: 0.999589	val: 0.791904	test: 0.736231

Epoch: 91
Loss: 0.08168730982799476
ROC train: 0.997056	val: 0.879354	test: 0.695988
PRC train: 0.999444	val: 0.790973	test: 0.730135

Epoch: 92
Loss: 0.08785125219323896
ROC train: 0.996829	val: 0.876644	test: 0.697917
PRC train: 0.999395	val: 0.796220	test: 0.736603

Epoch: 93
Loss: 0.08367502259984974
ROC train: 0.997718	val: 0.867610	test: 0.696952
PRC train: 0.999566	val: 0.778740	test: 0.741059

Epoch: 94
Loss: 0.09007550960243993
ROC train: 0.997258	val: 0.884372	test: 0.691069
PRC train: 0.996111	val: 0.803089	test: 0.715799

Epoch: 34
Loss: 0.15918109692917545
ROC train: 0.985384	val: 0.892302	test: 0.702836
PRC train: 0.996834	val: 0.811599	test: 0.722683

Epoch: 35
Loss: 0.15490293971743396
ROC train: 0.984666	val: 0.901435	test: 0.702450
PRC train: 0.996592	val: 0.829485	test: 0.725158

Epoch: 36
Loss: 0.16815205628346178
ROC train: 0.985587	val: 0.901034	test: 0.679205
PRC train: 0.997069	val: 0.833213	test: 0.686452

Epoch: 37
Loss: 0.144373127023508
ROC train: 0.986794	val: 0.901235	test: 0.695602
PRC train: 0.997303	val: 0.841762	test: 0.716764

Epoch: 38
Loss: 0.16093842256525676
ROC train: 0.986489	val: 0.898826	test: 0.692805
PRC train: 0.997257	val: 0.830749	test: 0.698032

Epoch: 39
Loss: 0.13359166953106633
ROC train: 0.988119	val: 0.897320	test: 0.698688
PRC train: 0.997617	val: 0.824694	test: 0.717737

Epoch: 40
Loss: 0.14512000712257356
ROC train: 0.985391	val: 0.892101	test: 0.706597
PRC train: 0.997072	val: 0.788791	test: 0.733331

Epoch: 41
Loss: 0.13904632855588828
ROC train: 0.989577	val: 0.900231	test: 0.695312
PRC train: 0.997916	val: 0.825070	test: 0.713680

Epoch: 42
Loss: 0.13352746320472877
ROC train: 0.990651	val: 0.897521	test: 0.682581
PRC train: 0.998151	val: 0.839073	test: 0.704278

Epoch: 43
Loss: 0.12727088061586653
ROC train: 0.989860	val: 0.899829	test: 0.684992
PRC train: 0.997992	val: 0.844304	test: 0.699865

Epoch: 44
Loss: 0.13600429683947174
ROC train: 0.990936	val: 0.900833	test: 0.698592
PRC train: 0.998223	val: 0.842031	test: 0.706164

Epoch: 45
Loss: 0.12679520325821123
ROC train: 0.990261	val: 0.896919	test: 0.691454
PRC train: 0.998092	val: 0.808698	test: 0.684360

Epoch: 46
Loss: 0.14055089195992526
ROC train: 0.992664	val: 0.899328	test: 0.695409
PRC train: 0.998564	val: 0.849110	test: 0.714579

Epoch: 47
Loss: 0.1304026446532888
ROC train: 0.988217	val: 0.897320	test: 0.698110
PRC train: 0.997665	val: 0.833354	test: 0.702578

Epoch: 48
Loss: 0.12916828528800242
ROC train: 0.992048	val: 0.902339	test: 0.699653
PRC train: 0.998441	val: 0.847001	test: 0.732953

Epoch: 49
Loss: 0.12151731020633345
ROC train: 0.992960	val: 0.893406	test: 0.704958
PRC train: 0.998627	val: 0.827186	test: 0.735557

Epoch: 50
Loss: 0.11150467296868231
ROC train: 0.989995	val: 0.881160	test: 0.693962
PRC train: 0.998047	val: 0.784244	test: 0.694541

Epoch: 51
Loss: 0.12533448260784244
ROC train: 0.992041	val: 0.880157	test: 0.690972
PRC train: 0.998454	val: 0.782533	test: 0.689738

Epoch: 52
Loss: 0.11162307585902645
ROC train: 0.993705	val: 0.901536	test: 0.698978
PRC train: 0.998764	val: 0.815075	test: 0.710712

Epoch: 53
Loss: 0.116113093321209
ROC train: 0.992517	val: 0.907859	test: 0.703607
PRC train: 0.998534	val: 0.844640	test: 0.735420

Epoch: 54
Loss: 0.1202750300251436
ROC train: 0.993964	val: 0.888387	test: 0.705247
PRC train: 0.998832	val: 0.801112	test: 0.722456

Epoch: 55
Loss: 0.11036225962008055
ROC train: 0.994796	val: 0.882164	test: 0.689622
PRC train: 0.999002	val: 0.798220	test: 0.703206

Epoch: 56
Loss: 0.12234570509957376
ROC train: 0.993100	val: 0.873532	test: 0.699267
PRC train: 0.998690	val: 0.787744	test: 0.713316

Epoch: 57
Loss: 0.1307422548774691
ROC train: 0.991197	val: 0.882867	test: 0.685667
PRC train: 0.998284	val: 0.789841	test: 0.680396

Epoch: 58
Loss: 0.11629260734550513
ROC train: 0.994973	val: 0.877045	test: 0.689815
PRC train: 0.999037	val: 0.778277	test: 0.717399

Epoch: 59
Loss: 0.1155590692544417
ROC train: 0.994246	val: 0.880558	test: 0.705247
PRC train: 0.998912	val: 0.795802	test: 0.722647

Epoch: 60
Loss: 0.10564808291357879
ROC train: 0.994076	val: 0.892603	test: 0.684703
PRC train: 0.998868	val: 0.839794	test: 0.698428

Epoch: 61
Loss: 0.11373835174698334
ROC train: 0.994670	val: 0.908261	test: 0.694059
PRC train: 0.998980	val: 0.870528	test: 0.716760

Epoch: 62
Loss: 0.11021376700716115
ROC train: 0.994360	val: 0.900130	test: 0.700810
PRC train: 0.998921	val: 0.841454	test: 0.744813

Epoch: 63
Loss: 0.10958261811580829
ROC train: 0.995307	val: 0.900833	test: 0.696084
PRC train: 0.999099	val: 0.848043	test: 0.734988

Epoch: 64
Loss: 0.11315929866099503
ROC train: 0.994328	val: 0.892703	test: 0.703607
PRC train: 0.998917	val: 0.836914	test: 0.732171

Epoch: 65
Loss: 0.09721545945319153
ROC train: 0.995830	val: 0.889792	test: 0.696759
PRC train: 0.999196	val: 0.825186	test: 0.703884

Epoch: 66
Loss: 0.11320542094643457
ROC train: 0.995897	val: 0.885476	test: 0.693383
PRC train: 0.999212	val: 0.796730	test: 0.677494

Epoch: 67
Loss: 0.10915941008865856
ROC train: 0.995279	val: 0.883569	test: 0.715760
PRC train: 0.999110	val: 0.789429	test: 0.732349

Epoch: 68
Loss: 0.10282721229833462
ROC train: 0.996273	val: 0.891800	test: 0.713059
PRC train: 0.999297	val: 0.805539	test: 0.711184

Epoch: 69
Loss: 0.1086322145377259
ROC train: 0.996768	val: 0.904346	test: 0.686053
PRC train: 0.999389	val: 0.829275	test: 0.687588

Epoch: 70
Loss: 0.10274643586679676
ROC train: 0.995273	val: 0.881361	test: 0.668789
PRC train: 0.999102	val: 0.803754	test: 0.664522

Epoch: 71
Loss: 0.08767905415213299
ROC train: 0.996649	val: 0.889792	test: 0.671971
PRC train: 0.999363	val: 0.822472	test: 0.668883

Epoch: 72
Loss: 0.09664903981405275
ROC train: 0.996916	val: 0.878551	test: 0.687500
PRC train: 0.999408	val: 0.784407	test: 0.682687

Epoch: 73
Loss: 0.09343657887954229
ROC train: 0.995424	val: 0.886781	test: 0.695120
PRC train: 0.999093	val: 0.779414	test: 0.697741

Epoch: 74
Loss: 0.0857110815605404
ROC train: 0.996395	val: 0.887082	test: 0.679880
PRC train: 0.999303	val: 0.789800	test: 0.666776

Epoch: 75
Loss: 0.10952902978641206
ROC train: 0.997990	val: 0.869216	test: 0.679977
PRC train: 0.999618	val: 0.764321	test: 0.677997

Epoch: 76
Loss: 0.08748628364807755
ROC train: 0.995945	val: 0.888287	test: 0.694734
PRC train: 0.999227	val: 0.799211	test: 0.696798

Epoch: 77
Loss: 0.09249440274737356
ROC train: 0.996082	val: 0.868212	test: 0.696952
PRC train: 0.999248	val: 0.761596	test: 0.696807

Epoch: 78
Loss: 0.09704933139300255
ROC train: 0.997193	val: 0.884774	test: 0.687500
PRC train: 0.999463	val: 0.784349	test: 0.690110

Epoch: 79
Loss: 0.08524570652644105
ROC train: 0.997932	val: 0.896617	test: 0.689718
PRC train: 0.999604	val: 0.825627	test: 0.709326

Epoch: 80
Loss: 0.089280558368699
ROC train: 0.997906	val: 0.893707	test: 0.703029
PRC train: 0.999601	val: 0.805394	test: 0.718915

Epoch: 81
Loss: 0.09332709107165593
ROC train: 0.998155	val: 0.887383	test: 0.678530
PRC train: 0.999647	val: 0.785928	test: 0.680379

Epoch: 82
Loss: 0.0784308909674757
ROC train: 0.997102	val: 0.879755	test: 0.672068
PRC train: 0.999438	val: 0.792229	test: 0.674492

Epoch: 83
Loss: 0.07933922260593493
ROC train: 0.996847	val: 0.892402	test: 0.681231
PRC train: 0.999368	val: 0.821151	test: 0.695359

Epoch: 84
Loss: 0.09942457677119376
ROC train: 0.997429	val: 0.894610	test: 0.689236
PRC train: 0.999508	val: 0.819565	test: 0.701222

Epoch: 85
Loss: 0.08987041736296587
ROC train: 0.996851	val: 0.889491	test: 0.692515
PRC train: 0.999401	val: 0.811970	test: 0.718549

Epoch: 86
Loss: 0.08147462844558531
ROC train: 0.997980	val: 0.875640	test: 0.688754
PRC train: 0.999615	val: 0.814361	test: 0.717328

Epoch: 87
Loss: 0.08612421306010817
ROC train: 0.998468	val: 0.861488	test: 0.685185
PRC train: 0.999706	val: 0.786484	test: 0.702511

Epoch: 88
Loss: 0.08976650144365782
ROC train: 0.998656	val: 0.872127	test: 0.673418
PRC train: 0.999743	val: 0.780557	test: 0.673688

Epoch: 89
Loss: 0.08678845994296745
ROC train: 0.997603	val: 0.868614	test: 0.692419
PRC train: 0.999541	val: 0.775274	test: 0.708518

Epoch: 90
Loss: 0.0768953513554845
ROC train: 0.998031	val: 0.881963	test: 0.684703
PRC train: 0.999627	val: 0.812346	test: 0.719015

Epoch: 91
Loss: 0.08074133219200695
ROC train: 0.997666	val: 0.876644	test: 0.686728
PRC train: 0.999557	val: 0.815590	test: 0.681313

Epoch: 92
Loss: 0.08509019043068909
ROC train: 0.997148	val: 0.851751	test: 0.684317
PRC train: 0.999458	val: 0.724798	test: 0.661164

Epoch: 93
Loss: 0.0826869102734904
ROC train: 0.996505	val: 0.879554	test: 0.698881
PRC train: 0.999332	val: 0.796952	test: 0.691950

Epoch: 94
Loss: 0.0793664830132572
ROC train: 0.998047	val: 0.888387	test: 0.691551
PRC train: 0.999726	val: 0.828917	test: 0.697804

Epoch: 33
Loss: 0.12475446761355002
ROC train: 0.997876	val: 0.895915	test: 0.678530
PRC train: 0.999595	val: 0.809205	test: 0.743595

Epoch: 34
Loss: 0.11253583259392996
ROC train: 0.999057	val: 0.895313	test: 0.676215
PRC train: 0.999823	val: 0.819051	test: 0.732629

Epoch: 35
Loss: 0.11361366829274573
ROC train: 0.999355	val: 0.905049	test: 0.670718
PRC train: 0.999878	val: 0.827843	test: 0.721959

Epoch: 36
Loss: 0.10963684594831727
ROC train: 0.998760	val: 0.894309	test: 0.661073
PRC train: 0.999764	val: 0.801465	test: 0.708130

Epoch: 37
Loss: 0.10073897919885318
ROC train: 0.999557	val: 0.891097	test: 0.652296
PRC train: 0.999917	val: 0.807439	test: 0.697897

Epoch: 38
Loss: 0.10381087840351681
ROC train: 0.999515	val: 0.907458	test: 0.645158
PRC train: 0.999908	val: 0.822356	test: 0.690246

Epoch: 39
Loss: 0.09958857169550968
ROC train: 0.996911	val: 0.893606	test: 0.665413
PRC train: 0.999378	val: 0.782752	test: 0.733067

Epoch: 40
Loss: 0.10080064269005806
ROC train: 0.999613	val: 0.896015	test: 0.671875
PRC train: 0.999926	val: 0.806884	test: 0.747531

Epoch: 41
Loss: 0.10070041123043456
ROC train: 0.998937	val: 0.904848	test: 0.657793
PRC train: 0.999793	val: 0.829132	test: 0.719313

Epoch: 42
Loss: 0.09415381653638175
ROC train: 0.999436	val: 0.910469	test: 0.652296
PRC train: 0.999892	val: 0.845356	test: 0.707429

Epoch: 43
Loss: 0.09822192269272871
ROC train: 0.999902	val: 0.905350	test: 0.652296
PRC train: 0.999981	val: 0.837375	test: 0.701777

Epoch: 44
Loss: 0.07775138122399229
ROC train: 0.999649	val: 0.891599	test: 0.650174
PRC train: 0.999934	val: 0.811254	test: 0.716815

Epoch: 45
Loss: 0.08476748557298754
ROC train: 0.999837	val: 0.901435	test: 0.639275
PRC train: 0.999969	val: 0.834763	test: 0.703532

Epoch: 46
Loss: 0.07733670613497552
ROC train: 0.999728	val: 0.907357	test: 0.630691
PRC train: 0.999949	val: 0.838493	test: 0.669955

Epoch: 47
Loss: 0.07122858054219604
ROC train: 0.999666	val: 0.894811	test: 0.635899
PRC train: 0.999937	val: 0.806756	test: 0.688319

Epoch: 48
Loss: 0.057307581513763105
ROC train: 0.999815	val: 0.909766	test: 0.647955
PRC train: 0.999966	val: 0.832080	test: 0.699871

Epoch: 49
Loss: 0.07376263884602915
ROC train: 0.999846	val: 0.899428	test: 0.638407
PRC train: 0.999971	val: 0.831650	test: 0.685541

Epoch: 50
Loss: 0.06052235622996076
ROC train: 0.999983	val: 0.893205	test: 0.647280
PRC train: 0.999997	val: 0.819277	test: 0.706116

Epoch: 51
Loss: 0.06395011851643449
ROC train: 0.999992	val: 0.896718	test: 0.654900
PRC train: 0.999998	val: 0.820668	test: 0.697518

Epoch: 52
Loss: 0.07391879648053146
ROC train: 0.999992	val: 0.896718	test: 0.648052
PRC train: 0.999998	val: 0.829672	test: 0.676551

Epoch: 53
Loss: 0.08484028189003477
ROC train: 0.999978	val: 0.908662	test: 0.638407
PRC train: 0.999996	val: 0.851707	test: 0.680123

Epoch: 54
Loss: 0.0660192585520169
ROC train: 0.999955	val: 0.915287	test: 0.643519
PRC train: 0.999991	val: 0.857627	test: 0.672306

Epoch: 55
Loss: 0.06642893521038931
ROC train: 0.999992	val: 0.890394	test: 0.656250
PRC train: 0.999998	val: 0.811954	test: 0.710922

Epoch: 56
Loss: 0.06323250862799454
ROC train: 1.000000	val: 0.893004	test: 0.649402
PRC train: 1.000000	val: 0.815703	test: 0.699426

Epoch: 57
Loss: 0.05570631565083226
ROC train: 0.999983	val: 0.896919	test: 0.650174
PRC train: 0.999997	val: 0.831404	test: 0.694560

Epoch: 58
Loss: 0.07714460738273317
ROC train: 0.999916	val: 0.879956	test: 0.638021
PRC train: 0.999984	val: 0.788993	test: 0.690194

Epoch: 59
Loss: 0.06592831904210006
ROC train: 0.999489	val: 0.865201	test: 0.650367
PRC train: 0.999904	val: 0.759795	test: 0.689909

Epoch: 60
Loss: 0.07357654107034174
ROC train: 0.999638	val: 0.910971	test: 0.673225
PRC train: 0.999934	val: 0.823971	test: 0.712084

Epoch: 61
Loss: 0.07283065986668213
ROC train: 0.999994	val: 0.896919	test: 0.660397
PRC train: 0.999999	val: 0.823013	test: 0.678586

Epoch: 62
Loss: 0.06245313919401396
ROC train: 1.000000	val: 0.889893	test: 0.642554
PRC train: 1.000000	val: 0.812624	test: 0.678607

Epoch: 63
Loss: 0.054163718088309956
ROC train: 0.999989	val: 0.899729	test: 0.638310
PRC train: 0.999998	val: 0.834071	test: 0.675213

Epoch: 64
Loss: 0.04877788425388333
ROC train: 1.000000	val: 0.895614	test: 0.629726
PRC train: 1.000000	val: 0.832873	test: 0.672209

Epoch: 65
Loss: 0.05460761963244947
ROC train: 0.999094	val: 0.881662	test: 0.634163
PRC train: 0.999821	val: 0.807777	test: 0.677462

Epoch: 66
Loss: 0.057029576485458935
ROC train: 0.999868	val: 0.894409	test: 0.652778
PRC train: 0.999975	val: 0.835229	test: 0.709417

Epoch: 67
Loss: 0.05051817215935391
ROC train: 1.000000	val: 0.903142	test: 0.652006
PRC train: 1.000000	val: 0.847893	test: 0.708252

Epoch: 68
Loss: 0.044862435579848314
ROC train: 1.000000	val: 0.909766	test: 0.663194
PRC train: 1.000000	val: 0.846547	test: 0.719047

Epoch: 69
Loss: 0.04972742126569289
ROC train: 1.000000	val: 0.904848	test: 0.655189
PRC train: 1.000000	val: 0.846948	test: 0.699085

Epoch: 70
Loss: 0.06129563532945432
ROC train: 1.000000	val: 0.898525	test: 0.643229
PRC train: 1.000000	val: 0.838433	test: 0.687135

Epoch: 71
Loss: 0.056166632354086185
ROC train: 0.999795	val: 0.893506	test: 0.659240
PRC train: 0.999962	val: 0.817036	test: 0.693105

Epoch: 72
Loss: 0.04639500050879154
ROC train: 0.999980	val: 0.905952	test: 0.660204
PRC train: 0.999996	val: 0.845434	test: 0.699934

Epoch: 73
Loss: 0.04507975725239472
ROC train: 1.000000	val: 0.908461	test: 0.665123
PRC train: 1.000000	val: 0.848329	test: 0.695968

Epoch: 74
Loss: 0.04327421339283068
ROC train: 0.999997	val: 0.900933	test: 0.663484
PRC train: 0.999999	val: 0.832103	test: 0.681127

Epoch: 75
Loss: 0.03230866546311081
ROC train: 0.999983	val: 0.891800	test: 0.647762
PRC train: 0.999997	val: 0.828093	test: 0.644852

Epoch: 76
Loss: 0.04059922393311117
ROC train: 0.999921	val: 0.891398	test: 0.637056
PRC train: 0.999985	val: 0.830418	test: 0.655180

Epoch: 77
Loss: 0.04739890881815154
ROC train: 1.000000	val: 0.904246	test: 0.647569
PRC train: 1.000000	val: 0.848984	test: 0.697857

Epoch: 78
Loss: 0.03332217600494551
ROC train: 1.000000	val: 0.909867	test: 0.669850
PRC train: 1.000000	val: 0.857258	test: 0.722211

Epoch: 79
Loss: 0.032693932402145486
ROC train: 1.000000	val: 0.909666	test: 0.669753
PRC train: 1.000000	val: 0.845135	test: 0.727173

Epoch: 80
Loss: 0.03181565629666639
ROC train: 1.000000	val: 0.908662	test: 0.669753
PRC train: 1.000000	val: 0.831436	test: 0.718715

Epoch: 81
Loss: 0.02999305712518931
ROC train: 1.000000	val: 0.910067	test: 0.663098
PRC train: 1.000000	val: 0.832661	test: 0.706595

Epoch: 82
Loss: 0.03968969474791718
ROC train: 1.000000	val: 0.910669	test: 0.656636
PRC train: 1.000000	val: 0.846824	test: 0.692436

Epoch: 83
Loss: 0.030879341297479792
ROC train: 1.000000	val: 0.906052	test: 0.658951
PRC train: 1.000000	val: 0.836004	test: 0.673126

Epoch: 84
Loss: 0.040870098965905786
ROC train: 1.000000	val: 0.895012	test: 0.667535
PRC train: 1.000000	val: 0.812151	test: 0.686379

Epoch: 85
Loss: 0.03277254230251808
ROC train: 1.000000	val: 0.895112	test: 0.669464
PRC train: 1.000000	val: 0.827454	test: 0.703484

Epoch: 86
Loss: 0.032849692784719504
ROC train: 0.999978	val: 0.898725	test: 0.671103
PRC train: 0.999996	val: 0.838077	test: 0.691448

Epoch: 87
Loss: 0.03152962607356149
ROC train: 1.000000	val: 0.898424	test: 0.676312
PRC train: 1.000000	val: 0.838528	test: 0.721449

Epoch: 88
Loss: 0.034676847994281335
ROC train: 1.000000	val: 0.900231	test: 0.670718
PRC train: 1.000000	val: 0.831732	test: 0.724855

Epoch: 89
Loss: 0.02859515879599243
ROC train: 0.999997	val: 0.902640	test: 0.656346
PRC train: 0.999999	val: 0.832408	test: 0.693170

Epoch: 90
Loss: 0.026002991835512045
ROC train: 1.000000	val: 0.899428	test: 0.655671
PRC train: 1.000000	val: 0.831204	test: 0.688945

Epoch: 91
Loss: 0.04189877517108871
ROC train: 1.000000	val: 0.899729	test: 0.667245
PRC train: 1.000000	val: 0.822862	test: 0.704674

Epoch: 92
Loss: 0.03174582556615383
ROC train: 0.999997	val: 0.900030	test: 0.659722
PRC train: 0.999999	val: 0.826952	test: 0.691774

Epoch: 93
Loss: 0.02097268948312566
PRC train: 0.999795	val: 0.855504	test: 0.774269

Epoch: 33
Loss: 0.10113768912502637
ROC train: 0.996819	val: 0.900532	test: 0.697049
PRC train: 0.999396	val: 0.830296	test: 0.766261

Epoch: 34
Loss: 0.10507235934055435
ROC train: 0.998788	val: 0.890595	test: 0.697531
PRC train: 0.999767	val: 0.812657	test: 0.782180

Epoch: 35
Loss: 0.12869942182015473
ROC train: 0.998336	val: 0.895714	test: 0.697531
PRC train: 0.999677	val: 0.839641	test: 0.781026

Epoch: 36
Loss: 0.0984504358479815
ROC train: 0.998945	val: 0.907156	test: 0.711709
PRC train: 0.999790	val: 0.859563	test: 0.778734

Epoch: 37
Loss: 0.09621300396328056
ROC train: 0.999341	val: 0.895714	test: 0.709491
PRC train: 0.999871	val: 0.822407	test: 0.773432

Epoch: 38
Loss: 0.08082676128635886
ROC train: 0.998796	val: 0.875038	test: 0.696277
PRC train: 0.999758	val: 0.782735	test: 0.761973

Epoch: 39
Loss: 0.08710461635055863
ROC train: 0.999571	val: 0.878250	test: 0.675058
PRC train: 0.999916	val: 0.791481	test: 0.750423

Epoch: 40
Loss: 0.07992305273547733
ROC train: 0.999007	val: 0.905149	test: 0.686439
PRC train: 0.999811	val: 0.843247	test: 0.767909

Epoch: 41
Loss: 0.07900778597133766
ROC train: 0.999694	val: 0.910268	test: 0.690008
PRC train: 0.999942	val: 0.854053	test: 0.765225

Epoch: 42
Loss: 0.07594241207814875
ROC train: 0.999532	val: 0.912275	test: 0.683256
PRC train: 0.999910	val: 0.845660	test: 0.742231

Epoch: 43
Loss: 0.09218372849480419
ROC train: 0.999526	val: 0.913781	test: 0.690779
PRC train: 0.999909	val: 0.865258	test: 0.749627

Epoch: 44
Loss: 0.06925399016574815
ROC train: 0.999632	val: 0.915387	test: 0.689911
PRC train: 0.999930	val: 0.871860	test: 0.757741

Epoch: 45
Loss: 0.0787206762082393
ROC train: 0.999624	val: 0.907658	test: 0.685282
PRC train: 0.999929	val: 0.864212	test: 0.753537

Epoch: 46
Loss: 0.07579372971234213
ROC train: 0.998482	val: 0.891398	test: 0.674961
PRC train: 0.999694	val: 0.853633	test: 0.741852

Epoch: 47
Loss: 0.08351840516682564
ROC train: 0.999708	val: 0.895313	test: 0.701678
PRC train: 0.999944	val: 0.853504	test: 0.778097

Epoch: 48
Loss: 0.07484272271533225
ROC train: 0.999818	val: 0.879253	test: 0.696856
PRC train: 0.999965	val: 0.833188	test: 0.771019

Epoch: 49
Loss: 0.07149469259677003
ROC train: 0.999916	val: 0.889190	test: 0.681520
PRC train: 0.999984	val: 0.847723	test: 0.756548

Epoch: 50
Loss: 0.05163720681313951
ROC train: 0.999790	val: 0.894811	test: 0.688947
PRC train: 0.999960	val: 0.857758	test: 0.755782

Epoch: 51
Loss: 0.07231434487039591
ROC train: 0.999994	val: 0.888287	test: 0.672647
PRC train: 0.999999	val: 0.839229	test: 0.745324

Epoch: 52
Loss: 0.06722684383938027
ROC train: 0.999989	val: 0.884071	test: 0.674672
PRC train: 0.999998	val: 0.832673	test: 0.744061

Epoch: 53
Loss: 0.061654204356140996
ROC train: 0.999899	val: 0.898223	test: 0.677180
PRC train: 0.999981	val: 0.848557	test: 0.743336

Epoch: 54
Loss: 0.04886204909958481
ROC train: 0.999989	val: 0.884071	test: 0.669850
PRC train: 0.999998	val: 0.811958	test: 0.752127

Epoch: 55
Loss: 0.0695517156121455
ROC train: 0.999992	val: 0.896517	test: 0.676698
PRC train: 0.999998	val: 0.834701	test: 0.750038

Epoch: 56
Loss: 0.06916854172833062
ROC train: 1.000000	val: 0.893406	test: 0.675829
PRC train: 1.000000	val: 0.849742	test: 0.726212

Epoch: 57
Loss: 0.053841384663114424
ROC train: 1.000000	val: 0.894409	test: 0.687500
PRC train: 1.000000	val: 0.845715	test: 0.750325

Epoch: 58
Loss: 0.06147583662565413
ROC train: 0.999950	val: 0.881662	test: 0.682870
PRC train: 0.999990	val: 0.824842	test: 0.754518

Epoch: 59
Loss: 0.053384981357555934
ROC train: 1.000000	val: 0.890093	test: 0.685860
PRC train: 1.000000	val: 0.835453	test: 0.756980

Epoch: 60
Loss: 0.06321664034426026
ROC train: 1.000000	val: 0.900331	test: 0.682581
PRC train: 1.000000	val: 0.861626	test: 0.750798

Epoch: 61
Loss: 0.03840671811490404
ROC train: 0.999994	val: 0.895413	test: 0.670332
PRC train: 0.999999	val: 0.853929	test: 0.740169

Epoch: 62
Loss: 0.043784946866352766
ROC train: 0.999893	val: 0.888086	test: 0.663002
PRC train: 0.999980	val: 0.847465	test: 0.727716

Epoch: 63
Loss: 0.04166551751681937
ROC train: 0.999997	val: 0.900432	test: 0.676794
PRC train: 0.999999	val: 0.867707	test: 0.749224

Epoch: 64
Loss: 0.04162493579965225
ROC train: 0.999989	val: 0.887484	test: 0.686246
PRC train: 0.999998	val: 0.848283	test: 0.754337

Epoch: 65
Loss: 0.04285484788426545
ROC train: 0.999955	val: 0.872428	test: 0.670235
PRC train: 0.999992	val: 0.825104	test: 0.745399

Epoch: 66
Loss: 0.034363422266057396
ROC train: 1.000000	val: 0.882465	test: 0.664255
PRC train: 1.000000	val: 0.839594	test: 0.738949

Epoch: 67
Loss: 0.03511490479353332
ROC train: 1.000000	val: 0.902439	test: 0.670910
PRC train: 1.000000	val: 0.851951	test: 0.740923

Epoch: 68
Loss: 0.026184633881828588
ROC train: 0.999992	val: 0.899328	test: 0.678530
PRC train: 0.999998	val: 0.846234	test: 0.743260

Epoch: 69
Loss: 0.032672605791857746
ROC train: 1.000000	val: 0.884272	test: 0.677469
PRC train: 1.000000	val: 0.830692	test: 0.732184

Epoch: 70
Loss: 0.031055093615550675
ROC train: 1.000000	val: 0.895614	test: 0.686246
PRC train: 1.000000	val: 0.832367	test: 0.744359

Epoch: 71
Loss: 0.0332054650664273
ROC train: 1.000000	val: 0.897822	test: 0.674769
PRC train: 1.000000	val: 0.840829	test: 0.742420

Epoch: 72
Loss: 0.04192705919046475
ROC train: 1.000000	val: 0.894610	test: 0.670235
PRC train: 1.000000	val: 0.841949	test: 0.743526

Epoch: 73
Loss: 0.030346425872455157
ROC train: 0.999882	val: 0.898223	test: 0.687596
PRC train: 0.999978	val: 0.845757	test: 0.757146

Epoch: 74
Loss: 0.04274306896111411
ROC train: 0.999994	val: 0.893004	test: 0.684510
PRC train: 0.999999	val: 0.840544	test: 0.748863

Epoch: 75
Loss: 0.04049973337971709
ROC train: 0.999989	val: 0.901736	test: 0.676601
PRC train: 0.999998	val: 0.863331	test: 0.732767

Epoch: 76
Loss: 0.040507775892489724
ROC train: 1.000000	val: 0.889591	test: 0.670235
PRC train: 1.000000	val: 0.823082	test: 0.732589

Epoch: 77
Loss: 0.03510694091346535
ROC train: 1.000000	val: 0.893205	test: 0.679109
PRC train: 1.000000	val: 0.810674	test: 0.740536

Epoch: 78
Loss: 0.02984664299136377
ROC train: 0.999997	val: 0.887383	test: 0.682388
PRC train: 0.999999	val: 0.810929	test: 0.742428

Epoch: 79
Loss: 0.04206243002858361
ROC train: 1.000000	val: 0.899428	test: 0.689911
PRC train: 1.000000	val: 0.851545	test: 0.752534

Epoch: 80
Loss: 0.03978777036432642
ROC train: 1.000000	val: 0.916090	test: 0.692226
PRC train: 1.000000	val: 0.871596	test: 0.754435

Epoch: 81
Loss: 0.05476465165834248
ROC train: 1.000000	val: 0.924621	test: 0.689429
PRC train: 1.000000	val: 0.877113	test: 0.757059

Epoch: 82
Loss: 0.04793890594083725
ROC train: 0.999997	val: 0.918197	test: 0.684221
PRC train: 0.999999	val: 0.868992	test: 0.753924

Epoch: 83
Loss: 0.040785326872193446
ROC train: 0.999994	val: 0.900130	test: 0.671875
PRC train: 0.999999	val: 0.850268	test: 0.743702

Epoch: 84
Loss: 0.059943858186569346
ROC train: 1.000000	val: 0.877848	test: 0.672261
PRC train: 1.000000	val: 0.823125	test: 0.737770

Epoch: 85
Loss: 0.04478616586314798
ROC train: 1.000000	val: 0.867911	test: 0.677469
PRC train: 1.000000	val: 0.803852	test: 0.739390

Epoch: 86
Loss: 0.051669404883147495
ROC train: 1.000000	val: 0.884974	test: 0.678048
PRC train: 1.000000	val: 0.828350	test: 0.751814

Epoch: 87
Loss: 0.02868463228773536
ROC train: 1.000000	val: 0.878049	test: 0.690394
PRC train: 1.000000	val: 0.828170	test: 0.763293

Epoch: 88
Loss: 0.03375845306330958
ROC train: 1.000000	val: 0.888789	test: 0.685667
PRC train: 1.000000	val: 0.842725	test: 0.768966

Epoch: 89
Loss: 0.026516623186005093
ROC train: 0.999986	val: 0.909164	test: 0.698206
PRC train: 0.999997	val: 0.869186	test: 0.759056

Epoch: 90
Loss: 0.03029714085181659
ROC train: 1.000000	val: 0.893406	test: 0.691454
PRC train: 1.000000	val: 0.845693	test: 0.769230

Epoch: 91
Loss: 0.03001872108230613
ROC train: 0.999994	val: 0.892703	test: 0.690779
PRC train: 0.999999	val: 0.844146	test: 0.754797

Epoch: 92
Loss: 0.025947198952712337
ROC train: 0.999992	val: 0.901134	test: 0.686632
PRC train: 0.999998	val: 0.854130	test: 0.757991

Epoch: 93
Loss: 0.019765139400199954
PRC train: 0.998698	val: 0.825581	test: 0.710201

Epoch: 33
Loss: 0.12061479197594291
ROC train: 0.995096	val: 0.891599	test: 0.679880
PRC train: 0.998955	val: 0.799255	test: 0.726297

Epoch: 34
Loss: 0.11309668077166164
ROC train: 0.994973	val: 0.895915	test: 0.690683
PRC train: 0.998933	val: 0.802045	test: 0.730915

Epoch: 35
Loss: 0.13491673449207486
ROC train: 0.996033	val: 0.914885	test: 0.702257
PRC train: 0.999169	val: 0.847115	test: 0.754356

Epoch: 36
Loss: 0.11470579370443675
ROC train: 0.996325	val: 0.928937	test: 0.700521
PRC train: 0.999230	val: 0.878896	test: 0.747665

Epoch: 37
Loss: 0.1077257121239361
ROC train: 0.996182	val: 0.902439	test: 0.695602
PRC train: 0.999222	val: 0.804048	test: 0.730701

Epoch: 38
Loss: 0.11284998115019691
ROC train: 0.998238	val: 0.903543	test: 0.679495
PRC train: 0.999655	val: 0.826082	test: 0.703798

Epoch: 39
Loss: 0.10003471960635876
ROC train: 0.996356	val: 0.887986	test: 0.658854
PRC train: 0.999257	val: 0.803041	test: 0.691437

Epoch: 40
Loss: 0.09775826752299491
ROC train: 0.997467	val: 0.887082	test: 0.680459
PRC train: 0.999488	val: 0.792196	test: 0.722079

Epoch: 41
Loss: 0.11102340640894655
ROC train: 0.996353	val: 0.892302	test: 0.686921
PRC train: 0.999275	val: 0.795390	test: 0.715336

Epoch: 42
Loss: 0.08051485379133798
ROC train: 0.998003	val: 0.894209	test: 0.671489
PRC train: 0.999580	val: 0.799129	test: 0.693677

Epoch: 43
Loss: 0.08338011814355879
ROC train: 0.998564	val: 0.905450	test: 0.691840
PRC train: 0.999710	val: 0.823664	test: 0.732703

Epoch: 44
Loss: 0.0894809987824032
ROC train: 0.998320	val: 0.906052	test: 0.682195
PRC train: 0.999665	val: 0.829601	test: 0.690576

Epoch: 45
Loss: 0.09771598514046534
ROC train: 0.998724	val: 0.894911	test: 0.676312
PRC train: 0.999745	val: 0.815675	test: 0.696576

Epoch: 46
Loss: 0.07577748888592928
ROC train: 0.998339	val: 0.918498	test: 0.675251
PRC train: 0.999684	val: 0.847870	test: 0.695722

Epoch: 47
Loss: 0.0799226518681934
ROC train: 0.998690	val: 0.902539	test: 0.674576
PRC train: 0.999749	val: 0.831157	test: 0.697753

Epoch: 48
Loss: 0.07777090646371128
ROC train: 0.999158	val: 0.900933	test: 0.673418
PRC train: 0.999841	val: 0.818931	test: 0.674771

Epoch: 49
Loss: 0.06946941660260393
ROC train: 0.999658	val: 0.899428	test: 0.670428
PRC train: 0.999935	val: 0.808372	test: 0.691922

Epoch: 50
Loss: 0.07287806371271563
ROC train: 0.999271	val: 0.900833	test: 0.663580
PRC train: 0.999861	val: 0.812912	test: 0.688666

Epoch: 51
Loss: 0.07638433716368402
ROC train: 0.999506	val: 0.902038	test: 0.677469
PRC train: 0.999902	val: 0.827120	test: 0.703668

Epoch: 52
Loss: 0.08386016209588674
ROC train: 0.998101	val: 0.868513	test: 0.659915
PRC train: 0.999621	val: 0.739948	test: 0.698689

Epoch: 53
Loss: 0.07831710194240768
ROC train: 0.999018	val: 0.888588	test: 0.667921
PRC train: 0.999812	val: 0.790265	test: 0.714051

Epoch: 54
Loss: 0.0854258661032545
ROC train: 0.997228	val: 0.876644	test: 0.662809
PRC train: 0.999478	val: 0.765319	test: 0.696304

Epoch: 55
Loss: 0.06863917374145079
ROC train: 0.999832	val: 0.875439	test: 0.677180
PRC train: 0.999968	val: 0.767517	test: 0.694915

Epoch: 56
Loss: 0.08811204873427535
ROC train: 0.999150	val: 0.892201	test: 0.679205
PRC train: 0.999839	val: 0.803390	test: 0.692923

Epoch: 57
Loss: 0.08107165484489119
ROC train: 0.999436	val: 0.874636	test: 0.674190
PRC train: 0.999893	val: 0.780844	test: 0.710116

Epoch: 58
Loss: 0.06255593890105969
ROC train: 0.999537	val: 0.894008	test: 0.676698
PRC train: 0.999910	val: 0.806342	test: 0.714717

Epoch: 59
Loss: 0.06400838728346941
ROC train: 0.999837	val: 0.896517	test: 0.674865
PRC train: 0.999969	val: 0.816231	test: 0.692314

Epoch: 60
Loss: 0.057131735421046485
ROC train: 0.999826	val: 0.896617	test: 0.694541
PRC train: 0.999967	val: 0.823924	test: 0.721849

Epoch: 61
Loss: 0.06212064025053642
ROC train: 0.999548	val: 0.894710	test: 0.685378
PRC train: 0.999915	val: 0.820982	test: 0.704215

Epoch: 62
Loss: 0.052558275842927035
ROC train: 0.999893	val: 0.885175	test: 0.665799
PRC train: 0.999980	val: 0.809569	test: 0.684970

Epoch: 63
Loss: 0.045980501040364795
ROC train: 0.999725	val: 0.895212	test: 0.667245
PRC train: 0.999948	val: 0.836362	test: 0.690070

Epoch: 64
Loss: 0.04159444956224489
ROC train: 0.999571	val: 0.898023	test: 0.667921
PRC train: 0.999919	val: 0.834073	test: 0.690673

Epoch: 65
Loss: 0.05023249983541355
ROC train: 0.999941	val: 0.898926	test: 0.667824
PRC train: 0.999989	val: 0.824074	test: 0.698218

Epoch: 66
Loss: 0.04879716382237379
ROC train: 0.999790	val: 0.903643	test: 0.680170
PRC train: 0.999960	val: 0.832102	test: 0.708438

Epoch: 67
Loss: 0.04539582283295398
ROC train: 0.999851	val: 0.899428	test: 0.681809
PRC train: 0.999972	val: 0.826780	test: 0.709195

Epoch: 68
Loss: 0.04512299226904774
ROC train: 0.999425	val: 0.896316	test: 0.667631
PRC train: 0.999891	val: 0.830245	test: 0.688251

Epoch: 69
Loss: 0.054811985718772764
ROC train: 0.999961	val: 0.893205	test: 0.668885
PRC train: 0.999993	val: 0.823964	test: 0.697322

Epoch: 70
Loss: 0.04158371299339157
ROC train: 0.999997	val: 0.895614	test: 0.666088
PRC train: 0.999999	val: 0.815670	test: 0.691483

Epoch: 71
Loss: 0.04356704272795265
ROC train: 0.999975	val: 0.886179	test: 0.674769
PRC train: 0.999995	val: 0.776503	test: 0.690612

Epoch: 72
Loss: 0.04610766599425204
ROC train: 0.999921	val: 0.885075	test: 0.670235
PRC train: 0.999985	val: 0.794341	test: 0.690469

Epoch: 73
Loss: 0.040828367137207174
ROC train: 0.999969	val: 0.893004	test: 0.665316
PRC train: 0.999994	val: 0.816527	test: 0.693188

Epoch: 74
Loss: 0.03952578160554855
ROC train: 0.999916	val: 0.889391	test: 0.672936
PRC train: 0.999984	val: 0.805370	test: 0.707305

Epoch: 75
Loss: 0.03671348493783098
ROC train: 0.999961	val: 0.895012	test: 0.679495
PRC train: 0.999993	val: 0.811222	test: 0.707458

Epoch: 76
Loss: 0.04706204941401473
ROC train: 0.999989	val: 0.895413	test: 0.667824
PRC train: 0.999998	val: 0.819214	test: 0.676506

Epoch: 77
Loss: 0.03768683578136927
ROC train: 0.999686	val: 0.885577	test: 0.680073
PRC train: 0.999939	val: 0.771074	test: 0.690735

Epoch: 78
Loss: 0.03785652527711527
ROC train: 0.999975	val: 0.896316	test: 0.687018
PRC train: 0.999995	val: 0.814884	test: 0.705019

Epoch: 79
Loss: 0.038213688811985884
ROC train: 0.999994	val: 0.900532	test: 0.680845
PRC train: 0.999999	val: 0.820859	test: 0.702464

Epoch: 80
Loss: 0.03062695140952259
ROC train: 0.999994	val: 0.901636	test: 0.676794
PRC train: 0.999999	val: 0.813059	test: 0.702729

Epoch: 81
Loss: 0.04693057068027828
ROC train: 0.999958	val: 0.896718	test: 0.665799
PRC train: 0.999992	val: 0.807915	test: 0.684300

Epoch: 82
Loss: 0.032164120046387135
ROC train: 0.999762	val: 0.894710	test: 0.662326
PRC train: 0.999954	val: 0.809871	test: 0.671190

Epoch: 83
Loss: 0.056169836386050075
ROC train: 0.999983	val: 0.891499	test: 0.676312
PRC train: 0.999997	val: 0.811701	test: 0.715056

Epoch: 84
Loss: 0.04543851710104359
ROC train: 1.000000	val: 0.897019	test: 0.686439
PRC train: 1.000000	val: 0.824838	test: 0.728493

Epoch: 85
Loss: 0.03699100569651388
ROC train: 0.999994	val: 0.905350	test: 0.687982
PRC train: 0.999999	val: 0.841858	test: 0.727241

Epoch: 86
Loss: 0.06534664869529036
ROC train: 0.999997	val: 0.904848	test: 0.690876
PRC train: 0.999999	val: 0.830780	test: 0.722299

Epoch: 87
Loss: 0.03595717847991407
ROC train: 0.999994	val: 0.902841	test: 0.696566
PRC train: 0.999999	val: 0.836845	test: 0.721139

Epoch: 88
Loss: 0.041292619937761045
ROC train: 0.999823	val: 0.883569	test: 0.695505
PRC train: 0.999967	val: 0.801317	test: 0.733998

Epoch: 89
Loss: 0.04444764368752461
ROC train: 1.000000	val: 0.903643	test: 0.688850
PRC train: 1.000000	val: 0.841049	test: 0.717682

Epoch: 90
Loss: 0.044812794849600025
ROC train: 1.000000	val: 0.898725	test: 0.675829
PRC train: 1.000000	val: 0.828049	test: 0.707796

Epoch: 91
Loss: 0.034203408808920435
ROC train: 0.999902	val: 0.875439	test: 0.662616
PRC train: 0.999981	val: 0.789090	test: 0.690357

Epoch: 92
Loss: 0.03598885518660564
ROC train: 1.000000	val: 0.892502	test: 0.693383
PRC train: 1.000000	val: 0.823708	test: 0.729643

Epoch: 93
Loss: 0.03192160146593971
PRC train: 0.999086	val: 0.760014	test: 0.721424

Epoch: 33
Loss: 0.151035708553036
ROC train: 0.993071	val: 0.885376	test: 0.667245
PRC train: 0.998578	val: 0.751574	test: 0.707813

Epoch: 34
Loss: 0.13137915443873
ROC train: 0.992440	val: 0.878250	test: 0.674383
PRC train: 0.998410	val: 0.756389	test: 0.706316

Epoch: 35
Loss: 0.12860851674447085
ROC train: 0.993699	val: 0.896718	test: 0.690972
PRC train: 0.998680	val: 0.776171	test: 0.740180

Epoch: 36
Loss: 0.11465249823706548
ROC train: 0.994664	val: 0.861086	test: 0.686921
PRC train: 0.998893	val: 0.718227	test: 0.746433

Epoch: 37
Loss: 0.1088029588044875
ROC train: 0.996364	val: 0.883469	test: 0.687596
PRC train: 0.999241	val: 0.751045	test: 0.748391

Epoch: 38
Loss: 0.1039448617171111
ROC train: 0.996692	val: 0.890696	test: 0.671875
PRC train: 0.999325	val: 0.787380	test: 0.724983

Epoch: 39
Loss: 0.10079938351011009
ROC train: 0.996319	val: 0.875238	test: 0.663580
PRC train: 0.999278	val: 0.750972	test: 0.712203

Epoch: 40
Loss: 0.10153377823365613
ROC train: 0.997512	val: 0.884071	test: 0.689043
PRC train: 0.999499	val: 0.757968	test: 0.751760

Epoch: 41
Loss: 0.09376400482257906
ROC train: 0.998373	val: 0.884874	test: 0.685378
PRC train: 0.999674	val: 0.757631	test: 0.746508

Epoch: 42
Loss: 0.09270729814784244
ROC train: 0.998811	val: 0.881963	test: 0.684606
PRC train: 0.999765	val: 0.758127	test: 0.745690

Epoch: 43
Loss: 0.092015360223105
ROC train: 0.998502	val: 0.877748	test: 0.675733
PRC train: 0.999713	val: 0.767281	test: 0.715598

Epoch: 44
Loss: 0.08406878485638469
ROC train: 0.998903	val: 0.888387	test: 0.690297
PRC train: 0.999790	val: 0.777141	test: 0.732270

Epoch: 45
Loss: 0.08594276724932635
ROC train: 0.997885	val: 0.882967	test: 0.688465
PRC train: 0.999584	val: 0.758258	test: 0.729421

Epoch: 46
Loss: 0.07980335613401221
ROC train: 0.998808	val: 0.881963	test: 0.690008
PRC train: 0.999768	val: 0.755608	test: 0.741045

Epoch: 47
Loss: 0.0918563686269783
ROC train: 0.999419	val: 0.884673	test: 0.695602
PRC train: 0.999888	val: 0.756309	test: 0.754137

Epoch: 48
Loss: 0.07789812293518875
ROC train: 0.999509	val: 0.870822	test: 0.696470
PRC train: 0.999907	val: 0.735173	test: 0.744978

Epoch: 49
Loss: 0.07991655115979468
ROC train: 0.999341	val: 0.859279	test: 0.688079
PRC train: 0.999876	val: 0.720579	test: 0.740363

Epoch: 50
Loss: 0.07709035076615908
ROC train: 0.999832	val: 0.879354	test: 0.692805
PRC train: 0.999968	val: 0.746949	test: 0.748852

Epoch: 51
Loss: 0.07366253802317899
ROC train: 0.999818	val: 0.878250	test: 0.684896
PRC train: 0.999965	val: 0.761726	test: 0.744080

Epoch: 52
Loss: 0.07074738487103578
ROC train: 0.999071	val: 0.893004	test: 0.699363
PRC train: 0.999820	val: 0.792264	test: 0.758492

Epoch: 53
Loss: 0.06721867992391813
ROC train: 0.999677	val: 0.896116	test: 0.711516
PRC train: 0.999940	val: 0.791345	test: 0.775670

Epoch: 54
Loss: 0.07001201592576298
ROC train: 0.999259	val: 0.882967	test: 0.695312
PRC train: 0.999861	val: 0.774598	test: 0.757347

Epoch: 55
Loss: 0.06619787945488591
ROC train: 0.999719	val: 0.884874	test: 0.682292
PRC train: 0.999947	val: 0.773372	test: 0.738474

Epoch: 56
Loss: 0.0652666251317475
ROC train: 0.999969	val: 0.889591	test: 0.669464
PRC train: 0.999994	val: 0.758600	test: 0.721512

Epoch: 57
Loss: 0.05274128267465108
ROC train: 0.999801	val: 0.884573	test: 0.656250
PRC train: 0.999962	val: 0.744854	test: 0.680672

Epoch: 58
Loss: 0.06375437497592752
ROC train: 0.999966	val: 0.881863	test: 0.681617
PRC train: 0.999994	val: 0.750377	test: 0.741448

Epoch: 59
Loss: 0.0611069075076094
ROC train: 0.999834	val: 0.878952	test: 0.697820
PRC train: 0.999969	val: 0.760026	test: 0.757300

Epoch: 60
Loss: 0.07016045050159574
ROC train: 0.999916	val: 0.887986	test: 0.692033
PRC train: 0.999984	val: 0.759411	test: 0.752216

Epoch: 61
Loss: 0.06672417179341558
ROC train: 0.999647	val: 0.858577	test: 0.681520
PRC train: 0.999933	val: 0.719776	test: 0.749933

Epoch: 62
Loss: 0.0613760597899981
ROC train: 0.999271	val: 0.864900	test: 0.689429
PRC train: 0.999858	val: 0.747939	test: 0.756197

Epoch: 63
Loss: 0.060499055652806034
ROC train: 0.997015	val: 0.873632	test: 0.689043
PRC train: 0.999374	val: 0.750163	test: 0.746535

Epoch: 64
Loss: 0.06782454732701006
ROC train: 0.999753	val: 0.863896	test: 0.662616
PRC train: 0.999953	val: 0.721964	test: 0.725863

Epoch: 65
Loss: 0.06231812467268383
ROC train: 0.999529	val: 0.878049	test: 0.672068
PRC train: 0.999910	val: 0.744597	test: 0.732906

Epoch: 66
Loss: 0.05136336552987881
ROC train: 0.999840	val: 0.874435	test: 0.676119
PRC train: 0.999970	val: 0.741559	test: 0.736278

Epoch: 67
Loss: 0.05773012269588137
ROC train: 0.999588	val: 0.845428	test: 0.639950
PRC train: 0.999920	val: 0.698038	test: 0.707213

Epoch: 68
Loss: 0.05983987605176842
ROC train: 0.999924	val: 0.884774	test: 0.665220
PRC train: 0.999986	val: 0.783103	test: 0.728944

Epoch: 69
Loss: 0.05858938839330413
ROC train: 0.999964	val: 0.879153	test: 0.668499
PRC train: 0.999993	val: 0.789246	test: 0.728039

Epoch: 70
Loss: 0.05701072533279083
ROC train: 0.999596	val: 0.854160	test: 0.651427
PRC train: 0.999925	val: 0.747632	test: 0.693546

Epoch: 71
Loss: 0.0505982750528078
ROC train: 1.000000	val: 0.872428	test: 0.658854
PRC train: 1.000000	val: 0.769106	test: 0.698862

Epoch: 72
Loss: 0.058018132744071485
ROC train: 0.999843	val: 0.865904	test: 0.665027
PRC train: 0.999970	val: 0.765751	test: 0.706756

Epoch: 73
Loss: 0.05628113627963193
ROC train: 0.999885	val: 0.876342	test: 0.664448
PRC train: 0.999978	val: 0.782361	test: 0.682857

Epoch: 74
Loss: 0.05305593845778218
ROC train: 0.999941	val: 0.878551	test: 0.666281
PRC train: 0.999989	val: 0.750928	test: 0.703602

Epoch: 75
Loss: 0.06561221811349056
ROC train: 0.999927	val: 0.889290	test: 0.680748
PRC train: 0.999986	val: 0.775718	test: 0.736959

Epoch: 76
Loss: 0.05036666000247566
ROC train: 0.999919	val: 0.871224	test: 0.684510
PRC train: 0.999985	val: 0.767973	test: 0.731995

Epoch: 77
Loss: 0.04048955933059314
ROC train: 0.999986	val: 0.873934	test: 0.662809
PRC train: 0.999997	val: 0.756722	test: 0.690912

Epoch: 78
Loss: 0.04284559399563199
ROC train: 0.999997	val: 0.878852	test: 0.665413
PRC train: 0.999999	val: 0.760400	test: 0.701552

Epoch: 79
Loss: 0.037974420502770445
ROC train: 0.999997	val: 0.876945	test: 0.661651
PRC train: 0.999999	val: 0.754411	test: 0.713252

Epoch: 80
Loss: 0.03411642767881403
ROC train: 0.999938	val: 0.873030	test: 0.668981
PRC train: 0.999988	val: 0.745618	test: 0.730000

Epoch: 81
Loss: 0.037523353324312544
ROC train: 1.000000	val: 0.881562	test: 0.679109
PRC train: 1.000000	val: 0.747177	test: 0.740032

Epoch: 82
Loss: 0.038778406622982604
ROC train: 1.000000	val: 0.905249	test: 0.674286
PRC train: 1.000000	val: 0.804060	test: 0.707918

Epoch: 83
Loss: 0.05275975179750552
ROC train: 0.999635	val: 0.880056	test: 0.645351
PRC train: 0.999931	val: 0.780090	test: 0.659268

Epoch: 84
Loss: 0.04126481698082109
ROC train: 0.999989	val: 0.872127	test: 0.656346
PRC train: 0.999998	val: 0.743101	test: 0.681024

Epoch: 85
Loss: 0.047423320077819416
ROC train: 1.000000	val: 0.877346	test: 0.662037
PRC train: 1.000000	val: 0.749051	test: 0.693489

Epoch: 86
Loss: 0.04221775632733251
ROC train: 0.999781	val: 0.883469	test: 0.669174
PRC train: 0.999960	val: 0.766687	test: 0.713475

Epoch: 87
Loss: 0.03437810534435461
ROC train: 1.000000	val: 0.863495	test: 0.652971
PRC train: 1.000000	val: 0.732145	test: 0.709160

Epoch: 88
Loss: 0.04342588856355856
ROC train: 1.000000	val: 0.875238	test: 0.660108
PRC train: 1.000000	val: 0.751198	test: 0.719459

Epoch: 89
Loss: 0.025730086366245426
ROC train: 1.000000	val: 0.881261	test: 0.664159
PRC train: 1.000000	val: 0.770505	test: 0.707311

Epoch: 90
Loss: 0.03791529367730273
ROC train: 1.000000	val: 0.877045	test: 0.670814
PRC train: 1.000000	val: 0.750906	test: 0.723634

Epoch: 91
Loss: 0.029978137988933895
ROC train: 1.000000	val: 0.874335	test: 0.680941
PRC train: 1.000000	val: 0.763306	test: 0.725442

Epoch: 92
Loss: 0.029511950112834678
ROC train: 1.000000	val: 0.889090	test: 0.693576
PRC train: 1.000000	val: 0.777837	test: 0.742242

Epoch: 93
Loss: 0.03020987974180713
ROC train: 1.000000	val: 0.882967	test: 0.692323
PRC train: 0.999726	val: 0.684912	test: 0.692888

Epoch: 33
Loss: 0.1274070053411248
ROC train: 0.997593	val: 0.860685	test: 0.655093
PRC train: 0.999510	val: 0.722781	test: 0.685796

Epoch: 34
Loss: 0.10206703363379485
ROC train: 0.997885	val: 0.871525	test: 0.665895
PRC train: 0.999577	val: 0.752727	test: 0.711248

Epoch: 35
Loss: 0.09988934537051145
ROC train: 0.998087	val: 0.865904	test: 0.679012
PRC train: 0.999613	val: 0.732903	test: 0.736239

Epoch: 36
Loss: 0.09181406717785508
ROC train: 0.998987	val: 0.847335	test: 0.681038
PRC train: 0.999803	val: 0.710900	test: 0.729304

Epoch: 37
Loss: 0.10363130587835152
ROC train: 0.998479	val: 0.860383	test: 0.672357
PRC train: 0.999704	val: 0.734944	test: 0.716130

Epoch: 38
Loss: 0.09063834105728481
ROC train: 0.997228	val: 0.862391	test: 0.648630
PRC train: 0.999425	val: 0.753934	test: 0.661163

Epoch: 39
Loss: 0.09972615006884857
ROC train: 0.998384	val: 0.852454	test: 0.655093
PRC train: 0.999685	val: 0.712803	test: 0.676197

Epoch: 40
Loss: 0.09340194958667002
ROC train: 0.998505	val: 0.826558	test: 0.657986
PRC train: 0.999720	val: 0.670805	test: 0.690365

Epoch: 41
Loss: 0.09310096150422155
ROC train: 0.998757	val: 0.860685	test: 0.660108
PRC train: 0.999746	val: 0.757836	test: 0.687018

Epoch: 42
Loss: 0.09711101996230177
ROC train: 0.999251	val: 0.861789	test: 0.651910
PRC train: 0.999848	val: 0.733125	test: 0.683585

Epoch: 43
Loss: 0.08263439430181439
ROC train: 0.998791	val: 0.851852	test: 0.654225
PRC train: 0.999754	val: 0.720386	test: 0.698092

Epoch: 44
Loss: 0.07108366454348317
ROC train: 0.999453	val: 0.862491	test: 0.665702
PRC train: 0.999891	val: 0.724153	test: 0.699005

Epoch: 45
Loss: 0.083153778131031
ROC train: 0.999635	val: 0.864398	test: 0.656154
PRC train: 0.999929	val: 0.708500	test: 0.686119

Epoch: 46
Loss: 0.06406533417033862
ROC train: 0.999666	val: 0.845830	test: 0.650752
PRC train: 0.999935	val: 0.703858	test: 0.675353

Epoch: 47
Loss: 0.0740252172827894
ROC train: 0.999481	val: 0.852554	test: 0.645255
PRC train: 0.999900	val: 0.699273	test: 0.665418

Epoch: 48
Loss: 0.06818801938701094
ROC train: 0.999632	val: 0.852956	test: 0.645062
PRC train: 0.999929	val: 0.701280	test: 0.667402

Epoch: 49
Loss: 0.06518939899609504
ROC train: 0.999153	val: 0.876342	test: 0.681327
PRC train: 0.999834	val: 0.758069	test: 0.708511

Epoch: 50
Loss: 0.06148909356020682
ROC train: 0.999520	val: 0.873733	test: 0.673804
PRC train: 0.999906	val: 0.757413	test: 0.711821

Epoch: 51
Loss: 0.06310392817434539
ROC train: 0.999770	val: 0.851250	test: 0.652874
PRC train: 0.999955	val: 0.728682	test: 0.695230

Epoch: 52
Loss: 0.06094020520326434
ROC train: 0.999689	val: 0.860584	test: 0.663773
PRC train: 0.999940	val: 0.724941	test: 0.686957

Epoch: 53
Loss: 0.06301537603577717
ROC train: 0.999795	val: 0.863696	test: 0.661265
PRC train: 0.999961	val: 0.726029	test: 0.688871

Epoch: 54
Loss: 0.059633652206478316
ROC train: 0.999930	val: 0.861688	test: 0.669367
PRC train: 0.999987	val: 0.710091	test: 0.706848

Epoch: 55
Loss: 0.0693925232644065
ROC train: 0.999916	val: 0.845830	test: 0.656829
PRC train: 0.999984	val: 0.672382	test: 0.696944

Epoch: 56
Loss: 0.06110587356988136
ROC train: 0.999815	val: 0.857372	test: 0.657311
PRC train: 0.999965	val: 0.732878	test: 0.678563

Epoch: 57
Loss: 0.07272963821593666
ROC train: 0.999778	val: 0.879354	test: 0.662423
PRC train: 0.999958	val: 0.758070	test: 0.666464

Epoch: 58
Loss: 0.04873928301303771
ROC train: 0.999950	val: 0.839004	test: 0.653164
PRC train: 0.999990	val: 0.686306	test: 0.681625

Epoch: 59
Loss: 0.06684461557170393
ROC train: 0.999961	val: 0.841112	test: 0.656154
PRC train: 0.999993	val: 0.696041	test: 0.688502

Epoch: 60
Loss: 0.06353250373530496
ROC train: 0.999961	val: 0.865603	test: 0.665702
PRC train: 0.999993	val: 0.737016	test: 0.698056

Epoch: 61
Loss: 0.07450290198700313
ROC train: 0.999986	val: 0.869216	test: 0.668981
PRC train: 0.999997	val: 0.750410	test: 0.694790

Epoch: 62
Loss: 0.07363897139070977
ROC train: 0.999436	val: 0.846733	test: 0.662519
PRC train: 0.999895	val: 0.702026	test: 0.683162

Epoch: 63
Loss: 0.06347053971480433
ROC train: 0.999994	val: 0.867711	test: 0.666667
PRC train: 0.999999	val: 0.725402	test: 0.690134

Epoch: 64
Loss: 0.06193559756078272
ROC train: 0.999955	val: 0.853257	test: 0.659240
PRC train: 0.999991	val: 0.725267	test: 0.682230

Epoch: 65
Loss: 0.05295013823351676
ROC train: 0.999966	val: 0.852856	test: 0.663484
PRC train: 0.999994	val: 0.734772	test: 0.690947

Epoch: 66
Loss: 0.050835215952720926
ROC train: 1.000000	val: 0.842919	test: 0.656154
PRC train: 1.000000	val: 0.723495	test: 0.697124

Epoch: 67
Loss: 0.04765430700666951
ROC train: 0.999997	val: 0.841112	test: 0.641011
PRC train: 0.999999	val: 0.718895	test: 0.683078

Epoch: 68
Loss: 0.0483677730917015
ROC train: 0.999983	val: 0.861588	test: 0.647762
PRC train: 0.999997	val: 0.746610	test: 0.690398

Epoch: 69
Loss: 0.03666239886339045
ROC train: 1.000000	val: 0.843722	test: 0.646123
PRC train: 1.000000	val: 0.717260	test: 0.690606

Epoch: 70
Loss: 0.04105034950261961
ROC train: 0.999994	val: 0.854863	test: 0.657407
PRC train: 0.999999	val: 0.725898	test: 0.693290

Epoch: 71
Loss: 0.05209905163184029
ROC train: 0.999994	val: 0.858677	test: 0.661362
PRC train: 0.999999	val: 0.722551	test: 0.697385

Epoch: 72
Loss: 0.04321543931250855
ROC train: 0.999992	val: 0.848038	test: 0.646316
PRC train: 0.999998	val: 0.700036	test: 0.673474

Epoch: 73
Loss: 0.03560445438498465
ROC train: 0.999405	val: 0.811904	test: 0.611690
PRC train: 0.999888	val: 0.655336	test: 0.628972

Epoch: 74
Loss: 0.04583207077666436
ROC train: 1.000000	val: 0.841815	test: 0.648823
PRC train: 1.000000	val: 0.681611	test: 0.675282

Epoch: 75
Loss: 0.03213729341346282
ROC train: 1.000000	val: 0.842216	test: 0.665316
PRC train: 1.000000	val: 0.684363	test: 0.701007

Epoch: 76
Loss: 0.03619049186720724
ROC train: 1.000000	val: 0.850748	test: 0.663677
PRC train: 1.000000	val: 0.706038	test: 0.701282

Epoch: 77
Loss: 0.034468582516921
ROC train: 0.999994	val: 0.864298	test: 0.663194
PRC train: 0.999999	val: 0.740622	test: 0.688295

Epoch: 78
Loss: 0.0368791977020028
ROC train: 1.000000	val: 0.860484	test: 0.672068
PRC train: 1.000000	val: 0.738494	test: 0.703897

Epoch: 79
Loss: 0.03522867050780088
ROC train: 0.999969	val: 0.841915	test: 0.658372
PRC train: 0.999994	val: 0.683297	test: 0.689172

Epoch: 80
Loss: 0.02702908196664858
ROC train: 0.999764	val: 0.836395	test: 0.645930
PRC train: 0.999955	val: 0.676487	test: 0.677227

Epoch: 81
Loss: 0.03378240711345685
ROC train: 1.000000	val: 0.865101	test: 0.659336
PRC train: 1.000000	val: 0.749292	test: 0.697072

Epoch: 82
Loss: 0.04341496536497467
ROC train: 1.000000	val: 0.876242	test: 0.657215
PRC train: 1.000000	val: 0.774339	test: 0.691413

Epoch: 83
Loss: 0.03469901379026557
ROC train: 0.999958	val: 0.871725	test: 0.657600
PRC train: 0.999992	val: 0.776379	test: 0.708164

Epoch: 84
Loss: 0.06456631992030565
ROC train: 0.999938	val: 0.880960	test: 0.656636
PRC train: 0.999988	val: 0.761008	test: 0.684770

Epoch: 85
Loss: 0.0577028299707678
ROC train: 1.000000	val: 0.861789	test: 0.648920
PRC train: 1.000000	val: 0.749166	test: 0.694977

Epoch: 86
Loss: 0.037260700893146224
ROC train: 1.000000	val: 0.863495	test: 0.649113
PRC train: 1.000000	val: 0.739339	test: 0.689940

Epoch: 87
Loss: 0.031899044991147395
ROC train: 1.000000	val: 0.843621	test: 0.645158
PRC train: 1.000000	val: 0.702062	test: 0.689088

Epoch: 88
Loss: 0.04757046787239722
ROC train: 0.999994	val: 0.844926	test: 0.647859
PRC train: 0.999999	val: 0.717550	test: 0.687458

Epoch: 89
Loss: 0.047936980264073184
ROC train: 0.999997	val: 0.873532	test: 0.664545
PRC train: 0.999999	val: 0.761737	test: 0.687345

Epoch: 90
Loss: 0.04149992850233523
ROC train: 1.000000	val: 0.839607	test: 0.652199
PRC train: 1.000000	val: 0.709662	test: 0.675736

Epoch: 91
Loss: 0.027045889480345395
ROC train: 1.000000	val: 0.846833	test: 0.638021
PRC train: 1.000000	val: 0.706096	test: 0.653644

Epoch: 92
Loss: 0.02964248379102635
ROC train: 1.000000	val: 0.855766	test: 0.632523
PRC train: 1.000000	val: 0.718550	test: 0.658262

Epoch: 93
Loss: 0.04202120135154276
ROC train: 1.000000	val: 0.863696	test: 0.630594
PRC train: 0.999558	val: 0.816796	test: 0.581307

Epoch: 33
Loss: 0.12016380208153946
ROC train: 0.998743	val: 0.863997	test: 0.517265
PRC train: 0.999737	val: 0.803865	test: 0.569841

Epoch: 34
Loss: 0.11159616862174918
ROC train: 0.998474	val: 0.872829	test: 0.535108
PRC train: 0.999687	val: 0.808024	test: 0.586811

Epoch: 35
Loss: 0.10288390993933653
ROC train: 0.998642	val: 0.880357	test: 0.552566
PRC train: 0.999714	val: 0.826716	test: 0.592161

Epoch: 36
Loss: 0.10275176450977698
ROC train: 0.998662	val: 0.861488	test: 0.558931
PRC train: 0.999729	val: 0.800210	test: 0.632130

Epoch: 37
Loss: 0.09444603242179316
ROC train: 0.999602	val: 0.870119	test: 0.566744
PRC train: 0.999921	val: 0.815298	test: 0.630779

Epoch: 38
Loss: 0.09759941717358873
ROC train: 0.999731	val: 0.864599	test: 0.544367
PRC train: 0.999948	val: 0.817619	test: 0.606538

Epoch: 39
Loss: 0.11079204280151608
ROC train: 0.999540	val: 0.870421	test: 0.563947
PRC train: 0.999908	val: 0.798191	test: 0.636079

Epoch: 40
Loss: 0.08628311827845535
ROC train: 0.999419	val: 0.872729	test: 0.568576
PRC train: 0.999885	val: 0.789514	test: 0.638583

Epoch: 41
Loss: 0.0984168934251095
ROC train: 0.999655	val: 0.882666	test: 0.572049
PRC train: 0.999932	val: 0.801440	test: 0.605356

Epoch: 42
Loss: 0.10677888005765643
ROC train: 0.999691	val: 0.886480	test: 0.583912
PRC train: 0.999940	val: 0.813216	test: 0.629619

Epoch: 43
Loss: 0.09551366581740252
ROC train: 0.999823	val: 0.845428	test: 0.597415
PRC train: 0.999966	val: 0.773271	test: 0.652533

Epoch: 44
Loss: 0.07564039029985974
ROC train: 0.999916	val: 0.859681	test: 0.579090
PRC train: 0.999984	val: 0.802935	test: 0.639099

Epoch: 45
Loss: 0.08424570696992052
ROC train: 0.999896	val: 0.855867	test: 0.556906
PRC train: 0.999980	val: 0.794691	test: 0.599065

Epoch: 46
Loss: 0.07763515264889032
ROC train: 0.999826	val: 0.859681	test: 0.540413
PRC train: 0.999967	val: 0.789556	test: 0.577394

Epoch: 47
Loss: 0.07549143892475844
ROC train: 0.999905	val: 0.876945	test: 0.550540
PRC train: 0.999982	val: 0.814127	test: 0.579087

Epoch: 48
Loss: 0.07770478816966694
ROC train: 0.999933	val: 0.869116	test: 0.555845
PRC train: 0.999987	val: 0.808871	test: 0.595249

Epoch: 49
Loss: 0.07311202955810336
ROC train: 0.999950	val: 0.865101	test: 0.557388
PRC train: 0.999990	val: 0.807364	test: 0.613161

Epoch: 50
Loss: 0.06260425478215757
ROC train: 0.999992	val: 0.853859	test: 0.544078
PRC train: 0.999998	val: 0.803076	test: 0.614156

Epoch: 51
Loss: 0.06268921701209455
ROC train: 0.999997	val: 0.858878	test: 0.545910
PRC train: 0.999999	val: 0.803555	test: 0.599489

Epoch: 52
Loss: 0.06402787364053976
ROC train: 0.999997	val: 0.873331	test: 0.546200
PRC train: 0.999999	val: 0.818001	test: 0.603703

Epoch: 53
Loss: 0.05470862369472724
ROC train: 0.999997	val: 0.869718	test: 0.547454
PRC train: 0.999999	val: 0.817139	test: 0.605516

Epoch: 54
Loss: 0.05025901107770704
ROC train: 0.999994	val: 0.868012	test: 0.546489
PRC train: 0.999999	val: 0.818375	test: 0.610769

Epoch: 55
Loss: 0.05019679039514065
ROC train: 0.999992	val: 0.871525	test: 0.557002
PRC train: 0.999998	val: 0.817901	test: 0.605188

Epoch: 56
Loss: 0.050384716975852735
ROC train: 1.000000	val: 0.864398	test: 0.539931
PRC train: 1.000000	val: 0.810583	test: 0.582942

Epoch: 57
Loss: 0.04428227032497256
ROC train: 1.000000	val: 0.854562	test: 0.527585
PRC train: 1.000000	val: 0.798527	test: 0.578831

Epoch: 58
Loss: 0.05976375498375456
ROC train: 0.999975	val: 0.857372	test: 0.530575
PRC train: 0.999995	val: 0.793775	test: 0.585086

Epoch: 59
Loss: 0.04254767107308523
ROC train: 1.000000	val: 0.874235	test: 0.577546
PRC train: 1.000000	val: 0.814915	test: 0.634588

Epoch: 60
Loss: 0.04455166684868528
ROC train: 0.999994	val: 0.874335	test: 0.594329
PRC train: 0.999999	val: 0.815760	test: 0.639841

Epoch: 61
Loss: 0.04282144228709035
ROC train: 0.999986	val: 0.854160	test: 0.571277
PRC train: 0.999997	val: 0.796911	test: 0.643872

Epoch: 62
Loss: 0.05955827263174136
ROC train: 1.000000	val: 0.854361	test: 0.550637
PRC train: 1.000000	val: 0.774411	test: 0.604376

Epoch: 63
Loss: 0.05502701853650795
ROC train: 1.000000	val: 0.859982	test: 0.551119
PRC train: 1.000000	val: 0.773017	test: 0.591466

Epoch: 64
Loss: 0.04089016386508887
ROC train: 0.999846	val: 0.858376	test: 0.556617
PRC train: 0.999970	val: 0.771244	test: 0.602291

Epoch: 65
Loss: 0.04867744698616688
ROC train: 1.000000	val: 0.860484	test: 0.543113
PRC train: 1.000000	val: 0.772184	test: 0.587556

Epoch: 66
Loss: 0.04118824324773927
ROC train: 1.000000	val: 0.836595	test: 0.514082
PRC train: 1.000000	val: 0.752197	test: 0.560108

Epoch: 67
Loss: 0.038030729784501345
ROC train: 1.000000	val: 0.829971	test: 0.501640
PRC train: 1.000000	val: 0.751603	test: 0.544988

Epoch: 68
Loss: 0.027827567972626616
ROC train: 1.000000	val: 0.834488	test: 0.508198
PRC train: 1.000000	val: 0.760727	test: 0.561629

Epoch: 69
Loss: 0.03483546899199319
ROC train: 0.999997	val: 0.821138	test: 0.511092
PRC train: 0.999999	val: 0.743954	test: 0.582690

Epoch: 70
Loss: 0.044878490246501646
ROC train: 0.999975	val: 0.820335	test: 0.518036
PRC train: 0.999995	val: 0.734578	test: 0.598531

Epoch: 71
Loss: 0.033653547186134995
ROC train: 1.000000	val: 0.873532	test: 0.527296
PRC train: 1.000000	val: 0.810659	test: 0.594427

Epoch: 72
Loss: 0.047847106211357404
ROC train: 1.000000	val: 0.876644	test: 0.540413
PRC train: 1.000000	val: 0.812651	test: 0.604208

Epoch: 73
Loss: 0.04803202344048396
ROC train: 1.000000	val: 0.880859	test: 0.567419
PRC train: 1.000000	val: 0.807018	test: 0.624887

Epoch: 74
Loss: 0.04708200632086347
ROC train: 1.000000	val: 0.888287	test: 0.566840
PRC train: 1.000000	val: 0.807993	test: 0.601506

Epoch: 75
Loss: 0.03468569819112893
ROC train: 1.000000	val: 0.882565	test: 0.563465
PRC train: 1.000000	val: 0.806340	test: 0.604663

Epoch: 76
Loss: 0.04166203403445078
ROC train: 1.000000	val: 0.880658	test: 0.569059
PRC train: 1.000000	val: 0.812314	test: 0.605252

Epoch: 77
Loss: 0.044028231377160346
ROC train: 1.000000	val: 0.878149	test: 0.568480
PRC train: 1.000000	val: 0.820134	test: 0.609065

Epoch: 78
Loss: 0.04012385188376958
ROC train: 0.999997	val: 0.871725	test: 0.550829
PRC train: 0.999999	val: 0.814589	test: 0.589290

Epoch: 79
Loss: 0.04107609894069349
ROC train: 0.999975	val: 0.864800	test: 0.548997
PRC train: 0.999995	val: 0.798726	test: 0.583083

Epoch: 80
Loss: 0.030298629761813706
ROC train: 1.000000	val: 0.875138	test: 0.564815
PRC train: 1.000000	val: 0.820652	test: 0.600119

Epoch: 81
Loss: 0.0380538971486045
ROC train: 0.999986	val: 0.873131	test: 0.564525
PRC train: 0.999997	val: 0.823800	test: 0.608920

Epoch: 82
Loss: 0.03526004529463431
ROC train: 1.000000	val: 0.862090	test: 0.553434
PRC train: 1.000000	val: 0.798602	test: 0.601608

Epoch: 83
Loss: 0.041819549826466115
ROC train: 1.000000	val: 0.874536	test: 0.547454
PRC train: 1.000000	val: 0.791102	test: 0.592592

Epoch: 84
Loss: 0.03135659356501516
ROC train: 1.000000	val: 0.863093	test: 0.530478
PRC train: 1.000000	val: 0.778876	test: 0.581383

Epoch: 85
Loss: 0.036509264507098224
ROC train: 1.000000	val: 0.851751	test: 0.536458
PRC train: 1.000000	val: 0.782382	test: 0.593064

Epoch: 86
Loss: 0.022444244402434654
ROC train: 1.000000	val: 0.863194	test: 0.544174
PRC train: 1.000000	val: 0.789721	test: 0.587345

Epoch: 87
Loss: 0.032714259459375894
ROC train: 1.000000	val: 0.859480	test: 0.541377
PRC train: 1.000000	val: 0.798533	test: 0.598511

Epoch: 88
Loss: 0.02945456015556225
ROC train: 1.000000	val: 0.866305	test: 0.533661
PRC train: 1.000000	val: 0.804316	test: 0.590433

Epoch: 89
Loss: 0.033351783912190146
ROC train: 1.000000	val: 0.871023	test: 0.530093
PRC train: 1.000000	val: 0.795487	test: 0.570998

Epoch: 90
Loss: 0.02788317674080729
ROC train: 1.000000	val: 0.869919	test: 0.530864
PRC train: 1.000000	val: 0.786047	test: 0.555155

Epoch: 91
Loss: 0.03012579832125702
ROC train: 1.000000	val: 0.865402	test: 0.535590
PRC train: 1.000000	val: 0.781932	test: 0.559107

Epoch: 92
Loss: 0.032499000969732975
ROC train: 1.000000	val: 0.850848	test: 0.528164
PRC train: 1.000000	val: 0.776584	test: 0.572775

Epoch: 93
Loss: 0.030580658150719336
PRC train: 0.999958	val: 0.747303	test: 0.683763

Epoch: 33
Loss: 0.11593748821930419
ROC train: 0.999655	val: 0.875740	test: 0.644965
PRC train: 0.999934	val: 0.795754	test: 0.679948

Epoch: 34
Loss: 0.10636936339670819
ROC train: 0.999776	val: 0.886279	test: 0.630787
PRC train: 0.999958	val: 0.821523	test: 0.673748

Epoch: 35
Loss: 0.11995738022169151
ROC train: 0.999941	val: 0.858075	test: 0.637249
PRC train: 0.999989	val: 0.763186	test: 0.683338

Epoch: 36
Loss: 0.11023816911662873
ROC train: 0.998564	val: 0.852454	test: 0.666377
PRC train: 0.999702	val: 0.733626	test: 0.700621

Epoch: 37
Loss: 0.08907640729512077
ROC train: 0.999899	val: 0.878952	test: 0.625675
PRC train: 0.999981	val: 0.788545	test: 0.670777

Epoch: 38
Loss: 0.1014061045001821
ROC train: 0.999992	val: 0.853257	test: 0.616223
PRC train: 0.999998	val: 0.741933	test: 0.661694

Epoch: 39
Loss: 0.1133618912752454
ROC train: 0.999950	val: 0.831677	test: 0.616319
PRC train: 0.999990	val: 0.700624	test: 0.643679

Epoch: 40
Loss: 0.08637614562950473
ROC train: 0.998710	val: 0.825555	test: 0.629630
PRC train: 0.999702	val: 0.710282	test: 0.681094

Epoch: 41
Loss: 0.0825390892948054
ROC train: 0.999871	val: 0.878551	test: 0.641011
PRC train: 0.999976	val: 0.813608	test: 0.700049

Epoch: 42
Loss: 0.08591119034183621
ROC train: 0.999921	val: 0.875640	test: 0.627604
PRC train: 0.999985	val: 0.815149	test: 0.672943

Epoch: 43
Loss: 0.09013052097995965
ROC train: 0.999902	val: 0.843019	test: 0.659240
PRC train: 0.999981	val: 0.760690	test: 0.695932

Epoch: 44
Loss: 0.08573700752895246
ROC train: 0.999905	val: 0.801867	test: 0.637153
PRC train: 0.999982	val: 0.713158	test: 0.663758

Epoch: 45
Loss: 0.07748597198284624
ROC train: 0.999871	val: 0.736224	test: 0.624228
PRC train: 0.999975	val: 0.657238	test: 0.636992

Epoch: 46
Loss: 0.06856043933356455
ROC train: 0.999992	val: 0.834387	test: 0.610725
PRC train: 0.999998	val: 0.757277	test: 0.655103

Epoch: 47
Loss: 0.07493542582475818
ROC train: 1.000000	val: 0.863093	test: 0.651331
PRC train: 1.000000	val: 0.776390	test: 0.681046

Epoch: 48
Loss: 0.059079561771363545
ROC train: 0.999972	val: 0.774064	test: 0.659433
PRC train: 0.999995	val: 0.697860	test: 0.686451

Epoch: 49
Loss: 0.0689095537382495
ROC train: 0.999972	val: 0.808993	test: 0.679880
PRC train: 0.999995	val: 0.724272	test: 0.712167

Epoch: 50
Loss: 0.060254907825715034
ROC train: 1.000000	val: 0.852956	test: 0.646123
PRC train: 1.000000	val: 0.796915	test: 0.698429

Epoch: 51
Loss: 0.06623980485350028
ROC train: 1.000000	val: 0.847737	test: 0.658468
PRC train: 1.000000	val: 0.776060	test: 0.694307

Epoch: 52
Loss: 0.0633030739153702
ROC train: 1.000000	val: 0.813309	test: 0.671393
PRC train: 1.000000	val: 0.710945	test: 0.696235

Epoch: 53
Loss: 0.04779001499746886
ROC train: 0.999972	val: 0.822744	test: 0.670525
PRC train: 0.999995	val: 0.721602	test: 0.690427

Epoch: 54
Loss: 0.04520670500687729
ROC train: 1.000000	val: 0.844826	test: 0.681231
PRC train: 1.000000	val: 0.745036	test: 0.711708

Epoch: 55
Loss: 0.050639403741365975
ROC train: 1.000000	val: 0.874636	test: 0.673611
PRC train: 1.000000	val: 0.786221	test: 0.690214

Epoch: 56
Loss: 0.038124922322797974
ROC train: 1.000000	val: 0.870421	test: 0.672550
PRC train: 1.000000	val: 0.782767	test: 0.687450

Epoch: 57
Loss: 0.049074776655159094
ROC train: 1.000000	val: 0.813309	test: 0.676698
PRC train: 1.000000	val: 0.725378	test: 0.697723

Epoch: 58
Loss: 0.0594622231953285
ROC train: 0.999891	val: 0.733514	test: 0.682870
PRC train: 0.999979	val: 0.642431	test: 0.701657

Epoch: 59
Loss: 0.059129338595765614
ROC train: 1.000000	val: 0.841112	test: 0.688368
PRC train: 1.000000	val: 0.745334	test: 0.699188

Epoch: 60
Loss: 0.051649390170167765
ROC train: 1.000000	val: 0.833584	test: 0.672164
PRC train: 1.000000	val: 0.723754	test: 0.681833

Epoch: 61
Loss: 0.05184789150038811
ROC train: 1.000000	val: 0.745358	test: 0.668499
PRC train: 1.000000	val: 0.638834	test: 0.690120

Epoch: 62
Loss: 0.03721463300610891
ROC train: 1.000000	val: 0.826960	test: 0.654032
PRC train: 1.000000	val: 0.725490	test: 0.684615

Epoch: 63
Loss: 0.0518368197351999
ROC train: 1.000000	val: 0.827763	test: 0.663773
PRC train: 1.000000	val: 0.739393	test: 0.684729

Epoch: 64
Loss: 0.028456701176867997
ROC train: 1.000000	val: 0.820536	test: 0.676119
PRC train: 1.000000	val: 0.739025	test: 0.694253

Epoch: 65
Loss: 0.04021971815660146
ROC train: 0.999997	val: 0.790826	test: 0.672840
PRC train: 0.999999	val: 0.709870	test: 0.689164

Epoch: 66
Loss: 0.05110004272867626
ROC train: 0.999964	val: 0.801465	test: 0.701678
PRC train: 0.999993	val: 0.712724	test: 0.699833

Epoch: 67
Loss: 0.06250430786060096
ROC train: 0.999994	val: 0.742146	test: 0.689815
PRC train: 0.999999	val: 0.673075	test: 0.701584

Epoch: 68
Loss: 0.0421589010612808
ROC train: 1.000000	val: 0.790224	test: 0.693480
PRC train: 1.000000	val: 0.720894	test: 0.713640

Epoch: 69
Loss: 0.04428664712837867
ROC train: 0.999997	val: 0.878651	test: 0.700617
PRC train: 0.999999	val: 0.801544	test: 0.711306

Epoch: 70
Loss: 0.04083768118477239
ROC train: 1.000000	val: 0.858777	test: 0.699653
PRC train: 1.000000	val: 0.782467	test: 0.719021

Epoch: 71
Loss: 0.04098141352958925
ROC train: 1.000000	val: 0.818328	test: 0.692998
PRC train: 1.000000	val: 0.731067	test: 0.701409

Epoch: 72
Loss: 0.03220286690614287
ROC train: 1.000000	val: 0.819030	test: 0.678434
PRC train: 1.000000	val: 0.740888	test: 0.692370

Epoch: 73
Loss: 0.034516522286473526
ROC train: 1.000000	val: 0.808993	test: 0.677951
PRC train: 1.000000	val: 0.732534	test: 0.694703

Epoch: 74
Loss: 0.034251237272865435
ROC train: 1.000000	val: 0.809696	test: 0.663677
PRC train: 1.000000	val: 0.730082	test: 0.685601

Epoch: 75
Loss: 0.03206742605341859
ROC train: 1.000000	val: 0.860986	test: 0.677469
PRC train: 1.000000	val: 0.781906	test: 0.713003

Epoch: 76
Loss: 0.036442839521650415
ROC train: 0.999938	val: 0.787112	test: 0.693769
PRC train: 0.999988	val: 0.707408	test: 0.709240

Epoch: 77
Loss: 0.0488289731510002
ROC train: 0.999997	val: 0.804577	test: 0.690876
PRC train: 0.999999	val: 0.711751	test: 0.705581

Epoch: 78
Loss: 0.03301565120107287
ROC train: 1.000000	val: 0.844926	test: 0.659336
PRC train: 1.000000	val: 0.767485	test: 0.678734

Epoch: 79
Loss: 0.0357378440471212
ROC train: 1.000000	val: 0.817826	test: 0.658083
PRC train: 1.000000	val: 0.737954	test: 0.669933

Epoch: 80
Loss: 0.041057063080902276
ROC train: 1.000000	val: 0.839607	test: 0.672164
PRC train: 1.000000	val: 0.755861	test: 0.679158

Epoch: 81
Loss: 0.042044772276155995
ROC train: 0.999992	val: 0.867409	test: 0.673900
PRC train: 0.999998	val: 0.794376	test: 0.691303

Epoch: 82
Loss: 0.04415555033656322
ROC train: 1.000000	val: 0.812105	test: 0.697531
PRC train: 1.000000	val: 0.733914	test: 0.697994

Epoch: 83
Loss: 0.035061406670867996
ROC train: 1.000000	val: 0.762321	test: 0.703704
PRC train: 1.000000	val: 0.674415	test: 0.702234

Epoch: 84
Loss: 0.03116116477492874
ROC train: 1.000000	val: 0.816421	test: 0.684414
PRC train: 1.000000	val: 0.734218	test: 0.705996

Epoch: 85
Loss: 0.03403302877363873
ROC train: 1.000000	val: 0.861287	test: 0.667728
PRC train: 1.000000	val: 0.787229	test: 0.698638

Epoch: 86
Loss: 0.06055731599817551
ROC train: 1.000000	val: 0.871625	test: 0.644579
PRC train: 1.000000	val: 0.816812	test: 0.670280

Epoch: 87
Loss: 0.02427070980684805
ROC train: 0.999938	val: 0.810097	test: 0.630305
PRC train: 0.999988	val: 0.773627	test: 0.634956

Epoch: 88
Loss: 0.054132054850297005
ROC train: 1.000000	val: 0.892502	test: 0.637924
PRC train: 1.000000	val: 0.861274	test: 0.665493

Epoch: 89
Loss: 0.04900399797072923
ROC train: 1.000000	val: 0.872026	test: 0.634838
PRC train: 1.000000	val: 0.827324	test: 0.678167

Epoch: 90
Loss: 0.03452934221187563
ROC train: 1.000000	val: 0.783298	test: 0.641397
PRC train: 1.000000	val: 0.716754	test: 0.673168

Epoch: 91
Loss: 0.030795788736065637
ROC train: 1.000000	val: 0.807086	test: 0.666667
PRC train: 1.000000	val: 0.732313	test: 0.691208

Epoch: 92
Loss: 0.034084077204116235
ROC train: 1.000000	val: 0.828465	test: 0.665509
PRC train: 1.000000	val: 0.749789	test: 0.672470

Epoch: 93
Loss: 0.036037450695475495
PRC train: 0.999867	val: 0.850137	test: 0.647701

Epoch: 33
Loss: 0.10756883523510281
ROC train: 0.999655	val: 0.889090	test: 0.633777
PRC train: 0.999935	val: 0.836390	test: 0.648713

Epoch: 34
Loss: 0.12719815756659048
ROC train: 0.999481	val: 0.873131	test: 0.629919
PRC train: 0.999903	val: 0.796963	test: 0.624748

Epoch: 35
Loss: 0.12841548285731078
ROC train: 0.999234	val: 0.858978	test: 0.611593
PRC train: 0.999857	val: 0.771115	test: 0.619412

Epoch: 36
Loss: 0.10373693919671959
ROC train: 0.999509	val: 0.881963	test: 0.627508
PRC train: 0.999908	val: 0.802494	test: 0.626797

Epoch: 37
Loss: 0.11359203522293589
ROC train: 0.999217	val: 0.880458	test: 0.634645
PRC train: 0.999852	val: 0.804298	test: 0.669179

Epoch: 38
Loss: 0.09929419218877975
ROC train: 0.997941	val: 0.892402	test: 0.621624
PRC train: 0.999540	val: 0.811560	test: 0.666349

Epoch: 39
Loss: 0.0930721634766356
ROC train: 0.999694	val: 0.888588	test: 0.603684
PRC train: 0.999942	val: 0.818935	test: 0.643800

Epoch: 40
Loss: 0.09418057728598658
ROC train: 0.999874	val: 0.898023	test: 0.616512
PRC train: 0.999976	val: 0.833326	test: 0.629503

Epoch: 41
Loss: 0.09546745576641016
ROC train: 0.999941	val: 0.887484	test: 0.619985
PRC train: 0.999989	val: 0.819400	test: 0.642711

Epoch: 42
Loss: 0.08348587158235755
ROC train: 1.000000	val: 0.892201	test: 0.644772
PRC train: 1.000000	val: 0.820607	test: 0.677925

Epoch: 43
Loss: 0.09488868787458585
ROC train: 0.999992	val: 0.886279	test: 0.662712
PRC train: 0.999998	val: 0.805212	test: 0.707473

Epoch: 44
Loss: 0.08428479152563476
ROC train: 0.999921	val: 0.877045	test: 0.640143
PRC train: 0.999985	val: 0.799110	test: 0.692513

Epoch: 45
Loss: 0.10331992509813075
ROC train: 0.999938	val: 0.885175	test: 0.635031
PRC train: 0.999988	val: 0.807211	test: 0.659877

Epoch: 46
Loss: 0.09188844544994702
ROC train: 0.999961	val: 0.887383	test: 0.641975
PRC train: 0.999993	val: 0.804795	test: 0.659597

Epoch: 47
Loss: 0.07745969033847712
ROC train: 0.999989	val: 0.878651	test: 0.633584
PRC train: 0.999998	val: 0.809033	test: 0.686705

Epoch: 48
Loss: 0.0689259111616833
ROC train: 0.999997	val: 0.877647	test: 0.644290
PRC train: 0.999999	val: 0.809710	test: 0.695259

Epoch: 49
Loss: 0.0849135911008487
ROC train: 0.999762	val: 0.856870	test: 0.622782
PRC train: 0.999954	val: 0.766915	test: 0.678800

Epoch: 50
Loss: 0.07482020681318165
ROC train: 0.999986	val: 0.875038	test: 0.621817
PRC train: 0.999997	val: 0.811267	test: 0.661920

Epoch: 51
Loss: 0.06857107627300281
ROC train: 0.999947	val: 0.881060	test: 0.640625
PRC train: 0.999990	val: 0.817596	test: 0.686323

Epoch: 52
Loss: 0.06305859373439114
ROC train: 0.999916	val: 0.867510	test: 0.647859
PRC train: 0.999984	val: 0.790811	test: 0.696301

Epoch: 53
Loss: 0.05987431429768129
ROC train: 1.000000	val: 0.872729	test: 0.649209
PRC train: 1.000000	val: 0.786690	test: 0.694268

Epoch: 54
Loss: 0.05567542017858714
ROC train: 1.000000	val: 0.892201	test: 0.656057
PRC train: 1.000000	val: 0.812474	test: 0.694034

Epoch: 55
Loss: 0.05803872643683339
ROC train: 1.000000	val: 0.892101	test: 0.657118
PRC train: 1.000000	val: 0.821588	test: 0.694558

Epoch: 56
Loss: 0.0427195219292596
ROC train: 1.000000	val: 0.897822	test: 0.655768
PRC train: 1.000000	val: 0.834983	test: 0.693468

Epoch: 57
Loss: 0.0554369736065472
ROC train: 1.000000	val: 0.892803	test: 0.647666
PRC train: 1.000000	val: 0.833061	test: 0.686414

Epoch: 58
Loss: 0.05921807279334778
ROC train: 1.000000	val: 0.869718	test: 0.636767
PRC train: 1.000000	val: 0.790209	test: 0.687423

Epoch: 59
Loss: 0.04814702012769353
ROC train: 0.999961	val: 0.858577	test: 0.643519
PRC train: 0.999993	val: 0.775340	test: 0.694370

Epoch: 60
Loss: 0.05626404900236466
ROC train: 1.000000	val: 0.869818	test: 0.633777
PRC train: 1.000000	val: 0.787409	test: 0.677316

Epoch: 61
Loss: 0.05269793265979622
ROC train: 1.000000	val: 0.874034	test: 0.617863
PRC train: 1.000000	val: 0.779158	test: 0.643892

Epoch: 62
Loss: 0.069377008333943
ROC train: 1.000000	val: 0.870621	test: 0.619985
PRC train: 1.000000	val: 0.769156	test: 0.648775

Epoch: 63
Loss: 0.0650291437837002
ROC train: 1.000000	val: 0.885476	test: 0.627218
PRC train: 1.000000	val: 0.798006	test: 0.648514

Epoch: 64
Loss: 0.06441384479510467
ROC train: 1.000000	val: 0.894911	test: 0.641011
PRC train: 1.000000	val: 0.821560	test: 0.666243

Epoch: 65
Loss: 0.04850585232048578
ROC train: 1.000000	val: 0.890294	test: 0.640529
PRC train: 1.000000	val: 0.828659	test: 0.668640

Epoch: 66
Loss: 0.04522416667097562
ROC train: 1.000000	val: 0.886580	test: 0.640914
PRC train: 1.000000	val: 0.821125	test: 0.673940

Epoch: 67
Loss: 0.04947550911908055
ROC train: 0.999916	val: 0.875339	test: 0.626543
PRC train: 0.999984	val: 0.815157	test: 0.662685

Epoch: 68
Loss: 0.03691438247335111
ROC train: 1.000000	val: 0.889792	test: 0.623939
PRC train: 1.000000	val: 0.828832	test: 0.655441

Epoch: 69
Loss: 0.03429458810990456
ROC train: 1.000000	val: 0.888387	test: 0.621914
PRC train: 1.000000	val: 0.833423	test: 0.659587

Epoch: 70
Loss: 0.043263609101487584
ROC train: 0.999989	val: 0.874034	test: 0.628472
PRC train: 0.999998	val: 0.828647	test: 0.651508

Epoch: 71
Loss: 0.04221763205414663
ROC train: 1.000000	val: 0.886179	test: 0.627990
PRC train: 1.000000	val: 0.844232	test: 0.678714

Epoch: 72
Loss: 0.029737370896943345
ROC train: 1.000000	val: 0.887383	test: 0.626350
PRC train: 1.000000	val: 0.836230	test: 0.667250

Epoch: 73
Loss: 0.0373756219655183
ROC train: 1.000000	val: 0.877045	test: 0.624904
PRC train: 1.000000	val: 0.815636	test: 0.679034

Epoch: 74
Loss: 0.03963547356498409
ROC train: 0.999997	val: 0.879655	test: 0.624518
PRC train: 0.999999	val: 0.816046	test: 0.684847

Epoch: 75
Loss: 0.035612221411193044
ROC train: 1.000000	val: 0.875941	test: 0.615066
PRC train: 1.000000	val: 0.808023	test: 0.668786

Epoch: 76
Loss: 0.04769653501625499
ROC train: 1.000000	val: 0.876242	test: 0.608410
PRC train: 1.000000	val: 0.795841	test: 0.628267

Epoch: 77
Loss: 0.026283423581363954
ROC train: 1.000000	val: 0.871324	test: 0.626447
PRC train: 1.000000	val: 0.802719	test: 0.672801

Epoch: 78
Loss: 0.038254919976643355
ROC train: 1.000000	val: 0.868212	test: 0.628665
PRC train: 1.000000	val: 0.800146	test: 0.681584

Epoch: 79
Loss: 0.02853422555921824
ROC train: 1.000000	val: 0.857975	test: 0.619502
PRC train: 1.000000	val: 0.788969	test: 0.666197

Epoch: 80
Loss: 0.03180936272046411
ROC train: 1.000000	val: 0.877045	test: 0.622010
PRC train: 1.000000	val: 0.810339	test: 0.647589

Epoch: 81
Loss: 0.03380833966286113
ROC train: 1.000000	val: 0.875439	test: 0.617477
PRC train: 1.000000	val: 0.804423	test: 0.638563

Epoch: 82
Loss: 0.03166903458438537
ROC train: 1.000000	val: 0.862893	test: 0.623650
PRC train: 1.000000	val: 0.785459	test: 0.674411

Epoch: 83
Loss: 0.02785757627276906
ROC train: 1.000000	val: 0.883368	test: 0.647087
PRC train: 1.000000	val: 0.807239	test: 0.708392

Epoch: 84
Loss: 0.029967850570426918
ROC train: 1.000000	val: 0.888186	test: 0.646026
PRC train: 1.000000	val: 0.812422	test: 0.703987

Epoch: 85
Loss: 0.032566617935359
ROC train: 1.000000	val: 0.869818	test: 0.620949
PRC train: 1.000000	val: 0.795448	test: 0.685962

Epoch: 86
Loss: 0.020623527752688473
ROC train: 1.000000	val: 0.854963	test: 0.609086
PRC train: 1.000000	val: 0.791012	test: 0.675488

Epoch: 87
Loss: 0.02816352948906012
ROC train: 1.000000	val: 0.866606	test: 0.618827
PRC train: 1.000000	val: 0.798821	test: 0.670537

Epoch: 88
Loss: 0.028710469581176075
ROC train: 1.000000	val: 0.867309	test: 0.628183
PRC train: 1.000000	val: 0.802180	test: 0.678025

Epoch: 89
Loss: 0.02592413973024732
ROC train: 1.000000	val: 0.876945	test: 0.633488
PRC train: 1.000000	val: 0.820624	test: 0.689597

Epoch: 90
Loss: 0.027729918187640056
ROC train: 1.000000	val: 0.880960	test: 0.640529
PRC train: 1.000000	val: 0.824588	test: 0.694055

Epoch: 91
Loss: 0.01760358566006733
ROC train: 0.999986	val: 0.879956	test: 0.643326
PRC train: 0.999997	val: 0.816532	test: 0.694962

Epoch: 92
Loss: 0.020605862667085226
ROC train: 1.000000	val: 0.895112	test: 0.640529
PRC train: 1.000000	val: 0.845896	test: 0.687773

Epoch: 93
Loss: 0.023138744133269138
ROC train: 1.000000	val: 0.888688	test: 0.633198
PRC train: 0.998576	val: 0.798117	test: 0.729043

Epoch: 33
Loss: 0.13051994202390393
ROC train: 0.992243	val: 0.862993	test: 0.664641
PRC train: 0.998412	val: 0.762216	test: 0.712731

Epoch: 34
Loss: 0.136399733694279
ROC train: 0.994437	val: 0.887383	test: 0.645448
PRC train: 0.998778	val: 0.784575	test: 0.668912

Epoch: 35
Loss: 0.10775509121188974
ROC train: 0.995189	val: 0.902439	test: 0.630980
PRC train: 0.998877	val: 0.797444	test: 0.647910

Epoch: 36
Loss: 0.10597789926836983
ROC train: 0.996283	val: 0.896116	test: 0.622782
PRC train: 0.999188	val: 0.784163	test: 0.644517

Epoch: 37
Loss: 0.10109811704706503
ROC train: 0.996608	val: 0.900733	test: 0.634259
PRC train: 0.999284	val: 0.795648	test: 0.652751

Epoch: 38
Loss: 0.10319187155115823
ROC train: 0.997228	val: 0.898926	test: 0.622492
PRC train: 0.999416	val: 0.798751	test: 0.624212

Epoch: 39
Loss: 0.08741328406521745
ROC train: 0.997672	val: 0.907859	test: 0.645158
PRC train: 0.999497	val: 0.820627	test: 0.677019

Epoch: 40
Loss: 0.08692757216404676
ROC train: 0.997773	val: 0.908863	test: 0.635995
PRC train: 0.999538	val: 0.813211	test: 0.650999

Epoch: 41
Loss: 0.08948899130446354
ROC train: 0.998356	val: 0.896316	test: 0.621046
PRC train: 0.999676	val: 0.808289	test: 0.647077

Epoch: 42
Loss: 0.10152555442296222
ROC train: 0.998061	val: 0.882264	test: 0.636960
PRC train: 0.999620	val: 0.797950	test: 0.686181

Epoch: 43
Loss: 0.11468322424689588
ROC train: 0.996535	val: 0.905049	test: 0.647087
PRC train: 0.999281	val: 0.825079	test: 0.712492

Epoch: 44
Loss: 0.0967898707381569
ROC train: 0.997444	val: 0.905049	test: 0.639853
PRC train: 0.999487	val: 0.808101	test: 0.690332

Epoch: 45
Loss: 0.09220436292921354
ROC train: 0.998659	val: 0.883268	test: 0.605999
PRC train: 0.999741	val: 0.778317	test: 0.644207

Epoch: 46
Loss: 0.08089693315991432
ROC train: 0.998715	val: 0.899127	test: 0.633391
PRC train: 0.999746	val: 0.805751	test: 0.669110

Epoch: 47
Loss: 0.08016244684481648
ROC train: 0.998451	val: 0.910669	test: 0.667149
PRC train: 0.999678	val: 0.824529	test: 0.710855

Epoch: 48
Loss: 0.07613308797879581
ROC train: 0.998637	val: 0.906354	test: 0.652296
PRC train: 0.999711	val: 0.814559	test: 0.691206

Epoch: 49
Loss: 0.08392164953316929
ROC train: 0.998841	val: 0.889792	test: 0.634934
PRC train: 0.999769	val: 0.800446	test: 0.667764

Epoch: 50
Loss: 0.07685341402189073
ROC train: 0.999352	val: 0.888789	test: 0.623071
PRC train: 0.999872	val: 0.788309	test: 0.667892

Epoch: 51
Loss: 0.0875425330983667
ROC train: 0.998945	val: 0.908562	test: 0.645930
PRC train: 0.999786	val: 0.837353	test: 0.681117

Epoch: 52
Loss: 0.09200138671232087
ROC train: 0.998508	val: 0.898926	test: 0.663484
PRC train: 0.999684	val: 0.828864	test: 0.689321

Epoch: 53
Loss: 0.07438896975613245
ROC train: 0.998897	val: 0.898123	test: 0.623650
PRC train: 0.999782	val: 0.805414	test: 0.618235

Epoch: 54
Loss: 0.0750049114761223
ROC train: 0.999574	val: 0.899328	test: 0.646605
PRC train: 0.999916	val: 0.816789	test: 0.686582

Epoch: 55
Loss: 0.07697323654701635
ROC train: 0.999501	val: 0.893606	test: 0.658372
PRC train: 0.999904	val: 0.815059	test: 0.718148

Epoch: 56
Loss: 0.06829237636588102
ROC train: 0.999849	val: 0.895513	test: 0.624614
PRC train: 0.999971	val: 0.795396	test: 0.672850

Epoch: 57
Loss: 0.06683711519339938
ROC train: 0.999773	val: 0.905350	test: 0.661651
PRC train: 0.999956	val: 0.806687	test: 0.693555

Epoch: 58
Loss: 0.06456948783443643
ROC train: 0.999784	val: 0.901235	test: 0.659819
PRC train: 0.999958	val: 0.807422	test: 0.701731

Epoch: 59
Loss: 0.058145858064684565
ROC train: 0.999947	val: 0.893506	test: 0.618056
PRC train: 0.999990	val: 0.790054	test: 0.673104

Epoch: 60
Loss: 0.09337901125953911
ROC train: 0.999916	val: 0.901134	test: 0.594329
PRC train: 0.999984	val: 0.790513	test: 0.639962

Epoch: 61
Loss: 0.059026826265887115
ROC train: 0.999927	val: 0.899227	test: 0.602045
PRC train: 0.999986	val: 0.794634	test: 0.649032

Epoch: 62
Loss: 0.06449488383376799
ROC train: 0.999613	val: 0.905952	test: 0.662133
PRC train: 0.999923	val: 0.835888	test: 0.704403

Epoch: 63
Loss: 0.06277200147138416
ROC train: 0.999745	val: 0.907658	test: 0.631269
PRC train: 0.999951	val: 0.833133	test: 0.671860

Epoch: 64
Loss: 0.07173926965894255
ROC train: 0.999874	val: 0.917394	test: 0.627990
PRC train: 0.999976	val: 0.825941	test: 0.663719

Epoch: 65
Loss: 0.06670924821744131
ROC train: 0.999843	val: 0.903643	test: 0.621046
PRC train: 0.999970	val: 0.811174	test: 0.661454

Epoch: 66
Loss: 0.05405788414973507
ROC train: 0.999778	val: 0.900632	test: 0.613040
PRC train: 0.999958	val: 0.804619	test: 0.653716

Epoch: 67
Loss: 0.05826419490669899
ROC train: 0.999756	val: 0.903744	test: 0.613137
PRC train: 0.999953	val: 0.803800	test: 0.653807

Epoch: 68
Loss: 0.04480718848980259
ROC train: 0.999961	val: 0.907257	test: 0.622975
PRC train: 0.999993	val: 0.806454	test: 0.666234

Epoch: 69
Loss: 0.04863031344677011
ROC train: 0.999966	val: 0.908461	test: 0.632812
PRC train: 0.999994	val: 0.807620	test: 0.655105

Epoch: 70
Loss: 0.04667934921509183
ROC train: 1.000000	val: 0.896417	test: 0.623553
PRC train: 1.000000	val: 0.800901	test: 0.655019

Epoch: 71
Loss: 0.05326746640393461
ROC train: 1.000000	val: 0.908662	test: 0.629533
PRC train: 1.000000	val: 0.814447	test: 0.668047

Epoch: 72
Loss: 0.03914054066402287
ROC train: 0.999975	val: 0.906655	test: 0.622203
PRC train: 0.999995	val: 0.807443	test: 0.659699

Epoch: 73
Loss: 0.04709746885741817
ROC train: 0.999997	val: 0.902941	test: 0.621142
PRC train: 0.999999	val: 0.810101	test: 0.671196

Epoch: 74
Loss: 0.045724092414198815
ROC train: 0.999955	val: 0.897922	test: 0.642747
PRC train: 0.999991	val: 0.798798	test: 0.680158

Epoch: 75
Loss: 0.04913437742098362
ROC train: 0.999986	val: 0.890696	test: 0.629437
PRC train: 0.999997	val: 0.781343	test: 0.667142

Epoch: 76
Loss: 0.06351495590894121
ROC train: 0.999997	val: 0.878450	test: 0.573013
PRC train: 0.999999	val: 0.767867	test: 0.616090

Epoch: 77
Loss: 0.044266850425560035
ROC train: 1.000000	val: 0.896919	test: 0.608893
PRC train: 1.000000	val: 0.795125	test: 0.649214

Epoch: 78
Loss: 0.03858555649554032
ROC train: 0.999980	val: 0.907558	test: 0.671007
PRC train: 0.999996	val: 0.814702	test: 0.710257

Epoch: 79
Loss: 0.04060296400472675
ROC train: 1.000000	val: 0.896015	test: 0.625965
PRC train: 1.000000	val: 0.790415	test: 0.676953

Epoch: 80
Loss: 0.039877755855845444
ROC train: 0.999899	val: 0.906354	test: 0.606481
PRC train: 0.999981	val: 0.803642	test: 0.660388

Epoch: 81
Loss: 0.03555636903469608
ROC train: 0.999795	val: 0.913078	test: 0.609279
PRC train: 0.999960	val: 0.808755	test: 0.639012

Epoch: 82
Loss: 0.045682243151758825
ROC train: 0.999933	val: 0.912677	test: 0.614101
PRC train: 0.999987	val: 0.823773	test: 0.646777

Epoch: 83
Loss: 0.055952700282321785
ROC train: 0.999964	val: 0.901837	test: 0.632137
PRC train: 0.999993	val: 0.810430	test: 0.687105

Epoch: 84
Loss: 0.03940838134073037
ROC train: 0.999952	val: 0.885577	test: 0.608121
PRC train: 0.999991	val: 0.775637	test: 0.653259

Epoch: 85
Loss: 0.05908796998778363
ROC train: 0.999997	val: 0.889792	test: 0.594715
PRC train: 0.999999	val: 0.780341	test: 0.639239

Epoch: 86
Loss: 0.04193491437003887
ROC train: 0.999992	val: 0.909465	test: 0.602238
PRC train: 0.999998	val: 0.830412	test: 0.666617

Epoch: 87
Loss: 0.04318238709861678
ROC train: 0.999947	val: 0.909465	test: 0.630498
PRC train: 0.999990	val: 0.820372	test: 0.691204

Epoch: 88
Loss: 0.06649093634992116
ROC train: 1.000000	val: 0.909766	test: 0.655671
PRC train: 1.000000	val: 0.825199	test: 0.712541

Epoch: 89
Loss: 0.04201301509113697
ROC train: 0.999997	val: 0.913681	test: 0.644869
PRC train: 0.999999	val: 0.831414	test: 0.695111

Epoch: 90
Loss: 0.04295998271485372
ROC train: 1.000000	val: 0.902339	test: 0.607735
PRC train: 1.000000	val: 0.813977	test: 0.668406

Epoch: 91
Loss: 0.037171428578353205
ROC train: 1.000000	val: 0.902439	test: 0.589506
PRC train: 1.000000	val: 0.823575	test: 0.657315

Epoch: 92
Loss: 0.03185700692895057
ROC train: 1.000000	val: 0.912677	test: 0.595100
PRC train: 1.000000	val: 0.835631	test: 0.652190

Epoch: 93
Loss: 0.03146740402259709
ROC train: 1.000000	val: 0.914684	test: 0.595004
PRC train: 0.999520	val: 0.789044	test: 0.683446

Epoch: 95
Loss: 0.09988170733863229
ROC train: 0.998146	val: 0.875941	test: 0.656539
PRC train: 0.999646	val: 0.768871	test: 0.675737

Epoch: 96
Loss: 0.09038623726503273
ROC train: 0.997834	val: 0.875238	test: 0.672550
PRC train: 0.999586	val: 0.781444	test: 0.684572

Epoch: 97
Loss: 0.07348753185350933
ROC train: 0.997998	val: 0.874435	test: 0.681617
PRC train: 0.999615	val: 0.771401	test: 0.694103

Epoch: 98
Loss: 0.09586942567491843
ROC train: 0.998397	val: 0.872930	test: 0.665027
PRC train: 0.999694	val: 0.772468	test: 0.666460

Epoch: 99
Loss: 0.06551012739428519
ROC train: 0.996576	val: 0.876443	test: 0.644965
PRC train: 0.999299	val: 0.790578	test: 0.651554

Epoch: 100
Loss: 0.0964674123114424
ROC train: 0.998625	val: 0.876342	test: 0.629630
PRC train: 0.999739	val: 0.796653	test: 0.644377

Epoch: 101
Loss: 0.08253234125046593
ROC train: 0.998600	val: 0.879655	test: 0.638310
PRC train: 0.999735	val: 0.789310	test: 0.648749

Epoch: 102
Loss: 0.0862949362305501
ROC train: 0.998597	val: 0.877647	test: 0.652006
PRC train: 0.999733	val: 0.791539	test: 0.655498

Epoch: 103
Loss: 0.07193734328464861
ROC train: 0.998442	val: 0.867108	test: 0.641782
PRC train: 0.999705	val: 0.776504	test: 0.645134

Epoch: 104
Loss: 0.08119443576241717
ROC train: 0.998949	val: 0.874837	test: 0.644579
PRC train: 0.999801	val: 0.779767	test: 0.648300

Epoch: 105
Loss: 0.07405769685297667
ROC train: 0.998906	val: 0.873131	test: 0.641782
PRC train: 0.999792	val: 0.776190	test: 0.635061

Epoch: 106
Loss: 0.08651432921768806
ROC train: 0.999041	val: 0.882867	test: 0.648920
PRC train: 0.999817	val: 0.779846	test: 0.635593

Epoch: 107
Loss: 0.07656685638406342
ROC train: 0.998617	val: 0.880859	test: 0.642554
PRC train: 0.999735	val: 0.780804	test: 0.641436

Epoch: 108
Loss: 0.08007958009078917
ROC train: 0.998729	val: 0.873030	test: 0.643133
PRC train: 0.999759	val: 0.769291	test: 0.646013

Epoch: 109
Loss: 0.07042284690977473
ROC train: 0.998052	val: 0.857774	test: 0.651138
PRC train: 0.999632	val: 0.753498	test: 0.657574

Epoch: 110
Loss: 0.09437701952798384
ROC train: 0.999074	val: 0.868714	test: 0.633488
PRC train: 0.999824	val: 0.760368	test: 0.642680

Epoch: 111
Loss: 0.06598832060807913
ROC train: 0.998921	val: 0.870521	test: 0.626350
PRC train: 0.999795	val: 0.766794	test: 0.637402

Epoch: 112
Loss: 0.06730453928725956
ROC train: 0.999153	val: 0.875640	test: 0.656154
PRC train: 0.999839	val: 0.771608	test: 0.668464

Epoch: 113
Loss: 0.0643956095457172
ROC train: 0.999122	val: 0.873733	test: 0.656250
PRC train: 0.999833	val: 0.778278	test: 0.667476

Epoch: 114
Loss: 0.07336555792492183
ROC train: 0.999052	val: 0.876543	test: 0.642072
PRC train: 0.999820	val: 0.785191	test: 0.641608

Epoch: 115
Loss: 0.06617790430693524
ROC train: 0.999157	val: 0.871424	test: 0.635706
PRC train: 0.999839	val: 0.779033	test: 0.626144

Epoch: 116
Loss: 0.060746574987773715
ROC train: 0.999271	val: 0.870822	test: 0.650752
PRC train: 0.999860	val: 0.783104	test: 0.648712

Epoch: 117
Loss: 0.07202341665330947
ROC train: 0.999213	val: 0.863696	test: 0.667728
PRC train: 0.999848	val: 0.784000	test: 0.665042

Epoch: 118
Loss: 0.05861189464858429
ROC train: 0.999328	val: 0.864398	test: 0.662616
PRC train: 0.999872	val: 0.780709	test: 0.666870

Epoch: 119
Loss: 0.061309128464877585
ROC train: 0.999419	val: 0.870220	test: 0.635513
PRC train: 0.999889	val: 0.776244	test: 0.629911

Epoch: 120
Loss: 0.05572909299222445
ROC train: 0.998910	val: 0.870922	test: 0.622203
PRC train: 0.999792	val: 0.772996	test: 0.611592

Early stopping
Best (ROC):	 train: 0.989640	val: 0.903443	test: 0.692805
Best (PRC):	 train: 0.997925	val: 0.821890	test: 0.707679

PRC train: 0.999474	val: 0.802762	test: 0.709567

Epoch: 95
Loss: 0.09651426038886335
ROC train: 0.996781	val: 0.870822	test: 0.676119
PRC train: 0.999384	val: 0.792033	test: 0.688691

Epoch: 96
Loss: 0.1045248837546058
ROC train: 0.996845	val: 0.858878	test: 0.683738
PRC train: 0.999371	val: 0.772408	test: 0.710514

Epoch: 97
Loss: 0.08045859409367526
ROC train: 0.994733	val: 0.882666	test: 0.699653
PRC train: 0.998976	val: 0.793801	test: 0.737656

Epoch: 98
Loss: 0.086100893853859
ROC train: 0.997858	val: 0.887283	test: 0.694444
PRC train: 0.999593	val: 0.792284	test: 0.729304

Epoch: 99
Loss: 0.0828144788805728
ROC train: 0.997475	val: 0.883168	test: 0.670525
PRC train: 0.999515	val: 0.806171	test: 0.685905

Epoch: 100
Loss: 0.0705513621228962
ROC train: 0.998307	val: 0.888487	test: 0.680363
PRC train: 0.999677	val: 0.805143	test: 0.694519

Epoch: 101
Loss: 0.07328822625586064
ROC train: 0.998693	val: 0.889993	test: 0.680845
PRC train: 0.999752	val: 0.787566	test: 0.691209

Epoch: 102
Loss: 0.07070368767932173
ROC train: 0.998450	val: 0.885276	test: 0.676987
PRC train: 0.999705	val: 0.776136	test: 0.687664

Epoch: 103
Loss: 0.08068221427636693
ROC train: 0.998472	val: 0.886681	test: 0.670332
PRC train: 0.999710	val: 0.789371	test: 0.670252

Epoch: 104
Loss: 0.08050956275873991
ROC train: 0.998642	val: 0.890194	test: 0.678337
PRC train: 0.999741	val: 0.797435	test: 0.676118

Epoch: 105
Loss: 0.06732840846580629
ROC train: 0.998609	val: 0.892302	test: 0.693094
PRC train: 0.999737	val: 0.805797	test: 0.718262

Epoch: 106
Loss: 0.0785895480070725
ROC train: 0.998691	val: 0.887082	test: 0.694155
PRC train: 0.999750	val: 0.805071	test: 0.735353

Epoch: 107
Loss: 0.07477689801425609
ROC train: 0.998627	val: 0.879454	test: 0.682099
PRC train: 0.999739	val: 0.787264	test: 0.712493

Epoch: 108
Loss: 0.07643967542039157
ROC train: 0.998555	val: 0.871625	test: 0.684606
PRC train: 0.999726	val: 0.768281	test: 0.697496

Epoch: 109
Loss: 0.07976977422123431
ROC train: 0.998655	val: 0.876342	test: 0.696663
PRC train: 0.999745	val: 0.770580	test: 0.698522

Epoch: 110
Loss: 0.07644282006470685
ROC train: 0.997660	val: 0.885978	test: 0.689525
PRC train: 0.999556	val: 0.794172	test: 0.699689

Epoch: 111
Loss: 0.0894711116139743
ROC train: 0.998799	val: 0.881562	test: 0.701389
PRC train: 0.999772	val: 0.792473	test: 0.720951

Epoch: 112
Loss: 0.07603623372191781
ROC train: 0.998878	val: 0.885476	test: 0.696181
PRC train: 0.999786	val: 0.829816	test: 0.710627

Epoch: 113
Loss: 0.07106782748016525
ROC train: 0.998935	val: 0.888086	test: 0.683256
PRC train: 0.999797	val: 0.829465	test: 0.700582

Epoch: 114
Loss: 0.06934509427862015
ROC train: 0.998583	val: 0.877045	test: 0.683256
PRC train: 0.999729	val: 0.789679	test: 0.695781

Epoch: 115
Loss: 0.06104667960290511
ROC train: 0.998670	val: 0.871224	test: 0.680459
PRC train: 0.999747	val: 0.774459	test: 0.695802

Epoch: 116
Loss: 0.06317700145778121
ROC train: 0.999055	val: 0.871123	test: 0.682292
PRC train: 0.999819	val: 0.802063	test: 0.704257

Epoch: 117
Loss: 0.05684173486769063
ROC train: 0.998766	val: 0.872328	test: 0.679880
PRC train: 0.999764	val: 0.805138	test: 0.704600

Epoch: 118
Loss: 0.07845464724527808
ROC train: 0.998582	val: 0.876744	test: 0.685860
PRC train: 0.999731	val: 0.791589	test: 0.708577

Epoch: 119
Loss: 0.061457015932923124
ROC train: 0.998408	val: 0.874335	test: 0.692998
PRC train: 0.999697	val: 0.770251	test: 0.732079

Epoch: 120
Loss: 0.07241641646302922
ROC train: 0.998983	val: 0.881662	test: 0.677083
PRC train: 0.999807	val: 0.797569	test: 0.701342

Early stopping
Best (ROC):	 train: 0.882281	val: 0.910770	test: 0.630691
Best (PRC):	 train: 0.970409	val: 0.825886	test: 0.681805

PRC train: 0.999625	val: 0.806677	test: 0.694728

Epoch: 95
Loss: 0.07292537171155385
ROC train: 0.998409	val: 0.890796	test: 0.674865
PRC train: 0.999693	val: 0.799200	test: 0.672872

Epoch: 96
Loss: 0.07166098469940696
ROC train: 0.997481	val: 0.886781	test: 0.671586
PRC train: 0.999516	val: 0.801029	test: 0.663918

Epoch: 97
Loss: 0.07956808803854458
ROC train: 0.998747	val: 0.869618	test: 0.667728
PRC train: 0.999762	val: 0.768266	test: 0.652419

Epoch: 98
Loss: 0.07958496702607414
ROC train: 0.999028	val: 0.866105	test: 0.661362
PRC train: 0.999816	val: 0.753099	test: 0.658128

Epoch: 99
Loss: 0.07368589851740474
ROC train: 0.998815	val: 0.864699	test: 0.674672
PRC train: 0.999773	val: 0.754403	test: 0.679274

Epoch: 100
Loss: 0.0683121190086748
ROC train: 0.998698	val: 0.869015	test: 0.687693
PRC train: 0.999749	val: 0.773622	test: 0.697964

Epoch: 101
Loss: 0.08408661932841201
ROC train: 0.998672	val: 0.870421	test: 0.673032
PRC train: 0.999745	val: 0.778991	test: 0.669447

Epoch: 102
Loss: 0.07889804481958804
ROC train: 0.998631	val: 0.878751	test: 0.661362
PRC train: 0.999738	val: 0.799500	test: 0.670140

Epoch: 103
Loss: 0.07972295998361613
ROC train: 0.998283	val: 0.871224	test: 0.684606
PRC train: 0.999672	val: 0.783531	test: 0.696436

Epoch: 104
Loss: 0.07371046849615581
ROC train: 0.998370	val: 0.878450	test: 0.704379
PRC train: 0.999689	val: 0.780175	test: 0.722472

Epoch: 105
Loss: 0.07192047338218478
ROC train: 0.998916	val: 0.875941	test: 0.676505
PRC train: 0.999793	val: 0.785469	test: 0.698386

Epoch: 106
Loss: 0.07772733561502686
ROC train: 0.998840	val: 0.872930	test: 0.662230
PRC train: 0.999777	val: 0.774681	test: 0.673246

Epoch: 107
Loss: 0.09844871467801217
ROC train: 0.998492	val: 0.886681	test: 0.676022
PRC train: 0.999711	val: 0.798821	test: 0.693527

Epoch: 108
Loss: 0.0814097725128993
ROC train: 0.998199	val: 0.864298	test: 0.661073
PRC train: 0.999651	val: 0.750659	test: 0.638629

Epoch: 109
Loss: 0.07133767156701173
ROC train: 0.998975	val: 0.882967	test: 0.683063
PRC train: 0.999804	val: 0.784147	test: 0.684660

Epoch: 110
Loss: 0.07392314264650725
ROC train: 0.999192	val: 0.878350	test: 0.675637
PRC train: 0.999845	val: 0.772603	test: 0.679012

Epoch: 111
Loss: 0.07245529753855642
ROC train: 0.998815	val: 0.869417	test: 0.668596
PRC train: 0.999778	val: 0.750149	test: 0.661243

Epoch: 112
Loss: 0.10519358561872079
ROC train: 0.998106	val: 0.876945	test: 0.695602
PRC train: 0.999640	val: 0.758068	test: 0.683438

Epoch: 113
Loss: 0.08472589697523933
ROC train: 0.998499	val: 0.881160	test: 0.684317
PRC train: 0.999715	val: 0.770620	test: 0.686532

Epoch: 114
Loss: 0.07022984570904962
ROC train: 0.998778	val: 0.881060	test: 0.679205
PRC train: 0.999768	val: 0.789006	test: 0.705689

Epoch: 115
Loss: 0.07079939410976184
ROC train: 0.999168	val: 0.882164	test: 0.675926
PRC train: 0.999841	val: 0.802153	test: 0.699009

Epoch: 116
Loss: 0.06732185090366545
ROC train: 0.999423	val: 0.878551	test: 0.680556
PRC train: 0.999889	val: 0.795257	test: 0.688615

Epoch: 117
Loss: 0.06366027329965233
ROC train: 0.999142	val: 0.884071	test: 0.697434
PRC train: 0.999835	val: 0.807415	test: 0.704595

Epoch: 118
Loss: 0.06166864558234072
ROC train: 0.998764	val: 0.892402	test: 0.685957
PRC train: 0.999765	val: 0.818861	test: 0.701370

Epoch: 119
Loss: 0.07422011134893435
ROC train: 0.999386	val: 0.895112	test: 0.668789
PRC train: 0.999881	val: 0.836198	test: 0.689631

Epoch: 120
Loss: 0.06808739923234594
ROC train: 0.999360	val: 0.885577	test: 0.682967
PRC train: 0.999878	val: 0.811997	test: 0.697137

Early stopping
Best (ROC):	 train: 0.885450	val: 0.919101	test: 0.688465
Best (PRC):	 train: 0.969860	val: 0.812304	test: 0.747713
All runs completed.

ROC train: 1.000000	val: 0.887885	test: 0.651235
PRC train: 1.000000	val: 0.805857	test: 0.693133

Epoch: 94
Loss: 0.030185749909721424
ROC train: 1.000000	val: 0.889190	test: 0.636863
PRC train: 1.000000	val: 0.803573	test: 0.676350

Epoch: 95
Loss: 0.026665833030356027
ROC train: 1.000000	val: 0.890997	test: 0.643904
PRC train: 1.000000	val: 0.804438	test: 0.685310

Epoch: 96
Loss: 0.025885029284891285
ROC train: 1.000000	val: 0.904346	test: 0.653164
PRC train: 1.000000	val: 0.832055	test: 0.685063

Epoch: 97
Loss: 0.03387116864479402
ROC train: 1.000000	val: 0.905049	test: 0.659336
PRC train: 1.000000	val: 0.838527	test: 0.695042

Epoch: 98
Loss: 0.029402633514846784
ROC train: 1.000000	val: 0.908562	test: 0.657407
PRC train: 1.000000	val: 0.846085	test: 0.685903

Epoch: 99
Loss: 0.02843628403487578
ROC train: 1.000000	val: 0.887584	test: 0.653742
PRC train: 1.000000	val: 0.802450	test: 0.711942

Epoch: 100
Loss: 0.030067056911353116
ROC train: 1.000000	val: 0.886681	test: 0.654225
PRC train: 1.000000	val: 0.797551	test: 0.717552

Epoch: 101
Loss: 0.029722768064535186
ROC train: 1.000000	val: 0.893104	test: 0.666281
PRC train: 1.000000	val: 0.815111	test: 0.679893

Epoch: 102
Loss: 0.0246136958639901
ROC train: 1.000000	val: 0.888086	test: 0.671103
PRC train: 1.000000	val: 0.804745	test: 0.683118

Epoch: 103
Loss: 0.03326030333111146
ROC train: 0.999997	val: 0.884673	test: 0.666474
PRC train: 0.999999	val: 0.805613	test: 0.675590

Epoch: 104
Loss: 0.022609184585703046
ROC train: 1.000000	val: 0.880458	test: 0.657022
PRC train: 1.000000	val: 0.791435	test: 0.667376

Epoch: 105
Loss: 0.018460981265157845
ROC train: 1.000000	val: 0.891900	test: 0.649306
PRC train: 1.000000	val: 0.803511	test: 0.662202

Epoch: 106
Loss: 0.02086353839272959
ROC train: 1.000000	val: 0.892201	test: 0.636285
PRC train: 1.000000	val: 0.797350	test: 0.683837

Epoch: 107
Loss: 0.023384837415701572
ROC train: 1.000000	val: 0.897220	test: 0.646316
PRC train: 1.000000	val: 0.807609	test: 0.692576

Epoch: 108
Loss: 0.01557157580252507
ROC train: 0.999997	val: 0.897420	test: 0.644483
PRC train: 0.999999	val: 0.814119	test: 0.682423

Epoch: 109
Loss: 0.025522989090994968
ROC train: 0.999997	val: 0.903543	test: 0.643133
PRC train: 0.999999	val: 0.828134	test: 0.681436

Epoch: 110
Loss: 0.029128167874494352
ROC train: 1.000000	val: 0.899528	test: 0.655478
PRC train: 1.000000	val: 0.811314	test: 0.690876

Epoch: 111
Loss: 0.020082205668794786
ROC train: 1.000000	val: 0.904446	test: 0.663194
PRC train: 1.000000	val: 0.817836	test: 0.700356

Epoch: 112
Loss: 0.01843613925610498
ROC train: 1.000000	val: 0.902841	test: 0.654803
PRC train: 1.000000	val: 0.815365	test: 0.687412

Epoch: 113
Loss: 0.01648050093799423
ROC train: 1.000000	val: 0.902539	test: 0.643519
PRC train: 1.000000	val: 0.826406	test: 0.676822

Epoch: 114
Loss: 0.017174979642532666
ROC train: 1.000000	val: 0.899729	test: 0.642168
PRC train: 1.000000	val: 0.817899	test: 0.669938

Epoch: 115
Loss: 0.0244630976709987
ROC train: 1.000000	val: 0.898826	test: 0.644676
PRC train: 1.000000	val: 0.815912	test: 0.684633

Epoch: 116
Loss: 0.023228070218363428
ROC train: 1.000000	val: 0.900632	test: 0.635802
PRC train: 1.000000	val: 0.828264	test: 0.684985

Epoch: 117
Loss: 0.022460399437835954
ROC train: 1.000000	val: 0.889792	test: 0.638503
PRC train: 1.000000	val: 0.807492	test: 0.670910

Epoch: 118
Loss: 0.015559866680469948
ROC train: 1.000000	val: 0.879855	test: 0.631462
PRC train: 1.000000	val: 0.786823	test: 0.676030

Epoch: 119
Loss: 0.02074243568441824
ROC train: 1.000000	val: 0.884974	test: 0.635417
PRC train: 1.000000	val: 0.794279	test: 0.675325

Epoch: 120
Loss: 0.020019505202558432
ROC train: 1.000000	val: 0.877748	test: 0.634163
PRC train: 1.000000	val: 0.786968	test: 0.688710

Early stopping
Best (ROC):	 train: 0.882416	val: 0.916391	test: 0.628183
Best (PRC):	 train: 0.969540	val: 0.847952	test: 0.638389

ROC train: 1.000000	val: 0.910469	test: 0.687596
PRC train: 1.000000	val: 0.876068	test: 0.756815

Epoch: 94
Loss: 0.023306872011269537
ROC train: 1.000000	val: 0.912878	test: 0.679109
PRC train: 1.000000	val: 0.877189	test: 0.754211

Epoch: 95
Loss: 0.018460553728021554
ROC train: 1.000000	val: 0.908461	test: 0.671971
PRC train: 1.000000	val: 0.868223	test: 0.742321

Epoch: 96
Loss: 0.01957882246881099
ROC train: 1.000000	val: 0.903744	test: 0.679591
PRC train: 1.000000	val: 0.864464	test: 0.740524

Epoch: 97
Loss: 0.03991336551081038
ROC train: 1.000000	val: 0.907056	test: 0.688175
PRC train: 1.000000	val: 0.870600	test: 0.747086

Epoch: 98
Loss: 0.02236290588240052
ROC train: 1.000000	val: 0.892603	test: 0.681231
PRC train: 1.000000	val: 0.841690	test: 0.743030

Epoch: 99
Loss: 0.021417145551898546
ROC train: 1.000000	val: 0.886078	test: 0.681520
PRC train: 1.000000	val: 0.822801	test: 0.742665

Epoch: 100
Loss: 0.037267713225942266
ROC train: 1.000000	val: 0.894409	test: 0.683353
PRC train: 1.000000	val: 0.844329	test: 0.748502

Epoch: 101
Loss: 0.04127313585016189
ROC train: 1.000000	val: 0.901235	test: 0.680266
PRC train: 1.000000	val: 0.846721	test: 0.753457

Epoch: 102
Loss: 0.030669209750869265
ROC train: 0.999997	val: 0.903142	test: 0.687596
PRC train: 0.999999	val: 0.828985	test: 0.764820

Epoch: 103
Loss: 0.030430965619096393
ROC train: 1.000000	val: 0.906454	test: 0.679977
PRC train: 1.000000	val: 0.871760	test: 0.749732

Epoch: 104
Loss: 0.03535009490430541
ROC train: 1.000000	val: 0.901435	test: 0.676119
PRC train: 1.000000	val: 0.872825	test: 0.736070

Epoch: 105
Loss: 0.026116260592175315
ROC train: 1.000000	val: 0.908160	test: 0.684028
PRC train: 1.000000	val: 0.874299	test: 0.751727

Epoch: 106
Loss: 0.022654167530287043
ROC train: 0.999994	val: 0.906253	test: 0.683063
PRC train: 0.999999	val: 0.855900	test: 0.757942

Epoch: 107
Loss: 0.034761230546123845
ROC train: 1.000000	val: 0.913179	test: 0.692612
PRC train: 1.000000	val: 0.866750	test: 0.758812

Epoch: 108
Loss: 0.01671647486944276
ROC train: 0.999997	val: 0.891699	test: 0.687596
PRC train: 0.999999	val: 0.853330	test: 0.751115

Epoch: 109
Loss: 0.0277013298540276
ROC train: 1.000000	val: 0.902740	test: 0.680266
PRC train: 1.000000	val: 0.867922	test: 0.744657

Epoch: 110
Loss: 0.025162064222144686
ROC train: 1.000000	val: 0.908361	test: 0.677951
PRC train: 1.000000	val: 0.866766	test: 0.734360

Epoch: 111
Loss: 0.025684361584798785
ROC train: 1.000000	val: 0.913179	test: 0.672454
PRC train: 1.000000	val: 0.867186	test: 0.732066

Epoch: 112
Loss: 0.018547194740082578
ROC train: 1.000000	val: 0.911573	test: 0.671875
PRC train: 1.000000	val: 0.861389	test: 0.735621

Epoch: 113
Loss: 0.02607396350868918
ROC train: 1.000000	val: 0.907859	test: 0.665509
PRC train: 1.000000	val: 0.861181	test: 0.738762

Epoch: 114
Loss: 0.023416846366724815
ROC train: 1.000000	val: 0.915989	test: 0.664448
PRC train: 1.000000	val: 0.880280	test: 0.743324

Epoch: 115
Loss: 0.01937973066860485
ROC train: 1.000000	val: 0.920104	test: 0.673225
PRC train: 1.000000	val: 0.893474	test: 0.752338

Epoch: 116
Loss: 0.020128147633182547
ROC train: 1.000000	val: 0.913681	test: 0.673900
PRC train: 1.000000	val: 0.876024	test: 0.750310

Epoch: 117
Loss: 0.017207917665847745
ROC train: 1.000000	val: 0.915989	test: 0.671296
PRC train: 1.000000	val: 0.873991	test: 0.745261

Epoch: 118
Loss: 0.012364335613819222
ROC train: 1.000000	val: 0.917796	test: 0.667824
PRC train: 1.000000	val: 0.877259	test: 0.738703

Epoch: 119
Loss: 0.014045817488033602
ROC train: 1.000000	val: 0.916893	test: 0.670428
PRC train: 1.000000	val: 0.872176	test: 0.734376

Epoch: 120
Loss: 0.01627769046125096
ROC train: 1.000000	val: 0.916290	test: 0.674093
PRC train: 1.000000	val: 0.871240	test: 0.737585

Early stopping
Best (ROC):	 train: 1.000000	val: 0.924621	test: 0.689429
Best (PRC):	 train: 1.000000	val: 0.877113	test: 0.757059

PRC train: 1.000000	val: 0.742757	test: 0.666522

Epoch: 94
Loss: 0.03318763891890244
ROC train: 0.999997	val: 0.858075	test: 0.642747
PRC train: 0.999999	val: 0.736661	test: 0.691652

Epoch: 95
Loss: 0.030867937087324816
ROC train: 1.000000	val: 0.866807	test: 0.654417
PRC train: 1.000000	val: 0.738497	test: 0.695623

Epoch: 96
Loss: 0.02505565547370936
ROC train: 0.999997	val: 0.863093	test: 0.653935
PRC train: 0.999999	val: 0.743881	test: 0.687205

Epoch: 97
Loss: 0.020708718088013302
ROC train: 1.000000	val: 0.860283	test: 0.644194
PRC train: 1.000000	val: 0.737944	test: 0.677491

Epoch: 98
Loss: 0.022166707484088034
ROC train: 1.000000	val: 0.848038	test: 0.626833
PRC train: 1.000000	val: 0.716042	test: 0.665019

Epoch: 99
Loss: 0.02698686183818092
ROC train: 1.000000	val: 0.850346	test: 0.637153
PRC train: 1.000000	val: 0.727227	test: 0.684897

Epoch: 100
Loss: 0.024062540590336575
ROC train: 1.000000	val: 0.857172	test: 0.639275
PRC train: 1.000000	val: 0.739692	test: 0.689088

Epoch: 101
Loss: 0.02632005858356008
ROC train: 1.000000	val: 0.868915	test: 0.655382
PRC train: 1.000000	val: 0.766516	test: 0.699527

Epoch: 102
Loss: 0.01428267318318738
ROC train: 1.000000	val: 0.864097	test: 0.653453
PRC train: 1.000000	val: 0.761813	test: 0.696795

Epoch: 103
Loss: 0.01989517155976284
ROC train: 1.000000	val: 0.864097	test: 0.655961
PRC train: 1.000000	val: 0.759735	test: 0.695766

Epoch: 104
Loss: 0.01789283012502017
ROC train: 1.000000	val: 0.857975	test: 0.654417
PRC train: 1.000000	val: 0.746753	test: 0.693967

Epoch: 105
Loss: 0.009461106698458293
ROC train: 1.000000	val: 0.853558	test: 0.649306
PRC train: 1.000000	val: 0.718944	test: 0.690352

Epoch: 106
Loss: 0.01704105660770487
ROC train: 1.000000	val: 0.844625	test: 0.641011
PRC train: 1.000000	val: 0.702014	test: 0.676244

Epoch: 107
Loss: 0.01722067405877504
ROC train: 1.000000	val: 0.850848	test: 0.652006
PRC train: 1.000000	val: 0.708426	test: 0.690402

Epoch: 108
Loss: 0.01925713192249573
ROC train: 1.000000	val: 0.842618	test: 0.641011
PRC train: 1.000000	val: 0.703422	test: 0.678459

Epoch: 109
Loss: 0.025258230321548177
ROC train: 0.999992	val: 0.847134	test: 0.626350
PRC train: 0.999998	val: 0.706429	test: 0.659357

Epoch: 110
Loss: 0.01765108794310997
ROC train: 1.000000	val: 0.849644	test: 0.639275
PRC train: 1.000000	val: 0.705695	test: 0.684244

Epoch: 111
Loss: 0.016473575663476202
ROC train: 1.000000	val: 0.861889	test: 0.648920
PRC train: 1.000000	val: 0.739774	test: 0.688549

Epoch: 112
Loss: 0.02005025977738211
ROC train: 1.000000	val: 0.868714	test: 0.650752
PRC train: 1.000000	val: 0.753869	test: 0.680810

Epoch: 113
Loss: 0.016459967001885668
ROC train: 1.000000	val: 0.867008	test: 0.658758
PRC train: 1.000000	val: 0.767833	test: 0.673788

Epoch: 114
Loss: 0.01982214294895881
ROC train: 1.000000	val: 0.859179	test: 0.653549
PRC train: 1.000000	val: 0.739155	test: 0.680782

Epoch: 115
Loss: 0.014784410002458583
ROC train: 1.000000	val: 0.861789	test: 0.649498
PRC train: 1.000000	val: 0.733943	test: 0.679055

Epoch: 116
Loss: 0.01656756524564101
ROC train: 1.000000	val: 0.848238	test: 0.648341
PRC train: 1.000000	val: 0.725233	test: 0.685265

Epoch: 117
Loss: 0.013235283994893505
ROC train: 1.000000	val: 0.843220	test: 0.648534
PRC train: 1.000000	val: 0.704780	test: 0.673235

Epoch: 118
Loss: 0.024612924712420964
ROC train: 1.000000	val: 0.861186	test: 0.654321
PRC train: 1.000000	val: 0.724265	test: 0.680085

Epoch: 119
Loss: 0.022192131407898077
ROC train: 1.000000	val: 0.851250	test: 0.641204
PRC train: 1.000000	val: 0.709170	test: 0.679363

Epoch: 120
Loss: 0.021760464125804718
ROC train: 1.000000	val: 0.864499	test: 0.659819
PRC train: 1.000000	val: 0.736324	test: 0.687111

Early stopping
Best (ROC):	 train: 0.868333	val: 0.915186	test: 0.645062
Best (PRC):	 train: 0.967110	val: 0.869227	test: 0.694059

ROC train: 0.999997	val: 0.891499	test: 0.708526
PRC train: 0.999999	val: 0.805729	test: 0.744056

Epoch: 94
Loss: 0.045283054866616886
ROC train: 1.000000	val: 0.898525	test: 0.704475
PRC train: 1.000000	val: 0.814512	test: 0.728744

Epoch: 95
Loss: 0.040681392649472334
ROC train: 1.000000	val: 0.893205	test: 0.698399
PRC train: 1.000000	val: 0.811726	test: 0.723449

Epoch: 96
Loss: 0.05788476762807958
ROC train: 1.000000	val: 0.901736	test: 0.712191
PRC train: 1.000000	val: 0.828546	test: 0.743872

Epoch: 97
Loss: 0.036698625741151326
ROC train: 0.999790	val: 0.886982	test: 0.707851
PRC train: 0.999959	val: 0.785571	test: 0.755561

Epoch: 98
Loss: 0.033135238885121834
ROC train: 0.999983	val: 0.888989	test: 0.701389
PRC train: 0.999997	val: 0.796187	test: 0.740961

Epoch: 99
Loss: 0.03607999934645012
ROC train: 0.999997	val: 0.902740	test: 0.682388
PRC train: 0.999999	val: 0.824427	test: 0.710814

Epoch: 100
Loss: 0.036591302852430306
ROC train: 1.000000	val: 0.906554	test: 0.686150
PRC train: 1.000000	val: 0.830356	test: 0.716798

Epoch: 101
Loss: 0.033782181130522136
ROC train: 1.000000	val: 0.881562	test: 0.686535
PRC train: 1.000000	val: 0.784171	test: 0.729057

Epoch: 102
Loss: 0.028286903026912842
ROC train: 0.999296	val: 0.865201	test: 0.672357
PRC train: 0.999862	val: 0.746943	test: 0.711234

Epoch: 103
Loss: 0.03222802064246867
ROC train: 1.000000	val: 0.893907	test: 0.695120
PRC train: 1.000000	val: 0.802791	test: 0.710850

Epoch: 104
Loss: 0.03891938604597643
ROC train: 1.000000	val: 0.889290	test: 0.687307
PRC train: 1.000000	val: 0.803087	test: 0.708911

Epoch: 105
Loss: 0.026241154250955016
ROC train: 0.999994	val: 0.879956	test: 0.687500
PRC train: 0.999999	val: 0.800728	test: 0.710506

Epoch: 106
Loss: 0.03036483122901998
ROC train: 1.000000	val: 0.884874	test: 0.690008
PRC train: 1.000000	val: 0.796446	test: 0.714896

Epoch: 107
Loss: 0.026817085492673972
ROC train: 1.000000	val: 0.899328	test: 0.702932
PRC train: 1.000000	val: 0.817605	test: 0.727811

Epoch: 108
Loss: 0.022801242074032002
ROC train: 1.000000	val: 0.901134	test: 0.695988
PRC train: 1.000000	val: 0.831374	test: 0.725742

Epoch: 109
Loss: 0.01990030743400391
ROC train: 1.000000	val: 0.898023	test: 0.684414
PRC train: 1.000000	val: 0.825607	test: 0.714642

Epoch: 110
Loss: 0.02686499935111431
ROC train: 1.000000	val: 0.897019	test: 0.679977
PRC train: 1.000000	val: 0.821978	test: 0.708775

Epoch: 111
Loss: 0.018250315465977163
ROC train: 1.000000	val: 0.892302	test: 0.675637
PRC train: 1.000000	val: 0.815970	test: 0.703404

Epoch: 112
Loss: 0.01639263674477191
ROC train: 0.999992	val: 0.885577	test: 0.660976
PRC train: 0.999998	val: 0.795412	test: 0.692190

Epoch: 113
Loss: 0.03979146078850113
ROC train: 1.000000	val: 0.883368	test: 0.677566
PRC train: 1.000000	val: 0.800027	test: 0.708129

Epoch: 114
Loss: 0.03696723551228869
ROC train: 0.999952	val: 0.891097	test: 0.684510
PRC train: 0.999991	val: 0.810801	test: 0.706820

Epoch: 115
Loss: 0.023543377044262147
ROC train: 1.000000	val: 0.892502	test: 0.674961
PRC train: 1.000000	val: 0.809096	test: 0.694633

Epoch: 116
Loss: 0.02529352261462253
ROC train: 1.000000	val: 0.884874	test: 0.656732
PRC train: 1.000000	val: 0.792722	test: 0.669213

Epoch: 117
Loss: 0.031463011355501246
ROC train: 0.999947	val: 0.875439	test: 0.648727
PRC train: 0.999990	val: 0.775872	test: 0.655544

Epoch: 118
Loss: 0.02822643050948154
ROC train: 1.000000	val: 0.881361	test: 0.666088
PRC train: 1.000000	val: 0.799123	test: 0.676840

Epoch: 119
Loss: 0.020084252877267585
ROC train: 1.000000	val: 0.888989	test: 0.689429
PRC train: 1.000000	val: 0.805039	test: 0.713280

Epoch: 120
Loss: 0.017633111026146845
ROC train: 1.000000	val: 0.893707	test: 0.669753
PRC train: 1.000000	val: 0.807349	test: 0.680760

Early stopping
Best (ROC):	 train: 0.996325	val: 0.928937	test: 0.700521
Best (PRC):	 train: 0.999230	val: 0.878896	test: 0.747665

PRC train: 1.000000	val: 0.767153	test: 0.742810

Epoch: 94
Loss: 0.017771373727093472
ROC train: 1.000000	val: 0.877547	test: 0.684606
PRC train: 1.000000	val: 0.771451	test: 0.750096

Epoch: 95
Loss: 0.02865569540173899
ROC train: 1.000000	val: 0.877948	test: 0.675058
PRC train: 1.000000	val: 0.765148	test: 0.729209

Epoch: 96
Loss: 0.02979934396916147
ROC train: 1.000000	val: 0.878952	test: 0.676698
PRC train: 1.000000	val: 0.747335	test: 0.723215

Epoch: 97
Loss: 0.035768886314308544
ROC train: 1.000000	val: 0.882565	test: 0.692805
PRC train: 1.000000	val: 0.757533	test: 0.748562

Epoch: 98
Loss: 0.02945599560512169
ROC train: 0.999997	val: 0.877447	test: 0.666184
PRC train: 0.999999	val: 0.763934	test: 0.722527

Epoch: 99
Loss: 0.025866251643122083
ROC train: 1.000000	val: 0.876543	test: 0.674865
PRC train: 1.000000	val: 0.771850	test: 0.733687

Epoch: 100
Loss: 0.023026055697831515
ROC train: 1.000000	val: 0.871826	test: 0.651427
PRC train: 1.000000	val: 0.753810	test: 0.693909

Epoch: 101
Loss: 0.02378817069071511
ROC train: 0.999989	val: 0.876443	test: 0.657986
PRC train: 0.999998	val: 0.750405	test: 0.704932

Epoch: 102
Loss: 0.019382993273494156
ROC train: 1.000000	val: 0.882465	test: 0.672840
PRC train: 1.000000	val: 0.761600	test: 0.726421

Epoch: 103
Loss: 0.022063506763304933
ROC train: 1.000000	val: 0.871826	test: 0.676698
PRC train: 1.000000	val: 0.763143	test: 0.729981

Epoch: 104
Loss: 0.027891596333229705
ROC train: 1.000000	val: 0.865502	test: 0.656732
PRC train: 1.000000	val: 0.757904	test: 0.707088

Epoch: 105
Loss: 0.02097151557656616
ROC train: 0.999983	val: 0.868212	test: 0.659819
PRC train: 0.999997	val: 0.745994	test: 0.702081

Epoch: 106
Loss: 0.01678909859849323
ROC train: 1.000000	val: 0.882365	test: 0.668306
PRC train: 1.000000	val: 0.766705	test: 0.725593

Epoch: 107
Loss: 0.03546912822262892
ROC train: 1.000000	val: 0.877848	test: 0.668981
PRC train: 1.000000	val: 0.758066	test: 0.737725

Epoch: 108
Loss: 0.019097703949113302
ROC train: 1.000000	val: 0.870621	test: 0.665316
PRC train: 1.000000	val: 0.750019	test: 0.725890

Epoch: 109
Loss: 0.02215983180752032
ROC train: 0.999980	val: 0.867911	test: 0.666570
PRC train: 0.999996	val: 0.746635	test: 0.732306

Epoch: 110
Loss: 0.019410187945294567
ROC train: 1.000000	val: 0.878551	test: 0.667728
PRC train: 1.000000	val: 0.753017	test: 0.739158

Epoch: 111
Loss: 0.019663502403008664
ROC train: 1.000000	val: 0.885577	test: 0.671296
PRC train: 1.000000	val: 0.769421	test: 0.743765

Epoch: 112
Loss: 0.027191609572580794
ROC train: 1.000000	val: 0.879755	test: 0.664062
PRC train: 1.000000	val: 0.763916	test: 0.730559

Epoch: 113
Loss: 0.026071488581674712
ROC train: 0.999961	val: 0.874435	test: 0.663773
PRC train: 0.999993	val: 0.753841	test: 0.726747

Epoch: 114
Loss: 0.01859447904936739
ROC train: 0.999997	val: 0.862391	test: 0.650463
PRC train: 0.999999	val: 0.730241	test: 0.701695

Epoch: 115
Loss: 0.025962767438248217
ROC train: 1.000000	val: 0.877547	test: 0.654610
PRC train: 1.000000	val: 0.756434	test: 0.707950

Epoch: 116
Loss: 0.019775707930558797
ROC train: 0.999997	val: 0.881763	test: 0.647280
PRC train: 0.999999	val: 0.779414	test: 0.688350

Epoch: 117
Loss: 0.017487114619013873
ROC train: 0.999997	val: 0.873632	test: 0.638503
PRC train: 0.999999	val: 0.776443	test: 0.687158

Epoch: 118
Loss: 0.019554112067029533
ROC train: 0.999986	val: 0.873030	test: 0.651813
PRC train: 0.999997	val: 0.781897	test: 0.685607

Epoch: 119
Loss: 0.022058198496781305
ROC train: 1.000000	val: 0.878651	test: 0.683063
PRC train: 1.000000	val: 0.761770	test: 0.742086

Epoch: 120
Loss: 0.02220524559854597
ROC train: 1.000000	val: 0.870119	test: 0.687886
PRC train: 1.000000	val: 0.751346	test: 0.753661

Early stopping
Best (ROC):	 train: 0.893466	val: 0.921108	test: 0.665413
Best (PRC):	 train: 0.973873	val: 0.829962	test: 0.687897

ROC train: 1.000000	val: 0.856770	test: 0.534722
PRC train: 1.000000	val: 0.782165	test: 0.574623

Epoch: 94
Loss: 0.017987820978060787
ROC train: 1.000000	val: 0.878551	test: 0.556520
PRC train: 1.000000	val: 0.802373	test: 0.584536

Epoch: 95
Loss: 0.020160645063755863
ROC train: 0.999992	val: 0.871123	test: 0.542052
PRC train: 0.999998	val: 0.802682	test: 0.574593

Epoch: 96
Loss: 0.02419000416887579
ROC train: 1.000000	val: 0.878250	test: 0.535397
PRC train: 1.000000	val: 0.812059	test: 0.587042

Epoch: 97
Loss: 0.024636044245157862
ROC train: 1.000000	val: 0.882064	test: 0.542824
PRC train: 1.000000	val: 0.823166	test: 0.588526

Epoch: 98
Loss: 0.024463546816622123
ROC train: 0.999992	val: 0.872428	test: 0.527392
PRC train: 0.999998	val: 0.817229	test: 0.580036

Epoch: 99
Loss: 0.01602191633514852
ROC train: 1.000000	val: 0.877447	test: 0.537326
PRC train: 1.000000	val: 0.818111	test: 0.584380

Epoch: 100
Loss: 0.02098411551307202
ROC train: 1.000000	val: 0.872328	test: 0.534626
PRC train: 1.000000	val: 0.821457	test: 0.588644

Epoch: 101
Loss: 0.023309077862251233
ROC train: 1.000000	val: 0.868012	test: 0.513696
PRC train: 1.000000	val: 0.812053	test: 0.571737

Epoch: 102
Loss: 0.021847222380332272
ROC train: 1.000000	val: 0.886380	test: 0.524306
PRC train: 1.000000	val: 0.826373	test: 0.567593

Epoch: 103
Loss: 0.016940938039635596
ROC train: 1.000000	val: 0.889290	test: 0.537616
PRC train: 1.000000	val: 0.834195	test: 0.571152

Epoch: 104
Loss: 0.016721242939251604
ROC train: 1.000000	val: 0.875841	test: 0.523245
PRC train: 1.000000	val: 0.815227	test: 0.576345

Epoch: 105
Loss: 0.014157590055623285
ROC train: 1.000000	val: 0.870320	test: 0.518615
PRC train: 1.000000	val: 0.812359	test: 0.561904

Epoch: 106
Loss: 0.014730892204493666
ROC train: 1.000000	val: 0.865803	test: 0.535590
PRC train: 1.000000	val: 0.803877	test: 0.574898

Epoch: 107
Loss: 0.029265214674259386
ROC train: 1.000000	val: 0.862190	test: 0.541184
PRC train: 1.000000	val: 0.804113	test: 0.590660

Epoch: 108
Loss: 0.017102823711635243
ROC train: 1.000000	val: 0.870119	test: 0.553916
PRC train: 1.000000	val: 0.804903	test: 0.616694

Epoch: 109
Loss: 0.01781730284330605
ROC train: 1.000000	val: 0.881160	test: 0.568962
PRC train: 1.000000	val: 0.801737	test: 0.625326

Epoch: 110
Loss: 0.022927274788052596
ROC train: 1.000000	val: 0.867610	test: 0.551601
PRC train: 1.000000	val: 0.783865	test: 0.616769

Epoch: 111
Loss: 0.015070181208033148
ROC train: 1.000000	val: 0.857874	test: 0.530093
PRC train: 1.000000	val: 0.780232	test: 0.588606

Epoch: 112
Loss: 0.017206163897706354
ROC train: 1.000000	val: 0.873833	test: 0.543017
PRC train: 1.000000	val: 0.793460	test: 0.579763

Epoch: 113
Loss: 0.018605608242583015
ROC train: 1.000000	val: 0.873833	test: 0.543789
PRC train: 1.000000	val: 0.790866	test: 0.588675

Epoch: 114
Loss: 0.02133839778537931
ROC train: 1.000000	val: 0.877447	test: 0.537326
PRC train: 1.000000	val: 0.784937	test: 0.590619

Epoch: 115
Loss: 0.02060819007391291
ROC train: 1.000000	val: 0.870822	test: 0.530093
PRC train: 1.000000	val: 0.781229	test: 0.601761

Epoch: 116
Loss: 0.019127210292902132
ROC train: 1.000000	val: 0.869919	test: 0.537905
PRC train: 1.000000	val: 0.782069	test: 0.602184

Epoch: 117
Loss: 0.02367516311473541
ROC train: 1.000000	val: 0.870019	test: 0.563272
PRC train: 1.000000	val: 0.780500	test: 0.620324

Epoch: 118
Loss: 0.015830391013137008
ROC train: 1.000000	val: 0.872428	test: 0.563947
PRC train: 1.000000	val: 0.776580	test: 0.619546

Epoch: 119
Loss: 0.02389169428143911
ROC train: 1.000000	val: 0.865101	test: 0.545235
PRC train: 1.000000	val: 0.781885	test: 0.597934

Epoch: 120
Loss: 0.020048671951453257
ROC train: 1.000000	val: 0.864499	test: 0.536458
PRC train: 1.000000	val: 0.786814	test: 0.593827

Early stopping
Best (ROC):	 train: 0.869183	val: 0.908562	test: 0.597897
Best (PRC):	 train: 0.965731	val: 0.877871	test: 0.634085

ROC train: 1.000000	val: 0.835993	test: 0.670139
PRC train: 1.000000	val: 0.765524	test: 0.669729

Epoch: 94
Loss: 0.025430165847782793
ROC train: 1.000000	val: 0.850647	test: 0.655671
PRC train: 1.000000	val: 0.794644	test: 0.654344

Epoch: 95
Loss: 0.01798301829702815
ROC train: 1.000000	val: 0.844023	test: 0.651910
PRC train: 1.000000	val: 0.777928	test: 0.647100

Epoch: 96
Loss: 0.024632752599394576
ROC train: 1.000000	val: 0.851149	test: 0.682195
PRC train: 1.000000	val: 0.774546	test: 0.683418

Epoch: 97
Loss: 0.029348445038475186
ROC train: 1.000000	val: 0.842517	test: 0.683931
PRC train: 1.000000	val: 0.776053	test: 0.694260

Epoch: 98
Loss: 0.021149304474846427
ROC train: 1.000000	val: 0.861186	test: 0.685860
PRC train: 1.000000	val: 0.802968	test: 0.704949

Epoch: 99
Loss: 0.019283673584052412
ROC train: 1.000000	val: 0.886380	test: 0.676698
PRC train: 1.000000	val: 0.826784	test: 0.716250

Epoch: 100
Loss: 0.028589800251925295
ROC train: 1.000000	val: 0.895012	test: 0.659433
PRC train: 1.000000	val: 0.837219	test: 0.684787

Epoch: 101
Loss: 0.020198677081542316
ROC train: 1.000000	val: 0.883168	test: 0.647473
PRC train: 1.000000	val: 0.829114	test: 0.671158

Epoch: 102
Loss: 0.017421122888957898
ROC train: 1.000000	val: 0.881060	test: 0.651524
PRC train: 1.000000	val: 0.816640	test: 0.683264

Epoch: 103
Loss: 0.016333280651432247
ROC train: 1.000000	val: 0.869718	test: 0.647377
PRC train: 1.000000	val: 0.808601	test: 0.679468

Epoch: 104
Loss: 0.02658010272510611
ROC train: 1.000000	val: 0.862290	test: 0.661651
PRC train: 1.000000	val: 0.790162	test: 0.685156

Epoch: 105
Loss: 0.021741498538647097
ROC train: 1.000000	val: 0.867008	test: 0.662230
PRC train: 1.000000	val: 0.798177	test: 0.691625

Epoch: 106
Loss: 0.018596184459582166
ROC train: 1.000000	val: 0.863194	test: 0.668499
PRC train: 1.000000	val: 0.790781	test: 0.700929

Epoch: 107
Loss: 0.012280917723106275
ROC train: 1.000000	val: 0.834186	test: 0.665799
PRC train: 1.000000	val: 0.762563	test: 0.704423

Epoch: 108
Loss: 0.021178325927914528
ROC train: 1.000000	val: 0.832279	test: 0.642747
PRC train: 1.000000	val: 0.778794	test: 0.691129

Epoch: 109
Loss: 0.014201916046365294
ROC train: 1.000000	val: 0.852354	test: 0.655285
PRC train: 1.000000	val: 0.785971	test: 0.699388

Epoch: 110
Loss: 0.016472995315859478
ROC train: 1.000000	val: 0.840309	test: 0.656829
PRC train: 1.000000	val: 0.757046	test: 0.685528

Epoch: 111
Loss: 0.021614064393555725
ROC train: 1.000000	val: 0.858276	test: 0.659144
PRC train: 1.000000	val: 0.787223	test: 0.695082

Epoch: 112
Loss: 0.019437931137264167
ROC train: 1.000000	val: 0.858376	test: 0.667535
PRC train: 1.000000	val: 0.792471	test: 0.714391

Epoch: 113
Loss: 0.026771833971450797
ROC train: 1.000000	val: 0.865201	test: 0.630691
PRC train: 1.000000	val: 0.820277	test: 0.630475

Epoch: 114
Loss: 0.025145164784607883
ROC train: 1.000000	val: 0.886982	test: 0.619020
PRC train: 1.000000	val: 0.825517	test: 0.610294

Epoch: 115
Loss: 0.02883454139290272
ROC train: 1.000000	val: 0.888287	test: 0.628954
PRC train: 1.000000	val: 0.809697	test: 0.639987

Epoch: 116
Loss: 0.03205464307745096
ROC train: 1.000000	val: 0.803874	test: 0.649306
PRC train: 1.000000	val: 0.690373	test: 0.679049

Epoch: 117
Loss: 0.02389122655230278
ROC train: 0.999975	val: 0.812205	test: 0.647184
PRC train: 0.999995	val: 0.703734	test: 0.681473

Epoch: 118
Loss: 0.03499532028161117
ROC train: 1.000000	val: 0.838603	test: 0.655478
PRC train: 1.000000	val: 0.731815	test: 0.695006

Epoch: 119
Loss: 0.016337631766712404
ROC train: 1.000000	val: 0.824049	test: 0.643808
PRC train: 1.000000	val: 0.709323	test: 0.666700

Epoch: 120
Loss: 0.04650414054146689
ROC train: 1.000000	val: 0.835291	test: 0.665606
PRC train: 1.000000	val: 0.728845	test: 0.690892

Early stopping
Best (ROC):	 train: 0.996807	val: 0.897220	test: 0.635320
Best (PRC):	 train: 0.999363	val: 0.843893	test: 0.657467

PRC train: 1.000000	val: 0.828122	test: 0.680832

Epoch: 94
Loss: 0.03161395893402851
ROC train: 1.000000	val: 0.882565	test: 0.630883
PRC train: 1.000000	val: 0.818633	test: 0.683009

Epoch: 95
Loss: 0.024987390658629875
ROC train: 1.000000	val: 0.879956	test: 0.613522
PRC train: 1.000000	val: 0.808814	test: 0.664450

Epoch: 96
Loss: 0.025061924282679345
ROC train: 1.000000	val: 0.870320	test: 0.610725
PRC train: 1.000000	val: 0.805515	test: 0.655715

Epoch: 97
Loss: 0.0323334493008639
ROC train: 1.000000	val: 0.845127	test: 0.608266
PRC train: 1.000000	val: 0.774819	test: 0.660598

Epoch: 98
Loss: 0.026579864464688373
ROC train: 1.000000	val: 0.844324	test: 0.603009
PRC train: 1.000000	val: 0.766978	test: 0.652218

Epoch: 99
Loss: 0.031196280586854048
ROC train: 1.000000	val: 0.860885	test: 0.628376
PRC train: 1.000000	val: 0.774809	test: 0.669267

Epoch: 100
Loss: 0.033315612647736005
ROC train: 1.000000	val: 0.880056	test: 0.632716
PRC train: 1.000000	val: 0.799801	test: 0.673616

Epoch: 101
Loss: 0.02671852462017867
ROC train: 1.000000	val: 0.875038	test: 0.615837
PRC train: 1.000000	val: 0.803443	test: 0.669549

Epoch: 102
Loss: 0.03625618250794232
ROC train: 1.000000	val: 0.879354	test: 0.620370
PRC train: 1.000000	val: 0.824468	test: 0.687396

Epoch: 103
Loss: 0.026335237049973197
ROC train: 1.000000	val: 0.875138	test: 0.625579
PRC train: 1.000000	val: 0.822989	test: 0.695431

Epoch: 104
Loss: 0.01833668421229458
ROC train: 1.000000	val: 0.873030	test: 0.610243
PRC train: 1.000000	val: 0.821934	test: 0.669279

Epoch: 105
Loss: 0.020343252451468112
ROC train: 1.000000	val: 0.878049	test: 0.613233
PRC train: 1.000000	val: 0.824431	test: 0.659459

Epoch: 106
Loss: 0.015924459928025235
ROC train: 1.000000	val: 0.874335	test: 0.612558
PRC train: 1.000000	val: 0.805506	test: 0.670031

Epoch: 107
Loss: 0.03172324396888127
ROC train: 1.000000	val: 0.873331	test: 0.634934
PRC train: 1.000000	val: 0.807474	test: 0.702432

Epoch: 108
Loss: 0.016714526354212663
ROC train: 1.000000	val: 0.870421	test: 0.634066
PRC train: 1.000000	val: 0.804489	test: 0.704916

Epoch: 109
Loss: 0.024121105583782616
ROC train: 1.000000	val: 0.885878	test: 0.631366
PRC train: 1.000000	val: 0.821965	test: 0.691696

Epoch: 110
Loss: 0.025746396829557466
ROC train: 1.000000	val: 0.877848	test: 0.631366
PRC train: 1.000000	val: 0.824600	test: 0.687052

Epoch: 111
Loss: 0.023803502406603567
ROC train: 0.999994	val: 0.872127	test: 0.625772
PRC train: 0.999999	val: 0.807612	test: 0.675895

Epoch: 112
Loss: 0.02184063527183531
ROC train: 1.000000	val: 0.882565	test: 0.644387
PRC train: 1.000000	val: 0.811999	test: 0.701539

Epoch: 113
Loss: 0.020579494739698268
ROC train: 1.000000	val: 0.877547	test: 0.650945
PRC train: 1.000000	val: 0.804145	test: 0.706750

Epoch: 114
Loss: 0.020758433599049962
ROC train: 1.000000	val: 0.879354	test: 0.646508
PRC train: 1.000000	val: 0.810319	test: 0.705317

Epoch: 115
Loss: 0.019539351019626762
ROC train: 1.000000	val: 0.872930	test: 0.631366
PRC train: 1.000000	val: 0.810561	test: 0.709675

Epoch: 116
Loss: 0.02536030273306872
ROC train: 1.000000	val: 0.883168	test: 0.646701
PRC train: 1.000000	val: 0.827560	test: 0.719088

Epoch: 117
Loss: 0.012505100335442549
ROC train: 1.000000	val: 0.888989	test: 0.650559
PRC train: 1.000000	val: 0.833847	test: 0.717861

Epoch: 118
Loss: 0.027604380062637802
ROC train: 1.000000	val: 0.894811	test: 0.651813
PRC train: 1.000000	val: 0.836354	test: 0.714256

Epoch: 119
Loss: 0.02031564627510196
ROC train: 1.000000	val: 0.888688	test: 0.660590
PRC train: 1.000000	val: 0.822120	test: 0.724240

Epoch: 120
Loss: 0.017046811139362125
ROC train: 1.000000	val: 0.893305	test: 0.654996
PRC train: 1.000000	val: 0.830516	test: 0.713210

Early stopping
Best (ROC):	 train: 0.999296	val: 0.898926	test: 0.633005
Best (PRC):	 train: 0.999867	val: 0.850137	test: 0.647701
All runs completed.
All runs completed.

PRC train: 1.000000	val: 0.821276	test: 0.644532

Epoch: 94
Loss: 0.04539666626700735
ROC train: 1.000000	val: 0.908762	test: 0.607735
PRC train: 1.000000	val: 0.817526	test: 0.649635

Epoch: 95
Loss: 0.030372723214755374
ROC train: 1.000000	val: 0.911372	test: 0.621528
PRC train: 1.000000	val: 0.845067	test: 0.660401

Epoch: 96
Loss: 0.04358506913754552
ROC train: 1.000000	val: 0.917294	test: 0.639757
PRC train: 1.000000	val: 0.850976	test: 0.673508

Epoch: 97
Loss: 0.032941489652215064
ROC train: 1.000000	val: 0.909766	test: 0.627218
PRC train: 1.000000	val: 0.837712	test: 0.680929

Epoch: 98
Loss: 0.02041787194253699
ROC train: 1.000000	val: 0.903844	test: 0.630498
PRC train: 1.000000	val: 0.818745	test: 0.682362

Epoch: 99
Loss: 0.030922344046900536
ROC train: 1.000000	val: 0.908361	test: 0.623843
PRC train: 1.000000	val: 0.818203	test: 0.677077

Epoch: 100
Loss: 0.04954771191051737
ROC train: 1.000000	val: 0.905651	test: 0.626350
PRC train: 1.000000	val: 0.812313	test: 0.664428

Epoch: 101
Loss: 0.03791798680169872
ROC train: 0.999997	val: 0.886580	test: 0.627122
PRC train: 0.999999	val: 0.783459	test: 0.659158

Epoch: 102
Loss: 0.03872160659473585
ROC train: 0.999972	val: 0.896919	test: 0.620563
PRC train: 0.999995	val: 0.798605	test: 0.673664

Epoch: 103
Loss: 0.03977464669928852
ROC train: 1.000000	val: 0.900130	test: 0.642265
PRC train: 1.000000	val: 0.796683	test: 0.683105

Epoch: 104
Loss: 0.0369071372971829
ROC train: 1.000000	val: 0.897220	test: 0.660012
PRC train: 1.000000	val: 0.779048	test: 0.694069

Epoch: 105
Loss: 0.040725173669402155
ROC train: 1.000000	val: 0.891900	test: 0.639757
PRC train: 1.000000	val: 0.784495	test: 0.686077

Epoch: 106
Loss: 0.042925962569562014
ROC train: 1.000000	val: 0.897922	test: 0.634356
PRC train: 1.000000	val: 0.805670	test: 0.700371

Epoch: 107
Loss: 0.02780492014094955
ROC train: 1.000000	val: 0.902038	test: 0.645930
PRC train: 1.000000	val: 0.809723	test: 0.698932

Epoch: 108
Loss: 0.03591334245270388
ROC train: 1.000000	val: 0.894610	test: 0.639371
PRC train: 1.000000	val: 0.773172	test: 0.668141

Epoch: 109
Loss: 0.0330285679784792
ROC train: 1.000000	val: 0.880257	test: 0.660976
PRC train: 1.000000	val: 0.738892	test: 0.685124

Epoch: 110
Loss: 0.041301570481385955
ROC train: 1.000000	val: 0.892904	test: 0.661362
PRC train: 1.000000	val: 0.763283	test: 0.701850

Epoch: 111
Loss: 0.039215830436155626
ROC train: 1.000000	val: 0.899428	test: 0.603588
PRC train: 1.000000	val: 0.777814	test: 0.662607

Epoch: 112
Loss: 0.02628363749804586
ROC train: 1.000000	val: 0.907759	test: 0.607350
PRC train: 1.000000	val: 0.818431	test: 0.674693

Epoch: 113
Loss: 0.028292186123765273
ROC train: 1.000000	val: 0.896617	test: 0.627122
PRC train: 1.000000	val: 0.824689	test: 0.675531

Epoch: 114
Loss: 0.029416187119222486
ROC train: 1.000000	val: 0.903844	test: 0.615837
PRC train: 1.000000	val: 0.807160	test: 0.650345

Epoch: 115
Loss: 0.024537304802937896
ROC train: 1.000000	val: 0.903443	test: 0.616223
PRC train: 1.000000	val: 0.815365	test: 0.664367

Epoch: 116
Loss: 0.03600899912158082
ROC train: 1.000000	val: 0.906253	test: 0.652199
PRC train: 1.000000	val: 0.845262	test: 0.710770

Epoch: 117
Loss: 0.025642541884831494
ROC train: 1.000000	val: 0.901636	test: 0.647280
PRC train: 1.000000	val: 0.855468	test: 0.697617

Epoch: 118
Loss: 0.03351446241654946
ROC train: 1.000000	val: 0.906253	test: 0.636092
PRC train: 1.000000	val: 0.851571	test: 0.669877

Epoch: 119
Loss: 0.029694394784976087
ROC train: 0.999989	val: 0.918900	test: 0.616416
PRC train: 0.999998	val: 0.860818	test: 0.651232

Epoch: 120
Loss: 0.02485248393683185
ROC train: 0.998620	val: 0.919101	test: 0.623939
PRC train: 0.999697	val: 0.855405	test: 0.665731

Epoch: 121
Loss: 0.0260704207013845
ROC train: 1.000000	val: 0.923216	test: 0.660012
PRC train: 1.000000	val: 0.846382	test: 0.696262

Epoch: 122
Loss: 0.02258907824879606
ROC train: 1.000000	val: 0.913380	test: 0.651620
PRC train: 1.000000	val: 0.824262	test: 0.675806

Epoch: 123
Loss: 0.020501613884318794
ROC train: 1.000000	val: 0.899629	test: 0.656925
PRC train: 1.000000	val: 0.819768	test: 0.690371

Epoch: 124
Loss: 0.020495332789840164
ROC train: 1.000000	val: 0.915588	test: 0.645930
PRC train: 1.000000	val: 0.841246	test: 0.687564

Epoch: 125
Loss: 0.013209441734775179
ROC train: 1.000000	val: 0.925926	test: 0.621142
PRC train: 1.000000	val: 0.865844	test: 0.656902

Epoch: 126
Loss: 0.01521734555829986
ROC train: 0.999994	val: 0.919000	test: 0.607735
PRC train: 0.999999	val: 0.840101	test: 0.641707

Epoch: 127
Loss: 0.025973580129612865
ROC train: 1.000000	val: 0.913380	test: 0.641590
PRC train: 1.000000	val: 0.831926	test: 0.681416

Epoch: 128
Loss: 0.017955545223283343
ROC train: 1.000000	val: 0.904948	test: 0.684703
PRC train: 1.000000	val: 0.827297	test: 0.714448

Epoch: 129
Loss: 0.021081599842835596
ROC train: 1.000000	val: 0.887684	test: 0.631366
PRC train: 1.000000	val: 0.767056	test: 0.674294

Epoch: 130
Loss: 0.010898971933869132
ROC train: 1.000000	val: 0.885677	test: 0.608121
PRC train: 1.000000	val: 0.769017	test: 0.656265

Epoch: 131
Loss: 0.016931433029323
ROC train: 1.000000	val: 0.907959	test: 0.632620
PRC train: 1.000000	val: 0.814134	test: 0.679472

Epoch: 132
Loss: 0.015060949526942107
ROC train: 1.000000	val: 0.910971	test: 0.641397
PRC train: 1.000000	val: 0.823101	test: 0.689375

Epoch: 133
Loss: 0.010082275486647804
ROC train: 1.000000	val: 0.902941	test: 0.619117
PRC train: 1.000000	val: 0.805454	test: 0.670009

Epoch: 134
Loss: 0.018166228008904335
ROC train: 1.000000	val: 0.899528	test: 0.630883
PRC train: 1.000000	val: 0.780094	test: 0.677583

Epoch: 135
Loss: 0.02070129661762075
ROC train: 0.999997	val: 0.899026	test: 0.640046
PRC train: 0.999999	val: 0.799336	test: 0.702979

Epoch: 136
Loss: 0.02400523067854582
ROC train: 1.000000	val: 0.915989	test: 0.651138
PRC train: 1.000000	val: 0.840709	test: 0.709031

Epoch: 137
Loss: 0.020527080289902883
ROC train: 1.000000	val: 0.915287	test: 0.642650
PRC train: 1.000000	val: 0.836857	test: 0.688509

Epoch: 138
Loss: 0.01387389393660111
ROC train: 1.000000	val: 0.911272	test: 0.611497
PRC train: 1.000000	val: 0.824332	test: 0.666284

Epoch: 139
Loss: 0.016973384447500607
ROC train: 1.000000	val: 0.906554	test: 0.598283
PRC train: 1.000000	val: 0.809669	test: 0.659639

Epoch: 140
Loss: 0.020868702340230194
ROC train: 1.000000	val: 0.904647	test: 0.591242
PRC train: 1.000000	val: 0.814275	test: 0.649243

Epoch: 141
Loss: 0.014164392724511329
ROC train: 1.000000	val: 0.906554	test: 0.598573
PRC train: 1.000000	val: 0.823428	test: 0.650996

Epoch: 142
Loss: 0.016570945023315502
ROC train: 1.000000	val: 0.900130	test: 0.622299
PRC train: 1.000000	val: 0.814916	test: 0.666384

Epoch: 143
Loss: 0.02154994312587426
ROC train: 1.000000	val: 0.899930	test: 0.641879
PRC train: 1.000000	val: 0.814133	test: 0.685296

Epoch: 144
Loss: 0.021696657436152973
ROC train: 1.000000	val: 0.913480	test: 0.656250
PRC train: 1.000000	val: 0.833096	test: 0.705008

Epoch: 145
Loss: 0.014267078440655416
ROC train: 1.000000	val: 0.914383	test: 0.646991
PRC train: 1.000000	val: 0.832020	test: 0.690252

Epoch: 146
Loss: 0.01851387338935031
ROC train: 1.000000	val: 0.909666	test: 0.617670
PRC train: 1.000000	val: 0.810688	test: 0.673291

Epoch: 147
Loss: 0.02096268859420062
ROC train: 1.000000	val: 0.894510	test: 0.595775
PRC train: 1.000000	val: 0.798805	test: 0.664245

Epoch: 148
Loss: 0.01617766395225282
ROC train: 1.000000	val: 0.910368	test: 0.615548
PRC train: 1.000000	val: 0.819819	test: 0.673959

Epoch: 149
Loss: 0.0187280683069195
ROC train: 1.000000	val: 0.921008	test: 0.621335
PRC train: 1.000000	val: 0.855839	test: 0.670848

Epoch: 150
Loss: 0.030228414827393992
ROC train: 1.000000	val: 0.913580	test: 0.621431
PRC train: 1.000000	val: 0.843023	test: 0.674812

Epoch: 151
Loss: 0.021857368077533062
ROC train: 1.000000	val: 0.905350	test: 0.617766
PRC train: 1.000000	val: 0.824221	test: 0.675534

Epoch: 152
Loss: 0.02585836218500903
ROC train: 1.000000	val: 0.888688	test: 0.612751
PRC train: 1.000000	val: 0.809513	test: 0.669763

Epoch: 153
Loss: 0.014313369472232444
ROC train: 1.000000	val: 0.901536	test: 0.609761
PRC train: 1.000000	val: 0.826503	test: 0.663163

Epoch: 154
Loss: 0.0221724517514512
ROC train: 1.000000	val: 0.903543	test: 0.621142
PRC train: 1.000000	val: 0.828872	test: 0.675622

Epoch: 155
Loss: 0.02338669350934854
ROC train: 1.000000	val: 0.897220	test: 0.645158
PRC train: 1.000000	val: 0.814169	test: 0.704524

Epoch: 156
Loss: 0.017189843242201592
ROC train: 1.000000	val: 0.896316	test: 0.645351
PRC train: 1.000000	val: 0.805246	test: 0.698992

Epoch: 157
Loss: 0.01723291013397532
ROC train: 1.000000	val: 0.898525	test: 0.642168
PRC train: 1.000000	val: 0.795633	test: 0.690122

Epoch: 158
Loss: 0.016476220567562486
ROC train: 1.000000	val: 0.906554	test: 0.638985
PRC train: 1.000000	val: 0.797450	test: 0.683685

Epoch: 159
Loss: 0.01405175481356394
ROC train: 1.000000	val: 0.915387	test: 0.641975
PRC train: 1.000000	val: 0.825893	test: 0.689568

Epoch: 160
Loss: 0.013532864142179357
ROC train: 1.000000	val: 0.914182	test: 0.647280
PRC train: 1.000000	val: 0.824167	test: 0.690214

Early stopping
Best (ROC):	 train: 1.000000	val: 0.925926	test: 0.621142
Best (PRC):	 train: 1.000000	val: 0.865844	test: 0.656902
All runs completed.
