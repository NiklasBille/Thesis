>>> Starting run for dataset: clintox
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running RANDOM configs_split_experiments/GraphMVP/clintox/random/train_prop=0.6.yml on cuda:0
Running RANDOM configs_split_experiments/GraphMVP/clintox/random/train_prop=0.7.yml on cuda:1
Running RANDOM configs_split_experiments/GraphMVP/clintox/random/train_prop=0.8.yml on cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/clintox/random/train_prop=0.7.yml --runseed 4 --device cuda:1
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/clintox/random/train_prop=0.7.yml --runseed 5 --device cuda:1
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/clintox/random/train_prop=0.6.yml --runseed 4 --device cuda:0
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/clintox/random/train_prop=0.7.yml --runseed 6 --device cuda:1
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/clintox/random/train_prop=0.6.yml --runseed 5 --device cuda:0
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/clintox/random/train_prop=0.6.yml --runseed 6 --device cuda:0
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/clintox/random/train_prop=0.8.yml --runseed 4 --device cuda:2
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/clintox/random/train_prop=0.8.yml --runseed 5 --device cuda:2
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/clintox/random/train_prop=0.8.yml --runseed 6 --device cuda:2
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/clintox/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/clintox/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/clintox/random/train_prop=0.6/clintox_random_6_26-05_11-06-56  ]
[ Using Seed :  6  ]
[ Using device :  cuda:0  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
randomly split
Data(edge_attr=[48, 2], edge_index=[2, 48], id=[1], x=[21, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6599246627809106
ROC train: 0.556433	val: 0.670800	test: 0.600844
PRC train: 0.530763	val: 0.559676	test: 0.534744

Epoch: 2
Loss: 0.6020100185098974
ROC train: 0.633006	val: 0.666399	test: 0.726173
PRC train: 0.553366	val: 0.557489	test: 0.586351

Epoch: 3
Loss: 0.5532730248877243
ROC train: 0.669166	val: 0.655873	test: 0.759002
PRC train: 0.557879	val: 0.564908	test: 0.574566

Epoch: 4
Loss: 0.5107263749121628
ROC train: 0.702431	val: 0.671160	test: 0.781160
PRC train: 0.570075	val: 0.588069	test: 0.584872

Epoch: 5
Loss: 0.4704096110394219
ROC train: 0.718703	val: 0.688306	test: 0.779716
PRC train: 0.578211	val: 0.594088	test: 0.590722

Epoch: 6
Loss: 0.4404260285891324
ROC train: 0.750291	val: 0.697772	test: 0.778919
PRC train: 0.589048	val: 0.572690	test: 0.584367

Epoch: 7
Loss: 0.406791710636513
ROC train: 0.791969	val: 0.700724	test: 0.789938
PRC train: 0.609021	val: 0.566224	test: 0.592937

Epoch: 8
Loss: 0.37507774713473274
ROC train: 0.813725	val: 0.707567	test: 0.789709
PRC train: 0.623082	val: 0.564433	test: 0.593184

Epoch: 9
Loss: 0.3534559402311376
ROC train: 0.827019	val: 0.706754	test: 0.785256
PRC train: 0.638450	val: 0.555964	test: 0.586741

Epoch: 10
Loss: 0.330788655827242
ROC train: 0.857318	val: 0.686518	test: 0.781802
PRC train: 0.656419	val: 0.561861	test: 0.595808

Epoch: 11
Loss: 0.3073401792600967
ROC train: 0.863703	val: 0.704825	test: 0.777593
PRC train: 0.679126	val: 0.560063	test: 0.578757

Epoch: 12
Loss: 0.29204962330661366
ROC train: 0.863085	val: 0.682094	test: 0.788568
PRC train: 0.684297	val: 0.551827	test: 0.584136

Epoch: 13
Loss: 0.27070630321491745
ROC train: 0.875652	val: 0.676865	test: 0.788310
PRC train: 0.698992	val: 0.557076	test: 0.587689

Epoch: 14
Loss: 0.25867081217305804
ROC train: 0.886824	val: 0.678391	test: 0.777993
PRC train: 0.719351	val: 0.556500	test: 0.584871

Epoch: 15
Loss: 0.24226271687421516
ROC train: 0.898680	val: 0.675013	test: 0.776136
PRC train: 0.728453	val: 0.570363	test: 0.588382

Epoch: 16
Loss: 0.22952317539059128
ROC train: 0.901464	val: 0.676826	test: 0.790102
PRC train: 0.738326	val: 0.585896	test: 0.592642

Epoch: 17
Loss: 0.21718256442798245
ROC train: 0.910178	val: 0.675780	test: 0.798843
PRC train: 0.755781	val: 0.590477	test: 0.624406

Epoch: 18
Loss: 0.20647945342261392
ROC train: 0.921675	val: 0.674899	test: 0.796133
PRC train: 0.762973	val: 0.583678	test: 0.606559

Epoch: 19
Loss: 0.2091352457784035
ROC train: 0.889580	val: 0.709338	test: 0.741130
PRC train: 0.756441	val: 0.564898	test: 0.573679

Epoch: 20
Loss: 0.20284033797987683
ROC train: 0.894102	val: 0.699756	test: 0.754858
PRC train: 0.742654	val: 0.556851	test: 0.582612

Epoch: 21
Loss: 0.1948288671086348
ROC train: 0.933136	val: 0.670295	test: 0.790174
PRC train: 0.790846	val: 0.552523	test: 0.625197

Epoch: 22
Loss: 0.18324388173604553
ROC train: 0.939507	val: 0.653854	test: 0.797489
PRC train: 0.803515	val: 0.545761	test: 0.615954

Epoch: 23
Loss: 0.1805079208520911
ROC train: 0.934473	val: 0.673285	test: 0.780095
PRC train: 0.797487	val: 0.550865	test: 0.598005

Epoch: 24
Loss: 0.18193475821466176
ROC train: 0.938228	val: 0.671666	test: 0.783620
PRC train: 0.800623	val: 0.548539	test: 0.598922

Epoch: 25
Loss: 0.16985150455729725
ROC train: 0.942092	val: 0.669519	test: 0.795505
PRC train: 0.812884	val: 0.548926	test: 0.599588

Epoch: 26
Loss: 0.16952781658984784
ROC train: 0.955078	val: 0.656650	test: 0.801329
PRC train: 0.835508	val: 0.552793	test: 0.620622

Epoch: 27
Loss: 0.1613781288953546
ROC train: 0.957428	val: 0.684110	test: 0.804071
PRC train: 0.848890	val: 0.561339	test: 0.611123

Epoch: 28
Loss: 0.15856237911533
ROC train: 0.957882	val: 0.681991	test: 0.818664
PRC train: 0.845356	val: 0.549927	test: 0.646979

Epoch: 29
Loss: 0.15757981067176133
ROC train: 0.954162	val: 0.694588	test: 0.801313
PRC train: 0.825604	val: 0.560085	test: 0.660782

Epoch: 30
Loss: 0.16490786572262578
ROC train: 0.962645	val: 0.697293	test: 0.805917
PRC train: 0.854610	val: 0.561189	test: 0.650228

Epoch: 31
Loss: 0.14999811398583274
ROC train: 0.958628	val: 0.694916	test: 0.800852
PRC train: 0.849508	val: 0.558985	test: 0.628569

Epoch: 32
Loss: 0.15943647502483752
ROC train: 0.966522	val: 0.697021	test: 0.804738
PRC train: 0.865034	val: 0.558828	test: 0.633900

Epoch: 33
Loss: 0.15408791613760547Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/clintox/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/clintox/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/clintox/random/train_prop=0.6/clintox_random_4_26-05_11-06-56  ]
[ Using Seed :  4  ]
[ Using device :  cuda:0  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
randomly split
Data(edge_attr=[48, 2], edge_index=[2, 48], id=[1], x=[21, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6704790134359726
ROC train: 0.552722	val: 0.482416	test: 0.625583
PRC train: 0.536239	val: 0.532967	test: 0.546745

Epoch: 2
Loss: 0.6115953055116372
ROC train: 0.663615	val: 0.576937	test: 0.762381
PRC train: 0.559602	val: 0.545812	test: 0.585807

Epoch: 3
Loss: 0.5614451373896168
ROC train: 0.679866	val: 0.627335	test: 0.760049
PRC train: 0.560966	val: 0.544793	test: 0.572064

Epoch: 4
Loss: 0.5197412351943147
ROC train: 0.691210	val: 0.655589	test: 0.768303
PRC train: 0.564062	val: 0.563194	test: 0.573441

Epoch: 5
Loss: 0.4843961517307722
ROC train: 0.719762	val: 0.667683	test: 0.784349
PRC train: 0.571720	val: 0.565633	test: 0.580959

Epoch: 6
Loss: 0.44517575438054513
ROC train: 0.734063	val: 0.675867	test: 0.781058
PRC train: 0.574034	val: 0.571400	test: 0.580762

Epoch: 7
Loss: 0.4132236872322382
ROC train: 0.756010	val: 0.679253	test: 0.779316
PRC train: 0.579385	val: 0.569820	test: 0.582699

Epoch: 8
Loss: 0.38932728661227295
ROC train: 0.789555	val: 0.684531	test: 0.783657
PRC train: 0.597315	val: 0.549217	test: 0.586341

Epoch: 9
Loss: 0.36144233407134263
ROC train: 0.807662	val: 0.689061	test: 0.765813
PRC train: 0.609722	val: 0.549649	test: 0.574972

Epoch: 10
Loss: 0.33201284050774577
ROC train: 0.848324	val: 0.692862	test: 0.753209
PRC train: 0.636649	val: 0.548805	test: 0.574555

Epoch: 11
Loss: 0.31304746530576094
ROC train: 0.859338	val: 0.709664	test: 0.759752
PRC train: 0.648677	val: 0.554225	test: 0.576308

Epoch: 12
Loss: 0.2933436903736739
ROC train: 0.867923	val: 0.712609	test: 0.767181
PRC train: 0.667066	val: 0.553751	test: 0.584033

Epoch: 13
Loss: 0.27431216664768554
ROC train: 0.876867	val: 0.696494	test: 0.777837
PRC train: 0.683017	val: 0.549708	test: 0.589859

Epoch: 14
Loss: 0.25707563737638695
ROC train: 0.883961	val: 0.684507	test: 0.771382
PRC train: 0.710629	val: 0.551210	test: 0.603015

Epoch: 15
Loss: 0.24198655286958828
ROC train: 0.873067	val: 0.684246	test: 0.757465
PRC train: 0.710277	val: 0.550300	test: 0.597463

Epoch: 16
Loss: 0.2404353621242648
ROC train: 0.866252	val: 0.698927	test: 0.739930
PRC train: 0.722601	val: 0.556220	test: 0.580138

Epoch: 17
Loss: 0.22835368033769604
ROC train: 0.915683	val: 0.708960	test: 0.788845
PRC train: 0.755839	val: 0.561832	test: 0.602445

Epoch: 18
Loss: 0.20874931293794777
ROC train: 0.908942	val: 0.688248	test: 0.791920
PRC train: 0.764993	val: 0.551219	test: 0.590489

Epoch: 19
Loss: 0.2019796866376557
ROC train: 0.907073	val: 0.681303	test: 0.810521
PRC train: 0.752952	val: 0.547606	test: 0.617624

Epoch: 20
Loss: 0.196356765970281
ROC train: 0.925657	val: 0.687492	test: 0.814929
PRC train: 0.756303	val: 0.568128	test: 0.627257

Epoch: 21
Loss: 0.1990502543861879
ROC train: 0.929548	val: 0.712791	test: 0.780479
PRC train: 0.782191	val: 0.567773	test: 0.591122

Epoch: 22
Loss: 0.18482797253068106
ROC train: 0.926176	val: 0.700958	test: 0.772637
PRC train: 0.795845	val: 0.559998	test: 0.583753

Epoch: 23
Loss: 0.18758769218203486
ROC train: 0.937141	val: 0.689790	test: 0.808355
PRC train: 0.809375	val: 0.552641	test: 0.617967

Epoch: 24
Loss: 0.18945756101116204
ROC train: 0.937035	val: 0.698737	test: 0.792784
PRC train: 0.799954	val: 0.557271	test: 0.610817

Epoch: 25
Loss: 0.17409408129700715
ROC train: 0.946852	val: 0.715497	test: 0.776728
PRC train: 0.814332	val: 0.572163	test: 0.591397

Epoch: 26
Loss: 0.1715198955579691
ROC train: 0.953760	val: 0.700444	test: 0.785081
PRC train: 0.825526	val: 0.564757	test: 0.593033

Epoch: 27
Loss: 0.16177747471480086
ROC train: 0.952824	val: 0.681575	test: 0.803210
PRC train: 0.831105	val: 0.561005	test: 0.604858

Epoch: 28
Loss: 0.1620378442668277
ROC train: 0.954947	val: 0.678311	test: 0.813966
PRC train: 0.834331	val: 0.557426	test: 0.618334

Epoch: 29
Loss: 0.1552948486102299
ROC train: 0.954508	val: 0.684844	test: 0.803816
PRC train: 0.841824	val: 0.561003	test: 0.607675

Epoch: 30
Loss: 0.16483454382202806
ROC train: 0.962711	val: 0.685460	test: 0.796934
PRC train: 0.849163	val: 0.566220	test: 0.613692

Epoch: 31
Loss: 0.14547954472526797
ROC train: 0.965816	val: 0.680514	test: 0.794224
PRC train: 0.853227	val: 0.573018	test: 0.625592

Epoch: 32
Loss: 0.15165396316378038
ROC train: 0.972819	val: 0.690148	test: 0.785112
PRC train: 0.867234	val: 0.559691	test: 0.615338

Epoch: 33
Loss: 0.15105246082831816Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/clintox/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/clintox/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/clintox/random/train_prop=0.6/clintox_random_5_26-05_11-06-56  ]
[ Using Seed :  5  ]
[ Using device :  cuda:0  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
randomly split
Data(edge_attr=[48, 2], edge_index=[2, 48], id=[1], x=[21, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6879187731136506
ROC train: 0.585262	val: 0.512358	test: 0.627111
PRC train: 0.536348	val: 0.517846	test: 0.529235

Epoch: 2
Loss: 0.6228931012743479
ROC train: 0.641018	val: 0.573960	test: 0.723978
PRC train: 0.548491	val: 0.532103	test: 0.558093

Epoch: 3
Loss: 0.5701108663770673
ROC train: 0.666701	val: 0.624445	test: 0.751791
PRC train: 0.554763	val: 0.539247	test: 0.569738

Epoch: 4
Loss: 0.5272906193495686
ROC train: 0.684601	val: 0.667869	test: 0.760711
PRC train: 0.560099	val: 0.571075	test: 0.571465

Epoch: 5
Loss: 0.489344462988935
ROC train: 0.704598	val: 0.686684	test: 0.764949
PRC train: 0.567793	val: 0.577616	test: 0.578511

Epoch: 6
Loss: 0.4532633804678764
ROC train: 0.731580	val: 0.688494	test: 0.758794
PRC train: 0.576670	val: 0.564157	test: 0.576087

Epoch: 7
Loss: 0.4174633721792174
ROC train: 0.772890	val: 0.695843	test: 0.781343
PRC train: 0.590135	val: 0.570863	test: 0.592406

Epoch: 8
Loss: 0.38547540433008926
ROC train: 0.806172	val: 0.682604	test: 0.785762
PRC train: 0.612524	val: 0.550129	test: 0.591529

Epoch: 9
Loss: 0.3627007680856971
ROC train: 0.814741	val: 0.701817	test: 0.767578
PRC train: 0.618305	val: 0.552237	test: 0.578877

Epoch: 10
Loss: 0.3366801134212485
ROC train: 0.834621	val: 0.717644	test: 0.775170
PRC train: 0.630103	val: 0.575382	test: 0.587103

Epoch: 11
Loss: 0.3125675963748414
ROC train: 0.850369	val: 0.714689	test: 0.767114
PRC train: 0.650683	val: 0.556751	test: 0.582942

Epoch: 12
Loss: 0.2995098846969072
ROC train: 0.858499	val: 0.699542	test: 0.779329
PRC train: 0.669594	val: 0.550469	test: 0.583656

Epoch: 13
Loss: 0.28098985845753044
ROC train: 0.881332	val: 0.678457	test: 0.798399
PRC train: 0.684343	val: 0.545207	test: 0.600967

Epoch: 14
Loss: 0.2526401726716965
ROC train: 0.889977	val: 0.680529	test: 0.792313
PRC train: 0.690965	val: 0.545342	test: 0.590906

Epoch: 15
Loss: 0.24705329078557922
ROC train: 0.896623	val: 0.683964	test: 0.782506
PRC train: 0.705036	val: 0.546395	test: 0.593728

Epoch: 16
Loss: 0.2313229576618617
ROC train: 0.903705	val: 0.671072	test: 0.795926
PRC train: 0.724466	val: 0.546006	test: 0.628783

Epoch: 17
Loss: 0.22259261439327083
ROC train: 0.914511	val: 0.664612	test: 0.795012
PRC train: 0.733813	val: 0.552369	test: 0.618839

Epoch: 18
Loss: 0.21572155696696343
ROC train: 0.922970	val: 0.690115	test: 0.776313
PRC train: 0.747894	val: 0.564137	test: 0.604090

Epoch: 19
Loss: 0.2141867690124222
ROC train: 0.897506	val: 0.710815	test: 0.721029
PRC train: 0.741929	val: 0.555541	test: 0.567332

Epoch: 20
Loss: 0.1984744784276136
ROC train: 0.932992	val: 0.693782	test: 0.776858
PRC train: 0.775202	val: 0.547610	test: 0.644928

Epoch: 21
Loss: 0.20362869094317426
ROC train: 0.938675	val: 0.687219	test: 0.785910
PRC train: 0.787035	val: 0.547938	test: 0.628045

Epoch: 22
Loss: 0.1975598621316373
ROC train: 0.934114	val: 0.667169	test: 0.789844
PRC train: 0.791274	val: 0.545893	test: 0.633274

Epoch: 23
Loss: 0.1882761773821146
ROC train: 0.939451	val: 0.652233	test: 0.792506
PRC train: 0.790650	val: 0.543629	test: 0.643727

Epoch: 24
Loss: 0.1709605810834385
ROC train: 0.943320	val: 0.648848	test: 0.790708
PRC train: 0.803803	val: 0.544569	test: 0.639569

Epoch: 25
Loss: 0.1813065028427143
ROC train: 0.948640	val: 0.660444	test: 0.760745
PRC train: 0.810115	val: 0.547447	test: 0.619526

Epoch: 26
Loss: 0.17582756463595328
ROC train: 0.944091	val: 0.678379	test: 0.774981
PRC train: 0.812801	val: 0.555648	test: 0.611744

Epoch: 27
Loss: 0.169201661806562
ROC train: 0.947675	val: 0.671556	test: 0.793556
PRC train: 0.816975	val: 0.554427	test: 0.623101

Epoch: 28
Loss: 0.16425760741193582
ROC train: 0.938839	val: 0.673570	test: 0.799250
PRC train: 0.814576	val: 0.557578	test: 0.645525

Epoch: 29
Loss: 0.15827612306956984
ROC train: 0.953831	val: 0.718354	test: 0.785305
PRC train: 0.840022	val: 0.570517	test: 0.619012

Epoch: 30
Loss: 0.15127304068888622
ROC train: 0.959438	val: 0.715782	test: 0.788451
PRC train: 0.852426	val: 0.571896	test: 0.631740

Epoch: 31
Loss: 0.1633250195521987
ROC train: 0.962474	val: 0.702696	test: 0.797403
PRC train: 0.855454	val: 0.580522	test: 0.623284

Epoch: 32
Loss: 0.16476764668381433
ROC train: 0.956809	val: 0.666818	test: 0.808761
PRC train: 0.843743	val: 0.572164	test: 0.637896

Epoch: 33
Loss: 0.14935809637595515Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/clintox/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/clintox/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/clintox/random/train_prop=0.7/clintox_random_6_26-05_11-06-56  ]
[ Using Seed :  6  ]
[ Using device :  cuda:1  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
randomly split
Data(edge_attr=[48, 2], edge_index=[2, 48], id=[1], x=[21, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6458090106064064
ROC train: 0.590737	val: 0.616595	test: 0.699643
PRC train: 0.536071	val: 0.562948	test: 0.564103

Epoch: 2
Loss: 0.578573405489915
ROC train: 0.641075	val: 0.647372	test: 0.793929
PRC train: 0.553174	val: 0.560314	test: 0.603462

Epoch: 3
Loss: 0.5284850333973716
ROC train: 0.656516	val: 0.675046	test: 0.820312
PRC train: 0.554033	val: 0.581712	test: 0.580701

Epoch: 4
Loss: 0.5026215270521474
ROC train: 0.660989	val: 0.686735	test: 0.830341
PRC train: 0.556812	val: 0.602995	test: 0.592922

Epoch: 5
Loss: 0.4399468444802367
ROC train: 0.739702	val: 0.664885	test: 0.885806
PRC train: 0.570464	val: 0.582059	test: 0.643386

Epoch: 6
Loss: 0.39313794901383775
ROC train: 0.757830	val: 0.670620	test: 0.892124
PRC train: 0.583738	val: 0.592688	test: 0.640081

Epoch: 7
Loss: 0.3682549333814106
ROC train: 0.753575	val: 0.676766	test: 0.871989
PRC train: 0.582822	val: 0.598494	test: 0.612036

Epoch: 8
Loss: 0.3447410605049745
ROC train: 0.761676	val: 0.669755	test: 0.877064
PRC train: 0.586184	val: 0.599943	test: 0.620580

Epoch: 9
Loss: 0.3151921419530175
ROC train: 0.781682	val: 0.666896	test: 0.878121
PRC train: 0.596084	val: 0.594601	test: 0.630185

Epoch: 10
Loss: 0.29546483592519684
ROC train: 0.814891	val: 0.657313	test: 0.865601
PRC train: 0.614089	val: 0.590259	test: 0.610064

Epoch: 11
Loss: 0.26691096522884805
ROC train: 0.823510	val: 0.639637	test: 0.866968
PRC train: 0.632863	val: 0.587119	test: 0.612542

Epoch: 12
Loss: 0.24745648383836844
ROC train: 0.820543	val: 0.642345	test: 0.853366
PRC train: 0.653573	val: 0.589864	test: 0.600807

Epoch: 13
Loss: 0.232571050114622
ROC train: 0.827678	val: 0.644685	test: 0.846909
PRC train: 0.645512	val: 0.588724	test: 0.593672

Epoch: 14
Loss: 0.23957351853093628
ROC train: 0.843959	val: 0.627307	test: 0.864400
PRC train: 0.649678	val: 0.568974	test: 0.609670

Epoch: 15
Loss: 0.2132476072005735
ROC train: 0.822182	val: 0.606861	test: 0.863140
PRC train: 0.645750	val: 0.542392	test: 0.615814

Epoch: 16
Loss: 0.20267569971436825
ROC train: 0.835850	val: 0.620608	test: 0.874992
PRC train: 0.660687	val: 0.546469	test: 0.629840

Epoch: 17
Loss: 0.19775633217330152
ROC train: 0.859865	val: 0.637450	test: 0.884327
PRC train: 0.663099	val: 0.563796	test: 0.652221

Epoch: 18
Loss: 0.19275904280844697
ROC train: 0.813648	val: 0.644547	test: 0.864940
PRC train: 0.640330	val: 0.571531	test: 0.630707

Epoch: 19
Loss: 0.19006544429526964
ROC train: 0.862603	val: 0.626230	test: 0.875804
PRC train: 0.686398	val: 0.560257	test: 0.639970

Epoch: 20
Loss: 0.1862027320560232
ROC train: 0.881599	val: 0.592697	test: 0.882105
PRC train: 0.720985	val: 0.546230	test: 0.631941

Epoch: 21
Loss: 0.17395572064224948
ROC train: 0.888857	val: 0.586860	test: 0.878708
PRC train: 0.727186	val: 0.541673	test: 0.661865

Epoch: 22
Loss: 0.2734146904950473
ROC train: 0.892425	val: 0.591177	test: 0.873870
PRC train: 0.727897	val: 0.536636	test: 0.629122

Epoch: 23
Loss: 0.2853340711251936
ROC train: 0.853437	val: 0.596912	test: 0.858632
PRC train: 0.669211	val: 0.533440	test: 0.604749

Epoch: 24
Loss: 0.21279722633052706
ROC train: 0.861181	val: 0.607700	test: 0.879553
PRC train: 0.670610	val: 0.537875	test: 0.647870

Epoch: 25
Loss: 0.17455595484377837
ROC train: 0.859591	val: 0.643959	test: 0.872150
PRC train: 0.683237	val: 0.557356	test: 0.653291

Epoch: 26
Loss: 0.21114110183115256
ROC train: 0.860883	val: 0.683856	test: 0.857944
PRC train: 0.702762	val: 0.577980	test: 0.624501

Epoch: 27
Loss: 0.1743032533731682
ROC train: 0.863115	val: 0.683009	test: 0.857815
PRC train: 0.711069	val: 0.583000	test: 0.636512

Epoch: 28
Loss: 0.20628962604265805
ROC train: 0.873010	val: 0.667129	test: 0.861042
PRC train: 0.717973	val: 0.578448	test: 0.645545

Epoch: 29
Loss: 0.1630769094395358
ROC train: 0.865466	val: 0.650061	test: 0.862206
PRC train: 0.701975	val: 0.558611	test: 0.649194

Epoch: 30
Loss: 0.17387400911978318
ROC train: 0.886256	val: 0.632661	test: 0.887009
PRC train: 0.722250	val: 0.571357	test: 0.645727

Epoch: 31
Loss: 0.1928340345297028
ROC train: 0.906215	val: 0.622492	test: 0.889290
PRC train: 0.748666	val: 0.559757	test: 0.640068

Epoch: 32
Loss: 0.15532325868996114
ROC train: 0.908651	val: 0.600079	test: 0.866996
PRC train: 0.731821	val: 0.533450	test: 0.663366

Epoch: 33
Loss: 0.19864439016684826Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/clintox/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/clintox/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/clintox/random/train_prop=0.7/clintox_random_5_26-05_11-06-56  ]
[ Using Seed :  5  ]
[ Using device :  cuda:1  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
randomly split
Data(edge_attr=[48, 2], edge_index=[2, 48], id=[1], x=[21, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6778797774011528
ROC train: 0.581075	val: 0.542509	test: 0.676542
PRC train: 0.532912	val: 0.523949	test: 0.539357

Epoch: 2
Loss: 0.6140933401519694
ROC train: 0.605397	val: 0.582374	test: 0.739425
PRC train: 0.536684	val: 0.535419	test: 0.556165

Epoch: 3
Loss: 0.5701927049728516
ROC train: 0.641381	val: 0.598759	test: 0.744835
PRC train: 0.548845	val: 0.537418	test: 0.551822

Epoch: 4
Loss: 0.5024378088590233
ROC train: 0.617743	val: 0.585379	test: 0.682491
PRC train: 0.542144	val: 0.533724	test: 0.538667

Epoch: 5
Loss: 0.4694555553463678
ROC train: 0.620993	val: 0.601759	test: 0.692342
PRC train: 0.542248	val: 0.543067	test: 0.541826

Epoch: 6
Loss: 0.4418768961484165
ROC train: 0.678397	val: 0.638784	test: 0.784943
PRC train: 0.550131	val: 0.557140	test: 0.574370

Epoch: 7
Loss: 0.4362918019250789
ROC train: 0.685351	val: 0.668753	test: 0.839910
PRC train: 0.551155	val: 0.576285	test: 0.602399

Epoch: 8
Loss: 0.35352431024142283
ROC train: 0.710021	val: 0.674833	test: 0.865007
PRC train: 0.563502	val: 0.560456	test: 0.637155

Epoch: 9
Loss: 0.36266578146889633
ROC train: 0.750298	val: 0.675500	test: 0.887232
PRC train: 0.582020	val: 0.560769	test: 0.662838

Epoch: 10
Loss: 0.3414013827961898
ROC train: 0.791271	val: 0.661485	test: 0.880854
PRC train: 0.604003	val: 0.560162	test: 0.659563

Epoch: 11
Loss: 0.28358874727709227
ROC train: 0.776207	val: 0.627391	test: 0.834910
PRC train: 0.622487	val: 0.542211	test: 0.579255

Epoch: 12
Loss: 0.2646742565622868
ROC train: 0.784360	val: 0.640239	test: 0.829497
PRC train: 0.620629	val: 0.546858	test: 0.578625

Epoch: 13
Loss: 0.26219508146838927
ROC train: 0.802358	val: 0.655194	test: 0.849494
PRC train: 0.628110	val: 0.558896	test: 0.593885

Epoch: 14
Loss: 0.2534016892456122
ROC train: 0.810502	val: 0.670075	test: 0.849163
PRC train: 0.635966	val: 0.585091	test: 0.595323

Epoch: 15
Loss: 0.2374386716214616
ROC train: 0.827371	val: 0.669964	test: 0.853253
PRC train: 0.644659	val: 0.567894	test: 0.624233

Epoch: 16
Loss: 0.22473554256243275
ROC train: 0.826542	val: 0.666258	test: 0.849118
PRC train: 0.654040	val: 0.570434	test: 0.620670

Epoch: 17
Loss: 0.25642079624233716
ROC train: 0.818082	val: 0.665031	test: 0.853605
PRC train: 0.639627	val: 0.569077	test: 0.625755

Epoch: 18
Loss: 0.22212242425276676
ROC train: 0.802109	val: 0.701645	test: 0.803945
PRC train: 0.652493	val: 0.582511	test: 0.597225

Epoch: 19
Loss: 0.26213830171417724
ROC train: 0.819202	val: 0.658035	test: 0.821047
PRC train: 0.646279	val: 0.565419	test: 0.579119

Epoch: 20
Loss: 0.23718571108220296
ROC train: 0.794402	val: 0.605402	test: 0.838345
PRC train: 0.632970	val: 0.559426	test: 0.594840

Epoch: 21
Loss: 0.1948122949528837
ROC train: 0.804235	val: 0.582565	test: 0.871818
PRC train: 0.630611	val: 0.544318	test: 0.684079

Epoch: 22
Loss: 0.2486184471439484
ROC train: 0.829055	val: 0.596600	test: 0.887382
PRC train: 0.645791	val: 0.557499	test: 0.712420

Epoch: 23
Loss: 0.29059068121795517
ROC train: 0.841600	val: 0.581448	test: 0.881000
PRC train: 0.641700	val: 0.547489	test: 0.681925

Epoch: 24
Loss: 0.23474050923155435
ROC train: 0.845845	val: 0.596586	test: 0.848822
PRC train: 0.660273	val: 0.551352	test: 0.636650

Epoch: 25
Loss: 0.2448484102614128
ROC train: 0.850495	val: 0.601151	test: 0.828740
PRC train: 0.682845	val: 0.542514	test: 0.607156

Epoch: 26
Loss: 0.17875730547374846
ROC train: 0.870961	val: 0.611478	test: 0.847987
PRC train: 0.689746	val: 0.543518	test: 0.636337

Epoch: 27
Loss: 0.18183211145524686
ROC train: 0.873927	val: 0.614551	test: 0.831761
PRC train: 0.694083	val: 0.544202	test: 0.626736

Epoch: 28
Loss: 0.1845083544680649
ROC train: 0.873910	val: 0.603979	test: 0.791386
PRC train: 0.709797	val: 0.542751	test: 0.606862

Epoch: 29
Loss: 0.21240975746655288
ROC train: 0.873867	val: 0.607432	test: 0.767427
PRC train: 0.716020	val: 0.541607	test: 0.580722

Epoch: 30
Loss: 0.16652591029455438
ROC train: 0.861763	val: 0.593296	test: 0.774593
PRC train: 0.687474	val: 0.534224	test: 0.564534

Epoch: 31
Loss: 0.16935497458717727
ROC train: 0.871436	val: 0.582116	test: 0.817998
PRC train: 0.691169	val: 0.530708	test: 0.581776

Epoch: 32
Loss: 0.20369035225347804
ROC train: 0.896865	val: 0.584083	test: 0.854129
PRC train: 0.722307	val: 0.537111	test: 0.618989

Epoch: 33
Loss: 0.17124086935234353Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/clintox/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/clintox/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/clintox/random/train_prop=0.7/clintox_random_4_26-05_11-06-56  ]
[ Using Seed :  4  ]
[ Using device :  cuda:1  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
randomly split
Data(edge_attr=[48, 2], edge_index=[2, 48], id=[1], x=[21, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6577882166025981
ROC train: 0.581513	val: 0.561870	test: 0.677444
PRC train: 0.536092	val: 0.530037	test: 0.575823

Epoch: 2
Loss: 0.5905921166193486
ROC train: 0.636895	val: 0.599251	test: 0.753677
PRC train: 0.546740	val: 0.540044	test: 0.566620

Epoch: 3
Loss: 0.5317958606222228
ROC train: 0.639003	val: 0.613865	test: 0.753693
PRC train: 0.548854	val: 0.546787	test: 0.562283

Epoch: 4
Loss: 0.5411123277324773
ROC train: 0.662765	val: 0.629663	test: 0.765897
PRC train: 0.557195	val: 0.549808	test: 0.560290

Epoch: 5
Loss: 0.4552714537751873
ROC train: 0.700892	val: 0.608905	test: 0.809558
PRC train: 0.562571	val: 0.562430	test: 0.572572

Epoch: 6
Loss: 0.43255455674975696
ROC train: 0.730593	val: 0.609756	test: 0.838104
PRC train: 0.570141	val: 0.560945	test: 0.590435

Epoch: 7
Loss: 0.38821119112802516
ROC train: 0.767071	val: 0.613302	test: 0.844877
PRC train: 0.580025	val: 0.559460	test: 0.589229

Epoch: 8
Loss: 0.35848154482589395
ROC train: 0.779310	val: 0.647837	test: 0.833951
PRC train: 0.586593	val: 0.568533	test: 0.580078

Epoch: 9
Loss: 0.34331160236398095
ROC train: 0.779730	val: 0.656000	test: 0.827020
PRC train: 0.595226	val: 0.551178	test: 0.576789

Epoch: 10
Loss: 0.28575932156801664
ROC train: 0.782833	val: 0.647589	test: 0.837211
PRC train: 0.595274	val: 0.570264	test: 0.586030

Epoch: 11
Loss: 0.2813079184162618
ROC train: 0.799541	val: 0.662128	test: 0.864705
PRC train: 0.594550	val: 0.578607	test: 0.603058

Epoch: 12
Loss: 0.2763094385808659
ROC train: 0.802732	val: 0.673200	test: 0.864749
PRC train: 0.601366	val: 0.602788	test: 0.608343

Epoch: 13
Loss: 0.25201870030236045
ROC train: 0.799610	val: 0.669088	test: 0.817583
PRC train: 0.616780	val: 0.580697	test: 0.582978

Epoch: 14
Loss: 0.22803341011561176
ROC train: 0.820103	val: 0.656269	test: 0.815686
PRC train: 0.632036	val: 0.581600	test: 0.583125

Epoch: 15
Loss: 0.21404954868265952
ROC train: 0.837576	val: 0.645866	test: 0.846428
PRC train: 0.649457	val: 0.574896	test: 0.592394

Epoch: 16
Loss: 0.25647137180230734
ROC train: 0.832863	val: 0.627667	test: 0.852143
PRC train: 0.647469	val: 0.546436	test: 0.601787

Epoch: 17
Loss: 0.2257507823019656
ROC train: 0.830265	val: 0.618372	test: 0.842326
PRC train: 0.648461	val: 0.541298	test: 0.599015

Epoch: 18
Loss: 0.20016971623281807
ROC train: 0.847597	val: 0.628336	test: 0.829454
PRC train: 0.655508	val: 0.548198	test: 0.591933

Epoch: 19
Loss: 0.21884768476917293
ROC train: 0.869559	val: 0.628614	test: 0.834613
PRC train: 0.677190	val: 0.548407	test: 0.605268

Epoch: 20
Loss: 0.20631400034019495
ROC train: 0.867877	val: 0.614203	test: 0.846994
PRC train: 0.667677	val: 0.542057	test: 0.612730

Epoch: 21
Loss: 0.21170683809389518
ROC train: 0.845413	val: 0.606338	test: 0.843828
PRC train: 0.674620	val: 0.541702	test: 0.588148

Epoch: 22
Loss: 0.18240995005798447
ROC train: 0.825875	val: 0.600958	test: 0.847742
PRC train: 0.672391	val: 0.553884	test: 0.598666

Epoch: 23
Loss: 0.19127711509915687
ROC train: 0.832531	val: 0.594259	test: 0.873437
PRC train: 0.688834	val: 0.557468	test: 0.636841

Epoch: 24
Loss: 0.18001260875552977
ROC train: 0.857929	val: 0.596376	test: 0.877522
PRC train: 0.715667	val: 0.550193	test: 0.664389

Epoch: 25
Loss: 0.22955487378492473
ROC train: 0.868259	val: 0.606494	test: 0.882169
PRC train: 0.719095	val: 0.554542	test: 0.673928

Epoch: 26
Loss: 0.17444154657005667
ROC train: 0.878518	val: 0.631735	test: 0.877822
PRC train: 0.695385	val: 0.556788	test: 0.663129

Epoch: 27
Loss: 0.24395468722530128
ROC train: 0.892953	val: 0.645986	test: 0.855507
PRC train: 0.695302	val: 0.568373	test: 0.647603

Epoch: 28
Loss: 0.20283898408941753
ROC train: 0.870667	val: 0.617354	test: 0.843757
PRC train: 0.678674	val: 0.548020	test: 0.644016

Epoch: 29
Loss: 0.21242892496027227
ROC train: 0.871864	val: 0.595250	test: 0.847244
PRC train: 0.702883	val: 0.539425	test: 0.610749

Epoch: 30
Loss: 0.20723345490500572
ROC train: 0.872573	val: 0.572721	test: 0.864677
PRC train: 0.697906	val: 0.535591	test: 0.619111

Epoch: 31
Loss: 0.19600582798686872
ROC train: 0.858231	val: 0.565639	test: 0.886912
PRC train: 0.661994	val: 0.528354	test: 0.760800

Epoch: 32
Loss: 0.22914713460303862
ROC train: 0.870939	val: 0.600157	test: 0.893247
PRC train: 0.683668	val: 0.537452	test: 0.703835

Epoch: 33
Loss: 0.2027745255355772Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/clintox/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/clintox/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/clintox/random/train_prop=0.8/clintox_random_6_26-05_11-06-56  ]
[ Using Seed :  6  ]
[ Using device :  cuda:2  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
randomly split
Data(edge_attr=[48, 2], edge_index=[2, 48], id=[1], x=[21, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6478553027944803
ROC train: 0.598653	val: 0.606952	test: 0.681814
PRC train: 0.534883	val: 0.539050	test: 0.553075

Epoch: 2
Loss: 0.5787488311429216
ROC train: 0.621156	val: 0.653743	test: 0.712581
PRC train: 0.541385	val: 0.539411	test: 0.555533

Epoch: 3
Loss: 0.519014889348149
ROC train: 0.660120	val: 0.695856	test: 0.780688
PRC train: 0.552704	val: 0.548220	test: 0.580398

Epoch: 4
Loss: 0.47310390691479565
ROC train: 0.710109	val: 0.758356	test: 0.832288
PRC train: 0.568682	val: 0.568583	test: 0.639769

Epoch: 5
Loss: 0.4333868675460685
ROC train: 0.716672	val: 0.741644	test: 0.817215
PRC train: 0.575815	val: 0.560147	test: 0.626425

Epoch: 6
Loss: 0.3899449703597072
ROC train: 0.770924	val: 0.738971	test: 0.839118
PRC train: 0.585742	val: 0.567054	test: 0.644114

Epoch: 7
Loss: 0.3606562630347982
ROC train: 0.798327	val: 0.735294	test: 0.834188
PRC train: 0.596916	val: 0.569058	test: 0.634458

Epoch: 8
Loss: 0.3264159850300376
ROC train: 0.824822	val: 0.739639	test: 0.846573
PRC train: 0.614790	val: 0.579256	test: 0.618573

Epoch: 9
Loss: 0.30459131087647895
ROC train: 0.833327	val: 0.735294	test: 0.827475
PRC train: 0.627568	val: 0.570591	test: 0.606091

Epoch: 10
Loss: 0.27978758599151216
ROC train: 0.845522	val: 0.745989	test: 0.835881
PRC train: 0.643106	val: 0.585548	test: 0.632598

Epoch: 11
Loss: 0.26433645081965157
ROC train: 0.853839	val: 0.736297	test: 0.830338
PRC train: 0.654074	val: 0.582051	test: 0.629419

Epoch: 12
Loss: 0.249724878149785
ROC train: 0.868392	val: 0.751671	test: 0.844388
PRC train: 0.673922	val: 0.598970	test: 0.640804

Epoch: 13
Loss: 0.2347738507415053
ROC train: 0.870574	val: 0.745321	test: 0.851771
PRC train: 0.689255	val: 0.586171	test: 0.644112

Epoch: 14
Loss: 0.21973374607862123
ROC train: 0.881480	val: 0.734626	test: 0.832193
PRC train: 0.722518	val: 0.586560	test: 0.629015

Epoch: 15
Loss: 0.21239839023854326
ROC train: 0.889776	val: 0.750334	test: 0.842737
PRC train: 0.738928	val: 0.592489	test: 0.634397

Epoch: 16
Loss: 0.21388732270011257
ROC train: 0.882883	val: 0.769719	test: 0.875534
PRC train: 0.734182	val: 0.600805	test: 0.663219

Epoch: 17
Loss: 0.19713684661479253
ROC train: 0.885619	val: 0.746324	test: 0.861100
PRC train: 0.749139	val: 0.586756	test: 0.644520

Epoch: 18
Loss: 0.19590674797878754
ROC train: 0.898828	val: 0.730949	test: 0.837731
PRC train: 0.744797	val: 0.585100	test: 0.627224

Epoch: 19
Loss: 0.18457611672138058
ROC train: 0.907149	val: 0.730615	test: 0.857507
PRC train: 0.747859	val: 0.596634	test: 0.617310

Epoch: 20
Loss: 0.18819810682218138
ROC train: 0.916777	val: 0.714572	test: 0.867297
PRC train: 0.784522	val: 0.595112	test: 0.650557

Epoch: 21
Loss: 0.17870632443463602
ROC train: 0.925746	val: 0.727607	test: 0.852861
PRC train: 0.798060	val: 0.586739	test: 0.637690

Epoch: 22
Loss: 0.17774055471117023
ROC train: 0.930030	val: 0.742981	test: 0.858708
PRC train: 0.797087	val: 0.591738	test: 0.643276

Epoch: 23
Loss: 0.1763255726218074
ROC train: 0.932406	val: 0.725602	test: 0.902203
PRC train: 0.791594	val: 0.585925	test: 0.676332

Epoch: 24
Loss: 0.16620383978237332
ROC train: 0.941281	val: 0.743984	test: 0.897167
PRC train: 0.811273	val: 0.588052	test: 0.671528

Epoch: 25
Loss: 0.17106286158922576
ROC train: 0.946560	val: 0.748663	test: 0.864901
PRC train: 0.810717	val: 0.605223	test: 0.623454

Epoch: 26
Loss: 0.1568497188544576
ROC train: 0.937173	val: 0.755013	test: 0.828080
PRC train: 0.804164	val: 0.595008	test: 0.599493

Epoch: 27
Loss: 0.15913557502508938
ROC train: 0.943234	val: 0.751003	test: 0.839272
PRC train: 0.817103	val: 0.594056	test: 0.614946

Epoch: 28
Loss: 0.15937352538402821
ROC train: 0.951831	val: 0.770722	test: 0.890458
PRC train: 0.843090	val: 0.616625	test: 0.671072

Epoch: 29
Loss: 0.1619040757863798
ROC train: 0.944051	val: 0.745989	test: 0.905126
PRC train: 0.823196	val: 0.626541	test: 0.693371

Epoch: 30
Loss: 0.1537847139323173
ROC train: 0.944557	val: 0.735294	test: 0.902547
PRC train: 0.810398	val: 0.598769	test: 0.694315

Epoch: 31
Loss: 0.14722626376622006
ROC train: 0.955937	val: 0.735628	test: 0.885786
PRC train: 0.825095	val: 0.604438	test: 0.669130

Epoch: 32
Loss: 0.1557016389731484
ROC train: 0.961140	val: 0.719586	test: 0.867271
PRC train: 0.844169	val: 0.605640	test: 0.664664

Epoch: 33
Loss: 0.1575521717219808Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/clintox/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/clintox/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/clintox/random/train_prop=0.8/clintox_random_5_26-05_11-06-56  ]
[ Using Seed :  5  ]
[ Using device :  cuda:2  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
randomly split
Data(edge_attr=[48, 2], edge_index=[2, 48], id=[1], x=[21, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6739932699869656
ROC train: 0.586777	val: 0.655414	test: 0.667246
PRC train: 0.532377	val: 0.535780	test: 0.546051

Epoch: 2
Loss: 0.6039009048515703
ROC train: 0.622383	val: 0.699866	test: 0.708789
PRC train: 0.541048	val: 0.547478	test: 0.558883

Epoch: 3
Loss: 0.5422679337839297
ROC train: 0.638978	val: 0.670455	test: 0.714267
PRC train: 0.544998	val: 0.539224	test: 0.559625

Epoch: 4
Loss: 0.4908330462096654
ROC train: 0.686516	val: 0.697193	test: 0.793410
PRC train: 0.559290	val: 0.549725	test: 0.622354

Epoch: 5
Loss: 0.4513627170402425
ROC train: 0.725045	val: 0.707553	test: 0.843313
PRC train: 0.571320	val: 0.556355	test: 0.651450

Epoch: 6
Loss: 0.40808303062268064
ROC train: 0.748367	val: 0.686497	test: 0.828509
PRC train: 0.578761	val: 0.550134	test: 0.611725

Epoch: 7
Loss: 0.37100363265844377
ROC train: 0.789115	val: 0.733289	test: 0.850109
PRC train: 0.596972	val: 0.573494	test: 0.626933

Epoch: 8
Loss: 0.3416621786133115
ROC train: 0.787544	val: 0.697527	test: 0.816881
PRC train: 0.601989	val: 0.552455	test: 0.602233

Epoch: 9
Loss: 0.31049789763733787
ROC train: 0.815541	val: 0.716578	test: 0.827577
PRC train: 0.617365	val: 0.562754	test: 0.603750

Epoch: 10
Loss: 0.2842787797829819
ROC train: 0.846727	val: 0.738971	test: 0.847296
PRC train: 0.636528	val: 0.583015	test: 0.657791

Epoch: 11
Loss: 0.27287986562975763
ROC train: 0.841082	val: 0.725267	test: 0.835653
PRC train: 0.644786	val: 0.570107	test: 0.632628

Epoch: 12
Loss: 0.2489106026899671
ROC train: 0.861305	val: 0.744652	test: 0.852293
PRC train: 0.653974	val: 0.577808	test: 0.644508

Epoch: 13
Loss: 0.23503336422999282
ROC train: 0.871575	val: 0.754011	test: 0.848727
PRC train: 0.681499	val: 0.593159	test: 0.643360

Epoch: 14
Loss: 0.21953475080136564
ROC train: 0.876192	val: 0.758356	test: 0.837883
PRC train: 0.700219	val: 0.588502	test: 0.609268

Epoch: 15
Loss: 0.2167564442278953
ROC train: 0.889392	val: 0.755682	test: 0.858374
PRC train: 0.708350	val: 0.598466	test: 0.640120

Epoch: 16
Loss: 0.2040400936745431
ROC train: 0.905544	val: 0.747995	test: 0.865503
PRC train: 0.743201	val: 0.613937	test: 0.643707

Epoch: 17
Loss: 0.19252944002603442
ROC train: 0.889533	val: 0.741979	test: 0.864006
PRC train: 0.735770	val: 0.588876	test: 0.652925

Epoch: 18
Loss: 0.18484881142835624
ROC train: 0.911811	val: 0.779412	test: 0.876711
PRC train: 0.762037	val: 0.627574	test: 0.686461

Epoch: 19
Loss: 0.19646998488332484
ROC train: 0.918183	val: 0.768048	test: 0.880993
PRC train: 0.780648	val: 0.607832	test: 0.680951

Epoch: 20
Loss: 0.18240503243801207
ROC train: 0.908454	val: 0.710227	test: 0.838568
PRC train: 0.770581	val: 0.562208	test: 0.634698

Epoch: 21
Loss: 0.18557396634036402
ROC train: 0.923402	val: 0.755013	test: 0.892287
PRC train: 0.773963	val: 0.614170	test: 0.685750

Epoch: 22
Loss: 0.17328844429943796
ROC train: 0.933710	val: 0.755013	test: 0.868062
PRC train: 0.796192	val: 0.597633	test: 0.670461

Epoch: 23
Loss: 0.17785752678174394
ROC train: 0.941716	val: 0.756684	test: 0.861395
PRC train: 0.813940	val: 0.631141	test: 0.673440

Epoch: 24
Loss: 0.16809774691460183
ROC train: 0.934508	val: 0.770388	test: 0.882492
PRC train: 0.802991	val: 0.629375	test: 0.705021

Epoch: 25
Loss: 0.16694306787058452
ROC train: 0.940140	val: 0.789439	test: 0.880633
PRC train: 0.795118	val: 0.609946	test: 0.696552

Epoch: 26
Loss: 0.16298889664526212
ROC train: 0.935981	val: 0.775067	test: 0.866045
PRC train: 0.776597	val: 0.627632	test: 0.684326

Epoch: 27
Loss: 0.15559169043208437
ROC train: 0.947253	val: 0.762032	test: 0.871330
PRC train: 0.810709	val: 0.600268	test: 0.696691

Epoch: 28
Loss: 0.1631717044441043
ROC train: 0.951270	val: 0.757687	test: 0.882566
PRC train: 0.835774	val: 0.621032	test: 0.706831

Epoch: 29
Loss: 0.15459434455427445
ROC train: 0.949792	val: 0.779412	test: 0.898372
PRC train: 0.833966	val: 0.616465	test: 0.741339

Epoch: 30
Loss: 0.14526840512363595
ROC train: 0.944014	val: 0.774398	test: 0.881747
PRC train: 0.816997	val: 0.599116	test: 0.720352

Epoch: 31
Loss: 0.15142009725751152
ROC train: 0.961123	val: 0.771390	test: 0.877816
PRC train: 0.835155	val: 0.610727	test: 0.699235

Epoch: 32
Loss: 0.1552176491259998
ROC train: 0.965107	val: 0.756350	test: 0.883476
PRC train: 0.862800	val: 0.610551	test: 0.699745

Epoch: 33
Loss: 0.16255143529435126Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/clintox/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/clintox/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/clintox/random/train_prop=0.8/clintox_random_4_26-05_11-06-56  ]
[ Using Seed :  4  ]
[ Using device :  cuda:2  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
randomly split
Data(edge_attr=[48, 2], edge_index=[2, 48], id=[1], x=[21, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6631536390950921
ROC train: 0.587704	val: 0.672794	test: 0.677476
PRC train: 0.542879	val: 0.540321	test: 0.561883

Epoch: 2
Loss: 0.5913859236319665
ROC train: 0.638230	val: 0.718249	test: 0.771617
PRC train: 0.551031	val: 0.549134	test: 0.606978

Epoch: 3
Loss: 0.537547738587744
ROC train: 0.660340	val: 0.715241	test: 0.776573
PRC train: 0.553395	val: 0.551217	test: 0.610637

Epoch: 4
Loss: 0.4845013970279058
ROC train: 0.704030	val: 0.738971	test: 0.816915
PRC train: 0.563798	val: 0.560730	test: 0.630331

Epoch: 5
Loss: 0.4375016554251194
ROC train: 0.738132	val: 0.741310	test: 0.846819
PRC train: 0.573695	val: 0.566515	test: 0.616515

Epoch: 6
Loss: 0.4043979012563842
ROC train: 0.756277	val: 0.724933	test: 0.836986
PRC train: 0.579122	val: 0.560609	test: 0.599661

Epoch: 7
Loss: 0.3658245425052952
ROC train: 0.797686	val: 0.737299	test: 0.859386
PRC train: 0.592051	val: 0.570270	test: 0.614021

Epoch: 8
Loss: 0.33504296024922275
ROC train: 0.817939	val: 0.735294	test: 0.851877
PRC train: 0.607449	val: 0.575743	test: 0.624925

Epoch: 9
Loss: 0.310685300507365
ROC train: 0.832409	val: 0.756350	test: 0.839367
PRC train: 0.618954	val: 0.594730	test: 0.638067

Epoch: 10
Loss: 0.2899702220649451
ROC train: 0.840274	val: 0.752005	test: 0.836956
PRC train: 0.629640	val: 0.585608	test: 0.628392

Epoch: 11
Loss: 0.2669387808428552
ROC train: 0.861416	val: 0.752340	test: 0.842858
PRC train: 0.671853	val: 0.588101	test: 0.640990

Epoch: 12
Loss: 0.24914419227709345
ROC train: 0.874479	val: 0.757019	test: 0.851726
PRC train: 0.693370	val: 0.588951	test: 0.648250

Epoch: 13
Loss: 0.23654811115641286
ROC train: 0.878649	val: 0.774733	test: 0.845883
PRC train: 0.697991	val: 0.588398	test: 0.637790

Epoch: 14
Loss: 0.2279354331767293
ROC train: 0.880436	val: 0.787767	test: 0.841222
PRC train: 0.722405	val: 0.595155	test: 0.610480

Epoch: 15
Loss: 0.2191943990650999
ROC train: 0.896414	val: 0.794786	test: 0.875605
PRC train: 0.734497	val: 0.613385	test: 0.667132

Epoch: 16
Loss: 0.21220114525442732
ROC train: 0.908652	val: 0.781417	test: 0.870331
PRC train: 0.754306	val: 0.607329	test: 0.672399

Epoch: 17
Loss: 0.19443664494874924
ROC train: 0.916051	val: 0.742313	test: 0.829837
PRC train: 0.769113	val: 0.580511	test: 0.624734

Epoch: 18
Loss: 0.20126788944490084
ROC train: 0.918072	val: 0.723262	test: 0.824340
PRC train: 0.765865	val: 0.594819	test: 0.626250

Epoch: 19
Loss: 0.18867741474504035
ROC train: 0.923498	val: 0.749332	test: 0.813821
PRC train: 0.770329	val: 0.592017	test: 0.593588

Epoch: 20
Loss: 0.1798118310764601
ROC train: 0.932064	val: 0.754679	test: 0.835664
PRC train: 0.786266	val: 0.609734	test: 0.642906

Epoch: 21
Loss: 0.17738019740813346
ROC train: 0.932724	val: 0.764706	test: 0.841567
PRC train: 0.786856	val: 0.605480	test: 0.638798

Epoch: 22
Loss: 0.17142090682511107
ROC train: 0.941455	val: 0.765374	test: 0.834347
PRC train: 0.799490	val: 0.603764	test: 0.632287

Epoch: 23
Loss: 0.17273167211400794
ROC train: 0.941928	val: 0.749332	test: 0.865234
PRC train: 0.809494	val: 0.599730	test: 0.663483

Epoch: 24
Loss: 0.17334275187965967
ROC train: 0.936440	val: 0.735628	test: 0.858014
PRC train: 0.784905	val: 0.597966	test: 0.682298

Epoch: 25
Loss: 0.16600402775196194
ROC train: 0.937081	val: 0.756350	test: 0.846659
PRC train: 0.789475	val: 0.585716	test: 0.643140

Epoch: 26
Loss: 0.16263779607724071
ROC train: 0.954283	val: 0.766711	test: 0.823965
PRC train: 0.822937	val: 0.589995	test: 0.625408

Epoch: 27
Loss: 0.15157003521671567
ROC train: 0.952445	val: 0.772393	test: 0.827425
PRC train: 0.824314	val: 0.592465	test: 0.600277

Epoch: 28
Loss: 0.15527523757585066
ROC train: 0.957219	val: 0.764706	test: 0.847292
PRC train: 0.843928	val: 0.596977	test: 0.621888

Epoch: 29
Loss: 0.1543275112616262
ROC train: 0.954748	val: 0.753342	test: 0.844456
PRC train: 0.828029	val: 0.592079	test: 0.639044

Epoch: 30
Loss: 0.15240140575548441
ROC train: 0.959259	val: 0.763369	test: 0.872201
PRC train: 0.846536	val: 0.606621	test: 0.662848

Epoch: 31
Loss: 0.14745996972139233
ROC train: 0.955690	val: 0.730281	test: 0.846061
PRC train: 0.840791	val: 0.583491	test: 0.631543

Epoch: 32
Loss: 0.14373226183156476
ROC train: 0.955276	val: 0.725267	test: 0.820084
PRC train: 0.839152	val: 0.578588	test: 0.622405

Epoch: 33
Loss: 0.14490180500098665
ROC train: 0.973337	val: 0.681889	test: 0.792569
PRC train: 0.874412	val: 0.566412	test: 0.621775

Epoch: 34
Loss: 0.14996708536465908
ROC train: 0.967871	val: 0.667524	test: 0.799265
PRC train: 0.863102	val: 0.560259	test: 0.631367

Epoch: 35
Loss: 0.15301647240277322
ROC train: 0.969934	val: 0.683340	test: 0.818164
PRC train: 0.870967	val: 0.566900	test: 0.627749

Epoch: 36
Loss: 0.1390815001558035
ROC train: 0.961758	val: 0.669235	test: 0.812147
PRC train: 0.852547	val: 0.565478	test: 0.621966

Epoch: 37
Loss: 0.14537813380438383
ROC train: 0.969916	val: 0.688361	test: 0.814670
PRC train: 0.878940	val: 0.572305	test: 0.628691

Epoch: 38
Loss: 0.13115386933358003
ROC train: 0.973611	val: 0.703924	test: 0.815704
PRC train: 0.884874	val: 0.580215	test: 0.632508

Epoch: 39
Loss: 0.13688149505181507
ROC train: 0.976144	val: 0.707850	test: 0.813942
PRC train: 0.887119	val: 0.576989	test: 0.636028

Epoch: 40
Loss: 0.14278382746819993
ROC train: 0.978853	val: 0.689045	test: 0.819608
PRC train: 0.893163	val: 0.568589	test: 0.636524

Epoch: 41
Loss: 0.13255725413269429
ROC train: 0.980020	val: 0.673671	test: 0.812551
PRC train: 0.903742	val: 0.565889	test: 0.621333

Epoch: 42
Loss: 0.14050157951774256
ROC train: 0.974658	val: 0.690352	test: 0.799063
PRC train: 0.896168	val: 0.564122	test: 0.601140

Epoch: 43
Loss: 0.13427834614106202
ROC train: 0.974817	val: 0.668649	test: 0.791465
PRC train: 0.886055	val: 0.550154	test: 0.604526

Epoch: 44
Loss: 0.13511138099102918
ROC train: 0.977737	val: 0.682856	test: 0.792645
PRC train: 0.889275	val: 0.552716	test: 0.630343

Epoch: 45
Loss: 0.1336663499725607
ROC train: 0.980858	val: 0.685607	test: 0.808753
PRC train: 0.897913	val: 0.565517	test: 0.636252

Epoch: 46
Loss: 0.12317153658988417
ROC train: 0.979871	val: 0.685834	test: 0.818903
PRC train: 0.903674	val: 0.572322	test: 0.619237

Epoch: 47
Loss: 0.13336353757394975
ROC train: 0.978877	val: 0.690700	test: 0.823779
PRC train: 0.904360	val: 0.571547	test: 0.617576

Epoch: 48
Loss: 0.12452137408681227
ROC train: 0.981275	val: 0.681428	test: 0.827087
PRC train: 0.912324	val: 0.570248	test: 0.623215

Epoch: 49
Loss: 0.11867147052718459
ROC train: 0.983730	val: 0.687066	test: 0.806799
PRC train: 0.918834	val: 0.584609	test: 0.633281

Epoch: 50
Loss: 0.12703175056132723
ROC train: 0.983795	val: 0.705140	test: 0.787158
PRC train: 0.914748	val: 0.592140	test: 0.608210

Epoch: 51
Loss: 0.12180326488889807
ROC train: 0.982723	val: 0.705994	test: 0.794965
PRC train: 0.916742	val: 0.579967	test: 0.604760

Epoch: 52
Loss: 0.12152411496176442
ROC train: 0.980382	val: 0.706546	test: 0.798697
PRC train: 0.909968	val: 0.576549	test: 0.602160

Epoch: 53
Loss: 0.12436392344658351
ROC train: 0.980904	val: 0.714911	test: 0.795467
PRC train: 0.905426	val: 0.580358	test: 0.600159

Epoch: 54
Loss: 0.10861104821258638
ROC train: 0.983488	val: 0.714974	test: 0.803714
PRC train: 0.915907	val: 0.578084	test: 0.611035

Epoch: 55
Loss: 0.12018209533696486
ROC train: 0.985006	val: 0.701797	test: 0.795608
PRC train: 0.917046	val: 0.579843	test: 0.621214

Epoch: 56
Loss: 0.10837409970897202
ROC train: 0.982448	val: 0.707780	test: 0.772464
PRC train: 0.907064	val: 0.585273	test: 0.594472

Epoch: 57
Loss: 0.11352981855436017
ROC train: 0.984532	val: 0.687286	test: 0.791078
PRC train: 0.923167	val: 0.567896	test: 0.599973

Epoch: 58
Loss: 0.10710756651755692
ROC train: 0.986488	val: 0.688221	test: 0.801694
PRC train: 0.936569	val: 0.579093	test: 0.611481

Epoch: 59
Loss: 0.10721609889843242
ROC train: 0.980924	val: 0.690575	test: 0.795666
PRC train: 0.918525	val: 0.587220	test: 0.612570

Epoch: 60
Loss: 0.10719835853194508
ROC train: 0.985083	val: 0.692029	test: 0.800787
PRC train: 0.927529	val: 0.578512	test: 0.620068

Epoch: 61
Loss: 0.11055889091915394
ROC train: 0.984790	val: 0.692982	test: 0.812611
PRC train: 0.925725	val: 0.568365	test: 0.624021

Epoch: 62
Loss: 0.10722951748518013
ROC train: 0.987053	val: 0.696931	test: 0.812569
PRC train: 0.939435	val: 0.570658	test: 0.624418

Epoch: 63
Loss: 0.09400493154939071
ROC train: 0.986858	val: 0.720080	test: 0.802427
PRC train: 0.936348	val: 0.573500	test: 0.621037

Epoch: 64
Loss: 0.11111985205446956
ROC train: 0.988182	val: 0.718935	test: 0.805188
PRC train: 0.939880	val: 0.576553	test: 0.618008

Epoch: 65
Loss: 0.11080325797254398
ROC train: 0.988860	val: 0.712248	test: 0.792232
PRC train: 0.941548	val: 0.579156	test: 0.610413

Epoch: 66
Loss: 0.10968251536252752
ROC train: 0.987258	val: 0.728785	test: 0.774192
PRC train: 0.926396	val: 0.585471	test: 0.608790

Epoch: 67
Loss: 0.10511473472983443
ROC train: 0.987290	val: 0.732622	test: 0.778559
PRC train: 0.929218	val: 0.595486	test: 0.604182

Epoch: 68
Loss: 0.08751341810307108
ROC train: 0.990063	val: 0.734351	test: 0.818903
PRC train: 0.943841	val: 0.588658	test: 0.609161

Epoch: 69
Loss: 0.10727689350119148
ROC train: 0.989834	val: 0.710506	test: 0.831013
PRC train: 0.948815	val: 0.578763	test: 0.632181

Epoch: 70
Loss: 0.1073407631500626
ROC train: 0.989413	val: 0.698082	test: 0.816446
PRC train: 0.943451	val: 0.584614	test: 0.625364

Epoch: 71
Loss: 0.104873826313716
ROC train: 0.990099	val: 0.709744	test: 0.795970
PRC train: 0.942442	val: 0.602869	test: 0.605072

Epoch: 72
Loss: 0.09991891468223235
ROC train: 0.990535	val: 0.684560	test: 0.809885
PRC train: 0.941671	val: 0.585559	test: 0.622949

Epoch: 73
Loss: 0.10131144853406562
ROC train: 0.988630	val: 0.679611	test: 0.817678
PRC train: 0.934936	val: 0.569994	test: 0.633895

Epoch: 74
Loss: 0.09899273416868631
ROC train: 0.990829	val: 0.703489	test: 0.810878
PRC train: 0.943197	val: 0.584263	test: 0.619513

Epoch: 75
Loss: 0.09511820897587484
ROC train: 0.990297	val: 0.702480	test: 0.799969
PRC train: 0.943890	val: 0.595498	test: 0.600078

Epoch: 76
Loss: 0.10928095662035503
ROC train: 0.989255	val: 0.714133	test: 0.790828
PRC train: 0.944385	val: 0.587837	test: 0.604421

Epoch: 77
Loss: 0.10008526131007686
ROC train: 0.986457	val: 0.707347	test: 0.790046
PRC train: 0.928718	val: 0.569464	test: 0.631179

Epoch: 78
Loss: 0.09934118983020014
ROC train: 0.986637	val: 0.704857	test: 0.799461
PRC train: 0.930207	val: 0.558485	test: 0.627252

Epoch: 79
Loss: 0.08759011774426978
ROC train: 0.989431	val: 0.695328	test: 0.802197
PRC train: 0.936860	val: 0.562794	test: 0.619644

Epoch: 80
Loss: 0.10119430261819282
ROC train: 0.990453	val: 0.690902	test: 0.800323
PRC train: 0.948174	val: 0.575261	test: 0.610955

Epoch: 81
Loss: 0.09722618198618593
ROC train: 0.989432	val: 0.694861	test: 0.812043
PRC train: 0.941051	val: 0.586955	test: 0.614467

Epoch: 82
Loss: 0.09623431132286828
ROC train: 0.991201	val: 0.714307	test: 0.806203
PRC train: 0.955486	val: 0.602462	test: 0.611692

Epoch: 83
Loss: 0.09845104549716929
ROC train: 0.988418	val: 0.732000	test: 0.786015
PRC train: 0.930546	val: 0.592773	test: 0.609242

Epoch: 84
Loss: 0.08884575193998501
ROC train: 0.989541	val: 0.736806	test: 0.784162
PRC train: 0.936119	val: 0.578792	test: 0.597146

Epoch: 85
Loss: 0.10678496226135824
ROC train: 0.990681	val: 0.715817	test: 0.814607
PRC train: 0.943576	val: 0.573244	test: 0.613664

Epoch: 86
Loss: 0.10439197550680265
ROC train: 0.991134	val: 0.731743	test: 0.821696
PRC train: 0.945929	val: 0.577854	test: 0.629840

Epoch: 87
Loss: 0.08604327199983675
ROC train: 0.991162	val: 0.753230	test: 0.809033
PRC train: 0.949157	val: 0.589982	test: 0.622840

Epoch: 88
Loss: 0.09878469384512889
ROC train: 0.991070	val: 0.743913	test: 0.802540
PRC train: 0.951496	val: 0.603473	test: 0.610838

Epoch: 89
Loss: 0.09753227058904393
ROC train: 0.992032	val: 0.719373	test: 0.808886
PRC train: 0.958842	val: 0.596527	test: 0.619258

Epoch: 90
Loss: 0.0830381970324849
ROC train: 0.992366	val: 0.707178	test: 0.812315
PRC train: 0.959683	val: 0.592524	test: 0.621933

Epoch: 91
Loss: 0.08155465552452656
ROC train: 0.992673	val: 0.690829	test: 0.821411
PRC train: 0.960912	val: 0.578405	test: 0.621568

Epoch: 92
Loss: 0.08981701690751939
ROC train: 0.992469	val: 0.687318	test: 0.823292
PRC train: 0.958638	val: 0.578172	test: 0.640173

Epoch: 93
Loss: 0.07655335137977534
ROC train: 0.991936	val: 0.682198	test: 0.815917
PRC train: 0.958814	val: 0.578255	test: 0.627939

ROC train: 0.967666	val: 0.708187	test: 0.782212
PRC train: 0.854677	val: 0.582558	test: 0.604032

Epoch: 34
Loss: 0.16077569471610795
ROC train: 0.966803	val: 0.695791	test: 0.815289
PRC train: 0.862961	val: 0.560902	test: 0.627264

Epoch: 35
Loss: 0.1447953771174198
ROC train: 0.968079	val: 0.708458	test: 0.807688
PRC train: 0.874883	val: 0.570070	test: 0.614843

Epoch: 36
Loss: 0.14050172359685914
ROC train: 0.971099	val: 0.716955	test: 0.795796
PRC train: 0.866538	val: 0.582655	test: 0.590923

Epoch: 37
Loss: 0.14833619249050017
ROC train: 0.970176	val: 0.727259	test: 0.787968
PRC train: 0.863126	val: 0.585518	test: 0.583468

Epoch: 38
Loss: 0.13178827838882343
ROC train: 0.971242	val: 0.721873	test: 0.805385
PRC train: 0.873794	val: 0.577175	test: 0.596795

Epoch: 39
Loss: 0.13545444119788164
ROC train: 0.965759	val: 0.727905	test: 0.789096
PRC train: 0.879887	val: 0.570771	test: 0.588032

Epoch: 40
Loss: 0.13905372716495834
ROC train: 0.964286	val: 0.680971	test: 0.795861
PRC train: 0.869791	val: 0.555369	test: 0.594186

Epoch: 41
Loss: 0.13843699923604375
ROC train: 0.968544	val: 0.645758	test: 0.822786
PRC train: 0.876074	val: 0.552007	test: 0.630574

Epoch: 42
Loss: 0.13171166706367382
ROC train: 0.975626	val: 0.651588	test: 0.822188
PRC train: 0.898371	val: 0.554466	test: 0.630559

Epoch: 43
Loss: 0.12917452142013142
ROC train: 0.964392	val: 0.665949	test: 0.790882
PRC train: 0.868056	val: 0.563911	test: 0.629888

Epoch: 44
Loss: 0.12523624850709245
ROC train: 0.961029	val: 0.684973	test: 0.759744
PRC train: 0.863811	val: 0.577702	test: 0.617485

Epoch: 45
Loss: 0.12435979520311874
ROC train: 0.969364	val: 0.706014	test: 0.763460
PRC train: 0.887638	val: 0.569200	test: 0.611262

Epoch: 46
Loss: 0.13534405185638965
ROC train: 0.971835	val: 0.691122	test: 0.804834
PRC train: 0.892350	val: 0.561493	test: 0.648423

Epoch: 47
Loss: 0.12672874210005805
ROC train: 0.972570	val: 0.686797	test: 0.817905
PRC train: 0.896704	val: 0.561912	test: 0.637833

Epoch: 48
Loss: 0.12072086060058064
ROC train: 0.981774	val: 0.712459	test: 0.816355
PRC train: 0.914191	val: 0.571198	test: 0.616796

Epoch: 49
Loss: 0.11507425913023098
ROC train: 0.981817	val: 0.729514	test: 0.813893
PRC train: 0.905042	val: 0.577803	test: 0.609140

Epoch: 50
Loss: 0.1190382269140107
ROC train: 0.980809	val: 0.710169	test: 0.822162
PRC train: 0.903076	val: 0.566900	test: 0.629116

Epoch: 51
Loss: 0.11219224767188381
ROC train: 0.981519	val: 0.711314	test: 0.827488
PRC train: 0.905435	val: 0.574395	test: 0.621332

Epoch: 52
Loss: 0.11891397622105257
ROC train: 0.981475	val: 0.721655	test: 0.802926
PRC train: 0.910470	val: 0.579721	test: 0.600372

Epoch: 53
Loss: 0.11077072827426704
ROC train: 0.983140	val: 0.714144	test: 0.804988
PRC train: 0.932299	val: 0.573812	test: 0.605404

Epoch: 54
Loss: 0.11152306040204425
ROC train: 0.979969	val: 0.679449	test: 0.816316
PRC train: 0.926958	val: 0.560826	test: 0.623059

Epoch: 55
Loss: 0.10206166529654774
ROC train: 0.981627	val: 0.687232	test: 0.817299
PRC train: 0.925463	val: 0.562520	test: 0.618042

Epoch: 56
Loss: 0.10499051493399361
ROC train: 0.983029	val: 0.725868	test: 0.801685
PRC train: 0.920434	val: 0.582712	test: 0.601219

Epoch: 57
Loss: 0.12274879612801108
ROC train: 0.986323	val: 0.730141	test: 0.805427
PRC train: 0.923963	val: 0.582854	test: 0.606695

Epoch: 58
Loss: 0.11109787042869179
ROC train: 0.986094	val: 0.717960	test: 0.806175
PRC train: 0.926764	val: 0.573990	test: 0.613290

Epoch: 59
Loss: 0.10564612984110094
ROC train: 0.981215	val: 0.693771	test: 0.803433
PRC train: 0.914204	val: 0.576286	test: 0.599651

Epoch: 60
Loss: 0.10979885787691357
ROC train: 0.980487	val: 0.683665	test: 0.796022
PRC train: 0.919346	val: 0.568486	test: 0.616744

Epoch: 61
Loss: 0.09902159012480685
ROC train: 0.983871	val: 0.694033	test: 0.802143
PRC train: 0.929879	val: 0.576508	test: 0.625555

Epoch: 62
Loss: 0.10453912325251026
ROC train: 0.983668	val: 0.704348	test: 0.816390
PRC train: 0.927928	val: 0.575675	test: 0.618767

Epoch: 63
Loss: 0.12594094587864324
ROC train: 0.987846	val: 0.723707	test: 0.818074
PRC train: 0.942830	val: 0.581668	test: 0.607652

Epoch: 64
Loss: 0.10412507434047374
ROC train: 0.989760	val: 0.720320	test: 0.823614
PRC train: 0.948960	val: 0.579407	test: 0.616916

Epoch: 65
Loss: 0.10006271388737557
ROC train: 0.986596	val: 0.708413	test: 0.813312
PRC train: 0.926453	val: 0.577897	test: 0.612354

Epoch: 66
Loss: 0.10873971361288351
ROC train: 0.988319	val: 0.698732	test: 0.825378
PRC train: 0.939994	val: 0.562849	test: 0.631187

Epoch: 67
Loss: 0.11233431506711951
ROC train: 0.991077	val: 0.706901	test: 0.817444
PRC train: 0.946971	val: 0.564873	test: 0.619327

Epoch: 68
Loss: 0.1006294515898948
ROC train: 0.990807	val: 0.709360	test: 0.818741
PRC train: 0.949083	val: 0.570603	test: 0.616006

Epoch: 69
Loss: 0.11620506542262568
ROC train: 0.990385	val: 0.704566	test: 0.821147
PRC train: 0.950727	val: 0.564947	test: 0.619997

Epoch: 70
Loss: 0.09351254554408227
ROC train: 0.988824	val: 0.734414	test: 0.797767
PRC train: 0.944471	val: 0.579875	test: 0.596978

Epoch: 71
Loss: 0.10401535761318836
ROC train: 0.990587	val: 0.722798	test: 0.815733
PRC train: 0.950432	val: 0.575235	test: 0.612403

Epoch: 72
Loss: 0.0960896359002028
ROC train: 0.990576	val: 0.698355	test: 0.836130
PRC train: 0.950604	val: 0.564310	test: 0.636579

Epoch: 73
Loss: 0.0845871497399996
ROC train: 0.990488	val: 0.690643	test: 0.832563
PRC train: 0.947154	val: 0.561245	test: 0.636801

Epoch: 74
Loss: 0.10294205763688294
ROC train: 0.989712	val: 0.668978	test: 0.826914
PRC train: 0.940729	val: 0.562539	test: 0.634313

Epoch: 75
Loss: 0.0955509788702916
ROC train: 0.990203	val: 0.672772	test: 0.819281
PRC train: 0.945960	val: 0.565377	test: 0.626058

Epoch: 76
Loss: 0.09422676800370577
ROC train: 0.990802	val: 0.676244	test: 0.831225
PRC train: 0.950160	val: 0.565675	test: 0.633127

Epoch: 77
Loss: 0.10549019061276804
ROC train: 0.991284	val: 0.677886	test: 0.833333
PRC train: 0.952553	val: 0.560494	test: 0.637512

Epoch: 78
Loss: 0.1056031561114868
ROC train: 0.990055	val: 0.670520	test: 0.832804
PRC train: 0.945859	val: 0.559731	test: 0.655087

Epoch: 79
Loss: 0.08771453635145025
ROC train: 0.991914	val: 0.696964	test: 0.826133
PRC train: 0.948773	val: 0.569853	test: 0.633290

Epoch: 80
Loss: 0.09509029492753732
ROC train: 0.992420	val: 0.694583	test: 0.819889
PRC train: 0.952842	val: 0.565863	test: 0.625689

Epoch: 81
Loss: 0.08926143152809499
ROC train: 0.993015	val: 0.698445	test: 0.808499
PRC train: 0.956337	val: 0.565813	test: 0.631741

Epoch: 82
Loss: 0.09669861820059303
ROC train: 0.990342	val: 0.692785	test: 0.820528
PRC train: 0.946566	val: 0.567694	test: 0.633014

Epoch: 83
Loss: 0.10398848138404937
ROC train: 0.990390	val: 0.679728	test: 0.834627
PRC train: 0.943349	val: 0.565965	test: 0.648492

Epoch: 84
Loss: 0.0736279212797512
ROC train: 0.989537	val: 0.688523	test: 0.828744
PRC train: 0.934800	val: 0.560489	test: 0.647493

Epoch: 85
Loss: 0.09425024055681566
ROC train: 0.991218	val: 0.711782	test: 0.822811
PRC train: 0.947068	val: 0.578239	test: 0.623370

Epoch: 86
Loss: 0.09204209157962319
ROC train: 0.990308	val: 0.701007	test: 0.835164
PRC train: 0.951794	val: 0.575513	test: 0.633654

Epoch: 87
Loss: 0.10045834766131854
ROC train: 0.989143	val: 0.688966	test: 0.832627
PRC train: 0.945774	val: 0.573531	test: 0.623839

Epoch: 88
Loss: 0.09682351705034527
ROC train: 0.992378	val: 0.711809	test: 0.817234
PRC train: 0.961488	val: 0.578298	test: 0.609234

Epoch: 89
Loss: 0.08769193682831312
ROC train: 0.992247	val: 0.724507	test: 0.813074
PRC train: 0.959057	val: 0.584305	test: 0.608061

Epoch: 90
Loss: 0.09871588383216337
ROC train: 0.988726	val: 0.699647	test: 0.827304
PRC train: 0.943393	val: 0.567727	test: 0.621974

Epoch: 91
Loss: 0.09015536682562789
ROC train: 0.992593	val: 0.699227	test: 0.819577
PRC train: 0.955909	val: 0.571911	test: 0.616966

Epoch: 92
Loss: 0.09230025374549608
ROC train: 0.992487	val: 0.694784	test: 0.811058
PRC train: 0.958286	val: 0.569744	test: 0.606605

Epoch: 93
Loss: 0.08072024522683612
ROC train: 0.992929	val: 0.688489	test: 0.816526
PRC train: 0.961613	val: 0.562711	test: 0.614347

Epoch: 94
Loss: 0.0967675034058371
ROC train: 0.960333	val: 0.682344	test: 0.797816
PRC train: 0.849642	val: 0.552681	test: 0.636891

Epoch: 34
Loss: 0.16509463336784963
ROC train: 0.961305	val: 0.668261	test: 0.807175
PRC train: 0.840142	val: 0.550455	test: 0.650131

Epoch: 35
Loss: 0.15393913596406333
ROC train: 0.952125	val: 0.662424	test: 0.807903
PRC train: 0.843974	val: 0.558130	test: 0.653845

Epoch: 36
Loss: 0.14426243717380538
ROC train: 0.963992	val: 0.688622	test: 0.775482
PRC train: 0.870469	val: 0.574150	test: 0.635703

Epoch: 37
Loss: 0.14269865653831848
ROC train: 0.969063	val: 0.689578	test: 0.757559
PRC train: 0.877056	val: 0.558947	test: 0.639876

Epoch: 38
Loss: 0.13862282561595396
ROC train: 0.969137	val: 0.675950	test: 0.770903
PRC train: 0.878993	val: 0.553934	test: 0.645959

Epoch: 39
Loss: 0.14568175002939174
ROC train: 0.970657	val: 0.674355	test: 0.761655
PRC train: 0.876160	val: 0.561238	test: 0.624398

Epoch: 40
Loss: 0.14225655246150584
ROC train: 0.969912	val: 0.686211	test: 0.754122
PRC train: 0.855499	val: 0.567984	test: 0.612270

Epoch: 41
Loss: 0.12442273647459193
ROC train: 0.973075	val: 0.703886	test: 0.776765
PRC train: 0.874927	val: 0.571471	test: 0.643633

Epoch: 42
Loss: 0.13828970499260737
ROC train: 0.974279	val: 0.709149	test: 0.797647
PRC train: 0.885291	val: 0.563592	test: 0.659150

Epoch: 43
Loss: 0.1219849630121629
ROC train: 0.978378	val: 0.704978	test: 0.804465
PRC train: 0.901798	val: 0.569940	test: 0.659728

Epoch: 44
Loss: 0.11892866199146718
ROC train: 0.978210	val: 0.702514	test: 0.802465
PRC train: 0.902967	val: 0.573352	test: 0.646574

Epoch: 45
Loss: 0.13239584768506318
ROC train: 0.971746	val: 0.665986	test: 0.814370
PRC train: 0.891070	val: 0.556260	test: 0.647428

Epoch: 46
Loss: 0.11855100816096446
ROC train: 0.973012	val: 0.643199	test: 0.812299
PRC train: 0.889151	val: 0.547732	test: 0.644578

Epoch: 47
Loss: 0.13918175645749112
ROC train: 0.979074	val: 0.678476	test: 0.787610
PRC train: 0.899871	val: 0.555977	test: 0.627205

Epoch: 48
Loss: 0.1344713147143364
ROC train: 0.981735	val: 0.700146	test: 0.792964
PRC train: 0.906157	val: 0.562518	test: 0.635474

Epoch: 49
Loss: 0.12373234234636568
ROC train: 0.982753	val: 0.723971	test: 0.797016
PRC train: 0.907065	val: 0.574994	test: 0.634419

Epoch: 50
Loss: 0.11585763285299201
ROC train: 0.980881	val: 0.712629	test: 0.791698
PRC train: 0.910600	val: 0.576640	test: 0.636164

Epoch: 51
Loss: 0.1209990302929154
ROC train: 0.977921	val: 0.726961	test: 0.795967
PRC train: 0.910281	val: 0.575895	test: 0.640447

Epoch: 52
Loss: 0.11807682562912977
ROC train: 0.973799	val: 0.708980	test: 0.785374
PRC train: 0.898263	val: 0.562811	test: 0.643334

Epoch: 53
Loss: 0.10512139566173657
ROC train: 0.979397	val: 0.687099	test: 0.778962
PRC train: 0.907291	val: 0.558885	test: 0.636794

Epoch: 54
Loss: 0.11371238840063608
ROC train: 0.982111	val: 0.703170	test: 0.780886
PRC train: 0.919801	val: 0.562266	test: 0.622219

Epoch: 55
Loss: 0.11514034159199937
ROC train: 0.981551	val: 0.707178	test: 0.782318
PRC train: 0.912475	val: 0.560245	test: 0.629186

Epoch: 56
Loss: 0.11552185072960452
ROC train: 0.983579	val: 0.687012	test: 0.786776
PRC train: 0.919718	val: 0.554656	test: 0.637460

Epoch: 57
Loss: 0.1110995810757809
ROC train: 0.982629	val: 0.668646	test: 0.765167
PRC train: 0.913111	val: 0.557096	test: 0.616511

Epoch: 58
Loss: 0.11658102040273455
ROC train: 0.985645	val: 0.689105	test: 0.780187
PRC train: 0.932058	val: 0.562408	test: 0.623895

Epoch: 59
Loss: 0.11055851010935405
ROC train: 0.985447	val: 0.683436	test: 0.814440
PRC train: 0.934880	val: 0.561059	test: 0.642877

Epoch: 60
Loss: 0.09772718493711649
ROC train: 0.985272	val: 0.702203	test: 0.804999
PRC train: 0.936409	val: 0.563808	test: 0.647703

Epoch: 61
Loss: 0.11264508521227344
ROC train: 0.988758	val: 0.724196	test: 0.804535
PRC train: 0.946076	val: 0.570594	test: 0.656349

Epoch: 62
Loss: 0.1130686671095327
ROC train: 0.987836	val: 0.730965	test: 0.800746
PRC train: 0.944046	val: 0.585093	test: 0.642571

Epoch: 63
Loss: 0.1044241370604922
ROC train: 0.982225	val: 0.717990	test: 0.795598
PRC train: 0.923863	val: 0.581581	test: 0.612865

Epoch: 64
Loss: 0.11317363465053487
ROC train: 0.978485	val: 0.690764	test: 0.806529
PRC train: 0.910154	val: 0.583967	test: 0.615407

Epoch: 65
Loss: 0.11143256244849019
ROC train: 0.976643	val: 0.667403	test: 0.827539
PRC train: 0.896593	val: 0.572974	test: 0.625330

Epoch: 66
Loss: 0.11533205563661306
ROC train: 0.978847	val: 0.687239	test: 0.812014
PRC train: 0.888698	val: 0.572492	test: 0.634234

Epoch: 67
Loss: 0.11033883855719909
ROC train: 0.982483	val: 0.689789	test: 0.800367
PRC train: 0.908810	val: 0.570749	test: 0.632453

Epoch: 68
Loss: 0.09836585349391984
ROC train: 0.989007	val: 0.694546	test: 0.784125
PRC train: 0.940466	val: 0.556359	test: 0.614798

Epoch: 69
Loss: 0.10622255791627075
ROC train: 0.987898	val: 0.725231	test: 0.776480
PRC train: 0.943161	val: 0.565990	test: 0.624620

Epoch: 70
Loss: 0.08951742968001769
ROC train: 0.985288	val: 0.749875	test: 0.777921
PRC train: 0.931420	val: 0.570731	test: 0.632931

Epoch: 71
Loss: 0.11520294577826606
ROC train: 0.986832	val: 0.750030	test: 0.794805
PRC train: 0.941801	val: 0.574587	test: 0.638877

Epoch: 72
Loss: 0.10120317919587112
ROC train: 0.985358	val: 0.744200	test: 0.764828
PRC train: 0.927819	val: 0.586788	test: 0.618767

Epoch: 73
Loss: 0.09052723425836097
ROC train: 0.987827	val: 0.735939	test: 0.775088
PRC train: 0.938808	val: 0.580492	test: 0.619557

Epoch: 74
Loss: 0.09792577513928517
ROC train: 0.989537	val: 0.731972	test: 0.802073
PRC train: 0.945974	val: 0.584175	test: 0.638271

Epoch: 75
Loss: 0.10464639017790417
ROC train: 0.987930	val: 0.707426	test: 0.815223
PRC train: 0.937007	val: 0.576296	test: 0.649462

Epoch: 76
Loss: 0.09259498098957875
ROC train: 0.990504	val: 0.719868	test: 0.809814
PRC train: 0.942757	val: 0.578441	test: 0.644375

Epoch: 77
Loss: 0.09997590605045098
ROC train: 0.987826	val: 0.734782	test: 0.801307
PRC train: 0.938108	val: 0.584011	test: 0.648485

Epoch: 78
Loss: 0.09896375867668508
ROC train: 0.989585	val: 0.742915	test: 0.799812
PRC train: 0.937124	val: 0.586637	test: 0.637934

Epoch: 79
Loss: 0.10233529700212213
ROC train: 0.986300	val: 0.728369	test: 0.787159
PRC train: 0.929482	val: 0.585964	test: 0.621092

Epoch: 80
Loss: 0.09872312918539133
ROC train: 0.988843	val: 0.712160	test: 0.796454
PRC train: 0.941700	val: 0.583168	test: 0.626785

Epoch: 81
Loss: 0.10448680190735739
ROC train: 0.991140	val: 0.701934	test: 0.805394
PRC train: 0.944523	val: 0.576333	test: 0.637859

Epoch: 82
Loss: 0.09335759426718257
ROC train: 0.990016	val: 0.702457	test: 0.799954
PRC train: 0.931972	val: 0.576312	test: 0.639262

Epoch: 83
Loss: 0.07793543198385634
ROC train: 0.990050	val: 0.694900	test: 0.814117
PRC train: 0.929851	val: 0.580158	test: 0.636695

Epoch: 84
Loss: 0.10121215912283651
ROC train: 0.990694	val: 0.679629	test: 0.819567
PRC train: 0.941914	val: 0.569896	test: 0.639406

Epoch: 85
Loss: 0.08813307949253009
ROC train: 0.989982	val: 0.671022	test: 0.815097
PRC train: 0.947233	val: 0.565903	test: 0.629848

Epoch: 86
Loss: 0.0958885898455738
ROC train: 0.991611	val: 0.706927	test: 0.777112
PRC train: 0.949600	val: 0.572054	test: 0.621129

Epoch: 87
Loss: 0.09675003355057504
ROC train: 0.991102	val: 0.712387	test: 0.767214
PRC train: 0.951261	val: 0.573527	test: 0.616548

Epoch: 88
Loss: 0.08659691948014168
ROC train: 0.990598	val: 0.688691	test: 0.789830
PRC train: 0.951411	val: 0.563647	test: 0.635365

Epoch: 89
Loss: 0.0985201583821615
ROC train: 0.989992	val: 0.700455	test: 0.781324
PRC train: 0.946474	val: 0.569221	test: 0.619629

Epoch: 90
Loss: 0.09966699837988917
ROC train: 0.991244	val: 0.695071	test: 0.773586
PRC train: 0.955227	val: 0.583792	test: 0.617234

Epoch: 91
Loss: 0.09174527512241973
ROC train: 0.992531	val: 0.682385	test: 0.789763
PRC train: 0.957718	val: 0.572374	test: 0.635765

Epoch: 92
Loss: 0.09574747366365896
ROC train: 0.992500	val: 0.671981	test: 0.787220
PRC train: 0.957312	val: 0.565801	test: 0.654202

Epoch: 93
Loss: 0.09525272775762167
ROC train: 0.992839	val: 0.675635	test: 0.780298
PRC train: 0.957362	val: 0.566480	test: 0.629952

Epoch: 94
Loss: 0.09757578345999915
ROC train: 0.911126	val: 0.610805	test: 0.846471
PRC train: 0.727284	val: 0.535949	test: 0.614061

Epoch: 34
Loss: 0.15902997157780346
ROC train: 0.899947	val: 0.637728	test: 0.790380
PRC train: 0.721061	val: 0.548092	test: 0.576750

Epoch: 35
Loss: 0.16222429220898077
ROC train: 0.926116	val: 0.641851	test: 0.853360
PRC train: 0.762159	val: 0.549758	test: 0.607987

Epoch: 36
Loss: 0.15605633374109734
ROC train: 0.913342	val: 0.627398	test: 0.872127
PRC train: 0.763357	val: 0.549262	test: 0.637634

Epoch: 37
Loss: 0.24395539628490343
ROC train: 0.920658	val: 0.635209	test: 0.868292
PRC train: 0.772512	val: 0.548834	test: 0.628362

Epoch: 38
Loss: 0.15769416538093317
ROC train: 0.905465	val: 0.634648	test: 0.855150
PRC train: 0.757651	val: 0.554846	test: 0.599952

Epoch: 39
Loss: 0.15527082411329005
ROC train: 0.918941	val: 0.629982	test: 0.868166
PRC train: 0.769657	val: 0.551462	test: 0.609031

Epoch: 40
Loss: 0.18812300420080827
ROC train: 0.931180	val: 0.631448	test: 0.891815
PRC train: 0.786196	val: 0.546360	test: 0.657773

Epoch: 41
Loss: 0.26631095787480674
ROC train: 0.911584	val: 0.606904	test: 0.879595
PRC train: 0.763388	val: 0.536235	test: 0.652782

Epoch: 42
Loss: 0.25059896243285795
ROC train: 0.885320	val: 0.592744	test: 0.857168
PRC train: 0.711825	val: 0.528140	test: 0.620152

Epoch: 43
Loss: 0.29292365887655736
ROC train: 0.849637	val: 0.570960	test: 0.838961
PRC train: 0.643079	val: 0.529443	test: 0.625970

Epoch: 44
Loss: 0.3377580522025521
ROC train: 0.878572	val: 0.561583	test: 0.820985
PRC train: 0.707241	val: 0.543109	test: 0.592443

Epoch: 45
Loss: 0.1770589630545656
ROC train: 0.839044	val: 0.574968	test: 0.766434
PRC train: 0.649215	val: 0.531458	test: 0.572035

Epoch: 46
Loss: 0.16600812037304208
ROC train: 0.868795	val: 0.579731	test: 0.790739
PRC train: 0.689972	val: 0.533956	test: 0.577064

Epoch: 47
Loss: 0.17170019598893355
ROC train: 0.905318	val: 0.584309	test: 0.833631
PRC train: 0.733146	val: 0.544433	test: 0.606544

Epoch: 48
Loss: 0.19678668235729563
ROC train: 0.912642	val: 0.585422	test: 0.849504
PRC train: 0.744599	val: 0.544793	test: 0.629779

Epoch: 49
Loss: 0.19530750907350605
ROC train: 0.907645	val: 0.588347	test: 0.844254
PRC train: 0.740716	val: 0.540945	test: 0.633624

Epoch: 50
Loss: 0.17788554000419457
ROC train: 0.911791	val: 0.596409	test: 0.823867
PRC train: 0.744101	val: 0.545761	test: 0.628263

Epoch: 51
Loss: 0.2233733395627931
ROC train: 0.912969	val: 0.589357	test: 0.832787
PRC train: 0.756168	val: 0.548121	test: 0.628544

Epoch: 52
Loss: 0.1657555209914755
ROC train: 0.874561	val: 0.594813	test: 0.849666
PRC train: 0.719422	val: 0.541380	test: 0.631018

Epoch: 53
Loss: 0.16035090775846655
ROC train: 0.902537	val: 0.601009	test: 0.873582
PRC train: 0.735422	val: 0.549516	test: 0.656375

Epoch: 54
Loss: 0.15819504327712755
ROC train: 0.925679	val: 0.604648	test: 0.882588
PRC train: 0.763756	val: 0.551005	test: 0.654869

Epoch: 55
Loss: 0.14634750751789496
ROC train: 0.924784	val: 0.609909	test: 0.881135
PRC train: 0.766406	val: 0.547687	test: 0.650601

Epoch: 56
Loss: 0.14409006545819522
ROC train: 0.930248	val: 0.602271	test: 0.877054
PRC train: 0.778830	val: 0.548294	test: 0.648195

Epoch: 57
Loss: 0.14688247291987538
ROC train: 0.937625	val: 0.601759	test: 0.884296
PRC train: 0.790946	val: 0.552129	test: 0.666916

Epoch: 58
Loss: 0.1344121424195201
ROC train: 0.941632	val: 0.602075	test: 0.888771
PRC train: 0.797486	val: 0.557589	test: 0.663293

Epoch: 59
Loss: 0.18444274394255034
ROC train: 0.940920	val: 0.604411	test: 0.890822
PRC train: 0.796172	val: 0.574032	test: 0.671502

Epoch: 60
Loss: 0.15392936579593114
ROC train: 0.918662	val: 0.596096	test: 0.889658
PRC train: 0.755984	val: 0.555073	test: 0.735754

Epoch: 61
Loss: 0.14093421784564586
ROC train: 0.935762	val: 0.602704	test: 0.889722
PRC train: 0.785615	val: 0.559386	test: 0.684444

Epoch: 62
Loss: 0.1654828234934019
ROC train: 0.936392	val: 0.609371	test: 0.867910
PRC train: 0.786855	val: 0.564296	test: 0.664412

Epoch: 63
Loss: 0.13861875719925706
ROC train: 0.948080	val: 0.608495	test: 0.879382
PRC train: 0.807522	val: 0.577644	test: 0.673320

Epoch: 64
Loss: 0.1681889354704605
ROC train: 0.940951	val: 0.608978	test: 0.877058
PRC train: 0.803786	val: 0.572460	test: 0.661937

Epoch: 65
Loss: 0.14518242324489897
ROC train: 0.930849	val: 0.609280	test: 0.866403
PRC train: 0.782611	val: 0.567167	test: 0.649635

Epoch: 66
Loss: 0.15181217089859078
ROC train: 0.932094	val: 0.611886	test: 0.855331
PRC train: 0.787599	val: 0.555910	test: 0.654310

Epoch: 67
Loss: 0.18441877210700414
ROC train: 0.933821	val: 0.633701	test: 0.852998
PRC train: 0.791766	val: 0.557032	test: 0.653193

Epoch: 68
Loss: 0.15412163109261887
ROC train: 0.942885	val: 0.634730	test: 0.871168
PRC train: 0.807628	val: 0.551294	test: 0.627651

Epoch: 69
Loss: 0.12979693262069497
ROC train: 0.946658	val: 0.642661	test: 0.886417
PRC train: 0.811667	val: 0.558675	test: 0.640155

Epoch: 70
Loss: 0.17541032914219967
ROC train: 0.948114	val: 0.650926	test: 0.891004
PRC train: 0.816067	val: 0.567061	test: 0.641996

Epoch: 71
Loss: 0.14449936582913447
ROC train: 0.921874	val: 0.684987	test: 0.844212
PRC train: 0.762962	val: 0.559999	test: 0.625759

Epoch: 72
Loss: 0.1777058340337398
ROC train: 0.899654	val: 0.722391	test: 0.831912
PRC train: 0.746384	val: 0.579724	test: 0.612479

Epoch: 73
Loss: 0.20206706765625282
ROC train: 0.902346	val: 0.709073	test: 0.858531
PRC train: 0.775027	val: 0.575721	test: 0.653481

Epoch: 74
Loss: 0.13768131260111996
ROC train: 0.920021	val: 0.669444	test: 0.867440
PRC train: 0.766126	val: 0.560866	test: 0.655849

Epoch: 75
Loss: 0.13671458835900635
ROC train: 0.932035	val: 0.654266	test: 0.856000
PRC train: 0.769506	val: 0.554099	test: 0.646791

Epoch: 76
Loss: 0.1312036153005208
ROC train: 0.939067	val: 0.655369	test: 0.851845
PRC train: 0.787980	val: 0.552147	test: 0.640336

Epoch: 77
Loss: 0.1405080644871048
ROC train: 0.942702	val: 0.661054	test: 0.853073
PRC train: 0.812679	val: 0.555997	test: 0.651379

Epoch: 78
Loss: 0.13161659876713058
ROC train: 0.946851	val: 0.660594	test: 0.866821
PRC train: 0.827950	val: 0.563263	test: 0.682975

Epoch: 79
Loss: 0.1558380026519795
ROC train: 0.951432	val: 0.661523	test: 0.866606
PRC train: 0.835688	val: 0.569004	test: 0.681195

Epoch: 80
Loss: 0.24466452738568
ROC train: 0.946339	val: 0.645320	test: 0.859855
PRC train: 0.814761	val: 0.555527	test: 0.665948

Epoch: 81
Loss: 0.1410789836745304
ROC train: 0.929492	val: 0.605224	test: 0.842101
PRC train: 0.802550	val: 0.553740	test: 0.650518

Epoch: 82
Loss: 0.18104112475625636
ROC train: 0.931271	val: 0.591220	test: 0.840472
PRC train: 0.793967	val: 0.547509	test: 0.650902

Epoch: 83
Loss: 0.22650415158639997
ROC train: 0.934227	val: 0.597482	test: 0.852389
PRC train: 0.805191	val: 0.542544	test: 0.645999

Epoch: 84
Loss: 0.1797384177907894
ROC train: 0.944269	val: 0.636220	test: 0.853601
PRC train: 0.801321	val: 0.548726	test: 0.635109

Epoch: 85
Loss: 0.18380479488571325
ROC train: 0.948162	val: 0.668597	test: 0.853815
PRC train: 0.825893	val: 0.572765	test: 0.652000

Epoch: 86
Loss: 0.16635350130109133
ROC train: 0.939950	val: 0.670712	test: 0.872406
PRC train: 0.799506	val: 0.568089	test: 0.699477

Epoch: 87
Loss: 0.15604137128942736
ROC train: 0.945799	val: 0.657106	test: 0.868816
PRC train: 0.817331	val: 0.556464	test: 0.660795

Epoch: 88
Loss: 0.23247809176697137
ROC train: 0.945562	val: 0.641801	test: 0.876738
PRC train: 0.821701	val: 0.558300	test: 0.643035

Epoch: 89
Loss: 0.16784605950158665
ROC train: 0.932526	val: 0.645902	test: 0.871049
PRC train: 0.797444	val: 0.550857	test: 0.654268

Epoch: 90
Loss: 0.1574771065181842
ROC train: 0.935788	val: 0.634990	test: 0.873372
PRC train: 0.818787	val: 0.548681	test: 0.670784

Epoch: 91
Loss: 0.14277329817597112
ROC train: 0.937677	val: 0.624353	test: 0.837142
PRC train: 0.803627	val: 0.547725	test: 0.647950

Epoch: 92
Loss: 0.13971887213835446
ROC train: 0.944647	val: 0.637903	test: 0.836822
PRC train: 0.807286	val: 0.556077	test: 0.647342

Epoch: 93
Loss: 0.14084058331055954
ROC train: 0.954255	val: 0.649208	test: 0.849022
PRC train: 0.825003	val: 0.561326	test: 0.656802

Epoch: 94
Loss: 0.24778230981547872
ROC train: 0.905851	val: 0.588641	test: 0.864213
PRC train: 0.722490	val: 0.542866	test: 0.621984

Epoch: 34
Loss: 0.1660315724890346
ROC train: 0.916849	val: 0.600938	test: 0.879205
PRC train: 0.729496	val: 0.545302	test: 0.638867

Epoch: 35
Loss: 0.1791575260042822
ROC train: 0.915913	val: 0.603411	test: 0.886367
PRC train: 0.728812	val: 0.550124	test: 0.656982

Epoch: 36
Loss: 0.17442116342327246
ROC train: 0.900137	val: 0.597100	test: 0.881550
PRC train: 0.718191	val: 0.544430	test: 0.682392

Epoch: 37
Loss: 0.162656116723147
ROC train: 0.914743	val: 0.583515	test: 0.896719
PRC train: 0.745326	val: 0.559510	test: 0.667322

Epoch: 38
Loss: 0.21223752373838578
ROC train: 0.910345	val: 0.577314	test: 0.896752
PRC train: 0.744477	val: 0.572335	test: 0.685572

Epoch: 39
Loss: 0.19678164604318296
ROC train: 0.875240	val: 0.581218	test: 0.867462
PRC train: 0.704563	val: 0.564544	test: 0.624092

Epoch: 40
Loss: 0.1662912710182446
ROC train: 0.875287	val: 0.556009	test: 0.848277
PRC train: 0.702706	val: 0.555189	test: 0.603376

Epoch: 41
Loss: 0.1824878119322288
ROC train: 0.893899	val: 0.560890	test: 0.874751
PRC train: 0.742863	val: 0.541536	test: 0.626299

Epoch: 42
Loss: 0.18680885021629268
ROC train: 0.878482	val: 0.578083	test: 0.876979
PRC train: 0.719943	val: 0.530145	test: 0.622362

Epoch: 43
Loss: 0.1513819437342428
ROC train: 0.878472	val: 0.610845	test: 0.884040
PRC train: 0.717677	val: 0.539111	test: 0.669834

Epoch: 44
Loss: 0.14667196429410925
ROC train: 0.889023	val: 0.639234	test: 0.868487
PRC train: 0.721727	val: 0.555902	test: 0.672456

Epoch: 45
Loss: 0.2267314612225671
ROC train: 0.900445	val: 0.644934	test: 0.875526
PRC train: 0.735643	val: 0.557171	test: 0.672814

Epoch: 46
Loss: 0.2185690763691722
ROC train: 0.876958	val: 0.637287	test: 0.866153
PRC train: 0.699939	val: 0.545271	test: 0.633672

Epoch: 47
Loss: 0.16336896527964578
ROC train: 0.876655	val: 0.650736	test: 0.849548
PRC train: 0.701107	val: 0.555503	test: 0.609686

Epoch: 48
Loss: 0.28067122696893543
ROC train: 0.888132	val: 0.664032	test: 0.844217
PRC train: 0.706706	val: 0.566344	test: 0.625568

Epoch: 49
Loss: 0.2608595942133253
ROC train: 0.894252	val: 0.657480	test: 0.833877
PRC train: 0.719294	val: 0.567641	test: 0.627419

Epoch: 50
Loss: 0.15470846829879087
ROC train: 0.892931	val: 0.650243	test: 0.839110
PRC train: 0.713365	val: 0.557435	test: 0.607638

Epoch: 51
Loss: 0.2033052872046292
ROC train: 0.892563	val: 0.638608	test: 0.852259
PRC train: 0.726264	val: 0.555604	test: 0.610879

Epoch: 52
Loss: 0.15972089441852916
ROC train: 0.899010	val: 0.633988	test: 0.868165
PRC train: 0.738896	val: 0.569111	test: 0.668975

Epoch: 53
Loss: 0.1610577261322915
ROC train: 0.903324	val: 0.645287	test: 0.871572
PRC train: 0.745385	val: 0.575156	test: 0.679346

Epoch: 54
Loss: 0.17608432177411676
ROC train: 0.913109	val: 0.642077	test: 0.865617
PRC train: 0.758025	val: 0.568440	test: 0.659960

Epoch: 55
Loss: 0.19154867191342012
ROC train: 0.923703	val: 0.630007	test: 0.867172
PRC train: 0.761000	val: 0.578326	test: 0.647440

Epoch: 56
Loss: 0.2146695553474593
ROC train: 0.896278	val: 0.617894	test: 0.825824
PRC train: 0.702527	val: 0.578519	test: 0.607112

Epoch: 57
Loss: 0.17409549873581337
ROC train: 0.889139	val: 0.644938	test: 0.784475
PRC train: 0.704962	val: 0.571593	test: 0.575638

Epoch: 58
Loss: 0.23079490076063033
ROC train: 0.896066	val: 0.626053	test: 0.748903
PRC train: 0.743437	val: 0.553698	test: 0.558196

Epoch: 59
Loss: 0.1489993353553251
ROC train: 0.891551	val: 0.608816	test: 0.789931
PRC train: 0.738722	val: 0.542452	test: 0.582206

Epoch: 60
Loss: 0.15951399548921702
ROC train: 0.896219	val: 0.619520	test: 0.829694
PRC train: 0.740291	val: 0.546565	test: 0.621528

Epoch: 61
Loss: 0.15486766759497603
ROC train: 0.848067	val: 0.638982	test: 0.842187
PRC train: 0.715731	val: 0.550995	test: 0.663115

Epoch: 62
Loss: 0.15524695667885344
ROC train: 0.865579	val: 0.636965	test: 0.876123
PRC train: 0.739785	val: 0.559946	test: 0.707520

Epoch: 63
Loss: 0.15398366059515348
ROC train: 0.913556	val: 0.630477	test: 0.884049
PRC train: 0.773736	val: 0.555800	test: 0.725256

Epoch: 64
Loss: 0.14799008635986005
ROC train: 0.926119	val: 0.631761	test: 0.875803
PRC train: 0.792093	val: 0.556717	test: 0.686955

Epoch: 65
Loss: 0.15621723892614436
ROC train: 0.935340	val: 0.633752	test: 0.870707
PRC train: 0.800191	val: 0.562711	test: 0.661610

Epoch: 66
Loss: 0.13783404773498714
ROC train: 0.941898	val: 0.629882	test: 0.873581
PRC train: 0.801166	val: 0.573370	test: 0.649955

Epoch: 67
Loss: 0.2110861046034597
ROC train: 0.948554	val: 0.634176	test: 0.877192
PRC train: 0.808517	val: 0.579114	test: 0.646650

Epoch: 68
Loss: 0.1902304661489554
ROC train: 0.941865	val: 0.649001	test: 0.863572
PRC train: 0.794481	val: 0.585566	test: 0.622191

Epoch: 69
Loss: 0.14336705056292492
ROC train: 0.937349	val: 0.656434	test: 0.884419
PRC train: 0.786946	val: 0.581260	test: 0.663928

Epoch: 70
Loss: 0.17704933662923272
ROC train: 0.943227	val: 0.660431	test: 0.891848
PRC train: 0.790662	val: 0.570498	test: 0.684657

Epoch: 71
Loss: 0.14794362059401062
ROC train: 0.889282	val: 0.669924	test: 0.888142
PRC train: 0.753015	val: 0.592633	test: 0.683529

Epoch: 72
Loss: 0.16229181618618044
ROC train: 0.927537	val: 0.653839	test: 0.898797
PRC train: 0.769655	val: 0.577604	test: 0.710687

Epoch: 73
Loss: 0.14682505715519004
ROC train: 0.905311	val: 0.628158	test: 0.890758
PRC train: 0.739677	val: 0.544930	test: 0.687708

Epoch: 74
Loss: 0.25121841170375675
ROC train: 0.924067	val: 0.643052	test: 0.906931
PRC train: 0.767021	val: 0.557462	test: 0.727044

Epoch: 75
Loss: 0.14420293463243616
ROC train: 0.892211	val: 0.646057	test: 0.891495
PRC train: 0.720356	val: 0.563275	test: 0.711094

Epoch: 76
Loss: 0.14843071249616308
ROC train: 0.919747	val: 0.662701	test: 0.890876
PRC train: 0.773802	val: 0.575949	test: 0.693206

Epoch: 77
Loss: 0.21552411590811876
ROC train: 0.941173	val: 0.656925	test: 0.884744
PRC train: 0.806067	val: 0.584637	test: 0.659523

Epoch: 78
Loss: 0.1499129146446453
ROC train: 0.924973	val: 0.644544	test: 0.876957
PRC train: 0.772725	val: 0.581268	test: 0.642399

Epoch: 79
Loss: 0.14863380494442402
ROC train: 0.934469	val: 0.628687	test: 0.878142
PRC train: 0.787934	val: 0.561688	test: 0.648992

Epoch: 80
Loss: 0.1470292208405048
ROC train: 0.942497	val: 0.610719	test: 0.871727
PRC train: 0.810178	val: 0.546966	test: 0.646809

Epoch: 81
Loss: 0.13607381560538506
ROC train: 0.944280	val: 0.622070	test: 0.880076
PRC train: 0.803417	val: 0.550762	test: 0.654705

Epoch: 82
Loss: 0.1974298396952602
ROC train: 0.950091	val: 0.625754	test: 0.893343
PRC train: 0.807369	val: 0.554973	test: 0.674988

Epoch: 83
Loss: 0.13800981667607887
ROC train: 0.948476	val: 0.634061	test: 0.897413
PRC train: 0.793196	val: 0.567244	test: 0.693670

Epoch: 84
Loss: 0.17005335086585088
ROC train: 0.947111	val: 0.654478	test: 0.896740
PRC train: 0.774269	val: 0.570994	test: 0.679153

Epoch: 85
Loss: 0.12979028736785667
ROC train: 0.931026	val: 0.676431	test: 0.865207
PRC train: 0.739060	val: 0.565020	test: 0.643725

Epoch: 86
Loss: 0.13011068406951787
ROC train: 0.939103	val: 0.669144	test: 0.875205
PRC train: 0.759711	val: 0.565442	test: 0.638814

Epoch: 87
Loss: 0.15803089440813772
ROC train: 0.954386	val: 0.647509	test: 0.900212
PRC train: 0.807798	val: 0.574314	test: 0.696009

Epoch: 88
Loss: 0.1412095494690294
ROC train: 0.950764	val: 0.649616	test: 0.894412
PRC train: 0.804162	val: 0.577761	test: 0.698289

Epoch: 89
Loss: 0.22521999116374625
ROC train: 0.949793	val: 0.666257	test: 0.872931
PRC train: 0.808546	val: 0.570180	test: 0.661760

Epoch: 90
Loss: 0.25185428957619677
ROC train: 0.912819	val: 0.666257	test: 0.789030
PRC train: 0.726042	val: 0.561330	test: 0.576489

Epoch: 91
Loss: 0.15015462820243552
ROC train: 0.934888	val: 0.684438	test: 0.850200
PRC train: 0.780671	val: 0.572410	test: 0.627583

Epoch: 92
Loss: 0.13140933847928185
ROC train: 0.935400	val: 0.675915	test: 0.877966
PRC train: 0.786989	val: 0.572898	test: 0.706419

Epoch: 93
Loss: 0.13451460012942085
ROC train: 0.927146	val: 0.662955	test: 0.884358
PRC train: 0.778150	val: 0.567713	test: 0.730970

Epoch: 94
Loss: 0.16131250755876514
ROC train: 0.869486	val: 0.618751	test: 0.882534
PRC train: 0.691475	val: 0.547247	test: 0.659832

Epoch: 34
Loss: 0.21113358929759843
ROC train: 0.865005	val: 0.626037	test: 0.858404
PRC train: 0.679329	val: 0.550530	test: 0.623067

Epoch: 35
Loss: 0.16766160058735669
ROC train: 0.864178	val: 0.637993	test: 0.860695
PRC train: 0.674527	val: 0.565308	test: 0.633012

Epoch: 36
Loss: 0.16734335781132953
ROC train: 0.895804	val: 0.634997	test: 0.879330
PRC train: 0.725372	val: 0.569469	test: 0.650788

Epoch: 37
Loss: 0.24233353350496842
ROC train: 0.915720	val: 0.623972	test: 0.886396
PRC train: 0.756531	val: 0.555127	test: 0.682151

Epoch: 38
Loss: 0.17011558585487654
ROC train: 0.893897	val: 0.614561	test: 0.857644
PRC train: 0.722295	val: 0.545883	test: 0.683470

Epoch: 39
Loss: 0.22973726933529742
ROC train: 0.900091	val: 0.617571	test: 0.855487
PRC train: 0.738044	val: 0.544614	test: 0.649454

Epoch: 40
Loss: 0.1606938206523846
ROC train: 0.884035	val: 0.618865	test: 0.853564
PRC train: 0.698232	val: 0.542284	test: 0.620139

Epoch: 41
Loss: 0.1787204435586904
ROC train: 0.888722	val: 0.625145	test: 0.862559
PRC train: 0.703398	val: 0.546664	test: 0.626831

Epoch: 42
Loss: 0.15367230252075698
ROC train: 0.904520	val: 0.636192	test: 0.871879
PRC train: 0.725793	val: 0.558235	test: 0.662768

Epoch: 43
Loss: 0.15456329235822694
ROC train: 0.917086	val: 0.629279	test: 0.882054
PRC train: 0.747922	val: 0.559074	test: 0.705223

Epoch: 44
Loss: 0.17916465927665562
ROC train: 0.919888	val: 0.613854	test: 0.885290
PRC train: 0.764455	val: 0.552274	test: 0.711328

Epoch: 45
Loss: 0.14688113138581477
ROC train: 0.917866	val: 0.598745	test: 0.893883
PRC train: 0.773824	val: 0.537106	test: 0.710521

Epoch: 46
Loss: 0.15494598813084245
ROC train: 0.920503	val: 0.601653	test: 0.890684
PRC train: 0.777641	val: 0.538925	test: 0.670245

Epoch: 47
Loss: 0.1667997800950567
ROC train: 0.928348	val: 0.611445	test: 0.891176
PRC train: 0.778445	val: 0.543263	test: 0.654486

Epoch: 48
Loss: 0.18847536823206332
ROC train: 0.926455	val: 0.624198	test: 0.879207
PRC train: 0.770703	val: 0.557390	test: 0.641363

Epoch: 49
Loss: 0.2789770795450307
ROC train: 0.923926	val: 0.614241	test: 0.886166
PRC train: 0.788040	val: 0.559097	test: 0.646417

Epoch: 50
Loss: 0.14853977887033037
ROC train: 0.919734	val: 0.609970	test: 0.890706
PRC train: 0.793763	val: 0.559181	test: 0.676642

Epoch: 51
Loss: 0.16898826737091074
ROC train: 0.934341	val: 0.627735	test: 0.897041
PRC train: 0.795982	val: 0.565157	test: 0.679575

Epoch: 52
Loss: 0.18080470558347547
ROC train: 0.934602	val: 0.642548	test: 0.914591
PRC train: 0.790656	val: 0.581061	test: 0.708239

Epoch: 53
Loss: 0.14510907608503482
ROC train: 0.938434	val: 0.636402	test: 0.921011
PRC train: 0.791107	val: 0.560683	test: 0.746201

Epoch: 54
Loss: 0.1632873374735761
ROC train: 0.940476	val: 0.639658	test: 0.916952
PRC train: 0.800196	val: 0.558776	test: 0.713082

Epoch: 55
Loss: 0.14429389894395192
ROC train: 0.935455	val: 0.646333	test: 0.893302
PRC train: 0.790354	val: 0.568255	test: 0.662760

Epoch: 56
Loss: 0.14139135316288368
ROC train: 0.939352	val: 0.635117	test: 0.888089
PRC train: 0.802901	val: 0.564157	test: 0.661981

Epoch: 57
Loss: 0.13349712785572615
ROC train: 0.939524	val: 0.612478	test: 0.887084
PRC train: 0.813908	val: 0.561063	test: 0.658408

Epoch: 58
Loss: 0.14530003236232777
ROC train: 0.938987	val: 0.594543	test: 0.886816
PRC train: 0.815193	val: 0.550050	test: 0.660622

Epoch: 59
Loss: 0.1322460748173288
ROC train: 0.941604	val: 0.595815	test: 0.878837
PRC train: 0.818914	val: 0.565247	test: 0.649226

Epoch: 60
Loss: 0.2301470194418796
ROC train: 0.945820	val: 0.609166	test: 0.871456
PRC train: 0.812441	val: 0.570933	test: 0.636043

Epoch: 61
Loss: 0.12608762279169244
ROC train: 0.942397	val: 0.599195	test: 0.877951
PRC train: 0.792419	val: 0.561828	test: 0.651419

Epoch: 62
Loss: 0.1536649004000964
ROC train: 0.941329	val: 0.612678	test: 0.887726
PRC train: 0.791879	val: 0.569875	test: 0.673517

Epoch: 63
Loss: 0.15019980732272542
ROC train: 0.937223	val: 0.636003	test: 0.892758
PRC train: 0.794716	val: 0.577434	test: 0.685894

Epoch: 64
Loss: 0.13740443489943446
ROC train: 0.924636	val: 0.645815	test: 0.861086
PRC train: 0.768753	val: 0.571091	test: 0.664992

Epoch: 65
Loss: 0.13058995625605807
ROC train: 0.946331	val: 0.614510	test: 0.888752
PRC train: 0.814792	val: 0.571882	test: 0.684191

Epoch: 66
Loss: 0.20211009702418997
ROC train: 0.951858	val: 0.601827	test: 0.895732
PRC train: 0.828889	val: 0.566429	test: 0.701263

Epoch: 67
Loss: 0.1806767828098897
ROC train: 0.939783	val: 0.616548	test: 0.883987
PRC train: 0.793278	val: 0.570931	test: 0.675334

Epoch: 68
Loss: 0.1391085148298666
ROC train: 0.901235	val: 0.601003	test: 0.807216
PRC train: 0.722900	val: 0.553205	test: 0.589951

Epoch: 69
Loss: 0.28067103747584443
ROC train: 0.922297	val: 0.617609	test: 0.852314
PRC train: 0.758607	val: 0.560539	test: 0.647043

Epoch: 70
Loss: 0.15455103853893798
ROC train: 0.893673	val: 0.632378	test: 0.891464
PRC train: 0.727722	val: 0.553501	test: 0.713308

Epoch: 71
Loss: 0.1536747639900469
ROC train: 0.888481	val: 0.638039	test: 0.889002
PRC train: 0.712487	val: 0.555229	test: 0.728962

Epoch: 72
Loss: 0.14919714172631537
ROC train: 0.936160	val: 0.655074	test: 0.900234
PRC train: 0.779299	val: 0.570056	test: 0.737912

Epoch: 73
Loss: 0.14301787077730116
ROC train: 0.945092	val: 0.661466	test: 0.906778
PRC train: 0.801415	val: 0.569792	test: 0.710147

Epoch: 74
Loss: 0.13894651020054263
ROC train: 0.948547	val: 0.652767	test: 0.903461
PRC train: 0.804412	val: 0.570629	test: 0.706542

Epoch: 75
Loss: 0.176218226103857
ROC train: 0.950449	val: 0.639221	test: 0.907991
PRC train: 0.810835	val: 0.563864	test: 0.708272

Epoch: 76
Loss: 0.14345869284170099
ROC train: 0.943052	val: 0.646600	test: 0.895514
PRC train: 0.805250	val: 0.564110	test: 0.698491

Epoch: 77
Loss: 0.13298956562602768
ROC train: 0.939708	val: 0.636774	test: 0.900149
PRC train: 0.808646	val: 0.559937	test: 0.707271

Epoch: 78
Loss: 0.13337918547744881
ROC train: 0.944897	val: 0.647158	test: 0.902600
PRC train: 0.818248	val: 0.576508	test: 0.740583

Epoch: 79
Loss: 0.1463634993605462
ROC train: 0.944641	val: 0.658841	test: 0.895021
PRC train: 0.812349	val: 0.582983	test: 0.705315

Epoch: 80
Loss: 0.13471479623193633
ROC train: 0.961481	val: 0.661089	test: 0.890423
PRC train: 0.837546	val: 0.589242	test: 0.691551

Epoch: 81
Loss: 0.1451701013589332
ROC train: 0.955359	val: 0.649058	test: 0.889519
PRC train: 0.833381	val: 0.566932	test: 0.692228

Epoch: 82
Loss: 0.12071499518523825
ROC train: 0.956307	val: 0.652915	test: 0.891816
PRC train: 0.845469	val: 0.566581	test: 0.674275

Epoch: 83
Loss: 0.15102706983283562
ROC train: 0.950999	val: 0.662288	test: 0.895202
PRC train: 0.828173	val: 0.572467	test: 0.674532

Epoch: 84
Loss: 0.14816453794332304
ROC train: 0.943085	val: 0.649821	test: 0.915177
PRC train: 0.821410	val: 0.564373	test: 0.711348

Epoch: 85
Loss: 0.13038923201217126
ROC train: 0.929438	val: 0.640700	test: 0.906600
PRC train: 0.800759	val: 0.554844	test: 0.710990

Epoch: 86
Loss: 0.12927233942331445
ROC train: 0.943192	val: 0.653074	test: 0.907295
PRC train: 0.807941	val: 0.567439	test: 0.709769

Epoch: 87
Loss: 0.12425248132047517
ROC train: 0.958012	val: 0.659057	test: 0.911173
PRC train: 0.831459	val: 0.576150	test: 0.724692

Epoch: 88
Loss: 0.1271732724661594
ROC train: 0.967179	val: 0.651739	test: 0.906793
PRC train: 0.849917	val: 0.584679	test: 0.729284

Epoch: 89
Loss: 0.1164515002379977
ROC train: 0.966377	val: 0.646706	test: 0.894274
PRC train: 0.857538	val: 0.569262	test: 0.713060

Epoch: 90
Loss: 0.15115719953258297
ROC train: 0.966341	val: 0.641952	test: 0.889558
PRC train: 0.861166	val: 0.568434	test: 0.690877

Epoch: 91
Loss: 0.1591451566295342
ROC train: 0.965480	val: 0.621433	test: 0.887732
PRC train: 0.851812	val: 0.555544	test: 0.700020

Epoch: 92
Loss: 0.1335240883287991
ROC train: 0.956178	val: 0.584060	test: 0.883111
PRC train: 0.833143	val: 0.533967	test: 0.662484

Epoch: 93
Loss: 0.14483720468783373
ROC train: 0.944717	val: 0.565854	test: 0.845916
PRC train: 0.810327	val: 0.529672	test: 0.629452

Epoch: 94
Loss: 0.1504203776156547
ROC train: 0.956483	val: 0.725602	test: 0.864129
PRC train: 0.848656	val: 0.581199	test: 0.648458

Epoch: 34
Loss: 0.15771492393055436
ROC train: 0.959441	val: 0.718583	test: 0.873731
PRC train: 0.857318	val: 0.600800	test: 0.655846

Epoch: 35
Loss: 0.14696982091262625
ROC train: 0.971114	val: 0.732955	test: 0.887114
PRC train: 0.875813	val: 0.589114	test: 0.673955

Epoch: 36
Loss: 0.15468790770989502
ROC train: 0.967375	val: 0.743984	test: 0.898170
PRC train: 0.864554	val: 0.599058	test: 0.689325

Epoch: 37
Loss: 0.13598727701229488
ROC train: 0.971474	val: 0.729947	test: 0.892181
PRC train: 0.874119	val: 0.610823	test: 0.694415

Epoch: 38
Loss: 0.139359771012621
ROC train: 0.970087	val: 0.707219	test: 0.865529
PRC train: 0.877391	val: 0.596673	test: 0.659267

Epoch: 39
Loss: 0.1380197753672913
ROC train: 0.968009	val: 0.723930	test: 0.851297
PRC train: 0.872803	val: 0.591286	test: 0.647108

Epoch: 40
Loss: 0.13794872548970788
ROC train: 0.964455	val: 0.726939	test: 0.858786
PRC train: 0.863676	val: 0.575773	test: 0.647077

Epoch: 41
Loss: 0.13682590530871047
ROC train: 0.974799	val: 0.738302	test: 0.870084
PRC train: 0.890364	val: 0.594772	test: 0.653584

Epoch: 42
Loss: 0.1505717494969388
ROC train: 0.978180	val: 0.722594	test: 0.882245
PRC train: 0.894479	val: 0.591945	test: 0.680742

Epoch: 43
Loss: 0.1335167938286333
ROC train: 0.975786	val: 0.711230	test: 0.889049
PRC train: 0.879401	val: 0.597741	test: 0.706740

Epoch: 44
Loss: 0.12389313536048951
ROC train: 0.973374	val: 0.716578	test: 0.891208
PRC train: 0.863628	val: 0.595437	test: 0.716929

Epoch: 45
Loss: 0.12475286871203446
ROC train: 0.971201	val: 0.702206	test: 0.879031
PRC train: 0.869865	val: 0.588071	test: 0.667547

Epoch: 46
Loss: 0.12664771602998015
ROC train: 0.979060	val: 0.687500	test: 0.875059
PRC train: 0.897779	val: 0.590209	test: 0.662470

Epoch: 47
Loss: 0.134783600483278
ROC train: 0.978909	val: 0.669118	test: 0.854790
PRC train: 0.895673	val: 0.561157	test: 0.646622

Epoch: 48
Loss: 0.143179295078894
ROC train: 0.976529	val: 0.702540	test: 0.848722
PRC train: 0.886970	val: 0.575659	test: 0.654952

Epoch: 49
Loss: 0.12719277077546381
ROC train: 0.979886	val: 0.730281	test: 0.891593
PRC train: 0.890920	val: 0.594072	test: 0.699485

Epoch: 50
Loss: 0.1148522077311382
ROC train: 0.978964	val: 0.717246	test: 0.890079
PRC train: 0.898519	val: 0.581660	test: 0.703791

Epoch: 51
Loss: 0.11983031493372853
ROC train: 0.980360	val: 0.714238	test: 0.868138
PRC train: 0.908532	val: 0.574276	test: 0.670146

Epoch: 52
Loss: 0.12695352283618472
ROC train: 0.980493	val: 0.732955	test: 0.867510
PRC train: 0.907210	val: 0.586192	test: 0.684327

Epoch: 53
Loss: 0.12007799772630894
ROC train: 0.979698	val: 0.724265	test: 0.848961
PRC train: 0.896862	val: 0.572264	test: 0.650458

Epoch: 54
Loss: 0.11216995576312025
ROC train: 0.983850	val: 0.740642	test: 0.887114
PRC train: 0.915367	val: 0.592201	test: 0.695897

Epoch: 55
Loss: 0.1060408496931563
ROC train: 0.984951	val: 0.732286	test: 0.873677
PRC train: 0.918901	val: 0.584224	test: 0.691530

Epoch: 56
Loss: 0.11317171387250342
ROC train: 0.983926	val: 0.731283	test: 0.857616
PRC train: 0.915167	val: 0.577546	test: 0.688963

Epoch: 57
Loss: 0.11456880669130239
ROC train: 0.984459	val: 0.738636	test: 0.864897
PRC train: 0.916596	val: 0.579679	test: 0.695021

Epoch: 58
Loss: 0.10286201445764424
ROC train: 0.985245	val: 0.728610	test: 0.863503
PRC train: 0.918800	val: 0.582120	test: 0.659505

Epoch: 59
Loss: 0.11441821751839913
ROC train: 0.985319	val: 0.708222	test: 0.844705
PRC train: 0.916160	val: 0.572846	test: 0.649378

Epoch: 60
Loss: 0.10620527029040712
ROC train: 0.985871	val: 0.710227	test: 0.878004
PRC train: 0.918669	val: 0.582421	test: 0.699442

Epoch: 61
Loss: 0.10821638600321035
ROC train: 0.985083	val: 0.712901	test: 0.891923
PRC train: 0.919192	val: 0.586886	test: 0.700914

Epoch: 62
Loss: 0.11075987940952241
ROC train: 0.983538	val: 0.699532	test: 0.882484
PRC train: 0.921592	val: 0.579534	test: 0.696053

Epoch: 63
Loss: 0.10793893726712497
ROC train: 0.981213	val: 0.689840	test: 0.867653
PRC train: 0.919102	val: 0.576620	test: 0.635496

Epoch: 64
Loss: 0.10921127864195561
ROC train: 0.983417	val: 0.695187	test: 0.850456
PRC train: 0.914599	val: 0.564248	test: 0.613687

Epoch: 65
Loss: 0.10238598913636243
ROC train: 0.987738	val: 0.714572	test: 0.885270
PRC train: 0.927960	val: 0.575488	test: 0.685308

Epoch: 66
Loss: 0.12718870103132557
ROC train: 0.988546	val: 0.733623	test: 0.878425
PRC train: 0.934930	val: 0.586581	test: 0.668755

Epoch: 67
Loss: 0.09395085510336679
ROC train: 0.982586	val: 0.733289	test: 0.872511
PRC train: 0.919897	val: 0.601012	test: 0.654785

Epoch: 68
Loss: 0.10560401532673654
ROC train: 0.987136	val: 0.716578	test: 0.860671
PRC train: 0.920483	val: 0.588415	test: 0.673037

Epoch: 69
Loss: 0.10162108899569948
ROC train: 0.986847	val: 0.711564	test: 0.855041
PRC train: 0.923203	val: 0.578570	test: 0.658680

Epoch: 70
Loss: 0.10397299981844126
ROC train: 0.988977	val: 0.740307	test: 0.873196
PRC train: 0.932900	val: 0.592434	test: 0.682518

Epoch: 71
Loss: 0.10703851067628511
ROC train: 0.986223	val: 0.750000	test: 0.884748
PRC train: 0.925251	val: 0.602839	test: 0.697275

Epoch: 72
Loss: 0.09629586095274363
ROC train: 0.988223	val: 0.729947	test: 0.862784
PRC train: 0.936594	val: 0.586451	test: 0.659515

Epoch: 73
Loss: 0.10792143915293273
ROC train: 0.988310	val: 0.700201	test: 0.845424
PRC train: 0.932157	val: 0.586027	test: 0.641073

Epoch: 74
Loss: 0.09565935502320265
ROC train: 0.985571	val: 0.717246	test: 0.855102
PRC train: 0.920165	val: 0.625421	test: 0.642562

Epoch: 75
Loss: 0.0986708732546443
ROC train: 0.984398	val: 0.738971	test: 0.878698
PRC train: 0.921644	val: 0.610408	test: 0.658237

Epoch: 76
Loss: 0.09653138124601757
ROC train: 0.983305	val: 0.733957	test: 0.886516
PRC train: 0.914896	val: 0.591509	test: 0.671714

Epoch: 77
Loss: 0.10065864998613912
ROC train: 0.989328	val: 0.733957	test: 0.893539
PRC train: 0.937767	val: 0.580562	test: 0.682936

Epoch: 78
Loss: 0.09994713868180956
ROC train: 0.986292	val: 0.719920	test: 0.856207
PRC train: 0.923985	val: 0.573653	test: 0.679340

Epoch: 79
Loss: 0.11918445314365647
ROC train: 0.985527	val: 0.695856	test: 0.814755
PRC train: 0.922060	val: 0.568619	test: 0.656544

Epoch: 80
Loss: 0.09664392000538453
ROC train: 0.989208	val: 0.725267	test: 0.856313
PRC train: 0.935955	val: 0.579977	test: 0.658256

Epoch: 81
Loss: 0.10585492517322843
ROC train: 0.989827	val: 0.725267	test: 0.859865
PRC train: 0.941352	val: 0.588071	test: 0.656782

Epoch: 82
Loss: 0.08439879521622651
ROC train: 0.986879	val: 0.710561	test: 0.837242
PRC train: 0.923039	val: 0.575257	test: 0.661162

Epoch: 83
Loss: 0.09927356291214234
ROC train: 0.989464	val: 0.729612	test: 0.878095
PRC train: 0.936138	val: 0.589761	test: 0.693071

Epoch: 84
Loss: 0.10497149956566414
ROC train: 0.989826	val: 0.732286	test: 0.881779
PRC train: 0.941702	val: 0.606633	test: 0.669389

Epoch: 85
Loss: 0.08893019367066009
ROC train: 0.988489	val: 0.711230	test: 0.855999
PRC train: 0.935408	val: 0.582513	test: 0.652708

Epoch: 86
Loss: 0.09781167000449302
ROC train: 0.988897	val: 0.703543	test: 0.854081
PRC train: 0.936982	val: 0.576519	test: 0.660746

Epoch: 87
Loss: 0.10468095490811644
ROC train: 0.990761	val: 0.722594	test: 0.874336
PRC train: 0.946007	val: 0.598516	test: 0.655640

Epoch: 88
Loss: 0.10033961150021505
ROC train: 0.989328	val: 0.724933	test: 0.858350
PRC train: 0.932042	val: 0.601629	test: 0.647198

Epoch: 89
Loss: 0.10188783736210405
ROC train: 0.990506	val: 0.728275	test: 0.868403
PRC train: 0.940466	val: 0.602609	test: 0.653231

Epoch: 90
Loss: 0.09536374334111386
ROC train: 0.989758	val: 0.731952	test: 0.892597
PRC train: 0.942402	val: 0.601628	test: 0.650683

Epoch: 91
Loss: 0.10147225474922628
ROC train: 0.989990	val: 0.734291	test: 0.870648
PRC train: 0.937869	val: 0.601813	test: 0.645731

Epoch: 92
Loss: 0.0963774308549721
ROC train: 0.989862	val: 0.715575	test: 0.858350
PRC train: 0.938267	val: 0.595241	test: 0.646206

Epoch: 93
Loss: 0.09586148369539811
ROC train: 0.990624	val: 0.719920	test: 0.858188
PRC train: 0.939831	val: 0.591675	test: 0.646560

Epoch: 94
Loss: 0.0915256704857399
ROC train: 0.958175	val: 0.758356	test: 0.878286
PRC train: 0.849214	val: 0.593570	test: 0.665971

Epoch: 34
Loss: 0.14305999226444102
ROC train: 0.970268	val: 0.740642	test: 0.868725
PRC train: 0.865979	val: 0.586891	test: 0.659183

Epoch: 35
Loss: 0.1354326680464975
ROC train: 0.970178	val: 0.724599	test: 0.830810
PRC train: 0.862661	val: 0.580605	test: 0.626082

Epoch: 36
Loss: 0.13822964639655738
ROC train: 0.971132	val: 0.763035	test: 0.876574
PRC train: 0.868828	val: 0.591575	test: 0.660341

Epoch: 37
Loss: 0.1381912254637443
ROC train: 0.973090	val: 0.754345	test: 0.879376
PRC train: 0.875412	val: 0.581957	test: 0.677957

Epoch: 38
Loss: 0.13348334943002874
ROC train: 0.973928	val: 0.740307	test: 0.850105
PRC train: 0.871105	val: 0.576630	test: 0.641165

Epoch: 39
Loss: 0.12761945494355
ROC train: 0.975082	val: 0.753342	test: 0.835558
PRC train: 0.873778	val: 0.584886	test: 0.630951

Epoch: 40
Loss: 0.1291009643560521
ROC train: 0.974098	val: 0.751337	test: 0.821726
PRC train: 0.872523	val: 0.586463	test: 0.629204

Epoch: 41
Loss: 0.13499854846695256
ROC train: 0.974014	val: 0.746658	test: 0.868169
PRC train: 0.875669	val: 0.598779	test: 0.661873

Epoch: 42
Loss: 0.12797351149290784
ROC train: 0.976671	val: 0.726604	test: 0.880258
PRC train: 0.888294	val: 0.594300	test: 0.678033

Epoch: 43
Loss: 0.12776507936169398
ROC train: 0.974622	val: 0.741310	test: 0.854746
PRC train: 0.882080	val: 0.580749	test: 0.645875

Epoch: 44
Loss: 0.12337914703385836
ROC train: 0.975081	val: 0.754011	test: 0.887929
PRC train: 0.893502	val: 0.597479	test: 0.689500

Epoch: 45
Loss: 0.1302684137129661
ROC train: 0.974140	val: 0.751671	test: 0.906697
PRC train: 0.892771	val: 0.599375	test: 0.735514

Epoch: 46
Loss: 0.12179674327803058
ROC train: 0.978336	val: 0.749666	test: 0.874321
PRC train: 0.894977	val: 0.584937	test: 0.653888

Epoch: 47
Loss: 0.12930906443318793
ROC train: 0.979520	val: 0.730949	test: 0.874923
PRC train: 0.896840	val: 0.578046	test: 0.675723

Epoch: 48
Loss: 0.13492839949698782
ROC train: 0.980383	val: 0.726939	test: 0.864363
PRC train: 0.900061	val: 0.582890	test: 0.657615

Epoch: 49
Loss: 0.12723462355710832
ROC train: 0.982257	val: 0.719251	test: 0.855674
PRC train: 0.905561	val: 0.580411	test: 0.629249

Epoch: 50
Loss: 0.12584516710832427
ROC train: 0.979296	val: 0.743316	test: 0.861471
PRC train: 0.892462	val: 0.598256	test: 0.629511

Epoch: 51
Loss: 0.12308339650353879
ROC train: 0.983645	val: 0.738636	test: 0.882741
PRC train: 0.907859	val: 0.600885	test: 0.641779

Epoch: 52
Loss: 0.11763939157446476
ROC train: 0.984691	val: 0.702540	test: 0.865499
PRC train: 0.917672	val: 0.571685	test: 0.651376

Epoch: 53
Loss: 0.12318275936094938
ROC train: 0.983462	val: 0.703209	test: 0.873094
PRC train: 0.922505	val: 0.581477	test: 0.648403

Epoch: 54
Loss: 0.12180239423422234
ROC train: 0.976090	val: 0.703543	test: 0.869126
PRC train: 0.892228	val: 0.588662	test: 0.649015

Epoch: 55
Loss: 0.11749468448534964
ROC train: 0.981898	val: 0.712901	test: 0.878819
PRC train: 0.904253	val: 0.586013	test: 0.662737

Epoch: 56
Loss: 0.11820498322009507
ROC train: 0.982083	val: 0.734960	test: 0.900374
PRC train: 0.905996	val: 0.588928	test: 0.694918

Epoch: 57
Loss: 0.11113840120995093
ROC train: 0.981832	val: 0.744652	test: 0.897410
PRC train: 0.913507	val: 0.580216	test: 0.693159

Epoch: 58
Loss: 0.11376593477988144
ROC train: 0.984382	val: 0.745989	test: 0.886698
PRC train: 0.922002	val: 0.586753	test: 0.670271

Epoch: 59
Loss: 0.11517869138049694
ROC train: 0.983895	val: 0.739639	test: 0.857680
PRC train: 0.913194	val: 0.583611	test: 0.661599

Epoch: 60
Loss: 0.11460779836860949
ROC train: 0.979385	val: 0.725602	test: 0.865443
PRC train: 0.898902	val: 0.574814	test: 0.642683

Epoch: 61
Loss: 0.12181804579718794
ROC train: 0.977936	val: 0.711564	test: 0.860198
PRC train: 0.901529	val: 0.572009	test: 0.641408

Epoch: 62
Loss: 0.10098726934456184
ROC train: 0.979051	val: 0.712901	test: 0.863527
PRC train: 0.899325	val: 0.583161	test: 0.657626

Epoch: 63
Loss: 0.11891143877907506
ROC train: 0.984372	val: 0.695187	test: 0.842520
PRC train: 0.913328	val: 0.571710	test: 0.638534

Epoch: 64
Loss: 0.10582292355658811
ROC train: 0.986553	val: 0.737299	test: 0.867003
PRC train: 0.925149	val: 0.583630	test: 0.646279

Epoch: 65
Loss: 0.11660011764630111
ROC train: 0.984760	val: 0.736297	test: 0.860710
PRC train: 0.916921	val: 0.586662	test: 0.647508

Epoch: 66
Loss: 0.11004400075597043
ROC train: 0.987971	val: 0.707888	test: 0.870414
PRC train: 0.933144	val: 0.573896	test: 0.664450

Epoch: 67
Loss: 0.10439419076111493
ROC train: 0.987516	val: 0.698529	test: 0.881677
PRC train: 0.925188	val: 0.572435	test: 0.657649

Epoch: 68
Loss: 0.11409207278082871
ROC train: 0.988438	val: 0.711898	test: 0.851297
PRC train: 0.930950	val: 0.577546	test: 0.639937

Epoch: 69
Loss: 0.10328248901180788
ROC train: 0.985320	val: 0.717580	test: 0.832752
PRC train: 0.918994	val: 0.567863	test: 0.635046

Epoch: 70
Loss: 0.09698175762631392
ROC train: 0.988519	val: 0.747660	test: 0.866923
PRC train: 0.932929	val: 0.588560	test: 0.639680

Epoch: 71
Loss: 0.10083183552444822
ROC train: 0.989181	val: 0.742981	test: 0.871311
PRC train: 0.939251	val: 0.593348	test: 0.666501

Epoch: 72
Loss: 0.09520317915573442
ROC train: 0.988367	val: 0.705882	test: 0.860706
PRC train: 0.936381	val: 0.575247	test: 0.655564

Epoch: 73
Loss: 0.09851460744451071
ROC train: 0.989825	val: 0.700201	test: 0.847582
PRC train: 0.946073	val: 0.577707	test: 0.641775

Epoch: 74
Loss: 0.11731451349820383
ROC train: 0.988647	val: 0.732286	test: 0.873965
PRC train: 0.940193	val: 0.582835	test: 0.657680

Epoch: 75
Loss: 0.10070701706006106
ROC train: 0.986731	val: 0.731283	test: 0.872091
PRC train: 0.935819	val: 0.574991	test: 0.628825

Epoch: 76
Loss: 0.10366640866879048
ROC train: 0.988450	val: 0.711230	test: 0.879640
PRC train: 0.941741	val: 0.569802	test: 0.654553

Epoch: 77
Loss: 0.10606588381066151
ROC train: 0.989222	val: 0.721257	test: 0.877081
PRC train: 0.939147	val: 0.583281	test: 0.651404

Epoch: 78
Loss: 0.09589790156587794
ROC train: 0.988134	val: 0.706885	test: 0.881019
PRC train: 0.931720	val: 0.566776	test: 0.662683

Epoch: 79
Loss: 0.09638706602169186
ROC train: 0.987979	val: 0.688503	test: 0.858547
PRC train: 0.932632	val: 0.557715	test: 0.676992

Epoch: 80
Loss: 0.09766535163777733
ROC train: 0.988958	val: 0.697527	test: 0.862038
PRC train: 0.937463	val: 0.566273	test: 0.676290

Epoch: 81
Loss: 0.10154107042980987
ROC train: 0.990407	val: 0.688837	test: 0.855492
PRC train: 0.943401	val: 0.567474	test: 0.651733

Epoch: 82
Loss: 0.09611931228219475
ROC train: 0.990775	val: 0.690842	test: 0.860853
PRC train: 0.949451	val: 0.569308	test: 0.647339

Epoch: 83
Loss: 0.09028776414098966
ROC train: 0.990692	val: 0.714572	test: 0.864268
PRC train: 0.946208	val: 0.574623	test: 0.648019

Epoch: 84
Loss: 0.10283637946164907
ROC train: 0.990803	val: 0.724265	test: 0.876522
PRC train: 0.944293	val: 0.581303	test: 0.673498

Epoch: 85
Loss: 0.08994172925629386
ROC train: 0.990041	val: 0.713904	test: 0.877675
PRC train: 0.937073	val: 0.582221	test: 0.653379

Epoch: 86
Loss: 0.09109030483832112
ROC train: 0.989602	val: 0.690842	test: 0.882605
PRC train: 0.937627	val: 0.561458	test: 0.678459

Epoch: 87
Loss: 0.09865346094847549
ROC train: 0.989058	val: 0.717246	test: 0.882234
PRC train: 0.940410	val: 0.581731	test: 0.665042

Epoch: 88
Loss: 0.09536247754530057
ROC train: 0.990007	val: 0.709559	test: 0.862875
PRC train: 0.944028	val: 0.578441	test: 0.631003

Epoch: 89
Loss: 0.0980918326105489
ROC train: 0.989279	val: 0.710561	test: 0.851789
PRC train: 0.937737	val: 0.580059	test: 0.623849

Epoch: 90
Loss: 0.10263729814783704
ROC train: 0.989183	val: 0.749666	test: 0.892070
PRC train: 0.939868	val: 0.590249	test: 0.668070

Epoch: 91
Loss: 0.08844515599418039
ROC train: 0.988730	val: 0.741310	test: 0.893119
PRC train: 0.937246	val: 0.586659	test: 0.655714

Epoch: 92
Loss: 0.0871927099842137
ROC train: 0.985735	val: 0.702874	test: 0.867865
PRC train: 0.924411	val: 0.567806	test: 0.634924

Epoch: 93
Loss: 0.09756776145877251
ROC train: 0.989003	val: 0.691845	test: 0.863133
PRC train: 0.942365	val: 0.574760	test: 0.632340

Epoch: 94
Loss: 0.09622208963463504
ROC train: 0.954148	val: 0.764037	test: 0.876945
PRC train: 0.842529	val: 0.617204	test: 0.690966

Epoch: 34
Loss: 0.14381546326283629
ROC train: 0.957608	val: 0.758690	test: 0.881591
PRC train: 0.848487	val: 0.632032	test: 0.692823

Epoch: 35
Loss: 0.15700832219451072
ROC train: 0.959463	val: 0.757353	test: 0.873205
PRC train: 0.855477	val: 0.606849	test: 0.689999

Epoch: 36
Loss: 0.14193877611676042
ROC train: 0.957312	val: 0.771390	test: 0.890614
PRC train: 0.856768	val: 0.621100	test: 0.714504

Epoch: 37
Loss: 0.1376322554387521
ROC train: 0.964597	val: 0.765374	test: 0.866643
PRC train: 0.862871	val: 0.592023	test: 0.700042

Epoch: 38
Loss: 0.13546381259103135
ROC train: 0.969633	val: 0.784759	test: 0.877623
PRC train: 0.870745	val: 0.611775	test: 0.711278

Epoch: 39
Loss: 0.14615876503165812
ROC train: 0.965504	val: 0.775067	test: 0.880871
PRC train: 0.853192	val: 0.604094	test: 0.684387

Epoch: 40
Loss: 0.12819503027448406
ROC train: 0.971507	val: 0.748329	test: 0.845368
PRC train: 0.862379	val: 0.592966	test: 0.656291

Epoch: 41
Loss: 0.13741679255847244
ROC train: 0.976207	val: 0.756350	test: 0.860979
PRC train: 0.883653	val: 0.587920	test: 0.691212

Epoch: 42
Loss: 0.13312117310859234
ROC train: 0.973466	val: 0.782754	test: 0.902775
PRC train: 0.885173	val: 0.632880	test: 0.712521

Epoch: 43
Loss: 0.12272270380256448
ROC train: 0.974040	val: 0.790107	test: 0.893424
PRC train: 0.884223	val: 0.616830	test: 0.734297

Epoch: 44
Loss: 0.12103338112947437
ROC train: 0.971277	val: 0.784425	test: 0.892226
PRC train: 0.877744	val: 0.614523	test: 0.734330

Epoch: 45
Loss: 0.13707406645471648
ROC train: 0.962626	val: 0.767045	test: 0.888497
PRC train: 0.853336	val: 0.632102	test: 0.726683

Epoch: 46
Loss: 0.1242216370974579
ROC train: 0.970232	val: 0.743316	test: 0.857113
PRC train: 0.873169	val: 0.598412	test: 0.706418

Epoch: 47
Loss: 0.12090518903674052
ROC train: 0.981272	val: 0.770722	test: 0.886384
PRC train: 0.900570	val: 0.612969	test: 0.720337

Epoch: 48
Loss: 0.13394756156972093
ROC train: 0.980369	val: 0.771390	test: 0.885998
PRC train: 0.899324	val: 0.596580	test: 0.721945

Epoch: 49
Loss: 0.1451796754697276
ROC train: 0.974336	val: 0.741644	test: 0.861126
PRC train: 0.872252	val: 0.566306	test: 0.712912

Epoch: 50
Loss: 0.12692227480299226
ROC train: 0.970291	val: 0.781417	test: 0.886926
PRC train: 0.875228	val: 0.600401	test: 0.720144

Epoch: 51
Loss: 0.13070540837397018
ROC train: 0.974568	val: 0.808489	test: 0.898432
PRC train: 0.881662	val: 0.612896	test: 0.729805

Epoch: 52
Loss: 0.12041233168163275
ROC train: 0.975625	val: 0.790775	test: 0.874786
PRC train: 0.873597	val: 0.592807	test: 0.724828

Epoch: 53
Loss: 0.11242670646956188
ROC train: 0.982226	val: 0.774398	test: 0.897379
PRC train: 0.915089	val: 0.617416	test: 0.717431

Epoch: 54
Loss: 0.11268737858228287
ROC train: 0.983246	val: 0.757353	test: 0.886770
PRC train: 0.912779	val: 0.607006	test: 0.716007

Epoch: 55
Loss: 0.11616522224357699
ROC train: 0.984102	val: 0.745655	test: 0.872659
PRC train: 0.908991	val: 0.594788	test: 0.700822

Epoch: 56
Loss: 0.11553757228716352
ROC train: 0.980890	val: 0.730615	test: 0.869339
PRC train: 0.906575	val: 0.592561	test: 0.702327

Epoch: 57
Loss: 0.11472815824656366
ROC train: 0.984968	val: 0.714906	test: 0.842130
PRC train: 0.913695	val: 0.579273	test: 0.692459

Epoch: 58
Loss: 0.10816958829880371
ROC train: 0.986087	val: 0.743650	test: 0.882158
PRC train: 0.920530	val: 0.590801	test: 0.718220

Epoch: 59
Loss: 0.11406400911902739
ROC train: 0.986170	val: 0.775401	test: 0.885407
PRC train: 0.917233	val: 0.602075	test: 0.722558

Epoch: 60
Loss: 0.10372109421535398
ROC train: 0.985555	val: 0.792781	test: 0.869035
PRC train: 0.919320	val: 0.606809	test: 0.714956

Epoch: 61
Loss: 0.11095617514391978
ROC train: 0.983728	val: 0.791444	test: 0.859793
PRC train: 0.919223	val: 0.612836	test: 0.713111

Epoch: 62
Loss: 0.10597973026992062
ROC train: 0.984495	val: 0.786430	test: 0.859839
PRC train: 0.923920	val: 0.603440	test: 0.701648

Epoch: 63
Loss: 0.11723822059751013
ROC train: 0.986605	val: 0.769385	test: 0.843539
PRC train: 0.928753	val: 0.587820	test: 0.688588

Epoch: 64
Loss: 0.11276989107733329
ROC train: 0.986190	val: 0.762366	test: 0.850460
PRC train: 0.928971	val: 0.593172	test: 0.686814

Epoch: 65
Loss: 0.10608021357879856
ROC train: 0.983839	val: 0.759024	test: 0.844826
PRC train: 0.912526	val: 0.578371	test: 0.703332

Epoch: 66
Loss: 0.1063495670282986
ROC train: 0.985855	val: 0.742647	test: 0.867597
PRC train: 0.922973	val: 0.585646	test: 0.702188

Epoch: 67
Loss: 0.10603679266835579
ROC train: 0.988561	val: 0.723262	test: 0.866786
PRC train: 0.935785	val: 0.583980	test: 0.712585

Epoch: 68
Loss: 0.10840166010199197
ROC train: 0.987870	val: 0.731618	test: 0.863133
PRC train: 0.930369	val: 0.579002	test: 0.713857

Epoch: 69
Loss: 0.09511567696676601
ROC train: 0.983292	val: 0.748663	test: 0.881246
PRC train: 0.913877	val: 0.594654	test: 0.722924

Epoch: 70
Loss: 0.10467127406160111
ROC train: 0.986347	val: 0.731618	test: 0.866552
PRC train: 0.927012	val: 0.589312	test: 0.710916

Epoch: 71
Loss: 0.09437357445823982
ROC train: 0.988606	val: 0.725602	test: 0.859312
PRC train: 0.935975	val: 0.581297	test: 0.709052

Epoch: 72
Loss: 0.09801086300678911
ROC train: 0.989234	val: 0.728610	test: 0.861471
PRC train: 0.937155	val: 0.596050	test: 0.711979

Epoch: 73
Loss: 0.09326584591541338
ROC train: 0.988802	val: 0.747326	test: 0.871549
PRC train: 0.933793	val: 0.599623	test: 0.717422

Epoch: 74
Loss: 0.09524957879571411
ROC train: 0.988618	val: 0.759693	test: 0.871954
PRC train: 0.933896	val: 0.609261	test: 0.705770

Epoch: 75
Loss: 0.09566659293528731
ROC train: 0.988615	val: 0.731618	test: 0.852629
PRC train: 0.937299	val: 0.591647	test: 0.698706

Epoch: 76
Loss: 0.10846267956215513
ROC train: 0.987486	val: 0.736631	test: 0.861962
PRC train: 0.930794	val: 0.586165	test: 0.705029

Epoch: 77
Loss: 0.10154799118332222
ROC train: 0.987039	val: 0.733957	test: 0.856571
PRC train: 0.931239	val: 0.575778	test: 0.687328

Epoch: 78
Loss: 0.0994234473656935
ROC train: 0.989007	val: 0.755348	test: 0.859028
PRC train: 0.942510	val: 0.586260	test: 0.700559

Epoch: 79
Loss: 0.10227487641368642
ROC train: 0.988758	val: 0.772727	test: 0.864961
PRC train: 0.940774	val: 0.601742	test: 0.712153

Epoch: 80
Loss: 0.09488156750323176
ROC train: 0.987269	val: 0.780080	test: 0.836020
PRC train: 0.933456	val: 0.607244	test: 0.689446

Epoch: 81
Loss: 0.09386001690389026
ROC train: 0.987110	val: 0.770388	test: 0.828288
PRC train: 0.928785	val: 0.603107	test: 0.698993

Epoch: 82
Loss: 0.09663720814689514
ROC train: 0.988412	val: 0.774733	test: 0.844974
PRC train: 0.932535	val: 0.609661	test: 0.697444

Epoch: 83
Loss: 0.0960319366755397
ROC train: 0.989510	val: 0.780414	test: 0.856571
PRC train: 0.935322	val: 0.604047	test: 0.685716

Epoch: 84
Loss: 0.11624676903250294
ROC train: 0.989960	val: 0.762032	test: 0.848090
PRC train: 0.940520	val: 0.595085	test: 0.678184

Epoch: 85
Loss: 0.08572581021450665
ROC train: 0.989402	val: 0.746658	test: 0.854068
PRC train: 0.935869	val: 0.605026	test: 0.692409

Epoch: 86
Loss: 0.09638313721784819
ROC train: 0.988911	val: 0.731283	test: 0.833172
PRC train: 0.931686	val: 0.586806	test: 0.661782

Epoch: 87
Loss: 0.09116571560194908
ROC train: 0.989593	val: 0.761029	test: 0.860361
PRC train: 0.934991	val: 0.605992	test: 0.645724

Epoch: 88
Loss: 0.0943450013511416
ROC train: 0.990510	val: 0.771725	test: 0.866218
PRC train: 0.943309	val: 0.616112	test: 0.658735

Epoch: 89
Loss: 0.09205773894033904
ROC train: 0.989195	val: 0.779412	test: 0.854950
PRC train: 0.944040	val: 0.618007	test: 0.690140

Epoch: 90
Loss: 0.09306413856797893
ROC train: 0.986736	val: 0.802807	test: 0.867794
PRC train: 0.931786	val: 0.628138	test: 0.690961

Epoch: 91
Loss: 0.10052559671546184
ROC train: 0.989162	val: 0.808155	test: 0.856961
PRC train: 0.938629	val: 0.623698	test: 0.703413

Epoch: 92
Loss: 0.09813034989480025
ROC train: 0.989966	val: 0.787767	test: 0.841574
PRC train: 0.940261	val: 0.602942	test: 0.698453

Epoch: 93
Loss: 0.08922571305913866
ROC train: 0.989143	val: 0.765040	test: 0.846924
PRC train: 0.939708	val: 0.583974	test: 0.684553


ROC train: 0.992991	val: 0.700787	test: 0.799116
PRC train: 0.964456	val: 0.564882	test: 0.602957

Epoch: 95
Loss: 0.09460064916539146
ROC train: 0.994005	val: 0.698980	test: 0.802094
PRC train: 0.967591	val: 0.569585	test: 0.625988

Epoch: 96
Loss: 0.09025002485337666
ROC train: 0.992496	val: 0.694184	test: 0.806144
PRC train: 0.956971	val: 0.568275	test: 0.643190

Epoch: 97
Loss: 0.0846951443410463
ROC train: 0.991234	val: 0.683215	test: 0.826422
PRC train: 0.955249	val: 0.560713	test: 0.635188

Epoch: 98
Loss: 0.08112060146845088
ROC train: 0.992073	val: 0.701895	test: 0.807577
PRC train: 0.952829	val: 0.571383	test: 0.608957

Epoch: 99
Loss: 0.08910986392777381
ROC train: 0.993132	val: 0.719630	test: 0.811779
PRC train: 0.961425	val: 0.574833	test: 0.605663

Epoch: 100
Loss: 0.0878331895861848
ROC train: 0.993567	val: 0.727100	test: 0.825695
PRC train: 0.965807	val: 0.579083	test: 0.617810

Epoch: 101
Loss: 0.08118090007905171
ROC train: 0.990271	val: 0.721066	test: 0.816769
PRC train: 0.948988	val: 0.583436	test: 0.602286

Epoch: 102
Loss: 0.08823012423513157
ROC train: 0.993587	val: 0.726280	test: 0.816883
PRC train: 0.963945	val: 0.582894	test: 0.604513

Epoch: 103
Loss: 0.08455035933536732
ROC train: 0.993140	val: 0.731444	test: 0.813723
PRC train: 0.964167	val: 0.578425	test: 0.617974

Epoch: 104
Loss: 0.10989524765872469
ROC train: 0.992766	val: 0.708685	test: 0.823042
PRC train: 0.960335	val: 0.565852	test: 0.627582

Epoch: 105
Loss: 0.07741726658999767
ROC train: 0.989011	val: 0.678127	test: 0.820335
PRC train: 0.945448	val: 0.553628	test: 0.647126

Epoch: 106
Loss: 0.08958695675608078
ROC train: 0.991855	val: 0.678226	test: 0.807597
PRC train: 0.952317	val: 0.551936	test: 0.619617

Epoch: 107
Loss: 0.08259182373428925
ROC train: 0.993560	val: 0.705726	test: 0.806917
PRC train: 0.960989	val: 0.569166	test: 0.603788

Epoch: 108
Loss: 0.08021570248525108
ROC train: 0.993764	val: 0.720346	test: 0.817507
PRC train: 0.967164	val: 0.575310	test: 0.616932

Epoch: 109
Loss: 0.07824481772375139
ROC train: 0.993586	val: 0.717047	test: 0.812190
PRC train: 0.966089	val: 0.570311	test: 0.628448

Epoch: 110
Loss: 0.07674201264992701
ROC train: 0.993151	val: 0.711287	test: 0.796080
PRC train: 0.961509	val: 0.564207	test: 0.613641

Epoch: 111
Loss: 0.09238982201579375
ROC train: 0.993850	val: 0.697017	test: 0.789582
PRC train: 0.966554	val: 0.558411	test: 0.615150

Epoch: 112
Loss: 0.09194027506062925
ROC train: 0.994680	val: 0.697275	test: 0.784146
PRC train: 0.969828	val: 0.558239	test: 0.612843

Epoch: 113
Loss: 0.0714613365380553
ROC train: 0.994940	val: 0.684760	test: 0.795672
PRC train: 0.970604	val: 0.561421	test: 0.637084

Epoch: 114
Loss: 0.0643798174756639
ROC train: 0.994743	val: 0.683154	test: 0.808421
PRC train: 0.969628	val: 0.565195	test: 0.647414

Epoch: 115
Loss: 0.07094141376793975
ROC train: 0.994563	val: 0.689358	test: 0.815965
PRC train: 0.969418	val: 0.570424	test: 0.648003

Epoch: 116
Loss: 0.06665157546720234
ROC train: 0.994316	val: 0.701061	test: 0.813727
PRC train: 0.968267	val: 0.578438	test: 0.624434

Epoch: 117
Loss: 0.06943077494280285
ROC train: 0.993871	val: 0.699658	test: 0.812631
PRC train: 0.966520	val: 0.577584	test: 0.623624

Epoch: 118
Loss: 0.06453994227112073
ROC train: 0.994569	val: 0.695453	test: 0.823168
PRC train: 0.971444	val: 0.566723	test: 0.636052

Epoch: 119
Loss: 0.07159455253147692
ROC train: 0.994255	val: 0.693788	test: 0.832217
PRC train: 0.968905	val: 0.564111	test: 0.654014

Epoch: 120
Loss: 0.08322581623910792
ROC train: 0.993815	val: 0.703802	test: 0.824983
PRC train: 0.963639	val: 0.567674	test: 0.653447

Early stopping
Best (ROC):	 train: 0.988824	val: 0.734414	test: 0.797767
Best (PRC):	 train: 0.944471	val: 0.579875	test: 0.596978

ROC train: 0.992230	val: 0.684181	test: 0.790767
PRC train: 0.955813	val: 0.566473	test: 0.633971

Epoch: 95
Loss: 0.0994310041486282
ROC train: 0.991360	val: 0.683607	test: 0.811974
PRC train: 0.951427	val: 0.561654	test: 0.646090

Epoch: 96
Loss: 0.09186212435232144
ROC train: 0.991451	val: 0.714007	test: 0.809359
PRC train: 0.949083	val: 0.571506	test: 0.636180

Epoch: 97
Loss: 0.09147374809176462
ROC train: 0.991616	val: 0.737635	test: 0.774448
PRC train: 0.952317	val: 0.582651	test: 0.616923

Epoch: 98
Loss: 0.08453311765394289
ROC train: 0.992458	val: 0.708123	test: 0.781288
PRC train: 0.962082	val: 0.577754	test: 0.632971

Epoch: 99
Loss: 0.0777352768761457
ROC train: 0.993735	val: 0.702424	test: 0.785045
PRC train: 0.966893	val: 0.582194	test: 0.627609

Epoch: 100
Loss: 0.08712258592422632
ROC train: 0.992919	val: 0.690999	test: 0.801570
PRC train: 0.962588	val: 0.576275	test: 0.626993

Epoch: 101
Loss: 0.09212953237580258
ROC train: 0.993455	val: 0.680426	test: 0.802332
PRC train: 0.964226	val: 0.575528	test: 0.638154

Epoch: 102
Loss: 0.09125575983041431
ROC train: 0.993206	val: 0.673387	test: 0.812231
PRC train: 0.962535	val: 0.575702	test: 0.643129

Epoch: 103
Loss: 0.0894448809447872
ROC train: 0.993056	val: 0.667812	test: 0.804549
PRC train: 0.958509	val: 0.574066	test: 0.640216

Epoch: 104
Loss: 0.0827017794436829
ROC train: 0.993156	val: 0.670663	test: 0.802181
PRC train: 0.961973	val: 0.572832	test: 0.635788

Epoch: 105
Loss: 0.07418096416785924
ROC train: 0.994101	val: 0.687650	test: 0.801988
PRC train: 0.968473	val: 0.568374	test: 0.641701

Epoch: 106
Loss: 0.08667716612949504
ROC train: 0.994360	val: 0.703708	test: 0.788437
PRC train: 0.969399	val: 0.573887	test: 0.629770

Epoch: 107
Loss: 0.10120351082373452
ROC train: 0.993398	val: 0.705684	test: 0.788983
PRC train: 0.964272	val: 0.566825	test: 0.631838

Epoch: 108
Loss: 0.09555391069412668
ROC train: 0.991996	val: 0.700724	test: 0.801745
PRC train: 0.959938	val: 0.568037	test: 0.637152

Epoch: 109
Loss: 0.0796361376194755
ROC train: 0.992944	val: 0.711284	test: 0.793159
PRC train: 0.960021	val: 0.576612	test: 0.641648

Epoch: 110
Loss: 0.08654461450887217
ROC train: 0.993191	val: 0.722804	test: 0.800814
PRC train: 0.960615	val: 0.591512	test: 0.637285

Epoch: 111
Loss: 0.07148403290075774
ROC train: 0.993356	val: 0.730179	test: 0.805869
PRC train: 0.962583	val: 0.589474	test: 0.637736

Epoch: 112
Loss: 0.07058505492980388
ROC train: 0.992861	val: 0.724980	test: 0.809208
PRC train: 0.962082	val: 0.583960	test: 0.629516

Epoch: 113
Loss: 0.09141024533734972
ROC train: 0.993542	val: 0.732994	test: 0.801051
PRC train: 0.965115	val: 0.595447	test: 0.621484

Epoch: 114
Loss: 0.07584187666247574
ROC train: 0.993479	val: 0.730311	test: 0.781410
PRC train: 0.961371	val: 0.582863	test: 0.609689

Epoch: 115
Loss: 0.08478043603881481
ROC train: 0.993135	val: 0.725498	test: 0.776086
PRC train: 0.958859	val: 0.576008	test: 0.592394

Epoch: 116
Loss: 0.07820809776807883
ROC train: 0.993821	val: 0.715537	test: 0.787229
PRC train: 0.968199	val: 0.577732	test: 0.615756

Epoch: 117
Loss: 0.07986868691610213
ROC train: 0.993382	val: 0.713623	test: 0.793633
PRC train: 0.968053	val: 0.575815	test: 0.622608

Epoch: 118
Loss: 0.07719435389173487
ROC train: 0.994527	val: 0.713184	test: 0.781947
PRC train: 0.970331	val: 0.583225	test: 0.614094

Epoch: 119
Loss: 0.0853647076468009
ROC train: 0.994390	val: 0.692339	test: 0.810467
PRC train: 0.970714	val: 0.575479	test: 0.627789

Epoch: 120
Loss: 0.06384349103753056
ROC train: 0.992982	val: 0.685393	test: 0.831358
PRC train: 0.963530	val: 0.568221	test: 0.634940

Early stopping
Best (ROC):	 train: 0.986832	val: 0.750030	test: 0.794805
Best (PRC):	 train: 0.941801	val: 0.574587	test: 0.638877

Epoch: 94
Loss: 0.09207756028229261
ROC train: 0.992690	val: 0.689381	test: 0.800606
PRC train: 0.963967	val: 0.594955	test: 0.630021

Epoch: 95
Loss: 0.08369896445517983
ROC train: 0.992540	val: 0.700325	test: 0.792599
PRC train: 0.963785	val: 0.596965	test: 0.623735

Epoch: 96
Loss: 0.09328444788704447
ROC train: 0.993384	val: 0.706701	test: 0.798801
PRC train: 0.962918	val: 0.604091	test: 0.623592

Epoch: 97
Loss: 0.08945215446970889
ROC train: 0.993019	val: 0.701996	test: 0.802049
PRC train: 0.960497	val: 0.592846	test: 0.617127

Epoch: 98
Loss: 0.07431482046937304
ROC train: 0.993530	val: 0.716698	test: 0.801888
PRC train: 0.963818	val: 0.595803	test: 0.618783

Epoch: 99
Loss: 0.07066302497656678
ROC train: 0.992703	val: 0.737894	test: 0.799605
PRC train: 0.959273	val: 0.603793	test: 0.619027

Epoch: 100
Loss: 0.08939345038361003
ROC train: 0.993004	val: 0.749010	test: 0.805978
PRC train: 0.961476	val: 0.607542	test: 0.621843

Epoch: 101
Loss: 0.07603158524961426
ROC train: 0.993937	val: 0.735761	test: 0.820596
PRC train: 0.963764	val: 0.595382	test: 0.626521

Epoch: 102
Loss: 0.08150387899299649
ROC train: 0.993611	val: 0.726233	test: 0.821901
PRC train: 0.963256	val: 0.591946	test: 0.641238

Epoch: 103
Loss: 0.08475349634938388
ROC train: 0.993875	val: 0.731441	test: 0.815746
PRC train: 0.965594	val: 0.594811	test: 0.624560

Epoch: 104
Loss: 0.08270672155387285
ROC train: 0.992020	val: 0.714662	test: 0.802999
PRC train: 0.953203	val: 0.593920	test: 0.622760

Epoch: 105
Loss: 0.08474937029764934
ROC train: 0.993613	val: 0.696497	test: 0.802240
PRC train: 0.957159	val: 0.583853	test: 0.622467

Epoch: 106
Loss: 0.08136512079171297
ROC train: 0.994071	val: 0.678803	test: 0.796162
PRC train: 0.962269	val: 0.577445	test: 0.615533

Epoch: 107
Loss: 0.07664325236360767
ROC train: 0.992744	val: 0.704931	test: 0.784353
PRC train: 0.956394	val: 0.603666	test: 0.617907

Epoch: 108
Loss: 0.0666228332766732
ROC train: 0.992504	val: 0.717997	test: 0.792030
PRC train: 0.956194	val: 0.600382	test: 0.620787

Epoch: 109
Loss: 0.07272512165298431
ROC train: 0.993550	val: 0.730878	test: 0.800038
PRC train: 0.963500	val: 0.591263	test: 0.625317

Epoch: 110
Loss: 0.081964881201068
ROC train: 0.993313	val: 0.738827	test: 0.799374
PRC train: 0.962393	val: 0.584211	test: 0.635196

Epoch: 111
Loss: 0.07993850874524323
ROC train: 0.993997	val: 0.736936	test: 0.798970
PRC train: 0.964623	val: 0.580007	test: 0.620232

Epoch: 112
Loss: 0.07124766321897107
ROC train: 0.994154	val: 0.727609	test: 0.808441
PRC train: 0.965465	val: 0.574041	test: 0.635935

Epoch: 113
Loss: 0.0809212770981475
ROC train: 0.994574	val: 0.714831	test: 0.814754
PRC train: 0.967441	val: 0.570693	test: 0.636046

Epoch: 114
Loss: 0.07761965642790224
ROC train: 0.994433	val: 0.718802	test: 0.816482
PRC train: 0.967999	val: 0.577964	test: 0.623324

Epoch: 115
Loss: 0.07776763103398782
ROC train: 0.993717	val: 0.730124	test: 0.806319
PRC train: 0.965562	val: 0.582356	test: 0.609473

Epoch: 116
Loss: 0.06850093206440486
ROC train: 0.994547	val: 0.723997	test: 0.816277
PRC train: 0.970291	val: 0.578925	test: 0.624286

Epoch: 117
Loss: 0.06747749919949379
ROC train: 0.994514	val: 0.731414	test: 0.813396
PRC train: 0.968211	val: 0.577471	test: 0.642003

Epoch: 118
Loss: 0.06734031663372972
ROC train: 0.994130	val: 0.738702	test: 0.806516
PRC train: 0.964282	val: 0.573467	test: 0.637138

Epoch: 119
Loss: 0.075958730467203
ROC train: 0.994349	val: 0.740157	test: 0.815752
PRC train: 0.967675	val: 0.576571	test: 0.627487

Epoch: 120
Loss: 0.08212278174726224
ROC train: 0.993896	val: 0.746391	test: 0.804011
PRC train: 0.964516	val: 0.586988	test: 0.623818

Epoch: 121
Loss: 0.07270840325363041
ROC train: 0.994594	val: 0.731320	test: 0.795530
PRC train: 0.968600	val: 0.589019	test: 0.615265

Epoch: 122
Loss: 0.07515525388850108
ROC train: 0.993366	val: 0.720185	test: 0.798924
PRC train: 0.964187	val: 0.589366	test: 0.619873

Early stopping
Best (ROC):	 train: 0.991162	val: 0.753230	test: 0.809033
Best (PRC):	 train: 0.949157	val: 0.589982	test: 0.622840
All runs completed.

ROC train: 0.949994	val: 0.653401	test: 0.858861
PRC train: 0.815158	val: 0.577733	test: 0.654422

Epoch: 95
Loss: 0.13004516438245184
ROC train: 0.949877	val: 0.651364	test: 0.866179
PRC train: 0.830852	val: 0.571281	test: 0.655061

Epoch: 96
Loss: 0.16541804961382153
ROC train: 0.952745	val: 0.656309	test: 0.866120
PRC train: 0.835326	val: 0.571889	test: 0.661736

Epoch: 97
Loss: 0.12876997942869295
ROC train: 0.952108	val: 0.651138	test: 0.852015
PRC train: 0.821663	val: 0.583409	test: 0.650872

Epoch: 98
Loss: 0.16818001836475477
ROC train: 0.959243	val: 0.650552	test: 0.854333
PRC train: 0.847354	val: 0.588537	test: 0.654139

Epoch: 99
Loss: 0.11082640397894258
ROC train: 0.952212	val: 0.648082	test: 0.833166
PRC train: 0.814344	val: 0.566901	test: 0.624916

Epoch: 100
Loss: 0.17275898665934428
ROC train: 0.955460	val: 0.658259	test: 0.855283
PRC train: 0.837408	val: 0.579550	test: 0.655801

Epoch: 101
Loss: 0.1698641576518791
ROC train: 0.930606	val: 0.671497	test: 0.874212
PRC train: 0.799823	val: 0.563549	test: 0.673443

Epoch: 102
Loss: 0.1529122785579657
ROC train: 0.904709	val: 0.666347	test: 0.896511
PRC train: 0.764887	val: 0.560086	test: 0.664250

Epoch: 103
Loss: 0.1813310492992414
ROC train: 0.892229	val: 0.644179	test: 0.858042
PRC train: 0.763082	val: 0.550310	test: 0.643632

Epoch: 104
Loss: 0.16162054377446664
ROC train: 0.890228	val: 0.600031	test: 0.809439
PRC train: 0.769643	val: 0.534875	test: 0.619451

Epoch: 105
Loss: 0.1514675132714285
ROC train: 0.919964	val: 0.586117	test: 0.829061
PRC train: 0.782497	val: 0.530195	test: 0.629372

Epoch: 106
Loss: 0.15129034738857766
ROC train: 0.946082	val: 0.598670	test: 0.866404
PRC train: 0.831581	val: 0.532774	test: 0.644984

Epoch: 107
Loss: 0.2466178848914237
ROC train: 0.947908	val: 0.602846	test: 0.878602
PRC train: 0.848852	val: 0.535333	test: 0.683948

Epoch: 108
Loss: 0.24868318359100933
ROC train: 0.930044	val: 0.586103	test: 0.882254
PRC train: 0.822186	val: 0.539564	test: 0.679335

Epoch: 109
Loss: 0.1618738111750277
ROC train: 0.924873	val: 0.602070	test: 0.867598
PRC train: 0.797775	val: 0.548226	test: 0.673177

Epoch: 110
Loss: 0.14478262303984515
ROC train: 0.925690	val: 0.624210	test: 0.852206
PRC train: 0.780798	val: 0.576179	test: 0.644403

Epoch: 111
Loss: 0.15068977314414267
ROC train: 0.931988	val: 0.623766	test: 0.847292
PRC train: 0.788920	val: 0.571892	test: 0.641758

Epoch: 112
Loss: 0.13313185635147312
ROC train: 0.953908	val: 0.632812	test: 0.852570
PRC train: 0.857151	val: 0.566794	test: 0.654192

Epoch: 113
Loss: 0.12766073227705813
ROC train: 0.961036	val: 0.634942	test: 0.863466
PRC train: 0.869763	val: 0.573820	test: 0.657624

Epoch: 114
Loss: 0.12759054064827674
ROC train: 0.962274	val: 0.631877	test: 0.865838
PRC train: 0.867110	val: 0.561514	test: 0.649569

Epoch: 115
Loss: 0.11724071432430179
ROC train: 0.963932	val: 0.636503	test: 0.874736
PRC train: 0.870452	val: 0.566643	test: 0.666864

Epoch: 116
Loss: 0.12827286019639608
ROC train: 0.964651	val: 0.636703	test: 0.870553
PRC train: 0.877591	val: 0.574398	test: 0.662643

Epoch: 117
Loss: 0.11528805303851672
ROC train: 0.963359	val: 0.634294	test: 0.867910
PRC train: 0.867225	val: 0.571524	test: 0.662505

Epoch: 118
Loss: 0.14674359165107181
ROC train: 0.964902	val: 0.640594	test: 0.866104
PRC train: 0.872149	val: 0.587883	test: 0.660076

Epoch: 119
Loss: 0.11186943657856727
ROC train: 0.948797	val: 0.638608	test: 0.858162
PRC train: 0.848581	val: 0.588254	test: 0.653262

Epoch: 120
Loss: 0.20709577106472538
ROC train: 0.955428	val: 0.640679	test: 0.861095
PRC train: 0.855770	val: 0.589122	test: 0.653842

Early stopping
Best (ROC):	 train: 0.899654	val: 0.722391	test: 0.831912
Best (PRC):	 train: 0.746384	val: 0.579724	test: 0.612479

ROC train: 0.989217	val: 0.737299	test: 0.854621
PRC train: 0.934766	val: 0.602623	test: 0.621989

Epoch: 95
Loss: 0.08667646304056079
ROC train: 0.990119	val: 0.721591	test: 0.846261
PRC train: 0.938665	val: 0.590991	test: 0.645714

Epoch: 96
Loss: 0.08613382162206579
ROC train: 0.990767	val: 0.720254	test: 0.850187
PRC train: 0.947070	val: 0.597073	test: 0.648191

Epoch: 97
Loss: 0.09268521363923783
ROC train: 0.990825	val: 0.715241	test: 0.876104
PRC train: 0.947481	val: 0.603292	test: 0.668022

Epoch: 98
Loss: 0.08594818350558672
ROC train: 0.990872	val: 0.710561	test: 0.876834
PRC train: 0.945395	val: 0.603004	test: 0.670737

Epoch: 99
Loss: 0.10909641142091062
ROC train: 0.990928	val: 0.720588	test: 0.885463
PRC train: 0.945688	val: 0.609910	test: 0.672620

Epoch: 100
Loss: 0.08128065532448567
ROC train: 0.988836	val: 0.726270	test: 0.878527
PRC train: 0.936873	val: 0.611700	test: 0.658908

Epoch: 101
Loss: 0.09698874925578245
ROC train: 0.990875	val: 0.732955	test: 0.864192
PRC train: 0.941543	val: 0.588963	test: 0.652275

Epoch: 102
Loss: 0.07952450228970981
ROC train: 0.990713	val: 0.767714	test: 0.880852
PRC train: 0.941860	val: 0.608063	test: 0.668019

Epoch: 103
Loss: 0.09455221221741186
ROC train: 0.989660	val: 0.758021	test: 0.881571
PRC train: 0.937755	val: 0.602925	test: 0.669091

Epoch: 104
Loss: 0.0980257486187519
ROC train: 0.990029	val: 0.739639	test: 0.868058
PRC train: 0.936261	val: 0.593229	test: 0.671081

Epoch: 105
Loss: 0.0847511911625358
ROC train: 0.991622	val: 0.727941	test: 0.883953
PRC train: 0.946041	val: 0.587318	test: 0.665209

Epoch: 106
Loss: 0.086469101735479
ROC train: 0.991906	val: 0.709225	test: 0.868164
PRC train: 0.948394	val: 0.571542	test: 0.652209

Epoch: 107
Loss: 0.08218482997521204
ROC train: 0.990940	val: 0.706551	test: 0.846321
PRC train: 0.940917	val: 0.578729	test: 0.642684

Epoch: 108
Loss: 0.08296062314952027
ROC train: 0.990985	val: 0.724933	test: 0.854590
PRC train: 0.942326	val: 0.584764	test: 0.648989

Epoch: 109
Loss: 0.08789398081134517
ROC train: 0.991585	val: 0.733623	test: 0.861152
PRC train: 0.947069	val: 0.582827	test: 0.648376

Epoch: 110
Loss: 0.07948429407438894
ROC train: 0.991333	val: 0.732286	test: 0.870769
PRC train: 0.946624	val: 0.588825	test: 0.664717

Epoch: 111
Loss: 0.08570600802936715
ROC train: 0.991470	val: 0.739305	test: 0.871458
PRC train: 0.948218	val: 0.606414	test: 0.660104

Epoch: 112
Loss: 0.08357006779947598
ROC train: 0.990718	val: 0.732286	test: 0.864340
PRC train: 0.942317	val: 0.600445	test: 0.653134

Epoch: 113
Loss: 0.07624242003123152
ROC train: 0.991521	val: 0.731283	test: 0.884401
PRC train: 0.949280	val: 0.605070	test: 0.661860

Epoch: 114
Loss: 0.09284881416647957
ROC train: 0.990974	val: 0.724265	test: 0.887156
PRC train: 0.946382	val: 0.597723	test: 0.675075

Epoch: 115
Loss: 0.0803801183906255
ROC train: 0.992218	val: 0.701537	test: 0.869781
PRC train: 0.952825	val: 0.583312	test: 0.659249

Epoch: 116
Loss: 0.08207617707759403
ROC train: 0.991555	val: 0.714238	test: 0.860883
PRC train: 0.947134	val: 0.582935	test: 0.659015

Epoch: 117
Loss: 0.09657850920665925
ROC train: 0.991422	val: 0.739305	test: 0.879727
PRC train: 0.946320	val: 0.590086	test: 0.672955

Epoch: 118
Loss: 0.08588324132487817
ROC train: 0.992082	val: 0.718583	test: 0.857017
PRC train: 0.951979	val: 0.589868	test: 0.655122

Epoch: 119
Loss: 0.08439936922203584
ROC train: 0.992464	val: 0.724933	test: 0.864147
PRC train: 0.953904	val: 0.594075	test: 0.658623

Epoch: 120
Loss: 0.07562074922438666
ROC train: 0.991767	val: 0.726939	test: 0.857226
PRC train: 0.948668	val: 0.599614	test: 0.625396

Early stopping
Best (ROC):	 train: 0.951831	val: 0.770722	test: 0.890458
Best (PRC):	 train: 0.843090	val: 0.616625	test: 0.671072

ROC train: 0.990420	val: 0.696524	test: 0.865889
PRC train: 0.950625	val: 0.577045	test: 0.643396

Epoch: 95
Loss: 0.09509170894797211
ROC train: 0.990621	val: 0.717580	test: 0.845140
PRC train: 0.946038	val: 0.571566	test: 0.610410

Epoch: 96
Loss: 0.09886779238733343
ROC train: 0.990187	val: 0.737634	test: 0.869304
PRC train: 0.943430	val: 0.588310	test: 0.624099

Epoch: 97
Loss: 0.08576794408564561
ROC train: 0.990631	val: 0.716578	test: 0.870039
PRC train: 0.948832	val: 0.574862	test: 0.651848

Epoch: 98
Loss: 0.0939103646421228
ROC train: 0.991399	val: 0.686832	test: 0.854909
PRC train: 0.953016	val: 0.567086	test: 0.637357

Epoch: 99
Loss: 0.09596093031715155
ROC train: 0.991411	val: 0.689505	test: 0.852931
PRC train: 0.949880	val: 0.570178	test: 0.635322

Epoch: 100
Loss: 0.09166945644918911
ROC train: 0.991663	val: 0.691176	test: 0.843012
PRC train: 0.951416	val: 0.571669	test: 0.609258

Epoch: 101
Loss: 0.08900238735874087
ROC train: 0.990349	val: 0.696524	test: 0.823434
PRC train: 0.937253	val: 0.565822	test: 0.609152

Epoch: 102
Loss: 0.10003904758756914
ROC train: 0.991413	val: 0.697193	test: 0.835630
PRC train: 0.945778	val: 0.565716	test: 0.637513

Epoch: 103
Loss: 0.08694380286249684
ROC train: 0.991318	val: 0.705548	test: 0.861425
PRC train: 0.949830	val: 0.578570	test: 0.645111

Epoch: 104
Loss: 0.08512252168367697
ROC train: 0.990011	val: 0.708890	test: 0.869876
PRC train: 0.948695	val: 0.585195	test: 0.646725

Epoch: 105
Loss: 0.07652421376201016
ROC train: 0.991282	val: 0.711564	test: 0.852376
PRC train: 0.948225	val: 0.587436	test: 0.639966

Epoch: 106
Loss: 0.08805820315475452
ROC train: 0.991577	val: 0.710896	test: 0.850248
PRC train: 0.949120	val: 0.587902	test: 0.617834

Epoch: 107
Loss: 0.07911858563954721
ROC train: 0.991668	val: 0.724265	test: 0.866184
PRC train: 0.948969	val: 0.585976	test: 0.632949

Epoch: 108
Loss: 0.09236963811160803
ROC train: 0.992169	val: 0.732286	test: 0.865555
PRC train: 0.954301	val: 0.577743	test: 0.632479

Epoch: 109
Loss: 0.089014183468625
ROC train: 0.990454	val: 0.732620	test: 0.848586
PRC train: 0.941742	val: 0.576318	test: 0.628650

Epoch: 110
Loss: 0.08479353554494443
ROC train: 0.991169	val: 0.712233	test: 0.846219
PRC train: 0.948404	val: 0.571777	test: 0.619836

Epoch: 111
Loss: 0.088198192755249
ROC train: 0.989759	val: 0.668449	test: 0.812859
PRC train: 0.941610	val: 0.557651	test: 0.631194

Epoch: 112
Loss: 0.08908490447372248
ROC train: 0.990313	val: 0.703209	test: 0.870652
PRC train: 0.946293	val: 0.581843	test: 0.663201

Epoch: 113
Loss: 0.085813468710505
ROC train: 0.991874	val: 0.705548	test: 0.880583
PRC train: 0.953007	val: 0.592064	test: 0.663053

Epoch: 114
Loss: 0.095498160603205
ROC train: 0.992251	val: 0.719251	test: 0.875294
PRC train: 0.953402	val: 0.588436	test: 0.657089

Epoch: 115
Loss: 0.0851448307665781
ROC train: 0.991136	val: 0.723596	test: 0.860027
PRC train: 0.948285	val: 0.612191	test: 0.631689

Epoch: 116
Loss: 0.08393905839589039
ROC train: 0.992368	val: 0.724933	test: 0.865945
PRC train: 0.951588	val: 0.608108	test: 0.638406

Epoch: 117
Loss: 0.08575396639196872
ROC train: 0.991954	val: 0.719586	test: 0.865139
PRC train: 0.952496	val: 0.582217	test: 0.635604

Epoch: 118
Loss: 0.0744520174298237
ROC train: 0.992381	val: 0.722928	test: 0.878020
PRC train: 0.952363	val: 0.579334	test: 0.670929

Epoch: 119
Loss: 0.08330223807354174
ROC train: 0.991567	val: 0.720588	test: 0.867581
PRC train: 0.949268	val: 0.579855	test: 0.661311

Epoch: 120
Loss: 0.09018899526124095
ROC train: 0.992272	val: 0.715575	test: 0.858279
PRC train: 0.956039	val: 0.577227	test: 0.644053

Early stopping
Best (ROC):	 train: 0.896414	val: 0.794786	test: 0.875605
Best (PRC):	 train: 0.734497	val: 0.613385	test: 0.667132
Epoch: 94
Loss: 0.09590980235993517
ROC train: 0.986981	val: 0.780749	test: 0.871061
PRC train: 0.933209	val: 0.596823	test: 0.708498

Epoch: 95
Loss: 0.09295475110218802
ROC train: 0.990223	val: 0.758690	test: 0.836202
PRC train: 0.943389	val: 0.586065	test: 0.700904

Epoch: 96
Loss: 0.08611000719939446
ROC train: 0.990656	val: 0.766711	test: 0.848722
PRC train: 0.950695	val: 0.601695	test: 0.703342

Epoch: 97
Loss: 0.11211115203638958
ROC train: 0.991023	val: 0.768048	test: 0.861005
PRC train: 0.949242	val: 0.602509	test: 0.690716

Epoch: 98
Loss: 0.09752599245787605
ROC train: 0.990596	val: 0.773730	test: 0.873840
PRC train: 0.943157	val: 0.616652	test: 0.707236

Epoch: 99
Loss: 0.0914989163260221
ROC train: 0.990535	val: 0.776070	test: 0.877736
PRC train: 0.942533	val: 0.619101	test: 0.702183

Epoch: 100
Loss: 0.09211819536146615
ROC train: 0.990579	val: 0.766377	test: 0.857453
PRC train: 0.943719	val: 0.605407	test: 0.712059

Epoch: 101
Loss: 0.09188597893086614
ROC train: 0.989969	val: 0.760695	test: 0.856181
PRC train: 0.942962	val: 0.599981	test: 0.707708

Epoch: 102
Loss: 0.09167948229960361
ROC train: 0.991571	val: 0.747660	test: 0.856900
PRC train: 0.951016	val: 0.601578	test: 0.707600

Epoch: 103
Loss: 0.08471462222049359
ROC train: 0.989483	val: 0.767045	test: 0.852527
PRC train: 0.942488	val: 0.594203	test: 0.675803

Epoch: 104
Loss: 0.11295804562773222
ROC train: 0.971195	val: 0.804479	test: 0.882700
PRC train: 0.874357	val: 0.626893	test: 0.700931

Epoch: 105
Loss: 0.09608020661817815
ROC train: 0.959196	val: 0.807821	test: 0.881682
PRC train: 0.844230	val: 0.621318	test: 0.706432

Epoch: 106
Loss: 0.09522220632234965
ROC train: 0.982019	val: 0.785762	test: 0.873590
PRC train: 0.912380	val: 0.606525	test: 0.692876

Epoch: 107
Loss: 0.09462883560627454
ROC train: 0.986488	val: 0.762032	test: 0.856287
PRC train: 0.934748	val: 0.589533	test: 0.691791

Epoch: 108
Loss: 0.0977087742728708
ROC train: 0.989773	val: 0.730281	test: 0.860513
PRC train: 0.943268	val: 0.589929	test: 0.694752

Epoch: 109
Loss: 0.07931789413691129
ROC train: 0.987463	val: 0.698864	test: 0.846802
PRC train: 0.929751	val: 0.569568	test: 0.695179

Epoch: 110
Loss: 0.08544185536441383
ROC train: 0.990023	val: 0.704545	test: 0.852705
PRC train: 0.942396	val: 0.574083	test: 0.690252

Epoch: 111
Loss: 0.09061434262614959
ROC train: 0.991429	val: 0.740307	test: 0.867805
PRC train: 0.949928	val: 0.583492	test: 0.714247

Epoch: 112
Loss: 0.0913661183389374
ROC train: 0.990908	val: 0.757687	test: 0.861902
PRC train: 0.945382	val: 0.593209	test: 0.717822

Epoch: 113
Loss: 0.09337360748273102
ROC train: 0.988439	val: 0.766711	test: 0.863939
PRC train: 0.928271	val: 0.596561	test: 0.723282

Epoch: 114
Loss: 0.1009309787397105
ROC train: 0.990312	val: 0.758356	test: 0.856612
PRC train: 0.942308	val: 0.602211	test: 0.715753

Epoch: 115
Loss: 0.09210644658107042
ROC train: 0.990608	val: 0.775401	test: 0.883381
PRC train: 0.946952	val: 0.617478	test: 0.707870

Epoch: 116
Loss: 0.08892387751682965
ROC train: 0.990961	val: 0.789773	test: 0.886471
PRC train: 0.949632	val: 0.615061	test: 0.688585

Epoch: 117
Loss: 0.09066780519267759
ROC train: 0.991046	val: 0.788102	test: 0.886501
PRC train: 0.949525	val: 0.610740	test: 0.703073

Epoch: 118
Loss: 0.08933889252207858
ROC train: 0.991763	val: 0.790441	test: 0.888284
PRC train: 0.952496	val: 0.610469	test: 0.701036

Epoch: 119
Loss: 0.09086055784962777
ROC train: 0.992231	val: 0.767380	test: 0.875582
PRC train: 0.955595	val: 0.609520	test: 0.691410

Epoch: 120
Loss: 0.08379837244501634
ROC train: 0.991861	val: 0.755682	test: 0.874067
PRC train: 0.954064	val: 0.606556	test: 0.689151

Early stopping
Best (ROC):	 train: 0.974568	val: 0.808489	test: 0.898432
Best (PRC):	 train: 0.881662	val: 0.612896	test: 0.729805
All runs completed.

ROC train: 0.932428	val: 0.577595	test: 0.770426
PRC train: 0.796799	val: 0.540946	test: 0.612863

Epoch: 95
Loss: 0.14569539590293396
ROC train: 0.947490	val: 0.603336	test: 0.811006
PRC train: 0.815108	val: 0.550927	test: 0.646149

Epoch: 96
Loss: 0.18147342275041498
ROC train: 0.958109	val: 0.619635	test: 0.861777
PRC train: 0.849252	val: 0.559876	test: 0.658631

Epoch: 97
Loss: 0.1423587261323121
ROC train: 0.955619	val: 0.632544	test: 0.880685
PRC train: 0.851229	val: 0.560979	test: 0.673514

Epoch: 98
Loss: 0.12594057141337997
ROC train: 0.941855	val: 0.655836	test: 0.855428
PRC train: 0.809261	val: 0.569749	test: 0.628876

Epoch: 99
Loss: 0.16863661396480434
ROC train: 0.946590	val: 0.695698	test: 0.849238
PRC train: 0.810346	val: 0.586401	test: 0.620095

Epoch: 100
Loss: 0.16092772166335853
ROC train: 0.943515	val: 0.709974	test: 0.870730
PRC train: 0.796970	val: 0.573176	test: 0.632242

Epoch: 101
Loss: 0.15398844931123465
ROC train: 0.947295	val: 0.709825	test: 0.893932
PRC train: 0.792547	val: 0.565498	test: 0.643603

Epoch: 102
Loss: 0.17986504749613333
ROC train: 0.959138	val: 0.713956	test: 0.912102
PRC train: 0.817754	val: 0.578232	test: 0.688115

Epoch: 103
Loss: 0.14925177974012574
ROC train: 0.949908	val: 0.672074	test: 0.889936
PRC train: 0.813316	val: 0.581907	test: 0.664111

Epoch: 104
Loss: 0.12885860182736436
ROC train: 0.958229	val: 0.665362	test: 0.894732
PRC train: 0.846542	val: 0.583395	test: 0.678915

Epoch: 105
Loss: 0.16947343946943594
ROC train: 0.955231	val: 0.675317	test: 0.904441
PRC train: 0.838989	val: 0.577451	test: 0.686345

Epoch: 106
Loss: 0.1555796475857637
ROC train: 0.936061	val: 0.689566	test: 0.900457
PRC train: 0.805233	val: 0.560461	test: 0.690348

Epoch: 107
Loss: 0.18451917853942748
ROC train: 0.935325	val: 0.725328	test: 0.875269
PRC train: 0.785786	val: 0.582742	test: 0.661883

Epoch: 108
Loss: 0.12816519139424493
ROC train: 0.938878	val: 0.739452	test: 0.833204
PRC train: 0.785712	val: 0.594567	test: 0.646175

Epoch: 109
Loss: 0.219791396794139
ROC train: 0.951541	val: 0.718998	test: 0.860321
PRC train: 0.808585	val: 0.598408	test: 0.673887

Epoch: 110
Loss: 0.12766014698110079
ROC train: 0.935158	val: 0.655562	test: 0.867098
PRC train: 0.804887	val: 0.577360	test: 0.683218

Epoch: 111
Loss: 0.16746601603593098
ROC train: 0.929111	val: 0.646477	test: 0.867322
PRC train: 0.811934	val: 0.579715	test: 0.686428

Epoch: 112
Loss: 0.16419396001405445
ROC train: 0.944457	val: 0.647877	test: 0.866018
PRC train: 0.833806	val: 0.580510	test: 0.676200

Epoch: 113
Loss: 0.12112304554757973
ROC train: 0.952385	val: 0.665763	test: 0.872545
PRC train: 0.830276	val: 0.586028	test: 0.674917

Epoch: 114
Loss: 0.1275616953837575
ROC train: 0.960049	val: 0.680738	test: 0.874399
PRC train: 0.834577	val: 0.591488	test: 0.657185

Epoch: 115
Loss: 0.13580995640247256
ROC train: 0.965324	val: 0.687990	test: 0.880087
PRC train: 0.840616	val: 0.592475	test: 0.651838

Epoch: 116
Loss: 0.12578158192884162
ROC train: 0.967404	val: 0.683618	test: 0.887666
PRC train: 0.852125	val: 0.604151	test: 0.654642

Epoch: 117
Loss: 0.1218967023080236
ROC train: 0.970077	val: 0.683097	test: 0.888217
PRC train: 0.862313	val: 0.605230	test: 0.657006

Epoch: 118
Loss: 0.11980256205516167
ROC train: 0.971840	val: 0.684350	test: 0.882993
PRC train: 0.872165	val: 0.603840	test: 0.652277

Epoch: 119
Loss: 0.16135926705649778
ROC train: 0.974188	val: 0.684544	test: 0.889851
PRC train: 0.881571	val: 0.610809	test: 0.665971

Epoch: 120
Loss: 0.11615227765605347
ROC train: 0.969904	val: 0.673733	test: 0.876434
PRC train: 0.873604	val: 0.599740	test: 0.653191

Epoch: 121
Loss: 0.2029520655194791
ROC train: 0.972453	val: 0.663281	test: 0.871504
PRC train: 0.875860	val: 0.601268	test: 0.647382

Epoch: 122
Loss: 0.12836413530711202
ROC train: 0.958752	val: 0.640073	test: 0.853036
PRC train: 0.825678	val: 0.571571	test: 0.626422

Epoch: 123
Loss: 0.15722648385269702
ROC train: 0.950630	val: 0.630163	test: 0.837018
PRC train: 0.804210	val: 0.558320	test: 0.622731

Epoch: 124
Loss: 0.12892605228471962
ROC train: 0.922615	val: 0.587192	test: 0.810750
PRC train: 0.769523	val: 0.560731	test: 0.619907

Epoch: 125
Loss: 0.21191590590192577
ROC train: 0.925635	val: 0.566982	test: 0.844718
PRC train: 0.804050	val: 0.548329	test: 0.650116

Epoch: 126
Loss: 0.17306394653406915
ROC train: 0.902117	val: 0.556897	test: 0.858274
PRC train: 0.777262	val: 0.525028	test: 0.670673

Epoch: 127
Loss: 0.13491002955731152
ROC train: 0.899521	val: 0.569495	test: 0.842219
PRC train: 0.766302	val: 0.530477	test: 0.645283

Epoch: 128
Loss: 0.19107209021610833
ROC train: 0.932136	val: 0.591298	test: 0.842000
PRC train: 0.802397	val: 0.541796	test: 0.651539

Epoch: 129
Loss: 0.12636989227719425
ROC train: 0.943007	val: 0.606680	test: 0.834043
PRC train: 0.822860	val: 0.558512	test: 0.653413

Epoch: 130
Loss: 0.13260500958003288
ROC train: 0.954066	val: 0.614950	test: 0.829733
PRC train: 0.846676	val: 0.573233	test: 0.657405

Epoch: 131
Loss: 0.13041729911734773
ROC train: 0.956546	val: 0.620246	test: 0.823569
PRC train: 0.852807	val: 0.579739	test: 0.645162

Epoch: 132
Loss: 0.20227408844445213
ROC train: 0.961133	val: 0.621186	test: 0.838204
PRC train: 0.862745	val: 0.579614	test: 0.649149

Epoch: 133
Loss: 0.16109529938844927
ROC train: 0.961372	val: 0.606621	test: 0.859183
PRC train: 0.863251	val: 0.578863	test: 0.670097

Epoch: 134
Loss: 0.12528495371691034
ROC train: 0.957173	val: 0.606133	test: 0.861443
PRC train: 0.847479	val: 0.560583	test: 0.676002

Epoch: 135
Loss: 0.12516983035788237
ROC train: 0.960722	val: 0.627834	test: 0.862250
PRC train: 0.845130	val: 0.571574	test: 0.672973

Epoch: 136
Loss: 0.11569677443558371
ROC train: 0.958299	val: 0.647325	test: 0.860841
PRC train: 0.826618	val: 0.575529	test: 0.673184

Epoch: 137
Loss: 0.13427465613941678
ROC train: 0.965076	val: 0.653344	test: 0.868691
PRC train: 0.845256	val: 0.580114	test: 0.678439

Epoch: 138
Loss: 0.11486799926147069
ROC train: 0.970734	val: 0.648162	test: 0.880350
PRC train: 0.866382	val: 0.589620	test: 0.681659

Epoch: 139
Loss: 0.1199984204685012
ROC train: 0.970824	val: 0.657252	test: 0.886610
PRC train: 0.866406	val: 0.588260	test: 0.675467

Epoch: 140
Loss: 0.1260318383373698
ROC train: 0.963987	val: 0.666045	test: 0.898985
PRC train: 0.848512	val: 0.587425	test: 0.688841

Epoch: 141
Loss: 0.15519645887516773
ROC train: 0.952524	val: 0.639673	test: 0.902910
PRC train: 0.818744	val: 0.569562	test: 0.685121

Epoch: 142
Loss: 0.13339465723118757
ROC train: 0.943687	val: 0.621222	test: 0.895908
PRC train: 0.792867	val: 0.552878	test: 0.682948

Epoch: 143
Loss: 0.13098866135427104
ROC train: 0.959087	val: 0.621271	test: 0.896165
PRC train: 0.815939	val: 0.551101	test: 0.673110

Early stopping
Best (ROC):	 train: 0.938878	val: 0.739452	test: 0.833204
Best (PRC):	 train: 0.785712	val: 0.594567	test: 0.646175

ROC train: 0.940459	val: 0.674362	test: 0.886869
PRC train: 0.802053	val: 0.579858	test: 0.733829

Epoch: 95
Loss: 0.13946052638620254
ROC train: 0.948617	val: 0.700813	test: 0.865116
PRC train: 0.800733	val: 0.591119	test: 0.696353

Epoch: 96
Loss: 0.2183167241190631
ROC train: 0.951049	val: 0.700560	test: 0.841915
PRC train: 0.795977	val: 0.597721	test: 0.649525

Epoch: 97
Loss: 0.18766283650224888
ROC train: 0.935896	val: 0.664999	test: 0.837840
PRC train: 0.764152	val: 0.559463	test: 0.599484

Epoch: 98
Loss: 0.14202124673257246
ROC train: 0.931794	val: 0.649189	test: 0.866413
PRC train: 0.757857	val: 0.546398	test: 0.633001

Epoch: 99
Loss: 0.16959793595388387
ROC train: 0.942306	val: 0.662613	test: 0.891259
PRC train: 0.805083	val: 0.568918	test: 0.697368

Epoch: 100
Loss: 0.13052051052968155
ROC train: 0.935115	val: 0.674709	test: 0.872460
PRC train: 0.787842	val: 0.584792	test: 0.693080

Epoch: 101
Loss: 0.13269790785973373
ROC train: 0.941183	val: 0.690138	test: 0.851150
PRC train: 0.801449	val: 0.600925	test: 0.696350

Epoch: 102
Loss: 0.1396188301372814
ROC train: 0.941608	val: 0.691060	test: 0.853265
PRC train: 0.805049	val: 0.589720	test: 0.676811

Epoch: 103
Loss: 0.13456289833689353
ROC train: 0.938200	val: 0.690627	test: 0.864823
PRC train: 0.796459	val: 0.580938	test: 0.681694

Epoch: 104
Loss: 0.1318040549328353
ROC train: 0.941791	val: 0.683314	test: 0.872845
PRC train: 0.803199	val: 0.577551	test: 0.687864

Epoch: 105
Loss: 0.12808948783254723
ROC train: 0.946709	val: 0.665176	test: 0.885823
PRC train: 0.817693	val: 0.576790	test: 0.707317

Epoch: 106
Loss: 0.1726746320264072
ROC train: 0.954115	val: 0.661869	test: 0.893973
PRC train: 0.831967	val: 0.582428	test: 0.720883

Epoch: 107
Loss: 0.13065144462719314
ROC train: 0.951961	val: 0.697428	test: 0.879815
PRC train: 0.811514	val: 0.582788	test: 0.700080

Epoch: 108
Loss: 0.14850233010051098
ROC train: 0.953921	val: 0.704098	test: 0.886818
PRC train: 0.804105	val: 0.591052	test: 0.705121

Epoch: 109
Loss: 0.13551259460864132
ROC train: 0.957445	val: 0.695017	test: 0.895065
PRC train: 0.819262	val: 0.592632	test: 0.737400

Epoch: 110
Loss: 0.11834235982922743
ROC train: 0.962242	val: 0.678201	test: 0.899187
PRC train: 0.839457	val: 0.589246	test: 0.736012

Epoch: 111
Loss: 0.12199906594776141
ROC train: 0.957000	val: 0.682993	test: 0.891400
PRC train: 0.822582	val: 0.578455	test: 0.720084

Epoch: 112
Loss: 0.12798544522272792
ROC train: 0.953204	val: 0.685208	test: 0.887757
PRC train: 0.814440	val: 0.576901	test: 0.712950

Epoch: 113
Loss: 0.15044513319248737
ROC train: 0.952967	val: 0.683165	test: 0.887523
PRC train: 0.816607	val: 0.573823	test: 0.695264

Epoch: 114
Loss: 0.14894558624352888
ROC train: 0.956619	val: 0.673657	test: 0.899672
PRC train: 0.834629	val: 0.586686	test: 0.740268

Epoch: 115
Loss: 0.12309939246891652
ROC train: 0.955965	val: 0.697548	test: 0.897392
PRC train: 0.840814	val: 0.582326	test: 0.732704

Epoch: 116
Loss: 0.11560513522653226
ROC train: 0.953835	val: 0.704753	test: 0.894060
PRC train: 0.832170	val: 0.582695	test: 0.722643

Epoch: 117
Loss: 0.12697316576187398
ROC train: 0.957317	val: 0.706214	test: 0.888665
PRC train: 0.838784	val: 0.588251	test: 0.716657

Epoch: 118
Loss: 0.1256678222994366
ROC train: 0.960648	val: 0.704781	test: 0.888996
PRC train: 0.842428	val: 0.590288	test: 0.722090

Epoch: 119
Loss: 0.18968848644346487
ROC train: 0.963323	val: 0.705302	test: 0.886037
PRC train: 0.844257	val: 0.590065	test: 0.714029

Epoch: 120
Loss: 0.17569264169313564
ROC train: 0.962717	val: 0.719254	test: 0.861651
PRC train: 0.831305	val: 0.585543	test: 0.690909

Epoch: 121
Loss: 0.11915460127139041
ROC train: 0.952889	val: 0.715844	test: 0.855326
PRC train: 0.818681	val: 0.581082	test: 0.683214

Epoch: 122
Loss: 0.12007738344895616
ROC train: 0.960979	val: 0.710631	test: 0.873101
PRC train: 0.834569	val: 0.578149	test: 0.702851

Epoch: 123
Loss: 0.14652088473244915
ROC train: 0.965168	val: 0.693061	test: 0.899992
PRC train: 0.851362	val: 0.577376	test: 0.731629

Epoch: 124
Loss: 0.11577833050049043
ROC train: 0.963551	val: 0.690212	test: 0.896034
PRC train: 0.845843	val: 0.576332	test: 0.736047

Epoch: 125
Loss: 0.2999457681329596
ROC train: 0.958592	val: 0.695698	test: 0.885672
PRC train: 0.828534	val: 0.572382	test: 0.695521

Epoch: 126
Loss: 0.12850618467868966
ROC train: 0.922789	val: 0.664085	test: 0.860347
PRC train: 0.761810	val: 0.552176	test: 0.644031

Epoch: 127
Loss: 0.2987988790304319
ROC train: 0.943038	val: 0.693665	test: 0.877332
PRC train: 0.804281	val: 0.567056	test: 0.673612

Epoch: 128
Loss: 0.14734513274244926
ROC train: 0.950219	val: 0.688255	test: 0.894786
PRC train: 0.827985	val: 0.565504	test: 0.714099

Epoch: 129
Loss: 0.17080241093397197
ROC train: 0.952108	val: 0.692997	test: 0.901387
PRC train: 0.827593	val: 0.566734	test: 0.703099

Epoch: 130
Loss: 0.1404623885794966
ROC train: 0.956531	val: 0.699297	test: 0.900373
PRC train: 0.829434	val: 0.569731	test: 0.703999

Epoch: 131
Loss: 0.1751702657889544
ROC train: 0.961839	val: 0.723826	test: 0.907487
PRC train: 0.844054	val: 0.582832	test: 0.710929

Epoch: 132
Loss: 0.12305651256821507
ROC train: 0.955745	val: 0.727598	test: 0.885017
PRC train: 0.827333	val: 0.581884	test: 0.685364

Epoch: 133
Loss: 0.1234532889336146
ROC train: 0.958441	val: 0.726864	test: 0.880120
PRC train: 0.842012	val: 0.581055	test: 0.680051

Epoch: 134
Loss: 0.13609188804847644
ROC train: 0.966628	val: 0.727831	test: 0.884681
PRC train: 0.860475	val: 0.586125	test: 0.690727

Epoch: 135
Loss: 0.11600246882572188
ROC train: 0.970032	val: 0.728571	test: 0.890860
PRC train: 0.870649	val: 0.589289	test: 0.699369

Epoch: 136
Loss: 0.117556533561524
ROC train: 0.971043	val: 0.715889	test: 0.907594
PRC train: 0.873305	val: 0.583925	test: 0.726901

Epoch: 137
Loss: 0.11078210847098187
ROC train: 0.970856	val: 0.715882	test: 0.910638
PRC train: 0.870367	val: 0.589151	test: 0.734186

Epoch: 138
Loss: 0.11104069934664589
ROC train: 0.970874	val: 0.712116	test: 0.910237
PRC train: 0.868081	val: 0.588403	test: 0.738004

Epoch: 139
Loss: 0.10279225350154333
ROC train: 0.971664	val: 0.708600	test: 0.912496
PRC train: 0.870663	val: 0.582923	test: 0.741552

Epoch: 140
Loss: 0.10960934771336364
ROC train: 0.973491	val: 0.713579	test: 0.912859
PRC train: 0.874251	val: 0.587432	test: 0.739492

Epoch: 141
Loss: 0.09713946755197159
ROC train: 0.974796	val: 0.713099	test: 0.908373
PRC train: 0.882069	val: 0.583235	test: 0.726623

Epoch: 142
Loss: 0.10898484080127288
ROC train: 0.976887	val: 0.725636	test: 0.909906
PRC train: 0.889319	val: 0.590771	test: 0.721798

Epoch: 143
Loss: 0.30754813740054343
ROC train: 0.968511	val: 0.718104	test: 0.914857
PRC train: 0.874231	val: 0.591225	test: 0.722445

Epoch: 144
Loss: 0.1553704749791339
ROC train: 0.859393	val: 0.667660	test: 0.894999
PRC train: 0.675616	val: 0.556577	test: 0.691534

Epoch: 145
Loss: 0.22636835329809676
ROC train: 0.889885	val: 0.705924	test: 0.898387
PRC train: 0.711194	val: 0.569644	test: 0.686407

Epoch: 146
Loss: 0.1476056297927197
ROC train: 0.932531	val: 0.780243	test: 0.853030
PRC train: 0.779199	val: 0.596564	test: 0.671179

Epoch: 147
Loss: 0.22373814784385174
ROC train: 0.939053	val: 0.767599	test: 0.834303
PRC train: 0.797033	val: 0.590188	test: 0.646152

Epoch: 148
Loss: 0.14479519762855547
ROC train: 0.952046	val: 0.710866	test: 0.846897
PRC train: 0.814068	val: 0.580333	test: 0.652955

Epoch: 149
Loss: 0.18939347915537397
ROC train: 0.940891	val: 0.664925	test: 0.851864
PRC train: 0.802387	val: 0.558549	test: 0.660202

Epoch: 150
Loss: 0.13677794722175068
ROC train: 0.939381	val: 0.641466	test: 0.859485
PRC train: 0.814448	val: 0.545346	test: 0.653422

Epoch: 151
Loss: 0.16503605917143796
ROC train: 0.958879	val: 0.678974	test: 0.862131
PRC train: 0.837241	val: 0.558394	test: 0.633475

Epoch: 152
Loss: 0.1116472711691803
ROC train: 0.958889	val: 0.715248	test: 0.836333
PRC train: 0.823858	val: 0.579907	test: 0.608145

Epoch: 153
Loss: 0.1211912953740498
ROC train: 0.962704	val: 0.718924	test: 0.849152
PRC train: 0.829513	val: 0.586497	test: 0.633313

Epoch: 154
Loss: 0.12031882894399697
ROC train: 0.969355	val: 0.710383	test: 0.880877
PRC train: 0.852577	val: 0.585048	test: 0.694833

Epoch: 155
Loss: 0.1145166235899521
ROC train: 0.965866	val: 0.695283	test: 0.892569
PRC train: 0.858874	val: 0.585680	test: 0.704508

Epoch: 156
Loss: 0.13290767405854315
ROC train: 0.967436	val: 0.692754	test: 0.900014
PRC train: 0.860823	val: 0.588632	test: 0.699662

Epoch: 157
Loss: 0.13529632874965278
ROC train: 0.964604	val: 0.704074	test: 0.888664
PRC train: 0.851146	val: 0.594271	test: 0.685342

Epoch: 158
Loss: 0.1277768721891413
ROC train: 0.971551	val: 0.705085	test: 0.873816
PRC train: 0.854863	val: 0.600491	test: 0.657658

Epoch: 159
Loss: 0.13092634414384494
ROC train: 0.975547	val: 0.706945	test: 0.881128
PRC train: 0.877576	val: 0.598573	test: 0.657080

Epoch: 160
Loss: 0.1088145663029293
ROC train: 0.973934	val: 0.712834	test: 0.903287
PRC train: 0.879516	val: 0.596590	test: 0.691608

Epoch: 161
Loss: 0.11330420871378324
ROC train: 0.970453	val: 0.716216	test: 0.907742
PRC train: 0.877991	val: 0.591630	test: 0.702543

Epoch: 162
Loss: 0.14298046833221317
ROC train: 0.972696	val: 0.729622	test: 0.912881
PRC train: 0.875548	val: 0.592488	test: 0.715682

Epoch: 163
Loss: 0.14678971491024276
ROC train: 0.971948	val: 0.742018	test: 0.911321
PRC train: 0.859472	val: 0.597717	test: 0.699124

Epoch: 164
Loss: 0.12446851547986489
ROC train: 0.959319	val: 0.745709	test: 0.872711
PRC train: 0.809384	val: 0.592938	test: 0.651932

Epoch: 165
Loss: 0.12308330425082034
ROC train: 0.946999	val: 0.708185	test: 0.880279
PRC train: 0.824422	val: 0.579768	test: 0.668143

Epoch: 166
Loss: 0.26576297839229246
ROC train: 0.946612	val: 0.699858	test: 0.884209
PRC train: 0.832476	val: 0.569129	test: 0.664654

Epoch: 167
Loss: 0.1379907802005549
ROC train: 0.962775	val: 0.731640	test: 0.896403
PRC train: 0.838719	val: 0.579167	test: 0.676128

Epoch: 168
Loss: 0.11738148121310352
ROC train: 0.963569	val: 0.734906	test: 0.900243
PRC train: 0.839666	val: 0.596917	test: 0.698772

Epoch: 169
Loss: 0.12115235544287999
ROC train: 0.966284	val: 0.724425	test: 0.900467
PRC train: 0.851606	val: 0.599883	test: 0.696792

Epoch: 170
Loss: 0.12187487508421517
ROC train: 0.968591	val: 0.706907	test: 0.889144
PRC train: 0.859436	val: 0.597262	test: 0.685112

Epoch: 171
Loss: 0.1263536317731222
ROC train: 0.969883	val: 0.700733	test: 0.885993
PRC train: 0.873150	val: 0.593525	test: 0.680643

Epoch: 172
Loss: 0.12980723050234702
ROC train: 0.970900	val: 0.701110	test: 0.890523
PRC train: 0.878261	val: 0.594550	test: 0.686503

Epoch: 173
Loss: 0.14868682169424047
ROC train: 0.967375	val: 0.695477	test: 0.896649
PRC train: 0.870737	val: 0.598578	test: 0.704857

Epoch: 174
Loss: 0.11644196053298014
ROC train: 0.965175	val: 0.704892	test: 0.891174
PRC train: 0.857745	val: 0.595841	test: 0.712712

Epoch: 175
Loss: 0.12853064093414016
ROC train: 0.969617	val: 0.723801	test: 0.884852
PRC train: 0.872729	val: 0.595923	test: 0.698672

Epoch: 176
Loss: 0.11453187083448405
ROC train: 0.971206	val: 0.743432	test: 0.876408
PRC train: 0.878613	val: 0.601609	test: 0.689199

Epoch: 177
Loss: 0.2271222152231493
ROC train: 0.966509	val: 0.747262	test: 0.836719
PRC train: 0.848179	val: 0.606300	test: 0.639087

Epoch: 178
Loss: 0.16899186903536542
ROC train: 0.958821	val: 0.716454	test: 0.840351
PRC train: 0.820559	val: 0.597606	test: 0.616446

Epoch: 179
Loss: 0.17599440873108882
ROC train: 0.955471	val: 0.675609	test: 0.884147
PRC train: 0.831907	val: 0.587457	test: 0.663319

Epoch: 180
Loss: 0.1818923534207116
ROC train: 0.950363	val: 0.693466	test: 0.899267
PRC train: 0.812313	val: 0.571695	test: 0.714072

Epoch: 181
Loss: 0.1437126525518769
ROC train: 0.953117	val: 0.713492	test: 0.896170
PRC train: 0.819767	val: 0.577766	test: 0.692929

Early stopping
Best (ROC):	 train: 0.932531	val: 0.780243	test: 0.853030
Best (PRC):	 train: 0.779199	val: 0.596564	test: 0.671179
All runs completed.
