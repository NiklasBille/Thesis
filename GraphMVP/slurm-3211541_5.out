>>> Starting run for dataset: hiv
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running SCAFF configs_split_experiments/GraphMVP/hiv/scaff/train_prop=0.6.yml on cuda:0
Running SCAFF configs_split_experiments/GraphMVP/hiv/scaff/train_prop=0.7.yml on cuda:1
Running SCAFF configs_split_experiments/GraphMVP/hiv/scaff/train_prop=0.8.yml on cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/hiv/scaff/train_prop=0.7.yml --runseed 4 --device cuda:1
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/hiv/scaff/train_prop=0.7.yml --runseed 5 --device cuda:1
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/hiv/scaff/train_prop=0.7.yml --runseed 6 --device cuda:1
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/hiv/scaff/train_prop=0.8.yml --runseed 4 --device cuda:2
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/hiv/scaff/train_prop=0.8.yml --runseed 5 --device cuda:2
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/hiv/scaff/train_prop=0.8.yml --runseed 6 --device cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/hiv/scaff/train_prop=0.6.yml --runseed 4 --device cuda:0
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/hiv/scaff/train_prop=0.6.yml --runseed 5 --device cuda:0
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/hiv/scaff/train_prop=0.6.yml --runseed 6 --device cuda:0
[11:11:15] WARNING: not removing hydrogen atom without neighbors
[11:11:15] WARNING: not removing hydrogen atom without neighbors
[11:11:15] WARNING: not removing hydrogen atom without neighbors
[11:11:15] WARNING: not removing hydrogen atom without neighbors
[11:11:15] WARNING: not removing hydrogen atom without neighbors
[11:11:15] WARNING: not removing hydrogen atom without neighbors
[11:11:15] WARNING: not removing hydrogen atom without neighbors
[11:11:15] WARNING: not removing hydrogen atom without neighbors
[11:11:15] WARNING: not removing hydrogen atom without neighbors
[11:11:15] WARNING: not removing hydrogen atom without neighbors
[11:11:15] WARNING: not removing hydrogen atom without neighbors
[11:11:15] WARNING: not removing hydrogen atom without neighbors
[11:11:15] WARNING: not removing hydrogen atom without neighbors
[11:11:15] WARNING: not removing hydrogen atom without neighbors
[11:11:17] WARNING: not removing hydrogen atom without neighbors
[11:11:17] WARNING: not removing hydrogen atom without neighbors
[11:11:17] WARNING: not removing hydrogen atom without neighbors
[11:11:17] WARNING: not removing hydrogen atom without neighbors
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/hiv/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/hiv/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/hiv/scaff/train_prop=0.6/hiv_scaff_5_26-05_11-11-03  ]
[ Using Seed :  5  ]
[ Using device :  cuda:0  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.31107425984010295
ROC train: 0.780670	val: 0.677178	test: 0.699714
PRC train: 0.255566	val: 0.172152	test: 0.168416

Epoch: 2
Loss: 0.140851344698492
ROC train: 0.811986	val: 0.669302	test: 0.686015
PRC train: 0.325990	val: 0.158739	test: 0.114722

Epoch: 3
Loss: 0.13057354404990393
ROC train: 0.824927	val: 0.690642	test: 0.748384
PRC train: 0.364237	val: 0.180523	test: 0.131322

Epoch: 4
Loss: 0.12640179680285138
ROC train: 0.839939	val: 0.694408	test: 0.725298
PRC train: 0.379515	val: 0.203027	test: 0.143090

Epoch: 5
Loss: 0.12454303157074206
ROC train: 0.854402	val: 0.702217	test: 0.748890
PRC train: 0.436698	val: 0.222302	test: 0.197771

Epoch: 6
Loss: 0.12075799176729132
ROC train: 0.849602	val: 0.698457	test: 0.746749
PRC train: 0.430289	val: 0.199888	test: 0.202641

Epoch: 7
Loss: 0.11974740480526558
ROC train: 0.873891	val: 0.692790	test: 0.737471
PRC train: 0.483970	val: 0.213591	test: 0.282321

Epoch: 8
Loss: 0.11619966522337759
ROC train: 0.873209	val: 0.701381	test: 0.753918
PRC train: 0.466606	val: 0.232716	test: 0.198238

Epoch: 9
Loss: 0.11405329381113263
ROC train: 0.863078	val: 0.698373	test: 0.731353
PRC train: 0.469881	val: 0.190706	test: 0.120961

Epoch: 10
Loss: 0.11336117896373576
ROC train: 0.881406	val: 0.709613	test: 0.735240
PRC train: 0.498174	val: 0.217343	test: 0.182126

Epoch: 11
Loss: 0.11213848538609406
ROC train: 0.882945	val: 0.696892	test: 0.736016
PRC train: 0.516146	val: 0.244866	test: 0.232462

Epoch: 12
Loss: 0.10831388554479193
ROC train: 0.891712	val: 0.692739	test: 0.727296
PRC train: 0.527265	val: 0.205710	test: 0.184152

Epoch: 13
Loss: 0.10773188429823927
ROC train: 0.894049	val: 0.699252	test: 0.726363
PRC train: 0.532032	val: 0.225974	test: 0.210113

Epoch: 14
Loss: 0.10832885914212302
ROC train: 0.891839	val: 0.711513	test: 0.736041
PRC train: 0.521505	val: 0.227793	test: 0.191618

Epoch: 15
Loss: 0.10731610106828555
ROC train: 0.903253	val: 0.690707	test: 0.728045
PRC train: 0.545454	val: 0.196850	test: 0.157136

Epoch: 16
Loss: 0.10751698407345743
ROC train: 0.909283	val: 0.698569	test: 0.746211
PRC train: 0.563433	val: 0.233904	test: 0.232857

Epoch: 17
Loss: 0.10546918794905562
ROC train: 0.913542	val: 0.710000	test: 0.751078
PRC train: 0.573445	val: 0.218662	test: 0.233743

Epoch: 18
Loss: 0.10482639312531151
ROC train: 0.904204	val: 0.695647	test: 0.755869
PRC train: 0.538078	val: 0.232519	test: 0.251222

Epoch: 19
Loss: 0.10360391384356925
ROC train: 0.916750	val: 0.718547	test: 0.753367
PRC train: 0.584449	val: 0.260042	test: 0.206185

Epoch: 20
Loss: 0.10263348177425896
ROC train: 0.912209	val: 0.703999	test: 0.733560
PRC train: 0.569203	val: 0.213882	test: 0.196099

Epoch: 21
Loss: 0.10322022728104682
ROC train: 0.918796	val: 0.706544	test: 0.746607
PRC train: 0.578993	val: 0.233816	test: 0.198559

Epoch: 22
Loss: 0.10029787944992435
ROC train: 0.921277	val: 0.706293	test: 0.746355
PRC train: 0.586578	val: 0.230917	test: 0.209187

Epoch: 23
Loss: 0.09979559156204093
ROC train: 0.924115	val: 0.708929	test: 0.740171
PRC train: 0.587659	val: 0.253306	test: 0.164478

Epoch: 24
Loss: 0.09918292927861555
ROC train: 0.924691	val: 0.715829	test: 0.764167
PRC train: 0.596373	val: 0.242185	test: 0.255980

Epoch: 25
Loss: 0.09883133550959605
ROC train: 0.929766	val: 0.714942	test: 0.751304
PRC train: 0.601577	val: 0.245775	test: 0.210571

Epoch: 26
Loss: 0.09797380750444448
ROC train: 0.929206	val: 0.725599	test: 0.758707
PRC train: 0.590235	val: 0.234854	test: 0.199160

Epoch: 27
Loss: 0.0990915237938069
ROC train: 0.932025	val: 0.721913	test: 0.763303
PRC train: 0.620396	val: 0.245764	test: 0.213832

Epoch: 28
Loss: 0.09791404770887975
ROC train: 0.928239	val: 0.720774	test: 0.752973
PRC train: 0.611971	val: 0.238258	test: 0.185922

Epoch: 29
Loss: 0.0951832283403219
ROC train: 0.933781	val: 0.706863	test: 0.747763
PRC train: 0.610676	val: 0.227152	test: 0.228872

Epoch: 30
Loss: 0.09595005782776966
ROC train: 0.935519	val: 0.695910	test: 0.734477
PRC train: 0.624824	val: 0.218927	test: 0.158421

Epoch: 31
Loss: 0.09791532653631381
ROC train: 0.934003	val: 0.713359	test: 0.743515
PRC train: 0.637917	val: 0.223539	test: 0.174767

Epoch: 32
Loss: 0.0940933402377589
ROC train: 0.938986	val: 0.715293	test: 0.761913
PRC train: 0.631594	val: 0.249353	test: 0.219344

Epoch: 33
Loss: 0.09382556010931992Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/hiv/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/hiv/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/hiv/scaff/train_prop=0.6/hiv_scaff_6_26-05_11-11-03  ]
[ Using Seed :  6  ]
[ Using device :  cuda:0  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.30716516620382706
ROC train: 0.783295	val: 0.670457	test: 0.704799
PRC train: 0.269386	val: 0.133958	test: 0.120702

Epoch: 2
Loss: 0.13906504909705078
ROC train: 0.809999	val: 0.665304	test: 0.693447
PRC train: 0.308161	val: 0.176197	test: 0.127508

Epoch: 3
Loss: 0.1318134042996514
ROC train: 0.825911	val: 0.687251	test: 0.738645
PRC train: 0.349326	val: 0.216703	test: 0.225770

Epoch: 4
Loss: 0.12733267453588465
ROC train: 0.837945	val: 0.694983	test: 0.744876
PRC train: 0.373102	val: 0.193009	test: 0.165626

Epoch: 5
Loss: 0.1247541519715547
ROC train: 0.847836	val: 0.684089	test: 0.739054
PRC train: 0.451339	val: 0.225696	test: 0.205527

Epoch: 6
Loss: 0.12465437870504474
ROC train: 0.849932	val: 0.696194	test: 0.752108
PRC train: 0.405540	val: 0.196045	test: 0.152936

Epoch: 7
Loss: 0.1195238209059864
ROC train: 0.851311	val: 0.688281	test: 0.719023
PRC train: 0.423217	val: 0.157065	test: 0.127233

Epoch: 8
Loss: 0.11859599001085096
ROC train: 0.870992	val: 0.693701	test: 0.730101
PRC train: 0.468544	val: 0.211383	test: 0.132373

Epoch: 9
Loss: 0.11621563679590809
ROC train: 0.873469	val: 0.707835	test: 0.741557
PRC train: 0.500456	val: 0.235397	test: 0.222632

Epoch: 10
Loss: 0.11498960475190116
ROC train: 0.857911	val: 0.688271	test: 0.715576
PRC train: 0.406165	val: 0.158907	test: 0.085638

Epoch: 11
Loss: 0.11294752839266474
ROC train: 0.876003	val: 0.700336	test: 0.718355
PRC train: 0.483266	val: 0.219711	test: 0.173284

Epoch: 12
Loss: 0.1125701983689873
ROC train: 0.888145	val: 0.694674	test: 0.754465
PRC train: 0.535104	val: 0.229154	test: 0.204844

Epoch: 13
Loss: 0.11048956048660045
ROC train: 0.883499	val: 0.701788	test: 0.742184
PRC train: 0.518423	val: 0.218691	test: 0.200355

Epoch: 14
Loss: 0.10944191464268957
ROC train: 0.897765	val: 0.693364	test: 0.747276
PRC train: 0.532652	val: 0.232785	test: 0.230651

Epoch: 15
Loss: 0.10766883276425837
ROC train: 0.907286	val: 0.703242	test: 0.743731
PRC train: 0.560937	val: 0.210333	test: 0.190530

Epoch: 16
Loss: 0.10516574147896403
ROC train: 0.898619	val: 0.717147	test: 0.774359
PRC train: 0.539360	val: 0.237511	test: 0.212116

Epoch: 17
Loss: 0.10838507873395715
ROC train: 0.898762	val: 0.704579	test: 0.750455
PRC train: 0.536478	val: 0.245294	test: 0.250027

Epoch: 18
Loss: 0.10666028251426121
ROC train: 0.910386	val: 0.705360	test: 0.739916
PRC train: 0.563900	val: 0.240040	test: 0.256158

Epoch: 19
Loss: 0.10339290531562725
ROC train: 0.913665	val: 0.708298	test: 0.751746
PRC train: 0.575558	val: 0.244863	test: 0.231556

Epoch: 20
Loss: 0.10174875510878575
ROC train: 0.911342	val: 0.704840	test: 0.744345
PRC train: 0.560444	val: 0.246037	test: 0.229723

Epoch: 21
Loss: 0.10337884596074888
ROC train: 0.910012	val: 0.698545	test: 0.754853
PRC train: 0.550639	val: 0.217515	test: 0.253524

Epoch: 22
Loss: 0.10363526618555206
ROC train: 0.911221	val: 0.702264	test: 0.744882
PRC train: 0.569807	val: 0.205404	test: 0.197984

Epoch: 23
Loss: 0.10021819987941581
ROC train: 0.919223	val: 0.718076	test: 0.757664
PRC train: 0.588856	val: 0.257402	test: 0.218972

Epoch: 24
Loss: 0.10012123245863078
ROC train: 0.925163	val: 0.716477	test: 0.758631
PRC train: 0.604367	val: 0.260007	test: 0.200464

Epoch: 25
Loss: 0.10138798673786306
ROC train: 0.916692	val: 0.703073	test: 0.752555
PRC train: 0.579458	val: 0.214611	test: 0.178034

Epoch: 26
Loss: 0.09933013892883279
ROC train: 0.919242	val: 0.713186	test: 0.756440
PRC train: 0.580246	val: 0.243387	test: 0.217068

Epoch: 27
Loss: 0.0980035309299583
ROC train: 0.923361	val: 0.697251	test: 0.729716
PRC train: 0.595645	val: 0.220833	test: 0.152159

Epoch: 28
Loss: 0.09876290979766726
ROC train: 0.931912	val: 0.716260	test: 0.771818
PRC train: 0.613613	val: 0.267495	test: 0.204798

Epoch: 29
Loss: 0.09773964511178831
ROC train: 0.925539	val: 0.715727	test: 0.762552
PRC train: 0.596289	val: 0.238135	test: 0.207345

Epoch: 30
Loss: 0.09686114598527545
ROC train: 0.936282	val: 0.703514	test: 0.750156
PRC train: 0.634437	val: 0.235032	test: 0.213334

Epoch: 31
Loss: 0.09365648149706232
ROC train: 0.933826	val: 0.692472	test: 0.742190
PRC train: 0.634460	val: 0.255132	test: 0.202460

Epoch: 32
Loss: 0.09721884425848032
ROC train: 0.936567	val: 0.717273	test: 0.762004
PRC train: 0.639004	val: 0.260466	test: 0.239655

Epoch: 33
Loss: 0.09584996385942714Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/hiv/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/hiv/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/hiv/scaff/train_prop=0.6/hiv_scaff_4_26-05_11-11-03  ]
[ Using Seed :  4  ]
[ Using device :  cuda:0  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.3231867073461868
ROC train: 0.787604	val: 0.688472	test: 0.698934
PRC train: 0.257098	val: 0.163739	test: 0.170165

Epoch: 2
Loss: 0.13903267737127156
ROC train: 0.816237	val: 0.698269	test: 0.721119
PRC train: 0.283502	val: 0.155437	test: 0.159103

Epoch: 3
Loss: 0.1316930392982251
ROC train: 0.835966	val: 0.693799	test: 0.746678
PRC train: 0.371902	val: 0.216517	test: 0.179704

Epoch: 4
Loss: 0.1288028503500718
ROC train: 0.835778	val: 0.684213	test: 0.728602
PRC train: 0.397173	val: 0.213533	test: 0.212840

Epoch: 5
Loss: 0.12575108785712522
ROC train: 0.836726	val: 0.690121	test: 0.746147
PRC train: 0.380166	val: 0.203410	test: 0.222477

Epoch: 6
Loss: 0.12349338253607757
ROC train: 0.855421	val: 0.695194	test: 0.735331
PRC train: 0.426637	val: 0.231667	test: 0.186240

Epoch: 7
Loss: 0.1196977541053299
ROC train: 0.861825	val: 0.676871	test: 0.736196
PRC train: 0.458129	val: 0.202691	test: 0.165710

Epoch: 8
Loss: 0.11729141335987799
ROC train: 0.864449	val: 0.681077	test: 0.713110
PRC train: 0.457682	val: 0.223192	test: 0.204545

Epoch: 9
Loss: 0.11590169674972906
ROC train: 0.874413	val: 0.683243	test: 0.718318
PRC train: 0.508334	val: 0.228692	test: 0.207628

Epoch: 10
Loss: 0.11452528266198789
ROC train: 0.879700	val: 0.703578	test: 0.750219
PRC train: 0.503611	val: 0.220147	test: 0.235567

Epoch: 11
Loss: 0.11106780637490597
ROC train: 0.882059	val: 0.703134	test: 0.742130
PRC train: 0.497054	val: 0.228753	test: 0.143550

Epoch: 12
Loss: 0.11062736688699232
ROC train: 0.890339	val: 0.702310	test: 0.729450
PRC train: 0.527833	val: 0.230658	test: 0.190105

Epoch: 13
Loss: 0.11149819411042497
ROC train: 0.889990	val: 0.714525	test: 0.748402
PRC train: 0.529575	val: 0.229397	test: 0.191656

Epoch: 14
Loss: 0.10963188232978993
ROC train: 0.891534	val: 0.705705	test: 0.751943
PRC train: 0.525670	val: 0.241026	test: 0.222687

Epoch: 15
Loss: 0.1100538849562297
ROC train: 0.899723	val: 0.711316	test: 0.747815
PRC train: 0.542571	val: 0.232678	test: 0.223375

Epoch: 16
Loss: 0.107752307395989
ROC train: 0.909292	val: 0.719250	test: 0.745845
PRC train: 0.569549	val: 0.252249	test: 0.193930

Epoch: 17
Loss: 0.10555059146545602
ROC train: 0.905687	val: 0.704780	test: 0.740475
PRC train: 0.545555	val: 0.258380	test: 0.219351

Epoch: 18
Loss: 0.10476145537546906
ROC train: 0.898026	val: 0.706031	test: 0.737169
PRC train: 0.529008	val: 0.228059	test: 0.212254

Epoch: 19
Loss: 0.10451442826326818
ROC train: 0.913492	val: 0.709885	test: 0.750854
PRC train: 0.572677	val: 0.249797	test: 0.230848

Epoch: 20
Loss: 0.10484134119533849
ROC train: 0.917082	val: 0.710694	test: 0.742966
PRC train: 0.580849	val: 0.245596	test: 0.241999

Epoch: 21
Loss: 0.10268065315225712
ROC train: 0.918806	val: 0.696639	test: 0.741115
PRC train: 0.581951	val: 0.228824	test: 0.253841

Epoch: 22
Loss: 0.10161431972412525
ROC train: 0.920554	val: 0.711330	test: 0.764355
PRC train: 0.596261	val: 0.268457	test: 0.189979

Epoch: 23
Loss: 0.0994551174970439
ROC train: 0.914364	val: 0.709390	test: 0.740223
PRC train: 0.571887	val: 0.203788	test: 0.151204

Epoch: 24
Loss: 0.09907404516454417
ROC train: 0.918452	val: 0.712236	test: 0.733057
PRC train: 0.581882	val: 0.213904	test: 0.152236

Epoch: 25
Loss: 0.10100862627075823
ROC train: 0.923961	val: 0.702795	test: 0.737308
PRC train: 0.595016	val: 0.250559	test: 0.240538

Epoch: 26
Loss: 0.09825806359942728
ROC train: 0.922877	val: 0.701797	test: 0.731754
PRC train: 0.587767	val: 0.222780	test: 0.165916

Epoch: 27
Loss: 0.09697697022173599
ROC train: 0.927083	val: 0.724979	test: 0.750931
PRC train: 0.594917	val: 0.219536	test: 0.167273

Epoch: 28
Loss: 0.09780224439310693
ROC train: 0.920947	val: 0.703347	test: 0.722911
PRC train: 0.582740	val: 0.205457	test: 0.190901

Epoch: 29
Loss: 0.09576461543296576
ROC train: 0.930537	val: 0.718054	test: 0.754099
PRC train: 0.625657	val: 0.245880	test: 0.226063

Epoch: 30
Loss: 0.09671091250532866
ROC train: 0.932464	val: 0.697417	test: 0.732937
PRC train: 0.621552	val: 0.247008	test: 0.239889

Epoch: 31
Loss: 0.09540529883579847
ROC train: 0.937579	val: 0.707405	test: 0.747422
PRC train: 0.628633	val: 0.237687	test: 0.227992

Epoch: 32
Loss: 0.09448603636162964
ROC train: 0.942713	val: 0.720499	test: 0.749046
PRC train: 0.646556	val: 0.252260	test: 0.206159

Epoch: 33
Loss: 0.09489052252274811Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/hiv/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/hiv/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/hiv/scaff/train_prop=0.7/hiv_scaff_4_26-05_11-11-03  ]
[ Using Seed :  4  ]
[ Using device :  cuda:1  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.3010660300254143
ROC train: 0.775080	val: 0.699283	test: 0.707862
PRC train: 0.249026	val: 0.150997	test: 0.114120

Epoch: 2
Loss: 0.14008911342634997
ROC train: 0.795970	val: 0.708367	test: 0.695743
PRC train: 0.296222	val: 0.225809	test: 0.149552

Epoch: 3
Loss: 0.13104371813306206
ROC train: 0.820770	val: 0.717526	test: 0.701039
PRC train: 0.356489	val: 0.275015	test: 0.140097

Epoch: 4
Loss: 0.12941581230171217
ROC train: 0.838521	val: 0.730116	test: 0.730564
PRC train: 0.380734	val: 0.258588	test: 0.136720

Epoch: 5
Loss: 0.12462945924986159
ROC train: 0.838127	val: 0.733709	test: 0.747495
PRC train: 0.388212	val: 0.298803	test: 0.193682

Epoch: 6
Loss: 0.12471827543574025
ROC train: 0.846603	val: 0.715299	test: 0.721974
PRC train: 0.409796	val: 0.254266	test: 0.121806

Epoch: 7
Loss: 0.1201669365244372
ROC train: 0.843281	val: 0.735092	test: 0.716604
PRC train: 0.418138	val: 0.247738	test: 0.147273

Epoch: 8
Loss: 0.12065415398572807
ROC train: 0.851869	val: 0.739602	test: 0.767052
PRC train: 0.464509	val: 0.306127	test: 0.203309

Epoch: 9
Loss: 0.11916805004442582
ROC train: 0.858215	val: 0.722601	test: 0.738010
PRC train: 0.435667	val: 0.215914	test: 0.128695

Epoch: 10
Loss: 0.11780161747978835
ROC train: 0.864665	val: 0.736505	test: 0.722852
PRC train: 0.490989	val: 0.241301	test: 0.116263

Epoch: 11
Loss: 0.11548175481361425
ROC train: 0.872329	val: 0.719972	test: 0.734890
PRC train: 0.464404	val: 0.243866	test: 0.112618

Epoch: 12
Loss: 0.11358306172445336
ROC train: 0.869161	val: 0.726910	test: 0.760414
PRC train: 0.476160	val: 0.278809	test: 0.194197

Epoch: 13
Loss: 0.11295298313843495
ROC train: 0.874765	val: 0.718222	test: 0.729506
PRC train: 0.497287	val: 0.276788	test: 0.138931

Epoch: 14
Loss: 0.11251837858226728
ROC train: 0.878185	val: 0.717099	test: 0.721591
PRC train: 0.504716	val: 0.264615	test: 0.116927

Epoch: 15
Loss: 0.11139097212487618
ROC train: 0.888471	val: 0.729398	test: 0.756842
PRC train: 0.525485	val: 0.245951	test: 0.143526

Epoch: 16
Loss: 0.11090815968990032
ROC train: 0.889703	val: 0.702483	test: 0.732808
PRC train: 0.522375	val: 0.249712	test: 0.098876

Epoch: 17
Loss: 0.11013870343388694
ROC train: 0.897172	val: 0.743668	test: 0.766392
PRC train: 0.537638	val: 0.292164	test: 0.164836

Epoch: 18
Loss: 0.10783854987539447
ROC train: 0.883720	val: 0.722011	test: 0.724563
PRC train: 0.502673	val: 0.239445	test: 0.087030

Epoch: 19
Loss: 0.1083484577943334
ROC train: 0.897585	val: 0.727724	test: 0.710093
PRC train: 0.524154	val: 0.252199	test: 0.088077

Epoch: 20
Loss: 0.10896169776204301
ROC train: 0.902802	val: 0.735778	test: 0.763249
PRC train: 0.555616	val: 0.291180	test: 0.177731

Epoch: 21
Loss: 0.10700329588863514
ROC train: 0.904039	val: 0.728666	test: 0.763965
PRC train: 0.537793	val: 0.309334	test: 0.183048

Epoch: 22
Loss: 0.10719663869957487
ROC train: 0.896800	val: 0.728755	test: 0.726971
PRC train: 0.515853	val: 0.237346	test: 0.086312

Epoch: 23
Loss: 0.10759461191114311
ROC train: 0.909525	val: 0.741946	test: 0.750025
PRC train: 0.567144	val: 0.304804	test: 0.205285

Epoch: 24
Loss: 0.10517734838246663
ROC train: 0.912790	val: 0.732674	test: 0.733148
PRC train: 0.568559	val: 0.283237	test: 0.114906

Epoch: 25
Loss: 0.10471766504335332
ROC train: 0.913997	val: 0.737380	test: 0.759731
PRC train: 0.575117	val: 0.296610	test: 0.178120

Epoch: 26
Loss: 0.10277031620165387
ROC train: 0.913226	val: 0.745426	test: 0.766443
PRC train: 0.578464	val: 0.323323	test: 0.215517

Epoch: 27
Loss: 0.10247602846361446
ROC train: 0.914554	val: 0.728928	test: 0.754992
PRC train: 0.587743	val: 0.294167	test: 0.165014

Epoch: 28
Loss: 0.10244568336506318
ROC train: 0.920693	val: 0.721233	test: 0.774107
PRC train: 0.594163	val: 0.279509	test: 0.157458

Epoch: 29
Loss: 0.10049226417802208
ROC train: 0.918342	val: 0.724615	test: 0.754422
PRC train: 0.582765	val: 0.277235	test: 0.138175

Epoch: 30
Loss: 0.09958541377266326
ROC train: 0.920489	val: 0.720369	test: 0.766731
PRC train: 0.581446	val: 0.268102	test: 0.143733

Epoch: 31
Loss: 0.10068932749455183
ROC train: 0.920274	val: 0.715280	test: 0.758040
PRC train: 0.594784	val: 0.268147	test: 0.124974

Epoch: 32
Loss: 0.09986590176903375
ROC train: 0.926675	val: 0.730482	test: 0.760606
PRC train: 0.598227	val: 0.300031	test: 0.158556

Epoch: 33
Loss: 0.09904346593785635Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/hiv/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/hiv/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/hiv/scaff/train_prop=0.7/hiv_scaff_6_26-05_11-11-03  ]
[ Using Seed :  6  ]
[ Using device :  cuda:1  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.28309519303444536
ROC train: 0.772701	val: 0.732071	test: 0.721895
PRC train: 0.222716	val: 0.171058	test: 0.156502

Epoch: 2
Loss: 0.13885316626448338
ROC train: 0.753400	val: 0.676383	test: 0.708377
PRC train: 0.194326	val: 0.150580	test: 0.209860

Epoch: 3
Loss: 0.13220831970110708
ROC train: 0.833996	val: 0.708851	test: 0.751969
PRC train: 0.372618	val: 0.249996	test: 0.171115

Epoch: 4
Loss: 0.12773442955617603
ROC train: 0.819256	val: 0.703819	test: 0.733995
PRC train: 0.339223	val: 0.264212	test: 0.235061

Epoch: 5
Loss: 0.12622035598315734
ROC train: 0.844407	val: 0.712676	test: 0.758497
PRC train: 0.428957	val: 0.280729	test: 0.211617

Epoch: 6
Loss: 0.12426534199533029
ROC train: 0.850486	val: 0.723755	test: 0.729266
PRC train: 0.384409	val: 0.290649	test: 0.143888

Epoch: 7
Loss: 0.12227368679695583
ROC train: 0.859019	val: 0.733131	test: 0.732113
PRC train: 0.451376	val: 0.265875	test: 0.172725

Epoch: 8
Loss: 0.12016060459746973
ROC train: 0.864948	val: 0.744720	test: 0.718029
PRC train: 0.455546	val: 0.297693	test: 0.109469

Epoch: 9
Loss: 0.1182851440847954
ROC train: 0.858402	val: 0.718211	test: 0.735015
PRC train: 0.451257	val: 0.264552	test: 0.138155

Epoch: 10
Loss: 0.11642269479319804
ROC train: 0.872388	val: 0.734411	test: 0.739882
PRC train: 0.470949	val: 0.277580	test: 0.160343

Epoch: 11
Loss: 0.11594003782266675
ROC train: 0.872126	val: 0.736997	test: 0.745229
PRC train: 0.468618	val: 0.262440	test: 0.149553

Epoch: 12
Loss: 0.11320051876785527
ROC train: 0.883178	val: 0.743669	test: 0.756913
PRC train: 0.505825	val: 0.316095	test: 0.185356

Epoch: 13
Loss: 0.11293424058137076
ROC train: 0.888386	val: 0.736324	test: 0.735868
PRC train: 0.524382	val: 0.313803	test: 0.160112

Epoch: 14
Loss: 0.11212435091978733
ROC train: 0.890148	val: 0.743144	test: 0.749564
PRC train: 0.509972	val: 0.282359	test: 0.142676

Epoch: 15
Loss: 0.10926928173555661
ROC train: 0.880972	val: 0.724356	test: 0.746328
PRC train: 0.480179	val: 0.267245	test: 0.171952

Epoch: 16
Loss: 0.11039350911618973
ROC train: 0.876396	val: 0.708677	test: 0.680337
PRC train: 0.509258	val: 0.272921	test: 0.096068

Epoch: 17
Loss: 0.11055547229757454
ROC train: 0.895377	val: 0.739449	test: 0.740060
PRC train: 0.525153	val: 0.276997	test: 0.112753

Epoch: 18
Loss: 0.10817132920713689
ROC train: 0.899929	val: 0.729472	test: 0.747011
PRC train: 0.540643	val: 0.316505	test: 0.199775

Epoch: 19
Loss: 0.10772022995555683
ROC train: 0.904652	val: 0.734416	test: 0.742868
PRC train: 0.550736	val: 0.275216	test: 0.143506

Epoch: 20
Loss: 0.10733678902182318
ROC train: 0.910251	val: 0.743872	test: 0.760146
PRC train: 0.566510	val: 0.291712	test: 0.168563

Epoch: 21
Loss: 0.10569776908773637
ROC train: 0.906245	val: 0.728686	test: 0.739389
PRC train: 0.545830	val: 0.300728	test: 0.186663

Epoch: 22
Loss: 0.10469889378065365
ROC train: 0.904017	val: 0.734953	test: 0.757220
PRC train: 0.555290	val: 0.300868	test: 0.179215

Epoch: 23
Loss: 0.10553663209244901
ROC train: 0.905116	val: 0.727335	test: 0.729645
PRC train: 0.546571	val: 0.265366	test: 0.127276

Epoch: 24
Loss: 0.10247806415519999
ROC train: 0.907860	val: 0.742537	test: 0.745417
PRC train: 0.566628	val: 0.307011	test: 0.202201

Epoch: 25
Loss: 0.1039644923970801
ROC train: 0.922821	val: 0.735580	test: 0.753168
PRC train: 0.586442	val: 0.321708	test: 0.201455

Epoch: 26
Loss: 0.10182559423678801
ROC train: 0.903247	val: 0.726008	test: 0.743874
PRC train: 0.542912	val: 0.291273	test: 0.179150

Epoch: 27
Loss: 0.10139120050586711
ROC train: 0.925062	val: 0.731160	test: 0.758273
PRC train: 0.600626	val: 0.306523	test: 0.206992

Epoch: 28
Loss: 0.10126196361697216
ROC train: 0.918669	val: 0.732822	test: 0.727066
PRC train: 0.570447	val: 0.282531	test: 0.106595

Epoch: 29
Loss: 0.09983718947425672
ROC train: 0.925085	val: 0.725532	test: 0.740118
PRC train: 0.585053	val: 0.306589	test: 0.146355

Epoch: 30
Loss: 0.10017534316615952
ROC train: 0.914895	val: 0.730909	test: 0.741569
PRC train: 0.582920	val: 0.303843	test: 0.129547

Epoch: 31
Loss: 0.10021897218299228
ROC train: 0.925126	val: 0.746028	test: 0.749594
PRC train: 0.581518	val: 0.263301	test: 0.119234

Epoch: 32
Loss: 0.09818516046632442
ROC train: 0.928037	val: 0.731764	test: 0.765354
PRC train: 0.608476	val: 0.306484	test: 0.187067

Epoch: 33
Loss: 0.09888209315880607Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/hiv/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/hiv/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/hiv/scaff/train_prop=0.7/hiv_scaff_5_26-05_11-11-03  ]
[ Using Seed :  5  ]
[ Using device :  cuda:1  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.28680886048467336
ROC train: 0.777390	val: 0.716884	test: 0.719294
PRC train: 0.225583	val: 0.175476	test: 0.146739

Epoch: 2
Loss: 0.13994130186860715
ROC train: 0.808887	val: 0.717600	test: 0.693274
PRC train: 0.315519	val: 0.184410	test: 0.110419

Epoch: 3
Loss: 0.13242818059246975
ROC train: 0.822414	val: 0.714789	test: 0.737704
PRC train: 0.366573	val: 0.239234	test: 0.135148

Epoch: 4
Loss: 0.12908140076611865
ROC train: 0.825276	val: 0.730680	test: 0.723196
PRC train: 0.360774	val: 0.271526	test: 0.168653

Epoch: 5
Loss: 0.12585540307746151
ROC train: 0.840389	val: 0.719678	test: 0.715289
PRC train: 0.389460	val: 0.275084	test: 0.133900

Epoch: 6
Loss: 0.12384979252373407
ROC train: 0.844873	val: 0.718683	test: 0.733998
PRC train: 0.405071	val: 0.267529	test: 0.116433

Epoch: 7
Loss: 0.12126120351016102
ROC train: 0.834099	val: 0.711246	test: 0.731086
PRC train: 0.361883	val: 0.211886	test: 0.139165

Epoch: 8
Loss: 0.11955022903993182
ROC train: 0.856609	val: 0.715100	test: 0.702121
PRC train: 0.425830	val: 0.291714	test: 0.135375

Epoch: 9
Loss: 0.11782858608433361
ROC train: 0.867244	val: 0.729292	test: 0.720329
PRC train: 0.483004	val: 0.286749	test: 0.144892

Epoch: 10
Loss: 0.11666472273485726
ROC train: 0.872285	val: 0.723012	test: 0.730356
PRC train: 0.464619	val: 0.279560	test: 0.111809

Epoch: 11
Loss: 0.11548973930177904
ROC train: 0.875069	val: 0.733403	test: 0.736296
PRC train: 0.485733	val: 0.301850	test: 0.174912

Epoch: 12
Loss: 0.1136055267344478
ROC train: 0.881702	val: 0.732083	test: 0.757388
PRC train: 0.504057	val: 0.319775	test: 0.191811

Epoch: 13
Loss: 0.11352024018857743
ROC train: 0.884043	val: 0.724731	test: 0.753804
PRC train: 0.485444	val: 0.304124	test: 0.149685

Epoch: 14
Loss: 0.11068222475561065
ROC train: 0.885114	val: 0.729040	test: 0.744888
PRC train: 0.512557	val: 0.319970	test: 0.187930

Epoch: 15
Loss: 0.11151562897933057
ROC train: 0.882959	val: 0.710480	test: 0.711446
PRC train: 0.482054	val: 0.259192	test: 0.105000

Epoch: 16
Loss: 0.11042741513849831
ROC train: 0.887938	val: 0.731083	test: 0.730606
PRC train: 0.520935	val: 0.292368	test: 0.164243

Epoch: 17
Loss: 0.10813133502307554
ROC train: 0.888156	val: 0.720980	test: 0.717613
PRC train: 0.541089	val: 0.279132	test: 0.133688

Epoch: 18
Loss: 0.10876498799870195
ROC train: 0.894732	val: 0.735111	test: 0.735210
PRC train: 0.503506	val: 0.280626	test: 0.143410

Epoch: 19
Loss: 0.10941488392506092
ROC train: 0.903371	val: 0.744050	test: 0.743776
PRC train: 0.549434	val: 0.290595	test: 0.163577

Epoch: 20
Loss: 0.10569043396246923
ROC train: 0.899721	val: 0.733858	test: 0.761621
PRC train: 0.536289	val: 0.310467	test: 0.222092

Epoch: 21
Loss: 0.1075037850647205
ROC train: 0.904667	val: 0.730061	test: 0.731784
PRC train: 0.546690	val: 0.308800	test: 0.193468

Epoch: 22
Loss: 0.10699365217127538
ROC train: 0.909505	val: 0.730180	test: 0.741161
PRC train: 0.559573	val: 0.290732	test: 0.162394

Epoch: 23
Loss: 0.1041544219118296
ROC train: 0.914245	val: 0.730950	test: 0.733364
PRC train: 0.567680	val: 0.323666	test: 0.134268

Epoch: 24
Loss: 0.1044932550364766
ROC train: 0.911454	val: 0.735910	test: 0.763447
PRC train: 0.563680	val: 0.294368	test: 0.215577

Epoch: 25
Loss: 0.10205431776357426
ROC train: 0.905447	val: 0.727505	test: 0.759216
PRC train: 0.542510	val: 0.271450	test: 0.176209

Epoch: 26
Loss: 0.10418610784170079
ROC train: 0.916523	val: 0.746198	test: 0.757893
PRC train: 0.578752	val: 0.320278	test: 0.193689

Epoch: 27
Loss: 0.101840334717019
ROC train: 0.915024	val: 0.716528	test: 0.753361
PRC train: 0.572638	val: 0.280593	test: 0.175662

Epoch: 28
Loss: 0.10058627774112637
ROC train: 0.926195	val: 0.739141	test: 0.772314
PRC train: 0.594398	val: 0.297053	test: 0.176627

Epoch: 29
Loss: 0.1012128478593998
ROC train: 0.918459	val: 0.734120	test: 0.749407
PRC train: 0.590893	val: 0.309998	test: 0.205521

Epoch: 30
Loss: 0.09992007105877933
ROC train: 0.918350	val: 0.759046	test: 0.738148
PRC train: 0.567908	val: 0.301178	test: 0.165272

Epoch: 31
Loss: 0.10028424807814455
ROC train: 0.929651	val: 0.728568	test: 0.733495
PRC train: 0.607832	val: 0.299966	test: 0.173621

Epoch: 32
Loss: 0.09936492205573519
ROC train: 0.930003	val: 0.726080	test: 0.758858
PRC train: 0.606633	val: 0.268286	test: 0.153090

Epoch: 33
Loss: 0.0998013741471665Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/hiv/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/hiv/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/hiv/scaff/train_prop=0.8/hiv_scaff_6_26-05_11-11-03  ]
[ Using Seed :  6  ]
[ Using device :  cuda:2  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.26556187155509897
ROC train: 0.755864	val: 0.756605	test: 0.705485
PRC train: 0.225197	val: 0.229008	test: 0.123719

Epoch: 2
Loss: 0.13824628221015542
ROC train: 0.794844	val: 0.756684	test: 0.736181
PRC train: 0.300659	val: 0.222636	test: 0.161450

Epoch: 3
Loss: 0.13268761115709193
ROC train: 0.800455	val: 0.775968	test: 0.694517
PRC train: 0.314887	val: 0.238613	test: 0.127420

Epoch: 4
Loss: 0.12941847680725263
ROC train: 0.818560	val: 0.770273	test: 0.725978
PRC train: 0.335474	val: 0.213232	test: 0.086524

Epoch: 5
Loss: 0.12622965642723677
ROC train: 0.821788	val: 0.781908	test: 0.751845
PRC train: 0.369454	val: 0.228592	test: 0.217870

Epoch: 6
Loss: 0.12460011985754071
ROC train: 0.840246	val: 0.790610	test: 0.738013
PRC train: 0.404645	val: 0.261395	test: 0.163170

Epoch: 7
Loss: 0.12324845347575068
ROC train: 0.836154	val: 0.798403	test: 0.750625
PRC train: 0.380492	val: 0.332102	test: 0.177801

Epoch: 8
Loss: 0.11991923374969875
ROC train: 0.857825	val: 0.798507	test: 0.741735
PRC train: 0.438058	val: 0.351971	test: 0.217873

Epoch: 9
Loss: 0.1192010250345987
ROC train: 0.849257	val: 0.796942	test: 0.719508
PRC train: 0.416946	val: 0.258908	test: 0.135309

Epoch: 10
Loss: 0.1192873245968452
ROC train: 0.858555	val: 0.816361	test: 0.766259
PRC train: 0.457459	val: 0.353985	test: 0.210932

Epoch: 11
Loss: 0.11544928024168645
ROC train: 0.857975	val: 0.803556	test: 0.724966
PRC train: 0.451945	val: 0.338236	test: 0.177199

Epoch: 12
Loss: 0.11523688076689927
ROC train: 0.868552	val: 0.792016	test: 0.760270
PRC train: 0.477686	val: 0.354579	test: 0.213484

Epoch: 13
Loss: 0.11473369103547207
ROC train: 0.872451	val: 0.806306	test: 0.758974
PRC train: 0.457742	val: 0.325370	test: 0.194150

Epoch: 14
Loss: 0.1138004967999603
ROC train: 0.872203	val: 0.817552	test: 0.685137
PRC train: 0.438758	val: 0.271667	test: 0.074516

Epoch: 15
Loss: 0.11166925859108058
ROC train: 0.880594	val: 0.814025	test: 0.770318
PRC train: 0.509173	val: 0.353728	test: 0.261798

Epoch: 16
Loss: 0.11179787963209742
ROC train: 0.882630	val: 0.810690	test: 0.741358
PRC train: 0.502329	val: 0.341656	test: 0.125089

Epoch: 17
Loss: 0.1113441836005565
ROC train: 0.884952	val: 0.805234	test: 0.746706
PRC train: 0.497639	val: 0.373664	test: 0.246839

Epoch: 18
Loss: 0.1097592389770901
ROC train: 0.886286	val: 0.786296	test: 0.772429
PRC train: 0.520655	val: 0.350276	test: 0.224255

Epoch: 19
Loss: 0.10960377812227431
ROC train: 0.884192	val: 0.819270	test: 0.756287
PRC train: 0.497192	val: 0.345984	test: 0.151663

Epoch: 20
Loss: 0.10880115910141361
ROC train: 0.887345	val: 0.810880	test: 0.750895
PRC train: 0.513890	val: 0.370658	test: 0.268308

Epoch: 21
Loss: 0.10825684845891785
ROC train: 0.901865	val: 0.827130	test: 0.746573
PRC train: 0.551515	val: 0.354880	test: 0.230418

Epoch: 22
Loss: 0.10608931448767017
ROC train: 0.891492	val: 0.805219	test: 0.742635
PRC train: 0.510465	val: 0.314358	test: 0.111617

Epoch: 23
Loss: 0.10627867674935818
ROC train: 0.898651	val: 0.799361	test: 0.735918
PRC train: 0.548660	val: 0.341391	test: 0.204603

Epoch: 24
Loss: 0.10450282448045255
ROC train: 0.907737	val: 0.819518	test: 0.765977
PRC train: 0.565344	val: 0.343547	test: 0.209240

Epoch: 25
Loss: 0.1061264778371791
ROC train: 0.903397	val: 0.786434	test: 0.758611
PRC train: 0.545802	val: 0.373668	test: 0.221146

Epoch: 26
Loss: 0.10470656203519327
ROC train: 0.909200	val: 0.820293	test: 0.739306
PRC train: 0.557778	val: 0.356838	test: 0.204074

Epoch: 27
Loss: 0.10376984043795148
ROC train: 0.908262	val: 0.803951	test: 0.753037
PRC train: 0.560282	val: 0.339192	test: 0.200786

Epoch: 28
Loss: 0.1025746020844485
ROC train: 0.912136	val: 0.811410	test: 0.775720
PRC train: 0.564028	val: 0.411774	test: 0.248187

Epoch: 29
Loss: 0.10241338947683758
ROC train: 0.907220	val: 0.809175	test: 0.757790
PRC train: 0.558571	val: 0.373176	test: 0.191452

Epoch: 30
Loss: 0.10186134921541216
ROC train: 0.919221	val: 0.796829	test: 0.742262
PRC train: 0.587068	val: 0.374871	test: 0.215279

Epoch: 31
Loss: 0.10262314291534536
ROC train: 0.916203	val: 0.787294	test: 0.747204
PRC train: 0.570261	val: 0.330066	test: 0.210754

Epoch: 32
Loss: 0.1014364021827615
ROC train: 0.916728	val: 0.810540	test: 0.772553
PRC train: 0.577157	val: 0.342602	test: 0.241869

Epoch: 33
Loss: 0.10018465728331262Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/hiv/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/hiv/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/hiv/scaff/train_prop=0.8/hiv_scaff_4_26-05_11-11-03  ]
[ Using Seed :  4  ]
[ Using device :  cuda:2  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.28387505540751795
ROC train: 0.772887	val: 0.730033	test: 0.722886
PRC train: 0.222652	val: 0.165869	test: 0.206316

Epoch: 2
Loss: 0.1368361538884881
ROC train: 0.795745	val: 0.770417	test: 0.738371
PRC train: 0.307234	val: 0.211939	test: 0.191918

Epoch: 3
Loss: 0.13246471411905542
ROC train: 0.810292	val: 0.773724	test: 0.743615
PRC train: 0.356996	val: 0.263808	test: 0.206282

Epoch: 4
Loss: 0.12843029520784177
ROC train: 0.830231	val: 0.789300	test: 0.747713
PRC train: 0.385843	val: 0.312367	test: 0.222838

Epoch: 5
Loss: 0.12537843803705812
ROC train: 0.826150	val: 0.783421	test: 0.739794
PRC train: 0.358441	val: 0.194888	test: 0.118114

Epoch: 6
Loss: 0.12399797002367446
ROC train: 0.829451	val: 0.799836	test: 0.713525
PRC train: 0.383111	val: 0.242321	test: 0.105418

Epoch: 7
Loss: 0.12163187624306503
ROC train: 0.838683	val: 0.768249	test: 0.741722
PRC train: 0.424185	val: 0.289455	test: 0.217157

Epoch: 8
Loss: 0.11957221347104174
ROC train: 0.854376	val: 0.813474	test: 0.749713
PRC train: 0.443565	val: 0.302736	test: 0.220348

Epoch: 9
Loss: 0.11872515854045604
ROC train: 0.849307	val: 0.751062	test: 0.769853
PRC train: 0.432250	val: 0.331051	test: 0.213502

Epoch: 10
Loss: 0.11834221590690162
ROC train: 0.864193	val: 0.822433	test: 0.755592
PRC train: 0.462672	val: 0.334692	test: 0.207472

Epoch: 11
Loss: 0.11544492811491437
ROC train: 0.860027	val: 0.793752	test: 0.748825
PRC train: 0.468551	val: 0.337883	test: 0.125070

Epoch: 12
Loss: 0.11559559298256145
ROC train: 0.861531	val: 0.788112	test: 0.750586
PRC train: 0.463814	val: 0.262892	test: 0.152397

Epoch: 13
Loss: 0.11497191467854039
ROC train: 0.861699	val: 0.779566	test: 0.738620
PRC train: 0.475987	val: 0.258228	test: 0.223508

Epoch: 14
Loss: 0.11276951849923501
ROC train: 0.863569	val: 0.797965	test: 0.744846
PRC train: 0.440872	val: 0.266622	test: 0.165655

Epoch: 15
Loss: 0.11284805321369641
ROC train: 0.879046	val: 0.822825	test: 0.760629
PRC train: 0.511277	val: 0.321916	test: 0.227821

Epoch: 16
Loss: 0.11118229208518518
ROC train: 0.875377	val: 0.801658	test: 0.754760
PRC train: 0.489602	val: 0.307705	test: 0.202453

Epoch: 17
Loss: 0.11267392863746156
ROC train: 0.878090	val: 0.769434	test: 0.735789
PRC train: 0.507998	val: 0.313886	test: 0.192488

Epoch: 18
Loss: 0.1098966120065459
ROC train: 0.884412	val: 0.788047	test: 0.736899
PRC train: 0.508097	val: 0.319744	test: 0.191179

Epoch: 19
Loss: 0.10858389838627679
ROC train: 0.880270	val: 0.808475	test: 0.764553
PRC train: 0.514983	val: 0.335188	test: 0.217220

Epoch: 20
Loss: 0.10869486074590047
ROC train: 0.887338	val: 0.775777	test: 0.734263
PRC train: 0.502970	val: 0.289737	test: 0.190354

Epoch: 21
Loss: 0.107962531229993
ROC train: 0.884738	val: 0.776847	test: 0.731306
PRC train: 0.509600	val: 0.337934	test: 0.204302

Epoch: 22
Loss: 0.10738609059388422
ROC train: 0.896267	val: 0.811291	test: 0.756108
PRC train: 0.537428	val: 0.363141	test: 0.229614

Epoch: 23
Loss: 0.10631108792704917
ROC train: 0.900801	val: 0.817203	test: 0.758170
PRC train: 0.536319	val: 0.332262	test: 0.212491

Epoch: 24
Loss: 0.10544682484785346
ROC train: 0.899429	val: 0.828205	test: 0.758825
PRC train: 0.548905	val: 0.318755	test: 0.183445

Epoch: 25
Loss: 0.10702337171300023
ROC train: 0.905982	val: 0.799220	test: 0.759455
PRC train: 0.559259	val: 0.319239	test: 0.202302

Epoch: 26
Loss: 0.10437101644069274
ROC train: 0.901570	val: 0.786550	test: 0.757780
PRC train: 0.542162	val: 0.300910	test: 0.203327

Epoch: 27
Loss: 0.10407359374166752
ROC train: 0.903344	val: 0.801382	test: 0.766871
PRC train: 0.549597	val: 0.327654	test: 0.206400

Epoch: 28
Loss: 0.10575849835913367
ROC train: 0.905877	val: 0.793737	test: 0.733759
PRC train: 0.558899	val: 0.318112	test: 0.148110

Epoch: 29
Loss: 0.10301270657311477
ROC train: 0.907666	val: 0.793746	test: 0.761679
PRC train: 0.573153	val: 0.338673	test: 0.191036

Epoch: 30
Loss: 0.1019205246232369
ROC train: 0.908895	val: 0.799349	test: 0.747566
PRC train: 0.553690	val: 0.334412	test: 0.176555

Epoch: 31
Loss: 0.10325367762286353
ROC train: 0.909466	val: 0.788565	test: 0.738079
PRC train: 0.573417	val: 0.319926	test: 0.167026

Epoch: 32
Loss: 0.10231654696913725
ROC train: 0.908299	val: 0.796241	test: 0.754455
PRC train: 0.556569	val: 0.276144	test: 0.155162

Epoch: 33
Loss: 0.10062610796562121Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/hiv/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/hiv/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/hiv/scaff/train_prop=0.8/hiv_scaff_5_26-05_11-11-03  ]
[ Using Seed :  5  ]
[ Using device :  cuda:2  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.2685423989074568
ROC train: 0.776835	val: 0.783519	test: 0.700514
PRC train: 0.234730	val: 0.205481	test: 0.178326

Epoch: 2
Loss: 0.13851585909754696
ROC train: 0.802707	val: 0.820268	test: 0.760123
PRC train: 0.307139	val: 0.277818	test: 0.179190

Epoch: 3
Loss: 0.13307965743889824
ROC train: 0.807731	val: 0.776865	test: 0.705162
PRC train: 0.320136	val: 0.251215	test: 0.124119

Epoch: 4
Loss: 0.12989816392657072
ROC train: 0.827101	val: 0.796847	test: 0.744800
PRC train: 0.367493	val: 0.261458	test: 0.147001

Epoch: 5
Loss: 0.12681105890941285
ROC train: 0.825064	val: 0.806177	test: 0.732658
PRC train: 0.372239	val: 0.322835	test: 0.159708

Epoch: 6
Loss: 0.12512607072850135
ROC train: 0.830218	val: 0.798746	test: 0.763815
PRC train: 0.379291	val: 0.291026	test: 0.186176

Epoch: 7
Loss: 0.12241954992075292
ROC train: 0.850173	val: 0.819236	test: 0.743771
PRC train: 0.430357	val: 0.330076	test: 0.191178

Epoch: 8
Loss: 0.121397412118119
ROC train: 0.838119	val: 0.764676	test: 0.726103
PRC train: 0.407733	val: 0.323991	test: 0.209959

Epoch: 9
Loss: 0.11888438427063432
ROC train: 0.854458	val: 0.814521	test: 0.742274
PRC train: 0.430764	val: 0.306820	test: 0.133447

Epoch: 10
Loss: 0.11732068013389207
ROC train: 0.863427	val: 0.813682	test: 0.773745
PRC train: 0.456484	val: 0.339285	test: 0.197993

Epoch: 11
Loss: 0.11591188764079498
ROC train: 0.856023	val: 0.833940	test: 0.762881
PRC train: 0.412802	val: 0.269162	test: 0.205827

Epoch: 12
Loss: 0.11522449672596242
ROC train: 0.864507	val: 0.821983	test: 0.768159
PRC train: 0.467629	val: 0.313429	test: 0.196338

Epoch: 13
Loss: 0.11431228560997722
ROC train: 0.871256	val: 0.786370	test: 0.757504
PRC train: 0.477355	val: 0.240533	test: 0.179803

Epoch: 14
Loss: 0.11482918336326528
ROC train: 0.871200	val: 0.809564	test: 0.745775
PRC train: 0.480486	val: 0.314369	test: 0.150242

Epoch: 15
Loss: 0.11267899289301529
ROC train: 0.876585	val: 0.808636	test: 0.764140
PRC train: 0.485080	val: 0.366467	test: 0.239764

Epoch: 16
Loss: 0.11080683621873857
ROC train: 0.881153	val: 0.811961	test: 0.782503
PRC train: 0.507691	val: 0.366776	test: 0.237460

Epoch: 17
Loss: 0.11008005176577303
ROC train: 0.881620	val: 0.819242	test: 0.750437
PRC train: 0.504290	val: 0.356658	test: 0.231572

Epoch: 18
Loss: 0.11043905986440072
ROC train: 0.892160	val: 0.817601	test: 0.772068
PRC train: 0.526965	val: 0.369391	test: 0.211299

Epoch: 19
Loss: 0.1089934157467664
ROC train: 0.894929	val: 0.816018	test: 0.752656
PRC train: 0.527348	val: 0.335282	test: 0.165424

Epoch: 20
Loss: 0.10848757076678922
ROC train: 0.886998	val: 0.806545	test: 0.779824
PRC train: 0.509395	val: 0.376551	test: 0.237802

Epoch: 21
Loss: 0.10640301765779456
ROC train: 0.896079	val: 0.817295	test: 0.766736
PRC train: 0.528639	val: 0.363487	test: 0.238275

Epoch: 22
Loss: 0.10702533645725507
ROC train: 0.894714	val: 0.814518	test: 0.754312
PRC train: 0.521519	val: 0.365979	test: 0.192826

Epoch: 23
Loss: 0.10791523801682733
ROC train: 0.895795	val: 0.806241	test: 0.771172
PRC train: 0.521467	val: 0.387662	test: 0.219970

Epoch: 24
Loss: 0.1064380830162793
ROC train: 0.903310	val: 0.806869	test: 0.749626
PRC train: 0.542153	val: 0.332732	test: 0.177124

Epoch: 25
Loss: 0.10502688563408778
ROC train: 0.891020	val: 0.804600	test: 0.748914
PRC train: 0.502455	val: 0.354370	test: 0.189113

Epoch: 26
Loss: 0.10368688862212265
ROC train: 0.905366	val: 0.805678	test: 0.764034
PRC train: 0.551643	val: 0.330724	test: 0.231004

Epoch: 27
Loss: 0.10383542298762277
ROC train: 0.903405	val: 0.810681	test: 0.746509
PRC train: 0.525710	val: 0.333966	test: 0.178524

Epoch: 28
Loss: 0.10294188539894106
ROC train: 0.907597	val: 0.797405	test: 0.768734
PRC train: 0.558418	val: 0.374577	test: 0.243829

Epoch: 29
Loss: 0.10241705469434276
ROC train: 0.917457	val: 0.805479	test: 0.761732
PRC train: 0.577313	val: 0.342018	test: 0.192056

Epoch: 30
Loss: 0.10249727864319609
ROC train: 0.903140	val: 0.824677	test: 0.763112
PRC train: 0.554084	val: 0.351646	test: 0.201885

Epoch: 31
Loss: 0.10189940456127507
ROC train: 0.918755	val: 0.826570	test: 0.748321
PRC train: 0.577815	val: 0.386604	test: 0.227306

Epoch: 32
Loss: 0.1008195071571842
ROC train: 0.919528	val: 0.814891	test: 0.773702
PRC train: 0.585468	val: 0.347232	test: 0.211830

Epoch: 33
Loss: 0.10118084839794927
ROC train: 0.937143	val: 0.713244	test: 0.765307
PRC train: 0.632345	val: 0.229860	test: 0.221790

Epoch: 34
Loss: 0.09481396015388446
ROC train: 0.940064	val: 0.711270	test: 0.747773
PRC train: 0.641494	val: 0.252356	test: 0.192546

Epoch: 35
Loss: 0.0950573256699484
ROC train: 0.942089	val: 0.710387	test: 0.750785
PRC train: 0.644385	val: 0.261749	test: 0.229764

Epoch: 36
Loss: 0.09520747064650165
ROC train: 0.939417	val: 0.709807	test: 0.753412
PRC train: 0.637498	val: 0.269865	test: 0.208431

Epoch: 37
Loss: 0.09192976703101538
ROC train: 0.943203	val: 0.712101	test: 0.755638
PRC train: 0.638034	val: 0.232409	test: 0.168838

Epoch: 38
Loss: 0.09324225012993498
ROC train: 0.938300	val: 0.729792	test: 0.761270
PRC train: 0.635061	val: 0.263406	test: 0.241228

Epoch: 39
Loss: 0.09382740560353046
ROC train: 0.937043	val: 0.726957	test: 0.764403
PRC train: 0.633585	val: 0.253438	test: 0.245958

Epoch: 40
Loss: 0.09117816911116325
ROC train: 0.947571	val: 0.724657	test: 0.737793
PRC train: 0.648065	val: 0.285313	test: 0.209133

Epoch: 41
Loss: 0.09050216079572654
ROC train: 0.952239	val: 0.716441	test: 0.751684
PRC train: 0.669566	val: 0.285998	test: 0.248459

Epoch: 42
Loss: 0.08955310311743805
ROC train: 0.936157	val: 0.706625	test: 0.717379
PRC train: 0.616221	val: 0.214296	test: 0.155183

Epoch: 43
Loss: 0.09075491421635537
ROC train: 0.954477	val: 0.717088	test: 0.762509
PRC train: 0.678860	val: 0.252944	test: 0.236229

Epoch: 44
Loss: 0.09088879933790055
ROC train: 0.952092	val: 0.712360	test: 0.745493
PRC train: 0.671447	val: 0.269786	test: 0.185856

Epoch: 45
Loss: 0.09045687935818925
ROC train: 0.915222	val: 0.701075	test: 0.740688
PRC train: 0.540955	val: 0.180480	test: 0.118880

Epoch: 46
Loss: 0.08937294349590147
ROC train: 0.949518	val: 0.720996	test: 0.755956
PRC train: 0.671400	val: 0.259290	test: 0.185091

Epoch: 47
Loss: 0.08862562517927591
ROC train: 0.956555	val: 0.709160	test: 0.746993
PRC train: 0.691392	val: 0.263135	test: 0.214092

Epoch: 48
Loss: 0.08729724170087419
ROC train: 0.958517	val: 0.709124	test: 0.736692
PRC train: 0.692181	val: 0.259583	test: 0.236634

Epoch: 49
Loss: 0.08684780348977333
ROC train: 0.950250	val: 0.710582	test: 0.746831
PRC train: 0.675291	val: 0.252364	test: 0.229284

Epoch: 50
Loss: 0.08648326007696482
ROC train: 0.959060	val: 0.710110	test: 0.751141
PRC train: 0.698464	val: 0.281407	test: 0.187451

Epoch: 51
Loss: 0.08612359447783968
ROC train: 0.954237	val: 0.715875	test: 0.746110
PRC train: 0.683809	val: 0.243869	test: 0.181772

Epoch: 52
Loss: 0.08623760074217879
ROC train: 0.957507	val: 0.707463	test: 0.733296
PRC train: 0.695755	val: 0.277024	test: 0.218961

Epoch: 53
Loss: 0.08510841880943898
ROC train: 0.961229	val: 0.711399	test: 0.738056
PRC train: 0.708342	val: 0.253303	test: 0.169615

Epoch: 54
Loss: 0.08419353699234747
ROC train: 0.961984	val: 0.711844	test: 0.747513
PRC train: 0.698023	val: 0.249303	test: 0.258116

Epoch: 55
Loss: 0.08412321760930193
ROC train: 0.955678	val: 0.715794	test: 0.742227
PRC train: 0.692833	val: 0.251044	test: 0.170076

Epoch: 56
Loss: 0.08573261284053615
ROC train: 0.965207	val: 0.718272	test: 0.762144
PRC train: 0.715226	val: 0.256885	test: 0.220822

Epoch: 57
Loss: 0.08435224401331065
ROC train: 0.963861	val: 0.717512	test: 0.755900
PRC train: 0.700230	val: 0.267444	test: 0.190812

Epoch: 58
Loss: 0.0840248928100563
ROC train: 0.964509	val: 0.720238	test: 0.754654
PRC train: 0.716938	val: 0.254543	test: 0.199109

Epoch: 59
Loss: 0.08208810520529546
ROC train: 0.965009	val: 0.713353	test: 0.727293
PRC train: 0.728574	val: 0.265312	test: 0.173703

Epoch: 60
Loss: 0.08243708345960449
ROC train: 0.965073	val: 0.713518	test: 0.758105
PRC train: 0.713071	val: 0.262541	test: 0.213911

Epoch: 61
Loss: 0.08204441059052023
ROC train: 0.963384	val: 0.717388	test: 0.734751
PRC train: 0.699821	val: 0.296168	test: 0.183052

Epoch: 62
Loss: 0.08378149828257812
ROC train: 0.971141	val: 0.719758	test: 0.744028
PRC train: 0.743057	val: 0.270890	test: 0.209546

Epoch: 63
Loss: 0.07997526062794759
ROC train: 0.964931	val: 0.711773	test: 0.755619
PRC train: 0.726717	val: 0.246971	test: 0.220847

Epoch: 64
Loss: 0.08117331335057051
ROC train: 0.966685	val: 0.722407	test: 0.757499
PRC train: 0.713165	val: 0.265672	test: 0.207361

Epoch: 65
Loss: 0.0814969136168196
ROC train: 0.969981	val: 0.719171	test: 0.750302
PRC train: 0.747068	val: 0.251990	test: 0.204855

Epoch: 66
Loss: 0.07792318149158961
ROC train: 0.972615	val: 0.719657	test: 0.760671
PRC train: 0.750345	val: 0.248139	test: 0.233623

Epoch: 67
Loss: 0.07920451729187683
ROC train: 0.969162	val: 0.710344	test: 0.767938
PRC train: 0.737255	val: 0.249609	test: 0.165546

Epoch: 68
Loss: 0.08057023744198877
ROC train: 0.969334	val: 0.712392	test: 0.760500
PRC train: 0.731738	val: 0.264901	test: 0.238360

Epoch: 69
Loss: 0.08214806694182072
ROC train: 0.973736	val: 0.716105	test: 0.749821
PRC train: 0.755615	val: 0.259911	test: 0.176313

Epoch: 70
Loss: 0.07818274740091151
ROC train: 0.970033	val: 0.709110	test: 0.745706
PRC train: 0.740944	val: 0.260989	test: 0.181053

Epoch: 71
Loss: 0.07858000084113784
ROC train: 0.972031	val: 0.711539	test: 0.759577
PRC train: 0.752559	val: 0.283507	test: 0.222985

Epoch: 72
Loss: 0.07982301399417503
ROC train: 0.975626	val: 0.714562	test: 0.751266
PRC train: 0.759030	val: 0.257535	test: 0.249109

Epoch: 73
Loss: 0.0793340963062785
ROC train: 0.974873	val: 0.726877	test: 0.759523
PRC train: 0.757087	val: 0.251138	test: 0.201068

Epoch: 74
Loss: 0.07764071934880931
ROC train: 0.974015	val: 0.722076	test: 0.760559
PRC train: 0.759773	val: 0.234710	test: 0.222832

Epoch: 75
Loss: 0.07710676576672518
ROC train: 0.976705	val: 0.715398	test: 0.753135
PRC train: 0.766243	val: 0.266131	test: 0.205286

Epoch: 76
Loss: 0.0755980167028274
ROC train: 0.974955	val: 0.715702	test: 0.760033
PRC train: 0.772755	val: 0.269314	test: 0.203091

Epoch: 77
Loss: 0.07679872527666622
ROC train: 0.975701	val: 0.718471	test: 0.758033
PRC train: 0.769817	val: 0.258351	test: 0.229256

Epoch: 78
Loss: 0.07433379238211776
ROC train: 0.975905	val: 0.706607	test: 0.739954
PRC train: 0.770063	val: 0.259079	test: 0.211602

Epoch: 79
Loss: 0.07413447889355133
ROC train: 0.974944	val: 0.713678	test: 0.756549
PRC train: 0.765923	val: 0.237397	test: 0.192175

Epoch: 80
Loss: 0.07526272181366865
ROC train: 0.976736	val: 0.725573	test: 0.770779
PRC train: 0.765859	val: 0.264331	test: 0.258155

Epoch: 81
Loss: 0.07587131555785184
ROC train: 0.978403	val: 0.720731	test: 0.763357
PRC train: 0.779469	val: 0.260508	test: 0.252259

Epoch: 82
Loss: 0.07461060841441561
ROC train: 0.972836	val: 0.715114	test: 0.745651
PRC train: 0.762742	val: 0.271856	test: 0.175603

Epoch: 83
Loss: 0.07467945672686778
ROC train: 0.976603	val: 0.723727	test: 0.766207
PRC train: 0.762862	val: 0.261272	test: 0.216272

Epoch: 84
Loss: 0.07366502009351117
ROC train: 0.978802	val: 0.720077	test: 0.763411
PRC train: 0.780337	val: 0.235214	test: 0.229488

Epoch: 85
Loss: 0.07191677994468247
ROC train: 0.978588	val: 0.711406	test: 0.751174
PRC train: 0.784778	val: 0.282127	test: 0.207681

Epoch: 86
Loss: 0.0720710485088107
ROC train: 0.981672	val: 0.727490	test: 0.752713
PRC train: 0.798870	val: 0.253495	test: 0.198279

Epoch: 87
Loss: 0.073113749155472
ROC train: 0.979760	val: 0.722359	test: 0.747052
PRC train: 0.787766	val: 0.262252	test: 0.191160

Epoch: 88
Loss: 0.071694569061136
ROC train: 0.980579	val: 0.711069	test: 0.754094
PRC train: 0.793531	val: 0.253240	test: 0.196630

Epoch: 89
Loss: 0.07199780419477532
ROC train: 0.980491	val: 0.713229	test: 0.737540
PRC train: 0.790471	val: 0.224961	test: 0.178544

Epoch: 90
Loss: 0.0735604208174641
ROC train: 0.981290	val: 0.708856	test: 0.749505
PRC train: 0.797114	val: 0.234801	test: 0.201674

Epoch: 91
Loss: 0.06921271613369408
ROC train: 0.982715	val: 0.721005	test: 0.761478
PRC train: 0.807083	val: 0.254730	test: 0.182856

Epoch: 92
Loss: 0.07103297611543002
ROC train: 0.982190	val: 0.726240	test: 0.759000
PRC train: 0.803441	val: 0.254456	test: 0.186616

Epoch: 93
Loss: 0.07034983109808661
ROC train: 0.983027	val: 0.711586	test: 0.742621
PRC train: 0.806668	val: 0.265879	test: 0.195131

Epoch: 94
Loss: 0.06993816873982556
ROC train: 0.943048	val: 0.716493	test: 0.746696
PRC train: 0.631808	val: 0.255697	test: 0.261064

Epoch: 34
Loss: 0.09445177641320396
ROC train: 0.946462	val: 0.712991	test: 0.741894
PRC train: 0.649147	val: 0.233552	test: 0.189754

Epoch: 35
Loss: 0.09244492272300643
ROC train: 0.941897	val: 0.708915	test: 0.745625
PRC train: 0.644572	val: 0.250440	test: 0.189626

Epoch: 36
Loss: 0.0944865796455573
ROC train: 0.940957	val: 0.711702	test: 0.759200
PRC train: 0.638945	val: 0.214721	test: 0.183896

Epoch: 37
Loss: 0.09231448172510436
ROC train: 0.936791	val: 0.710051	test: 0.734589
PRC train: 0.626271	val: 0.235533	test: 0.210420

Epoch: 38
Loss: 0.09077454769862528
ROC train: 0.946890	val: 0.697419	test: 0.753592
PRC train: 0.656277	val: 0.242637	test: 0.258538

Epoch: 39
Loss: 0.0909469450544935
ROC train: 0.946897	val: 0.708198	test: 0.764368
PRC train: 0.645005	val: 0.224424	test: 0.168473

Epoch: 40
Loss: 0.09056464550286063
ROC train: 0.945770	val: 0.714546	test: 0.760177
PRC train: 0.653098	val: 0.233066	test: 0.193819

Epoch: 41
Loss: 0.09088782617950153
ROC train: 0.951706	val: 0.723619	test: 0.763558
PRC train: 0.671703	val: 0.264406	test: 0.234301

Epoch: 42
Loss: 0.09079308031985459
ROC train: 0.950733	val: 0.703126	test: 0.757789
PRC train: 0.662483	val: 0.241977	test: 0.218442

Epoch: 43
Loss: 0.08973317839757536
ROC train: 0.952907	val: 0.724227	test: 0.755384
PRC train: 0.663373	val: 0.236031	test: 0.148547

Epoch: 44
Loss: 0.08871690107558218
ROC train: 0.955137	val: 0.724183	test: 0.756768
PRC train: 0.666526	val: 0.256805	test: 0.243335

Epoch: 45
Loss: 0.08809991112786007
ROC train: 0.959255	val: 0.717244	test: 0.744212
PRC train: 0.690234	val: 0.257776	test: 0.192566

Epoch: 46
Loss: 0.0881731926412974
ROC train: 0.959819	val: 0.716241	test: 0.760394
PRC train: 0.687523	val: 0.257413	test: 0.192227

Epoch: 47
Loss: 0.08787711239522308
ROC train: 0.953021	val: 0.711194	test: 0.756101
PRC train: 0.681255	val: 0.258046	test: 0.187988

Epoch: 48
Loss: 0.08592319766411577
ROC train: 0.955371	val: 0.714175	test: 0.761464
PRC train: 0.678913	val: 0.252558	test: 0.213419

Epoch: 49
Loss: 0.08697017734438625
ROC train: 0.956783	val: 0.711299	test: 0.737141
PRC train: 0.679833	val: 0.241459	test: 0.215952

Epoch: 50
Loss: 0.08760003577259447
ROC train: 0.961302	val: 0.717546	test: 0.755810
PRC train: 0.698231	val: 0.248489	test: 0.148759

Epoch: 51
Loss: 0.08598926955073795
ROC train: 0.962896	val: 0.720546	test: 0.755310
PRC train: 0.708543	val: 0.229744	test: 0.178751

Epoch: 52
Loss: 0.08494475598682509
ROC train: 0.963400	val: 0.701808	test: 0.755093
PRC train: 0.709083	val: 0.236085	test: 0.213777

Epoch: 53
Loss: 0.0869024152350871
ROC train: 0.958518	val: 0.716371	test: 0.740925
PRC train: 0.686211	val: 0.232957	test: 0.140018

Epoch: 54
Loss: 0.08472507056634702
ROC train: 0.964719	val: 0.715593	test: 0.748433
PRC train: 0.718955	val: 0.253519	test: 0.181852

Epoch: 55
Loss: 0.08391031391949672
ROC train: 0.964754	val: 0.727643	test: 0.750685
PRC train: 0.713541	val: 0.270227	test: 0.222722

Epoch: 56
Loss: 0.0836244353994037
ROC train: 0.962686	val: 0.715280	test: 0.753307
PRC train: 0.713421	val: 0.230725	test: 0.203095

Epoch: 57
Loss: 0.08320691187042634
ROC train: 0.962988	val: 0.713950	test: 0.752153
PRC train: 0.720823	val: 0.238806	test: 0.162935

Epoch: 58
Loss: 0.08228976784158311
ROC train: 0.966417	val: 0.717384	test: 0.763210
PRC train: 0.723260	val: 0.252949	test: 0.220421

Epoch: 59
Loss: 0.08400974856101578
ROC train: 0.966744	val: 0.713417	test: 0.753550
PRC train: 0.725189	val: 0.226561	test: 0.165172

Epoch: 60
Loss: 0.08158517850500993
ROC train: 0.968633	val: 0.725357	test: 0.758125
PRC train: 0.731661	val: 0.236886	test: 0.183098

Epoch: 61
Loss: 0.08385243784278212
ROC train: 0.966374	val: 0.721099	test: 0.766018
PRC train: 0.729070	val: 0.224516	test: 0.186163

Epoch: 62
Loss: 0.08254517152541793
ROC train: 0.961854	val: 0.703111	test: 0.761932
PRC train: 0.700839	val: 0.243143	test: 0.187090

Epoch: 63
Loss: 0.08176803196630988
ROC train: 0.970483	val: 0.704382	test: 0.767220
PRC train: 0.738096	val: 0.254815	test: 0.208168

Epoch: 64
Loss: 0.08070469718163716
ROC train: 0.968109	val: 0.715269	test: 0.757304
PRC train: 0.737164	val: 0.272426	test: 0.214857

Epoch: 65
Loss: 0.07810197429249935
ROC train: 0.971892	val: 0.719831	test: 0.750334
PRC train: 0.742939	val: 0.215444	test: 0.189071

Epoch: 66
Loss: 0.07977132545555096
ROC train: 0.969278	val: 0.723952	test: 0.763705
PRC train: 0.729523	val: 0.234772	test: 0.177966

Epoch: 67
Loss: 0.08003670272463961
ROC train: 0.971075	val: 0.717814	test: 0.767152
PRC train: 0.736288	val: 0.242292	test: 0.154748

Epoch: 68
Loss: 0.08004639269771797
ROC train: 0.972772	val: 0.719807	test: 0.766902
PRC train: 0.751901	val: 0.250872	test: 0.174211

Epoch: 69
Loss: 0.07914277593619713
ROC train: 0.970506	val: 0.721031	test: 0.769666
PRC train: 0.742517	val: 0.255515	test: 0.215732

Epoch: 70
Loss: 0.0777761895195101
ROC train: 0.974155	val: 0.715892	test: 0.757175
PRC train: 0.763661	val: 0.232200	test: 0.230152

Epoch: 71
Loss: 0.07659896519674603
ROC train: 0.968676	val: 0.716550	test: 0.752812
PRC train: 0.732720	val: 0.244682	test: 0.136751

Epoch: 72
Loss: 0.08044043547159661
ROC train: 0.976027	val: 0.727796	test: 0.762347
PRC train: 0.762656	val: 0.259208	test: 0.196615

Epoch: 73
Loss: 0.07610017547260774
ROC train: 0.972368	val: 0.714326	test: 0.747604
PRC train: 0.743137	val: 0.239128	test: 0.235709

Epoch: 74
Loss: 0.07558032628928626
ROC train: 0.978466	val: 0.714103	test: 0.763027
PRC train: 0.775762	val: 0.259837	test: 0.205670

Epoch: 75
Loss: 0.07634039792584073
ROC train: 0.976066	val: 0.709664	test: 0.764801
PRC train: 0.764389	val: 0.220122	test: 0.210109

Epoch: 76
Loss: 0.07659645975624438
ROC train: 0.972966	val: 0.704836	test: 0.744225
PRC train: 0.750219	val: 0.256556	test: 0.159664

Epoch: 77
Loss: 0.07596359371266592
ROC train: 0.977493	val: 0.723497	test: 0.753591
PRC train: 0.775084	val: 0.249568	test: 0.209197

Epoch: 78
Loss: 0.07486551379132005
ROC train: 0.975148	val: 0.707752	test: 0.759883
PRC train: 0.761070	val: 0.234210	test: 0.211997

Epoch: 79
Loss: 0.07376788812979142
ROC train: 0.976267	val: 0.715960	test: 0.749799
PRC train: 0.756677	val: 0.256390	test: 0.199254

Epoch: 80
Loss: 0.07368168816318392
ROC train: 0.975910	val: 0.708643	test: 0.750872
PRC train: 0.773009	val: 0.249928	test: 0.231981

Epoch: 81
Loss: 0.07332953147741186
ROC train: 0.975485	val: 0.712246	test: 0.752550
PRC train: 0.754914	val: 0.256394	test: 0.207775

Epoch: 82
Loss: 0.07393467275572986
ROC train: 0.978989	val: 0.718354	test: 0.766876
PRC train: 0.777405	val: 0.225544	test: 0.203109

Epoch: 83
Loss: 0.07434877387849513
ROC train: 0.981372	val: 0.713909	test: 0.755690
PRC train: 0.790960	val: 0.239078	test: 0.206925

Epoch: 84
Loss: 0.07329780666620705
ROC train: 0.974689	val: 0.708926	test: 0.753704
PRC train: 0.759951	val: 0.219681	test: 0.159717

Epoch: 85
Loss: 0.07477488917637193
ROC train: 0.977088	val: 0.708447	test: 0.771485
PRC train: 0.776947	val: 0.231221	test: 0.232975

Epoch: 86
Loss: 0.0743582421061109
ROC train: 0.980851	val: 0.704327	test: 0.773864
PRC train: 0.795840	val: 0.230865	test: 0.186023

Epoch: 87
Loss: 0.07107749702946675
ROC train: 0.979890	val: 0.710141	test: 0.744990
PRC train: 0.785185	val: 0.231366	test: 0.171746

Epoch: 88
Loss: 0.07144801280109245
ROC train: 0.978772	val: 0.709110	test: 0.747027
PRC train: 0.793482	val: 0.232904	test: 0.199336

Epoch: 89
Loss: 0.0729527735913908
ROC train: 0.980746	val: 0.714004	test: 0.741155
PRC train: 0.790178	val: 0.234491	test: 0.203689

Epoch: 90
Loss: 0.07122669345672991
ROC train: 0.982533	val: 0.715747	test: 0.739761
PRC train: 0.807356	val: 0.238928	test: 0.171481

Epoch: 91
Loss: 0.06978491135004106
ROC train: 0.980623	val: 0.708601	test: 0.752980
PRC train: 0.782798	val: 0.237617	test: 0.189338

Epoch: 92
Loss: 0.07125599532973324
ROC train: 0.980655	val: 0.713559	test: 0.742446
PRC train: 0.787079	val: 0.231986	test: 0.196113

Epoch: 93
Loss: 0.07122427695229631
ROC train: 0.982950	val: 0.713609	test: 0.750112
PRC train: 0.802462	val: 0.232720	test: 0.185396

Epoch: 94
Loss: 0.07123481660417105
ROC train: 0.941454	val: 0.705528	test: 0.756575
PRC train: 0.645367	val: 0.234381	test: 0.246574

Epoch: 34
Loss: 0.0937612568241624
ROC train: 0.935535	val: 0.706254	test: 0.762861
PRC train: 0.614545	val: 0.225745	test: 0.168912

Epoch: 35
Loss: 0.09226769011334741
ROC train: 0.942282	val: 0.703944	test: 0.742627
PRC train: 0.649584	val: 0.212796	test: 0.225652

Epoch: 36
Loss: 0.09330018990118195
ROC train: 0.940137	val: 0.698077	test: 0.739127
PRC train: 0.633602	val: 0.235732	test: 0.219962

Epoch: 37
Loss: 0.09279356844248816
ROC train: 0.944535	val: 0.722838	test: 0.739940
PRC train: 0.653407	val: 0.250857	test: 0.219026

Epoch: 38
Loss: 0.09200594613226613
ROC train: 0.943784	val: 0.706282	test: 0.758388
PRC train: 0.633565	val: 0.246698	test: 0.242217

Epoch: 39
Loss: 0.09347580397484632
ROC train: 0.945472	val: 0.706207	test: 0.743942
PRC train: 0.643642	val: 0.249358	test: 0.221018

Epoch: 40
Loss: 0.09115062808492351
ROC train: 0.953258	val: 0.709716	test: 0.759063
PRC train: 0.663803	val: 0.265327	test: 0.244566

Epoch: 41
Loss: 0.09094388392806611
ROC train: 0.955664	val: 0.699908	test: 0.756835
PRC train: 0.685992	val: 0.257795	test: 0.232960

Epoch: 42
Loss: 0.0894095023875362
ROC train: 0.953443	val: 0.707187	test: 0.760026
PRC train: 0.676317	val: 0.248568	test: 0.240639

Epoch: 43
Loss: 0.08944555669782182
ROC train: 0.951334	val: 0.711700	test: 0.740982
PRC train: 0.677875	val: 0.246505	test: 0.192002

Epoch: 44
Loss: 0.08711699815619836
ROC train: 0.952447	val: 0.713509	test: 0.749152
PRC train: 0.674983	val: 0.263365	test: 0.202969

Epoch: 45
Loss: 0.08998168913286184
ROC train: 0.952325	val: 0.707003	test: 0.744125
PRC train: 0.687168	val: 0.266348	test: 0.208490

Epoch: 46
Loss: 0.08823113076171712
ROC train: 0.952604	val: 0.704956	test: 0.764378
PRC train: 0.684662	val: 0.234483	test: 0.200340

Epoch: 47
Loss: 0.08814379414621659
ROC train: 0.955044	val: 0.708008	test: 0.762823
PRC train: 0.694118	val: 0.242839	test: 0.194847

Epoch: 48
Loss: 0.08579504586528192
ROC train: 0.957724	val: 0.703756	test: 0.736022
PRC train: 0.691288	val: 0.234224	test: 0.180236

Epoch: 49
Loss: 0.08611028697305102
ROC train: 0.962457	val: 0.713312	test: 0.756693
PRC train: 0.705992	val: 0.249917	test: 0.183822

Epoch: 50
Loss: 0.08630691380179094
ROC train: 0.957352	val: 0.694298	test: 0.746306
PRC train: 0.684493	val: 0.212775	test: 0.169489

Epoch: 51
Loss: 0.08586536076788079
ROC train: 0.957837	val: 0.719730	test: 0.758901
PRC train: 0.701693	val: 0.229589	test: 0.181430

Epoch: 52
Loss: 0.08409624705598993
ROC train: 0.958952	val: 0.702688	test: 0.744444
PRC train: 0.694487	val: 0.243095	test: 0.229979

Epoch: 53
Loss: 0.08367081546930083
ROC train: 0.961375	val: 0.717616	test: 0.736806
PRC train: 0.699303	val: 0.272576	test: 0.217778

Epoch: 54
Loss: 0.08427430157472691
ROC train: 0.959310	val: 0.698672	test: 0.740168
PRC train: 0.700044	val: 0.270739	test: 0.233562

Epoch: 55
Loss: 0.08492249419435471
ROC train: 0.962280	val: 0.709121	test: 0.748617
PRC train: 0.710091	val: 0.263806	test: 0.202432

Epoch: 56
Loss: 0.08400739949687305
ROC train: 0.963891	val: 0.709815	test: 0.750438
PRC train: 0.717748	val: 0.267876	test: 0.200903

Epoch: 57
Loss: 0.08209303164333026
ROC train: 0.962945	val: 0.699585	test: 0.739115
PRC train: 0.716724	val: 0.255378	test: 0.185458

Epoch: 58
Loss: 0.08376910877002978
ROC train: 0.962750	val: 0.700396	test: 0.744575
PRC train: 0.712131	val: 0.254750	test: 0.219880

Epoch: 59
Loss: 0.08195034073901243
ROC train: 0.966397	val: 0.709818	test: 0.770375
PRC train: 0.719205	val: 0.255809	test: 0.212266

Epoch: 60
Loss: 0.08269639243287893
ROC train: 0.966871	val: 0.709121	test: 0.763464
PRC train: 0.722290	val: 0.252926	test: 0.204926

Epoch: 61
Loss: 0.08127350140761833
ROC train: 0.967862	val: 0.702826	test: 0.755494
PRC train: 0.727282	val: 0.240989	test: 0.196478

Epoch: 62
Loss: 0.08206596390975357
ROC train: 0.968471	val: 0.716298	test: 0.749071
PRC train: 0.729639	val: 0.270132	test: 0.223303

Epoch: 63
Loss: 0.07976857348498428
ROC train: 0.967785	val: 0.710972	test: 0.731015
PRC train: 0.731064	val: 0.237651	test: 0.165143

Epoch: 64
Loss: 0.08120009615059073
ROC train: 0.969001	val: 0.714724	test: 0.751044
PRC train: 0.737969	val: 0.260158	test: 0.226212

Epoch: 65
Loss: 0.07907841730552106
ROC train: 0.968557	val: 0.707858	test: 0.747306
PRC train: 0.721179	val: 0.250774	test: 0.205374

Epoch: 66
Loss: 0.08064109558783202
ROC train: 0.967657	val: 0.703616	test: 0.757407
PRC train: 0.727340	val: 0.245977	test: 0.165119

Epoch: 67
Loss: 0.07970872873655169
ROC train: 0.971090	val: 0.697422	test: 0.756894
PRC train: 0.746412	val: 0.227015	test: 0.150623

Epoch: 68
Loss: 0.07925224338983565
ROC train: 0.973522	val: 0.707483	test: 0.753950
PRC train: 0.752321	val: 0.263107	test: 0.210637

Epoch: 69
Loss: 0.07882049312684597
ROC train: 0.973671	val: 0.699981	test: 0.764256
PRC train: 0.759811	val: 0.246439	test: 0.194321

Epoch: 70
Loss: 0.07862108497626073
ROC train: 0.973525	val: 0.705621	test: 0.752553
PRC train: 0.756720	val: 0.239301	test: 0.205567

Epoch: 71
Loss: 0.07804034893543038
ROC train: 0.974295	val: 0.714631	test: 0.750039
PRC train: 0.757129	val: 0.248961	test: 0.236481

Epoch: 72
Loss: 0.07711671399942677
ROC train: 0.975024	val: 0.703011	test: 0.756902
PRC train: 0.758168	val: 0.256250	test: 0.204468

Epoch: 73
Loss: 0.07567900127824063
ROC train: 0.969191	val: 0.704899	test: 0.758357
PRC train: 0.744148	val: 0.249866	test: 0.174558

Epoch: 74
Loss: 0.07613685826849455
ROC train: 0.975485	val: 0.708012	test: 0.737419
PRC train: 0.760487	val: 0.264027	test: 0.189788

Epoch: 75
Loss: 0.07494473777154305
ROC train: 0.973613	val: 0.710469	test: 0.732091
PRC train: 0.757533	val: 0.240691	test: 0.171329

Epoch: 76
Loss: 0.07569983019456965
ROC train: 0.973179	val: 0.712014	test: 0.752780
PRC train: 0.756162	val: 0.270744	test: 0.232492

Epoch: 77
Loss: 0.07389677693485258
ROC train: 0.974727	val: 0.693962	test: 0.737077
PRC train: 0.767737	val: 0.241019	test: 0.131504

Epoch: 78
Loss: 0.07571246381386114
ROC train: 0.973988	val: 0.704158	test: 0.747119
PRC train: 0.761439	val: 0.246225	test: 0.208107

Epoch: 79
Loss: 0.07388048937102466
ROC train: 0.977844	val: 0.707265	test: 0.755367
PRC train: 0.771146	val: 0.258011	test: 0.216283

Epoch: 80
Loss: 0.07499847546403275
ROC train: 0.975302	val: 0.705914	test: 0.749648
PRC train: 0.758161	val: 0.256780	test: 0.236821

Epoch: 81
Loss: 0.07506605413773378
ROC train: 0.978796	val: 0.706014	test: 0.756849
PRC train: 0.782971	val: 0.250130	test: 0.188486

Epoch: 82
Loss: 0.07349436439773802
ROC train: 0.977165	val: 0.708492	test: 0.749257
PRC train: 0.770501	val: 0.270304	test: 0.243508

Epoch: 83
Loss: 0.07245288292265363
ROC train: 0.979987	val: 0.700702	test: 0.743546
PRC train: 0.792030	val: 0.245738	test: 0.202698

Epoch: 84
Loss: 0.07341318220814777
ROC train: 0.979742	val: 0.704416	test: 0.745759
PRC train: 0.786964	val: 0.254449	test: 0.207333

Epoch: 85
Loss: 0.07266472749741187
ROC train: 0.978629	val: 0.706788	test: 0.746874
PRC train: 0.788693	val: 0.252074	test: 0.182797

Epoch: 86
Loss: 0.07207260369829811
ROC train: 0.979542	val: 0.700229	test: 0.749356
PRC train: 0.793473	val: 0.246156	test: 0.194146

Epoch: 87
Loss: 0.07280117381924515
ROC train: 0.981193	val: 0.706645	test: 0.744390
PRC train: 0.804047	val: 0.232556	test: 0.184846

Epoch: 88
Loss: 0.07387857685246016
ROC train: 0.982973	val: 0.710273	test: 0.757139
PRC train: 0.811220	val: 0.255469	test: 0.216199

Epoch: 89
Loss: 0.069473709675796
ROC train: 0.981225	val: 0.706814	test: 0.735936
PRC train: 0.795979	val: 0.265351	test: 0.206876

Epoch: 90
Loss: 0.07080466658473908
ROC train: 0.980830	val: 0.693054	test: 0.737145
PRC train: 0.791976	val: 0.234545	test: 0.152403

Epoch: 91
Loss: 0.07004112504927838
ROC train: 0.980637	val: 0.699905	test: 0.751395
PRC train: 0.797793	val: 0.246701	test: 0.180013

Epoch: 92
Loss: 0.07127191832884058
ROC train: 0.979658	val: 0.704922	test: 0.747583
PRC train: 0.798447	val: 0.244505	test: 0.158778

Epoch: 93
Loss: 0.0694381143659393
ROC train: 0.983109	val: 0.703266	test: 0.749168
PRC train: 0.807473	val: 0.240907	test: 0.188036
ROC train: 0.931962	val: 0.737236	test: 0.748121
PRC train: 0.600587	val: 0.287484	test: 0.117542

Epoch: 34
Loss: 0.09789961992664535
ROC train: 0.932249	val: 0.728520	test: 0.743499
PRC train: 0.620933	val: 0.291793	test: 0.153353

Epoch: 35
Loss: 0.09785543089356963
ROC train: 0.927224	val: 0.738447	test: 0.744021
PRC train: 0.595637	val: 0.298909	test: 0.184869

Epoch: 36
Loss: 0.09626556479479406
ROC train: 0.935342	val: 0.738688	test: 0.760512
PRC train: 0.614749	val: 0.320383	test: 0.210443

Epoch: 37
Loss: 0.09613313310437127
ROC train: 0.936248	val: 0.747534	test: 0.762909
PRC train: 0.631147	val: 0.330264	test: 0.215122

Epoch: 38
Loss: 0.0968925862376499
ROC train: 0.935318	val: 0.740314	test: 0.746112
PRC train: 0.612680	val: 0.305100	test: 0.190976

Epoch: 39
Loss: 0.09592089949479433
ROC train: 0.939499	val: 0.723286	test: 0.757778
PRC train: 0.639772	val: 0.298300	test: 0.172206

Epoch: 40
Loss: 0.09552940627294704
ROC train: 0.941296	val: 0.730077	test: 0.759816
PRC train: 0.640845	val: 0.313194	test: 0.158749

Epoch: 41
Loss: 0.0954260341796599
ROC train: 0.934448	val: 0.739644	test: 0.746980
PRC train: 0.628724	val: 0.318914	test: 0.181488

Epoch: 42
Loss: 0.09319074658168508
ROC train: 0.940616	val: 0.733259	test: 0.742745
PRC train: 0.639310	val: 0.289458	test: 0.156633

Epoch: 43
Loss: 0.09320390731298761
ROC train: 0.943781	val: 0.728616	test: 0.735133
PRC train: 0.656686	val: 0.284244	test: 0.150752

Epoch: 44
Loss: 0.09250357154556965
ROC train: 0.942542	val: 0.720152	test: 0.759420
PRC train: 0.645074	val: 0.295490	test: 0.185822

Epoch: 45
Loss: 0.09254273960422964
ROC train: 0.945066	val: 0.727087	test: 0.753021
PRC train: 0.658486	val: 0.285567	test: 0.192342

Epoch: 46
Loss: 0.09060937287190371
ROC train: 0.946798	val: 0.728968	test: 0.760754
PRC train: 0.657620	val: 0.298108	test: 0.208008

Epoch: 47
Loss: 0.0926004487625107
ROC train: 0.949977	val: 0.711716	test: 0.742138
PRC train: 0.664683	val: 0.298534	test: 0.175090

Epoch: 48
Loss: 0.09004371549425853
ROC train: 0.948984	val: 0.729098	test: 0.767049
PRC train: 0.653318	val: 0.297538	test: 0.167025

Epoch: 49
Loss: 0.09105825410639112
ROC train: 0.951080	val: 0.725742	test: 0.745626
PRC train: 0.665598	val: 0.287805	test: 0.147738

Epoch: 50
Loss: 0.09020053881042414
ROC train: 0.943310	val: 0.725785	test: 0.736133
PRC train: 0.634885	val: 0.276650	test: 0.114052

Epoch: 51
Loss: 0.09060531466159945
ROC train: 0.954284	val: 0.716195	test: 0.745279
PRC train: 0.672003	val: 0.275427	test: 0.149071

Epoch: 52
Loss: 0.08863764775247937
ROC train: 0.951902	val: 0.734943	test: 0.755413
PRC train: 0.671207	val: 0.304388	test: 0.176365

Epoch: 53
Loss: 0.08997614353651406
ROC train: 0.955224	val: 0.727188	test: 0.757965
PRC train: 0.679565	val: 0.291576	test: 0.165463

Epoch: 54
Loss: 0.0892329561687425
ROC train: 0.953749	val: 0.719356	test: 0.733054
PRC train: 0.669381	val: 0.272243	test: 0.120154

Epoch: 55
Loss: 0.08767084034205774
ROC train: 0.959187	val: 0.733435	test: 0.762536
PRC train: 0.696193	val: 0.287083	test: 0.160047

Epoch: 56
Loss: 0.08788293692566257
ROC train: 0.953370	val: 0.724398	test: 0.743887
PRC train: 0.680771	val: 0.315036	test: 0.173757

Epoch: 57
Loss: 0.0878851066524158
ROC train: 0.955050	val: 0.731088	test: 0.761629
PRC train: 0.691268	val: 0.319741	test: 0.197199

Epoch: 58
Loss: 0.08753168236715188
ROC train: 0.958496	val: 0.726341	test: 0.753426
PRC train: 0.700252	val: 0.305534	test: 0.170663

Epoch: 59
Loss: 0.08585281920665262
ROC train: 0.957363	val: 0.715687	test: 0.748166
PRC train: 0.677426	val: 0.310844	test: 0.182137

Epoch: 60
Loss: 0.08582541523861972
ROC train: 0.959184	val: 0.712764	test: 0.756224
PRC train: 0.703930	val: 0.297944	test: 0.185716

Epoch: 61
Loss: 0.08400205625431126
ROC train: 0.960063	val: 0.720315	test: 0.749981
PRC train: 0.701961	val: 0.284953	test: 0.141791

Epoch: 62
Loss: 0.08646672395489204
ROC train: 0.962977	val: 0.730215	test: 0.748638
PRC train: 0.710790	val: 0.301720	test: 0.170227

Epoch: 63
Loss: 0.08362348580403303
ROC train: 0.958794	val: 0.717646	test: 0.767724
PRC train: 0.690858	val: 0.289923	test: 0.173489

Epoch: 64
Loss: 0.0848814725369426
ROC train: 0.959446	val: 0.716972	test: 0.753003
PRC train: 0.702529	val: 0.281171	test: 0.163751

Epoch: 65
Loss: 0.08394557245239295
ROC train: 0.959096	val: 0.716091	test: 0.735746
PRC train: 0.695434	val: 0.272575	test: 0.107151

Epoch: 66
Loss: 0.08493050058045765
ROC train: 0.962949	val: 0.725863	test: 0.730946
PRC train: 0.708938	val: 0.298452	test: 0.171894

Epoch: 67
Loss: 0.08453233744302703
ROC train: 0.964366	val: 0.729745	test: 0.755727
PRC train: 0.718228	val: 0.268656	test: 0.147220

Epoch: 68
Loss: 0.08309442711278349
ROC train: 0.966262	val: 0.729406	test: 0.749265
PRC train: 0.722230	val: 0.298394	test: 0.167397

Epoch: 69
Loss: 0.08416362429341112
ROC train: 0.966742	val: 0.719191	test: 0.759487
PRC train: 0.732063	val: 0.293029	test: 0.184730

Epoch: 70
Loss: 0.08164477308860567
ROC train: 0.967093	val: 0.731962	test: 0.757642
PRC train: 0.730947	val: 0.296789	test: 0.188285

Epoch: 71
Loss: 0.08258763957889796
ROC train: 0.965292	val: 0.730317	test: 0.747511
PRC train: 0.716771	val: 0.281786	test: 0.172389

Epoch: 72
Loss: 0.0818327432648656
ROC train: 0.969708	val: 0.716626	test: 0.751346
PRC train: 0.744443	val: 0.306141	test: 0.182550

Epoch: 73
Loss: 0.08061817812666137
ROC train: 0.969122	val: 0.702526	test: 0.754184
PRC train: 0.744912	val: 0.281678	test: 0.188503

Epoch: 74
Loss: 0.08034239257209402
ROC train: 0.969495	val: 0.722466	test: 0.767693
PRC train: 0.731248	val: 0.314375	test: 0.237658

Epoch: 75
Loss: 0.07981576665468597
ROC train: 0.969235	val: 0.725141	test: 0.749630
PRC train: 0.742818	val: 0.275978	test: 0.162333

Epoch: 76
Loss: 0.07896541729614609
ROC train: 0.971658	val: 0.713964	test: 0.745278
PRC train: 0.754101	val: 0.297367	test: 0.160235

Epoch: 77
Loss: 0.07993220697053856
ROC train: 0.973902	val: 0.723369	test: 0.747733
PRC train: 0.759681	val: 0.292192	test: 0.144238

Epoch: 78
Loss: 0.07935366952477545
ROC train: 0.965248	val: 0.724239	test: 0.748303
PRC train: 0.729890	val: 0.277072	test: 0.173150

Epoch: 79
Loss: 0.0789323135476484
ROC train: 0.971554	val: 0.720255	test: 0.743219
PRC train: 0.744749	val: 0.253882	test: 0.147381

Epoch: 80
Loss: 0.0781047225034507
ROC train: 0.971143	val: 0.724503	test: 0.766618
PRC train: 0.746533	val: 0.289149	test: 0.208287

Epoch: 81
Loss: 0.07808924187854949
ROC train: 0.973695	val: 0.726229	test: 0.761772
PRC train: 0.756631	val: 0.297548	test: 0.229556

Epoch: 82
Loss: 0.07605995061030704
ROC train: 0.972094	val: 0.711778	test: 0.737520
PRC train: 0.745060	val: 0.269183	test: 0.159617

Epoch: 83
Loss: 0.07667009247396993
ROC train: 0.973456	val: 0.721724	test: 0.770145
PRC train: 0.756781	val: 0.284537	test: 0.174713

Epoch: 84
Loss: 0.07555096606227057
ROC train: 0.973335	val: 0.715420	test: 0.740247
PRC train: 0.740053	val: 0.286963	test: 0.185843

Epoch: 85
Loss: 0.07624329719750712
ROC train: 0.977541	val: 0.728499	test: 0.740626
PRC train: 0.773331	val: 0.270160	test: 0.160996

Epoch: 86
Loss: 0.07673495032475015
ROC train: 0.976566	val: 0.723569	test: 0.748344
PRC train: 0.774525	val: 0.284831	test: 0.198765

Epoch: 87
Loss: 0.07448931788314721
ROC train: 0.976164	val: 0.726544	test: 0.759740
PRC train: 0.779142	val: 0.292431	test: 0.203643

Epoch: 88
Loss: 0.07659889954148444
ROC train: 0.975776	val: 0.721927	test: 0.755261
PRC train: 0.769226	val: 0.295162	test: 0.187518

Epoch: 89
Loss: 0.07394874387260446
ROC train: 0.978891	val: 0.724827	test: 0.751738
PRC train: 0.778833	val: 0.286299	test: 0.189956

Epoch: 90
Loss: 0.07581536325633753
ROC train: 0.979354	val: 0.724178	test: 0.764188
PRC train: 0.785714	val: 0.283081	test: 0.186474

Epoch: 91
Loss: 0.07455242930736702
ROC train: 0.978823	val: 0.718387	test: 0.755802
PRC train: 0.783519	val: 0.281424	test: 0.187944

Epoch: 92
Loss: 0.07577845374730159
ROC train: 0.980430	val: 0.727469	test: 0.764252
PRC train: 0.792774	val: 0.286664	test: 0.175031

Epoch: 93
Loss: 0.07398728984349112
ROC train: 0.978005	val: 0.714897	test: 0.751562
PRC train: 0.790896	val: 0.269206	test: 0.145961

Epoch: 94
Loss: 0.07301434664219335
ROC train: 0.926801	val: 0.727072	test: 0.750374
PRC train: 0.599155	val: 0.282299	test: 0.176223

Epoch: 34
Loss: 0.09876571446048026
ROC train: 0.925345	val: 0.744559	test: 0.765271
PRC train: 0.590925	val: 0.303332	test: 0.198054

Epoch: 35
Loss: 0.09704979933451692
ROC train: 0.930603	val: 0.717056	test: 0.763640
PRC train: 0.612974	val: 0.294091	test: 0.219027

Epoch: 36
Loss: 0.09796326879007684
ROC train: 0.926854	val: 0.734794	test: 0.756284
PRC train: 0.604021	val: 0.311636	test: 0.170813

Epoch: 37
Loss: 0.09778027344073126
ROC train: 0.933296	val: 0.717865	test: 0.780542
PRC train: 0.611095	val: 0.308338	test: 0.210127

Epoch: 38
Loss: 0.09566768322274609
ROC train: 0.934697	val: 0.716956	test: 0.755969
PRC train: 0.611018	val: 0.271777	test: 0.110914

Epoch: 39
Loss: 0.09640656256740654
ROC train: 0.936397	val: 0.727020	test: 0.748796
PRC train: 0.636028	val: 0.290874	test: 0.140372

Epoch: 40
Loss: 0.0964834778937652
ROC train: 0.937186	val: 0.714054	test: 0.774951
PRC train: 0.637769	val: 0.306918	test: 0.204695

Epoch: 41
Loss: 0.09521551516685277
ROC train: 0.935272	val: 0.718550	test: 0.759630
PRC train: 0.621341	val: 0.244980	test: 0.122476

Epoch: 42
Loss: 0.09478185933596989
ROC train: 0.940045	val: 0.718308	test: 0.775870
PRC train: 0.648736	val: 0.276977	test: 0.151732

Epoch: 43
Loss: 0.09432050470390041
ROC train: 0.944759	val: 0.723755	test: 0.765573
PRC train: 0.637491	val: 0.290219	test: 0.166167

Epoch: 44
Loss: 0.0925340343609064
ROC train: 0.936784	val: 0.705138	test: 0.761449
PRC train: 0.621668	val: 0.258436	test: 0.129890

Epoch: 45
Loss: 0.09436454985882523
ROC train: 0.940623	val: 0.727726	test: 0.747238
PRC train: 0.631733	val: 0.286216	test: 0.166429

Epoch: 46
Loss: 0.09248087169998191
ROC train: 0.942195	val: 0.729841	test: 0.741551
PRC train: 0.645421	val: 0.292106	test: 0.138049

Epoch: 47
Loss: 0.09287868420203338
ROC train: 0.947115	val: 0.734628	test: 0.764064
PRC train: 0.656154	val: 0.295859	test: 0.171265

Epoch: 48
Loss: 0.0916680910863311
ROC train: 0.950656	val: 0.713287	test: 0.772313
PRC train: 0.674672	val: 0.271855	test: 0.187697

Epoch: 49
Loss: 0.0910514706041667
ROC train: 0.952850	val: 0.739467	test: 0.766249
PRC train: 0.678851	val: 0.292951	test: 0.146617

Epoch: 50
Loss: 0.09091998974440829
ROC train: 0.946714	val: 0.715261	test: 0.755962
PRC train: 0.666873	val: 0.284541	test: 0.140588

Epoch: 51
Loss: 0.08975835156711261
ROC train: 0.952478	val: 0.714171	test: 0.774354
PRC train: 0.668064	val: 0.295347	test: 0.198750

Epoch: 52
Loss: 0.08901244442091073
ROC train: 0.952203	val: 0.720336	test: 0.755130
PRC train: 0.683913	val: 0.297747	test: 0.160915

Epoch: 53
Loss: 0.08934897589703439
ROC train: 0.948627	val: 0.722403	test: 0.750581
PRC train: 0.666730	val: 0.296261	test: 0.191845

Epoch: 54
Loss: 0.08898235171140716
ROC train: 0.951165	val: 0.726816	test: 0.770879
PRC train: 0.667193	val: 0.305356	test: 0.177132

Epoch: 55
Loss: 0.08840415631716318
ROC train: 0.953351	val: 0.726622	test: 0.746671
PRC train: 0.680865	val: 0.298831	test: 0.187160

Epoch: 56
Loss: 0.08749713646052573
ROC train: 0.954032	val: 0.713476	test: 0.750064
PRC train: 0.685731	val: 0.267776	test: 0.140002

Epoch: 57
Loss: 0.08893772894717102
ROC train: 0.953508	val: 0.709503	test: 0.759540
PRC train: 0.692749	val: 0.290739	test: 0.172634

Epoch: 58
Loss: 0.08759447427454115
ROC train: 0.958136	val: 0.729188	test: 0.751586
PRC train: 0.702805	val: 0.291797	test: 0.148383

Epoch: 59
Loss: 0.08660751382818098
ROC train: 0.957509	val: 0.731763	test: 0.753315
PRC train: 0.687889	val: 0.257992	test: 0.116603

Epoch: 60
Loss: 0.08702847633878852
ROC train: 0.954533	val: 0.727066	test: 0.756869
PRC train: 0.682930	val: 0.317473	test: 0.179123

Epoch: 61
Loss: 0.08526251069605523
ROC train: 0.955466	val: 0.703325	test: 0.758027
PRC train: 0.689433	val: 0.210358	test: 0.135972

Epoch: 62
Loss: 0.08501431031411899
ROC train: 0.960050	val: 0.720838	test: 0.763392
PRC train: 0.708671	val: 0.277749	test: 0.141276

Epoch: 63
Loss: 0.08641077250926786
ROC train: 0.957689	val: 0.710400	test: 0.761001
PRC train: 0.692827	val: 0.293092	test: 0.205902

Epoch: 64
Loss: 0.08448714203491704
ROC train: 0.959743	val: 0.724945	test: 0.757361
PRC train: 0.707709	val: 0.265597	test: 0.157384

Epoch: 65
Loss: 0.08438477861466986
ROC train: 0.960831	val: 0.723433	test: 0.760707
PRC train: 0.710268	val: 0.272466	test: 0.147048

Epoch: 66
Loss: 0.08375434748814665
ROC train: 0.966483	val: 0.722274	test: 0.758271
PRC train: 0.732598	val: 0.284891	test: 0.168397

Epoch: 67
Loss: 0.08421277828582611
ROC train: 0.963629	val: 0.727727	test: 0.763214
PRC train: 0.711046	val: 0.271043	test: 0.152191

Epoch: 68
Loss: 0.08334039189829184
ROC train: 0.961563	val: 0.700748	test: 0.734309
PRC train: 0.713188	val: 0.259563	test: 0.150624

Epoch: 69
Loss: 0.08445245946523873
ROC train: 0.963999	val: 0.724372	test: 0.757098
PRC train: 0.719096	val: 0.279869	test: 0.142772

Epoch: 70
Loss: 0.08288609656596302
ROC train: 0.966458	val: 0.714671	test: 0.749272
PRC train: 0.723785	val: 0.226312	test: 0.127015

Epoch: 71
Loss: 0.08188441138723156
ROC train: 0.966129	val: 0.723779	test: 0.757283
PRC train: 0.728180	val: 0.278259	test: 0.176881

Epoch: 72
Loss: 0.08278493250559235
ROC train: 0.967854	val: 0.715024	test: 0.760532
PRC train: 0.733081	val: 0.263817	test: 0.155830

Epoch: 73
Loss: 0.08044387112944308
ROC train: 0.969212	val: 0.708993	test: 0.759797
PRC train: 0.742436	val: 0.268555	test: 0.161914

Epoch: 74
Loss: 0.08218197211525087
ROC train: 0.968661	val: 0.714687	test: 0.753196
PRC train: 0.736175	val: 0.251452	test: 0.131464

Epoch: 75
Loss: 0.0809563454041256
ROC train: 0.968522	val: 0.712743	test: 0.747709
PRC train: 0.744013	val: 0.275651	test: 0.171149

Epoch: 76
Loss: 0.07942080749528979
ROC train: 0.971124	val: 0.731573	test: 0.753522
PRC train: 0.741349	val: 0.286267	test: 0.176533

Epoch: 77
Loss: 0.08169187101554702
ROC train: 0.969697	val: 0.723545	test: 0.760042
PRC train: 0.744617	val: 0.297106	test: 0.192662

Epoch: 78
Loss: 0.07894670462450497
ROC train: 0.970829	val: 0.716868	test: 0.735792
PRC train: 0.741321	val: 0.267345	test: 0.167172

Epoch: 79
Loss: 0.079059406764102
ROC train: 0.973299	val: 0.714363	test: 0.755451
PRC train: 0.751851	val: 0.297509	test: 0.209606

Epoch: 80
Loss: 0.0783711585116298
ROC train: 0.972851	val: 0.728199	test: 0.731903
PRC train: 0.748506	val: 0.262153	test: 0.121331

Epoch: 81
Loss: 0.07902562913460885
ROC train: 0.974501	val: 0.725832	test: 0.745880
PRC train: 0.753077	val: 0.293238	test: 0.138031

Epoch: 82
Loss: 0.07914928165834101
ROC train: 0.968642	val: 0.728761	test: 0.730707
PRC train: 0.740803	val: 0.268821	test: 0.153325

Epoch: 83
Loss: 0.07894741210710979
ROC train: 0.974284	val: 0.719281	test: 0.757826
PRC train: 0.758696	val: 0.270790	test: 0.174318

Epoch: 84
Loss: 0.07794996542529845
ROC train: 0.975567	val: 0.724138	test: 0.759364
PRC train: 0.761773	val: 0.300920	test: 0.225548

Epoch: 85
Loss: 0.07762864112747689
ROC train: 0.975274	val: 0.707709	test: 0.759431
PRC train: 0.760785	val: 0.288136	test: 0.202069

Epoch: 86
Loss: 0.07646078207762633
ROC train: 0.975299	val: 0.730612	test: 0.748822
PRC train: 0.759869	val: 0.269642	test: 0.155360

Epoch: 87
Loss: 0.07785335794846929
ROC train: 0.976758	val: 0.718951	test: 0.743101
PRC train: 0.778303	val: 0.277017	test: 0.134172

Epoch: 88
Loss: 0.07722424724598631
ROC train: 0.972465	val: 0.730299	test: 0.760461
PRC train: 0.758953	val: 0.282426	test: 0.150465

Epoch: 89
Loss: 0.07638243174430029
ROC train: 0.978436	val: 0.719323	test: 0.755394
PRC train: 0.780099	val: 0.282954	test: 0.176105

Epoch: 90
Loss: 0.07583703122062668
ROC train: 0.975261	val: 0.713064	test: 0.760745
PRC train: 0.768168	val: 0.265759	test: 0.148574

Epoch: 91
Loss: 0.07491279129652911
ROC train: 0.976608	val: 0.721242	test: 0.755595
PRC train: 0.777544	val: 0.280026	test: 0.165250

Epoch: 92
Loss: 0.07501973267453847
ROC train: 0.978019	val: 0.708543	test: 0.745979
PRC train: 0.782253	val: 0.247318	test: 0.147676

Epoch: 93
Loss: 0.07531175714426598
ROC train: 0.980830	val: 0.724686	test: 0.758578
PRC train: 0.792431	val: 0.292997	test: 0.163409

Epoch: 94
Loss: 0.0741849520907139
ROC train: 0.929548	val: 0.721301	test: 0.753757
PRC train: 0.611955	val: 0.260515	test: 0.163985

Epoch: 34
Loss: 0.09717575259965389
ROC train: 0.925064	val: 0.720595	test: 0.731848
PRC train: 0.612312	val: 0.283673	test: 0.164638

Epoch: 35
Loss: 0.09666273433613948
ROC train: 0.929655	val: 0.731139	test: 0.753981
PRC train: 0.610868	val: 0.288917	test: 0.169398

Epoch: 36
Loss: 0.09664512975478402
ROC train: 0.931860	val: 0.744007	test: 0.747842
PRC train: 0.599161	val: 0.294766	test: 0.223968

Epoch: 37
Loss: 0.09591317203396228
ROC train: 0.933433	val: 0.733941	test: 0.728179
PRC train: 0.626967	val: 0.269890	test: 0.115842

Epoch: 38
Loss: 0.0949796975988236
ROC train: 0.938725	val: 0.744168	test: 0.760079
PRC train: 0.632619	val: 0.286089	test: 0.136847

Epoch: 39
Loss: 0.09505615137592992
ROC train: 0.936109	val: 0.733144	test: 0.747381
PRC train: 0.626881	val: 0.284435	test: 0.190366

Epoch: 40
Loss: 0.09536437029805386
ROC train: 0.934202	val: 0.737719	test: 0.758528
PRC train: 0.622590	val: 0.302597	test: 0.186430

Epoch: 41
Loss: 0.09408492645632399
ROC train: 0.939122	val: 0.743249	test: 0.749022
PRC train: 0.638160	val: 0.306529	test: 0.170368

Epoch: 42
Loss: 0.09540935047468523
ROC train: 0.945065	val: 0.739948	test: 0.756071
PRC train: 0.655933	val: 0.315232	test: 0.177107

Epoch: 43
Loss: 0.09359817385933177
ROC train: 0.941821	val: 0.718248	test: 0.747020
PRC train: 0.644520	val: 0.308156	test: 0.166900

Epoch: 44
Loss: 0.09352444240339741
ROC train: 0.938108	val: 0.731859	test: 0.758102
PRC train: 0.612543	val: 0.316943	test: 0.197755

Epoch: 45
Loss: 0.09220791214216818
ROC train: 0.942611	val: 0.741140	test: 0.740901
PRC train: 0.647484	val: 0.283369	test: 0.142583

Epoch: 46
Loss: 0.09091041701501165
ROC train: 0.949875	val: 0.739047	test: 0.767040
PRC train: 0.671185	val: 0.297891	test: 0.205538

Epoch: 47
Loss: 0.09043933491815383
ROC train: 0.951611	val: 0.732310	test: 0.740336
PRC train: 0.659196	val: 0.271239	test: 0.141390

Epoch: 48
Loss: 0.09003046494972473
ROC train: 0.948243	val: 0.740826	test: 0.757054
PRC train: 0.663787	val: 0.277395	test: 0.178248

Epoch: 49
Loss: 0.09116999350132717
ROC train: 0.941025	val: 0.719090	test: 0.750320
PRC train: 0.646538	val: 0.276499	test: 0.178302

Epoch: 50
Loss: 0.09066200481513509
ROC train: 0.954894	val: 0.729197	test: 0.761636
PRC train: 0.676550	val: 0.282904	test: 0.151936

Epoch: 51
Loss: 0.08886383551844819
ROC train: 0.952381	val: 0.718582	test: 0.759056
PRC train: 0.670499	val: 0.283441	test: 0.175076

Epoch: 52
Loss: 0.08825417672588455
ROC train: 0.955943	val: 0.738616	test: 0.748529
PRC train: 0.683579	val: 0.290674	test: 0.168809

Epoch: 53
Loss: 0.08850478744800372
ROC train: 0.959137	val: 0.742231	test: 0.749252
PRC train: 0.692837	val: 0.305216	test: 0.197376

Epoch: 54
Loss: 0.08722019927398779
ROC train: 0.954380	val: 0.743039	test: 0.757006
PRC train: 0.671328	val: 0.277246	test: 0.165019

Epoch: 55
Loss: 0.08779771043980107
ROC train: 0.957449	val: 0.734481	test: 0.763739
PRC train: 0.694238	val: 0.301242	test: 0.220773

Epoch: 56
Loss: 0.0882403786838444
ROC train: 0.957130	val: 0.733607	test: 0.753345
PRC train: 0.692016	val: 0.317392	test: 0.219176

Epoch: 57
Loss: 0.08654529811585952
ROC train: 0.957659	val: 0.740653	test: 0.750488
PRC train: 0.694078	val: 0.287082	test: 0.177082

Epoch: 58
Loss: 0.08637074005926819
ROC train: 0.960918	val: 0.738653	test: 0.743466
PRC train: 0.695516	val: 0.299844	test: 0.176426

Epoch: 59
Loss: 0.08614292549354385
ROC train: 0.957407	val: 0.748945	test: 0.760385
PRC train: 0.687517	val: 0.306860	test: 0.197806

Epoch: 60
Loss: 0.08629715854640961
ROC train: 0.958723	val: 0.734893	test: 0.727361
PRC train: 0.697239	val: 0.248979	test: 0.101666

Epoch: 61
Loss: 0.08592804244745941
ROC train: 0.962864	val: 0.730454	test: 0.747236
PRC train: 0.712594	val: 0.293551	test: 0.136029

Epoch: 62
Loss: 0.08580787607680344
ROC train: 0.960482	val: 0.722729	test: 0.752994
PRC train: 0.689751	val: 0.281198	test: 0.147100

Epoch: 63
Loss: 0.08407600123166163
ROC train: 0.962240	val: 0.734844	test: 0.751776
PRC train: 0.706710	val: 0.308451	test: 0.203005

Epoch: 64
Loss: 0.08413350730673941
ROC train: 0.958204	val: 0.721013	test: 0.772257
PRC train: 0.692102	val: 0.289218	test: 0.172914

Epoch: 65
Loss: 0.08383405988536122
ROC train: 0.964825	val: 0.740910	test: 0.750836
PRC train: 0.717366	val: 0.292459	test: 0.155774

Epoch: 66
Loss: 0.0830478824733883
ROC train: 0.965849	val: 0.727675	test: 0.761618
PRC train: 0.718036	val: 0.301946	test: 0.213667

Epoch: 67
Loss: 0.08337899946948894
ROC train: 0.968473	val: 0.741318	test: 0.747644
PRC train: 0.738294	val: 0.305363	test: 0.176016

Epoch: 68
Loss: 0.08324503581673905
ROC train: 0.967131	val: 0.736266	test: 0.756719
PRC train: 0.724449	val: 0.284581	test: 0.198012

Epoch: 69
Loss: 0.08214690279809905
ROC train: 0.965375	val: 0.739435	test: 0.738543
PRC train: 0.716513	val: 0.274361	test: 0.111421

Epoch: 70
Loss: 0.08127853332107374
ROC train: 0.970587	val: 0.743408	test: 0.752797
PRC train: 0.733706	val: 0.290125	test: 0.153964

Epoch: 71
Loss: 0.08019278623281562
ROC train: 0.966804	val: 0.748957	test: 0.747844
PRC train: 0.721187	val: 0.252497	test: 0.100383

Epoch: 72
Loss: 0.08093384812181877
ROC train: 0.971577	val: 0.749265	test: 0.752069
PRC train: 0.741846	val: 0.274828	test: 0.135217

Epoch: 73
Loss: 0.08084570082591078
ROC train: 0.971521	val: 0.734786	test: 0.743507
PRC train: 0.742955	val: 0.297861	test: 0.165622

Epoch: 74
Loss: 0.08009284506162737
ROC train: 0.967549	val: 0.734041	test: 0.770612
PRC train: 0.733487	val: 0.298308	test: 0.175353

Epoch: 75
Loss: 0.07999226173861887
ROC train: 0.971429	val: 0.738366	test: 0.758095
PRC train: 0.743161	val: 0.300239	test: 0.194837

Epoch: 76
Loss: 0.07987777208010592
ROC train: 0.971599	val: 0.726279	test: 0.739203
PRC train: 0.747644	val: 0.286970	test: 0.151425

Epoch: 77
Loss: 0.07760433764758629
ROC train: 0.967382	val: 0.725089	test: 0.740736
PRC train: 0.725859	val: 0.262146	test: 0.147769

Epoch: 78
Loss: 0.07722426021791895
ROC train: 0.973252	val: 0.734927	test: 0.744640
PRC train: 0.755676	val: 0.295283	test: 0.166605

Epoch: 79
Loss: 0.07959829478819147
ROC train: 0.973601	val: 0.743268	test: 0.754299
PRC train: 0.760416	val: 0.291543	test: 0.193322

Epoch: 80
Loss: 0.0764674922401377
ROC train: 0.974707	val: 0.737196	test: 0.756929
PRC train: 0.759940	val: 0.282556	test: 0.185596

Epoch: 81
Loss: 0.07811448057872826
ROC train: 0.972710	val: 0.726380	test: 0.758729
PRC train: 0.759532	val: 0.283848	test: 0.189303

Epoch: 82
Loss: 0.07688793874521609
ROC train: 0.973365	val: 0.725892	test: 0.742374
PRC train: 0.751936	val: 0.260557	test: 0.124910

Epoch: 83
Loss: 0.0773182814255872
ROC train: 0.975590	val: 0.738950	test: 0.748509
PRC train: 0.768085	val: 0.295402	test: 0.161480

Epoch: 84
Loss: 0.07578624029400832
ROC train: 0.974855	val: 0.736196	test: 0.737453
PRC train: 0.762486	val: 0.249745	test: 0.122691

Epoch: 85
Loss: 0.07653257722376558
ROC train: 0.975164	val: 0.732822	test: 0.758778
PRC train: 0.758427	val: 0.286580	test: 0.179296

Epoch: 86
Loss: 0.07641347341200698
ROC train: 0.975797	val: 0.733983	test: 0.766930
PRC train: 0.764897	val: 0.290303	test: 0.186354

Epoch: 87
Loss: 0.07680682781549762
ROC train: 0.976812	val: 0.734193	test: 0.746180
PRC train: 0.772417	val: 0.289640	test: 0.176095

Epoch: 88
Loss: 0.07379415664209646
ROC train: 0.978873	val: 0.731902	test: 0.749450
PRC train: 0.783345	val: 0.282303	test: 0.142992

Epoch: 89
Loss: 0.07401773649986709
ROC train: 0.979386	val: 0.736539	test: 0.734553
PRC train: 0.788527	val: 0.281243	test: 0.155930

Epoch: 90
Loss: 0.07395762262985875
ROC train: 0.977583	val: 0.734427	test: 0.746863
PRC train: 0.779019	val: 0.279717	test: 0.125092

Epoch: 91
Loss: 0.07279579439657541
ROC train: 0.977549	val: 0.720919	test: 0.747910
PRC train: 0.775333	val: 0.262891	test: 0.117288

Epoch: 92
Loss: 0.07457135078975266
ROC train: 0.974750	val: 0.719585	test: 0.750085
PRC train: 0.762956	val: 0.277194	test: 0.169680

Epoch: 93
Loss: 0.07398368654927255
ROC train: 0.979503	val: 0.744710	test: 0.742837
PRC train: 0.784472	val: 0.294533	test: 0.179410
ROC train: 0.915693	val: 0.821018	test: 0.748975
PRC train: 0.589268	val: 0.323111	test: 0.203530

Epoch: 34
Loss: 0.09959164057763868
ROC train: 0.913853	val: 0.819380	test: 0.754833
PRC train: 0.562675	val: 0.296805	test: 0.164301

Epoch: 35
Loss: 0.10002856278126161
ROC train: 0.923596	val: 0.818820	test: 0.773512
PRC train: 0.604706	val: 0.355576	test: 0.221371

Epoch: 36
Loss: 0.10004790946795634
ROC train: 0.925532	val: 0.782833	test: 0.757456
PRC train: 0.590184	val: 0.321821	test: 0.195744

Epoch: 37
Loss: 0.09824912267981648
ROC train: 0.918964	val: 0.779465	test: 0.755961
PRC train: 0.590619	val: 0.317505	test: 0.214678

Epoch: 38
Loss: 0.09934054080375233
ROC train: 0.924822	val: 0.804646	test: 0.768103
PRC train: 0.599988	val: 0.303171	test: 0.210351

Epoch: 39
Loss: 0.09882218462520664
ROC train: 0.925049	val: 0.811134	test: 0.754466
PRC train: 0.599543	val: 0.329814	test: 0.193991

Epoch: 40
Loss: 0.0975734682895121
ROC train: 0.912124	val: 0.809561	test: 0.763906
PRC train: 0.584005	val: 0.313181	test: 0.148945

Epoch: 41
Loss: 0.09808765614107635
ROC train: 0.921845	val: 0.786832	test: 0.736982
PRC train: 0.595388	val: 0.278788	test: 0.157001

Epoch: 42
Loss: 0.09800112104500547
ROC train: 0.932589	val: 0.812292	test: 0.766052
PRC train: 0.621106	val: 0.327754	test: 0.179457

Epoch: 43
Loss: 0.09610430945299978
ROC train: 0.931770	val: 0.824631	test: 0.784807
PRC train: 0.613125	val: 0.346372	test: 0.218597

Epoch: 44
Loss: 0.0957822253988439
ROC train: 0.933180	val: 0.802527	test: 0.769549
PRC train: 0.628066	val: 0.335404	test: 0.209915

Epoch: 45
Loss: 0.09625802862316352
ROC train: 0.933619	val: 0.805176	test: 0.757460
PRC train: 0.616337	val: 0.308604	test: 0.176421

Epoch: 46
Loss: 0.09479898939191206
ROC train: 0.935160	val: 0.800167	test: 0.776216
PRC train: 0.619526	val: 0.349709	test: 0.201061

Epoch: 47
Loss: 0.09507124031036802
ROC train: 0.937688	val: 0.808051	test: 0.752726
PRC train: 0.629020	val: 0.299961	test: 0.139407

Epoch: 48
Loss: 0.09420621918673383
ROC train: 0.935088	val: 0.809420	test: 0.756222
PRC train: 0.633298	val: 0.298909	test: 0.182425

Epoch: 49
Loss: 0.09368987463606826
ROC train: 0.936531	val: 0.807838	test: 0.783972
PRC train: 0.635570	val: 0.335083	test: 0.204433

Epoch: 50
Loss: 0.09361304769980147
ROC train: 0.937880	val: 0.790237	test: 0.765162
PRC train: 0.629498	val: 0.322699	test: 0.207784

Epoch: 51
Loss: 0.09312389042467521
ROC train: 0.937479	val: 0.784964	test: 0.729732
PRC train: 0.628305	val: 0.309923	test: 0.164435

Epoch: 52
Loss: 0.09267508015629784
ROC train: 0.943024	val: 0.788792	test: 0.770204
PRC train: 0.644553	val: 0.330665	test: 0.192135

Epoch: 53
Loss: 0.09297143060361276
ROC train: 0.946915	val: 0.803210	test: 0.770376
PRC train: 0.653757	val: 0.313999	test: 0.202261

Epoch: 54
Loss: 0.09191605906494728
ROC train: 0.936775	val: 0.791948	test: 0.763632
PRC train: 0.624898	val: 0.330413	test: 0.209882

Epoch: 55
Loss: 0.09212665549962298
ROC train: 0.946971	val: 0.809193	test: 0.760449
PRC train: 0.662890	val: 0.298134	test: 0.168926

Epoch: 56
Loss: 0.09195071498085049
ROC train: 0.945663	val: 0.800990	test: 0.754926
PRC train: 0.665332	val: 0.276320	test: 0.187575

Epoch: 57
Loss: 0.09040358364949358
ROC train: 0.952078	val: 0.789542	test: 0.764545
PRC train: 0.662320	val: 0.294119	test: 0.186930

Epoch: 58
Loss: 0.0901348207969066
ROC train: 0.950076	val: 0.799661	test: 0.764787
PRC train: 0.663084	val: 0.291523	test: 0.190463

Epoch: 59
Loss: 0.08898846240900928
ROC train: 0.953561	val: 0.801122	test: 0.763207
PRC train: 0.681589	val: 0.307394	test: 0.208712

Epoch: 60
Loss: 0.08941666471770988
ROC train: 0.953017	val: 0.825005	test: 0.765559
PRC train: 0.676508	val: 0.322108	test: 0.188328

Epoch: 61
Loss: 0.08854281306077248
ROC train: 0.949306	val: 0.803924	test: 0.765785
PRC train: 0.668590	val: 0.300721	test: 0.197855

Epoch: 62
Loss: 0.089581843366891
ROC train: 0.957004	val: 0.797668	test: 0.768595
PRC train: 0.692460	val: 0.257415	test: 0.165894

Epoch: 63
Loss: 0.08695860256239592
ROC train: 0.946246	val: 0.793351	test: 0.762558
PRC train: 0.654126	val: 0.286167	test: 0.207202

Epoch: 64
Loss: 0.0875960646426269
ROC train: 0.955765	val: 0.814980	test: 0.765548
PRC train: 0.685479	val: 0.313861	test: 0.217042

Epoch: 65
Loss: 0.08693635703825622
ROC train: 0.957450	val: 0.789101	test: 0.765743
PRC train: 0.686100	val: 0.291678	test: 0.165848

Epoch: 66
Loss: 0.0870037417661741
ROC train: 0.958456	val: 0.789242	test: 0.761627
PRC train: 0.681398	val: 0.314872	test: 0.195744

Epoch: 67
Loss: 0.08763164224130897
ROC train: 0.959397	val: 0.784128	test: 0.755932
PRC train: 0.695581	val: 0.289307	test: 0.166210

Epoch: 68
Loss: 0.08639940385012919
ROC train: 0.960120	val: 0.779851	test: 0.749422
PRC train: 0.703025	val: 0.289070	test: 0.188250

Epoch: 69
Loss: 0.0856444450856696
ROC train: 0.960076	val: 0.778568	test: 0.758808
PRC train: 0.705517	val: 0.296612	test: 0.236365

Epoch: 70
Loss: 0.08415042441729952
ROC train: 0.960171	val: 0.799291	test: 0.742270
PRC train: 0.704243	val: 0.286234	test: 0.146528

Epoch: 71
Loss: 0.08531030914054531
ROC train: 0.958918	val: 0.790420	test: 0.755036
PRC train: 0.685596	val: 0.270123	test: 0.157947

Epoch: 72
Loss: 0.0858690708773722
ROC train: 0.962075	val: 0.783745	test: 0.758114
PRC train: 0.702549	val: 0.284133	test: 0.174334

Epoch: 73
Loss: 0.08324638128602366
ROC train: 0.957579	val: 0.796171	test: 0.748290
PRC train: 0.685827	val: 0.215447	test: 0.127883

Epoch: 74
Loss: 0.08353790614887888
ROC train: 0.963524	val: 0.799873	test: 0.759619
PRC train: 0.714808	val: 0.283349	test: 0.188372

Epoch: 75
Loss: 0.08503077771790196
ROC train: 0.966266	val: 0.798697	test: 0.760779
PRC train: 0.723247	val: 0.307076	test: 0.174170

Epoch: 76
Loss: 0.08366029849345737
ROC train: 0.965493	val: 0.793599	test: 0.772002
PRC train: 0.712598	val: 0.304139	test: 0.209429

Epoch: 77
Loss: 0.08237638182927373
ROC train: 0.965310	val: 0.803581	test: 0.752037
PRC train: 0.714956	val: 0.262058	test: 0.128346

Epoch: 78
Loss: 0.08277156500088151
ROC train: 0.970214	val: 0.796128	test: 0.768153
PRC train: 0.738700	val: 0.300598	test: 0.156935

Epoch: 79
Loss: 0.08088704822131566
ROC train: 0.966496	val: 0.812624	test: 0.756585
PRC train: 0.721392	val: 0.290204	test: 0.181350

Epoch: 80
Loss: 0.08204223819971641
ROC train: 0.968369	val: 0.808005	test: 0.760888
PRC train: 0.730536	val: 0.313000	test: 0.178358

Epoch: 81
Loss: 0.08070934137264661
ROC train: 0.969126	val: 0.773286	test: 0.767917
PRC train: 0.728364	val: 0.297298	test: 0.173323

Epoch: 82
Loss: 0.07936304234293697
ROC train: 0.970550	val: 0.785035	test: 0.742490
PRC train: 0.738878	val: 0.315245	test: 0.186458

Epoch: 83
Loss: 0.08189969646785815
ROC train: 0.960822	val: 0.812926	test: 0.749906
PRC train: 0.690383	val: 0.275959	test: 0.152007

Epoch: 84
Loss: 0.08026751406684428
ROC train: 0.974149	val: 0.790558	test: 0.772634
PRC train: 0.757124	val: 0.297494	test: 0.213730

Epoch: 85
Loss: 0.08060393885607971
ROC train: 0.970708	val: 0.810654	test: 0.770664
PRC train: 0.742131	val: 0.278174	test: 0.186340

Epoch: 86
Loss: 0.07758340594398924
ROC train: 0.973758	val: 0.803884	test: 0.754395
PRC train: 0.748260	val: 0.302709	test: 0.213255

Epoch: 87
Loss: 0.0786618971263596
ROC train: 0.971695	val: 0.812959	test: 0.756764
PRC train: 0.740712	val: 0.276861	test: 0.161603

Epoch: 88
Loss: 0.07846778237828109
ROC train: 0.975875	val: 0.806159	test: 0.761210
PRC train: 0.765080	val: 0.312050	test: 0.200995

Epoch: 89
Loss: 0.0767904470034328
ROC train: 0.973063	val: 0.814334	test: 0.760513
PRC train: 0.748668	val: 0.315880	test: 0.162605

Epoch: 90
Loss: 0.07694087078256953
ROC train: 0.973068	val: 0.797769	test: 0.752048
PRC train: 0.750169	val: 0.289946	test: 0.171674

Epoch: 91
Loss: 0.07655169941712664
ROC train: 0.974392	val: 0.791054	test: 0.759458
PRC train: 0.760188	val: 0.306231	test: 0.185489

Epoch: 92
Loss: 0.07756819964885782
ROC train: 0.975908	val: 0.811471	test: 0.764345
PRC train: 0.768599	val: 0.297209	test: 0.190931

Epoch: 93
Loss: 0.07579940636998114
ROC train: 0.974523	val: 0.811474	test: 0.747421
PRC train: 0.753492	val: 0.277052	test: 0.168275

Epoch: 94
Loss: 0.07610965268807622
ROC train: 0.920373	val: 0.795782	test: 0.766121
PRC train: 0.596039	val: 0.336421	test: 0.230971

Epoch: 34
Loss: 0.09838229974563528
ROC train: 0.924183	val: 0.804404	test: 0.766917
PRC train: 0.594911	val: 0.382732	test: 0.199555

Epoch: 35
Loss: 0.10032702268196972
ROC train: 0.922387	val: 0.805451	test: 0.765160
PRC train: 0.584052	val: 0.349641	test: 0.228085

Epoch: 36
Loss: 0.09945627658038178
ROC train: 0.918843	val: 0.815678	test: 0.748902
PRC train: 0.579403	val: 0.362946	test: 0.206878

Epoch: 37
Loss: 0.09898993864188486
ROC train: 0.923202	val: 0.806229	test: 0.771340
PRC train: 0.585577	val: 0.291825	test: 0.184348

Epoch: 38
Loss: 0.09769665351198989
ROC train: 0.927692	val: 0.802745	test: 0.764070
PRC train: 0.591738	val: 0.350901	test: 0.206056

Epoch: 39
Loss: 0.0989718693505039
ROC train: 0.931005	val: 0.803333	test: 0.773856
PRC train: 0.608156	val: 0.362498	test: 0.205638

Epoch: 40
Loss: 0.09737373172837294
ROC train: 0.927549	val: 0.811891	test: 0.758226
PRC train: 0.598910	val: 0.383749	test: 0.190741

Epoch: 41
Loss: 0.09718657135043877
ROC train: 0.936567	val: 0.811456	test: 0.780465
PRC train: 0.624625	val: 0.363150	test: 0.216705

Epoch: 42
Loss: 0.09586438498342628
ROC train: 0.932561	val: 0.790261	test: 0.767294
PRC train: 0.606649	val: 0.317603	test: 0.198248

Epoch: 43
Loss: 0.09640886811401006
ROC train: 0.934087	val: 0.789612	test: 0.764117
PRC train: 0.609144	val: 0.365480	test: 0.238862

Epoch: 44
Loss: 0.09489246062239874
ROC train: 0.936473	val: 0.810445	test: 0.774438
PRC train: 0.619758	val: 0.361435	test: 0.234408

Epoch: 45
Loss: 0.09499215714523772
ROC train: 0.938288	val: 0.815813	test: 0.749230
PRC train: 0.618164	val: 0.315605	test: 0.162911

Epoch: 46
Loss: 0.09502807271119607
ROC train: 0.935615	val: 0.808988	test: 0.756336
PRC train: 0.614585	val: 0.330412	test: 0.178054

Epoch: 47
Loss: 0.09431578872424659
ROC train: 0.940213	val: 0.794897	test: 0.755407
PRC train: 0.626917	val: 0.370975	test: 0.185259

Epoch: 48
Loss: 0.09344154397573057
ROC train: 0.942899	val: 0.791912	test: 0.752467
PRC train: 0.648101	val: 0.352446	test: 0.209884

Epoch: 49
Loss: 0.09347868526466861
ROC train: 0.945501	val: 0.811790	test: 0.768856
PRC train: 0.643992	val: 0.354906	test: 0.230703

Epoch: 50
Loss: 0.09312199835798374
ROC train: 0.949036	val: 0.794879	test: 0.763313
PRC train: 0.648778	val: 0.363438	test: 0.240335

Epoch: 51
Loss: 0.09238374000054701
ROC train: 0.943121	val: 0.810577	test: 0.763460
PRC train: 0.647175	val: 0.340540	test: 0.168908

Epoch: 52
Loss: 0.09279968931671959
ROC train: 0.942629	val: 0.791538	test: 0.742743
PRC train: 0.634531	val: 0.313571	test: 0.196438

Epoch: 53
Loss: 0.09161184198885577
ROC train: 0.940078	val: 0.810302	test: 0.769947
PRC train: 0.627857	val: 0.355632	test: 0.198091

Epoch: 54
Loss: 0.09015002461996789
ROC train: 0.942686	val: 0.798476	test: 0.758143
PRC train: 0.630990	val: 0.357705	test: 0.213040

Epoch: 55
Loss: 0.09083753905259055
ROC train: 0.949090	val: 0.797426	test: 0.772632
PRC train: 0.656931	val: 0.369642	test: 0.263054

Epoch: 56
Loss: 0.0912620261832151
ROC train: 0.949355	val: 0.800115	test: 0.744680
PRC train: 0.652198	val: 0.365891	test: 0.170727

Epoch: 57
Loss: 0.08950663565747727
ROC train: 0.950129	val: 0.810262	test: 0.767848
PRC train: 0.664838	val: 0.332360	test: 0.167431

Epoch: 58
Loss: 0.0885961640497737
ROC train: 0.951168	val: 0.822222	test: 0.777356
PRC train: 0.667046	val: 0.375725	test: 0.192920

Epoch: 59
Loss: 0.08801667793013607
ROC train: 0.949026	val: 0.790702	test: 0.745725
PRC train: 0.659618	val: 0.336098	test: 0.159294

Epoch: 60
Loss: 0.08902350159484382
ROC train: 0.951452	val: 0.814490	test: 0.769588
PRC train: 0.658079	val: 0.315516	test: 0.188230

Epoch: 61
Loss: 0.0871494839232297
ROC train: 0.952616	val: 0.817794	test: 0.754008
PRC train: 0.671643	val: 0.349147	test: 0.169643

Epoch: 62
Loss: 0.08589161553046618
ROC train: 0.956123	val: 0.815029	test: 0.754091
PRC train: 0.675048	val: 0.351607	test: 0.187371

Epoch: 63
Loss: 0.0878425226912527
ROC train: 0.959805	val: 0.804306	test: 0.740364
PRC train: 0.701497	val: 0.331700	test: 0.156067

Epoch: 64
Loss: 0.08795770462920659
ROC train: 0.958521	val: 0.791599	test: 0.765843
PRC train: 0.696831	val: 0.345138	test: 0.185282

Epoch: 65
Loss: 0.08620923547089265
ROC train: 0.955121	val: 0.800632	test: 0.756523
PRC train: 0.682083	val: 0.350991	test: 0.180766

Epoch: 66
Loss: 0.08605320296663965
ROC train: 0.963131	val: 0.794465	test: 0.755049
PRC train: 0.699246	val: 0.329933	test: 0.177585

Epoch: 67
Loss: 0.08609445506028982
ROC train: 0.958453	val: 0.805234	test: 0.762618
PRC train: 0.689213	val: 0.361715	test: 0.204723

Epoch: 68
Loss: 0.08468074511778065
ROC train: 0.961351	val: 0.797148	test: 0.771104
PRC train: 0.703801	val: 0.395552	test: 0.240584

Epoch: 69
Loss: 0.08384521139643512
ROC train: 0.964125	val: 0.797693	test: 0.769074
PRC train: 0.710060	val: 0.396883	test: 0.212869

Epoch: 70
Loss: 0.08576361006515794
ROC train: 0.963457	val: 0.765374	test: 0.765639
PRC train: 0.707784	val: 0.317065	test: 0.193501

Epoch: 71
Loss: 0.0847446067461263
ROC train: 0.965346	val: 0.806958	test: 0.765557
PRC train: 0.716730	val: 0.354905	test: 0.190994

Epoch: 72
Loss: 0.08437335441061927
ROC train: 0.967427	val: 0.780592	test: 0.765783
PRC train: 0.720429	val: 0.339730	test: 0.199562

Epoch: 73
Loss: 0.08407367031372748
ROC train: 0.959864	val: 0.800531	test: 0.759740
PRC train: 0.678937	val: 0.318439	test: 0.147650

Epoch: 74
Loss: 0.08177061326124625
ROC train: 0.966114	val: 0.802840	test: 0.771023
PRC train: 0.717833	val: 0.354329	test: 0.198273

Epoch: 75
Loss: 0.08241566702338952
ROC train: 0.968424	val: 0.770662	test: 0.768783
PRC train: 0.721744	val: 0.336576	test: 0.216685

Epoch: 76
Loss: 0.0830167745401502
ROC train: 0.968387	val: 0.780307	test: 0.761803
PRC train: 0.722050	val: 0.304153	test: 0.166656

Epoch: 77
Loss: 0.08140984695315115
ROC train: 0.969957	val: 0.820755	test: 0.773250
PRC train: 0.729535	val: 0.363167	test: 0.201041

Epoch: 78
Loss: 0.0815822685147355
ROC train: 0.967501	val: 0.811043	test: 0.773503
PRC train: 0.716278	val: 0.365613	test: 0.182166

Epoch: 79
Loss: 0.08133838338765921
ROC train: 0.964055	val: 0.828502	test: 0.765988
PRC train: 0.712293	val: 0.380164	test: 0.194058

Epoch: 80
Loss: 0.08112970923977134
ROC train: 0.969010	val: 0.793109	test: 0.768377
PRC train: 0.728976	val: 0.364469	test: 0.232569

Epoch: 81
Loss: 0.08059902597449954
ROC train: 0.972314	val: 0.799977	test: 0.757015
PRC train: 0.747982	val: 0.358711	test: 0.211567

Epoch: 82
Loss: 0.08001513033040634
ROC train: 0.969839	val: 0.811551	test: 0.772184
PRC train: 0.736237	val: 0.344913	test: 0.191058

Epoch: 83
Loss: 0.07927207594618844
ROC train: 0.970256	val: 0.787386	test: 0.756917
PRC train: 0.736787	val: 0.328443	test: 0.145492

Epoch: 84
Loss: 0.07916850574178255
ROC train: 0.970477	val: 0.797754	test: 0.764752
PRC train: 0.735039	val: 0.318658	test: 0.201224

Epoch: 85
Loss: 0.0784295464683912
ROC train: 0.968332	val: 0.799208	test: 0.752933
PRC train: 0.737550	val: 0.334047	test: 0.131824

Epoch: 86
Loss: 0.07985585332892522
ROC train: 0.968808	val: 0.804484	test: 0.765376
PRC train: 0.737355	val: 0.346038	test: 0.161788

Epoch: 87
Loss: 0.07750550194685103
ROC train: 0.977090	val: 0.787003	test: 0.769522
PRC train: 0.759431	val: 0.322908	test: 0.174004

Epoch: 88
Loss: 0.07846586963397283
ROC train: 0.968717	val: 0.797065	test: 0.738425
PRC train: 0.723353	val: 0.326194	test: 0.185324

Epoch: 89
Loss: 0.07770168631827874
ROC train: 0.974958	val: 0.799915	test: 0.774308
PRC train: 0.750085	val: 0.332910	test: 0.184060

Epoch: 90
Loss: 0.0782687534976135
ROC train: 0.966417	val: 0.801667	test: 0.757780
PRC train: 0.712540	val: 0.318431	test: 0.153538

Epoch: 91
Loss: 0.07705785721389295
ROC train: 0.967991	val: 0.810608	test: 0.765233
PRC train: 0.733615	val: 0.351841	test: 0.191501

Epoch: 92
Loss: 0.076234226047468
ROC train: 0.974060	val: 0.814509	test: 0.769737
PRC train: 0.752684	val: 0.324091	test: 0.166297

Epoch: 93
Loss: 0.07562549674828833
ROC train: 0.975513	val: 0.804717	test: 0.766749
PRC train: 0.758691	val: 0.334568	test: 0.175406

Epoch: 94
Loss: 0.07586450867675033
ROC train: 0.918622	val: 0.788883	test: 0.760689
PRC train: 0.556331	val: 0.330629	test: 0.190406

Epoch: 34
Loss: 0.10021923240552957
ROC train: 0.916343	val: 0.820920	test: 0.769565
PRC train: 0.577003	val: 0.396148	test: 0.251317

Epoch: 35
Loss: 0.10046230637901929
ROC train: 0.922459	val: 0.811505	test: 0.751755
PRC train: 0.576759	val: 0.359011	test: 0.165370

Epoch: 36
Loss: 0.0993142636184336
ROC train: 0.921884	val: 0.832014	test: 0.751926
PRC train: 0.584373	val: 0.376288	test: 0.188350

Epoch: 37
Loss: 0.09863909593640116
ROC train: 0.927785	val: 0.824353	test: 0.764691
PRC train: 0.604496	val: 0.388115	test: 0.219185

Epoch: 38
Loss: 0.09818118093223348
ROC train: 0.926729	val: 0.833636	test: 0.775859
PRC train: 0.594617	val: 0.376072	test: 0.247416

Epoch: 39
Loss: 0.09938541676324009
ROC train: 0.932042	val: 0.815605	test: 0.768016
PRC train: 0.612322	val: 0.396195	test: 0.242609

Epoch: 40
Loss: 0.09718416705260206
ROC train: 0.919894	val: 0.809625	test: 0.694515
PRC train: 0.564493	val: 0.268459	test: 0.077397

Epoch: 41
Loss: 0.09702722477623202
ROC train: 0.931911	val: 0.811367	test: 0.763006
PRC train: 0.618968	val: 0.376818	test: 0.218367

Epoch: 42
Loss: 0.09559606842472183
ROC train: 0.930499	val: 0.798088	test: 0.767892
PRC train: 0.607766	val: 0.343354	test: 0.220612

Epoch: 43
Loss: 0.09715951818528162
ROC train: 0.936915	val: 0.815069	test: 0.775162
PRC train: 0.626331	val: 0.383568	test: 0.221577

Epoch: 44
Loss: 0.09455719268762663
ROC train: 0.934516	val: 0.820185	test: 0.776120
PRC train: 0.616562	val: 0.382213	test: 0.230704

Epoch: 45
Loss: 0.09528877660831427
ROC train: 0.933235	val: 0.823198	test: 0.773539
PRC train: 0.612850	val: 0.380386	test: 0.221636

Epoch: 46
Loss: 0.09363140252064493
ROC train: 0.939706	val: 0.797916	test: 0.741876
PRC train: 0.621525	val: 0.338644	test: 0.162476

Epoch: 47
Loss: 0.09384436518914885
ROC train: 0.944452	val: 0.812806	test: 0.771620
PRC train: 0.633462	val: 0.352788	test: 0.235822

Epoch: 48
Loss: 0.09363492462593824
ROC train: 0.940332	val: 0.821900	test: 0.774366
PRC train: 0.619498	val: 0.401570	test: 0.219000

Epoch: 49
Loss: 0.09379274551864328
ROC train: 0.937766	val: 0.803137	test: 0.761421
PRC train: 0.628183	val: 0.336846	test: 0.184349

Epoch: 50
Loss: 0.091554815248663
ROC train: 0.929771	val: 0.795298	test: 0.772622
PRC train: 0.612333	val: 0.326074	test: 0.210984

Epoch: 51
Loss: 0.09280780178352889
ROC train: 0.946867	val: 0.828361	test: 0.751797
PRC train: 0.647493	val: 0.364855	test: 0.170646

Epoch: 52
Loss: 0.09320291995045799
ROC train: 0.934324	val: 0.822889	test: 0.745760
PRC train: 0.605162	val: 0.302495	test: 0.130689

Epoch: 53
Loss: 0.09191090875112545
ROC train: 0.940889	val: 0.811263	test: 0.760040
PRC train: 0.626003	val: 0.354523	test: 0.206680

Epoch: 54
Loss: 0.0930079032434889
ROC train: 0.950193	val: 0.819533	test: 0.763978
PRC train: 0.658542	val: 0.392600	test: 0.210892

Epoch: 55
Loss: 0.08978073832936642
ROC train: 0.947325	val: 0.830379	test: 0.755990
PRC train: 0.658765	val: 0.357228	test: 0.172934

Epoch: 56
Loss: 0.08948487080123063
ROC train: 0.948747	val: 0.814567	test: 0.760382
PRC train: 0.655918	val: 0.370664	test: 0.167060

Epoch: 57
Loss: 0.08988388091630121
ROC train: 0.951525	val: 0.828728	test: 0.758840
PRC train: 0.668729	val: 0.369012	test: 0.193151

Epoch: 58
Loss: 0.08939844383237988
ROC train: 0.949646	val: 0.826077	test: 0.769816
PRC train: 0.650562	val: 0.368417	test: 0.235724

Epoch: 59
Loss: 0.08971855656145333
ROC train: 0.958004	val: 0.825412	test: 0.770953
PRC train: 0.676648	val: 0.381594	test: 0.213816

Epoch: 60
Loss: 0.08913737018824552
ROC train: 0.949634	val: 0.807019	test: 0.770820
PRC train: 0.653260	val: 0.397135	test: 0.224219

Epoch: 61
Loss: 0.08713611396121486
ROC train: 0.948190	val: 0.814316	test: 0.756285
PRC train: 0.655208	val: 0.322562	test: 0.174758

Epoch: 62
Loss: 0.08836503948588685
ROC train: 0.953420	val: 0.825982	test: 0.764314
PRC train: 0.678444	val: 0.356603	test: 0.188874

Epoch: 63
Loss: 0.08591777802995593
ROC train: 0.958652	val: 0.806961	test: 0.745864
PRC train: 0.685055	val: 0.331035	test: 0.173088

Epoch: 64
Loss: 0.087875772491376
ROC train: 0.956962	val: 0.825091	test: 0.754595
PRC train: 0.676773	val: 0.369634	test: 0.161371

Epoch: 65
Loss: 0.08661390721345613
ROC train: 0.960116	val: 0.810623	test: 0.743122
PRC train: 0.700728	val: 0.360277	test: 0.195007

Epoch: 66
Loss: 0.08751557511624093
ROC train: 0.953667	val: 0.808483	test: 0.772334
PRC train: 0.677746	val: 0.338304	test: 0.190380

Epoch: 67
Loss: 0.08596615022163202
ROC train: 0.959768	val: 0.833079	test: 0.779955
PRC train: 0.685744	val: 0.385895	test: 0.201874

Epoch: 68
Loss: 0.08651231561374292
ROC train: 0.960738	val: 0.817993	test: 0.755051
PRC train: 0.689688	val: 0.354022	test: 0.177382

Epoch: 69
Loss: 0.08460456709877223
ROC train: 0.958655	val: 0.792625	test: 0.729649
PRC train: 0.679929	val: 0.333296	test: 0.148225

Epoch: 70
Loss: 0.08436005006372439
ROC train: 0.963485	val: 0.812837	test: 0.744808
PRC train: 0.707846	val: 0.352583	test: 0.153609

Epoch: 71
Loss: 0.08365548199028823
ROC train: 0.964320	val: 0.809187	test: 0.750843
PRC train: 0.709947	val: 0.348573	test: 0.202975

Epoch: 72
Loss: 0.08322142116021032
ROC train: 0.965404	val: 0.813471	test: 0.766878
PRC train: 0.714118	val: 0.353181	test: 0.173939

Epoch: 73
Loss: 0.08344245253109482
ROC train: 0.965242	val: 0.809031	test: 0.755635
PRC train: 0.702390	val: 0.370970	test: 0.197840

Epoch: 74
Loss: 0.08104481065694626
ROC train: 0.964741	val: 0.799465	test: 0.752639
PRC train: 0.710000	val: 0.304495	test: 0.167384

Epoch: 75
Loss: 0.08276663499272341
ROC train: 0.963167	val: 0.807595	test: 0.748093
PRC train: 0.703051	val: 0.338590	test: 0.145960

Epoch: 76
Loss: 0.0832508212637226
ROC train: 0.964766	val: 0.819252	test: 0.790141
PRC train: 0.712294	val: 0.362839	test: 0.218256

Epoch: 77
Loss: 0.0821308919253087
ROC train: 0.970047	val: 0.810390	test: 0.757085
PRC train: 0.730131	val: 0.325931	test: 0.173602

Epoch: 78
Loss: 0.0827702611044258
ROC train: 0.968548	val: 0.810739	test: 0.776093
PRC train: 0.723614	val: 0.382622	test: 0.222892

Epoch: 79
Loss: 0.08067438329805028
ROC train: 0.969913	val: 0.826772	test: 0.768918
PRC train: 0.732841	val: 0.379480	test: 0.186954

Epoch: 80
Loss: 0.08078866785153035
ROC train: 0.969607	val: 0.807102	test: 0.771919
PRC train: 0.728891	val: 0.327771	test: 0.182303

Epoch: 81
Loss: 0.0808798421101829
ROC train: 0.967655	val: 0.824209	test: 0.766627
PRC train: 0.723720	val: 0.352791	test: 0.209174

Epoch: 82
Loss: 0.07944109701219848
ROC train: 0.970293	val: 0.808428	test: 0.769121
PRC train: 0.731176	val: 0.355223	test: 0.181716

Epoch: 83
Loss: 0.08017118801660113
ROC train: 0.970765	val: 0.811398	test: 0.766065
PRC train: 0.729143	val: 0.333158	test: 0.176703

Epoch: 84
Loss: 0.07906112734970416
ROC train: 0.972080	val: 0.775622	test: 0.773385
PRC train: 0.741213	val: 0.305048	test: 0.181988

Epoch: 85
Loss: 0.07926642797075797
ROC train: 0.969267	val: 0.805424	test: 0.767280
PRC train: 0.729957	val: 0.318442	test: 0.209736

Epoch: 86
Loss: 0.07774707584341145
ROC train: 0.967464	val: 0.806284	test: 0.772302
PRC train: 0.724963	val: 0.362508	test: 0.209151

Epoch: 87
Loss: 0.07874596560815232
ROC train: 0.977502	val: 0.816701	test: 0.758624
PRC train: 0.770506	val: 0.344647	test: 0.183105

Epoch: 88
Loss: 0.07929895181113342
ROC train: 0.975337	val: 0.800265	test: 0.769211
PRC train: 0.754901	val: 0.346883	test: 0.179320

Epoch: 89
Loss: 0.07720926704075372
ROC train: 0.971915	val: 0.811897	test: 0.778005
PRC train: 0.736338	val: 0.360292	test: 0.167753

Epoch: 90
Loss: 0.07731202532059103
ROC train: 0.976700	val: 0.808422	test: 0.762881
PRC train: 0.763572	val: 0.371089	test: 0.193960

Epoch: 91
Loss: 0.07702182565661772
ROC train: 0.976926	val: 0.804309	test: 0.785297
PRC train: 0.766767	val: 0.345572	test: 0.185437

Epoch: 92
Loss: 0.0760686382886096
ROC train: 0.976574	val: 0.802191	test: 0.765474
PRC train: 0.763073	val: 0.333650	test: 0.145654

Epoch: 93
Loss: 0.07456734679247537
ROC train: 0.978025	val: 0.819818	test: 0.760146
PRC train: 0.772163	val: 0.353410	test: 0.190204

Epoch: 94
Loss: 0.07706921890542356
ROC train: 0.974917	val: 0.708859	test: 0.738468
PRC train: 0.755047	val: 0.240331	test: 0.190753

Epoch: 95
Loss: 0.069784239878811
ROC train: 0.981838	val: 0.713389	test: 0.753700
PRC train: 0.802141	val: 0.259569	test: 0.232569

Epoch: 96
Loss: 0.07132947568372758
ROC train: 0.984693	val: 0.716863	test: 0.741254
PRC train: 0.819706	val: 0.263148	test: 0.188487

Epoch: 97
Loss: 0.06902902172452707
ROC train: 0.982245	val: 0.702556	test: 0.743073
PRC train: 0.809188	val: 0.252000	test: 0.198525

Epoch: 98
Loss: 0.07000715489521196
ROC train: 0.984621	val: 0.720974	test: 0.768498
PRC train: 0.818932	val: 0.268206	test: 0.222784

Epoch: 99
Loss: 0.06862020181485377
ROC train: 0.985256	val: 0.722687	test: 0.764322
PRC train: 0.822271	val: 0.276900	test: 0.244684

Epoch: 100
Loss: 0.06889609516225924
ROC train: 0.985142	val: 0.715902	test: 0.759749
PRC train: 0.822448	val: 0.270567	test: 0.216899

Epoch: 101
Loss: 0.06963693407702146
ROC train: 0.985949	val: 0.703143	test: 0.744635
PRC train: 0.827561	val: 0.277753	test: 0.225639

Epoch: 102
Loss: 0.06880491869030687
ROC train: 0.983455	val: 0.705017	test: 0.752146
PRC train: 0.803912	val: 0.243372	test: 0.170118

Epoch: 103
Loss: 0.06811612744436431
ROC train: 0.986428	val: 0.708140	test: 0.740329
PRC train: 0.833521	val: 0.262851	test: 0.229985

Epoch: 104
Loss: 0.06863838602504836
ROC train: 0.985551	val: 0.721960	test: 0.750353
PRC train: 0.822843	val: 0.266417	test: 0.208961

Epoch: 105
Loss: 0.06787769860943992
ROC train: 0.983611	val: 0.716121	test: 0.745400
PRC train: 0.815101	val: 0.265558	test: 0.200671

Epoch: 106
Loss: 0.06844632425635272
ROC train: 0.983563	val: 0.711289	test: 0.763921
PRC train: 0.809781	val: 0.254945	test: 0.210364

Epoch: 107
Loss: 0.06686656585466301
ROC train: 0.986447	val: 0.719056	test: 0.759495
PRC train: 0.835413	val: 0.264444	test: 0.197259

Epoch: 108
Loss: 0.06403568504702198
ROC train: 0.984531	val: 0.712508	test: 0.735537
PRC train: 0.804101	val: 0.263326	test: 0.213310

Epoch: 109
Loss: 0.06456257276784891
ROC train: 0.987067	val: 0.715094	test: 0.765814
PRC train: 0.836397	val: 0.251571	test: 0.228142

Epoch: 110
Loss: 0.06556100956055488
ROC train: 0.984019	val: 0.704590	test: 0.745380
PRC train: 0.802017	val: 0.231485	test: 0.206974

Epoch: 111
Loss: 0.06604234234848602
ROC train: 0.984961	val: 0.710724	test: 0.751017
PRC train: 0.816731	val: 0.245347	test: 0.168868

Epoch: 112
Loss: 0.06430744514595794
ROC train: 0.986320	val: 0.721017	test: 0.757038
PRC train: 0.830794	val: 0.261731	test: 0.229265

Epoch: 113
Loss: 0.06451363543885587
ROC train: 0.987632	val: 0.725759	test: 0.744055
PRC train: 0.837342	val: 0.273665	test: 0.201947

Epoch: 114
Loss: 0.06512618614804715
ROC train: 0.987651	val: 0.717052	test: 0.731464
PRC train: 0.834916	val: 0.252791	test: 0.188613

Epoch: 115
Loss: 0.06343460554587312
ROC train: 0.988034	val: 0.714944	test: 0.744392
PRC train: 0.838106	val: 0.257173	test: 0.182899

Epoch: 116
Loss: 0.0628497122008405
ROC train: 0.988296	val: 0.707071	test: 0.736076
PRC train: 0.844176	val: 0.255170	test: 0.213094

Epoch: 117
Loss: 0.06267600057317058
ROC train: 0.987382	val: 0.717448	test: 0.749026
PRC train: 0.836955	val: 0.245393	test: 0.250310

Epoch: 118
Loss: 0.06445904984476372
ROC train: 0.987466	val: 0.722707	test: 0.747157
PRC train: 0.827233	val: 0.259732	test: 0.213434

Epoch: 119
Loss: 0.06046437294434409
ROC train: 0.988469	val: 0.711828	test: 0.742188
PRC train: 0.841703	val: 0.237017	test: 0.212111

Epoch: 120
Loss: 0.06220281019936904
ROC train: 0.990158	val: 0.708610	test: 0.746155
PRC train: 0.857055	val: 0.257821	test: 0.225000

Early stopping
Best (ROC):	 train: 0.938300	val: 0.729792	test: 0.761270
Best (PRC):	 train: 0.635061	val: 0.263406	test: 0.241228

ROC train: 0.981162	val: 0.700600	test: 0.755485
PRC train: 0.795516	val: 0.253228	test: 0.190301

Epoch: 95
Loss: 0.07031709961500693
ROC train: 0.982796	val: 0.716973	test: 0.756471
PRC train: 0.806803	val: 0.244357	test: 0.206218

Epoch: 96
Loss: 0.0710580736282566
ROC train: 0.985316	val: 0.712337	test: 0.761524
PRC train: 0.814443	val: 0.236656	test: 0.250188

Epoch: 97
Loss: 0.06895572302555662
ROC train: 0.984282	val: 0.708064	test: 0.754531
PRC train: 0.813255	val: 0.250403	test: 0.212371

Epoch: 98
Loss: 0.06910344714407342
ROC train: 0.985021	val: 0.709506	test: 0.756445
PRC train: 0.820901	val: 0.224850	test: 0.187710

Epoch: 99
Loss: 0.06495373198795536
ROC train: 0.985841	val: 0.708432	test: 0.768342
PRC train: 0.824660	val: 0.248341	test: 0.189101

Epoch: 100
Loss: 0.06854837619784526
ROC train: 0.985465	val: 0.706419	test: 0.752691
PRC train: 0.825565	val: 0.242779	test: 0.203267

Epoch: 101
Loss: 0.06868299349126251
ROC train: 0.983794	val: 0.709980	test: 0.759563
PRC train: 0.816891	val: 0.235366	test: 0.205599

Epoch: 102
Loss: 0.06855478241020227
ROC train: 0.985892	val: 0.717938	test: 0.761201
PRC train: 0.828490	val: 0.243562	test: 0.175727

Epoch: 103
Loss: 0.06722326126860606
ROC train: 0.986100	val: 0.717943	test: 0.766490
PRC train: 0.829535	val: 0.236379	test: 0.180738

Epoch: 104
Loss: 0.06727358700869017
ROC train: 0.981500	val: 0.710734	test: 0.760622
PRC train: 0.791302	val: 0.184688	test: 0.155861

Epoch: 105
Loss: 0.0663840010944187
ROC train: 0.982963	val: 0.709950	test: 0.746631
PRC train: 0.813169	val: 0.235684	test: 0.219235

Epoch: 106
Loss: 0.06827065898522945
ROC train: 0.986480	val: 0.705788	test: 0.753867
PRC train: 0.832462	val: 0.214628	test: 0.151722

Epoch: 107
Loss: 0.06595658912786212
ROC train: 0.983977	val: 0.702436	test: 0.762444
PRC train: 0.808521	val: 0.229717	test: 0.203843

Epoch: 108
Loss: 0.06409484995704168
ROC train: 0.987970	val: 0.708199	test: 0.757535
PRC train: 0.838823	val: 0.224568	test: 0.160441

Epoch: 109
Loss: 0.06430194380580188
ROC train: 0.986914	val: 0.707260	test: 0.758707
PRC train: 0.838227	val: 0.234177	test: 0.215278

Epoch: 110
Loss: 0.06558610222071007
ROC train: 0.986609	val: 0.706656	test: 0.763632
PRC train: 0.828764	val: 0.236661	test: 0.211947

Epoch: 111
Loss: 0.06551536988268897
ROC train: 0.985611	val: 0.711406	test: 0.751879
PRC train: 0.824522	val: 0.218599	test: 0.174127

Epoch: 112
Loss: 0.06578589854972755
ROC train: 0.984235	val: 0.721163	test: 0.755507
PRC train: 0.811382	val: 0.216325	test: 0.172734

Epoch: 113
Loss: 0.06422866647035445
ROC train: 0.986520	val: 0.701249	test: 0.753260
PRC train: 0.828642	val: 0.234564	test: 0.237120

Epoch: 114
Loss: 0.06741991356671004
ROC train: 0.983440	val: 0.706381	test: 0.756938
PRC train: 0.800922	val: 0.245854	test: 0.222066

Epoch: 115
Loss: 0.06416213801706189
ROC train: 0.985213	val: 0.707635	test: 0.754472
PRC train: 0.818588	val: 0.219114	test: 0.161032

Epoch: 116
Loss: 0.06477118460629451
ROC train: 0.985539	val: 0.695845	test: 0.747263
PRC train: 0.827245	val: 0.236342	test: 0.143881

Epoch: 117
Loss: 0.06598732383274693
ROC train: 0.989842	val: 0.707060	test: 0.760504
PRC train: 0.856021	val: 0.238012	test: 0.210172

Epoch: 118
Loss: 0.06561586693852704
ROC train: 0.988890	val: 0.714145	test: 0.757860
PRC train: 0.847050	val: 0.249867	test: 0.189300

Epoch: 119
Loss: 0.06387809470064927
ROC train: 0.988376	val: 0.708451	test: 0.748088
PRC train: 0.843198	val: 0.222214	test: 0.199691

Epoch: 120
Loss: 0.06276011735846843
ROC train: 0.983169	val: 0.702990	test: 0.757504
PRC train: 0.804269	val: 0.227668	test: 0.151798

Early stopping
Best (ROC):	 train: 0.976027	val: 0.727796	test: 0.762347
Best (PRC):	 train: 0.762656	val: 0.259208	test: 0.196615


Epoch: 94
Loss: 0.07287788106600358
ROC train: 0.984199	val: 0.702883	test: 0.762030
PRC train: 0.815868	val: 0.233322	test: 0.176848

Epoch: 95
Loss: 0.06951601639983573
ROC train: 0.982963	val: 0.708625	test: 0.759939
PRC train: 0.802430	val: 0.254710	test: 0.243494

Epoch: 96
Loss: 0.07052706869488776
ROC train: 0.982879	val: 0.702056	test: 0.748470
PRC train: 0.807481	val: 0.221377	test: 0.171366

Epoch: 97
Loss: 0.0684789639847559
ROC train: 0.986044	val: 0.707368	test: 0.764681
PRC train: 0.825028	val: 0.253513	test: 0.188872

Epoch: 98
Loss: 0.07063412329958067
ROC train: 0.986014	val: 0.703922	test: 0.752608
PRC train: 0.826440	val: 0.254003	test: 0.201436

Epoch: 99
Loss: 0.06918878245024704
ROC train: 0.985743	val: 0.707277	test: 0.756311
PRC train: 0.827623	val: 0.261409	test: 0.205435

Epoch: 100
Loss: 0.06874469088546262
ROC train: 0.984446	val: 0.709845	test: 0.764627
PRC train: 0.817861	val: 0.253376	test: 0.177564

Epoch: 101
Loss: 0.06962459352543143
ROC train: 0.985597	val: 0.705893	test: 0.762514
PRC train: 0.826457	val: 0.254166	test: 0.183670

Epoch: 102
Loss: 0.06733393418787069
ROC train: 0.984678	val: 0.700565	test: 0.751183
PRC train: 0.819796	val: 0.261418	test: 0.187280

Epoch: 103
Loss: 0.06709228911090305
ROC train: 0.986518	val: 0.702791	test: 0.751019
PRC train: 0.825159	val: 0.241786	test: 0.171744

Epoch: 104
Loss: 0.0671834136984219
ROC train: 0.985839	val: 0.694510	test: 0.760311
PRC train: 0.832952	val: 0.247546	test: 0.228495

Epoch: 105
Loss: 0.06618882597718986
ROC train: 0.986702	val: 0.699393	test: 0.752504
PRC train: 0.834004	val: 0.250579	test: 0.166758

Epoch: 106
Loss: 0.06679681700805844
ROC train: 0.987862	val: 0.697747	test: 0.754239
PRC train: 0.840482	val: 0.251427	test: 0.172019

Epoch: 107
Loss: 0.06571292592169287
ROC train: 0.985482	val: 0.690498	test: 0.750348
PRC train: 0.827109	val: 0.247907	test: 0.204196

Epoch: 108
Loss: 0.0654120332908818
ROC train: 0.987029	val: 0.696556	test: 0.762223
PRC train: 0.832277	val: 0.241552	test: 0.202225

Epoch: 109
Loss: 0.06530954322498968
ROC train: 0.985852	val: 0.697975	test: 0.753434
PRC train: 0.823856	val: 0.239830	test: 0.167376

Epoch: 110
Loss: 0.06496699911649365
ROC train: 0.985841	val: 0.705828	test: 0.736895
PRC train: 0.822194	val: 0.246806	test: 0.196570

Epoch: 111
Loss: 0.0645450958297484
ROC train: 0.987629	val: 0.696554	test: 0.738874
PRC train: 0.835746	val: 0.219431	test: 0.165818

Epoch: 112
Loss: 0.06500770599747492
ROC train: 0.987984	val: 0.707531	test: 0.764506
PRC train: 0.848297	val: 0.235109	test: 0.162634

Epoch: 113
Loss: 0.06306972625779202
ROC train: 0.988706	val: 0.712467	test: 0.737248
PRC train: 0.843735	val: 0.248901	test: 0.178692

Epoch: 114
Loss: 0.0606290253407504
ROC train: 0.989708	val: 0.707987	test: 0.747970
PRC train: 0.863056	val: 0.246020	test: 0.208530

Epoch: 115
Loss: 0.06350486817624426
ROC train: 0.989553	val: 0.709567	test: 0.764156
PRC train: 0.856154	val: 0.260902	test: 0.216936

Epoch: 116
Loss: 0.06535674627815359
ROC train: 0.988885	val: 0.695365	test: 0.750861
PRC train: 0.860802	val: 0.247940	test: 0.165051

Epoch: 117
Loss: 0.06179155097587665
ROC train: 0.988048	val: 0.708586	test: 0.749150
PRC train: 0.852282	val: 0.262384	test: 0.193954

Epoch: 118
Loss: 0.06416687426951749
ROC train: 0.987324	val: 0.696120	test: 0.741444
PRC train: 0.841620	val: 0.235122	test: 0.160305

Epoch: 119
Loss: 0.06596072878962471
ROC train: 0.986916	val: 0.702825	test: 0.718045
PRC train: 0.835575	val: 0.254386	test: 0.164754

Epoch: 120
Loss: 0.06302762147386769
ROC train: 0.989412	val: 0.699093	test: 0.743657
PRC train: 0.860679	val: 0.242026	test: 0.179475

Early stopping
Best (ROC):	 train: 0.927083	val: 0.724979	test: 0.750931
Best (PRC):	 train: 0.594917	val: 0.219536	test: 0.167273
All runs completed.

ROC train: 0.977764	val: 0.712255	test: 0.743454
PRC train: 0.782163	val: 0.284657	test: 0.193607

Epoch: 95
Loss: 0.07566700787471323
ROC train: 0.976672	val: 0.728906	test: 0.749443
PRC train: 0.768779	val: 0.294552	test: 0.175409

Epoch: 96
Loss: 0.07264683538023198
ROC train: 0.980355	val: 0.718172	test: 0.755402
PRC train: 0.796435	val: 0.262584	test: 0.163808

Epoch: 97
Loss: 0.07226616731769421
ROC train: 0.980834	val: 0.712995	test: 0.748154
PRC train: 0.800790	val: 0.267312	test: 0.168105

Epoch: 98
Loss: 0.07362754651492061
ROC train: 0.978098	val: 0.702948	test: 0.741993
PRC train: 0.791019	val: 0.282779	test: 0.183747

Epoch: 99
Loss: 0.07154493857025242
ROC train: 0.977547	val: 0.712602	test: 0.751568
PRC train: 0.774885	val: 0.256321	test: 0.162240

Epoch: 100
Loss: 0.07242868388170798
ROC train: 0.981344	val: 0.714820	test: 0.756215
PRC train: 0.793531	val: 0.251012	test: 0.121028

Epoch: 101
Loss: 0.07146439039764227
ROC train: 0.981335	val: 0.715169	test: 0.728235
PRC train: 0.797609	val: 0.258099	test: 0.145359

Epoch: 102
Loss: 0.07245377677378151
ROC train: 0.982086	val: 0.730893	test: 0.750580
PRC train: 0.807543	val: 0.252252	test: 0.141812

Epoch: 103
Loss: 0.07145990221223483
ROC train: 0.983985	val: 0.720054	test: 0.755777
PRC train: 0.815163	val: 0.272166	test: 0.159097

Epoch: 104
Loss: 0.07069748672431009
ROC train: 0.982767	val: 0.716956	test: 0.753347
PRC train: 0.806034	val: 0.299958	test: 0.206940

Epoch: 105
Loss: 0.06757943646194386
ROC train: 0.974866	val: 0.710449	test: 0.726423
PRC train: 0.762343	val: 0.241263	test: 0.125615

Epoch: 106
Loss: 0.06917009424130284
ROC train: 0.981141	val: 0.707380	test: 0.744400
PRC train: 0.807011	val: 0.283758	test: 0.168270

Epoch: 107
Loss: 0.07156148511296587
ROC train: 0.981766	val: 0.728365	test: 0.743742
PRC train: 0.798718	val: 0.287356	test: 0.163109

Epoch: 108
Loss: 0.07147350780571696
ROC train: 0.983603	val: 0.724146	test: 0.739922
PRC train: 0.813211	val: 0.278421	test: 0.141710

Epoch: 109
Loss: 0.06919499048587341
ROC train: 0.984100	val: 0.716543	test: 0.753944
PRC train: 0.802877	val: 0.279383	test: 0.200147

Epoch: 110
Loss: 0.06994351978809156
ROC train: 0.985235	val: 0.709347	test: 0.745896
PRC train: 0.826530	val: 0.276999	test: 0.162076

Epoch: 111
Loss: 0.06734347521355467
ROC train: 0.985075	val: 0.721792	test: 0.749433
PRC train: 0.824028	val: 0.253567	test: 0.164100

Epoch: 112
Loss: 0.06798864761699024
ROC train: 0.983262	val: 0.724961	test: 0.743105
PRC train: 0.815314	val: 0.290798	test: 0.184258

Epoch: 113
Loss: 0.06869483752166519
ROC train: 0.984021	val: 0.722064	test: 0.749718
PRC train: 0.816805	val: 0.275467	test: 0.182766

Epoch: 114
Loss: 0.06733222205795618
ROC train: 0.985008	val: 0.710703	test: 0.737516
PRC train: 0.825369	val: 0.252900	test: 0.141236

Epoch: 115
Loss: 0.06818455200846583
ROC train: 0.987283	val: 0.726995	test: 0.748923
PRC train: 0.839707	val: 0.261854	test: 0.128638

Epoch: 116
Loss: 0.0678851263527011
ROC train: 0.986161	val: 0.719536	test: 0.745766
PRC train: 0.832807	val: 0.274926	test: 0.184268

Epoch: 117
Loss: 0.06804011632194884
ROC train: 0.986518	val: 0.722175	test: 0.759369
PRC train: 0.836147	val: 0.250427	test: 0.143254

Epoch: 118
Loss: 0.06767493027404688
ROC train: 0.987116	val: 0.720626	test: 0.743037
PRC train: 0.840745	val: 0.259289	test: 0.145302

Epoch: 119
Loss: 0.06529427010935639
ROC train: 0.988935	val: 0.720230	test: 0.742558
PRC train: 0.857038	val: 0.286203	test: 0.179377

Epoch: 120
Loss: 0.06608788309123835
ROC train: 0.986169	val: 0.711836	test: 0.745356
PRC train: 0.831138	val: 0.274716	test: 0.137255

Early stopping
Best (ROC):	 train: 0.913226	val: 0.745426	test: 0.766443
Best (PRC):	 train: 0.578464	val: 0.323323	test: 0.215517

ROC train: 0.979962	val: 0.715858	test: 0.740462
PRC train: 0.791754	val: 0.296314	test: 0.169013

Epoch: 95
Loss: 0.07301432770569494
ROC train: 0.981049	val: 0.711685	test: 0.735652
PRC train: 0.799193	val: 0.275683	test: 0.168466

Epoch: 96
Loss: 0.07384515146970735
ROC train: 0.979260	val: 0.716992	test: 0.758671
PRC train: 0.788935	val: 0.269265	test: 0.187823

Epoch: 97
Loss: 0.07070760445543986
ROC train: 0.981409	val: 0.713840	test: 0.754738
PRC train: 0.803469	val: 0.278742	test: 0.185048

Epoch: 98
Loss: 0.07279520906215019
ROC train: 0.978509	val: 0.716634	test: 0.762935
PRC train: 0.781659	val: 0.278989	test: 0.210053

Epoch: 99
Loss: 0.0723185000329021
ROC train: 0.975699	val: 0.731969	test: 0.748464
PRC train: 0.779039	val: 0.269115	test: 0.153808

Epoch: 100
Loss: 0.07286630615787545
ROC train: 0.982191	val: 0.717739	test: 0.760859
PRC train: 0.807308	val: 0.281626	test: 0.178653

Epoch: 101
Loss: 0.07242286358039993
ROC train: 0.981504	val: 0.717887	test: 0.767812
PRC train: 0.803994	val: 0.293449	test: 0.205775

Epoch: 102
Loss: 0.07013286364458392
ROC train: 0.977222	val: 0.705901	test: 0.738287
PRC train: 0.790388	val: 0.275322	test: 0.148674

Epoch: 103
Loss: 0.07174684391722104
ROC train: 0.982185	val: 0.708589	test: 0.748547
PRC train: 0.806040	val: 0.298734	test: 0.192741

Epoch: 104
Loss: 0.06957930107738272
ROC train: 0.983000	val: 0.702836	test: 0.760893
PRC train: 0.805292	val: 0.288984	test: 0.198362

Epoch: 105
Loss: 0.07153893018147467
ROC train: 0.983743	val: 0.720190	test: 0.767215
PRC train: 0.813459	val: 0.286593	test: 0.180938

Epoch: 106
Loss: 0.07060326543288271
ROC train: 0.983727	val: 0.712307	test: 0.747911
PRC train: 0.821294	val: 0.277187	test: 0.164844

Epoch: 107
Loss: 0.06978775788873276
ROC train: 0.984391	val: 0.720396	test: 0.748059
PRC train: 0.820749	val: 0.270320	test: 0.175778

Epoch: 108
Loss: 0.0671862882161918
ROC train: 0.984679	val: 0.726096	test: 0.755197
PRC train: 0.816584	val: 0.294983	test: 0.175722

Epoch: 109
Loss: 0.06938701843241885
ROC train: 0.983944	val: 0.711311	test: 0.755678
PRC train: 0.821184	val: 0.275518	test: 0.167817

Epoch: 110
Loss: 0.06758243228745554
ROC train: 0.985544	val: 0.709787	test: 0.751283
PRC train: 0.828094	val: 0.252542	test: 0.152015

Epoch: 111
Loss: 0.06748324957992068
ROC train: 0.986061	val: 0.711962	test: 0.749206
PRC train: 0.827803	val: 0.251908	test: 0.156983

Epoch: 112
Loss: 0.06829216396630579
ROC train: 0.986021	val: 0.710855	test: 0.754093
PRC train: 0.826101	val: 0.236486	test: 0.140321

Epoch: 113
Loss: 0.06852587101885577
ROC train: 0.984925	val: 0.715914	test: 0.755162
PRC train: 0.822089	val: 0.269873	test: 0.160805

Epoch: 114
Loss: 0.06702413165305106
ROC train: 0.986478	val: 0.716750	test: 0.740701
PRC train: 0.832285	val: 0.257414	test: 0.145576

Epoch: 115
Loss: 0.06702821998391453
ROC train: 0.986765	val: 0.720480	test: 0.747067
PRC train: 0.842109	val: 0.257570	test: 0.138124

Epoch: 116
Loss: 0.06586366625038531
ROC train: 0.986147	val: 0.725484	test: 0.755012
PRC train: 0.836484	val: 0.263851	test: 0.169973

Epoch: 117
Loss: 0.06646950286985433
ROC train: 0.987859	val: 0.719821	test: 0.756767
PRC train: 0.838844	val: 0.275668	test: 0.173680

Epoch: 118
Loss: 0.06657330086789535
ROC train: 0.986334	val: 0.722683	test: 0.763021
PRC train: 0.827998	val: 0.282505	test: 0.207308

Epoch: 119
Loss: 0.06614756222807493
ROC train: 0.986760	val: 0.717925	test: 0.743024
PRC train: 0.839486	val: 0.269890	test: 0.143203

Epoch: 120
Loss: 0.06494151167823227
ROC train: 0.986732	val: 0.708572	test: 0.745601
PRC train: 0.843875	val: 0.265424	test: 0.160569

Early stopping
Best (ROC):	 train: 0.936248	val: 0.747534	test: 0.762909
Best (PRC):	 train: 0.631147	val: 0.330264	test: 0.215122


Epoch: 94
Loss: 0.0733966210358537
ROC train: 0.980006	val: 0.736343	test: 0.725994
PRC train: 0.794151	val: 0.269853	test: 0.125223

Epoch: 95
Loss: 0.07355974059273557
ROC train: 0.981403	val: 0.729122	test: 0.735754
PRC train: 0.797508	val: 0.265661	test: 0.126573

Epoch: 96
Loss: 0.0735386897635032
ROC train: 0.977814	val: 0.738470	test: 0.736610
PRC train: 0.772757	val: 0.308698	test: 0.154836

Epoch: 97
Loss: 0.07199591100266127
ROC train: 0.982713	val: 0.726547	test: 0.727144
PRC train: 0.809249	val: 0.284666	test: 0.171205

Epoch: 98
Loss: 0.07252956847451147
ROC train: 0.982069	val: 0.724007	test: 0.754739
PRC train: 0.799310	val: 0.298988	test: 0.185956

Epoch: 99
Loss: 0.07292806726274471
ROC train: 0.982330	val: 0.731566	test: 0.739324
PRC train: 0.807375	val: 0.288063	test: 0.155512

Epoch: 100
Loss: 0.07055596504420589
ROC train: 0.982647	val: 0.736577	test: 0.745411
PRC train: 0.811066	val: 0.277991	test: 0.164577

Epoch: 101
Loss: 0.07111102567023017
ROC train: 0.980994	val: 0.723715	test: 0.756329
PRC train: 0.799306	val: 0.285880	test: 0.157215

Epoch: 102
Loss: 0.07105948779575469
ROC train: 0.975220	val: 0.712543	test: 0.728048
PRC train: 0.751594	val: 0.235673	test: 0.110879

Epoch: 103
Loss: 0.0709303168537159
ROC train: 0.982560	val: 0.728606	test: 0.749671
PRC train: 0.802810	val: 0.292636	test: 0.142003

Epoch: 104
Loss: 0.06975081271595343
ROC train: 0.985351	val: 0.722287	test: 0.743746
PRC train: 0.822007	val: 0.288879	test: 0.156815

Epoch: 105
Loss: 0.07024135220085777
ROC train: 0.983990	val: 0.720085	test: 0.749105
PRC train: 0.818972	val: 0.269383	test: 0.155107

Epoch: 106
Loss: 0.06950078768259794
ROC train: 0.982135	val: 0.726437	test: 0.730908
PRC train: 0.803744	val: 0.265120	test: 0.167096

Epoch: 107
Loss: 0.06923784404039841
ROC train: 0.985547	val: 0.724737	test: 0.747843
PRC train: 0.826340	val: 0.269572	test: 0.156563

Epoch: 108
Loss: 0.06757584763546017
ROC train: 0.983622	val: 0.714064	test: 0.742733
PRC train: 0.814244	val: 0.269392	test: 0.145503

Epoch: 109
Loss: 0.06811310920090272
ROC train: 0.985490	val: 0.721191	test: 0.739487
PRC train: 0.824901	val: 0.276237	test: 0.140298

Epoch: 110
Loss: 0.06757933392442113
ROC train: 0.986086	val: 0.722743	test: 0.743131
PRC train: 0.829038	val: 0.253031	test: 0.124115

Epoch: 111
Loss: 0.06778472992713924
ROC train: 0.982011	val: 0.703578	test: 0.737819
PRC train: 0.804584	val: 0.256809	test: 0.127574

Epoch: 112
Loss: 0.06573779569037864
ROC train: 0.984731	val: 0.726706	test: 0.745415
PRC train: 0.816985	val: 0.269585	test: 0.160489

Epoch: 113
Loss: 0.06825950575342905
ROC train: 0.987069	val: 0.725866	test: 0.759388
PRC train: 0.835498	val: 0.290760	test: 0.193820

Epoch: 114
Loss: 0.06619699146543787
ROC train: 0.984253	val: 0.713301	test: 0.743564
PRC train: 0.816177	val: 0.271801	test: 0.118910

Epoch: 115
Loss: 0.06777391389812354
ROC train: 0.985420	val: 0.714671	test: 0.742461
PRC train: 0.831201	val: 0.287019	test: 0.180018

Epoch: 116
Loss: 0.06633092000901972
ROC train: 0.987892	val: 0.711145	test: 0.737351
PRC train: 0.847675	val: 0.240537	test: 0.142797

Epoch: 117
Loss: 0.06377083941325348
ROC train: 0.985627	val: 0.704923	test: 0.723064
PRC train: 0.817714	val: 0.249068	test: 0.111802

Epoch: 118
Loss: 0.06530033102495507
ROC train: 0.988350	val: 0.722173	test: 0.742559
PRC train: 0.846112	val: 0.290700	test: 0.147462

Epoch: 119
Loss: 0.06597439347738399
ROC train: 0.987149	val: 0.719357	test: 0.740312
PRC train: 0.838216	val: 0.264702	test: 0.165521

Epoch: 120
Loss: 0.06537316365649172
ROC train: 0.988786	val: 0.720543	test: 0.749209
PRC train: 0.854841	val: 0.285394	test: 0.154953

Early stopping
Best (ROC):	 train: 0.918350	val: 0.759046	test: 0.738148
Best (PRC):	 train: 0.567908	val: 0.301178	test: 0.165272
All runs completed.

ROC train: 0.977757	val: 0.800115	test: 0.749723
PRC train: 0.775987	val: 0.326254	test: 0.180960

Epoch: 95
Loss: 0.07704063531631007
ROC train: 0.977332	val: 0.772974	test: 0.739284
PRC train: 0.757800	val: 0.303096	test: 0.185197

Epoch: 96
Loss: 0.07465731782385447
ROC train: 0.978430	val: 0.806416	test: 0.772359
PRC train: 0.769615	val: 0.353409	test: 0.181899

Epoch: 97
Loss: 0.07482453800339438
ROC train: 0.976165	val: 0.792576	test: 0.748062
PRC train: 0.769311	val: 0.331826	test: 0.159699

Epoch: 98
Loss: 0.07503642045041103
ROC train: 0.978082	val: 0.798486	test: 0.758315
PRC train: 0.763356	val: 0.296181	test: 0.143381

Epoch: 99
Loss: 0.07250835429473627
ROC train: 0.978751	val: 0.804646	test: 0.761853
PRC train: 0.777551	val: 0.340315	test: 0.184828

Epoch: 100
Loss: 0.07463693873117556
ROC train: 0.980227	val: 0.808186	test: 0.753493
PRC train: 0.785008	val: 0.352217	test: 0.165081

Epoch: 101
Loss: 0.07223716002003049
ROC train: 0.982675	val: 0.784171	test: 0.759352
PRC train: 0.800751	val: 0.306197	test: 0.153944

Epoch: 102
Loss: 0.07355219754295765
ROC train: 0.981891	val: 0.799113	test: 0.764113
PRC train: 0.793260	val: 0.324153	test: 0.173882

Epoch: 103
Loss: 0.07341098326625764
ROC train: 0.983324	val: 0.810850	test: 0.784032
PRC train: 0.806117	val: 0.332723	test: 0.189747

Epoch: 104
Loss: 0.07323859405665718
ROC train: 0.982634	val: 0.805148	test: 0.764503
PRC train: 0.797521	val: 0.337084	test: 0.219699

Epoch: 105
Loss: 0.07071530929851343
ROC train: 0.981191	val: 0.805516	test: 0.736507
PRC train: 0.798389	val: 0.298987	test: 0.129251

Epoch: 106
Loss: 0.07125077502679548
ROC train: 0.983236	val: 0.792196	test: 0.760026
PRC train: 0.804269	val: 0.333900	test: 0.173129

Epoch: 107
Loss: 0.07145559245669751
ROC train: 0.977878	val: 0.806786	test: 0.757919
PRC train: 0.769144	val: 0.315630	test: 0.159020

Epoch: 108
Loss: 0.07140944209936312
ROC train: 0.984295	val: 0.804821	test: 0.775840
PRC train: 0.810109	val: 0.340940	test: 0.170366

Epoch: 109
Loss: 0.07213161851064163
ROC train: 0.981691	val: 0.792744	test: 0.744174
PRC train: 0.793442	val: 0.301618	test: 0.129245

Epoch: 110
Loss: 0.0708389227031002
ROC train: 0.980923	val: 0.787362	test: 0.765005
PRC train: 0.785928	val: 0.324654	test: 0.207754

Epoch: 111
Loss: 0.07072377339714443
ROC train: 0.984551	val: 0.783347	test: 0.776448
PRC train: 0.813287	val: 0.315398	test: 0.203414

Epoch: 112
Loss: 0.07144243143556439
ROC train: 0.983757	val: 0.808428	test: 0.760322
PRC train: 0.809963	val: 0.370962	test: 0.171713

Epoch: 113
Loss: 0.06944928383682099
ROC train: 0.984233	val: 0.784275	test: 0.744296
PRC train: 0.804793	val: 0.296048	test: 0.166807

Epoch: 114
Loss: 0.06950972351681867
ROC train: 0.983348	val: 0.787463	test: 0.749539
PRC train: 0.802619	val: 0.318583	test: 0.186801

Epoch: 115
Loss: 0.07029170753612507
ROC train: 0.986504	val: 0.804658	test: 0.768014
PRC train: 0.828803	val: 0.355142	test: 0.200197

Epoch: 116
Loss: 0.06947492069664601
ROC train: 0.983646	val: 0.801162	test: 0.758024
PRC train: 0.805471	val: 0.345849	test: 0.217564

Epoch: 117
Loss: 0.06885421654864654
ROC train: 0.984010	val: 0.810081	test: 0.755268
PRC train: 0.813638	val: 0.353879	test: 0.209470

Epoch: 118
Loss: 0.06958346764834608
ROC train: 0.986589	val: 0.813957	test: 0.756592
PRC train: 0.824353	val: 0.370043	test: 0.225774

Epoch: 119
Loss: 0.06773338822847408
ROC train: 0.985739	val: 0.796872	test: 0.745370
PRC train: 0.821291	val: 0.312678	test: 0.161076

Epoch: 120
Loss: 0.06834699388932912
ROC train: 0.985971	val: 0.794775	test: 0.753995
PRC train: 0.824620	val: 0.339176	test: 0.186056

Early stopping
Best (ROC):	 train: 0.964055	val: 0.828502	test: 0.765988
Best (PRC):	 train: 0.712293	val: 0.380164	test: 0.194058

ROC train: 0.978056	val: 0.819613	test: 0.761181
PRC train: 0.766532	val: 0.382500	test: 0.186321

Epoch: 95
Loss: 0.07526675998205097
ROC train: 0.975414	val: 0.808504	test: 0.764414
PRC train: 0.754000	val: 0.378198	test: 0.208837

Epoch: 96
Loss: 0.07545992944235913
ROC train: 0.979680	val: 0.800075	test: 0.748178
PRC train: 0.779484	val: 0.290275	test: 0.193931

Epoch: 97
Loss: 0.0742715353182046
ROC train: 0.979057	val: 0.813112	test: 0.766712
PRC train: 0.781721	val: 0.355035	test: 0.219361

Epoch: 98
Loss: 0.07407566038002311
ROC train: 0.973996	val: 0.796890	test: 0.763694
PRC train: 0.759932	val: 0.318624	test: 0.176333

Epoch: 99
Loss: 0.07450729537384906
ROC train: 0.977179	val: 0.825832	test: 0.772201
PRC train: 0.766561	val: 0.362552	test: 0.187306

Epoch: 100
Loss: 0.07360410718405941
ROC train: 0.975420	val: 0.806039	test: 0.740285
PRC train: 0.771268	val: 0.317237	test: 0.160552

Epoch: 101
Loss: 0.0746659452429742
ROC train: 0.979343	val: 0.797249	test: 0.769163
PRC train: 0.792374	val: 0.323835	test: 0.189230

Epoch: 102
Loss: 0.0751081708481693
ROC train: 0.978886	val: 0.812221	test: 0.776465
PRC train: 0.776843	val: 0.368923	test: 0.200144

Epoch: 103
Loss: 0.07313203097664313
ROC train: 0.981357	val: 0.824386	test: 0.766680
PRC train: 0.788156	val: 0.340912	test: 0.177888

Epoch: 104
Loss: 0.07409460661707218
ROC train: 0.982488	val: 0.827056	test: 0.754229
PRC train: 0.803433	val: 0.318414	test: 0.142290

Epoch: 105
Loss: 0.07240142664014304
ROC train: 0.981178	val: 0.813412	test: 0.766537
PRC train: 0.797606	val: 0.359891	test: 0.173595

Epoch: 106
Loss: 0.0715750286621419
ROC train: 0.981674	val: 0.811731	test: 0.768082
PRC train: 0.796627	val: 0.296476	test: 0.153124

Epoch: 107
Loss: 0.07188094319405004
ROC train: 0.980014	val: 0.806309	test: 0.769273
PRC train: 0.776358	val: 0.378461	test: 0.225760

Epoch: 108
Loss: 0.07291015536179932
ROC train: 0.983036	val: 0.806177	test: 0.745661
PRC train: 0.800131	val: 0.315354	test: 0.133430

Epoch: 109
Loss: 0.0699130085447969
ROC train: 0.983946	val: 0.815081	test: 0.754342
PRC train: 0.809490	val: 0.294455	test: 0.160221

Epoch: 110
Loss: 0.06984942896113083
ROC train: 0.982387	val: 0.807028	test: 0.772220
PRC train: 0.804055	val: 0.347748	test: 0.181591

Epoch: 111
Loss: 0.07119927623490663
ROC train: 0.983877	val: 0.803403	test: 0.757859
PRC train: 0.813641	val: 0.327582	test: 0.203919

Epoch: 112
Loss: 0.07014215361462392
ROC train: 0.977338	val: 0.823162	test: 0.764914
PRC train: 0.777450	val: 0.328843	test: 0.173793

Epoch: 113
Loss: 0.07128029674060787
ROC train: 0.985439	val: 0.799922	test: 0.745055
PRC train: 0.820962	val: 0.296351	test: 0.117552

Epoch: 114
Loss: 0.06973855351689955
ROC train: 0.976235	val: 0.809518	test: 0.748881
PRC train: 0.758144	val: 0.260397	test: 0.116946

Epoch: 115
Loss: 0.0702924107671385
ROC train: 0.984425	val: 0.819031	test: 0.774729
PRC train: 0.816227	val: 0.351218	test: 0.195146

Epoch: 116
Loss: 0.06789806306685868
ROC train: 0.983676	val: 0.820161	test: 0.765189
PRC train: 0.808162	val: 0.368709	test: 0.170213

Epoch: 117
Loss: 0.06993032512176217
ROC train: 0.983504	val: 0.815917	test: 0.749530
PRC train: 0.804591	val: 0.292674	test: 0.125927

Epoch: 118
Loss: 0.06664740569646452
ROC train: 0.987994	val: 0.797432	test: 0.764659
PRC train: 0.833123	val: 0.321906	test: 0.180927

Epoch: 119
Loss: 0.06844075223337331
ROC train: 0.986685	val: 0.801208	test: 0.773261
PRC train: 0.828625	val: 0.328888	test: 0.185842

Epoch: 120
Loss: 0.06851696310869874
ROC train: 0.986375	val: 0.807956	test: 0.764994
PRC train: 0.825761	val: 0.320530	test: 0.167623

Early stopping
Best (ROC):	 train: 0.856023	val: 0.833940	test: 0.762881
Best (PRC):	 train: 0.412802	val: 0.269162	test: 0.205827

ROC train: 0.977743	val: 0.798807	test: 0.758207
PRC train: 0.773734	val: 0.272323	test: 0.155130

Epoch: 95
Loss: 0.07558089451016849
ROC train: 0.977211	val: 0.794376	test: 0.751110
PRC train: 0.771290	val: 0.296757	test: 0.161507

Epoch: 96
Loss: 0.07537694122071988
ROC train: 0.978987	val: 0.807445	test: 0.748186
PRC train: 0.780893	val: 0.286033	test: 0.145028

Epoch: 97
Loss: 0.07509055246443835
ROC train: 0.978038	val: 0.806189	test: 0.751231
PRC train: 0.781895	val: 0.305706	test: 0.153416

Epoch: 98
Loss: 0.0742859513119287
ROC train: 0.975983	val: 0.834356	test: 0.759016
PRC train: 0.758349	val: 0.275366	test: 0.153131

Epoch: 99
Loss: 0.07477268589573992
ROC train: 0.979423	val: 0.784364	test: 0.750070
PRC train: 0.773346	val: 0.292396	test: 0.142663

Epoch: 100
Loss: 0.07477130559496822
ROC train: 0.979153	val: 0.780292	test: 0.759451
PRC train: 0.789979	val: 0.296185	test: 0.170000

Epoch: 101
Loss: 0.07442523187119
ROC train: 0.978212	val: 0.788831	test: 0.771342
PRC train: 0.784921	val: 0.254739	test: 0.192994

Epoch: 102
Loss: 0.07278062113601008
ROC train: 0.981097	val: 0.800779	test: 0.768586
PRC train: 0.788812	val: 0.322667	test: 0.186027

Epoch: 103
Loss: 0.07222079654852788
ROC train: 0.979984	val: 0.798764	test: 0.774125
PRC train: 0.793576	val: 0.283286	test: 0.189505

Epoch: 104
Loss: 0.07252923929408064
ROC train: 0.982062	val: 0.772857	test: 0.756891
PRC train: 0.802247	val: 0.258275	test: 0.177886

Epoch: 105
Loss: 0.07383520854289086
ROC train: 0.979777	val: 0.828682	test: 0.761141
PRC train: 0.787796	val: 0.315891	test: 0.177824

Epoch: 106
Loss: 0.07221099626953839
ROC train: 0.980694	val: 0.789569	test: 0.759941
PRC train: 0.796441	val: 0.292832	test: 0.163124

Epoch: 107
Loss: 0.073629493298582
ROC train: 0.981218	val: 0.797564	test: 0.746741
PRC train: 0.795435	val: 0.278831	test: 0.143142

Epoch: 108
Loss: 0.07244497986648145
ROC train: 0.980813	val: 0.810078	test: 0.775562
PRC train: 0.797506	val: 0.303378	test: 0.200448

Epoch: 109
Loss: 0.07126888981813645
ROC train: 0.982876	val: 0.810957	test: 0.747871
PRC train: 0.805938	val: 0.307953	test: 0.176178

Epoch: 110
Loss: 0.07189661119248716
ROC train: 0.981234	val: 0.822984	test: 0.746863
PRC train: 0.792634	val: 0.307772	test: 0.125346

Epoch: 111
Loss: 0.0705852517505207
ROC train: 0.983337	val: 0.797968	test: 0.758535
PRC train: 0.814276	val: 0.285183	test: 0.183283

Epoch: 112
Loss: 0.07184891505218283
ROC train: 0.984675	val: 0.794229	test: 0.760299
PRC train: 0.810414	val: 0.312418	test: 0.209530

Epoch: 113
Loss: 0.0695096981566853
ROC train: 0.984158	val: 0.799438	test: 0.762720
PRC train: 0.810584	val: 0.310729	test: 0.193236

Epoch: 114
Loss: 0.07041705268218247
ROC train: 0.984912	val: 0.812497	test: 0.749480
PRC train: 0.821574	val: 0.277096	test: 0.142295

Epoch: 115
Loss: 0.0708637656281261
ROC train: 0.982712	val: 0.782527	test: 0.759543
PRC train: 0.796736	val: 0.315788	test: 0.200043

Epoch: 116
Loss: 0.06935312639848042
ROC train: 0.982073	val: 0.795032	test: 0.768114
PRC train: 0.794975	val: 0.249465	test: 0.156541

Epoch: 117
Loss: 0.06974355858990862
ROC train: 0.985291	val: 0.794652	test: 0.748630
PRC train: 0.822912	val: 0.237013	test: 0.140650

Epoch: 118
Loss: 0.0678401840760363
ROC train: 0.985606	val: 0.795796	test: 0.764783
PRC train: 0.829341	val: 0.287203	test: 0.177528

Epoch: 119
Loss: 0.06897628043122073
ROC train: 0.983831	val: 0.796235	test: 0.774100
PRC train: 0.812698	val: 0.287791	test: 0.198051

Epoch: 120
Loss: 0.06790655150465735
ROC train: 0.984647	val: 0.785013	test: 0.762006
PRC train: 0.821999	val: 0.282065	test: 0.188274

Epoch: 121
Loss: 0.06716727013835742
ROC train: 0.984553	val: 0.785678	test: 0.760671
PRC train: 0.824045	val: 0.279206	test: 0.193811

Epoch: 122
Loss: 0.06703198304756887
ROC train: 0.986331	val: 0.800133	test: 0.764657
PRC train: 0.833865	val: 0.296798	test: 0.179674

Epoch: 123
Loss: 0.06616018962852536
ROC train: 0.986612	val: 0.806226	test: 0.772004
PRC train: 0.828545	val: 0.304576	test: 0.172624

Epoch: 124
Loss: 0.06875698938364752
ROC train: 0.987028	val: 0.801327	test: 0.758159
PRC train: 0.832777	val: 0.253234	test: 0.164918

Epoch: 125
Loss: 0.06715178455817676
ROC train: 0.985597	val: 0.804012	test: 0.757894
PRC train: 0.827288	val: 0.263326	test: 0.160177

Epoch: 126
Loss: 0.0672169757657762
ROC train: 0.985207	val: 0.803342	test: 0.755513
PRC train: 0.821288	val: 0.276981	test: 0.145339

Epoch: 127
Loss: 0.06642715316962675
ROC train: 0.986015	val: 0.802282	test: 0.765082
PRC train: 0.823601	val: 0.291831	test: 0.191117

Epoch: 128
Loss: 0.06651447834921734
ROC train: 0.979168	val: 0.794156	test: 0.751465
PRC train: 0.778024	val: 0.255080	test: 0.138778

Epoch: 129
Loss: 0.06668641040796265
ROC train: 0.988539	val: 0.791899	test: 0.778364
PRC train: 0.846496	val: 0.276266	test: 0.207906

Epoch: 130
Loss: 0.06540165387475586
ROC train: 0.989088	val: 0.806667	test: 0.764157
PRC train: 0.850667	val: 0.281997	test: 0.170545

Epoch: 131
Loss: 0.06473963837810623
ROC train: 0.989126	val: 0.793902	test: 0.758974
PRC train: 0.850492	val: 0.288695	test: 0.169745

Epoch: 132
Loss: 0.06547430764363867
ROC train: 0.987583	val: 0.793966	test: 0.764880
PRC train: 0.845714	val: 0.288459	test: 0.185388

Epoch: 133
Loss: 0.0625393137019077
ROC train: 0.986235	val: 0.796765	test: 0.746679
PRC train: 0.827004	val: 0.235814	test: 0.135004

Early stopping
Best (ROC):	 train: 0.975983	val: 0.834356	test: 0.759016
Best (PRC):	 train: 0.758349	val: 0.275366	test: 0.153131
All runs completed.
