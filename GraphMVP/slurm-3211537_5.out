>>> Starting run for dataset: hiv
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running SCAFF configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.6.yml on cuda:0
Running SCAFF configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.7.yml on cuda:1
Running SCAFF configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.8.yml on cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.6.yml --runseed 4 --device cuda:0
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.6.yml --runseed 5 --device cuda:0
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.8.yml --runseed 4 --device cuda:2
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.8.yml --runseed 5 --device cuda:2
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.6.yml --runseed 6 --device cuda:0
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.7.yml --runseed 4 --device cuda:1
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.8.yml --runseed 6 --device cuda:2
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.7.yml --runseed 5 --device cuda:1
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.7.yml --runseed 6 --device cuda:1
[10:25:23] WARNING: not removing hydrogen atom without neighbors
[10:25:23] WARNING: not removing hydrogen atom without neighbors
[10:25:23] WARNING: not removing hydrogen atom without neighbors
[10:25:23] WARNING: not removing hydrogen atom without neighbors
[10:25:23] WARNING: not removing hydrogen atom without neighbors
[10:25:23] WARNING: not removing hydrogen atom without neighbors
[10:25:23] WARNING: not removing hydrogen atom without neighbors
[10:25:23] WARNING: not removing hydrogen atom without neighbors
[10:25:23] WARNING: not removing hydrogen atom without neighbors
[10:25:23] WARNING: not removing hydrogen atom without neighbors
[10:25:23] WARNING: not removing hydrogen atom without neighbors
[10:25:23] WARNING: not removing hydrogen atom without neighbors
[10:25:23] WARNING: not removing hydrogen atom without neighbors
[10:25:23] WARNING: not removing hydrogen atom without neighbors
[10:25:23] WARNING: not removing hydrogen atom without neighbors
[10:25:23] WARNING: not removing hydrogen atom without neighbors
[10:25:23] WARNING: not removing hydrogen atom without neighbors
[10:25:23] WARNING: not removing hydrogen atom without neighbors
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/hiv/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/hiv/scaff/train_prop=0.6/hiv_scaff_5_26-05_10-25-11  ]
[ Using Seed :  5  ]
[ Using device :  cuda:0  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.3053330992676394
ROC train: 0.783432	val: 0.680832	test: 0.697262
PRC train: 0.269509	val: 0.150150	test: 0.135001

Epoch: 2
Loss: 0.14335706435873613
ROC train: 0.801992	val: 0.664928	test: 0.682979
PRC train: 0.302676	val: 0.164547	test: 0.205278

Epoch: 3
Loss: 0.1327872971011249
ROC train: 0.812714	val: 0.666059	test: 0.742749
PRC train: 0.368973	val: 0.159949	test: 0.260753

Epoch: 4
Loss: 0.12959058424306402
ROC train: 0.829754	val: 0.669949	test: 0.718156
PRC train: 0.364417	val: 0.167785	test: 0.176712

Epoch: 5
Loss: 0.12903776413112292
ROC train: 0.839249	val: 0.674123	test: 0.741359
PRC train: 0.409435	val: 0.190720	test: 0.218960

Epoch: 6
Loss: 0.1242593034333345
ROC train: 0.851016	val: 0.675025	test: 0.737630
PRC train: 0.422043	val: 0.170886	test: 0.229819

Epoch: 7
Loss: 0.12227542935507119
ROC train: 0.862943	val: 0.694453	test: 0.738940
PRC train: 0.430596	val: 0.239436	test: 0.232219

Epoch: 8
Loss: 0.12022956765689861
ROC train: 0.863054	val: 0.678051	test: 0.712544
PRC train: 0.456913	val: 0.191628	test: 0.171249

Epoch: 9
Loss: 0.11754125403196042
ROC train: 0.857988	val: 0.688043	test: 0.726196
PRC train: 0.475751	val: 0.185345	test: 0.150325

Epoch: 10
Loss: 0.11637453893910595
ROC train: 0.881688	val: 0.690669	test: 0.732342
PRC train: 0.510636	val: 0.211593	test: 0.222563

Epoch: 11
Loss: 0.1146662873906476
ROC train: 0.879502	val: 0.690041	test: 0.712852
PRC train: 0.504017	val: 0.209297	test: 0.171659

Epoch: 12
Loss: 0.11236350760900747
ROC train: 0.882119	val: 0.693035	test: 0.728387
PRC train: 0.510686	val: 0.241788	test: 0.208821

Epoch: 13
Loss: 0.11120157825633532
ROC train: 0.884574	val: 0.696296	test: 0.727585
PRC train: 0.523495	val: 0.205869	test: 0.232685

Epoch: 14
Loss: 0.11035296604520103
ROC train: 0.886011	val: 0.701259	test: 0.724897
PRC train: 0.526725	val: 0.231012	test: 0.218325

Epoch: 15
Loss: 0.10878200780778897
ROC train: 0.892394	val: 0.685660	test: 0.738073
PRC train: 0.535068	val: 0.206699	test: 0.154421

Epoch: 16
Loss: 0.10897875754852732
ROC train: 0.901413	val: 0.697731	test: 0.730200
PRC train: 0.553574	val: 0.219554	test: 0.205577

Epoch: 17
Loss: 0.10901619181130745
ROC train: 0.897152	val: 0.694419	test: 0.741487
PRC train: 0.552399	val: 0.202013	test: 0.230912

Epoch: 18
Loss: 0.10622020460545259
ROC train: 0.902026	val: 0.694151	test: 0.743064
PRC train: 0.542296	val: 0.216293	test: 0.212587

Epoch: 19
Loss: 0.10527428724087035
ROC train: 0.906831	val: 0.694284	test: 0.748729
PRC train: 0.560560	val: 0.223479	test: 0.238144

Epoch: 20
Loss: 0.10425352552494359
ROC train: 0.906815	val: 0.697439	test: 0.731213
PRC train: 0.559791	val: 0.226668	test: 0.219537

Epoch: 21
Loss: 0.10404166559646315
ROC train: 0.912813	val: 0.689760	test: 0.737419
PRC train: 0.565131	val: 0.211677	test: 0.179598

Epoch: 22
Loss: 0.10286690298401564
ROC train: 0.915653	val: 0.696093	test: 0.726031
PRC train: 0.569698	val: 0.238485	test: 0.206095

Epoch: 23
Loss: 0.10287511781862055
ROC train: 0.911906	val: 0.695343	test: 0.730963
PRC train: 0.568414	val: 0.229832	test: 0.180367

Epoch: 24
Loss: 0.10183564261263403
ROC train: 0.918332	val: 0.701555	test: 0.731239
PRC train: 0.596898	val: 0.234793	test: 0.231205

Epoch: 25
Loss: 0.10097177015644573
ROC train: 0.922922	val: 0.694317	test: 0.723664
PRC train: 0.596891	val: 0.230755	test: 0.217693

Epoch: 26
Loss: 0.0995294353939761
ROC train: 0.915802	val: 0.700336	test: 0.722016
PRC train: 0.574474	val: 0.232680	test: 0.197488

Epoch: 27
Loss: 0.09993520727349162
ROC train: 0.925420	val: 0.702820	test: 0.723000
PRC train: 0.590449	val: 0.221025	test: 0.194273

Epoch: 28
Loss: 0.10098303376886618
ROC train: 0.922496	val: 0.694940	test: 0.726667
PRC train: 0.585520	val: 0.209920	test: 0.213870

Epoch: 29
Loss: 0.0977982624872841
ROC train: 0.932519	val: 0.698585	test: 0.745386
PRC train: 0.617325	val: 0.215237	test: 0.234734

Epoch: 30
Loss: 0.09786865864634865
ROC train: 0.930888	val: 0.689216	test: 0.720322
PRC train: 0.609269	val: 0.228743	test: 0.174059

Epoch: 31
Loss: 0.09668776686183027
ROC train: 0.932794	val: 0.697383	test: 0.713285
PRC train: 0.626856	val: 0.218680	test: 0.161267

Epoch: 32
Loss: 0.09669951362743873
ROC train: 0.936905	val: 0.710414	test: 0.733444
PRC train: 0.635921	val: 0.242595	test: 0.225907

Epoch: 33
Loss: 0.09504966511942976Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/hiv/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/hiv/scaff/train_prop=0.6/hiv_scaff_6_26-05_10-25-11  ]
[ Using Seed :  6  ]
[ Using device :  cuda:0  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.3058470404140546
ROC train: 0.777599	val: 0.688201	test: 0.744864
PRC train: 0.231825	val: 0.109683	test: 0.170594

Epoch: 2
Loss: 0.1422024960553404
ROC train: 0.798448	val: 0.679914	test: 0.734745
PRC train: 0.325299	val: 0.142437	test: 0.241789

Epoch: 3
Loss: 0.1331400395840416
ROC train: 0.828416	val: 0.674307	test: 0.735414
PRC train: 0.394071	val: 0.188313	test: 0.245623

Epoch: 4
Loss: 0.12978686049548238
ROC train: 0.829845	val: 0.682668	test: 0.734811
PRC train: 0.363080	val: 0.160550	test: 0.232020

Epoch: 5
Loss: 0.12714661042516717
ROC train: 0.841447	val: 0.683216	test: 0.749954
PRC train: 0.428061	val: 0.174111	test: 0.272381

Epoch: 6
Loss: 0.12467912812997758
ROC train: 0.860757	val: 0.689321	test: 0.748703
PRC train: 0.426720	val: 0.169325	test: 0.214074

Epoch: 7
Loss: 0.1202220504437921
ROC train: 0.861171	val: 0.679369	test: 0.744908
PRC train: 0.450251	val: 0.165129	test: 0.165646

Epoch: 8
Loss: 0.11940486787460723
ROC train: 0.870616	val: 0.689319	test: 0.741186
PRC train: 0.464991	val: 0.206926	test: 0.211280

Epoch: 9
Loss: 0.11816997161581416
ROC train: 0.874598	val: 0.695883	test: 0.748687
PRC train: 0.505252	val: 0.193218	test: 0.208468

Epoch: 10
Loss: 0.11564652436636241
ROC train: 0.870048	val: 0.678451	test: 0.687318
PRC train: 0.464893	val: 0.178432	test: 0.091836

Epoch: 11
Loss: 0.11557256134950038
ROC train: 0.876174	val: 0.698261	test: 0.731748
PRC train: 0.504783	val: 0.187992	test: 0.176647

Epoch: 12
Loss: 0.11217539915577975
ROC train: 0.872981	val: 0.690225	test: 0.754598
PRC train: 0.486744	val: 0.189550	test: 0.235977

Epoch: 13
Loss: 0.11150208618411597
ROC train: 0.884055	val: 0.677590	test: 0.734018
PRC train: 0.512649	val: 0.160736	test: 0.201862

Epoch: 14
Loss: 0.1109549626888311
ROC train: 0.882001	val: 0.686935	test: 0.746697
PRC train: 0.513541	val: 0.172162	test: 0.172564

Epoch: 15
Loss: 0.10879894437578663
ROC train: 0.901673	val: 0.690283	test: 0.722828
PRC train: 0.546354	val: 0.205000	test: 0.164601

Epoch: 16
Loss: 0.10789795555782715
ROC train: 0.888134	val: 0.720543	test: 0.765606
PRC train: 0.510115	val: 0.210718	test: 0.232342

Epoch: 17
Loss: 0.10852469920520771
ROC train: 0.900349	val: 0.693730	test: 0.747918
PRC train: 0.534178	val: 0.195461	test: 0.274575

Epoch: 18
Loss: 0.10496777464350675
ROC train: 0.904926	val: 0.703973	test: 0.751717
PRC train: 0.533519	val: 0.191087	test: 0.199870

Epoch: 19
Loss: 0.10458796716300804
ROC train: 0.907037	val: 0.706259	test: 0.734828
PRC train: 0.565164	val: 0.200777	test: 0.209869

Epoch: 20
Loss: 0.10470287806885403
ROC train: 0.907606	val: 0.708180	test: 0.745033
PRC train: 0.563312	val: 0.235017	test: 0.215586

Epoch: 21
Loss: 0.10494898307247554
ROC train: 0.900206	val: 0.703806	test: 0.738021
PRC train: 0.544832	val: 0.191186	test: 0.256340

Epoch: 22
Loss: 0.10443669330135627
ROC train: 0.915348	val: 0.708234	test: 0.749844
PRC train: 0.582164	val: 0.196198	test: 0.196096

Epoch: 23
Loss: 0.10089557410027147
ROC train: 0.915958	val: 0.717777	test: 0.765835
PRC train: 0.582192	val: 0.245158	test: 0.247966

Epoch: 24
Loss: 0.10147958196710821
ROC train: 0.922594	val: 0.720115	test: 0.746156
PRC train: 0.589121	val: 0.240257	test: 0.212168

Epoch: 25
Loss: 0.10169823151670818
ROC train: 0.915283	val: 0.701847	test: 0.719395
PRC train: 0.557498	val: 0.204624	test: 0.126969

Epoch: 26
Loss: 0.10017644714539055
ROC train: 0.919325	val: 0.714889	test: 0.750443
PRC train: 0.577126	val: 0.218072	test: 0.248492

Epoch: 27
Loss: 0.0987695855476753
ROC train: 0.924873	val: 0.703419	test: 0.741305
PRC train: 0.611124	val: 0.228792	test: 0.199750

Epoch: 28
Loss: 0.09897293354379802
ROC train: 0.926260	val: 0.701717	test: 0.746121
PRC train: 0.592777	val: 0.215965	test: 0.154337

Epoch: 29
Loss: 0.09769752454034158
ROC train: 0.925534	val: 0.707630	test: 0.748851
PRC train: 0.609420	val: 0.212742	test: 0.172436

Epoch: 30
Loss: 0.09804839518334021
ROC train: 0.928460	val: 0.704571	test: 0.739835
PRC train: 0.621969	val: 0.208143	test: 0.198008

Epoch: 31
Loss: 0.0964839315147362
ROC train: 0.935507	val: 0.706307	test: 0.734329
PRC train: 0.629169	val: 0.217512	test: 0.180869

Epoch: 32
Loss: 0.09683982793340143
ROC train: 0.933984	val: 0.713300	test: 0.753078
PRC train: 0.617902	val: 0.231634	test: 0.200097

Epoch: 33
Loss: 0.09703860825713884Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/hiv/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/hiv/scaff/train_prop=0.6/hiv_scaff_4_26-05_10-25-11  ]
[ Using Seed :  4  ]
[ Using device :  cuda:0  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.28571894583115764
ROC train: 0.773730	val: 0.678214	test: 0.680170
PRC train: 0.235669	val: 0.141424	test: 0.167233

Epoch: 2
Loss: 0.14287053154693768
ROC train: 0.800446	val: 0.682757	test: 0.726604
PRC train: 0.307054	val: 0.174435	test: 0.242704

Epoch: 3
Loss: 0.13454697225551454
ROC train: 0.830444	val: 0.690419	test: 0.735181
PRC train: 0.357637	val: 0.207730	test: 0.222732

Epoch: 4
Loss: 0.13029440716605906
ROC train: 0.823913	val: 0.670517	test: 0.714572
PRC train: 0.350862	val: 0.170573	test: 0.136812

Epoch: 5
Loss: 0.12892344560141897
ROC train: 0.840083	val: 0.673771	test: 0.742608
PRC train: 0.406066	val: 0.169402	test: 0.219566

Epoch: 6
Loss: 0.1259281735555625
ROC train: 0.847404	val: 0.682671	test: 0.717032
PRC train: 0.399773	val: 0.132783	test: 0.180381

Epoch: 7
Loss: 0.12240056209024437
ROC train: 0.856770	val: 0.673321	test: 0.732323
PRC train: 0.433031	val: 0.184759	test: 0.177497

Epoch: 8
Loss: 0.12140114188267788
ROC train: 0.857413	val: 0.676958	test: 0.734348
PRC train: 0.459503	val: 0.185641	test: 0.201829

Epoch: 9
Loss: 0.11943620277368432
ROC train: 0.861700	val: 0.682003	test: 0.712771
PRC train: 0.476768	val: 0.181022	test: 0.185110

Epoch: 10
Loss: 0.11523335290530885
ROC train: 0.871817	val: 0.684039	test: 0.747376
PRC train: 0.477066	val: 0.192368	test: 0.263585

Epoch: 11
Loss: 0.115333297266343
ROC train: 0.869198	val: 0.679185	test: 0.720455
PRC train: 0.487502	val: 0.195766	test: 0.252328

Epoch: 12
Loss: 0.1129758182877381
ROC train: 0.850585	val: 0.668327	test: 0.681495
PRC train: 0.406571	val: 0.147049	test: 0.186760

Epoch: 13
Loss: 0.11413832748671848
ROC train: 0.886345	val: 0.697121	test: 0.744330
PRC train: 0.514710	val: 0.193060	test: 0.245519

Epoch: 14
Loss: 0.11148464088098382
ROC train: 0.892580	val: 0.690576	test: 0.732500
PRC train: 0.502128	val: 0.186529	test: 0.181252

Epoch: 15
Loss: 0.11297502800051845
ROC train: 0.894127	val: 0.696036	test: 0.731413
PRC train: 0.541847	val: 0.198694	test: 0.253807

Epoch: 16
Loss: 0.10920061468942686
ROC train: 0.896702	val: 0.689845	test: 0.713327
PRC train: 0.542121	val: 0.200537	test: 0.194632

Epoch: 17
Loss: 0.10759286752958454
ROC train: 0.897635	val: 0.697464	test: 0.741091
PRC train: 0.550694	val: 0.208215	test: 0.210171

Epoch: 18
Loss: 0.10638450677683002
ROC train: 0.903222	val: 0.702532	test: 0.739814
PRC train: 0.550309	val: 0.217438	test: 0.203977

Epoch: 19
Loss: 0.10600303361200057
ROC train: 0.911939	val: 0.698836	test: 0.733668
PRC train: 0.562162	val: 0.197173	test: 0.242389

Epoch: 20
Loss: 0.10460192316717336
ROC train: 0.905844	val: 0.688485	test: 0.724865
PRC train: 0.565410	val: 0.219789	test: 0.199547

Epoch: 21
Loss: 0.10564366559919007
ROC train: 0.913872	val: 0.697833	test: 0.722665
PRC train: 0.578609	val: 0.209938	test: 0.252188

Epoch: 22
Loss: 0.10205341834227291
ROC train: 0.917550	val: 0.698346	test: 0.719313
PRC train: 0.595712	val: 0.229771	test: 0.214817

Epoch: 23
Loss: 0.1008750215648546
ROC train: 0.916871	val: 0.703777	test: 0.736133
PRC train: 0.578289	val: 0.216116	test: 0.165986

Epoch: 24
Loss: 0.10151707503647037
ROC train: 0.922914	val: 0.700968	test: 0.729544
PRC train: 0.590641	val: 0.194131	test: 0.171051

Epoch: 25
Loss: 0.10070000693813205
ROC train: 0.919337	val: 0.708328	test: 0.732772
PRC train: 0.594838	val: 0.212227	test: 0.249480

Epoch: 26
Loss: 0.10000912344265094
ROC train: 0.928160	val: 0.699555	test: 0.736179
PRC train: 0.612950	val: 0.214889	test: 0.214167

Epoch: 27
Loss: 0.09946248406981749
ROC train: 0.924355	val: 0.711860	test: 0.736966
PRC train: 0.594871	val: 0.209456	test: 0.189135

Epoch: 28
Loss: 0.09829623302380855
ROC train: 0.927860	val: 0.698337	test: 0.733961
PRC train: 0.611634	val: 0.200668	test: 0.228656

Epoch: 29
Loss: 0.09892543573017233
ROC train: 0.928840	val: 0.705856	test: 0.724531
PRC train: 0.597553	val: 0.204533	test: 0.230008

Epoch: 30
Loss: 0.09788132723792058
ROC train: 0.933077	val: 0.689469	test: 0.728395
PRC train: 0.616892	val: 0.213279	test: 0.215714

Epoch: 31
Loss: 0.09703481551086761
ROC train: 0.934621	val: 0.707020	test: 0.733142
PRC train: 0.627752	val: 0.219552	test: 0.184172

Epoch: 32
Loss: 0.09642208421318782
ROC train: 0.934466	val: 0.701076	test: 0.735172
PRC train: 0.605850	val: 0.201216	test: 0.163513

Epoch: 33
Loss: 0.09715458150208832Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/hiv/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/hiv/scaff/train_prop=0.7/hiv_scaff_4_26-05_10-25-11  ]
[ Using Seed :  4  ]
[ Using device :  cuda:1  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.2680872320282037
ROC train: 0.761576	val: 0.696450	test: 0.707812
PRC train: 0.246581	val: 0.187774	test: 0.178316

Epoch: 2
Loss: 0.14102084505891174
ROC train: 0.794466	val: 0.715478	test: 0.700421
PRC train: 0.305052	val: 0.246218	test: 0.196634

Epoch: 3
Loss: 0.13489722486472594
ROC train: 0.799367	val: 0.705393	test: 0.721873
PRC train: 0.331577	val: 0.260099	test: 0.194374

Epoch: 4
Loss: 0.132194603727677
ROC train: 0.830529	val: 0.709478	test: 0.709375
PRC train: 0.384504	val: 0.260444	test: 0.126218

Epoch: 5
Loss: 0.12825302655506704
ROC train: 0.828932	val: 0.726537	test: 0.740384
PRC train: 0.361095	val: 0.276885	test: 0.239724

Epoch: 6
Loss: 0.1263580739581492
ROC train: 0.846791	val: 0.710632	test: 0.719301
PRC train: 0.368848	val: 0.195152	test: 0.112730

Epoch: 7
Loss: 0.12347878245421962
ROC train: 0.843158	val: 0.716529	test: 0.724105
PRC train: 0.415305	val: 0.239249	test: 0.198720

Epoch: 8
Loss: 0.12246291348147564
ROC train: 0.850250	val: 0.702388	test: 0.729570
PRC train: 0.441635	val: 0.269295	test: 0.194358

Epoch: 9
Loss: 0.1206294109437752
ROC train: 0.856104	val: 0.698264	test: 0.746237
PRC train: 0.443170	val: 0.275828	test: 0.199433

Epoch: 10
Loss: 0.12010011707806521
ROC train: 0.865648	val: 0.705214	test: 0.734791
PRC train: 0.445146	val: 0.309457	test: 0.191171

Epoch: 11
Loss: 0.11700709125841041
ROC train: 0.872480	val: 0.702353	test: 0.734861
PRC train: 0.450016	val: 0.293713	test: 0.143014

Epoch: 12
Loss: 0.11589036936339919
ROC train: 0.875600	val: 0.717425	test: 0.743539
PRC train: 0.482792	val: 0.300368	test: 0.208316

Epoch: 13
Loss: 0.11352145197371036
ROC train: 0.882121	val: 0.708650	test: 0.741779
PRC train: 0.511955	val: 0.282685	test: 0.166751

Epoch: 14
Loss: 0.11450860195236397
ROC train: 0.884946	val: 0.701357	test: 0.728916
PRC train: 0.509420	val: 0.285687	test: 0.179372

Epoch: 15
Loss: 0.11250298965236663
ROC train: 0.887190	val: 0.691858	test: 0.738294
PRC train: 0.515580	val: 0.261005	test: 0.150301

Epoch: 16
Loss: 0.11140974400982617
ROC train: 0.873571	val: 0.715428	test: 0.719050
PRC train: 0.459536	val: 0.286370	test: 0.152569

Epoch: 17
Loss: 0.11050425830472266
ROC train: 0.895161	val: 0.716913	test: 0.742522
PRC train: 0.525748	val: 0.311067	test: 0.181232

Epoch: 18
Loss: 0.10979578215911232
ROC train: 0.898694	val: 0.705714	test: 0.729860
PRC train: 0.536707	val: 0.291479	test: 0.163428

Epoch: 19
Loss: 0.11054277927434521
ROC train: 0.896627	val: 0.693740	test: 0.716739
PRC train: 0.535422	val: 0.254255	test: 0.144227

Epoch: 20
Loss: 0.10859292190939034
ROC train: 0.900375	val: 0.699222	test: 0.723683
PRC train: 0.527732	val: 0.239726	test: 0.110012

Epoch: 21
Loss: 0.10786969692949282
ROC train: 0.902370	val: 0.703794	test: 0.725911
PRC train: 0.549102	val: 0.293443	test: 0.175525

Epoch: 22
Loss: 0.10725937905825048
ROC train: 0.908573	val: 0.705828	test: 0.730711
PRC train: 0.557342	val: 0.253789	test: 0.166390

Epoch: 23
Loss: 0.10667107539613606
ROC train: 0.908684	val: 0.710205	test: 0.730997
PRC train: 0.558496	val: 0.293566	test: 0.212839

Epoch: 24
Loss: 0.10520324488527533
ROC train: 0.907727	val: 0.703876	test: 0.724024
PRC train: 0.546181	val: 0.213442	test: 0.094999

Epoch: 25
Loss: 0.10503950976437042
ROC train: 0.909515	val: 0.705576	test: 0.738269
PRC train: 0.553776	val: 0.275686	test: 0.178701

Epoch: 26
Loss: 0.10337091898232914
ROC train: 0.912291	val: 0.718510	test: 0.742135
PRC train: 0.564712	val: 0.299982	test: 0.168156

Epoch: 27
Loss: 0.10412686360322243
ROC train: 0.910250	val: 0.713747	test: 0.738121
PRC train: 0.576816	val: 0.272267	test: 0.169366

Epoch: 28
Loss: 0.10231338777346385
ROC train: 0.916052	val: 0.710783	test: 0.755841
PRC train: 0.564945	val: 0.281828	test: 0.157740

Epoch: 29
Loss: 0.10157022094040409
ROC train: 0.923780	val: 0.709699	test: 0.745088
PRC train: 0.596179	val: 0.282738	test: 0.205028

Epoch: 30
Loss: 0.1021234408051167
ROC train: 0.915768	val: 0.695970	test: 0.743476
PRC train: 0.578623	val: 0.249476	test: 0.144349

Epoch: 31
Loss: 0.10174137893937424
ROC train: 0.923815	val: 0.705472	test: 0.740452
PRC train: 0.606021	val: 0.274616	test: 0.141301

Epoch: 32
Loss: 0.09977257747603924
ROC train: 0.925111	val: 0.710712	test: 0.750596
PRC train: 0.592409	val: 0.276292	test: 0.158456

Epoch: 33
Loss: 0.10128089701939673Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/hiv/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/hiv/scaff/train_prop=0.7/hiv_scaff_6_26-05_10-25-11  ]
[ Using Seed :  6  ]
[ Using device :  cuda:1  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.28339022569663874
ROC train: 0.781418	val: 0.709735	test: 0.709128
PRC train: 0.233423	val: 0.200177	test: 0.201614

Epoch: 2
Loss: 0.14163211562347613
ROC train: 0.779707	val: 0.695327	test: 0.679134
PRC train: 0.258805	val: 0.211379	test: 0.167860

Epoch: 3
Loss: 0.13505006221626803
ROC train: 0.817453	val: 0.698642	test: 0.722676
PRC train: 0.345479	val: 0.200551	test: 0.130881

Epoch: 4
Loss: 0.1306972786492029
ROC train: 0.824266	val: 0.688788	test: 0.723916
PRC train: 0.302626	val: 0.249420	test: 0.162646

Epoch: 5
Loss: 0.12950551491473114
ROC train: 0.831889	val: 0.691724	test: 0.749391
PRC train: 0.374977	val: 0.282501	test: 0.212470

Epoch: 6
Loss: 0.1269707279159943
ROC train: 0.823455	val: 0.701239	test: 0.743661
PRC train: 0.310473	val: 0.262300	test: 0.151197

Epoch: 7
Loss: 0.12628897831013614
ROC train: 0.851553	val: 0.701150	test: 0.718232
PRC train: 0.426943	val: 0.286672	test: 0.181277

Epoch: 8
Loss: 0.12222094634429263
ROC train: 0.851010	val: 0.721918	test: 0.707008
PRC train: 0.414680	val: 0.275745	test: 0.104799

Epoch: 9
Loss: 0.12183687337060618
ROC train: 0.853865	val: 0.706852	test: 0.715293
PRC train: 0.414979	val: 0.299759	test: 0.155668

Epoch: 10
Loss: 0.11912418911366073
ROC train: 0.857941	val: 0.709729	test: 0.739020
PRC train: 0.447378	val: 0.282756	test: 0.162060

Epoch: 11
Loss: 0.11852234094060571
ROC train: 0.873353	val: 0.696694	test: 0.737691
PRC train: 0.465678	val: 0.287384	test: 0.151478

Epoch: 12
Loss: 0.1172292535508519
ROC train: 0.880170	val: 0.704811	test: 0.752035
PRC train: 0.491496	val: 0.298770	test: 0.198558

Epoch: 13
Loss: 0.1149399788646518
ROC train: 0.882298	val: 0.699164	test: 0.748749
PRC train: 0.512506	val: 0.289761	test: 0.181633

Epoch: 14
Loss: 0.1142688968046996
ROC train: 0.879862	val: 0.703614	test: 0.737347
PRC train: 0.486096	val: 0.297368	test: 0.141722

Epoch: 15
Loss: 0.1129892953784558
ROC train: 0.885536	val: 0.695160	test: 0.719172
PRC train: 0.508554	val: 0.280154	test: 0.182520

Epoch: 16
Loss: 0.11220432661972586
ROC train: 0.889306	val: 0.697019	test: 0.733736
PRC train: 0.505034	val: 0.286708	test: 0.158724

Epoch: 17
Loss: 0.11131413261909263
ROC train: 0.893267	val: 0.695592	test: 0.713873
PRC train: 0.525301	val: 0.272813	test: 0.137132

Epoch: 18
Loss: 0.11029673564143831
ROC train: 0.892573	val: 0.694869	test: 0.734729
PRC train: 0.510924	val: 0.296372	test: 0.164456

Epoch: 19
Loss: 0.11054402148715707
ROC train: 0.891732	val: 0.702305	test: 0.721694
PRC train: 0.522838	val: 0.258357	test: 0.135040

Epoch: 20
Loss: 0.10991780748635821
ROC train: 0.900007	val: 0.695729	test: 0.712460
PRC train: 0.545513	val: 0.306596	test: 0.156703

Epoch: 21
Loss: 0.10788667068021275
ROC train: 0.900348	val: 0.704462	test: 0.752477
PRC train: 0.537872	val: 0.265834	test: 0.173574

Epoch: 22
Loss: 0.10617761601356172
ROC train: 0.902597	val: 0.703776	test: 0.734437
PRC train: 0.538764	val: 0.288638	test: 0.186618

Epoch: 23
Loss: 0.10540096765039653
ROC train: 0.909780	val: 0.714958	test: 0.740870
PRC train: 0.545154	val: 0.320662	test: 0.164160

Epoch: 24
Loss: 0.10507675031148928
ROC train: 0.905211	val: 0.691868	test: 0.740716
PRC train: 0.549213	val: 0.294122	test: 0.173048

Epoch: 25
Loss: 0.10486841073698336
ROC train: 0.916295	val: 0.709095	test: 0.737684
PRC train: 0.571881	val: 0.285150	test: 0.167027

Epoch: 26
Loss: 0.10493950317459083
ROC train: 0.904302	val: 0.710114	test: 0.751662
PRC train: 0.557155	val: 0.301024	test: 0.179381

Epoch: 27
Loss: 0.1041041263015566
ROC train: 0.917402	val: 0.708618	test: 0.745425
PRC train: 0.572912	val: 0.318735	test: 0.178272

Epoch: 28
Loss: 0.10248801421693296
ROC train: 0.917855	val: 0.696883	test: 0.688911
PRC train: 0.568481	val: 0.233451	test: 0.097389

Epoch: 29
Loss: 0.10164609793293852
ROC train: 0.912984	val: 0.703136	test: 0.743733
PRC train: 0.545033	val: 0.286985	test: 0.137374

Epoch: 30
Loss: 0.10176897844409685
ROC train: 0.925675	val: 0.694056	test: 0.756816
PRC train: 0.593940	val: 0.276428	test: 0.174420

Epoch: 31
Loss: 0.10145288363750564
ROC train: 0.913447	val: 0.722173	test: 0.745881
PRC train: 0.570638	val: 0.283026	test: 0.201914

Epoch: 32
Loss: 0.10013605176276136
ROC train: 0.926697	val: 0.711872	test: 0.736601
PRC train: 0.590001	val: 0.287166	test: 0.184862

Epoch: 33
Loss: 0.09913337331748369Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/hiv/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/hiv/scaff/train_prop=0.7/hiv_scaff_5_26-05_10-25-11  ]
[ Using Seed :  5  ]
[ Using device :  cuda:1  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.2833185247951293
ROC train: 0.738983	val: 0.705918	test: 0.711008
PRC train: 0.166700	val: 0.151964	test: 0.149999

Epoch: 2
Loss: 0.1425821236867784
ROC train: 0.777947	val: 0.685138	test: 0.660123
PRC train: 0.253716	val: 0.123594	test: 0.119388

Epoch: 3
Loss: 0.13529128948769395
ROC train: 0.812793	val: 0.715631	test: 0.696094
PRC train: 0.341909	val: 0.255651	test: 0.181541

Epoch: 4
Loss: 0.13446966275670955
ROC train: 0.824420	val: 0.707768	test: 0.724269
PRC train: 0.333714	val: 0.268608	test: 0.221524

Epoch: 5
Loss: 0.1292570111152546
ROC train: 0.829833	val: 0.699389	test: 0.705166
PRC train: 0.339147	val: 0.219266	test: 0.148727

Epoch: 6
Loss: 0.1271806383637811
ROC train: 0.841605	val: 0.709839	test: 0.715222
PRC train: 0.399540	val: 0.283165	test: 0.179120

Epoch: 7
Loss: 0.12510099184072165
ROC train: 0.838052	val: 0.712758	test: 0.723906
PRC train: 0.390235	val: 0.293555	test: 0.204589

Epoch: 8
Loss: 0.12360919380933656
ROC train: 0.850430	val: 0.713491	test: 0.719990
PRC train: 0.444258	val: 0.293844	test: 0.183920

Epoch: 9
Loss: 0.12074711326317536
ROC train: 0.857404	val: 0.697296	test: 0.714982
PRC train: 0.447196	val: 0.289474	test: 0.199420

Epoch: 10
Loss: 0.11889505041878524
ROC train: 0.858874	val: 0.702171	test: 0.745020
PRC train: 0.469316	val: 0.289754	test: 0.163127

Epoch: 11
Loss: 0.1174472842958995
ROC train: 0.862318	val: 0.702300	test: 0.719545
PRC train: 0.459328	val: 0.267710	test: 0.178346

Epoch: 12
Loss: 0.1158159131984094
ROC train: 0.866665	val: 0.702962	test: 0.732898
PRC train: 0.469931	val: 0.269852	test: 0.158503

Epoch: 13
Loss: 0.11462395698081963
ROC train: 0.880614	val: 0.722804	test: 0.750901
PRC train: 0.494864	val: 0.304382	test: 0.152796

Epoch: 14
Loss: 0.11385893484133619
ROC train: 0.864949	val: 0.710643	test: 0.737125
PRC train: 0.469202	val: 0.309914	test: 0.217445

Epoch: 15
Loss: 0.11246182005291369
ROC train: 0.883126	val: 0.704648	test: 0.758325
PRC train: 0.517020	val: 0.292360	test: 0.154572

Epoch: 16
Loss: 0.11097706680939286
ROC train: 0.889123	val: 0.726706	test: 0.752284
PRC train: 0.512609	val: 0.299262	test: 0.182395

Epoch: 17
Loss: 0.11172683759052189
ROC train: 0.886792	val: 0.707475	test: 0.708403
PRC train: 0.529419	val: 0.294277	test: 0.170033

Epoch: 18
Loss: 0.10959536023688152
ROC train: 0.889818	val: 0.694668	test: 0.748380
PRC train: 0.507666	val: 0.293253	test: 0.168664

Epoch: 19
Loss: 0.10997693380989365
ROC train: 0.893318	val: 0.698251	test: 0.734633
PRC train: 0.528729	val: 0.270633	test: 0.174360

Epoch: 20
Loss: 0.10705394918367277
ROC train: 0.897002	val: 0.711123	test: 0.761176
PRC train: 0.521675	val: 0.294051	test: 0.187823

Epoch: 21
Loss: 0.10719031543015196
ROC train: 0.895132	val: 0.703727	test: 0.730603
PRC train: 0.528598	val: 0.294094	test: 0.173312

Epoch: 22
Loss: 0.10704678111114502
ROC train: 0.904575	val: 0.705836	test: 0.743486
PRC train: 0.524341	val: 0.243001	test: 0.144092

Epoch: 23
Loss: 0.10698978933567051
ROC train: 0.906467	val: 0.714241	test: 0.721753
PRC train: 0.555275	val: 0.296131	test: 0.164345

Epoch: 24
Loss: 0.10459342532244544
ROC train: 0.907802	val: 0.701100	test: 0.741194
PRC train: 0.560078	val: 0.311453	test: 0.189234

Epoch: 25
Loss: 0.10501279036024205
ROC train: 0.912727	val: 0.716974	test: 0.751913
PRC train: 0.559910	val: 0.262819	test: 0.139442

Epoch: 26
Loss: 0.10533719392381326
ROC train: 0.912876	val: 0.701131	test: 0.748583
PRC train: 0.570373	val: 0.268215	test: 0.175435

Epoch: 27
Loss: 0.10302117852722387
ROC train: 0.912449	val: 0.695740	test: 0.739442
PRC train: 0.541683	val: 0.289232	test: 0.207159

Epoch: 28
Loss: 0.10335528935075612
ROC train: 0.924156	val: 0.717827	test: 0.740301
PRC train: 0.581935	val: 0.263390	test: 0.142201

Epoch: 29
Loss: 0.10346538636558585
ROC train: 0.916189	val: 0.712749	test: 0.749804
PRC train: 0.557342	val: 0.300231	test: 0.200130

Epoch: 30
Loss: 0.1003392488603298
ROC train: 0.923522	val: 0.706001	test: 0.735720
PRC train: 0.579577	val: 0.284430	test: 0.153687

Epoch: 31
Loss: 0.10088762579716841
ROC train: 0.914065	val: 0.708360	test: 0.718340
PRC train: 0.553446	val: 0.285855	test: 0.168926

Epoch: 32
Loss: 0.1001494290330987
ROC train: 0.927362	val: 0.698623	test: 0.726970
PRC train: 0.585666	val: 0.279096	test: 0.160315

Epoch: 33
Loss: 0.09977550148120493Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/hiv/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/hiv/scaff/train_prop=0.8/hiv_scaff_4_26-05_10-25-11  ]
[ Using Seed :  4  ]
[ Using device :  cuda:2  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.25532175729685036
ROC train: 0.748614	val: 0.714528	test: 0.637660
PRC train: 0.222164	val: 0.178570	test: 0.194851

Epoch: 2
Loss: 0.14146611805941112
ROC train: 0.786946	val: 0.748777	test: 0.735612
PRC train: 0.283541	val: 0.193967	test: 0.194418

Epoch: 3
Loss: 0.13533934455168808
ROC train: 0.803002	val: 0.780356	test: 0.725325
PRC train: 0.345426	val: 0.330649	test: 0.199589

Epoch: 4
Loss: 0.13109367340806344
ROC train: 0.799378	val: 0.760334	test: 0.771021
PRC train: 0.297210	val: 0.259562	test: 0.238420

Epoch: 5
Loss: 0.12826069268861534
ROC train: 0.817163	val: 0.762404	test: 0.704975
PRC train: 0.369442	val: 0.262395	test: 0.132562

Epoch: 6
Loss: 0.12744955949780654
ROC train: 0.829332	val: 0.768160	test: 0.692864
PRC train: 0.371419	val: 0.226315	test: 0.096035

Epoch: 7
Loss: 0.12378132175551462
ROC train: 0.829294	val: 0.755049	test: 0.735446
PRC train: 0.394110	val: 0.279754	test: 0.196806

Epoch: 8
Loss: 0.12303852553890554
ROC train: 0.837732	val: 0.789493	test: 0.750003
PRC train: 0.407215	val: 0.274024	test: 0.215628

Epoch: 9
Loss: 0.12162921816803586
ROC train: 0.840222	val: 0.783574	test: 0.779731
PRC train: 0.388690	val: 0.294393	test: 0.222653

Epoch: 10
Loss: 0.12016510408621257
ROC train: 0.847033	val: 0.782224	test: 0.753533
PRC train: 0.442798	val: 0.317874	test: 0.170216

Epoch: 11
Loss: 0.12021829871097016
ROC train: 0.856652	val: 0.794202	test: 0.744586
PRC train: 0.448343	val: 0.327010	test: 0.152948

Epoch: 12
Loss: 0.11659033589868097
ROC train: 0.856891	val: 0.788335	test: 0.761228
PRC train: 0.456848	val: 0.315257	test: 0.200035

Epoch: 13
Loss: 0.11644240542847753
ROC train: 0.864420	val: 0.787187	test: 0.734280
PRC train: 0.460490	val: 0.318536	test: 0.126148

Epoch: 14
Loss: 0.11411734606425937
ROC train: 0.872526	val: 0.767707	test: 0.736196
PRC train: 0.488733	val: 0.341886	test: 0.134953

Epoch: 15
Loss: 0.11420392521027319
ROC train: 0.875770	val: 0.800393	test: 0.758667
PRC train: 0.492501	val: 0.351511	test: 0.169362

Epoch: 16
Loss: 0.11277278046720433
ROC train: 0.881616	val: 0.806505	test: 0.777265
PRC train: 0.496969	val: 0.371481	test: 0.209034

Epoch: 17
Loss: 0.1136497525460372
ROC train: 0.882069	val: 0.791532	test: 0.757946
PRC train: 0.507705	val: 0.330593	test: 0.150083

Epoch: 18
Loss: 0.11169391462093786
ROC train: 0.886124	val: 0.796945	test: 0.759632
PRC train: 0.512806	val: 0.340977	test: 0.170836

Epoch: 19
Loss: 0.10989920842841018
ROC train: 0.882929	val: 0.777671	test: 0.765700
PRC train: 0.515490	val: 0.344687	test: 0.166204

Epoch: 20
Loss: 0.1089698019694243
ROC train: 0.893439	val: 0.786002	test: 0.769974
PRC train: 0.521745	val: 0.351817	test: 0.196172

Epoch: 21
Loss: 0.10816022750049535
ROC train: 0.894499	val: 0.795081	test: 0.744097
PRC train: 0.532090	val: 0.355634	test: 0.196775

Epoch: 22
Loss: 0.10901625253744025
ROC train: 0.890400	val: 0.792095	test: 0.777288
PRC train: 0.530835	val: 0.374085	test: 0.200215

Epoch: 23
Loss: 0.10807217751784315
ROC train: 0.897843	val: 0.811297	test: 0.746830
PRC train: 0.526006	val: 0.333700	test: 0.166301

Epoch: 24
Loss: 0.1058160888148815
ROC train: 0.900688	val: 0.786835	test: 0.761173
PRC train: 0.551519	val: 0.361630	test: 0.172226

Epoch: 25
Loss: 0.10639840121902529
ROC train: 0.908082	val: 0.785528	test: 0.760563
PRC train: 0.563173	val: 0.341322	test: 0.169518

Epoch: 26
Loss: 0.10416733215348248
ROC train: 0.904438	val: 0.783507	test: 0.734781
PRC train: 0.541760	val: 0.314271	test: 0.177120

Epoch: 27
Loss: 0.10495172701294488
ROC train: 0.911450	val: 0.799992	test: 0.757603
PRC train: 0.565040	val: 0.331971	test: 0.146483

Epoch: 28
Loss: 0.10455365948101303
ROC train: 0.912688	val: 0.794790	test: 0.753444
PRC train: 0.565091	val: 0.372972	test: 0.189007

Epoch: 29
Loss: 0.102853359613531
ROC train: 0.907888	val: 0.794747	test: 0.741776
PRC train: 0.573882	val: 0.357212	test: 0.159638

Epoch: 30
Loss: 0.10254412672381456
ROC train: 0.913143	val: 0.774327	test: 0.751577
PRC train: 0.558614	val: 0.361954	test: 0.185598

Epoch: 31
Loss: 0.10008055280912453
ROC train: 0.917241	val: 0.807852	test: 0.753935
PRC train: 0.576665	val: 0.339438	test: 0.164038

Epoch: 32
Loss: 0.10080247114568325
ROC train: 0.920393	val: 0.814325	test: 0.768873
PRC train: 0.580963	val: 0.326394	test: 0.147790

Epoch: 33
Loss: 0.10218511953565124Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/hiv/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/hiv/scaff/train_prop=0.8/hiv_scaff_6_26-05_10-25-11  ]
[ Using Seed :  6  ]
[ Using device :  cuda:2  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.26640520881910634
ROC train: 0.755984	val: 0.745373	test: 0.677589
PRC train: 0.253406	val: 0.217264	test: 0.147168

Epoch: 2
Loss: 0.1416152075368432
ROC train: 0.779175	val: 0.747097	test: 0.718753
PRC train: 0.293326	val: 0.290809	test: 0.201364

Epoch: 3
Loss: 0.13411208544838948
ROC train: 0.779508	val: 0.763365	test: 0.693869
PRC train: 0.318757	val: 0.310281	test: 0.186114

Epoch: 4
Loss: 0.13190992123657216
ROC train: 0.810644	val: 0.762425	test: 0.692186
PRC train: 0.356225	val: 0.308039	test: 0.114510

Epoch: 5
Loss: 0.12871372874693204
ROC train: 0.813271	val: 0.777499	test: 0.718353
PRC train: 0.341469	val: 0.285930	test: 0.208180

Epoch: 6
Loss: 0.12703136814468668
ROC train: 0.825062	val: 0.770175	test: 0.713787
PRC train: 0.393925	val: 0.317918	test: 0.194707

Epoch: 7
Loss: 0.1254027298848317
ROC train: 0.822036	val: 0.756200	test: 0.701479
PRC train: 0.352526	val: 0.265839	test: 0.180510

Epoch: 8
Loss: 0.12229885778885091
ROC train: 0.834618	val: 0.784321	test: 0.730453
PRC train: 0.404224	val: 0.321065	test: 0.217278

Epoch: 9
Loss: 0.12150616522995088
ROC train: 0.833404	val: 0.780873	test: 0.720236
PRC train: 0.422630	val: 0.341573	test: 0.147011

Epoch: 10
Loss: 0.12152182381506586
ROC train: 0.845254	val: 0.770962	test: 0.747801
PRC train: 0.437672	val: 0.365382	test: 0.188569

Epoch: 11
Loss: 0.11819496091724409
ROC train: 0.852149	val: 0.785229	test: 0.717130
PRC train: 0.446149	val: 0.359386	test: 0.174325

Epoch: 12
Loss: 0.11835393920492958
ROC train: 0.856345	val: 0.780301	test: 0.745771
PRC train: 0.441023	val: 0.363304	test: 0.222763

Epoch: 13
Loss: 0.11624571060859586
ROC train: 0.860420	val: 0.760447	test: 0.730532
PRC train: 0.453369	val: 0.350717	test: 0.207669

Epoch: 14
Loss: 0.11702652063085271
ROC train: 0.869731	val: 0.775916	test: 0.736996
PRC train: 0.473507	val: 0.361849	test: 0.155433

Epoch: 15
Loss: 0.1145265098088603
ROC train: 0.872220	val: 0.774345	test: 0.738301
PRC train: 0.484193	val: 0.337863	test: 0.140366

Epoch: 16
Loss: 0.11296871768290023
ROC train: 0.872999	val: 0.757621	test: 0.739503
PRC train: 0.499447	val: 0.333320	test: 0.143230

Epoch: 17
Loss: 0.11265967403907294
ROC train: 0.881186	val: 0.772040	test: 0.735955
PRC train: 0.499762	val: 0.333757	test: 0.161584

Epoch: 18
Loss: 0.11156662914142994
ROC train: 0.882883	val: 0.755720	test: 0.756604
PRC train: 0.504129	val: 0.318253	test: 0.151548

Epoch: 19
Loss: 0.11066499198829226
ROC train: 0.885179	val: 0.769915	test: 0.755047
PRC train: 0.514381	val: 0.304877	test: 0.140212

Epoch: 20
Loss: 0.1106494319413091
ROC train: 0.891145	val: 0.776060	test: 0.753218
PRC train: 0.534691	val: 0.351909	test: 0.206381

Epoch: 21
Loss: 0.10908758139414632
ROC train: 0.887942	val: 0.776740	test: 0.740316
PRC train: 0.517389	val: 0.360656	test: 0.257685

Epoch: 22
Loss: 0.10814749707106525
ROC train: 0.889439	val: 0.773326	test: 0.760513
PRC train: 0.526705	val: 0.336108	test: 0.192220

Epoch: 23
Loss: 0.10836975109257346
ROC train: 0.897603	val: 0.778577	test: 0.755246
PRC train: 0.531918	val: 0.334332	test: 0.213648

Epoch: 24
Loss: 0.10790972987077402
ROC train: 0.897718	val: 0.775157	test: 0.742015
PRC train: 0.543719	val: 0.328300	test: 0.175498

Epoch: 25
Loss: 0.10626780092528774
ROC train: 0.886136	val: 0.747593	test: 0.746048
PRC train: 0.477640	val: 0.346440	test: 0.183125

Epoch: 26
Loss: 0.10686930698461854
ROC train: 0.899752	val: 0.767615	test: 0.756345
PRC train: 0.544968	val: 0.362233	test: 0.202556

Epoch: 27
Loss: 0.10488806486807135
ROC train: 0.904122	val: 0.787068	test: 0.751135
PRC train: 0.549692	val: 0.324255	test: 0.213620

Epoch: 28
Loss: 0.1056175224174203
ROC train: 0.902302	val: 0.774278	test: 0.756378
PRC train: 0.531545	val: 0.363766	test: 0.273779

Epoch: 29
Loss: 0.10254755406199881
ROC train: 0.905286	val: 0.781869	test: 0.745014
PRC train: 0.557917	val: 0.319234	test: 0.183130

Epoch: 30
Loss: 0.10483510557961641
ROC train: 0.914776	val: 0.787205	test: 0.742946
PRC train: 0.574783	val: 0.334804	test: 0.180519

Epoch: 31
Loss: 0.10120904418328758
ROC train: 0.914343	val: 0.774728	test: 0.718737
PRC train: 0.572311	val: 0.337093	test: 0.197143

Epoch: 32
Loss: 0.1015918969957037
ROC train: 0.915089	val: 0.764296	test: 0.770828
PRC train: 0.567157	val: 0.312155	test: 0.209724

Epoch: 33
Loss: 0.10064551264298653Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/hiv/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/hiv/scaff/train_prop=0.8/hiv_scaff_5_26-05_10-25-11  ]
[ Using Seed :  5  ]
[ Using device :  cuda:2  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.26573402361899107
ROC train: 0.751163	val: 0.757058	test: 0.676599
PRC train: 0.219523	val: 0.190150	test: 0.189559

Epoch: 2
Loss: 0.14082998988887785
ROC train: 0.789413	val: 0.766596	test: 0.741731
PRC train: 0.298962	val: 0.315126	test: 0.202665

Epoch: 3
Loss: 0.13438741373999646
ROC train: 0.794944	val: 0.745130	test: 0.675048
PRC train: 0.292696	val: 0.200843	test: 0.106846

Epoch: 4
Loss: 0.1318880865071698
ROC train: 0.807873	val: 0.744893	test: 0.722022
PRC train: 0.329767	val: 0.296143	test: 0.200737

Epoch: 5
Loss: 0.12910192150377534
ROC train: 0.812113	val: 0.764991	test: 0.698270
PRC train: 0.361026	val: 0.332978	test: 0.154498

Epoch: 6
Loss: 0.12818785567456661
ROC train: 0.818184	val: 0.745563	test: 0.735460
PRC train: 0.369230	val: 0.286447	test: 0.174117

Epoch: 7
Loss: 0.12556820550175085
ROC train: 0.818544	val: 0.777340	test: 0.747168
PRC train: 0.356877	val: 0.324921	test: 0.230339

Epoch: 8
Loss: 0.12392812453485574
ROC train: 0.820748	val: 0.726518	test: 0.732432
PRC train: 0.339652	val: 0.309174	test: 0.200347

Epoch: 9
Loss: 0.12241032134978934
ROC train: 0.844020	val: 0.779603	test: 0.709015
PRC train: 0.424704	val: 0.326229	test: 0.178430

Epoch: 10
Loss: 0.1208132911461477
ROC train: 0.843331	val: 0.777793	test: 0.754702
PRC train: 0.370344	val: 0.349413	test: 0.176290

Epoch: 11
Loss: 0.1197350600999659
ROC train: 0.849771	val: 0.790050	test: 0.755494
PRC train: 0.426813	val: 0.309198	test: 0.185105

Epoch: 12
Loss: 0.11907078443354285
ROC train: 0.856986	val: 0.781550	test: 0.729458
PRC train: 0.451634	val: 0.319447	test: 0.191750

Epoch: 13
Loss: 0.1181407486944244
ROC train: 0.860888	val: 0.770175	test: 0.736638
PRC train: 0.468769	val: 0.309604	test: 0.194993

Epoch: 14
Loss: 0.11531045764946636
ROC train: 0.865023	val: 0.786789	test: 0.737388
PRC train: 0.474712	val: 0.328412	test: 0.188666

Epoch: 15
Loss: 0.11583016718273685
ROC train: 0.856973	val: 0.765291	test: 0.744190
PRC train: 0.438279	val: 0.288753	test: 0.182293

Epoch: 16
Loss: 0.11424107039471251
ROC train: 0.873090	val: 0.782309	test: 0.734921
PRC train: 0.475263	val: 0.341540	test: 0.194470

Epoch: 17
Loss: 0.1139148980504385
ROC train: 0.877735	val: 0.776075	test: 0.750279
PRC train: 0.501121	val: 0.340572	test: 0.193721

Epoch: 18
Loss: 0.11278073041110774
ROC train: 0.875184	val: 0.801290	test: 0.768626
PRC train: 0.497596	val: 0.342038	test: 0.201529

Epoch: 19
Loss: 0.111533680225591
ROC train: 0.875033	val: 0.773889	test: 0.725532
PRC train: 0.465931	val: 0.282269	test: 0.117235

Epoch: 20
Loss: 0.1116050410589136
ROC train: 0.873441	val: 0.786241	test: 0.755156
PRC train: 0.469251	val: 0.338109	test: 0.244561

Epoch: 21
Loss: 0.11042553261553571
ROC train: 0.880731	val: 0.776985	test: 0.756600
PRC train: 0.508681	val: 0.373648	test: 0.205849

Epoch: 22
Loss: 0.11129068117406458
ROC train: 0.884463	val: 0.794903	test: 0.757566
PRC train: 0.505464	val: 0.347031	test: 0.220030

Epoch: 23
Loss: 0.10784953451733971
ROC train: 0.885951	val: 0.784073	test: 0.760073
PRC train: 0.506700	val: 0.349851	test: 0.191000

Epoch: 24
Loss: 0.10787598642727612
ROC train: 0.890198	val: 0.797184	test: 0.750519
PRC train: 0.523475	val: 0.331809	test: 0.209689

Epoch: 25
Loss: 0.10758529418567316
ROC train: 0.892297	val: 0.770745	test: 0.729193
PRC train: 0.513478	val: 0.356790	test: 0.194331

Epoch: 26
Loss: 0.10654254099791817
ROC train: 0.890834	val: 0.777784	test: 0.740868
PRC train: 0.522327	val: 0.292902	test: 0.151416

Epoch: 27
Loss: 0.10705975698618059
ROC train: 0.896097	val: 0.783602	test: 0.756372
PRC train: 0.521348	val: 0.344784	test: 0.207046

Epoch: 28
Loss: 0.10439544653952593
ROC train: 0.893295	val: 0.774419	test: 0.740553
PRC train: 0.529841	val: 0.336415	test: 0.265856

Epoch: 29
Loss: 0.10455079980662492
ROC train: 0.905696	val: 0.789808	test: 0.761212
PRC train: 0.538014	val: 0.319360	test: 0.165500

Epoch: 30
Loss: 0.10548996068440691
ROC train: 0.903670	val: 0.796183	test: 0.737753
PRC train: 0.548638	val: 0.370349	test: 0.196121

Epoch: 31
Loss: 0.10379741005183328
ROC train: 0.910821	val: 0.796342	test: 0.738745
PRC train: 0.562934	val: 0.316273	test: 0.156488

Epoch: 32
Loss: 0.10234178619980101
ROC train: 0.895037	val: 0.790393	test: 0.755803
PRC train: 0.540957	val: 0.289257	test: 0.217580

Epoch: 33
Loss: 0.10411229034995682
ROC train: 0.935603	val: 0.701237	test: 0.751539
PRC train: 0.620915	val: 0.221300	test: 0.226718

Epoch: 34
Loss: 0.09492393671670486
ROC train: 0.939418	val: 0.702441	test: 0.737378
PRC train: 0.631544	val: 0.220555	test: 0.186079

Epoch: 35
Loss: 0.09416550347991952
ROC train: 0.936212	val: 0.704242	test: 0.725298
PRC train: 0.619371	val: 0.229302	test: 0.220245

Epoch: 36
Loss: 0.0940653352112668
ROC train: 0.940606	val: 0.696300	test: 0.746826
PRC train: 0.639706	val: 0.201242	test: 0.203862

Epoch: 37
Loss: 0.09474626361061224
ROC train: 0.936348	val: 0.692652	test: 0.724883
PRC train: 0.618994	val: 0.205541	test: 0.210014

Epoch: 38
Loss: 0.09263715091181406
ROC train: 0.943829	val: 0.704828	test: 0.728912
PRC train: 0.649325	val: 0.225429	test: 0.212580

Epoch: 39
Loss: 0.09232464332369882
ROC train: 0.945315	val: 0.687335	test: 0.738442
PRC train: 0.650005	val: 0.200583	test: 0.178036

Epoch: 40
Loss: 0.092535745161991
ROC train: 0.944296	val: 0.689903	test: 0.707374
PRC train: 0.652968	val: 0.193558	test: 0.187223

Epoch: 41
Loss: 0.0914915727531624
ROC train: 0.948379	val: 0.698180	test: 0.730067
PRC train: 0.655897	val: 0.242656	test: 0.216411

Epoch: 42
Loss: 0.09130843978291872
ROC train: 0.946872	val: 0.694416	test: 0.738048
PRC train: 0.663024	val: 0.200922	test: 0.176576

Epoch: 43
Loss: 0.09235182916461178
ROC train: 0.941413	val: 0.689540	test: 0.716244
PRC train: 0.641638	val: 0.196273	test: 0.135716

Epoch: 44
Loss: 0.09249058539138391
ROC train: 0.950698	val: 0.710103	test: 0.735391
PRC train: 0.655313	val: 0.218112	test: 0.238579

Epoch: 45
Loss: 0.08943874344096624
ROC train: 0.948385	val: 0.703644	test: 0.716047
PRC train: 0.663684	val: 0.220947	test: 0.148887

Epoch: 46
Loss: 0.09019003758898649
ROC train: 0.951830	val: 0.696616	test: 0.736922
PRC train: 0.673787	val: 0.218988	test: 0.181246

Epoch: 47
Loss: 0.0883736258153424
ROC train: 0.953412	val: 0.695497	test: 0.731986
PRC train: 0.668675	val: 0.212067	test: 0.191351

Epoch: 48
Loss: 0.08871543612821235
ROC train: 0.953574	val: 0.710991	test: 0.750777
PRC train: 0.659740	val: 0.218733	test: 0.219842

Epoch: 49
Loss: 0.08862932241556286
ROC train: 0.942909	val: 0.680000	test: 0.721839
PRC train: 0.641499	val: 0.222437	test: 0.189550

Epoch: 50
Loss: 0.08775785093196682
ROC train: 0.956311	val: 0.704960	test: 0.742084
PRC train: 0.684781	val: 0.247497	test: 0.211562

Epoch: 51
Loss: 0.08711291784557948
ROC train: 0.955211	val: 0.693477	test: 0.735078
PRC train: 0.680202	val: 0.223409	test: 0.228895

Epoch: 52
Loss: 0.08626946286945497
ROC train: 0.960058	val: 0.699375	test: 0.731282
PRC train: 0.698337	val: 0.217039	test: 0.205583

Epoch: 53
Loss: 0.08695304188417395
ROC train: 0.954219	val: 0.692720	test: 0.727004
PRC train: 0.687701	val: 0.209940	test: 0.171202

Epoch: 54
Loss: 0.08614931621740203
ROC train: 0.957456	val: 0.685360	test: 0.715127
PRC train: 0.676103	val: 0.175898	test: 0.117695

Epoch: 55
Loss: 0.08572608470411543
ROC train: 0.958665	val: 0.697601	test: 0.731525
PRC train: 0.672004	val: 0.220372	test: 0.206269

Epoch: 56
Loss: 0.08495921398841784
ROC train: 0.960625	val: 0.707034	test: 0.745274
PRC train: 0.705729	val: 0.226902	test: 0.210256

Epoch: 57
Loss: 0.08358244960094043
ROC train: 0.963595	val: 0.700378	test: 0.736269
PRC train: 0.705985	val: 0.206869	test: 0.206802

Epoch: 58
Loss: 0.08541473704172216
ROC train: 0.965207	val: 0.700357	test: 0.741066
PRC train: 0.716403	val: 0.232816	test: 0.206346

Epoch: 59
Loss: 0.08384905818635328
ROC train: 0.965236	val: 0.692923	test: 0.735378
PRC train: 0.714328	val: 0.201572	test: 0.153394

Epoch: 60
Loss: 0.08433336440200309
ROC train: 0.964805	val: 0.698030	test: 0.739451
PRC train: 0.724855	val: 0.230764	test: 0.170860

Epoch: 61
Loss: 0.08266631726760737
ROC train: 0.967113	val: 0.701464	test: 0.743757
PRC train: 0.728466	val: 0.227716	test: 0.187395

Epoch: 62
Loss: 0.08383472327805559
ROC train: 0.955036	val: 0.693045	test: 0.733720
PRC train: 0.690866	val: 0.226863	test: 0.148032

Epoch: 63
Loss: 0.08330666146484439
ROC train: 0.968983	val: 0.701920	test: 0.737555
PRC train: 0.732833	val: 0.223062	test: 0.178647

Epoch: 64
Loss: 0.08213352964781048
ROC train: 0.962406	val: 0.701637	test: 0.735287
PRC train: 0.708307	val: 0.204574	test: 0.180899

Epoch: 65
Loss: 0.08103634624440814
ROC train: 0.968448	val: 0.702445	test: 0.741657
PRC train: 0.726792	val: 0.219291	test: 0.211390

Epoch: 66
Loss: 0.08043829625574689
ROC train: 0.969095	val: 0.694295	test: 0.740834
PRC train: 0.728033	val: 0.217318	test: 0.183823

Epoch: 67
Loss: 0.08015179829054994
ROC train: 0.970331	val: 0.698771	test: 0.746006
PRC train: 0.734212	val: 0.216263	test: 0.179308

Epoch: 68
Loss: 0.08213535295309549
ROC train: 0.968779	val: 0.706816	test: 0.755477
PRC train: 0.733738	val: 0.233964	test: 0.178160

Epoch: 69
Loss: 0.08211219403995065
ROC train: 0.971253	val: 0.695866	test: 0.737928
PRC train: 0.738223	val: 0.218908	test: 0.199483

Epoch: 70
Loss: 0.0772840843114036
ROC train: 0.973166	val: 0.705080	test: 0.740232
PRC train: 0.743848	val: 0.216971	test: 0.224565

Epoch: 71
Loss: 0.0808939946267766
ROC train: 0.970930	val: 0.707507	test: 0.744723
PRC train: 0.740923	val: 0.218851	test: 0.195799

Epoch: 72
Loss: 0.0786639233976964
ROC train: 0.973964	val: 0.703683	test: 0.754632
PRC train: 0.753016	val: 0.221284	test: 0.200207

Epoch: 73
Loss: 0.07845900255680045
ROC train: 0.974558	val: 0.710620	test: 0.753767
PRC train: 0.760864	val: 0.255543	test: 0.197057

Epoch: 74
Loss: 0.07690670315015279
ROC train: 0.976733	val: 0.703455	test: 0.744347
PRC train: 0.768820	val: 0.228855	test: 0.179382

Epoch: 75
Loss: 0.07690985189806276
ROC train: 0.974233	val: 0.693413	test: 0.737989
PRC train: 0.751218	val: 0.204111	test: 0.204445

Epoch: 76
Loss: 0.07854726181078715
ROC train: 0.971014	val: 0.693644	test: 0.730943
PRC train: 0.731877	val: 0.201090	test: 0.135580

Epoch: 77
Loss: 0.07645592179714268
ROC train: 0.976770	val: 0.707199	test: 0.752414
PRC train: 0.765158	val: 0.251444	test: 0.231430

Epoch: 78
Loss: 0.07696138555422607
ROC train: 0.973328	val: 0.689448	test: 0.757582
PRC train: 0.751674	val: 0.196711	test: 0.180323

Epoch: 79
Loss: 0.07633652003645919
ROC train: 0.978737	val: 0.702277	test: 0.763376
PRC train: 0.771955	val: 0.233894	test: 0.229751

Epoch: 80
Loss: 0.0749916694831341
ROC train: 0.975539	val: 0.701415	test: 0.741707
PRC train: 0.760927	val: 0.218184	test: 0.225817

Epoch: 81
Loss: 0.07696052694744115
ROC train: 0.977771	val: 0.697444	test: 0.759076
PRC train: 0.779271	val: 0.217366	test: 0.169697

Epoch: 82
Loss: 0.07621439866530193
ROC train: 0.978063	val: 0.709074	test: 0.760981
PRC train: 0.772574	val: 0.220552	test: 0.208245

Epoch: 83
Loss: 0.07579529370378549
ROC train: 0.978526	val: 0.701803	test: 0.749829
PRC train: 0.781607	val: 0.211142	test: 0.184477

Epoch: 84
Loss: 0.07190124168751724
ROC train: 0.978020	val: 0.699904	test: 0.751759
PRC train: 0.785056	val: 0.210015	test: 0.170367

Epoch: 85
Loss: 0.07413861514688272
ROC train: 0.975940	val: 0.707495	test: 0.743456
PRC train: 0.769860	val: 0.223958	test: 0.164784

Epoch: 86
Loss: 0.07578905204274144
ROC train: 0.981520	val: 0.709176	test: 0.757144
PRC train: 0.790476	val: 0.245206	test: 0.219822

Epoch: 87
Loss: 0.07248784510222117
ROC train: 0.979222	val: 0.701847	test: 0.745780
PRC train: 0.790330	val: 0.216363	test: 0.150908

Epoch: 88
Loss: 0.07301408405833534
ROC train: 0.979848	val: 0.700848	test: 0.755078
PRC train: 0.788378	val: 0.221167	test: 0.207402

Epoch: 89
Loss: 0.0729928314671679
ROC train: 0.980127	val: 0.698771	test: 0.753462
PRC train: 0.786808	val: 0.218040	test: 0.198602

Epoch: 90
Loss: 0.0710889776651989
ROC train: 0.979254	val: 0.707500	test: 0.739538
PRC train: 0.780110	val: 0.205431	test: 0.169931

Epoch: 91
Loss: 0.07385408662410689
ROC train: 0.979426	val: 0.689910	test: 0.740547
PRC train: 0.786362	val: 0.211363	test: 0.195363

Epoch: 92
Loss: 0.07321726482479986
ROC train: 0.978868	val: 0.690803	test: 0.744356
PRC train: 0.790957	val: 0.201436	test: 0.188786

Epoch: 93
Loss: 0.07188082123699922
ROC train: 0.981101	val: 0.703637	test: 0.757480
PRC train: 0.800808	val: 0.235204	test: 0.198836

Epoch: 94
Loss: 0.07178760069727844
ROC train: 0.933508	val: 0.707105	test: 0.736522
PRC train: 0.606638	val: 0.218412	test: 0.199641

Epoch: 34
Loss: 0.09637015356600354
ROC train: 0.935456	val: 0.712633	test: 0.739173
PRC train: 0.618037	val: 0.236297	test: 0.247848

Epoch: 35
Loss: 0.09657121513537192
ROC train: 0.936106	val: 0.703476	test: 0.741956
PRC train: 0.631234	val: 0.231578	test: 0.204024

Epoch: 36
Loss: 0.09522281501647199
ROC train: 0.940194	val: 0.699884	test: 0.732100
PRC train: 0.646136	val: 0.234616	test: 0.189034

Epoch: 37
Loss: 0.09330162442617414
ROC train: 0.942952	val: 0.707447	test: 0.746219
PRC train: 0.635175	val: 0.225528	test: 0.175967

Epoch: 38
Loss: 0.09392198444369722
ROC train: 0.944459	val: 0.716832	test: 0.753391
PRC train: 0.647589	val: 0.243160	test: 0.258389

Epoch: 39
Loss: 0.09331279728206401
ROC train: 0.942128	val: 0.713300	test: 0.747869
PRC train: 0.650038	val: 0.228696	test: 0.229132

Epoch: 40
Loss: 0.09212915769563321
ROC train: 0.943151	val: 0.707617	test: 0.737272
PRC train: 0.639428	val: 0.252676	test: 0.215377

Epoch: 41
Loss: 0.08974266833439269
ROC train: 0.949214	val: 0.715691	test: 0.739128
PRC train: 0.656356	val: 0.240508	test: 0.223451

Epoch: 42
Loss: 0.09194165853029734
ROC train: 0.946396	val: 0.708303	test: 0.740904
PRC train: 0.653057	val: 0.210869	test: 0.169032

Epoch: 43
Loss: 0.08868662500543678
ROC train: 0.949117	val: 0.700600	test: 0.733558
PRC train: 0.662173	val: 0.210616	test: 0.206028

Epoch: 44
Loss: 0.09137613149019361
ROC train: 0.942605	val: 0.707965	test: 0.729217
PRC train: 0.659809	val: 0.219304	test: 0.179824

Epoch: 45
Loss: 0.09018103125888358
ROC train: 0.951716	val: 0.704931	test: 0.735104
PRC train: 0.670880	val: 0.215163	test: 0.196114

Epoch: 46
Loss: 0.08860751113125186
ROC train: 0.948963	val: 0.699098	test: 0.718350
PRC train: 0.656307	val: 0.233438	test: 0.141957

Epoch: 47
Loss: 0.0894385965412504
ROC train: 0.949972	val: 0.706925	test: 0.741938
PRC train: 0.663733	val: 0.234215	test: 0.232736

Epoch: 48
Loss: 0.08950960244954541
ROC train: 0.953004	val: 0.710946	test: 0.744572
PRC train: 0.657780	val: 0.231787	test: 0.246059

Epoch: 49
Loss: 0.08902320198266225
ROC train: 0.956027	val: 0.706063	test: 0.736057
PRC train: 0.671584	val: 0.238668	test: 0.173279

Epoch: 50
Loss: 0.0874081871525471
ROC train: 0.951855	val: 0.713560	test: 0.750928
PRC train: 0.679980	val: 0.234639	test: 0.205225

Epoch: 51
Loss: 0.08692602590321619
ROC train: 0.953527	val: 0.694205	test: 0.729468
PRC train: 0.679121	val: 0.224322	test: 0.148668

Epoch: 52
Loss: 0.08707088485609837
ROC train: 0.956336	val: 0.693824	test: 0.726818
PRC train: 0.687494	val: 0.229358	test: 0.158558

Epoch: 53
Loss: 0.08572314421294434
ROC train: 0.959126	val: 0.700115	test: 0.747018
PRC train: 0.691075	val: 0.224856	test: 0.156481

Epoch: 54
Loss: 0.08522032848327388
ROC train: 0.956811	val: 0.699412	test: 0.731900
PRC train: 0.694219	val: 0.211214	test: 0.191075

Epoch: 55
Loss: 0.08602223006507277
ROC train: 0.955893	val: 0.701259	test: 0.725071
PRC train: 0.668487	val: 0.209736	test: 0.183459

Epoch: 56
Loss: 0.0869902711784923
ROC train: 0.962070	val: 0.712023	test: 0.744489
PRC train: 0.704783	val: 0.233353	test: 0.180487

Epoch: 57
Loss: 0.08524103422707646
ROC train: 0.957745	val: 0.705320	test: 0.747961
PRC train: 0.690830	val: 0.240716	test: 0.191406

Epoch: 58
Loss: 0.08466019132467277
ROC train: 0.961054	val: 0.701707	test: 0.731921
PRC train: 0.690582	val: 0.209017	test: 0.153976

Epoch: 59
Loss: 0.08559749696468345
ROC train: 0.959865	val: 0.699482	test: 0.709976
PRC train: 0.693249	val: 0.226311	test: 0.131692

Epoch: 60
Loss: 0.08407189650168553
ROC train: 0.958981	val: 0.695166	test: 0.742249
PRC train: 0.692538	val: 0.225399	test: 0.206665

Epoch: 61
Loss: 0.08333976549378619
ROC train: 0.964660	val: 0.706065	test: 0.738329
PRC train: 0.709051	val: 0.230995	test: 0.198419

Epoch: 62
Loss: 0.0821494875752666
ROC train: 0.959372	val: 0.688884	test: 0.724120
PRC train: 0.682763	val: 0.213544	test: 0.153918

Epoch: 63
Loss: 0.08177194057590755
ROC train: 0.964323	val: 0.696528	test: 0.750987
PRC train: 0.719751	val: 0.248026	test: 0.204610

Epoch: 64
Loss: 0.08185324736430753
ROC train: 0.964813	val: 0.708513	test: 0.745394
PRC train: 0.718970	val: 0.246620	test: 0.192255

Epoch: 65
Loss: 0.08016750041446409
ROC train: 0.962626	val: 0.689652	test: 0.727410
PRC train: 0.700410	val: 0.214836	test: 0.161904

Epoch: 66
Loss: 0.0807724137592858
ROC train: 0.970774	val: 0.699173	test: 0.747183
PRC train: 0.730007	val: 0.234440	test: 0.200512

Epoch: 67
Loss: 0.08037079830972925
ROC train: 0.966748	val: 0.703489	test: 0.738529
PRC train: 0.728421	val: 0.220814	test: 0.144207

Epoch: 68
Loss: 0.08103443751722121
ROC train: 0.968008	val: 0.692328	test: 0.740856
PRC train: 0.730011	val: 0.231777	test: 0.176939

Epoch: 69
Loss: 0.08067863411745141
ROC train: 0.969761	val: 0.712997	test: 0.736819
PRC train: 0.730683	val: 0.240625	test: 0.180160

Epoch: 70
Loss: 0.07966577999420656
ROC train: 0.971034	val: 0.710529	test: 0.735618
PRC train: 0.734516	val: 0.241092	test: 0.194555

Epoch: 71
Loss: 0.07940867021848368
ROC train: 0.969340	val: 0.699128	test: 0.739106
PRC train: 0.715770	val: 0.241173	test: 0.196616

Epoch: 72
Loss: 0.0783092707009318
ROC train: 0.975130	val: 0.701108	test: 0.739056
PRC train: 0.759843	val: 0.256417	test: 0.179541

Epoch: 73
Loss: 0.07828278699789312
ROC train: 0.970339	val: 0.697221	test: 0.747704
PRC train: 0.743453	val: 0.221394	test: 0.155369

Epoch: 74
Loss: 0.08115146286884913
ROC train: 0.972005	val: 0.695482	test: 0.744697
PRC train: 0.738495	val: 0.208004	test: 0.157259

Epoch: 75
Loss: 0.07784724323311079
ROC train: 0.972350	val: 0.702208	test: 0.746020
PRC train: 0.743883	val: 0.225227	test: 0.181177

Epoch: 76
Loss: 0.07702459135075053
ROC train: 0.975205	val: 0.715426	test: 0.741475
PRC train: 0.758500	val: 0.240260	test: 0.187219

Epoch: 77
Loss: 0.07804525592708919
ROC train: 0.976103	val: 0.701330	test: 0.755299
PRC train: 0.764627	val: 0.240958	test: 0.189736

Epoch: 78
Loss: 0.07431893875572003
ROC train: 0.977763	val: 0.711705	test: 0.753618
PRC train: 0.771105	val: 0.257789	test: 0.188902

Epoch: 79
Loss: 0.07570977816838352
ROC train: 0.976090	val: 0.709578	test: 0.746183
PRC train: 0.758908	val: 0.242315	test: 0.176328

Epoch: 80
Loss: 0.07634288875021127
ROC train: 0.976433	val: 0.699903	test: 0.729786
PRC train: 0.751158	val: 0.243040	test: 0.226009

Epoch: 81
Loss: 0.07642873158603636
ROC train: 0.977396	val: 0.705617	test: 0.740500
PRC train: 0.759421	val: 0.237151	test: 0.202046

Epoch: 82
Loss: 0.07674207049164468
ROC train: 0.974503	val: 0.693893	test: 0.727773
PRC train: 0.752788	val: 0.220515	test: 0.172903

Epoch: 83
Loss: 0.07501435172719682
ROC train: 0.979315	val: 0.696872	test: 0.741294
PRC train: 0.779603	val: 0.242461	test: 0.184475

Epoch: 84
Loss: 0.07487293301018308
ROC train: 0.978807	val: 0.699877	test: 0.764869
PRC train: 0.772796	val: 0.234141	test: 0.213266

Epoch: 85
Loss: 0.07506407576625096
ROC train: 0.976538	val: 0.699666	test: 0.748188
PRC train: 0.764020	val: 0.232715	test: 0.190979

Epoch: 86
Loss: 0.07430711699816166
ROC train: 0.978057	val: 0.706202	test: 0.752287
PRC train: 0.759160	val: 0.205756	test: 0.174595

Epoch: 87
Loss: 0.07168838846178431
ROC train: 0.979417	val: 0.703616	test: 0.740230
PRC train: 0.781073	val: 0.241065	test: 0.185772

Epoch: 88
Loss: 0.07470112003457074
ROC train: 0.981669	val: 0.697177	test: 0.734024
PRC train: 0.796287	val: 0.234771	test: 0.161137

Epoch: 89
Loss: 0.07205931885717874
ROC train: 0.979667	val: 0.700142	test: 0.723155
PRC train: 0.769093	val: 0.211834	test: 0.140117

Epoch: 90
Loss: 0.07123980113628797
ROC train: 0.980065	val: 0.692811	test: 0.744101
PRC train: 0.782354	val: 0.213336	test: 0.150744

Epoch: 91
Loss: 0.07316694212679746
ROC train: 0.981812	val: 0.711408	test: 0.752752
PRC train: 0.795000	val: 0.233992	test: 0.207925

Epoch: 92
Loss: 0.07191060999358413
ROC train: 0.979464	val: 0.699898	test: 0.733072
PRC train: 0.782595	val: 0.226127	test: 0.153279

Epoch: 93
Loss: 0.07177180081576462
ROC train: 0.979162	val: 0.719686	test: 0.745305
PRC train: 0.762385	val: 0.238936	test: 0.220628

ROC train: 0.934725	val: 0.708930	test: 0.742032
PRC train: 0.629609	val: 0.227957	test: 0.220310

Epoch: 34
Loss: 0.09489694157661563
ROC train: 0.937748	val: 0.703956	test: 0.722074
PRC train: 0.640508	val: 0.222386	test: 0.177567

Epoch: 35
Loss: 0.09441937744155435
ROC train: 0.943137	val: 0.705582	test: 0.724177
PRC train: 0.618108	val: 0.206138	test: 0.195840

Epoch: 36
Loss: 0.09387573252059588
ROC train: 0.943097	val: 0.716124	test: 0.738266
PRC train: 0.635326	val: 0.220398	test: 0.183332

Epoch: 37
Loss: 0.0948027800669982
ROC train: 0.941458	val: 0.720747	test: 0.746640
PRC train: 0.643369	val: 0.225078	test: 0.239132

Epoch: 38
Loss: 0.09293035772335315
ROC train: 0.944093	val: 0.703618	test: 0.743997
PRC train: 0.648508	val: 0.208369	test: 0.187737

Epoch: 39
Loss: 0.09466579482493437
ROC train: 0.936162	val: 0.703192	test: 0.745666
PRC train: 0.632447	val: 0.216317	test: 0.214672

Epoch: 40
Loss: 0.09183335328581815
ROC train: 0.948563	val: 0.716575	test: 0.744020
PRC train: 0.654428	val: 0.231636	test: 0.216845

Epoch: 41
Loss: 0.09298981082032133
ROC train: 0.946259	val: 0.704618	test: 0.751610
PRC train: 0.655214	val: 0.236858	test: 0.218463

Epoch: 42
Loss: 0.09094437729046721
ROC train: 0.942178	val: 0.709045	test: 0.712563
PRC train: 0.648587	val: 0.215533	test: 0.192174

Epoch: 43
Loss: 0.08775647680715064
ROC train: 0.947715	val: 0.703449	test: 0.723501
PRC train: 0.650369	val: 0.202115	test: 0.166686

Epoch: 44
Loss: 0.09180825691195638
ROC train: 0.946537	val: 0.707778	test: 0.740000
PRC train: 0.665663	val: 0.221455	test: 0.218083

Epoch: 45
Loss: 0.09106305540112071
ROC train: 0.954514	val: 0.704263	test: 0.738046
PRC train: 0.673507	val: 0.228568	test: 0.156107

Epoch: 46
Loss: 0.08851881251314393
ROC train: 0.955428	val: 0.708007	test: 0.745998
PRC train: 0.686658	val: 0.229618	test: 0.216417

Epoch: 47
Loss: 0.090011726721753
ROC train: 0.953431	val: 0.712957	test: 0.743860
PRC train: 0.669470	val: 0.205566	test: 0.220692

Epoch: 48
Loss: 0.08622430362143461
ROC train: 0.956079	val: 0.711841	test: 0.747256
PRC train: 0.691736	val: 0.222584	test: 0.169912

Epoch: 49
Loss: 0.08924195408502061
ROC train: 0.953593	val: 0.698595	test: 0.743888
PRC train: 0.673404	val: 0.213207	test: 0.175759

Epoch: 50
Loss: 0.0865597621564426
ROC train: 0.955775	val: 0.693112	test: 0.722495
PRC train: 0.691891	val: 0.207069	test: 0.159896

Epoch: 51
Loss: 0.08736021739844832
ROC train: 0.959278	val: 0.703288	test: 0.723989
PRC train: 0.692870	val: 0.240179	test: 0.206914

Epoch: 52
Loss: 0.08664502149207585
ROC train: 0.958365	val: 0.707642	test: 0.732022
PRC train: 0.694336	val: 0.210339	test: 0.195851

Epoch: 53
Loss: 0.08486084433073954
ROC train: 0.956001	val: 0.717973	test: 0.750294
PRC train: 0.684579	val: 0.229688	test: 0.236384

Epoch: 54
Loss: 0.084814495847256
ROC train: 0.960113	val: 0.699323	test: 0.749615
PRC train: 0.700587	val: 0.219702	test: 0.202500

Epoch: 55
Loss: 0.08611981893164576
ROC train: 0.961857	val: 0.695434	test: 0.733028
PRC train: 0.693914	val: 0.218062	test: 0.195484

Epoch: 56
Loss: 0.08546876410492595
ROC train: 0.962571	val: 0.702721	test: 0.736090
PRC train: 0.709803	val: 0.220566	test: 0.187779

Epoch: 57
Loss: 0.08441892984208424
ROC train: 0.967261	val: 0.708263	test: 0.738776
PRC train: 0.713626	val: 0.232598	test: 0.161815

Epoch: 58
Loss: 0.08385287486203531
ROC train: 0.962307	val: 0.693017	test: 0.728766
PRC train: 0.704541	val: 0.213064	test: 0.179316

Epoch: 59
Loss: 0.08308027847993255
ROC train: 0.963091	val: 0.703955	test: 0.734884
PRC train: 0.716251	val: 0.219061	test: 0.164720

Epoch: 60
Loss: 0.08308805605881299
ROC train: 0.964153	val: 0.715887	test: 0.747170
PRC train: 0.714759	val: 0.229552	test: 0.193745

Epoch: 61
Loss: 0.08263086382723595
ROC train: 0.964967	val: 0.702960	test: 0.750180
PRC train: 0.720687	val: 0.227561	test: 0.224005

Epoch: 62
Loss: 0.08509351600396875
ROC train: 0.967710	val: 0.709915	test: 0.745766
PRC train: 0.725789	val: 0.229009	test: 0.229606

Epoch: 63
Loss: 0.08251919065630442
ROC train: 0.970117	val: 0.713145	test: 0.741700
PRC train: 0.727609	val: 0.218704	test: 0.155382

Epoch: 64
Loss: 0.08131895433063899
ROC train: 0.969294	val: 0.711464	test: 0.730255
PRC train: 0.736655	val: 0.221538	test: 0.185737

Epoch: 65
Loss: 0.0792929818260264
ROC train: 0.969914	val: 0.699509	test: 0.733086
PRC train: 0.730214	val: 0.210773	test: 0.166597

Epoch: 66
Loss: 0.08061462066578987
ROC train: 0.968735	val: 0.709908	test: 0.749351
PRC train: 0.738346	val: 0.227657	test: 0.227460

Epoch: 67
Loss: 0.08156775377718624
ROC train: 0.971456	val: 0.716551	test: 0.748457
PRC train: 0.742426	val: 0.225382	test: 0.187268

Epoch: 68
Loss: 0.078823924784036
ROC train: 0.973145	val: 0.700017	test: 0.728532
PRC train: 0.754721	val: 0.228884	test: 0.190991

Epoch: 69
Loss: 0.07959340628860748
ROC train: 0.973011	val: 0.706469	test: 0.739346
PRC train: 0.744640	val: 0.225232	test: 0.150974

Epoch: 70
Loss: 0.0793962346101746
ROC train: 0.972518	val: 0.707677	test: 0.754574
PRC train: 0.747736	val: 0.214842	test: 0.186608

Epoch: 71
Loss: 0.07965041357434807
ROC train: 0.973675	val: 0.719632	test: 0.758081
PRC train: 0.742932	val: 0.234268	test: 0.220840

Epoch: 72
Loss: 0.08049590117601547
ROC train: 0.972747	val: 0.698216	test: 0.736449
PRC train: 0.755475	val: 0.233021	test: 0.189278

Epoch: 73
Loss: 0.07663090575279603
ROC train: 0.973974	val: 0.708423	test: 0.741390
PRC train: 0.750251	val: 0.239989	test: 0.157483

Epoch: 74
Loss: 0.07790256630233702
ROC train: 0.975306	val: 0.711423	test: 0.744578
PRC train: 0.751617	val: 0.218950	test: 0.192161

Epoch: 75
Loss: 0.07611259825063013
ROC train: 0.975123	val: 0.708935	test: 0.750434
PRC train: 0.761200	val: 0.236159	test: 0.176058

Epoch: 76
Loss: 0.07666574379250723
ROC train: 0.975366	val: 0.710317	test: 0.752372
PRC train: 0.766308	val: 0.244184	test: 0.210546

Epoch: 77
Loss: 0.07536686570458048
ROC train: 0.975875	val: 0.719187	test: 0.752106
PRC train: 0.759484	val: 0.238694	test: 0.170329

Epoch: 78
Loss: 0.0773387379549011
ROC train: 0.976330	val: 0.706019	test: 0.748518
PRC train: 0.763911	val: 0.221832	test: 0.156702

Epoch: 79
Loss: 0.07833988482926219
ROC train: 0.974415	val: 0.688198	test: 0.740743
PRC train: 0.746246	val: 0.200006	test: 0.156032

Epoch: 80
Loss: 0.07536042527415757
ROC train: 0.976615	val: 0.707660	test: 0.760410
PRC train: 0.769279	val: 0.223251	test: 0.195631

Epoch: 81
Loss: 0.07380710687197749
ROC train: 0.977096	val: 0.710310	test: 0.758264
PRC train: 0.781100	val: 0.223597	test: 0.171889

Epoch: 82
Loss: 0.07464203649917847
ROC train: 0.976742	val: 0.702254	test: 0.740561
PRC train: 0.762930	val: 0.219407	test: 0.220276

Epoch: 83
Loss: 0.07360544151442876
ROC train: 0.975327	val: 0.702954	test: 0.732888
PRC train: 0.778885	val: 0.220119	test: 0.183147

Epoch: 84
Loss: 0.07328452128352164
ROC train: 0.974877	val: 0.687878	test: 0.739820
PRC train: 0.761732	val: 0.222610	test: 0.181481

Epoch: 85
Loss: 0.07455535876406315
ROC train: 0.980349	val: 0.704445	test: 0.741751
PRC train: 0.788086	val: 0.214309	test: 0.167231

Epoch: 86
Loss: 0.07272494591363804
ROC train: 0.981462	val: 0.704793	test: 0.744108
PRC train: 0.796293	val: 0.226888	test: 0.159678

Epoch: 87
Loss: 0.07200918739287474
ROC train: 0.980420	val: 0.699328	test: 0.753623
PRC train: 0.789250	val: 0.227014	test: 0.183827

Epoch: 88
Loss: 0.07202650202517354
ROC train: 0.980632	val: 0.705354	test: 0.750713
PRC train: 0.792056	val: 0.228246	test: 0.190871

Epoch: 89
Loss: 0.07438309266392173
ROC train: 0.976392	val: 0.685434	test: 0.740435
PRC train: 0.763286	val: 0.204832	test: 0.174829

Epoch: 90
Loss: 0.07316567674384544
ROC train: 0.982164	val: 0.696642	test: 0.739645
PRC train: 0.803548	val: 0.233615	test: 0.156040

Epoch: 91
Loss: 0.07201846632151028
ROC train: 0.981592	val: 0.703633	test: 0.736089
PRC train: 0.793042	val: 0.214627	test: 0.154847

Epoch: 92
Loss: 0.07145702590274386
ROC train: 0.983834	val: 0.701780	test: 0.759243
PRC train: 0.803339	val: 0.238722	test: 0.197598

Epoch: 93
Loss: 0.07186651074510066
ROC train: 0.983943	val: 0.701809	test: 0.757526
PRC train: 0.809483	val: 0.221946	test: 0.168811

Epoch: 94
Loss: 0.06994755860852273
ROC train: 0.926161	val: 0.710340	test: 0.749491
PRC train: 0.602115	val: 0.285814	test: 0.151627

Epoch: 34
Loss: 0.09845096262081653
ROC train: 0.934350	val: 0.706254	test: 0.741371
PRC train: 0.602812	val: 0.259387	test: 0.141879

Epoch: 35
Loss: 0.10025315336947228
ROC train: 0.929616	val: 0.701958	test: 0.744228
PRC train: 0.600426	val: 0.289772	test: 0.177067

Epoch: 36
Loss: 0.09904231065628492
ROC train: 0.931360	val: 0.708857	test: 0.749485
PRC train: 0.614736	val: 0.306842	test: 0.167802

Epoch: 37
Loss: 0.0974840190038515
ROC train: 0.933650	val: 0.708277	test: 0.739497
PRC train: 0.619760	val: 0.283247	test: 0.183294

Epoch: 38
Loss: 0.09678622453502837
ROC train: 0.935159	val: 0.721095	test: 0.737867
PRC train: 0.609949	val: 0.303064	test: 0.172576

Epoch: 39
Loss: 0.09623941605500337
ROC train: 0.940432	val: 0.712925	test: 0.758791
PRC train: 0.641762	val: 0.293889	test: 0.149781

Epoch: 40
Loss: 0.09740273395170435
ROC train: 0.937593	val: 0.713861	test: 0.741761
PRC train: 0.632640	val: 0.266336	test: 0.120142

Epoch: 41
Loss: 0.0959144311370044
ROC train: 0.935441	val: 0.709820	test: 0.742812
PRC train: 0.616506	val: 0.303642	test: 0.136739

Epoch: 42
Loss: 0.0954208269679836
ROC train: 0.938636	val: 0.724425	test: 0.756976
PRC train: 0.629584	val: 0.274791	test: 0.148764

Epoch: 43
Loss: 0.0939601305593398
ROC train: 0.939740	val: 0.701001	test: 0.728711
PRC train: 0.629584	val: 0.263115	test: 0.152001

Epoch: 44
Loss: 0.09426551848776839
ROC train: 0.939645	val: 0.717492	test: 0.760406
PRC train: 0.621791	val: 0.295820	test: 0.198350

Epoch: 45
Loss: 0.09303486817320625
ROC train: 0.943766	val: 0.724128	test: 0.754490
PRC train: 0.643111	val: 0.280952	test: 0.148736

Epoch: 46
Loss: 0.09186714777082262
ROC train: 0.937688	val: 0.715843	test: 0.745271
PRC train: 0.606713	val: 0.262073	test: 0.156868

Epoch: 47
Loss: 0.09553593994526757
ROC train: 0.945293	val: 0.721174	test: 0.755278
PRC train: 0.656147	val: 0.285350	test: 0.184464

Epoch: 48
Loss: 0.09236988146185393
ROC train: 0.945072	val: 0.722830	test: 0.749947
PRC train: 0.631078	val: 0.292673	test: 0.155458

Epoch: 49
Loss: 0.09159128178775537
ROC train: 0.952868	val: 0.717406	test: 0.746723
PRC train: 0.671508	val: 0.291328	test: 0.180603

Epoch: 50
Loss: 0.09016806394953207
ROC train: 0.944636	val: 0.694758	test: 0.727302
PRC train: 0.641426	val: 0.250246	test: 0.107634

Epoch: 51
Loss: 0.09078367557924757
ROC train: 0.947351	val: 0.719606	test: 0.737180
PRC train: 0.645289	val: 0.244632	test: 0.105936

Epoch: 52
Loss: 0.09007633989171893
ROC train: 0.955827	val: 0.718797	test: 0.747341
PRC train: 0.685069	val: 0.265727	test: 0.151697

Epoch: 53
Loss: 0.09030177548523173
ROC train: 0.951747	val: 0.703729	test: 0.755627
PRC train: 0.674912	val: 0.260677	test: 0.136596

Epoch: 54
Loss: 0.0895087666865488
ROC train: 0.953889	val: 0.700018	test: 0.732352
PRC train: 0.675550	val: 0.249104	test: 0.113082

Epoch: 55
Loss: 0.08920768569256889
ROC train: 0.949642	val: 0.722003	test: 0.749311
PRC train: 0.666416	val: 0.273279	test: 0.168277

Epoch: 56
Loss: 0.08896869773996109
ROC train: 0.952808	val: 0.722279	test: 0.751394
PRC train: 0.679013	val: 0.301255	test: 0.173993

Epoch: 57
Loss: 0.08951719053464358
ROC train: 0.957404	val: 0.718582	test: 0.741323
PRC train: 0.681171	val: 0.280187	test: 0.168435

Epoch: 58
Loss: 0.08754635604545657
ROC train: 0.953940	val: 0.714744	test: 0.744345
PRC train: 0.678327	val: 0.277688	test: 0.179902

Epoch: 59
Loss: 0.08721093878767237
ROC train: 0.960804	val: 0.725135	test: 0.755766
PRC train: 0.682996	val: 0.297693	test: 0.175797

Epoch: 60
Loss: 0.08602753370439589
ROC train: 0.960110	val: 0.729200	test: 0.747927
PRC train: 0.691979	val: 0.263586	test: 0.134733

Epoch: 61
Loss: 0.08541706394734755
ROC train: 0.956843	val: 0.726603	test: 0.748799
PRC train: 0.684512	val: 0.251905	test: 0.121963

Epoch: 62
Loss: 0.08584130594355845
ROC train: 0.950793	val: 0.720626	test: 0.750592
PRC train: 0.646580	val: 0.257216	test: 0.173092

Epoch: 63
Loss: 0.08532611918640749
ROC train: 0.963727	val: 0.717123	test: 0.745101
PRC train: 0.712144	val: 0.254424	test: 0.163471

Epoch: 64
Loss: 0.08538998311335688
ROC train: 0.958310	val: 0.722059	test: 0.746976
PRC train: 0.685730	val: 0.267988	test: 0.150007

Epoch: 65
Loss: 0.08465973969111039
ROC train: 0.959191	val: 0.710269	test: 0.752834
PRC train: 0.689230	val: 0.251085	test: 0.129182

Epoch: 66
Loss: 0.08617314727001028
ROC train: 0.965332	val: 0.712153	test: 0.745735
PRC train: 0.709915	val: 0.261684	test: 0.143959

Epoch: 67
Loss: 0.08516533272026665
ROC train: 0.964431	val: 0.710471	test: 0.730918
PRC train: 0.708242	val: 0.248251	test: 0.125582

Epoch: 68
Loss: 0.08293963496924969
ROC train: 0.962961	val: 0.705118	test: 0.738780
PRC train: 0.693632	val: 0.230087	test: 0.099655

Epoch: 69
Loss: 0.08368320376001567
ROC train: 0.965817	val: 0.717997	test: 0.746128
PRC train: 0.711639	val: 0.279716	test: 0.149469

Epoch: 70
Loss: 0.08270668590334544
ROC train: 0.969448	val: 0.729655	test: 0.744652
PRC train: 0.726001	val: 0.272977	test: 0.142583

Epoch: 71
Loss: 0.08200780254924746
ROC train: 0.966612	val: 0.717898	test: 0.745662
PRC train: 0.724849	val: 0.276467	test: 0.145484

Epoch: 72
Loss: 0.08211518489774149
ROC train: 0.964725	val: 0.718522	test: 0.740064
PRC train: 0.703565	val: 0.297429	test: 0.179963

Epoch: 73
Loss: 0.08231779873391411
ROC train: 0.965830	val: 0.725460	test: 0.753608
PRC train: 0.710888	val: 0.273597	test: 0.172146

Epoch: 74
Loss: 0.08108590061195314
ROC train: 0.969047	val: 0.726502	test: 0.754989
PRC train: 0.731352	val: 0.290843	test: 0.163054

Epoch: 75
Loss: 0.08105232747044912
ROC train: 0.972599	val: 0.729635	test: 0.759761
PRC train: 0.747372	val: 0.263823	test: 0.123540

Epoch: 76
Loss: 0.08058615873602548
ROC train: 0.968535	val: 0.720970	test: 0.749462
PRC train: 0.730311	val: 0.280556	test: 0.146152

Epoch: 77
Loss: 0.07864613097898027
ROC train: 0.971990	val: 0.722036	test: 0.757355
PRC train: 0.736579	val: 0.264900	test: 0.132827

Epoch: 78
Loss: 0.08013118665241702
ROC train: 0.968968	val: 0.713458	test: 0.754091
PRC train: 0.733490	val: 0.247885	test: 0.136958

Epoch: 79
Loss: 0.07998771173572691
ROC train: 0.970558	val: 0.715361	test: 0.735960
PRC train: 0.725168	val: 0.226795	test: 0.088099

Epoch: 80
Loss: 0.07716993080653714
ROC train: 0.967903	val: 0.718553	test: 0.760639
PRC train: 0.696677	val: 0.249948	test: 0.160480

Epoch: 81
Loss: 0.08027628012427254
ROC train: 0.972823	val: 0.725027	test: 0.749132
PRC train: 0.746512	val: 0.280144	test: 0.165590

Epoch: 82
Loss: 0.0787008433213779
ROC train: 0.973491	val: 0.720498	test: 0.748341
PRC train: 0.752001	val: 0.226898	test: 0.119640

Epoch: 83
Loss: 0.07838189686163147
ROC train: 0.973233	val: 0.733529	test: 0.739092
PRC train: 0.750764	val: 0.282029	test: 0.122718

Epoch: 84
Loss: 0.07785804965182684
ROC train: 0.972886	val: 0.722536	test: 0.740669
PRC train: 0.733490	val: 0.275543	test: 0.159716

Epoch: 85
Loss: 0.07782998688298588
ROC train: 0.972907	val: 0.713576	test: 0.745444
PRC train: 0.741302	val: 0.266654	test: 0.123808

Epoch: 86
Loss: 0.07773864520641721
ROC train: 0.975742	val: 0.721401	test: 0.751260
PRC train: 0.763538	val: 0.260001	test: 0.122406

Epoch: 87
Loss: 0.07416473312572208
ROC train: 0.974952	val: 0.730393	test: 0.758763
PRC train: 0.759483	val: 0.292230	test: 0.164309

Epoch: 88
Loss: 0.0766627134091197
ROC train: 0.971543	val: 0.706861	test: 0.753409
PRC train: 0.749244	val: 0.259740	test: 0.144552

Epoch: 89
Loss: 0.07469787740227946
ROC train: 0.977247	val: 0.715070	test: 0.750794
PRC train: 0.776923	val: 0.263403	test: 0.140839

Epoch: 90
Loss: 0.07513320882412163
ROC train: 0.976807	val: 0.726329	test: 0.754002
PRC train: 0.774658	val: 0.263458	test: 0.153989

Epoch: 91
Loss: 0.07530314315290952
ROC train: 0.977400	val: 0.711926	test: 0.749994
PRC train: 0.774582	val: 0.263697	test: 0.148117

Epoch: 92
Loss: 0.07575864768293601
ROC train: 0.978912	val: 0.713542	test: 0.750391
PRC train: 0.776856	val: 0.247261	test: 0.136776

Epoch: 93
Loss: 0.07467675189398036
ROC train: 0.979932	val: 0.714911	test: 0.741405
PRC train: 0.787251	val: 0.260367	test: 0.130347


ROC train: 0.921079	val: 0.701028	test: 0.750434
PRC train: 0.576040	val: 0.277689	test: 0.184782

Epoch: 34
Loss: 0.10018913786952205
ROC train: 0.925219	val: 0.714421	test: 0.739597
PRC train: 0.580394	val: 0.265027	test: 0.197570

Epoch: 35
Loss: 0.09695585839088328
ROC train: 0.932082	val: 0.715094	test: 0.743367
PRC train: 0.610060	val: 0.261681	test: 0.185081

Epoch: 36
Loss: 0.09883293666551103
ROC train: 0.928477	val: 0.699185	test: 0.729965
PRC train: 0.605515	val: 0.259648	test: 0.136523

Epoch: 37
Loss: 0.09895342986208455
ROC train: 0.933999	val: 0.711892	test: 0.748705
PRC train: 0.614461	val: 0.279346	test: 0.184879

Epoch: 38
Loss: 0.09555913139174319
ROC train: 0.936343	val: 0.705893	test: 0.724208
PRC train: 0.614924	val: 0.260628	test: 0.121710

Epoch: 39
Loss: 0.09698435140138273
ROC train: 0.937971	val: 0.712189	test: 0.730396
PRC train: 0.633627	val: 0.283939	test: 0.164027

Epoch: 40
Loss: 0.09642206558608915
ROC train: 0.939686	val: 0.712302	test: 0.750506
PRC train: 0.641106	val: 0.295074	test: 0.177946

Epoch: 41
Loss: 0.09635213837622474
ROC train: 0.936916	val: 0.700868	test: 0.742946
PRC train: 0.615839	val: 0.216933	test: 0.091277

Epoch: 42
Loss: 0.09548895687469326
ROC train: 0.942862	val: 0.704436	test: 0.747790
PRC train: 0.645517	val: 0.271172	test: 0.155451

Epoch: 43
Loss: 0.09566963622531645
ROC train: 0.941953	val: 0.702429	test: 0.739812
PRC train: 0.636439	val: 0.252858	test: 0.116505

Epoch: 44
Loss: 0.0945785682824962
ROC train: 0.942032	val: 0.711050	test: 0.742229
PRC train: 0.642049	val: 0.267553	test: 0.172391

Epoch: 45
Loss: 0.09329439083281355
ROC train: 0.945103	val: 0.704595	test: 0.729921
PRC train: 0.652034	val: 0.273254	test: 0.167195

Epoch: 46
Loss: 0.0923258383489584
ROC train: 0.944371	val: 0.707103	test: 0.728656
PRC train: 0.624591	val: 0.238829	test: 0.111131

Epoch: 47
Loss: 0.09308631481115494
ROC train: 0.946942	val: 0.720023	test: 0.751553
PRC train: 0.662443	val: 0.268474	test: 0.144719

Epoch: 48
Loss: 0.0923229880861016
ROC train: 0.951175	val: 0.716934	test: 0.745056
PRC train: 0.665097	val: 0.281648	test: 0.184190

Epoch: 49
Loss: 0.09169005152765503
ROC train: 0.951335	val: 0.698710	test: 0.744855
PRC train: 0.669935	val: 0.269046	test: 0.181548

Epoch: 50
Loss: 0.09201464959783294
ROC train: 0.950886	val: 0.708867	test: 0.744827
PRC train: 0.664109	val: 0.265628	test: 0.173882

Epoch: 51
Loss: 0.09030489014790291
ROC train: 0.953078	val: 0.708972	test: 0.743092
PRC train: 0.660465	val: 0.285791	test: 0.208128

Epoch: 52
Loss: 0.09167619394454792
ROC train: 0.942759	val: 0.702478	test: 0.728403
PRC train: 0.649386	val: 0.265229	test: 0.121885

Epoch: 53
Loss: 0.08915955506604081
ROC train: 0.948888	val: 0.721711	test: 0.741372
PRC train: 0.661863	val: 0.257454	test: 0.186416

Epoch: 54
Loss: 0.08933221834637466
ROC train: 0.948860	val: 0.694053	test: 0.731411
PRC train: 0.653283	val: 0.264676	test: 0.126287

Epoch: 55
Loss: 0.08721858322217066
ROC train: 0.952616	val: 0.716368	test: 0.736776
PRC train: 0.665478	val: 0.239113	test: 0.135744

Epoch: 56
Loss: 0.08881439809769212
ROC train: 0.956230	val: 0.696083	test: 0.725481
PRC train: 0.675281	val: 0.238941	test: 0.117712

Epoch: 57
Loss: 0.08889607969751656
ROC train: 0.955771	val: 0.709936	test: 0.738084
PRC train: 0.683849	val: 0.250176	test: 0.120240

Epoch: 58
Loss: 0.08818327420569932
ROC train: 0.956580	val: 0.699353	test: 0.749942
PRC train: 0.694065	val: 0.262922	test: 0.142675

Epoch: 59
Loss: 0.08721133242358496
ROC train: 0.958950	val: 0.702104	test: 0.739394
PRC train: 0.686780	val: 0.262109	test: 0.130936

Epoch: 60
Loss: 0.08643725450382564
ROC train: 0.961976	val: 0.714952	test: 0.748427
PRC train: 0.703545	val: 0.273375	test: 0.137687

Epoch: 61
Loss: 0.08507143928384973
ROC train: 0.958131	val: 0.698094	test: 0.742486
PRC train: 0.691515	val: 0.230969	test: 0.119527

Epoch: 62
Loss: 0.08505549962131523
ROC train: 0.960950	val: 0.706041	test: 0.757675
PRC train: 0.704384	val: 0.255167	test: 0.133690

Epoch: 63
Loss: 0.08485399159018389
ROC train: 0.962040	val: 0.719715	test: 0.747827
PRC train: 0.695827	val: 0.292577	test: 0.202092

Epoch: 64
Loss: 0.0847717557366646
ROC train: 0.962094	val: 0.719908	test: 0.735085
PRC train: 0.706639	val: 0.258622	test: 0.144246

Epoch: 65
Loss: 0.08441391435312333
ROC train: 0.957672	val: 0.702949	test: 0.732000
PRC train: 0.681532	val: 0.247404	test: 0.128168

Epoch: 66
Loss: 0.08353228179936126
ROC train: 0.966357	val: 0.713633	test: 0.743062
PRC train: 0.724513	val: 0.261627	test: 0.149901

Epoch: 67
Loss: 0.08349574511637532
ROC train: 0.963063	val: 0.711560	test: 0.749114
PRC train: 0.711490	val: 0.262851	test: 0.140307

Epoch: 68
Loss: 0.083566156273379
ROC train: 0.966917	val: 0.702426	test: 0.733013
PRC train: 0.725058	val: 0.236509	test: 0.140643

Epoch: 69
Loss: 0.08234858557024909
ROC train: 0.964582	val: 0.704968	test: 0.752754
PRC train: 0.717163	val: 0.272462	test: 0.128904

Epoch: 70
Loss: 0.08327126829256515
ROC train: 0.968381	val: 0.709867	test: 0.741346
PRC train: 0.729192	val: 0.260476	test: 0.147592

Epoch: 71
Loss: 0.08434940530623855
ROC train: 0.967860	val: 0.721842	test: 0.757945
PRC train: 0.726859	val: 0.263203	test: 0.163256

Epoch: 72
Loss: 0.08522997222610011
ROC train: 0.967411	val: 0.718717	test: 0.746469
PRC train: 0.720548	val: 0.255865	test: 0.135007

Epoch: 73
Loss: 0.08105954973320903
ROC train: 0.968252	val: 0.715307	test: 0.743315
PRC train: 0.715879	val: 0.272105	test: 0.187359

Epoch: 74
Loss: 0.0824714348885155
ROC train: 0.969836	val: 0.706581	test: 0.722029
PRC train: 0.724057	val: 0.234761	test: 0.096091

Epoch: 75
Loss: 0.08082558728200415
ROC train: 0.969739	val: 0.708370	test: 0.752182
PRC train: 0.737495	val: 0.258061	test: 0.145479

Epoch: 76
Loss: 0.07960968460756954
ROC train: 0.969364	val: 0.707139	test: 0.736079
PRC train: 0.738667	val: 0.269219	test: 0.135240

Epoch: 77
Loss: 0.08002781848026443
ROC train: 0.971252	val: 0.719439	test: 0.763055
PRC train: 0.740815	val: 0.263459	test: 0.167930

Epoch: 78
Loss: 0.07982829981004495
ROC train: 0.972837	val: 0.710411	test: 0.744058
PRC train: 0.750299	val: 0.262262	test: 0.129564

Epoch: 79
Loss: 0.07882600710628153
ROC train: 0.966982	val: 0.703504	test: 0.746945
PRC train: 0.723055	val: 0.291588	test: 0.198315

Epoch: 80
Loss: 0.07893527980194319
ROC train: 0.973815	val: 0.690943	test: 0.755308
PRC train: 0.743019	val: 0.261712	test: 0.138251

Epoch: 81
Loss: 0.07846938041405571
ROC train: 0.970059	val: 0.710158	test: 0.745755
PRC train: 0.728056	val: 0.244183	test: 0.129776

Epoch: 82
Loss: 0.07825623803400188
ROC train: 0.970855	val: 0.710908	test: 0.733229
PRC train: 0.746844	val: 0.252560	test: 0.162124

Epoch: 83
Loss: 0.07745202434672409
ROC train: 0.974197	val: 0.718536	test: 0.753186
PRC train: 0.755512	val: 0.263523	test: 0.146050

Epoch: 84
Loss: 0.07802177734034196
ROC train: 0.976762	val: 0.709695	test: 0.750749
PRC train: 0.763960	val: 0.300103	test: 0.199525

Epoch: 85
Loss: 0.07733544990637509
ROC train: 0.973784	val: 0.702840	test: 0.751020
PRC train: 0.754474	val: 0.274692	test: 0.170479

Epoch: 86
Loss: 0.07622723272799874
ROC train: 0.975884	val: 0.719016	test: 0.755552
PRC train: 0.762369	val: 0.275432	test: 0.192622

Epoch: 87
Loss: 0.0772464025071552
ROC train: 0.975143	val: 0.722359	test: 0.726449
PRC train: 0.754093	val: 0.254815	test: 0.121026

Epoch: 88
Loss: 0.07515415668378583
ROC train: 0.974762	val: 0.724308	test: 0.762058
PRC train: 0.757014	val: 0.274165	test: 0.148363

Epoch: 89
Loss: 0.07680480951570182
ROC train: 0.976945	val: 0.721726	test: 0.740300
PRC train: 0.768171	val: 0.286325	test: 0.176242

Epoch: 90
Loss: 0.07821800954554893
ROC train: 0.979308	val: 0.709151	test: 0.731824
PRC train: 0.781376	val: 0.260553	test: 0.149312

Epoch: 91
Loss: 0.07520544945229232
ROC train: 0.977135	val: 0.714200	test: 0.759333
PRC train: 0.770997	val: 0.261538	test: 0.125568

Epoch: 92
Loss: 0.07422896919064302
ROC train: 0.978167	val: 0.717871	test: 0.743619
PRC train: 0.773305	val: 0.234831	test: 0.133155

Epoch: 93
Loss: 0.07506534294917327
ROC train: 0.979126	val: 0.711829	test: 0.742754
PRC train: 0.783467	val: 0.281219	test: 0.139775

Epoch: 94
Loss: 0.07488438092453746
ROC train: 0.925649	val: 0.698291	test: 0.746058
PRC train: 0.581412	val: 0.250150	test: 0.195830

Epoch: 34
Loss: 0.10086329624436323
ROC train: 0.928012	val: 0.708702	test: 0.750606
PRC train: 0.603434	val: 0.279381	test: 0.176733

Epoch: 35
Loss: 0.09850716699750425
ROC train: 0.928373	val: 0.706991	test: 0.736420
PRC train: 0.604817	val: 0.265920	test: 0.160064

Epoch: 36
Loss: 0.09822637059326508
ROC train: 0.935013	val: 0.713910	test: 0.741575
PRC train: 0.615646	val: 0.260445	test: 0.167041

Epoch: 37
Loss: 0.09640160955711509
ROC train: 0.930105	val: 0.708354	test: 0.744068
PRC train: 0.614506	val: 0.292417	test: 0.203064

Epoch: 38
Loss: 0.09866307767114224
ROC train: 0.935064	val: 0.723653	test: 0.752931
PRC train: 0.623023	val: 0.264633	test: 0.137539

Epoch: 39
Loss: 0.09652601925788586
ROC train: 0.940512	val: 0.718458	test: 0.742685
PRC train: 0.624428	val: 0.277170	test: 0.178596

Epoch: 40
Loss: 0.0973095333438332
ROC train: 0.938114	val: 0.715939	test: 0.722492
PRC train: 0.622209	val: 0.298611	test: 0.175355

Epoch: 41
Loss: 0.09491037043741148
ROC train: 0.939061	val: 0.717212	test: 0.736891
PRC train: 0.626666	val: 0.269589	test: 0.173189

Epoch: 42
Loss: 0.09638882993290691
ROC train: 0.939134	val: 0.732299	test: 0.730424
PRC train: 0.633229	val: 0.246460	test: 0.134495

Epoch: 43
Loss: 0.09400710235568825
ROC train: 0.941656	val: 0.712303	test: 0.727855
PRC train: 0.634131	val: 0.267718	test: 0.148236

Epoch: 44
Loss: 0.09448359933489538
ROC train: 0.941881	val: 0.717174	test: 0.735389
PRC train: 0.621336	val: 0.285720	test: 0.203829

Epoch: 45
Loss: 0.09320516427894544
ROC train: 0.945450	val: 0.722399	test: 0.725040
PRC train: 0.646495	val: 0.266347	test: 0.166924

Epoch: 46
Loss: 0.09427276006246939
ROC train: 0.948795	val: 0.732427	test: 0.740105
PRC train: 0.661061	val: 0.265700	test: 0.150897

Epoch: 47
Loss: 0.09208345492518805
ROC train: 0.946872	val: 0.724101	test: 0.746623
PRC train: 0.628112	val: 0.284711	test: 0.190836

Epoch: 48
Loss: 0.09184023844678744
ROC train: 0.946728	val: 0.725518	test: 0.733795
PRC train: 0.646291	val: 0.277567	test: 0.152417

Epoch: 49
Loss: 0.09088528515207615
ROC train: 0.950456	val: 0.714212	test: 0.739745
PRC train: 0.660467	val: 0.239583	test: 0.143419

Epoch: 50
Loss: 0.09211443948407758
ROC train: 0.953260	val: 0.709089	test: 0.739967
PRC train: 0.662873	val: 0.279068	test: 0.157051

Epoch: 51
Loss: 0.09141587162903263
ROC train: 0.948092	val: 0.718097	test: 0.741242
PRC train: 0.656686	val: 0.256228	test: 0.153060

Epoch: 52
Loss: 0.09092148677132411
ROC train: 0.952788	val: 0.715686	test: 0.746597
PRC train: 0.663144	val: 0.286389	test: 0.152681

Epoch: 53
Loss: 0.08947006775408203
ROC train: 0.951436	val: 0.709587	test: 0.730130
PRC train: 0.662763	val: 0.250060	test: 0.131155

Epoch: 54
Loss: 0.0901657907765071
ROC train: 0.956607	val: 0.724212	test: 0.750201
PRC train: 0.683110	val: 0.280053	test: 0.147103

Epoch: 55
Loss: 0.08716159980039187
ROC train: 0.959738	val: 0.705240	test: 0.751605
PRC train: 0.675456	val: 0.265633	test: 0.168664

Epoch: 56
Loss: 0.08787294205974164
ROC train: 0.951220	val: 0.715524	test: 0.760659
PRC train: 0.676118	val: 0.292108	test: 0.183039

Epoch: 57
Loss: 0.08826861706766882
ROC train: 0.958595	val: 0.711614	test: 0.736680
PRC train: 0.679137	val: 0.294345	test: 0.160340

Epoch: 58
Loss: 0.08753749185009486
ROC train: 0.956362	val: 0.703508	test: 0.740627
PRC train: 0.668915	val: 0.271493	test: 0.173868

Epoch: 59
Loss: 0.08780545759249626
ROC train: 0.957994	val: 0.709170	test: 0.747152
PRC train: 0.677722	val: 0.271048	test: 0.174679

Epoch: 60
Loss: 0.08639678547634329
ROC train: 0.960189	val: 0.726837	test: 0.744837
PRC train: 0.694295	val: 0.256629	test: 0.121213

Epoch: 61
Loss: 0.08694938754480694
ROC train: 0.962105	val: 0.707700	test: 0.740923
PRC train: 0.701638	val: 0.249388	test: 0.140143

Epoch: 62
Loss: 0.08836108252316492
ROC train: 0.961413	val: 0.720372	test: 0.754156
PRC train: 0.697021	val: 0.285267	test: 0.172032

Epoch: 63
Loss: 0.0839883975565726
ROC train: 0.964191	val: 0.715777	test: 0.740614
PRC train: 0.707963	val: 0.278038	test: 0.153353

Epoch: 64
Loss: 0.08477744552290829
ROC train: 0.961326	val: 0.707410	test: 0.762193
PRC train: 0.698309	val: 0.265391	test: 0.161817

Epoch: 65
Loss: 0.08390113584991903
ROC train: 0.967094	val: 0.711350	test: 0.745011
PRC train: 0.719869	val: 0.266314	test: 0.158264

Epoch: 66
Loss: 0.08471644412490996
ROC train: 0.964385	val: 0.701049	test: 0.739834
PRC train: 0.703926	val: 0.276890	test: 0.179677

Epoch: 67
Loss: 0.08449835530552446
ROC train: 0.964114	val: 0.703366	test: 0.741496
PRC train: 0.695587	val: 0.238176	test: 0.154663

Epoch: 68
Loss: 0.08499263673367871
ROC train: 0.965950	val: 0.703737	test: 0.727521
PRC train: 0.711537	val: 0.265349	test: 0.144626

Epoch: 69
Loss: 0.08396304470895272
ROC train: 0.967297	val: 0.709349	test: 0.743023
PRC train: 0.722131	val: 0.248821	test: 0.161529

Epoch: 70
Loss: 0.08309721878133172
ROC train: 0.968146	val: 0.714250	test: 0.750307
PRC train: 0.710830	val: 0.274173	test: 0.175025

Epoch: 71
Loss: 0.08225832692239328
ROC train: 0.970108	val: 0.715956	test: 0.765070
PRC train: 0.728713	val: 0.240644	test: 0.134012

Epoch: 72
Loss: 0.08209667789660798
ROC train: 0.968376	val: 0.707950	test: 0.752129
PRC train: 0.731078	val: 0.258903	test: 0.141040

Epoch: 73
Loss: 0.08166123668578174
ROC train: 0.971108	val: 0.703956	test: 0.749826
PRC train: 0.729794	val: 0.257847	test: 0.170077

Epoch: 74
Loss: 0.08065411859149578
ROC train: 0.969502	val: 0.710146	test: 0.755272
PRC train: 0.732398	val: 0.260525	test: 0.174412

Epoch: 75
Loss: 0.08086536348425329
ROC train: 0.972069	val: 0.716678	test: 0.762215
PRC train: 0.734859	val: 0.290106	test: 0.186946

Epoch: 76
Loss: 0.08187381059014158
ROC train: 0.970372	val: 0.718390	test: 0.739435
PRC train: 0.731702	val: 0.254836	test: 0.144293

Epoch: 77
Loss: 0.07976799833671154
ROC train: 0.968893	val: 0.722562	test: 0.752025
PRC train: 0.726566	val: 0.284587	test: 0.163258

Epoch: 78
Loss: 0.08114582289970952
ROC train: 0.973022	val: 0.723418	test: 0.755300
PRC train: 0.740470	val: 0.280812	test: 0.147823

Epoch: 79
Loss: 0.07895800231455855
ROC train: 0.972284	val: 0.711866	test: 0.760659
PRC train: 0.733549	val: 0.264520	test: 0.170087

Epoch: 80
Loss: 0.07940240099798372
ROC train: 0.974070	val: 0.729666	test: 0.741611
PRC train: 0.750447	val: 0.255973	test: 0.147877

Epoch: 81
Loss: 0.07920196299143789
ROC train: 0.974224	val: 0.701616	test: 0.760537
PRC train: 0.747096	val: 0.242494	test: 0.169336

Epoch: 82
Loss: 0.07889371473423333
ROC train: 0.975390	val: 0.722135	test: 0.752597
PRC train: 0.743966	val: 0.246932	test: 0.140126

Epoch: 83
Loss: 0.07849465414225863
ROC train: 0.974497	val: 0.720855	test: 0.759571
PRC train: 0.747968	val: 0.265685	test: 0.148827

Epoch: 84
Loss: 0.07831592113818593
ROC train: 0.969785	val: 0.721121	test: 0.751218
PRC train: 0.734188	val: 0.249214	test: 0.140388

Epoch: 85
Loss: 0.07676302155388615
ROC train: 0.974915	val: 0.707812	test: 0.753914
PRC train: 0.745927	val: 0.261691	test: 0.164374

Epoch: 86
Loss: 0.07782059388344416
ROC train: 0.973145	val: 0.694202	test: 0.747770
PRC train: 0.744371	val: 0.231844	test: 0.164885

Epoch: 87
Loss: 0.07789007145366306
ROC train: 0.975114	val: 0.708645	test: 0.762894
PRC train: 0.754971	val: 0.260859	test: 0.160935

Epoch: 88
Loss: 0.07484327491349986
ROC train: 0.978600	val: 0.730021	test: 0.749795
PRC train: 0.770824	val: 0.255857	test: 0.141111

Epoch: 89
Loss: 0.07600107518234414
ROC train: 0.976785	val: 0.710781	test: 0.746217
PRC train: 0.758046	val: 0.256267	test: 0.150464

Epoch: 90
Loss: 0.07469121387251493
ROC train: 0.979496	val: 0.717852	test: 0.755154
PRC train: 0.778060	val: 0.250822	test: 0.131000

Epoch: 91
Loss: 0.07538443722453084
ROC train: 0.978537	val: 0.715590	test: 0.759529
PRC train: 0.774347	val: 0.239108	test: 0.118270

Epoch: 92
Loss: 0.07636832689265653
ROC train: 0.981336	val: 0.711221	test: 0.759002
PRC train: 0.789071	val: 0.254866	test: 0.134972

Epoch: 93
Loss: 0.07505104323839201
ROC train: 0.976526	val: 0.725833	test: 0.764151
PRC train: 0.767945	val: 0.281740	test: 0.184027
ROC train: 0.922322	val: 0.776446	test: 0.740078
PRC train: 0.589023	val: 0.330329	test: 0.204283

Epoch: 34
Loss: 0.10097597676988304
ROC train: 0.919976	val: 0.763445	test: 0.743131
PRC train: 0.586618	val: 0.340594	test: 0.173192

Epoch: 35
Loss: 0.09992365512654662
ROC train: 0.926651	val: 0.779590	test: 0.764843
PRC train: 0.595643	val: 0.337054	test: 0.233632

Epoch: 36
Loss: 0.09970272884353625
ROC train: 0.919247	val: 0.757499	test: 0.768387
PRC train: 0.592329	val: 0.324583	test: 0.200042

Epoch: 37
Loss: 0.09874820293301578
ROC train: 0.924543	val: 0.756880	test: 0.764526
PRC train: 0.601076	val: 0.342028	test: 0.168745

Epoch: 38
Loss: 0.09908597450461837
ROC train: 0.924818	val: 0.773580	test: 0.758520
PRC train: 0.587216	val: 0.333988	test: 0.173016

Epoch: 39
Loss: 0.09981499022800341
ROC train: 0.922399	val: 0.767967	test: 0.754383
PRC train: 0.596824	val: 0.317717	test: 0.188708

Epoch: 40
Loss: 0.0971148141269952
ROC train: 0.924379	val: 0.785283	test: 0.741519
PRC train: 0.595204	val: 0.318765	test: 0.146248

Epoch: 41
Loss: 0.09749473685039915
ROC train: 0.929378	val: 0.778258	test: 0.767775
PRC train: 0.614286	val: 0.313642	test: 0.184788

Epoch: 42
Loss: 0.09796046374117709
ROC train: 0.933452	val: 0.755165	test: 0.758450
PRC train: 0.617211	val: 0.313780	test: 0.209128

Epoch: 43
Loss: 0.09532038781436171
ROC train: 0.927404	val: 0.761403	test: 0.748062
PRC train: 0.612259	val: 0.326523	test: 0.152183

Epoch: 44
Loss: 0.09551633450037599
ROC train: 0.931980	val: 0.770683	test: 0.753960
PRC train: 0.627663	val: 0.333464	test: 0.161209

Epoch: 45
Loss: 0.09626387058909434
ROC train: 0.938043	val: 0.784050	test: 0.770407
PRC train: 0.631656	val: 0.333189	test: 0.188292

Epoch: 46
Loss: 0.09565268799214581
ROC train: 0.935018	val: 0.752330	test: 0.766540
PRC train: 0.631158	val: 0.338856	test: 0.186964

Epoch: 47
Loss: 0.09398022201200773
ROC train: 0.935738	val: 0.770297	test: 0.756241
PRC train: 0.626379	val: 0.325357	test: 0.164729

Epoch: 48
Loss: 0.09332897923775213
ROC train: 0.935582	val: 0.752425	test: 0.747264
PRC train: 0.621754	val: 0.322022	test: 0.171476

Epoch: 49
Loss: 0.0925819574909779
ROC train: 0.941928	val: 0.766152	test: 0.765847
PRC train: 0.644414	val: 0.310154	test: 0.180951

Epoch: 50
Loss: 0.09253146053375164
ROC train: 0.945958	val: 0.786232	test: 0.746532
PRC train: 0.649125	val: 0.325960	test: 0.197871

Epoch: 51
Loss: 0.09302783923126487
ROC train: 0.942848	val: 0.756553	test: 0.746693
PRC train: 0.649405	val: 0.351899	test: 0.185577

Epoch: 52
Loss: 0.09185189293106619
ROC train: 0.943336	val: 0.766718	test: 0.741349
PRC train: 0.655250	val: 0.344375	test: 0.188301

Epoch: 53
Loss: 0.0927608577316934
ROC train: 0.946271	val: 0.770092	test: 0.765332
PRC train: 0.644228	val: 0.339831	test: 0.214451

Epoch: 54
Loss: 0.09256318563398924
ROC train: 0.946155	val: 0.768877	test: 0.764576
PRC train: 0.651124	val: 0.324679	test: 0.190361

Epoch: 55
Loss: 0.09139554224616858
ROC train: 0.943967	val: 0.791544	test: 0.761560
PRC train: 0.650071	val: 0.373023	test: 0.207828

Epoch: 56
Loss: 0.09160073539099665
ROC train: 0.951816	val: 0.796012	test: 0.753937
PRC train: 0.667111	val: 0.309483	test: 0.165760

Epoch: 57
Loss: 0.08924297429733748
ROC train: 0.949175	val: 0.780782	test: 0.746335
PRC train: 0.656095	val: 0.291533	test: 0.170492

Epoch: 58
Loss: 0.08832372371577746
ROC train: 0.953067	val: 0.774431	test: 0.762197
PRC train: 0.670498	val: 0.319166	test: 0.189431

Epoch: 59
Loss: 0.08821410698792198
ROC train: 0.952865	val: 0.771994	test: 0.760152
PRC train: 0.680039	val: 0.316157	test: 0.186245

Epoch: 60
Loss: 0.08857271364945545
ROC train: 0.951239	val: 0.779113	test: 0.746185
PRC train: 0.662697	val: 0.307083	test: 0.181069

Epoch: 61
Loss: 0.08758590906972527
ROC train: 0.956034	val: 0.760380	test: 0.743717
PRC train: 0.687501	val: 0.316603	test: 0.154123

Epoch: 62
Loss: 0.08792207135145556
ROC train: 0.954757	val: 0.768834	test: 0.756660
PRC train: 0.687553	val: 0.296976	test: 0.182652

Epoch: 63
Loss: 0.08803661187629125
ROC train: 0.956078	val: 0.765643	test: 0.740219
PRC train: 0.686245	val: 0.269506	test: 0.143568

Epoch: 64
Loss: 0.086938337577434
ROC train: 0.960421	val: 0.770934	test: 0.747204
PRC train: 0.696141	val: 0.316262	test: 0.143552

Epoch: 65
Loss: 0.08617627291370066
ROC train: 0.959618	val: 0.796991	test: 0.754522
PRC train: 0.698323	val: 0.297809	test: 0.149081

Epoch: 66
Loss: 0.08541311545687473
ROC train: 0.957961	val: 0.772646	test: 0.752052
PRC train: 0.698481	val: 0.299950	test: 0.172634

Epoch: 67
Loss: 0.08570482037847194
ROC train: 0.956358	val: 0.762514	test: 0.766131
PRC train: 0.695379	val: 0.323888	test: 0.194767

Epoch: 68
Loss: 0.08433117537441866
ROC train: 0.960804	val: 0.778693	test: 0.758798
PRC train: 0.700508	val: 0.353313	test: 0.197315

Epoch: 69
Loss: 0.0839125014265108
ROC train: 0.963905	val: 0.787815	test: 0.757342
PRC train: 0.712786	val: 0.325539	test: 0.155992

Epoch: 70
Loss: 0.08541147317756939
ROC train: 0.962765	val: 0.773341	test: 0.750271
PRC train: 0.708320	val: 0.315846	test: 0.177937

Epoch: 71
Loss: 0.08148359561708304
ROC train: 0.965562	val: 0.784290	test: 0.754018
PRC train: 0.724544	val: 0.300319	test: 0.158405

Epoch: 72
Loss: 0.08223504631303202
ROC train: 0.965934	val: 0.759911	test: 0.769675
PRC train: 0.721479	val: 0.318133	test: 0.188085

Epoch: 73
Loss: 0.08356005216717521
ROC train: 0.959368	val: 0.759602	test: 0.774926
PRC train: 0.699199	val: 0.310518	test: 0.166199

Epoch: 74
Loss: 0.08303553723807633
ROC train: 0.964151	val: 0.779036	test: 0.790575
PRC train: 0.712743	val: 0.305289	test: 0.193070

Epoch: 75
Loss: 0.08320255288174717
ROC train: 0.967896	val: 0.786247	test: 0.743529
PRC train: 0.729920	val: 0.301586	test: 0.156516

Epoch: 76
Loss: 0.0828641436216244
ROC train: 0.963875	val: 0.774642	test: 0.742185
PRC train: 0.715880	val: 0.285177	test: 0.122820

Epoch: 77
Loss: 0.08297077073198182
ROC train: 0.967444	val: 0.782291	test: 0.762481
PRC train: 0.729035	val: 0.311739	test: 0.186757

Epoch: 78
Loss: 0.08245827695180823
ROC train: 0.962928	val: 0.766066	test: 0.757205
PRC train: 0.711788	val: 0.305957	test: 0.179178

Epoch: 79
Loss: 0.08081297287677261
ROC train: 0.970134	val: 0.768987	test: 0.732803
PRC train: 0.737700	val: 0.288166	test: 0.154547

Epoch: 80
Loss: 0.08195935594762088
ROC train: 0.967857	val: 0.789266	test: 0.753607
PRC train: 0.731110	val: 0.323223	test: 0.188656

Epoch: 81
Loss: 0.0820159807791428
ROC train: 0.968017	val: 0.778439	test: 0.752436
PRC train: 0.733228	val: 0.340118	test: 0.182693

Epoch: 82
Loss: 0.07902749655408763
ROC train: 0.971377	val: 0.793807	test: 0.756621
PRC train: 0.746518	val: 0.341153	test: 0.171862

Epoch: 83
Loss: 0.08082526778884633
ROC train: 0.967884	val: 0.763117	test: 0.741194
PRC train: 0.727432	val: 0.273910	test: 0.140105

Epoch: 84
Loss: 0.07851076904849656
ROC train: 0.970406	val: 0.790831	test: 0.761896
PRC train: 0.745723	val: 0.289009	test: 0.164945

Epoch: 85
Loss: 0.07960894735476706
ROC train: 0.972062	val: 0.800506	test: 0.764061
PRC train: 0.746550	val: 0.283323	test: 0.139058

Epoch: 86
Loss: 0.07956110835319866
ROC train: 0.963242	val: 0.765888	test: 0.726557
PRC train: 0.716187	val: 0.265146	test: 0.101723

Epoch: 87
Loss: 0.0783054843026504
ROC train: 0.970005	val: 0.780123	test: 0.739574
PRC train: 0.736766	val: 0.317465	test: 0.158252

Epoch: 88
Loss: 0.07937083516745803
ROC train: 0.972430	val: 0.768280	test: 0.752031
PRC train: 0.755358	val: 0.326946	test: 0.160448

Epoch: 89
Loss: 0.07853470498475654
ROC train: 0.970534	val: 0.800543	test: 0.768825
PRC train: 0.745097	val: 0.293453	test: 0.145325

Epoch: 90
Loss: 0.0776197051204601
ROC train: 0.975368	val: 0.792518	test: 0.744112
PRC train: 0.765703	val: 0.318766	test: 0.148979

Epoch: 91
Loss: 0.07843010432509896
ROC train: 0.966123	val: 0.764051	test: 0.734060
PRC train: 0.732569	val: 0.293859	test: 0.185499

Epoch: 92
Loss: 0.07611878776086163
ROC train: 0.975937	val: 0.800650	test: 0.748811
PRC train: 0.765802	val: 0.305217	test: 0.152552

Epoch: 93
Loss: 0.07696405293830555
ROC train: 0.975686	val: 0.787187	test: 0.762417
PRC train: 0.775172	val: 0.293416	test: 0.180738

Epoch: 94
Loss: 0.07612542460210898
ROC train: 0.921856	val: 0.781109	test: 0.730408
PRC train: 0.587525	val: 0.354710	test: 0.159908

Epoch: 34
Loss: 0.10030760737221579
ROC train: 0.920569	val: 0.804046	test: 0.759534
PRC train: 0.582190	val: 0.348037	test: 0.183010

Epoch: 35
Loss: 0.10012333606068456
ROC train: 0.924182	val: 0.815709	test: 0.752363
PRC train: 0.599495	val: 0.377989	test: 0.171469

Epoch: 36
Loss: 0.09961797773136757
ROC train: 0.929608	val: 0.790025	test: 0.751440
PRC train: 0.601894	val: 0.354309	test: 0.164118

Epoch: 37
Loss: 0.0985243804842213
ROC train: 0.930130	val: 0.817537	test: 0.749696
PRC train: 0.605706	val: 0.372382	test: 0.180394

Epoch: 38
Loss: 0.09821355573116272
ROC train: 0.921983	val: 0.797148	test: 0.761127
PRC train: 0.600000	val: 0.341385	test: 0.186017

Epoch: 39
Loss: 0.09781396177361477
ROC train: 0.930918	val: 0.790405	test: 0.753475
PRC train: 0.621579	val: 0.356940	test: 0.158257

Epoch: 40
Loss: 0.09644498086678571
ROC train: 0.928721	val: 0.790176	test: 0.749651
PRC train: 0.612444	val: 0.380389	test: 0.201253

Epoch: 41
Loss: 0.09755651898651423
ROC train: 0.936724	val: 0.800748	test: 0.739518
PRC train: 0.626881	val: 0.364086	test: 0.175613

Epoch: 42
Loss: 0.09552234774726683
ROC train: 0.935033	val: 0.803593	test: 0.763435
PRC train: 0.617368	val: 0.363800	test: 0.152303

Epoch: 43
Loss: 0.0957393416559278
ROC train: 0.932848	val: 0.789594	test: 0.754288
PRC train: 0.614732	val: 0.350312	test: 0.176800

Epoch: 44
Loss: 0.09454925337438039
ROC train: 0.937416	val: 0.796893	test: 0.740422
PRC train: 0.629990	val: 0.335262	test: 0.154348

Epoch: 45
Loss: 0.09521421122982526
ROC train: 0.930450	val: 0.787294	test: 0.764088
PRC train: 0.610386	val: 0.321877	test: 0.141313

Epoch: 46
Loss: 0.09376008080381014
ROC train: 0.937781	val: 0.787199	test: 0.759263
PRC train: 0.629155	val: 0.354622	test: 0.167374

Epoch: 47
Loss: 0.09382433135522109
ROC train: 0.933647	val: 0.796452	test: 0.746455
PRC train: 0.625504	val: 0.345380	test: 0.118347

Epoch: 48
Loss: 0.09345775397263928
ROC train: 0.941766	val: 0.789327	test: 0.754959
PRC train: 0.634531	val: 0.354243	test: 0.183894

Epoch: 49
Loss: 0.09223542508868743
ROC train: 0.934818	val: 0.781363	test: 0.757821
PRC train: 0.628040	val: 0.328251	test: 0.170375

Epoch: 50
Loss: 0.09273099308997458
ROC train: 0.940237	val: 0.793617	test: 0.754225
PRC train: 0.647942	val: 0.364488	test: 0.158297

Epoch: 51
Loss: 0.09235360527019332
ROC train: 0.945782	val: 0.776795	test: 0.740304
PRC train: 0.643547	val: 0.334082	test: 0.161573

Epoch: 52
Loss: 0.09161914697657002
ROC train: 0.948720	val: 0.783892	test: 0.760268
PRC train: 0.659227	val: 0.328983	test: 0.176191

Epoch: 53
Loss: 0.0906154626583201
ROC train: 0.948762	val: 0.797025	test: 0.753172
PRC train: 0.653782	val: 0.339957	test: 0.163604

Epoch: 54
Loss: 0.09133832310844599
ROC train: 0.946001	val: 0.813758	test: 0.741142
PRC train: 0.641593	val: 0.316189	test: 0.180122

Epoch: 55
Loss: 0.09113335575883828
ROC train: 0.948348	val: 0.792291	test: 0.728778
PRC train: 0.650488	val: 0.335149	test: 0.160686

Epoch: 56
Loss: 0.08809874081271535
ROC train: 0.947737	val: 0.798813	test: 0.749352
PRC train: 0.660012	val: 0.317153	test: 0.162970

Epoch: 57
Loss: 0.0912647157542501
ROC train: 0.952241	val: 0.775310	test: 0.749051
PRC train: 0.670667	val: 0.349873	test: 0.184212

Epoch: 58
Loss: 0.09005515213381768
ROC train: 0.955575	val: 0.780279	test: 0.744910
PRC train: 0.678753	val: 0.325230	test: 0.169470

Epoch: 59
Loss: 0.08947036100619589
ROC train: 0.953439	val: 0.787083	test: 0.745292
PRC train: 0.671483	val: 0.346198	test: 0.184221

Epoch: 60
Loss: 0.08869542378312788
ROC train: 0.952469	val: 0.795485	test: 0.738896
PRC train: 0.671125	val: 0.333639	test: 0.185052

Epoch: 61
Loss: 0.08704774190170181
ROC train: 0.957625	val: 0.776930	test: 0.739551
PRC train: 0.692291	val: 0.334660	test: 0.164949

Epoch: 62
Loss: 0.08758454770167129
ROC train: 0.957023	val: 0.785534	test: 0.741214
PRC train: 0.680718	val: 0.302480	test: 0.138786

Epoch: 63
Loss: 0.08794532043255765
ROC train: 0.958730	val: 0.796073	test: 0.745930
PRC train: 0.692890	val: 0.345242	test: 0.172142

Epoch: 64
Loss: 0.08665357086862154
ROC train: 0.958996	val: 0.806765	test: 0.755920
PRC train: 0.694447	val: 0.347695	test: 0.203297

Epoch: 65
Loss: 0.08662720597927223
ROC train: 0.958649	val: 0.789379	test: 0.766612
PRC train: 0.688727	val: 0.294521	test: 0.140864

Epoch: 66
Loss: 0.08619956903175817
ROC train: 0.954682	val: 0.779756	test: 0.731277
PRC train: 0.670166	val: 0.324854	test: 0.141461

Epoch: 67
Loss: 0.08596881525607929
ROC train: 0.961503	val: 0.784894	test: 0.747344
PRC train: 0.701445	val: 0.332049	test: 0.167002

Epoch: 68
Loss: 0.08491311877423088
ROC train: 0.958805	val: 0.797515	test: 0.732625
PRC train: 0.693304	val: 0.357449	test: 0.136750

Epoch: 69
Loss: 0.08437052468391769
ROC train: 0.962551	val: 0.775389	test: 0.738195
PRC train: 0.701720	val: 0.337268	test: 0.163126

Epoch: 70
Loss: 0.08401695904119157
ROC train: 0.960778	val: 0.783966	test: 0.751840
PRC train: 0.700853	val: 0.303265	test: 0.147657

Epoch: 71
Loss: 0.08371606987461547
ROC train: 0.964813	val: 0.785632	test: 0.754986
PRC train: 0.716367	val: 0.306255	test: 0.169313

Epoch: 72
Loss: 0.08330214753808206
ROC train: 0.965277	val: 0.802053	test: 0.735731
PRC train: 0.707110	val: 0.343889	test: 0.142837

Epoch: 73
Loss: 0.08337488193087178
ROC train: 0.964381	val: 0.792668	test: 0.731186
PRC train: 0.711757	val: 0.275590	test: 0.127977

Epoch: 74
Loss: 0.08176910345716548
ROC train: 0.963783	val: 0.782260	test: 0.753097
PRC train: 0.708907	val: 0.306960	test: 0.177330

Epoch: 75
Loss: 0.08215433269529646
ROC train: 0.962985	val: 0.792264	test: 0.744730
PRC train: 0.709140	val: 0.296550	test: 0.154038

Epoch: 76
Loss: 0.08290030456295946
ROC train: 0.966995	val: 0.780711	test: 0.720217
PRC train: 0.726153	val: 0.318360	test: 0.145678

Epoch: 77
Loss: 0.08102525061602196
ROC train: 0.967644	val: 0.788690	test: 0.731673
PRC train: 0.730352	val: 0.295061	test: 0.155943

Epoch: 78
Loss: 0.08167922163487733
ROC train: 0.970111	val: 0.793090	test: 0.729272
PRC train: 0.732915	val: 0.318024	test: 0.149359

Epoch: 79
Loss: 0.08009160259147008
ROC train: 0.967846	val: 0.793617	test: 0.746501
PRC train: 0.725818	val: 0.320929	test: 0.139657

Epoch: 80
Loss: 0.08048611988444626
ROC train: 0.969669	val: 0.804144	test: 0.741318
PRC train: 0.732312	val: 0.327641	test: 0.155620

Epoch: 81
Loss: 0.08059471753031205
ROC train: 0.970012	val: 0.792402	test: 0.738749
PRC train: 0.738894	val: 0.321117	test: 0.144151

Epoch: 82
Loss: 0.08040245422564402
ROC train: 0.970398	val: 0.815740	test: 0.745903
PRC train: 0.747213	val: 0.339334	test: 0.160227

Epoch: 83
Loss: 0.08052957952643411
ROC train: 0.969520	val: 0.823731	test: 0.761853
PRC train: 0.738718	val: 0.358779	test: 0.168368

Epoch: 84
Loss: 0.08035820631691418
ROC train: 0.971651	val: 0.803078	test: 0.758161
PRC train: 0.747994	val: 0.341783	test: 0.198286

Epoch: 85
Loss: 0.07880745596133308
ROC train: 0.969953	val: 0.801134	test: 0.745439
PRC train: 0.739530	val: 0.308195	test: 0.167144

Epoch: 86
Loss: 0.07833915153443086
ROC train: 0.968999	val: 0.793240	test: 0.753549
PRC train: 0.737672	val: 0.334903	test: 0.193828

Epoch: 87
Loss: 0.07773916224417457
ROC train: 0.972895	val: 0.806627	test: 0.742608
PRC train: 0.740622	val: 0.295953	test: 0.137401

Epoch: 88
Loss: 0.07850134615456138
ROC train: 0.974331	val: 0.802592	test: 0.741343
PRC train: 0.756548	val: 0.309172	test: 0.159054

Epoch: 89
Loss: 0.07685688679432642
ROC train: 0.972468	val: 0.793072	test: 0.745812
PRC train: 0.750921	val: 0.333254	test: 0.153396

Epoch: 90
Loss: 0.0780104368352195
ROC train: 0.974241	val: 0.794370	test: 0.728191
PRC train: 0.751995	val: 0.335061	test: 0.158257

Epoch: 91
Loss: 0.0767288730691475
ROC train: 0.973212	val: 0.791116	test: 0.740269
PRC train: 0.744087	val: 0.334392	test: 0.164360

Epoch: 92
Loss: 0.07540338589125153
ROC train: 0.976838	val: 0.793164	test: 0.746596
PRC train: 0.768696	val: 0.331013	test: 0.177658

Epoch: 93
Loss: 0.07707282891765639
ROC train: 0.974125	val: 0.806045	test: 0.746598
PRC train: 0.757472	val: 0.319812	test: 0.152922

ROC train: 0.908983	val: 0.771972	test: 0.747023
PRC train: 0.545958	val: 0.302898	test: 0.165023

Epoch: 34
Loss: 0.10242011336869371
ROC train: 0.907186	val: 0.775711	test: 0.748946
PRC train: 0.557724	val: 0.337215	test: 0.228059

Epoch: 35
Loss: 0.10161601417623492
ROC train: 0.915886	val: 0.775558	test: 0.735553
PRC train: 0.571989	val: 0.314206	test: 0.141538

Epoch: 36
Loss: 0.10151617279183281
ROC train: 0.911073	val: 0.793176	test: 0.748174
PRC train: 0.550653	val: 0.352713	test: 0.246051

Epoch: 37
Loss: 0.0999386641630629
ROC train: 0.918237	val: 0.788351	test: 0.742345
PRC train: 0.577648	val: 0.311916	test: 0.156289

Epoch: 38
Loss: 0.10090820084974694
ROC train: 0.918020	val: 0.772563	test: 0.747367
PRC train: 0.579164	val: 0.329228	test: 0.206616

Epoch: 39
Loss: 0.10024355179925055
ROC train: 0.921999	val: 0.778124	test: 0.755024
PRC train: 0.589261	val: 0.323071	test: 0.182700

Epoch: 40
Loss: 0.09951813676079142
ROC train: 0.919141	val: 0.764985	test: 0.730248
PRC train: 0.579275	val: 0.295273	test: 0.128518

Epoch: 41
Loss: 0.09912461507306825
ROC train: 0.919609	val: 0.772530	test: 0.762664
PRC train: 0.580035	val: 0.345801	test: 0.278178

Epoch: 42
Loss: 0.09894577326466912
ROC train: 0.928756	val: 0.783185	test: 0.769590
PRC train: 0.602284	val: 0.334061	test: 0.189510

Epoch: 43
Loss: 0.098517741372122
ROC train: 0.925958	val: 0.781385	test: 0.763756
PRC train: 0.590663	val: 0.317111	test: 0.172427

Epoch: 44
Loss: 0.09747373288640236
ROC train: 0.923774	val: 0.768993	test: 0.756824
PRC train: 0.596229	val: 0.329081	test: 0.156397

Epoch: 45
Loss: 0.09855002528905248
ROC train: 0.926198	val: 0.781924	test: 0.743991
PRC train: 0.591988	val: 0.317350	test: 0.184324

Epoch: 46
Loss: 0.09730125511025205
ROC train: 0.925524	val: 0.767676	test: 0.726092
PRC train: 0.599478	val: 0.290651	test: 0.140011

Epoch: 47
Loss: 0.09733759134030105
ROC train: 0.924293	val: 0.809349	test: 0.760198
PRC train: 0.580779	val: 0.333124	test: 0.199992

Epoch: 48
Loss: 0.09630671942182699
ROC train: 0.934789	val: 0.789875	test: 0.771591
PRC train: 0.618018	val: 0.336507	test: 0.205747

Epoch: 49
Loss: 0.09509035871882926
ROC train: 0.929843	val: 0.764275	test: 0.748522
PRC train: 0.596847	val: 0.286899	test: 0.166031

Epoch: 50
Loss: 0.09466448941687626
ROC train: 0.937107	val: 0.783243	test: 0.754474
PRC train: 0.626158	val: 0.321992	test: 0.199356

Epoch: 51
Loss: 0.09480844895571798
ROC train: 0.933682	val: 0.788850	test: 0.761983
PRC train: 0.618888	val: 0.326841	test: 0.149441

Epoch: 52
Loss: 0.09322984153363414
ROC train: 0.941343	val: 0.777995	test: 0.744761
PRC train: 0.629063	val: 0.289323	test: 0.165094

Epoch: 53
Loss: 0.09327387837496001
ROC train: 0.943486	val: 0.801621	test: 0.771255
PRC train: 0.637702	val: 0.345318	test: 0.215961

Epoch: 54
Loss: 0.09333556916148043
ROC train: 0.938594	val: 0.805908	test: 0.756341
PRC train: 0.632110	val: 0.360797	test: 0.214887

Epoch: 55
Loss: 0.09169296022987458
ROC train: 0.946291	val: 0.791152	test: 0.745895
PRC train: 0.634342	val: 0.306280	test: 0.203994

Epoch: 56
Loss: 0.0916215867999676
ROC train: 0.943638	val: 0.787885	test: 0.740049
PRC train: 0.642940	val: 0.302748	test: 0.165499

Epoch: 57
Loss: 0.09128369897331365
ROC train: 0.949101	val: 0.806471	test: 0.772622
PRC train: 0.656496	val: 0.309223	test: 0.198678

Epoch: 58
Loss: 0.09118324176854124
ROC train: 0.945361	val: 0.803415	test: 0.754242
PRC train: 0.650518	val: 0.337174	test: 0.168835

Epoch: 59
Loss: 0.09097018351110672
ROC train: 0.946632	val: 0.789796	test: 0.752697
PRC train: 0.644163	val: 0.310879	test: 0.181100

Epoch: 60
Loss: 0.09136576876501681
ROC train: 0.947103	val: 0.780393	test: 0.761432
PRC train: 0.648144	val: 0.328064	test: 0.177242

Epoch: 61
Loss: 0.08792982842391006
ROC train: 0.944716	val: 0.782968	test: 0.754240
PRC train: 0.644590	val: 0.303317	test: 0.156738

Epoch: 62
Loss: 0.09019335168949266
ROC train: 0.952200	val: 0.801352	test: 0.772191
PRC train: 0.670979	val: 0.314074	test: 0.158714

Epoch: 63
Loss: 0.08888701777909021
ROC train: 0.947437	val: 0.792653	test: 0.755225
PRC train: 0.659576	val: 0.324109	test: 0.188605

Epoch: 64
Loss: 0.08954391886025445
ROC train: 0.950427	val: 0.807968	test: 0.764706
PRC train: 0.654093	val: 0.305900	test: 0.180819

Epoch: 65
Loss: 0.08762503930903266
ROC train: 0.952185	val: 0.773390	test: 0.761212
PRC train: 0.674540	val: 0.288709	test: 0.178903

Epoch: 66
Loss: 0.08790824180096009
ROC train: 0.951289	val: 0.784915	test: 0.758288
PRC train: 0.679311	val: 0.299625	test: 0.179003

Epoch: 67
Loss: 0.08795515444063773
ROC train: 0.956753	val: 0.796514	test: 0.766427
PRC train: 0.676648	val: 0.310555	test: 0.159188

Epoch: 68
Loss: 0.08664700604527246
ROC train: 0.956935	val: 0.787977	test: 0.755453
PRC train: 0.677006	val: 0.308315	test: 0.153588

Epoch: 69
Loss: 0.08689632657120673
ROC train: 0.957653	val: 0.786063	test: 0.771218
PRC train: 0.675257	val: 0.293001	test: 0.154218

Epoch: 70
Loss: 0.08703844497681887
ROC train: 0.956337	val: 0.779189	test: 0.742158
PRC train: 0.674080	val: 0.279219	test: 0.159760

Epoch: 71
Loss: 0.08621475897073398
ROC train: 0.959157	val: 0.788084	test: 0.763201
PRC train: 0.689503	val: 0.298719	test: 0.214139

Epoch: 72
Loss: 0.08621515408770879
ROC train: 0.958947	val: 0.777992	test: 0.754111
PRC train: 0.679025	val: 0.307075	test: 0.141066

Epoch: 73
Loss: 0.0854931945507181
ROC train: 0.957051	val: 0.796293	test: 0.749955
PRC train: 0.679726	val: 0.298335	test: 0.189890

Epoch: 74
Loss: 0.08467752093613029
ROC train: 0.961373	val: 0.799802	test: 0.757940
PRC train: 0.706079	val: 0.282210	test: 0.162795

Epoch: 75
Loss: 0.08481798659009784
ROC train: 0.960220	val: 0.784493	test: 0.748688
PRC train: 0.702863	val: 0.316522	test: 0.164706

Epoch: 76
Loss: 0.08396899584307276
ROC train: 0.962658	val: 0.804055	test: 0.752342
PRC train: 0.699470	val: 0.287865	test: 0.158924

Epoch: 77
Loss: 0.08419820209200808
ROC train: 0.960835	val: 0.778880	test: 0.745853
PRC train: 0.689750	val: 0.274920	test: 0.139541

Epoch: 78
Loss: 0.08502944564527523
ROC train: 0.964359	val: 0.778552	test: 0.767479
PRC train: 0.706897	val: 0.303464	test: 0.192945

Epoch: 79
Loss: 0.08282788828472282
ROC train: 0.963461	val: 0.801021	test: 0.771965
PRC train: 0.718133	val: 0.304420	test: 0.184409

Epoch: 80
Loss: 0.08272227786825725
ROC train: 0.964458	val: 0.806091	test: 0.763083
PRC train: 0.715932	val: 0.321582	test: 0.171387

Epoch: 81
Loss: 0.08240858802173277
ROC train: 0.964066	val: 0.804560	test: 0.768352
PRC train: 0.714421	val: 0.275010	test: 0.164499

Epoch: 82
Loss: 0.08248534839418356
ROC train: 0.966614	val: 0.808636	test: 0.764553
PRC train: 0.726545	val: 0.307535	test: 0.176916

Epoch: 83
Loss: 0.08251538718398066
ROC train: 0.965002	val: 0.808559	test: 0.773176
PRC train: 0.717998	val: 0.306668	test: 0.171245

Epoch: 84
Loss: 0.08231106382640271
ROC train: 0.968895	val: 0.788109	test: 0.768516
PRC train: 0.726845	val: 0.311938	test: 0.172245

Epoch: 85
Loss: 0.08010434728648208
ROC train: 0.968474	val: 0.802328	test: 0.751003
PRC train: 0.726103	val: 0.295063	test: 0.189742

Epoch: 86
Loss: 0.08101449058095914
ROC train: 0.968666	val: 0.784144	test: 0.761311
PRC train: 0.726831	val: 0.306666	test: 0.174333

Epoch: 87
Loss: 0.07963339028218536
ROC train: 0.965781	val: 0.792071	test: 0.751419
PRC train: 0.725024	val: 0.299560	test: 0.158472

Epoch: 88
Loss: 0.07928311725541738
ROC train: 0.969437	val: 0.801483	test: 0.753927
PRC train: 0.736610	val: 0.300993	test: 0.154881

Epoch: 89
Loss: 0.07981932060226589
ROC train: 0.966835	val: 0.795179	test: 0.765403
PRC train: 0.727977	val: 0.296139	test: 0.151226

Epoch: 90
Loss: 0.07933386068135198
ROC train: 0.972325	val: 0.796281	test: 0.763078
PRC train: 0.742702	val: 0.289817	test: 0.155276

Epoch: 91
Loss: 0.07929683060985873
ROC train: 0.972684	val: 0.796927	test: 0.747940
PRC train: 0.750709	val: 0.264459	test: 0.131491

Epoch: 92
Loss: 0.0782094135295286
ROC train: 0.971579	val: 0.800424	test: 0.748844
PRC train: 0.742576	val: 0.296191	test: 0.169282

Epoch: 93
Loss: 0.07841553226575955
ROC train: 0.971080	val: 0.793605	test: 0.758317
PRC train: 0.735388	val: 0.334743	test: 0.183432

ROC train: 0.978463	val: 0.699539	test: 0.748973
PRC train: 0.790205	val: 0.224331	test: 0.186587

Epoch: 95
Loss: 0.07165675465310882
ROC train: 0.979807	val: 0.699058	test: 0.749623
PRC train: 0.786827	val: 0.218737	test: 0.183930

Epoch: 96
Loss: 0.07069316664545845
ROC train: 0.976605	val: 0.703240	test: 0.752365
PRC train: 0.762821	val: 0.211363	test: 0.192193

Epoch: 97
Loss: 0.07042314297308902
ROC train: 0.982070	val: 0.699928	test: 0.746180
PRC train: 0.798086	val: 0.219510	test: 0.203983

Epoch: 98
Loss: 0.06995845914752234
ROC train: 0.982581	val: 0.698911	test: 0.746636
PRC train: 0.806510	val: 0.211961	test: 0.173586

Epoch: 99
Loss: 0.0693413005811451
ROC train: 0.982998	val: 0.704940	test: 0.745513
PRC train: 0.815512	val: 0.199205	test: 0.162572

Epoch: 100
Loss: 0.06835512347397675
ROC train: 0.983687	val: 0.699764	test: 0.749094
PRC train: 0.807477	val: 0.213329	test: 0.205974

Epoch: 101
Loss: 0.06960790355629275
ROC train: 0.983276	val: 0.695878	test: 0.742881
PRC train: 0.817120	val: 0.225587	test: 0.191209

Epoch: 102
Loss: 0.07083805811436458
ROC train: 0.981292	val: 0.698084	test: 0.734604
PRC train: 0.800613	val: 0.193236	test: 0.146097

Epoch: 103
Loss: 0.06775930795095968
ROC train: 0.981594	val: 0.708323	test: 0.737976
PRC train: 0.800374	val: 0.199838	test: 0.146551

Epoch: 104
Loss: 0.06803491003708262
ROC train: 0.980835	val: 0.697135	test: 0.744630
PRC train: 0.803900	val: 0.203284	test: 0.176622

Epoch: 105
Loss: 0.07084227750312211
ROC train: 0.985023	val: 0.699271	test: 0.751107
PRC train: 0.825367	val: 0.205115	test: 0.195989

Epoch: 106
Loss: 0.06794985520060488
ROC train: 0.982516	val: 0.705174	test: 0.747626
PRC train: 0.806515	val: 0.203204	test: 0.178542

Epoch: 107
Loss: 0.06770861003715384
ROC train: 0.985475	val: 0.699708	test: 0.758581
PRC train: 0.834927	val: 0.220962	test: 0.198349

Epoch: 108
Loss: 0.06577288075728022
ROC train: 0.984741	val: 0.698613	test: 0.744480
PRC train: 0.814010	val: 0.199927	test: 0.183515

Epoch: 109
Loss: 0.06740087904832277
ROC train: 0.985123	val: 0.702212	test: 0.751535
PRC train: 0.822725	val: 0.215706	test: 0.190267

Epoch: 110
Loss: 0.06769886716216614
ROC train: 0.985722	val: 0.705201	test: 0.756839
PRC train: 0.821996	val: 0.210949	test: 0.202527

Epoch: 111
Loss: 0.06787043974461622
ROC train: 0.979512	val: 0.696364	test: 0.739808
PRC train: 0.789114	val: 0.206838	test: 0.161100

Epoch: 112
Loss: 0.06674604626201977
ROC train: 0.985606	val: 0.700191	test: 0.745750
PRC train: 0.825819	val: 0.217117	test: 0.164039

Epoch: 113
Loss: 0.06524359870837546
ROC train: 0.986211	val: 0.704209	test: 0.755479
PRC train: 0.824542	val: 0.226002	test: 0.221832

Epoch: 114
Loss: 0.0660755711155001
ROC train: 0.987400	val: 0.703199	test: 0.751247
PRC train: 0.843000	val: 0.222308	test: 0.194142

Epoch: 115
Loss: 0.06617391315831528
ROC train: 0.985677	val: 0.700575	test: 0.757766
PRC train: 0.829507	val: 0.211335	test: 0.196716

Epoch: 116
Loss: 0.06569234076475308
ROC train: 0.987500	val: 0.696133	test: 0.753769
PRC train: 0.838755	val: 0.213455	test: 0.157835

Epoch: 117
Loss: 0.06494424531545079
ROC train: 0.986675	val: 0.703047	test: 0.740833
PRC train: 0.827874	val: 0.215721	test: 0.202775

Epoch: 118
Loss: 0.06443333660904212
ROC train: 0.986644	val: 0.683890	test: 0.739731
PRC train: 0.831925	val: 0.207362	test: 0.155346

Epoch: 119
Loss: 0.06372207673318629
ROC train: 0.988500	val: 0.706390	test: 0.745522
PRC train: 0.845214	val: 0.221960	test: 0.180056

Epoch: 120
Loss: 0.0628953947451595
ROC train: 0.987216	val: 0.698694	test: 0.764599
PRC train: 0.840625	val: 0.229640	test: 0.196831

Early stopping
Best (ROC):	 train: 0.953574	val: 0.710991	test: 0.750777
Best (PRC):	 train: 0.659740	val: 0.218733	test: 0.219842

Epoch: 94
Loss: 0.06960678581064428
ROC train: 0.981534	val: 0.715114	test: 0.747604
PRC train: 0.781391	val: 0.237529	test: 0.225511

Epoch: 95
Loss: 0.0708395376259268
ROC train: 0.983573	val: 0.711339	test: 0.749986
PRC train: 0.807981	val: 0.249610	test: 0.182720

Epoch: 96
Loss: 0.06896877237444723
ROC train: 0.983400	val: 0.712967	test: 0.747853
PRC train: 0.810497	val: 0.236691	test: 0.197929

Epoch: 97
Loss: 0.07002411990988852
ROC train: 0.984767	val: 0.702747	test: 0.738238
PRC train: 0.813178	val: 0.240144	test: 0.186497

Epoch: 98
Loss: 0.06981195817504106
ROC train: 0.984013	val: 0.713696	test: 0.754362
PRC train: 0.809966	val: 0.245016	test: 0.181572

Epoch: 99
Loss: 0.06845470999498077
ROC train: 0.982553	val: 0.706345	test: 0.736996
PRC train: 0.788884	val: 0.236273	test: 0.211180

Epoch: 100
Loss: 0.07029877954623505
ROC train: 0.983872	val: 0.702100	test: 0.741609
PRC train: 0.808194	val: 0.243621	test: 0.179825

Epoch: 101
Loss: 0.06860373254337844
ROC train: 0.982392	val: 0.699914	test: 0.744852
PRC train: 0.797357	val: 0.231665	test: 0.162492

Epoch: 102
Loss: 0.07047112237187499
ROC train: 0.984266	val: 0.701053	test: 0.749414
PRC train: 0.807859	val: 0.240511	test: 0.178571

Epoch: 103
Loss: 0.06851025396232427
ROC train: 0.985125	val: 0.701777	test: 0.744963
PRC train: 0.812443	val: 0.241939	test: 0.188730

Epoch: 104
Loss: 0.06886419625780812
ROC train: 0.986605	val: 0.702187	test: 0.741118
PRC train: 0.830135	val: 0.236207	test: 0.186631

Epoch: 105
Loss: 0.06746840359348158
ROC train: 0.985760	val: 0.709521	test: 0.757379
PRC train: 0.824271	val: 0.238222	test: 0.179977

Epoch: 106
Loss: 0.068527750311419
ROC train: 0.985007	val: 0.703299	test: 0.748222
PRC train: 0.812411	val: 0.252122	test: 0.199181

Epoch: 107
Loss: 0.06625281565819766
ROC train: 0.986360	val: 0.711441	test: 0.749566
PRC train: 0.825485	val: 0.239629	test: 0.212359

Epoch: 108
Loss: 0.06508829319931836
ROC train: 0.985846	val: 0.701932	test: 0.738667
PRC train: 0.816417	val: 0.247692	test: 0.197580

Epoch: 109
Loss: 0.0674514402943308
ROC train: 0.985892	val: 0.704291	test: 0.750468
PRC train: 0.824664	val: 0.239657	test: 0.194943

Epoch: 110
Loss: 0.06670746358515157
ROC train: 0.987127	val: 0.702878	test: 0.734681
PRC train: 0.837813	val: 0.229604	test: 0.179775

Epoch: 111
Loss: 0.06386509167653506
ROC train: 0.986687	val: 0.694808	test: 0.736519
PRC train: 0.820103	val: 0.214402	test: 0.147700

Epoch: 112
Loss: 0.06579446279563952
ROC train: 0.987026	val: 0.714427	test: 0.764569
PRC train: 0.827679	val: 0.229785	test: 0.177427

Epoch: 113
Loss: 0.06445126449707973
ROC train: 0.985992	val: 0.690869	test: 0.746272
PRC train: 0.826499	val: 0.227760	test: 0.163343

Epoch: 114
Loss: 0.06496132380924671
ROC train: 0.986064	val: 0.697182	test: 0.747514
PRC train: 0.824245	val: 0.222824	test: 0.190959

Epoch: 115
Loss: 0.06345411901968967
ROC train: 0.986527	val: 0.694833	test: 0.724652
PRC train: 0.824278	val: 0.231678	test: 0.152225

Epoch: 116
Loss: 0.06464471175234013
ROC train: 0.989084	val: 0.707122	test: 0.751963
PRC train: 0.846215	val: 0.235202	test: 0.210995

Epoch: 117
Loss: 0.0652191399790646
ROC train: 0.988052	val: 0.709608	test: 0.753143
PRC train: 0.838886	val: 0.244154	test: 0.195224

Epoch: 118
Loss: 0.06363496336561461
ROC train: 0.988575	val: 0.706280	test: 0.747531
PRC train: 0.842947	val: 0.250030	test: 0.182377

Epoch: 119
Loss: 0.062011702817354984
ROC train: 0.988500	val: 0.706457	test: 0.750065
PRC train: 0.845969	val: 0.238070	test: 0.191944

Epoch: 120
Loss: 0.06385286466220087
ROC train: 0.989182	val: 0.699775	test: 0.742384
PRC train: 0.847238	val: 0.235477	test: 0.181777

Early stopping
Best (ROC):	 train: 0.888134	val: 0.720543	test: 0.765606
Best (PRC):	 train: 0.510115	val: 0.210718	test: 0.232342

ROC train: 0.980522	val: 0.690615	test: 0.731437
PRC train: 0.776865	val: 0.210141	test: 0.143383

Epoch: 95
Loss: 0.07167844445126054
ROC train: 0.980253	val: 0.694761	test: 0.740961
PRC train: 0.786116	val: 0.206168	test: 0.177180

Epoch: 96
Loss: 0.07040103609338336
ROC train: 0.980143	val: 0.703205	test: 0.741987
PRC train: 0.783153	val: 0.223599	test: 0.176827

Epoch: 97
Loss: 0.06800431853704536
ROC train: 0.980739	val: 0.703640	test: 0.744599
PRC train: 0.779670	val: 0.189070	test: 0.149798

Epoch: 98
Loss: 0.06969385985852787
ROC train: 0.983715	val: 0.687300	test: 0.745920
PRC train: 0.811063	val: 0.227622	test: 0.170743

Epoch: 99
Loss: 0.07050335502413592
ROC train: 0.985973	val: 0.702335	test: 0.751934
PRC train: 0.828552	val: 0.227872	test: 0.183867

Epoch: 100
Loss: 0.06856575063088083
ROC train: 0.985317	val: 0.705227	test: 0.754797
PRC train: 0.821266	val: 0.239559	test: 0.198194

Epoch: 101
Loss: 0.06951041043190986
ROC train: 0.983599	val: 0.690645	test: 0.725968
PRC train: 0.818597	val: 0.229928	test: 0.151113

Epoch: 102
Loss: 0.06646176217993882
ROC train: 0.984148	val: 0.696075	test: 0.737088
PRC train: 0.814863	val: 0.218414	test: 0.151763

Epoch: 103
Loss: 0.06772274389222538
ROC train: 0.986499	val: 0.702267	test: 0.752393
PRC train: 0.826167	val: 0.220270	test: 0.153093

Epoch: 104
Loss: 0.06733338998618148
ROC train: 0.984450	val: 0.703423	test: 0.754419
PRC train: 0.820883	val: 0.225474	test: 0.207424

Epoch: 105
Loss: 0.06678292160754357
ROC train: 0.985277	val: 0.710466	test: 0.755481
PRC train: 0.815463	val: 0.203529	test: 0.148021

Epoch: 106
Loss: 0.06733367240979994
ROC train: 0.986018	val: 0.713111	test: 0.751794
PRC train: 0.818309	val: 0.188148	test: 0.147420

Epoch: 107
Loss: 0.06858179353390596
ROC train: 0.985274	val: 0.703563	test: 0.768303
PRC train: 0.825979	val: 0.247231	test: 0.195412

Epoch: 108
Loss: 0.06626385330164294
ROC train: 0.985524	val: 0.698609	test: 0.745743
PRC train: 0.826483	val: 0.222073	test: 0.152131

Epoch: 109
Loss: 0.06614544190762202
ROC train: 0.987326	val: 0.716870	test: 0.773721
PRC train: 0.834328	val: 0.259951	test: 0.199404

Epoch: 110
Loss: 0.06559574977478701
ROC train: 0.988416	val: 0.709020	test: 0.748030
PRC train: 0.845869	val: 0.213338	test: 0.178681

Epoch: 111
Loss: 0.06578341724289782
ROC train: 0.987677	val: 0.694669	test: 0.738698
PRC train: 0.836259	val: 0.224059	test: 0.167153

Epoch: 112
Loss: 0.06554218210767106
ROC train: 0.985348	val: 0.698625	test: 0.738604
PRC train: 0.810622	val: 0.190103	test: 0.134421

Epoch: 113
Loss: 0.06353148359495214
ROC train: 0.985962	val: 0.699367	test: 0.741298
PRC train: 0.818689	val: 0.196262	test: 0.136890

Epoch: 114
Loss: 0.06581465176662224
ROC train: 0.988433	val: 0.706016	test: 0.749389
PRC train: 0.844155	val: 0.227695	test: 0.169080

Epoch: 115
Loss: 0.06353123616413035
ROC train: 0.989599	val: 0.702858	test: 0.762480
PRC train: 0.855529	val: 0.241893	test: 0.182559

Epoch: 116
Loss: 0.06493621974852844
ROC train: 0.988151	val: 0.705989	test: 0.753670
PRC train: 0.845052	val: 0.219118	test: 0.173449

Epoch: 117
Loss: 0.06168148531018148
ROC train: 0.987866	val: 0.709892	test: 0.755655
PRC train: 0.839369	val: 0.221070	test: 0.169306

Epoch: 118
Loss: 0.062190787574420744
ROC train: 0.989460	val: 0.707472	test: 0.750697
PRC train: 0.852992	val: 0.251259	test: 0.187262

Epoch: 119
Loss: 0.0651694455176515
ROC train: 0.989612	val: 0.710681	test: 0.747241
PRC train: 0.856976	val: 0.236248	test: 0.163957

Epoch: 120
Loss: 0.06303742302784937
ROC train: 0.988093	val: 0.699341	test: 0.747987
PRC train: 0.845216	val: 0.224414	test: 0.169614

Early stopping
Best (ROC):	 train: 0.941458	val: 0.720747	test: 0.746640
Best (PRC):	 train: 0.643369	val: 0.225078	test: 0.239132
All runs completed.


Epoch: 94
Loss: 0.07411624666492839
ROC train: 0.978604	val: 0.716732	test: 0.737758
PRC train: 0.777896	val: 0.236269	test: 0.110540

Epoch: 95
Loss: 0.07326435996870015
ROC train: 0.980087	val: 0.708151	test: 0.731703
PRC train: 0.780918	val: 0.228901	test: 0.107960

Epoch: 96
Loss: 0.07293768293048818
ROC train: 0.981183	val: 0.716231	test: 0.753392
PRC train: 0.785976	val: 0.250535	test: 0.140853

Epoch: 97
Loss: 0.07188882378042213
ROC train: 0.979078	val: 0.720977	test: 0.743528
PRC train: 0.769884	val: 0.243762	test: 0.135173

Epoch: 98
Loss: 0.07357642228654943
ROC train: 0.980714	val: 0.711495	test: 0.747655
PRC train: 0.783863	val: 0.256259	test: 0.155033

Epoch: 99
Loss: 0.07387131324652416
ROC train: 0.982807	val: 0.707767	test: 0.750295
PRC train: 0.798845	val: 0.267300	test: 0.144103

Epoch: 100
Loss: 0.07231264388582051
ROC train: 0.982364	val: 0.711671	test: 0.753501
PRC train: 0.792175	val: 0.267150	test: 0.141294

Epoch: 101
Loss: 0.07354564606276472
ROC train: 0.980849	val: 0.693161	test: 0.747280
PRC train: 0.783865	val: 0.219967	test: 0.126843

Epoch: 102
Loss: 0.07274267944414478
ROC train: 0.979290	val: 0.703664	test: 0.746776
PRC train: 0.780438	val: 0.250163	test: 0.162806

Epoch: 103
Loss: 0.07180011311729044
ROC train: 0.981046	val: 0.701014	test: 0.752566
PRC train: 0.784802	val: 0.241354	test: 0.138600

Epoch: 104
Loss: 0.07030239853344061
ROC train: 0.984828	val: 0.710288	test: 0.752908
PRC train: 0.811564	val: 0.256071	test: 0.152591

Epoch: 105
Loss: 0.07053301838073645
ROC train: 0.983007	val: 0.711375	test: 0.768956
PRC train: 0.797309	val: 0.261164	test: 0.155083

Epoch: 106
Loss: 0.07190425921118489
ROC train: 0.983252	val: 0.704704	test: 0.763707
PRC train: 0.791855	val: 0.270812	test: 0.187808

Epoch: 107
Loss: 0.07029767409817554
ROC train: 0.983440	val: 0.717063	test: 0.751675
PRC train: 0.809296	val: 0.238484	test: 0.121904

Epoch: 108
Loss: 0.07326596741249684
ROC train: 0.982773	val: 0.710497	test: 0.754993
PRC train: 0.798707	val: 0.254519	test: 0.139404

Epoch: 109
Loss: 0.06939581100798618
ROC train: 0.983119	val: 0.715891	test: 0.741792
PRC train: 0.809623	val: 0.245810	test: 0.124897

Epoch: 110
Loss: 0.07049349958360207
ROC train: 0.984914	val: 0.706272	test: 0.763090
PRC train: 0.812623	val: 0.255433	test: 0.157314

Epoch: 111
Loss: 0.06988234237639314
ROC train: 0.982831	val: 0.704211	test: 0.762502
PRC train: 0.808540	val: 0.255785	test: 0.146388

Epoch: 112
Loss: 0.06849967595003933
ROC train: 0.984059	val: 0.699250	test: 0.765736
PRC train: 0.814593	val: 0.233424	test: 0.145873

Epoch: 113
Loss: 0.07015854514048078
ROC train: 0.984671	val: 0.711728	test: 0.782667
PRC train: 0.809577	val: 0.266526	test: 0.177827

Epoch: 114
Loss: 0.0686490678135364
ROC train: 0.985191	val: 0.714038	test: 0.752340
PRC train: 0.814126	val: 0.234684	test: 0.130044

Epoch: 115
Loss: 0.06778430076906082
ROC train: 0.984972	val: 0.700398	test: 0.761985
PRC train: 0.812876	val: 0.257340	test: 0.162689

Epoch: 116
Loss: 0.0684095361538204
ROC train: 0.984525	val: 0.708936	test: 0.751085
PRC train: 0.812649	val: 0.234797	test: 0.129983

Epoch: 117
Loss: 0.06790346482436413
ROC train: 0.980972	val: 0.707224	test: 0.748966
PRC train: 0.789843	val: 0.211889	test: 0.107406

Epoch: 118
Loss: 0.06708454094205893
ROC train: 0.985402	val: 0.715097	test: 0.767737
PRC train: 0.813254	val: 0.229436	test: 0.138447

Epoch: 119
Loss: 0.06737844282090281
ROC train: 0.986563	val: 0.709981	test: 0.750619
PRC train: 0.818628	val: 0.240236	test: 0.139026

Epoch: 120
Loss: 0.06578109813894963
ROC train: 0.988197	val: 0.709850	test: 0.775910
PRC train: 0.837782	val: 0.259284	test: 0.147059

Early stopping
Best (ROC):	 train: 0.948795	val: 0.732427	test: 0.740105
Best (PRC):	 train: 0.661061	val: 0.265700	test: 0.150897

Epoch: 94
Loss: 0.07589754759448089
ROC train: 0.975493	val: 0.792653	test: 0.742770
PRC train: 0.761519	val: 0.329563	test: 0.165632

Epoch: 95
Loss: 0.07626107090896918
ROC train: 0.975070	val: 0.780420	test: 0.735258
PRC train: 0.765771	val: 0.294953	test: 0.139892

Epoch: 96
Loss: 0.07493585768042013
ROC train: 0.977014	val: 0.778672	test: 0.738373
PRC train: 0.765311	val: 0.324105	test: 0.136824

Epoch: 97
Loss: 0.07415575931799889
ROC train: 0.974896	val: 0.792904	test: 0.739145
PRC train: 0.765220	val: 0.339781	test: 0.146703

Epoch: 98
Loss: 0.07515720524644247
ROC train: 0.975805	val: 0.800286	test: 0.747558
PRC train: 0.767788	val: 0.325875	test: 0.175646

Epoch: 99
Loss: 0.07531446883721296
ROC train: 0.979424	val: 0.793920	test: 0.732397
PRC train: 0.777282	val: 0.328726	test: 0.147650

Epoch: 100
Loss: 0.07316327835937259
ROC train: 0.979311	val: 0.806713	test: 0.741100
PRC train: 0.784845	val: 0.315798	test: 0.161193

Epoch: 101
Loss: 0.07397122594290183
ROC train: 0.978039	val: 0.792827	test: 0.738776
PRC train: 0.783773	val: 0.299185	test: 0.151539

Epoch: 102
Loss: 0.07398349043954314
ROC train: 0.981821	val: 0.792466	test: 0.752535
PRC train: 0.804298	val: 0.321481	test: 0.171927

Epoch: 103
Loss: 0.0737543192354839
ROC train: 0.980176	val: 0.811174	test: 0.741637
PRC train: 0.788215	val: 0.352588	test: 0.164414

Epoch: 104
Loss: 0.07446533831667194
ROC train: 0.978892	val: 0.787426	test: 0.740346
PRC train: 0.781131	val: 0.295588	test: 0.142053

Epoch: 105
Loss: 0.07331046874017594
ROC train: 0.982014	val: 0.793054	test: 0.756884
PRC train: 0.797554	val: 0.344802	test: 0.175123

Epoch: 106
Loss: 0.07066584592312279
ROC train: 0.980951	val: 0.805954	test: 0.752763
PRC train: 0.803022	val: 0.349815	test: 0.144900

Epoch: 107
Loss: 0.0717524482808492
ROC train: 0.981367	val: 0.787156	test: 0.743944
PRC train: 0.800074	val: 0.337384	test: 0.160060

Epoch: 108
Loss: 0.07030320829670081
ROC train: 0.980914	val: 0.807047	test: 0.722109
PRC train: 0.795558	val: 0.326856	test: 0.143132

Epoch: 109
Loss: 0.07175800622494549
ROC train: 0.980387	val: 0.795659	test: 0.728703
PRC train: 0.789852	val: 0.341341	test: 0.158119

Epoch: 110
Loss: 0.07170810732730049
ROC train: 0.980858	val: 0.795157	test: 0.753002
PRC train: 0.802641	val: 0.325195	test: 0.158739

Epoch: 111
Loss: 0.06952233397225246
ROC train: 0.983099	val: 0.813936	test: 0.741708
PRC train: 0.813195	val: 0.332549	test: 0.138666

Epoch: 112
Loss: 0.07014862137713727
ROC train: 0.984634	val: 0.787460	test: 0.749037
PRC train: 0.820526	val: 0.318380	test: 0.157943

Epoch: 113
Loss: 0.06881275090033463
ROC train: 0.982939	val: 0.802849	test: 0.760863
PRC train: 0.810034	val: 0.310719	test: 0.154650

Epoch: 114
Loss: 0.06857847190716596
ROC train: 0.984626	val: 0.787622	test: 0.748621
PRC train: 0.813934	val: 0.324392	test: 0.144920

Epoch: 115
Loss: 0.06880390253907007
ROC train: 0.984302	val: 0.790038	test: 0.746111
PRC train: 0.817417	val: 0.366236	test: 0.185353

Epoch: 116
Loss: 0.068552115492063
ROC train: 0.983534	val: 0.797059	test: 0.735910
PRC train: 0.811638	val: 0.297773	test: 0.129749

Epoch: 117
Loss: 0.06806913407819
ROC train: 0.982788	val: 0.801979	test: 0.725964
PRC train: 0.803086	val: 0.326415	test: 0.123822

Epoch: 118
Loss: 0.06825943034208365
ROC train: 0.983475	val: 0.808829	test: 0.748354
PRC train: 0.815749	val: 0.315268	test: 0.149178

Epoch: 119
Loss: 0.06882571628700705
ROC train: 0.982197	val: 0.790659	test: 0.741739
PRC train: 0.800745	val: 0.299619	test: 0.135889

Epoch: 120
Loss: 0.06779203665637994
ROC train: 0.986075	val: 0.802674	test: 0.747681
PRC train: 0.825094	val: 0.331813	test: 0.158849

Early stopping
Best (ROC):	 train: 0.969520	val: 0.823731	test: 0.761853
Best (PRC):	 train: 0.738718	val: 0.358779	test: 0.168368
Epoch: 94
Loss: 0.07648462611549425
ROC train: 0.976585	val: 0.720245	test: 0.747200
PRC train: 0.771684	val: 0.250491	test: 0.122669

Epoch: 95
Loss: 0.07234990178842997
ROC train: 0.980105	val: 0.724626	test: 0.756064
PRC train: 0.787621	val: 0.239983	test: 0.125579

Epoch: 96
Loss: 0.0730341055081542
ROC train: 0.980760	val: 0.715670	test: 0.749307
PRC train: 0.791935	val: 0.249415	test: 0.130545

Epoch: 97
Loss: 0.07315421181885749
ROC train: 0.979154	val: 0.714011	test: 0.753184
PRC train: 0.781194	val: 0.249062	test: 0.123765

Epoch: 98
Loss: 0.07306146850714489
ROC train: 0.980622	val: 0.729134	test: 0.759118
PRC train: 0.794286	val: 0.241833	test: 0.173976

Epoch: 99
Loss: 0.07271344078564726
ROC train: 0.980852	val: 0.729084	test: 0.755046
PRC train: 0.784512	val: 0.268143	test: 0.135149

Epoch: 100
Loss: 0.07300396058567583
ROC train: 0.980258	val: 0.717552	test: 0.753716
PRC train: 0.796185	val: 0.259622	test: 0.137193

Epoch: 101
Loss: 0.0735838989375504
ROC train: 0.981547	val: 0.728619	test: 0.761660
PRC train: 0.801307	val: 0.261236	test: 0.154422

Epoch: 102
Loss: 0.07158364700693624
ROC train: 0.981601	val: 0.723340	test: 0.754519
PRC train: 0.797737	val: 0.266681	test: 0.149210

Epoch: 103
Loss: 0.07300391343548779
ROC train: 0.981677	val: 0.727140	test: 0.754943
PRC train: 0.802451	val: 0.246122	test: 0.132444

Epoch: 104
Loss: 0.06876320003711575
ROC train: 0.980908	val: 0.719621	test: 0.774106
PRC train: 0.798369	val: 0.266383	test: 0.150697

Epoch: 105
Loss: 0.07145395840314485
ROC train: 0.982598	val: 0.721490	test: 0.757194
PRC train: 0.803675	val: 0.270889	test: 0.153740

Epoch: 106
Loss: 0.06838054110396394
ROC train: 0.982603	val: 0.718446	test: 0.755273
PRC train: 0.802225	val: 0.271710	test: 0.141810

Epoch: 107
Loss: 0.07039000077857749
ROC train: 0.982718	val: 0.729081	test: 0.746071
PRC train: 0.812559	val: 0.241916	test: 0.140867

Epoch: 108
Loss: 0.07028540308743941
ROC train: 0.983894	val: 0.736560	test: 0.747398
PRC train: 0.811444	val: 0.301640	test: 0.149396

Epoch: 109
Loss: 0.06853417012741864
ROC train: 0.984840	val: 0.722207	test: 0.747530
PRC train: 0.817598	val: 0.224936	test: 0.121211

Epoch: 110
Loss: 0.06879764641772863
ROC train: 0.985256	val: 0.726047	test: 0.745108
PRC train: 0.822933	val: 0.252957	test: 0.139488

Epoch: 111
Loss: 0.06808636103654742
ROC train: 0.984491	val: 0.730137	test: 0.759284
PRC train: 0.813994	val: 0.261063	test: 0.147817

Epoch: 112
Loss: 0.06897808973215899
ROC train: 0.986465	val: 0.720619	test: 0.747754
PRC train: 0.829240	val: 0.225519	test: 0.114118

Epoch: 113
Loss: 0.07074149814748311
ROC train: 0.986332	val: 0.731641	test: 0.764442
PRC train: 0.827541	val: 0.260348	test: 0.142443

Epoch: 114
Loss: 0.06696904420081659
ROC train: 0.984117	val: 0.734433	test: 0.762496
PRC train: 0.817601	val: 0.257308	test: 0.135525

Epoch: 115
Loss: 0.0677621084742639
ROC train: 0.986212	val: 0.725489	test: 0.749915
PRC train: 0.827405	val: 0.240010	test: 0.120650

Epoch: 116
Loss: 0.06785374371766197
ROC train: 0.984896	val: 0.729722	test: 0.760090
PRC train: 0.826188	val: 0.235276	test: 0.148706

Epoch: 117
Loss: 0.06589745450666237
ROC train: 0.986385	val: 0.721107	test: 0.744126
PRC train: 0.828710	val: 0.250891	test: 0.127853

Epoch: 118
Loss: 0.0683123142765617
ROC train: 0.985284	val: 0.725451	test: 0.761436
PRC train: 0.809302	val: 0.259081	test: 0.185193

Epoch: 119
Loss: 0.0671889618238499
ROC train: 0.986487	val: 0.719948	test: 0.745929
PRC train: 0.823705	val: 0.242376	test: 0.125112

Epoch: 120
Loss: 0.0676855459339652
ROC train: 0.986576	val: 0.722095	test: 0.749621
PRC train: 0.837778	val: 0.234691	test: 0.098545

Epoch: 121
Loss: 0.06527518199419247
ROC train: 0.986912	val: 0.721829	test: 0.748488
PRC train: 0.839185	val: 0.242008	test: 0.116243

Epoch: 122
Loss: 0.06727564055039767
ROC train: 0.987558	val: 0.720645	test: 0.757787
PRC train: 0.839364	val: 0.261517	test: 0.140112

Epoch: 123
Loss: 0.06412751695603486
ROC train: 0.987873	val: 0.728289	test: 0.749645
PRC train: 0.842625	val: 0.260578	test: 0.142114

Epoch: 124
Loss: 0.06546665471390319
ROC train: 0.988519	val: 0.737760	test: 0.769091
PRC train: 0.845930	val: 0.258820	test: 0.156543

Epoch: 125
Loss: 0.06458346609985932
ROC train: 0.987087	val: 0.719971	test: 0.747811
PRC train: 0.838217	val: 0.246927	test: 0.125395

Epoch: 126
Loss: 0.06664759355616275
ROC train: 0.987849	val: 0.723805	test: 0.749868
PRC train: 0.846925	val: 0.227371	test: 0.111064

Epoch: 127
Loss: 0.06502783282989048
ROC train: 0.986745	val: 0.735088	test: 0.754161
PRC train: 0.839117	val: 0.256812	test: 0.129870

Epoch: 128
Loss: 0.06408333571988396
ROC train: 0.987315	val: 0.733890	test: 0.757109
PRC train: 0.841840	val: 0.238659	test: 0.138898

Epoch: 129
Loss: 0.06294141809737396
ROC train: 0.987425	val: 0.727081	test: 0.754077
PRC train: 0.843671	val: 0.253043	test: 0.125746

Epoch: 130
Loss: 0.06390005093584687
ROC train: 0.987947	val: 0.727086	test: 0.751512
PRC train: 0.839875	val: 0.269409	test: 0.146508

Epoch: 131
Loss: 0.06409847400165601
ROC train: 0.989328	val: 0.721644	test: 0.755171
PRC train: 0.852119	val: 0.245417	test: 0.125715

Epoch: 132
Loss: 0.06262320487639292
ROC train: 0.988709	val: 0.727053	test: 0.741565
PRC train: 0.849355	val: 0.220825	test: 0.104469

Epoch: 133
Loss: 0.06204766740366637
ROC train: 0.988025	val: 0.727967	test: 0.761625
PRC train: 0.845992	val: 0.224073	test: 0.146601

Epoch: 134
Loss: 0.06370622532607532
ROC train: 0.989797	val: 0.713146	test: 0.753047
PRC train: 0.860998	val: 0.215524	test: 0.101953

Epoch: 135
Loss: 0.06099021756488009
ROC train: 0.990525	val: 0.721967	test: 0.760948
PRC train: 0.866036	val: 0.255419	test: 0.125505

Epoch: 136
Loss: 0.06065435084086533
ROC train: 0.989220	val: 0.713249	test: 0.756878
PRC train: 0.853894	val: 0.225645	test: 0.135589

Epoch: 137
Loss: 0.06112256509493966
ROC train: 0.988856	val: 0.728623	test: 0.769608
PRC train: 0.846263	val: 0.243339	test: 0.121712

Epoch: 138
Loss: 0.06277588885991378
ROC train: 0.989492	val: 0.715941	test: 0.746067
PRC train: 0.857229	val: 0.230164	test: 0.112694

Epoch: 139
Loss: 0.06189659329784882
ROC train: 0.988171	val: 0.723255	test: 0.757034
PRC train: 0.844087	val: 0.264842	test: 0.130165

Epoch: 140
Loss: 0.06049159822208758
ROC train: 0.991277	val: 0.719930	test: 0.746719
PRC train: 0.865239	val: 0.239274	test: 0.145545

Epoch: 141
Loss: 0.060355582767163685
ROC train: 0.989772	val: 0.710102	test: 0.755736
PRC train: 0.861426	val: 0.240685	test: 0.112429

Epoch: 142
Loss: 0.059779662113602944
ROC train: 0.991109	val: 0.724613	test: 0.758121
PRC train: 0.872907	val: 0.251747	test: 0.136829

Epoch: 143
Loss: 0.060873278861534846
ROC train: 0.991089	val: 0.740432	test: 0.755502
PRC train: 0.871218	val: 0.235569	test: 0.112997

Epoch: 144
Loss: 0.0598504462632794
ROC train: 0.991284	val: 0.727440	test: 0.754525
PRC train: 0.870618	val: 0.237425	test: 0.149093

Epoch: 145
Loss: 0.05953012416703128
ROC train: 0.988860	val: 0.733224	test: 0.749611
PRC train: 0.858040	val: 0.235638	test: 0.134270

Epoch: 146
Loss: 0.058523924423579905
ROC train: 0.990297	val: 0.721568	test: 0.756600
PRC train: 0.864902	val: 0.204861	test: 0.136252

Epoch: 147
Loss: 0.05992725463653365
ROC train: 0.991695	val: 0.727823	test: 0.749534
PRC train: 0.879194	val: 0.240113	test: 0.129303

Epoch: 148
Loss: 0.06037549306792323
ROC train: 0.990451	val: 0.725937	test: 0.743687
PRC train: 0.866948	val: 0.229429	test: 0.122000

Epoch: 149
Loss: 0.058081384614307785
ROC train: 0.991297	val: 0.726397	test: 0.759668
PRC train: 0.870252	val: 0.231526	test: 0.126054

Epoch: 150
Loss: 0.05831530331707811
ROC train: 0.991771	val: 0.711894	test: 0.752498
PRC train: 0.874720	val: 0.225425	test: 0.099277

Epoch: 151
Loss: 0.05837668282995495
ROC train: 0.992446	val: 0.715250	test: 0.751798
PRC train: 0.887048	val: 0.238238	test: 0.128882

Epoch: 152
Loss: 0.058339883142693914
ROC train: 0.992786	val: 0.723818	test: 0.763056
PRC train: 0.888366	val: 0.253279	test: 0.145241

Epoch: 153
Loss: 0.05904598254984449
ROC train: 0.992991	val: 0.729068	test: 0.741978
PRC train: 0.892125	val: 0.259044	test: 0.134116

Epoch: 154
Loss: 0.057120758131475415
ROC train: 0.991624	val: 0.720239	test: 0.753946
ROC train: 0.977683	val: 0.713119	test: 0.756144
PRC train: 0.775619	val: 0.270788	test: 0.161053

Epoch: 95
Loss: 0.07449035265606
ROC train: 0.980200	val: 0.716835	test: 0.758312
PRC train: 0.787298	val: 0.278492	test: 0.166269

Epoch: 96
Loss: 0.07421475817870377
ROC train: 0.973002	val: 0.701600	test: 0.742614
PRC train: 0.740064	val: 0.254913	test: 0.157009

Epoch: 97
Loss: 0.07581409305480498
ROC train: 0.980190	val: 0.715205	test: 0.755781
PRC train: 0.786742	val: 0.244393	test: 0.147994

Epoch: 98
Loss: 0.07317042102670193
ROC train: 0.979496	val: 0.723660	test: 0.747227
PRC train: 0.781633	val: 0.243881	test: 0.176424

Epoch: 99
Loss: 0.0720810435067375
ROC train: 0.979535	val: 0.706643	test: 0.751879
PRC train: 0.786156	val: 0.272501	test: 0.186052

Epoch: 100
Loss: 0.07139495143943135
ROC train: 0.980834	val: 0.707719	test: 0.728659
PRC train: 0.786397	val: 0.236094	test: 0.097180

Epoch: 101
Loss: 0.07232232498599968
ROC train: 0.980601	val: 0.717015	test: 0.750521
PRC train: 0.793822	val: 0.256124	test: 0.158399

Epoch: 102
Loss: 0.07184066460168155
ROC train: 0.980768	val: 0.709124	test: 0.744236
PRC train: 0.793183	val: 0.261390	test: 0.136095

Epoch: 103
Loss: 0.07095939284763218
ROC train: 0.982080	val: 0.719482	test: 0.756711
PRC train: 0.796725	val: 0.277849	test: 0.147218

Epoch: 104
Loss: 0.07028293838850777
ROC train: 0.981409	val: 0.708148	test: 0.750920
PRC train: 0.784531	val: 0.287631	test: 0.185266

Epoch: 105
Loss: 0.07224055708096896
ROC train: 0.980213	val: 0.686905	test: 0.727501
PRC train: 0.787022	val: 0.273060	test: 0.142042

Epoch: 106
Loss: 0.06987998000373435
ROC train: 0.984206	val: 0.714855	test: 0.754095
PRC train: 0.816554	val: 0.253466	test: 0.158024

Epoch: 107
Loss: 0.07019155598059819
ROC train: 0.983255	val: 0.718260	test: 0.740159
PRC train: 0.809161	val: 0.280802	test: 0.170713

Epoch: 108
Loss: 0.06861918621180858
ROC train: 0.984311	val: 0.709590	test: 0.746086
PRC train: 0.818388	val: 0.276148	test: 0.152295

Epoch: 109
Loss: 0.06924232201390196
ROC train: 0.979636	val: 0.697699	test: 0.741669
PRC train: 0.789878	val: 0.263030	test: 0.160770

Epoch: 110
Loss: 0.07194336776649683
ROC train: 0.981574	val: 0.721099	test: 0.750938
PRC train: 0.806070	val: 0.270806	test: 0.143163

Epoch: 111
Loss: 0.06779871467687977
ROC train: 0.983034	val: 0.716257	test: 0.740839
PRC train: 0.806451	val: 0.227617	test: 0.132308

Epoch: 112
Loss: 0.06927743544877941
ROC train: 0.982958	val: 0.725680	test: 0.749753
PRC train: 0.807697	val: 0.265552	test: 0.155873

Epoch: 113
Loss: 0.06944974296982208
ROC train: 0.983493	val: 0.706447	test: 0.737846
PRC train: 0.809056	val: 0.247978	test: 0.124805

Epoch: 114
Loss: 0.06864082485579999
ROC train: 0.981686	val: 0.692108	test: 0.716014
PRC train: 0.796937	val: 0.233531	test: 0.109392

Epoch: 115
Loss: 0.06743106678320712
ROC train: 0.983687	val: 0.695682	test: 0.746673
PRC train: 0.806726	val: 0.206275	test: 0.106603

Epoch: 116
Loss: 0.06606747874340663
ROC train: 0.984234	val: 0.723302	test: 0.756717
PRC train: 0.813632	val: 0.264958	test: 0.136344

Epoch: 117
Loss: 0.06783703473494473
ROC train: 0.986243	val: 0.727168	test: 0.744394
PRC train: 0.822586	val: 0.216449	test: 0.115849

Epoch: 118
Loss: 0.0680820327332991
ROC train: 0.985424	val: 0.714420	test: 0.740565
PRC train: 0.822813	val: 0.267877	test: 0.137020

Epoch: 119
Loss: 0.0670356940032223
ROC train: 0.988663	val: 0.716166	test: 0.743919
PRC train: 0.848212	val: 0.261129	test: 0.146408

Epoch: 120
Loss: 0.06578726023289107
ROC train: 0.985998	val: 0.730549	test: 0.753174
PRC train: 0.825462	val: 0.248508	test: 0.145042

Epoch: 121
Loss: 0.06545073098273846
ROC train: 0.985439	val: 0.710650	test: 0.736568
PRC train: 0.828702	val: 0.259849	test: 0.130450

Epoch: 122
Loss: 0.06766283439826082
ROC train: 0.987016	val: 0.723424	test: 0.743676
PRC train: 0.839939	val: 0.225156	test: 0.132885

Epoch: 123
Loss: 0.06504614472262478
ROC train: 0.987087	val: 0.720742	test: 0.744146
PRC train: 0.835084	val: 0.265226	test: 0.163118

Epoch: 124
Loss: 0.06409006623086871
ROC train: 0.987245	val: 0.716041	test: 0.743029
PRC train: 0.834118	val: 0.243470	test: 0.131640

Epoch: 125
Loss: 0.06487904977250608
ROC train: 0.988129	val: 0.710961	test: 0.741669
PRC train: 0.849181	val: 0.263109	test: 0.140293

Epoch: 126
Loss: 0.06546851316785668
ROC train: 0.988386	val: 0.713027	test: 0.758180
PRC train: 0.849008	val: 0.279298	test: 0.138938

Epoch: 127
Loss: 0.06411573738737761
ROC train: 0.987549	val: 0.705996	test: 0.722133
PRC train: 0.846402	val: 0.227400	test: 0.107883

Epoch: 128
Loss: 0.06450614389893698
ROC train: 0.989105	val: 0.712927	test: 0.735720
PRC train: 0.850307	val: 0.261537	test: 0.143329

Epoch: 129
Loss: 0.06283556967913045
ROC train: 0.988023	val: 0.704805	test: 0.720229
PRC train: 0.843093	val: 0.233233	test: 0.119558

Epoch: 130
Loss: 0.06336398797273615
ROC train: 0.988755	val: 0.715545	test: 0.744125
PRC train: 0.848917	val: 0.235219	test: 0.121683

Epoch: 131
Loss: 0.0629622687266951
ROC train: 0.989554	val: 0.711628	test: 0.747480
PRC train: 0.851506	val: 0.251334	test: 0.132567

Epoch: 132
Loss: 0.0630609965177988
ROC train: 0.989089	val: 0.705341	test: 0.732959
PRC train: 0.854950	val: 0.251475	test: 0.125299

Epoch: 133
Loss: 0.06263186121914092
ROC train: 0.988588	val: 0.697632	test: 0.747338
PRC train: 0.846706	val: 0.235324	test: 0.113329

Epoch: 134
Loss: 0.06301309522026974
ROC train: 0.988601	val: 0.723269	test: 0.747344
PRC train: 0.854110	val: 0.259543	test: 0.144714

Epoch: 135
Loss: 0.06296891302155702
ROC train: 0.989457	val: 0.707576	test: 0.739177
PRC train: 0.856191	val: 0.259516	test: 0.134417

Epoch: 136
Loss: 0.062412571478773174
ROC train: 0.989794	val: 0.712420	test: 0.732436
PRC train: 0.857406	val: 0.241028	test: 0.121581

Epoch: 137
Loss: 0.06360212595592894
ROC train: 0.989713	val: 0.702877	test: 0.726959
PRC train: 0.862416	val: 0.243055	test: 0.117087

Epoch: 138
Loss: 0.05957770059642077
ROC train: 0.990241	val: 0.695360	test: 0.739592
PRC train: 0.864349	val: 0.219684	test: 0.116534

Epoch: 139
Loss: 0.06087702657833651
ROC train: 0.990753	val: 0.717251	test: 0.747439
PRC train: 0.864665	val: 0.252153	test: 0.122146

Epoch: 140
Loss: 0.06054129881366959
ROC train: 0.990372	val: 0.708851	test: 0.734805
PRC train: 0.863125	val: 0.239117	test: 0.113603

Epoch: 141
Loss: 0.05985865822815255
ROC train: 0.990445	val: 0.718863	test: 0.760746
PRC train: 0.866979	val: 0.235756	test: 0.140024

Epoch: 142
Loss: 0.06246811037250227
ROC train: 0.989937	val: 0.709930	test: 0.733422
PRC train: 0.859267	val: 0.240243	test: 0.123138

Epoch: 143
Loss: 0.059120632660257355
ROC train: 0.990930	val: 0.717735	test: 0.764576
PRC train: 0.866431	val: 0.267649	test: 0.154069

Epoch: 144
Loss: 0.06250418338149684
ROC train: 0.990277	val: 0.727769	test: 0.754430
PRC train: 0.866553	val: 0.252025	test: 0.127848

Epoch: 145
Loss: 0.060030766422753006
ROC train: 0.989757	val: 0.706404	test: 0.748205
PRC train: 0.858409	val: 0.254369	test: 0.138706

Epoch: 146
Loss: 0.058851616440126514
ROC train: 0.991262	val: 0.703251	test: 0.738456
PRC train: 0.870862	val: 0.247122	test: 0.135320

Epoch: 147
Loss: 0.06037371572932015
ROC train: 0.991131	val: 0.707961	test: 0.758666
PRC train: 0.874777	val: 0.254856	test: 0.135747

Epoch: 148
Loss: 0.058589847143285294
ROC train: 0.991700	val: 0.710061	test: 0.758390
PRC train: 0.879235	val: 0.244234	test: 0.135988

Epoch: 149
Loss: 0.05863264799428157
ROC train: 0.990604	val: 0.718414	test: 0.756295
PRC train: 0.867558	val: 0.241417	test: 0.141488

Epoch: 150
Loss: 0.05924756280123677
ROC train: 0.990593	val: 0.718388	test: 0.748556
PRC train: 0.867580	val: 0.239200	test: 0.110446

Epoch: 151
Loss: 0.06057714618930894
ROC train: 0.990573	val: 0.720402	test: 0.748598
PRC train: 0.868031	val: 0.272252	test: 0.126375

Epoch: 152
Loss: 0.05741121905570349
ROC train: 0.991543	val: 0.717762	test: 0.757365
PRC train: 0.873529	val: 0.268221	test: 0.128162

Epoch: 153
Loss: 0.05720445464187642
ROC train: 0.991181	val: 0.713843	test: 0.736150
PRC train: 0.873897	val: 0.228176	test: 0.106412

Epoch: 154
Loss: 0.05808044014211195
ROC train: 0.992240	val: 0.717312	test: 0.749932
ROC train: 0.975696	val: 0.787178	test: 0.753737
PRC train: 0.770974	val: 0.293426	test: 0.221365

Epoch: 95
Loss: 0.07686870245702218
ROC train: 0.977116	val: 0.780044	test: 0.752602
PRC train: 0.772070	val: 0.304552	test: 0.186018

Epoch: 96
Loss: 0.07575344086008444
ROC train: 0.976736	val: 0.781820	test: 0.760696
PRC train: 0.767248	val: 0.305706	test: 0.170283

Epoch: 97
Loss: 0.07490218364889509
ROC train: 0.977291	val: 0.786137	test: 0.745250
PRC train: 0.778672	val: 0.305914	test: 0.160908

Epoch: 98
Loss: 0.07647222631328787
ROC train: 0.974400	val: 0.778167	test: 0.740767
PRC train: 0.759434	val: 0.291597	test: 0.128279

Epoch: 99
Loss: 0.07438872942066248
ROC train: 0.974162	val: 0.781428	test: 0.749733
PRC train: 0.763612	val: 0.289309	test: 0.145571

Epoch: 100
Loss: 0.0751610977184241
ROC train: 0.975722	val: 0.804190	test: 0.746364
PRC train: 0.772529	val: 0.314872	test: 0.153601

Epoch: 101
Loss: 0.07440029348790703
ROC train: 0.979223	val: 0.791991	test: 0.749808
PRC train: 0.783818	val: 0.282814	test: 0.147521

Epoch: 102
Loss: 0.07426375042554594
ROC train: 0.977025	val: 0.799566	test: 0.754091
PRC train: 0.780089	val: 0.276354	test: 0.134547

Epoch: 103
Loss: 0.07406448014881355
ROC train: 0.980722	val: 0.787257	test: 0.747886
PRC train: 0.795383	val: 0.262745	test: 0.166510

Epoch: 104
Loss: 0.073209647339764
ROC train: 0.978932	val: 0.798504	test: 0.763933
PRC train: 0.781676	val: 0.332364	test: 0.180586

Epoch: 105
Loss: 0.07162799758596214
ROC train: 0.979743	val: 0.792573	test: 0.737044
PRC train: 0.788340	val: 0.287347	test: 0.107059

Epoch: 106
Loss: 0.0720483673829909
ROC train: 0.978908	val: 0.781382	test: 0.741982
PRC train: 0.775400	val: 0.285061	test: 0.144864

Epoch: 107
Loss: 0.07315469214346668
ROC train: 0.980914	val: 0.806612	test: 0.759756
PRC train: 0.787745	val: 0.326490	test: 0.172753

Epoch: 108
Loss: 0.07433503239890805
ROC train: 0.981844	val: 0.801391	test: 0.748661
PRC train: 0.798155	val: 0.304453	test: 0.136286

Epoch: 109
Loss: 0.07027103802603324
ROC train: 0.979654	val: 0.803997	test: 0.745874
PRC train: 0.791654	val: 0.314913	test: 0.156861

Epoch: 110
Loss: 0.07287953569668784
ROC train: 0.981123	val: 0.785705	test: 0.747527
PRC train: 0.796884	val: 0.296256	test: 0.158675

Epoch: 111
Loss: 0.07115327227901654
ROC train: 0.981853	val: 0.801174	test: 0.760588
PRC train: 0.803644	val: 0.297669	test: 0.183901

Epoch: 112
Loss: 0.07012279262885192
ROC train: 0.981127	val: 0.790613	test: 0.736590
PRC train: 0.805254	val: 0.305439	test: 0.139306

Epoch: 113
Loss: 0.07322863466568431
ROC train: 0.980125	val: 0.788724	test: 0.738595
PRC train: 0.788101	val: 0.280388	test: 0.122854

Epoch: 114
Loss: 0.07108581099538491
ROC train: 0.981537	val: 0.783990	test: 0.740049
PRC train: 0.803143	val: 0.272107	test: 0.131955

Epoch: 115
Loss: 0.07188003657483326
ROC train: 0.984317	val: 0.793066	test: 0.756674
PRC train: 0.823415	val: 0.296936	test: 0.147615

Epoch: 116
Loss: 0.07103071263782629
ROC train: 0.982321	val: 0.787098	test: 0.749914
PRC train: 0.810932	val: 0.301994	test: 0.170305

Epoch: 117
Loss: 0.06756294150482949
ROC train: 0.982366	val: 0.792368	test: 0.749789
PRC train: 0.809156	val: 0.305745	test: 0.148609

Epoch: 118
Loss: 0.06990224951608301
ROC train: 0.981712	val: 0.786792	test: 0.747110
PRC train: 0.808691	val: 0.295176	test: 0.168364

Epoch: 119
Loss: 0.06831534640144195
ROC train: 0.982941	val: 0.774541	test: 0.750493
PRC train: 0.807594	val: 0.251939	test: 0.130040

Epoch: 120
Loss: 0.06808355368481651
ROC train: 0.985125	val: 0.772744	test: 0.735845
PRC train: 0.824386	val: 0.304415	test: 0.149164

Epoch: 121
Loss: 0.06690238302425018
ROC train: 0.984167	val: 0.769762	test: 0.734987
PRC train: 0.818146	val: 0.262379	test: 0.116117

Epoch: 122
Loss: 0.07027020609828243
ROC train: 0.983502	val: 0.778412	test: 0.746967
PRC train: 0.808829	val: 0.276408	test: 0.154319

Epoch: 123
Loss: 0.06715473600633916
ROC train: 0.984700	val: 0.793170	test: 0.744698
PRC train: 0.819576	val: 0.286340	test: 0.141671

Epoch: 124
Loss: 0.06720299998732907
ROC train: 0.984053	val: 0.780304	test: 0.725543
PRC train: 0.823078	val: 0.302209	test: 0.113910

Epoch: 125
Loss: 0.0679217129497423
ROC train: 0.984859	val: 0.786777	test: 0.751449
PRC train: 0.824268	val: 0.283558	test: 0.162765

Epoch: 126
Loss: 0.06435765455644156
ROC train: 0.982822	val: 0.787530	test: 0.743904
PRC train: 0.811661	val: 0.238103	test: 0.128185

Epoch: 127
Loss: 0.06681030879453871
ROC train: 0.985940	val: 0.774903	test: 0.738740
PRC train: 0.833664	val: 0.274799	test: 0.106722

Epoch: 128
Loss: 0.06615119258460327
ROC train: 0.986545	val: 0.781853	test: 0.738987
PRC train: 0.835689	val: 0.282640	test: 0.117913

Epoch: 129
Loss: 0.06722127405554118
ROC train: 0.986787	val: 0.791449	test: 0.732355
PRC train: 0.842631	val: 0.282788	test: 0.146553

Epoch: 130
Loss: 0.06552865397098676
ROC train: 0.981613	val: 0.785307	test: 0.735261
PRC train: 0.811138	val: 0.290624	test: 0.166851

Epoch: 131
Loss: 0.06641205328306235
ROC train: 0.985282	val: 0.783853	test: 0.723707
PRC train: 0.824401	val: 0.264750	test: 0.114217

Epoch: 132
Loss: 0.06494423480940284
ROC train: 0.986537	val: 0.785558	test: 0.736202
PRC train: 0.835389	val: 0.262881	test: 0.136524

Epoch: 133
Loss: 0.06486868671752657
ROC train: 0.986767	val: 0.775184	test: 0.740192
PRC train: 0.839192	val: 0.268779	test: 0.146040

Epoch: 134
Loss: 0.06562792204443073
ROC train: 0.987204	val: 0.786210	test: 0.746470
PRC train: 0.847862	val: 0.265640	test: 0.141366

Epoch: 135
Loss: 0.06448380328455301
ROC train: 0.987826	val: 0.802938	test: 0.730609
PRC train: 0.848634	val: 0.247055	test: 0.126859

Epoch: 136
Loss: 0.0648954904960597
ROC train: 0.987970	val: 0.784079	test: 0.731246
PRC train: 0.846531	val: 0.253462	test: 0.126729

Epoch: 137
Loss: 0.06474994754169505
ROC train: 0.985991	val: 0.792738	test: 0.753929
PRC train: 0.836181	val: 0.238200	test: 0.144646

Epoch: 138
Loss: 0.0659056790057047
ROC train: 0.987206	val: 0.803819	test: 0.735383
PRC train: 0.841320	val: 0.244746	test: 0.117571

Epoch: 139
Loss: 0.06183194630965766
ROC train: 0.988488	val: 0.784061	test: 0.738510
PRC train: 0.847071	val: 0.276090	test: 0.133197

Epoch: 140
Loss: 0.0643366033411878
ROC train: 0.988099	val: 0.797729	test: 0.741957
PRC train: 0.849998	val: 0.271486	test: 0.153913

Epoch: 141
Loss: 0.06361232305758217
ROC train: 0.987836	val: 0.797451	test: 0.735526
PRC train: 0.843663	val: 0.272646	test: 0.136687

Epoch: 142
Loss: 0.06268493662592102
ROC train: 0.988752	val: 0.797521	test: 0.737666
PRC train: 0.856436	val: 0.275470	test: 0.153218

Early stopping
Best (ROC):	 train: 0.980914	val: 0.806612	test: 0.759756
Best (PRC):	 train: 0.787745	val: 0.326490	test: 0.172753

PRC train: 0.879664	val: 0.228709	test: 0.110195

Epoch: 155
Loss: 0.0599049898330115
ROC train: 0.992227	val: 0.705934	test: 0.740805
PRC train: 0.879182	val: 0.234616	test: 0.113112

Early stopping
Best (ROC):	 train: 0.985998	val: 0.730549	test: 0.753174
Best (PRC):	 train: 0.825462	val: 0.248508	test: 0.145042

Epoch: 94
Loss: 0.07856581978307406
ROC train: 0.972646	val: 0.811952	test: 0.763170
PRC train: 0.739662	val: 0.315560	test: 0.161688

Epoch: 95
Loss: 0.07811107479223522
ROC train: 0.970749	val: 0.790081	test: 0.767070
PRC train: 0.729656	val: 0.311711	test: 0.186031

Epoch: 96
Loss: 0.07772557505514573
ROC train: 0.971121	val: 0.794263	test: 0.748106
PRC train: 0.735988	val: 0.269088	test: 0.141188

Epoch: 97
Loss: 0.07650652149845426
ROC train: 0.976559	val: 0.808887	test: 0.741928
PRC train: 0.766605	val: 0.327007	test: 0.148698

Epoch: 98
Loss: 0.07693366006456293
ROC train: 0.974889	val: 0.804309	test: 0.754181
PRC train: 0.755034	val: 0.312761	test: 0.168877

Epoch: 99
Loss: 0.07651324627944031
ROC train: 0.973736	val: 0.793421	test: 0.757077
PRC train: 0.748919	val: 0.300796	test: 0.164145

Epoch: 100
Loss: 0.07669727116421976
ROC train: 0.974613	val: 0.801691	test: 0.759532
PRC train: 0.757024	val: 0.312583	test: 0.165724

Epoch: 101
Loss: 0.07585480143956713
ROC train: 0.974649	val: 0.786351	test: 0.754453
PRC train: 0.765381	val: 0.281398	test: 0.172436

Epoch: 102
Loss: 0.07537333732583198
ROC train: 0.975492	val: 0.801486	test: 0.756658
PRC train: 0.752732	val: 0.289347	test: 0.152192

Epoch: 103
Loss: 0.07354767897238376
ROC train: 0.979744	val: 0.794478	test: 0.749545
PRC train: 0.778715	val: 0.304231	test: 0.162547

Epoch: 104
Loss: 0.07567754543085474
ROC train: 0.978707	val: 0.799557	test: 0.748867
PRC train: 0.782803	val: 0.310306	test: 0.161522

Epoch: 105
Loss: 0.0726907322828207
ROC train: 0.977149	val: 0.811101	test: 0.762724
PRC train: 0.762007	val: 0.281186	test: 0.149624

Epoch: 106
Loss: 0.07587245826794718
ROC train: 0.979303	val: 0.785803	test: 0.736546
PRC train: 0.778122	val: 0.273132	test: 0.143647

Epoch: 107
Loss: 0.07301889073328871
ROC train: 0.975499	val: 0.814415	test: 0.739414
PRC train: 0.762749	val: 0.276128	test: 0.162903

Epoch: 108
Loss: 0.074278456960401
ROC train: 0.979894	val: 0.785714	test: 0.766316
PRC train: 0.777592	val: 0.283739	test: 0.136215

Epoch: 109
Loss: 0.0727527908679746
ROC train: 0.980837	val: 0.798507	test: 0.744022
PRC train: 0.792999	val: 0.276065	test: 0.136817

Epoch: 110
Loss: 0.07350042818339221
ROC train: 0.978124	val: 0.794915	test: 0.772883
PRC train: 0.775080	val: 0.264551	test: 0.151340

Epoch: 111
Loss: 0.07399747588138376
ROC train: 0.979988	val: 0.784998	test: 0.752140
PRC train: 0.788969	val: 0.243595	test: 0.149295

Epoch: 112
Loss: 0.070780313514152
ROC train: 0.981036	val: 0.800044	test: 0.779967
PRC train: 0.789899	val: 0.241734	test: 0.182448

Epoch: 113
Loss: 0.07129741281720567
ROC train: 0.982692	val: 0.780050	test: 0.770276
PRC train: 0.800645	val: 0.280388	test: 0.151282

Epoch: 114
Loss: 0.07235652128522205
ROC train: 0.982163	val: 0.783053	test: 0.767974
PRC train: 0.794863	val: 0.236044	test: 0.146282

Epoch: 115
Loss: 0.0728152095996022
ROC train: 0.981269	val: 0.802769	test: 0.775320
PRC train: 0.788470	val: 0.288548	test: 0.162927

Epoch: 116
Loss: 0.07064356499944698
ROC train: 0.981534	val: 0.804937	test: 0.762070
PRC train: 0.788950	val: 0.284375	test: 0.178314

Epoch: 117
Loss: 0.0721794352913039
ROC train: 0.984082	val: 0.796740	test: 0.752803
PRC train: 0.809580	val: 0.285584	test: 0.177719

Epoch: 118
Loss: 0.07082873221542478
ROC train: 0.981915	val: 0.785766	test: 0.755866
PRC train: 0.799460	val: 0.273616	test: 0.173710

Epoch: 119
Loss: 0.0704027983470394
ROC train: 0.979180	val: 0.808415	test: 0.739960
PRC train: 0.782182	val: 0.277960	test: 0.127425

Epoch: 120
Loss: 0.07035537399400385
ROC train: 0.983473	val: 0.787086	test: 0.742666
PRC train: 0.810380	val: 0.256758	test: 0.151216

Epoch: 121
Loss: 0.06937493906478501
ROC train: 0.983348	val: 0.796097	test: 0.752311
PRC train: 0.808923	val: 0.231527	test: 0.152847

Epoch: 122
Loss: 0.07104012894811264
ROC train: 0.984853	val: 0.796351	test: 0.752390
PRC train: 0.820713	val: 0.266049	test: 0.125940

Epoch: 123
Loss: 0.06869469983754353
ROC train: 0.982741	val: 0.797800	test: 0.758472
PRC train: 0.807224	val: 0.275729	test: 0.161152

Epoch: 124
Loss: 0.06891558228235
ROC train: 0.983444	val: 0.785705	test: 0.744114
PRC train: 0.807478	val: 0.233039	test: 0.142915

Epoch: 125
Loss: 0.06754554461956518
ROC train: 0.983097	val: 0.759847	test: 0.752259
PRC train: 0.798965	val: 0.255344	test: 0.142711

Epoch: 126
Loss: 0.06890428427418499
ROC train: 0.984269	val: 0.774557	test: 0.747745
PRC train: 0.810237	val: 0.227983	test: 0.146795

Epoch: 127
Loss: 0.06777684098777487
ROC train: 0.984481	val: 0.787980	test: 0.766751
PRC train: 0.811515	val: 0.294321	test: 0.184558

Epoch: 128
Loss: 0.06845786878711736
ROC train: 0.984114	val: 0.791768	test: 0.735460
PRC train: 0.810426	val: 0.243151	test: 0.129511

Epoch: 129
Loss: 0.06838457485186018
ROC train: 0.986025	val: 0.802365	test: 0.738473
PRC train: 0.823231	val: 0.259387	test: 0.133212

Epoch: 130
Loss: 0.06754239717447541
ROC train: 0.987344	val: 0.790895	test: 0.756241
PRC train: 0.837907	val: 0.243273	test: 0.136509

Epoch: 131
Loss: 0.0676868315861604
ROC train: 0.986331	val: 0.824870	test: 0.757859
PRC train: 0.832484	val: 0.267888	test: 0.150456

Epoch: 132
Loss: 0.06777805463361643
ROC train: 0.987262	val: 0.782343	test: 0.758603
PRC train: 0.835981	val: 0.274635	test: 0.183891

Epoch: 133
Loss: 0.06563165902594204
ROC train: 0.986162	val: 0.796673	test: 0.749335
PRC train: 0.827181	val: 0.256835	test: 0.146011

Epoch: 134
Loss: 0.066513989238468
ROC train: 0.987413	val: 0.820978	test: 0.754989
PRC train: 0.838420	val: 0.286246	test: 0.153520

Epoch: 135
Loss: 0.06610024190805158
ROC train: 0.987147	val: 0.812374	test: 0.746077
PRC train: 0.833184	val: 0.303395	test: 0.157874

Epoch: 136
Loss: 0.06534454069638385
ROC train: 0.986185	val: 0.804086	test: 0.755851
PRC train: 0.830687	val: 0.257689	test: 0.160544

Epoch: 137
Loss: 0.06743776986574727
ROC train: 0.986126	val: 0.814646	test: 0.747525
PRC train: 0.827135	val: 0.293633	test: 0.165107

Epoch: 138
Loss: 0.06736184016390534
ROC train: 0.986677	val: 0.803244	test: 0.733460
PRC train: 0.829692	val: 0.268524	test: 0.156792

Epoch: 139
Loss: 0.06423499832282498
ROC train: 0.986128	val: 0.806741	test: 0.740503
PRC train: 0.835171	val: 0.264705	test: 0.143409

Epoch: 140
Loss: 0.06487578329765444
ROC train: 0.987272	val: 0.807935	test: 0.749632
PRC train: 0.834027	val: 0.260659	test: 0.139114

Epoch: 141
Loss: 0.06503407781835609
ROC train: 0.987356	val: 0.802996	test: 0.747177
PRC train: 0.840433	val: 0.265798	test: 0.139788

Epoch: 142
Loss: 0.06343413047921165
ROC train: 0.988636	val: 0.788641	test: 0.741314
PRC train: 0.840030	val: 0.259460	test: 0.123471

Epoch: 143
Loss: 0.06367800780896653
ROC train: 0.989015	val: 0.810608	test: 0.754362
PRC train: 0.845856	val: 0.234946	test: 0.133976

Epoch: 144
Loss: 0.06324875302316023
ROC train: 0.988085	val: 0.799144	test: 0.758902
PRC train: 0.839284	val: 0.278125	test: 0.162190

Epoch: 145
Loss: 0.06198856707364131
ROC train: 0.988496	val: 0.803807	test: 0.747197
PRC train: 0.849532	val: 0.231603	test: 0.134955

Epoch: 146
Loss: 0.06351083432175703
ROC train: 0.987840	val: 0.821125	test: 0.751312
PRC train: 0.836560	val: 0.318233	test: 0.151236

Epoch: 147
Loss: 0.06263418268993388
ROC train: 0.988608	val: 0.801100	test: 0.759250
PRC train: 0.845503	val: 0.273940	test: 0.149140

Epoch: 148
Loss: 0.062310153174239366
ROC train: 0.987912	val: 0.811520	test: 0.760673
PRC train: 0.845409	val: 0.263245	test: 0.159532

Epoch: 149
Loss: 0.06291318591372355
ROC train: 0.989134	val: 0.785788	test: 0.757058
PRC train: 0.857485	val: 0.250688	test: 0.158866

Epoch: 150
Loss: 0.06333402029494206
ROC train: 0.989875	val: 0.791976	test: 0.737838
PRC train: 0.859567	val: 0.248249	test: 0.135577

Epoch: 151
Loss: 0.06302707619747104
ROC train: 0.988737	val: 0.792120	test: 0.743353
PRC train: 0.843148	val: 0.252111	test: 0.146096

Epoch: 152
Loss: 0.06230805761712415
ROC train: 0.989830	val: 0.807240	test: 0.746133
PRC train: 0.856080	val: 0.238379	test: 0.132644

Epoch: 153
Loss: 0.06305736941569091
ROC train: 0.989920	val: 0.817157	test: 0.756361
PRC train: 0.858845	val: 0.238084	test: 0.140675

Epoch: 154
Loss: 0.06127811001575914
ROC train: 0.989173	val: 0.796042	test: 0.747569
PRC train: 0.876249	val: 0.235234	test: 0.110329

Epoch: 155
Loss: 0.05705688268504657
ROC train: 0.992206	val: 0.713548	test: 0.748641
PRC train: 0.886146	val: 0.229410	test: 0.116313

Epoch: 156
Loss: 0.05755918674285634
ROC train: 0.992033	val: 0.726492	test: 0.741697
PRC train: 0.876148	val: 0.216332	test: 0.112103

Epoch: 157
Loss: 0.056688797446687096
ROC train: 0.993005	val: 0.717190	test: 0.745107
PRC train: 0.887079	val: 0.237393	test: 0.111861

Epoch: 158
Loss: 0.05887229564489896
ROC train: 0.993317	val: 0.712081	test: 0.737860
PRC train: 0.889459	val: 0.228520	test: 0.113076

Epoch: 159
Loss: 0.057055777955422195
ROC train: 0.993676	val: 0.718705	test: 0.748776
PRC train: 0.896340	val: 0.249275	test: 0.118777

Epoch: 160
Loss: 0.05477738064251394
ROC train: 0.992303	val: 0.709797	test: 0.759306
PRC train: 0.888341	val: 0.220439	test: 0.136944

Epoch: 161
Loss: 0.05874289119952252
ROC train: 0.992592	val: 0.715874	test: 0.746637
PRC train: 0.885541	val: 0.234091	test: 0.114425

Epoch: 162
Loss: 0.05759846898566427
ROC train: 0.992982	val: 0.723274	test: 0.750207
PRC train: 0.889671	val: 0.214745	test: 0.115566

Epoch: 163
Loss: 0.05469643920379407
ROC train: 0.993313	val: 0.722388	test: 0.750959
PRC train: 0.894312	val: 0.232832	test: 0.139746

Epoch: 164
Loss: 0.0529215516819048
ROC train: 0.993492	val: 0.716778	test: 0.742206
PRC train: 0.896048	val: 0.251397	test: 0.111709

Epoch: 165
Loss: 0.057929584702698635
ROC train: 0.994054	val: 0.715938	test: 0.753298
PRC train: 0.903661	val: 0.231088	test: 0.125321

Epoch: 166
Loss: 0.05464717846926755
ROC train: 0.993875	val: 0.711006	test: 0.751741
PRC train: 0.903057	val: 0.221094	test: 0.125820

Epoch: 167
Loss: 0.05449176709853643
ROC train: 0.993462	val: 0.725185	test: 0.761949
PRC train: 0.891699	val: 0.242848	test: 0.135921

Epoch: 168
Loss: 0.055532963475012895
ROC train: 0.993284	val: 0.714259	test: 0.737032
PRC train: 0.895460	val: 0.248694	test: 0.126192

Epoch: 169
Loss: 0.05616811253700409
ROC train: 0.992696	val: 0.720287	test: 0.741771
PRC train: 0.884139	val: 0.223045	test: 0.112581

Epoch: 170
Loss: 0.055111122517362096
ROC train: 0.992678	val: 0.733532	test: 0.747448
PRC train: 0.883503	val: 0.243539	test: 0.134256

Epoch: 171
Loss: 0.055802370971887075
ROC train: 0.993810	val: 0.724375	test: 0.740806
PRC train: 0.900926	val: 0.229428	test: 0.125612

Epoch: 172
Loss: 0.0539793872173148
ROC train: 0.994011	val: 0.717351	test: 0.752047
PRC train: 0.905269	val: 0.250461	test: 0.131419

Epoch: 173
Loss: 0.0535140890840474
ROC train: 0.994061	val: 0.721061	test: 0.749602
PRC train: 0.903953	val: 0.251288	test: 0.128048

Epoch: 174
Loss: 0.052540559510004796
ROC train: 0.993748	val: 0.713842	test: 0.747665
PRC train: 0.900055	val: 0.204557	test: 0.105830

Epoch: 175
Loss: 0.05263099796673359
ROC train: 0.993346	val: 0.713443	test: 0.730846
PRC train: 0.890009	val: 0.206231	test: 0.098290

Epoch: 176
Loss: 0.05529216410932302
ROC train: 0.994568	val: 0.714739	test: 0.760111
PRC train: 0.909560	val: 0.241687	test: 0.114099

Epoch: 177
Loss: 0.05408523344794279
ROC train: 0.994624	val: 0.719795	test: 0.758356
PRC train: 0.908937	val: 0.231570	test: 0.127760

Epoch: 178
Loss: 0.0544459884934261
ROC train: 0.993715	val: 0.722771	test: 0.762991
PRC train: 0.897998	val: 0.236442	test: 0.120697

Early stopping
Best (ROC):	 train: 0.991089	val: 0.740432	test: 0.755502
Best (PRC):	 train: 0.871218	val: 0.235569	test: 0.112997
All runs completed.

PRC train: 0.852031	val: 0.229577	test: 0.125415

Epoch: 155
Loss: 0.06175923462405785
ROC train: 0.990818	val: 0.811141	test: 0.747533
PRC train: 0.866405	val: 0.262444	test: 0.148138

Epoch: 156
Loss: 0.060867223143301744
ROC train: 0.990122	val: 0.812794	test: 0.773043
PRC train: 0.863748	val: 0.246251	test: 0.168445

Epoch: 157
Loss: 0.061757468021447326
ROC train: 0.991083	val: 0.800586	test: 0.757577
PRC train: 0.865821	val: 0.270762	test: 0.150326

Epoch: 158
Loss: 0.06013761435511114
ROC train: 0.991752	val: 0.815890	test: 0.755102
PRC train: 0.875657	val: 0.290112	test: 0.147543

Epoch: 159
Loss: 0.06112895406018381
ROC train: 0.990822	val: 0.797791	test: 0.755594
PRC train: 0.868111	val: 0.220590	test: 0.133598

Epoch: 160
Loss: 0.05844106368939689
ROC train: 0.991432	val: 0.791177	test: 0.754259
PRC train: 0.872225	val: 0.279543	test: 0.166756

Epoch: 161
Loss: 0.05918782147243535
ROC train: 0.991359	val: 0.805580	test: 0.754866
PRC train: 0.873914	val: 0.224368	test: 0.130068

Epoch: 162
Loss: 0.06091501089398965
ROC train: 0.991749	val: 0.802984	test: 0.764949
PRC train: 0.875487	val: 0.258626	test: 0.170114

Epoch: 163
Loss: 0.05861613103567642
ROC train: 0.989796	val: 0.803856	test: 0.769022
PRC train: 0.851481	val: 0.255349	test: 0.128824

Epoch: 164
Loss: 0.058335998022814306
ROC train: 0.990828	val: 0.804334	test: 0.743970
PRC train: 0.869758	val: 0.261524	test: 0.125596

Epoch: 165
Loss: 0.059166695546024585
ROC train: 0.991781	val: 0.802529	test: 0.741826
PRC train: 0.876975	val: 0.270715	test: 0.133859

Epoch: 166
Loss: 0.05809089163555564
ROC train: 0.991396	val: 0.796159	test: 0.761077
PRC train: 0.875778	val: 0.262549	test: 0.131440

Early stopping
Best (ROC):	 train: 0.986331	val: 0.824870	test: 0.757859
Best (PRC):	 train: 0.832484	val: 0.267888	test: 0.150456
All runs completed.
