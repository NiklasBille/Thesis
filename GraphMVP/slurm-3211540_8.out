>>> Starting run for dataset: sider
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running RANDOM configs_split_experiments/GraphMVP/sider/random/train_prop=0.6.yml on cuda:0
Running RANDOM configs_split_experiments/GraphMVP/sider/random/train_prop=0.7.yml on cuda:1
Running RANDOM configs_split_experiments/GraphMVP/sider/random/train_prop=0.8.yml on cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/sider/random/train_prop=0.7.yml --runseed 4 --device cuda:1
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/sider/random/train_prop=0.7.yml --runseed 5 --device cuda:1
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/sider/random/train_prop=0.7.yml --runseed 6 --device cuda:1
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/sider/random/train_prop=0.8.yml --runseed 4 --device cuda:2
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/sider/random/train_prop=0.8.yml --runseed 5 --device cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/sider/random/train_prop=0.6.yml --runseed 4 --device cuda:0
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/sider/random/train_prop=0.8.yml --runseed 6 --device cuda:2
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/sider/random/train_prop=0.6.yml --runseed 5 --device cuda:0
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/sider/random/train_prop=0.6.yml --runseed 6 --device cuda:0
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/sider/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/sider/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/sider/random/train_prop=0.6/sider_random_6_26-05_11-07-48  ]
[ Using Seed :  6  ]
[ Using device :  cuda:0  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
randomly split
Data(edge_attr=[38, 2], edge_index=[2, 38], id=[1], x=[18, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6896393485159796
ROC train: 0.524467	val: 0.514084	test: 0.494732
PRC train: 0.580613	val: 0.596281	test: 0.558249

Epoch: 2
Loss: 0.658615317127251
ROC train: 0.544678	val: 0.521803	test: 0.503600
PRC train: 0.595134	val: 0.602053	test: 0.562636

Epoch: 3
Loss: 0.6290714665626829
ROC train: 0.561553	val: 0.528564	test: 0.514992
PRC train: 0.604759	val: 0.602800	test: 0.567927

Epoch: 4
Loss: 0.6009719656212739
ROC train: 0.580061	val: 0.544534	test: 0.532066
PRC train: 0.615499	val: 0.609081	test: 0.575112

Epoch: 5
Loss: 0.5836245246252884
ROC train: 0.601161	val: 0.562973	test: 0.545236
PRC train: 0.628275	val: 0.616873	test: 0.582066

Epoch: 6
Loss: 0.5554021243731297
ROC train: 0.622762	val: 0.585681	test: 0.561072
PRC train: 0.640814	val: 0.626244	test: 0.586994

Epoch: 7
Loss: 0.5560503802982926
ROC train: 0.638346	val: 0.598134	test: 0.568678
PRC train: 0.649928	val: 0.634234	test: 0.591113

Epoch: 8
Loss: 0.5314152891720734
ROC train: 0.651518	val: 0.605037	test: 0.575046
PRC train: 0.657429	val: 0.640192	test: 0.594726

Epoch: 9
Loss: 0.5214296915379029
ROC train: 0.661309	val: 0.608122	test: 0.577930
PRC train: 0.663814	val: 0.644998	test: 0.596562

Epoch: 10
Loss: 0.5227772763882885
ROC train: 0.672284	val: 0.609253	test: 0.582394
PRC train: 0.668668	val: 0.648003	test: 0.599008

Epoch: 11
Loss: 0.5130503085477989
ROC train: 0.680481	val: 0.613921	test: 0.589695
PRC train: 0.672108	val: 0.653241	test: 0.601546

Epoch: 12
Loss: 0.5103109902552267
ROC train: 0.686188	val: 0.611576	test: 0.589634
PRC train: 0.675327	val: 0.653942	test: 0.601696

Epoch: 13
Loss: 0.5017126038197488
ROC train: 0.697392	val: 0.624859	test: 0.595151
PRC train: 0.682578	val: 0.662618	test: 0.604521

Epoch: 14
Loss: 0.49882126772311486
ROC train: 0.702021	val: 0.636811	test: 0.599543
PRC train: 0.686483	val: 0.669667	test: 0.605852

Epoch: 15
Loss: 0.49339931529488684
ROC train: 0.710700	val: 0.641166	test: 0.604776
PRC train: 0.690878	val: 0.672689	test: 0.608201

Epoch: 16
Loss: 0.4880164345912873
ROC train: 0.712404	val: 0.634868	test: 0.606060
PRC train: 0.691295	val: 0.671023	test: 0.612052

Epoch: 17
Loss: 0.48853428364722995
ROC train: 0.714407	val: 0.630119	test: 0.601459
PRC train: 0.693296	val: 0.671346	test: 0.612351

Epoch: 18
Loss: 0.4812815359559048
ROC train: 0.723452	val: 0.638407	test: 0.603181
PRC train: 0.699724	val: 0.676496	test: 0.612336

Epoch: 19
Loss: 0.47709262042292033
ROC train: 0.732111	val: 0.650165	test: 0.612962
PRC train: 0.706487	val: 0.678833	test: 0.615007

Epoch: 20
Loss: 0.4748703574388358
ROC train: 0.731019	val: 0.652988	test: 0.612404
PRC train: 0.707646	val: 0.680325	test: 0.615345

Epoch: 21
Loss: 0.4682036053345165
ROC train: 0.739414	val: 0.656832	test: 0.612330
PRC train: 0.712662	val: 0.680566	test: 0.618135

Epoch: 22
Loss: 0.46934437584982314
ROC train: 0.735504	val: 0.646411	test: 0.604204
PRC train: 0.708780	val: 0.673709	test: 0.613523

Epoch: 23
Loss: 0.46760993932631967
ROC train: 0.734955	val: 0.646185	test: 0.599972
PRC train: 0.708610	val: 0.673864	test: 0.610491

Epoch: 24
Loss: 0.46020152760637734
ROC train: 0.740900	val: 0.647120	test: 0.606215
PRC train: 0.713522	val: 0.675547	test: 0.611903

Epoch: 25
Loss: 0.469393622917831
ROC train: 0.744581	val: 0.650934	test: 0.606184
PRC train: 0.716042	val: 0.677890	test: 0.611834

Epoch: 26
Loss: 0.46053649260544877
ROC train: 0.755008	val: 0.659179	test: 0.611723
PRC train: 0.723205	val: 0.680410	test: 0.615228

Epoch: 27
Loss: 0.4543056294171185
ROC train: 0.759094	val: 0.657752	test: 0.615137
PRC train: 0.724978	val: 0.680305	test: 0.616867

Epoch: 28
Loss: 0.4665155020428913
ROC train: 0.757489	val: 0.646808	test: 0.609792
PRC train: 0.724995	val: 0.676068	test: 0.616817

Epoch: 29
Loss: 0.4545581453346155
ROC train: 0.762155	val: 0.650388	test: 0.616816
PRC train: 0.727051	val: 0.674967	test: 0.620447

Epoch: 30
Loss: 0.4519567124123086
ROC train: 0.760688	val: 0.652575	test: 0.615672
PRC train: 0.727625	val: 0.675216	test: 0.621511

Epoch: 31
Loss: 0.4484171196129866
ROC train: 0.764767	val: 0.652881	test: 0.617320
PRC train: 0.731450	val: 0.674980	test: 0.622946

Epoch: 32
Loss: 0.4553514587012554
ROC train: 0.771291	val: 0.653782	test: 0.615546
PRC train: 0.736396	val: 0.676056	test: 0.622699

Epoch: 33
Loss: 0.4477300488441096Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/sider/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/sider/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/sider/random/train_prop=0.6/sider_random_5_26-05_11-07-48  ]
[ Using Seed :  5  ]
[ Using device :  cuda:0  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
randomly split
Data(edge_attr=[38, 2], edge_index=[2, 38], id=[1], x=[18, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6880180664785523
ROC train: 0.517789	val: 0.510333	test: 0.484628
PRC train: 0.572150	val: 0.587866	test: 0.549578

Epoch: 2
Loss: 0.6542501012687846
ROC train: 0.549314	val: 0.527037	test: 0.505685
PRC train: 0.595722	val: 0.599921	test: 0.560928

Epoch: 3
Loss: 0.6275746750927055
ROC train: 0.566097	val: 0.538632	test: 0.513785
PRC train: 0.608840	val: 0.606173	test: 0.565896

Epoch: 4
Loss: 0.5979348172042285
ROC train: 0.582738	val: 0.550240	test: 0.523271
PRC train: 0.618923	val: 0.613667	test: 0.571739

Epoch: 5
Loss: 0.5754774294065305
ROC train: 0.603908	val: 0.567108	test: 0.535951
PRC train: 0.629491	val: 0.619808	test: 0.577810

Epoch: 6
Loss: 0.5565346908734734
ROC train: 0.619719	val: 0.579480	test: 0.541465
PRC train: 0.638190	val: 0.625751	test: 0.581362

Epoch: 7
Loss: 0.5455395117055117
ROC train: 0.634949	val: 0.591062	test: 0.552859
PRC train: 0.645908	val: 0.633326	test: 0.587918

Epoch: 8
Loss: 0.5351346203155979
ROC train: 0.649851	val: 0.599353	test: 0.560009
PRC train: 0.655107	val: 0.641555	test: 0.592246

Epoch: 9
Loss: 0.5262364660997276
ROC train: 0.662345	val: 0.612378	test: 0.573026
PRC train: 0.662035	val: 0.651065	test: 0.595485

Epoch: 10
Loss: 0.5240412720057488
ROC train: 0.671772	val: 0.619601	test: 0.580380
PRC train: 0.667195	val: 0.654781	test: 0.595593

Epoch: 11
Loss: 0.5150747423055234
ROC train: 0.681640	val: 0.619294	test: 0.585406
PRC train: 0.671874	val: 0.654907	test: 0.597979

Epoch: 12
Loss: 0.5069361845264733
ROC train: 0.692351	val: 0.631271	test: 0.594435
PRC train: 0.677338	val: 0.660913	test: 0.601537

Epoch: 13
Loss: 0.4969764175840781
ROC train: 0.697264	val: 0.634746	test: 0.593713
PRC train: 0.680715	val: 0.666513	test: 0.601914

Epoch: 14
Loss: 0.4974932873493013
ROC train: 0.695367	val: 0.624247	test: 0.584236
PRC train: 0.679676	val: 0.662808	test: 0.600868

Epoch: 15
Loss: 0.4900563536935535
ROC train: 0.705609	val: 0.634376	test: 0.587642
PRC train: 0.686382	val: 0.669594	test: 0.602537

Epoch: 16
Loss: 0.49018497984871223
ROC train: 0.716710	val: 0.644960	test: 0.607681
PRC train: 0.693223	val: 0.674156	test: 0.609237

Epoch: 17
Loss: 0.47795375480289476
ROC train: 0.718740	val: 0.645467	test: 0.606517
PRC train: 0.693876	val: 0.672533	test: 0.610118

Epoch: 18
Loss: 0.4809705669488613
ROC train: 0.719204	val: 0.641092	test: 0.600722
PRC train: 0.695103	val: 0.671082	test: 0.607785

Epoch: 19
Loss: 0.4783936005382859
ROC train: 0.727004	val: 0.647467	test: 0.604774
PRC train: 0.701011	val: 0.676281	test: 0.609904

Epoch: 20
Loss: 0.4733637603201167
ROC train: 0.733420	val: 0.651433	test: 0.617076
PRC train: 0.705283	val: 0.677010	test: 0.614651

Epoch: 21
Loss: 0.4726457078260432
ROC train: 0.733345	val: 0.646711	test: 0.613397
PRC train: 0.705399	val: 0.674604	test: 0.615335

Epoch: 22
Loss: 0.46602956629207515
ROC train: 0.734124	val: 0.642856	test: 0.605264
PRC train: 0.707105	val: 0.674245	test: 0.613463

Epoch: 23
Loss: 0.46524462376545
ROC train: 0.737971	val: 0.650491	test: 0.609524
PRC train: 0.710013	val: 0.675842	test: 0.614135

Epoch: 24
Loss: 0.4645179266431035
ROC train: 0.744317	val: 0.649307	test: 0.602758
PRC train: 0.713729	val: 0.673871	test: 0.608156

Epoch: 25
Loss: 0.46091540481621374
ROC train: 0.749051	val: 0.644982	test: 0.585801
PRC train: 0.717449	val: 0.675021	test: 0.598736

Epoch: 26
Loss: 0.4697363540394327
ROC train: 0.750627	val: 0.646376	test: 0.587399
PRC train: 0.720734	val: 0.675762	test: 0.604125

Epoch: 27
Loss: 0.4592889775345282
ROC train: 0.755704	val: 0.652399	test: 0.602341
PRC train: 0.724657	val: 0.676272	test: 0.613628

Epoch: 28
Loss: 0.46474139955628535
ROC train: 0.759055	val: 0.647056	test: 0.604632
PRC train: 0.726899	val: 0.675307	test: 0.615880

Epoch: 29
Loss: 0.45563380536592013
ROC train: 0.758918	val: 0.640310	test: 0.602774
PRC train: 0.727546	val: 0.672336	test: 0.617627

Epoch: 30
Loss: 0.45127726172396393
ROC train: 0.762614	val: 0.643429	test: 0.607029
PRC train: 0.730153	val: 0.672954	test: 0.620882

Epoch: 31
Loss: 0.45035434100731525
ROC train: 0.768575	val: 0.658443	test: 0.613851
PRC train: 0.732960	val: 0.677843	test: 0.622587

Epoch: 32
Loss: 0.44878513411594595
ROC train: 0.766761	val: 0.660530	test: 0.609685
PRC train: 0.733562	val: 0.678739	test: 0.620933

Epoch: 33
Loss: 0.4542612751439028Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/sider/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/sider/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/sider/random/train_prop=0.6/sider_random_4_26-05_11-07-48  ]
[ Using Seed :  4  ]
[ Using device :  cuda:0  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
randomly split
Data(edge_attr=[38, 2], edge_index=[2, 38], id=[1], x=[18, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6858974375677229
ROC train: 0.518425	val: 0.511748	test: 0.507299
PRC train: 0.582862	val: 0.597816	test: 0.566643

Epoch: 2
Loss: 0.656358434436346
ROC train: 0.548284	val: 0.533894	test: 0.512257
PRC train: 0.599106	val: 0.603861	test: 0.571766

Epoch: 3
Loss: 0.6235128822158373
ROC train: 0.562805	val: 0.538947	test: 0.517208
PRC train: 0.608155	val: 0.604511	test: 0.575085

Epoch: 4
Loss: 0.5986202179872547
ROC train: 0.577642	val: 0.546354	test: 0.523868
PRC train: 0.616691	val: 0.607021	test: 0.575625

Epoch: 5
Loss: 0.5797984500070397
ROC train: 0.598337	val: 0.562191	test: 0.534593
PRC train: 0.628205	val: 0.617470	test: 0.578798

Epoch: 6
Loss: 0.5579684355702876
ROC train: 0.619352	val: 0.582693	test: 0.545431
PRC train: 0.638700	val: 0.631425	test: 0.582028

Epoch: 7
Loss: 0.555434708183634
ROC train: 0.634982	val: 0.599779	test: 0.558758
PRC train: 0.646569	val: 0.640614	test: 0.586728

Epoch: 8
Loss: 0.5330294924572063
ROC train: 0.653093	val: 0.608597	test: 0.566262
PRC train: 0.656416	val: 0.645029	test: 0.589862

Epoch: 9
Loss: 0.5225394239608863
ROC train: 0.666775	val: 0.614547	test: 0.568261
PRC train: 0.664868	val: 0.650185	test: 0.591389

Epoch: 10
Loss: 0.5253211617677132
ROC train: 0.673777	val: 0.612101	test: 0.571959
PRC train: 0.670098	val: 0.653539	test: 0.595064

Epoch: 11
Loss: 0.5120328404773208
ROC train: 0.681341	val: 0.616031	test: 0.579666
PRC train: 0.675724	val: 0.658611	test: 0.598513

Epoch: 12
Loss: 0.5036196121854601
ROC train: 0.691500	val: 0.625851	test: 0.593563
PRC train: 0.680960	val: 0.666721	test: 0.604178

Epoch: 13
Loss: 0.5033492401531432
ROC train: 0.697779	val: 0.631212	test: 0.595689
PRC train: 0.684212	val: 0.668554	test: 0.606701

Epoch: 14
Loss: 0.49572707183878906
ROC train: 0.700570	val: 0.633506	test: 0.596673
PRC train: 0.686811	val: 0.668998	test: 0.610252

Epoch: 15
Loss: 0.49569601010419795
ROC train: 0.702447	val: 0.630423	test: 0.595108
PRC train: 0.689257	val: 0.667926	test: 0.612775

Epoch: 16
Loss: 0.4895827006188793
ROC train: 0.710178	val: 0.639709	test: 0.603666
PRC train: 0.696076	val: 0.672440	test: 0.616522

Epoch: 17
Loss: 0.4813851369032329
ROC train: 0.718012	val: 0.641952	test: 0.606329
PRC train: 0.700058	val: 0.674315	test: 0.616304

Epoch: 18
Loss: 0.48055638605485573
ROC train: 0.719148	val: 0.632595	test: 0.602009
PRC train: 0.699819	val: 0.670310	test: 0.613760

Epoch: 19
Loss: 0.47860199365263
ROC train: 0.723249	val: 0.633487	test: 0.608802
PRC train: 0.704115	val: 0.672364	test: 0.613624

Epoch: 20
Loss: 0.4708524968136166
ROC train: 0.725179	val: 0.630868	test: 0.606851
PRC train: 0.706684	val: 0.670341	test: 0.611234

Epoch: 21
Loss: 0.4737453496333812
ROC train: 0.731396	val: 0.631865	test: 0.600357
PRC train: 0.709355	val: 0.668258	test: 0.610356

Epoch: 22
Loss: 0.4769046003187963
ROC train: 0.734152	val: 0.642217	test: 0.602244
PRC train: 0.711625	val: 0.672760	test: 0.609110

Epoch: 23
Loss: 0.4656652444119308
ROC train: 0.738300	val: 0.650240	test: 0.613195
PRC train: 0.717648	val: 0.676564	test: 0.616753

Epoch: 24
Loss: 0.4652226252579187
ROC train: 0.744581	val: 0.651704	test: 0.617094
PRC train: 0.720643	val: 0.678372	test: 0.617815

Epoch: 25
Loss: 0.46101745442666475
ROC train: 0.750185	val: 0.644429	test: 0.613969
PRC train: 0.721984	val: 0.677485	test: 0.615614

Epoch: 26
Loss: 0.45267048347131983
ROC train: 0.754031	val: 0.643102	test: 0.610980
PRC train: 0.725641	val: 0.678386	test: 0.616560

Epoch: 27
Loss: 0.4585032459279381
ROC train: 0.757140	val: 0.642500	test: 0.610391
PRC train: 0.729412	val: 0.677933	test: 0.617248

Epoch: 28
Loss: 0.4538718058229903
ROC train: 0.754919	val: 0.641278	test: 0.614972
PRC train: 0.728681	val: 0.676181	test: 0.622069

Epoch: 29
Loss: 0.44978163637489277
ROC train: 0.758583	val: 0.641613	test: 0.616737
PRC train: 0.732252	val: 0.673453	test: 0.625282

Epoch: 30
Loss: 0.4550672554734895
ROC train: 0.761406	val: 0.638731	test: 0.612268
PRC train: 0.735520	val: 0.672429	test: 0.621987

Epoch: 31
Loss: 0.45043729446541636
ROC train: 0.769532	val: 0.648465	test: 0.622356
PRC train: 0.740948	val: 0.675498	test: 0.625747

Epoch: 32
Loss: 0.44507258792908216
ROC train: 0.770963	val: 0.653998	test: 0.626847
PRC train: 0.743371	val: 0.677104	test: 0.627174

Epoch: 33
Loss: 0.4489456078846545Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/sider/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/sider/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/sider/random/train_prop=0.7/sider_random_4_26-05_11-07-48  ]
[ Using Seed :  4  ]
[ Using device :  cuda:1  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
randomly split
Data(edge_attr=[38, 2], edge_index=[2, 38], id=[1], x=[18, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6854439203268439
ROC train: 0.525842	val: 0.508683	test: 0.512211
PRC train: 0.585636	val: 0.605522	test: 0.557627

Epoch: 2
Loss: 0.6515597069373943
ROC train: 0.553842	val: 0.517973	test: 0.510144
PRC train: 0.602642	val: 0.606523	test: 0.564712

Epoch: 3
Loss: 0.6179845224238287
ROC train: 0.563566	val: 0.519336	test: 0.512005
PRC train: 0.610847	val: 0.604541	test: 0.566104

Epoch: 4
Loss: 0.589527679992854
ROC train: 0.579104	val: 0.531877	test: 0.524667
PRC train: 0.620791	val: 0.608778	test: 0.567389

Epoch: 5
Loss: 0.5689231008471629
ROC train: 0.608023	val: 0.555960	test: 0.541668
PRC train: 0.634061	val: 0.620972	test: 0.572865

Epoch: 6
Loss: 0.5516071832266995
ROC train: 0.629402	val: 0.574571	test: 0.561557
PRC train: 0.642996	val: 0.630016	test: 0.581139

Epoch: 7
Loss: 0.5383178140753313
ROC train: 0.642259	val: 0.585645	test: 0.575471
PRC train: 0.649440	val: 0.637122	test: 0.588191

Epoch: 8
Loss: 0.5298312469636313
ROC train: 0.658986	val: 0.593741	test: 0.582749
PRC train: 0.660302	val: 0.643307	test: 0.593160

Epoch: 9
Loss: 0.5190206948867014
ROC train: 0.670328	val: 0.596721	test: 0.584998
PRC train: 0.668170	val: 0.648588	test: 0.593406

Epoch: 10
Loss: 0.5133035623358349
ROC train: 0.676725	val: 0.599663	test: 0.587271
PRC train: 0.672462	val: 0.652836	test: 0.593982

Epoch: 11
Loss: 0.5080064173210654
ROC train: 0.686617	val: 0.609257	test: 0.592297
PRC train: 0.677865	val: 0.657444	test: 0.598589

Epoch: 12
Loss: 0.5005544822774292
ROC train: 0.697857	val: 0.623349	test: 0.600842
PRC train: 0.683212	val: 0.663578	test: 0.601902

Epoch: 13
Loss: 0.4976335723800931
ROC train: 0.704774	val: 0.626385	test: 0.601849
PRC train: 0.687407	val: 0.667289	test: 0.604407

Epoch: 14
Loss: 0.49006333897846066
ROC train: 0.710726	val: 0.624584	test: 0.603408
PRC train: 0.691165	val: 0.670396	test: 0.606312

Epoch: 15
Loss: 0.4875063482183877
ROC train: 0.711192	val: 0.621544	test: 0.601250
PRC train: 0.694113	val: 0.679750	test: 0.605796

Epoch: 16
Loss: 0.481321219022189
ROC train: 0.721263	val: 0.627864	test: 0.611596
PRC train: 0.700061	val: 0.683547	test: 0.610224

Epoch: 17
Loss: 0.4778211359032033
ROC train: 0.727123	val: 0.629881	test: 0.611770
PRC train: 0.702440	val: 0.682982	test: 0.612577

Epoch: 18
Loss: 0.4720073994718964
ROC train: 0.732259	val: 0.633252	test: 0.612670
PRC train: 0.705812	val: 0.682763	test: 0.612277

Epoch: 19
Loss: 0.47141991639677705
ROC train: 0.735947	val: 0.633643	test: 0.606405
PRC train: 0.708042	val: 0.678532	test: 0.608909

Epoch: 20
Loss: 0.4702383339268135
ROC train: 0.735089	val: 0.631725	test: 0.606105
PRC train: 0.708020	val: 0.677214	test: 0.609596

Epoch: 21
Loss: 0.4658595535053344
ROC train: 0.744532	val: 0.638906	test: 0.613791
PRC train: 0.714950	val: 0.682741	test: 0.612850

Epoch: 22
Loss: 0.46100484670952
ROC train: 0.749399	val: 0.644904	test: 0.619259
PRC train: 0.720578	val: 0.691581	test: 0.617669

Epoch: 23
Loss: 0.45874899576781536
ROC train: 0.755293	val: 0.644515	test: 0.622655
PRC train: 0.724025	val: 0.690550	test: 0.621836

Epoch: 24
Loss: 0.45902598909561765
ROC train: 0.758252	val: 0.649798	test: 0.624407
PRC train: 0.726421	val: 0.692577	test: 0.623494

Epoch: 25
Loss: 0.4539261772645263
ROC train: 0.760280	val: 0.653974	test: 0.625991
PRC train: 0.729560	val: 0.694032	test: 0.621016

Epoch: 26
Loss: 0.4549268252436618
ROC train: 0.762341	val: 0.653550	test: 0.611018
PRC train: 0.731498	val: 0.694929	test: 0.615042

Epoch: 27
Loss: 0.4491236045981508
ROC train: 0.760482	val: 0.649997	test: 0.598153
PRC train: 0.729934	val: 0.688486	test: 0.604292

Epoch: 28
Loss: 0.45074872065222615
ROC train: 0.761876	val: 0.648383	test: 0.603294
PRC train: 0.730402	val: 0.688837	test: 0.604333

Epoch: 29
Loss: 0.4490147356378212
ROC train: 0.766673	val: 0.641769	test: 0.609155
PRC train: 0.735017	val: 0.690892	test: 0.607437

Epoch: 30
Loss: 0.4495928039852588
ROC train: 0.771188	val: 0.651922	test: 0.618581
PRC train: 0.739669	val: 0.697149	test: 0.614598

Epoch: 31
Loss: 0.44602784880651947
ROC train: 0.774409	val: 0.654284	test: 0.619564
PRC train: 0.742634	val: 0.697274	test: 0.617381

Epoch: 32
Loss: 0.43979375341445726
ROC train: 0.777866	val: 0.652294	test: 0.619836
PRC train: 0.745471	val: 0.697774	test: 0.617719

Epoch: 33
Loss: 0.43849648995116564Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/sider/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/sider/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/sider/random/train_prop=0.7/sider_random_6_26-05_11-07-48  ]
[ Using Seed :  6  ]
[ Using device :  cuda:1  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
randomly split
Data(edge_attr=[38, 2], edge_index=[2, 38], id=[1], x=[18, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6894875876928959
ROC train: 0.525423	val: 0.495972	test: 0.507626
PRC train: 0.581125	val: 0.601401	test: 0.554880

Epoch: 2
Loss: 0.655902309452592
ROC train: 0.541183	val: 0.493543	test: 0.506731
PRC train: 0.594418	val: 0.603096	test: 0.556522

Epoch: 3
Loss: 0.624314274065597
ROC train: 0.559269	val: 0.503118	test: 0.516873
PRC train: 0.605296	val: 0.601862	test: 0.562755

Epoch: 4
Loss: 0.5939860035445085
ROC train: 0.578374	val: 0.526734	test: 0.528720
PRC train: 0.617345	val: 0.610981	test: 0.566443

Epoch: 5
Loss: 0.571725338807306
ROC train: 0.604998	val: 0.545125	test: 0.543166
PRC train: 0.632689	val: 0.618899	test: 0.573250

Epoch: 6
Loss: 0.5509644781466732
ROC train: 0.630588	val: 0.567896	test: 0.563480
PRC train: 0.645840	val: 0.625027	test: 0.580388

Epoch: 7
Loss: 0.5409373431156558
ROC train: 0.646522	val: 0.584455	test: 0.580030
PRC train: 0.652703	val: 0.632853	test: 0.588986

Epoch: 8
Loss: 0.530184434363761
ROC train: 0.660510	val: 0.595158	test: 0.585984
PRC train: 0.660619	val: 0.640871	test: 0.591502

Epoch: 9
Loss: 0.5216082117006051
ROC train: 0.671770	val: 0.603373	test: 0.590182
PRC train: 0.667634	val: 0.650415	test: 0.597015

Epoch: 10
Loss: 0.5209911948265317
ROC train: 0.682735	val: 0.604398	test: 0.595336
PRC train: 0.672761	val: 0.653347	test: 0.601361

Epoch: 11
Loss: 0.5103132760082285
ROC train: 0.690731	val: 0.611473	test: 0.601544
PRC train: 0.676569	val: 0.654478	test: 0.602939

Epoch: 12
Loss: 0.5006015846133101
ROC train: 0.695960	val: 0.613982	test: 0.602767
PRC train: 0.680625	val: 0.657106	test: 0.602723

Epoch: 13
Loss: 0.498283398507599
ROC train: 0.702546	val: 0.614711	test: 0.604212
PRC train: 0.685354	val: 0.661854	test: 0.602218

Epoch: 14
Loss: 0.4912176624102169
ROC train: 0.708974	val: 0.617578	test: 0.610703
PRC train: 0.688028	val: 0.663084	test: 0.603594

Epoch: 15
Loss: 0.4870265611384387
ROC train: 0.715040	val: 0.623136	test: 0.609597
PRC train: 0.691650	val: 0.666847	test: 0.607170

Epoch: 16
Loss: 0.4849133744462231
ROC train: 0.718198	val: 0.627155	test: 0.605190
PRC train: 0.694613	val: 0.668511	test: 0.607524

Epoch: 17
Loss: 0.4772369836093857
ROC train: 0.725986	val: 0.633180	test: 0.614311
PRC train: 0.697920	val: 0.671688	test: 0.612352

Epoch: 18
Loss: 0.47281003109508124
ROC train: 0.731029	val: 0.635818	test: 0.614996
PRC train: 0.701326	val: 0.674270	test: 0.614303

Epoch: 19
Loss: 0.47585512136371666
ROC train: 0.730363	val: 0.632670	test: 0.600823
PRC train: 0.702952	val: 0.672407	test: 0.610647

Epoch: 20
Loss: 0.4696393914863867
ROC train: 0.740010	val: 0.640712	test: 0.605905
PRC train: 0.709549	val: 0.678361	test: 0.613268

Epoch: 21
Loss: 0.46883958522060726
ROC train: 0.744733	val: 0.647685	test: 0.609916
PRC train: 0.713274	val: 0.682540	test: 0.611603

Epoch: 22
Loss: 0.46356046675659834
ROC train: 0.744109	val: 0.641208	test: 0.600837
PRC train: 0.715084	val: 0.683761	test: 0.609088

Epoch: 23
Loss: 0.46241215977118294
ROC train: 0.746975	val: 0.637419	test: 0.602360
PRC train: 0.714673	val: 0.679434	test: 0.610232

Epoch: 24
Loss: 0.4603659150754768
ROC train: 0.753186	val: 0.643648	test: 0.612754
PRC train: 0.716914	val: 0.681739	test: 0.614889

Epoch: 25
Loss: 0.45760246181427955
ROC train: 0.760083	val: 0.647665	test: 0.619650
PRC train: 0.724317	val: 0.687043	test: 0.617606

Epoch: 26
Loss: 0.4579659465918118
ROC train: 0.760790	val: 0.642677	test: 0.614708
PRC train: 0.727420	val: 0.683055	test: 0.616949

Epoch: 27
Loss: 0.4548117694637599
ROC train: 0.764338	val: 0.643762	test: 0.616430
PRC train: 0.727640	val: 0.682975	test: 0.618905

Epoch: 28
Loss: 0.4509873204612185
ROC train: 0.769472	val: 0.646930	test: 0.618031
PRC train: 0.732721	val: 0.688482	test: 0.618299

Epoch: 29
Loss: 0.4465294235660167
ROC train: 0.772125	val: 0.644513	test: 0.617694
PRC train: 0.735460	val: 0.687914	test: 0.620809

Epoch: 30
Loss: 0.45253035992575563
ROC train: 0.772674	val: 0.640414	test: 0.620003
PRC train: 0.735613	val: 0.685057	test: 0.626506

Epoch: 31
Loss: 0.44468484619171045
ROC train: 0.776540	val: 0.647194	test: 0.617815
PRC train: 0.737788	val: 0.689731	test: 0.623855

Epoch: 32
Loss: 0.4418741748445934
ROC train: 0.780780	val: 0.649595	test: 0.619384
PRC train: 0.741332	val: 0.690210	test: 0.622854

Epoch: 33
Loss: 0.4394976492782489Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/sider/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/sider/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/sider/random/train_prop=0.7/sider_random_5_26-05_11-07-48  ]
[ Using Seed :  5  ]
[ Using device :  cuda:1  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
randomly split
Data(edge_attr=[38, 2], edge_index=[2, 38], id=[1], x=[18, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6878472033421072
ROC train: 0.516390	val: 0.509535	test: 0.483124
PRC train: 0.571016	val: 0.601973	test: 0.540925

Epoch: 2
Loss: 0.6538535356076709
ROC train: 0.548542	val: 0.519939	test: 0.498497
PRC train: 0.595608	val: 0.610356	test: 0.550908

Epoch: 3
Loss: 0.6203559930873955
ROC train: 0.568339	val: 0.529050	test: 0.513615
PRC train: 0.610125	val: 0.608521	test: 0.557269

Epoch: 4
Loss: 0.5912923218083638
ROC train: 0.585894	val: 0.538203	test: 0.524503
PRC train: 0.621329	val: 0.612651	test: 0.562696

Epoch: 5
Loss: 0.5669863519493308
ROC train: 0.610152	val: 0.554463	test: 0.541881
PRC train: 0.632460	val: 0.619635	test: 0.570960

Epoch: 6
Loss: 0.5500288559919757
ROC train: 0.628449	val: 0.560122	test: 0.557806
PRC train: 0.641128	val: 0.624056	test: 0.579225

Epoch: 7
Loss: 0.540259706698505
ROC train: 0.641634	val: 0.568674	test: 0.566789
PRC train: 0.648430	val: 0.631203	test: 0.584616

Epoch: 8
Loss: 0.5286574427585106
ROC train: 0.655268	val: 0.576780	test: 0.571101
PRC train: 0.656363	val: 0.637860	test: 0.588626

Epoch: 9
Loss: 0.5216825736208566
ROC train: 0.668465	val: 0.594329	test: 0.580580
PRC train: 0.663702	val: 0.644777	test: 0.591985

Epoch: 10
Loss: 0.5112912255604227
ROC train: 0.681269	val: 0.601358	test: 0.591277
PRC train: 0.669898	val: 0.649059	test: 0.595332

Epoch: 11
Loss: 0.5084543451502525
ROC train: 0.689656	val: 0.604720	test: 0.595261
PRC train: 0.673613	val: 0.649969	test: 0.596776

Epoch: 12
Loss: 0.5073614882154366
ROC train: 0.695848	val: 0.613245	test: 0.599820
PRC train: 0.677755	val: 0.655142	test: 0.597482

Epoch: 13
Loss: 0.4966674473894773
ROC train: 0.705482	val: 0.611092	test: 0.604364
PRC train: 0.682116	val: 0.657772	test: 0.599957

Epoch: 14
Loss: 0.4904108678464795
ROC train: 0.710255	val: 0.614593	test: 0.606468
PRC train: 0.685348	val: 0.660276	test: 0.601515

Epoch: 15
Loss: 0.4864127746006911
ROC train: 0.716892	val: 0.621978	test: 0.609539
PRC train: 0.689100	val: 0.664763	test: 0.603292

Epoch: 16
Loss: 0.4889795913886941
ROC train: 0.713086	val: 0.617682	test: 0.600560
PRC train: 0.689024	val: 0.664931	test: 0.600530

Epoch: 17
Loss: 0.4803452878294847
ROC train: 0.726865	val: 0.627276	test: 0.611226
PRC train: 0.696735	val: 0.675045	test: 0.604307

Epoch: 18
Loss: 0.47384597692055125
ROC train: 0.726249	val: 0.624148	test: 0.606927
PRC train: 0.697276	val: 0.668857	test: 0.602904

Epoch: 19
Loss: 0.4726513544607787
ROC train: 0.729285	val: 0.626826	test: 0.607173
PRC train: 0.700047	val: 0.670862	test: 0.602439

Epoch: 20
Loss: 0.4696945212788394
ROC train: 0.738460	val: 0.628877	test: 0.610624
PRC train: 0.705071	val: 0.676139	test: 0.604844

Epoch: 21
Loss: 0.46762506926026304
ROC train: 0.744743	val: 0.639221	test: 0.618355
PRC train: 0.710599	val: 0.683674	test: 0.607830

Epoch: 22
Loss: 0.46343335180650447
ROC train: 0.747108	val: 0.638514	test: 0.617547
PRC train: 0.713103	val: 0.682927	test: 0.606519

Epoch: 23
Loss: 0.4639604661205868
ROC train: 0.748430	val: 0.634863	test: 0.615488
PRC train: 0.714425	val: 0.681689	test: 0.604369

Epoch: 24
Loss: 0.4607820927964511
ROC train: 0.751047	val: 0.632586	test: 0.608815
PRC train: 0.716558	val: 0.680319	test: 0.603083

Epoch: 25
Loss: 0.4606481709981012
ROC train: 0.755087	val: 0.637206	test: 0.607579
PRC train: 0.720618	val: 0.683322	test: 0.603036

Epoch: 26
Loss: 0.45645100057415555
ROC train: 0.761920	val: 0.642774	test: 0.612416
PRC train: 0.723947	val: 0.686924	test: 0.605773

Epoch: 27
Loss: 0.4575349764294661
ROC train: 0.762058	val: 0.638475	test: 0.610799
PRC train: 0.724520	val: 0.684699	test: 0.607209

Epoch: 28
Loss: 0.4521376688194111
ROC train: 0.761741	val: 0.640289	test: 0.611762
PRC train: 0.724712	val: 0.681588	test: 0.610782

Epoch: 29
Loss: 0.45143878938238635
ROC train: 0.768536	val: 0.643212	test: 0.611181
PRC train: 0.729304	val: 0.684163	test: 0.607871

Epoch: 30
Loss: 0.4482522701230834
ROC train: 0.767820	val: 0.641139	test: 0.607965
PRC train: 0.729545	val: 0.687218	test: 0.604956

Epoch: 31
Loss: 0.44756718255735933
ROC train: 0.767498	val: 0.629731	test: 0.603789
PRC train: 0.730017	val: 0.679853	test: 0.603930

Epoch: 32
Loss: 0.44776279339069713
ROC train: 0.772773	val: 0.637615	test: 0.610101
PRC train: 0.732507	val: 0.681961	test: 0.606607

Epoch: 33
Loss: 0.44569135408038135Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/sider/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/sider/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/sider/random/train_prop=0.8/sider_random_6_26-05_11-07-48  ]
[ Using Seed :  6  ]
[ Using device :  cuda:2  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
randomly split
Data(edge_attr=[38, 2], edge_index=[2, 38], id=[1], x=[18, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6856574554747861
ROC train: 0.528306	val: 0.482240	test: 0.512230
PRC train: 0.587509	val: 0.569690	test: 0.563428

Epoch: 2
Loss: 0.6437429114892886
ROC train: 0.546764	val: 0.501829	test: 0.508765
PRC train: 0.600561	val: 0.582685	test: 0.562712

Epoch: 3
Loss: 0.6113784598722951
ROC train: 0.562828	val: 0.532881	test: 0.517533
PRC train: 0.610812	val: 0.599787	test: 0.563339

Epoch: 4
Loss: 0.5782836058256934
ROC train: 0.594646	val: 0.556513	test: 0.536162
PRC train: 0.629698	val: 0.613470	test: 0.569451

Epoch: 5
Loss: 0.5519597035815023
ROC train: 0.624582	val: 0.577381	test: 0.564961
PRC train: 0.646211	val: 0.620161	test: 0.579522

Epoch: 6
Loss: 0.5377638695806761
ROC train: 0.642582	val: 0.588550	test: 0.585590
PRC train: 0.654624	val: 0.627114	test: 0.590220

Epoch: 7
Loss: 0.5285771866174815
ROC train: 0.658411	val: 0.597692	test: 0.595987
PRC train: 0.662105	val: 0.630664	test: 0.594286

Epoch: 8
Loss: 0.5195779091997874
ROC train: 0.668587	val: 0.604224	test: 0.594567
PRC train: 0.667962	val: 0.630639	test: 0.594644

Epoch: 9
Loss: 0.5125708406616096
ROC train: 0.676192	val: 0.601763	test: 0.590721
PRC train: 0.673302	val: 0.630053	test: 0.593937

Epoch: 10
Loss: 0.5073784493657252
ROC train: 0.685477	val: 0.607898	test: 0.596514
PRC train: 0.679394	val: 0.630842	test: 0.597489

Epoch: 11
Loss: 0.495783448366833
ROC train: 0.690366	val: 0.609212	test: 0.591930
PRC train: 0.682382	val: 0.632943	test: 0.596514

Epoch: 12
Loss: 0.48849187848890957
ROC train: 0.697386	val: 0.602261	test: 0.592773
PRC train: 0.685273	val: 0.631001	test: 0.597313

Epoch: 13
Loss: 0.49117883045230437
ROC train: 0.704041	val: 0.605879	test: 0.596939
PRC train: 0.688760	val: 0.632386	test: 0.599729

Epoch: 14
Loss: 0.48667356014934776
ROC train: 0.708262	val: 0.611915	test: 0.597534
PRC train: 0.692125	val: 0.636061	test: 0.600368

Epoch: 15
Loss: 0.4789783807508791
ROC train: 0.713716	val: 0.617422	test: 0.600882
PRC train: 0.696544	val: 0.637938	test: 0.601045

Epoch: 16
Loss: 0.47817847191154905
ROC train: 0.717598	val: 0.619819	test: 0.602110
PRC train: 0.700849	val: 0.638588	test: 0.604985

Epoch: 17
Loss: 0.47061584984629434
ROC train: 0.721524	val: 0.633888	test: 0.601096
PRC train: 0.704505	val: 0.644970	test: 0.602775

Epoch: 18
Loss: 0.4704824662158377
ROC train: 0.725596	val: 0.635154	test: 0.594377
PRC train: 0.707280	val: 0.649592	test: 0.600218

Epoch: 19
Loss: 0.46808817607563213
ROC train: 0.735228	val: 0.641716	test: 0.604610
PRC train: 0.714349	val: 0.654423	test: 0.609800

Epoch: 20
Loss: 0.46807063762478024
ROC train: 0.738461	val: 0.638209	test: 0.606238
PRC train: 0.716871	val: 0.655246	test: 0.610880

Epoch: 21
Loss: 0.46637999330116875
ROC train: 0.738287	val: 0.632258	test: 0.611189
PRC train: 0.717261	val: 0.653727	test: 0.615562

Epoch: 22
Loss: 0.46079431857789865
ROC train: 0.743313	val: 0.641079	test: 0.612489
PRC train: 0.721538	val: 0.657250	test: 0.611694

Epoch: 23
Loss: 0.45860709898755714
ROC train: 0.745467	val: 0.650451	test: 0.611548
PRC train: 0.721434	val: 0.658289	test: 0.606851

Epoch: 24
Loss: 0.4603201857137981
ROC train: 0.751146	val: 0.650322	test: 0.611775
PRC train: 0.726511	val: 0.660407	test: 0.608717

Epoch: 25
Loss: 0.4598658358144698
ROC train: 0.756034	val: 0.648781	test: 0.609864
PRC train: 0.729625	val: 0.659815	test: 0.609799

Epoch: 26
Loss: 0.4548479546766423
ROC train: 0.758886	val: 0.647951	test: 0.606975
PRC train: 0.732545	val: 0.658841	test: 0.610810

Epoch: 27
Loss: 0.4526257097775349
ROC train: 0.759636	val: 0.643761	test: 0.603168
PRC train: 0.733817	val: 0.659958	test: 0.613208

Epoch: 28
Loss: 0.4501091139074399
ROC train: 0.762313	val: 0.649435	test: 0.606453
PRC train: 0.736156	val: 0.660456	test: 0.612276

Epoch: 29
Loss: 0.4529961003758804
ROC train: 0.761715	val: 0.641239	test: 0.611663
PRC train: 0.734492	val: 0.657222	test: 0.615341

Epoch: 30
Loss: 0.44814342618168
ROC train: 0.758642	val: 0.638312	test: 0.611661
PRC train: 0.734064	val: 0.655157	test: 0.612059

Epoch: 31
Loss: 0.4482517881658916
ROC train: 0.773433	val: 0.654602	test: 0.612091
PRC train: 0.742515	val: 0.664426	test: 0.611994

Epoch: 32
Loss: 0.4480955934785177
ROC train: 0.773168	val: 0.649452	test: 0.602624
PRC train: 0.742946	val: 0.667010	test: 0.610509

Epoch: 33
Loss: 0.4424783276900174Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/sider/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/sider/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/sider/random/train_prop=0.8/sider_random_4_26-05_11-07-48  ]
[ Using Seed :  4  ]
[ Using device :  cuda:2  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
randomly split
Data(edge_attr=[38, 2], edge_index=[2, 38], id=[1], x=[18, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6820945707275434
ROC train: 0.528274	val: 0.522367	test: 0.505384
PRC train: 0.589376	val: 0.589129	test: 0.563246

Epoch: 2
Loss: 0.6413334890142057
ROC train: 0.552523	val: 0.529407	test: 0.506268
PRC train: 0.604829	val: 0.602342	test: 0.565888

Epoch: 3
Loss: 0.6004643786571795
ROC train: 0.569012	val: 0.536420	test: 0.521837
PRC train: 0.614429	val: 0.613493	test: 0.566793

Epoch: 4
Loss: 0.5732097063361575
ROC train: 0.594984	val: 0.553451	test: 0.527927
PRC train: 0.629650	val: 0.619385	test: 0.567835

Epoch: 5
Loss: 0.5519855889515032
ROC train: 0.623274	val: 0.576258	test: 0.543207
PRC train: 0.642431	val: 0.623200	test: 0.572481

Epoch: 6
Loss: 0.5435406291728284
ROC train: 0.641726	val: 0.583915	test: 0.561249
PRC train: 0.653245	val: 0.624489	test: 0.581580

Epoch: 7
Loss: 0.5332974872321894
ROC train: 0.656291	val: 0.593644	test: 0.572512
PRC train: 0.662663	val: 0.628743	test: 0.583336

Epoch: 8
Loss: 0.5144858455638158
ROC train: 0.662646	val: 0.594448	test: 0.573504
PRC train: 0.668256	val: 0.632060	test: 0.583604

Epoch: 9
Loss: 0.5099348958000298
ROC train: 0.670619	val: 0.597475	test: 0.572866
PRC train: 0.673112	val: 0.633312	test: 0.584585

Epoch: 10
Loss: 0.504340405535788
ROC train: 0.687924	val: 0.605310	test: 0.583119
PRC train: 0.681423	val: 0.636268	test: 0.590134

Epoch: 11
Loss: 0.4991547911149247
ROC train: 0.697993	val: 0.623457	test: 0.597048
PRC train: 0.687954	val: 0.649819	test: 0.598443

Epoch: 12
Loss: 0.48881851470614485
ROC train: 0.701775	val: 0.624002	test: 0.598885
PRC train: 0.690656	val: 0.647959	test: 0.604353

Epoch: 13
Loss: 0.4859897795206332
ROC train: 0.703584	val: 0.616583	test: 0.592698
PRC train: 0.691902	val: 0.644109	test: 0.605761

Epoch: 14
Loss: 0.4824393418195484
ROC train: 0.711508	val: 0.615672	test: 0.598371
PRC train: 0.696723	val: 0.646782	test: 0.603927

Epoch: 15
Loss: 0.47981523920927727
ROC train: 0.715712	val: 0.616017	test: 0.605447
PRC train: 0.699886	val: 0.650378	test: 0.605798

Epoch: 16
Loss: 0.47781431454846574
ROC train: 0.712611	val: 0.614212	test: 0.608356
PRC train: 0.700255	val: 0.643858	test: 0.608577

Epoch: 17
Loss: 0.4750599708937546
ROC train: 0.724412	val: 0.625147	test: 0.607784
PRC train: 0.705284	val: 0.645274	test: 0.607905

Epoch: 18
Loss: 0.4697984279511557
ROC train: 0.727445	val: 0.631599	test: 0.607277
PRC train: 0.708336	val: 0.650667	test: 0.610120

Epoch: 19
Loss: 0.46727494763507077
ROC train: 0.735272	val: 0.642337	test: 0.615206
PRC train: 0.716167	val: 0.657488	test: 0.612757

Epoch: 20
Loss: 0.4696738926707793
ROC train: 0.735806	val: 0.642081	test: 0.615296
PRC train: 0.715008	val: 0.661380	test: 0.612322

Epoch: 21
Loss: 0.45961507221088543
ROC train: 0.738336	val: 0.631788	test: 0.598696
PRC train: 0.720177	val: 0.656037	test: 0.609794

Epoch: 22
Loss: 0.46593710327129045
ROC train: 0.745210	val: 0.633769	test: 0.594346
PRC train: 0.725291	val: 0.654227	test: 0.605268

Epoch: 23
Loss: 0.45883960754882447
ROC train: 0.751063	val: 0.637260	test: 0.600668
PRC train: 0.727938	val: 0.658637	test: 0.610822

Epoch: 24
Loss: 0.45680342857145134
ROC train: 0.752519	val: 0.641225	test: 0.610165
PRC train: 0.730129	val: 0.654025	test: 0.618386

Epoch: 25
Loss: 0.45361907252250544
ROC train: 0.757655	val: 0.648173	test: 0.614379
PRC train: 0.732402	val: 0.657722	test: 0.614591

Epoch: 26
Loss: 0.4515719746497231
ROC train: 0.763732	val: 0.648898	test: 0.620822
PRC train: 0.737310	val: 0.662900	test: 0.617197

Epoch: 27
Loss: 0.4519027963869823
ROC train: 0.764322	val: 0.643236	test: 0.614843
PRC train: 0.738473	val: 0.660643	test: 0.619433

Epoch: 28
Loss: 0.44544993809048616
ROC train: 0.769402	val: 0.641414	test: 0.618491
PRC train: 0.740355	val: 0.663159	test: 0.620258

Epoch: 29
Loss: 0.44614121585399635
ROC train: 0.765998	val: 0.633946	test: 0.613149
PRC train: 0.737839	val: 0.664863	test: 0.615285

Epoch: 30
Loss: 0.44861128406283174
ROC train: 0.771984	val: 0.649091	test: 0.611239
PRC train: 0.741281	val: 0.672099	test: 0.615546

Epoch: 31
Loss: 0.444664631927973
ROC train: 0.779434	val: 0.647844	test: 0.614244
PRC train: 0.748447	val: 0.665126	test: 0.620730

Epoch: 32
Loss: 0.444861660257863
ROC train: 0.776922	val: 0.637284	test: 0.607475
PRC train: 0.744066	val: 0.655150	test: 0.615937

Epoch: 33
Loss: 0.44136429262509136Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/sider/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/sider/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/sider/random/train_prop=0.8/sider_random_5_26-05_11-07-48  ]
[ Using Seed :  5  ]
[ Using device :  cuda:2  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
randomly split
Data(edge_attr=[38, 2], edge_index=[2, 38], id=[1], x=[18, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6847878973376147
ROC train: 0.524244	val: 0.486457	test: 0.499103
PRC train: 0.581768	val: 0.567631	test: 0.556558

Epoch: 2
Loss: 0.640843551029875
ROC train: 0.555963	val: 0.519063	test: 0.505749
PRC train: 0.606507	val: 0.588123	test: 0.557281

Epoch: 3
Loss: 0.6037623760692457
ROC train: 0.575487	val: 0.535334	test: 0.513508
PRC train: 0.618531	val: 0.600398	test: 0.561517

Epoch: 4
Loss: 0.5712664400361283
ROC train: 0.603361	val: 0.555197	test: 0.538477
PRC train: 0.632175	val: 0.607537	test: 0.570155

Epoch: 5
Loss: 0.5618653249641804
ROC train: 0.622205	val: 0.567642	test: 0.557642
PRC train: 0.642674	val: 0.614174	test: 0.580074

Epoch: 6
Loss: 0.53234540486997
ROC train: 0.640318	val: 0.577476	test: 0.567166
PRC train: 0.652793	val: 0.620426	test: 0.585107

Epoch: 7
Loss: 0.5269471446131911
ROC train: 0.655354	val: 0.580180	test: 0.578504
PRC train: 0.660254	val: 0.624955	test: 0.588783

Epoch: 8
Loss: 0.5153181207860067
ROC train: 0.665725	val: 0.590161	test: 0.586853
PRC train: 0.667279	val: 0.628770	test: 0.589885

Epoch: 9
Loss: 0.5080144851622465
ROC train: 0.678350	val: 0.597314	test: 0.587162
PRC train: 0.672905	val: 0.631414	test: 0.590649

Epoch: 10
Loss: 0.5057174681913843
ROC train: 0.689452	val: 0.604013	test: 0.595783
PRC train: 0.677506	val: 0.633616	test: 0.594642

Epoch: 11
Loss: 0.49650286418494416
ROC train: 0.695413	val: 0.612292	test: 0.598741
PRC train: 0.681083	val: 0.636166	test: 0.597141

Epoch: 12
Loss: 0.4930774018395255
ROC train: 0.698003	val: 0.616775	test: 0.596379
PRC train: 0.683962	val: 0.637365	test: 0.596358

Epoch: 13
Loss: 0.4859392536793564
ROC train: 0.702269	val: 0.614462	test: 0.601097
PRC train: 0.689352	val: 0.634684	test: 0.597513

Epoch: 14
Loss: 0.4867186965004938
ROC train: 0.707870	val: 0.609721	test: 0.598604
PRC train: 0.690322	val: 0.637243	test: 0.597534

Epoch: 15
Loss: 0.4797143948218679
ROC train: 0.715581	val: 0.613322	test: 0.594814
PRC train: 0.694221	val: 0.638978	test: 0.595361

Epoch: 16
Loss: 0.47317114933348325
ROC train: 0.718247	val: 0.616575	test: 0.595386
PRC train: 0.700752	val: 0.636130	test: 0.595710

Epoch: 17
Loss: 0.47141557913058973
ROC train: 0.724222	val: 0.624895	test: 0.602941
PRC train: 0.704495	val: 0.642753	test: 0.598156

Epoch: 18
Loss: 0.4709197010195534
ROC train: 0.718855	val: 0.618195	test: 0.599390
PRC train: 0.698118	val: 0.642089	test: 0.597099

Epoch: 19
Loss: 0.4696079472001153
ROC train: 0.727590	val: 0.628395	test: 0.599835
PRC train: 0.707796	val: 0.647236	test: 0.599697

Epoch: 20
Loss: 0.4696305741985592
ROC train: 0.736444	val: 0.630119	test: 0.605434
PRC train: 0.713403	val: 0.649418	test: 0.604774

Epoch: 21
Loss: 0.45980890359298954
ROC train: 0.737895	val: 0.629388	test: 0.604211
PRC train: 0.715235	val: 0.652631	test: 0.603423

Epoch: 22
Loss: 0.4642100901224415
ROC train: 0.744193	val: 0.636769	test: 0.601530
PRC train: 0.718785	val: 0.657716	test: 0.602746

Epoch: 23
Loss: 0.4595514952013284
ROC train: 0.745281	val: 0.642541	test: 0.604324
PRC train: 0.720879	val: 0.658037	test: 0.607643

Epoch: 24
Loss: 0.4584101001325032
ROC train: 0.745825	val: 0.641177	test: 0.605139
PRC train: 0.721653	val: 0.660627	test: 0.609332

Epoch: 25
Loss: 0.4542052484504867
ROC train: 0.748703	val: 0.639983	test: 0.601086
PRC train: 0.722732	val: 0.659505	test: 0.603565

Epoch: 26
Loss: 0.45433984573714686
ROC train: 0.753994	val: 0.636114	test: 0.598018
PRC train: 0.726377	val: 0.648453	test: 0.604262

Epoch: 27
Loss: 0.459399095122175
ROC train: 0.756812	val: 0.639492	test: 0.603606
PRC train: 0.728894	val: 0.652475	test: 0.605746

Epoch: 28
Loss: 0.448241181186291
ROC train: 0.754368	val: 0.641443	test: 0.607324
PRC train: 0.725981	val: 0.659919	test: 0.605321

Epoch: 29
Loss: 0.4546364384873581
ROC train: 0.762749	val: 0.642491	test: 0.608489
PRC train: 0.733908	val: 0.660969	test: 0.611343

Epoch: 30
Loss: 0.44520543432763426
ROC train: 0.763343	val: 0.636824	test: 0.612123
PRC train: 0.735405	val: 0.652717	test: 0.614370

Epoch: 31
Loss: 0.4436890527911156
ROC train: 0.773420	val: 0.647778	test: 0.617440
PRC train: 0.740298	val: 0.661300	test: 0.613211

Epoch: 32
Loss: 0.4475008990125312
ROC train: 0.771942	val: 0.649657	test: 0.611457
PRC train: 0.740367	val: 0.663203	test: 0.612467

Epoch: 33
Loss: 0.4427813200059495

ROC train: 0.773590	val: 0.656643	test: 0.618068
PRC train: 0.738424	val: 0.677579	test: 0.623298

Epoch: 34
Loss: 0.4459596245625756
ROC train: 0.772616	val: 0.657284	test: 0.617133
PRC train: 0.737816	val: 0.677622	test: 0.622908

Epoch: 35
Loss: 0.44502170906885236
ROC train: 0.775937	val: 0.648097	test: 0.608214
PRC train: 0.741427	val: 0.672391	test: 0.618766

Epoch: 36
Loss: 0.44567364719115
ROC train: 0.777030	val: 0.642892	test: 0.602847
PRC train: 0.743642	val: 0.670157	test: 0.614845

Epoch: 37
Loss: 0.44490253947883823
ROC train: 0.785218	val: 0.647015	test: 0.610892
PRC train: 0.748075	val: 0.669526	test: 0.617513

Epoch: 38
Loss: 0.443881787120024
ROC train: 0.789672	val: 0.647902	test: 0.614545
PRC train: 0.752506	val: 0.668100	test: 0.619844

Epoch: 39
Loss: 0.43959940428567945
ROC train: 0.784461	val: 0.644698	test: 0.612760
PRC train: 0.748883	val: 0.668836	test: 0.618011

Epoch: 40
Loss: 0.44099560075802874
ROC train: 0.793432	val: 0.659384	test: 0.621974
PRC train: 0.754582	val: 0.677355	test: 0.622260

Epoch: 41
Loss: 0.4385089801981588
ROC train: 0.793313	val: 0.660509	test: 0.616853
PRC train: 0.753804	val: 0.676722	test: 0.622554

Epoch: 42
Loss: 0.43807164337513405
ROC train: 0.795240	val: 0.644321	test: 0.607296
PRC train: 0.757129	val: 0.668459	test: 0.620138

Epoch: 43
Loss: 0.43903096839180444
ROC train: 0.790326	val: 0.636589	test: 0.603098
PRC train: 0.753623	val: 0.662341	test: 0.619098

Epoch: 44
Loss: 0.4420393124502087
ROC train: 0.804279	val: 0.648865	test: 0.609119
PRC train: 0.763793	val: 0.670903	test: 0.619145

Epoch: 45
Loss: 0.4291606047122036
ROC train: 0.804124	val: 0.660180	test: 0.603840
PRC train: 0.763042	val: 0.678499	test: 0.615750

Epoch: 46
Loss: 0.4251926300282297
ROC train: 0.810909	val: 0.661185	test: 0.606912
PRC train: 0.770527	val: 0.677629	test: 0.619686

Epoch: 47
Loss: 0.4330619757783122
ROC train: 0.808620	val: 0.650287	test: 0.607395
PRC train: 0.769721	val: 0.672212	test: 0.621144

Epoch: 48
Loss: 0.4209724129376188
ROC train: 0.809897	val: 0.648316	test: 0.607593
PRC train: 0.768552	val: 0.672011	test: 0.618131

Epoch: 49
Loss: 0.4233055161559718
ROC train: 0.816250	val: 0.652539	test: 0.614766
PRC train: 0.773269	val: 0.673545	test: 0.622709

Epoch: 50
Loss: 0.42434677845490537
ROC train: 0.820441	val: 0.650111	test: 0.616040
PRC train: 0.779167	val: 0.672908	test: 0.623832

Epoch: 51
Loss: 0.41693311111404985
ROC train: 0.823204	val: 0.648861	test: 0.619659
PRC train: 0.782648	val: 0.673067	test: 0.628099

Epoch: 52
Loss: 0.42003347358208326
ROC train: 0.825298	val: 0.650114	test: 0.619097
PRC train: 0.782461	val: 0.669099	test: 0.625877

Epoch: 53
Loss: 0.4163395105214475
ROC train: 0.822531	val: 0.641337	test: 0.607069
PRC train: 0.779698	val: 0.661102	test: 0.621667

Epoch: 54
Loss: 0.4166463052284472
ROC train: 0.826440	val: 0.641180	test: 0.603498
PRC train: 0.781608	val: 0.663122	test: 0.618735

Epoch: 55
Loss: 0.4094861309507888
ROC train: 0.829347	val: 0.641526	test: 0.607681
PRC train: 0.784611	val: 0.665779	test: 0.618428

Epoch: 56
Loss: 0.4114314517909762
ROC train: 0.832611	val: 0.643123	test: 0.611882
PRC train: 0.788920	val: 0.668857	test: 0.623429

Epoch: 57
Loss: 0.4140941611260014
ROC train: 0.831188	val: 0.642364	test: 0.613057
PRC train: 0.786779	val: 0.666657	test: 0.628947

Epoch: 58
Loss: 0.4166658481725625
ROC train: 0.833334	val: 0.647986	test: 0.617118
PRC train: 0.789492	val: 0.669633	test: 0.629185

Epoch: 59
Loss: 0.4111578102247492
ROC train: 0.835915	val: 0.657637	test: 0.614115
PRC train: 0.791277	val: 0.673975	test: 0.627675

Epoch: 60
Loss: 0.41332441220671584
ROC train: 0.834717	val: 0.653814	test: 0.613723
PRC train: 0.792892	val: 0.672400	test: 0.627322

Epoch: 61
Loss: 0.410011020859794
ROC train: 0.834069	val: 0.649821	test: 0.619315
PRC train: 0.792417	val: 0.666930	test: 0.625877

Epoch: 62
Loss: 0.4147907898670323
ROC train: 0.836191	val: 0.649984	test: 0.616869
PRC train: 0.790957	val: 0.666851	test: 0.623921

Epoch: 63
Loss: 0.4039365809596058
ROC train: 0.841856	val: 0.639613	test: 0.607205
PRC train: 0.795706	val: 0.662165	test: 0.621565

Epoch: 64
Loss: 0.4094537386800689
ROC train: 0.839750	val: 0.629332	test: 0.600024
PRC train: 0.796294	val: 0.659194	test: 0.623344

Epoch: 65
Loss: 0.4099034287600899
ROC train: 0.846934	val: 0.637605	test: 0.609439
PRC train: 0.802652	val: 0.663989	test: 0.628627

Epoch: 66
Loss: 0.4057209461229272
ROC train: 0.851099	val: 0.652710	test: 0.617233
PRC train: 0.804847	val: 0.667985	test: 0.631894

Epoch: 67
Loss: 0.3965589689547643
ROC train: 0.852395	val: 0.647446	test: 0.618607
PRC train: 0.809262	val: 0.663780	test: 0.634223

Epoch: 68
Loss: 0.3984913672641918
ROC train: 0.846915	val: 0.631134	test: 0.613619
PRC train: 0.805261	val: 0.655415	test: 0.631783

Epoch: 69
Loss: 0.3978703755733275
ROC train: 0.850447	val: 0.631647	test: 0.609641
PRC train: 0.807198	val: 0.658761	test: 0.626748

Epoch: 70
Loss: 0.40008159235115337
ROC train: 0.844701	val: 0.639409	test: 0.612491
PRC train: 0.801100	val: 0.665129	test: 0.627374

Epoch: 71
Loss: 0.4025048616667349
ROC train: 0.852875	val: 0.633534	test: 0.623623
PRC train: 0.808858	val: 0.659891	test: 0.632243

Epoch: 72
Loss: 0.4058430009196259
ROC train: 0.854536	val: 0.630070	test: 0.624223
PRC train: 0.811430	val: 0.657226	test: 0.632319

Epoch: 73
Loss: 0.39875197694706366
ROC train: 0.860298	val: 0.646471	test: 0.623403
PRC train: 0.815166	val: 0.667132	test: 0.633572

Epoch: 74
Loss: 0.3940219226347934
ROC train: 0.861198	val: 0.651730	test: 0.623519
PRC train: 0.816882	val: 0.671078	test: 0.633635

Epoch: 75
Loss: 0.3900926006703349
ROC train: 0.862351	val: 0.645266	test: 0.623000
PRC train: 0.818016	val: 0.665850	test: 0.630827

Epoch: 76
Loss: 0.3922842000015149
ROC train: 0.864212	val: 0.636142	test: 0.621457
PRC train: 0.820947	val: 0.660795	test: 0.632226

Epoch: 77
Loss: 0.3887213343494442
ROC train: 0.860361	val: 0.626087	test: 0.618445
PRC train: 0.821184	val: 0.655961	test: 0.636504

Epoch: 78
Loss: 0.3869687389513165
ROC train: 0.856286	val: 0.629033	test: 0.617747
PRC train: 0.818457	val: 0.654576	test: 0.635774

Epoch: 79
Loss: 0.38919184182360556
ROC train: 0.862331	val: 0.639107	test: 0.621057
PRC train: 0.823264	val: 0.661445	test: 0.633354

Epoch: 80
Loss: 0.38891695617507493
ROC train: 0.869404	val: 0.642934	test: 0.622463
PRC train: 0.827307	val: 0.663927	test: 0.632443

Epoch: 81
Loss: 0.38724862058449144
ROC train: 0.868739	val: 0.627605	test: 0.614844
PRC train: 0.825181	val: 0.653260	test: 0.631856

Epoch: 82
Loss: 0.3799845605944958
ROC train: 0.872804	val: 0.627178	test: 0.610627
PRC train: 0.828176	val: 0.651384	test: 0.625160

Epoch: 83
Loss: 0.3905667598390932
ROC train: 0.877323	val: 0.643035	test: 0.618226
PRC train: 0.833306	val: 0.661782	test: 0.629928

Epoch: 84
Loss: 0.3839247707130723
ROC train: 0.872385	val: 0.646270	test: 0.623575
PRC train: 0.830826	val: 0.663939	test: 0.637758

Epoch: 85
Loss: 0.38781989729848765
ROC train: 0.874586	val: 0.636182	test: 0.624207
PRC train: 0.834269	val: 0.662764	test: 0.636148

Epoch: 86
Loss: 0.3804934373716865
ROC train: 0.869253	val: 0.625965	test: 0.619819
PRC train: 0.828213	val: 0.655415	test: 0.633120

Epoch: 87
Loss: 0.3860103424485826
ROC train: 0.877101	val: 0.636689	test: 0.623301
PRC train: 0.834580	val: 0.659292	test: 0.639112

Epoch: 88
Loss: 0.3769031913117404
ROC train: 0.878628	val: 0.640212	test: 0.624458
PRC train: 0.838919	val: 0.662077	test: 0.637685

Epoch: 89
Loss: 0.37321727278834316
ROC train: 0.878375	val: 0.635756	test: 0.620101
PRC train: 0.837969	val: 0.659782	test: 0.633843

Epoch: 90
Loss: 0.3763507274581728
ROC train: 0.879137	val: 0.638226	test: 0.617681
PRC train: 0.838572	val: 0.661345	test: 0.630560

Epoch: 91
Loss: 0.37619086850458716
ROC train: 0.879807	val: 0.637649	test: 0.618515
PRC train: 0.839508	val: 0.659201	test: 0.634493

Epoch: 92
Loss: 0.3785897338936454
ROC train: 0.878419	val: 0.636386	test: 0.618583
PRC train: 0.839221	val: 0.659374	test: 0.635502

Epoch: 93
Loss: 0.3721062355807671
ROC train: 0.882027	val: 0.632339	test: 0.620460
PRC train: 0.842092	val: 0.656582	test: 0.637203

Epoch: 94
Loss: 0.3723992640297986
ROC train: 0.886743	val: 0.628250	test: 0.621724
ROC train: 0.771560	val: 0.652210	test: 0.604590
PRC train: 0.735877	val: 0.681540	test: 0.617206

Epoch: 34
Loss: 0.4478639211986468
ROC train: 0.775908	val: 0.645323	test: 0.605123
PRC train: 0.739541	val: 0.673853	test: 0.616330

Epoch: 35
Loss: 0.4516132901683012
ROC train: 0.778351	val: 0.644462	test: 0.597169
PRC train: 0.740245	val: 0.669632	test: 0.609894

Epoch: 36
Loss: 0.44555509367069723
ROC train: 0.774492	val: 0.651113	test: 0.599550
PRC train: 0.738301	val: 0.668863	test: 0.613463

Epoch: 37
Loss: 0.4514203454323519
ROC train: 0.764580	val: 0.643206	test: 0.592327
PRC train: 0.731849	val: 0.668711	test: 0.617079

Epoch: 38
Loss: 0.44726541268632297
ROC train: 0.784202	val: 0.648435	test: 0.605191
PRC train: 0.745649	val: 0.674113	test: 0.621485

Epoch: 39
Loss: 0.45159069887874387
ROC train: 0.789837	val: 0.654232	test: 0.610172
PRC train: 0.748116	val: 0.676353	test: 0.621479

Epoch: 40
Loss: 0.4417095420916875
ROC train: 0.792492	val: 0.647454	test: 0.611880
PRC train: 0.751763	val: 0.669252	test: 0.622702

Epoch: 41
Loss: 0.4410973182525314
ROC train: 0.789238	val: 0.642669	test: 0.608214
PRC train: 0.750099	val: 0.665665	test: 0.623387

Epoch: 42
Loss: 0.44083946477708524
ROC train: 0.795953	val: 0.651740	test: 0.608590
PRC train: 0.756840	val: 0.672663	test: 0.622471

Epoch: 43
Loss: 0.4383406522091639
ROC train: 0.795403	val: 0.654242	test: 0.603542
PRC train: 0.756414	val: 0.676122	test: 0.620290

Epoch: 44
Loss: 0.4347710246765851
ROC train: 0.800943	val: 0.653489	test: 0.607385
PRC train: 0.760837	val: 0.674398	test: 0.623231

Epoch: 45
Loss: 0.4327012159547282
ROC train: 0.801118	val: 0.651377	test: 0.607365
PRC train: 0.761582	val: 0.673547	test: 0.622448

Epoch: 46
Loss: 0.4302600303986102
ROC train: 0.801525	val: 0.644420	test: 0.605411
PRC train: 0.760586	val: 0.675772	test: 0.618651

Epoch: 47
Loss: 0.43134766005312236
ROC train: 0.805870	val: 0.643210	test: 0.615846
PRC train: 0.762622	val: 0.668772	test: 0.621897

Epoch: 48
Loss: 0.42557566547988646
ROC train: 0.799643	val: 0.638425	test: 0.617526
PRC train: 0.759202	val: 0.663426	test: 0.623959

Epoch: 49
Loss: 0.42772970277003275
ROC train: 0.809123	val: 0.637883	test: 0.611133
PRC train: 0.766741	val: 0.666722	test: 0.622214

Epoch: 50
Loss: 0.4291894668486405
ROC train: 0.814627	val: 0.649477	test: 0.611602
PRC train: 0.769704	val: 0.667715	test: 0.621375

Epoch: 51
Loss: 0.42247686446197485
ROC train: 0.815401	val: 0.647813	test: 0.616157
PRC train: 0.771314	val: 0.669902	test: 0.627562

Epoch: 52
Loss: 0.42458105161671716
ROC train: 0.814255	val: 0.637498	test: 0.608368
PRC train: 0.772462	val: 0.675950	test: 0.624763

Epoch: 53
Loss: 0.4225507474227158
ROC train: 0.821717	val: 0.639023	test: 0.614231
PRC train: 0.778094	val: 0.668513	test: 0.624035

Epoch: 54
Loss: 0.4205458985676859
ROC train: 0.815507	val: 0.644431	test: 0.617467
PRC train: 0.771366	val: 0.660831	test: 0.622889

Epoch: 55
Loss: 0.42189758954551715
ROC train: 0.823291	val: 0.646543	test: 0.622853
PRC train: 0.778936	val: 0.659843	test: 0.630845

Epoch: 56
Loss: 0.41532598076511734
ROC train: 0.825791	val: 0.638425	test: 0.618880
PRC train: 0.781665	val: 0.658839	test: 0.630048

Epoch: 57
Loss: 0.4198136817539949
ROC train: 0.828965	val: 0.641313	test: 0.616493
PRC train: 0.783706	val: 0.664559	test: 0.626592

Epoch: 58
Loss: 0.41774022900470875
ROC train: 0.830839	val: 0.642239	test: 0.615238
PRC train: 0.783572	val: 0.667863	test: 0.622441

Epoch: 59
Loss: 0.41615204381361853
ROC train: 0.833286	val: 0.639894	test: 0.615138
PRC train: 0.784774	val: 0.664056	test: 0.623029

Epoch: 60
Loss: 0.41270125853597417
ROC train: 0.835750	val: 0.640726	test: 0.613408
PRC train: 0.787105	val: 0.662520	test: 0.624956

Epoch: 61
Loss: 0.4054633299858585
ROC train: 0.835995	val: 0.641498	test: 0.615830
PRC train: 0.788761	val: 0.662493	test: 0.629671

Epoch: 62
Loss: 0.41588634707381006
ROC train: 0.838146	val: 0.642987	test: 0.621609
PRC train: 0.793376	val: 0.659703	test: 0.633253

Epoch: 63
Loss: 0.40605180391216106
ROC train: 0.842158	val: 0.643708	test: 0.614304
PRC train: 0.796356	val: 0.658528	test: 0.624824

Epoch: 64
Loss: 0.4086849926353172
ROC train: 0.840744	val: 0.630152	test: 0.608484
PRC train: 0.797000	val: 0.654878	test: 0.619366

Epoch: 65
Loss: 0.404057650393867
ROC train: 0.834834	val: 0.625032	test: 0.613564
PRC train: 0.789900	val: 0.654600	test: 0.621357

Epoch: 66
Loss: 0.4004015021513954
ROC train: 0.844207	val: 0.637594	test: 0.613871
PRC train: 0.799687	val: 0.660056	test: 0.620647

Epoch: 67
Loss: 0.3988368412308224
ROC train: 0.840912	val: 0.640878	test: 0.607073
PRC train: 0.796389	val: 0.659235	test: 0.618215

Epoch: 68
Loss: 0.40005198749938237
ROC train: 0.846862	val: 0.642006	test: 0.619862
PRC train: 0.799929	val: 0.662393	test: 0.630625

Epoch: 69
Loss: 0.3948220458724888
ROC train: 0.851306	val: 0.633284	test: 0.628251
PRC train: 0.802961	val: 0.657244	test: 0.638379

Epoch: 70
Loss: 0.4085859967986089
ROC train: 0.850087	val: 0.625181	test: 0.621229
PRC train: 0.802782	val: 0.655485	test: 0.630716

Epoch: 71
Loss: 0.4018621113073673
ROC train: 0.844548	val: 0.627191	test: 0.613833
PRC train: 0.799051	val: 0.653541	test: 0.622645

Epoch: 72
Loss: 0.3957335565095013
ROC train: 0.845119	val: 0.626184	test: 0.612713
PRC train: 0.800525	val: 0.651584	test: 0.623249

Epoch: 73
Loss: 0.3982767365152521
ROC train: 0.855215	val: 0.626863	test: 0.618607
PRC train: 0.808859	val: 0.651184	test: 0.627860

Epoch: 74
Loss: 0.3982839200890814
ROC train: 0.858476	val: 0.619215	test: 0.621589
PRC train: 0.812725	val: 0.647793	test: 0.630959

Epoch: 75
Loss: 0.39235396324236993
ROC train: 0.858676	val: 0.624747	test: 0.621154
PRC train: 0.812620	val: 0.651763	test: 0.632126

Epoch: 76
Loss: 0.3926691737579072
ROC train: 0.861252	val: 0.634072	test: 0.619680
PRC train: 0.813751	val: 0.655434	test: 0.631919

Epoch: 77
Loss: 0.39128037010577993
ROC train: 0.858496	val: 0.637195	test: 0.623635
PRC train: 0.811631	val: 0.655103	test: 0.633719

Epoch: 78
Loss: 0.39751653903808415
ROC train: 0.858048	val: 0.634061	test: 0.624208
PRC train: 0.811144	val: 0.653481	test: 0.633468

Epoch: 79
Loss: 0.3971845308086958
ROC train: 0.865330	val: 0.626002	test: 0.622536
PRC train: 0.817088	val: 0.651752	test: 0.635982

Epoch: 80
Loss: 0.3905442414350868
ROC train: 0.865993	val: 0.626377	test: 0.624037
PRC train: 0.817206	val: 0.650781	test: 0.636715

Epoch: 81
Loss: 0.3842429274861464
ROC train: 0.864314	val: 0.629833	test: 0.628548
PRC train: 0.817962	val: 0.650976	test: 0.637205

Epoch: 82
Loss: 0.3950274586044692
ROC train: 0.865947	val: 0.626118	test: 0.626955
PRC train: 0.821385	val: 0.648045	test: 0.634657

Epoch: 83
Loss: 0.3878133666767151
ROC train: 0.859158	val: 0.614628	test: 0.612798
PRC train: 0.814645	val: 0.640723	test: 0.628775

Epoch: 84
Loss: 0.386988186243726
ROC train: 0.865068	val: 0.620425	test: 0.613431
PRC train: 0.821363	val: 0.645411	test: 0.625005

Epoch: 85
Loss: 0.3852882677416555
ROC train: 0.867999	val: 0.621855	test: 0.625397
PRC train: 0.821952	val: 0.646817	test: 0.626594

Epoch: 86
Loss: 0.3832430952323944
ROC train: 0.871085	val: 0.617914	test: 0.626438
PRC train: 0.823355	val: 0.646546	test: 0.630330

Epoch: 87
Loss: 0.38800332760053335
ROC train: 0.874000	val: 0.620721	test: 0.623236
PRC train: 0.827109	val: 0.647180	test: 0.634049

Epoch: 88
Loss: 0.38408032332441794
ROC train: 0.871805	val: 0.632117	test: 0.616814
PRC train: 0.825569	val: 0.650017	test: 0.631615

Epoch: 89
Loss: 0.3861951288822574
ROC train: 0.872471	val: 0.636052	test: 0.623253
PRC train: 0.824825	val: 0.651911	test: 0.636179

Epoch: 90
Loss: 0.3820320103314505
ROC train: 0.871020	val: 0.623336	test: 0.627341
PRC train: 0.827703	val: 0.646932	test: 0.637034

Epoch: 91
Loss: 0.38441420162286116
ROC train: 0.863629	val: 0.612656	test: 0.623740
PRC train: 0.821573	val: 0.639427	test: 0.631749

Epoch: 92
Loss: 0.3730168767939141
ROC train: 0.871243	val: 0.627259	test: 0.624933
PRC train: 0.827738	val: 0.643543	test: 0.632880

Epoch: 93
Loss: 0.38151447727207316
ROC train: 0.879914	val: 0.638044	test: 0.626516
PRC train: 0.834630	val: 0.653086	test: 0.634812

Epoch: 94
Loss: 0.3758135102313235
ROC train: 0.773337	val: 0.658012	test: 0.621728
PRC train: 0.743675	val: 0.679964	test: 0.624164

Epoch: 34
Loss: 0.4419093066017521
ROC train: 0.776370	val: 0.658406	test: 0.619838
PRC train: 0.743641	val: 0.680522	test: 0.621523

Epoch: 35
Loss: 0.44526150861760855
ROC train: 0.783017	val: 0.653230	test: 0.619202
PRC train: 0.750377	val: 0.681198	test: 0.622772

Epoch: 36
Loss: 0.44233753622630106
ROC train: 0.785701	val: 0.646069	test: 0.615328
PRC train: 0.753732	val: 0.678975	test: 0.622713

Epoch: 37
Loss: 0.4380181655545863
ROC train: 0.789433	val: 0.647008	test: 0.616875
PRC train: 0.756498	val: 0.676104	test: 0.622608

Epoch: 38
Loss: 0.44448217384904626
ROC train: 0.789795	val: 0.646480	test: 0.616519
PRC train: 0.757777	val: 0.673884	test: 0.620676

Epoch: 39
Loss: 0.4411468448622812
ROC train: 0.790747	val: 0.647959	test: 0.622996
PRC train: 0.758931	val: 0.671948	test: 0.625204

Epoch: 40
Loss: 0.4337859980700576
ROC train: 0.792014	val: 0.642590	test: 0.611830
PRC train: 0.759813	val: 0.670901	test: 0.619996

Epoch: 41
Loss: 0.4370551217203481
ROC train: 0.793971	val: 0.639741	test: 0.608190
PRC train: 0.760794	val: 0.670253	test: 0.616812

Epoch: 42
Loss: 0.43027811178538206
ROC train: 0.801305	val: 0.642414	test: 0.616985
PRC train: 0.765961	val: 0.671522	test: 0.624113

Epoch: 43
Loss: 0.43835395366052593
ROC train: 0.804092	val: 0.647082	test: 0.619201
PRC train: 0.768179	val: 0.674208	test: 0.626821

Epoch: 44
Loss: 0.4287117776296618
ROC train: 0.800652	val: 0.652834	test: 0.616347
PRC train: 0.763759	val: 0.678097	test: 0.620360

Epoch: 45
Loss: 0.43225647557522556
ROC train: 0.804082	val: 0.655462	test: 0.620116
PRC train: 0.765839	val: 0.677512	test: 0.621276

Epoch: 46
Loss: 0.4246652918547927
ROC train: 0.812121	val: 0.651227	test: 0.625131
PRC train: 0.772058	val: 0.670488	test: 0.629839

Epoch: 47
Loss: 0.42657681364665617
ROC train: 0.809729	val: 0.639891	test: 0.618517
PRC train: 0.772542	val: 0.667971	test: 0.623846

Epoch: 48
Loss: 0.4298631403629124
ROC train: 0.805188	val: 0.642481	test: 0.621083
PRC train: 0.770728	val: 0.674247	test: 0.624446

Epoch: 49
Loss: 0.4255659380622185
ROC train: 0.813626	val: 0.657311	test: 0.628154
PRC train: 0.775066	val: 0.681643	test: 0.631301

Epoch: 50
Loss: 0.4223470092482114
ROC train: 0.814073	val: 0.662439	test: 0.623060
PRC train: 0.776196	val: 0.680981	test: 0.627510

Epoch: 51
Loss: 0.42379712404521563
ROC train: 0.817106	val: 0.656541	test: 0.622568
PRC train: 0.778562	val: 0.677027	test: 0.624663

Epoch: 52
Loss: 0.42095750552126787
ROC train: 0.814583	val: 0.641739	test: 0.618762
PRC train: 0.777775	val: 0.669283	test: 0.624583

Epoch: 53
Loss: 0.41986557448811634
ROC train: 0.809385	val: 0.631005	test: 0.609853
PRC train: 0.773294	val: 0.660698	test: 0.623789

Epoch: 54
Loss: 0.4157129471635391
ROC train: 0.814795	val: 0.636046	test: 0.610422
PRC train: 0.776679	val: 0.665613	test: 0.621817

Epoch: 55
Loss: 0.41563334748601205
ROC train: 0.823761	val: 0.646836	test: 0.613947
PRC train: 0.782374	val: 0.670439	test: 0.623285

Epoch: 56
Loss: 0.41890640647303573
ROC train: 0.830283	val: 0.652071	test: 0.622258
PRC train: 0.789349	val: 0.670176	test: 0.628567

Epoch: 57
Loss: 0.4098699033588949
ROC train: 0.830406	val: 0.655765	test: 0.631990
PRC train: 0.791923	val: 0.671154	test: 0.635710

Epoch: 58
Loss: 0.4159015896205232
ROC train: 0.833998	val: 0.653124	test: 0.632185
PRC train: 0.794427	val: 0.668294	test: 0.635887

Epoch: 59
Loss: 0.40707358024129137
ROC train: 0.838980	val: 0.637407	test: 0.622724
PRC train: 0.796995	val: 0.662829	test: 0.631407

Epoch: 60
Loss: 0.40880760084217116
ROC train: 0.832522	val: 0.629498	test: 0.612918
PRC train: 0.792340	val: 0.663296	test: 0.629505

Epoch: 61
Loss: 0.4088065039166762
ROC train: 0.831962	val: 0.637184	test: 0.614934
PRC train: 0.790753	val: 0.666391	test: 0.637382

Epoch: 62
Loss: 0.41055666950946657
ROC train: 0.837914	val: 0.651602	test: 0.624198
PRC train: 0.795722	val: 0.673598	test: 0.638484

Epoch: 63
Loss: 0.4095622020871843
ROC train: 0.839719	val: 0.652726	test: 0.626721
PRC train: 0.796915	val: 0.673474	test: 0.634136

Epoch: 64
Loss: 0.4053766386180966
ROC train: 0.838522	val: 0.636598	test: 0.621720
PRC train: 0.797868	val: 0.662625	test: 0.633176

Epoch: 65
Loss: 0.41381422360238795
ROC train: 0.843742	val: 0.635505	test: 0.623226
PRC train: 0.801215	val: 0.664736	test: 0.633056

Epoch: 66
Loss: 0.4037832349773198
ROC train: 0.825789	val: 0.645118	test: 0.623643
PRC train: 0.787513	val: 0.673974	test: 0.632553

Epoch: 67
Loss: 0.40784748773621926
ROC train: 0.834023	val: 0.645755	test: 0.627906
PRC train: 0.794912	val: 0.671539	test: 0.639437

Epoch: 68
Loss: 0.40202525493213426
ROC train: 0.846252	val: 0.639629	test: 0.624994
PRC train: 0.807396	val: 0.665196	test: 0.641349

Epoch: 69
Loss: 0.39952012329837305
ROC train: 0.848877	val: 0.635234	test: 0.625868
PRC train: 0.807648	val: 0.661388	test: 0.637909

Epoch: 70
Loss: 0.3970244086425455
ROC train: 0.852682	val: 0.636196	test: 0.629058
PRC train: 0.812161	val: 0.661186	test: 0.636142

Epoch: 71
Loss: 0.3949749380118748
ROC train: 0.854705	val: 0.644884	test: 0.633719
PRC train: 0.812579	val: 0.664898	test: 0.643708

Epoch: 72
Loss: 0.3960171301846339
ROC train: 0.855736	val: 0.640172	test: 0.628889
PRC train: 0.813631	val: 0.663784	test: 0.644892

Epoch: 73
Loss: 0.3924996791445156
ROC train: 0.858047	val: 0.637654	test: 0.624803
PRC train: 0.817279	val: 0.664825	test: 0.642762

Epoch: 74
Loss: 0.39532390846782683
ROC train: 0.856351	val: 0.638111	test: 0.622616
PRC train: 0.815053	val: 0.664559	test: 0.637391

Epoch: 75
Loss: 0.39200508356835545
ROC train: 0.861226	val: 0.649217	test: 0.624977
PRC train: 0.818610	val: 0.669593	test: 0.640263

Epoch: 76
Loss: 0.39223069001986605
ROC train: 0.857346	val: 0.642265	test: 0.618001
PRC train: 0.818590	val: 0.670196	test: 0.635427

Epoch: 77
Loss: 0.395415841707104
ROC train: 0.858334	val: 0.640086	test: 0.621643
PRC train: 0.820145	val: 0.668452	test: 0.634374

Epoch: 78
Loss: 0.39693264966037994
ROC train: 0.857234	val: 0.638757	test: 0.626086
PRC train: 0.817427	val: 0.664291	test: 0.629575

Epoch: 79
Loss: 0.3880590999297129
ROC train: 0.856395	val: 0.631023	test: 0.624419
PRC train: 0.814683	val: 0.657682	test: 0.628996

Epoch: 80
Loss: 0.3895368443954961
ROC train: 0.861976	val: 0.630057	test: 0.625178
PRC train: 0.819619	val: 0.655125	test: 0.637287

Epoch: 81
Loss: 0.3887845633873828
ROC train: 0.862630	val: 0.632222	test: 0.623986
PRC train: 0.821347	val: 0.655600	test: 0.635928

Epoch: 82
Loss: 0.38277198325339445
ROC train: 0.866245	val: 0.639429	test: 0.628253
PRC train: 0.825000	val: 0.659475	test: 0.640453

Epoch: 83
Loss: 0.37983458543979587
ROC train: 0.867769	val: 0.640935	test: 0.629485
PRC train: 0.826642	val: 0.658958	test: 0.643067

Epoch: 84
Loss: 0.3886010249476304
ROC train: 0.871383	val: 0.650131	test: 0.631242
PRC train: 0.829531	val: 0.666791	test: 0.646055

Epoch: 85
Loss: 0.38289174651166535
ROC train: 0.867465	val: 0.643299	test: 0.620210
PRC train: 0.826907	val: 0.665536	test: 0.637497

Epoch: 86
Loss: 0.38285539539317737
ROC train: 0.866883	val: 0.633321	test: 0.614696
PRC train: 0.825609	val: 0.661318	test: 0.630201

Epoch: 87
Loss: 0.37475104445707863
ROC train: 0.877993	val: 0.641141	test: 0.629621
PRC train: 0.835357	val: 0.665495	test: 0.638131

Epoch: 88
Loss: 0.3876798910902882
ROC train: 0.872918	val: 0.637173	test: 0.632151
PRC train: 0.832175	val: 0.666656	test: 0.642477

Epoch: 89
Loss: 0.3806973041727736
ROC train: 0.873136	val: 0.630487	test: 0.633636
PRC train: 0.834017	val: 0.664089	test: 0.648028

Epoch: 90
Loss: 0.37309523356126084
ROC train: 0.876593	val: 0.630100	test: 0.630373
PRC train: 0.836041	val: 0.663988	test: 0.642725

Epoch: 91
Loss: 0.37981097446711876
ROC train: 0.880429	val: 0.633754	test: 0.628853
PRC train: 0.838917	val: 0.663160	test: 0.642491

Epoch: 92
Loss: 0.37736340562988724
ROC train: 0.880924	val: 0.635145	test: 0.630750
PRC train: 0.837206	val: 0.660533	test: 0.645401

Epoch: 93
Loss: 0.38259626245344736
ROC train: 0.884078	val: 0.634853	test: 0.632116
PRC train: 0.843866	val: 0.662011	test: 0.642363

Epoch: 94
Loss: 0.37510080077043384
ROC train: 0.785428	val: 0.653530	test: 0.621799
PRC train: 0.749080	val: 0.699059	test: 0.618231

Epoch: 34
Loss: 0.4417982877244954
ROC train: 0.790700	val: 0.655508	test: 0.624044
PRC train: 0.752037	val: 0.701287	test: 0.619381

Epoch: 35
Loss: 0.4458335481828375
ROC train: 0.789829	val: 0.647641	test: 0.615550
PRC train: 0.752497	val: 0.696615	test: 0.612059

Epoch: 36
Loss: 0.43345341873103665
ROC train: 0.790135	val: 0.648854	test: 0.614538
PRC train: 0.752408	val: 0.693075	test: 0.612060

Epoch: 37
Loss: 0.4361259873023058
ROC train: 0.797475	val: 0.643578	test: 0.614371
PRC train: 0.759071	val: 0.695745	test: 0.616248

Epoch: 38
Loss: 0.43275276301160626
ROC train: 0.798463	val: 0.642850	test: 0.618106
PRC train: 0.760622	val: 0.695136	test: 0.616760

Epoch: 39
Loss: 0.42996008514822953
ROC train: 0.802866	val: 0.650130	test: 0.622911
PRC train: 0.762871	val: 0.697091	test: 0.618498

Epoch: 40
Loss: 0.43020751078484426
ROC train: 0.806564	val: 0.657368	test: 0.622973
PRC train: 0.765946	val: 0.701350	test: 0.619001

Epoch: 41
Loss: 0.43053323599465465
ROC train: 0.803001	val: 0.650998	test: 0.615325
PRC train: 0.764333	val: 0.700966	test: 0.613180

Epoch: 42
Loss: 0.4286046408565697
ROC train: 0.810957	val: 0.661864	test: 0.617254
PRC train: 0.769202	val: 0.706043	test: 0.614723

Epoch: 43
Loss: 0.4273125979819866
ROC train: 0.814481	val: 0.661203	test: 0.620672
PRC train: 0.771158	val: 0.704588	test: 0.617332

Epoch: 44
Loss: 0.4273816988874414
ROC train: 0.816173	val: 0.649845	test: 0.621193
PRC train: 0.775025	val: 0.705457	test: 0.617811

Epoch: 45
Loss: 0.4263934625520449
ROC train: 0.816372	val: 0.648534	test: 0.622044
PRC train: 0.775611	val: 0.706192	test: 0.618205

Epoch: 46
Loss: 0.4211630511802851
ROC train: 0.817663	val: 0.647940	test: 0.619134
PRC train: 0.775291	val: 0.702251	test: 0.616136

Epoch: 47
Loss: 0.4213043727399724
ROC train: 0.810403	val: 0.645786	test: 0.617070
PRC train: 0.771159	val: 0.696430	test: 0.615686

Epoch: 48
Loss: 0.42061200628278334
ROC train: 0.810370	val: 0.648631	test: 0.621460
PRC train: 0.770224	val: 0.700141	test: 0.620838

Epoch: 49
Loss: 0.41776742472612727
ROC train: 0.815168	val: 0.647668	test: 0.615128
PRC train: 0.772074	val: 0.698847	test: 0.621104

Epoch: 50
Loss: 0.41167740089875926
ROC train: 0.827070	val: 0.647397	test: 0.617777
PRC train: 0.783998	val: 0.700586	test: 0.624157

Epoch: 51
Loss: 0.41358301225773786
ROC train: 0.831594	val: 0.661726	test: 0.622834
PRC train: 0.785959	val: 0.707780	test: 0.621649

Epoch: 52
Loss: 0.4159582534682542
ROC train: 0.833020	val: 0.663836	test: 0.616554
PRC train: 0.790116	val: 0.710723	test: 0.617749

Epoch: 53
Loss: 0.4102576331240969
ROC train: 0.837837	val: 0.664592	test: 0.618173
PRC train: 0.792495	val: 0.707916	test: 0.620881

Epoch: 54
Loss: 0.41187683967716215
ROC train: 0.835244	val: 0.662411	test: 0.616020
PRC train: 0.790179	val: 0.708604	test: 0.617156

Epoch: 55
Loss: 0.40692571255936116
ROC train: 0.826459	val: 0.655898	test: 0.615044
PRC train: 0.784792	val: 0.704452	test: 0.614548

Epoch: 56
Loss: 0.4090725264813631
ROC train: 0.833496	val: 0.656932	test: 0.611852
PRC train: 0.791073	val: 0.705110	test: 0.617987

Epoch: 57
Loss: 0.40790742954622705
ROC train: 0.837395	val: 0.661693	test: 0.617139
PRC train: 0.792279	val: 0.704319	test: 0.616329

Epoch: 58
Loss: 0.4047783066273162
ROC train: 0.837591	val: 0.654687	test: 0.616577
PRC train: 0.793972	val: 0.702700	test: 0.613752

Epoch: 59
Loss: 0.4029849661031759
ROC train: 0.845896	val: 0.662073	test: 0.621051
PRC train: 0.797666	val: 0.707964	test: 0.621210

Epoch: 60
Loss: 0.40451313293514746
ROC train: 0.846644	val: 0.655910	test: 0.618654
PRC train: 0.800153	val: 0.703627	test: 0.618170

Epoch: 61
Loss: 0.39983463893283666
ROC train: 0.847955	val: 0.650765	test: 0.620878
PRC train: 0.802025	val: 0.701253	test: 0.618062

Epoch: 62
Loss: 0.39586035242088113
ROC train: 0.846069	val: 0.647969	test: 0.624215
PRC train: 0.801592	val: 0.697749	test: 0.620837

Epoch: 63
Loss: 0.402136025810399
ROC train: 0.846439	val: 0.648722	test: 0.623363
PRC train: 0.802469	val: 0.700036	test: 0.620506

Epoch: 64
Loss: 0.3996882391228657
ROC train: 0.842864	val: 0.646296	test: 0.621984
PRC train: 0.801895	val: 0.698423	test: 0.620392

Epoch: 65
Loss: 0.3966267986810459
ROC train: 0.851490	val: 0.652124	test: 0.621874
PRC train: 0.805634	val: 0.703123	test: 0.622205

Epoch: 66
Loss: 0.4014612845419388
ROC train: 0.855146	val: 0.656402	test: 0.619141
PRC train: 0.808323	val: 0.704624	test: 0.619586

Epoch: 67
Loss: 0.40269514386947997
ROC train: 0.856542	val: 0.651675	test: 0.616475
PRC train: 0.811242	val: 0.704397	test: 0.615959

Epoch: 68
Loss: 0.3977240874946556
ROC train: 0.860881	val: 0.648142	test: 0.613414
PRC train: 0.813015	val: 0.700865	test: 0.613239

Epoch: 69
Loss: 0.3950312680127046
ROC train: 0.861060	val: 0.650327	test: 0.615508
PRC train: 0.813671	val: 0.702049	test: 0.615353

Epoch: 70
Loss: 0.39451579674163906
ROC train: 0.861659	val: 0.650427	test: 0.613214
PRC train: 0.816137	val: 0.702972	test: 0.612723

Epoch: 71
Loss: 0.3924402698244855
ROC train: 0.863843	val: 0.656034	test: 0.621513
PRC train: 0.817521	val: 0.707944	test: 0.618390

Epoch: 72
Loss: 0.39000474141713154
ROC train: 0.863871	val: 0.657858	test: 0.621304
PRC train: 0.817253	val: 0.705059	test: 0.623892

Epoch: 73
Loss: 0.39026302724511674
ROC train: 0.859590	val: 0.650204	test: 0.612532
PRC train: 0.813116	val: 0.700052	test: 0.617470

Epoch: 74
Loss: 0.38872207771135864
ROC train: 0.857172	val: 0.644750	test: 0.614867
PRC train: 0.811099	val: 0.698788	test: 0.615178

Epoch: 75
Loss: 0.38879468827583247
ROC train: 0.863121	val: 0.651889	test: 0.615783
PRC train: 0.815901	val: 0.701085	test: 0.620625

Epoch: 76
Loss: 0.3894897456319617
ROC train: 0.870533	val: 0.662080	test: 0.617333
PRC train: 0.823859	val: 0.707994	test: 0.620935

Epoch: 77
Loss: 0.38807090089709484
ROC train: 0.872219	val: 0.657451	test: 0.622504
PRC train: 0.824591	val: 0.705962	test: 0.623873

Epoch: 78
Loss: 0.38500268368440826
ROC train: 0.869810	val: 0.655310	test: 0.617255
PRC train: 0.824035	val: 0.699111	test: 0.620659

Epoch: 79
Loss: 0.3816722027984055
ROC train: 0.870625	val: 0.653901	test: 0.622687
PRC train: 0.825252	val: 0.695824	test: 0.619085

Epoch: 80
Loss: 0.37701286346650054
ROC train: 0.877641	val: 0.656702	test: 0.626110
PRC train: 0.829283	val: 0.701741	test: 0.622100

Epoch: 81
Loss: 0.3823598160435602
ROC train: 0.872575	val: 0.648111	test: 0.621894
PRC train: 0.826356	val: 0.699522	test: 0.618704

Epoch: 82
Loss: 0.37957844567156296
ROC train: 0.876930	val: 0.641944	test: 0.620870
PRC train: 0.831380	val: 0.691523	test: 0.618489

Epoch: 83
Loss: 0.37922331246216945
ROC train: 0.878749	val: 0.649811	test: 0.623862
PRC train: 0.833201	val: 0.694584	test: 0.622700

Epoch: 84
Loss: 0.380027419475453
ROC train: 0.878312	val: 0.655224	test: 0.629235
PRC train: 0.834220	val: 0.699751	test: 0.630123

Epoch: 85
Loss: 0.3724436541271212
ROC train: 0.881300	val: 0.653341	test: 0.627848
PRC train: 0.834795	val: 0.699830	test: 0.629167

Epoch: 86
Loss: 0.3775644410742771
ROC train: 0.880649	val: 0.654076	test: 0.620536
PRC train: 0.835938	val: 0.698262	test: 0.623190

Epoch: 87
Loss: 0.37501376942574244
ROC train: 0.877769	val: 0.655245	test: 0.613144
PRC train: 0.834575	val: 0.699170	test: 0.616493

Epoch: 88
Loss: 0.37403042316465496
ROC train: 0.885319	val: 0.662852	test: 0.620041
PRC train: 0.841066	val: 0.702973	test: 0.620269

Epoch: 89
Loss: 0.3702284015442695
ROC train: 0.887043	val: 0.660423	test: 0.618704
PRC train: 0.843117	val: 0.699885	test: 0.621451

Epoch: 90
Loss: 0.3712450927253046
ROC train: 0.887342	val: 0.659616	test: 0.616495
PRC train: 0.842149	val: 0.700144	test: 0.621902

Epoch: 91
Loss: 0.36577356825605434
ROC train: 0.885668	val: 0.648940	test: 0.626353
PRC train: 0.843125	val: 0.694451	test: 0.622212

Epoch: 92
Loss: 0.3641131448209514
ROC train: 0.881303	val: 0.641856	test: 0.625270
PRC train: 0.839286	val: 0.688349	test: 0.621790

Epoch: 93
Loss: 0.36539079904637367
ROC train: 0.891745	val: 0.655946	test: 0.624672
PRC train: 0.846771	val: 0.698757	test: 0.624617

Epoch: 94
Loss: 0.3714375757284608
ROC train: 0.783238	val: 0.648941	test: 0.626809
PRC train: 0.741861	val: 0.692302	test: 0.625948

Epoch: 34
Loss: 0.4431323154699417
ROC train: 0.784377	val: 0.652020	test: 0.621538
PRC train: 0.745491	val: 0.693695	test: 0.621259

Epoch: 35
Loss: 0.44116449547518855
ROC train: 0.785587	val: 0.645187	test: 0.616681
PRC train: 0.748359	val: 0.687255	test: 0.618840

Epoch: 36
Loss: 0.4366869351878798
ROC train: 0.790970	val: 0.645297	test: 0.615072
PRC train: 0.750404	val: 0.686565	test: 0.616766

Epoch: 37
Loss: 0.4335142045761752
ROC train: 0.790173	val: 0.637603	test: 0.609180
PRC train: 0.751995	val: 0.682827	test: 0.614916

Epoch: 38
Loss: 0.43421667350988163
ROC train: 0.793900	val: 0.641633	test: 0.619540
PRC train: 0.754218	val: 0.685823	test: 0.623357

Epoch: 39
Loss: 0.43365022140730136
ROC train: 0.798049	val: 0.647731	test: 0.617918
PRC train: 0.758713	val: 0.687105	test: 0.622989

Epoch: 40
Loss: 0.43304322262559153
ROC train: 0.799429	val: 0.651270	test: 0.608908
PRC train: 0.759189	val: 0.692748	test: 0.617696

Epoch: 41
Loss: 0.4329456092320308
ROC train: 0.803773	val: 0.654354	test: 0.615112
PRC train: 0.761844	val: 0.694483	test: 0.616669

Epoch: 42
Loss: 0.4278573254252408
ROC train: 0.802798	val: 0.647066	test: 0.614320
PRC train: 0.763492	val: 0.688691	test: 0.615847

Epoch: 43
Loss: 0.42683487413196397
ROC train: 0.806516	val: 0.646066	test: 0.613263
PRC train: 0.765816	val: 0.691293	test: 0.616703

Epoch: 44
Loss: 0.4293735447160555
ROC train: 0.807693	val: 0.651373	test: 0.617230
PRC train: 0.765080	val: 0.694635	test: 0.620672

Epoch: 45
Loss: 0.4198529033774578
ROC train: 0.812684	val: 0.652976	test: 0.621592
PRC train: 0.768474	val: 0.697328	test: 0.623420

Epoch: 46
Loss: 0.41952880200785253
ROC train: 0.812351	val: 0.651209	test: 0.613915
PRC train: 0.769813	val: 0.697789	test: 0.618246

Epoch: 47
Loss: 0.4245428208964493
ROC train: 0.816113	val: 0.647787	test: 0.609986
PRC train: 0.774455	val: 0.690607	test: 0.619192

Epoch: 48
Loss: 0.4182020312937659
ROC train: 0.820859	val: 0.646536	test: 0.622771
PRC train: 0.778088	val: 0.688178	test: 0.627069

Epoch: 49
Loss: 0.421856047832441
ROC train: 0.820590	val: 0.644569	test: 0.618814
PRC train: 0.778516	val: 0.684749	test: 0.627673

Epoch: 50
Loss: 0.41737476771441834
ROC train: 0.820538	val: 0.648137	test: 0.619156
PRC train: 0.778015	val: 0.686538	test: 0.630262

Epoch: 51
Loss: 0.41821584009784096
ROC train: 0.819070	val: 0.647823	test: 0.616227
PRC train: 0.777542	val: 0.687027	test: 0.624749

Epoch: 52
Loss: 0.41668235412399124
ROC train: 0.822114	val: 0.643978	test: 0.618231
PRC train: 0.779676	val: 0.687768	test: 0.624384

Epoch: 53
Loss: 0.4182593788336592
ROC train: 0.827363	val: 0.640279	test: 0.621606
PRC train: 0.782317	val: 0.694225	test: 0.626574

Epoch: 54
Loss: 0.4140094236756623
ROC train: 0.830417	val: 0.641301	test: 0.623773
PRC train: 0.785362	val: 0.692766	test: 0.625787

Epoch: 55
Loss: 0.41017581067632597
ROC train: 0.833073	val: 0.653812	test: 0.623283
PRC train: 0.784613	val: 0.694660	test: 0.623110

Epoch: 56
Loss: 0.41311248854863303
ROC train: 0.834358	val: 0.653616	test: 0.614232
PRC train: 0.786259	val: 0.690436	test: 0.621735

Epoch: 57
Loss: 0.4062796061362727
ROC train: 0.836237	val: 0.649863	test: 0.609908
PRC train: 0.789918	val: 0.689322	test: 0.619073

Epoch: 58
Loss: 0.4061689985028407
ROC train: 0.839478	val: 0.647363	test: 0.614084
PRC train: 0.792427	val: 0.690123	test: 0.618180

Epoch: 59
Loss: 0.40949487611952995
ROC train: 0.841328	val: 0.649168	test: 0.620005
PRC train: 0.794072	val: 0.694732	test: 0.623518

Epoch: 60
Loss: 0.4083851541893393
ROC train: 0.841451	val: 0.648247	test: 0.614390
PRC train: 0.796477	val: 0.692655	test: 0.626947

Epoch: 61
Loss: 0.4072248585695697
ROC train: 0.842245	val: 0.651326	test: 0.609065
PRC train: 0.797409	val: 0.691135	test: 0.621880

Epoch: 62
Loss: 0.40301914026382735
ROC train: 0.846807	val: 0.651917	test: 0.614325
PRC train: 0.799594	val: 0.694136	test: 0.619104

Epoch: 63
Loss: 0.40078218576471836
ROC train: 0.847237	val: 0.644354	test: 0.616036
PRC train: 0.802066	val: 0.689672	test: 0.623153

Epoch: 64
Loss: 0.4074416366559808
ROC train: 0.846380	val: 0.638509	test: 0.619626
PRC train: 0.799959	val: 0.687338	test: 0.626538

Epoch: 65
Loss: 0.40194336250259655
ROC train: 0.851224	val: 0.647327	test: 0.625888
PRC train: 0.803209	val: 0.690577	test: 0.630925

Epoch: 66
Loss: 0.40066237537024707
ROC train: 0.853082	val: 0.650778	test: 0.619109
PRC train: 0.804227	val: 0.689594	test: 0.627720

Epoch: 67
Loss: 0.3993450241166168
ROC train: 0.850609	val: 0.636581	test: 0.619226
PRC train: 0.802449	val: 0.685502	test: 0.623870

Epoch: 68
Loss: 0.3998483319737211
ROC train: 0.846388	val: 0.632622	test: 0.615977
PRC train: 0.799974	val: 0.682690	test: 0.622349

Epoch: 69
Loss: 0.4010263571342573
ROC train: 0.851648	val: 0.636467	test: 0.617645
PRC train: 0.803442	val: 0.687640	test: 0.621753

Epoch: 70
Loss: 0.3922380622359962
ROC train: 0.855374	val: 0.641370	test: 0.623823
PRC train: 0.807238	val: 0.692047	test: 0.628366

Epoch: 71
Loss: 0.3947754465214729
ROC train: 0.858977	val: 0.637083	test: 0.625802
PRC train: 0.812469	val: 0.690260	test: 0.631362

Epoch: 72
Loss: 0.39603888813774096
ROC train: 0.855968	val: 0.636111	test: 0.615458
PRC train: 0.809402	val: 0.687019	test: 0.628865

Epoch: 73
Loss: 0.39683270022191613
ROC train: 0.859589	val: 0.636555	test: 0.621992
PRC train: 0.810630	val: 0.687229	test: 0.628412

Epoch: 74
Loss: 0.3916297025900888
ROC train: 0.857219	val: 0.629393	test: 0.619661
PRC train: 0.810568	val: 0.688401	test: 0.623941

Epoch: 75
Loss: 0.39400336215325443
ROC train: 0.861633	val: 0.636124	test: 0.629499
PRC train: 0.813359	val: 0.691265	test: 0.631341

Epoch: 76
Loss: 0.39129866863046364
ROC train: 0.863941	val: 0.644539	test: 0.632945
PRC train: 0.815088	val: 0.690180	test: 0.638605

Epoch: 77
Loss: 0.39440719201496954
ROC train: 0.865873	val: 0.642945	test: 0.627972
PRC train: 0.817649	val: 0.689962	test: 0.633313

Epoch: 78
Loss: 0.38705511648951263
ROC train: 0.866998	val: 0.651225	test: 0.625025
PRC train: 0.817782	val: 0.698547	test: 0.625997

Epoch: 79
Loss: 0.3901573252463184
ROC train: 0.862671	val: 0.652589	test: 0.611134
PRC train: 0.813651	val: 0.699802	test: 0.621645

Epoch: 80
Loss: 0.3882862339125144
ROC train: 0.871590	val: 0.647556	test: 0.614936
PRC train: 0.822297	val: 0.696090	test: 0.622018

Epoch: 81
Loss: 0.38372015603481424
ROC train: 0.872122	val: 0.644543	test: 0.624190
PRC train: 0.823965	val: 0.692126	test: 0.626406

Epoch: 82
Loss: 0.38683264719726274
ROC train: 0.863893	val: 0.633533	test: 0.621604
PRC train: 0.819204	val: 0.685917	test: 0.628799

Epoch: 83
Loss: 0.3800794162027573
ROC train: 0.874342	val: 0.647085	test: 0.631032
PRC train: 0.827041	val: 0.698399	test: 0.631483

Epoch: 84
Loss: 0.37914559713306295
ROC train: 0.875733	val: 0.640935	test: 0.625664
PRC train: 0.828585	val: 0.687573	test: 0.630886

Epoch: 85
Loss: 0.37777062346580537
ROC train: 0.875630	val: 0.644384	test: 0.624892
PRC train: 0.828992	val: 0.687563	test: 0.630490

Epoch: 86
Loss: 0.3726571212954065
ROC train: 0.880776	val: 0.654764	test: 0.629262
PRC train: 0.833880	val: 0.695992	test: 0.631867

Epoch: 87
Loss: 0.37492802565718386
ROC train: 0.882752	val: 0.649777	test: 0.629820
PRC train: 0.835287	val: 0.693364	test: 0.629893

Epoch: 88
Loss: 0.37493485890133665
ROC train: 0.883543	val: 0.646439	test: 0.626827
PRC train: 0.837144	val: 0.690602	test: 0.635309

Epoch: 89
Loss: 0.37292898847102995
ROC train: 0.884786	val: 0.641744	test: 0.631548
PRC train: 0.837739	val: 0.690866	test: 0.638374

Epoch: 90
Loss: 0.37399630840497045
ROC train: 0.881637	val: 0.636290	test: 0.633030
PRC train: 0.833472	val: 0.686627	test: 0.640478

Epoch: 91
Loss: 0.3727868678848041
ROC train: 0.881564	val: 0.636672	test: 0.631183
PRC train: 0.834845	val: 0.688699	test: 0.637077

Epoch: 92
Loss: 0.36772104557822305
ROC train: 0.882530	val: 0.636951	test: 0.622789
PRC train: 0.837141	val: 0.688999	test: 0.633073

Epoch: 93
Loss: 0.3665042227701373
ROC train: 0.884739	val: 0.643990	test: 0.622030
PRC train: 0.838099	val: 0.688539	test: 0.631857

Epoch: 94
Loss: 0.36651422081566293
ROC train: 0.770942	val: 0.643426	test: 0.610841
PRC train: 0.732902	val: 0.684655	test: 0.606031

Epoch: 34
Loss: 0.4450013511756783
ROC train: 0.778261	val: 0.636546	test: 0.613681
PRC train: 0.737290	val: 0.681028	test: 0.605629

Epoch: 35
Loss: 0.44199591585704145
ROC train: 0.780548	val: 0.634441	test: 0.608708
PRC train: 0.740019	val: 0.681967	test: 0.601534

Epoch: 36
Loss: 0.4369222172628052
ROC train: 0.786493	val: 0.639364	test: 0.614527
PRC train: 0.743442	val: 0.685885	test: 0.607892

Epoch: 37
Loss: 0.4400469902353002
ROC train: 0.786491	val: 0.639683	test: 0.619463
PRC train: 0.743484	val: 0.686787	test: 0.613441

Epoch: 38
Loss: 0.4359599455551556
ROC train: 0.780328	val: 0.633351	test: 0.608909
PRC train: 0.741203	val: 0.681565	test: 0.608054

Epoch: 39
Loss: 0.4390865029606533
ROC train: 0.789024	val: 0.640541	test: 0.614565
PRC train: 0.746488	val: 0.684900	test: 0.612090

Epoch: 40
Loss: 0.43641697137827873
ROC train: 0.796038	val: 0.647153	test: 0.612631
PRC train: 0.752849	val: 0.690831	test: 0.608427

Epoch: 41
Loss: 0.4303461134746778
ROC train: 0.790903	val: 0.637314	test: 0.609447
PRC train: 0.746891	val: 0.687429	test: 0.608786

Epoch: 42
Loss: 0.43210784261361823
ROC train: 0.802613	val: 0.637585	test: 0.621050
PRC train: 0.756725	val: 0.688075	test: 0.617991

Epoch: 43
Loss: 0.4334959552381123
ROC train: 0.799342	val: 0.632826	test: 0.623014
PRC train: 0.756303	val: 0.688684	test: 0.617073

Epoch: 44
Loss: 0.42962412171561193
ROC train: 0.805011	val: 0.632882	test: 0.614765
PRC train: 0.759698	val: 0.685831	test: 0.615786

Epoch: 45
Loss: 0.4254211142093131
ROC train: 0.804451	val: 0.636509	test: 0.613740
PRC train: 0.759347	val: 0.684714	test: 0.617745

Epoch: 46
Loss: 0.42309245936292866
ROC train: 0.811229	val: 0.643648	test: 0.621553
PRC train: 0.765148	val: 0.689444	test: 0.614949

Epoch: 47
Loss: 0.4264912766254659
ROC train: 0.810982	val: 0.633753	test: 0.618985
PRC train: 0.766961	val: 0.688575	test: 0.617734

Epoch: 48
Loss: 0.4238122282429524
ROC train: 0.814319	val: 0.638631	test: 0.617232
PRC train: 0.767650	val: 0.691990	test: 0.617765

Epoch: 49
Loss: 0.4233691589746649
ROC train: 0.817919	val: 0.639604	test: 0.618368
PRC train: 0.770664	val: 0.688483	test: 0.618952

Epoch: 50
Loss: 0.4221863716977453
ROC train: 0.817776	val: 0.630104	test: 0.621402
PRC train: 0.770425	val: 0.680256	test: 0.625799

Epoch: 51
Loss: 0.4201771264012908
ROC train: 0.821926	val: 0.633468	test: 0.627292
PRC train: 0.773422	val: 0.681998	test: 0.627938

Epoch: 52
Loss: 0.4223200265916636
ROC train: 0.823494	val: 0.640276	test: 0.619659
PRC train: 0.775289	val: 0.687995	test: 0.622452

Epoch: 53
Loss: 0.41763098422086764
ROC train: 0.823502	val: 0.640514	test: 0.610989
PRC train: 0.777235	val: 0.689567	test: 0.619187

Epoch: 54
Loss: 0.41781544337526544
ROC train: 0.826354	val: 0.633629	test: 0.615472
PRC train: 0.778776	val: 0.689108	test: 0.623351

Epoch: 55
Loss: 0.4150490141952867
ROC train: 0.829949	val: 0.634609	test: 0.625303
PRC train: 0.779995	val: 0.688156	test: 0.629983

Epoch: 56
Loss: 0.41495614593737395
ROC train: 0.826094	val: 0.625602	test: 0.618501
PRC train: 0.780920	val: 0.680090	test: 0.623142

Epoch: 57
Loss: 0.4147244737336239
ROC train: 0.831597	val: 0.626787	test: 0.616735
PRC train: 0.785474	val: 0.681527	test: 0.622298

Epoch: 58
Loss: 0.41547078385832453
ROC train: 0.831869	val: 0.630594	test: 0.620498
PRC train: 0.784872	val: 0.688181	test: 0.620977

Epoch: 59
Loss: 0.4071790191792206
ROC train: 0.827190	val: 0.631405	test: 0.615885
PRC train: 0.783298	val: 0.689000	test: 0.619701

Epoch: 60
Loss: 0.4071008331977371
ROC train: 0.835735	val: 0.638786	test: 0.621622
PRC train: 0.787727	val: 0.689001	test: 0.624894

Epoch: 61
Loss: 0.40807772857601377
ROC train: 0.834401	val: 0.627030	test: 0.616763
PRC train: 0.786684	val: 0.681032	test: 0.621316

Epoch: 62
Loss: 0.41142262844380345
ROC train: 0.835823	val: 0.616994	test: 0.616942
PRC train: 0.786679	val: 0.674784	test: 0.620985

Epoch: 63
Loss: 0.40954387488218674
ROC train: 0.819928	val: 0.623944	test: 0.615420
PRC train: 0.774972	val: 0.677604	test: 0.623932

Epoch: 64
Loss: 0.4030491138843989
ROC train: 0.842177	val: 0.632345	test: 0.621602
PRC train: 0.794403	val: 0.684279	test: 0.623439

Epoch: 65
Loss: 0.4005731168242112
ROC train: 0.846390	val: 0.639771	test: 0.619995
PRC train: 0.796916	val: 0.684934	test: 0.626512

Epoch: 66
Loss: 0.400144351018681
ROC train: 0.843295	val: 0.637023	test: 0.618260
PRC train: 0.793731	val: 0.682346	test: 0.625110

Epoch: 67
Loss: 0.4036401376103651
ROC train: 0.850563	val: 0.630595	test: 0.620701
PRC train: 0.799892	val: 0.681150	test: 0.617362

Epoch: 68
Loss: 0.4050241775468905
ROC train: 0.850385	val: 0.629112	test: 0.619046
PRC train: 0.801330	val: 0.682500	test: 0.615847

Epoch: 69
Loss: 0.39832233031694264
ROC train: 0.853665	val: 0.633898	test: 0.613388
PRC train: 0.806230	val: 0.681834	test: 0.623968

Epoch: 70
Loss: 0.40087814988577053
ROC train: 0.854634	val: 0.639810	test: 0.617795
PRC train: 0.808137	val: 0.690285	test: 0.627769

Epoch: 71
Loss: 0.3921813190101195
ROC train: 0.858064	val: 0.641033	test: 0.619131
PRC train: 0.809832	val: 0.692628	test: 0.620962

Epoch: 72
Loss: 0.3931661771555898
ROC train: 0.857630	val: 0.628080	test: 0.621852
PRC train: 0.810099	val: 0.681764	test: 0.625756

Epoch: 73
Loss: 0.3895193748562017
ROC train: 0.859604	val: 0.622900	test: 0.619838
PRC train: 0.810996	val: 0.675379	test: 0.624347

Epoch: 74
Loss: 0.39036448453046446
ROC train: 0.859940	val: 0.622431	test: 0.618512
PRC train: 0.810869	val: 0.673241	test: 0.621719

Epoch: 75
Loss: 0.3906775038804633
ROC train: 0.861977	val: 0.625605	test: 0.617435
PRC train: 0.813295	val: 0.679592	test: 0.623928

Epoch: 76
Loss: 0.3919856905283384
ROC train: 0.861837	val: 0.632116	test: 0.618701
PRC train: 0.813760	val: 0.685335	test: 0.624078

Epoch: 77
Loss: 0.38993380185452386
ROC train: 0.868165	val: 0.636670	test: 0.621550
PRC train: 0.819882	val: 0.684791	test: 0.628938

Epoch: 78
Loss: 0.38472280251129776
ROC train: 0.869381	val: 0.638726	test: 0.627768
PRC train: 0.820156	val: 0.683051	test: 0.629701

Epoch: 79
Loss: 0.3890316069336609
ROC train: 0.868298	val: 0.633441	test: 0.628270
PRC train: 0.819363	val: 0.680429	test: 0.627127

Epoch: 80
Loss: 0.38361623098838765
ROC train: 0.864312	val: 0.636910	test: 0.629820
PRC train: 0.817967	val: 0.686517	test: 0.633274

Epoch: 81
Loss: 0.38684168630218363
ROC train: 0.872443	val: 0.640777	test: 0.626978
PRC train: 0.824193	val: 0.685174	test: 0.630634

Epoch: 82
Loss: 0.3839490937750896
ROC train: 0.872817	val: 0.637444	test: 0.621353
PRC train: 0.826898	val: 0.684188	test: 0.626750

Epoch: 83
Loss: 0.3837421763068086
ROC train: 0.865794	val: 0.632424	test: 0.620438
PRC train: 0.820238	val: 0.683591	test: 0.628285

Epoch: 84
Loss: 0.3796373913351971
ROC train: 0.876139	val: 0.628092	test: 0.628554
PRC train: 0.831547	val: 0.677126	test: 0.630898

Epoch: 85
Loss: 0.38392736639583236
ROC train: 0.876588	val: 0.625363	test: 0.627826
PRC train: 0.831802	val: 0.674762	test: 0.630153

Epoch: 86
Loss: 0.3798816889359599
ROC train: 0.877730	val: 0.632668	test: 0.627498
PRC train: 0.832563	val: 0.677402	test: 0.633623

Epoch: 87
Loss: 0.3804129862745196
ROC train: 0.875664	val: 0.636086	test: 0.620739
PRC train: 0.830781	val: 0.678840	test: 0.627501

Epoch: 88
Loss: 0.37469852221790717
ROC train: 0.879591	val: 0.637254	test: 0.627259
PRC train: 0.832384	val: 0.680580	test: 0.631379

Epoch: 89
Loss: 0.3758000777817406
ROC train: 0.882736	val: 0.628297	test: 0.624745
PRC train: 0.835656	val: 0.676273	test: 0.625715

Epoch: 90
Loss: 0.3721098274467315
ROC train: 0.885456	val: 0.634071	test: 0.622229
PRC train: 0.839527	val: 0.683256	test: 0.627523

Epoch: 91
Loss: 0.37544900862674524
ROC train: 0.886894	val: 0.634279	test: 0.626214
PRC train: 0.840707	val: 0.681399	test: 0.632066

Epoch: 92
Loss: 0.37591339361042
ROC train: 0.886746	val: 0.625111	test: 0.628153
PRC train: 0.840459	val: 0.673987	test: 0.632052

Epoch: 93
Loss: 0.37421676933107295
ROC train: 0.886237	val: 0.621363	test: 0.624974
PRC train: 0.839543	val: 0.669792	test: 0.630583

Epoch: 94
Loss: 0.3678406845600831
ROC train: 0.776871	val: 0.649919	test: 0.612523
PRC train: 0.744608	val: 0.668614	test: 0.612752

Epoch: 34
Loss: 0.44418316626736243
ROC train: 0.779938	val: 0.647795	test: 0.614367
PRC train: 0.748621	val: 0.667721	test: 0.610132

Epoch: 35
Loss: 0.4433271791368979
ROC train: 0.779952	val: 0.641967	test: 0.609397
PRC train: 0.747467	val: 0.665874	test: 0.611664

Epoch: 36
Loss: 0.4381194275218464
ROC train: 0.783310	val: 0.644605	test: 0.608308
PRC train: 0.750144	val: 0.666672	test: 0.610261

Epoch: 37
Loss: 0.43512923244246904
ROC train: 0.783359	val: 0.656939	test: 0.609963
PRC train: 0.751271	val: 0.676799	test: 0.610644

Epoch: 38
Loss: 0.4429672331698472
ROC train: 0.790604	val: 0.646463	test: 0.620860
PRC train: 0.757028	val: 0.671753	test: 0.621894

Epoch: 39
Loss: 0.4362483295562593
ROC train: 0.793497	val: 0.644113	test: 0.624836
PRC train: 0.759092	val: 0.667604	test: 0.624107

Epoch: 40
Loss: 0.43509210451964825
ROC train: 0.790966	val: 0.646027	test: 0.615832
PRC train: 0.758221	val: 0.676551	test: 0.620179

Epoch: 41
Loss: 0.4355308694205843
ROC train: 0.796650	val: 0.652111	test: 0.614221
PRC train: 0.762419	val: 0.675524	test: 0.613257

Epoch: 42
Loss: 0.43944482217130226
ROC train: 0.800354	val: 0.650359	test: 0.616160
PRC train: 0.763732	val: 0.674009	test: 0.616859

Epoch: 43
Loss: 0.4369878274074118
ROC train: 0.798483	val: 0.645396	test: 0.624391
PRC train: 0.760127	val: 0.672324	test: 0.624178

Epoch: 44
Loss: 0.4312358606234186
ROC train: 0.804177	val: 0.655680	test: 0.621291
PRC train: 0.766211	val: 0.672201	test: 0.617992

Epoch: 45
Loss: 0.4300539586363395
ROC train: 0.806181	val: 0.660328	test: 0.616503
PRC train: 0.767059	val: 0.682307	test: 0.612340

Epoch: 46
Loss: 0.4284180097162773
ROC train: 0.809981	val: 0.667040	test: 0.620951
PRC train: 0.770519	val: 0.690019	test: 0.617791

Epoch: 47
Loss: 0.43404574384554745
ROC train: 0.809796	val: 0.661916	test: 0.619855
PRC train: 0.773076	val: 0.685052	test: 0.620928

Epoch: 48
Loss: 0.42380798322929464
ROC train: 0.814250	val: 0.655593	test: 0.620599
PRC train: 0.774859	val: 0.683547	test: 0.626645

Epoch: 49
Loss: 0.4210448092647764
ROC train: 0.813464	val: 0.652593	test: 0.625436
PRC train: 0.774940	val: 0.681810	test: 0.626880

Epoch: 50
Loss: 0.4211526517151671
ROC train: 0.813040	val: 0.647042	test: 0.624576
PRC train: 0.775100	val: 0.674472	test: 0.622846

Epoch: 51
Loss: 0.4185054486249422
ROC train: 0.811903	val: 0.646903	test: 0.628074
PRC train: 0.774929	val: 0.676131	test: 0.626953

Epoch: 52
Loss: 0.4179618639542218
ROC train: 0.817325	val: 0.646927	test: 0.626934
PRC train: 0.779647	val: 0.681374	test: 0.624914

Epoch: 53
Loss: 0.4215459626877913
ROC train: 0.819109	val: 0.656581	test: 0.630866
PRC train: 0.778651	val: 0.689204	test: 0.627728

Epoch: 54
Loss: 0.4164715818730699
ROC train: 0.819792	val: 0.646951	test: 0.619777
PRC train: 0.780378	val: 0.682771	test: 0.628161

Epoch: 55
Loss: 0.41831409786767004
ROC train: 0.825478	val: 0.652047	test: 0.618431
PRC train: 0.784586	val: 0.687803	test: 0.628782

Epoch: 56
Loss: 0.41579664356437984
ROC train: 0.827430	val: 0.656895	test: 0.629790
PRC train: 0.785076	val: 0.690608	test: 0.634295

Epoch: 57
Loss: 0.4119647622419159
ROC train: 0.827889	val: 0.656022	test: 0.632971
PRC train: 0.787345	val: 0.688687	test: 0.639058

Epoch: 58
Loss: 0.4125232378282031
ROC train: 0.832135	val: 0.654033	test: 0.630675
PRC train: 0.790344	val: 0.683612	test: 0.635358

Epoch: 59
Loss: 0.41108681188151064
ROC train: 0.833284	val: 0.651010	test: 0.628845
PRC train: 0.790547	val: 0.674349	test: 0.633995

Epoch: 60
Loss: 0.4147420337447377
ROC train: 0.835206	val: 0.651254	test: 0.640027
PRC train: 0.793231	val: 0.681479	test: 0.642684

Epoch: 61
Loss: 0.4099529842491191
ROC train: 0.837151	val: 0.653137	test: 0.635464
PRC train: 0.794607	val: 0.679632	test: 0.644267

Epoch: 62
Loss: 0.41006838205949164
ROC train: 0.839365	val: 0.660829	test: 0.619278
PRC train: 0.796425	val: 0.688109	test: 0.629137

Epoch: 63
Loss: 0.4104630603072349
ROC train: 0.836016	val: 0.652450	test: 0.614066
PRC train: 0.794516	val: 0.683281	test: 0.625195

Epoch: 64
Loss: 0.409868937391659
ROC train: 0.838045	val: 0.650685	test: 0.615172
PRC train: 0.795311	val: 0.678014	test: 0.628724

Epoch: 65
Loss: 0.40104512042919954
ROC train: 0.840382	val: 0.642728	test: 0.624205
PRC train: 0.801703	val: 0.671866	test: 0.638025

Epoch: 66
Loss: 0.405029029249986
ROC train: 0.843005	val: 0.647777	test: 0.635139
PRC train: 0.801127	val: 0.674238	test: 0.642196

Epoch: 67
Loss: 0.4057741527411644
ROC train: 0.844180	val: 0.645213	test: 0.624657
PRC train: 0.799241	val: 0.683918	test: 0.635393

Epoch: 68
Loss: 0.40449626479578066
ROC train: 0.849009	val: 0.646111	test: 0.619145
PRC train: 0.805755	val: 0.684611	test: 0.626315

Epoch: 69
Loss: 0.40324057137697367
ROC train: 0.851478	val: 0.649171	test: 0.623198
PRC train: 0.808576	val: 0.681398	test: 0.629681

Epoch: 70
Loss: 0.4027350615879164
ROC train: 0.849789	val: 0.652030	test: 0.631481
PRC train: 0.807231	val: 0.685108	test: 0.642992

Epoch: 71
Loss: 0.39722204282760176
ROC train: 0.853478	val: 0.658079	test: 0.628874
PRC train: 0.810261	val: 0.690871	test: 0.640916

Epoch: 72
Loss: 0.3989619940825038
ROC train: 0.853233	val: 0.653257	test: 0.626176
PRC train: 0.809307	val: 0.690556	test: 0.637682

Epoch: 73
Loss: 0.39770414895314044
ROC train: 0.857146	val: 0.656621	test: 0.635892
PRC train: 0.812575	val: 0.686967	test: 0.647071

Epoch: 74
Loss: 0.396034601347833
ROC train: 0.849827	val: 0.648235	test: 0.631008
PRC train: 0.806587	val: 0.683821	test: 0.645282

Epoch: 75
Loss: 0.39796253589556807
ROC train: 0.859071	val: 0.653354	test: 0.636521
PRC train: 0.814949	val: 0.685403	test: 0.644818

Epoch: 76
Loss: 0.3990583833585134
ROC train: 0.858082	val: 0.648024	test: 0.620320
PRC train: 0.812262	val: 0.686638	test: 0.628822

Epoch: 77
Loss: 0.3926318322254262
ROC train: 0.860685	val: 0.649987	test: 0.635185
PRC train: 0.816492	val: 0.690330	test: 0.638466

Epoch: 78
Loss: 0.39155542148236555
ROC train: 0.858839	val: 0.646386	test: 0.630780
PRC train: 0.814519	val: 0.685316	test: 0.638171

Epoch: 79
Loss: 0.39725978373875553
ROC train: 0.864926	val: 0.651331	test: 0.625544
PRC train: 0.821243	val: 0.686687	test: 0.635293

Epoch: 80
Loss: 0.3867311115483467
ROC train: 0.866538	val: 0.648535	test: 0.625682
PRC train: 0.821530	val: 0.687630	test: 0.641045

Epoch: 81
Loss: 0.38598120346802
ROC train: 0.867542	val: 0.658774	test: 0.628365
PRC train: 0.822512	val: 0.691233	test: 0.638013

Epoch: 82
Loss: 0.38977587835743
ROC train: 0.871639	val: 0.657432	test: 0.621393
PRC train: 0.826733	val: 0.691651	test: 0.633187

Epoch: 83
Loss: 0.3833114379622843
ROC train: 0.871489	val: 0.649316	test: 0.625045
PRC train: 0.825189	val: 0.691606	test: 0.635479

Epoch: 84
Loss: 0.38091288033411475
ROC train: 0.867459	val: 0.638558	test: 0.624264
PRC train: 0.823666	val: 0.679085	test: 0.632170

Epoch: 85
Loss: 0.3822073986905096
ROC train: 0.871770	val: 0.652459	test: 0.625279
PRC train: 0.827767	val: 0.689746	test: 0.635579

Epoch: 86
Loss: 0.3853258154308732
ROC train: 0.874278	val: 0.649525	test: 0.619331
PRC train: 0.830912	val: 0.689581	test: 0.635997

Epoch: 87
Loss: 0.37826308289822513
ROC train: 0.874030	val: 0.647990	test: 0.625669
PRC train: 0.830360	val: 0.688555	test: 0.641264

Epoch: 88
Loss: 0.38429677598993384
ROC train: 0.878011	val: 0.649498	test: 0.633363
PRC train: 0.835151	val: 0.690835	test: 0.645975

Epoch: 89
Loss: 0.3769159638490257
ROC train: 0.875439	val: 0.640564	test: 0.638341
PRC train: 0.830959	val: 0.685655	test: 0.642492

Epoch: 90
Loss: 0.3786381040181637
ROC train: 0.876860	val: 0.633778	test: 0.635672
PRC train: 0.833747	val: 0.684523	test: 0.643981

Epoch: 91
Loss: 0.3822192355958278
ROC train: 0.879051	val: 0.648812	test: 0.637144
PRC train: 0.835906	val: 0.694108	test: 0.641961

Epoch: 92
Loss: 0.37464785449912263
ROC train: 0.878798	val: 0.653971	test: 0.630692
PRC train: 0.835097	val: 0.696269	test: 0.630344

Epoch: 93
Loss: 0.37639272334155316
ROC train: 0.882996	val: 0.645729	test: 0.629196
PRC train: 0.836959	val: 0.691730	test: 0.633542

Epoch: 94
Loss: 0.37951998302690976
ROC train: 0.880844	val: 0.634425	test: 0.635995
ROC train: 0.779242	val: 0.642113	test: 0.612557
PRC train: 0.746964	val: 0.664430	test: 0.617575

Epoch: 34
Loss: 0.4461429699737861
ROC train: 0.782250	val: 0.638407	test: 0.606957
PRC train: 0.749498	val: 0.668147	test: 0.613462

Epoch: 35
Loss: 0.4413073192101103
ROC train: 0.790863	val: 0.638802	test: 0.611043
PRC train: 0.755908	val: 0.660709	test: 0.617763

Epoch: 36
Loss: 0.4367435986560667
ROC train: 0.791651	val: 0.638657	test: 0.611554
PRC train: 0.758652	val: 0.661648	test: 0.619888

Epoch: 37
Loss: 0.43363559711930605
ROC train: 0.799421	val: 0.648147	test: 0.616273
PRC train: 0.763237	val: 0.670175	test: 0.621008

Epoch: 38
Loss: 0.4295626069753335
ROC train: 0.799553	val: 0.653465	test: 0.609774
PRC train: 0.763200	val: 0.677482	test: 0.619085

Epoch: 39
Loss: 0.4334084935218092
ROC train: 0.800023	val: 0.654323	test: 0.605102
PRC train: 0.765378	val: 0.682290	test: 0.618073

Epoch: 40
Loss: 0.43439661052019896
ROC train: 0.801375	val: 0.648545	test: 0.605125
PRC train: 0.764695	val: 0.675515	test: 0.616215

Epoch: 41
Loss: 0.43478824829277346
ROC train: 0.803854	val: 0.640198	test: 0.609445
PRC train: 0.765386	val: 0.671094	test: 0.617752

Epoch: 42
Loss: 0.4284574873660607
ROC train: 0.804728	val: 0.638666	test: 0.612564
PRC train: 0.766796	val: 0.672278	test: 0.620297

Epoch: 43
Loss: 0.42770535699438506
ROC train: 0.806514	val: 0.653078	test: 0.609157
PRC train: 0.768397	val: 0.678996	test: 0.618044

Epoch: 44
Loss: 0.428428272986332
ROC train: 0.812743	val: 0.658016	test: 0.613253
PRC train: 0.775607	val: 0.681900	test: 0.620208

Epoch: 45
Loss: 0.424105621033517
ROC train: 0.812184	val: 0.652761	test: 0.613217
PRC train: 0.772141	val: 0.679718	test: 0.616992

Epoch: 46
Loss: 0.42665479130718964
ROC train: 0.814141	val: 0.660368	test: 0.621948
PRC train: 0.777597	val: 0.679463	test: 0.621988

Epoch: 47
Loss: 0.42291265259198224
ROC train: 0.816319	val: 0.654359	test: 0.627242
PRC train: 0.778067	val: 0.677252	test: 0.626946

Epoch: 48
Loss: 0.42256352772546163
ROC train: 0.815538	val: 0.641870	test: 0.608809
PRC train: 0.777176	val: 0.677924	test: 0.621028

Epoch: 49
Loss: 0.42358068228525064
ROC train: 0.821567	val: 0.655348	test: 0.608331
PRC train: 0.783695	val: 0.684481	test: 0.619713

Epoch: 50
Loss: 0.42475633536006363
ROC train: 0.817702	val: 0.659628	test: 0.615335
PRC train: 0.780834	val: 0.678414	test: 0.623652

Epoch: 51
Loss: 0.41710324793367815
ROC train: 0.812371	val: 0.657437	test: 0.615750
PRC train: 0.775806	val: 0.678433	test: 0.623786

Epoch: 52
Loss: 0.41269399376743576
ROC train: 0.821110	val: 0.650758	test: 0.621590
PRC train: 0.781025	val: 0.682820	test: 0.621628

Epoch: 53
Loss: 0.4213012028626914
ROC train: 0.819999	val: 0.649222	test: 0.627602
PRC train: 0.777608	val: 0.684558	test: 0.624201

Epoch: 54
Loss: 0.4194942225308435
ROC train: 0.824668	val: 0.642704	test: 0.622492
PRC train: 0.786665	val: 0.678267	test: 0.624580

Epoch: 55
Loss: 0.4195934049336727
ROC train: 0.831787	val: 0.647368	test: 0.628495
PRC train: 0.789755	val: 0.676399	test: 0.630022

Epoch: 56
Loss: 0.4141291069187599
ROC train: 0.832265	val: 0.643836	test: 0.621564
PRC train: 0.791452	val: 0.669031	test: 0.630780

Epoch: 57
Loss: 0.4094518677895177
ROC train: 0.836091	val: 0.644509	test: 0.616500
PRC train: 0.794633	val: 0.673151	test: 0.624000

Epoch: 58
Loss: 0.41082407195960247
ROC train: 0.837739	val: 0.644823	test: 0.616792
PRC train: 0.794574	val: 0.675935	test: 0.623533

Epoch: 59
Loss: 0.40930691653420403
ROC train: 0.837216	val: 0.650890	test: 0.626119
PRC train: 0.793325	val: 0.684319	test: 0.629156

Epoch: 60
Loss: 0.4100842904856165
ROC train: 0.836872	val: 0.643732	test: 0.628891
PRC train: 0.793280	val: 0.676235	test: 0.633893

Epoch: 61
Loss: 0.4093507162787355
ROC train: 0.841016	val: 0.651982	test: 0.625801
PRC train: 0.799075	val: 0.677252	test: 0.632286

Epoch: 62
Loss: 0.4085635388186112
ROC train: 0.842040	val: 0.638252	test: 0.619751
PRC train: 0.800421	val: 0.666965	test: 0.635865

Epoch: 63
Loss: 0.41164793721917325
ROC train: 0.842152	val: 0.629543	test: 0.619032
PRC train: 0.801894	val: 0.670308	test: 0.633588

Epoch: 64
Loss: 0.408473072633467
ROC train: 0.844070	val: 0.653704	test: 0.629930
PRC train: 0.798852	val: 0.680211	test: 0.630508

Epoch: 65
Loss: 0.4074360538553015
ROC train: 0.844391	val: 0.649155	test: 0.628852
PRC train: 0.800565	val: 0.675939	test: 0.631327

Epoch: 66
Loss: 0.40718420914762204
ROC train: 0.850442	val: 0.642205	test: 0.622258
PRC train: 0.806415	val: 0.671871	test: 0.628526

Epoch: 67
Loss: 0.4053349951724898
ROC train: 0.853256	val: 0.645623	test: 0.612728
PRC train: 0.807990	val: 0.679809	test: 0.629227

Epoch: 68
Loss: 0.39889490639233416
ROC train: 0.850772	val: 0.645077	test: 0.613831
PRC train: 0.807825	val: 0.676079	test: 0.633072

Epoch: 69
Loss: 0.40153137830372787
ROC train: 0.850975	val: 0.644665	test: 0.620451
PRC train: 0.808650	val: 0.678957	test: 0.632071

Epoch: 70
Loss: 0.3942595483522441
ROC train: 0.852276	val: 0.648245	test: 0.621175
PRC train: 0.809160	val: 0.675749	test: 0.630740

Epoch: 71
Loss: 0.39442863206557
ROC train: 0.855506	val: 0.644447	test: 0.622860
PRC train: 0.812442	val: 0.678057	test: 0.629459

Epoch: 72
Loss: 0.39948923761378163
ROC train: 0.860081	val: 0.647138	test: 0.627892
PRC train: 0.814906	val: 0.682909	test: 0.628555

Epoch: 73
Loss: 0.3978484777810003
ROC train: 0.856789	val: 0.637050	test: 0.622827
PRC train: 0.814772	val: 0.675155	test: 0.632116

Epoch: 74
Loss: 0.394829220529117
ROC train: 0.858427	val: 0.635128	test: 0.621069
PRC train: 0.815558	val: 0.676320	test: 0.634359

Epoch: 75
Loss: 0.39015643395430377
ROC train: 0.864101	val: 0.640001	test: 0.617951
PRC train: 0.820046	val: 0.684630	test: 0.633641

Epoch: 76
Loss: 0.4015789750163988
ROC train: 0.863118	val: 0.642008	test: 0.616741
PRC train: 0.820136	val: 0.679763	test: 0.630312

Epoch: 77
Loss: 0.38736383240411076
ROC train: 0.864096	val: 0.651204	test: 0.630991
PRC train: 0.821587	val: 0.685845	test: 0.634427

Epoch: 78
Loss: 0.3865827116102193
ROC train: 0.866238	val: 0.652667	test: 0.632256
PRC train: 0.822210	val: 0.689524	test: 0.636108

Epoch: 79
Loss: 0.3876798447843374
ROC train: 0.867713	val: 0.648152	test: 0.629841
PRC train: 0.821353	val: 0.692692	test: 0.639964

Epoch: 80
Loss: 0.3852367122014498
ROC train: 0.868210	val: 0.639233	test: 0.631498
PRC train: 0.822504	val: 0.685952	test: 0.637479

Epoch: 81
Loss: 0.38415676968268053
ROC train: 0.864721	val: 0.623043	test: 0.612531
PRC train: 0.821078	val: 0.668225	test: 0.625834

Epoch: 82
Loss: 0.3853481236085318
ROC train: 0.869149	val: 0.639440	test: 0.624385
PRC train: 0.823164	val: 0.683984	test: 0.634254

Epoch: 83
Loss: 0.38320556132934647
ROC train: 0.869062	val: 0.647721	test: 0.628953
PRC train: 0.826040	val: 0.684187	test: 0.635201

Epoch: 84
Loss: 0.3856086420085987
ROC train: 0.871386	val: 0.645136	test: 0.623701
PRC train: 0.825958	val: 0.683434	test: 0.636809

Epoch: 85
Loss: 0.3800881042209293
ROC train: 0.872448	val: 0.628781	test: 0.616538
PRC train: 0.829676	val: 0.677096	test: 0.633142

Epoch: 86
Loss: 0.38200781463911226
ROC train: 0.873412	val: 0.633083	test: 0.625943
PRC train: 0.830286	val: 0.672846	test: 0.635929

Epoch: 87
Loss: 0.38358275187728996
ROC train: 0.869849	val: 0.635134	test: 0.637025
PRC train: 0.826756	val: 0.675916	test: 0.635582

Epoch: 88
Loss: 0.3823877267735608
ROC train: 0.873419	val: 0.639786	test: 0.628461
PRC train: 0.831247	val: 0.680538	test: 0.630253

Epoch: 89
Loss: 0.3788673496479778
ROC train: 0.881060	val: 0.646966	test: 0.625175
PRC train: 0.839565	val: 0.681998	test: 0.632279

Epoch: 90
Loss: 0.37691816472851014
ROC train: 0.878774	val: 0.639542	test: 0.623498
PRC train: 0.832701	val: 0.676721	test: 0.633863

Epoch: 91
Loss: 0.38042000002614296
ROC train: 0.877357	val: 0.642293	test: 0.623339
PRC train: 0.831723	val: 0.679046	test: 0.635665

Epoch: 92
Loss: 0.37284937510704214
ROC train: 0.882324	val: 0.646709	test: 0.611791
PRC train: 0.841031	val: 0.680805	test: 0.632587

Epoch: 93
Loss: 0.3707027612628126
ROC train: 0.882326	val: 0.634776	test: 0.626263
PRC train: 0.841581	val: 0.669475	test: 0.641190

Epoch: 94
Loss: 0.3736802387111438ROC train: 0.774511	val: 0.648825	test: 0.610421
PRC train: 0.742954	val: 0.662952	test: 0.613913

Epoch: 34
Loss: 0.44543198208215956
ROC train: 0.774900	val: 0.641206	test: 0.608061
PRC train: 0.742156	val: 0.661420	test: 0.613762

Epoch: 35
Loss: 0.44137772959740496
ROC train: 0.778648	val: 0.645200	test: 0.616483
PRC train: 0.744907	val: 0.659684	test: 0.615787

Epoch: 36
Loss: 0.4432009419388068
ROC train: 0.779113	val: 0.647709	test: 0.608898
PRC train: 0.745178	val: 0.666022	test: 0.608591

Epoch: 37
Loss: 0.44470391608967275
ROC train: 0.785675	val: 0.647670	test: 0.611736
PRC train: 0.748886	val: 0.666342	test: 0.612437

Epoch: 38
Loss: 0.43557227954372524
ROC train: 0.789348	val: 0.648117	test: 0.623664
PRC train: 0.752899	val: 0.665022	test: 0.626191

Epoch: 39
Loss: 0.43980235766458076
ROC train: 0.788209	val: 0.652083	test: 0.619205
PRC train: 0.752825	val: 0.670038	test: 0.626974

Epoch: 40
Loss: 0.43692381891464827
ROC train: 0.792766	val: 0.647900	test: 0.616196
PRC train: 0.754186	val: 0.670337	test: 0.623208

Epoch: 41
Loss: 0.4376741581512559
ROC train: 0.790099	val: 0.635099	test: 0.610016
PRC train: 0.753524	val: 0.659700	test: 0.618709

Epoch: 42
Loss: 0.43146838665398785
ROC train: 0.793195	val: 0.636596	test: 0.600135
PRC train: 0.754765	val: 0.660240	test: 0.610068

Epoch: 43
Loss: 0.42974918213726576
ROC train: 0.799581	val: 0.645145	test: 0.611399
PRC train: 0.760476	val: 0.672181	test: 0.617953

Epoch: 44
Loss: 0.429594189787582
ROC train: 0.803891	val: 0.642136	test: 0.609764
PRC train: 0.765708	val: 0.668938	test: 0.621009

Epoch: 45
Loss: 0.4270520890146302
ROC train: 0.803920	val: 0.642719	test: 0.605773
PRC train: 0.766817	val: 0.672590	test: 0.618597

Epoch: 46
Loss: 0.4299945158370117
ROC train: 0.801418	val: 0.646813	test: 0.602214
PRC train: 0.764517	val: 0.672897	test: 0.613466

Epoch: 47
Loss: 0.4271966918156457
ROC train: 0.808896	val: 0.653162	test: 0.612748
PRC train: 0.770852	val: 0.674479	test: 0.620738

Epoch: 48
Loss: 0.42562225684788846
ROC train: 0.808998	val: 0.639210	test: 0.611671
PRC train: 0.772997	val: 0.666281	test: 0.628976

Epoch: 49
Loss: 0.4264367927916991
ROC train: 0.811733	val: 0.653315	test: 0.619522
PRC train: 0.772345	val: 0.674573	test: 0.630907

Epoch: 50
Loss: 0.4316674251175863
ROC train: 0.817092	val: 0.651518	test: 0.623000
PRC train: 0.776076	val: 0.669949	test: 0.633038

Epoch: 51
Loss: 0.4236599759928705
ROC train: 0.806374	val: 0.646219	test: 0.635760
PRC train: 0.765849	val: 0.670885	test: 0.639919

Epoch: 52
Loss: 0.4261129185987433
ROC train: 0.816845	val: 0.643057	test: 0.631434
PRC train: 0.776459	val: 0.674054	test: 0.638911

Epoch: 53
Loss: 0.41714891210574906
ROC train: 0.812375	val: 0.643726	test: 0.623635
PRC train: 0.771598	val: 0.676378	test: 0.626587

Epoch: 54
Loss: 0.4180818353244279
ROC train: 0.822629	val: 0.646415	test: 0.617413
PRC train: 0.782321	val: 0.677941	test: 0.622317

Epoch: 55
Loss: 0.41818599611378077
ROC train: 0.824309	val: 0.648089	test: 0.614808
PRC train: 0.785862	val: 0.675414	test: 0.624005

Epoch: 56
Loss: 0.4193912429916991
ROC train: 0.829276	val: 0.649691	test: 0.615845
PRC train: 0.788132	val: 0.677153	test: 0.624899

Epoch: 57
Loss: 0.4139332624782231
ROC train: 0.827404	val: 0.641235	test: 0.613882
PRC train: 0.787847	val: 0.675030	test: 0.624417

Epoch: 58
Loss: 0.4102999494938853
ROC train: 0.825700	val: 0.643886	test: 0.607989
PRC train: 0.786512	val: 0.677982	test: 0.623429

Epoch: 59
Loss: 0.4144973632290528
ROC train: 0.832694	val: 0.646945	test: 0.622803
PRC train: 0.791056	val: 0.679969	test: 0.634128

Epoch: 60
Loss: 0.40957676071498605
ROC train: 0.834906	val: 0.646674	test: 0.627577
PRC train: 0.793290	val: 0.683061	test: 0.637584

Epoch: 61
Loss: 0.4067289090327849
ROC train: 0.835328	val: 0.649445	test: 0.624147
PRC train: 0.792084	val: 0.685607	test: 0.631526

Epoch: 62
Loss: 0.4106956718974092
ROC train: 0.835929	val: 0.655974	test: 0.618389
PRC train: 0.793701	val: 0.686774	test: 0.629934

Epoch: 63
Loss: 0.4119667242069688
ROC train: 0.840475	val: 0.659159	test: 0.612173
PRC train: 0.797048	val: 0.688972	test: 0.623467

Epoch: 64
Loss: 0.40074176752276525
ROC train: 0.842356	val: 0.641442	test: 0.609581
PRC train: 0.800633	val: 0.674197	test: 0.621879

Epoch: 65
Loss: 0.40885847987086266
ROC train: 0.843342	val: 0.641240	test: 0.614869
PRC train: 0.799803	val: 0.675356	test: 0.624591

Epoch: 66
Loss: 0.4049905424044892
ROC train: 0.841272	val: 0.634781	test: 0.614285
PRC train: 0.799547	val: 0.676095	test: 0.627311

Epoch: 67
Loss: 0.40372803162605864
ROC train: 0.845948	val: 0.642728	test: 0.617470
PRC train: 0.802856	val: 0.676158	test: 0.627519

Epoch: 68
Loss: 0.4019936738870301
ROC train: 0.840409	val: 0.641619	test: 0.614956
PRC train: 0.798090	val: 0.679054	test: 0.623605

Epoch: 69
Loss: 0.40483962822865127
ROC train: 0.844623	val: 0.645375	test: 0.630543
PRC train: 0.802215	val: 0.683162	test: 0.635186

Epoch: 70
Loss: 0.403076905116272
ROC train: 0.851715	val: 0.646707	test: 0.633911
PRC train: 0.805871	val: 0.683118	test: 0.637735

Epoch: 71
Loss: 0.40086494427501523
ROC train: 0.855660	val: 0.643390	test: 0.626915
PRC train: 0.809226	val: 0.682302	test: 0.640555

Epoch: 72
Loss: 0.4013701167063931
ROC train: 0.856419	val: 0.655379	test: 0.628412
PRC train: 0.809584	val: 0.688428	test: 0.643414

Epoch: 73
Loss: 0.40053733174922
ROC train: 0.855523	val: 0.642796	test: 0.628680
PRC train: 0.811648	val: 0.682436	test: 0.647182

Epoch: 74
Loss: 0.39807725660804827
ROC train: 0.856364	val: 0.646702	test: 0.627936
PRC train: 0.813472	val: 0.688693	test: 0.640223

Epoch: 75
Loss: 0.39957910370218347
ROC train: 0.859052	val: 0.652818	test: 0.626300
PRC train: 0.816274	val: 0.693015	test: 0.638193

Epoch: 76
Loss: 0.393169450334779
ROC train: 0.860831	val: 0.643570	test: 0.628755
PRC train: 0.816133	val: 0.684212	test: 0.637738

Epoch: 77
Loss: 0.3920000582742634
ROC train: 0.860557	val: 0.656148	test: 0.617841
PRC train: 0.814088	val: 0.699662	test: 0.627463

Epoch: 78
Loss: 0.3952039967521509
ROC train: 0.860762	val: 0.646265	test: 0.622737
PRC train: 0.816727	val: 0.687308	test: 0.640949

Epoch: 79
Loss: 0.39266717836450293
ROC train: 0.864346	val: 0.655131	test: 0.624892
PRC train: 0.819613	val: 0.694144	test: 0.637978

Epoch: 80
Loss: 0.38714510234794525
ROC train: 0.862834	val: 0.660070	test: 0.628386
PRC train: 0.817404	val: 0.690849	test: 0.637401

Epoch: 81
Loss: 0.3931570504340904
ROC train: 0.869524	val: 0.650081	test: 0.630778
PRC train: 0.824813	val: 0.683709	test: 0.640904

Epoch: 82
Loss: 0.3830760558208309
ROC train: 0.869001	val: 0.645640	test: 0.632199
PRC train: 0.825111	val: 0.691100	test: 0.645244

Epoch: 83
Loss: 0.39159228386393974
ROC train: 0.868400	val: 0.659010	test: 0.629365
PRC train: 0.823924	val: 0.695395	test: 0.636631

Epoch: 84
Loss: 0.3877275162168526
ROC train: 0.870375	val: 0.663628	test: 0.631265
PRC train: 0.826501	val: 0.696258	test: 0.636197

Epoch: 85
Loss: 0.38118786727350584
ROC train: 0.869689	val: 0.651042	test: 0.635067
PRC train: 0.826143	val: 0.687786	test: 0.641221

Epoch: 86
Loss: 0.38376045695455163
ROC train: 0.874041	val: 0.650852	test: 0.635352
PRC train: 0.828500	val: 0.688940	test: 0.639020

Epoch: 87
Loss: 0.3810387915783383
ROC train: 0.875850	val: 0.648503	test: 0.625490
PRC train: 0.829650	val: 0.685278	test: 0.634438

Epoch: 88
Loss: 0.37998510819380094
ROC train: 0.877356	val: 0.639538	test: 0.632220
PRC train: 0.834138	val: 0.675631	test: 0.644224

Epoch: 89
Loss: 0.38282609859236816
ROC train: 0.877750	val: 0.639585	test: 0.634811
PRC train: 0.835952	val: 0.670762	test: 0.642254

Epoch: 90
Loss: 0.38203517580684154
ROC train: 0.876508	val: 0.643866	test: 0.635108
PRC train: 0.833732	val: 0.680644	test: 0.633661

Epoch: 91
Loss: 0.3769784813043582
ROC train: 0.880052	val: 0.645446	test: 0.634244
PRC train: 0.837847	val: 0.682875	test: 0.636051

Epoch: 92
Loss: 0.37493689147508663
ROC train: 0.873001	val: 0.654798	test: 0.633636
PRC train: 0.832362	val: 0.689664	test: 0.639538

Epoch: 93
Loss: 0.37430559001232194
ROC train: 0.879567	val: 0.656688	test: 0.636994
PRC train: 0.836875	val: 0.697683	test: 0.644084

Epoch: 94
Loss: 0.37619198622796224
PRC train: 0.844703	val: 0.653584	test: 0.636457

Epoch: 95
Loss: 0.3668130134623286
ROC train: 0.885467	val: 0.634130	test: 0.620552
PRC train: 0.842897	val: 0.656332	test: 0.638119

Epoch: 96
Loss: 0.3701166751748703
ROC train: 0.890074	val: 0.644039	test: 0.622511
PRC train: 0.847087	val: 0.662891	test: 0.637399

Epoch: 97
Loss: 0.3642208995479912
ROC train: 0.889381	val: 0.641602	test: 0.620980
PRC train: 0.846885	val: 0.666494	test: 0.633943

Epoch: 98
Loss: 0.36202419605241126
ROC train: 0.885637	val: 0.633909	test: 0.617590
PRC train: 0.842519	val: 0.660169	test: 0.639343

Epoch: 99
Loss: 0.3633893783155857
ROC train: 0.887526	val: 0.629366	test: 0.618392
PRC train: 0.844638	val: 0.655891	test: 0.636009

Epoch: 100
Loss: 0.359472709050482
ROC train: 0.891874	val: 0.628382	test: 0.621814
PRC train: 0.851044	val: 0.655990	test: 0.631847

Epoch: 101
Loss: 0.3640430206766991
ROC train: 0.895171	val: 0.632604	test: 0.619704
PRC train: 0.852175	val: 0.656405	test: 0.632972

Epoch: 102
Loss: 0.36513618350329524
ROC train: 0.893608	val: 0.638000	test: 0.621366
PRC train: 0.850565	val: 0.657776	test: 0.638839

Epoch: 103
Loss: 0.36334184920104523
ROC train: 0.896995	val: 0.641513	test: 0.635562
PRC train: 0.855628	val: 0.661561	test: 0.645764

Epoch: 104
Loss: 0.36686238390076187
ROC train: 0.894661	val: 0.628844	test: 0.632124
PRC train: 0.856101	val: 0.657837	test: 0.644293

Epoch: 105
Loss: 0.36324230760707277
ROC train: 0.893746	val: 0.625232	test: 0.621671
PRC train: 0.856066	val: 0.656266	test: 0.641512

Epoch: 106
Loss: 0.3605877976040943
ROC train: 0.896833	val: 0.638911	test: 0.618687
PRC train: 0.855346	val: 0.660737	test: 0.635533

Epoch: 107
Loss: 0.36065786184828696
ROC train: 0.897498	val: 0.638650	test: 0.620158
PRC train: 0.855132	val: 0.659666	test: 0.633082

Epoch: 108
Loss: 0.3503209656129831
ROC train: 0.899398	val: 0.635445	test: 0.623433
PRC train: 0.856561	val: 0.657990	test: 0.639449

Epoch: 109
Loss: 0.35449056436651744
ROC train: 0.900811	val: 0.630593	test: 0.626819
PRC train: 0.859647	val: 0.656761	test: 0.642576

Epoch: 110
Loss: 0.3511311161136016
ROC train: 0.900606	val: 0.635142	test: 0.628333
PRC train: 0.859906	val: 0.658683	test: 0.642851

Epoch: 111
Loss: 0.35282599884691046
ROC train: 0.901460	val: 0.632434	test: 0.628636
PRC train: 0.861706	val: 0.658371	test: 0.641704

Epoch: 112
Loss: 0.35824347844138515
ROC train: 0.905773	val: 0.631659	test: 0.628630
PRC train: 0.864852	val: 0.656862	test: 0.639548

Epoch: 113
Loss: 0.35086630378727907
ROC train: 0.906648	val: 0.634019	test: 0.624151
PRC train: 0.864392	val: 0.659321	test: 0.635805

Epoch: 114
Loss: 0.35225708115909815
ROC train: 0.905072	val: 0.637228	test: 0.619553
PRC train: 0.863371	val: 0.663931	test: 0.635289

Epoch: 115
Loss: 0.346236449078934
ROC train: 0.905256	val: 0.636809	test: 0.627199
PRC train: 0.866540	val: 0.663114	test: 0.641977

Epoch: 116
Loss: 0.35429974357476524
ROC train: 0.905894	val: 0.628335	test: 0.632702
PRC train: 0.867097	val: 0.656880	test: 0.642526

Epoch: 117
Loss: 0.3573451405530068
ROC train: 0.907737	val: 0.623125	test: 0.626388
PRC train: 0.866087	val: 0.655829	test: 0.636889

Epoch: 118
Loss: 0.3458934145246269
ROC train: 0.908725	val: 0.621077	test: 0.625363
PRC train: 0.869500	val: 0.653748	test: 0.640311

Epoch: 119
Loss: 0.34781307697635944
ROC train: 0.909409	val: 0.624333	test: 0.629738
PRC train: 0.870811	val: 0.655295	test: 0.643787

Epoch: 120
Loss: 0.34691984043165225
ROC train: 0.896303	val: 0.625361	test: 0.633577
PRC train: 0.856147	val: 0.657283	test: 0.639873

Early stopping
Best (ROC):	 train: 0.810909	val: 0.661185	test: 0.606912
Best (PRC):	 train: 0.770527	val: 0.677629	test: 0.619686

ROC train: 0.884866	val: 0.643624	test: 0.630236
PRC train: 0.839579	val: 0.657462	test: 0.637153

Epoch: 95
Loss: 0.3816520909536856
ROC train: 0.884115	val: 0.637923	test: 0.627550
PRC train: 0.841959	val: 0.656163	test: 0.637883

Epoch: 96
Loss: 0.37535851530144415
ROC train: 0.879018	val: 0.636457	test: 0.619082
PRC train: 0.839387	val: 0.655209	test: 0.630818

Epoch: 97
Loss: 0.37753960700357697
ROC train: 0.879725	val: 0.626017	test: 0.622472
PRC train: 0.841523	val: 0.652666	test: 0.632923

Epoch: 98
Loss: 0.37098353797045924
ROC train: 0.884453	val: 0.621055	test: 0.628587
PRC train: 0.843888	val: 0.647599	test: 0.633403

Epoch: 99
Loss: 0.37558577905541085
ROC train: 0.880761	val: 0.616547	test: 0.634272
PRC train: 0.839145	val: 0.644601	test: 0.637654

Epoch: 100
Loss: 0.3749229819398769
ROC train: 0.878095	val: 0.611887	test: 0.635680
PRC train: 0.835790	val: 0.639479	test: 0.639176

Epoch: 101
Loss: 0.37360786253607203
ROC train: 0.883511	val: 0.618883	test: 0.632896
PRC train: 0.840995	val: 0.640919	test: 0.640209

Epoch: 102
Loss: 0.3647752571153443
ROC train: 0.889533	val: 0.619138	test: 0.625960
PRC train: 0.846358	val: 0.644834	test: 0.638512

Epoch: 103
Loss: 0.36672969069588257
ROC train: 0.893911	val: 0.619354	test: 0.624646
PRC train: 0.850628	val: 0.649552	test: 0.637242

Epoch: 104
Loss: 0.36930494259811036
ROC train: 0.894274	val: 0.624868	test: 0.624034
PRC train: 0.848727	val: 0.653307	test: 0.636523

Epoch: 105
Loss: 0.36507773416906564
ROC train: 0.894073	val: 0.630956	test: 0.620672
PRC train: 0.848934	val: 0.655154	test: 0.634549

Epoch: 106
Loss: 0.36196820250834555
ROC train: 0.894328	val: 0.629852	test: 0.621425
PRC train: 0.851339	val: 0.650464	test: 0.632937

Epoch: 107
Loss: 0.3670792109998421
ROC train: 0.893251	val: 0.625652	test: 0.623579
PRC train: 0.849124	val: 0.649097	test: 0.632103

Epoch: 108
Loss: 0.36617264803960525
ROC train: 0.893245	val: 0.629664	test: 0.628883
PRC train: 0.849884	val: 0.652183	test: 0.639368

Epoch: 109
Loss: 0.3625277855196537
ROC train: 0.888004	val: 0.625079	test: 0.632932
PRC train: 0.850679	val: 0.649731	test: 0.650314

Epoch: 110
Loss: 0.36233699753448834
ROC train: 0.890898	val: 0.624266	test: 0.635927
PRC train: 0.849163	val: 0.649301	test: 0.646862

Epoch: 111
Loss: 0.3601788908728754
ROC train: 0.896960	val: 0.627255	test: 0.634592
PRC train: 0.853576	val: 0.649014	test: 0.644760

Epoch: 112
Loss: 0.366224759021395
ROC train: 0.898880	val: 0.632336	test: 0.629125
PRC train: 0.857674	val: 0.652153	test: 0.639331

Epoch: 113
Loss: 0.36161471880943724
ROC train: 0.900317	val: 0.635344	test: 0.629293
PRC train: 0.858226	val: 0.655422	test: 0.638924

Epoch: 114
Loss: 0.3602984720269342
ROC train: 0.900487	val: 0.618715	test: 0.627959
PRC train: 0.858351	val: 0.647338	test: 0.638234

Epoch: 115
Loss: 0.3594928257731367
ROC train: 0.898339	val: 0.619392	test: 0.625531
PRC train: 0.855185	val: 0.647071	test: 0.635813

Epoch: 116
Loss: 0.3626733303326021
ROC train: 0.899053	val: 0.628003	test: 0.626514
PRC train: 0.857670	val: 0.649855	test: 0.639216

Epoch: 117
Loss: 0.35786829318469693
ROC train: 0.899617	val: 0.637504	test: 0.620136
PRC train: 0.859923	val: 0.657848	test: 0.637525

Epoch: 118
Loss: 0.35226834462958156
ROC train: 0.898753	val: 0.637671	test: 0.619711
PRC train: 0.855554	val: 0.660071	test: 0.636349

Epoch: 119
Loss: 0.3546222325518075
ROC train: 0.905604	val: 0.630479	test: 0.621552
PRC train: 0.862851	val: 0.654428	test: 0.637655

Epoch: 120
Loss: 0.3480457867810207
ROC train: 0.907186	val: 0.632753	test: 0.629956
PRC train: 0.865893	val: 0.651232	test: 0.639849

Early stopping
Best (ROC):	 train: 0.766761	val: 0.660530	test: 0.609685
Best (PRC):	 train: 0.733562	val: 0.678739	test: 0.620933

ROC train: 0.875563	val: 0.635250	test: 0.630016
PRC train: 0.837089	val: 0.663605	test: 0.638026

Epoch: 95
Loss: 0.36702369817452035
ROC train: 0.875837	val: 0.639388	test: 0.625585
PRC train: 0.837892	val: 0.666905	test: 0.636024

Epoch: 96
Loss: 0.36893215388848855
ROC train: 0.876563	val: 0.641150	test: 0.619888
PRC train: 0.834801	val: 0.668653	test: 0.632839

Epoch: 97
Loss: 0.3684215882533849
ROC train: 0.883851	val: 0.646301	test: 0.625477
PRC train: 0.840033	val: 0.672057	test: 0.635300

Epoch: 98
Loss: 0.3671158126451343
ROC train: 0.882446	val: 0.629659	test: 0.627577
PRC train: 0.841992	val: 0.662280	test: 0.640950

Epoch: 99
Loss: 0.36877097741301157
ROC train: 0.884474	val: 0.627379	test: 0.632328
PRC train: 0.841764	val: 0.657176	test: 0.645069

Epoch: 100
Loss: 0.36508486767722625
ROC train: 0.885055	val: 0.637518	test: 0.641055
PRC train: 0.842684	val: 0.659129	test: 0.649543

Epoch: 101
Loss: 0.363824649842303
ROC train: 0.889649	val: 0.635878	test: 0.633904
PRC train: 0.847005	val: 0.661797	test: 0.645405

Epoch: 102
Loss: 0.36413023534667144
ROC train: 0.890445	val: 0.629147	test: 0.623084
PRC train: 0.848782	val: 0.659644	test: 0.638140

Epoch: 103
Loss: 0.3609934635185567
ROC train: 0.892697	val: 0.634451	test: 0.627620
PRC train: 0.849615	val: 0.662919	test: 0.638147

Epoch: 104
Loss: 0.35346901120518176
ROC train: 0.891286	val: 0.640774	test: 0.630508
PRC train: 0.847318	val: 0.663977	test: 0.634717

Epoch: 105
Loss: 0.35976446425934455
ROC train: 0.893825	val: 0.641787	test: 0.630768
PRC train: 0.850680	val: 0.664829	test: 0.637879

Epoch: 106
Loss: 0.36107332354754373
ROC train: 0.889959	val: 0.631711	test: 0.619187
PRC train: 0.846156	val: 0.659895	test: 0.636707

Epoch: 107
Loss: 0.3503027018332242
ROC train: 0.894141	val: 0.633852	test: 0.624282
PRC train: 0.851131	val: 0.661924	test: 0.638266

Epoch: 108
Loss: 0.3570993054273558
ROC train: 0.896307	val: 0.640405	test: 0.631738
PRC train: 0.855437	val: 0.663259	test: 0.643389

Epoch: 109
Loss: 0.3593201499647358
ROC train: 0.893757	val: 0.642547	test: 0.630788
PRC train: 0.854361	val: 0.665541	test: 0.644850

Epoch: 110
Loss: 0.3623347754822504
ROC train: 0.900893	val: 0.644409	test: 0.633017
PRC train: 0.859317	val: 0.669850	test: 0.640665

Epoch: 111
Loss: 0.35303560593685335
ROC train: 0.904182	val: 0.639360	test: 0.625466
PRC train: 0.863586	val: 0.665091	test: 0.636871

Epoch: 112
Loss: 0.35668490665726865
ROC train: 0.903476	val: 0.634852	test: 0.619629
PRC train: 0.862382	val: 0.663173	test: 0.636180

Epoch: 113
Loss: 0.3530558436769653
ROC train: 0.903190	val: 0.637835	test: 0.622389
PRC train: 0.861969	val: 0.666607	test: 0.634351

Epoch: 114
Loss: 0.3547498697708239
ROC train: 0.900591	val: 0.636615	test: 0.622793
PRC train: 0.858374	val: 0.666364	test: 0.635030

Epoch: 115
Loss: 0.34450232209742165
ROC train: 0.896431	val: 0.628549	test: 0.628193
PRC train: 0.855767	val: 0.657510	test: 0.640274

Epoch: 116
Loss: 0.3509075294737423
ROC train: 0.902369	val: 0.623718	test: 0.633409
PRC train: 0.859744	val: 0.649923	test: 0.642168

Epoch: 117
Loss: 0.35094377595040804
ROC train: 0.899409	val: 0.630786	test: 0.630159
PRC train: 0.856453	val: 0.655075	test: 0.635370

Epoch: 118
Loss: 0.34905825155453696
ROC train: 0.902585	val: 0.638352	test: 0.625020
PRC train: 0.860214	val: 0.666092	test: 0.633982

Epoch: 119
Loss: 0.3623825228116797
ROC train: 0.904659	val: 0.641274	test: 0.625460
PRC train: 0.863467	val: 0.671678	test: 0.636157

Epoch: 120
Loss: 0.3539751573793298
ROC train: 0.904502	val: 0.630989	test: 0.629023
PRC train: 0.862834	val: 0.664168	test: 0.638994

Early stopping
Best (ROC):	 train: 0.814073	val: 0.662439	test: 0.623060
Best (PRC):	 train: 0.776196	val: 0.680981	test: 0.627510
All runs completed.

ROC train: 0.888178	val: 0.656786	test: 0.623886
PRC train: 0.845002	val: 0.700185	test: 0.626476

Epoch: 95
Loss: 0.3663311288820528
ROC train: 0.886735	val: 0.653352	test: 0.626632
PRC train: 0.841274	val: 0.697300	test: 0.627509

Epoch: 96
Loss: 0.3686702374457291
ROC train: 0.874011	val: 0.638643	test: 0.618361
PRC train: 0.831282	val: 0.693498	test: 0.619293

Epoch: 97
Loss: 0.365213000707799
ROC train: 0.884874	val: 0.652371	test: 0.625679
PRC train: 0.839425	val: 0.699026	test: 0.621728

Epoch: 98
Loss: 0.3677981695605335
ROC train: 0.890567	val: 0.663208	test: 0.625737
PRC train: 0.845520	val: 0.704055	test: 0.622602

Epoch: 99
Loss: 0.36235709731431265
ROC train: 0.892694	val: 0.657791	test: 0.620894
PRC train: 0.849517	val: 0.700453	test: 0.620998

Epoch: 100
Loss: 0.3621287433420858
ROC train: 0.890076	val: 0.642501	test: 0.619607
PRC train: 0.849227	val: 0.692451	test: 0.620685

Epoch: 101
Loss: 0.3638817402280705
ROC train: 0.896978	val: 0.643145	test: 0.624831
PRC train: 0.855301	val: 0.690377	test: 0.624519

Epoch: 102
Loss: 0.3551249368480397
ROC train: 0.889394	val: 0.642512	test: 0.622807
PRC train: 0.846484	val: 0.689285	test: 0.623048

Epoch: 103
Loss: 0.35586024816801226
ROC train: 0.894660	val: 0.650328	test: 0.622927
PRC train: 0.849180	val: 0.693254	test: 0.625274

Epoch: 104
Loss: 0.35534707697109413
ROC train: 0.900287	val: 0.646978	test: 0.627668
PRC train: 0.858227	val: 0.694086	test: 0.627970

Epoch: 105
Loss: 0.35436103078432896
ROC train: 0.898693	val: 0.646637	test: 0.623880
PRC train: 0.858647	val: 0.694487	test: 0.624741

Epoch: 106
Loss: 0.35443506556115245
ROC train: 0.900142	val: 0.652434	test: 0.627269
PRC train: 0.859776	val: 0.697482	test: 0.627180

Epoch: 107
Loss: 0.35807530925945286
ROC train: 0.902671	val: 0.652841	test: 0.629068
PRC train: 0.863663	val: 0.696244	test: 0.627591

Epoch: 108
Loss: 0.35120691832629314
ROC train: 0.904218	val: 0.645445	test: 0.622445
PRC train: 0.865716	val: 0.693936	test: 0.621859

Epoch: 109
Loss: 0.3534331040139822
ROC train: 0.905109	val: 0.647231	test: 0.628687
PRC train: 0.863202	val: 0.694615	test: 0.627037

Epoch: 110
Loss: 0.3505203667300363
ROC train: 0.901492	val: 0.647113	test: 0.637733
PRC train: 0.860480	val: 0.689374	test: 0.631054

Epoch: 111
Loss: 0.35974059294979177
ROC train: 0.906552	val: 0.654110	test: 0.637048
PRC train: 0.866787	val: 0.697094	test: 0.634116

Epoch: 112
Loss: 0.3508559350096232
ROC train: 0.900133	val: 0.649478	test: 0.624181
PRC train: 0.861505	val: 0.698499	test: 0.625763

Epoch: 113
Loss: 0.35005474868256337
ROC train: 0.898265	val: 0.648973	test: 0.625905
PRC train: 0.858061	val: 0.696295	test: 0.622617

Epoch: 114
Loss: 0.3458005637652691
ROC train: 0.904114	val: 0.656347	test: 0.627729
PRC train: 0.866416	val: 0.692818	test: 0.628616

Epoch: 115
Loss: 0.34765834668510764
ROC train: 0.912003	val: 0.655803	test: 0.620060
PRC train: 0.872963	val: 0.695596	test: 0.623998

Epoch: 116
Loss: 0.3470220894185086
ROC train: 0.906166	val: 0.653954	test: 0.619271
PRC train: 0.869318	val: 0.696988	test: 0.621773

Epoch: 117
Loss: 0.34606151417765557
ROC train: 0.910057	val: 0.659665	test: 0.623208
PRC train: 0.874104	val: 0.702397	test: 0.627757

Epoch: 118
Loss: 0.3420286314940503
ROC train: 0.909441	val: 0.645963	test: 0.623669
PRC train: 0.872661	val: 0.693554	test: 0.623649

Epoch: 119
Loss: 0.34583237784877874
ROC train: 0.907714	val: 0.641760	test: 0.623468
PRC train: 0.869478	val: 0.692703	test: 0.622958

Epoch: 120
Loss: 0.33975271730475354
ROC train: 0.912127	val: 0.643948	test: 0.620761
PRC train: 0.872887	val: 0.694069	test: 0.623962

Early stopping
Best (ROC):	 train: 0.837837	val: 0.664592	test: 0.618173
Best (PRC):	 train: 0.792495	val: 0.707916	test: 0.620881

ROC train: 0.884155	val: 0.633626	test: 0.624104
PRC train: 0.837380	val: 0.677616	test: 0.631048

Epoch: 95
Loss: 0.3702313745102572
ROC train: 0.885586	val: 0.634087	test: 0.622904
PRC train: 0.839706	val: 0.679070	test: 0.626533

Epoch: 96
Loss: 0.37311349432429397
ROC train: 0.888140	val: 0.630648	test: 0.620488
PRC train: 0.842639	val: 0.679248	test: 0.628580

Epoch: 97
Loss: 0.3678358594710162
ROC train: 0.890242	val: 0.632431	test: 0.621550
PRC train: 0.845562	val: 0.680354	test: 0.621459

Epoch: 98
Loss: 0.36716558841090485
ROC train: 0.887904	val: 0.628948	test: 0.621612
PRC train: 0.841468	val: 0.677544	test: 0.626206

Epoch: 99
Loss: 0.36683754786658657
ROC train: 0.892255	val: 0.636564	test: 0.625494
PRC train: 0.846781	val: 0.681115	test: 0.633575

Epoch: 100
Loss: 0.36522599942345785
ROC train: 0.894940	val: 0.637159	test: 0.625307
PRC train: 0.849925	val: 0.681547	test: 0.630529

Epoch: 101
Loss: 0.3585785533892697
ROC train: 0.892922	val: 0.635222	test: 0.629010
PRC train: 0.848478	val: 0.679494	test: 0.629650

Epoch: 102
Loss: 0.3608730788484007
ROC train: 0.895789	val: 0.637618	test: 0.631406
PRC train: 0.850704	val: 0.680447	test: 0.636453

Epoch: 103
Loss: 0.358792348639442
ROC train: 0.894701	val: 0.636257	test: 0.625910
PRC train: 0.850002	val: 0.679182	test: 0.632704

Epoch: 104
Loss: 0.36209622331877417
ROC train: 0.900007	val: 0.640401	test: 0.627101
PRC train: 0.854726	val: 0.681636	test: 0.634104

Epoch: 105
Loss: 0.3614730628838948
ROC train: 0.898601	val: 0.643151	test: 0.625625
PRC train: 0.854936	val: 0.682076	test: 0.632367

Epoch: 106
Loss: 0.3567667719222123
ROC train: 0.897990	val: 0.639850	test: 0.628068
PRC train: 0.855955	val: 0.679684	test: 0.632618

Epoch: 107
Loss: 0.3518882748149413
ROC train: 0.897258	val: 0.635278	test: 0.627765
PRC train: 0.855701	val: 0.676345	test: 0.632173

Epoch: 108
Loss: 0.3552298641689903
ROC train: 0.901092	val: 0.632527	test: 0.623922
PRC train: 0.858360	val: 0.676365	test: 0.626127

Epoch: 109
Loss: 0.35509589125591245
ROC train: 0.898046	val: 0.631439	test: 0.617763
PRC train: 0.856473	val: 0.680050	test: 0.623348

Epoch: 110
Loss: 0.35391387803303564
ROC train: 0.896710	val: 0.638253	test: 0.623386
PRC train: 0.858085	val: 0.683228	test: 0.629888

Epoch: 111
Loss: 0.3505703349153143
ROC train: 0.898301	val: 0.638775	test: 0.620696
PRC train: 0.857003	val: 0.680173	test: 0.631571

Epoch: 112
Loss: 0.35424279483137966
ROC train: 0.904580	val: 0.631162	test: 0.621021
PRC train: 0.858965	val: 0.677182	test: 0.628307

Epoch: 113
Loss: 0.3437679797167692
ROC train: 0.904781	val: 0.637350	test: 0.627149
PRC train: 0.861184	val: 0.679871	test: 0.626558

Epoch: 114
Loss: 0.35524465941640754
ROC train: 0.906713	val: 0.636068	test: 0.628427
PRC train: 0.864003	val: 0.682947	test: 0.629231

Epoch: 115
Loss: 0.350751800505585
ROC train: 0.904769	val: 0.639748	test: 0.625575
PRC train: 0.862602	val: 0.686076	test: 0.630039

Epoch: 116
Loss: 0.34504221137900415
ROC train: 0.907521	val: 0.642172	test: 0.623516
PRC train: 0.865287	val: 0.687578	test: 0.631840

Epoch: 117
Loss: 0.3516780554780578
ROC train: 0.910822	val: 0.638491	test: 0.624933
PRC train: 0.869029	val: 0.685229	test: 0.635503

Epoch: 118
Loss: 0.3454627288916322
ROC train: 0.911385	val: 0.633318	test: 0.637854
PRC train: 0.871157	val: 0.680200	test: 0.640249

Epoch: 119
Loss: 0.3456156892588169
ROC train: 0.909710	val: 0.629083	test: 0.637578
PRC train: 0.869701	val: 0.674886	test: 0.639807

Epoch: 120
Loss: 0.3405522085814938
ROC train: 0.910951	val: 0.631661	test: 0.626698
PRC train: 0.871659	val: 0.676529	test: 0.633464

Early stopping
Best (ROC):	 train: 0.796038	val: 0.647153	test: 0.612631
Best (PRC):	 train: 0.752849	val: 0.690831	test: 0.608427

PRC train: 0.836456	val: 0.685395	test: 0.639920

Epoch: 95
Loss: 0.3826216837963929
ROC train: 0.881975	val: 0.636842	test: 0.633336
PRC train: 0.840206	val: 0.681085	test: 0.641884

Epoch: 96
Loss: 0.370315234830067
ROC train: 0.884825	val: 0.649194	test: 0.639573
PRC train: 0.839152	val: 0.693500	test: 0.645060

Epoch: 97
Loss: 0.37471897662493386
ROC train: 0.882472	val: 0.646912	test: 0.635550
PRC train: 0.839692	val: 0.692488	test: 0.648391

Epoch: 98
Loss: 0.3729541079689362
ROC train: 0.884209	val: 0.651226	test: 0.637768
PRC train: 0.841309	val: 0.689741	test: 0.646324

Epoch: 99
Loss: 0.3756055661538841
ROC train: 0.887705	val: 0.646228	test: 0.635716
PRC train: 0.844366	val: 0.687872	test: 0.643477

Epoch: 100
Loss: 0.3676758305229053
ROC train: 0.889104	val: 0.642400	test: 0.633405
PRC train: 0.846655	val: 0.690503	test: 0.642563

Epoch: 101
Loss: 0.372071962602587
ROC train: 0.884662	val: 0.657004	test: 0.617551
PRC train: 0.839166	val: 0.699490	test: 0.628912

Epoch: 102
Loss: 0.3707717371986775
ROC train: 0.890482	val: 0.651278	test: 0.623163
PRC train: 0.846643	val: 0.696377	test: 0.630318

Epoch: 103
Loss: 0.36698007867070215
ROC train: 0.880137	val: 0.637462	test: 0.639268
PRC train: 0.839916	val: 0.682312	test: 0.643714

Epoch: 104
Loss: 0.36409414248190897
ROC train: 0.891315	val: 0.649792	test: 0.647737
PRC train: 0.851225	val: 0.693383	test: 0.653726

Epoch: 105
Loss: 0.3645640644338999
ROC train: 0.895015	val: 0.649819	test: 0.639172
PRC train: 0.852091	val: 0.692541	test: 0.644893

Epoch: 106
Loss: 0.36147911858975956
ROC train: 0.894273	val: 0.647671	test: 0.638345
PRC train: 0.852045	val: 0.693705	test: 0.638785

Epoch: 107
Loss: 0.36798744151956375
ROC train: 0.891609	val: 0.644557	test: 0.631962
PRC train: 0.850847	val: 0.689176	test: 0.640703

Epoch: 108
Loss: 0.3610225330249701
ROC train: 0.897388	val: 0.651354	test: 0.631769
PRC train: 0.858662	val: 0.696601	test: 0.643347

Epoch: 109
Loss: 0.3592841678998727
ROC train: 0.890643	val: 0.662669	test: 0.620445
PRC train: 0.850105	val: 0.705307	test: 0.631165

Epoch: 110
Loss: 0.3664622319242989
ROC train: 0.893853	val: 0.654448	test: 0.628525
PRC train: 0.853100	val: 0.703542	test: 0.636441

Epoch: 111
Loss: 0.3548029388018758
ROC train: 0.894754	val: 0.643419	test: 0.637080
PRC train: 0.852378	val: 0.691229	test: 0.645371

Epoch: 112
Loss: 0.36193138417343734
ROC train: 0.893352	val: 0.643034	test: 0.633528
PRC train: 0.850001	val: 0.689347	test: 0.637291

Epoch: 113
Loss: 0.3576164032136244
ROC train: 0.903230	val: 0.653272	test: 0.626398
PRC train: 0.861582	val: 0.700618	test: 0.634293

Epoch: 114
Loss: 0.3481679051204325
ROC train: 0.901298	val: 0.651263	test: 0.621592
PRC train: 0.861357	val: 0.698123	test: 0.633283

Epoch: 115
Loss: 0.34982579516277984
ROC train: 0.895104	val: 0.645946	test: 0.623107
PRC train: 0.855961	val: 0.690972	test: 0.629686

Epoch: 116
Loss: 0.3496182489916036
ROC train: 0.901949	val: 0.656430	test: 0.629083
PRC train: 0.859172	val: 0.702675	test: 0.633374

Epoch: 117
Loss: 0.3504855714022282
ROC train: 0.904789	val: 0.650966	test: 0.619453
PRC train: 0.863497	val: 0.692243	test: 0.632060

Epoch: 118
Loss: 0.3536283806164958
ROC train: 0.905972	val: 0.651349	test: 0.627982
PRC train: 0.864447	val: 0.696155	test: 0.638746

Epoch: 119
Loss: 0.3495692312957533
ROC train: 0.903560	val: 0.656213	test: 0.635026
PRC train: 0.863094	val: 0.694728	test: 0.637875

Epoch: 120
Loss: 0.34624651265296946
ROC train: 0.908301	val: 0.652683	test: 0.639038
PRC train: 0.868075	val: 0.697343	test: 0.647220

Early stopping
Best (ROC):	 train: 0.809981	val: 0.667040	test: 0.620951
Best (PRC):	 train: 0.770519	val: 0.690019	test: 0.617791

ROC train: 0.882562	val: 0.635727	test: 0.628724
PRC train: 0.837013	val: 0.674049	test: 0.633793

Epoch: 95
Loss: 0.3761801422552388
ROC train: 0.884007	val: 0.643516	test: 0.624397
PRC train: 0.838405	val: 0.684538	test: 0.631765

Epoch: 96
Loss: 0.3688488977805137
ROC train: 0.885003	val: 0.643307	test: 0.617758
PRC train: 0.844510	val: 0.678033	test: 0.626792

Epoch: 97
Loss: 0.36699827677353325
ROC train: 0.883181	val: 0.633327	test: 0.611979
PRC train: 0.842810	val: 0.674916	test: 0.625681

Epoch: 98
Loss: 0.3683155684558737
ROC train: 0.887253	val: 0.637853	test: 0.612463
PRC train: 0.847481	val: 0.674064	test: 0.625872

Epoch: 99
Loss: 0.3688900351299667
ROC train: 0.889636	val: 0.646309	test: 0.619658
PRC train: 0.849050	val: 0.682544	test: 0.632981

Epoch: 100
Loss: 0.36868191210226264
ROC train: 0.883711	val: 0.642488	test: 0.614981
PRC train: 0.843643	val: 0.684911	test: 0.628683

Epoch: 101
Loss: 0.3728161470238733
ROC train: 0.890761	val: 0.650934	test: 0.616734
PRC train: 0.849217	val: 0.686178	test: 0.622386

Epoch: 102
Loss: 0.3661712963248983
ROC train: 0.875889	val: 0.625703	test: 0.607027
PRC train: 0.836298	val: 0.669991	test: 0.615039

Epoch: 103
Loss: 0.3634268259799448
ROC train: 0.882299	val: 0.637192	test: 0.619060
PRC train: 0.841579	val: 0.676205	test: 0.621268

Epoch: 104
Loss: 0.36705117549142946
ROC train: 0.894611	val: 0.646490	test: 0.625550
PRC train: 0.852865	val: 0.680169	test: 0.630698

Epoch: 105
Loss: 0.362967717009567
ROC train: 0.897513	val: 0.637301	test: 0.625731
PRC train: 0.855521	val: 0.675716	test: 0.630171

Epoch: 106
Loss: 0.36725066653285715
ROC train: 0.895516	val: 0.631088	test: 0.624229
PRC train: 0.854198	val: 0.670436	test: 0.632286

Epoch: 107
Loss: 0.3646496462048302
ROC train: 0.895925	val: 0.636625	test: 0.632785
PRC train: 0.854807	val: 0.674752	test: 0.639198

Epoch: 108
Loss: 0.35813762122410414
ROC train: 0.896011	val: 0.642888	test: 0.625383
PRC train: 0.856873	val: 0.680287	test: 0.631520

Epoch: 109
Loss: 0.35805886249323116
ROC train: 0.898610	val: 0.644294	test: 0.619721
PRC train: 0.858436	val: 0.684498	test: 0.629360

Epoch: 110
Loss: 0.35613178737146944
ROC train: 0.897325	val: 0.636135	test: 0.624536
PRC train: 0.857281	val: 0.673111	test: 0.633018

Epoch: 111
Loss: 0.3673243726171447
ROC train: 0.898193	val: 0.635234	test: 0.622070
PRC train: 0.859154	val: 0.676453	test: 0.635348

Epoch: 112
Loss: 0.3543175797646835
ROC train: 0.901806	val: 0.644885	test: 0.622729
PRC train: 0.864430	val: 0.684676	test: 0.634964

Epoch: 113
Loss: 0.35596585708003925
ROC train: 0.896527	val: 0.643724	test: 0.615580
PRC train: 0.858818	val: 0.680287	test: 0.626349

Epoch: 114
Loss: 0.3519247538333151
ROC train: 0.896988	val: 0.640517	test: 0.612573
PRC train: 0.855708	val: 0.677391	test: 0.623656

Epoch: 115
Loss: 0.3542454669972043
ROC train: 0.904148	val: 0.623177	test: 0.608865
PRC train: 0.867805	val: 0.664045	test: 0.621864

Epoch: 116
Loss: 0.35770094648988693
ROC train: 0.901399	val: 0.622530	test: 0.614846
PRC train: 0.864873	val: 0.663772	test: 0.624643

Epoch: 117
Loss: 0.35022851201704686
ROC train: 0.906322	val: 0.631478	test: 0.621068
PRC train: 0.870102	val: 0.674145	test: 0.627408

Epoch: 118
Loss: 0.3521210506163663
ROC train: 0.900246	val: 0.631459	test: 0.617431
PRC train: 0.862703	val: 0.684654	test: 0.629110

Epoch: 119
Loss: 0.35224759984775883
ROC train: 0.902534	val: 0.641708	test: 0.626738
PRC train: 0.864057	val: 0.689392	test: 0.636222

Epoch: 120
Loss: 0.3475700387257115
ROC train: 0.908807	val: 0.638111	test: 0.627045
PRC train: 0.870968	val: 0.689154	test: 0.639586

Early stopping
Best (ROC):	 train: 0.814141	val: 0.660368	test: 0.621948
Best (PRC):	 train: 0.777597	val: 0.679463	test: 0.621988

ROC train: 0.881736	val: 0.652036	test: 0.630739
PRC train: 0.839650	val: 0.685520	test: 0.636521

Epoch: 95
Loss: 0.3703099105732428
ROC train: 0.884278	val: 0.651336	test: 0.633931
PRC train: 0.841682	val: 0.688084	test: 0.640358

Epoch: 96
Loss: 0.3708581579855593
ROC train: 0.885595	val: 0.648244	test: 0.638013
PRC train: 0.842666	val: 0.688424	test: 0.645987

Epoch: 97
Loss: 0.37864893789325915
ROC train: 0.879286	val: 0.635998	test: 0.633972
PRC train: 0.838116	val: 0.674618	test: 0.642956

Epoch: 98
Loss: 0.3748139199760118
ROC train: 0.879216	val: 0.638964	test: 0.638692
PRC train: 0.835715	val: 0.686826	test: 0.648688

Epoch: 99
Loss: 0.37121611938352345
ROC train: 0.883787	val: 0.633481	test: 0.624494
PRC train: 0.842123	val: 0.671272	test: 0.633139

Epoch: 100
Loss: 0.36833472468089834
ROC train: 0.888208	val: 0.645162	test: 0.638095
PRC train: 0.846672	val: 0.689214	test: 0.636910

Epoch: 101
Loss: 0.37044086478316807
ROC train: 0.884322	val: 0.642929	test: 0.641222
PRC train: 0.842786	val: 0.688872	test: 0.638154

Epoch: 102
Loss: 0.3672768465611744
ROC train: 0.891479	val: 0.652321	test: 0.641329
PRC train: 0.850193	val: 0.687657	test: 0.643362

Epoch: 103
Loss: 0.36594708438644374
ROC train: 0.890160	val: 0.644523	test: 0.645123
PRC train: 0.848353	val: 0.684995	test: 0.649234

Epoch: 104
Loss: 0.3679682904319059
ROC train: 0.892209	val: 0.635252	test: 0.642808
PRC train: 0.852050	val: 0.674959	test: 0.653612

Epoch: 105
Loss: 0.3630072144229238
ROC train: 0.893410	val: 0.632006	test: 0.649078
PRC train: 0.853602	val: 0.674086	test: 0.656216

Epoch: 106
Loss: 0.370311289396317
ROC train: 0.895954	val: 0.644037	test: 0.639223
PRC train: 0.854233	val: 0.686734	test: 0.643942

Epoch: 107
Loss: 0.3642259269564678
ROC train: 0.896465	val: 0.643270	test: 0.625953
PRC train: 0.855596	val: 0.682547	test: 0.634657

Epoch: 108
Loss: 0.3626758720551892
ROC train: 0.895074	val: 0.643694	test: 0.637696
PRC train: 0.853682	val: 0.685747	test: 0.641980

Epoch: 109
Loss: 0.3621824608702465
ROC train: 0.896881	val: 0.645471	test: 0.643725
PRC train: 0.857224	val: 0.688388	test: 0.650562

Epoch: 110
Loss: 0.3589213201320597
ROC train: 0.896805	val: 0.643233	test: 0.647737
PRC train: 0.855847	val: 0.683627	test: 0.650218

Epoch: 111
Loss: 0.3558553974063049
ROC train: 0.896888	val: 0.641237	test: 0.638074
PRC train: 0.855586	val: 0.683323	test: 0.642644

Epoch: 112
Loss: 0.35464363938834453
ROC train: 0.900825	val: 0.647432	test: 0.634539
PRC train: 0.860779	val: 0.691332	test: 0.640760

Epoch: 113
Loss: 0.3525942116673347
ROC train: 0.902882	val: 0.644016	test: 0.637510
PRC train: 0.862205	val: 0.684040	test: 0.639828

Epoch: 114
Loss: 0.3563044677214247
ROC train: 0.904514	val: 0.636005	test: 0.644541
PRC train: 0.864708	val: 0.678565	test: 0.646333

Epoch: 115
Loss: 0.3565943229927612
ROC train: 0.904516	val: 0.640100	test: 0.639762
PRC train: 0.865712	val: 0.680089	test: 0.638942

Epoch: 116
Loss: 0.35959655353779724
ROC train: 0.904468	val: 0.644879	test: 0.635261
PRC train: 0.869209	val: 0.682897	test: 0.634474

Epoch: 117
Loss: 0.35480470703952205
ROC train: 0.909677	val: 0.637683	test: 0.638126
PRC train: 0.871207	val: 0.679930	test: 0.644852

Epoch: 118
Loss: 0.34677234308071275
ROC train: 0.907457	val: 0.638511	test: 0.626994
PRC train: 0.870374	val: 0.673361	test: 0.637669

Epoch: 119
Loss: 0.3499169051701472
ROC train: 0.901193	val: 0.638272	test: 0.634109
PRC train: 0.866359	val: 0.673486	test: 0.637632

Epoch: 120
Loss: 0.3524423603087293
ROC train: 0.909301	val: 0.643855	test: 0.634907
PRC train: 0.872932	val: 0.674893	test: 0.636614

Early stopping
Best (ROC):	 train: 0.870375	val: 0.663628	test: 0.631265
Best (PRC):	 train: 0.826501	val: 0.696258	test: 0.636197
All runs completed.

ROC train: 0.888879	val: 0.643513	test: 0.621376
PRC train: 0.840670	val: 0.689304	test: 0.633209

Epoch: 95
Loss: 0.37251980715947053
ROC train: 0.888755	val: 0.646443	test: 0.622585
PRC train: 0.843001	val: 0.692553	test: 0.636717

Epoch: 96
Loss: 0.36894966082413827
ROC train: 0.886343	val: 0.643939	test: 0.622196
PRC train: 0.840493	val: 0.685659	test: 0.634446

Epoch: 97
Loss: 0.3712653834966606
ROC train: 0.887783	val: 0.644503	test: 0.624682
PRC train: 0.841077	val: 0.686856	test: 0.633621

Epoch: 98
Loss: 0.3689082502473227
ROC train: 0.892026	val: 0.649103	test: 0.627616
PRC train: 0.843026	val: 0.690162	test: 0.641135

Epoch: 99
Loss: 0.36497716129409674
ROC train: 0.891458	val: 0.644667	test: 0.627192
PRC train: 0.843218	val: 0.692795	test: 0.634280

Epoch: 100
Loss: 0.3648184362227368
ROC train: 0.889818	val: 0.640929	test: 0.626137
PRC train: 0.841666	val: 0.690975	test: 0.630135

Epoch: 101
Loss: 0.3593199478084302
ROC train: 0.892607	val: 0.637617	test: 0.623862
PRC train: 0.846861	val: 0.684979	test: 0.635407

Epoch: 102
Loss: 0.3603051879474489
ROC train: 0.895768	val: 0.639399	test: 0.630112
PRC train: 0.850132	val: 0.683529	test: 0.638127

Epoch: 103
Loss: 0.3564077895317046
ROC train: 0.898742	val: 0.646740	test: 0.625295
PRC train: 0.852492	val: 0.691488	test: 0.635397

Epoch: 104
Loss: 0.36498095488066973
ROC train: 0.899378	val: 0.647672	test: 0.620866
PRC train: 0.852743	val: 0.692394	test: 0.634267

Epoch: 105
Loss: 0.35462854303817726
ROC train: 0.898848	val: 0.650766	test: 0.625486
PRC train: 0.852645	val: 0.694112	test: 0.634697

Epoch: 106
Loss: 0.3614340670513506
ROC train: 0.894830	val: 0.636432	test: 0.629207
PRC train: 0.848614	val: 0.684822	test: 0.632151

Epoch: 107
Loss: 0.3528369467392589
ROC train: 0.896440	val: 0.625334	test: 0.625317
PRC train: 0.850726	val: 0.678543	test: 0.631265

Epoch: 108
Loss: 0.3527199892003852
ROC train: 0.902970	val: 0.640651	test: 0.625351
PRC train: 0.859787	val: 0.690336	test: 0.631393

Epoch: 109
Loss: 0.3530303015037173
ROC train: 0.901802	val: 0.657386	test: 0.629425
PRC train: 0.858670	val: 0.697037	test: 0.637778

Epoch: 110
Loss: 0.3452535001685906
ROC train: 0.901017	val: 0.649254	test: 0.625080
PRC train: 0.856819	val: 0.695806	test: 0.638111

Epoch: 111
Loss: 0.3492655273977382
ROC train: 0.903511	val: 0.634952	test: 0.624865
PRC train: 0.859299	val: 0.684323	test: 0.632350

Epoch: 112
Loss: 0.34816713653957243
ROC train: 0.906320	val: 0.639040	test: 0.636829
PRC train: 0.861621	val: 0.690525	test: 0.639375

Epoch: 113
Loss: 0.3541717601603773
ROC train: 0.904416	val: 0.642177	test: 0.630108
PRC train: 0.860754	val: 0.694283	test: 0.637739

Epoch: 114
Loss: 0.3529977452796385
ROC train: 0.906373	val: 0.642242	test: 0.630811
PRC train: 0.859787	val: 0.689782	test: 0.634984

Epoch: 115
Loss: 0.3445113235701095
ROC train: 0.906548	val: 0.644052	test: 0.629538
PRC train: 0.859231	val: 0.688708	test: 0.635720

Epoch: 116
Loss: 0.35032312867850995
ROC train: 0.909414	val: 0.638745	test: 0.628953
PRC train: 0.864046	val: 0.686507	test: 0.636658

Epoch: 117
Loss: 0.3431368210517357
ROC train: 0.909610	val: 0.643144	test: 0.633124
PRC train: 0.865558	val: 0.690058	test: 0.639695

Epoch: 118
Loss: 0.34630341364873096
ROC train: 0.910746	val: 0.646917	test: 0.633546
PRC train: 0.867556	val: 0.694105	test: 0.639059

Epoch: 119
Loss: 0.34566562846456717
ROC train: 0.910203	val: 0.645299	test: 0.627400
PRC train: 0.867357	val: 0.693582	test: 0.631011

Epoch: 120
Loss: 0.3453567451282279
ROC train: 0.912697	val: 0.650441	test: 0.627786
PRC train: 0.869556	val: 0.697648	test: 0.631462

Epoch: 121
Loss: 0.3445328330344969
ROC train: 0.914012	val: 0.652190	test: 0.628960
PRC train: 0.870183	val: 0.692411	test: 0.637557

Epoch: 122
Loss: 0.3429000048697118
ROC train: 0.914757	val: 0.651022	test: 0.632110
PRC train: 0.872130	val: 0.690139	test: 0.638732

Epoch: 123
Loss: 0.3418959510986488
ROC train: 0.912898	val: 0.641537	test: 0.636620
PRC train: 0.868580	val: 0.687965	test: 0.638698

Epoch: 124
Loss: 0.3428574927728236
ROC train: 0.912413	val: 0.640841	test: 0.637518
PRC train: 0.871722	val: 0.685637	test: 0.639254

Epoch: 125
Loss: 0.3375893023214438
ROC train: 0.916453	val: 0.642921	test: 0.632608
PRC train: 0.875117	val: 0.688079	test: 0.639267

Epoch: 126
Loss: 0.335352520463593
ROC train: 0.917503	val: 0.644609	test: 0.635930
PRC train: 0.876300	val: 0.690737	test: 0.642192

Epoch: 127
Loss: 0.3402941553202001
ROC train: 0.920267	val: 0.649291	test: 0.632788
PRC train: 0.877075	val: 0.690792	test: 0.641701

Epoch: 128
Loss: 0.33356226870868
ROC train: 0.919919	val: 0.644153	test: 0.626388
PRC train: 0.875599	val: 0.686450	test: 0.639871

Epoch: 129
Loss: 0.339642704648338
ROC train: 0.920657	val: 0.646896	test: 0.626932
PRC train: 0.879755	val: 0.688045	test: 0.637835

Epoch: 130
Loss: 0.33444100294908036
ROC train: 0.921214	val: 0.651506	test: 0.624454
PRC train: 0.882037	val: 0.694252	test: 0.637474

Epoch: 131
Loss: 0.33268301671535666
ROC train: 0.919238	val: 0.642800	test: 0.632583
PRC train: 0.880589	val: 0.686170	test: 0.635514

Epoch: 132
Loss: 0.33584456070995644
ROC train: 0.921236	val: 0.645489	test: 0.635643
PRC train: 0.879873	val: 0.686553	test: 0.641042

Epoch: 133
Loss: 0.33043671015135156
ROC train: 0.922268	val: 0.646791	test: 0.632393
PRC train: 0.881368	val: 0.687096	test: 0.638970

Epoch: 134
Loss: 0.330703445240513
ROC train: 0.924078	val: 0.644807	test: 0.632596
PRC train: 0.886716	val: 0.685573	test: 0.639693

Epoch: 135
Loss: 0.32734688363167297
ROC train: 0.920446	val: 0.637510	test: 0.628621
PRC train: 0.884964	val: 0.681824	test: 0.635179

Epoch: 136
Loss: 0.32852937824744244
ROC train: 0.918054	val: 0.637474	test: 0.622482
PRC train: 0.882088	val: 0.682190	test: 0.632185

Epoch: 137
Loss: 0.3247885568552721
ROC train: 0.919291	val: 0.640506	test: 0.622843
PRC train: 0.884191	val: 0.684418	test: 0.633781

Epoch: 138
Loss: 0.3288933819027552
ROC train: 0.926645	val: 0.649582	test: 0.626943
PRC train: 0.890599	val: 0.694803	test: 0.637923

Epoch: 139
Loss: 0.3227939471301156
ROC train: 0.925726	val: 0.646690	test: 0.631324
PRC train: 0.892002	val: 0.689919	test: 0.640465

Epoch: 140
Loss: 0.3285112188425759
ROC train: 0.925319	val: 0.639678	test: 0.635785
PRC train: 0.890143	val: 0.679890	test: 0.639247

Epoch: 141
Loss: 0.32309647325938096
ROC train: 0.929228	val: 0.652366	test: 0.635968
PRC train: 0.891180	val: 0.689341	test: 0.641945

Epoch: 142
Loss: 0.3209368157194849
ROC train: 0.929135	val: 0.658681	test: 0.629601
PRC train: 0.890222	val: 0.695508	test: 0.640632

Epoch: 143
Loss: 0.32175121502060794
ROC train: 0.930157	val: 0.654697	test: 0.634799
PRC train: 0.891928	val: 0.695212	test: 0.639570

Epoch: 144
Loss: 0.3140770324968558
ROC train: 0.931128	val: 0.648014	test: 0.633492
PRC train: 0.895043	val: 0.693345	test: 0.638095

Epoch: 145
Loss: 0.3210019561946822
ROC train: 0.932189	val: 0.648728	test: 0.630164
PRC train: 0.896678	val: 0.689020	test: 0.640041

Epoch: 146
Loss: 0.3201073363349957
ROC train: 0.929878	val: 0.648870	test: 0.632554
PRC train: 0.895511	val: 0.686568	test: 0.638991

Epoch: 147
Loss: 0.3196869561406161
ROC train: 0.931283	val: 0.647823	test: 0.627959
PRC train: 0.897096	val: 0.691246	test: 0.634483

Epoch: 148
Loss: 0.32060752146051175
ROC train: 0.932343	val: 0.644272	test: 0.626981
PRC train: 0.900023	val: 0.690607	test: 0.636964

Epoch: 149
Loss: 0.3153507251670682
ROC train: 0.931825	val: 0.645119	test: 0.633503
PRC train: 0.898025	val: 0.687050	test: 0.638874

Epoch: 150
Loss: 0.31857861852495606
ROC train: 0.929813	val: 0.638413	test: 0.633791
PRC train: 0.897777	val: 0.685662	test: 0.633615

Epoch: 151
Loss: 0.3170735546715635
ROC train: 0.935308	val: 0.639146	test: 0.624252
PRC train: 0.904699	val: 0.682868	test: 0.636617

Epoch: 152
Loss: 0.3158884344689269
ROC train: 0.934495	val: 0.646618	test: 0.623248
PRC train: 0.901567	val: 0.687445	test: 0.633543

Epoch: 153
Loss: 0.31237082999460997
ROC train: 0.931834	val: 0.643682	test: 0.630774
PRC train: 0.902844	val: 0.685565	test: 0.631969

Epoch: 154
Loss: 0.31710880179751605
ROC train: 0.934407	val: 0.641141	test: 0.632794
PRC train: 0.897623	val: 0.683970	test: 0.636995

Epoch: 155
Loss: 0.3091778344047341
ROC train: 0.928630	val: 0.636881	test: 0.626577
PRC train: 0.893338	val: 0.681217	test: 0.634380

Epoch: 156
Loss: 0.3088666514608675
ROC train: 0.932115	val: 0.645229	test: 0.627404
PRC train: 0.901845	val: 0.687336	test: 0.636459

Epoch: 157
Loss: 0.3176795727871997
ROC train: 0.936836	val: 0.658400	test: 0.635950
PRC train: 0.903390	val: 0.698203	test: 0.642977

Epoch: 158
Loss: 0.3062616114618205
ROC train: 0.937324	val: 0.652572	test: 0.631109
PRC train: 0.904917	val: 0.696305	test: 0.640730

Epoch: 159
Loss: 0.30324133619280924
ROC train: 0.937611	val: 0.643800	test: 0.630678
PRC train: 0.905610	val: 0.686965	test: 0.640227

Epoch: 160
Loss: 0.3088862742208343
ROC train: 0.940921	val: 0.639458	test: 0.639678
PRC train: 0.911502	val: 0.680656	test: 0.640977

Epoch: 161
Loss: 0.3035222523594226
ROC train: 0.940111	val: 0.642820	test: 0.636482
PRC train: 0.911220	val: 0.679450	test: 0.640965

Epoch: 162
Loss: 0.30455013089119787
ROC train: 0.935076	val: 0.635541	test: 0.627012
PRC train: 0.908719	val: 0.674646	test: 0.635077

Epoch: 163
Loss: 0.30127908320755575
ROC train: 0.939957	val: 0.640518	test: 0.625390
PRC train: 0.911436	val: 0.680405	test: 0.631006

Epoch: 164
Loss: 0.2991755794050867
ROC train: 0.942194	val: 0.651982	test: 0.626302
PRC train: 0.913512	val: 0.689260	test: 0.633329

Epoch: 165
Loss: 0.29800254440823454
ROC train: 0.940447	val: 0.651022	test: 0.621674
PRC train: 0.912644	val: 0.686663	test: 0.636078

Epoch: 166
Loss: 0.3043299295736289
ROC train: 0.944473	val: 0.646065	test: 0.630558
PRC train: 0.915384	val: 0.685556	test: 0.639267

Epoch: 167
Loss: 0.29562724582457495
ROC train: 0.940718	val: 0.637352	test: 0.628533
PRC train: 0.909412	val: 0.679556	test: 0.637224

Epoch: 168
Loss: 0.29944826811125935
ROC train: 0.938848	val: 0.637922	test: 0.630180
PRC train: 0.912498	val: 0.679410	test: 0.635674

Epoch: 169
Loss: 0.2991841734209304
ROC train: 0.947229	val: 0.650950	test: 0.635567
PRC train: 0.923880	val: 0.687771	test: 0.637451

Epoch: 170
Loss: 0.29618413112619213
ROC train: 0.948645	val: 0.646698	test: 0.632196
PRC train: 0.922849	val: 0.690142	test: 0.637906

Epoch: 171
Loss: 0.29994632912005526
ROC train: 0.947648	val: 0.644013	test: 0.631341
PRC train: 0.922057	val: 0.688551	test: 0.634988

Epoch: 172
Loss: 0.2936095773747635
ROC train: 0.946059	val: 0.647743	test: 0.632240
PRC train: 0.921642	val: 0.692739	test: 0.637380

Epoch: 173
Loss: 0.2948302426936271
ROC train: 0.947712	val: 0.648658	test: 0.635102
PRC train: 0.922010	val: 0.687356	test: 0.639091

Epoch: 174
Loss: 0.292824077810565
ROC train: 0.948370	val: 0.651620	test: 0.628870
PRC train: 0.925405	val: 0.690795	test: 0.638865

Epoch: 175
Loss: 0.28870328979464177
ROC train: 0.947066	val: 0.644890	test: 0.625177
PRC train: 0.923245	val: 0.686841	test: 0.633850

Epoch: 176
Loss: 0.2897197170784769
ROC train: 0.948048	val: 0.640816	test: 0.626528
PRC train: 0.925614	val: 0.684784	test: 0.633353

Epoch: 177
Loss: 0.2877423511433276
ROC train: 0.951067	val: 0.643864	test: 0.628123
PRC train: 0.926647	val: 0.688616	test: 0.637893

Early stopping
Best (ROC):	 train: 0.929135	val: 0.658681	test: 0.629601
Best (PRC):	 train: 0.890222	val: 0.695508	test: 0.640632
All runs completed.
