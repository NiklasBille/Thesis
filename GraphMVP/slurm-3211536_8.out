>>> Starting run for dataset: sider
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running RANDOM configs_split_experiments/GraphCL/sider/random/train_prop=0.6.yml on cuda:0
Running RANDOM configs_split_experiments/GraphCL/sider/random/train_prop=0.7.yml on cuda:1
Running RANDOM configs_split_experiments/GraphCL/sider/random/train_prop=0.8.yml on cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.7.yml --runseed 4 --device cuda:1
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.7.yml --runseed 5 --device cuda:1
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.7.yml --runseed 6 --device cuda:1
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.6.yml --runseed 4 --device cuda:0
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.6.yml --runseed 5 --device cuda:0
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.8.yml --runseed 4 --device cuda:2
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.6.yml --runseed 6 --device cuda:0
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.8.yml --runseed 5 --device cuda:2
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.8.yml --runseed 6 --device cuda:2
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/random/train_prop=0.6/sider_random_4_26-05_09-56-15  ]
[ Using Seed :  4  ]
[ Using device :  cuda:0  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
randomly split
Data(edge_attr=[38, 2], edge_index=[2, 38], id=[1], x=[18, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6893422219922754
ROC train: 0.531295	val: 0.531084	test: 0.522157
PRC train: 0.582847	val: 0.598566	test: 0.568535

Epoch: 2
Loss: 0.6509093216654553
ROC train: 0.558268	val: 0.546899	test: 0.542052
PRC train: 0.600128	val: 0.606413	test: 0.576635

Epoch: 3
Loss: 0.608128236791585
ROC train: 0.569809	val: 0.555329	test: 0.538224
PRC train: 0.610703	val: 0.613087	test: 0.576695

Epoch: 4
Loss: 0.5864161184436145
ROC train: 0.582937	val: 0.559728	test: 0.539903
PRC train: 0.622185	val: 0.616929	test: 0.580234

Epoch: 5
Loss: 0.5714435627375253
ROC train: 0.602006	val: 0.569036	test: 0.552516
PRC train: 0.633217	val: 0.618579	test: 0.589747

Epoch: 6
Loss: 0.5466020292287164
ROC train: 0.619155	val: 0.589440	test: 0.568422
PRC train: 0.641738	val: 0.626787	test: 0.598797

Epoch: 7
Loss: 0.5513443842629465
ROC train: 0.631724	val: 0.597402	test: 0.580700
PRC train: 0.648567	val: 0.632040	test: 0.603943

Epoch: 8
Loss: 0.5333226808679379
ROC train: 0.643749	val: 0.600095	test: 0.580185
PRC train: 0.657973	val: 0.635716	test: 0.602667

Epoch: 9
Loss: 0.5199881791314303
ROC train: 0.651611	val: 0.602483	test: 0.577999
PRC train: 0.661539	val: 0.639697	test: 0.602903

Epoch: 10
Loss: 0.5228150580113385
ROC train: 0.665682	val: 0.613733	test: 0.584933
PRC train: 0.669037	val: 0.648223	test: 0.606307

Epoch: 11
Loss: 0.506827482163347
ROC train: 0.680017	val: 0.627963	test: 0.594481
PRC train: 0.677383	val: 0.657722	test: 0.609684

Epoch: 12
Loss: 0.5018162597476502
ROC train: 0.686606	val: 0.628465	test: 0.593780
PRC train: 0.681727	val: 0.661284	test: 0.610621

Epoch: 13
Loss: 0.49943678596247737
ROC train: 0.693152	val: 0.629619	test: 0.592901
PRC train: 0.684914	val: 0.660725	test: 0.611458

Epoch: 14
Loss: 0.4970659380427474
ROC train: 0.704007	val: 0.629956	test: 0.595181
PRC train: 0.692399	val: 0.665279	test: 0.612121

Epoch: 15
Loss: 0.4923152460874305
ROC train: 0.713041	val: 0.628721	test: 0.599406
PRC train: 0.699106	val: 0.667140	test: 0.614051

Epoch: 16
Loss: 0.4915589289338096
ROC train: 0.720639	val: 0.624742	test: 0.604606
PRC train: 0.703904	val: 0.663453	test: 0.615309

Epoch: 17
Loss: 0.4808465285959891
ROC train: 0.726127	val: 0.621232	test: 0.602332
PRC train: 0.707544	val: 0.659875	test: 0.612563

Epoch: 18
Loss: 0.48263958663056405
ROC train: 0.725762	val: 0.617207	test: 0.598337
PRC train: 0.707376	val: 0.656340	test: 0.610428

Epoch: 19
Loss: 0.47670603471280226
ROC train: 0.733223	val: 0.620676	test: 0.602084
PRC train: 0.712460	val: 0.660133	test: 0.610528

Epoch: 20
Loss: 0.4695539454732249
ROC train: 0.737541	val: 0.618557	test: 0.602606
PRC train: 0.716839	val: 0.656522	test: 0.611087

Epoch: 21
Loss: 0.4665411965945887
ROC train: 0.747208	val: 0.618008	test: 0.602545
PRC train: 0.722888	val: 0.657242	test: 0.612100

Epoch: 22
Loss: 0.46891403550140154
ROC train: 0.748465	val: 0.618168	test: 0.600521
PRC train: 0.723378	val: 0.661795	test: 0.612461

Epoch: 23
Loss: 0.4631619045308179
ROC train: 0.755600	val: 0.619535	test: 0.599021
PRC train: 0.729777	val: 0.664483	test: 0.611157

Epoch: 24
Loss: 0.46418255775920614
ROC train: 0.759331	val: 0.622385	test: 0.598025
PRC train: 0.732467	val: 0.660671	test: 0.608152

Epoch: 25
Loss: 0.46170552477284427
ROC train: 0.766011	val: 0.627351	test: 0.605009
PRC train: 0.738292	val: 0.669194	test: 0.613306

Epoch: 26
Loss: 0.4491370282584153
ROC train: 0.765615	val: 0.625394	test: 0.602627
PRC train: 0.737849	val: 0.674883	test: 0.615136

Epoch: 27
Loss: 0.45602875715351165
ROC train: 0.770820	val: 0.623230	test: 0.597445
PRC train: 0.742895	val: 0.669123	test: 0.612898

Epoch: 28
Loss: 0.4527423121244154
ROC train: 0.767453	val: 0.616253	test: 0.592701
PRC train: 0.736339	val: 0.657697	test: 0.608191

Epoch: 29
Loss: 0.44429366907714096
ROC train: 0.777322	val: 0.625615	test: 0.595826
PRC train: 0.743854	val: 0.666684	test: 0.606475

Epoch: 30
Loss: 0.45151623789889106
ROC train: 0.779722	val: 0.629998	test: 0.594538
PRC train: 0.745709	val: 0.668838	test: 0.607748

Epoch: 31
Loss: 0.4437140776624411
ROC train: 0.783383	val: 0.631028	test: 0.592211
PRC train: 0.750649	val: 0.669882	test: 0.607576

Epoch: 32
Loss: 0.4454668724983566
ROC train: 0.792687	val: 0.626449	test: 0.589875
PRC train: 0.759074	val: 0.669467	test: 0.608909

Epoch: 33
Loss: 0.4433004139186838Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/random/train_prop=0.6/sider_random_5_26-05_09-56-15  ]
[ Using Seed :  5  ]
[ Using device :  cuda:0  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
randomly split
Data(edge_attr=[38, 2], edge_index=[2, 38], id=[1], x=[18, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6931550057917415
ROC train: 0.524154	val: 0.525424	test: 0.501226
PRC train: 0.583010	val: 0.602029	test: 0.560350

Epoch: 2
Loss: 0.6414904508119503
ROC train: 0.546308	val: 0.533997	test: 0.512160
PRC train: 0.599990	val: 0.607885	test: 0.566841

Epoch: 3
Loss: 0.6173908892797243
ROC train: 0.557899	val: 0.535688	test: 0.513828
PRC train: 0.606792	val: 0.610953	test: 0.565299

Epoch: 4
Loss: 0.5860802210218483
ROC train: 0.578671	val: 0.546940	test: 0.522429
PRC train: 0.618700	val: 0.618777	test: 0.570325

Epoch: 5
Loss: 0.5609285213279097
ROC train: 0.602716	val: 0.562373	test: 0.533754
PRC train: 0.631006	val: 0.628252	test: 0.577791

Epoch: 6
Loss: 0.5511546668582231
ROC train: 0.621047	val: 0.575882	test: 0.540622
PRC train: 0.640964	val: 0.632475	test: 0.581654

Epoch: 7
Loss: 0.5409219684071178
ROC train: 0.635077	val: 0.589513	test: 0.550050
PRC train: 0.650028	val: 0.637745	test: 0.586781

Epoch: 8
Loss: 0.5383799779991237
ROC train: 0.648069	val: 0.600006	test: 0.558595
PRC train: 0.656100	val: 0.643924	test: 0.590415

Epoch: 9
Loss: 0.5279983894561824
ROC train: 0.658499	val: 0.603328	test: 0.560414
PRC train: 0.661957	val: 0.645134	test: 0.590613

Epoch: 10
Loss: 0.5236717264885015
ROC train: 0.669350	val: 0.605803	test: 0.562627
PRC train: 0.668226	val: 0.647349	test: 0.591824

Epoch: 11
Loss: 0.5157639737128348
ROC train: 0.680389	val: 0.611234	test: 0.566008
PRC train: 0.674280	val: 0.649610	test: 0.595111

Epoch: 12
Loss: 0.5040942329270603
ROC train: 0.689511	val: 0.610962	test: 0.567238
PRC train: 0.678771	val: 0.651465	test: 0.595524

Epoch: 13
Loss: 0.49584037932468805
ROC train: 0.695026	val: 0.608014	test: 0.565415
PRC train: 0.682556	val: 0.651680	test: 0.592362

Epoch: 14
Loss: 0.4957171638362028
ROC train: 0.702577	val: 0.608956	test: 0.567141
PRC train: 0.687417	val: 0.651341	test: 0.594812

Epoch: 15
Loss: 0.48756362311876555
ROC train: 0.711140	val: 0.615446	test: 0.572532
PRC train: 0.694051	val: 0.656045	test: 0.597141

Epoch: 16
Loss: 0.4891847581661105
ROC train: 0.716828	val: 0.620616	test: 0.577861
PRC train: 0.698122	val: 0.660869	test: 0.600120

Epoch: 17
Loss: 0.4742021006401722
ROC train: 0.721333	val: 0.624879	test: 0.579837
PRC train: 0.700997	val: 0.667709	test: 0.601019

Epoch: 18
Loss: 0.47767694676845907
ROC train: 0.731853	val: 0.626586	test: 0.587761
PRC train: 0.709689	val: 0.667585	test: 0.605800

Epoch: 19
Loss: 0.4733364074042443
ROC train: 0.730891	val: 0.623023	test: 0.594946
PRC train: 0.707192	val: 0.652997	test: 0.608958

Epoch: 20
Loss: 0.47010002214847824
ROC train: 0.735639	val: 0.623187	test: 0.595090
PRC train: 0.709713	val: 0.651855	test: 0.608642

Epoch: 21
Loss: 0.4683257726736991
ROC train: 0.749328	val: 0.623778	test: 0.589991
PRC train: 0.720299	val: 0.656844	test: 0.608440

Epoch: 22
Loss: 0.4680049374032738
ROC train: 0.747875	val: 0.617895	test: 0.584972
PRC train: 0.721564	val: 0.653881	test: 0.605209

Epoch: 23
Loss: 0.4679111471781479
ROC train: 0.753544	val: 0.619873	test: 0.587691
PRC train: 0.725372	val: 0.657751	test: 0.605910

Epoch: 24
Loss: 0.4596293628995757
ROC train: 0.762983	val: 0.618059	test: 0.589082
PRC train: 0.731618	val: 0.659414	test: 0.608344

Epoch: 25
Loss: 0.45286052473876287
ROC train: 0.765045	val: 0.611797	test: 0.583161
PRC train: 0.735228	val: 0.659142	test: 0.604411

Epoch: 26
Loss: 0.46183593039594356
ROC train: 0.767783	val: 0.609149	test: 0.590706
PRC train: 0.738520	val: 0.657739	test: 0.608401

Epoch: 27
Loss: 0.45540412675136643
ROC train: 0.770168	val: 0.614759	test: 0.597343
PRC train: 0.739691	val: 0.658702	test: 0.613114

Epoch: 28
Loss: 0.45443850591756496
ROC train: 0.775697	val: 0.618920	test: 0.594238
PRC train: 0.743560	val: 0.660887	test: 0.612426

Epoch: 29
Loss: 0.44168395621232687
ROC train: 0.778707	val: 0.622767	test: 0.595183
PRC train: 0.746596	val: 0.665447	test: 0.615557

Epoch: 30
Loss: 0.444512858312626
ROC train: 0.786079	val: 0.625906	test: 0.604106
PRC train: 0.750358	val: 0.667520	test: 0.616946

Epoch: 31
Loss: 0.4377835891327028
ROC train: 0.787506	val: 0.621564	test: 0.600754
PRC train: 0.752110	val: 0.663736	test: 0.611735

Epoch: 32
Loss: 0.4404037959328887
ROC train: 0.792326	val: 0.620350	test: 0.595972
PRC train: 0.756884	val: 0.661646	test: 0.612147

Epoch: 33
Loss: 0.4427252190475443Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/random/train_prop=0.6/sider_random_6_26-05_09-56-15  ]
[ Using Seed :  6  ]
[ Using device :  cuda:0  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
randomly split
Data(edge_attr=[38, 2], edge_index=[2, 38], id=[1], x=[18, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6816326374988477
ROC train: 0.538154	val: 0.532291	test: 0.517714
PRC train: 0.584666	val: 0.598344	test: 0.567392

Epoch: 2
Loss: 0.6383792272473402
ROC train: 0.555564	val: 0.539765	test: 0.521672
PRC train: 0.598766	val: 0.605414	test: 0.568687

Epoch: 3
Loss: 0.5954220215149288
ROC train: 0.569401	val: 0.542595	test: 0.525050
PRC train: 0.611831	val: 0.610795	test: 0.571933

Epoch: 4
Loss: 0.5718225283791897
ROC train: 0.580746	val: 0.548072	test: 0.528303
PRC train: 0.621235	val: 0.618076	test: 0.575373

Epoch: 5
Loss: 0.5736832732674648
ROC train: 0.600560	val: 0.565642	test: 0.534668
PRC train: 0.631654	val: 0.626220	test: 0.579255

Epoch: 6
Loss: 0.5461754279584865
ROC train: 0.626617	val: 0.589397	test: 0.543815
PRC train: 0.643492	val: 0.632745	test: 0.582713

Epoch: 7
Loss: 0.5520884875317188
ROC train: 0.637921	val: 0.591010	test: 0.544097
PRC train: 0.651326	val: 0.630481	test: 0.582469

Epoch: 8
Loss: 0.5307996200630711
ROC train: 0.650088	val: 0.597122	test: 0.555448
PRC train: 0.660084	val: 0.636102	test: 0.587062

Epoch: 9
Loss: 0.5179952627515007
ROC train: 0.659431	val: 0.603994	test: 0.564155
PRC train: 0.666043	val: 0.642412	test: 0.590126

Epoch: 10
Loss: 0.5206430409711202
ROC train: 0.669903	val: 0.609882	test: 0.569477
PRC train: 0.671423	val: 0.646761	test: 0.592466

Epoch: 11
Loss: 0.5086485854963712
ROC train: 0.680662	val: 0.616997	test: 0.572227
PRC train: 0.677019	val: 0.648113	test: 0.594546

Epoch: 12
Loss: 0.5023382909165287
ROC train: 0.684371	val: 0.616342	test: 0.569375
PRC train: 0.677637	val: 0.645682	test: 0.594858

Epoch: 13
Loss: 0.4960670997606708
ROC train: 0.691003	val: 0.615857	test: 0.570146
PRC train: 0.683765	val: 0.647692	test: 0.596132

Epoch: 14
Loss: 0.5005047293997763
ROC train: 0.696440	val: 0.618996	test: 0.572290
PRC train: 0.689331	val: 0.654146	test: 0.595792

Epoch: 15
Loss: 0.4911674566895256
ROC train: 0.703981	val: 0.615436	test: 0.575002
PRC train: 0.695255	val: 0.652170	test: 0.597327

Epoch: 16
Loss: 0.4840471691265822
ROC train: 0.710841	val: 0.615461	test: 0.584535
PRC train: 0.700626	val: 0.653959	test: 0.603358

Epoch: 17
Loss: 0.48420287602246026
ROC train: 0.722174	val: 0.622515	test: 0.593221
PRC train: 0.709500	val: 0.661013	test: 0.606394

Epoch: 18
Loss: 0.4767004427224126
ROC train: 0.731587	val: 0.626462	test: 0.593748
PRC train: 0.716354	val: 0.665274	test: 0.606297

Epoch: 19
Loss: 0.47182750878694113
ROC train: 0.735653	val: 0.626566	test: 0.592972
PRC train: 0.718685	val: 0.665492	test: 0.607421

Epoch: 20
Loss: 0.4694877660809251
ROC train: 0.739510	val: 0.631501	test: 0.594987
PRC train: 0.720234	val: 0.667000	test: 0.607062

Epoch: 21
Loss: 0.4662343699760828
ROC train: 0.742378	val: 0.632857	test: 0.588596
PRC train: 0.723332	val: 0.667531	test: 0.605263

Epoch: 22
Loss: 0.4674678524197264
ROC train: 0.743173	val: 0.627739	test: 0.578339
PRC train: 0.723602	val: 0.667020	test: 0.602089

Epoch: 23
Loss: 0.46576062969699505
ROC train: 0.747213	val: 0.627740	test: 0.576721
PRC train: 0.723956	val: 0.669240	test: 0.601935

Epoch: 24
Loss: 0.4547546809830706
ROC train: 0.753932	val: 0.632546	test: 0.582861
PRC train: 0.727921	val: 0.672633	test: 0.603077

Epoch: 25
Loss: 0.4657457672615467
ROC train: 0.758145	val: 0.630674	test: 0.583302
PRC train: 0.731410	val: 0.669070	test: 0.601268

Epoch: 26
Loss: 0.45518838976701526
ROC train: 0.760919	val: 0.632470	test: 0.588769
PRC train: 0.733723	val: 0.670944	test: 0.604883

Epoch: 27
Loss: 0.45367747803315084
ROC train: 0.759527	val: 0.628489	test: 0.586679
PRC train: 0.732030	val: 0.667141	test: 0.604709

Epoch: 28
Loss: 0.45949648184278286
ROC train: 0.768868	val: 0.624152	test: 0.585294
PRC train: 0.739434	val: 0.662388	test: 0.603723

Epoch: 29
Loss: 0.4478708981116507
ROC train: 0.777830	val: 0.619653	test: 0.582462
PRC train: 0.743970	val: 0.657505	test: 0.600999

Epoch: 30
Loss: 0.45231042045779835
ROC train: 0.781038	val: 0.614806	test: 0.580671
PRC train: 0.746309	val: 0.652021	test: 0.601838

Epoch: 31
Loss: 0.44097199118575753
ROC train: 0.782937	val: 0.617990	test: 0.579600
PRC train: 0.748953	val: 0.657114	test: 0.601826

Epoch: 32
Loss: 0.44846749375785233
ROC train: 0.785734	val: 0.623017	test: 0.581231
PRC train: 0.751919	val: 0.667326	test: 0.600961

Epoch: 33
Loss: 0.44065020169435853Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/random/train_prop=0.7/sider_random_6_26-05_09-56-15  ]
[ Using Seed :  6  ]
[ Using device :  cuda:1  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
randomly split
Data(edge_attr=[38, 2], edge_index=[2, 38], id=[1], x=[18, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6769078659037095
ROC train: 0.543594	val: 0.528099	test: 0.511667
PRC train: 0.587036	val: 0.610775	test: 0.551781

Epoch: 2
Loss: 0.6288207521294649
ROC train: 0.559089	val: 0.533899	test: 0.504309
PRC train: 0.603259	val: 0.610558	test: 0.551575

Epoch: 3
Loss: 0.5911346780076597
ROC train: 0.570692	val: 0.535149	test: 0.509718
PRC train: 0.614679	val: 0.615050	test: 0.556497

Epoch: 4
Loss: 0.5652902720132135
ROC train: 0.588378	val: 0.541889	test: 0.518907
PRC train: 0.625520	val: 0.617899	test: 0.559774

Epoch: 5
Loss: 0.5572862654565236
ROC train: 0.606831	val: 0.558013	test: 0.535861
PRC train: 0.633969	val: 0.622261	test: 0.565378

Epoch: 6
Loss: 0.5440915889683571
ROC train: 0.628895	val: 0.574659	test: 0.552777
PRC train: 0.646155	val: 0.628097	test: 0.576478

Epoch: 7
Loss: 0.5363723939302125
ROC train: 0.644655	val: 0.581659	test: 0.560281
PRC train: 0.655961	val: 0.633230	test: 0.579131

Epoch: 8
Loss: 0.5254479813448725
ROC train: 0.658590	val: 0.583439	test: 0.566026
PRC train: 0.664528	val: 0.637269	test: 0.582232

Epoch: 9
Loss: 0.516619930183574
ROC train: 0.672395	val: 0.587728	test: 0.573705
PRC train: 0.672867	val: 0.642235	test: 0.586247

Epoch: 10
Loss: 0.5132579649749452
ROC train: 0.685021	val: 0.592576	test: 0.580079
PRC train: 0.682021	val: 0.646076	test: 0.589973

Epoch: 11
Loss: 0.5054337147847591
ROC train: 0.693505	val: 0.592020	test: 0.581296
PRC train: 0.687966	val: 0.646578	test: 0.590186

Epoch: 12
Loss: 0.4987627990434359
ROC train: 0.696631	val: 0.591850	test: 0.578840
PRC train: 0.689070	val: 0.646536	test: 0.589388

Epoch: 13
Loss: 0.49264368930942065
ROC train: 0.704147	val: 0.596409	test: 0.575715
PRC train: 0.694283	val: 0.649712	test: 0.589020

Epoch: 14
Loss: 0.4868058351291471
ROC train: 0.712916	val: 0.601348	test: 0.574786
PRC train: 0.700958	val: 0.658620	test: 0.586819

Epoch: 15
Loss: 0.4852084663635293
ROC train: 0.717192	val: 0.599947	test: 0.570241
PRC train: 0.703460	val: 0.661437	test: 0.585855

Epoch: 16
Loss: 0.47874519317096065
ROC train: 0.725597	val: 0.602605	test: 0.575901
PRC train: 0.707962	val: 0.659305	test: 0.587595

Epoch: 17
Loss: 0.47628224428958454
ROC train: 0.729823	val: 0.598566	test: 0.575875
PRC train: 0.708212	val: 0.653904	test: 0.587573

Epoch: 18
Loss: 0.47091322046676853
ROC train: 0.737683	val: 0.601808	test: 0.581125
PRC train: 0.714060	val: 0.662786	test: 0.591504

Epoch: 19
Loss: 0.47147047438190876
ROC train: 0.741043	val: 0.601685	test: 0.580883
PRC train: 0.717131	val: 0.670940	test: 0.595218

Epoch: 20
Loss: 0.46630511001795133
ROC train: 0.746501	val: 0.607545	test: 0.587510
PRC train: 0.719663	val: 0.674936	test: 0.595924

Epoch: 21
Loss: 0.4632622114581081
ROC train: 0.752044	val: 0.610541	test: 0.589086
PRC train: 0.723342	val: 0.669926	test: 0.593546

Epoch: 22
Loss: 0.4597780371572828
ROC train: 0.755976	val: 0.605673	test: 0.589902
PRC train: 0.728283	val: 0.671335	test: 0.597183

Epoch: 23
Loss: 0.4571539502043467
ROC train: 0.758922	val: 0.602124	test: 0.589421
PRC train: 0.732305	val: 0.671153	test: 0.598005

Epoch: 24
Loss: 0.45547264535718396
ROC train: 0.758961	val: 0.602806	test: 0.585427
PRC train: 0.731527	val: 0.670099	test: 0.599151

Epoch: 25
Loss: 0.45780226085516923
ROC train: 0.771125	val: 0.615429	test: 0.592450
PRC train: 0.738786	val: 0.678923	test: 0.602694

Epoch: 26
Loss: 0.453258242847514
ROC train: 0.779195	val: 0.620072	test: 0.592394
PRC train: 0.744909	val: 0.680553	test: 0.602298

Epoch: 27
Loss: 0.4484608164124047
ROC train: 0.780268	val: 0.613419	test: 0.590971
PRC train: 0.746047	val: 0.676464	test: 0.602984

Epoch: 28
Loss: 0.4503116779401842
ROC train: 0.782441	val: 0.613321	test: 0.600125
PRC train: 0.747178	val: 0.678108	test: 0.604748

Epoch: 29
Loss: 0.44788109475020865
ROC train: 0.786425	val: 0.617500	test: 0.598270
PRC train: 0.751997	val: 0.677472	test: 0.602843

Epoch: 30
Loss: 0.4421671088742622
ROC train: 0.790668	val: 0.617179	test: 0.596396
PRC train: 0.756141	val: 0.675876	test: 0.603873

Epoch: 31
Loss: 0.4427263477888653
ROC train: 0.793317	val: 0.612722	test: 0.592935
PRC train: 0.758232	val: 0.671494	test: 0.602106

Epoch: 32
Loss: 0.44387802498795625
ROC train: 0.796360	val: 0.609319	test: 0.600810
PRC train: 0.760325	val: 0.672731	test: 0.604578

Epoch: 33
Loss: 0.44462342685034184Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/random/train_prop=0.7/sider_random_4_26-05_09-56-15  ]
[ Using Seed :  4  ]
[ Using device :  cuda:1  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
randomly split
Data(edge_attr=[38, 2], edge_index=[2, 38], id=[1], x=[18, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6890756163558474
ROC train: 0.536173	val: 0.513376	test: 0.526189
PRC train: 0.585341	val: 0.608272	test: 0.563525

Epoch: 2
Loss: 0.6425046883486156
ROC train: 0.555200	val: 0.530503	test: 0.534981
PRC train: 0.598938	val: 0.612557	test: 0.568881

Epoch: 3
Loss: 0.6030777625285472
ROC train: 0.561312	val: 0.532369	test: 0.530476
PRC train: 0.606401	val: 0.612669	test: 0.566280

Epoch: 4
Loss: 0.5755038332253107
ROC train: 0.574726	val: 0.540907	test: 0.531990
PRC train: 0.615959	val: 0.617336	test: 0.568049

Epoch: 5
Loss: 0.5606324652327315
ROC train: 0.597748	val: 0.554123	test: 0.545034
PRC train: 0.629246	val: 0.625166	test: 0.574349

Epoch: 6
Loss: 0.5478545923231621
ROC train: 0.620786	val: 0.573314	test: 0.558579
PRC train: 0.641096	val: 0.637984	test: 0.583227

Epoch: 7
Loss: 0.5366632948831076
ROC train: 0.633460	val: 0.580400	test: 0.569107
PRC train: 0.648280	val: 0.642586	test: 0.589286

Epoch: 8
Loss: 0.5296275560874364
ROC train: 0.643585	val: 0.583840	test: 0.575980
PRC train: 0.654395	val: 0.643277	test: 0.593624

Epoch: 9
Loss: 0.5202970381017683
ROC train: 0.656366	val: 0.590742	test: 0.579973
PRC train: 0.661442	val: 0.646724	test: 0.596331

Epoch: 10
Loss: 0.514724345903377
ROC train: 0.668196	val: 0.592955	test: 0.582562
PRC train: 0.668762	val: 0.649917	test: 0.597141

Epoch: 11
Loss: 0.5069850862012047
ROC train: 0.682256	val: 0.596432	test: 0.582082
PRC train: 0.675980	val: 0.654175	test: 0.596331

Epoch: 12
Loss: 0.5011492584293724
ROC train: 0.694993	val: 0.599271	test: 0.584399
PRC train: 0.683342	val: 0.658732	test: 0.598870

Epoch: 13
Loss: 0.4961543010044439
ROC train: 0.698520	val: 0.598965	test: 0.582393
PRC train: 0.686019	val: 0.654252	test: 0.597692

Epoch: 14
Loss: 0.49014811657982
ROC train: 0.707801	val: 0.603104	test: 0.582308
PRC train: 0.692545	val: 0.657352	test: 0.598067

Epoch: 15
Loss: 0.48554840317042103
ROC train: 0.716291	val: 0.601751	test: 0.581741
PRC train: 0.698796	val: 0.660271	test: 0.597785

Epoch: 16
Loss: 0.4790973012948436
ROC train: 0.720547	val: 0.599713	test: 0.584739
PRC train: 0.702307	val: 0.656903	test: 0.597523

Epoch: 17
Loss: 0.47394564785545884
ROC train: 0.724935	val: 0.597675	test: 0.591177
PRC train: 0.705972	val: 0.656883	test: 0.598190

Epoch: 18
Loss: 0.4728120893908609
ROC train: 0.734674	val: 0.603026	test: 0.594403
PRC train: 0.712862	val: 0.661953	test: 0.600042

Epoch: 19
Loss: 0.47237483298963884
ROC train: 0.742258	val: 0.602479	test: 0.587863
PRC train: 0.718314	val: 0.660106	test: 0.597240

Epoch: 20
Loss: 0.4677789257055797
ROC train: 0.740716	val: 0.594409	test: 0.583151
PRC train: 0.719348	val: 0.655615	test: 0.596755

Epoch: 21
Loss: 0.46195646230269655
ROC train: 0.744483	val: 0.599891	test: 0.588447
PRC train: 0.721420	val: 0.658438	test: 0.598887

Epoch: 22
Loss: 0.4667582747518258
ROC train: 0.751279	val: 0.599463	test: 0.590320
PRC train: 0.724883	val: 0.657807	test: 0.598624

Epoch: 23
Loss: 0.4628840773466589
ROC train: 0.760282	val: 0.597708	test: 0.594581
PRC train: 0.728660	val: 0.659044	test: 0.599701

Epoch: 24
Loss: 0.455901199719693
ROC train: 0.765021	val: 0.598765	test: 0.594866
PRC train: 0.731942	val: 0.663985	test: 0.600553

Epoch: 25
Loss: 0.45313724710282133
ROC train: 0.770151	val: 0.602710	test: 0.592944
PRC train: 0.736503	val: 0.666023	test: 0.598642

Epoch: 26
Loss: 0.4502750323742237
ROC train: 0.769380	val: 0.601079	test: 0.590019
PRC train: 0.736728	val: 0.661773	test: 0.596949

Epoch: 27
Loss: 0.450161306095072
ROC train: 0.774579	val: 0.596749	test: 0.590187
PRC train: 0.739858	val: 0.660415	test: 0.594553

Epoch: 28
Loss: 0.4482062733800115
ROC train: 0.776303	val: 0.593804	test: 0.589698
PRC train: 0.741200	val: 0.658254	test: 0.596803

Epoch: 29
Loss: 0.4463259932108099
ROC train: 0.781660	val: 0.596343	test: 0.586142
PRC train: 0.744178	val: 0.659853	test: 0.595330

Epoch: 30
Loss: 0.44497374217509905
ROC train: 0.784504	val: 0.606052	test: 0.598755
PRC train: 0.748054	val: 0.666747	test: 0.603776

Epoch: 31
Loss: 0.44336473734679566
ROC train: 0.790463	val: 0.611622	test: 0.604930
PRC train: 0.752596	val: 0.673627	test: 0.612976

Epoch: 32
Loss: 0.43840130440581787
ROC train: 0.794509	val: 0.612394	test: 0.604579
PRC train: 0.757134	val: 0.669665	test: 0.614272

Epoch: 33
Loss: 0.43729662235119526
ROC train: 0.797424	val: 0.611340	test: 0.602414Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/random/train_prop=0.7/sider_random_5_26-05_09-56-15  ]
[ Using Seed :  5  ]
[ Using device :  cuda:1  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
randomly split
Data(edge_attr=[38, 2], edge_index=[2, 38], id=[1], x=[18, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6902361535649
ROC train: 0.527287	val: 0.504796	test: 0.506394
PRC train: 0.583425	val: 0.608263	test: 0.548379

Epoch: 2
Loss: 0.6405833952926507
ROC train: 0.548532	val: 0.519804	test: 0.510678
PRC train: 0.600568	val: 0.608290	test: 0.558328

Epoch: 3
Loss: 0.6001865410659264
ROC train: 0.566767	val: 0.526017	test: 0.518218
PRC train: 0.612025	val: 0.612751	test: 0.560600

Epoch: 4
Loss: 0.5702614585932733
ROC train: 0.588535	val: 0.532880	test: 0.530987
PRC train: 0.623733	val: 0.618777	test: 0.565978

Epoch: 5
Loss: 0.5573441831042953
ROC train: 0.613411	val: 0.556956	test: 0.546965
PRC train: 0.635948	val: 0.632244	test: 0.574732

Epoch: 6
Loss: 0.549500065337893
ROC train: 0.628907	val: 0.566252	test: 0.554862
PRC train: 0.644444	val: 0.634987	test: 0.578965

Epoch: 7
Loss: 0.5391284402444331
ROC train: 0.636941	val: 0.565432	test: 0.558503
PRC train: 0.649774	val: 0.632705	test: 0.580099

Epoch: 8
Loss: 0.5300412718557669
ROC train: 0.649241	val: 0.574615	test: 0.569309
PRC train: 0.656994	val: 0.637662	test: 0.584943

Epoch: 9
Loss: 0.5224027705001919
ROC train: 0.665632	val: 0.585917	test: 0.581435
PRC train: 0.667257	val: 0.644163	test: 0.591420

Epoch: 10
Loss: 0.5132478765293299
ROC train: 0.675163	val: 0.585043	test: 0.585155
PRC train: 0.672604	val: 0.645060	test: 0.590662

Epoch: 11
Loss: 0.5076393822590596
ROC train: 0.681921	val: 0.587174	test: 0.586653
PRC train: 0.676403	val: 0.647585	test: 0.593768

Epoch: 12
Loss: 0.5032817158832497
ROC train: 0.694667	val: 0.594083	test: 0.588463
PRC train: 0.683948	val: 0.652905	test: 0.595789

Epoch: 13
Loss: 0.4974603220352767
ROC train: 0.702429	val: 0.593626	test: 0.586011
PRC train: 0.686281	val: 0.652527	test: 0.595519

Epoch: 14
Loss: 0.48896592672004546
ROC train: 0.708737	val: 0.598999	test: 0.587170
PRC train: 0.692054	val: 0.662158	test: 0.594372

Epoch: 15
Loss: 0.48322606648242933
ROC train: 0.715637	val: 0.593713	test: 0.589067
PRC train: 0.697287	val: 0.661846	test: 0.596384

Epoch: 16
Loss: 0.4834501806493565
ROC train: 0.722000	val: 0.586659	test: 0.584682
PRC train: 0.702725	val: 0.653856	test: 0.594747

Epoch: 17
Loss: 0.47695924837622905
ROC train: 0.727659	val: 0.584653	test: 0.590565
PRC train: 0.706452	val: 0.650308	test: 0.599599

Epoch: 18
Loss: 0.4730469595691217
ROC train: 0.731545	val: 0.588315	test: 0.589924
PRC train: 0.711348	val: 0.655462	test: 0.600241

Epoch: 19
Loss: 0.46735272636391745
ROC train: 0.737339	val: 0.594838	test: 0.590966
PRC train: 0.716578	val: 0.662370	test: 0.603437

Epoch: 20
Loss: 0.4675449252475625
ROC train: 0.745674	val: 0.595619	test: 0.593379
PRC train: 0.721356	val: 0.661038	test: 0.606162

Epoch: 21
Loss: 0.464652413971213
ROC train: 0.752523	val: 0.597794	test: 0.596445
PRC train: 0.726178	val: 0.661764	test: 0.607577

Epoch: 22
Loss: 0.4582810614177355
ROC train: 0.754417	val: 0.592748	test: 0.600768
PRC train: 0.728623	val: 0.656438	test: 0.607148

Epoch: 23
Loss: 0.46007698849849277
ROC train: 0.756850	val: 0.595912	test: 0.600612
PRC train: 0.730896	val: 0.656653	test: 0.606541

Epoch: 24
Loss: 0.45189879757798956
ROC train: 0.759910	val: 0.593635	test: 0.597342
PRC train: 0.731267	val: 0.658135	test: 0.606061

Epoch: 25
Loss: 0.4538770014005995
ROC train: 0.767993	val: 0.598940	test: 0.603599
PRC train: 0.735277	val: 0.668669	test: 0.609421

Epoch: 26
Loss: 0.4517424481480702
ROC train: 0.774446	val: 0.603921	test: 0.611314
PRC train: 0.739397	val: 0.675635	test: 0.613978

Epoch: 27
Loss: 0.4519024341098608
ROC train: 0.772396	val: 0.602963	test: 0.608212
PRC train: 0.739248	val: 0.673174	test: 0.613081

Epoch: 28
Loss: 0.4479892345668541
ROC train: 0.776253	val: 0.592663	test: 0.603860
PRC train: 0.741888	val: 0.664683	test: 0.611423

Epoch: 29
Loss: 0.4469790310968773
ROC train: 0.782677	val: 0.594341	test: 0.603508
PRC train: 0.747460	val: 0.663757	test: 0.611148

Epoch: 30
Loss: 0.4426890499053978
ROC train: 0.787524	val: 0.604540	test: 0.608660
PRC train: 0.752455	val: 0.679900	test: 0.613735

Epoch: 31
Loss: 0.4387489957521568
ROC train: 0.784141	val: 0.607733	test: 0.605150
PRC train: 0.750961	val: 0.682361	test: 0.613842

Epoch: 32
Loss: 0.4412630606462088
ROC train: 0.787018	val: 0.607544	test: 0.590365
PRC train: 0.755153	val: 0.680389	test: 0.610303

Epoch: 33
Loss: 0.4365297239191117
ROC train: 0.797844	val: 0.613053	test: 0.602318Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/random/train_prop=0.8/sider_random_6_26-05_09-56-15  ]
[ Using Seed :  6  ]
[ Using device :  cuda:2  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
randomly split
Data(edge_attr=[38, 2], edge_index=[2, 38], id=[1], x=[18, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6709023503880479
ROC train: 0.542720	val: 0.511258	test: 0.520170
PRC train: 0.590428	val: 0.588604	test: 0.562164

Epoch: 2
Loss: 0.6129930102142155
ROC train: 0.554868	val: 0.511529	test: 0.517316
PRC train: 0.605097	val: 0.592648	test: 0.562989

Epoch: 3
Loss: 0.5859458685118571
ROC train: 0.571634	val: 0.523561	test: 0.522490
PRC train: 0.617581	val: 0.597783	test: 0.567605

Epoch: 4
Loss: 0.5664321107452339
ROC train: 0.604680	val: 0.550220	test: 0.538071
PRC train: 0.632982	val: 0.607163	test: 0.576640

Epoch: 5
Loss: 0.5434131598033111
ROC train: 0.623711	val: 0.559838	test: 0.546262
PRC train: 0.643932	val: 0.613907	test: 0.580205

Epoch: 6
Loss: 0.5329109426767029
ROC train: 0.633646	val: 0.558876	test: 0.552366
PRC train: 0.652551	val: 0.613608	test: 0.582219

Epoch: 7
Loss: 0.5288995698997674
ROC train: 0.650886	val: 0.564295	test: 0.555890
PRC train: 0.664014	val: 0.614290	test: 0.585316

Epoch: 8
Loss: 0.5172370116478033
ROC train: 0.667559	val: 0.574992	test: 0.562363
PRC train: 0.673324	val: 0.616624	test: 0.591921

Epoch: 9
Loss: 0.5080317279870361
ROC train: 0.678165	val: 0.573100	test: 0.567652
PRC train: 0.679598	val: 0.611847	test: 0.588873

Epoch: 10
Loss: 0.5038975716058622
ROC train: 0.685729	val: 0.572700	test: 0.570651
PRC train: 0.686645	val: 0.616877	test: 0.592504

Epoch: 11
Loss: 0.4942492592532153
ROC train: 0.695400	val: 0.570667	test: 0.575255
PRC train: 0.694540	val: 0.616971	test: 0.593350

Epoch: 12
Loss: 0.4848198465114624
ROC train: 0.703722	val: 0.586781	test: 0.578435
PRC train: 0.698746	val: 0.620627	test: 0.592678

Epoch: 13
Loss: 0.4875581035650868
ROC train: 0.710428	val: 0.595416	test: 0.580432
PRC train: 0.704819	val: 0.623124	test: 0.594689

Epoch: 14
Loss: 0.48200286732765363
ROC train: 0.712704	val: 0.594514	test: 0.583679
PRC train: 0.707864	val: 0.623659	test: 0.599483

Epoch: 15
Loss: 0.47455118362465465
ROC train: 0.717153	val: 0.598724	test: 0.588466
PRC train: 0.711220	val: 0.629770	test: 0.602674

Epoch: 16
Loss: 0.47262205497639387
ROC train: 0.728897	val: 0.606396	test: 0.578810
PRC train: 0.717412	val: 0.628775	test: 0.601019

Epoch: 17
Loss: 0.4669471315257815
ROC train: 0.735599	val: 0.609900	test: 0.574449
PRC train: 0.720894	val: 0.627348	test: 0.599740

Epoch: 18
Loss: 0.46658093612199175
ROC train: 0.739504	val: 0.602464	test: 0.571732
PRC train: 0.722350	val: 0.622438	test: 0.594230

Epoch: 19
Loss: 0.4671468797540264
ROC train: 0.741228	val: 0.612063	test: 0.572657
PRC train: 0.723600	val: 0.635779	test: 0.597345

Epoch: 20
Loss: 0.46320877568529745
ROC train: 0.747946	val: 0.612221	test: 0.587276
PRC train: 0.730784	val: 0.635806	test: 0.604426

Epoch: 21
Loss: 0.4612796776891533
ROC train: 0.749596	val: 0.609170	test: 0.590524
PRC train: 0.730620	val: 0.634252	test: 0.611837

Epoch: 22
Loss: 0.458333592406707
ROC train: 0.748227	val: 0.604517	test: 0.583025
PRC train: 0.728607	val: 0.638497	test: 0.604778

Epoch: 23
Loss: 0.46154215663307374
ROC train: 0.763326	val: 0.619220	test: 0.592945
PRC train: 0.740830	val: 0.643178	test: 0.604186

Epoch: 24
Loss: 0.4560617731011639
ROC train: 0.761100	val: 0.609833	test: 0.595950
PRC train: 0.739121	val: 0.634720	test: 0.603960

Epoch: 25
Loss: 0.45500045105880116
ROC train: 0.766584	val: 0.613822	test: 0.589250
PRC train: 0.742772	val: 0.638974	test: 0.600634

Epoch: 26
Loss: 0.45262703026964185
ROC train: 0.770353	val: 0.620839	test: 0.573016
PRC train: 0.744279	val: 0.642930	test: 0.587548

Epoch: 27
Loss: 0.4458433421800974
ROC train: 0.772876	val: 0.615306	test: 0.574858
PRC train: 0.746558	val: 0.645537	test: 0.589980

Epoch: 28
Loss: 0.44490009765424715
ROC train: 0.777226	val: 0.615896	test: 0.584723
PRC train: 0.750180	val: 0.646935	test: 0.596891

Epoch: 29
Loss: 0.4453996498759777
ROC train: 0.783379	val: 0.616432	test: 0.589617
PRC train: 0.755405	val: 0.651519	test: 0.600540

Epoch: 30
Loss: 0.44117393836748614
ROC train: 0.787503	val: 0.616406	test: 0.584178
PRC train: 0.760493	val: 0.657711	test: 0.598192

Epoch: 31
Loss: 0.4420814112249799
ROC train: 0.788998	val: 0.612880	test: 0.579095
PRC train: 0.761848	val: 0.653855	test: 0.592093

Epoch: 32
Loss: 0.4449015005864977
ROC train: 0.797238	val: 0.612003	test: 0.579960
PRC train: 0.764655	val: 0.645495	test: 0.592245

Epoch: 33
Loss: 0.43854860901304793Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/random/train_prop=0.8/sider_random_4_26-05_09-56-15  ]
[ Using Seed :  4  ]
[ Using device :  cuda:2  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
randomly split
Data(edge_attr=[38, 2], edge_index=[2, 38], id=[1], x=[18, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6847621243109965
ROC train: 0.537416	val: 0.509763	test: 0.525839
PRC train: 0.590829	val: 0.590403	test: 0.561822

Epoch: 2
Loss: 0.6315058004856968
ROC train: 0.556924	val: 0.525940	test: 0.527683
PRC train: 0.604983	val: 0.597244	test: 0.568427

Epoch: 3
Loss: 0.5830974866341202
ROC train: 0.571026	val: 0.534041	test: 0.522270
PRC train: 0.616060	val: 0.600299	test: 0.566437

Epoch: 4
Loss: 0.5646465443518265
ROC train: 0.596705	val: 0.546621	test: 0.526215
PRC train: 0.630119	val: 0.605282	test: 0.570916

Epoch: 5
Loss: 0.5474382061018797
ROC train: 0.622734	val: 0.567442	test: 0.550466
PRC train: 0.643141	val: 0.615938	test: 0.586601

Epoch: 6
Loss: 0.538818039584935
ROC train: 0.636196	val: 0.564992	test: 0.559957
PRC train: 0.652457	val: 0.615372	test: 0.589711

Epoch: 7
Loss: 0.5294107866977162
ROC train: 0.650879	val: 0.577022	test: 0.566595
PRC train: 0.662442	val: 0.621595	test: 0.591393

Epoch: 8
Loss: 0.5128549943624865
ROC train: 0.661479	val: 0.587739	test: 0.563908
PRC train: 0.668243	val: 0.626470	test: 0.587470

Epoch: 9
Loss: 0.5083135953173616
ROC train: 0.674296	val: 0.586152	test: 0.566529
PRC train: 0.674892	val: 0.624371	test: 0.590056

Epoch: 10
Loss: 0.5009161871130269
ROC train: 0.686541	val: 0.582138	test: 0.570620
PRC train: 0.683330	val: 0.623052	test: 0.591644

Epoch: 11
Loss: 0.49657068805988513
ROC train: 0.691607	val: 0.584741	test: 0.572864
PRC train: 0.688421	val: 0.624386	test: 0.592875

Epoch: 12
Loss: 0.48972902526090545
ROC train: 0.699350	val: 0.581930	test: 0.586424
PRC train: 0.695942	val: 0.623468	test: 0.598708

Epoch: 13
Loss: 0.4815817373754895
ROC train: 0.705537	val: 0.590267	test: 0.589881
PRC train: 0.701180	val: 0.629041	test: 0.600588

Epoch: 14
Loss: 0.47893004715585696
ROC train: 0.710711	val: 0.604250	test: 0.584152
PRC train: 0.705920	val: 0.633601	test: 0.599857

Epoch: 15
Loss: 0.4781851456349199
ROC train: 0.714230	val: 0.601468	test: 0.585232
PRC train: 0.707025	val: 0.630367	test: 0.604307

Epoch: 16
Loss: 0.47815876603884855
ROC train: 0.721521	val: 0.600414	test: 0.596708
PRC train: 0.705348	val: 0.623603	test: 0.610582

Epoch: 17
Loss: 0.4736542770752056
ROC train: 0.730459	val: 0.603503	test: 0.602592
PRC train: 0.718070	val: 0.628906	test: 0.612276

Epoch: 18
Loss: 0.467685245206488
ROC train: 0.734098	val: 0.596901	test: 0.593831
PRC train: 0.719421	val: 0.634388	test: 0.609818

Epoch: 19
Loss: 0.46684007606787015
ROC train: 0.738460	val: 0.617337	test: 0.594322
PRC train: 0.722460	val: 0.638847	test: 0.604172

Epoch: 20
Loss: 0.468889725097847
ROC train: 0.740624	val: 0.630239	test: 0.596333
PRC train: 0.725456	val: 0.650343	test: 0.604583

Epoch: 21
Loss: 0.46045846955932646
ROC train: 0.748179	val: 0.619522	test: 0.595041
PRC train: 0.730370	val: 0.645594	test: 0.609632

Epoch: 22
Loss: 0.461687614113062
ROC train: 0.753249	val: 0.614140	test: 0.592903
PRC train: 0.734108	val: 0.642769	test: 0.610294

Epoch: 23
Loss: 0.45907943634852344
ROC train: 0.756635	val: 0.611548	test: 0.589829
PRC train: 0.735527	val: 0.643015	test: 0.603807

Epoch: 24
Loss: 0.4553904642927257
ROC train: 0.762515	val: 0.615490	test: 0.593024
PRC train: 0.739105	val: 0.639927	test: 0.607325

Epoch: 25
Loss: 0.4556307365364538
ROC train: 0.765717	val: 0.611400	test: 0.587878
PRC train: 0.743310	val: 0.632796	test: 0.605809

Epoch: 26
Loss: 0.4490993776072652
ROC train: 0.769407	val: 0.607807	test: 0.591362
PRC train: 0.747316	val: 0.631332	test: 0.610822

Epoch: 27
Loss: 0.4478966427242791
ROC train: 0.773768	val: 0.616538	test: 0.602450
PRC train: 0.748419	val: 0.639849	test: 0.620599

Epoch: 28
Loss: 0.4474933071883499
ROC train: 0.776565	val: 0.617137	test: 0.605439
PRC train: 0.750194	val: 0.649573	test: 0.620258

Epoch: 29
Loss: 0.4437108470028507
ROC train: 0.779653	val: 0.618032	test: 0.610735
PRC train: 0.752183	val: 0.651153	test: 0.620021

Epoch: 30
Loss: 0.44852286207086367
ROC train: 0.785828	val: 0.622336	test: 0.610511
PRC train: 0.755787	val: 0.650929	test: 0.618633

Epoch: 31
Loss: 0.44099467847155144
ROC train: 0.790317	val: 0.627655	test: 0.617924
PRC train: 0.757606	val: 0.658916	test: 0.625442

Epoch: 32
Loss: 0.4454700276182465
ROC train: 0.794297	val: 0.623057	test: 0.612616
PRC train: 0.760399	val: 0.661574	test: 0.625913

Epoch: 33
Loss: 0.43709785243455535Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/random/train_prop=0.8/sider_random_5_26-05_09-56-15  ]
[ Using Seed :  5  ]
[ Using device :  cuda:2  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
randomly split
Data(edge_attr=[38, 2], edge_index=[2, 38], id=[1], x=[18, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.683882145586555
ROC train: 0.529324	val: 0.497212	test: 0.506754
PRC train: 0.589578	val: 0.575907	test: 0.561418

Epoch: 2
Loss: 0.6229789769481888
ROC train: 0.550483	val: 0.505865	test: 0.505788
PRC train: 0.605755	val: 0.591448	test: 0.555863

Epoch: 3
Loss: 0.5869371600008871
ROC train: 0.568890	val: 0.521291	test: 0.507167
PRC train: 0.616641	val: 0.597915	test: 0.556536

Epoch: 4
Loss: 0.5637955466771591
ROC train: 0.600022	val: 0.548547	test: 0.520092
PRC train: 0.631972	val: 0.605455	test: 0.564947

Epoch: 5
Loss: 0.5655211683210076
ROC train: 0.619734	val: 0.557642	test: 0.534179
PRC train: 0.642147	val: 0.611048	test: 0.572177

Epoch: 6
Loss: 0.5345077577566053
ROC train: 0.631753	val: 0.557821	test: 0.542901
PRC train: 0.649677	val: 0.609800	test: 0.577491

Epoch: 7
Loss: 0.5282646803892168
ROC train: 0.642671	val: 0.554651	test: 0.554906
PRC train: 0.655812	val: 0.610516	test: 0.583407

Epoch: 8
Loss: 0.5178860049095053
ROC train: 0.657607	val: 0.564352	test: 0.560950
PRC train: 0.665659	val: 0.611855	test: 0.585221

Epoch: 9
Loss: 0.5114018361350432
ROC train: 0.672205	val: 0.582508	test: 0.561310
PRC train: 0.676508	val: 0.622868	test: 0.584667

Epoch: 10
Loss: 0.5078670434121942
ROC train: 0.678910	val: 0.588088	test: 0.567855
PRC train: 0.679647	val: 0.619382	test: 0.588401

Epoch: 11
Loss: 0.5005708958091482
ROC train: 0.685321	val: 0.580560	test: 0.567729
PRC train: 0.685277	val: 0.619183	test: 0.589171

Epoch: 12
Loss: 0.4926416596956158
ROC train: 0.693705	val: 0.584583	test: 0.571430
PRC train: 0.689632	val: 0.619039	test: 0.589976

Epoch: 13
Loss: 0.4872392905422226
ROC train: 0.703622	val: 0.596712	test: 0.580730
PRC train: 0.695897	val: 0.624620	test: 0.597476

Epoch: 14
Loss: 0.48487951352242753
ROC train: 0.708612	val: 0.590537	test: 0.577808
PRC train: 0.699399	val: 0.622174	test: 0.595283

Epoch: 15
Loss: 0.478021299082975
ROC train: 0.713322	val: 0.595523	test: 0.576515
PRC train: 0.703473	val: 0.624450	test: 0.593418

Epoch: 16
Loss: 0.4724574689766115
ROC train: 0.719148	val: 0.606329	test: 0.584640
PRC train: 0.707188	val: 0.631677	test: 0.597380

Epoch: 17
Loss: 0.4694933120757304
ROC train: 0.723526	val: 0.607464	test: 0.590469
PRC train: 0.710927	val: 0.635758	test: 0.599337

Epoch: 18
Loss: 0.4700130475165126
ROC train: 0.728045	val: 0.595238	test: 0.585678
PRC train: 0.714863	val: 0.626545	test: 0.599144

Epoch: 19
Loss: 0.4677784819242744
ROC train: 0.731835	val: 0.601105	test: 0.581590
PRC train: 0.718246	val: 0.630333	test: 0.601199

Epoch: 20
Loss: 0.46511553923184457
ROC train: 0.738620	val: 0.612269	test: 0.578303
PRC train: 0.720760	val: 0.633924	test: 0.601357

Epoch: 21
Loss: 0.46174720611143016
ROC train: 0.740338	val: 0.611743	test: 0.586744
PRC train: 0.722048	val: 0.631154	test: 0.601317

Epoch: 22
Loss: 0.4600635004550858
ROC train: 0.745246	val: 0.608346	test: 0.590503
PRC train: 0.725287	val: 0.629749	test: 0.602389

Epoch: 23
Loss: 0.4570104313106965
ROC train: 0.749991	val: 0.603194	test: 0.580690
PRC train: 0.729661	val: 0.626835	test: 0.600743

Epoch: 24
Loss: 0.4581699419148574
ROC train: 0.754596	val: 0.606941	test: 0.597910
PRC train: 0.733714	val: 0.637789	test: 0.611601

Epoch: 25
Loss: 0.45231349459006476
ROC train: 0.761303	val: 0.620101	test: 0.603187
PRC train: 0.737393	val: 0.648540	test: 0.622184

Epoch: 26
Loss: 0.4504928722991387
ROC train: 0.764548	val: 0.604689	test: 0.592908
PRC train: 0.739961	val: 0.637643	test: 0.618626

Epoch: 27
Loss: 0.4525056268946628
ROC train: 0.764849	val: 0.601842	test: 0.589463
PRC train: 0.739595	val: 0.628782	test: 0.615927

Epoch: 28
Loss: 0.4462322436656323
ROC train: 0.773976	val: 0.606154	test: 0.588929
PRC train: 0.747098	val: 0.631530	test: 0.611469

Epoch: 29
Loss: 0.4467650525553741
ROC train: 0.773671	val: 0.606544	test: 0.582701
PRC train: 0.748347	val: 0.639273	test: 0.608106

Epoch: 30
Loss: 0.4462213681824284
ROC train: 0.777749	val: 0.602433	test: 0.598291
PRC train: 0.749587	val: 0.636044	test: 0.616049

Epoch: 31
Loss: 0.4388690776296711
ROC train: 0.782655	val: 0.607962	test: 0.596127
PRC train: 0.752930	val: 0.634748	test: 0.616872

Epoch: 32
Loss: 0.44276878588137664
ROC train: 0.785362	val: 0.613350	test: 0.589450
PRC train: 0.756998	val: 0.641693	test: 0.614045

Epoch: 33
Loss: 0.4375262359439199
ROC train: 0.786992	val: 0.623697	test: 0.588513
ROC train: 0.798551	val: 0.627215	test: 0.597210
PRC train: 0.763066	val: 0.676460	test: 0.613651

Epoch: 34
Loss: 0.44045553381451963
ROC train: 0.801740	val: 0.635803	test: 0.609302
PRC train: 0.763877	val: 0.682025	test: 0.618884

Epoch: 35
Loss: 0.44249283535600614
ROC train: 0.790286	val: 0.640670	test: 0.616656
PRC train: 0.754083	val: 0.685558	test: 0.622601

Epoch: 36
Loss: 0.4430026996496047
ROC train: 0.800677	val: 0.637486	test: 0.611737
PRC train: 0.764560	val: 0.680464	test: 0.621039

Epoch: 37
Loss: 0.43899113991474475
ROC train: 0.806269	val: 0.632046	test: 0.605066
PRC train: 0.772192	val: 0.672178	test: 0.614772

Epoch: 38
Loss: 0.4331994641118709
ROC train: 0.802187	val: 0.618531	test: 0.595792
PRC train: 0.769625	val: 0.663791	test: 0.608003

Epoch: 39
Loss: 0.43542331291657177
ROC train: 0.803372	val: 0.616891	test: 0.590520
PRC train: 0.767697	val: 0.656200	test: 0.602726

Epoch: 40
Loss: 0.4297433393530077
ROC train: 0.805570	val: 0.621790	test: 0.590477
PRC train: 0.768927	val: 0.660935	test: 0.603536

Epoch: 41
Loss: 0.43199872111326315
ROC train: 0.812534	val: 0.623490	test: 0.599553
PRC train: 0.769486	val: 0.679659	test: 0.612016

Epoch: 42
Loss: 0.42624736619012504
ROC train: 0.817796	val: 0.630878	test: 0.602926
PRC train: 0.780124	val: 0.678356	test: 0.616758

Epoch: 43
Loss: 0.43179255108959813
ROC train: 0.818161	val: 0.630224	test: 0.597322
PRC train: 0.784315	val: 0.672392	test: 0.612481

Epoch: 44
Loss: 0.4286870133549707
ROC train: 0.818304	val: 0.626955	test: 0.597469
PRC train: 0.783965	val: 0.669537	test: 0.607865

Epoch: 45
Loss: 0.42742284306548806
ROC train: 0.822248	val: 0.627406	test: 0.599410
PRC train: 0.783945	val: 0.667018	test: 0.609571

Epoch: 46
Loss: 0.41978612155891765
ROC train: 0.827347	val: 0.628636	test: 0.602905
PRC train: 0.787400	val: 0.669270	test: 0.614238

Epoch: 47
Loss: 0.416457415458207
ROC train: 0.832795	val: 0.632083	test: 0.608569
PRC train: 0.788538	val: 0.678526	test: 0.615420

Epoch: 48
Loss: 0.4243783676228472
ROC train: 0.836297	val: 0.631274	test: 0.611249
PRC train: 0.791478	val: 0.677195	test: 0.617993

Epoch: 49
Loss: 0.4083196467894317
ROC train: 0.840346	val: 0.626511	test: 0.607140
PRC train: 0.796150	val: 0.670575	test: 0.616038

Epoch: 50
Loss: 0.416763113276963
ROC train: 0.839436	val: 0.621063	test: 0.602787
PRC train: 0.795221	val: 0.667037	test: 0.612464

Epoch: 51
Loss: 0.41344239513922176
ROC train: 0.838441	val: 0.628571	test: 0.601557
PRC train: 0.795522	val: 0.664918	test: 0.610129

Epoch: 52
Loss: 0.41155000026846184
ROC train: 0.841899	val: 0.636054	test: 0.599286
PRC train: 0.800134	val: 0.668431	test: 0.611769

Epoch: 53
Loss: 0.4108674533963011
ROC train: 0.844401	val: 0.633519	test: 0.598264
PRC train: 0.801490	val: 0.670078	test: 0.614168

Epoch: 54
Loss: 0.40666456982901633
ROC train: 0.847952	val: 0.624898	test: 0.605048
PRC train: 0.801217	val: 0.669820	test: 0.615825

Epoch: 55
Loss: 0.3953764615278783
ROC train: 0.850803	val: 0.626672	test: 0.604714
PRC train: 0.803928	val: 0.666343	test: 0.616977

Epoch: 56
Loss: 0.4037226275779482
ROC train: 0.854238	val: 0.626818	test: 0.603539
PRC train: 0.809764	val: 0.663636	test: 0.616171

Epoch: 57
Loss: 0.39823268281316976
ROC train: 0.853508	val: 0.630328	test: 0.602507
PRC train: 0.809978	val: 0.666427	test: 0.611838

Epoch: 58
Loss: 0.40189562763420733
ROC train: 0.853513	val: 0.636951	test: 0.604212
PRC train: 0.809113	val: 0.673272	test: 0.611903

Epoch: 59
Loss: 0.39552448226589504
ROC train: 0.855518	val: 0.635023	test: 0.598962
PRC train: 0.811647	val: 0.669477	test: 0.610639

Epoch: 60
Loss: 0.4025154726200272
ROC train: 0.859586	val: 0.633260	test: 0.597721
PRC train: 0.816329	val: 0.669859	test: 0.611152

Epoch: 61
Loss: 0.40371744354945516
ROC train: 0.857290	val: 0.631700	test: 0.593887
PRC train: 0.816261	val: 0.665160	test: 0.612493

Epoch: 62
Loss: 0.395551481862346
ROC train: 0.862154	val: 0.631538	test: 0.594633
PRC train: 0.819789	val: 0.669412	test: 0.611491

Epoch: 63
Loss: 0.3955517522689209
ROC train: 0.862148	val: 0.633137	test: 0.598700
PRC train: 0.817304	val: 0.670355	test: 0.611645

Epoch: 64
Loss: 0.39338228497585437
ROC train: 0.862066	val: 0.636834	test: 0.604155
PRC train: 0.815991	val: 0.674675	test: 0.615323

Epoch: 65
Loss: 0.39855169993173917
ROC train: 0.863566	val: 0.635114	test: 0.601150
PRC train: 0.818740	val: 0.672610	test: 0.616422

Epoch: 66
Loss: 0.39114522049269074
ROC train: 0.860140	val: 0.631733	test: 0.594281
PRC train: 0.815732	val: 0.668209	test: 0.609394

Epoch: 67
Loss: 0.39325150843825596
ROC train: 0.866977	val: 0.632262	test: 0.595889
PRC train: 0.820840	val: 0.668681	test: 0.609770

Epoch: 68
Loss: 0.3857262047629222
ROC train: 0.870921	val: 0.628777	test: 0.602992
PRC train: 0.822980	val: 0.665306	test: 0.613731

Epoch: 69
Loss: 0.38564952924898577
ROC train: 0.872410	val: 0.624481	test: 0.600831
PRC train: 0.825770	val: 0.663384	test: 0.613153

Epoch: 70
Loss: 0.39094548952652486
ROC train: 0.873450	val: 0.624747	test: 0.597394
PRC train: 0.829570	val: 0.661492	test: 0.611301

Epoch: 71
Loss: 0.3794008444607573
ROC train: 0.878415	val: 0.627346	test: 0.602306
PRC train: 0.836173	val: 0.660681	test: 0.614674

Epoch: 72
Loss: 0.3881507659796104
ROC train: 0.881018	val: 0.628887	test: 0.607350
PRC train: 0.839354	val: 0.661561	test: 0.618418

Epoch: 73
Loss: 0.3754017183967854
ROC train: 0.877536	val: 0.632287	test: 0.607414
PRC train: 0.836273	val: 0.667519	test: 0.618692

Epoch: 74
Loss: 0.38313172936634965
ROC train: 0.879676	val: 0.628442	test: 0.601969
PRC train: 0.838777	val: 0.664371	test: 0.614097

Epoch: 75
Loss: 0.38377547203472
ROC train: 0.881422	val: 0.625254	test: 0.598666
PRC train: 0.843393	val: 0.659795	test: 0.610741

Epoch: 76
Loss: 0.3807307776642055
ROC train: 0.880856	val: 0.623991	test: 0.598116
PRC train: 0.842130	val: 0.663031	test: 0.608403

Epoch: 77
Loss: 0.37835104174267914
ROC train: 0.879517	val: 0.618886	test: 0.595024
PRC train: 0.839422	val: 0.663491	test: 0.610242

Epoch: 78
Loss: 0.37235188572991096
ROC train: 0.885039	val: 0.625071	test: 0.600103
PRC train: 0.844212	val: 0.666799	test: 0.616111

Epoch: 79
Loss: 0.3711523690872326
ROC train: 0.887778	val: 0.628895	test: 0.606298
PRC train: 0.847847	val: 0.666005	test: 0.621722

Epoch: 80
Loss: 0.369848161678102
ROC train: 0.887016	val: 0.632023	test: 0.610488
PRC train: 0.843888	val: 0.664015	test: 0.626495

Epoch: 81
Loss: 0.3734038511912464
ROC train: 0.887858	val: 0.635869	test: 0.611881
PRC train: 0.843893	val: 0.666077	test: 0.628465

Epoch: 82
Loss: 0.37149761023515865
ROC train: 0.889281	val: 0.635041	test: 0.613470
PRC train: 0.846645	val: 0.666017	test: 0.630800

Epoch: 83
Loss: 0.3666551486464189
ROC train: 0.890334	val: 0.630425	test: 0.612272
PRC train: 0.849426	val: 0.660300	test: 0.630451

Epoch: 84
Loss: 0.36559044739466434
ROC train: 0.889753	val: 0.625119	test: 0.609036
PRC train: 0.852941	val: 0.657344	test: 0.627178

Epoch: 85
Loss: 0.363767550042874
ROC train: 0.889358	val: 0.626358	test: 0.608906
PRC train: 0.849176	val: 0.659547	test: 0.624877

Epoch: 86
Loss: 0.365675022958859
ROC train: 0.893007	val: 0.630742	test: 0.611985
PRC train: 0.849341	val: 0.663103	test: 0.626934

Epoch: 87
Loss: 0.365349660803918
ROC train: 0.895184	val: 0.628744	test: 0.612797
PRC train: 0.852626	val: 0.666645	test: 0.628911

Epoch: 88
Loss: 0.36607477905199615
ROC train: 0.891982	val: 0.622549	test: 0.609526
PRC train: 0.854209	val: 0.662400	test: 0.628265

Epoch: 89
Loss: 0.364094669506996
ROC train: 0.887687	val: 0.622093	test: 0.605196
PRC train: 0.850674	val: 0.658247	test: 0.625730

Epoch: 90
Loss: 0.35907249280963316
ROC train: 0.901568	val: 0.632694	test: 0.607977
PRC train: 0.862390	val: 0.668331	test: 0.624863

Epoch: 91
Loss: 0.35862922524525676
ROC train: 0.902979	val: 0.636414	test: 0.608548
PRC train: 0.861945	val: 0.670247	test: 0.627185

Epoch: 92
Loss: 0.35817224396042946
ROC train: 0.900332	val: 0.632500	test: 0.608743
PRC train: 0.859371	val: 0.669774	test: 0.630402

Epoch: 93
Loss: 0.35620647522449445
ROC train: 0.900147	val: 0.628811	test: 0.610293
PRC train: 0.861038	val: 0.666837	test: 0.635143

Epoch: 94
Loss: 0.355846574348342
ROC train: 0.797382	val: 0.616975	test: 0.597616
PRC train: 0.761701	val: 0.661900	test: 0.609968

Epoch: 34
Loss: 0.4377493427754704
ROC train: 0.802552	val: 0.616716	test: 0.601949
PRC train: 0.765886	val: 0.663966	test: 0.611060

Epoch: 35
Loss: 0.4370799549034784
ROC train: 0.803954	val: 0.619329	test: 0.597172
PRC train: 0.766023	val: 0.664760	test: 0.608225

Epoch: 36
Loss: 0.4393000226615186
ROC train: 0.804348	val: 0.623797	test: 0.596286
PRC train: 0.764541	val: 0.663517	test: 0.611577

Epoch: 37
Loss: 0.44004759847130676
ROC train: 0.799240	val: 0.613298	test: 0.586977
PRC train: 0.763359	val: 0.656028	test: 0.610598

Epoch: 38
Loss: 0.4392708934344074
ROC train: 0.805291	val: 0.612695	test: 0.591074
PRC train: 0.765134	val: 0.653576	test: 0.611241

Epoch: 39
Loss: 0.43157441946358654
ROC train: 0.808326	val: 0.610949	test: 0.593609
PRC train: 0.766694	val: 0.652881	test: 0.610555

Epoch: 40
Loss: 0.43583076992610525
ROC train: 0.811978	val: 0.601185	test: 0.597730
PRC train: 0.769270	val: 0.648387	test: 0.612244

Epoch: 41
Loss: 0.4290710930713351
ROC train: 0.813230	val: 0.596583	test: 0.599591
PRC train: 0.772077	val: 0.647563	test: 0.615822

Epoch: 42
Loss: 0.43639324823149683
ROC train: 0.817515	val: 0.598944	test: 0.601207
PRC train: 0.777782	val: 0.646941	test: 0.614523

Epoch: 43
Loss: 0.4214009431548263
ROC train: 0.817438	val: 0.609172	test: 0.596182
PRC train: 0.778389	val: 0.650620	test: 0.613225

Epoch: 44
Loss: 0.4255336661315669
ROC train: 0.819146	val: 0.613101	test: 0.596445
PRC train: 0.778682	val: 0.649928	test: 0.615036

Epoch: 45
Loss: 0.4199921149782087
ROC train: 0.809008	val: 0.605650	test: 0.592261
PRC train: 0.770783	val: 0.643225	test: 0.615753

Epoch: 46
Loss: 0.4237645452028267
ROC train: 0.822158	val: 0.602085	test: 0.603561
PRC train: 0.779051	val: 0.644101	test: 0.618900

Epoch: 47
Loss: 0.42606249575627614
ROC train: 0.831786	val: 0.604298	test: 0.607842
PRC train: 0.788178	val: 0.645808	test: 0.623041

Epoch: 48
Loss: 0.4188723667212278
ROC train: 0.832018	val: 0.605822	test: 0.599160
PRC train: 0.789910	val: 0.651871	test: 0.618250

Epoch: 49
Loss: 0.42141563685316136
ROC train: 0.834366	val: 0.610566	test: 0.599134
PRC train: 0.793303	val: 0.659191	test: 0.614951

Epoch: 50
Loss: 0.40826957444655027
ROC train: 0.833830	val: 0.618615	test: 0.604173
PRC train: 0.792904	val: 0.660169	test: 0.614041

Epoch: 51
Loss: 0.4146959734147654
ROC train: 0.839004	val: 0.625824	test: 0.604096
PRC train: 0.796011	val: 0.662775	test: 0.618804

Epoch: 52
Loss: 0.4105462573124269
ROC train: 0.837300	val: 0.624987	test: 0.599563
PRC train: 0.794427	val: 0.663833	test: 0.617115

Epoch: 53
Loss: 0.40981005289927686
ROC train: 0.840624	val: 0.614091	test: 0.602371
PRC train: 0.798813	val: 0.654393	test: 0.619332

Epoch: 54
Loss: 0.4100967438517271
ROC train: 0.836553	val: 0.609250	test: 0.596781
PRC train: 0.796225	val: 0.650657	test: 0.615376

Epoch: 55
Loss: 0.4135125816463032
ROC train: 0.846009	val: 0.617491	test: 0.601875
PRC train: 0.806899	val: 0.657648	test: 0.619886

Epoch: 56
Loss: 0.40593872814062826
ROC train: 0.848182	val: 0.620368	test: 0.610798
PRC train: 0.806037	val: 0.659396	test: 0.626225

Epoch: 57
Loss: 0.41461449521228455
ROC train: 0.847401	val: 0.616219	test: 0.612639
PRC train: 0.804998	val: 0.655322	test: 0.626566

Epoch: 58
Loss: 0.404284963794301
ROC train: 0.849594	val: 0.611711	test: 0.610966
PRC train: 0.808171	val: 0.656920	test: 0.626149

Epoch: 59
Loss: 0.4070165906164335
ROC train: 0.852580	val: 0.601602	test: 0.608568
PRC train: 0.810655	val: 0.650398	test: 0.623702

Epoch: 60
Loss: 0.40249426281632505
ROC train: 0.854912	val: 0.603564	test: 0.610077
PRC train: 0.811583	val: 0.646675	test: 0.622597

Epoch: 61
Loss: 0.4032389044204034
ROC train: 0.855120	val: 0.611737	test: 0.610883
PRC train: 0.810771	val: 0.649404	test: 0.619547

Epoch: 62
Loss: 0.39969130736049885
ROC train: 0.858801	val: 0.620214	test: 0.611198
PRC train: 0.815737	val: 0.655209	test: 0.617832

Epoch: 63
Loss: 0.3963727900819296
ROC train: 0.862506	val: 0.619041	test: 0.608869
PRC train: 0.819407	val: 0.657699	test: 0.617449

Epoch: 64
Loss: 0.39846191157931116
ROC train: 0.863931	val: 0.607823	test: 0.604388
PRC train: 0.822249	val: 0.652435	test: 0.615002

Epoch: 65
Loss: 0.38897915656805465
ROC train: 0.863492	val: 0.607951	test: 0.605442
PRC train: 0.821277	val: 0.651018	test: 0.617069

Epoch: 66
Loss: 0.38662085652429695
ROC train: 0.863935	val: 0.611954	test: 0.604789
PRC train: 0.824475	val: 0.654236	test: 0.619501

Epoch: 67
Loss: 0.38671179460366994
ROC train: 0.866102	val: 0.612422	test: 0.606710
PRC train: 0.826425	val: 0.654920	test: 0.622075

Epoch: 68
Loss: 0.3867346096997843
ROC train: 0.864175	val: 0.608264	test: 0.604977
PRC train: 0.823391	val: 0.653060	test: 0.622529

Epoch: 69
Loss: 0.38729524548164357
ROC train: 0.868550	val: 0.610970	test: 0.604920
PRC train: 0.830166	val: 0.658606	test: 0.620711

Epoch: 70
Loss: 0.39272489940861005
ROC train: 0.871408	val: 0.610954	test: 0.608236
PRC train: 0.834678	val: 0.656955	test: 0.621140

Epoch: 71
Loss: 0.39051315979542817
ROC train: 0.870232	val: 0.606234	test: 0.606668
PRC train: 0.829384	val: 0.648926	test: 0.617166

Epoch: 72
Loss: 0.3843009025394952
ROC train: 0.873232	val: 0.609776	test: 0.607318
PRC train: 0.832043	val: 0.651495	test: 0.617919

Epoch: 73
Loss: 0.3808695517502523
ROC train: 0.877261	val: 0.624693	test: 0.609827
PRC train: 0.837002	val: 0.662434	test: 0.622755

Epoch: 74
Loss: 0.3860737573792382
ROC train: 0.875478	val: 0.619464	test: 0.602740
PRC train: 0.834848	val: 0.662595	test: 0.619872

Epoch: 75
Loss: 0.3872135171455913
ROC train: 0.876670	val: 0.617395	test: 0.601318
PRC train: 0.835615	val: 0.660877	test: 0.619557

Epoch: 76
Loss: 0.380139244026399
ROC train: 0.875328	val: 0.610705	test: 0.601052
PRC train: 0.835731	val: 0.653025	test: 0.621061

Epoch: 77
Loss: 0.38488796043137297
ROC train: 0.876392	val: 0.605778	test: 0.602679
PRC train: 0.836267	val: 0.648693	test: 0.623100

Epoch: 78
Loss: 0.3854030377352408
ROC train: 0.881370	val: 0.618353	test: 0.613658
PRC train: 0.838613	val: 0.660327	test: 0.627106

Epoch: 79
Loss: 0.3842376711495749
ROC train: 0.881260	val: 0.617227	test: 0.615486
PRC train: 0.837925	val: 0.659899	test: 0.625071

Epoch: 80
Loss: 0.37391456945395835
ROC train: 0.883146	val: 0.612865	test: 0.612676
PRC train: 0.841284	val: 0.655538	test: 0.622640

Epoch: 81
Loss: 0.37357951267415246
ROC train: 0.885492	val: 0.613869	test: 0.610113
PRC train: 0.845401	val: 0.655449	test: 0.621868

Epoch: 82
Loss: 0.3696303333454575
ROC train: 0.885982	val: 0.615080	test: 0.606058
PRC train: 0.847184	val: 0.658998	test: 0.620708

Epoch: 83
Loss: 0.3653104844655626
ROC train: 0.884331	val: 0.610012	test: 0.602732
PRC train: 0.847544	val: 0.658665	test: 0.617545

Epoch: 84
Loss: 0.3740459587704434
ROC train: 0.884459	val: 0.610373	test: 0.602624
PRC train: 0.845984	val: 0.660513	test: 0.615586

Epoch: 85
Loss: 0.3737070634092837
ROC train: 0.887491	val: 0.605637	test: 0.604745
PRC train: 0.848139	val: 0.659695	test: 0.615103

Epoch: 86
Loss: 0.3703528622475859
ROC train: 0.890564	val: 0.612383	test: 0.612528
PRC train: 0.849716	val: 0.662442	test: 0.621839

Epoch: 87
Loss: 0.3715813555118848
ROC train: 0.891725	val: 0.618930	test: 0.613606
PRC train: 0.851001	val: 0.660272	test: 0.624169

Epoch: 88
Loss: 0.368044945749277
ROC train: 0.892639	val: 0.621547	test: 0.612680
PRC train: 0.852679	val: 0.657860	test: 0.626532

Epoch: 89
Loss: 0.3701902723066208
ROC train: 0.895195	val: 0.621064	test: 0.614391
PRC train: 0.854201	val: 0.658633	test: 0.628218

Epoch: 90
Loss: 0.3633291061235927
ROC train: 0.894908	val: 0.609660	test: 0.611180
PRC train: 0.852246	val: 0.656253	test: 0.627557

Epoch: 91
Loss: 0.36676602871248987
ROC train: 0.892818	val: 0.601003	test: 0.604662
PRC train: 0.855106	val: 0.650100	test: 0.626290

Epoch: 92
Loss: 0.36306886697733676
ROC train: 0.898028	val: 0.609967	test: 0.609473
PRC train: 0.862152	val: 0.653333	test: 0.625399

Epoch: 93
Loss: 0.3698637688405475
ROC train: 0.900971	val: 0.614514	test: 0.611796
PRC train: 0.863795	val: 0.659891	test: 0.623577

Epoch: 94
Loss: 0.35689102911901327
ROC train: 0.786464	val: 0.623906	test: 0.579560
PRC train: 0.751402	val: 0.667069	test: 0.598130

Epoch: 34
Loss: 0.44093038070127905
ROC train: 0.789569	val: 0.624798	test: 0.579668
PRC train: 0.754082	val: 0.664824	test: 0.599959

Epoch: 35
Loss: 0.4436972983267417
ROC train: 0.797581	val: 0.627715	test: 0.594463
PRC train: 0.759316	val: 0.668615	test: 0.605648

Epoch: 36
Loss: 0.4427204261325559
ROC train: 0.800844	val: 0.626655	test: 0.592175
PRC train: 0.761996	val: 0.663773	test: 0.605411

Epoch: 37
Loss: 0.4330397387734406
ROC train: 0.802359	val: 0.623986	test: 0.589139
PRC train: 0.763037	val: 0.659662	test: 0.604297

Epoch: 38
Loss: 0.4367217374528038
ROC train: 0.802214	val: 0.622933	test: 0.587167
PRC train: 0.761400	val: 0.662368	test: 0.602104

Epoch: 39
Loss: 0.4351577848589062
ROC train: 0.806457	val: 0.620432	test: 0.590801
PRC train: 0.764337	val: 0.658091	test: 0.605118

Epoch: 40
Loss: 0.4318983171005771
ROC train: 0.815283	val: 0.620469	test: 0.592595
PRC train: 0.771308	val: 0.657832	test: 0.608573

Epoch: 41
Loss: 0.42948490313214427
ROC train: 0.818286	val: 0.620275	test: 0.587382
PRC train: 0.773437	val: 0.657699	test: 0.608686

Epoch: 42
Loss: 0.4331390257327696
ROC train: 0.820716	val: 0.626534	test: 0.591382
PRC train: 0.777488	val: 0.661791	test: 0.608736

Epoch: 43
Loss: 0.4302899430312276
ROC train: 0.818067	val: 0.627709	test: 0.593047
PRC train: 0.777075	val: 0.663177	test: 0.607873

Epoch: 44
Loss: 0.4191669471198089
ROC train: 0.821933	val: 0.624064	test: 0.592873
PRC train: 0.779833	val: 0.659464	test: 0.610054

Epoch: 45
Loss: 0.42525425331269345
ROC train: 0.826664	val: 0.621515	test: 0.584360
PRC train: 0.783582	val: 0.657454	test: 0.604399

Epoch: 46
Loss: 0.4180672690430336
ROC train: 0.820293	val: 0.621507	test: 0.577552
PRC train: 0.775832	val: 0.650517	test: 0.598038

Epoch: 47
Loss: 0.4233383718070062
ROC train: 0.823611	val: 0.621961	test: 0.574649
PRC train: 0.779651	val: 0.650924	test: 0.598709

Epoch: 48
Loss: 0.4242160723119921
ROC train: 0.829599	val: 0.620856	test: 0.581813
PRC train: 0.784181	val: 0.659071	test: 0.603506

Epoch: 49
Loss: 0.42140925563688925
ROC train: 0.833953	val: 0.622073	test: 0.582849
PRC train: 0.791717	val: 0.656947	test: 0.601218

Epoch: 50
Loss: 0.414298119416526
ROC train: 0.833704	val: 0.624289	test: 0.587504
PRC train: 0.789657	val: 0.657854	test: 0.605570

Epoch: 51
Loss: 0.41874008188867634
ROC train: 0.840664	val: 0.621320	test: 0.592859
PRC train: 0.792296	val: 0.656709	test: 0.610650

Epoch: 52
Loss: 0.40936887702926567
ROC train: 0.840255	val: 0.623236	test: 0.595478
PRC train: 0.790615	val: 0.657886	test: 0.610909

Epoch: 53
Loss: 0.40955937477601745
ROC train: 0.838937	val: 0.625342	test: 0.595036
PRC train: 0.791883	val: 0.657946	test: 0.609282

Epoch: 54
Loss: 0.40625245408665384
ROC train: 0.841862	val: 0.624058	test: 0.592026
PRC train: 0.794361	val: 0.654586	test: 0.607763

Epoch: 55
Loss: 0.40003579774487863
ROC train: 0.843244	val: 0.621438	test: 0.596639
PRC train: 0.796163	val: 0.652766	test: 0.611951

Epoch: 56
Loss: 0.40390887063789255
ROC train: 0.848740	val: 0.627384	test: 0.599789
PRC train: 0.803347	val: 0.659435	test: 0.614561

Epoch: 57
Loss: 0.4057277482173012
ROC train: 0.851628	val: 0.625187	test: 0.596121
PRC train: 0.805568	val: 0.654727	test: 0.613666

Epoch: 58
Loss: 0.4062174655686315
ROC train: 0.854256	val: 0.625028	test: 0.597557
PRC train: 0.807372	val: 0.657930	test: 0.613011

Epoch: 59
Loss: 0.3984515951141496
ROC train: 0.855195	val: 0.625312	test: 0.596597
PRC train: 0.807217	val: 0.655841	test: 0.610467

Epoch: 60
Loss: 0.4014387977506597
ROC train: 0.855117	val: 0.627711	test: 0.595930
PRC train: 0.807994	val: 0.658822	test: 0.609109

Epoch: 61
Loss: 0.4056698268045129
ROC train: 0.853999	val: 0.625857	test: 0.587482
PRC train: 0.808284	val: 0.657955	test: 0.603850

Epoch: 62
Loss: 0.4016401226769488
ROC train: 0.856525	val: 0.625632	test: 0.586484
PRC train: 0.812396	val: 0.657916	test: 0.603894

Epoch: 63
Loss: 0.3981814947151981
ROC train: 0.859560	val: 0.627701	test: 0.589864
PRC train: 0.814737	val: 0.657831	test: 0.605317

Epoch: 64
Loss: 0.3948812406212764
ROC train: 0.863169	val: 0.633042	test: 0.591440
PRC train: 0.817088	val: 0.662296	test: 0.610844

Epoch: 65
Loss: 0.391015569107939
ROC train: 0.861267	val: 0.629146	test: 0.592319
PRC train: 0.815043	val: 0.660746	test: 0.614612

Epoch: 66
Loss: 0.3996071589841789
ROC train: 0.866919	val: 0.629841	test: 0.599060
PRC train: 0.820893	val: 0.663525	test: 0.615049

Epoch: 67
Loss: 0.3934161051764695
ROC train: 0.862548	val: 0.629335	test: 0.600697
PRC train: 0.818112	val: 0.662712	test: 0.616300

Epoch: 68
Loss: 0.39315331219429905
ROC train: 0.859004	val: 0.623380	test: 0.594751
PRC train: 0.811822	val: 0.656279	test: 0.613238

Epoch: 69
Loss: 0.38880365699731184
ROC train: 0.869745	val: 0.626338	test: 0.596296
PRC train: 0.821936	val: 0.659912	test: 0.610631

Epoch: 70
Loss: 0.38692035621383086
ROC train: 0.867968	val: 0.628399	test: 0.594798
PRC train: 0.822156	val: 0.660125	test: 0.605646

Epoch: 71
Loss: 0.3920251941404944
ROC train: 0.872528	val: 0.624692	test: 0.593369
PRC train: 0.829784	val: 0.654955	test: 0.606000

Epoch: 72
Loss: 0.39586483335670575
ROC train: 0.866238	val: 0.624399	test: 0.592154
PRC train: 0.821105	val: 0.657187	test: 0.604497

Epoch: 73
Loss: 0.38345459527186043
ROC train: 0.870852	val: 0.635571	test: 0.599323
PRC train: 0.826156	val: 0.664728	test: 0.613271

Epoch: 74
Loss: 0.3785709653802373
ROC train: 0.873488	val: 0.641093	test: 0.602007
PRC train: 0.830150	val: 0.668569	test: 0.615895

Epoch: 75
Loss: 0.37854952509195283
ROC train: 0.877939	val: 0.639942	test: 0.600764
PRC train: 0.835093	val: 0.667348	test: 0.612587

Epoch: 76
Loss: 0.3798865963901253
ROC train: 0.881119	val: 0.633851	test: 0.601918
PRC train: 0.837456	val: 0.659370	test: 0.612364

Epoch: 77
Loss: 0.3821858080007967
ROC train: 0.877533	val: 0.627542	test: 0.598530
PRC train: 0.833047	val: 0.655277	test: 0.612426

Epoch: 78
Loss: 0.3750121287695049
ROC train: 0.878579	val: 0.633764	test: 0.600759
PRC train: 0.836665	val: 0.665061	test: 0.612917

Epoch: 79
Loss: 0.3850907715369774
ROC train: 0.884493	val: 0.635911	test: 0.606093
PRC train: 0.844117	val: 0.666841	test: 0.619407

Epoch: 80
Loss: 0.3768079386304524
ROC train: 0.878196	val: 0.626122	test: 0.604520
PRC train: 0.837595	val: 0.658139	test: 0.620191

Epoch: 81
Loss: 0.3754973673561104
ROC train: 0.884393	val: 0.630422	test: 0.605136
PRC train: 0.842927	val: 0.660767	test: 0.620816

Epoch: 82
Loss: 0.36887995622824643
ROC train: 0.885742	val: 0.628396	test: 0.604347
PRC train: 0.845272	val: 0.660545	test: 0.620048

Epoch: 83
Loss: 0.36900376527146855
ROC train: 0.881916	val: 0.623705	test: 0.599687
PRC train: 0.838558	val: 0.655483	test: 0.619393

Epoch: 84
Loss: 0.3729144161203497
ROC train: 0.883559	val: 0.628948	test: 0.599184
PRC train: 0.840900	val: 0.657938	test: 0.618411

Epoch: 85
Loss: 0.37602980879357334
ROC train: 0.890048	val: 0.635028	test: 0.602021
PRC train: 0.845081	val: 0.665198	test: 0.619143

Epoch: 86
Loss: 0.3614024972340333
ROC train: 0.886374	val: 0.632890	test: 0.593417
PRC train: 0.844718	val: 0.666428	test: 0.615443

Epoch: 87
Loss: 0.36658594721806775
ROC train: 0.888454	val: 0.628396	test: 0.595967
PRC train: 0.846612	val: 0.663038	test: 0.617525

Epoch: 88
Loss: 0.36927599390494575
ROC train: 0.890308	val: 0.620468	test: 0.596412
PRC train: 0.850699	val: 0.658838	test: 0.618226

Epoch: 89
Loss: 0.3647178735294265
ROC train: 0.892884	val: 0.619585	test: 0.595880
PRC train: 0.855373	val: 0.656863	test: 0.618352

Epoch: 90
Loss: 0.36923648642543117
ROC train: 0.894205	val: 0.626539	test: 0.598945
PRC train: 0.856190	val: 0.659630	test: 0.618780

Epoch: 91
Loss: 0.3678728187187769
ROC train: 0.895874	val: 0.634621	test: 0.604463
PRC train: 0.855488	val: 0.667867	test: 0.621635

Epoch: 92
Loss: 0.3647895528739089
ROC train: 0.895938	val: 0.635195	test: 0.603373
PRC train: 0.857170	val: 0.665974	test: 0.621119

Epoch: 93
Loss: 0.3639021413957343
ROC train: 0.899147	val: 0.631219	test: 0.599555
PRC train: 0.861895	val: 0.663009	test: 0.619356

Epoch: 94
Loss: 0.35525551199352734
ROC train: 0.798332	val: 0.611474	test: 0.600608
PRC train: 0.760105	val: 0.672966	test: 0.604497

Epoch: 34
Loss: 0.43961653015050584
ROC train: 0.798228	val: 0.611713	test: 0.599571
PRC train: 0.760603	val: 0.671302	test: 0.603019

Epoch: 35
Loss: 0.4300651535311826
ROC train: 0.799700	val: 0.607183	test: 0.596900
PRC train: 0.762962	val: 0.670981	test: 0.602915

Epoch: 36
Loss: 0.4337737222214597
ROC train: 0.805194	val: 0.607400	test: 0.596108
PRC train: 0.766872	val: 0.670625	test: 0.601901

Epoch: 37
Loss: 0.4319286158304879
ROC train: 0.808078	val: 0.612699	test: 0.592072
PRC train: 0.769624	val: 0.671612	test: 0.601815

Epoch: 38
Loss: 0.4272963552625568
ROC train: 0.810031	val: 0.619950	test: 0.591570
PRC train: 0.770848	val: 0.677780	test: 0.602153

Epoch: 39
Loss: 0.42806552338345494
ROC train: 0.815855	val: 0.622792	test: 0.599103
PRC train: 0.776008	val: 0.681501	test: 0.605533

Epoch: 40
Loss: 0.4263607831604816
ROC train: 0.814520	val: 0.624301	test: 0.601662
PRC train: 0.774666	val: 0.685220	test: 0.610123

Epoch: 41
Loss: 0.42821551772516975
ROC train: 0.819211	val: 0.623048	test: 0.604862
PRC train: 0.779160	val: 0.682725	test: 0.609373

Epoch: 42
Loss: 0.4224288907440832
ROC train: 0.820432	val: 0.620396	test: 0.602159
PRC train: 0.780396	val: 0.682584	test: 0.610381

Epoch: 43
Loss: 0.4205670006905645
ROC train: 0.824678	val: 0.620197	test: 0.598735
PRC train: 0.781869	val: 0.682723	test: 0.606941

Epoch: 44
Loss: 0.4200018234771818
ROC train: 0.824242	val: 0.622955	test: 0.594430
PRC train: 0.781179	val: 0.690878	test: 0.604954

Epoch: 45
Loss: 0.4144489435972106
ROC train: 0.827827	val: 0.624090	test: 0.598169
PRC train: 0.784469	val: 0.690722	test: 0.605948

Epoch: 46
Loss: 0.4210032836574928
ROC train: 0.824396	val: 0.616536	test: 0.598247
PRC train: 0.783324	val: 0.685605	test: 0.605910

Epoch: 47
Loss: 0.4176069224689547
ROC train: 0.833111	val: 0.614991	test: 0.603936
PRC train: 0.788555	val: 0.687473	test: 0.611447

Epoch: 48
Loss: 0.41890346857711186
ROC train: 0.837127	val: 0.615665	test: 0.599630
PRC train: 0.793066	val: 0.679851	test: 0.607738

Epoch: 49
Loss: 0.41718568525672534
ROC train: 0.834961	val: 0.614821	test: 0.595369
PRC train: 0.791414	val: 0.678233	test: 0.606428

Epoch: 50
Loss: 0.40826228020729827
ROC train: 0.836283	val: 0.611573	test: 0.600271
PRC train: 0.793363	val: 0.675887	test: 0.607501

Epoch: 51
Loss: 0.414988428793279
ROC train: 0.836341	val: 0.611770	test: 0.601596
PRC train: 0.793057	val: 0.675622	test: 0.608364

Epoch: 52
Loss: 0.406608928079183
ROC train: 0.838504	val: 0.619363	test: 0.600379
PRC train: 0.794257	val: 0.681199	test: 0.609044

Epoch: 53
Loss: 0.4093288814040309
ROC train: 0.837316	val: 0.623024	test: 0.599880
PRC train: 0.793842	val: 0.681901	test: 0.607847

Epoch: 54
Loss: 0.4120559607553003
ROC train: 0.841673	val: 0.617745	test: 0.596859
PRC train: 0.798411	val: 0.679026	test: 0.604297

Epoch: 55
Loss: 0.4060613251290287
ROC train: 0.845542	val: 0.615151	test: 0.590557
PRC train: 0.802734	val: 0.680161	test: 0.600067

Epoch: 56
Loss: 0.40881606234426243
ROC train: 0.847546	val: 0.612094	test: 0.585858
PRC train: 0.804349	val: 0.678905	test: 0.598328

Epoch: 57
Loss: 0.40201317730395536
ROC train: 0.847447	val: 0.612654	test: 0.590173
PRC train: 0.802771	val: 0.677800	test: 0.600039

Epoch: 58
Loss: 0.40197166020153324
ROC train: 0.853779	val: 0.616870	test: 0.597295
PRC train: 0.808719	val: 0.681295	test: 0.605848

Epoch: 59
Loss: 0.3991606560822871
ROC train: 0.857003	val: 0.612642	test: 0.595763
PRC train: 0.812345	val: 0.678605	test: 0.605923

Epoch: 60
Loss: 0.39626229597329016
ROC train: 0.851599	val: 0.607176	test: 0.587625
PRC train: 0.808347	val: 0.666887	test: 0.599517

Epoch: 61
Loss: 0.39738927992122186
ROC train: 0.856119	val: 0.605444	test: 0.592592
PRC train: 0.810797	val: 0.670200	test: 0.604006

Epoch: 62
Loss: 0.393258501502961
ROC train: 0.857866	val: 0.609719	test: 0.592374
PRC train: 0.813626	val: 0.672402	test: 0.604791

Epoch: 63
Loss: 0.3944190723808759
ROC train: 0.859444	val: 0.614239	test: 0.590765
PRC train: 0.817723	val: 0.676372	test: 0.604375

Epoch: 64
Loss: 0.3945760846825991
ROC train: 0.864142	val: 0.620290	test: 0.593046
PRC train: 0.822763	val: 0.681288	test: 0.606278

Epoch: 65
Loss: 0.39140219996932085
ROC train: 0.865750	val: 0.623923	test: 0.602326
PRC train: 0.824483	val: 0.684145	test: 0.611829

Epoch: 66
Loss: 0.39458697852906865
ROC train: 0.867480	val: 0.618290	test: 0.603222
PRC train: 0.825035	val: 0.679235	test: 0.611892

Epoch: 67
Loss: 0.3873815412125059
ROC train: 0.865438	val: 0.606591	test: 0.598785
PRC train: 0.822212	val: 0.670740	test: 0.607123

Epoch: 68
Loss: 0.39278703009801974
ROC train: 0.866584	val: 0.613232	test: 0.594332
PRC train: 0.822592	val: 0.671865	test: 0.602081

Epoch: 69
Loss: 0.38711703712043233
ROC train: 0.865220	val: 0.618893	test: 0.591663
PRC train: 0.820354	val: 0.676949	test: 0.602871

Epoch: 70
Loss: 0.3837394685486656
ROC train: 0.870203	val: 0.608829	test: 0.592137
PRC train: 0.823739	val: 0.672097	test: 0.604851

Epoch: 71
Loss: 0.3843470426167659
ROC train: 0.874795	val: 0.600632	test: 0.591505
PRC train: 0.830394	val: 0.662935	test: 0.603250

Epoch: 72
Loss: 0.3791522212400086
ROC train: 0.875906	val: 0.605189	test: 0.596012
PRC train: 0.830880	val: 0.669903	test: 0.609415

Epoch: 73
Loss: 0.385566189723268
ROC train: 0.874573	val: 0.608187	test: 0.593780
PRC train: 0.830443	val: 0.674539	test: 0.609406

Epoch: 74
Loss: 0.37804320242058287
ROC train: 0.873931	val: 0.604659	test: 0.589225
PRC train: 0.832705	val: 0.670958	test: 0.606688

Epoch: 75
Loss: 0.37995845310496634
ROC train: 0.879810	val: 0.603955	test: 0.589213
PRC train: 0.835946	val: 0.665604	test: 0.603498

Epoch: 76
Loss: 0.3691363609235952
ROC train: 0.878430	val: 0.612233	test: 0.590551
PRC train: 0.832919	val: 0.670960	test: 0.603843

Epoch: 77
Loss: 0.37991799163649587
ROC train: 0.881243	val: 0.611322	test: 0.590209
PRC train: 0.838314	val: 0.674049	test: 0.603445

Epoch: 78
Loss: 0.3729303290505907
ROC train: 0.882845	val: 0.604816	test: 0.594871
PRC train: 0.838666	val: 0.669158	test: 0.605345

Epoch: 79
Loss: 0.37275396369278146
ROC train: 0.884775	val: 0.605292	test: 0.596853
PRC train: 0.839935	val: 0.668499	test: 0.606866

Epoch: 80
Loss: 0.3772877513444893
ROC train: 0.886041	val: 0.598591	test: 0.595506
PRC train: 0.842288	val: 0.665037	test: 0.605737

Epoch: 81
Loss: 0.36791729231354253
ROC train: 0.887410	val: 0.601181	test: 0.600567
PRC train: 0.846410	val: 0.665006	test: 0.609284

Epoch: 82
Loss: 0.3723276430650111
ROC train: 0.888579	val: 0.613979	test: 0.595851
PRC train: 0.844197	val: 0.672975	test: 0.610370

Epoch: 83
Loss: 0.36842057696545594
ROC train: 0.888765	val: 0.616548	test: 0.596488
PRC train: 0.845647	val: 0.674534	test: 0.610641

Epoch: 84
Loss: 0.3642152204534867
ROC train: 0.889981	val: 0.616863	test: 0.596997
PRC train: 0.846517	val: 0.675921	test: 0.611731

Epoch: 85
Loss: 0.36218216489601873
ROC train: 0.890167	val: 0.613685	test: 0.600030
PRC train: 0.846928	val: 0.676293	test: 0.612949

Epoch: 86
Loss: 0.36382183875818913
ROC train: 0.890737	val: 0.612601	test: 0.600355
PRC train: 0.845990	val: 0.672722	test: 0.613960

Epoch: 87
Loss: 0.3582033959787301
ROC train: 0.893556	val: 0.616469	test: 0.597464
PRC train: 0.846919	val: 0.676353	test: 0.613999

Epoch: 88
Loss: 0.36683269449929135
ROC train: 0.896685	val: 0.615978	test: 0.596178
PRC train: 0.848917	val: 0.678432	test: 0.611601

Epoch: 89
Loss: 0.3575579310095487
ROC train: 0.898877	val: 0.615465	test: 0.601589
PRC train: 0.853255	val: 0.678768	test: 0.613280

Epoch: 90
Loss: 0.35817894682978413
ROC train: 0.902276	val: 0.614443	test: 0.599400
PRC train: 0.858154	val: 0.676857	test: 0.612727

Epoch: 91
Loss: 0.36041406339015547
ROC train: 0.901077	val: 0.609535	test: 0.589979
PRC train: 0.856330	val: 0.674951	test: 0.607542

Epoch: 92
Loss: 0.35459620911613277
ROC train: 0.895510	val: 0.601119	test: 0.595177
PRC train: 0.851009	val: 0.668944	test: 0.609604

Epoch: 93
Loss: 0.3554758261514014
ROC train: 0.897568	val: 0.596570	test: 0.600777
PRC train: 0.852092	val: 0.666926	test: 0.613963

Epoch: 94
Loss: 0.3506007127082707
PRC train: 0.761207	val: 0.672190	test: 0.612876

Epoch: 34
Loss: 0.4383969714339552
ROC train: 0.797659	val: 0.609263	test: 0.598026
PRC train: 0.762250	val: 0.675480	test: 0.608399

Epoch: 35
Loss: 0.4339297842918757
ROC train: 0.800686	val: 0.604828	test: 0.601057
PRC train: 0.764178	val: 0.673708	test: 0.608019

Epoch: 36
Loss: 0.4303568986242866
ROC train: 0.806349	val: 0.602222	test: 0.604497
PRC train: 0.766968	val: 0.673687	test: 0.607375

Epoch: 37
Loss: 0.4288358947153851
ROC train: 0.807221	val: 0.602222	test: 0.598442
PRC train: 0.767018	val: 0.677902	test: 0.607020

Epoch: 38
Loss: 0.4267197497538479
ROC train: 0.809603	val: 0.600108	test: 0.597824
PRC train: 0.769611	val: 0.681289	test: 0.606903

Epoch: 39
Loss: 0.4322510151996931
ROC train: 0.813492	val: 0.599899	test: 0.593435
PRC train: 0.773545	val: 0.671837	test: 0.603271

Epoch: 40
Loss: 0.4262355738800132
ROC train: 0.816096	val: 0.603688	test: 0.593879
PRC train: 0.777621	val: 0.669142	test: 0.602235

Epoch: 41
Loss: 0.4237798291138978
ROC train: 0.818973	val: 0.609690	test: 0.598920
PRC train: 0.779928	val: 0.675424	test: 0.607237

Epoch: 42
Loss: 0.4231755690628831
ROC train: 0.821932	val: 0.614155	test: 0.603814
PRC train: 0.781045	val: 0.679399	test: 0.608965

Epoch: 43
Loss: 0.4201863611908216
ROC train: 0.820931	val: 0.609920	test: 0.595302
PRC train: 0.779249	val: 0.677035	test: 0.608309

Epoch: 44
Loss: 0.4221494091465648
ROC train: 0.824562	val: 0.608692	test: 0.597378
PRC train: 0.782738	val: 0.673255	test: 0.605858

Epoch: 45
Loss: 0.415283605327746
ROC train: 0.827836	val: 0.610963	test: 0.603059
PRC train: 0.786475	val: 0.678374	test: 0.606345

Epoch: 46
Loss: 0.4123528150004133
ROC train: 0.832193	val: 0.609429	test: 0.598920
PRC train: 0.789148	val: 0.679602	test: 0.607518

Epoch: 47
Loss: 0.4117290622861563
ROC train: 0.836375	val: 0.603977	test: 0.599056
PRC train: 0.792716	val: 0.674070	test: 0.604797

Epoch: 48
Loss: 0.41303150352593127
ROC train: 0.838778	val: 0.600887	test: 0.607493
PRC train: 0.794582	val: 0.670329	test: 0.607325

Epoch: 49
Loss: 0.408345267088579
ROC train: 0.837372	val: 0.605444	test: 0.601800
PRC train: 0.797230	val: 0.673908	test: 0.609047

Epoch: 50
Loss: 0.40929444725432934
ROC train: 0.837401	val: 0.611345	test: 0.595679
PRC train: 0.793486	val: 0.681977	test: 0.610523

Epoch: 51
Loss: 0.4099560561091456
ROC train: 0.841219	val: 0.614719	test: 0.598072
PRC train: 0.796714	val: 0.683664	test: 0.609756

Epoch: 52
Loss: 0.4105892076121619
ROC train: 0.844837	val: 0.604384	test: 0.607392
PRC train: 0.798179	val: 0.680941	test: 0.615220

Epoch: 53
Loss: 0.4036599760787886
ROC train: 0.843174	val: 0.597296	test: 0.606464
PRC train: 0.799785	val: 0.672961	test: 0.615706

Epoch: 54
Loss: 0.4042354376528442
ROC train: 0.847489	val: 0.607965	test: 0.600551
PRC train: 0.803099	val: 0.679913	test: 0.614759

Epoch: 55
Loss: 0.398026451617439
ROC train: 0.850597	val: 0.615731	test: 0.597424
PRC train: 0.806103	val: 0.684677	test: 0.612046

Epoch: 56
Loss: 0.39869962301380457
ROC train: 0.853181	val: 0.612011	test: 0.600162
PRC train: 0.807639	val: 0.680547	test: 0.614928

Epoch: 57
Loss: 0.3947463783378824
ROC train: 0.851550	val: 0.604576	test: 0.600156
PRC train: 0.807203	val: 0.671887	test: 0.613155

Epoch: 58
Loss: 0.39473430627119754
ROC train: 0.853761	val: 0.608204	test: 0.597521
PRC train: 0.808987	val: 0.673656	test: 0.609632

Epoch: 59
Loss: 0.39638766850670587
ROC train: 0.855826	val: 0.612269	test: 0.596141
PRC train: 0.808791	val: 0.676514	test: 0.606912

Epoch: 60
Loss: 0.3975303216063874
ROC train: 0.855230	val: 0.608996	test: 0.594628
PRC train: 0.810107	val: 0.674944	test: 0.608565

Epoch: 61
Loss: 0.39084818538515775
ROC train: 0.863059	val: 0.611234	test: 0.600984
PRC train: 0.818070	val: 0.675397	test: 0.615537

Epoch: 62
Loss: 0.3940877662015018
ROC train: 0.863066	val: 0.605914	test: 0.599133
PRC train: 0.815704	val: 0.672031	test: 0.610733

Epoch: 63
Loss: 0.390703224861963
ROC train: 0.861566	val: 0.604795	test: 0.601552
PRC train: 0.814102	val: 0.672733	test: 0.609422

Epoch: 64
Loss: 0.39147777866103184
ROC train: 0.865514	val: 0.608022	test: 0.598225
PRC train: 0.818436	val: 0.680109	test: 0.611186

Epoch: 65
Loss: 0.3908403224988646
ROC train: 0.865962	val: 0.614836	test: 0.596607
PRC train: 0.817920	val: 0.686186	test: 0.608397

Epoch: 66
Loss: 0.39134326022859106
ROC train: 0.867499	val: 0.619216	test: 0.598450
PRC train: 0.819786	val: 0.685624	test: 0.607925

Epoch: 67
Loss: 0.3859198940407772
ROC train: 0.868605	val: 0.618030	test: 0.601805
PRC train: 0.821635	val: 0.685616	test: 0.614307

Epoch: 68
Loss: 0.38347259446518556
ROC train: 0.870752	val: 0.601670	test: 0.609824
PRC train: 0.824349	val: 0.675322	test: 0.621219

Epoch: 69
Loss: 0.3880884420320186
ROC train: 0.868453	val: 0.597986	test: 0.605272
PRC train: 0.822640	val: 0.672481	test: 0.616164

Epoch: 70
Loss: 0.38461589072825475
ROC train: 0.871622	val: 0.609588	test: 0.598020
PRC train: 0.827118	val: 0.678465	test: 0.613825

Epoch: 71
Loss: 0.3768485428287023
ROC train: 0.877974	val: 0.613772	test: 0.599795
PRC train: 0.831857	val: 0.683228	test: 0.616259

Epoch: 72
Loss: 0.3785718223474222
ROC train: 0.882535	val: 0.609352	test: 0.607020
PRC train: 0.836170	val: 0.677787	test: 0.618637

Epoch: 73
Loss: 0.37398718872835496
ROC train: 0.881545	val: 0.601566	test: 0.611232
PRC train: 0.837526	val: 0.668515	test: 0.624134

Epoch: 74
Loss: 0.3751707551249569
ROC train: 0.883544	val: 0.599264	test: 0.603013
PRC train: 0.838701	val: 0.671780	test: 0.621047

Epoch: 75
Loss: 0.3784664327185633
ROC train: 0.883941	val: 0.606109	test: 0.602618
PRC train: 0.838071	val: 0.678864	test: 0.622454

Epoch: 76
Loss: 0.3768500002426737
ROC train: 0.880550	val: 0.613824	test: 0.606436
PRC train: 0.835617	val: 0.679250	test: 0.623990

Epoch: 77
Loss: 0.3726235965588811
ROC train: 0.882812	val: 0.612257	test: 0.609233
PRC train: 0.837364	val: 0.683551	test: 0.628932

Epoch: 78
Loss: 0.3717551652367031
ROC train: 0.886365	val: 0.611299	test: 0.612511
PRC train: 0.840785	val: 0.681389	test: 0.628234

Epoch: 79
Loss: 0.3671277487429317
ROC train: 0.885572	val: 0.608325	test: 0.613421
PRC train: 0.838832	val: 0.678347	test: 0.625593

Epoch: 80
Loss: 0.3676788238832667
ROC train: 0.889070	val: 0.605669	test: 0.606621
PRC train: 0.844940	val: 0.676342	test: 0.623216

Epoch: 81
Loss: 0.36075022404344076
ROC train: 0.889870	val: 0.601044	test: 0.602679
PRC train: 0.845477	val: 0.674210	test: 0.621455

Epoch: 82
Loss: 0.36386378990071255
ROC train: 0.889639	val: 0.597100	test: 0.605460
PRC train: 0.844918	val: 0.668369	test: 0.619154

Epoch: 83
Loss: 0.36629495202297935
ROC train: 0.891329	val: 0.598323	test: 0.596962
PRC train: 0.846557	val: 0.670045	test: 0.613625

Epoch: 84
Loss: 0.3639952858411961
ROC train: 0.892033	val: 0.605139	test: 0.588867
PRC train: 0.849472	val: 0.672783	test: 0.611459

Epoch: 85
Loss: 0.36162414048904484
ROC train: 0.895654	val: 0.608129	test: 0.597917
PRC train: 0.851496	val: 0.675482	test: 0.610894

Epoch: 86
Loss: 0.3650789794727379
ROC train: 0.896860	val: 0.607400	test: 0.603990
PRC train: 0.851924	val: 0.677345	test: 0.611776

Epoch: 87
Loss: 0.36136046815507705
ROC train: 0.897056	val: 0.605828	test: 0.600815
PRC train: 0.856253	val: 0.678439	test: 0.616391

Epoch: 88
Loss: 0.35601841880471125
ROC train: 0.898526	val: 0.608031	test: 0.605549
PRC train: 0.857079	val: 0.680183	test: 0.619381

Epoch: 89
Loss: 0.3563087935964899
ROC train: 0.898441	val: 0.610579	test: 0.606375
PRC train: 0.856501	val: 0.678137	test: 0.622897

Epoch: 90
Loss: 0.3545040903741074
ROC train: 0.899875	val: 0.609239	test: 0.602150
PRC train: 0.858556	val: 0.679615	test: 0.618449

Epoch: 91
Loss: 0.3535973422742364
ROC train: 0.900693	val: 0.615163	test: 0.606151
PRC train: 0.857653	val: 0.682234	test: 0.616469

Epoch: 92
Loss: 0.35297117482057183
ROC train: 0.902943	val: 0.613479	test: 0.610466
PRC train: 0.861648	val: 0.679767	test: 0.619891

Epoch: 93
Loss: 0.35195703703533177
ROC train: 0.905113	val: 0.610296	test: 0.604034
PRC train: 0.866413	val: 0.679583	test: 0.618890

Epoch: 94
Loss: 0.3521666033593942
ROC train: 0.907834	val: 0.605473	test: 0.606204
PRC train: 0.868727	val: 0.673676	test: 0.621518
PRC train: 0.764711	val: 0.682538	test: 0.616700

Epoch: 34
Loss: 0.43835333861240605
ROC train: 0.800284	val: 0.609206	test: 0.605946
PRC train: 0.766586	val: 0.680460	test: 0.617140

Epoch: 35
Loss: 0.4378991535355645
ROC train: 0.803108	val: 0.606157	test: 0.606964
PRC train: 0.767698	val: 0.677640	test: 0.617433

Epoch: 36
Loss: 0.43201427804862014
ROC train: 0.807546	val: 0.610588	test: 0.600841
PRC train: 0.773547	val: 0.678114	test: 0.613882

Epoch: 37
Loss: 0.4276982328212795
ROC train: 0.808453	val: 0.608739	test: 0.595573
PRC train: 0.775166	val: 0.677398	test: 0.610666

Epoch: 38
Loss: 0.4259126206774243
ROC train: 0.809152	val: 0.601808	test: 0.592283
PRC train: 0.774443	val: 0.678998	test: 0.608683

Epoch: 39
Loss: 0.4259924988870384
ROC train: 0.813323	val: 0.599017	test: 0.598462
PRC train: 0.775394	val: 0.683610	test: 0.611869

Epoch: 40
Loss: 0.428328286861713
ROC train: 0.818515	val: 0.601037	test: 0.603250
PRC train: 0.781941	val: 0.679936	test: 0.615486

Epoch: 41
Loss: 0.42582289981565574
ROC train: 0.817884	val: 0.601529	test: 0.598744
PRC train: 0.782493	val: 0.676057	test: 0.612773

Epoch: 42
Loss: 0.42149959221926453
ROC train: 0.817524	val: 0.608879	test: 0.595161
PRC train: 0.782539	val: 0.678743	test: 0.608140

Epoch: 43
Loss: 0.4237545226513617
ROC train: 0.822324	val: 0.613891	test: 0.603343
PRC train: 0.786964	val: 0.678089	test: 0.607056

Epoch: 44
Loss: 0.42234763618636917
ROC train: 0.825824	val: 0.617790	test: 0.605529
PRC train: 0.788842	val: 0.680828	test: 0.610236

Epoch: 45
Loss: 0.4157862325265277
ROC train: 0.822029	val: 0.612602	test: 0.598408
PRC train: 0.785622	val: 0.674705	test: 0.607470

Epoch: 46
Loss: 0.4187990992179012
ROC train: 0.825402	val: 0.614768	test: 0.596293
PRC train: 0.789807	val: 0.674099	test: 0.608178

Epoch: 47
Loss: 0.4152912281933516
ROC train: 0.829528	val: 0.615858	test: 0.597762
PRC train: 0.794345	val: 0.678503	test: 0.610395

Epoch: 48
Loss: 0.4141713837972167
ROC train: 0.835201	val: 0.618739	test: 0.602739
PRC train: 0.797397	val: 0.684188	test: 0.612626

Epoch: 49
Loss: 0.4139916177108847
ROC train: 0.838591	val: 0.625035	test: 0.607010
PRC train: 0.799776	val: 0.687948	test: 0.614808

Epoch: 50
Loss: 0.41346843193052596
ROC train: 0.840610	val: 0.625769	test: 0.602454
PRC train: 0.801390	val: 0.683262	test: 0.613730

Epoch: 51
Loss: 0.40841772939529203
ROC train: 0.840418	val: 0.615993	test: 0.601323
PRC train: 0.802110	val: 0.671710	test: 0.612070

Epoch: 52
Loss: 0.4061320615358218
ROC train: 0.840971	val: 0.611064	test: 0.601665
PRC train: 0.804555	val: 0.673994	test: 0.614365

Epoch: 53
Loss: 0.4067534025665357
ROC train: 0.844050	val: 0.615032	test: 0.603975
PRC train: 0.808454	val: 0.675364	test: 0.618772

Epoch: 54
Loss: 0.4097093215991295
ROC train: 0.851482	val: 0.617865	test: 0.607776
PRC train: 0.812824	val: 0.677956	test: 0.619297

Epoch: 55
Loss: 0.4001137991669064
ROC train: 0.852492	val: 0.615157	test: 0.607918
PRC train: 0.812360	val: 0.681239	test: 0.616889

Epoch: 56
Loss: 0.4021908256165951
ROC train: 0.849851	val: 0.615856	test: 0.604821
PRC train: 0.809764	val: 0.683741	test: 0.611588

Epoch: 57
Loss: 0.40261165126577114
ROC train: 0.847920	val: 0.610268	test: 0.606161
PRC train: 0.809120	val: 0.679096	test: 0.608947

Epoch: 58
Loss: 0.3977585618577242
ROC train: 0.855396	val: 0.620157	test: 0.605108
PRC train: 0.817453	val: 0.685621	test: 0.614299

Epoch: 59
Loss: 0.39679420333514315
ROC train: 0.853896	val: 0.617327	test: 0.601657
PRC train: 0.816251	val: 0.682431	test: 0.613832

Epoch: 60
Loss: 0.3984454143573269
ROC train: 0.859006	val: 0.615796	test: 0.607619
PRC train: 0.817977	val: 0.682908	test: 0.616143

Epoch: 61
Loss: 0.3915486134212249
ROC train: 0.861132	val: 0.611708	test: 0.607638
PRC train: 0.819201	val: 0.676025	test: 0.615813

Epoch: 62
Loss: 0.39377985004694954
ROC train: 0.863046	val: 0.608919	test: 0.604571
PRC train: 0.820567	val: 0.671290	test: 0.614272

Epoch: 63
Loss: 0.3892334292113508
ROC train: 0.863232	val: 0.609476	test: 0.596860
PRC train: 0.822162	val: 0.671790	test: 0.609294

Epoch: 64
Loss: 0.3941601987292505
ROC train: 0.866318	val: 0.613439	test: 0.599386
PRC train: 0.826799	val: 0.676537	test: 0.610010

Epoch: 65
Loss: 0.3914663653879605
ROC train: 0.869197	val: 0.611794	test: 0.603133
PRC train: 0.829378	val: 0.674358	test: 0.608769

Epoch: 66
Loss: 0.3873793564203198
ROC train: 0.865584	val: 0.604952	test: 0.600542
PRC train: 0.825155	val: 0.669243	test: 0.608280

Epoch: 67
Loss: 0.3811661169114024
ROC train: 0.868111	val: 0.607785	test: 0.601552
PRC train: 0.829067	val: 0.673049	test: 0.604996

Epoch: 68
Loss: 0.3824619740805642
ROC train: 0.868829	val: 0.608959	test: 0.597553
PRC train: 0.831880	val: 0.670636	test: 0.600657

Epoch: 69
Loss: 0.3776301026947846
ROC train: 0.869594	val: 0.614425	test: 0.589548
PRC train: 0.831924	val: 0.672872	test: 0.601516

Epoch: 70
Loss: 0.38675693486264007
ROC train: 0.871566	val: 0.621734	test: 0.591016
PRC train: 0.832571	val: 0.680687	test: 0.605954

Epoch: 71
Loss: 0.37925795370081694
ROC train: 0.876738	val: 0.620776	test: 0.597022
PRC train: 0.837779	val: 0.678984	test: 0.608276

Epoch: 72
Loss: 0.37946835177454646
ROC train: 0.881423	val: 0.612420	test: 0.595473
PRC train: 0.840431	val: 0.672458	test: 0.607809

Epoch: 73
Loss: 0.37631849815210133
ROC train: 0.873647	val: 0.599720	test: 0.591294
PRC train: 0.832186	val: 0.665128	test: 0.606649

Epoch: 74
Loss: 0.3779785663235377
ROC train: 0.878459	val: 0.604978	test: 0.600945
PRC train: 0.840286	val: 0.669747	test: 0.614113

Epoch: 75
Loss: 0.3728901515767403
ROC train: 0.881176	val: 0.609380	test: 0.603338
PRC train: 0.842827	val: 0.674125	test: 0.615911

Epoch: 76
Loss: 0.3655245295812475
ROC train: 0.882631	val: 0.607593	test: 0.598958
PRC train: 0.846218	val: 0.674789	test: 0.613800

Epoch: 77
Loss: 0.37399745508769194
ROC train: 0.885134	val: 0.606104	test: 0.594361
PRC train: 0.847245	val: 0.670049	test: 0.616577

Epoch: 78
Loss: 0.373310408901947
ROC train: 0.887994	val: 0.608246	test: 0.589788
PRC train: 0.849779	val: 0.670476	test: 0.616003

Epoch: 79
Loss: 0.37081211859620516
ROC train: 0.881767	val: 0.612692	test: 0.587776
PRC train: 0.843333	val: 0.673764	test: 0.612503

Epoch: 80
Loss: 0.3648982191425352
ROC train: 0.888140	val: 0.612945	test: 0.600060
PRC train: 0.849013	val: 0.676738	test: 0.624730

Epoch: 81
Loss: 0.3660589699635191
ROC train: 0.892586	val: 0.612746	test: 0.607955
PRC train: 0.852096	val: 0.679468	test: 0.627783

Epoch: 82
Loss: 0.3703048834696579
ROC train: 0.893180	val: 0.611587	test: 0.602820
PRC train: 0.853499	val: 0.674810	test: 0.621635

Epoch: 83
Loss: 0.3613062067235839
ROC train: 0.890917	val: 0.603690	test: 0.597572
PRC train: 0.850273	val: 0.667497	test: 0.616614

Epoch: 84
Loss: 0.3592559734807935
ROC train: 0.896183	val: 0.610192	test: 0.600464
PRC train: 0.857304	val: 0.671528	test: 0.619746

Epoch: 85
Loss: 0.35872574068790003
ROC train: 0.897716	val: 0.616845	test: 0.605103
PRC train: 0.858874	val: 0.679053	test: 0.622028

Epoch: 86
Loss: 0.36512061140913443
ROC train: 0.897083	val: 0.612692	test: 0.606994
PRC train: 0.857832	val: 0.678083	test: 0.623658

Epoch: 87
Loss: 0.3532133675543856
ROC train: 0.898350	val: 0.609673	test: 0.607997
PRC train: 0.857772	val: 0.676971	test: 0.624422

Epoch: 88
Loss: 0.3575809442449354
ROC train: 0.898517	val: 0.612925	test: 0.608876
PRC train: 0.857400	val: 0.677249	test: 0.620686

Epoch: 89
Loss: 0.35623668882190934
ROC train: 0.900773	val: 0.610113	test: 0.608508
PRC train: 0.861743	val: 0.676310	test: 0.617537

Epoch: 90
Loss: 0.3519742667424155
ROC train: 0.899157	val: 0.603460	test: 0.608574
PRC train: 0.862497	val: 0.671522	test: 0.617621

Epoch: 91
Loss: 0.35250147153558836
ROC train: 0.903493	val: 0.607731	test: 0.612807
PRC train: 0.863580	val: 0.675700	test: 0.621118

Epoch: 92
Loss: 0.3581551277473811
ROC train: 0.902508	val: 0.608242	test: 0.609279
PRC train: 0.861674	val: 0.675483	test: 0.622558

Epoch: 93
Loss: 0.35095484304682556
ROC train: 0.905151	val: 0.610396	test: 0.606172
PRC train: 0.866927	val: 0.679067	test: 0.624058

Epoch: 94
Loss: 0.3505731927807792
ROC train: 0.903167	val: 0.608979	test: 0.607103
ROC train: 0.794620	val: 0.619939	test: 0.613224
PRC train: 0.763423	val: 0.658768	test: 0.629326

Epoch: 34
Loss: 0.43672275793336396
ROC train: 0.795245	val: 0.619127	test: 0.615521
PRC train: 0.763735	val: 0.653361	test: 0.625251

Epoch: 35
Loss: 0.43699985020523535
ROC train: 0.799507	val: 0.614970	test: 0.617539
PRC train: 0.764419	val: 0.650665	test: 0.626000

Epoch: 36
Loss: 0.43724212712093247
ROC train: 0.799264	val: 0.620109	test: 0.605702
PRC train: 0.764213	val: 0.655637	test: 0.614691

Epoch: 37
Loss: 0.43133287495844785
ROC train: 0.803400	val: 0.626652	test: 0.601866
PRC train: 0.770870	val: 0.656645	test: 0.615645

Epoch: 38
Loss: 0.4329662114734627
ROC train: 0.807610	val: 0.627029	test: 0.602995
PRC train: 0.775935	val: 0.660949	test: 0.619054

Epoch: 39
Loss: 0.429413779720237
ROC train: 0.807014	val: 0.626158	test: 0.599136
PRC train: 0.773719	val: 0.657395	test: 0.618047

Epoch: 40
Loss: 0.43354883240967934
ROC train: 0.810208	val: 0.615946	test: 0.600080
PRC train: 0.773211	val: 0.652103	test: 0.618210

Epoch: 41
Loss: 0.43013114056829255
ROC train: 0.815043	val: 0.615856	test: 0.601555
PRC train: 0.779213	val: 0.660639	test: 0.611544

Epoch: 42
Loss: 0.4292136412834993
ROC train: 0.818209	val: 0.621567	test: 0.597366
PRC train: 0.781607	val: 0.668217	test: 0.612351

Epoch: 43
Loss: 0.425245044063153
ROC train: 0.818557	val: 0.617262	test: 0.602272
PRC train: 0.783323	val: 0.663273	test: 0.611982

Epoch: 44
Loss: 0.42098927766668764
ROC train: 0.820063	val: 0.621634	test: 0.606351
PRC train: 0.783780	val: 0.667750	test: 0.614443

Epoch: 45
Loss: 0.4237537711741591
ROC train: 0.817752	val: 0.629108	test: 0.603333
PRC train: 0.782624	val: 0.669376	test: 0.619645

Epoch: 46
Loss: 0.419765816338386
ROC train: 0.824582	val: 0.616883	test: 0.602988
PRC train: 0.788618	val: 0.664386	test: 0.621639

Epoch: 47
Loss: 0.41843879108099724
ROC train: 0.820361	val: 0.593592	test: 0.613596
PRC train: 0.784695	val: 0.654071	test: 0.629271

Epoch: 48
Loss: 0.42029797007721675
ROC train: 0.824421	val: 0.599274	test: 0.609933
PRC train: 0.787838	val: 0.660646	test: 0.626810

Epoch: 49
Loss: 0.41943181184840805
ROC train: 0.826970	val: 0.606216	test: 0.610686
PRC train: 0.789091	val: 0.662309	test: 0.625181

Epoch: 50
Loss: 0.41790648852104245
ROC train: 0.831593	val: 0.608016	test: 0.606542
PRC train: 0.794597	val: 0.662757	test: 0.624864

Epoch: 51
Loss: 0.4122934408417621
ROC train: 0.832412	val: 0.602735	test: 0.595736
PRC train: 0.797376	val: 0.658653	test: 0.623595

Epoch: 52
Loss: 0.4146992255679872
ROC train: 0.835208	val: 0.605113	test: 0.600264
PRC train: 0.797798	val: 0.654272	test: 0.622505

Epoch: 53
Loss: 0.41457087684779276
ROC train: 0.839013	val: 0.609503	test: 0.618499
PRC train: 0.799979	val: 0.658310	test: 0.631027

Epoch: 54
Loss: 0.412697134177741
ROC train: 0.839515	val: 0.609459	test: 0.619596
PRC train: 0.801606	val: 0.663264	test: 0.635621

Epoch: 55
Loss: 0.4117486506040862
ROC train: 0.840117	val: 0.616466	test: 0.616534
PRC train: 0.801551	val: 0.666874	test: 0.632452

Epoch: 56
Loss: 0.41325106153016433
ROC train: 0.841210	val: 0.611053	test: 0.613299
PRC train: 0.802949	val: 0.661333	test: 0.633165

Epoch: 57
Loss: 0.40868444888794364
ROC train: 0.843649	val: 0.612451	test: 0.622345
PRC train: 0.805915	val: 0.663041	test: 0.634659

Epoch: 58
Loss: 0.40813626977975626
ROC train: 0.844062	val: 0.614758	test: 0.626871
PRC train: 0.804681	val: 0.663379	test: 0.633103

Epoch: 59
Loss: 0.4081028774123556
ROC train: 0.847410	val: 0.612227	test: 0.624519
PRC train: 0.808249	val: 0.667739	test: 0.634003

Epoch: 60
Loss: 0.40283351007044715
ROC train: 0.849757	val: 0.612927	test: 0.618207
PRC train: 0.811427	val: 0.671467	test: 0.635624

Epoch: 61
Loss: 0.40252143454993233
ROC train: 0.851814	val: 0.619942	test: 0.613515
PRC train: 0.812872	val: 0.669598	test: 0.636108

Epoch: 62
Loss: 0.4072886366900807
ROC train: 0.853168	val: 0.612284	test: 0.614333
PRC train: 0.812749	val: 0.669890	test: 0.643414

Epoch: 63
Loss: 0.3984084625723932
ROC train: 0.854431	val: 0.610954	test: 0.614926
PRC train: 0.816003	val: 0.671186	test: 0.637154

Epoch: 64
Loss: 0.3991156964585367
ROC train: 0.854817	val: 0.604996	test: 0.608724
PRC train: 0.814426	val: 0.673569	test: 0.633099

Epoch: 65
Loss: 0.39930589363228963
ROC train: 0.851529	val: 0.602613	test: 0.603289
PRC train: 0.810657	val: 0.664163	test: 0.633692

Epoch: 66
Loss: 0.39362296698352656
ROC train: 0.859994	val: 0.609056	test: 0.609529
PRC train: 0.820191	val: 0.664988	test: 0.635853

Epoch: 67
Loss: 0.3982709023857266
ROC train: 0.863169	val: 0.615994	test: 0.606181
PRC train: 0.823337	val: 0.674696	test: 0.629450

Epoch: 68
Loss: 0.3893054838204163
ROC train: 0.865634	val: 0.612817	test: 0.610473
PRC train: 0.825996	val: 0.672322	test: 0.633416

Epoch: 69
Loss: 0.39311030582197776
ROC train: 0.867931	val: 0.615687	test: 0.618021
PRC train: 0.830239	val: 0.676244	test: 0.639501

Epoch: 70
Loss: 0.3905341634171922
ROC train: 0.868256	val: 0.609115	test: 0.615902
PRC train: 0.830510	val: 0.673934	test: 0.637615

Epoch: 71
Loss: 0.39168023970615123
ROC train: 0.869465	val: 0.606600	test: 0.612373
PRC train: 0.832819	val: 0.668493	test: 0.638456

Epoch: 72
Loss: 0.39524700943055147
ROC train: 0.868193	val: 0.610284	test: 0.614026
PRC train: 0.827448	val: 0.664344	test: 0.633748

Epoch: 73
Loss: 0.3894981282954405
ROC train: 0.868728	val: 0.599297	test: 0.615718
PRC train: 0.829726	val: 0.656274	test: 0.635248

Epoch: 74
Loss: 0.38704355682150027
ROC train: 0.871657	val: 0.600480	test: 0.609799
PRC train: 0.836152	val: 0.660357	test: 0.629953

Epoch: 75
Loss: 0.3870796935955776
ROC train: 0.875155	val: 0.603099	test: 0.600694
PRC train: 0.837606	val: 0.665846	test: 0.628859

Epoch: 76
Loss: 0.3913446451504555
ROC train: 0.877127	val: 0.607990	test: 0.599511
PRC train: 0.839661	val: 0.665947	test: 0.630462

Epoch: 77
Loss: 0.38362809889953564
ROC train: 0.874645	val: 0.611614	test: 0.598805
PRC train: 0.837989	val: 0.667398	test: 0.626633

Epoch: 78
Loss: 0.37849996396148666
ROC train: 0.876590	val: 0.608966	test: 0.601320
PRC train: 0.838931	val: 0.666026	test: 0.626128

Epoch: 79
Loss: 0.37892919441926776
ROC train: 0.879585	val: 0.602226	test: 0.603194
PRC train: 0.841470	val: 0.667638	test: 0.627216

Epoch: 80
Loss: 0.3826746952793667
ROC train: 0.878558	val: 0.595164	test: 0.602558
PRC train: 0.840112	val: 0.665460	test: 0.627261

Epoch: 81
Loss: 0.3769919070630614
ROC train: 0.878059	val: 0.592257	test: 0.597704
PRC train: 0.840135	val: 0.661289	test: 0.621725

Epoch: 82
Loss: 0.3781293019885426
ROC train: 0.881859	val: 0.614080	test: 0.590750
PRC train: 0.842699	val: 0.669108	test: 0.617936

Epoch: 83
Loss: 0.37556114066156276
ROC train: 0.882898	val: 0.619226	test: 0.590438
PRC train: 0.844206	val: 0.668835	test: 0.619084

Epoch: 84
Loss: 0.3756791340983277
ROC train: 0.884167	val: 0.617241	test: 0.597265
PRC train: 0.849242	val: 0.675671	test: 0.625617

Epoch: 85
Loss: 0.37660496002252675
ROC train: 0.887118	val: 0.609416	test: 0.604794
PRC train: 0.852922	val: 0.666479	test: 0.622254

Epoch: 86
Loss: 0.37017456721537734
ROC train: 0.889401	val: 0.612369	test: 0.597421
PRC train: 0.856858	val: 0.669683	test: 0.620421

Epoch: 87
Loss: 0.3721688832732784
ROC train: 0.887023	val: 0.612809	test: 0.598459
PRC train: 0.849714	val: 0.668802	test: 0.623759

Epoch: 88
Loss: 0.37164193791051814
ROC train: 0.893389	val: 0.610789	test: 0.608015
PRC train: 0.857344	val: 0.671044	test: 0.625918

Epoch: 89
Loss: 0.3685009790830263
ROC train: 0.893713	val: 0.611348	test: 0.608389
PRC train: 0.860505	val: 0.672377	test: 0.626410

Epoch: 90
Loss: 0.36815157912217394
ROC train: 0.893146	val: 0.615210	test: 0.599124
PRC train: 0.859359	val: 0.672822	test: 0.622977

Epoch: 91
Loss: 0.3666022459900938
ROC train: 0.891425	val: 0.625332	test: 0.594367
PRC train: 0.856078	val: 0.679241	test: 0.617608

Epoch: 92
Loss: 0.36857074549649865
ROC train: 0.894996	val: 0.616140	test: 0.598364
PRC train: 0.858516	val: 0.673609	test: 0.619163

Epoch: 93
Loss: 0.3604761947349243
ROC train: 0.893779	val: 0.605601	test: 0.606826
PRC train: 0.854202	val: 0.659140	test: 0.620682

Epoch: 94
Loss: 0.36254569573332673
ROC train: 0.796202	val: 0.615551	test: 0.579950
PRC train: 0.766055	val: 0.649997	test: 0.590226

Epoch: 34
Loss: 0.4340375149909457
ROC train: 0.793934	val: 0.615416	test: 0.585618
PRC train: 0.766500	val: 0.650669	test: 0.593265

Epoch: 35
Loss: 0.43517012349795936
ROC train: 0.803246	val: 0.605588	test: 0.599474
PRC train: 0.771172	val: 0.644862	test: 0.598796

Epoch: 36
Loss: 0.4335841997748332
ROC train: 0.804842	val: 0.612167	test: 0.597889
PRC train: 0.770121	val: 0.650486	test: 0.598783

Epoch: 37
Loss: 0.4253350948083189
ROC train: 0.805465	val: 0.621722	test: 0.582092
PRC train: 0.771920	val: 0.659156	test: 0.590700

Epoch: 38
Loss: 0.43294097864287445
ROC train: 0.805435	val: 0.619256	test: 0.568608
PRC train: 0.770043	val: 0.659396	test: 0.585222

Epoch: 39
Loss: 0.4303944800113718
ROC train: 0.812925	val: 0.608464	test: 0.584322
PRC train: 0.775464	val: 0.651875	test: 0.595911

Epoch: 40
Loss: 0.42591820841863565
ROC train: 0.810100	val: 0.614687	test: 0.590710
PRC train: 0.775971	val: 0.654853	test: 0.595866

Epoch: 41
Loss: 0.4277778220448535
ROC train: 0.810543	val: 0.607522	test: 0.584473
PRC train: 0.777885	val: 0.645408	test: 0.594160

Epoch: 42
Loss: 0.4263300407301684
ROC train: 0.817331	val: 0.614151	test: 0.583695
PRC train: 0.780736	val: 0.646966	test: 0.591872

Epoch: 43
Loss: 0.43155702538161067
ROC train: 0.825074	val: 0.619969	test: 0.586677
PRC train: 0.788608	val: 0.655141	test: 0.593943

Epoch: 44
Loss: 0.422445095454442
ROC train: 0.827376	val: 0.617067	test: 0.583335
PRC train: 0.792281	val: 0.656447	test: 0.590757

Epoch: 45
Loss: 0.42100102858641797
ROC train: 0.827406	val: 0.621838	test: 0.578235
PRC train: 0.789030	val: 0.666622	test: 0.586476

Epoch: 46
Loss: 0.42027155052046705
ROC train: 0.825662	val: 0.619851	test: 0.569673
PRC train: 0.786758	val: 0.665930	test: 0.584607

Epoch: 47
Loss: 0.4201357295716891
ROC train: 0.826955	val: 0.621990	test: 0.571868
PRC train: 0.787770	val: 0.665288	test: 0.590410

Epoch: 48
Loss: 0.4196273622513285
ROC train: 0.829908	val: 0.622460	test: 0.576439
PRC train: 0.791465	val: 0.665971	test: 0.593474

Epoch: 49
Loss: 0.41781493334918346
ROC train: 0.830707	val: 0.629110	test: 0.593367
PRC train: 0.793912	val: 0.670113	test: 0.597213

Epoch: 50
Loss: 0.4175901594671174
ROC train: 0.836651	val: 0.615253	test: 0.596693
PRC train: 0.799617	val: 0.659247	test: 0.602923

Epoch: 51
Loss: 0.41037615770353775
ROC train: 0.836538	val: 0.627360	test: 0.586998
PRC train: 0.797592	val: 0.669557	test: 0.603229

Epoch: 52
Loss: 0.4180348805195792
ROC train: 0.834783	val: 0.631419	test: 0.577968
PRC train: 0.796437	val: 0.670277	test: 0.594595

Epoch: 53
Loss: 0.4142016427521445
ROC train: 0.832784	val: 0.630499	test: 0.584448
PRC train: 0.795501	val: 0.670093	test: 0.592004

Epoch: 54
Loss: 0.41195403935780195
ROC train: 0.845979	val: 0.629462	test: 0.593205
PRC train: 0.805948	val: 0.671984	test: 0.600544

Epoch: 55
Loss: 0.41208891644725976
ROC train: 0.845358	val: 0.635971	test: 0.596964
PRC train: 0.807298	val: 0.668914	test: 0.601925

Epoch: 56
Loss: 0.4087900363432036
ROC train: 0.843619	val: 0.633986	test: 0.588469
PRC train: 0.804948	val: 0.669795	test: 0.599413

Epoch: 57
Loss: 0.4092706793189772
ROC train: 0.838985	val: 0.631303	test: 0.578722
PRC train: 0.800451	val: 0.672332	test: 0.597143

Epoch: 58
Loss: 0.40912778472028044
ROC train: 0.848046	val: 0.626898	test: 0.589995
PRC train: 0.809121	val: 0.674203	test: 0.603585

Epoch: 59
Loss: 0.4037842046165929
ROC train: 0.852724	val: 0.620699	test: 0.590103
PRC train: 0.811639	val: 0.669091	test: 0.602328

Epoch: 60
Loss: 0.40523490847360055
ROC train: 0.854497	val: 0.622330	test: 0.598216
PRC train: 0.813829	val: 0.671276	test: 0.603660

Epoch: 61
Loss: 0.4034833402688759
ROC train: 0.853772	val: 0.619454	test: 0.597466
PRC train: 0.813392	val: 0.668400	test: 0.604676

Epoch: 62
Loss: 0.40466075109552124
ROC train: 0.857295	val: 0.621896	test: 0.589092
PRC train: 0.815655	val: 0.670983	test: 0.601728

Epoch: 63
Loss: 0.3977298181245903
ROC train: 0.849280	val: 0.623493	test: 0.583268
PRC train: 0.807407	val: 0.671143	test: 0.595654

Epoch: 64
Loss: 0.39369099976533406
ROC train: 0.859409	val: 0.618379	test: 0.589325
PRC train: 0.817848	val: 0.665694	test: 0.600784

Epoch: 65
Loss: 0.39555365924837393
ROC train: 0.861737	val: 0.612922	test: 0.590756
PRC train: 0.819949	val: 0.666260	test: 0.604960

Epoch: 66
Loss: 0.4007346171243841
ROC train: 0.860650	val: 0.616646	test: 0.590391
PRC train: 0.818990	val: 0.663459	test: 0.604335

Epoch: 67
Loss: 0.3880322344555743
ROC train: 0.862193	val: 0.613312	test: 0.599070
PRC train: 0.820594	val: 0.665787	test: 0.612231

Epoch: 68
Loss: 0.3950907059951494
ROC train: 0.867454	val: 0.618053	test: 0.599060
PRC train: 0.824102	val: 0.674048	test: 0.609086

Epoch: 69
Loss: 0.3924007360877662
ROC train: 0.871118	val: 0.624534	test: 0.604148
PRC train: 0.828096	val: 0.678730	test: 0.614053

Epoch: 70
Loss: 0.38746387350836387
ROC train: 0.869913	val: 0.622706	test: 0.606736
PRC train: 0.827084	val: 0.675389	test: 0.611584

Epoch: 71
Loss: 0.38628916120580065
ROC train: 0.869610	val: 0.623726	test: 0.602852
PRC train: 0.827690	val: 0.671974	test: 0.607682

Epoch: 72
Loss: 0.38151383206643213
ROC train: 0.872686	val: 0.621509	test: 0.598889
PRC train: 0.830190	val: 0.670151	test: 0.607110

Epoch: 73
Loss: 0.3788250363143572
ROC train: 0.869500	val: 0.622443	test: 0.594173
PRC train: 0.825299	val: 0.671775	test: 0.607716

Epoch: 74
Loss: 0.3867112528756358
ROC train: 0.875362	val: 0.621671	test: 0.599275
PRC train: 0.832998	val: 0.673081	test: 0.617070

Epoch: 75
Loss: 0.3872248114451061
ROC train: 0.879573	val: 0.615779	test: 0.606677
PRC train: 0.837814	val: 0.670696	test: 0.617677

Epoch: 76
Loss: 0.38958316141525423
ROC train: 0.880116	val: 0.615478	test: 0.596820
PRC train: 0.836944	val: 0.668786	test: 0.615318

Epoch: 77
Loss: 0.3733813354386406
ROC train: 0.877090	val: 0.625525	test: 0.588823
PRC train: 0.834359	val: 0.669574	test: 0.606819

Epoch: 78
Loss: 0.38127034957766354
ROC train: 0.881621	val: 0.628057	test: 0.597101
PRC train: 0.839179	val: 0.676239	test: 0.608040

Epoch: 79
Loss: 0.37624192300063486
ROC train: 0.878108	val: 0.627343	test: 0.601469
PRC train: 0.837140	val: 0.679959	test: 0.606912

Epoch: 80
Loss: 0.37677504782762566
ROC train: 0.882848	val: 0.623731	test: 0.599391
PRC train: 0.840025	val: 0.675055	test: 0.610049

Epoch: 81
Loss: 0.37782526544957246
ROC train: 0.882631	val: 0.618485	test: 0.603773
PRC train: 0.841459	val: 0.678494	test: 0.611230

Epoch: 82
Loss: 0.3758486633427489
ROC train: 0.885351	val: 0.610425	test: 0.597007
PRC train: 0.843304	val: 0.675152	test: 0.616519

Epoch: 83
Loss: 0.372199998747421
ROC train: 0.882715	val: 0.615932	test: 0.582411
PRC train: 0.841139	val: 0.676191	test: 0.611305

Epoch: 84
Loss: 0.3748541033445962
ROC train: 0.886723	val: 0.617051	test: 0.598067
PRC train: 0.847243	val: 0.676147	test: 0.614045

Epoch: 85
Loss: 0.37048808930070487
ROC train: 0.889887	val: 0.617169	test: 0.596189
PRC train: 0.850447	val: 0.674545	test: 0.609265

Epoch: 86
Loss: 0.36702036622370715
ROC train: 0.891028	val: 0.624534	test: 0.588699
PRC train: 0.850336	val: 0.674794	test: 0.605645

Epoch: 87
Loss: 0.3674319349203206
ROC train: 0.882861	val: 0.620610	test: 0.582057
PRC train: 0.838227	val: 0.674217	test: 0.603347

Epoch: 88
Loss: 0.3565541420841004
ROC train: 0.895277	val: 0.606705	test: 0.604184
PRC train: 0.853952	val: 0.664629	test: 0.617737

Epoch: 89
Loss: 0.3603118615089983
ROC train: 0.896764	val: 0.609079	test: 0.607492
PRC train: 0.854615	val: 0.667738	test: 0.620108

Epoch: 90
Loss: 0.36320185528563403
ROC train: 0.896083	val: 0.616250	test: 0.602129
PRC train: 0.852964	val: 0.674296	test: 0.617139

Epoch: 91
Loss: 0.3608530210964112
ROC train: 0.896037	val: 0.618588	test: 0.613353
PRC train: 0.853657	val: 0.674300	test: 0.619178

Epoch: 92
Loss: 0.360139680351624
ROC train: 0.897065	val: 0.627919	test: 0.607224
PRC train: 0.858689	val: 0.679185	test: 0.619858

Epoch: 93
Loss: 0.3577516105911581
ROC train: 0.895027	val: 0.622407	test: 0.599321
PRC train: 0.855744	val: 0.675605	test: 0.619845

Epoch: 94
Loss: 0.35666925898552304
PRC train: 0.757418	val: 0.652778	test: 0.605516

Epoch: 34
Loss: 0.44128313398417973
ROC train: 0.783343	val: 0.607734	test: 0.593864
PRC train: 0.750468	val: 0.646257	test: 0.608329

Epoch: 35
Loss: 0.4415966203539801
ROC train: 0.794821	val: 0.609089	test: 0.595487
PRC train: 0.764867	val: 0.639436	test: 0.606949

Epoch: 36
Loss: 0.4370513089844586
ROC train: 0.793762	val: 0.618136	test: 0.593643
PRC train: 0.766267	val: 0.646958	test: 0.605875

Epoch: 37
Loss: 0.4399752313279561
ROC train: 0.796189	val: 0.614829	test: 0.594086
PRC train: 0.766647	val: 0.647768	test: 0.606881

Epoch: 38
Loss: 0.43502965281840433
ROC train: 0.800562	val: 0.612760	test: 0.589525
PRC train: 0.770394	val: 0.641310	test: 0.605105

Epoch: 39
Loss: 0.43591221173618855
ROC train: 0.802887	val: 0.617121	test: 0.589971
PRC train: 0.772268	val: 0.648215	test: 0.606849

Epoch: 40
Loss: 0.4331365192150364
ROC train: 0.805737	val: 0.610810	test: 0.582491
PRC train: 0.773371	val: 0.650993	test: 0.602643

Epoch: 41
Loss: 0.42793813329586056
ROC train: 0.810073	val: 0.620553	test: 0.580680
PRC train: 0.775991	val: 0.653827	test: 0.600812

Epoch: 42
Loss: 0.426738378899281
ROC train: 0.814907	val: 0.625264	test: 0.581820
PRC train: 0.777839	val: 0.652536	test: 0.597393

Epoch: 43
Loss: 0.4233257131231408
ROC train: 0.816789	val: 0.623410	test: 0.587657
PRC train: 0.779953	val: 0.657944	test: 0.598356

Epoch: 44
Loss: 0.4297914011245817
ROC train: 0.817902	val: 0.624538	test: 0.581346
PRC train: 0.784056	val: 0.654326	test: 0.592914

Epoch: 45
Loss: 0.4215348733883414
ROC train: 0.819719	val: 0.632701	test: 0.573353
PRC train: 0.785461	val: 0.654890	test: 0.588441

Epoch: 46
Loss: 0.42164912874416877
ROC train: 0.823081	val: 0.615459	test: 0.574827
PRC train: 0.788171	val: 0.649154	test: 0.591403

Epoch: 47
Loss: 0.4210070545699443
ROC train: 0.822369	val: 0.622104	test: 0.575267
PRC train: 0.788791	val: 0.655694	test: 0.585692

Epoch: 48
Loss: 0.42563235123392884
ROC train: 0.821385	val: 0.624037	test: 0.575784
PRC train: 0.787907	val: 0.657913	test: 0.586480

Epoch: 49
Loss: 0.4224018462258548
ROC train: 0.822501	val: 0.617208	test: 0.574057
PRC train: 0.788745	val: 0.651503	test: 0.588327

Epoch: 50
Loss: 0.4221347851651947
ROC train: 0.831017	val: 0.621657	test: 0.576042
PRC train: 0.793859	val: 0.646948	test: 0.591069

Epoch: 51
Loss: 0.4184135210784595
ROC train: 0.828495	val: 0.637839	test: 0.582782
PRC train: 0.792627	val: 0.668217	test: 0.589597

Epoch: 52
Loss: 0.4191661662971155
ROC train: 0.827441	val: 0.638167	test: 0.577498
PRC train: 0.790614	val: 0.673719	test: 0.586462

Epoch: 53
Loss: 0.41953139977270404
ROC train: 0.831238	val: 0.633286	test: 0.578385
PRC train: 0.793399	val: 0.666681	test: 0.589897

Epoch: 54
Loss: 0.40505760381544087
ROC train: 0.836202	val: 0.630591	test: 0.582408
PRC train: 0.799220	val: 0.663944	test: 0.594253

Epoch: 55
Loss: 0.40963695001693134
ROC train: 0.839917	val: 0.633143	test: 0.583834
PRC train: 0.802933	val: 0.668135	test: 0.592909

Epoch: 56
Loss: 0.40649018245622537
ROC train: 0.843263	val: 0.630664	test: 0.583663
PRC train: 0.806055	val: 0.660203	test: 0.593197

Epoch: 57
Loss: 0.41025950954394286
ROC train: 0.846287	val: 0.630122	test: 0.587257
PRC train: 0.808516	val: 0.656357	test: 0.597489

Epoch: 58
Loss: 0.4070641459541302
ROC train: 0.842251	val: 0.618504	test: 0.587813
PRC train: 0.804298	val: 0.651801	test: 0.599211

Epoch: 59
Loss: 0.40334692206624767
ROC train: 0.848636	val: 0.620488	test: 0.589256
PRC train: 0.811712	val: 0.651571	test: 0.596584

Epoch: 60
Loss: 0.40815551368313796
ROC train: 0.845710	val: 0.625328	test: 0.585607
PRC train: 0.804671	val: 0.659880	test: 0.589462

Epoch: 61
Loss: 0.4009839163646145
ROC train: 0.844568	val: 0.622336	test: 0.578394
PRC train: 0.804393	val: 0.660945	test: 0.590218

Epoch: 62
Loss: 0.4018609808657633
ROC train: 0.851920	val: 0.635764	test: 0.583330
PRC train: 0.811184	val: 0.666783	test: 0.589724

Epoch: 63
Loss: 0.3998500727501021
ROC train: 0.853037	val: 0.632416	test: 0.574349
PRC train: 0.813130	val: 0.667502	test: 0.585080

Epoch: 64
Loss: 0.3988511130425797
ROC train: 0.853168	val: 0.628360	test: 0.569475
PRC train: 0.813371	val: 0.670265	test: 0.581704

Epoch: 65
Loss: 0.3975634480266536
ROC train: 0.856367	val: 0.621980	test: 0.580116
PRC train: 0.815518	val: 0.670064	test: 0.590299

Epoch: 66
Loss: 0.39213103020130563
ROC train: 0.858085	val: 0.612934	test: 0.585446
PRC train: 0.819536	val: 0.657232	test: 0.599597

Epoch: 67
Loss: 0.4012297496188205
ROC train: 0.859758	val: 0.623694	test: 0.588479
PRC train: 0.821928	val: 0.662977	test: 0.598822

Epoch: 68
Loss: 0.3921724803632019
ROC train: 0.859332	val: 0.633565	test: 0.587814
PRC train: 0.818895	val: 0.668729	test: 0.596162

Epoch: 69
Loss: 0.39407901161966874
ROC train: 0.863607	val: 0.630024	test: 0.588642
PRC train: 0.822924	val: 0.668750	test: 0.599345

Epoch: 70
Loss: 0.3895028145188473
ROC train: 0.867676	val: 0.625706	test: 0.596599
PRC train: 0.828108	val: 0.668392	test: 0.604711

Epoch: 71
Loss: 0.3916022904146164
ROC train: 0.868967	val: 0.620039	test: 0.587832
PRC train: 0.829448	val: 0.669451	test: 0.600186

Epoch: 72
Loss: 0.3832372698271317
ROC train: 0.867136	val: 0.622858	test: 0.585849
PRC train: 0.827687	val: 0.675134	test: 0.593853

Epoch: 73
Loss: 0.3824687229342912
ROC train: 0.869654	val: 0.634342	test: 0.579984
PRC train: 0.828256	val: 0.678693	test: 0.587304

Epoch: 74
Loss: 0.3847111493458503
ROC train: 0.868786	val: 0.640632	test: 0.587550
PRC train: 0.828415	val: 0.679041	test: 0.589447

Epoch: 75
Loss: 0.38749497556101115
ROC train: 0.873334	val: 0.638714	test: 0.587897
PRC train: 0.835140	val: 0.674006	test: 0.596218

Epoch: 76
Loss: 0.3870079524566353
ROC train: 0.875013	val: 0.628636	test: 0.577269
PRC train: 0.836997	val: 0.666231	test: 0.588884

Epoch: 77
Loss: 0.38223235233031866
ROC train: 0.874601	val: 0.630843	test: 0.583903
PRC train: 0.833170	val: 0.672215	test: 0.588518

Epoch: 78
Loss: 0.3837839446943968
ROC train: 0.875653	val: 0.639257	test: 0.586101
PRC train: 0.833561	val: 0.673404	test: 0.591434

Epoch: 79
Loss: 0.38409055836074985
ROC train: 0.877230	val: 0.638475	test: 0.573579
PRC train: 0.837651	val: 0.672534	test: 0.585800

Epoch: 80
Loss: 0.37979850941280774
ROC train: 0.879741	val: 0.636492	test: 0.573876
PRC train: 0.840566	val: 0.678097	test: 0.587917

Epoch: 81
Loss: 0.3808833160764464
ROC train: 0.881779	val: 0.626782	test: 0.583785
PRC train: 0.841289	val: 0.669216	test: 0.597057

Epoch: 82
Loss: 0.3688681346541823
ROC train: 0.882311	val: 0.623471	test: 0.588636
PRC train: 0.843223	val: 0.669025	test: 0.597221

Epoch: 83
Loss: 0.3788678898023866
ROC train: 0.880760	val: 0.616976	test: 0.586643
PRC train: 0.839823	val: 0.669836	test: 0.594025

Epoch: 84
Loss: 0.37458849713322034
ROC train: 0.883633	val: 0.622562	test: 0.582925
PRC train: 0.846105	val: 0.666194	test: 0.595016

Epoch: 85
Loss: 0.3728318932111156
ROC train: 0.880708	val: 0.628966	test: 0.581684
PRC train: 0.843026	val: 0.671368	test: 0.595681

Epoch: 86
Loss: 0.37218191247681826
ROC train: 0.882667	val: 0.636339	test: 0.581714
PRC train: 0.847129	val: 0.672369	test: 0.592315

Epoch: 87
Loss: 0.3715163881276068
ROC train: 0.887012	val: 0.639400	test: 0.583650
PRC train: 0.850187	val: 0.672245	test: 0.591624

Epoch: 88
Loss: 0.36676673001423893
ROC train: 0.888937	val: 0.630324	test: 0.578396
PRC train: 0.852903	val: 0.666012	test: 0.591958

Epoch: 89
Loss: 0.36316684908516217
ROC train: 0.894043	val: 0.636159	test: 0.578324
PRC train: 0.857203	val: 0.672288	test: 0.592468

Epoch: 90
Loss: 0.3685799411358402
ROC train: 0.893513	val: 0.636173	test: 0.584008
PRC train: 0.854213	val: 0.671604	test: 0.594304

Epoch: 91
Loss: 0.366030949850401
ROC train: 0.892908	val: 0.631437	test: 0.581311
PRC train: 0.855854	val: 0.672355	test: 0.590919

Epoch: 92
Loss: 0.36350775884698844
ROC train: 0.890938	val: 0.619368	test: 0.575658
PRC train: 0.854170	val: 0.667352	test: 0.589688

Epoch: 93
Loss: 0.36583705813555006
ROC train: 0.893480	val: 0.623455	test: 0.582921
PRC train: 0.858723	val: 0.668833	test: 0.596023

Epoch: 94
Loss: 0.36396965617772625
ROC train: 0.895035	val: 0.634922	test: 0.586569
ROC train: 0.899226	val: 0.626746	test: 0.613392
PRC train: 0.860172	val: 0.663436	test: 0.636606

Epoch: 95
Loss: 0.3483741553419989
ROC train: 0.902586	val: 0.625402	test: 0.618723
PRC train: 0.863165	val: 0.661564	test: 0.638517

Epoch: 96
Loss: 0.35058939519812965
ROC train: 0.907219	val: 0.625969	test: 0.616034
PRC train: 0.867846	val: 0.664071	test: 0.636633

Epoch: 97
Loss: 0.3437631893000298
ROC train: 0.907437	val: 0.626680	test: 0.616653
PRC train: 0.867919	val: 0.664472	test: 0.634017

Epoch: 98
Loss: 0.3494467497483087
ROC train: 0.906075	val: 0.622786	test: 0.611463
PRC train: 0.868425	val: 0.661697	test: 0.629178

Epoch: 99
Loss: 0.3457312261362624
ROC train: 0.904465	val: 0.618551	test: 0.601726
PRC train: 0.869712	val: 0.658225	test: 0.626792

Epoch: 100
Loss: 0.3519551608151097
ROC train: 0.911878	val: 0.619627	test: 0.609148
PRC train: 0.875592	val: 0.662648	test: 0.632169

Epoch: 101
Loss: 0.3437960657143689
ROC train: 0.910171	val: 0.618215	test: 0.616592
PRC train: 0.874771	val: 0.663828	test: 0.637630

Epoch: 102
Loss: 0.34275919091699747
ROC train: 0.910782	val: 0.625375	test: 0.614138
PRC train: 0.874073	val: 0.667114	test: 0.635251

Epoch: 103
Loss: 0.35500661512763027
ROC train: 0.911046	val: 0.625126	test: 0.607924
PRC train: 0.873920	val: 0.663710	test: 0.631378

Epoch: 104
Loss: 0.34137527261428835
ROC train: 0.912475	val: 0.630238	test: 0.609399
PRC train: 0.875553	val: 0.664628	test: 0.633805

Epoch: 105
Loss: 0.3398550172302556
ROC train: 0.914437	val: 0.631760	test: 0.614103
PRC train: 0.879093	val: 0.664871	test: 0.635901

Epoch: 106
Loss: 0.3375552287884713
ROC train: 0.915395	val: 0.628373	test: 0.618553
PRC train: 0.878124	val: 0.663720	test: 0.641220

Epoch: 107
Loss: 0.3427483898530049
ROC train: 0.915508	val: 0.623468	test: 0.615508
PRC train: 0.880684	val: 0.663971	test: 0.637488

Epoch: 108
Loss: 0.3370719358634303
ROC train: 0.909088	val: 0.625303	test: 0.607874
PRC train: 0.875257	val: 0.662265	test: 0.627978

Epoch: 109
Loss: 0.33541674124567017
ROC train: 0.913776	val: 0.628288	test: 0.609941
PRC train: 0.879922	val: 0.663762	test: 0.631896

Epoch: 110
Loss: 0.3363405815950793
ROC train: 0.919386	val: 0.634088	test: 0.618715
PRC train: 0.885188	val: 0.669476	test: 0.636809

Epoch: 111
Loss: 0.32923827563979136
ROC train: 0.920533	val: 0.635530	test: 0.623060
PRC train: 0.884657	val: 0.666000	test: 0.637598

Epoch: 112
Loss: 0.3412194637174082
ROC train: 0.920222	val: 0.623387	test: 0.616853
PRC train: 0.884622	val: 0.657780	test: 0.634021

Epoch: 113
Loss: 0.3308875427194351
ROC train: 0.919758	val: 0.619385	test: 0.612606
PRC train: 0.883240	val: 0.658455	test: 0.631660

Epoch: 114
Loss: 0.3358196317727866
ROC train: 0.923095	val: 0.622257	test: 0.608932
PRC train: 0.888839	val: 0.665227	test: 0.630304

Epoch: 115
Loss: 0.33070828621113046
ROC train: 0.924303	val: 0.627612	test: 0.608361
PRC train: 0.890009	val: 0.667678	test: 0.633235

Epoch: 116
Loss: 0.3277311420165665
ROC train: 0.923243	val: 0.628463	test: 0.611729
PRC train: 0.890761	val: 0.665425	test: 0.636942

Epoch: 117
Loss: 0.33338630710685146
ROC train: 0.922604	val: 0.632117	test: 0.614237
PRC train: 0.891322	val: 0.665667	test: 0.638748

Epoch: 118
Loss: 0.3209851773824691
ROC train: 0.923806	val: 0.633902	test: 0.611233
PRC train: 0.892731	val: 0.666598	test: 0.636907

Epoch: 119
Loss: 0.3329182818177357
ROC train: 0.927974	val: 0.635996	test: 0.611845
PRC train: 0.895233	val: 0.669852	test: 0.635811

Epoch: 120
Loss: 0.32338174858988367
ROC train: 0.927988	val: 0.631550	test: 0.615420
PRC train: 0.896083	val: 0.666208	test: 0.635223

Early stopping
Best (ROC):	 train: 0.790286	val: 0.640670	test: 0.616656
Best (PRC):	 train: 0.754083	val: 0.685558	test: 0.622601

ROC train: 0.900715	val: 0.626823	test: 0.598827
PRC train: 0.860594	val: 0.664220	test: 0.617930

Epoch: 95
Loss: 0.36492622069248065
ROC train: 0.901894	val: 0.626355	test: 0.602208
PRC train: 0.859576	val: 0.661909	test: 0.621581

Epoch: 96
Loss: 0.36112812697272245
ROC train: 0.902129	val: 0.626068	test: 0.604375
PRC train: 0.860085	val: 0.657659	test: 0.624848

Epoch: 97
Loss: 0.3494628027167354
ROC train: 0.901947	val: 0.625460	test: 0.606207
PRC train: 0.860652	val: 0.656201	test: 0.627207

Epoch: 98
Loss: 0.351863867970299
ROC train: 0.903530	val: 0.629073	test: 0.606678
PRC train: 0.862470	val: 0.658484	test: 0.627621

Epoch: 99
Loss: 0.349156120134825
ROC train: 0.903252	val: 0.630297	test: 0.602511
PRC train: 0.864068	val: 0.660522	test: 0.622608

Epoch: 100
Loss: 0.3440413598992866
ROC train: 0.905184	val: 0.630283	test: 0.601945
PRC train: 0.866205	val: 0.663265	test: 0.618557

Epoch: 101
Loss: 0.3537428791080782
ROC train: 0.907371	val: 0.630588	test: 0.601632
PRC train: 0.866546	val: 0.663764	test: 0.617524

Epoch: 102
Loss: 0.3561610826934484
ROC train: 0.909063	val: 0.629834	test: 0.601481
PRC train: 0.870115	val: 0.660705	test: 0.618389

Epoch: 103
Loss: 0.3451052597766635
ROC train: 0.908052	val: 0.628166	test: 0.602413
PRC train: 0.868250	val: 0.655701	test: 0.617877

Epoch: 104
Loss: 0.35008978604665164
ROC train: 0.907858	val: 0.625177	test: 0.595727
PRC train: 0.865749	val: 0.655518	test: 0.615461

Epoch: 105
Loss: 0.3476031001434005
ROC train: 0.909453	val: 0.623587	test: 0.589998
PRC train: 0.867258	val: 0.657445	test: 0.613749

Epoch: 106
Loss: 0.3454821160062788
ROC train: 0.911385	val: 0.627889	test: 0.594860
PRC train: 0.869247	val: 0.662592	test: 0.618451

Epoch: 107
Loss: 0.3497268257335759
ROC train: 0.915487	val: 0.631109	test: 0.598522
PRC train: 0.874742	val: 0.661456	test: 0.617263

Epoch: 108
Loss: 0.3491938810962845
ROC train: 0.915657	val: 0.629796	test: 0.600682
PRC train: 0.876980	val: 0.660226	test: 0.616183

Epoch: 109
Loss: 0.3434644894331931
ROC train: 0.914492	val: 0.623251	test: 0.602161
PRC train: 0.875711	val: 0.657573	test: 0.616446

Epoch: 110
Loss: 0.3437976154670681
ROC train: 0.915297	val: 0.622571	test: 0.603520
PRC train: 0.876032	val: 0.657177	test: 0.620060

Epoch: 111
Loss: 0.3427366751618687
ROC train: 0.916527	val: 0.625693	test: 0.606719
PRC train: 0.876920	val: 0.660099	test: 0.623534

Epoch: 112
Loss: 0.33605368609034225
ROC train: 0.917249	val: 0.624426	test: 0.607122
PRC train: 0.878379	val: 0.660840	test: 0.623774

Epoch: 113
Loss: 0.3316735089588937
ROC train: 0.915484	val: 0.624352	test: 0.603690
PRC train: 0.877396	val: 0.660262	test: 0.623845

Epoch: 114
Loss: 0.32871069619466264
ROC train: 0.916593	val: 0.627088	test: 0.602087
PRC train: 0.879759	val: 0.658808	test: 0.623000

Epoch: 115
Loss: 0.32913505989558917
ROC train: 0.921559	val: 0.633546	test: 0.604456
PRC train: 0.884008	val: 0.663731	test: 0.624838

Epoch: 116
Loss: 0.3453432174179445
ROC train: 0.920134	val: 0.629629	test: 0.599413
PRC train: 0.884933	val: 0.662232	test: 0.622871

Epoch: 117
Loss: 0.3417937929435184
ROC train: 0.919181	val: 0.632066	test: 0.600692
PRC train: 0.886189	val: 0.666939	test: 0.624483

Epoch: 118
Loss: 0.33380492023111147
ROC train: 0.919926	val: 0.635198	test: 0.605578
PRC train: 0.887249	val: 0.669625	test: 0.625495

Epoch: 119
Loss: 0.32669244437286626
ROC train: 0.918927	val: 0.634306	test: 0.605461
PRC train: 0.887252	val: 0.665953	test: 0.625130

Epoch: 120
Loss: 0.33031180628160894
ROC train: 0.924825	val: 0.634174	test: 0.608169
PRC train: 0.892496	val: 0.663989	test: 0.626014

Early stopping
Best (ROC):	 train: 0.873488	val: 0.641093	test: 0.602007
Best (PRC):	 train: 0.830150	val: 0.668569	test: 0.615895

ROC train: 0.902778	val: 0.595385	test: 0.606242
PRC train: 0.859385	val: 0.664542	test: 0.620204

Epoch: 95
Loss: 0.35042704255760265
ROC train: 0.907069	val: 0.605755	test: 0.605204
PRC train: 0.867269	val: 0.671674	test: 0.618076

Epoch: 96
Loss: 0.35097028810479525
ROC train: 0.905912	val: 0.609961	test: 0.594764
PRC train: 0.864975	val: 0.671100	test: 0.613801

Epoch: 97
Loss: 0.34773756782135173
ROC train: 0.906049	val: 0.610302	test: 0.597133
PRC train: 0.866065	val: 0.670536	test: 0.616281

Epoch: 98
Loss: 0.3481646938978278
ROC train: 0.907829	val: 0.608480	test: 0.601524
PRC train: 0.867604	val: 0.670201	test: 0.618798

Epoch: 99
Loss: 0.3489184295220258
ROC train: 0.909004	val: 0.605618	test: 0.604447
PRC train: 0.867237	val: 0.673051	test: 0.619836

Epoch: 100
Loss: 0.3513643187428391
ROC train: 0.908798	val: 0.600859	test: 0.597250
PRC train: 0.867471	val: 0.671270	test: 0.614324

Epoch: 101
Loss: 0.3413790016725892
ROC train: 0.908915	val: 0.601966	test: 0.593925
PRC train: 0.868667	val: 0.667382	test: 0.609566

Epoch: 102
Loss: 0.33824126525346065
ROC train: 0.913442	val: 0.613266	test: 0.600575
PRC train: 0.873546	val: 0.674624	test: 0.617651

Epoch: 103
Loss: 0.3417599886877003
ROC train: 0.913997	val: 0.614503	test: 0.600936
PRC train: 0.874516	val: 0.673160	test: 0.618255

Epoch: 104
Loss: 0.34243587016725024
ROC train: 0.912865	val: 0.603225	test: 0.598087
PRC train: 0.871713	val: 0.665555	test: 0.615610

Epoch: 105
Loss: 0.34362337353061073
ROC train: 0.917376	val: 0.602012	test: 0.595750
PRC train: 0.875846	val: 0.664746	test: 0.615158

Epoch: 106
Loss: 0.3364496243789263
ROC train: 0.917073	val: 0.606409	test: 0.605192
PRC train: 0.875694	val: 0.664749	test: 0.620184

Epoch: 107
Loss: 0.341585062668872
ROC train: 0.918350	val: 0.603806	test: 0.605284
PRC train: 0.877713	val: 0.664043	test: 0.620265

Epoch: 108
Loss: 0.3345294658505501
ROC train: 0.916993	val: 0.604841	test: 0.602932
PRC train: 0.876121	val: 0.665317	test: 0.619440

Epoch: 109
Loss: 0.33289429745075155
ROC train: 0.913279	val: 0.603115	test: 0.603980
PRC train: 0.871376	val: 0.666959	test: 0.618035

Epoch: 110
Loss: 0.3331883285823627
ROC train: 0.919491	val: 0.605820	test: 0.608353
PRC train: 0.878082	val: 0.668273	test: 0.622188

Epoch: 111
Loss: 0.3334982086447619
ROC train: 0.922716	val: 0.611331	test: 0.605381
PRC train: 0.881735	val: 0.669201	test: 0.622928

Epoch: 112
Loss: 0.33378458461274724
ROC train: 0.922604	val: 0.614237	test: 0.607244
PRC train: 0.883386	val: 0.669565	test: 0.619358

Epoch: 113
Loss: 0.33310849330756576
ROC train: 0.919185	val: 0.609494	test: 0.596789
PRC train: 0.882417	val: 0.665049	test: 0.614184

Epoch: 114
Loss: 0.3317929420551563
ROC train: 0.922502	val: 0.608185	test: 0.591823
PRC train: 0.883221	val: 0.662833	test: 0.612936

Epoch: 115
Loss: 0.32914366415975777
ROC train: 0.924929	val: 0.609694	test: 0.595535
PRC train: 0.887136	val: 0.666653	test: 0.616700

Epoch: 116
Loss: 0.3290831595323745
ROC train: 0.926442	val: 0.612825	test: 0.599575
PRC train: 0.889256	val: 0.665567	test: 0.616835

Epoch: 117
Loss: 0.3237728255175002
ROC train: 0.924144	val: 0.608199	test: 0.600141
PRC train: 0.885841	val: 0.661653	test: 0.619073

Epoch: 118
Loss: 0.32758156756868334
ROC train: 0.924992	val: 0.604470	test: 0.602350
PRC train: 0.886099	val: 0.663961	test: 0.620686

Epoch: 119
Loss: 0.3231644905571258
ROC train: 0.927775	val: 0.610230	test: 0.602012
PRC train: 0.889149	val: 0.670532	test: 0.620817

Epoch: 120
Loss: 0.32741972211390613
ROC train: 0.927047	val: 0.606581	test: 0.596147
PRC train: 0.889748	val: 0.666843	test: 0.615797

Early stopping
Best (ROC):	 train: 0.814520	val: 0.624301	test: 0.601662
Best (PRC):	 train: 0.774666	val: 0.685220	test: 0.610123


Epoch: 95
Loss: 0.34856561783884443
ROC train: 0.906102	val: 0.602883	test: 0.611456
PRC train: 0.865194	val: 0.673616	test: 0.625025

Epoch: 96
Loss: 0.3456002229987985
ROC train: 0.906468	val: 0.598836	test: 0.608176
PRC train: 0.865867	val: 0.674433	test: 0.621712

Epoch: 97
Loss: 0.34934016758433317
ROC train: 0.908069	val: 0.596646	test: 0.610523
PRC train: 0.866994	val: 0.666854	test: 0.622603

Epoch: 98
Loss: 0.3450564535748914
ROC train: 0.909620	val: 0.598844	test: 0.602736
PRC train: 0.870966	val: 0.668999	test: 0.621734

Epoch: 99
Loss: 0.343728153771631
ROC train: 0.910334	val: 0.606318	test: 0.604706
PRC train: 0.870562	val: 0.676829	test: 0.621796

Epoch: 100
Loss: 0.3432137531595297
ROC train: 0.910659	val: 0.607032	test: 0.610870
PRC train: 0.871052	val: 0.678325	test: 0.622398

Epoch: 101
Loss: 0.3463126952447865
ROC train: 0.911995	val: 0.598246	test: 0.605518
PRC train: 0.872663	val: 0.673157	test: 0.619980

Epoch: 102
Loss: 0.33919553802216684
ROC train: 0.910739	val: 0.601303	test: 0.599931
PRC train: 0.870949	val: 0.671295	test: 0.614432

Epoch: 103
Loss: 0.3422415214069654
ROC train: 0.912222	val: 0.602981	test: 0.601430
PRC train: 0.872699	val: 0.669381	test: 0.617560

Epoch: 104
Loss: 0.34004968800067925
ROC train: 0.913215	val: 0.600940	test: 0.606951
PRC train: 0.872483	val: 0.672019	test: 0.620817

Epoch: 105
Loss: 0.3403710365838952
ROC train: 0.912683	val: 0.602173	test: 0.605492
PRC train: 0.871198	val: 0.678784	test: 0.614808

Epoch: 106
Loss: 0.3391420520681803
ROC train: 0.914603	val: 0.606531	test: 0.603362
PRC train: 0.872635	val: 0.679680	test: 0.614947

Epoch: 107
Loss: 0.3407448539803143
ROC train: 0.916489	val: 0.610700	test: 0.603017
PRC train: 0.877192	val: 0.680698	test: 0.615313

Epoch: 108
Loss: 0.3378738120768613
ROC train: 0.918917	val: 0.610357	test: 0.607164
PRC train: 0.882280	val: 0.678437	test: 0.619319

Epoch: 109
Loss: 0.3326420326192092
ROC train: 0.917964	val: 0.606751	test: 0.603384
PRC train: 0.877702	val: 0.675944	test: 0.619441

Epoch: 110
Loss: 0.3279535290657868
ROC train: 0.918168	val: 0.602517	test: 0.601451
PRC train: 0.879415	val: 0.675411	test: 0.619727

Epoch: 111
Loss: 0.33105081981352413
ROC train: 0.920243	val: 0.607619	test: 0.607654
PRC train: 0.881012	val: 0.677622	test: 0.626514

Epoch: 112
Loss: 0.32773830853608305
ROC train: 0.921625	val: 0.605305	test: 0.607761
PRC train: 0.884911	val: 0.671771	test: 0.626037

Epoch: 113
Loss: 0.32985359404269926
ROC train: 0.924219	val: 0.605328	test: 0.607152
PRC train: 0.887035	val: 0.673118	test: 0.624715

Epoch: 114
Loss: 0.3226688814558706
ROC train: 0.925585	val: 0.602243	test: 0.609793
PRC train: 0.888028	val: 0.673074	test: 0.623289

Epoch: 115
Loss: 0.3289405954053515
ROC train: 0.926257	val: 0.603290	test: 0.608765
PRC train: 0.889217	val: 0.675968	test: 0.625442

Epoch: 116
Loss: 0.3215407129798297
ROC train: 0.926830	val: 0.613530	test: 0.611128
PRC train: 0.890319	val: 0.682151	test: 0.624565

Epoch: 117
Loss: 0.31960331372204553
ROC train: 0.927738	val: 0.611337	test: 0.614385
PRC train: 0.892459	val: 0.680714	test: 0.627383

Epoch: 118
Loss: 0.32780173185690087
ROC train: 0.928576	val: 0.606486	test: 0.610575
PRC train: 0.893842	val: 0.679613	test: 0.625851

Epoch: 119
Loss: 0.3201241354145178
ROC train: 0.928109	val: 0.603367	test: 0.606939
PRC train: 0.891772	val: 0.679059	test: 0.620694

Epoch: 120
Loss: 0.3204194037284435
ROC train: 0.928502	val: 0.600584	test: 0.604495
PRC train: 0.893330	val: 0.674951	test: 0.619990

Early stopping
Best (ROC):	 train: 0.867499	val: 0.619216	test: 0.598450
Best (PRC):	 train: 0.819786	val: 0.685624	test: 0.607925

PRC train: 0.864276	val: 0.672960	test: 0.615239

Epoch: 95
Loss: 0.3532960198487043
ROC train: 0.900870	val: 0.601173	test: 0.603577
PRC train: 0.863135	val: 0.667425	test: 0.616456

Epoch: 96
Loss: 0.3435272170213289
ROC train: 0.904030	val: 0.604149	test: 0.604498
PRC train: 0.865426	val: 0.670061	test: 0.623918

Epoch: 97
Loss: 0.3504706296626444
ROC train: 0.908824	val: 0.612840	test: 0.608587
PRC train: 0.868753	val: 0.679958	test: 0.625288

Epoch: 98
Loss: 0.349652766492311
ROC train: 0.908952	val: 0.607128	test: 0.610077
PRC train: 0.871498	val: 0.674057	test: 0.627340

Epoch: 99
Loss: 0.34697782837443153
ROC train: 0.907947	val: 0.600992	test: 0.602874
PRC train: 0.872407	val: 0.666582	test: 0.623247

Epoch: 100
Loss: 0.35248559534321267
ROC train: 0.912057	val: 0.610143	test: 0.605367
PRC train: 0.876415	val: 0.669989	test: 0.622371

Epoch: 101
Loss: 0.3411302572786589
ROC train: 0.913575	val: 0.611800	test: 0.611274
PRC train: 0.876649	val: 0.671880	test: 0.626535

Epoch: 102
Loss: 0.34707564882135833
ROC train: 0.912559	val: 0.602451	test: 0.611725
PRC train: 0.875477	val: 0.666832	test: 0.624076

Epoch: 103
Loss: 0.34359614919637516
ROC train: 0.913089	val: 0.600253	test: 0.609525
PRC train: 0.875658	val: 0.669649	test: 0.621296

Epoch: 104
Loss: 0.33663684655725723
ROC train: 0.916217	val: 0.606118	test: 0.607560
PRC train: 0.880648	val: 0.677122	test: 0.617637

Epoch: 105
Loss: 0.33587937929264244
ROC train: 0.917800	val: 0.613805	test: 0.607138
PRC train: 0.882419	val: 0.681024	test: 0.618686

Epoch: 106
Loss: 0.33131557341868084
ROC train: 0.918583	val: 0.611137	test: 0.604448
PRC train: 0.882006	val: 0.676165	test: 0.619703

Epoch: 107
Loss: 0.3332114523250709
ROC train: 0.920811	val: 0.610717	test: 0.607351
PRC train: 0.883201	val: 0.675674	test: 0.619911

Epoch: 108
Loss: 0.32882647952655447
ROC train: 0.921423	val: 0.615635	test: 0.608229
PRC train: 0.885836	val: 0.683993	test: 0.619466

Epoch: 109
Loss: 0.3325299930657698
ROC train: 0.920774	val: 0.614662	test: 0.606668
PRC train: 0.886225	val: 0.686672	test: 0.619167

Epoch: 110
Loss: 0.3286244310629965
ROC train: 0.920394	val: 0.602451	test: 0.608495
PRC train: 0.886905	val: 0.676941	test: 0.624282

Epoch: 111
Loss: 0.32746887074631514
ROC train: 0.918910	val: 0.598370	test: 0.613420
PRC train: 0.883935	val: 0.670253	test: 0.629092

Epoch: 112
Loss: 0.3343001732944987
ROC train: 0.924259	val: 0.606820	test: 0.616067
PRC train: 0.889951	val: 0.675665	test: 0.629823

Epoch: 113
Loss: 0.3295303558161281
ROC train: 0.925244	val: 0.610637	test: 0.619547
PRC train: 0.891744	val: 0.676886	test: 0.629875

Epoch: 114
Loss: 0.3280170267090181
ROC train: 0.927886	val: 0.613567	test: 0.622647
PRC train: 0.893214	val: 0.672855	test: 0.630966

Epoch: 115
Loss: 0.32436981880288507
ROC train: 0.928688	val: 0.615970	test: 0.617512
PRC train: 0.894400	val: 0.674975	test: 0.631487

Epoch: 116
Loss: 0.32102558434763745
ROC train: 0.929171	val: 0.617441	test: 0.614866
PRC train: 0.897079	val: 0.678330	test: 0.632274

Epoch: 117
Loss: 0.32371158594349125
ROC train: 0.929158	val: 0.613752	test: 0.611767
PRC train: 0.898142	val: 0.673941	test: 0.630067

Epoch: 118
Loss: 0.3218540189148514
ROC train: 0.931040	val: 0.615141	test: 0.614685
PRC train: 0.896963	val: 0.672970	test: 0.628660

Epoch: 119
Loss: 0.3181137016011121
ROC train: 0.932153	val: 0.613028	test: 0.612421
PRC train: 0.900105	val: 0.669949	test: 0.626235

Epoch: 120
Loss: 0.31451030268740987
ROC train: 0.933750	val: 0.609215	test: 0.607210
PRC train: 0.903051	val: 0.673102	test: 0.628899

Early stopping
Best (ROC):	 train: 0.840610	val: 0.625769	test: 0.602454
Best (PRC):	 train: 0.801390	val: 0.683262	test: 0.613730
All runs completed.

ROC train: 0.897291	val: 0.622456	test: 0.599689
PRC train: 0.857565	val: 0.676480	test: 0.609004

Epoch: 95
Loss: 0.3654318529655459
ROC train: 0.900515	val: 0.623221	test: 0.602669
PRC train: 0.861461	val: 0.678456	test: 0.607773

Epoch: 96
Loss: 0.3580627721816822
ROC train: 0.900347	val: 0.619286	test: 0.606105
PRC train: 0.861563	val: 0.678349	test: 0.612625

Epoch: 97
Loss: 0.35941823182119814
ROC train: 0.899239	val: 0.612990	test: 0.603513
PRC train: 0.861641	val: 0.671059	test: 0.623249

Epoch: 98
Loss: 0.36216502660147615
ROC train: 0.902866	val: 0.607490	test: 0.617850
PRC train: 0.863610	val: 0.665076	test: 0.631100

Epoch: 99
Loss: 0.3592699065427279
ROC train: 0.905757	val: 0.616274	test: 0.622792
PRC train: 0.866569	val: 0.668268	test: 0.632139

Epoch: 100
Loss: 0.3552794265843535
ROC train: 0.904984	val: 0.616087	test: 0.618047
PRC train: 0.867287	val: 0.670485	test: 0.630216

Epoch: 101
Loss: 0.35224513481506153
ROC train: 0.906362	val: 0.618157	test: 0.606786
PRC train: 0.867448	val: 0.672030	test: 0.621841

Epoch: 102
Loss: 0.353376440579349
ROC train: 0.907593	val: 0.614238	test: 0.599698
PRC train: 0.871262	val: 0.671524	test: 0.614730

Epoch: 103
Loss: 0.3499874934387556
ROC train: 0.909742	val: 0.618535	test: 0.601763
PRC train: 0.874773	val: 0.671101	test: 0.616474

Epoch: 104
Loss: 0.3491976480772342
ROC train: 0.908471	val: 0.615134	test: 0.605728
PRC train: 0.874345	val: 0.674144	test: 0.617860

Epoch: 105
Loss: 0.34830233986330217
ROC train: 0.907462	val: 0.606884	test: 0.612814
PRC train: 0.872849	val: 0.666431	test: 0.626793

Epoch: 106
Loss: 0.3420375426020882
ROC train: 0.910039	val: 0.607771	test: 0.603410
PRC train: 0.876017	val: 0.669673	test: 0.629325

Epoch: 107
Loss: 0.3474999680725071
ROC train: 0.909083	val: 0.614963	test: 0.594145
PRC train: 0.873784	val: 0.677176	test: 0.623248

Epoch: 108
Loss: 0.35500056901612564
ROC train: 0.912142	val: 0.619711	test: 0.600068
PRC train: 0.875834	val: 0.678650	test: 0.626485

Epoch: 109
Loss: 0.3420273685403402
ROC train: 0.907566	val: 0.620446	test: 0.613214
PRC train: 0.870079	val: 0.677072	test: 0.631053

Epoch: 110
Loss: 0.34666280853624637
ROC train: 0.915643	val: 0.626692	test: 0.619261
PRC train: 0.880757	val: 0.683528	test: 0.632385

Epoch: 111
Loss: 0.3424195477494326
ROC train: 0.915201	val: 0.631774	test: 0.607796
PRC train: 0.880697	val: 0.686637	test: 0.622460

Epoch: 112
Loss: 0.347515626435604
ROC train: 0.915083	val: 0.628353	test: 0.601063
PRC train: 0.878770	val: 0.685689	test: 0.616707

Epoch: 113
Loss: 0.3397885006027949
ROC train: 0.914844	val: 0.628731	test: 0.605999
PRC train: 0.878533	val: 0.684660	test: 0.614907

Epoch: 114
Loss: 0.3329726203179083
ROC train: 0.919111	val: 0.626441	test: 0.608780
PRC train: 0.883857	val: 0.683214	test: 0.627062

Epoch: 115
Loss: 0.33201272612103694
ROC train: 0.916971	val: 0.627188	test: 0.605230
PRC train: 0.882475	val: 0.682134	test: 0.631032

Epoch: 116
Loss: 0.33867502291470675
ROC train: 0.921096	val: 0.625894	test: 0.605651
PRC train: 0.889148	val: 0.680824	test: 0.626101

Epoch: 117
Loss: 0.3353910878804671
ROC train: 0.921484	val: 0.623582	test: 0.607776
PRC train: 0.889069	val: 0.679806	test: 0.626807

Epoch: 118
Loss: 0.3374284556898869
ROC train: 0.920185	val: 0.619364	test: 0.609279
PRC train: 0.888073	val: 0.677952	test: 0.626382

Epoch: 119
Loss: 0.3354329315100281
ROC train: 0.922726	val: 0.614879	test: 0.613267
PRC train: 0.889056	val: 0.673842	test: 0.626664

Epoch: 120
Loss: 0.33048194123226227
ROC train: 0.924511	val: 0.624042	test: 0.616369
PRC train: 0.892879	val: 0.675893	test: 0.626195

Early stopping
Best (ROC):	 train: 0.845358	val: 0.635971	test: 0.596964
Best (PRC):	 train: 0.807298	val: 0.668914	test: 0.601925

ROC train: 0.901286	val: 0.616798	test: 0.609504
PRC train: 0.864540	val: 0.662605	test: 0.618936

Epoch: 95
Loss: 0.3630221960646455
ROC train: 0.900788	val: 0.622462	test: 0.607870
PRC train: 0.865057	val: 0.663913	test: 0.617481

Epoch: 96
Loss: 0.36272005862747714
ROC train: 0.902068	val: 0.622906	test: 0.609669
PRC train: 0.865716	val: 0.665902	test: 0.620308

Epoch: 97
Loss: 0.3561748764825745
ROC train: 0.902642	val: 0.609649	test: 0.609708
PRC train: 0.867113	val: 0.659348	test: 0.622932

Epoch: 98
Loss: 0.357270902828604
ROC train: 0.903764	val: 0.605477	test: 0.611379
PRC train: 0.867419	val: 0.653764	test: 0.623254

Epoch: 99
Loss: 0.3520768744450215
ROC train: 0.906792	val: 0.615195	test: 0.615436
PRC train: 0.873492	val: 0.658854	test: 0.626432

Epoch: 100
Loss: 0.34786704090224907
ROC train: 0.905389	val: 0.614034	test: 0.613228
PRC train: 0.871012	val: 0.658021	test: 0.628494

Epoch: 101
Loss: 0.3452783769993385
ROC train: 0.908523	val: 0.623943	test: 0.615224
PRC train: 0.871295	val: 0.664489	test: 0.628988

Epoch: 102
Loss: 0.3498692335706623
ROC train: 0.911489	val: 0.624974	test: 0.616728
PRC train: 0.877618	val: 0.664041	test: 0.630566

Epoch: 103
Loss: 0.35053898209583206
ROC train: 0.912372	val: 0.616748	test: 0.612930
PRC train: 0.878073	val: 0.658650	test: 0.630621

Epoch: 104
Loss: 0.35014236245408614
ROC train: 0.911559	val: 0.612633	test: 0.607489
PRC train: 0.876037	val: 0.657026	test: 0.627747

Epoch: 105
Loss: 0.34244944690058743
ROC train: 0.910620	val: 0.614816	test: 0.602941
PRC train: 0.874863	val: 0.660792	test: 0.624681

Epoch: 106
Loss: 0.34824825374468993
ROC train: 0.911717	val: 0.613513	test: 0.599237
PRC train: 0.876143	val: 0.661740	test: 0.620716

Epoch: 107
Loss: 0.34818814671822984
ROC train: 0.911366	val: 0.615448	test: 0.601926
PRC train: 0.881657	val: 0.663116	test: 0.621772

Epoch: 108
Loss: 0.3417767035112793
ROC train: 0.915212	val: 0.622339	test: 0.612731
PRC train: 0.884655	val: 0.667432	test: 0.630090

Epoch: 109
Loss: 0.33897085306236097
ROC train: 0.914263	val: 0.622068	test: 0.615872
PRC train: 0.883465	val: 0.666509	test: 0.634017

Epoch: 110
Loss: 0.34342813051826654
ROC train: 0.915822	val: 0.618512	test: 0.617124
PRC train: 0.885094	val: 0.660156	test: 0.632894

Epoch: 111
Loss: 0.34811988610692346
ROC train: 0.915557	val: 0.606721	test: 0.613256
PRC train: 0.885302	val: 0.650603	test: 0.628826

Epoch: 112
Loss: 0.3437841390321282
ROC train: 0.917097	val: 0.606705	test: 0.609177
PRC train: 0.885213	val: 0.652506	test: 0.625817

Epoch: 113
Loss: 0.34064584754088667
ROC train: 0.918333	val: 0.617307	test: 0.607146
PRC train: 0.882446	val: 0.658074	test: 0.625052

Epoch: 114
Loss: 0.34748003673594197
ROC train: 0.914544	val: 0.616201	test: 0.610399
PRC train: 0.880866	val: 0.656962	test: 0.625383

Epoch: 115
Loss: 0.33594267927875554
ROC train: 0.917629	val: 0.612541	test: 0.615749
PRC train: 0.884262	val: 0.657325	test: 0.627597

Epoch: 116
Loss: 0.3401997496937556
ROC train: 0.920843	val: 0.614724	test: 0.613022
PRC train: 0.887724	val: 0.661666	test: 0.629745

Epoch: 117
Loss: 0.347001618255452
ROC train: 0.920199	val: 0.606882	test: 0.607072
PRC train: 0.890078	val: 0.655615	test: 0.630150

Epoch: 118
Loss: 0.33186672203891643
ROC train: 0.914696	val: 0.611080	test: 0.604446
PRC train: 0.880134	val: 0.656865	test: 0.631253

Epoch: 119
Loss: 0.32867799096527645
ROC train: 0.916114	val: 0.622693	test: 0.605045
PRC train: 0.882114	val: 0.662209	test: 0.631237

Epoch: 120
Loss: 0.3369271367524392
ROC train: 0.923759	val: 0.628470	test: 0.609732
PRC train: 0.890648	val: 0.667150	test: 0.629689

Epoch: 121
Loss: 0.3305286840555053
ROC train: 0.923874	val: 0.625635	test: 0.608337
PRC train: 0.892735	val: 0.669377	test: 0.626046

Epoch: 122
Loss: 0.33606738492791133
ROC train: 0.924826	val: 0.619396	test: 0.611062
PRC train: 0.893835	val: 0.663492	test: 0.630754

Epoch: 123
Loss: 0.33045618546043526
ROC train: 0.923659	val: 0.617142	test: 0.614503
PRC train: 0.891203	val: 0.656835	test: 0.633875

Epoch: 124
Loss: 0.3321557445917236
ROC train: 0.922826	val: 0.616636	test: 0.613732
PRC train: 0.891748	val: 0.655874	test: 0.635332

Epoch: 125
Loss: 0.334353347200364
ROC train: 0.926464	val: 0.625103	test: 0.615527
PRC train: 0.895687	val: 0.660950	test: 0.635201

Epoch: 126
Loss: 0.33517657794905775
ROC train: 0.927878	val: 0.621022	test: 0.617196
PRC train: 0.897530	val: 0.659832	test: 0.633848

Epoch: 127
Loss: 0.32926172584985713
ROC train: 0.928513	val: 0.615610	test: 0.614240
PRC train: 0.901419	val: 0.660058	test: 0.628819

Epoch: 128
Loss: 0.3195703614241902
ROC train: 0.927387	val: 0.609754	test: 0.611079
PRC train: 0.900150	val: 0.657268	test: 0.627164

Epoch: 129
Loss: 0.32815363113935464
ROC train: 0.929543	val: 0.605793	test: 0.606452
PRC train: 0.902295	val: 0.652741	test: 0.627022

Epoch: 130
Loss: 0.32787234646733626
ROC train: 0.928312	val: 0.605312	test: 0.605111
PRC train: 0.903442	val: 0.648495	test: 0.628816

Epoch: 131
Loss: 0.3186013363755372
ROC train: 0.931841	val: 0.612401	test: 0.610213
PRC train: 0.904920	val: 0.654107	test: 0.629203

Epoch: 132
Loss: 0.3271328450089939
ROC train: 0.932916	val: 0.613487	test: 0.611182
PRC train: 0.905455	val: 0.654498	test: 0.628131

Epoch: 133
Loss: 0.3187366288879309
ROC train: 0.929974	val: 0.611245	test: 0.613634
PRC train: 0.903609	val: 0.652904	test: 0.630559

Epoch: 134
Loss: 0.3148847803795824
ROC train: 0.929636	val: 0.614575	test: 0.613244
PRC train: 0.902085	val: 0.657099	test: 0.629717

Epoch: 135
Loss: 0.3090879788520306
ROC train: 0.933353	val: 0.620518	test: 0.613030
PRC train: 0.905810	val: 0.660631	test: 0.629181

Epoch: 136
Loss: 0.3206053691556918
ROC train: 0.937514	val: 0.624163	test: 0.615758
PRC train: 0.909922	val: 0.661758	test: 0.628783

Epoch: 137
Loss: 0.31077693532169004
ROC train: 0.934970	val: 0.618770	test: 0.618059
PRC train: 0.907246	val: 0.657005	test: 0.629032

Epoch: 138
Loss: 0.30883305954776513
ROC train: 0.939222	val: 0.616495	test: 0.614400
PRC train: 0.911967	val: 0.657611	test: 0.629687

Epoch: 139
Loss: 0.30811192760518524
ROC train: 0.939181	val: 0.617181	test: 0.611303
PRC train: 0.911254	val: 0.658881	test: 0.629494

Epoch: 140
Loss: 0.3039136580853703
ROC train: 0.940318	val: 0.618447	test: 0.612964
PRC train: 0.914223	val: 0.660260	test: 0.628014

Epoch: 141
Loss: 0.3061105624761359
ROC train: 0.940076	val: 0.616966	test: 0.611362
PRC train: 0.914273	val: 0.660304	test: 0.627018

Epoch: 142
Loss: 0.3121694855312728
ROC train: 0.940683	val: 0.623461	test: 0.613555
PRC train: 0.917050	val: 0.664410	test: 0.626295

Epoch: 143
Loss: 0.30712443440891307
ROC train: 0.941206	val: 0.615473	test: 0.616221
PRC train: 0.918850	val: 0.659297	test: 0.625493

Epoch: 144
Loss: 0.3065739118615177
ROC train: 0.942276	val: 0.619132	test: 0.615486
PRC train: 0.918032	val: 0.662194	test: 0.625244

Epoch: 145
Loss: 0.30516028289877195
ROC train: 0.940268	val: 0.622251	test: 0.611067
PRC train: 0.915137	val: 0.662397	test: 0.624785

Epoch: 146
Loss: 0.30209149544980274
ROC train: 0.942758	val: 0.626322	test: 0.608961
PRC train: 0.918624	val: 0.665569	test: 0.624912

Epoch: 147
Loss: 0.3047056229341444
ROC train: 0.943054	val: 0.622963	test: 0.609814
PRC train: 0.916020	val: 0.665597	test: 0.624987

Epoch: 148
Loss: 0.2996421257107399
ROC train: 0.941319	val: 0.614768	test: 0.614411
PRC train: 0.915352	val: 0.661065	test: 0.625055

Epoch: 149
Loss: 0.3000763737366893
ROC train: 0.945007	val: 0.616383	test: 0.613954
PRC train: 0.919000	val: 0.659329	test: 0.626941

Epoch: 150
Loss: 0.29866911922524503
ROC train: 0.945135	val: 0.620733	test: 0.607615
PRC train: 0.919087	val: 0.658078	test: 0.630072

Epoch: 151
Loss: 0.29520891734823745
ROC train: 0.949659	val: 0.619303	test: 0.609310
PRC train: 0.924789	val: 0.658569	test: 0.627594

Epoch: 152
Loss: 0.3016783311203537
ROC train: 0.948766	val: 0.616846	test: 0.608501
PRC train: 0.926827	val: 0.657418	test: 0.623917

Epoch: 153
Loss: 0.29762096993233056
ROC train: 0.947310	val: 0.617548	test: 0.608005
PRC train: 0.926809	val: 0.657366	test: 0.624732

Epoch: 154
Loss: 0.3034649761323389
ROC train: 0.949422	val: 0.626644	test: 0.618010
PRC train: 0.929239	val: 0.662426	test: 0.628461
PRC train: 0.862978	val: 0.673294	test: 0.601230

Epoch: 95
Loss: 0.36268006534629427
ROC train: 0.894756	val: 0.645622	test: 0.583824
PRC train: 0.859506	val: 0.680525	test: 0.596274

Epoch: 96
Loss: 0.3612088952809739
ROC train: 0.895754	val: 0.640840	test: 0.581368
PRC train: 0.861692	val: 0.681542	test: 0.592284

Epoch: 97
Loss: 0.36250255965549966
ROC train: 0.899361	val: 0.631255	test: 0.578731
PRC train: 0.866033	val: 0.674412	test: 0.590799

Epoch: 98
Loss: 0.35546231500222125
ROC train: 0.894795	val: 0.623307	test: 0.581744
PRC train: 0.857901	val: 0.674149	test: 0.588154

Epoch: 99
Loss: 0.3619800341615195
ROC train: 0.900973	val: 0.631590	test: 0.580326
PRC train: 0.864183	val: 0.674181	test: 0.590925

Epoch: 100
Loss: 0.35520831841119976
ROC train: 0.899498	val: 0.638669	test: 0.586629
PRC train: 0.864520	val: 0.674553	test: 0.596262

Epoch: 101
Loss: 0.3581265657999819
ROC train: 0.897855	val: 0.633927	test: 0.581158
PRC train: 0.863896	val: 0.672682	test: 0.594336

Epoch: 102
Loss: 0.35583321883816177
ROC train: 0.898834	val: 0.636034	test: 0.580708
PRC train: 0.862241	val: 0.671451	test: 0.593629

Epoch: 103
Loss: 0.35682501468783084
ROC train: 0.903191	val: 0.635804	test: 0.583943
PRC train: 0.867703	val: 0.677560	test: 0.596977

Epoch: 104
Loss: 0.354517860490168
ROC train: 0.906319	val: 0.634387	test: 0.583033
PRC train: 0.872452	val: 0.675102	test: 0.597970

Epoch: 105
Loss: 0.3525533912421964
ROC train: 0.909348	val: 0.633980	test: 0.580038
PRC train: 0.875654	val: 0.675668	test: 0.592353

Epoch: 106
Loss: 0.34510148111303207
ROC train: 0.908705	val: 0.627333	test: 0.577140
PRC train: 0.876868	val: 0.672830	test: 0.588500

Epoch: 107
Loss: 0.3531004021517369
ROC train: 0.909485	val: 0.625996	test: 0.574294
PRC train: 0.877948	val: 0.671492	test: 0.588192

Epoch: 108
Loss: 0.34885986154700693
ROC train: 0.911097	val: 0.636421	test: 0.573136
PRC train: 0.879500	val: 0.673591	test: 0.589340

Epoch: 109
Loss: 0.3455487982718291
ROC train: 0.910385	val: 0.637636	test: 0.573488
PRC train: 0.876208	val: 0.675012	test: 0.588055

Epoch: 110
Loss: 0.3444024416046691
ROC train: 0.914637	val: 0.633644	test: 0.574996
PRC train: 0.882445	val: 0.674564	test: 0.586978

Epoch: 111
Loss: 0.3363858185660804
ROC train: 0.913388	val: 0.621316	test: 0.570555
PRC train: 0.882069	val: 0.670043	test: 0.585535

Epoch: 112
Loss: 0.3449038802974873
ROC train: 0.914018	val: 0.618886	test: 0.574320
PRC train: 0.882239	val: 0.666495	test: 0.587805

Epoch: 113
Loss: 0.34047658178258733
ROC train: 0.916041	val: 0.625023	test: 0.580105
PRC train: 0.883554	val: 0.670224	test: 0.590478

Epoch: 114
Loss: 0.3357726976530892
ROC train: 0.915568	val: 0.636183	test: 0.583090
PRC train: 0.883232	val: 0.676049	test: 0.593916

Epoch: 115
Loss: 0.33839144829981066
ROC train: 0.911860	val: 0.640988	test: 0.578971
PRC train: 0.882498	val: 0.682309	test: 0.593533

Epoch: 116
Loss: 0.337297305828662
ROC train: 0.914476	val: 0.635495	test: 0.582347
PRC train: 0.884839	val: 0.680367	test: 0.597304

Epoch: 117
Loss: 0.3389985040890157
ROC train: 0.918013	val: 0.638919	test: 0.585051
PRC train: 0.888922	val: 0.682666	test: 0.601866

Epoch: 118
Loss: 0.33456376946516614
ROC train: 0.918898	val: 0.641416	test: 0.583195
PRC train: 0.888644	val: 0.682709	test: 0.597316

Epoch: 119
Loss: 0.340922191557557
ROC train: 0.919836	val: 0.628934	test: 0.578242
PRC train: 0.889563	val: 0.676372	test: 0.591433

Epoch: 120
Loss: 0.34127643323755763
ROC train: 0.918587	val: 0.624810	test: 0.582423
PRC train: 0.888908	val: 0.676418	test: 0.590565

Epoch: 121
Loss: 0.3359897421901566
ROC train: 0.919468	val: 0.623721	test: 0.587740
PRC train: 0.887109	val: 0.678167	test: 0.594379

Epoch: 122
Loss: 0.3369332253042055
ROC train: 0.926197	val: 0.629131	test: 0.585736
PRC train: 0.896285	val: 0.676135	test: 0.599139

Epoch: 123
Loss: 0.32525349534398657
ROC train: 0.922975	val: 0.631624	test: 0.589048
PRC train: 0.893639	val: 0.676527	test: 0.600465

Epoch: 124
Loss: 0.33079067968635
ROC train: 0.926911	val: 0.635592	test: 0.593502
PRC train: 0.896116	val: 0.677751	test: 0.603571

Epoch: 125
Loss: 0.325415899645794
ROC train: 0.925063	val: 0.640230	test: 0.591770
PRC train: 0.894708	val: 0.678272	test: 0.602035

Epoch: 126
Loss: 0.32251213356856534
ROC train: 0.927183	val: 0.635678	test: 0.588089
PRC train: 0.899926	val: 0.677769	test: 0.600495

Epoch: 127
Loss: 0.3255393293249119
ROC train: 0.925692	val: 0.631482	test: 0.586197
PRC train: 0.899451	val: 0.678484	test: 0.600528

Epoch: 128
Loss: 0.3276979036075959
ROC train: 0.929303	val: 0.633266	test: 0.593686
PRC train: 0.900845	val: 0.681047	test: 0.607777

Epoch: 129
Loss: 0.3196821427526746
ROC train: 0.928901	val: 0.636446	test: 0.601602
PRC train: 0.899266	val: 0.679206	test: 0.607045

Epoch: 130
Loss: 0.3197886098193169
ROC train: 0.930349	val: 0.635834	test: 0.601916
PRC train: 0.901993	val: 0.680134	test: 0.610053

Early stopping
Best (ROC):	 train: 0.894756	val: 0.645622	test: 0.583824
Best (PRC):	 train: 0.859506	val: 0.680525	test: 0.596274


Epoch: 155
Loss: 0.2927676954448508
ROC train: 0.950094	val: 0.623922	test: 0.618713
PRC train: 0.929969	val: 0.663892	test: 0.627102

Early stopping
Best (ROC):	 train: 0.923759	val: 0.628470	test: 0.609732
Best (PRC):	 train: 0.890648	val: 0.667150	test: 0.629689
All runs completed.

ROC train: 0.897269	val: 0.608681	test: 0.606194
PRC train: 0.862252	val: 0.664272	test: 0.621531

Epoch: 95
Loss: 0.36502076793025673
ROC train: 0.895274	val: 0.605735	test: 0.601216
PRC train: 0.860817	val: 0.663456	test: 0.623059

Epoch: 96
Loss: 0.35698586527499804
ROC train: 0.899791	val: 0.606203	test: 0.599908
PRC train: 0.867452	val: 0.655147	test: 0.616457

Epoch: 97
Loss: 0.3567454500078562
ROC train: 0.897165	val: 0.605540	test: 0.603965
PRC train: 0.863020	val: 0.659311	test: 0.612539

Epoch: 98
Loss: 0.36013250762321086
ROC train: 0.901590	val: 0.615197	test: 0.607652
PRC train: 0.865936	val: 0.666331	test: 0.616354

Epoch: 99
Loss: 0.35769760405274453
ROC train: 0.903280	val: 0.620450	test: 0.601310
PRC train: 0.869361	val: 0.668481	test: 0.615377

Epoch: 100
Loss: 0.3568802958624803
ROC train: 0.906097	val: 0.611765	test: 0.600079
PRC train: 0.871779	val: 0.660346	test: 0.612289

Epoch: 101
Loss: 0.35908244536246847
ROC train: 0.903792	val: 0.613664	test: 0.596199
PRC train: 0.871453	val: 0.659576	test: 0.610690

Epoch: 102
Loss: 0.3514525074660748
ROC train: 0.905330	val: 0.622629	test: 0.597138
PRC train: 0.872299	val: 0.670370	test: 0.614333

Epoch: 103
Loss: 0.3521816038341517
ROC train: 0.907321	val: 0.625705	test: 0.604444
PRC train: 0.872613	val: 0.673426	test: 0.622423

Epoch: 104
Loss: 0.35389737587478776
ROC train: 0.907381	val: 0.613410	test: 0.602262
PRC train: 0.869862	val: 0.667133	test: 0.619277

Epoch: 105
Loss: 0.35308882127140806
ROC train: 0.904976	val: 0.612644	test: 0.599141
PRC train: 0.870373	val: 0.666614	test: 0.622770

Epoch: 106
Loss: 0.3527116805173559
ROC train: 0.910062	val: 0.622753	test: 0.604762
PRC train: 0.875874	val: 0.675919	test: 0.621888

Epoch: 107
Loss: 0.3528469153814539
ROC train: 0.908393	val: 0.625712	test: 0.605650
PRC train: 0.871627	val: 0.677169	test: 0.623730

Epoch: 108
Loss: 0.34812339649451185
ROC train: 0.913268	val: 0.618227	test: 0.603179
PRC train: 0.876709	val: 0.670275	test: 0.627068

Epoch: 109
Loss: 0.3496136553781489
ROC train: 0.913886	val: 0.620836	test: 0.600596
PRC train: 0.879370	val: 0.670300	test: 0.625108

Epoch: 110
Loss: 0.33765648552393757
ROC train: 0.914384	val: 0.620046	test: 0.604120
PRC train: 0.882581	val: 0.670077	test: 0.624583

Epoch: 111
Loss: 0.3444012676023567
ROC train: 0.914309	val: 0.616469	test: 0.605936
PRC train: 0.883578	val: 0.669452	test: 0.618629

Epoch: 112
Loss: 0.3405322683489011
ROC train: 0.914324	val: 0.622172	test: 0.609951
PRC train: 0.882290	val: 0.672968	test: 0.618810

Epoch: 113
Loss: 0.34340444131506226
ROC train: 0.914003	val: 0.628374	test: 0.606804
PRC train: 0.881804	val: 0.670278	test: 0.620932

Epoch: 114
Loss: 0.3410791956317201
ROC train: 0.914689	val: 0.632019	test: 0.597329
PRC train: 0.881973	val: 0.676941	test: 0.616790

Epoch: 115
Loss: 0.33942131332117426
ROC train: 0.917777	val: 0.628830	test: 0.597050
PRC train: 0.882594	val: 0.679368	test: 0.617934

Epoch: 116
Loss: 0.33530580304216845
ROC train: 0.918500	val: 0.618010	test: 0.597111
PRC train: 0.883263	val: 0.668741	test: 0.614699

Epoch: 117
Loss: 0.33660774293603074
ROC train: 0.920520	val: 0.622117	test: 0.598311
PRC train: 0.889887	val: 0.665803	test: 0.616719

Epoch: 118
Loss: 0.336317783063401
ROC train: 0.923075	val: 0.625722	test: 0.606133
PRC train: 0.892750	val: 0.668992	test: 0.622309

Epoch: 119
Loss: 0.3323454212292671
ROC train: 0.924441	val: 0.625417	test: 0.607926
PRC train: 0.895785	val: 0.671894	test: 0.624153

Epoch: 120
Loss: 0.33384336176948437
ROC train: 0.924055	val: 0.625592	test: 0.603584
PRC train: 0.895510	val: 0.671843	test: 0.620548

Epoch: 121
Loss: 0.3274043047302536
ROC train: 0.921169	val: 0.617599	test: 0.592317
PRC train: 0.892772	val: 0.669618	test: 0.609028

Epoch: 122
Loss: 0.32910647007294314
ROC train: 0.922232	val: 0.615688	test: 0.582179
PRC train: 0.891228	val: 0.668992	test: 0.604486

Epoch: 123
Loss: 0.33544743960352974
ROC train: 0.926233	val: 0.626082	test: 0.592155
PRC train: 0.898453	val: 0.673498	test: 0.609956

Epoch: 124
Loss: 0.32811116549919817
ROC train: 0.928877	val: 0.629400	test: 0.607040
PRC train: 0.899103	val: 0.672929	test: 0.618449

Epoch: 125
Loss: 0.32617874184397544
ROC train: 0.928335	val: 0.621813	test: 0.609853
PRC train: 0.899572	val: 0.672760	test: 0.620795

Epoch: 126
Loss: 0.3221618262093679
ROC train: 0.926309	val: 0.622880	test: 0.595320
PRC train: 0.898976	val: 0.675240	test: 0.617065

Epoch: 127
Loss: 0.32622721974468993
ROC train: 0.929471	val: 0.632627	test: 0.596668
PRC train: 0.902660	val: 0.676783	test: 0.616853

Epoch: 128
Loss: 0.3277783931434176
ROC train: 0.927496	val: 0.630076	test: 0.610585
PRC train: 0.899438	val: 0.675737	test: 0.623702

Epoch: 129
Loss: 0.32577335262438895
ROC train: 0.931453	val: 0.630449	test: 0.608053
PRC train: 0.903146	val: 0.676207	test: 0.622799

Epoch: 130
Loss: 0.3276928543242881
ROC train: 0.930927	val: 0.634827	test: 0.605099
PRC train: 0.902343	val: 0.672921	test: 0.622315

Epoch: 131
Loss: 0.3191458141796411
ROC train: 0.927071	val: 0.629745	test: 0.606410
PRC train: 0.898597	val: 0.677524	test: 0.625876

Epoch: 132
Loss: 0.32458421737260734
ROC train: 0.933366	val: 0.622320	test: 0.614720
PRC train: 0.906542	val: 0.674722	test: 0.631331

Epoch: 133
Loss: 0.31686402579319206
ROC train: 0.931485	val: 0.621808	test: 0.611955
PRC train: 0.904897	val: 0.672390	test: 0.626325

Epoch: 134
Loss: 0.3154658711758045
ROC train: 0.933854	val: 0.627884	test: 0.614701
PRC train: 0.905942	val: 0.671357	test: 0.630545

Epoch: 135
Loss: 0.31932049188119943
ROC train: 0.935861	val: 0.628419	test: 0.608278
PRC train: 0.906493	val: 0.664510	test: 0.623072

Epoch: 136
Loss: 0.3169617333027979
ROC train: 0.935865	val: 0.625146	test: 0.607251
PRC train: 0.908102	val: 0.665400	test: 0.617238

Epoch: 137
Loss: 0.31629908316331623
ROC train: 0.936866	val: 0.622758	test: 0.613608
PRC train: 0.909699	val: 0.670849	test: 0.619928

Epoch: 138
Loss: 0.31137101724123994
ROC train: 0.936992	val: 0.632668	test: 0.615787
PRC train: 0.909334	val: 0.674640	test: 0.623456

Epoch: 139
Loss: 0.31638676319570036
ROC train: 0.937847	val: 0.634482	test: 0.611903
PRC train: 0.910408	val: 0.674907	test: 0.622087

Epoch: 140
Loss: 0.3130406994096706
ROC train: 0.936811	val: 0.632740	test: 0.614353
PRC train: 0.909138	val: 0.673432	test: 0.621589

Epoch: 141
Loss: 0.3084764231762041
ROC train: 0.939741	val: 0.632106	test: 0.610255
PRC train: 0.913142	val: 0.676410	test: 0.621592

Epoch: 142
Loss: 0.3139968167585373
ROC train: 0.937008	val: 0.634477	test: 0.600125
PRC train: 0.906745	val: 0.679745	test: 0.619955

Epoch: 143
Loss: 0.3094812163690376
ROC train: 0.939625	val: 0.625737	test: 0.608541
PRC train: 0.911266	val: 0.677869	test: 0.617035

Epoch: 144
Loss: 0.3081927740082312
ROC train: 0.940601	val: 0.629246	test: 0.610138
PRC train: 0.912444	val: 0.674712	test: 0.618058

Epoch: 145
Loss: 0.30459465505367267
ROC train: 0.940718	val: 0.636332	test: 0.604592
PRC train: 0.913072	val: 0.676685	test: 0.616402

Epoch: 146
Loss: 0.3014210146959378
ROC train: 0.938500	val: 0.629090	test: 0.602546
PRC train: 0.910251	val: 0.674740	test: 0.619404

Epoch: 147
Loss: 0.30648883425391243
ROC train: 0.942218	val: 0.624495	test: 0.609191
PRC train: 0.915356	val: 0.668928	test: 0.624206

Epoch: 148
Loss: 0.3070125091902322
ROC train: 0.943360	val: 0.631526	test: 0.606563
PRC train: 0.919076	val: 0.671019	test: 0.623920

Epoch: 149
Loss: 0.3044656804249307
ROC train: 0.943853	val: 0.634253	test: 0.607440
PRC train: 0.917242	val: 0.671782	test: 0.622937

Epoch: 150
Loss: 0.30048030490140865
ROC train: 0.945397	val: 0.631113	test: 0.609657
PRC train: 0.918842	val: 0.672647	test: 0.622683

Epoch: 151
Loss: 0.2995712777457194
ROC train: 0.947243	val: 0.634791	test: 0.603099
PRC train: 0.921684	val: 0.676983	test: 0.623051

Epoch: 152
Loss: 0.3062548190436126
ROC train: 0.946420	val: 0.637412	test: 0.603933
PRC train: 0.921685	val: 0.682141	test: 0.618636

Epoch: 153
Loss: 0.30140934787917883
ROC train: 0.947022	val: 0.632353	test: 0.612708
PRC train: 0.923106	val: 0.673452	test: 0.627063

Epoch: 154
Loss: 0.2980835836982346
ROC train: 0.946123	val: 0.630921	test: 0.614933
PRC train: 0.923270	val: 0.672295	test: 0.630373

Epoch: 155
Loss: 0.29382007052991377
ROC train: 0.948831	val: 0.636736	test: 0.613223
PRC train: 0.924499	val: 0.669945	test: 0.627614

Epoch: 156
Loss: 0.29541628671335807
ROC train: 0.949550	val: 0.638839	test: 0.607671
PRC train: 0.925921	val: 0.673095	test: 0.624039

Epoch: 157
Loss: 0.29650706768128154
ROC train: 0.950372	val: 0.638901	test: 0.609851
PRC train: 0.926669	val: 0.675262	test: 0.627763

Epoch: 158
Loss: 0.2930316704518007
ROC train: 0.951427	val: 0.629501	test: 0.611385
PRC train: 0.927112	val: 0.668602	test: 0.628803

Epoch: 159
Loss: 0.2949172447309155
ROC train: 0.949610	val: 0.627006	test: 0.604899
PRC train: 0.927532	val: 0.668740	test: 0.620763

Epoch: 160
Loss: 0.29458872304579053
ROC train: 0.951921	val: 0.626462	test: 0.604443
PRC train: 0.928523	val: 0.664830	test: 0.621743

Epoch: 161
Loss: 0.2944041951804251
ROC train: 0.952145	val: 0.644701	test: 0.596872
PRC train: 0.927340	val: 0.680338	test: 0.615873

Epoch: 162
Loss: 0.28808018974410005
ROC train: 0.953017	val: 0.638408	test: 0.595259
PRC train: 0.926017	val: 0.678436	test: 0.612424

Epoch: 163
Loss: 0.2823776524436586
ROC train: 0.953133	val: 0.629412	test: 0.600851
PRC train: 0.925740	val: 0.670064	test: 0.616695

Epoch: 164
Loss: 0.28674961634089646
ROC train: 0.954297	val: 0.630698	test: 0.607553
PRC train: 0.929953	val: 0.674534	test: 0.623133

Epoch: 165
Loss: 0.2922382581996481
ROC train: 0.954601	val: 0.639493	test: 0.605506
PRC train: 0.932213	val: 0.679562	test: 0.620436

Epoch: 166
Loss: 0.2861286654938346
ROC train: 0.954006	val: 0.633254	test: 0.609087
PRC train: 0.930744	val: 0.674392	test: 0.620858

Epoch: 167
Loss: 0.279410180578957
ROC train: 0.952535	val: 0.633774	test: 0.606691
PRC train: 0.930544	val: 0.680549	test: 0.621027

Epoch: 168
Loss: 0.28627273009742027
ROC train: 0.954481	val: 0.637299	test: 0.601285
PRC train: 0.931588	val: 0.681920	test: 0.614991

Epoch: 169
Loss: 0.282157991059906
ROC train: 0.955521	val: 0.626260	test: 0.606859
PRC train: 0.933976	val: 0.670420	test: 0.618272

Epoch: 170
Loss: 0.282683922690478
ROC train: 0.955088	val: 0.619629	test: 0.604365
PRC train: 0.934548	val: 0.663510	test: 0.624119

Epoch: 171
Loss: 0.2833969600739139
ROC train: 0.957802	val: 0.624030	test: 0.600841
PRC train: 0.937367	val: 0.665069	test: 0.620904

Epoch: 172
Loss: 0.28092968540637275
ROC train: 0.956402	val: 0.625125	test: 0.607433
PRC train: 0.934376	val: 0.666415	test: 0.623055

Epoch: 173
Loss: 0.28103926888736325
ROC train: 0.954128	val: 0.628665	test: 0.604010
PRC train: 0.933368	val: 0.673798	test: 0.625805

Epoch: 174
Loss: 0.28031759061630074
ROC train: 0.959605	val: 0.632703	test: 0.609568
PRC train: 0.940322	val: 0.668957	test: 0.624103

Epoch: 175
Loss: 0.27644005840207425
ROC train: 0.958198	val: 0.637073	test: 0.605401
PRC train: 0.938388	val: 0.677296	test: 0.618374

Epoch: 176
Loss: 0.28182183697152885
ROC train: 0.959145	val: 0.632045	test: 0.604360
PRC train: 0.938881	val: 0.676524	test: 0.620182

Epoch: 177
Loss: 0.27501878942035035
ROC train: 0.959592	val: 0.622278	test: 0.611302
PRC train: 0.938481	val: 0.668341	test: 0.625420

Epoch: 178
Loss: 0.2791023536958193
ROC train: 0.960127	val: 0.629124	test: 0.611075
PRC train: 0.940482	val: 0.678615	test: 0.627755

Epoch: 179
Loss: 0.2739676716100411
ROC train: 0.960424	val: 0.633606	test: 0.600605
PRC train: 0.940585	val: 0.681440	test: 0.623769

Epoch: 180
Loss: 0.27934486426745864
ROC train: 0.962262	val: 0.628508	test: 0.598281
PRC train: 0.943942	val: 0.675204	test: 0.619870

Epoch: 181
Loss: 0.2757463789859952
ROC train: 0.962851	val: 0.624511	test: 0.604543
PRC train: 0.945780	val: 0.672282	test: 0.620195

Epoch: 182
Loss: 0.27131065691617096
ROC train: 0.963318	val: 0.637368	test: 0.609170
PRC train: 0.944728	val: 0.676309	test: 0.622617

Epoch: 183
Loss: 0.2670567586912903
ROC train: 0.964267	val: 0.639000	test: 0.607019
PRC train: 0.944195	val: 0.680439	test: 0.627272

Epoch: 184
Loss: 0.2679917661863058
ROC train: 0.964791	val: 0.636814	test: 0.604984
PRC train: 0.947142	val: 0.680093	test: 0.619925

Epoch: 185
Loss: 0.26624463501408896
ROC train: 0.964491	val: 0.633318	test: 0.603800
PRC train: 0.947404	val: 0.676526	test: 0.618294

Epoch: 186
Loss: 0.2633376512981273
ROC train: 0.965383	val: 0.632123	test: 0.604981
PRC train: 0.946889	val: 0.674808	test: 0.622620

Epoch: 187
Loss: 0.263445871987927
ROC train: 0.962838	val: 0.634581	test: 0.602406
PRC train: 0.943590	val: 0.672776	test: 0.627775

Epoch: 188
Loss: 0.26196005124731736
ROC train: 0.966661	val: 0.638935	test: 0.607963
PRC train: 0.948341	val: 0.677166	test: 0.626089

Epoch: 189
Loss: 0.26273227401212945
ROC train: 0.967012	val: 0.638456	test: 0.606881
PRC train: 0.949841	val: 0.679813	test: 0.625391

Epoch: 190
Loss: 0.2636891199763742
ROC train: 0.967583	val: 0.638281	test: 0.602936
PRC train: 0.951032	val: 0.678611	test: 0.623187

Epoch: 191
Loss: 0.25786495760180267
ROC train: 0.968383	val: 0.631322	test: 0.600659
PRC train: 0.951721	val: 0.676539	test: 0.616659

Epoch: 192
Loss: 0.25654917249268067
ROC train: 0.968466	val: 0.630772	test: 0.600333
PRC train: 0.951447	val: 0.675032	test: 0.619025

Epoch: 193
Loss: 0.25740931485525537
ROC train: 0.967650	val: 0.633656	test: 0.602103
PRC train: 0.949137	val: 0.677011	test: 0.622766

Epoch: 194
Loss: 0.2568408715832643
ROC train: 0.968375	val: 0.633503	test: 0.601131
PRC train: 0.950940	val: 0.677437	test: 0.621225

Epoch: 195
Loss: 0.257590665638048
ROC train: 0.969288	val: 0.636911	test: 0.595153
PRC train: 0.951368	val: 0.680665	test: 0.615055

Epoch: 196
Loss: 0.2627725557777086
ROC train: 0.970300	val: 0.634782	test: 0.594551
PRC train: 0.953438	val: 0.681839	test: 0.613341

Early stopping
Best (ROC):	 train: 0.952145	val: 0.644701	test: 0.596872
Best (PRC):	 train: 0.927340	val: 0.680338	test: 0.615873
All runs completed.
