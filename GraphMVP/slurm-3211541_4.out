>>> Starting run for dataset: clintox
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running SCAFF configs_split_experiments/GraphMVP/clintox/scaff/train_prop=0.6.yml on cuda:0
Running SCAFF configs_split_experiments/GraphMVP/clintox/scaff/train_prop=0.7.yml on cuda:1
Running SCAFF configs_split_experiments/GraphMVP/clintox/scaff/train_prop=0.8.yml on cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/clintox/scaff/train_prop=0.8.yml --runseed 4 --device cuda:2
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/clintox/scaff/train_prop=0.8.yml --runseed 5 --device cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/clintox/scaff/train_prop=0.6.yml --runseed 4 --device cuda:0
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/clintox/scaff/train_prop=0.7.yml --runseed 4 --device cuda:1
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/clintox/scaff/train_prop=0.8.yml --runseed 6 --device cuda:2
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/clintox/scaff/train_prop=0.6.yml --runseed 5 --device cuda:0
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/clintox/scaff/train_prop=0.7.yml --runseed 5 --device cuda:1
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/clintox/scaff/train_prop=0.6.yml --runseed 6 --device cuda:0
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/clintox/scaff/train_prop=0.7.yml --runseed 6 --device cuda:1
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/clintox/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/clintox/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/clintox/scaff/train_prop=0.6/clintox_scaff_4_26-05_11-11-03  ]
[ Using Seed :  4  ]
[ Using device :  cuda:0  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6654317265084133
ROC train: 0.577723	val: 0.551031	test: 0.460248
PRC train: 0.530435	val: 0.546484	test: 0.497577

Epoch: 2
Loss: 0.6036964618160507
ROC train: 0.706571	val: 0.554638	test: 0.542440
PRC train: 0.576811	val: 0.550261	test: 0.506107

Epoch: 3
Loss: 0.5508020378353229
ROC train: 0.751372	val: 0.551964	test: 0.558992
PRC train: 0.602309	val: 0.526174	test: 0.507658

Epoch: 4
Loss: 0.505891461986695
ROC train: 0.791933	val: 0.582346	test: 0.617328
PRC train: 0.623276	val: 0.527904	test: 0.516716

Epoch: 5
Loss: 0.47040492388736566
ROC train: 0.814986	val: 0.626691	test: 0.651657
PRC train: 0.632917	val: 0.533817	test: 0.527388

Epoch: 6
Loss: 0.4329783291747147
ROC train: 0.827471	val: 0.644455	test: 0.653558
PRC train: 0.638138	val: 0.539098	test: 0.532119

Epoch: 7
Loss: 0.4008352053020854
ROC train: 0.844336	val: 0.632323	test: 0.644719
PRC train: 0.652648	val: 0.533727	test: 0.527512

Epoch: 8
Loss: 0.3765268462633374
ROC train: 0.857681	val: 0.641489	test: 0.659461
PRC train: 0.668138	val: 0.535192	test: 0.528390

Epoch: 9
Loss: 0.3491247544933481
ROC train: 0.874867	val: 0.646907	test: 0.663436
PRC train: 0.684511	val: 0.538504	test: 0.529929

Epoch: 10
Loss: 0.32539265988158905
ROC train: 0.887493	val: 0.631688	test: 0.670723
PRC train: 0.711994	val: 0.536573	test: 0.529708

Epoch: 11
Loss: 0.3018326031148626
ROC train: 0.893181	val: 0.636279	test: 0.682660
PRC train: 0.721563	val: 0.537594	test: 0.532661

Epoch: 12
Loss: 0.2801075246910775
ROC train: 0.897719	val: 0.632769	test: 0.679929
PRC train: 0.732706	val: 0.537479	test: 0.533867

Epoch: 13
Loss: 0.26750122897822637
ROC train: 0.899026	val: 0.616273	test: 0.669006
PRC train: 0.731270	val: 0.533103	test: 0.530495

Epoch: 14
Loss: 0.2507672873356478
ROC train: 0.908575	val: 0.628772	test: 0.681631
PRC train: 0.736531	val: 0.535819	test: 0.537116

Epoch: 15
Loss: 0.2366371715132054
ROC train: 0.908007	val: 0.591889	test: 0.684583
PRC train: 0.742009	val: 0.527201	test: 0.534172

Epoch: 16
Loss: 0.2234002499262594
ROC train: 0.913447	val: 0.578945	test: 0.670979
PRC train: 0.760494	val: 0.527132	test: 0.534076

Epoch: 17
Loss: 0.21892675878718168
ROC train: 0.922814	val: 0.602513	test: 0.689670
PRC train: 0.778229	val: 0.535606	test: 0.542093

Epoch: 18
Loss: 0.21365980637161708
ROC train: 0.920824	val: 0.607454	test: 0.682043
PRC train: 0.782124	val: 0.532736	test: 0.541733

Epoch: 19
Loss: 0.20472964296719529
ROC train: 0.931567	val: 0.615154	test: 0.698307
PRC train: 0.785306	val: 0.536832	test: 0.543159

Epoch: 20
Loss: 0.18683943526893126
ROC train: 0.929151	val: 0.640323	test: 0.727269
PRC train: 0.782032	val: 0.544085	test: 0.557204

Epoch: 21
Loss: 0.1940279131135485
ROC train: 0.935412	val: 0.626205	test: 0.718728
PRC train: 0.787175	val: 0.536366	test: 0.549755

Epoch: 22
Loss: 0.18135813600118192
ROC train: 0.935390	val: 0.602858	test: 0.677719
PRC train: 0.800557	val: 0.530166	test: 0.540442

Epoch: 23
Loss: 0.1913066902731712
ROC train: 0.941709	val: 0.643212	test: 0.730421
PRC train: 0.810574	val: 0.544544	test: 0.554723

Epoch: 24
Loss: 0.17258419871125905
ROC train: 0.944012	val: 0.635067	test: 0.737498
PRC train: 0.815675	val: 0.544316	test: 0.560431

Epoch: 25
Loss: 0.17066941900475832
ROC train: 0.949427	val: 0.624963	test: 0.748457
PRC train: 0.822559	val: 0.546725	test: 0.559711

Epoch: 26
Loss: 0.1744605986738555
ROC train: 0.943387	val: 0.594866	test: 0.744071
PRC train: 0.822272	val: 0.531845	test: 0.552957

Epoch: 27
Loss: 0.16455999482361178
ROC train: 0.946491	val: 0.620856	test: 0.771841
PRC train: 0.827923	val: 0.537815	test: 0.564752

Epoch: 28
Loss: 0.1639438686750194
ROC train: 0.953226	val: 0.657067	test: 0.774497
PRC train: 0.833228	val: 0.553020	test: 0.579376

Epoch: 29
Loss: 0.17142101680239125
ROC train: 0.958089	val: 0.635456	test: 0.757600
PRC train: 0.843466	val: 0.553539	test: 0.568943

Epoch: 30
Loss: 0.16560550327650142
ROC train: 0.959779	val: 0.643972	test: 0.747173
PRC train: 0.846799	val: 0.555178	test: 0.567272

Epoch: 31
Loss: 0.1720484928576268
ROC train: 0.959352	val: 0.656291	test: 0.751397
PRC train: 0.841981	val: 0.549390	test: 0.581828

Epoch: 32
Loss: 0.1605407488974759
ROC train: 0.950134	val: 0.623402	test: 0.757328
PRC train: 0.843970	val: 0.548877	test: 0.567221

Epoch: 33
Loss: 0.15310179223424195Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/clintox/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/clintox/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/clintox/scaff/train_prop=0.6/clintox_scaff_6_26-05_11-11-03  ]
[ Using Seed :  6  ]
[ Using device :  cuda:0  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6534611737222237
ROC train: 0.591260	val: 0.511107	test: 0.516730
PRC train: 0.530071	val: 0.509779	test: 0.504455

Epoch: 2
Loss: 0.5820359933130063
ROC train: 0.702835	val: 0.544235	test: 0.567734
PRC train: 0.568207	val: 0.523378	test: 0.513889

Epoch: 3
Loss: 0.5306714747863898
ROC train: 0.761040	val: 0.556534	test: 0.610455
PRC train: 0.597417	val: 0.523074	test: 0.520685

Epoch: 4
Loss: 0.49533042444924624
ROC train: 0.788680	val: 0.597551	test: 0.653823
PRC train: 0.614097	val: 0.527689	test: 0.536455

Epoch: 5
Loss: 0.45470271132754625
ROC train: 0.804433	val: 0.624408	test: 0.659266
PRC train: 0.621694	val: 0.532479	test: 0.540791

Epoch: 6
Loss: 0.4172106836063896
ROC train: 0.826120	val: 0.627118	test: 0.670808
PRC train: 0.642077	val: 0.536227	test: 0.535534

Epoch: 7
Loss: 0.38962847021299163
ROC train: 0.850002	val: 0.610699	test: 0.669191
PRC train: 0.660095	val: 0.528116	test: 0.534758

Epoch: 8
Loss: 0.36760626002034225
ROC train: 0.860728	val: 0.594390	test: 0.670051
PRC train: 0.665660	val: 0.525957	test: 0.532999

Epoch: 9
Loss: 0.33928583743587887
ROC train: 0.870913	val: 0.609824	test: 0.678247
PRC train: 0.688235	val: 0.530884	test: 0.535124

Epoch: 10
Loss: 0.3150879451038667
ROC train: 0.868778	val: 0.596043	test: 0.674370
PRC train: 0.693798	val: 0.525409	test: 0.535388

Epoch: 11
Loss: 0.2942702739878353
ROC train: 0.877384	val: 0.595278	test: 0.680183
PRC train: 0.712340	val: 0.525369	test: 0.539265

Epoch: 12
Loss: 0.28425698023360857
ROC train: 0.878647	val: 0.594316	test: 0.680117
PRC train: 0.717317	val: 0.526163	test: 0.535478

Epoch: 13
Loss: 0.26250057837364815
ROC train: 0.895605	val: 0.645787	test: 0.703066
PRC train: 0.747756	val: 0.539549	test: 0.546550

Epoch: 14
Loss: 0.2428863897055974
ROC train: 0.905761	val: 0.647630	test: 0.710711
PRC train: 0.746514	val: 0.543275	test: 0.559194

Epoch: 15
Loss: 0.23657044012936734
ROC train: 0.909869	val: 0.621577	test: 0.701086
PRC train: 0.761982	val: 0.541387	test: 0.547758

Epoch: 16
Loss: 0.2292339169480003
ROC train: 0.912303	val: 0.620750	test: 0.702911
PRC train: 0.761167	val: 0.534113	test: 0.542634

Epoch: 17
Loss: 0.21732931797240512
ROC train: 0.920420	val: 0.636465	test: 0.712812
PRC train: 0.764874	val: 0.538580	test: 0.550038

Epoch: 18
Loss: 0.21174486230059353
ROC train: 0.925097	val: 0.630540	test: 0.694582
PRC train: 0.772285	val: 0.539255	test: 0.549391

Epoch: 19
Loss: 0.2060005719566675
ROC train: 0.927920	val: 0.623982	test: 0.701106
PRC train: 0.773557	val: 0.539297	test: 0.549275

Epoch: 20
Loss: 0.1863482434832082
ROC train: 0.929881	val: 0.617184	test: 0.717763
PRC train: 0.792229	val: 0.539532	test: 0.556214

Epoch: 21
Loss: 0.19414017470287392
ROC train: 0.935184	val: 0.610401	test: 0.714498
PRC train: 0.805063	val: 0.538109	test: 0.552949

Epoch: 22
Loss: 0.18129081905085798
ROC train: 0.938106	val: 0.593797	test: 0.727345
PRC train: 0.807411	val: 0.535694	test: 0.555605

Epoch: 23
Loss: 0.17715157740464443
ROC train: 0.930572	val: 0.575534	test: 0.684739
PRC train: 0.793416	val: 0.527616	test: 0.544172

Epoch: 24
Loss: 0.18928034057154575
ROC train: 0.943788	val: 0.636007	test: 0.696612
PRC train: 0.816997	val: 0.547355	test: 0.556683

Epoch: 25
Loss: 0.16959676300701904
ROC train: 0.942867	val: 0.625270	test: 0.689615
PRC train: 0.807190	val: 0.541110	test: 0.549364

Epoch: 26
Loss: 0.16353880067097898
ROC train: 0.944988	val: 0.618506	test: 0.706374
PRC train: 0.814835	val: 0.541355	test: 0.551814

Epoch: 27
Loss: 0.17806511356854998
ROC train: 0.951510	val: 0.617933	test: 0.707237
PRC train: 0.821411	val: 0.548045	test: 0.557014

Epoch: 28
Loss: 0.16118644368061139
ROC train: 0.955936	val: 0.633163	test: 0.725737
PRC train: 0.830471	val: 0.557569	test: 0.561139

Epoch: 29
Loss: 0.17108233663951847
ROC train: 0.954966	val: 0.639284	test: 0.756301
PRC train: 0.836232	val: 0.547985	test: 0.581513

Epoch: 30
Loss: 0.16935007800538365
ROC train: 0.961094	val: 0.643829	test: 0.740682
PRC train: 0.847507	val: 0.551603	test: 0.591913

Epoch: 31
Loss: 0.1682000067313269
ROC train: 0.959913	val: 0.636779	test: 0.695108
PRC train: 0.836477	val: 0.552469	test: 0.563477

Epoch: 32
Loss: 0.1511825079986026
ROC train: 0.962263	val: 0.634164	test: 0.702704
PRC train: 0.844704	val: 0.549993	test: 0.584965

Epoch: 33
Loss: 0.1619341883047361Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/clintox/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/clintox/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/clintox/scaff/train_prop=0.6/clintox_scaff_5_26-05_11-11-03  ]
[ Using Seed :  5  ]
[ Using device :  cuda:0  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6782854672877645
ROC train: 0.629166	val: 0.572022	test: 0.491111
PRC train: 0.547811	val: 0.522976	test: 0.505100

Epoch: 2
Loss: 0.6107242365923771
ROC train: 0.704015	val: 0.567408	test: 0.550083
PRC train: 0.571581	val: 0.524521	test: 0.506409

Epoch: 3
Loss: 0.5560126507314229
ROC train: 0.752038	val: 0.570500	test: 0.613400
PRC train: 0.597946	val: 0.526235	test: 0.514559

Epoch: 4
Loss: 0.5131434244683855
ROC train: 0.766225	val: 0.574010	test: 0.631779
PRC train: 0.608033	val: 0.524267	test: 0.520063

Epoch: 5
Loss: 0.47353861305292877
ROC train: 0.782337	val: 0.598214	test: 0.653593
PRC train: 0.617749	val: 0.529092	test: 0.528744

Epoch: 6
Loss: 0.44079475178687866
ROC train: 0.805785	val: 0.635070	test: 0.679981
PRC train: 0.632154	val: 0.536364	test: 0.538554

Epoch: 7
Loss: 0.40837127528163925
ROC train: 0.825041	val: 0.648796	test: 0.693336
PRC train: 0.645963	val: 0.538535	test: 0.543855

Epoch: 8
Loss: 0.37748157995278425
ROC train: 0.844826	val: 0.632082	test: 0.668642
PRC train: 0.656025	val: 0.533281	test: 0.535266

Epoch: 9
Loss: 0.35730015519846725
ROC train: 0.852585	val: 0.611590	test: 0.639892
PRC train: 0.658279	val: 0.529615	test: 0.525469

Epoch: 10
Loss: 0.3256101936081996
ROC train: 0.870889	val: 0.633203	test: 0.652834
PRC train: 0.670675	val: 0.535376	test: 0.532648

Epoch: 11
Loss: 0.306052046659945
ROC train: 0.877526	val: 0.635011	test: 0.670363
PRC train: 0.680632	val: 0.543791	test: 0.535427

Epoch: 12
Loss: 0.2977086738160274
ROC train: 0.872294	val: 0.616760	test: 0.677897
PRC train: 0.689898	val: 0.550172	test: 0.536073

Epoch: 13
Loss: 0.2741640101808037
ROC train: 0.885997	val: 0.623473	test: 0.672656
PRC train: 0.701699	val: 0.548955	test: 0.537084

Epoch: 14
Loss: 0.250025367585531
ROC train: 0.901152	val: 0.628894	test: 0.662409
PRC train: 0.716293	val: 0.549994	test: 0.539103

Epoch: 15
Loss: 0.23906884960330785
ROC train: 0.905114	val: 0.611164	test: 0.670053
PRC train: 0.726858	val: 0.535195	test: 0.537968

Epoch: 16
Loss: 0.23938927255949963
ROC train: 0.902382	val: 0.604731	test: 0.701210
PRC train: 0.737551	val: 0.533216	test: 0.540608

Epoch: 17
Loss: 0.22914660438975104
ROC train: 0.905964	val: 0.607037	test: 0.705142
PRC train: 0.736920	val: 0.527743	test: 0.542489

Epoch: 18
Loss: 0.22212103101919445
ROC train: 0.917973	val: 0.639464	test: 0.691763
PRC train: 0.747498	val: 0.541125	test: 0.550081

Epoch: 19
Loss: 0.2023057056511528
ROC train: 0.920767	val: 0.647726	test: 0.715074
PRC train: 0.747292	val: 0.540790	test: 0.565738

Epoch: 20
Loss: 0.19895518809345686
ROC train: 0.926353	val: 0.631940	test: 0.739788
PRC train: 0.769975	val: 0.537228	test: 0.566331

Epoch: 21
Loss: 0.2005102315358598
ROC train: 0.926908	val: 0.594915	test: 0.722558
PRC train: 0.778156	val: 0.529087	test: 0.553046

Epoch: 22
Loss: 0.1955787352630507
ROC train: 0.927801	val: 0.617548	test: 0.743221
PRC train: 0.788067	val: 0.539724	test: 0.559943

Epoch: 23
Loss: 0.18056648824044624
ROC train: 0.934034	val: 0.645313	test: 0.734888
PRC train: 0.801385	val: 0.545158	test: 0.557658

Epoch: 24
Loss: 0.18369264333532648
ROC train: 0.938405	val: 0.627209	test: 0.714419
PRC train: 0.819755	val: 0.558472	test: 0.547289

Epoch: 25
Loss: 0.1777478806342414
ROC train: 0.944024	val: 0.616228	test: 0.734317
PRC train: 0.823618	val: 0.541141	test: 0.555570

Epoch: 26
Loss: 0.1726782896332146
ROC train: 0.945691	val: 0.620020	test: 0.753277
PRC train: 0.808563	val: 0.537708	test: 0.563137

Epoch: 27
Loss: 0.17105053369975132
ROC train: 0.942248	val: 0.595414	test: 0.738339
PRC train: 0.796639	val: 0.530522	test: 0.551346

Epoch: 28
Loss: 0.17505646978630438
ROC train: 0.945454	val: 0.606360	test: 0.724926
PRC train: 0.827923	val: 0.535170	test: 0.550077

Epoch: 29
Loss: 0.1685849857063192
ROC train: 0.944478	val: 0.618433	test: 0.738094
PRC train: 0.826494	val: 0.541510	test: 0.555161

Epoch: 30
Loss: 0.1634892022264613
ROC train: 0.950006	val: 0.652137	test: 0.778032
PRC train: 0.817781	val: 0.544084	test: 0.572467

Epoch: 31
Loss: 0.1616478545186496
ROC train: 0.956360	val: 0.620156	test: 0.752166
PRC train: 0.835160	val: 0.539414	test: 0.567940

Epoch: 32
Loss: 0.15876512501188123
ROC train: 0.958587	val: 0.618884	test: 0.731155
PRC train: 0.838628	val: 0.549682	test: 0.556611

Epoch: 33
Loss: 0.16035455738795057Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/clintox/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/clintox/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/clintox/scaff/train_prop=0.7/clintox_scaff_5_26-05_11-11-03  ]
[ Using Seed :  5  ]
[ Using device :  cuda:1  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6739472509585855
ROC train: 0.645904	val: 0.588541	test: 0.470360
PRC train: 0.554603	val: 0.523481	test: 0.500426

Epoch: 2
Loss: 0.5958041919650576
ROC train: 0.679646	val: 0.586303	test: 0.475014
PRC train: 0.559137	val: 0.523728	test: 0.494104

Epoch: 3
Loss: 0.5334760157031588
ROC train: 0.697529	val: 0.594529	test: 0.485703
PRC train: 0.563956	val: 0.526638	test: 0.495282

Epoch: 4
Loss: 0.4849342097325547
ROC train: 0.730202	val: 0.640987	test: 0.509181
PRC train: 0.578090	val: 0.542272	test: 0.497396

Epoch: 5
Loss: 0.4375211191044418
ROC train: 0.774116	val: 0.677131	test: 0.542917
PRC train: 0.597719	val: 0.552340	test: 0.503794

Epoch: 6
Loss: 0.43055535410820023
ROC train: 0.787261	val: 0.687930	test: 0.562146
PRC train: 0.602696	val: 0.554335	test: 0.507980

Epoch: 7
Loss: 0.35787869284652524
ROC train: 0.792561	val: 0.694293	test: 0.579805
PRC train: 0.611064	val: 0.556648	test: 0.513154

Epoch: 8
Loss: 0.34045944182006527
ROC train: 0.780917	val: 0.664984	test: 0.560763
PRC train: 0.607065	val: 0.550903	test: 0.509234

Epoch: 9
Loss: 0.32659710704530454
ROC train: 0.801449	val: 0.681904	test: 0.559998
PRC train: 0.619724	val: 0.555316	test: 0.510753

Epoch: 10
Loss: 0.3054109522267755
ROC train: 0.824596	val: 0.722106	test: 0.608706
PRC train: 0.638287	val: 0.574527	test: 0.529538

Epoch: 11
Loss: 0.3098310836369106
ROC train: 0.819382	val: 0.722911	test: 0.618343
PRC train: 0.641643	val: 0.580851	test: 0.526856

Epoch: 12
Loss: 0.3004223656042415
ROC train: 0.821485	val: 0.690009	test: 0.562192
PRC train: 0.630858	val: 0.562627	test: 0.509472

Epoch: 13
Loss: 0.28136442401636796
ROC train: 0.807090	val: 0.664860	test: 0.527053
PRC train: 0.605440	val: 0.557168	test: 0.505286

Epoch: 14
Loss: 0.231213006309798
ROC train: 0.837505	val: 0.718019	test: 0.610645
PRC train: 0.652589	val: 0.569878	test: 0.515583

Epoch: 15
Loss: 0.25095473094897386
ROC train: 0.846203	val: 0.743752	test: 0.631416
PRC train: 0.669360	val: 0.571248	test: 0.526922

Epoch: 16
Loss: 0.24037852136519372
ROC train: 0.848390	val: 0.743517	test: 0.628921
PRC train: 0.671327	val: 0.578722	test: 0.527054

Epoch: 17
Loss: 0.34427212110955285
ROC train: 0.863346	val: 0.731020	test: 0.618340
PRC train: 0.685241	val: 0.576902	test: 0.520193

Epoch: 18
Loss: 0.21206262533943843
ROC train: 0.840204	val: 0.676498	test: 0.565474
PRC train: 0.672310	val: 0.561928	test: 0.513072

Epoch: 19
Loss: 0.20928940816145464
ROC train: 0.851548	val: 0.675903	test: 0.576387
PRC train: 0.688958	val: 0.571320	test: 0.516101

Epoch: 20
Loss: 0.20864487781877178
ROC train: 0.849839	val: 0.705843	test: 0.570599
PRC train: 0.675419	val: 0.617018	test: 0.521446

Epoch: 21
Loss: 0.3066469156309615
ROC train: 0.862935	val: 0.706895	test: 0.582090
PRC train: 0.676104	val: 0.621771	test: 0.534014

Epoch: 22
Loss: 0.18582556817024223
ROC train: 0.870541	val: 0.689092	test: 0.605123
PRC train: 0.691544	val: 0.580608	test: 0.521510

Epoch: 23
Loss: 0.18843032536446896
ROC train: 0.855692	val: 0.672004	test: 0.602051
PRC train: 0.677631	val: 0.566061	test: 0.517780

Epoch: 24
Loss: 0.2175418566444809
ROC train: 0.870979	val: 0.688457	test: 0.617737
PRC train: 0.693249	val: 0.576302	test: 0.521093

Epoch: 25
Loss: 0.1759873722802256
ROC train: 0.877827	val: 0.695631	test: 0.629766
PRC train: 0.703820	val: 0.607424	test: 0.524223

Epoch: 26
Loss: 0.21448119970550109
ROC train: 0.882552	val: 0.691929	test: 0.634245
PRC train: 0.705820	val: 0.589505	test: 0.525355

Epoch: 27
Loss: 0.17872082824396213
ROC train: 0.869127	val: 0.674309	test: 0.611518
PRC train: 0.688500	val: 0.576443	test: 0.518757

Epoch: 28
Loss: 0.21418908798071695
ROC train: 0.890723	val: 0.674867	test: 0.592464
PRC train: 0.709328	val: 0.580364	test: 0.514581

Epoch: 29
Loss: 0.18299037758735925
ROC train: 0.864451	val: 0.691720	test: 0.560740
PRC train: 0.679500	val: 0.601572	test: 0.512415

Epoch: 30
Loss: 0.21541438493358017
ROC train: 0.869769	val: 0.702067	test: 0.592118
PRC train: 0.678136	val: 0.591068	test: 0.524791

Epoch: 31
Loss: 0.1848029636153364
ROC train: 0.869406	val: 0.705466	test: 0.624950
PRC train: 0.686169	val: 0.588595	test: 0.534699

Epoch: 32
Loss: 0.17203250311120905
ROC train: 0.896278	val: 0.704856	test: 0.653845
PRC train: 0.713339	val: 0.592531	test: 0.540376

Epoch: 33
Loss: 0.18446385222271278Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/clintox/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/clintox/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/clintox/scaff/train_prop=0.7/clintox_scaff_6_26-05_11-11-03  ]
[ Using Seed :  6  ]
[ Using device :  cuda:1  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6471691984115322
ROC train: 0.610897	val: 0.565645	test: 0.470879
PRC train: 0.539465	val: 0.522284	test: 0.497505

Epoch: 2
Loss: 0.5632178239448723
ROC train: 0.688114	val: 0.596575	test: 0.529380
PRC train: 0.565863	val: 0.532119	test: 0.505477

Epoch: 3
Loss: 0.5285683452340814
ROC train: 0.718340	val: 0.612536	test: 0.522115
PRC train: 0.570847	val: 0.534960	test: 0.512805

Epoch: 4
Loss: 0.4734938799542265
ROC train: 0.739629	val: 0.643516	test: 0.500791
PRC train: 0.577978	val: 0.541846	test: 0.516555

Epoch: 5
Loss: 0.4305242950684254
ROC train: 0.760859	val: 0.664007	test: 0.511477
PRC train: 0.589622	val: 0.549015	test: 0.512135

Epoch: 6
Loss: 0.44850642879523883
ROC train: 0.792086	val: 0.674780	test: 0.572889
PRC train: 0.607559	val: 0.551802	test: 0.515148

Epoch: 7
Loss: 0.3979835050659537
ROC train: 0.795932	val: 0.632838	test: 0.520638
PRC train: 0.625721	val: 0.555045	test: 0.507810

Epoch: 8
Loss: 0.341902476179057
ROC train: 0.793223	val: 0.586124	test: 0.467531
PRC train: 0.621669	val: 0.536713	test: 0.501311

Epoch: 9
Loss: 0.2989369531670302
ROC train: 0.821603	val: 0.611798	test: 0.493682
PRC train: 0.641436	val: 0.542424	test: 0.500849

Epoch: 10
Loss: 0.28940065970102075
ROC train: 0.844859	val: 0.680018	test: 0.570253
PRC train: 0.655330	val: 0.553084	test: 0.512206

Epoch: 11
Loss: 0.2645745354499354
ROC train: 0.849793	val: 0.694928	test: 0.596767
PRC train: 0.651947	val: 0.551260	test: 0.517142

Epoch: 12
Loss: 0.29018082053786487
ROC train: 0.854633	val: 0.690100	test: 0.604346
PRC train: 0.654405	val: 0.548696	test: 0.519326

Epoch: 13
Loss: 0.2725819271458218
ROC train: 0.844900	val: 0.663122	test: 0.596404
PRC train: 0.655647	val: 0.542635	test: 0.516680

Epoch: 14
Loss: 0.2284851091444363
ROC train: 0.831581	val: 0.629927	test: 0.569267
PRC train: 0.659435	val: 0.536464	test: 0.511253

Epoch: 15
Loss: 0.24173593972895357
ROC train: 0.858838	val: 0.678973	test: 0.606909
PRC train: 0.685093	val: 0.552768	test: 0.520775

Epoch: 16
Loss: 0.2072620036002326
ROC train: 0.863706	val: 0.701108	test: 0.613819
PRC train: 0.678835	val: 0.567171	test: 0.529918

Epoch: 17
Loss: 0.2560634960749747
ROC train: 0.877959	val: 0.712063	test: 0.617921
PRC train: 0.689933	val: 0.574423	test: 0.526538

Epoch: 18
Loss: 0.1886657455691063
ROC train: 0.875783	val: 0.685714	test: 0.592470
PRC train: 0.704465	val: 0.561926	test: 0.516575

Epoch: 19
Loss: 0.18849393182250268
ROC train: 0.880173	val: 0.686876	test: 0.598329
PRC train: 0.709990	val: 0.570135	test: 0.517817

Epoch: 20
Loss: 0.1845231474084127
ROC train: 0.883547	val: 0.698873	test: 0.624177
PRC train: 0.716338	val: 0.585630	test: 0.523844

Epoch: 21
Loss: 0.20255083939182197
ROC train: 0.877685	val: 0.710043	test: 0.636722
PRC train: 0.709989	val: 0.589256	test: 0.528561

Epoch: 22
Loss: 0.19911163369990809
ROC train: 0.878447	val: 0.722091	test: 0.652924
PRC train: 0.704229	val: 0.587121	test: 0.534720

Epoch: 23
Loss: 0.20946365888111598
ROC train: 0.887993	val: 0.721411	test: 0.648718
PRC train: 0.706966	val: 0.587494	test: 0.534461

Epoch: 24
Loss: 0.16978027621888878
ROC train: 0.872092	val: 0.701524	test: 0.620078
PRC train: 0.693458	val: 0.581751	test: 0.526997

Epoch: 25
Loss: 0.2838833449796252
ROC train: 0.894554	val: 0.704247	test: 0.640107
PRC train: 0.734333	val: 0.608945	test: 0.533676

Epoch: 26
Loss: 0.24463038966418943
ROC train: 0.853124	val: 0.684657	test: 0.627224
PRC train: 0.683123	val: 0.599063	test: 0.537139

Epoch: 27
Loss: 0.20161654628388082
ROC train: 0.845486	val: 0.672374	test: 0.615027
PRC train: 0.679906	val: 0.588127	test: 0.535408

Epoch: 28
Loss: 0.22197409065942306
ROC train: 0.889959	val: 0.682457	test: 0.628088
PRC train: 0.723225	val: 0.568566	test: 0.527632

Epoch: 29
Loss: 0.25362450403100534
ROC train: 0.851191	val: 0.623618	test: 0.602422
PRC train: 0.684465	val: 0.545786	test: 0.519403

Epoch: 30
Loss: 0.18451750284541696
ROC train: 0.839143	val: 0.599348	test: 0.609732
PRC train: 0.693357	val: 0.536441	test: 0.519223

Epoch: 31
Loss: 0.1787500498661929
ROC train: 0.854137	val: 0.628448	test: 0.605923
PRC train: 0.706301	val: 0.542367	test: 0.520806

Epoch: 32
Loss: 0.17767736566914713
ROC train: 0.884666	val: 0.669571	test: 0.621937
PRC train: 0.736284	val: 0.563986	test: 0.526943

Epoch: 33
Loss: 0.17036559396545595Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/clintox/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/clintox/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/clintox/scaff/train_prop=0.7/clintox_scaff_4_26-05_11-11-03  ]
[ Using Seed :  4  ]
[ Using device :  cuda:1  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6566746048188407
ROC train: 0.605070	val: 0.534786	test: 0.478664
PRC train: 0.563839	val: 0.517249	test: 0.507297

Epoch: 2
Loss: 0.5891904789537161
ROC train: 0.669872	val: 0.627502	test: 0.500337
PRC train: 0.564309	val: 0.544568	test: 0.504729

Epoch: 3
Loss: 0.5310489156754017
ROC train: 0.696742	val: 0.635142	test: 0.486607
PRC train: 0.569486	val: 0.551361	test: 0.499518

Epoch: 4
Loss: 0.48378937619309215
ROC train: 0.731200	val: 0.635648	test: 0.475292
PRC train: 0.577001	val: 0.548722	test: 0.497940

Epoch: 5
Loss: 0.44839242802112117
ROC train: 0.763851	val: 0.678539	test: 0.502752
PRC train: 0.592227	val: 0.561427	test: 0.502358

Epoch: 6
Loss: 0.41197548708301823
ROC train: 0.785745	val: 0.708372	test: 0.561545
PRC train: 0.602886	val: 0.558988	test: 0.513602

Epoch: 7
Loss: 0.3751127789215407
ROC train: 0.782927	val: 0.735738	test: 0.594562
PRC train: 0.599760	val: 0.581660	test: 0.531277

Epoch: 8
Loss: 0.3427159475256215
ROC train: 0.785160	val: 0.705758	test: 0.568053
PRC train: 0.597430	val: 0.566902	test: 0.516034

Epoch: 9
Loss: 0.3166545879533994
ROC train: 0.789324	val: 0.664500	test: 0.535871
PRC train: 0.591854	val: 0.550713	test: 0.507489

Epoch: 10
Loss: 0.32927866122842386
ROC train: 0.820276	val: 0.701944	test: 0.564128
PRC train: 0.615531	val: 0.578117	test: 0.510434

Epoch: 11
Loss: 0.31409269748703733
ROC train: 0.801424	val: 0.718398	test: 0.558512
PRC train: 0.607064	val: 0.588152	test: 0.557039

Epoch: 12
Loss: 0.316978178603087
ROC train: 0.817560	val: 0.707626	test: 0.568609
PRC train: 0.616067	val: 0.588138	test: 0.557868

Epoch: 13
Loss: 0.25339478664736237
ROC train: 0.836425	val: 0.697647	test: 0.561066
PRC train: 0.635902	val: 0.572946	test: 0.516371

Epoch: 14
Loss: 0.2624009103206103
ROC train: 0.833519	val: 0.707008	test: 0.543229
PRC train: 0.640278	val: 0.566404	test: 0.512294

Epoch: 15
Loss: 0.24858804476278146
ROC train: 0.827533	val: 0.721760	test: 0.557073
PRC train: 0.637093	val: 0.562456	test: 0.512709

Epoch: 16
Loss: 0.217191024900234
ROC train: 0.836975	val: 0.737994	test: 0.582889
PRC train: 0.636891	val: 0.568994	test: 0.515756

Epoch: 17
Loss: 0.2528850312515598
ROC train: 0.845620	val: 0.726396	test: 0.600582
PRC train: 0.640410	val: 0.567962	test: 0.518779

Epoch: 18
Loss: 0.2557993161470069
ROC train: 0.838113	val: 0.703431	test: 0.594046
PRC train: 0.643931	val: 0.562870	test: 0.517300

Epoch: 19
Loss: 0.25632736979657555
ROC train: 0.828413	val: 0.677015	test: 0.537469
PRC train: 0.630966	val: 0.556337	test: 0.511107

Epoch: 20
Loss: 0.20481380610110098
ROC train: 0.831891	val: 0.662799	test: 0.539811
PRC train: 0.624959	val: 0.555664	test: 0.509690

Epoch: 21
Loss: 0.19532917812743525
ROC train: 0.859704	val: 0.699950	test: 0.604738
PRC train: 0.647731	val: 0.570578	test: 0.518481

Epoch: 22
Loss: 0.18921050422340513
ROC train: 0.868286	val: 0.726735	test: 0.605458
PRC train: 0.663547	val: 0.574333	test: 0.525083

Epoch: 23
Loss: 0.21830121268881442
ROC train: 0.883577	val: 0.722785	test: 0.605120
PRC train: 0.688449	val: 0.570924	test: 0.525894

Epoch: 24
Loss: 0.1805026123179853
ROC train: 0.889074	val: 0.704669	test: 0.604465
PRC train: 0.706140	val: 0.565654	test: 0.523182

Epoch: 25
Loss: 0.17538588558857454
ROC train: 0.899057	val: 0.685971	test: 0.594063
PRC train: 0.717965	val: 0.570213	test: 0.521436

Epoch: 26
Loss: 0.16942367887541843
ROC train: 0.902259	val: 0.684238	test: 0.602714
PRC train: 0.719643	val: 0.565638	test: 0.523785

Epoch: 27
Loss: 0.17512965586982437
ROC train: 0.905936	val: 0.685983	test: 0.618286
PRC train: 0.723852	val: 0.571250	test: 0.529712

Epoch: 28
Loss: 0.19713494565420833
ROC train: 0.904662	val: 0.689586	test: 0.634012
PRC train: 0.723118	val: 0.578348	test: 0.531560

Epoch: 29
Loss: 0.1674715377955632
ROC train: 0.893463	val: 0.679669	test: 0.621353
PRC train: 0.701015	val: 0.567597	test: 0.525734

Epoch: 30
Loss: 0.19804931457813973
ROC train: 0.906585	val: 0.675137	test: 0.622385
PRC train: 0.719228	val: 0.568819	test: 0.526719

Epoch: 31
Loss: 0.1698320129539116
ROC train: 0.911192	val: 0.688944	test: 0.636620
PRC train: 0.723844	val: 0.566567	test: 0.526915

Epoch: 32
Loss: 0.20097730811865278
ROC train: 0.917056	val: 0.699469	test: 0.642108
PRC train: 0.740834	val: 0.573635	test: 0.530783

Epoch: 33
Loss: 0.1585969791011731Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/clintox/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/clintox/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/clintox/scaff/train_prop=0.8/clintox_scaff_6_26-05_11-11-03  ]
[ Using Seed :  6  ]
[ Using device :  cuda:2  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6446409079770735
ROC train: 0.616014	val: 0.796176	test: 0.488860
PRC train: 0.541722	val: 0.555206	test: 0.500362

Epoch: 2
Loss: 0.5689807057963071
ROC train: 0.685620	val: 0.829992	test: 0.502691
PRC train: 0.560063	val: 0.576705	test: 0.502671

Epoch: 3
Loss: 0.512350927438046
ROC train: 0.730198	val: 0.822250	test: 0.493024
PRC train: 0.575182	val: 0.613021	test: 0.503780

Epoch: 4
Loss: 0.46629790112691316
ROC train: 0.772236	val: 0.860972	test: 0.531012
PRC train: 0.599228	val: 0.645461	test: 0.510975

Epoch: 5
Loss: 0.426267824240127
ROC train: 0.784054	val: 0.834413	test: 0.524479
PRC train: 0.597496	val: 0.595280	test: 0.508094

Epoch: 6
Loss: 0.39163860555361657
ROC train: 0.810568	val: 0.864131	test: 0.556584
PRC train: 0.607247	val: 0.574615	test: 0.513923

Epoch: 7
Loss: 0.35569145463399476
ROC train: 0.827820	val: 0.870225	test: 0.577520
PRC train: 0.618386	val: 0.574155	test: 0.519596

Epoch: 8
Loss: 0.3229370293023722
ROC train: 0.840457	val: 0.859574	test: 0.561219
PRC train: 0.627545	val: 0.579765	test: 0.517820

Epoch: 9
Loss: 0.30513449056892217
ROC train: 0.836632	val: 0.833214	test: 0.541082
PRC train: 0.623117	val: 0.576248	test: 0.512426

Epoch: 10
Loss: 0.2761505629365333
ROC train: 0.849190	val: 0.855490	test: 0.588226
PRC train: 0.646137	val: 0.575961	test: 0.522804

Epoch: 11
Loss: 0.2644670054497401
ROC train: 0.861798	val: 0.851607	test: 0.593085
PRC train: 0.671281	val: 0.576714	test: 0.525538

Epoch: 12
Loss: 0.2477370202064828
ROC train: 0.872797	val: 0.841993	test: 0.598143
PRC train: 0.683671	val: 0.648324	test: 0.524005

Epoch: 13
Loss: 0.23776220280785956
ROC train: 0.885016	val: 0.853118	test: 0.640535
PRC train: 0.706711	val: 0.655917	test: 0.537521

Epoch: 14
Loss: 0.2254738623022583
ROC train: 0.869256	val: 0.845876	test: 0.655042
PRC train: 0.710507	val: 0.648839	test: 0.537179

Epoch: 15
Loss: 0.21827407140082586
ROC train: 0.889968	val: 0.840956	test: 0.673969
PRC train: 0.728398	val: 0.667216	test: 0.546161

Epoch: 16
Loss: 0.21496539200558917
ROC train: 0.902204	val: 0.828794	test: 0.690528
PRC train: 0.746815	val: 0.618137	test: 0.554428

Epoch: 17
Loss: 0.21167241037693713
ROC train: 0.900136	val: 0.818754	test: 0.680883
PRC train: 0.740006	val: 0.605007	test: 0.549169

Epoch: 18
Loss: 0.198278098149937
ROC train: 0.907471	val: 0.781817	test: 0.687786
PRC train: 0.746992	val: 0.613896	test: 0.562992

Epoch: 19
Loss: 0.19762092202783998
ROC train: 0.917244	val: 0.817717	test: 0.700004
PRC train: 0.767637	val: 0.655438	test: 0.563513

Epoch: 20
Loss: 0.1892752275813916
ROC train: 0.916382	val: 0.810837	test: 0.723861
PRC train: 0.768137	val: 0.656788	test: 0.569937

Epoch: 21
Loss: 0.1929435627064699
ROC train: 0.924366	val: 0.808827	test: 0.720477
PRC train: 0.774485	val: 0.661185	test: 0.579313

Epoch: 22
Loss: 0.18191009879693623
ROC train: 0.926649	val: 0.804195	test: 0.709383
PRC train: 0.786848	val: 0.650052	test: 0.567555

Epoch: 23
Loss: 0.17794676646994334
ROC train: 0.925582	val: 0.790385	test: 0.702014
PRC train: 0.781599	val: 0.641336	test: 0.564639

Epoch: 24
Loss: 0.17702238912088486
ROC train: 0.936671	val: 0.809101	test: 0.723637
PRC train: 0.793720	val: 0.655864	test: 0.578642

Epoch: 25
Loss: 0.18380768402933115
ROC train: 0.933261	val: 0.810650	test: 0.690046
PRC train: 0.795956	val: 0.656755	test: 0.561208

Epoch: 26
Loss: 0.17185584634133616
ROC train: 0.941299	val: 0.838696	test: 0.707478
PRC train: 0.797260	val: 0.641907	test: 0.581588

Epoch: 27
Loss: 0.1700714939096502
ROC train: 0.928656	val: 0.820803	test: 0.714004
PRC train: 0.788297	val: 0.617294	test: 0.581324

Epoch: 28
Loss: 0.17331055549156066
ROC train: 0.942197	val: 0.811887	test: 0.728501
PRC train: 0.816749	val: 0.625449	test: 0.595086

Epoch: 29
Loss: 0.16976733636358476
ROC train: 0.946313	val: 0.821340	test: 0.710582
PRC train: 0.811931	val: 0.629657	test: 0.610389

Epoch: 30
Loss: 0.1759523169727914
ROC train: 0.947932	val: 0.850458	test: 0.744659
PRC train: 0.807313	val: 0.664314	test: 0.589832

Epoch: 31
Loss: 0.17095629642586532
ROC train: 0.947674	val: 0.831405	test: 0.742736
PRC train: 0.806164	val: 0.599113	test: 0.583113

Epoch: 32
Loss: 0.16470095189059566
ROC train: 0.951332	val: 0.849073	test: 0.757901
PRC train: 0.811841	val: 0.658930	test: 0.592169

Epoch: 33
Loss: 0.16594414287524922Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/clintox/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/clintox/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/clintox/scaff/train_prop=0.8/clintox_scaff_4_26-05_11-11-03  ]
[ Using Seed :  4  ]
[ Using device :  cuda:2  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6582933570956131
ROC train: 0.625971	val: 0.731386	test: 0.472857
PRC train: 0.552079	val: 0.528792	test: 0.507628

Epoch: 2
Loss: 0.5852283396063612
ROC train: 0.701368	val: 0.844839	test: 0.509676
PRC train: 0.575468	val: 0.556485	test: 0.504453

Epoch: 3
Loss: 0.5239660945897053
ROC train: 0.727023	val: 0.861584	test: 0.510711
PRC train: 0.576839	val: 0.566627	test: 0.502618

Epoch: 4
Loss: 0.47203007189087137
ROC train: 0.760425	val: 0.874695	test: 0.529469
PRC train: 0.585598	val: 0.574613	test: 0.507039

Epoch: 5
Loss: 0.432236342881655
ROC train: 0.781862	val: 0.870861	test: 0.527553
PRC train: 0.590578	val: 0.572672	test: 0.507461

Epoch: 6
Loss: 0.3946259279756574
ROC train: 0.804451	val: 0.874245	test: 0.553461
PRC train: 0.600650	val: 0.573718	test: 0.512984

Epoch: 7
Loss: 0.3667176129005436
ROC train: 0.808074	val: 0.860498	test: 0.565690
PRC train: 0.600099	val: 0.564051	test: 0.516639

Epoch: 8
Loss: 0.33717772750784725
ROC train: 0.832659	val: 0.859423	test: 0.587471
PRC train: 0.615864	val: 0.571085	test: 0.529312

Epoch: 9
Loss: 0.3100935175392947
ROC train: 0.847372	val: 0.852517	test: 0.593698
PRC train: 0.636787	val: 0.569530	test: 0.529289

Epoch: 10
Loss: 0.2821780134523
ROC train: 0.860101	val: 0.819214	test: 0.601280
PRC train: 0.657770	val: 0.566666	test: 0.535647

Epoch: 11
Loss: 0.2684867778476942
ROC train: 0.861033	val: 0.861359	test: 0.612647
PRC train: 0.665529	val: 0.567923	test: 0.533361

Epoch: 12
Loss: 0.2525993231783849
ROC train: 0.868024	val: 0.859236	test: 0.610686
PRC train: 0.671468	val: 0.566447	test: 0.533234

Epoch: 13
Loss: 0.23873022045484094
ROC train: 0.881655	val: 0.851969	test: 0.618881
PRC train: 0.703570	val: 0.574679	test: 0.535558

Epoch: 14
Loss: 0.22846525331721196
ROC train: 0.892131	val: 0.847998	test: 0.632885
PRC train: 0.719005	val: 0.572394	test: 0.538390

Epoch: 15
Loss: 0.22295003143637518
ROC train: 0.897447	val: 0.828094	test: 0.647437
PRC train: 0.733123	val: 0.553919	test: 0.540513

Epoch: 16
Loss: 0.2147858261426388
ROC train: 0.899941	val: 0.822226	test: 0.647112
PRC train: 0.745664	val: 0.553129	test: 0.537528

Epoch: 17
Loss: 0.21095966029294502
ROC train: 0.902825	val: 0.860410	test: 0.629336
PRC train: 0.743732	val: 0.573275	test: 0.532224

Epoch: 18
Loss: 0.1969926018850465
ROC train: 0.907310	val: 0.848047	test: 0.622590
PRC train: 0.748491	val: 0.568695	test: 0.530079

Epoch: 19
Loss: 0.19497629066293634
ROC train: 0.917529	val: 0.815507	test: 0.661927
PRC train: 0.768676	val: 0.588724	test: 0.542893

Epoch: 20
Loss: 0.19305532586422788
ROC train: 0.919017	val: 0.815619	test: 0.664362
PRC train: 0.774107	val: 0.648705	test: 0.545944

Epoch: 21
Loss: 0.19333505085675992
ROC train: 0.922565	val: 0.831053	test: 0.659771
PRC train: 0.776524	val: 0.606978	test: 0.546312

Epoch: 22
Loss: 0.18416549167978408
ROC train: 0.925682	val: 0.792669	test: 0.672695
PRC train: 0.777286	val: 0.599950	test: 0.549121

Epoch: 23
Loss: 0.186828531642342
ROC train: 0.933058	val: 0.799686	test: 0.703900
PRC train: 0.799759	val: 0.593731	test: 0.551067

Epoch: 24
Loss: 0.17565315651483968
ROC train: 0.936483	val: 0.770804	test: 0.692694
PRC train: 0.809008	val: 0.586347	test: 0.548187

Epoch: 25
Loss: 0.1769698482309658
ROC train: 0.938802	val: 0.807115	test: 0.672251
PRC train: 0.807795	val: 0.608571	test: 0.540957

Epoch: 26
Loss: 0.17140601152300775
ROC train: 0.943314	val: 0.845700	test: 0.684342
PRC train: 0.792611	val: 0.594027	test: 0.549341

Epoch: 27
Loss: 0.16295031388388187
ROC train: 0.942578	val: 0.855652	test: 0.698204
PRC train: 0.793800	val: 0.593590	test: 0.553323

Epoch: 28
Loss: 0.1683074852245656
ROC train: 0.943214	val: 0.859349	test: 0.692033
PRC train: 0.810914	val: 0.587993	test: 0.549362

Epoch: 29
Loss: 0.16522747672774296
ROC train: 0.945649	val: 0.832951	test: 0.698473
PRC train: 0.819515	val: 0.595446	test: 0.553012

Epoch: 30
Loss: 0.1615485052030598
ROC train: 0.941159	val: 0.812734	test: 0.690472
PRC train: 0.811975	val: 0.580276	test: 0.550055

Epoch: 31
Loss: 0.1699204539082056
ROC train: 0.948034	val: 0.825072	test: 0.719401
PRC train: 0.825482	val: 0.574936	test: 0.558252

Epoch: 32
Loss: 0.15400491565261198
ROC train: 0.951298	val: 0.866978	test: 0.750382
PRC train: 0.829679	val: 0.605275	test: 0.574913

Epoch: 33
Loss: 0.15703929705156333Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/clintox/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/clintox/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/clintox/scaff/train_prop=0.8/clintox_scaff_5_26-05_11-11-03  ]
[ Using Seed :  5  ]
[ Using device :  cuda:2  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6723342121039055
ROC train: 0.618443	val: 0.690848	test: 0.438220
PRC train: 0.542517	val: 0.535817	test: 0.499199

Epoch: 2
Loss: 0.5948074059532515
ROC train: 0.682431	val: 0.790494	test: 0.463228
PRC train: 0.558524	val: 0.559316	test: 0.493586

Epoch: 3
Loss: 0.5335531239647735
ROC train: 0.706598	val: 0.844238	test: 0.458350
PRC train: 0.565545	val: 0.564923	test: 0.489843

Epoch: 4
Loss: 0.47886776434547385
ROC train: 0.738053	val: 0.862919	test: 0.451563
PRC train: 0.574882	val: 0.572029	test: 0.491531

Epoch: 5
Loss: 0.4384794501772647
ROC train: 0.775004	val: 0.882324	test: 0.502418
PRC train: 0.586438	val: 0.584322	test: 0.503877

Epoch: 6
Loss: 0.40006407466542937
ROC train: 0.791271	val: 0.879390	test: 0.521312
PRC train: 0.591294	val: 0.576353	test: 0.502123

Epoch: 7
Loss: 0.3638401437320623
ROC train: 0.816632	val: 0.882211	test: 0.533011
PRC train: 0.604953	val: 0.579803	test: 0.505732

Epoch: 8
Loss: 0.33678596586027004
ROC train: 0.829176	val: 0.869775	test: 0.526504
PRC train: 0.613611	val: 0.573483	test: 0.504785

Epoch: 9
Loss: 0.3153850522190574
ROC train: 0.838761	val: 0.850047	test: 0.520807
PRC train: 0.618739	val: 0.571363	test: 0.507069

Epoch: 10
Loss: 0.28866571587869416
ROC train: 0.853951	val: 0.846575	test: 0.567289
PRC train: 0.643248	val: 0.575747	test: 0.519439

Epoch: 11
Loss: 0.2652166294346318
ROC train: 0.856897	val: 0.848560	test: 0.584109
PRC train: 0.655017	val: 0.576659	test: 0.521121

Epoch: 12
Loss: 0.25336866278871945
ROC train: 0.862265	val: 0.850096	test: 0.588737
PRC train: 0.664175	val: 0.575473	test: 0.524073

Epoch: 13
Loss: 0.2442352055193592
ROC train: 0.872928	val: 0.836648	test: 0.621104
PRC train: 0.688255	val: 0.597040	test: 0.532976

Epoch: 14
Loss: 0.23031812364672963
ROC train: 0.893265	val: 0.818817	test: 0.628399
PRC train: 0.714603	val: 0.637649	test: 0.535315

Epoch: 15
Loss: 0.21761025085988953
ROC train: 0.897551	val: 0.817257	test: 0.629885
PRC train: 0.727657	val: 0.595684	test: 0.534841

Epoch: 16
Loss: 0.2104074195508861
ROC train: 0.893579	val: 0.824573	test: 0.637905
PRC train: 0.728978	val: 0.580247	test: 0.536595

Epoch: 17
Loss: 0.20683409139022935
ROC train: 0.901070	val: 0.848311	test: 0.651509
PRC train: 0.737563	val: 0.606231	test: 0.541476

Epoch: 18
Loss: 0.21003046328659206
ROC train: 0.900210	val: 0.834026	test: 0.656787
PRC train: 0.751851	val: 0.647708	test: 0.538957

Epoch: 19
Loss: 0.1917774636436969
ROC train: 0.910428	val: 0.861359	test: 0.652409
PRC train: 0.753505	val: 0.674132	test: 0.540391

Epoch: 20
Loss: 0.1926455334088289
ROC train: 0.908421	val: 0.863569	test: 0.645312
PRC train: 0.756052	val: 0.639163	test: 0.537012

Epoch: 21
Loss: 0.19827600934392983
ROC train: 0.914110	val: 0.827395	test: 0.636344
PRC train: 0.775007	val: 0.641935	test: 0.537592

Epoch: 22
Loss: 0.19124521954517143
ROC train: 0.924058	val: 0.865667	test: 0.681089
PRC train: 0.775184	val: 0.677981	test: 0.550747

Epoch: 23
Loss: 0.18257820164077512
ROC train: 0.929518	val: 0.860248	test: 0.683363
PRC train: 0.778526	val: 0.611734	test: 0.550202

Epoch: 24
Loss: 0.1837000132261372
ROC train: 0.926758	val: 0.845963	test: 0.679453
PRC train: 0.780708	val: 0.635938	test: 0.546976

Epoch: 25
Loss: 0.17375637018112006
ROC train: 0.921226	val: 0.867789	test: 0.678892
PRC train: 0.773697	val: 0.664259	test: 0.552316

Epoch: 26
Loss: 0.17900987270594731
ROC train: 0.935966	val: 0.863520	test: 0.666424
PRC train: 0.793884	val: 0.716035	test: 0.540789

Epoch: 27
Loss: 0.17921631281270417
ROC train: 0.934113	val: 0.858913	test: 0.683644
PRC train: 0.808767	val: 0.610955	test: 0.547560

Epoch: 28
Loss: 0.180069129970518
ROC train: 0.931764	val: 0.904364	test: 0.729027
PRC train: 0.797129	val: 0.636646	test: 0.579825

Epoch: 29
Loss: 0.17445868009469861
ROC train: 0.942962	val: 0.899894	test: 0.703829
PRC train: 0.805294	val: 0.668194	test: 0.555921

Epoch: 30
Loss: 0.16573894029699182
ROC train: 0.946283	val: 0.862009	test: 0.697053
PRC train: 0.797927	val: 0.672724	test: 0.553800

Epoch: 31
Loss: 0.17647040960147836
ROC train: 0.950229	val: 0.848423	test: 0.708995
PRC train: 0.800490	val: 0.606442	test: 0.561290

Epoch: 32
Loss: 0.16290627416280407
ROC train: 0.953322	val: 0.864469	test: 0.722610
PRC train: 0.813104	val: 0.603069	test: 0.563029

Epoch: 33
Loss: 0.16742117758969327
ROC train: 0.955381	val: 0.655560	test: 0.783116
PRC train: 0.841833	val: 0.560127	test: 0.584221

Epoch: 34
Loss: 0.16684176615553273
ROC train: 0.957468	val: 0.635176	test: 0.790720
PRC train: 0.845228	val: 0.553554	test: 0.597371

Epoch: 35
Loss: 0.17143498695995493
ROC train: 0.960983	val: 0.615425	test: 0.766092
PRC train: 0.855802	val: 0.552872	test: 0.571891

Epoch: 36
Loss: 0.14779812941025494
ROC train: 0.965542	val: 0.644313	test: 0.760236
PRC train: 0.863034	val: 0.569033	test: 0.571346

Epoch: 37
Loss: 0.14784728428863642
ROC train: 0.967558	val: 0.672503	test: 0.772266
PRC train: 0.861095	val: 0.569473	test: 0.580320

Epoch: 38
Loss: 0.14869743695698723
ROC train: 0.966852	val: 0.665422	test: 0.776098
PRC train: 0.860698	val: 0.564825	test: 0.576955

Epoch: 39
Loss: 0.1540020708953769
ROC train: 0.966566	val: 0.643137	test: 0.764160
PRC train: 0.861429	val: 0.555326	test: 0.577300

Epoch: 40
Loss: 0.14779083079577937
ROC train: 0.967418	val: 0.640707	test: 0.764541
PRC train: 0.862324	val: 0.555476	test: 0.589109

Epoch: 41
Loss: 0.15395632465977055
ROC train: 0.970238	val: 0.648874	test: 0.762961
PRC train: 0.863003	val: 0.561219	test: 0.610765

Epoch: 42
Loss: 0.12873720191203614
ROC train: 0.970609	val: 0.668937	test: 0.759075
PRC train: 0.869653	val: 0.569126	test: 0.597300

Epoch: 43
Loss: 0.15264903320848147
ROC train: 0.969493	val: 0.645429	test: 0.739453
PRC train: 0.869492	val: 0.560363	test: 0.575275

Epoch: 44
Loss: 0.144027373644404
ROC train: 0.970426	val: 0.649171	test: 0.748124
PRC train: 0.870580	val: 0.568930	test: 0.574895

Epoch: 45
Loss: 0.14243602981765774
ROC train: 0.971857	val: 0.656264	test: 0.771355
PRC train: 0.870226	val: 0.566122	test: 0.587245

Epoch: 46
Loss: 0.13998882720886
ROC train: 0.972693	val: 0.624767	test: 0.770406
PRC train: 0.873525	val: 0.561017	test: 0.585130

Epoch: 47
Loss: 0.1396925717875135
ROC train: 0.969472	val: 0.597592	test: 0.768005
PRC train: 0.870230	val: 0.558110	test: 0.584562

Epoch: 48
Loss: 0.14772045235239345
ROC train: 0.972319	val: 0.638771	test: 0.794734
PRC train: 0.874978	val: 0.558806	test: 0.600902

Epoch: 49
Loss: 0.13719127763229833
ROC train: 0.970658	val: 0.656987	test: 0.806756
PRC train: 0.866423	val: 0.556804	test: 0.602242

Epoch: 50
Loss: 0.1332215658508787
ROC train: 0.972592	val: 0.654497	test: 0.805309
PRC train: 0.873054	val: 0.561406	test: 0.593431

Epoch: 51
Loss: 0.141485569741349
ROC train: 0.971613	val: 0.650305	test: 0.798213
PRC train: 0.870704	val: 0.562285	test: 0.587177

Epoch: 52
Loss: 0.12202082870300833
ROC train: 0.975110	val: 0.660566	test: 0.803284
PRC train: 0.877584	val: 0.570773	test: 0.637258

Epoch: 53
Loss: 0.12133563436486598
ROC train: 0.975082	val: 0.668831	test: 0.799660
PRC train: 0.878697	val: 0.570171	test: 0.640539

Epoch: 54
Loss: 0.1336604905949384
ROC train: 0.975962	val: 0.655380	test: 0.782723
PRC train: 0.886813	val: 0.566176	test: 0.605640

Epoch: 55
Loss: 0.12607341814076933
ROC train: 0.975445	val: 0.653957	test: 0.794637
PRC train: 0.886939	val: 0.558815	test: 0.624765

Epoch: 56
Loss: 0.1215351594928482
ROC train: 0.975517	val: 0.680445	test: 0.802365
PRC train: 0.883948	val: 0.568397	test: 0.624930

Epoch: 57
Loss: 0.11339907373011571
ROC train: 0.974770	val: 0.696199	test: 0.793482
PRC train: 0.878478	val: 0.577484	test: 0.613834

Epoch: 58
Loss: 0.13415006293641382
ROC train: 0.973847	val: 0.665420	test: 0.780705
PRC train: 0.879962	val: 0.569978	test: 0.622822

Epoch: 59
Loss: 0.15067440338264246
ROC train: 0.976355	val: 0.632779	test: 0.758640
PRC train: 0.889976	val: 0.560753	test: 0.601204

Epoch: 60
Loss: 0.1294658717325693
ROC train: 0.974570	val: 0.663525	test: 0.766094
PRC train: 0.886086	val: 0.569030	test: 0.613342

Epoch: 61
Loss: 0.12132250663612226
ROC train: 0.974051	val: 0.682979	test: 0.763988
PRC train: 0.875935	val: 0.569038	test: 0.603565

Epoch: 62
Loss: 0.13878000547816974
ROC train: 0.977283	val: 0.660581	test: 0.781806
PRC train: 0.883618	val: 0.564099	test: 0.599592

Epoch: 63
Loss: 0.12309178556713835
ROC train: 0.978452	val: 0.659680	test: 0.789149
PRC train: 0.889729	val: 0.563228	test: 0.607948

Epoch: 64
Loss: 0.138605900470191
ROC train: 0.979750	val: 0.658921	test: 0.801933
PRC train: 0.897650	val: 0.562441	test: 0.629136

Epoch: 65
Loss: 0.12944827801762243
ROC train: 0.978482	val: 0.669739	test: 0.809147
PRC train: 0.896226	val: 0.575605	test: 0.671861

Epoch: 66
Loss: 0.11914298426608626
ROC train: 0.979556	val: 0.665087	test: 0.798022
PRC train: 0.895431	val: 0.579134	test: 0.661769

Epoch: 67
Loss: 0.12526039427921165
ROC train: 0.979208	val: 0.657000	test: 0.797273
PRC train: 0.895015	val: 0.575608	test: 0.640660

Epoch: 68
Loss: 0.12648903436406236
ROC train: 0.978401	val: 0.647666	test: 0.800718
PRC train: 0.897456	val: 0.568110	test: 0.627577

Epoch: 69
Loss: 0.12868202201136902
ROC train: 0.978443	val: 0.649595	test: 0.818768
PRC train: 0.899863	val: 0.561236	test: 0.633164

Epoch: 70
Loss: 0.12534801203714319
ROC train: 0.979890	val: 0.665791	test: 0.825267
PRC train: 0.899989	val: 0.560626	test: 0.649151

Epoch: 71
Loss: 0.1112983979484683
ROC train: 0.978757	val: 0.672772	test: 0.832416
PRC train: 0.892108	val: 0.571081	test: 0.647334

Epoch: 72
Loss: 0.11479765688522676
ROC train: 0.980031	val: 0.671439	test: 0.824108
PRC train: 0.892761	val: 0.572191	test: 0.639568

Epoch: 73
Loss: 0.12114833214893733
ROC train: 0.980249	val: 0.672245	test: 0.812892
PRC train: 0.893289	val: 0.564286	test: 0.632521

Epoch: 74
Loss: 0.11580254052477595
ROC train: 0.977841	val: 0.659037	test: 0.800014
PRC train: 0.892872	val: 0.561690	test: 0.621592

Epoch: 75
Loss: 0.12282027844593024
ROC train: 0.979913	val: 0.653118	test: 0.795500
PRC train: 0.900625	val: 0.560992	test: 0.615051

Epoch: 76
Loss: 0.11190452430155315
ROC train: 0.980881	val: 0.647252	test: 0.809310
PRC train: 0.906059	val: 0.562796	test: 0.643265

Epoch: 77
Loss: 0.11347293450048937
ROC train: 0.981138	val: 0.640741	test: 0.812452
PRC train: 0.906482	val: 0.563835	test: 0.643817

Epoch: 78
Loss: 0.10723425618214498
ROC train: 0.981059	val: 0.636940	test: 0.792777
PRC train: 0.904275	val: 0.561797	test: 0.626499

Epoch: 79
Loss: 0.11454024716825068
ROC train: 0.979429	val: 0.657377	test: 0.785118
PRC train: 0.899622	val: 0.564215	test: 0.634607

Epoch: 80
Loss: 0.12440804875445785
ROC train: 0.977214	val: 0.679604	test: 0.784141
PRC train: 0.896464	val: 0.577750	test: 0.635028

Epoch: 81
Loss: 0.10768221830969657
ROC train: 0.980025	val: 0.657913	test: 0.771349
PRC train: 0.901251	val: 0.566941	test: 0.617357

Epoch: 82
Loss: 0.1114600528074059
ROC train: 0.982012	val: 0.658337	test: 0.793338
PRC train: 0.904595	val: 0.566959	test: 0.623627

Epoch: 83
Loss: 0.11166407677171827
ROC train: 0.982582	val: 0.663287	test: 0.805039
PRC train: 0.909371	val: 0.569924	test: 0.644558

Epoch: 84
Loss: 0.11718689957880338
ROC train: 0.983738	val: 0.661353	test: 0.803315
PRC train: 0.915609	val: 0.566280	test: 0.635675

Epoch: 85
Loss: 0.1029026053670386
ROC train: 0.982868	val: 0.648623	test: 0.814788
PRC train: 0.911917	val: 0.558645	test: 0.651397

Epoch: 86
Loss: 0.11472945885702414
ROC train: 0.981573	val: 0.650086	test: 0.834179
PRC train: 0.902175	val: 0.557350	test: 0.649551

Epoch: 87
Loss: 0.122922581999777
ROC train: 0.982917	val: 0.647922	test: 0.834404
PRC train: 0.903714	val: 0.560398	test: 0.646968

Epoch: 88
Loss: 0.12082382282874596
ROC train: 0.983522	val: 0.642769	test: 0.830149
PRC train: 0.909567	val: 0.560049	test: 0.642487

Epoch: 89
Loss: 0.10290266508056826
ROC train: 0.983187	val: 0.646052	test: 0.823888
PRC train: 0.913327	val: 0.562186	test: 0.647512

Epoch: 90
Loss: 0.11838745128808859
ROC train: 0.982800	val: 0.651089	test: 0.825175
PRC train: 0.912506	val: 0.560925	test: 0.654272

Epoch: 91
Loss: 0.1235246203047538
ROC train: 0.981473	val: 0.644712	test: 0.814562
PRC train: 0.904328	val: 0.555548	test: 0.661542

Epoch: 92
Loss: 0.11067200746331815
ROC train: 0.982617	val: 0.619804	test: 0.806942
PRC train: 0.911921	val: 0.555372	test: 0.642316

Epoch: 93
Loss: 0.11816627519566869
ROC train: 0.979518	val: 0.605016	test: 0.785732
PRC train: 0.898663	val: 0.558720	test: 0.621930

Epoch: 94
Loss: 0.11188074852793078
ROC train: 0.964961	val: 0.638047	test: 0.680579
PRC train: 0.849696	val: 0.554777	test: 0.563631

Epoch: 34
Loss: 0.1687056854095321
ROC train: 0.960392	val: 0.665124	test: 0.676754
PRC train: 0.850251	val: 0.562759	test: 0.558886

Epoch: 35
Loss: 0.15088918083358374
ROC train: 0.960755	val: 0.668848	test: 0.724832
PRC train: 0.843471	val: 0.563687	test: 0.591779

Epoch: 36
Loss: 0.1505554837309953
ROC train: 0.964895	val: 0.630733	test: 0.714605
PRC train: 0.848836	val: 0.558386	test: 0.555269

Epoch: 37
Loss: 0.16038957258432376
ROC train: 0.963896	val: 0.635055	test: 0.691100
PRC train: 0.842336	val: 0.554691	test: 0.550731

Epoch: 38
Loss: 0.15582837899885077
ROC train: 0.966513	val: 0.657782	test: 0.734990
PRC train: 0.847701	val: 0.559585	test: 0.599892

Epoch: 39
Loss: 0.15790640330712222
ROC train: 0.969234	val: 0.654969	test: 0.721553
PRC train: 0.857825	val: 0.562747	test: 0.610818

Epoch: 40
Loss: 0.14549141984086839
ROC train: 0.967827	val: 0.641561	test: 0.709772
PRC train: 0.864069	val: 0.558684	test: 0.584085

Epoch: 41
Loss: 0.16037718443432547
ROC train: 0.966995	val: 0.644869	test: 0.744304
PRC train: 0.867848	val: 0.557523	test: 0.611067

Epoch: 42
Loss: 0.16644298480393918
ROC train: 0.961307	val: 0.649437	test: 0.767860
PRC train: 0.848253	val: 0.553859	test: 0.601087

Epoch: 43
Loss: 0.15174546253923685
ROC train: 0.964976	val: 0.640073	test: 0.760585
PRC train: 0.853870	val: 0.549156	test: 0.589674

Epoch: 44
Loss: 0.15644775572256386
ROC train: 0.969671	val: 0.627830	test: 0.723624
PRC train: 0.861912	val: 0.553566	test: 0.570245

Epoch: 45
Loss: 0.13486435958769025
ROC train: 0.971940	val: 0.636256	test: 0.745849
PRC train: 0.862415	val: 0.561086	test: 0.592847

Epoch: 46
Loss: 0.1431414836045971
ROC train: 0.968658	val: 0.626064	test: 0.761399
PRC train: 0.853197	val: 0.551374	test: 0.615774

Epoch: 47
Loss: 0.15130798096191383
ROC train: 0.968911	val: 0.609548	test: 0.717273
PRC train: 0.866558	val: 0.537215	test: 0.583640

Epoch: 48
Loss: 0.14144631057697804
ROC train: 0.968415	val: 0.618979	test: 0.700202
PRC train: 0.863636	val: 0.535893	test: 0.579111

Epoch: 49
Loss: 0.14461086430667167
ROC train: 0.973925	val: 0.661544	test: 0.747411
PRC train: 0.874756	val: 0.555811	test: 0.590480

Epoch: 50
Loss: 0.14552019151399515
ROC train: 0.975051	val: 0.667352	test: 0.743784
PRC train: 0.874893	val: 0.563432	test: 0.591302

Epoch: 51
Loss: 0.1336929186767156
ROC train: 0.974038	val: 0.655400	test: 0.740822
PRC train: 0.876548	val: 0.562510	test: 0.595952

Epoch: 52
Loss: 0.12848336941018187
ROC train: 0.974706	val: 0.660359	test: 0.756227
PRC train: 0.885038	val: 0.559744	test: 0.624323

Epoch: 53
Loss: 0.1215082007745153
ROC train: 0.974888	val: 0.657701	test: 0.764095
PRC train: 0.882720	val: 0.560470	test: 0.668844

Epoch: 54
Loss: 0.1265862290075734
ROC train: 0.976217	val: 0.649498	test: 0.746143
PRC train: 0.887229	val: 0.554135	test: 0.669128

Epoch: 55
Loss: 0.13262884787040946
ROC train: 0.974024	val: 0.630711	test: 0.726216
PRC train: 0.880411	val: 0.551580	test: 0.634903

Epoch: 56
Loss: 0.13338164739821445
ROC train: 0.976168	val: 0.638825	test: 0.741024
PRC train: 0.881206	val: 0.560808	test: 0.622130

Epoch: 57
Loss: 0.12948439330259884
ROC train: 0.975800	val: 0.650201	test: 0.756777
PRC train: 0.880599	val: 0.569879	test: 0.621357

Epoch: 58
Loss: 0.1332228030317204
ROC train: 0.976526	val: 0.644555	test: 0.768178
PRC train: 0.886400	val: 0.566009	test: 0.627088

Epoch: 59
Loss: 0.1211652512398374
ROC train: 0.978648	val: 0.641820	test: 0.766896
PRC train: 0.893422	val: 0.562641	test: 0.636559

Epoch: 60
Loss: 0.12032498191286825
ROC train: 0.978424	val: 0.647292	test: 0.749633
PRC train: 0.892342	val: 0.560356	test: 0.607550

Epoch: 61
Loss: 0.12415171769247949
ROC train: 0.976566	val: 0.634765	test: 0.744671
PRC train: 0.887816	val: 0.557871	test: 0.601990

Epoch: 62
Loss: 0.1222454620151503
ROC train: 0.973953	val: 0.635805	test: 0.737861
PRC train: 0.882593	val: 0.554659	test: 0.594791

Epoch: 63
Loss: 0.12112425588058187
ROC train: 0.977693	val: 0.674511	test: 0.759559
PRC train: 0.887460	val: 0.561930	test: 0.621066

Epoch: 64
Loss: 0.14057450451332584
ROC train: 0.971091	val: 0.681990	test: 0.780267
PRC train: 0.874090	val: 0.560740	test: 0.624822

Epoch: 65
Loss: 0.1240183254631914
ROC train: 0.977808	val: 0.694756	test: 0.763637
PRC train: 0.888326	val: 0.585731	test: 0.598742

Epoch: 66
Loss: 0.1245918035323831
ROC train: 0.977864	val: 0.679247	test: 0.738498
PRC train: 0.886430	val: 0.572920	test: 0.597540

Epoch: 67
Loss: 0.12683890120722027
ROC train: 0.979060	val: 0.670881	test: 0.739631
PRC train: 0.886200	val: 0.563955	test: 0.589264

Epoch: 68
Loss: 0.11734301599984207
ROC train: 0.979465	val: 0.667325	test: 0.761742
PRC train: 0.892411	val: 0.561741	test: 0.622141

Epoch: 69
Loss: 0.12309077721412201
ROC train: 0.978592	val: 0.659911	test: 0.767721
PRC train: 0.890615	val: 0.559534	test: 0.628178

Epoch: 70
Loss: 0.11698851467610485
ROC train: 0.979048	val: 0.654186	test: 0.744574
PRC train: 0.889118	val: 0.559540	test: 0.622628

Epoch: 71
Loss: 0.11475850624345121
ROC train: 0.978902	val: 0.648862	test: 0.728375
PRC train: 0.890761	val: 0.556391	test: 0.628247

Epoch: 72
Loss: 0.12091380537664762
ROC train: 0.976724	val: 0.654990	test: 0.706649
PRC train: 0.881831	val: 0.559983	test: 0.581569

Epoch: 73
Loss: 0.12757482609840634
ROC train: 0.978661	val: 0.674266	test: 0.748335
PRC train: 0.890895	val: 0.575928	test: 0.605919

Epoch: 74
Loss: 0.1332854095696126
ROC train: 0.977091	val: 0.659040	test: 0.712903
PRC train: 0.885066	val: 0.569333	test: 0.592350

Epoch: 75
Loss: 0.1194142114656962
ROC train: 0.978430	val: 0.647986	test: 0.724094
PRC train: 0.889869	val: 0.563426	test: 0.617125

Epoch: 76
Loss: 0.12100410875378692
ROC train: 0.981036	val: 0.656109	test: 0.769919
PRC train: 0.899976	val: 0.557267	test: 0.662449

Epoch: 77
Loss: 0.12468012118772961
ROC train: 0.979518	val: 0.658347	test: 0.773848
PRC train: 0.895999	val: 0.558407	test: 0.660504

Epoch: 78
Loss: 0.12866808529361837
ROC train: 0.978392	val: 0.651283	test: 0.747075
PRC train: 0.896460	val: 0.566679	test: 0.642085

Epoch: 79
Loss: 0.10844438722329953
ROC train: 0.975288	val: 0.653640	test: 0.741307
PRC train: 0.888393	val: 0.569556	test: 0.632799

Epoch: 80
Loss: 0.12803983399581323
ROC train: 0.977922	val: 0.667800	test: 0.755713
PRC train: 0.897775	val: 0.570519	test: 0.662642

Epoch: 81
Loss: 0.12808224223176218
ROC train: 0.981098	val: 0.676639	test: 0.750835
PRC train: 0.903976	val: 0.572162	test: 0.637581

Epoch: 82
Loss: 0.1121656555719703
ROC train: 0.980831	val: 0.667009	test: 0.739333
PRC train: 0.902700	val: 0.569516	test: 0.632616

Epoch: 83
Loss: 0.11671103938735214
ROC train: 0.980022	val: 0.648790	test: 0.739619
PRC train: 0.903888	val: 0.564611	test: 0.638416

Epoch: 84
Loss: 0.11940713086838484
ROC train: 0.979208	val: 0.655147	test: 0.768278
PRC train: 0.898346	val: 0.561013	test: 0.647704

Epoch: 85
Loss: 0.11069459216569069
ROC train: 0.980087	val: 0.660870	test: 0.777767
PRC train: 0.897386	val: 0.561288	test: 0.648627

Epoch: 86
Loss: 0.12164633241572337
ROC train: 0.981998	val: 0.652366	test: 0.748616
PRC train: 0.904480	val: 0.567652	test: 0.649554

Epoch: 87
Loss: 0.11045007849130326
ROC train: 0.980172	val: 0.655396	test: 0.728727
PRC train: 0.903142	val: 0.570748	test: 0.637360

Epoch: 88
Loss: 0.11085183424011939
ROC train: 0.981106	val: 0.662211	test: 0.735836
PRC train: 0.903763	val: 0.572309	test: 0.652063

Epoch: 89
Loss: 0.11190432748546762
ROC train: 0.982041	val: 0.652177	test: 0.762942
PRC train: 0.906993	val: 0.571081	test: 0.656046

Epoch: 90
Loss: 0.1088593079146097
ROC train: 0.981017	val: 0.638074	test: 0.777528
PRC train: 0.902513	val: 0.555546	test: 0.669060

Epoch: 91
Loss: 0.10845762736806477
ROC train: 0.982330	val: 0.632639	test: 0.755330
PRC train: 0.906730	val: 0.553997	test: 0.634105

Epoch: 92
Loss: 0.1076503357688686
ROC train: 0.981997	val: 0.651473	test: 0.740060
PRC train: 0.903184	val: 0.560024	test: 0.630360

Epoch: 93
Loss: 0.13435529882432906
ROC train: 0.983121	val: 0.667709	test: 0.738652
PRC train: 0.907934	val: 0.569415	test: 0.641973

Epoch: 94
Loss: 0.11359073533198823
ROC train: 0.957947	val: 0.643252	test: 0.785087
PRC train: 0.827729	val: 0.548728	test: 0.583209

Epoch: 34
Loss: 0.15512896922059088
ROC train: 0.956766	val: 0.597511	test: 0.758316
PRC train: 0.840042	val: 0.534131	test: 0.578412

Epoch: 35
Loss: 0.16424319710421995
ROC train: 0.962188	val: 0.607931	test: 0.722683
PRC train: 0.855304	val: 0.556125	test: 0.557785

Epoch: 36
Loss: 0.1558409496224431
ROC train: 0.944073	val: 0.662084	test: 0.692584
PRC train: 0.825407	val: 0.557060	test: 0.567939

Epoch: 37
Loss: 0.1524921034587102
ROC train: 0.946294	val: 0.658116	test: 0.695030
PRC train: 0.826311	val: 0.554591	test: 0.568591

Epoch: 38
Loss: 0.1523771001312208
ROC train: 0.959194	val: 0.618930	test: 0.690774
PRC train: 0.844694	val: 0.550687	test: 0.541222

Epoch: 39
Loss: 0.15073311645881532
ROC train: 0.966183	val: 0.623667	test: 0.721322
PRC train: 0.855739	val: 0.546348	test: 0.560893

Epoch: 40
Loss: 0.13921380900852562
ROC train: 0.967590	val: 0.630957	test: 0.749223
PRC train: 0.847048	val: 0.550240	test: 0.607798

Epoch: 41
Loss: 0.1523162636061465
ROC train: 0.970620	val: 0.639982	test: 0.756588
PRC train: 0.856058	val: 0.553590	test: 0.607783

Epoch: 42
Loss: 0.1464616893005304
ROC train: 0.969524	val: 0.624735	test: 0.744740
PRC train: 0.862749	val: 0.559940	test: 0.575888

Epoch: 43
Loss: 0.15846643796293952
ROC train: 0.967988	val: 0.620066	test: 0.738219
PRC train: 0.863284	val: 0.548623	test: 0.573465

Epoch: 44
Loss: 0.1519653700371227
ROC train: 0.967156	val: 0.636725	test: 0.739022
PRC train: 0.857581	val: 0.551515	test: 0.583144

Epoch: 45
Loss: 0.1431170731043225
ROC train: 0.967788	val: 0.629473	test: 0.715355
PRC train: 0.860891	val: 0.552700	test: 0.596341

Epoch: 46
Loss: 0.1312657443368574
ROC train: 0.971939	val: 0.619412	test: 0.747579
PRC train: 0.872849	val: 0.546787	test: 0.618355

Epoch: 47
Loss: 0.1456321982492807
ROC train: 0.970086	val: 0.614525	test: 0.762835
PRC train: 0.865735	val: 0.540049	test: 0.616448

Epoch: 48
Loss: 0.1402358509453256
ROC train: 0.971635	val: 0.600615	test: 0.743224
PRC train: 0.876620	val: 0.537071	test: 0.586169

Epoch: 49
Loss: 0.1329182590135211
ROC train: 0.972198	val: 0.624184	test: 0.748001
PRC train: 0.875379	val: 0.543833	test: 0.599139

Epoch: 50
Loss: 0.14361488095335423
ROC train: 0.970811	val: 0.662290	test: 0.753694
PRC train: 0.865582	val: 0.554028	test: 0.586341

Epoch: 51
Loss: 0.13636713119802918
ROC train: 0.973616	val: 0.669585	test: 0.741834
PRC train: 0.873072	val: 0.555711	test: 0.578785

Epoch: 52
Loss: 0.14630205782621256
ROC train: 0.974990	val: 0.677676	test: 0.747757
PRC train: 0.872935	val: 0.555866	test: 0.577195

Epoch: 53
Loss: 0.1341719932421944
ROC train: 0.976434	val: 0.674774	test: 0.738000
PRC train: 0.880744	val: 0.556053	test: 0.573462

Epoch: 54
Loss: 0.15422419628972936
ROC train: 0.975849	val: 0.658185	test: 0.717751
PRC train: 0.879572	val: 0.559564	test: 0.565334

Epoch: 55
Loss: 0.13418779473977074
ROC train: 0.976269	val: 0.666143	test: 0.743389
PRC train: 0.884050	val: 0.554706	test: 0.580934

Epoch: 56
Loss: 0.13906198796569547
ROC train: 0.976072	val: 0.661234	test: 0.752745
PRC train: 0.885456	val: 0.560707	test: 0.600527

Epoch: 57
Loss: 0.14548046322964694
ROC train: 0.973822	val: 0.642479	test: 0.732031
PRC train: 0.880984	val: 0.557944	test: 0.590710

Epoch: 58
Loss: 0.13440851343607563
ROC train: 0.973878	val: 0.662692	test: 0.745819
PRC train: 0.879476	val: 0.565742	test: 0.616521

Epoch: 59
Loss: 0.12860372419633764
ROC train: 0.977193	val: 0.658538	test: 0.743967
PRC train: 0.892415	val: 0.559983	test: 0.616276

Epoch: 60
Loss: 0.15165111242845108
ROC train: 0.976862	val: 0.643815	test: 0.733549
PRC train: 0.893384	val: 0.555984	test: 0.595985

Epoch: 61
Loss: 0.14050943217801465
ROC train: 0.974522	val: 0.659889	test: 0.737364
PRC train: 0.879485	val: 0.559304	test: 0.593862

Epoch: 62
Loss: 0.1180706677180084
ROC train: 0.972946	val: 0.652175	test: 0.752647
PRC train: 0.874298	val: 0.567524	test: 0.609934

Epoch: 63
Loss: 0.12716101122507512
ROC train: 0.976317	val: 0.638263	test: 0.747882
PRC train: 0.884383	val: 0.549320	test: 0.606289

Epoch: 64
Loss: 0.13556958376802863
ROC train: 0.977495	val: 0.618915	test: 0.740284
PRC train: 0.888907	val: 0.544700	test: 0.616794

Epoch: 65
Loss: 0.13361664904383722
ROC train: 0.978220	val: 0.623343	test: 0.757891
PRC train: 0.889829	val: 0.544509	test: 0.633100

Epoch: 66
Loss: 0.1237269491650077
ROC train: 0.978461	val: 0.634603	test: 0.765202
PRC train: 0.891638	val: 0.547016	test: 0.634803

Epoch: 67
Loss: 0.11211346683230797
ROC train: 0.979834	val: 0.642364	test: 0.750562
PRC train: 0.898344	val: 0.551912	test: 0.621600

Epoch: 68
Loss: 0.13002446006167645
ROC train: 0.978078	val: 0.631143	test: 0.727628
PRC train: 0.888045	val: 0.546988	test: 0.614306

Epoch: 69
Loss: 0.13190616567123173
ROC train: 0.979322	val: 0.643091	test: 0.763729
PRC train: 0.896954	val: 0.552780	test: 0.621905

Epoch: 70
Loss: 0.10984901134794474
ROC train: 0.978754	val: 0.660416	test: 0.785620
PRC train: 0.897249	val: 0.563127	test: 0.643315

Epoch: 71
Loss: 0.13670456729144861
ROC train: 0.979496	val: 0.638779	test: 0.785855
PRC train: 0.897709	val: 0.558206	test: 0.621092

Epoch: 72
Loss: 0.14718541341707764
ROC train: 0.979957	val: 0.641882	test: 0.798565
PRC train: 0.901543	val: 0.559322	test: 0.631877

Epoch: 73
Loss: 0.11904147313651167
ROC train: 0.976960	val: 0.630249	test: 0.783721
PRC train: 0.892537	val: 0.556272	test: 0.660501

Epoch: 74
Loss: 0.11795003205234905
ROC train: 0.979990	val: 0.619104	test: 0.745276
PRC train: 0.896885	val: 0.558933	test: 0.636178

Epoch: 75
Loss: 0.13175962729480062
ROC train: 0.978231	val: 0.618330	test: 0.730211
PRC train: 0.891310	val: 0.556438	test: 0.608128

Epoch: 76
Loss: 0.12213316844592592
ROC train: 0.978511	val: 0.639611	test: 0.766747
PRC train: 0.894685	val: 0.558844	test: 0.642181

Epoch: 77
Loss: 0.11765960595054359
ROC train: 0.979685	val: 0.650716	test: 0.755825
PRC train: 0.900131	val: 0.559784	test: 0.644642

Epoch: 78
Loss: 0.13132970895765259
ROC train: 0.979812	val: 0.637110	test: 0.730715
PRC train: 0.902077	val: 0.557552	test: 0.614484

Epoch: 79
Loss: 0.12234101134333412
ROC train: 0.980040	val: 0.636821	test: 0.741501
PRC train: 0.901867	val: 0.561594	test: 0.615474

Epoch: 80
Loss: 0.11852689653158235
ROC train: 0.980788	val: 0.643752	test: 0.772666
PRC train: 0.903961	val: 0.562734	test: 0.634252

Epoch: 81
Loss: 0.11131366749684685
ROC train: 0.981656	val: 0.646425	test: 0.781330
PRC train: 0.905604	val: 0.562796	test: 0.643711

Epoch: 82
Loss: 0.11646238523396593
ROC train: 0.980845	val: 0.656323	test: 0.788423
PRC train: 0.902190	val: 0.564614	test: 0.645346

Epoch: 83
Loss: 0.11790801318854083
ROC train: 0.981899	val: 0.645865	test: 0.785708
PRC train: 0.907304	val: 0.553690	test: 0.640819

Epoch: 84
Loss: 0.12823788077799264
ROC train: 0.980503	val: 0.639554	test: 0.732683
PRC train: 0.896788	val: 0.552904	test: 0.615537

Epoch: 85
Loss: 0.12160452533098157
ROC train: 0.972565	val: 0.662805	test: 0.693806
PRC train: 0.868267	val: 0.564564	test: 0.596766

Epoch: 86
Loss: 0.11315931835399386
ROC train: 0.962852	val: 0.685996	test: 0.685123
PRC train: 0.850907	val: 0.573611	test: 0.560513

Epoch: 87
Loss: 0.12569228186254905
ROC train: 0.978853	val: 0.681542	test: 0.714775
PRC train: 0.893615	val: 0.577463	test: 0.596124

Epoch: 88
Loss: 0.11969033459762787
ROC train: 0.981505	val: 0.637615	test: 0.727605
PRC train: 0.902234	val: 0.556921	test: 0.610362

Epoch: 89
Loss: 0.11432434010139418
ROC train: 0.978843	val: 0.617583	test: 0.738996
PRC train: 0.892669	val: 0.538585	test: 0.636698

Epoch: 90
Loss: 0.12847683844410893
ROC train: 0.978444	val: 0.619198	test: 0.744051
PRC train: 0.893769	val: 0.538851	test: 0.636588

Epoch: 91
Loss: 0.11827386078238092
ROC train: 0.979678	val: 0.635964	test: 0.750273
PRC train: 0.898212	val: 0.544711	test: 0.641435

Epoch: 92
Loss: 0.11704384550865526
ROC train: 0.981139	val: 0.645576	test: 0.753570
PRC train: 0.902324	val: 0.552148	test: 0.646233

Epoch: 93
Loss: 0.11056124469675728
ROC train: 0.982043	val: 0.638733	test: 0.773291
PRC train: 0.908069	val: 0.568478	test: 0.632396

Epoch: 94
Loss: 0.12231582919841258
ROC train: 0.901908	val: 0.675820	test: 0.649494
PRC train: 0.727136	val: 0.572892	test: 0.532859

Epoch: 34
Loss: 0.1798286398311618
ROC train: 0.902942	val: 0.655660	test: 0.649962
PRC train: 0.734858	val: 0.573620	test: 0.532434

Epoch: 35
Loss: 0.20266518383995727
ROC train: 0.900426	val: 0.670345	test: 0.669461
PRC train: 0.730646	val: 0.591675	test: 0.534165

Epoch: 36
Loss: 0.22880461899553456
ROC train: 0.904165	val: 0.712485	test: 0.670830
PRC train: 0.734356	val: 0.590515	test: 0.538876

Epoch: 37
Loss: 0.22323493398140962
ROC train: 0.901244	val: 0.717201	test: 0.644562
PRC train: 0.723309	val: 0.591548	test: 0.535273

Epoch: 38
Loss: 0.17234538513664677
ROC train: 0.901519	val: 0.709922	test: 0.624449
PRC train: 0.730169	val: 0.574759	test: 0.527368

Epoch: 39
Loss: 0.16352033279443098
ROC train: 0.903464	val: 0.693052	test: 0.626909
PRC train: 0.736525	val: 0.562525	test: 0.524617

Epoch: 40
Loss: 0.18661319097959525
ROC train: 0.910566	val: 0.675486	test: 0.625248
PRC train: 0.742777	val: 0.573022	test: 0.527481

Epoch: 41
Loss: 0.22503039350971915
ROC train: 0.916774	val: 0.676003	test: 0.653315
PRC train: 0.741666	val: 0.603445	test: 0.535205

Epoch: 42
Loss: 0.2217181943209127
ROC train: 0.913885	val: 0.674724	test: 0.646629
PRC train: 0.744095	val: 0.635525	test: 0.532299

Epoch: 43
Loss: 0.25722393015578937
ROC train: 0.900376	val: 0.663276	test: 0.606790
PRC train: 0.736391	val: 0.619857	test: 0.521529

Epoch: 44
Loss: 0.16578942435553237
ROC train: 0.907643	val: 0.673261	test: 0.624154
PRC train: 0.734589	val: 0.628318	test: 0.524583

Epoch: 45
Loss: 0.16111204801982765
ROC train: 0.912605	val: 0.673669	test: 0.622408
PRC train: 0.738101	val: 0.635084	test: 0.526696

Epoch: 46
Loss: 0.16148853467726765
ROC train: 0.916635	val: 0.679984	test: 0.629834
PRC train: 0.746229	val: 0.641590	test: 0.527119

Epoch: 47
Loss: 0.16750768954513295
ROC train: 0.923920	val: 0.679007	test: 0.636473
PRC train: 0.758403	val: 0.651634	test: 0.529243

Epoch: 48
Loss: 0.22852049000973862
ROC train: 0.925167	val: 0.661411	test: 0.622867
PRC train: 0.760372	val: 0.614632	test: 0.530053

Epoch: 49
Loss: 0.15821128893690248
ROC train: 0.880340	val: 0.633738	test: 0.580851
PRC train: 0.656142	val: 0.549054	test: 0.517720

Epoch: 50
Loss: 0.16437570517264127
ROC train: 0.927258	val: 0.663383	test: 0.650418
PRC train: 0.773759	val: 0.613424	test: 0.535600

Epoch: 51
Loss: 0.2093980423574687
ROC train: 0.921752	val: 0.664151	test: 0.672012
PRC train: 0.761402	val: 0.601280	test: 0.540124

Epoch: 52
Loss: 0.1583107603341825
ROC train: 0.913006	val: 0.644313	test: 0.654954
PRC train: 0.754809	val: 0.618285	test: 0.546862

Epoch: 53
Loss: 0.2107087205013504
ROC train: 0.919542	val: 0.661910	test: 0.649608
PRC train: 0.767059	val: 0.594282	test: 0.539013

Epoch: 54
Loss: 0.1575201144406843
ROC train: 0.915045	val: 0.691924	test: 0.690918
PRC train: 0.739563	val: 0.606708	test: 0.550042

Epoch: 55
Loss: 0.15349725151319096
ROC train: 0.907777	val: 0.688842	test: 0.706547
PRC train: 0.722500	val: 0.593768	test: 0.551076

Epoch: 56
Loss: 0.21216419130566927
ROC train: 0.924488	val: 0.694600	test: 0.724376
PRC train: 0.748492	val: 0.604547	test: 0.561483

Epoch: 57
Loss: 0.316026257809262
ROC train: 0.918639	val: 0.673413	test: 0.748818
PRC train: 0.752879	val: 0.632106	test: 0.553154

Epoch: 58
Loss: 0.14845394966050934
ROC train: 0.917050	val: 0.641949	test: 0.690470
PRC train: 0.770161	val: 0.600175	test: 0.536950

Epoch: 59
Loss: 0.24807176676300874
ROC train: 0.921764	val: 0.662245	test: 0.677953
PRC train: 0.777777	val: 0.571582	test: 0.537596

Epoch: 60
Loss: 0.1610937359850452
ROC train: 0.872799	val: 0.676842	test: 0.597493
PRC train: 0.666072	val: 0.576932	test: 0.528064

Epoch: 61
Loss: 0.19431744098700837
ROC train: 0.888589	val: 0.683937	test: 0.624551
PRC train: 0.696829	val: 0.573552	test: 0.535464

Epoch: 62
Loss: 0.17121891706329662
ROC train: 0.912437	val: 0.716210	test: 0.680132
PRC train: 0.761782	val: 0.596707	test: 0.547888

Epoch: 63
Loss: 0.2908515506024101
ROC train: 0.918159	val: 0.709056	test: 0.686621
PRC train: 0.752018	val: 0.587320	test: 0.544745

Epoch: 64
Loss: 0.163449616171276
ROC train: 0.922138	val: 0.689390	test: 0.633814
PRC train: 0.740219	val: 0.581064	test: 0.549357

Epoch: 65
Loss: 0.15981427014265698
ROC train: 0.917430	val: 0.680981	test: 0.605163
PRC train: 0.726739	val: 0.589503	test: 0.561131

Epoch: 66
Loss: 0.16818685466258268
ROC train: 0.920353	val: 0.679136	test: 0.629222
PRC train: 0.736445	val: 0.596639	test: 0.548019

Epoch: 67
Loss: 0.16574177378100677
ROC train: 0.925456	val: 0.676586	test: 0.658117
PRC train: 0.745194	val: 0.608415	test: 0.550311

Epoch: 68
Loss: 0.15424036557647458
ROC train: 0.919889	val: 0.677713	test: 0.663012
PRC train: 0.749543	val: 0.606072	test: 0.551303

Epoch: 69
Loss: 0.19024632086330712
ROC train: 0.923793	val: 0.689067	test: 0.674506
PRC train: 0.759215	val: 0.626857	test: 0.554632

Epoch: 70
Loss: 0.1438255215254925
ROC train: 0.930727	val: 0.703889	test: 0.680218
PRC train: 0.774383	val: 0.604020	test: 0.556251

Epoch: 71
Loss: 0.1439838464034749
ROC train: 0.933205	val: 0.718105	test: 0.674478
PRC train: 0.773278	val: 0.607843	test: 0.549523

Epoch: 72
Loss: 0.17306798607263127
ROC train: 0.938156	val: 0.722389	test: 0.685617
PRC train: 0.783959	val: 0.620057	test: 0.559900

Epoch: 73
Loss: 0.13870176894963543
ROC train: 0.940951	val: 0.719826	test: 0.700076
PRC train: 0.788373	val: 0.617437	test: 0.563184

Epoch: 74
Loss: 0.14010458598004258
ROC train: 0.945182	val: 0.715740	test: 0.701644
PRC train: 0.798275	val: 0.601114	test: 0.565050

Epoch: 75
Loss: 0.17550607701316004
ROC train: 0.943211	val: 0.716867	test: 0.709609
PRC train: 0.798602	val: 0.592569	test: 0.567924

Epoch: 76
Loss: 0.13831512063817444
ROC train: 0.932636	val: 0.720302	test: 0.727574
PRC train: 0.780402	val: 0.585045	test: 0.581183

Epoch: 77
Loss: 0.15088739799419942
ROC train: 0.932347	val: 0.730604	test: 0.741389
PRC train: 0.778895	val: 0.623485	test: 0.580379

Epoch: 78
Loss: 0.138841086970019
ROC train: 0.929115	val: 0.738204	test: 0.740771
PRC train: 0.773008	val: 0.636725	test: 0.566702

Epoch: 79
Loss: 0.19100440241101233
ROC train: 0.932247	val: 0.743726	test: 0.728985
PRC train: 0.781480	val: 0.642839	test: 0.562586

Epoch: 80
Loss: 0.198809256826285
ROC train: 0.923995	val: 0.741868	test: 0.713509
PRC train: 0.756592	val: 0.665450	test: 0.561109

Epoch: 81
Loss: 0.18970257219605988
ROC train: 0.924288	val: 0.742500	test: 0.730901
PRC train: 0.756498	val: 0.658564	test: 0.566749

Epoch: 82
Loss: 0.1659690005980174
ROC train: 0.932817	val: 0.734586	test: 0.715720
PRC train: 0.766689	val: 0.634151	test: 0.564940

Epoch: 83
Loss: 0.15469773760954364
ROC train: 0.944409	val: 0.710241	test: 0.694364
PRC train: 0.799094	val: 0.626122	test: 0.568778

Epoch: 84
Loss: 0.17606059626410864
ROC train: 0.940534	val: 0.684384	test: 0.681839
PRC train: 0.804197	val: 0.598534	test: 0.552170

Epoch: 85
Loss: 0.23385564212749815
ROC train: 0.934470	val: 0.678843	test: 0.682757
PRC train: 0.800007	val: 0.589325	test: 0.559356

Epoch: 86
Loss: 0.16062771951689664
ROC train: 0.926583	val: 0.700696	test: 0.723158
PRC train: 0.793447	val: 0.600738	test: 0.582193

Epoch: 87
Loss: 0.14478697515341368
ROC train: 0.929073	val: 0.709613	test: 0.716400
PRC train: 0.789650	val: 0.593002	test: 0.568076

Epoch: 88
Loss: 0.14800825929419975
ROC train: 0.941907	val: 0.710974	test: 0.709076
PRC train: 0.807246	val: 0.588374	test: 0.571459

Epoch: 89
Loss: 0.14077614998329546
ROC train: 0.945448	val: 0.700349	test: 0.685833
PRC train: 0.814455	val: 0.581543	test: 0.580099

Epoch: 90
Loss: 0.13058886547293097
ROC train: 0.946314	val: 0.705141	test: 0.659750
PRC train: 0.813466	val: 0.586297	test: 0.571141

Epoch: 91
Loss: 0.1753055541177473
ROC train: 0.953096	val: 0.715554	test: 0.664585
PRC train: 0.822170	val: 0.597818	test: 0.571098

Epoch: 92
Loss: 0.1573425763835113
ROC train: 0.956673	val: 0.725733	test: 0.669602
PRC train: 0.821780	val: 0.602046	test: 0.572875

Epoch: 93
Loss: 0.17332062458874356
ROC train: 0.946029	val: 0.725324	test: 0.686553
PRC train: 0.792732	val: 0.603623	test: 0.554559

Epoch: 94
Loss: 0.13872557825728649
ROC train: 0.897675	val: 0.672702	test: 0.626745
PRC train: 0.740919	val: 0.573738	test: 0.529017

Epoch: 34
Loss: 0.29772183341344893
ROC train: 0.902741	val: 0.677294	test: 0.628944
PRC train: 0.741313	val: 0.578570	test: 0.529735

Epoch: 35
Loss: 0.19329381637556808
ROC train: 0.898765	val: 0.702628	test: 0.628474
PRC train: 0.733663	val: 0.576053	test: 0.530184

Epoch: 36
Loss: 0.166205637534926
ROC train: 0.887039	val: 0.713239	test: 0.633774
PRC train: 0.719069	val: 0.572079	test: 0.526458

Epoch: 37
Loss: 0.1649705499180722
ROC train: 0.892819	val: 0.707814	test: 0.632867
PRC train: 0.724837	val: 0.572148	test: 0.525504

Epoch: 38
Loss: 0.19493051626104535
ROC train: 0.905122	val: 0.698812	test: 0.636461
PRC train: 0.741464	val: 0.575827	test: 0.527089

Epoch: 39
Loss: 0.1506553713778019
ROC train: 0.911775	val: 0.677537	test: 0.637193
PRC train: 0.738186	val: 0.576100	test: 0.531291

Epoch: 40
Loss: 0.1719823157326978
ROC train: 0.913481	val: 0.680299	test: 0.642839
PRC train: 0.748435	val: 0.582897	test: 0.533415

Epoch: 41
Loss: 0.19010114382734983
ROC train: 0.906188	val: 0.698541	test: 0.658536
PRC train: 0.759892	val: 0.615120	test: 0.533863

Epoch: 42
Loss: 0.16676232254781478
ROC train: 0.910721	val: 0.713225	test: 0.679821
PRC train: 0.760472	val: 0.623026	test: 0.540132

Epoch: 43
Loss: 0.1853716251942769
ROC train: 0.912237	val: 0.719936	test: 0.685515
PRC train: 0.761613	val: 0.606934	test: 0.546980

Epoch: 44
Loss: 0.16479020919067117
ROC train: 0.904126	val: 0.711404	test: 0.678846
PRC train: 0.741418	val: 0.589736	test: 0.545585

Epoch: 45
Loss: 0.15402383229786637
ROC train: 0.913483	val: 0.720530	test: 0.698092
PRC train: 0.760080	val: 0.591505	test: 0.561559

Epoch: 46
Loss: 0.1891055486390582
ROC train: 0.918074	val: 0.721026	test: 0.721179
PRC train: 0.759440	val: 0.592113	test: 0.564350

Epoch: 47
Loss: 0.21635930486497584
ROC train: 0.913630	val: 0.669774	test: 0.719251
PRC train: 0.762704	val: 0.587341	test: 0.550483

Epoch: 48
Loss: 0.165256821664641
ROC train: 0.874898	val: 0.639980	test: 0.668214
PRC train: 0.715453	val: 0.574482	test: 0.534715

Epoch: 49
Loss: 0.19563849713670073
ROC train: 0.887922	val: 0.636501	test: 0.663843
PRC train: 0.734187	val: 0.594047	test: 0.537943

Epoch: 50
Loss: 0.18027708954148444
ROC train: 0.914991	val: 0.636575	test: 0.672088
PRC train: 0.764389	val: 0.605271	test: 0.543441

Epoch: 51
Loss: 0.14868025178219074
ROC train: 0.924944	val: 0.644586	test: 0.660078
PRC train: 0.773999	val: 0.599459	test: 0.541718

Epoch: 52
Loss: 0.1491165988059692
ROC train: 0.930055	val: 0.656658	test: 0.643298
PRC train: 0.783481	val: 0.577918	test: 0.537032

Epoch: 53
Loss: 0.1426634312003717
ROC train: 0.935299	val: 0.672347	test: 0.652618
PRC train: 0.789567	val: 0.591289	test: 0.536079

Epoch: 54
Loss: 0.1736517419689583
ROC train: 0.934258	val: 0.692061	test: 0.673871
PRC train: 0.784147	val: 0.605711	test: 0.541702

Epoch: 55
Loss: 0.15170896195651712
ROC train: 0.915769	val: 0.711119	test: 0.663548
PRC train: 0.756910	val: 0.613463	test: 0.534457

Epoch: 56
Loss: 0.1652836187113838
ROC train: 0.928227	val: 0.740666	test: 0.680759
PRC train: 0.782728	val: 0.624365	test: 0.540714

Epoch: 57
Loss: 0.1527618447289104
ROC train: 0.929410	val: 0.761469	test: 0.659664
PRC train: 0.776417	val: 0.630771	test: 0.538834

Epoch: 58
Loss: 0.141341997809158
ROC train: 0.929389	val: 0.752355	test: 0.656277
PRC train: 0.763369	val: 0.605883	test: 0.543325

Epoch: 59
Loss: 0.1473101280985935
ROC train: 0.939797	val: 0.743379	test: 0.665665
PRC train: 0.781934	val: 0.601033	test: 0.542002

Epoch: 60
Loss: 0.20849135190065615
ROC train: 0.925962	val: 0.737695	test: 0.682086
PRC train: 0.780523	val: 0.609121	test: 0.551770

Epoch: 61
Loss: 0.1477804642455937
ROC train: 0.886191	val: 0.712323	test: 0.664194
PRC train: 0.746781	val: 0.590520	test: 0.546989

Epoch: 62
Loss: 0.15214487461103482
ROC train: 0.914077	val: 0.736283	test: 0.684688
PRC train: 0.767807	val: 0.608953	test: 0.565829

Epoch: 63
Loss: 0.22130851728637801
ROC train: 0.934697	val: 0.736592	test: 0.700952
PRC train: 0.780141	val: 0.615862	test: 0.582844

Epoch: 64
Loss: 0.2130768367622812
ROC train: 0.930094	val: 0.709535	test: 0.684534
PRC train: 0.778172	val: 0.605721	test: 0.547725

Epoch: 65
Loss: 0.18496493650595427
ROC train: 0.918969	val: 0.693958	test: 0.675691
PRC train: 0.758405	val: 0.593698	test: 0.537077

Epoch: 66
Loss: 0.1667060574519635
ROC train: 0.916784	val: 0.695915	test: 0.670317
PRC train: 0.759163	val: 0.602981	test: 0.539219

Epoch: 67
Loss: 0.1762940267601867
ROC train: 0.925878	val: 0.709126	test: 0.660872
PRC train: 0.779360	val: 0.611860	test: 0.541845

Epoch: 68
Loss: 0.15299315143781778
ROC train: 0.932195	val: 0.715304	test: 0.642663
PRC train: 0.786999	val: 0.641974	test: 0.538345

Epoch: 69
Loss: 0.1976501116789286
ROC train: 0.934396	val: 0.725779	test: 0.609137
PRC train: 0.783979	val: 0.672033	test: 0.538641

Epoch: 70
Loss: 0.16975295185600986
ROC train: 0.933776	val: 0.721247	test: 0.600185
PRC train: 0.785757	val: 0.656356	test: 0.548777

Epoch: 71
Loss: 0.14499182544734432
ROC train: 0.939689	val: 0.724857	test: 0.643026
PRC train: 0.794187	val: 0.628820	test: 0.553432

Epoch: 72
Loss: 0.14464157454495585
ROC train: 0.942358	val: 0.723502	test: 0.681116
PRC train: 0.800725	val: 0.615839	test: 0.560944

Epoch: 73
Loss: 0.1396420812738845
ROC train: 0.939859	val: 0.724878	test: 0.700464
PRC train: 0.803983	val: 0.606620	test: 0.560884

Epoch: 74
Loss: 0.14619175442628643
ROC train: 0.944800	val: 0.725212	test: 0.707684
PRC train: 0.807674	val: 0.608785	test: 0.564805

Epoch: 75
Loss: 0.1321923574846895
ROC train: 0.947794	val: 0.732431	test: 0.694546
PRC train: 0.805568	val: 0.619057	test: 0.565391

Epoch: 76
Loss: 0.2330099077731293
ROC train: 0.946111	val: 0.736443	test: 0.685356
PRC train: 0.799727	val: 0.625364	test: 0.571148

Epoch: 77
Loss: 0.16784426959785823
ROC train: 0.912980	val: 0.737658	test: 0.665855
PRC train: 0.748172	val: 0.616339	test: 0.565409

Epoch: 78
Loss: 0.1947379566051505
ROC train: 0.919762	val: 0.735157	test: 0.644894
PRC train: 0.766723	val: 0.605649	test: 0.565454

Epoch: 79
Loss: 0.13812169180602746
ROC train: 0.923146	val: 0.684271	test: 0.650090
PRC train: 0.786273	val: 0.588321	test: 0.552813

Epoch: 80
Loss: 0.23563197791962365
ROC train: 0.928687	val: 0.684659	test: 0.690311
PRC train: 0.784978	val: 0.588487	test: 0.563108

Epoch: 81
Loss: 0.1760944732052097
ROC train: 0.930917	val: 0.715333	test: 0.699960
PRC train: 0.784592	val: 0.608385	test: 0.587292

Epoch: 82
Loss: 0.17198377277875637
ROC train: 0.894835	val: 0.723555	test: 0.676762
PRC train: 0.722669	val: 0.624002	test: 0.592950

Epoch: 83
Loss: 0.24581857662374756
ROC train: 0.916653	val: 0.729437	test: 0.649460
PRC train: 0.751604	val: 0.625466	test: 0.578965

Epoch: 84
Loss: 0.16123282209429338
ROC train: 0.910108	val: 0.702997	test: 0.645430
PRC train: 0.737189	val: 0.587698	test: 0.562595

Epoch: 85
Loss: 0.154554038887087
ROC train: 0.919332	val: 0.711852	test: 0.681655
PRC train: 0.762719	val: 0.595654	test: 0.551420

Epoch: 86
Loss: 0.151853870178063
ROC train: 0.936591	val: 0.737546	test: 0.710862
PRC train: 0.782740	val: 0.618479	test: 0.570935

Epoch: 87
Loss: 0.13967871943492266
ROC train: 0.941462	val: 0.757544	test: 0.718095
PRC train: 0.789842	val: 0.640547	test: 0.581166

Epoch: 88
Loss: 0.17723026899179045
ROC train: 0.941617	val: 0.758720	test: 0.709458
PRC train: 0.791059	val: 0.664582	test: 0.582439

Epoch: 89
Loss: 0.14491547854498926
ROC train: 0.926209	val: 0.762856	test: 0.679262
PRC train: 0.759887	val: 0.619713	test: 0.590667

Epoch: 90
Loss: 0.15342230039205387
ROC train: 0.935194	val: 0.739948	test: 0.668174
PRC train: 0.775556	val: 0.616425	test: 0.581041

Epoch: 91
Loss: 0.19670615110071266
ROC train: 0.944473	val: 0.718737	test: 0.666459
PRC train: 0.804465	val: 0.611423	test: 0.574176

Epoch: 92
Loss: 0.1649827521640612
ROC train: 0.944993	val: 0.737932	test: 0.668106
PRC train: 0.806903	val: 0.620681	test: 0.572115

Epoch: 93
Loss: 0.20605196279551247
ROC train: 0.941484	val: 0.758538	test: 0.709626
PRC train: 0.801484	val: 0.633337	test: 0.574362

Epoch: 94
Loss: 0.161947987252196
ROC train: 0.912699	val: 0.720327	test: 0.657153
PRC train: 0.740381	val: 0.593497	test: 0.534874

Epoch: 34
Loss: 0.16135948018359536
ROC train: 0.915790	val: 0.728171	test: 0.658335
PRC train: 0.747093	val: 0.602009	test: 0.538232

Epoch: 35
Loss: 0.1647241141003242
ROC train: 0.919032	val: 0.722835	test: 0.647482
PRC train: 0.750854	val: 0.604330	test: 0.532343

Epoch: 36
Loss: 0.18588858343523446
ROC train: 0.917843	val: 0.715765	test: 0.631705
PRC train: 0.745280	val: 0.597552	test: 0.532530

Epoch: 37
Loss: 0.16426647961808824
ROC train: 0.911923	val: 0.686752	test: 0.596648
PRC train: 0.751594	val: 0.574154	test: 0.524330

Epoch: 38
Loss: 0.1645754837042895
ROC train: 0.906258	val: 0.688968	test: 0.620662
PRC train: 0.758860	val: 0.573700	test: 0.526175

Epoch: 39
Loss: 0.15397451043338128
ROC train: 0.907852	val: 0.691383	test: 0.642232
PRC train: 0.760703	val: 0.578581	test: 0.532391

Epoch: 40
Loss: 0.1506282926451274
ROC train: 0.914679	val: 0.690380	test: 0.658803
PRC train: 0.768240	val: 0.577320	test: 0.537225

Epoch: 41
Loss: 0.1500827941675338
ROC train: 0.923115	val: 0.694701	test: 0.673469
PRC train: 0.776101	val: 0.598817	test: 0.542515

Epoch: 42
Loss: 0.14341841700581587
ROC train: 0.927996	val: 0.699516	test: 0.677573
PRC train: 0.779640	val: 0.598310	test: 0.539890

Epoch: 43
Loss: 0.15227324726999975
ROC train: 0.933914	val: 0.699007	test: 0.667936
PRC train: 0.786530	val: 0.589510	test: 0.538462

Epoch: 44
Loss: 0.18290550978513326
ROC train: 0.926692	val: 0.705820	test: 0.666178
PRC train: 0.755589	val: 0.588345	test: 0.538837

Epoch: 45
Loss: 0.21863291318314698
ROC train: 0.905774	val: 0.697151	test: 0.667794
PRC train: 0.717657	val: 0.613561	test: 0.537490

Epoch: 46
Loss: 0.21555925743262055
ROC train: 0.820368	val: 0.666721	test: 0.667426
PRC train: 0.687544	val: 0.570219	test: 0.547384

Epoch: 47
Loss: 0.3310815170791911
ROC train: 0.816441	val: 0.684915	test: 0.692902
PRC train: 0.661154	val: 0.577050	test: 0.544366

Epoch: 48
Loss: 0.1734290683407172
ROC train: 0.868141	val: 0.688803	test: 0.694597
PRC train: 0.715857	val: 0.585410	test: 0.555243

Epoch: 49
Loss: 0.1869365411462453
ROC train: 0.874100	val: 0.707329	test: 0.668296
PRC train: 0.730508	val: 0.584891	test: 0.539138

Epoch: 50
Loss: 0.24865222364803322
ROC train: 0.870638	val: 0.717952	test: 0.603247
PRC train: 0.700767	val: 0.573495	test: 0.523340

Epoch: 51
Loss: 0.19098123422860563
ROC train: 0.887478	val: 0.725163	test: 0.594686
PRC train: 0.708898	val: 0.571612	test: 0.516145

Epoch: 52
Loss: 0.16395988609248655
ROC train: 0.888528	val: 0.716907	test: 0.637731
PRC train: 0.704770	val: 0.570438	test: 0.522628

Epoch: 53
Loss: 0.1742159818694393
ROC train: 0.911588	val: 0.718083	test: 0.672641
PRC train: 0.727496	val: 0.576253	test: 0.533052

Epoch: 54
Loss: 0.17484018669945245
ROC train: 0.927210	val: 0.734664	test: 0.704722
PRC train: 0.756737	val: 0.590937	test: 0.546065

Epoch: 55
Loss: 0.15808766489861298
ROC train: 0.921947	val: 0.697390	test: 0.697868
PRC train: 0.746725	val: 0.590835	test: 0.541281

Epoch: 56
Loss: 0.15273075255404195
ROC train: 0.929458	val: 0.684895	test: 0.691275
PRC train: 0.767031	val: 0.594821	test: 0.576377

Epoch: 57
Loss: 0.20407750938173966
ROC train: 0.937996	val: 0.701511	test: 0.692859
PRC train: 0.781694	val: 0.600827	test: 0.585317

Epoch: 58
Loss: 0.1470473753341729
ROC train: 0.907960	val: 0.712332	test: 0.599539
PRC train: 0.739620	val: 0.584856	test: 0.567744

Epoch: 59
Loss: 0.15248491015132698
ROC train: 0.932694	val: 0.716065	test: 0.649375
PRC train: 0.782304	val: 0.588706	test: 0.574947

Epoch: 60
Loss: 0.15523121505343712
ROC train: 0.932167	val: 0.686064	test: 0.666473
PRC train: 0.792431	val: 0.577751	test: 0.569701

Epoch: 61
Loss: 0.14355134302973177
ROC train: 0.925586	val: 0.664482	test: 0.663922
PRC train: 0.790883	val: 0.568661	test: 0.569378

Epoch: 62
Loss: 0.2596892802474847
ROC train: 0.927920	val: 0.668305	test: 0.700000
PRC train: 0.775935	val: 0.577057	test: 0.579841

Epoch: 63
Loss: 0.19171347217483894
ROC train: 0.881450	val: 0.667285	test: 0.716995
PRC train: 0.724107	val: 0.597286	test: 0.553988

Epoch: 64
Loss: 0.18720887472226436
ROC train: 0.893482	val: 0.677130	test: 0.703942
PRC train: 0.715991	val: 0.606227	test: 0.590056

Epoch: 65
Loss: 0.2714663375955772
ROC train: 0.926442	val: 0.681474	test: 0.670382
PRC train: 0.744054	val: 0.615253	test: 0.576324

Epoch: 66
Loss: 0.18966470694889406
ROC train: 0.891802	val: 0.708666	test: 0.629851
PRC train: 0.709410	val: 0.598206	test: 0.570063

Epoch: 67
Loss: 0.19711413363862865
ROC train: 0.876994	val: 0.709630	test: 0.605891
PRC train: 0.700239	val: 0.593862	test: 0.564200

Epoch: 68
Loss: 0.21123825576438565
ROC train: 0.909404	val: 0.724887	test: 0.629392
PRC train: 0.738238	val: 0.625807	test: 0.567457

Epoch: 69
Loss: 0.18829585240247787
ROC train: 0.909505	val: 0.696684	test: 0.614607
PRC train: 0.745089	val: 0.596497	test: 0.560561

Epoch: 70
Loss: 0.16479611336166727
ROC train: 0.890640	val: 0.673952	test: 0.598873
PRC train: 0.713686	val: 0.571195	test: 0.556123

Epoch: 71
Loss: 0.18876238791187697
ROC train: 0.916777	val: 0.686717	test: 0.637476
PRC train: 0.745719	val: 0.587481	test: 0.564694

Epoch: 72
Loss: 0.15495127955738483
ROC train: 0.929773	val: 0.718668	test: 0.667851
PRC train: 0.764498	val: 0.605715	test: 0.577367

Epoch: 73
Loss: 0.1454519666845835
ROC train: 0.932763	val: 0.740387	test: 0.683435
PRC train: 0.775952	val: 0.612877	test: 0.579747

Epoch: 74
Loss: 0.14006288393079522
ROC train: 0.941673	val: 0.747704	test: 0.689214
PRC train: 0.795664	val: 0.619723	test: 0.581587

Epoch: 75
Loss: 0.13921791615698248
ROC train: 0.949301	val: 0.740867	test: 0.707137
PRC train: 0.805538	val: 0.623997	test: 0.582726

Epoch: 76
Loss: 0.19069150378448377
ROC train: 0.952252	val: 0.725523	test: 0.703520
PRC train: 0.808239	val: 0.634402	test: 0.582041

Epoch: 77
Loss: 0.12714595976137366
ROC train: 0.941375	val: 0.711467	test: 0.674673
PRC train: 0.785137	val: 0.672997	test: 0.574323

Epoch: 78
Loss: 0.15425447250670715
ROC train: 0.941231	val: 0.709524	test: 0.669024
PRC train: 0.788286	val: 0.664911	test: 0.574790

Epoch: 79
Loss: 0.19791661634327212
ROC train: 0.946946	val: 0.714403	test: 0.692216
PRC train: 0.796835	val: 0.653372	test: 0.580424

Epoch: 80
Loss: 0.1891312737417113
ROC train: 0.924971	val: 0.724469	test: 0.698925
PRC train: 0.767666	val: 0.612099	test: 0.563449

Epoch: 81
Loss: 0.17890794611886524
ROC train: 0.905441	val: 0.730884	test: 0.661068
PRC train: 0.758361	val: 0.584300	test: 0.552533

Epoch: 82
Loss: 0.1409664552774353
ROC train: 0.869519	val: 0.661492	test: 0.570191
PRC train: 0.717586	val: 0.550320	test: 0.554148

Epoch: 83
Loss: 0.1538864385671566
ROC train: 0.879379	val: 0.662147	test: 0.572104
PRC train: 0.738870	val: 0.551704	test: 0.554195

Epoch: 84
Loss: 0.16432837274051132
ROC train: 0.920695	val: 0.703654	test: 0.615605
PRC train: 0.771353	val: 0.569369	test: 0.564092

Epoch: 85
Loss: 0.14416698346873996
ROC train: 0.936014	val: 0.700063	test: 0.659265
PRC train: 0.768205	val: 0.578326	test: 0.573214

Epoch: 86
Loss: 0.1823766166489335
ROC train: 0.942414	val: 0.706776	test: 0.693849
PRC train: 0.794747	val: 0.598787	test: 0.583591

Epoch: 87
Loss: 0.13917841703424366
ROC train: 0.938032	val: 0.725226	test: 0.723222
PRC train: 0.799212	val: 0.601560	test: 0.591205

Epoch: 88
Loss: 0.1383029463793675
ROC train: 0.941202	val: 0.730142	test: 0.729643
PRC train: 0.807110	val: 0.600543	test: 0.589454

Epoch: 89
Loss: 0.19684327737768365
ROC train: 0.942146	val: 0.737843	test: 0.722710
PRC train: 0.805938	val: 0.605835	test: 0.588008

Epoch: 90
Loss: 0.2290464456131062
ROC train: 0.929320	val: 0.717645	test: 0.700969
PRC train: 0.791914	val: 0.593839	test: 0.580823

Epoch: 91
Loss: 0.1454630509666492
ROC train: 0.928053	val: 0.699343	test: 0.684920
PRC train: 0.773454	val: 0.604566	test: 0.574215

Epoch: 92
Loss: 0.13925919126187797
ROC train: 0.946032	val: 0.734659	test: 0.711440
PRC train: 0.803092	val: 0.625413	test: 0.578848

Epoch: 93
Loss: 0.13167029960093465
ROC train: 0.945167	val: 0.751462	test: 0.710436
PRC train: 0.806469	val: 0.655150	test: 0.581495

Epoch: 94
Loss: 0.13553030001799773
ROC train: 0.954452	val: 0.887444	test: 0.751219
PRC train: 0.832291	val: 0.618089	test: 0.574144

Epoch: 34
Loss: 0.1592577966621599
ROC train: 0.957160	val: 0.841817	test: 0.762649
PRC train: 0.837606	val: 0.567340	test: 0.572452

Epoch: 35
Loss: 0.16175667584846704
ROC train: 0.960657	val: 0.852781	test: 0.758364
PRC train: 0.842391	val: 0.575740	test: 0.567602

Epoch: 36
Loss: 0.16260801275460465
ROC train: 0.954510	val: 0.845250	test: 0.747521
PRC train: 0.832939	val: 0.627128	test: 0.584909

Epoch: 37
Loss: 0.15663135967961175
ROC train: 0.960387	val: 0.838746	test: 0.737088
PRC train: 0.841046	val: 0.603091	test: 0.580659

Epoch: 38
Loss: 0.1477677968083597
ROC train: 0.959210	val: 0.810925	test: 0.689508
PRC train: 0.837723	val: 0.604472	test: 0.562899

Epoch: 39
Loss: 0.1502538924990283
ROC train: 0.953232	val: 0.768931	test: 0.693856
PRC train: 0.824340	val: 0.631248	test: 0.560769

Epoch: 40
Loss: 0.15224745483540741
ROC train: 0.961715	val: 0.809614	test: 0.711132
PRC train: 0.834710	val: 0.593188	test: 0.559061

Epoch: 41
Loss: 0.14781608349106057
ROC train: 0.964940	val: 0.834912	test: 0.728994
PRC train: 0.842156	val: 0.596462	test: 0.586590

Epoch: 42
Loss: 0.13991480538016857
ROC train: 0.968117	val: 0.878504	test: 0.743871
PRC train: 0.856083	val: 0.614921	test: 0.577451

Epoch: 43
Loss: 0.14989730971901113
ROC train: 0.969909	val: 0.890578	test: 0.756082
PRC train: 0.859519	val: 0.611632	test: 0.569157

Epoch: 44
Loss: 0.14061564036219534
ROC train: 0.971143	val: 0.862982	test: 0.759649
PRC train: 0.866665	val: 0.615288	test: 0.571732

Epoch: 45
Loss: 0.13640278037153508
ROC train: 0.964675	val: 0.817605	test: 0.762895
PRC train: 0.847329	val: 0.602199	test: 0.592342

Epoch: 46
Loss: 0.14989023446306596
ROC train: 0.966954	val: 0.833014	test: 0.764236
PRC train: 0.849912	val: 0.618263	test: 0.602873

Epoch: 47
Loss: 0.142814545990382
ROC train: 0.971440	val: 0.819516	test: 0.774643
PRC train: 0.866133	val: 0.612975	test: 0.603100

Epoch: 48
Loss: 0.13016639020570248
ROC train: 0.973402	val: 0.792469	test: 0.768905
PRC train: 0.871264	val: 0.635220	test: 0.598454

Epoch: 49
Loss: 0.13318886997402904
ROC train: 0.969956	val: 0.782629	test: 0.729293
PRC train: 0.864125	val: 0.562143	test: 0.580956

Epoch: 50
Loss: 0.13450414013109463
ROC train: 0.969795	val: 0.870587	test: 0.768842
PRC train: 0.860516	val: 0.602303	test: 0.570742

Epoch: 51
Loss: 0.1479161365927644
ROC train: 0.973597	val: 0.875819	test: 0.771946
PRC train: 0.864591	val: 0.632194	test: 0.578332

Epoch: 52
Loss: 0.13352951558062182
ROC train: 0.975967	val: 0.859886	test: 0.755937
PRC train: 0.874418	val: 0.611618	test: 0.583081

Epoch: 53
Loss: 0.1339537421619024
ROC train: 0.972931	val: 0.846800	test: 0.732740
PRC train: 0.870912	val: 0.616424	test: 0.565737

Epoch: 54
Loss: 0.11994179795768563
ROC train: 0.977675	val: 0.817805	test: 0.746034
PRC train: 0.885550	val: 0.625316	test: 0.571619

Epoch: 55
Loss: 0.1377781294075399
ROC train: 0.975365	val: 0.814920	test: 0.768270
PRC train: 0.876781	val: 0.617815	test: 0.588088

Epoch: 56
Loss: 0.1304441184480911
ROC train: 0.975897	val: 0.829131	test: 0.742205
PRC train: 0.875835	val: 0.582169	test: 0.586113

Epoch: 57
Loss: 0.13240556164536774
ROC train: 0.977563	val: 0.820353	test: 0.720414
PRC train: 0.880034	val: 0.602946	test: 0.601356

Epoch: 58
Loss: 0.12784981784359345
ROC train: 0.975588	val: 0.763449	test: 0.729939
PRC train: 0.872926	val: 0.601551	test: 0.606048

Epoch: 59
Loss: 0.14102533267638878
ROC train: 0.977910	val: 0.767308	test: 0.747383
PRC train: 0.881528	val: 0.592989	test: 0.612465

Epoch: 60
Loss: 0.1299870124571112
ROC train: 0.977674	val: 0.807829	test: 0.762682
PRC train: 0.883385	val: 0.577937	test: 0.613495

Epoch: 61
Loss: 0.1350632748668481
ROC train: 0.977946	val: 0.805980	test: 0.764819
PRC train: 0.880339	val: 0.595636	test: 0.595861

Epoch: 62
Loss: 0.13004635991389066
ROC train: 0.972863	val: 0.781118	test: 0.784448
PRC train: 0.872138	val: 0.602664	test: 0.599333

Epoch: 63
Loss: 0.1391876719989778
ROC train: 0.978583	val: 0.843391	test: 0.788792
PRC train: 0.885866	val: 0.595948	test: 0.603740

Epoch: 64
Loss: 0.1288471293081626
ROC train: 0.978593	val: 0.821526	test: 0.781247
PRC train: 0.888276	val: 0.570119	test: 0.608366

Epoch: 65
Loss: 0.13727841668839888
ROC train: 0.978368	val: 0.803432	test: 0.767419
PRC train: 0.888827	val: 0.569470	test: 0.603081

Epoch: 66
Loss: 0.1377106455843173
ROC train: 0.978539	val: 0.824285	test: 0.763661
PRC train: 0.889546	val: 0.607374	test: 0.629050

Epoch: 67
Loss: 0.1168489456105336
ROC train: 0.976186	val: 0.826857	test: 0.738014
PRC train: 0.888331	val: 0.637469	test: 0.586870

Epoch: 68
Loss: 0.11132320492321349
ROC train: 0.974992	val: 0.818118	test: 0.723536
PRC train: 0.878738	val: 0.567621	test: 0.582079

Epoch: 69
Loss: 0.11494706803241048
ROC train: 0.977671	val: 0.786937	test: 0.757587
PRC train: 0.888770	val: 0.592990	test: 0.601005

Epoch: 70
Loss: 0.12681039280236103
ROC train: 0.977399	val: 0.790321	test: 0.740211
PRC train: 0.886301	val: 0.580030	test: 0.596175

Epoch: 71
Loss: 0.11829796066102408
ROC train: 0.980576	val: 0.817331	test: 0.732852
PRC train: 0.896440	val: 0.583611	test: 0.588890

Epoch: 72
Loss: 0.12453572680252209
ROC train: 0.981841	val: 0.842716	test: 0.757173
PRC train: 0.897344	val: 0.614783	test: 0.601638

Epoch: 73
Loss: 0.12346588016928242
ROC train: 0.980681	val: 0.842829	test: 0.767886
PRC train: 0.893645	val: 0.587912	test: 0.600468

Epoch: 74
Loss: 0.12156804551018918
ROC train: 0.980636	val: 0.853480	test: 0.777287
PRC train: 0.891209	val: 0.587847	test: 0.618463

Epoch: 75
Loss: 0.11886668892929964
ROC train: 0.981190	val: 0.847699	test: 0.788179
PRC train: 0.898341	val: 0.602588	test: 0.621264

Epoch: 76
Loss: 0.12855142984492912
ROC train: 0.979974	val: 0.805007	test: 0.749616
PRC train: 0.890173	val: 0.585612	test: 0.612655

Epoch: 77
Loss: 0.1201664438463446
ROC train: 0.981558	val: 0.812636	test: 0.766817
PRC train: 0.892604	val: 0.610163	test: 0.619434

Epoch: 78
Loss: 0.12517144052881232
ROC train: 0.982964	val: 0.827869	test: 0.761259
PRC train: 0.902762	val: 0.625261	test: 0.627620

Epoch: 79
Loss: 0.12353188096856951
ROC train: 0.981884	val: 0.829268	test: 0.756295
PRC train: 0.901673	val: 0.652314	test: 0.628235

Epoch: 80
Loss: 0.11426273843663044
ROC train: 0.982967	val: 0.817893	test: 0.758275
PRC train: 0.907763	val: 0.611588	test: 0.627498

Epoch: 81
Loss: 0.11235804411090311
ROC train: 0.981823	val: 0.842917	test: 0.781796
PRC train: 0.903167	val: 0.644442	test: 0.635703

Epoch: 82
Loss: 0.11008403560158866
ROC train: 0.980594	val: 0.891141	test: 0.796767
PRC train: 0.900995	val: 0.665756	test: 0.639715

Epoch: 83
Loss: 0.11183301722563962
ROC train: 0.982494	val: 0.829918	test: 0.755339
PRC train: 0.901225	val: 0.586322	test: 0.589921

Epoch: 84
Loss: 0.1252869555884498
ROC train: 0.981814	val: 0.721744	test: 0.751024
PRC train: 0.898229	val: 0.585755	test: 0.615250

Epoch: 85
Loss: 0.1139998229760707
ROC train: 0.982718	val: 0.804694	test: 0.774871
PRC train: 0.906887	val: 0.600180	test: 0.613886

Epoch: 86
Loss: 0.12337313712427385
ROC train: 0.983448	val: 0.850971	test: 0.779248
PRC train: 0.905596	val: 0.621066	test: 0.620211

Epoch: 87
Loss: 0.11408156076910556
ROC train: 0.981954	val: 0.846888	test: 0.759085
PRC train: 0.895983	val: 0.589376	test: 0.606522

Epoch: 88
Loss: 0.11212853495923243
ROC train: 0.980964	val: 0.846550	test: 0.756086
PRC train: 0.889926	val: 0.583503	test: 0.608893

Epoch: 89
Loss: 0.11706169829367111
ROC train: 0.983089	val: 0.875232	test: 0.760587
PRC train: 0.901818	val: 0.627356	test: 0.606032

Epoch: 90
Loss: 0.11353266222700595
ROC train: 0.981293	val: 0.781743	test: 0.739284
PRC train: 0.899709	val: 0.570269	test: 0.609324

Epoch: 91
Loss: 0.10703428504483692
ROC train: 0.980887	val: 0.718497	test: 0.728609
PRC train: 0.899494	val: 0.562868	test: 0.612671

Epoch: 92
Loss: 0.11259934781854715
ROC train: 0.979551	val: 0.757444	test: 0.759873
PRC train: 0.896277	val: 0.585440	test: 0.632913

Epoch: 93
Loss: 0.10719809617842684
ROC train: 0.984390	val: 0.840819	test: 0.789554
PRC train: 0.913528	val: 0.619020	test: 0.623312

Epoch: 94
Loss: 0.1326948069558675
ROC train: 0.946180	val: 0.865393	test: 0.756545
PRC train: 0.802303	val: 0.658769	test: 0.615380

Epoch: 34
Loss: 0.15797312183059248
ROC train: 0.955006	val: 0.826422	test: 0.711393
PRC train: 0.829294	val: 0.646039	test: 0.573221

Epoch: 35
Loss: 0.17526452995305966
ROC train: 0.961406	val: 0.813110	test: 0.752567
PRC train: 0.840526	val: 0.651576	test: 0.598032

Epoch: 36
Loss: 0.15889312804077832
ROC train: 0.962117	val: 0.804719	test: 0.758514
PRC train: 0.837533	val: 0.610365	test: 0.606266

Epoch: 37
Loss: 0.16585799272548613
ROC train: 0.961617	val: 0.801261	test: 0.746471
PRC train: 0.833279	val: 0.600864	test: 0.593636

Epoch: 38
Loss: 0.1555503516835394
ROC train: 0.958125	val: 0.801735	test: 0.776977
PRC train: 0.827880	val: 0.610588	test: 0.632417

Epoch: 39
Loss: 0.1575344326545808
ROC train: 0.966128	val: 0.804532	test: 0.761879
PRC train: 0.845896	val: 0.597197	test: 0.624261

Epoch: 40
Loss: 0.15297499949220014
ROC train: 0.966982	val: 0.812724	test: 0.774351
PRC train: 0.851787	val: 0.594213	test: 0.636494

Epoch: 41
Loss: 0.15153452963082376
ROC train: 0.967729	val: 0.811462	test: 0.769417
PRC train: 0.859602	val: 0.604157	test: 0.630251

Epoch: 42
Loss: 0.13962384115906706
ROC train: 0.967638	val: 0.813223	test: 0.754315
PRC train: 0.857131	val: 0.599539	test: 0.638220

Epoch: 43
Loss: 0.15089421851732618
ROC train: 0.969137	val: 0.839557	test: 0.728882
PRC train: 0.859095	val: 0.638627	test: 0.622341

Epoch: 44
Loss: 0.1471543520720115
ROC train: 0.969302	val: 0.835087	test: 0.745653
PRC train: 0.850990	val: 0.668466	test: 0.621994

Epoch: 45
Loss: 0.1493175768071648
ROC train: 0.966357	val: 0.872909	test: 0.793640
PRC train: 0.850127	val: 0.734197	test: 0.656875

Epoch: 46
Loss: 0.14771764226503212
ROC train: 0.969892	val: 0.860723	test: 0.788829
PRC train: 0.854874	val: 0.694671	test: 0.644609

Epoch: 47
Loss: 0.13651444587040593
ROC train: 0.968324	val: 0.806630	test: 0.787044
PRC train: 0.856718	val: 0.623773	test: 0.634871

Epoch: 48
Loss: 0.14080080394820169
ROC train: 0.973223	val: 0.827233	test: 0.814988
PRC train: 0.870604	val: 0.614361	test: 0.645527

Epoch: 49
Loss: 0.14079602709517716
ROC train: 0.972976	val: 0.854404	test: 0.794776
PRC train: 0.872813	val: 0.653707	test: 0.638254

Epoch: 50
Loss: 0.14070580071872482
ROC train: 0.975672	val: 0.832153	test: 0.776525
PRC train: 0.872290	val: 0.638598	test: 0.622256

Epoch: 51
Loss: 0.1315471260775126
ROC train: 0.975259	val: 0.822387	test: 0.793614
PRC train: 0.873381	val: 0.616121	test: 0.630637

Epoch: 52
Loss: 0.12909978801518912
ROC train: 0.978571	val: 0.827708	test: 0.785094
PRC train: 0.881461	val: 0.606320	test: 0.623198

Epoch: 53
Loss: 0.1263622756298184
ROC train: 0.977183	val: 0.850908	test: 0.786543
PRC train: 0.876678	val: 0.592476	test: 0.624532

Epoch: 54
Loss: 0.1286191062656499
ROC train: 0.973975	val: 0.829430	test: 0.741974
PRC train: 0.871507	val: 0.585330	test: 0.610474

Epoch: 55
Loss: 0.14797984152784885
ROC train: 0.976431	val: 0.831928	test: 0.751267
PRC train: 0.881585	val: 0.667123	test: 0.617263

Epoch: 56
Loss: 0.1338116506222356
ROC train: 0.971346	val: 0.867853	test: 0.788968
PRC train: 0.862889	val: 0.755120	test: 0.627232

Epoch: 57
Loss: 0.13534375734440932
ROC train: 0.972319	val: 0.874371	test: 0.778617
PRC train: 0.870755	val: 0.686294	test: 0.632497

Epoch: 58
Loss: 0.13654273292833435
ROC train: 0.970975	val: 0.818005	test: 0.741104
PRC train: 0.856552	val: 0.690693	test: 0.605989

Epoch: 59
Loss: 0.12534331637832558
ROC train: 0.976183	val: 0.848947	test: 0.776749
PRC train: 0.868244	val: 0.745597	test: 0.613191

Epoch: 60
Loss: 0.13734839772250795
ROC train: 0.974810	val: 0.817780	test: 0.759123
PRC train: 0.870201	val: 0.626273	test: 0.609499

Epoch: 61
Loss: 0.1203967223620879
ROC train: 0.976031	val: 0.850883	test: 0.792513
PRC train: 0.878246	val: 0.685471	test: 0.628597

Epoch: 62
Loss: 0.13396355171041027
ROC train: 0.971922	val: 0.867716	test: 0.770314
PRC train: 0.865295	val: 0.653210	test: 0.613337

Epoch: 63
Loss: 0.11721304299971147
ROC train: 0.976682	val: 0.863632	test: 0.797335
PRC train: 0.884829	val: 0.663551	test: 0.630381

Epoch: 64
Loss: 0.1395645840415683
ROC train: 0.978798	val: 0.859500	test: 0.796046
PRC train: 0.892772	val: 0.681008	test: 0.630874

Epoch: 65
Loss: 0.12319884719051913
ROC train: 0.980220	val: 0.867129	test: 0.795923
PRC train: 0.895059	val: 0.691922	test: 0.631387

Epoch: 66
Loss: 0.1273306439579577
ROC train: 0.979458	val: 0.833576	test: 0.775674
PRC train: 0.887577	val: 0.628691	test: 0.613174

Epoch: 67
Loss: 0.12409481847954955
ROC train: 0.980396	val: 0.859574	test: 0.796050
PRC train: 0.892301	val: 0.640474	test: 0.634672

Epoch: 68
Loss: 0.1304064135278012
ROC train: 0.978429	val: 0.865006	test: 0.775457
PRC train: 0.887942	val: 0.623056	test: 0.635862

Epoch: 69
Loss: 0.12601515769611876
ROC train: 0.979657	val: 0.873198	test: 0.792277
PRC train: 0.889015	val: 0.646722	test: 0.639466

Epoch: 70
Loss: 0.1368223199193851
ROC train: 0.980037	val: 0.874146	test: 0.810490
PRC train: 0.895784	val: 0.692559	test: 0.638079

Epoch: 71
Loss: 0.12788936848912574
ROC train: 0.977253	val: 0.886671	test: 0.804719
PRC train: 0.886682	val: 0.690033	test: 0.642786

Epoch: 72
Loss: 0.15954937845084471
ROC train: 0.979619	val: 0.834075	test: 0.771853
PRC train: 0.890805	val: 0.636508	test: 0.629323

Epoch: 73
Loss: 0.1321650037945635
ROC train: 0.976268	val: 0.793892	test: 0.749019
PRC train: 0.878401	val: 0.583965	test: 0.622112

Epoch: 74
Loss: 0.1308651776688258
ROC train: 0.976591	val: 0.805355	test: 0.748582
PRC train: 0.878191	val: 0.587536	test: 0.620831

Epoch: 75
Loss: 0.1236578922245339
ROC train: 0.980077	val: 0.815233	test: 0.753490
PRC train: 0.885204	val: 0.608157	test: 0.616711

Epoch: 76
Loss: 0.1214850732250802
ROC train: 0.980951	val: 0.819541	test: 0.759448
PRC train: 0.890052	val: 0.615845	test: 0.617509

Epoch: 77
Loss: 0.11840214892185279
ROC train: 0.981218	val: 0.844565	test: 0.773100
PRC train: 0.891522	val: 0.673567	test: 0.603290

Epoch: 78
Loss: 0.12148139302289333
ROC train: 0.981459	val: 0.815433	test: 0.762320
PRC train: 0.891971	val: 0.609098	test: 0.598231

Epoch: 79
Loss: 0.10903966620156483
ROC train: 0.980762	val: 0.804044	test: 0.766044
PRC train: 0.891016	val: 0.636354	test: 0.621269

Epoch: 80
Loss: 0.10940018863216705
ROC train: 0.981478	val: 0.822026	test: 0.762977
PRC train: 0.894621	val: 0.627435	test: 0.621662

Epoch: 81
Loss: 0.11526930954443278
ROC train: 0.979788	val: 0.825835	test: 0.762858
PRC train: 0.887838	val: 0.657038	test: 0.618952

Epoch: 82
Loss: 0.11249207181150248
ROC train: 0.981910	val: 0.867178	test: 0.783981
PRC train: 0.898936	val: 0.654546	test: 0.637011

Epoch: 83
Loss: 0.11127119197835462
ROC train: 0.983504	val: 0.859486	test: 0.812313
PRC train: 0.906353	val: 0.642356	test: 0.645294

Epoch: 84
Loss: 0.11036964991781191
ROC train: 0.983600	val: 0.828256	test: 0.801697
PRC train: 0.906951	val: 0.597602	test: 0.637770

Epoch: 85
Loss: 0.11070642652224331
ROC train: 0.983895	val: 0.838296	test: 0.818099
PRC train: 0.906898	val: 0.611164	test: 0.639168

Epoch: 86
Loss: 0.11400774171102908
ROC train: 0.983969	val: 0.870200	test: 0.832039
PRC train: 0.906469	val: 0.683306	test: 0.652670

Epoch: 87
Loss: 0.11268864007968368
ROC train: 0.981777	val: 0.864107	test: 0.797712
PRC train: 0.901631	val: 0.654601	test: 0.637368

Epoch: 88
Loss: 0.10345569572571486
ROC train: 0.983618	val: 0.843440	test: 0.799423
PRC train: 0.911009	val: 0.685866	test: 0.631837

Epoch: 89
Loss: 0.10794785956585844
ROC train: 0.984075	val: 0.840555	test: 0.810191
PRC train: 0.908652	val: 0.666383	test: 0.634950

Epoch: 90
Loss: 0.11112863526227837
ROC train: 0.983469	val: 0.855915	test: 0.811450
PRC train: 0.905883	val: 0.629140	test: 0.640438

Epoch: 91
Loss: 0.11265633991240476
ROC train: 0.983705	val: 0.865006	test: 0.819832
PRC train: 0.906450	val: 0.627362	test: 0.649878

Epoch: 92
Loss: 0.1103402215152172
ROC train: 0.982530	val: 0.876244	test: 0.834079
PRC train: 0.905436	val: 0.696316	test: 0.668195

Epoch: 93
Loss: 0.10901516093412167
ROC train: 0.984779	val: 0.859299	test: 0.837321
PRC train: 0.913620	val: 0.627870	test: 0.655394

Epoch: 94
Loss: 0.10223672386619798
ROC train: 0.945896	val: 0.881326	test: 0.726652
PRC train: 0.807540	val: 0.617757	test: 0.560767

Epoch: 34
Loss: 0.15657699596686342
ROC train: 0.955565	val: 0.875071	test: 0.704236
PRC train: 0.820418	val: 0.619977	test: 0.559563

Epoch: 35
Loss: 0.15502127943758376
ROC train: 0.958208	val: 0.886558	test: 0.735478
PRC train: 0.835050	val: 0.703087	test: 0.571097

Epoch: 36
Loss: 0.15591836835513834
ROC train: 0.956950	val: 0.892177	test: 0.766627
PRC train: 0.839535	val: 0.800523	test: 0.604729

Epoch: 37
Loss: 0.15980950722586937
ROC train: 0.951271	val: 0.855754	test: 0.730891
PRC train: 0.835088	val: 0.649156	test: 0.577532

Epoch: 38
Loss: 0.16080139858812065
ROC train: 0.956546	val: 0.840207	test: 0.728601
PRC train: 0.835064	val: 0.577562	test: 0.573441

Epoch: 39
Loss: 0.15211111862561966
ROC train: 0.958822	val: 0.847362	test: 0.745541
PRC train: 0.832595	val: 0.573896	test: 0.591613

Epoch: 40
Loss: 0.16182707756057518
ROC train: 0.958922	val: 0.872748	test: 0.771755
PRC train: 0.837371	val: 0.612402	test: 0.589758

Epoch: 41
Loss: 0.14762483855150282
ROC train: 0.960526	val: 0.883149	test: 0.739001
PRC train: 0.824227	val: 0.660634	test: 0.585790

Epoch: 42
Loss: 0.15107869348841307
ROC train: 0.954251	val: 0.883873	test: 0.707789
PRC train: 0.825658	val: 0.667313	test: 0.563690

Epoch: 43
Loss: 0.14756481485409056
ROC train: 0.957650	val: 0.863583	test: 0.704785
PRC train: 0.821691	val: 0.681563	test: 0.562560

Epoch: 44
Loss: 0.14896352722504272
ROC train: 0.958573	val: 0.899269	test: 0.710844
PRC train: 0.828654	val: 0.621604	test: 0.555515

Epoch: 45
Loss: 0.15315527737828516
ROC train: 0.955207	val: 0.899856	test: 0.735041
PRC train: 0.827435	val: 0.628994	test: 0.564053

Epoch: 46
Loss: 0.14823788616948871
ROC train: 0.969042	val: 0.884822	test: 0.749975
PRC train: 0.854723	val: 0.663599	test: 0.571641

Epoch: 47
Loss: 0.14184717931356583
ROC train: 0.966094	val: 0.876181	test: 0.739624
PRC train: 0.847224	val: 0.654924	test: 0.577030

Epoch: 48
Loss: 0.14095712754249543
ROC train: 0.965511	val: 0.848198	test: 0.733028
PRC train: 0.848480	val: 0.578837	test: 0.584908

Epoch: 49
Loss: 0.15431726245596528
ROC train: 0.969408	val: 0.835987	test: 0.786170
PRC train: 0.859038	val: 0.583309	test: 0.639147

Epoch: 50
Loss: 0.14462405302290843
ROC train: 0.966147	val: 0.877829	test: 0.821509
PRC train: 0.853992	val: 0.615406	test: 0.632860

Epoch: 51
Loss: 0.14810478903320398
ROC train: 0.966945	val: 0.878504	test: 0.801436
PRC train: 0.856199	val: 0.611742	test: 0.622690

Epoch: 52
Loss: 0.14776302357123605
ROC train: 0.968058	val: 0.849597	test: 0.788855
PRC train: 0.863450	val: 0.605579	test: 0.652000

Epoch: 53
Loss: 0.13803802167657836
ROC train: 0.969590	val: 0.871985	test: 0.804645
PRC train: 0.863003	val: 0.670066	test: 0.662950

Epoch: 54
Loss: 0.14107063210520127
ROC train: 0.969367	val: 0.900094	test: 0.807267
PRC train: 0.862310	val: 0.686480	test: 0.640042

Epoch: 55
Loss: 0.13661913187751565
ROC train: 0.970341	val: 0.903391	test: 0.794339
PRC train: 0.862280	val: 0.638009	test: 0.638443

Epoch: 56
Loss: 0.14340082343149002
ROC train: 0.971645	val: 0.901068	test: 0.800685
PRC train: 0.865490	val: 0.604258	test: 0.646604

Epoch: 57
Loss: 0.13692088348953751
ROC train: 0.975103	val: 0.909259	test: 0.824445
PRC train: 0.877737	val: 0.666515	test: 0.668086

Epoch: 58
Loss: 0.138418186787635
ROC train: 0.975871	val: 0.887707	test: 0.800360
PRC train: 0.877986	val: 0.692880	test: 0.659864

Epoch: 59
Loss: 0.15602914294664397
ROC train: 0.971865	val: 0.880602	test: 0.779360
PRC train: 0.861143	val: 0.655481	test: 0.646865

Epoch: 60
Loss: 0.12814652606991522
ROC train: 0.974710	val: 0.873247	test: 0.789666
PRC train: 0.872654	val: 0.659552	test: 0.644132

Epoch: 61
Loss: 0.14119384897171722
ROC train: 0.976488	val: 0.875570	test: 0.799060
PRC train: 0.878585	val: 0.672936	test: 0.657974

Epoch: 62
Loss: 0.13882960005040806
ROC train: 0.977513	val: 0.873922	test: 0.810991
PRC train: 0.882465	val: 0.675578	test: 0.664096

Epoch: 63
Loss: 0.13276426335102437
ROC train: 0.978232	val: 0.888319	test: 0.835700
PRC train: 0.883061	val: 0.656328	test: 0.665444

Epoch: 64
Loss: 0.12865529373815754
ROC train: 0.977496	val: 0.872298	test: 0.834538
PRC train: 0.882063	val: 0.632897	test: 0.654573

Epoch: 65
Loss: 0.13030525800274734
ROC train: 0.975923	val: 0.852419	test: 0.802228
PRC train: 0.879784	val: 0.591495	test: 0.634705

Epoch: 66
Loss: 0.13745009712568695
ROC train: 0.973574	val: 0.849397	test: 0.794238
PRC train: 0.874807	val: 0.599647	test: 0.634340

Epoch: 67
Loss: 0.1250943721351408
ROC train: 0.978288	val: 0.839420	test: 0.808641
PRC train: 0.885654	val: 0.640546	test: 0.639002

Epoch: 68
Loss: 0.12162760057753885
ROC train: 0.980830	val: 0.858150	test: 0.817535
PRC train: 0.893515	val: 0.694566	test: 0.648776

Epoch: 69
Loss: 0.1261251755354132
ROC train: 0.980234	val: 0.862733	test: 0.812414
PRC train: 0.892833	val: 0.699213	test: 0.659088

Epoch: 70
Loss: 0.13301981669927987
ROC train: 0.977192	val: 0.859999	test: 0.807666
PRC train: 0.879018	val: 0.697429	test: 0.641033

Epoch: 71
Loss: 0.12991061810072413
ROC train: 0.978379	val: 0.837185	test: 0.825323
PRC train: 0.881143	val: 0.635507	test: 0.641263

Epoch: 72
Loss: 0.13041033145624167
ROC train: 0.979884	val: 0.849646	test: 0.813027
PRC train: 0.891205	val: 0.615539	test: 0.652457

Epoch: 73
Loss: 0.11954377067935489
ROC train: 0.979837	val: 0.838658	test: 0.783309
PRC train: 0.890367	val: 0.637479	test: 0.637423

Epoch: 74
Loss: 0.12460783059319591
ROC train: 0.980646	val: 0.879902	test: 0.829066
PRC train: 0.893997	val: 0.679067	test: 0.661229

Epoch: 75
Loss: 0.12341366995018406
ROC train: 0.978593	val: 0.878005	test: 0.828539
PRC train: 0.883318	val: 0.639720	test: 0.671850

Epoch: 76
Loss: 0.13576458409007874
ROC train: 0.980237	val: 0.872748	test: 0.837997
PRC train: 0.893280	val: 0.652979	test: 0.665586

Epoch: 77
Loss: 0.12527423839237226
ROC train: 0.981471	val: 0.883761	test: 0.844530
PRC train: 0.898863	val: 0.667868	test: 0.658505

Epoch: 78
Loss: 0.12196984787570131
ROC train: 0.981974	val: 0.880489	test: 0.806792
PRC train: 0.896792	val: 0.654555	test: 0.637934

Epoch: 79
Loss: 0.11400975509421778
ROC train: 0.982914	val: 0.877105	test: 0.780522
PRC train: 0.902981	val: 0.646357	test: 0.631014

Epoch: 80
Loss: 0.10683319815660959
ROC train: 0.981463	val: 0.875369	test: 0.798605
PRC train: 0.897454	val: 0.640542	test: 0.644623

Epoch: 81
Loss: 0.11490796938058268
ROC train: 0.983130	val: 0.868464	test: 0.822458
PRC train: 0.904025	val: 0.613501	test: 0.648202

Epoch: 82
Loss: 0.11647063312540469
ROC train: 0.982307	val: 0.836648	test: 0.827867
PRC train: 0.900753	val: 0.583552	test: 0.655818

Epoch: 83
Loss: 0.1196144805188841
ROC train: 0.982533	val: 0.872235	test: 0.814375
PRC train: 0.905665	val: 0.658494	test: 0.661361

Epoch: 84
Loss: 0.11537566833061474
ROC train: 0.981021	val: 0.889542	test: 0.828252
PRC train: 0.897330	val: 0.650505	test: 0.655966

Epoch: 85
Loss: 0.11358470280524213
ROC train: 0.976756	val: 0.816768	test: 0.801556
PRC train: 0.891180	val: 0.629610	test: 0.639364

Epoch: 86
Loss: 0.12035325271919577
ROC train: 0.979632	val: 0.851133	test: 0.813374
PRC train: 0.894292	val: 0.620145	test: 0.648838

Epoch: 87
Loss: 0.11487118822816678
ROC train: 0.982007	val: 0.856527	test: 0.817897
PRC train: 0.900484	val: 0.625099	test: 0.645727

Epoch: 88
Loss: 0.11746533297555779
ROC train: 0.982598	val: 0.819116	test: 0.790327
PRC train: 0.907081	val: 0.631399	test: 0.626726

Epoch: 89
Loss: 0.11465884364642127
ROC train: 0.984611	val: 0.837934	test: 0.806580
PRC train: 0.912785	val: 0.606938	test: 0.638133

Epoch: 90
Loss: 0.1104434840784754
ROC train: 0.982728	val: 0.830104	test: 0.843406
PRC train: 0.902011	val: 0.597642	test: 0.665697

Epoch: 91
Loss: 0.11743004686626354
ROC train: 0.983371	val: 0.809227	test: 0.817983
PRC train: 0.908083	val: 0.581739	test: 0.655889

Epoch: 92
Loss: 0.11770850786519822
ROC train: 0.980229	val: 0.839919	test: 0.836910
PRC train: 0.896046	val: 0.590669	test: 0.672380

Epoch: 93
Loss: 0.11918623440914775
ROC train: 0.981466	val: 0.851045	test: 0.835711
PRC train: 0.903011	val: 0.592844	test: 0.654575

ROC train: 0.983013	val: 0.642872	test: 0.815449
PRC train: 0.911599	val: 0.566939	test: 0.652479

Epoch: 95
Loss: 0.12176946654564572
ROC train: 0.983140	val: 0.656590	test: 0.806068
PRC train: 0.908557	val: 0.567985	test: 0.642202

Epoch: 96
Loss: 0.10118089929713062
ROC train: 0.983253	val: 0.635816	test: 0.775062
PRC train: 0.911364	val: 0.559366	test: 0.615479

Epoch: 97
Loss: 0.12104252865673229
ROC train: 0.983674	val: 0.634071	test: 0.777007
PRC train: 0.913568	val: 0.561515	test: 0.610921

Epoch: 98
Loss: 0.10466193936423715
ROC train: 0.983858	val: 0.648249	test: 0.793054
PRC train: 0.917142	val: 0.562037	test: 0.621611

Epoch: 99
Loss: 0.11153065564427171
ROC train: 0.983569	val: 0.657683	test: 0.805641
PRC train: 0.914206	val: 0.564558	test: 0.629993

Epoch: 100
Loss: 0.11221090837243453
ROC train: 0.982916	val: 0.647827	test: 0.805183
PRC train: 0.911041	val: 0.564371	test: 0.635388

Epoch: 101
Loss: 0.10267635140719165
ROC train: 0.983418	val: 0.646096	test: 0.799784
PRC train: 0.909381	val: 0.566530	test: 0.639031

Epoch: 102
Loss: 0.11307126706392442
ROC train: 0.983710	val: 0.640257	test: 0.787971
PRC train: 0.912516	val: 0.561796	test: 0.645015

Epoch: 103
Loss: 0.10624488259384443
ROC train: 0.983774	val: 0.631180	test: 0.779029
PRC train: 0.914706	val: 0.557576	test: 0.652920

Epoch: 104
Loss: 0.11601304713899388
ROC train: 0.983615	val: 0.644111	test: 0.769900
PRC train: 0.915887	val: 0.562924	test: 0.656048

Epoch: 105
Loss: 0.11128871881162794
ROC train: 0.982256	val: 0.677552	test: 0.793994
PRC train: 0.906418	val: 0.569209	test: 0.661685

Epoch: 106
Loss: 0.10262651732791563
ROC train: 0.982285	val: 0.670784	test: 0.822732
PRC train: 0.906812	val: 0.566694	test: 0.654345

Epoch: 107
Loss: 0.11418824450227358
ROC train: 0.983680	val: 0.675174	test: 0.829723
PRC train: 0.912290	val: 0.566736	test: 0.660223

Epoch: 108
Loss: 0.10005669576141198
ROC train: 0.983692	val: 0.659286	test: 0.807512
PRC train: 0.915061	val: 0.561359	test: 0.648339

Epoch: 109
Loss: 0.12683056624153677
ROC train: 0.983205	val: 0.658046	test: 0.804490
PRC train: 0.916151	val: 0.565206	test: 0.627858

Epoch: 110
Loss: 0.10962590447709018
ROC train: 0.983728	val: 0.656636	test: 0.837791
PRC train: 0.915212	val: 0.568726	test: 0.654695

Epoch: 111
Loss: 0.09862109433837883
ROC train: 0.983699	val: 0.645416	test: 0.836812
PRC train: 0.913541	val: 0.567943	test: 0.653101

Epoch: 112
Loss: 0.11330487798617708
ROC train: 0.984944	val: 0.635984	test: 0.820040
PRC train: 0.918556	val: 0.572389	test: 0.636029

Epoch: 113
Loss: 0.11222103442511949
ROC train: 0.984476	val: 0.621917	test: 0.803300
PRC train: 0.921327	val: 0.560658	test: 0.635372

Epoch: 114
Loss: 0.11257745780501878
ROC train: 0.985603	val: 0.661784	test: 0.833728
PRC train: 0.922128	val: 0.567861	test: 0.650982

Epoch: 115
Loss: 0.10783996784959696
ROC train: 0.985506	val: 0.668094	test: 0.836543
PRC train: 0.921454	val: 0.568433	test: 0.654922

Epoch: 116
Loss: 0.09871655150525975
ROC train: 0.984930	val: 0.666073	test: 0.825893
PRC train: 0.920764	val: 0.566660	test: 0.641941

Epoch: 117
Loss: 0.10557250901091665
ROC train: 0.983991	val: 0.657371	test: 0.812122
PRC train: 0.920544	val: 0.571984	test: 0.626880

Epoch: 118
Loss: 0.09495345853634835
ROC train: 0.985475	val: 0.656253	test: 0.814897
PRC train: 0.922099	val: 0.565131	test: 0.648545

Epoch: 119
Loss: 0.10958099891452822
ROC train: 0.984868	val: 0.670056	test: 0.816631
PRC train: 0.918741	val: 0.579235	test: 0.648406

Epoch: 120
Loss: 0.1009675530387597
ROC train: 0.985510	val: 0.673082	test: 0.820272
PRC train: 0.920159	val: 0.572421	test: 0.654461

Early stopping
Best (ROC):	 train: 0.974770	val: 0.696199	test: 0.793482
Best (PRC):	 train: 0.878478	val: 0.577484	test: 0.613834

ROC train: 0.984075	val: 0.666842	test: 0.732852
PRC train: 0.910421	val: 0.570967	test: 0.633089

Epoch: 95
Loss: 0.09891150651151767
ROC train: 0.983943	val: 0.664350	test: 0.714338
PRC train: 0.910257	val: 0.569294	test: 0.629867

Epoch: 96
Loss: 0.12224267248205481
ROC train: 0.983442	val: 0.676988	test: 0.717203
PRC train: 0.907499	val: 0.574443	test: 0.626011

Epoch: 97
Loss: 0.11532157732187001
ROC train: 0.982074	val: 0.685498	test: 0.710896
PRC train: 0.904298	val: 0.578256	test: 0.624955

Epoch: 98
Loss: 0.109860253171598
ROC train: 0.984261	val: 0.693687	test: 0.741771
PRC train: 0.916270	val: 0.576406	test: 0.657778

Epoch: 99
Loss: 0.09941952901566517
ROC train: 0.983814	val: 0.682556	test: 0.771382
PRC train: 0.916528	val: 0.566850	test: 0.667526

Epoch: 100
Loss: 0.10498955329648696
ROC train: 0.983425	val: 0.687283	test: 0.779920
PRC train: 0.909061	val: 0.561773	test: 0.654543

Epoch: 101
Loss: 0.10131244050315874
ROC train: 0.982969	val: 0.687965	test: 0.779035
PRC train: 0.908291	val: 0.561230	test: 0.656466

Epoch: 102
Loss: 0.11230786301218512
ROC train: 0.984581	val: 0.683808	test: 0.760721
PRC train: 0.917066	val: 0.563715	test: 0.656281

Epoch: 103
Loss: 0.1061522563180963
ROC train: 0.983708	val: 0.672850	test: 0.757943
PRC train: 0.913305	val: 0.570580	test: 0.664491

Epoch: 104
Loss: 0.09905628264066597
ROC train: 0.984395	val: 0.675081	test: 0.755215
PRC train: 0.915676	val: 0.578243	test: 0.651917

Epoch: 105
Loss: 0.11032593179724112
ROC train: 0.981871	val: 0.678186	test: 0.762753
PRC train: 0.906065	val: 0.575630	test: 0.645599

Epoch: 106
Loss: 0.1132076203862003
ROC train: 0.983846	val: 0.660924	test: 0.768156
PRC train: 0.913393	val: 0.573725	test: 0.646773

Epoch: 107
Loss: 0.10282648895826253
ROC train: 0.985070	val: 0.663891	test: 0.750955
PRC train: 0.920175	val: 0.579383	test: 0.646171

Epoch: 108
Loss: 0.1075682255784562
ROC train: 0.984820	val: 0.667864	test: 0.731321
PRC train: 0.919632	val: 0.577167	test: 0.645329

Epoch: 109
Loss: 0.10826707823813264
ROC train: 0.983319	val: 0.664098	test: 0.711285
PRC train: 0.915627	val: 0.573125	test: 0.630740

Epoch: 110
Loss: 0.11786277554813526
ROC train: 0.983357	val: 0.655158	test: 0.726876
PRC train: 0.914424	val: 0.569701	test: 0.636483

Epoch: 111
Loss: 0.09951040728379948
ROC train: 0.984815	val: 0.669555	test: 0.763483
PRC train: 0.916953	val: 0.573898	test: 0.662779

Epoch: 112
Loss: 0.10953424804713599
ROC train: 0.985104	val: 0.677251	test: 0.777756
PRC train: 0.918493	val: 0.574084	test: 0.667466

Epoch: 113
Loss: 0.10070716069272377
ROC train: 0.984067	val: 0.683087	test: 0.746517
PRC train: 0.916613	val: 0.586179	test: 0.638347

Epoch: 114
Loss: 0.10090382563340523
ROC train: 0.983007	val: 0.675253	test: 0.737086
PRC train: 0.911278	val: 0.581808	test: 0.629046

Epoch: 115
Loss: 0.10333223261098952
ROC train: 0.983771	val: 0.662692	test: 0.737916
PRC train: 0.913868	val: 0.569292	test: 0.630082

Epoch: 116
Loss: 0.1028389764506953
ROC train: 0.985265	val: 0.676559	test: 0.763777
PRC train: 0.919493	val: 0.575203	test: 0.662973

Epoch: 117
Loss: 0.09969402080984197
ROC train: 0.985980	val: 0.681278	test: 0.774646
PRC train: 0.921264	val: 0.576653	test: 0.666542

Epoch: 118
Loss: 0.11212671178128614
ROC train: 0.985744	val: 0.685128	test: 0.762907
PRC train: 0.920679	val: 0.580690	test: 0.632578

Epoch: 119
Loss: 0.11057505933666455
ROC train: 0.986144	val: 0.671597	test: 0.750265
PRC train: 0.924045	val: 0.574623	test: 0.622604

Epoch: 120
Loss: 0.10116116441068293
ROC train: 0.985345	val: 0.666249	test: 0.777974
PRC train: 0.922775	val: 0.570641	test: 0.646505

Early stopping
Best (ROC):	 train: 0.977808	val: 0.694756	test: 0.763637
Best (PRC):	 train: 0.888326	val: 0.585731	test: 0.598742

ROC train: 0.983206	val: 0.627569	test: 0.778270
PRC train: 0.910574	val: 0.564089	test: 0.628517

Epoch: 95
Loss: 0.1189539951192921
ROC train: 0.982010	val: 0.646899	test: 0.760094
PRC train: 0.902064	val: 0.554336	test: 0.627803

Epoch: 96
Loss: 0.12763700496915548
ROC train: 0.981153	val: 0.648958	test: 0.752619
PRC train: 0.899726	val: 0.553704	test: 0.631094

Epoch: 97
Loss: 0.11043112564121194
ROC train: 0.983409	val: 0.624341	test: 0.746332
PRC train: 0.914366	val: 0.550578	test: 0.625295

Epoch: 98
Loss: 0.11304464073540811
ROC train: 0.984295	val: 0.637313	test: 0.744746
PRC train: 0.917526	val: 0.558747	test: 0.626034

Epoch: 99
Loss: 0.10710615013203159
ROC train: 0.983806	val: 0.649049	test: 0.756882
PRC train: 0.915909	val: 0.563559	test: 0.635910

Epoch: 100
Loss: 0.11598727441178601
ROC train: 0.984074	val: 0.655245	test: 0.779353
PRC train: 0.913972	val: 0.563278	test: 0.645118

Epoch: 101
Loss: 0.10815932606015967
ROC train: 0.983641	val: 0.642207	test: 0.769400
PRC train: 0.916334	val: 0.559681	test: 0.642695

Epoch: 102
Loss: 0.10785326023124105
ROC train: 0.982855	val: 0.638963	test: 0.766200
PRC train: 0.913469	val: 0.558990	test: 0.644237

Epoch: 103
Loss: 0.09432276012914807
ROC train: 0.982908	val: 0.650143	test: 0.764249
PRC train: 0.910600	val: 0.562202	test: 0.656688

Epoch: 104
Loss: 0.0992058038634207
ROC train: 0.984553	val: 0.658488	test: 0.762214
PRC train: 0.914587	val: 0.562262	test: 0.661254

Epoch: 105
Loss: 0.12208331140538975
ROC train: 0.985751	val: 0.652632	test: 0.751192
PRC train: 0.922295	val: 0.561342	test: 0.635692

Epoch: 106
Loss: 0.1011089080407179
ROC train: 0.985839	val: 0.646381	test: 0.754272
PRC train: 0.922606	val: 0.555332	test: 0.628889

Epoch: 107
Loss: 0.09582611727539903
ROC train: 0.985285	val: 0.649058	test: 0.767345
PRC train: 0.920240	val: 0.556622	test: 0.632027

Epoch: 108
Loss: 0.10629354772974874
ROC train: 0.984555	val: 0.649936	test: 0.777579
PRC train: 0.918029	val: 0.558654	test: 0.637908

Epoch: 109
Loss: 0.0980853145803852
ROC train: 0.984383	val: 0.655247	test: 0.784410
PRC train: 0.917587	val: 0.557365	test: 0.633925

Epoch: 110
Loss: 0.10791031651160539
ROC train: 0.984207	val: 0.672374	test: 0.775769
PRC train: 0.917789	val: 0.566024	test: 0.627248

Epoch: 111
Loss: 0.11076804266734588
ROC train: 0.985286	val: 0.673974	test: 0.757137
PRC train: 0.921218	val: 0.571380	test: 0.639419

Epoch: 112
Loss: 0.10909515143209601
ROC train: 0.983117	val: 0.680515	test: 0.750634
PRC train: 0.915889	val: 0.574925	test: 0.652641

Epoch: 113
Loss: 0.10376628144902274
ROC train: 0.979761	val: 0.680949	test: 0.732446
PRC train: 0.900705	val: 0.574033	test: 0.647162

Epoch: 114
Loss: 0.10068592385372915
ROC train: 0.981089	val: 0.667065	test: 0.728944
PRC train: 0.900294	val: 0.565348	test: 0.654538

Epoch: 115
Loss: 0.09504115919385449
ROC train: 0.982435	val: 0.659981	test: 0.731385
PRC train: 0.903487	val: 0.558553	test: 0.655202

Epoch: 116
Loss: 0.11122399969329293
ROC train: 0.984744	val: 0.644419	test: 0.738785
PRC train: 0.918680	val: 0.559578	test: 0.638149

Epoch: 117
Loss: 0.10889718342956275
ROC train: 0.985138	val: 0.639592	test: 0.754595
PRC train: 0.919237	val: 0.558031	test: 0.642971

Epoch: 118
Loss: 0.09875441287901884
ROC train: 0.985318	val: 0.621260	test: 0.740155
PRC train: 0.919408	val: 0.554014	test: 0.627026

Epoch: 119
Loss: 0.11389873211425994
ROC train: 0.984999	val: 0.608199	test: 0.739172
PRC train: 0.917784	val: 0.549386	test: 0.613168

Epoch: 120
Loss: 0.09623847785030284
ROC train: 0.985411	val: 0.619397	test: 0.750324
PRC train: 0.917686	val: 0.555359	test: 0.621445

Epoch: 121
Loss: 0.0894666013960191
ROC train: 0.985642	val: 0.629635	test: 0.766582
PRC train: 0.916922	val: 0.559054	test: 0.634489

Early stopping
Best (ROC):	 train: 0.962852	val: 0.685996	test: 0.685123
Best (PRC):	 train: 0.850907	val: 0.573611	test: 0.560513
All runs completed.

ROC train: 0.920844	val: 0.761435	test: 0.722769
PRC train: 0.772320	val: 0.618096	test: 0.566528

Epoch: 95
Loss: 0.1483884424117644
ROC train: 0.925403	val: 0.756778	test: 0.720173
PRC train: 0.786986	val: 0.610526	test: 0.559800

Epoch: 96
Loss: 0.1429394800793777
ROC train: 0.941278	val: 0.739133	test: 0.719087
PRC train: 0.809629	val: 0.605297	test: 0.558774

Epoch: 97
Loss: 0.14449605880298297
ROC train: 0.952188	val: 0.729004	test: 0.721995
PRC train: 0.824376	val: 0.608190	test: 0.566264

Epoch: 98
Loss: 0.14709251725273545
ROC train: 0.952598	val: 0.723183	test: 0.715385
PRC train: 0.827664	val: 0.609792	test: 0.560993

Epoch: 99
Loss: 0.13759443179055092
ROC train: 0.948968	val: 0.729498	test: 0.705717
PRC train: 0.816945	val: 0.621863	test: 0.555960

Epoch: 100
Loss: 0.224120873383505
ROC train: 0.952635	val: 0.726536	test: 0.703378
PRC train: 0.829866	val: 0.640368	test: 0.552192

Epoch: 101
Loss: 0.23129599992790353
ROC train: 0.950007	val: 0.711255	test: 0.685561
PRC train: 0.809085	val: 0.610804	test: 0.541040

Epoch: 102
Loss: 0.1828889437891003
ROC train: 0.943687	val: 0.696917	test: 0.682227
PRC train: 0.797684	val: 0.585333	test: 0.537473

Epoch: 103
Loss: 0.2969809646502195
ROC train: 0.937771	val: 0.684698	test: 0.705116
PRC train: 0.782756	val: 0.565304	test: 0.552913

Epoch: 104
Loss: 0.15394429185148478
ROC train: 0.913392	val: 0.682435	test: 0.707783
PRC train: 0.760697	val: 0.574277	test: 0.563754

Epoch: 105
Loss: 0.15592696990007823
ROC train: 0.917159	val: 0.669331	test: 0.708398
PRC train: 0.767205	val: 0.550140	test: 0.557275

Epoch: 106
Loss: 0.23715975768408418
ROC train: 0.930714	val: 0.683242	test: 0.707466
PRC train: 0.776352	val: 0.550536	test: 0.550398

Epoch: 107
Loss: 0.14556017721998302
ROC train: 0.933917	val: 0.693091	test: 0.682488
PRC train: 0.789614	val: 0.571839	test: 0.544868

Epoch: 108
Loss: 0.16293209167993034
ROC train: 0.944291	val: 0.705264	test: 0.694903
PRC train: 0.806790	val: 0.593778	test: 0.556247

Epoch: 109
Loss: 0.17549707847134832
ROC train: 0.942661	val: 0.711308	test: 0.697114
PRC train: 0.794373	val: 0.614621	test: 0.567525

Epoch: 110
Loss: 0.13590093648309207
ROC train: 0.949348	val: 0.728025	test: 0.673061
PRC train: 0.817353	val: 0.613543	test: 0.571487

Epoch: 111
Loss: 0.1778982218266016
ROC train: 0.953676	val: 0.739231	test: 0.668588
PRC train: 0.825463	val: 0.627264	test: 0.578266

Epoch: 112
Loss: 0.14688732638459465
ROC train: 0.945760	val: 0.711257	test: 0.654648
PRC train: 0.808433	val: 0.609712	test: 0.574219

Epoch: 113
Loss: 0.12939925785901457
ROC train: 0.944288	val: 0.699469	test: 0.658843
PRC train: 0.801004	val: 0.600036	test: 0.563814

Epoch: 114
Loss: 0.14602114027815796
ROC train: 0.945267	val: 0.667313	test: 0.674087
PRC train: 0.808711	val: 0.581859	test: 0.557685

Epoch: 115
Loss: 0.17434575899867455
ROC train: 0.941830	val: 0.672823	test: 0.681043
PRC train: 0.808197	val: 0.562295	test: 0.577065

Epoch: 116
Loss: 0.13064446314825884
ROC train: 0.940981	val: 0.686752	test: 0.668741
PRC train: 0.790636	val: 0.564279	test: 0.576202

Epoch: 117
Loss: 0.1312127425610385
ROC train: 0.942218	val: 0.683731	test: 0.683191
PRC train: 0.792752	val: 0.584302	test: 0.595315

Epoch: 118
Loss: 0.2308921358469905
ROC train: 0.952269	val: 0.688114	test: 0.708305
PRC train: 0.815092	val: 0.565215	test: 0.592384

Epoch: 119
Loss: 0.13762141944556283
ROC train: 0.939630	val: 0.685080	test: 0.702962
PRC train: 0.791510	val: 0.559564	test: 0.579902

Epoch: 120
Loss: 0.13621952731958722
ROC train: 0.946517	val: 0.704706	test: 0.702318
PRC train: 0.815764	val: 0.568977	test: 0.557876

Epoch: 121
Loss: 0.160780199223336
ROC train: 0.954186	val: 0.721089	test: 0.683423
PRC train: 0.819404	val: 0.584922	test: 0.572062

Epoch: 122
Loss: 0.1297361351086826
ROC train: 0.960039	val: 0.723577	test: 0.655923
PRC train: 0.819069	val: 0.591961	test: 0.565532

Epoch: 123
Loss: 0.152540621862938
ROC train: 0.960715	val: 0.725000	test: 0.651223
PRC train: 0.815994	val: 0.595695	test: 0.563803

Epoch: 124
Loss: 0.12324473103159791
ROC train: 0.954901	val: 0.719713	test: 0.622141
PRC train: 0.802720	val: 0.596262	test: 0.558576

Early stopping
Best (ROC):	 train: 0.926209	val: 0.762856	test: 0.679262
Best (PRC):	 train: 0.759887	val: 0.619713	test: 0.590667

ROC train: 0.944004	val: 0.750770	test: 0.708707
PRC train: 0.805053	val: 0.655504	test: 0.585007

Epoch: 95
Loss: 0.15179844626891068
ROC train: 0.950242	val: 0.742499	test: 0.708475
PRC train: 0.818492	val: 0.652794	test: 0.582807

Epoch: 96
Loss: 0.1366246756024098
ROC train: 0.956504	val: 0.722080	test: 0.732613
PRC train: 0.829511	val: 0.642653	test: 0.585317

Epoch: 97
Loss: 0.13495700494176882
ROC train: 0.955905	val: 0.720174	test: 0.729019
PRC train: 0.832822	val: 0.626124	test: 0.585308

Epoch: 98
Loss: 0.12677366697163428
ROC train: 0.956821	val: 0.722899	test: 0.727772
PRC train: 0.832465	val: 0.607122	test: 0.584958

Epoch: 99
Loss: 0.12692623454657906
ROC train: 0.957049	val: 0.735517	test: 0.730283
PRC train: 0.837119	val: 0.615425	test: 0.588759

Epoch: 100
Loss: 0.1333591599832245
ROC train: 0.960875	val: 0.731765	test: 0.737783
PRC train: 0.845049	val: 0.609838	test: 0.587508

Epoch: 101
Loss: 0.14036262924026896
ROC train: 0.962327	val: 0.716024	test: 0.745142
PRC train: 0.843657	val: 0.621434	test: 0.587308

Epoch: 102
Loss: 0.11936746828448208
ROC train: 0.957835	val: 0.699108	test: 0.724297
PRC train: 0.833158	val: 0.625508	test: 0.581720

Epoch: 103
Loss: 0.14152025489497172
ROC train: 0.961021	val: 0.697937	test: 0.713486
PRC train: 0.836624	val: 0.624011	test: 0.580860

Epoch: 104
Loss: 0.17467538360697263
ROC train: 0.957758	val: 0.688705	test: 0.691958
PRC train: 0.830180	val: 0.621532	test: 0.573969

Epoch: 105
Loss: 0.14119886066347015
ROC train: 0.946753	val: 0.696880	test: 0.668616
PRC train: 0.805515	val: 0.633834	test: 0.572636

Epoch: 106
Loss: 0.1533345605593774
ROC train: 0.943447	val: 0.703482	test: 0.671683
PRC train: 0.811023	val: 0.618563	test: 0.574802

Epoch: 107
Loss: 0.15001166858499598
ROC train: 0.944611	val: 0.718799	test: 0.676037
PRC train: 0.812233	val: 0.645732	test: 0.578961

Epoch: 108
Loss: 0.1317920786569053
ROC train: 0.948125	val: 0.706577	test: 0.693095
PRC train: 0.827493	val: 0.638477	test: 0.580906

Epoch: 109
Loss: 0.15771555322950473
ROC train: 0.948325	val: 0.686021	test: 0.696921
PRC train: 0.828318	val: 0.612826	test: 0.580060

Epoch: 110
Loss: 0.14302507327238645
ROC train: 0.949570	val: 0.699493	test: 0.687361
PRC train: 0.829799	val: 0.619381	test: 0.578179

Epoch: 111
Loss: 0.16242969928570794
ROC train: 0.954356	val: 0.724927	test: 0.689852
PRC train: 0.834837	val: 0.642993	test: 0.581193

Epoch: 112
Loss: 0.14072376296415687
ROC train: 0.947341	val: 0.715761	test: 0.695586
PRC train: 0.814683	val: 0.643193	test: 0.582022

Epoch: 113
Loss: 0.21192659043988
ROC train: 0.947553	val: 0.735710	test: 0.691207
PRC train: 0.818322	val: 0.671108	test: 0.585928

Epoch: 114
Loss: 0.12858986475400458
ROC train: 0.939094	val: 0.746582	test: 0.710524
PRC train: 0.791875	val: 0.645004	test: 0.607295

Epoch: 115
Loss: 0.15682605842716918
ROC train: 0.946340	val: 0.728021	test: 0.721825
PRC train: 0.799087	val: 0.648350	test: 0.607091

Epoch: 116
Loss: 0.14629208385702824
ROC train: 0.947067	val: 0.706684	test: 0.737290
PRC train: 0.802243	val: 0.646899	test: 0.602626

Epoch: 117
Loss: 0.12839440614319614
ROC train: 0.956507	val: 0.708133	test: 0.739824
PRC train: 0.826552	val: 0.643751	test: 0.602868

Epoch: 118
Loss: 0.2062174218908237
ROC train: 0.961184	val: 0.705186	test: 0.723960
PRC train: 0.839129	val: 0.643660	test: 0.593287

Epoch: 119
Loss: 0.16916557763208773
ROC train: 0.958952	val: 0.697162	test: 0.740233
PRC train: 0.844350	val: 0.616064	test: 0.588927

Epoch: 120
Loss: 0.1447092053828008
ROC train: 0.951947	val: 0.723029	test: 0.753929
PRC train: 0.835621	val: 0.626804	test: 0.600684

Epoch: 121
Loss: 0.32542764522005213
ROC train: 0.948700	val: 0.737171	test: 0.741298
PRC train: 0.818840	val: 0.620326	test: 0.601760

Epoch: 122
Loss: 0.18655938224077823
ROC train: 0.945107	val: 0.718750	test: 0.769864
PRC train: 0.812412	val: 0.598204	test: 0.602998

Epoch: 123
Loss: 0.17246752790497977
ROC train: 0.921909	val: 0.678633	test: 0.714388
PRC train: 0.767647	val: 0.579703	test: 0.579146

Epoch: 124
Loss: 0.2627718331205616
ROC train: 0.921690	val: 0.699968	test: 0.716763
PRC train: 0.764508	val: 0.604145	test: 0.577867

Epoch: 125
Loss: 0.15993068943414118
ROC train: 0.929597	val: 0.738502	test: 0.690164
PRC train: 0.768106	val: 0.602639	test: 0.582981

Epoch: 126
Loss: 0.27414314424175207
ROC train: 0.936840	val: 0.731826	test: 0.691292
PRC train: 0.766940	val: 0.597911	test: 0.581556

Epoch: 127
Loss: 0.16597852350296355
ROC train: 0.902261	val: 0.673179	test: 0.706970
PRC train: 0.734348	val: 0.583303	test: 0.575305

Epoch: 128
Loss: 0.18442287419219655
ROC train: 0.906525	val: 0.679853	test: 0.712783
PRC train: 0.758265	val: 0.588386	test: 0.583056

Early stopping
Best (ROC):	 train: 0.945167	val: 0.751462	test: 0.710436
Best (PRC):	 train: 0.806469	val: 0.655150	test: 0.581495

Epoch: 94
Loss: 0.1089349226971407
ROC train: 0.980933	val: 0.817693	test: 0.786244
PRC train: 0.904459	val: 0.596655	test: 0.623088

Epoch: 95
Loss: 0.11375589963160941
ROC train: 0.985201	val: 0.838159	test: 0.815974
PRC train: 0.915859	val: 0.641606	test: 0.638113

Epoch: 96
Loss: 0.11716934192788275
ROC train: 0.984669	val: 0.855016	test: 0.823243
PRC train: 0.912480	val: 0.635441	test: 0.659760

Epoch: 97
Loss: 0.10691659213259348
ROC train: 0.984555	val: 0.838159	test: 0.826959
PRC train: 0.915088	val: 0.623486	test: 0.652134

Epoch: 98
Loss: 0.11522614780135895
ROC train: 0.984375	val: 0.809863	test: 0.802945
PRC train: 0.919451	val: 0.602004	test: 0.637473

Epoch: 99
Loss: 0.109721562763563
ROC train: 0.981592	val: 0.802308	test: 0.740823
PRC train: 0.900609	val: 0.580411	test: 0.608070

Epoch: 100
Loss: 0.1210062552569624
ROC train: 0.979209	val: 0.794317	test: 0.759186
PRC train: 0.893423	val: 0.567308	test: 0.607792

Epoch: 101
Loss: 0.12167209033501405
ROC train: 0.980995	val: 0.808078	test: 0.789640
PRC train: 0.900860	val: 0.605277	test: 0.644423

Epoch: 102
Loss: 0.1167504549058173
ROC train: 0.983196	val: 0.832266	test: 0.813374
PRC train: 0.907832	val: 0.636292	test: 0.673868

Epoch: 103
Loss: 0.11675160420576233
ROC train: 0.983727	val: 0.834725	test: 0.838968
PRC train: 0.902716	val: 0.661658	test: 0.688774

Epoch: 104
Loss: 0.1076363448898584
ROC train: 0.985468	val: 0.811937	test: 0.847832
PRC train: 0.918352	val: 0.610180	test: 0.666758

Epoch: 105
Loss: 0.10786025793882807
ROC train: 0.983345	val: 0.804132	test: 0.829365
PRC train: 0.913726	val: 0.580892	test: 0.647087

Epoch: 106
Loss: 0.12037289852231114
ROC train: 0.984460	val: 0.823923	test: 0.843256
PRC train: 0.910940	val: 0.607905	test: 0.654059

Epoch: 107
Loss: 0.10480371450942175
ROC train: 0.985797	val: 0.835000	test: 0.815163
PRC train: 0.921344	val: 0.594793	test: 0.641857

Epoch: 108
Loss: 0.10064304793038929
ROC train: 0.984901	val: 0.814983	test: 0.819511
PRC train: 0.915492	val: 0.585759	test: 0.644833

Epoch: 109
Loss: 0.11029498492977667
ROC train: 0.985995	val: 0.802434	test: 0.835498
PRC train: 0.925184	val: 0.579849	test: 0.648213

Epoch: 110
Loss: 0.10771459313176979
ROC train: 0.985887	val: 0.810475	test: 0.834452
PRC train: 0.918193	val: 0.609425	test: 0.662639

Epoch: 111
Loss: 0.10643100158690222
ROC train: 0.983680	val: 0.844477	test: 0.828775
PRC train: 0.908250	val: 0.597674	test: 0.662690

Epoch: 112
Loss: 0.0957339049727735
ROC train: 0.981395	val: 0.877105	test: 0.835745
PRC train: 0.897167	val: 0.639646	test: 0.674192

Epoch: 113
Loss: 0.10158815292743444
ROC train: 0.984280	val: 0.860586	test: 0.831367
PRC train: 0.913137	val: 0.630751	test: 0.683067

Epoch: 114
Loss: 0.11011703116721497
ROC train: 0.985205	val: 0.837660	test: 0.824117
PRC train: 0.916981	val: 0.617096	test: 0.669932

Epoch: 115
Loss: 0.10046596016987057
ROC train: 0.986268	val: 0.803545	test: 0.829115
PRC train: 0.920096	val: 0.580975	test: 0.658484

Epoch: 116
Loss: 0.10829011312530604
ROC train: 0.985260	val: 0.804469	test: 0.826279
PRC train: 0.918159	val: 0.578564	test: 0.653434

Epoch: 117
Loss: 0.10420443366957025
ROC train: 0.985919	val: 0.816406	test: 0.813800
PRC train: 0.918679	val: 0.568357	test: 0.643541

Epoch: 118
Loss: 0.11616199144599057
ROC train: 0.985534	val: 0.772203	test: 0.810139
PRC train: 0.915030	val: 0.554229	test: 0.654425

Epoch: 119
Loss: 0.10512368504567929
ROC train: 0.984964	val: 0.757468	test: 0.811745
PRC train: 0.918377	val: 0.552525	test: 0.653639

Epoch: 120
Loss: 0.12045650113824875
ROC train: 0.984963	val: 0.834325	test: 0.833649
PRC train: 0.916489	val: 0.613525	test: 0.671503

Early stopping
Best (ROC):	 train: 0.975103	val: 0.909259	test: 0.824445
Best (PRC):	 train: 0.877737	val: 0.666515	test: 0.668086

ROC train: 0.982696	val: 0.843240	test: 0.827673
PRC train: 0.907498	val: 0.620856	test: 0.642447

Epoch: 95
Loss: 0.10906662322084407
ROC train: 0.982394	val: 0.878803	test: 0.831789
PRC train: 0.906961	val: 0.630793	test: 0.657580

Epoch: 96
Loss: 0.11338246864992518
ROC train: 0.984333	val: 0.883223	test: 0.818947
PRC train: 0.914425	val: 0.647965	test: 0.653751

Epoch: 97
Loss: 0.11223090351854607
ROC train: 0.984015	val: 0.882724	test: 0.805649
PRC train: 0.911465	val: 0.654581	test: 0.647881

Epoch: 98
Loss: 0.11144783766916573
ROC train: 0.985672	val: 0.894275	test: 0.799535
PRC train: 0.918650	val: 0.681007	test: 0.634628

Epoch: 99
Loss: 0.12229142417529792
ROC train: 0.983924	val: 0.896373	test: 0.780754
PRC train: 0.908002	val: 0.653755	test: 0.621021

Epoch: 100
Loss: 0.11090071249240936
ROC train: 0.983207	val: 0.875120	test: 0.801358
PRC train: 0.907426	val: 0.638825	test: 0.637841

Epoch: 101
Loss: 0.10384308522662747
ROC train: 0.985645	val: 0.878054	test: 0.824460
PRC train: 0.919317	val: 0.659054	test: 0.659658

Epoch: 102
Loss: 0.12523659481231098
ROC train: 0.986061	val: 0.862395	test: 0.802269
PRC train: 0.920649	val: 0.659385	test: 0.641765

Epoch: 103
Loss: 0.10850699397636225
ROC train: 0.984063	val: 0.852219	test: 0.776473
PRC train: 0.911454	val: 0.624008	test: 0.630913

Epoch: 104
Loss: 0.10819097695153398
ROC train: 0.983783	val: 0.868826	test: 0.782233
PRC train: 0.908810	val: 0.694105	test: 0.641436

Epoch: 105
Loss: 0.11103216765232504
ROC train: 0.985390	val: 0.866229	test: 0.784855
PRC train: 0.918963	val: 0.699685	test: 0.633534

Epoch: 106
Loss: 0.11356816342226865
ROC train: 0.985119	val: 0.864332	test: 0.791138
PRC train: 0.918635	val: 0.704502	test: 0.634629

Epoch: 107
Loss: 0.09955506972348287
ROC train: 0.986401	val: 0.838046	test: 0.773276
PRC train: 0.923424	val: 0.634797	test: 0.632260

Epoch: 108
Loss: 0.10585115031163675
ROC train: 0.984277	val: 0.828569	test: 0.747282
PRC train: 0.917234	val: 0.598318	test: 0.623053

Epoch: 109
Loss: 0.10142342619980979
ROC train: 0.985502	val: 0.866366	test: 0.774045
PRC train: 0.920412	val: 0.633816	test: 0.633898

Epoch: 110
Loss: 0.10041700850659499
ROC train: 0.984862	val: 0.877492	test: 0.807211
PRC train: 0.916192	val: 0.622248	test: 0.645115

Epoch: 111
Loss: 0.10946849437760427
ROC train: 0.984814	val: 0.885659	test: 0.822417
PRC train: 0.918524	val: 0.641900	test: 0.655254

Epoch: 112
Loss: 0.10527790887175134
ROC train: 0.984678	val: 0.858850	test: 0.771920
PRC train: 0.914128	val: 0.624295	test: 0.626583

Epoch: 113
Loss: 0.10203115985889757
ROC train: 0.985460	val: 0.867041	test: 0.770545
PRC train: 0.915799	val: 0.642444	test: 0.629348

Epoch: 114
Loss: 0.10779374986160802
ROC train: 0.985666	val: 0.853455	test: 0.805840
PRC train: 0.916880	val: 0.699166	test: 0.652495

Epoch: 115
Loss: 0.09347779847987087
ROC train: 0.986391	val: 0.833102	test: 0.802624
PRC train: 0.922944	val: 0.615664	test: 0.641477

Epoch: 116
Loss: 0.10760470463785661
ROC train: 0.985041	val: 0.829180	test: 0.801481
PRC train: 0.920529	val: 0.624552	test: 0.637861

Epoch: 117
Loss: 0.10182703759280658
ROC train: 0.985317	val: 0.850957	test: 0.805362
PRC train: 0.919854	val: 0.645612	test: 0.641803

Epoch: 118
Loss: 0.09908175735938246
ROC train: 0.985552	val: 0.836648	test: 0.775513
PRC train: 0.921758	val: 0.631028	test: 0.620058

Epoch: 119
Loss: 0.09182169075338296
ROC train: 0.986564	val: 0.833102	test: 0.803868
PRC train: 0.924749	val: 0.622509	test: 0.636730

Epoch: 120
Loss: 0.0990773982437227
ROC train: 0.986775	val: 0.833801	test: 0.815223
PRC train: 0.922174	val: 0.656566	test: 0.647006

Epoch: 121
Loss: 0.10231574645034339
ROC train: 0.987103	val: 0.801697	test: 0.814256
PRC train: 0.924744	val: 0.606037	test: 0.631278

Epoch: 122
Loss: 0.09334321292671265
ROC train: 0.986968	val: 0.816607	test: 0.815399
PRC train: 0.926499	val: 0.619019	test: 0.637724

Epoch: 123
Loss: 0.10401338666509108
ROC train: 0.986997	val: 0.822725	test: 0.819395
PRC train: 0.925870	val: 0.644737	test: 0.644427

Epoch: 124
Loss: 0.10741937882518834
ROC train: 0.986596	val: 0.857226	test: 0.814472
PRC train: 0.920788	val: 0.649505	test: 0.646525

Epoch: 125
Loss: 0.10607860655117674
ROC train: 0.986969	val: 0.850546	test: 0.830306
PRC train: 0.923241	val: 0.632825	test: 0.658470

Epoch: 126
Loss: 0.0952088920699024
ROC train: 0.986273	val: 0.836486	test: 0.821319
PRC train: 0.920409	val: 0.627029	test: 0.651904

Epoch: 127
Loss: 0.10658358700364579
ROC train: 0.987196	val: 0.848761	test: 0.841744
PRC train: 0.927536	val: 0.631859	test: 0.652123

Epoch: 128
Loss: 0.10029281214039523
ROC train: 0.988184	val: 0.858512	test: 0.838408
PRC train: 0.933551	val: 0.624303	test: 0.648706

Epoch: 129
Loss: 0.09621074009902579
ROC train: 0.987920	val: 0.845088	test: 0.828140
PRC train: 0.932169	val: 0.613175	test: 0.649699

Epoch: 130
Loss: 0.09247872772047769
ROC train: 0.986895	val: 0.837684	test: 0.800095
PRC train: 0.929292	val: 0.607102	test: 0.634979

Epoch: 131
Loss: 0.10210938789471827
ROC train: 0.987553	val: 0.837934	test: 0.793786
PRC train: 0.931643	val: 0.643879	test: 0.639554

Epoch: 132
Loss: 0.09460099760213204
ROC train: 0.987928	val: 0.849847	test: 0.814286
PRC train: 0.931943	val: 0.663020	test: 0.650642

Epoch: 133
Loss: 0.09146067871258114
ROC train: 0.986941	val: 0.872635	test: 0.805067
PRC train: 0.923592	val: 0.662735	test: 0.640131

Epoch: 134
Loss: 0.091540957139486
ROC train: 0.987016	val: 0.841044	test: 0.784317
PRC train: 0.927697	val: 0.653641	test: 0.624918

Early stopping
Best (ROC):	 train: 0.983924	val: 0.896373	test: 0.780754
Best (PRC):	 train: 0.908002	val: 0.653755	test: 0.621021

ROC train: 0.983808	val: 0.859524	test: 0.805407
PRC train: 0.911548	val: 0.637178	test: 0.632905

Epoch: 95
Loss: 0.11348133192534124
ROC train: 0.984607	val: 0.804444	test: 0.782633
PRC train: 0.914813	val: 0.622495	test: 0.621198

Epoch: 96
Loss: 0.11463698950846113
ROC train: 0.983672	val: 0.755546	test: 0.776798
PRC train: 0.907433	val: 0.617544	test: 0.616183

Epoch: 97
Loss: 0.11282475877533919
ROC train: 0.983587	val: 0.758681	test: 0.781221
PRC train: 0.911644	val: 0.572749	test: 0.615305

Epoch: 98
Loss: 0.1048844830850068
ROC train: 0.985086	val: 0.801735	test: 0.780672
PRC train: 0.920672	val: 0.612087	test: 0.621259

Epoch: 99
Loss: 0.11018086671952596
ROC train: 0.984652	val: 0.824798	test: 0.787869
PRC train: 0.916473	val: 0.635730	test: 0.626602

Epoch: 100
Loss: 0.11489029959207162
ROC train: 0.984862	val: 0.839420	test: 0.782733
PRC train: 0.912964	val: 0.629193	test: 0.621284

Epoch: 101
Loss: 0.10781490190613216
ROC train: 0.984772	val: 0.832153	test: 0.762470
PRC train: 0.912306	val: 0.605998	test: 0.620221

Epoch: 102
Loss: 0.11033117148761418
ROC train: 0.985485	val: 0.861373	test: 0.800644
PRC train: 0.912742	val: 0.607881	test: 0.628761

Epoch: 103
Loss: 0.10179108661853657
ROC train: 0.985561	val: 0.863945	test: 0.801769
PRC train: 0.919240	val: 0.606994	test: 0.625823

Epoch: 104
Loss: 0.10562814992230467
ROC train: 0.986259	val: 0.868165	test: 0.797223
PRC train: 0.923997	val: 0.604186	test: 0.629775

Epoch: 105
Loss: 0.10650007273925595
ROC train: 0.985522	val: 0.898833	test: 0.794862
PRC train: 0.921126	val: 0.625332	test: 0.623341

Epoch: 106
Loss: 0.10250877988442178
ROC train: 0.986124	val: 0.897659	test: 0.801470
PRC train: 0.921918	val: 0.641771	test: 0.623697

Epoch: 107
Loss: 0.11131786502823422
ROC train: 0.986110	val: 0.886671	test: 0.805242
PRC train: 0.921556	val: 0.666536	test: 0.621308

Epoch: 108
Loss: 0.10265228735916827
ROC train: 0.986619	val: 0.853294	test: 0.773926
PRC train: 0.926033	val: 0.620262	test: 0.611616

Epoch: 109
Loss: 0.1065854363975673
ROC train: 0.985709	val: 0.853094	test: 0.785244
PRC train: 0.920286	val: 0.602639	test: 0.623518

Epoch: 110
Loss: 0.10389311474201221
ROC train: 0.984864	val: 0.861960	test: 0.802164
PRC train: 0.916528	val: 0.599926	test: 0.631277

Epoch: 111
Loss: 0.10746371521840012
ROC train: 0.986597	val: 0.823438	test: 0.777844
PRC train: 0.925382	val: 0.594188	test: 0.620709

Epoch: 112
Loss: 0.09483574128935081
ROC train: 0.985988	val: 0.772080	test: 0.757961
PRC train: 0.922229	val: 0.576230	test: 0.613769

Epoch: 113
Loss: 0.10212911232533654
ROC train: 0.984276	val: 0.784129	test: 0.781307
PRC train: 0.912288	val: 0.582675	test: 0.617925

Epoch: 114
Loss: 0.09334502941387267
ROC train: 0.986265	val: 0.781944	test: 0.770052
PRC train: 0.919787	val: 0.633401	test: 0.630685

Epoch: 115
Loss: 0.11020483086394998
ROC train: 0.983838	val: 0.813697	test: 0.764644
PRC train: 0.908677	val: 0.645515	test: 0.623159

Epoch: 116
Loss: 0.11625365680234379
ROC train: 0.986749	val: 0.814846	test: 0.768480
PRC train: 0.928662	val: 0.667993	test: 0.625129

Epoch: 117
Loss: 0.10237418313318866
ROC train: 0.987226	val: 0.830505	test: 0.780496
PRC train: 0.930158	val: 0.667802	test: 0.630272

Epoch: 118
Loss: 0.09583057355171995
ROC train: 0.986351	val: 0.812587	test: 0.794055
PRC train: 0.922135	val: 0.597113	test: 0.628544

Epoch: 119
Loss: 0.09983673328225276
ROC train: 0.986438	val: 0.764637	test: 0.765996
PRC train: 0.921776	val: 0.572105	test: 0.615939

Epoch: 120
Loss: 0.10497416489902126
ROC train: 0.987256	val: 0.766197	test: 0.764748
PRC train: 0.930245	val: 0.587319	test: 0.622642

Epoch: 121
Loss: 0.09876446208176805
ROC train: 0.986326	val: 0.782942	test: 0.780227
PRC train: 0.925342	val: 0.609868	test: 0.622100

Epoch: 122
Loss: 0.09343536091129698
ROC train: 0.985774	val: 0.777435	test: 0.776555
PRC train: 0.919751	val: 0.585797	test: 0.623045

Epoch: 123
Loss: 0.10497795527446072
ROC train: 0.987084	val: 0.849210	test: 0.798366
PRC train: 0.926122	val: 0.613337	test: 0.626477

Epoch: 124
Loss: 0.10018117905701114
ROC train: 0.983595	val: 0.881638	test: 0.802045
PRC train: 0.910911	val: 0.672294	test: 0.629553

Epoch: 125
Loss: 0.10944708806357321
ROC train: 0.986466	val: 0.855416	test: 0.773750
PRC train: 0.923361	val: 0.625633	test: 0.626531

Epoch: 126
Loss: 0.10492820434186964
ROC train: 0.987099	val: 0.826285	test: 0.756474
PRC train: 0.925573	val: 0.605230	test: 0.620798

Epoch: 127
Loss: 0.10413851874022276
ROC train: 0.986731	val: 0.789798	test: 0.752616
PRC train: 0.924768	val: 0.604045	test: 0.616826

Epoch: 128
Loss: 0.09733295122557693
ROC train: 0.986538	val: 0.780570	test: 0.736845
PRC train: 0.926170	val: 0.599947	test: 0.616527

Epoch: 129
Loss: 0.09758121865748544
ROC train: 0.987670	val: 0.809364	test: 0.742721
PRC train: 0.932207	val: 0.632785	test: 0.613211

Epoch: 130
Loss: 0.10982627881440248
ROC train: 0.987298	val: 0.792844	test: 0.773761
PRC train: 0.928664	val: 0.650969	test: 0.623948

Epoch: 131
Loss: 0.09987952623690428
ROC train: 0.988108	val: 0.788287	test: 0.772200
PRC train: 0.933460	val: 0.629449	test: 0.622871

Epoch: 132
Loss: 0.08911581086297893
ROC train: 0.987769	val: 0.790135	test: 0.768054
PRC train: 0.933809	val: 0.582934	test: 0.623953

Epoch: 133
Loss: 0.0962731080941701
ROC train: 0.987358	val: 0.817956	test: 0.755574
PRC train: 0.931297	val: 0.599478	test: 0.608491

Epoch: 134
Loss: 0.10149359550239559
ROC train: 0.987472	val: 0.855529	test: 0.767755
PRC train: 0.933258	val: 0.624262	test: 0.613989

Epoch: 135
Loss: 0.09721019282080638
ROC train: 0.986807	val: 0.870313	test: 0.776761
PRC train: 0.929010	val: 0.690974	test: 0.628189

Epoch: 136
Loss: 0.09949402595166565
ROC train: 0.986803	val: 0.847499	test: 0.753901
PRC train: 0.927210	val: 0.620836	test: 0.621005

Epoch: 137
Loss: 0.10293035870425733
ROC train: 0.987268	val: 0.795441	test: 0.749149
PRC train: 0.930759	val: 0.603659	test: 0.625575

Epoch: 138
Loss: 0.09947903479573166
ROC train: 0.987992	val: 0.800973	test: 0.751790
PRC train: 0.935527	val: 0.605290	test: 0.623562

Epoch: 139
Loss: 0.08958589544493918
ROC train: 0.988074	val: 0.824686	test: 0.761409
PRC train: 0.934569	val: 0.634151	test: 0.623491

Epoch: 140
Loss: 0.10081529302977796
ROC train: 0.986769	val: 0.854404	test: 0.774337
PRC train: 0.923077	val: 0.687602	test: 0.626702

Early stopping
Best (ROC):	 train: 0.985522	val: 0.898833	test: 0.794862
Best (PRC):	 train: 0.921126	val: 0.625332	test: 0.623341

ROC train: 0.949246	val: 0.707209	test: 0.677341
PRC train: 0.804396	val: 0.600176	test: 0.551112

Epoch: 95
Loss: 0.13394462329550402
ROC train: 0.947966	val: 0.705264	test: 0.670872
PRC train: 0.803859	val: 0.606212	test: 0.570804

Epoch: 96
Loss: 0.1465004905562719
ROC train: 0.950297	val: 0.710156	test: 0.691581
PRC train: 0.811248	val: 0.611848	test: 0.578672

Epoch: 97
Loss: 0.1604251674976598
ROC train: 0.946246	val: 0.713438	test: 0.702007
PRC train: 0.808750	val: 0.598905	test: 0.583923

Epoch: 98
Loss: 0.13620430248788304
ROC train: 0.946655	val: 0.728817	test: 0.729059
PRC train: 0.807494	val: 0.606067	test: 0.591331

Epoch: 99
Loss: 0.18271217020943334
ROC train: 0.955131	val: 0.737646	test: 0.746400
PRC train: 0.825790	val: 0.613855	test: 0.607708

Epoch: 100
Loss: 0.14580439115397575
ROC train: 0.959261	val: 0.720546	test: 0.703730
PRC train: 0.829038	val: 0.582857	test: 0.590938

Epoch: 101
Loss: 0.2066827639877368
ROC train: 0.956932	val: 0.710787	test: 0.690941
PRC train: 0.812918	val: 0.576795	test: 0.583594

Epoch: 102
Loss: 0.12864011761965696
ROC train: 0.946469	val: 0.705969	test: 0.695334
PRC train: 0.777579	val: 0.591740	test: 0.578035

Epoch: 103
Loss: 0.1766500758503912
ROC train: 0.948743	val: 0.717623	test: 0.690731
PRC train: 0.787752	val: 0.598281	test: 0.577054

Epoch: 104
Loss: 0.1680974902783867
ROC train: 0.946241	val: 0.745164	test: 0.685637
PRC train: 0.789862	val: 0.603407	test: 0.578505

Epoch: 105
Loss: 0.22090553991800724
ROC train: 0.943393	val: 0.767317	test: 0.701550
PRC train: 0.790834	val: 0.638700	test: 0.579667

Epoch: 106
Loss: 0.13092061980065106
ROC train: 0.934298	val: 0.757721	test: 0.718254
PRC train: 0.770100	val: 0.614812	test: 0.588457

Epoch: 107
Loss: 0.14358382240800854
ROC train: 0.937521	val: 0.752087	test: 0.716037
PRC train: 0.777310	val: 0.615232	test: 0.587012

Epoch: 108
Loss: 0.13571681063444094
ROC train: 0.953090	val: 0.739543	test: 0.720249
PRC train: 0.809046	val: 0.619348	test: 0.585964

Epoch: 109
Loss: 0.12362927987221939
ROC train: 0.954413	val: 0.727902	test: 0.713928
PRC train: 0.811093	val: 0.631355	test: 0.585157

Epoch: 110
Loss: 0.13438671842711564
ROC train: 0.958781	val: 0.728842	test: 0.726026
PRC train: 0.817373	val: 0.632459	test: 0.590252

Epoch: 111
Loss: 0.1246501465553456
ROC train: 0.962583	val: 0.733944	test: 0.746519
PRC train: 0.830349	val: 0.613408	test: 0.595283

Epoch: 112
Loss: 0.21094447537160424
ROC train: 0.961300	val: 0.752954	test: 0.749603
PRC train: 0.830115	val: 0.619366	test: 0.599386

Epoch: 113
Loss: 0.12717285907858883
ROC train: 0.947807	val: 0.762933	test: 0.753543
PRC train: 0.779131	val: 0.613941	test: 0.571563

Epoch: 114
Loss: 0.1292458697517783
ROC train: 0.950753	val: 0.770077	test: 0.737696
PRC train: 0.785871	val: 0.602953	test: 0.576053

Epoch: 115
Loss: 0.1374345249183123
ROC train: 0.959565	val: 0.764654	test: 0.704733
PRC train: 0.817087	val: 0.608841	test: 0.591423

Epoch: 116
Loss: 0.12224254724778164
ROC train: 0.964188	val: 0.758089	test: 0.698200
PRC train: 0.830603	val: 0.614345	test: 0.589741

Epoch: 117
Loss: 0.16420987897500366
ROC train: 0.963990	val: 0.750102	test: 0.711247
PRC train: 0.838551	val: 0.615036	test: 0.587482

Epoch: 118
Loss: 0.12284264181539928
ROC train: 0.958602	val: 0.780218	test: 0.747276
PRC train: 0.823577	val: 0.653618	test: 0.597437

Epoch: 119
Loss: 0.15225381116472797
ROC train: 0.957055	val: 0.775081	test: 0.752200
PRC train: 0.825749	val: 0.650138	test: 0.600976

Epoch: 120
Loss: 0.14196162505924742
ROC train: 0.956810	val: 0.764135	test: 0.743949
PRC train: 0.831442	val: 0.621249	test: 0.605083

Epoch: 121
Loss: 0.12678172738883836
ROC train: 0.956691	val: 0.741311	test: 0.754507
PRC train: 0.829860	val: 0.616023	test: 0.600768

Epoch: 122
Loss: 0.15143626393098378
ROC train: 0.959317	val: 0.731106	test: 0.719705
PRC train: 0.838263	val: 0.609826	test: 0.586288

Epoch: 123
Loss: 0.15470227741080883
ROC train: 0.953894	val: 0.745594	test: 0.677517
PRC train: 0.821182	val: 0.651758	test: 0.576715

Epoch: 124
Loss: 0.18831575916204807
ROC train: 0.938139	val: 0.735848	test: 0.670668
PRC train: 0.808795	val: 0.664429	test: 0.572530

Epoch: 125
Loss: 0.12481589053193924
ROC train: 0.939991	val: 0.747277	test: 0.659818
PRC train: 0.809087	val: 0.657588	test: 0.575625

Epoch: 126
Loss: 0.16653397682522786
ROC train: 0.954783	val: 0.768113	test: 0.666955
PRC train: 0.822336	val: 0.642163	test: 0.579066

Epoch: 127
Loss: 0.12429907404858216
ROC train: 0.960048	val: 0.800578	test: 0.672528
PRC train: 0.818770	val: 0.637942	test: 0.583025

Epoch: 128
Loss: 0.1263909574614194
ROC train: 0.963521	val: 0.805025	test: 0.677794
PRC train: 0.827942	val: 0.635621	test: 0.584484

Epoch: 129
Loss: 0.12898935515609405
ROC train: 0.958374	val: 0.810065	test: 0.693333
PRC train: 0.823471	val: 0.622751	test: 0.589048

Epoch: 130
Loss: 0.1300380884867191
ROC train: 0.965624	val: 0.804973	test: 0.714490
PRC train: 0.840178	val: 0.624746	test: 0.590131

Epoch: 131
Loss: 0.12625835580126896
ROC train: 0.967221	val: 0.793469	test: 0.733095
PRC train: 0.836268	val: 0.636548	test: 0.592128

Epoch: 132
Loss: 0.17349966932003225
ROC train: 0.969186	val: 0.789792	test: 0.742126
PRC train: 0.847610	val: 0.615071	test: 0.596187

Epoch: 133
Loss: 0.13649998548435816
ROC train: 0.964604	val: 0.779875	test: 0.733078
PRC train: 0.849380	val: 0.601299	test: 0.596716

Epoch: 134
Loss: 0.1302608919048292
ROC train: 0.957580	val: 0.755495	test: 0.705844
PRC train: 0.832273	val: 0.583449	test: 0.589994

Epoch: 135
Loss: 0.12014497601640632
ROC train: 0.962242	val: 0.745367	test: 0.690765
PRC train: 0.844795	val: 0.576336	test: 0.579971

Epoch: 136
Loss: 0.12201702970546843
ROC train: 0.965860	val: 0.752250	test: 0.702607
PRC train: 0.846346	val: 0.592806	test: 0.584231

Epoch: 137
Loss: 0.16689339128320105
ROC train: 0.964028	val: 0.745659	test: 0.717216
PRC train: 0.841372	val: 0.602677	test: 0.592809

Epoch: 138
Loss: 0.1947928460845873
ROC train: 0.962449	val: 0.722475	test: 0.718322
PRC train: 0.846024	val: 0.598773	test: 0.585083

Epoch: 139
Loss: 0.1705959145779552
ROC train: 0.944895	val: 0.707170	test: 0.723759
PRC train: 0.820350	val: 0.633541	test: 0.589089

Epoch: 140
Loss: 0.1537479075617039
ROC train: 0.932350	val: 0.709191	test: 0.706530
PRC train: 0.793838	val: 0.604086	test: 0.586494

Epoch: 141
Loss: 0.14996922616674432
ROC train: 0.932274	val: 0.733833	test: 0.691893
PRC train: 0.798610	val: 0.609711	test: 0.584791

Epoch: 142
Loss: 0.19493842687966514
ROC train: 0.935918	val: 0.742588	test: 0.672069
PRC train: 0.798556	val: 0.611822	test: 0.576775

Epoch: 143
Loss: 0.1420583931081147
ROC train: 0.940293	val: 0.744209	test: 0.684348
PRC train: 0.803880	val: 0.626249	test: 0.582153

Epoch: 144
Loss: 0.19438515096164216
ROC train: 0.949226	val: 0.738736	test: 0.697925
PRC train: 0.815022	val: 0.607552	test: 0.586640

Epoch: 145
Loss: 0.3192155708793394
ROC train: 0.951356	val: 0.731702	test: 0.694337
PRC train: 0.817503	val: 0.599354	test: 0.582636

Epoch: 146
Loss: 0.13458108319018364
ROC train: 0.947131	val: 0.741681	test: 0.712650
PRC train: 0.817516	val: 0.615024	test: 0.584457

Epoch: 147
Loss: 0.1335273649728825
ROC train: 0.944152	val: 0.749579	test: 0.699308
PRC train: 0.809261	val: 0.626548	test: 0.576623

Epoch: 148
Loss: 0.13481297363947395
ROC train: 0.951108	val: 0.755844	test: 0.706831
PRC train: 0.817308	val: 0.650725	test: 0.578769

Epoch: 149
Loss: 0.1400529690917486
ROC train: 0.956348	val: 0.761455	test: 0.732829
PRC train: 0.817529	val: 0.641421	test: 0.585994

Epoch: 150
Loss: 0.12444203859998433
ROC train: 0.961308	val: 0.762844	test: 0.735318
PRC train: 0.829378	val: 0.631382	test: 0.586237

Epoch: 151
Loss: 0.14947861479281185
ROC train: 0.962348	val: 0.758312	test: 0.716204
PRC train: 0.836816	val: 0.629172	test: 0.582616

Epoch: 152
Loss: 0.1173715443752263
ROC train: 0.963123	val: 0.752085	test: 0.706034
PRC train: 0.840073	val: 0.626755	test: 0.581221

Epoch: 153
Loss: 0.16780113184705242
ROC train: 0.962086	val: 0.751502	test: 0.712545
PRC train: 0.841541	val: 0.650788	test: 0.586081

Epoch: 154
Loss: 0.1349467039476697
ROC train: 0.957759	val: 0.754698	test: 0.730085
PRC train: 0.836507	val: 0.629422	test: 0.589798All runs completed.


Epoch: 155
Loss: 0.11838340847407547
ROC train: 0.956189	val: 0.745376	test: 0.732324
PRC train: 0.831990	val: 0.605667	test: 0.592890

Epoch: 156
Loss: 0.16784914042570548
ROC train: 0.958342	val: 0.748942	test: 0.721791
PRC train: 0.833148	val: 0.595856	test: 0.591290

Epoch: 157
Loss: 0.1130867097461106
ROC train: 0.957442	val: 0.750526	test: 0.706582
PRC train: 0.821299	val: 0.588430	test: 0.583206

Epoch: 158
Loss: 0.11795588219777842
ROC train: 0.963013	val: 0.759763	test: 0.718515
PRC train: 0.835461	val: 0.594760	test: 0.586393

Epoch: 159
Loss: 0.12044941655445404
ROC train: 0.968169	val: 0.766748	test: 0.715329
PRC train: 0.855862	val: 0.610787	test: 0.583601

Epoch: 160
Loss: 0.1125971630835102
ROC train: 0.968773	val: 0.766375	test: 0.711083
PRC train: 0.859523	val: 0.613354	test: 0.578436

Epoch: 161
Loss: 0.12217041690087287
ROC train: 0.970529	val: 0.768307	test: 0.713328
PRC train: 0.868069	val: 0.627271	test: 0.576877

Epoch: 162
Loss: 0.1174074198947231
ROC train: 0.970949	val: 0.761810	test: 0.732534
PRC train: 0.868010	val: 0.633322	test: 0.582652

Epoch: 163
Loss: 0.11131653086640192
ROC train: 0.971862	val: 0.765469	test: 0.743022
PRC train: 0.867555	val: 0.656854	test: 0.592117

Epoch: 164
Loss: 0.1050739147112137
ROC train: 0.971431	val: 0.767612	test: 0.746593
PRC train: 0.865685	val: 0.655017	test: 0.597659

Early stopping
Best (ROC):	 train: 0.958374	val: 0.810065	test: 0.693333
Best (PRC):	 train: 0.823471	val: 0.622751	test: 0.589048
All runs completed.
