>>> Starting run for dataset: clintox
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running RANDOM configs_split_experiments/GraphCL/clintox/random/train_prop=0.6.yml on cuda:0
Running RANDOM configs_split_experiments/GraphCL/clintox/random/train_prop=0.7.yml on cuda:1
Running RANDOM configs_split_experiments/GraphCL/clintox/random/train_prop=0.8.yml on cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/clintox/random/train_prop=0.7.yml --runseed 4 --device cuda:1
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/clintox/random/train_prop=0.7.yml --runseed 5 --device cuda:1
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/clintox/random/train_prop=0.7.yml --runseed 6 --device cuda:1
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/clintox/random/train_prop=0.8.yml --runseed 4 --device cuda:2
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/clintox/random/train_prop=0.8.yml --runseed 5 --device cuda:2
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/clintox/random/train_prop=0.8.yml --runseed 6 --device cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/clintox/random/train_prop=0.6.yml --runseed 4 --device cuda:0
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/clintox/random/train_prop=0.6.yml --runseed 5 --device cuda:0
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/clintox/random/train_prop=0.6.yml --runseed 6 --device cuda:0
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/clintox/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/clintox/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/clintox/random/train_prop=0.6/clintox_random_5_26-05_09-45-23  ]
[ Using Seed :  5  ]
[ Using device :  cuda:0  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
randomly split
Data(edge_attr=[48, 2], edge_index=[2, 48], id=[1], x=[21, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6757938053667901
ROC train: 0.485775	val: 0.551665	test: 0.410596
PRC train: 0.504123	val: 0.525046	test: 0.494562

Epoch: 2
Loss: 0.6054093906991325
ROC train: 0.553833	val: 0.591791	test: 0.522583
PRC train: 0.520830	val: 0.535454	test: 0.511774

Epoch: 3
Loss: 0.5468493782388881
ROC train: 0.597923	val: 0.609016	test: 0.604231
PRC train: 0.531282	val: 0.531813	test: 0.525482

Epoch: 4
Loss: 0.4985886206298089
ROC train: 0.617358	val: 0.628229	test: 0.649398
PRC train: 0.535072	val: 0.536617	test: 0.535201

Epoch: 5
Loss: 0.45353521837407124
ROC train: 0.669756	val: 0.647837	test: 0.707481
PRC train: 0.549233	val: 0.540664	test: 0.549612

Epoch: 6
Loss: 0.4182291346110055
ROC train: 0.734512	val: 0.676196	test: 0.750872
PRC train: 0.574180	val: 0.548442	test: 0.568463

Epoch: 7
Loss: 0.38087523116666233
ROC train: 0.754260	val: 0.684115	test: 0.766998
PRC train: 0.582410	val: 0.546967	test: 0.579435

Epoch: 8
Loss: 0.35174101785647166
ROC train: 0.770207	val: 0.702780	test: 0.762641
PRC train: 0.588363	val: 0.551256	test: 0.576533

Epoch: 9
Loss: 0.3246130849610255
ROC train: 0.801317	val: 0.708710	test: 0.787035
PRC train: 0.608619	val: 0.552259	test: 0.591363

Epoch: 10
Loss: 0.2999583454085337
ROC train: 0.821088	val: 0.714613	test: 0.798651
PRC train: 0.624297	val: 0.550413	test: 0.605784

Epoch: 11
Loss: 0.2872257618297872
ROC train: 0.831502	val: 0.735813	test: 0.776721
PRC train: 0.627741	val: 0.557287	test: 0.588381

Epoch: 12
Loss: 0.26492990741677963
ROC train: 0.859651	val: 0.721199	test: 0.806580
PRC train: 0.648123	val: 0.555915	test: 0.601120

Epoch: 13
Loss: 0.2647848896689796
ROC train: 0.875232	val: 0.710790	test: 0.829191
PRC train: 0.667213	val: 0.562250	test: 0.616389

Epoch: 14
Loss: 0.23302572109277733
ROC train: 0.874184	val: 0.730048	test: 0.808505
PRC train: 0.661890	val: 0.560325	test: 0.598929

Epoch: 15
Loss: 0.23621800093041223
ROC train: 0.892611	val: 0.723855	test: 0.810373
PRC train: 0.693216	val: 0.559337	test: 0.612098

Epoch: 16
Loss: 0.22591778586457914
ROC train: 0.901402	val: 0.705232	test: 0.823209
PRC train: 0.721947	val: 0.572696	test: 0.643894

Epoch: 17
Loss: 0.21520799312618202
ROC train: 0.905162	val: 0.718842	test: 0.825389
PRC train: 0.714892	val: 0.563682	test: 0.627384

Epoch: 18
Loss: 0.20664466055250508
ROC train: 0.906772	val: 0.696084	test: 0.840023
PRC train: 0.713029	val: 0.551512	test: 0.628136

Epoch: 19
Loss: 0.21055543058804094
ROC train: 0.892671	val: 0.681132	test: 0.803297
PRC train: 0.733083	val: 0.550120	test: 0.602249

Epoch: 20
Loss: 0.2006194120800484
ROC train: 0.929197	val: 0.684065	test: 0.853854
PRC train: 0.779066	val: 0.550590	test: 0.632263

Epoch: 21
Loss: 0.19328164205417242
ROC train: 0.942071	val: 0.696669	test: 0.846380
PRC train: 0.787156	val: 0.555372	test: 0.639593

Epoch: 22
Loss: 0.19830075821965795
ROC train: 0.933487	val: 0.737488	test: 0.822867
PRC train: 0.772678	val: 0.558848	test: 0.612129

Epoch: 23
Loss: 0.19018682046497623
ROC train: 0.933774	val: 0.738915	test: 0.812327
PRC train: 0.778467	val: 0.561637	test: 0.612097

Epoch: 24
Loss: 0.1732303172280252
ROC train: 0.933826	val: 0.689914	test: 0.819559
PRC train: 0.797482	val: 0.548394	test: 0.640654

Epoch: 25
Loss: 0.1698302464180687
ROC train: 0.944655	val: 0.687234	test: 0.831886
PRC train: 0.799581	val: 0.551001	test: 0.627721

Epoch: 26
Loss: 0.18036372343030793
ROC train: 0.948487	val: 0.696238	test: 0.821482
PRC train: 0.796320	val: 0.553132	test: 0.616223

Epoch: 27
Loss: 0.1735201548874831
ROC train: 0.948545	val: 0.717325	test: 0.812465
PRC train: 0.805576	val: 0.557320	test: 0.612981

Epoch: 28
Loss: 0.16406107800202133
ROC train: 0.953832	val: 0.719645	test: 0.828096
PRC train: 0.812642	val: 0.561869	test: 0.622492

Epoch: 29
Loss: 0.1680098486886907
ROC train: 0.946036	val: 0.731903	test: 0.827933
PRC train: 0.789397	val: 0.559042	test: 0.631257

Epoch: 30
Loss: 0.16943063025382446
ROC train: 0.958808	val: 0.716415	test: 0.835170
PRC train: 0.839419	val: 0.561982	test: 0.661036

Epoch: 31
Loss: 0.17405474083170128
ROC train: 0.954548	val: 0.724855	test: 0.818107
PRC train: 0.834332	val: 0.569820	test: 0.616291

Epoch: 32
Loss: 0.15748795669171933
ROC train: 0.960084	val: 0.735055	test: 0.847322
PRC train: 0.853129	val: 0.563114	test: 0.653501

Epoch: 33
Loss: 0.14520625978667062Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/clintox/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/clintox/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/clintox/random/train_prop=0.6/clintox_random_6_26-05_09-45-23  ]
[ Using Seed :  6  ]
[ Using device :  cuda:0  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
randomly split
Data(edge_attr=[48, 2], edge_index=[2, 48], id=[1], x=[21, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6535000064807636
ROC train: 0.561275	val: 0.518244	test: 0.477710
PRC train: 0.522863	val: 0.509905	test: 0.498485

Epoch: 2
Loss: 0.5910083657880252
ROC train: 0.619630	val: 0.585100	test: 0.589464
PRC train: 0.535508	val: 0.522317	test: 0.521581

Epoch: 3
Loss: 0.53555356435945
ROC train: 0.674934	val: 0.622807	test: 0.673844
PRC train: 0.550017	val: 0.529438	test: 0.542155

Epoch: 4
Loss: 0.48214961618539576
ROC train: 0.702957	val: 0.658363	test: 0.719188
PRC train: 0.560097	val: 0.539793	test: 0.555533

Epoch: 5
Loss: 0.4363621844022221
ROC train: 0.722307	val: 0.691471	test: 0.738798
PRC train: 0.571883	val: 0.547907	test: 0.564710

Epoch: 6
Loss: 0.4012446021318892
ROC train: 0.751825	val: 0.702970	test: 0.760190
PRC train: 0.583649	val: 0.552388	test: 0.575199

Epoch: 7
Loss: 0.37559673578147257
ROC train: 0.788120	val: 0.713064	test: 0.771396
PRC train: 0.603875	val: 0.556032	test: 0.579694

Epoch: 8
Loss: 0.3390854679680333
ROC train: 0.813090	val: 0.715792	test: 0.779819
PRC train: 0.621729	val: 0.555719	test: 0.584595

Epoch: 9
Loss: 0.3169838282306985
ROC train: 0.829065	val: 0.711334	test: 0.795654
PRC train: 0.632272	val: 0.554607	test: 0.591600

Epoch: 10
Loss: 0.29487747162535277
ROC train: 0.850897	val: 0.708534	test: 0.823474
PRC train: 0.647482	val: 0.552920	test: 0.608775

Epoch: 11
Loss: 0.28540698787244145
ROC train: 0.864515	val: 0.723113	test: 0.822908
PRC train: 0.653999	val: 0.558224	test: 0.607636

Epoch: 12
Loss: 0.26260460648943584
ROC train: 0.876598	val: 0.710276	test: 0.839447
PRC train: 0.668872	val: 0.552576	test: 0.622212

Epoch: 13
Loss: 0.25247276847974215
ROC train: 0.886013	val: 0.712044	test: 0.835821
PRC train: 0.681467	val: 0.554315	test: 0.616062

Epoch: 14
Loss: 0.23446511151190003
ROC train: 0.897583	val: 0.711488	test: 0.822556
PRC train: 0.697899	val: 0.555027	test: 0.610181

Epoch: 15
Loss: 0.2332299795004813
ROC train: 0.914573	val: 0.681130	test: 0.824359
PRC train: 0.723593	val: 0.548964	test: 0.622587

Epoch: 16
Loss: 0.22523312044626118
ROC train: 0.923349	val: 0.671352	test: 0.838237
PRC train: 0.737799	val: 0.544402	test: 0.625436

Epoch: 17
Loss: 0.2045837375536057
ROC train: 0.925559	val: 0.692948	test: 0.844434
PRC train: 0.756608	val: 0.548072	test: 0.623907

Epoch: 18
Loss: 0.1928133787947797
ROC train: 0.933747	val: 0.713785	test: 0.835824
PRC train: 0.777179	val: 0.572719	test: 0.617785

Epoch: 19
Loss: 0.1998519795140882
ROC train: 0.942525	val: 0.717205	test: 0.829607
PRC train: 0.796550	val: 0.573551	test: 0.625060

Epoch: 20
Loss: 0.18864225931014694
ROC train: 0.947189	val: 0.700149	test: 0.826310
PRC train: 0.812410	val: 0.572955	test: 0.637000

Epoch: 21
Loss: 0.19031954469228812
ROC train: 0.953838	val: 0.698623	test: 0.826494
PRC train: 0.817854	val: 0.552646	test: 0.612571

Epoch: 22
Loss: 0.17452115750515856
ROC train: 0.953853	val: 0.685402	test: 0.833092
PRC train: 0.815920	val: 0.547358	test: 0.610212

Epoch: 23
Loss: 0.1719833828645972
ROC train: 0.952448	val: 0.703187	test: 0.848877
PRC train: 0.815924	val: 0.549971	test: 0.617085

Epoch: 24
Loss: 0.17327110632568893
ROC train: 0.949928	val: 0.711352	test: 0.858087
PRC train: 0.810027	val: 0.552699	test: 0.623396

Epoch: 25
Loss: 0.16941154677520048
ROC train: 0.945342	val: 0.690975	test: 0.847690
PRC train: 0.790609	val: 0.547520	test: 0.616951

Epoch: 26
Loss: 0.16321347606047198
ROC train: 0.954757	val: 0.644299	test: 0.828168
PRC train: 0.848929	val: 0.544720	test: 0.627501

Epoch: 27
Loss: 0.15866569017461837
ROC train: 0.964365	val: 0.691270	test: 0.808722
PRC train: 0.858889	val: 0.560876	test: 0.616039

Epoch: 28
Loss: 0.15226356246502273
ROC train: 0.966116	val: 0.720887	test: 0.790710
PRC train: 0.861861	val: 0.561409	test: 0.603833

Epoch: 29
Loss: 0.1573773640494081
ROC train: 0.957664	val: 0.717866	test: 0.759380
PRC train: 0.835261	val: 0.559335	test: 0.590918

Epoch: 30
Loss: 0.1658716047832104
ROC train: 0.960031	val: 0.738115	test: 0.773998
PRC train: 0.832422	val: 0.562315	test: 0.599818

Epoch: 31
Loss: 0.152714247520815
ROC train: 0.954184	val: 0.694062	test: 0.799330
PRC train: 0.822375	val: 0.572408	test: 0.633693

Epoch: 32
Loss: 0.14804296245106704
ROC train: 0.961964	val: 0.666598	test: 0.807314
PRC train: 0.855459	val: 0.567802	test: 0.623076

Epoch: 33
Loss: 0.15514982815549214Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/clintox/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/clintox/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/clintox/random/train_prop=0.6/clintox_random_4_26-05_09-45-23  ]
[ Using Seed :  4  ]
[ Using device :  cuda:0  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
randomly split
Data(edge_attr=[48, 2], edge_index=[2, 48], id=[1], x=[21, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6773631728307326
ROC train: 0.511065	val: 0.585885	test: 0.459927
PRC train: 0.511554	val: 0.529339	test: 0.500150

Epoch: 2
Loss: 0.6122370394293953
ROC train: 0.556857	val: 0.603377	test: 0.545716
PRC train: 0.525408	val: 0.529439	test: 0.515061

Epoch: 3
Loss: 0.5536877182218207
ROC train: 0.622435	val: 0.632393	test: 0.609767
PRC train: 0.540246	val: 0.536069	test: 0.528188

Epoch: 4
Loss: 0.4995232289541767
ROC train: 0.650398	val: 0.657589	test: 0.657435
PRC train: 0.548066	val: 0.543673	test: 0.537087

Epoch: 5
Loss: 0.45619626235217225
ROC train: 0.702049	val: 0.675430	test: 0.721180
PRC train: 0.563824	val: 0.550247	test: 0.552819

Epoch: 6
Loss: 0.41080055876715144
ROC train: 0.760021	val: 0.696569	test: 0.753247
PRC train: 0.588974	val: 0.561109	test: 0.563057

Epoch: 7
Loss: 0.3831156338274395
ROC train: 0.771026	val: 0.706939	test: 0.761004
PRC train: 0.598843	val: 0.559690	test: 0.568050

Epoch: 8
Loss: 0.3566669073479336
ROC train: 0.785718	val: 0.703777	test: 0.755096
PRC train: 0.613042	val: 0.555477	test: 0.569646

Epoch: 9
Loss: 0.3235350314979719
ROC train: 0.820080	val: 0.679222	test: 0.758078
PRC train: 0.626358	val: 0.547361	test: 0.576882

Epoch: 10
Loss: 0.3013663836039806
ROC train: 0.846705	val: 0.702262	test: 0.753430
PRC train: 0.646341	val: 0.550823	test: 0.577215

Epoch: 11
Loss: 0.2832339623209415
ROC train: 0.858694	val: 0.716997	test: 0.778111
PRC train: 0.658725	val: 0.556645	test: 0.581035

Epoch: 12
Loss: 0.26564076012913784
ROC train: 0.876880	val: 0.723082	test: 0.806197
PRC train: 0.679944	val: 0.581830	test: 0.598039

Epoch: 13
Loss: 0.25781102421549457
ROC train: 0.894858	val: 0.725616	test: 0.828837
PRC train: 0.689588	val: 0.561792	test: 0.614819

Epoch: 14
Loss: 0.24287730321851417
ROC train: 0.907524	val: 0.731275	test: 0.836560
PRC train: 0.700603	val: 0.563901	test: 0.612130

Epoch: 15
Loss: 0.23336224316178067
ROC train: 0.907759	val: 0.701170	test: 0.835059
PRC train: 0.720005	val: 0.555723	test: 0.626981

Epoch: 16
Loss: 0.22535595303423755
ROC train: 0.901456	val: 0.705894	test: 0.828653
PRC train: 0.709836	val: 0.554835	test: 0.621459

Epoch: 17
Loss: 0.22021319993566474
ROC train: 0.910315	val: 0.739133	test: 0.813473
PRC train: 0.720357	val: 0.562462	test: 0.617953

Epoch: 18
Loss: 0.2086878762689404
ROC train: 0.921386	val: 0.742110	test: 0.820799
PRC train: 0.762955	val: 0.566306	test: 0.635153

Epoch: 19
Loss: 0.2010999028918807
ROC train: 0.929263	val: 0.732191	test: 0.834393
PRC train: 0.766832	val: 0.564438	test: 0.669327

Epoch: 20
Loss: 0.1917237433346634
ROC train: 0.934523	val: 0.740340	test: 0.822900
PRC train: 0.780611	val: 0.563924	test: 0.637986

Epoch: 21
Loss: 0.18486368558299027
ROC train: 0.943123	val: 0.734686	test: 0.816416
PRC train: 0.808864	val: 0.563338	test: 0.622922

Epoch: 22
Loss: 0.17394489722616766
ROC train: 0.945514	val: 0.740921	test: 0.819807
PRC train: 0.822222	val: 0.564193	test: 0.630008

Epoch: 23
Loss: 0.17735833274574664
ROC train: 0.953631	val: 0.751073	test: 0.822286
PRC train: 0.819337	val: 0.565859	test: 0.632737

Epoch: 24
Loss: 0.1697987310098577
ROC train: 0.950733	val: 0.764717	test: 0.812378
PRC train: 0.809051	val: 0.568286	test: 0.623025

Epoch: 25
Loss: 0.16389143049407207
ROC train: 0.956415	val: 0.765593	test: 0.817593
PRC train: 0.832479	val: 0.573147	test: 0.632556

Epoch: 26
Loss: 0.17375948624427057
ROC train: 0.958500	val: 0.735498	test: 0.832676
PRC train: 0.840067	val: 0.567647	test: 0.646671

Epoch: 27
Loss: 0.15817994131768706
ROC train: 0.959084	val: 0.702989	test: 0.843271
PRC train: 0.840486	val: 0.561261	test: 0.653040

Epoch: 28
Loss: 0.15693047782033465
ROC train: 0.962475	val: 0.717480	test: 0.846782
PRC train: 0.843100	val: 0.568644	test: 0.660014

Epoch: 29
Loss: 0.1508719955233176
ROC train: 0.965047	val: 0.753064	test: 0.840507
PRC train: 0.851703	val: 0.569264	test: 0.638972

Epoch: 30
Loss: 0.17093613038273764
ROC train: 0.967032	val: 0.751500	test: 0.843064
PRC train: 0.860929	val: 0.568746	test: 0.640136

Epoch: 31
Loss: 0.15215968101055752
ROC train: 0.964711	val: 0.736302	test: 0.841512
PRC train: 0.855051	val: 0.565969	test: 0.645123

Epoch: 32
Loss: 0.15730608672139035
ROC train: 0.966989	val: 0.770674	test: 0.843862
PRC train: 0.860891	val: 0.577116	test: 0.661320

Epoch: 33
Loss: 0.15480874332053368Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/clintox/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/clintox/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/clintox/random/train_prop=0.7/clintox_random_4_26-05_09-45-23  ]
[ Using Seed :  4  ]
[ Using device :  cuda:1  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
randomly split
Data(edge_attr=[48, 2], edge_index=[2, 48], id=[1], x=[21, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6612536849596846
ROC train: 0.534938	val: 0.550047	test: 0.510256
PRC train: 0.515946	val: 0.522812	test: 0.510232

Epoch: 2
Loss: 0.5837799181764625
ROC train: 0.559269	val: 0.536794	test: 0.591300
PRC train: 0.521085	val: 0.518043	test: 0.522023

Epoch: 3
Loss: 0.5268389444044173
ROC train: 0.597130	val: 0.542231	test: 0.641377
PRC train: 0.529003	val: 0.523550	test: 0.533468

Epoch: 4
Loss: 0.5192890965346993
ROC train: 0.640987	val: 0.552241	test: 0.610445
PRC train: 0.544780	val: 0.529549	test: 0.528517

Epoch: 5
Loss: 0.43849897133516225
ROC train: 0.692913	val: 0.537947	test: 0.620151
PRC train: 0.570951	val: 0.529649	test: 0.530973

Epoch: 6
Loss: 0.41074148473900635
ROC train: 0.705587	val: 0.583873	test: 0.577124
PRC train: 0.572909	val: 0.534759	test: 0.525946

Epoch: 7
Loss: 0.3487034369438169
ROC train: 0.694721	val: 0.620865	test: 0.560381
PRC train: 0.562007	val: 0.538636	test: 0.523304

Epoch: 8
Loss: 0.34254943860456943
ROC train: 0.695782	val: 0.633467	test: 0.574201
PRC train: 0.561410	val: 0.543961	test: 0.524578

Epoch: 9
Loss: 0.308236814764672
ROC train: 0.726853	val: 0.651970	test: 0.661885
PRC train: 0.572334	val: 0.546704	test: 0.537083

Epoch: 10
Loss: 0.2675404220329317
ROC train: 0.771040	val: 0.679276	test: 0.754801
PRC train: 0.585309	val: 0.553655	test: 0.561061

Epoch: 11
Loss: 0.26140295779726364
ROC train: 0.790011	val: 0.668687	test: 0.811546
PRC train: 0.587031	val: 0.548804	test: 0.592134

Epoch: 12
Loss: 0.27649454982507227
ROC train: 0.802658	val: 0.663323	test: 0.831654
PRC train: 0.594542	val: 0.550446	test: 0.609610

Epoch: 13
Loss: 0.24444898362910314
ROC train: 0.800670	val: 0.658341	test: 0.831243
PRC train: 0.595164	val: 0.575732	test: 0.595926

Epoch: 14
Loss: 0.22322290169678652
ROC train: 0.803522	val: 0.661720	test: 0.809756
PRC train: 0.599230	val: 0.567158	test: 0.581093

Epoch: 15
Loss: 0.21727645693100173
ROC train: 0.831078	val: 0.671645	test: 0.824716
PRC train: 0.622372	val: 0.563559	test: 0.591591

Epoch: 16
Loss: 0.2655279211590825
ROC train: 0.846220	val: 0.653870	test: 0.828418
PRC train: 0.640588	val: 0.562622	test: 0.597826

Epoch: 17
Loss: 0.2226823882948637
ROC train: 0.833472	val: 0.616904	test: 0.806414
PRC train: 0.646569	val: 0.543349	test: 0.582939

Epoch: 18
Loss: 0.1981090586873912
ROC train: 0.863832	val: 0.632226	test: 0.813026
PRC train: 0.661357	val: 0.546462	test: 0.581942

Epoch: 19
Loss: 0.2070274278384033
ROC train: 0.886383	val: 0.639414	test: 0.857334
PRC train: 0.678021	val: 0.549865	test: 0.618596

Epoch: 20
Loss: 0.2004062615958529
ROC train: 0.883728	val: 0.636135	test: 0.852551
PRC train: 0.668202	val: 0.550279	test: 0.626207

Epoch: 21
Loss: 0.18914171204080726
ROC train: 0.889483	val: 0.678372	test: 0.807760
PRC train: 0.682083	val: 0.568630	test: 0.597490

Epoch: 22
Loss: 0.18619469878527273
ROC train: 0.888798	val: 0.666277	test: 0.799790
PRC train: 0.693544	val: 0.557184	test: 0.597724

Epoch: 23
Loss: 0.2100273754331409
ROC train: 0.900244	val: 0.643917	test: 0.848542
PRC train: 0.713244	val: 0.547581	test: 0.610327

Epoch: 24
Loss: 0.18301583340660915
ROC train: 0.882003	val: 0.629975	test: 0.869677
PRC train: 0.710174	val: 0.545122	test: 0.613322

Epoch: 25
Loss: 0.18896999787148575
ROC train: 0.892665	val: 0.662136	test: 0.883190
PRC train: 0.725201	val: 0.550540	test: 0.620688

Epoch: 26
Loss: 0.16761431094826768
ROC train: 0.882288	val: 0.690794	test: 0.868966
PRC train: 0.693087	val: 0.563134	test: 0.603683

Epoch: 27
Loss: 0.2445776345756908
ROC train: 0.889712	val: 0.699321	test: 0.872817
PRC train: 0.706464	val: 0.568511	test: 0.613262

Epoch: 28
Loss: 0.18493435138493414
ROC train: 0.894916	val: 0.673462	test: 0.900510
PRC train: 0.719124	val: 0.552292	test: 0.654317

Epoch: 29
Loss: 0.19650206102945236
ROC train: 0.896938	val: 0.684072	test: 0.895629
PRC train: 0.727368	val: 0.553375	test: 0.653555

Epoch: 30
Loss: 0.1687614879245221
ROC train: 0.895212	val: 0.669312	test: 0.889947
PRC train: 0.715656	val: 0.555254	test: 0.639181

Epoch: 31
Loss: 0.20563129192093427
ROC train: 0.902995	val: 0.657281	test: 0.885483
PRC train: 0.723047	val: 0.554410	test: 0.630450

Epoch: 32
Loss: 0.235036212542094
ROC train: 0.915598	val: 0.633894	test: 0.937947
PRC train: 0.733464	val: 0.547441	test: 0.717855

Epoch: 33
Loss: 0.1818341573355184Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/clintox/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/clintox/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/clintox/random/train_prop=0.7/clintox_random_6_26-05_09-45-23  ]
[ Using Seed :  6  ]
[ Using device :  cuda:1  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
randomly split
Data(edge_attr=[48, 2], edge_index=[2, 48], id=[1], x=[21, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6490128329308156
ROC train: 0.576119	val: 0.497413	test: 0.571919
PRC train: 0.522910	val: 0.506668	test: 0.514009

Epoch: 2
Loss: 0.5670184624462353
ROC train: 0.588613	val: 0.549458	test: 0.641511
PRC train: 0.526317	val: 0.516540	test: 0.532144

Epoch: 3
Loss: 0.5006070078685999
ROC train: 0.642731	val: 0.595966	test: 0.719267
PRC train: 0.539036	val: 0.529784	test: 0.548055

Epoch: 4
Loss: 0.4846233866022261
ROC train: 0.665502	val: 0.633414	test: 0.764171
PRC train: 0.546067	val: 0.543259	test: 0.562504

Epoch: 5
Loss: 0.4055814555717089
ROC train: 0.733032	val: 0.638183	test: 0.845940
PRC train: 0.568023	val: 0.545068	test: 0.603175

Epoch: 6
Loss: 0.3609879447977141
ROC train: 0.746544	val: 0.660973	test: 0.850155
PRC train: 0.572746	val: 0.549275	test: 0.609703

Epoch: 7
Loss: 0.3312424980410231
ROC train: 0.741030	val: 0.675873	test: 0.843379
PRC train: 0.571287	val: 0.551894	test: 0.611032

Epoch: 8
Loss: 0.3136754045240108
ROC train: 0.756757	val: 0.672977	test: 0.869214
PRC train: 0.576919	val: 0.550427	test: 0.629752

Epoch: 9
Loss: 0.285276689991468
ROC train: 0.784880	val: 0.654980	test: 0.897039
PRC train: 0.589932	val: 0.545640	test: 0.639933

Epoch: 10
Loss: 0.2615961998968455
ROC train: 0.806061	val: 0.642148	test: 0.871777
PRC train: 0.604656	val: 0.544211	test: 0.618571

Epoch: 11
Loss: 0.2436450593567198
ROC train: 0.807505	val: 0.621592	test: 0.845212
PRC train: 0.603529	val: 0.538977	test: 0.612067

Epoch: 12
Loss: 0.22962071012852983
ROC train: 0.819952	val: 0.596334	test: 0.864717
PRC train: 0.610837	val: 0.534433	test: 0.609957

Epoch: 13
Loss: 0.2246337501523389
ROC train: 0.835147	val: 0.594119	test: 0.874523
PRC train: 0.624656	val: 0.533693	test: 0.610284

Epoch: 14
Loss: 0.2288876883767185
ROC train: 0.848726	val: 0.585182	test: 0.892286
PRC train: 0.636046	val: 0.532820	test: 0.671043

Epoch: 15
Loss: 0.20900497510981114
ROC train: 0.849735	val: 0.606537	test: 0.887213
PRC train: 0.643218	val: 0.541000	test: 0.672069

Epoch: 16
Loss: 0.1877842047661413
ROC train: 0.847707	val: 0.656246	test: 0.869941
PRC train: 0.629301	val: 0.549244	test: 0.657997

Epoch: 17
Loss: 0.20089482369362247
ROC train: 0.866689	val: 0.660827	test: 0.887800
PRC train: 0.649533	val: 0.549308	test: 0.697685

Epoch: 18
Loss: 0.1917474180227947
ROC train: 0.856309	val: 0.651075	test: 0.895053
PRC train: 0.662831	val: 0.548237	test: 0.715153

Epoch: 19
Loss: 0.22229945304008253
ROC train: 0.872049	val: 0.627083	test: 0.877903
PRC train: 0.675635	val: 0.544477	test: 0.710584

Epoch: 20
Loss: 0.18462006491535482
ROC train: 0.885794	val: 0.605174	test: 0.867514
PRC train: 0.687220	val: 0.537589	test: 0.690447

Epoch: 21
Loss: 0.18004641945558625
ROC train: 0.885496	val: 0.587745	test: 0.847635
PRC train: 0.684484	val: 0.536355	test: 0.627822

Epoch: 22
Loss: 0.24179939701602401
ROC train: 0.890669	val: 0.595064	test: 0.864711
PRC train: 0.683381	val: 0.538078	test: 0.621136

Epoch: 23
Loss: 0.26874516477936755
ROC train: 0.873681	val: 0.608584	test: 0.876669
PRC train: 0.676700	val: 0.540522	test: 0.611433

Epoch: 24
Loss: 0.21063112532185818
ROC train: 0.867793	val: 0.585323	test: 0.869223
PRC train: 0.678279	val: 0.536068	test: 0.669583

Epoch: 25
Loss: 0.19873136196876082
ROC train: 0.873493	val: 0.610390	test: 0.880525
PRC train: 0.670060	val: 0.542588	test: 0.664877

Epoch: 26
Loss: 0.2035340869084988
ROC train: 0.875596	val: 0.630924	test: 0.874981
PRC train: 0.662816	val: 0.553527	test: 0.651997

Epoch: 27
Loss: 0.17688149959236865
ROC train: 0.893973	val: 0.580644	test: 0.891088
PRC train: 0.702958	val: 0.535106	test: 0.665570

Epoch: 28
Loss: 0.21955304604154188
ROC train: 0.897824	val: 0.594460	test: 0.886292
PRC train: 0.704837	val: 0.534032	test: 0.667279

Epoch: 29
Loss: 0.17107241911977963
ROC train: 0.879456	val: 0.636126	test: 0.849986
PRC train: 0.665398	val: 0.542724	test: 0.638644

Epoch: 30
Loss: 0.17140737263481506
ROC train: 0.893068	val: 0.655642	test: 0.862505
PRC train: 0.693930	val: 0.547068	test: 0.645922

Epoch: 31
Loss: 0.190763293271693
ROC train: 0.913607	val: 0.646818	test: 0.904010
PRC train: 0.729228	val: 0.542889	test: 0.687898

Epoch: 32
Loss: 0.1652665155587052
ROC train: 0.917892	val: 0.609959	test: 0.912476
PRC train: 0.747547	val: 0.533450	test: 0.687160

Epoch: 33
Loss: 0.1916160800732083Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/clintox/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/clintox/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/clintox/random/train_prop=0.7/clintox_random_5_26-05_09-45-23  ]
[ Using Seed :  5  ]
[ Using device :  cuda:1  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
randomly split
Data(edge_attr=[48, 2], edge_index=[2, 48], id=[1], x=[21, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6645409317032073
ROC train: 0.527953	val: 0.510116	test: 0.484912
PRC train: 0.513428	val: 0.519845	test: 0.507646

Epoch: 2
Loss: 0.5938080780232348
ROC train: 0.582615	val: 0.583569	test: 0.656209
PRC train: 0.527869	val: 0.535056	test: 0.530922

Epoch: 3
Loss: 0.5254334154319535
ROC train: 0.608136	val: 0.593784	test: 0.693819
PRC train: 0.534532	val: 0.536028	test: 0.538016

Epoch: 4
Loss: 0.4685345272224546
ROC train: 0.598998	val: 0.607102	test: 0.668144
PRC train: 0.531611	val: 0.547621	test: 0.534628

Epoch: 5
Loss: 0.42069528961012576
ROC train: 0.607027	val: 0.604596	test: 0.667878
PRC train: 0.531732	val: 0.544524	test: 0.535385

Epoch: 6
Loss: 0.4242646059357492
ROC train: 0.651690	val: 0.595296	test: 0.693039
PRC train: 0.539529	val: 0.538596	test: 0.541225

Epoch: 7
Loss: 0.3970556480037192
ROC train: 0.724909	val: 0.640674	test: 0.761652
PRC train: 0.562003	val: 0.549643	test: 0.565630

Epoch: 8
Loss: 0.3217485672982487
ROC train: 0.764139	val: 0.613498	test: 0.780645
PRC train: 0.588838	val: 0.545769	test: 0.579559

Epoch: 9
Loss: 0.32349823646042764
ROC train: 0.769345	val: 0.612349	test: 0.735275
PRC train: 0.593843	val: 0.544329	test: 0.569665

Epoch: 10
Loss: 0.3163072326030409
ROC train: 0.786490	val: 0.639993	test: 0.818273
PRC train: 0.590486	val: 0.554047	test: 0.591408

Epoch: 11
Loss: 0.26114947685585005
ROC train: 0.773240	val: 0.617743	test: 0.811240
PRC train: 0.584393	val: 0.569493	test: 0.582460

Epoch: 12
Loss: 0.2454727000505315
ROC train: 0.788248	val: 0.599935	test: 0.850698
PRC train: 0.595578	val: 0.545897	test: 0.620646

Epoch: 13
Loss: 0.2785632211789169
ROC train: 0.800403	val: 0.600284	test: 0.871112
PRC train: 0.601554	val: 0.546693	test: 0.634070

Epoch: 14
Loss: 0.26038283947924334
ROC train: 0.823073	val: 0.600397	test: 0.850817
PRC train: 0.613924	val: 0.544127	test: 0.625300

Epoch: 15
Loss: 0.23315909461164278
ROC train: 0.830256	val: 0.606487	test: 0.798935
PRC train: 0.618447	val: 0.542767	test: 0.601008

Epoch: 16
Loss: 0.21412153913840132
ROC train: 0.831969	val: 0.611663	test: 0.762403
PRC train: 0.623458	val: 0.543828	test: 0.587505

Epoch: 17
Loss: 0.2553621738541968
ROC train: 0.840246	val: 0.573942	test: 0.799335
PRC train: 0.626716	val: 0.535221	test: 0.613390

Epoch: 18
Loss: 0.22585701948954476
ROC train: 0.822075	val: 0.556474	test: 0.776662
PRC train: 0.613432	val: 0.531419	test: 0.588131

Epoch: 19
Loss: 0.27243301879554194
ROC train: 0.834002	val: 0.642294	test: 0.783837
PRC train: 0.614154	val: 0.556974	test: 0.571227

Epoch: 20
Loss: 0.26727735838278666
ROC train: 0.832774	val: 0.655336	test: 0.824157
PRC train: 0.627982	val: 0.576390	test: 0.588773

Epoch: 21
Loss: 0.20128480273763177
ROC train: 0.836191	val: 0.593060	test: 0.879350
PRC train: 0.638214	val: 0.538679	test: 0.668171

Epoch: 22
Loss: 0.262340876730726
ROC train: 0.852316	val: 0.594712	test: 0.896955
PRC train: 0.664122	val: 0.538303	test: 0.691582

Epoch: 23
Loss: 0.2986046077089045
ROC train: 0.853046	val: 0.608136	test: 0.899529
PRC train: 0.653159	val: 0.536804	test: 0.676279

Epoch: 24
Loss: 0.25717223496822667
ROC train: 0.817641	val: 0.669910	test: 0.852689
PRC train: 0.611630	val: 0.561989	test: 0.612663

Epoch: 25
Loss: 0.22637289651328096
ROC train: 0.835011	val: 0.673511	test: 0.884115
PRC train: 0.643731	val: 0.556236	test: 0.633168

Epoch: 26
Loss: 0.18520937641047713
ROC train: 0.836636	val: 0.650147	test: 0.868670
PRC train: 0.653370	val: 0.544778	test: 0.645062

Epoch: 27
Loss: 0.20688249340602732
ROC train: 0.857521	val: 0.656707	test: 0.878422
PRC train: 0.662620	val: 0.546961	test: 0.648658

Epoch: 28
Loss: 0.17874470201663278
ROC train: 0.879945	val: 0.666027	test: 0.882779
PRC train: 0.665607	val: 0.554831	test: 0.652976

Epoch: 29
Loss: 0.2267914785136355
ROC train: 0.882075	val: 0.657217	test: 0.880354
PRC train: 0.672885	val: 0.576473	test: 0.648983

Epoch: 30
Loss: 0.1735244081661421
ROC train: 0.880250	val: 0.624535	test: 0.870836
PRC train: 0.679287	val: 0.587042	test: 0.647760

Epoch: 31
Loss: 0.17642902660437218
ROC train: 0.882837	val: 0.618608	test: 0.876370
PRC train: 0.683765	val: 0.585175	test: 0.669806

Epoch: 32
Loss: 0.21272218024885364
ROC train: 0.892958	val: 0.620804	test: 0.882218
PRC train: 0.692207	val: 0.585465	test: 0.687561

Epoch: 33
Loss: 0.17333327109867702Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/clintox/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/clintox/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/clintox/random/train_prop=0.8/clintox_random_5_26-05_09-45-23  ]
[ Using Seed :  5  ]
[ Using device :  cuda:2  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
randomly split
Data(edge_attr=[48, 2], edge_index=[2, 48], id=[1], x=[21, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6586456644242035
ROC train: 0.525133	val: 0.430147	test: 0.473571
PRC train: 0.511984	val: 0.500192	test: 0.510757

Epoch: 2
Loss: 0.5793447546458688
ROC train: 0.595615	val: 0.577540	test: 0.629452
PRC train: 0.527710	val: 0.522728	test: 0.532536

Epoch: 3
Loss: 0.5139903526693467
ROC train: 0.634918	val: 0.633356	test: 0.698444
PRC train: 0.536600	val: 0.533939	test: 0.547431

Epoch: 4
Loss: 0.4516892659049302
ROC train: 0.678511	val: 0.689171	test: 0.760572
PRC train: 0.548690	val: 0.548382	test: 0.567283

Epoch: 5
Loss: 0.40829533546104635
ROC train: 0.731995	val: 0.734291	test: 0.805379
PRC train: 0.567490	val: 0.566919	test: 0.581415

Epoch: 6
Loss: 0.3700490878908723
ROC train: 0.755927	val: 0.741979	test: 0.807208
PRC train: 0.578671	val: 0.563537	test: 0.579034

Epoch: 7
Loss: 0.33555944384436487
ROC train: 0.790269	val: 0.789773	test: 0.839118
PRC train: 0.593079	val: 0.587002	test: 0.599043

Epoch: 8
Loss: 0.30538996143505065
ROC train: 0.807448	val: 0.777406	test: 0.821724
PRC train: 0.603971	val: 0.576009	test: 0.594696

Epoch: 9
Loss: 0.2901981842304427
ROC train: 0.828305	val: 0.781083	test: 0.835699
PRC train: 0.614943	val: 0.580773	test: 0.614604

Epoch: 10
Loss: 0.26848576729057483
ROC train: 0.843433	val: 0.811163	test: 0.845255
PRC train: 0.635182	val: 0.624456	test: 0.619769

Epoch: 11
Loss: 0.25765491215883884
ROC train: 0.861502	val: 0.802473	test: 0.842646
PRC train: 0.650115	val: 0.601921	test: 0.619977

Epoch: 12
Loss: 0.24221497599664535
ROC train: 0.877682	val: 0.840575	test: 0.856276
PRC train: 0.665694	val: 0.628576	test: 0.617047

Epoch: 13
Loss: 0.22378376138308295
ROC train: 0.888834	val: 0.839572	test: 0.864875
PRC train: 0.689638	val: 0.659391	test: 0.628057

Epoch: 14
Loss: 0.21548387316324996
ROC train: 0.894632	val: 0.828543	test: 0.863137
PRC train: 0.701084	val: 0.662373	test: 0.629100

Epoch: 15
Loss: 0.2092364073404916
ROC train: 0.891043	val: 0.842914	test: 0.877096
PRC train: 0.688878	val: 0.629531	test: 0.635933

Epoch: 16
Loss: 0.21055681336534599
ROC train: 0.905566	val: 0.834225	test: 0.869486
PRC train: 0.714631	val: 0.626884	test: 0.642092

Epoch: 17
Loss: 0.19320832597711973
ROC train: 0.926776	val: 0.825869	test: 0.876407
PRC train: 0.766114	val: 0.648745	test: 0.696884

Epoch: 18
Loss: 0.19845902949751043
ROC train: 0.928776	val: 0.829545	test: 0.868199
PRC train: 0.771113	val: 0.652310	test: 0.705963

Epoch: 19
Loss: 0.19988087123972745
ROC train: 0.920642	val: 0.827206	test: 0.863750
PRC train: 0.752940	val: 0.641350	test: 0.653062

Epoch: 20
Loss: 0.1908897724835061
ROC train: 0.925830	val: 0.817179	test: 0.824472
PRC train: 0.764903	val: 0.614028	test: 0.626841

Epoch: 21
Loss: 0.19010522587855433
ROC train: 0.942299	val: 0.846257	test: 0.873079
PRC train: 0.807300	val: 0.651443	test: 0.690118

Epoch: 22
Loss: 0.17352832464538756
ROC train: 0.943484	val: 0.853944	test: 0.891431
PRC train: 0.809678	val: 0.654752	test: 0.693837

Epoch: 23
Loss: 0.1778785378859094
ROC train: 0.946936	val: 0.834893	test: 0.901154
PRC train: 0.812361	val: 0.641564	test: 0.707055

Epoch: 24
Loss: 0.16281226327823656
ROC train: 0.951488	val: 0.836230	test: 0.909514
PRC train: 0.824793	val: 0.642948	test: 0.718503

Epoch: 25
Loss: 0.1736194621580238
ROC train: 0.957170	val: 0.813503	test: 0.866639
PRC train: 0.826855	val: 0.619066	test: 0.658967

Epoch: 26
Loss: 0.1671867322313154
ROC train: 0.951669	val: 0.807152	test: 0.873787
PRC train: 0.806995	val: 0.616217	test: 0.684490

Epoch: 27
Loss: 0.17113287238880984
ROC train: 0.954092	val: 0.819519	test: 0.888588
PRC train: 0.815497	val: 0.623369	test: 0.694725

Epoch: 28
Loss: 0.15549846457463748
ROC train: 0.959549	val: 0.804479	test: 0.892469
PRC train: 0.839680	val: 0.608978	test: 0.697836

Epoch: 29
Loss: 0.15517344218800586
ROC train: 0.957316	val: 0.802807	test: 0.915205
PRC train: 0.843152	val: 0.645180	test: 0.721860

Epoch: 30
Loss: 0.1507121736122577
ROC train: 0.961038	val: 0.791110	test: 0.912570
PRC train: 0.848470	val: 0.644392	test: 0.722724

Epoch: 31
Loss: 0.1455516124447977
ROC train: 0.963767	val: 0.803142	test: 0.897080
PRC train: 0.848254	val: 0.619755	test: 0.704512

Epoch: 32
Loss: 0.15592038451509496
ROC train: 0.968813	val: 0.776404	test: 0.917064
PRC train: 0.866369	val: 0.628383	test: 0.716609

Epoch: 33
Loss: 0.17001475866845747Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/clintox/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/clintox/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/clintox/random/train_prop=0.8/clintox_random_6_26-05_09-45-23  ]
[ Using Seed :  6  ]
[ Using device :  cuda:2  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
randomly split
Data(edge_attr=[48, 2], edge_index=[2, 48], id=[1], x=[21, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.646052962059797
ROC train: 0.560384	val: 0.490976	test: 0.520870
PRC train: 0.519620	val: 0.506147	test: 0.509196

Epoch: 2
Loss: 0.5636943032857342
ROC train: 0.610244	val: 0.544786	test: 0.622942
PRC train: 0.531500	val: 0.514435	test: 0.533058

Epoch: 3
Loss: 0.49957392064838757
ROC train: 0.655885	val: 0.635361	test: 0.702496
PRC train: 0.543589	val: 0.533327	test: 0.552665

Epoch: 4
Loss: 0.4429695989604965
ROC train: 0.702943	val: 0.701537	test: 0.752648
PRC train: 0.559565	val: 0.547905	test: 0.577921

Epoch: 5
Loss: 0.39799317191150735
ROC train: 0.742154	val: 0.719920	test: 0.781211
PRC train: 0.574073	val: 0.555076	test: 0.585393

Epoch: 6
Loss: 0.3572807609638045
ROC train: 0.764123	val: 0.769719	test: 0.826013
PRC train: 0.586988	val: 0.571089	test: 0.608384

Epoch: 7
Loss: 0.32924893327120186
ROC train: 0.777854	val: 0.801136	test: 0.837731
PRC train: 0.593673	val: 0.577137	test: 0.604788

Epoch: 8
Loss: 0.2964115128248342
ROC train: 0.799727	val: 0.823529	test: 0.851275
PRC train: 0.603977	val: 0.592661	test: 0.613526

Epoch: 9
Loss: 0.27855110557517865
ROC train: 0.820342	val: 0.835561	test: 0.826229
PRC train: 0.614679	val: 0.592898	test: 0.609151

Epoch: 10
Loss: 0.2663380138646909
ROC train: 0.823964	val: 0.838904	test: 0.812417
PRC train: 0.640816	val: 0.603702	test: 0.628085

Epoch: 11
Loss: 0.2456117821936096
ROC train: 0.840646	val: 0.827874	test: 0.815501
PRC train: 0.645849	val: 0.600613	test: 0.675828

Epoch: 12
Loss: 0.2368162071935517
ROC train: 0.872654	val: 0.843917	test: 0.859540
PRC train: 0.678944	val: 0.610645	test: 0.631519

Epoch: 13
Loss: 0.22268956116107202
ROC train: 0.881047	val: 0.856952	test: 0.884438
PRC train: 0.695764	val: 0.655164	test: 0.648117

Epoch: 14
Loss: 0.22164864483343233
ROC train: 0.899812	val: 0.866979	test: 0.894896
PRC train: 0.710973	val: 0.635808	test: 0.655835

Epoch: 15
Loss: 0.20272587687222193
ROC train: 0.905867	val: 0.858623	test: 0.892109
PRC train: 0.732402	val: 0.626603	test: 0.661277

Epoch: 16
Loss: 0.2045809196978426
ROC train: 0.914936	val: 0.873663	test: 0.876726
PRC train: 0.756350	val: 0.642512	test: 0.650138

Epoch: 17
Loss: 0.19344030121751682
ROC train: 0.916881	val: 0.873997	test: 0.859275
PRC train: 0.759977	val: 0.652950	test: 0.678217

Epoch: 18
Loss: 0.189553378673689
ROC train: 0.922290	val: 0.856618	test: 0.847723
PRC train: 0.773124	val: 0.641394	test: 0.670168

Epoch: 19
Loss: 0.1930683879336354
ROC train: 0.937619	val: 0.848262	test: 0.861880
PRC train: 0.799072	val: 0.655373	test: 0.667287

Epoch: 20
Loss: 0.18419986188019793
ROC train: 0.940042	val: 0.824198	test: 0.842854
PRC train: 0.821006	val: 0.671654	test: 0.675778

Epoch: 21
Loss: 0.18025332285196766
ROC train: 0.940772	val: 0.831885	test: 0.846122
PRC train: 0.817402	val: 0.635412	test: 0.691314

Epoch: 22
Loss: 0.1782299583099145
ROC train: 0.932305	val: 0.838570	test: 0.847920
PRC train: 0.805732	val: 0.605346	test: 0.654485

Epoch: 23
Loss: 0.16844787444268378
ROC train: 0.919005	val: 0.803476	test: 0.833198
PRC train: 0.779029	val: 0.594458	test: 0.672379

Epoch: 24
Loss: 0.16420530925144197
ROC train: 0.935930	val: 0.843583	test: 0.837257
PRC train: 0.810902	val: 0.621880	test: 0.684482

Epoch: 25
Loss: 0.16625355639959377
ROC train: 0.952531	val: 0.835896	test: 0.877679
PRC train: 0.843789	val: 0.646076	test: 0.709196

Epoch: 26
Loss: 0.1610318478533949
ROC train: 0.953617	val: 0.827540	test: 0.880845
PRC train: 0.845208	val: 0.653938	test: 0.698206

Epoch: 27
Loss: 0.1597515017054366
ROC train: 0.956364	val: 0.820187	test: 0.891238
PRC train: 0.848301	val: 0.663366	test: 0.652986

Epoch: 28
Loss: 0.16486296830010122
ROC train: 0.958623	val: 0.828877	test: 0.902532
PRC train: 0.867365	val: 0.655522	test: 0.718979

Epoch: 29
Loss: 0.16511544061626343
ROC train: 0.959964	val: 0.832219	test: 0.911566
PRC train: 0.865389	val: 0.672732	test: 0.736856

Epoch: 30
Loss: 0.15053197604797308
ROC train: 0.959982	val: 0.838904	test: 0.905065
PRC train: 0.865962	val: 0.678758	test: 0.721761

Epoch: 31
Loss: 0.15656784964214426
ROC train: 0.959215	val: 0.834893	test: 0.906935
PRC train: 0.861766	val: 0.671694	test: 0.681912

Epoch: 32
Loss: 0.15323495179436003
ROC train: 0.961582	val: 0.828877	test: 0.895910
PRC train: 0.862231	val: 0.665770	test: 0.676292

Epoch: 33
Loss: 0.1384877092941203Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/clintox/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: clintox
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/clintox/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/clintox/random/train_prop=0.8/clintox_random_4_26-05_09-45-23  ]
[ Using Seed :  4  ]
[ Using device :  cuda:2  ]
Dataset: clintox
Data: Data(edge_attr=[82372, 2], edge_index=[2, 82372], id=[1477], x=[38637, 2], y=[2954])
MoleculeDataset(1477)
randomly split
Data(edge_attr=[48, 2], edge_index=[2, 48], id=[1], x=[21, 2], y=[2])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=2, bias=True)
)
Epoch: 1
Loss: 0.6668288173687262
ROC train: 0.569392	val: 0.502005	test: 0.535072
PRC train: 0.522268	val: 0.506946	test: 0.517211

Epoch: 2
Loss: 0.5833024773943156
ROC train: 0.593320	val: 0.535094	test: 0.601009
PRC train: 0.530512	val: 0.513381	test: 0.528373

Epoch: 3
Loss: 0.5182498444475313
ROC train: 0.623269	val: 0.577206	test: 0.663176
PRC train: 0.540624	val: 0.522460	test: 0.543633

Epoch: 4
Loss: 0.4599557888572539
ROC train: 0.682523	val: 0.627674	test: 0.697841
PRC train: 0.558908	val: 0.532619	test: 0.555179

Epoch: 5
Loss: 0.41149029371216317
ROC train: 0.743295	val: 0.710561	test: 0.770681
PRC train: 0.584467	val: 0.549419	test: 0.580696

Epoch: 6
Loss: 0.3733813471988861
ROC train: 0.755276	val: 0.708222	test: 0.763309
PRC train: 0.587650	val: 0.547479	test: 0.577207

Epoch: 7
Loss: 0.3383364376411525
ROC train: 0.787660	val: 0.783757	test: 0.814454
PRC train: 0.604020	val: 0.569230	test: 0.599386

Epoch: 8
Loss: 0.3080303375855139
ROC train: 0.795172	val: 0.800468	test: 0.829792
PRC train: 0.617970	val: 0.578806	test: 0.606638

Epoch: 9
Loss: 0.28640142200315427
ROC train: 0.810573	val: 0.776738	test: 0.820504
PRC train: 0.621732	val: 0.570167	test: 0.602895

Epoch: 10
Loss: 0.27199002594038096
ROC train: 0.829646	val: 0.762701	test: 0.819369
PRC train: 0.639524	val: 0.564071	test: 0.606248

Epoch: 11
Loss: 0.2491103438410022
ROC train: 0.865427	val: 0.802139	test: 0.851154
PRC train: 0.672341	val: 0.588710	test: 0.662679

Epoch: 12
Loss: 0.2462054875070832
ROC train: 0.879936	val: 0.804813	test: 0.839586
PRC train: 0.681418	val: 0.591373	test: 0.651821

Epoch: 13
Loss: 0.22721857129608525
ROC train: 0.891301	val: 0.802807	test: 0.845459
PRC train: 0.672877	val: 0.596910	test: 0.652047

Epoch: 14
Loss: 0.21611981023075946
ROC train: 0.906848	val: 0.831551	test: 0.850460
PRC train: 0.706467	val: 0.616705	test: 0.647413

Epoch: 15
Loss: 0.22090204242176958
ROC train: 0.918729	val: 0.831885	test: 0.855163
PRC train: 0.742300	val: 0.621576	test: 0.698285

Epoch: 16
Loss: 0.20825657017173055
ROC train: 0.920483	val: 0.835561	test: 0.854564
PRC train: 0.750419	val: 0.613454	test: 0.641596

Epoch: 17
Loss: 0.19359865421420758
ROC train: 0.918090	val: 0.836564	test: 0.848631
PRC train: 0.761092	val: 0.604384	test: 0.643693

Epoch: 18
Loss: 0.19857992005263675
ROC train: 0.933304	val: 0.825201	test: 0.850172
PRC train: 0.779156	val: 0.603943	test: 0.648320

Epoch: 19
Loss: 0.18488211104834115
ROC train: 0.942479	val: 0.829545	test: 0.869035
PRC train: 0.783135	val: 0.629067	test: 0.675363

Epoch: 20
Loss: 0.18965917954948872
ROC train: 0.932498	val: 0.810829	test: 0.882640
PRC train: 0.759837	val: 0.608720	test: 0.665351

Epoch: 21
Loss: 0.18447197827290596
ROC train: 0.940380	val: 0.848596	test: 0.885857
PRC train: 0.793523	val: 0.629317	test: 0.691632

Epoch: 22
Loss: 0.17394164158933784
ROC train: 0.947284	val: 0.866979	test: 0.889171
PRC train: 0.793617	val: 0.656244	test: 0.658714

Epoch: 23
Loss: 0.17131505560315735
ROC train: 0.948164	val: 0.837233	test: 0.887493
PRC train: 0.803955	val: 0.641305	test: 0.655352

Epoch: 24
Loss: 0.16961369755308103
ROC train: 0.952104	val: 0.820521	test: 0.887853
PRC train: 0.810602	val: 0.624407	test: 0.656719

Epoch: 25
Loss: 0.16725676547211163
ROC train: 0.954479	val: 0.819853	test: 0.902907
PRC train: 0.822873	val: 0.627095	test: 0.674715

Epoch: 26
Loss: 0.1550391992609264
ROC train: 0.959596	val: 0.804479	test: 0.888365
PRC train: 0.849023	val: 0.630603	test: 0.655426

Epoch: 27
Loss: 0.15899995603533754
ROC train: 0.957951	val: 0.812834	test: 0.876184
PRC train: 0.832288	val: 0.635336	test: 0.633287

Epoch: 28
Loss: 0.1535995384154062
ROC train: 0.960871	val: 0.814171	test: 0.885548
PRC train: 0.851386	val: 0.636742	test: 0.636376

Epoch: 29
Loss: 0.1558024816040204
ROC train: 0.969055	val: 0.818182	test: 0.895520
PRC train: 0.869901	val: 0.631925	test: 0.645426

Epoch: 30
Loss: 0.15710020482824452
ROC train: 0.960680	val: 0.803142	test: 0.895789
PRC train: 0.849638	val: 0.610055	test: 0.643235

Epoch: 31
Loss: 0.14498535033729273
ROC train: 0.965309	val: 0.784091	test: 0.918888
PRC train: 0.850140	val: 0.598996	test: 0.665502

Epoch: 32
Loss: 0.14276763099939543
ROC train: 0.973425	val: 0.788436	test: 0.906186
PRC train: 0.873506	val: 0.615114	test: 0.658093

Epoch: 33
Loss: 0.14057274570464612
ROC train: 0.962621	val: 0.737649	test: 0.842113
PRC train: 0.864246	val: 0.561414	test: 0.653395

Epoch: 34
Loss: 0.1614735833606309
ROC train: 0.967541	val: 0.730296	test: 0.826722
PRC train: 0.874838	val: 0.559313	test: 0.642793

Epoch: 35
Loss: 0.14266150092062108
ROC train: 0.967286	val: 0.720529	test: 0.809157
PRC train: 0.874178	val: 0.556890	test: 0.628109

Epoch: 36
Loss: 0.13886807732955891
ROC train: 0.962513	val: 0.737478	test: 0.798453
PRC train: 0.853398	val: 0.561676	test: 0.605775

Epoch: 37
Loss: 0.1357159906302393
ROC train: 0.969988	val: 0.741243	test: 0.817549
PRC train: 0.876303	val: 0.564627	test: 0.613166

Epoch: 38
Loss: 0.13131204133686197
ROC train: 0.971788	val: 0.746490	test: 0.835219
PRC train: 0.879829	val: 0.568148	test: 0.623561

Epoch: 39
Loss: 0.139693944384694
ROC train: 0.974103	val: 0.728528	test: 0.845547
PRC train: 0.884058	val: 0.563630	test: 0.630194

Epoch: 40
Loss: 0.14052027573944498
ROC train: 0.976058	val: 0.743913	test: 0.841747
PRC train: 0.880181	val: 0.570419	test: 0.623895

Epoch: 41
Loss: 0.12004880267341053
ROC train: 0.972722	val: 0.762593	test: 0.821453
PRC train: 0.866828	val: 0.576116	test: 0.607290

Epoch: 42
Loss: 0.12956100919038852
ROC train: 0.975170	val: 0.752021	test: 0.831056
PRC train: 0.881400	val: 0.575922	test: 0.611441

Epoch: 43
Loss: 0.12969703717811404
ROC train: 0.977833	val: 0.742851	test: 0.835470
PRC train: 0.899786	val: 0.570479	test: 0.617918

Epoch: 44
Loss: 0.1239117122106283
ROC train: 0.975087	val: 0.744999	test: 0.815104
PRC train: 0.892089	val: 0.569705	test: 0.605182

Epoch: 45
Loss: 0.12886872086342324
ROC train: 0.977467	val: 0.728609	test: 0.793125
PRC train: 0.897221	val: 0.569642	test: 0.600089

Epoch: 46
Loss: 0.12705061074868193
ROC train: 0.980759	val: 0.710607	test: 0.785791
PRC train: 0.907630	val: 0.568534	test: 0.606125

Epoch: 47
Loss: 0.13104686113895214
ROC train: 0.978822	val: 0.707758	test: 0.798167
PRC train: 0.908120	val: 0.564606	test: 0.614633

Epoch: 48
Loss: 0.14052438080225108
ROC train: 0.979654	val: 0.714979	test: 0.826388
PRC train: 0.915551	val: 0.569494	test: 0.638441

Epoch: 49
Loss: 0.12156074971086553
ROC train: 0.979798	val: 0.743218	test: 0.821396
PRC train: 0.906581	val: 0.577545	test: 0.635785

Epoch: 50
Loss: 0.1094216037883957
ROC train: 0.976073	val: 0.760783	test: 0.811332
PRC train: 0.889057	val: 0.585735	test: 0.624950

Epoch: 51
Loss: 0.12937373397375293
ROC train: 0.978048	val: 0.755514	test: 0.824069
PRC train: 0.900635	val: 0.584847	test: 0.625022

Epoch: 52
Loss: 0.11327802778754323
ROC train: 0.982096	val: 0.732871	test: 0.829518
PRC train: 0.914865	val: 0.576206	test: 0.638682

Epoch: 53
Loss: 0.10886089933894924
ROC train: 0.982279	val: 0.718553	test: 0.838544
PRC train: 0.914827	val: 0.570715	test: 0.627882

Epoch: 54
Loss: 0.11820942809857243
ROC train: 0.983170	val: 0.706069	test: 0.853129
PRC train: 0.924324	val: 0.563173	test: 0.637615

Epoch: 55
Loss: 0.12439419408921956
ROC train: 0.984115	val: 0.722290	test: 0.846900
PRC train: 0.923133	val: 0.564037	test: 0.629393

Epoch: 56
Loss: 0.11620132954114593
ROC train: 0.983638	val: 0.732563	test: 0.846517
PRC train: 0.920310	val: 0.570018	test: 0.633506

Epoch: 57
Loss: 0.10390492857960568
ROC train: 0.983958	val: 0.731452	test: 0.852090
PRC train: 0.919363	val: 0.569910	test: 0.645860

Epoch: 58
Loss: 0.12147197121636535
ROC train: 0.983014	val: 0.745530	test: 0.836764
PRC train: 0.911804	val: 0.572032	test: 0.627835

Epoch: 59
Loss: 0.113931249868434
ROC train: 0.983241	val: 0.732612	test: 0.838719
PRC train: 0.909697	val: 0.566028	test: 0.629761

Epoch: 60
Loss: 0.10901683225954366
ROC train: 0.985785	val: 0.735236	test: 0.825519
PRC train: 0.919820	val: 0.567615	test: 0.629594

Epoch: 61
Loss: 0.10728891086033253
ROC train: 0.984027	val: 0.744066	test: 0.805838
PRC train: 0.912445	val: 0.572552	test: 0.616290

Epoch: 62
Loss: 0.10110660479325304
ROC train: 0.982558	val: 0.748626	test: 0.804325
PRC train: 0.911603	val: 0.570930	test: 0.617726

Epoch: 63
Loss: 0.12312439834028366
ROC train: 0.979898	val: 0.754701	test: 0.813985
PRC train: 0.908735	val: 0.578732	test: 0.624370

Epoch: 64
Loss: 0.09861154885805672
ROC train: 0.985499	val: 0.753767	test: 0.834395
PRC train: 0.929651	val: 0.595699	test: 0.642101

Epoch: 65
Loss: 0.11945354050392415
ROC train: 0.986834	val: 0.762311	test: 0.827905
PRC train: 0.930030	val: 0.597463	test: 0.633981

Epoch: 66
Loss: 0.10007285858476192
ROC train: 0.986488	val: 0.780645	test: 0.815793
PRC train: 0.927065	val: 0.599022	test: 0.634967

Epoch: 67
Loss: 0.11321849500818602
ROC train: 0.986305	val: 0.775023	test: 0.818228
PRC train: 0.927500	val: 0.587270	test: 0.627185

Epoch: 68
Loss: 0.09159418975656394
ROC train: 0.987827	val: 0.742566	test: 0.822866
PRC train: 0.934766	val: 0.574114	test: 0.638699

Epoch: 69
Loss: 0.10422113541004607
ROC train: 0.988498	val: 0.758735	test: 0.822841
PRC train: 0.932556	val: 0.588897	test: 0.640017

Epoch: 70
Loss: 0.10499847323672494
ROC train: 0.987779	val: 0.760209	test: 0.813214
PRC train: 0.928225	val: 0.592644	test: 0.631231

Epoch: 71
Loss: 0.10025093589158708
ROC train: 0.987884	val: 0.745568	test: 0.815268
PRC train: 0.934178	val: 0.584987	test: 0.629760

Epoch: 72
Loss: 0.09015978088962218
ROC train: 0.988118	val: 0.752127	test: 0.803868
PRC train: 0.934731	val: 0.590081	test: 0.627556

Epoch: 73
Loss: 0.09996610028314815
ROC train: 0.988354	val: 0.761395	test: 0.803415
PRC train: 0.935405	val: 0.604243	test: 0.630481

Epoch: 74
Loss: 0.10977337555577849
ROC train: 0.989986	val: 0.776903	test: 0.817127
PRC train: 0.940645	val: 0.602824	test: 0.630660

Epoch: 75
Loss: 0.09873294824115274
ROC train: 0.990369	val: 0.774332	test: 0.834556
PRC train: 0.943879	val: 0.591519	test: 0.639275

Epoch: 76
Loss: 0.121283678375803
ROC train: 0.988867	val: 0.769227	test: 0.820134
PRC train: 0.931005	val: 0.595910	test: 0.621643

Epoch: 77
Loss: 0.10092622942941532
ROC train: 0.989689	val: 0.753927	test: 0.821824
PRC train: 0.937072	val: 0.589598	test: 0.629104

Epoch: 78
Loss: 0.08507820804958294
ROC train: 0.990337	val: 0.737717	test: 0.837990
PRC train: 0.944873	val: 0.574369	test: 0.647069

Epoch: 79
Loss: 0.09758297269564492
ROC train: 0.990212	val: 0.755875	test: 0.838849
PRC train: 0.944131	val: 0.579423	test: 0.636636

Epoch: 80
Loss: 0.08963324602599228
ROC train: 0.990595	val: 0.764928	test: 0.830989
PRC train: 0.945617	val: 0.586978	test: 0.631417

Epoch: 81
Loss: 0.09191262454508495
ROC train: 0.989576	val: 0.759532	test: 0.826935
PRC train: 0.941408	val: 0.583331	test: 0.628615

Epoch: 82
Loss: 0.0998335489292692
ROC train: 0.987704	val: 0.743913	test: 0.827658
PRC train: 0.936399	val: 0.576651	test: 0.635690

Epoch: 83
Loss: 0.08670674476689902
ROC train: 0.987067	val: 0.733950	test: 0.843473
PRC train: 0.934228	val: 0.572896	test: 0.647295

Epoch: 84
Loss: 0.08526647524299577
ROC train: 0.991025	val: 0.748192	test: 0.850028
PRC train: 0.943391	val: 0.588107	test: 0.644633

Epoch: 85
Loss: 0.08154710270284705
ROC train: 0.990923	val: 0.747858	test: 0.845700
PRC train: 0.943381	val: 0.598748	test: 0.637702

Epoch: 86
Loss: 0.09464783134338223
ROC train: 0.990333	val: 0.735818	test: 0.844798
PRC train: 0.941569	val: 0.590499	test: 0.644308

Epoch: 87
Loss: 0.08776514918294165
ROC train: 0.990761	val: 0.734180	test: 0.820329
PRC train: 0.943010	val: 0.582435	test: 0.627089

Epoch: 88
Loss: 0.09269297561711344
ROC train: 0.991704	val: 0.741453	test: 0.801206
PRC train: 0.951471	val: 0.578813	test: 0.617564

Epoch: 89
Loss: 0.10938857946395
ROC train: 0.992230	val: 0.755150	test: 0.796169
PRC train: 0.950989	val: 0.577518	test: 0.609435

Epoch: 90
Loss: 0.0908731365079148
ROC train: 0.991950	val: 0.760302	test: 0.806864
PRC train: 0.947858	val: 0.580491	test: 0.616533

Epoch: 91
Loss: 0.08485862770669618
ROC train: 0.992309	val: 0.758308	test: 0.822708
PRC train: 0.950069	val: 0.581454	test: 0.655674

Epoch: 92
Loss: 0.08993287837121056
ROC train: 0.992422	val: 0.751307	test: 0.804260
PRC train: 0.949748	val: 0.578691	test: 0.636797

Epoch: 93
Loss: 0.07652189927390048
ROC train: 0.991502	val: 0.741582	test: 0.786880
PRC train: 0.942913	val: 0.574945	test: 0.625795

Epoch: 94
Loss: 0.08348703838733643
ROC train: 0.972345	val: 0.702113	test: 0.794686
PRC train: 0.875830	val: 0.566388	test: 0.619154

Epoch: 34
Loss: 0.1414922112054874
ROC train: 0.972822	val: 0.717458	test: 0.808676
PRC train: 0.878399	val: 0.566406	test: 0.644223

Epoch: 35
Loss: 0.14295036368416789
ROC train: 0.973819	val: 0.736565	test: 0.814848
PRC train: 0.882661	val: 0.567748	test: 0.623402

Epoch: 36
Loss: 0.13116252911200887
ROC train: 0.971391	val: 0.727429	test: 0.823686
PRC train: 0.877873	val: 0.564228	test: 0.624347

Epoch: 37
Loss: 0.13692855232429973
ROC train: 0.965726	val: 0.733683	test: 0.811093
PRC train: 0.867574	val: 0.565473	test: 0.617608

Epoch: 38
Loss: 0.13079833358414378
ROC train: 0.965902	val: 0.743839	test: 0.800299
PRC train: 0.864058	val: 0.565518	test: 0.606357

Epoch: 39
Loss: 0.14141804883220527
ROC train: 0.967877	val: 0.726398	test: 0.825291
PRC train: 0.854486	val: 0.557651	test: 0.612978

Epoch: 40
Loss: 0.1567444321822992
ROC train: 0.966871	val: 0.690071	test: 0.847638
PRC train: 0.870139	val: 0.555214	test: 0.644563

Epoch: 41
Loss: 0.1288034950404171
ROC train: 0.971434	val: 0.671683	test: 0.845241
PRC train: 0.887910	val: 0.553266	test: 0.636396

Epoch: 42
Loss: 0.14714548514711756
ROC train: 0.975410	val: 0.714105	test: 0.813895
PRC train: 0.897003	val: 0.565578	test: 0.622403

Epoch: 43
Loss: 0.1264646687196565
ROC train: 0.978734	val: 0.718938	test: 0.812065
PRC train: 0.904115	val: 0.566880	test: 0.618115

Epoch: 44
Loss: 0.13370942324412682
ROC train: 0.968618	val: 0.721405	test: 0.803584
PRC train: 0.880142	val: 0.578190	test: 0.617129

Epoch: 45
Loss: 0.12815753187653892
ROC train: 0.976743	val: 0.718186	test: 0.828564
PRC train: 0.894136	val: 0.579665	test: 0.648191

Epoch: 46
Loss: 0.12139533728337126
ROC train: 0.977271	val: 0.715379	test: 0.831937
PRC train: 0.894755	val: 0.559150	test: 0.634944

Epoch: 47
Loss: 0.12518110626503143
ROC train: 0.979389	val: 0.729469	test: 0.827610
PRC train: 0.900328	val: 0.559953	test: 0.634960

Epoch: 48
Loss: 0.11497876070562885
ROC train: 0.981722	val: 0.735527	test: 0.814526
PRC train: 0.909224	val: 0.564981	test: 0.630568

Epoch: 49
Loss: 0.11649435736030503
ROC train: 0.980719	val: 0.742160	test: 0.816762
PRC train: 0.897498	val: 0.571292	test: 0.620377

Epoch: 50
Loss: 0.1262223710823453
ROC train: 0.983088	val: 0.734800	test: 0.805384
PRC train: 0.912811	val: 0.566330	test: 0.617395

Epoch: 51
Loss: 0.11590821823420523
ROC train: 0.984273	val: 0.717292	test: 0.791372
PRC train: 0.921786	val: 0.561737	test: 0.610437

Epoch: 52
Loss: 0.09749494194146868
ROC train: 0.985707	val: 0.730149	test: 0.787778
PRC train: 0.926453	val: 0.573875	test: 0.608794

Epoch: 53
Loss: 0.11308107785899335
ROC train: 0.984372	val: 0.721017	test: 0.779583
PRC train: 0.917752	val: 0.567600	test: 0.605741

Epoch: 54
Loss: 0.11831927895273792
ROC train: 0.983062	val: 0.725830	test: 0.812022
PRC train: 0.910751	val: 0.569437	test: 0.619641

Epoch: 55
Loss: 0.10989102163248438
ROC train: 0.986230	val: 0.749579	test: 0.845436
PRC train: 0.928040	val: 0.571946	test: 0.632700

Epoch: 56
Loss: 0.10255170143236234
ROC train: 0.987286	val: 0.772770	test: 0.817440
PRC train: 0.926819	val: 0.584740	test: 0.631897

Epoch: 57
Loss: 0.12185495357282045
ROC train: 0.987091	val: 0.765831	test: 0.798401
PRC train: 0.923626	val: 0.581238	test: 0.625437

Epoch: 58
Loss: 0.12151943697019946
ROC train: 0.988031	val: 0.753314	test: 0.795865
PRC train: 0.928373	val: 0.573814	test: 0.627320

Epoch: 59
Loss: 0.10851325920736787
ROC train: 0.984673	val: 0.723367	test: 0.796794
PRC train: 0.920817	val: 0.558606	test: 0.625877

Epoch: 60
Loss: 0.11747880248236006
ROC train: 0.985611	val: 0.728154	test: 0.780346
PRC train: 0.918983	val: 0.561574	test: 0.607998

Epoch: 61
Loss: 0.10870169207328215
ROC train: 0.987654	val: 0.727642	test: 0.795172
PRC train: 0.931457	val: 0.563337	test: 0.615895

Epoch: 62
Loss: 0.113617008034726
ROC train: 0.986864	val: 0.712803	test: 0.820054
PRC train: 0.936821	val: 0.560674	test: 0.631531

Epoch: 63
Loss: 0.09297880691342364
ROC train: 0.987376	val: 0.719173	test: 0.817811
PRC train: 0.935526	val: 0.564569	test: 0.638736

Epoch: 64
Loss: 0.09697436674667352
ROC train: 0.987055	val: 0.708613	test: 0.804455
PRC train: 0.934245	val: 0.566694	test: 0.630489

Epoch: 65
Loss: 0.11479833628382938
ROC train: 0.986741	val: 0.676902	test: 0.810201
PRC train: 0.938600	val: 0.560813	test: 0.638708

Epoch: 66
Loss: 0.1200551762408561
ROC train: 0.987126	val: 0.671949	test: 0.819113
PRC train: 0.937412	val: 0.556776	test: 0.647399

Epoch: 67
Loss: 0.1069169139390669
ROC train: 0.986337	val: 0.706275	test: 0.821070
PRC train: 0.933615	val: 0.558062	test: 0.647948

Epoch: 68
Loss: 0.09714039659256958
ROC train: 0.989152	val: 0.742179	test: 0.822786
PRC train: 0.942406	val: 0.571011	test: 0.642711

Epoch: 69
Loss: 0.11127372048980372
ROC train: 0.989553	val: 0.745049	test: 0.810636
PRC train: 0.939145	val: 0.571350	test: 0.639588

Epoch: 70
Loss: 0.11163630161098656
ROC train: 0.985863	val: 0.733367	test: 0.822851
PRC train: 0.925917	val: 0.573269	test: 0.644804

Epoch: 71
Loss: 0.09861433549982798
ROC train: 0.980521	val: 0.732563	test: 0.812251
PRC train: 0.906902	val: 0.573693	test: 0.629479

Epoch: 72
Loss: 0.09738151740090872
ROC train: 0.985105	val: 0.713022	test: 0.834211
PRC train: 0.930954	val: 0.566865	test: 0.651988

Epoch: 73
Loss: 0.09690701971656715
ROC train: 0.985979	val: 0.707077	test: 0.833065
PRC train: 0.939474	val: 0.566245	test: 0.652693

Epoch: 74
Loss: 0.09748443796195891
ROC train: 0.989816	val: 0.717667	test: 0.822978
PRC train: 0.945205	val: 0.570820	test: 0.638519

Epoch: 75
Loss: 0.10467080851590825
ROC train: 0.990092	val: 0.715831	test: 0.816382
PRC train: 0.946062	val: 0.566380	test: 0.627027

Epoch: 76
Loss: 0.10260029194181614
ROC train: 0.988685	val: 0.707154	test: 0.823870
PRC train: 0.947725	val: 0.567156	test: 0.635978

Epoch: 77
Loss: 0.10029967742705446
ROC train: 0.988544	val: 0.706565	test: 0.820313
PRC train: 0.943052	val: 0.563416	test: 0.639412

Epoch: 78
Loss: 0.10350256039724003
ROC train: 0.989474	val: 0.711766	test: 0.813474
PRC train: 0.943410	val: 0.565859	test: 0.630582

Epoch: 79
Loss: 0.09663117130441001
ROC train: 0.990336	val: 0.714960	test: 0.796538
PRC train: 0.948790	val: 0.566267	test: 0.604630

Epoch: 80
Loss: 0.10175149132330844
ROC train: 0.990187	val: 0.714159	test: 0.774825
PRC train: 0.944785	val: 0.566594	test: 0.591320

Epoch: 81
Loss: 0.09215394444167734
ROC train: 0.991235	val: 0.719203	test: 0.797115
PRC train: 0.948022	val: 0.570593	test: 0.605205

Epoch: 82
Loss: 0.10298304187463982
ROC train: 0.991920	val: 0.723269	test: 0.829399
PRC train: 0.956682	val: 0.573250	test: 0.642939

Epoch: 83
Loss: 0.09332229699781519
ROC train: 0.991486	val: 0.726888	test: 0.829811
PRC train: 0.954010	val: 0.580049	test: 0.642851

Epoch: 84
Loss: 0.10048985506903843
ROC train: 0.991964	val: 0.726692	test: 0.822283
PRC train: 0.954213	val: 0.581581	test: 0.640785

Epoch: 85
Loss: 0.0927219906940984
ROC train: 0.991574	val: 0.724529	test: 0.842201
PRC train: 0.951766	val: 0.581298	test: 0.654054

Epoch: 86
Loss: 0.08188014257200828
ROC train: 0.991327	val: 0.733421	test: 0.848111
PRC train: 0.950455	val: 0.585544	test: 0.654504

Epoch: 87
Loss: 0.09161338229294165
ROC train: 0.991132	val: 0.733723	test: 0.845381
PRC train: 0.951325	val: 0.577715	test: 0.658329

Epoch: 88
Loss: 0.08980887510052027
ROC train: 0.992857	val: 0.736013	test: 0.837741
PRC train: 0.959424	val: 0.576980	test: 0.647379

Epoch: 89
Loss: 0.09977309063243708
ROC train: 0.992507	val: 0.727889	test: 0.818681
PRC train: 0.954101	val: 0.579339	test: 0.642472

Epoch: 90
Loss: 0.08275767876722633
ROC train: 0.992877	val: 0.711639	test: 0.819808
PRC train: 0.955327	val: 0.574615	test: 0.641186

Epoch: 91
Loss: 0.09250613915529686
ROC train: 0.992690	val: 0.702393	test: 0.836892
PRC train: 0.956316	val: 0.571284	test: 0.647163

Epoch: 92
Loss: 0.08955485083401099
ROC train: 0.993406	val: 0.718494	test: 0.827756
PRC train: 0.959002	val: 0.573245	test: 0.638497

Epoch: 93
Loss: 0.08461742790611156
ROC train: 0.993191	val: 0.732415	test: 0.823839
PRC train: 0.959681	val: 0.580828	test: 0.638850

Epoch: 94
Loss: 0.08674557951085063
ROC train: 0.960032	val: 0.766382	test: 0.839298
PRC train: 0.855542	val: 0.579672	test: 0.648594

Epoch: 34
Loss: 0.1504577783273769
ROC train: 0.963921	val: 0.742749	test: 0.851947
PRC train: 0.860323	val: 0.572971	test: 0.661720

Epoch: 35
Loss: 0.14378203716603313
ROC train: 0.970109	val: 0.755807	test: 0.850922
PRC train: 0.869478	val: 0.570558	test: 0.649051

Epoch: 36
Loss: 0.14067159070672147
ROC train: 0.969920	val: 0.767988	test: 0.856083
PRC train: 0.873309	val: 0.570194	test: 0.637318

Epoch: 37
Loss: 0.14423602919433617
ROC train: 0.974633	val: 0.759808	test: 0.840923
PRC train: 0.884558	val: 0.571488	test: 0.635456

Epoch: 38
Loss: 0.14221895600401185
ROC train: 0.977009	val: 0.757016	test: 0.849991
PRC train: 0.888789	val: 0.569742	test: 0.656766

Epoch: 39
Loss: 0.1294784328908536
ROC train: 0.978892	val: 0.776127	test: 0.849286
PRC train: 0.890870	val: 0.580013	test: 0.644795

Epoch: 40
Loss: 0.1405464640671069
ROC train: 0.979124	val: 0.771298	test: 0.840865
PRC train: 0.890709	val: 0.576210	test: 0.637079

Epoch: 41
Loss: 0.13714955986909927
ROC train: 0.977875	val: 0.748296	test: 0.844043
PRC train: 0.891616	val: 0.565638	test: 0.651555

Epoch: 42
Loss: 0.12064477647665847
ROC train: 0.977514	val: 0.756695	test: 0.837816
PRC train: 0.895033	val: 0.566564	test: 0.645140

Epoch: 43
Loss: 0.1232678338577378
ROC train: 0.976694	val: 0.752715	test: 0.836325
PRC train: 0.892748	val: 0.566092	test: 0.655791

Epoch: 44
Loss: 0.1293749533222975
ROC train: 0.978464	val: 0.757931	test: 0.844584
PRC train: 0.896358	val: 0.573241	test: 0.656516

Epoch: 45
Loss: 0.13209587472445738
ROC train: 0.978419	val: 0.739417	test: 0.848835
PRC train: 0.898421	val: 0.572961	test: 0.671428

Epoch: 46
Loss: 0.1294135971702649
ROC train: 0.980321	val: 0.747338	test: 0.849286
PRC train: 0.908316	val: 0.569250	test: 0.653069

Epoch: 47
Loss: 0.10675457323166045
ROC train: 0.981194	val: 0.746316	test: 0.847765
PRC train: 0.907786	val: 0.567828	test: 0.642736

Epoch: 48
Loss: 0.11954410395781578
ROC train: 0.984092	val: 0.772186	test: 0.837565
PRC train: 0.915399	val: 0.575502	test: 0.643278

Epoch: 49
Loss: 0.11840393733922519
ROC train: 0.985055	val: 0.763515	test: 0.840439
PRC train: 0.918991	val: 0.570345	test: 0.643748

Epoch: 50
Loss: 0.12799336863911928
ROC train: 0.984457	val: 0.749633	test: 0.840405
PRC train: 0.918381	val: 0.567111	test: 0.642995

Epoch: 51
Loss: 0.109587328892997
ROC train: 0.982372	val: 0.765309	test: 0.809821
PRC train: 0.903152	val: 0.572562	test: 0.614258

Epoch: 52
Loss: 0.11275343141963476
ROC train: 0.985745	val: 0.764675	test: 0.818664
PRC train: 0.908387	val: 0.572965	test: 0.619310

Epoch: 53
Loss: 0.10520384437753685
ROC train: 0.985014	val: 0.748243	test: 0.821792
PRC train: 0.911909	val: 0.563554	test: 0.629723

Epoch: 54
Loss: 0.11617300973455053
ROC train: 0.986287	val: 0.756191	test: 0.816548
PRC train: 0.926720	val: 0.568589	test: 0.620185

Epoch: 55
Loss: 0.10460550431377329
ROC train: 0.987113	val: 0.759363	test: 0.833551
PRC train: 0.930385	val: 0.569229	test: 0.635402

Epoch: 56
Loss: 0.11112928725031856
ROC train: 0.987979	val: 0.785305	test: 0.841944
PRC train: 0.934908	val: 0.579933	test: 0.644253

Epoch: 57
Loss: 0.11806490942582844
ROC train: 0.987853	val: 0.775496	test: 0.840393
PRC train: 0.938928	val: 0.583202	test: 0.656837

Epoch: 58
Loss: 0.09132828057049137
ROC train: 0.984240	val: 0.740430	test: 0.838888
PRC train: 0.929454	val: 0.574715	test: 0.654688

Epoch: 59
Loss: 0.10529834774675606
ROC train: 0.983172	val: 0.733097	test: 0.839166
PRC train: 0.922844	val: 0.571711	test: 0.658420

Epoch: 60
Loss: 0.10932842484669113
ROC train: 0.986761	val: 0.771980	test: 0.829422
PRC train: 0.920963	val: 0.586444	test: 0.640780

Epoch: 61
Loss: 0.11564261584591001
ROC train: 0.987617	val: 0.767131	test: 0.830759
PRC train: 0.925656	val: 0.590219	test: 0.637055

Epoch: 62
Loss: 0.10511537208662064
ROC train: 0.984413	val: 0.738467	test: 0.839738
PRC train: 0.926222	val: 0.577406	test: 0.660417

Epoch: 63
Loss: 0.10841331461753734
ROC train: 0.986048	val: 0.750306	test: 0.840296
PRC train: 0.929516	val: 0.580789	test: 0.630317

Epoch: 64
Loss: 0.10521811927451702
ROC train: 0.986888	val: 0.756865	test: 0.830016
PRC train: 0.932744	val: 0.577556	test: 0.621013

Epoch: 65
Loss: 0.10970548411327066
ROC train: 0.987505	val: 0.755516	test: 0.815629
PRC train: 0.930315	val: 0.585833	test: 0.608367

Epoch: 66
Loss: 0.11351722947244919
ROC train: 0.987372	val: 0.737295	test: 0.828035
PRC train: 0.924934	val: 0.591099	test: 0.630917

Epoch: 67
Loss: 0.10402642396397703
ROC train: 0.986702	val: 0.716192	test: 0.836417
PRC train: 0.931788	val: 0.581336	test: 0.647429

Epoch: 68
Loss: 0.1047094787289875
ROC train: 0.989345	val: 0.725676	test: 0.846447
PRC train: 0.940156	val: 0.580839	test: 0.644707

Epoch: 69
Loss: 0.11893771904525133
ROC train: 0.989812	val: 0.744748	test: 0.845334
PRC train: 0.938664	val: 0.579429	test: 0.640622

Epoch: 70
Loss: 0.09664855900444991
ROC train: 0.989763	val: 0.739849	test: 0.835527
PRC train: 0.941459	val: 0.575783	test: 0.634533

Epoch: 71
Loss: 0.10611067447240854
ROC train: 0.990071	val: 0.731018	test: 0.843420
PRC train: 0.946380	val: 0.571325	test: 0.648225

Epoch: 72
Loss: 0.10468898107046237
ROC train: 0.988613	val: 0.722813	test: 0.855873
PRC train: 0.942831	val: 0.571441	test: 0.657759

Epoch: 73
Loss: 0.08876998664703203
ROC train: 0.990465	val: 0.740248	test: 0.860127
PRC train: 0.947064	val: 0.577612	test: 0.642872

Epoch: 74
Loss: 0.10423984886099158
ROC train: 0.989634	val: 0.754766	test: 0.851108
PRC train: 0.939809	val: 0.582678	test: 0.632106

Epoch: 75
Loss: 0.1052272539872561
ROC train: 0.991092	val: 0.737978	test: 0.844670
PRC train: 0.949402	val: 0.572320	test: 0.634264

Epoch: 76
Loss: 0.08039417100515416
ROC train: 0.990830	val: 0.705390	test: 0.831707
PRC train: 0.947839	val: 0.566496	test: 0.635467

Epoch: 77
Loss: 0.09828604827122465
ROC train: 0.991811	val: 0.715708	test: 0.825000
PRC train: 0.951363	val: 0.567596	test: 0.626664

Epoch: 78
Loss: 0.08797369662910823
ROC train: 0.991311	val: 0.723280	test: 0.820056
PRC train: 0.951581	val: 0.568552	test: 0.627250

Epoch: 79
Loss: 0.09381590277710511
ROC train: 0.991901	val: 0.732843	test: 0.841500
PRC train: 0.952203	val: 0.570203	test: 0.641863

Epoch: 80
Loss: 0.0911589549698851
ROC train: 0.991875	val: 0.750382	test: 0.833405
PRC train: 0.952561	val: 0.572642	test: 0.632571

Epoch: 81
Loss: 0.08986387634657265
ROC train: 0.992639	val: 0.754026	test: 0.825234
PRC train: 0.954367	val: 0.580501	test: 0.616533

Epoch: 82
Loss: 0.1081245460577462
ROC train: 0.990997	val: 0.750631	test: 0.837828
PRC train: 0.950577	val: 0.576980	test: 0.623756

Epoch: 83
Loss: 0.10367962666141743
ROC train: 0.990952	val: 0.742889	test: 0.837771
PRC train: 0.949259	val: 0.571922	test: 0.624523

Epoch: 84
Loss: 0.09983462628116381
ROC train: 0.990746	val: 0.731823	test: 0.840375
PRC train: 0.948646	val: 0.569246	test: 0.624029

Epoch: 85
Loss: 0.08870574276006803
ROC train: 0.991963	val: 0.725743	test: 0.832613
PRC train: 0.949249	val: 0.568352	test: 0.615924

Epoch: 86
Loss: 0.08494976732275754
ROC train: 0.992417	val: 0.713422	test: 0.854797
PRC train: 0.955185	val: 0.565065	test: 0.633897

Epoch: 87
Loss: 0.11245475548532627
ROC train: 0.989361	val: 0.690269	test: 0.863474
PRC train: 0.943144	val: 0.554530	test: 0.652031

Epoch: 88
Loss: 0.09823752898583507
ROC train: 0.991078	val: 0.700022	test: 0.846892
PRC train: 0.947388	val: 0.563926	test: 0.644157

Epoch: 89
Loss: 0.09086237275363691
ROC train: 0.992594	val: 0.700938	test: 0.844072
PRC train: 0.956846	val: 0.563697	test: 0.641008

Epoch: 90
Loss: 0.09236278542818077
ROC train: 0.992739	val: 0.695441	test: 0.837990
PRC train: 0.956885	val: 0.562967	test: 0.641339

Epoch: 91
Loss: 0.0731115222337482
ROC train: 0.993329	val: 0.694490	test: 0.822648
PRC train: 0.958614	val: 0.564088	test: 0.623800

Epoch: 92
Loss: 0.08524443746592208
ROC train: 0.993613	val: 0.692936	test: 0.825965
PRC train: 0.960887	val: 0.562984	test: 0.626783

Epoch: 93
Loss: 0.07466316107729885
ROC train: 0.991784	val: 0.709387	test: 0.837767
PRC train: 0.956825	val: 0.564990	test: 0.639806

Epoch: 94
Loss: 0.08167396135799328
ROC train: 0.872892	val: 0.592230	test: 0.918810
PRC train: 0.693933	val: 0.542778	test: 0.733928

Epoch: 34
Loss: 0.22775268044578562
ROC train: 0.914977	val: 0.629015	test: 0.915766
PRC train: 0.745869	val: 0.556439	test: 0.708110

Epoch: 35
Loss: 0.16162219674561606
ROC train: 0.917483	val: 0.654134	test: 0.890002
PRC train: 0.761654	val: 0.562031	test: 0.646343

Epoch: 36
Loss: 0.15899337634671812
ROC train: 0.923088	val: 0.671416	test: 0.883517
PRC train: 0.751668	val: 0.564375	test: 0.640326

Epoch: 37
Loss: 0.25231930765198146
ROC train: 0.925252	val: 0.662446	test: 0.898898
PRC train: 0.765303	val: 0.568153	test: 0.679871

Epoch: 38
Loss: 0.1708249672121204
ROC train: 0.896485	val: 0.656236	test: 0.876851
PRC train: 0.710915	val: 0.557514	test: 0.693105

Epoch: 39
Loss: 0.2237407266313441
ROC train: 0.912282	val: 0.675072	test: 0.874214
PRC train: 0.733469	val: 0.559363	test: 0.682460

Epoch: 40
Loss: 0.16648390023495654
ROC train: 0.901495	val: 0.649604	test: 0.867942
PRC train: 0.721546	val: 0.552785	test: 0.648966

Epoch: 41
Loss: 0.17596192984424447
ROC train: 0.912376	val: 0.641542	test: 0.868593
PRC train: 0.751815	val: 0.555099	test: 0.634042

Epoch: 42
Loss: 0.15585289691005838
ROC train: 0.929408	val: 0.657818	test: 0.873165
PRC train: 0.779291	val: 0.562380	test: 0.643451

Epoch: 43
Loss: 0.14672917417727993
ROC train: 0.936637	val: 0.675757	test: 0.887249
PRC train: 0.794932	val: 0.571527	test: 0.649965

Epoch: 44
Loss: 0.17360999963665788
ROC train: 0.940674	val: 0.684186	test: 0.902520
PRC train: 0.798818	val: 0.569834	test: 0.666433

Epoch: 45
Loss: 0.14842518905785043
ROC train: 0.940594	val: 0.661096	test: 0.899978
PRC train: 0.800487	val: 0.562199	test: 0.649088

Epoch: 46
Loss: 0.1443209342587635
ROC train: 0.939519	val: 0.663957	test: 0.904283
PRC train: 0.804793	val: 0.559389	test: 0.662794

Epoch: 47
Loss: 0.1713086949131955
ROC train: 0.944137	val: 0.691649	test: 0.905939
PRC train: 0.813987	val: 0.570084	test: 0.661329

Epoch: 48
Loss: 0.16233215383458705
ROC train: 0.930084	val: 0.715060	test: 0.886658
PRC train: 0.789188	val: 0.587656	test: 0.642717

Epoch: 49
Loss: 0.24219434251193447
ROC train: 0.941951	val: 0.714697	test: 0.924109
PRC train: 0.819315	val: 0.585711	test: 0.671535

Epoch: 50
Loss: 0.15871778341156045
ROC train: 0.927294	val: 0.667231	test: 0.917625
PRC train: 0.796324	val: 0.560910	test: 0.669162

Epoch: 51
Loss: 0.1540850433265286
ROC train: 0.935039	val: 0.665543	test: 0.910757
PRC train: 0.809834	val: 0.556078	test: 0.660221

Epoch: 52
Loss: 0.17358358709462146
ROC train: 0.941716	val: 0.644373	test: 0.902147
PRC train: 0.807823	val: 0.562590	test: 0.654157

Epoch: 53
Loss: 0.13844169626995528
ROC train: 0.946158	val: 0.640024	test: 0.909448
PRC train: 0.810114	val: 0.563917	test: 0.662792

Epoch: 54
Loss: 0.18268711109499836
ROC train: 0.943037	val: 0.651672	test: 0.883997
PRC train: 0.810384	val: 0.575388	test: 0.637183

Epoch: 55
Loss: 0.14897747596752484
ROC train: 0.910181	val: 0.665199	test: 0.764863
PRC train: 0.759748	val: 0.578343	test: 0.576984

Epoch: 56
Loss: 0.14405267170929578
ROC train: 0.938663	val: 0.673061	test: 0.841879
PRC train: 0.804847	val: 0.604592	test: 0.609992

Epoch: 57
Loss: 0.13998703684515004
ROC train: 0.953999	val: 0.669590	test: 0.902201
PRC train: 0.827048	val: 0.585752	test: 0.662414

Epoch: 58
Loss: 0.13290733055548604
ROC train: 0.954992	val: 0.671603	test: 0.922480
PRC train: 0.829069	val: 0.573396	test: 0.691161

Epoch: 59
Loss: 0.12620328615614862
ROC train: 0.957732	val: 0.669493	test: 0.928093
PRC train: 0.844433	val: 0.568073	test: 0.680242

Epoch: 60
Loss: 0.2396997101053513
ROC train: 0.958099	val: 0.677337	test: 0.929119
PRC train: 0.854173	val: 0.567982	test: 0.677473

Epoch: 61
Loss: 0.12845058899493053
ROC train: 0.947085	val: 0.683912	test: 0.920925
PRC train: 0.837298	val: 0.567507	test: 0.682493

Epoch: 62
Loss: 0.1847591104792702
ROC train: 0.947821	val: 0.696379	test: 0.923116
PRC train: 0.820600	val: 0.569002	test: 0.697940

Epoch: 63
Loss: 0.1457292994147194
ROC train: 0.947920	val: 0.666635	test: 0.920489
PRC train: 0.828857	val: 0.559715	test: 0.697882

Epoch: 64
Loss: 0.1320285814591294
ROC train: 0.948206	val: 0.652713	test: 0.911013
PRC train: 0.833917	val: 0.563672	test: 0.699021

Epoch: 65
Loss: 0.13790825571060686
ROC train: 0.948384	val: 0.652965	test: 0.894777
PRC train: 0.836045	val: 0.567413	test: 0.678516

Epoch: 66
Loss: 0.20817352657921973
ROC train: 0.943871	val: 0.660748	test: 0.896010
PRC train: 0.818508	val: 0.557627	test: 0.677702

Epoch: 67
Loss: 0.16439394958637116
ROC train: 0.940052	val: 0.662018	test: 0.922592
PRC train: 0.818824	val: 0.554042	test: 0.691955

Epoch: 68
Loss: 0.13098623938889845
ROC train: 0.938476	val: 0.655067	test: 0.908759
PRC train: 0.801160	val: 0.550573	test: 0.655788

Epoch: 69
Loss: 0.18865364097714488
ROC train: 0.956066	val: 0.648365	test: 0.932585
PRC train: 0.839385	val: 0.550379	test: 0.691129

Epoch: 70
Loss: 0.1433635521043982
ROC train: 0.942507	val: 0.607708	test: 0.942301
PRC train: 0.807593	val: 0.543671	test: 0.747383

Epoch: 71
Loss: 0.16088123568904178
ROC train: 0.943380	val: 0.618247	test: 0.934396
PRC train: 0.806197	val: 0.554382	test: 0.720880

Epoch: 72
Loss: 0.14221030191389308
ROC train: 0.940226	val: 0.668433	test: 0.923938
PRC train: 0.803147	val: 0.573553	test: 0.689308

Epoch: 73
Loss: 0.13490448617822068
ROC train: 0.927536	val: 0.680004	test: 0.892811
PRC train: 0.791790	val: 0.571298	test: 0.652024

Epoch: 74
Loss: 0.14956048697488408
ROC train: 0.944338	val: 0.678558	test: 0.905668
PRC train: 0.842292	val: 0.572864	test: 0.678566

Epoch: 75
Loss: 0.1863250073889545
ROC train: 0.949456	val: 0.669901	test: 0.912825
PRC train: 0.842171	val: 0.573628	test: 0.709827

Epoch: 76
Loss: 0.14026850899634843
ROC train: 0.939496	val: 0.671077	test: 0.884759
PRC train: 0.823206	val: 0.567113	test: 0.706040

Epoch: 77
Loss: 0.14924651302320113
ROC train: 0.946187	val: 0.685050	test: 0.900236
PRC train: 0.815989	val: 0.576252	test: 0.684007

Epoch: 78
Loss: 0.15163543739038865
ROC train: 0.958400	val: 0.683002	test: 0.938840
PRC train: 0.844770	val: 0.576587	test: 0.758817

Epoch: 79
Loss: 0.13063958255674785
ROC train: 0.940770	val: 0.673349	test: 0.940457
PRC train: 0.829655	val: 0.572994	test: 0.760503

Epoch: 80
Loss: 0.13064149197660901
ROC train: 0.949391	val: 0.659088	test: 0.934779
PRC train: 0.842102	val: 0.564572	test: 0.756240

Epoch: 81
Loss: 0.1568769941559342
ROC train: 0.953504	val: 0.661577	test: 0.930682
PRC train: 0.846160	val: 0.561691	test: 0.746602

Epoch: 82
Loss: 0.11895313914161117
ROC train: 0.954617	val: 0.675649	test: 0.935874
PRC train: 0.848402	val: 0.568591	test: 0.748928

Epoch: 83
Loss: 0.14588520793271242
ROC train: 0.957593	val: 0.675268	test: 0.937611
PRC train: 0.852090	val: 0.566958	test: 0.733016

Epoch: 84
Loss: 0.12222550579589386
ROC train: 0.957171	val: 0.676509	test: 0.940485
PRC train: 0.858328	val: 0.574677	test: 0.729574

Epoch: 85
Loss: 0.11793488880292306
ROC train: 0.961888	val: 0.672013	test: 0.941233
PRC train: 0.873706	val: 0.583137	test: 0.731258

Epoch: 86
Loss: 0.13570427166991256
ROC train: 0.968184	val: 0.668053	test: 0.936308
PRC train: 0.885400	val: 0.584915	test: 0.701305

Epoch: 87
Loss: 0.12048024872715765
ROC train: 0.968158	val: 0.637163	test: 0.906580
PRC train: 0.883380	val: 0.589935	test: 0.650959

Epoch: 88
Loss: 0.11747803018175909
ROC train: 0.967944	val: 0.614606	test: 0.902611
PRC train: 0.879655	val: 0.568979	test: 0.649746

Epoch: 89
Loss: 0.1251889718250073
ROC train: 0.970697	val: 0.604712	test: 0.904438
PRC train: 0.885638	val: 0.579878	test: 0.655580

Epoch: 90
Loss: 0.21373930453917617
ROC train: 0.972375	val: 0.583826	test: 0.904391
PRC train: 0.891305	val: 0.556731	test: 0.662753

Epoch: 91
Loss: 0.17810855662475106
ROC train: 0.966880	val: 0.584006	test: 0.896107
PRC train: 0.875333	val: 0.566517	test: 0.660423

Epoch: 92
Loss: 0.15118028314885773
ROC train: 0.953719	val: 0.614229	test: 0.898858
PRC train: 0.846705	val: 0.566651	test: 0.672035

Epoch: 93
Loss: 0.148542198014806
ROC train: 0.959159	val: 0.638190	test: 0.886317
PRC train: 0.842372	val: 0.553297	test: 0.641148

Epoch: 94
Loss: 0.1505399403429713
ROC train: 0.924374	val: 0.626961	test: 0.916001
PRC train: 0.759750	val: 0.538048	test: 0.681482

Epoch: 34
Loss: 0.16132368988376786
ROC train: 0.913024	val: 0.627743	test: 0.902295
PRC train: 0.730373	val: 0.541733	test: 0.632888

Epoch: 35
Loss: 0.15408945426943949
ROC train: 0.927167	val: 0.636491	test: 0.926880
PRC train: 0.757197	val: 0.545599	test: 0.660660

Epoch: 36
Loss: 0.16276798053205271
ROC train: 0.928584	val: 0.625203	test: 0.933076
PRC train: 0.770213	val: 0.538587	test: 0.708794

Epoch: 37
Loss: 0.25664908714048973
ROC train: 0.924706	val: 0.659336	test: 0.924076
PRC train: 0.766195	val: 0.552977	test: 0.691427

Epoch: 38
Loss: 0.15157183688891845
ROC train: 0.882146	val: 0.684674	test: 0.890781
PRC train: 0.678752	val: 0.587910	test: 0.651082

Epoch: 39
Loss: 0.16139595056739522
ROC train: 0.904492	val: 0.672380	test: 0.904260
PRC train: 0.754820	val: 0.552169	test: 0.697699

Epoch: 40
Loss: 0.1967465921649314
ROC train: 0.911533	val: 0.641255	test: 0.902541
PRC train: 0.762939	val: 0.543371	test: 0.701807

Epoch: 41
Loss: 0.24644888087184463
ROC train: 0.917546	val: 0.667184	test: 0.901558
PRC train: 0.756000	val: 0.550906	test: 0.684094

Epoch: 42
Loss: 0.20973204874640552
ROC train: 0.895021	val: 0.689043	test: 0.881546
PRC train: 0.711832	val: 0.554681	test: 0.670128

Epoch: 43
Loss: 0.2710016091131132
ROC train: 0.873140	val: 0.641535	test: 0.886591
PRC train: 0.690055	val: 0.550391	test: 0.709982

Epoch: 44
Loss: 0.39005869895157785
ROC train: 0.887095	val: 0.621839	test: 0.883109
PRC train: 0.735615	val: 0.545116	test: 0.687303

Epoch: 45
Loss: 0.1699394295280675
ROC train: 0.907395	val: 0.625082	test: 0.894875
PRC train: 0.726542	val: 0.551537	test: 0.650800

Epoch: 46
Loss: 0.1781646759748869
ROC train: 0.905216	val: 0.618049	test: 0.907337
PRC train: 0.725793	val: 0.547203	test: 0.650322

Epoch: 47
Loss: 0.20988280862727052
ROC train: 0.901942	val: 0.626584	test: 0.909095
PRC train: 0.708744	val: 0.544956	test: 0.657054

Epoch: 48
Loss: 0.2479783716690654
ROC train: 0.908079	val: 0.626230	test: 0.915654
PRC train: 0.706653	val: 0.546479	test: 0.672026

Epoch: 49
Loss: 0.1623789710188323
ROC train: 0.911729	val: 0.606425	test: 0.914024
PRC train: 0.730065	val: 0.540824	test: 0.679402

Epoch: 50
Loss: 0.1600169171571188
ROC train: 0.918948	val: 0.602627	test: 0.914302
PRC train: 0.742504	val: 0.539134	test: 0.682710

Epoch: 51
Loss: 0.2347304455149743
ROC train: 0.929858	val: 0.591449	test: 0.925155
PRC train: 0.775946	val: 0.538389	test: 0.695614

Epoch: 52
Loss: 0.16170311248614339
ROC train: 0.890179	val: 0.566714	test: 0.910894
PRC train: 0.750380	val: 0.536742	test: 0.694460

Epoch: 53
Loss: 0.1547328169184314
ROC train: 0.897944	val: 0.591127	test: 0.916005
PRC train: 0.757403	val: 0.540669	test: 0.695495

Epoch: 54
Loss: 0.14970474130405306
ROC train: 0.927880	val: 0.645673	test: 0.912871
PRC train: 0.787566	val: 0.556331	test: 0.692913

Epoch: 55
Loss: 0.1514909558509153
ROC train: 0.939872	val: 0.670063	test: 0.911146
PRC train: 0.801059	val: 0.566664	test: 0.687464

Epoch: 56
Loss: 0.14030211615815844
ROC train: 0.940637	val: 0.678934	test: 0.908919
PRC train: 0.795063	val: 0.564889	test: 0.668795

Epoch: 57
Loss: 0.14561096069279172
ROC train: 0.949191	val: 0.685051	test: 0.918864
PRC train: 0.806589	val: 0.567369	test: 0.676530

Epoch: 58
Loss: 0.15038824094999786
ROC train: 0.954334	val: 0.657761	test: 0.923564
PRC train: 0.820392	val: 0.552525	test: 0.686052

Epoch: 59
Loss: 0.17832846680182363
ROC train: 0.953760	val: 0.661542	test: 0.922592
PRC train: 0.816593	val: 0.557438	test: 0.689072

Epoch: 60
Loss: 0.1567048032375117
ROC train: 0.943080	val: 0.657782	test: 0.920193
PRC train: 0.788072	val: 0.572925	test: 0.713120

Epoch: 61
Loss: 0.15638681630109832
ROC train: 0.950019	val: 0.674110	test: 0.926239
PRC train: 0.799457	val: 0.578922	test: 0.715304

Epoch: 62
Loss: 0.14362013011692681
ROC train: 0.948498	val: 0.701138	test: 0.905309
PRC train: 0.790901	val: 0.572502	test: 0.685164

Epoch: 63
Loss: 0.13364811929909629
ROC train: 0.950300	val: 0.682529	test: 0.892213
PRC train: 0.805448	val: 0.568776	test: 0.689813

Epoch: 64
Loss: 0.15622844629357543
ROC train: 0.956475	val: 0.658984	test: 0.925048
PRC train: 0.836135	val: 0.558729	test: 0.714025

Epoch: 65
Loss: 0.13507517162976596
ROC train: 0.955545	val: 0.656104	test: 0.928819
PRC train: 0.821436	val: 0.560518	test: 0.726141

Epoch: 66
Loss: 0.17817720922291017
ROC train: 0.962191	val: 0.649864	test: 0.929764
PRC train: 0.837230	val: 0.559984	test: 0.715640

Epoch: 67
Loss: 0.18817021940204193
ROC train: 0.938123	val: 0.635273	test: 0.865230
PRC train: 0.770772	val: 0.544445	test: 0.641784

Epoch: 68
Loss: 0.1785787358103815
ROC train: 0.944351	val: 0.629128	test: 0.889147
PRC train: 0.785836	val: 0.541068	test: 0.660420

Epoch: 69
Loss: 0.1315603320384835
ROC train: 0.953753	val: 0.626656	test: 0.916160
PRC train: 0.836313	val: 0.553204	test: 0.707420

Epoch: 70
Loss: 0.18154752107825683
ROC train: 0.953128	val: 0.637922	test: 0.921224
PRC train: 0.838464	val: 0.553269	test: 0.716092

Epoch: 71
Loss: 0.1340651841467279
ROC train: 0.950457	val: 0.667056	test: 0.915338
PRC train: 0.821943	val: 0.552772	test: 0.704054

Epoch: 72
Loss: 0.16676195630321802
ROC train: 0.950980	val: 0.668866	test: 0.912358
PRC train: 0.823557	val: 0.553212	test: 0.683248

Epoch: 73
Loss: 0.15021101823114752
ROC train: 0.953246	val: 0.662689	test: 0.896303
PRC train: 0.827606	val: 0.555585	test: 0.664260

Epoch: 74
Loss: 0.12598871672270104
ROC train: 0.956579	val: 0.650458	test: 0.919002
PRC train: 0.825230	val: 0.552969	test: 0.685687

Epoch: 75
Loss: 0.12980911182676258
ROC train: 0.960412	val: 0.640095	test: 0.928931
PRC train: 0.838506	val: 0.546873	test: 0.703779

Epoch: 76
Loss: 0.137142153679784
ROC train: 0.964116	val: 0.647571	test: 0.923404
PRC train: 0.844732	val: 0.548436	test: 0.703634

Epoch: 77
Loss: 0.13485884978175272
ROC train: 0.963148	val: 0.659117	test: 0.899566
PRC train: 0.836901	val: 0.551276	test: 0.675081

Epoch: 78
Loss: 0.12853202401457728
ROC train: 0.961377	val: 0.658197	test: 0.895923
PRC train: 0.835760	val: 0.555700	test: 0.682515

Epoch: 79
Loss: 0.16925580691063874
ROC train: 0.965061	val: 0.653376	test: 0.913512
PRC train: 0.844749	val: 0.564663	test: 0.699675

Epoch: 80
Loss: 0.2486466103212587
ROC train: 0.966972	val: 0.649842	test: 0.918789
PRC train: 0.847887	val: 0.567094	test: 0.693895

Epoch: 81
Loss: 0.12990761975133588
ROC train: 0.953669	val: 0.644151	test: 0.908245
PRC train: 0.831078	val: 0.566381	test: 0.674323

Epoch: 82
Loss: 0.18744017294669937
ROC train: 0.947472	val: 0.669033	test: 0.919894
PRC train: 0.834748	val: 0.572402	test: 0.685530

Epoch: 83
Loss: 0.2290490313241563
ROC train: 0.931355	val: 0.691185	test: 0.925646
PRC train: 0.796260	val: 0.565785	test: 0.677837

Epoch: 84
Loss: 0.14690346404652183
ROC train: 0.918426	val: 0.718594	test: 0.891187
PRC train: 0.752830	val: 0.570206	test: 0.627374

Epoch: 85
Loss: 0.14716649278705313
ROC train: 0.930700	val: 0.734713	test: 0.885280
PRC train: 0.790042	val: 0.576849	test: 0.647851

Epoch: 86
Loss: 0.13085233180567388
ROC train: 0.940449	val: 0.753600	test: 0.885360
PRC train: 0.812665	val: 0.588814	test: 0.663842

Epoch: 87
Loss: 0.19510685794447674
ROC train: 0.952734	val: 0.738571	test: 0.906686
PRC train: 0.834145	val: 0.592305	test: 0.697163

Epoch: 88
Loss: 0.23420078693041235
ROC train: 0.921712	val: 0.696337	test: 0.888180
PRC train: 0.770799	val: 0.580620	test: 0.700089

Epoch: 89
Loss: 0.20152646297533144
ROC train: 0.915104	val: 0.699279	test: 0.879330
PRC train: 0.754589	val: 0.572292	test: 0.689640

Epoch: 90
Loss: 0.21079751893916562
ROC train: 0.932498	val: 0.720685	test: 0.893351
PRC train: 0.788297	val: 0.583567	test: 0.685221

Epoch: 91
Loss: 0.14119708587356644
ROC train: 0.923790	val: 0.692997	test: 0.870143
PRC train: 0.749963	val: 0.564951	test: 0.657135

Epoch: 92
Loss: 0.14853898921285133
ROC train: 0.926870	val: 0.681093	test: 0.865582
PRC train: 0.753807	val: 0.560385	test: 0.663953

Epoch: 93
Loss: 0.14316831215419337
ROC train: 0.941127	val: 0.684476	test: 0.874245
PRC train: 0.789709	val: 0.560852	test: 0.673532

Epoch: 94
Loss: 0.25367891512851426
ROC train: 0.898514	val: 0.627451	test: 0.888509
PRC train: 0.699003	val: 0.570862	test: 0.665965

Epoch: 34
Loss: 0.17184338712356256
ROC train: 0.908083	val: 0.636253	test: 0.896831
PRC train: 0.709138	val: 0.564140	test: 0.695852

Epoch: 35
Loss: 0.19700587258613803
ROC train: 0.908767	val: 0.651388	test: 0.911663
PRC train: 0.713002	val: 0.564269	test: 0.716157

Epoch: 36
Loss: 0.19820931012813703
ROC train: 0.900881	val: 0.658246	test: 0.912197
PRC train: 0.702669	val: 0.557532	test: 0.681774

Epoch: 37
Loss: 0.17148647760211427
ROC train: 0.891491	val: 0.666750	test: 0.892628
PRC train: 0.692053	val: 0.564268	test: 0.657104

Epoch: 38
Loss: 0.25813370740788927
ROC train: 0.893615	val: 0.665633	test: 0.876691
PRC train: 0.695883	val: 0.565243	test: 0.655899

Epoch: 39
Loss: 0.2297952814515402
ROC train: 0.898338	val: 0.646757	test: 0.883110
PRC train: 0.701842	val: 0.549978	test: 0.680676

Epoch: 40
Loss: 0.17537232951543769
ROC train: 0.874309	val: 0.643594	test: 0.877684
PRC train: 0.656260	val: 0.551997	test: 0.655585

Epoch: 41
Loss: 0.2297471348360173
ROC train: 0.888510	val: 0.651869	test: 0.899796
PRC train: 0.689176	val: 0.555375	test: 0.671782

Epoch: 42
Loss: 0.16970159688166478
ROC train: 0.910522	val: 0.650729	test: 0.914329
PRC train: 0.752504	val: 0.549837	test: 0.658427

Epoch: 43
Loss: 0.16097575610887493
ROC train: 0.920983	val: 0.654269	test: 0.912027
PRC train: 0.765712	val: 0.549663	test: 0.657851

Epoch: 44
Loss: 0.15208022174778515
ROC train: 0.920706	val: 0.664266	test: 0.909655
PRC train: 0.755476	val: 0.550580	test: 0.661896

Epoch: 45
Loss: 0.19749296364421595
ROC train: 0.924887	val: 0.658600	test: 0.915669
PRC train: 0.763806	val: 0.547605	test: 0.671324

Epoch: 46
Loss: 0.1779026300012298
ROC train: 0.911476	val: 0.664914	test: 0.914574
PRC train: 0.726355	val: 0.546621	test: 0.681733

Epoch: 47
Loss: 0.1604706923879018
ROC train: 0.914039	val: 0.687956	test: 0.907513
PRC train: 0.709264	val: 0.559164	test: 0.689802

Epoch: 48
Loss: 0.22361410468802143
ROC train: 0.905589	val: 0.670943	test: 0.875713
PRC train: 0.697872	val: 0.555810	test: 0.691011

Epoch: 49
Loss: 0.30461810269469003
ROC train: 0.905977	val: 0.652932	test: 0.853388
PRC train: 0.716129	val: 0.551723	test: 0.739032

Epoch: 50
Loss: 0.17488101445546275
ROC train: 0.904273	val: 0.652645	test: 0.881381
PRC train: 0.733163	val: 0.550875	test: 0.724020

Epoch: 51
Loss: 0.25839609848887657
ROC train: 0.905787	val: 0.679477	test: 0.904027
PRC train: 0.729705	val: 0.553533	test: 0.671943

Epoch: 52
Loss: 0.16679505294687152
ROC train: 0.906457	val: 0.663669	test: 0.905349
PRC train: 0.736964	val: 0.551308	test: 0.673280

Epoch: 53
Loss: 0.1704096760670699
ROC train: 0.907456	val: 0.682694	test: 0.890026
PRC train: 0.733824	val: 0.552498	test: 0.648367

Epoch: 54
Loss: 0.23753181976265508
ROC train: 0.912867	val: 0.715695	test: 0.885507
PRC train: 0.745383	val: 0.573271	test: 0.669311

Epoch: 55
Loss: 0.20315922520145918
ROC train: 0.899131	val: 0.706771	test: 0.852408
PRC train: 0.730116	val: 0.571896	test: 0.639326

Epoch: 56
Loss: 0.22377196142380634
ROC train: 0.908767	val: 0.674266	test: 0.833224
PRC train: 0.746758	val: 0.558955	test: 0.625317

Epoch: 57
Loss: 0.17183600688542114
ROC train: 0.880879	val: 0.633514	test: 0.766431
PRC train: 0.716917	val: 0.543606	test: 0.605795

Epoch: 58
Loss: 0.27789047000072903
ROC train: 0.887818	val: 0.611816	test: 0.767329
PRC train: 0.728889	val: 0.537695	test: 0.608668

Epoch: 59
Loss: 0.21506713460953555
ROC train: 0.911936	val: 0.641916	test: 0.851941
PRC train: 0.760799	val: 0.549013	test: 0.651672

Epoch: 60
Loss: 0.17245581234609036
ROC train: 0.893508	val: 0.635403	test: 0.854056
PRC train: 0.739765	val: 0.552083	test: 0.631038

Epoch: 61
Loss: 0.16212685565006404
ROC train: 0.856497	val: 0.663684	test: 0.856375
PRC train: 0.716708	val: 0.562054	test: 0.625964

Epoch: 62
Loss: 0.16820812804377405
ROC train: 0.898747	val: 0.676029	test: 0.869908
PRC train: 0.728416	val: 0.559392	test: 0.643692

Epoch: 63
Loss: 0.16413363187301383
ROC train: 0.909541	val: 0.678472	test: 0.865485
PRC train: 0.733296	val: 0.558428	test: 0.642614

Epoch: 64
Loss: 0.156354175841149
ROC train: 0.917875	val: 0.694833	test: 0.865822
PRC train: 0.739345	val: 0.564931	test: 0.633386

Epoch: 65
Loss: 0.15075486488650386
ROC train: 0.924516	val: 0.704946	test: 0.870955
PRC train: 0.749672	val: 0.571606	test: 0.629771

Epoch: 66
Loss: 0.15187267868440232
ROC train: 0.927738	val: 0.717105	test: 0.870624
PRC train: 0.755864	val: 0.577343	test: 0.633430

Epoch: 67
Loss: 0.18381946766525775
ROC train: 0.929446	val: 0.729057	test: 0.867938
PRC train: 0.760201	val: 0.583238	test: 0.633654

Epoch: 68
Loss: 0.2195074392604442
ROC train: 0.924280	val: 0.743313	test: 0.859569
PRC train: 0.751457	val: 0.598249	test: 0.623868

Epoch: 69
Loss: 0.18848091099603118
ROC train: 0.931658	val: 0.731646	test: 0.888944
PRC train: 0.777887	val: 0.576076	test: 0.667192

Epoch: 70
Loss: 0.17699498885926251
ROC train: 0.876721	val: 0.708416	test: 0.827112
PRC train: 0.719122	val: 0.595608	test: 0.602502

Epoch: 71
Loss: 0.155716005634588
ROC train: 0.861210	val: 0.724328	test: 0.828864
PRC train: 0.691924	val: 0.587919	test: 0.607970

Epoch: 72
Loss: 0.19929058567322663
ROC train: 0.893923	val: 0.742120	test: 0.872134
PRC train: 0.704636	val: 0.579622	test: 0.625906

Epoch: 73
Loss: 0.15629354150941177
ROC train: 0.917596	val: 0.704185	test: 0.899169
PRC train: 0.759889	val: 0.567265	test: 0.653402

Epoch: 74
Loss: 0.2766548517332488
ROC train: 0.926168	val: 0.669955	test: 0.914002
PRC train: 0.785540	val: 0.554947	test: 0.692150

Epoch: 75
Loss: 0.14893301831446812
ROC train: 0.915047	val: 0.655783	test: 0.907304
PRC train: 0.764294	val: 0.547051	test: 0.687911

Epoch: 76
Loss: 0.16210059258393716
ROC train: 0.919543	val: 0.682163	test: 0.892222
PRC train: 0.759081	val: 0.553763	test: 0.667389

Epoch: 77
Loss: 0.22452135730408146
ROC train: 0.924527	val: 0.709841	test: 0.875504
PRC train: 0.752427	val: 0.570494	test: 0.637578

Epoch: 78
Loss: 0.14546652517305678
ROC train: 0.918570	val: 0.691261	test: 0.871627
PRC train: 0.755742	val: 0.564629	test: 0.627850

Epoch: 79
Loss: 0.18681513129553132
ROC train: 0.919932	val: 0.682642	test: 0.877320
PRC train: 0.761336	val: 0.563643	test: 0.623754

Epoch: 80
Loss: 0.1558960997255026
ROC train: 0.925335	val: 0.620352	test: 0.889658
PRC train: 0.776884	val: 0.546495	test: 0.629717

Epoch: 81
Loss: 0.14976656565845264
ROC train: 0.931378	val: 0.633503	test: 0.878880
PRC train: 0.785317	val: 0.548191	test: 0.633716

Epoch: 82
Loss: 0.21772935575818914
ROC train: 0.947646	val: 0.688454	test: 0.890897
PRC train: 0.792417	val: 0.562778	test: 0.633737

Epoch: 83
Loss: 0.1391794869911856
ROC train: 0.930031	val: 0.741259	test: 0.876306
PRC train: 0.726314	val: 0.584430	test: 0.631647

Epoch: 84
Loss: 0.18284221351042648
ROC train: 0.929721	val: 0.729931	test: 0.871029
PRC train: 0.736325	val: 0.586467	test: 0.631845

Epoch: 85
Loss: 0.13728861260614264
ROC train: 0.942790	val: 0.728653	test: 0.871147
PRC train: 0.794362	val: 0.583598	test: 0.641678

Epoch: 86
Loss: 0.1332678509485131
ROC train: 0.951187	val: 0.714107	test: 0.874276
PRC train: 0.815212	val: 0.568508	test: 0.667322

Epoch: 87
Loss: 0.12915740075080923
ROC train: 0.954660	val: 0.701989	test: 0.877246
PRC train: 0.826361	val: 0.566262	test: 0.673308

Epoch: 88
Loss: 0.14829912678424884
ROC train: 0.957129	val: 0.704030	test: 0.881012
PRC train: 0.833777	val: 0.567074	test: 0.672780

Epoch: 89
Loss: 0.21162828572269765
ROC train: 0.954525	val: 0.704940	test: 0.885814
PRC train: 0.831948	val: 0.561615	test: 0.676191

Epoch: 90
Loss: 0.15378396370213385
ROC train: 0.941636	val: 0.708625	test: 0.868094
PRC train: 0.789252	val: 0.569081	test: 0.659910

Epoch: 91
Loss: 0.14250407335343362
ROC train: 0.942848	val: 0.715750	test: 0.874695
PRC train: 0.784952	val: 0.571887	test: 0.656904

Epoch: 92
Loss: 0.1540299114546233
ROC train: 0.935199	val: 0.704565	test: 0.882524
PRC train: 0.788620	val: 0.565923	test: 0.653920

Epoch: 93
Loss: 0.13588106904353323
ROC train: 0.926630	val: 0.681975	test: 0.877695
PRC train: 0.780469	val: 0.558945	test: 0.663670

Epoch: 94
Loss: 0.14356677267807272
ROC train: 0.969912	val: 0.775401	test: 0.914383
PRC train: 0.874923	val: 0.632171	test: 0.718743

Epoch: 34
Loss: 0.1514994622599912
ROC train: 0.971676	val: 0.783422	test: 0.897663
PRC train: 0.872441	val: 0.636400	test: 0.704183

Epoch: 35
Loss: 0.1487660807252476
ROC train: 0.969316	val: 0.775735	test: 0.888750
PRC train: 0.859894	val: 0.623980	test: 0.701285

Epoch: 36
Loss: 0.14223379120675927
ROC train: 0.969763	val: 0.782754	test: 0.910710
PRC train: 0.873737	val: 0.623345	test: 0.703052

Epoch: 37
Loss: 0.1461829691074243
ROC train: 0.976123	val: 0.766043	test: 0.898458
PRC train: 0.894059	val: 0.598690	test: 0.683099

Epoch: 38
Loss: 0.1290050072682435
ROC train: 0.974972	val: 0.756684	test: 0.892586
PRC train: 0.879049	val: 0.591066	test: 0.647869

Epoch: 39
Loss: 0.1466013717839558
ROC train: 0.976750	val: 0.764706	test: 0.916552
PRC train: 0.890650	val: 0.597936	test: 0.666281

Epoch: 40
Loss: 0.13769231808121224
ROC train: 0.978002	val: 0.767714	test: 0.899594
PRC train: 0.888384	val: 0.604710	test: 0.656042

Epoch: 41
Loss: 0.1344835003533662
ROC train: 0.974498	val: 0.718917	test: 0.856662
PRC train: 0.876807	val: 0.567141	test: 0.678661

Epoch: 42
Loss: 0.12655394423645733
ROC train: 0.978456	val: 0.764706	test: 0.914455
PRC train: 0.897441	val: 0.597086	test: 0.720423

Epoch: 43
Loss: 0.12386943763439542
ROC train: 0.978135	val: 0.781083	test: 0.902142
PRC train: 0.894747	val: 0.601142	test: 0.695896

Epoch: 44
Loss: 0.12805128792585369
ROC train: 0.972739	val: 0.779412	test: 0.862175
PRC train: 0.876185	val: 0.584911	test: 0.632832

Epoch: 45
Loss: 0.138001037656633
ROC train: 0.974153	val: 0.818516	test: 0.879478
PRC train: 0.887133	val: 0.613050	test: 0.659251

Epoch: 46
Loss: 0.1441989068721469
ROC train: 0.978767	val: 0.816176	test: 0.898575
PRC train: 0.898776	val: 0.629485	test: 0.683559

Epoch: 47
Loss: 0.12368284672205174
ROC train: 0.980312	val: 0.790107	test: 0.898129
PRC train: 0.895524	val: 0.593419	test: 0.709026

Epoch: 48
Loss: 0.11468204494877006
ROC train: 0.979275	val: 0.789439	test: 0.904660
PRC train: 0.894290	val: 0.596624	test: 0.707245

Epoch: 49
Loss: 0.12782830505045717
ROC train: 0.979232	val: 0.780749	test: 0.913618
PRC train: 0.903890	val: 0.611346	test: 0.720415

Epoch: 50
Loss: 0.13900346240308892
ROC train: 0.974421	val: 0.777072	test: 0.899564
PRC train: 0.892092	val: 0.611993	test: 0.702148

Epoch: 51
Loss: 0.120455484549713
ROC train: 0.980794	val: 0.755013	test: 0.903217
PRC train: 0.895479	val: 0.590219	test: 0.712731

Epoch: 52
Loss: 0.12226771782459793
ROC train: 0.980501	val: 0.716578	test: 0.905791
PRC train: 0.893953	val: 0.564160	test: 0.723128

Epoch: 53
Loss: 0.11081589689451912
ROC train: 0.981120	val: 0.706885	test: 0.920865
PRC train: 0.899260	val: 0.565422	test: 0.730352

Epoch: 54
Loss: 0.11292220558518277
ROC train: 0.982047	val: 0.735963	test: 0.907609
PRC train: 0.910798	val: 0.582365	test: 0.721537

Epoch: 55
Loss: 0.11260027097043898
ROC train: 0.980327	val: 0.740642	test: 0.902771
PRC train: 0.905871	val: 0.585718	test: 0.727898

Epoch: 56
Loss: 0.11709162226503063
ROC train: 0.981096	val: 0.755682	test: 0.917090
PRC train: 0.909231	val: 0.598999	test: 0.738241

Epoch: 57
Loss: 0.11208455744156728
ROC train: 0.980603	val: 0.751003	test: 0.904073
PRC train: 0.904708	val: 0.573899	test: 0.694818

Epoch: 58
Loss: 0.10547725401426758
ROC train: 0.983272	val: 0.782420	test: 0.900192
PRC train: 0.914906	val: 0.582563	test: 0.690522

Epoch: 59
Loss: 0.12203254407349169
ROC train: 0.983942	val: 0.801471	test: 0.908613
PRC train: 0.918862	val: 0.615710	test: 0.712443

Epoch: 60
Loss: 0.11101640074673473
ROC train: 0.984164	val: 0.808155	test: 0.918873
PRC train: 0.919247	val: 0.634639	test: 0.742140

Epoch: 61
Loss: 0.11740779770283458
ROC train: 0.984843	val: 0.781417	test: 0.907499
PRC train: 0.921661	val: 0.595701	test: 0.727267

Epoch: 62
Loss: 0.11503467901825634
ROC train: 0.985740	val: 0.756684	test: 0.904747
PRC train: 0.926416	val: 0.594683	test: 0.720432

Epoch: 63
Loss: 0.10906631067368514
ROC train: 0.984691	val: 0.747660	test: 0.895100
PRC train: 0.920749	val: 0.587435	test: 0.675160

Epoch: 64
Loss: 0.10722054761705427
ROC train: 0.982720	val: 0.757353	test: 0.907473
PRC train: 0.919940	val: 0.614208	test: 0.671724

Epoch: 65
Loss: 0.1090785948290794
ROC train: 0.985081	val: 0.775401	test: 0.918397
PRC train: 0.922458	val: 0.621061	test: 0.668710

Epoch: 66
Loss: 0.11476778084917157
ROC train: 0.986300	val: 0.777072	test: 0.916583
PRC train: 0.921413	val: 0.607249	test: 0.656699

Epoch: 67
Loss: 0.09712788580624415
ROC train: 0.986995	val: 0.767714	test: 0.923621
PRC train: 0.920645	val: 0.608422	test: 0.701699

Epoch: 68
Loss: 0.11038588421102094
ROC train: 0.987533	val: 0.753342	test: 0.920687
PRC train: 0.927054	val: 0.619090	test: 0.707823

Epoch: 69
Loss: 0.11116717707617414
ROC train: 0.988714	val: 0.757019	test: 0.909692
PRC train: 0.931018	val: 0.606606	test: 0.721448

Epoch: 70
Loss: 0.09758417206068028
ROC train: 0.987301	val: 0.765374	test: 0.916102
PRC train: 0.925232	val: 0.606629	test: 0.737105

Epoch: 71
Loss: 0.10128826212087294
ROC train: 0.986314	val: 0.753342	test: 0.923530
PRC train: 0.921268	val: 0.616745	test: 0.744354

Epoch: 72
Loss: 0.106373197045922
ROC train: 0.986940	val: 0.747995	test: 0.921432
PRC train: 0.924235	val: 0.609834	test: 0.718679

Epoch: 73
Loss: 0.11066095579356323
ROC train: 0.986503	val: 0.728275	test: 0.906905
PRC train: 0.924431	val: 0.588229	test: 0.704641

Epoch: 74
Loss: 0.10147131121886258
ROC train: 0.987483	val: 0.742647	test: 0.929043
PRC train: 0.931142	val: 0.599897	test: 0.754833

Epoch: 75
Loss: 0.0979650248679746
ROC train: 0.987874	val: 0.721591	test: 0.912069
PRC train: 0.936115	val: 0.587434	test: 0.741074

Epoch: 76
Loss: 0.0979721517891931
ROC train: 0.989372	val: 0.711564	test: 0.903936
PRC train: 0.940213	val: 0.583987	test: 0.730392

Epoch: 77
Loss: 0.0998387905898068
ROC train: 0.987883	val: 0.715241	test: 0.894380
PRC train: 0.932858	val: 0.596236	test: 0.717623

Epoch: 78
Loss: 0.09820375616714982
ROC train: 0.988568	val: 0.722259	test: 0.884820
PRC train: 0.934994	val: 0.583572	test: 0.705867

Epoch: 79
Loss: 0.10770364383703539
ROC train: 0.989130	val: 0.741310	test: 0.897193
PRC train: 0.938579	val: 0.594783	test: 0.720396

Epoch: 80
Loss: 0.10394039698006699
ROC train: 0.988178	val: 0.745655	test: 0.919153
PRC train: 0.936970	val: 0.603061	test: 0.755827

Epoch: 81
Loss: 0.09906715715082767
ROC train: 0.990131	val: 0.735294	test: 0.914724
PRC train: 0.944085	val: 0.609927	test: 0.750061

Epoch: 82
Loss: 0.10227704686085812
ROC train: 0.990337	val: 0.728944	test: 0.904539
PRC train: 0.943294	val: 0.597149	test: 0.733966

Epoch: 83
Loss: 0.09921054139111499
ROC train: 0.989412	val: 0.739305	test: 0.929403
PRC train: 0.936949	val: 0.598823	test: 0.744871

Epoch: 84
Loss: 0.09986325848173136
ROC train: 0.988568	val: 0.737299	test: 0.932068
PRC train: 0.932861	val: 0.598279	test: 0.731257

Epoch: 85
Loss: 0.09460653261685412
ROC train: 0.990204	val: 0.747660	test: 0.937581
PRC train: 0.938901	val: 0.590503	test: 0.752749

Epoch: 86
Loss: 0.08497981018689071
ROC train: 0.988294	val: 0.738971	test: 0.924579
PRC train: 0.930235	val: 0.577185	test: 0.739831

Epoch: 87
Loss: 0.09054269452018325
ROC train: 0.990160	val: 0.741644	test: 0.930781
PRC train: 0.941258	val: 0.582079	test: 0.750038

Epoch: 88
Loss: 0.08559949425147444
ROC train: 0.991097	val: 0.740976	test: 0.931125
PRC train: 0.945725	val: 0.589663	test: 0.750790

Epoch: 89
Loss: 0.08942605148962246
ROC train: 0.990957	val: 0.743984	test: 0.926018
PRC train: 0.946957	val: 0.594211	test: 0.729186

Epoch: 90
Loss: 0.09124600704446575
ROC train: 0.990735	val: 0.733623	test: 0.921868
PRC train: 0.945122	val: 0.589244	test: 0.720801

Epoch: 91
Loss: 0.09334223517940857
ROC train: 0.990725	val: 0.718917	test: 0.923920
PRC train: 0.940959	val: 0.584059	test: 0.716351

Epoch: 92
Loss: 0.09657453159420157
ROC train: 0.990498	val: 0.717580	test: 0.930421
PRC train: 0.940242	val: 0.582690	test: 0.719984

Epoch: 93
Loss: 0.08291357707766109
ROC train: 0.990829	val: 0.706551	test: 0.919573
PRC train: 0.943551	val: 0.579197	test: 0.730418

Epoch: 94
Loss: 0.09248965373859341
ROC train: 0.966121	val: 0.837567	test: 0.896569
PRC train: 0.874193	val: 0.686281	test: 0.683322

Epoch: 34
Loss: 0.14804987115461893
ROC train: 0.967418	val: 0.842580	test: 0.894157
PRC train: 0.878978	val: 0.660738	test: 0.676764

Epoch: 35
Loss: 0.14270313385850705
ROC train: 0.966100	val: 0.812834	test: 0.886354
PRC train: 0.866097	val: 0.620327	test: 0.638103

Epoch: 36
Loss: 0.1326822284118602
ROC train: 0.969501	val: 0.821524	test: 0.881768
PRC train: 0.887131	val: 0.634919	test: 0.644701

Epoch: 37
Loss: 0.13043448369298896
ROC train: 0.968559	val: 0.835227	test: 0.888644
PRC train: 0.880441	val: 0.651992	test: 0.701515

Epoch: 38
Loss: 0.13276079821220135
ROC train: 0.965053	val: 0.821524	test: 0.920535
PRC train: 0.873071	val: 0.693054	test: 0.733262

Epoch: 39
Loss: 0.13856506472506577
ROC train: 0.970462	val: 0.824198	test: 0.922572
PRC train: 0.877601	val: 0.635731	test: 0.722446

Epoch: 40
Loss: 0.13673324943908297
ROC train: 0.972969	val: 0.816845	test: 0.898291
PRC train: 0.890365	val: 0.632119	test: 0.671576

Epoch: 41
Loss: 0.12478446353658354
ROC train: 0.973759	val: 0.810829	test: 0.915027
PRC train: 0.892135	val: 0.657884	test: 0.677366

Epoch: 42
Loss: 0.13375490310865112
ROC train: 0.977788	val: 0.797126	test: 0.912195
PRC train: 0.902589	val: 0.656165	test: 0.696776

Epoch: 43
Loss: 0.13592897553759525
ROC train: 0.974789	val: 0.785428	test: 0.900075
PRC train: 0.889036	val: 0.649719	test: 0.662474

Epoch: 44
Loss: 0.12575490353259722
ROC train: 0.976510	val: 0.786096	test: 0.869724
PRC train: 0.895584	val: 0.633200	test: 0.683519

Epoch: 45
Loss: 0.1325831091241037
ROC train: 0.974889	val: 0.797126	test: 0.878020
PRC train: 0.889608	val: 0.648889	test: 0.682986

Epoch: 46
Loss: 0.13752165006122408
ROC train: 0.976272	val: 0.799465	test: 0.912463
PRC train: 0.899275	val: 0.639420	test: 0.733668

Epoch: 47
Loss: 0.12549593609553042
ROC train: 0.980126	val: 0.801805	test: 0.900419
PRC train: 0.910710	val: 0.634883	test: 0.731110

Epoch: 48
Loss: 0.12495964018893506
ROC train: 0.977422	val: 0.842914	test: 0.885751
PRC train: 0.902477	val: 0.644713	test: 0.718671

Epoch: 49
Loss: 0.12898509859889723
ROC train: 0.979324	val: 0.847259	test: 0.911490
PRC train: 0.916586	val: 0.656084	test: 0.721676

Epoch: 50
Loss: 0.12068304805631853
ROC train: 0.977018	val: 0.809826	test: 0.902619
PRC train: 0.911615	val: 0.641674	test: 0.715962

Epoch: 51
Loss: 0.12322204553096802
ROC train: 0.979804	val: 0.811163	test: 0.890007
PRC train: 0.917907	val: 0.650876	test: 0.700119

Epoch: 52
Loss: 0.11598842329269927
ROC train: 0.980149	val: 0.791110	test: 0.890311
PRC train: 0.919700	val: 0.653395	test: 0.628874

Epoch: 53
Loss: 0.11966147758712202
ROC train: 0.980882	val: 0.774064	test: 0.866983
PRC train: 0.911840	val: 0.642312	test: 0.621482

Epoch: 54
Loss: 0.11600534704061316
ROC train: 0.981517	val: 0.776738	test: 0.884722
PRC train: 0.911185	val: 0.643698	test: 0.663149

Epoch: 55
Loss: 0.11026156678250949
ROC train: 0.983717	val: 0.807152	test: 0.923803
PRC train: 0.918411	val: 0.675935	test: 0.730678

Epoch: 56
Loss: 0.1172542148740912
ROC train: 0.982138	val: 0.810829	test: 0.924477
PRC train: 0.917346	val: 0.688210	test: 0.726525

Epoch: 57
Loss: 0.1099366809186703
ROC train: 0.975681	val: 0.794118	test: 0.896300
PRC train: 0.897427	val: 0.681127	test: 0.667201

Epoch: 58
Loss: 0.12080963354759813
ROC train: 0.982962	val: 0.776070	test: 0.902710
PRC train: 0.917045	val: 0.649312	test: 0.671111

Epoch: 59
Loss: 0.1109170830361208
ROC train: 0.985438	val: 0.763035	test: 0.913675
PRC train: 0.923342	val: 0.632568	test: 0.699541

Epoch: 60
Loss: 0.10918208224882726
ROC train: 0.985233	val: 0.736631	test: 0.921300
PRC train: 0.922137	val: 0.619712	test: 0.721495

Epoch: 61
Loss: 0.11075838414962766
ROC train: 0.984678	val: 0.728610	test: 0.895849
PRC train: 0.921130	val: 0.638063	test: 0.653970

Epoch: 62
Loss: 0.10549201475971651
ROC train: 0.985453	val: 0.735628	test: 0.881454
PRC train: 0.922774	val: 0.645632	test: 0.621651

Epoch: 63
Loss: 0.1065943278221533
ROC train: 0.984865	val: 0.734626	test: 0.887311
PRC train: 0.922555	val: 0.628076	test: 0.634482

Epoch: 64
Loss: 0.1106762603453546
ROC train: 0.985276	val: 0.774733	test: 0.892434
PRC train: 0.924185	val: 0.650429	test: 0.645533

Epoch: 65
Loss: 0.1089661189699909
ROC train: 0.984872	val: 0.783088	test: 0.900430
PRC train: 0.923882	val: 0.651159	test: 0.658246

Epoch: 66
Loss: 0.10908235240551156
ROC train: 0.985820	val: 0.786765	test: 0.907518
PRC train: 0.926846	val: 0.636185	test: 0.678187

Epoch: 67
Loss: 0.1062651372758251
ROC train: 0.986601	val: 0.786096	test: 0.903323
PRC train: 0.930650	val: 0.650986	test: 0.676314

Epoch: 68
Loss: 0.1044849014507013
ROC train: 0.986536	val: 0.778075	test: 0.892794
PRC train: 0.931429	val: 0.649882	test: 0.662827

Epoch: 69
Loss: 0.10376227299255483
ROC train: 0.987087	val: 0.769719	test: 0.891401
PRC train: 0.931985	val: 0.647350	test: 0.662842

Epoch: 70
Loss: 0.10315053941538958
ROC train: 0.985618	val: 0.752005	test: 0.878713
PRC train: 0.930213	val: 0.614825	test: 0.698286

Epoch: 71
Loss: 0.09945508962878699
ROC train: 0.985934	val: 0.796457	test: 0.905826
PRC train: 0.931443	val: 0.662759	test: 0.713958

Epoch: 72
Loss: 0.11178391923484923
ROC train: 0.984933	val: 0.822861	test: 0.908117
PRC train: 0.926536	val: 0.671536	test: 0.689443

Epoch: 73
Loss: 0.10361165049019472
ROC train: 0.986024	val: 0.782086	test: 0.897436
PRC train: 0.920626	val: 0.626235	test: 0.649821

Epoch: 74
Loss: 0.09912436459028047
ROC train: 0.987740	val: 0.762366	test: 0.879133
PRC train: 0.933194	val: 0.616928	test: 0.681594

Epoch: 75
Loss: 0.09488959403246733
ROC train: 0.987556	val: 0.773396	test: 0.884494
PRC train: 0.935442	val: 0.641567	test: 0.673742

Epoch: 76
Loss: 0.10098944238441307
ROC train: 0.987782	val: 0.785428	test: 0.885301
PRC train: 0.939522	val: 0.656017	test: 0.691206

Epoch: 77
Loss: 0.10192530271107705
ROC train: 0.986528	val: 0.742313	test: 0.879697
PRC train: 0.932698	val: 0.631874	test: 0.698891

Epoch: 78
Loss: 0.09965456585615504
ROC train: 0.988985	val: 0.737634	test: 0.881019
PRC train: 0.939379	val: 0.625503	test: 0.667907

Epoch: 79
Loss: 0.10026246517928863
ROC train: 0.988029	val: 0.768717	test: 0.886952
PRC train: 0.939120	val: 0.628342	test: 0.669794

Epoch: 80
Loss: 0.11893555950136322
ROC train: 0.986434	val: 0.793783	test: 0.898008
PRC train: 0.933865	val: 0.644682	test: 0.700880

Epoch: 81
Loss: 0.09364091295328243
ROC train: 0.986252	val: 0.778409	test: 0.889977
PRC train: 0.929448	val: 0.629509	test: 0.660042

Epoch: 82
Loss: 0.09580254256495371
ROC train: 0.986364	val: 0.725602	test: 0.869230
PRC train: 0.923762	val: 0.608511	test: 0.656235

Epoch: 83
Loss: 0.09984881565949313
ROC train: 0.987282	val: 0.754345	test: 0.885574
PRC train: 0.931023	val: 0.628531	test: 0.661641

Epoch: 84
Loss: 0.10399683032057891
ROC train: 0.988650	val: 0.764372	test: 0.874832
PRC train: 0.935272	val: 0.631236	test: 0.641835

Epoch: 85
Loss: 0.10814967853490379
ROC train: 0.990473	val: 0.769385	test: 0.855238
PRC train: 0.944936	val: 0.634535	test: 0.642094

Epoch: 86
Loss: 0.09822362640373147
ROC train: 0.990167	val: 0.765040	test: 0.843610
PRC train: 0.944013	val: 0.635344	test: 0.654886

Epoch: 87
Loss: 0.09209771316956059
ROC train: 0.989782	val: 0.781751	test: 0.866411
PRC train: 0.943627	val: 0.644466	test: 0.651034

Epoch: 88
Loss: 0.0880495850829782
ROC train: 0.988667	val: 0.779746	test: 0.883203
PRC train: 0.941018	val: 0.646770	test: 0.656032

Epoch: 89
Loss: 0.10038527860671134
ROC train: 0.989414	val: 0.757019	test: 0.872000
PRC train: 0.943840	val: 0.627412	test: 0.649714

Epoch: 90
Loss: 0.09578261288260818
ROC train: 0.990051	val: 0.769385	test: 0.900911
PRC train: 0.944935	val: 0.639361	test: 0.673780

Epoch: 91
Loss: 0.0946817962176085
ROC train: 0.988649	val: 0.761698	test: 0.906753
PRC train: 0.935795	val: 0.645530	test: 0.660979

Epoch: 92
Loss: 0.09607918010574408
ROC train: 0.989507	val: 0.762032	test: 0.896447
PRC train: 0.938201	val: 0.639209	test: 0.654980

Epoch: 93
Loss: 0.1009354128873929
ROC train: 0.989408	val: 0.773061	test: 0.885123
PRC train: 0.943022	val: 0.645053	test: 0.662528

Epoch: 94
Loss: 0.08956047226820923
ROC train: 0.969699	val: 0.770722	test: 0.912028
PRC train: 0.869219	val: 0.609516	test: 0.702501

Epoch: 34
Loss: 0.14633424061941414
ROC train: 0.974395	val: 0.780749	test: 0.874158
PRC train: 0.877872	val: 0.621100	test: 0.661419

Epoch: 35
Loss: 0.1422389590592979
ROC train: 0.963051	val: 0.809158	test: 0.881185
PRC train: 0.857796	val: 0.648304	test: 0.699579

Epoch: 36
Loss: 0.14074733333477954
ROC train: 0.971668	val: 0.836230	test: 0.904149
PRC train: 0.874383	val: 0.645926	test: 0.674440

Epoch: 37
Loss: 0.143843667813108
ROC train: 0.971130	val: 0.785094	test: 0.898185
PRC train: 0.869378	val: 0.615116	test: 0.682348

Epoch: 38
Loss: 0.13540220700747105
ROC train: 0.971932	val: 0.787767	test: 0.891208
PRC train: 0.882970	val: 0.619089	test: 0.670187

Epoch: 39
Loss: 0.1395811695131459
ROC train: 0.970184	val: 0.794118	test: 0.881859
PRC train: 0.881042	val: 0.614331	test: 0.629937

Epoch: 40
Loss: 0.125329694851472
ROC train: 0.973915	val: 0.802473	test: 0.906636
PRC train: 0.893306	val: 0.623665	test: 0.661364

Epoch: 41
Loss: 0.1310042152285253
ROC train: 0.976598	val: 0.793115	test: 0.926650
PRC train: 0.904270	val: 0.622112	test: 0.694490

Epoch: 42
Loss: 0.12756414656282677
ROC train: 0.977029	val: 0.772727	test: 0.925931
PRC train: 0.906023	val: 0.619438	test: 0.715203

Epoch: 43
Loss: 0.1273554487219166
ROC train: 0.976509	val: 0.767714	test: 0.896153
PRC train: 0.898959	val: 0.618982	test: 0.666021

Epoch: 44
Loss: 0.1325361743133769
ROC train: 0.969894	val: 0.761698	test: 0.893245
PRC train: 0.874268	val: 0.646135	test: 0.681482

Epoch: 45
Loss: 0.13802165631527755
ROC train: 0.976385	val: 0.767714	test: 0.900552
PRC train: 0.889124	val: 0.632052	test: 0.692583

Epoch: 46
Loss: 0.12129500182606123
ROC train: 0.978206	val: 0.777741	test: 0.903070
PRC train: 0.894458	val: 0.636262	test: 0.700957

Epoch: 47
Loss: 0.12723667526550722
ROC train: 0.979550	val: 0.784425	test: 0.902350
PRC train: 0.895454	val: 0.646591	test: 0.671706

Epoch: 48
Loss: 0.13309494360150703
ROC train: 0.979633	val: 0.768717	test: 0.900734
PRC train: 0.900974	val: 0.612160	test: 0.663785

Epoch: 49
Loss: 0.1369863417194102
ROC train: 0.981798	val: 0.766377	test: 0.886050
PRC train: 0.905443	val: 0.601560	test: 0.691093

Epoch: 50
Loss: 0.12673503205096276
ROC train: 0.976567	val: 0.789773	test: 0.896928
PRC train: 0.898551	val: 0.649644	test: 0.683879

Epoch: 51
Loss: 0.12876179222711714
ROC train: 0.980848	val: 0.777406	test: 0.918199
PRC train: 0.912342	val: 0.634641	test: 0.728412

Epoch: 52
Loss: 0.11544346295258057
ROC train: 0.981748	val: 0.766043	test: 0.916162
PRC train: 0.908608	val: 0.616384	test: 0.712842

Epoch: 53
Loss: 0.12184985438588218
ROC train: 0.981789	val: 0.784425	test: 0.925227
PRC train: 0.909375	val: 0.639096	test: 0.696076

Epoch: 54
Loss: 0.1173206618388819
ROC train: 0.982609	val: 0.774733	test: 0.920358
PRC train: 0.913239	val: 0.638004	test: 0.679324

Epoch: 55
Loss: 0.11102190189627134
ROC train: 0.983316	val: 0.766043	test: 0.897618
PRC train: 0.913651	val: 0.608196	test: 0.657724

Epoch: 56
Loss: 0.11402600026536817
ROC train: 0.981662	val: 0.787767	test: 0.923413
PRC train: 0.912591	val: 0.619549	test: 0.674837

Epoch: 57
Loss: 0.10532210854737963
ROC train: 0.975932	val: 0.786765	test: 0.937165
PRC train: 0.912784	val: 0.621997	test: 0.710174

Epoch: 58
Loss: 0.12274655914546542
ROC train: 0.983453	val: 0.766043	test: 0.927487
PRC train: 0.919974	val: 0.612450	test: 0.694626

Epoch: 59
Loss: 0.11651834469656246
ROC train: 0.983633	val: 0.742981	test: 0.913887
PRC train: 0.918281	val: 0.599610	test: 0.702347

Epoch: 60
Loss: 0.11885759719793976
ROC train: 0.985633	val: 0.761029	test: 0.914871
PRC train: 0.929025	val: 0.620328	test: 0.710924

Epoch: 61
Loss: 0.12827780830053662
ROC train: 0.984288	val: 0.782754	test: 0.896716
PRC train: 0.924589	val: 0.629632	test: 0.662216

Epoch: 62
Loss: 0.117963279678751
ROC train: 0.984916	val: 0.764706	test: 0.884809
PRC train: 0.924453	val: 0.618436	test: 0.656919

Epoch: 63
Loss: 0.1067390766204708
ROC train: 0.983562	val: 0.746658	test: 0.871371
PRC train: 0.919704	val: 0.621289	test: 0.673524

Epoch: 64
Loss: 0.10423152107260045
ROC train: 0.985488	val: 0.760027	test: 0.883537
PRC train: 0.922295	val: 0.605852	test: 0.675114

Epoch: 65
Loss: 0.11561691177989333
ROC train: 0.986077	val: 0.759693	test: 0.905172
PRC train: 0.927882	val: 0.591952	test: 0.683456

Epoch: 66
Loss: 0.10318413037748846
ROC train: 0.985372	val: 0.746324	test: 0.898367
PRC train: 0.924481	val: 0.606750	test: 0.652811

Epoch: 67
Loss: 0.12206203352403189
ROC train: 0.985418	val: 0.762032	test: 0.891086
PRC train: 0.925668	val: 0.620038	test: 0.638197

Epoch: 68
Loss: 0.114903401846286
ROC train: 0.985287	val: 0.744318	test: 0.879855
PRC train: 0.924297	val: 0.602260	test: 0.656119

Epoch: 69
Loss: 0.10270672572361532
ROC train: 0.986670	val: 0.752340	test: 0.920657
PRC train: 0.930697	val: 0.598004	test: 0.714356

Epoch: 70
Loss: 0.10774369203339547
ROC train: 0.987026	val: 0.762366	test: 0.938989
PRC train: 0.932070	val: 0.606416	test: 0.750959

Epoch: 71
Loss: 0.09780872943354257
ROC train: 0.987778	val: 0.760361	test: 0.911547
PRC train: 0.934553	val: 0.600509	test: 0.686313

Epoch: 72
Loss: 0.10314279135588708
ROC train: 0.986302	val: 0.756350	test: 0.899624
PRC train: 0.927820	val: 0.605304	test: 0.669495

Epoch: 73
Loss: 0.1078724260937846
ROC train: 0.986831	val: 0.789439	test: 0.923560
PRC train: 0.931149	val: 0.632323	test: 0.696284

Epoch: 74
Loss: 0.09827391990929468
ROC train: 0.987037	val: 0.792112	test: 0.917926
PRC train: 0.931553	val: 0.619070	test: 0.693458

Epoch: 75
Loss: 0.08878284967131381
ROC train: 0.988028	val: 0.792112	test: 0.883714
PRC train: 0.934428	val: 0.617349	test: 0.656003

Epoch: 76
Loss: 0.10073503125040466
ROC train: 0.988309	val: 0.770388	test: 0.879281
PRC train: 0.937034	val: 0.630691	test: 0.669032

Epoch: 77
Loss: 0.08702215717873421
ROC train: 0.988919	val: 0.764372	test: 0.895084
PRC train: 0.939366	val: 0.611982	test: 0.675078

Epoch: 78
Loss: 0.0922588464463534
ROC train: 0.988750	val: 0.753342	test: 0.908041
PRC train: 0.934787	val: 0.640378	test: 0.684084

Epoch: 79
Loss: 0.10324304198089114
ROC train: 0.989958	val: 0.753342	test: 0.918438
PRC train: 0.940898	val: 0.607069	test: 0.686023

Epoch: 80
Loss: 0.11541941533093744
ROC train: 0.989330	val: 0.763703	test: 0.908608
PRC train: 0.940152	val: 0.625436	test: 0.674001

Epoch: 81
Loss: 0.10384739839284776
ROC train: 0.986530	val: 0.759358	test: 0.909854
PRC train: 0.929498	val: 0.624275	test: 0.691365

Epoch: 82
Loss: 0.1070010367621482
ROC train: 0.985333	val: 0.762701	test: 0.892374
PRC train: 0.924244	val: 0.595388	test: 0.665251

Epoch: 83
Loss: 0.1142643591350215
ROC train: 0.988167	val: 0.763369	test: 0.893812
PRC train: 0.939871	val: 0.601235	test: 0.639642

Epoch: 84
Loss: 0.10208858578022015
ROC train: 0.987637	val: 0.738971	test: 0.902573
PRC train: 0.937828	val: 0.587723	test: 0.657362

Epoch: 85
Loss: 0.095307459945638
ROC train: 0.987400	val: 0.750668	test: 0.919786
PRC train: 0.933642	val: 0.600015	test: 0.678735

Epoch: 86
Loss: 0.09793307207898436
ROC train: 0.988453	val: 0.753008	test: 0.893691
PRC train: 0.936983	val: 0.586754	test: 0.677008

Epoch: 87
Loss: 0.10220767241218265
ROC train: 0.989425	val: 0.747660	test: 0.881318
PRC train: 0.945057	val: 0.580264	test: 0.697436

Epoch: 88
Loss: 0.09582680320890384
ROC train: 0.988614	val: 0.749332	test: 0.904610
PRC train: 0.939613	val: 0.585152	test: 0.685663

Epoch: 89
Loss: 0.10250591577196458
ROC train: 0.989930	val: 0.712901	test: 0.864613
PRC train: 0.945051	val: 0.569202	test: 0.667570

Epoch: 90
Loss: 0.10114636518899649
ROC train: 0.990397	val: 0.708556	test: 0.890575
PRC train: 0.947938	val: 0.576036	test: 0.662849

Epoch: 91
Loss: 0.09623010165781216
ROC train: 0.990569	val: 0.740642	test: 0.907655
PRC train: 0.949165	val: 0.626448	test: 0.666928

Epoch: 92
Loss: 0.09500023796909565
ROC train: 0.990096	val: 0.741979	test: 0.911967
PRC train: 0.945690	val: 0.600161	test: 0.704396

Epoch: 93
Loss: 0.08525684464593833
ROC train: 0.990550	val: 0.739973	test: 0.914455
PRC train: 0.947329	val: 0.595210	test: 0.711868

Epoch: 94
Loss: 0.10242850004360282
ROC train: 0.992403	val: 0.734634	test: 0.797423
PRC train: 0.952509	val: 0.575272	test: 0.656820

Epoch: 95
Loss: 0.08109356271924134
ROC train: 0.991099	val: 0.722014	test: 0.802518
PRC train: 0.953484	val: 0.573656	test: 0.626589

Epoch: 96
Loss: 0.09546393562726453
ROC train: 0.993106	val: 0.714781	test: 0.821472
PRC train: 0.963894	val: 0.572376	test: 0.668722

Epoch: 97
Loss: 0.0874335028038491
ROC train: 0.992846	val: 0.713974	test: 0.827446
PRC train: 0.958863	val: 0.567784	test: 0.649993

Epoch: 98
Loss: 0.0918556517373968
ROC train: 0.993321	val: 0.723148	test: 0.829510
PRC train: 0.961262	val: 0.570920	test: 0.650974

Epoch: 99
Loss: 0.09228102734703679
ROC train: 0.993187	val: 0.736349	test: 0.815451
PRC train: 0.956814	val: 0.582207	test: 0.622700

Epoch: 100
Loss: 0.08281917373290645
ROC train: 0.993084	val: 0.741099	test: 0.839448
PRC train: 0.958132	val: 0.593276	test: 0.631345

Epoch: 101
Loss: 0.08455027590986612
ROC train: 0.991164	val: 0.735737	test: 0.843293
PRC train: 0.948784	val: 0.587002	test: 0.630312

Epoch: 102
Loss: 0.09059018443764894
ROC train: 0.992789	val: 0.723847	test: 0.859075
PRC train: 0.959197	val: 0.580539	test: 0.649657

Epoch: 103
Loss: 0.06584204658530377
ROC train: 0.993132	val: 0.724950	test: 0.856248
PRC train: 0.957443	val: 0.585864	test: 0.649756

Epoch: 104
Loss: 0.07822504430820287
ROC train: 0.993375	val: 0.730572	test: 0.840506
PRC train: 0.958024	val: 0.586238	test: 0.637456

Epoch: 105
Loss: 0.06616254466265098
ROC train: 0.993898	val: 0.735370	test: 0.826248
PRC train: 0.963297	val: 0.585579	test: 0.638906

Epoch: 106
Loss: 0.07291148219615128
ROC train: 0.994284	val: 0.735639	test: 0.825422
PRC train: 0.966026	val: 0.577998	test: 0.659481

Epoch: 107
Loss: 0.0872024224794825
ROC train: 0.994064	val: 0.731627	test: 0.825695
PRC train: 0.965221	val: 0.576767	test: 0.658842

Epoch: 108
Loss: 0.09611164825557711
ROC train: 0.993983	val: 0.729790	test: 0.833328
PRC train: 0.964926	val: 0.583244	test: 0.642687

Epoch: 109
Loss: 0.07121818360496043
ROC train: 0.993684	val: 0.736997	test: 0.844205
PRC train: 0.961502	val: 0.589382	test: 0.638016

Epoch: 110
Loss: 0.08433128541721613
ROC train: 0.993712	val: 0.733700	test: 0.854620
PRC train: 0.964065	val: 0.585292	test: 0.641316

Epoch: 111
Loss: 0.06941189746677845
ROC train: 0.992230	val: 0.727919	test: 0.850088
PRC train: 0.960587	val: 0.580641	test: 0.635267

Epoch: 112
Loss: 0.08564464866375812
ROC train: 0.991087	val: 0.729469	test: 0.844555
PRC train: 0.956860	val: 0.579475	test: 0.633904

Epoch: 113
Loss: 0.08488805374051189
ROC train: 0.991881	val: 0.739021	test: 0.844238
PRC train: 0.959542	val: 0.581152	test: 0.642372

Epoch: 114
Loss: 0.07604659003409885
ROC train: 0.993197	val: 0.732624	test: 0.845293
PRC train: 0.959541	val: 0.578480	test: 0.634054

Epoch: 115
Loss: 0.07039368484241632
ROC train: 0.993749	val: 0.721270	test: 0.837693
PRC train: 0.960494	val: 0.577204	test: 0.626573

Epoch: 116
Loss: 0.07920933132542243
ROC train: 0.993269	val: 0.706372	test: 0.844578
PRC train: 0.959591	val: 0.565318	test: 0.633003

Epoch: 117
Loss: 0.07968386163561214
ROC train: 0.993372	val: 0.687378	test: 0.826725
PRC train: 0.959472	val: 0.560197	test: 0.624419

Epoch: 118
Loss: 0.07850950770503967
ROC train: 0.990855	val: 0.705045	test: 0.805618
PRC train: 0.954435	val: 0.573423	test: 0.609445

Epoch: 119
Loss: 0.08874954469368299
ROC train: 0.993980	val: 0.726635	test: 0.830506
PRC train: 0.962109	val: 0.581341	test: 0.622996

Epoch: 120
Loss: 0.0803373190867459
ROC train: 0.993680	val: 0.713943	test: 0.848177
PRC train: 0.966492	val: 0.574642	test: 0.656032

Early stopping
Best (ROC):	 train: 0.986488	val: 0.780645	test: 0.815793
Best (PRC):	 train: 0.927065	val: 0.599022	test: 0.634967

ROC train: 0.993177	val: 0.738582	test: 0.839301
PRC train: 0.963904	val: 0.579963	test: 0.646304

Epoch: 95
Loss: 0.07765333016904155
ROC train: 0.992729	val: 0.729386	test: 0.831008
PRC train: 0.960368	val: 0.580968	test: 0.646024

Epoch: 96
Loss: 0.08437884593487244
ROC train: 0.992719	val: 0.730255	test: 0.811657
PRC train: 0.957590	val: 0.577473	test: 0.631894

Epoch: 97
Loss: 0.08407249830430337
ROC train: 0.991477	val: 0.730576	test: 0.809857
PRC train: 0.951686	val: 0.573968	test: 0.617974

Epoch: 98
Loss: 0.08709339854805416
ROC train: 0.991624	val: 0.722509	test: 0.811687
PRC train: 0.954291	val: 0.573396	test: 0.631175

Epoch: 99
Loss: 0.0863761676498942
ROC train: 0.992956	val: 0.721307	test: 0.822544
PRC train: 0.959916	val: 0.574741	test: 0.647764

Epoch: 100
Loss: 0.08470721717963284
ROC train: 0.993232	val: 0.718776	test: 0.814966
PRC train: 0.959093	val: 0.570891	test: 0.644787

Epoch: 101
Loss: 0.08358775725230533
ROC train: 0.992243	val: 0.703157	test: 0.807177
PRC train: 0.953399	val: 0.569524	test: 0.632181

Epoch: 102
Loss: 0.08593176855655987
ROC train: 0.992140	val: 0.703081	test: 0.815247
PRC train: 0.953007	val: 0.572030	test: 0.627202

Epoch: 103
Loss: 0.07747788550288837
ROC train: 0.993260	val: 0.703202	test: 0.824407
PRC train: 0.958648	val: 0.573249	test: 0.629148

Epoch: 104
Loss: 0.08404698345699875
ROC train: 0.994125	val: 0.701400	test: 0.832122
PRC train: 0.961631	val: 0.577639	test: 0.644369

Epoch: 105
Loss: 0.08565167669390594
ROC train: 0.993821	val: 0.711544	test: 0.833328
PRC train: 0.959882	val: 0.583501	test: 0.647264

Epoch: 106
Loss: 0.08295437497249859
ROC train: 0.990971	val: 0.730032	test: 0.816808
PRC train: 0.951996	val: 0.580521	test: 0.638978

Epoch: 107
Loss: 0.07526998170506638
ROC train: 0.992884	val: 0.752293	test: 0.812792
PRC train: 0.957631	val: 0.579546	test: 0.625714

Epoch: 108
Loss: 0.07377895787819544
ROC train: 0.992228	val: 0.755527	test: 0.817495
PRC train: 0.957256	val: 0.583562	test: 0.625857

Epoch: 109
Loss: 0.07634593093228771
ROC train: 0.993081	val: 0.741770	test: 0.817302
PRC train: 0.963316	val: 0.574989	test: 0.631101

Epoch: 110
Loss: 0.09779540342422874
ROC train: 0.993207	val: 0.726933	test: 0.814578
PRC train: 0.962405	val: 0.568620	test: 0.630523

Epoch: 111
Loss: 0.06928278654991853
ROC train: 0.994375	val: 0.712662	test: 0.779185
PRC train: 0.965728	val: 0.566177	test: 0.620555

Epoch: 112
Loss: 0.07163481353519345
ROC train: 0.994324	val: 0.710920	test: 0.753564
PRC train: 0.964324	val: 0.568184	test: 0.612434

Epoch: 113
Loss: 0.09611262508933241
ROC train: 0.993078	val: 0.722785	test: 0.793404
PRC train: 0.964189	val: 0.574843	test: 0.628532

Epoch: 114
Loss: 0.07324461504650073
ROC train: 0.993048	val: 0.731906	test: 0.820939
PRC train: 0.963652	val: 0.581023	test: 0.639880

Epoch: 115
Loss: 0.08238564049325356
ROC train: 0.994158	val: 0.734554	test: 0.836985
PRC train: 0.965832	val: 0.586435	test: 0.644538

Epoch: 116
Loss: 0.07105711207301885
ROC train: 0.994335	val: 0.734887	test: 0.845577
PRC train: 0.968583	val: 0.592455	test: 0.650013

Epoch: 117
Loss: 0.08829378790908418
ROC train: 0.994119	val: 0.733950	test: 0.831483
PRC train: 0.966615	val: 0.589403	test: 0.641064

Epoch: 118
Loss: 0.07983934206308155
ROC train: 0.993131	val: 0.720059	test: 0.809224
PRC train: 0.961229	val: 0.579724	test: 0.631881

Epoch: 119
Loss: 0.06952980608300681
ROC train: 0.993999	val: 0.702794	test: 0.807511
PRC train: 0.967021	val: 0.581821	test: 0.631169

Epoch: 120
Loss: 0.07277593454143644
ROC train: 0.994189	val: 0.701832	test: 0.797218
PRC train: 0.966271	val: 0.564317	test: 0.623235

Early stopping
Best (ROC):	 train: 0.987286	val: 0.772770	test: 0.817440
Best (PRC):	 train: 0.926819	val: 0.584740	test: 0.631897

ROC train: 0.992400	val: 0.728141	test: 0.833765
PRC train: 0.958542	val: 0.570146	test: 0.637076

Epoch: 95
Loss: 0.07590133867040724
ROC train: 0.993099	val: 0.729030	test: 0.831532
PRC train: 0.957331	val: 0.574030	test: 0.628031

Epoch: 96
Loss: 0.08963902193589424
ROC train: 0.993301	val: 0.729083	test: 0.837361
PRC train: 0.957235	val: 0.571631	test: 0.631695

Epoch: 97
Loss: 0.07727697212530191
ROC train: 0.992886	val: 0.722290	test: 0.848781
PRC train: 0.955177	val: 0.569221	test: 0.644028

Epoch: 98
Loss: 0.0770701033177258
ROC train: 0.993518	val: 0.726197	test: 0.849113
PRC train: 0.958167	val: 0.585606	test: 0.646956

Epoch: 99
Loss: 0.09228632350378449
ROC train: 0.994342	val: 0.716260	test: 0.846453
PRC train: 0.962604	val: 0.572434	test: 0.646949

Epoch: 100
Loss: 0.0875982645870666
ROC train: 0.992807	val: 0.705521	test: 0.825862
PRC train: 0.957467	val: 0.566552	test: 0.619534

Epoch: 101
Loss: 0.08428604051975142
ROC train: 0.992857	val: 0.700655	test: 0.809867
PRC train: 0.958383	val: 0.563713	test: 0.611420

Epoch: 102
Loss: 0.0768890158290626
ROC train: 0.993469	val: 0.714083	test: 0.826776
PRC train: 0.961623	val: 0.566006	test: 0.621563

Epoch: 103
Loss: 0.08812662250638248
ROC train: 0.993274	val: 0.719546	test: 0.848485
PRC train: 0.960012	val: 0.565663	test: 0.640713

Epoch: 104
Loss: 0.1005053411767489
ROC train: 0.993006	val: 0.721403	test: 0.854631
PRC train: 0.961355	val: 0.568814	test: 0.645062

Epoch: 105
Loss: 0.08078300913126359
ROC train: 0.993463	val: 0.716994	test: 0.843688
PRC train: 0.963743	val: 0.569103	test: 0.638205

Epoch: 106
Loss: 0.08322891124465495
ROC train: 0.993547	val: 0.719856	test: 0.815545
PRC train: 0.964552	val: 0.567034	test: 0.621469

Epoch: 107
Loss: 0.07761727658241073
ROC train: 0.993636	val: 0.719374	test: 0.803667
PRC train: 0.963607	val: 0.569169	test: 0.607594

Epoch: 108
Loss: 0.07714925707212283
ROC train: 0.994716	val: 0.714510	test: 0.828100
PRC train: 0.969030	val: 0.566834	test: 0.620958

Epoch: 109
Loss: 0.08695266014158097
ROC train: 0.994106	val: 0.712821	test: 0.830979
PRC train: 0.967247	val: 0.567423	test: 0.620878

Epoch: 110
Loss: 0.08078187044824225
ROC train: 0.994426	val: 0.708771	test: 0.821424
PRC train: 0.967656	val: 0.564931	test: 0.615202

Epoch: 111
Loss: 0.08836762795289846
ROC train: 0.994222	val: 0.704041	test: 0.826679
PRC train: 0.968051	val: 0.563665	test: 0.622891

Epoch: 112
Loss: 0.1005979653469906
ROC train: 0.994130	val: 0.708210	test: 0.829585
PRC train: 0.968749	val: 0.568621	test: 0.622117

Epoch: 113
Loss: 0.07260600353846275
ROC train: 0.994822	val: 0.717869	test: 0.839580
PRC train: 0.969291	val: 0.570126	test: 0.622230

Epoch: 114
Loss: 0.0692944504076208
ROC train: 0.994490	val: 0.716830	test: 0.848815
PRC train: 0.966123	val: 0.564947	test: 0.638915

Epoch: 115
Loss: 0.07386852720558525
ROC train: 0.994307	val: 0.719324	test: 0.851773
PRC train: 0.967270	val: 0.564701	test: 0.644819

Epoch: 116
Loss: 0.0676544116012164
ROC train: 0.994648	val: 0.717061	test: 0.839777
PRC train: 0.970434	val: 0.566051	test: 0.640502

Epoch: 117
Loss: 0.06884267982838269
ROC train: 0.994617	val: 0.705622	test: 0.821958
PRC train: 0.971225	val: 0.568696	test: 0.631437

Epoch: 118
Loss: 0.07382967463450725
ROC train: 0.994809	val: 0.702835	test: 0.824319
PRC train: 0.971025	val: 0.571001	test: 0.621318

Epoch: 119
Loss: 0.08236555287029708
ROC train: 0.995357	val: 0.712953	test: 0.810820
PRC train: 0.971379	val: 0.582136	test: 0.610207

Epoch: 120
Loss: 0.07093899774554935
ROC train: 0.995082	val: 0.714680	test: 0.812828
PRC train: 0.969450	val: 0.583830	test: 0.608229

Early stopping
Best (ROC):	 train: 0.987979	val: 0.785305	test: 0.841944
Best (PRC):	 train: 0.934908	val: 0.579933	test: 0.644253
All runs completed.

ROC train: 0.958092	val: 0.645324	test: 0.883134
PRC train: 0.844800	val: 0.556820	test: 0.638933

Epoch: 95
Loss: 0.12832159002248195
ROC train: 0.958240	val: 0.642946	test: 0.902606
PRC train: 0.855801	val: 0.548868	test: 0.662911

Epoch: 96
Loss: 0.1518904766625664
ROC train: 0.967148	val: 0.647634	test: 0.929610
PRC train: 0.878693	val: 0.553551	test: 0.700376

Epoch: 97
Loss: 0.13944844024589517
ROC train: 0.958071	val: 0.651970	test: 0.939357
PRC train: 0.858205	val: 0.572510	test: 0.772101

Epoch: 98
Loss: 0.11670857186083294
ROC train: 0.950575	val: 0.646126	test: 0.936253
PRC train: 0.842461	val: 0.578272	test: 0.766701

Epoch: 99
Loss: 0.15358582920838776
ROC train: 0.966948	val: 0.661334	test: 0.934576
PRC train: 0.880684	val: 0.582093	test: 0.713382

Epoch: 100
Loss: 0.17261091424218353
ROC train: 0.965804	val: 0.656568	test: 0.939202
PRC train: 0.870878	val: 0.576552	test: 0.698291

Epoch: 101
Loss: 0.12305865668280477
ROC train: 0.965283	val: 0.648322	test: 0.930764
PRC train: 0.868539	val: 0.575614	test: 0.677101

Epoch: 102
Loss: 0.17472545748464066
ROC train: 0.965320	val: 0.637436	test: 0.887012
PRC train: 0.866626	val: 0.578504	test: 0.672310

Epoch: 103
Loss: 0.14185209975203852
ROC train: 0.954600	val: 0.632992	test: 0.808105
PRC train: 0.854160	val: 0.568952	test: 0.647897

Epoch: 104
Loss: 0.1290781336518858
ROC train: 0.952098	val: 0.658357	test: 0.808574
PRC train: 0.854570	val: 0.572410	test: 0.622031

Epoch: 105
Loss: 0.13985037069107512
ROC train: 0.966523	val: 0.666316	test: 0.875110
PRC train: 0.869262	val: 0.582102	test: 0.641639

Epoch: 106
Loss: 0.1381463481235242
ROC train: 0.964313	val: 0.684397	test: 0.897938
PRC train: 0.845021	val: 0.573488	test: 0.649059

Epoch: 107
Loss: 0.1775463758791937
ROC train: 0.965876	val: 0.685969	test: 0.908994
PRC train: 0.854156	val: 0.579165	test: 0.665525

Epoch: 108
Loss: 0.11811805231861532
ROC train: 0.962586	val: 0.672349	test: 0.905693
PRC train: 0.865121	val: 0.595650	test: 0.659430

Epoch: 109
Loss: 0.23562276512335606
ROC train: 0.962463	val: 0.659222	test: 0.901768
PRC train: 0.875655	val: 0.596596	test: 0.672837

Epoch: 110
Loss: 0.12501266814488324
ROC train: 0.965092	val: 0.630055	test: 0.910116
PRC train: 0.883681	val: 0.578968	test: 0.665576

Epoch: 111
Loss: 0.12195788856178122
ROC train: 0.967758	val: 0.618040	test: 0.924638
PRC train: 0.892192	val: 0.565310	test: 0.688836

Epoch: 112
Loss: 0.11625619652165364
ROC train: 0.970604	val: 0.608285	test: 0.918693
PRC train: 0.896010	val: 0.553950	test: 0.680914

Epoch: 113
Loss: 0.10774376834465585
ROC train: 0.972644	val: 0.625047	test: 0.914357
PRC train: 0.896034	val: 0.557516	test: 0.687513

Epoch: 114
Loss: 0.12014607161418552
ROC train: 0.970082	val: 0.649685	test: 0.894339
PRC train: 0.889737	val: 0.574761	test: 0.664711

Epoch: 115
Loss: 0.12990082937728137
ROC train: 0.969774	val: 0.671145	test: 0.887630
PRC train: 0.889777	val: 0.583091	test: 0.641572

Epoch: 116
Loss: 0.11921781087495202
ROC train: 0.971367	val: 0.663087	test: 0.918003
PRC train: 0.890140	val: 0.595260	test: 0.667684

Epoch: 117
Loss: 0.10921535460209797
ROC train: 0.968573	val: 0.663047	test: 0.909799
PRC train: 0.882620	val: 0.589322	test: 0.659608

Epoch: 118
Loss: 0.11437454689939945
ROC train: 0.971345	val: 0.678690	test: 0.916161
PRC train: 0.887683	val: 0.599895	test: 0.660098

Epoch: 119
Loss: 0.15421285868780762
ROC train: 0.969235	val: 0.683910	test: 0.930080
PRC train: 0.880918	val: 0.592133	test: 0.676422

Epoch: 120
Loss: 0.13601432447890044
ROC train: 0.966837	val: 0.666476	test: 0.930598
PRC train: 0.875996	val: 0.588655	test: 0.678088

Early stopping
Best (ROC):	 train: 0.930084	val: 0.715060	test: 0.886658
Best (PRC):	 train: 0.789188	val: 0.587656	test: 0.642717

ROC train: 0.936367	val: 0.682180	test: 0.887106
PRC train: 0.795028	val: 0.559250	test: 0.677721

Epoch: 95
Loss: 0.1347812718822971
ROC train: 0.948125	val: 0.681484	test: 0.908481
PRC train: 0.813141	val: 0.557824	test: 0.695808

Epoch: 96
Loss: 0.18107021930281625
ROC train: 0.959802	val: 0.692873	test: 0.924856
PRC train: 0.833897	val: 0.554529	test: 0.701114

Epoch: 97
Loss: 0.1646060705043087
ROC train: 0.951946	val: 0.680747	test: 0.917091
PRC train: 0.815432	val: 0.554072	test: 0.694012

Epoch: 98
Loss: 0.14777059465212275
ROC train: 0.948483	val: 0.689948	test: 0.909752
PRC train: 0.805627	val: 0.561977	test: 0.701180

Epoch: 99
Loss: 0.17716248337900103
ROC train: 0.945873	val: 0.692660	test: 0.912636
PRC train: 0.810343	val: 0.579044	test: 0.704559

Epoch: 100
Loss: 0.12852486650021264
ROC train: 0.943463	val: 0.659362	test: 0.902317
PRC train: 0.811620	val: 0.570348	test: 0.691734

Epoch: 101
Loss: 0.12810988118386143
ROC train: 0.947609	val: 0.653083	test: 0.892714
PRC train: 0.820864	val: 0.566110	test: 0.694826

Epoch: 102
Loss: 0.13894262535667484
ROC train: 0.956304	val: 0.673608	test: 0.902317
PRC train: 0.835501	val: 0.568490	test: 0.702233

Epoch: 103
Loss: 0.12842121399669296
ROC train: 0.950159	val: 0.678329	test: 0.906291
PRC train: 0.821292	val: 0.568194	test: 0.677302

Epoch: 104
Loss: 0.12224563019895433
ROC train: 0.950799	val: 0.682418	test: 0.909773
PRC train: 0.822133	val: 0.569908	test: 0.688961

Epoch: 105
Loss: 0.13060958703129139
ROC train: 0.957111	val: 0.684874	test: 0.919867
PRC train: 0.830564	val: 0.568076	test: 0.701390

Epoch: 106
Loss: 0.1824559048882179
ROC train: 0.960665	val: 0.686804	test: 0.922944
PRC train: 0.837381	val: 0.567703	test: 0.706225

Epoch: 107
Loss: 0.12988650634451232
ROC train: 0.960371	val: 0.706804	test: 0.915104
PRC train: 0.833860	val: 0.572097	test: 0.698733

Epoch: 108
Loss: 0.14292538505369706
ROC train: 0.957131	val: 0.709877	test: 0.900576
PRC train: 0.822837	val: 0.578556	test: 0.676504

Epoch: 109
Loss: 0.17513612441022144
ROC train: 0.963125	val: 0.697042	test: 0.916044
PRC train: 0.838250	val: 0.575708	test: 0.698100

Epoch: 110
Loss: 0.13236962502983515
ROC train: 0.955332	val: 0.674886	test: 0.893366
PRC train: 0.809683	val: 0.566339	test: 0.692483

Epoch: 111
Loss: 0.12942393265025728
ROC train: 0.946601	val: 0.660957	test: 0.892265
PRC train: 0.786351	val: 0.556456	test: 0.668808

Epoch: 112
Loss: 0.19013376454916536
ROC train: 0.950638	val: 0.680170	test: 0.899465
PRC train: 0.795404	val: 0.561085	test: 0.677154

Epoch: 113
Loss: 0.1878895613345824
ROC train: 0.947978	val: 0.678748	test: 0.887929
PRC train: 0.792814	val: 0.556550	test: 0.656793

Epoch: 114
Loss: 0.14635353763766032
ROC train: 0.953026	val: 0.673189	test: 0.882108
PRC train: 0.799637	val: 0.559520	test: 0.685716

Epoch: 115
Loss: 0.14370070883663266
ROC train: 0.954866	val: 0.645115	test: 0.891780
PRC train: 0.817141	val: 0.562834	test: 0.699581

Epoch: 116
Loss: 0.13004897096043944
ROC train: 0.942628	val: 0.620260	test: 0.875852
PRC train: 0.808121	val: 0.552892	test: 0.697691

Epoch: 117
Loss: 0.14565115471314027
ROC train: 0.953356	val: 0.643656	test: 0.887779
PRC train: 0.833281	val: 0.555277	test: 0.712009

Epoch: 118
Loss: 0.13361559911112703
ROC train: 0.961864	val: 0.653535	test: 0.888270
PRC train: 0.839035	val: 0.553898	test: 0.682879

Epoch: 119
Loss: 0.16986790073694474
ROC train: 0.962918	val: 0.666034	test: 0.892404
PRC train: 0.842934	val: 0.558422	test: 0.680208

Epoch: 120
Loss: 0.2132474249026135
ROC train: 0.959148	val: 0.685885	test: 0.889232
PRC train: 0.838385	val: 0.562910	test: 0.697012

Early stopping
Best (ROC):	 train: 0.924280	val: 0.743313	test: 0.859569
Best (PRC):	 train: 0.751457	val: 0.598249	test: 0.623868

ROC train: 0.945059	val: 0.686853	test: 0.866245
PRC train: 0.796037	val: 0.561758	test: 0.665515

Epoch: 95
Loss: 0.14763211526190254
ROC train: 0.926349	val: 0.659626	test: 0.834744
PRC train: 0.784958	val: 0.561897	test: 0.638327

Epoch: 96
Loss: 0.18036920838850562
ROC train: 0.942943	val: 0.659096	test: 0.862394
PRC train: 0.806232	val: 0.571763	test: 0.671298

Epoch: 97
Loss: 0.1459600639665694
ROC train: 0.945314	val: 0.673948	test: 0.879181
PRC train: 0.802111	val: 0.574879	test: 0.673973

Epoch: 98
Loss: 0.1688084963824727
ROC train: 0.950792	val: 0.668593	test: 0.899871
PRC train: 0.809851	val: 0.569887	test: 0.687984

Epoch: 99
Loss: 0.13861890681290148
ROC train: 0.950283	val: 0.668635	test: 0.902808
PRC train: 0.816315	val: 0.565022	test: 0.695023

Epoch: 100
Loss: 0.15752557446344304
ROC train: 0.947277	val: 0.664257	test: 0.894807
PRC train: 0.817819	val: 0.580120	test: 0.711640

Epoch: 101
Loss: 0.1654740294845412
ROC train: 0.939855	val: 0.650870	test: 0.893852
PRC train: 0.810490	val: 0.574062	test: 0.745195

Epoch: 102
Loss: 0.14783220629137503
ROC train: 0.948100	val: 0.683229	test: 0.895343
PRC train: 0.817921	val: 0.557775	test: 0.700502

Epoch: 103
Loss: 0.12950494498565385
ROC train: 0.934710	val: 0.701869	test: 0.865659
PRC train: 0.795672	val: 0.562469	test: 0.680722

Epoch: 104
Loss: 0.13692380142748245
ROC train: 0.941318	val: 0.710990	test: 0.858214
PRC train: 0.810772	val: 0.575880	test: 0.679506

Epoch: 105
Loss: 0.13197553245777655
ROC train: 0.955003	val: 0.703747	test: 0.898965
PRC train: 0.836754	val: 0.580644	test: 0.708042

Epoch: 106
Loss: 0.12043620232481429
ROC train: 0.961411	val: 0.692805	test: 0.929183
PRC train: 0.849482	val: 0.581976	test: 0.733994

Epoch: 107
Loss: 0.14865209196211593
ROC train: 0.963229	val: 0.673095	test: 0.932590
PRC train: 0.855783	val: 0.569698	test: 0.722622

Epoch: 108
Loss: 0.35410949325378677
ROC train: 0.962701	val: 0.653047	test: 0.920300
PRC train: 0.854655	val: 0.563353	test: 0.705686

Epoch: 109
Loss: 0.1630060207817344
ROC train: 0.927610	val: 0.603039	test: 0.880132
PRC train: 0.798489	val: 0.551673	test: 0.663802

Epoch: 110
Loss: 0.14627093538987426
ROC train: 0.907089	val: 0.599452	test: 0.866023
PRC train: 0.760568	val: 0.559114	test: 0.678975

Epoch: 111
Loss: 0.17243835398950152
ROC train: 0.932114	val: 0.600833	test: 0.886884
PRC train: 0.807430	val: 0.554626	test: 0.698546

Epoch: 112
Loss: 0.130947617188705
ROC train: 0.935989	val: 0.601207	test: 0.884266
PRC train: 0.813811	val: 0.543227	test: 0.675631

Epoch: 113
Loss: 0.1446193897532948
ROC train: 0.938764	val: 0.608743	test: 0.900690
PRC train: 0.807345	val: 0.542274	test: 0.690539

Epoch: 114
Loss: 0.13259225707918518
ROC train: 0.947118	val: 0.627323	test: 0.908685
PRC train: 0.816470	val: 0.543780	test: 0.697065

Epoch: 115
Loss: 0.145038527594535
ROC train: 0.953104	val: 0.653219	test: 0.913192
PRC train: 0.837797	val: 0.554389	test: 0.700719

Epoch: 116
Loss: 0.1564925562074161
ROC train: 0.951825	val: 0.668165	test: 0.907616
PRC train: 0.840441	val: 0.564045	test: 0.689702

Epoch: 117
Loss: 0.11325578743521365
ROC train: 0.954743	val: 0.676813	test: 0.920210
PRC train: 0.842698	val: 0.571130	test: 0.706585

Epoch: 118
Loss: 0.13691583563533818
ROC train: 0.954381	val: 0.689255	test: 0.929055
PRC train: 0.837918	val: 0.575125	test: 0.715250

Epoch: 119
Loss: 0.12385211464961646
ROC train: 0.949725	val: 0.679034	test: 0.935127
PRC train: 0.835388	val: 0.570731	test: 0.723757

Epoch: 120
Loss: 0.14226659658120427
ROC train: 0.949826	val: 0.663219	test: 0.935698
PRC train: 0.838305	val: 0.566065	test: 0.721280

Epoch: 121
Loss: 0.17911422433566315
ROC train: 0.944655	val: 0.647743	test: 0.927004
PRC train: 0.839161	val: 0.554461	test: 0.715132

Early stopping
Best (ROC):	 train: 0.940449	val: 0.753600	test: 0.885360
Best (PRC):	 train: 0.812665	val: 0.588814	test: 0.663842
All runs completed.

ROC train: 0.990872	val: 0.738971	test: 0.914435
PRC train: 0.941443	val: 0.589002	test: 0.723103

Epoch: 95
Loss: 0.10165024040883139
ROC train: 0.990755	val: 0.748997	test: 0.910483
PRC train: 0.939863	val: 0.587743	test: 0.696413

Epoch: 96
Loss: 0.08980331781887416
ROC train: 0.990790	val: 0.738971	test: 0.923875
PRC train: 0.943746	val: 0.594210	test: 0.709917

Epoch: 97
Loss: 0.09893764765555961
ROC train: 0.990282	val: 0.718583	test: 0.916670
PRC train: 0.941024	val: 0.586483	test: 0.702457

Epoch: 98
Loss: 0.09728505586781394
ROC train: 0.991110	val: 0.699532	test: 0.892794
PRC train: 0.944151	val: 0.575037	test: 0.680216

Epoch: 99
Loss: 0.09238966417895253
ROC train: 0.991514	val: 0.710561	test: 0.920251
PRC train: 0.948597	val: 0.591396	test: 0.691803

Epoch: 100
Loss: 0.0879024560860033
ROC train: 0.991556	val: 0.732955	test: 0.906110
PRC train: 0.949139	val: 0.595824	test: 0.680634

Epoch: 101
Loss: 0.08349739772433043
ROC train: 0.991874	val: 0.738302	test: 0.894649
PRC train: 0.950270	val: 0.591367	test: 0.680323

Epoch: 102
Loss: 0.08265560716555942
ROC train: 0.992035	val: 0.742313	test: 0.901033
PRC train: 0.952190	val: 0.594388	test: 0.677832

Epoch: 103
Loss: 0.07455245276856859
ROC train: 0.991637	val: 0.736297	test: 0.885842
PRC train: 0.951275	val: 0.596858	test: 0.665185

Epoch: 104
Loss: 0.09127396888960412
ROC train: 0.991956	val: 0.731283	test: 0.883714
PRC train: 0.953848	val: 0.586404	test: 0.677422

Epoch: 105
Loss: 0.08432703255066648
ROC train: 0.992475	val: 0.723930	test: 0.885929
PRC train: 0.954513	val: 0.578858	test: 0.689309

Epoch: 106
Loss: 0.08300607420809705
ROC train: 0.991816	val: 0.704545	test: 0.900010
PRC train: 0.952072	val: 0.576259	test: 0.707750

Epoch: 107
Loss: 0.07181427667213798
ROC train: 0.989860	val: 0.681484	test: 0.883294
PRC train: 0.947616	val: 0.564198	test: 0.687522

Epoch: 108
Loss: 0.09527154325439077
ROC train: 0.991317	val: 0.688837	test: 0.881946
PRC train: 0.953933	val: 0.564003	test: 0.684542

Epoch: 109
Loss: 0.07326859396053506
ROC train: 0.990979	val: 0.694853	test: 0.885944
PRC train: 0.952986	val: 0.562165	test: 0.692519

Epoch: 110
Loss: 0.0832335860635904
ROC train: 0.991663	val: 0.705548	test: 0.893975
PRC train: 0.953275	val: 0.570340	test: 0.716875

Epoch: 111
Loss: 0.08461839615146258
ROC train: 0.991568	val: 0.713904	test: 0.907594
PRC train: 0.952620	val: 0.578894	test: 0.721936

Epoch: 112
Loss: 0.0727138061567035
ROC train: 0.991910	val: 0.718583	test: 0.905289
PRC train: 0.954339	val: 0.578594	test: 0.701442

Epoch: 113
Loss: 0.08670328786496677
ROC train: 0.992289	val: 0.684492	test: 0.901154
PRC train: 0.955408	val: 0.577737	test: 0.690645

Epoch: 114
Loss: 0.09190949861586639
ROC train: 0.991691	val: 0.673797	test: 0.893574
PRC train: 0.952887	val: 0.570443	test: 0.677210

Epoch: 115
Loss: 0.08150293297259108
ROC train: 0.992471	val: 0.706885	test: 0.900344
PRC train: 0.955668	val: 0.588008	test: 0.682926

Epoch: 116
Loss: 0.08769720713382945
ROC train: 0.992175	val: 0.724265	test: 0.873833
PRC train: 0.954722	val: 0.579006	test: 0.654063

Epoch: 117
Loss: 0.0817763784583174
ROC train: 0.991497	val: 0.714906	test: 0.869066
PRC train: 0.952687	val: 0.567317	test: 0.666583

Epoch: 118
Loss: 0.08171460441948855
ROC train: 0.991273	val: 0.719586	test: 0.886917
PRC train: 0.953510	val: 0.574245	test: 0.714338

Epoch: 119
Loss: 0.09418864286048455
ROC train: 0.990798	val: 0.707219	test: 0.881916
PRC train: 0.951960	val: 0.571997	test: 0.708771

Epoch: 120
Loss: 0.08404409179112413
ROC train: 0.991767	val: 0.712901	test: 0.899264
PRC train: 0.954925	val: 0.578306	test: 0.712848

Early stopping
Best (ROC):	 train: 0.943484	val: 0.853944	test: 0.891431
Best (PRC):	 train: 0.809678	val: 0.654752	test: 0.693837

ROC train: 0.989628	val: 0.774398	test: 0.892044
PRC train: 0.942506	val: 0.642160	test: 0.665401

Epoch: 95
Loss: 0.10119514246441727
ROC train: 0.987185	val: 0.749666	test: 0.900627
PRC train: 0.932751	val: 0.626968	test: 0.681015

Epoch: 96
Loss: 0.09283614096856971
ROC train: 0.981818	val: 0.716578	test: 0.891684
PRC train: 0.916836	val: 0.619793	test: 0.674772

Epoch: 97
Loss: 0.10632808914226297
ROC train: 0.987535	val: 0.744318	test: 0.895576
PRC train: 0.933373	val: 0.640223	test: 0.643815

Epoch: 98
Loss: 0.09419912779333746
ROC train: 0.988993	val: 0.738636	test: 0.874696
PRC train: 0.938130	val: 0.612067	test: 0.620085

Epoch: 99
Loss: 0.10827380138884876
ROC train: 0.990168	val: 0.737634	test: 0.887156
PRC train: 0.944959	val: 0.624190	test: 0.682250

Epoch: 100
Loss: 0.09449237157507777
ROC train: 0.989993	val: 0.745989	test: 0.875354
PRC train: 0.946560	val: 0.639797	test: 0.660519

Epoch: 101
Loss: 0.09296264373996857
ROC train: 0.990275	val: 0.745321	test: 0.876971
PRC train: 0.946532	val: 0.639621	test: 0.638498

Epoch: 102
Loss: 0.10183312605702896
ROC train: 0.989798	val: 0.773730	test: 0.888867
PRC train: 0.943094	val: 0.659053	test: 0.641627

Epoch: 103
Loss: 0.0906392889504307
ROC train: 0.989758	val: 0.786430	test: 0.894066
PRC train: 0.940414	val: 0.639678	test: 0.644635

Epoch: 104
Loss: 0.09716365242299521
ROC train: 0.990281	val: 0.782420	test: 0.895565
PRC train: 0.943483	val: 0.626730	test: 0.670771

Epoch: 105
Loss: 0.08479299113268332
ROC train: 0.990786	val: 0.785762	test: 0.911399
PRC train: 0.947825	val: 0.634368	test: 0.685801

Epoch: 106
Loss: 0.09202873575087736
ROC train: 0.990895	val: 0.776070	test: 0.900552
PRC train: 0.949671	val: 0.627348	test: 0.681707

Epoch: 107
Loss: 0.08137074512528437
ROC train: 0.991521	val: 0.743650	test: 0.894801
PRC train: 0.951556	val: 0.615515	test: 0.671982

Epoch: 108
Loss: 0.08402743753084174
ROC train: 0.991370	val: 0.757687	test: 0.912687
PRC train: 0.950317	val: 0.636938	test: 0.688352

Epoch: 109
Loss: 0.08564939790073585
ROC train: 0.991146	val: 0.754345	test: 0.894770
PRC train: 0.947939	val: 0.620034	test: 0.636585

Epoch: 110
Loss: 0.08930634450461834
ROC train: 0.990640	val: 0.754679	test: 0.881049
PRC train: 0.945945	val: 0.622882	test: 0.635442

Epoch: 111
Loss: 0.08264068959157375
ROC train: 0.990270	val: 0.745321	test: 0.874128
PRC train: 0.945330	val: 0.633830	test: 0.658159

Epoch: 112
Loss: 0.0820935122627533
ROC train: 0.991050	val: 0.740976	test: 0.871387
PRC train: 0.946875	val: 0.640871	test: 0.656709

Epoch: 113
Loss: 0.09057532588351287
ROC train: 0.991376	val: 0.755013	test: 0.865752
PRC train: 0.948246	val: 0.642838	test: 0.628525

Epoch: 114
Loss: 0.08258583056877673
ROC train: 0.991541	val: 0.756684	test: 0.859267
PRC train: 0.950513	val: 0.626770	test: 0.625888

Epoch: 115
Loss: 0.08303390367773698
ROC train: 0.991553	val: 0.759693	test: 0.847010
PRC train: 0.950972	val: 0.627383	test: 0.625590

Epoch: 116
Loss: 0.0760678376747473
ROC train: 0.991766	val: 0.767045	test: 0.862905
PRC train: 0.951391	val: 0.635785	test: 0.635858

Epoch: 117
Loss: 0.08471997094587923
ROC train: 0.991404	val: 0.783422	test: 0.908340
PRC train: 0.948943	val: 0.649618	test: 0.708371

Epoch: 118
Loss: 0.09285812004577162
ROC train: 0.991727	val: 0.778409	test: 0.907590
PRC train: 0.949457	val: 0.635498	test: 0.725146

Epoch: 119
Loss: 0.08355778108920431
ROC train: 0.991642	val: 0.767380	test: 0.895130
PRC train: 0.949478	val: 0.628040	test: 0.663520

Epoch: 120
Loss: 0.08194156346938944
ROC train: 0.991850	val: 0.772059	test: 0.912778
PRC train: 0.953346	val: 0.645863	test: 0.671554

Early stopping
Best (ROC):	 train: 0.916881	val: 0.873997	test: 0.859275
Best (PRC):	 train: 0.759977	val: 0.652950	test: 0.678217

ROC train: 0.990233	val: 0.748663	test: 0.922663
PRC train: 0.946708	val: 0.593011	test: 0.712814

Epoch: 95
Loss: 0.08434128930591953
ROC train: 0.990377	val: 0.736631	test: 0.911789
PRC train: 0.946343	val: 0.588292	test: 0.701911

Epoch: 96
Loss: 0.10328687182383586
ROC train: 0.990566	val: 0.719920	test: 0.918438
PRC train: 0.948962	val: 0.581524	test: 0.724484

Epoch: 97
Loss: 0.08850092935664382
ROC train: 0.990852	val: 0.708890	test: 0.890813
PRC train: 0.949991	val: 0.567243	test: 0.685104

Epoch: 98
Loss: 0.10037724825224437
ROC train: 0.991624	val: 0.727273	test: 0.875957
PRC train: 0.949358	val: 0.574263	test: 0.652972

Epoch: 99
Loss: 0.08962470590232671
ROC train: 0.988643	val: 0.728610	test: 0.884794
PRC train: 0.939159	val: 0.594344	test: 0.668379

Epoch: 100
Loss: 0.09435038910595273
ROC train: 0.990294	val: 0.745655	test: 0.877335
PRC train: 0.943860	val: 0.597375	test: 0.672085

Epoch: 101
Loss: 0.08716465912435442
ROC train: 0.990932	val: 0.761698	test: 0.891264
PRC train: 0.948014	val: 0.594305	test: 0.640825

Epoch: 102
Loss: 0.09966499333684564
ROC train: 0.991336	val: 0.744987	test: 0.879565
PRC train: 0.948269	val: 0.588336	test: 0.632749

Epoch: 103
Loss: 0.09412255977768194
ROC train: 0.991696	val: 0.741310	test: 0.891026
PRC train: 0.948432	val: 0.588078	test: 0.641321

Epoch: 104
Loss: 0.08699578032320847
ROC train: 0.991390	val: 0.746992	test: 0.886232
PRC train: 0.946310	val: 0.595645	test: 0.648664

Epoch: 105
Loss: 0.09440197049554175
ROC train: 0.991047	val: 0.738302	test: 0.887190
PRC train: 0.943594	val: 0.592337	test: 0.651179

Epoch: 106
Loss: 0.08719557486457764
ROC train: 0.991362	val: 0.743984	test: 0.899969
PRC train: 0.945463	val: 0.597011	test: 0.649053

Epoch: 107
Loss: 0.08629627062927887
ROC train: 0.989923	val: 0.759024	test: 0.916761
PRC train: 0.940989	val: 0.599365	test: 0.663903

Epoch: 108
Loss: 0.09642848828138649
ROC train: 0.989864	val: 0.769385	test: 0.917374
PRC train: 0.941087	val: 0.606037	test: 0.665888

Epoch: 109
Loss: 0.08418899494992489
ROC train: 0.991699	val: 0.760695	test: 0.900014
PRC train: 0.949529	val: 0.597499	test: 0.644156

Epoch: 110
Loss: 0.07672429661289959
ROC train: 0.991942	val: 0.753008	test: 0.880213
PRC train: 0.953318	val: 0.587388	test: 0.629395

Epoch: 111
Loss: 0.09308368105225773
ROC train: 0.991215	val: 0.744318	test: 0.888822
PRC train: 0.950982	val: 0.586106	test: 0.642115

Epoch: 112
Loss: 0.09407607540467736
ROC train: 0.991528	val: 0.737299	test: 0.893017
PRC train: 0.951326	val: 0.583552	test: 0.652582

Epoch: 113
Loss: 0.09256911240083791
ROC train: 0.992252	val: 0.713570	test: 0.883355
PRC train: 0.952616	val: 0.572939	test: 0.657689

Epoch: 114
Loss: 0.08818899766946878
ROC train: 0.992156	val: 0.735294	test: 0.903278
PRC train: 0.953468	val: 0.581036	test: 0.663041

Epoch: 115
Loss: 0.092137345065622
ROC train: 0.992129	val: 0.737968	test: 0.909480
PRC train: 0.955951	val: 0.592438	test: 0.686996

Epoch: 116
Loss: 0.07601644936424849
ROC train: 0.992486	val: 0.727607	test: 0.901093
PRC train: 0.955186	val: 0.573904	test: 0.674251

Epoch: 117
Loss: 0.08287760315061138
ROC train: 0.992504	val: 0.711564	test: 0.893347
PRC train: 0.956991	val: 0.563021	test: 0.670818

Epoch: 118
Loss: 0.076912575191642
ROC train: 0.992512	val: 0.720922	test: 0.893422
PRC train: 0.959751	val: 0.577070	test: 0.673270

Epoch: 119
Loss: 0.07851080456196247
ROC train: 0.991367	val: 0.708556	test: 0.876676
PRC train: 0.953469	val: 0.575050	test: 0.655158

Epoch: 120
Loss: 0.08479647609556973
ROC train: 0.992684	val: 0.722594	test: 0.863852
PRC train: 0.957835	val: 0.573902	test: 0.645597

Early stopping
Best (ROC):	 train: 0.947284	val: 0.866979	test: 0.889171
Best (PRC):	 train: 0.793617	val: 0.656244	test: 0.658714
All runs completed.
