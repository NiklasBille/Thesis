>>> Starting run for dataset: sider
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running SCAFF configs_split_experiments/GraphCL/sider/scaff/train_prop=0.6.yml on cuda:0
Running SCAFF configs_split_experiments/GraphCL/sider/scaff/train_prop=0.7.yml on cuda:1
Running SCAFF configs_split_experiments/GraphCL/sider/scaff/train_prop=0.8.yml on cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.7.yml --runseed 4 --device cuda:1
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.7.yml --runseed 5 --device cuda:1
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.7.yml --runseed 6 --device cuda:1
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.8.yml --runseed 4 --device cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.6.yml --runseed 4 --device cuda:0
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.8.yml --runseed 5 --device cuda:2
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.6.yml --runseed 5 --device cuda:0
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.6.yml --runseed 6 --device cuda:0
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.8.yml --runseed 6 --device cuda:2
[10:59:58] WARNING: not removing hydrogen atom without neighbors
[10:59:58] WARNING: not removing hydrogen atom without neighbors
[10:59:58] WARNING: not removing hydrogen atom without neighbors
[10:59:58] WARNING: not removing hydrogen atom without neighbors
[10:59:58] WARNING: not removing hydrogen atom without neighbors
[10:59:58] WARNING: not removing hydrogen atom without neighbors
[10:59:58] WARNING: not removing hydrogen atom without neighbors
[10:59:58] WARNING: not removing hydrogen atom without neighbors
[10:59:58] WARNING: not removing hydrogen atom without neighbors
[10:59:58] WARNING: not removing hydrogen atom without neighbors
[10:59:58] WARNING: not removing hydrogen atom without neighbors
[10:59:58] WARNING: not removing hydrogen atom without neighbors
[10:59:58] WARNING: not removing hydrogen atom without neighbors
[10:59:58] WARNING: not removing hydrogen atom without neighbors
[10:59:58] WARNING: not removing hydrogen atom without neighbors
[10:59:58] WARNING: not removing hydrogen atom without neighbors
[10:59:58] WARNING: not removing hydrogen atom without neighbors
[10:59:58] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[10:59:59] WARNING: not removing hydrogen atom without neighbors
[11:00:00] WARNING: not removing hydrogen atom without neighbors
[11:00:00] WARNING: not removing hydrogen atom without neighbors
[11:00:00] WARNING: not removing hydrogen atom without neighbors
[11:00:00] WARNING: not removing hydrogen atom without neighbors
[11:00:00] WARNING: not removing hydrogen atom without neighbors
[11:00:00] WARNING: not removing hydrogen atom without neighbors
[11:00:00] WARNING: not removing hydrogen atom without neighbors
[11:00:00] WARNING: not removing hydrogen atom without neighbors
[11:00:00] WARNING: not removing hydrogen atom without neighbors
[11:00:00] WARNING: not removing hydrogen atom without neighbors
[11:00:00] WARNING: not removing hydrogen atom without neighbors
[11:00:00] WARNING: not removing hydrogen atom without neighbors
[11:00:00] WARNING: not removing hydrogen atom without neighbors
[11:00:00] WARNING: not removing hydrogen atom without neighbors
[11:00:00] WARNING: not removing hydrogen atom without neighbors
[11:00:00] WARNING: not removing hydrogen atom without neighbors
[11:00:00] WARNING: not removing hydrogen atom without neighbors
[11:00:00] WARNING: not removing hydrogen atom without neighbors
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/scaff/train_prop=0.6/sider_scaff_5_26-05_10-59-58  ]
[ Using Seed :  5  ]
[ Using device :  cuda:0  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6939305775397764
ROC train: 0.535334	val: 0.509709	test: 0.493827
PRC train: 0.577255	val: 0.599593	test: 0.587745

Epoch: 2
Loss: 0.6543618991110175
ROC train: 0.561533	val: 0.526289	test: 0.493536
PRC train: 0.599675	val: 0.607558	test: 0.586210

Epoch: 3
Loss: 0.6258379718701657
ROC train: 0.573397	val: 0.528802	test: 0.494563
PRC train: 0.607166	val: 0.608248	test: 0.583238

Epoch: 4
Loss: 0.5934156023528536
ROC train: 0.586259	val: 0.536830	test: 0.495846
PRC train: 0.615353	val: 0.612090	test: 0.583117

Epoch: 5
Loss: 0.5781695121367522
ROC train: 0.598901	val: 0.539147	test: 0.501987
PRC train: 0.624344	val: 0.615966	test: 0.585808

Epoch: 6
Loss: 0.5669332972194259
ROC train: 0.632300	val: 0.538649	test: 0.523848
PRC train: 0.643740	val: 0.621051	test: 0.595983

Epoch: 7
Loss: 0.54183323831215
ROC train: 0.657503	val: 0.540485	test: 0.541453
PRC train: 0.655139	val: 0.621845	test: 0.601411

Epoch: 8
Loss: 0.5380815094587005
ROC train: 0.668986	val: 0.543117	test: 0.551932
PRC train: 0.662503	val: 0.624340	test: 0.607254

Epoch: 9
Loss: 0.5348342804472745
ROC train: 0.681452	val: 0.547500	test: 0.562970
PRC train: 0.671298	val: 0.626922	test: 0.614084

Epoch: 10
Loss: 0.5156482431275388
ROC train: 0.688942	val: 0.549754	test: 0.568669
PRC train: 0.676818	val: 0.626246	test: 0.615785

Epoch: 11
Loss: 0.5161048386143482
ROC train: 0.695492	val: 0.549770	test: 0.567875
PRC train: 0.682289	val: 0.626664	test: 0.613097

Epoch: 12
Loss: 0.5044266826958811
ROC train: 0.704914	val: 0.549995	test: 0.569829
PRC train: 0.690000	val: 0.626941	test: 0.613148

Epoch: 13
Loss: 0.4993310783911965
ROC train: 0.711018	val: 0.544431	test: 0.573206
PRC train: 0.694114	val: 0.623755	test: 0.616463

Epoch: 14
Loss: 0.49453093404757864
ROC train: 0.717964	val: 0.548184	test: 0.574792
PRC train: 0.698612	val: 0.627074	test: 0.618492

Epoch: 15
Loss: 0.4911378300203759
ROC train: 0.725551	val: 0.550246	test: 0.573641
PRC train: 0.704117	val: 0.630081	test: 0.617292

Epoch: 16
Loss: 0.48945829205361197
ROC train: 0.732194	val: 0.548795	test: 0.574288
PRC train: 0.709000	val: 0.631485	test: 0.619779

Epoch: 17
Loss: 0.4887587644430215
ROC train: 0.729035	val: 0.546696	test: 0.575118
PRC train: 0.707758	val: 0.627802	test: 0.621857

Epoch: 18
Loss: 0.4812213557034884
ROC train: 0.738986	val: 0.548633	test: 0.580952
PRC train: 0.714746	val: 0.628292	test: 0.625707

Epoch: 19
Loss: 0.47357409388093086
ROC train: 0.747914	val: 0.552808	test: 0.589031
PRC train: 0.720094	val: 0.633094	test: 0.628245

Epoch: 20
Loss: 0.46948233308826354
ROC train: 0.749598	val: 0.551369	test: 0.589430
PRC train: 0.721414	val: 0.632389	test: 0.627786

Epoch: 21
Loss: 0.4741685219624291
ROC train: 0.750025	val: 0.548047	test: 0.586015
PRC train: 0.720763	val: 0.628962	test: 0.624075

Epoch: 22
Loss: 0.4730762430544094
ROC train: 0.755894	val: 0.548366	test: 0.586985
PRC train: 0.724308	val: 0.628595	test: 0.625401

Epoch: 23
Loss: 0.4697057151078815
ROC train: 0.761502	val: 0.547899	test: 0.589608
PRC train: 0.727056	val: 0.626866	test: 0.630936

Epoch: 24
Loss: 0.47213994339524046
ROC train: 0.767549	val: 0.552806	test: 0.592450
PRC train: 0.732187	val: 0.633221	test: 0.631055

Epoch: 25
Loss: 0.46573969376775215
ROC train: 0.768025	val: 0.555982	test: 0.591102
PRC train: 0.733947	val: 0.639078	test: 0.627312

Epoch: 26
Loss: 0.4637130075108165
ROC train: 0.769188	val: 0.550724	test: 0.590540
PRC train: 0.735108	val: 0.635892	test: 0.625710

Epoch: 27
Loss: 0.4615176683421732
ROC train: 0.771473	val: 0.542872	test: 0.587633
PRC train: 0.736301	val: 0.630544	test: 0.626609

Epoch: 28
Loss: 0.45249609802453516
ROC train: 0.778170	val: 0.542235	test: 0.590690
PRC train: 0.741505	val: 0.630156	test: 0.629004

Epoch: 29
Loss: 0.46346750518776236
ROC train: 0.781304	val: 0.542884	test: 0.589664
PRC train: 0.745413	val: 0.629738	test: 0.627591

Epoch: 30
Loss: 0.45271879703540013
ROC train: 0.778829	val: 0.546128	test: 0.589632
PRC train: 0.745446	val: 0.629780	test: 0.629321

Epoch: 31
Loss: 0.4590012499279327
ROC train: 0.787239	val: 0.544073	test: 0.586020
PRC train: 0.750419	val: 0.627585	test: 0.629278

Epoch: 32
Loss: 0.44952794437103916
ROC train: 0.793843	val: 0.548299	test: 0.583945
PRC train: 0.753037	val: 0.630304	test: 0.626254

Epoch: 33
Loss: 0.4507954423253016Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/scaff/train_prop=0.6/sider_scaff_6_26-05_10-59-58  ]
[ Using Seed :  6  ]
[ Using device :  cuda:0  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6839208982853179
ROC train: 0.548732	val: 0.517369	test: 0.518933
PRC train: 0.578008	val: 0.599738	test: 0.594474

Epoch: 2
Loss: 0.6468102150611534
ROC train: 0.560922	val: 0.527041	test: 0.513685
PRC train: 0.591871	val: 0.602141	test: 0.589307

Epoch: 3
Loss: 0.613089768107116
ROC train: 0.564354	val: 0.532001	test: 0.500415
PRC train: 0.600085	val: 0.604227	test: 0.584555

Epoch: 4
Loss: 0.585580491813169
ROC train: 0.578898	val: 0.533646	test: 0.502764
PRC train: 0.610537	val: 0.608374	test: 0.583883

Epoch: 5
Loss: 0.5671793835836754
ROC train: 0.600858	val: 0.531988	test: 0.512767
PRC train: 0.623873	val: 0.608436	test: 0.586466

Epoch: 6
Loss: 0.5561951430216231
ROC train: 0.625082	val: 0.536150	test: 0.531691
PRC train: 0.637769	val: 0.613194	test: 0.596333

Epoch: 7
Loss: 0.5452075508210402
ROC train: 0.646306	val: 0.538060	test: 0.550229
PRC train: 0.648410	val: 0.617790	test: 0.605677

Epoch: 8
Loss: 0.541294659048088
ROC train: 0.664705	val: 0.539796	test: 0.561010
PRC train: 0.659227	val: 0.620312	test: 0.609382

Epoch: 9
Loss: 0.5245399059682571
ROC train: 0.677892	val: 0.544779	test: 0.568971
PRC train: 0.667649	val: 0.619129	test: 0.613121

Epoch: 10
Loss: 0.5198554792732764
ROC train: 0.681921	val: 0.547207	test: 0.572746
PRC train: 0.670228	val: 0.619040	test: 0.614748

Epoch: 11
Loss: 0.5146937272957173
ROC train: 0.691382	val: 0.542686	test: 0.578445
PRC train: 0.677180	val: 0.620664	test: 0.618104

Epoch: 12
Loss: 0.5052336611341834
ROC train: 0.701322	val: 0.534740	test: 0.582810
PRC train: 0.684736	val: 0.617246	test: 0.621711

Epoch: 13
Loss: 0.5063848954586834
ROC train: 0.706367	val: 0.533137	test: 0.581686
PRC train: 0.689638	val: 0.614834	test: 0.621836

Epoch: 14
Loss: 0.4977899587186571
ROC train: 0.713808	val: 0.538902	test: 0.583492
PRC train: 0.693761	val: 0.617504	test: 0.622191

Epoch: 15
Loss: 0.48980455150545715
ROC train: 0.722238	val: 0.545452	test: 0.586629
PRC train: 0.699167	val: 0.620258	test: 0.623740

Epoch: 16
Loss: 0.487243703297494
ROC train: 0.729083	val: 0.551982	test: 0.591648
PRC train: 0.703104	val: 0.625414	test: 0.626439

Epoch: 17
Loss: 0.48305828977432735
ROC train: 0.734927	val: 0.556128	test: 0.594326
PRC train: 0.706635	val: 0.627967	test: 0.630016

Epoch: 18
Loss: 0.4769595430196167
ROC train: 0.741327	val: 0.555353	test: 0.595579
PRC train: 0.712333	val: 0.630433	test: 0.630180

Epoch: 19
Loss: 0.47427713652884246
ROC train: 0.746064	val: 0.549644	test: 0.595192
PRC train: 0.715947	val: 0.628226	test: 0.630632

Epoch: 20
Loss: 0.4772582624838653
ROC train: 0.747457	val: 0.549729	test: 0.590657
PRC train: 0.716773	val: 0.630472	test: 0.631737

Epoch: 21
Loss: 0.4688321951786597
ROC train: 0.752929	val: 0.545051	test: 0.590729
PRC train: 0.720754	val: 0.628700	test: 0.631470

Epoch: 22
Loss: 0.4713893788707144
ROC train: 0.758993	val: 0.545985	test: 0.593167
PRC train: 0.726214	val: 0.628396	test: 0.634047

Epoch: 23
Loss: 0.4654732883325172
ROC train: 0.762072	val: 0.547587	test: 0.597650
PRC train: 0.729575	val: 0.630331	test: 0.633490

Epoch: 24
Loss: 0.46748491926600644
ROC train: 0.764594	val: 0.544839	test: 0.596224
PRC train: 0.731070	val: 0.628718	test: 0.633425

Epoch: 25
Loss: 0.46465962078868134
ROC train: 0.768492	val: 0.544512	test: 0.594938
PRC train: 0.733048	val: 0.625257	test: 0.634192

Epoch: 26
Loss: 0.4603596361638569
ROC train: 0.773520	val: 0.550020	test: 0.600837
PRC train: 0.737539	val: 0.628649	test: 0.636208

Epoch: 27
Loss: 0.46098089614496995
ROC train: 0.774768	val: 0.546713	test: 0.597901
PRC train: 0.737821	val: 0.627145	test: 0.634090

Epoch: 28
Loss: 0.4586730862370104
ROC train: 0.776801	val: 0.539632	test: 0.596863
PRC train: 0.737547	val: 0.622819	test: 0.632382

Epoch: 29
Loss: 0.4555380480797949
ROC train: 0.782650	val: 0.536646	test: 0.596838
PRC train: 0.740346	val: 0.622985	test: 0.632247

Epoch: 30
Loss: 0.45923776361035756
ROC train: 0.787552	val: 0.541442	test: 0.594983
PRC train: 0.746958	val: 0.628222	test: 0.629410

Epoch: 31
Loss: 0.4560908727110535
ROC train: 0.787864	val: 0.545321	test: 0.593287
PRC train: 0.748283	val: 0.630745	test: 0.630843

Epoch: 32
Loss: 0.4467094848269936
ROC train: 0.792903	val: 0.540020	test: 0.596263
PRC train: 0.752408	val: 0.628499	test: 0.634123

Epoch: 33
Loss: 0.4541535900130572
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/scaff/train_prop=0.6/sider_scaff_4_26-05_10-59-58  ]
[ Using Seed :  4  ]
[ Using device :  cuda:0  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6910982690008114
ROC train: 0.547236	val: 0.507796	test: 0.486846
PRC train: 0.580679	val: 0.599525	test: 0.586444

Epoch: 2
Loss: 0.6515846214536464
ROC train: 0.566422	val: 0.518300	test: 0.502264
PRC train: 0.597736	val: 0.602360	test: 0.581333

Epoch: 3
Loss: 0.6124983129027904
ROC train: 0.569860	val: 0.527533	test: 0.496782
PRC train: 0.604530	val: 0.605154	test: 0.581481

Epoch: 4
Loss: 0.5886565313825393
ROC train: 0.579478	val: 0.530802	test: 0.499724
PRC train: 0.611909	val: 0.605859	test: 0.583467

Epoch: 5
Loss: 0.5786451795119313
ROC train: 0.608707	val: 0.534929	test: 0.517317
PRC train: 0.629172	val: 0.612234	test: 0.593744

Epoch: 6
Loss: 0.554143762370203
ROC train: 0.638725	val: 0.537173	test: 0.535230
PRC train: 0.646334	val: 0.616417	test: 0.604744

Epoch: 7
Loss: 0.5442784701192624
ROC train: 0.656365	val: 0.539967	test: 0.551105
PRC train: 0.654798	val: 0.618867	test: 0.611994

Epoch: 8
Loss: 0.5322932475567561
ROC train: 0.668455	val: 0.546037	test: 0.561118
PRC train: 0.661994	val: 0.623527	test: 0.614803

Epoch: 9
Loss: 0.5287072051878009
ROC train: 0.678419	val: 0.550291	test: 0.564174
PRC train: 0.668438	val: 0.627662	test: 0.614780

Epoch: 10
Loss: 0.5182104451649937
ROC train: 0.688577	val: 0.552872	test: 0.568004
PRC train: 0.675904	val: 0.629242	test: 0.617791

Epoch: 11
Loss: 0.5119549795319607
ROC train: 0.695228	val: 0.551426	test: 0.570749
PRC train: 0.679685	val: 0.627723	test: 0.620695

Epoch: 12
Loss: 0.5059923017411128
ROC train: 0.702288	val: 0.545967	test: 0.577779
PRC train: 0.684286	val: 0.621811	test: 0.625749

Epoch: 13
Loss: 0.5003709389259241
ROC train: 0.710637	val: 0.547676	test: 0.581302
PRC train: 0.691283	val: 0.623107	test: 0.628178

Epoch: 14
Loss: 0.49588877992795793
ROC train: 0.717697	val: 0.548034	test: 0.580478
PRC train: 0.697032	val: 0.625376	test: 0.627357

Epoch: 15
Loss: 0.4920663591746869
ROC train: 0.727254	val: 0.546986	test: 0.578963
PRC train: 0.703691	val: 0.626210	test: 0.625013

Epoch: 16
Loss: 0.4877007387918394
ROC train: 0.732564	val: 0.543162	test: 0.582783
PRC train: 0.706767	val: 0.622770	test: 0.629419

Epoch: 17
Loss: 0.4809178798190812
ROC train: 0.740721	val: 0.545409	test: 0.586123
PRC train: 0.712685	val: 0.624318	test: 0.626483

Epoch: 18
Loss: 0.47871352257808825
ROC train: 0.744129	val: 0.546883	test: 0.585347
PRC train: 0.715806	val: 0.625783	test: 0.624331

Epoch: 19
Loss: 0.47927468943433
ROC train: 0.744467	val: 0.542918	test: 0.584600
PRC train: 0.714423	val: 0.624142	test: 0.623897

Epoch: 20
Loss: 0.47530106240533626
ROC train: 0.755048	val: 0.546346	test: 0.589987
PRC train: 0.722561	val: 0.629045	test: 0.630035

Epoch: 21
Loss: 0.4681164237316521
ROC train: 0.758397	val: 0.543906	test: 0.590865
PRC train: 0.724834	val: 0.631443	test: 0.628984

Epoch: 22
Loss: 0.4682803007077239
ROC train: 0.763541	val: 0.545514	test: 0.585930
PRC train: 0.730417	val: 0.630144	test: 0.625624

Epoch: 23
Loss: 0.46677828416594763
ROC train: 0.763590	val: 0.548688	test: 0.584381
PRC train: 0.729213	val: 0.628585	test: 0.624368

Epoch: 24
Loss: 0.4628286905440799
ROC train: 0.769686	val: 0.550252	test: 0.591393
PRC train: 0.733525	val: 0.629555	test: 0.629810

Epoch: 25
Loss: 0.4611297519584091
ROC train: 0.775717	val: 0.551940	test: 0.596527
PRC train: 0.738113	val: 0.632886	test: 0.632506

Epoch: 26
Loss: 0.454102213714468
ROC train: 0.777033	val: 0.551192	test: 0.596435
PRC train: 0.740529	val: 0.633456	test: 0.633491

Epoch: 27
Loss: 0.46072341276937784
ROC train: 0.780452	val: 0.547760	test: 0.594761
PRC train: 0.742379	val: 0.629516	test: 0.634025

Epoch: 28
Loss: 0.4571675298336619
ROC train: 0.785221	val: 0.549455	test: 0.594888
PRC train: 0.745412	val: 0.632667	test: 0.630629

Epoch: 29
Loss: 0.4561312689993763
ROC train: 0.785081	val: 0.545209	test: 0.588976
PRC train: 0.745951	val: 0.630990	test: 0.624357

Epoch: 30
Loss: 0.4492089273917765
ROC train: 0.783828	val: 0.542676	test: 0.585830
PRC train: 0.742613	val: 0.626846	test: 0.622146

Epoch: 31
Loss: 0.4489071940624998
ROC train: 0.786206	val: 0.547491	test: 0.590999
PRC train: 0.743956	val: 0.629417	test: 0.626498

Epoch: 32
Loss: 0.4469267313322686
ROC train: 0.797769	val: 0.562729	test: 0.600343
PRC train: 0.755190	val: 0.643067	test: 0.637347

Epoch: 33
Loss: 0.44179630310587015
ROC train: 0.799408	val: 0.576111	test: 0.601191Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/scaff/train_prop=0.7/sider_scaff_4_26-05_10-59-58  ]
[ Using Seed :  4  ]
[ Using device :  cuda:1  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6915920396636948
ROC train: 0.543049	val: 0.506413	test: 0.491725
PRC train: 0.583345	val: 0.610615	test: 0.573956

Epoch: 2
Loss: 0.6505394494178256
ROC train: 0.564237	val: 0.531119	test: 0.505373
PRC train: 0.600743	val: 0.616390	test: 0.567472

Epoch: 3
Loss: 0.6150929772971627
ROC train: 0.570104	val: 0.534933	test: 0.502343
PRC train: 0.608635	val: 0.619747	test: 0.569070

Epoch: 4
Loss: 0.58632801010956
ROC train: 0.579315	val: 0.530957	test: 0.509523
PRC train: 0.617679	val: 0.621644	test: 0.577157

Epoch: 5
Loss: 0.5694923193999076
ROC train: 0.603630	val: 0.529216	test: 0.529615
PRC train: 0.631989	val: 0.624407	test: 0.589292

Epoch: 6
Loss: 0.5551590447671026
ROC train: 0.630187	val: 0.532909	test: 0.559273
PRC train: 0.646439	val: 0.626247	test: 0.607423

Epoch: 7
Loss: 0.5421490514076505
ROC train: 0.643832	val: 0.536614	test: 0.570441
PRC train: 0.652879	val: 0.627861	test: 0.608399

Epoch: 8
Loss: 0.5337833158322196
ROC train: 0.654699	val: 0.542138	test: 0.578472
PRC train: 0.659566	val: 0.632092	test: 0.612242

Epoch: 9
Loss: 0.5260899343742108
ROC train: 0.667027	val: 0.550928	test: 0.589119
PRC train: 0.668907	val: 0.638129	test: 0.618126

Epoch: 10
Loss: 0.5193611507112521
ROC train: 0.678264	val: 0.555326	test: 0.597280
PRC train: 0.674551	val: 0.642560	test: 0.623875

Epoch: 11
Loss: 0.5100520254023706
ROC train: 0.688270	val: 0.554545	test: 0.599114
PRC train: 0.678604	val: 0.642819	test: 0.623496

Epoch: 12
Loss: 0.5063462443623522
ROC train: 0.699110	val: 0.552091	test: 0.605644
PRC train: 0.686426	val: 0.641793	test: 0.625591

Epoch: 13
Loss: 0.4997503130233518
ROC train: 0.705813	val: 0.551112	test: 0.604391
PRC train: 0.690845	val: 0.639867	test: 0.623316

Epoch: 14
Loss: 0.49674965500295265
ROC train: 0.710194	val: 0.557292	test: 0.602053
PRC train: 0.694358	val: 0.642249	test: 0.623321

Epoch: 15
Loss: 0.4948700778353278
ROC train: 0.719025	val: 0.560553	test: 0.611367
PRC train: 0.701746	val: 0.645662	test: 0.630042

Epoch: 16
Loss: 0.48573783973850665
ROC train: 0.729641	val: 0.559838	test: 0.616404
PRC train: 0.709551	val: 0.645646	test: 0.632120

Epoch: 17
Loss: 0.4850010959559007
ROC train: 0.729950	val: 0.559270	test: 0.609745
PRC train: 0.711364	val: 0.645522	test: 0.630229

Epoch: 18
Loss: 0.4820413196008768
ROC train: 0.732890	val: 0.551336	test: 0.601561
PRC train: 0.713086	val: 0.643591	test: 0.623971

Epoch: 19
Loss: 0.47713237737476144
ROC train: 0.742468	val: 0.549025	test: 0.604386
PRC train: 0.721539	val: 0.642002	test: 0.625166

Epoch: 20
Loss: 0.4746798261092682
ROC train: 0.749809	val: 0.548838	test: 0.605881
PRC train: 0.727018	val: 0.641584	test: 0.628245

Epoch: 21
Loss: 0.4726145670631131
ROC train: 0.753403	val: 0.553115	test: 0.611144
PRC train: 0.728485	val: 0.646549	test: 0.633398

Epoch: 22
Loss: 0.4697968021739146
ROC train: 0.757179	val: 0.555653	test: 0.608587
PRC train: 0.730801	val: 0.647665	test: 0.631451

Epoch: 23
Loss: 0.46907862964324926
ROC train: 0.766043	val: 0.562112	test: 0.614904
PRC train: 0.736552	val: 0.651296	test: 0.635566

Epoch: 24
Loss: 0.4635090211787944
ROC train: 0.770104	val: 0.566767	test: 0.615304
PRC train: 0.739767	val: 0.650603	test: 0.633324

Epoch: 25
Loss: 0.46329282533877264
ROC train: 0.772401	val: 0.565692	test: 0.611740
PRC train: 0.742029	val: 0.651538	test: 0.631629

Epoch: 26
Loss: 0.456428520638541
ROC train: 0.773697	val: 0.559492	test: 0.605911
PRC train: 0.744395	val: 0.646619	test: 0.624538

Epoch: 27
Loss: 0.45900549858047857
ROC train: 0.775288	val: 0.554187	test: 0.609674
PRC train: 0.745993	val: 0.642553	test: 0.625685

Epoch: 28
Loss: 0.45688474150588987
ROC train: 0.781943	val: 0.563321	test: 0.615791
PRC train: 0.751165	val: 0.646616	test: 0.633436

Epoch: 29
Loss: 0.45468646135678137
ROC train: 0.789647	val: 0.559103	test: 0.605653
PRC train: 0.756986	val: 0.643064	test: 0.634003

Epoch: 30
Loss: 0.4503062320271394
ROC train: 0.793944	val: 0.557823	test: 0.608342
PRC train: 0.760845	val: 0.646495	test: 0.634092

Epoch: 31
Loss: 0.4494914372793572
ROC train: 0.793613	val: 0.558165	test: 0.613016
PRC train: 0.760813	val: 0.645392	test: 0.630890

Epoch: 32
Loss: 0.4471120799854428
ROC train: 0.801689	val: 0.559379	test: 0.615895
PRC train: 0.767619	val: 0.646186	test: 0.634238

Epoch: 33
Loss: 0.44392247674034696Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/scaff/train_prop=0.7/sider_scaff_6_26-05_10-59-58  ]
[ Using Seed :  6  ]
[ Using device :  cuda:1  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6842770585899797
ROC train: 0.543481	val: 0.516436	test: 0.530041
PRC train: 0.580777	val: 0.613376	test: 0.582315

Epoch: 2
Loss: 0.6442306387270994
ROC train: 0.556484	val: 0.524922	test: 0.517697
PRC train: 0.594645	val: 0.614282	test: 0.576877

Epoch: 3
Loss: 0.607891684423852
ROC train: 0.566860	val: 0.526234	test: 0.506994
PRC train: 0.603821	val: 0.614468	test: 0.577012

Epoch: 4
Loss: 0.5920692483989153
ROC train: 0.576613	val: 0.526426	test: 0.508849
PRC train: 0.612685	val: 0.616427	test: 0.579994

Epoch: 5
Loss: 0.5645055752039645
ROC train: 0.600598	val: 0.527933	test: 0.536238
PRC train: 0.627707	val: 0.618908	test: 0.595265

Epoch: 6
Loss: 0.5575614824811547
ROC train: 0.626208	val: 0.526653	test: 0.565238
PRC train: 0.642478	val: 0.624834	test: 0.606438

Epoch: 7
Loss: 0.5451183709996789
ROC train: 0.643416	val: 0.534357	test: 0.578309
PRC train: 0.649910	val: 0.629629	test: 0.612386

Epoch: 8
Loss: 0.532426599355154
ROC train: 0.654869	val: 0.544018	test: 0.582482
PRC train: 0.658350	val: 0.632368	test: 0.615573

Epoch: 9
Loss: 0.5299984812806748
ROC train: 0.665489	val: 0.555067	test: 0.583645
PRC train: 0.665040	val: 0.634732	test: 0.616851

Epoch: 10
Loss: 0.5188692939830342
ROC train: 0.675478	val: 0.563122	test: 0.589560
PRC train: 0.672744	val: 0.637476	test: 0.619664

Epoch: 11
Loss: 0.5132128856586007
ROC train: 0.684161	val: 0.564953	test: 0.595325
PRC train: 0.678336	val: 0.638675	test: 0.621589

Epoch: 12
Loss: 0.5091010153279896
ROC train: 0.692716	val: 0.559529	test: 0.595923
PRC train: 0.682679	val: 0.639061	test: 0.620734

Epoch: 13
Loss: 0.5036663425237535
ROC train: 0.703549	val: 0.554480	test: 0.597257
PRC train: 0.690595	val: 0.639822	test: 0.620070

Epoch: 14
Loss: 0.4960526362991756
ROC train: 0.708339	val: 0.549322	test: 0.594007
PRC train: 0.694290	val: 0.639407	test: 0.618145

Epoch: 15
Loss: 0.4908611533359828
ROC train: 0.717379	val: 0.551819	test: 0.598506
PRC train: 0.701811	val: 0.641136	test: 0.619441

Epoch: 16
Loss: 0.48631621443427814
ROC train: 0.727626	val: 0.561616	test: 0.612596
PRC train: 0.708252	val: 0.646262	test: 0.626964

Epoch: 17
Loss: 0.48284654401966093
ROC train: 0.733594	val: 0.569507	test: 0.614697
PRC train: 0.712095	val: 0.650121	test: 0.625956

Epoch: 18
Loss: 0.4791070319636558
ROC train: 0.735035	val: 0.571442	test: 0.614280
PRC train: 0.713240	val: 0.652286	test: 0.625179

Epoch: 19
Loss: 0.4798960936901157
ROC train: 0.740513	val: 0.567147	test: 0.608804
PRC train: 0.718599	val: 0.649259	test: 0.623979

Epoch: 20
Loss: 0.47234650122916105
ROC train: 0.748094	val: 0.568484	test: 0.618479
PRC train: 0.725562	val: 0.649870	test: 0.630672

Epoch: 21
Loss: 0.4746768383504806
ROC train: 0.753593	val: 0.568465	test: 0.618693
PRC train: 0.728845	val: 0.650161	test: 0.632602

Epoch: 22
Loss: 0.46888179945544917
ROC train: 0.755512	val: 0.570009	test: 0.616440
PRC train: 0.730517	val: 0.651538	test: 0.631947

Epoch: 23
Loss: 0.4692583651259482
ROC train: 0.765614	val: 0.568093	test: 0.616725
PRC train: 0.738053	val: 0.647537	test: 0.630470

Epoch: 24
Loss: 0.45909216919602863
ROC train: 0.766883	val: 0.563006	test: 0.613931
PRC train: 0.736666	val: 0.644297	test: 0.627024

Epoch: 25
Loss: 0.4610313469993539
ROC train: 0.771097	val: 0.566273	test: 0.610304
PRC train: 0.741286	val: 0.648078	test: 0.625582

Epoch: 26
Loss: 0.45771462470608293
ROC train: 0.772149	val: 0.560843	test: 0.610529
PRC train: 0.740379	val: 0.648276	test: 0.626357

Epoch: 27
Loss: 0.45468529315417017
ROC train: 0.776549	val: 0.560830	test: 0.606917
PRC train: 0.743472	val: 0.643927	test: 0.625275

Epoch: 28
Loss: 0.45506708305712207
ROC train: 0.780795	val: 0.562955	test: 0.604635
PRC train: 0.747672	val: 0.644722	test: 0.623386

Epoch: 29
Loss: 0.4582461477165224
ROC train: 0.783918	val: 0.561178	test: 0.603572
PRC train: 0.750335	val: 0.647197	test: 0.624064

Epoch: 30
Loss: 0.4526707398631489
ROC train: 0.787760	val: 0.563351	test: 0.613072
PRC train: 0.751766	val: 0.650584	test: 0.631284

Epoch: 31
Loss: 0.450983846487257
ROC train: 0.790430	val: 0.566273	test: 0.616582
PRC train: 0.754101	val: 0.646394	test: 0.632785

Epoch: 32
Loss: 0.4476918375087516
ROC train: 0.792603	val: 0.575250	test: 0.613317
PRC train: 0.758670	val: 0.643759	test: 0.629432

Epoch: 33
Loss: 0.4432703717297146Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/scaff/train_prop=0.7/sider_scaff_5_26-05_10-59-58  ]
[ Using Seed :  5  ]
[ Using device :  cuda:1  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6944820221442513
ROC train: 0.528026	val: 0.505128	test: 0.490513
PRC train: 0.578631	val: 0.607062	test: 0.572779

Epoch: 2
Loss: 0.6503699209333457
ROC train: 0.554352	val: 0.523670	test: 0.493407
PRC train: 0.600470	val: 0.613027	test: 0.574698

Epoch: 3
Loss: 0.6167025973477457
ROC train: 0.565652	val: 0.525876	test: 0.497128
PRC train: 0.607477	val: 0.613781	test: 0.576081

Epoch: 4
Loss: 0.5870502698843707
ROC train: 0.580204	val: 0.530041	test: 0.506192
PRC train: 0.617003	val: 0.616864	test: 0.580584

Epoch: 5
Loss: 0.566175894530061
ROC train: 0.608297	val: 0.528520	test: 0.535516
PRC train: 0.633098	val: 0.617630	test: 0.592974

Epoch: 6
Loss: 0.5537386345807023
ROC train: 0.631350	val: 0.533496	test: 0.570112
PRC train: 0.644103	val: 0.621988	test: 0.609356

Epoch: 7
Loss: 0.5454320513084377
ROC train: 0.649108	val: 0.537471	test: 0.588389
PRC train: 0.652971	val: 0.625213	test: 0.615195

Epoch: 8
Loss: 0.5378259926763733
ROC train: 0.661143	val: 0.542710	test: 0.595915
PRC train: 0.661383	val: 0.631609	test: 0.619211

Epoch: 9
Loss: 0.5318037687309967
ROC train: 0.669187	val: 0.549986	test: 0.597540
PRC train: 0.667453	val: 0.635707	test: 0.619901

Epoch: 10
Loss: 0.5189203869055232
ROC train: 0.680409	val: 0.559540	test: 0.607689
PRC train: 0.675067	val: 0.639186	test: 0.623160

Epoch: 11
Loss: 0.5153424605344681
ROC train: 0.691190	val: 0.560924	test: 0.614546
PRC train: 0.681196	val: 0.639723	test: 0.626987

Epoch: 12
Loss: 0.5068656760544487
ROC train: 0.696557	val: 0.563074	test: 0.613076
PRC train: 0.683172	val: 0.640688	test: 0.626861

Epoch: 13
Loss: 0.49966143272676933
ROC train: 0.702520	val: 0.561202	test: 0.610496
PRC train: 0.688545	val: 0.640786	test: 0.624044

Epoch: 14
Loss: 0.4969595844197268
ROC train: 0.710787	val: 0.557894	test: 0.610635
PRC train: 0.696061	val: 0.641172	test: 0.625428

Epoch: 15
Loss: 0.4920705987808146
ROC train: 0.716774	val: 0.557210	test: 0.609072
PRC train: 0.701719	val: 0.642864	test: 0.626006

Epoch: 16
Loss: 0.48289526973795643
ROC train: 0.721466	val: 0.563657	test: 0.604226
PRC train: 0.705660	val: 0.643565	test: 0.620593

Epoch: 17
Loss: 0.48559396522848114
ROC train: 0.729466	val: 0.557480	test: 0.616248
PRC train: 0.710340	val: 0.644015	test: 0.632150

Epoch: 18
Loss: 0.47884823441140917
ROC train: 0.734883	val: 0.553446	test: 0.616526
PRC train: 0.714683	val: 0.642947	test: 0.632660

Epoch: 19
Loss: 0.47981981522798656
ROC train: 0.737521	val: 0.559877	test: 0.610980
PRC train: 0.719565	val: 0.645955	test: 0.628398

Epoch: 20
Loss: 0.4764297889943918
ROC train: 0.741020	val: 0.563054	test: 0.612793
PRC train: 0.724684	val: 0.647434	test: 0.633158

Epoch: 21
Loss: 0.47263906191577776
ROC train: 0.749005	val: 0.547100	test: 0.610547
PRC train: 0.728413	val: 0.647114	test: 0.635923

Epoch: 22
Loss: 0.4684658287529853
ROC train: 0.757640	val: 0.555806	test: 0.613328
PRC train: 0.734653	val: 0.650538	test: 0.637199

Epoch: 23
Loss: 0.4690908312232813
ROC train: 0.761955	val: 0.569842	test: 0.605213
PRC train: 0.738086	val: 0.649689	test: 0.629957

Epoch: 24
Loss: 0.46596619871682154
ROC train: 0.762463	val: 0.568165	test: 0.600139
PRC train: 0.738778	val: 0.647351	test: 0.622332

Epoch: 25
Loss: 0.46334606100792997
ROC train: 0.764018	val: 0.567908	test: 0.604171
PRC train: 0.738495	val: 0.643391	test: 0.625267

Epoch: 26
Loss: 0.4609589859044465
ROC train: 0.769163	val: 0.569875	test: 0.606308
PRC train: 0.743396	val: 0.646998	test: 0.630060

Epoch: 27
Loss: 0.4648639222914369
ROC train: 0.773634	val: 0.555682	test: 0.608962
PRC train: 0.744329	val: 0.648127	test: 0.632007

Epoch: 28
Loss: 0.4532615125063617
ROC train: 0.778011	val: 0.565369	test: 0.615407
PRC train: 0.746936	val: 0.648880	test: 0.632944

Epoch: 29
Loss: 0.4578267924948933
ROC train: 0.781892	val: 0.572815	test: 0.613562
PRC train: 0.751498	val: 0.649732	test: 0.631301

Epoch: 30
Loss: 0.4521536163934775
ROC train: 0.786568	val: 0.569543	test: 0.610893
PRC train: 0.756191	val: 0.645630	test: 0.631145

Epoch: 31
Loss: 0.45108228691506025
ROC train: 0.790546	val: 0.565229	test: 0.607434
PRC train: 0.759789	val: 0.646513	test: 0.633367

Epoch: 32
Loss: 0.4533014811230002
ROC train: 0.795087	val: 0.567890	test: 0.610810
PRC train: 0.761512	val: 0.646716	test: 0.635135

Epoch: 33
Loss: 0.44852960368026223Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/scaff/train_prop=0.8/sider_scaff_6_26-05_10-59-58  ]
[ Using Seed :  6  ]
[ Using device :  cuda:2  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6783422599529451
ROC train: 0.547055	val: 0.515927	test: 0.519467
PRC train: 0.586092	val: 0.603706	test: 0.589337

Epoch: 2
Loss: 0.6317779950197459
ROC train: 0.556487	val: 0.506094	test: 0.501266
PRC train: 0.599172	val: 0.595238	test: 0.585118

Epoch: 3
Loss: 0.5937095883505704
ROC train: 0.564991	val: 0.496490	test: 0.495742
PRC train: 0.609290	val: 0.591452	test: 0.583827

Epoch: 4
Loss: 0.569179372073246
ROC train: 0.593037	val: 0.518654	test: 0.521933
PRC train: 0.626125	val: 0.602732	test: 0.593691

Epoch: 5
Loss: 0.5530480396786528
ROC train: 0.619765	val: 0.543722	test: 0.548227
PRC train: 0.639470	val: 0.618337	test: 0.604612

Epoch: 6
Loss: 0.5415341264052325
ROC train: 0.639434	val: 0.561511	test: 0.568876
PRC train: 0.650331	val: 0.630804	test: 0.616945

Epoch: 7
Loss: 0.5375645959067301
ROC train: 0.650926	val: 0.565475	test: 0.581168
PRC train: 0.658001	val: 0.630370	test: 0.622167

Epoch: 8
Loss: 0.522979020196618
ROC train: 0.660586	val: 0.570039	test: 0.585619
PRC train: 0.663887	val: 0.633293	test: 0.624089

Epoch: 9
Loss: 0.5159610707530204
ROC train: 0.670616	val: 0.585073	test: 0.590244
PRC train: 0.670753	val: 0.642550	test: 0.625767

Epoch: 10
Loss: 0.5069632097259883
ROC train: 0.680451	val: 0.594400	test: 0.593912
PRC train: 0.679658	val: 0.641020	test: 0.627437

Epoch: 11
Loss: 0.5009879339067679
ROC train: 0.684621	val: 0.587974	test: 0.593912
PRC train: 0.684112	val: 0.636646	test: 0.627524

Epoch: 12
Loss: 0.4960008872389522
ROC train: 0.696695	val: 0.590569	test: 0.601884
PRC train: 0.693009	val: 0.642813	test: 0.630914

Epoch: 13
Loss: 0.49170233460630053
ROC train: 0.704679	val: 0.597572	test: 0.599221
PRC train: 0.696678	val: 0.646878	test: 0.625785

Epoch: 14
Loss: 0.4919247550117049
ROC train: 0.710642	val: 0.602981	test: 0.606733
PRC train: 0.700451	val: 0.648718	test: 0.629076

Epoch: 15
Loss: 0.4851750226054664
ROC train: 0.715755	val: 0.592229	test: 0.612222
PRC train: 0.704386	val: 0.647390	test: 0.630634

Epoch: 16
Loss: 0.48242504015897536
ROC train: 0.721727	val: 0.603797	test: 0.618618
PRC train: 0.709774	val: 0.652060	test: 0.636437

Epoch: 17
Loss: 0.4841780283858613
ROC train: 0.726034	val: 0.615188	test: 0.617414
PRC train: 0.713242	val: 0.655568	test: 0.638554

Epoch: 18
Loss: 0.4762065648625273
ROC train: 0.729135	val: 0.618325	test: 0.615916
PRC train: 0.715470	val: 0.657728	test: 0.632915

Epoch: 19
Loss: 0.4754293210274052
ROC train: 0.736451	val: 0.618679	test: 0.616745
PRC train: 0.720607	val: 0.657816	test: 0.631054

Epoch: 20
Loss: 0.47079802032292184
ROC train: 0.736412	val: 0.610608	test: 0.613307
PRC train: 0.719376	val: 0.652407	test: 0.633918

Epoch: 21
Loss: 0.47143263700761934
ROC train: 0.742612	val: 0.606144	test: 0.616194
PRC train: 0.724462	val: 0.653227	test: 0.633404

Epoch: 22
Loss: 0.4682931112613131
ROC train: 0.753033	val: 0.610615	test: 0.613254
PRC train: 0.729139	val: 0.656126	test: 0.629793

Epoch: 23
Loss: 0.46508139202583126
ROC train: 0.755308	val: 0.612919	test: 0.612052
PRC train: 0.731775	val: 0.655628	test: 0.626693

Epoch: 24
Loss: 0.46062959756178323
ROC train: 0.757978	val: 0.608920	test: 0.614274
PRC train: 0.733817	val: 0.651707	test: 0.628006

Epoch: 25
Loss: 0.4663729267338688
ROC train: 0.762712	val: 0.616642	test: 0.613958
PRC train: 0.738364	val: 0.656861	test: 0.628815

Epoch: 26
Loss: 0.4633657838554628
ROC train: 0.764007	val: 0.616355	test: 0.613479
PRC train: 0.738497	val: 0.661085	test: 0.629074

Epoch: 27
Loss: 0.4621557498235993
ROC train: 0.767304	val: 0.623381	test: 0.614732
PRC train: 0.742034	val: 0.663879	test: 0.629520

Epoch: 28
Loss: 0.46052541409992054
ROC train: 0.774121	val: 0.617010	test: 0.612022
PRC train: 0.746811	val: 0.663636	test: 0.625164

Epoch: 29
Loss: 0.4538874822135564
ROC train: 0.776519	val: 0.615522	test: 0.605531
PRC train: 0.749188	val: 0.664637	test: 0.621931

Epoch: 30
Loss: 0.4483675689765871
ROC train: 0.780692	val: 0.618462	test: 0.610698
PRC train: 0.752342	val: 0.661256	test: 0.628181

Epoch: 31
Loss: 0.45124953512848087
ROC train: 0.786887	val: 0.615632	test: 0.611136
PRC train: 0.754826	val: 0.660654	test: 0.628204

Epoch: 32
Loss: 0.4514238767383638
ROC train: 0.782954	val: 0.608611	test: 0.611185
PRC train: 0.751646	val: 0.657169	test: 0.626250

Epoch: 33
Loss: 0.447742063742231Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/scaff/train_prop=0.8/sider_scaff_4_26-05_10-59-58  ]
[ Using Seed :  4  ]
[ Using device :  cuda:2  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6882747669287028
ROC train: 0.548477	val: 0.503748	test: 0.490665
PRC train: 0.589194	val: 0.607712	test: 0.574489

Epoch: 2
Loss: 0.6369503026644268
ROC train: 0.570320	val: 0.511753	test: 0.507871
PRC train: 0.606914	val: 0.604614	test: 0.583392

Epoch: 3
Loss: 0.5944787072293212
ROC train: 0.573020	val: 0.506289	test: 0.504833
PRC train: 0.612105	val: 0.600310	test: 0.586042

Epoch: 4
Loss: 0.5704258719422924
ROC train: 0.591988	val: 0.515654	test: 0.520700
PRC train: 0.624668	val: 0.608766	test: 0.592339

Epoch: 5
Loss: 0.5565078568386421
ROC train: 0.623533	val: 0.539066	test: 0.554105
PRC train: 0.642997	val: 0.623282	test: 0.606407

Epoch: 6
Loss: 0.5445098810688955
ROC train: 0.641307	val: 0.543479	test: 0.569630
PRC train: 0.649912	val: 0.628705	test: 0.612946

Epoch: 7
Loss: 0.5369939803219308
ROC train: 0.652001	val: 0.557999	test: 0.575242
PRC train: 0.655783	val: 0.640468	test: 0.614814

Epoch: 8
Loss: 0.5218464504278593
ROC train: 0.665370	val: 0.567982	test: 0.581442
PRC train: 0.664463	val: 0.645274	test: 0.615714

Epoch: 9
Loss: 0.5140351013264483
ROC train: 0.676487	val: 0.567312	test: 0.585816
PRC train: 0.671695	val: 0.642970	test: 0.619684

Epoch: 10
Loss: 0.5081091932437992
ROC train: 0.686783	val: 0.565535	test: 0.596698
PRC train: 0.680043	val: 0.639847	test: 0.629286

Epoch: 11
Loss: 0.49964940823172793
ROC train: 0.695147	val: 0.578942	test: 0.595105
PRC train: 0.684970	val: 0.648509	test: 0.624215

Epoch: 12
Loss: 0.4968273949145547
ROC train: 0.702199	val: 0.583434	test: 0.591665
PRC train: 0.690486	val: 0.650058	test: 0.627985

Epoch: 13
Loss: 0.49177861013180396
ROC train: 0.708390	val: 0.585761	test: 0.595760
PRC train: 0.695892	val: 0.648610	test: 0.629007

Epoch: 14
Loss: 0.4861193522352442
ROC train: 0.720288	val: 0.596083	test: 0.602094
PRC train: 0.704575	val: 0.653855	test: 0.631669

Epoch: 15
Loss: 0.48327501315353655
ROC train: 0.723347	val: 0.594361	test: 0.603243
PRC train: 0.706957	val: 0.659013	test: 0.628273

Epoch: 16
Loss: 0.4807059346282244
ROC train: 0.734962	val: 0.593606	test: 0.604954
PRC train: 0.714228	val: 0.656807	test: 0.626779

Epoch: 17
Loss: 0.4729513952891555
ROC train: 0.740600	val: 0.594685	test: 0.607374
PRC train: 0.718704	val: 0.656926	test: 0.631336

Epoch: 18
Loss: 0.47250917660042246
ROC train: 0.743385	val: 0.602679	test: 0.606779
PRC train: 0.720783	val: 0.657728	test: 0.633729

Epoch: 19
Loss: 0.4681669421032984
ROC train: 0.750066	val: 0.609374	test: 0.610101
PRC train: 0.726688	val: 0.659315	test: 0.630803

Epoch: 20
Loss: 0.4651689135671053
ROC train: 0.755778	val: 0.617359	test: 0.616738
PRC train: 0.731151	val: 0.662202	test: 0.632304

Epoch: 21
Loss: 0.46652994068152526
ROC train: 0.753307	val: 0.620747	test: 0.616903
PRC train: 0.731416	val: 0.660965	test: 0.636910

Epoch: 22
Loss: 0.46221756609116493
ROC train: 0.762134	val: 0.617215	test: 0.617686
PRC train: 0.736120	val: 0.661575	test: 0.635470

Epoch: 23
Loss: 0.4624789755236365
ROC train: 0.770552	val: 0.612012	test: 0.610748
PRC train: 0.743873	val: 0.659215	test: 0.633752

Epoch: 24
Loss: 0.45955980552637143
ROC train: 0.774428	val: 0.617903	test: 0.618304
PRC train: 0.747547	val: 0.662107	test: 0.633685

Epoch: 25
Loss: 0.45374132066939155
ROC train: 0.774162	val: 0.615819	test: 0.618489
PRC train: 0.747400	val: 0.665008	test: 0.633716

Epoch: 26
Loss: 0.4574025616627849
ROC train: 0.772738	val: 0.614344	test: 0.613415
PRC train: 0.747129	val: 0.664391	test: 0.636293

Epoch: 27
Loss: 0.4578477974747007
ROC train: 0.781844	val: 0.627385	test: 0.603127
PRC train: 0.752180	val: 0.672904	test: 0.626771

Epoch: 28
Loss: 0.44859613838817075
ROC train: 0.786754	val: 0.624910	test: 0.599489
PRC train: 0.754410	val: 0.671203	test: 0.623939

Epoch: 29
Loss: 0.4507042368500243
ROC train: 0.788119	val: 0.634441	test: 0.602027
PRC train: 0.755758	val: 0.668712	test: 0.629429

Epoch: 30
Loss: 0.4484245085595567
ROC train: 0.791227	val: 0.638463	test: 0.600222
PRC train: 0.758511	val: 0.672711	test: 0.628440

Epoch: 31
Loss: 0.4517941143177458
ROC train: 0.790857	val: 0.615018	test: 0.601245
PRC train: 0.758643	val: 0.667425	test: 0.626116

Epoch: 32
Loss: 0.4435759256383517
ROC train: 0.801145	val: 0.620128	test: 0.598226
PRC train: 0.765315	val: 0.667909	test: 0.625578

Epoch: 33
Loss: 0.4414951364767076Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/scaff/train_prop=0.8/sider_scaff_5_26-05_10-59-58  ]
[ Using Seed :  5  ]
[ Using device :  cuda:2  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6896633639960229
ROC train: 0.538927	val: 0.523479	test: 0.469154
PRC train: 0.585955	val: 0.611489	test: 0.573664

Epoch: 2
Loss: 0.6382178691310492
ROC train: 0.561693	val: 0.506280	test: 0.492982
PRC train: 0.604117	val: 0.602689	test: 0.581276

Epoch: 3
Loss: 0.5971578956953222
ROC train: 0.579439	val: 0.506632	test: 0.502043
PRC train: 0.615474	val: 0.601866	test: 0.587640

Epoch: 4
Loss: 0.5726369030103517
ROC train: 0.605537	val: 0.526944	test: 0.527434
PRC train: 0.629556	val: 0.611908	test: 0.594849

Epoch: 5
Loss: 0.5542475169818585
ROC train: 0.629008	val: 0.545477	test: 0.555394
PRC train: 0.643956	val: 0.621221	test: 0.607064

Epoch: 6
Loss: 0.5429790504000562
ROC train: 0.644195	val: 0.559059	test: 0.571019
PRC train: 0.652869	val: 0.627017	test: 0.615328

Epoch: 7
Loss: 0.5309302798370255
ROC train: 0.654332	val: 0.576518	test: 0.578785
PRC train: 0.658642	val: 0.635816	test: 0.619196

Epoch: 8
Loss: 0.5243098229793699
ROC train: 0.667701	val: 0.589726	test: 0.587288
PRC train: 0.667712	val: 0.642885	test: 0.622572

Epoch: 9
Loss: 0.5171869020982243
ROC train: 0.675792	val: 0.585315	test: 0.594305
PRC train: 0.671608	val: 0.646572	test: 0.622140

Epoch: 10
Loss: 0.5116106788499611
ROC train: 0.680776	val: 0.593465	test: 0.588204
PRC train: 0.674204	val: 0.648507	test: 0.618967

Epoch: 11
Loss: 0.5031833959912566
ROC train: 0.693750	val: 0.602850	test: 0.600991
PRC train: 0.684861	val: 0.653663	test: 0.625136

Epoch: 12
Loss: 0.49230419554483784
ROC train: 0.695666	val: 0.598819	test: 0.584356
PRC train: 0.689088	val: 0.650520	test: 0.619774

Epoch: 13
Loss: 0.49537518127239843
ROC train: 0.707289	val: 0.596959	test: 0.588569
PRC train: 0.695889	val: 0.650586	test: 0.623943

Epoch: 14
Loss: 0.48370452284445975
ROC train: 0.718809	val: 0.613641	test: 0.598313
PRC train: 0.701559	val: 0.658664	test: 0.628327

Epoch: 15
Loss: 0.4867532794307644
ROC train: 0.722963	val: 0.606797	test: 0.591815
PRC train: 0.704902	val: 0.655947	test: 0.624673

Epoch: 16
Loss: 0.4883884365102545
ROC train: 0.723903	val: 0.600692	test: 0.592380
PRC train: 0.706242	val: 0.652001	test: 0.623718

Epoch: 17
Loss: 0.4789915283899755
ROC train: 0.728226	val: 0.616773	test: 0.604036
PRC train: 0.707987	val: 0.665098	test: 0.627134

Epoch: 18
Loss: 0.47632929967208054
ROC train: 0.734429	val: 0.633302	test: 0.612261
PRC train: 0.715602	val: 0.663931	test: 0.629800

Epoch: 19
Loss: 0.4719472256497073
ROC train: 0.739593	val: 0.622423	test: 0.612976
PRC train: 0.719873	val: 0.662167	test: 0.627154

Epoch: 20
Loss: 0.4751084833501881
ROC train: 0.739354	val: 0.608588	test: 0.608468
PRC train: 0.717448	val: 0.659031	test: 0.623194

Epoch: 21
Loss: 0.4667392602397918
ROC train: 0.750282	val: 0.612279	test: 0.604780
PRC train: 0.725981	val: 0.662369	test: 0.623563

Epoch: 22
Loss: 0.4662706606769705
ROC train: 0.753557	val: 0.617185	test: 0.605434
PRC train: 0.729781	val: 0.661948	test: 0.626456

Epoch: 23
Loss: 0.4620762354141054
ROC train: 0.754502	val: 0.617002	test: 0.600730
PRC train: 0.729359	val: 0.664268	test: 0.623118

Epoch: 24
Loss: 0.4618823125248078
ROC train: 0.761885	val: 0.624855	test: 0.605028
PRC train: 0.734684	val: 0.667336	test: 0.625187

Epoch: 25
Loss: 0.4565627756585321
ROC train: 0.770195	val: 0.626048	test: 0.608758
PRC train: 0.743608	val: 0.665489	test: 0.626345

Epoch: 26
Loss: 0.45958695096855573
ROC train: 0.770048	val: 0.622812	test: 0.612182
PRC train: 0.745070	val: 0.665700	test: 0.631571

Epoch: 27
Loss: 0.45912298039392907
ROC train: 0.772574	val: 0.625216	test: 0.609658
PRC train: 0.746014	val: 0.669225	test: 0.630905

Epoch: 28
Loss: 0.45527785675158833
ROC train: 0.777898	val: 0.626676	test: 0.610934
PRC train: 0.749820	val: 0.671253	test: 0.631639

Epoch: 29
Loss: 0.4585958689091865
ROC train: 0.784604	val: 0.635545	test: 0.602826
PRC train: 0.755823	val: 0.672574	test: 0.626615

Epoch: 30
Loss: 0.45625305985221043
ROC train: 0.786059	val: 0.638709	test: 0.597842
PRC train: 0.756833	val: 0.672764	test: 0.624570

Epoch: 31
Loss: 0.4514625494107575
ROC train: 0.787399	val: 0.636230	test: 0.597262
PRC train: 0.756466	val: 0.666566	test: 0.626193

Epoch: 32
Loss: 0.4488628528561918
ROC train: 0.788366	val: 0.631960	test: 0.593534
PRC train: 0.756470	val: 0.666977	test: 0.627021

Epoch: 33
Loss: 0.4511047884617823
PRC train: 0.756962	val: 0.649288	test: 0.635202

Epoch: 34
Loss: 0.4424848765734596
ROC train: 0.803013	val: 0.579531	test: 0.597715
PRC train: 0.761081	val: 0.650552	test: 0.632628

Epoch: 35
Loss: 0.44717891245079067
ROC train: 0.803844	val: 0.576435	test: 0.597176
PRC train: 0.762374	val: 0.648555	test: 0.631508

Epoch: 36
Loss: 0.44713221349973953
ROC train: 0.807761	val: 0.566828	test: 0.594845
PRC train: 0.766362	val: 0.643069	test: 0.633719

Epoch: 37
Loss: 0.44045703361584954
ROC train: 0.810542	val: 0.562245	test: 0.593843
PRC train: 0.764718	val: 0.642611	test: 0.633818

Epoch: 38
Loss: 0.4385688876611759
ROC train: 0.811649	val: 0.569209	test: 0.588748
PRC train: 0.766549	val: 0.648789	test: 0.630598

Epoch: 39
Loss: 0.4412578216255403
ROC train: 0.814263	val: 0.566176	test: 0.584203
PRC train: 0.768269	val: 0.648316	test: 0.628860

Epoch: 40
Loss: 0.44144222048158555
ROC train: 0.816739	val: 0.568273	test: 0.583444
PRC train: 0.771555	val: 0.648241	test: 0.626527

Epoch: 41
Loss: 0.4338690638084487
ROC train: 0.811144	val: 0.572231	test: 0.584391
PRC train: 0.768496	val: 0.648713	test: 0.621852

Epoch: 42
Loss: 0.4408988520534641
ROC train: 0.817334	val: 0.574301	test: 0.587609
PRC train: 0.775159	val: 0.650052	test: 0.624723

Epoch: 43
Loss: 0.4258346212298079
ROC train: 0.822184	val: 0.578401	test: 0.589444
PRC train: 0.780184	val: 0.650715	test: 0.625309

Epoch: 44
Loss: 0.42676461771017693
ROC train: 0.826245	val: 0.581641	test: 0.590735
PRC train: 0.781592	val: 0.651936	test: 0.626488

Epoch: 45
Loss: 0.4264402556922291
ROC train: 0.826370	val: 0.579818	test: 0.590574
PRC train: 0.779292	val: 0.654444	test: 0.623228

Epoch: 46
Loss: 0.42633652387803533
ROC train: 0.828611	val: 0.573547	test: 0.590697
PRC train: 0.781879	val: 0.651758	test: 0.625797

Epoch: 47
Loss: 0.4263081072757139
ROC train: 0.830029	val: 0.559587	test: 0.587253
PRC train: 0.783987	val: 0.643501	test: 0.626695

Epoch: 48
Loss: 0.42429299761496225
ROC train: 0.831679	val: 0.559750	test: 0.592982
PRC train: 0.785659	val: 0.642264	test: 0.627436

Epoch: 49
Loss: 0.42117934864900214
ROC train: 0.829880	val: 0.564778	test: 0.596835
PRC train: 0.784580	val: 0.642641	test: 0.626731

Epoch: 50
Loss: 0.42543947971923984
ROC train: 0.831198	val: 0.566484	test: 0.597835
PRC train: 0.785909	val: 0.641255	test: 0.628501

Epoch: 51
Loss: 0.42335640329507235
ROC train: 0.836661	val: 0.564436	test: 0.592186
PRC train: 0.790878	val: 0.638676	test: 0.626607

Epoch: 52
Loss: 0.4141095194195208
ROC train: 0.837925	val: 0.563164	test: 0.588504
PRC train: 0.790792	val: 0.638623	test: 0.625761

Epoch: 53
Loss: 0.41996037930704333
ROC train: 0.838496	val: 0.564709	test: 0.583465
PRC train: 0.790627	val: 0.640663	test: 0.623489

Epoch: 54
Loss: 0.41720471363243267
ROC train: 0.841869	val: 0.565813	test: 0.582835
PRC train: 0.795551	val: 0.639835	test: 0.622931

Epoch: 55
Loss: 0.4172189267201043
ROC train: 0.842511	val: 0.571983	test: 0.587161
PRC train: 0.795402	val: 0.643198	test: 0.627340

Epoch: 56
Loss: 0.4163831032167311
ROC train: 0.847038	val: 0.574733	test: 0.589490
PRC train: 0.799109	val: 0.643386	test: 0.627849

Epoch: 57
Loss: 0.41044673111910557
ROC train: 0.848052	val: 0.574931	test: 0.592399
PRC train: 0.800639	val: 0.645099	test: 0.628944

Epoch: 58
Loss: 0.39993100730100295
ROC train: 0.846947	val: 0.574186	test: 0.597396
PRC train: 0.799434	val: 0.646143	test: 0.630226

Epoch: 59
Loss: 0.41998269159101187
ROC train: 0.845619	val: 0.564660	test: 0.596335
PRC train: 0.799697	val: 0.642594	test: 0.629597

Epoch: 60
Loss: 0.40849984086978863
ROC train: 0.847086	val: 0.564087	test: 0.586980
PRC train: 0.801381	val: 0.643021	test: 0.621161

Epoch: 61
Loss: 0.4060171895384427
ROC train: 0.851403	val: 0.559873	test: 0.583945
PRC train: 0.802987	val: 0.640568	test: 0.621287

Epoch: 62
Loss: 0.40850018948859645
ROC train: 0.846760	val: 0.560419	test: 0.579974
PRC train: 0.798346	val: 0.641945	test: 0.619709

Epoch: 63
Loss: 0.40426096555978897
ROC train: 0.854792	val: 0.563884	test: 0.582686
PRC train: 0.806762	val: 0.644732	test: 0.618904

Epoch: 64
Loss: 0.4052952999871111
ROC train: 0.855861	val: 0.561566	test: 0.583413
PRC train: 0.809468	val: 0.641489	test: 0.619094

Epoch: 65
Loss: 0.39985321220964315
ROC train: 0.856825	val: 0.560300	test: 0.587903
PRC train: 0.809980	val: 0.638959	test: 0.622190

Epoch: 66
Loss: 0.3974609190170646
ROC train: 0.851442	val: 0.562294	test: 0.585175
PRC train: 0.805205	val: 0.641015	test: 0.622346

Epoch: 67
Loss: 0.407166215479912
ROC train: 0.856182	val: 0.559561	test: 0.588236
PRC train: 0.810572	val: 0.637037	test: 0.624317

Epoch: 68
Loss: 0.40083101891439615
ROC train: 0.856798	val: 0.571598	test: 0.588139
PRC train: 0.810537	val: 0.641632	test: 0.624901

Epoch: 69
Loss: 0.39674804810841124
ROC train: 0.861087	val: 0.573096	test: 0.585142
PRC train: 0.814744	val: 0.641098	test: 0.624725

Epoch: 70
Loss: 0.4017553387990086
ROC train: 0.864240	val: 0.569815	test: 0.586914
PRC train: 0.819540	val: 0.640180	test: 0.627929

Epoch: 71
Loss: 0.40077351136349826
ROC train: 0.863879	val: 0.563723	test: 0.589397
PRC train: 0.819999	val: 0.636747	test: 0.626611

Epoch: 72
Loss: 0.3967171200361358
ROC train: 0.868906	val: 0.557583	test: 0.592534
PRC train: 0.822611	val: 0.634836	test: 0.629986

Epoch: 73
Loss: 0.393194146016288
ROC train: 0.868505	val: 0.561905	test: 0.593353
PRC train: 0.820203	val: 0.637254	test: 0.627653

Epoch: 74
Loss: 0.3928400777051614
ROC train: 0.868071	val: 0.565745	test: 0.592772
PRC train: 0.822449	val: 0.638823	test: 0.623622

Epoch: 75
Loss: 0.38773952377207477
ROC train: 0.869913	val: 0.562317	test: 0.586338
PRC train: 0.826985	val: 0.635633	test: 0.623726

Epoch: 76
Loss: 0.3890417869220822
ROC train: 0.870988	val: 0.559565	test: 0.585459
PRC train: 0.829232	val: 0.632932	test: 0.627793

Epoch: 77
Loss: 0.3883524798907749
ROC train: 0.874585	val: 0.564245	test: 0.592050
PRC train: 0.830508	val: 0.637840	test: 0.629854

Epoch: 78
Loss: 0.38829456548236907
ROC train: 0.871007	val: 0.571376	test: 0.592482
PRC train: 0.824468	val: 0.643482	test: 0.626171

Epoch: 79
Loss: 0.3925516717405812
ROC train: 0.876072	val: 0.570458	test: 0.596765
PRC train: 0.830226	val: 0.643553	test: 0.627702

Epoch: 80
Loss: 0.3840655212668033
ROC train: 0.876381	val: 0.567265	test: 0.593451
PRC train: 0.834293	val: 0.642492	test: 0.628478

Epoch: 81
Loss: 0.3814639280185125
ROC train: 0.880317	val: 0.569797	test: 0.591776
PRC train: 0.838777	val: 0.643281	test: 0.628608

Epoch: 82
Loss: 0.3830315140160141
ROC train: 0.878150	val: 0.577643	test: 0.592908
PRC train: 0.839456	val: 0.645736	test: 0.626722

Epoch: 83
Loss: 0.37315966147190527
ROC train: 0.878000	val: 0.580360	test: 0.591838
PRC train: 0.839962	val: 0.646867	test: 0.627191

Epoch: 84
Loss: 0.37551005638582846
ROC train: 0.880436	val: 0.581782	test: 0.588330
PRC train: 0.843437	val: 0.650304	test: 0.625727

Epoch: 85
Loss: 0.3752983598090038
ROC train: 0.883951	val: 0.584508	test: 0.590373
PRC train: 0.842943	val: 0.655377	test: 0.626809

Epoch: 86
Loss: 0.37257498300958714
ROC train: 0.884240	val: 0.581132	test: 0.595339
PRC train: 0.839730	val: 0.653632	test: 0.628663

Epoch: 87
Loss: 0.37971830321404
ROC train: 0.885134	val: 0.572326	test: 0.598804
PRC train: 0.843051	val: 0.645725	test: 0.630154

Epoch: 88
Loss: 0.37873937627376303
ROC train: 0.882630	val: 0.572916	test: 0.597326
PRC train: 0.841366	val: 0.644990	test: 0.628089

Epoch: 89
Loss: 0.3755200431202388
ROC train: 0.882271	val: 0.578219	test: 0.595883
PRC train: 0.840294	val: 0.646039	test: 0.627114

Epoch: 90
Loss: 0.37750337478831125
ROC train: 0.884222	val: 0.577482	test: 0.594172
PRC train: 0.841761	val: 0.642407	test: 0.626847

Epoch: 91
Loss: 0.37017106770840963
ROC train: 0.887830	val: 0.577486	test: 0.591545
PRC train: 0.845699	val: 0.642166	test: 0.627186

Epoch: 92
Loss: 0.3746532572856687
ROC train: 0.888753	val: 0.574190	test: 0.588516
PRC train: 0.848135	val: 0.639793	test: 0.625207

Epoch: 93
Loss: 0.37343266412167225
ROC train: 0.890646	val: 0.570469	test: 0.587010
PRC train: 0.849680	val: 0.640655	test: 0.628927

Epoch: 94
Loss: 0.368882538768531
ROC train: 0.890836	val: 0.565041	test: 0.583991ROC train: 0.795128	val: 0.537701	test: 0.599478
PRC train: 0.752969	val: 0.626447	test: 0.633532

Epoch: 34
Loss: 0.43880176635201035
ROC train: 0.792954	val: 0.533107	test: 0.599122
PRC train: 0.750708	val: 0.621967	test: 0.631341

Epoch: 35
Loss: 0.4463618378762051
ROC train: 0.786153	val: 0.529709	test: 0.596109
PRC train: 0.741764	val: 0.618771	test: 0.630384

Epoch: 36
Loss: 0.4444225106795562
ROC train: 0.803378	val: 0.539580	test: 0.602453
PRC train: 0.761660	val: 0.628210	test: 0.633950

Epoch: 37
Loss: 0.4448013941294797
ROC train: 0.809402	val: 0.545265	test: 0.605308
PRC train: 0.766610	val: 0.630170	test: 0.633341

Epoch: 38
Loss: 0.4415870311826162
ROC train: 0.807852	val: 0.545724	test: 0.602434
PRC train: 0.764274	val: 0.625595	test: 0.635297

Epoch: 39
Loss: 0.4371518761917231
ROC train: 0.807181	val: 0.553229	test: 0.609174
PRC train: 0.765104	val: 0.631335	test: 0.636398

Epoch: 40
Loss: 0.4351362361475066
ROC train: 0.807874	val: 0.545573	test: 0.603621
PRC train: 0.765623	val: 0.630128	test: 0.634732

Epoch: 41
Loss: 0.4446869215293931
ROC train: 0.809704	val: 0.536329	test: 0.597492
PRC train: 0.765439	val: 0.624433	test: 0.632772

Epoch: 42
Loss: 0.43452480883828537
ROC train: 0.809978	val: 0.532116	test: 0.593679
PRC train: 0.762617	val: 0.617566	test: 0.630326

Epoch: 43
Loss: 0.4391975774690912
ROC train: 0.817188	val: 0.539665	test: 0.597888
PRC train: 0.771803	val: 0.619512	test: 0.631506

Epoch: 44
Loss: 0.4387231184358926
ROC train: 0.817642	val: 0.539564	test: 0.599037
PRC train: 0.770480	val: 0.618573	test: 0.634404

Epoch: 45
Loss: 0.4332419814371606
ROC train: 0.817278	val: 0.539210	test: 0.601196
PRC train: 0.768089	val: 0.618787	test: 0.635972

Epoch: 46
Loss: 0.429728459898456
ROC train: 0.827266	val: 0.542264	test: 0.600674
PRC train: 0.779881	val: 0.618942	test: 0.631650

Epoch: 47
Loss: 0.42930072072019
ROC train: 0.830449	val: 0.545832	test: 0.602157
PRC train: 0.783358	val: 0.623660	test: 0.631166

Epoch: 48
Loss: 0.4241925845925839
ROC train: 0.834897	val: 0.542646	test: 0.599762
PRC train: 0.785376	val: 0.623229	test: 0.633741

Epoch: 49
Loss: 0.4202959946547848
ROC train: 0.828754	val: 0.537995	test: 0.595261
PRC train: 0.779733	val: 0.621055	test: 0.631891

Epoch: 50
Loss: 0.4243229071315919
ROC train: 0.831520	val: 0.546244	test: 0.599690
PRC train: 0.782672	val: 0.624870	test: 0.635610

Epoch: 51
Loss: 0.4140071835968592
ROC train: 0.836774	val: 0.551155	test: 0.600484
PRC train: 0.787097	val: 0.627741	test: 0.634337

Epoch: 52
Loss: 0.41918585697212024
ROC train: 0.835693	val: 0.541934	test: 0.594655
PRC train: 0.786408	val: 0.620958	test: 0.630068

Epoch: 53
Loss: 0.4138885852940558
ROC train: 0.839219	val: 0.538863	test: 0.596625
PRC train: 0.791428	val: 0.619260	test: 0.630981

Epoch: 54
Loss: 0.4158966480500911
ROC train: 0.840478	val: 0.543876	test: 0.599497
PRC train: 0.794043	val: 0.623454	test: 0.633201

Epoch: 55
Loss: 0.4121155381699508
ROC train: 0.841307	val: 0.545003	test: 0.599376
PRC train: 0.794446	val: 0.624740	test: 0.634635

Epoch: 56
Loss: 0.4109154867259108
ROC train: 0.849356	val: 0.548349	test: 0.597740
PRC train: 0.801114	val: 0.627566	test: 0.632396

Epoch: 57
Loss: 0.41901281634268817
ROC train: 0.847776	val: 0.538972	test: 0.591162
PRC train: 0.801252	val: 0.622766	test: 0.630188

Epoch: 58
Loss: 0.4168630514907559
ROC train: 0.844646	val: 0.529560	test: 0.589376
PRC train: 0.798471	val: 0.617176	test: 0.633783

Epoch: 59
Loss: 0.41007298088443567
ROC train: 0.849279	val: 0.539815	test: 0.596617
PRC train: 0.799759	val: 0.624401	test: 0.638300

Epoch: 60
Loss: 0.41116942046062704
ROC train: 0.850967	val: 0.549999	test: 0.600279
PRC train: 0.803904	val: 0.629931	test: 0.638633

Epoch: 61
Loss: 0.4058729296526244
ROC train: 0.856106	val: 0.552298	test: 0.606760
PRC train: 0.808510	val: 0.630684	test: 0.642033

Epoch: 62
Loss: 0.4026944427986405
ROC train: 0.856178	val: 0.547919	test: 0.611872
PRC train: 0.808744	val: 0.627766	test: 0.643410

Epoch: 63
Loss: 0.40809517993154903
ROC train: 0.856304	val: 0.543810	test: 0.609337
PRC train: 0.809068	val: 0.622798	test: 0.640492

Epoch: 64
Loss: 0.40607863407164174
ROC train: 0.853852	val: 0.547583	test: 0.608096
PRC train: 0.808331	val: 0.624963	test: 0.636609

Epoch: 65
Loss: 0.40362461474441247
ROC train: 0.855102	val: 0.546326	test: 0.606938
PRC train: 0.810766	val: 0.623130	test: 0.634117

Epoch: 66
Loss: 0.39861331005125555
ROC train: 0.853925	val: 0.545360	test: 0.605358
PRC train: 0.806498	val: 0.623309	test: 0.636856

Epoch: 67
Loss: 0.4036414620494255
ROC train: 0.856308	val: 0.545627	test: 0.604976
PRC train: 0.808919	val: 0.624582	test: 0.638356

Epoch: 68
Loss: 0.39981134252941175
ROC train: 0.861905	val: 0.548739	test: 0.605517
PRC train: 0.815990	val: 0.624592	test: 0.635934

Epoch: 69
Loss: 0.39337634013273004
ROC train: 0.862427	val: 0.554971	test: 0.605866
PRC train: 0.816610	val: 0.629399	test: 0.635078

Epoch: 70
Loss: 0.3961451944704355
ROC train: 0.865946	val: 0.552452	test: 0.603632
PRC train: 0.818501	val: 0.628439	test: 0.636371

Epoch: 71
Loss: 0.3944965542483198
ROC train: 0.867370	val: 0.551115	test: 0.596414
PRC train: 0.819538	val: 0.625008	test: 0.636208

Epoch: 72
Loss: 0.3926931744878074
ROC train: 0.868853	val: 0.548802	test: 0.597765
PRC train: 0.821040	val: 0.624927	test: 0.637262

Epoch: 73
Loss: 0.39853979621951513
ROC train: 0.871307	val: 0.549929	test: 0.600089
PRC train: 0.823415	val: 0.627684	test: 0.636194

Epoch: 74
Loss: 0.3901939670861858
ROC train: 0.869277	val: 0.551511	test: 0.598533
PRC train: 0.822510	val: 0.630035	test: 0.634043

Epoch: 75
Loss: 0.38939559226748244
ROC train: 0.863465	val: 0.541312	test: 0.586995
PRC train: 0.817283	val: 0.624139	test: 0.629030

Epoch: 76
Loss: 0.38173323697122075
ROC train: 0.866939	val: 0.545324	test: 0.587851
PRC train: 0.821368	val: 0.626569	test: 0.628078

Epoch: 77
Loss: 0.3936678193752879
ROC train: 0.873519	val: 0.551333	test: 0.592832
PRC train: 0.827690	val: 0.628155	test: 0.632042

Epoch: 78
Loss: 0.38222491298245753
ROC train: 0.876454	val: 0.553591	test: 0.601653
PRC train: 0.829440	val: 0.626925	test: 0.637238

Epoch: 79
Loss: 0.39089277908046166
ROC train: 0.877324	val: 0.556376	test: 0.603589
PRC train: 0.829635	val: 0.629234	test: 0.637792

Epoch: 80
Loss: 0.37772902536205955
ROC train: 0.877526	val: 0.560277	test: 0.598133
PRC train: 0.831005	val: 0.632394	test: 0.635838

Epoch: 81
Loss: 0.3838761141336944
ROC train: 0.872120	val: 0.554767	test: 0.592890
PRC train: 0.825129	val: 0.629380	test: 0.634193

Epoch: 82
Loss: 0.3928537392403705
ROC train: 0.878034	val: 0.560540	test: 0.598308
PRC train: 0.831511	val: 0.634275	test: 0.638195

Epoch: 83
Loss: 0.3789722965196135
ROC train: 0.878586	val: 0.562026	test: 0.609511
PRC train: 0.830856	val: 0.635143	test: 0.642005

Epoch: 84
Loss: 0.37514848292695707
ROC train: 0.881476	val: 0.565701	test: 0.612095
PRC train: 0.835387	val: 0.635142	test: 0.641300

Epoch: 85
Loss: 0.3753030005970587
ROC train: 0.882789	val: 0.558538	test: 0.602698
PRC train: 0.838190	val: 0.628666	test: 0.638506

Epoch: 86
Loss: 0.3743115122804336
ROC train: 0.875278	val: 0.549699	test: 0.590897
PRC train: 0.833177	val: 0.624001	test: 0.634018

Epoch: 87
Loss: 0.37591679725817945
ROC train: 0.881176	val: 0.557258	test: 0.598785
PRC train: 0.838586	val: 0.631640	test: 0.638469

Epoch: 88
Loss: 0.38173383931523175
ROC train: 0.884221	val: 0.565623	test: 0.610049
PRC train: 0.840096	val: 0.636220	test: 0.642469

Epoch: 89
Loss: 0.3800789233559696
ROC train: 0.888680	val: 0.565884	test: 0.608769
PRC train: 0.842424	val: 0.633626	test: 0.643866

Epoch: 90
Loss: 0.368453708752106
ROC train: 0.889446	val: 0.558928	test: 0.601841
PRC train: 0.843656	val: 0.629558	test: 0.641732

Epoch: 91
Loss: 0.36721664568161494
ROC train: 0.887503	val: 0.556779	test: 0.596873
PRC train: 0.843327	val: 0.626962	test: 0.638525

Epoch: 92
Loss: 0.3730962698778816
ROC train: 0.891418	val: 0.557061	test: 0.596551
PRC train: 0.847968	val: 0.626326	test: 0.637335

Epoch: 93
Loss: 0.3702622633479643
ROC train: 0.894322	val: 0.558608	test: 0.602180
PRC train: 0.851911	val: 0.627151	test: 0.640255

Epoch: 94
Loss: 0.37538711566802085

ROC train: 0.791481	val: 0.544268	test: 0.581701
PRC train: 0.750796	val: 0.629448	test: 0.622900

Epoch: 34
Loss: 0.4459837539639472
ROC train: 0.795596	val: 0.535248	test: 0.576980
PRC train: 0.755457	val: 0.623449	test: 0.620650

Epoch: 35
Loss: 0.4450046003067086
ROC train: 0.801348	val: 0.546344	test: 0.585051
PRC train: 0.762486	val: 0.630034	test: 0.625376

Epoch: 36
Loss: 0.4401158777878816
ROC train: 0.800355	val: 0.551870	test: 0.591242
PRC train: 0.763276	val: 0.633596	test: 0.628897

Epoch: 37
Loss: 0.4378917348915759
ROC train: 0.803380	val: 0.551768	test: 0.589057
PRC train: 0.763687	val: 0.630158	test: 0.630410

Epoch: 38
Loss: 0.4398236711541857
ROC train: 0.800815	val: 0.549082	test: 0.584591
PRC train: 0.761235	val: 0.628118	test: 0.629141

Epoch: 39
Loss: 0.44980790461674025
ROC train: 0.808378	val: 0.552308	test: 0.579970
PRC train: 0.766239	val: 0.632404	test: 0.626004

Epoch: 40
Loss: 0.4337671039958973
ROC train: 0.812818	val: 0.549300	test: 0.576305
PRC train: 0.770349	val: 0.629708	test: 0.623597

Epoch: 41
Loss: 0.4331604829618588
ROC train: 0.812884	val: 0.551171	test: 0.582113
PRC train: 0.771589	val: 0.631581	test: 0.624940

Epoch: 42
Loss: 0.4369286218982451
ROC train: 0.816046	val: 0.548482	test: 0.587170
PRC train: 0.773876	val: 0.632906	test: 0.626452

Epoch: 43
Loss: 0.43490836445643305
ROC train: 0.819931	val: 0.542537	test: 0.590113
PRC train: 0.777295	val: 0.627077	test: 0.629776

Epoch: 44
Loss: 0.43185027259406905
ROC train: 0.818806	val: 0.535528	test: 0.589462
PRC train: 0.776277	val: 0.620120	test: 0.629449

Epoch: 45
Loss: 0.4312126616883856
ROC train: 0.818604	val: 0.532855	test: 0.587830
PRC train: 0.777273	val: 0.617486	test: 0.626966

Epoch: 46
Loss: 0.4281236051031748
ROC train: 0.821158	val: 0.532359	test: 0.579282
PRC train: 0.778370	val: 0.620032	test: 0.626308

Epoch: 47
Loss: 0.4365499690412101
ROC train: 0.823325	val: 0.539350	test: 0.570959
PRC train: 0.779225	val: 0.626490	test: 0.621112

Epoch: 48
Loss: 0.425452379672943
ROC train: 0.824991	val: 0.552060	test: 0.572931
PRC train: 0.781467	val: 0.634049	test: 0.621428

Epoch: 49
Loss: 0.4313517273710694
ROC train: 0.823332	val: 0.552791	test: 0.585385
PRC train: 0.782480	val: 0.631252	test: 0.625553

Epoch: 50
Loss: 0.4327126011595466
ROC train: 0.817834	val: 0.541196	test: 0.588473
PRC train: 0.776353	val: 0.622821	test: 0.627611

Epoch: 51
Loss: 0.4288471614779794
ROC train: 0.827452	val: 0.537297	test: 0.578848
PRC train: 0.784806	val: 0.619490	test: 0.624717

Epoch: 52
Loss: 0.4320371874924846
ROC train: 0.827969	val: 0.541472	test: 0.573303
PRC train: 0.785113	val: 0.620269	test: 0.616539

Epoch: 53
Loss: 0.4235028723807527
ROC train: 0.830357	val: 0.547548	test: 0.573497
PRC train: 0.786647	val: 0.622926	test: 0.614473

Epoch: 54
Loss: 0.4214919973448214
ROC train: 0.834658	val: 0.546190	test: 0.581289
PRC train: 0.789204	val: 0.620773	test: 0.620625

Epoch: 55
Loss: 0.4180257233481612
ROC train: 0.835565	val: 0.537668	test: 0.582573
PRC train: 0.793702	val: 0.616401	test: 0.626748

Epoch: 56
Loss: 0.4204072797659303
ROC train: 0.839627	val: 0.540765	test: 0.584676
PRC train: 0.795918	val: 0.618749	test: 0.627351

Epoch: 57
Loss: 0.41513918090104024
ROC train: 0.840529	val: 0.549038	test: 0.583769
PRC train: 0.796193	val: 0.627552	test: 0.623035

Epoch: 58
Loss: 0.4117357301817496
ROC train: 0.840457	val: 0.548388	test: 0.582041
PRC train: 0.794656	val: 0.626853	test: 0.623553

Epoch: 59
Loss: 0.4128214496522715
ROC train: 0.845219	val: 0.547181	test: 0.583024
PRC train: 0.797815	val: 0.624212	test: 0.627445

Epoch: 60
Loss: 0.41242417489827954
ROC train: 0.847141	val: 0.546489	test: 0.587872
PRC train: 0.800237	val: 0.623640	test: 0.630403

Epoch: 61
Loss: 0.4115978486539715
ROC train: 0.849366	val: 0.544872	test: 0.583417
PRC train: 0.800990	val: 0.622606	test: 0.626480

Epoch: 62
Loss: 0.4046818008393273
ROC train: 0.847017	val: 0.541690	test: 0.581020
PRC train: 0.798211	val: 0.620173	test: 0.624740

Epoch: 63
Loss: 0.41105853187358926
ROC train: 0.849686	val: 0.540916	test: 0.587308
PRC train: 0.802025	val: 0.619088	test: 0.628442

Epoch: 64
Loss: 0.402205455037083
ROC train: 0.850659	val: 0.541299	test: 0.587800
PRC train: 0.804328	val: 0.620687	test: 0.630538

Epoch: 65
Loss: 0.40495257039228055
ROC train: 0.851831	val: 0.548464	test: 0.590920
PRC train: 0.803434	val: 0.625300	test: 0.629894

Epoch: 66
Loss: 0.4030500188374363
ROC train: 0.853337	val: 0.554993	test: 0.592057
PRC train: 0.805201	val: 0.630656	test: 0.627732

Epoch: 67
Loss: 0.40533128162233534
ROC train: 0.854145	val: 0.553760	test: 0.588512
PRC train: 0.807001	val: 0.629643	test: 0.630232

Epoch: 68
Loss: 0.40211417004172617
ROC train: 0.854529	val: 0.548767	test: 0.578315
PRC train: 0.807126	val: 0.623953	test: 0.627389

Epoch: 69
Loss: 0.40094074269723134
ROC train: 0.858763	val: 0.551221	test: 0.579077
PRC train: 0.810532	val: 0.623993	test: 0.624014

Epoch: 70
Loss: 0.4069351063448827
ROC train: 0.861781	val: 0.550669	test: 0.582586
PRC train: 0.814109	val: 0.622400	test: 0.624277

Epoch: 71
Loss: 0.4053974544891425
ROC train: 0.860162	val: 0.549190	test: 0.584804
PRC train: 0.811492	val: 0.618941	test: 0.625975

Epoch: 72
Loss: 0.39613200216942973
ROC train: 0.864283	val: 0.551917	test: 0.588853
PRC train: 0.817893	val: 0.621555	test: 0.628250

Epoch: 73
Loss: 0.3993410376586908
ROC train: 0.863403	val: 0.555606	test: 0.588149
PRC train: 0.819140	val: 0.625399	test: 0.628802

Epoch: 74
Loss: 0.39970250008806263
ROC train: 0.861863	val: 0.555781	test: 0.581333
PRC train: 0.818807	val: 0.625575	test: 0.626967

Epoch: 75
Loss: 0.3900764307024246
ROC train: 0.858418	val: 0.553746	test: 0.578129
PRC train: 0.814511	val: 0.622992	test: 0.623313

Epoch: 76
Loss: 0.3986391334379288
ROC train: 0.862434	val: 0.552885	test: 0.584931
PRC train: 0.818495	val: 0.623037	test: 0.622842

Epoch: 77
Loss: 0.3969615535757823
ROC train: 0.866718	val: 0.553080	test: 0.597920
PRC train: 0.821105	val: 0.625422	test: 0.631050

Epoch: 78
Loss: 0.3945393141111753
ROC train: 0.866905	val: 0.550582	test: 0.600649
PRC train: 0.821602	val: 0.625824	test: 0.634510

Epoch: 79
Loss: 0.3945766324946538
ROC train: 0.869485	val: 0.546766	test: 0.598749
PRC train: 0.823206	val: 0.624133	test: 0.631770

Epoch: 80
Loss: 0.38896473726834646
ROC train: 0.872256	val: 0.540686	test: 0.595686
PRC train: 0.826761	val: 0.618742	test: 0.627631

Epoch: 81
Loss: 0.39055817868763804
ROC train: 0.872498	val: 0.540669	test: 0.588430
PRC train: 0.827258	val: 0.618089	test: 0.623620

Epoch: 82
Loss: 0.38265206833205867
ROC train: 0.874641	val: 0.540750	test: 0.582718
PRC train: 0.828562	val: 0.619485	test: 0.623386

Epoch: 83
Loss: 0.3830761108152543
ROC train: 0.874995	val: 0.538571	test: 0.577789
PRC train: 0.827730	val: 0.620363	test: 0.622078

Epoch: 84
Loss: 0.3844641839856488
ROC train: 0.875539	val: 0.539985	test: 0.579579
PRC train: 0.828007	val: 0.623285	test: 0.622628

Epoch: 85
Loss: 0.39126560885962436
ROC train: 0.876140	val: 0.542059	test: 0.585156
PRC train: 0.829038	val: 0.623408	test: 0.626499

Epoch: 86
Loss: 0.38491841977290975
ROC train: 0.878601	val: 0.546738	test: 0.597482
PRC train: 0.833511	val: 0.623720	test: 0.630495

Epoch: 87
Loss: 0.38271311998928
ROC train: 0.880204	val: 0.547121	test: 0.598309
PRC train: 0.835333	val: 0.625303	test: 0.630683

Epoch: 88
Loss: 0.3800445761567726
ROC train: 0.879066	val: 0.542621	test: 0.594078
PRC train: 0.834634	val: 0.622512	test: 0.629926

Epoch: 89
Loss: 0.3795555197769083
ROC train: 0.882540	val: 0.537758	test: 0.590610
PRC train: 0.838525	val: 0.618725	test: 0.627034

Epoch: 90
Loss: 0.36964430726947095
ROC train: 0.887854	val: 0.540119	test: 0.591610
PRC train: 0.842547	val: 0.618259	test: 0.626158

Epoch: 91
Loss: 0.3747228638249359
ROC train: 0.889339	val: 0.545094	test: 0.593291
PRC train: 0.843598	val: 0.618690	test: 0.628212

Epoch: 92
Loss: 0.37537836012004416
ROC train: 0.890083	val: 0.549373	test: 0.591010
PRC train: 0.848169	val: 0.620081	test: 0.626764

Epoch: 93
Loss: 0.369160604814796
ROC train: 0.887434	val: 0.547511	test: 0.585334
PRC train: 0.845136	val: 0.619365	test: 0.623930

Epoch: 94
Loss: 0.365725489905658
ROC train: 0.889685	val: 0.541841	test: 0.585967
ROC train: 0.805659	val: 0.562151	test: 0.613456
PRC train: 0.771481	val: 0.644115	test: 0.631222

Epoch: 34
Loss: 0.4411406771199985
ROC train: 0.807741	val: 0.553562	test: 0.615312
PRC train: 0.773749	val: 0.645876	test: 0.633401

Epoch: 35
Loss: 0.4412031160952076
ROC train: 0.809464	val: 0.550179	test: 0.611296
PRC train: 0.774924	val: 0.645082	test: 0.633382

Epoch: 36
Loss: 0.44020967042654835
ROC train: 0.808449	val: 0.547379	test: 0.610144
PRC train: 0.773520	val: 0.645347	test: 0.632317

Epoch: 37
Loss: 0.4387385033210339
ROC train: 0.812253	val: 0.561726	test: 0.615279
PRC train: 0.776844	val: 0.648496	test: 0.632482

Epoch: 38
Loss: 0.4369422792259484
ROC train: 0.815718	val: 0.563910	test: 0.615151
PRC train: 0.778982	val: 0.647817	test: 0.632496

Epoch: 39
Loss: 0.4327366874659625
ROC train: 0.820205	val: 0.563292	test: 0.611844
PRC train: 0.782683	val: 0.646615	test: 0.632496

Epoch: 40
Loss: 0.4368364312978011
ROC train: 0.822194	val: 0.560454	test: 0.614613
PRC train: 0.783646	val: 0.646952	test: 0.633628

Epoch: 41
Loss: 0.42901216284537697
ROC train: 0.825156	val: 0.566921	test: 0.612421
PRC train: 0.786273	val: 0.649470	test: 0.634193

Epoch: 42
Loss: 0.43271579766446366
ROC train: 0.825319	val: 0.562494	test: 0.606177
PRC train: 0.786942	val: 0.643195	test: 0.633119

Epoch: 43
Loss: 0.42844226842333594
ROC train: 0.823377	val: 0.564520	test: 0.612384
PRC train: 0.785914	val: 0.646253	test: 0.635580

Epoch: 44
Loss: 0.42638575449142535
ROC train: 0.830097	val: 0.562305	test: 0.610001
PRC train: 0.790921	val: 0.645310	test: 0.631904

Epoch: 45
Loss: 0.42473099130661646
ROC train: 0.831596	val: 0.558118	test: 0.600504
PRC train: 0.791348	val: 0.645758	test: 0.627538

Epoch: 46
Loss: 0.42088505952513433
ROC train: 0.833313	val: 0.567235	test: 0.600582
PRC train: 0.791240	val: 0.650111	test: 0.628406

Epoch: 47
Loss: 0.41845720226470345
ROC train: 0.836249	val: 0.578384	test: 0.610003
PRC train: 0.795324	val: 0.652836	test: 0.630669

Epoch: 48
Loss: 0.41758117240867565
ROC train: 0.838469	val: 0.570795	test: 0.616046
PRC train: 0.797744	val: 0.649186	test: 0.635174

Epoch: 49
Loss: 0.4185851280797868
ROC train: 0.838632	val: 0.568639	test: 0.614275
PRC train: 0.798881	val: 0.649054	test: 0.634418

Epoch: 50
Loss: 0.42056426057817875
ROC train: 0.835930	val: 0.574198	test: 0.622121
PRC train: 0.796450	val: 0.649412	test: 0.637025

Epoch: 51
Loss: 0.4191839620898598
ROC train: 0.840407	val: 0.569705	test: 0.619595
PRC train: 0.798425	val: 0.645156	test: 0.636796

Epoch: 52
Loss: 0.4136471236549022
ROC train: 0.845455	val: 0.562067	test: 0.610619
PRC train: 0.805477	val: 0.644654	test: 0.634295

Epoch: 53
Loss: 0.4180719196341191
ROC train: 0.848174	val: 0.566225	test: 0.610163
PRC train: 0.808505	val: 0.647543	test: 0.633778

Epoch: 54
Loss: 0.41066930422556586
ROC train: 0.847163	val: 0.560619	test: 0.609653
PRC train: 0.807982	val: 0.647721	test: 0.634149

Epoch: 55
Loss: 0.4095764477953185
ROC train: 0.852076	val: 0.566999	test: 0.607010
PRC train: 0.808886	val: 0.648411	test: 0.632470

Epoch: 56
Loss: 0.40488700202097244
ROC train: 0.855386	val: 0.568784	test: 0.610139
PRC train: 0.811259	val: 0.648511	test: 0.632790

Epoch: 57
Loss: 0.4077478270878367
ROC train: 0.854332	val: 0.567898	test: 0.617153
PRC train: 0.809848	val: 0.648888	test: 0.638065

Epoch: 58
Loss: 0.406600016129402
ROC train: 0.854198	val: 0.568880	test: 0.618902
PRC train: 0.808791	val: 0.651351	test: 0.640114

Epoch: 59
Loss: 0.39989744768519586
ROC train: 0.854172	val: 0.569529	test: 0.620789
PRC train: 0.809429	val: 0.648692	test: 0.639463

Epoch: 60
Loss: 0.4026476491700791
ROC train: 0.859828	val: 0.560248	test: 0.622461
PRC train: 0.815890	val: 0.645243	test: 0.639788

Epoch: 61
Loss: 0.4008090300792964
ROC train: 0.863081	val: 0.563318	test: 0.618281
PRC train: 0.820718	val: 0.647047	test: 0.635008

Epoch: 62
Loss: 0.3994049665360164
ROC train: 0.866598	val: 0.570623	test: 0.624660
PRC train: 0.824316	val: 0.649990	test: 0.640510

Epoch: 63
Loss: 0.3964844777296123
ROC train: 0.865815	val: 0.569867	test: 0.624472
PRC train: 0.825159	val: 0.651443	test: 0.639337

Epoch: 64
Loss: 0.3962211548678197
ROC train: 0.866541	val: 0.569107	test: 0.618262
PRC train: 0.825369	val: 0.649443	test: 0.633846

Epoch: 65
Loss: 0.3955015333304839
ROC train: 0.866368	val: 0.565657	test: 0.616879
PRC train: 0.824260	val: 0.643552	test: 0.636079

Epoch: 66
Loss: 0.39603181370922746
ROC train: 0.868039	val: 0.566667	test: 0.620045
PRC train: 0.826866	val: 0.642695	test: 0.641365

Epoch: 67
Loss: 0.38796899652783784
ROC train: 0.867388	val: 0.570792	test: 0.618766
PRC train: 0.825161	val: 0.645468	test: 0.639782

Epoch: 68
Loss: 0.3909637131413016
ROC train: 0.867273	val: 0.570169	test: 0.617954
PRC train: 0.824262	val: 0.647028	test: 0.641330

Epoch: 69
Loss: 0.3878583069233792
ROC train: 0.870691	val: 0.566610	test: 0.621664
PRC train: 0.828475	val: 0.647658	test: 0.645020

Epoch: 70
Loss: 0.3828369356349557
ROC train: 0.874188	val: 0.572386	test: 0.620803
PRC train: 0.832127	val: 0.647539	test: 0.643960

Epoch: 71
Loss: 0.3859718741393772
ROC train: 0.875800	val: 0.580059	test: 0.618597
PRC train: 0.833901	val: 0.652153	test: 0.641033

Epoch: 72
Loss: 0.38386889170480387
ROC train: 0.879330	val: 0.574356	test: 0.616136
PRC train: 0.838046	val: 0.650475	test: 0.642140

Epoch: 73
Loss: 0.38404568427033037
ROC train: 0.880097	val: 0.572074	test: 0.612629
PRC train: 0.838094	val: 0.651650	test: 0.640198

Epoch: 74
Loss: 0.38144858156059713
ROC train: 0.880154	val: 0.573067	test: 0.610907
PRC train: 0.836968	val: 0.650749	test: 0.633708

Epoch: 75
Loss: 0.3834362676799379
ROC train: 0.882539	val: 0.581134	test: 0.615598
PRC train: 0.838722	val: 0.652978	test: 0.634840

Epoch: 76
Loss: 0.3796277902361318
ROC train: 0.880171	val: 0.578968	test: 0.613145
PRC train: 0.836329	val: 0.650553	test: 0.638496

Epoch: 77
Loss: 0.38108475692027055
ROC train: 0.884608	val: 0.580453	test: 0.615566
PRC train: 0.842011	val: 0.651245	test: 0.638373

Epoch: 78
Loss: 0.37950592693324653
ROC train: 0.886693	val: 0.574777	test: 0.610283
PRC train: 0.844115	val: 0.649439	test: 0.632645

Epoch: 79
Loss: 0.3800036882833096
ROC train: 0.887032	val: 0.570240	test: 0.611085
PRC train: 0.844564	val: 0.648361	test: 0.633001

Epoch: 80
Loss: 0.37874131311773
ROC train: 0.886986	val: 0.576158	test: 0.620072
PRC train: 0.844966	val: 0.650755	test: 0.635936

Epoch: 81
Loss: 0.3755941254742515
ROC train: 0.885439	val: 0.577709	test: 0.618296
PRC train: 0.843490	val: 0.651119	test: 0.634884

Epoch: 82
Loss: 0.37310850250265365
ROC train: 0.890275	val: 0.582216	test: 0.609246
PRC train: 0.845861	val: 0.654327	test: 0.633500

Epoch: 83
Loss: 0.3740652095353399
ROC train: 0.891223	val: 0.587639	test: 0.600333
PRC train: 0.848794	val: 0.656130	test: 0.626434

Epoch: 84
Loss: 0.37074598313011986
ROC train: 0.894693	val: 0.576990	test: 0.606000
PRC train: 0.855343	val: 0.650672	test: 0.630536

Epoch: 85
Loss: 0.3722287332503612
ROC train: 0.894491	val: 0.568735	test: 0.614595
PRC train: 0.853180	val: 0.645414	test: 0.640923

Epoch: 86
Loss: 0.36531891103138825
ROC train: 0.896190	val: 0.574841	test: 0.619938
PRC train: 0.854417	val: 0.648815	test: 0.640063

Epoch: 87
Loss: 0.36867592679577155
ROC train: 0.898569	val: 0.578130	test: 0.616164
PRC train: 0.857901	val: 0.651885	test: 0.638776

Epoch: 88
Loss: 0.36594364356920944
ROC train: 0.898596	val: 0.581815	test: 0.613538
PRC train: 0.858226	val: 0.652881	test: 0.635200

Epoch: 89
Loss: 0.3647282276833866
ROC train: 0.897785	val: 0.573573	test: 0.610490
PRC train: 0.856103	val: 0.647803	test: 0.633553

Epoch: 90
Loss: 0.364248543264444
ROC train: 0.900798	val: 0.573040	test: 0.615868
PRC train: 0.859885	val: 0.648093	test: 0.637207

Epoch: 91
Loss: 0.3639715327657284
ROC train: 0.902100	val: 0.580305	test: 0.620192
PRC train: 0.861248	val: 0.652417	test: 0.643429

Epoch: 92
Loss: 0.36042906151657006
ROC train: 0.902504	val: 0.584828	test: 0.622070
PRC train: 0.860975	val: 0.653951	test: 0.643086

Epoch: 93
Loss: 0.3605926062477445
ROC train: 0.903649	val: 0.583943	test: 0.617893
PRC train: 0.861223	val: 0.653662	test: 0.639592

Epoch: 94
Loss: 0.3598260923673722
ROC train: 0.797188	val: 0.571577	test: 0.609048
PRC train: 0.763235	val: 0.640638	test: 0.628063

Epoch: 34
Loss: 0.4445726340157325
ROC train: 0.801655	val: 0.558204	test: 0.605284
PRC train: 0.764986	val: 0.639719	test: 0.631056

Epoch: 35
Loss: 0.442711647902734
ROC train: 0.801593	val: 0.567339	test: 0.610330
PRC train: 0.765032	val: 0.647096	test: 0.631304

Epoch: 36
Loss: 0.4414254509128398
ROC train: 0.803487	val: 0.566521	test: 0.613180
PRC train: 0.767524	val: 0.643677	test: 0.632552

Epoch: 37
Loss: 0.44201117108214955
ROC train: 0.806978	val: 0.560892	test: 0.606122
PRC train: 0.770661	val: 0.639869	test: 0.628054

Epoch: 38
Loss: 0.4364707503005023
ROC train: 0.814920	val: 0.558585	test: 0.605241
PRC train: 0.777034	val: 0.638526	test: 0.627967

Epoch: 39
Loss: 0.4339487575170724
ROC train: 0.817713	val: 0.570254	test: 0.607662
PRC train: 0.778836	val: 0.644243	test: 0.631307

Epoch: 40
Loss: 0.4373990307636829
ROC train: 0.813663	val: 0.568665	test: 0.607729
PRC train: 0.776128	val: 0.644945	test: 0.630344

Epoch: 41
Loss: 0.4347614725866758
ROC train: 0.813404	val: 0.568178	test: 0.607002
PRC train: 0.776120	val: 0.646973	test: 0.628534

Epoch: 42
Loss: 0.43539766700262805
ROC train: 0.814184	val: 0.567357	test: 0.611186
PRC train: 0.776717	val: 0.648016	test: 0.628820

Epoch: 43
Loss: 0.43127927111534636
ROC train: 0.822871	val: 0.570014	test: 0.611687
PRC train: 0.782633	val: 0.647928	test: 0.629804

Epoch: 44
Loss: 0.42901498835633056
ROC train: 0.827973	val: 0.569656	test: 0.612033
PRC train: 0.786909	val: 0.646330	test: 0.629820

Epoch: 45
Loss: 0.42917783149054434
ROC train: 0.829243	val: 0.570175	test: 0.611058
PRC train: 0.789276	val: 0.649134	test: 0.630672

Epoch: 46
Loss: 0.42718730607079414
ROC train: 0.829427	val: 0.560016	test: 0.605015
PRC train: 0.790574	val: 0.646012	test: 0.630774

Epoch: 47
Loss: 0.4243319877012678
ROC train: 0.829421	val: 0.562740	test: 0.602822
PRC train: 0.790388	val: 0.642291	test: 0.625850

Epoch: 48
Loss: 0.42160225756124575
ROC train: 0.829282	val: 0.569574	test: 0.599966
PRC train: 0.790502	val: 0.641769	test: 0.622086

Epoch: 49
Loss: 0.41805626559239967
ROC train: 0.831091	val: 0.573817	test: 0.594244
PRC train: 0.791635	val: 0.643254	test: 0.620715

Epoch: 50
Loss: 0.4207435831053797
ROC train: 0.830509	val: 0.574239	test: 0.597342
PRC train: 0.791784	val: 0.646219	test: 0.625028

Epoch: 51
Loss: 0.4204073322251909
ROC train: 0.837535	val: 0.568585	test: 0.604908
PRC train: 0.798293	val: 0.649523	test: 0.629226

Epoch: 52
Loss: 0.415244246880513
ROC train: 0.842699	val: 0.562731	test: 0.608015
PRC train: 0.801324	val: 0.647423	test: 0.633266

Epoch: 53
Loss: 0.41351083796168575
ROC train: 0.844760	val: 0.558271	test: 0.606957
PRC train: 0.803918	val: 0.646167	test: 0.632496

Epoch: 54
Loss: 0.40926293596175245
ROC train: 0.846462	val: 0.555170	test: 0.613714
PRC train: 0.805552	val: 0.642524	test: 0.635352

Epoch: 55
Loss: 0.4100597640413158
ROC train: 0.849558	val: 0.564288	test: 0.611448
PRC train: 0.806670	val: 0.643708	test: 0.634144

Epoch: 56
Loss: 0.41093505054652313
ROC train: 0.849300	val: 0.570223	test: 0.606339
PRC train: 0.806058	val: 0.642883	test: 0.632117

Epoch: 57
Loss: 0.4076378356150218
ROC train: 0.851428	val: 0.575471	test: 0.614297
PRC train: 0.808902	val: 0.645218	test: 0.638095

Epoch: 58
Loss: 0.4090596891197625
ROC train: 0.853542	val: 0.580125	test: 0.615970
PRC train: 0.811784	val: 0.650385	test: 0.637749

Epoch: 59
Loss: 0.40482129023411584
ROC train: 0.854567	val: 0.578557	test: 0.609313
PRC train: 0.812276	val: 0.651435	test: 0.633396

Epoch: 60
Loss: 0.40424199097657704
ROC train: 0.854044	val: 0.579442	test: 0.614532
PRC train: 0.811636	val: 0.650657	test: 0.635350

Epoch: 61
Loss: 0.4045128159675156
ROC train: 0.858341	val: 0.579591	test: 0.612731
PRC train: 0.816308	val: 0.651836	test: 0.633949

Epoch: 62
Loss: 0.4032173443420971
ROC train: 0.861176	val: 0.572611	test: 0.606777
PRC train: 0.816292	val: 0.652327	test: 0.633959

Epoch: 63
Loss: 0.39855897793729017
ROC train: 0.864557	val: 0.578932	test: 0.610914
PRC train: 0.817105	val: 0.652452	test: 0.634007

Epoch: 64
Loss: 0.4067830985647592
ROC train: 0.864873	val: 0.580758	test: 0.615169
PRC train: 0.819448	val: 0.646747	test: 0.631831

Epoch: 65
Loss: 0.4020718367928026
ROC train: 0.864798	val: 0.565116	test: 0.599917
PRC train: 0.819118	val: 0.641122	test: 0.623144

Epoch: 66
Loss: 0.39680464540903393
ROC train: 0.865723	val: 0.568463	test: 0.598237
PRC train: 0.821616	val: 0.643426	test: 0.623423

Epoch: 67
Loss: 0.39878120356803437
ROC train: 0.869370	val: 0.575569	test: 0.609976
PRC train: 0.826290	val: 0.645776	test: 0.629071

Epoch: 68
Loss: 0.3939067778180249
ROC train: 0.871150	val: 0.574396	test: 0.613057
PRC train: 0.826872	val: 0.645654	test: 0.628407

Epoch: 69
Loss: 0.3903418983011899
ROC train: 0.872143	val: 0.567271	test: 0.608158
PRC train: 0.830982	val: 0.644642	test: 0.627141

Epoch: 70
Loss: 0.39074259938988853
ROC train: 0.871636	val: 0.556897	test: 0.593731
PRC train: 0.830125	val: 0.640383	test: 0.623471

Epoch: 71
Loss: 0.3901141315959256
ROC train: 0.871860	val: 0.566913	test: 0.600403
PRC train: 0.829161	val: 0.642675	test: 0.625324

Epoch: 72
Loss: 0.38676641685848545
ROC train: 0.874560	val: 0.579806	test: 0.613449
PRC train: 0.830328	val: 0.646351	test: 0.628381

Epoch: 73
Loss: 0.38876820361523295
ROC train: 0.874347	val: 0.583341	test: 0.611013
PRC train: 0.830276	val: 0.646648	test: 0.626025

Epoch: 74
Loss: 0.3907191445007491
ROC train: 0.875909	val: 0.581469	test: 0.606276
PRC train: 0.831608	val: 0.648108	test: 0.623258

Epoch: 75
Loss: 0.3821819532227707
ROC train: 0.876265	val: 0.576382	test: 0.604134
PRC train: 0.831813	val: 0.649059	test: 0.621046

Epoch: 76
Loss: 0.3843602529144223
ROC train: 0.881014	val: 0.574930	test: 0.602231
PRC train: 0.837788	val: 0.647826	test: 0.623120

Epoch: 77
Loss: 0.3830726372585606
ROC train: 0.878878	val: 0.572257	test: 0.606885
PRC train: 0.833051	val: 0.645904	test: 0.626157

Epoch: 78
Loss: 0.38527824169457425
ROC train: 0.881057	val: 0.563715	test: 0.603531
PRC train: 0.836580	val: 0.637920	test: 0.625296

Epoch: 79
Loss: 0.3811798276741991
ROC train: 0.882983	val: 0.564547	test: 0.599735
PRC train: 0.839580	val: 0.637929	test: 0.623887

Epoch: 80
Loss: 0.3803566537052567
ROC train: 0.883959	val: 0.575572	test: 0.600571
PRC train: 0.842006	val: 0.640929	test: 0.624841

Epoch: 81
Loss: 0.3798110520926989
ROC train: 0.884199	val: 0.580190	test: 0.597470
PRC train: 0.842712	val: 0.643740	test: 0.623678

Epoch: 82
Loss: 0.3735795986165526
ROC train: 0.889098	val: 0.584229	test: 0.617276
PRC train: 0.847479	val: 0.647644	test: 0.635978

Epoch: 83
Loss: 0.36972750898908163
ROC train: 0.891946	val: 0.577998	test: 0.619478
PRC train: 0.849609	val: 0.647635	test: 0.636928

Epoch: 84
Loss: 0.37105129289741945
ROC train: 0.890134	val: 0.576485	test: 0.607590
PRC train: 0.850446	val: 0.645839	test: 0.631999

Epoch: 85
Loss: 0.36994668086139126
ROC train: 0.893272	val: 0.575232	test: 0.607130
PRC train: 0.851334	val: 0.647745	test: 0.629887

Epoch: 86
Loss: 0.3732536563103851
ROC train: 0.886448	val: 0.566293	test: 0.593901
PRC train: 0.844511	val: 0.641154	test: 0.621148

Epoch: 87
Loss: 0.3713310138990996
ROC train: 0.894102	val: 0.566327	test: 0.592963
PRC train: 0.854575	val: 0.641329	test: 0.620003

Epoch: 88
Loss: 0.3635739932340315
ROC train: 0.894660	val: 0.570727	test: 0.589103
PRC train: 0.855479	val: 0.638815	test: 0.617598

Epoch: 89
Loss: 0.3681743746085954
ROC train: 0.898405	val: 0.577384	test: 0.589132
PRC train: 0.854015	val: 0.641150	test: 0.620209

Epoch: 90
Loss: 0.363633624138141
ROC train: 0.900520	val: 0.581461	test: 0.596100
PRC train: 0.856119	val: 0.645124	test: 0.622417

Epoch: 91
Loss: 0.3613722471398471
ROC train: 0.901924	val: 0.583381	test: 0.602628
PRC train: 0.859949	val: 0.647225	test: 0.625326

Epoch: 92
Loss: 0.3622837503802539
ROC train: 0.900851	val: 0.576043	test: 0.603637
PRC train: 0.859083	val: 0.644232	test: 0.627722

Epoch: 93
Loss: 0.3644476739954038
ROC train: 0.902550	val: 0.577431	test: 0.598876
PRC train: 0.862081	val: 0.644827	test: 0.623538

Epoch: 94
Loss: 0.3617616607248738
ROC train: 0.796638	val: 0.574606	test: 0.613065
PRC train: 0.763470	val: 0.648480	test: 0.634200

Epoch: 34
Loss: 0.4441525331593553
ROC train: 0.800245	val: 0.567107	test: 0.608574
PRC train: 0.766076	val: 0.643425	test: 0.631791

Epoch: 35
Loss: 0.4447042257585814
ROC train: 0.804676	val: 0.567213	test: 0.608103
PRC train: 0.770863	val: 0.645732	test: 0.635343

Epoch: 36
Loss: 0.44509498066290154
ROC train: 0.803428	val: 0.569474	test: 0.613434
PRC train: 0.769755	val: 0.651073	test: 0.638348

Epoch: 37
Loss: 0.4408539160422985
ROC train: 0.801250	val: 0.551440	test: 0.612213
PRC train: 0.767043	val: 0.641990	test: 0.638727

Epoch: 38
Loss: 0.44507943952211926
ROC train: 0.809704	val: 0.563615	test: 0.605805
PRC train: 0.774166	val: 0.648580	test: 0.634057

Epoch: 39
Loss: 0.4380163380609363
ROC train: 0.813057	val: 0.568129	test: 0.603537
PRC train: 0.777506	val: 0.647312	test: 0.632564

Epoch: 40
Loss: 0.43942078755979275
ROC train: 0.813986	val: 0.562764	test: 0.597439
PRC train: 0.777576	val: 0.645267	test: 0.627929

Epoch: 41
Loss: 0.43164731349254787
ROC train: 0.815956	val: 0.562249	test: 0.610706
PRC train: 0.779636	val: 0.645145	test: 0.635220

Epoch: 42
Loss: 0.43142484533445624
ROC train: 0.817833	val: 0.559396	test: 0.615546
PRC train: 0.781664	val: 0.646806	test: 0.637651

Epoch: 43
Loss: 0.4319448809993026
ROC train: 0.821287	val: 0.556824	test: 0.613069
PRC train: 0.783174	val: 0.647057	test: 0.637965

Epoch: 44
Loss: 0.431413346614114
ROC train: 0.824588	val: 0.572058	test: 0.614471
PRC train: 0.785572	val: 0.650509	test: 0.639561

Epoch: 45
Loss: 0.42634043463736654
ROC train: 0.825899	val: 0.574890	test: 0.616725
PRC train: 0.789169	val: 0.649452	test: 0.642835

Epoch: 46
Loss: 0.4265713807147344
ROC train: 0.829391	val: 0.570079	test: 0.619616
PRC train: 0.792382	val: 0.648939	test: 0.645449

Epoch: 47
Loss: 0.4262893212291305
ROC train: 0.829626	val: 0.555384	test: 0.613422
PRC train: 0.792682	val: 0.644055	test: 0.642003

Epoch: 48
Loss: 0.42446812598070266
ROC train: 0.827016	val: 0.547141	test: 0.608067
PRC train: 0.789190	val: 0.642770	test: 0.633776

Epoch: 49
Loss: 0.422164969166559
ROC train: 0.828373	val: 0.548993	test: 0.609568
PRC train: 0.789277	val: 0.642859	test: 0.632091

Epoch: 50
Loss: 0.4212983306439797
ROC train: 0.834119	val: 0.549520	test: 0.609840
PRC train: 0.794549	val: 0.644687	test: 0.638230

Epoch: 51
Loss: 0.41993929948370035
ROC train: 0.838259	val: 0.558497	test: 0.612513
PRC train: 0.798726	val: 0.647190	test: 0.640509

Epoch: 52
Loss: 0.42066084047513386
ROC train: 0.838338	val: 0.561775	test: 0.609369
PRC train: 0.800003	val: 0.648820	test: 0.639453

Epoch: 53
Loss: 0.415966184706475
ROC train: 0.840478	val: 0.560112	test: 0.611147
PRC train: 0.800410	val: 0.645319	test: 0.634791

Epoch: 54
Loss: 0.41810183144918467
ROC train: 0.843505	val: 0.560356	test: 0.607004
PRC train: 0.802011	val: 0.647129	test: 0.630074

Epoch: 55
Loss: 0.41350729323059926
ROC train: 0.844218	val: 0.561957	test: 0.609420
PRC train: 0.804412	val: 0.648492	test: 0.634834

Epoch: 56
Loss: 0.4123602938032463
ROC train: 0.844164	val: 0.568778	test: 0.617227
PRC train: 0.804316	val: 0.651911	test: 0.638775

Epoch: 57
Loss: 0.4140646844358169
ROC train: 0.845909	val: 0.566463	test: 0.621160
PRC train: 0.806019	val: 0.649403	test: 0.642189

Epoch: 58
Loss: 0.4105424469645615
ROC train: 0.847845	val: 0.561261	test: 0.619280
PRC train: 0.806711	val: 0.645840	test: 0.647739

Epoch: 59
Loss: 0.4045997497763627
ROC train: 0.851461	val: 0.567393	test: 0.620637
PRC train: 0.811920	val: 0.653918	test: 0.648034

Epoch: 60
Loss: 0.4093437866570112
ROC train: 0.852741	val: 0.567838	test: 0.617789
PRC train: 0.812607	val: 0.656147	test: 0.640347

Epoch: 61
Loss: 0.4052951631257028
ROC train: 0.856465	val: 0.566465	test: 0.612467
PRC train: 0.816546	val: 0.653097	test: 0.638309

Epoch: 62
Loss: 0.4110627071369435
ROC train: 0.855311	val: 0.559578	test: 0.597855
PRC train: 0.814711	val: 0.648657	test: 0.629496

Epoch: 63
Loss: 0.4034883966533509
ROC train: 0.860014	val: 0.558761	test: 0.603194
PRC train: 0.817204	val: 0.646772	test: 0.632403

Epoch: 64
Loss: 0.40337970592907024
ROC train: 0.861848	val: 0.564117	test: 0.608975
PRC train: 0.818628	val: 0.650245	test: 0.633338

Epoch: 65
Loss: 0.40313527481302747
ROC train: 0.860322	val: 0.566190	test: 0.607152
PRC train: 0.820742	val: 0.650155	test: 0.632947

Epoch: 66
Loss: 0.41048563388995923
ROC train: 0.861945	val: 0.564759	test: 0.610591
PRC train: 0.822558	val: 0.648777	test: 0.635271

Epoch: 67
Loss: 0.3963397221914714
ROC train: 0.864525	val: 0.565290	test: 0.609333
PRC train: 0.823955	val: 0.651918	test: 0.638406

Epoch: 68
Loss: 0.39742322604567476
ROC train: 0.862450	val: 0.567632	test: 0.605715
PRC train: 0.821261	val: 0.650911	test: 0.635771

Epoch: 69
Loss: 0.39840268987524236
ROC train: 0.859200	val: 0.567711	test: 0.603127
PRC train: 0.818122	val: 0.645782	test: 0.628292

Epoch: 70
Loss: 0.3944393832696707
ROC train: 0.869255	val: 0.567032	test: 0.605913
PRC train: 0.829248	val: 0.646107	test: 0.633010

Epoch: 71
Loss: 0.39354906236915227
ROC train: 0.870675	val: 0.570942	test: 0.609248
PRC train: 0.830653	val: 0.650723	test: 0.636108

Epoch: 72
Loss: 0.3946812266359247
ROC train: 0.873190	val: 0.572398	test: 0.616752
PRC train: 0.832645	val: 0.652880	test: 0.638791

Epoch: 73
Loss: 0.3904397220689044
ROC train: 0.873063	val: 0.566073	test: 0.621199
PRC train: 0.833385	val: 0.648786	test: 0.642842

Epoch: 74
Loss: 0.38671608008946695
ROC train: 0.873646	val: 0.565358	test: 0.619512
PRC train: 0.831986	val: 0.645892	test: 0.641578

Epoch: 75
Loss: 0.3847389733358604
ROC train: 0.876178	val: 0.576331	test: 0.616052
PRC train: 0.834514	val: 0.649462	test: 0.639971

Epoch: 76
Loss: 0.39168964857685074
ROC train: 0.878697	val: 0.579790	test: 0.609794
PRC train: 0.837310	val: 0.648181	test: 0.633194

Epoch: 77
Loss: 0.3829566469472946
ROC train: 0.879210	val: 0.576455	test: 0.610789
PRC train: 0.837886	val: 0.648845	test: 0.632795

Epoch: 78
Loss: 0.3838181324364784
ROC train: 0.881747	val: 0.572657	test: 0.620899
PRC train: 0.842251	val: 0.650406	test: 0.635813

Epoch: 79
Loss: 0.3828506630730176
ROC train: 0.882148	val: 0.568936	test: 0.615988
PRC train: 0.842736	val: 0.647278	test: 0.636625

Epoch: 80
Loss: 0.38080085365847677
ROC train: 0.880888	val: 0.570058	test: 0.618581
PRC train: 0.841348	val: 0.650729	test: 0.639360

Epoch: 81
Loss: 0.37742899453997697
ROC train: 0.881755	val: 0.573808	test: 0.618995
PRC train: 0.841953	val: 0.651499	test: 0.639892

Epoch: 82
Loss: 0.3802648024454732
ROC train: 0.885728	val: 0.576116	test: 0.623075
PRC train: 0.843714	val: 0.649771	test: 0.641203

Epoch: 83
Loss: 0.374618819476115
ROC train: 0.885812	val: 0.579006	test: 0.619642
PRC train: 0.844694	val: 0.652428	test: 0.634807

Epoch: 84
Loss: 0.37582296476818067
ROC train: 0.889085	val: 0.577777	test: 0.614845
PRC train: 0.848769	val: 0.650363	test: 0.632173

Epoch: 85
Loss: 0.37543703047251975
ROC train: 0.890644	val: 0.575503	test: 0.620262
PRC train: 0.850233	val: 0.649140	test: 0.638003

Epoch: 86
Loss: 0.3746767728436537
ROC train: 0.890496	val: 0.577855	test: 0.629087
PRC train: 0.849572	val: 0.651532	test: 0.643793

Epoch: 87
Loss: 0.37633418007956
ROC train: 0.889974	val: 0.579349	test: 0.627086
PRC train: 0.849073	val: 0.652387	test: 0.643894

Epoch: 88
Loss: 0.36822244776797447
ROC train: 0.889968	val: 0.574118	test: 0.629884
PRC train: 0.850446	val: 0.646553	test: 0.645098

Epoch: 89
Loss: 0.36717347335273764
ROC train: 0.891867	val: 0.570174	test: 0.624916
PRC train: 0.853852	val: 0.644881	test: 0.640156

Epoch: 90
Loss: 0.3669811165185411
ROC train: 0.895077	val: 0.577959	test: 0.612117
PRC train: 0.856750	val: 0.651694	test: 0.634789

Epoch: 91
Loss: 0.3674879189867025
ROC train: 0.895324	val: 0.585721	test: 0.614897
PRC train: 0.856573	val: 0.657050	test: 0.637741

Epoch: 92
Loss: 0.36569457113275805
ROC train: 0.895825	val: 0.590138	test: 0.618013
PRC train: 0.856665	val: 0.659005	test: 0.638811

Epoch: 93
Loss: 0.3638272159116997
ROC train: 0.899361	val: 0.580015	test: 0.617517
PRC train: 0.861519	val: 0.656023	test: 0.638548

Epoch: 94
Loss: 0.36100065252029406
ROC train: 0.795817	val: 0.619646	test: 0.605660
PRC train: 0.763241	val: 0.665592	test: 0.629139

Epoch: 34
Loss: 0.4395660575725843
ROC train: 0.797280	val: 0.629900	test: 0.602963
PRC train: 0.763907	val: 0.671801	test: 0.626672

Epoch: 35
Loss: 0.4357583359850283
ROC train: 0.803776	val: 0.631798	test: 0.601759
PRC train: 0.769236	val: 0.671062	test: 0.621789

Epoch: 36
Loss: 0.4357022447385086
ROC train: 0.805643	val: 0.627458	test: 0.602954
PRC train: 0.772580	val: 0.666290	test: 0.622138

Epoch: 37
Loss: 0.43936755522234494
ROC train: 0.804736	val: 0.630785	test: 0.610190
PRC train: 0.772093	val: 0.665527	test: 0.631881

Epoch: 38
Loss: 0.43586557079519983
ROC train: 0.811530	val: 0.624956	test: 0.603492
PRC train: 0.776910	val: 0.665582	test: 0.629138

Epoch: 39
Loss: 0.43066340076993515
ROC train: 0.815846	val: 0.622834	test: 0.602581
PRC train: 0.780839	val: 0.667776	test: 0.628714

Epoch: 40
Loss: 0.4337769459154523
ROC train: 0.815201	val: 0.630993	test: 0.603547
PRC train: 0.779824	val: 0.667476	test: 0.631855

Epoch: 41
Loss: 0.4323208067717247
ROC train: 0.819058	val: 0.635473	test: 0.593168
PRC train: 0.781835	val: 0.672126	test: 0.622896

Epoch: 42
Loss: 0.4300143250325794
ROC train: 0.823302	val: 0.637416	test: 0.582130
PRC train: 0.788928	val: 0.677994	test: 0.614431

Epoch: 43
Loss: 0.4322095845394135
ROC train: 0.821693	val: 0.634430	test: 0.591500
PRC train: 0.787610	val: 0.672101	test: 0.622868

Epoch: 44
Loss: 0.4284239026114444
ROC train: 0.821043	val: 0.631824	test: 0.602556
PRC train: 0.786960	val: 0.672802	test: 0.631265

Epoch: 45
Loss: 0.42484959500779357
ROC train: 0.826632	val: 0.633002	test: 0.602676
PRC train: 0.789063	val: 0.672032	test: 0.629632

Epoch: 46
Loss: 0.42766927751574135
ROC train: 0.831797	val: 0.633657	test: 0.599171
PRC train: 0.795022	val: 0.672122	test: 0.626968

Epoch: 47
Loss: 0.42915369455572144
ROC train: 0.825049	val: 0.613700	test: 0.593152
PRC train: 0.787372	val: 0.665499	test: 0.626603

Epoch: 48
Loss: 0.4182024961879809
ROC train: 0.828417	val: 0.610134	test: 0.600364
PRC train: 0.790941	val: 0.658262	test: 0.627742

Epoch: 49
Loss: 0.41727966991593296
ROC train: 0.834324	val: 0.623952	test: 0.596380
PRC train: 0.797327	val: 0.667098	test: 0.621941

Epoch: 50
Loss: 0.41963287071576383
ROC train: 0.837412	val: 0.629204	test: 0.594140
PRC train: 0.801503	val: 0.670492	test: 0.621538

Epoch: 51
Loss: 0.412332248195088
ROC train: 0.838435	val: 0.624915	test: 0.597733
PRC train: 0.801927	val: 0.664398	test: 0.626812

Epoch: 52
Loss: 0.4132301046219357
ROC train: 0.837915	val: 0.614542	test: 0.592498
PRC train: 0.800333	val: 0.659603	test: 0.622130

Epoch: 53
Loss: 0.41763644524139726
ROC train: 0.839714	val: 0.604139	test: 0.597530
PRC train: 0.801358	val: 0.659076	test: 0.624864

Epoch: 54
Loss: 0.42009726005770825
ROC train: 0.843317	val: 0.617430	test: 0.602517
PRC train: 0.806327	val: 0.668079	test: 0.630474

Epoch: 55
Loss: 0.4125637948156059
ROC train: 0.844937	val: 0.635293	test: 0.606237
PRC train: 0.808577	val: 0.675854	test: 0.631481

Epoch: 56
Loss: 0.40827545427351036
ROC train: 0.848055	val: 0.631958	test: 0.604614
PRC train: 0.811403	val: 0.671380	test: 0.630550

Epoch: 57
Loss: 0.40969121109241174
ROC train: 0.844050	val: 0.626898	test: 0.580763
PRC train: 0.806702	val: 0.673773	test: 0.617438

Epoch: 58
Loss: 0.40345670511102416
ROC train: 0.851072	val: 0.613119	test: 0.595193
PRC train: 0.812455	val: 0.667224	test: 0.622297

Epoch: 59
Loss: 0.40448367811428676
ROC train: 0.854239	val: 0.617571	test: 0.605966
PRC train: 0.816055	val: 0.666187	test: 0.625963

Epoch: 60
Loss: 0.40250970340854497
ROC train: 0.857633	val: 0.621808	test: 0.596214
PRC train: 0.819977	val: 0.669874	test: 0.622047

Epoch: 61
Loss: 0.4001250660577781
ROC train: 0.859004	val: 0.626032	test: 0.589668
PRC train: 0.820776	val: 0.669150	test: 0.620617

Epoch: 62
Loss: 0.4006726759488644
ROC train: 0.856769	val: 0.630038	test: 0.610211
PRC train: 0.817326	val: 0.669883	test: 0.629193

Epoch: 63
Loss: 0.402983666403521
ROC train: 0.853955	val: 0.629977	test: 0.616563
PRC train: 0.816370	val: 0.671170	test: 0.630806

Epoch: 64
Loss: 0.40023150760987064
ROC train: 0.859544	val: 0.624292	test: 0.596215
PRC train: 0.821523	val: 0.673607	test: 0.621837

Epoch: 65
Loss: 0.40365537986343886
ROC train: 0.862479	val: 0.628770	test: 0.592318
PRC train: 0.826205	val: 0.673321	test: 0.621731

Epoch: 66
Loss: 0.4017602576985773
ROC train: 0.863848	val: 0.620557	test: 0.602451
PRC train: 0.826565	val: 0.667218	test: 0.626599

Epoch: 67
Loss: 0.39554725653547684
ROC train: 0.864493	val: 0.622890	test: 0.600053
PRC train: 0.825249	val: 0.664814	test: 0.627862

Epoch: 68
Loss: 0.39353795098367195
ROC train: 0.864655	val: 0.627805	test: 0.596873
PRC train: 0.825968	val: 0.669377	test: 0.625042

Epoch: 69
Loss: 0.4033880417170007
ROC train: 0.865289	val: 0.615200	test: 0.604246
PRC train: 0.828514	val: 0.667062	test: 0.628576

Epoch: 70
Loss: 0.3900707691328897
ROC train: 0.870787	val: 0.618848	test: 0.592587
PRC train: 0.834499	val: 0.664262	test: 0.623510

Epoch: 71
Loss: 0.39365325632291004
ROC train: 0.872215	val: 0.618616	test: 0.585886
PRC train: 0.836668	val: 0.666284	test: 0.619005

Epoch: 72
Loss: 0.3925007006128332
ROC train: 0.870858	val: 0.615943	test: 0.593111
PRC train: 0.833300	val: 0.667785	test: 0.620929

Epoch: 73
Loss: 0.3864410110885304
ROC train: 0.871131	val: 0.605588	test: 0.592896
PRC train: 0.830876	val: 0.657903	test: 0.619714

Epoch: 74
Loss: 0.3932880143532551
ROC train: 0.875701	val: 0.607554	test: 0.590674
PRC train: 0.835298	val: 0.653582	test: 0.618687

Epoch: 75
Loss: 0.3854934086315951
ROC train: 0.875374	val: 0.615380	test: 0.593584
PRC train: 0.835997	val: 0.662662	test: 0.621774

Epoch: 76
Loss: 0.3893299298189966
ROC train: 0.875677	val: 0.618411	test: 0.594157
PRC train: 0.835046	val: 0.661006	test: 0.624390

Epoch: 77
Loss: 0.3853610069439613
ROC train: 0.879626	val: 0.616092	test: 0.589005
PRC train: 0.838828	val: 0.659497	test: 0.622420

Epoch: 78
Loss: 0.38740302738096527
ROC train: 0.881527	val: 0.612929	test: 0.586865
PRC train: 0.841655	val: 0.660399	test: 0.621911

Epoch: 79
Loss: 0.38003530045725664
ROC train: 0.881188	val: 0.623545	test: 0.585509
PRC train: 0.841465	val: 0.665379	test: 0.618323

Epoch: 80
Loss: 0.3809380056330009
ROC train: 0.883223	val: 0.629764	test: 0.580301
PRC train: 0.843391	val: 0.670839	test: 0.615727

Epoch: 81
Loss: 0.3798420228312611
ROC train: 0.882597	val: 0.640089	test: 0.584258
PRC train: 0.844279	val: 0.675348	test: 0.620113

Epoch: 82
Loss: 0.3719487794474439
ROC train: 0.881869	val: 0.634867	test: 0.588103
PRC train: 0.841945	val: 0.673067	test: 0.622300

Epoch: 83
Loss: 0.38463560067677416
ROC train: 0.884221	val: 0.616289	test: 0.592801
PRC train: 0.842121	val: 0.663593	test: 0.626264

Epoch: 84
Loss: 0.37484929285745305
ROC train: 0.890235	val: 0.613889	test: 0.587608
PRC train: 0.851005	val: 0.660345	test: 0.621408

Epoch: 85
Loss: 0.37401751973950026
ROC train: 0.890341	val: 0.623100	test: 0.590643
PRC train: 0.851360	val: 0.660747	test: 0.625548

Epoch: 86
Loss: 0.3766630385964235
ROC train: 0.890746	val: 0.630244	test: 0.584629
PRC train: 0.853695	val: 0.669627	test: 0.624820

Epoch: 87
Loss: 0.3707743494974564
ROC train: 0.891455	val: 0.630300	test: 0.571295
PRC train: 0.852760	val: 0.670946	test: 0.619870

Epoch: 88
Loss: 0.3698124490970719
ROC train: 0.893938	val: 0.631075	test: 0.578379
PRC train: 0.855123	val: 0.668666	test: 0.624423

Epoch: 89
Loss: 0.37031707847547446
ROC train: 0.895575	val: 0.634032	test: 0.591856
PRC train: 0.857569	val: 0.672811	test: 0.626880

Epoch: 90
Loss: 0.3654473969378121
ROC train: 0.897676	val: 0.629565	test: 0.595597
PRC train: 0.859203	val: 0.670978	test: 0.626355

Epoch: 91
Loss: 0.36581025764772074
ROC train: 0.897271	val: 0.626845	test: 0.582522
PRC train: 0.856329	val: 0.666193	test: 0.620249

Epoch: 92
Loss: 0.36149898616920917
ROC train: 0.897317	val: 0.622279	test: 0.591224
PRC train: 0.857286	val: 0.670539	test: 0.624187

Epoch: 93
Loss: 0.3643330186423458
ROC train: 0.898304	val: 0.618609	test: 0.589506
PRC train: 0.859497	val: 0.667982	test: 0.622607

Epoch: 94
Loss: 0.3609648560415687
ROC train: 0.783857	val: 0.604272	test: 0.611555
PRC train: 0.753065	val: 0.656295	test: 0.627782

Epoch: 34
Loss: 0.44499854134822386
ROC train: 0.788829	val: 0.601463	test: 0.603089
PRC train: 0.759129	val: 0.655731	test: 0.625291

Epoch: 35
Loss: 0.4438770303667116
ROC train: 0.792477	val: 0.613320	test: 0.610419
PRC train: 0.762247	val: 0.656956	test: 0.627168

Epoch: 36
Loss: 0.43956871060157726
ROC train: 0.797142	val: 0.623184	test: 0.608281
PRC train: 0.765226	val: 0.664340	test: 0.623888

Epoch: 37
Loss: 0.44005523665983554
ROC train: 0.802714	val: 0.639580	test: 0.598083
PRC train: 0.768182	val: 0.671686	test: 0.623251

Epoch: 38
Loss: 0.4406812132250345
ROC train: 0.803769	val: 0.633810	test: 0.597240
PRC train: 0.768792	val: 0.670899	test: 0.624865

Epoch: 39
Loss: 0.43744265170959207
ROC train: 0.803366	val: 0.624572	test: 0.603278
PRC train: 0.769754	val: 0.667383	test: 0.627396

Epoch: 40
Loss: 0.4417225480114875
ROC train: 0.806799	val: 0.625917	test: 0.600439
PRC train: 0.773762	val: 0.668154	test: 0.626941

Epoch: 41
Loss: 0.4341916196692283
ROC train: 0.808909	val: 0.630550	test: 0.605407
PRC train: 0.775621	val: 0.669409	test: 0.630596

Epoch: 42
Loss: 0.43479244629845376
ROC train: 0.813528	val: 0.618073	test: 0.602947
PRC train: 0.777997	val: 0.665957	test: 0.628550

Epoch: 43
Loss: 0.42412998321130074
ROC train: 0.810138	val: 0.616466	test: 0.597610
PRC train: 0.773726	val: 0.664071	test: 0.625602

Epoch: 44
Loss: 0.42840994681862854
ROC train: 0.818247	val: 0.624816	test: 0.599156
PRC train: 0.780521	val: 0.667639	test: 0.627224

Epoch: 45
Loss: 0.42650295115075665
ROC train: 0.825243	val: 0.636867	test: 0.595140
PRC train: 0.787299	val: 0.673552	test: 0.626123

Epoch: 46
Loss: 0.43190747858630535
ROC train: 0.827969	val: 0.640619	test: 0.586282
PRC train: 0.787945	val: 0.676705	test: 0.620464

Epoch: 47
Loss: 0.4263316324763629
ROC train: 0.829932	val: 0.641067	test: 0.597073
PRC train: 0.790595	val: 0.675524	test: 0.624026

Epoch: 48
Loss: 0.42760726330818927
ROC train: 0.826928	val: 0.632201	test: 0.598454
PRC train: 0.789564	val: 0.669329	test: 0.623611

Epoch: 49
Loss: 0.41950860594848505
ROC train: 0.828815	val: 0.634568	test: 0.590832
PRC train: 0.789930	val: 0.673145	test: 0.620578

Epoch: 50
Loss: 0.42236534624557953
ROC train: 0.825741	val: 0.637914	test: 0.609630
PRC train: 0.786343	val: 0.670415	test: 0.635836

Epoch: 51
Loss: 0.428610286182278
ROC train: 0.833558	val: 0.640357	test: 0.594895
PRC train: 0.792478	val: 0.674190	test: 0.627108

Epoch: 52
Loss: 0.4166223348088022
ROC train: 0.835227	val: 0.646396	test: 0.577365
PRC train: 0.794227	val: 0.676215	test: 0.621753

Epoch: 53
Loss: 0.42229005225500654
ROC train: 0.838653	val: 0.637048	test: 0.592981
PRC train: 0.796108	val: 0.671539	test: 0.623221

Epoch: 54
Loss: 0.41586271332650515
ROC train: 0.833868	val: 0.626567	test: 0.605324
PRC train: 0.791631	val: 0.668982	test: 0.627638

Epoch: 55
Loss: 0.4182343562460179
ROC train: 0.836867	val: 0.629505	test: 0.601287
PRC train: 0.795189	val: 0.669102	test: 0.630875

Epoch: 56
Loss: 0.40689705568762236
ROC train: 0.845534	val: 0.638776	test: 0.599507
PRC train: 0.804612	val: 0.673616	test: 0.628463

Epoch: 57
Loss: 0.408764752476368
ROC train: 0.845616	val: 0.637790	test: 0.604909
PRC train: 0.803011	val: 0.674100	test: 0.632186

Epoch: 58
Loss: 0.4085951017814427
ROC train: 0.844875	val: 0.632026	test: 0.613823
PRC train: 0.803597	val: 0.671461	test: 0.635909

Epoch: 59
Loss: 0.40862926642914027
ROC train: 0.848430	val: 0.630167	test: 0.604618
PRC train: 0.807895	val: 0.670569	test: 0.630154

Epoch: 60
Loss: 0.4093985565788202
ROC train: 0.848298	val: 0.632188	test: 0.586379
PRC train: 0.807877	val: 0.680235	test: 0.621852

Epoch: 61
Loss: 0.4027349975487569
ROC train: 0.850726	val: 0.634497	test: 0.581940
PRC train: 0.807398	val: 0.678178	test: 0.621038

Epoch: 62
Loss: 0.4074313522697574
ROC train: 0.850431	val: 0.632681	test: 0.602135
PRC train: 0.804970	val: 0.670303	test: 0.629798

Epoch: 63
Loss: 0.4094675416708527
ROC train: 0.851506	val: 0.628613	test: 0.602044
PRC train: 0.806329	val: 0.667678	test: 0.631364

Epoch: 64
Loss: 0.40284020394294495
ROC train: 0.851444	val: 0.629330	test: 0.607932
PRC train: 0.811746	val: 0.668480	test: 0.632591

Epoch: 65
Loss: 0.3992094896506101
ROC train: 0.850563	val: 0.634696	test: 0.611555
PRC train: 0.808741	val: 0.666209	test: 0.635681

Epoch: 66
Loss: 0.4020459995341069
ROC train: 0.858514	val: 0.638156	test: 0.600896
PRC train: 0.815475	val: 0.669514	test: 0.629293

Epoch: 67
Loss: 0.3999022298509014
ROC train: 0.862340	val: 0.618222	test: 0.586223
PRC train: 0.819527	val: 0.663942	test: 0.623547

Epoch: 68
Loss: 0.3984078465744814
ROC train: 0.862640	val: 0.611895	test: 0.594586
PRC train: 0.820591	val: 0.663513	test: 0.629442

Epoch: 69
Loss: 0.39221563775188256
ROC train: 0.863196	val: 0.619102	test: 0.591468
PRC train: 0.822701	val: 0.667859	test: 0.624550

Epoch: 70
Loss: 0.397312518392417
ROC train: 0.861378	val: 0.621817	test: 0.591344
PRC train: 0.820047	val: 0.663961	test: 0.623878

Epoch: 71
Loss: 0.39521481913967205
ROC train: 0.866185	val: 0.618086	test: 0.589748
PRC train: 0.822740	val: 0.660747	test: 0.624717

Epoch: 72
Loss: 0.39072769734713436
ROC train: 0.862446	val: 0.617419	test: 0.586365
PRC train: 0.819066	val: 0.663438	test: 0.622158

Epoch: 73
Loss: 0.3870526347318296
ROC train: 0.869750	val: 0.618806	test: 0.588811
PRC train: 0.827441	val: 0.664744	test: 0.622389

Epoch: 74
Loss: 0.3966679593244639
ROC train: 0.869814	val: 0.619323	test: 0.593333
PRC train: 0.829055	val: 0.661266	test: 0.622334

Epoch: 75
Loss: 0.3891312509568544
ROC train: 0.871752	val: 0.617108	test: 0.598745
PRC train: 0.832578	val: 0.665665	test: 0.623780

Epoch: 76
Loss: 0.38745945507107876
ROC train: 0.874564	val: 0.626392	test: 0.595907
PRC train: 0.835494	val: 0.666963	test: 0.624171

Epoch: 77
Loss: 0.3905466517382794
ROC train: 0.875146	val: 0.627667	test: 0.605958
PRC train: 0.834383	val: 0.667476	test: 0.629687

Epoch: 78
Loss: 0.38556454465356205
ROC train: 0.875725	val: 0.625041	test: 0.608506
PRC train: 0.836278	val: 0.666839	test: 0.630601

Epoch: 79
Loss: 0.38365207178872174
ROC train: 0.877251	val: 0.628091	test: 0.595095
PRC train: 0.836871	val: 0.665920	test: 0.625967

Epoch: 80
Loss: 0.38661172959933415
ROC train: 0.878791	val: 0.630898	test: 0.599369
PRC train: 0.837678	val: 0.665552	test: 0.630418

Epoch: 81
Loss: 0.3802977036445605
ROC train: 0.877400	val: 0.613822	test: 0.613950
PRC train: 0.836346	val: 0.657162	test: 0.637791

Epoch: 82
Loss: 0.3884161475469813
ROC train: 0.881908	val: 0.614682	test: 0.614407
PRC train: 0.840740	val: 0.661703	test: 0.636910

Epoch: 83
Loss: 0.3787256334714401
ROC train: 0.880023	val: 0.625540	test: 0.598494
PRC train: 0.840377	val: 0.668162	test: 0.627219

Epoch: 84
Loss: 0.3795012037086659
ROC train: 0.883436	val: 0.617176	test: 0.581552
PRC train: 0.844482	val: 0.663478	test: 0.620833

Epoch: 85
Loss: 0.37427012827016604
ROC train: 0.883057	val: 0.617921	test: 0.595125
PRC train: 0.844083	val: 0.661591	test: 0.628297

Epoch: 86
Loss: 0.3727499025786797
ROC train: 0.882524	val: 0.624080	test: 0.604192
PRC train: 0.842159	val: 0.663067	test: 0.631535

Epoch: 87
Loss: 0.3761661257696657
ROC train: 0.888448	val: 0.628854	test: 0.603018
PRC train: 0.849139	val: 0.670658	test: 0.629024

Epoch: 88
Loss: 0.3739823280949469
ROC train: 0.886090	val: 0.637385	test: 0.593514
PRC train: 0.847347	val: 0.672620	test: 0.626566

Epoch: 89
Loss: 0.3716678695569435
ROC train: 0.886093	val: 0.633719	test: 0.605365
PRC train: 0.846154	val: 0.668069	test: 0.630625

Epoch: 90
Loss: 0.3706839777929999
ROC train: 0.882231	val: 0.624921	test: 0.598238
PRC train: 0.841069	val: 0.667348	test: 0.629128

Epoch: 91
Loss: 0.36968531869992205
ROC train: 0.891057	val: 0.619048	test: 0.595102
PRC train: 0.850995	val: 0.661659	test: 0.627377

Epoch: 92
Loss: 0.370097000128157
ROC train: 0.892884	val: 0.615562	test: 0.598854
PRC train: 0.853729	val: 0.667205	test: 0.628571

Epoch: 93
Loss: 0.37644252673978373
ROC train: 0.893565	val: 0.621148	test: 0.601037
PRC train: 0.853833	val: 0.667473	test: 0.627053

Epoch: 94
Loss: 0.3702426315407875
ROC train: 0.791949	val: 0.631661	test: 0.601373
PRC train: 0.761175	val: 0.665262	test: 0.631146

Epoch: 34
Loss: 0.44608644947896436
ROC train: 0.796826	val: 0.630285	test: 0.598229
PRC train: 0.766194	val: 0.668005	test: 0.628734

Epoch: 35
Loss: 0.4433050236981642
ROC train: 0.799042	val: 0.633742	test: 0.593336
PRC train: 0.768552	val: 0.671393	test: 0.627419

Epoch: 36
Loss: 0.4411459846826462
ROC train: 0.797956	val: 0.627751	test: 0.604742
PRC train: 0.768537	val: 0.666424	test: 0.630969

Epoch: 37
Loss: 0.4399005178629155
ROC train: 0.803602	val: 0.635446	test: 0.610842
PRC train: 0.772912	val: 0.667721	test: 0.638365

Epoch: 38
Loss: 0.444639133821391
ROC train: 0.806515	val: 0.633746	test: 0.607468
PRC train: 0.773581	val: 0.664871	test: 0.637549

Epoch: 39
Loss: 0.4433165707817134
ROC train: 0.811270	val: 0.642787	test: 0.603992
PRC train: 0.776756	val: 0.672509	test: 0.633718

Epoch: 40
Loss: 0.43486547331853487
ROC train: 0.812250	val: 0.636577	test: 0.605249
PRC train: 0.780694	val: 0.673518	test: 0.631993

Epoch: 41
Loss: 0.4326802083929201
ROC train: 0.813622	val: 0.630092	test: 0.594044
PRC train: 0.782792	val: 0.669929	test: 0.625090

Epoch: 42
Loss: 0.4370818343765192
ROC train: 0.814506	val: 0.623188	test: 0.593560
PRC train: 0.781342	val: 0.663805	test: 0.624331

Epoch: 43
Loss: 0.4330512348280928
ROC train: 0.813227	val: 0.621422	test: 0.597963
PRC train: 0.780083	val: 0.665716	test: 0.627524

Epoch: 44
Loss: 0.4274396137256281
ROC train: 0.818039	val: 0.632785	test: 0.603695
PRC train: 0.786049	val: 0.669027	test: 0.629931

Epoch: 45
Loss: 0.4307312093120145
ROC train: 0.822181	val: 0.627443	test: 0.603975
PRC train: 0.788557	val: 0.669204	test: 0.627065

Epoch: 46
Loss: 0.42753542766668406
ROC train: 0.825355	val: 0.621263	test: 0.598553
PRC train: 0.790237	val: 0.673050	test: 0.624901

Epoch: 47
Loss: 0.4256105201686461
ROC train: 0.820739	val: 0.620338	test: 0.602977
PRC train: 0.784721	val: 0.666595	test: 0.632022

Epoch: 48
Loss: 0.42462287838135265
ROC train: 0.827070	val: 0.621078	test: 0.605015
PRC train: 0.791811	val: 0.664574	test: 0.630766

Epoch: 49
Loss: 0.4241334171055269
ROC train: 0.827876	val: 0.629789	test: 0.601115
PRC train: 0.792777	val: 0.669876	test: 0.623596

Epoch: 50
Loss: 0.426433558749493
ROC train: 0.829475	val: 0.629974	test: 0.607339
PRC train: 0.796559	val: 0.669184	test: 0.626929

Epoch: 51
Loss: 0.4174052594108055
ROC train: 0.829656	val: 0.624646	test: 0.610130
PRC train: 0.796276	val: 0.665610	test: 0.630860

Epoch: 52
Loss: 0.42332065710172306
ROC train: 0.837695	val: 0.624281	test: 0.608928
PRC train: 0.804066	val: 0.671377	test: 0.631011

Epoch: 53
Loss: 0.4255278396756287
ROC train: 0.839020	val: 0.625313	test: 0.601544
PRC train: 0.805926	val: 0.670060	test: 0.630182

Epoch: 54
Loss: 0.420166772444889
ROC train: 0.837428	val: 0.625869	test: 0.597553
PRC train: 0.803947	val: 0.669068	test: 0.629472

Epoch: 55
Loss: 0.41706468322126194
ROC train: 0.840092	val: 0.630164	test: 0.587202
PRC train: 0.803187	val: 0.671644	test: 0.625487

Epoch: 56
Loss: 0.41675937782629446
ROC train: 0.844843	val: 0.623977	test: 0.593991
PRC train: 0.808269	val: 0.667096	test: 0.623948

Epoch: 57
Loss: 0.41553310456187853
ROC train: 0.843472	val: 0.628530	test: 0.589576
PRC train: 0.808306	val: 0.675942	test: 0.623189

Epoch: 58
Loss: 0.41539150189223334
ROC train: 0.842117	val: 0.614412	test: 0.595678
PRC train: 0.806954	val: 0.662666	test: 0.628322

Epoch: 59
Loss: 0.41496937303690007
ROC train: 0.843882	val: 0.615328	test: 0.596516
PRC train: 0.808277	val: 0.657351	test: 0.628111

Epoch: 60
Loss: 0.4136265514925773
ROC train: 0.846298	val: 0.622357	test: 0.582697
PRC train: 0.809727	val: 0.667988	test: 0.620005

Epoch: 61
Loss: 0.40941714400814355
ROC train: 0.850445	val: 0.631486	test: 0.581767
PRC train: 0.811735	val: 0.669061	test: 0.617656

Epoch: 62
Loss: 0.40822402195553603
ROC train: 0.853499	val: 0.628801	test: 0.590597
PRC train: 0.816039	val: 0.665730	test: 0.622751

Epoch: 63
Loss: 0.407961809966383
ROC train: 0.852523	val: 0.635459	test: 0.597935
PRC train: 0.815632	val: 0.674169	test: 0.629847

Epoch: 64
Loss: 0.4084623547477175
ROC train: 0.856249	val: 0.634599	test: 0.604889
PRC train: 0.819667	val: 0.671557	test: 0.634236

Epoch: 65
Loss: 0.4039615741660773
ROC train: 0.857551	val: 0.630167	test: 0.592422
PRC train: 0.820215	val: 0.672085	test: 0.628038

Epoch: 66
Loss: 0.4052187050831095
ROC train: 0.859318	val: 0.621666	test: 0.586820
PRC train: 0.822278	val: 0.669226	test: 0.622866

Epoch: 67
Loss: 0.40283227114019143
ROC train: 0.863057	val: 0.629259	test: 0.588007
PRC train: 0.825177	val: 0.671097	test: 0.624612

Epoch: 68
Loss: 0.39712585659803057
ROC train: 0.864168	val: 0.629646	test: 0.597645
PRC train: 0.826173	val: 0.671539	test: 0.632183

Epoch: 69
Loss: 0.3957134099527382
ROC train: 0.863697	val: 0.625441	test: 0.598297
PRC train: 0.827331	val: 0.673304	test: 0.632014

Epoch: 70
Loss: 0.39092600344788137
ROC train: 0.866023	val: 0.614099	test: 0.592020
PRC train: 0.827524	val: 0.672398	test: 0.627565

Epoch: 71
Loss: 0.3928745693211039
ROC train: 0.866806	val: 0.613439	test: 0.594758
PRC train: 0.828626	val: 0.672871	test: 0.627298

Epoch: 72
Loss: 0.3910135027279168
ROC train: 0.867717	val: 0.622138	test: 0.587794
PRC train: 0.830288	val: 0.671166	test: 0.622552

Epoch: 73
Loss: 0.3864636460354026
ROC train: 0.869470	val: 0.629615	test: 0.598626
PRC train: 0.831915	val: 0.672446	test: 0.628466

Epoch: 74
Loss: 0.38736389915200153
ROC train: 0.871509	val: 0.628117	test: 0.601943
PRC train: 0.832991	val: 0.666296	test: 0.632050

Epoch: 75
Loss: 0.3863428148146041
ROC train: 0.873472	val: 0.613981	test: 0.596063
PRC train: 0.835194	val: 0.660336	test: 0.631097

Epoch: 76
Loss: 0.37888335483858177
ROC train: 0.871217	val: 0.620869	test: 0.592512
PRC train: 0.833339	val: 0.669817	test: 0.625965

Epoch: 77
Loss: 0.38964248750573965
ROC train: 0.872961	val: 0.625456	test: 0.591949
PRC train: 0.836333	val: 0.670350	test: 0.626283

Epoch: 78
Loss: 0.38444691325124103
ROC train: 0.872052	val: 0.629776	test: 0.594635
PRC train: 0.835191	val: 0.666949	test: 0.623766

Epoch: 79
Loss: 0.37893181776492285
ROC train: 0.875030	val: 0.627853	test: 0.602632
PRC train: 0.837584	val: 0.666716	test: 0.627975

Epoch: 80
Loss: 0.38602889123939105
ROC train: 0.880523	val: 0.613310	test: 0.597549
PRC train: 0.841451	val: 0.663643	test: 0.629656

Epoch: 81
Loss: 0.3776093593783311
ROC train: 0.879085	val: 0.606237	test: 0.581654
PRC train: 0.837998	val: 0.662641	test: 0.622725

Epoch: 82
Loss: 0.3791812792304669
ROC train: 0.883691	val: 0.623113	test: 0.591838
PRC train: 0.844065	val: 0.666118	test: 0.630331

Epoch: 83
Loss: 0.3769946339319018
ROC train: 0.883744	val: 0.621012	test: 0.589489
PRC train: 0.843842	val: 0.661606	test: 0.630293

Epoch: 84
Loss: 0.3830858976028114
ROC train: 0.884650	val: 0.618227	test: 0.600515
PRC train: 0.846363	val: 0.662875	test: 0.633423

Epoch: 85
Loss: 0.37520901568861137
ROC train: 0.886789	val: 0.632241	test: 0.592149
PRC train: 0.847121	val: 0.672157	test: 0.626039

Epoch: 86
Loss: 0.37688589621773827
ROC train: 0.886860	val: 0.636512	test: 0.596398
PRC train: 0.847704	val: 0.672544	test: 0.626785

Epoch: 87
Loss: 0.3772543898775688
ROC train: 0.887381	val: 0.643449	test: 0.590006
PRC train: 0.850194	val: 0.675093	test: 0.624994

Epoch: 88
Loss: 0.3778378556649838
ROC train: 0.884726	val: 0.641020	test: 0.597742
PRC train: 0.846261	val: 0.666523	test: 0.631601

Epoch: 89
Loss: 0.37760034828376654
ROC train: 0.889553	val: 0.629886	test: 0.592488
PRC train: 0.852381	val: 0.669930	test: 0.629925

Epoch: 90
Loss: 0.37127866534629816
ROC train: 0.890337	val: 0.616689	test: 0.583772
PRC train: 0.853056	val: 0.667771	test: 0.626770

Epoch: 91
Loss: 0.37253116134416076
ROC train: 0.892805	val: 0.619204	test: 0.595623
PRC train: 0.854287	val: 0.666905	test: 0.631189

Epoch: 92
Loss: 0.37075921999201544
ROC train: 0.889562	val: 0.629481	test: 0.601672
PRC train: 0.851182	val: 0.668422	test: 0.633816

Epoch: 93
Loss: 0.3702882310840815
ROC train: 0.892619	val: 0.632411	test: 0.588136
PRC train: 0.854994	val: 0.670853	test: 0.625217

Epoch: 94
Loss: 0.36840972965034935
ROC train: 0.905833	val: 0.581270	test: 0.613436
PRC train: 0.864970	val: 0.650934	test: 0.637877

Epoch: 95
Loss: 0.3559049884590122
ROC train: 0.905145	val: 0.578020	test: 0.617839
PRC train: 0.866623	val: 0.650138	test: 0.641476

Epoch: 96
Loss: 0.353544258673421
ROC train: 0.907412	val: 0.575412	test: 0.614013
PRC train: 0.867800	val: 0.649507	test: 0.637757

Epoch: 97
Loss: 0.3525932497323457
ROC train: 0.909927	val: 0.574887	test: 0.606797
PRC train: 0.869430	val: 0.650546	test: 0.631911

Epoch: 98
Loss: 0.3545791199631747
ROC train: 0.909634	val: 0.581256	test: 0.609932
PRC train: 0.870230	val: 0.650923	test: 0.633515

Epoch: 99
Loss: 0.35123484891265117
ROC train: 0.911335	val: 0.580995	test: 0.610326
PRC train: 0.873479	val: 0.649159	test: 0.636153

Epoch: 100
Loss: 0.35513120380770513
ROC train: 0.910445	val: 0.576282	test: 0.609373
PRC train: 0.873722	val: 0.646538	test: 0.637783

Epoch: 101
Loss: 0.35232365680531696
ROC train: 0.913631	val: 0.584249	test: 0.613235
PRC train: 0.876276	val: 0.651296	test: 0.639926

Epoch: 102
Loss: 0.3510141274191456
ROC train: 0.910560	val: 0.583995	test: 0.608589
PRC train: 0.870223	val: 0.649802	test: 0.634205

Epoch: 103
Loss: 0.3463636968157399
ROC train: 0.913454	val: 0.586354	test: 0.605853
PRC train: 0.878667	val: 0.650976	test: 0.632803

Epoch: 104
Loss: 0.34748901359895656
ROC train: 0.914517	val: 0.584606	test: 0.607214
PRC train: 0.880002	val: 0.651595	test: 0.632550

Epoch: 105
Loss: 0.347314606806654
ROC train: 0.916006	val: 0.585064	test: 0.613620
PRC train: 0.882324	val: 0.652947	test: 0.636416

Epoch: 106
Loss: 0.3496434986074361
ROC train: 0.916358	val: 0.579482	test: 0.618004
PRC train: 0.884571	val: 0.650811	test: 0.637886

Epoch: 107
Loss: 0.346111402619233
ROC train: 0.916163	val: 0.576328	test: 0.616129
PRC train: 0.883370	val: 0.649338	test: 0.637841

Epoch: 108
Loss: 0.35048476396689376
ROC train: 0.919805	val: 0.570979	test: 0.606682
PRC train: 0.884122	val: 0.647579	test: 0.635135

Epoch: 109
Loss: 0.3462625367961303
ROC train: 0.920516	val: 0.570236	test: 0.609023
PRC train: 0.885686	val: 0.645684	test: 0.635410

Epoch: 110
Loss: 0.34041262578455483
ROC train: 0.920239	val: 0.575777	test: 0.617891
PRC train: 0.886951	val: 0.649186	test: 0.638707

Epoch: 111
Loss: 0.34021210015225795
ROC train: 0.918850	val: 0.572361	test: 0.621917
PRC train: 0.882795	val: 0.646780	test: 0.641742

Epoch: 112
Loss: 0.3381672070756288
ROC train: 0.922490	val: 0.574718	test: 0.623737
PRC train: 0.890197	val: 0.649281	test: 0.639791

Epoch: 113
Loss: 0.3353677972699201
ROC train: 0.924396	val: 0.576111	test: 0.617193
PRC train: 0.893198	val: 0.649846	test: 0.634121

Epoch: 114
Loss: 0.33295603077315594
ROC train: 0.923977	val: 0.574084	test: 0.617050
PRC train: 0.893701	val: 0.648224	test: 0.634095

Epoch: 115
Loss: 0.3302601782510686
ROC train: 0.924855	val: 0.572761	test: 0.611164
PRC train: 0.892377	val: 0.646279	test: 0.632505

Epoch: 116
Loss: 0.33373460922456805
ROC train: 0.926496	val: 0.575655	test: 0.602966
PRC train: 0.895632	val: 0.647703	test: 0.629274

Epoch: 117
Loss: 0.33253125183907245
ROC train: 0.928609	val: 0.573288	test: 0.601199
PRC train: 0.897593	val: 0.647631	test: 0.627849

Epoch: 118
Loss: 0.3329613689766002
ROC train: 0.925084	val: 0.571156	test: 0.611837
PRC train: 0.891422	val: 0.645371	test: 0.633830

Epoch: 119
Loss: 0.332258892773591
ROC train: 0.929060	val: 0.575210	test: 0.612356
PRC train: 0.897739	val: 0.646577	test: 0.634507

Epoch: 120
Loss: 0.33037253238232894
ROC train: 0.924642	val: 0.568512	test: 0.600133
PRC train: 0.892498	val: 0.641246	test: 0.624926

Early stopping
Best (ROC):	 train: 0.891223	val: 0.587639	test: 0.600333
Best (PRC):	 train: 0.848794	val: 0.656130	test: 0.626434

PRC train: 0.846098	val: 0.640702	test: 0.629602

Epoch: 95
Loss: 0.3726899168942651
ROC train: 0.893405	val: 0.568902	test: 0.585877
PRC train: 0.852326	val: 0.641154	test: 0.630357

Epoch: 96
Loss: 0.3764169203974943
ROC train: 0.887993	val: 0.580366	test: 0.584944
PRC train: 0.847768	val: 0.648592	test: 0.625550

Epoch: 97
Loss: 0.36637024059121537
ROC train: 0.893723	val: 0.591747	test: 0.593106
PRC train: 0.852826	val: 0.657389	test: 0.627731

Epoch: 98
Loss: 0.36276311869513267
ROC train: 0.895809	val: 0.586108	test: 0.591892
PRC train: 0.852714	val: 0.653212	test: 0.628201

Epoch: 99
Loss: 0.3624698268635324
ROC train: 0.889441	val: 0.575981	test: 0.586284
PRC train: 0.843184	val: 0.648243	test: 0.626545

Epoch: 100
Loss: 0.3651829732319267
ROC train: 0.889566	val: 0.571116	test: 0.585971
PRC train: 0.843628	val: 0.644254	test: 0.628604

Epoch: 101
Loss: 0.3688195795207734
ROC train: 0.895453	val: 0.574397	test: 0.592744
PRC train: 0.852457	val: 0.645463	test: 0.631286

Epoch: 102
Loss: 0.36074471747136555
ROC train: 0.901288	val: 0.572040	test: 0.599111
PRC train: 0.862037	val: 0.642637	test: 0.632540

Epoch: 103
Loss: 0.35490495117229126
ROC train: 0.903752	val: 0.567622	test: 0.595993
PRC train: 0.864149	val: 0.639888	test: 0.630028

Epoch: 104
Loss: 0.3601602995775937
ROC train: 0.905754	val: 0.575457	test: 0.592285
PRC train: 0.867105	val: 0.645154	test: 0.625989

Epoch: 105
Loss: 0.3522666187447242
ROC train: 0.905011	val: 0.576880	test: 0.590616
PRC train: 0.865115	val: 0.645816	test: 0.624938

Epoch: 106
Loss: 0.36012159546006917
ROC train: 0.903824	val: 0.575058	test: 0.590783
PRC train: 0.862536	val: 0.646701	test: 0.628589

Epoch: 107
Loss: 0.35052987202874536
ROC train: 0.902133	val: 0.573649	test: 0.588668
PRC train: 0.858244	val: 0.644021	test: 0.625873

Epoch: 108
Loss: 0.3426726827294752
ROC train: 0.906477	val: 0.580171	test: 0.592269
PRC train: 0.864896	val: 0.648611	test: 0.626169

Epoch: 109
Loss: 0.3498822490051458
ROC train: 0.909849	val: 0.575741	test: 0.595591
PRC train: 0.874820	val: 0.646938	test: 0.632394

Epoch: 110
Loss: 0.3523392903645424
ROC train: 0.910990	val: 0.577142	test: 0.594623
PRC train: 0.875795	val: 0.647983	test: 0.631524

Epoch: 111
Loss: 0.3474642504485247
ROC train: 0.907846	val: 0.580837	test: 0.592915
PRC train: 0.871963	val: 0.651014	test: 0.629566

Epoch: 112
Loss: 0.34226560245540083
ROC train: 0.910239	val: 0.576679	test: 0.596988
PRC train: 0.876279	val: 0.645039	test: 0.631725

Epoch: 113
Loss: 0.3504332230800462
ROC train: 0.910225	val: 0.572136	test: 0.601175
PRC train: 0.878800	val: 0.638320	test: 0.633048

Epoch: 114
Loss: 0.34827629726003
ROC train: 0.908883	val: 0.573817	test: 0.603543
PRC train: 0.876451	val: 0.637252	test: 0.632634

Epoch: 115
Loss: 0.3431996469151344
ROC train: 0.913366	val: 0.582159	test: 0.604373
PRC train: 0.880820	val: 0.642311	test: 0.633391

Epoch: 116
Loss: 0.3441021463024213
ROC train: 0.906242	val: 0.583120	test: 0.597678
PRC train: 0.866675	val: 0.646495	test: 0.630016

Epoch: 117
Loss: 0.3535765699956703
ROC train: 0.913599	val: 0.581932	test: 0.596913
PRC train: 0.879483	val: 0.647810	test: 0.631049

Epoch: 118
Loss: 0.338067665835642
ROC train: 0.913410	val: 0.579067	test: 0.592411
PRC train: 0.880316	val: 0.645917	test: 0.628476

Epoch: 119
Loss: 0.34868670334228963
ROC train: 0.918382	val: 0.577677	test: 0.596590
PRC train: 0.886059	val: 0.644463	test: 0.631897

Epoch: 120
Loss: 0.33172455403965323
ROC train: 0.917008	val: 0.578849	test: 0.599598
PRC train: 0.883319	val: 0.645847	test: 0.631344

Epoch: 121
Loss: 0.34012777971784225
ROC train: 0.919029	val: 0.579079	test: 0.598411
PRC train: 0.881610	val: 0.646276	test: 0.629873

Epoch: 122
Loss: 0.34129655751573784
ROC train: 0.920662	val: 0.582219	test: 0.594690
PRC train: 0.886669	val: 0.648298	test: 0.628702

Epoch: 123
Loss: 0.34342334316910395
ROC train: 0.917831	val: 0.580106	test: 0.586358
PRC train: 0.879469	val: 0.645674	test: 0.624980

Epoch: 124
Loss: 0.3433847903010679
ROC train: 0.919776	val: 0.586517	test: 0.590108
PRC train: 0.883559	val: 0.648690	test: 0.627619

Epoch: 125
Loss: 0.33624236305018634
ROC train: 0.921801	val: 0.585630	test: 0.597218
PRC train: 0.888629	val: 0.649574	test: 0.632769

Epoch: 126
Loss: 0.3354104725523308
ROC train: 0.923608	val: 0.579286	test: 0.595883
PRC train: 0.892161	val: 0.645607	test: 0.634918

Epoch: 127
Loss: 0.33280060626537283
ROC train: 0.922502	val: 0.572555	test: 0.596298
PRC train: 0.891407	val: 0.641310	test: 0.634883

Epoch: 128
Loss: 0.3412589637795082
ROC train: 0.921734	val: 0.568911	test: 0.598924
PRC train: 0.888986	val: 0.637669	test: 0.634618

Epoch: 129
Loss: 0.3330294102917788
ROC train: 0.923989	val: 0.571627	test: 0.600319
PRC train: 0.888679	val: 0.636836	test: 0.636409

Epoch: 130
Loss: 0.3270753618495427
ROC train: 0.926791	val: 0.578374	test: 0.600726
PRC train: 0.891963	val: 0.643562	test: 0.635591

Epoch: 131
Loss: 0.3326437857288016
ROC train: 0.927131	val: 0.583294	test: 0.599176
PRC train: 0.893929	val: 0.647979	test: 0.634216

Epoch: 132
Loss: 0.32121202703749285
ROC train: 0.928486	val: 0.582640	test: 0.596494
PRC train: 0.895453	val: 0.648796	test: 0.635084

Early stopping
Best (ROC):	 train: 0.893723	val: 0.591747	test: 0.593106
Best (PRC):	 train: 0.852826	val: 0.657389	test: 0.627731
ROC train: 0.896175	val: 0.566014	test: 0.604742
PRC train: 0.856457	val: 0.631181	test: 0.639450

Epoch: 95
Loss: 0.3742044921759528
ROC train: 0.896449	val: 0.566376	test: 0.601315
PRC train: 0.858213	val: 0.634181	test: 0.636288

Epoch: 96
Loss: 0.36629801036429993
ROC train: 0.896627	val: 0.561441	test: 0.600863
PRC train: 0.856490	val: 0.631586	test: 0.637642

Epoch: 97
Loss: 0.3622847091641652
ROC train: 0.898234	val: 0.564104	test: 0.604734
PRC train: 0.854797	val: 0.631988	test: 0.637580

Epoch: 98
Loss: 0.3565002821859383
ROC train: 0.898503	val: 0.561701	test: 0.604096
PRC train: 0.856210	val: 0.632203	test: 0.637259

Epoch: 99
Loss: 0.3573419967565296
ROC train: 0.897805	val: 0.562505	test: 0.598577
PRC train: 0.855456	val: 0.633081	test: 0.635469

Epoch: 100
Loss: 0.35610820444578906
ROC train: 0.897553	val: 0.565623	test: 0.600725
PRC train: 0.855959	val: 0.633396	test: 0.635958

Epoch: 101
Loss: 0.3590573437226008
ROC train: 0.900616	val: 0.566766	test: 0.607539
PRC train: 0.859880	val: 0.633475	test: 0.641803

Epoch: 102
Loss: 0.3604051494782872
ROC train: 0.900932	val: 0.572609	test: 0.614280
PRC train: 0.859799	val: 0.635658	test: 0.646625

Epoch: 103
Loss: 0.3579666136706587
ROC train: 0.901442	val: 0.568247	test: 0.613978
PRC train: 0.860251	val: 0.634782	test: 0.646144

Epoch: 104
Loss: 0.35157027090937404
ROC train: 0.899821	val: 0.562421	test: 0.609319
PRC train: 0.860809	val: 0.634594	test: 0.643355

Epoch: 105
Loss: 0.3596884120058994
ROC train: 0.904050	val: 0.558363	test: 0.609781
PRC train: 0.864847	val: 0.632733	test: 0.641658

Epoch: 106
Loss: 0.3493570106131532
ROC train: 0.904351	val: 0.558328	test: 0.605046
PRC train: 0.864382	val: 0.632264	test: 0.642021

Epoch: 107
Loss: 0.3627354270674308
ROC train: 0.904117	val: 0.563026	test: 0.599862
PRC train: 0.863856	val: 0.632949	test: 0.640387

Epoch: 108
Loss: 0.350602720362907
ROC train: 0.908397	val: 0.566851	test: 0.601880
PRC train: 0.867605	val: 0.633216	test: 0.639777

Epoch: 109
Loss: 0.3443344613572453
ROC train: 0.908917	val: 0.562554	test: 0.601085
PRC train: 0.869791	val: 0.628761	test: 0.640385

Epoch: 110
Loss: 0.35696630725944256
ROC train: 0.907983	val: 0.559982	test: 0.596356
PRC train: 0.868629	val: 0.624307	test: 0.638933

Epoch: 111
Loss: 0.3594337291155718
ROC train: 0.909379	val: 0.559141	test: 0.598955
PRC train: 0.868296	val: 0.624943	test: 0.639952

Epoch: 112
Loss: 0.3492664516927805
ROC train: 0.910240	val: 0.561584	test: 0.602099
PRC train: 0.869626	val: 0.628495	test: 0.641683

Epoch: 113
Loss: 0.3457917810967046
ROC train: 0.914402	val: 0.559899	test: 0.607485
PRC train: 0.875397	val: 0.627814	test: 0.646380

Epoch: 114
Loss: 0.3556818987281034
ROC train: 0.913075	val: 0.556384	test: 0.605322
PRC train: 0.873745	val: 0.627724	test: 0.643990

Epoch: 115
Loss: 0.3434032302885084
ROC train: 0.911298	val: 0.551745	test: 0.606742
PRC train: 0.874681	val: 0.623762	test: 0.645786

Epoch: 116
Loss: 0.33943258131115744
ROC train: 0.910332	val: 0.551402	test: 0.603729
PRC train: 0.873617	val: 0.624884	test: 0.645857

Epoch: 117
Loss: 0.3463040539797018
ROC train: 0.917296	val: 0.556836	test: 0.601999
PRC train: 0.882304	val: 0.629019	test: 0.643290

Epoch: 118
Loss: 0.3334851193871884
ROC train: 0.917590	val: 0.560228	test: 0.604110
PRC train: 0.882062	val: 0.626198	test: 0.642542

Epoch: 119
Loss: 0.33770624600449595
ROC train: 0.919933	val: 0.561211	test: 0.604908
PRC train: 0.884913	val: 0.626619	test: 0.641783

Epoch: 120
Loss: 0.33405508488494523
ROC train: 0.913053	val: 0.563360	test: 0.604847
PRC train: 0.876537	val: 0.629134	test: 0.642313

Epoch: 121
Loss: 0.33432873126608936
ROC train: 0.916381	val: 0.565394	test: 0.612185
PRC train: 0.880240	val: 0.630669	test: 0.645221

Epoch: 122
Loss: 0.3419797461959032
ROC train: 0.919660	val: 0.558645	test: 0.617495
PRC train: 0.883888	val: 0.626490	test: 0.647482

Epoch: 123
Loss: 0.3393620891887719
ROC train: 0.918229	val: 0.548142	test: 0.615209
PRC train: 0.884575	val: 0.620980	test: 0.648575

Epoch: 124
Loss: 0.33037947662764827
ROC train: 0.916808	val: 0.551745	test: 0.608553
PRC train: 0.882952	val: 0.622734	test: 0.646370

Epoch: 125
Loss: 0.33520347092560104
ROC train: 0.921686	val: 0.560308	test: 0.608268
PRC train: 0.888857	val: 0.627142	test: 0.644341

Epoch: 126
Loss: 0.32913501803020256
ROC train: 0.921198	val: 0.564254	test: 0.605946
PRC train: 0.887684	val: 0.630047	test: 0.641656

Epoch: 127
Loss: 0.34417288773622073
ROC train: 0.922353	val: 0.570414	test: 0.606055
PRC train: 0.890402	val: 0.632722	test: 0.640854

Epoch: 128
Loss: 0.3292889677640748
ROC train: 0.924464	val: 0.570571	test: 0.609745
PRC train: 0.891321	val: 0.634105	test: 0.644576

Epoch: 129
Loss: 0.3258090207175146
ROC train: 0.925523	val: 0.569509	test: 0.612157
PRC train: 0.892315	val: 0.633498	test: 0.645244

Epoch: 130
Loss: 0.3275020426584689
ROC train: 0.926954	val: 0.570281	test: 0.614128
PRC train: 0.896231	val: 0.632272	test: 0.645687

Epoch: 131
Loss: 0.3369272448341383
ROC train: 0.924976	val: 0.567601	test: 0.613561
PRC train: 0.895828	val: 0.630915	test: 0.647212

Epoch: 132
Loss: 0.3259633589740754
ROC train: 0.923973	val: 0.562042	test: 0.603806
PRC train: 0.892121	val: 0.630064	test: 0.646064

Epoch: 133
Loss: 0.32381045982552015
ROC train: 0.922301	val: 0.555995	test: 0.601219
PRC train: 0.890845	val: 0.626103	test: 0.644209

Epoch: 134
Loss: 0.32988640710572337
ROC train: 0.927327	val: 0.560171	test: 0.601176
PRC train: 0.897035	val: 0.629701	test: 0.645291

Epoch: 135
Loss: 0.32364705230682933
ROC train: 0.930244	val: 0.564555	test: 0.603723
PRC train: 0.898767	val: 0.630989	test: 0.646462

Epoch: 136
Loss: 0.32728389679609726
ROC train: 0.931156	val: 0.564141	test: 0.608818
PRC train: 0.899384	val: 0.633257	test: 0.647172

Epoch: 137
Loss: 0.3235504487378147
ROC train: 0.930550	val: 0.568245	test: 0.612052
PRC train: 0.900403	val: 0.636081	test: 0.647400

Early stopping
Best (ROC):	 train: 0.900932	val: 0.572609	test: 0.614280
Best (PRC):	 train: 0.859799	val: 0.635658	test: 0.646625

ROC train: 0.895181	val: 0.633931	test: 0.601352
PRC train: 0.856438	val: 0.665444	test: 0.626147

Epoch: 95
Loss: 0.371400945195112
ROC train: 0.892331	val: 0.643086	test: 0.590678
PRC train: 0.850595	val: 0.671327	test: 0.621136

Epoch: 96
Loss: 0.36479616695784595
ROC train: 0.898841	val: 0.633334	test: 0.594915
PRC train: 0.862083	val: 0.667108	test: 0.624332

Epoch: 97
Loss: 0.36142637458662474
ROC train: 0.898875	val: 0.619746	test: 0.590629
PRC train: 0.863240	val: 0.662999	test: 0.625474

Epoch: 98
Loss: 0.3567006646624207
ROC train: 0.899987	val: 0.623002	test: 0.580327
PRC train: 0.862748	val: 0.662653	test: 0.624787

Epoch: 99
Loss: 0.3618173444552621
ROC train: 0.900657	val: 0.623658	test: 0.573179
PRC train: 0.861806	val: 0.664850	test: 0.620352

Epoch: 100
Loss: 0.3539292971938056
ROC train: 0.900967	val: 0.616598	test: 0.595066
PRC train: 0.863475	val: 0.666309	test: 0.627324

Epoch: 101
Loss: 0.35636270971742745
ROC train: 0.904258	val: 0.625673	test: 0.593653
PRC train: 0.869015	val: 0.671229	test: 0.626938

Epoch: 102
Loss: 0.35236220805802065
ROC train: 0.903743	val: 0.626746	test: 0.587582
PRC train: 0.868126	val: 0.668659	test: 0.626613

Epoch: 103
Loss: 0.3574148776262726
ROC train: 0.904427	val: 0.617955	test: 0.604935
PRC train: 0.866491	val: 0.663037	test: 0.635548

Epoch: 104
Loss: 0.35508580091054726
ROC train: 0.904836	val: 0.612747	test: 0.598606
PRC train: 0.866503	val: 0.660506	test: 0.631512

Epoch: 105
Loss: 0.3565473472383317
ROC train: 0.906271	val: 0.623045	test: 0.597154
PRC train: 0.867501	val: 0.663934	test: 0.630240

Epoch: 106
Loss: 0.35448853701626015
ROC train: 0.906168	val: 0.631195	test: 0.601289
PRC train: 0.868424	val: 0.664106	test: 0.632187

Epoch: 107
Loss: 0.35088181425140846
ROC train: 0.911198	val: 0.630312	test: 0.594750
PRC train: 0.874139	val: 0.667317	test: 0.626555

Epoch: 108
Loss: 0.34832215564793334
ROC train: 0.910701	val: 0.619514	test: 0.585801
PRC train: 0.872362	val: 0.665189	test: 0.622466

Epoch: 109
Loss: 0.34804276008944424
ROC train: 0.909584	val: 0.622430	test: 0.591913
PRC train: 0.871905	val: 0.664669	test: 0.629031

Epoch: 110
Loss: 0.34962416524044154
ROC train: 0.910754	val: 0.620418	test: 0.595203
PRC train: 0.874585	val: 0.662731	test: 0.630491

Epoch: 111
Loss: 0.350268980704919
ROC train: 0.910524	val: 0.617829	test: 0.595465
PRC train: 0.872541	val: 0.660278	test: 0.630761

Epoch: 112
Loss: 0.34787603537634876
ROC train: 0.912239	val: 0.625192	test: 0.588446
PRC train: 0.875659	val: 0.661698	test: 0.626982

Epoch: 113
Loss: 0.3456431140963338
ROC train: 0.914209	val: 0.625704	test: 0.582262
PRC train: 0.878469	val: 0.660846	test: 0.625049

Epoch: 114
Loss: 0.34811383178838073
ROC train: 0.915447	val: 0.624546	test: 0.572566
PRC train: 0.877891	val: 0.663869	test: 0.619655

Epoch: 115
Loss: 0.3503517947333849
ROC train: 0.910484	val: 0.611298	test: 0.566103
PRC train: 0.872297	val: 0.662218	test: 0.616961

Epoch: 116
Loss: 0.34666043799561597
ROC train: 0.917230	val: 0.626446	test: 0.582096
PRC train: 0.881087	val: 0.665997	test: 0.624642

Epoch: 117
Loss: 0.3460749570954005
ROC train: 0.914180	val: 0.631239	test: 0.603854
PRC train: 0.874494	val: 0.670006	test: 0.634382

Epoch: 118
Loss: 0.33947783087039485
ROC train: 0.918633	val: 0.638831	test: 0.605314
PRC train: 0.882239	val: 0.668780	test: 0.635094

Epoch: 119
Loss: 0.33416699006933126
ROC train: 0.919006	val: 0.631967	test: 0.608274
PRC train: 0.884024	val: 0.665859	test: 0.633851

Epoch: 120
Loss: 0.3405413843691824
ROC train: 0.918016	val: 0.622577	test: 0.611493
PRC train: 0.881059	val: 0.662644	test: 0.635931

Early stopping
Best (ROC):	 train: 0.835227	val: 0.646396	test: 0.577365
Best (PRC):	 train: 0.794227	val: 0.676215	test: 0.621753

ROC train: 0.898299	val: 0.569768	test: 0.620376
PRC train: 0.860990	val: 0.648675	test: 0.637440

Epoch: 95
Loss: 0.35810736948287
ROC train: 0.899501	val: 0.574347	test: 0.625040
PRC train: 0.861666	val: 0.647274	test: 0.637871

Epoch: 96
Loss: 0.3608586579607318
ROC train: 0.900280	val: 0.582081	test: 0.627263
PRC train: 0.864041	val: 0.654362	test: 0.638104

Epoch: 97
Loss: 0.3616325128430824
ROC train: 0.903002	val: 0.589054	test: 0.627961
PRC train: 0.867630	val: 0.656104	test: 0.636200

Epoch: 98
Loss: 0.3601456468491338
ROC train: 0.904559	val: 0.581952	test: 0.625706
PRC train: 0.869232	val: 0.655167	test: 0.640227

Epoch: 99
Loss: 0.35714482960403887
ROC train: 0.904893	val: 0.578127	test: 0.616374
PRC train: 0.867545	val: 0.653363	test: 0.640109

Epoch: 100
Loss: 0.3567705404242125
ROC train: 0.904216	val: 0.585926	test: 0.610420
PRC train: 0.866426	val: 0.658062	test: 0.635383

Epoch: 101
Loss: 0.35922281652189614
ROC train: 0.906569	val: 0.595612	test: 0.612613
PRC train: 0.869032	val: 0.660585	test: 0.635449

Epoch: 102
Loss: 0.35099631815690036
ROC train: 0.907486	val: 0.591087	test: 0.617148
PRC train: 0.870984	val: 0.656698	test: 0.637087

Epoch: 103
Loss: 0.35192803327835986
ROC train: 0.910318	val: 0.586200	test: 0.617302
PRC train: 0.872289	val: 0.655190	test: 0.636022

Epoch: 104
Loss: 0.3536258769678659
ROC train: 0.910741	val: 0.586650	test: 0.617021
PRC train: 0.874733	val: 0.657262	test: 0.638529

Epoch: 105
Loss: 0.348208159072341
ROC train: 0.910890	val: 0.583214	test: 0.614769
PRC train: 0.874590	val: 0.653850	test: 0.641536

Epoch: 106
Loss: 0.347864567355348
ROC train: 0.914263	val: 0.574683	test: 0.618027
PRC train: 0.877827	val: 0.650558	test: 0.644678

Epoch: 107
Loss: 0.3459769739331615
ROC train: 0.916574	val: 0.573029	test: 0.613232
PRC train: 0.881713	val: 0.648895	test: 0.639015

Epoch: 108
Loss: 0.34657455526881575
ROC train: 0.915760	val: 0.579123	test: 0.611399
PRC train: 0.880699	val: 0.651161	test: 0.639148

Epoch: 109
Loss: 0.3475466208881603
ROC train: 0.915104	val: 0.582878	test: 0.614055
PRC train: 0.879247	val: 0.654374	test: 0.638638

Epoch: 110
Loss: 0.34391352097077627
ROC train: 0.918309	val: 0.582638	test: 0.615404
PRC train: 0.881118	val: 0.653993	test: 0.634470

Epoch: 111
Loss: 0.3465996972776836
ROC train: 0.920130	val: 0.576499	test: 0.612215
PRC train: 0.883863	val: 0.652173	test: 0.632933

Epoch: 112
Loss: 0.3385660004193988
ROC train: 0.916395	val: 0.568399	test: 0.610332
PRC train: 0.880348	val: 0.650653	test: 0.636530

Epoch: 113
Loss: 0.3360319186018367
ROC train: 0.920455	val: 0.574107	test: 0.610321
PRC train: 0.885158	val: 0.652397	test: 0.636838

Epoch: 114
Loss: 0.3350230250719339
ROC train: 0.919293	val: 0.579736	test: 0.602018
PRC train: 0.883902	val: 0.649010	test: 0.630028

Epoch: 115
Loss: 0.34429893426780434
ROC train: 0.922164	val: 0.581881	test: 0.614597
PRC train: 0.886164	val: 0.648452	test: 0.639330

Epoch: 116
Loss: 0.3359665729844762
ROC train: 0.917327	val: 0.580188	test: 0.619564
PRC train: 0.883094	val: 0.650235	test: 0.641505

Epoch: 117
Loss: 0.3387321997681756
ROC train: 0.923012	val: 0.578426	test: 0.618422
PRC train: 0.889230	val: 0.648366	test: 0.638789

Epoch: 118
Loss: 0.33198368692045555
ROC train: 0.924836	val: 0.580696	test: 0.613993
PRC train: 0.889582	val: 0.649040	test: 0.636052

Epoch: 119
Loss: 0.3297001704298791
ROC train: 0.925341	val: 0.583141	test: 0.617107
PRC train: 0.890416	val: 0.646674	test: 0.638161

Epoch: 120
Loss: 0.33093824299024543
ROC train: 0.927455	val: 0.584987	test: 0.621248
PRC train: 0.892600	val: 0.649323	test: 0.642722

Epoch: 121
Loss: 0.3317182713231294
ROC train: 0.927534	val: 0.589744	test: 0.616729
PRC train: 0.892316	val: 0.653743	test: 0.639612

Epoch: 122
Loss: 0.32736355805797884
ROC train: 0.928865	val: 0.582529	test: 0.612777
PRC train: 0.892958	val: 0.650157	test: 0.639227

Epoch: 123
Loss: 0.3313167689220499
ROC train: 0.927816	val: 0.580781	test: 0.613833
PRC train: 0.892845	val: 0.650951	test: 0.639168

Epoch: 124
Loss: 0.32533407643080575
ROC train: 0.928870	val: 0.590820	test: 0.620173
PRC train: 0.893232	val: 0.655278	test: 0.637577

Epoch: 125
Loss: 0.3299603583773251
ROC train: 0.932076	val: 0.590000	test: 0.617237
PRC train: 0.897672	val: 0.654052	test: 0.636208

Epoch: 126
Loss: 0.3259482343885728
ROC train: 0.930796	val: 0.588371	test: 0.610791
PRC train: 0.898821	val: 0.651734	test: 0.633699

Epoch: 127
Loss: 0.32174565931028576
ROC train: 0.931870	val: 0.587297	test: 0.615691
PRC train: 0.899355	val: 0.654031	test: 0.635398

Epoch: 128
Loss: 0.3194544887885393
ROC train: 0.933791	val: 0.582052	test: 0.620351
PRC train: 0.901658	val: 0.653648	test: 0.640956

Epoch: 129
Loss: 0.32503177701180375
ROC train: 0.933580	val: 0.576119	test: 0.619730
PRC train: 0.900268	val: 0.652143	test: 0.644396

Epoch: 130
Loss: 0.32110048080006176
ROC train: 0.934143	val: 0.577966	test: 0.610859
PRC train: 0.901830	val: 0.652134	test: 0.633769

Epoch: 131
Loss: 0.31540116683074815
ROC train: 0.934246	val: 0.584355	test: 0.611068
PRC train: 0.902861	val: 0.654349	test: 0.636451

Epoch: 132
Loss: 0.3128296219184452
ROC train: 0.934952	val: 0.587463	test: 0.612697
PRC train: 0.902860	val: 0.653201	test: 0.638760

Epoch: 133
Loss: 0.3095964295617508
ROC train: 0.934591	val: 0.587884	test: 0.615191
PRC train: 0.902538	val: 0.651761	test: 0.638412

Epoch: 134
Loss: 0.31709787562943625
ROC train: 0.935796	val: 0.577868	test: 0.610606
PRC train: 0.903803	val: 0.648118	test: 0.637943

Epoch: 135
Loss: 0.31412855244176224
ROC train: 0.936666	val: 0.576581	test: 0.613721
PRC train: 0.907290	val: 0.649343	test: 0.641805

Epoch: 136
Loss: 0.3121448979060527
ROC train: 0.937308	val: 0.583217	test: 0.615612
PRC train: 0.910238	val: 0.649948	test: 0.640862

Early stopping
Best (ROC):	 train: 0.906569	val: 0.595612	test: 0.612613
Best (PRC):	 train: 0.869032	val: 0.660585	test: 0.635449

PRC train: 0.848003	val: 0.618733	test: 0.625059

Epoch: 95
Loss: 0.3648041778097192
ROC train: 0.890950	val: 0.544098	test: 0.588446
PRC train: 0.849915	val: 0.621219	test: 0.624306

Epoch: 96
Loss: 0.36359648133734923
ROC train: 0.894076	val: 0.543403	test: 0.587562
PRC train: 0.853793	val: 0.618677	test: 0.622793

Epoch: 97
Loss: 0.36503011907233435
ROC train: 0.894518	val: 0.537612	test: 0.585127
PRC train: 0.853407	val: 0.614578	test: 0.624161

Epoch: 98
Loss: 0.35539061886755846
ROC train: 0.894107	val: 0.538988	test: 0.586976
PRC train: 0.852713	val: 0.615059	test: 0.625924

Epoch: 99
Loss: 0.36199787900626357
ROC train: 0.894541	val: 0.543675	test: 0.587734
PRC train: 0.852569	val: 0.617763	test: 0.626119

Epoch: 100
Loss: 0.3709400723710355
ROC train: 0.897220	val: 0.547767	test: 0.585817
PRC train: 0.854274	val: 0.619102	test: 0.626349

Epoch: 101
Loss: 0.3598713845842706
ROC train: 0.899803	val: 0.545528	test: 0.581103
PRC train: 0.857879	val: 0.615768	test: 0.622845

Epoch: 102
Loss: 0.36340767233458904
ROC train: 0.900520	val: 0.541258	test: 0.582472
PRC train: 0.860604	val: 0.615493	test: 0.626619

Epoch: 103
Loss: 0.3585806356303049
ROC train: 0.900283	val: 0.541598	test: 0.584260
PRC train: 0.859131	val: 0.618456	test: 0.630431

Epoch: 104
Loss: 0.3593506348918034
ROC train: 0.901602	val: 0.546934	test: 0.583653
PRC train: 0.858275	val: 0.622994	test: 0.628781

Epoch: 105
Loss: 0.3576512617918486
ROC train: 0.902307	val: 0.556752	test: 0.594252
PRC train: 0.860816	val: 0.629168	test: 0.631279

Epoch: 106
Loss: 0.35811395927912404
ROC train: 0.899764	val: 0.556585	test: 0.598285
PRC train: 0.857571	val: 0.630817	test: 0.633868

Epoch: 107
Loss: 0.36101038382070183
ROC train: 0.902286	val: 0.554453	test: 0.596296
PRC train: 0.862079	val: 0.629210	test: 0.632301

Epoch: 108
Loss: 0.35340694452968935
ROC train: 0.901439	val: 0.555443	test: 0.592400
PRC train: 0.860313	val: 0.628513	test: 0.628084

Epoch: 109
Loss: 0.35915244894858334
ROC train: 0.905373	val: 0.559003	test: 0.589473
PRC train: 0.864164	val: 0.629912	test: 0.626576

Epoch: 110
Loss: 0.3513543602343609
ROC train: 0.907949	val: 0.558453	test: 0.590927
PRC train: 0.867484	val: 0.629872	test: 0.630165

Epoch: 111
Loss: 0.35208142719421376
ROC train: 0.908823	val: 0.558930	test: 0.597034
PRC train: 0.869266	val: 0.630958	test: 0.636922

Epoch: 112
Loss: 0.35339366589670507
ROC train: 0.909063	val: 0.563176	test: 0.599911
PRC train: 0.870752	val: 0.633093	test: 0.635744

Epoch: 113
Loss: 0.3434836246345347
ROC train: 0.910366	val: 0.564226	test: 0.595714
PRC train: 0.871622	val: 0.633415	test: 0.631722

Epoch: 114
Loss: 0.3510118458346501
ROC train: 0.910703	val: 0.556947	test: 0.592423
PRC train: 0.871967	val: 0.628489	test: 0.627993

Epoch: 115
Loss: 0.3454983104114351
ROC train: 0.909928	val: 0.552230	test: 0.589479
PRC train: 0.870455	val: 0.624506	test: 0.628347

Epoch: 116
Loss: 0.34684919291556565
ROC train: 0.904760	val: 0.552160	test: 0.588258
PRC train: 0.864323	val: 0.625362	test: 0.626258

Epoch: 117
Loss: 0.3435267259924088
ROC train: 0.908074	val: 0.556116	test: 0.592178
PRC train: 0.867701	val: 0.627168	test: 0.628549

Epoch: 118
Loss: 0.34022654185320933
ROC train: 0.911115	val: 0.558348	test: 0.597247
PRC train: 0.871792	val: 0.629047	test: 0.630577

Epoch: 119
Loss: 0.34287662549588355
ROC train: 0.914100	val: 0.558438	test: 0.601989
PRC train: 0.873129	val: 0.627115	test: 0.633654

Epoch: 120
Loss: 0.3392786849649555
ROC train: 0.916013	val: 0.560064	test: 0.605695
PRC train: 0.877736	val: 0.627098	test: 0.636739

Epoch: 121
Loss: 0.34248583859669873
ROC train: 0.916931	val: 0.560218	test: 0.607764
PRC train: 0.879977	val: 0.626913	test: 0.636924

Epoch: 122
Loss: 0.3319246985449341
ROC train: 0.919054	val: 0.563401	test: 0.605926
PRC train: 0.883254	val: 0.629091	test: 0.638221

Epoch: 123
Loss: 0.3352142631902243
ROC train: 0.919651	val: 0.561285	test: 0.602278
PRC train: 0.881233	val: 0.628189	test: 0.637685

Epoch: 124
Loss: 0.33251573928165906
ROC train: 0.919385	val: 0.555900	test: 0.600759
PRC train: 0.880112	val: 0.626586	test: 0.634666

Epoch: 125
Loss: 0.3364729253432065
ROC train: 0.919100	val: 0.557434	test: 0.600871
PRC train: 0.881184	val: 0.627077	test: 0.632430

Epoch: 126
Loss: 0.3364193250899753
ROC train: 0.922285	val: 0.559001	test: 0.599370
PRC train: 0.884917	val: 0.626960	test: 0.630608

Epoch: 127
Loss: 0.33392642066947675
ROC train: 0.920868	val: 0.553601	test: 0.599865
PRC train: 0.886773	val: 0.623248	test: 0.632226

Epoch: 128
Loss: 0.3355973459407655
ROC train: 0.917967	val: 0.548957	test: 0.603398
PRC train: 0.882957	val: 0.621199	test: 0.636217

Epoch: 129
Loss: 0.3388053631392459
ROC train: 0.916821	val: 0.550817	test: 0.601605
PRC train: 0.877149	val: 0.623171	test: 0.633337

Epoch: 130
Loss: 0.3364009801212699
ROC train: 0.921730	val: 0.550420	test: 0.600979
PRC train: 0.882708	val: 0.625900	test: 0.634089

Epoch: 131
Loss: 0.3282271457687763
ROC train: 0.919555	val: 0.555062	test: 0.597668
PRC train: 0.878809	val: 0.629308	test: 0.634144

Epoch: 132
Loss: 0.33263910622635295
ROC train: 0.925083	val: 0.558707	test: 0.605032
PRC train: 0.886665	val: 0.629895	test: 0.637186

Epoch: 133
Loss: 0.32495491078183414
ROC train: 0.927672	val: 0.558315	test: 0.609204
PRC train: 0.892286	val: 0.629614	test: 0.639485

Epoch: 134
Loss: 0.3375476306782524
ROC train: 0.926711	val: 0.558089	test: 0.610936
PRC train: 0.890962	val: 0.628612	test: 0.641833

Epoch: 135
Loss: 0.33001556337196986
ROC train: 0.924641	val: 0.565777	test: 0.608758
PRC train: 0.887690	val: 0.632934	test: 0.636155

Epoch: 136
Loss: 0.3223435792259199
ROC train: 0.926698	val: 0.565774	test: 0.605363
PRC train: 0.889716	val: 0.631088	test: 0.632543

Epoch: 137
Loss: 0.3245246604118103
ROC train: 0.927875	val: 0.563546	test: 0.603827
PRC train: 0.893242	val: 0.630029	test: 0.633585

Epoch: 138
Loss: 0.31689587062673363
ROC train: 0.929743	val: 0.568243	test: 0.600666
PRC train: 0.896001	val: 0.631900	test: 0.635040

Epoch: 139
Loss: 0.3306178764894848
ROC train: 0.931085	val: 0.563064	test: 0.599321
PRC train: 0.896277	val: 0.630138	test: 0.638695

Epoch: 140
Loss: 0.3214741452241385
ROC train: 0.928667	val: 0.554859	test: 0.593728
PRC train: 0.891276	val: 0.627058	test: 0.636382

Epoch: 141
Loss: 0.3244146939197219
ROC train: 0.929721	val: 0.557859	test: 0.595208
PRC train: 0.892874	val: 0.626801	test: 0.636580

Epoch: 142
Loss: 0.31798142091848114
ROC train: 0.932381	val: 0.561099	test: 0.602042
PRC train: 0.896255	val: 0.626998	test: 0.638982

Epoch: 143
Loss: 0.31937849069472046
ROC train: 0.933916	val: 0.563430	test: 0.595716
PRC train: 0.897805	val: 0.629150	test: 0.635004

Epoch: 144
Loss: 0.3163710835503556
ROC train: 0.934943	val: 0.561971	test: 0.599859
PRC train: 0.902639	val: 0.630107	test: 0.633889

Epoch: 145
Loss: 0.31445379944880947
ROC train: 0.932764	val: 0.559962	test: 0.599809
PRC train: 0.900221	val: 0.629362	test: 0.634613

Epoch: 146
Loss: 0.3094900746115832
ROC train: 0.932674	val: 0.559566	test: 0.595382
PRC train: 0.900284	val: 0.629955	test: 0.634342

Epoch: 147
Loss: 0.3095616613198544
ROC train: 0.936402	val: 0.559382	test: 0.594585
PRC train: 0.903585	val: 0.629280	test: 0.636135

Epoch: 148
Loss: 0.32470013099455475
ROC train: 0.935754	val: 0.564177	test: 0.596471
PRC train: 0.904385	val: 0.630428	test: 0.636114

Epoch: 149
Loss: 0.314211862803352
ROC train: 0.936790	val: 0.562736	test: 0.606343
PRC train: 0.905290	val: 0.628811	test: 0.640084

Epoch: 150
Loss: 0.3108534984899952
ROC train: 0.938770	val: 0.562746	test: 0.611565
PRC train: 0.906417	val: 0.628813	test: 0.642845

Epoch: 151
Loss: 0.3056204231082227
ROC train: 0.939288	val: 0.562403	test: 0.610400
PRC train: 0.906381	val: 0.628686	test: 0.645389

Epoch: 152
Loss: 0.3166914079700192
ROC train: 0.939777	val: 0.563611	test: 0.608991
PRC train: 0.908962	val: 0.629028	test: 0.643588

Epoch: 153
Loss: 0.30991810764332095
ROC train: 0.937020	val: 0.563994	test: 0.605303
PRC train: 0.907275	val: 0.627867	test: 0.639697

Epoch: 154
Loss: 0.3035484275913338
ROC train: 0.939311	val: 0.562429	test: 0.600202
PRC train: 0.906922	val: 0.626075	test: 0.639164

Epoch: 155
Loss: 0.308695016021048
ROC train: 0.896295	val: 0.621399	test: 0.591879
PRC train: 0.857230	val: 0.665081	test: 0.628404

Epoch: 95
Loss: 0.3621399097738776
ROC train: 0.895905	val: 0.625808	test: 0.606043
PRC train: 0.857074	val: 0.668533	test: 0.635989

Epoch: 96
Loss: 0.36490706126854544
ROC train: 0.900650	val: 0.639853	test: 0.594156
PRC train: 0.863642	val: 0.674719	test: 0.631827

Epoch: 97
Loss: 0.3681913869771518
ROC train: 0.902249	val: 0.639357	test: 0.592608
PRC train: 0.864536	val: 0.675249	test: 0.631222

Epoch: 98
Loss: 0.36050512360260484
ROC train: 0.900329	val: 0.632483	test: 0.591125
PRC train: 0.862596	val: 0.673136	test: 0.633296

Epoch: 99
Loss: 0.36218111995260344
ROC train: 0.902774	val: 0.633108	test: 0.596075
PRC train: 0.865764	val: 0.669129	test: 0.637661

Epoch: 100
Loss: 0.363488743355396
ROC train: 0.904303	val: 0.645442	test: 0.589957
PRC train: 0.865590	val: 0.675076	test: 0.635158

Epoch: 101
Loss: 0.3591706014633462
ROC train: 0.907098	val: 0.635832	test: 0.592488
PRC train: 0.871667	val: 0.669689	test: 0.636260

Epoch: 102
Loss: 0.3606022026529823
ROC train: 0.906351	val: 0.628352	test: 0.605969
PRC train: 0.870166	val: 0.663316	test: 0.643736

Epoch: 103
Loss: 0.35305974911955806
ROC train: 0.906912	val: 0.637765	test: 0.607988
PRC train: 0.872028	val: 0.671213	test: 0.643547

Epoch: 104
Loss: 0.3644565093942999
ROC train: 0.907071	val: 0.641313	test: 0.597046
PRC train: 0.869839	val: 0.675868	test: 0.637553

Epoch: 105
Loss: 0.35339990346035427
ROC train: 0.905766	val: 0.636081	test: 0.589621
PRC train: 0.867926	val: 0.674780	test: 0.632041

Epoch: 106
Loss: 0.3608951409731162
ROC train: 0.909169	val: 0.627407	test: 0.584324
PRC train: 0.875366	val: 0.666644	test: 0.631053

Epoch: 107
Loss: 0.35031989783232137
ROC train: 0.908218	val: 0.626205	test: 0.583167
PRC train: 0.872801	val: 0.668417	test: 0.628997

Epoch: 108
Loss: 0.3500594935675723
ROC train: 0.911379	val: 0.634865	test: 0.597964
PRC train: 0.875668	val: 0.673317	test: 0.634911

Epoch: 109
Loss: 0.35268796255051515
ROC train: 0.911070	val: 0.630461	test: 0.611565
PRC train: 0.875213	val: 0.669940	test: 0.638367

Epoch: 110
Loss: 0.3500211818785624
ROC train: 0.909995	val: 0.636451	test: 0.584694
PRC train: 0.872243	val: 0.676107	test: 0.625961

Epoch: 111
Loss: 0.35198870135579113
ROC train: 0.912178	val: 0.644728	test: 0.591261
PRC train: 0.876423	val: 0.675358	test: 0.631948

Epoch: 112
Loss: 0.34915063451572076
ROC train: 0.915076	val: 0.643589	test: 0.604456
PRC train: 0.880813	val: 0.675957	test: 0.641678

Epoch: 113
Loss: 0.34695201531510617
ROC train: 0.915699	val: 0.637794	test: 0.596540
PRC train: 0.882177	val: 0.673243	test: 0.639084

Epoch: 114
Loss: 0.3405515102610158
ROC train: 0.914468	val: 0.631152	test: 0.601180
PRC train: 0.879963	val: 0.666176	test: 0.639148

Epoch: 115
Loss: 0.3437395633110391
ROC train: 0.917400	val: 0.631962	test: 0.609579
PRC train: 0.882818	val: 0.665328	test: 0.642402

Epoch: 116
Loss: 0.34507019954102275
ROC train: 0.918759	val: 0.639646	test: 0.596978
PRC train: 0.884858	val: 0.672414	test: 0.633108

Epoch: 117
Loss: 0.3428504925966076
ROC train: 0.917161	val: 0.632456	test: 0.587962
PRC train: 0.883778	val: 0.671240	test: 0.629214

Epoch: 118
Loss: 0.3425574549226268
ROC train: 0.920537	val: 0.616793	test: 0.598045
PRC train: 0.890072	val: 0.658658	test: 0.638108

Epoch: 119
Loss: 0.3457832705724916
ROC train: 0.920039	val: 0.619392	test: 0.602747
PRC train: 0.889792	val: 0.657187	test: 0.641581

Epoch: 120
Loss: 0.3383359726481525
ROC train: 0.921086	val: 0.632449	test: 0.604200
PRC train: 0.890219	val: 0.663165	test: 0.636736

Epoch: 121
Loss: 0.34263748306408576
ROC train: 0.921834	val: 0.639046	test: 0.599570
PRC train: 0.889476	val: 0.669254	test: 0.634424

Epoch: 122
Loss: 0.3429447355880464
ROC train: 0.921885	val: 0.622370	test: 0.594874
PRC train: 0.889620	val: 0.664405	test: 0.630478

Epoch: 123
Loss: 0.3391839756824059
ROC train: 0.923275	val: 0.623763	test: 0.595467
PRC train: 0.890380	val: 0.667458	test: 0.633901

Epoch: 124
Loss: 0.33347842690064255
ROC train: 0.924436	val: 0.629116	test: 0.592457
PRC train: 0.891677	val: 0.667139	test: 0.632496

Epoch: 125
Loss: 0.3317046488106651
ROC train: 0.926658	val: 0.625259	test: 0.596222
PRC train: 0.894199	val: 0.663743	test: 0.632006

Epoch: 126
Loss: 0.34092762113875963
ROC train: 0.925815	val: 0.625338	test: 0.601072
PRC train: 0.895044	val: 0.662201	test: 0.633906

Epoch: 127
Loss: 0.32859690991577206
ROC train: 0.926831	val: 0.627951	test: 0.600487
PRC train: 0.897779	val: 0.661581	test: 0.637424

Epoch: 128
Loss: 0.33284629622277107
ROC train: 0.927887	val: 0.630491	test: 0.587122
PRC train: 0.899527	val: 0.663411	test: 0.632863

Epoch: 129
Loss: 0.3299755638869618
ROC train: 0.928314	val: 0.630169	test: 0.590646
PRC train: 0.896745	val: 0.660654	test: 0.637034

Epoch: 130
Loss: 0.33106645312133887
ROC train: 0.927565	val: 0.629820	test: 0.588002
PRC train: 0.896251	val: 0.664590	test: 0.633728

Epoch: 131
Loss: 0.3320069853638755
ROC train: 0.928188	val: 0.628744	test: 0.584552
PRC train: 0.897818	val: 0.662166	test: 0.625089

Epoch: 132
Loss: 0.33094561368447684
ROC train: 0.930214	val: 0.637440	test: 0.585227
PRC train: 0.902314	val: 0.665009	test: 0.626554

Epoch: 133
Loss: 0.3261208858048678
ROC train: 0.931705	val: 0.631820	test: 0.598312
PRC train: 0.904910	val: 0.661328	test: 0.636447

Epoch: 134
Loss: 0.3266206620568446
ROC train: 0.931211	val: 0.626335	test: 0.590213
PRC train: 0.903504	val: 0.657878	test: 0.635731

Epoch: 135
Loss: 0.3225199986226802
ROC train: 0.933019	val: 0.624660	test: 0.590684
PRC train: 0.905782	val: 0.659296	test: 0.630190

Early stopping
Best (ROC):	 train: 0.904303	val: 0.645442	test: 0.589957
Best (PRC):	 train: 0.865590	val: 0.675076	test: 0.635158

ROC train: 0.902505	val: 0.576248	test: 0.595748
PRC train: 0.862249	val: 0.645799	test: 0.621026

Epoch: 95
Loss: 0.35673407479461827
ROC train: 0.904124	val: 0.571896	test: 0.600609
PRC train: 0.864679	val: 0.646725	test: 0.627556

Epoch: 96
Loss: 0.35652256312812924
ROC train: 0.901370	val: 0.574258	test: 0.607121
PRC train: 0.859808	val: 0.647649	test: 0.630801

Epoch: 97
Loss: 0.35651045506355084
ROC train: 0.904728	val: 0.582349	test: 0.609379
PRC train: 0.865132	val: 0.649565	test: 0.632871

Epoch: 98
Loss: 0.3507871111593007
ROC train: 0.906368	val: 0.578929	test: 0.601605
PRC train: 0.867241	val: 0.648305	test: 0.628265

Epoch: 99
Loss: 0.3517283568011605
ROC train: 0.906335	val: 0.572046	test: 0.594231
PRC train: 0.867762	val: 0.643876	test: 0.626722

Epoch: 100
Loss: 0.35578081963781727
ROC train: 0.904630	val: 0.573751	test: 0.587640
PRC train: 0.864149	val: 0.644972	test: 0.621520

Epoch: 101
Loss: 0.34909350841895403
ROC train: 0.906585	val: 0.577202	test: 0.596693
PRC train: 0.866795	val: 0.645069	test: 0.621705

Epoch: 102
Loss: 0.3509683167723564
ROC train: 0.912320	val: 0.575741	test: 0.602604
PRC train: 0.875086	val: 0.642154	test: 0.626972

Epoch: 103
Loss: 0.35032030514113266
ROC train: 0.910726	val: 0.570484	test: 0.595646
PRC train: 0.874332	val: 0.639116	test: 0.623931

Epoch: 104
Loss: 0.35133822278363525
ROC train: 0.911755	val: 0.577685	test: 0.601701
PRC train: 0.873076	val: 0.647397	test: 0.628945

Epoch: 105
Loss: 0.3397685663490242
ROC train: 0.913750	val: 0.586259	test: 0.601121
PRC train: 0.875332	val: 0.651538	test: 0.626848

Epoch: 106
Loss: 0.34190052712185
ROC train: 0.914442	val: 0.587070	test: 0.603264
PRC train: 0.874449	val: 0.650872	test: 0.626291

Epoch: 107
Loss: 0.3462787085606668
ROC train: 0.915461	val: 0.582773	test: 0.597339
PRC train: 0.876512	val: 0.649700	test: 0.624824

Epoch: 108
Loss: 0.344208559000049
ROC train: 0.914686	val: 0.580935	test: 0.598711
PRC train: 0.878594	val: 0.645792	test: 0.622359

Epoch: 109
Loss: 0.3460491740765577
ROC train: 0.916993	val: 0.585056	test: 0.606655
PRC train: 0.882647	val: 0.648049	test: 0.628819

Epoch: 110
Loss: 0.3395611750602479
ROC train: 0.919234	val: 0.581305	test: 0.609001
PRC train: 0.883515	val: 0.649244	test: 0.633724

Epoch: 111
Loss: 0.3375445130984066
ROC train: 0.918898	val: 0.579392	test: 0.599318
PRC train: 0.882791	val: 0.648292	test: 0.627233

Epoch: 112
Loss: 0.3424418759820761
ROC train: 0.919441	val: 0.578250	test: 0.591454
PRC train: 0.883044	val: 0.649182	test: 0.622763

Epoch: 113
Loss: 0.337971331870475
ROC train: 0.921819	val: 0.580263	test: 0.592602
PRC train: 0.888200	val: 0.650308	test: 0.624606

Epoch: 114
Loss: 0.3303956127768317
ROC train: 0.921512	val: 0.582635	test: 0.603517
PRC train: 0.889672	val: 0.646414	test: 0.627752

Epoch: 115
Loss: 0.33578891248545634
ROC train: 0.922999	val: 0.582410	test: 0.609949
PRC train: 0.891304	val: 0.653310	test: 0.632327

Epoch: 116
Loss: 0.3333301702548616
ROC train: 0.920162	val: 0.585732	test: 0.597818
PRC train: 0.887946	val: 0.657855	test: 0.626575

Epoch: 117
Loss: 0.33540627634918907
ROC train: 0.920737	val: 0.583053	test: 0.587423
PRC train: 0.885851	val: 0.652203	test: 0.620303

Epoch: 118
Loss: 0.3368054818091587
ROC train: 0.923144	val: 0.586512	test: 0.593865
PRC train: 0.890193	val: 0.654978	test: 0.623250

Epoch: 119
Loss: 0.33161619122634767
ROC train: 0.924164	val: 0.591681	test: 0.598805
PRC train: 0.892864	val: 0.653412	test: 0.624865

Epoch: 120
Loss: 0.3321728027441462
ROC train: 0.927750	val: 0.594276	test: 0.603139
PRC train: 0.896740	val: 0.656125	test: 0.630375

Epoch: 121
Loss: 0.32798776618503056
ROC train: 0.928507	val: 0.589389	test: 0.598742
PRC train: 0.898541	val: 0.660675	test: 0.630476

Epoch: 122
Loss: 0.32767195978074354
ROC train: 0.928089	val: 0.584164	test: 0.595745
PRC train: 0.898823	val: 0.656896	test: 0.626683

Epoch: 123
Loss: 0.3308683664333022
ROC train: 0.928713	val: 0.582436	test: 0.595886
PRC train: 0.899636	val: 0.649222	test: 0.626799

Epoch: 124
Loss: 0.32424734280422424
ROC train: 0.929098	val: 0.581385	test: 0.592576
PRC train: 0.898140	val: 0.650828	test: 0.626708

Epoch: 125
Loss: 0.32054076511385066
ROC train: 0.931457	val: 0.585370	test: 0.600561
PRC train: 0.900954	val: 0.652476	test: 0.629631

Epoch: 126
Loss: 0.3222208644078895
ROC train: 0.931698	val: 0.587517	test: 0.606006
PRC train: 0.901446	val: 0.653122	test: 0.629845

Epoch: 127
Loss: 0.3190871982385061
ROC train: 0.931685	val: 0.586447	test: 0.608097
PRC train: 0.900856	val: 0.652626	test: 0.633182

Epoch: 128
Loss: 0.3196986583122151
ROC train: 0.933306	val: 0.587068	test: 0.610132
PRC train: 0.903622	val: 0.653229	test: 0.631536

Epoch: 129
Loss: 0.32286401173635015
ROC train: 0.934532	val: 0.582276	test: 0.603397
PRC train: 0.905643	val: 0.647707	test: 0.627165

Epoch: 130
Loss: 0.31841292237637486
ROC train: 0.934802	val: 0.580237	test: 0.599587
PRC train: 0.906499	val: 0.647835	test: 0.625168

Epoch: 131
Loss: 0.32460908248119097
ROC train: 0.934749	val: 0.580171	test: 0.600232
PRC train: 0.905533	val: 0.649954	test: 0.625050

Epoch: 132
Loss: 0.3150019964679788
ROC train: 0.936315	val: 0.578887	test: 0.596694
PRC train: 0.908248	val: 0.647005	test: 0.625662

Epoch: 133
Loss: 0.3182607306805584
ROC train: 0.935909	val: 0.582518	test: 0.590358
PRC train: 0.908097	val: 0.645800	test: 0.619457

Epoch: 134
Loss: 0.3142208638486345
ROC train: 0.937481	val: 0.590709	test: 0.603105
PRC train: 0.910524	val: 0.655372	test: 0.627699

Epoch: 135
Loss: 0.31274552956173285
ROC train: 0.937795	val: 0.586529	test: 0.596532
PRC train: 0.909073	val: 0.653199	test: 0.627304

Epoch: 136
Loss: 0.3210604794168044
ROC train: 0.940076	val: 0.580705	test: 0.597979
PRC train: 0.910731	val: 0.651272	test: 0.629326

Epoch: 137
Loss: 0.3031306496503151
ROC train: 0.937892	val: 0.578492	test: 0.595608
PRC train: 0.908057	val: 0.647180	test: 0.625304

Epoch: 138
Loss: 0.3144150902943714
ROC train: 0.939788	val: 0.583311	test: 0.598141
PRC train: 0.910166	val: 0.652265	test: 0.625512

Epoch: 139
Loss: 0.30866291684567293
ROC train: 0.941556	val: 0.587681	test: 0.599689
PRC train: 0.914732	val: 0.655112	test: 0.626829

Epoch: 140
Loss: 0.3065781051453836
ROC train: 0.943154	val: 0.590578	test: 0.598995
PRC train: 0.916593	val: 0.654201	test: 0.626631

Epoch: 141
Loss: 0.3061915504711267
ROC train: 0.943395	val: 0.587756	test: 0.597806
PRC train: 0.916796	val: 0.652096	test: 0.626071

Epoch: 142
Loss: 0.30812377487049347
ROC train: 0.941917	val: 0.582535	test: 0.599915
PRC train: 0.913964	val: 0.650071	test: 0.627559

Epoch: 143
Loss: 0.3089602356261174
ROC train: 0.942867	val: 0.584744	test: 0.600178
PRC train: 0.916669	val: 0.653199	test: 0.628058

Epoch: 144
Loss: 0.30686682796990405
ROC train: 0.943820	val: 0.587611	test: 0.598721
PRC train: 0.917226	val: 0.651880	test: 0.626423

Epoch: 145
Loss: 0.3033494875821016
ROC train: 0.945114	val: 0.586529	test: 0.598572
PRC train: 0.920768	val: 0.652728	test: 0.626960

Epoch: 146
Loss: 0.30450139580860447
ROC train: 0.945050	val: 0.591008	test: 0.604304
PRC train: 0.919760	val: 0.653825	test: 0.630284

Epoch: 147
Loss: 0.3066838488772937
ROC train: 0.945886	val: 0.593735	test: 0.606281
PRC train: 0.919585	val: 0.657195	test: 0.631270

Epoch: 148
Loss: 0.30727662486794066
ROC train: 0.946607	val: 0.587062	test: 0.601711
PRC train: 0.919410	val: 0.654823	test: 0.631687

Epoch: 149
Loss: 0.2983947181791462
ROC train: 0.946272	val: 0.589701	test: 0.596505
PRC train: 0.920988	val: 0.653946	test: 0.629143

Epoch: 150
Loss: 0.29865778556935507
ROC train: 0.948504	val: 0.589279	test: 0.594917
PRC train: 0.923703	val: 0.651170	test: 0.627379

Epoch: 151
Loss: 0.30237009520787805
ROC train: 0.947288	val: 0.586334	test: 0.597747
PRC train: 0.922906	val: 0.649357	test: 0.627338

Epoch: 152
Loss: 0.3036457767101267
ROC train: 0.950031	val: 0.584186	test: 0.600433
PRC train: 0.926606	val: 0.648326	test: 0.629279

Epoch: 153
Loss: 0.2910524530192047
ROC train: 0.949430	val: 0.587058	test: 0.599664
PRC train: 0.926102	val: 0.649867	test: 0.628617

Epoch: 154
Loss: 0.29201098100445927
ROC train: 0.948519	val: 0.591518	test: 0.602526
PRC train: 0.927084	val: 0.651876	test: 0.627787

Epoch: 155
Loss: 0.2945616293725761
ROC train: 0.949613	val: 0.591459	test: 0.601773
PRC train: 0.926654	val: 0.651484	test: 0.628860

Early stopping
Best (ROC):	 train: 0.927750	val: 0.594276	test: 0.603139
Best (PRC):	 train: 0.896740	val: 0.656125	test: 0.630375
All runs completed.

ROC train: 0.896589	val: 0.621254	test: 0.590941
PRC train: 0.859047	val: 0.669624	test: 0.624696

Epoch: 95
Loss: 0.36402684490106607
ROC train: 0.896005	val: 0.619475	test: 0.589130
PRC train: 0.858397	val: 0.666522	test: 0.626829

Epoch: 96
Loss: 0.3560364511195745
ROC train: 0.900674	val: 0.622698	test: 0.585362
PRC train: 0.861529	val: 0.665342	test: 0.624293

Epoch: 97
Loss: 0.35855073758876027
ROC train: 0.902560	val: 0.633409	test: 0.577118
PRC train: 0.862414	val: 0.667560	test: 0.619003

Epoch: 98
Loss: 0.35963753797323533
ROC train: 0.904837	val: 0.635931	test: 0.583637
PRC train: 0.864286	val: 0.672487	test: 0.621386

Epoch: 99
Loss: 0.3584523051806155
ROC train: 0.903282	val: 0.621852	test: 0.581167
PRC train: 0.862325	val: 0.669374	test: 0.621983

Epoch: 100
Loss: 0.3617218246107788
ROC train: 0.906144	val: 0.619966	test: 0.575643
PRC train: 0.867318	val: 0.665489	test: 0.619356

Epoch: 101
Loss: 0.3542155088807065
ROC train: 0.905367	val: 0.621736	test: 0.588178
PRC train: 0.867488	val: 0.664677	test: 0.625170

Epoch: 102
Loss: 0.36035398572875676
ROC train: 0.903092	val: 0.627896	test: 0.591219
PRC train: 0.867034	val: 0.668744	test: 0.628620

Epoch: 103
Loss: 0.3555421655981982
ROC train: 0.907117	val: 0.633230	test: 0.585684
PRC train: 0.871381	val: 0.673221	test: 0.625339

Epoch: 104
Loss: 0.3554186698151903
ROC train: 0.909209	val: 0.635111	test: 0.584301
PRC train: 0.872327	val: 0.672815	test: 0.626129

Epoch: 105
Loss: 0.3552161914104833
ROC train: 0.909400	val: 0.633266	test: 0.585309
PRC train: 0.871815	val: 0.669827	test: 0.624940

Epoch: 106
Loss: 0.35301486659360437
ROC train: 0.907404	val: 0.629281	test: 0.599102
PRC train: 0.872477	val: 0.668715	test: 0.631634

Epoch: 107
Loss: 0.3503399064750721
ROC train: 0.910397	val: 0.632748	test: 0.589226
PRC train: 0.875602	val: 0.670501	test: 0.628878

Epoch: 108
Loss: 0.3472740888498035
ROC train: 0.911738	val: 0.639622	test: 0.589833
PRC train: 0.875995	val: 0.673179	test: 0.625864

Epoch: 109
Loss: 0.3484212187177575
ROC train: 0.913191	val: 0.635291	test: 0.589451
PRC train: 0.876283	val: 0.669818	test: 0.627504

Epoch: 110
Loss: 0.3517112346791139
ROC train: 0.915923	val: 0.629799	test: 0.580319
PRC train: 0.879172	val: 0.664960	test: 0.625338

Epoch: 111
Loss: 0.3459001708086422
ROC train: 0.916488	val: 0.630840	test: 0.590058
PRC train: 0.881323	val: 0.667370	test: 0.627916

Epoch: 112
Loss: 0.3410641582086981
ROC train: 0.916066	val: 0.637568	test: 0.607537
PRC train: 0.881580	val: 0.671343	test: 0.632153

Epoch: 113
Loss: 0.34912579931484844
ROC train: 0.915346	val: 0.640218	test: 0.588772
PRC train: 0.880133	val: 0.678038	test: 0.626159

Epoch: 114
Loss: 0.33738317133082163
ROC train: 0.916934	val: 0.627052	test: 0.593512
PRC train: 0.881066	val: 0.669664	test: 0.627781

Epoch: 115
Loss: 0.3365564734653924
ROC train: 0.917911	val: 0.632586	test: 0.600762
PRC train: 0.882244	val: 0.669363	test: 0.634077

Epoch: 116
Loss: 0.3392258274911728
ROC train: 0.919609	val: 0.637898	test: 0.592252
PRC train: 0.884225	val: 0.668095	test: 0.629591

Epoch: 117
Loss: 0.34474061634700937
ROC train: 0.918137	val: 0.629333	test: 0.585190
PRC train: 0.885683	val: 0.672453	test: 0.624997

Epoch: 118
Loss: 0.33887836510467884
ROC train: 0.921899	val: 0.637604	test: 0.561590
PRC train: 0.886695	val: 0.675461	test: 0.617822

Epoch: 119
Loss: 0.3352297001160108
ROC train: 0.922913	val: 0.639795	test: 0.581878
PRC train: 0.886412	val: 0.675162	test: 0.625688

Epoch: 120
Loss: 0.3360511129592522
ROC train: 0.922221	val: 0.637812	test: 0.591846
PRC train: 0.886640	val: 0.675488	test: 0.629534

Epoch: 121
Loss: 0.3358504392315404
ROC train: 0.924030	val: 0.627941	test: 0.585895
PRC train: 0.889501	val: 0.673535	test: 0.629615

Epoch: 122
Loss: 0.33527648059606247
ROC train: 0.920322	val: 0.630346	test: 0.587676
PRC train: 0.885142	val: 0.672832	test: 0.628932

Epoch: 123
Loss: 0.331885661572563
ROC train: 0.925261	val: 0.637906	test: 0.581249
PRC train: 0.890592	val: 0.673191	test: 0.626800

Epoch: 124
Loss: 0.331457497797384
ROC train: 0.926636	val: 0.635277	test: 0.580360
PRC train: 0.893820	val: 0.670280	test: 0.627152

Epoch: 125
Loss: 0.33131325146974777
ROC train: 0.926355	val: 0.637716	test: 0.579415
PRC train: 0.893005	val: 0.675245	test: 0.630905

Epoch: 126
Loss: 0.33041558808310545
ROC train: 0.927006	val: 0.640794	test: 0.579148
PRC train: 0.891156	val: 0.671212	test: 0.629558

Epoch: 127
Loss: 0.3302399032240938
ROC train: 0.929450	val: 0.642350	test: 0.583161
PRC train: 0.894166	val: 0.670195	test: 0.629719

Epoch: 128
Loss: 0.322352936604695
ROC train: 0.929232	val: 0.640425	test: 0.589525
PRC train: 0.895545	val: 0.671124	test: 0.633750

Epoch: 129
Loss: 0.3290538891215918
ROC train: 0.929640	val: 0.633253	test: 0.585556
PRC train: 0.895764	val: 0.667503	test: 0.629829

Epoch: 130
Loss: 0.32655988194062985
ROC train: 0.930867	val: 0.630999	test: 0.580212
PRC train: 0.898405	val: 0.662742	test: 0.627055

Epoch: 131
Loss: 0.3301747367370513
ROC train: 0.932133	val: 0.629479	test: 0.587285
PRC train: 0.900329	val: 0.666009	test: 0.632206

Epoch: 132
Loss: 0.3214649936445463
ROC train: 0.931041	val: 0.622592	test: 0.584726
PRC train: 0.897723	val: 0.665268	test: 0.631292

Epoch: 133
Loss: 0.32023020330074403
ROC train: 0.933306	val: 0.630697	test: 0.581138
PRC train: 0.901456	val: 0.668315	test: 0.627552

Epoch: 134
Loss: 0.32964466993933933
ROC train: 0.934195	val: 0.631061	test: 0.578871
PRC train: 0.903528	val: 0.667047	test: 0.626611

Epoch: 135
Loss: 0.32143279416449344
ROC train: 0.930936	val: 0.633281	test: 0.589835
PRC train: 0.899674	val: 0.667804	test: 0.635198

Epoch: 136
Loss: 0.3174911009363638
ROC train: 0.931876	val: 0.630611	test: 0.590574
PRC train: 0.899756	val: 0.666580	test: 0.633075

Epoch: 137
Loss: 0.31878057908279256
ROC train: 0.934327	val: 0.629920	test: 0.590891
PRC train: 0.902092	val: 0.667192	test: 0.635323

Epoch: 138
Loss: 0.3192823312413903
ROC train: 0.936724	val: 0.628659	test: 0.576118
PRC train: 0.906341	val: 0.666895	test: 0.625099

Epoch: 139
Loss: 0.3183994713973092
ROC train: 0.935461	val: 0.632076	test: 0.583434
PRC train: 0.905207	val: 0.667775	test: 0.629152

Epoch: 140
Loss: 0.31535264055601175
ROC train: 0.933947	val: 0.628156	test: 0.592079
PRC train: 0.902545	val: 0.668492	test: 0.634719

Epoch: 141
Loss: 0.31311020797139055
ROC train: 0.934699	val: 0.624727	test: 0.584545
PRC train: 0.902866	val: 0.666602	test: 0.632561

Epoch: 142
Loss: 0.31168914417405197
ROC train: 0.936412	val: 0.625672	test: 0.579539
PRC train: 0.906140	val: 0.668275	test: 0.626203

Epoch: 143
Loss: 0.31449051177751575
ROC train: 0.939400	val: 0.634109	test: 0.589597
PRC train: 0.909235	val: 0.667726	test: 0.633116

Epoch: 144
Loss: 0.3093684043300373
ROC train: 0.939745	val: 0.637844	test: 0.601778
PRC train: 0.911016	val: 0.668667	test: 0.638360

Epoch: 145
Loss: 0.3124182539975694
ROC train: 0.940681	val: 0.642841	test: 0.589613
PRC train: 0.910849	val: 0.671367	test: 0.634215

Epoch: 146
Loss: 0.3086200137758307
ROC train: 0.940609	val: 0.642721	test: 0.581430
PRC train: 0.910129	val: 0.673029	test: 0.630765

Epoch: 147
Loss: 0.30834551113058517
ROC train: 0.939727	val: 0.643185	test: 0.577517
PRC train: 0.907746	val: 0.671986	test: 0.625178

Epoch: 148
Loss: 0.30446586926471486
ROC train: 0.941880	val: 0.638750	test: 0.582011
PRC train: 0.911427	val: 0.671400	test: 0.625812

Epoch: 149
Loss: 0.30773019428516096
ROC train: 0.942539	val: 0.626818	test: 0.584305
PRC train: 0.913105	val: 0.663447	test: 0.627840

Epoch: 150
Loss: 0.3072567326056249
ROC train: 0.943385	val: 0.630802	test: 0.590498
PRC train: 0.916191	val: 0.666032	test: 0.629689

Epoch: 151
Loss: 0.30344888279279997
ROC train: 0.944685	val: 0.631357	test: 0.580876
PRC train: 0.917471	val: 0.670025	test: 0.627172

Epoch: 152
Loss: 0.3083830149199367
ROC train: 0.945341	val: 0.618823	test: 0.586250
PRC train: 0.918065	val: 0.660373	test: 0.626621

Epoch: 153
Loss: 0.3007674359478754
ROC train: 0.945394	val: 0.620067	test: 0.594591
PRC train: 0.920616	val: 0.663394	test: 0.628862

Epoch: 154
Loss: 0.30029475263280275
ROC train: 0.945518	val: 0.627311	test: 0.584166
PRC train: 0.919897	val: 0.668036	test: 0.624702

Epoch: 155
Loss: 0.29903506067000507
ROC train: 0.945913	val: 0.628965	test: 0.584630
PRC train: 0.918591	val: 0.665842	test: 0.624745

Epoch: 156
Loss: 0.2980863544796145
ROC train: 0.947041	val: 0.631814	test: 0.589264
PRC train: 0.920662	val: 0.671662	test: 0.628666

Epoch: 157
Loss: 0.29957087508789015
ROC train: 0.946583	val: 0.632898	test: 0.595217
PRC train: 0.919780	val: 0.672435	test: 0.632599

Epoch: 158
Loss: 0.2973506881758207
ROC train: 0.948114	val: 0.631425	test: 0.601044
PRC train: 0.922029	val: 0.667704	test: 0.638564

Epoch: 159
Loss: 0.2992515900870301
ROC train: 0.946836	val: 0.631647	test: 0.595789
PRC train: 0.922581	val: 0.667702	test: 0.633329

Epoch: 160
Loss: 0.2985365779752396
ROC train: 0.948965	val: 0.622557	test: 0.596104
PRC train: 0.924175	val: 0.659188	test: 0.631197

Epoch: 161
Loss: 0.29869488590113347
ROC train: 0.950105	val: 0.627479	test: 0.596721
PRC train: 0.924646	val: 0.664649	test: 0.633967

Epoch: 162
Loss: 0.30125929302987425
ROC train: 0.950461	val: 0.633032	test: 0.595229
PRC train: 0.924723	val: 0.667929	test: 0.635730

Epoch: 163
Loss: 0.29215517295812515
ROC train: 0.949898	val: 0.630876	test: 0.594870
PRC train: 0.921882	val: 0.664104	test: 0.632494

Epoch: 164
Loss: 0.29055645234604166
ROC train: 0.949613	val: 0.632201	test: 0.597246
PRC train: 0.922790	val: 0.671575	test: 0.632684

Epoch: 165
Loss: 0.28900600473493476
ROC train: 0.951966	val: 0.630619	test: 0.600445
PRC train: 0.926961	val: 0.669973	test: 0.633592

Epoch: 166
Loss: 0.29279219374383203
ROC train: 0.952375	val: 0.631243	test: 0.587054
PRC train: 0.928299	val: 0.670691	test: 0.628693

Epoch: 167
Loss: 0.2883065582255536
ROC train: 0.952626	val: 0.633189	test: 0.581409
PRC train: 0.928190	val: 0.669506	test: 0.626751

Epoch: 168
Loss: 0.2872416622291807
ROC train: 0.952818	val: 0.624649	test: 0.588435
PRC train: 0.929486	val: 0.663613	test: 0.627817

Epoch: 169
Loss: 0.2855378517481687
ROC train: 0.951893	val: 0.622934	test: 0.593127
PRC train: 0.929658	val: 0.664253	test: 0.635772

Epoch: 170
Loss: 0.2883892051443026
ROC train: 0.952851	val: 0.626132	test: 0.597256
PRC train: 0.929261	val: 0.664833	test: 0.636648

Epoch: 171
Loss: 0.27989957184154024
ROC train: 0.954767	val: 0.623428	test: 0.593533
PRC train: 0.932791	val: 0.665083	test: 0.629390

Epoch: 172
Loss: 0.28850696387785213
ROC train: 0.954946	val: 0.623044	test: 0.590856
PRC train: 0.932042	val: 0.665100	test: 0.627868

Epoch: 173
Loss: 0.287938680072087
ROC train: 0.953839	val: 0.631724	test: 0.599473
PRC train: 0.928249	val: 0.665920	test: 0.633185

Epoch: 174
Loss: 0.28081435517623327
ROC train: 0.958100	val: 0.628437	test: 0.599351
PRC train: 0.936205	val: 0.667532	test: 0.633945

Epoch: 175
Loss: 0.2820109213400998
ROC train: 0.958420	val: 0.623703	test: 0.587931
PRC train: 0.936670	val: 0.664782	test: 0.628113

Epoch: 176
Loss: 0.28169851667576035
ROC train: 0.956750	val: 0.632039	test: 0.578962
PRC train: 0.934943	val: 0.668104	test: 0.625165

Epoch: 177
Loss: 0.2778003227698372
ROC train: 0.957100	val: 0.621988	test: 0.590741
PRC train: 0.936114	val: 0.665680	test: 0.628480

Epoch: 178
Loss: 0.2823761575880378
ROC train: 0.958201	val: 0.623772	test: 0.595504
PRC train: 0.936351	val: 0.664750	test: 0.632052

Epoch: 179
Loss: 0.27761175864001447
ROC train: 0.959164	val: 0.627246	test: 0.589356
PRC train: 0.937710	val: 0.664655	test: 0.630012

Epoch: 180
Loss: 0.2783075615367895
ROC train: 0.959457	val: 0.629857	test: 0.590518
PRC train: 0.938519	val: 0.667166	test: 0.628216

Epoch: 181
Loss: 0.27649773205173567
ROC train: 0.959813	val: 0.632671	test: 0.592615
PRC train: 0.939286	val: 0.667886	test: 0.627638

Epoch: 182
Loss: 0.2760162202093723
ROC train: 0.961073	val: 0.632647	test: 0.589654
PRC train: 0.938618	val: 0.665693	test: 0.627544

Early stopping
Best (ROC):	 train: 0.939727	val: 0.643185	test: 0.577517
Best (PRC):	 train: 0.907746	val: 0.671986	test: 0.625178
All runs completed.

ROC train: 0.940193	val: 0.562814	test: 0.597590
PRC train: 0.907697	val: 0.626509	test: 0.636103

Epoch: 156
Loss: 0.3051369479141477
ROC train: 0.941756	val: 0.562543	test: 0.598321
PRC train: 0.907356	val: 0.627122	test: 0.637179

Epoch: 157
Loss: 0.29943761651541695
ROC train: 0.941905	val: 0.562001	test: 0.595276
PRC train: 0.908513	val: 0.626796	test: 0.633520

Epoch: 158
Loss: 0.30445594365096396
ROC train: 0.941689	val: 0.560225	test: 0.592456
PRC train: 0.907930	val: 0.625810	test: 0.630170

Epoch: 159
Loss: 0.30218688637064384
ROC train: 0.942292	val: 0.557323	test: 0.595981
PRC train: 0.911142	val: 0.624452	test: 0.635318

Epoch: 160
Loss: 0.3048302105008568
ROC train: 0.942786	val: 0.556822	test: 0.597443
PRC train: 0.913638	val: 0.623320	test: 0.640978

Epoch: 161
Loss: 0.2974717386787597
ROC train: 0.942441	val: 0.553192	test: 0.595434
PRC train: 0.915326	val: 0.621166	test: 0.639753

Epoch: 162
Loss: 0.3037672095640832
ROC train: 0.944217	val: 0.557200	test: 0.599983
PRC train: 0.918316	val: 0.622669	test: 0.642382

Epoch: 163
Loss: 0.3000407671095973
ROC train: 0.944970	val: 0.559827	test: 0.605492
PRC train: 0.921829	val: 0.624640	test: 0.642760

Epoch: 164
Loss: 0.3002307470134598
ROC train: 0.947620	val: 0.562532	test: 0.606698
PRC train: 0.922814	val: 0.629596	test: 0.642229

Epoch: 165
Loss: 0.3102604149591641
ROC train: 0.949230	val: 0.561096	test: 0.602036
PRC train: 0.919932	val: 0.629260	test: 0.641643

Epoch: 166
Loss: 0.29157804343160565
ROC train: 0.947084	val: 0.559203	test: 0.598087
PRC train: 0.917738	val: 0.625559	test: 0.639426

Epoch: 167
Loss: 0.29617098249810747
ROC train: 0.947261	val: 0.561128	test: 0.599142
PRC train: 0.916929	val: 0.624749	test: 0.636995

Epoch: 168
Loss: 0.29958032396295203
ROC train: 0.946337	val: 0.561049	test: 0.600310
PRC train: 0.918015	val: 0.623868	test: 0.635751

Epoch: 169
Loss: 0.293354749566531
ROC train: 0.947163	val: 0.561084	test: 0.599873
PRC train: 0.917580	val: 0.623996	test: 0.638150

Epoch: 170
Loss: 0.29173747456032156
ROC train: 0.947715	val: 0.561409	test: 0.604951
PRC train: 0.922803	val: 0.623517	test: 0.640782

Epoch: 171
Loss: 0.286706502169658
ROC train: 0.949689	val: 0.566896	test: 0.606699
PRC train: 0.924642	val: 0.628391	test: 0.642230

Epoch: 172
Loss: 0.2925577108801584
ROC train: 0.950180	val: 0.571857	test: 0.605928
PRC train: 0.922743	val: 0.631591	test: 0.643610

Epoch: 173
Loss: 0.29376325510434725
ROC train: 0.950056	val: 0.569147	test: 0.607539
PRC train: 0.921857	val: 0.630732	test: 0.643583

Epoch: 174
Loss: 0.2863349527852719
ROC train: 0.951681	val: 0.562257	test: 0.601861
PRC train: 0.924908	val: 0.627744	test: 0.641064

Epoch: 175
Loss: 0.28445378491835405
ROC train: 0.952882	val: 0.558882	test: 0.596245
PRC train: 0.930360	val: 0.625529	test: 0.636951

Epoch: 176
Loss: 0.2936286648951357
ROC train: 0.953780	val: 0.560064	test: 0.595366
PRC train: 0.931117	val: 0.626435	test: 0.636972

Epoch: 177
Loss: 0.28753185380278873
ROC train: 0.953549	val: 0.566354	test: 0.601083
PRC train: 0.927037	val: 0.629688	test: 0.637696

Epoch: 178
Loss: 0.28290962286427696
ROC train: 0.952916	val: 0.566841	test: 0.607122
PRC train: 0.925408	val: 0.628526	test: 0.641189

Epoch: 179
Loss: 0.2816305600188517
ROC train: 0.953804	val: 0.567070	test: 0.604175
PRC train: 0.926189	val: 0.629163	test: 0.641545

Epoch: 180
Loss: 0.27995074056115465
ROC train: 0.955104	val: 0.566985	test: 0.598703
PRC train: 0.928030	val: 0.630268	test: 0.639403

Epoch: 181
Loss: 0.2783296759179625
ROC train: 0.954832	val: 0.567764	test: 0.593541
PRC train: 0.928286	val: 0.630002	test: 0.637170

Epoch: 182
Loss: 0.28222949001500913
ROC train: 0.955714	val: 0.565793	test: 0.600241
PRC train: 0.929043	val: 0.628172	test: 0.640763

Epoch: 183
Loss: 0.27654498918088205
ROC train: 0.954845	val: 0.562413	test: 0.599012
PRC train: 0.926929	val: 0.626508	test: 0.639226

Epoch: 184
Loss: 0.27944140255647293
ROC train: 0.956662	val: 0.560358	test: 0.598226
PRC train: 0.928989	val: 0.626054	test: 0.638903

Epoch: 185
Loss: 0.27148782412873607
ROC train: 0.957571	val: 0.558761	test: 0.599946
PRC train: 0.931057	val: 0.625299	test: 0.638147

Epoch: 186
Loss: 0.27579927088884354
ROC train: 0.958880	val: 0.561844	test: 0.603493
PRC train: 0.933680	val: 0.625873	test: 0.639952

Epoch: 187
Loss: 0.27877759671623226
ROC train: 0.959167	val: 0.570338	test: 0.601088
PRC train: 0.934307	val: 0.629881	test: 0.637616

Epoch: 188
Loss: 0.28078777326498283
ROC train: 0.959063	val: 0.571438	test: 0.597370
PRC train: 0.933924	val: 0.632806	test: 0.639182

Epoch: 189
Loss: 0.27285717612927984
ROC train: 0.959669	val: 0.568479	test: 0.597945
PRC train: 0.936511	val: 0.631722	test: 0.641481

Epoch: 190
Loss: 0.2661812412652652
ROC train: 0.958854	val: 0.569002	test: 0.595712
PRC train: 0.933913	val: 0.632382	test: 0.639431

Epoch: 191
Loss: 0.2739240330492651
ROC train: 0.955929	val: 0.568970	test: 0.590530
PRC train: 0.929535	val: 0.633887	test: 0.633693

Epoch: 192
Loss: 0.27115910713915004
ROC train: 0.956161	val: 0.571457	test: 0.589865
PRC train: 0.931542	val: 0.635567	test: 0.634135

Epoch: 193
Loss: 0.26744695462182255
ROC train: 0.959732	val: 0.570616	test: 0.597309
PRC train: 0.936151	val: 0.634338	test: 0.638966

Epoch: 194
Loss: 0.26416674781386346
ROC train: 0.959167	val: 0.566737	test: 0.601005
PRC train: 0.934212	val: 0.629672	test: 0.639372

Epoch: 195
Loss: 0.27433896048786865
ROC train: 0.961660	val: 0.568336	test: 0.604633
PRC train: 0.938743	val: 0.629655	test: 0.640093

Epoch: 196
Loss: 0.2734350870953387
ROC train: 0.962875	val: 0.568563	test: 0.604742
PRC train: 0.938522	val: 0.629933	test: 0.642007

Epoch: 197
Loss: 0.26400384326390963
ROC train: 0.960763	val: 0.571532	test: 0.596217
PRC train: 0.940269	val: 0.631264	test: 0.636258

Epoch: 198
Loss: 0.27890969361145
ROC train: 0.958478	val: 0.572164	test: 0.592280
PRC train: 0.936440	val: 0.633342	test: 0.635161

Epoch: 199
Loss: 0.26365011743261546
ROC train: 0.963993	val: 0.568032	test: 0.598501
PRC train: 0.942369	val: 0.634417	test: 0.638817

Epoch: 200
Loss: 0.2748299297503148
ROC train: 0.964387	val: 0.568696	test: 0.599072
PRC train: 0.943111	val: 0.634284	test: 0.638018

Epoch: 201
Loss: 0.2627482042784538
ROC train: 0.964285	val: 0.569449	test: 0.604000
PRC train: 0.943502	val: 0.634401	test: 0.638697

Epoch: 202
Loss: 0.27074518871760933
ROC train: 0.963298	val: 0.563549	test: 0.608210
PRC train: 0.943098	val: 0.628285	test: 0.643153

Epoch: 203
Loss: 0.26164074884368804
ROC train: 0.963702	val: 0.560264	test: 0.603682
PRC train: 0.943870	val: 0.625539	test: 0.643151

Epoch: 204
Loss: 0.26557002909289373
ROC train: 0.964277	val: 0.560149	test: 0.600231
PRC train: 0.944659	val: 0.625206	test: 0.640908

Epoch: 205
Loss: 0.27187674781920523
ROC train: 0.964759	val: 0.564924	test: 0.600318
PRC train: 0.943851	val: 0.626709	test: 0.640470

Epoch: 206
Loss: 0.26571457201139426
ROC train: 0.966360	val: 0.571061	test: 0.603337
PRC train: 0.939442	val: 0.632186	test: 0.641557

Epoch: 207
Loss: 0.2609875253564139
ROC train: 0.963866	val: 0.569932	test: 0.607876
PRC train: 0.938973	val: 0.632285	test: 0.645626

Epoch: 208
Loss: 0.2589841224234455
ROC train: 0.964890	val: 0.568702	test: 0.608657
PRC train: 0.944652	val: 0.631661	test: 0.644973

Epoch: 209
Loss: 0.2573224193116668
ROC train: 0.965663	val: 0.565011	test: 0.604783
PRC train: 0.945037	val: 0.629759	test: 0.639823

Epoch: 210
Loss: 0.2551538769277052
ROC train: 0.966508	val: 0.561233	test: 0.602419
PRC train: 0.944670	val: 0.629028	test: 0.634567

Epoch: 211
Loss: 0.2508935637404681
ROC train: 0.966524	val: 0.559170	test: 0.599156
PRC train: 0.945460	val: 0.627902	test: 0.631468

Epoch: 212
Loss: 0.26173799804018294
ROC train: 0.967744	val: 0.557946	test: 0.596244
PRC train: 0.950036	val: 0.625768	test: 0.633700

Epoch: 213
Loss: 0.25578449243233276
ROC train: 0.967711	val: 0.559978	test: 0.599946
PRC train: 0.948642	val: 0.626707	test: 0.634770

Epoch: 214
Loss: 0.25431908716825546
ROC train: 0.969313	val: 0.566085	test: 0.605291
PRC train: 0.949672	val: 0.630695	test: 0.638071

Epoch: 215
Loss: 0.25019976712352815
ROC train: 0.970463	val: 0.568970	test: 0.609409
PRC train: 0.952015	val: 0.633703	test: 0.640877

Epoch: 216
Loss: 0.253742780897365
ROC train: 0.971070	val: 0.567629	test: 0.609207
PRC train: 0.953890	val: 0.633585	test: 0.644395

Epoch: 217
Loss: 0.24963441273092948
ROC train: 0.969031	val: 0.565686	test: 0.606501
PRC train: 0.952258	val: 0.631211	test: 0.642878

Epoch: 218
Loss: 0.2432178702884804
ROC train: 0.970956	val: 0.567756	test: 0.602117
PRC train: 0.953135	val: 0.629780	test: 0.637130

Epoch: 219
Loss: 0.24548238455108795
ROC train: 0.971098	val: 0.566445	test: 0.599011
PRC train: 0.952568	val: 0.627318	test: 0.633654

Epoch: 220
Loss: 0.2513026979326617
ROC train: 0.970749	val: 0.563722	test: 0.596113
PRC train: 0.951498	val: 0.625112	test: 0.632704

Epoch: 221
Loss: 0.2460527589501059
ROC train: 0.970079	val: 0.561950	test: 0.596358
PRC train: 0.951929	val: 0.623783	test: 0.636176

Epoch: 222
Loss: 0.25053661484600004
ROC train: 0.969270	val: 0.566024	test: 0.598944
PRC train: 0.951213	val: 0.625957	test: 0.640031

Epoch: 223
Loss: 0.2490163022459773
ROC train: 0.970894	val: 0.568409	test: 0.604949
PRC train: 0.953308	val: 0.629318	test: 0.641253

Epoch: 224
Loss: 0.24374288739712013
ROC train: 0.972442	val: 0.563102	test: 0.603159
PRC train: 0.955136	val: 0.628869	test: 0.638112

Epoch: 225
Loss: 0.251883503972907
ROC train: 0.973326	val: 0.561526	test: 0.598833
PRC train: 0.955917	val: 0.628745	test: 0.634909

Epoch: 226
Loss: 0.2526116639500695
ROC train: 0.973179	val: 0.564544	test: 0.595336
PRC train: 0.955445	val: 0.630113	test: 0.636083

Epoch: 227
Loss: 0.23816246884452336
ROC train: 0.973018	val: 0.565137	test: 0.594998
PRC train: 0.954126	val: 0.630523	test: 0.636174

Epoch: 228
Loss: 0.24831869399140682
ROC train: 0.973102	val: 0.566507	test: 0.597090
PRC train: 0.953715	val: 0.630684	test: 0.635245

Epoch: 229
Loss: 0.23803984380470955
ROC train: 0.973619	val: 0.570693	test: 0.594503
PRC train: 0.955197	val: 0.632953	test: 0.632604

Epoch: 230
Loss: 0.24495848582574642
ROC train: 0.974404	val: 0.567325	test: 0.592564
PRC train: 0.958111	val: 0.630729	test: 0.632350

Epoch: 231
Loss: 0.23781312288179302
ROC train: 0.974390	val: 0.559545	test: 0.590022
PRC train: 0.958561	val: 0.625222	test: 0.632722

Epoch: 232
Loss: 0.23634923599960286
ROC train: 0.972266	val: 0.553861	test: 0.588270
PRC train: 0.955804	val: 0.621785	test: 0.633473

Epoch: 233
Loss: 0.2335120915111895
ROC train: 0.974810	val: 0.553168	test: 0.592841
PRC train: 0.959034	val: 0.620067	test: 0.632610

Early stopping
Best (ROC):	 train: 0.958478	val: 0.572164	test: 0.592280
Best (PRC):	 train: 0.936440	val: 0.633342	test: 0.635161
All runs completed.
