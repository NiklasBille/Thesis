>>> Starting run for dataset: hiv
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running RANDOM configs_static_noise_experiments/GraphCL/hiv/noise=0.0.yml on cuda:0
Running RANDOM configs_static_noise_experiments/GraphCL/hiv/noise=0.05.yml on cuda:1
Running RANDOM configs_static_noise_experiments/GraphCL/hiv/noise=0.1.yml on cuda:2
Running RANDOM configs_static_noise_experiments/GraphCL/hiv/noise=0.2.yml on cuda:3
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.1.yml --runseed 4 --device cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.2.yml --runseed 4 --device cuda:3
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.1.yml --runseed 5 --device cuda:2
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.2.yml --runseed 5 --device cuda:3
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.1.yml --runseed 6 --device cuda:2
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.2.yml --runseed 6 --device cuda:3
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.05.yml --runseed 4 --device cuda:1
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.0.yml --runseed 4 --device cuda:0
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.05.yml --runseed 5 --device cuda:1
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.0.yml --runseed 5 --device cuda:0
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.05.yml --runseed 6 --device cuda:1
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.0.yml --runseed 6 --device cuda:0
[11:29:03] WARNING: not removing hydrogen atom without neighbors
[11:29:03] WARNING: not removing hydrogen atom without neighbors
[11:29:04] WARNING: not removing hydrogen atom without neighbors
[11:29:04] WARNING: not removing hydrogen atom without neighbors
[11:29:04] WARNING: not removing hydrogen atom without neighbors
[11:29:04] WARNING: not removing hydrogen atom without neighbors
[11:29:06] WARNING: not removing hydrogen atom without neighbors
[11:29:06] WARNING: not removing hydrogen atom without neighbors
[11:29:06] WARNING: not removing hydrogen atom without neighbors
[11:29:06] WARNING: not removing hydrogen atom without neighbors
[11:29:07] WARNING: not removing hydrogen atom without neighbors
[11:29:07] WARNING: not removing hydrogen atom without neighbors
[11:29:08] WARNING: not removing hydrogen atom without neighbors
[11:29:08] WARNING: not removing hydrogen atom without neighbors
[11:29:08] WARNING: not removing hydrogen atom without neighbors
[11:29:08] WARNING: not removing hydrogen atom without neighbors
[11:29:08] WARNING: not removing hydrogen atom without neighbors
[11:29:08] WARNING: not removing hydrogen atom without neighbors
[11:29:12] WARNING: not removing hydrogen atom without neighbors
[11:29:12] WARNING: not removing hydrogen atom without neighbors
[11:29:12] WARNING: not removing hydrogen atom without neighbors
[11:29:12] WARNING: not removing hydrogen atom without neighbors
[11:29:13] WARNING: not removing hydrogen atom without neighbors
[11:29:13] WARNING: not removing hydrogen atom without neighbors
[11:29:20] WARNING: not removing hydrogen atom without neighbors
[11:29:20] WARNING: not removing hydrogen atom without neighbors
[11:29:20] WARNING: not removing hydrogen atom without neighbors
[11:29:20] WARNING: not removing hydrogen atom without neighbors
[11:29:21] WARNING: not removing hydrogen atom without neighbors
[11:29:21] WARNING: not removing hydrogen atom without neighbors
[11:29:22] WARNING: not removing hydrogen atom without neighbors
[11:29:22] WARNING: not removing hydrogen atom without neighbors
[11:29:23] WARNING: not removing hydrogen atom without neighbors
[11:29:23] WARNING: not removing hydrogen atom without neighbors
[11:29:23] WARNING: not removing hydrogen atom without neighbors
[11:29:23] WARNING: not removing hydrogen atom without neighbors
[11:29:26] WARNING: not removing hydrogen atom without neighbors
[11:29:26] WARNING: not removing hydrogen atom without neighbors
[11:29:26] WARNING: not removing hydrogen atom without neighbors
[11:29:26] WARNING: not removing hydrogen atom without neighbors
[11:29:27] WARNING: not removing hydrogen atom without neighbors
[11:29:27] WARNING: not removing hydrogen atom without neighbors
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.0.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/hiv/noise=0.0
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/hiv/noise=0.0/hiv_scaff_4_26-05_11-28-51  ]
[ Using Seed :  4  ]
[ Using device :  cuda:0  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.25557598095820705
ROC train: 0.759874	val: 0.732988	test: 0.636602
PRC train: 0.218501	val: 0.175144	test: 0.186240

Epoch: 2
Loss: 0.14073774354099988
ROC train: 0.774599	val: 0.751727	test: 0.715251
PRC train: 0.271809	val: 0.242886	test: 0.198677

Epoch: 3
Loss: 0.1353053849251217
ROC train: 0.803987	val: 0.778231	test: 0.727799
PRC train: 0.334931	val: 0.337886	test: 0.233529

Epoch: 4
Loss: 0.1310061244621855
ROC train: 0.808318	val: 0.758641	test: 0.742135
PRC train: 0.313894	val: 0.285819	test: 0.245293

Epoch: 5
Loss: 0.12958461296836693
ROC train: 0.818461	val: 0.768254	test: 0.743827
PRC train: 0.383441	val: 0.290364	test: 0.166550

Epoch: 6
Loss: 0.12741899283414654
ROC train: 0.826196	val: 0.758132	test: 0.699589
PRC train: 0.341897	val: 0.210096	test: 0.078858

Epoch: 7
Loss: 0.12381839677865547
ROC train: 0.839549	val: 0.746920	test: 0.721348
PRC train: 0.409463	val: 0.297782	test: 0.184458

Epoch: 8
Loss: 0.12274857334277751
ROC train: 0.845813	val: 0.783259	test: 0.733960
PRC train: 0.428962	val: 0.285709	test: 0.213227

Epoch: 9
Loss: 0.12008796906441847
ROC train: 0.850564	val: 0.773537	test: 0.741550
PRC train: 0.438966	val: 0.338622	test: 0.167826

Epoch: 10
Loss: 0.1188376402915932
ROC train: 0.845215	val: 0.782444	test: 0.763960
PRC train: 0.433975	val: 0.331094	test: 0.201102

Epoch: 11
Loss: 0.11964700014898143
ROC train: 0.859887	val: 0.783485	test: 0.734769
PRC train: 0.472582	val: 0.374206	test: 0.121958

Epoch: 12
Loss: 0.11497388080332052
ROC train: 0.853874	val: 0.770334	test: 0.719776
PRC train: 0.457986	val: 0.328750	test: 0.146023

Epoch: 13
Loss: 0.11560213540071555
ROC train: 0.872692	val: 0.782628	test: 0.737249
PRC train: 0.480444	val: 0.330400	test: 0.190704

Epoch: 14
Loss: 0.1130727684441683
ROC train: 0.878951	val: 0.770738	test: 0.745634
PRC train: 0.491096	val: 0.362914	test: 0.187311

Epoch: 15
Loss: 0.11353629707717718
ROC train: 0.878121	val: 0.764608	test: 0.753421
PRC train: 0.494430	val: 0.347371	test: 0.142290

Epoch: 16
Loss: 0.11206581612639911
ROC train: 0.884284	val: 0.793112	test: 0.759507
PRC train: 0.505074	val: 0.367611	test: 0.203586

Epoch: 17
Loss: 0.11223320139560508
ROC train: 0.882993	val: 0.771314	test: 0.740961
PRC train: 0.514309	val: 0.327104	test: 0.139155

Epoch: 18
Loss: 0.11156918655341531
ROC train: 0.886858	val: 0.761611	test: 0.749644
PRC train: 0.514454	val: 0.330405	test: 0.170002

Epoch: 19
Loss: 0.10862529198516019
ROC train: 0.882103	val: 0.782704	test: 0.771944
PRC train: 0.510729	val: 0.336729	test: 0.208317

Epoch: 20
Loss: 0.10843692914340367
ROC train: 0.895159	val: 0.760671	test: 0.740839
PRC train: 0.538724	val: 0.332138	test: 0.165575

Epoch: 21
Loss: 0.10754432574630732
ROC train: 0.890988	val: 0.795473	test: 0.743367
PRC train: 0.522238	val: 0.341008	test: 0.180827

Epoch: 22
Loss: 0.10753302418750067
ROC train: 0.893790	val: 0.798819	test: 0.768109
PRC train: 0.525452	val: 0.370924	test: 0.205387

Epoch: 23
Loss: 0.10723045964137928
ROC train: 0.900991	val: 0.792049	test: 0.750727
PRC train: 0.537277	val: 0.343186	test: 0.168799

Epoch: 24
Loss: 0.10498226622368588
ROC train: 0.904120	val: 0.766969	test: 0.742608
PRC train: 0.558583	val: 0.350429	test: 0.191233

Epoch: 25
Loss: 0.10615004271179129
ROC train: 0.905450	val: 0.777692	test: 0.751635
PRC train: 0.550753	val: 0.351294	test: 0.154119

Epoch: 26
Loss: 0.10327020171465615
ROC train: 0.908952	val: 0.774012	test: 0.742071
PRC train: 0.553028	val: 0.303238	test: 0.170312

Epoch: 27
Loss: 0.10466914512830444
ROC train: 0.917519	val: 0.784826	test: 0.761761
PRC train: 0.562997	val: 0.332560	test: 0.183803

Epoch: 28
Loss: 0.10381005289839225
ROC train: 0.909410	val: 0.761127	test: 0.724062
PRC train: 0.548796	val: 0.335327	test: 0.177045

Epoch: 29
Loss: 0.10278340423476172
ROC train: 0.911710	val: 0.778059	test: 0.734661
PRC train: 0.570707	val: 0.354361	test: 0.168329

Epoch: 30
Loss: 0.10170026215288686
ROC train: 0.917128	val: 0.767079	test: 0.746803
PRC train: 0.543948	val: 0.336823	test: 0.168601

Epoch: 31
Loss: 0.10030184863120079
ROC train: 0.926458	val: 0.789575	test: 0.741637
PRC train: 0.590020	val: 0.343667	test: 0.170817

Epoch: 32
Loss: 0.10144768133036207
ROC train: 0.921319	val: 0.787224	test: 0.777839
PRC train: 0.588450	val: 0.327325	test: 0.157918

Epoch: 33
Loss: 0.09997898474344714Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.0.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/hiv/noise=0.0
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/hiv/noise=0.0/hiv_scaff_6_26-05_11-28-51  ]
[ Using Seed :  6  ]
[ Using device :  cuda:0  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.2665060820270058
ROC train: 0.754143	val: 0.741537	test: 0.659688
PRC train: 0.230513	val: 0.197682	test: 0.128910

Epoch: 2
Loss: 0.14188501786821148
ROC train: 0.777638	val: 0.743398	test: 0.714469
PRC train: 0.266438	val: 0.210689	test: 0.140382

Epoch: 3
Loss: 0.13476412111565933
ROC train: 0.787716	val: 0.770867	test: 0.716115
PRC train: 0.311622	val: 0.333203	test: 0.235731

Epoch: 4
Loss: 0.13240689439940384
ROC train: 0.803956	val: 0.741959	test: 0.681436
PRC train: 0.324194	val: 0.198350	test: 0.093909

Epoch: 5
Loss: 0.12899643251487886
ROC train: 0.814773	val: 0.785861	test: 0.726057
PRC train: 0.348012	val: 0.286406	test: 0.233543

Epoch: 6
Loss: 0.12780901281365953
ROC train: 0.825635	val: 0.787478	test: 0.732216
PRC train: 0.386196	val: 0.300572	test: 0.245790

Epoch: 7
Loss: 0.12586368832617065
ROC train: 0.822045	val: 0.753102	test: 0.678472
PRC train: 0.361944	val: 0.259321	test: 0.138148

Epoch: 8
Loss: 0.12485300944474473
ROC train: 0.837921	val: 0.788556	test: 0.736416
PRC train: 0.393039	val: 0.303178	test: 0.196209

Epoch: 9
Loss: 0.1224153954413477
ROC train: 0.830053	val: 0.781896	test: 0.704409
PRC train: 0.393089	val: 0.280971	test: 0.139066

Epoch: 10
Loss: 0.12147933176256188
ROC train: 0.845566	val: 0.779073	test: 0.753904
PRC train: 0.418113	val: 0.372575	test: 0.220787

Epoch: 11
Loss: 0.11933683944798734
ROC train: 0.852287	val: 0.763580	test: 0.703469
PRC train: 0.426420	val: 0.340988	test: 0.208471

Epoch: 12
Loss: 0.11771830336969706
ROC train: 0.855045	val: 0.772768	test: 0.750121
PRC train: 0.448960	val: 0.355604	test: 0.191261

Epoch: 13
Loss: 0.11713830392761376
ROC train: 0.860322	val: 0.797944	test: 0.755320
PRC train: 0.449298	val: 0.344554	test: 0.199451

Epoch: 14
Loss: 0.11672470802245889
ROC train: 0.865148	val: 0.791416	test: 0.739806
PRC train: 0.448283	val: 0.348999	test: 0.173057

Epoch: 15
Loss: 0.11615856422789611
ROC train: 0.875337	val: 0.780925	test: 0.741190
PRC train: 0.480643	val: 0.303410	test: 0.148352

Epoch: 16
Loss: 0.11446315784966035
ROC train: 0.869545	val: 0.772986	test: 0.726070
PRC train: 0.483741	val: 0.329120	test: 0.177047

Epoch: 17
Loss: 0.11360849837273634
ROC train: 0.881235	val: 0.795650	test: 0.741774
PRC train: 0.480632	val: 0.342095	test: 0.191016

Epoch: 18
Loss: 0.11135259935207997
ROC train: 0.881953	val: 0.780552	test: 0.743058
PRC train: 0.498171	val: 0.330855	test: 0.178254

Epoch: 19
Loss: 0.11202598502121082
ROC train: 0.879752	val: 0.788176	test: 0.762827
PRC train: 0.493824	val: 0.310598	test: 0.153603

Epoch: 20
Loss: 0.11134909606284975
ROC train: 0.886799	val: 0.791189	test: 0.777002
PRC train: 0.511837	val: 0.387636	test: 0.240319

Epoch: 21
Loss: 0.10797328133250803
ROC train: 0.891441	val: 0.782992	test: 0.743861
PRC train: 0.525580	val: 0.345706	test: 0.233434

Epoch: 22
Loss: 0.10940200169100787
ROC train: 0.890467	val: 0.797120	test: 0.755260
PRC train: 0.523020	val: 0.352315	test: 0.178361

Epoch: 23
Loss: 0.10826335290051446
ROC train: 0.897717	val: 0.808973	test: 0.743458
PRC train: 0.528547	val: 0.332964	test: 0.215865

Epoch: 24
Loss: 0.1074978119030941
ROC train: 0.902571	val: 0.778053	test: 0.743465
PRC train: 0.547887	val: 0.325014	test: 0.170059

Epoch: 25
Loss: 0.1076531457004315
ROC train: 0.886025	val: 0.762940	test: 0.733682
PRC train: 0.508805	val: 0.325256	test: 0.188968

Epoch: 26
Loss: 0.10624998029033669
ROC train: 0.903651	val: 0.798026	test: 0.766324
PRC train: 0.548503	val: 0.370376	test: 0.254676

Epoch: 27
Loss: 0.10471628893065954
ROC train: 0.897311	val: 0.783320	test: 0.743956
PRC train: 0.536805	val: 0.352226	test: 0.227190

Epoch: 28
Loss: 0.10502838071536623
ROC train: 0.900016	val: 0.803382	test: 0.763703
PRC train: 0.532975	val: 0.348012	test: 0.278287

Epoch: 29
Loss: 0.10331668263142657
ROC train: 0.902723	val: 0.784346	test: 0.749622
PRC train: 0.541881	val: 0.311279	test: 0.185710

Epoch: 30
Loss: 0.10567683240445629
ROC train: 0.913522	val: 0.771311	test: 0.733083
PRC train: 0.570757	val: 0.354155	test: 0.209377

Epoch: 31
Loss: 0.10205274989087747
ROC train: 0.909884	val: 0.792478	test: 0.733087
PRC train: 0.568457	val: 0.352584	test: 0.236297

Epoch: 32
Loss: 0.10133209688589431
ROC train: 0.914924	val: 0.780160	test: 0.771349
PRC train: 0.570378	val: 0.321454	test: 0.200434

Epoch: 33
Loss: 0.10132516658877987Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.05.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.05
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/hiv/noise=0.05
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/hiv/noise=0.05/hiv_scaff_6_26-05_11-28-51  ]
[ Using Seed :  6  ]
[ Using device :  cuda:1  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.25561512200047654
ROC train: 0.728490	val: 0.727357	test: 0.712248
PRC train: 0.155181	val: 0.133282	test: 0.207702

Epoch: 2
Loss: 0.1452815784936663
ROC train: 0.780536	val: 0.753803	test: 0.680593
PRC train: 0.251149	val: 0.235882	test: 0.202265

Epoch: 3
Loss: 0.1390555522056649
ROC train: 0.792162	val: 0.765209	test: 0.735090
PRC train: 0.282346	val: 0.263353	test: 0.256634

Epoch: 4
Loss: 0.1365321426554171
ROC train: 0.804354	val: 0.778837	test: 0.735169
PRC train: 0.310094	val: 0.295213	test: 0.247150

Epoch: 5
Loss: 0.13245000403394255
ROC train: 0.796735	val: 0.777955	test: 0.702563
PRC train: 0.316556	val: 0.265914	test: 0.130183

Epoch: 6
Loss: 0.13134324032426117
ROC train: 0.817152	val: 0.792536	test: 0.713086
PRC train: 0.344945	val: 0.326624	test: 0.191017

Epoch: 7
Loss: 0.12830425983759433
ROC train: 0.827494	val: 0.785497	test: 0.743259
PRC train: 0.366772	val: 0.314293	test: 0.244208

Epoch: 8
Loss: 0.12769214527308811
ROC train: 0.825735	val: 0.776578	test: 0.745574
PRC train: 0.377077	val: 0.301740	test: 0.204977

Epoch: 9
Loss: 0.1263957134499441
ROC train: 0.848086	val: 0.801673	test: 0.743661
PRC train: 0.414505	val: 0.329178	test: 0.247510

Epoch: 10
Loss: 0.12410464452958858
ROC train: 0.846809	val: 0.798032	test: 0.707853
PRC train: 0.419781	val: 0.295212	test: 0.169786

Epoch: 11
Loss: 0.12382721647747633
ROC train: 0.853167	val: 0.782202	test: 0.713874
PRC train: 0.425631	val: 0.273369	test: 0.178792

Epoch: 12
Loss: 0.12196935091916691
ROC train: 0.862870	val: 0.802463	test: 0.742009
PRC train: 0.446519	val: 0.348997	test: 0.185854

Epoch: 13
Loss: 0.12003275857919075
ROC train: 0.862778	val: 0.797083	test: 0.745279
PRC train: 0.450906	val: 0.318391	test: 0.261495

Epoch: 14
Loss: 0.11748460037580802
ROC train: 0.868577	val: 0.766023	test: 0.718065
PRC train: 0.464893	val: 0.332363	test: 0.176765

Epoch: 15
Loss: 0.11746024288761779
ROC train: 0.870643	val: 0.797451	test: 0.734251
PRC train: 0.431803	val: 0.307989	test: 0.174796

Epoch: 16
Loss: 0.11633937681976864
ROC train: 0.872239	val: 0.806312	test: 0.740092
PRC train: 0.465331	val: 0.369448	test: 0.268415

Epoch: 17
Loss: 0.11598057372205775
ROC train: 0.875646	val: 0.761761	test: 0.721727
PRC train: 0.455365	val: 0.295894	test: 0.162673

Epoch: 18
Loss: 0.11442050444826679
ROC train: 0.888802	val: 0.786774	test: 0.728664
PRC train: 0.498649	val: 0.350202	test: 0.174549

Epoch: 19
Loss: 0.11314839832715431
ROC train: 0.886471	val: 0.791829	test: 0.745561
PRC train: 0.500201	val: 0.324117	test: 0.206294

Epoch: 20
Loss: 0.11104368247446357
ROC train: 0.891927	val: 0.795182	test: 0.727426
PRC train: 0.523180	val: 0.361112	test: 0.214168

Epoch: 21
Loss: 0.1104841481944417
ROC train: 0.900857	val: 0.809815	test: 0.751818
PRC train: 0.539695	val: 0.359808	test: 0.263090

Epoch: 22
Loss: 0.10927302859376685
ROC train: 0.892677	val: 0.772615	test: 0.732023
PRC train: 0.500890	val: 0.310671	test: 0.288185

Epoch: 23
Loss: 0.10808735004663629
ROC train: 0.906361	val: 0.774682	test: 0.750930
PRC train: 0.561961	val: 0.351500	test: 0.213080

Epoch: 24
Loss: 0.10816665984804316
ROC train: 0.897232	val: 0.779842	test: 0.742492
PRC train: 0.497543	val: 0.322017	test: 0.218975

Epoch: 25
Loss: 0.10639356026252984
ROC train: 0.909350	val: 0.788384	test: 0.752189
PRC train: 0.553973	val: 0.378651	test: 0.252571

Epoch: 26
Loss: 0.10478493378729745
ROC train: 0.908395	val: 0.799952	test: 0.737890
PRC train: 0.557580	val: 0.317245	test: 0.158608

Epoch: 27
Loss: 0.10453965267994669
ROC train: 0.917921	val: 0.823817	test: 0.746567
PRC train: 0.587597	val: 0.357704	test: 0.240667

Epoch: 28
Loss: 0.1029643734892156
ROC train: 0.920323	val: 0.788354	test: 0.725418
PRC train: 0.577285	val: 0.321461	test: 0.195953

Epoch: 29
Loss: 0.10200687433217766
ROC train: 0.927410	val: 0.813238	test: 0.755030
PRC train: 0.607118	val: 0.338910	test: 0.224030

Epoch: 30
Loss: 0.10177167486907734
ROC train: 0.921966	val: 0.814490	test: 0.747330
PRC train: 0.603383	val: 0.321215	test: 0.196801

Epoch: 31
Loss: 0.10091094534270016
ROC train: 0.927806	val: 0.798522	test: 0.740049
PRC train: 0.613061	val: 0.365239	test: 0.224781

Epoch: 32
Loss: 0.10126368194112419
ROC train: 0.933329	val: 0.790194	test: 0.732608Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.1.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.1
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/hiv/noise=0.1
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/hiv/noise=0.1/hiv_scaff_5_26-05_11-28-51  ]
[ Using Seed :  5  ]
[ Using device :  cuda:2  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.23500295471130805
ROC train: 0.721711	val: 0.763044	test: 0.697550
PRC train: 0.132405	val: 0.181114	test: 0.149470

Epoch: 2
Loss: 0.14826726677570473
ROC train: 0.753777	val: 0.741910	test: 0.738097
PRC train: 0.180082	val: 0.180219	test: 0.223864

Epoch: 3
Loss: 0.14273017479747324
ROC train: 0.766168	val: 0.729231	test: 0.694610
PRC train: 0.221609	val: 0.201017	test: 0.202750

Epoch: 4
Loss: 0.1395504483895184
ROC train: 0.794790	val: 0.750026	test: 0.710996
PRC train: 0.297074	val: 0.276948	test: 0.209709

Epoch: 5
Loss: 0.13648315530265542
ROC train: 0.796963	val: 0.773996	test: 0.715375
PRC train: 0.309448	val: 0.250322	test: 0.238371

Epoch: 6
Loss: 0.1335366631167459
ROC train: 0.815755	val: 0.766932	test: 0.711530
PRC train: 0.327117	val: 0.290277	test: 0.180380

Epoch: 7
Loss: 0.13183021875117942
ROC train: 0.816445	val: 0.748840	test: 0.714896
PRC train: 0.335639	val: 0.287881	test: 0.253874

Epoch: 8
Loss: 0.12942370895837715
ROC train: 0.835048	val: 0.754538	test: 0.708880
PRC train: 0.362398	val: 0.250196	test: 0.178939

Epoch: 9
Loss: 0.1283767350110627
ROC train: 0.813643	val: 0.710180	test: 0.732032
PRC train: 0.329067	val: 0.213149	test: 0.198638

Epoch: 10
Loss: 0.12694240714466878
ROC train: 0.834507	val: 0.797674	test: 0.721491
PRC train: 0.376211	val: 0.260262	test: 0.197264

Epoch: 11
Loss: 0.12489412664778281
ROC train: 0.857237	val: 0.752220	test: 0.714931
PRC train: 0.415110	val: 0.314568	test: 0.219386

Epoch: 12
Loss: 0.12345159414351475
ROC train: 0.854868	val: 0.770368	test: 0.724724
PRC train: 0.410199	val: 0.306156	test: 0.220465

Epoch: 13
Loss: 0.12434403780928724
ROC train: 0.854592	val: 0.765475	test: 0.753831
PRC train: 0.421162	val: 0.325164	test: 0.243383

Epoch: 14
Loss: 0.12108969327795555
ROC train: 0.874582	val: 0.734589	test: 0.699907
PRC train: 0.457209	val: 0.318570	test: 0.205305

Epoch: 15
Loss: 0.11932906756794287
ROC train: 0.860491	val: 0.719635	test: 0.733840
PRC train: 0.441651	val: 0.282135	test: 0.160238

Epoch: 16
Loss: 0.11839648434746988
ROC train: 0.876616	val: 0.750165	test: 0.715595
PRC train: 0.477513	val: 0.335210	test: 0.206549

Epoch: 17
Loss: 0.11599764452291339
ROC train: 0.888605	val: 0.770451	test: 0.721575
PRC train: 0.494818	val: 0.323746	test: 0.217548

Epoch: 18
Loss: 0.11468736993108514
ROC train: 0.886856	val: 0.746451	test: 0.741384
PRC train: 0.465515	val: 0.322745	test: 0.230324

Epoch: 19
Loss: 0.11286248826071256
ROC train: 0.892439	val: 0.762741	test: 0.741505
PRC train: 0.510289	val: 0.322618	test: 0.208206

Epoch: 20
Loss: 0.1125528106397515
ROC train: 0.898210	val: 0.783182	test: 0.746154
PRC train: 0.535546	val: 0.312741	test: 0.205457

Epoch: 21
Loss: 0.11272463344100347
ROC train: 0.901586	val: 0.745343	test: 0.727299
PRC train: 0.536053	val: 0.321363	test: 0.192228

Epoch: 22
Loss: 0.11108927854073311
ROC train: 0.912430	val: 0.772524	test: 0.741333
PRC train: 0.551223	val: 0.327016	test: 0.150130

Epoch: 23
Loss: 0.10851181164417116
ROC train: 0.917542	val: 0.759264	test: 0.743373
PRC train: 0.579099	val: 0.353788	test: 0.193146

Epoch: 24
Loss: 0.10870726043017227
ROC train: 0.907346	val: 0.775261	test: 0.754679
PRC train: 0.561417	val: 0.339023	test: 0.209819

Epoch: 25
Loss: 0.10649327120554423
ROC train: 0.906168	val: 0.744400	test: 0.694557
PRC train: 0.559850	val: 0.322124	test: 0.175331

Epoch: 26
Loss: 0.10609415314728764
ROC train: 0.910948	val: 0.770392	test: 0.726580
PRC train: 0.588888	val: 0.312969	test: 0.210602

Epoch: 27
Loss: 0.10441945162693166
ROC train: 0.922921	val: 0.784998	test: 0.753595
PRC train: 0.607470	val: 0.349049	test: 0.224894

Epoch: 28
Loss: 0.10431200646311263
ROC train: 0.925761	val: 0.787919	test: 0.740818
PRC train: 0.613944	val: 0.339811	test: 0.200512

Epoch: 29
Loss: 0.10208594983920025
ROC train: 0.923662	val: 0.785999	test: 0.734972
PRC train: 0.609999	val: 0.337773	test: 0.214202

Epoch: 30
Loss: 0.10133183355375489
ROC train: 0.929420	val: 0.778096	test: 0.739821
PRC train: 0.632076	val: 0.321694	test: 0.240041

Epoch: 31
Loss: 0.09983290488465962
ROC train: 0.934894	val: 0.764076	test: 0.736889
PRC train: 0.635481	val: 0.324203	test: 0.193910

Epoch: 32
Loss: 0.09892843786955825
ROC train: 0.937788	val: 0.782968	test: 0.733599Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.05.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.05
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/hiv/noise=0.05
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/hiv/noise=0.05/hiv_scaff_5_26-05_11-28-51  ]
[ Using Seed :  5  ]
[ Using device :  cuda:1  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.2327228109941981
ROC train: 0.753228	val: 0.729531	test: 0.684247
PRC train: 0.168131	val: 0.175389	test: 0.118793

Epoch: 2
Loss: 0.1447863383050554
ROC train: 0.748433	val: 0.745600	test: 0.732716
PRC train: 0.192661	val: 0.239809	test: 0.186692

Epoch: 3
Loss: 0.1396893823508348
ROC train: 0.766809	val: 0.728824	test: 0.687425
PRC train: 0.219537	val: 0.247923	test: 0.190782

Epoch: 4
Loss: 0.13574211893825114
ROC train: 0.804981	val: 0.783165	test: 0.741880
PRC train: 0.314489	val: 0.328825	test: 0.192858

Epoch: 5
Loss: 0.13365677119523214
ROC train: 0.815746	val: 0.776798	test: 0.714365
PRC train: 0.341643	val: 0.292991	test: 0.204625

Epoch: 6
Loss: 0.13014964746548743
ROC train: 0.825672	val: 0.777061	test: 0.729595
PRC train: 0.344792	val: 0.326629	test: 0.230002

Epoch: 7
Loss: 0.12925243666241204
ROC train: 0.825593	val: 0.778280	test: 0.681390
PRC train: 0.342572	val: 0.267800	test: 0.133704

Epoch: 8
Loss: 0.12774875279513417
ROC train: 0.840207	val: 0.774655	test: 0.734684
PRC train: 0.384882	val: 0.289153	test: 0.208716

Epoch: 9
Loss: 0.1260677630578342
ROC train: 0.846402	val: 0.789340	test: 0.734191
PRC train: 0.399372	val: 0.301229	test: 0.215328

Epoch: 10
Loss: 0.12366563172271107
ROC train: 0.847842	val: 0.770829	test: 0.715193
PRC train: 0.395189	val: 0.281358	test: 0.167209

Epoch: 11
Loss: 0.12315599598959832
ROC train: 0.856588	val: 0.767236	test: 0.722445
PRC train: 0.415123	val: 0.343915	test: 0.205113

Epoch: 12
Loss: 0.12110979805997572
ROC train: 0.866146	val: 0.782631	test: 0.734122
PRC train: 0.454928	val: 0.355462	test: 0.206189

Epoch: 13
Loss: 0.1196201248848719
ROC train: 0.861453	val: 0.788580	test: 0.749671
PRC train: 0.442930	val: 0.328819	test: 0.211064

Epoch: 14
Loss: 0.11807652343108639
ROC train: 0.873229	val: 0.793819	test: 0.746299
PRC train: 0.462552	val: 0.374524	test: 0.188888

Epoch: 15
Loss: 0.11760349334021973
ROC train: 0.873109	val: 0.760493	test: 0.729290
PRC train: 0.454694	val: 0.308401	test: 0.180413

Epoch: 16
Loss: 0.11696779494794886
ROC train: 0.872588	val: 0.802619	test: 0.723931
PRC train: 0.475433	val: 0.364380	test: 0.158686

Epoch: 17
Loss: 0.11409846969630501
ROC train: 0.880289	val: 0.796045	test: 0.731179
PRC train: 0.487102	val: 0.358308	test: 0.158696

Epoch: 18
Loss: 0.1133973218687659
ROC train: 0.888253	val: 0.776773	test: 0.729255
PRC train: 0.504551	val: 0.353865	test: 0.248748

Epoch: 19
Loss: 0.1130992894442541
ROC train: 0.890477	val: 0.778571	test: 0.724346
PRC train: 0.504791	val: 0.378629	test: 0.188731

Epoch: 20
Loss: 0.11025822567919076
ROC train: 0.893148	val: 0.780696	test: 0.715993
PRC train: 0.529227	val: 0.343638	test: 0.189039

Epoch: 21
Loss: 0.10980442035480838
ROC train: 0.899965	val: 0.788700	test: 0.722727
PRC train: 0.530349	val: 0.329378	test: 0.157461

Epoch: 22
Loss: 0.10871964093554937
ROC train: 0.902848	val: 0.788703	test: 0.730126
PRC train: 0.545362	val: 0.365111	test: 0.162669

Epoch: 23
Loss: 0.10806720098882938
ROC train: 0.901145	val: 0.804358	test: 0.731090
PRC train: 0.532618	val: 0.342880	test: 0.155657

Epoch: 24
Loss: 0.10726966282978971
ROC train: 0.912008	val: 0.805929	test: 0.744700
PRC train: 0.564910	val: 0.346751	test: 0.213178

Epoch: 25
Loss: 0.10609571973582284
ROC train: 0.905068	val: 0.776980	test: 0.696661
PRC train: 0.543482	val: 0.314414	test: 0.178153

Epoch: 26
Loss: 0.10589228055428042
ROC train: 0.915597	val: 0.802653	test: 0.725624
PRC train: 0.580835	val: 0.348107	test: 0.206333

Epoch: 27
Loss: 0.10537210635280297
ROC train: 0.914651	val: 0.796293	test: 0.742386
PRC train: 0.598783	val: 0.332375	test: 0.174509

Epoch: 28
Loss: 0.10293807158053175
ROC train: 0.917238	val: 0.808406	test: 0.754754
PRC train: 0.595033	val: 0.372865	test: 0.195563

Epoch: 29
Loss: 0.10245723894770312
ROC train: 0.921263	val: 0.796808	test: 0.727003
PRC train: 0.604648	val: 0.360642	test: 0.182143

Epoch: 30
Loss: 0.09933798989141528
ROC train: 0.917526	val: 0.779202	test: 0.733398
PRC train: 0.601189	val: 0.356146	test: 0.168749

Epoch: 31
Loss: 0.09925796711879982
ROC train: 0.922965	val: 0.780178	test: 0.738044
PRC train: 0.617660	val: 0.323602	test: 0.211289

Epoch: 32
Loss: 0.09925153826391732
ROC train: 0.933785	val: 0.795418	test: 0.729408Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.0.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/hiv/noise=0.0
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/hiv/noise=0.0/hiv_scaff_5_26-05_11-28-51  ]
[ Using Seed :  5  ]
[ Using device :  cuda:0  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.26563493554622686
ROC train: 0.768597	val: 0.754691	test: 0.659010
PRC train: 0.228951	val: 0.169659	test: 0.161562

Epoch: 2
Loss: 0.13994533222035166
ROC train: 0.769494	val: 0.724516	test: 0.715220
PRC train: 0.254007	val: 0.267724	test: 0.228985

Epoch: 3
Loss: 0.13535312124140628
ROC train: 0.803121	val: 0.752033	test: 0.696669
PRC train: 0.319838	val: 0.260510	test: 0.120609

Epoch: 4
Loss: 0.1311975962193608
ROC train: 0.807168	val: 0.748092	test: 0.699220
PRC train: 0.348305	val: 0.311963	test: 0.157727

Epoch: 5
Loss: 0.1280740492835669
ROC train: 0.805274	val: 0.766877	test: 0.697941
PRC train: 0.333509	val: 0.291257	test: 0.175348

Epoch: 6
Loss: 0.12855434068651136
ROC train: 0.819108	val: 0.725805	test: 0.729259
PRC train: 0.361174	val: 0.249021	test: 0.175259

Epoch: 7
Loss: 0.12450475008779768
ROC train: 0.819870	val: 0.764339	test: 0.734421
PRC train: 0.362499	val: 0.330053	test: 0.205588

Epoch: 8
Loss: 0.12499070280897873
ROC train: 0.826631	val: 0.754991	test: 0.719336
PRC train: 0.403140	val: 0.338824	test: 0.236258

Epoch: 9
Loss: 0.12114541770197106
ROC train: 0.848383	val: 0.777808	test: 0.721028
PRC train: 0.423591	val: 0.288452	test: 0.145659

Epoch: 10
Loss: 0.12082509936709364
ROC train: 0.843053	val: 0.773712	test: 0.747542
PRC train: 0.409148	val: 0.370344	test: 0.186231

Epoch: 11
Loss: 0.11895418235872292
ROC train: 0.843338	val: 0.785558	test: 0.744365
PRC train: 0.440958	val: 0.283618	test: 0.234083

Epoch: 12
Loss: 0.11795736728404305
ROC train: 0.855084	val: 0.768411	test: 0.740812
PRC train: 0.458853	val: 0.327053	test: 0.214241

Epoch: 13
Loss: 0.11737336134723382
ROC train: 0.864976	val: 0.769829	test: 0.744584
PRC train: 0.476673	val: 0.342971	test: 0.185753

Epoch: 14
Loss: 0.11530406616479232
ROC train: 0.859327	val: 0.768767	test: 0.754072
PRC train: 0.480647	val: 0.327946	test: 0.156418

Epoch: 15
Loss: 0.11576370918648637
ROC train: 0.858442	val: 0.778702	test: 0.772852
PRC train: 0.460232	val: 0.353097	test: 0.240429

Epoch: 16
Loss: 0.11310840653783125
ROC train: 0.868953	val: 0.768901	test: 0.767834
PRC train: 0.480972	val: 0.369673	test: 0.210619

Epoch: 17
Loss: 0.11279495123506891
ROC train: 0.875960	val: 0.773219	test: 0.758794
PRC train: 0.510487	val: 0.341684	test: 0.179699

Epoch: 18
Loss: 0.11205135356459274
ROC train: 0.877576	val: 0.789915	test: 0.773047
PRC train: 0.509899	val: 0.365118	test: 0.207005

Epoch: 19
Loss: 0.10953450994290884
ROC train: 0.869704	val: 0.778758	test: 0.703399
PRC train: 0.438031	val: 0.252825	test: 0.077069

Epoch: 20
Loss: 0.11009618022277073
ROC train: 0.878389	val: 0.780273	test: 0.781773
PRC train: 0.511351	val: 0.352626	test: 0.229820

Epoch: 21
Loss: 0.11047725791261324
ROC train: 0.881456	val: 0.779009	test: 0.762784
PRC train: 0.509970	val: 0.354519	test: 0.216677

Epoch: 22
Loss: 0.1108882597129917
ROC train: 0.879916	val: 0.779496	test: 0.756424
PRC train: 0.507278	val: 0.311852	test: 0.193392

Epoch: 23
Loss: 0.10782673201515246
ROC train: 0.893467	val: 0.780047	test: 0.761546
PRC train: 0.531527	val: 0.351277	test: 0.212107

Epoch: 24
Loss: 0.10754621471427207
ROC train: 0.892434	val: 0.791514	test: 0.758238
PRC train: 0.539276	val: 0.343259	test: 0.202490

Epoch: 25
Loss: 0.10797231667033327
ROC train: 0.886293	val: 0.757183	test: 0.740584
PRC train: 0.518355	val: 0.312179	test: 0.182263

Epoch: 26
Loss: 0.10571961274091642
ROC train: 0.892167	val: 0.783905	test: 0.762211
PRC train: 0.526461	val: 0.334219	test: 0.209059

Epoch: 27
Loss: 0.1063136632362269
ROC train: 0.900305	val: 0.785751	test: 0.767506
PRC train: 0.532069	val: 0.369686	test: 0.219466

Epoch: 28
Loss: 0.10336241607330156
ROC train: 0.899376	val: 0.780172	test: 0.768781
PRC train: 0.554837	val: 0.331916	test: 0.218193

Epoch: 29
Loss: 0.10395679089558182
ROC train: 0.903681	val: 0.797481	test: 0.757724
PRC train: 0.546035	val: 0.314116	test: 0.136766

Epoch: 30
Loss: 0.10454608891677974
ROC train: 0.902011	val: 0.794465	test: 0.756677
PRC train: 0.536075	val: 0.365274	test: 0.224327

Epoch: 31
Loss: 0.10429171840050269
ROC train: 0.906976	val: 0.792527	test: 0.768107
PRC train: 0.562325	val: 0.331335	test: 0.174355

Epoch: 32
Loss: 0.10090283086281801
ROC train: 0.908281	val: 0.793954	test: 0.782321
PRC train: 0.561564	val: 0.340242	test: 0.274106

Epoch: 33
Loss: 0.10294072623719597Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.1.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.1
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/hiv/noise=0.1
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/hiv/noise=0.1/hiv_scaff_6_26-05_11-28-51  ]
[ Using Seed :  6  ]
[ Using device :  cuda:2  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.25721852522480115
ROC train: 0.730928	val: 0.702978	test: 0.684169
PRC train: 0.144455	val: 0.121337	test: 0.166626

Epoch: 2
Loss: 0.14812472356721182
ROC train: 0.762217	val: 0.729663	test: 0.690674
PRC train: 0.187455	val: 0.160610	test: 0.151535

Epoch: 3
Loss: 0.14275248475392774
ROC train: 0.776437	val: 0.737841	test: 0.706228
PRC train: 0.245348	val: 0.198479	test: 0.161715

Epoch: 4
Loss: 0.13980285412124857
ROC train: 0.798067	val: 0.722045	test: 0.712934
PRC train: 0.276520	val: 0.205842	test: 0.145858

Epoch: 5
Loss: 0.1364940052324784
ROC train: 0.800362	val: 0.748454	test: 0.715321
PRC train: 0.316437	val: 0.257469	test: 0.173124

Epoch: 6
Loss: 0.13382028483215014
ROC train: 0.809605	val: 0.754859	test: 0.698718
PRC train: 0.295530	val: 0.288859	test: 0.129241

Epoch: 7
Loss: 0.13111985601878828
ROC train: 0.825851	val: 0.739032	test: 0.726121
PRC train: 0.346545	val: 0.277396	test: 0.195439

Epoch: 8
Loss: 0.130376920518917
ROC train: 0.828725	val: 0.722035	test: 0.719000
PRC train: 0.351411	val: 0.263609	test: 0.172880

Epoch: 9
Loss: 0.12806646912228417
ROC train: 0.848047	val: 0.726481	test: 0.732693
PRC train: 0.398500	val: 0.296171	test: 0.215389

Epoch: 10
Loss: 0.12633422666329897
ROC train: 0.839648	val: 0.758114	test: 0.690743
PRC train: 0.380845	val: 0.219942	test: 0.150606

Epoch: 11
Loss: 0.12546273760203797
ROC train: 0.853949	val: 0.741837	test: 0.693737
PRC train: 0.401562	val: 0.254883	test: 0.154036

Epoch: 12
Loss: 0.12514192439915417
ROC train: 0.853636	val: 0.766891	test: 0.713237
PRC train: 0.414584	val: 0.290533	test: 0.171354

Epoch: 13
Loss: 0.12090372664595568
ROC train: 0.861728	val: 0.756715	test: 0.737820
PRC train: 0.422607	val: 0.289915	test: 0.180616

Epoch: 14
Loss: 0.11907929408821956
ROC train: 0.868624	val: 0.728612	test: 0.731283
PRC train: 0.467573	val: 0.321782	test: 0.224848

Epoch: 15
Loss: 0.11834873133040398
ROC train: 0.869018	val: 0.746209	test: 0.716277
PRC train: 0.468081	val: 0.330334	test: 0.165764

Epoch: 16
Loss: 0.11787062307924079
ROC train: 0.870659	val: 0.769875	test: 0.758551
PRC train: 0.455912	val: 0.310282	test: 0.238981

Epoch: 17
Loss: 0.11724209466565613
ROC train: 0.891247	val: 0.755267	test: 0.728112
PRC train: 0.493940	val: 0.317681	test: 0.214965

Epoch: 18
Loss: 0.11511139560550852
ROC train: 0.895361	val: 0.759143	test: 0.707567
PRC train: 0.515915	val: 0.286996	test: 0.151038

Epoch: 19
Loss: 0.11453921423205665
ROC train: 0.894074	val: 0.766228	test: 0.720060
PRC train: 0.523854	val: 0.301301	test: 0.185853

Epoch: 20
Loss: 0.11236057284478301
ROC train: 0.898917	val: 0.774085	test: 0.709850
PRC train: 0.528476	val: 0.318511	test: 0.216617

Epoch: 21
Loss: 0.11070439206259604
ROC train: 0.896128	val: 0.790503	test: 0.721553
PRC train: 0.531171	val: 0.316172	test: 0.234371

Epoch: 22
Loss: 0.1107929186995068
ROC train: 0.907418	val: 0.741571	test: 0.713488
PRC train: 0.527130	val: 0.301896	test: 0.257728

Epoch: 23
Loss: 0.10890240880158325
ROC train: 0.907384	val: 0.761568	test: 0.730335
PRC train: 0.556501	val: 0.319032	test: 0.202294

Epoch: 24
Loss: 0.10791936968611962
ROC train: 0.895499	val: 0.732400	test: 0.704444
PRC train: 0.488685	val: 0.271964	test: 0.213632

Epoch: 25
Loss: 0.10676955476893263
ROC train: 0.919959	val: 0.749311	test: 0.720564
PRC train: 0.587094	val: 0.289181	test: 0.221936

Epoch: 26
Loss: 0.10591502452917718
ROC train: 0.912784	val: 0.754250	test: 0.716991
PRC train: 0.548838	val: 0.242096	test: 0.137462

Epoch: 27
Loss: 0.10514220414043524
ROC train: 0.930224	val: 0.756246	test: 0.743411
PRC train: 0.602755	val: 0.289929	test: 0.209197

Epoch: 28
Loss: 0.10233378213188554
ROC train: 0.926872	val: 0.774064	test: 0.730147
PRC train: 0.605904	val: 0.306065	test: 0.196721

Epoch: 29
Loss: 0.10209527924731544
ROC train: 0.937545	val: 0.761837	test: 0.739833
PRC train: 0.636930	val: 0.314435	test: 0.230125

Epoch: 30
Loss: 0.09964887474487316
ROC train: 0.929416	val: 0.755291	test: 0.726827
PRC train: 0.630128	val: 0.290353	test: 0.207448

Epoch: 31
Loss: 0.09850275747797263
ROC train: 0.936869	val: 0.767499	test: 0.724431
PRC train: 0.654160	val: 0.326193	test: 0.199403

Epoch: 32
Loss: 0.09858178532668066
ROC train: 0.945546	val: 0.780895	test: 0.720029Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.1.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.1
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/hiv/noise=0.1
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/hiv/noise=0.1/hiv_scaff_4_26-05_11-28-51  ]
[ Using Seed :  4  ]
[ Using device :  cuda:2  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.2845120525332704
ROC train: 0.738661	val: 0.726331	test: 0.652535
PRC train: 0.167651	val: 0.149765	test: 0.169261

Epoch: 2
Loss: 0.14744107513724222
ROC train: 0.759826	val: 0.755830	test: 0.701503
PRC train: 0.204286	val: 0.212174	test: 0.178083

Epoch: 3
Loss: 0.14290538890178828
ROC train: 0.776909	val: 0.737434	test: 0.728815
PRC train: 0.242671	val: 0.230010	test: 0.219754

Epoch: 4
Loss: 0.13859390334554186
ROC train: 0.788268	val: 0.719470	test: 0.714768
PRC train: 0.245922	val: 0.202961	test: 0.115813

Epoch: 5
Loss: 0.13652410460276837
ROC train: 0.791324	val: 0.702200	test: 0.683063
PRC train: 0.310843	val: 0.243034	test: 0.183891

Epoch: 6
Loss: 0.1348307163218206
ROC train: 0.815725	val: 0.762456	test: 0.717708
PRC train: 0.321066	val: 0.239709	test: 0.164670

Epoch: 7
Loss: 0.13105005836652028
ROC train: 0.807173	val: 0.720263	test: 0.757693
PRC train: 0.313530	val: 0.317226	test: 0.253321

Epoch: 8
Loss: 0.1301459006482346
ROC train: 0.828535	val: 0.749378	test: 0.713861
PRC train: 0.375374	val: 0.258588	test: 0.187615

Epoch: 9
Loss: 0.12877558596315408
ROC train: 0.834345	val: 0.752039	test: 0.711841
PRC train: 0.386350	val: 0.335630	test: 0.217463

Epoch: 10
Loss: 0.12785177765610056
ROC train: 0.835944	val: 0.764624	test: 0.703592
PRC train: 0.380657	val: 0.302943	test: 0.176444

Epoch: 11
Loss: 0.12630289593033184
ROC train: 0.849394	val: 0.795081	test: 0.697484
PRC train: 0.402920	val: 0.268826	test: 0.144692

Epoch: 12
Loss: 0.1239880538779328
ROC train: 0.856145	val: 0.788813	test: 0.728137
PRC train: 0.402974	val: 0.358980	test: 0.181898

Epoch: 13
Loss: 0.12164944806642185
ROC train: 0.853382	val: 0.782037	test: 0.696883
PRC train: 0.417203	val: 0.337159	test: 0.168553

Epoch: 14
Loss: 0.12072926728450774
ROC train: 0.864229	val: 0.752946	test: 0.730601
PRC train: 0.457671	val: 0.314243	test: 0.205368

Epoch: 15
Loss: 0.11962244819483947
ROC train: 0.875149	val: 0.781033	test: 0.733618
PRC train: 0.470885	val: 0.325011	test: 0.202609

Epoch: 16
Loss: 0.11899383305522132
ROC train: 0.871435	val: 0.789392	test: 0.723535
PRC train: 0.445279	val: 0.350852	test: 0.208068

Epoch: 17
Loss: 0.11774370461725747
ROC train: 0.876677	val: 0.785601	test: 0.699762
PRC train: 0.467880	val: 0.370125	test: 0.225195

Epoch: 18
Loss: 0.11687464847546118
ROC train: 0.887012	val: 0.795029	test: 0.713623
PRC train: 0.500363	val: 0.385379	test: 0.227782

Epoch: 19
Loss: 0.11326361584219809
ROC train: 0.895633	val: 0.800814	test: 0.672979
PRC train: 0.505156	val: 0.374972	test: 0.177390

Epoch: 20
Loss: 0.11238535614099054
ROC train: 0.896230	val: 0.785301	test: 0.723135
PRC train: 0.519336	val: 0.385524	test: 0.233096

Epoch: 21
Loss: 0.11224336988349451
ROC train: 0.878679	val: 0.768393	test: 0.727361
PRC train: 0.462486	val: 0.355542	test: 0.213959

Epoch: 22
Loss: 0.10967098094540152
ROC train: 0.903280	val: 0.799144	test: 0.713965
PRC train: 0.538391	val: 0.340851	test: 0.186821

Epoch: 23
Loss: 0.10987150307592419
ROC train: 0.909323	val: 0.797763	test: 0.711696
PRC train: 0.553167	val: 0.345260	test: 0.185605

Epoch: 24
Loss: 0.10754537969496135
ROC train: 0.914624	val: 0.785093	test: 0.706318
PRC train: 0.549623	val: 0.368586	test: 0.227756

Epoch: 25
Loss: 0.10870342404206125
ROC train: 0.918333	val: 0.828701	test: 0.721447
PRC train: 0.583388	val: 0.373706	test: 0.183825

Epoch: 26
Loss: 0.10500527372758303
ROC train: 0.919408	val: 0.803792	test: 0.734290
PRC train: 0.604760	val: 0.394032	test: 0.178919

Epoch: 27
Loss: 0.10423037073544288
ROC train: 0.922323	val: 0.787153	test: 0.697119
PRC train: 0.605151	val: 0.341948	test: 0.174689

Epoch: 28
Loss: 0.10351168671698334
ROC train: 0.921078	val: 0.783935	test: 0.719070
PRC train: 0.552525	val: 0.341533	test: 0.251740

Epoch: 29
Loss: 0.10319139840735475
ROC train: 0.925473	val: 0.800908	test: 0.717244
PRC train: 0.617647	val: 0.379526	test: 0.198469

Epoch: 30
Loss: 0.10059397528083272
ROC train: 0.928487	val: 0.789431	test: 0.709794
PRC train: 0.592200	val: 0.302577	test: 0.216487

Epoch: 31
Loss: 0.09963866384402473
ROC train: 0.939974	val: 0.807050	test: 0.733174
PRC train: 0.648347	val: 0.377579	test: 0.259811

Epoch: 32
Loss: 0.09723591148166956
ROC train: 0.940427	val: 0.818312	test: 0.733660Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.05.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.05
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/hiv/noise=0.05
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/hiv/noise=0.05/hiv_scaff_4_26-05_11-28-51  ]
[ Using Seed :  4  ]
[ Using device :  cuda:1  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.2827008170863588
ROC train: 0.739636	val: 0.717816	test: 0.626567
PRC train: 0.174970	val: 0.176079	test: 0.087586

Epoch: 2
Loss: 0.14383775852325595
ROC train: 0.785024	val: 0.780194	test: 0.683327
PRC train: 0.270115	val: 0.207874	test: 0.158389

Epoch: 3
Loss: 0.13991591737982942
ROC train: 0.780742	val: 0.763574	test: 0.733222
PRC train: 0.268195	val: 0.264341	test: 0.203991

Epoch: 4
Loss: 0.13522402300769237
ROC train: 0.796191	val: 0.723891	test: 0.721789
PRC train: 0.305298	val: 0.291953	test: 0.250000

Epoch: 5
Loss: 0.13326102577737042
ROC train: 0.797099	val: 0.701132	test: 0.680643
PRC train: 0.325663	val: 0.252213	test: 0.177750

Epoch: 6
Loss: 0.13100993405947975
ROC train: 0.820121	val: 0.769308	test: 0.708418
PRC train: 0.359413	val: 0.294255	test: 0.150092

Epoch: 7
Loss: 0.12917452288049236
ROC train: 0.816865	val: 0.771002	test: 0.731127
PRC train: 0.380929	val: 0.355144	test: 0.216682

Epoch: 8
Loss: 0.12651187782785675
ROC train: 0.829979	val: 0.785975	test: 0.717482
PRC train: 0.391378	val: 0.297409	test: 0.209122

Epoch: 9
Loss: 0.12598634445936888
ROC train: 0.834698	val: 0.795032	test: 0.713100
PRC train: 0.405932	val: 0.357118	test: 0.202254

Epoch: 10
Loss: 0.12424234884878381
ROC train: 0.837805	val: 0.778635	test: 0.725281
PRC train: 0.396463	val: 0.313084	test: 0.169285

Epoch: 11
Loss: 0.12263524835023405
ROC train: 0.856079	val: 0.793443	test: 0.713376
PRC train: 0.426254	val: 0.292962	test: 0.157459

Epoch: 12
Loss: 0.12207297611703538
ROC train: 0.857158	val: 0.816027	test: 0.732996
PRC train: 0.439771	val: 0.375886	test: 0.186937

Epoch: 13
Loss: 0.11937463173524256
ROC train: 0.849111	val: 0.778032	test: 0.707853
PRC train: 0.447605	val: 0.361073	test: 0.172390

Epoch: 14
Loss: 0.11883916115550368
ROC train: 0.867595	val: 0.798743	test: 0.721273
PRC train: 0.453833	val: 0.352052	test: 0.211472

Epoch: 15
Loss: 0.11635253546198368
ROC train: 0.875608	val: 0.806600	test: 0.715414
PRC train: 0.492934	val: 0.367847	test: 0.211466

Epoch: 16
Loss: 0.11580050535646974
ROC train: 0.871956	val: 0.797059	test: 0.714678
PRC train: 0.439334	val: 0.375642	test: 0.223147

Epoch: 17
Loss: 0.11595877044595851
ROC train: 0.877573	val: 0.812919	test: 0.724404
PRC train: 0.507346	val: 0.352125	test: 0.211411

Epoch: 18
Loss: 0.11327929439024122
ROC train: 0.878760	val: 0.814285	test: 0.728280
PRC train: 0.494851	val: 0.366301	test: 0.221619

Epoch: 19
Loss: 0.11282375330757217
ROC train: 0.888163	val: 0.822620	test: 0.703926
PRC train: 0.531808	val: 0.373144	test: 0.160854

Epoch: 20
Loss: 0.11083815157673965
ROC train: 0.893402	val: 0.822865	test: 0.709164
PRC train: 0.550374	val: 0.388968	test: 0.177188

Epoch: 21
Loss: 0.11102234651858776
ROC train: 0.879276	val: 0.807708	test: 0.735567
PRC train: 0.502931	val: 0.346770	test: 0.198166

Epoch: 22
Loss: 0.10828863783877508
ROC train: 0.898784	val: 0.814640	test: 0.713436
PRC train: 0.553053	val: 0.367057	test: 0.184370

Epoch: 23
Loss: 0.1072548113920026
ROC train: 0.899360	val: 0.803232	test: 0.720678
PRC train: 0.550216	val: 0.327206	test: 0.177765

Epoch: 24
Loss: 0.10591144873684336
ROC train: 0.893219	val: 0.792662	test: 0.717494
PRC train: 0.538953	val: 0.375940	test: 0.216727

Epoch: 25
Loss: 0.10773997491797345
ROC train: 0.912371	val: 0.825642	test: 0.725574
PRC train: 0.584058	val: 0.384151	test: 0.152180

Epoch: 26
Loss: 0.10559552581360727
ROC train: 0.915883	val: 0.812521	test: 0.713572
PRC train: 0.598103	val: 0.396259	test: 0.192269

Epoch: 27
Loss: 0.10504217416464134
ROC train: 0.910266	val: 0.798470	test: 0.692765
PRC train: 0.600727	val: 0.339116	test: 0.157387

Epoch: 28
Loss: 0.10286585392883384
ROC train: 0.913804	val: 0.828064	test: 0.718311
PRC train: 0.602311	val: 0.400897	test: 0.195262

Epoch: 29
Loss: 0.10222296884633082
ROC train: 0.913528	val: 0.818722	test: 0.747838
PRC train: 0.599438	val: 0.398056	test: 0.170311

Epoch: 30
Loss: 0.10254205179893643
ROC train: 0.920760	val: 0.788415	test: 0.703463
PRC train: 0.602707	val: 0.368842	test: 0.193192

Epoch: 31
Loss: 0.09914661474323287
ROC train: 0.927234	val: 0.813780	test: 0.735785
PRC train: 0.632759	val: 0.371129	test: 0.193158

Epoch: 32
Loss: 0.09903167485210963
ROC train: 0.931493	val: 0.833052	test: 0.733125Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.2.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:3
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.2
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/hiv/noise=0.2
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/hiv/noise=0.2/hiv_scaff_4_26-05_11-28-51  ]
[ Using Seed :  4  ]
[ Using device :  cuda:3  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.2867880115144636
ROC train: 0.700322	val: 0.716656	test: 0.645553
PRC train: 0.125725	val: 0.148416	test: 0.179846

Epoch: 2
Loss: 0.15302763099617908
ROC train: 0.733626	val: 0.728579	test: 0.706095
PRC train: 0.145955	val: 0.172323	test: 0.208411

Epoch: 3
Loss: 0.1483583364644302
ROC train: 0.731241	val: 0.719745	test: 0.751755
PRC train: 0.153385	val: 0.156914	test: 0.219608

Epoch: 4
Loss: 0.1456928283591273
ROC train: 0.761658	val: 0.697271	test: 0.744951
PRC train: 0.187637	val: 0.159403	test: 0.202425

Epoch: 5
Loss: 0.14280006766973838
ROC train: 0.769902	val: 0.690360	test: 0.667052
PRC train: 0.227574	val: 0.205250	test: 0.169261

Epoch: 6
Loss: 0.1411010949497549
ROC train: 0.797085	val: 0.753720	test: 0.723774
PRC train: 0.253848	val: 0.224600	test: 0.168610

Epoch: 7
Loss: 0.13926496004137
ROC train: 0.793860	val: 0.748236	test: 0.744140
PRC train: 0.268614	val: 0.268785	test: 0.222219

Epoch: 8
Loss: 0.13744583433653376
ROC train: 0.819768	val: 0.786593	test: 0.749800
PRC train: 0.323251	val: 0.272317	test: 0.241050

Epoch: 9
Loss: 0.13529279420092752
ROC train: 0.815590	val: 0.784459	test: 0.740547
PRC train: 0.293094	val: 0.237709	test: 0.206617

Epoch: 10
Loss: 0.13327507025409163
ROC train: 0.828643	val: 0.784937	test: 0.744466
PRC train: 0.357517	val: 0.281459	test: 0.233973

Epoch: 11
Loss: 0.1319350560010077
ROC train: 0.839839	val: 0.792071	test: 0.730167
PRC train: 0.378065	val: 0.267749	test: 0.213269

Epoch: 12
Loss: 0.130914016415783
ROC train: 0.839858	val: 0.796168	test: 0.747705
PRC train: 0.352940	val: 0.333676	test: 0.222837

Epoch: 13
Loss: 0.1290401026176606
ROC train: 0.845904	val: 0.778804	test: 0.715321
PRC train: 0.384703	val: 0.301132	test: 0.157814

Epoch: 14
Loss: 0.12680270532883425
ROC train: 0.849527	val: 0.790209	test: 0.754599
PRC train: 0.381758	val: 0.321761	test: 0.196869

Epoch: 15
Loss: 0.1263910017832569
ROC train: 0.853751	val: 0.777808	test: 0.752467
PRC train: 0.382548	val: 0.238558	test: 0.178410

Epoch: 16
Loss: 0.12496376413856594
ROC train: 0.864368	val: 0.796054	test: 0.757942
PRC train: 0.410798	val: 0.344675	test: 0.276933

Epoch: 17
Loss: 0.12327250149364691
ROC train: 0.863932	val: 0.779771	test: 0.761031
PRC train: 0.443251	val: 0.300241	test: 0.258965

Epoch: 18
Loss: 0.12138667164973528
ROC train: 0.876852	val: 0.798917	test: 0.764316
PRC train: 0.451186	val: 0.362461	test: 0.265460

Epoch: 19
Loss: 0.11959961892606415
ROC train: 0.882759	val: 0.785255	test: 0.738462
PRC train: 0.491212	val: 0.322789	test: 0.244978

Epoch: 20
Loss: 0.11904559638039472
ROC train: 0.878479	val: 0.777909	test: 0.741192
PRC train: 0.469164	val: 0.302781	test: 0.265230

Epoch: 21
Loss: 0.11757570989726103
ROC train: 0.886970	val: 0.797411	test: 0.769547
PRC train: 0.485666	val: 0.354150	test: 0.268667

Epoch: 22
Loss: 0.11428028173277506
ROC train: 0.892745	val: 0.786379	test: 0.742975
PRC train: 0.505551	val: 0.322128	test: 0.213330

Epoch: 23
Loss: 0.1148452891022305
ROC train: 0.913484	val: 0.785286	test: 0.730047
PRC train: 0.543383	val: 0.301512	test: 0.228441

Epoch: 24
Loss: 0.1114023988075004
ROC train: 0.910947	val: 0.789600	test: 0.748029
PRC train: 0.513436	val: 0.305368	test: 0.264255

Epoch: 25
Loss: 0.11039483497171156
ROC train: 0.917915	val: 0.817564	test: 0.743798
PRC train: 0.565407	val: 0.310239	test: 0.220274

Epoch: 26
Loss: 0.10839214695362702
ROC train: 0.912041	val: 0.812929	test: 0.754864
PRC train: 0.561280	val: 0.319500	test: 0.249557

Epoch: 27
Loss: 0.10804843595509528
ROC train: 0.925635	val: 0.796685	test: 0.745229
PRC train: 0.593652	val: 0.275901	test: 0.235614

Epoch: 28
Loss: 0.104567823981223
ROC train: 0.919195	val: 0.787153	test: 0.735424
PRC train: 0.556308	val: 0.273756	test: 0.215552

Epoch: 29
Loss: 0.105154585567613
ROC train: 0.931342	val: 0.797392	test: 0.745087
PRC train: 0.587436	val: 0.279690	test: 0.202254

Epoch: 30
Loss: 0.10341615437239127
ROC train: 0.943184	val: 0.790803	test: 0.749524
PRC train: 0.658651	val: 0.264278	test: 0.239516

Epoch: 31
Loss: 0.10126926562810398
ROC train: 0.945456	val: 0.805562	test: 0.759596
PRC train: 0.648430	val: 0.307301	test: 0.242887

Epoch: 32
Loss: 0.09909941980800457
ROC train: 0.943774	val: 0.783011	test: 0.748048Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.2.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:3
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.2
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/hiv/noise=0.2
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/hiv/noise=0.2/hiv_scaff_6_26-05_11-28-51  ]
[ Using Seed :  6  ]
[ Using device :  cuda:3  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.2589523825829249
ROC train: 0.690903	val: 0.640016	test: 0.634597
PRC train: 0.098723	val: 0.112863	test: 0.112573

Epoch: 2
Loss: 0.15381311456593005
ROC train: 0.738159	val: 0.702393	test: 0.656867
PRC train: 0.147266	val: 0.134687	test: 0.155501

Epoch: 3
Loss: 0.1486192536178992
ROC train: 0.748875	val: 0.732033	test: 0.686979
PRC train: 0.165885	val: 0.160989	test: 0.160718

Epoch: 4
Loss: 0.14599707064182754
ROC train: 0.778468	val: 0.709218	test: 0.682458
PRC train: 0.208944	val: 0.187361	test: 0.179161

Epoch: 5
Loss: 0.14212928739571257
ROC train: 0.786555	val: 0.755331	test: 0.707992
PRC train: 0.230400	val: 0.167732	test: 0.115275

Epoch: 6
Loss: 0.14089095058666837
ROC train: 0.801183	val: 0.759709	test: 0.725991
PRC train: 0.284642	val: 0.201631	test: 0.150018

Epoch: 7
Loss: 0.1368751988566315
ROC train: 0.804422	val: 0.755337	test: 0.723873
PRC train: 0.272953	val: 0.261023	test: 0.158289

Epoch: 8
Loss: 0.1358585602712182
ROC train: 0.810736	val: 0.715364	test: 0.702518
PRC train: 0.289282	val: 0.153545	test: 0.106900

Epoch: 9
Loss: 0.13380540326730517
ROC train: 0.827968	val: 0.745043	test: 0.734373
PRC train: 0.341887	val: 0.250656	test: 0.221461

Epoch: 10
Loss: 0.13202410329593162
ROC train: 0.836479	val: 0.767052	test: 0.723645
PRC train: 0.351892	val: 0.224624	test: 0.160110

Epoch: 11
Loss: 0.13064298587331288
ROC train: 0.843958	val: 0.770705	test: 0.737038
PRC train: 0.372313	val: 0.284981	test: 0.199461

Epoch: 12
Loss: 0.129396029380495
ROC train: 0.844377	val: 0.743986	test: 0.740312
PRC train: 0.371786	val: 0.250158	test: 0.227720

Epoch: 13
Loss: 0.12751674856231734
ROC train: 0.859314	val: 0.758488	test: 0.747969
PRC train: 0.405636	val: 0.243852	test: 0.183261

Epoch: 14
Loss: 0.125402929312485
ROC train: 0.859486	val: 0.777637	test: 0.737631
PRC train: 0.401627	val: 0.324040	test: 0.246960

Epoch: 15
Loss: 0.12302856697961881
ROC train: 0.861818	val: 0.799790	test: 0.726038
PRC train: 0.422009	val: 0.319367	test: 0.221021

Epoch: 16
Loss: 0.1224352784437487
ROC train: 0.874978	val: 0.773341	test: 0.756708
PRC train: 0.458120	val: 0.327976	test: 0.247001

Epoch: 17
Loss: 0.12032543625626282
ROC train: 0.876900	val: 0.742651	test: 0.742594
PRC train: 0.442578	val: 0.285412	test: 0.194314

Epoch: 18
Loss: 0.12015430192745688
ROC train: 0.887548	val: 0.719185	test: 0.713484
PRC train: 0.485004	val: 0.255139	test: 0.168736

Epoch: 19
Loss: 0.11819575918061695
ROC train: 0.890174	val: 0.763476	test: 0.756183
PRC train: 0.495452	val: 0.283672	test: 0.247033

Epoch: 20
Loss: 0.11786821827552497
ROC train: 0.892269	val: 0.767364	test: 0.743746
PRC train: 0.496717	val: 0.313045	test: 0.181393

Epoch: 21
Loss: 0.11349778603407851
ROC train: 0.898659	val: 0.775132	test: 0.759930
PRC train: 0.505383	val: 0.271058	test: 0.203523

Epoch: 22
Loss: 0.11331786020399304
ROC train: 0.924070	val: 0.732872	test: 0.737845
PRC train: 0.566135	val: 0.267744	test: 0.198599

Epoch: 23
Loss: 0.11126923436195933
ROC train: 0.918516	val: 0.726824	test: 0.742374
PRC train: 0.565130	val: 0.312513	test: 0.219791

Epoch: 24
Loss: 0.10969649439255337
ROC train: 0.904296	val: 0.752015	test: 0.700350
PRC train: 0.542556	val: 0.301737	test: 0.173257

Epoch: 25
Loss: 0.10799720069165153
ROC train: 0.917937	val: 0.760527	test: 0.732413
PRC train: 0.567327	val: 0.290229	test: 0.202748

Epoch: 26
Loss: 0.10780700781037447
ROC train: 0.929114	val: 0.761810	test: 0.737670
PRC train: 0.607213	val: 0.269201	test: 0.176485

Epoch: 27
Loss: 0.10445199727795891
ROC train: 0.936978	val: 0.771926	test: 0.733378
PRC train: 0.629359	val: 0.274443	test: 0.190453

Epoch: 28
Loss: 0.10278319843942334
ROC train: 0.914981	val: 0.804089	test: 0.735976
PRC train: 0.593550	val: 0.288158	test: 0.179461

Epoch: 29
Loss: 0.10113746548755709
ROC train: 0.943116	val: 0.731494	test: 0.709757
PRC train: 0.660438	val: 0.264061	test: 0.218213

Epoch: 30
Loss: 0.09922685761467061
ROC train: 0.937993	val: 0.750814	test: 0.730841
PRC train: 0.653422	val: 0.298186	test: 0.201463

Epoch: 31
Loss: 0.0985814178801224
ROC train: 0.941999	val: 0.744087	test: 0.726401
PRC train: 0.659783	val: 0.314269	test: 0.189201

Epoch: 32
Loss: 0.09714060988691504
ROC train: 0.953652	val: 0.751730	test: 0.727926Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/hiv/noise=0.2.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:3
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.2
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/hiv/noise=0.2
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/hiv/noise=0.2/hiv_scaff_5_26-05_11-28-51  ]
[ Using Seed :  5  ]
[ Using device :  cuda:3  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.2353451549927261
ROC train: 0.705473	val: 0.708627	test: 0.681914
PRC train: 0.106749	val: 0.148039	test: 0.136024

Epoch: 2
Loss: 0.15237816560406792
ROC train: 0.730228	val: 0.699487	test: 0.709100
PRC train: 0.149519	val: 0.158829	test: 0.138604

Epoch: 3
Loss: 0.1483423808832064
ROC train: 0.758026	val: 0.760649	test: 0.706051
PRC train: 0.195430	val: 0.235965	test: 0.197422

Epoch: 4
Loss: 0.14534321404900807
ROC train: 0.781101	val: 0.746917	test: 0.717125
PRC train: 0.241569	val: 0.234860	test: 0.215025

Epoch: 5
Loss: 0.14123281189822856
ROC train: 0.787471	val: 0.765196	test: 0.701485
PRC train: 0.248416	val: 0.234604	test: 0.187918

Epoch: 6
Loss: 0.13907589704477696
ROC train: 0.800905	val: 0.740358	test: 0.707033
PRC train: 0.261632	val: 0.243589	test: 0.180449

Epoch: 7
Loss: 0.13747652622167125
ROC train: 0.803169	val: 0.694781	test: 0.692926
PRC train: 0.277223	val: 0.213757	test: 0.178200

Epoch: 8
Loss: 0.1355849693391773
ROC train: 0.817054	val: 0.732054	test: 0.704266
PRC train: 0.301813	val: 0.198464	test: 0.174863

Epoch: 9
Loss: 0.13434343736630985
ROC train: 0.826984	val: 0.759051	test: 0.723131
PRC train: 0.343997	val: 0.234923	test: 0.197105

Epoch: 10
Loss: 0.13273748364237178
ROC train: 0.835349	val: 0.754608	test: 0.700126
PRC train: 0.347686	val: 0.255102	test: 0.156108

Epoch: 11
Loss: 0.13017052739551147
ROC train: 0.853819	val: 0.773984	test: 0.727144
PRC train: 0.387592	val: 0.295685	test: 0.237963

Epoch: 12
Loss: 0.12869076559501985
ROC train: 0.848764	val: 0.733842	test: 0.718338
PRC train: 0.365135	val: 0.250706	test: 0.196576

Epoch: 13
Loss: 0.1276596025511976
ROC train: 0.854166	val: 0.762744	test: 0.719144
PRC train: 0.396475	val: 0.254026	test: 0.214861

Epoch: 14
Loss: 0.12700832690265612
ROC train: 0.870078	val: 0.743288	test: 0.704587
PRC train: 0.429245	val: 0.308343	test: 0.274166

Epoch: 15
Loss: 0.12495325570783132
ROC train: 0.870139	val: 0.739479	test: 0.711031
PRC train: 0.419709	val: 0.279825	test: 0.166360

Epoch: 16
Loss: 0.12294886315249685
ROC train: 0.859547	val: 0.742253	test: 0.719355
PRC train: 0.397683	val: 0.332903	test: 0.198055

Epoch: 17
Loss: 0.12119200806659425
ROC train: 0.877768	val: 0.739047	test: 0.694071
PRC train: 0.449218	val: 0.297213	test: 0.153885

Epoch: 18
Loss: 0.1200292998471338
ROC train: 0.877865	val: 0.771556	test: 0.699774
PRC train: 0.402040	val: 0.323029	test: 0.198899

Epoch: 19
Loss: 0.11933466329099811
ROC train: 0.888002	val: 0.712816	test: 0.696319
PRC train: 0.469288	val: 0.346169	test: 0.182136

Epoch: 20
Loss: 0.11668529884844321
ROC train: 0.894006	val: 0.772796	test: 0.710186
PRC train: 0.475676	val: 0.299712	test: 0.199093

Epoch: 21
Loss: 0.11690086617497612
ROC train: 0.895336	val: 0.724751	test: 0.714782
PRC train: 0.525750	val: 0.334047	test: 0.194388

Epoch: 22
Loss: 0.11355763245533147
ROC train: 0.909333	val: 0.766510	test: 0.687756
PRC train: 0.544187	val: 0.304690	test: 0.164411

Epoch: 23
Loss: 0.11302384394918438
ROC train: 0.903295	val: 0.736772	test: 0.706692
PRC train: 0.515015	val: 0.237746	test: 0.130415

Epoch: 24
Loss: 0.11152148303599234
ROC train: 0.906180	val: 0.742915	test: 0.732465
PRC train: 0.531777	val: 0.334763	test: 0.202518

Epoch: 25
Loss: 0.11060855793426476
ROC train: 0.904099	val: 0.745468	test: 0.686446
PRC train: 0.550142	val: 0.323808	test: 0.148000

Epoch: 26
Loss: 0.10938771589820326
ROC train: 0.919149	val: 0.734265	test: 0.720512
PRC train: 0.588324	val: 0.310640	test: 0.175437

Epoch: 27
Loss: 0.10666382521606256
ROC train: 0.921810	val: 0.743809	test: 0.694148
PRC train: 0.595776	val: 0.312669	test: 0.150954

Epoch: 28
Loss: 0.10590558726639958
ROC train: 0.928410	val: 0.777116	test: 0.735597
PRC train: 0.613584	val: 0.289408	test: 0.187290

Epoch: 29
Loss: 0.10359112389941001
ROC train: 0.929545	val: 0.744041	test: 0.715779
PRC train: 0.602428	val: 0.318260	test: 0.196253

Epoch: 30
Loss: 0.10224227841850002
ROC train: 0.941250	val: 0.776623	test: 0.725698
PRC train: 0.623104	val: 0.301438	test: 0.183317

Epoch: 31
Loss: 0.10217286779449165
ROC train: 0.944522	val: 0.768065	test: 0.707434
PRC train: 0.659352	val: 0.291417	test: 0.163417

Epoch: 32
Loss: 0.09914151119574185
ROC train: 0.935903	val: 0.758941	test: 0.727838
ROC train: 0.920515	val: 0.781893	test: 0.745480
PRC train: 0.583833	val: 0.316695	test: 0.137903

Epoch: 34
Loss: 0.09913441859907067
ROC train: 0.925517	val: 0.783883	test: 0.764775
PRC train: 0.594408	val: 0.358228	test: 0.156887

Epoch: 35
Loss: 0.09898296380442523
ROC train: 0.926693	val: 0.798905	test: 0.767226
PRC train: 0.593522	val: 0.355219	test: 0.166976

Epoch: 36
Loss: 0.09893122986303346
ROC train: 0.931860	val: 0.770053	test: 0.751685
PRC train: 0.609307	val: 0.355362	test: 0.192840

Epoch: 37
Loss: 0.09762127996491653
ROC train: 0.926409	val: 0.795292	test: 0.744727
PRC train: 0.587396	val: 0.358169	test: 0.188755

Epoch: 38
Loss: 0.09828495108652806
ROC train: 0.922452	val: 0.772652	test: 0.751409
PRC train: 0.596121	val: 0.319009	test: 0.166153

Epoch: 39
Loss: 0.09728221401163827
ROC train: 0.937161	val: 0.771066	test: 0.757017
PRC train: 0.627798	val: 0.368868	test: 0.187698

Epoch: 40
Loss: 0.09633757502592344
ROC train: 0.924712	val: 0.793804	test: 0.754406
PRC train: 0.592676	val: 0.359876	test: 0.199280

Epoch: 41
Loss: 0.09716534433530902
ROC train: 0.937672	val: 0.791250	test: 0.745300
PRC train: 0.628339	val: 0.349719	test: 0.176385

Epoch: 42
Loss: 0.09663445637043294
ROC train: 0.938575	val: 0.795975	test: 0.754837
PRC train: 0.618039	val: 0.372834	test: 0.161817

Epoch: 43
Loss: 0.0956479329309504
ROC train: 0.939566	val: 0.782294	test: 0.747671
PRC train: 0.631358	val: 0.358085	test: 0.175978

Epoch: 44
Loss: 0.09572272807573794
ROC train: 0.940284	val: 0.789248	test: 0.742575
PRC train: 0.630717	val: 0.349858	test: 0.176388

Epoch: 45
Loss: 0.09428401796828885
ROC train: 0.942915	val: 0.789986	test: 0.752892
PRC train: 0.631889	val: 0.312332	test: 0.177211

Epoch: 46
Loss: 0.09302452536611988
ROC train: 0.938887	val: 0.775527	test: 0.741345
PRC train: 0.628980	val: 0.337909	test: 0.169925

Epoch: 47
Loss: 0.09240502117958674
ROC train: 0.934623	val: 0.801701	test: 0.744080
PRC train: 0.627149	val: 0.350411	test: 0.133355

Epoch: 48
Loss: 0.09427654057591195
ROC train: 0.943004	val: 0.797662	test: 0.743512
PRC train: 0.641359	val: 0.358930	test: 0.190617

Epoch: 49
Loss: 0.09165127303041139
ROC train: 0.941039	val: 0.763310	test: 0.756341
PRC train: 0.632164	val: 0.319206	test: 0.177792

Epoch: 50
Loss: 0.09321889893038877
ROC train: 0.942776	val: 0.784912	test: 0.737942
PRC train: 0.641309	val: 0.369234	test: 0.124827

Epoch: 51
Loss: 0.091725101703689
ROC train: 0.950310	val: 0.790428	test: 0.743481
PRC train: 0.658589	val: 0.341916	test: 0.188295

Epoch: 52
Loss: 0.09157567278446356
ROC train: 0.947741	val: 0.791875	test: 0.755882
PRC train: 0.656611	val: 0.324043	test: 0.164158

Epoch: 53
Loss: 0.08995209109685842
ROC train: 0.953781	val: 0.798394	test: 0.743099
PRC train: 0.667668	val: 0.349274	test: 0.167336

Epoch: 54
Loss: 0.08937274927882702
ROC train: 0.951529	val: 0.788804	test: 0.756061
PRC train: 0.650443	val: 0.320681	test: 0.192330

Epoch: 55
Loss: 0.08952292901190742
ROC train: 0.950169	val: 0.778304	test: 0.718635
PRC train: 0.666304	val: 0.327904	test: 0.144129

Epoch: 56
Loss: 0.08777647536011317
ROC train: 0.953945	val: 0.793807	test: 0.741067
PRC train: 0.679251	val: 0.326395	test: 0.152243

Epoch: 57
Loss: 0.08909485441935036
ROC train: 0.956797	val: 0.795026	test: 0.738755
PRC train: 0.680630	val: 0.352360	test: 0.197820

Epoch: 58
Loss: 0.08964170596054635
ROC train: 0.956805	val: 0.782631	test: 0.744470
PRC train: 0.677190	val: 0.351770	test: 0.186968

Epoch: 59
Loss: 0.087865102690339
ROC train: 0.951529	val: 0.796036	test: 0.738512
PRC train: 0.661709	val: 0.366438	test: 0.162583

Epoch: 60
Loss: 0.089097013792246
ROC train: 0.953717	val: 0.799505	test: 0.748921
PRC train: 0.676027	val: 0.330890	test: 0.187558

Epoch: 61
Loss: 0.08763449979281998
ROC train: 0.955459	val: 0.798317	test: 0.759064
PRC train: 0.685969	val: 0.333067	test: 0.187513

Epoch: 62
Loss: 0.08778329408659573
ROC train: 0.959063	val: 0.799282	test: 0.749702
PRC train: 0.691364	val: 0.313307	test: 0.180871

Epoch: 63
Loss: 0.08659064166123717
ROC train: 0.958349	val: 0.789875	test: 0.765401
PRC train: 0.684140	val: 0.320288	test: 0.200006

Epoch: 64
Loss: 0.08620605806259352
ROC train: 0.961370	val: 0.801523	test: 0.757261
PRC train: 0.697146	val: 0.334914	test: 0.217052

Epoch: 65
Loss: 0.08608420628765293
ROC train: 0.959126	val: 0.776786	test: 0.765894
PRC train: 0.691637	val: 0.297419	test: 0.162283

Epoch: 66
Loss: 0.08470735694706236
ROC train: 0.958442	val: 0.783920	test: 0.742604
PRC train: 0.684591	val: 0.330097	test: 0.171175

Epoch: 67
Loss: 0.08498426573799546
ROC train: 0.963586	val: 0.797001	test: 0.745067
PRC train: 0.700687	val: 0.302904	test: 0.163860

Epoch: 68
Loss: 0.08438163930729795
ROC train: 0.963027	val: 0.797399	test: 0.743875
PRC train: 0.701217	val: 0.350490	test: 0.144016

Epoch: 69
Loss: 0.08473482065969211
ROC train: 0.963276	val: 0.800047	test: 0.763315
PRC train: 0.707404	val: 0.325047	test: 0.172199

Epoch: 70
Loss: 0.08237595883964147
ROC train: 0.967981	val: 0.786847	test: 0.738883
PRC train: 0.724898	val: 0.307445	test: 0.160400

Epoch: 71
Loss: 0.08248656108081555
ROC train: 0.966821	val: 0.779419	test: 0.758336
PRC train: 0.719075	val: 0.330166	test: 0.159899

Epoch: 72
Loss: 0.08358567814532342
ROC train: 0.967448	val: 0.797310	test: 0.746631
PRC train: 0.706749	val: 0.324049	test: 0.148950

Epoch: 73
Loss: 0.08057973010906072
ROC train: 0.967657	val: 0.801720	test: 0.743377
PRC train: 0.728715	val: 0.327194	test: 0.132839

Epoch: 74
Loss: 0.08127928090790904
ROC train: 0.967447	val: 0.799122	test: 0.772271
PRC train: 0.726370	val: 0.336483	test: 0.191176

Epoch: 75
Loss: 0.08134473956576936
ROC train: 0.969124	val: 0.786957	test: 0.729166
PRC train: 0.727887	val: 0.345612	test: 0.155079

Epoch: 76
Loss: 0.08269482613468625
ROC train: 0.970212	val: 0.791333	test: 0.719755
PRC train: 0.733832	val: 0.357976	test: 0.173705

Epoch: 77
Loss: 0.08092990296166565
ROC train: 0.969246	val: 0.792793	test: 0.736173
PRC train: 0.727639	val: 0.338456	test: 0.157629

Epoch: 78
Loss: 0.08128655312943883
ROC train: 0.970818	val: 0.802913	test: 0.747948
PRC train: 0.735964	val: 0.352563	test: 0.147698

Epoch: 79
Loss: 0.0808406312609027
ROC train: 0.970439	val: 0.806649	test: 0.741272
PRC train: 0.738534	val: 0.363793	test: 0.155031

Epoch: 80
Loss: 0.08023925977771758
ROC train: 0.970729	val: 0.808422	test: 0.748498
PRC train: 0.741632	val: 0.330407	test: 0.139687

Epoch: 81
Loss: 0.07763868293842219
ROC train: 0.969688	val: 0.786238	test: 0.748541
PRC train: 0.743018	val: 0.310258	test: 0.166354

Epoch: 82
Loss: 0.08081753668445558
ROC train: 0.972890	val: 0.810908	test: 0.749713
PRC train: 0.749744	val: 0.357379	test: 0.187955

Epoch: 83
Loss: 0.07956451811901664
ROC train: 0.972260	val: 0.821202	test: 0.762477
PRC train: 0.738583	val: 0.345169	test: 0.183068

Epoch: 84
Loss: 0.0789137528563096
ROC train: 0.976372	val: 0.794432	test: 0.746366
PRC train: 0.769309	val: 0.368656	test: 0.190007

Epoch: 85
Loss: 0.07835627697042308
ROC train: 0.970254	val: 0.789358	test: 0.736376
PRC train: 0.738987	val: 0.310526	test: 0.167751

Epoch: 86
Loss: 0.07742995143225403
ROC train: 0.969437	val: 0.787812	test: 0.747013
PRC train: 0.726429	val: 0.319521	test: 0.208927

Epoch: 87
Loss: 0.07753807194973432
ROC train: 0.969626	val: 0.789808	test: 0.754120
PRC train: 0.722321	val: 0.268274	test: 0.174772

Epoch: 88
Loss: 0.0784664945115759
ROC train: 0.976398	val: 0.793755	test: 0.744725
PRC train: 0.765705	val: 0.298648	test: 0.149611

Epoch: 89
Loss: 0.075629224004682
ROC train: 0.977816	val: 0.800898	test: 0.750942
PRC train: 0.774028	val: 0.323581	test: 0.157784

Epoch: 90
Loss: 0.07638157308912129
ROC train: 0.975253	val: 0.792074	test: 0.738778
PRC train: 0.749623	val: 0.299143	test: 0.153987

Epoch: 91
Loss: 0.07565399033052703
ROC train: 0.976643	val: 0.804894	test: 0.738419
PRC train: 0.766257	val: 0.350170	test: 0.168236

Epoch: 92
Loss: 0.07379751849180254
ROC train: 0.978611	val: 0.805063	test: 0.747098
PRC train: 0.779120	val: 0.326714	test: 0.165761

Epoch: 93
Loss: 0.07651224790945244
ROC train: 0.976988	val: 0.799931	test: 0.737198
PRC train: 0.761622	val: 0.301758	test: 0.157944

Epoch: 94
Loss: 0.07460108196265533
PRC train: 0.658781	val: 0.357397	test: 0.187021

Epoch: 33
Loss: 0.09668332077936154
ROC train: 0.936911	val: 0.779765	test: 0.740818
PRC train: 0.665635	val: 0.310473	test: 0.152858

Epoch: 34
Loss: 0.09824908955214659
ROC train: 0.934033	val: 0.769964	test: 0.740511
PRC train: 0.639713	val: 0.345051	test: 0.224815

Epoch: 35
Loss: 0.09473922213792757
ROC train: 0.941673	val: 0.760962	test: 0.741988
PRC train: 0.673854	val: 0.338594	test: 0.220157

Epoch: 36
Loss: 0.09245142664856273
ROC train: 0.942818	val: 0.743068	test: 0.708258
PRC train: 0.701275	val: 0.345163	test: 0.192847

Epoch: 37
Loss: 0.09388504786387282
ROC train: 0.949404	val: 0.784076	test: 0.752882
PRC train: 0.707390	val: 0.317193	test: 0.195062

Epoch: 38
Loss: 0.09201760796091461
ROC train: 0.950966	val: 0.766709	test: 0.728461
PRC train: 0.698043	val: 0.345139	test: 0.194609

Epoch: 39
Loss: 0.08998561687124194
ROC train: 0.947617	val: 0.787065	test: 0.728158
PRC train: 0.685732	val: 0.335264	test: 0.206249

Epoch: 40
Loss: 0.08884390428438446
ROC train: 0.950460	val: 0.777505	test: 0.724425
PRC train: 0.710066	val: 0.319853	test: 0.204980

Epoch: 41
Loss: 0.08988954324381676
ROC train: 0.955597	val: 0.778868	test: 0.721163
PRC train: 0.725785	val: 0.316380	test: 0.174440

Epoch: 42
Loss: 0.0863233604051895
ROC train: 0.958091	val: 0.779982	test: 0.735804
PRC train: 0.745034	val: 0.338473	test: 0.210686

Epoch: 43
Loss: 0.08579562724052328
ROC train: 0.959317	val: 0.787833	test: 0.728409
PRC train: 0.753180	val: 0.337143	test: 0.224905

Epoch: 44
Loss: 0.08507850914560564
ROC train: 0.961285	val: 0.777484	test: 0.732490
PRC train: 0.720775	val: 0.325197	test: 0.223235

Epoch: 45
Loss: 0.08393423662324127
ROC train: 0.963391	val: 0.779419	test: 0.733083
PRC train: 0.767281	val: 0.340802	test: 0.142886

Epoch: 46
Loss: 0.0813540685494455
ROC train: 0.965248	val: 0.789015	test: 0.743784
PRC train: 0.757591	val: 0.315507	test: 0.183816

Epoch: 47
Loss: 0.08268203942718087
ROC train: 0.964593	val: 0.769893	test: 0.756701
PRC train: 0.754848	val: 0.354237	test: 0.193760

Epoch: 48
Loss: 0.08158341986998717
ROC train: 0.968962	val: 0.778445	test: 0.731242
PRC train: 0.776696	val: 0.314354	test: 0.159092

Epoch: 49
Loss: 0.08096438402311923
ROC train: 0.965925	val: 0.778846	test: 0.748979
PRC train: 0.781772	val: 0.325055	test: 0.198397

Epoch: 50
Loss: 0.07978529461124265
ROC train: 0.974692	val: 0.776293	test: 0.721404
PRC train: 0.822182	val: 0.276480	test: 0.129471

Epoch: 51
Loss: 0.07622587869287713
ROC train: 0.971798	val: 0.783133	test: 0.742639
PRC train: 0.778979	val: 0.320286	test: 0.219357

Epoch: 52
Loss: 0.07887831224774158
ROC train: 0.975796	val: 0.774694	test: 0.758130
PRC train: 0.815432	val: 0.343907	test: 0.205636

Epoch: 53
Loss: 0.07596599473440682
ROC train: 0.976606	val: 0.766666	test: 0.734993
PRC train: 0.822379	val: 0.335586	test: 0.196264

Epoch: 54
Loss: 0.07661862516913112
ROC train: 0.978948	val: 0.773513	test: 0.739541
PRC train: 0.846935	val: 0.335791	test: 0.208429

Epoch: 55
Loss: 0.07566710830831427
ROC train: 0.977090	val: 0.790329	test: 0.727996
PRC train: 0.832480	val: 0.334763	test: 0.190963

Epoch: 56
Loss: 0.07491046586003866
ROC train: 0.977058	val: 0.775901	test: 0.734064
PRC train: 0.827382	val: 0.291044	test: 0.153840

Epoch: 57
Loss: 0.07145888517330867
ROC train: 0.977888	val: 0.795182	test: 0.736044
PRC train: 0.837265	val: 0.328860	test: 0.219528

Epoch: 58
Loss: 0.07126622667133234
ROC train: 0.982536	val: 0.772784	test: 0.741575
PRC train: 0.856596	val: 0.303524	test: 0.174018

Epoch: 59
Loss: 0.0712540800180852
ROC train: 0.977021	val: 0.773705	test: 0.766805
PRC train: 0.822951	val: 0.352699	test: 0.231210

Epoch: 60
Loss: 0.06965584933510038
ROC train: 0.982446	val: 0.772511	test: 0.742013
PRC train: 0.855488	val: 0.294074	test: 0.173035

Epoch: 61
Loss: 0.0686739195701831
ROC train: 0.981427	val: 0.784042	test: 0.733245
PRC train: 0.857481	val: 0.316648	test: 0.168293

Epoch: 62
Loss: 0.06630791436494937
ROC train: 0.983918	val: 0.792894	test: 0.709251
PRC train: 0.872288	val: 0.311208	test: 0.162603

Epoch: 63
Loss: 0.06652803596003257
ROC train: 0.987918	val: 0.778748	test: 0.719805
PRC train: 0.893543	val: 0.250534	test: 0.122985

Epoch: 64
Loss: 0.06560781928907274
ROC train: 0.984267	val: 0.785203	test: 0.752193
PRC train: 0.871945	val: 0.323433	test: 0.173213

Epoch: 65
Loss: 0.06455877284064641
ROC train: 0.987687	val: 0.782104	test: 0.733460
PRC train: 0.892767	val: 0.319412	test: 0.156490

Epoch: 66
Loss: 0.06152026063929905
ROC train: 0.985123	val: 0.766516	test: 0.728639
PRC train: 0.871128	val: 0.355009	test: 0.203470

Epoch: 67
Loss: 0.06297620954920546
ROC train: 0.985034	val: 0.768819	test: 0.770318
PRC train: 0.874413	val: 0.307245	test: 0.204452

Epoch: 68
Loss: 0.06197712597930369
ROC train: 0.988680	val: 0.771749	test: 0.737160
PRC train: 0.894800	val: 0.308481	test: 0.198774

Epoch: 69
Loss: 0.06313301771882722
ROC train: 0.989783	val: 0.788038	test: 0.715958
PRC train: 0.911308	val: 0.282884	test: 0.114379

Epoch: 70
Loss: 0.06126875786426302
ROC train: 0.990269	val: 0.788645	test: 0.730655
PRC train: 0.913158	val: 0.314330	test: 0.128931

Epoch: 71
Loss: 0.05972768405604014
ROC train: 0.985059	val: 0.794147	test: 0.728353
PRC train: 0.883373	val: 0.315089	test: 0.174829

Epoch: 72
Loss: 0.06004148400035641
ROC train: 0.991807	val: 0.781088	test: 0.741233
PRC train: 0.918966	val: 0.320286	test: 0.168386

Epoch: 73
Loss: 0.05776797259690163
ROC train: 0.991618	val: 0.785524	test: 0.737177
PRC train: 0.921556	val: 0.272362	test: 0.162819

Epoch: 74
Loss: 0.05748640331078143
ROC train: 0.992289	val: 0.812050	test: 0.747017
PRC train: 0.922936	val: 0.330137	test: 0.162349

Epoch: 75
Loss: 0.058303266395345124
ROC train: 0.991696	val: 0.790430	test: 0.753298
PRC train: 0.924327	val: 0.312242	test: 0.186580

Epoch: 76
Loss: 0.057026455111668525
ROC train: 0.992657	val: 0.780530	test: 0.737009
PRC train: 0.930836	val: 0.284037	test: 0.187181

Epoch: 77
Loss: 0.055158581347512815
ROC train: 0.992435	val: 0.794410	test: 0.746223
PRC train: 0.923873	val: 0.320756	test: 0.204278

Epoch: 78
Loss: 0.05553382987621464
ROC train: 0.991795	val: 0.779122	test: 0.731289
PRC train: 0.921542	val: 0.310471	test: 0.190071

Epoch: 79
Loss: 0.05258744627728717
ROC train: 0.992222	val: 0.780598	test: 0.731453
PRC train: 0.916010	val: 0.322004	test: 0.201786

Epoch: 80
Loss: 0.0512255450089339
ROC train: 0.989892	val: 0.790050	test: 0.726335
PRC train: 0.907925	val: 0.306677	test: 0.161138

Epoch: 81
Loss: 0.053541040724246806
ROC train: 0.995536	val: 0.818492	test: 0.756946
PRC train: 0.946830	val: 0.324468	test: 0.199683

Epoch: 82
Loss: 0.05587461426642339
ROC train: 0.994823	val: 0.797986	test: 0.755845
PRC train: 0.946333	val: 0.329903	test: 0.206265

Epoch: 83
Loss: 0.051851833111000105
ROC train: 0.992093	val: 0.803228	test: 0.756285
PRC train: 0.914318	val: 0.319322	test: 0.230819

Epoch: 84
Loss: 0.051951052499623084
ROC train: 0.996082	val: 0.799217	test: 0.740986
PRC train: 0.956270	val: 0.295478	test: 0.151632

Epoch: 85
Loss: 0.05126123830666108
ROC train: 0.995457	val: 0.785821	test: 0.750903
PRC train: 0.946856	val: 0.280667	test: 0.185364

Epoch: 86
Loss: 0.05140788871120465
ROC train: 0.995022	val: 0.783268	test: 0.747948
PRC train: 0.938674	val: 0.315935	test: 0.180454

Epoch: 87
Loss: 0.049844618093201294
ROC train: 0.994663	val: 0.785237	test: 0.744508
PRC train: 0.939490	val: 0.340032	test: 0.242492

Epoch: 88
Loss: 0.05017852132716949
ROC train: 0.995102	val: 0.782110	test: 0.745957
PRC train: 0.948579	val: 0.339757	test: 0.193058

Epoch: 89
Loss: 0.04696481298325749
ROC train: 0.994803	val: 0.780056	test: 0.761927
PRC train: 0.940114	val: 0.336274	test: 0.181284

Epoch: 90
Loss: 0.051035572494277356
ROC train: 0.996089	val: 0.782469	test: 0.743357
PRC train: 0.964058	val: 0.338699	test: 0.181739

Epoch: 91
Loss: 0.04969304142028232
ROC train: 0.997030	val: 0.772073	test: 0.742712
PRC train: 0.963886	val: 0.296448	test: 0.173921

Epoch: 92
Loss: 0.046744982425506114
ROC train: 0.997224	val: 0.774306	test: 0.741546
PRC train: 0.967543	val: 0.292382	test: 0.186725

Epoch: 93
Loss: 0.04721212235615325
ROC train: 0.997204	val: 0.806447	test: 0.753197
ROC train: 0.915671	val: 0.764403	test: 0.727720
PRC train: 0.579064	val: 0.319098	test: 0.192732

Epoch: 34
Loss: 0.10178431644967399
ROC train: 0.919724	val: 0.803247	test: 0.737025
PRC train: 0.579032	val: 0.335014	test: 0.166768

Epoch: 35
Loss: 0.10110105726990308
ROC train: 0.915691	val: 0.800528	test: 0.756478
PRC train: 0.556998	val: 0.337951	test: 0.222345

Epoch: 36
Loss: 0.10070418769922497
ROC train: 0.916114	val: 0.779649	test: 0.746787
PRC train: 0.582570	val: 0.333391	test: 0.207866

Epoch: 37
Loss: 0.09950390860483951
ROC train: 0.924947	val: 0.789967	test: 0.758205
PRC train: 0.597563	val: 0.346200	test: 0.224612

Epoch: 38
Loss: 0.09944888830805346
ROC train: 0.918981	val: 0.783038	test: 0.754043
PRC train: 0.585128	val: 0.350469	test: 0.214069

Epoch: 39
Loss: 0.09929553283080332
ROC train: 0.923139	val: 0.784067	test: 0.772010
PRC train: 0.599326	val: 0.369053	test: 0.218563

Epoch: 40
Loss: 0.09856930484083884
ROC train: 0.927894	val: 0.810746	test: 0.740725
PRC train: 0.606235	val: 0.346350	test: 0.186469

Epoch: 41
Loss: 0.09790435330052807
ROC train: 0.926115	val: 0.787689	test: 0.761674
PRC train: 0.607579	val: 0.334874	test: 0.187053

Epoch: 42
Loss: 0.09724214619162448
ROC train: 0.929841	val: 0.772649	test: 0.741814
PRC train: 0.610499	val: 0.343379	test: 0.222022

Epoch: 43
Loss: 0.09664242915611757
ROC train: 0.930591	val: 0.779162	test: 0.744252
PRC train: 0.617325	val: 0.347287	test: 0.193764

Epoch: 44
Loss: 0.09562246359757341
ROC train: 0.932505	val: 0.786477	test: 0.739530
PRC train: 0.607787	val: 0.352916	test: 0.224135

Epoch: 45
Loss: 0.09621630079715318
ROC train: 0.937747	val: 0.785892	test: 0.743313
PRC train: 0.632103	val: 0.333542	test: 0.183153

Epoch: 46
Loss: 0.09557562325540536
ROC train: 0.927277	val: 0.781893	test: 0.741386
PRC train: 0.605278	val: 0.315879	test: 0.143096

Epoch: 47
Loss: 0.09467859778808697
ROC train: 0.936450	val: 0.785182	test: 0.757527
PRC train: 0.626166	val: 0.347358	test: 0.199451

Epoch: 48
Loss: 0.0938971809456291
ROC train: 0.934996	val: 0.775267	test: 0.751845
PRC train: 0.632253	val: 0.313122	test: 0.162554

Epoch: 49
Loss: 0.09307267582230792
ROC train: 0.944564	val: 0.807090	test: 0.752025
PRC train: 0.646102	val: 0.321169	test: 0.180698

Epoch: 50
Loss: 0.09361455075421778
ROC train: 0.944014	val: 0.798596	test: 0.751840
PRC train: 0.646079	val: 0.335818	test: 0.222732

Epoch: 51
Loss: 0.09365589200207496
ROC train: 0.944070	val: 0.785524	test: 0.736086
PRC train: 0.650686	val: 0.342996	test: 0.184547

Epoch: 52
Loss: 0.09125863186800118
ROC train: 0.933955	val: 0.792839	test: 0.711067
PRC train: 0.620009	val: 0.269815	test: 0.163851

Epoch: 53
Loss: 0.0923561252389897
ROC train: 0.946936	val: 0.788850	test: 0.748352
PRC train: 0.655036	val: 0.336654	test: 0.208293

Epoch: 54
Loss: 0.09112471283735245
ROC train: 0.945589	val: 0.784964	test: 0.747185
PRC train: 0.641759	val: 0.346813	test: 0.212530

Epoch: 55
Loss: 0.09063872971341713
ROC train: 0.943914	val: 0.802683	test: 0.737652
PRC train: 0.642798	val: 0.387736	test: 0.219118

Epoch: 56
Loss: 0.09139852785767767
ROC train: 0.953198	val: 0.803697	test: 0.741565
PRC train: 0.667397	val: 0.324686	test: 0.176610

Epoch: 57
Loss: 0.09003625697293646
ROC train: 0.948745	val: 0.806649	test: 0.726186
PRC train: 0.663198	val: 0.345632	test: 0.176511

Epoch: 58
Loss: 0.08833970996119182
ROC train: 0.952666	val: 0.793179	test: 0.753875
PRC train: 0.668221	val: 0.310167	test: 0.194041

Epoch: 59
Loss: 0.08838623114093258
ROC train: 0.953210	val: 0.806594	test: 0.727486
PRC train: 0.669960	val: 0.307657	test: 0.182116

Epoch: 60
Loss: 0.08872259823066185
ROC train: 0.953438	val: 0.799334	test: 0.745057
PRC train: 0.673704	val: 0.333477	test: 0.185671

Epoch: 61
Loss: 0.08743457312095451
ROC train: 0.956935	val: 0.794135	test: 0.743288
PRC train: 0.687493	val: 0.295576	test: 0.150881

Epoch: 62
Loss: 0.08766928930045514
ROC train: 0.953993	val: 0.791826	test: 0.751702
PRC train: 0.683655	val: 0.326787	test: 0.193270

Epoch: 63
Loss: 0.08829311613767767
ROC train: 0.953625	val: 0.790093	test: 0.725323
PRC train: 0.687535	val: 0.332712	test: 0.163825

Epoch: 64
Loss: 0.08719087607407933
ROC train: 0.956695	val: 0.774397	test: 0.732218
PRC train: 0.692072	val: 0.297798	test: 0.151206

Epoch: 65
Loss: 0.08645388519860658
ROC train: 0.959581	val: 0.800611	test: 0.729103
PRC train: 0.694047	val: 0.312121	test: 0.161465

Epoch: 66
Loss: 0.08619091119682999
ROC train: 0.959127	val: 0.800996	test: 0.747784
PRC train: 0.690101	val: 0.327847	test: 0.176054

Epoch: 67
Loss: 0.0853017636131752
ROC train: 0.958898	val: 0.786079	test: 0.755621
PRC train: 0.693499	val: 0.323597	test: 0.192402

Epoch: 68
Loss: 0.08447619572783346
ROC train: 0.959481	val: 0.806802	test: 0.752442
PRC train: 0.696882	val: 0.323837	test: 0.183717

Epoch: 69
Loss: 0.08429080683122425
ROC train: 0.964467	val: 0.812329	test: 0.754773
PRC train: 0.708958	val: 0.315838	test: 0.177683

Epoch: 70
Loss: 0.08542886776726963
ROC train: 0.963479	val: 0.804389	test: 0.736594
PRC train: 0.708525	val: 0.318224	test: 0.213573

Epoch: 71
Loss: 0.0832945845442458
ROC train: 0.964215	val: 0.808418	test: 0.734421
PRC train: 0.717403	val: 0.320070	test: 0.209987

Epoch: 72
Loss: 0.08366254554286082
ROC train: 0.964140	val: 0.785344	test: 0.756044
PRC train: 0.711542	val: 0.321928	test: 0.192527

Epoch: 73
Loss: 0.08419259549313031
ROC train: 0.961761	val: 0.795503	test: 0.755683
PRC train: 0.681622	val: 0.309935	test: 0.188538

Epoch: 74
Loss: 0.083929936422348
ROC train: 0.964341	val: 0.819487	test: 0.763669
PRC train: 0.704375	val: 0.314993	test: 0.181839

Epoch: 75
Loss: 0.08116896322361934
ROC train: 0.966563	val: 0.784976	test: 0.752836
PRC train: 0.715103	val: 0.301065	test: 0.178092

Epoch: 76
Loss: 0.08353152053851036
ROC train: 0.967894	val: 0.796912	test: 0.749960
PRC train: 0.720400	val: 0.307414	test: 0.123564

Epoch: 77
Loss: 0.08155685957793936
ROC train: 0.967104	val: 0.793917	test: 0.761931
PRC train: 0.728399	val: 0.314433	test: 0.210295

Epoch: 78
Loss: 0.08212003253045078
ROC train: 0.965496	val: 0.797564	test: 0.747625
PRC train: 0.718277	val: 0.321503	test: 0.183900

Epoch: 79
Loss: 0.08102346127005126
ROC train: 0.968594	val: 0.779768	test: 0.745518
PRC train: 0.733248	val: 0.312966	test: 0.168866

Epoch: 80
Loss: 0.08022409428651872
ROC train: 0.966765	val: 0.788449	test: 0.756913
PRC train: 0.728368	val: 0.297285	test: 0.191221

Epoch: 81
Loss: 0.08048233922324634
ROC train: 0.969502	val: 0.784774	test: 0.758221
PRC train: 0.730602	val: 0.313583	test: 0.206104

Epoch: 82
Loss: 0.08048467907140845
ROC train: 0.973832	val: 0.789771	test: 0.752608
PRC train: 0.751552	val: 0.299793	test: 0.190271

Epoch: 83
Loss: 0.07993999905163288
ROC train: 0.970298	val: 0.805384	test: 0.740439
PRC train: 0.739269	val: 0.298485	test: 0.166670

Epoch: 84
Loss: 0.07945222739449838
ROC train: 0.968639	val: 0.796189	test: 0.775500
PRC train: 0.716564	val: 0.297030	test: 0.219538

Epoch: 85
Loss: 0.07903281221542591
ROC train: 0.972919	val: 0.787671	test: 0.746349
PRC train: 0.750071	val: 0.308901	test: 0.131754

Epoch: 86
Loss: 0.07842632739120678
ROC train: 0.973747	val: 0.797273	test: 0.731922
PRC train: 0.756749	val: 0.312269	test: 0.175097

Epoch: 87
Loss: 0.07956767600473949
ROC train: 0.973307	val: 0.790084	test: 0.761967
PRC train: 0.742597	val: 0.287332	test: 0.171451

Epoch: 88
Loss: 0.07626040965673356
ROC train: 0.975171	val: 0.785555	test: 0.741731
PRC train: 0.753527	val: 0.314981	test: 0.205287

Epoch: 89
Loss: 0.07829511518588916
ROC train: 0.974874	val: 0.808079	test: 0.774030
PRC train: 0.756324	val: 0.299959	test: 0.175198

Epoch: 90
Loss: 0.07775910026444419
ROC train: 0.974421	val: 0.793302	test: 0.747465
PRC train: 0.759553	val: 0.311933	test: 0.220142

Epoch: 91
Loss: 0.0785774968604272
ROC train: 0.967483	val: 0.788158	test: 0.737979
PRC train: 0.727969	val: 0.319187	test: 0.197413

Epoch: 92
Loss: 0.07675733171818314
ROC train: 0.975568	val: 0.806352	test: 0.744252
PRC train: 0.763735	val: 0.280932	test: 0.161615

Epoch: 93
Loss: 0.07607952922371218
ROC train: 0.978222	val: 0.803816	test: 0.750978
PRC train: 0.777436	val: 0.315652	test: 0.188206


PRC train: 0.607091	val: 0.367461	test: 0.182614

Epoch: 33
Loss: 0.09828409757091072
ROC train: 0.930630	val: 0.788393	test: 0.744230
PRC train: 0.622268	val: 0.338688	test: 0.192407

Epoch: 34
Loss: 0.09729292103900974
ROC train: 0.928397	val: 0.802469	test: 0.730576
PRC train: 0.629792	val: 0.323245	test: 0.211181

Epoch: 35
Loss: 0.09681841258725365
ROC train: 0.935849	val: 0.810179	test: 0.739717
PRC train: 0.648160	val: 0.317115	test: 0.188854

Epoch: 36
Loss: 0.09441159761037285
ROC train: 0.930716	val: 0.789043	test: 0.742228
PRC train: 0.625488	val: 0.309473	test: 0.186526

Epoch: 37
Loss: 0.09477403412925592
ROC train: 0.938691	val: 0.803902	test: 0.729033
PRC train: 0.652556	val: 0.313469	test: 0.187928

Epoch: 38
Loss: 0.09601590452054583
ROC train: 0.948133	val: 0.786223	test: 0.720694
PRC train: 0.691629	val: 0.326228	test: 0.138442

Epoch: 39
Loss: 0.09184197716125503
ROC train: 0.947778	val: 0.803473	test: 0.717914
PRC train: 0.683124	val: 0.302253	test: 0.121308

Epoch: 40
Loss: 0.09187966321956176
ROC train: 0.949004	val: 0.785843	test: 0.717333
PRC train: 0.679106	val: 0.319102	test: 0.136073

Epoch: 41
Loss: 0.09251638105418948
ROC train: 0.951964	val: 0.802273	test: 0.739403
PRC train: 0.690651	val: 0.305888	test: 0.191383

Epoch: 42
Loss: 0.09002521070774971
ROC train: 0.953572	val: 0.791250	test: 0.738587
PRC train: 0.698868	val: 0.332016	test: 0.172097

Epoch: 43
Loss: 0.08832396068166717
ROC train: 0.959680	val: 0.816759	test: 0.722138
PRC train: 0.729661	val: 0.324643	test: 0.169888

Epoch: 44
Loss: 0.09075019049291691
ROC train: 0.959938	val: 0.810690	test: 0.734970
PRC train: 0.720368	val: 0.354565	test: 0.263334

Epoch: 45
Loss: 0.08702699076260635
ROC train: 0.956327	val: 0.816790	test: 0.748421
PRC train: 0.717130	val: 0.348925	test: 0.202242

Epoch: 46
Loss: 0.08843571850310919
ROC train: 0.957949	val: 0.807347	test: 0.737063
PRC train: 0.717415	val: 0.356214	test: 0.187580

Epoch: 47
Loss: 0.08574764221988532
ROC train: 0.959378	val: 0.808581	test: 0.726349
PRC train: 0.724320	val: 0.339836	test: 0.161386

Epoch: 48
Loss: 0.08532427307804791
ROC train: 0.957596	val: 0.784122	test: 0.751629
PRC train: 0.712957	val: 0.340141	test: 0.180187

Epoch: 49
Loss: 0.08442107568617147
ROC train: 0.962243	val: 0.796945	test: 0.755082
PRC train: 0.737278	val: 0.314640	test: 0.217706

Epoch: 50
Loss: 0.08511553740650239
ROC train: 0.968438	val: 0.802380	test: 0.744184
PRC train: 0.758240	val: 0.356008	test: 0.174419

Epoch: 51
Loss: 0.0828644838284024
ROC train: 0.963259	val: 0.792496	test: 0.729006
PRC train: 0.734062	val: 0.316537	test: 0.171971

Epoch: 52
Loss: 0.08167761556031626
ROC train: 0.969985	val: 0.812261	test: 0.756726
PRC train: 0.767187	val: 0.358383	test: 0.184159

Epoch: 53
Loss: 0.08155886291364062
ROC train: 0.963232	val: 0.794637	test: 0.717553
PRC train: 0.733886	val: 0.329436	test: 0.176566

Epoch: 54
Loss: 0.0809373146000407
ROC train: 0.970835	val: 0.804913	test: 0.725066
PRC train: 0.778852	val: 0.349249	test: 0.179632

Epoch: 55
Loss: 0.07874171302536398
ROC train: 0.973402	val: 0.789961	test: 0.741474
PRC train: 0.782252	val: 0.325125	test: 0.170629

Epoch: 56
Loss: 0.07916298955925632
ROC train: 0.975093	val: 0.780925	test: 0.755654
PRC train: 0.793288	val: 0.331200	test: 0.205291

Epoch: 57
Loss: 0.07683090867886092
ROC train: 0.969875	val: 0.800237	test: 0.714313
PRC train: 0.776196	val: 0.336025	test: 0.147526

Epoch: 58
Loss: 0.08034568960374859
ROC train: 0.973046	val: 0.804906	test: 0.737370
PRC train: 0.788978	val: 0.344040	test: 0.216063

Epoch: 59
Loss: 0.07686997104598042
ROC train: 0.976369	val: 0.797564	test: 0.754364
PRC train: 0.806276	val: 0.334931	test: 0.167378

Epoch: 60
Loss: 0.07533753559075705
ROC train: 0.977449	val: 0.821211	test: 0.748429
PRC train: 0.822476	val: 0.353028	test: 0.171382

Epoch: 61
Loss: 0.07494698683400931
ROC train: 0.977357	val: 0.797206	test: 0.731963
PRC train: 0.806653	val: 0.340729	test: 0.196960

Epoch: 62
Loss: 0.07407724688770802
ROC train: 0.980133	val: 0.811710	test: 0.753987
PRC train: 0.834118	val: 0.333157	test: 0.209853

Epoch: 63
Loss: 0.07333736603506437
ROC train: 0.982299	val: 0.804698	test: 0.757396
PRC train: 0.837204	val: 0.349300	test: 0.193335

Epoch: 64
Loss: 0.07329380595393682
ROC train: 0.981089	val: 0.794000	test: 0.761649
PRC train: 0.832769	val: 0.351951	test: 0.185181

Epoch: 65
Loss: 0.07079927072016827
ROC train: 0.976667	val: 0.798293	test: 0.749955
PRC train: 0.813984	val: 0.316465	test: 0.200695

Epoch: 66
Loss: 0.07182176110367662
ROC train: 0.981368	val: 0.788935	test: 0.733208
PRC train: 0.839336	val: 0.316212	test: 0.166976

Epoch: 67
Loss: 0.07188560537847592
ROC train: 0.982992	val: 0.800062	test: 0.743523
PRC train: 0.853506	val: 0.328009	test: 0.189776

Epoch: 68
Loss: 0.06936950455157409
ROC train: 0.984734	val: 0.789058	test: 0.749962
PRC train: 0.855329	val: 0.368576	test: 0.236961

Epoch: 69
Loss: 0.06910215515296
ROC train: 0.982611	val: 0.796489	test: 0.765204
PRC train: 0.843984	val: 0.347669	test: 0.209100

Epoch: 70
Loss: 0.06964280780585161
ROC train: 0.983662	val: 0.797772	test: 0.749640
PRC train: 0.844941	val: 0.392860	test: 0.234190

Epoch: 71
Loss: 0.06741727751522582
ROC train: 0.982424	val: 0.808856	test: 0.742936
PRC train: 0.848403	val: 0.361705	test: 0.205062

Epoch: 72
Loss: 0.06879761897140145
ROC train: 0.977536	val: 0.793182	test: 0.739294
PRC train: 0.798048	val: 0.321159	test: 0.206616

Epoch: 73
Loss: 0.06814120078603232
ROC train: 0.987015	val: 0.802451	test: 0.753846
PRC train: 0.865990	val: 0.354514	test: 0.174617

Epoch: 74
Loss: 0.06407817421052776
ROC train: 0.986863	val: 0.815060	test: 0.773142
PRC train: 0.876548	val: 0.357105	test: 0.219684

Epoch: 75
Loss: 0.06632032361819826
ROC train: 0.985903	val: 0.782123	test: 0.766407
PRC train: 0.857350	val: 0.352507	test: 0.209225

Epoch: 76
Loss: 0.06696045901603992
ROC train: 0.987123	val: 0.802062	test: 0.738987
PRC train: 0.869308	val: 0.354750	test: 0.187528

Epoch: 77
Loss: 0.06373486338728483
ROC train: 0.979494	val: 0.774514	test: 0.731252
PRC train: 0.780728	val: 0.253463	test: 0.110211

Epoch: 78
Loss: 0.06571087521127043
ROC train: 0.986335	val: 0.800558	test: 0.757985
PRC train: 0.871383	val: 0.345978	test: 0.203266

Epoch: 79
Loss: 0.06393505525107869
ROC train: 0.989370	val: 0.801489	test: 0.757975
PRC train: 0.890427	val: 0.345419	test: 0.224281

Epoch: 80
Loss: 0.06120438504594204
ROC train: 0.988677	val: 0.773981	test: 0.749391
PRC train: 0.879104	val: 0.316543	test: 0.195300

Epoch: 81
Loss: 0.061470091094811156
ROC train: 0.985919	val: 0.765613	test: 0.741430
PRC train: 0.864185	val: 0.277061	test: 0.127961

Epoch: 82
Loss: 0.06487038240543573
ROC train: 0.990156	val: 0.789630	test: 0.754553
PRC train: 0.891449	val: 0.317488	test: 0.205577

Epoch: 83
Loss: 0.06284840439766964
ROC train: 0.990149	val: 0.779906	test: 0.748937
PRC train: 0.895015	val: 0.321586	test: 0.221102

Epoch: 84
Loss: 0.06075068681046708
ROC train: 0.988724	val: 0.771614	test: 0.742836
PRC train: 0.879513	val: 0.311832	test: 0.223669

Epoch: 85
Loss: 0.059557312113395676
ROC train: 0.991627	val: 0.797898	test: 0.758781
PRC train: 0.904289	val: 0.345644	test: 0.142773

Epoch: 86
Loss: 0.05908503059759009
ROC train: 0.991178	val: 0.806153	test: 0.751285
PRC train: 0.901687	val: 0.347427	test: 0.175607

Epoch: 87
Loss: 0.05878036408459845
ROC train: 0.993504	val: 0.792876	test: 0.754574
PRC train: 0.920583	val: 0.327883	test: 0.172191

Epoch: 88
Loss: 0.05807932275070435
ROC train: 0.993975	val: 0.794490	test: 0.760594
PRC train: 0.923496	val: 0.325787	test: 0.170955

Epoch: 89
Loss: 0.05893810906463077
ROC train: 0.993330	val: 0.779437	test: 0.758746
PRC train: 0.922794	val: 0.322821	test: 0.175777

Epoch: 90
Loss: 0.05676086793841154
ROC train: 0.993535	val: 0.803599	test: 0.734871
PRC train: 0.917139	val: 0.348407	test: 0.190640

Epoch: 91
Loss: 0.056072084683185426
ROC train: 0.992452	val: 0.782377	test: 0.752747
PRC train: 0.908525	val: 0.327923	test: 0.178445

Epoch: 92
Loss: 0.055397370628132006
ROC train: 0.993880	val: 0.796220	test: 0.759111
PRC train: 0.932032	val: 0.340855	test: 0.174753

Epoch: 93
Loss: 0.05329337260956493
ROC train: 0.990462	val: 0.767110	test: 0.739474
PRC train: 0.661150	val: 0.360013	test: 0.213514

Epoch: 33
Loss: 0.09726506287415199
ROC train: 0.949694	val: 0.814157	test: 0.736252
PRC train: 0.673689	val: 0.365606	test: 0.181216

Epoch: 34
Loss: 0.09576882673309577
ROC train: 0.946375	val: 0.808207	test: 0.734954
PRC train: 0.656412	val: 0.372553	test: 0.208595

Epoch: 35
Loss: 0.09464105348770077
ROC train: 0.945145	val: 0.800056	test: 0.726262
PRC train: 0.663049	val: 0.391962	test: 0.237195

Epoch: 36
Loss: 0.09373101654461873
ROC train: 0.957895	val: 0.817883	test: 0.721515
PRC train: 0.708001	val: 0.372540	test: 0.203878

Epoch: 37
Loss: 0.09243971722943983
ROC train: 0.953491	val: 0.792080	test: 0.715083
PRC train: 0.703303	val: 0.382111	test: 0.195723

Epoch: 38
Loss: 0.08934291976038582
ROC train: 0.959439	val: 0.798443	test: 0.706860
PRC train: 0.728605	val: 0.349352	test: 0.174814

Epoch: 39
Loss: 0.09044180304827097
ROC train: 0.953632	val: 0.806042	test: 0.721439
PRC train: 0.712712	val: 0.320894	test: 0.174356

Epoch: 40
Loss: 0.08698785991885383
ROC train: 0.960278	val: 0.824739	test: 0.723604
PRC train: 0.748974	val: 0.342343	test: 0.145218

Epoch: 41
Loss: 0.08596196153479943
ROC train: 0.960101	val: 0.805510	test: 0.712094
PRC train: 0.714585	val: 0.390930	test: 0.224133

Epoch: 42
Loss: 0.08471688584128798
ROC train: 0.965198	val: 0.818302	test: 0.719031
PRC train: 0.746395	val: 0.360354	test: 0.207665

Epoch: 43
Loss: 0.08550748002021206
ROC train: 0.969532	val: 0.807775	test: 0.719869
PRC train: 0.764452	val: 0.378838	test: 0.212702

Epoch: 44
Loss: 0.08220822999425777
ROC train: 0.969406	val: 0.825948	test: 0.718585
PRC train: 0.763777	val: 0.357734	test: 0.192284

Epoch: 45
Loss: 0.08193547501373058
ROC train: 0.972991	val: 0.817350	test: 0.727090
PRC train: 0.778187	val: 0.367382	test: 0.209397

Epoch: 46
Loss: 0.07910022081648363
ROC train: 0.977763	val: 0.814346	test: 0.727266
PRC train: 0.816122	val: 0.340389	test: 0.174449

Epoch: 47
Loss: 0.08122172146275033
ROC train: 0.974550	val: 0.797748	test: 0.721594
PRC train: 0.797850	val: 0.321931	test: 0.164272

Epoch: 48
Loss: 0.08152995628156247
ROC train: 0.978277	val: 0.799998	test: 0.730416
PRC train: 0.822960	val: 0.387448	test: 0.198593

Epoch: 49
Loss: 0.0785952569384532
ROC train: 0.979852	val: 0.816428	test: 0.746768
PRC train: 0.818943	val: 0.327451	test: 0.157511

Epoch: 50
Loss: 0.07697057430483964
ROC train: 0.979121	val: 0.808844	test: 0.714815
PRC train: 0.826796	val: 0.338547	test: 0.188391

Epoch: 51
Loss: 0.07556264476394235
ROC train: 0.978035	val: 0.815418	test: 0.730787
PRC train: 0.813866	val: 0.321710	test: 0.174188

Epoch: 52
Loss: 0.07599016596319896
ROC train: 0.981174	val: 0.790445	test: 0.709725
PRC train: 0.834557	val: 0.284836	test: 0.137066

Epoch: 53
Loss: 0.07307694193187807
ROC train: 0.980289	val: 0.808630	test: 0.734881
PRC train: 0.835387	val: 0.334481	test: 0.200156

Epoch: 54
Loss: 0.07015872940158702
ROC train: 0.980093	val: 0.822163	test: 0.709135
PRC train: 0.819863	val: 0.328216	test: 0.197525

Epoch: 55
Loss: 0.07152110504064299
ROC train: 0.979944	val: 0.796550	test: 0.728025
PRC train: 0.814930	val: 0.336044	test: 0.225212

Epoch: 56
Loss: 0.07121196078141828
ROC train: 0.987224	val: 0.805396	test: 0.726067
PRC train: 0.878667	val: 0.332330	test: 0.171936

Epoch: 57
Loss: 0.07019071481738161
ROC train: 0.983027	val: 0.805699	test: 0.720431
PRC train: 0.847794	val: 0.350543	test: 0.200068

Epoch: 58
Loss: 0.06809169327464294
ROC train: 0.985827	val: 0.816698	test: 0.723477
PRC train: 0.862714	val: 0.305033	test: 0.160350

Epoch: 59
Loss: 0.06867300028336591
ROC train: 0.987284	val: 0.820577	test: 0.731810
PRC train: 0.880272	val: 0.343302	test: 0.153862

Epoch: 60
Loss: 0.06586058442964496
ROC train: 0.982658	val: 0.791936	test: 0.720910
PRC train: 0.832568	val: 0.355333	test: 0.229998

Epoch: 61
Loss: 0.06728339253691186
ROC train: 0.983147	val: 0.804594	test: 0.728757
PRC train: 0.858506	val: 0.319413	test: 0.162850

Epoch: 62
Loss: 0.06363942711931307
ROC train: 0.989284	val: 0.800350	test: 0.710276
PRC train: 0.890084	val: 0.354277	test: 0.205993

Epoch: 63
Loss: 0.06333133061200351
ROC train: 0.989657	val: 0.794974	test: 0.724699
PRC train: 0.894646	val: 0.333581	test: 0.179572

Epoch: 64
Loss: 0.0650674215529119
ROC train: 0.990140	val: 0.821523	test: 0.725371
PRC train: 0.896958	val: 0.355389	test: 0.188556

Epoch: 65
Loss: 0.06100939124116738
ROC train: 0.991656	val: 0.802010	test: 0.725449
PRC train: 0.905724	val: 0.377561	test: 0.251462

Epoch: 66
Loss: 0.06275667282798787
ROC train: 0.990299	val: 0.801419	test: 0.749848
PRC train: 0.896541	val: 0.363508	test: 0.216561

Epoch: 67
Loss: 0.058358035464696305
ROC train: 0.990793	val: 0.794229	test: 0.731911
PRC train: 0.907369	val: 0.289061	test: 0.140846

Epoch: 68
Loss: 0.06114237009649318
ROC train: 0.994028	val: 0.793299	test: 0.731953
PRC train: 0.932512	val: 0.359731	test: 0.193797

Epoch: 69
Loss: 0.06005298963457105
ROC train: 0.989412	val: 0.805657	test: 0.754099
PRC train: 0.888234	val: 0.360285	test: 0.218905

Epoch: 70
Loss: 0.05788540984018916
ROC train: 0.991118	val: 0.807341	test: 0.712352
PRC train: 0.907053	val: 0.302860	test: 0.163664

Epoch: 71
Loss: 0.05759115554446701
ROC train: 0.992616	val: 0.797533	test: 0.706238
PRC train: 0.913004	val: 0.312397	test: 0.191869

Epoch: 72
Loss: 0.05814329806806514
ROC train: 0.992096	val: 0.817157	test: 0.747751
PRC train: 0.913601	val: 0.380502	test: 0.221484

Epoch: 73
Loss: 0.05645780788164578
ROC train: 0.992739	val: 0.780717	test: 0.731540
PRC train: 0.920617	val: 0.350130	test: 0.208039

Epoch: 74
Loss: 0.05638309126701948
ROC train: 0.994086	val: 0.797542	test: 0.739259
PRC train: 0.929832	val: 0.305407	test: 0.175677

Epoch: 75
Loss: 0.05692794660464638
ROC train: 0.995480	val: 0.800121	test: 0.728471
PRC train: 0.940014	val: 0.320075	test: 0.182149

Epoch: 76
Loss: 0.05429258476099787
ROC train: 0.995791	val: 0.801514	test: 0.731453
PRC train: 0.948080	val: 0.334973	test: 0.186438

Epoch: 77
Loss: 0.054419973269320666
ROC train: 0.995141	val: 0.810945	test: 0.733842
PRC train: 0.934146	val: 0.315395	test: 0.176455

Epoch: 78
Loss: 0.05428731971505879
ROC train: 0.996041	val: 0.805767	test: 0.719504
PRC train: 0.954197	val: 0.326410	test: 0.165860

Epoch: 79
Loss: 0.05245642893311943
ROC train: 0.995714	val: 0.819221	test: 0.741411
PRC train: 0.945974	val: 0.339378	test: 0.229015

Epoch: 80
Loss: 0.050947027522277706
ROC train: 0.996807	val: 0.811875	test: 0.717223
PRC train: 0.957902	val: 0.326706	test: 0.196400

Epoch: 81
Loss: 0.049965109423646646
ROC train: 0.994892	val: 0.802974	test: 0.725742
PRC train: 0.939356	val: 0.314837	test: 0.211578

Epoch: 82
Loss: 0.05298995783318893
ROC train: 0.994786	val: 0.793917	test: 0.722685
PRC train: 0.934717	val: 0.331381	test: 0.211657

Epoch: 83
Loss: 0.04892980427484826
ROC train: 0.996842	val: 0.790825	test: 0.734278
PRC train: 0.955146	val: 0.327302	test: 0.207323

Epoch: 84
Loss: 0.051058335871176225
ROC train: 0.996275	val: 0.800277	test: 0.728707
PRC train: 0.948981	val: 0.304006	test: 0.172355

Epoch: 85
Loss: 0.04787990176708326
ROC train: 0.996872	val: 0.799925	test: 0.739387
PRC train: 0.956326	val: 0.357742	test: 0.206029

Epoch: 86
Loss: 0.04938838191558929
ROC train: 0.997018	val: 0.784404	test: 0.729272
PRC train: 0.957721	val: 0.349765	test: 0.215287

Epoch: 87
Loss: 0.048446061940763195
ROC train: 0.997196	val: 0.805308	test: 0.733199
PRC train: 0.964314	val: 0.335216	test: 0.179994

Epoch: 88
Loss: 0.0466666756947346
ROC train: 0.996150	val: 0.824729	test: 0.718589
PRC train: 0.950065	val: 0.328701	test: 0.159151

Epoch: 89
Loss: 0.04591227541785115
ROC train: 0.997766	val: 0.820326	test: 0.742610
PRC train: 0.968067	val: 0.346386	test: 0.210242

Epoch: 90
Loss: 0.04786182688276145
ROC train: 0.997337	val: 0.809851	test: 0.734361
PRC train: 0.963699	val: 0.358438	test: 0.238048

Epoch: 91
Loss: 0.045101229106000076
ROC train: 0.997745	val: 0.810583	test: 0.746789
PRC train: 0.963007	val: 0.366403	test: 0.224856

Epoch: 92
Loss: 0.04536643752937784
ROC train: 0.997309	val: 0.775270	test: 0.733732
PRC train: 0.961804	val: 0.329015	test: 0.227992

Epoch: 93
Loss: 0.04509721563351068
ROC train: 0.998298	val: 0.811992	test: 0.734765
PRC train: 0.682641	val: 0.345496	test: 0.183814

Epoch: 33
Loss: 0.09708440324240246
ROC train: 0.948460	val: 0.762006	test: 0.735194
PRC train: 0.665070	val: 0.295738	test: 0.163457

Epoch: 34
Loss: 0.09329516039749078
ROC train: 0.947251	val: 0.760349	test: 0.734313
PRC train: 0.712060	val: 0.296005	test: 0.171952

Epoch: 35
Loss: 0.09401734728171555
ROC train: 0.955213	val: 0.790681	test: 0.739174
PRC train: 0.724644	val: 0.318109	test: 0.187325

Epoch: 36
Loss: 0.09223429632334326
ROC train: 0.953547	val: 0.758004	test: 0.719888
PRC train: 0.701039	val: 0.267589	test: 0.177873

Epoch: 37
Loss: 0.08994293595288334
ROC train: 0.953240	val: 0.753916	test: 0.724854
PRC train: 0.692582	val: 0.290930	test: 0.204301

Epoch: 38
Loss: 0.09185667562089227
ROC train: 0.953743	val: 0.758702	test: 0.746279
PRC train: 0.713214	val: 0.298618	test: 0.176130

Epoch: 39
Loss: 0.09029974862111445
ROC train: 0.958710	val: 0.753883	test: 0.719501
PRC train: 0.732316	val: 0.282103	test: 0.140557

Epoch: 40
Loss: 0.08754747525915461
ROC train: 0.964338	val: 0.754960	test: 0.716644
PRC train: 0.753951	val: 0.280806	test: 0.204821

Epoch: 41
Loss: 0.088036108983566
ROC train: 0.961799	val: 0.766479	test: 0.714720
PRC train: 0.746880	val: 0.281432	test: 0.198519

Epoch: 42
Loss: 0.0853772570839236
ROC train: 0.962539	val: 0.777965	test: 0.696589
PRC train: 0.745563	val: 0.296222	test: 0.162008

Epoch: 43
Loss: 0.08504886457644328
ROC train: 0.971258	val: 0.740496	test: 0.700774
PRC train: 0.789724	val: 0.271976	test: 0.154744

Epoch: 44
Loss: 0.08316431659454726
ROC train: 0.970645	val: 0.782233	test: 0.728513
PRC train: 0.780621	val: 0.336926	test: 0.185209

Epoch: 45
Loss: 0.08457407967947368
ROC train: 0.958775	val: 0.782423	test: 0.737915
PRC train: 0.725783	val: 0.329582	test: 0.205748

Epoch: 46
Loss: 0.07965849633673588
ROC train: 0.965206	val: 0.761139	test: 0.716781
PRC train: 0.787914	val: 0.317866	test: 0.162837

Epoch: 47
Loss: 0.08045746741120796
ROC train: 0.970569	val: 0.755110	test: 0.711557
PRC train: 0.788095	val: 0.288268	test: 0.141925

Epoch: 48
Loss: 0.07831396006783077
ROC train: 0.971009	val: 0.761623	test: 0.714886
PRC train: 0.786617	val: 0.284363	test: 0.199548

Epoch: 49
Loss: 0.07770144922245682
ROC train: 0.975149	val: 0.754072	test: 0.716213
PRC train: 0.815932	val: 0.305746	test: 0.156872

Epoch: 50
Loss: 0.07809033339460339
ROC train: 0.977137	val: 0.736203	test: 0.725080
PRC train: 0.807139	val: 0.300585	test: 0.146478

Epoch: 51
Loss: 0.0761892170032467
ROC train: 0.975237	val: 0.769927	test: 0.721269
PRC train: 0.804745	val: 0.332971	test: 0.193774

Epoch: 52
Loss: 0.07457812389627397
ROC train: 0.980382	val: 0.761568	test: 0.718036
PRC train: 0.835746	val: 0.309868	test: 0.193861

Epoch: 53
Loss: 0.0750424443879507
ROC train: 0.980587	val: 0.755129	test: 0.724966
PRC train: 0.830524	val: 0.294280	test: 0.199554

Epoch: 54
Loss: 0.07307799778429329
ROC train: 0.979467	val: 0.754143	test: 0.713054
PRC train: 0.822609	val: 0.306349	test: 0.154349

Epoch: 55
Loss: 0.0734902306038488
ROC train: 0.979354	val: 0.759526	test: 0.728786
PRC train: 0.841975	val: 0.314905	test: 0.173167

Epoch: 56
Loss: 0.06879437361290565
ROC train: 0.982768	val: 0.746212	test: 0.706450
PRC train: 0.854816	val: 0.331017	test: 0.201936

Epoch: 57
Loss: 0.06861854208573334
ROC train: 0.983388	val: 0.775066	test: 0.728948
PRC train: 0.861040	val: 0.302142	test: 0.169742

Epoch: 58
Loss: 0.07160452105149416
ROC train: 0.986218	val: 0.753037	test: 0.721804
PRC train: 0.873562	val: 0.269081	test: 0.168879

Epoch: 59
Loss: 0.06661224608356113
ROC train: 0.985419	val: 0.772640	test: 0.727123
PRC train: 0.869791	val: 0.293497	test: 0.147813

Epoch: 60
Loss: 0.06703463067723521
ROC train: 0.987492	val: 0.734130	test: 0.699591
PRC train: 0.887376	val: 0.275129	test: 0.157375

Epoch: 61
Loss: 0.066938763268512
ROC train: 0.983777	val: 0.757710	test: 0.707406
PRC train: 0.870080	val: 0.276403	test: 0.177843

Epoch: 62
Loss: 0.06640682907467722
ROC train: 0.986036	val: 0.755548	test: 0.724906
PRC train: 0.877777	val: 0.303691	test: 0.171862

Epoch: 63
Loss: 0.06584580769983163
ROC train: 0.985856	val: 0.786030	test: 0.731822
PRC train: 0.878063	val: 0.288057	test: 0.170897

Epoch: 64
Loss: 0.0633157358680474
ROC train: 0.988663	val: 0.770105	test: 0.731949
PRC train: 0.890705	val: 0.289301	test: 0.179704

Epoch: 65
Loss: 0.0633594349262494
ROC train: 0.989428	val: 0.743793	test: 0.716433
PRC train: 0.899580	val: 0.252978	test: 0.158002

Epoch: 66
Loss: 0.06093019653911629
ROC train: 0.989645	val: 0.758584	test: 0.728718
PRC train: 0.889539	val: 0.273516	test: 0.207531

Epoch: 67
Loss: 0.06149962102833191
ROC train: 0.991324	val: 0.762416	test: 0.729305
PRC train: 0.911157	val: 0.298946	test: 0.173035

Epoch: 68
Loss: 0.06037042011712023
ROC train: 0.990799	val: 0.776075	test: 0.733842
PRC train: 0.905806	val: 0.288518	test: 0.169310

Epoch: 69
Loss: 0.05921618082075965
ROC train: 0.991847	val: 0.767995	test: 0.727830
PRC train: 0.911527	val: 0.287934	test: 0.155859

Epoch: 70
Loss: 0.05925887185277005
ROC train: 0.989877	val: 0.756638	test: 0.729945
PRC train: 0.904287	val: 0.329528	test: 0.178283

Epoch: 71
Loss: 0.057939531171043564
ROC train: 0.992135	val: 0.767502	test: 0.735290
PRC train: 0.915373	val: 0.317623	test: 0.202281

Epoch: 72
Loss: 0.056001413269158196
ROC train: 0.990552	val: 0.752168	test: 0.734103
PRC train: 0.906340	val: 0.276917	test: 0.158852

Epoch: 73
Loss: 0.05734463584159819
ROC train: 0.992915	val: 0.757860	test: 0.720730
PRC train: 0.923916	val: 0.263743	test: 0.133175

Epoch: 74
Loss: 0.05503318776104929
ROC train: 0.994772	val: 0.754807	test: 0.729941
PRC train: 0.942860	val: 0.273827	test: 0.154626

Epoch: 75
Loss: 0.056312843718684474
ROC train: 0.995173	val: 0.754905	test: 0.729068
PRC train: 0.942564	val: 0.297178	test: 0.157488

Epoch: 76
Loss: 0.054619366531786326
ROC train: 0.992971	val: 0.763270	test: 0.716667
PRC train: 0.919439	val: 0.308616	test: 0.192761

Epoch: 77
Loss: 0.053283339261914996
ROC train: 0.995260	val: 0.738346	test: 0.718538
PRC train: 0.942112	val: 0.259297	test: 0.140958

Epoch: 78
Loss: 0.05186674227772771
ROC train: 0.993629	val: 0.753576	test: 0.731488
PRC train: 0.928400	val: 0.323087	test: 0.156837

Epoch: 79
Loss: 0.05533135139437864
ROC train: 0.994423	val: 0.761001	test: 0.732028
PRC train: 0.938478	val: 0.287469	test: 0.162036

Epoch: 80
Loss: 0.05087290703226559
ROC train: 0.995516	val: 0.746335	test: 0.710985
PRC train: 0.948771	val: 0.283019	test: 0.145500

Epoch: 81
Loss: 0.05193425054462199
ROC train: 0.996878	val: 0.801946	test: 0.712049
PRC train: 0.957317	val: 0.283405	test: 0.121758

Epoch: 82
Loss: 0.04919599967033391
ROC train: 0.993577	val: 0.742630	test: 0.718434
PRC train: 0.928273	val: 0.307650	test: 0.198480

Epoch: 83
Loss: 0.050959243429099896
ROC train: 0.996627	val: 0.738196	test: 0.722198
PRC train: 0.951912	val: 0.274784	test: 0.201959

Epoch: 84
Loss: 0.050223958459985375
ROC train: 0.993617	val: 0.768408	test: 0.728531
PRC train: 0.926003	val: 0.298738	test: 0.182181

Epoch: 85
Loss: 0.04939342053176861
ROC train: 0.996699	val: 0.765212	test: 0.726692
PRC train: 0.955645	val: 0.271649	test: 0.148248

Epoch: 86
Loss: 0.04679915063510841
ROC train: 0.995737	val: 0.780090	test: 0.734070
PRC train: 0.944427	val: 0.316280	test: 0.159162

Epoch: 87
Loss: 0.0498441279968417
ROC train: 0.997392	val: 0.757560	test: 0.717009
PRC train: 0.968025	val: 0.273545	test: 0.114353

Epoch: 88
Loss: 0.047789661784107824
ROC train: 0.996466	val: 0.739801	test: 0.727801
PRC train: 0.959664	val: 0.248978	test: 0.139109

Epoch: 89
Loss: 0.046913943755141976
ROC train: 0.996879	val: 0.773369	test: 0.727243
PRC train: 0.959192	val: 0.267243	test: 0.138537

Epoch: 90
Loss: 0.04715036591919026
ROC train: 0.997530	val: 0.757722	test: 0.732378
PRC train: 0.964775	val: 0.292684	test: 0.207072

Epoch: 91
Loss: 0.04548343490225243
ROC train: 0.997793	val: 0.742578	test: 0.731063
PRC train: 0.968320	val: 0.291217	test: 0.168359

Epoch: 92
Loss: 0.0455297920441245
ROC train: 0.997531	val: 0.783148	test: 0.727388
PRC train: 0.967454	val: 0.323233	test: 0.146227

Epoch: 93
Loss: 0.045146644539714204
ROC train: 0.998156	val: 0.769967	test: 0.717911
PRC train: 0.642450	val: 0.397635	test: 0.172532

Epoch: 33
Loss: 0.09626498809578583
ROC train: 0.935198	val: 0.818226	test: 0.735926
PRC train: 0.655794	val: 0.414105	test: 0.192302

Epoch: 34
Loss: 0.09628516252319444
ROC train: 0.936145	val: 0.801704	test: 0.707808
PRC train: 0.648191	val: 0.384046	test: 0.188515

Epoch: 35
Loss: 0.09695314808576445
ROC train: 0.936563	val: 0.809267	test: 0.721899
PRC train: 0.646535	val: 0.395909	test: 0.212029

Epoch: 36
Loss: 0.09578269160074006
ROC train: 0.939655	val: 0.801450	test: 0.714803
PRC train: 0.677266	val: 0.350626	test: 0.139753

Epoch: 37
Loss: 0.09449826815945062
ROC train: 0.944462	val: 0.801299	test: 0.695971
PRC train: 0.680287	val: 0.371599	test: 0.133794

Epoch: 38
Loss: 0.0942429958791633
ROC train: 0.945169	val: 0.784355	test: 0.733193
PRC train: 0.693081	val: 0.383637	test: 0.184576

Epoch: 39
Loss: 0.09196115775791568
ROC train: 0.946435	val: 0.820038	test: 0.724494
PRC train: 0.691631	val: 0.368416	test: 0.197059

Epoch: 40
Loss: 0.09028375266864407
ROC train: 0.949427	val: 0.817641	test: 0.729790
PRC train: 0.693171	val: 0.352414	test: 0.154309

Epoch: 41
Loss: 0.08889921936909684
ROC train: 0.939991	val: 0.810923	test: 0.700426
PRC train: 0.652002	val: 0.352759	test: 0.173193

Epoch: 42
Loss: 0.09028005803695004
ROC train: 0.941370	val: 0.815807	test: 0.717536
PRC train: 0.669601	val: 0.327876	test: 0.154377

Epoch: 43
Loss: 0.09003762949213119
ROC train: 0.953306	val: 0.820369	test: 0.729228
PRC train: 0.719020	val: 0.386268	test: 0.173215

Epoch: 44
Loss: 0.08854071466462861
ROC train: 0.954697	val: 0.828358	test: 0.699940
PRC train: 0.704236	val: 0.351082	test: 0.140505

Epoch: 45
Loss: 0.08677041092282525
ROC train: 0.957815	val: 0.816033	test: 0.742282
PRC train: 0.729384	val: 0.398202	test: 0.205098

Epoch: 46
Loss: 0.08658680618901367
ROC train: 0.962071	val: 0.828107	test: 0.725474
PRC train: 0.746540	val: 0.400794	test: 0.167148

Epoch: 47
Loss: 0.08521737791070325
ROC train: 0.962895	val: 0.819643	test: 0.724315
PRC train: 0.744716	val: 0.386745	test: 0.172693

Epoch: 48
Loss: 0.08587027745335135
ROC train: 0.965304	val: 0.823664	test: 0.716064
PRC train: 0.760822	val: 0.380581	test: 0.158235

Epoch: 49
Loss: 0.08373898712388587
ROC train: 0.964620	val: 0.795218	test: 0.709815
PRC train: 0.761964	val: 0.297891	test: 0.094209

Epoch: 50
Loss: 0.08281215901686725
ROC train: 0.966247	val: 0.798874	test: 0.721936
PRC train: 0.769585	val: 0.375259	test: 0.159833

Epoch: 51
Loss: 0.08089174922204832
ROC train: 0.965547	val: 0.805712	test: 0.726775
PRC train: 0.753521	val: 0.366787	test: 0.161916

Epoch: 52
Loss: 0.08102464744449682
ROC train: 0.966076	val: 0.799511	test: 0.703026
PRC train: 0.778748	val: 0.338186	test: 0.133553

Epoch: 53
Loss: 0.07913024701684448
ROC train: 0.973422	val: 0.803094	test: 0.708077
PRC train: 0.802322	val: 0.370080	test: 0.151734

Epoch: 54
Loss: 0.08059693951995436
ROC train: 0.971924	val: 0.806541	test: 0.705581
PRC train: 0.790814	val: 0.353740	test: 0.164839

Epoch: 55
Loss: 0.0781247550441547
ROC train: 0.975437	val: 0.814555	test: 0.717670
PRC train: 0.809557	val: 0.397185	test: 0.181820

Epoch: 56
Loss: 0.07795126457405209
ROC train: 0.974968	val: 0.789701	test: 0.694032
PRC train: 0.797726	val: 0.311210	test: 0.157414

Epoch: 57
Loss: 0.07846401482252485
ROC train: 0.972649	val: 0.801039	test: 0.701445
PRC train: 0.794038	val: 0.344398	test: 0.138391

Epoch: 58
Loss: 0.0753027123530238
ROC train: 0.977494	val: 0.823694	test: 0.723975
PRC train: 0.823369	val: 0.396175	test: 0.161303

Epoch: 59
Loss: 0.07674053641985512
ROC train: 0.976969	val: 0.787490	test: 0.720039
PRC train: 0.812229	val: 0.297665	test: 0.161135

Epoch: 60
Loss: 0.07550087593189692
ROC train: 0.968440	val: 0.783412	test: 0.714079
PRC train: 0.778502	val: 0.362523	test: 0.171321

Epoch: 61
Loss: 0.07330948187145518
ROC train: 0.976565	val: 0.811098	test: 0.736206
PRC train: 0.823311	val: 0.344473	test: 0.177931

Epoch: 62
Loss: 0.07282964141459103
ROC train: 0.979043	val: 0.796777	test: 0.719590
PRC train: 0.825627	val: 0.346255	test: 0.144894

Epoch: 63
Loss: 0.07166195344369465
ROC train: 0.974148	val: 0.806655	test: 0.719991
PRC train: 0.800003	val: 0.319473	test: 0.176998

Epoch: 64
Loss: 0.07457402942597298
ROC train: 0.978539	val: 0.809830	test: 0.718618
PRC train: 0.811983	val: 0.339551	test: 0.152320

Epoch: 65
Loss: 0.07164358124775058
ROC train: 0.981386	val: 0.822641	test: 0.678076
PRC train: 0.832996	val: 0.320043	test: 0.146081

Epoch: 66
Loss: 0.0706277285719581
ROC train: 0.973627	val: 0.791915	test: 0.740625
PRC train: 0.817590	val: 0.337465	test: 0.166083

Epoch: 67
Loss: 0.07095726152417994
ROC train: 0.981754	val: 0.812463	test: 0.722216
PRC train: 0.848496	val: 0.328518	test: 0.159717

Epoch: 68
Loss: 0.06964171472720664
ROC train: 0.982820	val: 0.806229	test: 0.726636
PRC train: 0.849080	val: 0.340251	test: 0.155001

Epoch: 69
Loss: 0.06752897538042069
ROC train: 0.983190	val: 0.797974	test: 0.729263
PRC train: 0.854965	val: 0.341768	test: 0.160115

Epoch: 70
Loss: 0.06893812646927523
ROC train: 0.985411	val: 0.805957	test: 0.734775
PRC train: 0.865434	val: 0.323445	test: 0.169352

Epoch: 71
Loss: 0.06765768752236043
ROC train: 0.989165	val: 0.799741	test: 0.701877
PRC train: 0.890978	val: 0.360434	test: 0.157575

Epoch: 72
Loss: 0.06534033074427172
ROC train: 0.985986	val: 0.821125	test: 0.716675
PRC train: 0.865270	val: 0.369679	test: 0.171961

Epoch: 73
Loss: 0.06547777593935251
ROC train: 0.985223	val: 0.811147	test: 0.720914
PRC train: 0.870625	val: 0.329809	test: 0.165151

Epoch: 74
Loss: 0.062081184825841774
ROC train: 0.984162	val: 0.809404	test: 0.706254
PRC train: 0.858681	val: 0.258111	test: 0.101800

Epoch: 75
Loss: 0.06620557240886005
ROC train: 0.984174	val: 0.806272	test: 0.709158
PRC train: 0.851269	val: 0.319636	test: 0.143806

Epoch: 76
Loss: 0.06433726256623928
ROC train: 0.989418	val: 0.823284	test: 0.725885
PRC train: 0.886629	val: 0.307088	test: 0.137702

Epoch: 77
Loss: 0.06289222341692208
ROC train: 0.988576	val: 0.816101	test: 0.730734
PRC train: 0.878354	val: 0.302963	test: 0.133486

Epoch: 78
Loss: 0.06318557142569775
ROC train: 0.989111	val: 0.808293	test: 0.715504
PRC train: 0.896511	val: 0.321315	test: 0.160573

Epoch: 79
Loss: 0.06258202553441981
ROC train: 0.988956	val: 0.809738	test: 0.724775
PRC train: 0.896251	val: 0.291553	test: 0.135104

Epoch: 80
Loss: 0.06158933730588982
ROC train: 0.991443	val: 0.825372	test: 0.713059
PRC train: 0.905799	val: 0.318589	test: 0.136943

Epoch: 81
Loss: 0.05937996089736243
ROC train: 0.991176	val: 0.801039	test: 0.719008
PRC train: 0.905669	val: 0.330680	test: 0.158277

Epoch: 82
Loss: 0.060194391042390834
ROC train: 0.991155	val: 0.801627	test: 0.709915
PRC train: 0.904420	val: 0.340958	test: 0.148768

Epoch: 83
Loss: 0.057681436503983205
ROC train: 0.990213	val: 0.822534	test: 0.713753
PRC train: 0.904601	val: 0.313031	test: 0.102839

Epoch: 84
Loss: 0.0583503505743883
ROC train: 0.991575	val: 0.829227	test: 0.724858
PRC train: 0.912280	val: 0.376771	test: 0.160187

Epoch: 85
Loss: 0.06197637816369378
ROC train: 0.988644	val: 0.796651	test: 0.682642
PRC train: 0.885923	val: 0.345625	test: 0.147134

Epoch: 86
Loss: 0.05871601018765078
ROC train: 0.992716	val: 0.796501	test: 0.724746
PRC train: 0.917322	val: 0.344128	test: 0.165988

Epoch: 87
Loss: 0.05887673528205181
ROC train: 0.993012	val: 0.801774	test: 0.712889
PRC train: 0.918506	val: 0.361077	test: 0.158478

Epoch: 88
Loss: 0.05684959887661879
ROC train: 0.990885	val: 0.809058	test: 0.736092
PRC train: 0.895265	val: 0.304813	test: 0.142532

Epoch: 89
Loss: 0.05852861448233165
ROC train: 0.993364	val: 0.799566	test: 0.697746
PRC train: 0.921324	val: 0.342026	test: 0.129297

Epoch: 90
Loss: 0.05705027331027516
ROC train: 0.991609	val: 0.810436	test: 0.716856
PRC train: 0.914031	val: 0.371629	test: 0.169062

Epoch: 91
Loss: 0.054718479299512825
ROC train: 0.994241	val: 0.793259	test: 0.718803
PRC train: 0.935658	val: 0.310506	test: 0.161444

Epoch: 92
Loss: 0.055198739479255986
ROC train: 0.993392	val: 0.792141	test: 0.700023
PRC train: 0.929972	val: 0.273563	test: 0.127390

Epoch: 93
Loss: 0.05475558376393438
ROC train: 0.994452	val: 0.807485	test: 0.720010
ROC train: 0.908368	val: 0.772726	test: 0.774324
PRC train: 0.555015	val: 0.293437	test: 0.175939

Epoch: 34
Loss: 0.10247094508831857
ROC train: 0.905126	val: 0.773200	test: 0.778431
PRC train: 0.558440	val: 0.354944	test: 0.237486

Epoch: 35
Loss: 0.10223492940135363
ROC train: 0.917355	val: 0.780680	test: 0.758485
PRC train: 0.583446	val: 0.300005	test: 0.147811

Epoch: 36
Loss: 0.10028196229435281
ROC train: 0.913877	val: 0.789257	test: 0.769167
PRC train: 0.569532	val: 0.336988	test: 0.191954

Epoch: 37
Loss: 0.10020587897867585
ROC train: 0.916184	val: 0.770368	test: 0.767896
PRC train: 0.581418	val: 0.302520	test: 0.144832

Epoch: 38
Loss: 0.09980315916644729
ROC train: 0.919510	val: 0.764100	test: 0.752643
PRC train: 0.585683	val: 0.348441	test: 0.228213

Epoch: 39
Loss: 0.0996962596179953
ROC train: 0.920341	val: 0.780068	test: 0.774036
PRC train: 0.598160	val: 0.338174	test: 0.203171

Epoch: 40
Loss: 0.09840229118549504
ROC train: 0.918751	val: 0.755423	test: 0.710773
PRC train: 0.575128	val: 0.266906	test: 0.100339

Epoch: 41
Loss: 0.09787767548715713
ROC train: 0.922099	val: 0.779998	test: 0.754061
PRC train: 0.604452	val: 0.343241	test: 0.211933

Epoch: 42
Loss: 0.09695170775055649
ROC train: 0.926189	val: 0.794441	test: 0.768551
PRC train: 0.592147	val: 0.319678	test: 0.188922

Epoch: 43
Loss: 0.09800390490118364
ROC train: 0.926193	val: 0.781431	test: 0.782752
PRC train: 0.603716	val: 0.321586	test: 0.177349

Epoch: 44
Loss: 0.09766668263889314
ROC train: 0.927116	val: 0.764122	test: 0.766264
PRC train: 0.613881	val: 0.319536	test: 0.143114

Epoch: 45
Loss: 0.09784419290017747
ROC train: 0.932189	val: 0.792974	test: 0.774623
PRC train: 0.630037	val: 0.319956	test: 0.186221

Epoch: 46
Loss: 0.09449881445942167
ROC train: 0.931729	val: 0.786752	test: 0.747492
PRC train: 0.600219	val: 0.310532	test: 0.150755

Epoch: 47
Loss: 0.0949301466898857
ROC train: 0.936138	val: 0.784661	test: 0.776100
PRC train: 0.624239	val: 0.321463	test: 0.214533

Epoch: 48
Loss: 0.09482422764276635
ROC train: 0.935882	val: 0.786694	test: 0.793221
PRC train: 0.620756	val: 0.357886	test: 0.207973

Epoch: 49
Loss: 0.09458328855736883
ROC train: 0.931752	val: 0.772615	test: 0.776813
PRC train: 0.616373	val: 0.316851	test: 0.196854

Epoch: 50
Loss: 0.09312183444728
ROC train: 0.935534	val: 0.761449	test: 0.767348
PRC train: 0.619967	val: 0.260899	test: 0.162941

Epoch: 51
Loss: 0.09518328768927078
ROC train: 0.940639	val: 0.771819	test: 0.774449
PRC train: 0.642382	val: 0.330740	test: 0.174636

Epoch: 52
Loss: 0.0932832595305374
ROC train: 0.940669	val: 0.771256	test: 0.774159
PRC train: 0.643339	val: 0.283078	test: 0.140759

Epoch: 53
Loss: 0.09293733421041941
ROC train: 0.937236	val: 0.792922	test: 0.769152
PRC train: 0.635322	val: 0.338024	test: 0.229532

Epoch: 54
Loss: 0.09196603038239934
ROC train: 0.942791	val: 0.794361	test: 0.785602
PRC train: 0.650073	val: 0.329973	test: 0.214786

Epoch: 55
Loss: 0.09027614291173222
ROC train: 0.943625	val: 0.773546	test: 0.755638
PRC train: 0.636812	val: 0.278966	test: 0.154264

Epoch: 56
Loss: 0.09095673171491636
ROC train: 0.944798	val: 0.789820	test: 0.771222
PRC train: 0.648384	val: 0.314677	test: 0.174056

Epoch: 57
Loss: 0.09117731848163217
ROC train: 0.948145	val: 0.784349	test: 0.784922
PRC train: 0.663129	val: 0.305056	test: 0.197929

Epoch: 58
Loss: 0.08896828533103829
ROC train: 0.944242	val: 0.797864	test: 0.788990
PRC train: 0.658877	val: 0.321251	test: 0.185584

Epoch: 59
Loss: 0.08857971259388468
ROC train: 0.950583	val: 0.778194	test: 0.765032
PRC train: 0.674301	val: 0.326415	test: 0.182054

Epoch: 60
Loss: 0.0908574542409796
ROC train: 0.950050	val: 0.787692	test: 0.773234
PRC train: 0.670507	val: 0.343060	test: 0.165999

Epoch: 61
Loss: 0.08932859710210637
ROC train: 0.943030	val: 0.777175	test: 0.762071
PRC train: 0.641147	val: 0.323651	test: 0.179869

Epoch: 62
Loss: 0.08936420448593071
ROC train: 0.953342	val: 0.775145	test: 0.773686
PRC train: 0.676511	val: 0.302894	test: 0.175628

Epoch: 63
Loss: 0.08803547806980466
ROC train: 0.951955	val: 0.787267	test: 0.768149
PRC train: 0.674596	val: 0.283053	test: 0.156840

Epoch: 64
Loss: 0.08715264879810361
ROC train: 0.951855	val: 0.779933	test: 0.769783
PRC train: 0.670090	val: 0.298297	test: 0.163801

Epoch: 65
Loss: 0.08659150385912276
ROC train: 0.952172	val: 0.774005	test: 0.776124
PRC train: 0.682010	val: 0.296784	test: 0.182933

Epoch: 66
Loss: 0.08819781368153166
ROC train: 0.951459	val: 0.779933	test: 0.779264
PRC train: 0.680574	val: 0.299306	test: 0.165860

Epoch: 67
Loss: 0.0850222461982774
ROC train: 0.955379	val: 0.780117	test: 0.782539
PRC train: 0.681041	val: 0.289143	test: 0.179742

Epoch: 68
Loss: 0.08579642307114858
ROC train: 0.955734	val: 0.786122	test: 0.770577
PRC train: 0.684361	val: 0.325929	test: 0.173449

Epoch: 69
Loss: 0.08545183385568905
ROC train: 0.956981	val: 0.780631	test: 0.767095
PRC train: 0.691809	val: 0.287647	test: 0.134105

Epoch: 70
Loss: 0.08620283451204264
ROC train: 0.961104	val: 0.788302	test: 0.779440
PRC train: 0.699441	val: 0.277069	test: 0.157529

Epoch: 71
Loss: 0.08598450882699896
ROC train: 0.956907	val: 0.790445	test: 0.780732
PRC train: 0.687742	val: 0.324010	test: 0.216821

Epoch: 72
Loss: 0.08390458417905873
ROC train: 0.957108	val: 0.774584	test: 0.769775
PRC train: 0.692433	val: 0.311431	test: 0.170937

Epoch: 73
Loss: 0.08440510410859342
ROC train: 0.959400	val: 0.804456	test: 0.765372
PRC train: 0.703981	val: 0.306536	test: 0.184346

Epoch: 74
Loss: 0.08427398793074273
ROC train: 0.960512	val: 0.793041	test: 0.775639
PRC train: 0.705668	val: 0.282449	test: 0.153593

Epoch: 75
Loss: 0.08360274207121109
ROC train: 0.962208	val: 0.799165	test: 0.779951
PRC train: 0.715529	val: 0.286442	test: 0.158206

Epoch: 76
Loss: 0.08236902399867102
ROC train: 0.960999	val: 0.771296	test: 0.777130
PRC train: 0.710552	val: 0.282347	test: 0.154771

Epoch: 77
Loss: 0.08260807647894362
ROC train: 0.960251	val: 0.778773	test: 0.763647
PRC train: 0.700725	val: 0.278986	test: 0.157452

Epoch: 78
Loss: 0.08293058369758859
ROC train: 0.962548	val: 0.780815	test: 0.782588
PRC train: 0.719056	val: 0.323785	test: 0.186808

Epoch: 79
Loss: 0.08317170735441844
ROC train: 0.965842	val: 0.798372	test: 0.793159
PRC train: 0.737291	val: 0.299255	test: 0.175525

Epoch: 80
Loss: 0.08148652066709602
ROC train: 0.967786	val: 0.793011	test: 0.785174
PRC train: 0.734374	val: 0.305488	test: 0.167107

Epoch: 81
Loss: 0.08074197699373564
ROC train: 0.960713	val: 0.782166	test: 0.778681
PRC train: 0.707963	val: 0.336534	test: 0.198001

Epoch: 82
Loss: 0.08172433596617847
ROC train: 0.966268	val: 0.787689	test: 0.776519
PRC train: 0.724937	val: 0.297404	test: 0.176533

Epoch: 83
Loss: 0.08268525607353894
ROC train: 0.965373	val: 0.786814	test: 0.783959
PRC train: 0.727036	val: 0.330830	test: 0.199207

Epoch: 84
Loss: 0.08003858049255347
ROC train: 0.968238	val: 0.780549	test: 0.781458
PRC train: 0.741145	val: 0.298456	test: 0.174677

Epoch: 85
Loss: 0.07912268788508801
ROC train: 0.969504	val: 0.794900	test: 0.776348
PRC train: 0.743157	val: 0.300790	test: 0.195974

Epoch: 86
Loss: 0.07997497299323111
ROC train: 0.965242	val: 0.792328	test: 0.778292
PRC train: 0.730422	val: 0.334282	test: 0.212104

Epoch: 87
Loss: 0.07951549233834346
ROC train: 0.968627	val: 0.795136	test: 0.767249
PRC train: 0.739687	val: 0.276512	test: 0.143927

Epoch: 88
Loss: 0.07974663003095092
ROC train: 0.967364	val: 0.777527	test: 0.773937
PRC train: 0.727921	val: 0.301346	test: 0.158613

Epoch: 89
Loss: 0.07895384285405614
ROC train: 0.968463	val: 0.778895	test: 0.775266
PRC train: 0.743853	val: 0.301123	test: 0.165752

Epoch: 90
Loss: 0.07915200138935038
ROC train: 0.969932	val: 0.798354	test: 0.776821
PRC train: 0.738246	val: 0.325104	test: 0.199479

Epoch: 91
Loss: 0.07849246108340786
ROC train: 0.974128	val: 0.797494	test: 0.765389
PRC train: 0.757681	val: 0.293736	test: 0.140419

Epoch: 92
Loss: 0.07903028803690332
ROC train: 0.971373	val: 0.793779	test: 0.768902
PRC train: 0.744868	val: 0.304244	test: 0.159396

Epoch: 93
Loss: 0.07824467926722471
ROC train: 0.973382	val: 0.809279	test: 0.775428
PRC train: 0.747543	val: 0.333234	test: 0.209020

Epoch: 94
Loss: 0.07854128944507824
PRC train: 0.643547	val: 0.376207	test: 0.217952

Epoch: 33
Loss: 0.09659781458208741
ROC train: 0.931018	val: 0.766314	test: 0.723081
PRC train: 0.640594	val: 0.347211	test: 0.115344

Epoch: 34
Loss: 0.09632227108049296
ROC train: 0.936517	val: 0.788550	test: 0.727225
PRC train: 0.644804	val: 0.348467	test: 0.173343

Epoch: 35
Loss: 0.09421983659819624
ROC train: 0.938114	val: 0.770852	test: 0.737981
PRC train: 0.648473	val: 0.331849	test: 0.157538

Epoch: 36
Loss: 0.09381359500813523
ROC train: 0.943049	val: 0.807800	test: 0.721010
PRC train: 0.666275	val: 0.331973	test: 0.190133

Epoch: 37
Loss: 0.09306878840881841
ROC train: 0.938597	val: 0.787686	test: 0.728284
PRC train: 0.669447	val: 0.365189	test: 0.217432

Epoch: 38
Loss: 0.09253783235329745
ROC train: 0.947120	val: 0.798709	test: 0.725352
PRC train: 0.697698	val: 0.347122	test: 0.182502

Epoch: 39
Loss: 0.09206102619148403
ROC train: 0.948897	val: 0.756121	test: 0.712329
PRC train: 0.704753	val: 0.350144	test: 0.191705

Epoch: 40
Loss: 0.0902489392205859
ROC train: 0.949249	val: 0.783448	test: 0.718430
PRC train: 0.695147	val: 0.364806	test: 0.227882

Epoch: 41
Loss: 0.09078081850477909
ROC train: 0.950553	val: 0.778990	test: 0.712237
PRC train: 0.698612	val: 0.388571	test: 0.201071

Epoch: 42
Loss: 0.08727901151602485
ROC train: 0.953538	val: 0.787603	test: 0.712038
PRC train: 0.710678	val: 0.350542	test: 0.248386

Epoch: 43
Loss: 0.08851341358478199
ROC train: 0.955688	val: 0.794349	test: 0.720120
PRC train: 0.731745	val: 0.358771	test: 0.198652

Epoch: 44
Loss: 0.0869612463031747
ROC train: 0.953194	val: 0.776871	test: 0.687848
PRC train: 0.714277	val: 0.283178	test: 0.125717

Epoch: 45
Loss: 0.08658298570980076
ROC train: 0.956372	val: 0.777946	test: 0.716522
PRC train: 0.722495	val: 0.311193	test: 0.188721

Epoch: 46
Loss: 0.08474209659678177
ROC train: 0.950670	val: 0.783384	test: 0.735327
PRC train: 0.720576	val: 0.337464	test: 0.143709

Epoch: 47
Loss: 0.08596500701501489
ROC train: 0.962907	val: 0.793066	test: 0.728929
PRC train: 0.748035	val: 0.376367	test: 0.214200

Epoch: 48
Loss: 0.08343560682733572
ROC train: 0.956152	val: 0.772046	test: 0.720228
PRC train: 0.731217	val: 0.339473	test: 0.217358

Epoch: 49
Loss: 0.08182205495904256
ROC train: 0.962631	val: 0.785665	test: 0.726673
PRC train: 0.755285	val: 0.324981	test: 0.179801

Epoch: 50
Loss: 0.08400063292501396
ROC train: 0.969944	val: 0.792913	test: 0.706340
PRC train: 0.781516	val: 0.310116	test: 0.143104

Epoch: 51
Loss: 0.0818386282050591
ROC train: 0.970599	val: 0.795102	test: 0.732451
PRC train: 0.789686	val: 0.363155	test: 0.219781

Epoch: 52
Loss: 0.08075421120738491
ROC train: 0.967513	val: 0.797092	test: 0.735897
PRC train: 0.777404	val: 0.340053	test: 0.171567

Epoch: 53
Loss: 0.0803084612740274
ROC train: 0.960908	val: 0.770371	test: 0.703001
PRC train: 0.746943	val: 0.331662	test: 0.180090

Epoch: 54
Loss: 0.07936236238812426
ROC train: 0.970272	val: 0.788057	test: 0.706450
PRC train: 0.792538	val: 0.381227	test: 0.189794

Epoch: 55
Loss: 0.07673649732726584
ROC train: 0.972777	val: 0.796866	test: 0.723239
PRC train: 0.781964	val: 0.387249	test: 0.243339

Epoch: 56
Loss: 0.07783795697108405
ROC train: 0.969399	val: 0.781948	test: 0.706377
PRC train: 0.773748	val: 0.316649	test: 0.164964

Epoch: 57
Loss: 0.07698695319306106
ROC train: 0.976368	val: 0.791204	test: 0.726573
PRC train: 0.808491	val: 0.361754	test: 0.222444

Epoch: 58
Loss: 0.07619101544267176
ROC train: 0.976028	val: 0.812944	test: 0.740518
PRC train: 0.803056	val: 0.376743	test: 0.253752

Epoch: 59
Loss: 0.07652065251470543
ROC train: 0.978138	val: 0.788357	test: 0.732368
PRC train: 0.813138	val: 0.376837	test: 0.204877

Epoch: 60
Loss: 0.07287740943863132
ROC train: 0.978381	val: 0.784474	test: 0.728172
PRC train: 0.813339	val: 0.349095	test: 0.216965

Epoch: 61
Loss: 0.07247449713260835
ROC train: 0.978844	val: 0.801318	test: 0.720559
PRC train: 0.833031	val: 0.384287	test: 0.196114

Epoch: 62
Loss: 0.07267094935347763
ROC train: 0.979916	val: 0.793939	test: 0.714052
PRC train: 0.830976	val: 0.360821	test: 0.161299

Epoch: 63
Loss: 0.07127622263675978
ROC train: 0.982235	val: 0.801811	test: 0.714141
PRC train: 0.839637	val: 0.358590	test: 0.185005

Epoch: 64
Loss: 0.07120126345144284
ROC train: 0.981495	val: 0.799465	test: 0.714770
PRC train: 0.847075	val: 0.354282	test: 0.189631

Epoch: 65
Loss: 0.06910630290190353
ROC train: 0.981700	val: 0.790197	test: 0.698704
PRC train: 0.845362	val: 0.318699	test: 0.196486

Epoch: 66
Loss: 0.06879913979070537
ROC train: 0.985836	val: 0.796716	test: 0.727270
PRC train: 0.866282	val: 0.350491	test: 0.239797

Epoch: 67
Loss: 0.06641187447976941
ROC train: 0.984163	val: 0.803507	test: 0.724616
PRC train: 0.855459	val: 0.317906	test: 0.221401

Epoch: 68
Loss: 0.06782462043757857
ROC train: 0.981784	val: 0.782126	test: 0.699073
PRC train: 0.845912	val: 0.310928	test: 0.176214

Epoch: 69
Loss: 0.06880242522471423
ROC train: 0.984406	val: 0.778387	test: 0.699817
PRC train: 0.862790	val: 0.318938	test: 0.173589

Epoch: 70
Loss: 0.0669583966443618
ROC train: 0.986659	val: 0.798727	test: 0.723521
PRC train: 0.867399	val: 0.336845	test: 0.184722

Epoch: 71
Loss: 0.06432296949802879
ROC train: 0.983303	val: 0.800219	test: 0.702472
PRC train: 0.851152	val: 0.331410	test: 0.214752

Epoch: 72
Loss: 0.06589791422423247
ROC train: 0.989474	val: 0.811186	test: 0.732704
PRC train: 0.884483	val: 0.360989	test: 0.188442

Epoch: 73
Loss: 0.06373400691824892
ROC train: 0.987465	val: 0.790959	test: 0.707397
PRC train: 0.880994	val: 0.316353	test: 0.226233

Epoch: 74
Loss: 0.06296699208373722
ROC train: 0.989367	val: 0.797111	test: 0.704206
PRC train: 0.887338	val: 0.313889	test: 0.147781

Epoch: 75
Loss: 0.0636177244899895
ROC train: 0.989306	val: 0.781725	test: 0.721690
PRC train: 0.896289	val: 0.338711	test: 0.204054

Epoch: 76
Loss: 0.06255090081601232
ROC train: 0.989264	val: 0.792307	test: 0.710485
PRC train: 0.893587	val: 0.332784	test: 0.171837

Epoch: 77
Loss: 0.062209574595397006
ROC train: 0.988567	val: 0.798262	test: 0.727938
PRC train: 0.887604	val: 0.340552	test: 0.204112

Epoch: 78
Loss: 0.06134193694103323
ROC train: 0.989320	val: 0.800412	test: 0.726067
PRC train: 0.892404	val: 0.330769	test: 0.228826

Epoch: 79
Loss: 0.06010012476529033
ROC train: 0.991518	val: 0.788534	test: 0.721498
PRC train: 0.901683	val: 0.329877	test: 0.166660

Epoch: 80
Loss: 0.06064183364091219
ROC train: 0.991052	val: 0.806134	test: 0.727080
PRC train: 0.903671	val: 0.346445	test: 0.210841

Epoch: 81
Loss: 0.060813176039595455
ROC train: 0.991699	val: 0.799968	test: 0.722013
PRC train: 0.911872	val: 0.323541	test: 0.197829

Epoch: 82
Loss: 0.05950020683118138
ROC train: 0.993364	val: 0.804453	test: 0.725103
PRC train: 0.921329	val: 0.336795	test: 0.215358

Epoch: 83
Loss: 0.05648574504010373
ROC train: 0.992869	val: 0.804383	test: 0.721290
PRC train: 0.916283	val: 0.335699	test: 0.220621

Epoch: 84
Loss: 0.057574002314057286
ROC train: 0.993551	val: 0.814763	test: 0.726461
PRC train: 0.916233	val: 0.327069	test: 0.186467

Epoch: 85
Loss: 0.0580357418241887
ROC train: 0.991948	val: 0.804891	test: 0.757809
PRC train: 0.911332	val: 0.372274	test: 0.263970

Epoch: 86
Loss: 0.05559522208432595
ROC train: 0.994487	val: 0.817381	test: 0.732223
PRC train: 0.925911	val: 0.361413	test: 0.208878

Epoch: 87
Loss: 0.055601838794302444
ROC train: 0.993649	val: 0.774382	test: 0.734288
PRC train: 0.920095	val: 0.337553	test: 0.220871

Epoch: 88
Loss: 0.05407543009752824
ROC train: 0.993969	val: 0.801511	test: 0.740630
PRC train: 0.925673	val: 0.326791	test: 0.191734

Epoch: 89
Loss: 0.05648444286488114
ROC train: 0.992843	val: 0.800549	test: 0.740059
PRC train: 0.913938	val: 0.322388	test: 0.201864

Epoch: 90
Loss: 0.05247183702441582
ROC train: 0.995088	val: 0.797934	test: 0.724216
PRC train: 0.935327	val: 0.296609	test: 0.138099

Epoch: 91
Loss: 0.05547168064156481
ROC train: 0.994728	val: 0.801734	test: 0.735186
PRC train: 0.932435	val: 0.339171	test: 0.163221

Epoch: 92
Loss: 0.05313392313332317
ROC train: 0.995793	val: 0.797377	test: 0.749186
PRC train: 0.942504	val: 0.333309	test: 0.218835

Epoch: 93
Loss: 0.05334314532217168
ROC train: 0.994735	val: 0.812825	test: 0.730084
PRC train: 0.649211	val: 0.286159	test: 0.254687

Epoch: 33
Loss: 0.09951513868890788
ROC train: 0.946908	val: 0.804159	test: 0.746737
PRC train: 0.675996	val: 0.288539	test: 0.205261

Epoch: 34
Loss: 0.0961723689718959
ROC train: 0.948528	val: 0.774624	test: 0.729697
PRC train: 0.665591	val: 0.294537	test: 0.216922

Epoch: 35
Loss: 0.0962199750261176
ROC train: 0.956160	val: 0.781418	test: 0.748970
PRC train: 0.690497	val: 0.297899	test: 0.261555

Epoch: 36
Loss: 0.09444225536879854
ROC train: 0.958911	val: 0.799450	test: 0.733436
PRC train: 0.716925	val: 0.262841	test: 0.228630

Epoch: 37
Loss: 0.09045602718083831
ROC train: 0.956987	val: 0.784199	test: 0.725740
PRC train: 0.711892	val: 0.246523	test: 0.241949

Epoch: 38
Loss: 0.09136952535187448
ROC train: 0.962779	val: 0.795993	test: 0.737853
PRC train: 0.733146	val: 0.280654	test: 0.222807

Epoch: 39
Loss: 0.09005189887989073
ROC train: 0.965168	val: 0.796422	test: 0.744881
PRC train: 0.763397	val: 0.279391	test: 0.171016

Epoch: 40
Loss: 0.08657665541275987
ROC train: 0.971712	val: 0.790243	test: 0.719228
PRC train: 0.787165	val: 0.250134	test: 0.132701

Epoch: 41
Loss: 0.0843651895121627
ROC train: 0.966150	val: 0.798072	test: 0.741905
PRC train: 0.752159	val: 0.304486	test: 0.278249

Epoch: 42
Loss: 0.08241630016601699
ROC train: 0.973452	val: 0.783785	test: 0.753213
PRC train: 0.783807	val: 0.295216	test: 0.235146

Epoch: 43
Loss: 0.08381750870571297
ROC train: 0.977179	val: 0.803529	test: 0.742069
PRC train: 0.809316	val: 0.287185	test: 0.252452

Epoch: 44
Loss: 0.08200342181992308
ROC train: 0.976834	val: 0.808495	test: 0.734833
PRC train: 0.804192	val: 0.258628	test: 0.193990

Epoch: 45
Loss: 0.08073159297303206
ROC train: 0.973487	val: 0.782750	test: 0.742593
PRC train: 0.776413	val: 0.302985	test: 0.277512

Epoch: 46
Loss: 0.07723020522749066
ROC train: 0.978999	val: 0.798835	test: 0.736687
PRC train: 0.816920	val: 0.272914	test: 0.194818

Epoch: 47
Loss: 0.07694307699528719
ROC train: 0.980657	val: 0.794147	test: 0.705809
PRC train: 0.832018	val: 0.262940	test: 0.096969

Epoch: 48
Loss: 0.077980152100996
ROC train: 0.983102	val: 0.794251	test: 0.742293
PRC train: 0.844063	val: 0.273556	test: 0.215609

Epoch: 49
Loss: 0.07482234369961059
ROC train: 0.984143	val: 0.810853	test: 0.725856
PRC train: 0.854973	val: 0.267960	test: 0.147946

Epoch: 50
Loss: 0.07264851080812318
ROC train: 0.987912	val: 0.804781	test: 0.755090
PRC train: 0.877503	val: 0.294128	test: 0.162638

Epoch: 51
Loss: 0.0734700522704367
ROC train: 0.988035	val: 0.794196	test: 0.736534
PRC train: 0.874630	val: 0.245481	test: 0.139806

Epoch: 52
Loss: 0.07085172888385746
ROC train: 0.990824	val: 0.790206	test: 0.732139
PRC train: 0.905070	val: 0.230222	test: 0.203667

Epoch: 53
Loss: 0.06926973749663529
ROC train: 0.989882	val: 0.797775	test: 0.743634
PRC train: 0.896547	val: 0.289418	test: 0.230933

Epoch: 54
Loss: 0.06863209511127481
ROC train: 0.985129	val: 0.778347	test: 0.740690
PRC train: 0.860276	val: 0.254238	test: 0.197337

Epoch: 55
Loss: 0.06590761502517563
ROC train: 0.990901	val: 0.805044	test: 0.731497
PRC train: 0.899790	val: 0.264378	test: 0.159232

Epoch: 56
Loss: 0.06824035223324143
ROC train: 0.992966	val: 0.789505	test: 0.739972
PRC train: 0.927631	val: 0.274549	test: 0.194365

Epoch: 57
Loss: 0.06629110890428498
ROC train: 0.990379	val: 0.794392	test: 0.735901
PRC train: 0.889711	val: 0.267090	test: 0.167411

Epoch: 58
Loss: 0.06503134002146628
ROC train: 0.988744	val: 0.797270	test: 0.698642
PRC train: 0.846995	val: 0.194292	test: 0.084489

Epoch: 59
Loss: 0.06101275902405078
ROC train: 0.991644	val: 0.792643	test: 0.735252
PRC train: 0.909627	val: 0.228574	test: 0.140700

Epoch: 60
Loss: 0.06283893238774786
ROC train: 0.988018	val: 0.791841	test: 0.758365
PRC train: 0.879436	val: 0.316533	test: 0.252851

Epoch: 61
Loss: 0.061051701387159506
ROC train: 0.993863	val: 0.791308	test: 0.764414
PRC train: 0.930711	val: 0.304612	test: 0.219898

Epoch: 62
Loss: 0.05970192752859386
ROC train: 0.993539	val: 0.792999	test: 0.740379
PRC train: 0.934178	val: 0.253078	test: 0.185868

Epoch: 63
Loss: 0.06000015223199383
ROC train: 0.995052	val: 0.799349	test: 0.754820
PRC train: 0.943669	val: 0.271318	test: 0.243620

Epoch: 64
Loss: 0.05603868898312612
ROC train: 0.994269	val: 0.793400	test: 0.731551
PRC train: 0.936179	val: 0.267145	test: 0.162470

Epoch: 65
Loss: 0.057244972256826385
ROC train: 0.994674	val: 0.783764	test: 0.723444
PRC train: 0.938994	val: 0.266650	test: 0.175424

Epoch: 66
Loss: 0.0571377550476628
ROC train: 0.993592	val: 0.789640	test: 0.742564
PRC train: 0.927215	val: 0.267474	test: 0.178773

Epoch: 67
Loss: 0.05231163366614454
ROC train: 0.996666	val: 0.813893	test: 0.752894
PRC train: 0.955685	val: 0.281859	test: 0.197317

Epoch: 68
Loss: 0.05538585733289451
ROC train: 0.996322	val: 0.799306	test: 0.727753
PRC train: 0.951774	val: 0.270733	test: 0.126967

Epoch: 69
Loss: 0.05291377207544512
ROC train: 0.996290	val: 0.821364	test: 0.734294
PRC train: 0.947324	val: 0.293303	test: 0.129203

Epoch: 70
Loss: 0.054517104406378594
ROC train: 0.996669	val: 0.796958	test: 0.748458
PRC train: 0.954126	val: 0.268328	test: 0.168868

Epoch: 71
Loss: 0.05256756460751412
ROC train: 0.996014	val: 0.788424	test: 0.722320
PRC train: 0.950385	val: 0.276011	test: 0.193368

Epoch: 72
Loss: 0.050604337361680914
ROC train: 0.996956	val: 0.787043	test: 0.753651
PRC train: 0.960935	val: 0.309336	test: 0.214740

Epoch: 73
Loss: 0.04846720879071407
ROC train: 0.996042	val: 0.794422	test: 0.737253
PRC train: 0.954516	val: 0.317940	test: 0.191467

Epoch: 74
Loss: 0.04704312426733885
ROC train: 0.997193	val: 0.775788	test: 0.721675
PRC train: 0.965628	val: 0.270886	test: 0.143687

Epoch: 75
Loss: 0.048329264225585644
ROC train: 0.997894	val: 0.806643	test: 0.752720
PRC train: 0.973150	val: 0.247704	test: 0.182824

Epoch: 76
Loss: 0.050305534649202344
ROC train: 0.998627	val: 0.810148	test: 0.736071
PRC train: 0.979966	val: 0.268009	test: 0.144489

Epoch: 77
Loss: 0.04680376833920064
ROC train: 0.997628	val: 0.802157	test: 0.739022
PRC train: 0.964120	val: 0.230237	test: 0.145041

Epoch: 78
Loss: 0.046984296489425724
ROC train: 0.998071	val: 0.779480	test: 0.718925
PRC train: 0.973858	val: 0.257023	test: 0.118412

Epoch: 79
Loss: 0.04523427388687016
ROC train: 0.998322	val: 0.804646	test: 0.728651
PRC train: 0.977566	val: 0.238397	test: 0.131528

Epoch: 80
Loss: 0.045180795724436174
ROC train: 0.998596	val: 0.791596	test: 0.693449
PRC train: 0.979549	val: 0.239081	test: 0.096023

Epoch: 81
Loss: 0.0445730577173856
ROC train: 0.998213	val: 0.793378	test: 0.723822
PRC train: 0.973865	val: 0.298870	test: 0.185679

Epoch: 82
Loss: 0.04104176791266134
ROC train: 0.998949	val: 0.786492	test: 0.717716
PRC train: 0.987596	val: 0.269596	test: 0.176733

Epoch: 83
Loss: 0.042821062229639
ROC train: 0.998958	val: 0.810638	test: 0.745804
PRC train: 0.986115	val: 0.285308	test: 0.184839

Epoch: 84
Loss: 0.04164488999638122
ROC train: 0.998356	val: 0.814224	test: 0.754277
PRC train: 0.975674	val: 0.282610	test: 0.163785

Epoch: 85
Loss: 0.04179628649886191
ROC train: 0.998628	val: 0.803121	test: 0.710848
PRC train: 0.977781	val: 0.247766	test: 0.093132

Epoch: 86
Loss: 0.04108619527457812
ROC train: 0.998927	val: 0.803259	test: 0.722654
PRC train: 0.985866	val: 0.286576	test: 0.148339

Epoch: 87
Loss: 0.04119066297845605
ROC train: 0.999400	val: 0.806039	test: 0.726327
PRC train: 0.989080	val: 0.229622	test: 0.128451

Epoch: 88
Loss: 0.04049585397083356
ROC train: 0.998911	val: 0.812586	test: 0.734605
PRC train: 0.989872	val: 0.285768	test: 0.187172

Epoch: 89
Loss: 0.04074364650151914
ROC train: 0.998892	val: 0.799349	test: 0.729610
PRC train: 0.982049	val: 0.276731	test: 0.144302

Epoch: 90
Loss: 0.03923093242563815
ROC train: 0.998722	val: 0.820161	test: 0.737245
PRC train: 0.980951	val: 0.339927	test: 0.227921

Epoch: 91
Loss: 0.03760941844075755
ROC train: 0.999577	val: 0.795687	test: 0.730223
PRC train: 0.992930	val: 0.258396	test: 0.134345

Epoch: 92
Loss: 0.03752931868615413
ROC train: 0.999427	val: 0.807445	test: 0.734902
PRC train: 0.991731	val: 0.300734	test: 0.164451

Epoch: 93
Loss: 0.037767757504742684
ROC train: 0.999334	val: 0.810644	test: 0.730030
PRC train: 0.704694	val: 0.293502	test: 0.193182

Epoch: 33
Loss: 0.0926720714229692
ROC train: 0.960291	val: 0.743193	test: 0.728046
PRC train: 0.709826	val: 0.277588	test: 0.177160

Epoch: 34
Loss: 0.09316490914316446
ROC train: 0.952550	val: 0.740857	test: 0.725875
PRC train: 0.707304	val: 0.273529	test: 0.204251

Epoch: 35
Loss: 0.09214184249498082
ROC train: 0.957379	val: 0.757404	test: 0.724263
PRC train: 0.703710	val: 0.280760	test: 0.166850

Epoch: 36
Loss: 0.08888590206059271
ROC train: 0.964259	val: 0.732624	test: 0.721742
PRC train: 0.750186	val: 0.252185	test: 0.164934

Epoch: 37
Loss: 0.08896002931077068
ROC train: 0.959951	val: 0.762067	test: 0.732519
PRC train: 0.739536	val: 0.269359	test: 0.179298

Epoch: 38
Loss: 0.08572775750402803
ROC train: 0.954258	val: 0.703704	test: 0.708310
PRC train: 0.678091	val: 0.234260	test: 0.177956

Epoch: 39
Loss: 0.08759019209901106
ROC train: 0.969264	val: 0.751412	test: 0.719459
PRC train: 0.772224	val: 0.264387	test: 0.150617

Epoch: 40
Loss: 0.08572830454236065
ROC train: 0.968887	val: 0.751157	test: 0.731563
PRC train: 0.776150	val: 0.269873	test: 0.193666

Epoch: 41
Loss: 0.08247087072441872
ROC train: 0.969689	val: 0.763521	test: 0.723284
PRC train: 0.785485	val: 0.251974	test: 0.194469

Epoch: 42
Loss: 0.07965647246988886
ROC train: 0.973133	val: 0.773742	test: 0.736659
PRC train: 0.801731	val: 0.307501	test: 0.170832

Epoch: 43
Loss: 0.08274159106199272
ROC train: 0.975309	val: 0.746607	test: 0.726101
PRC train: 0.802781	val: 0.252664	test: 0.160580

Epoch: 44
Loss: 0.07755444669579328
ROC train: 0.978421	val: 0.790102	test: 0.734873
PRC train: 0.838599	val: 0.285969	test: 0.192797

Epoch: 45
Loss: 0.07544218334197253
ROC train: 0.982237	val: 0.773690	test: 0.723089
PRC train: 0.847203	val: 0.310098	test: 0.194406

Epoch: 46
Loss: 0.07842334003805786
ROC train: 0.976197	val: 0.760640	test: 0.727704
PRC train: 0.826240	val: 0.276633	test: 0.156374

Epoch: 47
Loss: 0.07166341990043353
ROC train: 0.982288	val: 0.762863	test: 0.725700
PRC train: 0.841797	val: 0.289039	test: 0.172305

Epoch: 48
Loss: 0.07298663803835283
ROC train: 0.983042	val: 0.758592	test: 0.732784
PRC train: 0.858895	val: 0.249855	test: 0.162609

Epoch: 49
Loss: 0.072342969858218
ROC train: 0.981259	val: 0.810473	test: 0.744076
PRC train: 0.851806	val: 0.295933	test: 0.165456

Epoch: 50
Loss: 0.07328462024029873
ROC train: 0.982148	val: 0.742710	test: 0.720288
PRC train: 0.855281	val: 0.273429	test: 0.170272

Epoch: 51
Loss: 0.06909539258763829
ROC train: 0.982274	val: 0.786440	test: 0.733145
PRC train: 0.842021	val: 0.290915	test: 0.188288

Epoch: 52
Loss: 0.06743710705125612
ROC train: 0.982931	val: 0.764350	test: 0.734697
PRC train: 0.848293	val: 0.301151	test: 0.179690

Epoch: 53
Loss: 0.06651895762959911
ROC train: 0.986106	val: 0.752195	test: 0.733620
PRC train: 0.864797	val: 0.296382	test: 0.180410

Epoch: 54
Loss: 0.06796405397988903
ROC train: 0.988444	val: 0.764939	test: 0.725995
PRC train: 0.899066	val: 0.329968	test: 0.191143

Epoch: 55
Loss: 0.06258625656106775
ROC train: 0.987113	val: 0.768179	test: 0.727451
PRC train: 0.888068	val: 0.259026	test: 0.183957

Epoch: 56
Loss: 0.0659416591342452
ROC train: 0.988279	val: 0.743579	test: 0.728369
PRC train: 0.891383	val: 0.280068	test: 0.188552

Epoch: 57
Loss: 0.06254690910969557
ROC train: 0.988468	val: 0.773663	test: 0.735082
PRC train: 0.887918	val: 0.318803	test: 0.210309

Epoch: 58
Loss: 0.062229804011334884
ROC train: 0.992176	val: 0.764664	test: 0.738247
PRC train: 0.916376	val: 0.280143	test: 0.209448

Epoch: 59
Loss: 0.06203472151314683
ROC train: 0.992119	val: 0.768301	test: 0.736244
PRC train: 0.920682	val: 0.286675	test: 0.178198

Epoch: 60
Loss: 0.057402953811173864
ROC train: 0.994035	val: 0.772021	test: 0.730630
PRC train: 0.939512	val: 0.264438	test: 0.165162

Epoch: 61
Loss: 0.057548251507528146
ROC train: 0.985180	val: 0.752388	test: 0.720493
PRC train: 0.877285	val: 0.302228	test: 0.212022

Epoch: 62
Loss: 0.055700321545030664
ROC train: 0.989124	val: 0.742563	test: 0.723359
PRC train: 0.890947	val: 0.285539	test: 0.185205

Epoch: 63
Loss: 0.05821242612780761
ROC train: 0.992939	val: 0.780016	test: 0.711895
PRC train: 0.921778	val: 0.248618	test: 0.150297

Epoch: 64
Loss: 0.05579026257152917
ROC train: 0.994939	val: 0.783222	test: 0.736084
PRC train: 0.942585	val: 0.299191	test: 0.179371

Epoch: 65
Loss: 0.055014462194292596
ROC train: 0.992353	val: 0.743891	test: 0.728828
PRC train: 0.919564	val: 0.269015	test: 0.205195

Epoch: 66
Loss: 0.05442912640378288
ROC train: 0.990328	val: 0.782328	test: 0.727111
PRC train: 0.898830	val: 0.280726	test: 0.186918

Epoch: 67
Loss: 0.05198509054123781
ROC train: 0.996269	val: 0.788516	test: 0.736223
PRC train: 0.955815	val: 0.272847	test: 0.194162

Epoch: 68
Loss: 0.05021902367814527
ROC train: 0.994496	val: 0.804909	test: 0.730957
PRC train: 0.939132	val: 0.272080	test: 0.171254

Epoch: 69
Loss: 0.05173931989455271
ROC train: 0.993920	val: 0.769581	test: 0.727712
PRC train: 0.934195	val: 0.267488	test: 0.128577

Epoch: 70
Loss: 0.049824281026438835
ROC train: 0.993307	val: 0.762658	test: 0.721619
PRC train: 0.929857	val: 0.291727	test: 0.216643

Epoch: 71
Loss: 0.04804497918158853
ROC train: 0.993831	val: 0.769217	test: 0.722971
PRC train: 0.931665	val: 0.267002	test: 0.179605

Epoch: 72
Loss: 0.04756369224743189
ROC train: 0.995956	val: 0.781572	test: 0.721265
PRC train: 0.949513	val: 0.331419	test: 0.230841

Epoch: 73
Loss: 0.0463980790701217
ROC train: 0.996075	val: 0.786036	test: 0.730097
PRC train: 0.950171	val: 0.251051	test: 0.159722

Epoch: 74
Loss: 0.04664018374833682
ROC train: 0.997210	val: 0.741727	test: 0.709597
PRC train: 0.966245	val: 0.254570	test: 0.124692

Epoch: 75
Loss: 0.04685634500520834
ROC train: 0.997504	val: 0.767260	test: 0.738695
PRC train: 0.966881	val: 0.255862	test: 0.172028

Epoch: 76
Loss: 0.04837747670780244
ROC train: 0.996333	val: 0.771345	test: 0.725394
PRC train: 0.955942	val: 0.276241	test: 0.144179

Epoch: 77
Loss: 0.04483561489565415
ROC train: 0.996530	val: 0.751638	test: 0.722652
PRC train: 0.965441	val: 0.247208	test: 0.201094

Epoch: 78
Loss: 0.04568772578731106
ROC train: 0.997276	val: 0.781415	test: 0.743336
PRC train: 0.962180	val: 0.255553	test: 0.167208

Epoch: 79
Loss: 0.04460819816008336
ROC train: 0.998188	val: 0.743833	test: 0.709017
PRC train: 0.977198	val: 0.290940	test: 0.192796

Epoch: 80
Loss: 0.040553307735542866
ROC train: 0.997778	val: 0.756709	test: 0.715273
PRC train: 0.971814	val: 0.256218	test: 0.174317

Epoch: 81
Loss: 0.04215261604707288
ROC train: 0.998178	val: 0.754305	test: 0.739379
PRC train: 0.976149	val: 0.297262	test: 0.171647

Epoch: 82
Loss: 0.041112518212020464
ROC train: 0.997800	val: 0.745811	test: 0.716315
PRC train: 0.971564	val: 0.253324	test: 0.175681

Epoch: 83
Loss: 0.0413614002824182
ROC train: 0.999235	val: 0.759399	test: 0.716594
PRC train: 0.987626	val: 0.266671	test: 0.149739

Epoch: 84
Loss: 0.041297684426329175
ROC train: 0.997220	val: 0.735260	test: 0.726296
PRC train: 0.957915	val: 0.266559	test: 0.217785

Epoch: 85
Loss: 0.0381764608407432
ROC train: 0.998001	val: 0.757196	test: 0.713337
PRC train: 0.971873	val: 0.227394	test: 0.144416

Epoch: 86
Loss: 0.040679845628783295
ROC train: 0.997585	val: 0.761929	test: 0.734387
PRC train: 0.961164	val: 0.270649	test: 0.189403

Epoch: 87
Loss: 0.039644255487073635
ROC train: 0.999065	val: 0.779220	test: 0.724126
PRC train: 0.985982	val: 0.228420	test: 0.153610

Epoch: 88
Loss: 0.03813561502173551
ROC train: 0.999285	val: 0.747425	test: 0.716501
PRC train: 0.988018	val: 0.218235	test: 0.128258

Epoch: 89
Loss: 0.03806563734785319
ROC train: 0.998594	val: 0.756154	test: 0.726399
PRC train: 0.978669	val: 0.234665	test: 0.132092

Epoch: 90
Loss: 0.03774814158297729
ROC train: 0.999162	val: 0.748702	test: 0.739168
PRC train: 0.986998	val: 0.274268	test: 0.214240

Epoch: 91
Loss: 0.0347524541501564
ROC train: 0.998719	val: 0.766568	test: 0.743371
PRC train: 0.980808	val: 0.244564	test: 0.175255

Epoch: 92
Loss: 0.03679847686585285
ROC train: 0.997353	val: 0.748604	test: 0.730481
PRC train: 0.959466	val: 0.308419	test: 0.212376

Epoch: 93
Loss: 0.03648312760500306
ROC train: 0.999395	val: 0.756464	test: 0.718969
PRC train: 0.628011	val: 0.317909	test: 0.196610

Epoch: 33
Loss: 0.09660759982453973
ROC train: 0.951240	val: 0.761513	test: 0.705543
PRC train: 0.677875	val: 0.233915	test: 0.133169

Epoch: 34
Loss: 0.09689312865583204
ROC train: 0.943752	val: 0.749930	test: 0.718581
PRC train: 0.672802	val: 0.298194	test: 0.220753

Epoch: 35
Loss: 0.0946455622737796
ROC train: 0.957815	val: 0.749902	test: 0.735200
PRC train: 0.726866	val: 0.311856	test: 0.161960

Epoch: 36
Loss: 0.09192733437980762
ROC train: 0.951778	val: 0.747952	test: 0.677236
PRC train: 0.691875	val: 0.274306	test: 0.164630

Epoch: 37
Loss: 0.09231169159773173
ROC train: 0.945255	val: 0.752012	test: 0.670832
PRC train: 0.668107	val: 0.293830	test: 0.171940

Epoch: 38
Loss: 0.09139807746484986
ROC train: 0.960800	val: 0.776749	test: 0.682582
PRC train: 0.739257	val: 0.280570	test: 0.155807

Epoch: 39
Loss: 0.08808145732466789
ROC train: 0.958944	val: 0.738288	test: 0.698785
PRC train: 0.729045	val: 0.247317	test: 0.174352

Epoch: 40
Loss: 0.08791786665425057
ROC train: 0.965002	val: 0.761886	test: 0.712167
PRC train: 0.751726	val: 0.273551	test: 0.179959

Epoch: 41
Loss: 0.08621296458658259
ROC train: 0.962698	val: 0.765227	test: 0.710035
PRC train: 0.738122	val: 0.293804	test: 0.153552

Epoch: 42
Loss: 0.08421127635799634
ROC train: 0.957924	val: 0.746145	test: 0.714274
PRC train: 0.742186	val: 0.300139	test: 0.166365

Epoch: 43
Loss: 0.08512153958897932
ROC train: 0.965511	val: 0.755496	test: 0.704135
PRC train: 0.769002	val: 0.218675	test: 0.149984

Epoch: 44
Loss: 0.08381820416566205
ROC train: 0.975085	val: 0.749639	test: 0.718907
PRC train: 0.808193	val: 0.265115	test: 0.147951

Epoch: 45
Loss: 0.08153800408403243
ROC train: 0.973005	val: 0.754688	test: 0.714276
PRC train: 0.792057	val: 0.243072	test: 0.128913

Epoch: 46
Loss: 0.07761348710650563
ROC train: 0.978828	val: 0.772588	test: 0.735157
PRC train: 0.819282	val: 0.243610	test: 0.131458

Epoch: 47
Loss: 0.07784490798289159
ROC train: 0.974213	val: 0.755429	test: 0.735180
PRC train: 0.809379	val: 0.325828	test: 0.176156

Epoch: 48
Loss: 0.07831057899362841
ROC train: 0.974146	val: 0.736794	test: 0.716049
PRC train: 0.807501	val: 0.235606	test: 0.149579

Epoch: 49
Loss: 0.07465111966151414
ROC train: 0.981633	val: 0.744590	test: 0.708478
PRC train: 0.853400	val: 0.282366	test: 0.163788

Epoch: 50
Loss: 0.07421177159516826
ROC train: 0.983129	val: 0.772919	test: 0.724929
PRC train: 0.860651	val: 0.235177	test: 0.163951

Epoch: 51
Loss: 0.07673169574604019
ROC train: 0.983884	val: 0.758068	test: 0.706464
PRC train: 0.864803	val: 0.267631	test: 0.180574

Epoch: 52
Loss: 0.07059271740995272
ROC train: 0.982877	val: 0.776878	test: 0.723703
PRC train: 0.851714	val: 0.289767	test: 0.200065

Epoch: 53
Loss: 0.07115220059521486
ROC train: 0.988996	val: 0.757719	test: 0.716167
PRC train: 0.894646	val: 0.265403	test: 0.148878

Epoch: 54
Loss: 0.07051855038153763
ROC train: 0.984566	val: 0.773880	test: 0.708063
PRC train: 0.852770	val: 0.280044	test: 0.172731

Epoch: 55
Loss: 0.0686316369376999
ROC train: 0.988668	val: 0.783066	test: 0.726934
PRC train: 0.875084	val: 0.332216	test: 0.173458

Epoch: 56
Loss: 0.06759554590340335
ROC train: 0.988032	val: 0.750876	test: 0.709067
PRC train: 0.891610	val: 0.262304	test: 0.131512

Epoch: 57
Loss: 0.06648421651258538
ROC train: 0.987543	val: 0.775432	test: 0.715732
PRC train: 0.880194	val: 0.283809	test: 0.175708

Epoch: 58
Loss: 0.06836612470155887
ROC train: 0.987827	val: 0.765925	test: 0.729798
PRC train: 0.882388	val: 0.286699	test: 0.165256

Epoch: 59
Loss: 0.06378302885283628
ROC train: 0.989169	val: 0.763583	test: 0.710288
PRC train: 0.889808	val: 0.294503	test: 0.172503

Epoch: 60
Loss: 0.06461289723999539
ROC train: 0.991789	val: 0.746849	test: 0.723461
PRC train: 0.919483	val: 0.295815	test: 0.197074

Epoch: 61
Loss: 0.06173555566853529
ROC train: 0.990448	val: 0.758742	test: 0.721374
PRC train: 0.910772	val: 0.309288	test: 0.174810

Epoch: 62
Loss: 0.06260808261374336
ROC train: 0.988615	val: 0.776060	test: 0.727218
PRC train: 0.888449	val: 0.205907	test: 0.135233

Epoch: 63
Loss: 0.06083170663124163
ROC train: 0.993475	val: 0.761651	test: 0.692244
PRC train: 0.926906	val: 0.177566	test: 0.100360

Epoch: 64
Loss: 0.05928522931006302
ROC train: 0.991629	val: 0.774474	test: 0.725655
PRC train: 0.901002	val: 0.243106	test: 0.172549

Epoch: 65
Loss: 0.0601110887224696
ROC train: 0.992451	val: 0.764174	test: 0.710802
PRC train: 0.926704	val: 0.259704	test: 0.191508

Epoch: 66
Loss: 0.056571049180197945
ROC train: 0.991988	val: 0.767179	test: 0.704033
PRC train: 0.918022	val: 0.268941	test: 0.182741

Epoch: 67
Loss: 0.05422809970485467
ROC train: 0.993418	val: 0.768433	test: 0.732308
PRC train: 0.925701	val: 0.247635	test: 0.192050

Epoch: 68
Loss: 0.05538155944221599
ROC train: 0.996142	val: 0.762101	test: 0.708820
PRC train: 0.953360	val: 0.243919	test: 0.157743

Epoch: 69
Loss: 0.05535546857032303
ROC train: 0.994553	val: 0.765842	test: 0.719699
PRC train: 0.935165	val: 0.229940	test: 0.169064

Epoch: 70
Loss: 0.052624477216572554
ROC train: 0.994786	val: 0.746580	test: 0.713509
PRC train: 0.945147	val: 0.246213	test: 0.212884

Epoch: 71
Loss: 0.053117086568352824
ROC train: 0.994712	val: 0.756874	test: 0.696976
PRC train: 0.946713	val: 0.172723	test: 0.108916

Epoch: 72
Loss: 0.0518798830985173
ROC train: 0.996601	val: 0.770346	test: 0.722069
PRC train: 0.956862	val: 0.251198	test: 0.170375

Epoch: 73
Loss: 0.04939540773124717
ROC train: 0.993122	val: 0.765352	test: 0.726698
PRC train: 0.909728	val: 0.264367	test: 0.194425

Epoch: 74
Loss: 0.05167027887622963
ROC train: 0.994910	val: 0.758907	test: 0.718233
PRC train: 0.945133	val: 0.303741	test: 0.190879

Epoch: 75
Loss: 0.04736264758984024
ROC train: 0.996358	val: 0.777236	test: 0.733000
PRC train: 0.956239	val: 0.288252	test: 0.189638

Epoch: 76
Loss: 0.04995256663752064
ROC train: 0.992868	val: 0.751087	test: 0.727588
PRC train: 0.926331	val: 0.230427	test: 0.173704

Epoch: 77
Loss: 0.04385737413653599
ROC train: 0.997862	val: 0.770867	test: 0.735883
PRC train: 0.968052	val: 0.248428	test: 0.178212

Epoch: 78
Loss: 0.04687009864721163
ROC train: 0.997437	val: 0.746742	test: 0.717604
PRC train: 0.968828	val: 0.238460	test: 0.189416

Epoch: 79
Loss: 0.04674813711056357
ROC train: 0.996401	val: 0.759774	test: 0.715914
PRC train: 0.960329	val: 0.265639	test: 0.163337

Epoch: 80
Loss: 0.04561258723812415
ROC train: 0.996523	val: 0.774012	test: 0.721368
PRC train: 0.954068	val: 0.300933	test: 0.208704

Epoch: 81
Loss: 0.045290150373582284
ROC train: 0.997847	val: 0.774033	test: 0.723911
PRC train: 0.971828	val: 0.282406	test: 0.194828

Epoch: 82
Loss: 0.04745109206877248
ROC train: 0.997845	val: 0.769805	test: 0.721379
PRC train: 0.972212	val: 0.275606	test: 0.190017

Epoch: 83
Loss: 0.04141352157861884
ROC train: 0.997586	val: 0.768350	test: 0.737295
PRC train: 0.971864	val: 0.294332	test: 0.194441

Epoch: 84
Loss: 0.042463763219520806
ROC train: 0.997821	val: 0.772184	test: 0.735018
PRC train: 0.972453	val: 0.263126	test: 0.169875

Epoch: 85
Loss: 0.04032753414557188
ROC train: 0.997833	val: 0.771675	test: 0.764472
PRC train: 0.964748	val: 0.254710	test: 0.209734

Epoch: 86
Loss: 0.042356308130794655
ROC train: 0.998458	val: 0.775934	test: 0.714193
PRC train: 0.979262	val: 0.264246	test: 0.121334

Epoch: 87
Loss: 0.040139542383038636
ROC train: 0.997039	val: 0.761724	test: 0.727853
PRC train: 0.963148	val: 0.226010	test: 0.151046

Epoch: 88
Loss: 0.04191782799933507
ROC train: 0.998434	val: 0.753552	test: 0.722183
PRC train: 0.975663	val: 0.219888	test: 0.159906

Epoch: 89
Loss: 0.039570668265847035
ROC train: 0.998881	val: 0.775631	test: 0.740534
PRC train: 0.982705	val: 0.225434	test: 0.175104

Epoch: 90
Loss: 0.03850370421699047
ROC train: 0.998689	val: 0.747887	test: 0.692078
PRC train: 0.976959	val: 0.133218	test: 0.090305

Epoch: 91
Loss: 0.04062779563965492
ROC train: 0.997614	val: 0.775882	test: 0.733396
PRC train: 0.966798	val: 0.277963	test: 0.161062

Epoch: 92
Loss: 0.03941372217810098
ROC train: 0.999422	val: 0.766537	test: 0.734477
PRC train: 0.989617	val: 0.242572	test: 0.155605

Epoch: 93
Loss: 0.03889485329252968
ROC train: 0.999193	val: 0.763840	test: 0.729524
ROC train: 0.973622	val: 0.799009	test: 0.744491
PRC train: 0.758197	val: 0.323599	test: 0.164617

Epoch: 95
Loss: 0.07378186815386314
ROC train: 0.978476	val: 0.797500	test: 0.745028
PRC train: 0.778897	val: 0.312954	test: 0.181839

Epoch: 96
Loss: 0.07408447984920055
ROC train: 0.982065	val: 0.786544	test: 0.740943
PRC train: 0.788747	val: 0.312421	test: 0.168272

Epoch: 97
Loss: 0.07427759343829342
ROC train: 0.977986	val: 0.803715	test: 0.743649
PRC train: 0.774787	val: 0.315071	test: 0.151011

Epoch: 98
Loss: 0.07394256787566807
ROC train: 0.979361	val: 0.798648	test: 0.753346
PRC train: 0.773963	val: 0.281812	test: 0.160677

Epoch: 99
Loss: 0.0741959218572491
ROC train: 0.982368	val: 0.794364	test: 0.756670
PRC train: 0.802230	val: 0.332620	test: 0.172307

Epoch: 100
Loss: 0.07370175282370615
ROC train: 0.982317	val: 0.797374	test: 0.749734
PRC train: 0.804442	val: 0.319562	test: 0.156439

Epoch: 101
Loss: 0.07252636950516932
ROC train: 0.981130	val: 0.775625	test: 0.753444
PRC train: 0.794814	val: 0.303386	test: 0.194053

Epoch: 102
Loss: 0.07243643868641586
ROC train: 0.982780	val: 0.788865	test: 0.736646
PRC train: 0.812878	val: 0.300534	test: 0.181803

Epoch: 103
Loss: 0.07055645046799094
ROC train: 0.981914	val: 0.804202	test: 0.758278
PRC train: 0.801183	val: 0.321913	test: 0.188173

Epoch: 104
Loss: 0.07171693027661513
ROC train: 0.981741	val: 0.787781	test: 0.736644
PRC train: 0.792893	val: 0.300095	test: 0.137101

Epoch: 105
Loss: 0.07121267613809247
ROC train: 0.983308	val: 0.785001	test: 0.748636
PRC train: 0.802911	val: 0.326392	test: 0.176355

Epoch: 106
Loss: 0.07163478427458264
ROC train: 0.982732	val: 0.792821	test: 0.758528
PRC train: 0.804295	val: 0.335702	test: 0.160434

Epoch: 107
Loss: 0.07044828170719158
ROC train: 0.981307	val: 0.790172	test: 0.748218
PRC train: 0.790828	val: 0.299335	test: 0.136772

Epoch: 108
Loss: 0.06853190399963952
ROC train: 0.982395	val: 0.804089	test: 0.735400
PRC train: 0.801210	val: 0.311066	test: 0.157052

Epoch: 109
Loss: 0.07188488772932225
ROC train: 0.984076	val: 0.793060	test: 0.735230
PRC train: 0.810829	val: 0.284963	test: 0.142480

Epoch: 110
Loss: 0.06851222706929523
ROC train: 0.971711	val: 0.777900	test: 0.752820
PRC train: 0.766685	val: 0.312879	test: 0.175925

Epoch: 111
Loss: 0.06910349526482018
ROC train: 0.983827	val: 0.786911	test: 0.755528
PRC train: 0.814649	val: 0.329185	test: 0.183905

Epoch: 112
Loss: 0.06911696609893399
ROC train: 0.984197	val: 0.793008	test: 0.753657
PRC train: 0.821953	val: 0.284261	test: 0.144647

Epoch: 113
Loss: 0.06920021155151339
ROC train: 0.985137	val: 0.796272	test: 0.760617
PRC train: 0.819057	val: 0.319265	test: 0.185615

Epoch: 114
Loss: 0.06804453811608355
ROC train: 0.984123	val: 0.790035	test: 0.723873
PRC train: 0.816681	val: 0.310533	test: 0.145399

Epoch: 115
Loss: 0.06756146001143123
ROC train: 0.985461	val: 0.810546	test: 0.748131
PRC train: 0.823100	val: 0.315664	test: 0.155476

Epoch: 116
Loss: 0.06759560961775649
ROC train: 0.985422	val: 0.804600	test: 0.729923
PRC train: 0.823004	val: 0.290036	test: 0.123965

Epoch: 117
Loss: 0.06840322223309087
ROC train: 0.985724	val: 0.791985	test: 0.737426
PRC train: 0.824681	val: 0.313822	test: 0.135008

Epoch: 118
Loss: 0.06832164246968025
ROC train: 0.987120	val: 0.783435	test: 0.743104
PRC train: 0.842998	val: 0.291085	test: 0.149382

Epoch: 119
Loss: 0.0686003834623153
ROC train: 0.983908	val: 0.790044	test: 0.756189
PRC train: 0.816870	val: 0.275863	test: 0.140282

Epoch: 120
Loss: 0.0672850736782509
ROC train: 0.984044	val: 0.787117	test: 0.739800
PRC train: 0.818357	val: 0.281173	test: 0.142461

Early stopping
Best (ROC):	 train: 0.972260	val: 0.821202	test: 0.762477
Best (PRC):	 train: 0.738583	val: 0.345169	test: 0.183068

PRC train: 0.966580	val: 0.305577	test: 0.184753

Epoch: 94
Loss: 0.04841875167220173
ROC train: 0.997040	val: 0.779909	test: 0.745405
PRC train: 0.962433	val: 0.354951	test: 0.185222

Epoch: 95
Loss: 0.04697680908951599
ROC train: 0.997656	val: 0.788406	test: 0.751726
PRC train: 0.972136	val: 0.314137	test: 0.201957

Epoch: 96
Loss: 0.04591636900434508
ROC train: 0.997220	val: 0.801226	test: 0.748836
PRC train: 0.967185	val: 0.335635	test: 0.178240

Epoch: 97
Loss: 0.04306806517435702
ROC train: 0.997568	val: 0.775099	test: 0.733104
PRC train: 0.967826	val: 0.333765	test: 0.172006

Epoch: 98
Loss: 0.04628090078980529
ROC train: 0.997649	val: 0.803060	test: 0.757373
PRC train: 0.969739	val: 0.305566	test: 0.182806

Epoch: 99
Loss: 0.04068594195016721
ROC train: 0.997394	val: 0.761173	test: 0.760789
PRC train: 0.966094	val: 0.299063	test: 0.171080

Epoch: 100
Loss: 0.042933787128243514
ROC train: 0.997847	val: 0.794027	test: 0.737805
PRC train: 0.970783	val: 0.333734	test: 0.189185

Epoch: 101
Loss: 0.04469656565545003
ROC train: 0.997695	val: 0.796309	test: 0.743948
PRC train: 0.969701	val: 0.336991	test: 0.196504

Epoch: 102
Loss: 0.040112612583450155
ROC train: 0.998776	val: 0.784995	test: 0.734900
PRC train: 0.981551	val: 0.302620	test: 0.195075

Epoch: 103
Loss: 0.04118156345000834
ROC train: 0.997003	val: 0.771703	test: 0.742009
PRC train: 0.960412	val: 0.325437	test: 0.182618

Epoch: 104
Loss: 0.04362662980213962
ROC train: 0.998339	val: 0.776063	test: 0.739543
PRC train: 0.975860	val: 0.338318	test: 0.197054

Epoch: 105
Loss: 0.042672041950645265
ROC train: 0.996741	val: 0.776085	test: 0.738259
PRC train: 0.957399	val: 0.343521	test: 0.194402

Epoch: 106
Loss: 0.03933014633863231
ROC train: 0.997889	val: 0.769204	test: 0.741706
PRC train: 0.970442	val: 0.306223	test: 0.208656

Epoch: 107
Loss: 0.040761155545704586
ROC train: 0.998265	val: 0.772839	test: 0.731679
PRC train: 0.972304	val: 0.282787	test: 0.161690

Epoch: 108
Loss: 0.038369538451760714
ROC train: 0.998544	val: 0.791143	test: 0.750878
PRC train: 0.977176	val: 0.335320	test: 0.201963

Epoch: 109
Loss: 0.04092795865768778
ROC train: 0.998111	val: 0.772799	test: 0.742479
PRC train: 0.972679	val: 0.308894	test: 0.186595

Epoch: 110
Loss: 0.03742948260923099
ROC train: 0.999131	val: 0.765006	test: 0.720918
PRC train: 0.985416	val: 0.270458	test: 0.175927

Epoch: 111
Loss: 0.038061110367451904
ROC train: 0.999302	val: 0.773610	test: 0.713420
PRC train: 0.988583	val: 0.284962	test: 0.124122

Epoch: 112
Loss: 0.03499573221380605
ROC train: 0.997728	val: 0.775405	test: 0.739224
PRC train: 0.970230	val: 0.265600	test: 0.211734

Epoch: 113
Loss: 0.041194434696906604
ROC train: 0.998895	val: 0.761467	test: 0.743097
PRC train: 0.983526	val: 0.331822	test: 0.182471

Epoch: 114
Loss: 0.037687916852608104
ROC train: 0.998981	val: 0.793838	test: 0.744860
PRC train: 0.984974	val: 0.313686	test: 0.171344

Epoch: 115
Loss: 0.035582420434337854
ROC train: 0.999201	val: 0.777175	test: 0.745953
PRC train: 0.987365	val: 0.299048	test: 0.159967

Epoch: 116
Loss: 0.034830045622490854
ROC train: 0.998744	val: 0.783856	test: 0.747728
PRC train: 0.983543	val: 0.336715	test: 0.189086

Epoch: 117
Loss: 0.03438249563919484
ROC train: 0.997340	val: 0.791210	test: 0.763966
PRC train: 0.960590	val: 0.280283	test: 0.164498

Epoch: 118
Loss: 0.03607158823894854
ROC train: 0.998782	val: 0.767193	test: 0.743274
PRC train: 0.981849	val: 0.326395	test: 0.193975

Epoch: 119
Loss: 0.03432638576629649
ROC train: 0.999350	val: 0.773911	test: 0.751780
PRC train: 0.989761	val: 0.339951	test: 0.184463

Epoch: 120
Loss: 0.03691207308920026
ROC train: 0.999327	val: 0.766883	test: 0.748350
PRC train: 0.989869	val: 0.305911	test: 0.195272

Early stopping
Best (ROC):	 train: 0.995536	val: 0.818492	test: 0.756946
Best (PRC):	 train: 0.946830	val: 0.324468	test: 0.199683

PRC train: 0.895757	val: 0.319236	test: 0.151130

Epoch: 94
Loss: 0.05693337982653655
ROC train: 0.994122	val: 0.798372	test: 0.760333
PRC train: 0.929249	val: 0.353715	test: 0.201347

Epoch: 95
Loss: 0.05426668190786935
ROC train: 0.992649	val: 0.795739	test: 0.767077
PRC train: 0.916713	val: 0.358353	test: 0.169185

Epoch: 96
Loss: 0.05510972093096251
ROC train: 0.994613	val: 0.777929	test: 0.750938
PRC train: 0.931469	val: 0.327167	test: 0.190951

Epoch: 97
Loss: 0.05420233473549525
ROC train: 0.995504	val: 0.786859	test: 0.740646
PRC train: 0.941094	val: 0.331308	test: 0.168131

Epoch: 98
Loss: 0.05255425099811165
ROC train: 0.995921	val: 0.797650	test: 0.753228
PRC train: 0.946785	val: 0.322277	test: 0.164036

Epoch: 99
Loss: 0.05419554775033535
ROC train: 0.995703	val: 0.790179	test: 0.737834
PRC train: 0.944569	val: 0.319514	test: 0.190853

Epoch: 100
Loss: 0.052363396384747136
ROC train: 0.995678	val: 0.785062	test: 0.744730
PRC train: 0.945771	val: 0.283687	test: 0.128666

Epoch: 101
Loss: 0.0524711797733234
ROC train: 0.996691	val: 0.788868	test: 0.751828
PRC train: 0.950862	val: 0.298982	test: 0.181961

Epoch: 102
Loss: 0.05274238816866201
ROC train: 0.994907	val: 0.778439	test: 0.739402
PRC train: 0.932196	val: 0.319734	test: 0.163718

Epoch: 103
Loss: 0.049981769388054285
ROC train: 0.995484	val: 0.775803	test: 0.743954
PRC train: 0.939638	val: 0.294066	test: 0.168575

Epoch: 104
Loss: 0.04890272081839277
ROC train: 0.996950	val: 0.795669	test: 0.738755
PRC train: 0.954006	val: 0.325339	test: 0.176040

Epoch: 105
Loss: 0.0485583529754
ROC train: 0.994922	val: 0.772496	test: 0.750737
PRC train: 0.932461	val: 0.356139	test: 0.179747

Epoch: 106
Loss: 0.04973901890195034
ROC train: 0.995259	val: 0.807616	test: 0.737351
PRC train: 0.939865	val: 0.343700	test: 0.181982

Epoch: 107
Loss: 0.05110170609584452
ROC train: 0.996063	val: 0.791024	test: 0.738060
PRC train: 0.942944	val: 0.328738	test: 0.178114

Epoch: 108
Loss: 0.04698260603859031
ROC train: 0.996529	val: 0.796339	test: 0.729962
PRC train: 0.957489	val: 0.326250	test: 0.125674

Epoch: 109
Loss: 0.04871333909284305
ROC train: 0.995899	val: 0.775781	test: 0.743373
PRC train: 0.938610	val: 0.324700	test: 0.177767

Epoch: 110
Loss: 0.0486755908950453
ROC train: 0.996681	val: 0.798773	test: 0.723778
PRC train: 0.954154	val: 0.323194	test: 0.170253

Epoch: 111
Loss: 0.04904809470538283
ROC train: 0.996197	val: 0.787487	test: 0.719261
PRC train: 0.945207	val: 0.341434	test: 0.182504

Epoch: 112
Loss: 0.046478212468330046
ROC train: 0.997518	val: 0.804453	test: 0.755787
PRC train: 0.963835	val: 0.341983	test: 0.158792

Epoch: 113
Loss: 0.046344710278686974
ROC train: 0.997586	val: 0.784095	test: 0.734875
PRC train: 0.964467	val: 0.320890	test: 0.120444

Epoch: 114
Loss: 0.046020602429461786
ROC train: 0.996437	val: 0.785889	test: 0.729477
PRC train: 0.953372	val: 0.361489	test: 0.169203

Epoch: 115
Loss: 0.04733015068843957
ROC train: 0.996745	val: 0.781483	test: 0.713731
PRC train: 0.953733	val: 0.332536	test: 0.152709

Epoch: 116
Loss: 0.043733952885494164
ROC train: 0.998061	val: 0.763990	test: 0.755159
PRC train: 0.966905	val: 0.293873	test: 0.142771

Epoch: 117
Loss: 0.04635833245247209
ROC train: 0.997526	val: 0.796783	test: 0.745853
PRC train: 0.963140	val: 0.302952	test: 0.168703

Epoch: 118
Loss: 0.04576071884274699
ROC train: 0.996801	val: 0.761504	test: 0.742164
PRC train: 0.952536	val: 0.296149	test: 0.166598

Epoch: 119
Loss: 0.04265320605423051
ROC train: 0.997819	val: 0.763059	test: 0.743755
PRC train: 0.967499	val: 0.300665	test: 0.167980

Epoch: 120
Loss: 0.044187373084342875
ROC train: 0.997659	val: 0.776167	test: 0.728693
PRC train: 0.962868	val: 0.278128	test: 0.114430

Early stopping
Best (ROC):	 train: 0.917921	val: 0.823817	test: 0.746567
Best (PRC):	 train: 0.587597	val: 0.357704	test: 0.240667

PRC train: 0.972126	val: 0.294482	test: 0.178778

Epoch: 94
Loss: 0.043747523119889505
ROC train: 0.997293	val: 0.756280	test: 0.729018
PRC train: 0.961557	val: 0.287422	test: 0.173668

Epoch: 95
Loss: 0.04278854437350608
ROC train: 0.997049	val: 0.762646	test: 0.726188
PRC train: 0.963936	val: 0.235858	test: 0.134991

Epoch: 96
Loss: 0.0439081978151045
ROC train: 0.997557	val: 0.736142	test: 0.717903
PRC train: 0.966506	val: 0.265800	test: 0.194560

Epoch: 97
Loss: 0.04478686843080597
ROC train: 0.996893	val: 0.762352	test: 0.725238
PRC train: 0.958970	val: 0.311695	test: 0.168087

Epoch: 98
Loss: 0.04289589697096519
ROC train: 0.998154	val: 0.732936	test: 0.720080
PRC train: 0.971457	val: 0.289782	test: 0.190132

Epoch: 99
Loss: 0.043539615455367386
ROC train: 0.996714	val: 0.751950	test: 0.721327
PRC train: 0.948355	val: 0.301557	test: 0.163660

Epoch: 100
Loss: 0.040061947225586085
ROC train: 0.998209	val: 0.731034	test: 0.717839
PRC train: 0.974094	val: 0.308095	test: 0.151452

Epoch: 101
Loss: 0.04004224526334967
ROC train: 0.997933	val: 0.748126	test: 0.728979
PRC train: 0.966246	val: 0.286367	test: 0.184610

Epoch: 102
Loss: 0.041427594463082494
ROC train: 0.998547	val: 0.743996	test: 0.724406
PRC train: 0.976173	val: 0.272691	test: 0.152711

Epoch: 103
Loss: 0.03932351986350278
ROC train: 0.998507	val: 0.730422	test: 0.731202
PRC train: 0.976477	val: 0.244814	test: 0.115704

Epoch: 104
Loss: 0.039083509811906544
ROC train: 0.998414	val: 0.761798	test: 0.723481
PRC train: 0.973856	val: 0.287397	test: 0.133233

Epoch: 105
Loss: 0.03780825655129086
ROC train: 0.998557	val: 0.719323	test: 0.731003
PRC train: 0.978270	val: 0.267391	test: 0.138489

Epoch: 106
Loss: 0.04172827512614042
ROC train: 0.999230	val: 0.723490	test: 0.714987
PRC train: 0.985712	val: 0.221120	test: 0.127150

Epoch: 107
Loss: 0.039028718813789165
ROC train: 0.998747	val: 0.758622	test: 0.714720
PRC train: 0.977728	val: 0.287901	test: 0.161177

Epoch: 108
Loss: 0.03681186134706258
ROC train: 0.999165	val: 0.732973	test: 0.729512
PRC train: 0.984704	val: 0.294968	test: 0.171235

Epoch: 109
Loss: 0.041005440284609035
ROC train: 0.999180	val: 0.736001	test: 0.713872
PRC train: 0.986127	val: 0.303508	test: 0.178181

Epoch: 110
Loss: 0.03830134711277197
ROC train: 0.998878	val: 0.738741	test: 0.711422
PRC train: 0.982196	val: 0.279604	test: 0.144225

Epoch: 111
Loss: 0.03838120510414687
ROC train: 0.999252	val: 0.748977	test: 0.729682
PRC train: 0.987430	val: 0.301959	test: 0.175560

Epoch: 112
Loss: 0.0360934334204021
ROC train: 0.998318	val: 0.759180	test: 0.736304
PRC train: 0.972453	val: 0.285052	test: 0.165797

Epoch: 113
Loss: 0.03559674433418807
ROC train: 0.999310	val: 0.769789	test: 0.724471
PRC train: 0.988084	val: 0.297229	test: 0.172716

Epoch: 114
Loss: 0.03361924954515535
ROC train: 0.998802	val: 0.742483	test: 0.742206
PRC train: 0.980582	val: 0.293189	test: 0.176865

Epoch: 115
Loss: 0.03443357126524469
ROC train: 0.999164	val: 0.760251	test: 0.726107
PRC train: 0.985711	val: 0.296336	test: 0.177429

Epoch: 116
Loss: 0.03512594590659761
ROC train: 0.999094	val: 0.752002	test: 0.719869
PRC train: 0.984098	val: 0.290955	test: 0.146138

Epoch: 117
Loss: 0.03608007116864922
ROC train: 0.999156	val: 0.787490	test: 0.732328
PRC train: 0.982910	val: 0.303287	test: 0.166554

Epoch: 118
Loss: 0.03399588237947647
ROC train: 0.998783	val: 0.756739	test: 0.720190
PRC train: 0.980023	val: 0.296130	test: 0.155507

Epoch: 119
Loss: 0.03413108176978702
ROC train: 0.999345	val: 0.749550	test: 0.739962
PRC train: 0.987864	val: 0.302984	test: 0.176825

Epoch: 120
Loss: 0.03438824730048356
ROC train: 0.999678	val: 0.740349	test: 0.717996
PRC train: 0.993328	val: 0.235813	test: 0.139438

Early stopping
Best (ROC):	 train: 0.996878	val: 0.801946	test: 0.712049
Best (PRC):	 train: 0.957317	val: 0.283405	test: 0.121758
Epoch: 94
Loss: 0.07659026155209106
ROC train: 0.978093	val: 0.784480	test: 0.742801
PRC train: 0.778999	val: 0.298875	test: 0.197647

Epoch: 95
Loss: 0.07520893397102414
ROC train: 0.978020	val: 0.793767	test: 0.732366
PRC train: 0.778854	val: 0.310103	test: 0.192916

Epoch: 96
Loss: 0.07604909636522594
ROC train: 0.978355	val: 0.791054	test: 0.740177
PRC train: 0.776398	val: 0.325975	test: 0.173331

Epoch: 97
Loss: 0.07486432122104231
ROC train: 0.978454	val: 0.783497	test: 0.749352
PRC train: 0.780467	val: 0.303259	test: 0.179048

Epoch: 98
Loss: 0.07440724793156409
ROC train: 0.976640	val: 0.792126	test: 0.732710
PRC train: 0.754029	val: 0.277428	test: 0.137128

Epoch: 99
Loss: 0.07461892309574622
ROC train: 0.975185	val: 0.779639	test: 0.746055
PRC train: 0.766421	val: 0.297494	test: 0.199557

Epoch: 100
Loss: 0.0755645880027416
ROC train: 0.979397	val: 0.791633	test: 0.755963
PRC train: 0.786276	val: 0.286704	test: 0.165025

Epoch: 101
Loss: 0.07327036490024083
ROC train: 0.979689	val: 0.782551	test: 0.732863
PRC train: 0.786658	val: 0.287710	test: 0.160069

Epoch: 102
Loss: 0.07470761977630323
ROC train: 0.979835	val: 0.803375	test: 0.745729
PRC train: 0.785372	val: 0.294989	test: 0.176265

Epoch: 103
Loss: 0.0744791812550999
ROC train: 0.980003	val: 0.782153	test: 0.746266
PRC train: 0.786593	val: 0.287940	test: 0.188859

Epoch: 104
Loss: 0.07373011180236339
ROC train: 0.980341	val: 0.801413	test: 0.736584
PRC train: 0.786048	val: 0.316643	test: 0.226469

Epoch: 105
Loss: 0.07307247445014382
ROC train: 0.976359	val: 0.786192	test: 0.721215
PRC train: 0.766775	val: 0.284589	test: 0.128390

Epoch: 106
Loss: 0.07316373144520938
ROC train: 0.977805	val: 0.809879	test: 0.731457
PRC train: 0.772117	val: 0.307140	test: 0.202897

Epoch: 107
Loss: 0.07361852716272414
ROC train: 0.982288	val: 0.806927	test: 0.750710
PRC train: 0.798749	val: 0.305638	test: 0.167727

Epoch: 108
Loss: 0.07364355282903644
ROC train: 0.979142	val: 0.789744	test: 0.743755
PRC train: 0.788962	val: 0.299620	test: 0.156266

Epoch: 109
Loss: 0.0713029386446445
ROC train: 0.981262	val: 0.806379	test: 0.738471
PRC train: 0.795940	val: 0.320144	test: 0.168280

Epoch: 110
Loss: 0.0707372645712056
ROC train: 0.978957	val: 0.787729	test: 0.751577
PRC train: 0.782452	val: 0.313823	test: 0.189560

Epoch: 111
Loss: 0.07156335201286661
ROC train: 0.982018	val: 0.802221	test: 0.747749
PRC train: 0.801595	val: 0.298581	test: 0.198374

Epoch: 112
Loss: 0.07135434665314185
ROC train: 0.981107	val: 0.802668	test: 0.746814
PRC train: 0.799886	val: 0.302075	test: 0.168528

Epoch: 113
Loss: 0.07136702028649648
ROC train: 0.982043	val: 0.805944	test: 0.735742
PRC train: 0.796941	val: 0.276276	test: 0.123399

Epoch: 114
Loss: 0.0689356358929884
ROC train: 0.983157	val: 0.775573	test: 0.741071
PRC train: 0.810671	val: 0.284195	test: 0.158410

Epoch: 115
Loss: 0.07021052823679179
ROC train: 0.985740	val: 0.787046	test: 0.745374
PRC train: 0.826452	val: 0.285510	test: 0.180409

Epoch: 116
Loss: 0.07031050902542896
ROC train: 0.985341	val: 0.794738	test: 0.758564
PRC train: 0.823111	val: 0.300033	test: 0.200429

Epoch: 117
Loss: 0.06892143385809187
ROC train: 0.984171	val: 0.809729	test: 0.763750
PRC train: 0.813288	val: 0.299467	test: 0.196328

Epoch: 118
Loss: 0.06873586667516964
ROC train: 0.984561	val: 0.790910	test: 0.753269
PRC train: 0.818155	val: 0.306968	test: 0.220254

Epoch: 119
Loss: 0.06807404222018126
ROC train: 0.985078	val: 0.784854	test: 0.735957
PRC train: 0.822066	val: 0.251076	test: 0.162374

Epoch: 120
Loss: 0.06652840932210435
ROC train: 0.987375	val: 0.798994	test: 0.739369
PRC train: 0.837029	val: 0.305561	test: 0.213085

Early stopping
Best (ROC):	 train: 0.964341	val: 0.819487	test: 0.763669
Best (PRC):	 train: 0.704375	val: 0.314993	test: 0.181839

PRC train: 0.970296	val: 0.316227	test: 0.178443

Epoch: 94
Loss: 0.04283567658994701
ROC train: 0.998439	val: 0.784502	test: 0.737063
PRC train: 0.973727	val: 0.364831	test: 0.217423

Epoch: 95
Loss: 0.043258187844233346
ROC train: 0.998213	val: 0.781290	test: 0.719890
PRC train: 0.973452	val: 0.316341	test: 0.186301

Epoch: 96
Loss: 0.04228359617668356
ROC train: 0.998314	val: 0.794808	test: 0.731611
PRC train: 0.972433	val: 0.290264	test: 0.177948

Epoch: 97
Loss: 0.04202778714551142
ROC train: 0.998098	val: 0.778102	test: 0.722279
PRC train: 0.969012	val: 0.330125	test: 0.165871

Epoch: 98
Loss: 0.04078616929497085
ROC train: 0.997822	val: 0.786210	test: 0.737732
PRC train: 0.971426	val: 0.335223	test: 0.178404

Epoch: 99
Loss: 0.04207466179470021
ROC train: 0.997731	val: 0.802288	test: 0.740766
PRC train: 0.968641	val: 0.347172	test: 0.228345

Epoch: 100
Loss: 0.04143105503704132
ROC train: 0.998226	val: 0.801694	test: 0.726310
PRC train: 0.972237	val: 0.346192	test: 0.185374

Epoch: 101
Loss: 0.03864189980190136
ROC train: 0.998575	val: 0.788586	test: 0.747025
PRC train: 0.978206	val: 0.317737	test: 0.201090

Epoch: 102
Loss: 0.03743589174357256
ROC train: 0.998547	val: 0.817246	test: 0.744024
PRC train: 0.976928	val: 0.346288	test: 0.191270

Epoch: 103
Loss: 0.039487601627298065
ROC train: 0.998841	val: 0.791988	test: 0.713430
PRC train: 0.981631	val: 0.346423	test: 0.193090

Epoch: 104
Loss: 0.0398729495698701
ROC train: 0.997334	val: 0.790280	test: 0.722077
PRC train: 0.967364	val: 0.357582	test: 0.234895

Epoch: 105
Loss: 0.038551800815266865
ROC train: 0.999138	val: 0.811434	test: 0.728150
PRC train: 0.985243	val: 0.318787	test: 0.179209

Epoch: 106
Loss: 0.03754241961306243
ROC train: 0.998839	val: 0.825320	test: 0.732270
PRC train: 0.980494	val: 0.340782	test: 0.197630

Epoch: 107
Loss: 0.03973603630921784
ROC train: 0.999016	val: 0.813373	test: 0.734690
PRC train: 0.984639	val: 0.359019	test: 0.178346

Epoch: 108
Loss: 0.036212583581511706
ROC train: 0.998441	val: 0.781323	test: 0.725916
PRC train: 0.981685	val: 0.331788	test: 0.215956

Epoch: 109
Loss: 0.03850384345434759
ROC train: 0.998922	val: 0.811340	test: 0.729688
PRC train: 0.983405	val: 0.348963	test: 0.224336

Epoch: 110
Loss: 0.038064998312779014
ROC train: 0.999191	val: 0.802552	test: 0.734323
PRC train: 0.986123	val: 0.321338	test: 0.176435

Epoch: 111
Loss: 0.03456054795280446
ROC train: 0.999174	val: 0.793375	test: 0.724191
PRC train: 0.989022	val: 0.362402	test: 0.199451

Epoch: 112
Loss: 0.04015079081274307
ROC train: 0.999334	val: 0.816070	test: 0.726594
PRC train: 0.987783	val: 0.316334	test: 0.152654

Epoch: 113
Loss: 0.03451699584619246
ROC train: 0.999132	val: 0.804793	test: 0.726341
PRC train: 0.987149	val: 0.355711	test: 0.212010

Epoch: 114
Loss: 0.038789415744899844
ROC train: 0.999402	val: 0.814607	test: 0.730159
PRC train: 0.988838	val: 0.343459	test: 0.178365

Epoch: 115
Loss: 0.034529739678735454
ROC train: 0.998590	val: 0.800693	test: 0.713840
PRC train: 0.976825	val: 0.314071	test: 0.178175

Epoch: 116
Loss: 0.034218545861824975
ROC train: 0.999184	val: 0.788363	test: 0.737139
PRC train: 0.988133	val: 0.366221	test: 0.192070

Epoch: 117
Loss: 0.03351837422830512
ROC train: 0.999122	val: 0.801820	test: 0.718382
PRC train: 0.986239	val: 0.341976	test: 0.208896

Epoch: 118
Loss: 0.03613461578340259
ROC train: 0.999212	val: 0.783298	test: 0.745868
PRC train: 0.984714	val: 0.366677	test: 0.219033

Epoch: 119
Loss: 0.03610459850906385
ROC train: 0.999652	val: 0.793283	test: 0.725649
PRC train: 0.993798	val: 0.340801	test: 0.201781

Epoch: 120
Loss: 0.03539067460073227
ROC train: 0.999470	val: 0.803807	test: 0.735001
PRC train: 0.990860	val: 0.299594	test: 0.225116

Early stopping
Best (ROC):	 train: 0.918333	val: 0.828701	test: 0.721447
Best (PRC):	 train: 0.583388	val: 0.373706	test: 0.183825
All runs completed.

PRC train: 0.990625	val: 0.268634	test: 0.182937

Epoch: 94
Loss: 0.03614116057863604
ROC train: 0.998612	val: 0.770867	test: 0.729655
PRC train: 0.973379	val: 0.250432	test: 0.128895

Epoch: 95
Loss: 0.036228336706301746
ROC train: 0.998636	val: 0.789719	test: 0.757792
PRC train: 0.979644	val: 0.263509	test: 0.230691

Epoch: 96
Loss: 0.03635388823768293
ROC train: 0.999389	val: 0.802760	test: 0.735538
PRC train: 0.992213	val: 0.254052	test: 0.119691

Epoch: 97
Loss: 0.03638528735075506
ROC train: 0.999586	val: 0.793681	test: 0.735524
PRC train: 0.994685	val: 0.277862	test: 0.185481

Epoch: 98
Loss: 0.035733584957832396
ROC train: 0.999340	val: 0.790564	test: 0.746121
PRC train: 0.989236	val: 0.280709	test: 0.196896

Epoch: 99
Loss: 0.03314773329949967
ROC train: 0.999457	val: 0.812065	test: 0.747911
PRC train: 0.991297	val: 0.293774	test: 0.199224

Epoch: 100
Loss: 0.032373438418584685
ROC train: 0.999558	val: 0.791498	test: 0.741940
PRC train: 0.993130	val: 0.292675	test: 0.189134

Epoch: 101
Loss: 0.03542795164454414
ROC train: 0.999595	val: 0.785965	test: 0.715331
PRC train: 0.993978	val: 0.275843	test: 0.208506

Epoch: 102
Loss: 0.0332921272431231
ROC train: 0.999556	val: 0.791140	test: 0.726092
PRC train: 0.994826	val: 0.248658	test: 0.124733

Epoch: 103
Loss: 0.03141889453412492
ROC train: 0.999652	val: 0.803131	test: 0.738670
PRC train: 0.994041	val: 0.296734	test: 0.200838

Epoch: 104
Loss: 0.03390363125499291
ROC train: 0.999821	val: 0.819674	test: 0.743846
PRC train: 0.996455	val: 0.273454	test: 0.186221

Epoch: 105
Loss: 0.03339131354544775
ROC train: 0.999904	val: 0.794833	test: 0.734950
PRC train: 0.998084	val: 0.275117	test: 0.198597

Epoch: 106
Loss: 0.03338902931787653
ROC train: 0.999810	val: 0.796958	test: 0.745793
PRC train: 0.996326	val: 0.257366	test: 0.213632

Epoch: 107
Loss: 0.03130285994162834
ROC train: 0.999310	val: 0.781976	test: 0.717725
PRC train: 0.988805	val: 0.237050	test: 0.191750

Epoch: 108
Loss: 0.03215493772880438
ROC train: 0.999796	val: 0.791354	test: 0.742434
PRC train: 0.996559	val: 0.284821	test: 0.223002

Epoch: 109
Loss: 0.031463206789162514
ROC train: 0.999736	val: 0.788130	test: 0.749348
PRC train: 0.995350	val: 0.244296	test: 0.184344

Epoch: 110
Loss: 0.030140605161530235
ROC train: 0.999618	val: 0.784765	test: 0.718907
PRC train: 0.991855	val: 0.277853	test: 0.184285

Epoch: 111
Loss: 0.029780565004692512
ROC train: 0.999857	val: 0.793782	test: 0.761527
PRC train: 0.997304	val: 0.276920	test: 0.205562

Epoch: 112
Loss: 0.028914117977277158
ROC train: 0.999792	val: 0.796162	test: 0.764837
PRC train: 0.996782	val: 0.274095	test: 0.217941

Epoch: 113
Loss: 0.031818625354807534
ROC train: 0.999795	val: 0.771936	test: 0.710647
PRC train: 0.996209	val: 0.254487	test: 0.134404

Epoch: 114
Loss: 0.029773151644599382
ROC train: 0.999578	val: 0.770993	test: 0.753665
PRC train: 0.992452	val: 0.275428	test: 0.225604

Epoch: 115
Loss: 0.028752060332178503
ROC train: 0.999935	val: 0.780824	test: 0.741414
PRC train: 0.998657	val: 0.262111	test: 0.173460

Epoch: 116
Loss: 0.028186371344133928
ROC train: 0.999739	val: 0.790273	test: 0.743222
PRC train: 0.996170	val: 0.288977	test: 0.213863

Epoch: 117
Loss: 0.02712994794155631
ROC train: 0.999816	val: 0.791201	test: 0.728097
PRC train: 0.996359	val: 0.292110	test: 0.172215

Epoch: 118
Loss: 0.029219634582859935
ROC train: 0.999931	val: 0.779042	test: 0.725327
PRC train: 0.998842	val: 0.272189	test: 0.161332

Epoch: 119
Loss: 0.02413162502129823
ROC train: 0.999837	val: 0.807038	test: 0.753566
PRC train: 0.997526	val: 0.297785	test: 0.233256

Epoch: 120
Loss: 0.02847977252743204
ROC train: 0.999861	val: 0.791051	test: 0.713828
PRC train: 0.997627	val: 0.214259	test: 0.098631

Early stopping
Best (ROC):	 train: 0.996290	val: 0.821364	test: 0.734294
Best (PRC):	 train: 0.947324	val: 0.293303	test: 0.129203

PRC train: 0.989929	val: 0.274305	test: 0.209282

Epoch: 94
Loss: 0.03809222972858056
ROC train: 0.998867	val: 0.732963	test: 0.718052
PRC train: 0.980864	val: 0.260040	test: 0.196424

Epoch: 95
Loss: 0.035825471059466964
ROC train: 0.998683	val: 0.738395	test: 0.726449
PRC train: 0.983460	val: 0.229838	test: 0.162247

Epoch: 96
Loss: 0.03169366599311439
ROC train: 0.999158	val: 0.749378	test: 0.735124
PRC train: 0.986571	val: 0.291718	test: 0.183258

Epoch: 97
Loss: 0.03713072840552452
ROC train: 0.998725	val: 0.761347	test: 0.745221
PRC train: 0.978926	val: 0.296767	test: 0.197679

Epoch: 98
Loss: 0.0321802793633402
ROC train: 0.999317	val: 0.753420	test: 0.712546
PRC train: 0.988707	val: 0.316251	test: 0.186331

Epoch: 99
Loss: 0.03254527074658848
ROC train: 0.999701	val: 0.734093	test: 0.725006
PRC train: 0.994464	val: 0.260318	test: 0.192247

Epoch: 100
Loss: 0.03251591815591692
ROC train: 0.998977	val: 0.756782	test: 0.722138
PRC train: 0.984034	val: 0.289885	test: 0.234347

Epoch: 101
Loss: 0.03336585313656358
ROC train: 0.999326	val: 0.774342	test: 0.718963
PRC train: 0.987460	val: 0.294437	test: 0.225285

Epoch: 102
Loss: 0.03281425060879955
ROC train: 0.999698	val: 0.749715	test: 0.735337
PRC train: 0.994226	val: 0.270050	test: 0.208088

Epoch: 103
Loss: 0.03239589468735953
ROC train: 0.999565	val: 0.770098	test: 0.728035
PRC train: 0.992148	val: 0.324101	test: 0.190604

Epoch: 104
Loss: 0.03211942937616106
ROC train: 0.999569	val: 0.748708	test: 0.724265
PRC train: 0.991722	val: 0.277168	test: 0.187159

Epoch: 105
Loss: 0.032696187201415886
ROC train: 0.998576	val: 0.761057	test: 0.730284
PRC train: 0.976846	val: 0.272643	test: 0.222646

Epoch: 106
Loss: 0.02980260604353443
ROC train: 0.999572	val: 0.759853	test: 0.727602
PRC train: 0.992716	val: 0.297109	test: 0.190260

Epoch: 107
Loss: 0.03024956217053035
ROC train: 0.999831	val: 0.751412	test: 0.732903
PRC train: 0.996259	val: 0.223908	test: 0.151841

Epoch: 108
Loss: 0.027592290238469434
ROC train: 0.999718	val: 0.760760	test: 0.728996
PRC train: 0.993954	val: 0.260189	test: 0.223827

Epoch: 109
Loss: 0.028047651973730627
ROC train: 0.999790	val: 0.731889	test: 0.741779
PRC train: 0.995455	val: 0.257137	test: 0.199775

Epoch: 110
Loss: 0.028095246969706833
ROC train: 0.999464	val: 0.739540	test: 0.743944
PRC train: 0.989168	val: 0.256429	test: 0.169430

Epoch: 111
Loss: 0.03362844475346541
ROC train: 0.999593	val: 0.739305	test: 0.733757
PRC train: 0.993058	val: 0.272382	test: 0.197054

Epoch: 112
Loss: 0.02642073853174786
ROC train: 0.999858	val: 0.743699	test: 0.747349
PRC train: 0.996814	val: 0.283057	test: 0.174813

Epoch: 113
Loss: 0.02778216550679897
ROC train: 0.999630	val: 0.760659	test: 0.737096
PRC train: 0.992292	val: 0.281239	test: 0.174426

Epoch: 114
Loss: 0.026982300211734526
ROC train: 0.999803	val: 0.759697	test: 0.733585
PRC train: 0.996292	val: 0.268895	test: 0.161326

Epoch: 115
Loss: 0.029792904483584945
ROC train: 0.999721	val: 0.760319	test: 0.722362
PRC train: 0.994519	val: 0.279061	test: 0.197818

Epoch: 116
Loss: 0.027120965676619768
ROC train: 0.999617	val: 0.753950	test: 0.730792
PRC train: 0.992193	val: 0.249401	test: 0.201877

Epoch: 117
Loss: 0.028574601947986073
ROC train: 0.999742	val: 0.741861	test: 0.734520
PRC train: 0.994156	val: 0.218954	test: 0.168601

Epoch: 118
Loss: 0.025829517402029073
ROC train: 0.999809	val: 0.747599	test: 0.724097
PRC train: 0.995949	val: 0.236675	test: 0.164346

Epoch: 119
Loss: 0.027148574001134615
ROC train: 0.999825	val: 0.732767	test: 0.720715
PRC train: 0.995821	val: 0.263934	test: 0.199473

Epoch: 120
Loss: 0.02648866637796559
ROC train: 0.999860	val: 0.731080	test: 0.737631
PRC train: 0.996835	val: 0.234155	test: 0.177634

Early stopping
Best (ROC):	 train: 0.981259	val: 0.810473	test: 0.744076
Best (PRC):	 train: 0.851806	val: 0.295933	test: 0.165456

PRC train: 0.934597	val: 0.280827	test: 0.160518

Epoch: 94
Loss: 0.055941911564745574
ROC train: 0.994304	val: 0.803311	test: 0.706338
PRC train: 0.934510	val: 0.266216	test: 0.118261

Epoch: 95
Loss: 0.05299045805263
ROC train: 0.993582	val: 0.783384	test: 0.722940
PRC train: 0.923718	val: 0.314674	test: 0.151720

Epoch: 96
Loss: 0.04880464071945149
ROC train: 0.992637	val: 0.809564	test: 0.696752
PRC train: 0.916603	val: 0.289942	test: 0.119105

Epoch: 97
Loss: 0.05101065101441532
ROC train: 0.994395	val: 0.841019	test: 0.729348
PRC train: 0.933994	val: 0.366546	test: 0.138445

Epoch: 98
Loss: 0.04995368538471315
ROC train: 0.996323	val: 0.820905	test: 0.723148
PRC train: 0.950352	val: 0.362480	test: 0.181337

Epoch: 99
Loss: 0.05362263437080665
ROC train: 0.993863	val: 0.821364	test: 0.720981
PRC train: 0.927484	val: 0.346230	test: 0.156386

Epoch: 100
Loss: 0.05142468330479643
ROC train: 0.994707	val: 0.805020	test: 0.708598
PRC train: 0.945962	val: 0.327829	test: 0.134346

Epoch: 101
Loss: 0.05065095774833929
ROC train: 0.995737	val: 0.820311	test: 0.701881
PRC train: 0.947679	val: 0.305279	test: 0.124183

Epoch: 102
Loss: 0.049475975547253095
ROC train: 0.994415	val: 0.820914	test: 0.736297
PRC train: 0.937722	val: 0.273750	test: 0.147526

Epoch: 103
Loss: 0.048360620905149976
ROC train: 0.996448	val: 0.807837	test: 0.710672
PRC train: 0.952588	val: 0.346280	test: 0.141194

Epoch: 104
Loss: 0.05022013374682569
ROC train: 0.995441	val: 0.797524	test: 0.709400
PRC train: 0.943237	val: 0.344425	test: 0.165988

Epoch: 105
Loss: 0.05076762398901229
ROC train: 0.996469	val: 0.812365	test: 0.713739
PRC train: 0.951289	val: 0.332619	test: 0.194621

Epoch: 106
Loss: 0.04543408366374172
ROC train: 0.996851	val: 0.813122	test: 0.712142
PRC train: 0.957985	val: 0.333607	test: 0.154695

Epoch: 107
Loss: 0.04834724596061126
ROC train: 0.996990	val: 0.807754	test: 0.686187
PRC train: 0.955995	val: 0.316161	test: 0.111459

Epoch: 108
Loss: 0.04510643677728603
ROC train: 0.997888	val: 0.799052	test: 0.726885
PRC train: 0.966790	val: 0.318664	test: 0.146088

Epoch: 109
Loss: 0.046999507151497415
ROC train: 0.997077	val: 0.800761	test: 0.711207
PRC train: 0.963765	val: 0.288094	test: 0.110954

Epoch: 110
Loss: 0.04785471235536757
ROC train: 0.996853	val: 0.816863	test: 0.706072
PRC train: 0.956473	val: 0.324516	test: 0.126283

Epoch: 111
Loss: 0.046458207922071976
ROC train: 0.997149	val: 0.799129	test: 0.691898
PRC train: 0.962448	val: 0.328445	test: 0.149261

Epoch: 112
Loss: 0.046863905155712336
ROC train: 0.997476	val: 0.825798	test: 0.714635
PRC train: 0.964086	val: 0.346677	test: 0.112849

Epoch: 113
Loss: 0.047140345494405496
ROC train: 0.996596	val: 0.805243	test: 0.703345
PRC train: 0.954730	val: 0.356564	test: 0.119063

Epoch: 114
Loss: 0.04682265294527453
ROC train: 0.997302	val: 0.811067	test: 0.730147
PRC train: 0.957610	val: 0.361350	test: 0.159766

Epoch: 115
Loss: 0.04318532053618891
ROC train: 0.997644	val: 0.812818	test: 0.711286
PRC train: 0.963397	val: 0.348007	test: 0.130385

Epoch: 116
Loss: 0.04617856293048593
ROC train: 0.997457	val: 0.811125	test: 0.722102
PRC train: 0.962993	val: 0.303694	test: 0.127371

Epoch: 117
Loss: 0.04314680443539996
ROC train: 0.998137	val: 0.812019	test: 0.708451
PRC train: 0.971266	val: 0.317860	test: 0.135910

Epoch: 118
Loss: 0.041988132654171346
ROC train: 0.997876	val: 0.817822	test: 0.729132
PRC train: 0.966273	val: 0.323890	test: 0.177254

Epoch: 119
Loss: 0.04188014209073485
ROC train: 0.998689	val: 0.813471	test: 0.711823
PRC train: 0.977483	val: 0.336773	test: 0.136756

Epoch: 120
Loss: 0.04195602198617888
ROC train: 0.997986	val: 0.801499	test: 0.712177
PRC train: 0.972547	val: 0.285686	test: 0.126934

Epoch: 121
Loss: 0.04058594491391417
ROC train: 0.998125	val: 0.803574	test: 0.714255
PRC train: 0.973975	val: 0.306926	test: 0.153788

Epoch: 122
Loss: 0.041728702860222296
ROC train: 0.997309	val: 0.781186	test: 0.707397
PRC train: 0.961383	val: 0.278207	test: 0.111599

Epoch: 123
Loss: 0.03944739886161452
ROC train: 0.998126	val: 0.800323	test: 0.690467
PRC train: 0.974992	val: 0.331143	test: 0.112186

Epoch: 124
Loss: 0.038715497413092034
ROC train: 0.998535	val: 0.813100	test: 0.713778
PRC train: 0.976071	val: 0.311770	test: 0.127255

Epoch: 125
Loss: 0.04294146241107316
ROC train: 0.998150	val: 0.805210	test: 0.729780
PRC train: 0.970584	val: 0.347950	test: 0.162489

Epoch: 126
Loss: 0.039606435157312145
ROC train: 0.998249	val: 0.811416	test: 0.716638
PRC train: 0.968681	val: 0.371163	test: 0.158306

Epoch: 127
Loss: 0.0391670811605194
ROC train: 0.998862	val: 0.789823	test: 0.691692
PRC train: 0.981365	val: 0.281021	test: 0.128634

Epoch: 128
Loss: 0.039731495658416036
ROC train: 0.998479	val: 0.824047	test: 0.721142
PRC train: 0.974638	val: 0.345301	test: 0.172010

Epoch: 129
Loss: 0.04107711438902433
ROC train: 0.998680	val: 0.795133	test: 0.701700
PRC train: 0.979432	val: 0.320583	test: 0.144344

Epoch: 130
Loss: 0.04014898159067731
ROC train: 0.998501	val: 0.806777	test: 0.716561
PRC train: 0.976352	val: 0.342326	test: 0.140805

Epoch: 131
Loss: 0.03774012114969594
ROC train: 0.998517	val: 0.792154	test: 0.697140
PRC train: 0.976327	val: 0.351180	test: 0.144626

Epoch: 132
Loss: 0.03793253873054982
ROC train: 0.998708	val: 0.802074	test: 0.714842
PRC train: 0.979239	val: 0.294988	test: 0.138260

Early stopping
Best (ROC):	 train: 0.994395	val: 0.841019	test: 0.729348
Best (PRC):	 train: 0.933994	val: 0.366546	test: 0.138445

PRC train: 0.988054	val: 0.233494	test: 0.188449

Epoch: 94
Loss: 0.03761909156354422
ROC train: 0.998497	val: 0.774238	test: 0.736268
PRC train: 0.980566	val: 0.240939	test: 0.194389

Epoch: 95
Loss: 0.03439752223181033
ROC train: 0.998905	val: 0.775555	test: 0.730033
PRC train: 0.983574	val: 0.196720	test: 0.164745

Epoch: 96
Loss: 0.034896000615670324
ROC train: 0.999442	val: 0.769287	test: 0.739263
PRC train: 0.990579	val: 0.259457	test: 0.199048

Epoch: 97
Loss: 0.03828319851911021
ROC train: 0.999664	val: 0.769471	test: 0.720719
PRC train: 0.993764	val: 0.218505	test: 0.148704

Epoch: 98
Loss: 0.032423589616998934
ROC train: 0.999374	val: 0.769783	test: 0.751256
PRC train: 0.989249	val: 0.271198	test: 0.192117

Epoch: 99
Loss: 0.03437905462095992
ROC train: 0.999791	val: 0.794508	test: 0.711001
PRC train: 0.996060	val: 0.249326	test: 0.144396

Epoch: 100
Loss: 0.035845454469170764
ROC train: 0.998742	val: 0.783510	test: 0.729885
PRC train: 0.980001	val: 0.250489	test: 0.141208

Epoch: 101
Loss: 0.03577266995436023
ROC train: 0.999281	val: 0.765086	test: 0.711949
PRC train: 0.986905	val: 0.314542	test: 0.156197

Epoch: 102
Loss: 0.034995432962465337
ROC train: 0.999598	val: 0.781982	test: 0.732422
PRC train: 0.993122	val: 0.202449	test: 0.144973

Epoch: 103
Loss: 0.031232691891383522
ROC train: 0.999043	val: 0.766063	test: 0.732857
PRC train: 0.990826	val: 0.241703	test: 0.175088

Epoch: 104
Loss: 0.032169985059902984
ROC train: 0.999745	val: 0.773742	test: 0.736362
PRC train: 0.994416	val: 0.278646	test: 0.151954

Epoch: 105
Loss: 0.033222937497633165
ROC train: 0.999527	val: 0.759112	test: 0.737175
PRC train: 0.991322	val: 0.257631	test: 0.140745

Epoch: 106
Loss: 0.032940690463626424
ROC train: 0.999838	val: 0.781222	test: 0.731884
PRC train: 0.996450	val: 0.254073	test: 0.151454

Epoch: 107
Loss: 0.030136233758122494
ROC train: 0.998915	val: 0.761142	test: 0.723110
PRC train: 0.985079	val: 0.230875	test: 0.163891

Epoch: 108
Loss: 0.03124656999811071
ROC train: 0.999741	val: 0.759817	test: 0.723036
PRC train: 0.994905	val: 0.205089	test: 0.156856

Epoch: 109
Loss: 0.0317618493812323
ROC train: 0.999482	val: 0.755738	test: 0.738433
PRC train: 0.990173	val: 0.254882	test: 0.178295

Epoch: 110
Loss: 0.02939827718096889
ROC train: 0.999825	val: 0.765591	test: 0.733782
PRC train: 0.996673	val: 0.229395	test: 0.164815

Epoch: 111
Loss: 0.029706910335432647
ROC train: 0.999879	val: 0.764275	test: 0.718148
PRC train: 0.997452	val: 0.207661	test: 0.160140

Epoch: 112
Loss: 0.029882968613607255
ROC train: 0.999647	val: 0.754657	test: 0.719492
PRC train: 0.993897	val: 0.237011	test: 0.171971

Epoch: 113
Loss: 0.029121053784277005
ROC train: 0.999647	val: 0.768941	test: 0.726967
PRC train: 0.993625	val: 0.300459	test: 0.169819

Epoch: 114
Loss: 0.031261646029698116
ROC train: 0.999617	val: 0.753341	test: 0.726855
PRC train: 0.992125	val: 0.214657	test: 0.142612

Epoch: 115
Loss: 0.03149107546880398
ROC train: 0.999503	val: 0.746724	test: 0.726665
PRC train: 0.991472	val: 0.287494	test: 0.196416

Epoch: 116
Loss: 0.02638715177960083
ROC train: 0.999875	val: 0.782104	test: 0.727449
PRC train: 0.997236	val: 0.228730	test: 0.157917

Epoch: 117
Loss: 0.02709894503529826
ROC train: 0.999857	val: 0.760242	test: 0.714863
PRC train: 0.997018	val: 0.221983	test: 0.166821

Epoch: 118
Loss: 0.02898900355527019
ROC train: 0.999884	val: 0.750300	test: 0.711845
PRC train: 0.997567	val: 0.232358	test: 0.160696

Epoch: 119
Loss: 0.028108462487543125
ROC train: 0.999911	val: 0.759688	test: 0.719268
PRC train: 0.997995	val: 0.240595	test: 0.166859

Epoch: 120
Loss: 0.026734956204962627
ROC train: 0.999913	val: 0.763472	test: 0.722795
PRC train: 0.998135	val: 0.218865	test: 0.141479

Epoch: 121
Loss: 0.028306722662551728
ROC train: 0.999924	val: 0.780188	test: 0.707418
PRC train: 0.998199	val: 0.225768	test: 0.150509

Epoch: 122
Loss: 0.025952463177161846
ROC train: 0.999802	val: 0.774012	test: 0.733541
PRC train: 0.995890	val: 0.213304	test: 0.159340

Epoch: 123
Loss: 0.023823702745722923
ROC train: 0.999924	val: 0.774514	test: 0.730132
PRC train: 0.998320	val: 0.239156	test: 0.149590

Epoch: 124
Loss: 0.02663329279449581
ROC train: 0.999564	val: 0.765922	test: 0.714552
PRC train: 0.991160	val: 0.262015	test: 0.153060

Epoch: 125
Loss: 0.024757384843333917
ROC train: 0.999793	val: 0.776946	test: 0.722214
PRC train: 0.995096	val: 0.256567	test: 0.145848

Epoch: 126
Loss: 0.026959893964053343
ROC train: 0.999659	val: 0.758224	test: 0.736304
PRC train: 0.994212	val: 0.224631	test: 0.173946

Epoch: 127
Loss: 0.02486145720043575
ROC train: 0.999840	val: 0.765013	test: 0.708708
PRC train: 0.996450	val: 0.246658	test: 0.180412

Epoch: 128
Loss: 0.027233342515286724
ROC train: 0.999897	val: 0.765836	test: 0.724118
PRC train: 0.997608	val: 0.245046	test: 0.144068

Epoch: 129
Loss: 0.02303975663318374
ROC train: 0.999964	val: 0.758999	test: 0.724016
PRC train: 0.999116	val: 0.218270	test: 0.148730

Epoch: 130
Loss: 0.02585076314745718
ROC train: 0.999937	val: 0.754850	test: 0.704585
PRC train: 0.998412	val: 0.194570	test: 0.119565

Epoch: 131
Loss: 0.025136423608925634
ROC train: 0.999939	val: 0.760591	test: 0.726381
PRC train: 0.998529	val: 0.303925	test: 0.153232

Epoch: 132
Loss: 0.024327875365342245
ROC train: 0.999981	val: 0.757523	test: 0.745094
PRC train: 0.999520	val: 0.234231	test: 0.178014

Epoch: 133
Loss: 0.024590950722607488
ROC train: 0.999926	val: 0.775380	test: 0.724411
PRC train: 0.998126	val: 0.236629	test: 0.192658

Epoch: 134
Loss: 0.02415854507882606
ROC train: 0.999932	val: 0.752887	test: 0.724593
PRC train: 0.998368	val: 0.258071	test: 0.173504

Early stopping
Best (ROC):	 train: 0.999791	val: 0.794508	test: 0.711001
Best (PRC):	 train: 0.996060	val: 0.249326	test: 0.144396
All runs completed.

ROC train: 0.972572	val: 0.795993	test: 0.775115
PRC train: 0.757133	val: 0.315798	test: 0.169870

Epoch: 95
Loss: 0.07700850145886551
ROC train: 0.971621	val: 0.774382	test: 0.781394
PRC train: 0.746874	val: 0.334554	test: 0.221084

Epoch: 96
Loss: 0.0774419396162691
ROC train: 0.971392	val: 0.776391	test: 0.766483
PRC train: 0.760197	val: 0.276869	test: 0.141491

Epoch: 97
Loss: 0.0760298121172646
ROC train: 0.972956	val: 0.776541	test: 0.773028
PRC train: 0.755927	val: 0.268090	test: 0.150224

Epoch: 98
Loss: 0.07612813021405819
ROC train: 0.973422	val: 0.780093	test: 0.794847
PRC train: 0.769013	val: 0.333117	test: 0.191217

Epoch: 99
Loss: 0.07614321988170045
ROC train: 0.974728	val: 0.792594	test: 0.766761
PRC train: 0.762932	val: 0.318457	test: 0.163727

Epoch: 100
Loss: 0.07722439710881321
ROC train: 0.974469	val: 0.782714	test: 0.773692
PRC train: 0.769385	val: 0.308380	test: 0.175907

Epoch: 101
Loss: 0.07502609196489371
ROC train: 0.974961	val: 0.808526	test: 0.768292
PRC train: 0.755940	val: 0.301172	test: 0.170165

Epoch: 102
Loss: 0.07460771983238752
ROC train: 0.971935	val: 0.786241	test: 0.781286
PRC train: 0.747544	val: 0.306799	test: 0.186642

Epoch: 103
Loss: 0.07554093151836892
ROC train: 0.977689	val: 0.790549	test: 0.766836
PRC train: 0.779012	val: 0.294618	test: 0.146337

Epoch: 104
Loss: 0.07312104643673159
ROC train: 0.976172	val: 0.782885	test: 0.760712
PRC train: 0.776658	val: 0.250684	test: 0.133332

Epoch: 105
Loss: 0.07268043460939662
ROC train: 0.974726	val: 0.786869	test: 0.786220
PRC train: 0.766159	val: 0.289406	test: 0.173735

Epoch: 106
Loss: 0.0749477302317536
ROC train: 0.976144	val: 0.780194	test: 0.774013
PRC train: 0.778142	val: 0.284425	test: 0.151839

Epoch: 107
Loss: 0.07338305033344932
ROC train: 0.978157	val: 0.783700	test: 0.759476
PRC train: 0.779533	val: 0.296193	test: 0.151867

Epoch: 108
Loss: 0.07312628781487904
ROC train: 0.978729	val: 0.787285	test: 0.763414
PRC train: 0.783032	val: 0.315882	test: 0.151310

Epoch: 109
Loss: 0.07319881097963901
ROC train: 0.979025	val: 0.785601	test: 0.760515
PRC train: 0.793215	val: 0.277474	test: 0.148362

Epoch: 110
Loss: 0.07367419181623214
ROC train: 0.977162	val: 0.793476	test: 0.789372
PRC train: 0.778846	val: 0.310774	test: 0.152570

Epoch: 111
Loss: 0.07212125430618763
ROC train: 0.981048	val: 0.785901	test: 0.771658
PRC train: 0.799839	val: 0.298882	test: 0.152945

Epoch: 112
Loss: 0.0712111735389947
ROC train: 0.981506	val: 0.789777	test: 0.788179
PRC train: 0.806587	val: 0.296673	test: 0.178087

Epoch: 113
Loss: 0.07224377081045996
ROC train: 0.982146	val: 0.805191	test: 0.791873
PRC train: 0.800263	val: 0.296223	test: 0.158200

Epoch: 114
Loss: 0.07094676306159298
ROC train: 0.980631	val: 0.782839	test: 0.783831
PRC train: 0.792924	val: 0.284282	test: 0.162723

Epoch: 115
Loss: 0.07168174131839641
ROC train: 0.980644	val: 0.785975	test: 0.784260
PRC train: 0.801849	val: 0.290537	test: 0.161517

Epoch: 116
Loss: 0.07156219758250569
ROC train: 0.981321	val: 0.782221	test: 0.770838
PRC train: 0.795884	val: 0.294878	test: 0.157634

Epoch: 117
Loss: 0.0736835784297473
ROC train: 0.981726	val: 0.802699	test: 0.768018
PRC train: 0.803533	val: 0.298777	test: 0.153790

Epoch: 118
Loss: 0.07004088865119083
ROC train: 0.979389	val: 0.791694	test: 0.756988
PRC train: 0.789091	val: 0.319406	test: 0.162386

Epoch: 119
Loss: 0.06947836770806338
ROC train: 0.979442	val: 0.792105	test: 0.775963
PRC train: 0.797231	val: 0.316781	test: 0.142026

Epoch: 120
Loss: 0.07077267841683385
ROC train: 0.982375	val: 0.785751	test: 0.788613
PRC train: 0.808881	val: 0.347740	test: 0.172202

Epoch: 121
Loss: 0.06861843158939264
ROC train: 0.983520	val: 0.809570	test: 0.784256
PRC train: 0.815095	val: 0.312438	test: 0.188617

Epoch: 122
Loss: 0.07099710309140439
ROC train: 0.981601	val: 0.799242	test: 0.773126
PRC train: 0.799824	val: 0.270499	test: 0.147400

Epoch: 123
Loss: 0.06948838756008942
ROC train: 0.982358	val: 0.802028	test: 0.769360
PRC train: 0.808015	val: 0.324028	test: 0.169888

Epoch: 124
Loss: 0.07108359434903205
ROC train: 0.980788	val: 0.801529	test: 0.747969
PRC train: 0.797822	val: 0.260995	test: 0.127053

Epoch: 125
Loss: 0.06845826477982993
ROC train: 0.981965	val: 0.785570	test: 0.759607
PRC train: 0.799821	val: 0.295990	test: 0.142396

Epoch: 126
Loss: 0.06868951201708196
ROC train: 0.982479	val: 0.794422	test: 0.758441
PRC train: 0.808644	val: 0.300357	test: 0.166652

Epoch: 127
Loss: 0.06782506581038009
ROC train: 0.983550	val: 0.813275	test: 0.779038
PRC train: 0.801652	val: 0.350831	test: 0.205709

Epoch: 128
Loss: 0.06873392701931735
ROC train: 0.984257	val: 0.817858	test: 0.774681
PRC train: 0.818956	val: 0.317587	test: 0.175394

Epoch: 129
Loss: 0.06750322928227004
ROC train: 0.985421	val: 0.794303	test: 0.761987
PRC train: 0.823442	val: 0.319527	test: 0.159767

Epoch: 130
Loss: 0.06742620395810696
ROC train: 0.986517	val: 0.809545	test: 0.771575
PRC train: 0.835261	val: 0.274217	test: 0.143238

Epoch: 131
Loss: 0.06712151628835437
ROC train: 0.984229	val: 0.805090	test: 0.756616
PRC train: 0.823033	val: 0.293158	test: 0.138598

Epoch: 132
Loss: 0.06637569222394035
ROC train: 0.985108	val: 0.801058	test: 0.786645
PRC train: 0.827691	val: 0.335701	test: 0.187389

Epoch: 133
Loss: 0.06548551881126337
ROC train: 0.985756	val: 0.806842	test: 0.777790
PRC train: 0.830969	val: 0.305672	test: 0.161256

Epoch: 134
Loss: 0.0660575285576794
ROC train: 0.987056	val: 0.793094	test: 0.774302
PRC train: 0.839961	val: 0.274117	test: 0.169689

Epoch: 135
Loss: 0.06597721416354141
ROC train: 0.986756	val: 0.800724	test: 0.780722
PRC train: 0.837713	val: 0.293120	test: 0.161804

Epoch: 136
Loss: 0.06548465266907577
ROC train: 0.986218	val: 0.788194	test: 0.773518
PRC train: 0.826771	val: 0.275001	test: 0.167634

Epoch: 137
Loss: 0.06533888544979191
ROC train: 0.987754	val: 0.794903	test: 0.778860
PRC train: 0.844311	val: 0.299698	test: 0.186703

Epoch: 138
Loss: 0.06524522062165128
ROC train: 0.986174	val: 0.786128	test: 0.747015
PRC train: 0.838782	val: 0.289391	test: 0.142890

Epoch: 139
Loss: 0.06490120711503702
ROC train: 0.987245	val: 0.776134	test: 0.767753
PRC train: 0.837737	val: 0.284444	test: 0.153686

Epoch: 140
Loss: 0.06400283684201728
ROC train: 0.986231	val: 0.759553	test: 0.760955
PRC train: 0.832426	val: 0.269030	test: 0.134674

Epoch: 141
Loss: 0.06430857255307552
ROC train: 0.984846	val: 0.781982	test: 0.769047
PRC train: 0.825661	val: 0.297857	test: 0.138960

Epoch: 142
Loss: 0.06534132086999635
ROC train: 0.984461	val: 0.786351	test: 0.746007
PRC train: 0.800134	val: 0.260236	test: 0.120085

Epoch: 143
Loss: 0.06496082691499146
ROC train: 0.989285	val: 0.777426	test: 0.766967
PRC train: 0.851779	val: 0.274226	test: 0.151149

Epoch: 144
Loss: 0.06416950624965603
ROC train: 0.986185	val: 0.795041	test: 0.781464
PRC train: 0.835157	val: 0.302970	test: 0.153619

Epoch: 145
Loss: 0.06320983070858378
ROC train: 0.986374	val: 0.775264	test: 0.762587
PRC train: 0.829428	val: 0.270894	test: 0.129693

Epoch: 146
Loss: 0.06533015228470465
ROC train: 0.986700	val: 0.790442	test: 0.750200
PRC train: 0.832094	val: 0.274897	test: 0.141522

Epoch: 147
Loss: 0.0633698643312122
ROC train: 0.987349	val: 0.797542	test: 0.756664
PRC train: 0.836532	val: 0.277315	test: 0.145595

Epoch: 148
Loss: 0.06404078112438863
ROC train: 0.986505	val: 0.782456	test: 0.766245
PRC train: 0.837007	val: 0.326220	test: 0.173653

Epoch: 149
Loss: 0.06320233351542918
ROC train: 0.989175	val: 0.787242	test: 0.760148
PRC train: 0.851186	val: 0.272794	test: 0.146002

Epoch: 150
Loss: 0.061998461455580835
ROC train: 0.990211	val: 0.801652	test: 0.752193
PRC train: 0.860303	val: 0.297039	test: 0.139725

Epoch: 151
Loss: 0.06381579460020351
ROC train: 0.989788	val: 0.793207	test: 0.766353
PRC train: 0.852459	val: 0.300405	test: 0.162326

Epoch: 152
Loss: 0.061427268984243
ROC train: 0.989651	val: 0.793231	test: 0.759632
PRC train: 0.856160	val: 0.266815	test: 0.148347

Epoch: 153
Loss: 0.06264810070755265
ROC train: 0.989819	val: 0.795877	test: 0.769267
PRC train: 0.853274	val: 0.267825	test: 0.144047

Epoch: 154
Loss: 0.06244404361198237
ROC train: 0.989150	val: 0.792787	test: 0.773217
PRC train: 0.936179	val: 0.327969	test: 0.218445

Epoch: 94
Loss: 0.052215360677797855
ROC train: 0.995250	val: 0.785001	test: 0.733645
PRC train: 0.938052	val: 0.326254	test: 0.212199

Epoch: 95
Loss: 0.05275986256808835
ROC train: 0.995334	val: 0.796875	test: 0.743099
PRC train: 0.945002	val: 0.328119	test: 0.226061

Epoch: 96
Loss: 0.04921213531886357
ROC train: 0.997038	val: 0.789545	test: 0.728795
PRC train: 0.958090	val: 0.319800	test: 0.169090

Epoch: 97
Loss: 0.04873228826869563
ROC train: 0.995933	val: 0.790708	test: 0.725412
PRC train: 0.944341	val: 0.322977	test: 0.200200

Epoch: 98
Loss: 0.051700774758454256
ROC train: 0.995494	val: 0.777995	test: 0.742807
PRC train: 0.938993	val: 0.315117	test: 0.207408

Epoch: 99
Loss: 0.048977462455233
ROC train: 0.996121	val: 0.781492	test: 0.743093
PRC train: 0.948644	val: 0.316644	test: 0.203276

Epoch: 100
Loss: 0.04907266069872248
ROC train: 0.995097	val: 0.806309	test: 0.742262
PRC train: 0.940490	val: 0.312757	test: 0.202471

Epoch: 101
Loss: 0.05019607356239531
ROC train: 0.994785	val: 0.795203	test: 0.751144
PRC train: 0.929954	val: 0.321083	test: 0.248471

Epoch: 102
Loss: 0.04844742989343736
ROC train: 0.994758	val: 0.809031	test: 0.741484
PRC train: 0.937695	val: 0.366330	test: 0.222644

Epoch: 103
Loss: 0.04714992532331128
ROC train: 0.996703	val: 0.794891	test: 0.730076
PRC train: 0.956933	val: 0.342798	test: 0.234624

Epoch: 104
Loss: 0.04691126778294717
ROC train: 0.996765	val: 0.779272	test: 0.715263
PRC train: 0.957079	val: 0.294008	test: 0.176904

Epoch: 105
Loss: 0.04586124540018215
ROC train: 0.994731	val: 0.783029	test: 0.719108
PRC train: 0.944355	val: 0.316852	test: 0.181206

Epoch: 106
Loss: 0.0467256769233784
ROC train: 0.997397	val: 0.780880	test: 0.734935
PRC train: 0.961092	val: 0.318060	test: 0.200338

Epoch: 107
Loss: 0.047215301360652974
ROC train: 0.997183	val: 0.808581	test: 0.731155
PRC train: 0.957907	val: 0.328365	test: 0.201198

Epoch: 108
Loss: 0.04277113220552028
ROC train: 0.997032	val: 0.806643	test: 0.742909
PRC train: 0.956805	val: 0.342159	test: 0.230432

Epoch: 109
Loss: 0.044055786552685286
ROC train: 0.997191	val: 0.781844	test: 0.733085
PRC train: 0.957242	val: 0.329692	test: 0.190858

Epoch: 110
Loss: 0.045261687852874356
ROC train: 0.997698	val: 0.806728	test: 0.748012
PRC train: 0.963479	val: 0.336294	test: 0.218054

Epoch: 111
Loss: 0.04538474091202618
ROC train: 0.997724	val: 0.807132	test: 0.749269
PRC train: 0.965963	val: 0.326428	test: 0.189122

Epoch: 112
Loss: 0.045176618660624425
ROC train: 0.997784	val: 0.792175	test: 0.735263
PRC train: 0.965608	val: 0.346625	test: 0.180183

Epoch: 113
Loss: 0.04398328147280662
ROC train: 0.996364	val: 0.798532	test: 0.749626
PRC train: 0.948008	val: 0.371897	test: 0.191063

Epoch: 114
Loss: 0.041092986471493696
ROC train: 0.998481	val: 0.799401	test: 0.734796
PRC train: 0.976131	val: 0.313700	test: 0.192106

Epoch: 115
Loss: 0.043443898253360355
ROC train: 0.997140	val: 0.794376	test: 0.734775
PRC train: 0.958728	val: 0.269387	test: 0.150482

Epoch: 116
Loss: 0.044829068333118206
ROC train: 0.998803	val: 0.808676	test: 0.725854
PRC train: 0.978071	val: 0.332289	test: 0.191317

Epoch: 117
Loss: 0.04256419723176151
ROC train: 0.998319	val: 0.801027	test: 0.739485
PRC train: 0.971902	val: 0.335566	test: 0.209528

Epoch: 118
Loss: 0.04269186860303624
ROC train: 0.997846	val: 0.822803	test: 0.741565
PRC train: 0.969638	val: 0.332047	test: 0.228928

Epoch: 119
Loss: 0.039532169654373714
ROC train: 0.998811	val: 0.801425	test: 0.720000
PRC train: 0.979172	val: 0.299510	test: 0.162835

Epoch: 120
Loss: 0.04043846737346838
ROC train: 0.998715	val: 0.795243	test: 0.750347
PRC train: 0.977340	val: 0.347858	test: 0.220577

Epoch: 121
Loss: 0.04023581706762946
ROC train: 0.998423	val: 0.792187	test: 0.750323
PRC train: 0.973919	val: 0.332546	test: 0.223117

Epoch: 122
Loss: 0.043944490734882345
ROC train: 0.998314	val: 0.798780	test: 0.743917
PRC train: 0.975153	val: 0.363619	test: 0.199678

Epoch: 123
Loss: 0.039185519579646465
ROC train: 0.998375	val: 0.800249	test: 0.750086
PRC train: 0.972508	val: 0.352421	test: 0.190482

Epoch: 124
Loss: 0.038251481703211736
ROC train: 0.998525	val: 0.795607	test: 0.759760
PRC train: 0.975321	val: 0.333465	test: 0.223727

Epoch: 125
Loss: 0.03952157799958695
ROC train: 0.998671	val: 0.801045	test: 0.735731
PRC train: 0.977057	val: 0.347349	test: 0.188408

Epoch: 126
Loss: 0.03924873193057757
ROC train: 0.999086	val: 0.803333	test: 0.732550
PRC train: 0.984147	val: 0.335199	test: 0.190199

Epoch: 127
Loss: 0.03951108872085848
ROC train: 0.998895	val: 0.797595	test: 0.759895
PRC train: 0.979827	val: 0.358959	test: 0.218492

Epoch: 128
Loss: 0.03838452070090692
ROC train: 0.998958	val: 0.789196	test: 0.734495
PRC train: 0.980411	val: 0.324628	test: 0.179213

Epoch: 129
Loss: 0.03539429547227238
ROC train: 0.999131	val: 0.802114	test: 0.760973
PRC train: 0.983000	val: 0.337501	test: 0.195602

Epoch: 130
Loss: 0.0373732136476337
ROC train: 0.998966	val: 0.799061	test: 0.733137
PRC train: 0.982842	val: 0.315841	test: 0.200003

Epoch: 131
Loss: 0.03890330949587566
ROC train: 0.998982	val: 0.804658	test: 0.743634
PRC train: 0.980068	val: 0.370684	test: 0.188396

Epoch: 132
Loss: 0.036594276692662596
ROC train: 0.998607	val: 0.801774	test: 0.747525
PRC train: 0.977170	val: 0.307642	test: 0.158958

Epoch: 133
Loss: 0.03467890520283032
ROC train: 0.997963	val: 0.808639	test: 0.756981
PRC train: 0.967568	val: 0.371859	test: 0.264997

Epoch: 134
Loss: 0.03577624051907799
ROC train: 0.999117	val: 0.807350	test: 0.763143
PRC train: 0.982598	val: 0.375484	test: 0.239575

Epoch: 135
Loss: 0.03867897350450895
ROC train: 0.999254	val: 0.794138	test: 0.741924
PRC train: 0.986452	val: 0.301932	test: 0.187970

Epoch: 136
Loss: 0.036294250617348124
ROC train: 0.999068	val: 0.798969	test: 0.749033
PRC train: 0.983216	val: 0.306331	test: 0.181979

Epoch: 137
Loss: 0.03551111079201161
ROC train: 0.999443	val: 0.804230	test: 0.748512
PRC train: 0.988475	val: 0.319615	test: 0.184207

Epoch: 138
Loss: 0.03774844744683594
ROC train: 0.999153	val: 0.791308	test: 0.741140
PRC train: 0.985190	val: 0.321352	test: 0.198920

Epoch: 139
Loss: 0.03428975666856281
ROC train: 0.999336	val: 0.782873	test: 0.754020
PRC train: 0.987997	val: 0.290193	test: 0.194551

Epoch: 140
Loss: 0.03338398265142375
ROC train: 0.999349	val: 0.782260	test: 0.742801
PRC train: 0.988171	val: 0.283792	test: 0.145272

Epoch: 141
Loss: 0.03357005891203923
ROC train: 0.999450	val: 0.769140	test: 0.744814
PRC train: 0.989968	val: 0.301254	test: 0.204236

Epoch: 142
Loss: 0.03198127903510642
ROC train: 0.999410	val: 0.801946	test: 0.756266
PRC train: 0.987795	val: 0.351928	test: 0.253756

Epoch: 143
Loss: 0.033902301908833754
ROC train: 0.999329	val: 0.800179	test: 0.749817
PRC train: 0.987444	val: 0.328078	test: 0.248368

Epoch: 144
Loss: 0.034214893478359425
ROC train: 0.999426	val: 0.792319	test: 0.743755
PRC train: 0.988542	val: 0.311971	test: 0.194948

Epoch: 145
Loss: 0.03144760420943009
ROC train: 0.999242	val: 0.800347	test: 0.766069
PRC train: 0.985284	val: 0.333544	test: 0.271136

Epoch: 146
Loss: 0.032659152664723134
ROC train: 0.999348	val: 0.795613	test: 0.743162
PRC train: 0.986748	val: 0.294781	test: 0.183206

Epoch: 147
Loss: 0.03301907484780088
ROC train: 0.999651	val: 0.794562	test: 0.751214
PRC train: 0.992652	val: 0.300814	test: 0.165824

Epoch: 148
Loss: 0.032607690933082814
ROC train: 0.999320	val: 0.787937	test: 0.728125
PRC train: 0.986879	val: 0.294933	test: 0.176392

Epoch: 149
Loss: 0.034257604872140704
ROC train: 0.999536	val: 0.802634	test: 0.736080
PRC train: 0.991517	val: 0.282522	test: 0.152083

Epoch: 150
Loss: 0.029924857653236547
ROC train: 0.999705	val: 0.799444	test: 0.749356
PRC train: 0.993716	val: 0.326102	test: 0.192229

Epoch: 151
Loss: 0.03412524000569377
ROC train: 0.998606	val: 0.805559	test: 0.716988
PRC train: 0.983117	val: 0.298453	test: 0.156345

Epoch: 152
Loss: 0.036563923014154245
ROC train: 0.999544	val: 0.800555	test: 0.756616
PRC train: 0.991195	val: 0.335054	test: 0.222941

Epoch: 153
Loss: 0.031150691683204494
ROC train: 0.999646	val: 0.800635	test: 0.752552
PRC train: 0.992488	val: 0.326496	test: 0.210779

Early stopping
Best (ROC):	 train: 0.997846	val: 0.822803	test: 0.741565
Best (PRC):	 train: 0.969638	val: 0.332047	test: 0.228928
All runs completed.

PRC train: 0.859139	val: 0.323023	test: 0.173336

Epoch: 155
Loss: 0.06096725760038035
ROC train: 0.990447	val: 0.797766	test: 0.767574
PRC train: 0.861031	val: 0.295856	test: 0.166749

Epoch: 156
Loss: 0.060049230562286206
ROC train: 0.989524	val: 0.800323	test: 0.769285
PRC train: 0.856967	val: 0.314555	test: 0.172078

Epoch: 157
Loss: 0.06225862893025709
ROC train: 0.991237	val: 0.791927	test: 0.770160
PRC train: 0.870143	val: 0.306675	test: 0.178292

Epoch: 158
Loss: 0.06146653174746102
ROC train: 0.990275	val: 0.802892	test: 0.756129
PRC train: 0.865769	val: 0.279015	test: 0.148039

Epoch: 159
Loss: 0.0623935414477056
ROC train: 0.990891	val: 0.803774	test: 0.753531
PRC train: 0.863813	val: 0.278386	test: 0.129434

Epoch: 160
Loss: 0.060281495142084925
ROC train: 0.990904	val: 0.779091	test: 0.762954
PRC train: 0.873840	val: 0.284120	test: 0.170739

Epoch: 161
Loss: 0.06046486772477353
ROC train: 0.989861	val: 0.806101	test: 0.754895
PRC train: 0.857919	val: 0.276295	test: 0.156302

Epoch: 162
Loss: 0.060692053457772795
ROC train: 0.990570	val: 0.802610	test: 0.762769
PRC train: 0.861865	val: 0.280565	test: 0.176509

Epoch: 163
Loss: 0.06060023878757823
ROC train: 0.991572	val: 0.803198	test: 0.765127
PRC train: 0.872873	val: 0.320784	test: 0.169216

Early stopping
Best (ROC):	 train: 0.984257	val: 0.817858	test: 0.774681
Best (PRC):	 train: 0.818956	val: 0.317587	test: 0.175394
All runs completed.
