>>> Starting run for dataset: bace
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running RANDOM configs_split_experiments/GraphCL/bace/random/train_prop=0.6.yml on cuda:0
Running RANDOM configs_split_experiments/GraphCL/bace/random/train_prop=0.7.yml on cuda:1
Running RANDOM configs_split_experiments/GraphCL/bace/random/train_prop=0.8.yml on cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.7.yml --runseed 4 --device cuda:1
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.7.yml --runseed 5 --device cuda:1
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.7.yml --runseed 6 --device cuda:1
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.6.yml --runseed 4 --device cuda:0
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.6.yml --runseed 5 --device cuda:0
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.6.yml --runseed 6 --device cuda:0
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.8.yml --runseed 4 --device cuda:2
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.8.yml --runseed 5 --device cuda:2
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.8.yml --runseed 6 --device cuda:2
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/random/train_prop=0.6/bace_random_4_26-05_09-43-14  ]
[ Using Seed :  4  ]
[ Using device :  cuda:0  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
randomly split
Data(edge_attr=[78, 2], edge_index=[2, 78], id=[1], x=[37, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6952484010982346
ROC train: 0.657252	val: 0.654334	test: 0.651061
PRC train: 0.586744	val: 0.596214	test: 0.522582

Epoch: 2
Loss: 0.6626062205434747
ROC train: 0.735909	val: 0.686724	test: 0.713572
PRC train: 0.676841	val: 0.654113	test: 0.614852

Epoch: 3
Loss: 0.6262431767512451
ROC train: 0.790671	val: 0.733948	test: 0.771441
PRC train: 0.737893	val: 0.695911	test: 0.682644

Epoch: 4
Loss: 0.5938324094887109
ROC train: 0.818500	val: 0.748212	test: 0.788064
PRC train: 0.767975	val: 0.695313	test: 0.698087

Epoch: 5
Loss: 0.548207413567566
ROC train: 0.846854	val: 0.768400	test: 0.801459
PRC train: 0.796075	val: 0.703799	test: 0.706873

Epoch: 6
Loss: 0.5446329175944045
ROC train: 0.861449	val: 0.767522	test: 0.800309
PRC train: 0.805140	val: 0.704940	test: 0.713681

Epoch: 7
Loss: 0.5015289919857843
ROC train: 0.867392	val: 0.771824	test: 0.803581
PRC train: 0.816056	val: 0.710380	test: 0.720513

Epoch: 8
Loss: 0.48961704542076967
ROC train: 0.874781	val: 0.777266	test: 0.808974
PRC train: 0.828787	val: 0.708958	test: 0.724422

Epoch: 9
Loss: 0.46022190109211814
ROC train: 0.884452	val: 0.782620	test: 0.806985
PRC train: 0.842711	val: 0.719297	test: 0.717982

Epoch: 10
Loss: 0.4679130066179284
ROC train: 0.887671	val: 0.785561	test: 0.812290
PRC train: 0.849669	val: 0.723172	test: 0.726483

Epoch: 11
Loss: 0.4544289567737003
ROC train: 0.891126	val: 0.788106	test: 0.815517
PRC train: 0.853641	val: 0.728418	test: 0.732754

Epoch: 12
Loss: 0.43778322726541113
ROC train: 0.897759	val: 0.790783	test: 0.813749
PRC train: 0.861752	val: 0.738649	test: 0.739136

Epoch: 13
Loss: 0.45315007400026197
ROC train: 0.898872	val: 0.792846	test: 0.808974
PRC train: 0.867350	val: 0.738749	test: 0.730904

Epoch: 14
Loss: 0.4312437788487276
ROC train: 0.903213	val: 0.793812	test: 0.816401
PRC train: 0.871068	val: 0.734576	test: 0.735568

Epoch: 15
Loss: 0.43293970651888114
ROC train: 0.904785	val: 0.794733	test: 0.819717
PRC train: 0.873821	val: 0.735782	test: 0.746178

Epoch: 16
Loss: 0.4375619165386633
ROC train: 0.907333	val: 0.798113	test: 0.821397
PRC train: 0.875886	val: 0.754574	test: 0.752224

Epoch: 17
Loss: 0.42244478964475696
ROC train: 0.912453	val: 0.796050	test: 0.822989
PRC train: 0.880840	val: 0.754009	test: 0.756468

Epoch: 18
Loss: 0.43861799922551703
ROC train: 0.914758	val: 0.794558	test: 0.824226
PRC train: 0.885582	val: 0.748431	test: 0.761451

Epoch: 19
Loss: 0.4226081916756829
ROC train: 0.919195	val: 0.800834	test: 0.825066
PRC train: 0.892785	val: 0.757317	test: 0.758160

Epoch: 20
Loss: 0.41396949560512586
ROC train: 0.920802	val: 0.800571	test: 0.824182
PRC train: 0.896748	val: 0.760826	test: 0.753565

Epoch: 21
Loss: 0.3945936257495762
ROC train: 0.923159	val: 0.800702	test: 0.827498
PRC train: 0.899890	val: 0.762819	test: 0.760825

Epoch: 22
Loss: 0.3901386842621521
ROC train: 0.921502	val: 0.804082	test: 0.828647
PRC train: 0.897504	val: 0.764231	test: 0.764434

Epoch: 23
Loss: 0.3777817611828855
ROC train: 0.923092	val: 0.809129	test: 0.829664
PRC train: 0.898709	val: 0.774440	test: 0.765160

Epoch: 24
Loss: 0.4072285393485377
ROC train: 0.925692	val: 0.809963	test: 0.831786
PRC train: 0.902061	val: 0.784368	test: 0.765687

Epoch: 25
Loss: 0.3868864646484656
ROC train: 0.929898	val: 0.809480	test: 0.832405
PRC train: 0.909971	val: 0.774707	test: 0.762669

Epoch: 26
Loss: 0.4084346789621086
ROC train: 0.926618	val: 0.807417	test: 0.835897
PRC train: 0.904430	val: 0.764156	test: 0.766418

Epoch: 27
Loss: 0.3878700522768577
ROC train: 0.930314	val: 0.817468	test: 0.835544
PRC train: 0.906571	val: 0.782222	test: 0.767790

Epoch: 28
Loss: 0.3772475750247588
ROC train: 0.931493	val: 0.812991	test: 0.837356
PRC train: 0.909038	val: 0.775782	test: 0.774148

Epoch: 29
Loss: 0.3723102243167629
ROC train: 0.934511	val: 0.816370	test: 0.838329
PRC train: 0.915689	val: 0.780011	test: 0.774195

Epoch: 30
Loss: 0.38303988045865295
ROC train: 0.936813	val: 0.823568	test: 0.837710
PRC train: 0.919314	val: 0.796876	test: 0.771872

Epoch: 31
Loss: 0.368881596521092
ROC train: 0.937107	val: 0.823436	test: 0.835942
PRC train: 0.919085	val: 0.798201	test: 0.771275

Epoch: 32
Loss: 0.3710085563198536
ROC train: 0.939812	val: 0.820364	test: 0.834660
PRC train: 0.922239	val: 0.796662	test: 0.768620

Epoch: 33
Loss: 0.36746258320661573
ROC train: 0.942223	val: 0.818565	test: 0.828470Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/random/train_prop=0.6/bace_random_6_26-05_09-43-14  ]
[ Using Seed :  6  ]
[ Using device :  cuda:0  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
randomly split
Data(edge_attr=[78, 2], edge_index=[2, 78], id=[1], x=[37, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6907899011787678
ROC train: 0.671745	val: 0.669563	test: 0.637622
PRC train: 0.592156	val: 0.613061	test: 0.548383

Epoch: 2
Loss: 0.6582528011099902
ROC train: 0.698433	val: 0.680492	test: 0.669408
PRC train: 0.616397	val: 0.627971	test: 0.585998

Epoch: 3
Loss: 0.6353860938004895
ROC train: 0.748329	val: 0.714812	test: 0.711804
PRC train: 0.683961	val: 0.659439	test: 0.640153

Epoch: 4
Loss: 0.601876948426625
ROC train: 0.798145	val: 0.747904	test: 0.774271
PRC train: 0.742888	val: 0.692085	test: 0.698492

Epoch: 5
Loss: 0.5846873422334196
ROC train: 0.836741	val: 0.763178	test: 0.794916
PRC train: 0.784016	val: 0.699186	test: 0.707219

Epoch: 6
Loss: 0.5492795603280518
ROC train: 0.858069	val: 0.766601	test: 0.802387
PRC train: 0.805420	val: 0.698511	test: 0.706134

Epoch: 7
Loss: 0.5255844389239097
ROC train: 0.866844	val: 0.764582	test: 0.800044
PRC train: 0.826740	val: 0.703269	test: 0.715881

Epoch: 8
Loss: 0.5012497505383107
ROC train: 0.870832	val: 0.765021	test: 0.794562
PRC train: 0.834317	val: 0.709364	test: 0.716600

Epoch: 9
Loss: 0.4872913128189668
ROC train: 0.878352	val: 0.768137	test: 0.800884
PRC train: 0.838455	val: 0.705703	test: 0.713626

Epoch: 10
Loss: 0.48982634949427617
ROC train: 0.884594	val: 0.775247	test: 0.803669
PRC train: 0.846277	val: 0.715813	test: 0.714392

Epoch: 11
Loss: 0.4699219048159645
ROC train: 0.889371	val: 0.788589	test: 0.804996
PRC train: 0.854780	val: 0.738180	test: 0.724326

Epoch: 12
Loss: 0.45776397965148363
ROC train: 0.897372	val: 0.797498	test: 0.815429
PRC train: 0.864635	val: 0.750779	test: 0.740044

Epoch: 13
Loss: 0.43372504823882774
ROC train: 0.901831	val: 0.798508	test: 0.822149
PRC train: 0.870605	val: 0.755143	test: 0.746089

Epoch: 14
Loss: 0.4334385375600357
ROC train: 0.906373	val: 0.802765	test: 0.820336
PRC train: 0.876000	val: 0.769700	test: 0.743483

Epoch: 15
Loss: 0.41531256057731725
ROC train: 0.910312	val: 0.806847	test: 0.819584
PRC train: 0.882528	val: 0.774950	test: 0.746061

Epoch: 16
Loss: 0.42408000688566916
ROC train: 0.912762	val: 0.805969	test: 0.816180
PRC train: 0.887771	val: 0.778775	test: 0.745057

Epoch: 17
Loss: 0.4015220545459747
ROC train: 0.913688	val: 0.804038	test: 0.810035
PRC train: 0.890501	val: 0.782863	test: 0.740437

Epoch: 18
Loss: 0.40883848441629467
ROC train: 0.923085	val: 0.805530	test: 0.818037
PRC train: 0.900895	val: 0.779664	test: 0.742446

Epoch: 19
Loss: 0.3936847316018337
ROC train: 0.919268	val: 0.797103	test: 0.823165
PRC train: 0.897523	val: 0.758384	test: 0.749112

Epoch: 20
Loss: 0.402652632046349
ROC train: 0.926407	val: 0.800571	test: 0.829266
PRC train: 0.905101	val: 0.760720	test: 0.757188

Epoch: 21
Loss: 0.3989897233731065
ROC train: 0.929464	val: 0.803160	test: 0.829797
PRC train: 0.909816	val: 0.773714	test: 0.758030

Epoch: 22
Loss: 0.3941498166288454
ROC train: 0.932228	val: 0.810050	test: 0.834660
PRC train: 0.914161	val: 0.774654	test: 0.762531

Epoch: 23
Loss: 0.38146110627231855
ROC train: 0.931490	val: 0.810577	test: 0.833687
PRC train: 0.911589	val: 0.769702	test: 0.758216

Epoch: 24
Loss: 0.3672051511055394
ROC train: 0.932747	val: 0.811630	test: 0.833333
PRC train: 0.912856	val: 0.773150	test: 0.760161

Epoch: 25
Loss: 0.36048456025007003
ROC train: 0.936289	val: 0.815054	test: 0.834881
PRC train: 0.918062	val: 0.785275	test: 0.764260

Epoch: 26
Loss: 0.40093435817099854
ROC train: 0.941086	val: 0.816239	test: 0.832891
PRC train: 0.924656	val: 0.793463	test: 0.765130

Epoch: 27
Loss: 0.36039015936654084
ROC train: 0.943322	val: 0.811894	test: 0.831432
PRC train: 0.928002	val: 0.791855	test: 0.762887

Epoch: 28
Loss: 0.36781476682144537
ROC train: 0.945282	val: 0.810840	test: 0.831477
PRC train: 0.930697	val: 0.792058	test: 0.761834

Epoch: 29
Loss: 0.3673755969568864
ROC train: 0.945535	val: 0.815844	test: 0.833422
PRC train: 0.931787	val: 0.791788	test: 0.765600

Epoch: 30
Loss: 0.3759461913816377
ROC train: 0.943261	val: 0.813210	test: 0.835986
PRC train: 0.929508	val: 0.783934	test: 0.766614

Epoch: 31
Loss: 0.3574227700547468
ROC train: 0.944868	val: 0.816063	test: 0.835986
PRC train: 0.930241	val: 0.790117	test: 0.763827

Epoch: 32
Loss: 0.3585839064968205
ROC train: 0.947869	val: 0.814878	test: 0.833378
PRC train: 0.932868	val: 0.789391	test: 0.755210

Epoch: 33
Loss: 0.35643863399964004
ROC train: 0.949841	val: 0.815800	test: 0.833024Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/random/train_prop=0.6/bace_random_5_26-05_09-43-14  ]
[ Using Seed :  5  ]
[ Using device :  cuda:0  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
randomly split
Data(edge_attr=[78, 2], edge_index=[2, 78], id=[1], x=[37, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.697543191426134
ROC train: 0.650226	val: 0.631336	test: 0.645491
PRC train: 0.586735	val: 0.574349	test: 0.587723

Epoch: 2
Loss: 0.6584131357897757
ROC train: 0.720167	val: 0.676454	test: 0.703095
PRC train: 0.669177	val: 0.641965	test: 0.654026

Epoch: 3
Loss: 0.6347990779847718
ROC train: 0.775041	val: 0.721747	test: 0.740230
PRC train: 0.732509	val: 0.683118	test: 0.678141

Epoch: 4
Loss: 0.594624852035688
ROC train: 0.816065	val: 0.737152	test: 0.774934
PRC train: 0.775313	val: 0.698763	test: 0.707323

Epoch: 5
Loss: 0.566510488650445
ROC train: 0.834134	val: 0.741145	test: 0.778957
PRC train: 0.792435	val: 0.701714	test: 0.702149

Epoch: 6
Loss: 0.5516014016061691
ROC train: 0.845638	val: 0.756858	test: 0.802122
PRC train: 0.791894	val: 0.694410	test: 0.717279

Epoch: 7
Loss: 0.5318340794362006
ROC train: 0.849634	val: 0.759798	test: 0.801636
PRC train: 0.799523	val: 0.695173	test: 0.716178

Epoch: 8
Loss: 0.5238322130612094
ROC train: 0.858211	val: 0.765240	test: 0.804244
PRC train: 0.816967	val: 0.707434	test: 0.715997

Epoch: 9
Loss: 0.4903016482277336
ROC train: 0.873264	val: 0.772087	test: 0.804332
PRC train: 0.840712	val: 0.721243	test: 0.723667

Epoch: 10
Loss: 0.4777779454942347
ROC train: 0.883365	val: 0.779592	test: 0.801061
PRC train: 0.858577	val: 0.738219	test: 0.723632

Epoch: 11
Loss: 0.47391457736621184
ROC train: 0.894776	val: 0.795918	test: 0.814412
PRC train: 0.870574	val: 0.752999	test: 0.736124

Epoch: 12
Loss: 0.45777672554192295
ROC train: 0.897686	val: 0.804213	test: 0.817949
PRC train: 0.872396	val: 0.765454	test: 0.740889

Epoch: 13
Loss: 0.45041680196393286
ROC train: 0.900787	val: 0.802853	test: 0.816755
PRC train: 0.877078	val: 0.770574	test: 0.739327

Epoch: 14
Loss: 0.43841453222644633
ROC train: 0.903712	val: 0.798420	test: 0.816976
PRC train: 0.879586	val: 0.770113	test: 0.741513

Epoch: 15
Loss: 0.42885794650429654
ROC train: 0.910809	val: 0.804213	test: 0.818833
PRC train: 0.889415	val: 0.772396	test: 0.733442

Epoch: 16
Loss: 0.4209307324405415
ROC train: 0.912904	val: 0.807812	test: 0.816888
PRC train: 0.892195	val: 0.778706	test: 0.728034

Epoch: 17
Loss: 0.4436225977940601
ROC train: 0.915248	val: 0.816239	test: 0.819982
PRC train: 0.893197	val: 0.789506	test: 0.732604

Epoch: 18
Loss: 0.43168201844049203
ROC train: 0.915025	val: 0.818784	test: 0.822679
PRC train: 0.892101	val: 0.790137	test: 0.735622

Epoch: 19
Loss: 0.40969458198884523
ROC train: 0.920015	val: 0.821242	test: 0.828338
PRC train: 0.895307	val: 0.789147	test: 0.744900

Epoch: 20
Loss: 0.4077769031369604
ROC train: 0.923531	val: 0.820276	test: 0.830548
PRC train: 0.898670	val: 0.786834	test: 0.748989

Epoch: 21
Loss: 0.414032464895036
ROC train: 0.926304	val: 0.813342	test: 0.827586
PRC train: 0.904574	val: 0.780283	test: 0.742851

Epoch: 22
Loss: 0.39358903627202235
ROC train: 0.927267	val: 0.811455	test: 0.826614
PRC train: 0.906449	val: 0.780412	test: 0.742202

Epoch: 23
Loss: 0.40898039512073747
ROC train: 0.927228	val: 0.814878	test: 0.821839
PRC train: 0.907037	val: 0.784792	test: 0.740829

Epoch: 24
Loss: 0.395080504852067
ROC train: 0.928406	val: 0.818653	test: 0.825950
PRC train: 0.909655	val: 0.788083	test: 0.747007

Epoch: 25
Loss: 0.40051155464197
ROC train: 0.931838	val: 0.819882	test: 0.832228
PRC train: 0.914716	val: 0.784390	test: 0.754579

Epoch: 26
Loss: 0.3814733972947585
ROC train: 0.933928	val: 0.819794	test: 0.834571
PRC train: 0.916961	val: 0.782080	test: 0.754779

Epoch: 27
Loss: 0.38558287699147387
ROC train: 0.934530	val: 0.818126	test: 0.833952
PRC train: 0.918279	val: 0.780107	test: 0.750554

Epoch: 28
Loss: 0.3689852735824721
ROC train: 0.936020	val: 0.822076	test: 0.832007
PRC train: 0.919810	val: 0.787298	test: 0.753698

Epoch: 29
Loss: 0.3677866800400535
ROC train: 0.938506	val: 0.826158	test: 0.831432
PRC train: 0.922358	val: 0.793664	test: 0.753308

Epoch: 30
Loss: 0.37294091972745524
ROC train: 0.938572	val: 0.825587	test: 0.830416
PRC train: 0.923026	val: 0.792022	test: 0.751693

Epoch: 31
Loss: 0.3752974437024575
ROC train: 0.941248	val: 0.820233	test: 0.834792
PRC train: 0.927293	val: 0.788182	test: 0.758512

Epoch: 32
Loss: 0.3570249590191814
ROC train: 0.941517	val: 0.818170	test: 0.831432
PRC train: 0.927422	val: 0.788799	test: 0.759180

Epoch: 33
Loss: 0.38650553486357253
ROC train: 0.944408	val: 0.819662	test: 0.828382Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/random/train_prop=0.7/bace_random_5_26-05_09-43-14  ]
[ Using Seed :  5  ]
[ Using device :  cuda:1  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
randomly split
Data(edge_attr=[78, 2], edge_index=[2, 78], id=[1], x=[37, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6897519339754404
ROC train: 0.644865	val: 0.581110	test: 0.651516
PRC train: 0.581271	val: 0.541248	test: 0.630316

Epoch: 2
Loss: 0.6702862250972094
ROC train: 0.714837	val: 0.657536	test: 0.736883
PRC train: 0.656678	val: 0.612852	test: 0.705470

Epoch: 3
Loss: 0.6293324423668224
ROC train: 0.767249	val: 0.715152	test: 0.783582
PRC train: 0.702447	val: 0.662560	test: 0.750280

Epoch: 4
Loss: 0.5999703894108698
ROC train: 0.799229	val: 0.739000	test: 0.822718
PRC train: 0.736211	val: 0.684009	test: 0.778664

Epoch: 5
Loss: 0.5759568768027066
ROC train: 0.815141	val: 0.755529	test: 0.833554
PRC train: 0.754001	val: 0.700840	test: 0.779827

Epoch: 6
Loss: 0.566424845522702
ROC train: 0.823722	val: 0.760331	test: 0.836049
PRC train: 0.771378	val: 0.719181	test: 0.774212

Epoch: 7
Loss: 0.5295709131341231
ROC train: 0.828275	val: 0.761826	test: 0.838856
PRC train: 0.786597	val: 0.742184	test: 0.770832

Epoch: 8
Loss: 0.5457910883905486
ROC train: 0.853429	val: 0.780952	test: 0.858190
PRC train: 0.809404	val: 0.758949	test: 0.792835

Epoch: 9
Loss: 0.48853915229540823
ROC train: 0.857188	val: 0.790555	test: 0.859281
PRC train: 0.812158	val: 0.763358	test: 0.797589

Epoch: 10
Loss: 0.5116413513557714
ROC train: 0.860367	val: 0.792050	test: 0.851719
PRC train: 0.821156	val: 0.758259	test: 0.776356

Epoch: 11
Loss: 0.5064808149223209
ROC train: 0.863650	val: 0.797481	test: 0.853590
PRC train: 0.826315	val: 0.764978	test: 0.772095

Epoch: 12
Loss: 0.47538879072491264
ROC train: 0.874196	val: 0.811177	test: 0.863647
PRC train: 0.842280	val: 0.785762	test: 0.783158

Epoch: 13
Loss: 0.494062790034949
ROC train: 0.877785	val: 0.802440	test: 0.862867
PRC train: 0.845826	val: 0.767730	test: 0.782077

Epoch: 14
Loss: 0.49044341584664475
ROC train: 0.881844	val: 0.794726	test: 0.859281
PRC train: 0.849786	val: 0.749775	test: 0.780233

Epoch: 15
Loss: 0.4368267865545274
ROC train: 0.890458	val: 0.802204	test: 0.870741
PRC train: 0.860021	val: 0.763187	test: 0.795272

Epoch: 16
Loss: 0.48080159415634316
ROC train: 0.886406	val: 0.801023	test: 0.865362
PRC train: 0.858141	val: 0.766551	test: 0.789953

Epoch: 17
Loss: 0.45457759449797236
ROC train: 0.891384	val: 0.798505	test: 0.858813
PRC train: 0.862984	val: 0.757027	test: 0.786802

Epoch: 18
Loss: 0.43721316786193876
ROC train: 0.893313	val: 0.795356	test: 0.861776
PRC train: 0.864826	val: 0.750660	test: 0.786263

Epoch: 19
Loss: 0.45588176410552717
ROC train: 0.900867	val: 0.802361	test: 0.869104
PRC train: 0.875297	val: 0.752727	test: 0.789239

Epoch: 20
Loss: 0.42153446190231014
ROC train: 0.904294	val: 0.802676	test: 0.864193
PRC train: 0.880702	val: 0.757005	test: 0.784620

Epoch: 21
Loss: 0.42071537835912726
ROC train: 0.907867	val: 0.793152	test: 0.862945
PRC train: 0.885360	val: 0.750330	test: 0.783227

Epoch: 22
Loss: 0.45429149430851784
ROC train: 0.909381	val: 0.800945	test: 0.868481
PRC train: 0.886407	val: 0.765003	test: 0.787388

Epoch: 23
Loss: 0.41641701393508795
ROC train: 0.910555	val: 0.810941	test: 0.873236
PRC train: 0.887079	val: 0.772130	test: 0.796633

Epoch: 24
Loss: 0.41403115289228304
ROC train: 0.911279	val: 0.812515	test: 0.878927
PRC train: 0.890658	val: 0.771873	test: 0.810978

Epoch: 25
Loss: 0.43084446925691966
ROC train: 0.911403	val: 0.808658	test: 0.879395
PRC train: 0.889832	val: 0.765829	test: 0.810992

Epoch: 26
Loss: 0.4268125373160666
ROC train: 0.907312	val: 0.793939	test: 0.870352
PRC train: 0.883680	val: 0.753849	test: 0.800724

Epoch: 27
Loss: 0.43951674112623984
ROC train: 0.902096	val: 0.795750	test: 0.870508
PRC train: 0.877497	val: 0.761234	test: 0.802889

Epoch: 28
Loss: 0.4178971138590528
ROC train: 0.901981	val: 0.802834	test: 0.876043
PRC train: 0.880570	val: 0.769800	test: 0.814180

Epoch: 29
Loss: 0.41639054028689254
ROC train: 0.912050	val: 0.812987	test: 0.885164
PRC train: 0.892318	val: 0.781358	test: 0.824449

Epoch: 30
Loss: 0.4283528406788809
ROC train: 0.917438	val: 0.805667	test: 0.887425
PRC train: 0.897649	val: 0.762912	test: 0.818618

Epoch: 31
Loss: 0.42267898802436354
ROC train: 0.918273	val: 0.801968	test: 0.884307
PRC train: 0.899353	val: 0.765147	test: 0.817801

Epoch: 32
Loss: 0.4221783556394084
ROC train: 0.916084	val: 0.792365	test: 0.873002
PRC train: 0.895552	val: 0.761939	test: 0.808095

Epoch: 33
Loss: 0.4360063027712323
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/random/train_prop=0.8/bace_random_4_26-05_09-43-14  ]
[ Using Seed :  4  ]
[ Using device :  cuda:2  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
randomly split
Data(edge_attr=[78, 2], edge_index=[2, 78], id=[1], x=[37, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6880498161289453
ROC train: 0.672625	val: 0.669083	test: 0.635854
PRC train: 0.607286	val: 0.576435	test: 0.568502

Epoch: 2
Loss: 0.65860371730286
ROC train: 0.756402	val: 0.739580	test: 0.733193
PRC train: 0.696720	val: 0.627214	test: 0.677939

Epoch: 3
Loss: 0.6288995525001704
ROC train: 0.794354	val: 0.787967	test: 0.802346
PRC train: 0.730761	val: 0.678177	test: 0.735921

Epoch: 4
Loss: 0.5787113913568755
ROC train: 0.823190	val: 0.800109	test: 0.825105
PRC train: 0.756265	val: 0.698249	test: 0.772683

Epoch: 5
Loss: 0.5466593695037664
ROC train: 0.844425	val: 0.799021	test: 0.827381
PRC train: 0.789378	val: 0.698428	test: 0.777407

Epoch: 6
Loss: 0.5355546109095214
ROC train: 0.856335	val: 0.791410	test: 0.842787
PRC train: 0.798792	val: 0.668420	test: 0.792590

Epoch: 7
Loss: 0.513202306238633
ROC train: 0.855861	val: 0.782530	test: 0.842787
PRC train: 0.801214	val: 0.658546	test: 0.789810

Epoch: 8
Loss: 0.5143593428709329
ROC train: 0.869808	val: 0.790323	test: 0.843662
PRC train: 0.836398	val: 0.688408	test: 0.792828

Epoch: 9
Loss: 0.49270750908768546
ROC train: 0.877213	val: 0.788873	test: 0.840161
PRC train: 0.843641	val: 0.689117	test: 0.789271

Epoch: 10
Loss: 0.47519913420456766
ROC train: 0.879903	val: 0.795759	test: 0.839461
PRC train: 0.847566	val: 0.695421	test: 0.785843

Epoch: 11
Loss: 0.47689992345497834
ROC train: 0.885013	val: 0.804821	test: 0.850665
PRC train: 0.853251	val: 0.703541	test: 0.800351

Epoch: 12
Loss: 0.45122801466522144
ROC train: 0.889984	val: 0.802646	test: 0.849440
PRC train: 0.859406	val: 0.703932	test: 0.785980

Epoch: 13
Loss: 0.45249098234340746
ROC train: 0.890199	val: 0.798296	test: 0.854167
PRC train: 0.861553	val: 0.699009	test: 0.781164

Epoch: 14
Loss: 0.4455094726942795
ROC train: 0.892095	val: 0.807358	test: 0.856443
PRC train: 0.863977	val: 0.717534	test: 0.785478

Epoch: 15
Loss: 0.4565372818064324
ROC train: 0.896447	val: 0.813519	test: 0.852941
PRC train: 0.871040	val: 0.727052	test: 0.786582

Epoch: 16
Loss: 0.44319801945763737
ROC train: 0.900059	val: 0.815332	test: 0.855742
PRC train: 0.874899	val: 0.726222	test: 0.795362

Epoch: 17
Loss: 0.4343068237024187
ROC train: 0.900997	val: 0.816781	test: 0.850315
PRC train: 0.877045	val: 0.730952	test: 0.790792

Epoch: 18
Loss: 0.4397154464178337
ROC train: 0.904931	val: 0.823306	test: 0.858018
PRC train: 0.880374	val: 0.743549	test: 0.798465

Epoch: 19
Loss: 0.41640003150698446
ROC train: 0.909133	val: 0.825661	test: 0.848039
PRC train: 0.885844	val: 0.738157	test: 0.786223

Epoch: 20
Loss: 0.42372296319540714
ROC train: 0.912902	val: 0.834179	test: 0.859594
PRC train: 0.889513	val: 0.749747	test: 0.810913

Epoch: 21
Loss: 0.43020411457620994
ROC train: 0.912523	val: 0.829830	test: 0.865721
PRC train: 0.888558	val: 0.746114	test: 0.824875

Epoch: 22
Loss: 0.4224107407845681
ROC train: 0.913778	val: 0.823849	test: 0.865896
PRC train: 0.889775	val: 0.740286	test: 0.816785

Epoch: 23
Loss: 0.4182355145872506
ROC train: 0.915569	val: 0.817144	test: 0.862920
PRC train: 0.893448	val: 0.725634	test: 0.811023

Epoch: 24
Loss: 0.41659676797331746
ROC train: 0.913404	val: 0.816057	test: 0.858718
PRC train: 0.892169	val: 0.733350	test: 0.805132

Epoch: 25
Loss: 0.39732786718542634
ROC train: 0.915626	val: 0.825118	test: 0.858894
PRC train: 0.895714	val: 0.746669	test: 0.798903

Epoch: 26
Loss: 0.39147761681338833
ROC train: 0.921803	val: 0.825843	test: 0.871499
PRC train: 0.903147	val: 0.749025	test: 0.818232

Epoch: 27
Loss: 0.40840506058011206
ROC train: 0.927060	val: 0.827474	test: 0.870623
PRC train: 0.907695	val: 0.743343	test: 0.808820

Epoch: 28
Loss: 0.4042570770042412
ROC train: 0.926879	val: 0.835266	test: 0.866246
PRC train: 0.907885	val: 0.745829	test: 0.794675

Epoch: 29
Loss: 0.39217834777504096
ROC train: 0.928121	val: 0.837441	test: 0.868873
PRC train: 0.909795	val: 0.752156	test: 0.803067

Epoch: 30
Loss: 0.3981696905393657
ROC train: 0.926440	val: 0.838166	test: 0.871148
PRC train: 0.908195	val: 0.763469	test: 0.813871

Epoch: 31
Loss: 0.397276793548658
ROC train: 0.928568	val: 0.844146	test: 0.865896
PRC train: 0.909143	val: 0.765941	test: 0.803669

Epoch: 32
Loss: 0.37321100425547576
ROC train: 0.929557	val: 0.840159	test: 0.866071
PRC train: 0.910106	val: 0.759868	test: 0.799855

Epoch: 33
Loss: 0.37360948102858316
ROC train: 0.930976	val: 0.838528	test: 0.866947Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/random/train_prop=0.7/bace_random_4_26-05_09-43-14  ]
[ Using Seed :  4  ]
[ Using device :  cuda:1  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
randomly split
Data(edge_attr=[78, 2], edge_index=[2, 78], id=[1], x=[37, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6895574952240187
ROC train: 0.673449	val: 0.582212	test: 0.690808
PRC train: 0.591480	val: 0.524095	test: 0.617502

Epoch: 2
Loss: 0.6450204146840306
ROC train: 0.721824	val: 0.641401	test: 0.729789
PRC train: 0.643798	val: 0.576807	test: 0.663381

Epoch: 3
Loss: 0.623334656811336
ROC train: 0.773395	val: 0.694057	test: 0.780697
PRC train: 0.698390	val: 0.633119	test: 0.706129

Epoch: 4
Loss: 0.5865446958824749
ROC train: 0.810997	val: 0.741913	test: 0.808763
PRC train: 0.739223	val: 0.671628	test: 0.717330

Epoch: 5
Loss: 0.5609613420211579
ROC train: 0.829579	val: 0.762298	test: 0.832073
PRC train: 0.753467	val: 0.677184	test: 0.742685

Epoch: 6
Loss: 0.5390744362028912
ROC train: 0.845478	val: 0.768201	test: 0.843923
PRC train: 0.770763	val: 0.683462	test: 0.762298

Epoch: 7
Loss: 0.5366170608045042
ROC train: 0.855201	val: 0.776230	test: 0.849926
PRC train: 0.791366	val: 0.714777	test: 0.769337

Epoch: 8
Loss: 0.5159711799361817
ROC train: 0.856462	val: 0.773475	test: 0.835971
PRC train: 0.810852	val: 0.709107	test: 0.761217

Epoch: 9
Loss: 0.5112600494181454
ROC train: 0.862005	val: 0.776387	test: 0.841974
PRC train: 0.813836	val: 0.709217	test: 0.771665

Epoch: 10
Loss: 0.5077145323734322
ROC train: 0.870123	val: 0.778985	test: 0.844391
PRC train: 0.827119	val: 0.713879	test: 0.780825

Epoch: 11
Loss: 0.5064308879679353
ROC train: 0.872655	val: 0.784809	test: 0.835971
PRC train: 0.835633	val: 0.736836	test: 0.772179

Epoch: 12
Loss: 0.4838161073949256
ROC train: 0.869016	val: 0.779772	test: 0.825368
PRC train: 0.835697	val: 0.733058	test: 0.755445

Epoch: 13
Loss: 0.4456346801478409
ROC train: 0.880608	val: 0.798898	test: 0.836907
PRC train: 0.848031	val: 0.747914	test: 0.761784

Epoch: 14
Loss: 0.46101223840731215
ROC train: 0.882690	val: 0.799764	test: 0.843455
PRC train: 0.850785	val: 0.750577	test: 0.770506

Epoch: 15
Loss: 0.48450170477116494
ROC train: 0.885111	val: 0.804014	test: 0.849848
PRC train: 0.858422	val: 0.767108	test: 0.778769

Epoch: 16
Loss: 0.4801567739558587
ROC train: 0.889606	val: 0.803699	test: 0.850706
PRC train: 0.862422	val: 0.770214	test: 0.765271

Epoch: 17
Loss: 0.4809512931016219
ROC train: 0.891564	val: 0.796773	test: 0.846106
PRC train: 0.861887	val: 0.756930	test: 0.763531

Epoch: 18
Loss: 0.43692865983741713
ROC train: 0.897046	val: 0.796773	test: 0.850784
PRC train: 0.867299	val: 0.761330	test: 0.772651

Epoch: 19
Loss: 0.4787650106947491
ROC train: 0.900541	val: 0.791106	test: 0.856631
PRC train: 0.871058	val: 0.749417	test: 0.791254

Epoch: 20
Loss: 0.444249795123949
ROC train: 0.901273	val: 0.786541	test: 0.850316
PRC train: 0.875397	val: 0.748354	test: 0.787241

Epoch: 21
Loss: 0.41834971604852217
ROC train: 0.906507	val: 0.805431	test: 0.869026
PRC train: 0.880424	val: 0.780939	test: 0.813299

Epoch: 22
Loss: 0.4163156585246717
ROC train: 0.908578	val: 0.800236	test: 0.868559
PRC train: 0.881809	val: 0.769231	test: 0.813226

Epoch: 23
Loss: 0.4338641416520847
ROC train: 0.905385	val: 0.795435	test: 0.860918
PRC train: 0.879660	val: 0.766404	test: 0.798774

Epoch: 24
Loss: 0.4202860542745562
ROC train: 0.908668	val: 0.803778	test: 0.865674
PRC train: 0.881199	val: 0.778380	test: 0.790553

Epoch: 25
Loss: 0.42995012945288524
ROC train: 0.909090	val: 0.804250	test: 0.862244
PRC train: 0.882137	val: 0.768902	test: 0.789098

Epoch: 26
Loss: 0.4667064727477689
ROC train: 0.908231	val: 0.803463	test: 0.864193
PRC train: 0.882062	val: 0.756872	test: 0.799610

Epoch: 27
Loss: 0.42608953296507524
ROC train: 0.916270	val: 0.803148	test: 0.862945
PRC train: 0.889739	val: 0.766872	test: 0.798409

Epoch: 28
Loss: 0.4049413701184438
ROC train: 0.919254	val: 0.804959	test: 0.867623
PRC train: 0.894002	val: 0.770452	test: 0.796911

Epoch: 29
Loss: 0.415085868276562
ROC train: 0.916877	val: 0.803070	test: 0.869728
PRC train: 0.891902	val: 0.759103	test: 0.799549

Epoch: 30
Loss: 0.4475562811206026
ROC train: 0.919180	val: 0.800787	test: 0.867857
PRC train: 0.897368	val: 0.768248	test: 0.801172

Epoch: 31
Loss: 0.4154314418392806
ROC train: 0.921003	val: 0.791342	test: 0.876355
PRC train: 0.902851	val: 0.750927	test: 0.811278

Epoch: 32
Loss: 0.42730673846375644
ROC train: 0.918160	val: 0.784573	test: 0.878304
PRC train: 0.897871	val: 0.738277	test: 0.821870

Epoch: 33
Loss: 0.4308090808977084
ROC train: 0.923124	val: 0.787485	test: 0.877056Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/random/train_prop=0.7/bace_random_6_26-05_09-43-14  ]
[ Using Seed :  6  ]
[ Using device :  cuda:1  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
randomly split
Data(edge_attr=[78, 2], edge_index=[2, 78], id=[1], x=[37, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6927860489974107
ROC train: 0.677607	val: 0.641165	test: 0.685585
PRC train: 0.611471	val: 0.598510	test: 0.635679

Epoch: 2
Loss: 0.6732253862383186
ROC train: 0.693389	val: 0.666588	test: 0.711390
PRC train: 0.624504	val: 0.631437	test: 0.604595

Epoch: 3
Loss: 0.6324669220711693
ROC train: 0.728063	val: 0.710665	test: 0.760817
PRC train: 0.675567	val: 0.658759	test: 0.675788

Epoch: 4
Loss: 0.6340028895599026
ROC train: 0.778816	val: 0.729870	test: 0.804163
PRC train: 0.725764	val: 0.660391	test: 0.736860

Epoch: 5
Loss: 0.5901062425198214
ROC train: 0.805627	val: 0.709327	test: 0.809153
PRC train: 0.753252	val: 0.647542	test: 0.754943

Epoch: 6
Loss: 0.600520190930453
ROC train: 0.816687	val: 0.711295	test: 0.807593
PRC train: 0.762535	val: 0.660240	test: 0.770787

Epoch: 7
Loss: 0.5298927684858509
ROC train: 0.826623	val: 0.732861	test: 0.829110
PRC train: 0.766771	val: 0.658058	test: 0.770718

Epoch: 8
Loss: 0.5295205958645204
ROC train: 0.843279	val: 0.744667	test: 0.835269
PRC train: 0.792243	val: 0.674844	test: 0.788280

Epoch: 9
Loss: 0.5093721287045541
ROC train: 0.859787	val: 0.760409	test: 0.846340
PRC train: 0.815016	val: 0.692343	test: 0.811054

Epoch: 10
Loss: 0.5094222777790518
ROC train: 0.864516	val: 0.759307	test: 0.841194
PRC train: 0.822506	val: 0.695137	test: 0.802575

Epoch: 11
Loss: 0.4884965942556603
ROC train: 0.877400	val: 0.775994	test: 0.850004
PRC train: 0.839290	val: 0.717216	test: 0.799781

Epoch: 12
Loss: 0.48765875894446686
ROC train: 0.881064	val: 0.786619	test: 0.861152
PRC train: 0.843614	val: 0.740212	test: 0.806179

Epoch: 13
Loss: 0.505306541477066
ROC train: 0.882674	val: 0.790004	test: 0.864193
PRC train: 0.846758	val: 0.761205	test: 0.806351

Epoch: 14
Loss: 0.4763604994911219
ROC train: 0.884797	val: 0.783392	test: 0.865830
PRC train: 0.850034	val: 0.749710	test: 0.812105

Epoch: 15
Loss: 0.4534569550247435
ROC train: 0.884890	val: 0.778749	test: 0.861854
PRC train: 0.852719	val: 0.735382	test: 0.799234

Epoch: 16
Loss: 0.49827701233025634
ROC train: 0.882814	val: 0.773632	test: 0.863959
PRC train: 0.848693	val: 0.732744	test: 0.799057

Epoch: 17
Loss: 0.4535526566085705
ROC train: 0.886452	val: 0.786698	test: 0.872457
PRC train: 0.845774	val: 0.736624	test: 0.812467

Epoch: 18
Loss: 0.4572047562278689
ROC train: 0.893378	val: 0.792444	test: 0.868636
PRC train: 0.855429	val: 0.740662	test: 0.804772

Epoch: 19
Loss: 0.46113656761748434
ROC train: 0.898759	val: 0.789768	test: 0.859749
PRC train: 0.870798	val: 0.752003	test: 0.791430

Epoch: 20
Loss: 0.4209915186954877
ROC train: 0.902276	val: 0.795750	test: 0.865050
PRC train: 0.873877	val: 0.766443	test: 0.797255

Epoch: 21
Loss: 0.4299441515725026
ROC train: 0.904212	val: 0.803148	test: 0.867467
PRC train: 0.878418	val: 0.774251	test: 0.792198

Epoch: 22
Loss: 0.44017600906466303
ROC train: 0.904596	val: 0.803070	test: 0.866609
PRC train: 0.880411	val: 0.772637	test: 0.787885

Epoch: 23
Loss: 0.43624920571678344
ROC train: 0.904402	val: 0.794254	test: 0.865362
PRC train: 0.881115	val: 0.769376	test: 0.786421

Epoch: 24
Loss: 0.4372475266792584
ROC train: 0.906423	val: 0.790397	test: 0.868870
PRC train: 0.883536	val: 0.767743	test: 0.788800

Epoch: 25
Loss: 0.4104035104339358
ROC train: 0.911888	val: 0.798819	test: 0.874951
PRC train: 0.889776	val: 0.771481	test: 0.797666

Epoch: 26
Loss: 0.43926348364193846
ROC train: 0.912588	val: 0.805667	test: 0.874016
PRC train: 0.890827	val: 0.774856	test: 0.798204

Epoch: 27
Loss: 0.45037182775941176
ROC train: 0.913587	val: 0.808579	test: 0.868481
PRC train: 0.892856	val: 0.781728	test: 0.793387

Epoch: 28
Loss: 0.4404261064031111
ROC train: 0.912912	val: 0.799528	test: 0.865596
PRC train: 0.891752	val: 0.777544	test: 0.787480

Epoch: 29
Loss: 0.4268345919952212
ROC train: 0.910397	val: 0.788194	test: 0.878693
PRC train: 0.883665	val: 0.759340	test: 0.808543

Epoch: 30
Loss: 0.3993511121133755
ROC train: 0.912653	val: 0.789925	test: 0.877134
PRC train: 0.891182	val: 0.759405	test: 0.804256

Epoch: 31
Loss: 0.4069885125403889
ROC train: 0.915969	val: 0.799528	test: 0.881890
PRC train: 0.897615	val: 0.771038	test: 0.802721

Epoch: 32
Loss: 0.3767490583327072
ROC train: 0.920019	val: 0.800315	test: 0.878927
PRC train: 0.901938	val: 0.775745	test: 0.807056

Epoch: 33
Loss: 0.392676199710675
ROC train: 0.923368	val: 0.801810	test: 0.876510Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/random/train_prop=0.8/bace_random_6_26-05_09-43-14  ]
[ Using Seed :  6  ]
[ Using device :  cuda:2  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
randomly split
Data(edge_attr=[78, 2], edge_index=[2, 78], id=[1], x=[37, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6889412341745179
ROC train: 0.659725	val: 0.686481	test: 0.587010
PRC train: 0.591841	val: 0.563106	test: 0.564947

Epoch: 2
Loss: 0.6518201715472882
ROC train: 0.729055	val: 0.740304	test: 0.708333
PRC train: 0.673965	val: 0.631759	test: 0.620894

Epoch: 3
Loss: 0.6174308424870901
ROC train: 0.791554	val: 0.712396	test: 0.778361
PRC train: 0.742473	val: 0.618409	test: 0.737445

Epoch: 4
Loss: 0.595311748878182
ROC train: 0.799707	val: 0.731968	test: 0.810749
PRC train: 0.750887	val: 0.620340	test: 0.783184

Epoch: 5
Loss: 0.5563556181507416
ROC train: 0.825107	val: 0.756615	test: 0.816877
PRC train: 0.778070	val: 0.660806	test: 0.773738

Epoch: 6
Loss: 0.5383343168367868
ROC train: 0.853213	val: 0.774012	test: 0.843662
PRC train: 0.807458	val: 0.670162	test: 0.809299

Epoch: 7
Loss: 0.5328806982995914
ROC train: 0.853735	val: 0.772925	test: 0.847864
PRC train: 0.805593	val: 0.661226	test: 0.815125

Epoch: 8
Loss: 0.4978998122984596
ROC train: 0.865705	val: 0.785430	test: 0.837885
PRC train: 0.834267	val: 0.677112	test: 0.790577

Epoch: 9
Loss: 0.4910915589216926
ROC train: 0.873818	val: 0.807539	test: 0.853992
PRC train: 0.840499	val: 0.716299	test: 0.809779

Epoch: 10
Loss: 0.47283820447910585
ROC train: 0.881374	val: 0.794853	test: 0.867997
PRC train: 0.849646	val: 0.710430	test: 0.822100

Epoch: 11
Loss: 0.47489695253465875
ROC train: 0.886958	val: 0.800290	test: 0.864321
PRC train: 0.858969	val: 0.711479	test: 0.807186

Epoch: 12
Loss: 0.45107856340610014
ROC train: 0.890921	val: 0.823306	test: 0.870798
PRC train: 0.860854	val: 0.740339	test: 0.806170

Epoch: 13
Loss: 0.4620068535603597
ROC train: 0.895770	val: 0.825299	test: 0.869398
PRC train: 0.867889	val: 0.736538	test: 0.800501

Epoch: 14
Loss: 0.4641896813888948
ROC train: 0.893880	val: 0.808989	test: 0.859244
PRC train: 0.866888	val: 0.720092	test: 0.791205

Epoch: 15
Loss: 0.46370083103045034
ROC train: 0.899604	val: 0.816781	test: 0.859244
PRC train: 0.875941	val: 0.731122	test: 0.798195

Epoch: 16
Loss: 0.4470412860312877
ROC train: 0.901858	val: 0.821675	test: 0.861169
PRC train: 0.879637	val: 0.734783	test: 0.802712

Epoch: 17
Loss: 0.4383693214573515
ROC train: 0.902594	val: 0.824937	test: 0.865196
PRC train: 0.881382	val: 0.742712	test: 0.797334

Epoch: 18
Loss: 0.42826005302701586
ROC train: 0.903631	val: 0.819862	test: 0.864321
PRC train: 0.881311	val: 0.734980	test: 0.804791

Epoch: 19
Loss: 0.43899744770473115
ROC train: 0.909567	val: 0.825299	test: 0.862745
PRC train: 0.888452	val: 0.727716	test: 0.802088

Epoch: 20
Loss: 0.42175526529214186
ROC train: 0.913945	val: 0.827655	test: 0.865896
PRC train: 0.893540	val: 0.735639	test: 0.801027

Epoch: 21
Loss: 0.4135198880508722
ROC train: 0.913550	val: 0.832186	test: 0.872724
PRC train: 0.893145	val: 0.753399	test: 0.801698

Epoch: 22
Loss: 0.4168653421160993
ROC train: 0.916788	val: 0.835991	test: 0.869923
PRC train: 0.898245	val: 0.755881	test: 0.801883

Epoch: 23
Loss: 0.4051174800118803
ROC train: 0.916681	val: 0.833454	test: 0.872199
PRC train: 0.898339	val: 0.755192	test: 0.804496

Epoch: 24
Loss: 0.39986376627525233
ROC train: 0.917675	val: 0.830555	test: 0.876225
PRC train: 0.898817	val: 0.754875	test: 0.812719

Epoch: 25
Loss: 0.41457765790732076
ROC train: 0.917804	val: 0.814607	test: 0.873424
PRC train: 0.898823	val: 0.730986	test: 0.819045

Epoch: 26
Loss: 0.3906454354522994
ROC train: 0.924361	val: 0.825843	test: 0.877276
PRC train: 0.905699	val: 0.736459	test: 0.821258

Epoch: 27
Loss: 0.4008299207128211
ROC train: 0.924620	val: 0.830373	test: 0.874650
PRC train: 0.908101	val: 0.743286	test: 0.819695

Epoch: 28
Loss: 0.4152868490517986
ROC train: 0.922069	val: 0.827292	test: 0.874825
PRC train: 0.905704	val: 0.754858	test: 0.814115

Epoch: 29
Loss: 0.3948314385000841
ROC train: 0.924775	val: 0.833273	test: 0.871674
PRC train: 0.907821	val: 0.754570	test: 0.811075

Epoch: 30
Loss: 0.3912771647052619
ROC train: 0.926665	val: 0.832186	test: 0.878676
PRC train: 0.910856	val: 0.753318	test: 0.800000

Epoch: 31
Loss: 0.39169005683715474
ROC train: 0.929164	val: 0.830192	test: 0.880602
PRC train: 0.913565	val: 0.756521	test: 0.800695

Epoch: 32
Loss: 0.37355622343200856
ROC train: 0.929037	val: 0.831098	test: 0.880077
PRC train: 0.914094	val: 0.761732	test: 0.816722

Epoch: 33
Loss: 0.3857982450796572
ROC train: 0.934975	val: 0.841791	test: 0.879552Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/random/train_prop=0.8/bace_random_5_26-05_09-43-14  ]
[ Using Seed :  5  ]
[ Using device :  cuda:2  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
randomly split
Data(edge_attr=[78, 2], edge_index=[2, 78], id=[1], x=[37, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6973815516031922
ROC train: 0.648607	val: 0.642443	test: 0.593662
PRC train: 0.582495	val: 0.631415	test: 0.553151

Epoch: 2
Loss: 0.6545505362287691
ROC train: 0.741724	val: 0.676151	test: 0.681022
PRC train: 0.678515	val: 0.629562	test: 0.652253

Epoch: 3
Loss: 0.6222928996266619
ROC train: 0.778812	val: 0.707140	test: 0.741246
PRC train: 0.725162	val: 0.651835	test: 0.714109

Epoch: 4
Loss: 0.5853733395159388
ROC train: 0.805505	val: 0.735230	test: 0.762955
PRC train: 0.759256	val: 0.648593	test: 0.740115

Epoch: 5
Loss: 0.5614120806990095
ROC train: 0.826868	val: 0.758971	test: 0.789566
PRC train: 0.782044	val: 0.651849	test: 0.768124

Epoch: 6
Loss: 0.5361322592335286
ROC train: 0.837709	val: 0.770931	test: 0.809174
PRC train: 0.798095	val: 0.666383	test: 0.778591

Epoch: 7
Loss: 0.5103122552059295
ROC train: 0.854603	val: 0.781805	test: 0.813200
PRC train: 0.822154	val: 0.680503	test: 0.784165

Epoch: 8
Loss: 0.5140329657513789
ROC train: 0.870685	val: 0.795941	test: 0.829657
PRC train: 0.839566	val: 0.690678	test: 0.797263

Epoch: 9
Loss: 0.49903385715875836
ROC train: 0.881102	val: 0.806270	test: 0.844888
PRC train: 0.851879	val: 0.693309	test: 0.803682

Epoch: 10
Loss: 0.48634672755458225
ROC train: 0.885021	val: 0.815875	test: 0.853992
PRC train: 0.858017	val: 0.702431	test: 0.810787

Epoch: 11
Loss: 0.47396079056372475
ROC train: 0.887732	val: 0.818956	test: 0.859069
PRC train: 0.861982	val: 0.708460	test: 0.808863

Epoch: 12
Loss: 0.4579652129086586
ROC train: 0.889206	val: 0.820587	test: 0.857143
PRC train: 0.863712	val: 0.712079	test: 0.808616

Epoch: 13
Loss: 0.45466945766163985
ROC train: 0.890962	val: 0.817688	test: 0.855567
PRC train: 0.864251	val: 0.721524	test: 0.810492

Epoch: 14
Loss: 0.46949565272285765
ROC train: 0.894472	val: 0.820587	test: 0.859594
PRC train: 0.868238	val: 0.722467	test: 0.812325

Epoch: 15
Loss: 0.4372974402252499
ROC train: 0.895384	val: 0.814244	test: 0.851541
PRC train: 0.871548	val: 0.711062	test: 0.800769

Epoch: 16
Loss: 0.4384081743645976
ROC train: 0.900048	val: 0.816963	test: 0.842437
PRC train: 0.877776	val: 0.710721	test: 0.786571

Epoch: 17
Loss: 0.422212630846344
ROC train: 0.905872	val: 0.831823	test: 0.855917
PRC train: 0.883417	val: 0.738264	test: 0.798848

Epoch: 18
Loss: 0.43167181855278514
ROC train: 0.908249	val: 0.837441	test: 0.860819
PRC train: 0.885877	val: 0.741894	test: 0.803083

Epoch: 19
Loss: 0.4267767409170428
ROC train: 0.906163	val: 0.825480	test: 0.861169
PRC train: 0.884613	val: 0.729855	test: 0.799752

Epoch: 20
Loss: 0.42475034968617253
ROC train: 0.912281	val: 0.834179	test: 0.859594
PRC train: 0.891772	val: 0.736809	test: 0.786073

Epoch: 21
Loss: 0.42411310564934357
ROC train: 0.914399	val: 0.849221	test: 0.877101
PRC train: 0.892562	val: 0.762665	test: 0.801610

Epoch: 22
Loss: 0.4337372943886681
ROC train: 0.916316	val: 0.846502	test: 0.880777
PRC train: 0.896012	val: 0.761551	test: 0.808643

Epoch: 23
Loss: 0.40332119690945306
ROC train: 0.916136	val: 0.844690	test: 0.866772
PRC train: 0.898713	val: 0.753777	test: 0.792447

Epoch: 24
Loss: 0.38963512699119607
ROC train: 0.919040	val: 0.837260	test: 0.868697
PRC train: 0.904234	val: 0.741148	test: 0.792810

Epoch: 25
Loss: 0.41341371070914573
ROC train: 0.921213	val: 0.842515	test: 0.876926
PRC train: 0.904930	val: 0.757809	test: 0.818826

Epoch: 26
Loss: 0.39491743447451444
ROC train: 0.918766	val: 0.842153	test: 0.879027
PRC train: 0.900619	val: 0.759223	test: 0.831566

Epoch: 27
Loss: 0.39877524318291896
ROC train: 0.927088	val: 0.842697	test: 0.878151
PRC train: 0.910660	val: 0.746102	test: 0.830401

Epoch: 28
Loss: 0.39132884849121724
ROC train: 0.928892	val: 0.840341	test: 0.877626
PRC train: 0.912602	val: 0.743347	test: 0.823481

Epoch: 29
Loss: 0.3855080140873252
ROC train: 0.930963	val: 0.843965	test: 0.878501
PRC train: 0.915555	val: 0.747871	test: 0.829177

Epoch: 30
Loss: 0.3716371743991203
ROC train: 0.931769	val: 0.844146	test: 0.871499
PRC train: 0.916591	val: 0.754247	test: 0.818612

Epoch: 31
Loss: 0.3863957237963202
ROC train: 0.933866	val: 0.840522	test: 0.880777
PRC train: 0.920909	val: 0.759125	test: 0.830903

Epoch: 32
Loss: 0.3812417314255159
ROC train: 0.932499	val: 0.846140	test: 0.880077
PRC train: 0.918790	val: 0.764334	test: 0.831570

Epoch: 33
Loss: 0.38225059538870243

PRC train: 0.925801	val: 0.791337	test: 0.761533

Epoch: 34
Loss: 0.362420051120428
ROC train: 0.944961	val: 0.817643	test: 0.832935
PRC train: 0.928883	val: 0.778486	test: 0.763946

Epoch: 35
Loss: 0.31738537398077016
ROC train: 0.945667	val: 0.818258	test: 0.832714
PRC train: 0.929029	val: 0.776123	test: 0.764139

Epoch: 36
Loss: 0.3368012670030146
ROC train: 0.947975	val: 0.821242	test: 0.834527
PRC train: 0.930523	val: 0.781529	test: 0.770431

Epoch: 37
Loss: 0.3401201311504198
ROC train: 0.947828	val: 0.823349	test: 0.837754
PRC train: 0.930082	val: 0.785629	test: 0.779093

Epoch: 38
Loss: 0.3448967921191728
ROC train: 0.947377	val: 0.820364	test: 0.845668
PRC train: 0.930045	val: 0.767191	test: 0.788879

Epoch: 39
Loss: 0.3256794440070845
ROC train: 0.953068	val: 0.819969	test: 0.843413
PRC train: 0.939284	val: 0.773282	test: 0.781031

Epoch: 40
Loss: 0.3181928326241965
ROC train: 0.955755	val: 0.822822	test: 0.844916
PRC train: 0.942976	val: 0.782492	test: 0.781342

Epoch: 41
Loss: 0.3291590340240687
ROC train: 0.956607	val: 0.818740	test: 0.843236
PRC train: 0.944787	val: 0.783555	test: 0.775186

Epoch: 42
Loss: 0.3296760241900828
ROC train: 0.956892	val: 0.812289	test: 0.845137
PRC train: 0.944691	val: 0.760350	test: 0.779136

Epoch: 43
Loss: 0.333723713483874
ROC train: 0.958739	val: 0.815932	test: 0.842131
PRC train: 0.945440	val: 0.761655	test: 0.781511

Epoch: 44
Loss: 0.3231007213600483
ROC train: 0.958954	val: 0.819487	test: 0.834129
PRC train: 0.946481	val: 0.769301	test: 0.777192

Epoch: 45
Loss: 0.32061823371691145
ROC train: 0.958418	val: 0.820759	test: 0.834704
PRC train: 0.946545	val: 0.776198	test: 0.779005

Epoch: 46
Loss: 0.32153710242948824
ROC train: 0.956781	val: 0.817380	test: 0.836207
PRC train: 0.944510	val: 0.761301	test: 0.776084

Epoch: 47
Loss: 0.31903357356324713
ROC train: 0.962404	val: 0.818960	test: 0.837268
PRC train: 0.951300	val: 0.767168	test: 0.769530

Epoch: 48
Loss: 0.3102369497747087
ROC train: 0.962438	val: 0.820189	test: 0.841379
PRC train: 0.951275	val: 0.775563	test: 0.777199

Epoch: 49
Loss: 0.3075267407788161
ROC train: 0.961639	val: 0.816151	test: 0.844474
PRC train: 0.949688	val: 0.767192	test: 0.782446

Epoch: 50
Loss: 0.30828859677151343
ROC train: 0.960706	val: 0.808690	test: 0.840805
PRC train: 0.949527	val: 0.760622	test: 0.778646

Epoch: 51
Loss: 0.3158790220875677
ROC train: 0.962859	val: 0.822164	test: 0.840981
PRC train: 0.951957	val: 0.781425	test: 0.779016

Epoch: 52
Loss: 0.29025031215852615
ROC train: 0.962715	val: 0.824973	test: 0.832493
PRC train: 0.952636	val: 0.793241	test: 0.764774

Epoch: 53
Loss: 0.29991014621644296
ROC train: 0.962671	val: 0.820715	test: 0.835323
PRC train: 0.951808	val: 0.769914	test: 0.769621

Epoch: 54
Loss: 0.28898386659906655
ROC train: 0.963996	val: 0.815229	test: 0.834527
PRC train: 0.955055	val: 0.756399	test: 0.767259

Epoch: 55
Loss: 0.30613964064704224
ROC train: 0.965725	val: 0.820891	test: 0.841114
PRC train: 0.957014	val: 0.774192	test: 0.772236

Epoch: 56
Loss: 0.31149797303406124
ROC train: 0.967766	val: 0.825324	test: 0.845579
PRC train: 0.959292	val: 0.778639	test: 0.770260

Epoch: 57
Loss: 0.30128684827603397
ROC train: 0.965686	val: 0.823085	test: 0.846552
PRC train: 0.957206	val: 0.775959	test: 0.771735

Epoch: 58
Loss: 0.2967230987876167
ROC train: 0.964706	val: 0.825236	test: 0.840849
PRC train: 0.955061	val: 0.786180	test: 0.774475

Epoch: 59
Loss: 0.3044360704487608
ROC train: 0.965084	val: 0.829625	test: 0.836870
PRC train: 0.955465	val: 0.797698	test: 0.774766

Epoch: 60
Loss: 0.2874900543635603
ROC train: 0.965436	val: 0.825104	test: 0.833422
PRC train: 0.957613	val: 0.789677	test: 0.766937

Epoch: 61
Loss: 0.29098270590339975
ROC train: 0.969008	val: 0.824007	test: 0.835544
PRC train: 0.962225	val: 0.781112	test: 0.766726

Epoch: 62
Loss: 0.2749562586996816
ROC train: 0.971291	val: 0.824358	test: 0.840009
PRC train: 0.964131	val: 0.778746	test: 0.773746

Epoch: 63
Loss: 0.2796595012903418
ROC train: 0.967264	val: 0.817073	test: 0.844076
PRC train: 0.958567	val: 0.769493	test: 0.785340

Epoch: 64
Loss: 0.2891125775658545
ROC train: 0.968077	val: 0.819706	test: 0.844032
PRC train: 0.958795	val: 0.771366	test: 0.781618

Epoch: 65
Loss: 0.24938239298464066
ROC train: 0.970556	val: 0.818389	test: 0.839523
PRC train: 0.962099	val: 0.775426	test: 0.772967

Epoch: 66
Loss: 0.2828079467445359
ROC train: 0.971448	val: 0.810533	test: 0.836693
PRC train: 0.963577	val: 0.770247	test: 0.773964

Epoch: 67
Loss: 0.2804907647658235
ROC train: 0.973815	val: 0.819355	test: 0.836384
PRC train: 0.966612	val: 0.777293	test: 0.778338

Epoch: 68
Loss: 0.2730376514141301
ROC train: 0.972707	val: 0.826289	test: 0.838462
PRC train: 0.965816	val: 0.787468	test: 0.777664

Epoch: 69
Loss: 0.2812997226309134
ROC train: 0.968993	val: 0.825236	test: 0.839478
PRC train: 0.960399	val: 0.776916	test: 0.770170

Epoch: 70
Loss: 0.2731438900491745
ROC train: 0.971561	val: 0.824095	test: 0.838771
PRC train: 0.964331	val: 0.772592	test: 0.769363

Epoch: 71
Loss: 0.2839533610041925
ROC train: 0.975020	val: 0.822778	test: 0.840584
PRC train: 0.969271	val: 0.775970	test: 0.771579

Epoch: 72
Loss: 0.28618659829024545
ROC train: 0.975725	val: 0.820408	test: 0.845181
PRC train: 0.969930	val: 0.782958	test: 0.777186

Epoch: 73
Loss: 0.2923364629982136
ROC train: 0.975284	val: 0.822251	test: 0.847215
PRC train: 0.969837	val: 0.781202	test: 0.784498

Epoch: 74
Loss: 0.2643830267028153
ROC train: 0.974491	val: 0.829625	test: 0.848320
PRC train: 0.969009	val: 0.786205	test: 0.780086

Epoch: 75
Loss: 0.2587004018411857
ROC train: 0.975123	val: 0.830459	test: 0.849116
PRC train: 0.969620	val: 0.789972	test: 0.779102

Epoch: 76
Loss: 0.24497325203297632
ROC train: 0.977984	val: 0.826904	test: 0.843192
PRC train: 0.973061	val: 0.790725	test: 0.773319

Epoch: 77
Loss: 0.2560264943806775
ROC train: 0.976735	val: 0.818828	test: 0.843590
PRC train: 0.971658	val: 0.781338	test: 0.778535

Epoch: 78
Loss: 0.23611424223729915
ROC train: 0.975378	val: 0.818038	test: 0.845579
PRC train: 0.969680	val: 0.776976	test: 0.783205

Epoch: 79
Loss: 0.2726588207964179
ROC train: 0.977156	val: 0.822646	test: 0.844253
PRC train: 0.972507	val: 0.783806	test: 0.782456

Epoch: 80
Loss: 0.2441434045680262
ROC train: 0.979728	val: 0.819750	test: 0.838373
PRC train: 0.975486	val: 0.779599	test: 0.778280

Epoch: 81
Loss: 0.25037804757712584
ROC train: 0.980497	val: 0.816546	test: 0.837843
PRC train: 0.976247	val: 0.779645	test: 0.778177

Epoch: 82
Loss: 0.2587330591398131
ROC train: 0.979562	val: 0.820364	test: 0.840716
PRC train: 0.975020	val: 0.786117	test: 0.780377

Epoch: 83
Loss: 0.234436568093608
ROC train: 0.981389	val: 0.826026	test: 0.834748
PRC train: 0.977337	val: 0.791404	test: 0.774804

Epoch: 84
Loss: 0.25827784295474504
ROC train: 0.980777	val: 0.822603	test: 0.831079
PRC train: 0.976121	val: 0.790435	test: 0.768794

Epoch: 85
Loss: 0.2432537016622498
ROC train: 0.980889	val: 0.824226	test: 0.830327
PRC train: 0.976606	val: 0.799656	test: 0.766857

Epoch: 86
Loss: 0.2612323885350689
ROC train: 0.979241	val: 0.824841	test: 0.833466
PRC train: 0.974608	val: 0.804657	test: 0.769084

Epoch: 87
Loss: 0.23344209757874268
ROC train: 0.980865	val: 0.821418	test: 0.835190
PRC train: 0.976432	val: 0.788474	test: 0.767026

Epoch: 88
Loss: 0.24684259160264793
ROC train: 0.982482	val: 0.819618	test: 0.835986
PRC train: 0.978785	val: 0.783075	test: 0.766011

Epoch: 89
Loss: 0.24348938199996772
ROC train: 0.983574	val: 0.819443	test: 0.832493
PRC train: 0.980152	val: 0.779017	test: 0.759431

Epoch: 90
Loss: 0.24814772615418204
ROC train: 0.983667	val: 0.817204	test: 0.830018
PRC train: 0.980257	val: 0.778173	test: 0.757294

Epoch: 91
Loss: 0.24442816864600286
ROC train: 0.983971	val: 0.817994	test: 0.834748
PRC train: 0.980723	val: 0.768835	test: 0.761066

Epoch: 92
Loss: 0.2431545440226734
ROC train: 0.983800	val: 0.822910	test: 0.839390
PRC train: 0.980458	val: 0.772681	test: 0.768015

Epoch: 93
Loss: 0.22114746808750976
ROC train: 0.983300	val: 0.823919	test: 0.839125
PRC train: 0.979450	val: 0.775380	test: 0.774157

Epoch: 94
Loss: 0.24262174837392764
ROC train: 0.983354	val: 0.819267	test: 0.835544
PRC train: 0.929920	val: 0.794144	test: 0.756409

Epoch: 34
Loss: 0.3463227917754584
ROC train: 0.946294	val: 0.819487	test: 0.828117
PRC train: 0.932667	val: 0.788794	test: 0.759167

Epoch: 35
Loss: 0.36719713563523365
ROC train: 0.946919	val: 0.817336	test: 0.831830
PRC train: 0.933563	val: 0.775950	test: 0.765406

Epoch: 36
Loss: 0.3551222615997449
ROC train: 0.950601	val: 0.821286	test: 0.834085
PRC train: 0.938850	val: 0.789802	test: 0.768256

Epoch: 37
Loss: 0.3591459699120674
ROC train: 0.950135	val: 0.826684	test: 0.830769
PRC train: 0.938500	val: 0.807339	test: 0.761683

Epoch: 38
Loss: 0.32905979425056076
ROC train: 0.952154	val: 0.827650	test: 0.830327
PRC train: 0.940269	val: 0.807492	test: 0.757126

Epoch: 39
Loss: 0.35148333000851334
ROC train: 0.954295	val: 0.827562	test: 0.832582
PRC train: 0.943270	val: 0.802872	test: 0.760590

Epoch: 40
Loss: 0.3535145076751371
ROC train: 0.953535	val: 0.829318	test: 0.830813
PRC train: 0.943146	val: 0.803592	test: 0.760210

Epoch: 41
Loss: 0.347126937267994
ROC train: 0.953668	val: 0.828791	test: 0.835455
PRC train: 0.943647	val: 0.802894	test: 0.764236

Epoch: 42
Loss: 0.3193824286023701
ROC train: 0.953521	val: 0.833662	test: 0.830018
PRC train: 0.943124	val: 0.802016	test: 0.757751

Epoch: 43
Loss: 0.3231022760226749
ROC train: 0.954094	val: 0.832521	test: 0.828382
PRC train: 0.943450	val: 0.798014	test: 0.754920

Epoch: 44
Loss: 0.32508188680023953
ROC train: 0.955583	val: 0.826728	test: 0.828780
PRC train: 0.944914	val: 0.789975	test: 0.755703

Epoch: 45
Loss: 0.3280906198976567
ROC train: 0.957847	val: 0.824973	test: 0.834483
PRC train: 0.947796	val: 0.793316	test: 0.764242

Epoch: 46
Loss: 0.3128605024114488
ROC train: 0.955755	val: 0.825455	test: 0.834041
PRC train: 0.945612	val: 0.790271	test: 0.766665

Epoch: 47
Loss: 0.3212543594397575
ROC train: 0.961414	val: 0.828133	test: 0.830062
PRC train: 0.953017	val: 0.794087	test: 0.761992

Epoch: 48
Loss: 0.32214430227643476
ROC train: 0.961497	val: 0.829800	test: 0.825685
PRC train: 0.952972	val: 0.796911	test: 0.761966

Epoch: 49
Loss: 0.31292046017848024
ROC train: 0.961899	val: 0.828440	test: 0.835765
PRC train: 0.953810	val: 0.794698	test: 0.766776

Epoch: 50
Loss: 0.3144892728515958
ROC train: 0.963800	val: 0.825894	test: 0.838417
PRC train: 0.955113	val: 0.794625	test: 0.771970

Epoch: 51
Loss: 0.3138565590057346
ROC train: 0.962519	val: 0.825850	test: 0.833156
PRC train: 0.954177	val: 0.804143	test: 0.765734

Epoch: 52
Loss: 0.3057537621644091
ROC train: 0.962066	val: 0.826860	test: 0.834571
PRC train: 0.952611	val: 0.803062	test: 0.764843

Epoch: 53
Loss: 0.2940183991243308
ROC train: 0.963090	val: 0.827474	test: 0.836737
PRC train: 0.954007	val: 0.800010	test: 0.766517

Epoch: 54
Loss: 0.31223358729866746
ROC train: 0.964496	val: 0.829756	test: 0.836163
PRC train: 0.955310	val: 0.801385	test: 0.767828

Epoch: 55
Loss: 0.31232772245225915
ROC train: 0.966941	val: 0.833092	test: 0.836118
PRC train: 0.959221	val: 0.801154	test: 0.764489

Epoch: 56
Loss: 0.29786065708654214
ROC train: 0.968557	val: 0.831117	test: 0.840053
PRC train: 0.961099	val: 0.798287	test: 0.764716

Epoch: 57
Loss: 0.31480895988847146
ROC train: 0.969912	val: 0.828747	test: 0.841645
PRC train: 0.962259	val: 0.791145	test: 0.769415

Epoch: 58
Loss: 0.2850467338572511
ROC train: 0.968508	val: 0.824753	test: 0.837268
PRC train: 0.961407	val: 0.785180	test: 0.762711

Epoch: 59
Loss: 0.28731578682951775
ROC train: 0.965970	val: 0.811982	test: 0.834615
PRC train: 0.958585	val: 0.766413	test: 0.766052

Epoch: 60
Loss: 0.3133886390700475
ROC train: 0.969322	val: 0.819311	test: 0.833775
PRC train: 0.962108	val: 0.784542	test: 0.763593

Epoch: 61
Loss: 0.2861726013065346
ROC train: 0.968780	val: 0.833531	test: 0.837135
PRC train: 0.960832	val: 0.819749	test: 0.772630

Epoch: 62
Loss: 0.27169215796238183
ROC train: 0.970468	val: 0.826070	test: 0.840716
PRC train: 0.963046	val: 0.801779	test: 0.775447

Epoch: 63
Loss: 0.27983286458609186
ROC train: 0.969714	val: 0.821856	test: 0.836958
PRC train: 0.962388	val: 0.783186	test: 0.773084

Epoch: 64
Loss: 0.2602721098411347
ROC train: 0.971458	val: 0.825280	test: 0.840318
PRC train: 0.964353	val: 0.786938	test: 0.776950

Epoch: 65
Loss: 0.26239191293714703
ROC train: 0.971801	val: 0.827430	test: 0.843148
PRC train: 0.964866	val: 0.793274	test: 0.780557

Epoch: 66
Loss: 0.2870804571131519
ROC train: 0.972389	val: 0.826596	test: 0.840760
PRC train: 0.964906	val: 0.791148	test: 0.777305

Epoch: 67
Loss: 0.28509817561164663
ROC train: 0.972541	val: 0.821330	test: 0.835234
PRC train: 0.964802	val: 0.789351	test: 0.766052

Epoch: 68
Loss: 0.2639769587163974
ROC train: 0.975740	val: 0.823173	test: 0.837179
PRC train: 0.969718	val: 0.797722	test: 0.763535

Epoch: 69
Loss: 0.26223417331036153
ROC train: 0.975723	val: 0.827738	test: 0.842042
PRC train: 0.969667	val: 0.798612	test: 0.772712

Epoch: 70
Loss: 0.28813480677321607
ROC train: 0.975701	val: 0.829669	test: 0.848011
PRC train: 0.969979	val: 0.801132	test: 0.775829

Epoch: 71
Loss: 0.2929454949127817
ROC train: 0.973589	val: 0.830503	test: 0.842175
PRC train: 0.967291	val: 0.795147	test: 0.768471

Epoch: 72
Loss: 0.26242788431831465
ROC train: 0.973300	val: 0.827606	test: 0.834792
PRC train: 0.967383	val: 0.791299	test: 0.762785

Epoch: 73
Loss: 0.25310426159541494
ROC train: 0.973481	val: 0.822251	test: 0.835411
PRC train: 0.965486	val: 0.785016	test: 0.765318

Epoch: 74
Loss: 0.2622513157786702
ROC train: 0.975794	val: 0.820891	test: 0.836472
PRC train: 0.969674	val: 0.785051	test: 0.764632

Epoch: 75
Loss: 0.25778061622689935
ROC train: 0.977901	val: 0.830985	test: 0.841689
PRC train: 0.972862	val: 0.797774	test: 0.766866

Epoch: 76
Loss: 0.2543004892098815
ROC train: 0.977362	val: 0.829976	test: 0.843943
PRC train: 0.972107	val: 0.790958	test: 0.773385

Epoch: 77
Loss: 0.2588462384774781
ROC train: 0.977034	val: 0.829405	test: 0.840230
PRC train: 0.971612	val: 0.793082	test: 0.771871

Epoch: 78
Loss: 0.24541277022408514
ROC train: 0.980130	val: 0.828615	test: 0.844209
PRC train: 0.975343	val: 0.797630	test: 0.777658

Epoch: 79
Loss: 0.24984633146855992
ROC train: 0.981379	val: 0.829318	test: 0.842750
PRC train: 0.977018	val: 0.804956	test: 0.775758

Epoch: 80
Loss: 0.25565452671583744
ROC train: 0.980478	val: 0.828484	test: 0.842175
PRC train: 0.975921	val: 0.795080	test: 0.774102

Epoch: 81
Loss: 0.2349721075773333
ROC train: 0.982237	val: 0.830108	test: 0.844430
PRC train: 0.978075	val: 0.794303	test: 0.783841

Epoch: 82
Loss: 0.23024778285433636
ROC train: 0.981428	val: 0.827255	test: 0.845756
PRC train: 0.976682	val: 0.792801	test: 0.791944

Epoch: 83
Loss: 0.24012018358941462
ROC train: 0.982898	val: 0.832214	test: 0.845447
PRC train: 0.978966	val: 0.800082	test: 0.783910

Epoch: 84
Loss: 0.22244603592694406
ROC train: 0.982462	val: 0.831995	test: 0.844209
PRC train: 0.979086	val: 0.801534	test: 0.780878

Epoch: 85
Loss: 0.24489939690035734
ROC train: 0.982428	val: 0.836515	test: 0.839920
PRC train: 0.978940	val: 0.812209	test: 0.775866

Epoch: 86
Loss: 0.24753595239987242
ROC train: 0.982051	val: 0.836603	test: 0.833112
PRC train: 0.977420	val: 0.812643	test: 0.771602

Epoch: 87
Loss: 0.251567652815602
ROC train: 0.981017	val: 0.826904	test: 0.834129
PRC train: 0.976313	val: 0.792534	test: 0.779911

Epoch: 88
Loss: 0.2512280215431148
ROC train: 0.981323	val: 0.819267	test: 0.837489
PRC train: 0.977349	val: 0.781971	test: 0.783043

Epoch: 89
Loss: 0.23381511239534863
ROC train: 0.985353	val: 0.829449	test: 0.838992
PRC train: 0.982445	val: 0.800458	test: 0.784419

Epoch: 90
Loss: 0.22621504961407204
ROC train: 0.986308	val: 0.830020	test: 0.845049
PRC train: 0.983350	val: 0.797696	test: 0.786928

Epoch: 91
Loss: 0.23424812236716813
ROC train: 0.986578	val: 0.828045	test: 0.846817
PRC train: 0.983479	val: 0.794652	test: 0.788891

Epoch: 92
Loss: 0.22255342517837048
ROC train: 0.983859	val: 0.821856	test: 0.835146
PRC train: 0.980775	val: 0.778492	test: 0.774370

Epoch: 93
Loss: 0.2426900316245625
ROC train: 0.983077	val: 0.826158	test: 0.829443
PRC train: 0.979705	val: 0.786333	test: 0.771158

Epoch: 94
Loss: 0.22547537592853528
ROC train: 0.985583	val: 0.828001	test: 0.838904
PRC train: 0.934830	val: 0.791490	test: 0.750359

Epoch: 34
Loss: 0.348574347857323
ROC train: 0.951047	val: 0.818433	test: 0.831344
PRC train: 0.936906	val: 0.794598	test: 0.750948

Epoch: 35
Loss: 0.33385944908649207
ROC train: 0.950265	val: 0.819179	test: 0.830990
PRC train: 0.936481	val: 0.796493	test: 0.758623

Epoch: 36
Loss: 0.32857210668003484
ROC train: 0.948758	val: 0.817643	test: 0.832361
PRC train: 0.935420	val: 0.787811	test: 0.767491

Epoch: 37
Loss: 0.3514709268131676
ROC train: 0.948817	val: 0.817819	test: 0.831079
PRC train: 0.936007	val: 0.792229	test: 0.763471

Epoch: 38
Loss: 0.33915003693822154
ROC train: 0.946208	val: 0.808119	test: 0.823386
PRC train: 0.934669	val: 0.783372	test: 0.752369

Epoch: 39
Loss: 0.3311138783864651
ROC train: 0.955108	val: 0.806276	test: 0.822546
PRC train: 0.945463	val: 0.780130	test: 0.757667

Epoch: 40
Loss: 0.33127907094799103
ROC train: 0.956823	val: 0.810358	test: 0.822325
PRC train: 0.947064	val: 0.791041	test: 0.751217

Epoch: 41
Loss: 0.3218990690921373
ROC train: 0.956916	val: 0.814878	test: 0.827188
PRC train: 0.946599	val: 0.801024	test: 0.758915

Epoch: 42
Loss: 0.33170800598094374
ROC train: 0.957470	val: 0.819574	test: 0.831300
PRC train: 0.946799	val: 0.804595	test: 0.762811

Epoch: 43
Loss: 0.3004208741262484
ROC train: 0.957396	val: 0.815537	test: 0.833156
PRC train: 0.948846	val: 0.793307	test: 0.768300

Epoch: 44
Loss: 0.32146965789407433
ROC train: 0.959376	val: 0.813605	test: 0.836782
PRC train: 0.951048	val: 0.786868	test: 0.773798

Epoch: 45
Loss: 0.3255739183724255
ROC train: 0.960767	val: 0.813518	test: 0.836516
PRC train: 0.952540	val: 0.785646	test: 0.774778

Epoch: 46
Loss: 0.3193972298618324
ROC train: 0.961228	val: 0.811367	test: 0.837754
PRC train: 0.952297	val: 0.780385	test: 0.774771

Epoch: 47
Loss: 0.32086664323386366
ROC train: 0.961487	val: 0.805135	test: 0.835986
PRC train: 0.952053	val: 0.771172	test: 0.769485

Epoch: 48
Loss: 0.31648204024141197
ROC train: 0.962271	val: 0.809129	test: 0.833112
PRC train: 0.952400	val: 0.778447	test: 0.766410

Epoch: 49
Loss: 0.3271289508805027
ROC train: 0.963320	val: 0.818697	test: 0.834173
PRC train: 0.953231	val: 0.795678	test: 0.770315

Epoch: 50
Loss: 0.3175478855983761
ROC train: 0.963849	val: 0.819838	test: 0.832847
PRC train: 0.954272	val: 0.796495	test: 0.775289

Epoch: 51
Loss: 0.3077466102665207
ROC train: 0.962195	val: 0.813123	test: 0.832007
PRC train: 0.952979	val: 0.779749	test: 0.768649

Epoch: 52
Loss: 0.29073573112316103
ROC train: 0.964848	val: 0.814044	test: 0.837710
PRC train: 0.956855	val: 0.777106	test: 0.768413

Epoch: 53
Loss: 0.28536240375352
ROC train: 0.965515	val: 0.818345	test: 0.840274
PRC train: 0.957618	val: 0.794630	test: 0.767073

Epoch: 54
Loss: 0.29239182779018985
ROC train: 0.965387	val: 0.818828	test: 0.836251
PRC train: 0.957725	val: 0.793859	test: 0.761052

Epoch: 55
Loss: 0.294741242067317
ROC train: 0.963910	val: 0.816590	test: 0.835190
PRC train: 0.955215	val: 0.779715	test: 0.759372

Epoch: 56
Loss: 0.2858473480566256
ROC train: 0.965921	val: 0.812420	test: 0.831565
PRC train: 0.958824	val: 0.776453	test: 0.759585

Epoch: 57
Loss: 0.29073483043647264
ROC train: 0.968528	val: 0.810007	test: 0.826525
PRC train: 0.963085	val: 0.776581	test: 0.752766

Epoch: 58
Loss: 0.2786298845000388
ROC train: 0.971644	val: 0.818565	test: 0.829841
PRC train: 0.966352	val: 0.793805	test: 0.759149

Epoch: 59
Loss: 0.2782244875687421
ROC train: 0.971850	val: 0.821242	test: 0.836782
PRC train: 0.965439	val: 0.788024	test: 0.767932

Epoch: 60
Loss: 0.2564478780975086
ROC train: 0.972489	val: 0.819487	test: 0.839965
PRC train: 0.966637	val: 0.794318	test: 0.778188

Epoch: 61
Loss: 0.2836859117421798
ROC train: 0.974118	val: 0.820628	test: 0.840849
PRC train: 0.968797	val: 0.812729	test: 0.781263

Epoch: 62
Loss: 0.27168309133240776
ROC train: 0.973472	val: 0.820759	test: 0.835279
PRC train: 0.968220	val: 0.810409	test: 0.775262

Epoch: 63
Loss: 0.281755284527831
ROC train: 0.975245	val: 0.815975	test: 0.830946
PRC train: 0.970516	val: 0.793896	test: 0.774482

Epoch: 64
Loss: 0.2803069869556481
ROC train: 0.976044	val: 0.819004	test: 0.832891
PRC train: 0.971771	val: 0.802662	test: 0.774594

Epoch: 65
Loss: 0.25523591216659747
ROC train: 0.976884	val: 0.810489	test: 0.830769
PRC train: 0.972926	val: 0.788464	test: 0.766834

Epoch: 66
Loss: 0.27170351582994745
ROC train: 0.978035	val: 0.813825	test: 0.830902
PRC train: 0.973944	val: 0.794287	test: 0.764473

Epoch: 67
Loss: 0.28023971023464267
ROC train: 0.976869	val: 0.814220	test: 0.829576
PRC train: 0.972147	val: 0.799012	test: 0.765112

Epoch: 68
Loss: 0.275102699327462
ROC train: 0.974983	val: 0.811806	test: 0.829487
PRC train: 0.969737	val: 0.787981	test: 0.768390

Epoch: 69
Loss: 0.2931969945941808
ROC train: 0.974305	val: 0.808822	test: 0.829885
PRC train: 0.969323	val: 0.774416	test: 0.770488

Epoch: 70
Loss: 0.24572956356520642
ROC train: 0.977440	val: 0.816722	test: 0.829178
PRC train: 0.973574	val: 0.789281	test: 0.770694

Epoch: 71
Loss: 0.27542986443633505
ROC train: 0.976759	val: 0.814703	test: 0.828559
PRC train: 0.972895	val: 0.793457	test: 0.766335

Epoch: 72
Loss: 0.24741146475246747
ROC train: 0.977817	val: 0.819618	test: 0.829443
PRC train: 0.973617	val: 0.804121	test: 0.764422

Epoch: 73
Loss: 0.2776737569577649
ROC train: 0.975740	val: 0.817994	test: 0.832891
PRC train: 0.970511	val: 0.798681	test: 0.765828

Epoch: 74
Loss: 0.2612829219984674
ROC train: 0.973349	val: 0.817029	test: 0.833687
PRC train: 0.967539	val: 0.806295	test: 0.762725

Epoch: 75
Loss: 0.248472891421345
ROC train: 0.976798	val: 0.818960	test: 0.831300
PRC train: 0.971693	val: 0.804451	test: 0.771451

Epoch: 76
Loss: 0.24975450293994012
ROC train: 0.980434	val: 0.823568	test: 0.831477
PRC train: 0.976472	val: 0.804375	test: 0.773288

Epoch: 77
Loss: 0.24791342766600732
ROC train: 0.981350	val: 0.822998	test: 0.831256
PRC train: 0.978103	val: 0.801796	test: 0.765976

Epoch: 78
Loss: 0.23135576837593352
ROC train: 0.982521	val: 0.820233	test: 0.834792
PRC train: 0.979463	val: 0.792356	test: 0.765891

Epoch: 79
Loss: 0.24867963232914492
ROC train: 0.979961	val: 0.818345	test: 0.833775
PRC train: 0.976329	val: 0.787836	test: 0.763937

Epoch: 80
Loss: 0.2501855971490033
ROC train: 0.980324	val: 0.827518	test: 0.827056
PRC train: 0.976738	val: 0.804890	test: 0.754852

Epoch: 81
Loss: 0.2678006646900196
ROC train: 0.981796	val: 0.818433	test: 0.823961
PRC train: 0.978899	val: 0.788187	test: 0.755914

Epoch: 82
Loss: 0.24264703459964923
ROC train: 0.983545	val: 0.812113	test: 0.830681
PRC train: 0.980768	val: 0.789542	test: 0.770608

Epoch: 83
Loss: 0.22537978487717955
ROC train: 0.984079	val: 0.815537	test: 0.835146
PRC train: 0.981110	val: 0.796868	test: 0.776038

Epoch: 84
Loss: 0.23535881662613142
ROC train: 0.984530	val: 0.813386	test: 0.836295
PRC train: 0.981530	val: 0.782067	test: 0.779138

Epoch: 85
Loss: 0.23215968314639351
ROC train: 0.985500	val: 0.820628	test: 0.841424
PRC train: 0.982742	val: 0.781706	test: 0.785016

Epoch: 86
Loss: 0.24758536466362563
ROC train: 0.985532	val: 0.825499	test: 0.841600
PRC train: 0.982719	val: 0.797424	test: 0.786274

Epoch: 87
Loss: 0.23679137207492004
ROC train: 0.984794	val: 0.830985	test: 0.838019
PRC train: 0.982346	val: 0.806341	test: 0.777166

Epoch: 88
Loss: 0.255751820500667
ROC train: 0.983325	val: 0.824753	test: 0.826746
PRC train: 0.980579	val: 0.791589	test: 0.761970

Epoch: 89
Loss: 0.22902482675489083
ROC train: 0.980620	val: 0.828176	test: 0.824757
PRC train: 0.977145	val: 0.800381	test: 0.757457

Epoch: 90
Loss: 0.2343998341096691
ROC train: 0.982643	val: 0.826991	test: 0.829708
PRC train: 0.979710	val: 0.808116	test: 0.761491

Epoch: 91
Loss: 0.22922137582913626
ROC train: 0.984349	val: 0.813913	test: 0.835013
PRC train: 0.981494	val: 0.795762	test: 0.775414

Epoch: 92
Loss: 0.22782819858682343
ROC train: 0.982859	val: 0.807154	test: 0.835190
PRC train: 0.979589	val: 0.787108	test: 0.775508

Epoch: 93
Loss: 0.24241128164098508
ROC train: 0.984153	val: 0.812377	test: 0.840628
PRC train: 0.980589	val: 0.784583	test: 0.779041

Epoch: 94
Loss: 0.2439756389554537
ROC train: 0.983922	val: 0.812728	test: 0.839788ROC train: 0.914183	val: 0.791185	test: 0.878148
PRC train: 0.889776	val: 0.765791	test: 0.807730

Epoch: 34
Loss: 0.3713343261504149
ROC train: 0.917801	val: 0.793152	test: 0.881422
PRC train: 0.893826	val: 0.767131	test: 0.804727

Epoch: 35
Loss: 0.4050077814590334
ROC train: 0.923799	val: 0.806612	test: 0.880564
PRC train: 0.903520	val: 0.777810	test: 0.800753

Epoch: 36
Loss: 0.37005444486633504
ROC train: 0.927363	val: 0.808658	test: 0.870040
PRC train: 0.908044	val: 0.779458	test: 0.788181

Epoch: 37
Loss: 0.39070701942475683
ROC train: 0.927393	val: 0.800945	test: 0.867311
PRC train: 0.907340	val: 0.774614	test: 0.784439

Epoch: 38
Loss: 0.40479524661604227
ROC train: 0.926537	val: 0.803148	test: 0.876666
PRC train: 0.905875	val: 0.770990	test: 0.801283

Epoch: 39
Loss: 0.4214414279074372
ROC train: 0.925640	val: 0.807399	test: 0.881968
PRC train: 0.907164	val: 0.776412	test: 0.804802

Epoch: 40
Loss: 0.37724033478919056
ROC train: 0.927851	val: 0.813223	test: 0.876043
PRC train: 0.911179	val: 0.789119	test: 0.806040

Epoch: 41
Loss: 0.3989450350837557
ROC train: 0.932672	val: 0.817395	test: 0.874717
PRC train: 0.916216	val: 0.794263	test: 0.810413

Epoch: 42
Loss: 0.37725417623033664
ROC train: 0.937537	val: 0.816135	test: 0.873236
PRC train: 0.920156	val: 0.793478	test: 0.808345

Epoch: 43
Loss: 0.3796940539172658
ROC train: 0.938719	val: 0.820386	test: 0.889218
PRC train: 0.922880	val: 0.799944	test: 0.829239

Epoch: 44
Loss: 0.3830983806597232
ROC train: 0.931312	val: 0.817867	test: 0.897404
PRC train: 0.915295	val: 0.793939	test: 0.847305

Epoch: 45
Loss: 0.36489099046400975
ROC train: 0.933487	val: 0.806061	test: 0.893506
PRC train: 0.918721	val: 0.777904	test: 0.838631

Epoch: 46
Loss: 0.35643548889514953
ROC train: 0.933229	val: 0.799685	test: 0.880331
PRC train: 0.917142	val: 0.765205	test: 0.820809

Epoch: 47
Loss: 0.38982762680136995
ROC train: 0.933778	val: 0.801338	test: 0.881110
PRC train: 0.916776	val: 0.767141	test: 0.826159

Epoch: 48
Loss: 0.39000749347603103
ROC train: 0.933286	val: 0.810704	test: 0.881188
PRC train: 0.915265	val: 0.789087	test: 0.825489

Epoch: 49
Loss: 0.33842597171803257
ROC train: 0.935980	val: 0.808186	test: 0.878070
PRC train: 0.921507	val: 0.787314	test: 0.818664

Epoch: 50
Loss: 0.34640729901061595
ROC train: 0.938854	val: 0.812593	test: 0.877758
PRC train: 0.924850	val: 0.788598	test: 0.815765

Epoch: 51
Loss: 0.38936262359298873
ROC train: 0.940952	val: 0.820779	test: 0.876355
PRC train: 0.928111	val: 0.794716	test: 0.809732

Epoch: 52
Loss: 0.37737294699010715
ROC train: 0.941176	val: 0.825895	test: 0.877992
PRC train: 0.925948	val: 0.802578	test: 0.811903

Epoch: 53
Loss: 0.3756268680422264
ROC train: 0.944941	val: 0.819441	test: 0.876588
PRC train: 0.930490	val: 0.799606	test: 0.817185

Epoch: 54
Loss: 0.3301173430606462
ROC train: 0.939698	val: 0.810468	test: 0.877056
PRC train: 0.925233	val: 0.797948	test: 0.825412

Epoch: 55
Loss: 0.3656612591860399
ROC train: 0.940661	val: 0.812515	test: 0.875887
PRC train: 0.926840	val: 0.798409	test: 0.810583

Epoch: 56
Loss: 0.335511101355757
ROC train: 0.943125	val: 0.820307	test: 0.878304
PRC train: 0.927737	val: 0.796758	test: 0.813517

Epoch: 57
Loss: 0.3122845856430193
ROC train: 0.941530	val: 0.814876	test: 0.875497
PRC train: 0.925322	val: 0.790560	test: 0.803374

Epoch: 58
Loss: 0.3182624014572393
ROC train: 0.942719	val: 0.811885	test: 0.883371
PRC train: 0.928170	val: 0.793462	test: 0.811384

Epoch: 59
Loss: 0.36046110192666153
ROC train: 0.944454	val: 0.810311	test: 0.886178
PRC train: 0.931882	val: 0.787045	test: 0.815312

Epoch: 60
Loss: 0.31821598059634465
ROC train: 0.947897	val: 0.804801	test: 0.880876
PRC train: 0.934976	val: 0.779231	test: 0.804640

Epoch: 61
Loss: 0.3529812373561764
ROC train: 0.943107	val: 0.792837	test: 0.874172
PRC train: 0.929141	val: 0.761562	test: 0.805819

Epoch: 62
Loss: 0.35998540432266896
ROC train: 0.942051	val: 0.792680	test: 0.867077
PRC train: 0.928990	val: 0.763691	test: 0.794070

Epoch: 63
Loss: 0.3344432142064695
ROC train: 0.944256	val: 0.800157	test: 0.872067
PRC train: 0.932941	val: 0.778098	test: 0.793851

Epoch: 64
Loss: 0.35815920743112356
ROC train: 0.947600	val: 0.803148	test: 0.880720
PRC train: 0.936945	val: 0.787343	test: 0.816681

Epoch: 65
Loss: 0.3675091834262594
ROC train: 0.945316	val: 0.792680	test: 0.879707
PRC train: 0.933340	val: 0.762522	test: 0.820989

Epoch: 66
Loss: 0.3889174667698316
ROC train: 0.949582	val: 0.806848	test: 0.866064
PRC train: 0.937441	val: 0.788487	test: 0.795225

Epoch: 67
Loss: 0.36899216878184565
ROC train: 0.945255	val: 0.806533	test: 0.868870
PRC train: 0.931132	val: 0.792061	test: 0.791315

Epoch: 68
Loss: 0.34954808605313215
ROC train: 0.941436	val: 0.802912	test: 0.875965
PRC train: 0.926999	val: 0.787736	test: 0.801087

Epoch: 69
Loss: 0.3729630081197803
ROC train: 0.945025	val: 0.805588	test: 0.888127
PRC train: 0.932055	val: 0.790723	test: 0.828918

Epoch: 70
Loss: 0.3611143522208976
ROC train: 0.951548	val: 0.814089	test: 0.892025
PRC train: 0.940763	val: 0.790286	test: 0.838233

Epoch: 71
Loss: 0.3228993583873411
ROC train: 0.950927	val: 0.810075	test: 0.885476
PRC train: 0.940048	val: 0.782641	test: 0.824039

Epoch: 72
Loss: 0.37188401972341395
ROC train: 0.948899	val: 0.806061	test: 0.879629
PRC train: 0.937414	val: 0.780527	test: 0.814310

Epoch: 73
Loss: 0.33034256783127247
ROC train: 0.949045	val: 0.808264	test: 0.874639
PRC train: 0.937893	val: 0.785904	test: 0.805715

Epoch: 74
Loss: 0.3565746618974977
ROC train: 0.953104	val: 0.814955	test: 0.869650
PRC train: 0.941598	val: 0.791578	test: 0.803340

Epoch: 75
Loss: 0.33356444672997326
ROC train: 0.955848	val: 0.814089	test: 0.862867
PRC train: 0.943859	val: 0.791877	test: 0.796802

Epoch: 76
Loss: 0.3241354984372355
ROC train: 0.956340	val: 0.819441	test: 0.866220
PRC train: 0.945271	val: 0.795038	test: 0.809635

Epoch: 77
Loss: 0.31468750460641215
ROC train: 0.956660	val: 0.819441	test: 0.884852
PRC train: 0.947809	val: 0.797965	test: 0.830171

Epoch: 78
Loss: 0.35561226478251606
ROC train: 0.954510	val: 0.815033	test: 0.886723
PRC train: 0.945618	val: 0.795810	test: 0.834827

Epoch: 79
Loss: 0.3185634734785419
ROC train: 0.956362	val: 0.812279	test: 0.874328
PRC train: 0.947580	val: 0.795604	test: 0.824250

Epoch: 80
Loss: 0.3325603475149284
ROC train: 0.959796	val: 0.821251	test: 0.873002
PRC train: 0.951223	val: 0.801739	test: 0.826836

Epoch: 81
Loss: 0.303928839810243
ROC train: 0.956112	val: 0.818969	test: 0.864505
PRC train: 0.946625	val: 0.792504	test: 0.817833

Epoch: 82
Loss: 0.29116068468942763
ROC train: 0.953782	val: 0.814482	test: 0.863959
PRC train: 0.944003	val: 0.786500	test: 0.816203

Epoch: 83
Loss: 0.348863576982086
ROC train: 0.957762	val: 0.808422	test: 0.879083
PRC train: 0.949197	val: 0.782100	test: 0.831231

Epoch: 84
Loss: 0.31807156439800993
ROC train: 0.956985	val: 0.805274	test: 0.884540
PRC train: 0.947941	val: 0.784035	test: 0.836995

Epoch: 85
Loss: 0.376559255536183
ROC train: 0.959106	val: 0.805746	test: 0.880954
PRC train: 0.949901	val: 0.784205	test: 0.828500

Epoch: 86
Loss: 0.30021799036513125
ROC train: 0.959841	val: 0.807320	test: 0.884073
PRC train: 0.951594	val: 0.779079	test: 0.831729

Epoch: 87
Loss: 0.3208584955418206
ROC train: 0.960166	val: 0.807556	test: 0.878226
PRC train: 0.951673	val: 0.773391	test: 0.825746

Epoch: 88
Loss: 0.3264602079954691
ROC train: 0.961297	val: 0.818654	test: 0.865362
PRC train: 0.950455	val: 0.796121	test: 0.804265

Epoch: 89
Loss: 0.30276714772691793
ROC train: 0.961545	val: 0.819835	test: 0.874561
PRC train: 0.952161	val: 0.799849	test: 0.812908

Epoch: 90
Loss: 0.3181159506166736
ROC train: 0.962127	val: 0.816293	test: 0.882669
PRC train: 0.953380	val: 0.787189	test: 0.825242

Epoch: 91
Loss: 0.2807831181442598
ROC train: 0.960532	val: 0.816214	test: 0.867389
PRC train: 0.952785	val: 0.790777	test: 0.805879

Epoch: 92
Loss: 0.3224700166845621
ROC train: 0.962355	val: 0.820858	test: 0.871287
PRC train: 0.953592	val: 0.798402	test: 0.812494

Epoch: 93
Loss: 0.30001835461476206
ROC train: 0.959612	val: 0.820464	test: 0.879083
PRC train: 0.950601	val: 0.794993	test: 0.821555

Epoch: 94
Loss: 0.3007954040390373
PRC train: 0.907255	val: 0.742388	test: 0.803067

Epoch: 34
Loss: 0.43345380592118554
ROC train: 0.924442	val: 0.789925	test: 0.877290
PRC train: 0.909203	val: 0.730406	test: 0.803651

Epoch: 35
Loss: 0.392907716398146
ROC train: 0.923702	val: 0.789610	test: 0.870430
PRC train: 0.907875	val: 0.727345	test: 0.795480

Epoch: 36
Loss: 0.4216468585863026
ROC train: 0.920545	val: 0.793625	test: 0.868870
PRC train: 0.902915	val: 0.737556	test: 0.798932

Epoch: 37
Loss: 0.38539568707999516
ROC train: 0.926993	val: 0.790161	test: 0.860918
PRC train: 0.910785	val: 0.751660	test: 0.786925

Epoch: 38
Loss: 0.39463709045479023
ROC train: 0.927478	val: 0.798426	test: 0.867077
PRC train: 0.909662	val: 0.750225	test: 0.795305

Epoch: 39
Loss: 0.3967482893714894
ROC train: 0.921648	val: 0.800079	test: 0.874094
PRC train: 0.901531	val: 0.741354	test: 0.813027

Epoch: 40
Loss: 0.39773720412216085
ROC train: 0.924363	val: 0.798190	test: 0.871989
PRC train: 0.907942	val: 0.742384	test: 0.807009

Epoch: 41
Loss: 0.3849701737872486
ROC train: 0.929484	val: 0.799134	test: 0.867701
PRC train: 0.914305	val: 0.758480	test: 0.791890

Epoch: 42
Loss: 0.37769276512903244
ROC train: 0.932618	val: 0.797166	test: 0.873470
PRC train: 0.916642	val: 0.761579	test: 0.803759

Epoch: 43
Loss: 0.3987240934470548
ROC train: 0.928979	val: 0.798977	test: 0.885554
PRC train: 0.910433	val: 0.756400	test: 0.825990

Epoch: 44
Loss: 0.34542803717275306
ROC train: 0.928941	val: 0.799685	test: 0.885164
PRC train: 0.907314	val: 0.766595	test: 0.825438

Epoch: 45
Loss: 0.37950919742269595
ROC train: 0.932467	val: 0.793231	test: 0.884852
PRC train: 0.913429	val: 0.762932	test: 0.822940

Epoch: 46
Loss: 0.40530126978551656
ROC train: 0.933088	val: 0.793152	test: 0.881578
PRC train: 0.916384	val: 0.757946	test: 0.820931

Epoch: 47
Loss: 0.35600232327140013
ROC train: 0.934423	val: 0.804172	test: 0.885164
PRC train: 0.917449	val: 0.767558	test: 0.828303

Epoch: 48
Loss: 0.35375271074514736
ROC train: 0.937855	val: 0.803384	test: 0.884307
PRC train: 0.921818	val: 0.769257	test: 0.823039

Epoch: 49
Loss: 0.37166388628365027
ROC train: 0.938753	val: 0.810311	test: 0.881188
PRC train: 0.924049	val: 0.779254	test: 0.820224

Epoch: 50
Loss: 0.3611959703674228
ROC train: 0.941918	val: 0.805982	test: 0.882046
PRC train: 0.927545	val: 0.769860	test: 0.816008

Epoch: 51
Loss: 0.3272789440104222
ROC train: 0.935366	val: 0.788115	test: 0.878615
PRC train: 0.919102	val: 0.741216	test: 0.817564

Epoch: 52
Loss: 0.33422960468393514
ROC train: 0.939843	val: 0.796537	test: 0.873704
PRC train: 0.925646	val: 0.761988	test: 0.804979

Epoch: 53
Loss: 0.34369251876308676
ROC train: 0.943074	val: 0.798426	test: 0.864583
PRC train: 0.930273	val: 0.762182	test: 0.793421

Epoch: 54
Loss: 0.36986537372437506
ROC train: 0.943938	val: 0.796930	test: 0.863725
PRC train: 0.930830	val: 0.763861	test: 0.793225

Epoch: 55
Loss: 0.3687384611026896
ROC train: 0.940441	val: 0.794176	test: 0.875965
PRC train: 0.926470	val: 0.751945	test: 0.805246

Epoch: 56
Loss: 0.37227805031239636
ROC train: 0.938918	val: 0.796458	test: 0.875731
PRC train: 0.924625	val: 0.752713	test: 0.802514

Epoch: 57
Loss: 0.340607404764008
ROC train: 0.945794	val: 0.806769	test: 0.872301
PRC train: 0.931466	val: 0.770344	test: 0.800073

Epoch: 58
Loss: 0.33403408624495073
ROC train: 0.945695	val: 0.805982	test: 0.867311
PRC train: 0.932749	val: 0.779831	test: 0.798117

Epoch: 59
Loss: 0.3908782050894083
ROC train: 0.945765	val: 0.808343	test: 0.870975
PRC train: 0.933578	val: 0.779107	test: 0.797920

Epoch: 60
Loss: 0.36460750477718
ROC train: 0.944580	val: 0.815191	test: 0.876744
PRC train: 0.932690	val: 0.781900	test: 0.809105

Epoch: 61
Loss: 0.4236640128762108
ROC train: 0.945206	val: 0.809996	test: 0.874094
PRC train: 0.934652	val: 0.778325	test: 0.804885

Epoch: 62
Loss: 0.32840350349179914
ROC train: 0.948509	val: 0.797166	test: 0.870196
PRC train: 0.937477	val: 0.759906	test: 0.804102

Epoch: 63
Loss: 0.3465350529679371
ROC train: 0.947636	val: 0.794805	test: 0.871443
PRC train: 0.935447	val: 0.755464	test: 0.808190

Epoch: 64
Loss: 0.36059859370195113
ROC train: 0.948895	val: 0.809366	test: 0.880175
PRC train: 0.938602	val: 0.772739	test: 0.813797

Epoch: 65
Loss: 0.33529144384045517
ROC train: 0.946401	val: 0.814561	test: 0.871053
PRC train: 0.935858	val: 0.775552	test: 0.793677

Epoch: 66
Loss: 0.35037862367014666
ROC train: 0.948549	val: 0.810704	test: 0.866142
PRC train: 0.937114	val: 0.771126	test: 0.794692

Epoch: 67
Loss: 0.33362332280928003
ROC train: 0.952105	val: 0.806375	test: 0.879317
PRC train: 0.941907	val: 0.772521	test: 0.829982

Epoch: 68
Loss: 0.3349059640296762
ROC train: 0.950453	val: 0.799134	test: 0.887269
PRC train: 0.939169	val: 0.766420	test: 0.835961

Epoch: 69
Loss: 0.3088438955213674
ROC train: 0.950648	val: 0.801102	test: 0.880019
PRC train: 0.940591	val: 0.777059	test: 0.813802

Epoch: 70
Loss: 0.3705960962228262
ROC train: 0.951473	val: 0.800315	test: 0.873314
PRC train: 0.941339	val: 0.776553	test: 0.804344

Epoch: 71
Loss: 0.3537328336413056
ROC train: 0.951160	val: 0.797954	test: 0.879161
PRC train: 0.939695	val: 0.761786	test: 0.817536

Epoch: 72
Loss: 0.3528969471528948
ROC train: 0.951376	val: 0.798190	test: 0.881968
PRC train: 0.937691	val: 0.752111	test: 0.823288

Epoch: 73
Loss: 0.3355382618587393
ROC train: 0.954501	val: 0.807556	test: 0.874951
PRC train: 0.943448	val: 0.769761	test: 0.800907

Epoch: 74
Loss: 0.33507843317873826
ROC train: 0.953459	val: 0.808343	test: 0.868481
PRC train: 0.944409	val: 0.771681	test: 0.790269

Epoch: 75
Loss: 0.30606539307996994
ROC train: 0.953152	val: 0.802440	test: 0.872067
PRC train: 0.943357	val: 0.771085	test: 0.799243

Epoch: 76
Loss: 0.38418851035560947
ROC train: 0.955636	val: 0.798347	test: 0.877836
PRC train: 0.946233	val: 0.770169	test: 0.804257

Epoch: 77
Loss: 0.3203493000958916
ROC train: 0.955701	val: 0.802834	test: 0.873860
PRC train: 0.945733	val: 0.777489	test: 0.815485

Epoch: 78
Loss: 0.3439512040421916
ROC train: 0.956019	val: 0.802912	test: 0.868169
PRC train: 0.946590	val: 0.774109	test: 0.806921

Epoch: 79
Loss: 0.30379795442352847
ROC train: 0.956814	val: 0.802125	test: 0.867155
PRC train: 0.947660	val: 0.774042	test: 0.798645

Epoch: 80
Loss: 0.3232405778031742
ROC train: 0.955864	val: 0.796852	test: 0.870741
PRC train: 0.946209	val: 0.762959	test: 0.793198

Epoch: 81
Loss: 0.2917887030484088
ROC train: 0.956204	val: 0.797954	test: 0.869806
PRC train: 0.946828	val: 0.764266	test: 0.796843

Epoch: 82
Loss: 0.3216046686338236
ROC train: 0.957367	val: 0.796773	test: 0.865050
PRC train: 0.949262	val: 0.762871	test: 0.785453

Epoch: 83
Loss: 0.2972212486663702
ROC train: 0.957727	val: 0.793861	test: 0.868325
PRC train: 0.949321	val: 0.755341	test: 0.792404

Epoch: 84
Loss: 0.351674803789706
ROC train: 0.958449	val: 0.796301	test: 0.874873
PRC train: 0.949375	val: 0.756432	test: 0.801390

Epoch: 85
Loss: 0.2961387433258547
ROC train: 0.959659	val: 0.802204	test: 0.882280
PRC train: 0.952165	val: 0.762181	test: 0.813712

Epoch: 86
Loss: 0.31395125324450934
ROC train: 0.961276	val: 0.807635	test: 0.881890
PRC train: 0.953736	val: 0.773109	test: 0.812880

Epoch: 87
Loss: 0.29854697132770763
ROC train: 0.961114	val: 0.806375	test: 0.872768
PRC train: 0.953077	val: 0.780720	test: 0.794077

Epoch: 88
Loss: 0.29010399756642086
ROC train: 0.960564	val: 0.804565	test: 0.875263
PRC train: 0.953330	val: 0.782770	test: 0.807742

Epoch: 89
Loss: 0.289502106903229
ROC train: 0.959544	val: 0.803935	test: 0.882358
PRC train: 0.952966	val: 0.780615	test: 0.812821

Epoch: 90
Loss: 0.27952599788318866
ROC train: 0.960943	val: 0.805824	test: 0.885788
PRC train: 0.953362	val: 0.782785	test: 0.820307

Epoch: 91
Loss: 0.33757345730699406
ROC train: 0.962655	val: 0.810232	test: 0.884618
PRC train: 0.954787	val: 0.785025	test: 0.816850

Epoch: 92
Loss: 0.3329143427394013
ROC train: 0.963075	val: 0.802991	test: 0.883527
PRC train: 0.954654	val: 0.773775	test: 0.817406

Epoch: 93
Loss: 0.34589074012293086
ROC train: 0.964343	val: 0.798347	test: 0.885476
PRC train: 0.955493	val: 0.768634	test: 0.818194

Epoch: 94
Loss: 0.29549626660298955
ROC train: 0.961276	val: 0.811964	test: 0.876822
PRC train: 0.913069	val: 0.759460	test: 0.804718

Epoch: 34
Loss: 0.36451789443331734
ROC train: 0.932823	val: 0.830192	test: 0.858718
PRC train: 0.916164	val: 0.749919	test: 0.795221

Epoch: 35
Loss: 0.38295996022454376
ROC train: 0.933216	val: 0.824755	test: 0.855742
PRC train: 0.917684	val: 0.741756	test: 0.792509

Epoch: 36
Loss: 0.37523658555209505
ROC train: 0.935053	val: 0.827474	test: 0.874650
PRC train: 0.920742	val: 0.758252	test: 0.821225

Epoch: 37
Loss: 0.3800763912228642
ROC train: 0.936001	val: 0.829830	test: 0.875700
PRC train: 0.920897	val: 0.755708	test: 0.816161

Epoch: 38
Loss: 0.38022304079394154
ROC train: 0.937992	val: 0.834179	test: 0.869048
PRC train: 0.922504	val: 0.754261	test: 0.809032

Epoch: 39
Loss: 0.35866353221519776
ROC train: 0.939110	val: 0.838528	test: 0.857318
PRC train: 0.924081	val: 0.755772	test: 0.798156

Epoch: 40
Loss: 0.3541558801714221
ROC train: 0.939354	val: 0.845053	test: 0.855742
PRC train: 0.923024	val: 0.763265	test: 0.802669

Epoch: 41
Loss: 0.36342742060970923
ROC train: 0.939730	val: 0.845596	test: 0.860994
PRC train: 0.923916	val: 0.764622	test: 0.809281

Epoch: 42
Loss: 0.35470144175466345
ROC train: 0.942537	val: 0.844690	test: 0.870273
PRC train: 0.928811	val: 0.767910	test: 0.821127

Epoch: 43
Loss: 0.3544175673213449
ROC train: 0.942153	val: 0.837804	test: 0.871849
PRC train: 0.930332	val: 0.765644	test: 0.817664

Epoch: 44
Loss: 0.35906562730887004
ROC train: 0.943503	val: 0.832729	test: 0.866947
PRC train: 0.931903	val: 0.763108	test: 0.813900

Epoch: 45
Loss: 0.33433579164742816
ROC train: 0.946932	val: 0.835085	test: 0.862745
PRC train: 0.935014	val: 0.764223	test: 0.805214

Epoch: 46
Loss: 0.33473072951172667
ROC train: 0.948550	val: 0.844146	test: 0.864846
PRC train: 0.936349	val: 0.773673	test: 0.807206

Epoch: 47
Loss: 0.34513239185407024
ROC train: 0.948028	val: 0.847408	test: 0.855392
PRC train: 0.936966	val: 0.771136	test: 0.794734

Epoch: 48
Loss: 0.3508278403803048
ROC train: 0.950744	val: 0.844871	test: 0.864671
PRC train: 0.939935	val: 0.777659	test: 0.805160

Epoch: 49
Loss: 0.35320554304646007
ROC train: 0.951458	val: 0.841609	test: 0.867472
PRC train: 0.940812	val: 0.773017	test: 0.810046

Epoch: 50
Loss: 0.312288616945721
ROC train: 0.950074	val: 0.846321	test: 0.874825
PRC train: 0.938418	val: 0.777021	test: 0.827855

Epoch: 51
Loss: 0.3327702933770552
ROC train: 0.949846	val: 0.840884	test: 0.874300
PRC train: 0.937367	val: 0.767593	test: 0.827152

Epoch: 52
Loss: 0.3395868422067329
ROC train: 0.954117	val: 0.838528	test: 0.867647
PRC train: 0.943559	val: 0.762748	test: 0.822883

Epoch: 53
Loss: 0.33770044076620404
ROC train: 0.954518	val: 0.842515	test: 0.859069
PRC train: 0.946408	val: 0.770086	test: 0.810053

Epoch: 54
Loss: 0.30343801328837067
ROC train: 0.955196	val: 0.840884	test: 0.858368
PRC train: 0.947297	val: 0.776792	test: 0.814814

Epoch: 55
Loss: 0.3284135551940883
ROC train: 0.956605	val: 0.831279	test: 0.860644
PRC train: 0.949512	val: 0.764124	test: 0.810223

Epoch: 56
Loss: 0.31780249140242045
ROC train: 0.959088	val: 0.833635	test: 0.855392
PRC train: 0.951363	val: 0.754528	test: 0.804897

Epoch: 57
Loss: 0.3242988595443736
ROC train: 0.960425	val: 0.826386	test: 0.863445
PRC train: 0.952975	val: 0.753469	test: 0.821427

Epoch: 58
Loss: 0.3234874645161725
ROC train: 0.959254	val: 0.829105	test: 0.870448
PRC train: 0.951660	val: 0.759243	test: 0.828112

Epoch: 59
Loss: 0.32053329502065314
ROC train: 0.959986	val: 0.834360	test: 0.865196
PRC train: 0.952414	val: 0.766026	test: 0.822576

Epoch: 60
Loss: 0.3003966477750415
ROC train: 0.959438	val: 0.833998	test: 0.864496
PRC train: 0.951685	val: 0.759069	test: 0.815107

Epoch: 61
Loss: 0.31574638500249586
ROC train: 0.959962	val: 0.837622	test: 0.865371
PRC train: 0.951192	val: 0.765590	test: 0.817984

Epoch: 62
Loss: 0.32716205075104077
ROC train: 0.959901	val: 0.845777	test: 0.842612
PRC train: 0.953001	val: 0.772939	test: 0.790890

Epoch: 63
Loss: 0.30833784065358627
ROC train: 0.959366	val: 0.845596	test: 0.863445
PRC train: 0.952117	val: 0.781260	test: 0.811970

Epoch: 64
Loss: 0.3004638168048006
ROC train: 0.960935	val: 0.844328	test: 0.869048
PRC train: 0.954293	val: 0.776276	test: 0.816502

Epoch: 65
Loss: 0.2978602393060623
ROC train: 0.963785	val: 0.843603	test: 0.864496
PRC train: 0.956948	val: 0.764060	test: 0.817027

Epoch: 66
Loss: 0.30311362160143174
ROC train: 0.964859	val: 0.836354	test: 0.871674
PRC train: 0.957940	val: 0.764809	test: 0.826482

Epoch: 67
Loss: 0.30665425205455443
ROC train: 0.961963	val: 0.832367	test: 0.859944
PRC train: 0.955071	val: 0.759310	test: 0.806496

Epoch: 68
Loss: 0.29616263659505887
ROC train: 0.963455	val: 0.844690	test: 0.861520
PRC train: 0.957307	val: 0.768629	test: 0.814363

Epoch: 69
Loss: 0.2930529824214646
ROC train: 0.963367	val: 0.845053	test: 0.869573
PRC train: 0.957151	val: 0.772014	test: 0.818697

Epoch: 70
Loss: 0.29995086618689343
ROC train: 0.967029	val: 0.847771	test: 0.873599
PRC train: 0.961791	val: 0.780504	test: 0.829595

Epoch: 71
Loss: 0.29116639288298396
ROC train: 0.966144	val: 0.847046	test: 0.859769
PRC train: 0.960715	val: 0.767769	test: 0.810563

Epoch: 72
Loss: 0.2956420869512123
ROC train: 0.966073	val: 0.840159	test: 0.853466
PRC train: 0.961043	val: 0.761885	test: 0.799981

Epoch: 73
Loss: 0.30020370903784127
ROC train: 0.969598	val: 0.838166	test: 0.852241
PRC train: 0.965351	val: 0.766879	test: 0.801536

Epoch: 74
Loss: 0.2953425470513847
ROC train: 0.968765	val: 0.835266	test: 0.851366
PRC train: 0.964062	val: 0.759502	test: 0.794295

Epoch: 75
Loss: 0.32118758536910835
ROC train: 0.966637	val: 0.830736	test: 0.848039
PRC train: 0.961637	val: 0.747130	test: 0.786448

Epoch: 76
Loss: 0.2967675417449213
ROC train: 0.966960	val: 0.836897	test: 0.864321
PRC train: 0.961411	val: 0.777274	test: 0.820539

Epoch: 77
Loss: 0.30149502774320774
ROC train: 0.967654	val: 0.844509	test: 0.855042
PRC train: 0.962660	val: 0.779450	test: 0.814905

Epoch: 78
Loss: 0.27616425197325806
ROC train: 0.968885	val: 0.842697	test: 0.845063
PRC train: 0.964844	val: 0.774350	test: 0.793177

Epoch: 79
Loss: 0.29581260703056717
ROC train: 0.969597	val: 0.841791	test: 0.856268
PRC train: 0.965443	val: 0.779666	test: 0.802701

Epoch: 80
Loss: 0.2891938488833975
ROC train: 0.969196	val: 0.846321	test: 0.848739
PRC train: 0.964710	val: 0.785424	test: 0.806187

Epoch: 81
Loss: 0.28203674616016755
ROC train: 0.967251	val: 0.847952	test: 0.835959
PRC train: 0.962820	val: 0.772019	test: 0.800998

Epoch: 82
Loss: 0.27059401061097454
ROC train: 0.971500	val: 0.837441	test: 0.840336
PRC train: 0.967516	val: 0.760453	test: 0.788026

Epoch: 83
Loss: 0.2710278619775176
ROC train: 0.972816	val: 0.837260	test: 0.841737
PRC train: 0.968497	val: 0.766100	test: 0.785814

Epoch: 84
Loss: 0.2805353163969616
ROC train: 0.972327	val: 0.838528	test: 0.826506
PRC train: 0.968539	val: 0.762870	test: 0.775751

Epoch: 85
Loss: 0.268740367344691
ROC train: 0.973489	val: 0.838166	test: 0.831583
PRC train: 0.969401	val: 0.767770	test: 0.786471

Epoch: 86
Loss: 0.2841336135656346
ROC train: 0.975782	val: 0.834542	test: 0.838060
PRC train: 0.971817	val: 0.761158	test: 0.793661

Epoch: 87
Loss: 0.2860414338025983
ROC train: 0.974964	val: 0.840703	test: 0.841036
PRC train: 0.971279	val: 0.772592	test: 0.796742

Epoch: 88
Loss: 0.27140152138419615
ROC train: 0.972468	val: 0.835448	test: 0.847689
PRC train: 0.968556	val: 0.760699	test: 0.799529

Epoch: 89
Loss: 0.28230262958506047
ROC train: 0.971691	val: 0.835448	test: 0.848389
PRC train: 0.967370	val: 0.750971	test: 0.809071

Epoch: 90
Loss: 0.2848510711071312
ROC train: 0.975260	val: 0.832729	test: 0.852941
PRC train: 0.971792	val: 0.758839	test: 0.804104

Epoch: 91
Loss: 0.26774025789600797
ROC train: 0.977867	val: 0.829467	test: 0.846989
PRC train: 0.974852	val: 0.755067	test: 0.791546

Epoch: 92
Loss: 0.25616064327870486
ROC train: 0.976826	val: 0.828199	test: 0.843312
PRC train: 0.973550	val: 0.745412	test: 0.781069

Epoch: 93
Loss: 0.2600627103351361
ROC train: 0.975842	val: 0.835991	test: 0.847689
PRC train: 0.971992	val: 0.767858	test: 0.796847

Epoch: 94
Loss: 0.24477156397565528
ROC train: 0.977867	val: 0.834723	test: 0.846113
PRC train: 0.904702	val: 0.776982	test: 0.803398

Epoch: 34
Loss: 0.43864775793836086
ROC train: 0.924800	val: 0.806690	test: 0.875263
PRC train: 0.906826	val: 0.783548	test: 0.792735

Epoch: 35
Loss: 0.41714849394509057
ROC train: 0.924347	val: 0.812436	test: 0.864427
PRC train: 0.906637	val: 0.790416	test: 0.779626

Epoch: 36
Loss: 0.4022895104546887
ROC train: 0.924148	val: 0.812987	test: 0.865128
PRC train: 0.906051	val: 0.791098	test: 0.784930

Epoch: 37
Loss: 0.4039531575487862
ROC train: 0.925434	val: 0.804014	test: 0.870819
PRC train: 0.906839	val: 0.780386	test: 0.796285

Epoch: 38
Loss: 0.3795669619296811
ROC train: 0.926511	val: 0.794726	test: 0.871911
PRC train: 0.906312	val: 0.761022	test: 0.797936

Epoch: 39
Loss: 0.382146592769757
ROC train: 0.928886	val: 0.804880	test: 0.878771
PRC train: 0.912022	val: 0.773527	test: 0.811068

Epoch: 40
Loss: 0.4025935757179834
ROC train: 0.929676	val: 0.808422	test: 0.870508
PRC train: 0.913818	val: 0.776610	test: 0.803586

Epoch: 41
Loss: 0.3852718372474847
ROC train: 0.928469	val: 0.802125	test: 0.863101
PRC train: 0.911884	val: 0.767024	test: 0.796574

Epoch: 42
Loss: 0.3656381066840645
ROC train: 0.930147	val: 0.800157	test: 0.869182
PRC train: 0.914962	val: 0.767942	test: 0.807062

Epoch: 43
Loss: 0.3998831756288826
ROC train: 0.931459	val: 0.801181	test: 0.874951
PRC train: 0.913886	val: 0.773551	test: 0.814483

Epoch: 44
Loss: 0.36468116666641376
ROC train: 0.931353	val: 0.798741	test: 0.874717
PRC train: 0.909900	val: 0.772533	test: 0.816899

Epoch: 45
Loss: 0.3685710759955173
ROC train: 0.934211	val: 0.797245	test: 0.869728
PRC train: 0.914121	val: 0.769741	test: 0.809067

Epoch: 46
Loss: 0.37940456031016573
ROC train: 0.937618	val: 0.796065	test: 0.874172
PRC train: 0.921774	val: 0.767958	test: 0.809249

Epoch: 47
Loss: 0.3907702253720918
ROC train: 0.939321	val: 0.796143	test: 0.871131
PRC train: 0.926275	val: 0.770626	test: 0.808418

Epoch: 48
Loss: 0.3640858874764577
ROC train: 0.941670	val: 0.793703	test: 0.865128
PRC train: 0.928736	val: 0.766839	test: 0.802651

Epoch: 49
Loss: 0.3678040600398301
ROC train: 0.939105	val: 0.784494	test: 0.871209
PRC train: 0.924794	val: 0.742207	test: 0.807631

Epoch: 50
Loss: 0.3637441473178069
ROC train: 0.936794	val: 0.781110	test: 0.870741
PRC train: 0.921259	val: 0.741435	test: 0.814971

Epoch: 51
Loss: 0.37101504840307903
ROC train: 0.939511	val: 0.792129	test: 0.869806
PRC train: 0.924239	val: 0.756461	test: 0.816528

Epoch: 52
Loss: 0.3473802858887115
ROC train: 0.942076	val: 0.794726	test: 0.873782
PRC train: 0.928283	val: 0.755761	test: 0.820777

Epoch: 53
Loss: 0.34963746112953603
ROC train: 0.943369	val: 0.796852	test: 0.875185
PRC train: 0.929841	val: 0.764764	test: 0.819052

Epoch: 54
Loss: 0.34294553826371443
ROC train: 0.946331	val: 0.802361	test: 0.873626
PRC train: 0.932846	val: 0.767222	test: 0.818691

Epoch: 55
Loss: 0.37512190699412595
ROC train: 0.944878	val: 0.803070	test: 0.869650
PRC train: 0.933089	val: 0.772267	test: 0.814151

Epoch: 56
Loss: 0.33185571495148963
ROC train: 0.947065	val: 0.809209	test: 0.870430
PRC train: 0.935887	val: 0.784336	test: 0.820333

Epoch: 57
Loss: 0.3447141347239329
ROC train: 0.942169	val: 0.807556	test: 0.864583
PRC train: 0.931204	val: 0.783354	test: 0.811183

Epoch: 58
Loss: 0.36872764265719427
ROC train: 0.937252	val: 0.804250	test: 0.866687
PRC train: 0.926423	val: 0.778729	test: 0.809394

Epoch: 59
Loss: 0.3767001424106217
ROC train: 0.942460	val: 0.798977	test: 0.873704
PRC train: 0.929935	val: 0.773138	test: 0.818144

Epoch: 60
Loss: 0.3312492560582996
ROC train: 0.945144	val: 0.803148	test: 0.870585
PRC train: 0.930010	val: 0.772998	test: 0.815098

Epoch: 61
Loss: 0.3402861000554861
ROC train: 0.946386	val: 0.804565	test: 0.864660
PRC train: 0.932609	val: 0.767925	test: 0.804289

Epoch: 62
Loss: 0.35859032459287954
ROC train: 0.947873	val: 0.807241	test: 0.862556
PRC train: 0.936186	val: 0.771952	test: 0.805355

Epoch: 63
Loss: 0.3645469961095137
ROC train: 0.948278	val: 0.816135	test: 0.869650
PRC train: 0.935903	val: 0.786003	test: 0.816353

Epoch: 64
Loss: 0.3861150714598457
ROC train: 0.949691	val: 0.813853	test: 0.881032
PRC train: 0.938681	val: 0.778530	test: 0.826812

Epoch: 65
Loss: 0.3366748168911048
ROC train: 0.949170	val: 0.812121	test: 0.883215
PRC train: 0.935912	val: 0.774796	test: 0.826798

Epoch: 66
Loss: 0.31588849918493833
ROC train: 0.949098	val: 0.814404	test: 0.884073
PRC train: 0.933990	val: 0.775863	test: 0.827799

Epoch: 67
Loss: 0.3224443512061919
ROC train: 0.946746	val: 0.813538	test: 0.873860
PRC train: 0.933629	val: 0.778150	test: 0.809942

Epoch: 68
Loss: 0.3755026919809852
ROC train: 0.946764	val: 0.807241	test: 0.863881
PRC train: 0.935878	val: 0.778108	test: 0.795611

Epoch: 69
Loss: 0.3549944329996026
ROC train: 0.946214	val: 0.799528	test: 0.865050
PRC train: 0.935073	val: 0.776816	test: 0.798959

Epoch: 70
Loss: 0.3620402004745143
ROC train: 0.949012	val: 0.797717	test: 0.871521
PRC train: 0.937225	val: 0.778506	test: 0.815201

Epoch: 71
Loss: 0.3748107208636935
ROC train: 0.950792	val: 0.794805	test: 0.874639
PRC train: 0.938695	val: 0.774607	test: 0.822241

Epoch: 72
Loss: 0.34633162262129896
ROC train: 0.948815	val: 0.788508	test: 0.869104
PRC train: 0.936749	val: 0.766362	test: 0.811615

Epoch: 73
Loss: 0.309390876465053
ROC train: 0.947609	val: 0.796852	test: 0.867935
PRC train: 0.935492	val: 0.771676	test: 0.804295

Epoch: 74
Loss: 0.3575479792662497
ROC train: 0.948319	val: 0.799134	test: 0.863491
PRC train: 0.937073	val: 0.775645	test: 0.794189

Epoch: 75
Loss: 0.33519366734603706
ROC train: 0.950027	val: 0.800708	test: 0.861542
PRC train: 0.937779	val: 0.775682	test: 0.782188

Epoch: 76
Loss: 0.32615827085242477
ROC train: 0.954188	val: 0.808737	test: 0.876121
PRC train: 0.943555	val: 0.774722	test: 0.807039

Epoch: 77
Loss: 0.34317925779050285
ROC train: 0.952342	val: 0.815348	test: 0.878693
PRC train: 0.941469	val: 0.783711	test: 0.819242

Epoch: 78
Loss: 0.3876471566769523
ROC train: 0.952773	val: 0.811492	test: 0.874951
PRC train: 0.942202	val: 0.788927	test: 0.810224

Epoch: 79
Loss: 0.2892452974280246
ROC train: 0.950884	val: 0.810862	test: 0.862400
PRC train: 0.939837	val: 0.783749	test: 0.805018

Epoch: 80
Loss: 0.32416216517236274
ROC train: 0.953567	val: 0.803542	test: 0.869338
PRC train: 0.944268	val: 0.766130	test: 0.818151

Epoch: 81
Loss: 0.32561487759929697
ROC train: 0.950357	val: 0.792208	test: 0.871989
PRC train: 0.940886	val: 0.734694	test: 0.820509

Epoch: 82
Loss: 0.3174802871201068
ROC train: 0.952525	val: 0.803306	test: 0.877758
PRC train: 0.944182	val: 0.757733	test: 0.828972

Epoch: 83
Loss: 0.322119093139227
ROC train: 0.958903	val: 0.817710	test: 0.881812
PRC train: 0.950528	val: 0.790661	test: 0.829454

Epoch: 84
Loss: 0.3038250765663035
ROC train: 0.954354	val: 0.821724	test: 0.884930
PRC train: 0.944106	val: 0.799404	test: 0.828127

Epoch: 85
Loss: 0.3045021677037226
ROC train: 0.954975	val: 0.820858	test: 0.879629
PRC train: 0.945051	val: 0.795956	test: 0.819127

Epoch: 86
Loss: 0.3019424662025033
ROC train: 0.958700	val: 0.814640	test: 0.870663
PRC train: 0.950542	val: 0.788169	test: 0.813029

Epoch: 87
Loss: 0.34440857609031106
ROC train: 0.959232	val: 0.810704	test: 0.868013
PRC train: 0.950419	val: 0.784750	test: 0.812255

Epoch: 88
Loss: 0.3276027276133128
ROC train: 0.958107	val: 0.808186	test: 0.865908
PRC train: 0.949220	val: 0.783087	test: 0.811061

Epoch: 89
Loss: 0.3065499712269316
ROC train: 0.960279	val: 0.812830	test: 0.862789
PRC train: 0.951397	val: 0.789906	test: 0.798151

Epoch: 90
Loss: 0.30497933509762415
ROC train: 0.961315	val: 0.811649	test: 0.864738
PRC train: 0.953490	val: 0.782924	test: 0.792401

Epoch: 91
Loss: 0.29526102556242645
ROC train: 0.960097	val: 0.809603	test: 0.869182
PRC train: 0.953900	val: 0.777049	test: 0.802821

Epoch: 92
Loss: 0.3135345541605362
ROC train: 0.960124	val: 0.814089	test: 0.872457
PRC train: 0.953224	val: 0.774651	test: 0.814615

Epoch: 93
Loss: 0.30799447229488847
ROC train: 0.961130	val: 0.818024	test: 0.861074
PRC train: 0.953291	val: 0.787244	test: 0.798068

Epoch: 94
Loss: 0.2780800408945077
ROC train: 0.961480	val: 0.813932	test: 0.854370
PRC train: 0.919290	val: 0.765841	test: 0.815479

Epoch: 34
Loss: 0.37132863027252844
ROC train: 0.936237	val: 0.837079	test: 0.880077
PRC train: 0.922561	val: 0.759971	test: 0.817342

Epoch: 35
Loss: 0.3639056719892805
ROC train: 0.939325	val: 0.847408	test: 0.880427
PRC train: 0.926690	val: 0.770435	test: 0.823074

Epoch: 36
Loss: 0.37482596335817325
ROC train: 0.941116	val: 0.852302	test: 0.882878
PRC train: 0.928302	val: 0.778161	test: 0.831086

Epoch: 37
Loss: 0.37313845907201504
ROC train: 0.941722	val: 0.848315	test: 0.881127
PRC train: 0.930087	val: 0.777228	test: 0.830051

Epoch: 38
Loss: 0.36248724130224347
ROC train: 0.941159	val: 0.845415	test: 0.880602
PRC train: 0.930431	val: 0.770450	test: 0.829898

Epoch: 39
Loss: 0.3609411590455438
ROC train: 0.938876	val: 0.841428	test: 0.884979
PRC train: 0.927420	val: 0.760386	test: 0.835803

Epoch: 40
Loss: 0.3475572055631811
ROC train: 0.942930	val: 0.837622	test: 0.872724
PRC train: 0.932090	val: 0.752834	test: 0.815827

Epoch: 41
Loss: 0.3521287021401602
ROC train: 0.942216	val: 0.833454	test: 0.878676
PRC train: 0.930159	val: 0.746648	test: 0.819261

Epoch: 42
Loss: 0.3503411275835243
ROC train: 0.947023	val: 0.839616	test: 0.875000
PRC train: 0.936104	val: 0.750971	test: 0.813669

Epoch: 43
Loss: 0.3398861503001346
ROC train: 0.948064	val: 0.844871	test: 0.878326
PRC train: 0.936990	val: 0.756167	test: 0.813544

Epoch: 44
Loss: 0.33493077418368644
ROC train: 0.949132	val: 0.844871	test: 0.880252
PRC train: 0.937915	val: 0.755238	test: 0.817333

Epoch: 45
Loss: 0.35775116633110277
ROC train: 0.950622	val: 0.846502	test: 0.879202
PRC train: 0.939763	val: 0.761347	test: 0.819631

Epoch: 46
Loss: 0.3446197017642724
ROC train: 0.952177	val: 0.842878	test: 0.875525
PRC train: 0.942553	val: 0.759291	test: 0.816261

Epoch: 47
Loss: 0.3446499166546538
ROC train: 0.951283	val: 0.836354	test: 0.876576
PRC train: 0.941391	val: 0.751611	test: 0.823008

Epoch: 48
Loss: 0.33801273559769107
ROC train: 0.952061	val: 0.839435	test: 0.879727
PRC train: 0.943502	val: 0.761262	test: 0.827135

Epoch: 49
Loss: 0.3538497935860037
ROC train: 0.952870	val: 0.845959	test: 0.874125
PRC train: 0.943835	val: 0.766986	test: 0.819285

Epoch: 50
Loss: 0.3407878488005056
ROC train: 0.954202	val: 0.842153	test: 0.874125
PRC train: 0.945629	val: 0.786015	test: 0.822369

Epoch: 51
Loss: 0.3402702406482409
ROC train: 0.956994	val: 0.841428	test: 0.874125
PRC train: 0.949028	val: 0.776547	test: 0.817851

Epoch: 52
Loss: 0.3513684012168128
ROC train: 0.955294	val: 0.843965	test: 0.862395
PRC train: 0.946787	val: 0.766972	test: 0.797818

Epoch: 53
Loss: 0.3173779688458098
ROC train: 0.955100	val: 0.843059	test: 0.874650
PRC train: 0.944140	val: 0.763514	test: 0.807872

Epoch: 54
Loss: 0.34725454508762327
ROC train: 0.953881	val: 0.837985	test: 0.878676
PRC train: 0.943093	val: 0.765636	test: 0.825796

Epoch: 55
Loss: 0.33502360156900596
ROC train: 0.957696	val: 0.839616	test: 0.873950
PRC train: 0.949957	val: 0.746783	test: 0.820683

Epoch: 56
Loss: 0.34051943743646695
ROC train: 0.958017	val: 0.835266	test: 0.879377
PRC train: 0.950986	val: 0.750889	test: 0.822089

Epoch: 57
Loss: 0.31710001459703574
ROC train: 0.959033	val: 0.836173	test: 0.873775
PRC train: 0.952916	val: 0.762174	test: 0.815322

Epoch: 58
Loss: 0.3216608438008377
ROC train: 0.960648	val: 0.840703	test: 0.869223
PRC train: 0.954006	val: 0.763096	test: 0.815762

Epoch: 59
Loss: 0.3249856072374916
ROC train: 0.959708	val: 0.844328	test: 0.872724
PRC train: 0.951855	val: 0.761959	test: 0.817873

Epoch: 60
Loss: 0.32003667674563496
ROC train: 0.959011	val: 0.843059	test: 0.876225
PRC train: 0.951170	val: 0.757201	test: 0.820511

Epoch: 61
Loss: 0.3331854241858017
ROC train: 0.960025	val: 0.850489	test: 0.879902
PRC train: 0.952445	val: 0.769733	test: 0.831063

Epoch: 62
Loss: 0.32074632462779595
ROC train: 0.962052	val: 0.845415	test: 0.875175
PRC train: 0.955243	val: 0.760559	test: 0.829878

Epoch: 63
Loss: 0.30958180492793347
ROC train: 0.963719	val: 0.849402	test: 0.876576
PRC train: 0.956635	val: 0.764115	test: 0.830197

Epoch: 64
Loss: 0.3142194291182833
ROC train: 0.964293	val: 0.848133	test: 0.872199
PRC train: 0.957240	val: 0.768342	test: 0.820532

Epoch: 65
Loss: 0.31542560113858076
ROC train: 0.967226	val: 0.843422	test: 0.872374
PRC train: 0.961593	val: 0.769319	test: 0.824816

Epoch: 66
Loss: 0.3057335975075486
ROC train: 0.965507	val: 0.853933	test: 0.877101
PRC train: 0.958667	val: 0.784675	test: 0.838698

Epoch: 67
Loss: 0.2902339174590379
ROC train: 0.967726	val: 0.847590	test: 0.869398
PRC train: 0.962172	val: 0.766471	test: 0.824407

Epoch: 68
Loss: 0.29768868414402694
ROC train: 0.969402	val: 0.842153	test: 0.867122
PRC train: 0.964682	val: 0.758698	test: 0.818236

Epoch: 69
Loss: 0.2901125966158863
ROC train: 0.968677	val: 0.845415	test: 0.872199
PRC train: 0.963044	val: 0.750138	test: 0.830477

Epoch: 70
Loss: 0.28595723470448614
ROC train: 0.969700	val: 0.851214	test: 0.872199
PRC train: 0.964036	val: 0.752977	test: 0.829407

Epoch: 71
Loss: 0.31156827535652015
ROC train: 0.969664	val: 0.846684	test: 0.883228
PRC train: 0.963518	val: 0.753320	test: 0.843367

Epoch: 72
Loss: 0.2955805711022573
ROC train: 0.970245	val: 0.843059	test: 0.879027
PRC train: 0.964130	val: 0.753767	test: 0.834167

Epoch: 73
Loss: 0.2979398156472521
ROC train: 0.967713	val: 0.834179	test: 0.874300
PRC train: 0.960174	val: 0.735073	test: 0.833671

Epoch: 74
Loss: 0.29244621199610715
ROC train: 0.970456	val: 0.833454	test: 0.883403
PRC train: 0.965025	val: 0.752108	test: 0.843981

Epoch: 75
Loss: 0.2952415085891075
ROC train: 0.972772	val: 0.844509	test: 0.878676
PRC train: 0.968551	val: 0.766788	test: 0.840393

Epoch: 76
Loss: 0.2883341806966844
ROC train: 0.971173	val: 0.842697	test: 0.883403
PRC train: 0.965968	val: 0.760397	test: 0.848436

Epoch: 77
Loss: 0.29392899472747697
ROC train: 0.973401	val: 0.839978	test: 0.870623
PRC train: 0.968496	val: 0.731923	test: 0.830211

Epoch: 78
Loss: 0.266995228112249
ROC train: 0.974324	val: 0.832548	test: 0.869923
PRC train: 0.969525	val: 0.723825	test: 0.820775

Epoch: 79
Loss: 0.2742831374559002
ROC train: 0.973837	val: 0.837804	test: 0.879377
PRC train: 0.969175	val: 0.742695	test: 0.832395

Epoch: 80
Loss: 0.2945154441330742
ROC train: 0.974461	val: 0.844871	test: 0.883578
PRC train: 0.969653	val: 0.747692	test: 0.846455

Epoch: 81
Loss: 0.28276721996520154
ROC train: 0.974214	val: 0.835991	test: 0.871324
PRC train: 0.969030	val: 0.749142	test: 0.833284

Epoch: 82
Loss: 0.2932970588753571
ROC train: 0.975343	val: 0.825661	test: 0.853466
PRC train: 0.970425	val: 0.727712	test: 0.813787

Epoch: 83
Loss: 0.2813289797728149
ROC train: 0.975067	val: 0.828380	test: 0.860469
PRC train: 0.970515	val: 0.733993	test: 0.822043

Epoch: 84
Loss: 0.2757113163015183
ROC train: 0.970176	val: 0.833454	test: 0.871499
PRC train: 0.964381	val: 0.741475	test: 0.823851

Epoch: 85
Loss: 0.27525249013056513
ROC train: 0.972010	val: 0.844509	test: 0.868347
PRC train: 0.966971	val: 0.760600	test: 0.821718

Epoch: 86
Loss: 0.2788189991659088
ROC train: 0.975268	val: 0.851577	test: 0.867822
PRC train: 0.971289	val: 0.781694	test: 0.827785

Epoch: 87
Loss: 0.2583457573886286
ROC train: 0.974406	val: 0.847227	test: 0.874125
PRC train: 0.970322	val: 0.775154	test: 0.835594

Epoch: 88
Loss: 0.2701797985342869
ROC train: 0.976305	val: 0.843059	test: 0.871148
PRC train: 0.972854	val: 0.760461	test: 0.826441

Epoch: 89
Loss: 0.27772336139252013
ROC train: 0.978897	val: 0.835991	test: 0.863620
PRC train: 0.976079	val: 0.742008	test: 0.815901

Epoch: 90
Loss: 0.27602092373296117
ROC train: 0.978850	val: 0.834723	test: 0.860819
PRC train: 0.975672	val: 0.735710	test: 0.813192

Epoch: 91
Loss: 0.24914502894783858
ROC train: 0.977968	val: 0.836354	test: 0.863796
PRC train: 0.974243	val: 0.730713	test: 0.812302

Epoch: 92
Loss: 0.25428273618371217
ROC train: 0.979532	val: 0.838528	test: 0.865196
PRC train: 0.976406	val: 0.737367	test: 0.812832

Epoch: 93
Loss: 0.26014265565233397
ROC train: 0.979715	val: 0.842334	test: 0.863620
PRC train: 0.976571	val: 0.739274	test: 0.801135

Epoch: 94
Loss: 0.26862739891543413
ROC train: 0.980218	val: 0.840884	test: 0.867122ROC train: 0.931441	val: 0.844328	test: 0.875000
PRC train: 0.916440	val: 0.747985	test: 0.822922

Epoch: 34
Loss: 0.3833997393302979
ROC train: 0.936790	val: 0.848496	test: 0.883929
PRC train: 0.921476	val: 0.756797	test: 0.836735

Epoch: 35
Loss: 0.38768767971870266
ROC train: 0.938426	val: 0.848315	test: 0.885329
PRC train: 0.923751	val: 0.765866	test: 0.836127

Epoch: 36
Loss: 0.3719094726136225
ROC train: 0.938882	val: 0.852664	test: 0.878501
PRC train: 0.924855	val: 0.774860	test: 0.828350

Epoch: 37
Loss: 0.35812941818609356
ROC train: 0.940269	val: 0.847408	test: 0.879202
PRC train: 0.927418	val: 0.771277	test: 0.827281

Epoch: 38
Loss: 0.35915126313754286
ROC train: 0.938260	val: 0.841066	test: 0.878326
PRC train: 0.925306	val: 0.771191	test: 0.832764

Epoch: 39
Loss: 0.3585205828785685
ROC train: 0.936815	val: 0.846321	test: 0.875000
PRC train: 0.922958	val: 0.772747	test: 0.832012

Epoch: 40
Loss: 0.3733663507203445
ROC train: 0.940531	val: 0.846684	test: 0.882703
PRC train: 0.928028	val: 0.770244	test: 0.843459

Epoch: 41
Loss: 0.3643826636367955
ROC train: 0.943342	val: 0.843965	test: 0.887605
PRC train: 0.931665	val: 0.765049	test: 0.846510

Epoch: 42
Loss: 0.35097089126408115
ROC train: 0.946004	val: 0.841428	test: 0.894433
PRC train: 0.935640	val: 0.760735	test: 0.850458

Epoch: 43
Loss: 0.3537958251066639
ROC train: 0.947679	val: 0.844871	test: 0.894608
PRC train: 0.937757	val: 0.765615	test: 0.852499

Epoch: 44
Loss: 0.33604434584051657
ROC train: 0.945647	val: 0.852845	test: 0.889881
PRC train: 0.935167	val: 0.778822	test: 0.846392

Epoch: 45
Loss: 0.3568506004057964
ROC train: 0.947003	val: 0.852302	test: 0.876926
PRC train: 0.936784	val: 0.772923	test: 0.829614

Epoch: 46
Loss: 0.35440065240146446
ROC train: 0.947643	val: 0.845415	test: 0.868347
PRC train: 0.937279	val: 0.760355	test: 0.820860

Epoch: 47
Loss: 0.35762515506345854
ROC train: 0.949313	val: 0.836354	test: 0.871499
PRC train: 0.939387	val: 0.746076	test: 0.829196

Epoch: 48
Loss: 0.3455849004539875
ROC train: 0.949997	val: 0.847227	test: 0.888655
PRC train: 0.939874	val: 0.762856	test: 0.847718

Epoch: 49
Loss: 0.3398759385110329
ROC train: 0.951596	val: 0.855926	test: 0.881127
PRC train: 0.942589	val: 0.780270	test: 0.836599

Epoch: 50
Loss: 0.3305018648250365
ROC train: 0.954175	val: 0.856470	test: 0.878326
PRC train: 0.946119	val: 0.783604	test: 0.833276

Epoch: 51
Loss: 0.34271118990360794
ROC train: 0.952554	val: 0.855926	test: 0.874300
PRC train: 0.943498	val: 0.782292	test: 0.823937

Epoch: 52
Loss: 0.3352804817095842
ROC train: 0.949956	val: 0.858826	test: 0.872899
PRC train: 0.938524	val: 0.788571	test: 0.829166

Epoch: 53
Loss: 0.328703044415791
ROC train: 0.952300	val: 0.846865	test: 0.876576
PRC train: 0.942290	val: 0.771261	test: 0.831885

Epoch: 54
Loss: 0.33894574552314494
ROC train: 0.953443	val: 0.849221	test: 0.874300
PRC train: 0.945819	val: 0.769381	test: 0.822047

Epoch: 55
Loss: 0.3358778957535941
ROC train: 0.954832	val: 0.854295	test: 0.875700
PRC train: 0.948046	val: 0.782409	test: 0.823432

Epoch: 56
Loss: 0.33189194794350513
ROC train: 0.953110	val: 0.858101	test: 0.899160
PRC train: 0.945198	val: 0.786441	test: 0.860167

Epoch: 57
Loss: 0.3233363643861824
ROC train: 0.952549	val: 0.857195	test: 0.895308
PRC train: 0.944161	val: 0.782624	test: 0.861154

Epoch: 58
Loss: 0.32762362373720866
ROC train: 0.953776	val: 0.850671	test: 0.883403
PRC train: 0.945076	val: 0.773070	test: 0.837865

Epoch: 59
Loss: 0.31474919503785487
ROC train: 0.956207	val: 0.849402	test: 0.888130
PRC train: 0.947165	val: 0.778579	test: 0.842781

Epoch: 60
Loss: 0.32965676621019546
ROC train: 0.955726	val: 0.855020	test: 0.881828
PRC train: 0.945989	val: 0.785688	test: 0.842107

Epoch: 61
Loss: 0.3257041996733169
ROC train: 0.959948	val: 0.849764	test: 0.863445
PRC train: 0.952208	val: 0.775708	test: 0.817982

Epoch: 62
Loss: 0.31498170696184274
ROC train: 0.960746	val: 0.849040	test: 0.869048
PRC train: 0.953509	val: 0.775161	test: 0.819663

Epoch: 63
Loss: 0.31012013316025766
ROC train: 0.959091	val: 0.857376	test: 0.882353
PRC train: 0.951087	val: 0.778737	test: 0.840809

Epoch: 64
Loss: 0.3076944455065186
ROC train: 0.959616	val: 0.856651	test: 0.886905
PRC train: 0.952106	val: 0.776192	test: 0.848909

Epoch: 65
Loss: 0.29746678743684724
ROC train: 0.960615	val: 0.857738	test: 0.877451
PRC train: 0.954736	val: 0.776801	test: 0.838468

Epoch: 66
Loss: 0.3127632404659545
ROC train: 0.962791	val: 0.855020	test: 0.863270
PRC train: 0.957646	val: 0.771057	test: 0.813944

Epoch: 67
Loss: 0.3165090677767937
ROC train: 0.963230	val: 0.851395	test: 0.891807
PRC train: 0.957133	val: 0.784600	test: 0.854842

Epoch: 68
Loss: 0.2910613181520715
ROC train: 0.964524	val: 0.858826	test: 0.889531
PRC train: 0.958792	val: 0.786366	test: 0.857926

Epoch: 69
Loss: 0.2944110215633104
ROC train: 0.966207	val: 0.857920	test: 0.879377
PRC train: 0.961118	val: 0.778429	test: 0.841581

Epoch: 70
Loss: 0.3051813225693497
ROC train: 0.967883	val: 0.855745	test: 0.880602
PRC train: 0.963121	val: 0.779260	test: 0.836565

Epoch: 71
Loss: 0.286459883905516
ROC train: 0.969783	val: 0.859913	test: 0.878852
PRC train: 0.964260	val: 0.777668	test: 0.834209

Epoch: 72
Loss: 0.2971719383852961
ROC train: 0.968394	val: 0.858644	test: 0.883929
PRC train: 0.962690	val: 0.797853	test: 0.839486

Epoch: 73
Loss: 0.2775616570314529
ROC train: 0.965503	val: 0.854657	test: 0.862920
PRC train: 0.959381	val: 0.770003	test: 0.810665

Epoch: 74
Loss: 0.2910559533977708
ROC train: 0.965864	val: 0.843603	test: 0.865196
PRC train: 0.959934	val: 0.756276	test: 0.808638

Epoch: 75
Loss: 0.29958108288659036
ROC train: 0.969058	val: 0.847590	test: 0.879552
PRC train: 0.963421	val: 0.767166	test: 0.823935

Epoch: 76
Loss: 0.2810254717217427
ROC train: 0.967237	val: 0.856651	test: 0.880777
PRC train: 0.961553	val: 0.784742	test: 0.831512

Epoch: 77
Loss: 0.2902726651910306
ROC train: 0.968861	val: 0.851395	test: 0.875875
PRC train: 0.963784	val: 0.771174	test: 0.827766

Epoch: 78
Loss: 0.2827169775638215
ROC train: 0.971843	val: 0.851939	test: 0.874650
PRC train: 0.967547	val: 0.771815	test: 0.830050

Epoch: 79
Loss: 0.27699286302578946
ROC train: 0.971632	val: 0.849583	test: 0.875700
PRC train: 0.966521	val: 0.764179	test: 0.825490

Epoch: 80
Loss: 0.2801454621783527
ROC train: 0.971442	val: 0.847227	test: 0.865721
PRC train: 0.966610	val: 0.763214	test: 0.806885

Epoch: 81
Loss: 0.2676044417811375
ROC train: 0.973283	val: 0.847408	test: 0.881828
PRC train: 0.968465	val: 0.773584	test: 0.836696

Epoch: 82
Loss: 0.2841587637883296
ROC train: 0.973403	val: 0.856470	test: 0.874650
PRC train: 0.968880	val: 0.781951	test: 0.832527

Epoch: 83
Loss: 0.2747508526454524
ROC train: 0.973472	val: 0.850852	test: 0.870798
PRC train: 0.969420	val: 0.771567	test: 0.820353

Epoch: 84
Loss: 0.2812106973071841
ROC train: 0.973725	val: 0.850671	test: 0.870448
PRC train: 0.969138	val: 0.772085	test: 0.816256

Epoch: 85
Loss: 0.2756353951334574
ROC train: 0.975194	val: 0.854657	test: 0.868873
PRC train: 0.970368	val: 0.773874	test: 0.820151

Epoch: 86
Loss: 0.27454729716063514
ROC train: 0.974884	val: 0.853751	test: 0.868522
PRC train: 0.970189	val: 0.768749	test: 0.813298

Epoch: 87
Loss: 0.28426462074706316
ROC train: 0.973211	val: 0.853751	test: 0.867997
PRC train: 0.968304	val: 0.767728	test: 0.811706

Epoch: 88
Loss: 0.27016820046491363
ROC train: 0.977519	val: 0.856651	test: 0.874825
PRC train: 0.973753	val: 0.772901	test: 0.826569

Epoch: 89
Loss: 0.27773777999325366
ROC train: 0.978895	val: 0.859007	test: 0.872374
PRC train: 0.975390	val: 0.777799	test: 0.821322

Epoch: 90
Loss: 0.274065205258882
ROC train: 0.978097	val: 0.857376	test: 0.871148
PRC train: 0.974170	val: 0.781515	test: 0.817707

Epoch: 91
Loss: 0.2662334152914363
ROC train: 0.979141	val: 0.855382	test: 0.870623
PRC train: 0.975775	val: 0.780543	test: 0.817791

Epoch: 92
Loss: 0.26011499566741536
ROC train: 0.978523	val: 0.852845	test: 0.863971
PRC train: 0.974508	val: 0.767965	test: 0.806208

Epoch: 93
Loss: 0.27185511769244397
ROC train: 0.978417	val: 0.858101	test: 0.854342
PRC train: 0.974904	val: 0.767781	test: 0.800392

Epoch: 94
Loss: 0.2637383257051905
PRC train: 0.979489	val: 0.771597	test: 0.774246

Epoch: 95
Loss: 0.24164639699017057
ROC train: 0.981705	val: 0.811850	test: 0.837135
PRC train: 0.976890	val: 0.754695	test: 0.775965

Epoch: 96
Loss: 0.2346450331635181
ROC train: 0.982217	val: 0.813869	test: 0.841512
PRC train: 0.977752	val: 0.756773	test: 0.777000

Epoch: 97
Loss: 0.21463127288461026
ROC train: 0.982031	val: 0.821286	test: 0.844651
PRC train: 0.977937	val: 0.778092	test: 0.780407

Epoch: 98
Loss: 0.23403929592701075
ROC train: 0.984045	val: 0.833443	test: 0.844518
PRC train: 0.980883	val: 0.807121	test: 0.779919

Epoch: 99
Loss: 0.2241519139071566
ROC train: 0.985407	val: 0.829537	test: 0.839257
PRC train: 0.982255	val: 0.799193	test: 0.773713

Epoch: 100
Loss: 0.20901410499912976
ROC train: 0.986215	val: 0.819618	test: 0.837445
PRC train: 0.983100	val: 0.780365	test: 0.778614

Epoch: 101
Loss: 0.2302637387471516
ROC train: 0.985843	val: 0.818214	test: 0.846994
PRC train: 0.982731	val: 0.776928	test: 0.790340

Epoch: 102
Loss: 0.20950396068762417
ROC train: 0.985201	val: 0.821286	test: 0.853360
PRC train: 0.981928	val: 0.776342	test: 0.796848

Epoch: 103
Loss: 0.2262721828162404
ROC train: 0.985309	val: 0.820057	test: 0.854465
PRC train: 0.981936	val: 0.768501	test: 0.796461

Epoch: 104
Loss: 0.22117023672008715
ROC train: 0.987239	val: 0.818565	test: 0.843678
PRC train: 0.984111	val: 0.762188	test: 0.787050

Epoch: 105
Loss: 0.21359327668142875
ROC train: 0.987323	val: 0.815493	test: 0.833643
PRC train: 0.984284	val: 0.761913	test: 0.773928

Epoch: 106
Loss: 0.19667733737329338
ROC train: 0.984412	val: 0.813913	test: 0.830902
PRC train: 0.980828	val: 0.767151	test: 0.767334

Epoch: 107
Loss: 0.19257951598439094
ROC train: 0.983964	val: 0.819004	test: 0.829752
PRC train: 0.979374	val: 0.779411	test: 0.767799

Epoch: 108
Loss: 0.23291026534903758
ROC train: 0.988165	val: 0.820189	test: 0.831786
PRC train: 0.985827	val: 0.783607	test: 0.770974

Epoch: 109
Loss: 0.18956022040000234
ROC train: 0.988445	val: 0.814264	test: 0.839655
PRC train: 0.985808	val: 0.766655	test: 0.783112

Epoch: 110
Loss: 0.21413963957279086
ROC train: 0.986771	val: 0.811718	test: 0.845977
PRC train: 0.983148	val: 0.760828	test: 0.793558

Epoch: 111
Loss: 0.2053374791843264
ROC train: 0.989081	val: 0.817248	test: 0.845977
PRC train: 0.986336	val: 0.772221	test: 0.794739

Epoch: 112
Loss: 0.19822486743498585
ROC train: 0.989527	val: 0.819135	test: 0.845004
PRC train: 0.986951	val: 0.778577	test: 0.789629

Epoch: 113
Loss: 0.2005160781728707
ROC train: 0.988988	val: 0.819925	test: 0.842529
PRC train: 0.986344	val: 0.781359	test: 0.778079

Epoch: 114
Loss: 0.19185889878136908
ROC train: 0.990311	val: 0.820320	test: 0.837268
PRC train: 0.987783	val: 0.787234	test: 0.767156

Epoch: 115
Loss: 0.21799939462622228
ROC train: 0.990693	val: 0.821461	test: 0.838506
PRC train: 0.988481	val: 0.785604	test: 0.767658

Epoch: 116
Loss: 0.22028616124172726
ROC train: 0.990441	val: 0.823963	test: 0.838904
PRC train: 0.988403	val: 0.785795	test: 0.772416

Epoch: 117
Loss: 0.2035287998165738
ROC train: 0.990365	val: 0.816985	test: 0.842219
PRC train: 0.988292	val: 0.774844	test: 0.774297

Epoch: 118
Loss: 0.215166924750757
ROC train: 0.991036	val: 0.811587	test: 0.846065
PRC train: 0.988858	val: 0.764968	test: 0.778572

Epoch: 119
Loss: 0.2187321817990702
ROC train: 0.992180	val: 0.807505	test: 0.847038
PRC train: 0.990401	val: 0.767864	test: 0.777527

Epoch: 120
Loss: 0.18037237474031298
ROC train: 0.991370	val: 0.809173	test: 0.845181
PRC train: 0.989586	val: 0.768154	test: 0.782727

Epoch: 121
Loss: 0.18568724034639517
ROC train: 0.990390	val: 0.811104	test: 0.845535
PRC train: 0.988436	val: 0.762043	test: 0.780759

Epoch: 122
Loss: 0.2160307525784072
ROC train: 0.991698	val: 0.815054	test: 0.840672
PRC train: 0.989754	val: 0.770689	test: 0.778512

Epoch: 123
Loss: 0.18337866145160747
ROC train: 0.991933	val: 0.816897	test: 0.839346
PRC train: 0.989858	val: 0.776101	test: 0.779093

Epoch: 124
Loss: 0.17950329474105908
ROC train: 0.992594	val: 0.819399	test: 0.839567
PRC train: 0.990903	val: 0.784572	test: 0.774618

Epoch: 125
Loss: 0.20383192214004348
ROC train: 0.991051	val: 0.814176	test: 0.850619
PRC train: 0.989307	val: 0.774398	test: 0.785590

Epoch: 126
Loss: 0.19391469969850747
ROC train: 0.989407	val: 0.810007	test: 0.853227
PRC train: 0.986852	val: 0.766127	test: 0.785197

Epoch: 127
Loss: 0.20101268946652356
ROC train: 0.992433	val: 0.814176	test: 0.846729
PRC train: 0.990881	val: 0.779736	test: 0.776617

Epoch: 128
Loss: 0.20872303449799862
ROC train: 0.993528	val: 0.814132	test: 0.843767
PRC train: 0.992065	val: 0.780751	test: 0.779711

Epoch: 129
Loss: 0.17678419394421674
ROC train: 0.991242	val: 0.809831	test: 0.840186
PRC train: 0.988905	val: 0.760415	test: 0.781224

Epoch: 130
Loss: 0.18713781196708684
ROC train: 0.993349	val: 0.811411	test: 0.840849
PRC train: 0.991695	val: 0.774631	test: 0.780526

Epoch: 131
Loss: 0.19774653814432105
ROC train: 0.992109	val: 0.809655	test: 0.846508
PRC train: 0.990284	val: 0.772606	test: 0.785798

Epoch: 132
Loss: 0.17496663020644493
ROC train: 0.990581	val: 0.809436	test: 0.842794
PRC train: 0.988681	val: 0.771985	test: 0.780008

Epoch: 133
Loss: 0.18471271859603267
ROC train: 0.991433	val: 0.814483	test: 0.840141
PRC train: 0.989785	val: 0.777806	test: 0.776584

Early stopping
Best (ROC):	 train: 0.984045	val: 0.833443	test: 0.844518
Best (PRC):	 train: 0.980883	val: 0.807121	test: 0.779919

PRC train: 0.952361	val: 0.789226	test: 0.815444

Epoch: 95
Loss: 0.2928458556110839
ROC train: 0.958833	val: 0.808107	test: 0.876433
PRC train: 0.951043	val: 0.786397	test: 0.809378

Epoch: 96
Loss: 0.3144533871333307
ROC train: 0.960654	val: 0.810075	test: 0.878849
PRC train: 0.952514	val: 0.788015	test: 0.812541

Epoch: 97
Loss: 0.3162108234139174
ROC train: 0.962001	val: 0.813066	test: 0.886022
PRC train: 0.953673	val: 0.790612	test: 0.823042

Epoch: 98
Loss: 0.32456275333877943
ROC train: 0.963416	val: 0.808894	test: 0.886178
PRC train: 0.956117	val: 0.783105	test: 0.821832

Epoch: 99
Loss: 0.3008790721604342
ROC train: 0.959029	val: 0.803621	test: 0.880097
PRC train: 0.952832	val: 0.780420	test: 0.815714

Epoch: 100
Loss: 0.3043306234706314
ROC train: 0.961301	val: 0.810232	test: 0.879863
PRC train: 0.955520	val: 0.786470	test: 0.815407

Epoch: 101
Loss: 0.2887141623021909
ROC train: 0.964627	val: 0.812200	test: 0.879941
PRC train: 0.958237	val: 0.781272	test: 0.814030

Epoch: 102
Loss: 0.2948732252411555
ROC train: 0.965464	val: 0.814010	test: 0.877368
PRC train: 0.959145	val: 0.794703	test: 0.808699

Epoch: 103
Loss: 0.30266448061834694
ROC train: 0.961850	val: 0.801574	test: 0.870118
PRC train: 0.955574	val: 0.771957	test: 0.808189

Epoch: 104
Loss: 0.28835536393911226
ROC train: 0.965493	val: 0.806769	test: 0.865518
PRC train: 0.959591	val: 0.781870	test: 0.804597

Epoch: 105
Loss: 0.2807157322545383
ROC train: 0.965489	val: 0.806061	test: 0.876744
PRC train: 0.959053	val: 0.784193	test: 0.822563

Epoch: 106
Loss: 0.3008096052005322
ROC train: 0.962504	val: 0.804408	test: 0.887035
PRC train: 0.956017	val: 0.782795	test: 0.835377

Epoch: 107
Loss: 0.2955565456894259
ROC train: 0.963014	val: 0.812436	test: 0.883917
PRC train: 0.956438	val: 0.788831	test: 0.819643

Epoch: 108
Loss: 0.2904200583723232
ROC train: 0.963962	val: 0.811334	test: 0.867779
PRC train: 0.956428	val: 0.787277	test: 0.790070

Epoch: 109
Loss: 0.29458074035370746
ROC train: 0.964900	val: 0.806533	test: 0.863257
PRC train: 0.956417	val: 0.784356	test: 0.782997

Epoch: 110
Loss: 0.2820133148976597
ROC train: 0.964821	val: 0.808107	test: 0.862478
PRC train: 0.954701	val: 0.782423	test: 0.787853

Epoch: 111
Loss: 0.29257749780303566
ROC train: 0.965793	val: 0.806533	test: 0.870819
PRC train: 0.956815	val: 0.781268	test: 0.802008

Epoch: 112
Loss: 0.3215361143034202
ROC train: 0.965945	val: 0.805116	test: 0.880486
PRC train: 0.958769	val: 0.776480	test: 0.813579

Epoch: 113
Loss: 0.3206536977650072
ROC train: 0.964719	val: 0.798741	test: 0.878382
PRC train: 0.957026	val: 0.767637	test: 0.803509

Epoch: 114
Loss: 0.33937302988434104
ROC train: 0.966520	val: 0.807399	test: 0.878693
PRC train: 0.959479	val: 0.785845	test: 0.816017

Epoch: 115
Loss: 0.28589243900560274
ROC train: 0.965216	val: 0.814010	test: 0.875809
PRC train: 0.957039	val: 0.795404	test: 0.811212

Epoch: 116
Loss: 0.27847275214154565
ROC train: 0.964490	val: 0.814246	test: 0.875809
PRC train: 0.955568	val: 0.794998	test: 0.799679

Epoch: 117
Loss: 0.30667834734274313
ROC train: 0.966744	val: 0.812436	test: 0.877446
PRC train: 0.958590	val: 0.792855	test: 0.798272

Epoch: 118
Loss: 0.2769925992194853
ROC train: 0.969401	val: 0.810075	test: 0.877056
PRC train: 0.962271	val: 0.791671	test: 0.795789

Epoch: 119
Loss: 0.28146662207429063
ROC train: 0.968550	val: 0.808737	test: 0.874172
PRC train: 0.961528	val: 0.792223	test: 0.796807

Epoch: 120
Loss: 0.2645873651475176
ROC train: 0.968686	val: 0.806297	test: 0.874795
PRC train: 0.961617	val: 0.790718	test: 0.804965

Early stopping
Best (ROC):	 train: 0.944580	val: 0.815191	test: 0.876744
Best (PRC):	 train: 0.932690	val: 0.781900	test: 0.809105

ROC train: 0.956712	val: 0.820071	test: 0.882046
PRC train: 0.946651	val: 0.785613	test: 0.824063

Epoch: 95
Loss: 0.30287777485108863
ROC train: 0.960200	val: 0.823613	test: 0.889686
PRC train: 0.950431	val: 0.788079	test: 0.835273

Epoch: 96
Loss: 0.2862049896060801
ROC train: 0.963706	val: 0.821251	test: 0.886022
PRC train: 0.955662	val: 0.796592	test: 0.834651

Epoch: 97
Loss: 0.32913737570115514
ROC train: 0.965812	val: 0.823062	test: 0.884696
PRC train: 0.958165	val: 0.801352	test: 0.834959

Epoch: 98
Loss: 0.2792026241608827
ROC train: 0.963477	val: 0.824400	test: 0.877758
PRC train: 0.953989	val: 0.804449	test: 0.820414

Epoch: 99
Loss: 0.30393720907960053
ROC train: 0.962141	val: 0.813381	test: 0.874094
PRC train: 0.951405	val: 0.782614	test: 0.820636

Epoch: 100
Loss: 0.2887063340050598
ROC train: 0.961392	val: 0.807792	test: 0.878849
PRC train: 0.949858	val: 0.770567	test: 0.828873

Epoch: 101
Loss: 0.30236643975796473
ROC train: 0.960877	val: 0.803148	test: 0.889842
PRC train: 0.949646	val: 0.773642	test: 0.839196

Epoch: 102
Loss: 0.28864278514003405
ROC train: 0.960949	val: 0.801259	test: 0.894987
PRC train: 0.950964	val: 0.775795	test: 0.847545

Epoch: 103
Loss: 0.2989926162956574
ROC train: 0.964244	val: 0.804565	test: 0.892336
PRC train: 0.956538	val: 0.775855	test: 0.849354

Epoch: 104
Loss: 0.30218360867895416
ROC train: 0.965766	val: 0.812043	test: 0.893038
PRC train: 0.958406	val: 0.786774	test: 0.850271

Epoch: 105
Loss: 0.31980914024118656
ROC train: 0.964781	val: 0.814010	test: 0.881656
PRC train: 0.956881	val: 0.796920	test: 0.836448

Epoch: 106
Loss: 0.27789337711018897
ROC train: 0.965184	val: 0.813223	test: 0.874951
PRC train: 0.956463	val: 0.795697	test: 0.827084

Epoch: 107
Loss: 0.31967373807527794
ROC train: 0.967048	val: 0.817316	test: 0.879161
PRC train: 0.959023	val: 0.796463	test: 0.833666

Epoch: 108
Loss: 0.26963466001976116
ROC train: 0.966452	val: 0.822353	test: 0.891557
PRC train: 0.959145	val: 0.795205	test: 0.850464

Epoch: 109
Loss: 0.29063105626067337
ROC train: 0.967490	val: 0.823534	test: 0.894052
PRC train: 0.960882	val: 0.796615	test: 0.853983

Epoch: 110
Loss: 0.3014177549901823
ROC train: 0.968794	val: 0.819520	test: 0.888360
PRC train: 0.962613	val: 0.793710	test: 0.842391

Epoch: 111
Loss: 0.25580711001280343
ROC train: 0.967971	val: 0.816608	test: 0.879629
PRC train: 0.959711	val: 0.794271	test: 0.827913

Epoch: 112
Loss: 0.29050591392451436
ROC train: 0.969584	val: 0.821488	test: 0.877212
PRC train: 0.960745	val: 0.803852	test: 0.821852

Epoch: 113
Loss: 0.29555663984797276
ROC train: 0.967784	val: 0.821802	test: 0.880253
PRC train: 0.958588	val: 0.802400	test: 0.828331

Epoch: 114
Loss: 0.29836206341178756
ROC train: 0.966121	val: 0.817316	test: 0.882046
PRC train: 0.957883	val: 0.789964	test: 0.833654

Epoch: 115
Loss: 0.28425733681481635
ROC train: 0.968291	val: 0.819362	test: 0.886801
PRC train: 0.962399	val: 0.789074	test: 0.840402

Epoch: 116
Loss: 0.26996268421831715
ROC train: 0.968420	val: 0.823140	test: 0.893818
PRC train: 0.962831	val: 0.788804	test: 0.851085

Epoch: 117
Loss: 0.2613447126907325
ROC train: 0.968542	val: 0.819520	test: 0.888360
PRC train: 0.962474	val: 0.784407	test: 0.842720

Epoch: 118
Loss: 0.26289530612337836
ROC train: 0.970234	val: 0.821645	test: 0.882124
PRC train: 0.964471	val: 0.790239	test: 0.833778

Epoch: 119
Loss: 0.2972814873717399
ROC train: 0.972508	val: 0.817946	test: 0.872846
PRC train: 0.966972	val: 0.789537	test: 0.825618

Epoch: 120
Loss: 0.3060412830395291
ROC train: 0.965769	val: 0.811019	test: 0.871989
PRC train: 0.956747	val: 0.772201	test: 0.826661

Early stopping
Best (ROC):	 train: 0.941176	val: 0.825895	test: 0.877992
Best (PRC):	 train: 0.925948	val: 0.802578	test: 0.811903

PRC train: 0.953041	val: 0.777995	test: 0.776871

Epoch: 95
Loss: 0.27275174666240354
ROC train: 0.961441	val: 0.813302	test: 0.857956
PRC train: 0.954054	val: 0.780743	test: 0.782687

Epoch: 96
Loss: 0.28214159050401344
ROC train: 0.962303	val: 0.812672	test: 0.869338
PRC train: 0.955625	val: 0.784208	test: 0.813241

Epoch: 97
Loss: 0.3051536799413951
ROC train: 0.963129	val: 0.808422	test: 0.865830
PRC train: 0.957016	val: 0.782774	test: 0.816907

Epoch: 98
Loss: 0.2830579898904758
ROC train: 0.963023	val: 0.806769	test: 0.868714
PRC train: 0.957141	val: 0.773343	test: 0.819065

Epoch: 99
Loss: 0.28750723131559675
ROC train: 0.964393	val: 0.807871	test: 0.870741
PRC train: 0.959188	val: 0.773082	test: 0.815342

Epoch: 100
Loss: 0.3239943052029971
ROC train: 0.965963	val: 0.810626	test: 0.867389
PRC train: 0.960274	val: 0.780289	test: 0.806467

Epoch: 101
Loss: 0.3152788644009966
ROC train: 0.964343	val: 0.816529	test: 0.863101
PRC train: 0.957140	val: 0.786990	test: 0.802524

Epoch: 102
Loss: 0.3266452738428353
ROC train: 0.962179	val: 0.817080	test: 0.860217
PRC train: 0.953189	val: 0.789403	test: 0.790707

Epoch: 103
Loss: 0.3024611630996327
ROC train: 0.964050	val: 0.814797	test: 0.862166
PRC train: 0.957029	val: 0.786774	test: 0.799211

Epoch: 104
Loss: 0.3181209848132794
ROC train: 0.962881	val: 0.814876	test: 0.868714
PRC train: 0.956580	val: 0.783958	test: 0.806447

Epoch: 105
Loss: 0.2766188208812084
ROC train: 0.963846	val: 0.814325	test: 0.863023
PRC train: 0.958123	val: 0.784897	test: 0.798828

Epoch: 106
Loss: 0.2859914647671423
ROC train: 0.962669	val: 0.808815	test: 0.865128
PRC train: 0.954620	val: 0.781779	test: 0.802484

Epoch: 107
Loss: 0.3131303092834252
ROC train: 0.965952	val: 0.805431	test: 0.874094
PRC train: 0.959951	val: 0.772381	test: 0.812469

Epoch: 108
Loss: 0.2666771975530207
ROC train: 0.966552	val: 0.805588	test: 0.871131
PRC train: 0.961707	val: 0.770088	test: 0.805473

Epoch: 109
Loss: 0.30557263554928776
ROC train: 0.967260	val: 0.809603	test: 0.861464
PRC train: 0.962352	val: 0.787680	test: 0.794796

Epoch: 110
Loss: 0.2692016547582872
ROC train: 0.964009	val: 0.810941	test: 0.854370
PRC train: 0.958323	val: 0.790883	test: 0.789949

Epoch: 111
Loss: 0.3097097690688494
ROC train: 0.964415	val: 0.813144	test: 0.868403
PRC train: 0.958621	val: 0.791332	test: 0.806520

Epoch: 112
Loss: 0.28437646025390395
ROC train: 0.965654	val: 0.812357	test: 0.874951
PRC train: 0.959582	val: 0.780932	test: 0.818879

Epoch: 113
Loss: 0.29261974325025075
ROC train: 0.967299	val: 0.808107	test: 0.877368
PRC train: 0.960977	val: 0.773809	test: 0.836268

Epoch: 114
Loss: 0.28814237997086256
ROC train: 0.967113	val: 0.811649	test: 0.867311
PRC train: 0.960729	val: 0.778335	test: 0.813376

Epoch: 115
Loss: 0.311545279271669
ROC train: 0.967098	val: 0.816057	test: 0.858502
PRC train: 0.960743	val: 0.781152	test: 0.793263

Epoch: 116
Loss: 0.3544453261509132
ROC train: 0.970654	val: 0.820464	test: 0.870040
PRC train: 0.964937	val: 0.785647	test: 0.815440

Epoch: 117
Loss: 0.28278272355122525
ROC train: 0.966938	val: 0.819992	test: 0.873080
PRC train: 0.960349	val: 0.793221	test: 0.819046

Epoch: 118
Loss: 0.3094590971007874
ROC train: 0.956028	val: 0.807713	test: 0.874250
PRC train: 0.948365	val: 0.776366	test: 0.817185

Epoch: 119
Loss: 0.3393562033888015
ROC train: 0.959072	val: 0.805824	test: 0.885086
PRC train: 0.952509	val: 0.778832	test: 0.834562

Epoch: 120
Loss: 0.32363418186449866
ROC train: 0.965852	val: 0.802519	test: 0.870975
PRC train: 0.960255	val: 0.778237	test: 0.814200

Early stopping
Best (ROC):	 train: 0.954354	val: 0.821724	test: 0.884930
Best (PRC):	 train: 0.944106	val: 0.799404	test: 0.828127

PRC train: 0.976951	val: 0.743652	test: 0.811619

Epoch: 95
Loss: 0.2411366016217431
ROC train: 0.979891	val: 0.840884	test: 0.868873
PRC train: 0.976609	val: 0.752525	test: 0.815944

Epoch: 96
Loss: 0.26813874775295443
ROC train: 0.977094	val: 0.848315	test: 0.856793
PRC train: 0.973580	val: 0.744978	test: 0.808572

Epoch: 97
Loss: 0.26416516558324477
ROC train: 0.979770	val: 0.840341	test: 0.853116
PRC train: 0.976526	val: 0.729035	test: 0.803334

Epoch: 98
Loss: 0.2512233202975963
ROC train: 0.980429	val: 0.830011	test: 0.866772
PRC train: 0.976916	val: 0.742854	test: 0.835167

Epoch: 99
Loss: 0.269691090566392
ROC train: 0.978801	val: 0.840884	test: 0.866422
PRC train: 0.974974	val: 0.749804	test: 0.829392

Epoch: 100
Loss: 0.2603932538427185
ROC train: 0.976419	val: 0.849040	test: 0.854692
PRC train: 0.972751	val: 0.764985	test: 0.818471

Epoch: 101
Loss: 0.2687475434162252
ROC train: 0.980273	val: 0.847227	test: 0.868697
PRC train: 0.977118	val: 0.765514	test: 0.819380

Epoch: 102
Loss: 0.2437295615341411
ROC train: 0.981860	val: 0.850308	test: 0.878852
PRC train: 0.979683	val: 0.777310	test: 0.837525

Epoch: 103
Loss: 0.25097704789846453
ROC train: 0.979638	val: 0.848315	test: 0.875875
PRC train: 0.976930	val: 0.767505	test: 0.835502

Epoch: 104
Loss: 0.23918686896548597
ROC train: 0.978479	val: 0.837985	test: 0.875000
PRC train: 0.975240	val: 0.741637	test: 0.830195

Epoch: 105
Loss: 0.2503766008748715
ROC train: 0.982366	val: 0.835629	test: 0.862570
PRC train: 0.980017	val: 0.750762	test: 0.823052

Epoch: 106
Loss: 0.24882436448098905
ROC train: 0.983424	val: 0.841791	test: 0.854867
PRC train: 0.981192	val: 0.760329	test: 0.816833

Epoch: 107
Loss: 0.2547687144194274
ROC train: 0.983371	val: 0.844328	test: 0.852066
PRC train: 0.981224	val: 0.760938	test: 0.809905

Epoch: 108
Loss: 0.24629228869307535
ROC train: 0.984669	val: 0.840159	test: 0.846289
PRC train: 0.982933	val: 0.761149	test: 0.801476

Epoch: 109
Loss: 0.22385327120481008
ROC train: 0.982600	val: 0.846502	test: 0.850665
PRC train: 0.980416	val: 0.768246	test: 0.797783

Epoch: 110
Loss: 0.23504017009189343
ROC train: 0.981569	val: 0.845596	test: 0.854517
PRC train: 0.978822	val: 0.763788	test: 0.806251

Epoch: 111
Loss: 0.24580387840610363
ROC train: 0.982374	val: 0.840522	test: 0.862045
PRC train: 0.979823	val: 0.765856	test: 0.814941

Epoch: 112
Loss: 0.2586339000147407
ROC train: 0.981314	val: 0.841791	test: 0.859419
PRC train: 0.977954	val: 0.750449	test: 0.810925

Epoch: 113
Loss: 0.24945234527517365
ROC train: 0.982547	val: 0.836897	test: 0.855742
PRC train: 0.979824	val: 0.746009	test: 0.800093

Epoch: 114
Loss: 0.22640458292175697
ROC train: 0.981322	val: 0.826205	test: 0.852766
PRC train: 0.978597	val: 0.736482	test: 0.794200

Epoch: 115
Loss: 0.2339164901270613
ROC train: 0.981580	val: 0.838166	test: 0.862220
PRC train: 0.978635	val: 0.751233	test: 0.820245

Epoch: 116
Loss: 0.2175496174023243
ROC train: 0.982363	val: 0.849402	test: 0.860294
PRC train: 0.979348	val: 0.766929	test: 0.813914

Epoch: 117
Loss: 0.22221805958108756
ROC train: 0.984299	val: 0.853570	test: 0.857843
PRC train: 0.982105	val: 0.772518	test: 0.788332

Epoch: 118
Loss: 0.23046622560706656
ROC train: 0.985368	val: 0.850308	test: 0.862570
PRC train: 0.983379	val: 0.772784	test: 0.809079

Epoch: 119
Loss: 0.23059446316351068
ROC train: 0.983941	val: 0.842878	test: 0.862395
PRC train: 0.981771	val: 0.758390	test: 0.814543

Epoch: 120
Loss: 0.23179164774860964
ROC train: 0.986153	val: 0.837985	test: 0.848915
PRC train: 0.984260	val: 0.755610	test: 0.801815

Early stopping
Best (ROC):	 train: 0.965507	val: 0.853933	test: 0.877101
Best (PRC):	 train: 0.958667	val: 0.784675	test: 0.838698
All runs completed.

PRC train: 0.982521	val: 0.798484	test: 0.778757

Epoch: 95
Loss: 0.21867249461150295
ROC train: 0.985946	val: 0.822383	test: 0.838638
PRC train: 0.982731	val: 0.787707	test: 0.779347

Epoch: 96
Loss: 0.2234093184631456
ROC train: 0.986656	val: 0.826070	test: 0.838815
PRC train: 0.983763	val: 0.791788	test: 0.779940

Epoch: 97
Loss: 0.21368028631509675
ROC train: 0.984638	val: 0.828703	test: 0.843899
PRC train: 0.981071	val: 0.788871	test: 0.787116

Epoch: 98
Loss: 0.2186382570227577
ROC train: 0.982413	val: 0.827474	test: 0.839744
PRC train: 0.977998	val: 0.787239	test: 0.776188

Epoch: 99
Loss: 0.21229167430198284
ROC train: 0.985956	val: 0.833355	test: 0.833466
PRC train: 0.982861	val: 0.800807	test: 0.766324

Epoch: 100
Loss: 0.2335003887480108
ROC train: 0.988033	val: 0.835681	test: 0.829266
PRC train: 0.985441	val: 0.801515	test: 0.769800

Epoch: 101
Loss: 0.2155335107754477
ROC train: 0.987979	val: 0.833311	test: 0.834748
PRC train: 0.985671	val: 0.795687	test: 0.778669

Epoch: 102
Loss: 0.2144762598287602
ROC train: 0.986465	val: 0.830810	test: 0.836030
PRC train: 0.983364	val: 0.799554	test: 0.780822

Epoch: 103
Loss: 0.21104143992790592
ROC train: 0.987714	val: 0.827781	test: 0.835721
PRC train: 0.985096	val: 0.797438	test: 0.781804

Epoch: 104
Loss: 0.21527684565838856
ROC train: 0.990282	val: 0.834233	test: 0.831565
PRC train: 0.988388	val: 0.807589	test: 0.773743

Epoch: 105
Loss: 0.2103308712104549
ROC train: 0.986700	val: 0.828659	test: 0.825906
PRC train: 0.983732	val: 0.797228	test: 0.765417

Epoch: 106
Loss: 0.18145299172183155
ROC train: 0.984704	val: 0.825543	test: 0.832493
PRC train: 0.981017	val: 0.789638	test: 0.774135

Epoch: 107
Loss: 0.22697768031924742
ROC train: 0.986877	val: 0.829449	test: 0.839257
PRC train: 0.984142	val: 0.797521	test: 0.780732

Epoch: 108
Loss: 0.2042622169472302
ROC train: 0.988854	val: 0.835418	test: 0.844032
PRC train: 0.986473	val: 0.808092	test: 0.784683

Epoch: 109
Loss: 0.21789872857828488
ROC train: 0.986989	val: 0.831161	test: 0.842529
PRC train: 0.984148	val: 0.795628	test: 0.784588

Epoch: 110
Loss: 0.207495334228465
ROC train: 0.986803	val: 0.827167	test: 0.838948
PRC train: 0.983826	val: 0.788199	test: 0.780476

Epoch: 111
Loss: 0.20355586774385884
ROC train: 0.989089	val: 0.827035	test: 0.831432
PRC train: 0.986714	val: 0.792980	test: 0.772802

Epoch: 112
Loss: 0.20814292114181338
ROC train: 0.987555	val: 0.830020	test: 0.832095
PRC train: 0.984890	val: 0.794544	test: 0.773576

Epoch: 113
Loss: 0.1857589677247372
ROC train: 0.989140	val: 0.836998	test: 0.839346
PRC train: 0.986235	val: 0.811291	test: 0.780666

Epoch: 114
Loss: 0.19494054587706877
ROC train: 0.988141	val: 0.833004	test: 0.848630
PRC train: 0.985115	val: 0.802020	test: 0.794185

Epoch: 115
Loss: 0.2349855660669076
ROC train: 0.989968	val: 0.833882	test: 0.850177
PRC train: 0.987698	val: 0.796859	test: 0.795682

Epoch: 116
Loss: 0.21227726430367544
ROC train: 0.991159	val: 0.837920	test: 0.846021
PRC train: 0.989293	val: 0.807363	test: 0.787226

Epoch: 117
Loss: 0.21377088719497433
ROC train: 0.988937	val: 0.831731	test: 0.844916
PRC train: 0.986344	val: 0.803676	test: 0.784769

Epoch: 118
Loss: 0.2102457864939631
ROC train: 0.988680	val: 0.834716	test: 0.849204
PRC train: 0.986066	val: 0.807558	test: 0.787125

Epoch: 119
Loss: 0.2040135293271864
ROC train: 0.989013	val: 0.830459	test: 0.840141
PRC train: 0.986645	val: 0.800808	test: 0.775902

Epoch: 120
Loss: 0.19802047054347452
ROC train: 0.987509	val: 0.827430	test: 0.833908
PRC train: 0.984374	val: 0.796074	test: 0.767621

Epoch: 121
Loss: 0.20705749810170465
ROC train: 0.989664	val: 0.837261	test: 0.831874
PRC train: 0.987260	val: 0.809140	test: 0.765283

Epoch: 122
Loss: 0.20248118242457108
ROC train: 0.989444	val: 0.835901	test: 0.833201
PRC train: 0.987069	val: 0.808317	test: 0.772529

Epoch: 123
Loss: 0.18858365194561114
ROC train: 0.989596	val: 0.828528	test: 0.834129
PRC train: 0.987201	val: 0.793177	test: 0.775731

Epoch: 124
Loss: 0.20257307020156612
ROC train: 0.991703	val: 0.827694	test: 0.836649
PRC train: 0.989806	val: 0.790281	test: 0.772742

Epoch: 125
Loss: 0.18509640485632367
ROC train: 0.993359	val: 0.827211	test: 0.841158
PRC train: 0.991976	val: 0.791265	test: 0.773588

Epoch: 126
Loss: 0.1685563534033107
ROC train: 0.994383	val: 0.823875	test: 0.845623
PRC train: 0.993532	val: 0.788559	test: 0.781804

Epoch: 127
Loss: 0.16300433810026152
ROC train: 0.993773	val: 0.818521	test: 0.843988
PRC train: 0.992642	val: 0.782804	test: 0.785691

Epoch: 128
Loss: 0.197997987404449
ROC train: 0.992597	val: 0.818477	test: 0.845623
PRC train: 0.991176	val: 0.780433	test: 0.790287

Epoch: 129
Loss: 0.19198767203441633
ROC train: 0.992320	val: 0.824226	test: 0.843103
PRC train: 0.990757	val: 0.784687	test: 0.788628

Epoch: 130
Loss: 0.20331481287876182
ROC train: 0.992095	val: 0.830283	test: 0.842573
PRC train: 0.990435	val: 0.791725	test: 0.781804

Epoch: 131
Loss: 0.19770107317695168
ROC train: 0.993611	val: 0.839719	test: 0.839523
PRC train: 0.992329	val: 0.808313	test: 0.776354

Epoch: 132
Loss: 0.20301541494243755
ROC train: 0.991904	val: 0.838051	test: 0.831123
PRC train: 0.990114	val: 0.809201	test: 0.766466

Epoch: 133
Loss: 0.16741346812918032
ROC train: 0.991855	val: 0.833662	test: 0.832361
PRC train: 0.990193	val: 0.801493	test: 0.772225

Epoch: 134
Loss: 0.18733470669736518
ROC train: 0.990573	val: 0.831775	test: 0.835234
PRC train: 0.988583	val: 0.797483	test: 0.777026

Epoch: 135
Loss: 0.18668465513051702
ROC train: 0.993996	val: 0.835418	test: 0.838152
PRC train: 0.992893	val: 0.800273	test: 0.776127

Epoch: 136
Loss: 0.16619943195685338
ROC train: 0.994682	val: 0.836471	test: 0.837091
PRC train: 0.993608	val: 0.810351	test: 0.778309

Epoch: 137
Loss: 0.16006735851771836
ROC train: 0.995201	val: 0.835813	test: 0.840849
PRC train: 0.994234	val: 0.806737	test: 0.784238

Epoch: 138
Loss: 0.16256647552387923
ROC train: 0.994118	val: 0.836340	test: 0.844209
PRC train: 0.992853	val: 0.801720	test: 0.786180

Epoch: 139
Loss: 0.17290118670375854
ROC train: 0.995404	val: 0.841080	test: 0.838019
PRC train: 0.994351	val: 0.804178	test: 0.773067

Epoch: 140
Loss: 0.15039870361197466
ROC train: 0.995103	val: 0.837876	test: 0.832582
PRC train: 0.994213	val: 0.802281	test: 0.768478

Epoch: 141
Loss: 0.19406783247872822
ROC train: 0.994451	val: 0.831995	test: 0.836074
PRC train: 0.993385	val: 0.795754	test: 0.774922

Epoch: 142
Loss: 0.16473036638832209
ROC train: 0.993462	val: 0.832609	test: 0.837224
PRC train: 0.992153	val: 0.804510	test: 0.776469

Epoch: 143
Loss: 0.18893417278659144
ROC train: 0.993849	val: 0.833662	test: 0.838550
PRC train: 0.992786	val: 0.802384	test: 0.776506

Epoch: 144
Loss: 0.17153373223768964
ROC train: 0.993719	val: 0.831556	test: 0.842573
PRC train: 0.992312	val: 0.794817	test: 0.781302

Epoch: 145
Loss: 0.1723092189615233
ROC train: 0.994515	val: 0.829361	test: 0.841910
PRC train: 0.993252	val: 0.795395	test: 0.780807

Epoch: 146
Loss: 0.19134076886338658
ROC train: 0.995691	val: 0.838490	test: 0.840981
PRC train: 0.994882	val: 0.812174	test: 0.777933

Epoch: 147
Loss: 0.1931832396062351
ROC train: 0.995093	val: 0.841738	test: 0.840805
PRC train: 0.994248	val: 0.817637	test: 0.776728

Epoch: 148
Loss: 0.15320700548971225
ROC train: 0.994260	val: 0.837525	test: 0.841866
PRC train: 0.993446	val: 0.802712	test: 0.778502

Epoch: 149
Loss: 0.18361029609342389
ROC train: 0.994402	val: 0.830766	test: 0.841070
PRC train: 0.993413	val: 0.795281	test: 0.780778

Epoch: 150
Loss: 0.16987474298360788
ROC train: 0.992741	val: 0.832960	test: 0.838594
PRC train: 0.991069	val: 0.805069	test: 0.773274

Epoch: 151
Loss: 0.19714451258464177
ROC train: 0.995360	val: 0.836603	test: 0.837003
PRC train: 0.994394	val: 0.806400	test: 0.775750

Epoch: 152
Loss: 0.17194083271883
ROC train: 0.994623	val: 0.829976	test: 0.841158
PRC train: 0.993572	val: 0.791121	test: 0.782745

Epoch: 153
Loss: 0.1699128302414837
ROC train: 0.995049	val: 0.831205	test: 0.844607
PRC train: 0.994122	val: 0.794785	test: 0.786447

Epoch: 154
Loss: 0.1533427100497553
ROC train: 0.995323	val: 0.831907	test: 0.844828
PRC train: 0.994441	val: 0.796432	test: 0.788733

Epoch: 155
Loss: 0.1521629619196766
PRC train: 0.980348	val: 0.780314	test: 0.773057

Epoch: 95
Loss: 0.22421318556603062
ROC train: 0.986762	val: 0.811982	test: 0.835765
PRC train: 0.984382	val: 0.786911	test: 0.771366

Epoch: 96
Loss: 0.2165100639593376
ROC train: 0.986056	val: 0.810314	test: 0.835455
PRC train: 0.983633	val: 0.778473	test: 0.777438

Epoch: 97
Loss: 0.23250813318084135
ROC train: 0.986830	val: 0.815317	test: 0.834615
PRC train: 0.984414	val: 0.787523	test: 0.776621

Epoch: 98
Loss: 0.22341372997218434
ROC train: 0.987244	val: 0.818038	test: 0.833687
PRC train: 0.984959	val: 0.788419	test: 0.773659

Epoch: 99
Loss: 0.2402362048671084
ROC train: 0.987629	val: 0.815493	test: 0.835146
PRC train: 0.985330	val: 0.781869	test: 0.770457

Epoch: 100
Loss: 0.2369114343813676
ROC train: 0.986044	val: 0.816546	test: 0.837622
PRC train: 0.983283	val: 0.786390	test: 0.770272

Epoch: 101
Loss: 0.21574539748511007
ROC train: 0.986294	val: 0.822427	test: 0.839523
PRC train: 0.983478	val: 0.794520	test: 0.770881

Epoch: 102
Loss: 0.24135933065052784
ROC train: 0.987631	val: 0.824007	test: 0.838064
PRC train: 0.985373	val: 0.796531	test: 0.769300

Epoch: 103
Loss: 0.1855461302370293
ROC train: 0.988273	val: 0.819750	test: 0.834350
PRC train: 0.986088	val: 0.789270	test: 0.762217

Epoch: 104
Loss: 0.22248821603321825
ROC train: 0.988827	val: 0.820891	test: 0.832095
PRC train: 0.986742	val: 0.798458	test: 0.766763

Epoch: 105
Loss: 0.21411850537553845
ROC train: 0.988859	val: 0.826728	test: 0.832228
PRC train: 0.986891	val: 0.809681	test: 0.765184

Epoch: 106
Loss: 0.21477399952001394
ROC train: 0.989684	val: 0.828835	test: 0.839169
PRC train: 0.987740	val: 0.809174	test: 0.770913

Epoch: 107
Loss: 0.21828969058056039
ROC train: 0.990326	val: 0.826377	test: 0.839655
PRC train: 0.988728	val: 0.799522	test: 0.770553

Epoch: 108
Loss: 0.21053163454138782
ROC train: 0.990034	val: 0.825368	test: 0.837268
PRC train: 0.988458	val: 0.793500	test: 0.765345

Epoch: 109
Loss: 0.20185375790993423
ROC train: 0.987964	val: 0.831161	test: 0.830681
PRC train: 0.986232	val: 0.800121	test: 0.759256

Epoch: 110
Loss: 0.2112789703808523
ROC train: 0.988542	val: 0.831029	test: 0.830327
PRC train: 0.986620	val: 0.800886	test: 0.758823

Epoch: 111
Loss: 0.21699072277298925
ROC train: 0.990399	val: 0.828089	test: 0.838285
PRC train: 0.988748	val: 0.804172	test: 0.765048

Epoch: 112
Loss: 0.1955106696217601
ROC train: 0.990664	val: 0.826772	test: 0.837489
PRC train: 0.988880	val: 0.799465	test: 0.763523

Epoch: 113
Loss: 0.21397647369453032
ROC train: 0.990370	val: 0.828396	test: 0.837798
PRC train: 0.988598	val: 0.804227	test: 0.762991

Epoch: 114
Loss: 0.17865637050192712
ROC train: 0.991531	val: 0.830151	test: 0.840716
PRC train: 0.989950	val: 0.812827	test: 0.767546

Epoch: 115
Loss: 0.19106944939673506
ROC train: 0.991595	val: 0.828615	test: 0.841689
PRC train: 0.990115	val: 0.814159	test: 0.768856

Epoch: 116
Loss: 0.19107527695696985
ROC train: 0.990110	val: 0.818609	test: 0.841910
PRC train: 0.988102	val: 0.790761	test: 0.772461

Epoch: 117
Loss: 0.2011931652611385
ROC train: 0.991933	val: 0.817160	test: 0.842794
PRC train: 0.990418	val: 0.781973	test: 0.765914

Epoch: 118
Loss: 0.1934303917001132
ROC train: 0.989748	val: 0.821549	test: 0.840141
PRC train: 0.988227	val: 0.790076	test: 0.752202

Epoch: 119
Loss: 0.208510240880837
ROC train: 0.990843	val: 0.823480	test: 0.837622
PRC train: 0.989834	val: 0.790791	test: 0.746491

Epoch: 120
Loss: 0.20090337385150825
ROC train: 0.990914	val: 0.825763	test: 0.838064
PRC train: 0.989687	val: 0.783799	test: 0.757733

Epoch: 121
Loss: 0.18279335667339155
ROC train: 0.990395	val: 0.832609	test: 0.842706
PRC train: 0.989144	val: 0.791361	test: 0.767457

Epoch: 122
Loss: 0.20354774216307803
ROC train: 0.990831	val: 0.835286	test: 0.843369
PRC train: 0.989297	val: 0.798708	test: 0.766979

Epoch: 123
Loss: 0.22581930712364473
ROC train: 0.991997	val: 0.828001	test: 0.837445
PRC train: 0.990592	val: 0.797032	test: 0.767676

Epoch: 124
Loss: 0.20524461758639834
ROC train: 0.989787	val: 0.822515	test: 0.832361
PRC train: 0.988020	val: 0.798292	test: 0.769386

Epoch: 125
Loss: 0.2037371081144733
ROC train: 0.990135	val: 0.821856	test: 0.836914
PRC train: 0.987967	val: 0.786003	test: 0.772809

Epoch: 126
Loss: 0.1715968574063845
ROC train: 0.988920	val: 0.820979	test: 0.838948
PRC train: 0.986462	val: 0.780556	test: 0.771774

Epoch: 127
Loss: 0.2035866885364382
ROC train: 0.991004	val: 0.820057	test: 0.837798
PRC train: 0.989300	val: 0.788526	test: 0.769729

Epoch: 128
Loss: 0.21690942808099095
ROC train: 0.992149	val: 0.821418	test: 0.836649
PRC train: 0.990710	val: 0.793715	test: 0.767355

Epoch: 129
Loss: 0.22857380767736654
ROC train: 0.991678	val: 0.826991	test: 0.840053
PRC train: 0.990112	val: 0.795956	test: 0.771791

Epoch: 130
Loss: 0.19679371676565474
ROC train: 0.991997	val: 0.834145	test: 0.838108
PRC train: 0.990695	val: 0.802823	test: 0.765194

Epoch: 131
Loss: 0.21092575229006344
ROC train: 0.992144	val: 0.832126	test: 0.840053
PRC train: 0.990702	val: 0.806513	test: 0.760884

Epoch: 132
Loss: 0.19652959116679758
ROC train: 0.993408	val: 0.823875	test: 0.837931
PRC train: 0.992117	val: 0.792115	test: 0.751753

Epoch: 133
Loss: 0.19395934933312875
ROC train: 0.993741	val: 0.823480	test: 0.836428
PRC train: 0.992565	val: 0.792857	test: 0.750794

Epoch: 134
Loss: 0.17588222002478499
ROC train: 0.992281	val: 0.827211	test: 0.839390
PRC train: 0.990882	val: 0.801717	test: 0.763102

Epoch: 135
Loss: 0.18004437422504052
ROC train: 0.991806	val: 0.826904	test: 0.842485
PRC train: 0.990212	val: 0.801423	test: 0.767587

Epoch: 136
Loss: 0.18813562016453894
ROC train: 0.991659	val: 0.821725	test: 0.843722
PRC train: 0.989981	val: 0.784807	test: 0.768209

Epoch: 137
Loss: 0.1747344638629727
ROC train: 0.992930	val: 0.829054	test: 0.846286
PRC train: 0.991460	val: 0.794441	test: 0.769643

Epoch: 138
Loss: 0.1876026939351712
ROC train: 0.993981	val: 0.832697	test: 0.845756
PRC train: 0.992893	val: 0.799188	test: 0.771660

Epoch: 139
Loss: 0.1590953827249583
ROC train: 0.993479	val: 0.821110	test: 0.844828
PRC train: 0.992247	val: 0.786294	test: 0.780727

Epoch: 140
Loss: 0.2015719008950451
ROC train: 0.992021	val: 0.818302	test: 0.850531
PRC train: 0.990337	val: 0.783752	test: 0.788270

Epoch: 141
Loss: 0.16677393416717223
ROC train: 0.992134	val: 0.822032	test: 0.850486
PRC train: 0.990503	val: 0.791686	test: 0.783924

Epoch: 142
Loss: 0.1742441302164715
ROC train: 0.994113	val: 0.826465	test: 0.842352
PRC train: 0.993142	val: 0.804695	test: 0.774415

Epoch: 143
Loss: 0.17354315749056595
ROC train: 0.993699	val: 0.823524	test: 0.837975
PRC train: 0.992349	val: 0.797519	test: 0.770175

Epoch: 144
Loss: 0.20110471858592677
ROC train: 0.992683	val: 0.824358	test: 0.833908
PRC train: 0.991178	val: 0.793412	test: 0.765322

Epoch: 145
Loss: 0.19055818041792105
ROC train: 0.993052	val: 0.825148	test: 0.836118
PRC train: 0.991846	val: 0.786441	test: 0.769098

Epoch: 146
Loss: 0.1900506191424386
ROC train: 0.992224	val: 0.831951	test: 0.838815
PRC train: 0.990783	val: 0.797987	test: 0.770271

Epoch: 147
Loss: 0.1875337317239209
ROC train: 0.991957	val: 0.833224	test: 0.837622
PRC train: 0.990587	val: 0.801368	test: 0.769726

Epoch: 148
Loss: 0.16095667434707284
ROC train: 0.994642	val: 0.827650	test: 0.837666
PRC train: 0.993725	val: 0.793484	test: 0.771196

Epoch: 149
Loss: 0.16679008232970535
ROC train: 0.995142	val: 0.814878	test: 0.839080
PRC train: 0.994353	val: 0.775107	test: 0.776541

Epoch: 150
Loss: 0.18532573693517737
ROC train: 0.994782	val: 0.816590	test: 0.844607
PRC train: 0.993931	val: 0.782784	test: 0.779595

Epoch: 151
Loss: 0.18353761268865965
ROC train: 0.994290	val: 0.815624	test: 0.838594
PRC train: 0.993319	val: 0.775366	test: 0.767874

Epoch: 152
Loss: 0.15260835466505157
ROC train: 0.992741	val: 0.810621	test: 0.836472
PRC train: 0.991510	val: 0.761859	test: 0.769195

Epoch: 153
Loss: 0.17749046807055818
ROC train: 0.994495	val: 0.817907	test: 0.836693
PRC train: 0.993471	val: 0.774065	test: 0.777193

Epoch: 154
Loss: 0.15340299624033693
ROC train: 0.995304	val: 0.824358	test: 0.842175
PRC train: 0.994397	val: 0.782333	test: 0.782826

Epoch: 155
Loss: 0.19203988759094218
ROC train: 0.995730	val: 0.826289	test: 0.847392
PRC train: 0.994961	val: 0.785995	test: 0.785626

Epoch: 156
Loss: 0.16929140516972147
ROC train: 0.994971	val: 0.823261	test: 0.849956
PRC train: 0.994011	val: 0.781862	test: 0.790408

Epoch: 157
Loss: 0.17759518178139785
ROC train: 0.995235	val: 0.826904	test: 0.849116
PRC train: 0.994404	val: 0.788876	test: 0.789220

Early stopping
Best (ROC):	 train: 0.990831	val: 0.835286	test: 0.843369
Best (PRC):	 train: 0.989297	val: 0.798708	test: 0.766979

PRC train: 0.974621	val: 0.754089	test: 0.795047

Epoch: 95
Loss: 0.24597874089280403
ROC train: 0.977109	val: 0.839435	test: 0.841912
PRC train: 0.973895	val: 0.758435	test: 0.797464

Epoch: 96
Loss: 0.2655634786427939
ROC train: 0.975603	val: 0.841791	test: 0.840686
PRC train: 0.972732	val: 0.762047	test: 0.803256

Epoch: 97
Loss: 0.2837182754129632
ROC train: 0.977338	val: 0.839253	test: 0.839636
PRC train: 0.974651	val: 0.754136	test: 0.797702

Epoch: 98
Loss: 0.25549792862494847
ROC train: 0.976679	val: 0.842515	test: 0.855917
PRC train: 0.973074	val: 0.754026	test: 0.808235

Epoch: 99
Loss: 0.2664124976911821
ROC train: 0.977089	val: 0.848496	test: 0.847514
PRC train: 0.973710	val: 0.773037	test: 0.810862

Epoch: 100
Loss: 0.25597059492715407
ROC train: 0.978346	val: 0.838891	test: 0.832983
PRC train: 0.975543	val: 0.757132	test: 0.794587

Epoch: 101
Loss: 0.2480314868004073
ROC train: 0.981592	val: 0.834723	test: 0.835259
PRC train: 0.978989	val: 0.747166	test: 0.789295

Epoch: 102
Loss: 0.24959817688544428
ROC train: 0.979745	val: 0.846321	test: 0.849965
PRC train: 0.976580	val: 0.762521	test: 0.803612

Epoch: 103
Loss: 0.24367510400226738
ROC train: 0.981415	val: 0.843059	test: 0.844013
PRC train: 0.978411	val: 0.748636	test: 0.795083

Epoch: 104
Loss: 0.25314306938301523
ROC train: 0.980940	val: 0.844509	test: 0.838585
PRC train: 0.978213	val: 0.740627	test: 0.791525

Epoch: 105
Loss: 0.2588175162317551
ROC train: 0.981513	val: 0.839072	test: 0.842787
PRC train: 0.979186	val: 0.736830	test: 0.798518

Epoch: 106
Loss: 0.26198394559142324
ROC train: 0.982342	val: 0.835085	test: 0.856968
PRC train: 0.979892	val: 0.750250	test: 0.806055

Epoch: 107
Loss: 0.2552289212954993
ROC train: 0.982624	val: 0.839616	test: 0.859419
PRC train: 0.980082	val: 0.758713	test: 0.807184

Epoch: 108
Loss: 0.25722911108833796
ROC train: 0.981292	val: 0.847952	test: 0.859419
PRC train: 0.978669	val: 0.770234	test: 0.808729

Epoch: 109
Loss: 0.25527970698368124
ROC train: 0.980589	val: 0.844509	test: 0.853466
PRC train: 0.977800	val: 0.772233	test: 0.799399

Epoch: 110
Loss: 0.25363495060734237
ROC train: 0.982272	val: 0.835266	test: 0.843662
PRC train: 0.979620	val: 0.762588	test: 0.787360

Epoch: 111
Loss: 0.24435972620994528
ROC train: 0.983159	val: 0.832548	test: 0.846113
PRC train: 0.980626	val: 0.742203	test: 0.799293

Epoch: 112
Loss: 0.24417515842726903
ROC train: 0.982558	val: 0.841972	test: 0.841036
PRC train: 0.979898	val: 0.751838	test: 0.797209

Epoch: 113
Loss: 0.2513578601429027
ROC train: 0.982616	val: 0.834360	test: 0.849440
PRC train: 0.980146	val: 0.762217	test: 0.798297

Epoch: 114
Loss: 0.23338202679128245
ROC train: 0.983606	val: 0.831642	test: 0.855217
PRC train: 0.981517	val: 0.752652	test: 0.794842

Epoch: 115
Loss: 0.23300416828532367
ROC train: 0.981822	val: 0.835266	test: 0.843838
PRC train: 0.979062	val: 0.737641	test: 0.791765

Epoch: 116
Loss: 0.24187607091734648
ROC train: 0.980256	val: 0.841066	test: 0.828782
PRC train: 0.977012	val: 0.729293	test: 0.776182

Epoch: 117
Loss: 0.24944927215959783
ROC train: 0.981675	val: 0.833454	test: 0.836134
PRC train: 0.978318	val: 0.729591	test: 0.754550

Epoch: 118
Loss: 0.24984122496863564
ROC train: 0.984255	val: 0.825843	test: 0.848214
PRC train: 0.981122	val: 0.740242	test: 0.778403

Epoch: 119
Loss: 0.22665072167437436
ROC train: 0.983613	val: 0.834542	test: 0.839111
PRC train: 0.980979	val: 0.748935	test: 0.786572

Epoch: 120
Loss: 0.22459517442632732
ROC train: 0.983775	val: 0.831642	test: 0.840686
PRC train: 0.981473	val: 0.749949	test: 0.783551

Epoch: 121
Loss: 0.25301169519990074
ROC train: 0.984991	val: 0.837260	test: 0.849965
PRC train: 0.982775	val: 0.767047	test: 0.791356

Epoch: 122
Loss: 0.2408383306431428
ROC train: 0.986203	val: 0.838347	test: 0.837710
PRC train: 0.983975	val: 0.776096	test: 0.785404

Epoch: 123
Loss: 0.23769755726812897
ROC train: 0.984677	val: 0.833273	test: 0.838410
PRC train: 0.982233	val: 0.752431	test: 0.784293

Epoch: 124
Loss: 0.2553097726420356
ROC train: 0.983703	val: 0.825480	test: 0.854342
PRC train: 0.981269	val: 0.744529	test: 0.793684

Epoch: 125
Loss: 0.2344531717732859
ROC train: 0.985693	val: 0.835266	test: 0.845238
PRC train: 0.983599	val: 0.750024	test: 0.789641

Epoch: 126
Loss: 0.25171979363927494
ROC train: 0.985758	val: 0.835085	test: 0.827031
PRC train: 0.983689	val: 0.747091	test: 0.772926

Epoch: 127
Loss: 0.22550449782940424
ROC train: 0.986746	val: 0.834179	test: 0.836660
PRC train: 0.984571	val: 0.750905	test: 0.789014

Epoch: 128
Loss: 0.21332018202307418
ROC train: 0.984568	val: 0.830192	test: 0.839461
PRC train: 0.982475	val: 0.747495	test: 0.787612

Epoch: 129
Loss: 0.23065041661279487
ROC train: 0.985944	val: 0.829467	test: 0.842437
PRC train: 0.984147	val: 0.747247	test: 0.787498

Epoch: 130
Loss: 0.21447047605703098
ROC train: 0.988055	val: 0.829105	test: 0.848739
PRC train: 0.986635	val: 0.748177	test: 0.791029

Epoch: 131
Loss: 0.23115679753034746
ROC train: 0.987059	val: 0.826205	test: 0.847339
PRC train: 0.985310	val: 0.741037	test: 0.787880

Epoch: 132
Loss: 0.21864753327334813
ROC train: 0.985867	val: 0.814244	test: 0.830882
PRC train: 0.984092	val: 0.718620	test: 0.772121

Epoch: 133
Loss: 0.22506762051755244
ROC train: 0.986170	val: 0.820950	test: 0.828431
PRC train: 0.984120	val: 0.732089	test: 0.774761

Epoch: 134
Loss: 0.22062235150704096
ROC train: 0.987460	val: 0.824393	test: 0.845588
PRC train: 0.985580	val: 0.745000	test: 0.786149

Early stopping
Best (ROC):	 train: 0.977089	val: 0.848496	test: 0.847514
Best (PRC):	 train: 0.973710	val: 0.773037	test: 0.810862

ROC train: 0.995372	val: 0.829098	test: 0.840805
PRC train: 0.994473	val: 0.787669	test: 0.786732

Epoch: 156
Loss: 0.15455267144821874
ROC train: 0.996051	val: 0.829361	test: 0.836516
PRC train: 0.995350	val: 0.790098	test: 0.776516

Epoch: 157
Loss: 0.16184843443666516
ROC train: 0.995745	val: 0.826114	test: 0.840230
PRC train: 0.994990	val: 0.786382	test: 0.782241

Epoch: 158
Loss: 0.15495237575344717
ROC train: 0.994691	val: 0.821549	test: 0.847126
PRC train: 0.993742	val: 0.779050	test: 0.790784

Epoch: 159
Loss: 0.15585940860201566
ROC train: 0.995632	val: 0.822690	test: 0.852697
PRC train: 0.994890	val: 0.780290	test: 0.798477

Epoch: 160
Loss: 0.17247228989591884
ROC train: 0.997558	val: 0.833619	test: 0.850752
PRC train: 0.997185	val: 0.799273	test: 0.792854

Epoch: 161
Loss: 0.157276001234065
ROC train: 0.997080	val: 0.839763	test: 0.842175
PRC train: 0.996589	val: 0.812914	test: 0.778464

Epoch: 162
Loss: 0.16227836744513444
ROC train: 0.996788	val: 0.838183	test: 0.837401
PRC train: 0.996254	val: 0.806605	test: 0.772424

Epoch: 163
Loss: 0.15494898977997035
ROC train: 0.995970	val: 0.830327	test: 0.838948
PRC train: 0.995296	val: 0.797494	test: 0.775853

Epoch: 164
Loss: 0.15389889071170035
ROC train: 0.996867	val: 0.831293	test: 0.843634
PRC train: 0.996347	val: 0.797048	test: 0.783954

Epoch: 165
Loss: 0.15470091740734235
ROC train: 0.996703	val: 0.829581	test: 0.847613
PRC train: 0.996171	val: 0.790475	test: 0.791508

Epoch: 166
Loss: 0.15368960651310737
ROC train: 0.997190	val: 0.829800	test: 0.848099
PRC train: 0.996746	val: 0.785269	test: 0.794553

Epoch: 167
Loss: 0.15686433459159607
ROC train: 0.997166	val: 0.826860	test: 0.847966
PRC train: 0.996696	val: 0.772242	test: 0.789965

Epoch: 168
Loss: 0.16212056326905822
ROC train: 0.997308	val: 0.825938	test: 0.848630
PRC train: 0.996904	val: 0.770797	test: 0.787357

Epoch: 169
Loss: 0.16281977818681925
ROC train: 0.997352	val: 0.828747	test: 0.840495
PRC train: 0.996880	val: 0.785518	test: 0.776840

Epoch: 170
Loss: 0.13297699988427733
ROC train: 0.997347	val: 0.830327	test: 0.836074
PRC train: 0.996850	val: 0.793248	test: 0.774378

Epoch: 171
Loss: 0.14785814375842704
ROC train: 0.997175	val: 0.829932	test: 0.836737
PRC train: 0.996630	val: 0.796530	test: 0.778901

Epoch: 172
Loss: 0.14469377707364928
ROC train: 0.997506	val: 0.830810	test: 0.838108
PRC train: 0.997030	val: 0.794492	test: 0.779236

Epoch: 173
Loss: 0.14949891754599695
ROC train: 0.996725	val: 0.834496	test: 0.842131
PRC train: 0.996066	val: 0.795277	test: 0.782201

Epoch: 174
Loss: 0.1451135213576345
ROC train: 0.997156	val: 0.835374	test: 0.848055
PRC train: 0.996663	val: 0.798062	test: 0.791179

Epoch: 175
Loss: 0.1503314111350441
ROC train: 0.997200	val: 0.833750	test: 0.849293
PRC train: 0.996741	val: 0.799505	test: 0.794088

Epoch: 176
Loss: 0.1571459928003613
ROC train: 0.996808	val: 0.824051	test: 0.848099
PRC train: 0.996206	val: 0.778883	test: 0.799830

Epoch: 177
Loss: 0.15265886583009555
ROC train: 0.996563	val: 0.820759	test: 0.841600
PRC train: 0.995762	val: 0.772585	test: 0.789848

Epoch: 178
Loss: 0.142523605535846
ROC train: 0.997778	val: 0.829625	test: 0.843192
PRC train: 0.997383	val: 0.788904	test: 0.786093

Epoch: 179
Loss: 0.14820860207333136
ROC train: 0.996627	val: 0.830503	test: 0.842706
PRC train: 0.996016	val: 0.793480	test: 0.783852

Epoch: 180
Loss: 0.14094651427148663
ROC train: 0.995426	val: 0.828176	test: 0.847436
PRC train: 0.994534	val: 0.789280	test: 0.789619

Epoch: 181
Loss: 0.14523387951451697
ROC train: 0.994976	val: 0.829361	test: 0.846640
PRC train: 0.994055	val: 0.790206	test: 0.790172

Epoch: 182
Loss: 0.13315690670928107
ROC train: 0.996605	val: 0.830371	test: 0.842042
PRC train: 0.996209	val: 0.793094	test: 0.781954

Early stopping
Best (ROC):	 train: 0.995093	val: 0.841738	test: 0.840805
Best (PRC):	 train: 0.994248	val: 0.817637	test: 0.776728
All runs completed.

ROC train: 0.978747	val: 0.855020	test: 0.868522
PRC train: 0.975030	val: 0.762092	test: 0.811456

Epoch: 95
Loss: 0.26817483364671174
ROC train: 0.980536	val: 0.850127	test: 0.867472
PRC train: 0.977831	val: 0.770763	test: 0.819697

Epoch: 96
Loss: 0.2579084965970543
ROC train: 0.981072	val: 0.848858	test: 0.864846
PRC train: 0.978686	val: 0.755930	test: 0.816765

Epoch: 97
Loss: 0.25724757368920426
ROC train: 0.981476	val: 0.852664	test: 0.863620
PRC train: 0.979030	val: 0.754920	test: 0.820307

Epoch: 98
Loss: 0.2522477477844402
ROC train: 0.982467	val: 0.859732	test: 0.866772
PRC train: 0.979950	val: 0.784232	test: 0.818218

Epoch: 99
Loss: 0.25782908881682565
ROC train: 0.981687	val: 0.854839	test: 0.867822
PRC train: 0.978678	val: 0.770893	test: 0.817224

Epoch: 100
Loss: 0.2495431339477186
ROC train: 0.981413	val: 0.854476	test: 0.856793
PRC train: 0.978223	val: 0.765937	test: 0.814979

Epoch: 101
Loss: 0.23256082632902908
ROC train: 0.983596	val: 0.853208	test: 0.861870
PRC train: 0.981126	val: 0.771086	test: 0.819199

Epoch: 102
Loss: 0.25819702287010005
ROC train: 0.980579	val: 0.851395	test: 0.878676
PRC train: 0.977645	val: 0.767390	test: 0.828395

Epoch: 103
Loss: 0.25927021480977486
ROC train: 0.982643	val: 0.856832	test: 0.886380
PRC train: 0.980132	val: 0.784898	test: 0.841777

Epoch: 104
Loss: 0.24353148488140194
ROC train: 0.984305	val: 0.857376	test: 0.882703
PRC train: 0.981812	val: 0.783245	test: 0.834731

Epoch: 105
Loss: 0.2388201138963268
ROC train: 0.982697	val: 0.853570	test: 0.876926
PRC train: 0.980280	val: 0.777325	test: 0.819722

Epoch: 106
Loss: 0.2585070440573832
ROC train: 0.982463	val: 0.859188	test: 0.867297
PRC train: 0.979751	val: 0.778075	test: 0.814518

Epoch: 107
Loss: 0.2552339458197511
ROC train: 0.982533	val: 0.861906	test: 0.876751
PRC train: 0.980387	val: 0.787441	test: 0.821327

Epoch: 108
Loss: 0.22823373676088524
ROC train: 0.982544	val: 0.858826	test: 0.872549
PRC train: 0.980296	val: 0.788792	test: 0.816216

Epoch: 109
Loss: 0.23336840704855635
ROC train: 0.983717	val: 0.853751	test: 0.862395
PRC train: 0.981390	val: 0.774952	test: 0.816375

Epoch: 110
Loss: 0.24774154012330868
ROC train: 0.981330	val: 0.846684	test: 0.868873
PRC train: 0.978729	val: 0.753434	test: 0.827115

Epoch: 111
Loss: 0.2365101085999508
ROC train: 0.984684	val: 0.845959	test: 0.863620
PRC train: 0.982680	val: 0.736849	test: 0.812936

Epoch: 112
Loss: 0.23423462460817585
ROC train: 0.986323	val: 0.851033	test: 0.873775
PRC train: 0.984668	val: 0.754197	test: 0.827520

Epoch: 113
Loss: 0.23250394428543428
ROC train: 0.986274	val: 0.856107	test: 0.876926
PRC train: 0.984439	val: 0.761065	test: 0.833444

Epoch: 114
Loss: 0.2300208286229425
ROC train: 0.986613	val: 0.857738	test: 0.865371
PRC train: 0.984681	val: 0.766614	test: 0.824223

Epoch: 115
Loss: 0.2256104644385454
ROC train: 0.984250	val: 0.858282	test: 0.867472
PRC train: 0.981842	val: 0.775503	test: 0.820007

Epoch: 116
Loss: 0.26245470486889655
ROC train: 0.984840	val: 0.862631	test: 0.868697
PRC train: 0.982499	val: 0.781447	test: 0.830587

Epoch: 117
Loss: 0.22564462302732197
ROC train: 0.985920	val: 0.858826	test: 0.860644
PRC train: 0.983995	val: 0.780613	test: 0.817583

Epoch: 118
Loss: 0.23969860673628016
ROC train: 0.988006	val: 0.857376	test: 0.855567
PRC train: 0.986598	val: 0.777295	test: 0.803136

Epoch: 119
Loss: 0.2301459461074375
ROC train: 0.988238	val: 0.865350	test: 0.859069
PRC train: 0.986799	val: 0.780609	test: 0.794570

Epoch: 120
Loss: 0.23819368433856553
ROC train: 0.987002	val: 0.867524	test: 0.869748
PRC train: 0.984892	val: 0.789241	test: 0.814819

Epoch: 121
Loss: 0.2405505431320793
ROC train: 0.985964	val: 0.856832	test: 0.874650
PRC train: 0.984113	val: 0.778710	test: 0.818399

Epoch: 122
Loss: 0.22118987390319972
ROC train: 0.984133	val: 0.854114	test: 0.878501
PRC train: 0.981677	val: 0.775090	test: 0.824173

Epoch: 123
Loss: 0.24957343659072934
ROC train: 0.989141	val: 0.861182	test: 0.879727
PRC train: 0.987661	val: 0.774789	test: 0.822211

Epoch: 124
Loss: 0.22434363234637425
ROC train: 0.988933	val: 0.861182	test: 0.879552
PRC train: 0.987112	val: 0.781405	test: 0.830031

Epoch: 125
Loss: 0.2364777632118383
ROC train: 0.988512	val: 0.853570	test: 0.874475
PRC train: 0.987012	val: 0.776626	test: 0.827658

Epoch: 126
Loss: 0.23589130765857388
ROC train: 0.987609	val: 0.848133	test: 0.865546
PRC train: 0.986073	val: 0.762357	test: 0.807702

Epoch: 127
Loss: 0.21532842180233067
ROC train: 0.987559	val: 0.846140	test: 0.861695
PRC train: 0.985850	val: 0.753751	test: 0.774505

Epoch: 128
Loss: 0.22135556303334258
ROC train: 0.987892	val: 0.853208	test: 0.866422
PRC train: 0.986334	val: 0.766701	test: 0.809954

Epoch: 129
Loss: 0.22068266731394298
ROC train: 0.988655	val: 0.856832	test: 0.870973
PRC train: 0.987212	val: 0.784894	test: 0.825695

Epoch: 130
Loss: 0.20853235510572393
ROC train: 0.989556	val: 0.859188	test: 0.867472
PRC train: 0.988297	val: 0.789132	test: 0.816673

Epoch: 131
Loss: 0.20662583699232345
ROC train: 0.989420	val: 0.854476	test: 0.858543
PRC train: 0.987995	val: 0.773530	test: 0.799944

Epoch: 132
Loss: 0.23272381327423833
ROC train: 0.988295	val: 0.847771	test: 0.867647
PRC train: 0.986453	val: 0.760142	test: 0.805057

Epoch: 133
Loss: 0.21963371370011237
ROC train: 0.989536	val: 0.850127	test: 0.869748
PRC train: 0.988097	val: 0.769869	test: 0.811519

Epoch: 134
Loss: 0.20970098401745746
ROC train: 0.989526	val: 0.853751	test: 0.866246
PRC train: 0.988143	val: 0.755056	test: 0.808493

Epoch: 135
Loss: 0.2266342629523556
ROC train: 0.988330	val: 0.848858	test: 0.867472
PRC train: 0.986720	val: 0.727899	test: 0.778022

Epoch: 136
Loss: 0.19393614759521585
ROC train: 0.990660	val: 0.857738	test: 0.878676
PRC train: 0.989512	val: 0.774574	test: 0.799443

Epoch: 137
Loss: 0.20624374891853153
ROC train: 0.990331	val: 0.861000	test: 0.874125
PRC train: 0.989160	val: 0.787356	test: 0.824387

Epoch: 138
Loss: 0.20615193619481884
ROC train: 0.988371	val: 0.859007	test: 0.873249
PRC train: 0.986807	val: 0.785038	test: 0.819782

Epoch: 139
Loss: 0.1954571546547136
ROC train: 0.988144	val: 0.856470	test: 0.881127
PRC train: 0.986162	val: 0.767613	test: 0.820748

Epoch: 140
Loss: 0.20517583980910628
ROC train: 0.986465	val: 0.855745	test: 0.873950
PRC train: 0.984648	val: 0.758874	test: 0.817568

Epoch: 141
Loss: 0.21345982508554462
ROC train: 0.990386	val: 0.848496	test: 0.879377
PRC train: 0.989197	val: 0.773000	test: 0.827944

Epoch: 142
Loss: 0.21162895434892973
ROC train: 0.991479	val: 0.845053	test: 0.882003
PRC train: 0.990587	val: 0.769133	test: 0.832167

Epoch: 143
Loss: 0.21051827626659106
ROC train: 0.991825	val: 0.838891	test: 0.875525
PRC train: 0.990860	val: 0.753159	test: 0.812570

Epoch: 144
Loss: 0.22251394735590163
ROC train: 0.991031	val: 0.836354	test: 0.873775
PRC train: 0.989908	val: 0.747055	test: 0.807935

Epoch: 145
Loss: 0.20703830766912276
ROC train: 0.988808	val: 0.845777	test: 0.866071
PRC train: 0.987492	val: 0.760066	test: 0.806216

Epoch: 146
Loss: 0.20510178615257346
ROC train: 0.991487	val: 0.846321	test: 0.873599
PRC train: 0.990537	val: 0.762960	test: 0.817470

Epoch: 147
Loss: 0.20638359397240008
ROC train: 0.991351	val: 0.843965	test: 0.878501
PRC train: 0.990138	val: 0.759349	test: 0.826374

Epoch: 148
Loss: 0.21036865917956565
ROC train: 0.992017	val: 0.850127	test: 0.884279
PRC train: 0.990972	val: 0.766276	test: 0.827089

Epoch: 149
Loss: 0.1905666465460713
ROC train: 0.991808	val: 0.853570	test: 0.876050
PRC train: 0.990859	val: 0.754311	test: 0.815594

Epoch: 150
Loss: 0.1917647795143979
ROC train: 0.992973	val: 0.855745	test: 0.873775
PRC train: 0.992298	val: 0.765839	test: 0.821925

Epoch: 151
Loss: 0.20835514895318194
ROC train: 0.992415	val: 0.848496	test: 0.884804
PRC train: 0.991520	val: 0.764423	test: 0.836787

Epoch: 152
Loss: 0.1869506710281023
ROC train: 0.991896	val: 0.844146	test: 0.882353
PRC train: 0.990975	val: 0.762348	test: 0.831305

Epoch: 153
Loss: 0.1884371910969443
ROC train: 0.992704	val: 0.848496	test: 0.880602
PRC train: 0.991970	val: 0.758478	test: 0.825631

Epoch: 154
Loss: 0.19106583448681344
ROC train: 0.992954	val: 0.852845	test: 0.883228
PRC train: 0.992257	val: 0.749748	test: 0.829621

Epoch: 155
Loss: 0.18080602836431484
ROC train: 0.993486	val: 0.851395	test: 0.881478
PRC train: 0.992749	val: 0.765854	test: 0.834764

Early stopping
Best (ROC):	 train: 0.987002	val: 0.867524	test: 0.869748
Best (PRC):	 train: 0.984892	val: 0.789241	test: 0.814819
All runs completed.
