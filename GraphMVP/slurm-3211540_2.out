>>> Starting run for dataset: bace
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running RANDOM configs_split_experiments/GraphMVP/bace/random/train_prop=0.6.yml on cuda:0
Running RANDOM configs_split_experiments/GraphMVP/bace/random/train_prop=0.7.yml on cuda:1
Running RANDOM configs_split_experiments/GraphMVP/bace/random/train_prop=0.8.yml on cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/bace/random/train_prop=0.8.yml --runseed 4 --device cuda:2
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/bace/random/train_prop=0.8.yml --runseed 5 --device cuda:2
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/bace/random/train_prop=0.8.yml --runseed 6 --device cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/bace/random/train_prop=0.7.yml --runseed 4 --device cuda:1
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/bace/random/train_prop=0.7.yml --runseed 5 --device cuda:1
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/bace/random/train_prop=0.7.yml --runseed 6 --device cuda:1
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/bace/random/train_prop=0.6.yml --runseed 4 --device cuda:0
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/bace/random/train_prop=0.6.yml --runseed 5 --device cuda:0
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphMVP/bace/random/train_prop=0.6.yml --runseed 6 --device cuda:0
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/bace/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/bace/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/bace/random/train_prop=0.6/bace_random_6_26-05_11-05-13  ]
[ Using Seed :  6  ]
[ Using device :  cuda:0  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
randomly split
Data(edge_attr=[78, 2], edge_index=[2, 78], id=[1], x=[37, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6885052275229808
ROC train: 0.658668	val: 0.644854	test: 0.626393
PRC train: 0.608582	val: 0.621196	test: 0.536074

Epoch: 2
Loss: 0.6544354809318869
ROC train: 0.724067	val: 0.682115	test: 0.690186
PRC train: 0.666432	val: 0.649076	test: 0.582698

Epoch: 3
Loss: 0.6076432531506305
ROC train: 0.765169	val: 0.706693	test: 0.731256
PRC train: 0.708989	val: 0.659526	test: 0.617391

Epoch: 4
Loss: 0.5740599580041402
ROC train: 0.797364	val: 0.721396	test: 0.767418
PRC train: 0.741311	val: 0.645754	test: 0.641430

Epoch: 5
Loss: 0.5522617551321988
ROC train: 0.815266	val: 0.741584	test: 0.794562
PRC train: 0.756732	val: 0.647336	test: 0.662366

Epoch: 6
Loss: 0.5361691598336629
ROC train: 0.847544	val: 0.763529	test: 0.803404
PRC train: 0.797365	val: 0.672628	test: 0.673531

Epoch: 7
Loss: 0.5146086104965562
ROC train: 0.859950	val: 0.769717	test: 0.799469
PRC train: 0.822666	val: 0.705527	test: 0.680980

Epoch: 8
Loss: 0.48613610813617003
ROC train: 0.871155	val: 0.776607	test: 0.809019
PRC train: 0.837025	val: 0.705881	test: 0.688070

Epoch: 9
Loss: 0.4793863005838751
ROC train: 0.876246	val: 0.783673	test: 0.816711
PRC train: 0.841957	val: 0.703084	test: 0.682551

Epoch: 10
Loss: 0.46724183611430936
ROC train: 0.892189	val: 0.797103	test: 0.825376
PRC train: 0.864097	val: 0.741941	test: 0.709263

Epoch: 11
Loss: 0.4631588447793254
ROC train: 0.899827	val: 0.805662	test: 0.831830
PRC train: 0.873722	val: 0.754347	test: 0.734880

Epoch: 12
Loss: 0.42551730856720615
ROC train: 0.905040	val: 0.807593	test: 0.834085
PRC train: 0.876029	val: 0.748780	test: 0.744595

Epoch: 13
Loss: 0.4334631643519515
ROC train: 0.906218	val: 0.805091	test: 0.834527
PRC train: 0.877974	val: 0.751078	test: 0.756985

Epoch: 14
Loss: 0.43857088291762536
ROC train: 0.906402	val: 0.811104	test: 0.833554
PRC train: 0.882035	val: 0.774038	test: 0.766954

Epoch: 15
Loss: 0.41509339602098666
ROC train: 0.910400	val: 0.819969	test: 0.836914
PRC train: 0.888418	val: 0.780544	test: 0.765851

Epoch: 16
Loss: 0.41685283462221934
ROC train: 0.916566	val: 0.819618	test: 0.835986
PRC train: 0.895405	val: 0.774765	test: 0.767516

Epoch: 17
Loss: 0.4216442688571498
ROC train: 0.919464	val: 0.823436	test: 0.833201
PRC train: 0.901136	val: 0.782460	test: 0.760120

Epoch: 18
Loss: 0.40282413294879865
ROC train: 0.921282	val: 0.823919	test: 0.834836
PRC train: 0.903617	val: 0.785692	test: 0.757317

Epoch: 19
Loss: 0.4084283957985293
ROC train: 0.921926	val: 0.818433	test: 0.839080
PRC train: 0.901932	val: 0.775446	test: 0.759923

Epoch: 20
Loss: 0.4218759470646199
ROC train: 0.925496	val: 0.815229	test: 0.841689
PRC train: 0.904217	val: 0.773968	test: 0.770082

Epoch: 21
Loss: 0.3991287654671229
ROC train: 0.924315	val: 0.820364	test: 0.828780
PRC train: 0.905906	val: 0.792154	test: 0.750116

Epoch: 22
Loss: 0.3854683122181902
ROC train: 0.925579	val: 0.824183	test: 0.825287
PRC train: 0.906437	val: 0.795839	test: 0.744721

Epoch: 23
Loss: 0.3787606100520507
ROC train: 0.929038	val: 0.823436	test: 0.836118
PRC train: 0.907268	val: 0.786283	test: 0.764008

Epoch: 24
Loss: 0.39717768331511066
ROC train: 0.929966	val: 0.827781	test: 0.842529
PRC train: 0.907813	val: 0.789787	test: 0.773446

Epoch: 25
Loss: 0.3767521043154322
ROC train: 0.934094	val: 0.834540	test: 0.843280
PRC train: 0.914025	val: 0.798060	test: 0.768100

Epoch: 26
Loss: 0.3951378457900653
ROC train: 0.934212	val: 0.832741	test: 0.841158
PRC train: 0.913117	val: 0.794438	test: 0.759394

Epoch: 27
Loss: 0.39013565888018975
ROC train: 0.934413	val: 0.833838	test: 0.840141
PRC train: 0.915799	val: 0.796958	test: 0.757595

Epoch: 28
Loss: 0.3574292349148926
ROC train: 0.934966	val: 0.830239	test: 0.838771
PRC train: 0.916745	val: 0.797168	test: 0.760502

Epoch: 29
Loss: 0.3733315440041404
ROC train: 0.939219	val: 0.826245	test: 0.844430
PRC train: 0.921604	val: 0.793097	test: 0.773710

Epoch: 30
Loss: 0.3701831379635133
ROC train: 0.939322	val: 0.821505	test: 0.848320
PRC train: 0.922219	val: 0.790695	test: 0.784509

Epoch: 31
Loss: 0.35818959526368266
ROC train: 0.942394	val: 0.828089	test: 0.849293
PRC train: 0.926356	val: 0.798520	test: 0.785164

Epoch: 32
Loss: 0.374752466631754
ROC train: 0.945319	val: 0.835594	test: 0.844562
PRC train: 0.929457	val: 0.808170	test: 0.775405

Epoch: 33
Loss: 0.36387221008090953
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/bace/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/bace/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/bace/random/train_prop=0.6/bace_random_4_26-05_11-05-13  ]
[ Using Seed :  4  ]
[ Using device :  cuda:0  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
randomly split
Data(edge_attr=[78, 2], edge_index=[2, 78], id=[1], x=[37, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6842570192253905
ROC train: 0.685483	val: 0.632916	test: 0.645049
PRC train: 0.618426	val: 0.617468	test: 0.553235

Epoch: 2
Loss: 0.6483067268688927
ROC train: 0.709623	val: 0.650033	test: 0.677365
PRC train: 0.640123	val: 0.629633	test: 0.581461

Epoch: 3
Loss: 0.6129113357845848
ROC train: 0.744851	val: 0.680053	test: 0.720292
PRC train: 0.678752	val: 0.646423	test: 0.615433

Epoch: 4
Loss: 0.5755419216343212
ROC train: 0.781119	val: 0.708580	test: 0.752653
PRC train: 0.727049	val: 0.657991	test: 0.643914

Epoch: 5
Loss: 0.5524184930146676
ROC train: 0.823311	val: 0.735045	test: 0.776304
PRC train: 0.776101	val: 0.679780	test: 0.668002

Epoch: 6
Loss: 0.5160836657114092
ROC train: 0.843723	val: 0.747509	test: 0.778117
PRC train: 0.803288	val: 0.701899	test: 0.671478

Epoch: 7
Loss: 0.5109578177591537
ROC train: 0.853510	val: 0.768795	test: 0.788948
PRC train: 0.813013	val: 0.724305	test: 0.674478

Epoch: 8
Loss: 0.49128767767146353
ROC train: 0.858659	val: 0.778670	test: 0.804819
PRC train: 0.813539	val: 0.714998	test: 0.672114

Epoch: 9
Loss: 0.48388849242166887
ROC train: 0.870425	val: 0.786351	test: 0.804730
PRC train: 0.832623	val: 0.727479	test: 0.678476

Epoch: 10
Loss: 0.46941092314677546
ROC train: 0.876647	val: 0.792100	test: 0.801415
PRC train: 0.844850	val: 0.737696	test: 0.676239

Epoch: 11
Loss: 0.46148713901514504
ROC train: 0.883090	val: 0.795392	test: 0.811671
PRC train: 0.855595	val: 0.739632	test: 0.690348

Epoch: 12
Loss: 0.43219383809435363
ROC train: 0.895124	val: 0.802897	test: 0.824050
PRC train: 0.873235	val: 0.752451	test: 0.712579

Epoch: 13
Loss: 0.4578347903275738
ROC train: 0.901674	val: 0.806452	test: 0.827409
PRC train: 0.884148	val: 0.762214	test: 0.728183

Epoch: 14
Loss: 0.43411653185174265
ROC train: 0.902091	val: 0.801229	test: 0.833996
PRC train: 0.884061	val: 0.754409	test: 0.740969

Epoch: 15
Loss: 0.43630817497428503
ROC train: 0.902830	val: 0.804082	test: 0.836118
PRC train: 0.879538	val: 0.742554	test: 0.737915

Epoch: 16
Loss: 0.4209033787478136
ROC train: 0.903654	val: 0.812596	test: 0.828117
PRC train: 0.882224	val: 0.764607	test: 0.727972

Epoch: 17
Loss: 0.4274675053221708
ROC train: 0.901116	val: 0.805135	test: 0.836207
PRC train: 0.873598	val: 0.735129	test: 0.738046

Epoch: 18
Loss: 0.44008911310575416
ROC train: 0.908925	val: 0.812420	test: 0.842617
PRC train: 0.887893	val: 0.767519	test: 0.756542

Epoch: 19
Loss: 0.4266100507663627
ROC train: 0.915442	val: 0.818740	test: 0.847259
PRC train: 0.898326	val: 0.786778	test: 0.768914

Epoch: 20
Loss: 0.41701097211098254
ROC train: 0.906640	val: 0.793592	test: 0.836958
PRC train: 0.892799	val: 0.761439	test: 0.779500

Epoch: 21
Loss: 0.4133524262418163
ROC train: 0.916113	val: 0.801624	test: 0.845181
PRC train: 0.900798	val: 0.763539	test: 0.777891

Epoch: 22
Loss: 0.41065703331734077
ROC train: 0.921478	val: 0.810621	test: 0.847569
PRC train: 0.903145	val: 0.768009	test: 0.765627

Epoch: 23
Loss: 0.3830750008216007
ROC train: 0.919624	val: 0.811148	test: 0.840893
PRC train: 0.898336	val: 0.762966	test: 0.756676

Epoch: 24
Loss: 0.40221624924111954
ROC train: 0.922664	val: 0.813079	test: 0.842042
PRC train: 0.902875	val: 0.766210	test: 0.763322

Epoch: 25
Loss: 0.3827428456411437
ROC train: 0.925868	val: 0.816107	test: 0.841202
PRC train: 0.907806	val: 0.774039	test: 0.765405

Epoch: 26
Loss: 0.40914185868731956
ROC train: 0.926760	val: 0.818345	test: 0.840672
PRC train: 0.908897	val: 0.776017	test: 0.762034

Epoch: 27
Loss: 0.38932854364943864
ROC train: 0.929111	val: 0.822076	test: 0.842661
PRC train: 0.911855	val: 0.785937	test: 0.765850

Epoch: 28
Loss: 0.3685730464297321
ROC train: 0.927960	val: 0.815142	test: 0.847082
PRC train: 0.909531	val: 0.776345	test: 0.771822

Epoch: 29
Loss: 0.3797279332991
ROC train: 0.929327	val: 0.820496	test: 0.843236
PRC train: 0.911436	val: 0.785157	test: 0.763742

Epoch: 30
Loss: 0.36818138688969776
ROC train: 0.928783	val: 0.825806	test: 0.838904
PRC train: 0.909789	val: 0.790185	test: 0.750826

Epoch: 31
Loss: 0.3901556844730279
ROC train: 0.929822	val: 0.822734	test: 0.843678
PRC train: 0.911515	val: 0.788667	test: 0.766347

Epoch: 32
Loss: 0.39381905618194857
ROC train: 0.934501	val: 0.831424	test: 0.840318
PRC train: 0.919822	val: 0.804066	test: 0.761708

Epoch: 33
Loss: 0.3673832521062867Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/bace/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/bace/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/bace/random/train_prop=0.6/bace_random_5_26-05_11-05-13  ]
[ Using Seed :  5  ]
[ Using device :  cuda:0  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
randomly split
Data(edge_attr=[78, 2], edge_index=[2, 78], id=[1], x=[37, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6722272957257384
ROC train: 0.682480	val: 0.640860	test: 0.637356
PRC train: 0.589026	val: 0.626878	test: 0.533030

Epoch: 2
Loss: 0.6333633605542653
ROC train: 0.710424	val: 0.660917	test: 0.669496
PRC train: 0.624531	val: 0.644161	test: 0.564472

Epoch: 3
Loss: 0.6058541333197202
ROC train: 0.750367	val: 0.694536	test: 0.718170
PRC train: 0.669959	val: 0.661379	test: 0.607981

Epoch: 4
Loss: 0.5708737277012091
ROC train: 0.793429	val: 0.723678	test: 0.761185
PRC train: 0.729671	val: 0.661771	test: 0.648486

Epoch: 5
Loss: 0.5357993866446986
ROC train: 0.834409	val: 0.747334	test: 0.784129
PRC train: 0.785729	val: 0.680902	test: 0.662418

Epoch: 6
Loss: 0.5017799635014214
ROC train: 0.851856	val: 0.762914	test: 0.784881
PRC train: 0.808804	val: 0.701278	test: 0.659404

Epoch: 7
Loss: 0.5126352374705293
ROC train: 0.864747	val: 0.774808	test: 0.794032
PRC train: 0.823703	val: 0.712605	test: 0.668158

Epoch: 8
Loss: 0.4906397778735216
ROC train: 0.875009	val: 0.784288	test: 0.823607
PRC train: 0.834035	val: 0.699635	test: 0.693058

Epoch: 9
Loss: 0.4751428472302861
ROC train: 0.881449	val: 0.789247	test: 0.815252
PRC train: 0.851510	val: 0.714699	test: 0.684330

Epoch: 10
Loss: 0.4574472307851122
ROC train: 0.885320	val: 0.798859	test: 0.813926
PRC train: 0.857855	val: 0.746339	test: 0.690381

Epoch: 11
Loss: 0.4586833011821622
ROC train: 0.893521	val: 0.803248	test: 0.826348
PRC train: 0.863279	val: 0.737698	test: 0.715599

Epoch: 12
Loss: 0.4279987886639339
ROC train: 0.901772	val: 0.808909	test: 0.833643
PRC train: 0.874818	val: 0.754329	test: 0.741361

Epoch: 13
Loss: 0.44071743463479085
ROC train: 0.905207	val: 0.806847	test: 0.825199
PRC train: 0.884385	val: 0.761260	test: 0.738678

Epoch: 14
Loss: 0.4221315865146037
ROC train: 0.899758	val: 0.792363	test: 0.828824
PRC train: 0.867726	val: 0.716972	test: 0.727724

Epoch: 15
Loss: 0.43194391277006267
ROC train: 0.906569	val: 0.799342	test: 0.833952
PRC train: 0.884363	val: 0.734269	test: 0.747497

Epoch: 16
Loss: 0.4413311304461752
ROC train: 0.910618	val: 0.812245	test: 0.831698
PRC train: 0.891655	val: 0.768922	test: 0.740825

Epoch: 17
Loss: 0.4291974340033304
ROC train: 0.916074	val: 0.811323	test: 0.835721
PRC train: 0.896224	val: 0.760723	test: 0.754158

Epoch: 18
Loss: 0.4159993838234605
ROC train: 0.919254	val: 0.814878	test: 0.832317
PRC train: 0.900461	val: 0.768414	test: 0.752476

Epoch: 19
Loss: 0.3862418507576938
ROC train: 0.922649	val: 0.824665	test: 0.832626
PRC train: 0.906042	val: 0.785249	test: 0.751967

Epoch: 20
Loss: 0.41436430112069134
ROC train: 0.922791	val: 0.824446	test: 0.842661
PRC train: 0.905509	val: 0.786788	test: 0.773813

Epoch: 21
Loss: 0.40332151846156794
ROC train: 0.917103	val: 0.815712	test: 0.840539
PRC train: 0.898544	val: 0.777800	test: 0.778377

Epoch: 22
Loss: 0.40512600524272085
ROC train: 0.924824	val: 0.825806	test: 0.842661
PRC train: 0.908228	val: 0.789358	test: 0.763819

Epoch: 23
Loss: 0.4088859248565122
ROC train: 0.924712	val: 0.824270	test: 0.840230
PRC train: 0.907312	val: 0.785353	test: 0.758836

Epoch: 24
Loss: 0.39919376360100256
ROC train: 0.926725	val: 0.826553	test: 0.836649
PRC train: 0.909796	val: 0.791803	test: 0.754551

Epoch: 25
Loss: 0.3942881620516652
ROC train: 0.929753	val: 0.827079	test: 0.832140
PRC train: 0.915046	val: 0.794391	test: 0.742597

Epoch: 26
Loss: 0.3786592636951017
ROC train: 0.931287	val: 0.834014	test: 0.837533
PRC train: 0.916167	val: 0.801768	test: 0.751268

Epoch: 27
Loss: 0.3855912903349953
ROC train: 0.932379	val: 0.828045	test: 0.850133
PRC train: 0.915913	val: 0.789336	test: 0.782526

Epoch: 28
Loss: 0.38219776682457507
ROC train: 0.934099	val: 0.827167	test: 0.852343
PRC train: 0.917802	val: 0.783626	test: 0.788653

Epoch: 29
Loss: 0.36091414445658804
ROC train: 0.935032	val: 0.834496	test: 0.841821
PRC train: 0.921080	val: 0.804266	test: 0.764288

Epoch: 30
Loss: 0.3673070321740102
ROC train: 0.935064	val: 0.834409	test: 0.839036
PRC train: 0.919714	val: 0.805694	test: 0.759614

Epoch: 31
Loss: 0.38812190171884126
ROC train: 0.936867	val: 0.827167	test: 0.842661
PRC train: 0.922880	val: 0.789615	test: 0.768027

Epoch: 32
Loss: 0.35989254961760775
ROC train: 0.938548	val: 0.822690	test: 0.845579
PRC train: 0.925365	val: 0.779688	test: 0.771192

Epoch: 33
Loss: 0.3843949637908415
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/bace/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/bace/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/bace/random/train_prop=0.7/bace_random_4_26-05_11-05-13  ]
[ Using Seed :  4  ]
[ Using device :  cuda:1  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
randomly split
Data(edge_attr=[78, 2], edge_index=[2, 78], id=[1], x=[37, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6835217828860409
ROC train: 0.682293	val: 0.648564	test: 0.674203
PRC train: 0.618688	val: 0.594072	test: 0.621362

Epoch: 2
Loss: 0.640697346140146
ROC train: 0.717876	val: 0.689492	test: 0.717471
PRC train: 0.647884	val: 0.624796	test: 0.656127

Epoch: 3
Loss: 0.6071012198142188
ROC train: 0.752593	val: 0.718615	test: 0.762376
PRC train: 0.686688	val: 0.645951	test: 0.682254

Epoch: 4
Loss: 0.5694521376400166
ROC train: 0.778311	val: 0.739709	test: 0.797458
PRC train: 0.714952	val: 0.654632	test: 0.703005

Epoch: 5
Loss: 0.5641226864503566
ROC train: 0.811906	val: 0.757261	test: 0.830982
PRC train: 0.748743	val: 0.661080	test: 0.731077

Epoch: 6
Loss: 0.534640758316277
ROC train: 0.836785	val: 0.760724	test: 0.837530
PRC train: 0.777705	val: 0.659650	test: 0.740712

Epoch: 7
Loss: 0.5068311856564668
ROC train: 0.844168	val: 0.760960	test: 0.845560
PRC train: 0.783248	val: 0.656549	test: 0.752777

Epoch: 8
Loss: 0.4992272147438161
ROC train: 0.850054	val: 0.786147	test: 0.858891
PRC train: 0.795824	val: 0.680508	test: 0.757887

Epoch: 9
Loss: 0.5150574466037066
ROC train: 0.855618	val: 0.790083	test: 0.851797
PRC train: 0.810777	val: 0.693360	test: 0.743342

Epoch: 10
Loss: 0.4926449269002232
ROC train: 0.871642	val: 0.786777	test: 0.852888
PRC train: 0.839619	val: 0.713116	test: 0.752924

Epoch: 11
Loss: 0.5367102068397669
ROC train: 0.869827	val: 0.784652	test: 0.832853
PRC train: 0.843091	val: 0.736347	test: 0.761312

Epoch: 12
Loss: 0.4758271346641883
ROC train: 0.845334	val: 0.758599	test: 0.804163
PRC train: 0.808032	val: 0.715338	test: 0.714161

Epoch: 13
Loss: 0.4466908557931902
ROC train: 0.880353	val: 0.801259	test: 0.848523
PRC train: 0.856107	val: 0.762891	test: 0.778991

Epoch: 14
Loss: 0.4657370082436557
ROC train: 0.888137	val: 0.801653	test: 0.861776
PRC train: 0.864056	val: 0.768986	test: 0.789416

Epoch: 15
Loss: 0.4722000383781487
ROC train: 0.888667	val: 0.806061	test: 0.866687
PRC train: 0.863303	val: 0.774644	test: 0.788366

Epoch: 16
Loss: 0.4622179171346879
ROC train: 0.888144	val: 0.806297	test: 0.861620
PRC train: 0.865571	val: 0.766663	test: 0.777751

Epoch: 17
Loss: 0.4714158910201025
ROC train: 0.888353	val: 0.801574	test: 0.866142
PRC train: 0.866852	val: 0.762813	test: 0.781988

Epoch: 18
Loss: 0.4295009291704409
ROC train: 0.892929	val: 0.805431	test: 0.871677
PRC train: 0.870821	val: 0.764605	test: 0.795202

Epoch: 19
Loss: 0.4886966093440016
ROC train: 0.896277	val: 0.800787	test: 0.868013
PRC train: 0.875372	val: 0.757596	test: 0.798504

Epoch: 20
Loss: 0.44858550621369186
ROC train: 0.896388	val: 0.791578	test: 0.858580
PRC train: 0.874223	val: 0.756846	test: 0.791049

Epoch: 21
Loss: 0.42057681210347464
ROC train: 0.900742	val: 0.796773	test: 0.869494
PRC train: 0.878644	val: 0.757281	test: 0.801827

Epoch: 22
Loss: 0.4363627318988505
ROC train: 0.898296	val: 0.800551	test: 0.869962
PRC train: 0.876339	val: 0.757949	test: 0.790121

Epoch: 23
Loss: 0.43359097556556014
ROC train: 0.904043	val: 0.816844	test: 0.882124
PRC train: 0.883418	val: 0.777770	test: 0.805339

Epoch: 24
Loss: 0.4478004350875581
ROC train: 0.905083	val: 0.829122	test: 0.880486
PRC train: 0.885463	val: 0.790637	test: 0.811893

Epoch: 25
Loss: 0.43687849237063425
ROC train: 0.904436	val: 0.815821	test: 0.859593
PRC train: 0.887543	val: 0.775402	test: 0.782603

Epoch: 26
Loss: 0.46246781959287253
ROC train: 0.903881	val: 0.815270	test: 0.861308
PRC train: 0.886135	val: 0.779106	test: 0.784063

Epoch: 27
Loss: 0.4217536717179916
ROC train: 0.912452	val: 0.816686	test: 0.880097
PRC train: 0.893724	val: 0.776105	test: 0.808080

Epoch: 28
Loss: 0.42933682046047145
ROC train: 0.913372	val: 0.822511	test: 0.891869
PRC train: 0.894477	val: 0.783418	test: 0.826654

Epoch: 29
Loss: 0.4446111031149435
ROC train: 0.908907	val: 0.821488	test: 0.884385
PRC train: 0.891961	val: 0.776343	test: 0.818159

Epoch: 30
Loss: 0.4197366018969532
ROC train: 0.910444	val: 0.806769	test: 0.873626
PRC train: 0.891381	val: 0.751919	test: 0.794255

Epoch: 31
Loss: 0.41379116782581304
ROC train: 0.915171	val: 0.802676	test: 0.878226
PRC train: 0.896674	val: 0.751628	test: 0.809445

Epoch: 32
Loss: 0.4253919389421716
ROC train: 0.913555	val: 0.803306	test: 0.873782
PRC train: 0.894274	val: 0.761222	test: 0.819256

Epoch: 33
Loss: 0.42001052259449906
ROC train: 0.915927	val: 0.807320	test: 0.867779Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/bace/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/bace/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/bace/random/train_prop=0.7/bace_random_6_26-05_11-05-13  ]
[ Using Seed :  6  ]
[ Using device :  cuda:1  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
randomly split
Data(edge_attr=[78, 2], edge_index=[2, 78], id=[1], x=[37, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6810888616372182
ROC train: 0.683248	val: 0.649193	test: 0.688392
PRC train: 0.621890	val: 0.589806	test: 0.623035

Epoch: 2
Loss: 0.6505724240285626
ROC train: 0.729396	val: 0.683274	test: 0.733375
PRC train: 0.669965	val: 0.612802	test: 0.657620

Epoch: 3
Loss: 0.6079629543098383
ROC train: 0.773384	val: 0.728926	test: 0.794652
PRC train: 0.707567	val: 0.643660	test: 0.708491

Epoch: 4
Loss: 0.6013591694840248
ROC train: 0.791686	val: 0.732074	test: 0.820223
PRC train: 0.712143	val: 0.631949	test: 0.743952

Epoch: 5
Loss: 0.5612295559415468
ROC train: 0.818936	val: 0.723967	test: 0.824199
PRC train: 0.745236	val: 0.631230	test: 0.748801

Epoch: 6
Loss: 0.5490093078926547
ROC train: 0.821310	val: 0.718851	test: 0.800655
PRC train: 0.771334	val: 0.642051	test: 0.720675

Epoch: 7
Loss: 0.5313169305573655
ROC train: 0.828248	val: 0.757418	test: 0.836907
PRC train: 0.758991	val: 0.683659	test: 0.759051

Epoch: 8
Loss: 0.5154055809961109
ROC train: 0.844091	val: 0.767651	test: 0.852421
PRC train: 0.776748	val: 0.682968	test: 0.769443

Epoch: 9
Loss: 0.5010834059248485
ROC train: 0.864796	val: 0.769540	test: 0.853824
PRC train: 0.821891	val: 0.683424	test: 0.767430

Epoch: 10
Loss: 0.49661697096414414
ROC train: 0.874229	val: 0.787407	test: 0.860373
PRC train: 0.831803	val: 0.709460	test: 0.776667

Epoch: 11
Loss: 0.4713269460522923
ROC train: 0.880482	val: 0.802991	test: 0.866609
PRC train: 0.837312	val: 0.731896	test: 0.788814

Epoch: 12
Loss: 0.4715256694943185
ROC train: 0.877490	val: 0.814561	test: 0.870196
PRC train: 0.827331	val: 0.752861	test: 0.805570

Epoch: 13
Loss: 0.4810190965056795
ROC train: 0.884890	val: 0.815191	test: 0.868247
PRC train: 0.848851	val: 0.766763	test: 0.813001

Epoch: 14
Loss: 0.4691713442632016
ROC train: 0.883234	val: 0.816057	test: 0.865440
PRC train: 0.842598	val: 0.765707	test: 0.812134

Epoch: 15
Loss: 0.4592333459340008
ROC train: 0.893080	val: 0.810075	test: 0.863413
PRC train: 0.861739	val: 0.756807	test: 0.801655

Epoch: 16
Loss: 0.476698773265697
ROC train: 0.895115	val: 0.815033	test: 0.872690
PRC train: 0.861505	val: 0.757894	test: 0.805227

Epoch: 17
Loss: 0.4568198169540647
ROC train: 0.896140	val: 0.829280	test: 0.878615
PRC train: 0.860080	val: 0.784224	test: 0.813097

Epoch: 18
Loss: 0.443720592198237
ROC train: 0.899323	val: 0.820622	test: 0.875419
PRC train: 0.867905	val: 0.774791	test: 0.816462

Epoch: 19
Loss: 0.4612404839370459
ROC train: 0.902624	val: 0.816765	test: 0.872223
PRC train: 0.878051	val: 0.756270	test: 0.794955

Epoch: 20
Loss: 0.43865234294652067
ROC train: 0.903709	val: 0.824242	test: 0.876277
PRC train: 0.874650	val: 0.765171	test: 0.804617

Epoch: 21
Loss: 0.42653363230139263
ROC train: 0.897336	val: 0.832113	test: 0.868481
PRC train: 0.866287	val: 0.786586	test: 0.798273

Epoch: 22
Loss: 0.40903218137126024
ROC train: 0.905713	val: 0.813932	test: 0.876978
PRC train: 0.880327	val: 0.760159	test: 0.804092

Epoch: 23
Loss: 0.40529086946089593
ROC train: 0.908752	val: 0.809839	test: 0.874484
PRC train: 0.885511	val: 0.771749	test: 0.811190

Epoch: 24
Loss: 0.4160342101559243
ROC train: 0.912944	val: 0.824085	test: 0.880331
PRC train: 0.892028	val: 0.789381	test: 0.824682

Epoch: 25
Loss: 0.3994829251192386
ROC train: 0.914726	val: 0.822196	test: 0.889296
PRC train: 0.883762	val: 0.777261	test: 0.816348

Epoch: 26
Loss: 0.42395078583642015
ROC train: 0.915318	val: 0.823691	test: 0.886879
PRC train: 0.885057	val: 0.775358	test: 0.816339

Epoch: 27
Loss: 0.40679853174205255
ROC train: 0.917377	val: 0.832113	test: 0.880642
PRC train: 0.895349	val: 0.785183	test: 0.801676

Epoch: 28
Loss: 0.4199831033833833
ROC train: 0.916910	val: 0.824321	test: 0.872690
PRC train: 0.898950	val: 0.776098	test: 0.788881

Epoch: 29
Loss: 0.4411697724818242
ROC train: 0.915997	val: 0.828493	test: 0.873860
PRC train: 0.896638	val: 0.804845	test: 0.801157

Epoch: 30
Loss: 0.4317221895169704
ROC train: 0.917962	val: 0.838017	test: 0.874795
PRC train: 0.899881	val: 0.817311	test: 0.811253

Epoch: 31
Loss: 0.39373707707815986
ROC train: 0.914386	val: 0.826761	test: 0.887581
PRC train: 0.892950	val: 0.805014	test: 0.831062

Epoch: 32
Loss: 0.4031972078811167
ROC train: 0.916741	val: 0.820071	test: 0.889374
PRC train: 0.894501	val: 0.793762	test: 0.832721

Epoch: 33
Loss: 0.3907131882039453
ROC train: 0.924557	val: 0.814640	test: 0.887581Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/bace/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/bace/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/bace/random/train_prop=0.8/bace_random_5_26-05_11-05-13  ]
[ Using Seed :  5  ]
[ Using device :  cuda:2  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
randomly split
Data(edge_attr=[78, 2], edge_index=[2, 78], id=[1], x=[37, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6725043708509938
ROC train: 0.677775	val: 0.676694	test: 0.608543
PRC train: 0.611564	val: 0.562131	test: 0.540071

Epoch: 2
Loss: 0.6293931587374687
ROC train: 0.719629	val: 0.719282	test: 0.676471
PRC train: 0.655049	val: 0.603497	test: 0.587550

Epoch: 3
Loss: 0.5932847500883236
ROC train: 0.775291	val: 0.770388	test: 0.752101
PRC train: 0.708879	val: 0.654380	test: 0.662046

Epoch: 4
Loss: 0.5543968609379275
ROC train: 0.823523	val: 0.795216	test: 0.815476
PRC train: 0.757973	val: 0.661580	test: 0.734588

Epoch: 5
Loss: 0.5376586131407664
ROC train: 0.847855	val: 0.797572	test: 0.830532
PRC train: 0.792419	val: 0.638518	test: 0.758631

Epoch: 6
Loss: 0.5018592855997048
ROC train: 0.858736	val: 0.797934	test: 0.826155
PRC train: 0.812837	val: 0.641497	test: 0.754299

Epoch: 7
Loss: 0.49319175684122946
ROC train: 0.865611	val: 0.795034	test: 0.837185
PRC train: 0.824133	val: 0.636551	test: 0.771088

Epoch: 8
Loss: 0.4875612371801489
ROC train: 0.874590	val: 0.809170	test: 0.857668
PRC train: 0.838633	val: 0.675362	test: 0.797413

Epoch: 9
Loss: 0.47650772278527576
ROC train: 0.879841	val: 0.812432	test: 0.857668
PRC train: 0.853222	val: 0.692577	test: 0.793545

Epoch: 10
Loss: 0.475352118276423
ROC train: 0.886161	val: 0.827655	test: 0.866071
PRC train: 0.863550	val: 0.741240	test: 0.809723

Epoch: 11
Loss: 0.46522167373606615
ROC train: 0.888218	val: 0.835448	test: 0.844888
PRC train: 0.870504	val: 0.753605	test: 0.780733

Epoch: 12
Loss: 0.45329017910474645
ROC train: 0.889932	val: 0.837441	test: 0.846814
PRC train: 0.870505	val: 0.756079	test: 0.786300

Epoch: 13
Loss: 0.4550513001412207
ROC train: 0.896745	val: 0.835085	test: 0.863445
PRC train: 0.873681	val: 0.749149	test: 0.808349

Epoch: 14
Loss: 0.44749960910876635
ROC train: 0.896214	val: 0.831279	test: 0.853641
PRC train: 0.875624	val: 0.727699	test: 0.762746

Epoch: 15
Loss: 0.4274789937463243
ROC train: 0.899323	val: 0.835085	test: 0.866772
PRC train: 0.878694	val: 0.728551	test: 0.791350

Epoch: 16
Loss: 0.4436877893274346
ROC train: 0.904555	val: 0.846502	test: 0.869223
PRC train: 0.885997	val: 0.752185	test: 0.803457

Epoch: 17
Loss: 0.42238753738287454
ROC train: 0.907929	val: 0.841791	test: 0.858894
PRC train: 0.890235	val: 0.761880	test: 0.790742

Epoch: 18
Loss: 0.42400676663331954
ROC train: 0.902923	val: 0.833092	test: 0.862395
PRC train: 0.883688	val: 0.762339	test: 0.795686

Epoch: 19
Loss: 0.403314777043234
ROC train: 0.907480	val: 0.843965	test: 0.856092
PRC train: 0.888247	val: 0.776589	test: 0.785167

Epoch: 20
Loss: 0.40502651001382883
ROC train: 0.914841	val: 0.846140	test: 0.863095
PRC train: 0.898802	val: 0.775051	test: 0.800395

Epoch: 21
Loss: 0.42041809268701175
ROC train: 0.917096	val: 0.849764	test: 0.865021
PRC train: 0.900506	val: 0.779087	test: 0.796760

Epoch: 22
Loss: 0.4070376852917188
ROC train: 0.917329	val: 0.852664	test: 0.866947
PRC train: 0.900951	val: 0.782044	test: 0.798423

Epoch: 23
Loss: 0.41342871395358605
ROC train: 0.918753	val: 0.858826	test: 0.864846
PRC train: 0.904129	val: 0.782884	test: 0.792064

Epoch: 24
Loss: 0.3984788583426749
ROC train: 0.920882	val: 0.856107	test: 0.867822
PRC train: 0.908274	val: 0.774986	test: 0.796239

Epoch: 25
Loss: 0.4036497977551372
ROC train: 0.923278	val: 0.862088	test: 0.871849
PRC train: 0.909637	val: 0.789579	test: 0.804175

Epoch: 26
Loss: 0.4046888955913076
ROC train: 0.924039	val: 0.861544	test: 0.868172
PRC train: 0.911046	val: 0.794675	test: 0.801982

Epoch: 27
Loss: 0.3878844471187481
ROC train: 0.924473	val: 0.861725	test: 0.869223
PRC train: 0.910722	val: 0.802785	test: 0.806101

Epoch: 28
Loss: 0.38861993556981883
ROC train: 0.925893	val: 0.858826	test: 0.852241
PRC train: 0.912653	val: 0.774494	test: 0.780166

Epoch: 29
Loss: 0.40494271842281615
ROC train: 0.926646	val: 0.854657	test: 0.859069
PRC train: 0.912667	val: 0.762413	test: 0.789940

Epoch: 30
Loss: 0.39965500074858135
ROC train: 0.928491	val: 0.857376	test: 0.861870
PRC train: 0.913971	val: 0.761650	test: 0.794515

Epoch: 31
Loss: 0.3847220658434975
ROC train: 0.928387	val: 0.851214	test: 0.875000
PRC train: 0.914847	val: 0.773417	test: 0.806236

Epoch: 32
Loss: 0.39625045506335005
ROC train: 0.924968	val: 0.853933	test: 0.874125
PRC train: 0.908953	val: 0.799611	test: 0.806570

Epoch: 33
Loss: 0.37988430721141286Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/bace/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/bace/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/bace/random/train_prop=0.8/bace_random_6_26-05_11-05-13  ]
[ Using Seed :  6  ]
[ Using device :  cuda:2  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
randomly split
Data(edge_attr=[78, 2], edge_index=[2, 78], id=[1], x=[37, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6818994358910813
ROC train: 0.685411	val: 0.695361	test: 0.633754
PRC train: 0.625151	val: 0.559198	test: 0.556195

Epoch: 2
Loss: 0.6422336729493198
ROC train: 0.742666	val: 0.745741	test: 0.729167
PRC train: 0.681482	val: 0.608738	test: 0.662365

Epoch: 3
Loss: 0.6016661931216344
ROC train: 0.788594	val: 0.775825	test: 0.796919
PRC train: 0.715236	val: 0.620932	test: 0.724715

Epoch: 4
Loss: 0.5586241348629498
ROC train: 0.816354	val: 0.790685	test: 0.834034
PRC train: 0.736788	val: 0.627060	test: 0.779662

Epoch: 5
Loss: 0.538007721771872
ROC train: 0.836361	val: 0.791410	test: 0.824930
PRC train: 0.776350	val: 0.661540	test: 0.735814

Epoch: 6
Loss: 0.5269734387105481
ROC train: 0.852400	val: 0.804639	test: 0.850140
PRC train: 0.797826	val: 0.652585	test: 0.780293

Epoch: 7
Loss: 0.5106797628819055
ROC train: 0.859343	val: 0.792497	test: 0.849265
PRC train: 0.811628	val: 0.646366	test: 0.780584

Epoch: 8
Loss: 0.4811029911380416
ROC train: 0.869286	val: 0.804458	test: 0.846464
PRC train: 0.832526	val: 0.687032	test: 0.764587

Epoch: 9
Loss: 0.47828103721460485
ROC train: 0.883485	val: 0.826024	test: 0.859594
PRC train: 0.849763	val: 0.734758	test: 0.794869

Epoch: 10
Loss: 0.4543581324778582
ROC train: 0.885820	val: 0.832548	test: 0.866246
PRC train: 0.857837	val: 0.753311	test: 0.815954

Epoch: 11
Loss: 0.4643301298567991
ROC train: 0.889861	val: 0.837441	test: 0.855392
PRC train: 0.865866	val: 0.757310	test: 0.793084

Epoch: 12
Loss: 0.44446097990087463
ROC train: 0.893099	val: 0.842334	test: 0.866071
PRC train: 0.865632	val: 0.760816	test: 0.803949

Epoch: 13
Loss: 0.46361750016106074
ROC train: 0.894104	val: 0.845053	test: 0.863620
PRC train: 0.869619	val: 0.761797	test: 0.800636

Epoch: 14
Loss: 0.4365197476834872
ROC train: 0.899779	val: 0.845777	test: 0.864146
PRC train: 0.875811	val: 0.764959	test: 0.802259

Epoch: 15
Loss: 0.4459648073009653
ROC train: 0.905538	val: 0.846684	test: 0.872724
PRC train: 0.883109	val: 0.771796	test: 0.810896

Epoch: 16
Loss: 0.437108897101783
ROC train: 0.906843	val: 0.849946	test: 0.870273
PRC train: 0.885900	val: 0.776210	test: 0.800454

Epoch: 17
Loss: 0.44186646627789966
ROC train: 0.902742	val: 0.843422	test: 0.866947
PRC train: 0.879765	val: 0.762092	test: 0.772754

Epoch: 18
Loss: 0.43507534748346455
ROC train: 0.902608	val: 0.839797	test: 0.873950
PRC train: 0.876238	val: 0.764225	test: 0.806856

Epoch: 19
Loss: 0.4207491244873659
ROC train: 0.909161	val: 0.841609	test: 0.867472
PRC train: 0.890709	val: 0.764276	test: 0.802009

Epoch: 20
Loss: 0.4163505324454876
ROC train: 0.914478	val: 0.839072	test: 0.868697
PRC train: 0.895987	val: 0.765202	test: 0.811948

Epoch: 21
Loss: 0.4296968479655178
ROC train: 0.913591	val: 0.840159	test: 0.873950
PRC train: 0.893717	val: 0.764674	test: 0.810398

Epoch: 22
Loss: 0.3996411483570096
ROC train: 0.913249	val: 0.841428	test: 0.869223
PRC train: 0.892991	val: 0.758145	test: 0.798331

Epoch: 23
Loss: 0.40049690324725973
ROC train: 0.916093	val: 0.850489	test: 0.871324
PRC train: 0.896112	val: 0.774870	test: 0.792467

Epoch: 24
Loss: 0.38463958529657577
ROC train: 0.918141	val: 0.865712	test: 0.871849
PRC train: 0.899633	val: 0.811452	test: 0.805694

Epoch: 25
Loss: 0.40844846679159674
ROC train: 0.921265	val: 0.862269	test: 0.869398
PRC train: 0.905630	val: 0.804133	test: 0.803739

Epoch: 26
Loss: 0.39692304154363367
ROC train: 0.920985	val: 0.860638	test: 0.862570
PRC train: 0.905542	val: 0.786310	test: 0.794193

Epoch: 27
Loss: 0.4094221472351992
ROC train: 0.922990	val: 0.850127	test: 0.866947
PRC train: 0.908602	val: 0.781646	test: 0.800503

Epoch: 28
Loss: 0.39431825421487793
ROC train: 0.919109	val: 0.841791	test: 0.877626
PRC train: 0.901718	val: 0.774058	test: 0.816580

Epoch: 29
Loss: 0.38032977393017975
ROC train: 0.925127	val: 0.847590	test: 0.869048
PRC train: 0.911877	val: 0.768740	test: 0.801471

Epoch: 30
Loss: 0.38196264304025407
ROC train: 0.929751	val: 0.860275	test: 0.871849
PRC train: 0.916066	val: 0.782709	test: 0.803940

Epoch: 31
Loss: 0.39150102085166505
ROC train: 0.929777	val: 0.854657	test: 0.872199
PRC train: 0.915517	val: 0.782575	test: 0.804605

Epoch: 32
Loss: 0.37598613446688817
ROC train: 0.929624	val: 0.851577	test: 0.873249
PRC train: 0.913707	val: 0.778634	test: 0.809947

Epoch: 33
Loss: 0.39147141345639425Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/bace/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/bace/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/bace/random/train_prop=0.8/bace_random_4_26-05_11-05-13  ]
[ Using Seed :  4  ]
[ Using device :  cuda:2  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
randomly split
Data(edge_attr=[78, 2], edge_index=[2, 78], id=[1], x=[37, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.677064111419494
ROC train: 0.684592	val: 0.688655	test: 0.627276
PRC train: 0.629737	val: 0.568029	test: 0.581653

Epoch: 2
Loss: 0.6400510032280786
ROC train: 0.713217	val: 0.715477	test: 0.670343
PRC train: 0.654080	val: 0.592166	test: 0.609209

Epoch: 3
Loss: 0.6035772040310039
ROC train: 0.759968	val: 0.744291	test: 0.732143
PRC train: 0.697479	val: 0.609449	test: 0.665013

Epoch: 4
Loss: 0.5658599842833743
ROC train: 0.794067	val: 0.768938	test: 0.789216
PRC train: 0.722272	val: 0.609252	test: 0.732107

Epoch: 5
Loss: 0.5454154544122709
ROC train: 0.835142	val: 0.791954	test: 0.797969
PRC train: 0.781346	val: 0.646636	test: 0.725449

Epoch: 6
Loss: 0.5050134953045152
ROC train: 0.853348	val: 0.786336	test: 0.817402
PRC train: 0.808968	val: 0.646795	test: 0.764633

Epoch: 7
Loss: 0.5125950493246524
ROC train: 0.864809	val: 0.790141	test: 0.816176
PRC train: 0.831697	val: 0.673450	test: 0.770110

Epoch: 8
Loss: 0.4803231824312351
ROC train: 0.870019	val: 0.808083	test: 0.834734
PRC train: 0.843730	val: 0.699429	test: 0.768099

Epoch: 9
Loss: 0.491387905605985
ROC train: 0.881528	val: 0.827292	test: 0.855217
PRC train: 0.857157	val: 0.729249	test: 0.796160

Epoch: 10
Loss: 0.4727489553451275
ROC train: 0.885097	val: 0.831098	test: 0.853641
PRC train: 0.863430	val: 0.736293	test: 0.786195

Epoch: 11
Loss: 0.45687572469321697
ROC train: 0.886881	val: 0.828017	test: 0.849090
PRC train: 0.866749	val: 0.739952	test: 0.780021

Epoch: 12
Loss: 0.46267667551716657
ROC train: 0.889880	val: 0.827836	test: 0.849265
PRC train: 0.868374	val: 0.734958	test: 0.757221

Epoch: 13
Loss: 0.45865212504633474
ROC train: 0.891638	val: 0.829105	test: 0.852766
PRC train: 0.870110	val: 0.717899	test: 0.755313

Epoch: 14
Loss: 0.44606710683193834
ROC train: 0.896856	val: 0.834360	test: 0.863270
PRC train: 0.877597	val: 0.739532	test: 0.781534

Epoch: 15
Loss: 0.4476118517672979
ROC train: 0.902841	val: 0.846321	test: 0.869398
PRC train: 0.884576	val: 0.757410	test: 0.805462

Epoch: 16
Loss: 0.45098855970713403
ROC train: 0.904343	val: 0.845777	test: 0.863445
PRC train: 0.885955	val: 0.753787	test: 0.797652

Epoch: 17
Loss: 0.4220999373964599
ROC train: 0.905281	val: 0.851395	test: 0.859944
PRC train: 0.887533	val: 0.768216	test: 0.794532

Epoch: 18
Loss: 0.4349203035884391
ROC train: 0.907227	val: 0.853389	test: 0.868172
PRC train: 0.888935	val: 0.764105	test: 0.800675

Epoch: 19
Loss: 0.42234703467040635
ROC train: 0.909567	val: 0.850308	test: 0.863095
PRC train: 0.892831	val: 0.756164	test: 0.789060

Epoch: 20
Loss: 0.416950314088648
ROC train: 0.912535	val: 0.850489	test: 0.864496
PRC train: 0.896253	val: 0.760536	test: 0.794463

Epoch: 21
Loss: 0.40305042235838967
ROC train: 0.914934	val: 0.850489	test: 0.855217
PRC train: 0.899316	val: 0.760209	test: 0.787083

Epoch: 22
Loss: 0.41306864598742327
ROC train: 0.916860	val: 0.853933	test: 0.862745
PRC train: 0.902426	val: 0.767528	test: 0.794470

Epoch: 23
Loss: 0.40443683792015045
ROC train: 0.917516	val: 0.848315	test: 0.863270
PRC train: 0.904213	val: 0.762755	test: 0.794334

Epoch: 24
Loss: 0.4200456845612937
ROC train: 0.919428	val: 0.855020	test: 0.867472
PRC train: 0.904354	val: 0.764775	test: 0.798174

Epoch: 25
Loss: 0.4119102170095913
ROC train: 0.917931	val: 0.850127	test: 0.864671
PRC train: 0.901099	val: 0.758540	test: 0.791587

Epoch: 26
Loss: 0.3935027895048455
ROC train: 0.918326	val: 0.855020	test: 0.881828
PRC train: 0.902270	val: 0.776628	test: 0.820256

Epoch: 27
Loss: 0.4154378459441047
ROC train: 0.921853	val: 0.857557	test: 0.868347
PRC train: 0.906998	val: 0.768065	test: 0.801794

Epoch: 28
Loss: 0.3927685876089025
ROC train: 0.922968	val: 0.857376	test: 0.863095
PRC train: 0.908345	val: 0.777625	test: 0.773244

Epoch: 29
Loss: 0.39898822734455053
ROC train: 0.925791	val: 0.857013	test: 0.860469
PRC train: 0.913429	val: 0.774138	test: 0.794782

Epoch: 30
Loss: 0.39274513465949257
ROC train: 0.924440	val: 0.855745	test: 0.867297
PRC train: 0.910863	val: 0.772816	test: 0.803762

Epoch: 31
Loss: 0.3972671814265708
ROC train: 0.920918	val: 0.849583	test: 0.849615
PRC train: 0.904682	val: 0.749394	test: 0.769529

Epoch: 32
Loss: 0.38331512217929864
ROC train: 0.927104	val: 0.859551	test: 0.871148
PRC train: 0.912754	val: 0.771031	test: 0.801963

Epoch: 33
Loss: 0.3823906053235358
ROC train: 0.929876	val: 0.874230	test: 0.883578Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphMVP/bace/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/split/GraphMVP/bace/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphMVP/bace/random/train_prop=0.7/bace_random_5_26-05_11-05-13  ]
[ Using Seed :  5  ]
[ Using device :  cuda:1  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
randomly split
Data(edge_attr=[78, 2], edge_index=[2, 78], id=[1], x=[37, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6712685261688321
ROC train: 0.678245	val: 0.659425	test: 0.651049
PRC train: 0.599794	val: 0.615137	test: 0.587262

Epoch: 2
Loss: 0.6439948491010019
ROC train: 0.709535	val: 0.682645	test: 0.694629
PRC train: 0.639270	val: 0.626727	test: 0.635010

Epoch: 3
Loss: 0.5821983897946473
ROC train: 0.770047	val: 0.726564	test: 0.776565
PRC train: 0.706888	val: 0.651641	test: 0.704679

Epoch: 4
Loss: 0.5757713643567046
ROC train: 0.812671	val: 0.763951	test: 0.840337
PRC train: 0.744391	val: 0.659691	test: 0.773399

Epoch: 5
Loss: 0.5519881020880082
ROC train: 0.825224	val: 0.768910	test: 0.840571
PRC train: 0.762364	val: 0.667881	test: 0.755495

Epoch: 6
Loss: 0.5355865167148923
ROC train: 0.834443	val: 0.746635	test: 0.809776
PRC train: 0.786067	val: 0.652523	test: 0.736177

Epoch: 7
Loss: 0.4916885360830162
ROC train: 0.854860	val: 0.766549	test: 0.852888
PRC train: 0.803612	val: 0.670321	test: 0.775081

Epoch: 8
Loss: 0.48591166632461646
ROC train: 0.861390	val: 0.780323	test: 0.864583
PRC train: 0.812857	val: 0.694552	test: 0.776769

Epoch: 9
Loss: 0.45374704222294665
ROC train: 0.867641	val: 0.783471	test: 0.852966
PRC train: 0.832367	val: 0.716475	test: 0.766492

Epoch: 10
Loss: 0.5049619870595243
ROC train: 0.877321	val: 0.807163	test: 0.863023
PRC train: 0.846682	val: 0.750326	test: 0.780291

Epoch: 11
Loss: 0.4655523587396079
ROC train: 0.877476	val: 0.812436	test: 0.847119
PRC train: 0.849722	val: 0.765149	test: 0.779135

Epoch: 12
Loss: 0.4806676457088116
ROC train: 0.878230	val: 0.812593	test: 0.847743
PRC train: 0.850787	val: 0.766764	test: 0.783862

Epoch: 13
Loss: 0.46631784511884533
ROC train: 0.886963	val: 0.812200	test: 0.859593
PRC train: 0.862326	val: 0.767159	test: 0.787526

Epoch: 14
Loss: 0.4686385842197371
ROC train: 0.896561	val: 0.808658	test: 0.874016
PRC train: 0.874729	val: 0.766235	test: 0.814697

Epoch: 15
Loss: 0.4106507112877507
ROC train: 0.892861	val: 0.813538	test: 0.876355
PRC train: 0.866919	val: 0.778357	test: 0.818499

Epoch: 16
Loss: 0.45143447227070255
ROC train: 0.903215	val: 0.804172	test: 0.866532
PRC train: 0.885419	val: 0.753902	test: 0.797147

Epoch: 17
Loss: 0.421221279850515
ROC train: 0.904129	val: 0.792837	test: 0.857956
PRC train: 0.885339	val: 0.750027	test: 0.793968

Epoch: 18
Loss: 0.4365034255801719
ROC train: 0.902944	val: 0.809603	test: 0.873236
PRC train: 0.880709	val: 0.777406	test: 0.818946

Epoch: 19
Loss: 0.4390705823447584
ROC train: 0.900368	val: 0.809996	test: 0.880564
PRC train: 0.880263	val: 0.767640	test: 0.829129

Epoch: 20
Loss: 0.42175613324864036
ROC train: 0.903985	val: 0.812121	test: 0.880876
PRC train: 0.881420	val: 0.755912	test: 0.813154

Epoch: 21
Loss: 0.4030995411849303
ROC train: 0.904025	val: 0.813459	test: 0.875107
PRC train: 0.879309	val: 0.751407	test: 0.796810

Epoch: 22
Loss: 0.44475399278894195
ROC train: 0.909819	val: 0.808107	test: 0.869026
PRC train: 0.891302	val: 0.754090	test: 0.791370

Epoch: 23
Loss: 0.41280494090012887
ROC train: 0.911331	val: 0.816372	test: 0.864271
PRC train: 0.891225	val: 0.757342	test: 0.792687

Epoch: 24
Loss: 0.41451285443693103
ROC train: 0.903729	val: 0.819126	test: 0.864738
PRC train: 0.880561	val: 0.763404	test: 0.803629

Epoch: 25
Loss: 0.42544518318002533
ROC train: 0.908476	val: 0.809760	test: 0.865128
PRC train: 0.887077	val: 0.750614	test: 0.797321

Epoch: 26
Loss: 0.4128474094790892
ROC train: 0.908569	val: 0.784573	test: 0.854837
PRC train: 0.891163	val: 0.731682	test: 0.778539

Epoch: 27
Loss: 0.4180579525922184
ROC train: 0.915207	val: 0.804801	test: 0.882669
PRC train: 0.897336	val: 0.759563	test: 0.818135

Epoch: 28
Loss: 0.3988611274231089
ROC train: 0.907917	val: 0.818969	test: 0.893662
PRC train: 0.884500	val: 0.783220	test: 0.836508

Epoch: 29
Loss: 0.41618236360748445
ROC train: 0.917364	val: 0.819284	test: 0.895845
PRC train: 0.897767	val: 0.787965	test: 0.840748

Epoch: 30
Loss: 0.4005082880988896
ROC train: 0.920617	val: 0.810468	test: 0.886801
PRC train: 0.903705	val: 0.781477	test: 0.823499

Epoch: 31
Loss: 0.4051362872609971
ROC train: 0.917598	val: 0.800315	test: 0.877446
PRC train: 0.901898	val: 0.756506	test: 0.814841

Epoch: 32
Loss: 0.3864656425561605
ROC train: 0.921892	val: 0.798741	test: 0.878537
PRC train: 0.909265	val: 0.758327	test: 0.812675

Epoch: 33
Loss: 0.41055878626704
ROC train: 0.919460	val: 0.809917	test: 0.892259ROC train: 0.943609	val: 0.829669	test: 0.845756
PRC train: 0.927064	val: 0.800776	test: 0.777464

Epoch: 34
Loss: 0.3667522817391215
ROC train: 0.946284	val: 0.828220	test: 0.846419
PRC train: 0.930001	val: 0.796587	test: 0.780176

Epoch: 35
Loss: 0.34912054060948206
ROC train: 0.947470	val: 0.832434	test: 0.848187
PRC train: 0.933957	val: 0.803226	test: 0.782347

Epoch: 36
Loss: 0.33820914331979934
ROC train: 0.946926	val: 0.829361	test: 0.847569
PRC train: 0.933374	val: 0.800466	test: 0.778460

Epoch: 37
Loss: 0.34495948791804176
ROC train: 0.947688	val: 0.834233	test: 0.850575
PRC train: 0.933050	val: 0.809278	test: 0.781126

Epoch: 38
Loss: 0.33496245685733406
ROC train: 0.948898	val: 0.833311	test: 0.850354
PRC train: 0.934371	val: 0.809900	test: 0.780844

Epoch: 39
Loss: 0.3455720576730551
ROC train: 0.950792	val: 0.830766	test: 0.851592
PRC train: 0.936912	val: 0.801478	test: 0.780529

Epoch: 40
Loss: 0.32425713207368173
ROC train: 0.952298	val: 0.829581	test: 0.851680
PRC train: 0.940218	val: 0.798545	test: 0.780248

Epoch: 41
Loss: 0.3452215543901716
ROC train: 0.953976	val: 0.821988	test: 0.853360
PRC train: 0.943485	val: 0.788126	test: 0.782751

Epoch: 42
Loss: 0.3326691002645096
ROC train: 0.954883	val: 0.820715	test: 0.851282
PRC train: 0.944119	val: 0.787661	test: 0.776514

Epoch: 43
Loss: 0.33627491776661256
ROC train: 0.955471	val: 0.827957	test: 0.849956
PRC train: 0.945310	val: 0.800911	test: 0.773697

Epoch: 44
Loss: 0.3256648698232033
ROC train: 0.956228	val: 0.832873	test: 0.854465
PRC train: 0.945752	val: 0.807317	test: 0.786369

Epoch: 45
Loss: 0.3241739259765483
ROC train: 0.959219	val: 0.840553	test: 0.859814
PRC train: 0.947905	val: 0.815318	test: 0.793420

Epoch: 46
Loss: 0.30660504566351343
ROC train: 0.960853	val: 0.839895	test: 0.865385
PRC train: 0.949138	val: 0.807946	test: 0.803065

Epoch: 47
Loss: 0.31054867549353815
ROC train: 0.960189	val: 0.835725	test: 0.861583
PRC train: 0.949786	val: 0.800608	test: 0.788425

Epoch: 48
Loss: 0.3192015929939771
ROC train: 0.960022	val: 0.831380	test: 0.853492
PRC train: 0.949017	val: 0.799225	test: 0.779852

Epoch: 49
Loss: 0.3035832242422549
ROC train: 0.958685	val: 0.828484	test: 0.845933
PRC train: 0.946726	val: 0.799250	test: 0.776605

Epoch: 50
Loss: 0.31459688241111844
ROC train: 0.961179	val: 0.831117	test: 0.848055
PRC train: 0.949946	val: 0.800077	test: 0.775587

Epoch: 51
Loss: 0.3329293847245568
ROC train: 0.961267	val: 0.834804	test: 0.851857
PRC train: 0.950341	val: 0.801171	test: 0.782247

Epoch: 52
Loss: 0.3138879811862304
ROC train: 0.962818	val: 0.829537	test: 0.859903
PRC train: 0.952816	val: 0.794218	test: 0.798572

Epoch: 53
Loss: 0.30065176024452966
ROC train: 0.963499	val: 0.833355	test: 0.856499
PRC train: 0.953463	val: 0.804797	test: 0.793150

Epoch: 54
Loss: 0.29667636169166905
ROC train: 0.963379	val: 0.837612	test: 0.854200
PRC train: 0.954440	val: 0.812663	test: 0.788165

Epoch: 55
Loss: 0.29525729507085746
ROC train: 0.962504	val: 0.842177	test: 0.849823
PRC train: 0.953496	val: 0.817199	test: 0.784055

Epoch: 56
Loss: 0.29454611929004043
ROC train: 0.963420	val: 0.834145	test: 0.852078
PRC train: 0.952788	val: 0.806274	test: 0.787286

Epoch: 57
Loss: 0.31565250792563176
ROC train: 0.964148	val: 0.828747	test: 0.854863
PRC train: 0.953114	val: 0.796219	test: 0.791863

Epoch: 58
Loss: 0.3127375467976827
ROC train: 0.965123	val: 0.837393	test: 0.856764
PRC train: 0.956028	val: 0.802038	test: 0.792917

Epoch: 59
Loss: 0.27542882534029856
ROC train: 0.967916	val: 0.840465	test: 0.856233
PRC train: 0.958387	val: 0.804557	test: 0.788832

Epoch: 60
Loss: 0.2844397845679443
ROC train: 0.967558	val: 0.837569	test: 0.848939
PRC train: 0.958126	val: 0.802914	test: 0.777089

Epoch: 61
Loss: 0.3022958049064697
ROC train: 0.966990	val: 0.840246	test: 0.849072
PRC train: 0.957564	val: 0.812992	test: 0.775767

Epoch: 62
Loss: 0.297952836408403
ROC train: 0.967675	val: 0.842528	test: 0.853758
PRC train: 0.958678	val: 0.813091	test: 0.785744

Epoch: 63
Loss: 0.2895628629988224
ROC train: 0.969802	val: 0.839939	test: 0.856410
PRC train: 0.960705	val: 0.804860	test: 0.791686

Epoch: 64
Loss: 0.28864371842596453
ROC train: 0.968891	val: 0.841431	test: 0.853404
PRC train: 0.960290	val: 0.807237	test: 0.787788

Epoch: 65
Loss: 0.28605617327601573
ROC train: 0.966602	val: 0.841475	test: 0.850044
PRC train: 0.957742	val: 0.809303	test: 0.784529

Epoch: 66
Loss: 0.2658464655621665
ROC train: 0.966985	val: 0.840597	test: 0.849602
PRC train: 0.958480	val: 0.807027	test: 0.787874

Epoch: 67
Loss: 0.2827914344142963
ROC train: 0.966620	val: 0.838929	test: 0.842308
PRC train: 0.958242	val: 0.813123	test: 0.772565

Epoch: 68
Loss: 0.27570658928216046
ROC train: 0.965664	val: 0.835286	test: 0.839434
PRC train: 0.956626	val: 0.812129	test: 0.768291

Epoch: 69
Loss: 0.2963449490368219
ROC train: 0.971370	val: 0.836427	test: 0.846994
PRC train: 0.964292	val: 0.809062	test: 0.779294

Epoch: 70
Loss: 0.27085185140476525
ROC train: 0.973070	val: 0.831995	test: 0.854996
PRC train: 0.966405	val: 0.799878	test: 0.793053

Epoch: 71
Loss: 0.2711835263407244
ROC train: 0.973690	val: 0.827562	test: 0.863616
PRC train: 0.966579	val: 0.788480	test: 0.805518

Epoch: 72
Loss: 0.2609301435963961
ROC train: 0.973726	val: 0.829142	test: 0.863572
PRC train: 0.967004	val: 0.786475	test: 0.801740

Epoch: 73
Loss: 0.2873127354821893
ROC train: 0.970103	val: 0.828966	test: 0.862997
PRC train: 0.962552	val: 0.786699	test: 0.795485

Epoch: 74
Loss: 0.28065661477846937
ROC train: 0.957815	val: 0.820628	test: 0.854200
PRC train: 0.947658	val: 0.773949	test: 0.784695

Epoch: 75
Loss: 0.28918612955023704
ROC train: 0.971561	val: 0.825587	test: 0.859682
PRC train: 0.963912	val: 0.773998	test: 0.789115

Epoch: 76
Loss: 0.2659595587474227
ROC train: 0.971791	val: 0.831468	test: 0.850531
PRC train: 0.965072	val: 0.797219	test: 0.778115

Epoch: 77
Loss: 0.27731437379762647
ROC train: 0.974309	val: 0.843581	test: 0.854067
PRC train: 0.968255	val: 0.818600	test: 0.782987

Epoch: 78
Loss: 0.2551779904177151
ROC train: 0.972430	val: 0.847048	test: 0.855305
PRC train: 0.965230	val: 0.819316	test: 0.787746

Epoch: 79
Loss: 0.27765998544124365
ROC train: 0.974971	val: 0.849155	test: 0.856101
PRC train: 0.969294	val: 0.822254	test: 0.789996

Epoch: 80
Loss: 0.28501116534646753
ROC train: 0.975348	val: 0.843055	test: 0.845225
PRC train: 0.970222	val: 0.827287	test: 0.774223

Epoch: 81
Loss: 0.24792770420327928
ROC train: 0.972722	val: 0.828396	test: 0.843324
PRC train: 0.966742	val: 0.804109	test: 0.778706

Epoch: 82
Loss: 0.2607793802212961
ROC train: 0.975289	val: 0.840772	test: 0.849293
PRC train: 0.969289	val: 0.829226	test: 0.783120

Epoch: 83
Loss: 0.2644656718564591
ROC train: 0.977465	val: 0.848102	test: 0.848718
PRC train: 0.971316	val: 0.834019	test: 0.775660

Epoch: 84
Loss: 0.2605890455556822
ROC train: 0.975108	val: 0.839105	test: 0.845579
PRC train: 0.969852	val: 0.812698	test: 0.771040

Epoch: 85
Loss: 0.27549549036153237
ROC train: 0.976196	val: 0.833838	test: 0.852166
PRC train: 0.971343	val: 0.802373	test: 0.786289

Epoch: 86
Loss: 0.2416876162996903
ROC train: 0.977372	val: 0.837920	test: 0.849867
PRC train: 0.972435	val: 0.818653	test: 0.780807

Epoch: 87
Loss: 0.24327168369609126
ROC train: 0.978712	val: 0.841080	test: 0.852918
PRC train: 0.973934	val: 0.819212	test: 0.784182

Epoch: 88
Loss: 0.25703182510669287
ROC train: 0.977141	val: 0.832697	test: 0.854598
PRC train: 0.972080	val: 0.797946	test: 0.784933

Epoch: 89
Loss: 0.25432730705533874
ROC train: 0.958949	val: 0.817819	test: 0.851105
PRC train: 0.948936	val: 0.787487	test: 0.782847

Epoch: 90
Loss: 0.25626836683843063
ROC train: 0.966470	val: 0.830064	test: 0.853139
PRC train: 0.958507	val: 0.807734	test: 0.785326

Epoch: 91
Loss: 0.24437052105124124
ROC train: 0.979856	val: 0.839895	test: 0.853581
PRC train: 0.974972	val: 0.818137	test: 0.784473

Epoch: 92
Loss: 0.24836347907770498
ROC train: 0.977141	val: 0.835330	test: 0.853581
PRC train: 0.971315	val: 0.815929	test: 0.786372

Epoch: 93
Loss: 0.24791745600386586
ROC train: 0.979204	val: 0.838666	test: 0.856145
PRC train: 0.974657	val: 0.818278	test: 0.791625

Epoch: 94
Loss: 0.24627225237783212
ROC train: 0.935589	val: 0.830020	test: 0.843059
PRC train: 0.921440	val: 0.804610	test: 0.766317

Epoch: 34
Loss: 0.38399916852398563
ROC train: 0.935618	val: 0.826684	test: 0.850000
PRC train: 0.921029	val: 0.797485	test: 0.776699

Epoch: 35
Loss: 0.3458860878930902
ROC train: 0.935824	val: 0.829669	test: 0.851061
PRC train: 0.922742	val: 0.807610	test: 0.775705

Epoch: 36
Loss: 0.35579174810241554
ROC train: 0.936240	val: 0.825631	test: 0.851901
PRC train: 0.923071	val: 0.805497	test: 0.782298

Epoch: 37
Loss: 0.3827202294126179
ROC train: 0.929954	val: 0.812201	test: 0.845181
PRC train: 0.917853	val: 0.790700	test: 0.782908

Epoch: 38
Loss: 0.36477563531428947
ROC train: 0.929844	val: 0.810972	test: 0.852343
PRC train: 0.916167	val: 0.778944	test: 0.794924

Epoch: 39
Loss: 0.36600046852596485
ROC train: 0.943087	val: 0.827913	test: 0.855836
PRC train: 0.930520	val: 0.799117	test: 0.785753

Epoch: 40
Loss: 0.3594640352768858
ROC train: 0.940133	val: 0.837525	test: 0.850663
PRC train: 0.926164	val: 0.809088	test: 0.772024

Epoch: 41
Loss: 0.351706436040309
ROC train: 0.937715	val: 0.834672	test: 0.841600
PRC train: 0.923122	val: 0.806666	test: 0.758844

Epoch: 42
Loss: 0.3555661296035414
ROC train: 0.944981	val: 0.835199	test: 0.854951
PRC train: 0.932669	val: 0.808964	test: 0.779781

Epoch: 43
Loss: 0.33655339229549874
ROC train: 0.946424	val: 0.829318	test: 0.855438
PRC train: 0.933205	val: 0.796193	test: 0.783657

Epoch: 44
Loss: 0.3543369804552778
ROC train: 0.948244	val: 0.834014	test: 0.851857
PRC train: 0.933915	val: 0.799956	test: 0.773798

Epoch: 45
Loss: 0.35388558033300077
ROC train: 0.949386	val: 0.836691	test: 0.854863
PRC train: 0.934961	val: 0.797183	test: 0.777972

Epoch: 46
Loss: 0.3209641784911711
ROC train: 0.949557	val: 0.833531	test: 0.858267
PRC train: 0.934781	val: 0.791346	test: 0.783592

Epoch: 47
Loss: 0.33803817148359183
ROC train: 0.951502	val: 0.832785	test: 0.859859
PRC train: 0.939168	val: 0.797286	test: 0.786910

Epoch: 48
Loss: 0.3475741737832476
ROC train: 0.951806	val: 0.832126	test: 0.860301
PRC train: 0.940475	val: 0.799517	test: 0.789699

Epoch: 49
Loss: 0.3350119754083098
ROC train: 0.951262	val: 0.835067	test: 0.863218
PRC train: 0.939686	val: 0.806283	test: 0.793451

Epoch: 50
Loss: 0.3404823025708147
ROC train: 0.952183	val: 0.835462	test: 0.864854
PRC train: 0.939463	val: 0.807089	test: 0.795520

Epoch: 51
Loss: 0.3295945685014641
ROC train: 0.950424	val: 0.840597	test: 0.860698
PRC train: 0.937717	val: 0.814416	test: 0.790079

Epoch: 52
Loss: 0.33042435283657
ROC train: 0.950914	val: 0.840465	test: 0.856543
PRC train: 0.936860	val: 0.801138	test: 0.781974

Epoch: 53
Loss: 0.3249408765015513
ROC train: 0.951394	val: 0.832390	test: 0.851857
PRC train: 0.939823	val: 0.787189	test: 0.776793

Epoch: 54
Loss: 0.3219193054291392
ROC train: 0.955407	val: 0.831073	test: 0.856410
PRC train: 0.945723	val: 0.791803	test: 0.783208

Epoch: 55
Loss: 0.3323660057474376
ROC train: 0.955206	val: 0.840114	test: 0.857206
PRC train: 0.944352	val: 0.815856	test: 0.780648

Epoch: 56
Loss: 0.3162522196399228
ROC train: 0.951576	val: 0.838183	test: 0.848851
PRC train: 0.940653	val: 0.808772	test: 0.770914

Epoch: 57
Loss: 0.3115737685948656
ROC train: 0.953251	val: 0.834672	test: 0.847569
PRC train: 0.942673	val: 0.800115	test: 0.773572

Epoch: 58
Loss: 0.3229628312827786
ROC train: 0.956514	val: 0.834979	test: 0.844695
PRC train: 0.946236	val: 0.805712	test: 0.769089

Epoch: 59
Loss: 0.31539717427970415
ROC train: 0.958499	val: 0.838929	test: 0.848408
PRC train: 0.947349	val: 0.814071	test: 0.777465

Epoch: 60
Loss: 0.3060916423248986
ROC train: 0.958170	val: 0.838534	test: 0.852697
PRC train: 0.947356	val: 0.809731	test: 0.784965

Epoch: 61
Loss: 0.314803301888114
ROC train: 0.958837	val: 0.838885	test: 0.857118
PRC train: 0.948233	val: 0.810473	test: 0.791718

Epoch: 62
Loss: 0.3222044165289259
ROC train: 0.961218	val: 0.837042	test: 0.854951
PRC train: 0.950972	val: 0.812871	test: 0.787679

Epoch: 63
Loss: 0.30009756392121956
ROC train: 0.962551	val: 0.836164	test: 0.852829
PRC train: 0.953064	val: 0.808916	test: 0.779719

Epoch: 64
Loss: 0.3195214502954141
ROC train: 0.960116	val: 0.832083	test: 0.851061
PRC train: 0.950210	val: 0.798815	test: 0.777993

Epoch: 65
Loss: 0.28620009340972086
ROC train: 0.960983	val: 0.829493	test: 0.852210
PRC train: 0.950280	val: 0.795781	test: 0.779462

Epoch: 66
Loss: 0.3026522809689797
ROC train: 0.960718	val: 0.835813	test: 0.852255
PRC train: 0.950219	val: 0.809168	test: 0.775645

Epoch: 67
Loss: 0.31044364058460566
ROC train: 0.958807	val: 0.841431	test: 0.852608
PRC train: 0.948443	val: 0.817148	test: 0.781114

Epoch: 68
Loss: 0.3068982856163429
ROC train: 0.963937	val: 0.842309	test: 0.863263
PRC train: 0.954460	val: 0.820512	test: 0.797676

Epoch: 69
Loss: 0.30063088954073935
ROC train: 0.962702	val: 0.840641	test: 0.857073
PRC train: 0.953590	val: 0.819915	test: 0.795780

Epoch: 70
Loss: 0.2924369755204822
ROC train: 0.961056	val: 0.842045	test: 0.851282
PRC train: 0.952028	val: 0.824333	test: 0.785942

Epoch: 71
Loss: 0.2941731136606305
ROC train: 0.961830	val: 0.847400	test: 0.849779
PRC train: 0.952703	val: 0.831593	test: 0.777437

Epoch: 72
Loss: 0.31576002631472966
ROC train: 0.959719	val: 0.843669	test: 0.846552
PRC train: 0.950154	val: 0.824871	test: 0.769230

Epoch: 73
Loss: 0.28287463101920096
ROC train: 0.964488	val: 0.843450	test: 0.848718
PRC train: 0.956211	val: 0.820457	test: 0.774472

Epoch: 74
Loss: 0.2885724243426946
ROC train: 0.968653	val: 0.846215	test: 0.858665
PRC train: 0.961181	val: 0.815249	test: 0.787889

Epoch: 75
Loss: 0.2908696607462007
ROC train: 0.968893	val: 0.839939	test: 0.868656
PRC train: 0.961384	val: 0.805825	test: 0.803480

Epoch: 76
Loss: 0.27966201816073777
ROC train: 0.968582	val: 0.835023	test: 0.862997
PRC train: 0.962050	val: 0.811685	test: 0.799086

Epoch: 77
Loss: 0.27007456539289365
ROC train: 0.970003	val: 0.838841	test: 0.855084
PRC train: 0.964141	val: 0.817951	test: 0.788437

Epoch: 78
Loss: 0.2695459987487317
ROC train: 0.971502	val: 0.845205	test: 0.860080
PRC train: 0.965122	val: 0.826710	test: 0.791791

Epoch: 79
Loss: 0.2813150173506799
ROC train: 0.971429	val: 0.844196	test: 0.861715
PRC train: 0.964374	val: 0.828379	test: 0.793437

Epoch: 80
Loss: 0.2781400633084732
ROC train: 0.971820	val: 0.833268	test: 0.858444
PRC train: 0.965224	val: 0.810833	test: 0.791564

Epoch: 81
Loss: 0.27340846349571124
ROC train: 0.972918	val: 0.842923	test: 0.845402
PRC train: 0.966902	val: 0.828003	test: 0.769709

Epoch: 82
Loss: 0.3029058989750522
ROC train: 0.962166	val: 0.829888	test: 0.838417
PRC train: 0.952389	val: 0.799221	test: 0.759413

Epoch: 83
Loss: 0.27124846671030833
ROC train: 0.959251	val: 0.821944	test: 0.842750
PRC train: 0.946479	val: 0.771911	test: 0.766988

Epoch: 84
Loss: 0.29632315067748544
ROC train: 0.969520	val: 0.837086	test: 0.845579
PRC train: 0.961637	val: 0.807365	test: 0.769617

Epoch: 85
Loss: 0.26906831164169304
ROC train: 0.972492	val: 0.845951	test: 0.852122
PRC train: 0.965211	val: 0.827129	test: 0.776478

Epoch: 86
Loss: 0.28346156155381336
ROC train: 0.973138	val: 0.844591	test: 0.868391
PRC train: 0.966008	val: 0.827203	test: 0.803874

Epoch: 87
Loss: 0.26474919590145257
ROC train: 0.972550	val: 0.834540	test: 0.868656
PRC train: 0.965088	val: 0.813455	test: 0.813292

Epoch: 88
Loss: 0.28727210289222405
ROC train: 0.976007	val: 0.834672	test: 0.859505
PRC train: 0.970703	val: 0.814778	test: 0.801081

Epoch: 89
Loss: 0.27295875923136215
ROC train: 0.977847	val: 0.841255	test: 0.850354
PRC train: 0.973609	val: 0.830543	test: 0.781231

Epoch: 90
Loss: 0.2792261784533573
ROC train: 0.971115	val: 0.834584	test: 0.846463
PRC train: 0.965595	val: 0.825646	test: 0.776662

Epoch: 91
Loss: 0.2833221054559414
ROC train: 0.967987	val: 0.835594	test: 0.844607
PRC train: 0.961989	val: 0.817612	test: 0.769961

Epoch: 92
Loss: 0.2634504765136736
ROC train: 0.972631	val: 0.841387	test: 0.853935
PRC train: 0.966555	val: 0.822501	test: 0.774254

Epoch: 93
Loss: 0.27148429088252246
ROC train: 0.974981	val: 0.840465	test: 0.857029
PRC train: 0.969184	val: 0.825001	test: 0.784883

Epoch: 94
Loss: 0.27209019210029506ROC train: 0.940557	val: 0.830151	test: 0.843811
PRC train: 0.927921	val: 0.794139	test: 0.759996

Epoch: 34
Loss: 0.3792601070439279
ROC train: 0.941243	val: 0.832960	test: 0.844607
PRC train: 0.928402	val: 0.803036	test: 0.761490

Epoch: 35
Loss: 0.3572930234547495
ROC train: 0.941644	val: 0.831161	test: 0.841689
PRC train: 0.928319	val: 0.796275	test: 0.754864

Epoch: 36
Loss: 0.34878898822041293
ROC train: 0.943046	val: 0.831644	test: 0.841777
PRC train: 0.930361	val: 0.796554	test: 0.756963

Epoch: 37
Loss: 0.34656519156141646
ROC train: 0.941238	val: 0.833750	test: 0.840584
PRC train: 0.927751	val: 0.804136	test: 0.755586

Epoch: 38
Loss: 0.35686415663293103
ROC train: 0.944986	val: 0.834628	test: 0.847834
PRC train: 0.933317	val: 0.809082	test: 0.769518

Epoch: 39
Loss: 0.35803637633340546
ROC train: 0.947458	val: 0.836252	test: 0.853492
PRC train: 0.936345	val: 0.805838	test: 0.783558

Epoch: 40
Loss: 0.34767302121934945
ROC train: 0.949150	val: 0.839456	test: 0.856233
PRC train: 0.938556	val: 0.814826	test: 0.787795

Epoch: 41
Loss: 0.3622505505723481
ROC train: 0.947519	val: 0.831688	test: 0.851061
PRC train: 0.936202	val: 0.800658	test: 0.782419

Epoch: 42
Loss: 0.3338624253942476
ROC train: 0.949601	val: 0.826421	test: 0.851282
PRC train: 0.939309	val: 0.791055	test: 0.780576

Epoch: 43
Loss: 0.35787657059556505
ROC train: 0.951965	val: 0.830195	test: 0.846552
PRC train: 0.941822	val: 0.793930	test: 0.767147

Epoch: 44
Loss: 0.3428547914249084
ROC train: 0.953271	val: 0.834452	test: 0.846242
PRC train: 0.942615	val: 0.800295	test: 0.761579

Epoch: 45
Loss: 0.31861976517923507
ROC train: 0.952477	val: 0.838534	test: 0.843501
PRC train: 0.942046	val: 0.805750	test: 0.757740

Epoch: 46
Loss: 0.33125251803202416
ROC train: 0.950669	val: 0.835901	test: 0.842927
PRC train: 0.940520	val: 0.807016	test: 0.755810

Epoch: 47
Loss: 0.34178153840907005
ROC train: 0.952962	val: 0.831688	test: 0.851636
PRC train: 0.943202	val: 0.801544	test: 0.772818

Epoch: 48
Loss: 0.3446745600973661
ROC train: 0.956448	val: 0.834057	test: 0.854111
PRC train: 0.947049	val: 0.804605	test: 0.773583

Epoch: 49
Loss: 0.3161913542261313
ROC train: 0.954868	val: 0.837042	test: 0.844253
PRC train: 0.944576	val: 0.808455	test: 0.759029

Epoch: 50
Loss: 0.3147352916170501
ROC train: 0.956990	val: 0.832390	test: 0.850044
PRC train: 0.947724	val: 0.802300	test: 0.772344

Epoch: 51
Loss: 0.330133706545254
ROC train: 0.956314	val: 0.831556	test: 0.854642
PRC train: 0.947851	val: 0.797758	test: 0.777049

Epoch: 52
Loss: 0.3113542003495302
ROC train: 0.957259	val: 0.835813	test: 0.853227
PRC train: 0.948651	val: 0.807891	test: 0.771222

Epoch: 53
Loss: 0.33310712179728597
ROC train: 0.958347	val: 0.841650	test: 0.849204
PRC train: 0.949424	val: 0.811428	test: 0.764504

Epoch: 54
Loss: 0.33184467697285863
ROC train: 0.957426	val: 0.835857	test: 0.840893
PRC train: 0.948289	val: 0.797364	test: 0.756149

Epoch: 55
Loss: 0.32920745014991254
ROC train: 0.959479	val: 0.838227	test: 0.848364
PRC train: 0.950541	val: 0.805396	test: 0.769215

Epoch: 56
Loss: 0.3229038811773073
ROC train: 0.958278	val: 0.839017	test: 0.854553
PRC train: 0.948794	val: 0.808036	test: 0.783058

Epoch: 57
Loss: 0.32032212719646447
ROC train: 0.961879	val: 0.839368	test: 0.857604
PRC train: 0.952728	val: 0.808879	test: 0.783057

Epoch: 58
Loss: 0.29236596191448483
ROC train: 0.963026	val: 0.837964	test: 0.848541
PRC train: 0.954362	val: 0.804038	test: 0.765717

Epoch: 59
Loss: 0.3101439682768115
ROC train: 0.962766	val: 0.829361	test: 0.847613
PRC train: 0.953764	val: 0.789082	test: 0.769791

Epoch: 60
Loss: 0.330086819653844
ROC train: 0.964991	val: 0.832609	test: 0.856278
PRC train: 0.955290	val: 0.801658	test: 0.785524

Epoch: 61
Loss: 0.29573609291641195
ROC train: 0.961806	val: 0.842835	test: 0.854377
PRC train: 0.951764	val: 0.823482	test: 0.780546

Epoch: 62
Loss: 0.29936027891622213
ROC train: 0.963717	val: 0.840553	test: 0.856012
PRC train: 0.954490	val: 0.820764	test: 0.783105

Epoch: 63
Loss: 0.30496945876777987
ROC train: 0.966593	val: 0.830371	test: 0.864677
PRC train: 0.958325	val: 0.801057	test: 0.799432

Epoch: 64
Loss: 0.2844413936031595
ROC train: 0.968234	val: 0.831424	test: 0.857958
PRC train: 0.961127	val: 0.800545	test: 0.785803

Epoch: 65
Loss: 0.29702192335260125
ROC train: 0.967867	val: 0.836954	test: 0.851370
PRC train: 0.960582	val: 0.812179	test: 0.764831

Epoch: 66
Loss: 0.2923350417433562
ROC train: 0.967421	val: 0.835637	test: 0.846463
PRC train: 0.959828	val: 0.811002	test: 0.752427

Epoch: 67
Loss: 0.29542607642009955
ROC train: 0.967235	val: 0.825411	test: 0.854907
PRC train: 0.959545	val: 0.790684	test: 0.773212

Epoch: 68
Loss: 0.28642132168445505
ROC train: 0.967617	val: 0.823261	test: 0.860035
PRC train: 0.960051	val: 0.781759	test: 0.785725

Epoch: 69
Loss: 0.2944848335746708
ROC train: 0.970596	val: 0.833136	test: 0.852034
PRC train: 0.964446	val: 0.799211	test: 0.775820

Epoch: 70
Loss: 0.30688422010382765
ROC train: 0.971835	val: 0.836296	test: 0.856012
PRC train: 0.965595	val: 0.803918	test: 0.782125

Epoch: 71
Loss: 0.2960140503883104
ROC train: 0.970101	val: 0.839675	test: 0.858930
PRC train: 0.963252	val: 0.817687	test: 0.785612

Epoch: 72
Loss: 0.2759098456800562
ROC train: 0.969883	val: 0.833575	test: 0.858134
PRC train: 0.963399	val: 0.814478	test: 0.791019

Epoch: 73
Loss: 0.2961842176468564
ROC train: 0.970336	val: 0.829186	test: 0.849956
PRC train: 0.963744	val: 0.806655	test: 0.774006

Epoch: 74
Loss: 0.291517681236634
ROC train: 0.967896	val: 0.823349	test: 0.845225
PRC train: 0.961044	val: 0.797790	test: 0.763900

Epoch: 75
Loss: 0.2929845387475491
ROC train: 0.969674	val: 0.822515	test: 0.845800
PRC train: 0.962515	val: 0.793125	test: 0.764611

Epoch: 76
Loss: 0.27113134400637584
ROC train: 0.971762	val: 0.822559	test: 0.853581
PRC train: 0.965037	val: 0.791418	test: 0.773672

Epoch: 77
Loss: 0.2789466417826426
ROC train: 0.973530	val: 0.834672	test: 0.860698
PRC train: 0.967637	val: 0.811666	test: 0.779028

Epoch: 78
Loss: 0.26735033194798874
ROC train: 0.973099	val: 0.839851	test: 0.854775
PRC train: 0.966870	val: 0.821306	test: 0.775153

Epoch: 79
Loss: 0.257969796619618
ROC train: 0.973815	val: 0.837305	test: 0.854111
PRC train: 0.968371	val: 0.819424	test: 0.778052

Epoch: 80
Loss: 0.2745584336620112
ROC train: 0.973721	val: 0.830195	test: 0.855659
PRC train: 0.968204	val: 0.807615	test: 0.790228

Epoch: 81
Loss: 0.2859512292625848
ROC train: 0.970375	val: 0.821988	test: 0.859416
PRC train: 0.963100	val: 0.789381	test: 0.798358

Epoch: 82
Loss: 0.27186032685964756
ROC train: 0.975662	val: 0.838490	test: 0.866932
PRC train: 0.970247	val: 0.817156	test: 0.797648

Epoch: 83
Loss: 0.26869101076640894
ROC train: 0.968891	val: 0.837832	test: 0.840672
PRC train: 0.962167	val: 0.821084	test: 0.764228

Epoch: 84
Loss: 0.2784786256308753
ROC train: 0.976017	val: 0.832521	test: 0.838992
PRC train: 0.970632	val: 0.811987	test: 0.766737

Epoch: 85
Loss: 0.26900774268822997
ROC train: 0.973658	val: 0.822910	test: 0.845889
PRC train: 0.967560	val: 0.797862	test: 0.781593

Epoch: 86
Loss: 0.2946570803815232
ROC train: 0.974814	val: 0.830722	test: 0.859151
PRC train: 0.968956	val: 0.796473	test: 0.793550

Epoch: 87
Loss: 0.2708502952761939
ROC train: 0.972683	val: 0.830634	test: 0.866004
PRC train: 0.965590	val: 0.801056	test: 0.804047

Epoch: 88
Loss: 0.26659441626699953
ROC train: 0.974202	val: 0.839544	test: 0.853802
PRC train: 0.968431	val: 0.824148	test: 0.775329

Epoch: 89
Loss: 0.26709475208930655
ROC train: 0.977678	val: 0.838666	test: 0.854421
PRC train: 0.973203	val: 0.817124	test: 0.776997

Epoch: 90
Loss: 0.2592560733884808
ROC train: 0.977749	val: 0.834189	test: 0.860875
PRC train: 0.972856	val: 0.806810	test: 0.792634

Epoch: 91
Loss: 0.25035097721525734
ROC train: 0.977249	val: 0.833838	test: 0.853669
PRC train: 0.971566	val: 0.796065	test: 0.782827

Epoch: 92
Loss: 0.26205755929058544
ROC train: 0.973849	val: 0.828001	test: 0.837931
PRC train: 0.966726	val: 0.783223	test: 0.756834

Epoch: 93
Loss: 0.26222719938321437
ROC train: 0.976678	val: 0.826333	test: 0.842794
PRC train: 0.969970	val: 0.784821	test: 0.762883

Epoch: 94
Loss: 0.2501652701212581
PRC train: 0.906286	val: 0.780496	test: 0.812358

Epoch: 34
Loss: 0.42069726486208514
ROC train: 0.920716	val: 0.818654	test: 0.879941
PRC train: 0.902731	val: 0.780100	test: 0.800840

Epoch: 35
Loss: 0.3812340455899833
ROC train: 0.919871	val: 0.827942	test: 0.877524
PRC train: 0.902680	val: 0.790481	test: 0.811203

Epoch: 36
Loss: 0.3786439490420923
ROC train: 0.927790	val: 0.823849	test: 0.881110
PRC train: 0.908244	val: 0.784740	test: 0.815072

Epoch: 37
Loss: 0.38405231141990315
ROC train: 0.922136	val: 0.798977	test: 0.881656
PRC train: 0.898699	val: 0.759395	test: 0.822379

Epoch: 38
Loss: 0.39928515715073853
ROC train: 0.926698	val: 0.816135	test: 0.885632
PRC train: 0.905172	val: 0.778232	test: 0.825350

Epoch: 39
Loss: 0.3673648936263119
ROC train: 0.924744	val: 0.834238	test: 0.885242
PRC train: 0.903496	val: 0.808410	test: 0.815447

Epoch: 40
Loss: 0.41775575505788326
ROC train: 0.928160	val: 0.825580	test: 0.878148
PRC train: 0.912245	val: 0.796533	test: 0.796154

Epoch: 41
Loss: 0.3674573499043908
ROC train: 0.931785	val: 0.822668	test: 0.882669
PRC train: 0.916441	val: 0.787863	test: 0.808354

Epoch: 42
Loss: 0.35675250970502165
ROC train: 0.933227	val: 0.827233	test: 0.889374
PRC train: 0.916707	val: 0.800820	test: 0.818372

Epoch: 43
Loss: 0.3770704979332592
ROC train: 0.934432	val: 0.826919	test: 0.888205
PRC train: 0.916774	val: 0.790132	test: 0.811373

Epoch: 44
Loss: 0.3646326622503178
ROC train: 0.935068	val: 0.826761	test: 0.890699
PRC train: 0.916131	val: 0.792050	test: 0.820664

Epoch: 45
Loss: 0.3795682719106713
ROC train: 0.936725	val: 0.818261	test: 0.886957
PRC train: 0.919482	val: 0.779494	test: 0.805876

Epoch: 46
Loss: 0.3578866429799541
ROC train: 0.938304	val: 0.818497	test: 0.884540
PRC train: 0.921148	val: 0.779713	test: 0.805191

Epoch: 47
Loss: 0.41581998215997784
ROC train: 0.936896	val: 0.819126	test: 0.881656
PRC train: 0.920038	val: 0.786204	test: 0.802229

Epoch: 48
Loss: 0.37419280070603916
ROC train: 0.932860	val: 0.814404	test: 0.882124
PRC train: 0.914604	val: 0.788814	test: 0.813084

Epoch: 49
Loss: 0.38419541452981176
ROC train: 0.935883	val: 0.808973	test: 0.888049
PRC train: 0.920437	val: 0.776505	test: 0.819769

Epoch: 50
Loss: 0.3868889157300358
ROC train: 0.937417	val: 0.811255	test: 0.888516
PRC train: 0.923332	val: 0.778612	test: 0.820595

Epoch: 51
Loss: 0.37370179182433577
ROC train: 0.941544	val: 0.824715	test: 0.882591
PRC train: 0.927678	val: 0.801410	test: 0.815328

Epoch: 52
Loss: 0.3514238774160886
ROC train: 0.937018	val: 0.832113	test: 0.883761
PRC train: 0.922865	val: 0.809048	test: 0.823643

Epoch: 53
Loss: 0.34229460367165715
ROC train: 0.935642	val: 0.828571	test: 0.892103
PRC train: 0.920939	val: 0.804335	test: 0.836896

Epoch: 54
Loss: 0.3564372612218707
ROC train: 0.943624	val: 0.821094	test: 0.888750
PRC train: 0.932135	val: 0.791784	test: 0.826995

Epoch: 55
Loss: 0.34266742384443527
ROC train: 0.939967	val: 0.817631	test: 0.889062
PRC train: 0.927776	val: 0.784292	test: 0.825707

Epoch: 56
Loss: 0.33722931395415756
ROC train: 0.941984	val: 0.831720	test: 0.896702
PRC train: 0.928117	val: 0.796132	test: 0.838933

Epoch: 57
Loss: 0.3505139072444075
ROC train: 0.942974	val: 0.829831	test: 0.897872
PRC train: 0.928507	val: 0.792605	test: 0.839550

Epoch: 58
Loss: 0.3472721992021772
ROC train: 0.940483	val: 0.824242	test: 0.888283
PRC train: 0.927282	val: 0.791320	test: 0.831595

Epoch: 59
Loss: 0.3698514868568825
ROC train: 0.945126	val: 0.823062	test: 0.880175
PRC train: 0.934088	val: 0.793570	test: 0.818796

Epoch: 60
Loss: 0.3251873820064728
ROC train: 0.928164	val: 0.804250	test: 0.868325
PRC train: 0.916199	val: 0.774407	test: 0.805177

Epoch: 61
Loss: 0.353025993370526
ROC train: 0.941718	val: 0.822039	test: 0.877524
PRC train: 0.931278	val: 0.790882	test: 0.810668

Epoch: 62
Loss: 0.3832401422367011
ROC train: 0.946667	val: 0.833294	test: 0.882981
PRC train: 0.934925	val: 0.795550	test: 0.816331

Epoch: 63
Loss: 0.351116476851944
ROC train: 0.937250	val: 0.845022	test: 0.879863
PRC train: 0.921848	val: 0.809604	test: 0.808320

Epoch: 64
Loss: 0.3383101241778891
ROC train: 0.941494	val: 0.826368	test: 0.880720
PRC train: 0.927933	val: 0.798263	test: 0.816802

Epoch: 65
Loss: 0.3014514925993488
ROC train: 0.945488	val: 0.823534	test: 0.882046
PRC train: 0.932554	val: 0.794751	test: 0.819439

Epoch: 66
Loss: 0.33802996183865974
ROC train: 0.948849	val: 0.830303	test: 0.888205
PRC train: 0.937373	val: 0.798313	test: 0.830937

Epoch: 67
Loss: 0.3484120658846126
ROC train: 0.949838	val: 0.829280	test: 0.888049
PRC train: 0.938194	val: 0.794677	test: 0.827867

Epoch: 68
Loss: 0.3733005065459727
ROC train: 0.953973	val: 0.824872	test: 0.886879
PRC train: 0.944094	val: 0.792976	test: 0.820631

Epoch: 69
Loss: 0.31924286419996883
ROC train: 0.951925	val: 0.822826	test: 0.883917
PRC train: 0.943348	val: 0.794991	test: 0.817148

Epoch: 70
Loss: 0.353291557927039
ROC train: 0.952712	val: 0.828650	test: 0.887191
PRC train: 0.943512	val: 0.803899	test: 0.828223

Epoch: 71
Loss: 0.3615734075855904
ROC train: 0.948926	val: 0.830460	test: 0.887815
PRC train: 0.937602	val: 0.805970	test: 0.830972

Epoch: 72
Loss: 0.3223687968536859
ROC train: 0.949120	val: 0.834632	test: 0.884852
PRC train: 0.937768	val: 0.802616	test: 0.827490

Epoch: 73
Loss: 0.3536833681583351
ROC train: 0.952637	val: 0.843526	test: 0.892336
PRC train: 0.941959	val: 0.812966	test: 0.837147

Epoch: 74
Loss: 0.3232010743106987
ROC train: 0.949573	val: 0.840299	test: 0.898106
PRC train: 0.938860	val: 0.814251	test: 0.840004

Epoch: 75
Loss: 0.3557188796248921
ROC train: 0.949059	val: 0.819677	test: 0.893662
PRC train: 0.938718	val: 0.776381	test: 0.834648

Epoch: 76
Loss: 0.3526272614026299
ROC train: 0.944980	val: 0.808422	test: 0.897872
PRC train: 0.932687	val: 0.769194	test: 0.843804

Epoch: 77
Loss: 0.32770713624101716
ROC train: 0.950776	val: 0.810390	test: 0.891401
PRC train: 0.939699	val: 0.775876	test: 0.834770

Epoch: 78
Loss: 0.3792441887199865
ROC train: 0.950708	val: 0.817946	test: 0.883761
PRC train: 0.936954	val: 0.783193	test: 0.817686

Epoch: 79
Loss: 0.3102549520356546
ROC train: 0.953538	val: 0.835891	test: 0.890699
PRC train: 0.939886	val: 0.801997	test: 0.821115

Epoch: 80
Loss: 0.3326331799808311
ROC train: 0.955040	val: 0.827784	test: 0.898028
PRC train: 0.943647	val: 0.786944	test: 0.820762

Epoch: 81
Loss: 0.32459020247473647
ROC train: 0.949246	val: 0.807556	test: 0.894363
PRC train: 0.938928	val: 0.765920	test: 0.830591

Epoch: 82
Loss: 0.3220304343815307
ROC train: 0.948743	val: 0.810547	test: 0.889218
PRC train: 0.939849	val: 0.774550	test: 0.834006

Epoch: 83
Loss: 0.3505152271660676
ROC train: 0.957001	val: 0.827863	test: 0.895221
PRC train: 0.948193	val: 0.804200	test: 0.842577

Epoch: 84
Loss: 0.3206063331234312
ROC train: 0.949043	val: 0.821960	test: 0.880409
PRC train: 0.937196	val: 0.794555	test: 0.820279

Epoch: 85
Loss: 0.3138484432151356
ROC train: 0.951739	val: 0.831169	test: 0.875185
PRC train: 0.940849	val: 0.802947	test: 0.813211

Epoch: 86
Loss: 0.3263052583261655
ROC train: 0.957683	val: 0.832507	test: 0.881578
PRC train: 0.949849	val: 0.808685	test: 0.819164

Epoch: 87
Loss: 0.34805275211319114
ROC train: 0.954871	val: 0.812357	test: 0.884774
PRC train: 0.947238	val: 0.781294	test: 0.825560

Epoch: 88
Loss: 0.3344855020841492
ROC train: 0.958502	val: 0.813853	test: 0.881968
PRC train: 0.950488	val: 0.787286	test: 0.813637

Epoch: 89
Loss: 0.3191478312224764
ROC train: 0.959871	val: 0.828729	test: 0.889998
PRC train: 0.950153	val: 0.809306	test: 0.821624

Epoch: 90
Loss: 0.30367059487664017
ROC train: 0.959929	val: 0.828493	test: 0.892492
PRC train: 0.950268	val: 0.807181	test: 0.823083

Epoch: 91
Loss: 0.30861507080548695
ROC train: 0.955402	val: 0.815978	test: 0.880175
PRC train: 0.946603	val: 0.788784	test: 0.807855

Epoch: 92
Loss: 0.29172434459092234
ROC train: 0.959278	val: 0.825108	test: 0.888984
PRC train: 0.951566	val: 0.800731	test: 0.827378

Epoch: 93
Loss: 0.3455649436047491
ROC train: 0.960457	val: 0.833766	test: 0.890543
PRC train: 0.951429	val: 0.806859	test: 0.827288

Epoch: 94
Loss: 0.312951821189481
ROC train: 0.963072	val: 0.832349	test: 0.893662
PRC train: 0.954107	val: 0.804303	test: 0.830144
PRC train: 0.899390	val: 0.766774	test: 0.800697

Epoch: 34
Loss: 0.4453306613307933
ROC train: 0.914316	val: 0.818103	test: 0.873080
PRC train: 0.897193	val: 0.790037	test: 0.806515

Epoch: 35
Loss: 0.4014894308796239
ROC train: 0.914719	val: 0.821094	test: 0.873548
PRC train: 0.895347	val: 0.783841	test: 0.789914

Epoch: 36
Loss: 0.4167197767196457
ROC train: 0.919054	val: 0.805510	test: 0.868013
PRC train: 0.901062	val: 0.760449	test: 0.779866

Epoch: 37
Loss: 0.3980534467741527
ROC train: 0.914402	val: 0.790240	test: 0.859359
PRC train: 0.899001	val: 0.747648	test: 0.773838

Epoch: 38
Loss: 0.40108672746548385
ROC train: 0.920766	val: 0.807950	test: 0.865752
PRC train: 0.905511	val: 0.771591	test: 0.780761

Epoch: 39
Loss: 0.3922864417846662
ROC train: 0.923099	val: 0.820858	test: 0.873470
PRC train: 0.907180	val: 0.785775	test: 0.786241

Epoch: 40
Loss: 0.4039719397547146
ROC train: 0.923616	val: 0.825659	test: 0.874717
PRC train: 0.907356	val: 0.784360	test: 0.792316

Epoch: 41
Loss: 0.4086009438082951
ROC train: 0.924094	val: 0.826368	test: 0.881032
PRC train: 0.907628	val: 0.785371	test: 0.813470

Epoch: 42
Loss: 0.3726231868933735
ROC train: 0.923668	val: 0.812043	test: 0.877446
PRC train: 0.909604	val: 0.770985	test: 0.811272

Epoch: 43
Loss: 0.4381082384175258
ROC train: 0.922747	val: 0.824793	test: 0.888438
PRC train: 0.906494	val: 0.797498	test: 0.822790

Epoch: 44
Loss: 0.3728405777828322
ROC train: 0.919995	val: 0.834947	test: 0.888049
PRC train: 0.899718	val: 0.809551	test: 0.830934

Epoch: 45
Loss: 0.3617496460387441
ROC train: 0.928243	val: 0.818969	test: 0.879941
PRC train: 0.913128	val: 0.793942	test: 0.812478

Epoch: 46
Loss: 0.40303761654604975
ROC train: 0.927426	val: 0.822275	test: 0.879083
PRC train: 0.913863	val: 0.792615	test: 0.810214

Epoch: 47
Loss: 0.3631827540506754
ROC train: 0.919525	val: 0.831405	test: 0.884307
PRC train: 0.897354	val: 0.794194	test: 0.815711

Epoch: 48
Loss: 0.3792413753912325
ROC train: 0.928588	val: 0.814089	test: 0.882202
PRC train: 0.913065	val: 0.773359	test: 0.804377

Epoch: 49
Loss: 0.3749505016822855
ROC train: 0.924421	val: 0.805274	test: 0.873236
PRC train: 0.905129	val: 0.755256	test: 0.793694

Epoch: 50
Loss: 0.3854013403485642
ROC train: 0.927982	val: 0.797166	test: 0.869026
PRC train: 0.913676	val: 0.757848	test: 0.799055

Epoch: 51
Loss: 0.35830051235304505
ROC train: 0.931264	val: 0.805588	test: 0.878226
PRC train: 0.918963	val: 0.770042	test: 0.810978

Epoch: 52
Loss: 0.3627340469634149
ROC train: 0.931786	val: 0.817159	test: 0.877524
PRC train: 0.920397	val: 0.777275	test: 0.801560

Epoch: 53
Loss: 0.3815755066709109
ROC train: 0.933649	val: 0.825974	test: 0.885008
PRC train: 0.922564	val: 0.790614	test: 0.805923

Epoch: 54
Loss: 0.39357557625723416
ROC train: 0.936393	val: 0.815821	test: 0.885632
PRC train: 0.923056	val: 0.783342	test: 0.817112

Epoch: 55
Loss: 0.3898810619003429
ROC train: 0.933606	val: 0.820858	test: 0.892103
PRC train: 0.919673	val: 0.795373	test: 0.826451

Epoch: 56
Loss: 0.3823132125136444
ROC train: 0.938523	val: 0.830146	test: 0.892492
PRC train: 0.925105	val: 0.798500	test: 0.814383

Epoch: 57
Loss: 0.3605707616528258
ROC train: 0.938987	val: 0.829359	test: 0.881968
PRC train: 0.923928	val: 0.791100	test: 0.786051

Epoch: 58
Loss: 0.3652614650806003
ROC train: 0.937816	val: 0.812436	test: 0.872301
PRC train: 0.925853	val: 0.776046	test: 0.793045

Epoch: 59
Loss: 0.3762317074240592
ROC train: 0.935188	val: 0.811806	test: 0.878693
PRC train: 0.922046	val: 0.779293	test: 0.809310

Epoch: 60
Loss: 0.3555798699900034
ROC train: 0.934066	val: 0.815348	test: 0.883137
PRC train: 0.919813	val: 0.788109	test: 0.812937

Epoch: 61
Loss: 0.4071997122762029
ROC train: 0.935941	val: 0.806139	test: 0.877524
PRC train: 0.923462	val: 0.773623	test: 0.810386

Epoch: 62
Loss: 0.3268440043900566
ROC train: 0.933796	val: 0.793074	test: 0.866064
PRC train: 0.922468	val: 0.745557	test: 0.793952

Epoch: 63
Loss: 0.360850789726571
ROC train: 0.944553	val: 0.825187	test: 0.887503
PRC train: 0.933700	val: 0.780926	test: 0.813607

Epoch: 64
Loss: 0.36429139636087277
ROC train: 0.939166	val: 0.832113	test: 0.890387
PRC train: 0.925286	val: 0.782617	test: 0.817068

Epoch: 65
Loss: 0.34274024009166915
ROC train: 0.940700	val: 0.808501	test: 0.877446
PRC train: 0.929221	val: 0.760001	test: 0.800838

Epoch: 66
Loss: 0.36665275081876275
ROC train: 0.942737	val: 0.808894	test: 0.881890
PRC train: 0.930871	val: 0.765196	test: 0.819955

Epoch: 67
Loss: 0.36892513016683226
ROC train: 0.942974	val: 0.815427	test: 0.893974
PRC train: 0.932580	val: 0.788325	test: 0.841051

Epoch: 68
Loss: 0.34739349470224257
ROC train: 0.943919	val: 0.808973	test: 0.892882
PRC train: 0.934007	val: 0.780595	test: 0.838851

Epoch: 69
Loss: 0.34196422642186464
ROC train: 0.947279	val: 0.821015	test: 0.886879
PRC train: 0.937605	val: 0.791960	test: 0.823189

Epoch: 70
Loss: 0.35537866866704587
ROC train: 0.943430	val: 0.831169	test: 0.880564
PRC train: 0.931555	val: 0.805218	test: 0.817793

Epoch: 71
Loss: 0.36111767075096196
ROC train: 0.940036	val: 0.821409	test: 0.873938
PRC train: 0.927557	val: 0.800060	test: 0.816014

Epoch: 72
Loss: 0.3546443279359183
ROC train: 0.944470	val: 0.811728	test: 0.879551
PRC train: 0.933420	val: 0.785986	test: 0.827089

Epoch: 73
Loss: 0.32466313859608453
ROC train: 0.946654	val: 0.809681	test: 0.884618
PRC train: 0.936018	val: 0.771912	test: 0.809683

Epoch: 74
Loss: 0.33625734276733177
ROC train: 0.944080	val: 0.813066	test: 0.886489
PRC train: 0.934016	val: 0.759679	test: 0.804351

Epoch: 75
Loss: 0.3554600214203763
ROC train: 0.943732	val: 0.814325	test: 0.894208
PRC train: 0.932640	val: 0.774010	test: 0.825197

Epoch: 76
Loss: 0.3920689383555798
ROC train: 0.945783	val: 0.820228	test: 0.893974
PRC train: 0.934565	val: 0.782642	test: 0.830918

Epoch: 77
Loss: 0.3467670360130109
ROC train: 0.946555	val: 0.820464	test: 0.890232
PRC train: 0.935970	val: 0.785916	test: 0.836146

Epoch: 78
Loss: 0.33375914102898185
ROC train: 0.945526	val: 0.815506	test: 0.888049
PRC train: 0.935574	val: 0.775182	test: 0.837468

Epoch: 79
Loss: 0.31545535131017843
ROC train: 0.946077	val: 0.810075	test: 0.889452
PRC train: 0.936965	val: 0.770958	test: 0.838206

Epoch: 80
Loss: 0.34625894983879907
ROC train: 0.945954	val: 0.808028	test: 0.883917
PRC train: 0.936063	val: 0.769886	test: 0.822748

Epoch: 81
Loss: 0.3007488917311005
ROC train: 0.944673	val: 0.804723	test: 0.879629
PRC train: 0.933081	val: 0.762633	test: 0.808288

Epoch: 82
Loss: 0.3400696547425607
ROC train: 0.947972	val: 0.805431	test: 0.876744
PRC train: 0.937590	val: 0.751595	test: 0.804406

Epoch: 83
Loss: 0.32743250212980435
ROC train: 0.951437	val: 0.817473	test: 0.885320
PRC train: 0.942998	val: 0.778351	test: 0.822357

Epoch: 84
Loss: 0.3520515056343814
ROC train: 0.951390	val: 0.819756	test: 0.897794
PRC train: 0.941354	val: 0.788881	test: 0.839768

Epoch: 85
Loss: 0.3146137348761487
ROC train: 0.950797	val: 0.814404	test: 0.898573
PRC train: 0.939784	val: 0.784610	test: 0.841603

Epoch: 86
Loss: 0.323922125795287
ROC train: 0.954095	val: 0.824872	test: 0.894519
PRC train: 0.943258	val: 0.793770	test: 0.836557

Epoch: 87
Loss: 0.33351663457938396
ROC train: 0.951573	val: 0.817395	test: 0.875185
PRC train: 0.940002	val: 0.778892	test: 0.806760

Epoch: 88
Loss: 0.30301400440158865
ROC train: 0.952669	val: 0.813695	test: 0.884462
PRC train: 0.943037	val: 0.779950	test: 0.830390

Epoch: 89
Loss: 0.3236961481008048
ROC train: 0.954476	val: 0.811728	test: 0.892025
PRC train: 0.946026	val: 0.781235	test: 0.838150

Epoch: 90
Loss: 0.2930677881577503
ROC train: 0.949998	val: 0.808501	test: 0.887893
PRC train: 0.940292	val: 0.780340	test: 0.832224

Epoch: 91
Loss: 0.3514372744237034
ROC train: 0.950902	val: 0.816450	test: 0.886022
PRC train: 0.940338	val: 0.781380	test: 0.820265

Epoch: 92
Loss: 0.3463183394566418
ROC train: 0.955482	val: 0.814325	test: 0.884462
PRC train: 0.946006	val: 0.778300	test: 0.820991

Epoch: 93
Loss: 0.36625941339811324
ROC train: 0.951573	val: 0.810941	test: 0.892181
PRC train: 0.941686	val: 0.784191	test: 0.848464

Epoch: 94
Loss: 0.3231463584898845
ROC train: 0.953567	val: 0.810075	test: 0.897248
PRC train: 0.903148	val: 0.779327	test: 0.831662

Epoch: 34
Loss: 0.38835664286255056
ROC train: 0.920505	val: 0.811177	test: 0.886957
PRC train: 0.905100	val: 0.782361	test: 0.820359

Epoch: 35
Loss: 0.40220721028524453
ROC train: 0.913727	val: 0.785832	test: 0.864583
PRC train: 0.901941	val: 0.751609	test: 0.791671

Epoch: 36
Loss: 0.3644754734509025
ROC train: 0.921763	val: 0.802676	test: 0.876666
PRC train: 0.904895	val: 0.768559	test: 0.807818

Epoch: 37
Loss: 0.4341116310861259
ROC train: 0.926993	val: 0.818182	test: 0.887191
PRC train: 0.911869	val: 0.785459	test: 0.826068

Epoch: 38
Loss: 0.3713816138013105
ROC train: 0.925872	val: 0.809996	test: 0.884229
PRC train: 0.912166	val: 0.775912	test: 0.819498

Epoch: 39
Loss: 0.4127571154708292
ROC train: 0.928598	val: 0.816765	test: 0.885710
PRC train: 0.915943	val: 0.778734	test: 0.820848

Epoch: 40
Loss: 0.37070826634656995
ROC train: 0.928234	val: 0.809917	test: 0.877290
PRC train: 0.916865	val: 0.767071	test: 0.802070

Epoch: 41
Loss: 0.4042899988489238
ROC train: 0.931393	val: 0.807084	test: 0.869962
PRC train: 0.919464	val: 0.753807	test: 0.781290

Epoch: 42
Loss: 0.362549746808507
ROC train: 0.929820	val: 0.803306	test: 0.866532
PRC train: 0.917181	val: 0.751558	test: 0.778769

Epoch: 43
Loss: 0.3821263472995146
ROC train: 0.930603	val: 0.810390	test: 0.883605
PRC train: 0.916916	val: 0.772296	test: 0.812868

Epoch: 44
Loss: 0.39517343477713734
ROC train: 0.926921	val: 0.810390	test: 0.887737
PRC train: 0.910059	val: 0.771506	test: 0.824543

Epoch: 45
Loss: 0.38015290675081387
ROC train: 0.928117	val: 0.802519	test: 0.880253
PRC train: 0.913434	val: 0.749532	test: 0.814351

Epoch: 46
Loss: 0.3793425263018376
ROC train: 0.929342	val: 0.797481	test: 0.869026
PRC train: 0.915518	val: 0.735014	test: 0.803272

Epoch: 47
Loss: 0.40915744081288385
ROC train: 0.935391	val: 0.808028	test: 0.873470
PRC train: 0.922832	val: 0.757192	test: 0.796798

Epoch: 48
Loss: 0.4040968232120082
ROC train: 0.934694	val: 0.815112	test: 0.876510
PRC train: 0.922553	val: 0.767757	test: 0.788833

Epoch: 49
Loss: 0.3535608092909421
ROC train: 0.925373	val: 0.806926	test: 0.862789
PRC train: 0.912465	val: 0.763280	test: 0.765759

Epoch: 50
Loss: 0.37686303022642004
ROC train: 0.935768	val: 0.832822	test: 0.892103
PRC train: 0.922675	val: 0.803109	test: 0.822260

Epoch: 51
Loss: 0.3792505394116965
ROC train: 0.932629	val: 0.840457	test: 0.896312
PRC train: 0.918181	val: 0.816465	test: 0.835230

Epoch: 52
Loss: 0.4015871566041248
ROC train: 0.937194	val: 0.825659	test: 0.887347
PRC train: 0.924530	val: 0.793275	test: 0.823280

Epoch: 53
Loss: 0.3951788561340831
ROC train: 0.932503	val: 0.809839	test: 0.866999
PRC train: 0.920007	val: 0.765171	test: 0.803089

Epoch: 54
Loss: 0.3726814447640576
ROC train: 0.938240	val: 0.823140	test: 0.884540
PRC train: 0.925453	val: 0.788230	test: 0.823882

Epoch: 55
Loss: 0.36117122541647284
ROC train: 0.931587	val: 0.819599	test: 0.889140
PRC train: 0.916009	val: 0.786695	test: 0.823451

Epoch: 56
Loss: 0.35021743260646854
ROC train: 0.934159	val: 0.812043	test: 0.888516
PRC train: 0.918020	val: 0.770642	test: 0.830804

Epoch: 57
Loss: 0.3515971939280115
ROC train: 0.932647	val: 0.796222	test: 0.876978
PRC train: 0.916474	val: 0.744696	test: 0.811801

Epoch: 58
Loss: 0.3428455368725215
ROC train: 0.938362	val: 0.804329	test: 0.881656
PRC train: 0.926374	val: 0.752733	test: 0.818841

Epoch: 59
Loss: 0.33180359937344983
ROC train: 0.930172	val: 0.801889	test: 0.874484
PRC train: 0.915700	val: 0.749399	test: 0.809636

Epoch: 60
Loss: 0.3467684205365894
ROC train: 0.941384	val: 0.814719	test: 0.881344
PRC train: 0.929478	val: 0.772818	test: 0.818879

Epoch: 61
Loss: 0.382785571565257
ROC train: 0.935775	val: 0.812987	test: 0.870897
PRC train: 0.924301	val: 0.776873	test: 0.805465

Epoch: 62
Loss: 0.3725676167323452
ROC train: 0.937015	val: 0.809366	test: 0.877602
PRC train: 0.924771	val: 0.779488	test: 0.818193

Epoch: 63
Loss: 0.3483003164292422
ROC train: 0.940973	val: 0.814797	test: 0.891011
PRC train: 0.930582	val: 0.786495	test: 0.834153

Epoch: 64
Loss: 0.35985445748434475
ROC train: 0.937672	val: 0.805037	test: 0.893896
PRC train: 0.927684	val: 0.778855	test: 0.838514

Epoch: 65
Loss: 0.3830348301842712
ROC train: 0.941562	val: 0.802676	test: 0.889998
PRC train: 0.931633	val: 0.763370	test: 0.828892

Epoch: 66
Loss: 0.4222150493165036
ROC train: 0.944815	val: 0.814876	test: 0.882046
PRC train: 0.933106	val: 0.773132	test: 0.805319

Epoch: 67
Loss: 0.3457365415555254
ROC train: 0.942299	val: 0.814325	test: 0.880486
PRC train: 0.928220	val: 0.769267	test: 0.802064

Epoch: 68
Loss: 0.3495798133517547
ROC train: 0.944084	val: 0.808028	test: 0.885398
PRC train: 0.931440	val: 0.762350	test: 0.808650

Epoch: 69
Loss: 0.36219019103399697
ROC train: 0.943813	val: 0.808894	test: 0.891401
PRC train: 0.931780	val: 0.755920	test: 0.825727

Epoch: 70
Loss: 0.35902095684297
ROC train: 0.941972	val: 0.819992	test: 0.897404
PRC train: 0.929157	val: 0.782194	test: 0.833175

Epoch: 71
Loss: 0.3549593160509267
ROC train: 0.947579	val: 0.815742	test: 0.894052
PRC train: 0.935917	val: 0.772420	test: 0.826728

Epoch: 72
Loss: 0.3674720311494344
ROC train: 0.950136	val: 0.817710	test: 0.892492
PRC train: 0.938350	val: 0.772874	test: 0.817000

Epoch: 73
Loss: 0.36782328020396454
ROC train: 0.949328	val: 0.820622	test: 0.895533
PRC train: 0.937359	val: 0.782443	test: 0.836430

Epoch: 74
Loss: 0.3579630994058284
ROC train: 0.947654	val: 0.823377	test: 0.885008
PRC train: 0.935522	val: 0.784951	test: 0.819421

Epoch: 75
Loss: 0.35263842409976326
ROC train: 0.945600	val: 0.821724	test: 0.879083
PRC train: 0.933248	val: 0.784300	test: 0.809004

Epoch: 76
Loss: 0.3235049746830946
ROC train: 0.950176	val: 0.831326	test: 0.889842
PRC train: 0.938060	val: 0.792522	test: 0.823630

Epoch: 77
Loss: 0.3393440483425583
ROC train: 0.953066	val: 0.830697	test: 0.897248
PRC train: 0.940549	val: 0.790371	test: 0.837330

Epoch: 78
Loss: 0.35383350912535183
ROC train: 0.953014	val: 0.830460	test: 0.885866
PRC train: 0.941358	val: 0.790518	test: 0.816515

Epoch: 79
Loss: 0.330742527585625
ROC train: 0.950115	val: 0.826368	test: 0.874250
PRC train: 0.938635	val: 0.784340	test: 0.796378

Epoch: 80
Loss: 0.3302114739062749
ROC train: 0.952579	val: 0.832428	test: 0.881110
PRC train: 0.941005	val: 0.789166	test: 0.806609

Epoch: 81
Loss: 0.3206662522460938
ROC train: 0.955072	val: 0.833058	test: 0.891713
PRC train: 0.944593	val: 0.799207	test: 0.826170

Epoch: 82
Loss: 0.3114210594613678
ROC train: 0.954867	val: 0.824951	test: 0.895533
PRC train: 0.945056	val: 0.790114	test: 0.817840

Epoch: 83
Loss: 0.3439736015944867
ROC train: 0.955045	val: 0.819520	test: 0.893350
PRC train: 0.945467	val: 0.784622	test: 0.818800

Epoch: 84
Loss: 0.35262800014009493
ROC train: 0.954856	val: 0.818182	test: 0.888984
PRC train: 0.945178	val: 0.779755	test: 0.816458

Epoch: 85
Loss: 0.33653455897197204
ROC train: 0.954555	val: 0.821488	test: 0.890387
PRC train: 0.944895	val: 0.781952	test: 0.823999

Epoch: 86
Loss: 0.3101840048748387
ROC train: 0.955586	val: 0.826997	test: 0.890933
PRC train: 0.944987	val: 0.792399	test: 0.826471

Epoch: 87
Loss: 0.32098784353462745
ROC train: 0.953215	val: 0.818811	test: 0.880642
PRC train: 0.943135	val: 0.787565	test: 0.814433

Epoch: 88
Loss: 0.34490486998269215
ROC train: 0.953432	val: 0.817001	test: 0.881422
PRC train: 0.942562	val: 0.783832	test: 0.814831

Epoch: 89
Loss: 0.3263002503578072
ROC train: 0.954544	val: 0.824636	test: 0.892025
PRC train: 0.943954	val: 0.794119	test: 0.828944

Epoch: 90
Loss: 0.3049361026983258
ROC train: 0.958068	val: 0.831011	test: 0.898184
PRC train: 0.948423	val: 0.801189	test: 0.840353

Epoch: 91
Loss: 0.30423110043931745
ROC train: 0.954178	val: 0.818339	test: 0.881812
PRC train: 0.944233	val: 0.773847	test: 0.805597

Epoch: 92
Loss: 0.3121458457393834
ROC train: 0.952128	val: 0.814797	test: 0.875341
PRC train: 0.940903	val: 0.750269	test: 0.794982

Epoch: 93
Loss: 0.3530873626862757
ROC train: 0.948592	val: 0.815663	test: 0.872534
PRC train: 0.938134	val: 0.751316	test: 0.792914

Epoch: 94
Loss: 0.34650916164755474
ROC train: 0.949472	val: 0.820150	test: 0.889062
PRC train: 0.937949	val: 0.775715	test: 0.825409
ROC train: 0.928582	val: 0.862631	test: 0.870098
PRC train: 0.912983	val: 0.789790	test: 0.808042

Epoch: 34
Loss: 0.39452126521794517
ROC train: 0.929628	val: 0.862269	test: 0.856968
PRC train: 0.914717	val: 0.782743	test: 0.789524

Epoch: 35
Loss: 0.3818150585996386
ROC train: 0.934210	val: 0.854839	test: 0.863620
PRC train: 0.919852	val: 0.774225	test: 0.793174

Epoch: 36
Loss: 0.38276651069046663
ROC train: 0.933216	val: 0.859369	test: 0.867297
PRC train: 0.919002	val: 0.786363	test: 0.803020

Epoch: 37
Loss: 0.3706888246018224
ROC train: 0.935682	val: 0.864625	test: 0.869048
PRC train: 0.921390	val: 0.798802	test: 0.806454

Epoch: 38
Loss: 0.3742046505990847
ROC train: 0.934273	val: 0.858463	test: 0.869573
PRC train: 0.922375	val: 0.796370	test: 0.808231

Epoch: 39
Loss: 0.37184564648219504
ROC train: 0.935836	val: 0.863538	test: 0.876401
PRC train: 0.923486	val: 0.806489	test: 0.810301

Epoch: 40
Loss: 0.3644917471077994
ROC train: 0.938286	val: 0.870243	test: 0.868873
PRC train: 0.925314	val: 0.805931	test: 0.802110

Epoch: 41
Loss: 0.34467603270398905
ROC train: 0.936901	val: 0.873324	test: 0.871849
PRC train: 0.923433	val: 0.811909	test: 0.805053

Epoch: 42
Loss: 0.3465716501573469
ROC train: 0.942064	val: 0.871874	test: 0.873249
PRC train: 0.928722	val: 0.811035	test: 0.802450

Epoch: 43
Loss: 0.3597642048780117
ROC train: 0.938717	val: 0.862813	test: 0.874125
PRC train: 0.924858	val: 0.797739	test: 0.810476

Epoch: 44
Loss: 0.3513506617314799
ROC train: 0.941634	val: 0.862994	test: 0.873775
PRC train: 0.929240	val: 0.796038	test: 0.805088

Epoch: 45
Loss: 0.3660074567749337
ROC train: 0.945954	val: 0.873142	test: 0.877976
PRC train: 0.933164	val: 0.812142	test: 0.815644

Epoch: 46
Loss: 0.3504721109772229
ROC train: 0.943848	val: 0.872780	test: 0.871674
PRC train: 0.930714	val: 0.810182	test: 0.811634

Epoch: 47
Loss: 0.34755572507242716
ROC train: 0.940517	val: 0.871149	test: 0.866947
PRC train: 0.926818	val: 0.805319	test: 0.802715

Epoch: 48
Loss: 0.35277611303903333
ROC train: 0.943724	val: 0.866618	test: 0.864671
PRC train: 0.930415	val: 0.789914	test: 0.794578

Epoch: 49
Loss: 0.33926663375423194
ROC train: 0.947256	val: 0.866437	test: 0.870098
PRC train: 0.934461	val: 0.782817	test: 0.797908

Epoch: 50
Loss: 0.35298594899470465
ROC train: 0.948841	val: 0.870968	test: 0.870798
PRC train: 0.936904	val: 0.804636	test: 0.798943

Epoch: 51
Loss: 0.3484504104953946
ROC train: 0.948377	val: 0.873505	test: 0.868873
PRC train: 0.936495	val: 0.806804	test: 0.797468

Epoch: 52
Loss: 0.34832880558066776
ROC train: 0.949588	val: 0.874955	test: 0.874650
PRC train: 0.937303	val: 0.810286	test: 0.806815

Epoch: 53
Loss: 0.33787850641699363
ROC train: 0.949313	val: 0.872236	test: 0.881653
PRC train: 0.935785	val: 0.799465	test: 0.822085

Epoch: 54
Loss: 0.35015205096529395
ROC train: 0.949808	val: 0.868431	test: 0.876401
PRC train: 0.937370	val: 0.786530	test: 0.817502

Epoch: 55
Loss: 0.3401805448985015
ROC train: 0.951613	val: 0.863175	test: 0.871499
PRC train: 0.941185	val: 0.789167	test: 0.817538

Epoch: 56
Loss: 0.33088211880002466
ROC train: 0.949687	val: 0.862994	test: 0.878852
PRC train: 0.938795	val: 0.797532	test: 0.819400

Epoch: 57
Loss: 0.3407222180691257
ROC train: 0.952939	val: 0.872780	test: 0.883754
PRC train: 0.943457	val: 0.807678	test: 0.826624

Epoch: 58
Loss: 0.319556121211455
ROC train: 0.949357	val: 0.870787	test: 0.868873
PRC train: 0.939467	val: 0.796254	test: 0.804914

Epoch: 59
Loss: 0.33366498013044277
ROC train: 0.953014	val: 0.863538	test: 0.859419
PRC train: 0.942845	val: 0.782745	test: 0.791721

Epoch: 60
Loss: 0.31515363041239847
ROC train: 0.953172	val: 0.861906	test: 0.850840
PRC train: 0.943973	val: 0.782551	test: 0.783289

Epoch: 61
Loss: 0.33646433238346796
ROC train: 0.953197	val: 0.870968	test: 0.861520
PRC train: 0.942385	val: 0.803078	test: 0.796004

Epoch: 62
Loss: 0.3289616943041557
ROC train: 0.956222	val: 0.865893	test: 0.873775
PRC train: 0.945822	val: 0.803615	test: 0.809279

Epoch: 63
Loss: 0.33174769586466824
ROC train: 0.954953	val: 0.868068	test: 0.883929
PRC train: 0.944916	val: 0.806906	test: 0.826596

Epoch: 64
Loss: 0.3235766495937663
ROC train: 0.957163	val: 0.864987	test: 0.886204
PRC train: 0.947163	val: 0.790534	test: 0.825384

Epoch: 65
Loss: 0.31909861238248344
ROC train: 0.956986	val: 0.860094	test: 0.874125
PRC train: 0.947333	val: 0.777646	test: 0.815790

Epoch: 66
Loss: 0.3074040538848286
ROC train: 0.959088	val: 0.865350	test: 0.869748
PRC train: 0.949593	val: 0.787794	test: 0.808706

Epoch: 67
Loss: 0.3101417417887442
ROC train: 0.961464	val: 0.867887	test: 0.868873
PRC train: 0.952825	val: 0.788542	test: 0.808536

Epoch: 68
Loss: 0.29721587609410605
ROC train: 0.962066	val: 0.875680	test: 0.868347
PRC train: 0.953413	val: 0.806251	test: 0.805986

Epoch: 69
Loss: 0.3221871744394213
ROC train: 0.962472	val: 0.878579	test: 0.865371
PRC train: 0.954243	val: 0.814710	test: 0.801602

Epoch: 70
Loss: 0.3034398950243141
ROC train: 0.962634	val: 0.877311	test: 0.870448
PRC train: 0.954872	val: 0.813684	test: 0.810317

Epoch: 71
Loss: 0.3092006828661856
ROC train: 0.955202	val: 0.869880	test: 0.855567
PRC train: 0.944266	val: 0.795361	test: 0.794770

Epoch: 72
Loss: 0.32556132403086224
ROC train: 0.959204	val: 0.872236	test: 0.861345
PRC train: 0.948840	val: 0.812908	test: 0.800847

Epoch: 73
Loss: 0.2834256695540923
ROC train: 0.961967	val: 0.876586	test: 0.877976
PRC train: 0.954179	val: 0.830647	test: 0.824904

Epoch: 74
Loss: 0.30354215333499884
ROC train: 0.963280	val: 0.867343	test: 0.869048
PRC train: 0.956098	val: 0.811015	test: 0.814075

Epoch: 75
Loss: 0.31439666628541696
ROC train: 0.966891	val: 0.866618	test: 0.871674
PRC train: 0.960032	val: 0.797832	test: 0.809808

Epoch: 76
Loss: 0.30042808430403634
ROC train: 0.964675	val: 0.866981	test: 0.873249
PRC train: 0.957622	val: 0.792444	test: 0.809391

Epoch: 77
Loss: 0.30826562945210045
ROC train: 0.966707	val: 0.872236	test: 0.876751
PRC train: 0.959115	val: 0.804989	test: 0.809200

Epoch: 78
Loss: 0.2930252708080953
ROC train: 0.965990	val: 0.870424	test: 0.871324
PRC train: 0.959146	val: 0.798608	test: 0.805596

Epoch: 79
Loss: 0.30203571098808435
ROC train: 0.965760	val: 0.871330	test: 0.879727
PRC train: 0.959705	val: 0.803591	test: 0.822953

Epoch: 80
Loss: 0.29389630216637097
ROC train: 0.966606	val: 0.870605	test: 0.885329
PRC train: 0.960286	val: 0.802777	test: 0.830164

Epoch: 81
Loss: 0.2727232686790721
ROC train: 0.968672	val: 0.873142	test: 0.880252
PRC train: 0.961691	val: 0.804396	test: 0.823471

Epoch: 82
Loss: 0.30445832562009734
ROC train: 0.966387	val: 0.872236	test: 0.880077
PRC train: 0.958858	val: 0.816509	test: 0.831634

Epoch: 83
Loss: 0.296474152334394
ROC train: 0.967062	val: 0.874411	test: 0.880602
PRC train: 0.960301	val: 0.818487	test: 0.822930

Epoch: 84
Loss: 0.27674950342991816
ROC train: 0.966831	val: 0.864625	test: 0.871499
PRC train: 0.961009	val: 0.799680	test: 0.811090

Epoch: 85
Loss: 0.2746627865571547
ROC train: 0.966210	val: 0.868068	test: 0.881478
PRC train: 0.958802	val: 0.802037	test: 0.822652

Epoch: 86
Loss: 0.2958714815731419
ROC train: 0.967971	val: 0.871693	test: 0.873249
PRC train: 0.961021	val: 0.797400	test: 0.814389

Epoch: 87
Loss: 0.30087386649549963
ROC train: 0.970448	val: 0.871874	test: 0.869748
PRC train: 0.963717	val: 0.804996	test: 0.809376

Epoch: 88
Loss: 0.3004162169065775
ROC train: 0.971558	val: 0.873324	test: 0.877101
PRC train: 0.965457	val: 0.813099	test: 0.818623

Epoch: 89
Loss: 0.2851844924173893
ROC train: 0.972165	val: 0.867343	test: 0.880252
PRC train: 0.967368	val: 0.799099	test: 0.822952

Epoch: 90
Loss: 0.29138651450582087
ROC train: 0.971951	val: 0.868793	test: 0.881303
PRC train: 0.967414	val: 0.793957	test: 0.825748

Epoch: 91
Loss: 0.2763344100102097
ROC train: 0.974063	val: 0.868612	test: 0.881653
PRC train: 0.969153	val: 0.799138	test: 0.820909

Epoch: 92
Loss: 0.27083782041647864
ROC train: 0.974763	val: 0.866800	test: 0.883754
PRC train: 0.969737	val: 0.801234	test: 0.826031

Epoch: 93
Loss: 0.27498291078736364
ROC train: 0.972861	val: 0.861363	test: 0.880077
PRC train: 0.967849	val: 0.781520	test: 0.820803

Epoch: 94
Loss: 0.2759254367475862
ROC train: 0.929417	val: 0.857013	test: 0.861169
PRC train: 0.915718	val: 0.776755	test: 0.794147

Epoch: 34
Loss: 0.37481989548167205
ROC train: 0.929747	val: 0.857376	test: 0.855742
PRC train: 0.915946	val: 0.764354	test: 0.788637

Epoch: 35
Loss: 0.3874845199040636
ROC train: 0.933733	val: 0.856289	test: 0.865371
PRC train: 0.920167	val: 0.765810	test: 0.797452

Epoch: 36
Loss: 0.3915034009866484
ROC train: 0.933185	val: 0.867343	test: 0.865021
PRC train: 0.919619	val: 0.783910	test: 0.798083

Epoch: 37
Loss: 0.358896484174771
ROC train: 0.933464	val: 0.866800	test: 0.866947
PRC train: 0.919227	val: 0.788217	test: 0.799202

Epoch: 38
Loss: 0.37302213292517544
ROC train: 0.934668	val: 0.867706	test: 0.874475
PRC train: 0.920060	val: 0.814273	test: 0.806270

Epoch: 39
Loss: 0.36498771292973997
ROC train: 0.939596	val: 0.868612	test: 0.873074
PRC train: 0.927166	val: 0.800908	test: 0.800162

Epoch: 40
Loss: 0.37326109671221175
ROC train: 0.938294	val: 0.862269	test: 0.880252
PRC train: 0.925416	val: 0.799804	test: 0.814038

Epoch: 41
Loss: 0.34692596817086263
ROC train: 0.940513	val: 0.868249	test: 0.875525
PRC train: 0.928742	val: 0.797171	test: 0.807134

Epoch: 42
Loss: 0.3520092014585858
ROC train: 0.939919	val: 0.867343	test: 0.870448
PRC train: 0.928472	val: 0.792533	test: 0.799566

Epoch: 43
Loss: 0.37913030202739684
ROC train: 0.940928	val: 0.864987	test: 0.875525
PRC train: 0.929008	val: 0.781146	test: 0.810353

Epoch: 44
Loss: 0.35489934852092536
ROC train: 0.942518	val: 0.872418	test: 0.873074
PRC train: 0.930694	val: 0.789167	test: 0.811097

Epoch: 45
Loss: 0.3460788842326985
ROC train: 0.942573	val: 0.873324	test: 0.861345
PRC train: 0.931635	val: 0.783601	test: 0.798835

Epoch: 46
Loss: 0.35528147382462866
ROC train: 0.943179	val: 0.863719	test: 0.857143
PRC train: 0.931588	val: 0.774911	test: 0.790130

Epoch: 47
Loss: 0.3697863282834757
ROC train: 0.944306	val: 0.861363	test: 0.862570
PRC train: 0.932067	val: 0.776304	test: 0.796582

Epoch: 48
Loss: 0.3422574457386122
ROC train: 0.944206	val: 0.869155	test: 0.858543
PRC train: 0.932950	val: 0.779952	test: 0.792494

Epoch: 49
Loss: 0.3656333993908162
ROC train: 0.946924	val: 0.873142	test: 0.870098
PRC train: 0.936800	val: 0.787873	test: 0.803156

Epoch: 50
Loss: 0.342723921457743
ROC train: 0.947080	val: 0.860638	test: 0.873599
PRC train: 0.936705	val: 0.772334	test: 0.806816

Epoch: 51
Loss: 0.34800065992424983
ROC train: 0.946560	val: 0.860819	test: 0.869048
PRC train: 0.936608	val: 0.771540	test: 0.801360

Epoch: 52
Loss: 0.3562420167464184
ROC train: 0.945501	val: 0.875861	test: 0.876050
PRC train: 0.934016	val: 0.822798	test: 0.814886

Epoch: 53
Loss: 0.340203170782491
ROC train: 0.949181	val: 0.878217	test: 0.863971
PRC train: 0.939106	val: 0.808452	test: 0.800484

Epoch: 54
Loss: 0.3480363205980594
ROC train: 0.950439	val: 0.876948	test: 0.864846
PRC train: 0.940913	val: 0.807436	test: 0.798364

Epoch: 55
Loss: 0.3218717126209456
ROC train: 0.948731	val: 0.870424	test: 0.880252
PRC train: 0.936600	val: 0.812525	test: 0.814703

Epoch: 56
Loss: 0.35146541875211523
ROC train: 0.951449	val: 0.869155	test: 0.876751
PRC train: 0.940926	val: 0.788937	test: 0.809431

Epoch: 57
Loss: 0.3477380792843904
ROC train: 0.949552	val: 0.855745	test: 0.876225
PRC train: 0.938773	val: 0.772884	test: 0.817163

Epoch: 58
Loss: 0.332627387646157
ROC train: 0.946190	val: 0.850308	test: 0.878676
PRC train: 0.935100	val: 0.779448	test: 0.822220

Epoch: 59
Loss: 0.3352180008197682
ROC train: 0.953955	val: 0.862450	test: 0.874300
PRC train: 0.943474	val: 0.774440	test: 0.817908

Epoch: 60
Loss: 0.3454892818965611
ROC train: 0.954515	val: 0.876586	test: 0.868697
PRC train: 0.945555	val: 0.793513	test: 0.808409

Epoch: 61
Loss: 0.317957354649958
ROC train: 0.955240	val: 0.880210	test: 0.872724
PRC train: 0.946723	val: 0.802936	test: 0.811002

Epoch: 62
Loss: 0.3284374025376571
ROC train: 0.956866	val: 0.880935	test: 0.872024
PRC train: 0.948388	val: 0.805796	test: 0.808507

Epoch: 63
Loss: 0.31786810489910433
ROC train: 0.957959	val: 0.876586	test: 0.864671
PRC train: 0.949232	val: 0.802562	test: 0.799989

Epoch: 64
Loss: 0.32344436658201525
ROC train: 0.960184	val: 0.874411	test: 0.868697
PRC train: 0.951522	val: 0.801803	test: 0.806695

Epoch: 65
Loss: 0.31808912352094704
ROC train: 0.956496	val: 0.878760	test: 0.872724
PRC train: 0.948050	val: 0.807756	test: 0.810089

Epoch: 66
Loss: 0.31602451315320795
ROC train: 0.959360	val: 0.874955	test: 0.878852
PRC train: 0.951975	val: 0.795566	test: 0.820000

Epoch: 67
Loss: 0.3100863980918887
ROC train: 0.961754	val: 0.863719	test: 0.870273
PRC train: 0.954120	val: 0.778308	test: 0.804930

Epoch: 68
Loss: 0.3131928554955427
ROC train: 0.957045	val: 0.866437	test: 0.880777
PRC train: 0.949109	val: 0.800156	test: 0.825234

Epoch: 69
Loss: 0.3233282388485529
ROC train: 0.958829	val: 0.863538	test: 0.871148
PRC train: 0.951076	val: 0.787743	test: 0.811709

Epoch: 70
Loss: 0.31259376424795227
ROC train: 0.960558	val: 0.878398	test: 0.878326
PRC train: 0.953830	val: 0.806798	test: 0.819334

Epoch: 71
Loss: 0.29945237580486195
ROC train: 0.961695	val: 0.879848	test: 0.880777
PRC train: 0.954639	val: 0.814773	test: 0.818627

Epoch: 72
Loss: 0.31628239778501127
ROC train: 0.962752	val: 0.881298	test: 0.875175
PRC train: 0.956148	val: 0.814686	test: 0.811194

Epoch: 73
Loss: 0.3051919639188349
ROC train: 0.961854	val: 0.871874	test: 0.866246
PRC train: 0.956030	val: 0.791267	test: 0.798688

Epoch: 74
Loss: 0.32075531513743283
ROC train: 0.964719	val: 0.866256	test: 0.884104
PRC train: 0.958917	val: 0.808370	test: 0.820062

Epoch: 75
Loss: 0.30905365354134007
ROC train: 0.964705	val: 0.861725	test: 0.884979
PRC train: 0.959265	val: 0.797977	test: 0.821373

Epoch: 76
Loss: 0.2934771463005636
ROC train: 0.963304	val: 0.874955	test: 0.870273
PRC train: 0.956261	val: 0.792457	test: 0.797780

Epoch: 77
Loss: 0.29441869478913824
ROC train: 0.953491	val: 0.852845	test: 0.844888
PRC train: 0.945211	val: 0.758797	test: 0.760558

Epoch: 78
Loss: 0.3167849009488661
ROC train: 0.964726	val: 0.866981	test: 0.852416
PRC train: 0.957862	val: 0.784482	test: 0.781052

Epoch: 79
Loss: 0.314127299953714
ROC train: 0.966650	val: 0.872418	test: 0.870098
PRC train: 0.960670	val: 0.805439	test: 0.807407

Epoch: 80
Loss: 0.2907690011415978
ROC train: 0.965209	val: 0.861544	test: 0.870623
PRC train: 0.958480	val: 0.783437	test: 0.809867

Epoch: 81
Loss: 0.2867985588697063
ROC train: 0.969297	val: 0.865893	test: 0.871148
PRC train: 0.964219	val: 0.781121	test: 0.805629

Epoch: 82
Loss: 0.2855135977435223
ROC train: 0.966383	val: 0.878942	test: 0.878676
PRC train: 0.961408	val: 0.795528	test: 0.816859

Epoch: 83
Loss: 0.2860142679261943
ROC train: 0.966831	val: 0.878579	test: 0.891282
PRC train: 0.961266	val: 0.810591	test: 0.831986

Epoch: 84
Loss: 0.29332988359829165
ROC train: 0.972374	val: 0.889815	test: 0.881653
PRC train: 0.966780	val: 0.821687	test: 0.823954

Epoch: 85
Loss: 0.28730926267617257
ROC train: 0.971713	val: 0.875498	test: 0.865721
PRC train: 0.965940	val: 0.793814	test: 0.804061

Epoch: 86
Loss: 0.28039958477224547
ROC train: 0.971574	val: 0.876767	test: 0.866246
PRC train: 0.966738	val: 0.797686	test: 0.805040

Epoch: 87
Loss: 0.2936772494556648
ROC train: 0.971986	val: 0.873867	test: 0.885679
PRC train: 0.966182	val: 0.800950	test: 0.830241

Epoch: 88
Loss: 0.32401495624268983
ROC train: 0.968333	val: 0.871874	test: 0.899335
PRC train: 0.960661	val: 0.817931	test: 0.846328

Epoch: 89
Loss: 0.28505360523295226
ROC train: 0.970500	val: 0.863538	test: 0.876926
PRC train: 0.964928	val: 0.783506	test: 0.808851

Epoch: 90
Loss: 0.29290591307554836
ROC train: 0.968317	val: 0.859732	test: 0.878501
PRC train: 0.962386	val: 0.796995	test: 0.812184

Epoch: 91
Loss: 0.27999439137294135
ROC train: 0.972658	val: 0.881660	test: 0.870798
PRC train: 0.967195	val: 0.822858	test: 0.799695

Epoch: 92
Loss: 0.28155056292439107
ROC train: 0.973706	val: 0.879304	test: 0.877451
PRC train: 0.968101	val: 0.810474	test: 0.808111

Epoch: 93
Loss: 0.2661567811536013
ROC train: 0.971050	val: 0.872599	test: 0.871148
PRC train: 0.965870	val: 0.792795	test: 0.800024

Epoch: 94
Loss: 0.2847458713878766
PRC train: 0.916352	val: 0.800146	test: 0.825078

Epoch: 34
Loss: 0.37228687796642707
ROC train: 0.928957	val: 0.862269	test: 0.867822
PRC train: 0.915836	val: 0.771177	test: 0.804172

Epoch: 35
Loss: 0.38185119190195405
ROC train: 0.928434	val: 0.861182	test: 0.859769
PRC train: 0.915775	val: 0.771459	test: 0.792243

Epoch: 36
Loss: 0.387818697638456
ROC train: 0.931066	val: 0.869155	test: 0.870448
PRC train: 0.918102	val: 0.788124	test: 0.807049

Epoch: 37
Loss: 0.37690236470193633
ROC train: 0.935210	val: 0.869880	test: 0.875000
PRC train: 0.923496	val: 0.783656	test: 0.807286

Epoch: 38
Loss: 0.3650852657318479
ROC train: 0.932773	val: 0.869880	test: 0.875875
PRC train: 0.921335	val: 0.795404	test: 0.807526

Epoch: 39
Loss: 0.37750129902734575
ROC train: 0.931765	val: 0.859369	test: 0.858368
PRC train: 0.920690	val: 0.776877	test: 0.789467

Epoch: 40
Loss: 0.36822764900057525
ROC train: 0.935752	val: 0.862813	test: 0.856793
PRC train: 0.924699	val: 0.778849	test: 0.787328

Epoch: 41
Loss: 0.37333268283102844
ROC train: 0.938931	val: 0.864444	test: 0.866597
PRC train: 0.926655	val: 0.780986	test: 0.797746

Epoch: 42
Loss: 0.36378584082177085
ROC train: 0.936866	val: 0.863719	test: 0.863796
PRC train: 0.924215	val: 0.775294	test: 0.800805

Epoch: 43
Loss: 0.35422366039378855
ROC train: 0.936373	val: 0.869699	test: 0.868697
PRC train: 0.923594	val: 0.775682	test: 0.807066

Epoch: 44
Loss: 0.36818099910664454
ROC train: 0.940359	val: 0.870968	test: 0.874475
PRC train: 0.928191	val: 0.790194	test: 0.813042

Epoch: 45
Loss: 0.3678351549104998
ROC train: 0.941854	val: 0.868793	test: 0.872024
PRC train: 0.930134	val: 0.776692	test: 0.803388

Epoch: 46
Loss: 0.35162381644797025
ROC train: 0.939401	val: 0.868068	test: 0.860819
PRC train: 0.927659	val: 0.776058	test: 0.794245

Epoch: 47
Loss: 0.3677904014903081
ROC train: 0.940554	val: 0.876767	test: 0.870973
PRC train: 0.929375	val: 0.801554	test: 0.808042

Epoch: 48
Loss: 0.3670841919424081
ROC train: 0.941204	val: 0.871874	test: 0.859069
PRC train: 0.930385	val: 0.792107	test: 0.794761

Epoch: 49
Loss: 0.37658781689416915
ROC train: 0.944257	val: 0.866800	test: 0.861520
PRC train: 0.933661	val: 0.769913	test: 0.795778

Epoch: 50
Loss: 0.3608349768616673
ROC train: 0.944133	val: 0.867343	test: 0.870798
PRC train: 0.934221	val: 0.769641	test: 0.809819

Epoch: 51
Loss: 0.3602061797511449
ROC train: 0.941672	val: 0.868793	test: 0.863095
PRC train: 0.931608	val: 0.774111	test: 0.804083

Epoch: 52
Loss: 0.362164372649414
ROC train: 0.942330	val: 0.864081	test: 0.872199
PRC train: 0.929701	val: 0.774427	test: 0.812366

Epoch: 53
Loss: 0.34195564985124777
ROC train: 0.944441	val: 0.866075	test: 0.875000
PRC train: 0.932797	val: 0.781192	test: 0.816973

Epoch: 54
Loss: 0.34919466501552776
ROC train: 0.945442	val: 0.881660	test: 0.871849
PRC train: 0.933614	val: 0.802279	test: 0.811746

Epoch: 55
Loss: 0.3479115048353921
ROC train: 0.947134	val: 0.886553	test: 0.879377
PRC train: 0.937144	val: 0.812161	test: 0.823528

Epoch: 56
Loss: 0.34226367443962447
ROC train: 0.948956	val: 0.881841	test: 0.879727
PRC train: 0.939293	val: 0.806556	test: 0.816340

Epoch: 57
Loss: 0.33890666606299263
ROC train: 0.947929	val: 0.865712	test: 0.867122
PRC train: 0.937986	val: 0.770718	test: 0.802384

Epoch: 58
Loss: 0.32811181646531057
ROC train: 0.947028	val: 0.854295	test: 0.862395
PRC train: 0.936503	val: 0.755201	test: 0.800172

Epoch: 59
Loss: 0.34471848102073877
ROC train: 0.949632	val: 0.863900	test: 0.864146
PRC train: 0.938844	val: 0.773218	test: 0.799568

Epoch: 60
Loss: 0.3320546108719489
ROC train: 0.949170	val: 0.872599	test: 0.862745
PRC train: 0.938027	val: 0.787956	test: 0.798657

Epoch: 61
Loss: 0.3309156579453757
ROC train: 0.950923	val: 0.868612	test: 0.869573
PRC train: 0.940041	val: 0.784707	test: 0.807127

Epoch: 62
Loss: 0.3393121723178233
ROC train: 0.951274	val: 0.855926	test: 0.853992
PRC train: 0.940942	val: 0.743123	test: 0.787436

Epoch: 63
Loss: 0.3240043169676966
ROC train: 0.955375	val: 0.869699	test: 0.874825
PRC train: 0.947081	val: 0.774600	test: 0.812616

Epoch: 64
Loss: 0.34164526713403964
ROC train: 0.951695	val: 0.868431	test: 0.875175
PRC train: 0.943630	val: 0.790806	test: 0.823139

Epoch: 65
Loss: 0.32977786693909406
ROC train: 0.951692	val: 0.870787	test: 0.867472
PRC train: 0.943524	val: 0.785509	test: 0.814480

Epoch: 66
Loss: 0.3398488790228052
ROC train: 0.954202	val: 0.868612	test: 0.876225
PRC train: 0.945383	val: 0.786810	test: 0.819152

Epoch: 67
Loss: 0.3145568626734973
ROC train: 0.954214	val: 0.862994	test: 0.866422
PRC train: 0.945169	val: 0.765073	test: 0.804209

Epoch: 68
Loss: 0.3404694973974558
ROC train: 0.957471	val: 0.871874	test: 0.873424
PRC train: 0.948965	val: 0.779689	test: 0.815083

Epoch: 69
Loss: 0.3271130462356733
ROC train: 0.957142	val: 0.884197	test: 0.879552
PRC train: 0.949168	val: 0.808659	test: 0.820059

Epoch: 70
Loss: 0.3203514719731402
ROC train: 0.956207	val: 0.883472	test: 0.881127
PRC train: 0.946543	val: 0.809621	test: 0.825720

Epoch: 71
Loss: 0.32419998131215644
ROC train: 0.960504	val: 0.876948	test: 0.873599
PRC train: 0.951713	val: 0.788602	test: 0.814534

Epoch: 72
Loss: 0.3337716314162159
ROC train: 0.953016	val: 0.864262	test: 0.859769
PRC train: 0.943585	val: 0.767601	test: 0.804854

Epoch: 73
Loss: 0.31490646133048317
ROC train: 0.959768	val: 0.869155	test: 0.875175
PRC train: 0.950284	val: 0.786605	test: 0.813215

Epoch: 74
Loss: 0.3071734668508952
ROC train: 0.961978	val: 0.876767	test: 0.878151
PRC train: 0.953872	val: 0.791873	test: 0.820869

Epoch: 75
Loss: 0.323645512114036
ROC train: 0.961969	val: 0.876948	test: 0.868172
PRC train: 0.955042	val: 0.794806	test: 0.808302

Epoch: 76
Loss: 0.30639575054568563
ROC train: 0.961049	val: 0.876767	test: 0.882178
PRC train: 0.953173	val: 0.798374	test: 0.829295

Epoch: 77
Loss: 0.31614255016719084
ROC train: 0.960670	val: 0.876586	test: 0.877801
PRC train: 0.952086	val: 0.795153	test: 0.825460

Epoch: 78
Loss: 0.29284571681541705
ROC train: 0.963249	val: 0.873505	test: 0.872724
PRC train: 0.955493	val: 0.779912	test: 0.816621

Epoch: 79
Loss: 0.3132026523105159
ROC train: 0.962692	val: 0.876223	test: 0.882353
PRC train: 0.955149	val: 0.788880	test: 0.826862

Epoch: 80
Loss: 0.3042534711780403
ROC train: 0.964573	val: 0.881298	test: 0.874475
PRC train: 0.956671	val: 0.807538	test: 0.823581

Epoch: 81
Loss: 0.2924617784434745
ROC train: 0.962055	val: 0.868068	test: 0.867297
PRC train: 0.954258	val: 0.785549	test: 0.808516

Epoch: 82
Loss: 0.31980849069819284
ROC train: 0.964029	val: 0.876223	test: 0.876576
PRC train: 0.956820	val: 0.804166	test: 0.818162

Epoch: 83
Loss: 0.3084880300816174
ROC train: 0.965095	val: 0.874411	test: 0.883228
PRC train: 0.958476	val: 0.789525	test: 0.826166

Epoch: 84
Loss: 0.3011258781365544
ROC train: 0.963935	val: 0.868249	test: 0.874300
PRC train: 0.955993	val: 0.771676	test: 0.818511

Epoch: 85
Loss: 0.29689424506714823
ROC train: 0.964279	val: 0.868793	test: 0.880077
PRC train: 0.956461	val: 0.776326	test: 0.827428

Epoch: 86
Loss: 0.31009267445396305
ROC train: 0.965386	val: 0.859369	test: 0.870973
PRC train: 0.958714	val: 0.764321	test: 0.816306

Epoch: 87
Loss: 0.2955221511632282
ROC train: 0.967141	val: 0.868068	test: 0.864496
PRC train: 0.960454	val: 0.776279	test: 0.809159

Epoch: 88
Loss: 0.3020888546348182
ROC train: 0.967084	val: 0.873686	test: 0.877451
PRC train: 0.960306	val: 0.785889	test: 0.821634

Epoch: 89
Loss: 0.2832366744180114
ROC train: 0.970127	val: 0.874773	test: 0.883053
PRC train: 0.963408	val: 0.792260	test: 0.826979

Epoch: 90
Loss: 0.279542557893039
ROC train: 0.968388	val: 0.875680	test: 0.883053
PRC train: 0.961990	val: 0.801346	test: 0.837344

Epoch: 91
Loss: 0.29823968547440216
ROC train: 0.968874	val: 0.881116	test: 0.870448
PRC train: 0.962854	val: 0.805096	test: 0.821102

Epoch: 92
Loss: 0.278317810819604
ROC train: 0.970237	val: 0.882204	test: 0.866597
PRC train: 0.964108	val: 0.796637	test: 0.811166

Epoch: 93
Loss: 0.2866328157906647
ROC train: 0.971747	val: 0.876586	test: 0.883053
PRC train: 0.965676	val: 0.790724	test: 0.827182

Epoch: 94
Loss: 0.30821194614498915
ROC train: 0.968600	val: 0.879123	test: 0.875875
ROC train: 0.980757	val: 0.832785	test: 0.862423
PRC train: 0.976741	val: 0.802814	test: 0.802205

Epoch: 95
Loss: 0.24089014134605444
ROC train: 0.982771	val: 0.835857	test: 0.862423
PRC train: 0.978983	val: 0.802470	test: 0.794625

Epoch: 96
Loss: 0.23884057465900355
ROC train: 0.981130	val: 0.836208	test: 0.855924
PRC train: 0.977639	val: 0.806296	test: 0.787881

Epoch: 97
Loss: 0.24648457356922088
ROC train: 0.981735	val: 0.835462	test: 0.855305
PRC train: 0.978317	val: 0.807190	test: 0.789291

Epoch: 98
Loss: 0.24597688450258537
ROC train: 0.981291	val: 0.837086	test: 0.851503
PRC train: 0.977160	val: 0.810717	test: 0.783901

Epoch: 99
Loss: 0.22444945141015138
ROC train: 0.979924	val: 0.842791	test: 0.846375
PRC train: 0.975391	val: 0.813725	test: 0.771889

Epoch: 100
Loss: 0.23416711777855154
ROC train: 0.978102	val: 0.842967	test: 0.848187
PRC train: 0.973307	val: 0.823093	test: 0.774411

Epoch: 101
Loss: 0.23762148087871177
ROC train: 0.983709	val: 0.844591	test: 0.852255
PRC train: 0.980170	val: 0.820253	test: 0.780881

Epoch: 102
Loss: 0.2064992558338915
ROC train: 0.983043	val: 0.839675	test: 0.851680
PRC train: 0.979919	val: 0.817421	test: 0.783253

Epoch: 103
Loss: 0.2320834068625081
ROC train: 0.980208	val: 0.835286	test: 0.848011
PRC train: 0.976760	val: 0.818256	test: 0.778176

Epoch: 104
Loss: 0.24501453528864886
ROC train: 0.983057	val: 0.838271	test: 0.858974
PRC train: 0.980342	val: 0.816393	test: 0.795323

Epoch: 105
Loss: 0.23434624728881023
ROC train: 0.984050	val: 0.842967	test: 0.863307
PRC train: 0.981352	val: 0.812240	test: 0.802410

Epoch: 106
Loss: 0.2371658303034001
ROC train: 0.984045	val: 0.846434	test: 0.857958
PRC train: 0.980666	val: 0.818842	test: 0.791741

Epoch: 107
Loss: 0.23858850981792065
ROC train: 0.984638	val: 0.845776	test: 0.852166
PRC train: 0.981069	val: 0.820264	test: 0.781006

Epoch: 108
Loss: 0.23211247218145037
ROC train: 0.985965	val: 0.842133	test: 0.861804
PRC train: 0.982661	val: 0.812829	test: 0.797102

Epoch: 109
Loss: 0.21285506457485026
ROC train: 0.984613	val: 0.840421	test: 0.864987
PRC train: 0.981699	val: 0.807610	test: 0.801400

Epoch: 110
Loss: 0.2306104795965344
ROC train: 0.984268	val: 0.840202	test: 0.864898
PRC train: 0.981335	val: 0.809017	test: 0.805202

Epoch: 111
Loss: 0.23142728591184744
ROC train: 0.985417	val: 0.839324	test: 0.857427
PRC train: 0.982483	val: 0.815091	test: 0.792244

Epoch: 112
Loss: 0.21725283997278677
ROC train: 0.985370	val: 0.834672	test: 0.854598
PRC train: 0.982307	val: 0.809702	test: 0.785563

Epoch: 113
Loss: 0.2339382526491519
ROC train: 0.987597	val: 0.834233	test: 0.859195
PRC train: 0.984739	val: 0.801052	test: 0.796026

Epoch: 114
Loss: 0.2417690624572717
ROC train: 0.987389	val: 0.839851	test: 0.860522
PRC train: 0.985170	val: 0.803680	test: 0.798618

Epoch: 115
Loss: 0.21026730232581958
ROC train: 0.987239	val: 0.841782	test: 0.859019
PRC train: 0.985043	val: 0.814143	test: 0.794115

Epoch: 116
Loss: 0.21882726082398032
ROC train: 0.985544	val: 0.832829	test: 0.859284
PRC train: 0.982114	val: 0.802036	test: 0.795992

Epoch: 117
Loss: 0.2141065821070656
ROC train: 0.987817	val: 0.840772	test: 0.854996
PRC train: 0.985157	val: 0.813452	test: 0.784561

Epoch: 118
Loss: 0.21514340279722496
ROC train: 0.987842	val: 0.841255	test: 0.860920
PRC train: 0.985298	val: 0.808489	test: 0.798103

Epoch: 119
Loss: 0.21053249222014675
ROC train: 0.988146	val: 0.840290	test: 0.866180
PRC train: 0.985808	val: 0.805398	test: 0.806446

Epoch: 120
Loss: 0.2157658252659178
ROC train: 0.987229	val: 0.839280	test: 0.867153
PRC train: 0.984651	val: 0.804891	test: 0.805373

Early stopping
Best (ROC):	 train: 0.974971	val: 0.849155	test: 0.856101
Best (PRC):	 train: 0.969294	val: 0.822254	test: 0.789996

ROC train: 0.975926	val: 0.835857	test: 0.850928
PRC train: 0.969587	val: 0.819271	test: 0.772777

Epoch: 95
Loss: 0.2582201337279658
ROC train: 0.974966	val: 0.834321	test: 0.851415
PRC train: 0.967772	val: 0.808201	test: 0.768779

Epoch: 96
Loss: 0.2480708925903819
ROC train: 0.971399	val: 0.834979	test: 0.844430
PRC train: 0.964642	val: 0.805473	test: 0.762340

Epoch: 97
Loss: 0.27536346451442767
ROC train: 0.975752	val: 0.836691	test: 0.848453
PRC train: 0.970043	val: 0.811344	test: 0.772220

Epoch: 98
Loss: 0.2416344149678339
ROC train: 0.978503	val: 0.834584	test: 0.855570
PRC train: 0.973069	val: 0.811515	test: 0.784936

Epoch: 99
Loss: 0.276332076167914
ROC train: 0.979096	val: 0.835594	test: 0.851680
PRC train: 0.974081	val: 0.819316	test: 0.786113

Epoch: 100
Loss: 0.2789630856428254
ROC train: 0.976994	val: 0.842879	test: 0.846950
PRC train: 0.971315	val: 0.830207	test: 0.780295

Epoch: 101
Loss: 0.23417876078612537
ROC train: 0.971953	val: 0.837042	test: 0.845137
PRC train: 0.964252	val: 0.808948	test: 0.769681

Epoch: 102
Loss: 0.2500867608631836
ROC train: 0.973249	val: 0.828308	test: 0.856852
PRC train: 0.966274	val: 0.789245	test: 0.787397

Epoch: 103
Loss: 0.2702775386180107
ROC train: 0.973839	val: 0.825894	test: 0.857206
PRC train: 0.967504	val: 0.797560	test: 0.791878

Epoch: 104
Loss: 0.25346223379205884
ROC train: 0.980233	val: 0.834409	test: 0.854288
PRC train: 0.975470	val: 0.820783	test: 0.783584

Epoch: 105
Loss: 0.2391205907822483
ROC train: 0.980581	val: 0.829405	test: 0.856101
PRC train: 0.976144	val: 0.804951	test: 0.784260

Epoch: 106
Loss: 0.24571640881427473
ROC train: 0.977146	val: 0.828791	test: 0.851194
PRC train: 0.972470	val: 0.794795	test: 0.774892

Epoch: 107
Loss: 0.22674019197159528
ROC train: 0.973785	val: 0.828571	test: 0.836118
PRC train: 0.968764	val: 0.804847	test: 0.759793

Epoch: 108
Loss: 0.25719862741809996
ROC train: 0.976713	val: 0.825982	test: 0.836118
PRC train: 0.971731	val: 0.801400	test: 0.756566

Epoch: 109
Loss: 0.22968134289125944
ROC train: 0.968793	val: 0.827167	test: 0.826083
PRC train: 0.962784	val: 0.804882	test: 0.740936

Epoch: 110
Loss: 0.22603600040878752
ROC train: 0.976730	val: 0.837700	test: 0.841070
PRC train: 0.971572	val: 0.816738	test: 0.762555

Epoch: 111
Loss: 0.24891558556560284
ROC train: 0.981884	val: 0.839149	test: 0.850973
PRC train: 0.977336	val: 0.818802	test: 0.783860

Epoch: 112
Loss: 0.2282466868531587
ROC train: 0.980424	val: 0.834628	test: 0.854598
PRC train: 0.976132	val: 0.812623	test: 0.786806

Epoch: 113
Loss: 0.23548792489215123
ROC train: 0.981605	val: 0.832521	test: 0.854598
PRC train: 0.976987	val: 0.798371	test: 0.786366

Epoch: 114
Loss: 0.23887402510352646
ROC train: 0.983006	val: 0.839675	test: 0.844695
PRC train: 0.978632	val: 0.814778	test: 0.771532

Epoch: 115
Loss: 0.2208577195911884
ROC train: 0.981208	val: 0.843976	test: 0.843457
PRC train: 0.976872	val: 0.825841	test: 0.764918

Epoch: 116
Loss: 0.24363032566194934
ROC train: 0.982575	val: 0.843669	test: 0.853095
PRC train: 0.978547	val: 0.832085	test: 0.780857

Epoch: 117
Loss: 0.23451701565501956
ROC train: 0.982820	val: 0.823568	test: 0.858576
PRC train: 0.978365	val: 0.807458	test: 0.801211

Epoch: 118
Loss: 0.25539346757996473
ROC train: 0.983143	val: 0.831073	test: 0.852962
PRC train: 0.979085	val: 0.819213	test: 0.794022

Epoch: 119
Loss: 0.23679574254955035
ROC train: 0.982901	val: 0.837393	test: 0.841821
PRC train: 0.979071	val: 0.827495	test: 0.771951

Epoch: 120
Loss: 0.2160164387309477
ROC train: 0.985167	val: 0.843845	test: 0.851680
PRC train: 0.981780	val: 0.827749	test: 0.784264

Early stopping
Best (ROC):	 train: 0.961830	val: 0.847400	test: 0.849779
Best (PRC):	 train: 0.952703	val: 0.831593	test: 0.777437

ROC train: 0.977308	val: 0.834760	test: 0.845402
PRC train: 0.971533	val: 0.808741	test: 0.762074

Epoch: 95
Loss: 0.2513932072205664
ROC train: 0.978866	val: 0.836691	test: 0.858355
PRC train: 0.974301	val: 0.819354	test: 0.790505

Epoch: 96
Loss: 0.24637815844426036
ROC train: 0.979243	val: 0.831995	test: 0.859372
PRC train: 0.974948	val: 0.815334	test: 0.798376

Epoch: 97
Loss: 0.23816678672777103
ROC train: 0.978459	val: 0.826816	test: 0.851105
PRC train: 0.973905	val: 0.803542	test: 0.782381

Epoch: 98
Loss: 0.23877625289705273
ROC train: 0.979030	val: 0.831863	test: 0.844960
PRC train: 0.974162	val: 0.804952	test: 0.766455

Epoch: 99
Loss: 0.24236521140953327
ROC train: 0.980571	val: 0.833619	test: 0.851636
PRC train: 0.976309	val: 0.816602	test: 0.774497

Epoch: 100
Loss: 0.2575282602870753
ROC train: 0.979807	val: 0.828791	test: 0.856543
PRC train: 0.975162	val: 0.812626	test: 0.784144

Epoch: 101
Loss: 0.24294080283715871
ROC train: 0.982433	val: 0.831512	test: 0.849646
PRC train: 0.978418	val: 0.813602	test: 0.780300

Epoch: 102
Loss: 0.250682335841271
ROC train: 0.981081	val: 0.831600	test: 0.849602
PRC train: 0.976731	val: 0.802627	test: 0.781614

Epoch: 103
Loss: 0.23807916970827414
ROC train: 0.977181	val: 0.826904	test: 0.845402
PRC train: 0.972049	val: 0.787280	test: 0.768476

Epoch: 104
Loss: 0.2499301051008893
ROC train: 0.977651	val: 0.831117	test: 0.827763
PRC train: 0.973105	val: 0.808673	test: 0.738335

Epoch: 105
Loss: 0.23953851787183794
ROC train: 0.980997	val: 0.829976	test: 0.841600
PRC train: 0.975989	val: 0.805949	test: 0.766216

Epoch: 106
Loss: 0.21513564117034234
ROC train: 0.981032	val: 0.826772	test: 0.857781
PRC train: 0.975851	val: 0.799088	test: 0.796262

Epoch: 107
Loss: 0.24925870386325286
ROC train: 0.983846	val: 0.829888	test: 0.850221
PRC train: 0.979790	val: 0.801127	test: 0.782560

Epoch: 108
Loss: 0.24027595534372181
ROC train: 0.982026	val: 0.838666	test: 0.843369
PRC train: 0.978417	val: 0.812469	test: 0.761813

Epoch: 109
Loss: 0.23725831725252233
ROC train: 0.984275	val: 0.835286	test: 0.857383
PRC train: 0.981028	val: 0.801013	test: 0.782202

Epoch: 110
Loss: 0.22331894228061624
ROC train: 0.983633	val: 0.832565	test: 0.862069
PRC train: 0.980488	val: 0.804531	test: 0.792122

Epoch: 111
Loss: 0.22595681955016775
ROC train: 0.984520	val: 0.831731	test: 0.859372
PRC train: 0.981294	val: 0.819022	test: 0.791370

Epoch: 112
Loss: 0.24664392877541472
ROC train: 0.983065	val: 0.828220	test: 0.862953
PRC train: 0.979325	val: 0.813778	test: 0.800401

Epoch: 113
Loss: 0.19481150666581223
ROC train: 0.981213	val: 0.833004	test: 0.861538
PRC train: 0.976786	val: 0.814211	test: 0.795108

Epoch: 114
Loss: 0.226947051974376
ROC train: 0.982690	val: 0.835374	test: 0.853890
PRC train: 0.978619	val: 0.811110	test: 0.779247

Epoch: 115
Loss: 0.24124517909050952
ROC train: 0.984091	val: 0.829274	test: 0.847126
PRC train: 0.980618	val: 0.800453	test: 0.770936

Epoch: 116
Loss: 0.2384259404003568
ROC train: 0.986367	val: 0.828396	test: 0.841468
PRC train: 0.983488	val: 0.806295	test: 0.762989

Epoch: 117
Loss: 0.24441898939562823
ROC train: 0.986735	val: 0.830546	test: 0.850044
PRC train: 0.984300	val: 0.816571	test: 0.774812

Epoch: 118
Loss: 0.23769674000072982
ROC train: 0.984530	val: 0.830108	test: 0.864810
PRC train: 0.981395	val: 0.815034	test: 0.801724

Epoch: 119
Loss: 0.20913926214058984
ROC train: 0.985882	val: 0.833531	test: 0.856808
PRC train: 0.982899	val: 0.820352	test: 0.784892

Epoch: 120
Loss: 0.22542573954463296
ROC train: 0.985941	val: 0.830898	test: 0.845756
PRC train: 0.982475	val: 0.809200	test: 0.759596

Early stopping
Best (ROC):	 train: 0.961806	val: 0.842835	test: 0.854377
Best (PRC):	 train: 0.951764	val: 0.823482	test: 0.780546
All runs completed.


Epoch: 95
Loss: 0.29079329856995834
ROC train: 0.960600	val: 0.823849	test: 0.893506
PRC train: 0.952371	val: 0.798287	test: 0.833094

Epoch: 96
Loss: 0.30459331745535856
ROC train: 0.958668	val: 0.823140	test: 0.887659
PRC train: 0.949640	val: 0.795330	test: 0.829343

Epoch: 97
Loss: 0.28132976736731274
ROC train: 0.953332	val: 0.828493	test: 0.884696
PRC train: 0.943409	val: 0.799333	test: 0.828918

Epoch: 98
Loss: 0.32266764535574716
ROC train: 0.953671	val: 0.829909	test: 0.884774
PRC train: 0.944242	val: 0.798728	test: 0.828430

Epoch: 99
Loss: 0.3002856600048688
ROC train: 0.956670	val: 0.819992	test: 0.876744
PRC train: 0.946778	val: 0.787389	test: 0.816972

Epoch: 100
Loss: 0.30613040926660784
ROC train: 0.957360	val: 0.819835	test: 0.879863
PRC train: 0.946776	val: 0.791014	test: 0.819724

Epoch: 101
Loss: 0.31958385572335335
ROC train: 0.956453	val: 0.835340	test: 0.889296
PRC train: 0.946704	val: 0.814017	test: 0.829533

Epoch: 102
Loss: 0.33161088146281953
ROC train: 0.959255	val: 0.818654	test: 0.887425
PRC train: 0.949573	val: 0.790187	test: 0.831823

Epoch: 103
Loss: 0.307561065449491
ROC train: 0.957683	val: 0.809760	test: 0.871677
PRC train: 0.949461	val: 0.770272	test: 0.799907

Epoch: 104
Loss: 0.3202925032832776
ROC train: 0.964602	val: 0.822353	test: 0.877212
PRC train: 0.958164	val: 0.785372	test: 0.804797

Epoch: 105
Loss: 0.28881023240154907
ROC train: 0.965306	val: 0.830618	test: 0.888594
PRC train: 0.957907	val: 0.798398	test: 0.824636

Epoch: 106
Loss: 0.3145623971301197
ROC train: 0.966903	val: 0.831484	test: 0.891635
PRC train: 0.960375	val: 0.795195	test: 0.831747

Epoch: 107
Loss: 0.3338681550398719
ROC train: 0.967481	val: 0.838882	test: 0.891791
PRC train: 0.961239	val: 0.804205	test: 0.825464

Epoch: 108
Loss: 0.2724352034246372
ROC train: 0.966082	val: 0.843841	test: 0.889608
PRC train: 0.959986	val: 0.814306	test: 0.820854

Epoch: 109
Loss: 0.2976588703298847
ROC train: 0.966170	val: 0.834711	test: 0.887503
PRC train: 0.959160	val: 0.807844	test: 0.821962

Epoch: 110
Loss: 0.302062177780455
ROC train: 0.967892	val: 0.828493	test: 0.881656
PRC train: 0.961504	val: 0.801616	test: 0.818116

Epoch: 111
Loss: 0.30302995942092803
ROC train: 0.967673	val: 0.836993	test: 0.890777
PRC train: 0.961693	val: 0.813288	test: 0.836089

Epoch: 112
Loss: 0.2645716113509947
ROC train: 0.966865	val: 0.840299	test: 0.888360
PRC train: 0.960448	val: 0.814549	test: 0.828885

Epoch: 113
Loss: 0.2528928235764558
ROC train: 0.966265	val: 0.833530	test: 0.885086
PRC train: 0.960401	val: 0.803484	test: 0.822581

Epoch: 114
Loss: 0.3043417577420184
ROC train: 0.965169	val: 0.830146	test: 0.880720
PRC train: 0.959052	val: 0.797143	test: 0.808852

Epoch: 115
Loss: 0.3081377650435306
ROC train: 0.966324	val: 0.835577	test: 0.885320
PRC train: 0.960749	val: 0.807956	test: 0.816719

Epoch: 116
Loss: 0.3063495053775599
ROC train: 0.964807	val: 0.836442	test: 0.894441
PRC train: 0.956197	val: 0.807850	test: 0.842492

Epoch: 117
Loss: 0.2650940192745307
ROC train: 0.965547	val: 0.833373	test: 0.893350
PRC train: 0.958847	val: 0.804374	test: 0.847862

Epoch: 118
Loss: 0.2868768387630546
ROC train: 0.969760	val: 0.824400	test: 0.887269
PRC train: 0.964438	val: 0.795175	test: 0.832225

Epoch: 119
Loss: 0.2797575842354868
ROC train: 0.967698	val: 0.822511	test: 0.882124
PRC train: 0.962561	val: 0.789909	test: 0.824345

Epoch: 120
Loss: 0.2817279035840791
ROC train: 0.966326	val: 0.819284	test: 0.879395
PRC train: 0.959577	val: 0.790628	test: 0.819876

Early stopping
Best (ROC):	 train: 0.937250	val: 0.845022	test: 0.879863
Best (PRC):	 train: 0.921848	val: 0.809604	test: 0.808320


Epoch: 95
Loss: 0.3150140960031107
ROC train: 0.948836	val: 0.827076	test: 0.895767
PRC train: 0.936215	val: 0.790348	test: 0.832312

Epoch: 96
Loss: 0.31731771443142515
ROC train: 0.953826	val: 0.832822	test: 0.891791
PRC train: 0.943057	val: 0.795361	test: 0.829732

Epoch: 97
Loss: 0.3670508342610024
ROC train: 0.959603	val: 0.837308	test: 0.889920
PRC train: 0.950171	val: 0.798165	test: 0.828303

Epoch: 98
Loss: 0.3034632899567395
ROC train: 0.959411	val: 0.838646	test: 0.892259
PRC train: 0.949589	val: 0.802711	test: 0.824259

Epoch: 99
Loss: 0.3115531109661582
ROC train: 0.954612	val: 0.836206	test: 0.891791
PRC train: 0.944061	val: 0.799929	test: 0.819353

Epoch: 100
Loss: 0.32960055831023605
ROC train: 0.954943	val: 0.830854	test: 0.891245
PRC train: 0.944654	val: 0.790672	test: 0.822871

Epoch: 101
Loss: 0.28457478177033935
ROC train: 0.959794	val: 0.825108	test: 0.895923
PRC train: 0.950771	val: 0.789142	test: 0.830450

Epoch: 102
Loss: 0.29176013015243896
ROC train: 0.960794	val: 0.819756	test: 0.895455
PRC train: 0.952468	val: 0.789857	test: 0.831420

Epoch: 103
Loss: 0.35842469926717047
ROC train: 0.959991	val: 0.809130	test: 0.891635
PRC train: 0.951328	val: 0.778422	test: 0.832488

Epoch: 104
Loss: 0.2993618891260225
ROC train: 0.960130	val: 0.810232	test: 0.900600
PRC train: 0.950347	val: 0.777999	test: 0.850138

Epoch: 105
Loss: 0.31276640282975243
ROC train: 0.960462	val: 0.818339	test: 0.903251
PRC train: 0.951021	val: 0.779105	test: 0.850127

Epoch: 106
Loss: 0.2863239231307483
ROC train: 0.960546	val: 0.824793	test: 0.897716
PRC train: 0.951207	val: 0.782114	test: 0.828726

Epoch: 107
Loss: 0.32896805914329913
ROC train: 0.959153	val: 0.823455	test: 0.891557
PRC train: 0.948569	val: 0.777261	test: 0.820214

Epoch: 108
Loss: 0.29250389739167304
ROC train: 0.959171	val: 0.820622	test: 0.897404
PRC train: 0.948900	val: 0.770701	test: 0.834799

Epoch: 109
Loss: 0.2929633097830376
ROC train: 0.961786	val: 0.822826	test: 0.909956
PRC train: 0.951224	val: 0.786233	test: 0.857112

Epoch: 110
Loss: 0.33077200862412653
ROC train: 0.962163	val: 0.827627	test: 0.904654
PRC train: 0.952341	val: 0.794433	test: 0.849831

Epoch: 111
Loss: 0.29809133970774304
ROC train: 0.953790	val: 0.818261	test: 0.888594
PRC train: 0.940627	val: 0.792122	test: 0.832727

Epoch: 112
Loss: 0.3092735208149093
ROC train: 0.962885	val: 0.823062	test: 0.898495
PRC train: 0.953195	val: 0.799514	test: 0.848025

Epoch: 113
Loss: 0.33938657526008587
ROC train: 0.957472	val: 0.824872	test: 0.887971
PRC train: 0.946767	val: 0.793805	test: 0.818888

Epoch: 114
Loss: 0.3378291284458202
ROC train: 0.964081	val: 0.828965	test: 0.892882
PRC train: 0.954619	val: 0.787058	test: 0.824413

Epoch: 115
Loss: 0.3012041738486272
ROC train: 0.964886	val: 0.829516	test: 0.905356
PRC train: 0.957710	val: 0.790183	test: 0.847208

Epoch: 116
Loss: 0.3038395341518673
ROC train: 0.962466	val: 0.825817	test: 0.900756
PRC train: 0.955646	val: 0.773880	test: 0.837299

Epoch: 117
Loss: 0.29119716710496046
ROC train: 0.966048	val: 0.824793	test: 0.898339
PRC train: 0.958883	val: 0.789643	test: 0.829579

Epoch: 118
Loss: 0.2819935505317642
ROC train: 0.965687	val: 0.816922	test: 0.889452
PRC train: 0.958692	val: 0.781459	test: 0.819964

Epoch: 119
Loss: 0.2818696075759715
ROC train: 0.965476	val: 0.812436	test: 0.888984
PRC train: 0.958231	val: 0.782190	test: 0.827279

Epoch: 120
Loss: 0.28722607188875465
ROC train: 0.966301	val: 0.823534	test: 0.898495
PRC train: 0.959061	val: 0.796682	test: 0.846775

Early stopping
Best (ROC):	 train: 0.932629	val: 0.840457	test: 0.896312
Best (PRC):	 train: 0.918181	val: 0.816465	test: 0.835230

ROC train: 0.973469	val: 0.865893	test: 0.873950
PRC train: 0.968338	val: 0.785174	test: 0.815856

Epoch: 95
Loss: 0.26938637816547156
ROC train: 0.971879	val: 0.871149	test: 0.881127
PRC train: 0.965991	val: 0.808193	test: 0.833215

Epoch: 96
Loss: 0.2794556058565411
ROC train: 0.975881	val: 0.867343	test: 0.877451
PRC train: 0.971665	val: 0.788089	test: 0.826211

Epoch: 97
Loss: 0.26222491984844193
ROC train: 0.974620	val: 0.862088	test: 0.879377
PRC train: 0.970354	val: 0.778791	test: 0.831652

Epoch: 98
Loss: 0.27329063624454264
ROC train: 0.975930	val: 0.867887	test: 0.883053
PRC train: 0.971868	val: 0.801121	test: 0.834398

Epoch: 99
Loss: 0.27706928502804395
ROC train: 0.977828	val: 0.867706	test: 0.877801
PRC train: 0.973952	val: 0.801380	test: 0.825622

Epoch: 100
Loss: 0.26632023184141507
ROC train: 0.977078	val: 0.872236	test: 0.873950
PRC train: 0.972711	val: 0.810509	test: 0.820691

Epoch: 101
Loss: 0.26783124401390157
ROC train: 0.976911	val: 0.871330	test: 0.877801
PRC train: 0.971897	val: 0.808121	test: 0.824425

Epoch: 102
Loss: 0.2771443631621585
ROC train: 0.975255	val: 0.875861	test: 0.870623
PRC train: 0.971092	val: 0.813466	test: 0.825362

Epoch: 103
Loss: 0.25188432977230396
ROC train: 0.976178	val: 0.859188	test: 0.850665
PRC train: 0.971658	val: 0.772141	test: 0.797534

Epoch: 104
Loss: 0.26844728377364957
ROC train: 0.975483	val: 0.850852	test: 0.857843
PRC train: 0.971133	val: 0.773868	test: 0.802820

Epoch: 105
Loss: 0.25872853855778816
ROC train: 0.976493	val: 0.865712	test: 0.867822
PRC train: 0.971981	val: 0.799918	test: 0.804399

Epoch: 106
Loss: 0.2631706305879913
ROC train: 0.972851	val: 0.866800	test: 0.861695
PRC train: 0.968290	val: 0.785097	test: 0.777718

Epoch: 107
Loss: 0.26466674661317957
ROC train: 0.979468	val: 0.870424	test: 0.876401
PRC train: 0.975872	val: 0.788579	test: 0.822147

Epoch: 108
Loss: 0.2511465011547981
ROC train: 0.977151	val: 0.867887	test: 0.879377
PRC train: 0.973503	val: 0.794107	test: 0.827405

Epoch: 109
Loss: 0.2625716196632546
ROC train: 0.977155	val: 0.875136	test: 0.871148
PRC train: 0.972192	val: 0.802497	test: 0.812072

Epoch: 110
Loss: 0.27893996232945206
ROC train: 0.980043	val: 0.876767	test: 0.871324
PRC train: 0.976090	val: 0.806461	test: 0.813181

Epoch: 111
Loss: 0.2460385591162329
ROC train: 0.977451	val: 0.866256	test: 0.853291
PRC train: 0.973306	val: 0.782609	test: 0.790240

Epoch: 112
Loss: 0.2659100722475542
ROC train: 0.975047	val: 0.872599	test: 0.865196
PRC train: 0.970771	val: 0.803605	test: 0.808321

Epoch: 113
Loss: 0.2631982919579671
ROC train: 0.976730	val: 0.866981	test: 0.863095
PRC train: 0.972019	val: 0.794207	test: 0.811669

Epoch: 114
Loss: 0.26174375208814177
ROC train: 0.980970	val: 0.870787	test: 0.864496
PRC train: 0.977175	val: 0.792740	test: 0.806579

Epoch: 115
Loss: 0.2558847552788886
ROC train: 0.978833	val: 0.863719	test: 0.865196
PRC train: 0.974058	val: 0.770128	test: 0.807259

Epoch: 116
Loss: 0.2549527780480609
ROC train: 0.979278	val: 0.862994	test: 0.878501
PRC train: 0.975534	val: 0.787631	test: 0.821711

Epoch: 117
Loss: 0.2445174227508819
ROC train: 0.981156	val: 0.856832	test: 0.867997
PRC train: 0.977999	val: 0.781568	test: 0.808435

Epoch: 118
Loss: 0.24324376669589584
ROC train: 0.981855	val: 0.862631	test: 0.867822
PRC train: 0.978625	val: 0.789944	test: 0.811429

Epoch: 119
Loss: 0.2437763039701421
ROC train: 0.981926	val: 0.870787	test: 0.862395
PRC train: 0.978272	val: 0.792320	test: 0.801704

Epoch: 120
Loss: 0.2489156308176526
ROC train: 0.979877	val: 0.862631	test: 0.865196
PRC train: 0.976164	val: 0.783604	test: 0.812620

Early stopping
Best (ROC):	 train: 0.962472	val: 0.878579	test: 0.865371
Best (PRC):	 train: 0.954243	val: 0.814710	test: 0.801602

PRC train: 0.962751	val: 0.792219	test: 0.820393

Epoch: 95
Loss: 0.2893680503219779
ROC train: 0.967442	val: 0.872961	test: 0.886905
PRC train: 0.960856	val: 0.791705	test: 0.836199

Epoch: 96
Loss: 0.2958478006035182
ROC train: 0.961652	val: 0.857376	test: 0.874650
PRC train: 0.952489	val: 0.777304	test: 0.829416

Epoch: 97
Loss: 0.2892557252237153
ROC train: 0.969562	val: 0.866256	test: 0.866597
PRC train: 0.963921	val: 0.789845	test: 0.819298

Epoch: 98
Loss: 0.2784374491090147
ROC train: 0.973620	val: 0.871330	test: 0.869048
PRC train: 0.968250	val: 0.788426	test: 0.808787

Epoch: 99
Loss: 0.2897627967847304
ROC train: 0.972672	val: 0.876767	test: 0.885504
PRC train: 0.968268	val: 0.798649	test: 0.825749

Epoch: 100
Loss: 0.2941720039294958
ROC train: 0.969105	val: 0.876586	test: 0.880777
PRC train: 0.964185	val: 0.790964	test: 0.820836

Epoch: 101
Loss: 0.27584296698766453
ROC train: 0.970058	val: 0.876767	test: 0.883228
PRC train: 0.964892	val: 0.791304	test: 0.826610

Epoch: 102
Loss: 0.26952006868035355
ROC train: 0.972335	val: 0.872780	test: 0.886905
PRC train: 0.967783	val: 0.796829	test: 0.838582

Epoch: 103
Loss: 0.2888634814748976
ROC train: 0.972074	val: 0.865712	test: 0.882528
PRC train: 0.967021	val: 0.783411	test: 0.832910

Epoch: 104
Loss: 0.2603952249379907
ROC train: 0.968580	val: 0.868431	test: 0.861345
PRC train: 0.962362	val: 0.777264	test: 0.803471

Epoch: 105
Loss: 0.2843397885766739
ROC train: 0.973055	val: 0.872780	test: 0.877976
PRC train: 0.967443	val: 0.788606	test: 0.822454

Epoch: 106
Loss: 0.28107538991393594
ROC train: 0.974980	val: 0.877673	test: 0.884104
PRC train: 0.969890	val: 0.810408	test: 0.835559

Epoch: 107
Loss: 0.28500668612093744
ROC train: 0.973063	val: 0.875680	test: 0.872374
PRC train: 0.968664	val: 0.806726	test: 0.820224

Epoch: 108
Loss: 0.2689766176465603
ROC train: 0.976504	val: 0.883110	test: 0.883403
PRC train: 0.971616	val: 0.817533	test: 0.831734

Epoch: 109
Loss: 0.2774018425640342
ROC train: 0.975170	val: 0.883653	test: 0.879727
PRC train: 0.969245	val: 0.810853	test: 0.831641

Epoch: 110
Loss: 0.27086389982918885
ROC train: 0.976139	val: 0.876404	test: 0.868522
PRC train: 0.970959	val: 0.780031	test: 0.810018

Epoch: 111
Loss: 0.26301009900206856
ROC train: 0.973767	val: 0.874592	test: 0.869573
PRC train: 0.968123	val: 0.796958	test: 0.803637

Epoch: 112
Loss: 0.2588091109342232
ROC train: 0.976118	val: 0.877673	test: 0.868697
PRC train: 0.972220	val: 0.801600	test: 0.811630

Epoch: 113
Loss: 0.2568739889980651
ROC train: 0.976260	val: 0.868974	test: 0.878676
PRC train: 0.971935	val: 0.791332	test: 0.824441

Epoch: 114
Loss: 0.27631828509616935
ROC train: 0.974884	val: 0.877492	test: 0.869573
PRC train: 0.970311	val: 0.804208	test: 0.816478

Epoch: 115
Loss: 0.2684873523559408
ROC train: 0.974087	val: 0.863538	test: 0.874300
PRC train: 0.969697	val: 0.785654	test: 0.821372

Epoch: 116
Loss: 0.2665637460691269
ROC train: 0.976018	val: 0.866800	test: 0.863971
PRC train: 0.972195	val: 0.780620	test: 0.808732

Epoch: 117
Loss: 0.2560738631990479
ROC train: 0.980100	val: 0.876586	test: 0.880602
PRC train: 0.976751	val: 0.809391	test: 0.840664

Epoch: 118
Loss: 0.25409229363993674
ROC train: 0.979620	val: 0.870605	test: 0.877801
PRC train: 0.975810	val: 0.783322	test: 0.834916

Epoch: 119
Loss: 0.24928485232698133
ROC train: 0.975722	val: 0.861544	test: 0.869923
PRC train: 0.972113	val: 0.760945	test: 0.817849

Epoch: 120
Loss: 0.26553245489290045
ROC train: 0.975229	val: 0.862450	test: 0.877101
PRC train: 0.970435	val: 0.774132	test: 0.833413

Early stopping
Best (ROC):	 train: 0.947134	val: 0.886553	test: 0.879377
Best (PRC):	 train: 0.937144	val: 0.812161	test: 0.823528

PRC train: 0.943895	val: 0.778329	test: 0.851572

Epoch: 95
Loss: 0.29279274896440605
ROC train: 0.956469	val: 0.808028	test: 0.888828
PRC train: 0.948098	val: 0.774463	test: 0.832509

Epoch: 96
Loss: 0.3145413560577566
ROC train: 0.954260	val: 0.810862	test: 0.892103
PRC train: 0.945594	val: 0.766209	test: 0.831273

Epoch: 97
Loss: 0.3344815046006172
ROC train: 0.952204	val: 0.814797	test: 0.896624
PRC train: 0.942953	val: 0.769630	test: 0.843757

Epoch: 98
Loss: 0.32112359566318677
ROC train: 0.947126	val: 0.806690	test: 0.886567
PRC train: 0.937781	val: 0.763427	test: 0.827892

Epoch: 99
Loss: 0.2989810234859574
ROC train: 0.945912	val: 0.800157	test: 0.876510
PRC train: 0.938024	val: 0.761760	test: 0.817920

Epoch: 100
Loss: 0.307598228075765
ROC train: 0.959907	val: 0.819441	test: 0.888672
PRC train: 0.952664	val: 0.789689	test: 0.830636

Epoch: 101
Loss: 0.30405127706364127
ROC train: 0.960546	val: 0.828965	test: 0.893818
PRC train: 0.952576	val: 0.800625	test: 0.839614

Epoch: 102
Loss: 0.2979964888215073
ROC train: 0.961588	val: 0.825423	test: 0.899899
PRC train: 0.954283	val: 0.785726	test: 0.848478

Epoch: 103
Loss: 0.3085260853200461
ROC train: 0.958740	val: 0.813774	test: 0.892103
PRC train: 0.950071	val: 0.766487	test: 0.833683

Epoch: 104
Loss: 0.32382897571004043
ROC train: 0.959497	val: 0.819599	test: 0.883995
PRC train: 0.950750	val: 0.781239	test: 0.821677

Epoch: 105
Loss: 0.32516408915057105
ROC train: 0.961132	val: 0.834475	test: 0.884540
PRC train: 0.953326	val: 0.808882	test: 0.822870

Epoch: 106
Loss: 0.3010421334570906
ROC train: 0.958517	val: 0.828414	test: 0.892492
PRC train: 0.950197	val: 0.801705	test: 0.833966

Epoch: 107
Loss: 0.3317414112357319
ROC train: 0.957296	val: 0.822039	test: 0.884151
PRC train: 0.950655	val: 0.786423	test: 0.817313

Epoch: 108
Loss: 0.3046006371354272
ROC train: 0.956081	val: 0.809524	test: 0.871287
PRC train: 0.949068	val: 0.769017	test: 0.792824

Epoch: 109
Loss: 0.3043669150425575
ROC train: 0.958792	val: 0.812515	test: 0.875107
PRC train: 0.951521	val: 0.778031	test: 0.797125

Epoch: 110
Loss: 0.3113515653968989
ROC train: 0.960101	val: 0.826210	test: 0.886256
PRC train: 0.952079	val: 0.797823	test: 0.821567

Epoch: 111
Loss: 0.32509011757237716
ROC train: 0.961971	val: 0.838804	test: 0.889452
PRC train: 0.955111	val: 0.808487	test: 0.820439

Epoch: 112
Loss: 0.30404871583718424
ROC train: 0.960246	val: 0.828729	test: 0.885398
PRC train: 0.953763	val: 0.793576	test: 0.813514

Epoch: 113
Loss: 0.3357882138412232
ROC train: 0.962328	val: 0.815348	test: 0.892103
PRC train: 0.955764	val: 0.773657	test: 0.828946

Epoch: 114
Loss: 0.34500817924201077
ROC train: 0.956992	val: 0.806926	test: 0.889062
PRC train: 0.949254	val: 0.769504	test: 0.830538

Epoch: 115
Loss: 0.343918204300741
ROC train: 0.961197	val: 0.818103	test: 0.893272
PRC train: 0.953899	val: 0.786321	test: 0.839958

Epoch: 116
Loss: 0.2877490452498631
ROC train: 0.962192	val: 0.822590	test: 0.893428
PRC train: 0.955967	val: 0.792892	test: 0.839665

Epoch: 117
Loss: 0.30722102668453133
ROC train: 0.963158	val: 0.817001	test: 0.888906
PRC train: 0.957597	val: 0.792250	test: 0.832583

Epoch: 118
Loss: 0.2691927518868774
ROC train: 0.964839	val: 0.813459	test: 0.891089
PRC train: 0.958273	val: 0.784947	test: 0.838435

Epoch: 119
Loss: 0.33241434757843785
ROC train: 0.962323	val: 0.809524	test: 0.886723
PRC train: 0.954979	val: 0.778614	test: 0.826959

Epoch: 120
Loss: 0.3204470505125175
ROC train: 0.961692	val: 0.815112	test: 0.879629
PRC train: 0.953830	val: 0.785799	test: 0.807645

Epoch: 121
Loss: 0.36281375828160306
ROC train: 0.959602	val: 0.830933	test: 0.893272
PRC train: 0.951608	val: 0.808366	test: 0.830427

Epoch: 122
Loss: 0.304111691365218
ROC train: 0.956872	val: 0.806218	test: 0.873080
PRC train: 0.951266	val: 0.780537	test: 0.803396

Epoch: 123
Loss: 0.3410945761995859
ROC train: 0.963503	val: 0.816214	test: 0.887269
PRC train: 0.957200	val: 0.792625	test: 0.822559

Epoch: 124
Loss: 0.2951490231111187
ROC train: 0.961401	val: 0.828886	test: 0.899743
PRC train: 0.952493	val: 0.805947	test: 0.838208

Epoch: 125
Loss: 0.2726008198294735
ROC train: 0.962156	val: 0.833766	test: 0.890543
PRC train: 0.953567	val: 0.808724	test: 0.825722

Epoch: 126
Loss: 0.33455162113452386
ROC train: 0.960367	val: 0.825974	test: 0.884696
PRC train: 0.952007	val: 0.794065	test: 0.818427

Epoch: 127
Loss: 0.30750943182062207
ROC train: 0.961775	val: 0.826682	test: 0.879941
PRC train: 0.954159	val: 0.788669	test: 0.809605

Epoch: 128
Loss: 0.30384122055733315
ROC train: 0.962360	val: 0.819441	test: 0.882358
PRC train: 0.955528	val: 0.777006	test: 0.814566

Epoch: 129
Loss: 0.31057153415873073
ROC train: 0.963382	val: 0.814561	test: 0.886100
PRC train: 0.956968	val: 0.770064	test: 0.819794

Epoch: 130
Loss: 0.3124707292741326
ROC train: 0.967824	val: 0.813538	test: 0.890621
PRC train: 0.962056	val: 0.774876	test: 0.825404

Epoch: 131
Loss: 0.2773753420101196
ROC train: 0.964264	val: 0.815742	test: 0.869572
PRC train: 0.955553	val: 0.779428	test: 0.788232

Epoch: 132
Loss: 0.27449833390253275
ROC train: 0.966782	val: 0.824085	test: 0.884229
PRC train: 0.959695	val: 0.797031	test: 0.818056

Epoch: 133
Loss: 0.2769398239360608
ROC train: 0.967790	val: 0.821251	test: 0.894441
PRC train: 0.961220	val: 0.791306	test: 0.833536

Epoch: 134
Loss: 0.2766109931361943
ROC train: 0.966315	val: 0.809760	test: 0.896780
PRC train: 0.960589	val: 0.763052	test: 0.835492

Epoch: 135
Loss: 0.2758309807341471
ROC train: 0.964577	val: 0.810153	test: 0.891245
PRC train: 0.958219	val: 0.756684	test: 0.828445

Epoch: 136
Loss: 0.2849200139796687
ROC train: 0.968287	val: 0.819520	test: 0.888283
PRC train: 0.963610	val: 0.780610	test: 0.819875

Epoch: 137
Loss: 0.2618997741566299
ROC train: 0.968169	val: 0.819913	test: 0.891245
PRC train: 0.963133	val: 0.791061	test: 0.829551

Epoch: 138
Loss: 0.3060167784552176
ROC train: 0.967123	val: 0.824636	test: 0.892648
PRC train: 0.960830	val: 0.804309	test: 0.832438

Epoch: 139
Loss: 0.2870666679296966
ROC train: 0.969279	val: 0.822117	test: 0.887581
PRC train: 0.963948	val: 0.804826	test: 0.821889

Epoch: 140
Loss: 0.30356691493158333
ROC train: 0.967005	val: 0.816293	test: 0.876043
PRC train: 0.960566	val: 0.794712	test: 0.806864

Epoch: 141
Loss: 0.2975940633266666
ROC train: 0.969257	val: 0.826682	test: 0.881266
PRC train: 0.963051	val: 0.809138	test: 0.814472

Epoch: 142
Loss: 0.278941162531407
ROC train: 0.971330	val: 0.823219	test: 0.885866
PRC train: 0.966874	val: 0.796034	test: 0.819489

Epoch: 143
Loss: 0.27940689085487364
ROC train: 0.968718	val: 0.816844	test: 0.889998
PRC train: 0.963932	val: 0.784979	test: 0.828310

Epoch: 144
Loss: 0.26902334872150474
ROC train: 0.968819	val: 0.818575	test: 0.885944
PRC train: 0.963451	val: 0.780988	test: 0.825347

Epoch: 145
Loss: 0.28277705134825315
ROC train: 0.971750	val: 0.831484	test: 0.889374
PRC train: 0.966852	val: 0.797763	test: 0.828177

Epoch: 146
Loss: 0.28297801999434846
ROC train: 0.967971	val: 0.824479	test: 0.886334
PRC train: 0.963560	val: 0.788233	test: 0.824314

Early stopping
Best (ROC):	 train: 0.961971	val: 0.838804	test: 0.889452
Best (PRC):	 train: 0.955111	val: 0.808487	test: 0.820439

ROC train: 0.961514	val: 0.857557	test: 0.850840
PRC train: 0.955162	val: 0.760276	test: 0.771388

Epoch: 95
Loss: 0.27100634061910367
ROC train: 0.969567	val: 0.859913	test: 0.847164
PRC train: 0.964914	val: 0.762427	test: 0.775646

Epoch: 96
Loss: 0.2843720097054451
ROC train: 0.975007	val: 0.878217	test: 0.876225
PRC train: 0.970397	val: 0.811539	test: 0.814011

Epoch: 97
Loss: 0.2852737522944494
ROC train: 0.972393	val: 0.883472	test: 0.888831
PRC train: 0.967887	val: 0.832255	test: 0.824778

Epoch: 98
Loss: 0.2661282883271814
ROC train: 0.975305	val: 0.883291	test: 0.883403
PRC train: 0.970507	val: 0.820831	test: 0.819313

Epoch: 99
Loss: 0.26933181237378434
ROC train: 0.976205	val: 0.877854	test: 0.883578
PRC train: 0.971336	val: 0.811657	test: 0.823461

Epoch: 100
Loss: 0.2643707900176298
ROC train: 0.975647	val: 0.867706	test: 0.889706
PRC train: 0.971680	val: 0.798769	test: 0.830674

Epoch: 101
Loss: 0.2578921381687036
ROC train: 0.975820	val: 0.861363	test: 0.881828
PRC train: 0.972188	val: 0.787611	test: 0.817612

Epoch: 102
Loss: 0.26305052545405794
ROC train: 0.976260	val: 0.861906	test: 0.866947
PRC train: 0.972842	val: 0.775237	test: 0.802246

Epoch: 103
Loss: 0.26081129339441744
ROC train: 0.977411	val: 0.872599	test: 0.872199
PRC train: 0.973703	val: 0.801929	test: 0.815333

Epoch: 104
Loss: 0.2680800428406837
ROC train: 0.976686	val: 0.880391	test: 0.864846
PRC train: 0.972935	val: 0.808217	test: 0.802338

Epoch: 105
Loss: 0.2615438698940268
ROC train: 0.973761	val: 0.867706	test: 0.852766
PRC train: 0.969692	val: 0.771201	test: 0.793289

Epoch: 106
Loss: 0.27191781193417713
ROC train: 0.976039	val: 0.873686	test: 0.862570
PRC train: 0.971755	val: 0.779249	test: 0.808304

Epoch: 107
Loss: 0.2590207838455468
ROC train: 0.978004	val: 0.891265	test: 0.877976
PRC train: 0.974198	val: 0.822947	test: 0.833450

Epoch: 108
Loss: 0.26827873916939815
ROC train: 0.974683	val: 0.893802	test: 0.870448
PRC train: 0.970929	val: 0.838119	test: 0.817100

Epoch: 109
Loss: 0.25808459660034005
ROC train: 0.979144	val: 0.882747	test: 0.877976
PRC train: 0.975509	val: 0.829752	test: 0.814873

Epoch: 110
Loss: 0.27228384307151077
ROC train: 0.980584	val: 0.882566	test: 0.872549
PRC train: 0.977224	val: 0.815397	test: 0.815790

Epoch: 111
Loss: 0.2729541680499389
ROC train: 0.980247	val: 0.880573	test: 0.872199
PRC train: 0.977208	val: 0.813697	test: 0.813342

Epoch: 112
Loss: 0.24928995356620126
ROC train: 0.979311	val: 0.884016	test: 0.878852
PRC train: 0.975362	val: 0.832092	test: 0.823638

Epoch: 113
Loss: 0.25246991214091263
ROC train: 0.980275	val: 0.883653	test: 0.875875
PRC train: 0.977000	val: 0.813245	test: 0.818325

Epoch: 114
Loss: 0.2639062787529561
ROC train: 0.980174	val: 0.868249	test: 0.876225
PRC train: 0.976650	val: 0.787896	test: 0.815034

Epoch: 115
Loss: 0.25542612265598263
ROC train: 0.981022	val: 0.874592	test: 0.886905
PRC train: 0.977942	val: 0.803369	test: 0.834470

Epoch: 116
Loss: 0.26344516261885254
ROC train: 0.980332	val: 0.886191	test: 0.888130
PRC train: 0.976529	val: 0.814618	test: 0.835074

Epoch: 117
Loss: 0.27961329186369455
ROC train: 0.979679	val: 0.860275	test: 0.875525
PRC train: 0.976225	val: 0.767568	test: 0.816288

Epoch: 118
Loss: 0.24731884086291797
ROC train: 0.980374	val: 0.869337	test: 0.874300
PRC train: 0.977578	val: 0.783958	test: 0.812591

Epoch: 119
Loss: 0.25113637737573774
ROC train: 0.983784	val: 0.876223	test: 0.883228
PRC train: 0.981192	val: 0.812449	test: 0.835073

Epoch: 120
Loss: 0.2512636652366437
ROC train: 0.982769	val: 0.878217	test: 0.872024
PRC train: 0.979605	val: 0.808150	test: 0.820272

Epoch: 121
Loss: 0.22798135212423376
ROC train: 0.983151	val: 0.887822	test: 0.873950
PRC train: 0.980129	val: 0.836712	test: 0.823560

Epoch: 122
Loss: 0.24753279430649483
ROC train: 0.981951	val: 0.883291	test: 0.882878
PRC train: 0.978626	val: 0.826610	test: 0.824608

Epoch: 123
Loss: 0.2384438496845628
ROC train: 0.985510	val: 0.878579	test: 0.869398
PRC train: 0.982991	val: 0.809511	test: 0.807416

Epoch: 124
Loss: 0.2426368081088856
ROC train: 0.983146	val: 0.886734	test: 0.857843
PRC train: 0.980626	val: 0.804878	test: 0.799225

Epoch: 125
Loss: 0.2357469276781811
ROC train: 0.981956	val: 0.876767	test: 0.871499
PRC train: 0.979326	val: 0.802125	test: 0.816842

Epoch: 126
Loss: 0.24755792459925807
ROC train: 0.983368	val: 0.870243	test: 0.871324
PRC train: 0.980414	val: 0.789141	test: 0.815941

Epoch: 127
Loss: 0.23797470789035483
ROC train: 0.980902	val: 0.861725	test: 0.870623
PRC train: 0.978153	val: 0.765130	test: 0.814659

Epoch: 128
Loss: 0.22522238452070673
ROC train: 0.978828	val: 0.866256	test: 0.867822
PRC train: 0.975954	val: 0.772660	test: 0.807037

Epoch: 129
Loss: 0.25681944440839277
ROC train: 0.984763	val: 0.870787	test: 0.873599
PRC train: 0.982163	val: 0.789039	test: 0.816800

Epoch: 130
Loss: 0.23496772365119717
ROC train: 0.986332	val: 0.878760	test: 0.865896
PRC train: 0.984175	val: 0.790489	test: 0.806599

Epoch: 131
Loss: 0.23748948852634308
ROC train: 0.984755	val: 0.881298	test: 0.872199
PRC train: 0.982338	val: 0.793374	test: 0.812645

Epoch: 132
Loss: 0.22525389947725896
ROC train: 0.984719	val: 0.882022	test: 0.879377
PRC train: 0.982276	val: 0.811532	test: 0.818937

Epoch: 133
Loss: 0.23821601108649065
ROC train: 0.984837	val: 0.868974	test: 0.874125
PRC train: 0.982292	val: 0.804366	test: 0.813812

Epoch: 134
Loss: 0.23509514436522294
ROC train: 0.984940	val: 0.866618	test: 0.848915
PRC train: 0.983070	val: 0.793777	test: 0.789195

Epoch: 135
Loss: 0.2288837385874994
ROC train: 0.984975	val: 0.875680	test: 0.861520
PRC train: 0.982678	val: 0.802046	test: 0.800291

Epoch: 136
Loss: 0.21736475386973525
ROC train: 0.986494	val: 0.883653	test: 0.853116
PRC train: 0.984668	val: 0.810562	test: 0.790454

Epoch: 137
Loss: 0.22714528317771024
ROC train: 0.985499	val: 0.877129	test: 0.858894
PRC train: 0.983515	val: 0.813847	test: 0.795436

Epoch: 138
Loss: 0.22344104816551164
ROC train: 0.985373	val: 0.876223	test: 0.876926
PRC train: 0.983193	val: 0.817762	test: 0.823809

Epoch: 139
Loss: 0.24642326711511453
ROC train: 0.984633	val: 0.877854	test: 0.855742
PRC train: 0.982051	val: 0.803443	test: 0.800884

Epoch: 140
Loss: 0.23782835803843297
ROC train: 0.983747	val: 0.882022	test: 0.861695
PRC train: 0.980929	val: 0.812717	test: 0.808712

Epoch: 141
Loss: 0.23635047037331863
ROC train: 0.986911	val: 0.876223	test: 0.860294
PRC train: 0.985039	val: 0.807622	test: 0.806577

Epoch: 142
Loss: 0.2123888979179367
ROC train: 0.987447	val: 0.876586	test: 0.870623
PRC train: 0.985925	val: 0.806486	test: 0.812748

Epoch: 143
Loss: 0.24271067443227556
ROC train: 0.988166	val: 0.873686	test: 0.872024
PRC train: 0.986211	val: 0.811592	test: 0.814295

Early stopping
Best (ROC):	 train: 0.974683	val: 0.893802	test: 0.870448
Best (PRC):	 train: 0.970929	val: 0.838119	test: 0.817100
All runs completed.
All runs completed.
