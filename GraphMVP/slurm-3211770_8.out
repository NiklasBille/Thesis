>>> Starting run for dataset: sider
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running RANDOM configs_static_noise_experiments/GraphCL/sider/noise=0.0.yml on cuda:0
Running RANDOM configs_static_noise_experiments/GraphCL/sider/noise=0.05.yml on cuda:1
Running RANDOM configs_static_noise_experiments/GraphCL/sider/noise=0.1.yml on cuda:2
Running RANDOM configs_static_noise_experiments/GraphCL/sider/noise=0.2.yml on cuda:3
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.0.yml --runseed 4 --device cuda:0
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.05.yml --runseed 4 --device cuda:1
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.2.yml --runseed 4 --device cuda:3
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.0.yml --runseed 5 --device cuda:0
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.05.yml --runseed 5 --device cuda:1
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.2.yml --runseed 5 --device cuda:3
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.0.yml --runseed 6 --device cuda:0
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.05.yml --runseed 6 --device cuda:1
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.2.yml --runseed 6 --device cuda:3
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.1.yml --runseed 4 --device cuda:2
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.1.yml --runseed 5 --device cuda:2
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.1.yml --runseed 6 --device cuda:2
[11:31:04] WARNING: not removing hydrogen atom without neighbors
[11:31:04] WARNING: not removing hydrogen atom without neighbors
[11:31:04] WARNING: not removing hydrogen atom without neighbors
[11:31:04] WARNING: not removing hydrogen atom without neighbors
[11:31:04] WARNING: not removing hydrogen atom without neighbors
[11:31:04] WARNING: not removing hydrogen atom without neighbors
[11:31:04] WARNING: not removing hydrogen atom without neighbors
[11:31:04] WARNING: not removing hydrogen atom without neighbors
[11:31:04] WARNING: not removing hydrogen atom without neighbors
[11:31:04] WARNING: not removing hydrogen atom without neighbors
[11:31:04] WARNING: not removing hydrogen atom without neighbors
[11:31:04] WARNING: not removing hydrogen atom without neighbors
[11:31:04] WARNING: not removing hydrogen atom without neighbors
[11:31:04] WARNING: not removing hydrogen atom without neighbors
[11:31:04] WARNING: not removing hydrogen atom without neighbors
[11:31:04] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:05] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:06] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:07] WARNING: not removing hydrogen atom without neighbors
[11:31:08] WARNING: not removing hydrogen atom without neighbors
[11:31:08] WARNING: not removing hydrogen atom without neighbors
[11:31:08] WARNING: not removing hydrogen atom without neighbors
[11:31:08] WARNING: not removing hydrogen atom without neighbors
[11:31:08] WARNING: not removing hydrogen atom without neighbors
[11:31:08] WARNING: not removing hydrogen atom without neighbors
[11:31:08] WARNING: not removing hydrogen atom without neighbors
[11:31:08] WARNING: not removing hydrogen atom without neighbors
[11:31:08] WARNING: not removing hydrogen atom without neighbors
[11:31:08] WARNING: not removing hydrogen atom without neighbors
[11:31:08] WARNING: not removing hydrogen atom without neighbors
[11:31:08] WARNING: not removing hydrogen atom without neighbors
[11:31:08] WARNING: not removing hydrogen atom without neighbors
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.0.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/sider/noise=0.0
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/sider/noise=0.0/sider_scaff_5_26-05_11-31-03  ]
[ Using Seed :  5  ]
[ Using device :  cuda:0  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6896610549675813
ROC train: 0.538954	val: 0.523652	test: 0.469374
PRC train: 0.585972	val: 0.611558	test: 0.573831

Epoch: 2
Loss: 0.6382306907836411
ROC train: 0.561793	val: 0.506458	test: 0.492737
PRC train: 0.604070	val: 0.602350	test: 0.581230

Epoch: 3
Loss: 0.5971758448472141
ROC train: 0.579417	val: 0.506823	test: 0.502082
PRC train: 0.615463	val: 0.601695	test: 0.587601

Epoch: 4
Loss: 0.5726468561386833
ROC train: 0.605204	val: 0.526877	test: 0.526639
PRC train: 0.629573	val: 0.612029	test: 0.594842

Epoch: 5
Loss: 0.554248517731317
ROC train: 0.628973	val: 0.545238	test: 0.555272
PRC train: 0.644285	val: 0.620991	test: 0.607664

Epoch: 6
Loss: 0.5430177126092619
ROC train: 0.644402	val: 0.558604	test: 0.571466
PRC train: 0.653104	val: 0.627222	test: 0.615936

Epoch: 7
Loss: 0.5310871660780002
ROC train: 0.654268	val: 0.575605	test: 0.580788
PRC train: 0.658892	val: 0.635636	test: 0.619931

Epoch: 8
Loss: 0.52433549920736
ROC train: 0.667569	val: 0.588512	test: 0.586918
PRC train: 0.667821	val: 0.643673	test: 0.622770

Epoch: 9
Loss: 0.5178029327240644
ROC train: 0.677469	val: 0.590532	test: 0.596026
PRC train: 0.672667	val: 0.647605	test: 0.623166

Epoch: 10
Loss: 0.5113908155078234
ROC train: 0.683089	val: 0.600787	test: 0.589529
PRC train: 0.675849	val: 0.650571	test: 0.620582

Epoch: 11
Loss: 0.5028139332615884
ROC train: 0.693961	val: 0.605913	test: 0.605616
PRC train: 0.684878	val: 0.655685	test: 0.627053

Epoch: 12
Loss: 0.49237711985534915
ROC train: 0.697909	val: 0.601693	test: 0.589658
PRC train: 0.690512	val: 0.653170	test: 0.621710

Epoch: 13
Loss: 0.4947559745795161
ROC train: 0.705402	val: 0.596745	test: 0.590008
PRC train: 0.694933	val: 0.649764	test: 0.624128

Epoch: 14
Loss: 0.48335846834463253
ROC train: 0.718538	val: 0.616541	test: 0.599551
PRC train: 0.701998	val: 0.660510	test: 0.627751

Epoch: 15
Loss: 0.48812907047251564
ROC train: 0.724226	val: 0.617489	test: 0.597237
PRC train: 0.706273	val: 0.661169	test: 0.625773

Epoch: 16
Loss: 0.488258353955801
ROC train: 0.724945	val: 0.604836	test: 0.594677
PRC train: 0.708233	val: 0.656284	test: 0.623065

Epoch: 17
Loss: 0.4787813116712011
ROC train: 0.729629	val: 0.614649	test: 0.603768
PRC train: 0.710698	val: 0.664232	test: 0.625040

Epoch: 18
Loss: 0.47546023105100266
ROC train: 0.738350	val: 0.630434	test: 0.608636
PRC train: 0.720695	val: 0.663295	test: 0.628976

Epoch: 19
Loss: 0.47176177228466426
ROC train: 0.743349	val: 0.626883	test: 0.611989
PRC train: 0.724419	val: 0.664529	test: 0.626962

Epoch: 20
Loss: 0.47605124017087286
ROC train: 0.743603	val: 0.619577	test: 0.607413
PRC train: 0.723300	val: 0.662920	test: 0.625397

Epoch: 21
Loss: 0.4671991983546716
ROC train: 0.751245	val: 0.625203	test: 0.604753
PRC train: 0.728871	val: 0.669776	test: 0.626012

Epoch: 22
Loss: 0.466892022663974
ROC train: 0.752238	val: 0.626088	test: 0.603480
PRC train: 0.729748	val: 0.668825	test: 0.623530

Epoch: 23
Loss: 0.46322270798940296
ROC train: 0.754099	val: 0.623416	test: 0.606723
PRC train: 0.727521	val: 0.666996	test: 0.623889

Epoch: 24
Loss: 0.4621235420536884
ROC train: 0.760779	val: 0.630380	test: 0.612175
PRC train: 0.733743	val: 0.667690	test: 0.627250

Epoch: 25
Loss: 0.4570744675311598
ROC train: 0.768880	val: 0.629847	test: 0.608287
PRC train: 0.741518	val: 0.667712	test: 0.624981

Epoch: 26
Loss: 0.46075909917444174
ROC train: 0.768691	val: 0.631066	test: 0.614065
PRC train: 0.743249	val: 0.671183	test: 0.631640

Epoch: 27
Loss: 0.4596343615100669
ROC train: 0.772543	val: 0.638054	test: 0.606466
PRC train: 0.746231	val: 0.677227	test: 0.629210

Epoch: 28
Loss: 0.4535286475827716
ROC train: 0.778625	val: 0.634235	test: 0.602057
PRC train: 0.750637	val: 0.675398	test: 0.629932

Epoch: 29
Loss: 0.459064839702798
ROC train: 0.784066	val: 0.632124	test: 0.594462
PRC train: 0.754448	val: 0.673500	test: 0.622127

Epoch: 30
Loss: 0.4566356639984944
ROC train: 0.785875	val: 0.636008	test: 0.593007
PRC train: 0.755466	val: 0.672805	test: 0.622720

Epoch: 31
Loss: 0.4519703254211899
ROC train: 0.787680	val: 0.631423	test: 0.599882
PRC train: 0.756896	val: 0.666865	test: 0.628346

Epoch: 32
Loss: 0.4505847455743865
ROC train: 0.785845	val: 0.629394	test: 0.602278
PRC train: 0.754617	val: 0.667123	test: 0.626090

Epoch: 33
Loss: 0.4511601506741393
ROC train: 0.789261	val: 0.637433	test: 0.607624Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.0.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/sider/noise=0.0
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/sider/noise=0.0/sider_scaff_4_26-05_11-31-03  ]
[ Using Seed :  4  ]
[ Using device :  cuda:0  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6882702317032028
ROC train: 0.548516	val: 0.504413	test: 0.490896
PRC train: 0.589186	val: 0.607637	test: 0.574543

Epoch: 2
Loss: 0.6368753594586357
ROC train: 0.570913	val: 0.511103	test: 0.508417
PRC train: 0.606921	val: 0.604351	test: 0.583523

Epoch: 3
Loss: 0.5947138954011013
ROC train: 0.573766	val: 0.506870	test: 0.505932
PRC train: 0.612348	val: 0.599832	test: 0.587197

Epoch: 4
Loss: 0.5705785240444798
ROC train: 0.591023	val: 0.514358	test: 0.518957
PRC train: 0.624325	val: 0.608551	test: 0.592010

Epoch: 5
Loss: 0.5565936850075734
ROC train: 0.624573	val: 0.537750	test: 0.556045
PRC train: 0.642940	val: 0.624127	test: 0.607154

Epoch: 6
Loss: 0.5443202438910568
ROC train: 0.641575	val: 0.542750	test: 0.571051
PRC train: 0.649746	val: 0.627796	test: 0.613549

Epoch: 7
Loss: 0.5367753916546315
ROC train: 0.652046	val: 0.553297	test: 0.574415
PRC train: 0.655832	val: 0.638973	test: 0.614390

Epoch: 8
Loss: 0.5218267445453728
ROC train: 0.666093	val: 0.566142	test: 0.580507
PRC train: 0.665056	val: 0.643877	test: 0.615458

Epoch: 9
Loss: 0.5139533679606225
ROC train: 0.675940	val: 0.564519	test: 0.587012
PRC train: 0.672584	val: 0.639760	test: 0.620776

Epoch: 10
Loss: 0.5078309945331763
ROC train: 0.681410	val: 0.557622	test: 0.598201
PRC train: 0.677963	val: 0.635408	test: 0.631654

Epoch: 11
Loss: 0.49911659093584915
ROC train: 0.694925	val: 0.579328	test: 0.598440
PRC train: 0.685747	val: 0.646298	test: 0.626076

Epoch: 12
Loss: 0.4968967389066023
ROC train: 0.702937	val: 0.585868	test: 0.594317
PRC train: 0.690525	val: 0.648403	test: 0.627217

Epoch: 13
Loss: 0.49133547794712856
ROC train: 0.708572	val: 0.585898	test: 0.592360
PRC train: 0.696699	val: 0.646884	test: 0.624977

Epoch: 14
Loss: 0.4857803891977084
ROC train: 0.721442	val: 0.595850	test: 0.595403
PRC train: 0.705258	val: 0.652072	test: 0.625940

Epoch: 15
Loss: 0.4826186377893894
ROC train: 0.723903	val: 0.591847	test: 0.595902
PRC train: 0.706062	val: 0.654648	test: 0.620190

Epoch: 16
Loss: 0.48079849555603127
ROC train: 0.731381	val: 0.589901	test: 0.603152
PRC train: 0.713560	val: 0.654319	test: 0.622994

Epoch: 17
Loss: 0.473029126895519
ROC train: 0.738727	val: 0.592815	test: 0.607238
PRC train: 0.717018	val: 0.652707	test: 0.629327

Epoch: 18
Loss: 0.4719393575575417
ROC train: 0.745271	val: 0.600265	test: 0.604546
PRC train: 0.720448	val: 0.654226	test: 0.628388

Epoch: 19
Loss: 0.4669206872483457
ROC train: 0.750700	val: 0.603998	test: 0.604932
PRC train: 0.726705	val: 0.655208	test: 0.626274

Epoch: 20
Loss: 0.465441722608318
ROC train: 0.756194	val: 0.612225	test: 0.614251
PRC train: 0.731802	val: 0.658692	test: 0.632065

Epoch: 21
Loss: 0.4672446436753753
ROC train: 0.754896	val: 0.612252	test: 0.611321
PRC train: 0.733355	val: 0.656996	test: 0.634306

Epoch: 22
Loss: 0.46175788275621754
ROC train: 0.763365	val: 0.611285	test: 0.610887
PRC train: 0.738250	val: 0.660190	test: 0.637254

Epoch: 23
Loss: 0.46221010476324054
ROC train: 0.768883	val: 0.609183	test: 0.604829
PRC train: 0.741960	val: 0.660670	test: 0.633224

Epoch: 24
Loss: 0.45900833843453287
ROC train: 0.773629	val: 0.614251	test: 0.610156
PRC train: 0.746707	val: 0.662360	test: 0.629056

Epoch: 25
Loss: 0.4527749914006005
ROC train: 0.774287	val: 0.612488	test: 0.613101
PRC train: 0.747825	val: 0.661447	test: 0.631922

Epoch: 26
Loss: 0.4566330502041501
ROC train: 0.774558	val: 0.611259	test: 0.613264
PRC train: 0.748622	val: 0.662476	test: 0.634956

Epoch: 27
Loss: 0.45749816918409214
ROC train: 0.780887	val: 0.622902	test: 0.604506
PRC train: 0.751461	val: 0.668832	test: 0.626632

Epoch: 28
Loss: 0.45093253015095947
ROC train: 0.783370	val: 0.619839	test: 0.597706
PRC train: 0.751951	val: 0.665322	test: 0.624477

Epoch: 29
Loss: 0.451333741970945
ROC train: 0.785240	val: 0.621396	test: 0.591780
PRC train: 0.754123	val: 0.664474	test: 0.627217

Epoch: 30
Loss: 0.4478250474847343
ROC train: 0.789108	val: 0.621864	test: 0.590914
PRC train: 0.757036	val: 0.668250	test: 0.626462

Epoch: 31
Loss: 0.45133614290593227
ROC train: 0.791968	val: 0.620401	test: 0.591268
PRC train: 0.759496	val: 0.669071	test: 0.620845

Epoch: 32
Loss: 0.4458468981190099
ROC train: 0.797944	val: 0.628989	test: 0.589210
PRC train: 0.763430	val: 0.671588	test: 0.620416

Epoch: 33
Loss: 0.4414566081018429
ROC train: 0.792172	val: 0.623414	test: 0.596527Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.0.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/sider/noise=0.0
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/sider/noise=0.0/sider_scaff_6_26-05_11-31-03  ]
[ Using Seed :  6  ]
[ Using device :  cuda:0  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6783314014404448
ROC train: 0.547029	val: 0.515671	test: 0.519508
PRC train: 0.586076	val: 0.603974	test: 0.589475

Epoch: 2
Loss: 0.6317613669509214
ROC train: 0.556379	val: 0.505054	test: 0.501378
PRC train: 0.599270	val: 0.595339	test: 0.585532

Epoch: 3
Loss: 0.5938512764704384
ROC train: 0.564896	val: 0.497150	test: 0.495839
PRC train: 0.609207	val: 0.592346	test: 0.583067

Epoch: 4
Loss: 0.5689032075539449
ROC train: 0.592430	val: 0.518581	test: 0.521515
PRC train: 0.625900	val: 0.604758	test: 0.594359

Epoch: 5
Loss: 0.5528789705964618
ROC train: 0.619940	val: 0.544596	test: 0.549399
PRC train: 0.639622	val: 0.618708	test: 0.605108

Epoch: 6
Loss: 0.5415903497006866
ROC train: 0.640136	val: 0.561450	test: 0.570488
PRC train: 0.650360	val: 0.630476	test: 0.616949

Epoch: 7
Loss: 0.5379114652452833
ROC train: 0.651376	val: 0.568022	test: 0.582023
PRC train: 0.657989	val: 0.632263	test: 0.622018

Epoch: 8
Loss: 0.5225318590629351
ROC train: 0.661675	val: 0.571746	test: 0.588713
PRC train: 0.664351	val: 0.634754	test: 0.626026

Epoch: 9
Loss: 0.5158301869673759
ROC train: 0.671432	val: 0.581056	test: 0.591502
PRC train: 0.671525	val: 0.644159	test: 0.626058

Epoch: 10
Loss: 0.5070935658051023
ROC train: 0.682516	val: 0.592174	test: 0.597494
PRC train: 0.680685	val: 0.645174	test: 0.628936

Epoch: 11
Loss: 0.5001313026242814
ROC train: 0.688915	val: 0.593535	test: 0.600805
PRC train: 0.686284	val: 0.643452	test: 0.628938

Epoch: 12
Loss: 0.49534966393560625
ROC train: 0.698638	val: 0.592491	test: 0.608206
PRC train: 0.693550	val: 0.646202	test: 0.631662

Epoch: 13
Loss: 0.4914292094007056
ROC train: 0.705451	val: 0.594955	test: 0.608296
PRC train: 0.697110	val: 0.646780	test: 0.633267

Epoch: 14
Loss: 0.4917384805475155
ROC train: 0.711713	val: 0.596353	test: 0.616818
PRC train: 0.700693	val: 0.648000	test: 0.632444

Epoch: 15
Loss: 0.4845446002817796
ROC train: 0.716934	val: 0.583501	test: 0.616460
PRC train: 0.704745	val: 0.644106	test: 0.630401

Epoch: 16
Loss: 0.482071637020285
ROC train: 0.724044	val: 0.601563	test: 0.619166
PRC train: 0.711293	val: 0.654238	test: 0.633405

Epoch: 17
Loss: 0.4843459714399344
ROC train: 0.728048	val: 0.615459	test: 0.620101
PRC train: 0.715608	val: 0.657633	test: 0.634378

Epoch: 18
Loss: 0.47543598123505487
ROC train: 0.729622	val: 0.616068	test: 0.621361
PRC train: 0.716929	val: 0.660938	test: 0.632985

Epoch: 19
Loss: 0.47356750096401967
ROC train: 0.736625	val: 0.618538	test: 0.617293
PRC train: 0.721626	val: 0.662371	test: 0.631455

Epoch: 20
Loss: 0.4710834910888019
ROC train: 0.737976	val: 0.613480	test: 0.613408
PRC train: 0.721314	val: 0.656904	test: 0.631100

Epoch: 21
Loss: 0.4707020561755155
ROC train: 0.746395	val: 0.613866	test: 0.616334
PRC train: 0.727858	val: 0.656942	test: 0.629831

Epoch: 22
Loss: 0.46688485403852253
ROC train: 0.755985	val: 0.620160	test: 0.609652
PRC train: 0.731176	val: 0.665737	test: 0.627264

Epoch: 23
Loss: 0.46684322051959615
ROC train: 0.758804	val: 0.620164	test: 0.608952
PRC train: 0.733743	val: 0.659563	test: 0.625490

Epoch: 24
Loss: 0.4596326333165931
ROC train: 0.756047	val: 0.610862	test: 0.608140
PRC train: 0.733008	val: 0.652055	test: 0.625908

Epoch: 25
Loss: 0.4649721160060384
ROC train: 0.763524	val: 0.623312	test: 0.611173
PRC train: 0.739626	val: 0.661114	test: 0.627094

Epoch: 26
Loss: 0.46378825781162425
ROC train: 0.766145	val: 0.623654	test: 0.614556
PRC train: 0.740292	val: 0.664777	test: 0.626543

Epoch: 27
Loss: 0.4631792283701005
ROC train: 0.772040	val: 0.623431	test: 0.621137
PRC train: 0.746453	val: 0.663924	test: 0.629693

Epoch: 28
Loss: 0.4594696780835116
ROC train: 0.775257	val: 0.613771	test: 0.620391
PRC train: 0.748537	val: 0.661089	test: 0.627951

Epoch: 29
Loss: 0.453392626038948
ROC train: 0.776999	val: 0.615755	test: 0.611333
PRC train: 0.750882	val: 0.661852	test: 0.623071

Epoch: 30
Loss: 0.4494805966940101
ROC train: 0.778429	val: 0.621397	test: 0.606078
PRC train: 0.752678	val: 0.660521	test: 0.625394

Epoch: 31
Loss: 0.4521384224813554
ROC train: 0.786803	val: 0.627560	test: 0.604068
PRC train: 0.756200	val: 0.665566	test: 0.625206

Epoch: 32
Loss: 0.4528455029342665
ROC train: 0.780282	val: 0.617570	test: 0.608074
PRC train: 0.751534	val: 0.660835	test: 0.622571

Epoch: 33
Loss: 0.4473010578044132
ROC train: 0.781392	val: 0.613355	test: 0.613054Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.1.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.1
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/sider/noise=0.1
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/sider/noise=0.1/sider_scaff_5_26-05_11-31-03  ]
[ Using Seed :  5  ]
[ Using device :  cuda:2  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6878956418878627
ROC train: 0.542910	val: 0.477336	test: 0.500653
PRC train: 0.587012	val: 0.595606	test: 0.585355

Epoch: 2
Loss: 0.6473882207021908
ROC train: 0.574107	val: 0.499560	test: 0.525215
PRC train: 0.606469	val: 0.600917	test: 0.591889

Epoch: 3
Loss: 0.6130444668910148
ROC train: 0.572178	val: 0.507739	test: 0.519233
PRC train: 0.610266	val: 0.598472	test: 0.589171

Epoch: 4
Loss: 0.581263964916183
ROC train: 0.579015	val: 0.511783	test: 0.515992
PRC train: 0.618404	val: 0.600069	test: 0.589514

Epoch: 5
Loss: 0.5615698852449691
ROC train: 0.601134	val: 0.519553	test: 0.530236
PRC train: 0.632015	val: 0.606551	test: 0.595851

Epoch: 6
Loss: 0.5427808261503898
ROC train: 0.632054	val: 0.535154	test: 0.545912
PRC train: 0.649612	val: 0.611271	test: 0.603891

Epoch: 7
Loss: 0.5355635760193572
ROC train: 0.652372	val: 0.550625	test: 0.560989
PRC train: 0.662697	val: 0.618131	test: 0.612402

Epoch: 8
Loss: 0.5229782950377009
ROC train: 0.665596	val: 0.559446	test: 0.570503
PRC train: 0.671066	val: 0.624478	test: 0.616567

Epoch: 9
Loss: 0.5141797939899948
ROC train: 0.676811	val: 0.557431	test: 0.577910
PRC train: 0.679545	val: 0.625791	test: 0.616036

Epoch: 10
Loss: 0.5053248123814199
ROC train: 0.687496	val: 0.552347	test: 0.577875
PRC train: 0.687841	val: 0.621424	test: 0.616339

Epoch: 11
Loss: 0.5056374856278384
ROC train: 0.696466	val: 0.551915	test: 0.581136
PRC train: 0.693453	val: 0.621912	test: 0.618689

Epoch: 12
Loss: 0.49244689565633015
ROC train: 0.712051	val: 0.550007	test: 0.587134
PRC train: 0.702790	val: 0.626043	test: 0.619907

Epoch: 13
Loss: 0.48854119887909864
ROC train: 0.720990	val: 0.554210	test: 0.585146
PRC train: 0.708601	val: 0.630988	test: 0.617007

Epoch: 14
Loss: 0.4806649450131948
ROC train: 0.728597	val: 0.552302	test: 0.588226
PRC train: 0.716165	val: 0.626588	test: 0.621808

Epoch: 15
Loss: 0.4800951682499372
ROC train: 0.737561	val: 0.555246	test: 0.591758
PRC train: 0.722589	val: 0.629327	test: 0.626215

Epoch: 16
Loss: 0.4741560762429047
ROC train: 0.752484	val: 0.553933	test: 0.595437
PRC train: 0.729328	val: 0.634778	test: 0.624676

Epoch: 17
Loss: 0.47455612643649037
ROC train: 0.759191	val: 0.559988	test: 0.584740
PRC train: 0.732468	val: 0.636681	test: 0.618328

Epoch: 18
Loss: 0.4689156226093528
ROC train: 0.766050	val: 0.562297	test: 0.585157
PRC train: 0.738533	val: 0.631991	test: 0.618964

Epoch: 19
Loss: 0.46379065014354576
ROC train: 0.773137	val: 0.573391	test: 0.586191
PRC train: 0.744744	val: 0.637600	test: 0.618017

Epoch: 20
Loss: 0.46104894687987086
ROC train: 0.780230	val: 0.571232	test: 0.595362
PRC train: 0.750979	val: 0.638773	test: 0.622027

Epoch: 21
Loss: 0.4585396282100028
ROC train: 0.787086	val: 0.567262	test: 0.592865
PRC train: 0.755182	val: 0.636032	test: 0.620373

Epoch: 22
Loss: 0.4504048467310847
ROC train: 0.794734	val: 0.574158	test: 0.584096
PRC train: 0.762274	val: 0.644171	test: 0.616838

Epoch: 23
Loss: 0.4550842525819176
ROC train: 0.796410	val: 0.583985	test: 0.578434
PRC train: 0.763614	val: 0.652537	test: 0.614858

Epoch: 24
Loss: 0.4548376925933934
ROC train: 0.804881	val: 0.572250	test: 0.580977
PRC train: 0.770588	val: 0.644314	test: 0.617646

Epoch: 25
Loss: 0.44829697206411423
ROC train: 0.809046	val: 0.568311	test: 0.576917
PRC train: 0.774247	val: 0.639193	test: 0.614953

Epoch: 26
Loss: 0.44247762883196656
ROC train: 0.815391	val: 0.570431	test: 0.564707
PRC train: 0.777333	val: 0.648226	test: 0.608625

Epoch: 27
Loss: 0.4376796524305521
ROC train: 0.810672	val: 0.569224	test: 0.575779
PRC train: 0.777037	val: 0.644860	test: 0.616513

Epoch: 28
Loss: 0.4353396400848645
ROC train: 0.817362	val: 0.558767	test: 0.576725
PRC train: 0.779931	val: 0.632414	test: 0.617625

Epoch: 29
Loss: 0.43727750073488975
ROC train: 0.821482	val: 0.546532	test: 0.583734
PRC train: 0.781086	val: 0.625566	test: 0.620183

Epoch: 30
Loss: 0.4294814431420605
ROC train: 0.825731	val: 0.535896	test: 0.579671
PRC train: 0.785876	val: 0.619469	test: 0.616485

Epoch: 31
Loss: 0.43053284851568063
ROC train: 0.832169	val: 0.557681	test: 0.578863
PRC train: 0.791868	val: 0.632963	test: 0.616255

Epoch: 32
Loss: 0.4239121060227123
ROC train: 0.835857	val: 0.587119	test: 0.569797Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.05.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.05
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/sider/noise=0.05
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/sider/noise=0.05/sider_scaff_6_26-05_11-31-03  ]
[ Using Seed :  6  ]
[ Using device :  cuda:1  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6860320311270888
ROC train: 0.549990	val: 0.501901	test: 0.521704
PRC train: 0.587672	val: 0.605328	test: 0.593347

Epoch: 2
Loss: 0.6414469042103957
ROC train: 0.568300	val: 0.496253	test: 0.512274
PRC train: 0.602579	val: 0.600434	test: 0.591479

Epoch: 3
Loss: 0.6111290947850966
ROC train: 0.566410	val: 0.498050	test: 0.503322
PRC train: 0.607460	val: 0.602126	test: 0.586304

Epoch: 4
Loss: 0.5814307334853864
ROC train: 0.574664	val: 0.506082	test: 0.499913
PRC train: 0.614888	val: 0.609351	test: 0.583921

Epoch: 5
Loss: 0.5589618701806038
ROC train: 0.605655	val: 0.525220	test: 0.518321
PRC train: 0.630739	val: 0.618118	test: 0.592114

Epoch: 6
Loss: 0.5451839929730771
ROC train: 0.636214	val: 0.551793	test: 0.543711
PRC train: 0.647580	val: 0.629266	test: 0.604938

Epoch: 7
Loss: 0.5345380594188696
ROC train: 0.653681	val: 0.562821	test: 0.563276
PRC train: 0.658199	val: 0.633573	test: 0.613026

Epoch: 8
Loss: 0.5235112095521232
ROC train: 0.665202	val: 0.570417	test: 0.574145
PRC train: 0.666058	val: 0.635085	test: 0.616430

Epoch: 9
Loss: 0.5162119606188524
ROC train: 0.681550	val: 0.579469	test: 0.586855
PRC train: 0.676172	val: 0.637555	test: 0.620679

Epoch: 10
Loss: 0.5054238262413902
ROC train: 0.694378	val: 0.588228	test: 0.583788
PRC train: 0.684228	val: 0.640052	test: 0.620157

Epoch: 11
Loss: 0.503203726559965
ROC train: 0.704837	val: 0.589864	test: 0.583585
PRC train: 0.690510	val: 0.640261	test: 0.619671

Epoch: 12
Loss: 0.4950363537957826
ROC train: 0.716289	val: 0.589367	test: 0.585818
PRC train: 0.698609	val: 0.642021	test: 0.618453

Epoch: 13
Loss: 0.4879828367694875
ROC train: 0.723782	val: 0.592442	test: 0.585083
PRC train: 0.704320	val: 0.644703	test: 0.620002

Epoch: 14
Loss: 0.48896152003226134
ROC train: 0.731321	val: 0.597916	test: 0.589274
PRC train: 0.711962	val: 0.647567	test: 0.623258

Epoch: 15
Loss: 0.47750075467946634
ROC train: 0.738348	val: 0.603767	test: 0.581547
PRC train: 0.718679	val: 0.654295	test: 0.614482

Epoch: 16
Loss: 0.4750748840518271
ROC train: 0.748250	val: 0.601658	test: 0.585763
PRC train: 0.726988	val: 0.650128	test: 0.617425

Epoch: 17
Loss: 0.4716960808411619
ROC train: 0.753464	val: 0.590936	test: 0.586179
PRC train: 0.728743	val: 0.647289	test: 0.617940

Epoch: 18
Loss: 0.4670388633769319
ROC train: 0.765349	val: 0.602198	test: 0.587648
PRC train: 0.739139	val: 0.646512	test: 0.624044

Epoch: 19
Loss: 0.46267887013177544
ROC train: 0.771935	val: 0.613355	test: 0.584807
PRC train: 0.743600	val: 0.651591	test: 0.621038

Epoch: 20
Loss: 0.4625637776418869
ROC train: 0.778075	val: 0.603266	test: 0.593481
PRC train: 0.749442	val: 0.659689	test: 0.620020

Epoch: 21
Loss: 0.4583642005536127
ROC train: 0.782152	val: 0.598613	test: 0.583986
PRC train: 0.749684	val: 0.657995	test: 0.615444

Epoch: 22
Loss: 0.4544116100234675
ROC train: 0.788710	val: 0.604643	test: 0.558212
PRC train: 0.753703	val: 0.656434	test: 0.606133

Epoch: 23
Loss: 0.4535718179240291
ROC train: 0.795644	val: 0.618636	test: 0.567486
PRC train: 0.763840	val: 0.656863	test: 0.609099

Epoch: 24
Loss: 0.4468780363783022
ROC train: 0.802288	val: 0.610526	test: 0.582715
PRC train: 0.768903	val: 0.652888	test: 0.612787

Epoch: 25
Loss: 0.4453889008665852
ROC train: 0.805478	val: 0.598032	test: 0.594110
PRC train: 0.772373	val: 0.649947	test: 0.620451

Epoch: 26
Loss: 0.4465348082917931
ROC train: 0.812009	val: 0.598244	test: 0.584423
PRC train: 0.775869	val: 0.645854	test: 0.619660

Epoch: 27
Loss: 0.44473471136915677
ROC train: 0.815750	val: 0.608460	test: 0.587026
PRC train: 0.780665	val: 0.656497	test: 0.619261

Epoch: 28
Loss: 0.43871131202279595
ROC train: 0.817016	val: 0.610796	test: 0.591684
PRC train: 0.785075	val: 0.664467	test: 0.621631

Epoch: 29
Loss: 0.4329842559566989
ROC train: 0.819968	val: 0.626804	test: 0.582570
PRC train: 0.784288	val: 0.665109	test: 0.619879

Epoch: 30
Loss: 0.4348289588378356
ROC train: 0.824008	val: 0.614394	test: 0.570963
PRC train: 0.787074	val: 0.664399	test: 0.608207

Epoch: 31
Loss: 0.42902795979541075
ROC train: 0.830543	val: 0.602097	test: 0.588794
PRC train: 0.791873	val: 0.652702	test: 0.622183

Epoch: 32
Loss: 0.43155321988279827
ROC train: 0.835436	val: 0.625041	test: 0.587753Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.1.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.1
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/sider/noise=0.1
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/sider/noise=0.1/sider_scaff_4_26-05_11-31-03  ]
[ Using Seed :  4  ]
[ Using device :  cuda:2  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.682893233315426
ROC train: 0.541103	val: 0.514045	test: 0.494503
PRC train: 0.584304	val: 0.602157	test: 0.575449

Epoch: 2
Loss: 0.6399539006729891
ROC train: 0.552726	val: 0.509301	test: 0.502079
PRC train: 0.594677	val: 0.599738	test: 0.585124

Epoch: 3
Loss: 0.604769523183266
ROC train: 0.556315	val: 0.504515	test: 0.512108
PRC train: 0.599947	val: 0.597324	test: 0.590340

Epoch: 4
Loss: 0.575516113479097
ROC train: 0.575383	val: 0.510184	test: 0.524882
PRC train: 0.612812	val: 0.602018	test: 0.594061

Epoch: 5
Loss: 0.5651358720194954
ROC train: 0.604311	val: 0.522625	test: 0.546748
PRC train: 0.627306	val: 0.608265	test: 0.602618

Epoch: 6
Loss: 0.5482833884721663
ROC train: 0.628560	val: 0.531946	test: 0.573870
PRC train: 0.640854	val: 0.614084	test: 0.610549

Epoch: 7
Loss: 0.5352166464388624
ROC train: 0.639717	val: 0.538143	test: 0.582512
PRC train: 0.648506	val: 0.619269	test: 0.614522

Epoch: 8
Loss: 0.5281916432840214
ROC train: 0.649671	val: 0.543970	test: 0.591077
PRC train: 0.655651	val: 0.625807	test: 0.619238

Epoch: 9
Loss: 0.5163930434156153
ROC train: 0.661150	val: 0.560274	test: 0.596000
PRC train: 0.664332	val: 0.633840	test: 0.624402

Epoch: 10
Loss: 0.5099501899225619
ROC train: 0.672063	val: 0.569850	test: 0.601773
PRC train: 0.672989	val: 0.637986	test: 0.627187

Epoch: 11
Loss: 0.4997134686942891
ROC train: 0.684068	val: 0.576360	test: 0.599927
PRC train: 0.682170	val: 0.644443	test: 0.627211

Epoch: 12
Loss: 0.4967657204331827
ROC train: 0.696773	val: 0.581148	test: 0.606179
PRC train: 0.691222	val: 0.650674	test: 0.629108

Epoch: 13
Loss: 0.49491961076876095
ROC train: 0.708771	val: 0.586664	test: 0.614002
PRC train: 0.699212	val: 0.656352	test: 0.631179

Epoch: 14
Loss: 0.4908614603983838
ROC train: 0.718478	val: 0.583920	test: 0.619535
PRC train: 0.705902	val: 0.652106	test: 0.636009

Epoch: 15
Loss: 0.4838537506213771
ROC train: 0.727669	val: 0.581810	test: 0.614484
PRC train: 0.712729	val: 0.646405	test: 0.634435

Epoch: 16
Loss: 0.4775088784284301
ROC train: 0.741867	val: 0.586838	test: 0.618176
PRC train: 0.724175	val: 0.650502	test: 0.640187

Epoch: 17
Loss: 0.478234234337173
ROC train: 0.750758	val: 0.594781	test: 0.621427
PRC train: 0.730202	val: 0.658407	test: 0.639917

Epoch: 18
Loss: 0.46901291289919655
ROC train: 0.760969	val: 0.585142	test: 0.623962
PRC train: 0.737382	val: 0.655520	test: 0.641094

Epoch: 19
Loss: 0.46869571564776435
ROC train: 0.771415	val: 0.582426	test: 0.610385
PRC train: 0.744272	val: 0.651788	test: 0.637481

Epoch: 20
Loss: 0.4653101768116654
ROC train: 0.777769	val: 0.582396	test: 0.596566
PRC train: 0.748080	val: 0.648336	test: 0.634779

Epoch: 21
Loss: 0.46456390588252783
ROC train: 0.780678	val: 0.580911	test: 0.608537
PRC train: 0.751557	val: 0.644151	test: 0.636339

Epoch: 22
Loss: 0.4601727303639274
ROC train: 0.788534	val: 0.577237	test: 0.609851
PRC train: 0.758556	val: 0.641607	test: 0.637410

Epoch: 23
Loss: 0.4545036035261406
ROC train: 0.785930	val: 0.613406	test: 0.610384
PRC train: 0.756885	val: 0.661068	test: 0.637691

Epoch: 24
Loss: 0.45142168368286795
ROC train: 0.801926	val: 0.597722	test: 0.628242
PRC train: 0.768308	val: 0.660922	test: 0.649480

Epoch: 25
Loss: 0.445328124063304
ROC train: 0.792189	val: 0.610630	test: 0.603857
PRC train: 0.763139	val: 0.661621	test: 0.627151

Epoch: 26
Loss: 0.444170200966674
ROC train: 0.793686	val: 0.613329	test: 0.598464
PRC train: 0.761786	val: 0.660932	test: 0.628803

Epoch: 27
Loss: 0.4409361834669959
ROC train: 0.813031	val: 0.605218	test: 0.598767
PRC train: 0.777431	val: 0.656805	test: 0.630966

Epoch: 28
Loss: 0.4380322569742159
ROC train: 0.810931	val: 0.619728	test: 0.603890
PRC train: 0.776595	val: 0.668658	test: 0.635849

Epoch: 29
Loss: 0.43792799484504447
ROC train: 0.822445	val: 0.587330	test: 0.612275
PRC train: 0.787773	val: 0.651517	test: 0.642240

Epoch: 30
Loss: 0.43320150585401385
ROC train: 0.822411	val: 0.590783	test: 0.590065
PRC train: 0.785981	val: 0.655279	test: 0.629333

Epoch: 31
Loss: 0.4262097805572491
ROC train: 0.834044	val: 0.591936	test: 0.587186
PRC train: 0.795480	val: 0.649995	test: 0.625144

Epoch: 32
Loss: 0.4296741644910019
ROC train: 0.839949	val: 0.601725	test: 0.599102Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.05.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.05
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/sider/noise=0.05
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/sider/noise=0.05/sider_scaff_4_26-05_11-31-03  ]
[ Using Seed :  4  ]
[ Using device :  cuda:1  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6829829957783395
ROC train: 0.536372	val: 0.512990	test: 0.496317
PRC train: 0.581619	val: 0.598491	test: 0.571207

Epoch: 2
Loss: 0.6382204064968517
ROC train: 0.554122	val: 0.505519	test: 0.501711
PRC train: 0.595109	val: 0.596568	test: 0.581530

Epoch: 3
Loss: 0.6011345129801728
ROC train: 0.563537	val: 0.504189	test: 0.504954
PRC train: 0.603480	val: 0.598372	test: 0.585368

Epoch: 4
Loss: 0.5735154057374243
ROC train: 0.584233	val: 0.514444	test: 0.519795
PRC train: 0.617521	val: 0.605166	test: 0.591049

Epoch: 5
Loss: 0.564197973587753
ROC train: 0.613177	val: 0.535977	test: 0.542376
PRC train: 0.633972	val: 0.617636	test: 0.601211

Epoch: 6
Loss: 0.5474665152209618
ROC train: 0.635823	val: 0.545341	test: 0.568045
PRC train: 0.649432	val: 0.624310	test: 0.612062

Epoch: 7
Loss: 0.5328554239941654
ROC train: 0.646010	val: 0.551761	test: 0.579916
PRC train: 0.657440	val: 0.629912	test: 0.616826

Epoch: 8
Loss: 0.527526575459585
ROC train: 0.659353	val: 0.559685	test: 0.588083
PRC train: 0.665370	val: 0.635159	test: 0.622632

Epoch: 9
Loss: 0.5158204295880418
ROC train: 0.672990	val: 0.578117	test: 0.593657
PRC train: 0.673745	val: 0.640276	test: 0.629995

Epoch: 10
Loss: 0.5074439563124548
ROC train: 0.685538	val: 0.592935	test: 0.601312
PRC train: 0.679625	val: 0.646707	test: 0.634360

Epoch: 11
Loss: 0.4962566062512823
ROC train: 0.695712	val: 0.600273	test: 0.603295
PRC train: 0.688001	val: 0.652371	test: 0.637461

Epoch: 12
Loss: 0.49561315378623955
ROC train: 0.710378	val: 0.601539	test: 0.611754
PRC train: 0.699956	val: 0.656641	test: 0.638424

Epoch: 13
Loss: 0.49121160578625495
ROC train: 0.718162	val: 0.598522	test: 0.612530
PRC train: 0.703963	val: 0.655336	test: 0.638452

Epoch: 14
Loss: 0.49016636475806186
ROC train: 0.725996	val: 0.598287	test: 0.610339
PRC train: 0.710341	val: 0.652388	test: 0.637964

Epoch: 15
Loss: 0.4839663906002435
ROC train: 0.731142	val: 0.593697	test: 0.602526
PRC train: 0.715732	val: 0.649644	test: 0.637141

Epoch: 16
Loss: 0.47606198445887804
ROC train: 0.746629	val: 0.600334	test: 0.610589
PRC train: 0.724080	val: 0.653712	test: 0.636763

Epoch: 17
Loss: 0.4757936790498902
ROC train: 0.753904	val: 0.611380	test: 0.615989
PRC train: 0.729083	val: 0.660416	test: 0.636885

Epoch: 18
Loss: 0.4699483525385939
ROC train: 0.757236	val: 0.609784	test: 0.618060
PRC train: 0.733643	val: 0.658480	test: 0.639023

Epoch: 19
Loss: 0.46786692797870694
ROC train: 0.765078	val: 0.602916	test: 0.612938
PRC train: 0.737580	val: 0.653996	test: 0.635774

Epoch: 20
Loss: 0.4678705717339917
ROC train: 0.769600	val: 0.602201	test: 0.604124
PRC train: 0.740914	val: 0.654049	test: 0.632561

Epoch: 21
Loss: 0.4613843221096913
ROC train: 0.780705	val: 0.613403	test: 0.616569
PRC train: 0.750713	val: 0.659510	test: 0.636550

Epoch: 22
Loss: 0.45833747013690135
ROC train: 0.785815	val: 0.614082	test: 0.617020
PRC train: 0.756363	val: 0.657873	test: 0.637180

Epoch: 23
Loss: 0.45755952992997795
ROC train: 0.786785	val: 0.614871	test: 0.608992
PRC train: 0.753973	val: 0.656569	test: 0.632430

Epoch: 24
Loss: 0.45831688667358517
ROC train: 0.790441	val: 0.618337	test: 0.609617
PRC train: 0.759900	val: 0.659201	test: 0.633301

Epoch: 25
Loss: 0.45293791939150774
ROC train: 0.794166	val: 0.626534	test: 0.595070
PRC train: 0.761006	val: 0.665848	test: 0.632708

Epoch: 26
Loss: 0.44957221704952505
ROC train: 0.795788	val: 0.617218	test: 0.600778
PRC train: 0.762575	val: 0.662930	test: 0.631120

Epoch: 27
Loss: 0.44795238674569815
ROC train: 0.804601	val: 0.614594	test: 0.600130
PRC train: 0.771515	val: 0.662791	test: 0.629965

Epoch: 28
Loss: 0.4443415278907189
ROC train: 0.807738	val: 0.630016	test: 0.588835
PRC train: 0.772292	val: 0.667790	test: 0.631092

Epoch: 29
Loss: 0.44350179893887837
ROC train: 0.807991	val: 0.619832	test: 0.594108
PRC train: 0.772008	val: 0.664105	test: 0.632550

Epoch: 30
Loss: 0.43632878796592234
ROC train: 0.818040	val: 0.618523	test: 0.600860
PRC train: 0.780128	val: 0.666168	test: 0.632120

Epoch: 31
Loss: 0.43206716106805454
ROC train: 0.822659	val: 0.616230	test: 0.604154
PRC train: 0.782725	val: 0.664683	test: 0.629894

Epoch: 32
Loss: 0.4316005074628978
ROC train: 0.824311	val: 0.623922	test: 0.604016Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.1.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.1
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/sider/noise=0.1
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/sider/noise=0.1/sider_scaff_6_26-05_11-31-03  ]
[ Using Seed :  6  ]
[ Using device :  cuda:2  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6855350171348482
ROC train: 0.540844	val: 0.500915	test: 0.523605
PRC train: 0.584175	val: 0.604455	test: 0.593351

Epoch: 2
Loss: 0.6439897176950679
ROC train: 0.564256	val: 0.500691	test: 0.524472
PRC train: 0.598818	val: 0.605491	test: 0.595992

Epoch: 3
Loss: 0.614688387405506
ROC train: 0.566634	val: 0.495150	test: 0.519518
PRC train: 0.603478	val: 0.600949	test: 0.591036

Epoch: 4
Loss: 0.5833666936009471
ROC train: 0.572243	val: 0.503197	test: 0.515487
PRC train: 0.610964	val: 0.605764	test: 0.588928

Epoch: 5
Loss: 0.56138313448525
ROC train: 0.596491	val: 0.517112	test: 0.534926
PRC train: 0.624216	val: 0.613418	test: 0.596026

Epoch: 6
Loss: 0.5456096089095135
ROC train: 0.626796	val: 0.536323	test: 0.551913
PRC train: 0.640702	val: 0.620456	test: 0.604318

Epoch: 7
Loss: 0.5369176325232775
ROC train: 0.648256	val: 0.544205	test: 0.564782
PRC train: 0.654686	val: 0.621890	test: 0.608863

Epoch: 8
Loss: 0.5261707353858395
ROC train: 0.661835	val: 0.547169	test: 0.571126
PRC train: 0.664149	val: 0.621843	test: 0.611591

Epoch: 9
Loss: 0.5153252282548427
ROC train: 0.673973	val: 0.551879	test: 0.581582
PRC train: 0.671977	val: 0.621857	test: 0.616717

Epoch: 10
Loss: 0.5061183099150783
ROC train: 0.685727	val: 0.562154	test: 0.588380
PRC train: 0.679601	val: 0.625161	test: 0.619869

Epoch: 11
Loss: 0.5023861710733647
ROC train: 0.699950	val: 0.567580	test: 0.586403
PRC train: 0.690460	val: 0.627138	test: 0.619474

Epoch: 12
Loss: 0.4949711943880365
ROC train: 0.713721	val: 0.561644	test: 0.576473
PRC train: 0.699451	val: 0.622992	test: 0.615374

Epoch: 13
Loss: 0.4865384786863548
ROC train: 0.722840	val: 0.554745	test: 0.579079
PRC train: 0.705677	val: 0.619365	test: 0.615215

Epoch: 14
Loss: 0.4917126453140101
ROC train: 0.732470	val: 0.552197	test: 0.584431
PRC train: 0.713307	val: 0.619922	test: 0.626045

Epoch: 15
Loss: 0.47836411962395065
ROC train: 0.744999	val: 0.562995	test: 0.579362
PRC train: 0.722440	val: 0.627545	test: 0.624439

Epoch: 16
Loss: 0.4752921121784991
ROC train: 0.749981	val: 0.557339	test: 0.589125
PRC train: 0.725589	val: 0.624572	test: 0.628758

Epoch: 17
Loss: 0.47445636684739484
ROC train: 0.758594	val: 0.554392	test: 0.581836
PRC train: 0.729838	val: 0.625021	test: 0.621583

Epoch: 18
Loss: 0.4677374416631479
ROC train: 0.766538	val: 0.545611	test: 0.580323
PRC train: 0.735638	val: 0.623592	test: 0.616565

Epoch: 19
Loss: 0.46405421356339877
ROC train: 0.771034	val: 0.554004	test: 0.592325
PRC train: 0.739830	val: 0.622378	test: 0.622934

Epoch: 20
Loss: 0.46576129633459207
ROC train: 0.776618	val: 0.559599	test: 0.587795
PRC train: 0.745068	val: 0.624659	test: 0.621572

Epoch: 21
Loss: 0.46199524054011876
ROC train: 0.783736	val: 0.568087	test: 0.580688
PRC train: 0.750201	val: 0.628804	test: 0.621464

Epoch: 22
Loss: 0.45892178353455054
ROC train: 0.789310	val: 0.576865	test: 0.577485
PRC train: 0.752527	val: 0.636995	test: 0.617878

Epoch: 23
Loss: 0.451149867225871
ROC train: 0.798609	val: 0.583010	test: 0.565028
PRC train: 0.761409	val: 0.643611	test: 0.613794

Epoch: 24
Loss: 0.4419285940085837
ROC train: 0.804604	val: 0.561519	test: 0.563294
PRC train: 0.767728	val: 0.639647	test: 0.611571

Epoch: 25
Loss: 0.44531439252083443
ROC train: 0.814500	val: 0.555052	test: 0.559897
PRC train: 0.776172	val: 0.633460	test: 0.607891

Epoch: 26
Loss: 0.43936106712147505
ROC train: 0.821395	val: 0.544824	test: 0.552684
PRC train: 0.781899	val: 0.626146	test: 0.597335

Epoch: 27
Loss: 0.43755632012352424
ROC train: 0.812758	val: 0.560558	test: 0.548710
PRC train: 0.772835	val: 0.634510	test: 0.596914

Epoch: 28
Loss: 0.43164524838402374
ROC train: 0.807649	val: 0.544666	test: 0.572865
PRC train: 0.763935	val: 0.625933	test: 0.614299

Epoch: 29
Loss: 0.4331834322024357
ROC train: 0.820577	val: 0.546060	test: 0.572170
PRC train: 0.776244	val: 0.628761	test: 0.620882

Epoch: 30
Loss: 0.435232186926273
ROC train: 0.829286	val: 0.552150	test: 0.560995
PRC train: 0.786338	val: 0.632193	test: 0.615247

Epoch: 31
Loss: 0.42841199447584993
ROC train: 0.827740	val: 0.564340	test: 0.576024
PRC train: 0.785772	val: 0.638122	test: 0.626758

Epoch: 32
Loss: 0.42899784128275414
ROC train: 0.838675	val: 0.571164	test: 0.575069Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.2.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:3
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.2
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/sider/noise=0.2
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/sider/noise=0.2/sider_scaff_5_26-05_11-31-03  ]
[ Using Seed :  5  ]
[ Using device :  cuda:3  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6883905815788202
ROC train: 0.536209	val: 0.471741	test: 0.498569
PRC train: 0.581654	val: 0.589140	test: 0.583087

Epoch: 2
Loss: 0.6485858100674043
ROC train: 0.577112	val: 0.477335	test: 0.522758
PRC train: 0.604354	val: 0.586508	test: 0.592938

Epoch: 3
Loss: 0.6166787527275759
ROC train: 0.590275	val: 0.493940	test: 0.531747
PRC train: 0.615218	val: 0.588358	test: 0.594348

Epoch: 4
Loss: 0.5883369780424862
ROC train: 0.592109	val: 0.499374	test: 0.531985
PRC train: 0.620427	val: 0.593787	test: 0.599391

Epoch: 5
Loss: 0.5680312318270362
ROC train: 0.588349	val: 0.509348	test: 0.527995
PRC train: 0.625110	val: 0.601224	test: 0.601816

Epoch: 6
Loss: 0.5473049863844582
ROC train: 0.612791	val: 0.525800	test: 0.535919
PRC train: 0.642376	val: 0.612217	test: 0.606666

Epoch: 7
Loss: 0.5370332714243561
ROC train: 0.636013	val: 0.534701	test: 0.549352
PRC train: 0.653476	val: 0.620821	test: 0.613771

Epoch: 8
Loss: 0.52594027781131
ROC train: 0.657852	val: 0.541232	test: 0.564829
PRC train: 0.664854	val: 0.623049	test: 0.620249

Epoch: 9
Loss: 0.5145876840983078
ROC train: 0.674504	val: 0.541035	test: 0.579316
PRC train: 0.675838	val: 0.620231	test: 0.624735

Epoch: 10
Loss: 0.5033423012530132
ROC train: 0.686494	val: 0.544708	test: 0.584061
PRC train: 0.685864	val: 0.621152	test: 0.627612

Epoch: 11
Loss: 0.5029891326522468
ROC train: 0.698773	val: 0.555342	test: 0.585301
PRC train: 0.695079	val: 0.626033	test: 0.624669

Epoch: 12
Loss: 0.48859134066485443
ROC train: 0.716451	val: 0.559935	test: 0.587629
PRC train: 0.706225	val: 0.632519	test: 0.622786

Epoch: 13
Loss: 0.49064586350502104
ROC train: 0.725810	val: 0.558383	test: 0.593432
PRC train: 0.710266	val: 0.630469	test: 0.625437

Epoch: 14
Loss: 0.4788699342064847
ROC train: 0.738775	val: 0.553867	test: 0.597065
PRC train: 0.723367	val: 0.626759	test: 0.632171

Epoch: 15
Loss: 0.4789465444109552
ROC train: 0.745981	val: 0.554720	test: 0.598588
PRC train: 0.730750	val: 0.631117	test: 0.634060

Epoch: 16
Loss: 0.4708731288514504
ROC train: 0.760236	val: 0.558173	test: 0.595001
PRC train: 0.737953	val: 0.639153	test: 0.632689

Epoch: 17
Loss: 0.47036326777615384
ROC train: 0.770532	val: 0.565504	test: 0.600385
PRC train: 0.745997	val: 0.644024	test: 0.633796

Epoch: 18
Loss: 0.4638801213483196
ROC train: 0.773993	val: 0.563773	test: 0.605060
PRC train: 0.749252	val: 0.640219	test: 0.632261

Epoch: 19
Loss: 0.45854667748001815
ROC train: 0.779206	val: 0.568803	test: 0.599792
PRC train: 0.754343	val: 0.639046	test: 0.624823

Epoch: 20
Loss: 0.45687733295751654
ROC train: 0.786141	val: 0.580531	test: 0.577805
PRC train: 0.757715	val: 0.646921	test: 0.612874

Epoch: 21
Loss: 0.46057770635426215
ROC train: 0.793363	val: 0.585356	test: 0.583052
PRC train: 0.763315	val: 0.651140	test: 0.616532

Epoch: 22
Loss: 0.44874527008289056
ROC train: 0.797546	val: 0.580763	test: 0.594888
PRC train: 0.765151	val: 0.652934	test: 0.623080

Epoch: 23
Loss: 0.44250270172894773
ROC train: 0.803081	val: 0.576072	test: 0.592463
PRC train: 0.766939	val: 0.657703	test: 0.623910

Epoch: 24
Loss: 0.4447551748936408
ROC train: 0.809628	val: 0.584018	test: 0.571155
PRC train: 0.772854	val: 0.658416	test: 0.614519

Epoch: 25
Loss: 0.43903652021780726
ROC train: 0.812824	val: 0.589238	test: 0.559841
PRC train: 0.779225	val: 0.657817	test: 0.601921

Epoch: 26
Loss: 0.43532497587879826
ROC train: 0.818049	val: 0.587749	test: 0.558874
PRC train: 0.781792	val: 0.663072	test: 0.598670

Epoch: 27
Loss: 0.43062223804906585
ROC train: 0.823618	val: 0.592291	test: 0.579856
PRC train: 0.789121	val: 0.659715	test: 0.615837

Epoch: 28
Loss: 0.428170534736423
ROC train: 0.829914	val: 0.591582	test: 0.585180
PRC train: 0.793554	val: 0.660068	test: 0.617885

Epoch: 29
Loss: 0.42829262350222636
ROC train: 0.831481	val: 0.591641	test: 0.593683
PRC train: 0.796150	val: 0.655122	test: 0.621828

Epoch: 30
Loss: 0.4190193252186562
ROC train: 0.837798	val: 0.591893	test: 0.590002
PRC train: 0.798671	val: 0.657919	test: 0.621567

Epoch: 31
Loss: 0.4175332377099483
ROC train: 0.840063	val: 0.594293	test: 0.589434
PRC train: 0.800028	val: 0.661589	test: 0.625572

Epoch: 32
Loss: 0.41797043440480497
ROC train: 0.841528	val: 0.587656	test: 0.575851Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.2.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:3
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.2
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/sider/noise=0.2
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/sider/noise=0.2/sider_scaff_4_26-05_11-31-03  ]
[ Using Seed :  4  ]
[ Using device :  cuda:3  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6836461189229937
ROC train: 0.542664	val: 0.504976	test: 0.488193
PRC train: 0.580187	val: 0.599240	test: 0.568964

Epoch: 2
Loss: 0.6441711165951015
ROC train: 0.568522	val: 0.511137	test: 0.507590
PRC train: 0.596973	val: 0.594750	test: 0.585860

Epoch: 3
Loss: 0.6121204784176382
ROC train: 0.571259	val: 0.503990	test: 0.515913
PRC train: 0.604772	val: 0.594111	test: 0.592662

Epoch: 4
Loss: 0.5835347492501992
ROC train: 0.580063	val: 0.508230	test: 0.520625
PRC train: 0.613011	val: 0.598472	test: 0.592314

Epoch: 5
Loss: 0.5671000874001914
ROC train: 0.600808	val: 0.520291	test: 0.533815
PRC train: 0.625689	val: 0.606796	test: 0.599890

Epoch: 6
Loss: 0.5526003317350774
ROC train: 0.623590	val: 0.533215	test: 0.547785
PRC train: 0.638487	val: 0.613840	test: 0.605240

Epoch: 7
Loss: 0.5359522844615544
ROC train: 0.640387	val: 0.545657	test: 0.562546
PRC train: 0.651119	val: 0.620012	test: 0.611933

Epoch: 8
Loss: 0.5275433283845976
ROC train: 0.651811	val: 0.548920	test: 0.568047
PRC train: 0.660907	val: 0.623391	test: 0.618208

Epoch: 9
Loss: 0.5162257086439526
ROC train: 0.662449	val: 0.553748	test: 0.571375
PRC train: 0.667372	val: 0.628031	test: 0.619911

Epoch: 10
Loss: 0.5088797875757328
ROC train: 0.675922	val: 0.564656	test: 0.563984
PRC train: 0.677746	val: 0.633295	test: 0.613548

Epoch: 11
Loss: 0.5022069159885856
ROC train: 0.685778	val: 0.558267	test: 0.555092
PRC train: 0.685971	val: 0.632570	test: 0.608625

Epoch: 12
Loss: 0.49888731440476874
ROC train: 0.699611	val: 0.558627	test: 0.553490
PRC train: 0.697466	val: 0.635115	test: 0.606642

Epoch: 13
Loss: 0.4931517678097771
ROC train: 0.713458	val: 0.551675	test: 0.557416
PRC train: 0.708357	val: 0.633165	test: 0.608089

Epoch: 14
Loss: 0.48900054901585044
ROC train: 0.722696	val: 0.545373	test: 0.566258
PRC train: 0.714685	val: 0.629445	test: 0.610896

Epoch: 15
Loss: 0.4848291746511662
ROC train: 0.732369	val: 0.543505	test: 0.566013
PRC train: 0.722925	val: 0.628471	test: 0.611076

Epoch: 16
Loss: 0.4771774831793908
ROC train: 0.742849	val: 0.545270	test: 0.565550
PRC train: 0.731348	val: 0.628757	test: 0.610026

Epoch: 17
Loss: 0.47666382656153183
ROC train: 0.752111	val: 0.540998	test: 0.553938
PRC train: 0.736681	val: 0.627263	test: 0.604955

Epoch: 18
Loss: 0.4709407676508823
ROC train: 0.761416	val: 0.533279	test: 0.563362
PRC train: 0.740911	val: 0.621548	test: 0.607966

Epoch: 19
Loss: 0.467850230570254
ROC train: 0.767917	val: 0.508387	test: 0.575330
PRC train: 0.744753	val: 0.612290	test: 0.614261

Epoch: 20
Loss: 0.46221894782090855
ROC train: 0.776391	val: 0.502940	test: 0.573152
PRC train: 0.751759	val: 0.606892	test: 0.615011

Epoch: 21
Loss: 0.4586376344283364
ROC train: 0.783236	val: 0.526108	test: 0.562439
PRC train: 0.757792	val: 0.619960	test: 0.608276

Epoch: 22
Loss: 0.45695730545188207
ROC train: 0.790106	val: 0.533361	test: 0.545977
PRC train: 0.762309	val: 0.624846	test: 0.598528

Epoch: 23
Loss: 0.45174851345011635
ROC train: 0.790455	val: 0.528732	test: 0.543144
PRC train: 0.760545	val: 0.625785	test: 0.595418

Epoch: 24
Loss: 0.45240958257202085
ROC train: 0.799546	val: 0.526466	test: 0.550915
PRC train: 0.767899	val: 0.624315	test: 0.601639

Epoch: 25
Loss: 0.44295190886000313
ROC train: 0.804073	val: 0.527491	test: 0.541761
PRC train: 0.771560	val: 0.624736	test: 0.598450

Epoch: 26
Loss: 0.43769645450829275
ROC train: 0.809353	val: 0.523246	test: 0.544444
PRC train: 0.775681	val: 0.620850	test: 0.598264

Epoch: 27
Loss: 0.4382019472069807
ROC train: 0.816285	val: 0.534425	test: 0.550418
PRC train: 0.783180	val: 0.625208	test: 0.599117

Epoch: 28
Loss: 0.4367774726889178
ROC train: 0.823989	val: 0.543789	test: 0.540084
PRC train: 0.787894	val: 0.631662	test: 0.593995

Epoch: 29
Loss: 0.431973912023091
ROC train: 0.828307	val: 0.540421	test: 0.524927
PRC train: 0.792126	val: 0.625575	test: 0.588571

Epoch: 30
Loss: 0.42377646781624456
ROC train: 0.829919	val: 0.531478	test: 0.546122
PRC train: 0.792254	val: 0.622300	test: 0.600089

Epoch: 31
Loss: 0.42692171346496
ROC train: 0.827543	val: 0.534729	test: 0.558728
PRC train: 0.789812	val: 0.624868	test: 0.608851

Epoch: 32
Loss: 0.420720210457384
ROC train: 0.830967	val: 0.525746	test: 0.552538Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.05.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.05
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/sider/noise=0.05
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/sider/noise=0.05/sider_scaff_5_26-05_11-31-03  ]
[ Using Seed :  5  ]
[ Using device :  cuda:1  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6880017101446974
ROC train: 0.547997	val: 0.479517	test: 0.502474
PRC train: 0.587495	val: 0.599373	test: 0.584477

Epoch: 2
Loss: 0.6452417080016971
ROC train: 0.571446	val: 0.505036	test: 0.521947
PRC train: 0.604959	val: 0.599777	test: 0.588412

Epoch: 3
Loss: 0.6091107519971215
ROC train: 0.574778	val: 0.503779	test: 0.511307
PRC train: 0.610015	val: 0.600583	test: 0.586730

Epoch: 4
Loss: 0.5754615500259604
ROC train: 0.587069	val: 0.513753	test: 0.510122
PRC train: 0.620069	val: 0.606786	test: 0.588947

Epoch: 5
Loss: 0.5570582614806912
ROC train: 0.611541	val: 0.528447	test: 0.526282
PRC train: 0.634910	val: 0.617067	test: 0.596506

Epoch: 6
Loss: 0.5404178928500123
ROC train: 0.635781	val: 0.545841	test: 0.553318
PRC train: 0.646740	val: 0.627210	test: 0.607887

Epoch: 7
Loss: 0.5356926965713726
ROC train: 0.650658	val: 0.553396	test: 0.566499
PRC train: 0.657554	val: 0.634843	test: 0.613352

Epoch: 8
Loss: 0.5233518926111373
ROC train: 0.666569	val: 0.565649	test: 0.578375
PRC train: 0.667788	val: 0.638287	test: 0.619017

Epoch: 9
Loss: 0.5143381918101858
ROC train: 0.679238	val: 0.567699	test: 0.581656
PRC train: 0.678349	val: 0.637095	test: 0.620450

Epoch: 10
Loss: 0.5030882815122361
ROC train: 0.691090	val: 0.568242	test: 0.585306
PRC train: 0.686155	val: 0.634840	test: 0.623058

Epoch: 11
Loss: 0.5029161677425161
ROC train: 0.701335	val: 0.566920	test: 0.592581
PRC train: 0.692958	val: 0.636210	test: 0.625638

Epoch: 12
Loss: 0.4916315840104257
ROC train: 0.708552	val: 0.559694	test: 0.597840
PRC train: 0.696662	val: 0.638183	test: 0.625135

Epoch: 13
Loss: 0.49112517268620814
ROC train: 0.719122	val: 0.571151	test: 0.593452
PRC train: 0.705741	val: 0.640626	test: 0.622064

Epoch: 14
Loss: 0.4829762050108314
ROC train: 0.727629	val: 0.575117	test: 0.594406
PRC train: 0.713747	val: 0.637455	test: 0.623811

Epoch: 15
Loss: 0.4813560448218369
ROC train: 0.739695	val: 0.582410	test: 0.602117
PRC train: 0.719362	val: 0.643345	test: 0.629003

Epoch: 16
Loss: 0.4750559190989832
ROC train: 0.746768	val: 0.574343	test: 0.601407
PRC train: 0.724014	val: 0.644067	test: 0.625692

Epoch: 17
Loss: 0.4724731076601791
ROC train: 0.756809	val: 0.576866	test: 0.595161
PRC train: 0.732776	val: 0.644768	test: 0.622025

Epoch: 18
Loss: 0.4679000759501545
ROC train: 0.762495	val: 0.585369	test: 0.597551
PRC train: 0.738171	val: 0.648097	test: 0.621085

Epoch: 19
Loss: 0.46367559539466985
ROC train: 0.768071	val: 0.595606	test: 0.600973
PRC train: 0.740534	val: 0.652949	test: 0.622926

Epoch: 20
Loss: 0.4608350795396915
ROC train: 0.774448	val: 0.597318	test: 0.600466
PRC train: 0.744687	val: 0.656901	test: 0.626392

Epoch: 21
Loss: 0.4579294806019563
ROC train: 0.782857	val: 0.591269	test: 0.604937
PRC train: 0.749997	val: 0.652685	test: 0.630748

Epoch: 22
Loss: 0.45265529312668845
ROC train: 0.792886	val: 0.594383	test: 0.599065
PRC train: 0.758257	val: 0.654029	test: 0.625224

Epoch: 23
Loss: 0.4522055882891306
ROC train: 0.795023	val: 0.592986	test: 0.598441
PRC train: 0.759480	val: 0.654001	test: 0.621936

Epoch: 24
Loss: 0.45665976792147117
ROC train: 0.799502	val: 0.588381	test: 0.596038
PRC train: 0.764472	val: 0.654839	test: 0.620389

Epoch: 25
Loss: 0.45041880633193926
ROC train: 0.808395	val: 0.608520	test: 0.587697
PRC train: 0.769167	val: 0.663206	test: 0.617382

Epoch: 26
Loss: 0.44888452119296074
ROC train: 0.801737	val: 0.612819	test: 0.593069
PRC train: 0.764819	val: 0.670776	test: 0.622346

Epoch: 27
Loss: 0.4376999854462345
ROC train: 0.800839	val: 0.600922	test: 0.608753
PRC train: 0.769389	val: 0.660973	test: 0.629947

Epoch: 28
Loss: 0.43828458099332435
ROC train: 0.812650	val: 0.599165	test: 0.597884
PRC train: 0.776605	val: 0.660710	test: 0.620695

Epoch: 29
Loss: 0.4418593732512598
ROC train: 0.819600	val: 0.598360	test: 0.596014
PRC train: 0.782811	val: 0.656102	test: 0.620646

Epoch: 30
Loss: 0.43403079998884986
ROC train: 0.822671	val: 0.592541	test: 0.598352
PRC train: 0.785424	val: 0.650708	test: 0.628894

Epoch: 31
Loss: 0.43220024696590215
ROC train: 0.824954	val: 0.598261	test: 0.601583
PRC train: 0.788894	val: 0.659744	test: 0.629747

Epoch: 32
Loss: 0.4298170251097887
ROC train: 0.824761	val: 0.600199	test: 0.604658Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/sider/noise=0.2.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:3
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.2
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/sider/noise=0.2
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/sider/noise=0.2/sider_scaff_6_26-05_11-31-03  ]
[ Using Seed :  6  ]
[ Using device :  cuda:3  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6846996316592758
ROC train: 0.538406	val: 0.497123	test: 0.521794
PRC train: 0.584466	val: 0.602908	test: 0.590811

Epoch: 2
Loss: 0.6449296583362456
ROC train: 0.555078	val: 0.500193	test: 0.512706
PRC train: 0.596413	val: 0.605408	test: 0.588468

Epoch: 3
Loss: 0.6171320358783345
ROC train: 0.559833	val: 0.504493	test: 0.520807
PRC train: 0.602149	val: 0.602903	test: 0.590210

Epoch: 4
Loss: 0.5884449814752427
ROC train: 0.560538	val: 0.512492	test: 0.514461
PRC train: 0.607254	val: 0.607059	test: 0.587775

Epoch: 5
Loss: 0.5702287758643287
ROC train: 0.573833	val: 0.517812	test: 0.515784
PRC train: 0.617399	val: 0.611896	test: 0.591629

Epoch: 6
Loss: 0.5523462865913881
ROC train: 0.604026	val: 0.529811	test: 0.529716
PRC train: 0.633387	val: 0.616766	test: 0.597628

Epoch: 7
Loss: 0.5398856192459024
ROC train: 0.631316	val: 0.532788	test: 0.549302
PRC train: 0.648029	val: 0.613470	test: 0.603364

Epoch: 8
Loss: 0.5281555678130401
ROC train: 0.644254	val: 0.535037	test: 0.555885
PRC train: 0.656511	val: 0.610662	test: 0.605070

Epoch: 9
Loss: 0.5193293468623127
ROC train: 0.656974	val: 0.543357	test: 0.561011
PRC train: 0.665513	val: 0.614323	test: 0.608835

Epoch: 10
Loss: 0.5111708817304311
ROC train: 0.670514	val: 0.548577	test: 0.572626
PRC train: 0.674534	val: 0.615414	test: 0.612809

Epoch: 11
Loss: 0.5049604665529694
ROC train: 0.684556	val: 0.554907	test: 0.582778
PRC train: 0.684852	val: 0.616816	test: 0.614961

Epoch: 12
Loss: 0.5003637257984507
ROC train: 0.700579	val: 0.561345	test: 0.583413
PRC train: 0.697064	val: 0.619386	test: 0.617502

Epoch: 13
Loss: 0.49369892471654675
ROC train: 0.715303	val: 0.562830	test: 0.583630
PRC train: 0.706108	val: 0.619917	test: 0.616580

Epoch: 14
Loss: 0.4964559497946947
ROC train: 0.725953	val: 0.554889	test: 0.588092
PRC train: 0.713816	val: 0.617183	test: 0.616352

Epoch: 15
Loss: 0.48299356425066253
ROC train: 0.732158	val: 0.549538	test: 0.594679
PRC train: 0.716172	val: 0.615352	test: 0.616056

Epoch: 16
Loss: 0.4779813617003675
ROC train: 0.746129	val: 0.552112	test: 0.588296
PRC train: 0.727628	val: 0.617476	test: 0.614840

Epoch: 17
Loss: 0.47918001488147316
ROC train: 0.758001	val: 0.549793	test: 0.585023
PRC train: 0.736002	val: 0.621004	test: 0.616148

Epoch: 18
Loss: 0.4707501800924021
ROC train: 0.766980	val: 0.548145	test: 0.584101
PRC train: 0.745114	val: 0.624635	test: 0.616101

Epoch: 19
Loss: 0.47141493691790987
ROC train: 0.773993	val: 0.558128	test: 0.589908
PRC train: 0.751024	val: 0.625383	test: 0.617152

Epoch: 20
Loss: 0.46026227685809495
ROC train: 0.782049	val: 0.549847	test: 0.578539
PRC train: 0.758997	val: 0.623917	test: 0.613921

Epoch: 21
Loss: 0.46194229164775064
ROC train: 0.790279	val: 0.543421	test: 0.585773
PRC train: 0.765204	val: 0.622695	test: 0.615410

Epoch: 22
Loss: 0.4559638169291613
ROC train: 0.790403	val: 0.536783	test: 0.587491
PRC train: 0.764561	val: 0.623517	test: 0.615898

Epoch: 23
Loss: 0.449930751168255
ROC train: 0.797580	val: 0.530969	test: 0.576191
PRC train: 0.767208	val: 0.617228	test: 0.614183

Epoch: 24
Loss: 0.4429002518983105
ROC train: 0.808818	val: 0.532705	test: 0.549279
PRC train: 0.777548	val: 0.620783	test: 0.605484

Epoch: 25
Loss: 0.45044946258140806
ROC train: 0.812857	val: 0.555602	test: 0.562610
PRC train: 0.781253	val: 0.629903	test: 0.608175

Epoch: 26
Loss: 0.4415999402107419
ROC train: 0.811332	val: 0.551405	test: 0.560794
PRC train: 0.779393	val: 0.627989	test: 0.607267

Epoch: 27
Loss: 0.44000746484329306
ROC train: 0.820333	val: 0.565594	test: 0.558673
PRC train: 0.785471	val: 0.637089	test: 0.608390

Epoch: 28
Loss: 0.43949025097075867
ROC train: 0.827928	val: 0.552437	test: 0.563810
PRC train: 0.792696	val: 0.631462	test: 0.606731

Epoch: 29
Loss: 0.4312156330475897
ROC train: 0.828558	val: 0.547554	test: 0.557856
PRC train: 0.794102	val: 0.627879	test: 0.605512

Epoch: 30
Loss: 0.4249224445099344
ROC train: 0.831550	val: 0.557718	test: 0.555026
PRC train: 0.797008	val: 0.634978	test: 0.606129

Epoch: 31
Loss: 0.4268374949502155
ROC train: 0.837084	val: 0.562670	test: 0.556656
PRC train: 0.801177	val: 0.637075	test: 0.608420

Epoch: 32
Loss: 0.41916412272594367
ROC train: 0.838795	val: 0.576758	test: 0.540613
PRC train: 0.758628	val: 0.669097	test: 0.629561

Epoch: 34
Loss: 0.445259127075988
ROC train: 0.795621	val: 0.630358	test: 0.599225
PRC train: 0.764200	val: 0.668495	test: 0.626391

Epoch: 35
Loss: 0.4443328504341609
ROC train: 0.797034	val: 0.633697	test: 0.587533
PRC train: 0.766311	val: 0.673171	test: 0.624907

Epoch: 36
Loss: 0.44251862344514403
ROC train: 0.797306	val: 0.629140	test: 0.595234
PRC train: 0.767079	val: 0.670880	test: 0.625449

Epoch: 37
Loss: 0.44009758639134294
ROC train: 0.802168	val: 0.630466	test: 0.595494
PRC train: 0.770495	val: 0.666857	test: 0.628070

Epoch: 38
Loss: 0.44603121894156406
ROC train: 0.805566	val: 0.628589	test: 0.596877
PRC train: 0.772404	val: 0.663317	test: 0.631355

Epoch: 39
Loss: 0.44190641070410297
ROC train: 0.809207	val: 0.645167	test: 0.597767
PRC train: 0.775491	val: 0.675506	test: 0.630269

Epoch: 40
Loss: 0.43601679780387653
ROC train: 0.810530	val: 0.640486	test: 0.602268
PRC train: 0.779579	val: 0.673265	test: 0.632720

Epoch: 41
Loss: 0.4345676907105827
ROC train: 0.813479	val: 0.636466	test: 0.583956
PRC train: 0.781519	val: 0.674229	test: 0.622871

Epoch: 42
Loss: 0.4381822282359247
ROC train: 0.814825	val: 0.631510	test: 0.580543
PRC train: 0.781706	val: 0.669713	test: 0.618574

Epoch: 43
Loss: 0.4331385494470556
ROC train: 0.812449	val: 0.621196	test: 0.595709
PRC train: 0.779310	val: 0.664486	test: 0.623668

Epoch: 44
Loss: 0.4278975562879287
ROC train: 0.817708	val: 0.633627	test: 0.602487
PRC train: 0.784541	val: 0.669573	test: 0.628733

Epoch: 45
Loss: 0.43261016253026935
ROC train: 0.820987	val: 0.638030	test: 0.600422
PRC train: 0.787776	val: 0.675099	test: 0.627705

Epoch: 46
Loss: 0.43005682481617435
ROC train: 0.823374	val: 0.632824	test: 0.593960
PRC train: 0.788733	val: 0.675443	test: 0.624873

Epoch: 47
Loss: 0.42667041560514274
ROC train: 0.823442	val: 0.638269	test: 0.599611
PRC train: 0.788477	val: 0.677243	test: 0.629727

Epoch: 48
Loss: 0.42490020628699565
ROC train: 0.825720	val: 0.634824	test: 0.596362
PRC train: 0.790674	val: 0.671783	test: 0.628493

Epoch: 49
Loss: 0.4264111543161702
ROC train: 0.826699	val: 0.636535	test: 0.584579
PRC train: 0.791619	val: 0.674843	test: 0.618774

Epoch: 50
Loss: 0.42754203661350143
ROC train: 0.830201	val: 0.635899	test: 0.591861
PRC train: 0.795550	val: 0.677636	test: 0.621907

Epoch: 51
Loss: 0.4178230455524755
ROC train: 0.831881	val: 0.631601	test: 0.602950
PRC train: 0.795844	val: 0.672662	test: 0.628298

Epoch: 52
Loss: 0.42144110728784945
ROC train: 0.837715	val: 0.629276	test: 0.600079
PRC train: 0.801288	val: 0.676110	test: 0.626827

Epoch: 53
Loss: 0.42440293349146785
ROC train: 0.838693	val: 0.624686	test: 0.586565
PRC train: 0.801784	val: 0.674815	test: 0.623120

Epoch: 54
Loss: 0.42325080514570523
ROC train: 0.832906	val: 0.613867	test: 0.583927
PRC train: 0.798988	val: 0.671340	test: 0.622273

Epoch: 55
Loss: 0.420362614852273
ROC train: 0.837982	val: 0.632429	test: 0.583458
PRC train: 0.801906	val: 0.677908	test: 0.623398

Epoch: 56
Loss: 0.41732784666828626
ROC train: 0.841729	val: 0.638682	test: 0.578734
PRC train: 0.804289	val: 0.678599	test: 0.621840

Epoch: 57
Loss: 0.419946627377353
ROC train: 0.836117	val: 0.634621	test: 0.569517
PRC train: 0.800523	val: 0.683190	test: 0.614100

Epoch: 58
Loss: 0.41465087696519304
ROC train: 0.842022	val: 0.614818	test: 0.590750
PRC train: 0.807453	val: 0.672841	test: 0.625265

Epoch: 59
Loss: 0.4176877992047475
ROC train: 0.844870	val: 0.610244	test: 0.594832
PRC train: 0.809043	val: 0.661800	test: 0.626341

Epoch: 60
Loss: 0.4111519738242029
ROC train: 0.845421	val: 0.610402	test: 0.594980
PRC train: 0.809181	val: 0.665484	test: 0.623908

Epoch: 61
Loss: 0.4090816775368092
ROC train: 0.853073	val: 0.626942	test: 0.589584
PRC train: 0.814177	val: 0.671488	test: 0.620543

Epoch: 62
Loss: 0.40483963857307215
ROC train: 0.854694	val: 0.638072	test: 0.584537
PRC train: 0.815074	val: 0.674502	test: 0.621930

Epoch: 63
Loss: 0.40790010300469176
ROC train: 0.852041	val: 0.644174	test: 0.593398
PRC train: 0.813952	val: 0.681105	test: 0.629662

Epoch: 64
Loss: 0.4068686803966607
ROC train: 0.854711	val: 0.637441	test: 0.603569
PRC train: 0.817437	val: 0.673867	test: 0.634445

Epoch: 65
Loss: 0.4049511874684505
ROC train: 0.855692	val: 0.635796	test: 0.578943
PRC train: 0.815497	val: 0.675764	test: 0.625875

Epoch: 66
Loss: 0.40441782948739435
ROC train: 0.859814	val: 0.631527	test: 0.570164
PRC train: 0.820568	val: 0.676599	test: 0.621799

Epoch: 67
Loss: 0.401465081161004
ROC train: 0.863437	val: 0.638096	test: 0.580336
PRC train: 0.824984	val: 0.678814	test: 0.627796

Epoch: 68
Loss: 0.3954872876442691
ROC train: 0.863657	val: 0.632574	test: 0.596847
PRC train: 0.824574	val: 0.675753	test: 0.634205

Epoch: 69
Loss: 0.3945185956243519
ROC train: 0.864515	val: 0.628501	test: 0.599069
PRC train: 0.826483	val: 0.676893	test: 0.632452

Epoch: 70
Loss: 0.39151395044809945
ROC train: 0.865368	val: 0.616749	test: 0.587005
PRC train: 0.826121	val: 0.673697	test: 0.624922

Epoch: 71
Loss: 0.39450470814961924
ROC train: 0.867357	val: 0.625211	test: 0.587768
PRC train: 0.828997	val: 0.676265	test: 0.624850

Epoch: 72
Loss: 0.38938828568802847
ROC train: 0.867797	val: 0.627578	test: 0.590306
PRC train: 0.829178	val: 0.673382	test: 0.623464

Epoch: 73
Loss: 0.3849760253311
ROC train: 0.869654	val: 0.627838	test: 0.600918
PRC train: 0.833204	val: 0.673813	test: 0.628234

Epoch: 74
Loss: 0.3884531344300102
ROC train: 0.867095	val: 0.615819	test: 0.590249
PRC train: 0.829756	val: 0.668681	test: 0.621130

Epoch: 75
Loss: 0.3852678618292415
ROC train: 0.871713	val: 0.611526	test: 0.595387
PRC train: 0.833342	val: 0.664041	test: 0.627159

Epoch: 76
Loss: 0.3835371632043243
ROC train: 0.877198	val: 0.626044	test: 0.587456
PRC train: 0.838222	val: 0.673387	test: 0.623150

Epoch: 77
Loss: 0.3886307826432484
ROC train: 0.875179	val: 0.625112	test: 0.587629
PRC train: 0.838012	val: 0.674177	test: 0.625544

Epoch: 78
Loss: 0.38618404978292914
ROC train: 0.876448	val: 0.641305	test: 0.591366
PRC train: 0.835796	val: 0.673845	test: 0.626532

Epoch: 79
Loss: 0.37759053866463693
ROC train: 0.879197	val: 0.644651	test: 0.596097
PRC train: 0.837406	val: 0.676115	test: 0.627960

Epoch: 80
Loss: 0.3853714572940887
ROC train: 0.880576	val: 0.623554	test: 0.592615
PRC train: 0.839396	val: 0.672598	test: 0.627098

Epoch: 81
Loss: 0.38173327990915573
ROC train: 0.880479	val: 0.627983	test: 0.576721
PRC train: 0.839584	val: 0.674742	test: 0.621253

Epoch: 82
Loss: 0.381897792599059
ROC train: 0.883091	val: 0.636115	test: 0.597578
PRC train: 0.845048	val: 0.674886	test: 0.631877

Epoch: 83
Loss: 0.3756327375777195
ROC train: 0.884748	val: 0.635560	test: 0.597140
PRC train: 0.845498	val: 0.671138	test: 0.633380

Epoch: 84
Loss: 0.3797692765564247
ROC train: 0.885745	val: 0.628092	test: 0.610953
PRC train: 0.847732	val: 0.670652	test: 0.638026

Epoch: 85
Loss: 0.3754015589820893
ROC train: 0.887604	val: 0.635826	test: 0.594718
PRC train: 0.846621	val: 0.678730	test: 0.628490

Epoch: 86
Loss: 0.3744722599025104
ROC train: 0.887365	val: 0.639762	test: 0.593638
PRC train: 0.846387	val: 0.677590	test: 0.627749

Epoch: 87
Loss: 0.3823628066966781
ROC train: 0.887153	val: 0.626068	test: 0.598163
PRC train: 0.847807	val: 0.672318	test: 0.630559

Epoch: 88
Loss: 0.3782031010575057
ROC train: 0.889876	val: 0.633644	test: 0.597659
PRC train: 0.851832	val: 0.672915	test: 0.630372

Epoch: 89
Loss: 0.3745544498043594
ROC train: 0.892157	val: 0.640064	test: 0.590983
PRC train: 0.855308	val: 0.677856	test: 0.629848

Epoch: 90
Loss: 0.36909051271072046
ROC train: 0.891107	val: 0.637786	test: 0.584731
PRC train: 0.854836	val: 0.676255	test: 0.628469

Epoch: 91
Loss: 0.371945660444238
ROC train: 0.894352	val: 0.641457	test: 0.592236
PRC train: 0.858497	val: 0.681030	test: 0.632667

Epoch: 92
Loss: 0.36613065198288375
ROC train: 0.893619	val: 0.633889	test: 0.606769
PRC train: 0.855895	val: 0.675012	test: 0.635333

Epoch: 93
Loss: 0.36863434523444283
ROC train: 0.896838	val: 0.644229	test: 0.586418
PRC train: 0.859798	val: 0.680981	test: 0.628225

Epoch: 94
Loss: 0.36319149479964163
ROC train: 0.897616	val: 0.636874	test: 0.590012
PRC train: 0.760945	val: 0.664772	test: 0.622997

Epoch: 34
Loss: 0.4385754231351927
ROC train: 0.794814	val: 0.629817	test: 0.601202
PRC train: 0.763082	val: 0.670320	test: 0.623913

Epoch: 35
Loss: 0.4368489689045062
ROC train: 0.805559	val: 0.633605	test: 0.597534
PRC train: 0.772534	val: 0.672214	test: 0.620206

Epoch: 36
Loss: 0.4365506368185801
ROC train: 0.808015	val: 0.629399	test: 0.600806
PRC train: 0.775737	val: 0.666742	test: 0.624511

Epoch: 37
Loss: 0.439058349552488
ROC train: 0.808690	val: 0.629695	test: 0.603717
PRC train: 0.776860	val: 0.664749	test: 0.630671

Epoch: 38
Loss: 0.43745308204336586
ROC train: 0.812674	val: 0.619435	test: 0.595581
PRC train: 0.779504	val: 0.660733	test: 0.624889

Epoch: 39
Loss: 0.4325164722059741
ROC train: 0.814578	val: 0.618059	test: 0.595642
PRC train: 0.780664	val: 0.661763	test: 0.619131

Epoch: 40
Loss: 0.4345005612887133
ROC train: 0.817783	val: 0.624836	test: 0.604363
PRC train: 0.782684	val: 0.659173	test: 0.632946

Epoch: 41
Loss: 0.4321449933852167
ROC train: 0.821489	val: 0.632787	test: 0.595153
PRC train: 0.785428	val: 0.667700	test: 0.624691

Epoch: 42
Loss: 0.4307050698996603
ROC train: 0.824073	val: 0.635023	test: 0.584383
PRC train: 0.790833	val: 0.671919	test: 0.615987

Epoch: 43
Loss: 0.4334983488467361
ROC train: 0.822440	val: 0.634757	test: 0.590079
PRC train: 0.788348	val: 0.669243	test: 0.624313

Epoch: 44
Loss: 0.42902544805927406
ROC train: 0.822831	val: 0.637802	test: 0.596392
PRC train: 0.787550	val: 0.673713	test: 0.626917

Epoch: 45
Loss: 0.42618625032048457
ROC train: 0.825242	val: 0.634044	test: 0.598143
PRC train: 0.788684	val: 0.672846	test: 0.626485

Epoch: 46
Loss: 0.4242490793070961
ROC train: 0.829170	val: 0.631557	test: 0.599764
PRC train: 0.792959	val: 0.672524	test: 0.628805

Epoch: 47
Loss: 0.42793155867830823
ROC train: 0.827644	val: 0.628448	test: 0.600392
PRC train: 0.789792	val: 0.670971	test: 0.631191

Epoch: 48
Loss: 0.42065057462009614
ROC train: 0.828688	val: 0.630961	test: 0.606710
PRC train: 0.791298	val: 0.668709	test: 0.633382

Epoch: 49
Loss: 0.416614513392685
ROC train: 0.833497	val: 0.637092	test: 0.602165
PRC train: 0.797093	val: 0.673336	test: 0.625844

Epoch: 50
Loss: 0.4183453732443403
ROC train: 0.841566	val: 0.640060	test: 0.598206
PRC train: 0.805018	val: 0.673761	test: 0.625500

Epoch: 51
Loss: 0.41231082882537134
ROC train: 0.840891	val: 0.636844	test: 0.587251
PRC train: 0.802979	val: 0.671223	test: 0.622466

Epoch: 52
Loss: 0.4125944990520488
ROC train: 0.841542	val: 0.631220	test: 0.584954
PRC train: 0.802759	val: 0.666527	test: 0.620045

Epoch: 53
Loss: 0.4185765424138694
ROC train: 0.842353	val: 0.622194	test: 0.588656
PRC train: 0.803758	val: 0.666205	test: 0.620693

Epoch: 54
Loss: 0.42132430374688923
ROC train: 0.841864	val: 0.620434	test: 0.590762
PRC train: 0.803178	val: 0.668170	test: 0.625562

Epoch: 55
Loss: 0.4134546326899877
ROC train: 0.841339	val: 0.632829	test: 0.605027
PRC train: 0.803571	val: 0.671941	test: 0.634501

Epoch: 56
Loss: 0.4085963647563052
ROC train: 0.846948	val: 0.634351	test: 0.600928
PRC train: 0.810621	val: 0.671368	test: 0.633797

Epoch: 57
Loss: 0.40919008992359773
ROC train: 0.846255	val: 0.636077	test: 0.566361
PRC train: 0.808004	val: 0.676688	test: 0.613929

Epoch: 58
Loss: 0.4027309865488304
ROC train: 0.855378	val: 0.618227	test: 0.587531
PRC train: 0.815790	val: 0.665144	test: 0.621461

Epoch: 59
Loss: 0.4033227158099832
ROC train: 0.855515	val: 0.610800	test: 0.589027
PRC train: 0.816429	val: 0.660241	test: 0.618110

Epoch: 60
Loss: 0.40084450186082926
ROC train: 0.856896	val: 0.620106	test: 0.581125
PRC train: 0.817721	val: 0.667950	test: 0.617434

Epoch: 61
Loss: 0.3997308520256945
ROC train: 0.859262	val: 0.623457	test: 0.576524
PRC train: 0.820028	val: 0.665856	test: 0.616018

Epoch: 62
Loss: 0.39806767113230873
ROC train: 0.852284	val: 0.627463	test: 0.599196
PRC train: 0.811423	val: 0.666469	test: 0.625384

Epoch: 63
Loss: 0.4017491018570006
ROC train: 0.847944	val: 0.634006	test: 0.603863
PRC train: 0.808829	val: 0.671355	test: 0.628373

Epoch: 64
Loss: 0.39697747408872214
ROC train: 0.861161	val: 0.635479	test: 0.587386
PRC train: 0.822687	val: 0.675112	test: 0.621593

Epoch: 65
Loss: 0.4012654279886645
ROC train: 0.859386	val: 0.630234	test: 0.577815
PRC train: 0.820673	val: 0.668155	test: 0.616736

Epoch: 66
Loss: 0.40072148285721126
ROC train: 0.866322	val: 0.632305	test: 0.587355
PRC train: 0.825820	val: 0.673058	test: 0.620427

Epoch: 67
Loss: 0.3964139034787951
ROC train: 0.865508	val: 0.630559	test: 0.585887
PRC train: 0.823682	val: 0.673653	test: 0.621539

Epoch: 68
Loss: 0.3905008726729318
ROC train: 0.867824	val: 0.634812	test: 0.594158
PRC train: 0.828411	val: 0.675375	test: 0.627026

Epoch: 69
Loss: 0.40043138620379715
ROC train: 0.869160	val: 0.633544	test: 0.602034
PRC train: 0.832597	val: 0.674565	test: 0.632196

Epoch: 70
Loss: 0.3892424288499944
ROC train: 0.872243	val: 0.632117	test: 0.587637
PRC train: 0.836205	val: 0.672721	test: 0.622860

Epoch: 71
Loss: 0.38984624204229423
ROC train: 0.873605	val: 0.624490	test: 0.583293
PRC train: 0.838727	val: 0.669266	test: 0.619314

Epoch: 72
Loss: 0.3898885037088805
ROC train: 0.872887	val: 0.635094	test: 0.589390
PRC train: 0.836312	val: 0.675516	test: 0.622696

Epoch: 73
Loss: 0.38583003367671304
ROC train: 0.870412	val: 0.623400	test: 0.591246
PRC train: 0.834647	val: 0.669170	test: 0.623068

Epoch: 74
Loss: 0.3941152100281403
ROC train: 0.875592	val: 0.607325	test: 0.592491
PRC train: 0.838759	val: 0.659210	test: 0.622482

Epoch: 75
Loss: 0.38579575169146524
ROC train: 0.876452	val: 0.619568	test: 0.576706
PRC train: 0.840276	val: 0.668460	test: 0.618070

Epoch: 76
Loss: 0.38584293325339003
ROC train: 0.878150	val: 0.622552	test: 0.594813
PRC train: 0.840654	val: 0.666776	test: 0.624659

Epoch: 77
Loss: 0.38257401733200025
ROC train: 0.877971	val: 0.618175	test: 0.595449
PRC train: 0.840172	val: 0.664783	test: 0.625248

Epoch: 78
Loss: 0.3860351727572829
ROC train: 0.881906	val: 0.611541	test: 0.586449
PRC train: 0.842266	val: 0.661439	test: 0.624954

Epoch: 79
Loss: 0.3780818547407182
ROC train: 0.884973	val: 0.627199	test: 0.581028
PRC train: 0.846098	val: 0.667119	test: 0.620944

Epoch: 80
Loss: 0.3808361727543169
ROC train: 0.884775	val: 0.634557	test: 0.575323
PRC train: 0.846767	val: 0.668967	test: 0.616722

Epoch: 81
Loss: 0.37750172072826194
ROC train: 0.885970	val: 0.636573	test: 0.585192
PRC train: 0.848797	val: 0.672262	test: 0.624245

Epoch: 82
Loss: 0.36997095742037145
ROC train: 0.884743	val: 0.623858	test: 0.589215
PRC train: 0.845224	val: 0.667996	test: 0.626627

Epoch: 83
Loss: 0.3802295883825647
ROC train: 0.889685	val: 0.619119	test: 0.586470
PRC train: 0.852144	val: 0.667000	test: 0.626117

Epoch: 84
Loss: 0.37556488022926954
ROC train: 0.890675	val: 0.614472	test: 0.582190
PRC train: 0.853850	val: 0.664495	test: 0.625454

Epoch: 85
Loss: 0.3746243548377879
ROC train: 0.889565	val: 0.615842	test: 0.575775
PRC train: 0.852958	val: 0.661506	test: 0.623314

Epoch: 86
Loss: 0.3776558427691145
ROC train: 0.892834	val: 0.631474	test: 0.572488
PRC train: 0.856554	val: 0.670339	test: 0.622973

Epoch: 87
Loss: 0.37094108140385923
ROC train: 0.893154	val: 0.631742	test: 0.568355
PRC train: 0.856745	val: 0.669975	test: 0.620765

Epoch: 88
Loss: 0.3674273901466788
ROC train: 0.894978	val: 0.617482	test: 0.569043
PRC train: 0.858159	val: 0.665145	test: 0.616317

Epoch: 89
Loss: 0.36959376158037716
ROC train: 0.896326	val: 0.615975	test: 0.576984
PRC train: 0.861356	val: 0.665065	test: 0.617359

Epoch: 90
Loss: 0.36527177860245064
ROC train: 0.898344	val: 0.627685	test: 0.584279
PRC train: 0.862320	val: 0.669801	test: 0.621144

Epoch: 91
Loss: 0.3651752278270811
ROC train: 0.897038	val: 0.623161	test: 0.578406
PRC train: 0.858880	val: 0.665314	test: 0.622593

Epoch: 92
Loss: 0.360555737656257
ROC train: 0.899533	val: 0.623861	test: 0.585236
PRC train: 0.862845	val: 0.671075	test: 0.629879

Epoch: 93
Loss: 0.36163900534862403
ROC train: 0.899839	val: 0.630303	test: 0.584276
PRC train: 0.865586	val: 0.671712	test: 0.624755

Epoch: 94
Loss: 0.3617839650791371
ROC train: 0.900471	val: 0.633119	test: 0.592631
PRC train: 0.753616	val: 0.658252	test: 0.626019

Epoch: 34
Loss: 0.44752083074927046
ROC train: 0.781161	val: 0.614193	test: 0.607736
PRC train: 0.753387	val: 0.655885	test: 0.627976

Epoch: 35
Loss: 0.4443331317838951
ROC train: 0.783512	val: 0.616060	test: 0.612288
PRC train: 0.754323	val: 0.653811	test: 0.627515

Epoch: 36
Loss: 0.43952574358511204
ROC train: 0.797900	val: 0.628482	test: 0.610926
PRC train: 0.766913	val: 0.663909	test: 0.626207

Epoch: 37
Loss: 0.4371385183093344
ROC train: 0.804574	val: 0.643720	test: 0.600821
PRC train: 0.770724	val: 0.674446	test: 0.621104

Epoch: 38
Loss: 0.4394382270294189
ROC train: 0.804230	val: 0.641711	test: 0.597007
PRC train: 0.770331	val: 0.674423	test: 0.620125

Epoch: 39
Loss: 0.4362234421933474
ROC train: 0.802899	val: 0.630547	test: 0.610268
PRC train: 0.772566	val: 0.664520	test: 0.626363

Epoch: 40
Loss: 0.4422812021322116
ROC train: 0.804568	val: 0.625752	test: 0.600693
PRC train: 0.774220	val: 0.661457	test: 0.627192

Epoch: 41
Loss: 0.4345080393082135
ROC train: 0.803755	val: 0.629476	test: 0.607822
PRC train: 0.772758	val: 0.665159	test: 0.629194

Epoch: 42
Loss: 0.4337485343638397
ROC train: 0.814422	val: 0.619655	test: 0.606386
PRC train: 0.780442	val: 0.664979	test: 0.626910

Epoch: 43
Loss: 0.42556409305074305
ROC train: 0.814341	val: 0.622133	test: 0.599820
PRC train: 0.780287	val: 0.666488	test: 0.621153

Epoch: 44
Loss: 0.43193393835215266
ROC train: 0.816375	val: 0.626474	test: 0.606193
PRC train: 0.781645	val: 0.669547	test: 0.626070

Epoch: 45
Loss: 0.42469002404428124
ROC train: 0.823832	val: 0.639869	test: 0.614965
PRC train: 0.788889	val: 0.672014	test: 0.632490

Epoch: 46
Loss: 0.43057378410601244
ROC train: 0.824493	val: 0.639837	test: 0.606031
PRC train: 0.788228	val: 0.677214	test: 0.625579

Epoch: 47
Loss: 0.42695770246557496
ROC train: 0.828873	val: 0.634259	test: 0.609104
PRC train: 0.792101	val: 0.673168	test: 0.626570

Epoch: 48
Loss: 0.4272174109578459
ROC train: 0.831385	val: 0.631604	test: 0.608124
PRC train: 0.793457	val: 0.668083	test: 0.627635

Epoch: 49
Loss: 0.4165009271970404
ROC train: 0.831043	val: 0.634092	test: 0.594613
PRC train: 0.792743	val: 0.676034	test: 0.621934

Epoch: 50
Loss: 0.4208815783337558
ROC train: 0.833263	val: 0.638516	test: 0.605032
PRC train: 0.794102	val: 0.671590	test: 0.628332

Epoch: 51
Loss: 0.4256224153261125
ROC train: 0.835695	val: 0.635852	test: 0.589204
PRC train: 0.796724	val: 0.673944	test: 0.619516

Epoch: 52
Loss: 0.41633334178726955
ROC train: 0.838723	val: 0.638491	test: 0.582671
PRC train: 0.798085	val: 0.671058	test: 0.618365

Epoch: 53
Loss: 0.42058398362395444
ROC train: 0.836354	val: 0.635392	test: 0.583498
PRC train: 0.797936	val: 0.667535	test: 0.619030

Epoch: 54
Loss: 0.4168013246034521
ROC train: 0.840565	val: 0.633078	test: 0.602123
PRC train: 0.802148	val: 0.669444	test: 0.628082

Epoch: 55
Loss: 0.41932617966377944
ROC train: 0.840132	val: 0.630685	test: 0.607195
PRC train: 0.801871	val: 0.667512	test: 0.632411

Epoch: 56
Loss: 0.4080947171855782
ROC train: 0.846653	val: 0.633506	test: 0.611945
PRC train: 0.807750	val: 0.671635	test: 0.632809

Epoch: 57
Loss: 0.4045310874745479
ROC train: 0.847378	val: 0.632295	test: 0.611476
PRC train: 0.806940	val: 0.670176	test: 0.631167

Epoch: 58
Loss: 0.40952762185814723
ROC train: 0.849230	val: 0.622760	test: 0.607164
PRC train: 0.810149	val: 0.666674	test: 0.629579

Epoch: 59
Loss: 0.4110986455074307
ROC train: 0.848490	val: 0.629472	test: 0.595471
PRC train: 0.810428	val: 0.667877	test: 0.624155

Epoch: 60
Loss: 0.41252053279306666
ROC train: 0.848982	val: 0.629319	test: 0.595251
PRC train: 0.809840	val: 0.672738	test: 0.623634

Epoch: 61
Loss: 0.40611726490475386
ROC train: 0.850584	val: 0.629747	test: 0.598014
PRC train: 0.808275	val: 0.674288	test: 0.628708

Epoch: 62
Loss: 0.40549712070907545
ROC train: 0.852265	val: 0.625700	test: 0.611245
PRC train: 0.809801	val: 0.670427	test: 0.635941

Epoch: 63
Loss: 0.4100684251251616
ROC train: 0.853611	val: 0.627942	test: 0.609370
PRC train: 0.811488	val: 0.671354	test: 0.635388

Epoch: 64
Loss: 0.40126423263040134
ROC train: 0.854410	val: 0.621559	test: 0.601297
PRC train: 0.813058	val: 0.666778	test: 0.631805

Epoch: 65
Loss: 0.4003391091151733
ROC train: 0.855602	val: 0.620062	test: 0.607177
PRC train: 0.813930	val: 0.659544	test: 0.631982

Epoch: 66
Loss: 0.39720564021509164
ROC train: 0.857949	val: 0.616381	test: 0.599245
PRC train: 0.815277	val: 0.662398	test: 0.627567

Epoch: 67
Loss: 0.4022703493840999
ROC train: 0.861232	val: 0.616168	test: 0.588798
PRC train: 0.817057	val: 0.666602	test: 0.623219

Epoch: 68
Loss: 0.39909570912208314
ROC train: 0.863820	val: 0.623018	test: 0.590854
PRC train: 0.822360	val: 0.668849	test: 0.625257

Epoch: 69
Loss: 0.39538121974430307
ROC train: 0.863563	val: 0.620955	test: 0.591735
PRC train: 0.821876	val: 0.666775	test: 0.624097

Epoch: 70
Loss: 0.3998398850848268
ROC train: 0.863469	val: 0.621265	test: 0.589822
PRC train: 0.823060	val: 0.665919	test: 0.625378

Epoch: 71
Loss: 0.3949765854909521
ROC train: 0.865281	val: 0.629020	test: 0.588658
PRC train: 0.822568	val: 0.666873	test: 0.624930

Epoch: 72
Loss: 0.3897155610527073
ROC train: 0.869202	val: 0.632709	test: 0.587533
PRC train: 0.823908	val: 0.672200	test: 0.622212

Epoch: 73
Loss: 0.3859035495233848
ROC train: 0.867611	val: 0.625320	test: 0.581724
PRC train: 0.823064	val: 0.669927	test: 0.621915

Epoch: 74
Loss: 0.3974378896677543
ROC train: 0.871498	val: 0.613820	test: 0.584994
PRC train: 0.829954	val: 0.662339	test: 0.620143

Epoch: 75
Loss: 0.3891227488480383
ROC train: 0.869460	val: 0.609088	test: 0.577230
PRC train: 0.828635	val: 0.663647	test: 0.614599

Epoch: 76
Loss: 0.3879103169800721
ROC train: 0.875526	val: 0.621340	test: 0.582412
PRC train: 0.835062	val: 0.667297	test: 0.618692

Epoch: 77
Loss: 0.3863092367929853
ROC train: 0.874158	val: 0.618517	test: 0.603348
PRC train: 0.832201	val: 0.663761	test: 0.633887

Epoch: 78
Loss: 0.3825081000608118
ROC train: 0.874156	val: 0.620192	test: 0.607501
PRC train: 0.832616	val: 0.666197	test: 0.633393

Epoch: 79
Loss: 0.383278730538112
ROC train: 0.876206	val: 0.620547	test: 0.597408
PRC train: 0.834228	val: 0.666013	test: 0.629939

Epoch: 80
Loss: 0.3844171131486362
ROC train: 0.878090	val: 0.626786	test: 0.582999
PRC train: 0.839032	val: 0.669582	test: 0.624218

Epoch: 81
Loss: 0.3824338017611584
ROC train: 0.878119	val: 0.621413	test: 0.598212
PRC train: 0.839075	val: 0.664102	test: 0.628709

Epoch: 82
Loss: 0.38685219390279096
ROC train: 0.879194	val: 0.618627	test: 0.603532
PRC train: 0.837100	val: 0.667549	test: 0.634108

Epoch: 83
Loss: 0.3790234126117257
ROC train: 0.876325	val: 0.629664	test: 0.590396
PRC train: 0.835807	val: 0.673831	test: 0.628104

Epoch: 84
Loss: 0.38426138128248233
ROC train: 0.882106	val: 0.632385	test: 0.575679
PRC train: 0.843745	val: 0.669758	test: 0.615017

Epoch: 85
Loss: 0.37484091125197655
ROC train: 0.881751	val: 0.633985	test: 0.582994
PRC train: 0.844790	val: 0.668095	test: 0.619732

Epoch: 86
Loss: 0.37839106463486666
ROC train: 0.884810	val: 0.628072	test: 0.596660
PRC train: 0.845540	val: 0.664730	test: 0.631464

Epoch: 87
Loss: 0.37410517343700267
ROC train: 0.886822	val: 0.626492	test: 0.600306
PRC train: 0.847038	val: 0.667011	test: 0.631789

Epoch: 88
Loss: 0.3744803158123438
ROC train: 0.885204	val: 0.637437	test: 0.590356
PRC train: 0.843770	val: 0.673658	test: 0.627362

Epoch: 89
Loss: 0.3702475335492067
ROC train: 0.886074	val: 0.639961	test: 0.592338
PRC train: 0.848309	val: 0.675751	test: 0.625616

Epoch: 90
Loss: 0.374330317790024
ROC train: 0.888464	val: 0.636957	test: 0.586494
PRC train: 0.848945	val: 0.672271	test: 0.624785

Epoch: 91
Loss: 0.3722459789100797
ROC train: 0.892136	val: 0.622667	test: 0.591907
PRC train: 0.851044	val: 0.661576	test: 0.629708

Epoch: 92
Loss: 0.36982866255515445
ROC train: 0.895910	val: 0.623695	test: 0.599012
PRC train: 0.855360	val: 0.667741	test: 0.628235

Epoch: 93
Loss: 0.3734866916789844
ROC train: 0.893456	val: 0.630679	test: 0.597333
PRC train: 0.856494	val: 0.671688	test: 0.629161

Epoch: 94
Loss: 0.3692586588738182
ROC train: 0.894968	val: 0.636780	test: 0.606289
PRC train: 0.792269	val: 0.651010	test: 0.612543

Epoch: 33
Loss: 0.42167259200991125
ROC train: 0.841062	val: 0.586174	test: 0.576325
PRC train: 0.796629	val: 0.647278	test: 0.620764

Epoch: 34
Loss: 0.42166910495789944
ROC train: 0.840042	val: 0.571766	test: 0.573744
PRC train: 0.798040	val: 0.638433	test: 0.621371

Epoch: 35
Loss: 0.41429926551982355
ROC train: 0.854773	val: 0.582517	test: 0.563133
PRC train: 0.809440	val: 0.649855	test: 0.618582

Epoch: 36
Loss: 0.41493384143629
ROC train: 0.853564	val: 0.575188	test: 0.565801
PRC train: 0.808643	val: 0.649249	test: 0.616323

Epoch: 37
Loss: 0.4120125576445449
ROC train: 0.855401	val: 0.573079	test: 0.557914
PRC train: 0.811522	val: 0.647555	test: 0.614901

Epoch: 38
Loss: 0.40166836037317316
ROC train: 0.855278	val: 0.578296	test: 0.549839
PRC train: 0.812113	val: 0.651147	test: 0.606665

Epoch: 39
Loss: 0.40105492527703107
ROC train: 0.855472	val: 0.571058	test: 0.565399
PRC train: 0.812384	val: 0.643498	test: 0.615123

Epoch: 40
Loss: 0.4076912641478815
ROC train: 0.860595	val: 0.563014	test: 0.563091
PRC train: 0.814988	val: 0.640675	test: 0.614282

Epoch: 41
Loss: 0.40711673557276784
ROC train: 0.864127	val: 0.572577	test: 0.567752
PRC train: 0.818267	val: 0.644916	test: 0.616391

Epoch: 42
Loss: 0.3988874730880185
ROC train: 0.864847	val: 0.585779	test: 0.563265
PRC train: 0.821073	val: 0.657494	test: 0.612270

Epoch: 43
Loss: 0.3980682750260834
ROC train: 0.859430	val: 0.581091	test: 0.566863
PRC train: 0.817446	val: 0.652073	test: 0.614720

Epoch: 44
Loss: 0.39376534930617246
ROC train: 0.867504	val: 0.589600	test: 0.557332
PRC train: 0.826149	val: 0.658818	test: 0.613885

Epoch: 45
Loss: 0.39086583405730024
ROC train: 0.872940	val: 0.575972	test: 0.568672
PRC train: 0.826464	val: 0.645942	test: 0.620953

Epoch: 46
Loss: 0.3870309075143261
ROC train: 0.876127	val: 0.577465	test: 0.566866
PRC train: 0.827393	val: 0.649845	test: 0.618492

Epoch: 47
Loss: 0.3865353422885327
ROC train: 0.877760	val: 0.574352	test: 0.560770
PRC train: 0.829970	val: 0.647127	test: 0.612017

Epoch: 48
Loss: 0.3855994577940548
ROC train: 0.872443	val: 0.567935	test: 0.567205
PRC train: 0.824614	val: 0.640350	test: 0.618574

Epoch: 49
Loss: 0.37904768759783697
ROC train: 0.881913	val: 0.586422	test: 0.562970
PRC train: 0.835113	val: 0.652595	test: 0.612551

Epoch: 50
Loss: 0.37792883898354235
ROC train: 0.883212	val: 0.576992	test: 0.564852
PRC train: 0.839118	val: 0.646048	test: 0.615353

Epoch: 51
Loss: 0.377691893816989
ROC train: 0.884377	val: 0.575499	test: 0.556422
PRC train: 0.841230	val: 0.647605	test: 0.613532

Epoch: 52
Loss: 0.37983636793966175
ROC train: 0.881369	val: 0.558368	test: 0.569225
PRC train: 0.837270	val: 0.637789	test: 0.619039

Epoch: 53
Loss: 0.37243588453462106
ROC train: 0.889148	val: 0.574711	test: 0.563392
PRC train: 0.845063	val: 0.648954	test: 0.617494

Epoch: 54
Loss: 0.3756597580730901
ROC train: 0.891177	val: 0.573458	test: 0.562976
PRC train: 0.846632	val: 0.649442	test: 0.617690

Epoch: 55
Loss: 0.37314317673910236
ROC train: 0.890614	val: 0.558935	test: 0.565627
PRC train: 0.843770	val: 0.638260	test: 0.619740

Epoch: 56
Loss: 0.3721208688547931
ROC train: 0.889963	val: 0.568025	test: 0.545334
PRC train: 0.848059	val: 0.649943	test: 0.605096

Epoch: 57
Loss: 0.3692861779522564
ROC train: 0.895205	val: 0.564589	test: 0.558903
PRC train: 0.852611	val: 0.644791	test: 0.616110

Epoch: 58
Loss: 0.36526793684473197
ROC train: 0.893462	val: 0.562331	test: 0.561245
PRC train: 0.849972	val: 0.639757	test: 0.618381

Epoch: 59
Loss: 0.3671400043297394
ROC train: 0.895875	val: 0.566941	test: 0.548596
PRC train: 0.852880	val: 0.645669	test: 0.610948

Epoch: 60
Loss: 0.3637352482821409
ROC train: 0.896647	val: 0.567680	test: 0.552583
PRC train: 0.852320	val: 0.643101	test: 0.609729

Epoch: 61
Loss: 0.3647547931875469
ROC train: 0.899966	val: 0.571408	test: 0.556951
PRC train: 0.853527	val: 0.644465	test: 0.612855

Epoch: 62
Loss: 0.356265773873824
ROC train: 0.899574	val: 0.575718	test: 0.541393
PRC train: 0.857274	val: 0.644495	test: 0.606967

Epoch: 63
Loss: 0.36110734213400897
ROC train: 0.902423	val: 0.567988	test: 0.549792
PRC train: 0.861238	val: 0.642058	test: 0.609836

Epoch: 64
Loss: 0.35516304111152525
ROC train: 0.902551	val: 0.570430	test: 0.569415
PRC train: 0.858021	val: 0.645265	test: 0.620485

Epoch: 65
Loss: 0.3533646762883664
ROC train: 0.906245	val: 0.584057	test: 0.558678
PRC train: 0.860555	val: 0.652689	test: 0.612389

Epoch: 66
Loss: 0.3527036723930651
ROC train: 0.906660	val: 0.589703	test: 0.551280
PRC train: 0.861732	val: 0.655242	test: 0.608821

Epoch: 67
Loss: 0.35289517521827785
ROC train: 0.909424	val: 0.586589	test: 0.573563
PRC train: 0.863740	val: 0.657483	test: 0.619377

Epoch: 68
Loss: 0.35353007485825294
ROC train: 0.911437	val: 0.585599	test: 0.563511
PRC train: 0.866222	val: 0.656971	test: 0.616951

Epoch: 69
Loss: 0.35109977802916076
ROC train: 0.911816	val: 0.576476	test: 0.562521
PRC train: 0.867137	val: 0.653698	test: 0.617437

Epoch: 70
Loss: 0.35082900028156994
ROC train: 0.906900	val: 0.576626	test: 0.559199
PRC train: 0.863690	val: 0.651903	test: 0.617300

Epoch: 71
Loss: 0.343197282078779
ROC train: 0.909208	val: 0.582092	test: 0.553451
PRC train: 0.864434	val: 0.655621	test: 0.612518

Epoch: 72
Loss: 0.3441904886410382
ROC train: 0.908461	val: 0.561550	test: 0.584799
PRC train: 0.865966	val: 0.640753	test: 0.622182

Epoch: 73
Loss: 0.33874076950598
ROC train: 0.914491	val: 0.582559	test: 0.572212
PRC train: 0.872406	val: 0.649964	test: 0.615840

Epoch: 74
Loss: 0.342686917206757
ROC train: 0.915290	val: 0.578485	test: 0.558381
PRC train: 0.870037	val: 0.650522	test: 0.613144

Epoch: 75
Loss: 0.3442839151003222
ROC train: 0.918267	val: 0.577833	test: 0.573461
PRC train: 0.873238	val: 0.654211	test: 0.624869

Epoch: 76
Loss: 0.336533720251074
ROC train: 0.918316	val: 0.571003	test: 0.583619
PRC train: 0.875101	val: 0.647852	test: 0.628775

Epoch: 77
Loss: 0.338591415331434
ROC train: 0.920670	val: 0.564085	test: 0.563506
PRC train: 0.877385	val: 0.643778	test: 0.618319

Epoch: 78
Loss: 0.3362783395801488
ROC train: 0.920481	val: 0.575392	test: 0.548114
PRC train: 0.877354	val: 0.650174	test: 0.611023

Epoch: 79
Loss: 0.337201274534347
ROC train: 0.920103	val: 0.571005	test: 0.554551
PRC train: 0.875546	val: 0.645376	test: 0.612926

Epoch: 80
Loss: 0.33183106520289324
ROC train: 0.923401	val: 0.587034	test: 0.547240
PRC train: 0.878884	val: 0.654767	test: 0.607366

Epoch: 81
Loss: 0.3322993493458342
ROC train: 0.925805	val: 0.586993	test: 0.555300
PRC train: 0.880924	val: 0.655924	test: 0.609594

Epoch: 82
Loss: 0.32996149404919306
ROC train: 0.925641	val: 0.582363	test: 0.568747
PRC train: 0.880112	val: 0.655028	test: 0.613124

Epoch: 83
Loss: 0.3254596859171523
ROC train: 0.926569	val: 0.590875	test: 0.556167
PRC train: 0.882590	val: 0.660724	test: 0.608540

Epoch: 84
Loss: 0.3245444969836418
ROC train: 0.926621	val: 0.588282	test: 0.555100
PRC train: 0.884365	val: 0.655715	test: 0.610147

Epoch: 85
Loss: 0.32930263089811884
ROC train: 0.929647	val: 0.576760	test: 0.562289
PRC train: 0.887869	val: 0.653977	test: 0.607685

Epoch: 86
Loss: 0.3211132616438661
ROC train: 0.931274	val: 0.569659	test: 0.573504
PRC train: 0.889727	val: 0.648578	test: 0.615297

Epoch: 87
Loss: 0.3211334439642078
ROC train: 0.931726	val: 0.576303	test: 0.559225
PRC train: 0.890738	val: 0.650380	test: 0.611484

Epoch: 88
Loss: 0.32210616046288937
ROC train: 0.933188	val: 0.570348	test: 0.557551
PRC train: 0.891262	val: 0.647366	test: 0.608098

Epoch: 89
Loss: 0.32117417044833224
ROC train: 0.930912	val: 0.578927	test: 0.553777
PRC train: 0.887742	val: 0.653872	test: 0.606049

Epoch: 90
Loss: 0.31391957966396344
ROC train: 0.933429	val: 0.574152	test: 0.568293
PRC train: 0.892341	val: 0.651291	test: 0.617975

Epoch: 91
Loss: 0.3140388849918908
ROC train: 0.933745	val: 0.581664	test: 0.578776
PRC train: 0.893005	val: 0.647631	test: 0.619859

Epoch: 92
Loss: 0.3172354210254128
ROC train: 0.935000	val: 0.591536	test: 0.569905
PRC train: 0.893051	val: 0.653343	test: 0.611398

Epoch: 93
Loss: 0.3196032911279696
ROC train: 0.937609	val: 0.583200	test: 0.568641
PRC train: 0.898982	val: 0.652413	test: 0.613671
PRC train: 0.794738	val: 0.657600	test: 0.623629

Epoch: 33
Loss: 0.4260247536778188
ROC train: 0.837140	val: 0.627182	test: 0.600800
PRC train: 0.796642	val: 0.656566	test: 0.626745

Epoch: 34
Loss: 0.4211990690299561
ROC train: 0.842255	val: 0.620719	test: 0.591778
PRC train: 0.801647	val: 0.664843	test: 0.618106

Epoch: 35
Loss: 0.420185207667637
ROC train: 0.841779	val: 0.603452	test: 0.592667
PRC train: 0.803424	val: 0.655242	test: 0.619432

Epoch: 36
Loss: 0.4145868624933854
ROC train: 0.844391	val: 0.606018	test: 0.588571
PRC train: 0.803915	val: 0.646922	test: 0.617734

Epoch: 37
Loss: 0.41489987137870254
ROC train: 0.846372	val: 0.609723	test: 0.594216
PRC train: 0.803843	val: 0.645315	test: 0.618213

Epoch: 38
Loss: 0.4104957892467002
ROC train: 0.848248	val: 0.610821	test: 0.597805
PRC train: 0.804628	val: 0.650582	test: 0.621770

Epoch: 39
Loss: 0.41155692049451736
ROC train: 0.849983	val: 0.604483	test: 0.587968
PRC train: 0.807370	val: 0.651074	test: 0.614970

Epoch: 40
Loss: 0.4061134611933337
ROC train: 0.853447	val: 0.591395	test: 0.585433
PRC train: 0.810690	val: 0.641857	test: 0.617704

Epoch: 41
Loss: 0.40564761485542905
ROC train: 0.859370	val: 0.594248	test: 0.578433
PRC train: 0.818292	val: 0.649927	test: 0.610984

Epoch: 42
Loss: 0.3981941518023377
ROC train: 0.855297	val: 0.606687	test: 0.591455
PRC train: 0.816921	val: 0.646988	test: 0.617487

Epoch: 43
Loss: 0.4003370021209355
ROC train: 0.859513	val: 0.610149	test: 0.588197
PRC train: 0.819169	val: 0.648666	test: 0.622025

Epoch: 44
Loss: 0.3967249430917556
ROC train: 0.857645	val: 0.606282	test: 0.553676
PRC train: 0.821014	val: 0.657166	test: 0.603952

Epoch: 45
Loss: 0.39905732185471043
ROC train: 0.865185	val: 0.596128	test: 0.578032
PRC train: 0.828156	val: 0.642606	test: 0.618604

Epoch: 46
Loss: 0.3963652825805243
ROC train: 0.868994	val: 0.620263	test: 0.582038
PRC train: 0.831340	val: 0.655620	test: 0.616742

Epoch: 47
Loss: 0.39810709003783906
ROC train: 0.867034	val: 0.619431	test: 0.596448
PRC train: 0.830920	val: 0.653441	test: 0.624038

Epoch: 48
Loss: 0.39359515590753746
ROC train: 0.873904	val: 0.616812	test: 0.588754
PRC train: 0.836011	val: 0.655433	test: 0.621856

Epoch: 49
Loss: 0.387941252725774
ROC train: 0.869852	val: 0.610220	test: 0.571786
PRC train: 0.831249	val: 0.661967	test: 0.612151

Epoch: 50
Loss: 0.39695586798916854
ROC train: 0.873490	val: 0.608741	test: 0.581586
PRC train: 0.836100	val: 0.646486	test: 0.619120

Epoch: 51
Loss: 0.38551082365855205
ROC train: 0.876869	val: 0.617710	test: 0.569282
PRC train: 0.836586	val: 0.652465	test: 0.611496

Epoch: 52
Loss: 0.3866408851951292
ROC train: 0.879104	val: 0.630191	test: 0.576823
PRC train: 0.838684	val: 0.662587	test: 0.614779

Epoch: 53
Loss: 0.3891067104550264
ROC train: 0.878598	val: 0.620496	test: 0.587426
PRC train: 0.839229	val: 0.651550	test: 0.620718

Epoch: 54
Loss: 0.3833249473489432
ROC train: 0.881671	val: 0.610824	test: 0.566625
PRC train: 0.839756	val: 0.650528	test: 0.609287

Epoch: 55
Loss: 0.37837173692113757
ROC train: 0.883147	val: 0.605436	test: 0.579790
PRC train: 0.840818	val: 0.652219	test: 0.615614

Epoch: 56
Loss: 0.3779400639435432
ROC train: 0.883937	val: 0.628964	test: 0.583041
PRC train: 0.841978	val: 0.661511	test: 0.617045

Epoch: 57
Loss: 0.3783415809641995
ROC train: 0.884694	val: 0.631174	test: 0.580161
PRC train: 0.845979	val: 0.660585	test: 0.615396

Epoch: 58
Loss: 0.37646942932659905
ROC train: 0.885824	val: 0.624345	test: 0.594121
PRC train: 0.848140	val: 0.658648	test: 0.622531

Epoch: 59
Loss: 0.37847056066265145
ROC train: 0.892143	val: 0.625219	test: 0.576190
PRC train: 0.852707	val: 0.664207	test: 0.611187

Epoch: 60
Loss: 0.3701791757916662
ROC train: 0.892035	val: 0.617004	test: 0.570945
PRC train: 0.852973	val: 0.662158	test: 0.615504

Epoch: 61
Loss: 0.3732636588901529
ROC train: 0.894298	val: 0.617383	test: 0.573646
PRC train: 0.854428	val: 0.661294	test: 0.614444

Epoch: 62
Loss: 0.36587316608169307
ROC train: 0.893674	val: 0.621351	test: 0.578469
PRC train: 0.856577	val: 0.663363	test: 0.615888

Epoch: 63
Loss: 0.3648543887188784
ROC train: 0.897489	val: 0.629554	test: 0.595838
PRC train: 0.857648	val: 0.659155	test: 0.626218

Epoch: 64
Loss: 0.3665712343452481
ROC train: 0.896536	val: 0.618421	test: 0.606701
PRC train: 0.854865	val: 0.655036	test: 0.629591

Epoch: 65
Loss: 0.36380570678728236
ROC train: 0.899551	val: 0.608643	test: 0.591314
PRC train: 0.860773	val: 0.654332	test: 0.623215

Epoch: 66
Loss: 0.35981746960840183
ROC train: 0.899525	val: 0.614015	test: 0.578038
PRC train: 0.861316	val: 0.655562	test: 0.615235

Epoch: 67
Loss: 0.35949610078646643
ROC train: 0.900354	val: 0.620008	test: 0.584182
PRC train: 0.862197	val: 0.658629	test: 0.619777

Epoch: 68
Loss: 0.35631658324508453
ROC train: 0.900774	val: 0.619726	test: 0.574543
PRC train: 0.864592	val: 0.666411	test: 0.614788

Epoch: 69
Loss: 0.35880295672374846
ROC train: 0.903259	val: 0.618416	test: 0.582913
PRC train: 0.866403	val: 0.663370	test: 0.620653

Epoch: 70
Loss: 0.35284136420472334
ROC train: 0.905766	val: 0.612620	test: 0.583457
PRC train: 0.868444	val: 0.652821	test: 0.622674

Epoch: 71
Loss: 0.35079492373622967
ROC train: 0.905787	val: 0.607196	test: 0.586690
PRC train: 0.868666	val: 0.661607	test: 0.622126

Epoch: 72
Loss: 0.34942280058081393
ROC train: 0.906047	val: 0.608457	test: 0.579524
PRC train: 0.870825	val: 0.659683	test: 0.618238

Epoch: 73
Loss: 0.34786908512198295
ROC train: 0.903821	val: 0.606729	test: 0.572287
PRC train: 0.866993	val: 0.651405	test: 0.609806

Epoch: 74
Loss: 0.35080106779251385
ROC train: 0.911446	val: 0.617775	test: 0.577444
PRC train: 0.877439	val: 0.661963	test: 0.619919

Epoch: 75
Loss: 0.35196249594113904
ROC train: 0.909978	val: 0.614072	test: 0.573495
PRC train: 0.872548	val: 0.660208	test: 0.614277

Epoch: 76
Loss: 0.34471652892016647
ROC train: 0.912937	val: 0.620538	test: 0.579646
PRC train: 0.876069	val: 0.661372	test: 0.618439

Epoch: 77
Loss: 0.34024687465849973
ROC train: 0.912031	val: 0.615673	test: 0.595469
PRC train: 0.875251	val: 0.660782	test: 0.628776

Epoch: 78
Loss: 0.34236260966829396
ROC train: 0.913948	val: 0.616320	test: 0.585440
PRC train: 0.881802	val: 0.666210	test: 0.618805

Epoch: 79
Loss: 0.3361929521305302
ROC train: 0.917006	val: 0.616256	test: 0.587347
PRC train: 0.883495	val: 0.659621	test: 0.625348

Epoch: 80
Loss: 0.3434121353716383
ROC train: 0.916997	val: 0.615530	test: 0.585589
PRC train: 0.886020	val: 0.664811	test: 0.624297

Epoch: 81
Loss: 0.3408990421395813
ROC train: 0.916219	val: 0.618101	test: 0.575930
PRC train: 0.886921	val: 0.666584	test: 0.619571

Epoch: 82
Loss: 0.3363297706597852
ROC train: 0.918286	val: 0.619151	test: 0.591188
PRC train: 0.885747	val: 0.661105	test: 0.628060

Epoch: 83
Loss: 0.34071420544802095
ROC train: 0.921791	val: 0.623473	test: 0.583146
PRC train: 0.887831	val: 0.665414	test: 0.620851

Epoch: 84
Loss: 0.33607473373520225
ROC train: 0.920826	val: 0.613751	test: 0.573835
PRC train: 0.886961	val: 0.663003	test: 0.614698

Epoch: 85
Loss: 0.33306450022656925
ROC train: 0.920999	val: 0.609703	test: 0.575605
PRC train: 0.887216	val: 0.660554	test: 0.616207

Epoch: 86
Loss: 0.3302740893379202
ROC train: 0.921108	val: 0.609068	test: 0.585135
PRC train: 0.886706	val: 0.661742	test: 0.621038

Epoch: 87
Loss: 0.33151053608709885
ROC train: 0.920899	val: 0.599031	test: 0.594173
PRC train: 0.885005	val: 0.656169	test: 0.625261

Epoch: 88
Loss: 0.3290581836199931
ROC train: 0.926596	val: 0.614289	test: 0.578086
PRC train: 0.892704	val: 0.661728	test: 0.616808

Epoch: 89
Loss: 0.32091615173670357
ROC train: 0.926714	val: 0.616429	test: 0.571050
PRC train: 0.893380	val: 0.656340	test: 0.613676

Epoch: 90
Loss: 0.3275241906486165
ROC train: 0.928884	val: 0.621842	test: 0.582647
PRC train: 0.895584	val: 0.662701	test: 0.622021

Epoch: 91
Loss: 0.320941741600188
ROC train: 0.927746	val: 0.621949	test: 0.604184
PRC train: 0.894073	val: 0.663398	test: 0.631507

Epoch: 92
Loss: 0.3209047790562977
ROC train: 0.929181	val: 0.617792	test: 0.593892
PRC train: 0.896298	val: 0.660598	test: 0.629934

Epoch: 93
Loss: 0.3197376019619194
ROC train: 0.931061	val: 0.610975	test: 0.570813
PRC train: 0.799640	val: 0.664881	test: 0.617670

Epoch: 33
Loss: 0.41572468310911337
ROC train: 0.847551	val: 0.583114	test: 0.590633
PRC train: 0.807284	val: 0.653713	test: 0.620981

Epoch: 34
Loss: 0.40955867037209864
ROC train: 0.848447	val: 0.585699	test: 0.589340
PRC train: 0.810788	val: 0.654482	test: 0.623999

Epoch: 35
Loss: 0.4060837293065654
ROC train: 0.849289	val: 0.597447	test: 0.577957
PRC train: 0.809737	val: 0.660927	test: 0.620701

Epoch: 36
Loss: 0.4089556862925475
ROC train: 0.853036	val: 0.595843	test: 0.580926
PRC train: 0.812003	val: 0.658592	test: 0.614610

Epoch: 37
Loss: 0.4066718162473684
ROC train: 0.856150	val: 0.600467	test: 0.559649
PRC train: 0.813049	val: 0.661413	test: 0.603174

Epoch: 38
Loss: 0.3976425667012834
ROC train: 0.856683	val: 0.602140	test: 0.573124
PRC train: 0.815836	val: 0.666031	test: 0.615419

Epoch: 39
Loss: 0.3964298245630564
ROC train: 0.861011	val: 0.601273	test: 0.567879
PRC train: 0.820353	val: 0.659432	test: 0.617563

Epoch: 40
Loss: 0.3938248907097749
ROC train: 0.858416	val: 0.608745	test: 0.548450
PRC train: 0.815711	val: 0.661402	test: 0.604092

Epoch: 41
Loss: 0.39807377312987524
ROC train: 0.857663	val: 0.601345	test: 0.569406
PRC train: 0.816020	val: 0.660385	test: 0.616448

Epoch: 42
Loss: 0.3931088258457961
ROC train: 0.864963	val: 0.597739	test: 0.564741
PRC train: 0.821921	val: 0.659775	test: 0.611342

Epoch: 43
Loss: 0.39448788466725243
ROC train: 0.868248	val: 0.602756	test: 0.572719
PRC train: 0.826065	val: 0.664156	test: 0.615555

Epoch: 44
Loss: 0.3895048042025773
ROC train: 0.872500	val: 0.610494	test: 0.582808
PRC train: 0.831826	val: 0.666340	test: 0.616630

Epoch: 45
Loss: 0.3889880848439596
ROC train: 0.873912	val: 0.611351	test: 0.572958
PRC train: 0.831953	val: 0.664568	test: 0.610389

Epoch: 46
Loss: 0.3817877571547901
ROC train: 0.873959	val: 0.611034	test: 0.581832
PRC train: 0.831075	val: 0.662347	test: 0.611848

Epoch: 47
Loss: 0.37696976577026514
ROC train: 0.875429	val: 0.611526	test: 0.578086
PRC train: 0.831393	val: 0.661386	test: 0.613900

Epoch: 48
Loss: 0.38014992845617324
ROC train: 0.878634	val: 0.607927	test: 0.573218
PRC train: 0.836067	val: 0.660983	test: 0.614958

Epoch: 49
Loss: 0.37667023416163103
ROC train: 0.879835	val: 0.607488	test: 0.574061
PRC train: 0.834527	val: 0.661077	test: 0.613195

Epoch: 50
Loss: 0.3775633846149413
ROC train: 0.883763	val: 0.604495	test: 0.572666
PRC train: 0.838947	val: 0.659153	test: 0.618446

Epoch: 51
Loss: 0.3743519002916821
ROC train: 0.883601	val: 0.583940	test: 0.581088
PRC train: 0.839366	val: 0.654684	test: 0.626736

Epoch: 52
Loss: 0.37505383219102123
ROC train: 0.887149	val: 0.583521	test: 0.583398
PRC train: 0.842844	val: 0.656289	test: 0.624517

Epoch: 53
Loss: 0.3677794092043556
ROC train: 0.888341	val: 0.600979	test: 0.573228
PRC train: 0.843907	val: 0.661541	test: 0.616217

Epoch: 54
Loss: 0.3717861417448782
ROC train: 0.887489	val: 0.598599	test: 0.562087
PRC train: 0.843388	val: 0.659562	test: 0.610388

Epoch: 55
Loss: 0.36944314360941843
ROC train: 0.889730	val: 0.595306	test: 0.576046
PRC train: 0.843355	val: 0.661543	test: 0.618352

Epoch: 56
Loss: 0.36872789215596985
ROC train: 0.894171	val: 0.600654	test: 0.580411
PRC train: 0.849463	val: 0.661771	test: 0.618677

Epoch: 57
Loss: 0.36807624731348465
ROC train: 0.896372	val: 0.610817	test: 0.579443
PRC train: 0.852283	val: 0.665743	test: 0.615120

Epoch: 58
Loss: 0.3638107754829897
ROC train: 0.895047	val: 0.610448	test: 0.582920
PRC train: 0.850980	val: 0.666296	test: 0.617023

Epoch: 59
Loss: 0.36863235955384877
ROC train: 0.899144	val: 0.605054	test: 0.584014
PRC train: 0.855264	val: 0.666827	test: 0.620175

Epoch: 60
Loss: 0.36119752212352474
ROC train: 0.899570	val: 0.601652	test: 0.587783
PRC train: 0.855224	val: 0.662883	test: 0.620339

Epoch: 61
Loss: 0.3580407596006269
ROC train: 0.899081	val: 0.600417	test: 0.581514
PRC train: 0.854854	val: 0.661490	test: 0.614012

Epoch: 62
Loss: 0.35479596415302955
ROC train: 0.898668	val: 0.599488	test: 0.572364
PRC train: 0.854202	val: 0.661212	test: 0.616331

Epoch: 63
Loss: 0.35358318962324964
ROC train: 0.900631	val: 0.596266	test: 0.576420
PRC train: 0.856784	val: 0.658008	test: 0.617042

Epoch: 64
Loss: 0.35301732252327417
ROC train: 0.901990	val: 0.595688	test: 0.580273
PRC train: 0.856623	val: 0.659102	test: 0.618366

Epoch: 65
Loss: 0.3514650745443764
ROC train: 0.901560	val: 0.599457	test: 0.574594
PRC train: 0.853073	val: 0.660332	test: 0.616628

Epoch: 66
Loss: 0.34982571139355895
ROC train: 0.906589	val: 0.598448	test: 0.576413
PRC train: 0.859672	val: 0.659462	test: 0.612864

Epoch: 67
Loss: 0.347098741695145
ROC train: 0.908393	val: 0.596652	test: 0.576490
PRC train: 0.864196	val: 0.656312	test: 0.615080

Epoch: 68
Loss: 0.3438126790151815
ROC train: 0.910356	val: 0.602530	test: 0.581162
PRC train: 0.866120	val: 0.658609	test: 0.613759

Epoch: 69
Loss: 0.3453675479066545
ROC train: 0.911791	val: 0.604946	test: 0.583591
PRC train: 0.866312	val: 0.659002	test: 0.614935

Epoch: 70
Loss: 0.3441381739667465
ROC train: 0.912425	val: 0.602213	test: 0.582350
PRC train: 0.868949	val: 0.656945	test: 0.613465

Epoch: 71
Loss: 0.34262425240196726
ROC train: 0.913942	val: 0.598918	test: 0.571406
PRC train: 0.871420	val: 0.655842	test: 0.611317

Epoch: 72
Loss: 0.3390157562769535
ROC train: 0.915563	val: 0.601373	test: 0.570388
PRC train: 0.874541	val: 0.658738	test: 0.614105

Epoch: 73
Loss: 0.33939425723444294
ROC train: 0.914656	val: 0.608256	test: 0.565535
PRC train: 0.872998	val: 0.665263	test: 0.613574

Epoch: 74
Loss: 0.33765072024485343
ROC train: 0.916467	val: 0.606953	test: 0.569153
PRC train: 0.872365	val: 0.662163	test: 0.611548

Epoch: 75
Loss: 0.33711008365347306
ROC train: 0.917595	val: 0.601084	test: 0.576170
PRC train: 0.873849	val: 0.659422	test: 0.608390

Epoch: 76
Loss: 0.3334686370017653
ROC train: 0.920208	val: 0.602193	test: 0.584865
PRC train: 0.877511	val: 0.659247	test: 0.611948

Epoch: 77
Loss: 0.3310337255767185
ROC train: 0.919942	val: 0.609166	test: 0.587121
PRC train: 0.878487	val: 0.662217	test: 0.615528

Epoch: 78
Loss: 0.33787947645344635
ROC train: 0.920324	val: 0.605768	test: 0.581291
PRC train: 0.880243	val: 0.663920	test: 0.616455

Epoch: 79
Loss: 0.33120378371466375
ROC train: 0.924147	val: 0.602656	test: 0.575287
PRC train: 0.887668	val: 0.661115	test: 0.614351

Epoch: 80
Loss: 0.33230994267039027
ROC train: 0.923908	val: 0.597078	test: 0.569128
PRC train: 0.888099	val: 0.658943	test: 0.616857

Epoch: 81
Loss: 0.3255418718660442
ROC train: 0.923817	val: 0.604473	test: 0.575382
PRC train: 0.887303	val: 0.659305	test: 0.616364

Epoch: 82
Loss: 0.32282552493146394
ROC train: 0.925543	val: 0.600991	test: 0.579111
PRC train: 0.887439	val: 0.657205	test: 0.615792

Epoch: 83
Loss: 0.32060522576572137
ROC train: 0.928109	val: 0.598940	test: 0.574462
PRC train: 0.890715	val: 0.659276	test: 0.615101

Epoch: 84
Loss: 0.31733239417697856
ROC train: 0.931819	val: 0.593646	test: 0.575767
PRC train: 0.898336	val: 0.656587	test: 0.617869

Epoch: 85
Loss: 0.32182291032864735
ROC train: 0.932783	val: 0.594493	test: 0.578115
PRC train: 0.903348	val: 0.655496	test: 0.617465

Epoch: 86
Loss: 0.318946750951016
ROC train: 0.932020	val: 0.602481	test: 0.575492
PRC train: 0.903481	val: 0.657752	test: 0.612840

Epoch: 87
Loss: 0.31167108198730054
ROC train: 0.932163	val: 0.599328	test: 0.572130
PRC train: 0.901780	val: 0.657208	test: 0.611479

Epoch: 88
Loss: 0.32015129128687436
ROC train: 0.933445	val: 0.595206	test: 0.571255
PRC train: 0.904538	val: 0.657054	test: 0.613846

Epoch: 89
Loss: 0.31834007874944636
ROC train: 0.935805	val: 0.598206	test: 0.571246
PRC train: 0.907480	val: 0.658009	test: 0.616240

Epoch: 90
Loss: 0.31314388819514943
ROC train: 0.936239	val: 0.601149	test: 0.568643
PRC train: 0.909310	val: 0.659419	test: 0.616079

Epoch: 91
Loss: 0.3106580718249283
ROC train: 0.936761	val: 0.604163	test: 0.571910
PRC train: 0.911087	val: 0.657850	test: 0.617223

Epoch: 92
Loss: 0.3166647078752046
ROC train: 0.937778	val: 0.596528	test: 0.582969
PRC train: 0.911874	val: 0.655512	test: 0.620509

Epoch: 93
Loss: 0.3080175558434298
ROC train: 0.937770	val: 0.590277	test: 0.583442
PRC train: 0.792478	val: 0.621182	test: 0.606714

Epoch: 33
Loss: 0.4220145166476283
ROC train: 0.844822	val: 0.520631	test: 0.538305
PRC train: 0.803509	val: 0.617072	test: 0.598207

Epoch: 34
Loss: 0.4140360760211089
ROC train: 0.845983	val: 0.531478	test: 0.535083
PRC train: 0.804800	val: 0.621959	test: 0.594255

Epoch: 35
Loss: 0.40918215414881437
ROC train: 0.843656	val: 0.533781	test: 0.527069
PRC train: 0.805178	val: 0.623254	test: 0.591251

Epoch: 36
Loss: 0.4126355984389588
ROC train: 0.851833	val: 0.537431	test: 0.543711
PRC train: 0.811366	val: 0.626707	test: 0.596650

Epoch: 37
Loss: 0.4083707276546963
ROC train: 0.856417	val: 0.542487	test: 0.544728
PRC train: 0.811739	val: 0.627903	test: 0.598901

Epoch: 38
Loss: 0.4027374793788588
ROC train: 0.863303	val: 0.528086	test: 0.537219
PRC train: 0.820501	val: 0.627688	test: 0.596218

Epoch: 39
Loss: 0.4058366661065291
ROC train: 0.863864	val: 0.521460	test: 0.532511
PRC train: 0.824865	val: 0.623990	test: 0.592190

Epoch: 40
Loss: 0.4040068848769887
ROC train: 0.867609	val: 0.525418	test: 0.527666
PRC train: 0.827648	val: 0.619302	test: 0.586672

Epoch: 41
Loss: 0.3967350381471598
ROC train: 0.868220	val: 0.514113	test: 0.535749
PRC train: 0.828424	val: 0.614273	test: 0.590757

Epoch: 42
Loss: 0.3991924560216997
ROC train: 0.866720	val: 0.512363	test: 0.545626
PRC train: 0.825987	val: 0.616541	test: 0.596071

Epoch: 43
Loss: 0.3991480937446453
ROC train: 0.870100	val: 0.511279	test: 0.548904
PRC train: 0.827564	val: 0.619919	test: 0.595892

Epoch: 44
Loss: 0.39190684263197395
ROC train: 0.874994	val: 0.521033	test: 0.538569
PRC train: 0.831257	val: 0.623798	test: 0.591172

Epoch: 45
Loss: 0.38942198503988035
ROC train: 0.874394	val: 0.526432	test: 0.533987
PRC train: 0.830275	val: 0.623346	test: 0.590490

Epoch: 46
Loss: 0.39087558933985744
ROC train: 0.875575	val: 0.522192	test: 0.540165
PRC train: 0.834297	val: 0.621575	test: 0.593225

Epoch: 47
Loss: 0.3903536904080759
ROC train: 0.879948	val: 0.512918	test: 0.543941
PRC train: 0.838718	val: 0.617844	test: 0.597894

Epoch: 48
Loss: 0.38309808254497096
ROC train: 0.882536	val: 0.519551	test: 0.555336
PRC train: 0.840475	val: 0.618855	test: 0.605280

Epoch: 49
Loss: 0.38185210379884743
ROC train: 0.884382	val: 0.533693	test: 0.559039
PRC train: 0.841356	val: 0.618294	test: 0.607360

Epoch: 50
Loss: 0.3725785797857471
ROC train: 0.884375	val: 0.548076	test: 0.541141
PRC train: 0.843174	val: 0.624715	test: 0.599215

Epoch: 51
Loss: 0.3755811202981792
ROC train: 0.885596	val: 0.548563	test: 0.540549
PRC train: 0.844826	val: 0.622157	test: 0.600556

Epoch: 52
Loss: 0.37795622361767295
ROC train: 0.885832	val: 0.541078	test: 0.528245
PRC train: 0.846101	val: 0.623011	test: 0.591423

Epoch: 53
Loss: 0.3747528395953505
ROC train: 0.886365	val: 0.535428	test: 0.536537
PRC train: 0.845420	val: 0.621164	test: 0.595363

Epoch: 54
Loss: 0.37531807364989755
ROC train: 0.887708	val: 0.526646	test: 0.551239
PRC train: 0.844359	val: 0.611423	test: 0.605503

Epoch: 55
Loss: 0.37452935765568396
ROC train: 0.888183	val: 0.529148	test: 0.543658
PRC train: 0.847177	val: 0.619470	test: 0.597041

Epoch: 56
Loss: 0.3688478453934239
ROC train: 0.889890	val: 0.524751	test: 0.558128
PRC train: 0.851668	val: 0.613869	test: 0.602840

Epoch: 57
Loss: 0.37057062125976514
ROC train: 0.893701	val: 0.524185	test: 0.565400
PRC train: 0.852027	val: 0.616648	test: 0.606177

Epoch: 58
Loss: 0.3662716389178956
ROC train: 0.893271	val: 0.530776	test: 0.551765
PRC train: 0.850766	val: 0.621543	test: 0.600222

Epoch: 59
Loss: 0.36776894501108737
ROC train: 0.899011	val: 0.525017	test: 0.560542
PRC train: 0.858201	val: 0.617801	test: 0.608330

Epoch: 60
Loss: 0.3623824757984757
ROC train: 0.899746	val: 0.528968	test: 0.555654
PRC train: 0.860594	val: 0.620581	test: 0.605923

Epoch: 61
Loss: 0.3604271078095199
ROC train: 0.898730	val: 0.535014	test: 0.553951
PRC train: 0.857412	val: 0.626717	test: 0.606448

Epoch: 62
Loss: 0.360215141481003
ROC train: 0.900945	val: 0.537627	test: 0.541881
PRC train: 0.857621	val: 0.625416	test: 0.599480

Epoch: 63
Loss: 0.35508707351616114
ROC train: 0.898910	val: 0.535598	test: 0.538625
PRC train: 0.858192	val: 0.621735	test: 0.597107

Epoch: 64
Loss: 0.36101005664444846
ROC train: 0.902872	val: 0.543528	test: 0.535871
PRC train: 0.862884	val: 0.619061	test: 0.597083

Epoch: 65
Loss: 0.35146397101299937
ROC train: 0.902883	val: 0.531844	test: 0.548983
PRC train: 0.862989	val: 0.614020	test: 0.601537

Epoch: 66
Loss: 0.35811978658616694
ROC train: 0.901113	val: 0.523014	test: 0.555115
PRC train: 0.865175	val: 0.615896	test: 0.602754

Epoch: 67
Loss: 0.35408078814916893
ROC train: 0.905875	val: 0.506022	test: 0.557848
PRC train: 0.866404	val: 0.605950	test: 0.606837

Epoch: 68
Loss: 0.34678657696210524
ROC train: 0.906801	val: 0.528474	test: 0.548500
PRC train: 0.867451	val: 0.617085	test: 0.600174

Epoch: 69
Loss: 0.3447322046065021
ROC train: 0.906324	val: 0.528553	test: 0.545442
PRC train: 0.867755	val: 0.616877	test: 0.599647

Epoch: 70
Loss: 0.3433157925040251
ROC train: 0.907585	val: 0.524021	test: 0.545846
PRC train: 0.870990	val: 0.613324	test: 0.599312

Epoch: 71
Loss: 0.3434720609859106
ROC train: 0.908928	val: 0.517090	test: 0.559550
PRC train: 0.871095	val: 0.612335	test: 0.605646

Epoch: 72
Loss: 0.34216121019809614
ROC train: 0.911657	val: 0.524753	test: 0.554887
PRC train: 0.873153	val: 0.610296	test: 0.604766

Epoch: 73
Loss: 0.34102543549039954
ROC train: 0.913358	val: 0.535240	test: 0.538855
PRC train: 0.873785	val: 0.617112	test: 0.600342

Epoch: 74
Loss: 0.33843350355118806
ROC train: 0.915454	val: 0.536752	test: 0.538853
PRC train: 0.877610	val: 0.620395	test: 0.601402

Epoch: 75
Loss: 0.3415707142942964
ROC train: 0.916543	val: 0.525010	test: 0.552463
PRC train: 0.879814	val: 0.613609	test: 0.605760

Epoch: 76
Loss: 0.339258767981213
ROC train: 0.915433	val: 0.524034	test: 0.556892
PRC train: 0.879260	val: 0.615559	test: 0.608879

Epoch: 77
Loss: 0.33576582203558464
ROC train: 0.918104	val: 0.509503	test: 0.565392
PRC train: 0.881661	val: 0.608954	test: 0.611750

Epoch: 78
Loss: 0.3370167230981538
ROC train: 0.915947	val: 0.507540	test: 0.557152
PRC train: 0.881073	val: 0.603961	test: 0.606140

Epoch: 79
Loss: 0.33785188728885446
ROC train: 0.917198	val: 0.521643	test: 0.546568
PRC train: 0.882147	val: 0.611226	test: 0.601098

Epoch: 80
Loss: 0.33690367922534514
ROC train: 0.921530	val: 0.514542	test: 0.536842
PRC train: 0.885406	val: 0.607688	test: 0.596442

Epoch: 81
Loss: 0.3322118164090586
ROC train: 0.918861	val: 0.510209	test: 0.534105
PRC train: 0.884118	val: 0.609764	test: 0.596452

Epoch: 82
Loss: 0.33225983947670296
ROC train: 0.922245	val: 0.511281	test: 0.539707
PRC train: 0.887210	val: 0.606703	test: 0.598893

Epoch: 83
Loss: 0.32887352908131967
ROC train: 0.922667	val: 0.508959	test: 0.544968
PRC train: 0.885539	val: 0.602489	test: 0.598854

Epoch: 84
Loss: 0.33087272821037944
ROC train: 0.924053	val: 0.521468	test: 0.534239
PRC train: 0.888624	val: 0.614678	test: 0.594904

Epoch: 85
Loss: 0.3222069948020998
ROC train: 0.923222	val: 0.525180	test: 0.539800
PRC train: 0.888688	val: 0.617252	test: 0.599272

Epoch: 86
Loss: 0.32670668049022467
ROC train: 0.927253	val: 0.529283	test: 0.554169
PRC train: 0.893133	val: 0.614230	test: 0.605113

Epoch: 87
Loss: 0.3216037971021014
ROC train: 0.928983	val: 0.524437	test: 0.559912
PRC train: 0.892103	val: 0.613005	test: 0.608479

Epoch: 88
Loss: 0.31819952105440297
ROC train: 0.929381	val: 0.520318	test: 0.554249
PRC train: 0.894535	val: 0.608095	test: 0.606369

Epoch: 89
Loss: 0.3170112865305594
ROC train: 0.930012	val: 0.513478	test: 0.555789
PRC train: 0.897874	val: 0.603743	test: 0.607040

Epoch: 90
Loss: 0.3187276603829722
ROC train: 0.929936	val: 0.531934	test: 0.552712
PRC train: 0.897458	val: 0.617246	test: 0.605509

Epoch: 91
Loss: 0.31337993600074876
ROC train: 0.930624	val: 0.536844	test: 0.556485
PRC train: 0.896550	val: 0.622690	test: 0.608030

Epoch: 92
Loss: 0.3134866736121279
ROC train: 0.933017	val: 0.539442	test: 0.553359
PRC train: 0.900599	val: 0.623436	test: 0.605542

Epoch: 93
Loss: 0.31362787509702106
ROC train: 0.934056	val: 0.543114	test: 0.547799
PRC train: 0.785489	val: 0.668940	test: 0.629393

Epoch: 33
Loss: 0.43290714937476765
ROC train: 0.825437	val: 0.626769	test: 0.609826
PRC train: 0.784573	val: 0.666691	test: 0.635134

Epoch: 34
Loss: 0.42970843030980044
ROC train: 0.826361	val: 0.623932	test: 0.605809
PRC train: 0.784935	val: 0.664590	test: 0.637770

Epoch: 35
Loss: 0.4222021542886882
ROC train: 0.840111	val: 0.630422	test: 0.590664
PRC train: 0.798828	val: 0.668656	test: 0.627756

Epoch: 36
Loss: 0.4243463064193069
ROC train: 0.841914	val: 0.618678	test: 0.593058
PRC train: 0.801363	val: 0.668378	test: 0.625545

Epoch: 37
Loss: 0.416614776789448
ROC train: 0.841938	val: 0.623874	test: 0.596685
PRC train: 0.799791	val: 0.667646	test: 0.631304

Epoch: 38
Loss: 0.424032250513892
ROC train: 0.844753	val: 0.620660	test: 0.603225
PRC train: 0.801257	val: 0.661912	test: 0.633217

Epoch: 39
Loss: 0.4156405185321727
ROC train: 0.848383	val: 0.624637	test: 0.599381
PRC train: 0.808647	val: 0.667715	test: 0.623648

Epoch: 40
Loss: 0.4167149136779303
ROC train: 0.848783	val: 0.620039	test: 0.604129
PRC train: 0.806116	val: 0.664143	test: 0.632110

Epoch: 41
Loss: 0.40958801983554477
ROC train: 0.849640	val: 0.624597	test: 0.599324
PRC train: 0.805760	val: 0.663421	test: 0.632532

Epoch: 42
Loss: 0.4103564894111648
ROC train: 0.853044	val: 0.613897	test: 0.602600
PRC train: 0.808703	val: 0.660018	test: 0.633072

Epoch: 43
Loss: 0.4070533636415569
ROC train: 0.852767	val: 0.618824	test: 0.603095
PRC train: 0.811065	val: 0.665229	test: 0.631392

Epoch: 44
Loss: 0.40748397412123605
ROC train: 0.855538	val: 0.617989	test: 0.610958
PRC train: 0.812537	val: 0.666154	test: 0.630629

Epoch: 45
Loss: 0.39832572682801326
ROC train: 0.857989	val: 0.613804	test: 0.610467
PRC train: 0.814549	val: 0.662098	test: 0.635209

Epoch: 46
Loss: 0.404427901048311
ROC train: 0.863399	val: 0.613175	test: 0.603555
PRC train: 0.820773	val: 0.665320	test: 0.633584

Epoch: 47
Loss: 0.40428034423027787
ROC train: 0.865084	val: 0.607967	test: 0.609632
PRC train: 0.820501	val: 0.666154	test: 0.631681

Epoch: 48
Loss: 0.39196276369613037
ROC train: 0.870437	val: 0.615287	test: 0.609068
PRC train: 0.826630	val: 0.667222	test: 0.629954

Epoch: 49
Loss: 0.3984188690278672
ROC train: 0.869140	val: 0.627920	test: 0.610193
PRC train: 0.825950	val: 0.669505	test: 0.635787

Epoch: 50
Loss: 0.38845899578625576
ROC train: 0.864176	val: 0.618520	test: 0.609953
PRC train: 0.820293	val: 0.668222	test: 0.640431

Epoch: 51
Loss: 0.3903045748527202
ROC train: 0.873702	val: 0.613831	test: 0.602521
PRC train: 0.832758	val: 0.667026	test: 0.628458

Epoch: 52
Loss: 0.3903616432500524
ROC train: 0.876045	val: 0.620598	test: 0.596286
PRC train: 0.830911	val: 0.666350	test: 0.633089

Epoch: 53
Loss: 0.39248914056656103
ROC train: 0.880150	val: 0.622538	test: 0.599881
PRC train: 0.837995	val: 0.666128	test: 0.634651

Epoch: 54
Loss: 0.38239847215760825
ROC train: 0.882057	val: 0.624962	test: 0.597019
PRC train: 0.840093	val: 0.669377	test: 0.630076

Epoch: 55
Loss: 0.38869047430405607
ROC train: 0.881240	val: 0.618347	test: 0.600311
PRC train: 0.841049	val: 0.666575	test: 0.627799

Epoch: 56
Loss: 0.37938655531228593
ROC train: 0.882437	val: 0.614276	test: 0.591870
PRC train: 0.841628	val: 0.664542	test: 0.621925

Epoch: 57
Loss: 0.37910807211256153
ROC train: 0.887408	val: 0.623682	test: 0.588134
PRC train: 0.845011	val: 0.670163	test: 0.623963

Epoch: 58
Loss: 0.3709032239902452
ROC train: 0.883576	val: 0.624337	test: 0.590283
PRC train: 0.843413	val: 0.672340	test: 0.631654

Epoch: 59
Loss: 0.3732843470876896
ROC train: 0.882877	val: 0.620216	test: 0.596822
PRC train: 0.843317	val: 0.676189	test: 0.630216

Epoch: 60
Loss: 0.37409040989223724
ROC train: 0.889857	val: 0.622336	test: 0.589608
PRC train: 0.853450	val: 0.677802	test: 0.622723

Epoch: 61
Loss: 0.376312401886852
ROC train: 0.889817	val: 0.636285	test: 0.589840
PRC train: 0.848792	val: 0.681549	test: 0.628272

Epoch: 62
Loss: 0.37347985561146363
ROC train: 0.889294	val: 0.646080	test: 0.589192
PRC train: 0.848186	val: 0.686046	test: 0.631195

Epoch: 63
Loss: 0.3748220781209885
ROC train: 0.894656	val: 0.632651	test: 0.592459
PRC train: 0.851679	val: 0.676158	test: 0.624691

Epoch: 64
Loss: 0.36932148482067967
ROC train: 0.891235	val: 0.635535	test: 0.596314
PRC train: 0.846545	val: 0.675346	test: 0.635961

Epoch: 65
Loss: 0.3720273331449392
ROC train: 0.897841	val: 0.623440	test: 0.602843
PRC train: 0.856019	val: 0.672477	test: 0.632444

Epoch: 66
Loss: 0.3684841368136865
ROC train: 0.893945	val: 0.623163	test: 0.604400
PRC train: 0.854678	val: 0.673071	test: 0.625174

Epoch: 67
Loss: 0.36355159745207627
ROC train: 0.898947	val: 0.625312	test: 0.616703
PRC train: 0.857714	val: 0.674193	test: 0.641803

Epoch: 68
Loss: 0.35930979201518365
ROC train: 0.900273	val: 0.628600	test: 0.604037
PRC train: 0.857653	val: 0.673355	test: 0.638183

Epoch: 69
Loss: 0.3571049639302716
ROC train: 0.898751	val: 0.633993	test: 0.602801
PRC train: 0.855012	val: 0.676583	test: 0.631099

Epoch: 70
Loss: 0.3563230704245476
ROC train: 0.901646	val: 0.624855	test: 0.605246
PRC train: 0.859800	val: 0.672285	test: 0.636580

Epoch: 71
Loss: 0.3566535419989615
ROC train: 0.900596	val: 0.629074	test: 0.603703
PRC train: 0.859832	val: 0.675477	test: 0.636318

Epoch: 72
Loss: 0.35942047981745395
ROC train: 0.904819	val: 0.621964	test: 0.603704
PRC train: 0.862006	val: 0.670650	test: 0.628568

Epoch: 73
Loss: 0.3524278376700822
ROC train: 0.905256	val: 0.626676	test: 0.597465
PRC train: 0.858165	val: 0.674373	test: 0.624610

Epoch: 74
Loss: 0.3575205847149334
ROC train: 0.904758	val: 0.634181	test: 0.599102
PRC train: 0.858705	val: 0.678929	test: 0.633751

Epoch: 75
Loss: 0.3479877709762076
ROC train: 0.905134	val: 0.629482	test: 0.593607
PRC train: 0.862801	val: 0.673979	test: 0.636459

Epoch: 76
Loss: 0.3518836051845269
ROC train: 0.906373	val: 0.629175	test: 0.587821
PRC train: 0.862475	val: 0.678720	test: 0.627512

Epoch: 77
Loss: 0.34813658690700117
ROC train: 0.911951	val: 0.631573	test: 0.592915
PRC train: 0.869265	val: 0.679614	test: 0.628529

Epoch: 78
Loss: 0.35119225301791507
ROC train: 0.914877	val: 0.625396	test: 0.598232
PRC train: 0.872608	val: 0.679779	test: 0.632169

Epoch: 79
Loss: 0.3406191621773931
ROC train: 0.909574	val: 0.613817	test: 0.607587
PRC train: 0.871710	val: 0.675013	test: 0.635512

Epoch: 80
Loss: 0.34647633423483926
ROC train: 0.914824	val: 0.618861	test: 0.605777
PRC train: 0.876119	val: 0.668750	test: 0.636813

Epoch: 81
Loss: 0.3423160294973848
ROC train: 0.914743	val: 0.627628	test: 0.592388
PRC train: 0.873430	val: 0.671162	test: 0.628464

Epoch: 82
Loss: 0.34282333364046597
ROC train: 0.916664	val: 0.634351	test: 0.584103
PRC train: 0.874753	val: 0.673202	test: 0.623779

Epoch: 83
Loss: 0.33841914109720284
ROC train: 0.915634	val: 0.627202	test: 0.584560
PRC train: 0.873767	val: 0.670803	test: 0.623075

Epoch: 84
Loss: 0.3360200742717747
ROC train: 0.919226	val: 0.630927	test: 0.588100
PRC train: 0.878181	val: 0.677445	test: 0.624487

Epoch: 85
Loss: 0.33481040332616446
ROC train: 0.918332	val: 0.634887	test: 0.598370
PRC train: 0.875466	val: 0.681398	test: 0.627725

Epoch: 86
Loss: 0.33625504961461794
ROC train: 0.920992	val: 0.632506	test: 0.605780
PRC train: 0.883144	val: 0.679575	test: 0.627204

Epoch: 87
Loss: 0.33598897765855384
ROC train: 0.923181	val: 0.637893	test: 0.609071
PRC train: 0.885826	val: 0.680370	test: 0.631749

Epoch: 88
Loss: 0.3325053990754262
ROC train: 0.923089	val: 0.630162	test: 0.606976
PRC train: 0.883688	val: 0.676117	test: 0.631451

Epoch: 89
Loss: 0.3263135548899444
ROC train: 0.924418	val: 0.631562	test: 0.595822
PRC train: 0.885264	val: 0.676418	test: 0.627958

Epoch: 90
Loss: 0.3309633539097702
ROC train: 0.924715	val: 0.642664	test: 0.592294
PRC train: 0.887747	val: 0.679811	test: 0.627946

Epoch: 91
Loss: 0.32521700055729214
ROC train: 0.924822	val: 0.644512	test: 0.599712
PRC train: 0.884766	val: 0.682257	test: 0.633431

Epoch: 92
Loss: 0.3285810362407765
ROC train: 0.926576	val: 0.639982	test: 0.605294
PRC train: 0.886226	val: 0.682088	test: 0.637037

Epoch: 93
Loss: 0.3252904429715152
ROC train: 0.925734	val: 0.637297	test: 0.603280
PRC train: 0.800951	val: 0.642308	test: 0.595901

Epoch: 33
Loss: 0.4163841441919088
ROC train: 0.844781	val: 0.558393	test: 0.544389
PRC train: 0.806053	val: 0.631877	test: 0.598271

Epoch: 34
Loss: 0.41155532864806715
ROC train: 0.840959	val: 0.556710	test: 0.545558
PRC train: 0.802564	val: 0.625140	test: 0.596215

Epoch: 35
Loss: 0.4128989118854326
ROC train: 0.847314	val: 0.554725	test: 0.547937
PRC train: 0.809701	val: 0.634348	test: 0.601416

Epoch: 36
Loss: 0.4097236298238446
ROC train: 0.844453	val: 0.562434	test: 0.547813
PRC train: 0.807303	val: 0.635937	test: 0.603647

Epoch: 37
Loss: 0.4084548737865317
ROC train: 0.853801	val: 0.558628	test: 0.551896
PRC train: 0.815786	val: 0.631174	test: 0.604957

Epoch: 38
Loss: 0.40959368172660443
ROC train: 0.852053	val: 0.564535	test: 0.554396
PRC train: 0.813497	val: 0.632227	test: 0.607759

Epoch: 39
Loss: 0.4015434913295904
ROC train: 0.855852	val: 0.557308	test: 0.566148
PRC train: 0.815323	val: 0.632644	test: 0.609653

Epoch: 40
Loss: 0.3973946826140467
ROC train: 0.862325	val: 0.560959	test: 0.565493
PRC train: 0.824108	val: 0.637487	test: 0.605003

Epoch: 41
Loss: 0.39839717376744205
ROC train: 0.859660	val: 0.569484	test: 0.567139
PRC train: 0.821131	val: 0.634942	test: 0.604210

Epoch: 42
Loss: 0.3971189242332887
ROC train: 0.865103	val: 0.559373	test: 0.563379
PRC train: 0.824199	val: 0.629736	test: 0.601095

Epoch: 43
Loss: 0.3909898185261307
ROC train: 0.870750	val: 0.559038	test: 0.553461
PRC train: 0.830357	val: 0.629450	test: 0.595443

Epoch: 44
Loss: 0.38738240332572005
ROC train: 0.867953	val: 0.570292	test: 0.543706
PRC train: 0.829415	val: 0.634471	test: 0.590368

Epoch: 45
Loss: 0.388638480201474
ROC train: 0.873532	val: 0.557282	test: 0.554811
PRC train: 0.836687	val: 0.630932	test: 0.600638

Epoch: 46
Loss: 0.3861545417952862
ROC train: 0.866924	val: 0.570605	test: 0.550437
PRC train: 0.828649	val: 0.639649	test: 0.607910

Epoch: 47
Loss: 0.38556965651907127
ROC train: 0.869913	val: 0.568830	test: 0.558438
PRC train: 0.830194	val: 0.639712	test: 0.608528

Epoch: 48
Loss: 0.38478830288900634
ROC train: 0.879482	val: 0.555803	test: 0.572884
PRC train: 0.841446	val: 0.634016	test: 0.614826

Epoch: 49
Loss: 0.3763811810791199
ROC train: 0.876287	val: 0.558216	test: 0.574440
PRC train: 0.837019	val: 0.641523	test: 0.613387

Epoch: 50
Loss: 0.37774103721715957
ROC train: 0.883678	val: 0.546300	test: 0.581517
PRC train: 0.845776	val: 0.633363	test: 0.615281

Epoch: 51
Loss: 0.3764548813302567
ROC train: 0.884363	val: 0.545747	test: 0.560329
PRC train: 0.848623	val: 0.620097	test: 0.607861

Epoch: 52
Loss: 0.3730024181042189
ROC train: 0.882156	val: 0.557797	test: 0.565999
PRC train: 0.844562	val: 0.628886	test: 0.607220

Epoch: 53
Loss: 0.37381834761131627
ROC train: 0.886277	val: 0.557292	test: 0.569845
PRC train: 0.848294	val: 0.628991	test: 0.612030

Epoch: 54
Loss: 0.3725799905484573
ROC train: 0.889212	val: 0.561927	test: 0.569145
PRC train: 0.850979	val: 0.632562	test: 0.609096

Epoch: 55
Loss: 0.3690366549351707
ROC train: 0.889511	val: 0.549101	test: 0.575282
PRC train: 0.850748	val: 0.626901	test: 0.608671

Epoch: 56
Loss: 0.36778602759705364
ROC train: 0.892315	val: 0.552267	test: 0.570554
PRC train: 0.855071	val: 0.626371	test: 0.608836

Epoch: 57
Loss: 0.37016989466242867
ROC train: 0.889999	val: 0.570194	test: 0.556581
PRC train: 0.851644	val: 0.640164	test: 0.603284

Epoch: 58
Loss: 0.36915051309965713
ROC train: 0.893014	val: 0.560503	test: 0.562146
PRC train: 0.855101	val: 0.635129	test: 0.611968

Epoch: 59
Loss: 0.36775261398331194
ROC train: 0.897723	val: 0.546972	test: 0.561139
PRC train: 0.862109	val: 0.625856	test: 0.607948

Epoch: 60
Loss: 0.3636983464848925
ROC train: 0.896006	val: 0.547855	test: 0.558987
PRC train: 0.860518	val: 0.633109	test: 0.604307

Epoch: 61
Loss: 0.3611438999328409
ROC train: 0.899212	val: 0.550757	test: 0.559273
PRC train: 0.863395	val: 0.632247	test: 0.608732

Epoch: 62
Loss: 0.35629509906414447
ROC train: 0.892388	val: 0.565217	test: 0.545529
PRC train: 0.855586	val: 0.635524	test: 0.605873

Epoch: 63
Loss: 0.3544676299450105
ROC train: 0.897319	val: 0.565945	test: 0.541302
PRC train: 0.863616	val: 0.636742	test: 0.599652

Epoch: 64
Loss: 0.35686734921454366
ROC train: 0.902939	val: 0.542194	test: 0.548556
PRC train: 0.867050	val: 0.617244	test: 0.595869

Epoch: 65
Loss: 0.3576516195898313
ROC train: 0.902240	val: 0.552115	test: 0.553127
PRC train: 0.865896	val: 0.623780	test: 0.597549

Epoch: 66
Loss: 0.3508552137209627
ROC train: 0.904712	val: 0.551649	test: 0.565153
PRC train: 0.868963	val: 0.628688	test: 0.605159

Epoch: 67
Loss: 0.3490838721599691
ROC train: 0.904770	val: 0.562027	test: 0.560273
PRC train: 0.867736	val: 0.635840	test: 0.605810

Epoch: 68
Loss: 0.3489889586280523
ROC train: 0.906239	val: 0.562213	test: 0.551454
PRC train: 0.870023	val: 0.633463	test: 0.601623

Epoch: 69
Loss: 0.3483960578937297
ROC train: 0.907902	val: 0.545792	test: 0.560032
PRC train: 0.874733	val: 0.630945	test: 0.602813

Epoch: 70
Loss: 0.34730295344540807
ROC train: 0.909058	val: 0.547495	test: 0.544649
PRC train: 0.877624	val: 0.627096	test: 0.598184

Epoch: 71
Loss: 0.34329930157644395
ROC train: 0.910082	val: 0.549310	test: 0.550895
PRC train: 0.878088	val: 0.628777	test: 0.601199

Epoch: 72
Loss: 0.34500020181170615
ROC train: 0.908640	val: 0.556923	test: 0.555539
PRC train: 0.874747	val: 0.631405	test: 0.602395

Epoch: 73
Loss: 0.3449895227343144
ROC train: 0.911411	val: 0.550914	test: 0.555446
PRC train: 0.880487	val: 0.627340	test: 0.603251

Epoch: 74
Loss: 0.34092770690375535
ROC train: 0.912737	val: 0.543253	test: 0.558858
PRC train: 0.883586	val: 0.625107	test: 0.607118

Epoch: 75
Loss: 0.34150582249319594
ROC train: 0.915341	val: 0.541820	test: 0.546970
PRC train: 0.885296	val: 0.620709	test: 0.599444

Epoch: 76
Loss: 0.34059394846545527
ROC train: 0.915493	val: 0.544432	test: 0.535377
PRC train: 0.884920	val: 0.617172	test: 0.593262

Epoch: 77
Loss: 0.33592448503055616
ROC train: 0.917582	val: 0.548243	test: 0.545321
PRC train: 0.886216	val: 0.622562	test: 0.600411

Epoch: 78
Loss: 0.3325057517735458
ROC train: 0.916889	val: 0.555772	test: 0.552394
PRC train: 0.886748	val: 0.629107	test: 0.604512

Epoch: 79
Loss: 0.3291171167281669
ROC train: 0.917959	val: 0.557122	test: 0.548155
PRC train: 0.888370	val: 0.629818	test: 0.603317

Epoch: 80
Loss: 0.3322633730910603
ROC train: 0.921214	val: 0.547159	test: 0.551851
PRC train: 0.891601	val: 0.623471	test: 0.601910

Epoch: 81
Loss: 0.3324948638372374
ROC train: 0.921489	val: 0.556023	test: 0.543198
PRC train: 0.893489	val: 0.629323	test: 0.596695

Epoch: 82
Loss: 0.32904092417732744
ROC train: 0.924069	val: 0.560071	test: 0.546043
PRC train: 0.893658	val: 0.630313	test: 0.599725

Epoch: 83
Loss: 0.32545306048966516
ROC train: 0.924038	val: 0.564700	test: 0.550557
PRC train: 0.896378	val: 0.632322	test: 0.604268

Epoch: 84
Loss: 0.32472338080136787
ROC train: 0.924703	val: 0.552745	test: 0.561013
PRC train: 0.896345	val: 0.627808	test: 0.607592

Epoch: 85
Loss: 0.33061406065839216
ROC train: 0.926385	val: 0.536853	test: 0.568217
PRC train: 0.899508	val: 0.617685	test: 0.611305

Epoch: 86
Loss: 0.32536107787007745
ROC train: 0.927037	val: 0.549600	test: 0.562063
PRC train: 0.902180	val: 0.622089	test: 0.606490

Epoch: 87
Loss: 0.32643858937765147
ROC train: 0.928419	val: 0.554317	test: 0.564586
PRC train: 0.900433	val: 0.624800	test: 0.608222

Epoch: 88
Loss: 0.31667833113617555
ROC train: 0.930913	val: 0.552918	test: 0.561607
PRC train: 0.903397	val: 0.622701	test: 0.608697

Epoch: 89
Loss: 0.31359014152182685
ROC train: 0.930930	val: 0.558249	test: 0.559289
PRC train: 0.906138	val: 0.627063	test: 0.607789

Epoch: 90
Loss: 0.31529865742183893
ROC train: 0.931320	val: 0.557308	test: 0.561522
PRC train: 0.909722	val: 0.629668	test: 0.610299

Epoch: 91
Loss: 0.3112160713684992
ROC train: 0.931366	val: 0.564048	test: 0.559331
PRC train: 0.909072	val: 0.630526	test: 0.610159

Epoch: 92
Loss: 0.30959039165594426
ROC train: 0.933524	val: 0.557075	test: 0.557489
PRC train: 0.910080	val: 0.628601	test: 0.608265

Epoch: 93
Loss: 0.31012708641402564
ROC train: 0.934975	val: 0.542281	test: 0.564218
PRC train: 0.795928	val: 0.641745	test: 0.622052

Epoch: 33
Loss: 0.424644156867906
ROC train: 0.842983	val: 0.572690	test: 0.549423
PRC train: 0.801220	val: 0.643196	test: 0.609901

Epoch: 34
Loss: 0.420315149763692
ROC train: 0.840295	val: 0.558829	test: 0.556330
PRC train: 0.796327	val: 0.637323	test: 0.614845

Epoch: 35
Loss: 0.41791831235616506
ROC train: 0.843419	val: 0.548455	test: 0.572799
PRC train: 0.801473	val: 0.631551	test: 0.616710

Epoch: 36
Loss: 0.41258457011251864
ROC train: 0.851143	val: 0.563791	test: 0.556953
PRC train: 0.805976	val: 0.640960	test: 0.609640

Epoch: 37
Loss: 0.4070087615783894
ROC train: 0.855571	val: 0.566970	test: 0.560652
PRC train: 0.807238	val: 0.641355	test: 0.617257

Epoch: 38
Loss: 0.40811098086576864
ROC train: 0.853477	val: 0.566672	test: 0.574360
PRC train: 0.806368	val: 0.637429	test: 0.619294

Epoch: 39
Loss: 0.40573623132964426
ROC train: 0.855012	val: 0.565712	test: 0.553854
PRC train: 0.806098	val: 0.636634	test: 0.616125

Epoch: 40
Loss: 0.3983010403840668
ROC train: 0.860482	val: 0.556151	test: 0.538768
PRC train: 0.812330	val: 0.630747	test: 0.605886

Epoch: 41
Loss: 0.4016504177406605
ROC train: 0.860081	val: 0.545953	test: 0.548629
PRC train: 0.812245	val: 0.625124	test: 0.607750

Epoch: 42
Loss: 0.4006979169554226
ROC train: 0.864580	val: 0.547444	test: 0.573350
PRC train: 0.821091	val: 0.630741	test: 0.614860

Epoch: 43
Loss: 0.396014490564429
ROC train: 0.865063	val: 0.560936	test: 0.569177
PRC train: 0.819266	val: 0.637056	test: 0.619883

Epoch: 44
Loss: 0.39144429128084895
ROC train: 0.864813	val: 0.541644	test: 0.581253
PRC train: 0.817434	val: 0.625688	test: 0.622353

Epoch: 45
Loss: 0.3952943714889411
ROC train: 0.868732	val: 0.543128	test: 0.569332
PRC train: 0.822705	val: 0.632288	test: 0.617996

Epoch: 46
Loss: 0.3904848233121935
ROC train: 0.872231	val: 0.559843	test: 0.565664
PRC train: 0.827051	val: 0.637887	test: 0.613318

Epoch: 47
Loss: 0.3902583705498019
ROC train: 0.876098	val: 0.565310	test: 0.571408
PRC train: 0.831872	val: 0.638557	test: 0.613466

Epoch: 48
Loss: 0.3852161300703285
ROC train: 0.876030	val: 0.559573	test: 0.559941
PRC train: 0.832092	val: 0.634251	test: 0.614086

Epoch: 49
Loss: 0.3858789765204759
ROC train: 0.872482	val: 0.551405	test: 0.561625
PRC train: 0.829205	val: 0.631627	test: 0.616390

Epoch: 50
Loss: 0.3851609943903461
ROC train: 0.874428	val: 0.539464	test: 0.575067
PRC train: 0.830938	val: 0.630355	test: 0.615786

Epoch: 51
Loss: 0.37892756247277426
ROC train: 0.876340	val: 0.548905	test: 0.560409
PRC train: 0.832638	val: 0.638016	test: 0.614545

Epoch: 52
Loss: 0.38109230559387997
ROC train: 0.881170	val: 0.550131	test: 0.565880
PRC train: 0.841406	val: 0.630505	test: 0.617405

Epoch: 53
Loss: 0.3796967588032265
ROC train: 0.880459	val: 0.542448	test: 0.572835
PRC train: 0.842723	val: 0.621459	test: 0.618799

Epoch: 54
Loss: 0.37674710191029426
ROC train: 0.886043	val: 0.545987	test: 0.551686
PRC train: 0.844502	val: 0.627294	test: 0.606393

Epoch: 55
Loss: 0.3712451866341584
ROC train: 0.883924	val: 0.552482	test: 0.551514
PRC train: 0.839689	val: 0.627228	test: 0.611543

Epoch: 56
Loss: 0.3800016510311341
ROC train: 0.882414	val: 0.564558	test: 0.547585
PRC train: 0.839234	val: 0.635298	test: 0.612502

Epoch: 57
Loss: 0.37583572416664907
ROC train: 0.892347	val: 0.562905	test: 0.559506
PRC train: 0.851044	val: 0.637049	test: 0.615431

Epoch: 58
Loss: 0.37185783922834503
ROC train: 0.891836	val: 0.551677	test: 0.575039
PRC train: 0.849954	val: 0.629112	test: 0.620421

Epoch: 59
Loss: 0.3718634757338737
ROC train: 0.890466	val: 0.549956	test: 0.571354
PRC train: 0.846700	val: 0.629258	test: 0.618827

Epoch: 60
Loss: 0.36572145380924004
ROC train: 0.891282	val: 0.568670	test: 0.550282
PRC train: 0.848277	val: 0.637286	test: 0.611170

Epoch: 61
Loss: 0.3676555895869646
ROC train: 0.895547	val: 0.560740	test: 0.553039
PRC train: 0.852823	val: 0.637030	test: 0.615504

Epoch: 62
Loss: 0.3604228780523175
ROC train: 0.893287	val: 0.552206	test: 0.555591
PRC train: 0.849984	val: 0.635578	test: 0.613735

Epoch: 63
Loss: 0.35932011616805515
ROC train: 0.893868	val: 0.560475	test: 0.557788
PRC train: 0.851236	val: 0.638550	test: 0.618979

Epoch: 64
Loss: 0.3648918909960702
ROC train: 0.898197	val: 0.552986	test: 0.571650
PRC train: 0.857367	val: 0.626790	test: 0.624940

Epoch: 65
Loss: 0.360122747867896
ROC train: 0.901929	val: 0.553630	test: 0.567882
PRC train: 0.860344	val: 0.629289	test: 0.617037

Epoch: 66
Loss: 0.36043987201556954
ROC train: 0.903137	val: 0.555651	test: 0.567219
PRC train: 0.860848	val: 0.631228	test: 0.617063

Epoch: 67
Loss: 0.35849150311996136
ROC train: 0.898205	val: 0.550649	test: 0.561926
PRC train: 0.856175	val: 0.623723	test: 0.621702

Epoch: 68
Loss: 0.35221037128649096
ROC train: 0.904202	val: 0.559923	test: 0.552742
PRC train: 0.864435	val: 0.634538	test: 0.609747

Epoch: 69
Loss: 0.3516999167128309
ROC train: 0.903080	val: 0.563917	test: 0.566268
PRC train: 0.863678	val: 0.637571	test: 0.615594

Epoch: 70
Loss: 0.35156994496819527
ROC train: 0.905917	val: 0.547374	test: 0.556942
PRC train: 0.864377	val: 0.626981	test: 0.615955

Epoch: 71
Loss: 0.3480196296117566
ROC train: 0.905032	val: 0.556305	test: 0.551780
PRC train: 0.864713	val: 0.631038	test: 0.615491

Epoch: 72
Loss: 0.34829901884624165
ROC train: 0.907878	val: 0.555200	test: 0.551457
PRC train: 0.867158	val: 0.631741	test: 0.611576

Epoch: 73
Loss: 0.34262753803503276
ROC train: 0.908446	val: 0.558287	test: 0.554529
PRC train: 0.867336	val: 0.633143	test: 0.612401

Epoch: 74
Loss: 0.3474398963104633
ROC train: 0.911825	val: 0.563849	test: 0.566655
PRC train: 0.872938	val: 0.638157	test: 0.620788

Epoch: 75
Loss: 0.3479268096067195
ROC train: 0.913911	val: 0.568051	test: 0.555849
PRC train: 0.876149	val: 0.637762	test: 0.617695

Epoch: 76
Loss: 0.3418287812596188
ROC train: 0.912413	val: 0.554353	test: 0.546929
PRC train: 0.875579	val: 0.631804	test: 0.614978

Epoch: 77
Loss: 0.34313479149034587
ROC train: 0.910345	val: 0.540823	test: 0.550741
PRC train: 0.874413	val: 0.629756	test: 0.619139

Epoch: 78
Loss: 0.34235474024802376
ROC train: 0.913598	val: 0.541825	test: 0.550410
PRC train: 0.876293	val: 0.623229	test: 0.619553

Epoch: 79
Loss: 0.33658483531045597
ROC train: 0.917915	val: 0.558313	test: 0.560667
PRC train: 0.879932	val: 0.630359	test: 0.618604

Epoch: 80
Loss: 0.33887139794381194
ROC train: 0.918609	val: 0.565718	test: 0.562140
PRC train: 0.882343	val: 0.636558	test: 0.618264

Epoch: 81
Loss: 0.3348759580071339
ROC train: 0.920026	val: 0.558627	test: 0.555004
PRC train: 0.884786	val: 0.632677	test: 0.618015

Epoch: 82
Loss: 0.33374981726095837
ROC train: 0.919022	val: 0.547064	test: 0.552873
PRC train: 0.884487	val: 0.632052	test: 0.616641

Epoch: 83
Loss: 0.3295525643035385
ROC train: 0.922236	val: 0.547154	test: 0.553860
PRC train: 0.888659	val: 0.628206	test: 0.612563

Epoch: 84
Loss: 0.3310196012514083
ROC train: 0.919643	val: 0.556925	test: 0.560126
PRC train: 0.885121	val: 0.626836	test: 0.622466

Epoch: 85
Loss: 0.33270037159246457
ROC train: 0.920502	val: 0.553391	test: 0.555040
PRC train: 0.885771	val: 0.622641	test: 0.620562

Epoch: 86
Loss: 0.32691910522215223
ROC train: 0.922609	val: 0.544447	test: 0.551230
PRC train: 0.886635	val: 0.623406	test: 0.615821

Epoch: 87
Loss: 0.3286958098453363
ROC train: 0.925146	val: 0.553259	test: 0.564442
PRC train: 0.889541	val: 0.630010	test: 0.622329

Epoch: 88
Loss: 0.3243796438718819
ROC train: 0.926092	val: 0.559195	test: 0.562532
PRC train: 0.891479	val: 0.633437	test: 0.622739

Epoch: 89
Loss: 0.320997020876439
ROC train: 0.928551	val: 0.555526	test: 0.555733
PRC train: 0.897089	val: 0.627217	test: 0.619691

Epoch: 90
Loss: 0.32078881103239854
ROC train: 0.928938	val: 0.551715	test: 0.554770
PRC train: 0.895248	val: 0.622981	test: 0.617017

Epoch: 91
Loss: 0.3174545932300356
ROC train: 0.930220	val: 0.557728	test: 0.557082
PRC train: 0.899164	val: 0.627224	test: 0.615013

Epoch: 92
Loss: 0.3215242936253328
ROC train: 0.932204	val: 0.557467	test: 0.550883
PRC train: 0.899483	val: 0.625365	test: 0.614901

Epoch: 93
Loss: 0.3105446106480115
ROC train: 0.931098	val: 0.551193	test: 0.555670
PRC train: 0.801034	val: 0.657806	test: 0.634732

Epoch: 33
Loss: 0.4258207764850622
ROC train: 0.840599	val: 0.592604	test: 0.602913
PRC train: 0.800644	val: 0.658698	test: 0.636112

Epoch: 34
Loss: 0.42151352757188915
ROC train: 0.844824	val: 0.584260	test: 0.612633
PRC train: 0.804496	val: 0.654289	test: 0.641574

Epoch: 35
Loss: 0.4148629992940748
ROC train: 0.844812	val: 0.572395	test: 0.581836
PRC train: 0.801968	val: 0.645910	test: 0.627960

Epoch: 36
Loss: 0.4189367858580456
ROC train: 0.852322	val: 0.570461	test: 0.590802
PRC train: 0.811973	val: 0.646082	test: 0.629092

Epoch: 37
Loss: 0.41114884608742513
ROC train: 0.846971	val: 0.602023	test: 0.602702
PRC train: 0.807109	val: 0.662767	test: 0.638755

Epoch: 38
Loss: 0.4108065162699173
ROC train: 0.853623	val: 0.578175	test: 0.604911
PRC train: 0.813756	val: 0.647727	test: 0.639763

Epoch: 39
Loss: 0.4086506067843164
ROC train: 0.851303	val: 0.591560	test: 0.594140
PRC train: 0.810170	val: 0.669752	test: 0.634934

Epoch: 40
Loss: 0.4034271783136978
ROC train: 0.864208	val: 0.559702	test: 0.604681
PRC train: 0.823561	val: 0.646907	test: 0.636683

Epoch: 41
Loss: 0.4017317468635607
ROC train: 0.862681	val: 0.573724	test: 0.616984
PRC train: 0.821120	val: 0.655008	test: 0.642840

Epoch: 42
Loss: 0.404704280231977
ROC train: 0.860655	val: 0.579847	test: 0.601040
PRC train: 0.820262	val: 0.653792	test: 0.634556

Epoch: 43
Loss: 0.39927732441726793
ROC train: 0.862728	val: 0.574594	test: 0.595978
PRC train: 0.825132	val: 0.653394	test: 0.633766

Epoch: 44
Loss: 0.39442127304472285
ROC train: 0.866065	val: 0.589851	test: 0.603201
PRC train: 0.823747	val: 0.657483	test: 0.634959

Epoch: 45
Loss: 0.3947843369927412
ROC train: 0.871536	val: 0.577553	test: 0.600853
PRC train: 0.829742	val: 0.648546	test: 0.635439

Epoch: 46
Loss: 0.38995673163379213
ROC train: 0.870919	val: 0.574227	test: 0.604303
PRC train: 0.828371	val: 0.649606	test: 0.635868

Epoch: 47
Loss: 0.3897620306982357
ROC train: 0.871741	val: 0.595553	test: 0.603145
PRC train: 0.830034	val: 0.666231	test: 0.639132

Epoch: 48
Loss: 0.38906652952169923
ROC train: 0.878427	val: 0.571275	test: 0.605917
PRC train: 0.837019	val: 0.648677	test: 0.633951

Epoch: 49
Loss: 0.3807401988647182
ROC train: 0.870050	val: 0.571398	test: 0.598626
PRC train: 0.826574	val: 0.651444	test: 0.635079

Epoch: 50
Loss: 0.3777504649802688
ROC train: 0.879305	val: 0.558891	test: 0.598240
PRC train: 0.839049	val: 0.645756	test: 0.638455

Epoch: 51
Loss: 0.37589929996440496
ROC train: 0.881230	val: 0.570250	test: 0.605015
PRC train: 0.839549	val: 0.654845	test: 0.642963

Epoch: 52
Loss: 0.3778252057094284
ROC train: 0.884079	val: 0.586687	test: 0.593297
PRC train: 0.840257	val: 0.663243	test: 0.638531

Epoch: 53
Loss: 0.3781210404016083
ROC train: 0.882822	val: 0.572605	test: 0.585206
PRC train: 0.842789	val: 0.654293	test: 0.628370

Epoch: 54
Loss: 0.37252771748428676
ROC train: 0.886002	val: 0.584798	test: 0.599059
PRC train: 0.848314	val: 0.655769	test: 0.636123

Epoch: 55
Loss: 0.37533927268481404
ROC train: 0.887961	val: 0.590739	test: 0.603610
PRC train: 0.847848	val: 0.661427	test: 0.635602

Epoch: 56
Loss: 0.366503825309538
ROC train: 0.887928	val: 0.569899	test: 0.592235
PRC train: 0.845422	val: 0.646022	test: 0.624968

Epoch: 57
Loss: 0.3735086921637877
ROC train: 0.890223	val: 0.582559	test: 0.602136
PRC train: 0.849347	val: 0.658232	test: 0.635427

Epoch: 58
Loss: 0.36371249063247607
ROC train: 0.893626	val: 0.591421	test: 0.607446
PRC train: 0.854214	val: 0.667999	test: 0.639405

Epoch: 59
Loss: 0.3704804820745624
ROC train: 0.889561	val: 0.590022	test: 0.611551
PRC train: 0.848978	val: 0.664085	test: 0.638985

Epoch: 60
Loss: 0.36328378886134466
ROC train: 0.894467	val: 0.585749	test: 0.610184
PRC train: 0.852636	val: 0.662640	test: 0.643264

Epoch: 61
Loss: 0.36398183963648945
ROC train: 0.894379	val: 0.599614	test: 0.597880
PRC train: 0.855548	val: 0.669786	test: 0.637848

Epoch: 62
Loss: 0.3630893793420814
ROC train: 0.897085	val: 0.577954	test: 0.591353
PRC train: 0.857538	val: 0.651334	test: 0.629960

Epoch: 63
Loss: 0.35832779185641545
ROC train: 0.894799	val: 0.588203	test: 0.611651
PRC train: 0.852387	val: 0.663401	test: 0.637665

Epoch: 64
Loss: 0.36117984797267527
ROC train: 0.891422	val: 0.609875	test: 0.597997
PRC train: 0.846300	val: 0.676517	test: 0.633129

Epoch: 65
Loss: 0.36209958448192187
ROC train: 0.902156	val: 0.588940	test: 0.586784
PRC train: 0.861443	val: 0.661263	test: 0.626613

Epoch: 66
Loss: 0.35665502381505315
ROC train: 0.900663	val: 0.579614	test: 0.587385
PRC train: 0.861554	val: 0.659718	test: 0.626256

Epoch: 67
Loss: 0.353557743642835
ROC train: 0.902696	val: 0.586035	test: 0.606966
PRC train: 0.862324	val: 0.665321	test: 0.635069

Epoch: 68
Loss: 0.34782601292053783
ROC train: 0.905256	val: 0.592231	test: 0.601443
PRC train: 0.864561	val: 0.663412	test: 0.629697

Epoch: 69
Loss: 0.34737446106123604
ROC train: 0.907251	val: 0.608150	test: 0.596106
PRC train: 0.869239	val: 0.672269	test: 0.628762

Epoch: 70
Loss: 0.3458253192581577
ROC train: 0.905978	val: 0.603575	test: 0.606945
PRC train: 0.869434	val: 0.670323	test: 0.635945

Epoch: 71
Loss: 0.3458972452511243
ROC train: 0.908453	val: 0.586079	test: 0.600228
PRC train: 0.871978	val: 0.663078	test: 0.631094

Epoch: 72
Loss: 0.3436457907657767
ROC train: 0.907117	val: 0.574478	test: 0.589784
PRC train: 0.870763	val: 0.658330	test: 0.625588

Epoch: 73
Loss: 0.3422373868110826
ROC train: 0.907442	val: 0.599615	test: 0.604501
PRC train: 0.871449	val: 0.676497	test: 0.639588

Epoch: 74
Loss: 0.3440601306071449
ROC train: 0.909675	val: 0.590512	test: 0.600359
PRC train: 0.871755	val: 0.666743	test: 0.634098

Epoch: 75
Loss: 0.34314446620772
ROC train: 0.914549	val: 0.574184	test: 0.590074
PRC train: 0.877044	val: 0.653243	test: 0.627143

Epoch: 76
Loss: 0.34185621027981894
ROC train: 0.915489	val: 0.580995	test: 0.591936
PRC train: 0.877941	val: 0.665253	test: 0.629875

Epoch: 77
Loss: 0.3348650736126493
ROC train: 0.913300	val: 0.579008	test: 0.596023
PRC train: 0.875603	val: 0.663328	test: 0.629808

Epoch: 78
Loss: 0.33967148633646443
ROC train: 0.916343	val: 0.579600	test: 0.595712
PRC train: 0.879336	val: 0.659153	test: 0.626481

Epoch: 79
Loss: 0.33513936193172555
ROC train: 0.914529	val: 0.590313	test: 0.592871
PRC train: 0.878090	val: 0.669500	test: 0.631101

Epoch: 80
Loss: 0.33992849794807894
ROC train: 0.919170	val: 0.581907	test: 0.586168
PRC train: 0.885195	val: 0.661359	test: 0.626724

Epoch: 81
Loss: 0.3295632995621308
ROC train: 0.917641	val: 0.587813	test: 0.584218
PRC train: 0.880909	val: 0.662376	test: 0.621071

Epoch: 82
Loss: 0.3348103890094343
ROC train: 0.921590	val: 0.598195	test: 0.595591
PRC train: 0.887145	val: 0.667183	test: 0.627664

Epoch: 83
Loss: 0.32644050017389925
ROC train: 0.916814	val: 0.593887	test: 0.606542
PRC train: 0.879398	val: 0.667505	test: 0.638063

Epoch: 84
Loss: 0.32883708852619364
ROC train: 0.919474	val: 0.585979	test: 0.603961
PRC train: 0.882241	val: 0.662175	test: 0.634054

Epoch: 85
Loss: 0.3293690648589739
ROC train: 0.926714	val: 0.572789	test: 0.591281
PRC train: 0.894272	val: 0.655343	test: 0.622196

Epoch: 86
Loss: 0.32798904318687133
ROC train: 0.925260	val: 0.599417	test: 0.590244
PRC train: 0.892796	val: 0.665345	test: 0.624239

Epoch: 87
Loss: 0.3233820649766138
ROC train: 0.929432	val: 0.587341	test: 0.590162
PRC train: 0.894497	val: 0.664569	test: 0.619828

Epoch: 88
Loss: 0.3253446070562643
ROC train: 0.926729	val: 0.582286	test: 0.590268
PRC train: 0.891800	val: 0.665743	test: 0.624880

Epoch: 89
Loss: 0.3189949212150425
ROC train: 0.926306	val: 0.593288	test: 0.594748
PRC train: 0.891140	val: 0.666010	test: 0.633787

Epoch: 90
Loss: 0.32136015213711316
ROC train: 0.928147	val: 0.604740	test: 0.595415
PRC train: 0.894930	val: 0.673623	test: 0.630698

Epoch: 91
Loss: 0.31506682555621945
ROC train: 0.927504	val: 0.593703	test: 0.587620
PRC train: 0.893340	val: 0.671583	test: 0.626897

Epoch: 92
Loss: 0.31789276782081916
ROC train: 0.932615	val: 0.589849	test: 0.589337
PRC train: 0.900918	val: 0.660624	test: 0.625525

Epoch: 93
Loss: 0.31524380194004314
ROC train: 0.932150	val: 0.592620	test: 0.600702
PRC train: 0.788912	val: 0.661631	test: 0.625715

Epoch: 33
Loss: 0.4252582090903522
ROC train: 0.832523	val: 0.596666	test: 0.602694
PRC train: 0.795443	val: 0.658404	test: 0.628488

Epoch: 34
Loss: 0.42584218336872925
ROC train: 0.833744	val: 0.580481	test: 0.592467
PRC train: 0.791810	val: 0.646106	test: 0.629584

Epoch: 35
Loss: 0.42234140867237346
ROC train: 0.844107	val: 0.598345	test: 0.590291
PRC train: 0.802944	val: 0.660285	test: 0.620251

Epoch: 36
Loss: 0.42318822220534386
ROC train: 0.843702	val: 0.597152	test: 0.594059
PRC train: 0.804116	val: 0.663320	test: 0.619723

Epoch: 37
Loss: 0.4186267993941383
ROC train: 0.843681	val: 0.593614	test: 0.588498
PRC train: 0.802589	val: 0.657826	test: 0.624294

Epoch: 38
Loss: 0.4126283210110116
ROC train: 0.850784	val: 0.610812	test: 0.594150
PRC train: 0.810283	val: 0.664326	test: 0.625598

Epoch: 39
Loss: 0.40827700247211557
ROC train: 0.851240	val: 0.612492	test: 0.605999
PRC train: 0.811394	val: 0.664704	test: 0.629793

Epoch: 40
Loss: 0.4073185749590767
ROC train: 0.854178	val: 0.606619	test: 0.592784
PRC train: 0.813012	val: 0.657789	test: 0.626089

Epoch: 41
Loss: 0.40733028225347256
ROC train: 0.859374	val: 0.602991	test: 0.593253
PRC train: 0.817135	val: 0.657678	test: 0.624361

Epoch: 42
Loss: 0.40106867662934337
ROC train: 0.854985	val: 0.597779	test: 0.599187
PRC train: 0.813503	val: 0.660224	test: 0.623727

Epoch: 43
Loss: 0.40565585291151135
ROC train: 0.860971	val: 0.602791	test: 0.591965
PRC train: 0.820661	val: 0.661147	test: 0.622213

Epoch: 44
Loss: 0.40501388056164345
ROC train: 0.861375	val: 0.600714	test: 0.585646
PRC train: 0.818860	val: 0.654543	test: 0.621737

Epoch: 45
Loss: 0.3914916773428653
ROC train: 0.866742	val: 0.613672	test: 0.592691
PRC train: 0.820815	val: 0.662604	test: 0.626917

Epoch: 46
Loss: 0.39688021284999103
ROC train: 0.867022	val: 0.615989	test: 0.599485
PRC train: 0.822802	val: 0.665033	test: 0.630824

Epoch: 47
Loss: 0.3897289936584591
ROC train: 0.871638	val: 0.617871	test: 0.589884
PRC train: 0.826877	val: 0.664240	test: 0.624116

Epoch: 48
Loss: 0.39795069433188135
ROC train: 0.868722	val: 0.606787	test: 0.581587
PRC train: 0.822649	val: 0.655666	test: 0.622211

Epoch: 49
Loss: 0.3920631475201759
ROC train: 0.872297	val: 0.610133	test: 0.587940
PRC train: 0.827468	val: 0.654675	test: 0.624135

Epoch: 50
Loss: 0.3842780310719647
ROC train: 0.875093	val: 0.601856	test: 0.587160
PRC train: 0.833322	val: 0.652309	test: 0.623453

Epoch: 51
Loss: 0.38559892871036533
ROC train: 0.877228	val: 0.597526	test: 0.590700
PRC train: 0.836582	val: 0.652767	test: 0.625322

Epoch: 52
Loss: 0.38376418980034754
ROC train: 0.877860	val: 0.599471	test: 0.588987
PRC train: 0.835798	val: 0.660562	test: 0.627639

Epoch: 53
Loss: 0.3842814371246996
ROC train: 0.881122	val: 0.603491	test: 0.592464
PRC train: 0.836906	val: 0.662564	test: 0.625822

Epoch: 54
Loss: 0.38451305958548687
ROC train: 0.879670	val: 0.594951	test: 0.594191
PRC train: 0.836981	val: 0.655893	test: 0.625950

Epoch: 55
Loss: 0.38584902900970797
ROC train: 0.880905	val: 0.598097	test: 0.600799
PRC train: 0.837091	val: 0.655841	test: 0.630560

Epoch: 56
Loss: 0.37432141147466763
ROC train: 0.882322	val: 0.591328	test: 0.589500
PRC train: 0.839667	val: 0.655625	test: 0.622280

Epoch: 57
Loss: 0.3766472490221293
ROC train: 0.882487	val: 0.594944	test: 0.587675
PRC train: 0.841402	val: 0.654785	test: 0.625442

Epoch: 58
Loss: 0.37906556661267743
ROC train: 0.890326	val: 0.602989	test: 0.582599
PRC train: 0.848823	val: 0.660287	test: 0.622300

Epoch: 59
Loss: 0.376524264191209
ROC train: 0.891141	val: 0.608327	test: 0.590342
PRC train: 0.848138	val: 0.660800	test: 0.627198

Epoch: 60
Loss: 0.36856618412319414
ROC train: 0.889965	val: 0.607719	test: 0.589013
PRC train: 0.846155	val: 0.659680	test: 0.623707

Epoch: 61
Loss: 0.3743604459546093
ROC train: 0.893439	val: 0.610032	test: 0.587465
PRC train: 0.849653	val: 0.659865	test: 0.624453

Epoch: 62
Loss: 0.3644178277449258
ROC train: 0.893396	val: 0.611140	test: 0.593694
PRC train: 0.852236	val: 0.658250	test: 0.630150

Epoch: 63
Loss: 0.3654583496933504
ROC train: 0.892910	val: 0.602838	test: 0.605085
PRC train: 0.850873	val: 0.657426	test: 0.631063

Epoch: 64
Loss: 0.3632048100034313
ROC train: 0.892221	val: 0.598801	test: 0.602004
PRC train: 0.849008	val: 0.656484	test: 0.628917

Epoch: 65
Loss: 0.3668758471105285
ROC train: 0.897743	val: 0.609529	test: 0.587008
PRC train: 0.854887	val: 0.660061	test: 0.628844

Epoch: 66
Loss: 0.35953342242822045
ROC train: 0.895978	val: 0.602295	test: 0.584831
PRC train: 0.854537	val: 0.658179	test: 0.626681

Epoch: 67
Loss: 0.35887298843739546
ROC train: 0.899437	val: 0.605908	test: 0.594285
PRC train: 0.859835	val: 0.660245	test: 0.631365

Epoch: 68
Loss: 0.3591267020815926
ROC train: 0.903418	val: 0.615465	test: 0.591998
PRC train: 0.860788	val: 0.661427	test: 0.628512

Epoch: 69
Loss: 0.357371691421114
ROC train: 0.903246	val: 0.612798	test: 0.599809
PRC train: 0.862381	val: 0.661700	test: 0.631567

Epoch: 70
Loss: 0.3579293672303505
ROC train: 0.901818	val: 0.595941	test: 0.598725
PRC train: 0.859616	val: 0.656497	test: 0.631073

Epoch: 71
Loss: 0.3576151041427976
ROC train: 0.903360	val: 0.604791	test: 0.594231
PRC train: 0.861616	val: 0.657835	test: 0.629905

Epoch: 72
Loss: 0.3513694683582619
ROC train: 0.903989	val: 0.606940	test: 0.608552
PRC train: 0.862503	val: 0.657956	test: 0.635146

Epoch: 73
Loss: 0.34936019119059436
ROC train: 0.904969	val: 0.602243	test: 0.607639
PRC train: 0.865468	val: 0.659149	test: 0.633664

Epoch: 74
Loss: 0.3519683727790668
ROC train: 0.909533	val: 0.608006	test: 0.597438
PRC train: 0.868437	val: 0.662313	test: 0.631607

Epoch: 75
Loss: 0.3504905435012304
ROC train: 0.909639	val: 0.608743	test: 0.597827
PRC train: 0.866782	val: 0.661483	test: 0.630545

Epoch: 76
Loss: 0.34645797528328315
ROC train: 0.908495	val: 0.602399	test: 0.597790
PRC train: 0.869264	val: 0.657325	test: 0.628527

Epoch: 77
Loss: 0.3466712677624445
ROC train: 0.911052	val: 0.596244	test: 0.599708
PRC train: 0.872148	val: 0.659763	test: 0.632406

Epoch: 78
Loss: 0.3447015781195215
ROC train: 0.912278	val: 0.609393	test: 0.605928
PRC train: 0.870379	val: 0.663930	test: 0.636672

Epoch: 79
Loss: 0.34555624002137186
ROC train: 0.913185	val: 0.613651	test: 0.598556
PRC train: 0.873001	val: 0.663157	test: 0.627793

Epoch: 80
Loss: 0.34141066563975264
ROC train: 0.913855	val: 0.605016	test: 0.592392
PRC train: 0.873440	val: 0.660721	test: 0.627040

Epoch: 81
Loss: 0.346680576871223
ROC train: 0.914403	val: 0.598671	test: 0.612312
PRC train: 0.870199	val: 0.662439	test: 0.636149

Epoch: 82
Loss: 0.33848453881885743
ROC train: 0.917159	val: 0.602980	test: 0.610795
PRC train: 0.874712	val: 0.664137	test: 0.633765

Epoch: 83
Loss: 0.33725107597082193
ROC train: 0.916317	val: 0.606114	test: 0.596265
PRC train: 0.873348	val: 0.662346	test: 0.627313

Epoch: 84
Loss: 0.33451978162425816
ROC train: 0.915709	val: 0.603347	test: 0.595876
PRC train: 0.873834	val: 0.663306	test: 0.627960

Epoch: 85
Loss: 0.3331929176472553
ROC train: 0.919472	val: 0.611623	test: 0.596519
PRC train: 0.880859	val: 0.663584	test: 0.628139

Epoch: 86
Loss: 0.32852069079289103
ROC train: 0.919366	val: 0.610790	test: 0.593742
PRC train: 0.881801	val: 0.662587	test: 0.628951

Epoch: 87
Loss: 0.32743411434318664
ROC train: 0.919614	val: 0.611039	test: 0.590530
PRC train: 0.877592	val: 0.664507	test: 0.630092

Epoch: 88
Loss: 0.33118971011031245
ROC train: 0.923110	val: 0.606186	test: 0.598939
PRC train: 0.884951	val: 0.665388	test: 0.629933

Epoch: 89
Loss: 0.3340112243358878
ROC train: 0.924904	val: 0.597070	test: 0.591835
PRC train: 0.886932	val: 0.657023	test: 0.624342

Epoch: 90
Loss: 0.3286939830935392
ROC train: 0.925487	val: 0.615013	test: 0.594282
PRC train: 0.887603	val: 0.660950	test: 0.627348

Epoch: 91
Loss: 0.3272345492337528
ROC train: 0.925345	val: 0.622243	test: 0.595043
PRC train: 0.889918	val: 0.668215	test: 0.629871

Epoch: 92
Loss: 0.32618731654407557
ROC train: 0.927341	val: 0.611726	test: 0.598491
PRC train: 0.888792	val: 0.663926	test: 0.628042

Epoch: 93
Loss: 0.3256110305973139
ROC train: 0.926871	val: 0.602698	test: 0.594225
PRC train: 0.867030	val: 0.671248	test: 0.629064

Epoch: 95
Loss: 0.3625442545035348
ROC train: 0.899590	val: 0.636766	test: 0.591276
PRC train: 0.864567	val: 0.675716	test: 0.630737

Epoch: 96
Loss: 0.35574763965012723
ROC train: 0.902848	val: 0.627986	test: 0.572683
PRC train: 0.866685	val: 0.667286	test: 0.618784

Epoch: 97
Loss: 0.3588402067583578
ROC train: 0.904211	val: 0.632746	test: 0.569969
PRC train: 0.869191	val: 0.673182	test: 0.615501

Epoch: 98
Loss: 0.35687170820329994
ROC train: 0.906948	val: 0.636461	test: 0.575307
PRC train: 0.872581	val: 0.677727	test: 0.622123

Epoch: 99
Loss: 0.3572295437104711
ROC train: 0.905505	val: 0.626782	test: 0.571120
PRC train: 0.869414	val: 0.673748	test: 0.620542

Epoch: 100
Loss: 0.3556323419793178
ROC train: 0.907466	val: 0.616559	test: 0.560998
PRC train: 0.872387	val: 0.669343	test: 0.613574

Epoch: 101
Loss: 0.3543843488061945
ROC train: 0.907794	val: 0.617044	test: 0.571659
PRC train: 0.872826	val: 0.664408	test: 0.620882

Epoch: 102
Loss: 0.3544668329529892
ROC train: 0.907087	val: 0.626227	test: 0.575775
PRC train: 0.872588	val: 0.665552	test: 0.624924

Epoch: 103
Loss: 0.34997487848176884
ROC train: 0.912583	val: 0.630784	test: 0.575372
PRC train: 0.878494	val: 0.669373	test: 0.626665

Epoch: 104
Loss: 0.35515129085953734
ROC train: 0.909825	val: 0.626697	test: 0.565716
PRC train: 0.875110	val: 0.668493	test: 0.622285

Epoch: 105
Loss: 0.354607069154369
ROC train: 0.911383	val: 0.623302	test: 0.566677
PRC train: 0.875711	val: 0.664971	test: 0.619939

Epoch: 106
Loss: 0.3503180877711134
ROC train: 0.912161	val: 0.628141	test: 0.578287
PRC train: 0.877882	val: 0.667362	test: 0.625393

Epoch: 107
Loss: 0.34833829303341624
ROC train: 0.912325	val: 0.629579	test: 0.573322
PRC train: 0.878894	val: 0.674599	test: 0.620628

Epoch: 108
Loss: 0.34697686755350066
ROC train: 0.912541	val: 0.629120	test: 0.570685
PRC train: 0.878571	val: 0.675470	test: 0.618163

Epoch: 109
Loss: 0.34858070349181547
ROC train: 0.915874	val: 0.624559	test: 0.575876
PRC train: 0.882250	val: 0.669743	test: 0.619392

Epoch: 110
Loss: 0.34880175643629674
ROC train: 0.917154	val: 0.623932	test: 0.567906
PRC train: 0.883382	val: 0.669696	test: 0.617860

Epoch: 111
Loss: 0.3440640868687642
ROC train: 0.913936	val: 0.621133	test: 0.580950
PRC train: 0.880049	val: 0.667233	test: 0.626019

Epoch: 112
Loss: 0.3409982587971839
ROC train: 0.912599	val: 0.618087	test: 0.593366
PRC train: 0.877961	val: 0.667511	test: 0.628877

Epoch: 113
Loss: 0.34318974324615487
ROC train: 0.916486	val: 0.623872	test: 0.570932
PRC train: 0.883593	val: 0.672898	test: 0.619969

Epoch: 114
Loss: 0.3332497539019732
ROC train: 0.916129	val: 0.623163	test: 0.572803
PRC train: 0.884275	val: 0.670577	test: 0.622158

Epoch: 115
Loss: 0.337879508229763
ROC train: 0.919577	val: 0.633546	test: 0.581067
PRC train: 0.887847	val: 0.671132	test: 0.627508

Epoch: 116
Loss: 0.3403137121614273
ROC train: 0.921591	val: 0.632369	test: 0.575476
PRC train: 0.889287	val: 0.671409	test: 0.622025

Epoch: 117
Loss: 0.33918228431675584
ROC train: 0.922103	val: 0.633918	test: 0.572823
PRC train: 0.891743	val: 0.673484	test: 0.622144

Epoch: 118
Loss: 0.3388458053295561
ROC train: 0.923499	val: 0.631017	test: 0.557433
PRC train: 0.892852	val: 0.669736	test: 0.612088

Epoch: 119
Loss: 0.3320950247644209
ROC train: 0.924488	val: 0.637939	test: 0.564498
PRC train: 0.894227	val: 0.673740	test: 0.614377

Epoch: 120
Loss: 0.33508370663478415
ROC train: 0.925983	val: 0.637036	test: 0.573283
PRC train: 0.895066	val: 0.675799	test: 0.619760

Early stopping
Best (ROC):	 train: 0.841566	val: 0.640060	test: 0.598206
Best (PRC):	 train: 0.805018	val: 0.673761	test: 0.625500

PRC train: 0.857306	val: 0.666131	test: 0.632673

Epoch: 95
Loss: 0.36922932674841735
ROC train: 0.893987	val: 0.633111	test: 0.594961
PRC train: 0.851722	val: 0.668527	test: 0.630419

Epoch: 96
Loss: 0.36464299503281655
ROC train: 0.894419	val: 0.624235	test: 0.584952
PRC train: 0.854072	val: 0.669688	test: 0.624041

Epoch: 97
Loss: 0.3614576779082682
ROC train: 0.895933	val: 0.618327	test: 0.585562
PRC train: 0.856912	val: 0.666186	test: 0.625636

Epoch: 98
Loss: 0.35564821755392845
ROC train: 0.901105	val: 0.632263	test: 0.588033
PRC train: 0.862974	val: 0.668934	test: 0.627550

Epoch: 99
Loss: 0.3607838823546448
ROC train: 0.901192	val: 0.633680	test: 0.585504
PRC train: 0.862735	val: 0.667383	test: 0.626746

Epoch: 100
Loss: 0.35456736352102397
ROC train: 0.901884	val: 0.621104	test: 0.593188
PRC train: 0.863747	val: 0.666458	test: 0.629996

Epoch: 101
Loss: 0.3580279352172318
ROC train: 0.903396	val: 0.619134	test: 0.593954
PRC train: 0.864107	val: 0.667752	test: 0.632575

Epoch: 102
Loss: 0.3527701776640987
ROC train: 0.902321	val: 0.626927	test: 0.587500
PRC train: 0.862831	val: 0.668983	test: 0.629631

Epoch: 103
Loss: 0.3555662218097167
ROC train: 0.903354	val: 0.626960	test: 0.601665
PRC train: 0.862857	val: 0.667940	test: 0.636615

Epoch: 104
Loss: 0.3533634559812814
ROC train: 0.906060	val: 0.622326	test: 0.589379
PRC train: 0.867233	val: 0.667876	test: 0.627205

Epoch: 105
Loss: 0.35461569202191606
ROC train: 0.907406	val: 0.629652	test: 0.586827
PRC train: 0.869378	val: 0.670936	test: 0.625590

Epoch: 106
Loss: 0.35314233451537
ROC train: 0.903455	val: 0.634122	test: 0.583638
PRC train: 0.863873	val: 0.673439	test: 0.628067

Epoch: 107
Loss: 0.3512527053401661
ROC train: 0.909465	val: 0.628726	test: 0.584114
PRC train: 0.871192	val: 0.672510	test: 0.626607

Epoch: 108
Loss: 0.34874837188087304
ROC train: 0.909841	val: 0.628226	test: 0.575537
PRC train: 0.869613	val: 0.671542	test: 0.623363

Epoch: 109
Loss: 0.35125180071800416
ROC train: 0.904928	val: 0.623126	test: 0.588622
PRC train: 0.866172	val: 0.664583	test: 0.627635

Epoch: 110
Loss: 0.3533372585929798
ROC train: 0.910536	val: 0.622261	test: 0.591715
PRC train: 0.873970	val: 0.664756	test: 0.630867

Epoch: 111
Loss: 0.3495958966108196
ROC train: 0.909483	val: 0.617249	test: 0.597737
PRC train: 0.872702	val: 0.663552	test: 0.633445

Epoch: 112
Loss: 0.3465908405362835
ROC train: 0.910112	val: 0.617854	test: 0.595831
PRC train: 0.873568	val: 0.661286	test: 0.633853

Epoch: 113
Loss: 0.34894479088386143
ROC train: 0.912791	val: 0.622543	test: 0.579882
PRC train: 0.876998	val: 0.666597	test: 0.630009

Epoch: 114
Loss: 0.34835320640425094
ROC train: 0.912956	val: 0.621066	test: 0.581316
PRC train: 0.873451	val: 0.667072	test: 0.627927

Epoch: 115
Loss: 0.3515994872431727
ROC train: 0.915619	val: 0.616564	test: 0.579897
PRC train: 0.876899	val: 0.666209	test: 0.627488

Epoch: 116
Loss: 0.344743860684637
ROC train: 0.916993	val: 0.622145	test: 0.581855
PRC train: 0.880356	val: 0.665231	test: 0.631497

Epoch: 117
Loss: 0.34592566263997304
ROC train: 0.917022	val: 0.632131	test: 0.591658
PRC train: 0.879945	val: 0.669948	test: 0.633746

Epoch: 118
Loss: 0.3395525994971972
ROC train: 0.917223	val: 0.632213	test: 0.592136
PRC train: 0.879749	val: 0.668466	test: 0.633411

Epoch: 119
Loss: 0.3361474987167385
ROC train: 0.918298	val: 0.630125	test: 0.596308
PRC train: 0.884334	val: 0.667577	test: 0.633357

Epoch: 120
Loss: 0.33811202103139804
ROC train: 0.919321	val: 0.620802	test: 0.591136
PRC train: 0.886035	val: 0.664283	test: 0.631909

Early stopping
Best (ROC):	 train: 0.804574	val: 0.643720	test: 0.600821
Best (PRC):	 train: 0.770724	val: 0.674446	test: 0.621104

PRC train: 0.911286	val: 0.653002	test: 0.623212

Epoch: 94
Loss: 0.3070965763984916
ROC train: 0.940654	val: 0.593904	test: 0.577344
PRC train: 0.913880	val: 0.655984	test: 0.616306

Epoch: 95
Loss: 0.3056918195870774
ROC train: 0.941495	val: 0.598575	test: 0.575186
PRC train: 0.913904	val: 0.655213	test: 0.615569

Epoch: 96
Loss: 0.3023816791429059
ROC train: 0.942882	val: 0.601271	test: 0.568591
PRC train: 0.917592	val: 0.656145	test: 0.614912

Epoch: 97
Loss: 0.30448166863422715
ROC train: 0.943635	val: 0.598504	test: 0.566955
PRC train: 0.919787	val: 0.654874	test: 0.612776

Epoch: 98
Loss: 0.2985245235527533
ROC train: 0.942267	val: 0.599854	test: 0.573148
PRC train: 0.918232	val: 0.653681	test: 0.612585

Epoch: 99
Loss: 0.29804516299769485
ROC train: 0.945406	val: 0.599909	test: 0.574376
PRC train: 0.922258	val: 0.656355	test: 0.614635

Epoch: 100
Loss: 0.29981413802397366
ROC train: 0.946907	val: 0.594528	test: 0.574516
PRC train: 0.919249	val: 0.655116	test: 0.618236

Epoch: 101
Loss: 0.2970147362362356
ROC train: 0.946184	val: 0.594203	test: 0.574112
PRC train: 0.919976	val: 0.652529	test: 0.617617

Epoch: 102
Loss: 0.2924415515302514
ROC train: 0.946322	val: 0.595466	test: 0.575788
PRC train: 0.923958	val: 0.653192	test: 0.616426

Epoch: 103
Loss: 0.2955541950220741
ROC train: 0.950150	val: 0.591068	test: 0.573663
PRC train: 0.929628	val: 0.650758	test: 0.617597

Epoch: 104
Loss: 0.29034314907933184
ROC train: 0.950415	val: 0.593390	test: 0.575147
PRC train: 0.931722	val: 0.653595	test: 0.623395

Epoch: 105
Loss: 0.2898089921610631
ROC train: 0.951083	val: 0.597009	test: 0.574243
PRC train: 0.933838	val: 0.654060	test: 0.622679

Epoch: 106
Loss: 0.2913404566887934
ROC train: 0.950925	val: 0.595958	test: 0.569513
PRC train: 0.933123	val: 0.653043	test: 0.616012

Epoch: 107
Loss: 0.28806029466460664
ROC train: 0.951467	val: 0.595721	test: 0.574953
PRC train: 0.935515	val: 0.653315	test: 0.621297

Epoch: 108
Loss: 0.2801310480613752
ROC train: 0.951967	val: 0.591841	test: 0.577722
PRC train: 0.935005	val: 0.652864	test: 0.620936

Epoch: 109
Loss: 0.28062065064398234
ROC train: 0.952851	val: 0.594687	test: 0.579703
PRC train: 0.936010	val: 0.651701	test: 0.619091

Epoch: 110
Loss: 0.27936872435322047
ROC train: 0.954532	val: 0.593256	test: 0.569066
PRC train: 0.937212	val: 0.652050	test: 0.613012

Epoch: 111
Loss: 0.27889024959493114
ROC train: 0.956974	val: 0.592967	test: 0.567974
PRC train: 0.939582	val: 0.650965	test: 0.613256

Epoch: 112
Loss: 0.285691384878482
ROC train: 0.957778	val: 0.591504	test: 0.577107
PRC train: 0.939448	val: 0.650246	test: 0.615462

Epoch: 113
Loss: 0.27640175850304016
ROC train: 0.955879	val: 0.591295	test: 0.581343
PRC train: 0.934769	val: 0.650092	test: 0.617507

Epoch: 114
Loss: 0.2739181259469494
ROC train: 0.958115	val: 0.592550	test: 0.574773
PRC train: 0.940498	val: 0.649821	test: 0.615407

Epoch: 115
Loss: 0.27920873952938563
ROC train: 0.960179	val: 0.593918	test: 0.572602
PRC train: 0.946468	val: 0.653189	test: 0.621348

Epoch: 116
Loss: 0.2705369039325661
ROC train: 0.961764	val: 0.593743	test: 0.571612
PRC train: 0.947188	val: 0.653234	test: 0.618980

Epoch: 117
Loss: 0.2669590753765808
ROC train: 0.960568	val: 0.589422	test: 0.570828
PRC train: 0.944440	val: 0.651034	test: 0.615682

Epoch: 118
Loss: 0.2693728295077225
ROC train: 0.961222	val: 0.588788	test: 0.569644
PRC train: 0.947159	val: 0.647732	test: 0.613068

Epoch: 119
Loss: 0.26771818408081594
ROC train: 0.963294	val: 0.590685	test: 0.569315
PRC train: 0.948715	val: 0.649980	test: 0.617606

Epoch: 120
Loss: 0.266403684321075
ROC train: 0.964292	val: 0.587798	test: 0.557778
PRC train: 0.948552	val: 0.649996	test: 0.615877

Early stopping
Best (ROC):	 train: 0.875429	val: 0.611526	test: 0.578086
Best (PRC):	 train: 0.831393	val: 0.661386	test: 0.613900

PRC train: 0.897095	val: 0.656813	test: 0.623069

Epoch: 94
Loss: 0.3195444321998201
ROC train: 0.933323	val: 0.616817	test: 0.564268
PRC train: 0.901971	val: 0.664783	test: 0.615492

Epoch: 95
Loss: 0.3141978403111922
ROC train: 0.933891	val: 0.612565	test: 0.572598
PRC train: 0.901530	val: 0.662483	test: 0.620242

Epoch: 96
Loss: 0.31227739115084086
ROC train: 0.934610	val: 0.605035	test: 0.579107
PRC train: 0.903377	val: 0.656303	test: 0.621608

Epoch: 97
Loss: 0.31313668488491514
ROC train: 0.937081	val: 0.599684	test: 0.579333
PRC train: 0.905459	val: 0.657048	test: 0.621354

Epoch: 98
Loss: 0.3142170752053498
ROC train: 0.934403	val: 0.597803	test: 0.579594
PRC train: 0.906403	val: 0.652872	test: 0.623290

Epoch: 99
Loss: 0.3158494682544025
ROC train: 0.937556	val: 0.612342	test: 0.570052
PRC train: 0.910722	val: 0.660497	test: 0.617669

Epoch: 100
Loss: 0.30753868735203743
ROC train: 0.938721	val: 0.613963	test: 0.572098
PRC train: 0.911978	val: 0.662496	test: 0.618251

Epoch: 101
Loss: 0.306003588975906
ROC train: 0.940514	val: 0.615016	test: 0.579855
PRC train: 0.914784	val: 0.661530	test: 0.622902

Epoch: 102
Loss: 0.30699679843591154
ROC train: 0.939549	val: 0.611569	test: 0.577433
PRC train: 0.914637	val: 0.661195	test: 0.619313

Epoch: 103
Loss: 0.30440035574540847
ROC train: 0.939699	val: 0.600215	test: 0.573000
PRC train: 0.913768	val: 0.657785	test: 0.618899

Epoch: 104
Loss: 0.3053099295823137
ROC train: 0.942121	val: 0.596676	test: 0.565981
PRC train: 0.914372	val: 0.659400	test: 0.617447

Epoch: 105
Loss: 0.29883108918170387
ROC train: 0.941545	val: 0.605148	test: 0.574653
PRC train: 0.916100	val: 0.658100	test: 0.625794

Epoch: 106
Loss: 0.3023336778143525
ROC train: 0.942238	val: 0.611835	test: 0.582867
PRC train: 0.916398	val: 0.656183	test: 0.632130

Epoch: 107
Loss: 0.29463881572591033
ROC train: 0.944876	val: 0.617366	test: 0.579709
PRC train: 0.920133	val: 0.662327	test: 0.625720

Epoch: 108
Loss: 0.30369652606077313
ROC train: 0.945337	val: 0.620445	test: 0.577202
PRC train: 0.915974	val: 0.663074	test: 0.625552

Epoch: 109
Loss: 0.2964003821402995
ROC train: 0.946315	val: 0.616755	test: 0.572648
PRC train: 0.916242	val: 0.657427	test: 0.627122

Epoch: 110
Loss: 0.2980992184057231
ROC train: 0.948937	val: 0.608788	test: 0.565235
PRC train: 0.924347	val: 0.656326	test: 0.621330

Epoch: 111
Loss: 0.29208165446879
ROC train: 0.948517	val: 0.612185	test: 0.574359
PRC train: 0.926103	val: 0.660454	test: 0.621077

Epoch: 112
Loss: 0.29153400458763534
ROC train: 0.947627	val: 0.617506	test: 0.571801
PRC train: 0.922444	val: 0.662405	test: 0.619925

Epoch: 113
Loss: 0.2873797921542572
ROC train: 0.949938	val: 0.619335	test: 0.568639
PRC train: 0.926274	val: 0.667256	test: 0.616633

Epoch: 114
Loss: 0.2933586611959811
ROC train: 0.952554	val: 0.619816	test: 0.565753
PRC train: 0.932092	val: 0.665755	test: 0.617561

Epoch: 115
Loss: 0.2922402675172794
ROC train: 0.952877	val: 0.621404	test: 0.565211
PRC train: 0.932018	val: 0.667796	test: 0.616486

Epoch: 116
Loss: 0.29004834620181497
ROC train: 0.953326	val: 0.620285	test: 0.568498
PRC train: 0.930212	val: 0.663744	test: 0.617812

Epoch: 117
Loss: 0.284322418646873
ROC train: 0.953107	val: 0.617454	test: 0.571646
PRC train: 0.932225	val: 0.662154	test: 0.618166

Epoch: 118
Loss: 0.2863009736807858
ROC train: 0.953693	val: 0.617912	test: 0.565434
PRC train: 0.929729	val: 0.663684	test: 0.615369

Epoch: 119
Loss: 0.28729248024651605
ROC train: 0.955007	val: 0.605766	test: 0.568135
PRC train: 0.934706	val: 0.660308	test: 0.621494

Epoch: 120
Loss: 0.28351041294674023
ROC train: 0.954783	val: 0.606984	test: 0.569375
PRC train: 0.934705	val: 0.665685	test: 0.620592

Early stopping
Best (ROC):	 train: 0.884694	val: 0.631174	test: 0.580161
Best (PRC):	 train: 0.845979	val: 0.660585	test: 0.615396

PRC train: 0.904429	val: 0.623176	test: 0.604287

Epoch: 94
Loss: 0.3080500857070353
ROC train: 0.934893	val: 0.537907	test: 0.546417
PRC train: 0.905493	val: 0.617414	test: 0.604132

Epoch: 95
Loss: 0.3109428691090662
ROC train: 0.935342	val: 0.532402	test: 0.541560
PRC train: 0.901463	val: 0.614437	test: 0.600925

Epoch: 96
Loss: 0.30813655971379345
ROC train: 0.937140	val: 0.521876	test: 0.551545
PRC train: 0.906451	val: 0.610013	test: 0.605291

Epoch: 97
Loss: 0.30426547164261486
ROC train: 0.938781	val: 0.516960	test: 0.556328
PRC train: 0.911927	val: 0.605908	test: 0.609432

Epoch: 98
Loss: 0.3075557953889759
ROC train: 0.940956	val: 0.531717	test: 0.545666
PRC train: 0.914658	val: 0.612997	test: 0.602980

Epoch: 99
Loss: 0.3103863254023421
ROC train: 0.941510	val: 0.534160	test: 0.542503
PRC train: 0.913688	val: 0.619352	test: 0.602339

Epoch: 100
Loss: 0.30272242445156294
ROC train: 0.941999	val: 0.536062	test: 0.544729
PRC train: 0.912983	val: 0.621485	test: 0.603395

Epoch: 101
Loss: 0.30132148641026824
ROC train: 0.943852	val: 0.533356	test: 0.542571
PRC train: 0.916180	val: 0.619404	test: 0.604460

Epoch: 102
Loss: 0.2964625476916625
ROC train: 0.943063	val: 0.525812	test: 0.540350
PRC train: 0.917639	val: 0.613203	test: 0.602096

Epoch: 103
Loss: 0.29790130631255135
ROC train: 0.942422	val: 0.519992	test: 0.549320
PRC train: 0.915319	val: 0.610850	test: 0.605699

Epoch: 104
Loss: 0.29857806166310896
ROC train: 0.944508	val: 0.518156	test: 0.560388
PRC train: 0.916768	val: 0.610748	test: 0.612974

Epoch: 105
Loss: 0.290241720021739
ROC train: 0.946050	val: 0.529576	test: 0.544896
PRC train: 0.919846	val: 0.616172	test: 0.605806

Epoch: 106
Loss: 0.2982988597558662
ROC train: 0.947133	val: 0.530742	test: 0.545686
PRC train: 0.923046	val: 0.614164	test: 0.605685

Epoch: 107
Loss: 0.29033317696171085
ROC train: 0.946671	val: 0.525470	test: 0.543070
PRC train: 0.922184	val: 0.615841	test: 0.605141

Epoch: 108
Loss: 0.28661989725143766
ROC train: 0.947708	val: 0.520358	test: 0.539703
PRC train: 0.926866	val: 0.615176	test: 0.603107

Epoch: 109
Loss: 0.28876482021279704
ROC train: 0.948288	val: 0.522354	test: 0.534421
PRC train: 0.929546	val: 0.610572	test: 0.597758

Epoch: 110
Loss: 0.2888180207580785
ROC train: 0.951750	val: 0.530156	test: 0.527337
PRC train: 0.932157	val: 0.617661	test: 0.592384

Epoch: 111
Loss: 0.2930501982234901
ROC train: 0.951050	val: 0.532080	test: 0.528506
PRC train: 0.931096	val: 0.617718	test: 0.596766

Epoch: 112
Loss: 0.2878756588575745
ROC train: 0.954142	val: 0.525382	test: 0.532440
PRC train: 0.929996	val: 0.618790	test: 0.599578

Epoch: 113
Loss: 0.28340476581661933
ROC train: 0.956363	val: 0.522253	test: 0.535219
PRC train: 0.933569	val: 0.615504	test: 0.601857

Epoch: 114
Loss: 0.2831193217152561
ROC train: 0.955490	val: 0.534646	test: 0.532845
PRC train: 0.932780	val: 0.618064	test: 0.599327

Epoch: 115
Loss: 0.2757645343222722
ROC train: 0.956076	val: 0.531812	test: 0.533015
PRC train: 0.933965	val: 0.615205	test: 0.599493

Epoch: 116
Loss: 0.28254091350573834
ROC train: 0.956386	val: 0.524609	test: 0.537888
PRC train: 0.932185	val: 0.611520	test: 0.602009

Epoch: 117
Loss: 0.27793685149305636
ROC train: 0.958049	val: 0.521759	test: 0.532597
PRC train: 0.934621	val: 0.610804	test: 0.601321

Epoch: 118
Loss: 0.2780510762108833
ROC train: 0.958749	val: 0.518581	test: 0.537844
PRC train: 0.940873	val: 0.607918	test: 0.603697

Epoch: 119
Loss: 0.2721834514647168
ROC train: 0.960263	val: 0.520655	test: 0.538340
PRC train: 0.943045	val: 0.605776	test: 0.603599

Epoch: 120
Loss: 0.27615304149017517
ROC train: 0.960617	val: 0.533605	test: 0.531101
PRC train: 0.944490	val: 0.613883	test: 0.595356

Early stopping
Best (ROC):	 train: 0.675922	val: 0.564656	test: 0.563984
Best (PRC):	 train: 0.677746	val: 0.633295	test: 0.613548

PRC train: 0.911971	val: 0.622156	test: 0.610526

Epoch: 94
Loss: 0.31168614298375363
ROC train: 0.934494	val: 0.540265	test: 0.563027
PRC train: 0.909680	val: 0.616953	test: 0.607564

Epoch: 95
Loss: 0.30893487861904273
ROC train: 0.934146	val: 0.542008	test: 0.562364
PRC train: 0.907173	val: 0.618502	test: 0.606021

Epoch: 96
Loss: 0.3079857980426672
ROC train: 0.935268	val: 0.558994	test: 0.566440
PRC train: 0.910122	val: 0.631161	test: 0.609786

Epoch: 97
Loss: 0.30610271976697323
ROC train: 0.939833	val: 0.564605	test: 0.558892
PRC train: 0.915675	val: 0.631550	test: 0.609474

Epoch: 98
Loss: 0.299011047157205
ROC train: 0.940341	val: 0.551436	test: 0.560796
PRC train: 0.919019	val: 0.620868	test: 0.608498

Epoch: 99
Loss: 0.30396032207632523
ROC train: 0.940227	val: 0.545620	test: 0.565363
PRC train: 0.921828	val: 0.619252	test: 0.607463

Epoch: 100
Loss: 0.3012795333027652
ROC train: 0.940273	val: 0.542760	test: 0.561189
PRC train: 0.919640	val: 0.617227	test: 0.605375

Epoch: 101
Loss: 0.3002796991811857
ROC train: 0.940181	val: 0.550738	test: 0.552383
PRC train: 0.919064	val: 0.616576	test: 0.603230

Epoch: 102
Loss: 0.3047329697733997
ROC train: 0.945565	val: 0.553414	test: 0.558396
PRC train: 0.927840	val: 0.619409	test: 0.606953

Epoch: 103
Loss: 0.2971463945870153
ROC train: 0.944900	val: 0.544923	test: 0.574012
PRC train: 0.926283	val: 0.620480	test: 0.615481

Epoch: 104
Loss: 0.2997268263188685
ROC train: 0.944719	val: 0.545861	test: 0.570167
PRC train: 0.926765	val: 0.626898	test: 0.617231

Epoch: 105
Loss: 0.2923655007015634
ROC train: 0.947740	val: 0.546766	test: 0.556177
PRC train: 0.928516	val: 0.621557	test: 0.604739

Epoch: 106
Loss: 0.2930153739185458
ROC train: 0.947474	val: 0.561812	test: 0.552846
PRC train: 0.925079	val: 0.629884	test: 0.605468

Epoch: 107
Loss: 0.2867449386950206
ROC train: 0.950633	val: 0.553453	test: 0.556265
PRC train: 0.934331	val: 0.627126	test: 0.609964

Epoch: 108
Loss: 0.2870445590587796
ROC train: 0.951118	val: 0.545185	test: 0.551935
PRC train: 0.935325	val: 0.618986	test: 0.609186

Epoch: 109
Loss: 0.2892537925853106
ROC train: 0.951740	val: 0.544235	test: 0.553308
PRC train: 0.935390	val: 0.618785	test: 0.611348

Epoch: 110
Loss: 0.2827370365333885
ROC train: 0.952642	val: 0.550904	test: 0.549872
PRC train: 0.936804	val: 0.625160	test: 0.609755

Epoch: 111
Loss: 0.2820817579876172
ROC train: 0.953419	val: 0.541803	test: 0.552011
PRC train: 0.936758	val: 0.621149	test: 0.607144

Epoch: 112
Loss: 0.2835214226600212
ROC train: 0.953431	val: 0.542500	test: 0.545331
PRC train: 0.936644	val: 0.617727	test: 0.605557

Epoch: 113
Loss: 0.27983482857595926
ROC train: 0.955970	val: 0.543880	test: 0.548427
PRC train: 0.938852	val: 0.619499	test: 0.605516

Epoch: 114
Loss: 0.287221073534402
ROC train: 0.958420	val: 0.542022	test: 0.555926
PRC train: 0.942820	val: 0.619583	test: 0.609194

Epoch: 115
Loss: 0.2791379306478119
ROC train: 0.958635	val: 0.547198	test: 0.562445
PRC train: 0.943519	val: 0.622932	test: 0.613790

Epoch: 116
Loss: 0.28190436917775497
ROC train: 0.957189	val: 0.556432	test: 0.560595
PRC train: 0.938727	val: 0.629749	test: 0.613292

Epoch: 117
Loss: 0.2750299798501149
ROC train: 0.956450	val: 0.563908	test: 0.551565
PRC train: 0.940839	val: 0.632342	test: 0.606625

Epoch: 118
Loss: 0.27345141193733596
ROC train: 0.959698	val: 0.545356	test: 0.553705
PRC train: 0.943870	val: 0.621195	test: 0.602722

Epoch: 119
Loss: 0.27018014187484146
ROC train: 0.960562	val: 0.538279	test: 0.554495
PRC train: 0.946321	val: 0.618453	test: 0.606926

Epoch: 120
Loss: 0.27191372267116903
ROC train: 0.960923	val: 0.550390	test: 0.555924
PRC train: 0.945964	val: 0.628060	test: 0.610634

Early stopping
Best (ROC):	 train: 0.838795	val: 0.576758	test: 0.540613
Best (PRC):	 train: 0.800951	val: 0.642308	test: 0.595901

PRC train: 0.898805	val: 0.623200	test: 0.622013

Epoch: 94
Loss: 0.3215710006942033
ROC train: 0.932182	val: 0.560493	test: 0.538964
PRC train: 0.900853	val: 0.628417	test: 0.617369

Epoch: 95
Loss: 0.317734993322042
ROC train: 0.935420	val: 0.556428	test: 0.550533
PRC train: 0.907210	val: 0.627135	test: 0.619561

Epoch: 96
Loss: 0.30784403509292496
ROC train: 0.935250	val: 0.550899	test: 0.558585
PRC train: 0.907279	val: 0.624873	test: 0.620870

Epoch: 97
Loss: 0.30977557794795785
ROC train: 0.935390	val: 0.548014	test: 0.548602
PRC train: 0.908339	val: 0.630761	test: 0.613810

Epoch: 98
Loss: 0.30874609754740334
ROC train: 0.937017	val: 0.543899	test: 0.558873
PRC train: 0.911062	val: 0.622071	test: 0.620375

Epoch: 99
Loss: 0.30780009231139205
ROC train: 0.937691	val: 0.546800	test: 0.542126
PRC train: 0.909892	val: 0.620236	test: 0.610366

Epoch: 100
Loss: 0.3084908901917558
ROC train: 0.938510	val: 0.554719	test: 0.548099
PRC train: 0.908006	val: 0.622895	test: 0.617557

Epoch: 101
Loss: 0.30409325916339136
ROC train: 0.939074	val: 0.563711	test: 0.559253
PRC train: 0.910995	val: 0.626116	test: 0.621608

Epoch: 102
Loss: 0.309518451161183
ROC train: 0.939966	val: 0.549938	test: 0.551445
PRC train: 0.913848	val: 0.624040	test: 0.616668

Epoch: 103
Loss: 0.30138314432326435
ROC train: 0.941216	val: 0.545410	test: 0.553336
PRC train: 0.916190	val: 0.621266	test: 0.621217

Epoch: 104
Loss: 0.30340986462765607
ROC train: 0.940204	val: 0.550489	test: 0.537156
PRC train: 0.915591	val: 0.623500	test: 0.611780

Epoch: 105
Loss: 0.2966821539158821
ROC train: 0.944037	val: 0.539152	test: 0.547645
PRC train: 0.918219	val: 0.618924	test: 0.618598

Epoch: 106
Loss: 0.3005016684441274
ROC train: 0.944321	val: 0.550364	test: 0.557751
PRC train: 0.921030	val: 0.624704	test: 0.623608

Epoch: 107
Loss: 0.294350501418746
ROC train: 0.946271	val: 0.559892	test: 0.554210
PRC train: 0.925919	val: 0.631219	test: 0.618548

Epoch: 108
Loss: 0.29621970404913645
ROC train: 0.945403	val: 0.553202	test: 0.561087
PRC train: 0.920958	val: 0.625652	test: 0.625703

Epoch: 109
Loss: 0.29441923920308305
ROC train: 0.948286	val: 0.553172	test: 0.554511
PRC train: 0.921609	val: 0.623741	test: 0.619789

Epoch: 110
Loss: 0.2922784678681401
ROC train: 0.948746	val: 0.562845	test: 0.544118
PRC train: 0.924372	val: 0.629983	test: 0.611215

Epoch: 111
Loss: 0.29055889700871146
ROC train: 0.948278	val: 0.554807	test: 0.562115
PRC train: 0.923705	val: 0.629163	test: 0.620069

Epoch: 112
Loss: 0.28530972415859707
ROC train: 0.949581	val: 0.548377	test: 0.556586
PRC train: 0.927496	val: 0.629073	test: 0.620988

Epoch: 113
Loss: 0.28818732820116477
ROC train: 0.949841	val: 0.551168	test: 0.563339
PRC train: 0.924642	val: 0.624645	test: 0.625186

Epoch: 114
Loss: 0.2963604113885536
ROC train: 0.952697	val: 0.560729	test: 0.564125
PRC train: 0.930460	val: 0.625343	test: 0.622295

Epoch: 115
Loss: 0.29262907382006603
ROC train: 0.953927	val: 0.560283	test: 0.555816
PRC train: 0.933548	val: 0.627758	test: 0.614778

Epoch: 116
Loss: 0.296075737834809
ROC train: 0.951766	val: 0.557692	test: 0.568475
PRC train: 0.931156	val: 0.627816	test: 0.625736

Epoch: 117
Loss: 0.2841670299172934
ROC train: 0.952799	val: 0.558681	test: 0.548901
PRC train: 0.932700	val: 0.630515	test: 0.614935

Epoch: 118
Loss: 0.27937523597665964
ROC train: 0.954378	val: 0.550728	test: 0.554831
PRC train: 0.930437	val: 0.620147	test: 0.619439

Epoch: 119
Loss: 0.27835360947431276
ROC train: 0.956256	val: 0.546960	test: 0.561685
PRC train: 0.932155	val: 0.617309	test: 0.622281

Epoch: 120
Loss: 0.27863346447062276
ROC train: 0.956647	val: 0.549184	test: 0.554979
PRC train: 0.935773	val: 0.621656	test: 0.618932

Early stopping
Best (ROC):	 train: 0.798609	val: 0.583010	test: 0.565028
Best (PRC):	 train: 0.761409	val: 0.643611	test: 0.613794

PRC train: 0.901608	val: 0.661545	test: 0.629477

Epoch: 94
Loss: 0.3143515891159817
ROC train: 0.931541	val: 0.595481	test: 0.605362
PRC train: 0.899160	val: 0.668686	test: 0.637236

Epoch: 95
Loss: 0.31653837304540505
ROC train: 0.934198	val: 0.598103	test: 0.598405
PRC train: 0.902256	val: 0.665546	test: 0.632285

Epoch: 96
Loss: 0.3094805421163083
ROC train: 0.934366	val: 0.589533	test: 0.591396
PRC train: 0.899668	val: 0.657730	test: 0.627124

Epoch: 97
Loss: 0.30596036802044885
ROC train: 0.937924	val: 0.588170	test: 0.594064
PRC train: 0.906498	val: 0.656756	test: 0.629840

Epoch: 98
Loss: 0.3082475766580888
ROC train: 0.936033	val: 0.586011	test: 0.591693
PRC train: 0.904129	val: 0.657680	test: 0.627154

Epoch: 99
Loss: 0.30618789340865415
ROC train: 0.937245	val: 0.580329	test: 0.598109
PRC train: 0.903645	val: 0.651884	test: 0.626002

Epoch: 100
Loss: 0.3091272623373121
ROC train: 0.939246	val: 0.582984	test: 0.599103
PRC train: 0.908397	val: 0.656412	test: 0.629505

Epoch: 101
Loss: 0.2980089884837321
ROC train: 0.935427	val: 0.600923	test: 0.590922
PRC train: 0.905915	val: 0.672493	test: 0.631668

Epoch: 102
Loss: 0.3024754416471283
ROC train: 0.940652	val: 0.591023	test: 0.588940
PRC train: 0.911265	val: 0.663424	test: 0.623694

Epoch: 103
Loss: 0.30014375505670116
ROC train: 0.939553	val: 0.585789	test: 0.578931
PRC train: 0.915041	val: 0.659437	test: 0.622487

Epoch: 104
Loss: 0.3000433100701425
ROC train: 0.944496	val: 0.585265	test: 0.589186
PRC train: 0.918918	val: 0.660600	test: 0.626669

Epoch: 105
Loss: 0.29504563646542986
ROC train: 0.943516	val: 0.590351	test: 0.596818
PRC train: 0.914404	val: 0.662958	test: 0.631151

Epoch: 106
Loss: 0.29588072629402073
ROC train: 0.941450	val: 0.583750	test: 0.596551
PRC train: 0.911534	val: 0.659841	test: 0.632050

Epoch: 107
Loss: 0.2994502604940929
ROC train: 0.946376	val: 0.577903	test: 0.591259
PRC train: 0.916534	val: 0.650813	test: 0.621437

Epoch: 108
Loss: 0.2938992426042032
ROC train: 0.946410	val: 0.582178	test: 0.587612
PRC train: 0.918934	val: 0.651375	test: 0.622394

Epoch: 109
Loss: 0.29832959863581027
ROC train: 0.945509	val: 0.594822	test: 0.584340
PRC train: 0.919425	val: 0.661357	test: 0.626105

Epoch: 110
Loss: 0.2935538624690395
ROC train: 0.948506	val: 0.584859	test: 0.586759
PRC train: 0.927407	val: 0.663059	test: 0.622201

Epoch: 111
Loss: 0.2906618207785317
ROC train: 0.948314	val: 0.583717	test: 0.582753
PRC train: 0.923882	val: 0.657113	test: 0.619546

Epoch: 112
Loss: 0.2931572336005575
ROC train: 0.946272	val: 0.590127	test: 0.583910
PRC train: 0.921528	val: 0.662806	test: 0.627545

Epoch: 113
Loss: 0.2877989144548263
ROC train: 0.948398	val: 0.590352	test: 0.589618
PRC train: 0.924328	val: 0.663019	test: 0.629417

Epoch: 114
Loss: 0.28718338148334743
ROC train: 0.950281	val: 0.604173	test: 0.598977
PRC train: 0.923812	val: 0.669917	test: 0.634503

Epoch: 115
Loss: 0.2832616883153996
ROC train: 0.950161	val: 0.600944	test: 0.593805
PRC train: 0.922659	val: 0.673275	test: 0.630538

Epoch: 116
Loss: 0.28553678958825
ROC train: 0.954036	val: 0.589984	test: 0.595861
PRC train: 0.926773	val: 0.662200	test: 0.628129

Epoch: 117
Loss: 0.2826175802455249
ROC train: 0.953765	val: 0.584126	test: 0.590804
PRC train: 0.933146	val: 0.661297	test: 0.628005

Epoch: 118
Loss: 0.2778641614256677
ROC train: 0.952999	val: 0.580043	test: 0.580191
PRC train: 0.935520	val: 0.656502	test: 0.620743

Epoch: 119
Loss: 0.2776723616736688
ROC train: 0.956012	val: 0.563347	test: 0.577387
PRC train: 0.932557	val: 0.646946	test: 0.614876

Epoch: 120
Loss: 0.2772878301877418
ROC train: 0.954907	val: 0.582906	test: 0.587713
PRC train: 0.933553	val: 0.659220	test: 0.625064

Early stopping
Best (ROC):	 train: 0.810931	val: 0.619728	test: 0.603890
Best (PRC):	 train: 0.776595	val: 0.668658	test: 0.635849
All runs completed.

PRC train: 0.861289	val: 0.674149	test: 0.629258

Epoch: 95
Loss: 0.36351542460687924
ROC train: 0.896719	val: 0.638822	test: 0.608155
PRC train: 0.859927	val: 0.675056	test: 0.634858

Epoch: 96
Loss: 0.3633928334535386
ROC train: 0.898545	val: 0.639866	test: 0.595171
PRC train: 0.860478	val: 0.677699	test: 0.626895

Epoch: 97
Loss: 0.3668718431531904
ROC train: 0.902187	val: 0.637482	test: 0.583153
PRC train: 0.864817	val: 0.675568	test: 0.622957

Epoch: 98
Loss: 0.3625318038441618
ROC train: 0.901564	val: 0.643916	test: 0.594250
PRC train: 0.863349	val: 0.677112	test: 0.632526

Epoch: 99
Loss: 0.36162901297186995
ROC train: 0.903414	val: 0.637691	test: 0.596942
PRC train: 0.865410	val: 0.673483	test: 0.634595

Epoch: 100
Loss: 0.36088758963747497
ROC train: 0.904793	val: 0.641325	test: 0.584008
PRC train: 0.863618	val: 0.677661	test: 0.626514

Epoch: 101
Loss: 0.36169232314476496
ROC train: 0.907766	val: 0.641607	test: 0.592440
PRC train: 0.869961	val: 0.676982	test: 0.630444

Epoch: 102
Loss: 0.35547062143226227
ROC train: 0.903254	val: 0.636101	test: 0.606904
PRC train: 0.867128	val: 0.672216	test: 0.638791

Epoch: 103
Loss: 0.35287362284424206
ROC train: 0.905426	val: 0.649104	test: 0.603386
PRC train: 0.869705	val: 0.677474	test: 0.637861

Epoch: 104
Loss: 0.36416678913974654
ROC train: 0.906599	val: 0.650065	test: 0.584016
PRC train: 0.870646	val: 0.681869	test: 0.629032

Epoch: 105
Loss: 0.35525569453824507
ROC train: 0.900224	val: 0.630399	test: 0.583612
PRC train: 0.861576	val: 0.674938	test: 0.627787

Epoch: 106
Loss: 0.3583812810811502
ROC train: 0.905584	val: 0.637585	test: 0.585511
PRC train: 0.868063	val: 0.669725	test: 0.627836

Epoch: 107
Loss: 0.3515440689021947
ROC train: 0.908820	val: 0.638948	test: 0.584159
PRC train: 0.871765	val: 0.677735	test: 0.631312

Epoch: 108
Loss: 0.35340712051593753
ROC train: 0.912260	val: 0.630495	test: 0.592129
PRC train: 0.875374	val: 0.672465	test: 0.632582

Epoch: 109
Loss: 0.3544577294059968
ROC train: 0.910460	val: 0.628858	test: 0.595525
PRC train: 0.873772	val: 0.669935	test: 0.632924

Epoch: 110
Loss: 0.35367913982778826
ROC train: 0.909157	val: 0.639972	test: 0.571679
PRC train: 0.874720	val: 0.679317	test: 0.620075

Epoch: 111
Loss: 0.3532653587759104
ROC train: 0.912881	val: 0.646315	test: 0.579884
PRC train: 0.875366	val: 0.676776	test: 0.631414

Epoch: 112
Loss: 0.34899480328150223
ROC train: 0.912828	val: 0.639892	test: 0.586016
PRC train: 0.878127	val: 0.671069	test: 0.634010

Epoch: 113
Loss: 0.34993804700923914
ROC train: 0.914527	val: 0.644551	test: 0.592989
PRC train: 0.880979	val: 0.675108	test: 0.637611

Epoch: 114
Loss: 0.34309814240805236
ROC train: 0.913275	val: 0.644377	test: 0.600903
PRC train: 0.880992	val: 0.676227	test: 0.638891

Epoch: 115
Loss: 0.344270549634496
ROC train: 0.916729	val: 0.637821	test: 0.607244
PRC train: 0.883150	val: 0.670777	test: 0.638942

Epoch: 116
Loss: 0.3429708952030009
ROC train: 0.918762	val: 0.643906	test: 0.599656
PRC train: 0.883668	val: 0.676161	test: 0.634561

Epoch: 117
Loss: 0.3421806612692243
ROC train: 0.919661	val: 0.640447	test: 0.591852
PRC train: 0.886585	val: 0.676614	test: 0.632706

Epoch: 118
Loss: 0.3406015005317424
ROC train: 0.921632	val: 0.630728	test: 0.601788
PRC train: 0.890026	val: 0.667723	test: 0.639968

Epoch: 119
Loss: 0.34342954277232696
ROC train: 0.921327	val: 0.632407	test: 0.603923
PRC train: 0.889031	val: 0.673030	test: 0.639873

Epoch: 120
Loss: 0.3355979937361872
ROC train: 0.921523	val: 0.646135	test: 0.605490
PRC train: 0.891967	val: 0.680216	test: 0.636787

Epoch: 121
Loss: 0.33726818833472333
ROC train: 0.922590	val: 0.644025	test: 0.609843
PRC train: 0.892607	val: 0.680228	test: 0.638431

Epoch: 122
Loss: 0.34236000240220144
ROC train: 0.922872	val: 0.625997	test: 0.604605
PRC train: 0.893886	val: 0.672361	test: 0.635381

Epoch: 123
Loss: 0.33729547100335255
ROC train: 0.923937	val: 0.639207	test: 0.603340
PRC train: 0.893962	val: 0.677287	test: 0.637981

Epoch: 124
Loss: 0.33331685416079193
ROC train: 0.924785	val: 0.645348	test: 0.594930
PRC train: 0.895217	val: 0.679368	test: 0.633559

Epoch: 125
Loss: 0.3317238730468439
ROC train: 0.925672	val: 0.634917	test: 0.593609
PRC train: 0.896357	val: 0.678914	test: 0.629992

Epoch: 126
Loss: 0.33738689679791817
ROC train: 0.926416	val: 0.639491	test: 0.586048
PRC train: 0.897604	val: 0.674917	test: 0.629173

Epoch: 127
Loss: 0.3288126173959146
ROC train: 0.925917	val: 0.646207	test: 0.594443
PRC train: 0.898760	val: 0.676641	test: 0.635183

Epoch: 128
Loss: 0.33195885734678987
ROC train: 0.928474	val: 0.636311	test: 0.589122
PRC train: 0.901810	val: 0.673221	test: 0.631667

Epoch: 129
Loss: 0.33168975861947964
ROC train: 0.928268	val: 0.634989	test: 0.594362
PRC train: 0.901067	val: 0.669064	test: 0.632293

Epoch: 130
Loss: 0.328559216675404
ROC train: 0.927198	val: 0.637151	test: 0.598643
PRC train: 0.898985	val: 0.675073	test: 0.634796

Epoch: 131
Loss: 0.32810953839605617
ROC train: 0.926923	val: 0.630259	test: 0.593705
PRC train: 0.896501	val: 0.667728	test: 0.630349

Epoch: 132
Loss: 0.3274093056854736
ROC train: 0.931134	val: 0.641762	test: 0.593406
PRC train: 0.900627	val: 0.675548	test: 0.632047

Epoch: 133
Loss: 0.32623848060840555
ROC train: 0.932397	val: 0.644822	test: 0.596656
PRC train: 0.904683	val: 0.673049	test: 0.634846

Epoch: 134
Loss: 0.3228331051777335
ROC train: 0.931993	val: 0.633680	test: 0.600822
PRC train: 0.902929	val: 0.666709	test: 0.638475

Epoch: 135
Loss: 0.3224018304048781
ROC train: 0.934468	val: 0.638453	test: 0.590565
PRC train: 0.907166	val: 0.672707	test: 0.630530

Epoch: 136
Loss: 0.32326385924763734
ROC train: 0.933673	val: 0.641501	test: 0.586447
PRC train: 0.905353	val: 0.677055	test: 0.630296

Epoch: 137
Loss: 0.31896238059270454
ROC train: 0.932562	val: 0.628357	test: 0.580254
PRC train: 0.901693	val: 0.670764	test: 0.628352

Epoch: 138
Loss: 0.3207289889316308
ROC train: 0.934577	val: 0.638364	test: 0.584910
PRC train: 0.908225	val: 0.670273	test: 0.632731

Epoch: 139
Loss: 0.32272890389055964
ROC train: 0.934780	val: 0.643937	test: 0.601182
PRC train: 0.908401	val: 0.673991	test: 0.640588

Early stopping
Best (ROC):	 train: 0.906599	val: 0.650065	test: 0.584016
Best (PRC):	 train: 0.870646	val: 0.681869	test: 0.629032
All runs completed.


Epoch: 94
Loss: 0.3144259694664842
ROC train: 0.938265	val: 0.569479	test: 0.565899
PRC train: 0.902254	val: 0.650411	test: 0.612639

Epoch: 95
Loss: 0.30895908831783725
ROC train: 0.940812	val: 0.590194	test: 0.557873
PRC train: 0.903529	val: 0.659376	test: 0.609268

Epoch: 96
Loss: 0.3078856499303413
ROC train: 0.940053	val: 0.599597	test: 0.555734
PRC train: 0.903065	val: 0.659361	test: 0.609313

Epoch: 97
Loss: 0.3096822313347877
ROC train: 0.940583	val: 0.588250	test: 0.553702
PRC train: 0.906839	val: 0.656457	test: 0.607259

Epoch: 98
Loss: 0.3065522274865529
ROC train: 0.940978	val: 0.584681	test: 0.546204
PRC train: 0.907235	val: 0.659756	test: 0.606210

Epoch: 99
Loss: 0.3137815279244173
ROC train: 0.942490	val: 0.574529	test: 0.568746
PRC train: 0.907391	val: 0.658383	test: 0.616342

Epoch: 100
Loss: 0.3087074155636556
ROC train: 0.943855	val: 0.598663	test: 0.560898
PRC train: 0.909207	val: 0.667003	test: 0.612821

Epoch: 101
Loss: 0.301361358541529
ROC train: 0.942633	val: 0.597540	test: 0.581163
PRC train: 0.909755	val: 0.660203	test: 0.621640

Epoch: 102
Loss: 0.2995428305882018
ROC train: 0.944742	val: 0.591074	test: 0.569916
PRC train: 0.914268	val: 0.656079	test: 0.616970

Epoch: 103
Loss: 0.2981917198005843
ROC train: 0.946694	val: 0.580016	test: 0.561332
PRC train: 0.914605	val: 0.649152	test: 0.613807

Epoch: 104
Loss: 0.29809200645336914
ROC train: 0.947862	val: 0.584544	test: 0.564019
PRC train: 0.916664	val: 0.652354	test: 0.616653

Epoch: 105
Loss: 0.29716638484114516
ROC train: 0.949378	val: 0.590617	test: 0.574922
PRC train: 0.920674	val: 0.659177	test: 0.621580

Epoch: 106
Loss: 0.29648693829295647
ROC train: 0.950027	val: 0.594214	test: 0.563451
PRC train: 0.920610	val: 0.660607	test: 0.615970

Epoch: 107
Loss: 0.2906725746168305
ROC train: 0.950303	val: 0.595001	test: 0.560136
PRC train: 0.925451	val: 0.662393	test: 0.612716

Epoch: 108
Loss: 0.29057984254948077
ROC train: 0.952755	val: 0.590480	test: 0.559347
PRC train: 0.926174	val: 0.661079	test: 0.610542

Epoch: 109
Loss: 0.28942025623475637
ROC train: 0.952551	val: 0.589949	test: 0.555364
PRC train: 0.925442	val: 0.661832	test: 0.607629

Epoch: 110
Loss: 0.2837085945153069
ROC train: 0.953247	val: 0.587903	test: 0.548454
PRC train: 0.927277	val: 0.660458	test: 0.604963

Epoch: 111
Loss: 0.284934742714573
ROC train: 0.953072	val: 0.577600	test: 0.555762
PRC train: 0.928047	val: 0.651178	test: 0.608787

Epoch: 112
Loss: 0.2890111229374138
ROC train: 0.954749	val: 0.581140	test: 0.559580
PRC train: 0.930497	val: 0.655778	test: 0.611150

Epoch: 113
Loss: 0.28095984804305246
ROC train: 0.956620	val: 0.594448	test: 0.554448
PRC train: 0.930556	val: 0.661039	test: 0.609422

Epoch: 114
Loss: 0.27818173179200806
ROC train: 0.955796	val: 0.598572	test: 0.545854
PRC train: 0.928857	val: 0.660689	test: 0.603245

Epoch: 115
Loss: 0.2866316545090335
ROC train: 0.956800	val: 0.593273	test: 0.553651
PRC train: 0.931622	val: 0.659333	test: 0.609874

Epoch: 116
Loss: 0.2770710950760467
ROC train: 0.958350	val: 0.595355	test: 0.550312
PRC train: 0.931403	val: 0.662465	test: 0.609949

Epoch: 117
Loss: 0.27701943585926314
ROC train: 0.958693	val: 0.587028	test: 0.567817
PRC train: 0.930831	val: 0.659107	test: 0.614338

Epoch: 118
Loss: 0.2753120276730063
ROC train: 0.960809	val: 0.583836	test: 0.561761
PRC train: 0.932714	val: 0.655352	test: 0.611737

Epoch: 119
Loss: 0.2748556307958645
ROC train: 0.961200	val: 0.587016	test: 0.548539
PRC train: 0.933569	val: 0.655629	test: 0.604824

Epoch: 120
Loss: 0.27395891791704474
ROC train: 0.961739	val: 0.588129	test: 0.553197
PRC train: 0.939002	val: 0.657101	test: 0.606026

Epoch: 121
Loss: 0.27219933492667936
ROC train: 0.961716	val: 0.585175	test: 0.555197
PRC train: 0.940437	val: 0.655411	test: 0.608666

Epoch: 122
Loss: 0.2661199892758203
ROC train: 0.963271	val: 0.596620	test: 0.552688
PRC train: 0.942659	val: 0.664529	test: 0.607743

Epoch: 123
Loss: 0.2708301362371816
ROC train: 0.964576	val: 0.581858	test: 0.568745
PRC train: 0.943165	val: 0.657413	test: 0.613769

Epoch: 124
Loss: 0.2684087647242082
ROC train: 0.965336	val: 0.582380	test: 0.555374
PRC train: 0.940628	val: 0.655952	test: 0.610596

Epoch: 125
Loss: 0.26222400592392975
ROC train: 0.965845	val: 0.589451	test: 0.550404
PRC train: 0.942723	val: 0.658852	test: 0.608942

Epoch: 126
Loss: 0.26032159013257583
ROC train: 0.965330	val: 0.582755	test: 0.570081
PRC train: 0.944802	val: 0.653831	test: 0.618104

Epoch: 127
Loss: 0.2630969132605503
ROC train: 0.966073	val: 0.595309	test: 0.564622
PRC train: 0.945132	val: 0.661466	test: 0.612255

Epoch: 128
Loss: 0.26126556555182545
ROC train: 0.967533	val: 0.593730	test: 0.558008
PRC train: 0.947228	val: 0.658139	test: 0.608052

Epoch: 129
Loss: 0.26269785580977
ROC train: 0.968548	val: 0.592284	test: 0.550331
PRC train: 0.950634	val: 0.657888	test: 0.606947

Epoch: 130
Loss: 0.26092375570334786
ROC train: 0.969022	val: 0.586903	test: 0.553919
PRC train: 0.952155	val: 0.656658	test: 0.607685

Epoch: 131
Loss: 0.25749165757843634
ROC train: 0.969493	val: 0.577910	test: 0.560320
PRC train: 0.949425	val: 0.656421	test: 0.613811

Early stopping
Best (ROC):	 train: 0.940053	val: 0.599597	test: 0.555734
Best (PRC):	 train: 0.903065	val: 0.659361	test: 0.609313
All runs completed.

PRC train: 0.888844	val: 0.679415	test: 0.633857

Epoch: 94
Loss: 0.3267989741673475
ROC train: 0.928531	val: 0.644070	test: 0.604940
PRC train: 0.892030	val: 0.680958	test: 0.637795

Epoch: 95
Loss: 0.3267565176999023
ROC train: 0.930994	val: 0.632235	test: 0.603384
PRC train: 0.898355	val: 0.674876	test: 0.635999

Epoch: 96
Loss: 0.31860172309557744
ROC train: 0.930971	val: 0.635761	test: 0.592823
PRC train: 0.897415	val: 0.676167	test: 0.633291

Epoch: 97
Loss: 0.32120264004261123
ROC train: 0.933016	val: 0.644856	test: 0.590319
PRC train: 0.897683	val: 0.679657	test: 0.634064

Epoch: 98
Loss: 0.3194266306343991
ROC train: 0.932011	val: 0.645415	test: 0.589854
PRC train: 0.898730	val: 0.682433	test: 0.632099

Epoch: 99
Loss: 0.32266725845656963
ROC train: 0.933481	val: 0.638850	test: 0.593813
PRC train: 0.901719	val: 0.673900	test: 0.630775

Epoch: 100
Loss: 0.3148810484100027
ROC train: 0.935840	val: 0.634956	test: 0.598892
PRC train: 0.904422	val: 0.671218	test: 0.631818

Epoch: 101
Loss: 0.3146997988747383
ROC train: 0.937175	val: 0.625019	test: 0.602709
PRC train: 0.904717	val: 0.671118	test: 0.634261

Epoch: 102
Loss: 0.3162477403915379
ROC train: 0.936763	val: 0.627381	test: 0.607102
PRC train: 0.902822	val: 0.675172	test: 0.638616

Epoch: 103
Loss: 0.30961060322269235
ROC train: 0.938401	val: 0.635982	test: 0.598173
PRC train: 0.905721	val: 0.680605	test: 0.631135

Epoch: 104
Loss: 0.313191649589797
ROC train: 0.939794	val: 0.638068	test: 0.598220
PRC train: 0.906490	val: 0.675064	test: 0.630395

Epoch: 105
Loss: 0.3033299595101537
ROC train: 0.940071	val: 0.646138	test: 0.603041
PRC train: 0.904722	val: 0.679541	test: 0.636099

Epoch: 106
Loss: 0.3067522854080412
ROC train: 0.942143	val: 0.643914	test: 0.596544
PRC train: 0.909389	val: 0.678888	test: 0.630608

Epoch: 107
Loss: 0.3094404995930341
ROC train: 0.941238	val: 0.643486	test: 0.602310
PRC train: 0.908587	val: 0.676936	test: 0.636398

Epoch: 108
Loss: 0.30011094137224753
ROC train: 0.942462	val: 0.646874	test: 0.606090
PRC train: 0.911165	val: 0.679911	test: 0.637238

Epoch: 109
Loss: 0.3051014940774493
ROC train: 0.942049	val: 0.651328	test: 0.606669
PRC train: 0.911225	val: 0.680146	test: 0.635003

Epoch: 110
Loss: 0.30399629552802293
ROC train: 0.943568	val: 0.643856	test: 0.602819
PRC train: 0.913329	val: 0.677514	test: 0.633732

Epoch: 111
Loss: 0.3009784199143127
ROC train: 0.944691	val: 0.639229	test: 0.608129
PRC train: 0.915087	val: 0.675169	test: 0.638740

Epoch: 112
Loss: 0.30076594521545075
ROC train: 0.945339	val: 0.637787	test: 0.600591
PRC train: 0.915343	val: 0.672330	test: 0.632208

Epoch: 113
Loss: 0.2920527080200054
ROC train: 0.947885	val: 0.638747	test: 0.604805
PRC train: 0.918498	val: 0.673596	test: 0.639233

Epoch: 114
Loss: 0.2971315841608843
ROC train: 0.946497	val: 0.636103	test: 0.609089
PRC train: 0.920192	val: 0.674296	test: 0.643792

Epoch: 115
Loss: 0.2934918925458937
ROC train: 0.947289	val: 0.628302	test: 0.600934
PRC train: 0.922861	val: 0.671779	test: 0.638781

Epoch: 116
Loss: 0.29316461545150335
ROC train: 0.947074	val: 0.626372	test: 0.604714
PRC train: 0.923224	val: 0.668944	test: 0.635611

Epoch: 117
Loss: 0.2969151983777454
ROC train: 0.948945	val: 0.628162	test: 0.604729
PRC train: 0.926126	val: 0.669096	test: 0.633905

Epoch: 118
Loss: 0.29092767838648
ROC train: 0.952130	val: 0.634368	test: 0.602911
PRC train: 0.929020	val: 0.673088	test: 0.634074

Epoch: 119
Loss: 0.2881873456037225
ROC train: 0.951879	val: 0.643568	test: 0.601616
PRC train: 0.930133	val: 0.676724	test: 0.637879

Epoch: 120
Loss: 0.293281824817206
ROC train: 0.952065	val: 0.638271	test: 0.606069
PRC train: 0.930742	val: 0.675068	test: 0.637109

Epoch: 121
Loss: 0.28568494289962787
ROC train: 0.953095	val: 0.636309	test: 0.607145
PRC train: 0.931970	val: 0.676025	test: 0.629467

Epoch: 122
Loss: 0.2854661640486158
ROC train: 0.954034	val: 0.637099	test: 0.599263
PRC train: 0.931897	val: 0.676308	test: 0.628186

Epoch: 123
Loss: 0.2847257093384452
ROC train: 0.954328	val: 0.635223	test: 0.596550
PRC train: 0.933539	val: 0.679857	test: 0.627770

Epoch: 124
Loss: 0.2804526074275614
ROC train: 0.953689	val: 0.635032	test: 0.601767
PRC train: 0.934635	val: 0.676625	test: 0.631391

Epoch: 125
Loss: 0.28296513303346094
ROC train: 0.954787	val: 0.644961	test: 0.608297
PRC train: 0.936438	val: 0.678785	test: 0.640132

Epoch: 126
Loss: 0.2769005821440185
ROC train: 0.956589	val: 0.630564	test: 0.605776
PRC train: 0.942519	val: 0.671091	test: 0.638432

Epoch: 127
Loss: 0.27853172590551534
ROC train: 0.958637	val: 0.630538	test: 0.607000
PRC train: 0.942857	val: 0.670848	test: 0.637183

Epoch: 128
Loss: 0.2803382688716716
ROC train: 0.958850	val: 0.630081	test: 0.602770
PRC train: 0.938797	val: 0.668037	test: 0.636310

Epoch: 129
Loss: 0.27429779545382504
ROC train: 0.958959	val: 0.639197	test: 0.604101
PRC train: 0.940841	val: 0.675507	test: 0.633985

Epoch: 130
Loss: 0.2774487644993203
ROC train: 0.960746	val: 0.649884	test: 0.599046
PRC train: 0.942296	val: 0.681569	test: 0.632939

Epoch: 131
Loss: 0.2741604534470854
ROC train: 0.959316	val: 0.641210	test: 0.598780
PRC train: 0.944006	val: 0.676240	test: 0.630847

Epoch: 132
Loss: 0.27230306568534707
ROC train: 0.960682	val: 0.633815	test: 0.601988
PRC train: 0.943739	val: 0.675318	test: 0.634671

Epoch: 133
Loss: 0.2774174215261638
ROC train: 0.962109	val: 0.626023	test: 0.600980
PRC train: 0.943185	val: 0.670836	test: 0.640535

Epoch: 134
Loss: 0.26762627960618723
ROC train: 0.963603	val: 0.624488	test: 0.600427
PRC train: 0.948671	val: 0.671230	test: 0.632841

Epoch: 135
Loss: 0.26711132837449597
ROC train: 0.963879	val: 0.636996	test: 0.594681
PRC train: 0.949114	val: 0.675875	test: 0.627248

Epoch: 136
Loss: 0.2590381881409018
ROC train: 0.965523	val: 0.643375	test: 0.592816
PRC train: 0.948162	val: 0.676741	test: 0.628413

Epoch: 137
Loss: 0.2602932581456638
ROC train: 0.964769	val: 0.648289	test: 0.588609
PRC train: 0.949579	val: 0.678178	test: 0.625693

Epoch: 138
Loss: 0.26840113412060707
ROC train: 0.965476	val: 0.643697	test: 0.601456
PRC train: 0.951469	val: 0.674601	test: 0.633473

Epoch: 139
Loss: 0.2586422771049552
ROC train: 0.966197	val: 0.647660	test: 0.599908
PRC train: 0.950630	val: 0.676889	test: 0.631497

Epoch: 140
Loss: 0.2636327610100956
ROC train: 0.966698	val: 0.644164	test: 0.600990
PRC train: 0.952557	val: 0.675860	test: 0.629933

Epoch: 141
Loss: 0.25719914816712436
ROC train: 0.968203	val: 0.633408	test: 0.606028
PRC train: 0.955780	val: 0.671891	test: 0.635041

Epoch: 142
Loss: 0.2604281807915429
ROC train: 0.969379	val: 0.627062	test: 0.601623
PRC train: 0.957597	val: 0.672872	test: 0.636065

Epoch: 143
Loss: 0.25795395637204843
ROC train: 0.969507	val: 0.633706	test: 0.596239
PRC train: 0.958207	val: 0.674100	test: 0.634178

Epoch: 144
Loss: 0.25664408525480137
ROC train: 0.969311	val: 0.640747	test: 0.604611
PRC train: 0.958321	val: 0.678277	test: 0.637839

Early stopping
Best (ROC):	 train: 0.942049	val: 0.651328	test: 0.606669
Best (PRC):	 train: 0.911225	val: 0.680146	test: 0.635003

PRC train: 0.887064	val: 0.660619	test: 0.625420

Epoch: 94
Loss: 0.31966106219369994
ROC train: 0.930349	val: 0.599831	test: 0.592973
PRC train: 0.893175	val: 0.656098	test: 0.624778

Epoch: 95
Loss: 0.3196773392087274
ROC train: 0.932058	val: 0.611691	test: 0.601213
PRC train: 0.896245	val: 0.660576	test: 0.630397

Epoch: 96
Loss: 0.3180180464171346
ROC train: 0.933123	val: 0.618317	test: 0.598527
PRC train: 0.900107	val: 0.663287	test: 0.630530

Epoch: 97
Loss: 0.3205186114369756
ROC train: 0.933532	val: 0.616529	test: 0.586425
PRC train: 0.899684	val: 0.662258	test: 0.622916

Epoch: 98
Loss: 0.3158869563579464
ROC train: 0.935683	val: 0.614063	test: 0.590483
PRC train: 0.901578	val: 0.662953	test: 0.625785

Epoch: 99
Loss: 0.3164240058488318
ROC train: 0.935634	val: 0.611662	test: 0.591768
PRC train: 0.903361	val: 0.662493	test: 0.627212

Epoch: 100
Loss: 0.31804001431257156
ROC train: 0.935812	val: 0.614195	test: 0.594715
PRC train: 0.903665	val: 0.661561	test: 0.629693

Epoch: 101
Loss: 0.31047307834217885
ROC train: 0.935457	val: 0.612802	test: 0.596810
PRC train: 0.900639	val: 0.662358	test: 0.630306

Epoch: 102
Loss: 0.3108281828347234
ROC train: 0.935396	val: 0.604347	test: 0.591590
PRC train: 0.904848	val: 0.657789	test: 0.626152

Epoch: 103
Loss: 0.31298953807048957
ROC train: 0.938212	val: 0.607235	test: 0.605086
PRC train: 0.905738	val: 0.661137	test: 0.636309

Epoch: 104
Loss: 0.30789279496431987
ROC train: 0.939578	val: 0.609772	test: 0.616102
PRC train: 0.906107	val: 0.662884	test: 0.638523

Epoch: 105
Loss: 0.31444900713441915
ROC train: 0.938903	val: 0.607404	test: 0.617221
PRC train: 0.910069	val: 0.663433	test: 0.636507

Epoch: 106
Loss: 0.31244971020593076
ROC train: 0.940173	val: 0.623325	test: 0.601339
PRC train: 0.909343	val: 0.664871	test: 0.633624

Epoch: 107
Loss: 0.30523229060265145
ROC train: 0.939871	val: 0.614938	test: 0.595213
PRC train: 0.908652	val: 0.663098	test: 0.630349

Epoch: 108
Loss: 0.30188836708179545
ROC train: 0.942005	val: 0.604660	test: 0.604502
PRC train: 0.914258	val: 0.659909	test: 0.631924

Epoch: 109
Loss: 0.3023621504023085
ROC train: 0.943910	val: 0.611569	test: 0.607868
PRC train: 0.915325	val: 0.662812	test: 0.635305

Epoch: 110
Loss: 0.2988104374165842
ROC train: 0.944202	val: 0.611009	test: 0.607506
PRC train: 0.910311	val: 0.661871	test: 0.637260

Epoch: 111
Loss: 0.29523750034997076
ROC train: 0.946043	val: 0.613869	test: 0.608665
PRC train: 0.913152	val: 0.661298	test: 0.637037

Epoch: 112
Loss: 0.3000415229496459
ROC train: 0.946607	val: 0.615288	test: 0.606409
PRC train: 0.920164	val: 0.660808	test: 0.634698

Epoch: 113
Loss: 0.2925974149124063
ROC train: 0.946438	val: 0.620571	test: 0.599253
PRC train: 0.921579	val: 0.664286	test: 0.629905

Epoch: 114
Loss: 0.2957479104642477
ROC train: 0.949467	val: 0.622284	test: 0.604454
PRC train: 0.922054	val: 0.664969	test: 0.632810

Epoch: 115
Loss: 0.29203327205804264
ROC train: 0.950153	val: 0.621413	test: 0.600770
PRC train: 0.922491	val: 0.666397	test: 0.634850

Epoch: 116
Loss: 0.2860504475269433
ROC train: 0.950736	val: 0.615394	test: 0.601638
PRC train: 0.924383	val: 0.665815	test: 0.634808

Epoch: 117
Loss: 0.28833950645920337
ROC train: 0.951886	val: 0.612996	test: 0.604995
PRC train: 0.923758	val: 0.665369	test: 0.636293

Epoch: 118
Loss: 0.28899505574119494
ROC train: 0.953078	val: 0.616159	test: 0.611004
PRC train: 0.926000	val: 0.662185	test: 0.639514

Epoch: 119
Loss: 0.2864328946570555
ROC train: 0.955694	val: 0.615813	test: 0.614934
PRC train: 0.932811	val: 0.661510	test: 0.639239

Epoch: 120
Loss: 0.28671598217274075
ROC train: 0.954521	val: 0.616785	test: 0.601267
PRC train: 0.930315	val: 0.661674	test: 0.632431

Epoch: 121
Loss: 0.28461768086276085
ROC train: 0.954697	val: 0.620750	test: 0.606754
PRC train: 0.927835	val: 0.662769	test: 0.637530

Epoch: 122
Loss: 0.27997067570324047
ROC train: 0.956099	val: 0.622370	test: 0.610274
PRC train: 0.933658	val: 0.665371	test: 0.638832

Epoch: 123
Loss: 0.2822253142802252
ROC train: 0.955367	val: 0.611280	test: 0.608941
PRC train: 0.927207	val: 0.660417	test: 0.638722

Epoch: 124
Loss: 0.2825615458931898
ROC train: 0.957239	val: 0.617389	test: 0.602700
PRC train: 0.931206	val: 0.664314	test: 0.634833

Epoch: 125
Loss: 0.2791171420341317
ROC train: 0.959721	val: 0.619435	test: 0.608939
PRC train: 0.934954	val: 0.662195	test: 0.636535

Epoch: 126
Loss: 0.2769695451981287
ROC train: 0.959104	val: 0.625991	test: 0.608330
PRC train: 0.932591	val: 0.666172	test: 0.637174

Epoch: 127
Loss: 0.28107214787143964
ROC train: 0.959106	val: 0.613255	test: 0.611977
PRC train: 0.932067	val: 0.662898	test: 0.635790

Epoch: 128
Loss: 0.2753630094646047
ROC train: 0.959277	val: 0.615069	test: 0.605325
PRC train: 0.933212	val: 0.662474	test: 0.636474

Epoch: 129
Loss: 0.276937974764207
ROC train: 0.962209	val: 0.609988	test: 0.607489
PRC train: 0.939724	val: 0.656860	test: 0.637208

Epoch: 130
Loss: 0.27474980172029395
ROC train: 0.960945	val: 0.615499	test: 0.606979
PRC train: 0.936612	val: 0.660818	test: 0.636437

Epoch: 131
Loss: 0.26914887989849806
ROC train: 0.962608	val: 0.614330	test: 0.598949
PRC train: 0.940586	val: 0.664766	test: 0.634342

Epoch: 132
Loss: 0.26651385004291867
ROC train: 0.964157	val: 0.612703	test: 0.604220
PRC train: 0.942249	val: 0.665560	test: 0.638896

Epoch: 133
Loss: 0.26381716580170295
ROC train: 0.963853	val: 0.610892	test: 0.608031
PRC train: 0.943457	val: 0.662196	test: 0.640899

Epoch: 134
Loss: 0.2654210984431054
ROC train: 0.963737	val: 0.616314	test: 0.603735
PRC train: 0.942062	val: 0.663771	test: 0.631577

Epoch: 135
Loss: 0.2628562778381604
ROC train: 0.964656	val: 0.610879	test: 0.597692
PRC train: 0.942347	val: 0.663370	test: 0.632088

Epoch: 136
Loss: 0.2627511601849629
ROC train: 0.967106	val: 0.606829	test: 0.605493
PRC train: 0.946722	val: 0.658557	test: 0.635106

Epoch: 137
Loss: 0.2609727125860249
ROC train: 0.966037	val: 0.605047	test: 0.608960
PRC train: 0.943429	val: 0.660374	test: 0.636262

Epoch: 138
Loss: 0.2608694294040745
ROC train: 0.967390	val: 0.620377	test: 0.604452
PRC train: 0.946499	val: 0.664668	test: 0.635303

Epoch: 139
Loss: 0.25345633752207897
ROC train: 0.968323	val: 0.624994	test: 0.598984
PRC train: 0.948121	val: 0.664322	test: 0.633587

Epoch: 140
Loss: 0.25626346083163876
ROC train: 0.968225	val: 0.616573	test: 0.595586
PRC train: 0.947019	val: 0.662629	test: 0.629820

Epoch: 141
Loss: 0.2570690459737546
ROC train: 0.970249	val: 0.609890	test: 0.595731
PRC train: 0.950716	val: 0.658503	test: 0.631123

Epoch: 142
Loss: 0.2538382973990455
ROC train: 0.971806	val: 0.615366	test: 0.596117
PRC train: 0.953775	val: 0.659320	test: 0.630856

Epoch: 143
Loss: 0.25195744377419144
ROC train: 0.969932	val: 0.615710	test: 0.592578
PRC train: 0.952090	val: 0.664357	test: 0.631045

Epoch: 144
Loss: 0.2489951650077121
ROC train: 0.970996	val: 0.609071	test: 0.604968
PRC train: 0.954050	val: 0.663132	test: 0.638102

Epoch: 145
Loss: 0.2512157795346703
ROC train: 0.972840	val: 0.612545	test: 0.607884
PRC train: 0.957204	val: 0.665715	test: 0.638980

Epoch: 146
Loss: 0.24675337907363643
ROC train: 0.973874	val: 0.622819	test: 0.602310
PRC train: 0.957285	val: 0.668363	test: 0.636842

Epoch: 147
Loss: 0.24924372439321366
ROC train: 0.971324	val: 0.616787	test: 0.610968
PRC train: 0.952946	val: 0.666906	test: 0.637026

Epoch: 148
Loss: 0.24535125278421907
ROC train: 0.970414	val: 0.621074	test: 0.609704
PRC train: 0.950450	val: 0.670261	test: 0.637898

Epoch: 149
Loss: 0.24528401859943855
ROC train: 0.972488	val: 0.610138	test: 0.605608
PRC train: 0.952014	val: 0.664833	test: 0.635180

Epoch: 150
Loss: 0.23688823168646506
ROC train: 0.974911	val: 0.614445	test: 0.597689
PRC train: 0.958168	val: 0.663576	test: 0.632771

Epoch: 151
Loss: 0.24173570928513666
ROC train: 0.976125	val: 0.609284	test: 0.598728
PRC train: 0.959569	val: 0.659827	test: 0.634078

Epoch: 152
Loss: 0.2425479990612276
ROC train: 0.976544	val: 0.609838	test: 0.599778
PRC train: 0.959588	val: 0.659303	test: 0.633196

Epoch: 153
Loss: 0.24330470275411145
ROC train: 0.975953	val: 0.614176	test: 0.601100
PRC train: 0.959590	val: 0.663863	test: 0.632834

Epoch: 154
Loss: 0.23641247173618493
ROC train: 0.975450	val: 0.603511	test: 0.600560
PRC train: 0.961416	val: 0.658882	test: 0.633995

Epoch: 155
Loss: 0.2369762115098882
ROC train: 0.977744	val: 0.613426	test: 0.597650
PRC train: 0.962333	val: 0.662890	test: 0.633671

Epoch: 156
Loss: 0.23653845505979482
ROC train: 0.978121	val: 0.616477	test: 0.601134
PRC train: 0.966596	val: 0.663778	test: 0.635364

Epoch: 157
Loss: 0.23205215942118498
ROC train: 0.978553	val: 0.615445	test: 0.607242
PRC train: 0.965409	val: 0.662779	test: 0.637819

Epoch: 158
Loss: 0.22886616812352076
ROC train: 0.978833	val: 0.616168	test: 0.607308
PRC train: 0.965807	val: 0.663033	test: 0.637564

Epoch: 159
Loss: 0.23001938940329403
ROC train: 0.980458	val: 0.611102	test: 0.613762
PRC train: 0.966879	val: 0.660548	test: 0.641101

Epoch: 160
Loss: 0.22933673831210966
ROC train: 0.980487	val: 0.608281	test: 0.611295
PRC train: 0.967453	val: 0.657628	test: 0.639701

Epoch: 161
Loss: 0.23019188667609355
ROC train: 0.980928	val: 0.612230	test: 0.600520
PRC train: 0.967230	val: 0.659769	test: 0.634685

Early stopping
Best (ROC):	 train: 0.959104	val: 0.625991	test: 0.608330
Best (PRC):	 train: 0.932591	val: 0.666172	test: 0.637174
All runs completed.
