>>> Starting run for dataset: sider
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running SCAFF configs_split_experiments/GraphCL/sider/scaff/train_prop=0.6.yml on cuda:0
Running SCAFF configs_split_experiments/GraphCL/sider/scaff/train_prop=0.7.yml on cuda:1
Running SCAFF configs_split_experiments/GraphCL/sider/scaff/train_prop=0.8.yml on cuda:2
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.7.yml --runseed 1 --device cuda:1
Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.7.yml --runseed 2 --device cuda:1
Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.7.yml --runseed 3 --device cuda:1
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.6.yml --runseed 1 --device cuda:0
Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.6.yml --runseed 2 --device cuda:0
Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.6.yml --runseed 3 --device cuda:0
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.8.yml --runseed 1 --device cuda:2
Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.8.yml --runseed 2 --device cuda:2
Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.8.yml --runseed 3 --device cuda:2
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] [14:43:17] WARNING: not removing hydrogen atom without neighborsWARNING: not removing hydrogen atom without neighbors

[14:43:17] [14:43:17] WARNING: not removing hydrogen atom without neighborsWARNING: not removing hydrogen atom without neighbors

[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:17] WARNING: not removing hydrogen atom without neighbors
[14:43:18] WARNING: not removing hydrogen atom without neighbors
[14:43:18] WARNING: not removing hydrogen atom without neighbors
[14:43:18] WARNING: not removing hydrogen atom without neighbors
[14:43:18] WARNING: not removing hydrogen atom without neighbors
[14:43:18] WARNING: not removing hydrogen atom without neighbors
[14:43:18] WARNING: not removing hydrogen atom without neighbors
[14:43:18] WARNING: not removing hydrogen atom without neighbors
[14:43:18] WARNING: not removing hydrogen atom without neighbors
[14:43:18] WARNING: not removing hydrogen atom without neighbors
[14:43:18] WARNING: not removing hydrogen atom without neighbors
[14:43:18] WARNING: not removing hydrogen atom without neighbors
[14:43:18] WARNING: not removing hydrogen atom without neighbors
[14:43:18] WARNING: not removing hydrogen atom without neighbors
[14:43:18] WARNING: not removing hydrogen atom without neighbors
[14:43:18] WARNING: not removing hydrogen atom without neighbors
[14:43:18] WARNING: not removing hydrogen atom without neighbors
[14:43:18] WARNING: not removing hydrogen atom without neighbors
[14:43:18] WARNING: not removing hydrogen atom without neighbors
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:0
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/scaff/train_prop=0.6/sider_scaff_2_20-05_14-43-16  ]
[ Using Seed :  2  ]
[ Using device :  cuda:0  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.695176249255707
ROC train: 0.554233	val: 0.520164	test: 0.505756
PRC train: 0.585292	val: 0.603380	test: 0.585510

Epoch: 2
Loss: 0.6572703786603732
ROC train: 0.575530	val: 0.527951	test: 0.514044
PRC train: 0.598985	val: 0.603288	test: 0.588106

Epoch: 3
Loss: 0.630999139493623
ROC train: 0.583864	val: 0.530904	test: 0.511497
PRC train: 0.607481	val: 0.605375	test: 0.586473

Epoch: 4
Loss: 0.6013585647522899
ROC train: 0.592082	val: 0.531078	test: 0.511091
PRC train: 0.616190	val: 0.604310	test: 0.585854

Epoch: 5
Loss: 0.5678183504550397
ROC train: 0.603806	val: 0.538600	test: 0.512674
PRC train: 0.626129	val: 0.607544	test: 0.589323

Epoch: 6
Loss: 0.558653839073873
ROC train: 0.626680	val: 0.538455	test: 0.524426
PRC train: 0.641578	val: 0.610200	test: 0.597372

Epoch: 7
Loss: 0.5507474975148648
ROC train: 0.658142	val: 0.537405	test: 0.547331
PRC train: 0.658157	val: 0.609433	test: 0.608460

Epoch: 8
Loss: 0.5392563858322167
ROC train: 0.674835	val: 0.536177	test: 0.555636
PRC train: 0.665904	val: 0.612338	test: 0.608632

Epoch: 9
Loss: 0.5285323876957271
ROC train: 0.673338	val: 0.539739	test: 0.556660
PRC train: 0.667005	val: 0.616097	test: 0.609049

Epoch: 10
Loss: 0.5197906764548883
ROC train: 0.682355	val: 0.542632	test: 0.560537
PRC train: 0.673508	val: 0.619909	test: 0.609920

Epoch: 11
Loss: 0.5086550975146095
ROC train: 0.698073	val: 0.542442	test: 0.565537
PRC train: 0.683159	val: 0.619525	test: 0.612590

Epoch: 12
Loss: 0.5058647399237084
ROC train: 0.702960	val: 0.541703	test: 0.562752
PRC train: 0.687016	val: 0.618293	test: 0.611945

Epoch: 13
Loss: 0.4975875955153591
ROC train: 0.703388	val: 0.550112	test: 0.563812
PRC train: 0.686387	val: 0.620191	test: 0.613221

Epoch: 14
Loss: 0.4917247256861344
ROC train: 0.713227	val: 0.553257	test: 0.569026
PRC train: 0.692594	val: 0.622491	test: 0.616974

Epoch: 15
Loss: 0.4877756588552283
ROC train: 0.719165	val: 0.552056	test: 0.565735
PRC train: 0.695244	val: 0.622313	test: 0.616398

Epoch: 16
Loss: 0.48662810772107257
ROC train: 0.724678	val: 0.546250	test: 0.569127
PRC train: 0.698384	val: 0.620547	test: 0.620002

Epoch: 17
Loss: 0.48284808365844606
ROC train: 0.728665	val: 0.538222	test: 0.576817
PRC train: 0.701828	val: 0.619417	test: 0.626510

Epoch: 18
Loss: 0.47780109104739976
ROC train: 0.733595	val: 0.532677	test: 0.577455
PRC train: 0.706171	val: 0.619631	test: 0.627411

Epoch: 19
Loss: 0.4801482978676635
ROC train: 0.736495	val: 0.537295	test: 0.580754
PRC train: 0.709651	val: 0.622491	test: 0.626016

Epoch: 20
Loss: 0.475920642402184
ROC train: 0.745351	val: 0.539444	test: 0.584948
PRC train: 0.714693	val: 0.624728	test: 0.627695

Epoch: 21
Loss: 0.4754180668656732
ROC train: 0.749409	val: 0.537554	test: 0.582145
PRC train: 0.717064	val: 0.624691	test: 0.628173

Epoch: 22
Loss: 0.47142739707840003
ROC train: 0.750211	val: 0.535122	test: 0.577718
PRC train: 0.720222	val: 0.622443	test: 0.625138

Epoch: 23
Loss: 0.4678755587329785
ROC train: 0.752841	val: 0.535611	test: 0.584570
PRC train: 0.722578	val: 0.623048	test: 0.625620

Epoch: 24
Loss: 0.4682985119620086
ROC train: 0.762420	val: 0.536540	test: 0.591183
PRC train: 0.730151	val: 0.624873	test: 0.628114

Epoch: 25
Loss: 0.4585436957062058
ROC train: 0.769381	val: 0.543366	test: 0.596105
PRC train: 0.733878	val: 0.628406	test: 0.632407

Epoch: 26
Loss: 0.46543097775118014
ROC train: 0.771518	val: 0.544567	test: 0.589494
PRC train: 0.732856	val: 0.628273	test: 0.629655

Epoch: 27
Loss: 0.4576424408294091
ROC train: 0.768790	val: 0.550824	test: 0.580453
PRC train: 0.733871	val: 0.630353	test: 0.621363

Epoch: 28
Loss: 0.4758702516009789
ROC train: 0.767748	val: 0.556441	test: 0.575926
PRC train: 0.735489	val: 0.633699	test: 0.615434

Epoch: 29
Loss: 0.4556069397157838
ROC train: 0.777601	val: 0.555955	test: 0.576634
PRC train: 0.741315	val: 0.633650	test: 0.618374

Epoch: 30
Loss: 0.457913109360873
ROC train: 0.785187	val: 0.552403	test: 0.575701
PRC train: 0.745128	val: 0.631127	test: 0.621046

Epoch: 31
Loss: 0.4453202784116155
ROC train: 0.789829	val: 0.543986	test: 0.578951
PRC train: 0.747392	val: 0.626114	test: 0.626087

Epoch: 32
Loss: 0.45612599329634435
ROC train: 0.790670	val: 0.551958	test: 0.575459
PRC train: 0.748374	val: 0.632030	test: 0.623629

Epoch: 33
Loss: 0.44688953198781556
ROC train: 0.787581	val: 0.561253	test: 0.574651Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:0
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/scaff/train_prop=0.6/sider_scaff_3_20-05_14-43-16  ]
[ Using Seed :  3  ]
[ Using device :  cuda:0  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.685882444165129
ROC train: 0.547209	val: 0.520854	test: 0.502403
PRC train: 0.580602	val: 0.604593	test: 0.583179

Epoch: 2
Loss: 0.6496922199301823
ROC train: 0.565770	val: 0.540162	test: 0.510132
PRC train: 0.599318	val: 0.609274	test: 0.586670

Epoch: 3
Loss: 0.6162201549385669
ROC train: 0.573727	val: 0.543209	test: 0.508664
PRC train: 0.607809	val: 0.611459	test: 0.588250

Epoch: 4
Loss: 0.5918112679127308
ROC train: 0.582742	val: 0.542386	test: 0.504108
PRC train: 0.613979	val: 0.612365	test: 0.586601

Epoch: 5
Loss: 0.5660314556909157
ROC train: 0.601819	val: 0.542420	test: 0.508272
PRC train: 0.625316	val: 0.614341	test: 0.590107

Epoch: 6
Loss: 0.5575261744103166
ROC train: 0.632415	val: 0.541841	test: 0.526886
PRC train: 0.643292	val: 0.615785	test: 0.599023

Epoch: 7
Loss: 0.5408832263289495
ROC train: 0.655498	val: 0.543673	test: 0.544557
PRC train: 0.655620	val: 0.617055	test: 0.605350

Epoch: 8
Loss: 0.5306764979287165
ROC train: 0.664256	val: 0.542223	test: 0.551796
PRC train: 0.660065	val: 0.617836	test: 0.609118

Epoch: 9
Loss: 0.5168361169739338
ROC train: 0.674963	val: 0.545855	test: 0.564024
PRC train: 0.669553	val: 0.619700	test: 0.614296

Epoch: 10
Loss: 0.5145772551041099
ROC train: 0.685072	val: 0.550210	test: 0.571494
PRC train: 0.678609	val: 0.622003	test: 0.617222

Epoch: 11
Loss: 0.5077697552129664
ROC train: 0.696042	val: 0.549743	test: 0.578483
PRC train: 0.685550	val: 0.623178	test: 0.620579

Epoch: 12
Loss: 0.504587285478242
ROC train: 0.704061	val: 0.550135	test: 0.583070
PRC train: 0.690744	val: 0.625526	test: 0.623219

Epoch: 13
Loss: 0.5043867642855858
ROC train: 0.713381	val: 0.552580	test: 0.586875
PRC train: 0.694696	val: 0.626363	test: 0.630094

Epoch: 14
Loss: 0.49649266834327893
ROC train: 0.718029	val: 0.554703	test: 0.587654
PRC train: 0.698538	val: 0.624791	test: 0.626923

Epoch: 15
Loss: 0.48921660466002326
ROC train: 0.720743	val: 0.561191	test: 0.588687
PRC train: 0.700123	val: 0.628125	test: 0.626555

Epoch: 16
Loss: 0.48242876420976843
ROC train: 0.727483	val: 0.568536	test: 0.589325
PRC train: 0.706680	val: 0.634544	test: 0.627386

Epoch: 17
Loss: 0.484093198968122
ROC train: 0.736569	val: 0.574279	test: 0.585927
PRC train: 0.714661	val: 0.640157	test: 0.627485

Epoch: 18
Loss: 0.47732414334806594
ROC train: 0.740914	val: 0.570751	test: 0.585975
PRC train: 0.716050	val: 0.636172	test: 0.627815

Epoch: 19
Loss: 0.4746431155409333
ROC train: 0.745301	val: 0.569168	test: 0.588746
PRC train: 0.718546	val: 0.636429	test: 0.627750

Epoch: 20
Loss: 0.47114132823707205
ROC train: 0.748284	val: 0.563837	test: 0.591255
PRC train: 0.720126	val: 0.634509	test: 0.628361

Epoch: 21
Loss: 0.4695546456995147
ROC train: 0.753531	val: 0.562670	test: 0.593868
PRC train: 0.723339	val: 0.635558	test: 0.629644

Epoch: 22
Loss: 0.4692169437243152
ROC train: 0.759473	val: 0.553634	test: 0.591308
PRC train: 0.727985	val: 0.634759	test: 0.628412

Epoch: 23
Loss: 0.4685487204252592
ROC train: 0.762228	val: 0.541667	test: 0.581901
PRC train: 0.730452	val: 0.627659	test: 0.624330

Epoch: 24
Loss: 0.46702197146956115
ROC train: 0.764625	val: 0.534698	test: 0.578470
PRC train: 0.731068	val: 0.625969	test: 0.622739

Epoch: 25
Loss: 0.46041581954723054
ROC train: 0.766333	val: 0.541267	test: 0.581194
PRC train: 0.733542	val: 0.631274	test: 0.624371

Epoch: 26
Loss: 0.46679759142690247
ROC train: 0.774671	val: 0.544632	test: 0.588994
PRC train: 0.737582	val: 0.629058	test: 0.630885

Epoch: 27
Loss: 0.4571980215907767
ROC train: 0.775091	val: 0.548621	test: 0.590669
PRC train: 0.736332	val: 0.625084	test: 0.633603

Epoch: 28
Loss: 0.4515389761710664
ROC train: 0.783413	val: 0.555667	test: 0.593292
PRC train: 0.744235	val: 0.628937	test: 0.633084

Epoch: 29
Loss: 0.458148176371922
ROC train: 0.780679	val: 0.557906	test: 0.594993
PRC train: 0.744025	val: 0.632503	test: 0.630303

Epoch: 30
Loss: 0.453208259085757
ROC train: 0.786081	val: 0.558994	test: 0.597513
PRC train: 0.747492	val: 0.632073	test: 0.630165

Epoch: 31
Loss: 0.45338781054133065
ROC train: 0.789361	val: 0.562027	test: 0.598257
PRC train: 0.748543	val: 0.631108	test: 0.632649

Epoch: 32
Loss: 0.4500948749816284
ROC train: 0.791289	val: 0.552027	test: 0.591248
PRC train: 0.749937	val: 0.623299	test: 0.632221

Epoch: 33
Loss: 0.4479985836293343Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:0
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/scaff/train_prop=0.6/sider_scaff_1_20-05_14-43-16  ]
[ Using Seed :  1  ]
[ Using device :  cuda:0  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6947655647696578
ROC train: 0.531727	val: 0.527940	test: 0.510881
PRC train: 0.570791	val: 0.606112	test: 0.590508

Epoch: 2
Loss: 0.6516546436099074
ROC train: 0.552472	val: 0.528210	test: 0.508587
PRC train: 0.589450	val: 0.603168	test: 0.586564

Epoch: 3
Loss: 0.6139147539947482
ROC train: 0.563455	val: 0.533336	test: 0.501970
PRC train: 0.599402	val: 0.603463	test: 0.583259

Epoch: 4
Loss: 0.5880559381207597
ROC train: 0.578979	val: 0.533550	test: 0.504568
PRC train: 0.610807	val: 0.607677	test: 0.585264

Epoch: 5
Loss: 0.5663408272064342
ROC train: 0.610604	val: 0.536141	test: 0.522610
PRC train: 0.629636	val: 0.613104	test: 0.596428

Epoch: 6
Loss: 0.5606734925388154
ROC train: 0.637526	val: 0.533817	test: 0.544902
PRC train: 0.642601	val: 0.611883	test: 0.610822

Epoch: 7
Loss: 0.542635792412832
ROC train: 0.656842	val: 0.535221	test: 0.557077
PRC train: 0.649342	val: 0.612077	test: 0.619454

Epoch: 8
Loss: 0.5412302892647248
ROC train: 0.667040	val: 0.539832	test: 0.562197
PRC train: 0.660205	val: 0.614739	test: 0.621676

Epoch: 9
Loss: 0.5271878410947308
ROC train: 0.678130	val: 0.536065	test: 0.567999
PRC train: 0.668395	val: 0.613178	test: 0.622637

Epoch: 10
Loss: 0.51911251948861
ROC train: 0.680123	val: 0.533037	test: 0.570018
PRC train: 0.672315	val: 0.613822	test: 0.622333

Epoch: 11
Loss: 0.51357160834736
ROC train: 0.692632	val: 0.537492	test: 0.582851
PRC train: 0.679648	val: 0.615010	test: 0.628138

Epoch: 12
Loss: 0.5114020954510676
ROC train: 0.701336	val: 0.548237	test: 0.591248
PRC train: 0.681062	val: 0.618723	test: 0.630986

Epoch: 13
Loss: 0.5027638690541154
ROC train: 0.709391	val: 0.555043	test: 0.590149
PRC train: 0.684050	val: 0.621150	test: 0.630177

Epoch: 14
Loss: 0.4965542197580013
ROC train: 0.714078	val: 0.558832	test: 0.589648
PRC train: 0.691087	val: 0.626522	test: 0.628213

Epoch: 15
Loss: 0.4994792631688191
ROC train: 0.718764	val: 0.551336	test: 0.588223
PRC train: 0.695137	val: 0.624283	test: 0.628698

Epoch: 16
Loss: 0.49281375334143274
ROC train: 0.731908	val: 0.534666	test: 0.597247
PRC train: 0.701492	val: 0.614867	test: 0.631586

Epoch: 17
Loss: 0.48747886553146413
ROC train: 0.734858	val: 0.528069	test: 0.602464
PRC train: 0.705696	val: 0.611883	test: 0.633400

Epoch: 18
Loss: 0.48215274926363627
ROC train: 0.737360	val: 0.536058	test: 0.600553
PRC train: 0.709565	val: 0.617725	test: 0.633944

Epoch: 19
Loss: 0.48206107296081624
ROC train: 0.741195	val: 0.543177	test: 0.598501
PRC train: 0.714332	val: 0.622892	test: 0.634829

Epoch: 20
Loss: 0.477172503345411
ROC train: 0.749619	val: 0.551864	test: 0.603527
PRC train: 0.718236	val: 0.629128	test: 0.638920

Epoch: 21
Loss: 0.4700037638508103
ROC train: 0.748679	val: 0.554382	test: 0.598298
PRC train: 0.714220	val: 0.626805	test: 0.638068

Epoch: 22
Loss: 0.46897864199951206
ROC train: 0.756076	val: 0.553810	test: 0.602738
PRC train: 0.721309	val: 0.624937	test: 0.638420

Epoch: 23
Loss: 0.4649190445232198
ROC train: 0.761240	val: 0.549325	test: 0.606065
PRC train: 0.727622	val: 0.626215	test: 0.637323

Epoch: 24
Loss: 0.4652018199076339
ROC train: 0.761742	val: 0.541933	test: 0.600364
PRC train: 0.726735	val: 0.621853	test: 0.631767

Epoch: 25
Loss: 0.4602971659389507
ROC train: 0.768710	val: 0.541767	test: 0.605917
PRC train: 0.729074	val: 0.618874	test: 0.635867

Epoch: 26
Loss: 0.46013264906145984
ROC train: 0.770645	val: 0.549028	test: 0.610246
PRC train: 0.730517	val: 0.620134	test: 0.642716

Epoch: 27
Loss: 0.4610669815120977
ROC train: 0.773740	val: 0.556998	test: 0.608462
PRC train: 0.736099	val: 0.628419	test: 0.639987

Epoch: 28
Loss: 0.45563346491732903
ROC train: 0.776249	val: 0.558737	test: 0.611445
PRC train: 0.737732	val: 0.630253	test: 0.641778

Epoch: 29
Loss: 0.45050623430545245
ROC train: 0.782575	val: 0.553495	test: 0.613179
PRC train: 0.740849	val: 0.622778	test: 0.641767

Epoch: 30
Loss: 0.4543024415037825
ROC train: 0.785078	val: 0.548152	test: 0.609245
PRC train: 0.743330	val: 0.621211	test: 0.637086

Epoch: 31
Loss: 0.4504542556637485
ROC train: 0.788470	val: 0.547311	test: 0.606082
PRC train: 0.745770	val: 0.622423	test: 0.633800

Epoch: 32
Loss: 0.4481724429675217
ROC train: 0.792212	val: 0.551742	test: 0.611951
PRC train: 0.749837	val: 0.626380	test: 0.639233

Epoch: 33
Loss: 0.45445791111615247
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:1
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/scaff/train_prop=0.7/sider_scaff_2_20-05_14-43-16  ]
[ Using Seed :  2  ]
[ Using device :  cuda:1  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6957404884475673
ROC train: 0.549938	val: 0.522584	test: 0.510252
PRC train: 0.586377	val: 0.614656	test: 0.569445

Epoch: 2
Loss: 0.6588142405498312
ROC train: 0.572052	val: 0.524713	test: 0.516026
PRC train: 0.602490	val: 0.611870	test: 0.570740

Epoch: 3
Loss: 0.6248822000983743
ROC train: 0.577062	val: 0.527966	test: 0.517285
PRC train: 0.608188	val: 0.613051	test: 0.571532

Epoch: 4
Loss: 0.5986364601229783
ROC train: 0.577783	val: 0.529662	test: 0.510297
PRC train: 0.612231	val: 0.613853	test: 0.574428

Epoch: 5
Loss: 0.5710346318468837
ROC train: 0.588335	val: 0.526621	test: 0.513695
PRC train: 0.619542	val: 0.614440	test: 0.579336

Epoch: 6
Loss: 0.5589443810055678
ROC train: 0.613390	val: 0.523641	test: 0.536218
PRC train: 0.631663	val: 0.615759	test: 0.589934

Epoch: 7
Loss: 0.545049457392068
ROC train: 0.641247	val: 0.527483	test: 0.564647
PRC train: 0.644407	val: 0.620691	test: 0.603326

Epoch: 8
Loss: 0.5345419362876944
ROC train: 0.658569	val: 0.533315	test: 0.580306
PRC train: 0.653719	val: 0.622739	test: 0.609723

Epoch: 9
Loss: 0.5280840277826393
ROC train: 0.672165	val: 0.538027	test: 0.590468
PRC train: 0.663141	val: 0.624633	test: 0.613634

Epoch: 10
Loss: 0.5191222975049328
ROC train: 0.682317	val: 0.546665	test: 0.599219
PRC train: 0.672415	val: 0.628181	test: 0.616498

Epoch: 11
Loss: 0.5109410596634426
ROC train: 0.687716	val: 0.549427	test: 0.603099
PRC train: 0.677194	val: 0.629800	test: 0.617757

Epoch: 12
Loss: 0.5089519575053058
ROC train: 0.695517	val: 0.550914	test: 0.610241
PRC train: 0.681867	val: 0.632044	test: 0.622533

Epoch: 13
Loss: 0.5022624275193261
ROC train: 0.704371	val: 0.557421	test: 0.615840
PRC train: 0.688344	val: 0.636351	test: 0.627655

Epoch: 14
Loss: 0.49666453226949464
ROC train: 0.712756	val: 0.560674	test: 0.620081
PRC train: 0.694111	val: 0.636330	test: 0.630293

Epoch: 15
Loss: 0.4944211616939381
ROC train: 0.718750	val: 0.557429	test: 0.618225
PRC train: 0.698855	val: 0.634466	test: 0.630413

Epoch: 16
Loss: 0.4884908065811281
ROC train: 0.721384	val: 0.555877	test: 0.608730
PRC train: 0.701934	val: 0.634065	test: 0.624484

Epoch: 17
Loss: 0.48416165545515627
ROC train: 0.726963	val: 0.552301	test: 0.607868
PRC train: 0.708157	val: 0.634874	test: 0.626547

Epoch: 18
Loss: 0.4837106279144372
ROC train: 0.735525	val: 0.554967	test: 0.612777
PRC train: 0.715258	val: 0.636766	test: 0.630321

Epoch: 19
Loss: 0.48245539711895635
ROC train: 0.742320	val: 0.557673	test: 0.601838
PRC train: 0.720048	val: 0.639738	test: 0.625597

Epoch: 20
Loss: 0.4764245221418899
ROC train: 0.747141	val: 0.556164	test: 0.593909
PRC train: 0.724188	val: 0.641620	test: 0.622081

Epoch: 21
Loss: 0.47045109868934243
ROC train: 0.749647	val: 0.551931	test: 0.593556
PRC train: 0.726176	val: 0.641616	test: 0.622166

Epoch: 22
Loss: 0.4725617457425806
ROC train: 0.749432	val: 0.550839	test: 0.593971
PRC train: 0.725569	val: 0.642571	test: 0.622152

Epoch: 23
Loss: 0.465941444026932
ROC train: 0.755501	val: 0.554691	test: 0.590795
PRC train: 0.729529	val: 0.643684	test: 0.619565

Epoch: 24
Loss: 0.4646444870315173
ROC train: 0.760133	val: 0.554922	test: 0.594676
PRC train: 0.733239	val: 0.642093	test: 0.620062

Epoch: 25
Loss: 0.4623741818529501
ROC train: 0.764627	val: 0.560579	test: 0.605527
PRC train: 0.736779	val: 0.643087	test: 0.624834

Epoch: 26
Loss: 0.4615757451942898
ROC train: 0.769094	val: 0.568602	test: 0.604591
PRC train: 0.740261	val: 0.645018	test: 0.625643

Epoch: 27
Loss: 0.46178981973364475
ROC train: 0.772870	val: 0.574815	test: 0.601683
PRC train: 0.742956	val: 0.646841	test: 0.623302

Epoch: 28
Loss: 0.4570909647949764
ROC train: 0.775541	val: 0.575809	test: 0.601678
PRC train: 0.745302	val: 0.647907	test: 0.623532

Epoch: 29
Loss: 0.4582532704320929
ROC train: 0.779802	val: 0.561608	test: 0.606439
PRC train: 0.747711	val: 0.642494	test: 0.628203

Epoch: 30
Loss: 0.45216206273373627
ROC train: 0.783747	val: 0.556753	test: 0.607677
PRC train: 0.750286	val: 0.637276	test: 0.631720

Epoch: 31
Loss: 0.45367657969899555
ROC train: 0.786051	val: 0.565421	test: 0.603691
PRC train: 0.752139	val: 0.642443	test: 0.630200

Epoch: 32
Loss: 0.4519962132417699
ROC train: 0.789614	val: 0.572720	test: 0.610642
PRC train: 0.754749	val: 0.645569	test: 0.634597

Epoch: 33
Loss: 0.45558870075483565Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:1
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/scaff/train_prop=0.7/sider_scaff_3_20-05_14-43-16  ]
[ Using Seed :  3  ]
[ Using device :  cuda:1  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6873442089156412
ROC train: 0.546062	val: 0.516925	test: 0.508111
PRC train: 0.582871	val: 0.613623	test: 0.570176

Epoch: 2
Loss: 0.6469540135882976
ROC train: 0.563234	val: 0.529495	test: 0.510657
PRC train: 0.600948	val: 0.610966	test: 0.573625

Epoch: 3
Loss: 0.613785049189381
ROC train: 0.562721	val: 0.522329	test: 0.500973
PRC train: 0.604341	val: 0.611632	test: 0.572009

Epoch: 4
Loss: 0.5882892313386902
ROC train: 0.574270	val: 0.522455	test: 0.502328
PRC train: 0.612611	val: 0.615269	test: 0.572610

Epoch: 5
Loss: 0.5663489364831935
ROC train: 0.605787	val: 0.520021	test: 0.527903
PRC train: 0.629128	val: 0.618043	test: 0.588188

Epoch: 6
Loss: 0.5512045646563255
ROC train: 0.634817	val: 0.519490	test: 0.562236
PRC train: 0.644640	val: 0.617204	test: 0.606318

Epoch: 7
Loss: 0.5468070390802052
ROC train: 0.648258	val: 0.529011	test: 0.585898
PRC train: 0.652465	val: 0.622472	test: 0.619952

Epoch: 8
Loss: 0.5344546409649176
ROC train: 0.656651	val: 0.539228	test: 0.593551
PRC train: 0.658646	val: 0.628440	test: 0.625390

Epoch: 9
Loss: 0.5275218184556436
ROC train: 0.666675	val: 0.548866	test: 0.597590
PRC train: 0.664321	val: 0.633501	test: 0.624673

Epoch: 10
Loss: 0.5158464954207125
ROC train: 0.678339	val: 0.549467	test: 0.596632
PRC train: 0.671549	val: 0.633112	test: 0.622390

Epoch: 11
Loss: 0.5119478459436515
ROC train: 0.690875	val: 0.553409	test: 0.600779
PRC train: 0.679659	val: 0.634505	test: 0.622230

Epoch: 12
Loss: 0.507418273471028
ROC train: 0.700482	val: 0.556527	test: 0.604476
PRC train: 0.686392	val: 0.636745	test: 0.622973

Epoch: 13
Loss: 0.5009076671047066
ROC train: 0.706128	val: 0.555711	test: 0.602891
PRC train: 0.691110	val: 0.635433	test: 0.622446

Epoch: 14
Loss: 0.49849883548372836
ROC train: 0.714942	val: 0.555017	test: 0.606036
PRC train: 0.696863	val: 0.637841	test: 0.624547

Epoch: 15
Loss: 0.4927117375212907
ROC train: 0.719891	val: 0.562731	test: 0.599024
PRC train: 0.700729	val: 0.643808	test: 0.621448

Epoch: 16
Loss: 0.48793694335148047
ROC train: 0.723070	val: 0.569054	test: 0.590782
PRC train: 0.705711	val: 0.647664	test: 0.619016

Epoch: 17
Loss: 0.48064831881317194
ROC train: 0.731510	val: 0.568972	test: 0.591252
PRC train: 0.712760	val: 0.647544	test: 0.617869

Epoch: 18
Loss: 0.48092740229360664
ROC train: 0.738889	val: 0.569865	test: 0.597656
PRC train: 0.718869	val: 0.647467	test: 0.623984

Epoch: 19
Loss: 0.47939695874259747
ROC train: 0.744139	val: 0.565117	test: 0.597705
PRC train: 0.722431	val: 0.644154	test: 0.625272

Epoch: 20
Loss: 0.47511515172244356
ROC train: 0.749341	val: 0.573200	test: 0.601001
PRC train: 0.726446	val: 0.649570	test: 0.628261

Epoch: 21
Loss: 0.47481812774153664
ROC train: 0.751144	val: 0.570151	test: 0.598820
PRC train: 0.727049	val: 0.652813	test: 0.627570

Epoch: 22
Loss: 0.47073844673847737
ROC train: 0.757695	val: 0.573243	test: 0.598687
PRC train: 0.732162	val: 0.652886	test: 0.626125

Epoch: 23
Loss: 0.46509153226776495
ROC train: 0.760448	val: 0.562198	test: 0.599449
PRC train: 0.734592	val: 0.646458	test: 0.621800

Epoch: 24
Loss: 0.4695353358483204
ROC train: 0.762363	val: 0.555644	test: 0.603274
PRC train: 0.735786	val: 0.641983	test: 0.624136

Epoch: 25
Loss: 0.4665723067345862
ROC train: 0.768995	val: 0.562702	test: 0.603717
PRC train: 0.741284	val: 0.640433	test: 0.625137

Epoch: 26
Loss: 0.45873283939717485
ROC train: 0.772220	val: 0.568149	test: 0.605950
PRC train: 0.745141	val: 0.641048	test: 0.625860

Epoch: 27
Loss: 0.458898036092116
ROC train: 0.770775	val: 0.570342	test: 0.608538
PRC train: 0.745069	val: 0.643272	test: 0.627297

Epoch: 28
Loss: 0.46300072639216794
ROC train: 0.774486	val: 0.567649	test: 0.606092
PRC train: 0.746166	val: 0.647387	test: 0.626096

Epoch: 29
Loss: 0.4538623884078382
ROC train: 0.779282	val: 0.565325	test: 0.611705
PRC train: 0.748066	val: 0.646406	test: 0.626292

Epoch: 30
Loss: 0.4519590372538805
ROC train: 0.784528	val: 0.560976	test: 0.609613
PRC train: 0.752527	val: 0.642941	test: 0.626759

Epoch: 31
Loss: 0.44991122329935074
ROC train: 0.788392	val: 0.567538	test: 0.607200
PRC train: 0.756946	val: 0.648313	test: 0.626926

Epoch: 32
Loss: 0.44797561839695377
ROC train: 0.789444	val: 0.565972	test: 0.612467
PRC train: 0.758077	val: 0.642447	test: 0.630484

Epoch: 33
Loss: 0.44721517536695365Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:1
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/scaff/train_prop=0.7/sider_scaff_1_20-05_14-43-16  ]
[ Using Seed :  1  ]
[ Using device :  cuda:1  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6938191077200606
ROC train: 0.532734	val: 0.532868	test: 0.504177
PRC train: 0.574333	val: 0.619502	test: 0.574682

Epoch: 2
Loss: 0.6521900964210894
ROC train: 0.546854	val: 0.534803	test: 0.502154
PRC train: 0.588773	val: 0.620625	test: 0.570489

Epoch: 3
Loss: 0.615443617163859
ROC train: 0.555568	val: 0.531255	test: 0.496126
PRC train: 0.598108	val: 0.618473	test: 0.567945

Epoch: 4
Loss: 0.5914279666610958
ROC train: 0.573590	val: 0.534591	test: 0.504639
PRC train: 0.611517	val: 0.620084	test: 0.574085

Epoch: 5
Loss: 0.5756628134043416
ROC train: 0.598245	val: 0.541581	test: 0.525056
PRC train: 0.626717	val: 0.624750	test: 0.587448

Epoch: 6
Loss: 0.5565898515612877
ROC train: 0.627624	val: 0.544684	test: 0.561031
PRC train: 0.643684	val: 0.629619	test: 0.608137

Epoch: 7
Loss: 0.5472180415288184
ROC train: 0.643739	val: 0.548077	test: 0.580383
PRC train: 0.652263	val: 0.631507	test: 0.620776

Epoch: 8
Loss: 0.5372415799036502
ROC train: 0.657251	val: 0.549798	test: 0.592243
PRC train: 0.659899	val: 0.632050	test: 0.625845

Epoch: 9
Loss: 0.5275651948739641
ROC train: 0.670392	val: 0.557904	test: 0.604617
PRC train: 0.668204	val: 0.634356	test: 0.630506

Epoch: 10
Loss: 0.5213755940833933
ROC train: 0.679695	val: 0.558994	test: 0.611554
PRC train: 0.670675	val: 0.634389	test: 0.635957

Epoch: 11
Loss: 0.5142533678112976
ROC train: 0.688882	val: 0.552998	test: 0.611207
PRC train: 0.679181	val: 0.632773	test: 0.633854

Epoch: 12
Loss: 0.5090337950657031
ROC train: 0.697275	val: 0.552742	test: 0.613640
PRC train: 0.687259	val: 0.633040	test: 0.637148

Epoch: 13
Loss: 0.5033649527512968
ROC train: 0.705082	val: 0.554311	test: 0.610752
PRC train: 0.694663	val: 0.636722	test: 0.634230

Epoch: 14
Loss: 0.5000879388428944
ROC train: 0.712911	val: 0.558216	test: 0.607271
PRC train: 0.696916	val: 0.638967	test: 0.638596

Epoch: 15
Loss: 0.49260176740292133
ROC train: 0.719002	val: 0.560463	test: 0.600153
PRC train: 0.703089	val: 0.640272	test: 0.635034

Epoch: 16
Loss: 0.4889855475913265
ROC train: 0.726693	val: 0.561228	test: 0.596585
PRC train: 0.708273	val: 0.640369	test: 0.628120

Epoch: 17
Loss: 0.4860941936267842
ROC train: 0.732895	val: 0.568757	test: 0.596051
PRC train: 0.714476	val: 0.644131	test: 0.623916

Epoch: 18
Loss: 0.4819638624419867
ROC train: 0.740926	val: 0.568086	test: 0.601857
PRC train: 0.719907	val: 0.644141	test: 0.629007

Epoch: 19
Loss: 0.4800623374447249
ROC train: 0.743178	val: 0.571349	test: 0.607186
PRC train: 0.719605	val: 0.647694	test: 0.634776

Epoch: 20
Loss: 0.4777107182999487
ROC train: 0.744779	val: 0.575145	test: 0.609465
PRC train: 0.721509	val: 0.648819	test: 0.635663

Epoch: 21
Loss: 0.4730798698447349
ROC train: 0.750780	val: 0.573396	test: 0.609131
PRC train: 0.725774	val: 0.649006	test: 0.633458

Epoch: 22
Loss: 0.47152154904756977
ROC train: 0.753639	val: 0.568420	test: 0.607712
PRC train: 0.728041	val: 0.642585	test: 0.631870

Epoch: 23
Loss: 0.4691564582727164
ROC train: 0.758397	val: 0.562136	test: 0.602814
PRC train: 0.732947	val: 0.638946	test: 0.629372

Epoch: 24
Loss: 0.4693585215352032
ROC train: 0.759477	val: 0.560860	test: 0.610232
PRC train: 0.731014	val: 0.638327	test: 0.631892

Epoch: 25
Loss: 0.46666410562625743
ROC train: 0.764782	val: 0.563493	test: 0.612525
PRC train: 0.733383	val: 0.644712	test: 0.636749

Epoch: 26
Loss: 0.4625303925258032
ROC train: 0.767298	val: 0.571431	test: 0.608226
PRC train: 0.738953	val: 0.651820	test: 0.634348

Epoch: 27
Loss: 0.45944425216390616
ROC train: 0.775600	val: 0.569760	test: 0.611186
PRC train: 0.745936	val: 0.648754	test: 0.636329

Epoch: 28
Loss: 0.4531386082123554
ROC train: 0.776802	val: 0.565692	test: 0.614850
PRC train: 0.746070	val: 0.643910	test: 0.638987

Epoch: 29
Loss: 0.4519081212621594
ROC train: 0.779520	val: 0.575004	test: 0.618313
PRC train: 0.748629	val: 0.648017	test: 0.641073

Epoch: 30
Loss: 0.4508274059744438
ROC train: 0.786017	val: 0.581530	test: 0.616605
PRC train: 0.753449	val: 0.651693	test: 0.640291

Epoch: 31
Loss: 0.45099090763087224
ROC train: 0.789673	val: 0.576997	test: 0.607696
PRC train: 0.757349	val: 0.648672	test: 0.632428

Epoch: 32
Loss: 0.4484866154353067
ROC train: 0.792497	val: 0.578569	test: 0.620585
PRC train: 0.759803	val: 0.648750	test: 0.639724

Epoch: 33
Loss: 0.4454646257371289Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:2
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/scaff/train_prop=0.8/sider_scaff_1_20-05_14-43-16  ]
[ Using Seed :  1  ]
[ Using device :  cuda:2  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6899478478612087
ROC train: 0.541673	val: 0.508770	test: 0.503274
PRC train: 0.583546	val: 0.603655	test: 0.583536

Epoch: 2
Loss: 0.638765746757025
ROC train: 0.560552	val: 0.507824	test: 0.500379
PRC train: 0.600429	val: 0.599304	test: 0.581393

Epoch: 3
Loss: 0.6038958930540957
ROC train: 0.569760	val: 0.504999	test: 0.499071
PRC train: 0.609142	val: 0.597452	test: 0.583586

Epoch: 4
Loss: 0.5740537920484509
ROC train: 0.593990	val: 0.520196	test: 0.510368
PRC train: 0.626225	val: 0.609195	test: 0.589921

Epoch: 5
Loss: 0.557995503158234
ROC train: 0.630254	val: 0.555394	test: 0.542681
PRC train: 0.646637	val: 0.634609	test: 0.604280

Epoch: 6
Loss: 0.5442786605734388
ROC train: 0.643631	val: 0.554866	test: 0.564564
PRC train: 0.652669	val: 0.633242	test: 0.615706

Epoch: 7
Loss: 0.5310800075379534
ROC train: 0.651541	val: 0.555998	test: 0.574774
PRC train: 0.657244	val: 0.630749	test: 0.619149

Epoch: 8
Loss: 0.5339945270193235
ROC train: 0.662361	val: 0.565057	test: 0.579872
PRC train: 0.664170	val: 0.632800	test: 0.626076

Epoch: 9
Loss: 0.515176065940919
ROC train: 0.677040	val: 0.572425	test: 0.588904
PRC train: 0.673997	val: 0.637694	test: 0.631856

Epoch: 10
Loss: 0.5059556814920032
ROC train: 0.687739	val: 0.589894	test: 0.590760
PRC train: 0.682814	val: 0.645153	test: 0.630590

Epoch: 11
Loss: 0.5047558705175613
ROC train: 0.696255	val: 0.596032	test: 0.595750
PRC train: 0.691521	val: 0.649145	test: 0.633710

Epoch: 12
Loss: 0.49614405008812057
ROC train: 0.706267	val: 0.595344	test: 0.597740
PRC train: 0.697722	val: 0.649479	test: 0.637076

Epoch: 13
Loss: 0.4924217744355729
ROC train: 0.715475	val: 0.601349	test: 0.602534
PRC train: 0.704579	val: 0.657201	test: 0.638554

Epoch: 14
Loss: 0.4860052709453237
ROC train: 0.719986	val: 0.601816	test: 0.600357
PRC train: 0.707525	val: 0.652691	test: 0.632758

Epoch: 15
Loss: 0.4884664849257273
ROC train: 0.724266	val: 0.608522	test: 0.603611
PRC train: 0.712462	val: 0.653623	test: 0.631666

Epoch: 16
Loss: 0.4833556022086657
ROC train: 0.732290	val: 0.596002	test: 0.604529
PRC train: 0.717014	val: 0.649118	test: 0.632953

Epoch: 17
Loss: 0.4769119857657317
ROC train: 0.735807	val: 0.589045	test: 0.606965
PRC train: 0.716719	val: 0.647974	test: 0.633895

Epoch: 18
Loss: 0.47596654636659
ROC train: 0.741701	val: 0.593868	test: 0.603521
PRC train: 0.720911	val: 0.649986	test: 0.633351

Epoch: 19
Loss: 0.4725334716459308
ROC train: 0.745907	val: 0.594690	test: 0.602603
PRC train: 0.725398	val: 0.650452	test: 0.633308

Epoch: 20
Loss: 0.46936277955453853
ROC train: 0.749639	val: 0.598030	test: 0.606058
PRC train: 0.730309	val: 0.653453	test: 0.633802

Epoch: 21
Loss: 0.4654156591224542
ROC train: 0.757709	val: 0.605931	test: 0.600388
PRC train: 0.735623	val: 0.653449	test: 0.630094

Epoch: 22
Loss: 0.46864580181761983
ROC train: 0.764395	val: 0.602636	test: 0.601423
PRC train: 0.739438	val: 0.653910	test: 0.629309

Epoch: 23
Loss: 0.4636518403946659
ROC train: 0.768985	val: 0.598833	test: 0.602745
PRC train: 0.744793	val: 0.651921	test: 0.627419

Epoch: 24
Loss: 0.46412959528583064
ROC train: 0.772381	val: 0.603155	test: 0.597184
PRC train: 0.745007	val: 0.656347	test: 0.622388

Epoch: 25
Loss: 0.46128179657545576
ROC train: 0.775802	val: 0.616624	test: 0.603754
PRC train: 0.748095	val: 0.663235	test: 0.629621

Epoch: 26
Loss: 0.45794050055425667
ROC train: 0.777906	val: 0.620327	test: 0.605884
PRC train: 0.750213	val: 0.659703	test: 0.633638

Epoch: 27
Loss: 0.4598229390569048
ROC train: 0.776922	val: 0.610177	test: 0.610847
PRC train: 0.748714	val: 0.657341	test: 0.636839

Epoch: 28
Loss: 0.45973403227687826
ROC train: 0.779630	val: 0.606340	test: 0.610856
PRC train: 0.752104	val: 0.656708	test: 0.636312

Epoch: 29
Loss: 0.4506626982141328
ROC train: 0.784315	val: 0.612720	test: 0.608338
PRC train: 0.756291	val: 0.661010	test: 0.637603

Epoch: 30
Loss: 0.4469723647142236
ROC train: 0.785383	val: 0.604869	test: 0.608327
PRC train: 0.757295	val: 0.657628	test: 0.632213

Epoch: 31
Loss: 0.4484576985218906
ROC train: 0.788381	val: 0.614326	test: 0.609242
PRC train: 0.761741	val: 0.658701	test: 0.636327

Epoch: 32
Loss: 0.44756037462938714
ROC train: 0.793769	val: 0.619506	test: 0.605473
PRC train: 0.766308	val: 0.661671	test: 0.636859

Epoch: 33
Loss: 0.44315918850522157Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:2
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/scaff/train_prop=0.8/sider_scaff_2_20-05_14-43-16  ]
[ Using Seed :  2  ]
[ Using device :  cuda:2  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6900040592129083
ROC train: 0.557671	val: 0.497034	test: 0.524879
PRC train: 0.590433	val: 0.605194	test: 0.582345

Epoch: 2
Loss: 0.6432254683052973
ROC train: 0.572252	val: 0.504373	test: 0.517177
PRC train: 0.601098	val: 0.600166	test: 0.585660

Epoch: 3
Loss: 0.605922399791031
ROC train: 0.574815	val: 0.507360	test: 0.501927
PRC train: 0.608420	val: 0.600678	test: 0.581234

Epoch: 4
Loss: 0.5777948267824277
ROC train: 0.589958	val: 0.517115	test: 0.503382
PRC train: 0.621162	val: 0.611837	test: 0.586514

Epoch: 5
Loss: 0.5586600224838317
ROC train: 0.625946	val: 0.550065	test: 0.552662
PRC train: 0.639491	val: 0.630904	test: 0.611823

Epoch: 6
Loss: 0.542163182537324
ROC train: 0.641665	val: 0.556578	test: 0.562726
PRC train: 0.649917	val: 0.632613	test: 0.613715

Epoch: 7
Loss: 0.5354936634327625
ROC train: 0.651923	val: 0.560835	test: 0.571599
PRC train: 0.656133	val: 0.632184	test: 0.616420

Epoch: 8
Loss: 0.5237684453457407
ROC train: 0.671008	val: 0.585076	test: 0.600941
PRC train: 0.667406	val: 0.640180	test: 0.629319

Epoch: 9
Loss: 0.5165633579624367
ROC train: 0.678997	val: 0.602548	test: 0.599407
PRC train: 0.673565	val: 0.649202	test: 0.627326

Epoch: 10
Loss: 0.5082471821762279
ROC train: 0.685242	val: 0.602945	test: 0.593357
PRC train: 0.677617	val: 0.654270	test: 0.622067

Epoch: 11
Loss: 0.5028543344728366
ROC train: 0.694201	val: 0.608122	test: 0.601883
PRC train: 0.684268	val: 0.654876	test: 0.626189

Epoch: 12
Loss: 0.4951524362717767
ROC train: 0.700752	val: 0.604864	test: 0.603214
PRC train: 0.689489	val: 0.653013	test: 0.628505

Epoch: 13
Loss: 0.4931312981197092
ROC train: 0.704960	val: 0.603714	test: 0.609727
PRC train: 0.692914	val: 0.654382	test: 0.634117

Epoch: 14
Loss: 0.4907097189376146
ROC train: 0.712932	val: 0.615677	test: 0.608882
PRC train: 0.698631	val: 0.659740	test: 0.637150

Epoch: 15
Loss: 0.48445828709684446
ROC train: 0.717938	val: 0.609823	test: 0.607216
PRC train: 0.701803	val: 0.654706	test: 0.640429

Epoch: 16
Loss: 0.48150499397553564
ROC train: 0.724473	val: 0.604536	test: 0.606958
PRC train: 0.706934	val: 0.652613	test: 0.634434

Epoch: 17
Loss: 0.47816340371190746
ROC train: 0.732159	val: 0.608530	test: 0.606071
PRC train: 0.712875	val: 0.656052	test: 0.634117

Epoch: 18
Loss: 0.4760682647843324
ROC train: 0.737588	val: 0.609876	test: 0.609186
PRC train: 0.714873	val: 0.659842	test: 0.633339

Epoch: 19
Loss: 0.4765245386021297
ROC train: 0.742626	val: 0.619398	test: 0.605912
PRC train: 0.716435	val: 0.664684	test: 0.626348

Epoch: 20
Loss: 0.4714357388085838
ROC train: 0.746777	val: 0.622384	test: 0.614589
PRC train: 0.719937	val: 0.663928	test: 0.629850

Epoch: 21
Loss: 0.47340873487125396
ROC train: 0.750148	val: 0.619856	test: 0.620454
PRC train: 0.723631	val: 0.660176	test: 0.632937

Epoch: 22
Loss: 0.4655020460593372
ROC train: 0.757589	val: 0.618103	test: 0.620903
PRC train: 0.728760	val: 0.660476	test: 0.635206

Epoch: 23
Loss: 0.4606724355849841
ROC train: 0.762745	val: 0.619189	test: 0.620481
PRC train: 0.732626	val: 0.660161	test: 0.635876

Epoch: 24
Loss: 0.4637324436001511
ROC train: 0.762873	val: 0.612173	test: 0.609310
PRC train: 0.736662	val: 0.658504	test: 0.633739

Epoch: 25
Loss: 0.4653110280816656
ROC train: 0.771532	val: 0.635874	test: 0.612682
PRC train: 0.741292	val: 0.668688	test: 0.630613

Epoch: 26
Loss: 0.4584245992766334
ROC train: 0.770338	val: 0.627404	test: 0.606515
PRC train: 0.739579	val: 0.668454	test: 0.628771

Epoch: 27
Loss: 0.45872506223091747
ROC train: 0.771969	val: 0.625833	test: 0.599142
PRC train: 0.740231	val: 0.668657	test: 0.626505

Epoch: 28
Loss: 0.45686755666836537
ROC train: 0.773969	val: 0.626935	test: 0.602890
PRC train: 0.741616	val: 0.667931	test: 0.626555

Epoch: 29
Loss: 0.4567838066884802
ROC train: 0.773230	val: 0.625629	test: 0.604263
PRC train: 0.742384	val: 0.663315	test: 0.626781

Epoch: 30
Loss: 0.4513867722462406
ROC train: 0.780230	val: 0.619179	test: 0.609758
PRC train: 0.746718	val: 0.663243	test: 0.629052

Epoch: 31
Loss: 0.4540673594289194
ROC train: 0.781211	val: 0.622991	test: 0.611699
PRC train: 0.747820	val: 0.665888	test: 0.632423

Epoch: 32
Loss: 0.448400964567632
ROC train: 0.786406	val: 0.624099	test: 0.614655
PRC train: 0.750536	val: 0.664560	test: 0.629414

Epoch: 33
Loss: 0.4467173581450538
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/sider/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:2
  input_data_dir: 
  dataset: sider
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/sider/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/sider/scaff/train_prop=0.8/sider_scaff_3_20-05_14-43-16  ]
[ Using Seed :  3  ]
[ Using device :  cuda:2  ]
Dataset: sider
Data: Data(edge_attr=[100912, 2], edge_index=[2, 100912], id=[1427], x=[48006, 2], y=[38529])
MoleculeDataset(1427)
split via scaffold
Data(edge_attr=[24, 2], edge_index=[2, 24], id=[1], x=[13, 2], y=[27])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=27, bias=True)
)
Epoch: 1
Loss: 0.6808354345050786
ROC train: 0.549954	val: 0.522569	test: 0.497784
PRC train: 0.589189	val: 0.612019	test: 0.577701

Epoch: 2
Loss: 0.6365109055351409
ROC train: 0.572549	val: 0.521054	test: 0.506598
PRC train: 0.608493	val: 0.604929	test: 0.587099

Epoch: 3
Loss: 0.5933291132353569
ROC train: 0.575227	val: 0.511552	test: 0.500560
PRC train: 0.613813	val: 0.602756	test: 0.588277

Epoch: 4
Loss: 0.5789237969902372
ROC train: 0.590401	val: 0.525031	test: 0.510925
PRC train: 0.626701	val: 0.616743	test: 0.592107

Epoch: 5
Loss: 0.5533964634304365
ROC train: 0.622983	val: 0.548159	test: 0.538158
PRC train: 0.643035	val: 0.625948	test: 0.603397

Epoch: 6
Loss: 0.5395429748938381
ROC train: 0.642734	val: 0.555362	test: 0.563775
PRC train: 0.652397	val: 0.627863	test: 0.615786

Epoch: 7
Loss: 0.5312884804274434
ROC train: 0.658087	val: 0.569930	test: 0.580224
PRC train: 0.662848	val: 0.631058	test: 0.619841

Epoch: 8
Loss: 0.5188509707091061
ROC train: 0.668637	val: 0.578140	test: 0.576989
PRC train: 0.670166	val: 0.636596	test: 0.615167

Epoch: 9
Loss: 0.50821110833075
ROC train: 0.679628	val: 0.587109	test: 0.582308
PRC train: 0.677192	val: 0.642752	test: 0.618935

Epoch: 10
Loss: 0.5031949144818046
ROC train: 0.690495	val: 0.593425	test: 0.591226
PRC train: 0.683764	val: 0.648182	test: 0.623318

Epoch: 11
Loss: 0.4970781523980473
ROC train: 0.698436	val: 0.595124	test: 0.600794
PRC train: 0.691865	val: 0.650432	test: 0.627223

Epoch: 12
Loss: 0.49475784740039364
ROC train: 0.704920	val: 0.594964	test: 0.590854
PRC train: 0.694028	val: 0.649642	test: 0.624291

Epoch: 13
Loss: 0.4937273327310616
ROC train: 0.715730	val: 0.600612	test: 0.589529
PRC train: 0.701423	val: 0.651120	test: 0.624700

Epoch: 14
Loss: 0.4817058706806421
ROC train: 0.719368	val: 0.601802	test: 0.589026
PRC train: 0.704021	val: 0.654774	test: 0.623330

Epoch: 15
Loss: 0.4833223011703405
ROC train: 0.724689	val: 0.591150	test: 0.597074
PRC train: 0.710693	val: 0.649189	test: 0.628961

Epoch: 16
Loss: 0.4810484047558214
ROC train: 0.726898	val: 0.591690	test: 0.597756
PRC train: 0.713290	val: 0.650487	test: 0.631927

Epoch: 17
Loss: 0.4793194463285178
ROC train: 0.737417	val: 0.598986	test: 0.601558
PRC train: 0.717995	val: 0.658892	test: 0.629462

Epoch: 18
Loss: 0.47511930190672447
ROC train: 0.740488	val: 0.606543	test: 0.610061
PRC train: 0.718932	val: 0.659457	test: 0.633757

Epoch: 19
Loss: 0.4747502126865511
ROC train: 0.743236	val: 0.607099	test: 0.607578
PRC train: 0.724244	val: 0.655494	test: 0.635267

Epoch: 20
Loss: 0.4660257755258728
ROC train: 0.753373	val: 0.608275	test: 0.597286
PRC train: 0.731412	val: 0.659134	test: 0.624049

Epoch: 21
Loss: 0.4678210130166507
ROC train: 0.758453	val: 0.609879	test: 0.592551
PRC train: 0.735066	val: 0.660921	test: 0.619918

Epoch: 22
Loss: 0.46196713613007157
ROC train: 0.761213	val: 0.613943	test: 0.602225
PRC train: 0.737729	val: 0.659549	test: 0.630385

Epoch: 23
Loss: 0.4634556162345903
ROC train: 0.765987	val: 0.615547	test: 0.603658
PRC train: 0.739152	val: 0.659240	test: 0.633003

Epoch: 24
Loss: 0.46337776051820734
ROC train: 0.770511	val: 0.612251	test: 0.603740
PRC train: 0.743954	val: 0.656031	test: 0.628290

Epoch: 25
Loss: 0.45650066448392324
ROC train: 0.771954	val: 0.617468	test: 0.599722
PRC train: 0.744729	val: 0.656175	test: 0.629102

Epoch: 26
Loss: 0.45871193672095767
ROC train: 0.775051	val: 0.621443	test: 0.592271
PRC train: 0.745665	val: 0.658370	test: 0.630623

Epoch: 27
Loss: 0.4543217982043729
ROC train: 0.780294	val: 0.620780	test: 0.604300
PRC train: 0.749817	val: 0.660633	test: 0.631920

Epoch: 28
Loss: 0.45915596725973157
ROC train: 0.782123	val: 0.623756	test: 0.610723
PRC train: 0.752307	val: 0.668303	test: 0.631905

Epoch: 29
Loss: 0.45405204424738754
ROC train: 0.787444	val: 0.633682	test: 0.605138
PRC train: 0.757124	val: 0.673771	test: 0.633029

Epoch: 30
Loss: 0.4550209122015304
ROC train: 0.788581	val: 0.621931	test: 0.608522
PRC train: 0.759613	val: 0.666139	test: 0.634297

Epoch: 31
Loss: 0.448376643102275
ROC train: 0.790411	val: 0.617164	test: 0.615741
PRC train: 0.761482	val: 0.662882	test: 0.636909

Epoch: 32
Loss: 0.44757442245832096
ROC train: 0.790702	val: 0.614983	test: 0.612846
PRC train: 0.759504	val: 0.662408	test: 0.635065

Epoch: 33
Loss: 0.44518895934434094
PRC train: 0.747423	val: 0.638616	test: 0.621623

Epoch: 34
Loss: 0.45491362363119164
ROC train: 0.792114	val: 0.559723	test: 0.579005
PRC train: 0.751154	val: 0.635493	test: 0.623211

Epoch: 35
Loss: 0.44970968839404696
ROC train: 0.799179	val: 0.549958	test: 0.580482
PRC train: 0.758164	val: 0.629968	test: 0.625310

Epoch: 36
Loss: 0.44370416353752773
ROC train: 0.804044	val: 0.541098	test: 0.580180
PRC train: 0.758889	val: 0.622669	test: 0.624870

Epoch: 37
Loss: 0.44173977822325766
ROC train: 0.803978	val: 0.540967	test: 0.583798
PRC train: 0.760438	val: 0.618431	test: 0.626532

Epoch: 38
Loss: 0.44135250703878787
ROC train: 0.802334	val: 0.549359	test: 0.585636
PRC train: 0.760144	val: 0.621453	test: 0.628116

Epoch: 39
Loss: 0.43916375528454293
ROC train: 0.804037	val: 0.552154	test: 0.584503
PRC train: 0.764106	val: 0.623656	test: 0.623114

Epoch: 40
Loss: 0.4346846761611017
ROC train: 0.806907	val: 0.547932	test: 0.582060
PRC train: 0.764631	val: 0.625470	test: 0.625806

Epoch: 41
Loss: 0.43301232268422507
ROC train: 0.807619	val: 0.542462	test: 0.575889
PRC train: 0.763398	val: 0.623867	test: 0.623904

Epoch: 42
Loss: 0.4394513846788996
ROC train: 0.811803	val: 0.541440	test: 0.578929
PRC train: 0.766316	val: 0.623245	test: 0.626231

Epoch: 43
Loss: 0.44178501457413943
ROC train: 0.806435	val: 0.543652	test: 0.584964
PRC train: 0.762712	val: 0.621961	test: 0.624727

Epoch: 44
Loss: 0.43646131310803765
ROC train: 0.810396	val: 0.545454	test: 0.590922
PRC train: 0.767692	val: 0.626879	test: 0.630066

Epoch: 45
Loss: 0.42805859795560514
ROC train: 0.817629	val: 0.550349	test: 0.590897
PRC train: 0.774206	val: 0.630251	test: 0.629458

Epoch: 46
Loss: 0.4323355018603067
ROC train: 0.821423	val: 0.552475	test: 0.584852
PRC train: 0.776823	val: 0.631544	test: 0.627373

Epoch: 47
Loss: 0.4269511752492203
ROC train: 0.819591	val: 0.549871	test: 0.584516
PRC train: 0.775955	val: 0.627760	test: 0.621139

Epoch: 48
Loss: 0.4264204670939482
ROC train: 0.823203	val: 0.550094	test: 0.583734
PRC train: 0.779798	val: 0.628781	test: 0.620244

Epoch: 49
Loss: 0.4223912523701268
ROC train: 0.825601	val: 0.541801	test: 0.580179
PRC train: 0.781440	val: 0.622869	test: 0.623181

Epoch: 50
Loss: 0.4259092471107983
ROC train: 0.828335	val: 0.541361	test: 0.577269
PRC train: 0.784128	val: 0.620490	test: 0.622223

Epoch: 51
Loss: 0.4238954649605493
ROC train: 0.828588	val: 0.546708	test: 0.575639
PRC train: 0.784483	val: 0.623312	test: 0.612248

Epoch: 52
Loss: 0.42352700519228237
ROC train: 0.833136	val: 0.544105	test: 0.577881
PRC train: 0.787022	val: 0.619952	test: 0.613941

Epoch: 53
Loss: 0.4232758795670726
ROC train: 0.836366	val: 0.547232	test: 0.584311
PRC train: 0.788838	val: 0.621297	test: 0.619964

Epoch: 54
Loss: 0.4181136262353458
ROC train: 0.839151	val: 0.555661	test: 0.589717
PRC train: 0.793670	val: 0.626829	test: 0.621880

Epoch: 55
Loss: 0.4207492178032878
ROC train: 0.842040	val: 0.560755	test: 0.591934
PRC train: 0.796052	val: 0.630991	test: 0.625190

Epoch: 56
Loss: 0.4124252885832246
ROC train: 0.839145	val: 0.554229	test: 0.586769
PRC train: 0.792250	val: 0.627132	test: 0.622870

Epoch: 57
Loss: 0.4147159338253951
ROC train: 0.840678	val: 0.556486	test: 0.586565
PRC train: 0.794027	val: 0.628800	test: 0.619377

Epoch: 58
Loss: 0.4129084459109559
ROC train: 0.843730	val: 0.557118	test: 0.592744
PRC train: 0.797147	val: 0.627191	test: 0.622085

Epoch: 59
Loss: 0.41546902647892026
ROC train: 0.847924	val: 0.550907	test: 0.600377
PRC train: 0.799662	val: 0.625596	test: 0.632683

Epoch: 60
Loss: 0.4065808901744131
ROC train: 0.849272	val: 0.549527	test: 0.603718
PRC train: 0.800006	val: 0.627462	test: 0.637789

Epoch: 61
Loss: 0.41028825569058724
ROC train: 0.847466	val: 0.555167	test: 0.600103
PRC train: 0.801648	val: 0.633920	test: 0.633366

Epoch: 62
Loss: 0.4067208418892568
ROC train: 0.849441	val: 0.559384	test: 0.600791
PRC train: 0.807205	val: 0.635380	test: 0.630851

Epoch: 63
Loss: 0.40389216931099936
ROC train: 0.850416	val: 0.560730	test: 0.599087
PRC train: 0.806982	val: 0.630781	test: 0.625763

Epoch: 64
Loss: 0.40067252543616105
ROC train: 0.856204	val: 0.556700	test: 0.596488
PRC train: 0.808703	val: 0.626500	test: 0.626009

Epoch: 65
Loss: 0.4025497345501371
ROC train: 0.856447	val: 0.554573	test: 0.597183
PRC train: 0.808675	val: 0.628570	test: 0.627476

Epoch: 66
Loss: 0.4004169425953781
ROC train: 0.859209	val: 0.553254	test: 0.594099
PRC train: 0.811859	val: 0.629731	test: 0.629164

Epoch: 67
Loss: 0.40274139455559255
ROC train: 0.858956	val: 0.552851	test: 0.587884
PRC train: 0.811575	val: 0.629882	test: 0.625478

Epoch: 68
Loss: 0.40027671833968403
ROC train: 0.859336	val: 0.547765	test: 0.584299
PRC train: 0.811168	val: 0.626514	test: 0.622506

Epoch: 69
Loss: 0.3921089924704188
ROC train: 0.861401	val: 0.550980	test: 0.585194
PRC train: 0.813794	val: 0.626413	test: 0.620270

Epoch: 70
Loss: 0.3974808979250715
ROC train: 0.860693	val: 0.553618	test: 0.586785
PRC train: 0.812904	val: 0.628497	test: 0.622789

Epoch: 71
Loss: 0.39096700729849926
ROC train: 0.860101	val: 0.554578	test: 0.589059
PRC train: 0.809915	val: 0.630474	test: 0.623041

Epoch: 72
Loss: 0.39103335696754976
ROC train: 0.861541	val: 0.550522	test: 0.589389
PRC train: 0.810205	val: 0.630047	test: 0.624258

Epoch: 73
Loss: 0.3967373894745112
ROC train: 0.864718	val: 0.547446	test: 0.586663
PRC train: 0.816611	val: 0.626168	test: 0.624058

Epoch: 74
Loss: 0.3893475212033456
ROC train: 0.867286	val: 0.548457	test: 0.587034
PRC train: 0.820415	val: 0.623678	test: 0.622840

Epoch: 75
Loss: 0.3873561044152672
ROC train: 0.870556	val: 0.556303	test: 0.589598
PRC train: 0.825672	val: 0.626753	test: 0.621517

Epoch: 76
Loss: 0.38357483333380094
ROC train: 0.869817	val: 0.553993	test: 0.588826
PRC train: 0.824614	val: 0.626174	test: 0.621308

Epoch: 77
Loss: 0.38871831899601605
ROC train: 0.871769	val: 0.544355	test: 0.595431
PRC train: 0.828357	val: 0.622387	test: 0.627351

Epoch: 78
Loss: 0.3814861907740116
ROC train: 0.870892	val: 0.544540	test: 0.594072
PRC train: 0.824578	val: 0.623213	test: 0.629372

Epoch: 79
Loss: 0.3901848743469856
ROC train: 0.872600	val: 0.556006	test: 0.588868
PRC train: 0.825182	val: 0.631666	test: 0.626889

Epoch: 80
Loss: 0.3828449948520467
ROC train: 0.874520	val: 0.562609	test: 0.589068
PRC train: 0.826932	val: 0.636941	test: 0.624395

Epoch: 81
Loss: 0.3759556964476218
ROC train: 0.876501	val: 0.561006	test: 0.585945
PRC train: 0.827051	val: 0.635246	test: 0.621884

Epoch: 82
Loss: 0.3889067291097045
ROC train: 0.879021	val: 0.558481	test: 0.586070
PRC train: 0.831799	val: 0.632394	test: 0.620869

Epoch: 83
Loss: 0.38350157229217297
ROC train: 0.882971	val: 0.557540	test: 0.591321
PRC train: 0.837689	val: 0.634914	test: 0.624138

Epoch: 84
Loss: 0.37219647367968745
ROC train: 0.881526	val: 0.550984	test: 0.587476
PRC train: 0.835040	val: 0.630958	test: 0.623043

Epoch: 85
Loss: 0.38290526989363755
ROC train: 0.882201	val: 0.548610	test: 0.589683
PRC train: 0.835059	val: 0.628002	test: 0.621937

Epoch: 86
Loss: 0.37787047605867774
ROC train: 0.881207	val: 0.553606	test: 0.592191
PRC train: 0.834330	val: 0.631106	test: 0.624434

Epoch: 87
Loss: 0.377771242739924
ROC train: 0.883682	val: 0.553772	test: 0.594300
PRC train: 0.835240	val: 0.629721	test: 0.624576

Epoch: 88
Loss: 0.38017001906675874
ROC train: 0.882209	val: 0.553804	test: 0.586442
PRC train: 0.835264	val: 0.629678	test: 0.619149

Epoch: 89
Loss: 0.37192312001996836
ROC train: 0.882177	val: 0.548930	test: 0.582660
PRC train: 0.835325	val: 0.627376	test: 0.618644

Epoch: 90
Loss: 0.37078665999495164
ROC train: 0.884649	val: 0.548560	test: 0.585457
PRC train: 0.839429	val: 0.628697	test: 0.621145

Epoch: 91
Loss: 0.36977799233256914
ROC train: 0.886391	val: 0.553805	test: 0.588750
PRC train: 0.840814	val: 0.630473	test: 0.622471

Epoch: 92
Loss: 0.3733917259537708
ROC train: 0.886862	val: 0.557335	test: 0.592560
PRC train: 0.842531	val: 0.631274	test: 0.622364

Epoch: 93
Loss: 0.3682120990680384
ROC train: 0.884191	val: 0.554590	test: 0.588163
PRC train: 0.839974	val: 0.629422	test: 0.624183

Epoch: 94
Loss: 0.3681530436532796
ROC train: 0.887248	val: 0.557359	test: 0.592189ROC train: 0.791812	val: 0.550210	test: 0.606556
PRC train: 0.751311	val: 0.627673	test: 0.639421

Epoch: 34
Loss: 0.4395477454977032
ROC train: 0.795848	val: 0.546630	test: 0.606724
PRC train: 0.753849	val: 0.625701	test: 0.640029

Epoch: 35
Loss: 0.4462585769611053
ROC train: 0.803491	val: 0.546601	test: 0.608031
PRC train: 0.757900	val: 0.622463	test: 0.642127

Epoch: 36
Loss: 0.443735013380866
ROC train: 0.800305	val: 0.547506	test: 0.608291
PRC train: 0.756099	val: 0.619347	test: 0.642289

Epoch: 37
Loss: 0.4424581962462393
ROC train: 0.804363	val: 0.546888	test: 0.607996
PRC train: 0.759368	val: 0.617525	test: 0.641323

Epoch: 38
Loss: 0.4400890460545398
ROC train: 0.802728	val: 0.537214	test: 0.597702
PRC train: 0.757497	val: 0.610919	test: 0.636616

Epoch: 39
Loss: 0.4400060209069928
ROC train: 0.806425	val: 0.545390	test: 0.599829
PRC train: 0.760894	val: 0.621302	test: 0.635212

Epoch: 40
Loss: 0.4430065800516946
ROC train: 0.808201	val: 0.556461	test: 0.605268
PRC train: 0.765012	val: 0.630911	test: 0.636952

Epoch: 41
Loss: 0.43817332214530097
ROC train: 0.815303	val: 0.553782	test: 0.614430
PRC train: 0.769184	val: 0.625846	test: 0.640998

Epoch: 42
Loss: 0.43746712552942635
ROC train: 0.818604	val: 0.550120	test: 0.617854
PRC train: 0.771818	val: 0.622112	test: 0.645234

Epoch: 43
Loss: 0.4341959292298077
ROC train: 0.819037	val: 0.552884	test: 0.619452
PRC train: 0.772880	val: 0.623236	test: 0.646012

Epoch: 44
Loss: 0.4332693120622704
ROC train: 0.821613	val: 0.554132	test: 0.614491
PRC train: 0.774536	val: 0.622893	test: 0.643923

Epoch: 45
Loss: 0.42663262882747327
ROC train: 0.824037	val: 0.550832	test: 0.608956
PRC train: 0.776715	val: 0.624166	test: 0.639928

Epoch: 46
Loss: 0.4313922779811148
ROC train: 0.822646	val: 0.555177	test: 0.605300
PRC train: 0.773925	val: 0.629995	test: 0.637312

Epoch: 47
Loss: 0.42762949252409466
ROC train: 0.823124	val: 0.558443	test: 0.603533
PRC train: 0.774446	val: 0.631168	test: 0.638764

Epoch: 48
Loss: 0.42517464711579755
ROC train: 0.826381	val: 0.559768	test: 0.606333
PRC train: 0.777005	val: 0.630052	test: 0.640300

Epoch: 49
Loss: 0.4209044210990411
ROC train: 0.830535	val: 0.565886	test: 0.605569
PRC train: 0.781766	val: 0.635624	test: 0.640188

Epoch: 50
Loss: 0.4239527181903832
ROC train: 0.834463	val: 0.555756	test: 0.604113
PRC train: 0.783600	val: 0.628242	test: 0.641297

Epoch: 51
Loss: 0.42191034723305215
ROC train: 0.831440	val: 0.547550	test: 0.602037
PRC train: 0.781792	val: 0.621304	test: 0.641597

Epoch: 52
Loss: 0.4289652666858187
ROC train: 0.830785	val: 0.545212	test: 0.604430
PRC train: 0.782299	val: 0.616706	test: 0.643666

Epoch: 53
Loss: 0.4179927865985801
ROC train: 0.831867	val: 0.555138	test: 0.613200
PRC train: 0.781876	val: 0.622742	test: 0.645974

Epoch: 54
Loss: 0.41801586224832027
ROC train: 0.833214	val: 0.553487	test: 0.617587
PRC train: 0.784862	val: 0.626674	test: 0.647477

Epoch: 55
Loss: 0.4197669973464006
ROC train: 0.840057	val: 0.548733	test: 0.612973
PRC train: 0.789550	val: 0.623302	test: 0.644594

Epoch: 56
Loss: 0.41430111150779014
ROC train: 0.842670	val: 0.544352	test: 0.606038
PRC train: 0.790706	val: 0.618866	test: 0.638550

Epoch: 57
Loss: 0.41453919686221574
ROC train: 0.839425	val: 0.551111	test: 0.605580
PRC train: 0.791943	val: 0.625150	test: 0.637056

Epoch: 58
Loss: 0.41374740608082433
ROC train: 0.839993	val: 0.555335	test: 0.606031
PRC train: 0.792494	val: 0.629936	test: 0.637362

Epoch: 59
Loss: 0.40295945553801477
ROC train: 0.842079	val: 0.554464	test: 0.613304
PRC train: 0.793761	val: 0.628785	test: 0.641147

Epoch: 60
Loss: 0.41436753326728054
ROC train: 0.844791	val: 0.553817	test: 0.618663
PRC train: 0.796505	val: 0.628494	test: 0.646316

Epoch: 61
Loss: 0.411619011060505
ROC train: 0.851351	val: 0.558695	test: 0.616395
PRC train: 0.800735	val: 0.631717	test: 0.646992

Epoch: 62
Loss: 0.4039224466822221
ROC train: 0.853470	val: 0.559917	test: 0.609572
PRC train: 0.802857	val: 0.635231	test: 0.641247

Epoch: 63
Loss: 0.4081125073638566
ROC train: 0.852439	val: 0.558303	test: 0.610313
PRC train: 0.801948	val: 0.630495	test: 0.642209

Epoch: 64
Loss: 0.406291522575011
ROC train: 0.850738	val: 0.559993	test: 0.610101
PRC train: 0.801121	val: 0.629746	test: 0.643140

Epoch: 65
Loss: 0.39960672553054805
ROC train: 0.848260	val: 0.558975	test: 0.604161
PRC train: 0.798231	val: 0.629040	test: 0.641794

Epoch: 66
Loss: 0.40171436144941075
ROC train: 0.851921	val: 0.555832	test: 0.598262
PRC train: 0.801792	val: 0.624112	test: 0.638446

Epoch: 67
Loss: 0.4050817995126976
ROC train: 0.855070	val: 0.551784	test: 0.598563
PRC train: 0.803451	val: 0.619362	test: 0.640045

Epoch: 68
Loss: 0.39384759553195464
ROC train: 0.852726	val: 0.552095	test: 0.601669
PRC train: 0.801355	val: 0.619222	test: 0.640494

Epoch: 69
Loss: 0.40167037741259176
ROC train: 0.862136	val: 0.561143	test: 0.612021
PRC train: 0.810717	val: 0.626910	test: 0.642880

Epoch: 70
Loss: 0.3927182401216244
ROC train: 0.864324	val: 0.564151	test: 0.610072
PRC train: 0.812083	val: 0.633036	test: 0.640298

Epoch: 71
Loss: 0.3987616179920228
ROC train: 0.862764	val: 0.562642	test: 0.606264
PRC train: 0.810922	val: 0.638170	test: 0.639593

Epoch: 72
Loss: 0.39422492348207605
ROC train: 0.862697	val: 0.552676	test: 0.603714
PRC train: 0.810908	val: 0.630994	test: 0.642741

Epoch: 73
Loss: 0.38789171938773287
ROC train: 0.864674	val: 0.546634	test: 0.600452
PRC train: 0.813591	val: 0.626923	test: 0.641721

Epoch: 74
Loss: 0.39335126064012765
ROC train: 0.870013	val: 0.561698	test: 0.609354
PRC train: 0.819411	val: 0.635272	test: 0.640365

Epoch: 75
Loss: 0.39447082855707705
ROC train: 0.870593	val: 0.571919	test: 0.610571
PRC train: 0.821425	val: 0.638162	test: 0.640616

Epoch: 76
Loss: 0.39432503386794754
ROC train: 0.866366	val: 0.573047	test: 0.606866
PRC train: 0.814425	val: 0.638107	test: 0.638392

Epoch: 77
Loss: 0.3923245386018883
ROC train: 0.867879	val: 0.570765	test: 0.604447
PRC train: 0.816045	val: 0.642478	test: 0.636210

Epoch: 78
Loss: 0.3837080972305962
ROC train: 0.870813	val: 0.569878	test: 0.603227
PRC train: 0.820808	val: 0.642690	test: 0.636884

Epoch: 79
Loss: 0.3853077897843915
ROC train: 0.872636	val: 0.567307	test: 0.599408
PRC train: 0.822741	val: 0.639267	test: 0.636403

Epoch: 80
Loss: 0.3850881358516638
ROC train: 0.864695	val: 0.561105	test: 0.597599
PRC train: 0.814758	val: 0.631339	test: 0.634592

Epoch: 81
Loss: 0.38999549108961573
ROC train: 0.871935	val: 0.557831	test: 0.606390
PRC train: 0.823794	val: 0.629121	test: 0.636504

Epoch: 82
Loss: 0.3752447368809036
ROC train: 0.879170	val: 0.561246	test: 0.615034
PRC train: 0.834966	val: 0.631727	test: 0.642216

Epoch: 83
Loss: 0.3811257598493074
ROC train: 0.879986	val: 0.559697	test: 0.617006
PRC train: 0.834278	val: 0.632269	test: 0.643460

Epoch: 84
Loss: 0.3745734059785456
ROC train: 0.878359	val: 0.561775	test: 0.612319
PRC train: 0.831995	val: 0.634807	test: 0.638481

Epoch: 85
Loss: 0.3829021784504074
ROC train: 0.879614	val: 0.563441	test: 0.605823
PRC train: 0.831460	val: 0.636835	test: 0.637511

Epoch: 86
Loss: 0.3773808271724124
ROC train: 0.877895	val: 0.563607	test: 0.602052
PRC train: 0.828226	val: 0.634000	test: 0.634878

Epoch: 87
Loss: 0.3789246817948335
ROC train: 0.877605	val: 0.562450	test: 0.603710
PRC train: 0.826302	val: 0.632674	test: 0.637043

Epoch: 88
Loss: 0.3807743592864251
ROC train: 0.881311	val: 0.565361	test: 0.610436
PRC train: 0.832163	val: 0.635699	test: 0.641689

Epoch: 89
Loss: 0.3756690893740112
ROC train: 0.885697	val: 0.570482	test: 0.612345
PRC train: 0.835910	val: 0.639727	test: 0.641563

Epoch: 90
Loss: 0.36801906550392893
ROC train: 0.885187	val: 0.569076	test: 0.604325
PRC train: 0.833526	val: 0.638960	test: 0.639660

Epoch: 91
Loss: 0.3756288239470981
ROC train: 0.886414	val: 0.569427	test: 0.601390
PRC train: 0.835674	val: 0.639792	test: 0.639127

Epoch: 92
Loss: 0.3740194302557916
ROC train: 0.889588	val: 0.572545	test: 0.607651
PRC train: 0.838494	val: 0.640226	test: 0.641600

Epoch: 93
Loss: 0.37206020043254295
ROC train: 0.886319	val: 0.560501	test: 0.599857
PRC train: 0.834993	val: 0.632150	test: 0.638981

Epoch: 94
Loss: 0.3659555695508825
ROC train: 0.793174	val: 0.555650	test: 0.594876
PRC train: 0.752178	val: 0.628383	test: 0.636535

Epoch: 34
Loss: 0.4483211483050548
ROC train: 0.792009	val: 0.568674	test: 0.603492
PRC train: 0.753611	val: 0.637237	test: 0.637444

Epoch: 35
Loss: 0.44991849541964546
ROC train: 0.793329	val: 0.569885	test: 0.600033
PRC train: 0.754490	val: 0.634822	test: 0.633888

Epoch: 36
Loss: 0.44703556589340343
ROC train: 0.801789	val: 0.564610	test: 0.598014
PRC train: 0.760105	val: 0.628062	test: 0.633890

Epoch: 37
Loss: 0.447542585133443
ROC train: 0.803536	val: 0.557399	test: 0.596761
PRC train: 0.761506	val: 0.626680	test: 0.633641

Epoch: 38
Loss: 0.44421987431543536
ROC train: 0.805003	val: 0.557480	test: 0.596542
PRC train: 0.762154	val: 0.628008	test: 0.634552

Epoch: 39
Loss: 0.4349677550612212
ROC train: 0.809532	val: 0.561223	test: 0.598295
PRC train: 0.765945	val: 0.635380	test: 0.635548

Epoch: 40
Loss: 0.4359498974047179
ROC train: 0.812041	val: 0.563487	test: 0.600714
PRC train: 0.767842	val: 0.639789	test: 0.636843

Epoch: 41
Loss: 0.43573619374728495
ROC train: 0.815168	val: 0.556261	test: 0.599626
PRC train: 0.769951	val: 0.634740	test: 0.634820

Epoch: 42
Loss: 0.4303148455356443
ROC train: 0.816663	val: 0.545609	test: 0.593064
PRC train: 0.771345	val: 0.626908	test: 0.631675

Epoch: 43
Loss: 0.4285602350439121
ROC train: 0.820012	val: 0.549809	test: 0.592924
PRC train: 0.774483	val: 0.629285	test: 0.630647

Epoch: 44
Loss: 0.43404214540956454
ROC train: 0.820798	val: 0.556686	test: 0.594702
PRC train: 0.775266	val: 0.632580	test: 0.631133

Epoch: 45
Loss: 0.42423093376669146
ROC train: 0.825185	val: 0.557893	test: 0.601497
PRC train: 0.778812	val: 0.631662	test: 0.635358

Epoch: 46
Loss: 0.4221709769972207
ROC train: 0.824055	val: 0.554451	test: 0.597993
PRC train: 0.779030	val: 0.630937	test: 0.633654

Epoch: 47
Loss: 0.42645261456055217
ROC train: 0.825113	val: 0.557112	test: 0.597691
PRC train: 0.779961	val: 0.632545	test: 0.631419

Epoch: 48
Loss: 0.4302084713810918
ROC train: 0.827849	val: 0.560038	test: 0.595368
PRC train: 0.782833	val: 0.632151	test: 0.631258

Epoch: 49
Loss: 0.4261818421194773
ROC train: 0.829235	val: 0.555875	test: 0.593018
PRC train: 0.784408	val: 0.628380	test: 0.629836

Epoch: 50
Loss: 0.4148995119472644
ROC train: 0.825761	val: 0.551163	test: 0.594196
PRC train: 0.782801	val: 0.628009	test: 0.627877

Epoch: 51
Loss: 0.4221882982170025
ROC train: 0.829534	val: 0.556040	test: 0.598163
PRC train: 0.784882	val: 0.632523	test: 0.632218

Epoch: 52
Loss: 0.41826925210001936
ROC train: 0.834540	val: 0.560002	test: 0.602094
PRC train: 0.790737	val: 0.636780	test: 0.637876

Epoch: 53
Loss: 0.42452543225003947
ROC train: 0.836542	val: 0.553210	test: 0.601370
PRC train: 0.796603	val: 0.636431	test: 0.637233

Epoch: 54
Loss: 0.42190987560101584
ROC train: 0.834377	val: 0.546320	test: 0.594751
PRC train: 0.793779	val: 0.634488	test: 0.629727

Epoch: 55
Loss: 0.42296135822158715
ROC train: 0.818979	val: 0.538081	test: 0.588775
PRC train: 0.777696	val: 0.626987	test: 0.626513

Epoch: 56
Loss: 0.41452020266808787
ROC train: 0.832334	val: 0.539445	test: 0.591365
PRC train: 0.789407	val: 0.628045	test: 0.628912

Epoch: 57
Loss: 0.41024280473242297
ROC train: 0.838329	val: 0.540192	test: 0.598735
PRC train: 0.796266	val: 0.625023	test: 0.630985

Epoch: 58
Loss: 0.4094511318939363
ROC train: 0.835461	val: 0.540433	test: 0.599752
PRC train: 0.794198	val: 0.625291	test: 0.630427

Epoch: 59
Loss: 0.40744139137546853
ROC train: 0.840833	val: 0.547374	test: 0.594649
PRC train: 0.799633	val: 0.628212	test: 0.629355

Epoch: 60
Loss: 0.4120950788678338
ROC train: 0.845267	val: 0.552982	test: 0.590560
PRC train: 0.801922	val: 0.630970	test: 0.630225

Epoch: 61
Loss: 0.40960380727795564
ROC train: 0.847354	val: 0.558303	test: 0.594123
PRC train: 0.803407	val: 0.633837	test: 0.631025

Epoch: 62
Loss: 0.41301828402297014
ROC train: 0.851509	val: 0.553640	test: 0.592880
PRC train: 0.805451	val: 0.633001	test: 0.631887

Epoch: 63
Loss: 0.40764102576191485
ROC train: 0.850507	val: 0.549375	test: 0.595687
PRC train: 0.804163	val: 0.628012	test: 0.636257

Epoch: 64
Loss: 0.41169155615394887
ROC train: 0.851756	val: 0.557909	test: 0.602180
PRC train: 0.807440	val: 0.631584	test: 0.636400

Epoch: 65
Loss: 0.40588717256158846
ROC train: 0.850438	val: 0.560102	test: 0.600636
PRC train: 0.808285	val: 0.632632	test: 0.632246

Epoch: 66
Loss: 0.4120594708783285
ROC train: 0.855140	val: 0.564704	test: 0.600557
PRC train: 0.812235	val: 0.636418	test: 0.632471

Epoch: 67
Loss: 0.39733464125123014
ROC train: 0.856057	val: 0.565641	test: 0.595746
PRC train: 0.813273	val: 0.636418	test: 0.633569

Epoch: 68
Loss: 0.4012000720503013
ROC train: 0.857016	val: 0.567232	test: 0.594222
PRC train: 0.812788	val: 0.638930	test: 0.632931

Epoch: 69
Loss: 0.39622693133186404
ROC train: 0.857990	val: 0.563346	test: 0.593293
PRC train: 0.813628	val: 0.638611	test: 0.630108

Epoch: 70
Loss: 0.393378374803263
ROC train: 0.857080	val: 0.555368	test: 0.584751
PRC train: 0.810650	val: 0.631608	test: 0.628431

Epoch: 71
Loss: 0.40626630333267816
ROC train: 0.863164	val: 0.564364	test: 0.592244
PRC train: 0.818180	val: 0.636795	test: 0.632190

Epoch: 72
Loss: 0.39789255831952075
ROC train: 0.864673	val: 0.568978	test: 0.598584
PRC train: 0.820231	val: 0.637912	test: 0.634001

Epoch: 73
Loss: 0.39321986500109446
ROC train: 0.867377	val: 0.566449	test: 0.597160
PRC train: 0.824446	val: 0.635872	test: 0.632384

Epoch: 74
Loss: 0.3925519397889524
ROC train: 0.867808	val: 0.562125	test: 0.593172
PRC train: 0.823176	val: 0.636115	test: 0.632980

Epoch: 75
Loss: 0.3945720654920797
ROC train: 0.865341	val: 0.556143	test: 0.588272
PRC train: 0.819343	val: 0.633816	test: 0.630485

Epoch: 76
Loss: 0.3958892393987774
ROC train: 0.869222	val: 0.553685	test: 0.591652
PRC train: 0.826521	val: 0.631424	test: 0.631665

Epoch: 77
Loss: 0.3886912269113626
ROC train: 0.872789	val: 0.558047	test: 0.598276
PRC train: 0.834329	val: 0.631675	test: 0.635004

Epoch: 78
Loss: 0.38318286258249357
ROC train: 0.871897	val: 0.560578	test: 0.598109
PRC train: 0.835164	val: 0.632080	test: 0.636344

Epoch: 79
Loss: 0.3924644199025682
ROC train: 0.874605	val: 0.564401	test: 0.599127
PRC train: 0.834221	val: 0.636344	test: 0.633182

Epoch: 80
Loss: 0.3811536504483294
ROC train: 0.874710	val: 0.558488	test: 0.596719
PRC train: 0.832087	val: 0.632464	test: 0.629486

Epoch: 81
Loss: 0.38123551621436974
ROC train: 0.869479	val: 0.551749	test: 0.592030
PRC train: 0.826189	val: 0.629237	test: 0.627566

Epoch: 82
Loss: 0.3862147820442221
ROC train: 0.866797	val: 0.546649	test: 0.590110
PRC train: 0.824915	val: 0.624983	test: 0.627642

Epoch: 83
Loss: 0.38093265308797847
ROC train: 0.878190	val: 0.553495	test: 0.597208
PRC train: 0.838189	val: 0.628707	test: 0.632898

Epoch: 84
Loss: 0.3800527742896971
ROC train: 0.879172	val: 0.557277	test: 0.600576
PRC train: 0.834276	val: 0.633393	test: 0.634436

Epoch: 85
Loss: 0.38653020687035106
ROC train: 0.881344	val: 0.552072	test: 0.598446
PRC train: 0.836254	val: 0.630993	test: 0.633906

Epoch: 86
Loss: 0.381679260738373
ROC train: 0.881508	val: 0.549648	test: 0.597513
PRC train: 0.838267	val: 0.629617	test: 0.633473

Epoch: 87
Loss: 0.3799440477029581
ROC train: 0.881925	val: 0.556430	test: 0.599180
PRC train: 0.839033	val: 0.633518	test: 0.636368

Epoch: 88
Loss: 0.3754326442175622
ROC train: 0.876944	val: 0.557519	test: 0.590911
PRC train: 0.832237	val: 0.635626	test: 0.635015

Epoch: 89
Loss: 0.37977171618280914
ROC train: 0.880485	val: 0.558031	test: 0.591898
PRC train: 0.838094	val: 0.636197	test: 0.634495

Epoch: 90
Loss: 0.3682891468234045
ROC train: 0.881753	val: 0.560633	test: 0.593328
PRC train: 0.839778	val: 0.636042	test: 0.630320

Epoch: 91
Loss: 0.36878634876488475
ROC train: 0.882825	val: 0.559051	test: 0.594759
PRC train: 0.842397	val: 0.633354	test: 0.630515

Epoch: 92
Loss: 0.3830078470441255
ROC train: 0.889144	val: 0.561666	test: 0.599247
PRC train: 0.849042	val: 0.634394	test: 0.634197

Epoch: 93
Loss: 0.3693388054723255
ROC train: 0.888659	val: 0.556569	test: 0.599440
PRC train: 0.847464	val: 0.632170	test: 0.633673

Epoch: 94
Loss: 0.372423752672422
ROC train: 0.792678	val: 0.568905	test: 0.617950
PRC train: 0.756758	val: 0.643729	test: 0.638336

Epoch: 34
Loss: 0.4430101900577535
ROC train: 0.793862	val: 0.564948	test: 0.617111
PRC train: 0.757114	val: 0.643341	test: 0.636859

Epoch: 35
Loss: 0.44395819891094085
ROC train: 0.797817	val: 0.569630	test: 0.613698
PRC train: 0.761285	val: 0.645923	test: 0.632740

Epoch: 36
Loss: 0.44319039265059257
ROC train: 0.804240	val: 0.574398	test: 0.610451
PRC train: 0.765431	val: 0.646454	test: 0.630682

Epoch: 37
Loss: 0.44290189264041524
ROC train: 0.804393	val: 0.576114	test: 0.605025
PRC train: 0.766733	val: 0.649360	test: 0.627994

Epoch: 38
Loss: 0.4417267606238496
ROC train: 0.804682	val: 0.572101	test: 0.607780
PRC train: 0.767535	val: 0.648630	test: 0.634370

Epoch: 39
Loss: 0.4413111042436593
ROC train: 0.804474	val: 0.558326	test: 0.607487
PRC train: 0.766924	val: 0.643924	test: 0.635995

Epoch: 40
Loss: 0.4370227133821027
ROC train: 0.809400	val: 0.564762	test: 0.600460
PRC train: 0.769831	val: 0.646362	test: 0.627119

Epoch: 41
Loss: 0.437329582577232
ROC train: 0.811585	val: 0.576425	test: 0.600996
PRC train: 0.774175	val: 0.649349	test: 0.628450

Epoch: 42
Loss: 0.43051355983518236
ROC train: 0.814396	val: 0.575669	test: 0.600927
PRC train: 0.776978	val: 0.647876	test: 0.630018

Epoch: 43
Loss: 0.43544238091953313
ROC train: 0.815581	val: 0.574530	test: 0.601722
PRC train: 0.777791	val: 0.644038	test: 0.629902

Epoch: 44
Loss: 0.4248267179339797
ROC train: 0.819886	val: 0.577027	test: 0.605332
PRC train: 0.780530	val: 0.644636	test: 0.629828

Epoch: 45
Loss: 0.4271107873428
ROC train: 0.827716	val: 0.575073	test: 0.607399
PRC train: 0.785070	val: 0.645182	test: 0.633137

Epoch: 46
Loss: 0.4267491955928933
ROC train: 0.826978	val: 0.568715	test: 0.603463
PRC train: 0.783084	val: 0.645852	test: 0.629537

Epoch: 47
Loss: 0.4281693874248199
ROC train: 0.826982	val: 0.569099	test: 0.610250
PRC train: 0.784219	val: 0.649510	test: 0.633728

Epoch: 48
Loss: 0.42541242754119224
ROC train: 0.834068	val: 0.571182	test: 0.608126
PRC train: 0.790473	val: 0.648551	test: 0.629298

Epoch: 49
Loss: 0.4199172895221087
ROC train: 0.833955	val: 0.569649	test: 0.606236
PRC train: 0.791427	val: 0.645887	test: 0.627658

Epoch: 50
Loss: 0.4211076584178751
ROC train: 0.834232	val: 0.573226	test: 0.608355
PRC train: 0.793024	val: 0.647751	test: 0.630456

Epoch: 51
Loss: 0.41859469420821693
ROC train: 0.838321	val: 0.574535	test: 0.606096
PRC train: 0.795833	val: 0.647437	test: 0.630230

Epoch: 52
Loss: 0.4152564560711687
ROC train: 0.841497	val: 0.573409	test: 0.602013
PRC train: 0.797212	val: 0.646706	test: 0.629727

Epoch: 53
Loss: 0.41225302270732506
ROC train: 0.841516	val: 0.577012	test: 0.607861
PRC train: 0.799707	val: 0.649991	test: 0.629832

Epoch: 54
Loss: 0.4128707474966876
ROC train: 0.843004	val: 0.571108	test: 0.608933
PRC train: 0.800008	val: 0.645322	test: 0.630837

Epoch: 55
Loss: 0.41655077069489993
ROC train: 0.843954	val: 0.568578	test: 0.616972
PRC train: 0.801683	val: 0.643514	test: 0.635613

Epoch: 56
Loss: 0.4089265628224051
ROC train: 0.844334	val: 0.577559	test: 0.612793
PRC train: 0.800685	val: 0.647203	test: 0.630169

Epoch: 57
Loss: 0.40770722529033987
ROC train: 0.843741	val: 0.581515	test: 0.602026
PRC train: 0.801347	val: 0.652057	test: 0.624303

Epoch: 58
Loss: 0.40410205245945097
ROC train: 0.850182	val: 0.582080	test: 0.600763
PRC train: 0.805828	val: 0.653640	test: 0.624775

Epoch: 59
Loss: 0.4078011295697149
ROC train: 0.851428	val: 0.571564	test: 0.610144
PRC train: 0.806123	val: 0.645640	test: 0.632677

Epoch: 60
Loss: 0.4059303950658413
ROC train: 0.850269	val: 0.572477	test: 0.611282
PRC train: 0.808972	val: 0.646611	test: 0.633206

Epoch: 61
Loss: 0.40334160876531877
ROC train: 0.854817	val: 0.574154	test: 0.610240
PRC train: 0.813278	val: 0.649845	test: 0.636514

Epoch: 62
Loss: 0.4102152652854861
ROC train: 0.854455	val: 0.573507	test: 0.613230
PRC train: 0.812755	val: 0.648572	test: 0.637072

Epoch: 63
Loss: 0.40253418342919106
ROC train: 0.854062	val: 0.570036	test: 0.600880
PRC train: 0.811408	val: 0.643780	test: 0.626484

Epoch: 64
Loss: 0.4034550427010031
ROC train: 0.858356	val: 0.569471	test: 0.593584
PRC train: 0.815064	val: 0.641401	test: 0.620732

Epoch: 65
Loss: 0.4019584273148169
ROC train: 0.860804	val: 0.572567	test: 0.599374
PRC train: 0.817526	val: 0.643376	test: 0.622508

Epoch: 66
Loss: 0.398614497667957
ROC train: 0.864628	val: 0.577392	test: 0.600008
PRC train: 0.820190	val: 0.647594	test: 0.622408

Epoch: 67
Loss: 0.3944712496045465
ROC train: 0.863639	val: 0.582677	test: 0.607801
PRC train: 0.820100	val: 0.647967	test: 0.626789

Epoch: 68
Loss: 0.3936923755232787
ROC train: 0.864138	val: 0.578130	test: 0.605265
PRC train: 0.821969	val: 0.646068	test: 0.626824

Epoch: 69
Loss: 0.39665024233456286
ROC train: 0.865611	val: 0.579648	test: 0.608675
PRC train: 0.823678	val: 0.647471	test: 0.629047

Epoch: 70
Loss: 0.38727549694929586
ROC train: 0.869578	val: 0.582290	test: 0.612096
PRC train: 0.825563	val: 0.649490	test: 0.631580

Epoch: 71
Loss: 0.395798491767711
ROC train: 0.869777	val: 0.588073	test: 0.621481
PRC train: 0.825351	val: 0.654443	test: 0.636318

Epoch: 72
Loss: 0.3903111661607053
ROC train: 0.869095	val: 0.589335	test: 0.627237
PRC train: 0.824642	val: 0.654475	test: 0.639918

Epoch: 73
Loss: 0.39419469210327096
ROC train: 0.872174	val: 0.579806	test: 0.616041
PRC train: 0.827804	val: 0.649130	test: 0.634874

Epoch: 74
Loss: 0.3924426983820985
ROC train: 0.875170	val: 0.581305	test: 0.615833
PRC train: 0.830098	val: 0.648719	test: 0.630137

Epoch: 75
Loss: 0.3880308779822828
ROC train: 0.876367	val: 0.585002	test: 0.616924
PRC train: 0.830986	val: 0.651553	test: 0.630885

Epoch: 76
Loss: 0.3863717332849128
ROC train: 0.877990	val: 0.586013	test: 0.622947
PRC train: 0.834978	val: 0.653054	test: 0.638635

Epoch: 77
Loss: 0.38157217503012675
ROC train: 0.874838	val: 0.582295	test: 0.622137
PRC train: 0.832882	val: 0.654070	test: 0.639676

Epoch: 78
Loss: 0.38161609064037466
ROC train: 0.878131	val: 0.575969	test: 0.622370
PRC train: 0.836095	val: 0.651970	test: 0.639697

Epoch: 79
Loss: 0.3812282838702282
ROC train: 0.882456	val: 0.575313	test: 0.628220
PRC train: 0.839192	val: 0.648876	test: 0.639032

Epoch: 80
Loss: 0.3842204451194243
ROC train: 0.879556	val: 0.572687	test: 0.611845
PRC train: 0.835803	val: 0.644028	test: 0.630388

Epoch: 81
Loss: 0.38365956330300854
ROC train: 0.882731	val: 0.583778	test: 0.620299
PRC train: 0.839555	val: 0.648359	test: 0.635736

Epoch: 82
Loss: 0.3777382387225831
ROC train: 0.884152	val: 0.582413	test: 0.622513
PRC train: 0.841118	val: 0.651190	test: 0.636494

Epoch: 83
Loss: 0.37756458960959854
ROC train: 0.883607	val: 0.579631	test: 0.617932
PRC train: 0.839813	val: 0.650695	test: 0.636848

Epoch: 84
Loss: 0.3719522773159548
ROC train: 0.882752	val: 0.583390	test: 0.616632
PRC train: 0.838048	val: 0.651504	test: 0.636604

Epoch: 85
Loss: 0.3796089552572121
ROC train: 0.887115	val: 0.593865	test: 0.620940
PRC train: 0.844777	val: 0.655130	test: 0.636403

Epoch: 86
Loss: 0.37011104232317316
ROC train: 0.888657	val: 0.591598	test: 0.623803
PRC train: 0.848333	val: 0.652864	test: 0.636678

Epoch: 87
Loss: 0.373145251341773
ROC train: 0.890254	val: 0.582391	test: 0.612716
PRC train: 0.850300	val: 0.650801	test: 0.630941

Epoch: 88
Loss: 0.368608025967305
ROC train: 0.890777	val: 0.580089	test: 0.614540
PRC train: 0.851238	val: 0.648721	test: 0.630526

Epoch: 89
Loss: 0.3717893653507781
ROC train: 0.893468	val: 0.580788	test: 0.612496
PRC train: 0.852263	val: 0.647619	test: 0.630382

Epoch: 90
Loss: 0.3722732212745701
ROC train: 0.894144	val: 0.585766	test: 0.618264
PRC train: 0.853081	val: 0.650815	test: 0.633085

Epoch: 91
Loss: 0.36553910650186133
ROC train: 0.894571	val: 0.587921	test: 0.610658
PRC train: 0.853627	val: 0.653530	test: 0.631098

Epoch: 92
Loss: 0.37250434391369247
ROC train: 0.893942	val: 0.590183	test: 0.613269
PRC train: 0.852511	val: 0.653624	test: 0.629913

Epoch: 93
Loss: 0.36394021855861086
ROC train: 0.896947	val: 0.584000	test: 0.614967
PRC train: 0.856113	val: 0.651376	test: 0.634732

Epoch: 94
Loss: 0.36282123716157494
ROC train: 0.897540	val: 0.582040	test: 0.612039
ROC train: 0.788674	val: 0.563112	test: 0.617815
PRC train: 0.755422	val: 0.639259	test: 0.633295

Epoch: 34
Loss: 0.4453651117586098
ROC train: 0.792838	val: 0.572986	test: 0.612644
PRC train: 0.760988	val: 0.642165	test: 0.628387

Epoch: 35
Loss: 0.44288741787083324
ROC train: 0.802373	val: 0.563785	test: 0.610402
PRC train: 0.766633	val: 0.640650	test: 0.627795

Epoch: 36
Loss: 0.4416628141728898
ROC train: 0.804923	val: 0.562964	test: 0.617827
PRC train: 0.768789	val: 0.641451	test: 0.630911

Epoch: 37
Loss: 0.4393150139842339
ROC train: 0.807059	val: 0.559982	test: 0.617453
PRC train: 0.771617	val: 0.644456	test: 0.630960

Epoch: 38
Loss: 0.43886967111433534
ROC train: 0.810068	val: 0.551680	test: 0.612848
PRC train: 0.774026	val: 0.640593	test: 0.627945

Epoch: 39
Loss: 0.4359310915667524
ROC train: 0.808515	val: 0.546242	test: 0.617688
PRC train: 0.773814	val: 0.636490	test: 0.629412

Epoch: 40
Loss: 0.4415174352826087
ROC train: 0.814651	val: 0.566135	test: 0.625289
PRC train: 0.779164	val: 0.645822	test: 0.634952

Epoch: 41
Loss: 0.43433959924105825
ROC train: 0.815921	val: 0.571575	test: 0.623009
PRC train: 0.779452	val: 0.647526	test: 0.634768

Epoch: 42
Loss: 0.43265961111318973
ROC train: 0.816212	val: 0.563382	test: 0.613421
PRC train: 0.778889	val: 0.645242	test: 0.628892

Epoch: 43
Loss: 0.4340615226105756
ROC train: 0.817933	val: 0.561615	test: 0.613798
PRC train: 0.781507	val: 0.641166	test: 0.627931

Epoch: 44
Loss: 0.4254173191147591
ROC train: 0.819927	val: 0.561644	test: 0.611134
PRC train: 0.783625	val: 0.638869	test: 0.626061

Epoch: 45
Loss: 0.4321957848011193
ROC train: 0.823384	val: 0.566937	test: 0.614382
PRC train: 0.785540	val: 0.640441	test: 0.627175

Epoch: 46
Loss: 0.42717369177701225
ROC train: 0.823879	val: 0.575398	test: 0.613949
PRC train: 0.784459	val: 0.646280	test: 0.626090

Epoch: 47
Loss: 0.4236914081890195
ROC train: 0.828086	val: 0.570210	test: 0.616050
PRC train: 0.788064	val: 0.647134	test: 0.629600

Epoch: 48
Loss: 0.4275557023213057
ROC train: 0.828407	val: 0.563205	test: 0.617736
PRC train: 0.788642	val: 0.649968	test: 0.631896

Epoch: 49
Loss: 0.4243800459969493
ROC train: 0.831101	val: 0.558553	test: 0.623740
PRC train: 0.791368	val: 0.647601	test: 0.636297

Epoch: 50
Loss: 0.4202627653280626
ROC train: 0.830700	val: 0.552909	test: 0.624122
PRC train: 0.791487	val: 0.642073	test: 0.635535

Epoch: 51
Loss: 0.42304925014005407
ROC train: 0.837502	val: 0.558369	test: 0.615911
PRC train: 0.799699	val: 0.642304	test: 0.630131

Epoch: 52
Loss: 0.4182388682451318
ROC train: 0.837935	val: 0.566226	test: 0.611554
PRC train: 0.800148	val: 0.643319	test: 0.626394

Epoch: 53
Loss: 0.4176040870592241
ROC train: 0.840330	val: 0.572594	test: 0.612199
PRC train: 0.802608	val: 0.645917	test: 0.628832

Epoch: 54
Loss: 0.41375180754966084
ROC train: 0.842979	val: 0.565837	test: 0.619432
PRC train: 0.802872	val: 0.647514	test: 0.636755

Epoch: 55
Loss: 0.41707810527400374
ROC train: 0.843267	val: 0.558554	test: 0.618965
PRC train: 0.804065	val: 0.647158	test: 0.634006

Epoch: 56
Loss: 0.415686716603088
ROC train: 0.839987	val: 0.559834	test: 0.618654
PRC train: 0.803394	val: 0.649561	test: 0.633228

Epoch: 57
Loss: 0.40959997951452615
ROC train: 0.844495	val: 0.571960	test: 0.625624
PRC train: 0.806482	val: 0.650832	test: 0.635527

Epoch: 58
Loss: 0.4143936603302788
ROC train: 0.846883	val: 0.570409	test: 0.616884
PRC train: 0.808812	val: 0.649040	test: 0.631360

Epoch: 59
Loss: 0.4141289773814674
ROC train: 0.848755	val: 0.563357	test: 0.621425
PRC train: 0.808509	val: 0.648811	test: 0.634475

Epoch: 60
Loss: 0.4111448347653898
ROC train: 0.845347	val: 0.556631	test: 0.622329
PRC train: 0.805840	val: 0.643756	test: 0.634223

Epoch: 61
Loss: 0.40580069473114944
ROC train: 0.844964	val: 0.558277	test: 0.617761
PRC train: 0.807783	val: 0.643297	test: 0.630278

Epoch: 62
Loss: 0.4093569981395543
ROC train: 0.853556	val: 0.560317	test: 0.614840
PRC train: 0.814491	val: 0.642225	test: 0.630946

Epoch: 63
Loss: 0.4075651555600393
ROC train: 0.854913	val: 0.555260	test: 0.609534
PRC train: 0.814719	val: 0.639349	test: 0.627116

Epoch: 64
Loss: 0.4040593379027082
ROC train: 0.854660	val: 0.558947	test: 0.606850
PRC train: 0.815495	val: 0.641773	test: 0.625271

Epoch: 65
Loss: 0.4038363028897886
ROC train: 0.855102	val: 0.567706	test: 0.604208
PRC train: 0.815511	val: 0.646451	test: 0.624265

Epoch: 66
Loss: 0.40237287133144045
ROC train: 0.857323	val: 0.574292	test: 0.606702
PRC train: 0.816666	val: 0.647676	test: 0.629208

Epoch: 67
Loss: 0.4034629501275401
ROC train: 0.857866	val: 0.573509	test: 0.601862
PRC train: 0.817835	val: 0.649015	test: 0.626622

Epoch: 68
Loss: 0.3995053972098288
ROC train: 0.859698	val: 0.572564	test: 0.607139
PRC train: 0.820446	val: 0.645469	test: 0.628557

Epoch: 69
Loss: 0.400398615963161
ROC train: 0.860400	val: 0.565669	test: 0.609377
PRC train: 0.820130	val: 0.644582	test: 0.633199

Epoch: 70
Loss: 0.3973845112884721
ROC train: 0.865566	val: 0.576468	test: 0.612772
PRC train: 0.824792	val: 0.650229	test: 0.630915

Epoch: 71
Loss: 0.3954008890679727
ROC train: 0.868309	val: 0.567469	test: 0.606907
PRC train: 0.827551	val: 0.645560	test: 0.626151

Epoch: 72
Loss: 0.3913226864729398
ROC train: 0.868673	val: 0.560922	test: 0.605769
PRC train: 0.827999	val: 0.643704	test: 0.626176

Epoch: 73
Loss: 0.3994972299082923
ROC train: 0.868418	val: 0.570158	test: 0.613707
PRC train: 0.831061	val: 0.646866	test: 0.630470

Epoch: 74
Loss: 0.3900813012735129
ROC train: 0.872562	val: 0.561478	test: 0.619662
PRC train: 0.832144	val: 0.642783	test: 0.632719

Epoch: 75
Loss: 0.39430751103967887
ROC train: 0.873714	val: 0.563109	test: 0.616005
PRC train: 0.832900	val: 0.643321	test: 0.630233

Epoch: 76
Loss: 0.39065081260739903
ROC train: 0.874710	val: 0.569158	test: 0.619984
PRC train: 0.836632	val: 0.643239	test: 0.635320

Epoch: 77
Loss: 0.39467703768970774
ROC train: 0.875966	val: 0.570312	test: 0.624014
PRC train: 0.837257	val: 0.643011	test: 0.637577

Epoch: 78
Loss: 0.38477464699037284
ROC train: 0.876492	val: 0.558937	test: 0.621607
PRC train: 0.836920	val: 0.640710	test: 0.634826

Epoch: 79
Loss: 0.3838598952294912
ROC train: 0.879047	val: 0.560598	test: 0.618503
PRC train: 0.837871	val: 0.643260	test: 0.630749

Epoch: 80
Loss: 0.38446085998066437
ROC train: 0.880114	val: 0.571907	test: 0.618288
PRC train: 0.838962	val: 0.650923	test: 0.632978

Epoch: 81
Loss: 0.3838794396736991
ROC train: 0.882790	val: 0.567222	test: 0.618451
PRC train: 0.841366	val: 0.648966	test: 0.636079

Epoch: 82
Loss: 0.3792120400599307
ROC train: 0.881958	val: 0.559429	test: 0.618837
PRC train: 0.842228	val: 0.645179	test: 0.637385

Epoch: 83
Loss: 0.3785010046442304
ROC train: 0.883284	val: 0.570873	test: 0.619664
PRC train: 0.843215	val: 0.648246	test: 0.637138

Epoch: 84
Loss: 0.375934266050594
ROC train: 0.885278	val: 0.573279	test: 0.622514
PRC train: 0.846267	val: 0.650765	test: 0.636174

Epoch: 85
Loss: 0.3751154517878691
ROC train: 0.884498	val: 0.562371	test: 0.618559
PRC train: 0.845404	val: 0.647381	test: 0.633847

Epoch: 86
Loss: 0.38024362625619945
ROC train: 0.886976	val: 0.564504	test: 0.615487
PRC train: 0.845960	val: 0.645865	test: 0.630961

Epoch: 87
Loss: 0.37249672325160077
ROC train: 0.885738	val: 0.563677	test: 0.608298
PRC train: 0.844650	val: 0.643751	test: 0.629388

Epoch: 88
Loss: 0.3725806071372249
ROC train: 0.889011	val: 0.576169	test: 0.610498
PRC train: 0.849320	val: 0.652416	test: 0.633501

Epoch: 89
Loss: 0.3666873574141984
ROC train: 0.881920	val: 0.570502	test: 0.606148
PRC train: 0.841899	val: 0.645313	test: 0.630168

Epoch: 90
Loss: 0.37139422735332156
ROC train: 0.894585	val: 0.574915	test: 0.609898
PRC train: 0.855182	val: 0.645742	test: 0.629943

Epoch: 91
Loss: 0.3661163356169884
ROC train: 0.892953	val: 0.572838	test: 0.600864
PRC train: 0.851987	val: 0.642475	test: 0.626045

Epoch: 92
Loss: 0.3711586211385822
ROC train: 0.895872	val: 0.565845	test: 0.599261
PRC train: 0.854718	val: 0.642780	test: 0.624782

Epoch: 93
Loss: 0.3663613640625833
ROC train: 0.894903	val: 0.566346	test: 0.615640
PRC train: 0.852568	val: 0.645600	test: 0.631480

Epoch: 94
Loss: 0.3630542520109626
ROC train: 0.895263	val: 0.569034	test: 0.620593
ROC train: 0.795624	val: 0.576239	test: 0.629579
PRC train: 0.762265	val: 0.646046	test: 0.644794

Epoch: 34
Loss: 0.44793371305040725
ROC train: 0.799202	val: 0.561221	test: 0.625310
PRC train: 0.761523	val: 0.639323	test: 0.646032

Epoch: 35
Loss: 0.4435388859992752
ROC train: 0.799618	val: 0.560333	test: 0.626256
PRC train: 0.763238	val: 0.643062	test: 0.646731

Epoch: 36
Loss: 0.44388716832354735
ROC train: 0.801103	val: 0.576821	test: 0.629512
PRC train: 0.766754	val: 0.649336	test: 0.647829

Epoch: 37
Loss: 0.44416944692513516
ROC train: 0.806544	val: 0.587009	test: 0.615014
PRC train: 0.773091	val: 0.657895	test: 0.641556

Epoch: 38
Loss: 0.4371199569312821
ROC train: 0.807236	val: 0.585979	test: 0.606350
PRC train: 0.771905	val: 0.658786	test: 0.634401

Epoch: 39
Loss: 0.43829366826011373
ROC train: 0.808512	val: 0.577461	test: 0.608800
PRC train: 0.773295	val: 0.653869	test: 0.635986

Epoch: 40
Loss: 0.4374763278687371
ROC train: 0.811747	val: 0.571235	test: 0.615229
PRC train: 0.775486	val: 0.653697	test: 0.640314

Epoch: 41
Loss: 0.4308294681396418
ROC train: 0.814565	val: 0.577146	test: 0.612320
PRC train: 0.776558	val: 0.659314	test: 0.643768

Epoch: 42
Loss: 0.43232723037159726
ROC train: 0.820551	val: 0.574084	test: 0.614490
PRC train: 0.782666	val: 0.651642	test: 0.643056

Epoch: 43
Loss: 0.433402132256618
ROC train: 0.821411	val: 0.568927	test: 0.624928
PRC train: 0.782497	val: 0.645051	test: 0.648357

Epoch: 44
Loss: 0.43504399856257714
ROC train: 0.824128	val: 0.570187	test: 0.631066
PRC train: 0.784793	val: 0.648355	test: 0.650985

Epoch: 45
Loss: 0.426785963726883
ROC train: 0.826380	val: 0.579340	test: 0.630496
PRC train: 0.786982	val: 0.656328	test: 0.646273

Epoch: 46
Loss: 0.4293983346821724
ROC train: 0.825368	val: 0.585339	test: 0.624098
PRC train: 0.786445	val: 0.657970	test: 0.641313

Epoch: 47
Loss: 0.4243336318936364
ROC train: 0.833334	val: 0.582681	test: 0.631137
PRC train: 0.793161	val: 0.656815	test: 0.649104

Epoch: 48
Loss: 0.4295418654080646
ROC train: 0.833879	val: 0.573562	test: 0.634358
PRC train: 0.793048	val: 0.648068	test: 0.651709

Epoch: 49
Loss: 0.42235542649280633
ROC train: 0.833688	val: 0.571186	test: 0.629662
PRC train: 0.790517	val: 0.652709	test: 0.646857

Epoch: 50
Loss: 0.42099316226563815
ROC train: 0.835319	val: 0.571457	test: 0.625494
PRC train: 0.791538	val: 0.655864	test: 0.645664

Epoch: 51
Loss: 0.4264662241814046
ROC train: 0.838177	val: 0.576406	test: 0.630637
PRC train: 0.797773	val: 0.654888	test: 0.648422

Epoch: 52
Loss: 0.4209333955793104
ROC train: 0.840502	val: 0.578851	test: 0.625826
PRC train: 0.801236	val: 0.651484	test: 0.645650

Epoch: 53
Loss: 0.4164743983876086
ROC train: 0.842252	val: 0.569689	test: 0.614424
PRC train: 0.801187	val: 0.653122	test: 0.639107

Epoch: 54
Loss: 0.41632506108721423
ROC train: 0.840401	val: 0.576811	test: 0.619312
PRC train: 0.798779	val: 0.660174	test: 0.641795

Epoch: 55
Loss: 0.4179823091376603
ROC train: 0.843239	val: 0.577190	test: 0.634218
PRC train: 0.802518	val: 0.658053	test: 0.649509

Epoch: 56
Loss: 0.41178056211642283
ROC train: 0.842025	val: 0.572319	test: 0.636231
PRC train: 0.800760	val: 0.651442	test: 0.649040

Epoch: 57
Loss: 0.41313676729142795
ROC train: 0.845619	val: 0.564652	test: 0.634106
PRC train: 0.803051	val: 0.650659	test: 0.649079

Epoch: 58
Loss: 0.4084342837701046
ROC train: 0.849382	val: 0.566020	test: 0.625303
PRC train: 0.806625	val: 0.651082	test: 0.645788

Epoch: 59
Loss: 0.4075844979554344
ROC train: 0.850541	val: 0.576167	test: 0.627660
PRC train: 0.808450	val: 0.653412	test: 0.644443

Epoch: 60
Loss: 0.4086111072737076
ROC train: 0.845599	val: 0.575141	test: 0.622812
PRC train: 0.803641	val: 0.650223	test: 0.639726

Epoch: 61
Loss: 0.40649699274271484
ROC train: 0.852080	val: 0.574949	test: 0.633655
PRC train: 0.810054	val: 0.652564	test: 0.645807

Epoch: 62
Loss: 0.40333670961301105
ROC train: 0.856727	val: 0.569175	test: 0.640611
PRC train: 0.814223	val: 0.657298	test: 0.652824

Epoch: 63
Loss: 0.4034135390193449
ROC train: 0.860603	val: 0.571843	test: 0.636830
PRC train: 0.818094	val: 0.659160	test: 0.654397

Epoch: 64
Loss: 0.40042220889603974
ROC train: 0.860997	val: 0.582933	test: 0.637381
PRC train: 0.818900	val: 0.659689	test: 0.653941

Epoch: 65
Loss: 0.3991269868854479
ROC train: 0.862151	val: 0.580743	test: 0.640335
PRC train: 0.817890	val: 0.657562	test: 0.653475

Epoch: 66
Loss: 0.4016503760176659
ROC train: 0.861274	val: 0.573384	test: 0.634642
PRC train: 0.815136	val: 0.652549	test: 0.651465

Epoch: 67
Loss: 0.40057837175298294
ROC train: 0.862781	val: 0.571814	test: 0.633060
PRC train: 0.815785	val: 0.650138	test: 0.649323

Epoch: 68
Loss: 0.40115162047804354
ROC train: 0.864330	val: 0.579528	test: 0.639538
PRC train: 0.819405	val: 0.653501	test: 0.651166

Epoch: 69
Loss: 0.39497184864154083
ROC train: 0.867681	val: 0.573979	test: 0.646116
PRC train: 0.823997	val: 0.656019	test: 0.655309

Epoch: 70
Loss: 0.39425853189809223
ROC train: 0.868599	val: 0.573431	test: 0.642589
PRC train: 0.825596	val: 0.659743	test: 0.653038

Epoch: 71
Loss: 0.39377003340094635
ROC train: 0.871419	val: 0.574842	test: 0.637947
PRC train: 0.827286	val: 0.660260	test: 0.650752

Epoch: 72
Loss: 0.39215923534984976
ROC train: 0.869025	val: 0.585958	test: 0.634766
PRC train: 0.824684	val: 0.661514	test: 0.650442

Epoch: 73
Loss: 0.38387315943594824
ROC train: 0.870355	val: 0.585549	test: 0.635139
PRC train: 0.826444	val: 0.661212	test: 0.652031

Epoch: 74
Loss: 0.39027212271150635
ROC train: 0.874641	val: 0.577267	test: 0.632092
PRC train: 0.831436	val: 0.658881	test: 0.651071

Epoch: 75
Loss: 0.38640118663715184
ROC train: 0.873654	val: 0.570008	test: 0.628088
PRC train: 0.829546	val: 0.651709	test: 0.646797

Epoch: 76
Loss: 0.38441372318053246
ROC train: 0.880176	val: 0.574403	test: 0.632904
PRC train: 0.836039	val: 0.657628	test: 0.647796

Epoch: 77
Loss: 0.3841792206127033
ROC train: 0.875637	val: 0.585059	test: 0.633499
PRC train: 0.834685	val: 0.659068	test: 0.648724

Epoch: 78
Loss: 0.38678360343861906
ROC train: 0.874877	val: 0.590106	test: 0.637153
PRC train: 0.834539	val: 0.659132	test: 0.653824

Epoch: 79
Loss: 0.3811030494270552
ROC train: 0.881730	val: 0.585676	test: 0.638003
PRC train: 0.839012	val: 0.658259	test: 0.649457

Epoch: 80
Loss: 0.38244950256112853
ROC train: 0.880319	val: 0.577463	test: 0.625086
PRC train: 0.837104	val: 0.654407	test: 0.641344

Epoch: 81
Loss: 0.38114842864094445
ROC train: 0.884555	val: 0.578203	test: 0.626952
PRC train: 0.842323	val: 0.653629	test: 0.643347

Epoch: 82
Loss: 0.38409718817240934
ROC train: 0.883580	val: 0.577975	test: 0.629677
PRC train: 0.843506	val: 0.652481	test: 0.642660

Epoch: 83
Loss: 0.3755992282975564
ROC train: 0.886032	val: 0.574790	test: 0.628524
PRC train: 0.845739	val: 0.654472	test: 0.644284

Epoch: 84
Loss: 0.3777887912226385
ROC train: 0.885782	val: 0.578075	test: 0.629089
PRC train: 0.844396	val: 0.655822	test: 0.646039

Epoch: 85
Loss: 0.3791861241183053
ROC train: 0.887518	val: 0.583288	test: 0.631976
PRC train: 0.847345	val: 0.659285	test: 0.647714

Epoch: 86
Loss: 0.37735388269619863
ROC train: 0.884334	val: 0.582791	test: 0.631230
PRC train: 0.845498	val: 0.654259	test: 0.646687

Epoch: 87
Loss: 0.3767882196247032
ROC train: 0.887521	val: 0.569790	test: 0.622863
PRC train: 0.847558	val: 0.649106	test: 0.644234

Epoch: 88
Loss: 0.3704148992268895
ROC train: 0.893210	val: 0.571793	test: 0.629859
PRC train: 0.853028	val: 0.651374	test: 0.649162

Epoch: 89
Loss: 0.37113561518490623
ROC train: 0.892668	val: 0.571864	test: 0.629447
PRC train: 0.851098	val: 0.653506	test: 0.646806

Epoch: 90
Loss: 0.36793061920526554
ROC train: 0.893236	val: 0.571141	test: 0.624137
PRC train: 0.851361	val: 0.653874	test: 0.645836

Epoch: 91
Loss: 0.36737111742837597
ROC train: 0.896167	val: 0.570368	test: 0.620738
PRC train: 0.855643	val: 0.652399	test: 0.644320

Epoch: 92
Loss: 0.36346044040594316
ROC train: 0.896728	val: 0.575463	test: 0.627948
PRC train: 0.860327	val: 0.653291	test: 0.644103

Epoch: 93
Loss: 0.37260677756263477
ROC train: 0.898697	val: 0.574854	test: 0.625604
PRC train: 0.861218	val: 0.653929	test: 0.644695

Epoch: 94
Loss: 0.3677499349651697ROC train: 0.786979	val: 0.619465	test: 0.610460
PRC train: 0.752868	val: 0.661057	test: 0.630452

Epoch: 34
Loss: 0.4464634824589667
ROC train: 0.787711	val: 0.619525	test: 0.611839
PRC train: 0.754012	val: 0.662964	test: 0.632696

Epoch: 35
Loss: 0.448890822825883
ROC train: 0.794826	val: 0.631727	test: 0.603799
PRC train: 0.762015	val: 0.671535	test: 0.630783

Epoch: 36
Loss: 0.44392480055130684
ROC train: 0.797806	val: 0.638114	test: 0.600564
PRC train: 0.764051	val: 0.675678	test: 0.630009

Epoch: 37
Loss: 0.44225724458028476
ROC train: 0.802547	val: 0.628090	test: 0.606004
PRC train: 0.767406	val: 0.669882	test: 0.631379

Epoch: 38
Loss: 0.4398723799836812
ROC train: 0.801496	val: 0.618636	test: 0.605482
PRC train: 0.764345	val: 0.667136	test: 0.632908

Epoch: 39
Loss: 0.4410565515707936
ROC train: 0.803573	val: 0.621916	test: 0.604358
PRC train: 0.765349	val: 0.669288	test: 0.633948

Epoch: 40
Loss: 0.4353341233359469
ROC train: 0.805591	val: 0.622715	test: 0.600740
PRC train: 0.768505	val: 0.667439	test: 0.631552

Epoch: 41
Loss: 0.4326196498525118
ROC train: 0.809692	val: 0.623773	test: 0.605145
PRC train: 0.772276	val: 0.669659	test: 0.629219

Epoch: 42
Loss: 0.437130967924433
ROC train: 0.811698	val: 0.628130	test: 0.606137
PRC train: 0.773577	val: 0.672017	test: 0.632444

Epoch: 43
Loss: 0.4398234516007321
ROC train: 0.810472	val: 0.616555	test: 0.610194
PRC train: 0.772665	val: 0.666666	test: 0.632848

Epoch: 44
Loss: 0.4341210226140588
ROC train: 0.810138	val: 0.617602	test: 0.604129
PRC train: 0.771213	val: 0.667047	test: 0.629992

Epoch: 45
Loss: 0.4298040695401137
ROC train: 0.816971	val: 0.615897	test: 0.615980
PRC train: 0.780241	val: 0.666078	test: 0.632777

Epoch: 46
Loss: 0.4327308116732941
ROC train: 0.816980	val: 0.613381	test: 0.612848
PRC train: 0.779466	val: 0.665768	test: 0.629697

Epoch: 47
Loss: 0.431646081703532
ROC train: 0.821641	val: 0.629789	test: 0.597985
PRC train: 0.783467	val: 0.674525	test: 0.625829

Epoch: 48
Loss: 0.4203070741696847
ROC train: 0.826324	val: 0.614608	test: 0.597464
PRC train: 0.788195	val: 0.667769	test: 0.630599

Epoch: 49
Loss: 0.42569719259635247
ROC train: 0.818699	val: 0.599067	test: 0.598535
PRC train: 0.784804	val: 0.662584	test: 0.632061

Epoch: 50
Loss: 0.41988614380169575
ROC train: 0.827900	val: 0.607213	test: 0.596846
PRC train: 0.789042	val: 0.668513	test: 0.627730

Epoch: 51
Loss: 0.4174210909433274
ROC train: 0.827479	val: 0.608047	test: 0.600242
PRC train: 0.789571	val: 0.664484	test: 0.627650

Epoch: 52
Loss: 0.41960281129523747
ROC train: 0.826462	val: 0.607953	test: 0.602300
PRC train: 0.790185	val: 0.663240	test: 0.628817

Epoch: 53
Loss: 0.4137002205774959
ROC train: 0.830172	val: 0.611387	test: 0.601303
PRC train: 0.792069	val: 0.665789	test: 0.626852

Epoch: 54
Loss: 0.4143835562995493
ROC train: 0.835045	val: 0.631762	test: 0.600773
PRC train: 0.795124	val: 0.674583	test: 0.629525

Epoch: 55
Loss: 0.4177151809295435
ROC train: 0.835575	val: 0.628455	test: 0.599630
PRC train: 0.796800	val: 0.671495	test: 0.633505

Epoch: 56
Loss: 0.4097256854488087
ROC train: 0.838658	val: 0.625534	test: 0.588301
PRC train: 0.800446	val: 0.672432	test: 0.627332

Epoch: 57
Loss: 0.4134961184470239
ROC train: 0.841186	val: 0.645917	test: 0.582359
PRC train: 0.801547	val: 0.682994	test: 0.627240

Epoch: 58
Loss: 0.4132040628485371
ROC train: 0.841469	val: 0.642697	test: 0.596821
PRC train: 0.803548	val: 0.678883	test: 0.629921

Epoch: 59
Loss: 0.41228035341252334
ROC train: 0.843255	val: 0.633342	test: 0.585690
PRC train: 0.802762	val: 0.675331	test: 0.623529

Epoch: 60
Loss: 0.4087263771650047
ROC train: 0.846113	val: 0.635453	test: 0.591757
PRC train: 0.804276	val: 0.677638	test: 0.625701

Epoch: 61
Loss: 0.40885448688783715
ROC train: 0.848210	val: 0.631183	test: 0.592623
PRC train: 0.807296	val: 0.674239	test: 0.623799

Epoch: 62
Loss: 0.40907534558887937
ROC train: 0.851507	val: 0.638641	test: 0.592672
PRC train: 0.810062	val: 0.678853	test: 0.623183

Epoch: 63
Loss: 0.4080802973244991
ROC train: 0.853110	val: 0.630222	test: 0.589003
PRC train: 0.811525	val: 0.676544	test: 0.621487

Epoch: 64
Loss: 0.4077091891637217
ROC train: 0.852306	val: 0.634716	test: 0.586045
PRC train: 0.811569	val: 0.677828	test: 0.621828

Epoch: 65
Loss: 0.3992515723453008
ROC train: 0.853558	val: 0.631175	test: 0.595428
PRC train: 0.814432	val: 0.677069	test: 0.629043

Epoch: 66
Loss: 0.40369407442523153
ROC train: 0.851822	val: 0.620320	test: 0.598778
PRC train: 0.813273	val: 0.667682	test: 0.631403

Epoch: 67
Loss: 0.3998551877201114
ROC train: 0.857484	val: 0.619818	test: 0.604784
PRC train: 0.817314	val: 0.672737	test: 0.633674

Epoch: 68
Loss: 0.39929090233262243
ROC train: 0.858819	val: 0.615618	test: 0.598625
PRC train: 0.818189	val: 0.674606	test: 0.631208

Epoch: 69
Loss: 0.3954803672512281
ROC train: 0.859325	val: 0.630461	test: 0.596407
PRC train: 0.819918	val: 0.675540	test: 0.622723

Epoch: 70
Loss: 0.3932360947116744
ROC train: 0.863238	val: 0.635392	test: 0.591587
PRC train: 0.821028	val: 0.679076	test: 0.624698

Epoch: 71
Loss: 0.39626171369864205
ROC train: 0.862732	val: 0.633645	test: 0.583156
PRC train: 0.820087	val: 0.675149	test: 0.624065

Epoch: 72
Loss: 0.3931072895141271
ROC train: 0.860237	val: 0.626594	test: 0.589639
PRC train: 0.821532	val: 0.674535	test: 0.625014

Epoch: 73
Loss: 0.3899268840616782
ROC train: 0.864513	val: 0.624907	test: 0.594954
PRC train: 0.825867	val: 0.672408	test: 0.633038

Epoch: 74
Loss: 0.3916819640146717
ROC train: 0.869211	val: 0.636527	test: 0.603512
PRC train: 0.828279	val: 0.676591	test: 0.632220

Epoch: 75
Loss: 0.3880245868110952
ROC train: 0.866485	val: 0.632905	test: 0.611599
PRC train: 0.827228	val: 0.675081	test: 0.636705

Epoch: 76
Loss: 0.39125486028012013
ROC train: 0.867357	val: 0.630748	test: 0.601599
PRC train: 0.826501	val: 0.679575	test: 0.629664

Epoch: 77
Loss: 0.38552187998376575
ROC train: 0.869180	val: 0.620832	test: 0.597432
PRC train: 0.827131	val: 0.676423	test: 0.633571

Epoch: 78
Loss: 0.38283171516083625
ROC train: 0.870909	val: 0.616260	test: 0.601467
PRC train: 0.831554	val: 0.669682	test: 0.634075

Epoch: 79
Loss: 0.38589846184641985
ROC train: 0.872705	val: 0.629545	test: 0.595994
PRC train: 0.833084	val: 0.674630	test: 0.632213

Epoch: 80
Loss: 0.3850943936002437
ROC train: 0.870210	val: 0.628690	test: 0.602095
PRC train: 0.829696	val: 0.671198	test: 0.631354

Epoch: 81
Loss: 0.38757113386868014
ROC train: 0.874935	val: 0.631607	test: 0.604720
PRC train: 0.834569	val: 0.675713	test: 0.634814

Epoch: 82
Loss: 0.3835766451898779
ROC train: 0.874004	val: 0.621014	test: 0.596329
PRC train: 0.833663	val: 0.669198	test: 0.626152

Epoch: 83
Loss: 0.3798466585579755
ROC train: 0.876501	val: 0.623938	test: 0.598625
PRC train: 0.836964	val: 0.671470	test: 0.626228

Epoch: 84
Loss: 0.3792054438202115
ROC train: 0.881321	val: 0.634032	test: 0.587083
PRC train: 0.838741	val: 0.677430	test: 0.624689

Epoch: 85
Loss: 0.37395006724506746
ROC train: 0.883871	val: 0.632251	test: 0.591058
PRC train: 0.843135	val: 0.674153	test: 0.626677

Epoch: 86
Loss: 0.3765133498041232
ROC train: 0.881562	val: 0.626954	test: 0.598386
PRC train: 0.842210	val: 0.670091	test: 0.632439

Epoch: 87
Loss: 0.3791272020516947
ROC train: 0.881727	val: 0.630889	test: 0.595132
PRC train: 0.840801	val: 0.673740	test: 0.629799

Epoch: 88
Loss: 0.3716227329649734
ROC train: 0.888469	val: 0.638454	test: 0.584966
PRC train: 0.848413	val: 0.677047	test: 0.622943

Epoch: 89
Loss: 0.37086975857686755
ROC train: 0.886976	val: 0.628256	test: 0.582739
PRC train: 0.847516	val: 0.674023	test: 0.619712

Epoch: 90
Loss: 0.3772996962096401
ROC train: 0.883009	val: 0.612590	test: 0.601905
PRC train: 0.844247	val: 0.666868	test: 0.626255

Epoch: 91
Loss: 0.3710628074794727
ROC train: 0.889474	val: 0.630088	test: 0.591383
PRC train: 0.849678	val: 0.669015	test: 0.625057

Epoch: 92
Loss: 0.37322076576804897
ROC train: 0.889413	val: 0.626645	test: 0.586509
PRC train: 0.850545	val: 0.671645	test: 0.622232

Epoch: 93
Loss: 0.37358245498930576
ROC train: 0.890486	val: 0.624787	test: 0.579358
PRC train: 0.853792	val: 0.669377	test: 0.619347

Epoch: 94
Loss: 0.36670999363431533
ROC train: 0.893381	val: 0.627269	test: 0.578675
ROC train: 0.796345	val: 0.619882	test: 0.594141
PRC train: 0.767797	val: 0.662223	test: 0.628831

Epoch: 34
Loss: 0.44550188012164416
ROC train: 0.799141	val: 0.621321	test: 0.593509
PRC train: 0.769897	val: 0.663874	test: 0.630270

Epoch: 35
Loss: 0.4440145684457512
ROC train: 0.796410	val: 0.612162	test: 0.605700
PRC train: 0.766444	val: 0.663596	test: 0.637245

Epoch: 36
Loss: 0.43822018329103374
ROC train: 0.794891	val: 0.604795	test: 0.609758
PRC train: 0.768287	val: 0.660360	test: 0.639474

Epoch: 37
Loss: 0.4411715982404923
ROC train: 0.798323	val: 0.607070	test: 0.603915
PRC train: 0.769619	val: 0.659040	test: 0.637802

Epoch: 38
Loss: 0.4430543699208188
ROC train: 0.803939	val: 0.611795	test: 0.610358
PRC train: 0.772728	val: 0.662473	test: 0.638898

Epoch: 39
Loss: 0.4365767737495959
ROC train: 0.809584	val: 0.614223	test: 0.604270
PRC train: 0.779153	val: 0.662721	test: 0.636217

Epoch: 40
Loss: 0.43796655001178514
ROC train: 0.811910	val: 0.614496	test: 0.603593
PRC train: 0.777598	val: 0.664628	test: 0.634117

Epoch: 41
Loss: 0.428782724807763
ROC train: 0.815810	val: 0.601479	test: 0.602951
PRC train: 0.781873	val: 0.658595	test: 0.635660

Epoch: 42
Loss: 0.42727670753594904
ROC train: 0.814228	val: 0.593780	test: 0.607672
PRC train: 0.783284	val: 0.654462	test: 0.639630

Epoch: 43
Loss: 0.43106731447121066
ROC train: 0.816839	val: 0.612684	test: 0.597847
PRC train: 0.784313	val: 0.660643	test: 0.635829

Epoch: 44
Loss: 0.4323257144340197
ROC train: 0.818332	val: 0.617361	test: 0.605975
PRC train: 0.784975	val: 0.665996	test: 0.641087

Epoch: 45
Loss: 0.42435246301942636
ROC train: 0.816815	val: 0.599772	test: 0.615842
PRC train: 0.784325	val: 0.657675	test: 0.644422

Epoch: 46
Loss: 0.4257894612960972
ROC train: 0.824453	val: 0.607719	test: 0.614824
PRC train: 0.789232	val: 0.658544	test: 0.643059

Epoch: 47
Loss: 0.425772684737984
ROC train: 0.828703	val: 0.619631	test: 0.613229
PRC train: 0.794073	val: 0.666157	test: 0.643249

Epoch: 48
Loss: 0.42607572381859093
ROC train: 0.830632	val: 0.609716	test: 0.609741
PRC train: 0.796174	val: 0.663634	test: 0.638793

Epoch: 49
Loss: 0.4184155957004892
ROC train: 0.834089	val: 0.620507	test: 0.602968
PRC train: 0.798469	val: 0.664804	test: 0.633162

Epoch: 50
Loss: 0.4212693425122412
ROC train: 0.834062	val: 0.629167	test: 0.600375
PRC train: 0.797252	val: 0.664715	test: 0.634180

Epoch: 51
Loss: 0.4223950413320935
ROC train: 0.826477	val: 0.620619	test: 0.609349
PRC train: 0.792246	val: 0.664474	test: 0.641374

Epoch: 52
Loss: 0.4178278882168362
ROC train: 0.835625	val: 0.623980	test: 0.600732
PRC train: 0.799562	val: 0.669321	test: 0.635133

Epoch: 53
Loss: 0.4201344846173514
ROC train: 0.840249	val: 0.625132	test: 0.594830
PRC train: 0.805033	val: 0.671626	test: 0.630073

Epoch: 54
Loss: 0.4189644283416872
ROC train: 0.840236	val: 0.616900	test: 0.592804
PRC train: 0.805631	val: 0.666496	test: 0.624961

Epoch: 55
Loss: 0.4177271166890956
ROC train: 0.837050	val: 0.613093	test: 0.593340
PRC train: 0.799937	val: 0.662977	test: 0.626539

Epoch: 56
Loss: 0.4118953212091225
ROC train: 0.840298	val: 0.614968	test: 0.601506
PRC train: 0.802875	val: 0.666059	test: 0.632886

Epoch: 57
Loss: 0.41219193583050434
ROC train: 0.845780	val: 0.629346	test: 0.607802
PRC train: 0.806715	val: 0.671748	test: 0.634441

Epoch: 58
Loss: 0.41263347130426203
ROC train: 0.847788	val: 0.629574	test: 0.596806
PRC train: 0.806518	val: 0.674055	test: 0.627281

Epoch: 59
Loss: 0.408416350153498
ROC train: 0.848857	val: 0.617749	test: 0.598903
PRC train: 0.811866	val: 0.667542	test: 0.630243

Epoch: 60
Loss: 0.41081601295055004
ROC train: 0.848822	val: 0.610350	test: 0.602323
PRC train: 0.810654	val: 0.661033	test: 0.632383

Epoch: 61
Loss: 0.41085218882423324
ROC train: 0.849042	val: 0.615404	test: 0.601618
PRC train: 0.809036	val: 0.668298	test: 0.633957

Epoch: 62
Loss: 0.40811074706643885
ROC train: 0.855591	val: 0.630957	test: 0.604031
PRC train: 0.816366	val: 0.674212	test: 0.634856

Epoch: 63
Loss: 0.40447866311285036
ROC train: 0.854604	val: 0.625243	test: 0.605014
PRC train: 0.816200	val: 0.667565	test: 0.638183

Epoch: 64
Loss: 0.40490422501327156
ROC train: 0.854781	val: 0.622342	test: 0.606231
PRC train: 0.814523	val: 0.666717	test: 0.635982

Epoch: 65
Loss: 0.3988548873969478
ROC train: 0.860871	val: 0.630781	test: 0.595528
PRC train: 0.821119	val: 0.671072	test: 0.632071

Epoch: 66
Loss: 0.4067030227055972
ROC train: 0.861333	val: 0.632288	test: 0.601007
PRC train: 0.821715	val: 0.671507	test: 0.636382

Epoch: 67
Loss: 0.40042764815436926
ROC train: 0.862026	val: 0.622460	test: 0.596305
PRC train: 0.821710	val: 0.669842	test: 0.629777

Epoch: 68
Loss: 0.3943279274682662
ROC train: 0.863688	val: 0.624316	test: 0.576459
PRC train: 0.822282	val: 0.674044	test: 0.622780

Epoch: 69
Loss: 0.40018196496466346
ROC train: 0.865200	val: 0.619300	test: 0.590828
PRC train: 0.824133	val: 0.668881	test: 0.628794

Epoch: 70
Loss: 0.3996133865349041
ROC train: 0.863075	val: 0.614532	test: 0.601464
PRC train: 0.821037	val: 0.665135	test: 0.633449

Epoch: 71
Loss: 0.3895191531053249
ROC train: 0.870367	val: 0.625363	test: 0.592565
PRC train: 0.830303	val: 0.670184	test: 0.629294

Epoch: 72
Loss: 0.39382656391355353
ROC train: 0.870443	val: 0.628801	test: 0.575485
PRC train: 0.829150	val: 0.668859	test: 0.624025

Epoch: 73
Loss: 0.38915475839008806
ROC train: 0.869951	val: 0.616416	test: 0.600145
PRC train: 0.829577	val: 0.661401	test: 0.632589

Epoch: 74
Loss: 0.38388857509216673
ROC train: 0.869408	val: 0.620525	test: 0.604069
PRC train: 0.831539	val: 0.665721	test: 0.635105

Epoch: 75
Loss: 0.38833509954374756
ROC train: 0.871787	val: 0.634433	test: 0.590374
PRC train: 0.834909	val: 0.678382	test: 0.624924

Epoch: 76
Loss: 0.3884986010322701
ROC train: 0.871543	val: 0.631737	test: 0.595983
PRC train: 0.834940	val: 0.675120	test: 0.628394

Epoch: 77
Loss: 0.3891293147177013
ROC train: 0.873902	val: 0.618976	test: 0.605752
PRC train: 0.836281	val: 0.667124	test: 0.634233

Epoch: 78
Loss: 0.3854136062299425
ROC train: 0.877412	val: 0.622945	test: 0.592394
PRC train: 0.839532	val: 0.668691	test: 0.631414

Epoch: 79
Loss: 0.3892813451640572
ROC train: 0.877994	val: 0.628612	test: 0.581200
PRC train: 0.843310	val: 0.668026	test: 0.629974

Epoch: 80
Loss: 0.38678418066360554
ROC train: 0.882643	val: 0.635375	test: 0.591471
PRC train: 0.848044	val: 0.670649	test: 0.630693

Epoch: 81
Loss: 0.38054380957601747
ROC train: 0.883923	val: 0.628488	test: 0.595321
PRC train: 0.847338	val: 0.671465	test: 0.632702

Epoch: 82
Loss: 0.38235540878076235
ROC train: 0.884002	val: 0.620993	test: 0.600516
PRC train: 0.846523	val: 0.669007	test: 0.635399

Epoch: 83
Loss: 0.3756933306482598
ROC train: 0.886106	val: 0.630806	test: 0.591265
PRC train: 0.845580	val: 0.669901	test: 0.630584

Epoch: 84
Loss: 0.3752672318103392
ROC train: 0.889245	val: 0.633187	test: 0.595275
PRC train: 0.850373	val: 0.673858	test: 0.632269

Epoch: 85
Loss: 0.37678248898990785
ROC train: 0.882692	val: 0.631701	test: 0.595983
PRC train: 0.844652	val: 0.674765	test: 0.631263

Epoch: 86
Loss: 0.3697412361021208
ROC train: 0.888604	val: 0.635865	test: 0.595677
PRC train: 0.850854	val: 0.673102	test: 0.631387

Epoch: 87
Loss: 0.3736730536367562
ROC train: 0.888644	val: 0.627993	test: 0.591967
PRC train: 0.850381	val: 0.672870	test: 0.630153

Epoch: 88
Loss: 0.37314922984920235
ROC train: 0.889170	val: 0.622746	test: 0.590346
PRC train: 0.851726	val: 0.671901	test: 0.630126

Epoch: 89
Loss: 0.37066128256543696
ROC train: 0.885625	val: 0.620372	test: 0.605179
PRC train: 0.847702	val: 0.667518	test: 0.638539

Epoch: 90
Loss: 0.37105480831876186
ROC train: 0.890315	val: 0.632317	test: 0.583515
PRC train: 0.850875	val: 0.671795	test: 0.627661

Epoch: 91
Loss: 0.36521423201841985
ROC train: 0.895498	val: 0.644958	test: 0.582797
PRC train: 0.859096	val: 0.681880	test: 0.624168

Epoch: 92
Loss: 0.37260296700672607
ROC train: 0.895835	val: 0.643197	test: 0.594328
PRC train: 0.860213	val: 0.682011	test: 0.628637

Epoch: 93
Loss: 0.36607643348052343
ROC train: 0.897343	val: 0.639216	test: 0.595839
PRC train: 0.861623	val: 0.677338	test: 0.634308

Epoch: 94
Loss: 0.3631071048440643
ROC train: 0.798460	val: 0.624013	test: 0.609668
PRC train: 0.766033	val: 0.670378	test: 0.632404

Epoch: 34
Loss: 0.4470633832165462
ROC train: 0.801948	val: 0.623153	test: 0.614471
PRC train: 0.768636	val: 0.668096	test: 0.628610

Epoch: 35
Loss: 0.4440920260880783
ROC train: 0.804752	val: 0.619142	test: 0.618019
PRC train: 0.771875	val: 0.662195	test: 0.631115

Epoch: 36
Loss: 0.4439264280163301
ROC train: 0.803794	val: 0.616588	test: 0.616691
PRC train: 0.769981	val: 0.659761	test: 0.632392

Epoch: 37
Loss: 0.4354547436258701
ROC train: 0.808985	val: 0.617373	test: 0.611772
PRC train: 0.775085	val: 0.659537	test: 0.633192

Epoch: 38
Loss: 0.43621971587003916
ROC train: 0.808485	val: 0.613602	test: 0.608515
PRC train: 0.774312	val: 0.659598	test: 0.628832

Epoch: 39
Loss: 0.4418590267094865
ROC train: 0.815033	val: 0.615208	test: 0.599847
PRC train: 0.780271	val: 0.661523	test: 0.626392

Epoch: 40
Loss: 0.44165187062063477
ROC train: 0.808448	val: 0.604652	test: 0.602343
PRC train: 0.772480	val: 0.653833	test: 0.627087

Epoch: 41
Loss: 0.43151906504296145
ROC train: 0.809902	val: 0.607008	test: 0.610112
PRC train: 0.771672	val: 0.655102	test: 0.627333

Epoch: 42
Loss: 0.43467296450838244
ROC train: 0.822363	val: 0.624957	test: 0.611700
PRC train: 0.783500	val: 0.666437	test: 0.632441

Epoch: 43
Loss: 0.42947255109970994
ROC train: 0.824089	val: 0.622288	test: 0.600321
PRC train: 0.786025	val: 0.666029	test: 0.630734

Epoch: 44
Loss: 0.4302946288939483
ROC train: 0.824839	val: 0.615559	test: 0.590326
PRC train: 0.788621	val: 0.660205	test: 0.628435

Epoch: 45
Loss: 0.4289637192988199
ROC train: 0.829345	val: 0.621611	test: 0.590968
PRC train: 0.792764	val: 0.666643	test: 0.627395

Epoch: 46
Loss: 0.4296736537205369
ROC train: 0.830590	val: 0.622403	test: 0.600323
PRC train: 0.794037	val: 0.665592	test: 0.630957

Epoch: 47
Loss: 0.42767382799934656
ROC train: 0.827431	val: 0.622926	test: 0.607565
PRC train: 0.792495	val: 0.669635	test: 0.631161

Epoch: 48
Loss: 0.42376135624641986
ROC train: 0.832218	val: 0.626439	test: 0.606645
PRC train: 0.793738	val: 0.669407	test: 0.625453

Epoch: 49
Loss: 0.4199657088927351
ROC train: 0.829485	val: 0.612588	test: 0.604587
PRC train: 0.791705	val: 0.661493	test: 0.626925

Epoch: 50
Loss: 0.41827649275801837
ROC train: 0.838429	val: 0.614888	test: 0.597890
PRC train: 0.800134	val: 0.661699	test: 0.624248

Epoch: 51
Loss: 0.4171419333403573
ROC train: 0.827682	val: 0.599405	test: 0.586304
PRC train: 0.786897	val: 0.654750	test: 0.619022

Epoch: 52
Loss: 0.4157366491717719
ROC train: 0.838755	val: 0.614362	test: 0.598491
PRC train: 0.797925	val: 0.663899	test: 0.626062

Epoch: 53
Loss: 0.41398086062544187
ROC train: 0.843308	val: 0.619762	test: 0.603313
PRC train: 0.804637	val: 0.666116	test: 0.626946

Epoch: 54
Loss: 0.4124602485539864
ROC train: 0.841052	val: 0.608421	test: 0.600258
PRC train: 0.800481	val: 0.657891	test: 0.628907

Epoch: 55
Loss: 0.41368167953946455
ROC train: 0.846344	val: 0.613915	test: 0.599427
PRC train: 0.807132	val: 0.661992	test: 0.624995

Epoch: 56
Loss: 0.4134151370877491
ROC train: 0.847418	val: 0.623004	test: 0.590529
PRC train: 0.807726	val: 0.669114	test: 0.621151

Epoch: 57
Loss: 0.4068094598548996
ROC train: 0.848859	val: 0.626751	test: 0.590285
PRC train: 0.809719	val: 0.671232	test: 0.622589

Epoch: 58
Loss: 0.40784560471438597
ROC train: 0.849389	val: 0.620050	test: 0.594256
PRC train: 0.812702	val: 0.663017	test: 0.625578

Epoch: 59
Loss: 0.4041968402331527
ROC train: 0.854056	val: 0.617680	test: 0.586461
PRC train: 0.817778	val: 0.664342	test: 0.621035

Epoch: 60
Loss: 0.40928785364358955
ROC train: 0.857479	val: 0.624272	test: 0.581866
PRC train: 0.818955	val: 0.666560	test: 0.622594

Epoch: 61
Loss: 0.39814939428111246
ROC train: 0.858244	val: 0.624430	test: 0.593635
PRC train: 0.819052	val: 0.664980	test: 0.628739

Epoch: 62
Loss: 0.40815173419300355
ROC train: 0.861559	val: 0.623889	test: 0.597959
PRC train: 0.823786	val: 0.664752	test: 0.630444

Epoch: 63
Loss: 0.4082413160719424
ROC train: 0.860651	val: 0.621827	test: 0.595977
PRC train: 0.822391	val: 0.664449	test: 0.627162

Epoch: 64
Loss: 0.4007449096698929
ROC train: 0.860259	val: 0.625712	test: 0.593122
PRC train: 0.821816	val: 0.670601	test: 0.622906

Epoch: 65
Loss: 0.4021681400446523
ROC train: 0.860338	val: 0.624601	test: 0.600194
PRC train: 0.822127	val: 0.667217	test: 0.625380

Epoch: 66
Loss: 0.400115730698721
ROC train: 0.862284	val: 0.624600	test: 0.599052
PRC train: 0.822210	val: 0.669129	test: 0.625383

Epoch: 67
Loss: 0.3979004147171087
ROC train: 0.863916	val: 0.627921	test: 0.597819
PRC train: 0.824800	val: 0.674117	test: 0.626073

Epoch: 68
Loss: 0.3983547497368985
ROC train: 0.868560	val: 0.625222	test: 0.598001
PRC train: 0.828874	val: 0.670877	test: 0.629961

Epoch: 69
Loss: 0.397360051781814
ROC train: 0.870162	val: 0.622719	test: 0.583293
PRC train: 0.831475	val: 0.668251	test: 0.625061

Epoch: 70
Loss: 0.400199922424766
ROC train: 0.872339	val: 0.626918	test: 0.590443
PRC train: 0.832883	val: 0.667423	test: 0.623708

Epoch: 71
Loss: 0.39017182344766405
ROC train: 0.869694	val: 0.622429	test: 0.595125
PRC train: 0.829915	val: 0.668829	test: 0.625375

Epoch: 72
Loss: 0.3850819698133204
ROC train: 0.871581	val: 0.623381	test: 0.601940
PRC train: 0.834308	val: 0.668994	test: 0.633050

Epoch: 73
Loss: 0.3860531938404729
ROC train: 0.871801	val: 0.611082	test: 0.593168
PRC train: 0.829860	val: 0.661520	test: 0.627713

Epoch: 74
Loss: 0.3916681610339838
ROC train: 0.876569	val: 0.633956	test: 0.580070
PRC train: 0.836980	val: 0.677857	test: 0.623696

Epoch: 75
Loss: 0.39358286715339724
ROC train: 0.873003	val: 0.629008	test: 0.586595
PRC train: 0.834657	val: 0.674740	test: 0.622774

Epoch: 76
Loss: 0.3868918971577131
ROC train: 0.874863	val: 0.616317	test: 0.588396
PRC train: 0.836191	val: 0.662842	test: 0.627487

Epoch: 77
Loss: 0.3851913406071988
ROC train: 0.877158	val: 0.622093	test: 0.579013
PRC train: 0.838288	val: 0.666875	test: 0.621180

Epoch: 78
Loss: 0.383928517540806
ROC train: 0.879530	val: 0.639538	test: 0.588266
PRC train: 0.843698	val: 0.673225	test: 0.624143

Epoch: 79
Loss: 0.3856761233876741
ROC train: 0.879604	val: 0.636420	test: 0.590882
PRC train: 0.843408	val: 0.673305	test: 0.626601

Epoch: 80
Loss: 0.3811308272061867
ROC train: 0.882171	val: 0.611889	test: 0.588043
PRC train: 0.844962	val: 0.659743	test: 0.626601

Epoch: 81
Loss: 0.3804383412655473
ROC train: 0.885407	val: 0.608788	test: 0.578725
PRC train: 0.848579	val: 0.656816	test: 0.623188

Epoch: 82
Loss: 0.3815393902286662
ROC train: 0.882015	val: 0.620672	test: 0.571161
PRC train: 0.843254	val: 0.665580	test: 0.615594

Epoch: 83
Loss: 0.3778372986906584
ROC train: 0.881532	val: 0.627949	test: 0.576612
PRC train: 0.843928	val: 0.674998	test: 0.620609

Epoch: 84
Loss: 0.3775966460833863
ROC train: 0.885147	val: 0.619675	test: 0.580074
PRC train: 0.847491	val: 0.671773	test: 0.626900

Epoch: 85
Loss: 0.3816523823415944
ROC train: 0.883841	val: 0.629367	test: 0.576731
PRC train: 0.845291	val: 0.676687	test: 0.624661

Epoch: 86
Loss: 0.3720870455434948
ROC train: 0.888489	val: 0.632854	test: 0.581096
PRC train: 0.850296	val: 0.673842	test: 0.626639

Epoch: 87
Loss: 0.3689963839589939
ROC train: 0.886460	val: 0.622427	test: 0.579357
PRC train: 0.847181	val: 0.663069	test: 0.622438

Epoch: 88
Loss: 0.3731532603485982
ROC train: 0.891687	val: 0.617382	test: 0.580778
PRC train: 0.854298	val: 0.662132	test: 0.621162

Epoch: 89
Loss: 0.3733663726820661
ROC train: 0.893738	val: 0.617370	test: 0.592725
PRC train: 0.856308	val: 0.666194	test: 0.628025

Epoch: 90
Loss: 0.37317650578265743
ROC train: 0.891248	val: 0.624439	test: 0.575701
PRC train: 0.851525	val: 0.665351	test: 0.619739

Epoch: 91
Loss: 0.368067213698288
ROC train: 0.890022	val: 0.615674	test: 0.575557
PRC train: 0.853189	val: 0.658246	test: 0.618699

Epoch: 92
Loss: 0.3653650452590258
ROC train: 0.896052	val: 0.641761	test: 0.577430
PRC train: 0.860357	val: 0.678457	test: 0.619604

Epoch: 93
Loss: 0.3683514308403361
ROC train: 0.890011	val: 0.637044	test: 0.576461
PRC train: 0.852483	val: 0.679452	test: 0.623204

Epoch: 94
Loss: 0.365556425663014
ROC train: 0.893404	val: 0.635284	test: 0.579557
ROC train: 0.888592	val: 0.556446	test: 0.601009
PRC train: 0.848928	val: 0.632028	test: 0.632278

Epoch: 95
Loss: 0.37174811866733093
ROC train: 0.890797	val: 0.556182	test: 0.603088
PRC train: 0.854031	val: 0.632106	test: 0.632493

Epoch: 96
Loss: 0.3706379601932705
ROC train: 0.890626	val: 0.552072	test: 0.603522
PRC train: 0.852562	val: 0.627721	test: 0.632067

Epoch: 97
Loss: 0.36774331882685873
ROC train: 0.892956	val: 0.551719	test: 0.604703
PRC train: 0.853235	val: 0.627133	test: 0.631994

Epoch: 98
Loss: 0.36444806767508575
ROC train: 0.894009	val: 0.550808	test: 0.599224
PRC train: 0.852442	val: 0.631494	test: 0.634175

Epoch: 99
Loss: 0.36657859987693503
ROC train: 0.894041	val: 0.558736	test: 0.599762
PRC train: 0.850447	val: 0.639312	test: 0.635454

Epoch: 100
Loss: 0.3754567666588078
ROC train: 0.896763	val: 0.564369	test: 0.604740
PRC train: 0.858170	val: 0.641924	test: 0.636938

Epoch: 101
Loss: 0.3657073207872278
ROC train: 0.899538	val: 0.557271	test: 0.598045
PRC train: 0.860940	val: 0.634509	test: 0.634385

Epoch: 102
Loss: 0.3668454672136449
ROC train: 0.897474	val: 0.549037	test: 0.595666
PRC train: 0.861023	val: 0.626265	test: 0.632275

Epoch: 103
Loss: 0.3574451531588153
ROC train: 0.897792	val: 0.550190	test: 0.600447
PRC train: 0.861729	val: 0.626608	test: 0.632229

Epoch: 104
Loss: 0.35809277906603626
ROC train: 0.900556	val: 0.552241	test: 0.600159
PRC train: 0.864211	val: 0.629903	test: 0.633262

Epoch: 105
Loss: 0.356543747098572
ROC train: 0.901936	val: 0.551809	test: 0.605294
PRC train: 0.864127	val: 0.630714	test: 0.637826

Epoch: 106
Loss: 0.35720795034389974
ROC train: 0.899689	val: 0.559099	test: 0.598895
PRC train: 0.859977	val: 0.635060	test: 0.634766

Epoch: 107
Loss: 0.358212496721275
ROC train: 0.897716	val: 0.562101	test: 0.592844
PRC train: 0.858317	val: 0.635322	test: 0.632694

Epoch: 108
Loss: 0.34503487248332687
ROC train: 0.903816	val: 0.560144	test: 0.596782
PRC train: 0.866504	val: 0.634526	test: 0.631853

Epoch: 109
Loss: 0.3511087051992747
ROC train: 0.903367	val: 0.556393	test: 0.600943
PRC train: 0.868618	val: 0.630614	test: 0.632166

Epoch: 110
Loss: 0.35333539151027415
ROC train: 0.900856	val: 0.552442	test: 0.599942
PRC train: 0.866182	val: 0.627874	test: 0.630636

Epoch: 111
Loss: 0.3519387320028409
ROC train: 0.901777	val: 0.555746	test: 0.591913
PRC train: 0.863935	val: 0.631170	test: 0.627613

Epoch: 112
Loss: 0.3447268527643653
ROC train: 0.904246	val: 0.561472	test: 0.595356
PRC train: 0.865588	val: 0.636616	test: 0.630274

Epoch: 113
Loss: 0.35717547134439587
ROC train: 0.911308	val: 0.566483	test: 0.604503
PRC train: 0.875147	val: 0.638590	test: 0.636049

Epoch: 114
Loss: 0.35434239620307123
ROC train: 0.910290	val: 0.563775	test: 0.608658
PRC train: 0.873403	val: 0.636090	test: 0.638116

Epoch: 115
Loss: 0.3453767894098181
ROC train: 0.910451	val: 0.559547	test: 0.606951
PRC train: 0.873732	val: 0.634544	test: 0.639730

Epoch: 116
Loss: 0.3470714479783696
ROC train: 0.914018	val: 0.554007	test: 0.608500
PRC train: 0.878960	val: 0.633077	test: 0.640808

Epoch: 117
Loss: 0.3405018905535112
ROC train: 0.915113	val: 0.551665	test: 0.607923
PRC train: 0.880635	val: 0.630673	test: 0.638606

Epoch: 118
Loss: 0.34543641180912005
ROC train: 0.915738	val: 0.550410	test: 0.605695
PRC train: 0.881004	val: 0.629436	test: 0.636915

Epoch: 119
Loss: 0.33850974345270307
ROC train: 0.915068	val: 0.556143	test: 0.602364
PRC train: 0.879603	val: 0.633835	test: 0.635550

Epoch: 120
Loss: 0.33978081949698774
ROC train: 0.914960	val: 0.566076	test: 0.602950
PRC train: 0.879755	val: 0.640069	test: 0.634325

Early stopping
Best (ROC):	 train: 0.736569	val: 0.574279	test: 0.585927
Best (PRC):	 train: 0.714661	val: 0.640157	test: 0.627485

PRC train: 0.858041	val: 0.649962	test: 0.633125

Epoch: 95
Loss: 0.3614308588501908
ROC train: 0.894942	val: 0.587184	test: 0.610108
PRC train: 0.853866	val: 0.652112	test: 0.628371

Epoch: 96
Loss: 0.36054749047075135
ROC train: 0.899300	val: 0.586346	test: 0.614123
PRC train: 0.860615	val: 0.650424	test: 0.634016

Epoch: 97
Loss: 0.35611030800579796
ROC train: 0.900042	val: 0.585374	test: 0.618834
PRC train: 0.860542	val: 0.648448	test: 0.635252

Epoch: 98
Loss: 0.3605377155025961
ROC train: 0.901679	val: 0.585927	test: 0.615580
PRC train: 0.860342	val: 0.651275	test: 0.634408

Epoch: 99
Loss: 0.3612500410098506
ROC train: 0.902652	val: 0.580315	test: 0.611292
PRC train: 0.860522	val: 0.653223	test: 0.633319

Epoch: 100
Loss: 0.3624018001822258
ROC train: 0.905319	val: 0.581503	test: 0.630710
PRC train: 0.865872	val: 0.652846	test: 0.645233

Epoch: 101
Loss: 0.3557561808279787
ROC train: 0.906296	val: 0.582626	test: 0.627903
PRC train: 0.866837	val: 0.652114	test: 0.641173

Epoch: 102
Loss: 0.35665395403176753
ROC train: 0.907435	val: 0.580381	test: 0.620760
PRC train: 0.869302	val: 0.650129	test: 0.639581

Epoch: 103
Loss: 0.3575692398243634
ROC train: 0.906408	val: 0.579574	test: 0.621506
PRC train: 0.868103	val: 0.651122	test: 0.637973

Epoch: 104
Loss: 0.34912115174245906
ROC train: 0.907755	val: 0.569768	test: 0.611126
PRC train: 0.868490	val: 0.643700	test: 0.631113

Epoch: 105
Loss: 0.3545563911308732
ROC train: 0.909650	val: 0.569974	test: 0.609162
PRC train: 0.871319	val: 0.644327	test: 0.632102

Epoch: 106
Loss: 0.34687840995497343
ROC train: 0.909656	val: 0.573936	test: 0.611783
PRC train: 0.870871	val: 0.647789	test: 0.632045

Epoch: 107
Loss: 0.3523368367510118
ROC train: 0.907971	val: 0.573875	test: 0.605574
PRC train: 0.868328	val: 0.646374	test: 0.627756

Epoch: 108
Loss: 0.3457228620188367
ROC train: 0.910374	val: 0.580026	test: 0.605570
PRC train: 0.873612	val: 0.647671	test: 0.629358

Epoch: 109
Loss: 0.3430752421774566
ROC train: 0.911292	val: 0.580336	test: 0.615798
PRC train: 0.873191	val: 0.647429	test: 0.635268

Epoch: 110
Loss: 0.3495944221477059
ROC train: 0.914660	val: 0.584469	test: 0.625120
PRC train: 0.874963	val: 0.651019	test: 0.639675

Epoch: 111
Loss: 0.34392232133711637
ROC train: 0.915120	val: 0.586072	test: 0.624205
PRC train: 0.876163	val: 0.653500	test: 0.639604

Epoch: 112
Loss: 0.3447478772085722
ROC train: 0.914175	val: 0.582292	test: 0.614674
PRC train: 0.875229	val: 0.652376	test: 0.634594

Epoch: 113
Loss: 0.3443503764496382
ROC train: 0.915155	val: 0.577609	test: 0.602736
PRC train: 0.878497	val: 0.650864	test: 0.628797

Epoch: 114
Loss: 0.34378686286996063
ROC train: 0.915120	val: 0.568924	test: 0.601304
PRC train: 0.879877	val: 0.651408	test: 0.630032

Epoch: 115
Loss: 0.33952320923181273
ROC train: 0.917959	val: 0.571868	test: 0.605671
PRC train: 0.882756	val: 0.652569	test: 0.631080

Epoch: 116
Loss: 0.34136821380700555
ROC train: 0.918281	val: 0.573541	test: 0.612058
PRC train: 0.881446	val: 0.652952	test: 0.632313

Epoch: 117
Loss: 0.3332745288026844
ROC train: 0.915081	val: 0.579611	test: 0.614962
PRC train: 0.877029	val: 0.652181	test: 0.635094

Epoch: 118
Loss: 0.33886494837984044
ROC train: 0.917038	val: 0.580846	test: 0.616076
PRC train: 0.879663	val: 0.653281	test: 0.634578

Epoch: 119
Loss: 0.3346828055140937
ROC train: 0.919716	val: 0.584946	test: 0.613722
PRC train: 0.882978	val: 0.653622	test: 0.634307

Epoch: 120
Loss: 0.3372694521688361
ROC train: 0.919924	val: 0.582750	test: 0.601935
PRC train: 0.884037	val: 0.654634	test: 0.631399

Early stopping
Best (ROC):	 train: 0.887115	val: 0.593865	test: 0.620940
Best (PRC):	 train: 0.844777	val: 0.655130	test: 0.636403

PRC train: 0.854041	val: 0.672099	test: 0.618831

Epoch: 95
Loss: 0.3654588113609839
ROC train: 0.895959	val: 0.629625	test: 0.583053
PRC train: 0.855985	val: 0.671495	test: 0.620860

Epoch: 96
Loss: 0.3654785693252788
ROC train: 0.893220	val: 0.629124	test: 0.592133
PRC train: 0.854608	val: 0.669697	test: 0.625610

Epoch: 97
Loss: 0.36847788419049954
ROC train: 0.895379	val: 0.624552	test: 0.597110
PRC train: 0.855923	val: 0.670524	test: 0.627373

Epoch: 98
Loss: 0.36403648195823807
ROC train: 0.897997	val: 0.629235	test: 0.592416
PRC train: 0.858480	val: 0.671625	test: 0.625327

Epoch: 99
Loss: 0.36082853782243646
ROC train: 0.896444	val: 0.636608	test: 0.591073
PRC train: 0.856725	val: 0.673605	test: 0.623841

Epoch: 100
Loss: 0.3665388551730427
ROC train: 0.895207	val: 0.634919	test: 0.601324
PRC train: 0.852500	val: 0.672693	test: 0.629807

Epoch: 101
Loss: 0.3645489362299135
ROC train: 0.899524	val: 0.643920	test: 0.590194
PRC train: 0.857527	val: 0.678895	test: 0.624703

Epoch: 102
Loss: 0.35804227665405003
ROC train: 0.900567	val: 0.644754	test: 0.583217
PRC train: 0.861775	val: 0.679526	test: 0.617003

Epoch: 103
Loss: 0.367552158648787
ROC train: 0.903199	val: 0.634834	test: 0.591255
PRC train: 0.865720	val: 0.676391	test: 0.622569

Epoch: 104
Loss: 0.35977104338280846
ROC train: 0.903310	val: 0.629043	test: 0.602404
PRC train: 0.864694	val: 0.671264	test: 0.626980

Epoch: 105
Loss: 0.3545434662472041
ROC train: 0.904488	val: 0.622982	test: 0.595708
PRC train: 0.865825	val: 0.668295	test: 0.624512

Epoch: 106
Loss: 0.35771142212288576
ROC train: 0.904925	val: 0.622453	test: 0.591061
PRC train: 0.865665	val: 0.671715	test: 0.623466

Epoch: 107
Loss: 0.351193222513059
ROC train: 0.906587	val: 0.636337	test: 0.579755
PRC train: 0.867923	val: 0.676702	test: 0.621269

Epoch: 108
Loss: 0.3527929992008645
ROC train: 0.906336	val: 0.641253	test: 0.580407
PRC train: 0.868707	val: 0.678390	test: 0.623163

Epoch: 109
Loss: 0.3484402083111332
ROC train: 0.909364	val: 0.637208	test: 0.588982
PRC train: 0.872209	val: 0.673539	test: 0.626897

Epoch: 110
Loss: 0.3484521238140422
ROC train: 0.909670	val: 0.636983	test: 0.595191
PRC train: 0.872837	val: 0.672528	test: 0.626641

Epoch: 111
Loss: 0.3462197486229883
ROC train: 0.911015	val: 0.622533	test: 0.601310
PRC train: 0.872745	val: 0.667094	test: 0.626963

Epoch: 112
Loss: 0.35336288678552863
ROC train: 0.910580	val: 0.625452	test: 0.589965
PRC train: 0.871464	val: 0.668912	test: 0.625621

Epoch: 113
Loss: 0.35326937370811384
ROC train: 0.910641	val: 0.628413	test: 0.583133
PRC train: 0.871284	val: 0.673639	test: 0.620859

Epoch: 114
Loss: 0.34777298548060337
ROC train: 0.915101	val: 0.622318	test: 0.585739
PRC train: 0.876877	val: 0.672288	test: 0.623804

Epoch: 115
Loss: 0.3442923759746807
ROC train: 0.912356	val: 0.623818	test: 0.600575
PRC train: 0.873536	val: 0.674828	test: 0.625846

Epoch: 116
Loss: 0.3485709085358053
ROC train: 0.913245	val: 0.631403	test: 0.595437
PRC train: 0.873296	val: 0.677201	test: 0.624696

Epoch: 117
Loss: 0.3442335779006646
ROC train: 0.914009	val: 0.628323	test: 0.584142
PRC train: 0.875880	val: 0.673854	test: 0.624221

Epoch: 118
Loss: 0.3458583933264362
ROC train: 0.917058	val: 0.621308	test: 0.586805
PRC train: 0.879851	val: 0.672226	test: 0.623789

Epoch: 119
Loss: 0.34535754826102
ROC train: 0.917047	val: 0.619237	test: 0.592938
PRC train: 0.881902	val: 0.670395	test: 0.625816

Epoch: 120
Loss: 0.34350242575574585
ROC train: 0.918134	val: 0.626746	test: 0.586038
PRC train: 0.883527	val: 0.670793	test: 0.623055

Early stopping
Best (ROC):	 train: 0.841186	val: 0.645917	test: 0.582359
Best (PRC):	 train: 0.801547	val: 0.682994	test: 0.627240

ROC train: 0.886345	val: 0.557976	test: 0.597030
PRC train: 0.838484	val: 0.629218	test: 0.638267

Epoch: 95
Loss: 0.366371146140928
ROC train: 0.891206	val: 0.577523	test: 0.611283
PRC train: 0.844692	val: 0.643447	test: 0.646126

Epoch: 96
Loss: 0.367453229015513
ROC train: 0.893828	val: 0.578394	test: 0.614021
PRC train: 0.845663	val: 0.642931	test: 0.647460

Epoch: 97
Loss: 0.36463454945381574
ROC train: 0.897505	val: 0.566125	test: 0.613169
PRC train: 0.852440	val: 0.636689	test: 0.644259

Epoch: 98
Loss: 0.36891239849030927
ROC train: 0.893535	val: 0.561294	test: 0.606779
PRC train: 0.848624	val: 0.634281	test: 0.641840

Epoch: 99
Loss: 0.3637663187900325
ROC train: 0.895384	val: 0.563969	test: 0.609758
PRC train: 0.849195	val: 0.634808	test: 0.645331

Epoch: 100
Loss: 0.3628729427732593
ROC train: 0.894305	val: 0.565253	test: 0.606979
PRC train: 0.847748	val: 0.634940	test: 0.644600

Epoch: 101
Loss: 0.35788945035727293
ROC train: 0.897577	val: 0.567121	test: 0.606938
PRC train: 0.851860	val: 0.639632	test: 0.642389

Epoch: 102
Loss: 0.35754511378320264
ROC train: 0.898026	val: 0.559585	test: 0.606939
PRC train: 0.851100	val: 0.634187	test: 0.640348

Epoch: 103
Loss: 0.36467555817371233
ROC train: 0.901620	val: 0.558425	test: 0.611776
PRC train: 0.857845	val: 0.631589	test: 0.643179

Epoch: 104
Loss: 0.3578166326395913
ROC train: 0.892742	val: 0.548619	test: 0.609565
PRC train: 0.848614	val: 0.628566	test: 0.642831

Epoch: 105
Loss: 0.36023231063367234
ROC train: 0.892551	val: 0.556246	test: 0.601857
PRC train: 0.848816	val: 0.633466	test: 0.639805

Epoch: 106
Loss: 0.35536376226231536
ROC train: 0.900428	val: 0.574274	test: 0.608808
PRC train: 0.854688	val: 0.642959	test: 0.641945

Epoch: 107
Loss: 0.35109730449930426
ROC train: 0.902826	val: 0.578858	test: 0.609829
PRC train: 0.858221	val: 0.644096	test: 0.644577

Epoch: 108
Loss: 0.3518587395129004
ROC train: 0.900000	val: 0.572995	test: 0.609087
PRC train: 0.860048	val: 0.641952	test: 0.643841

Epoch: 109
Loss: 0.36460081097178276
ROC train: 0.903114	val: 0.567314	test: 0.607672
PRC train: 0.858751	val: 0.637624	test: 0.643813

Epoch: 110
Loss: 0.3569975876288833
ROC train: 0.904400	val: 0.563396	test: 0.609104
PRC train: 0.858192	val: 0.633929	test: 0.643045

Epoch: 111
Loss: 0.3482397616144406
ROC train: 0.905729	val: 0.569093	test: 0.616586
PRC train: 0.864228	val: 0.636095	test: 0.648886

Epoch: 112
Loss: 0.3450855291426559
ROC train: 0.906353	val: 0.569113	test: 0.612921
PRC train: 0.864977	val: 0.636034	test: 0.644821

Epoch: 113
Loss: 0.3482462516945554
ROC train: 0.905862	val: 0.568141	test: 0.610774
PRC train: 0.862301	val: 0.636534	test: 0.643704

Epoch: 114
Loss: 0.35684064059646536
ROC train: 0.906517	val: 0.570578	test: 0.616714
PRC train: 0.863007	val: 0.637696	test: 0.650344

Epoch: 115
Loss: 0.3444138296757172
ROC train: 0.908165	val: 0.576109	test: 0.617288
PRC train: 0.864901	val: 0.640908	test: 0.648819

Epoch: 116
Loss: 0.34412427693976894
ROC train: 0.911841	val: 0.578588	test: 0.615508
PRC train: 0.870086	val: 0.645937	test: 0.645136

Epoch: 117
Loss: 0.3491874283258678
ROC train: 0.912060	val: 0.569560	test: 0.613447
PRC train: 0.868531	val: 0.639386	test: 0.646255

Epoch: 118
Loss: 0.3477398671773504
ROC train: 0.909733	val: 0.572014	test: 0.621840
PRC train: 0.866773	val: 0.639039	test: 0.649231

Epoch: 119
Loss: 0.3458519645486777
ROC train: 0.911375	val: 0.573560	test: 0.628006
PRC train: 0.867478	val: 0.639962	test: 0.652660

Epoch: 120
Loss: 0.3451106696617363
ROC train: 0.912677	val: 0.574532	test: 0.617468
PRC train: 0.869877	val: 0.640270	test: 0.644864

Epoch: 121
Loss: 0.3419400169965338
ROC train: 0.915862	val: 0.574709	test: 0.611944
PRC train: 0.873497	val: 0.641782	test: 0.641494

Epoch: 122
Loss: 0.33833172694002595
ROC train: 0.918742	val: 0.571129	test: 0.613867
PRC train: 0.877353	val: 0.638798	test: 0.644136

Epoch: 123
Loss: 0.3393146887607509
ROC train: 0.918157	val: 0.566152	test: 0.616886
PRC train: 0.877755	val: 0.635820	test: 0.647568

Epoch: 124
Loss: 0.34690330523270924
ROC train: 0.915978	val: 0.562606	test: 0.612221
PRC train: 0.875896	val: 0.635121	test: 0.646036

Epoch: 125
Loss: 0.34228892924261
ROC train: 0.916077	val: 0.561168	test: 0.609357
PRC train: 0.875016	val: 0.635796	test: 0.642082

Epoch: 126
Loss: 0.33764954655108587
ROC train: 0.918802	val: 0.563341	test: 0.613881
PRC train: 0.876519	val: 0.636652	test: 0.642284

Epoch: 127
Loss: 0.33644320331688976
ROC train: 0.918106	val: 0.563734	test: 0.614230
PRC train: 0.875657	val: 0.636629	test: 0.645368

Epoch: 128
Loss: 0.3384156703218004
ROC train: 0.921986	val: 0.565774	test: 0.615749
PRC train: 0.879933	val: 0.636193	test: 0.644439

Epoch: 129
Loss: 0.32673208932206965
ROC train: 0.917998	val: 0.564983	test: 0.610807
PRC train: 0.875508	val: 0.635513	test: 0.640335

Epoch: 130
Loss: 0.33135603196612456
ROC train: 0.923135	val: 0.568575	test: 0.613510
PRC train: 0.882270	val: 0.637831	test: 0.643825

Epoch: 131
Loss: 0.3312899602485747
ROC train: 0.924962	val: 0.572419	test: 0.614413
PRC train: 0.886338	val: 0.638528	test: 0.643118

Epoch: 132
Loss: 0.32955564382682
ROC train: 0.925479	val: 0.573767	test: 0.615665
PRC train: 0.886186	val: 0.639810	test: 0.644392

Epoch: 133
Loss: 0.32672815613618333
ROC train: 0.919607	val: 0.563922	test: 0.608452
PRC train: 0.874242	val: 0.636376	test: 0.643934

Epoch: 134
Loss: 0.3324297380805925
ROC train: 0.924295	val: 0.564579	test: 0.614848
PRC train: 0.881216	val: 0.637929	test: 0.646237

Epoch: 135
Loss: 0.3281901224816474
ROC train: 0.924875	val: 0.562224	test: 0.615376
PRC train: 0.885420	val: 0.636901	test: 0.646621

Epoch: 136
Loss: 0.32315318543987037
ROC train: 0.926478	val: 0.563031	test: 0.617520
PRC train: 0.887817	val: 0.637258	test: 0.651690

Epoch: 137
Loss: 0.33267304579299106
ROC train: 0.930169	val: 0.571029	test: 0.616072
PRC train: 0.892402	val: 0.641920	test: 0.649171

Epoch: 138
Loss: 0.3164117332667862
ROC train: 0.927264	val: 0.567743	test: 0.609785
PRC train: 0.887751	val: 0.638021	test: 0.645539

Epoch: 139
Loss: 0.3189766782752564
ROC train: 0.928709	val: 0.568505	test: 0.612076
PRC train: 0.890336	val: 0.638411	test: 0.645332

Epoch: 140
Loss: 0.31519298363027554
ROC train: 0.929426	val: 0.568301	test: 0.617929
PRC train: 0.891046	val: 0.638586	test: 0.646814

Epoch: 141
Loss: 0.3263407029173327
ROC train: 0.930320	val: 0.574250	test: 0.620525
PRC train: 0.894978	val: 0.641078	test: 0.646426

Epoch: 142
Loss: 0.32939064329630596
ROC train: 0.932685	val: 0.570454	test: 0.619711
PRC train: 0.896701	val: 0.638591	test: 0.647467

Early stopping
Best (ROC):	 train: 0.902826	val: 0.578858	test: 0.609829
Best (PRC):	 train: 0.858221	val: 0.644096	test: 0.644577

PRC train: 0.844667	val: 0.632374	test: 0.627833

Epoch: 95
Loss: 0.3615650781433104
ROC train: 0.890961	val: 0.552353	test: 0.596436
PRC train: 0.843915	val: 0.628404	test: 0.628683

Epoch: 96
Loss: 0.37102834279834696
ROC train: 0.889388	val: 0.553738	test: 0.596011
PRC train: 0.842128	val: 0.628701	test: 0.627788

Epoch: 97
Loss: 0.36297495484655773
ROC train: 0.889466	val: 0.558261	test: 0.590925
PRC train: 0.843157	val: 0.631212	test: 0.625412

Epoch: 98
Loss: 0.37019139962477604
ROC train: 0.891204	val: 0.562214	test: 0.593424
PRC train: 0.846105	val: 0.631885	test: 0.624840

Epoch: 99
Loss: 0.367177109762211
ROC train: 0.894904	val: 0.560885	test: 0.597458
PRC train: 0.852547	val: 0.631747	test: 0.626406

Epoch: 100
Loss: 0.37162194059583054
ROC train: 0.897249	val: 0.557937	test: 0.597000
PRC train: 0.851578	val: 0.632933	test: 0.628262

Epoch: 101
Loss: 0.35790118513290076
ROC train: 0.895250	val: 0.556720	test: 0.593321
PRC train: 0.850285	val: 0.633371	test: 0.629634

Epoch: 102
Loss: 0.36693717500269446
ROC train: 0.897579	val: 0.560260	test: 0.597139
PRC train: 0.853531	val: 0.635943	test: 0.629089

Epoch: 103
Loss: 0.3549063398221631
ROC train: 0.900086	val: 0.561454	test: 0.593951
PRC train: 0.859228	val: 0.637093	test: 0.626735

Epoch: 104
Loss: 0.3535625209921047
ROC train: 0.898900	val: 0.563164	test: 0.588276
PRC train: 0.860015	val: 0.636146	test: 0.624087

Epoch: 105
Loss: 0.35670912587406645
ROC train: 0.901396	val: 0.560866	test: 0.590423
PRC train: 0.863019	val: 0.634139	test: 0.625803

Epoch: 106
Loss: 0.35617268649020367
ROC train: 0.898702	val: 0.559241	test: 0.593781
PRC train: 0.860051	val: 0.634525	test: 0.626869

Epoch: 107
Loss: 0.35274349037936353
ROC train: 0.901077	val: 0.566283	test: 0.593040
PRC train: 0.857285	val: 0.638481	test: 0.628850

Epoch: 108
Loss: 0.3456681246813485
ROC train: 0.897987	val: 0.566244	test: 0.585410
PRC train: 0.856764	val: 0.636800	test: 0.624628

Epoch: 109
Loss: 0.35550829922380556
ROC train: 0.899019	val: 0.568241	test: 0.587664
PRC train: 0.856173	val: 0.638490	test: 0.622428

Epoch: 110
Loss: 0.3635474956786436
ROC train: 0.903203	val: 0.567035	test: 0.588575
PRC train: 0.863951	val: 0.637513	test: 0.625676

Epoch: 111
Loss: 0.3509482181477891
ROC train: 0.898458	val: 0.563428	test: 0.593391
PRC train: 0.857025	val: 0.634723	test: 0.627097

Epoch: 112
Loss: 0.3528758271428449
ROC train: 0.904042	val: 0.563226	test: 0.595586
PRC train: 0.864326	val: 0.633903	test: 0.627520

Epoch: 113
Loss: 0.351756229505528
ROC train: 0.907365	val: 0.562618	test: 0.591136
PRC train: 0.867282	val: 0.634042	test: 0.625882

Epoch: 114
Loss: 0.3561968421450141
ROC train: 0.908410	val: 0.564838	test: 0.587811
PRC train: 0.867827	val: 0.633561	test: 0.624772

Epoch: 115
Loss: 0.3423747522940538
ROC train: 0.910307	val: 0.566082	test: 0.585823
PRC train: 0.869464	val: 0.635960	test: 0.625004

Epoch: 116
Loss: 0.3481756989504046
ROC train: 0.912268	val: 0.566470	test: 0.589572
PRC train: 0.869195	val: 0.637391	test: 0.626594

Epoch: 117
Loss: 0.3443567073164847
ROC train: 0.909883	val: 0.562848	test: 0.589116
PRC train: 0.865564	val: 0.633672	test: 0.626086

Epoch: 118
Loss: 0.34162188684369266
ROC train: 0.909421	val: 0.560729	test: 0.588821
PRC train: 0.866336	val: 0.632008	test: 0.626011

Epoch: 119
Loss: 0.33866410436891053
ROC train: 0.912308	val: 0.558956	test: 0.591089
PRC train: 0.872081	val: 0.630687	test: 0.626621

Epoch: 120
Loss: 0.34023826332533136
ROC train: 0.910881	val: 0.556756	test: 0.591507
PRC train: 0.872886	val: 0.628815	test: 0.625393

Epoch: 121
Loss: 0.34592733679525195
ROC train: 0.912904	val: 0.558036	test: 0.591582
PRC train: 0.872886	val: 0.629639	test: 0.627633

Epoch: 122
Loss: 0.3390951858370478
ROC train: 0.914058	val: 0.560379	test: 0.588515
PRC train: 0.872074	val: 0.631051	test: 0.622136

Epoch: 123
Loss: 0.3363758749902931
ROC train: 0.915346	val: 0.563337	test: 0.589289
PRC train: 0.875963	val: 0.633732	test: 0.621531

Epoch: 124
Loss: 0.3429157720196679
ROC train: 0.917336	val: 0.567792	test: 0.591560
PRC train: 0.876640	val: 0.638700	test: 0.627027

Epoch: 125
Loss: 0.33672512200113824
ROC train: 0.913157	val: 0.567710	test: 0.582479
PRC train: 0.873657	val: 0.637352	test: 0.623010

Epoch: 126
Loss: 0.3402694142613587
ROC train: 0.913233	val: 0.563962	test: 0.580610
PRC train: 0.871107	val: 0.635450	test: 0.621961

Epoch: 127
Loss: 0.33246029431446866
ROC train: 0.918685	val: 0.568291	test: 0.582527
PRC train: 0.877989	val: 0.638572	test: 0.626407

Epoch: 128
Loss: 0.33563765230650855
ROC train: 0.921319	val: 0.565909	test: 0.588502
PRC train: 0.881723	val: 0.636030	test: 0.629522

Epoch: 129
Loss: 0.3256561629764024
ROC train: 0.923159	val: 0.564123	test: 0.595751
PRC train: 0.882757	val: 0.635321	test: 0.631644

Epoch: 130
Loss: 0.32986371047629504
ROC train: 0.921525	val: 0.560471	test: 0.598135
PRC train: 0.879243	val: 0.633753	test: 0.634075

Epoch: 131
Loss: 0.3319463070309488
ROC train: 0.923081	val: 0.558170	test: 0.594474
PRC train: 0.880670	val: 0.631224	test: 0.631667

Epoch: 132
Loss: 0.3263448957139456
ROC train: 0.924210	val: 0.563717	test: 0.592156
PRC train: 0.883959	val: 0.632737	test: 0.628759

Epoch: 133
Loss: 0.3248904869025863
ROC train: 0.924153	val: 0.558708	test: 0.590587
PRC train: 0.887044	val: 0.629631	test: 0.627574

Epoch: 134
Loss: 0.32612959910143974
ROC train: 0.925063	val: 0.553502	test: 0.590392
PRC train: 0.886813	val: 0.625775	test: 0.628475

Epoch: 135
Loss: 0.318329085445485
ROC train: 0.926541	val: 0.555958	test: 0.594528
PRC train: 0.887864	val: 0.628281	test: 0.631526

Epoch: 136
Loss: 0.32302062915311014
ROC train: 0.928370	val: 0.561569	test: 0.596239
PRC train: 0.889638	val: 0.634666	test: 0.630637

Epoch: 137
Loss: 0.33218203162484533
ROC train: 0.930309	val: 0.561720	test: 0.594997
PRC train: 0.891314	val: 0.636189	test: 0.632546

Epoch: 138
Loss: 0.32230749753935733
ROC train: 0.926842	val: 0.559353	test: 0.594305
PRC train: 0.889705	val: 0.631796	test: 0.633048

Epoch: 139
Loss: 0.31281438989174803
ROC train: 0.926910	val: 0.554512	test: 0.593890
PRC train: 0.890798	val: 0.627040	test: 0.632627

Epoch: 140
Loss: 0.31610619722879424
ROC train: 0.930246	val: 0.546821	test: 0.595140
PRC train: 0.891724	val: 0.624976	test: 0.633287

Epoch: 141
Loss: 0.31483840800871776
ROC train: 0.931867	val: 0.552704	test: 0.595533
PRC train: 0.893800	val: 0.628580	test: 0.630946

Epoch: 142
Loss: 0.31502234583716016
ROC train: 0.931915	val: 0.563518	test: 0.599455
PRC train: 0.895036	val: 0.633497	test: 0.632213

Epoch: 143
Loss: 0.32100928369259063
ROC train: 0.930799	val: 0.558791	test: 0.604194
PRC train: 0.894137	val: 0.631118	test: 0.637267

Epoch: 144
Loss: 0.3175125369544534
ROC train: 0.933126	val: 0.565962	test: 0.601945
PRC train: 0.896355	val: 0.633956	test: 0.635427

Epoch: 145
Loss: 0.3150528091255633
ROC train: 0.930586	val: 0.561680	test: 0.590981
PRC train: 0.892819	val: 0.632840	test: 0.630942

Epoch: 146
Loss: 0.3141429676794839
ROC train: 0.927152	val: 0.556632	test: 0.585437
PRC train: 0.890560	val: 0.628747	test: 0.626612

Epoch: 147
Loss: 0.30951961987371124
ROC train: 0.934102	val: 0.556914	test: 0.594830
PRC train: 0.897353	val: 0.629536	test: 0.632982

Epoch: 148
Loss: 0.30734735121391793
ROC train: 0.936190	val: 0.558796	test: 0.602594
PRC train: 0.898678	val: 0.631147	test: 0.636060

Epoch: 149
Loss: 0.31333343461663504
ROC train: 0.934990	val: 0.560709	test: 0.603959
PRC train: 0.900296	val: 0.633677	test: 0.634390

Epoch: 150
Loss: 0.3133062486807128
ROC train: 0.937739	val: 0.566817	test: 0.599963
PRC train: 0.903646	val: 0.637526	test: 0.635562

Epoch: 151
Loss: 0.3065746788074357
ROC train: 0.938459	val: 0.569611	test: 0.596475
PRC train: 0.906080	val: 0.639869	test: 0.634196

Epoch: 152
Loss: 0.31685366809338344
ROC train: 0.939973	val: 0.563993	test: 0.592545
PRC train: 0.906673	val: 0.635127	test: 0.633629

Epoch: 153
Loss: 0.30280317501844467
ROC train: 0.937357	val: 0.562298	test: 0.592590
PRC train: 0.901891	val: 0.631778	test: 0.632506

Epoch: 154
Loss: 0.30455681258548206
ROC train: 0.938636	val: 0.563959	test: 0.596737
PRC train: 0.903141	val: 0.634978	test: 0.636176

Epoch: 155
Loss: 0.3068330894376657
PRC train: 0.853022	val: 0.648070	test: 0.635207

Epoch: 95
Loss: 0.3637497710504781
ROC train: 0.897510	val: 0.567753	test: 0.620809
PRC train: 0.855519	val: 0.646962	test: 0.636426

Epoch: 96
Loss: 0.36337745383730535
ROC train: 0.898006	val: 0.560255	test: 0.615453
PRC train: 0.857385	val: 0.642895	test: 0.632223

Epoch: 97
Loss: 0.36700386510350386
ROC train: 0.900039	val: 0.565451	test: 0.610206
PRC train: 0.859364	val: 0.645612	test: 0.628340

Epoch: 98
Loss: 0.3633932195421043
ROC train: 0.904206	val: 0.567999	test: 0.605625
PRC train: 0.862512	val: 0.648944	test: 0.628032

Epoch: 99
Loss: 0.3566537428778949
ROC train: 0.905012	val: 0.571356	test: 0.613931
PRC train: 0.865078	val: 0.650497	test: 0.631569

Epoch: 100
Loss: 0.3564054560927975
ROC train: 0.901578	val: 0.564590	test: 0.609550
PRC train: 0.860572	val: 0.646927	test: 0.628853

Epoch: 101
Loss: 0.3575235345716657
ROC train: 0.902091	val: 0.563621	test: 0.606998
PRC train: 0.860973	val: 0.646177	test: 0.626995

Epoch: 102
Loss: 0.3557024633662379
ROC train: 0.902847	val: 0.566560	test: 0.612794
PRC train: 0.861025	val: 0.647981	test: 0.630878

Epoch: 103
Loss: 0.353095711491993
ROC train: 0.905503	val: 0.569740	test: 0.618626
PRC train: 0.865457	val: 0.649579	test: 0.636662

Epoch: 104
Loss: 0.3521758108011124
ROC train: 0.908070	val: 0.571179	test: 0.606815
PRC train: 0.869509	val: 0.648420	test: 0.632592

Epoch: 105
Loss: 0.35860243776658596
ROC train: 0.908175	val: 0.566983	test: 0.601877
PRC train: 0.868709	val: 0.646321	test: 0.629918

Epoch: 106
Loss: 0.35308072738813956
ROC train: 0.910301	val: 0.566037	test: 0.605313
PRC train: 0.870699	val: 0.644221	test: 0.630856

Epoch: 107
Loss: 0.34980835731025806
ROC train: 0.906545	val: 0.578479	test: 0.599788
PRC train: 0.865743	val: 0.645662	test: 0.625177

Epoch: 108
Loss: 0.3530193263822511
ROC train: 0.911769	val: 0.572972	test: 0.615790
PRC train: 0.873375	val: 0.649341	test: 0.635801

Epoch: 109
Loss: 0.3471360076148088
ROC train: 0.908179	val: 0.564732	test: 0.615455
PRC train: 0.869038	val: 0.645535	test: 0.635957

Epoch: 110
Loss: 0.3438556985444772
ROC train: 0.911240	val: 0.573774	test: 0.616086
PRC train: 0.871862	val: 0.649735	test: 0.635302

Epoch: 111
Loss: 0.3414503918707761
ROC train: 0.913833	val: 0.571691	test: 0.611769
PRC train: 0.874203	val: 0.648549	test: 0.632638

Epoch: 112
Loss: 0.3456428727340442
ROC train: 0.915935	val: 0.563083	test: 0.613293
PRC train: 0.876090	val: 0.645755	test: 0.634155

Epoch: 113
Loss: 0.3447429731191963
ROC train: 0.915932	val: 0.566340	test: 0.619969
PRC train: 0.875198	val: 0.649355	test: 0.634395

Epoch: 114
Loss: 0.33922127331916935
ROC train: 0.916803	val: 0.572214	test: 0.615568
PRC train: 0.875804	val: 0.650750	test: 0.633676

Epoch: 115
Loss: 0.3415742644955425
ROC train: 0.915678	val: 0.579682	test: 0.604380
PRC train: 0.875458	val: 0.650503	test: 0.629167

Epoch: 116
Loss: 0.34089025533387335
ROC train: 0.919556	val: 0.579310	test: 0.605130
PRC train: 0.880993	val: 0.650399	test: 0.632547

Epoch: 117
Loss: 0.3394517727503865
ROC train: 0.918794	val: 0.570028	test: 0.605544
PRC train: 0.879354	val: 0.648250	test: 0.630438

Epoch: 118
Loss: 0.34080382909127055
ROC train: 0.921962	val: 0.578284	test: 0.616697
PRC train: 0.880820	val: 0.650428	test: 0.632485

Epoch: 119
Loss: 0.3414803335541325
ROC train: 0.921226	val: 0.583482	test: 0.606439
PRC train: 0.879574	val: 0.651622	test: 0.626824

Epoch: 120
Loss: 0.337917034627745
ROC train: 0.922449	val: 0.569157	test: 0.600542
PRC train: 0.885579	val: 0.649861	test: 0.629815

Epoch: 121
Loss: 0.33413431732810395
ROC train: 0.921248	val: 0.570415	test: 0.608203
PRC train: 0.885909	val: 0.651632	test: 0.631979

Epoch: 122
Loss: 0.33445936194014547
ROC train: 0.925204	val: 0.574022	test: 0.608016
PRC train: 0.890213	val: 0.651234	test: 0.632817

Epoch: 123
Loss: 0.3365542640444694
ROC train: 0.925112	val: 0.570811	test: 0.599278
PRC train: 0.889746	val: 0.648796	test: 0.629408

Epoch: 124
Loss: 0.32748317767148927
ROC train: 0.926063	val: 0.579670	test: 0.602546
PRC train: 0.890945	val: 0.649708	test: 0.625906

Epoch: 125
Loss: 0.32942571062471615
ROC train: 0.925357	val: 0.575051	test: 0.603255
PRC train: 0.889533	val: 0.648556	test: 0.628800

Epoch: 126
Loss: 0.3344091141496555
ROC train: 0.925331	val: 0.575573	test: 0.612119
PRC train: 0.889553	val: 0.651787	test: 0.636626

Epoch: 127
Loss: 0.32092120703465
ROC train: 0.923341	val: 0.582265	test: 0.619210
PRC train: 0.889917	val: 0.651097	test: 0.635865

Epoch: 128
Loss: 0.32972926073748404
ROC train: 0.928108	val: 0.577202	test: 0.610871
PRC train: 0.895715	val: 0.648972	test: 0.633301

Epoch: 129
Loss: 0.3238837963501178
ROC train: 0.930562	val: 0.567338	test: 0.603170
PRC train: 0.898062	val: 0.646629	test: 0.627564

Epoch: 130
Loss: 0.32661951888975393
ROC train: 0.929977	val: 0.573740	test: 0.604165
PRC train: 0.892907	val: 0.648450	test: 0.628662

Epoch: 131
Loss: 0.3259453980880448
ROC train: 0.930162	val: 0.574235	test: 0.611083
PRC train: 0.895159	val: 0.648218	test: 0.631986

Epoch: 132
Loss: 0.32083428307125805
ROC train: 0.933054	val: 0.573614	test: 0.613567
PRC train: 0.899986	val: 0.647579	test: 0.635283

Epoch: 133
Loss: 0.3212414330682085
ROC train: 0.934947	val: 0.577245	test: 0.609490
PRC train: 0.899990	val: 0.649943	test: 0.635227

Epoch: 134
Loss: 0.3182792797578382
ROC train: 0.934710	val: 0.578331	test: 0.602806
PRC train: 0.898155	val: 0.651651	test: 0.631432

Epoch: 135
Loss: 0.31978654853808786
ROC train: 0.935832	val: 0.576467	test: 0.605153
PRC train: 0.901976	val: 0.649289	test: 0.631698

Epoch: 136
Loss: 0.3146797184966469
ROC train: 0.933962	val: 0.576247	test: 0.611620
PRC train: 0.900363	val: 0.646745	test: 0.630401

Epoch: 137
Loss: 0.3154608902978858
ROC train: 0.935662	val: 0.569225	test: 0.613421
PRC train: 0.902303	val: 0.645294	test: 0.632925

Epoch: 138
Loss: 0.3206464495216255
ROC train: 0.938550	val: 0.570389	test: 0.611222
PRC train: 0.905775	val: 0.645652	test: 0.632051

Epoch: 139
Loss: 0.31520012217293125
ROC train: 0.938279	val: 0.575811	test: 0.608861
PRC train: 0.907508	val: 0.649035	test: 0.632056

Epoch: 140
Loss: 0.31037096102188677
ROC train: 0.938211	val: 0.572859	test: 0.604041
PRC train: 0.908474	val: 0.647729	test: 0.633428

Epoch: 141
Loss: 0.3147830557823674
ROC train: 0.936185	val: 0.569716	test: 0.603657
PRC train: 0.904787	val: 0.648007	test: 0.630807

Epoch: 142
Loss: 0.31076223775533707
ROC train: 0.939291	val: 0.571942	test: 0.607930
PRC train: 0.908463	val: 0.645163	test: 0.628874

Epoch: 143
Loss: 0.31264326039676926
ROC train: 0.939828	val: 0.570488	test: 0.615388
PRC train: 0.911614	val: 0.645024	test: 0.634576

Epoch: 144
Loss: 0.30775286241930533
ROC train: 0.940450	val: 0.573113	test: 0.614969
PRC train: 0.914828	val: 0.649215	test: 0.639201

Epoch: 145
Loss: 0.31013492700001005
ROC train: 0.942185	val: 0.577452	test: 0.609180
PRC train: 0.914638	val: 0.650058	test: 0.635075

Epoch: 146
Loss: 0.3104865977106182
ROC train: 0.940843	val: 0.572845	test: 0.606760
PRC train: 0.912243	val: 0.648076	test: 0.629900

Epoch: 147
Loss: 0.314098387016323
ROC train: 0.941147	val: 0.578083	test: 0.605916
PRC train: 0.912568	val: 0.646753	test: 0.627049

Epoch: 148
Loss: 0.3084129589532985
ROC train: 0.938836	val: 0.579056	test: 0.610542
PRC train: 0.914236	val: 0.647884	test: 0.629806

Epoch: 149
Loss: 0.3069579727935101
ROC train: 0.941500	val: 0.571020	test: 0.612758
PRC train: 0.915918	val: 0.649586	test: 0.633595

Epoch: 150
Loss: 0.30926820227745344
ROC train: 0.944420	val: 0.572786	test: 0.608877
PRC train: 0.918081	val: 0.648464	test: 0.632569

Epoch: 151
Loss: 0.3028518618449615
ROC train: 0.945250	val: 0.567643	test: 0.603608
PRC train: 0.917890	val: 0.645993	test: 0.631790

Epoch: 152
Loss: 0.3029166330799377
ROC train: 0.946298	val: 0.569044	test: 0.607699
PRC train: 0.918739	val: 0.647334	test: 0.634949

Epoch: 153
Loss: 0.30058509404805633
ROC train: 0.946670	val: 0.574333	test: 0.605115
PRC train: 0.918703	val: 0.645918	test: 0.629615

Epoch: 154
Loss: 0.3000967356551324
ROC train: 0.946301	val: 0.573454	test: 0.598924
PRC train: 0.918271	val: 0.644377	test: 0.623251

Early stopping
Best (ROC):	 train: 0.921226	val: 0.583482	test: 0.606439
Best (PRC):	 train: 0.879574	val: 0.651622	test: 0.626824

ROC train: 0.895395	val: 0.568677	test: 0.632944
PRC train: 0.856300	val: 0.650308	test: 0.649831

Epoch: 95
Loss: 0.369853416136997
ROC train: 0.897837	val: 0.577158	test: 0.640368
PRC train: 0.860179	val: 0.651227	test: 0.651391

Epoch: 96
Loss: 0.36496387335542024
ROC train: 0.901968	val: 0.584297	test: 0.630991
PRC train: 0.862890	val: 0.655550	test: 0.646886

Epoch: 97
Loss: 0.3581209436919655
ROC train: 0.901602	val: 0.575565	test: 0.622585
PRC train: 0.861818	val: 0.655926	test: 0.644353

Epoch: 98
Loss: 0.35467953894893917
ROC train: 0.901943	val: 0.579797	test: 0.622795
PRC train: 0.862743	val: 0.655580	test: 0.646931

Epoch: 99
Loss: 0.35853294184619866
ROC train: 0.904394	val: 0.588022	test: 0.620027
PRC train: 0.865618	val: 0.660123	test: 0.643913

Epoch: 100
Loss: 0.35673113410055435
ROC train: 0.899247	val: 0.586116	test: 0.619530
PRC train: 0.858749	val: 0.658117	test: 0.642016

Epoch: 101
Loss: 0.35845792807537274
ROC train: 0.903880	val: 0.583867	test: 0.621795
PRC train: 0.864868	val: 0.658421	test: 0.644521

Epoch: 102
Loss: 0.35568657295559225
ROC train: 0.906719	val: 0.582321	test: 0.623964
PRC train: 0.869844	val: 0.654842	test: 0.646995

Epoch: 103
Loss: 0.3496093154644953
ROC train: 0.906842	val: 0.578084	test: 0.628872
PRC train: 0.870432	val: 0.652273	test: 0.651985

Epoch: 104
Loss: 0.35659729850804256
ROC train: 0.908076	val: 0.577422	test: 0.625019
PRC train: 0.870414	val: 0.655203	test: 0.644597

Epoch: 105
Loss: 0.3518337209137081
ROC train: 0.912332	val: 0.581193	test: 0.623745
PRC train: 0.876899	val: 0.658095	test: 0.644363

Epoch: 106
Loss: 0.3510804605041943
ROC train: 0.911666	val: 0.585199	test: 0.629897
PRC train: 0.877177	val: 0.659291	test: 0.650243

Epoch: 107
Loss: 0.3508111481863887
ROC train: 0.912792	val: 0.576578	test: 0.631622
PRC train: 0.878009	val: 0.657440	test: 0.653295

Epoch: 108
Loss: 0.3504200207456789
ROC train: 0.913689	val: 0.575618	test: 0.628673
PRC train: 0.876234	val: 0.657412	test: 0.650549

Epoch: 109
Loss: 0.34377720091275143
ROC train: 0.915231	val: 0.582556	test: 0.622633
PRC train: 0.878895	val: 0.659659	test: 0.644455

Epoch: 110
Loss: 0.34670762222778506
ROC train: 0.914706	val: 0.590316	test: 0.623765
PRC train: 0.880074	val: 0.659662	test: 0.645493

Epoch: 111
Loss: 0.342780051724612
ROC train: 0.917503	val: 0.591126	test: 0.627002
PRC train: 0.883540	val: 0.656818	test: 0.648215

Epoch: 112
Loss: 0.34365267264781996
ROC train: 0.919855	val: 0.591005	test: 0.626819
PRC train: 0.886054	val: 0.659494	test: 0.650670

Epoch: 113
Loss: 0.3418914112577178
ROC train: 0.920235	val: 0.589384	test: 0.624667
PRC train: 0.885463	val: 0.660329	test: 0.649546

Epoch: 114
Loss: 0.3382604308386748
ROC train: 0.919748	val: 0.583407	test: 0.625181
PRC train: 0.886519	val: 0.656848	test: 0.647948

Epoch: 115
Loss: 0.33904165991600577
ROC train: 0.919621	val: 0.576014	test: 0.619402
PRC train: 0.886230	val: 0.652870	test: 0.646321

Epoch: 116
Loss: 0.34048478082894595
ROC train: 0.917535	val: 0.584233	test: 0.621230
PRC train: 0.884555	val: 0.654002	test: 0.645518

Epoch: 117
Loss: 0.34261547761185507
ROC train: 0.920671	val: 0.576918	test: 0.618982
PRC train: 0.887748	val: 0.652061	test: 0.644373

Epoch: 118
Loss: 0.33649738466547796
ROC train: 0.924383	val: 0.572196	test: 0.622765
PRC train: 0.891882	val: 0.652370	test: 0.647667

Epoch: 119
Loss: 0.3326635044671774
ROC train: 0.922864	val: 0.572798	test: 0.628206
PRC train: 0.890236	val: 0.652769	test: 0.651937

Epoch: 120
Loss: 0.3331429158991774
ROC train: 0.924839	val: 0.573688	test: 0.625779
PRC train: 0.891851	val: 0.651659	test: 0.647892

Epoch: 121
Loss: 0.3280000785535548
ROC train: 0.922870	val: 0.578068	test: 0.616924
PRC train: 0.890797	val: 0.650544	test: 0.641489

Epoch: 122
Loss: 0.33330591205980636
ROC train: 0.922117	val: 0.583103	test: 0.613399
PRC train: 0.891358	val: 0.653831	test: 0.642510

Epoch: 123
Loss: 0.33277983231557684
ROC train: 0.927387	val: 0.580489	test: 0.622177
PRC train: 0.897692	val: 0.655334	test: 0.647258

Epoch: 124
Loss: 0.32787846832047346
ROC train: 0.927665	val: 0.581282	test: 0.626624
PRC train: 0.898683	val: 0.653828	test: 0.649300

Epoch: 125
Loss: 0.3275221738435922
ROC train: 0.929517	val: 0.583978	test: 0.622447
PRC train: 0.900209	val: 0.657210	test: 0.649711

Epoch: 126
Loss: 0.32267991127661705
ROC train: 0.928274	val: 0.580891	test: 0.614831
PRC train: 0.898205	val: 0.655845	test: 0.644465

Epoch: 127
Loss: 0.32589848485865064
ROC train: 0.930541	val: 0.585333	test: 0.618448
PRC train: 0.900833	val: 0.658389	test: 0.646637

Epoch: 128
Loss: 0.32520502060458967
ROC train: 0.931115	val: 0.589881	test: 0.624069
PRC train: 0.902698	val: 0.658720	test: 0.651253

Epoch: 129
Loss: 0.3270575486835844
ROC train: 0.931206	val: 0.586216	test: 0.620784
PRC train: 0.903798	val: 0.654359	test: 0.649551

Epoch: 130
Loss: 0.3215594832103218
ROC train: 0.931974	val: 0.584045	test: 0.620272
PRC train: 0.903265	val: 0.653012	test: 0.644834

Epoch: 131
Loss: 0.31683192345764644
ROC train: 0.935428	val: 0.588103	test: 0.618079
PRC train: 0.906292	val: 0.658164	test: 0.645163

Epoch: 132
Loss: 0.31835684240553774
ROC train: 0.936488	val: 0.593942	test: 0.622511
PRC train: 0.910351	val: 0.661839	test: 0.647434

Epoch: 133
Loss: 0.3216953544924783
ROC train: 0.935579	val: 0.587879	test: 0.625113
PRC train: 0.908866	val: 0.659236	test: 0.646657

Epoch: 134
Loss: 0.31943102589706657
ROC train: 0.935929	val: 0.582806	test: 0.623254
PRC train: 0.908752	val: 0.655029	test: 0.645066

Epoch: 135
Loss: 0.32048707565103157
ROC train: 0.937256	val: 0.586909	test: 0.620470
PRC train: 0.910530	val: 0.656338	test: 0.646494

Epoch: 136
Loss: 0.31726519102478545
ROC train: 0.938154	val: 0.586011	test: 0.624685
PRC train: 0.912309	val: 0.656587	test: 0.649279

Epoch: 137
Loss: 0.31784294020894754
ROC train: 0.936999	val: 0.592682	test: 0.635443
PRC train: 0.910550	val: 0.656129	test: 0.654266

Epoch: 138
Loss: 0.31606671923119345
ROC train: 0.936568	val: 0.590842	test: 0.631837
PRC train: 0.907530	val: 0.654067	test: 0.653250

Epoch: 139
Loss: 0.31492699205010094
ROC train: 0.938417	val: 0.588085	test: 0.621982
PRC train: 0.910080	val: 0.654792	test: 0.650123

Epoch: 140
Loss: 0.3108373654274142
ROC train: 0.939602	val: 0.587212	test: 0.621059
PRC train: 0.911256	val: 0.654265	test: 0.650410

Epoch: 141
Loss: 0.30982909351189525
ROC train: 0.940662	val: 0.581186	test: 0.622475
PRC train: 0.911640	val: 0.650959	test: 0.653529

Epoch: 142
Loss: 0.3109227554174536
ROC train: 0.940878	val: 0.582016	test: 0.622648
PRC train: 0.913380	val: 0.652256	test: 0.647776

Epoch: 143
Loss: 0.3072789110520179
ROC train: 0.940238	val: 0.586778	test: 0.623457
PRC train: 0.914062	val: 0.658511	test: 0.646247

Epoch: 144
Loss: 0.31045344099093225
ROC train: 0.942307	val: 0.588363	test: 0.623758
PRC train: 0.918662	val: 0.658526	test: 0.647308

Epoch: 145
Loss: 0.305173846644207
ROC train: 0.941571	val: 0.585032	test: 0.619534
PRC train: 0.917171	val: 0.656096	test: 0.647948

Epoch: 146
Loss: 0.30313119956390255
ROC train: 0.940667	val: 0.580707	test: 0.620601
PRC train: 0.914872	val: 0.652893	test: 0.646642

Epoch: 147
Loss: 0.30432464535851106
ROC train: 0.941104	val: 0.579653	test: 0.621755
PRC train: 0.914680	val: 0.653116	test: 0.647496

Epoch: 148
Loss: 0.3043194229269887
ROC train: 0.944414	val: 0.586864	test: 0.623375
PRC train: 0.920739	val: 0.656010	test: 0.649946

Epoch: 149
Loss: 0.29922520348831777
ROC train: 0.945414	val: 0.589169	test: 0.624929
PRC train: 0.922056	val: 0.656369	test: 0.649497

Epoch: 150
Loss: 0.3020228379369637
ROC train: 0.946799	val: 0.587208	test: 0.623400
PRC train: 0.920914	val: 0.657047	test: 0.647852

Epoch: 151
Loss: 0.29769476585766586
ROC train: 0.947521	val: 0.584510	test: 0.625319
PRC train: 0.921867	val: 0.657395	test: 0.651263

Epoch: 152
Loss: 0.29518112074245223
ROC train: 0.942401	val: 0.587082	test: 0.628274
PRC train: 0.916192	val: 0.657684	test: 0.650943

Epoch: 153
Loss: 0.2994106210885663
ROC train: 0.946599	val: 0.584987	test: 0.625681
PRC train: 0.921413	val: 0.658260	test: 0.649748

Epoch: 154
Loss: 0.2982997351738302
ROC train: 0.948003	val: 0.581138	test: 0.621806
PRC train: 0.924279	val: 0.656584	test: 0.650442
PRC train: 0.856392	val: 0.683118	test: 0.626263

Epoch: 95
Loss: 0.3654041332739364
ROC train: 0.900023	val: 0.639069	test: 0.582880
PRC train: 0.864843	val: 0.680100	test: 0.624939

Epoch: 96
Loss: 0.365380338333264
ROC train: 0.898093	val: 0.637901	test: 0.584401
PRC train: 0.861816	val: 0.674508	test: 0.628595

Epoch: 97
Loss: 0.36685519793674004
ROC train: 0.900570	val: 0.636844	test: 0.577062
PRC train: 0.863234	val: 0.678573	test: 0.625379

Epoch: 98
Loss: 0.36237689754970537
ROC train: 0.900629	val: 0.623422	test: 0.587632
PRC train: 0.866447	val: 0.676803	test: 0.621915

Epoch: 99
Loss: 0.366176483806538
ROC train: 0.902345	val: 0.630002	test: 0.582205
PRC train: 0.864055	val: 0.679917	test: 0.625324

Epoch: 100
Loss: 0.35590697205870525
ROC train: 0.904260	val: 0.626037	test: 0.586115
PRC train: 0.868484	val: 0.671549	test: 0.628820

Epoch: 101
Loss: 0.3633830677553229
ROC train: 0.906873	val: 0.618774	test: 0.594422
PRC train: 0.871731	val: 0.666154	test: 0.628005

Epoch: 102
Loss: 0.3558616019982902
ROC train: 0.909142	val: 0.627415	test: 0.584368
PRC train: 0.873666	val: 0.673258	test: 0.618264

Epoch: 103
Loss: 0.3549530197119749
ROC train: 0.906099	val: 0.625964	test: 0.576420
PRC train: 0.868588	val: 0.669473	test: 0.618635

Epoch: 104
Loss: 0.3520705517475181
ROC train: 0.908876	val: 0.634117	test: 0.578823
PRC train: 0.873957	val: 0.677572	test: 0.624623

Epoch: 105
Loss: 0.3639272584653054
ROC train: 0.908662	val: 0.633733	test: 0.581067
PRC train: 0.872891	val: 0.671050	test: 0.624872

Epoch: 106
Loss: 0.3569083449148904
ROC train: 0.909798	val: 0.640071	test: 0.585302
PRC train: 0.875325	val: 0.678315	test: 0.623202

Epoch: 107
Loss: 0.3556163895117146
ROC train: 0.907916	val: 0.625242	test: 0.584472
PRC train: 0.874758	val: 0.672746	test: 0.624057

Epoch: 108
Loss: 0.3528933995642416
ROC train: 0.909836	val: 0.640058	test: 0.582364
PRC train: 0.875914	val: 0.683632	test: 0.622943

Epoch: 109
Loss: 0.35380736134359647
ROC train: 0.910107	val: 0.643156	test: 0.569889
PRC train: 0.873289	val: 0.685311	test: 0.622998

Epoch: 110
Loss: 0.3507571214762129
ROC train: 0.913645	val: 0.640142	test: 0.575206
PRC train: 0.879049	val: 0.683822	test: 0.622536

Epoch: 111
Loss: 0.3467800301560914
ROC train: 0.914603	val: 0.627206	test: 0.571278
PRC train: 0.882052	val: 0.673072	test: 0.621748

Epoch: 112
Loss: 0.34990670164832
ROC train: 0.914921	val: 0.621837	test: 0.572313
PRC train: 0.881881	val: 0.669307	test: 0.620661

Epoch: 113
Loss: 0.3440055428528672
ROC train: 0.916152	val: 0.633330	test: 0.581970
PRC train: 0.882568	val: 0.672857	test: 0.621988

Epoch: 114
Loss: 0.3449942525173828
ROC train: 0.918046	val: 0.634777	test: 0.575937
PRC train: 0.883488	val: 0.679121	test: 0.622152

Epoch: 115
Loss: 0.34262716019418576
ROC train: 0.916773	val: 0.624189	test: 0.568009
PRC train: 0.881733	val: 0.673657	test: 0.618030

Epoch: 116
Loss: 0.34079630288345025
ROC train: 0.918322	val: 0.623773	test: 0.570951
PRC train: 0.883528	val: 0.670692	test: 0.616871

Epoch: 117
Loss: 0.34654253205274443
ROC train: 0.919999	val: 0.626367	test: 0.583759
PRC train: 0.885681	val: 0.674911	test: 0.621664

Epoch: 118
Loss: 0.33929901416588587
ROC train: 0.918407	val: 0.618854	test: 0.586209
PRC train: 0.885064	val: 0.672922	test: 0.625165

Epoch: 119
Loss: 0.33783172759679264
ROC train: 0.920689	val: 0.620271	test: 0.584006
PRC train: 0.889963	val: 0.666551	test: 0.627153

Epoch: 120
Loss: 0.3369844792224338
ROC train: 0.922605	val: 0.623199	test: 0.585480
PRC train: 0.891732	val: 0.672965	test: 0.627978

Epoch: 121
Loss: 0.3305740585164288
ROC train: 0.922438	val: 0.632551	test: 0.572491
PRC train: 0.889471	val: 0.675671	test: 0.624181

Epoch: 122
Loss: 0.33798986383905405
ROC train: 0.922531	val: 0.624698	test: 0.574610
PRC train: 0.888613	val: 0.671634	test: 0.622528

Epoch: 123
Loss: 0.3311674801826963
ROC train: 0.924877	val: 0.623081	test: 0.570404
PRC train: 0.891024	val: 0.671399	test: 0.620798

Epoch: 124
Loss: 0.33622348759500825
ROC train: 0.925467	val: 0.620623	test: 0.579190
PRC train: 0.891343	val: 0.672174	test: 0.628294

Epoch: 125
Loss: 0.3385536283828498
ROC train: 0.926482	val: 0.618450	test: 0.582144
PRC train: 0.895111	val: 0.670424	test: 0.626130

Epoch: 126
Loss: 0.33073881946622646
ROC train: 0.924441	val: 0.628157	test: 0.580404
PRC train: 0.893069	val: 0.673028	test: 0.624003

Epoch: 127
Loss: 0.3364489183223444
ROC train: 0.926527	val: 0.636440	test: 0.576072
PRC train: 0.894020	val: 0.681000	test: 0.627810

Epoch: 128
Loss: 0.32782409955466774
ROC train: 0.926519	val: 0.641700	test: 0.583386
PRC train: 0.893608	val: 0.684531	test: 0.632132

Epoch: 129
Loss: 0.32943454815859907
ROC train: 0.928735	val: 0.641515	test: 0.579416
PRC train: 0.895160	val: 0.684042	test: 0.628606

Epoch: 130
Loss: 0.3244700649529358
ROC train: 0.929246	val: 0.637656	test: 0.579417
PRC train: 0.898691	val: 0.681432	test: 0.623696

Epoch: 131
Loss: 0.3295277008569716
ROC train: 0.932378	val: 0.621630	test: 0.584517
PRC train: 0.900915	val: 0.672235	test: 0.626630

Epoch: 132
Loss: 0.3212992007093832
ROC train: 0.925321	val: 0.605134	test: 0.589045
PRC train: 0.891563	val: 0.660452	test: 0.632880

Epoch: 133
Loss: 0.3300913368451684
ROC train: 0.930239	val: 0.617027	test: 0.591831
PRC train: 0.898693	val: 0.668732	test: 0.629578

Epoch: 134
Loss: 0.3263937669572361
ROC train: 0.932119	val: 0.620365	test: 0.586873
PRC train: 0.899091	val: 0.666739	test: 0.628723

Epoch: 135
Loss: 0.3274497299956843
ROC train: 0.929658	val: 0.622719	test: 0.589593
PRC train: 0.894545	val: 0.671154	test: 0.631624

Epoch: 136
Loss: 0.324923183232509
ROC train: 0.934004	val: 0.627268	test: 0.577141
PRC train: 0.899123	val: 0.677520	test: 0.622554

Epoch: 137
Loss: 0.3256215855937008
ROC train: 0.932928	val: 0.625658	test: 0.581096
PRC train: 0.898572	val: 0.675201	test: 0.625647

Epoch: 138
Loss: 0.3198761182458504
ROC train: 0.931057	val: 0.620306	test: 0.576365
PRC train: 0.898186	val: 0.666490	test: 0.627260

Epoch: 139
Loss: 0.3184378433651228
ROC train: 0.935999	val: 0.617084	test: 0.583774
PRC train: 0.906802	val: 0.670114	test: 0.630005

Epoch: 140
Loss: 0.31628681074273607
ROC train: 0.938109	val: 0.625780	test: 0.581961
PRC train: 0.908635	val: 0.677311	test: 0.626258

Epoch: 141
Loss: 0.3166422991615606
ROC train: 0.937998	val: 0.616288	test: 0.583070
PRC train: 0.907002	val: 0.667610	test: 0.624251

Epoch: 142
Loss: 0.31856209188762075
ROC train: 0.939454	val: 0.623007	test: 0.583400
PRC train: 0.909876	val: 0.669503	test: 0.629299

Epoch: 143
Loss: 0.31737531947641345
ROC train: 0.936838	val: 0.614131	test: 0.589198
PRC train: 0.907305	val: 0.665578	test: 0.630642

Epoch: 144
Loss: 0.3191059552176281
ROC train: 0.940338	val: 0.622071	test: 0.578578
PRC train: 0.913439	val: 0.675853	test: 0.624544

Early stopping
Best (ROC):	 train: 0.910107	val: 0.643156	test: 0.569889
Best (PRC):	 train: 0.873289	val: 0.685311	test: 0.622998


Epoch: 155
Loss: 0.2999368286965413
ROC train: 0.948795	val: 0.581201	test: 0.618532
PRC train: 0.926445	val: 0.652794	test: 0.649476

Epoch: 156
Loss: 0.2910626095151413
ROC train: 0.949412	val: 0.577771	test: 0.615797
PRC train: 0.926467	val: 0.650950	test: 0.647711

Epoch: 157
Loss: 0.2974063276597055
ROC train: 0.950749	val: 0.583379	test: 0.618364
PRC train: 0.927235	val: 0.653836	test: 0.643721

Epoch: 158
Loss: 0.29873074793627824
ROC train: 0.948720	val: 0.591701	test: 0.617305
PRC train: 0.923991	val: 0.656612	test: 0.642331

Epoch: 159
Loss: 0.2916057836458599
ROC train: 0.951978	val: 0.591206	test: 0.613178
PRC train: 0.925427	val: 0.657564	test: 0.644638

Epoch: 160
Loss: 0.2900866097483228
ROC train: 0.951223	val: 0.586158	test: 0.613309
PRC train: 0.923649	val: 0.656796	test: 0.643699

Epoch: 161
Loss: 0.2933288782288836
ROC train: 0.952352	val: 0.583302	test: 0.620239
PRC train: 0.925206	val: 0.657991	test: 0.649940

Epoch: 162
Loss: 0.2941663017577808
ROC train: 0.951372	val: 0.584998	test: 0.618986
PRC train: 0.925561	val: 0.657609	test: 0.648911

Epoch: 163
Loss: 0.2863998794605131
ROC train: 0.953724	val: 0.580156	test: 0.625572
PRC train: 0.930022	val: 0.655705	test: 0.650792

Epoch: 164
Loss: 0.2890483266995697
ROC train: 0.955512	val: 0.588511	test: 0.631432
PRC train: 0.934155	val: 0.659020	test: 0.652337

Epoch: 165
Loss: 0.28272886242037243
ROC train: 0.955474	val: 0.591528	test: 0.629493
PRC train: 0.934919	val: 0.659638	test: 0.650664

Epoch: 166
Loss: 0.2821915446375429
ROC train: 0.955132	val: 0.589785	test: 0.625001
PRC train: 0.932437	val: 0.658247	test: 0.646297

Epoch: 167
Loss: 0.28841102422415277
ROC train: 0.954949	val: 0.587453	test: 0.619961
PRC train: 0.930737	val: 0.657872	test: 0.642943

Early stopping
Best (ROC):	 train: 0.936488	val: 0.593942	test: 0.622511
Best (PRC):	 train: 0.910351	val: 0.661839	test: 0.647434

ROC train: 0.894842	val: 0.634803	test: 0.591625
PRC train: 0.859238	val: 0.676325	test: 0.633620

Epoch: 95
Loss: 0.3623617964181244
ROC train: 0.898631	val: 0.637060	test: 0.597320
PRC train: 0.862902	val: 0.679001	test: 0.635256

Epoch: 96
Loss: 0.3614647092221583
ROC train: 0.901295	val: 0.640387	test: 0.604865
PRC train: 0.865113	val: 0.676022	test: 0.633738

Epoch: 97
Loss: 0.36078157574328235
ROC train: 0.899711	val: 0.643884	test: 0.584585
PRC train: 0.863140	val: 0.679139	test: 0.627903

Epoch: 98
Loss: 0.35418992657570547
ROC train: 0.898331	val: 0.639827	test: 0.594213
PRC train: 0.862587	val: 0.676897	test: 0.634196

Epoch: 99
Loss: 0.35786031889727066
ROC train: 0.901192	val: 0.637114	test: 0.600413
PRC train: 0.862444	val: 0.674107	test: 0.633276

Epoch: 100
Loss: 0.358982668747745
ROC train: 0.903469	val: 0.637740	test: 0.594172
PRC train: 0.866955	val: 0.675398	test: 0.631994

Epoch: 101
Loss: 0.3535571286211337
ROC train: 0.903885	val: 0.640736	test: 0.584248
PRC train: 0.869932	val: 0.677924	test: 0.626297

Epoch: 102
Loss: 0.354263321306524
ROC train: 0.906469	val: 0.652286	test: 0.585930
PRC train: 0.870652	val: 0.683228	test: 0.627720

Epoch: 103
Loss: 0.35262211984487485
ROC train: 0.909246	val: 0.651625	test: 0.593342
PRC train: 0.875637	val: 0.682232	test: 0.635879

Epoch: 104
Loss: 0.35374439805851654
ROC train: 0.908351	val: 0.636716	test: 0.595818
PRC train: 0.875227	val: 0.675208	test: 0.640790

Epoch: 105
Loss: 0.35382876606904784
ROC train: 0.909280	val: 0.637647	test: 0.592363
PRC train: 0.875809	val: 0.675671	test: 0.633692

Epoch: 106
Loss: 0.3528314556748412
ROC train: 0.910018	val: 0.637269	test: 0.590954
PRC train: 0.876099	val: 0.674266	test: 0.632062

Epoch: 107
Loss: 0.3509572129792128
ROC train: 0.906007	val: 0.629166	test: 0.577810
PRC train: 0.871495	val: 0.670186	test: 0.623133

Epoch: 108
Loss: 0.3469560318621854
ROC train: 0.911011	val: 0.637453	test: 0.593321
PRC train: 0.878286	val: 0.676670	test: 0.628680

Epoch: 109
Loss: 0.34782618862925285
ROC train: 0.910596	val: 0.629544	test: 0.589981
PRC train: 0.880661	val: 0.672721	test: 0.629535

Epoch: 110
Loss: 0.3438543412137215
ROC train: 0.910638	val: 0.637944	test: 0.577924
PRC train: 0.881292	val: 0.675442	test: 0.625349

Epoch: 111
Loss: 0.3456514650346975
ROC train: 0.915275	val: 0.641295	test: 0.587895
PRC train: 0.885711	val: 0.677500	test: 0.629957

Epoch: 112
Loss: 0.34305805264688494
ROC train: 0.915595	val: 0.643798	test: 0.588939
PRC train: 0.885782	val: 0.679845	test: 0.630932

Epoch: 113
Loss: 0.3429828291168125
ROC train: 0.915711	val: 0.642072	test: 0.589667
PRC train: 0.886930	val: 0.677455	test: 0.628389

Epoch: 114
Loss: 0.3379802851938196
ROC train: 0.916705	val: 0.640318	test: 0.601199
PRC train: 0.888664	val: 0.677565	test: 0.632507

Epoch: 115
Loss: 0.3437326442827389
ROC train: 0.918845	val: 0.652043	test: 0.595541
PRC train: 0.891590	val: 0.677428	test: 0.632328

Epoch: 116
Loss: 0.33566504132550656
ROC train: 0.921367	val: 0.657799	test: 0.591892
PRC train: 0.893212	val: 0.678882	test: 0.630176

Epoch: 117
Loss: 0.3315545664644199
ROC train: 0.921364	val: 0.651159	test: 0.597138
PRC train: 0.891659	val: 0.681178	test: 0.633329

Epoch: 118
Loss: 0.3290474299352601
ROC train: 0.917768	val: 0.642068	test: 0.604400
PRC train: 0.887299	val: 0.674275	test: 0.635655

Epoch: 119
Loss: 0.3271713726121934
ROC train: 0.920120	val: 0.642592	test: 0.594386
PRC train: 0.889127	val: 0.674428	test: 0.630901

Epoch: 120
Loss: 0.3308214301614845
ROC train: 0.922177	val: 0.644038	test: 0.581830
PRC train: 0.893236	val: 0.675553	test: 0.625939

Epoch: 121
Loss: 0.33091171790922014
ROC train: 0.923771	val: 0.644076	test: 0.582269
PRC train: 0.893588	val: 0.673390	test: 0.626723

Epoch: 122
Loss: 0.3350120353932556
ROC train: 0.924989	val: 0.656221	test: 0.581212
PRC train: 0.894589	val: 0.678152	test: 0.631646

Epoch: 123
Loss: 0.33440500498711867
ROC train: 0.920947	val: 0.640936	test: 0.607030
PRC train: 0.890508	val: 0.673755	test: 0.643410

Epoch: 124
Loss: 0.32972180670938195
ROC train: 0.925035	val: 0.658893	test: 0.596559
PRC train: 0.897109	val: 0.680924	test: 0.635126

Epoch: 125
Loss: 0.3291779784657103
ROC train: 0.924451	val: 0.661008	test: 0.580139
PRC train: 0.896660	val: 0.682730	test: 0.629218

Epoch: 126
Loss: 0.3336255267238381
ROC train: 0.925059	val: 0.653279	test: 0.572584
PRC train: 0.895439	val: 0.680949	test: 0.629735

Epoch: 127
Loss: 0.3311705757937919
ROC train: 0.927809	val: 0.647917	test: 0.597006
PRC train: 0.898388	val: 0.683804	test: 0.640655

Epoch: 128
Loss: 0.3264820219350245
ROC train: 0.930052	val: 0.642028	test: 0.597207
PRC train: 0.901208	val: 0.678320	test: 0.639835

Epoch: 129
Loss: 0.3258932509256237
ROC train: 0.929200	val: 0.647317	test: 0.587535
PRC train: 0.901944	val: 0.677207	test: 0.636629

Epoch: 130
Loss: 0.3324584014446231
ROC train: 0.929425	val: 0.657731	test: 0.580701
PRC train: 0.902380	val: 0.683941	test: 0.635134

Epoch: 131
Loss: 0.3226326404987822
ROC train: 0.929584	val: 0.656288	test: 0.588318
PRC train: 0.902194	val: 0.682398	test: 0.635150

Epoch: 132
Loss: 0.327606423281863
ROC train: 0.930538	val: 0.646962	test: 0.575375
PRC train: 0.903739	val: 0.677130	test: 0.629798

Epoch: 133
Loss: 0.3276525570826157
ROC train: 0.930969	val: 0.652428	test: 0.569225
PRC train: 0.905817	val: 0.675648	test: 0.628680

Epoch: 134
Loss: 0.3198323795855266
ROC train: 0.930036	val: 0.648968	test: 0.588002
PRC train: 0.905456	val: 0.676093	test: 0.638323

Epoch: 135
Loss: 0.32128510270646393
ROC train: 0.931876	val: 0.645709	test: 0.599717
PRC train: 0.904970	val: 0.680065	test: 0.641539

Epoch: 136
Loss: 0.31897414231218996
ROC train: 0.935219	val: 0.655238	test: 0.578099
PRC train: 0.909082	val: 0.682263	test: 0.625445

Epoch: 137
Loss: 0.3174265328129546
ROC train: 0.936342	val: 0.654267	test: 0.566483
PRC train: 0.911093	val: 0.676794	test: 0.624636

Epoch: 138
Loss: 0.3180569473290846
ROC train: 0.935453	val: 0.646769	test: 0.578797
PRC train: 0.909975	val: 0.675604	test: 0.632675

Epoch: 139
Loss: 0.3162069454024877
ROC train: 0.935781	val: 0.652009	test: 0.597154
PRC train: 0.910668	val: 0.677406	test: 0.640889

Epoch: 140
Loss: 0.313447700156102
ROC train: 0.934927	val: 0.650402	test: 0.596052
PRC train: 0.909279	val: 0.679568	test: 0.635279

Epoch: 141
Loss: 0.3102574376357529
ROC train: 0.935792	val: 0.650880	test: 0.590943
PRC train: 0.909570	val: 0.678198	test: 0.635468

Epoch: 142
Loss: 0.31889744856180385
ROC train: 0.938389	val: 0.654335	test: 0.588898
PRC train: 0.914761	val: 0.677102	test: 0.636872

Epoch: 143
Loss: 0.31113360544446145
ROC train: 0.939061	val: 0.664272	test: 0.586148
PRC train: 0.915151	val: 0.684769	test: 0.637253

Epoch: 144
Loss: 0.31740041621663434
ROC train: 0.939285	val: 0.655010	test: 0.582568
PRC train: 0.914911	val: 0.680633	test: 0.635680

Epoch: 145
Loss: 0.3130012537933266
ROC train: 0.937406	val: 0.646857	test: 0.590133
PRC train: 0.913597	val: 0.679571	test: 0.632027

Epoch: 146
Loss: 0.3089586289114376
ROC train: 0.939289	val: 0.651033	test: 0.586012
PRC train: 0.914542	val: 0.676376	test: 0.631906

Epoch: 147
Loss: 0.3057164842648033
ROC train: 0.941366	val: 0.652639	test: 0.581767
PRC train: 0.915561	val: 0.674457	test: 0.630219

Epoch: 148
Loss: 0.3056348605690549
ROC train: 0.942270	val: 0.658027	test: 0.587279
PRC train: 0.917906	val: 0.679805	test: 0.635341

Epoch: 149
Loss: 0.3043044507589854
ROC train: 0.944398	val: 0.654658	test: 0.594039
PRC train: 0.920318	val: 0.678374	test: 0.636809

Epoch: 150
Loss: 0.30112529648679226
ROC train: 0.943272	val: 0.651405	test: 0.586379
PRC train: 0.918716	val: 0.678297	test: 0.635430

Epoch: 151
Loss: 0.30008864955430126
ROC train: 0.942736	val: 0.649879	test: 0.582928
PRC train: 0.918149	val: 0.686089	test: 0.635485

Epoch: 152
Loss: 0.30583758634004854
ROC train: 0.945084	val: 0.649555	test: 0.581271
PRC train: 0.922151	val: 0.683184	test: 0.634101

Epoch: 153
Loss: 0.29798882043318986
ROC train: 0.944429	val: 0.644821	test: 0.581412
PRC train: 0.922557	val: 0.677234	test: 0.633172

Epoch: 154
Loss: 0.30048752648137145
ROC train: 0.944930	val: 0.657153	test: 0.580520
PRC train: 0.923031	val: 0.684055	test: 0.636585All runs completed.

ROC train: 0.941079	val: 0.565961	test: 0.602169
PRC train: 0.908445	val: 0.637496	test: 0.637614

Epoch: 156
Loss: 0.3030438911868653
ROC train: 0.939556	val: 0.557665	test: 0.603417
PRC train: 0.903158	val: 0.632938	test: 0.639059

Epoch: 157
Loss: 0.29955571496712863
ROC train: 0.941064	val: 0.561364	test: 0.602229
PRC train: 0.904404	val: 0.634110	test: 0.637784

Epoch: 158
Loss: 0.30250623492550616
ROC train: 0.941269	val: 0.565672	test: 0.602397
PRC train: 0.906372	val: 0.636114	test: 0.639934

Epoch: 159
Loss: 0.303471956012197
ROC train: 0.943421	val: 0.565689	test: 0.598355
PRC train: 0.910959	val: 0.635815	test: 0.637605

Epoch: 160
Loss: 0.2988927751927928
ROC train: 0.943316	val: 0.561987	test: 0.593859
PRC train: 0.911628	val: 0.633045	test: 0.633783

Epoch: 161
Loss: 0.2974690476240285
ROC train: 0.943126	val: 0.560762	test: 0.595309
PRC train: 0.912794	val: 0.631980	test: 0.635126

Epoch: 162
Loss: 0.2980777658174334
ROC train: 0.945064	val: 0.566623	test: 0.599168
PRC train: 0.913157	val: 0.636605	test: 0.639145

Epoch: 163
Loss: 0.29686342499195395
ROC train: 0.945038	val: 0.571485	test: 0.595377
PRC train: 0.912858	val: 0.641930	test: 0.636225

Epoch: 164
Loss: 0.2981293473782315
ROC train: 0.946190	val: 0.570956	test: 0.597566
PRC train: 0.914355	val: 0.640669	test: 0.638747

Epoch: 165
Loss: 0.2934552198807685
ROC train: 0.945109	val: 0.568881	test: 0.596965
PRC train: 0.911604	val: 0.639038	test: 0.640443

Epoch: 166
Loss: 0.2920377791251108
ROC train: 0.947870	val: 0.565697	test: 0.601231
PRC train: 0.916404	val: 0.639211	test: 0.642610

Epoch: 167
Loss: 0.2922566928030929
ROC train: 0.946568	val: 0.568396	test: 0.605248
PRC train: 0.915421	val: 0.641406	test: 0.641794

Epoch: 168
Loss: 0.2914005850285395
ROC train: 0.947697	val: 0.571622	test: 0.603010
PRC train: 0.915073	val: 0.642770	test: 0.642979

Epoch: 169
Loss: 0.2922922689745491
ROC train: 0.944874	val: 0.565624	test: 0.596060
PRC train: 0.913540	val: 0.635694	test: 0.639471

Epoch: 170
Loss: 0.29233627805363577
ROC train: 0.947660	val: 0.563694	test: 0.598789
PRC train: 0.918736	val: 0.633728	test: 0.637268

Epoch: 171
Loss: 0.2854964283397903
ROC train: 0.949751	val: 0.565375	test: 0.598092
PRC train: 0.922304	val: 0.636191	test: 0.636948

Epoch: 172
Loss: 0.2920712964159375
ROC train: 0.950436	val: 0.567306	test: 0.589299
PRC train: 0.921603	val: 0.635899	test: 0.633722

Epoch: 173
Loss: 0.29149026496453045
ROC train: 0.950059	val: 0.571348	test: 0.590859
PRC train: 0.920345	val: 0.638965	test: 0.635591

Epoch: 174
Loss: 0.2854732867431306
ROC train: 0.949733	val: 0.570133	test: 0.596013
PRC train: 0.920716	val: 0.638504	test: 0.639259

Epoch: 175
Loss: 0.2916211262218729
ROC train: 0.952809	val: 0.565228	test: 0.599929
PRC train: 0.920909	val: 0.638687	test: 0.643472

Epoch: 176
Loss: 0.29682074643456197
ROC train: 0.953566	val: 0.565486	test: 0.593729
PRC train: 0.922743	val: 0.637886	test: 0.639026

Epoch: 177
Loss: 0.2843258488864165
ROC train: 0.953308	val: 0.570136	test: 0.588283
PRC train: 0.922414	val: 0.637774	test: 0.634967

Epoch: 178
Loss: 0.2882821244478036
ROC train: 0.952360	val: 0.567755	test: 0.587729
PRC train: 0.924104	val: 0.636475	test: 0.630938

Epoch: 179
Loss: 0.288203232990732
ROC train: 0.953782	val: 0.563289	test: 0.592020
PRC train: 0.925293	val: 0.633401	test: 0.631979

Epoch: 180
Loss: 0.2873622411298371
ROC train: 0.952462	val: 0.560183	test: 0.593476
PRC train: 0.921621	val: 0.631093	test: 0.637393

Epoch: 181
Loss: 0.2865179957959612
ROC train: 0.953707	val: 0.561942	test: 0.595294
PRC train: 0.924136	val: 0.632461	test: 0.636581

Epoch: 182
Loss: 0.2883430355819113
ROC train: 0.953579	val: 0.560551	test: 0.597387
PRC train: 0.929140	val: 0.632000	test: 0.635846

Epoch: 183
Loss: 0.2780904057530321
ROC train: 0.950381	val: 0.560126	test: 0.590809
PRC train: 0.923905	val: 0.631208	test: 0.632931

Epoch: 184
Loss: 0.2829986585825459
ROC train: 0.955629	val: 0.570521	test: 0.591836
PRC train: 0.928933	val: 0.637602	test: 0.635981

Epoch: 185
Loss: 0.27938100314603076
ROC train: 0.958209	val: 0.567206	test: 0.598031
PRC train: 0.930613	val: 0.636908	test: 0.640903

Epoch: 186
Loss: 0.2750485950662755
ROC train: 0.957446	val: 0.564260	test: 0.600079
PRC train: 0.928564	val: 0.633048	test: 0.641281

Epoch: 187
Loss: 0.2767287536915288
ROC train: 0.957322	val: 0.565605	test: 0.605139
PRC train: 0.928649	val: 0.632431	test: 0.640180

Epoch: 188
Loss: 0.27975197201729063
ROC train: 0.955408	val: 0.570580	test: 0.604631
PRC train: 0.926780	val: 0.633867	test: 0.637017

Epoch: 189
Loss: 0.2698230291553156
ROC train: 0.956747	val: 0.568020	test: 0.594259
PRC train: 0.929436	val: 0.634926	test: 0.637204

Epoch: 190
Loss: 0.2862831345455199
ROC train: 0.957912	val: 0.566137	test: 0.583202
PRC train: 0.933501	val: 0.634405	test: 0.631116

Epoch: 191
Loss: 0.268798427289184
ROC train: 0.960258	val: 0.570252	test: 0.585433
PRC train: 0.934330	val: 0.638765	test: 0.632058

Epoch: 192
Loss: 0.27167654417956166
ROC train: 0.959667	val: 0.565884	test: 0.590808
PRC train: 0.935296	val: 0.635207	test: 0.634533

Epoch: 193
Loss: 0.2771173306241078
ROC train: 0.959361	val: 0.563511	test: 0.594570
PRC train: 0.934290	val: 0.631709	test: 0.637555

Epoch: 194
Loss: 0.27502959177692177
ROC train: 0.960946	val: 0.571224	test: 0.592298
PRC train: 0.934932	val: 0.635365	test: 0.637363

Epoch: 195
Loss: 0.27016411602962115
ROC train: 0.960414	val: 0.571114	test: 0.590439
PRC train: 0.932910	val: 0.634218	test: 0.634576

Epoch: 196
Loss: 0.2697918868625393
ROC train: 0.961710	val: 0.564806	test: 0.590176
PRC train: 0.935274	val: 0.630693	test: 0.633058

Epoch: 197
Loss: 0.2699205770213416
ROC train: 0.961727	val: 0.565945	test: 0.591605
PRC train: 0.935099	val: 0.631575	test: 0.633578

Epoch: 198
Loss: 0.2685377080083927
ROC train: 0.962757	val: 0.569538	test: 0.595732
PRC train: 0.936670	val: 0.635532	test: 0.635788

Epoch: 199
Loss: 0.2656640349976887
ROC train: 0.961407	val: 0.570321	test: 0.594611
PRC train: 0.936131	val: 0.637906	test: 0.635271

Epoch: 200
Loss: 0.26553603132485626
ROC train: 0.962033	val: 0.568314	test: 0.589865
PRC train: 0.937381	val: 0.637231	test: 0.636452

Epoch: 201
Loss: 0.2600613606614966
ROC train: 0.962046	val: 0.567242	test: 0.585846
PRC train: 0.937695	val: 0.636399	test: 0.635285

Epoch: 202
Loss: 0.27010376993358426
ROC train: 0.964166	val: 0.563882	test: 0.585304
PRC train: 0.940897	val: 0.633764	test: 0.630920

Epoch: 203
Loss: 0.25687534745623136
ROC train: 0.964294	val: 0.560564	test: 0.585327
PRC train: 0.939709	val: 0.632073	test: 0.632379

Early stopping
Best (ROC):	 train: 0.947697	val: 0.571622	test: 0.603010
Best (PRC):	 train: 0.915073	val: 0.642770	test: 0.642979
All runs completed.


Epoch: 155
Loss: 0.29482746365339996
ROC train: 0.946464	val: 0.658416	test: 0.575926
PRC train: 0.924139	val: 0.682178	test: 0.631821

Epoch: 156
Loss: 0.30037860520133536
ROC train: 0.945176	val: 0.654034	test: 0.587259
PRC train: 0.920775	val: 0.681391	test: 0.638386

Epoch: 157
Loss: 0.30081178645605744
ROC train: 0.947085	val: 0.650564	test: 0.588885
PRC train: 0.923969	val: 0.680441	test: 0.638467

Epoch: 158
Loss: 0.30169532568089963
ROC train: 0.946586	val: 0.649661	test: 0.581974
PRC train: 0.924354	val: 0.679211	test: 0.635460

Epoch: 159
Loss: 0.29768159928329563
ROC train: 0.945732	val: 0.638852	test: 0.575049
PRC train: 0.921405	val: 0.676113	test: 0.631569

Epoch: 160
Loss: 0.29817788409546014
ROC train: 0.948055	val: 0.639989	test: 0.590423
PRC train: 0.925590	val: 0.676968	test: 0.639041

Epoch: 161
Loss: 0.29773536111346743
ROC train: 0.950281	val: 0.656535	test: 0.585308
PRC train: 0.928499	val: 0.682200	test: 0.635888

Epoch: 162
Loss: 0.2995741577188019
ROC train: 0.947865	val: 0.646062	test: 0.579339
PRC train: 0.925867	val: 0.674615	test: 0.634940

Epoch: 163
Loss: 0.30254715819991407
ROC train: 0.948492	val: 0.634462	test: 0.589807
PRC train: 0.927825	val: 0.669729	test: 0.640105

Epoch: 164
Loss: 0.2931964510485634
ROC train: 0.947954	val: 0.638570	test: 0.596206
PRC train: 0.926144	val: 0.676685	test: 0.639576

Epoch: 165
Loss: 0.3056075995653914
ROC train: 0.950605	val: 0.645442	test: 0.578694
PRC train: 0.927655	val: 0.674933	test: 0.635624

Epoch: 166
Loss: 0.2918989289406232
ROC train: 0.950639	val: 0.638118	test: 0.578166
PRC train: 0.930670	val: 0.675388	test: 0.636389

Epoch: 167
Loss: 0.2967221857115865
ROC train: 0.951797	val: 0.651508	test: 0.585789
PRC train: 0.931157	val: 0.682212	test: 0.637718

Epoch: 168
Loss: 0.2927608104935275
ROC train: 0.950606	val: 0.644515	test: 0.594593
PRC train: 0.928568	val: 0.682329	test: 0.645218

Epoch: 169
Loss: 0.29182010206589754
ROC train: 0.952682	val: 0.648319	test: 0.585350
PRC train: 0.929173	val: 0.678976	test: 0.638902

Epoch: 170
Loss: 0.2883145945169575
ROC train: 0.953322	val: 0.653102	test: 0.577663
PRC train: 0.930952	val: 0.676428	test: 0.632351

Epoch: 171
Loss: 0.28562467862621865
ROC train: 0.956058	val: 0.648293	test: 0.585997
PRC train: 0.934438	val: 0.674733	test: 0.636677

Epoch: 172
Loss: 0.2807482298154988
ROC train: 0.955418	val: 0.639322	test: 0.590180
PRC train: 0.935882	val: 0.675982	test: 0.640321

Epoch: 173
Loss: 0.2843717587724983
ROC train: 0.954453	val: 0.639163	test: 0.582050
PRC train: 0.933509	val: 0.677690	test: 0.636961

Epoch: 174
Loss: 0.28036364958512167
ROC train: 0.952529	val: 0.639666	test: 0.580812
PRC train: 0.931401	val: 0.676244	test: 0.634970

Epoch: 175
Loss: 0.27637444840779807
ROC train: 0.956034	val: 0.641076	test: 0.581696
PRC train: 0.936824	val: 0.678976	test: 0.634752

Epoch: 176
Loss: 0.2772729911329316
ROC train: 0.958390	val: 0.643043	test: 0.584430
PRC train: 0.938086	val: 0.677607	test: 0.638748

Epoch: 177
Loss: 0.282822911697371
ROC train: 0.956264	val: 0.639302	test: 0.591306
PRC train: 0.934829	val: 0.674220	test: 0.640717

Epoch: 178
Loss: 0.27700758874645387
ROC train: 0.955182	val: 0.638813	test: 0.590995
PRC train: 0.935397	val: 0.672981	test: 0.639403

Early stopping
Best (ROC):	 train: 0.939061	val: 0.664272	test: 0.586148
Best (PRC):	 train: 0.915151	val: 0.684769	test: 0.637253
All runs completed.
