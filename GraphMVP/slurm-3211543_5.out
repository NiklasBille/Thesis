>>> Starting run for dataset: hiv
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running RANDOM configs_static_noise_experiments/GraphMVP/hiv/noise=0.0.yml on cuda:0
Running RANDOM configs_static_noise_experiments/GraphMVP/hiv/noise=0.05.yml on cuda:1
Running RANDOM configs_static_noise_experiments/GraphMVP/hiv/noise=0.1.yml on cuda:2
Running RANDOM configs_static_noise_experiments/GraphMVP/hiv/noise=0.2.yml on cuda:3
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/hiv/noise=0.0.yml --runseed 4 --device cuda:0
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/hiv/noise=0.1.yml --runseed 4 --device cuda:2
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/hiv/noise=0.0.yml --runseed 5 --device cuda:0
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/hiv/noise=0.1.yml --runseed 5 --device cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/hiv/noise=0.2.yml --runseed 4 --device cuda:3
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/hiv/noise=0.05.yml --runseed 4 --device cuda:1
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/hiv/noise=0.0.yml --runseed 6 --device cuda:0
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/hiv/noise=0.1.yml --runseed 6 --device cuda:2
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/hiv/noise=0.2.yml --runseed 5 --device cuda:3
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/hiv/noise=0.05.yml --runseed 5 --device cuda:1
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/hiv/noise=0.2.yml --runseed 6 --device cuda:3
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphMVP/hiv/noise=0.05.yml --runseed 6 --device cuda:1
[11:19:19] WARNING: not removing hydrogen atom without neighbors
[11:19:19] WARNING: not removing hydrogen atom without neighbors
[11:19:19] WARNING: not removing hydrogen atom without neighbors
[11:19:19] WARNING: not removing hydrogen atom without neighbors
[11:19:20] WARNING: not removing hydrogen atom without neighbors
[11:19:20] WARNING: not removing hydrogen atom without neighbors
[11:19:22] WARNING: not removing hydrogen atom without neighbors
[11:19:22] WARNING: not removing hydrogen atom without neighbors
[11:19:22] WARNING: not removing hydrogen atom without neighbors
[11:19:22] WARNING: not removing hydrogen atom without neighbors
[11:19:22] WARNING: not removing hydrogen atom without neighbors
[11:19:22] WARNING: not removing hydrogen atom without neighbors
[11:19:24] WARNING: not removing hydrogen atom without neighbors
[11:19:24] WARNING: not removing hydrogen atom without neighbors
[11:19:24] WARNING: not removing hydrogen atom without neighbors
[11:19:24] WARNING: not removing hydrogen atom without neighbors
[11:19:25] WARNING: not removing hydrogen atom without neighbors
[11:19:25] WARNING: not removing hydrogen atom without neighbors
[11:19:28] WARNING: not removing hydrogen atom without neighbors
[11:19:28] WARNING: not removing hydrogen atom without neighbors
[11:19:29] WARNING: not removing hydrogen atom without neighbors
[11:19:29] WARNING: not removing hydrogen atom without neighbors
[11:19:29] WARNING: not removing hydrogen atom without neighbors
[11:19:29] WARNING: not removing hydrogen atom without neighbors
[11:19:36] WARNING: not removing hydrogen atom without neighbors
[11:19:36] WARNING: not removing hydrogen atom without neighbors
[11:19:36] WARNING: not removing hydrogen atom without neighbors
[11:19:36] WARNING: not removing hydrogen atom without neighbors
[11:19:36] WARNING: not removing hydrogen atom without neighbors
[11:19:36] WARNING: not removing hydrogen atom without neighbors
[11:19:38] WARNING: not removing hydrogen atom without neighbors
[11:19:38] WARNING: not removing hydrogen atom without neighbors
[11:19:38] WARNING: not removing hydrogen atom without neighbors
[11:19:38] WARNING: not removing hydrogen atom without neighbors
[11:19:40] WARNING: not removing hydrogen atom without neighbors
[11:19:40] WARNING: not removing hydrogen atom without neighbors
[11:19:42] WARNING: not removing hydrogen atom without neighbors
[11:19:42] WARNING: not removing hydrogen atom without neighbors
[11:19:43] WARNING: not removing hydrogen atom without neighbors
[11:19:43] WARNING: not removing hydrogen atom without neighbors
[11:19:43] WARNING: not removing hydrogen atom without neighbors
[11:19:43] WARNING: not removing hydrogen atom without neighbors
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/hiv/noise=0.0.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/hiv/noise=0.0
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/hiv/noise=0.0/hiv_scaff_5_26-05_11-19-07  ]
[ Using Seed :  5  ]
[ Using device :  cuda:0  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.2685627223853538
ROC train: 0.776595	val: 0.781850	test: 0.699573
PRC train: 0.236388	val: 0.200252	test: 0.173299

Epoch: 2
Loss: 0.1386106800729488
ROC train: 0.803917	val: 0.819264	test: 0.750801
PRC train: 0.309411	val: 0.266001	test: 0.176890

Epoch: 3
Loss: 0.13300359319119484
ROC train: 0.805377	val: 0.780512	test: 0.694681
PRC train: 0.315316	val: 0.250349	test: 0.131075

Epoch: 4
Loss: 0.12986967145543477
ROC train: 0.823161	val: 0.796134	test: 0.736304
PRC train: 0.349215	val: 0.226558	test: 0.117449

Epoch: 5
Loss: 0.1268632970252722
ROC train: 0.819385	val: 0.797840	test: 0.717270
PRC train: 0.357979	val: 0.269141	test: 0.117243

Epoch: 6
Loss: 0.12513412698544232
ROC train: 0.827577	val: 0.791318	test: 0.765019
PRC train: 0.382701	val: 0.306946	test: 0.192298

Epoch: 7
Loss: 0.12227804697110244
ROC train: 0.847083	val: 0.822846	test: 0.752127
PRC train: 0.428160	val: 0.322784	test: 0.198900

Epoch: 8
Loss: 0.12154691298259876
ROC train: 0.838028	val: 0.765720	test: 0.731175
PRC train: 0.407547	val: 0.336696	test: 0.221633

Epoch: 9
Loss: 0.11867119968278865
ROC train: 0.855034	val: 0.809989	test: 0.730431
PRC train: 0.436005	val: 0.320766	test: 0.122918

Epoch: 10
Loss: 0.11699188662260913
ROC train: 0.858443	val: 0.799113	test: 0.772508
PRC train: 0.445838	val: 0.352000	test: 0.228346

Epoch: 11
Loss: 0.11588762880802095
ROC train: 0.862917	val: 0.826851	test: 0.756882
PRC train: 0.431922	val: 0.276669	test: 0.197328

Epoch: 12
Loss: 0.11499201026040037
ROC train: 0.862784	val: 0.825538	test: 0.759826
PRC train: 0.467240	val: 0.308419	test: 0.170923

Epoch: 13
Loss: 0.11392614001756883
ROC train: 0.870847	val: 0.790868	test: 0.757672
PRC train: 0.476406	val: 0.232224	test: 0.157656

Epoch: 14
Loss: 0.11398657742365235
ROC train: 0.868307	val: 0.818899	test: 0.731142
PRC train: 0.459090	val: 0.274580	test: 0.135714

Epoch: 15
Loss: 0.11262087197331823
ROC train: 0.872429	val: 0.806636	test: 0.757935
PRC train: 0.474958	val: 0.360080	test: 0.238650

Epoch: 16
Loss: 0.11101392071524768
ROC train: 0.877288	val: 0.812815	test: 0.781840
PRC train: 0.497400	val: 0.367699	test: 0.221301

Epoch: 17
Loss: 0.11032013521337022
ROC train: 0.885157	val: 0.812858	test: 0.755391
PRC train: 0.515272	val: 0.365727	test: 0.218319

Epoch: 18
Loss: 0.11085688064905085
ROC train: 0.894156	val: 0.824040	test: 0.775824
PRC train: 0.528221	val: 0.377531	test: 0.207427

Epoch: 19
Loss: 0.1086950706739603
ROC train: 0.891869	val: 0.827136	test: 0.750138
PRC train: 0.522785	val: 0.320731	test: 0.164922

Epoch: 20
Loss: 0.1089044699853918
ROC train: 0.885397	val: 0.795626	test: 0.782348
PRC train: 0.499789	val: 0.381932	test: 0.260090

Epoch: 21
Loss: 0.10648032984507219
ROC train: 0.894794	val: 0.809153	test: 0.776664
PRC train: 0.528279	val: 0.354542	test: 0.243091

Epoch: 22
Loss: 0.10703741245999622
ROC train: 0.899702	val: 0.820127	test: 0.766007
PRC train: 0.541540	val: 0.377536	test: 0.214979

Epoch: 23
Loss: 0.10750392310491141
ROC train: 0.898865	val: 0.808734	test: 0.774499
PRC train: 0.536645	val: 0.383547	test: 0.225156

Epoch: 24
Loss: 0.10579551507112528
ROC train: 0.895476	val: 0.801376	test: 0.734352
PRC train: 0.520531	val: 0.298378	test: 0.158455

Epoch: 25
Loss: 0.10489056611993115
ROC train: 0.895711	val: 0.802607	test: 0.750235
PRC train: 0.517014	val: 0.339777	test: 0.201160

Epoch: 26
Loss: 0.10344245707816416
ROC train: 0.901597	val: 0.807218	test: 0.777103
PRC train: 0.543703	val: 0.325243	test: 0.227442

Epoch: 27
Loss: 0.10455812450651439
ROC train: 0.899390	val: 0.808587	test: 0.747834
PRC train: 0.500758	val: 0.313888	test: 0.159116

Epoch: 28
Loss: 0.10261333122734845
ROC train: 0.904234	val: 0.780867	test: 0.770152
PRC train: 0.552776	val: 0.364062	test: 0.266091

Epoch: 29
Loss: 0.10295960845074192
ROC train: 0.916160	val: 0.796342	test: 0.762690
PRC train: 0.577212	val: 0.345405	test: 0.191329

Epoch: 30
Loss: 0.10222121239103492
ROC train: 0.901871	val: 0.807993	test: 0.747600
PRC train: 0.554224	val: 0.346613	test: 0.193107

Epoch: 31
Loss: 0.10215078031028808
ROC train: 0.915474	val: 0.811015	test: 0.754777
PRC train: 0.560549	val: 0.360781	test: 0.226496

Epoch: 32
Loss: 0.10160489728983965
ROC train: 0.917478	val: 0.806753	test: 0.772678
PRC train: 0.583282	val: 0.344935	test: 0.217518

Epoch: 33
Loss: 0.10143350608041046Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/hiv/noise=0.0.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/hiv/noise=0.0
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/hiv/noise=0.0/hiv_scaff_4_26-05_11-19-07  ]
[ Using Seed :  4  ]
[ Using device :  cuda:0  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.28389955170240105
ROC train: 0.772915	val: 0.740260	test: 0.723305
PRC train: 0.224757	val: 0.161278	test: 0.205110

Epoch: 2
Loss: 0.13688817686666346
ROC train: 0.796283	val: 0.767961	test: 0.740399
PRC train: 0.304048	val: 0.208967	test: 0.195752

Epoch: 3
Loss: 0.13236475972248077
ROC train: 0.809992	val: 0.776636	test: 0.749678
PRC train: 0.355565	val: 0.256841	test: 0.221976

Epoch: 4
Loss: 0.12843731456088917
ROC train: 0.829755	val: 0.786275	test: 0.751498
PRC train: 0.382132	val: 0.319808	test: 0.232810

Epoch: 5
Loss: 0.12507121609486505
ROC train: 0.821853	val: 0.787806	test: 0.728280
PRC train: 0.338005	val: 0.196044	test: 0.097694

Epoch: 6
Loss: 0.12410735169779441
ROC train: 0.834323	val: 0.792132	test: 0.729178
PRC train: 0.392952	val: 0.262699	test: 0.122951

Epoch: 7
Loss: 0.12128716894650647
ROC train: 0.832002	val: 0.743092	test: 0.736969
PRC train: 0.406820	val: 0.268867	test: 0.221088

Epoch: 8
Loss: 0.11911796411091082
ROC train: 0.853528	val: 0.798979	test: 0.754165
PRC train: 0.435734	val: 0.307301	test: 0.219019

Epoch: 9
Loss: 0.11863098401786319
ROC train: 0.852910	val: 0.763344	test: 0.770878
PRC train: 0.434049	val: 0.308910	test: 0.193911

Epoch: 10
Loss: 0.11803660877538255
ROC train: 0.861648	val: 0.822200	test: 0.761932
PRC train: 0.452212	val: 0.324889	test: 0.187521

Epoch: 11
Loss: 0.11532895534980034
ROC train: 0.850180	val: 0.811125	test: 0.725072
PRC train: 0.420607	val: 0.272462	test: 0.091340

Epoch: 12
Loss: 0.11526520669667713
ROC train: 0.864173	val: 0.790852	test: 0.752691
PRC train: 0.468551	val: 0.275964	test: 0.166544

Epoch: 13
Loss: 0.11487913663823887
ROC train: 0.865386	val: 0.780742	test: 0.749383
PRC train: 0.482521	val: 0.264847	test: 0.243317

Epoch: 14
Loss: 0.11274182486470033
ROC train: 0.869854	val: 0.800595	test: 0.760511
PRC train: 0.464854	val: 0.270771	test: 0.195887

Epoch: 15
Loss: 0.11222194148540862
ROC train: 0.878434	val: 0.815038	test: 0.760436
PRC train: 0.508420	val: 0.324597	test: 0.236956

Epoch: 16
Loss: 0.1113202164566125
ROC train: 0.879295	val: 0.799968	test: 0.751380
PRC train: 0.505372	val: 0.276763	test: 0.198961

Epoch: 17
Loss: 0.11262308960325919
ROC train: 0.883379	val: 0.766467	test: 0.749771
PRC train: 0.509460	val: 0.297766	test: 0.191925

Epoch: 18
Loss: 0.10954970926031936
ROC train: 0.877980	val: 0.781988	test: 0.725408
PRC train: 0.490924	val: 0.304001	test: 0.183473

Epoch: 19
Loss: 0.10826682149391749
ROC train: 0.875889	val: 0.800482	test: 0.761511
PRC train: 0.512153	val: 0.331547	test: 0.207423

Epoch: 20
Loss: 0.10891441599824342
ROC train: 0.888205	val: 0.797291	test: 0.745453
PRC train: 0.506250	val: 0.308457	test: 0.197900

Epoch: 21
Loss: 0.10781963437955269
ROC train: 0.888158	val: 0.776976	test: 0.737838
PRC train: 0.520220	val: 0.343019	test: 0.215965

Epoch: 22
Loss: 0.10711731088055744
ROC train: 0.895542	val: 0.794646	test: 0.766782
PRC train: 0.544451	val: 0.363935	test: 0.225233

Epoch: 23
Loss: 0.10728828313670152
ROC train: 0.899921	val: 0.817831	test: 0.771033
PRC train: 0.535050	val: 0.335499	test: 0.221758

Epoch: 24
Loss: 0.105590969639237
ROC train: 0.900542	val: 0.813446	test: 0.760337
PRC train: 0.545902	val: 0.314052	test: 0.185407

Epoch: 25
Loss: 0.10742747643305002
ROC train: 0.907367	val: 0.797999	test: 0.763868
PRC train: 0.559053	val: 0.324772	test: 0.205269

Epoch: 26
Loss: 0.10444514024284463
ROC train: 0.903579	val: 0.790886	test: 0.763466
PRC train: 0.546202	val: 0.306842	test: 0.200249

Epoch: 27
Loss: 0.10426297340252748
ROC train: 0.909523	val: 0.810213	test: 0.771653
PRC train: 0.565900	val: 0.339712	test: 0.198934

Epoch: 28
Loss: 0.10540006837607635
ROC train: 0.906835	val: 0.794961	test: 0.743425
PRC train: 0.558385	val: 0.300831	test: 0.156900

Epoch: 29
Loss: 0.10335076269201679
ROC train: 0.910645	val: 0.782965	test: 0.755743
PRC train: 0.580763	val: 0.335183	test: 0.198975

Epoch: 30
Loss: 0.1022518295806009
ROC train: 0.898151	val: 0.771023	test: 0.740406
PRC train: 0.513166	val: 0.324996	test: 0.159200

Epoch: 31
Loss: 0.10362918135150966
ROC train: 0.905611	val: 0.782230	test: 0.737896
PRC train: 0.556642	val: 0.321588	test: 0.166991

Epoch: 32
Loss: 0.10225748237232235
ROC train: 0.907700	val: 0.784787	test: 0.752624
PRC train: 0.558531	val: 0.267719	test: 0.155875

Epoch: 33
Loss: 0.10107675331073367Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/hiv/noise=0.0.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/hiv/noise=0.0
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/hiv/noise=0.0/hiv_scaff_6_26-05_11-19-07  ]
[ Using Seed :  6  ]
[ Using device :  cuda:0  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.26552033966106675
ROC train: 0.758119	val: 0.757192	test: 0.708477
PRC train: 0.231886	val: 0.230679	test: 0.127074

Epoch: 2
Loss: 0.13812904940897622
ROC train: 0.795285	val: 0.754152	test: 0.733096
PRC train: 0.303087	val: 0.216728	test: 0.158046

Epoch: 3
Loss: 0.13272226484550975
ROC train: 0.804504	val: 0.780322	test: 0.710116
PRC train: 0.320965	val: 0.245808	test: 0.158773

Epoch: 4
Loss: 0.129531897772524
ROC train: 0.809732	val: 0.763231	test: 0.719983
PRC train: 0.306610	val: 0.167586	test: 0.080213

Epoch: 5
Loss: 0.12639247403339948
ROC train: 0.818225	val: 0.784554	test: 0.734981
PRC train: 0.355382	val: 0.225458	test: 0.192647

Epoch: 6
Loss: 0.12469791903312114
ROC train: 0.840456	val: 0.800617	test: 0.733405
PRC train: 0.403669	val: 0.275509	test: 0.157199

Epoch: 7
Loss: 0.12316210864733376
ROC train: 0.828447	val: 0.785420	test: 0.741810
PRC train: 0.356045	val: 0.302441	test: 0.182090

Epoch: 8
Loss: 0.12026472731884875
ROC train: 0.850995	val: 0.797947	test: 0.748948
PRC train: 0.422402	val: 0.322776	test: 0.231964

Epoch: 9
Loss: 0.11934371423739244
ROC train: 0.853636	val: 0.807800	test: 0.730055
PRC train: 0.428843	val: 0.303287	test: 0.153814

Epoch: 10
Loss: 0.11879900878322483
ROC train: 0.855427	val: 0.811085	test: 0.766989
PRC train: 0.459831	val: 0.350124	test: 0.207838

Epoch: 11
Loss: 0.11551222450552887
ROC train: 0.856022	val: 0.803152	test: 0.727509
PRC train: 0.448903	val: 0.336836	test: 0.174774

Epoch: 12
Loss: 0.11525380855393812
ROC train: 0.867537	val: 0.794125	test: 0.753632
PRC train: 0.474846	val: 0.341349	test: 0.212011

Epoch: 13
Loss: 0.11510190841308418
ROC train: 0.868247	val: 0.813354	test: 0.758396
PRC train: 0.461764	val: 0.316746	test: 0.191028

Epoch: 14
Loss: 0.1139600597681503
ROC train: 0.867008	val: 0.813523	test: 0.685201
PRC train: 0.431225	val: 0.261303	test: 0.072043

Epoch: 15
Loss: 0.11219608534111943
ROC train: 0.880807	val: 0.819784	test: 0.771176
PRC train: 0.507278	val: 0.367805	test: 0.258745

Epoch: 16
Loss: 0.11205932546161426
ROC train: 0.881013	val: 0.818850	test: 0.736750
PRC train: 0.502526	val: 0.342145	test: 0.122547

Epoch: 17
Loss: 0.11095923710620414
ROC train: 0.882055	val: 0.814242	test: 0.732598
PRC train: 0.495057	val: 0.364820	test: 0.195032

Epoch: 18
Loss: 0.10955819597900361
ROC train: 0.886339	val: 0.792839	test: 0.764391
PRC train: 0.522644	val: 0.358027	test: 0.218294

Epoch: 19
Loss: 0.10932607675031357
ROC train: 0.871233	val: 0.814417	test: 0.726547
PRC train: 0.459585	val: 0.280897	test: 0.096624

Epoch: 20
Loss: 0.1089510591177415
ROC train: 0.884749	val: 0.811419	test: 0.744727
PRC train: 0.506265	val: 0.362378	test: 0.277964

Epoch: 21
Loss: 0.10860391721515097
ROC train: 0.897007	val: 0.829099	test: 0.735167
PRC train: 0.549914	val: 0.338078	test: 0.188887

Epoch: 22
Loss: 0.10623875424198996
ROC train: 0.888186	val: 0.802102	test: 0.729357
PRC train: 0.509307	val: 0.341850	test: 0.106804

Epoch: 23
Loss: 0.1067818579895712
ROC train: 0.891859	val: 0.809711	test: 0.735601
PRC train: 0.526570	val: 0.341104	test: 0.185598

Epoch: 24
Loss: 0.10471271373957688
ROC train: 0.907588	val: 0.819230	test: 0.757570
PRC train: 0.564402	val: 0.360836	test: 0.207470

Epoch: 25
Loss: 0.10655516692418686
ROC train: 0.899728	val: 0.790837	test: 0.757481
PRC train: 0.546134	val: 0.379514	test: 0.211701

Epoch: 26
Loss: 0.10543048435247056
ROC train: 0.906421	val: 0.828358	test: 0.739385
PRC train: 0.553364	val: 0.362330	test: 0.208424

Epoch: 27
Loss: 0.10429362462101036
ROC train: 0.907571	val: 0.817090	test: 0.738747
PRC train: 0.569371	val: 0.340180	test: 0.200391

Epoch: 28
Loss: 0.10325519148118564
ROC train: 0.906896	val: 0.821226	test: 0.757844
PRC train: 0.551384	val: 0.398479	test: 0.233663

Epoch: 29
Loss: 0.10279833462082383
ROC train: 0.909966	val: 0.823165	test: 0.756863
PRC train: 0.566532	val: 0.385709	test: 0.195537

Epoch: 30
Loss: 0.10161615376942645
ROC train: 0.912776	val: 0.814836	test: 0.734835
PRC train: 0.575777	val: 0.373154	test: 0.168813

Epoch: 31
Loss: 0.10287331754697514
ROC train: 0.916451	val: 0.793890	test: 0.754644
PRC train: 0.577484	val: 0.336292	test: 0.226438

Epoch: 32
Loss: 0.10123195469436819
ROC train: 0.915428	val: 0.810245	test: 0.761345
PRC train: 0.579771	val: 0.371322	test: 0.235006

Epoch: 33
Loss: 0.10016919774062462Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/hiv/noise=0.05.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.05
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/hiv/noise=0.05
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/hiv/noise=0.05/hiv_scaff_6_26-05_11-19-07  ]
[ Using Seed :  6  ]
[ Using device :  cuda:1  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.2752440435154616
ROC train: 0.753022	val: 0.750521	test: 0.731060
PRC train: 0.181489	val: 0.187104	test: 0.161326

Epoch: 2
Loss: 0.14162476199923993
ROC train: 0.789481	val: 0.795574	test: 0.706804
PRC train: 0.256781	val: 0.274713	test: 0.192323

Epoch: 3
Loss: 0.13541111704431713
ROC train: 0.805520	val: 0.795739	test: 0.747832
PRC train: 0.308158	val: 0.263026	test: 0.220371

Epoch: 4
Loss: 0.1322906123129978
ROC train: 0.823674	val: 0.822166	test: 0.716175
PRC train: 0.358167	val: 0.305432	test: 0.222069

Epoch: 5
Loss: 0.12831363113326189
ROC train: 0.806408	val: 0.801088	test: 0.695732
PRC train: 0.315331	val: 0.247792	test: 0.087202

Epoch: 6
Loss: 0.1256010738378207
ROC train: 0.833642	val: 0.834154	test: 0.726267
PRC train: 0.396190	val: 0.355566	test: 0.190893

Epoch: 7
Loss: 0.12346674132723544
ROC train: 0.842298	val: 0.823103	test: 0.734392
PRC train: 0.425308	val: 0.365100	test: 0.180295

Epoch: 8
Loss: 0.12279943305499112
ROC train: 0.843109	val: 0.806039	test: 0.716003
PRC train: 0.408027	val: 0.281240	test: 0.148690

Epoch: 9
Loss: 0.12248581573362657
ROC train: 0.855606	val: 0.810641	test: 0.748124
PRC train: 0.443182	val: 0.311099	test: 0.176934

Epoch: 10
Loss: 0.11941196280443228
ROC train: 0.849278	val: 0.811646	test: 0.668062
PRC train: 0.423516	val: 0.248227	test: 0.074398

Epoch: 11
Loss: 0.11892260956149447
ROC train: 0.860691	val: 0.823719	test: 0.727413
PRC train: 0.449288	val: 0.330756	test: 0.117988

Epoch: 12
Loss: 0.11668284125036862
ROC train: 0.854770	val: 0.793489	test: 0.746204
PRC train: 0.424870	val: 0.318480	test: 0.275480

Epoch: 13
Loss: 0.11681289951668572
ROC train: 0.859830	val: 0.819882	test: 0.758076
PRC train: 0.458384	val: 0.283996	test: 0.139452

Epoch: 14
Loss: 0.11366275358396048
ROC train: 0.870444	val: 0.802093	test: 0.753311
PRC train: 0.464652	val: 0.312940	test: 0.144532

Epoch: 15
Loss: 0.1139361760876801
ROC train: 0.881311	val: 0.819386	test: 0.755028
PRC train: 0.525145	val: 0.392007	test: 0.249601

Epoch: 16
Loss: 0.11196635467710674
ROC train: 0.882342	val: 0.811502	test: 0.750940
PRC train: 0.524988	val: 0.392593	test: 0.195222

Epoch: 17
Loss: 0.11096289321270493
ROC train: 0.881414	val: 0.805960	test: 0.752656
PRC train: 0.511006	val: 0.344612	test: 0.220421

Epoch: 18
Loss: 0.1105782317468206
ROC train: 0.890724	val: 0.808706	test: 0.750520
PRC train: 0.533269	val: 0.342339	test: 0.196259

Epoch: 19
Loss: 0.10903215884068695
ROC train: 0.890601	val: 0.821453	test: 0.767101
PRC train: 0.536826	val: 0.365397	test: 0.198232

Epoch: 20
Loss: 0.10768394497130102
ROC train: 0.895236	val: 0.797481	test: 0.740932
PRC train: 0.550928	val: 0.372527	test: 0.249578

Epoch: 21
Loss: 0.10743572379493627
ROC train: 0.896480	val: 0.812751	test: 0.753805
PRC train: 0.541893	val: 0.359447	test: 0.196992

Epoch: 22
Loss: 0.1061031138770978
ROC train: 0.900223	val: 0.816379	test: 0.746107
PRC train: 0.561018	val: 0.353199	test: 0.268367

Epoch: 23
Loss: 0.10518443898624523
ROC train: 0.890734	val: 0.798354	test: 0.738031
PRC train: 0.511633	val: 0.307601	test: 0.213198

Epoch: 24
Loss: 0.10502991701006775
ROC train: 0.901048	val: 0.822418	test: 0.743879
PRC train: 0.560862	val: 0.378985	test: 0.241059

Epoch: 25
Loss: 0.10418482799951648
ROC train: 0.910201	val: 0.813440	test: 0.746098
PRC train: 0.571783	val: 0.367985	test: 0.188237

Epoch: 26
Loss: 0.10366333535485936
ROC train: 0.908364	val: 0.809830	test: 0.730989
PRC train: 0.576979	val: 0.319472	test: 0.148348

Epoch: 27
Loss: 0.10199255165989643
ROC train: 0.917662	val: 0.824291	test: 0.741073
PRC train: 0.584530	val: 0.360722	test: 0.204381

Epoch: 28
Loss: 0.10280290145314555
ROC train: 0.917241	val: 0.810173	test: 0.733156
PRC train: 0.590293	val: 0.352415	test: 0.185720

Epoch: 29
Loss: 0.10053635998051418
ROC train: 0.927305	val: 0.824714	test: 0.739622
PRC train: 0.631466	val: 0.368836	test: 0.210618

Epoch: 30
Loss: 0.09963827453000569
ROC train: 0.924181	val: 0.803865	test: 0.740406
PRC train: 0.618787	val: 0.355817	test: 0.203006

Epoch: 31
Loss: 0.10004491401988419
ROC train: 0.924500	val: 0.806933	test: 0.744636
PRC train: 0.617323	val: 0.363918	test: 0.216363

Epoch: 32
Loss: 0.09769499945941476
ROC train: 0.922070	val: 0.811012	test: 0.754964Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/hiv/noise=0.05.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.05
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/hiv/noise=0.05
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/hiv/noise=0.05/hiv_scaff_4_26-05_11-19-07  ]
[ Using Seed :  4  ]
[ Using device :  cuda:1  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.29057943933538205
ROC train: 0.757546	val: 0.735392	test: 0.671568
PRC train: 0.211564	val: 0.133186	test: 0.104646

Epoch: 2
Loss: 0.14251846884409058
ROC train: 0.781742	val: 0.728787	test: 0.724382
PRC train: 0.243646	val: 0.188561	test: 0.159454

Epoch: 3
Loss: 0.13705608090688584
ROC train: 0.796563	val: 0.742826	test: 0.735953
PRC train: 0.281829	val: 0.221766	test: 0.130681

Epoch: 4
Loss: 0.13230927444996643
ROC train: 0.812975	val: 0.766611	test: 0.732196
PRC train: 0.330769	val: 0.237120	test: 0.167696

Epoch: 5
Loss: 0.12792995889161948
ROC train: 0.822875	val: 0.760698	test: 0.688306
PRC train: 0.357810	val: 0.227706	test: 0.106761

Epoch: 6
Loss: 0.12842357957430947
ROC train: 0.825941	val: 0.787695	test: 0.715570
PRC train: 0.345890	val: 0.231223	test: 0.129035

Epoch: 7
Loss: 0.1256209175805085
ROC train: 0.822605	val: 0.760215	test: 0.723923
PRC train: 0.363593	val: 0.345013	test: 0.203115

Epoch: 8
Loss: 0.12438085064710014
ROC train: 0.841312	val: 0.791116	test: 0.734543
PRC train: 0.431300	val: 0.289976	test: 0.157749

Epoch: 9
Loss: 0.12208017011739433
ROC train: 0.846064	val: 0.803253	test: 0.741225
PRC train: 0.427062	val: 0.344082	test: 0.178278

Epoch: 10
Loss: 0.12087329771967818
ROC train: 0.848694	val: 0.771100	test: 0.711366
PRC train: 0.416963	val: 0.305160	test: 0.142846

Epoch: 11
Loss: 0.12012801535656611
ROC train: 0.860307	val: 0.789312	test: 0.738680
PRC train: 0.460302	val: 0.322032	test: 0.181037

Epoch: 12
Loss: 0.1191830475038156
ROC train: 0.862201	val: 0.823851	test: 0.742542
PRC train: 0.456677	val: 0.352636	test: 0.181850

Epoch: 13
Loss: 0.1178526792245047
ROC train: 0.866640	val: 0.797573	test: 0.731337
PRC train: 0.460290	val: 0.372039	test: 0.201597

Epoch: 14
Loss: 0.11585748767562254
ROC train: 0.870620	val: 0.800157	test: 0.731420
PRC train: 0.479912	val: 0.389965	test: 0.207496

Epoch: 15
Loss: 0.11525773527554026
ROC train: 0.877820	val: 0.781771	test: 0.735930
PRC train: 0.492722	val: 0.360611	test: 0.198228

Epoch: 16
Loss: 0.11346821273918249
ROC train: 0.871860	val: 0.783430	test: 0.733106
PRC train: 0.477693	val: 0.384494	test: 0.199109

Epoch: 17
Loss: 0.11359578382872276
ROC train: 0.888182	val: 0.805007	test: 0.723741
PRC train: 0.523252	val: 0.379327	test: 0.192655

Epoch: 18
Loss: 0.11323032829196585
ROC train: 0.886797	val: 0.788942	test: 0.741011
PRC train: 0.500204	val: 0.382133	test: 0.240439

Epoch: 19
Loss: 0.11164121265475258
ROC train: 0.889679	val: 0.795010	test: 0.683673
PRC train: 0.505086	val: 0.329654	test: 0.112259

Epoch: 20
Loss: 0.11022228562713159
ROC train: 0.895537	val: 0.794824	test: 0.738689
PRC train: 0.543123	val: 0.378656	test: 0.198868

Epoch: 21
Loss: 0.10947025524496022
ROC train: 0.892536	val: 0.775310	test: 0.735422
PRC train: 0.541169	val: 0.396715	test: 0.222289

Epoch: 22
Loss: 0.1078052971174953
ROC train: 0.901289	val: 0.819013	test: 0.721318
PRC train: 0.543726	val: 0.389524	test: 0.151388

Epoch: 23
Loss: 0.10760192953778319
ROC train: 0.904788	val: 0.812276	test: 0.737303
PRC train: 0.539786	val: 0.359836	test: 0.152366

Epoch: 24
Loss: 0.10639868239796368
ROC train: 0.907530	val: 0.786134	test: 0.722175
PRC train: 0.534790	val: 0.379257	test: 0.174950

Epoch: 25
Loss: 0.10788757180058556
ROC train: 0.914371	val: 0.823716	test: 0.723235
PRC train: 0.571278	val: 0.347363	test: 0.130002

Epoch: 26
Loss: 0.10487316556086877
ROC train: 0.913537	val: 0.799517	test: 0.723797
PRC train: 0.583711	val: 0.390313	test: 0.163412

Epoch: 27
Loss: 0.10445307566762965
ROC train: 0.916367	val: 0.796403	test: 0.725483
PRC train: 0.568028	val: 0.384231	test: 0.187715

Epoch: 28
Loss: 0.10301426220910216
ROC train: 0.923671	val: 0.800705	test: 0.740729
PRC train: 0.581765	val: 0.395984	test: 0.225144

Epoch: 29
Loss: 0.1019111858857823
ROC train: 0.917045	val: 0.772083	test: 0.725688
PRC train: 0.595927	val: 0.339345	test: 0.120096

Epoch: 30
Loss: 0.10195975561591086
ROC train: 0.925401	val: 0.767943	test: 0.749680
PRC train: 0.622680	val: 0.368787	test: 0.213892

Epoch: 31
Loss: 0.10171541726398019
ROC train: 0.924974	val: 0.777726	test: 0.750775
PRC train: 0.601243	val: 0.338889	test: 0.216179

Epoch: 32
Loss: 0.09776732267679888
ROC train: 0.930506	val: 0.788381	test: 0.748027Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/hiv/noise=0.1.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.1
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/hiv/noise=0.1
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/hiv/noise=0.1/hiv_scaff_6_26-05_11-19-07  ]
[ Using Seed :  6  ]
[ Using device :  cuda:2  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.2768088197677937
ROC train: 0.750448	val: 0.783638	test: 0.734738
PRC train: 0.171694	val: 0.196502	test: 0.157213

Epoch: 2
Loss: 0.1452387794379981
ROC train: 0.777566	val: 0.768708	test: 0.700051
PRC train: 0.212621	val: 0.193702	test: 0.148906

Epoch: 3
Loss: 0.13946757076832256
ROC train: 0.791258	val: 0.760368	test: 0.729736
PRC train: 0.255739	val: 0.172955	test: 0.168996

Epoch: 4
Loss: 0.1372017867197714
ROC train: 0.809120	val: 0.772349	test: 0.710891
PRC train: 0.290941	val: 0.230263	test: 0.139857

Epoch: 5
Loss: 0.13410662572093457
ROC train: 0.807996	val: 0.794032	test: 0.706454
PRC train: 0.304606	val: 0.256239	test: 0.124918

Epoch: 6
Loss: 0.1308328193898809
ROC train: 0.823317	val: 0.797754	test: 0.699177
PRC train: 0.332829	val: 0.266635	test: 0.142045

Epoch: 7
Loss: 0.1288207038717731
ROC train: 0.812767	val: 0.767594	test: 0.726393
PRC train: 0.308144	val: 0.263625	test: 0.161133

Epoch: 8
Loss: 0.12812263836925197
ROC train: 0.832334	val: 0.772646	test: 0.696636
PRC train: 0.321529	val: 0.213546	test: 0.087784

Epoch: 9
Loss: 0.1265357219449592
ROC train: 0.847633	val: 0.791067	test: 0.729800
PRC train: 0.406999	val: 0.276192	test: 0.161690

Epoch: 10
Loss: 0.12398171141814263
ROC train: 0.850092	val: 0.798329	test: 0.685378
PRC train: 0.408817	val: 0.263295	test: 0.107532

Epoch: 11
Loss: 0.12317417959827809
ROC train: 0.846246	val: 0.798819	test: 0.738309
PRC train: 0.398410	val: 0.263705	test: 0.146905

Epoch: 12
Loss: 0.1217992248716163
ROC train: 0.857253	val: 0.802723	test: 0.723994
PRC train: 0.432974	val: 0.327511	test: 0.199807

Epoch: 13
Loss: 0.12115805135628371
ROC train: 0.860543	val: 0.791262	test: 0.746959
PRC train: 0.417085	val: 0.242596	test: 0.143620

Epoch: 14
Loss: 0.11702470467874092
ROC train: 0.864183	val: 0.772481	test: 0.709058
PRC train: 0.449437	val: 0.310637	test: 0.167944

Epoch: 15
Loss: 0.1187113328725379
ROC train: 0.876160	val: 0.802074	test: 0.726970
PRC train: 0.492403	val: 0.334692	test: 0.177771

Epoch: 16
Loss: 0.11580243235457802
ROC train: 0.883972	val: 0.805810	test: 0.733616
PRC train: 0.500044	val: 0.360231	test: 0.246467

Epoch: 17
Loss: 0.11446764092190781
ROC train: 0.867814	val: 0.771415	test: 0.732899
PRC train: 0.472381	val: 0.293410	test: 0.238779

Epoch: 18
Loss: 0.11456073270358781
ROC train: 0.890952	val: 0.808827	test: 0.715309
PRC train: 0.528162	val: 0.253500	test: 0.154057

Epoch: 19
Loss: 0.11147927927847186
ROC train: 0.897877	val: 0.801832	test: 0.744748
PRC train: 0.530206	val: 0.354235	test: 0.214084

Epoch: 20
Loss: 0.11098237182614566
ROC train: 0.896440	val: 0.793755	test: 0.726602
PRC train: 0.534210	val: 0.320188	test: 0.183327

Epoch: 21
Loss: 0.110576442607949
ROC train: 0.905720	val: 0.792386	test: 0.718844
PRC train: 0.558263	val: 0.355393	test: 0.200690

Epoch: 22
Loss: 0.10950445132236854
ROC train: 0.906944	val: 0.790365	test: 0.723681
PRC train: 0.538189	val: 0.315891	test: 0.210989

Epoch: 23
Loss: 0.10833795867464903
ROC train: 0.907260	val: 0.779437	test: 0.730217
PRC train: 0.549286	val: 0.315872	test: 0.200156

Epoch: 24
Loss: 0.1088154455679515
ROC train: 0.907524	val: 0.794759	test: 0.703513
PRC train: 0.556832	val: 0.318299	test: 0.205315

Epoch: 25
Loss: 0.10697644390863778
ROC train: 0.911225	val: 0.794609	test: 0.721211
PRC train: 0.562904	val: 0.326540	test: 0.186461

Epoch: 26
Loss: 0.10467386898773791
ROC train: 0.920493	val: 0.791287	test: 0.728666
PRC train: 0.578176	val: 0.304197	test: 0.171770

Epoch: 27
Loss: 0.10408122915555144
ROC train: 0.925438	val: 0.812647	test: 0.731743
PRC train: 0.611908	val: 0.368542	test: 0.217802

Epoch: 28
Loss: 0.1039385151716144
ROC train: 0.921593	val: 0.771593	test: 0.725605
PRC train: 0.567112	val: 0.310455	test: 0.153899

Epoch: 29
Loss: 0.10269396604524277
ROC train: 0.929972	val: 0.789318	test: 0.721466
PRC train: 0.597407	val: 0.262244	test: 0.143813

Epoch: 30
Loss: 0.10182152154860062
ROC train: 0.926354	val: 0.785289	test: 0.728195
PRC train: 0.600964	val: 0.277939	test: 0.168906

Epoch: 31
Loss: 0.10076725117674475
ROC train: 0.927097	val: 0.791275	test: 0.732600
PRC train: 0.599373	val: 0.340962	test: 0.176874

Epoch: 32
Loss: 0.09909839158713507
ROC train: 0.934834	val: 0.791287	test: 0.738670Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/hiv/noise=0.1.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.1
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/hiv/noise=0.1
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/hiv/noise=0.1/hiv_scaff_5_26-05_11-19-07  ]
[ Using Seed :  5  ]
[ Using device :  cuda:2  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.25786278568502824
ROC train: 0.751414	val: 0.741252	test: 0.686025
PRC train: 0.174495	val: 0.201938	test: 0.130646

Epoch: 2
Loss: 0.14670884559225883
ROC train: 0.756929	val: 0.720109	test: 0.728148
PRC train: 0.211344	val: 0.181885	test: 0.188264

Epoch: 3
Loss: 0.1406378779669451
ROC train: 0.780961	val: 0.762805	test: 0.726981
PRC train: 0.238967	val: 0.226002	test: 0.163192

Epoch: 4
Loss: 0.13804299287247115
ROC train: 0.806292	val: 0.780264	test: 0.728871
PRC train: 0.298389	val: 0.264246	test: 0.193611

Epoch: 5
Loss: 0.13425233756921284
ROC train: 0.810697	val: 0.803752	test: 0.764567
PRC train: 0.296686	val: 0.230953	test: 0.186252

Epoch: 6
Loss: 0.13163697528034976
ROC train: 0.819614	val: 0.787545	test: 0.760163
PRC train: 0.323721	val: 0.266855	test: 0.247513

Epoch: 7
Loss: 0.12963441744846083
ROC train: 0.823127	val: 0.766583	test: 0.709554
PRC train: 0.362738	val: 0.292368	test: 0.137861

Epoch: 8
Loss: 0.12890004977280775
ROC train: 0.830844	val: 0.762027	test: 0.721663
PRC train: 0.360782	val: 0.233631	test: 0.184069

Epoch: 9
Loss: 0.12712577018397417
ROC train: 0.839633	val: 0.761813	test: 0.735188
PRC train: 0.391301	val: 0.308517	test: 0.207816

Epoch: 10
Loss: 0.12516630232836523
ROC train: 0.844764	val: 0.794649	test: 0.742921
PRC train: 0.413452	val: 0.287531	test: 0.190663

Epoch: 11
Loss: 0.12341656087565771
ROC train: 0.849218	val: 0.784183	test: 0.730329
PRC train: 0.390116	val: 0.264686	test: 0.155206

Epoch: 12
Loss: 0.12153699392542158
ROC train: 0.858753	val: 0.804496	test: 0.753220
PRC train: 0.435846	val: 0.333578	test: 0.233853

Epoch: 13
Loss: 0.11960185829241134
ROC train: 0.871848	val: 0.810782	test: 0.749002
PRC train: 0.457818	val: 0.290325	test: 0.189036

Epoch: 14
Loss: 0.11809943896737284
ROC train: 0.867398	val: 0.739357	test: 0.749184
PRC train: 0.459644	val: 0.294847	test: 0.167243

Epoch: 15
Loss: 0.11785788199783942
ROC train: 0.876419	val: 0.778069	test: 0.755569
PRC train: 0.478688	val: 0.282733	test: 0.153649

Epoch: 16
Loss: 0.116137297466502
ROC train: 0.884922	val: 0.810568	test: 0.743983
PRC train: 0.497013	val: 0.318953	test: 0.144698

Epoch: 17
Loss: 0.11578059680544593
ROC train: 0.881171	val: 0.811615	test: 0.760843
PRC train: 0.469946	val: 0.364993	test: 0.202656

Epoch: 18
Loss: 0.1144314090821256
ROC train: 0.884510	val: 0.760279	test: 0.752658
PRC train: 0.509426	val: 0.364371	test: 0.232495

Epoch: 19
Loss: 0.11272109796534406
ROC train: 0.891270	val: 0.806091	test: 0.749889
PRC train: 0.521659	val: 0.341555	test: 0.171086

Epoch: 20
Loss: 0.11119557119853087
ROC train: 0.891565	val: 0.797922	test: 0.735563
PRC train: 0.502024	val: 0.310587	test: 0.145868

Epoch: 21
Loss: 0.11254970721203346
ROC train: 0.885609	val: 0.748809	test: 0.743587
PRC train: 0.518718	val: 0.327359	test: 0.157937

Epoch: 22
Loss: 0.11066525914306552
ROC train: 0.908552	val: 0.814199	test: 0.758261
PRC train: 0.558624	val: 0.349180	test: 0.176746

Epoch: 23
Loss: 0.10977042501862146
ROC train: 0.897756	val: 0.809061	test: 0.756391
PRC train: 0.534942	val: 0.327906	test: 0.178340

Epoch: 24
Loss: 0.10914531416482577
ROC train: 0.905572	val: 0.802610	test: 0.768386
PRC train: 0.567753	val: 0.367626	test: 0.189108

Epoch: 25
Loss: 0.10849512978587367
ROC train: 0.905670	val: 0.794266	test: 0.755733
PRC train: 0.560847	val: 0.333702	test: 0.181432

Epoch: 26
Loss: 0.10714863122105724
ROC train: 0.902454	val: 0.788384	test: 0.742676
PRC train: 0.563951	val: 0.317573	test: 0.204972

Epoch: 27
Loss: 0.10625554584846314
ROC train: 0.917902	val: 0.817659	test: 0.749072
PRC train: 0.577725	val: 0.375019	test: 0.168796

Epoch: 28
Loss: 0.10489018224599586
ROC train: 0.918450	val: 0.809888	test: 0.772595
PRC train: 0.591603	val: 0.321015	test: 0.166136

Epoch: 29
Loss: 0.10406457269952932
ROC train: 0.919149	val: 0.802189	test: 0.776686
PRC train: 0.589572	val: 0.315724	test: 0.138785

Epoch: 30
Loss: 0.10183808370343547
ROC train: 0.918623	val: 0.797077	test: 0.767128
PRC train: 0.600407	val: 0.374719	test: 0.170939

Epoch: 31
Loss: 0.10111522049550566
ROC train: 0.921482	val: 0.767713	test: 0.761581
PRC train: 0.598158	val: 0.296978	test: 0.157362

Epoch: 32
Loss: 0.10080084823399117
ROC train: 0.923026	val: 0.788890	test: 0.771960Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/hiv/noise=0.05.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.05
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/hiv/noise=0.05
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/hiv/noise=0.05/hiv_scaff_5_26-05_11-19-07  ]
[ Using Seed :  5  ]
[ Using device :  cuda:1  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.25612348944959384
ROC train: 0.759763	val: 0.767955	test: 0.700377
PRC train: 0.181315	val: 0.171343	test: 0.103137

Epoch: 2
Loss: 0.1432069684073285
ROC train: 0.766357	val: 0.692972	test: 0.746571
PRC train: 0.249301	val: 0.212693	test: 0.251150

Epoch: 3
Loss: 0.13782214740229945
ROC train: 0.779776	val: 0.769710	test: 0.729232
PRC train: 0.244947	val: 0.262411	test: 0.164531

Epoch: 4
Loss: 0.13449959898050026
ROC train: 0.808034	val: 0.791112	test: 0.735966
PRC train: 0.324220	val: 0.247694	test: 0.186159

Epoch: 5
Loss: 0.13034753990751227
ROC train: 0.825207	val: 0.812411	test: 0.732780
PRC train: 0.354255	val: 0.312460	test: 0.168642

Epoch: 6
Loss: 0.12774032956430376
ROC train: 0.818097	val: 0.761197	test: 0.754686
PRC train: 0.322304	val: 0.281669	test: 0.275979

Epoch: 7
Loss: 0.1261233249845796
ROC train: 0.836587	val: 0.789940	test: 0.714218
PRC train: 0.367836	val: 0.303077	test: 0.127345

Epoch: 8
Loss: 0.12502772263228812
ROC train: 0.825094	val: 0.752192	test: 0.707893
PRC train: 0.330051	val: 0.235481	test: 0.194790

Epoch: 9
Loss: 0.12328839746859649
ROC train: 0.849988	val: 0.809221	test: 0.747774
PRC train: 0.431254	val: 0.366491	test: 0.217976

Epoch: 10
Loss: 0.12127478290267671
ROC train: 0.849313	val: 0.804484	test: 0.718245
PRC train: 0.435599	val: 0.336197	test: 0.201031

Epoch: 11
Loss: 0.12001606567358834
ROC train: 0.858329	val: 0.833091	test: 0.743973
PRC train: 0.442505	val: 0.338454	test: 0.183109

Epoch: 12
Loss: 0.11756964793707159
ROC train: 0.864032	val: 0.791330	test: 0.756504
PRC train: 0.466935	val: 0.348736	test: 0.194649

Epoch: 13
Loss: 0.1184818619790342
ROC train: 0.868605	val: 0.816768	test: 0.758155
PRC train: 0.459044	val: 0.348885	test: 0.166711

Epoch: 14
Loss: 0.11483719745047502
ROC train: 0.865486	val: 0.764229	test: 0.738801
PRC train: 0.466904	val: 0.377316	test: 0.216617

Epoch: 15
Loss: 0.11574155103118014
ROC train: 0.875519	val: 0.796471	test: 0.779640
PRC train: 0.491512	val: 0.346377	test: 0.203237

Epoch: 16
Loss: 0.11473102488959688
ROC train: 0.879712	val: 0.806413	test: 0.743593
PRC train: 0.472680	val: 0.327785	test: 0.203351

Epoch: 17
Loss: 0.11291941811860368
ROC train: 0.884204	val: 0.826263	test: 0.752647
PRC train: 0.515676	val: 0.369394	test: 0.186621

Epoch: 18
Loss: 0.11158179685234468
ROC train: 0.881083	val: 0.791067	test: 0.764706
PRC train: 0.504737	val: 0.381646	test: 0.248077

Epoch: 19
Loss: 0.11150790233459354
ROC train: 0.895751	val: 0.821992	test: 0.763118
PRC train: 0.534986	val: 0.394773	test: 0.194488

Epoch: 20
Loss: 0.10981552265357492
ROC train: 0.889391	val: 0.798434	test: 0.764420
PRC train: 0.516382	val: 0.371451	test: 0.224486

Epoch: 21
Loss: 0.11023010192049712
ROC train: 0.889343	val: 0.767318	test: 0.753151
PRC train: 0.497505	val: 0.328118	test: 0.183136

Epoch: 22
Loss: 0.10838669185833393
ROC train: 0.902675	val: 0.820737	test: 0.770780
PRC train: 0.558372	val: 0.376798	test: 0.230174

Epoch: 23
Loss: 0.1072079653991607
ROC train: 0.905612	val: 0.793796	test: 0.758638
PRC train: 0.553152	val: 0.340464	test: 0.196574

Epoch: 24
Loss: 0.10674009656214148
ROC train: 0.908759	val: 0.797071	test: 0.753079
PRC train: 0.571102	val: 0.358586	test: 0.212726

Epoch: 25
Loss: 0.10528533367372005
ROC train: 0.897456	val: 0.769192	test: 0.746154
PRC train: 0.512983	val: 0.340057	test: 0.200685

Epoch: 26
Loss: 0.10513376359767661
ROC train: 0.908226	val: 0.818045	test: 0.757483
PRC train: 0.580358	val: 0.373200	test: 0.255314

Epoch: 27
Loss: 0.10363467021011988
ROC train: 0.912926	val: 0.818250	test: 0.763812
PRC train: 0.589227	val: 0.352845	test: 0.223075

Epoch: 28
Loss: 0.10290412192021345
ROC train: 0.911537	val: 0.820988	test: 0.772738
PRC train: 0.572406	val: 0.323680	test: 0.201459

Epoch: 29
Loss: 0.10126833069301727
ROC train: 0.919678	val: 0.795304	test: 0.746042
PRC train: 0.605386	val: 0.392645	test: 0.203687

Epoch: 30
Loss: 0.10307351435057487
ROC train: 0.920461	val: 0.784591	test: 0.762844
PRC train: 0.603145	val: 0.363035	test: 0.235139

Epoch: 31
Loss: 0.10036663040329635
ROC train: 0.922650	val: 0.799370	test: 0.742992
PRC train: 0.614383	val: 0.379149	test: 0.179828

Epoch: 32
Loss: 0.10000857674201137
ROC train: 0.923875	val: 0.794086	test: 0.753458Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/hiv/noise=0.1.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.1
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/hiv/noise=0.1
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/hiv/noise=0.1/hiv_scaff_4_26-05_11-19-07  ]
[ Using Seed :  4  ]
[ Using device :  cuda:2  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.2928513291730091
ROC train: 0.738942	val: 0.729442	test: 0.685992
PRC train: 0.163894	val: 0.112309	test: 0.107224

Epoch: 2
Loss: 0.14607924300287017
ROC train: 0.769557	val: 0.754134	test: 0.661196
PRC train: 0.226257	val: 0.165638	test: 0.125309

Epoch: 3
Loss: 0.1404740359214377
ROC train: 0.788263	val: 0.737284	test: 0.706464
PRC train: 0.268343	val: 0.174648	test: 0.141995

Epoch: 4
Loss: 0.13664345576105183
ROC train: 0.799935	val: 0.748432	test: 0.716489
PRC train: 0.317111	val: 0.214053	test: 0.141411

Epoch: 5
Loss: 0.1325837292130206
ROC train: 0.809941	val: 0.767897	test: 0.694861
PRC train: 0.342110	val: 0.244042	test: 0.129429

Epoch: 6
Loss: 0.13141969357185612
ROC train: 0.816039	val: 0.781128	test: 0.734392
PRC train: 0.327887	val: 0.213636	test: 0.170031

Epoch: 7
Loss: 0.1290250465272011
ROC train: 0.813667	val: 0.755490	test: 0.730667
PRC train: 0.328226	val: 0.297200	test: 0.201889

Epoch: 8
Loss: 0.12776616017174086
ROC train: 0.835715	val: 0.793779	test: 0.750013
PRC train: 0.395838	val: 0.286132	test: 0.181009

Epoch: 9
Loss: 0.1251369430523535
ROC train: 0.836616	val: 0.796299	test: 0.753047
PRC train: 0.409364	val: 0.350803	test: 0.210051

Epoch: 10
Loss: 0.12364890574552038
ROC train: 0.836302	val: 0.751715	test: 0.736976
PRC train: 0.375855	val: 0.291860	test: 0.154684

Epoch: 11
Loss: 0.12271438006750075
ROC train: 0.844069	val: 0.771813	test: 0.738844
PRC train: 0.438214	val: 0.307446	test: 0.224007

Epoch: 12
Loss: 0.12257576291205814
ROC train: 0.861878	val: 0.821934	test: 0.736430
PRC train: 0.438541	val: 0.342212	test: 0.182460

Epoch: 13
Loss: 0.11971786690693545
ROC train: 0.863741	val: 0.805115	test: 0.741430
PRC train: 0.460015	val: 0.364947	test: 0.226886

Epoch: 14
Loss: 0.11833342700229732
ROC train: 0.861099	val: 0.793360	test: 0.738100
PRC train: 0.444974	val: 0.339045	test: 0.199395

Epoch: 15
Loss: 0.11718343587952003
ROC train: 0.875290	val: 0.801453	test: 0.747442
PRC train: 0.468029	val: 0.359770	test: 0.246070

Epoch: 16
Loss: 0.11733508761982148
ROC train: 0.874302	val: 0.780353	test: 0.726602
PRC train: 0.488745	val: 0.332798	test: 0.238773

Epoch: 17
Loss: 0.11629108978336386
ROC train: 0.883353	val: 0.815011	test: 0.741582
PRC train: 0.501665	val: 0.317404	test: 0.172015

Epoch: 18
Loss: 0.11382927489871462
ROC train: 0.876352	val: 0.805213	test: 0.718546
PRC train: 0.449146	val: 0.329860	test: 0.232653

Epoch: 19
Loss: 0.11356406650415239
ROC train: 0.889081	val: 0.819111	test: 0.717785
PRC train: 0.516526	val: 0.342972	test: 0.115525

Epoch: 20
Loss: 0.1118550705545317
ROC train: 0.897096	val: 0.806440	test: 0.724900
PRC train: 0.533210	val: 0.284535	test: 0.128689

Epoch: 21
Loss: 0.11169411142613643
ROC train: 0.888986	val: 0.800788	test: 0.755656
PRC train: 0.516566	val: 0.368889	test: 0.218592

Epoch: 22
Loss: 0.10880279092719787
ROC train: 0.894974	val: 0.817871	test: 0.735016
PRC train: 0.518719	val: 0.355290	test: 0.178308

Epoch: 23
Loss: 0.10775956015221587
ROC train: 0.908881	val: 0.816983	test: 0.726936
PRC train: 0.559042	val: 0.318818	test: 0.154407

Epoch: 24
Loss: 0.10723249733299717
ROC train: 0.901242	val: 0.787665	test: 0.717351
PRC train: 0.514820	val: 0.292908	test: 0.161655

Epoch: 25
Loss: 0.10819922952772784
ROC train: 0.911289	val: 0.815654	test: 0.740779
PRC train: 0.568045	val: 0.355355	test: 0.181441

Epoch: 26
Loss: 0.1069711182165865
ROC train: 0.915028	val: 0.792760	test: 0.720452
PRC train: 0.585959	val: 0.353031	test: 0.199755

Epoch: 27
Loss: 0.10542198926620633
ROC train: 0.920722	val: 0.813559	test: 0.741051
PRC train: 0.603045	val: 0.350311	test: 0.206017

Epoch: 28
Loss: 0.10332480746274883
ROC train: 0.916567	val: 0.811480	test: 0.741895
PRC train: 0.563821	val: 0.335624	test: 0.175592

Epoch: 29
Loss: 0.10415951151980014
ROC train: 0.917315	val: 0.817439	test: 0.741820
PRC train: 0.597357	val: 0.332641	test: 0.154977

Epoch: 30
Loss: 0.10252290302373725
ROC train: 0.906688	val: 0.811015	test: 0.754729
PRC train: 0.535043	val: 0.308573	test: 0.231528

Epoch: 31
Loss: 0.10199303774352998
ROC train: 0.926818	val: 0.819879	test: 0.746940
PRC train: 0.634538	val: 0.391148	test: 0.209976

Epoch: 32
Loss: 0.09976624482258126
ROC train: 0.935493	val: 0.815228	test: 0.758893Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/hiv/noise=0.2.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:3
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.2
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/hiv/noise=0.2
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/hiv/noise=0.2/hiv_scaff_4_26-05_11-19-07  ]
[ Using Seed :  4  ]
[ Using device :  cuda:3  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.29479068504372324
ROC train: 0.709560	val: 0.690495	test: 0.694624
PRC train: 0.130780	val: 0.099103	test: 0.112678

Epoch: 2
Loss: 0.1510282209450515
ROC train: 0.756539	val: 0.759875	test: 0.693351
PRC train: 0.182557	val: 0.136942	test: 0.118055

Epoch: 3
Loss: 0.14523913923903906
ROC train: 0.748465	val: 0.710033	test: 0.728085
PRC train: 0.173250	val: 0.159004	test: 0.191963

Epoch: 4
Loss: 0.142773083605671
ROC train: 0.777376	val: 0.752985	test: 0.678686
PRC train: 0.212326	val: 0.185632	test: 0.089343

Epoch: 5
Loss: 0.1394212150637825
ROC train: 0.790285	val: 0.770365	test: 0.711368
PRC train: 0.255964	val: 0.198686	test: 0.146392

Epoch: 6
Loss: 0.1382669434379961
ROC train: 0.798746	val: 0.782946	test: 0.723836
PRC train: 0.271258	val: 0.173180	test: 0.123593

Epoch: 7
Loss: 0.1367791079277849
ROC train: 0.780677	val: 0.729551	test: 0.716659
PRC train: 0.242584	val: 0.203758	test: 0.203984

Epoch: 8
Loss: 0.13393418924527464
ROC train: 0.804179	val: 0.748451	test: 0.693839
PRC train: 0.286733	val: 0.177516	test: 0.103998

Epoch: 9
Loss: 0.1325985918552018
ROC train: 0.817122	val: 0.795834	test: 0.721244
PRC train: 0.318643	val: 0.235218	test: 0.131268

Epoch: 10
Loss: 0.13112709771105235
ROC train: 0.819024	val: 0.740805	test: 0.689812
PRC train: 0.312635	val: 0.188784	test: 0.092921

Epoch: 11
Loss: 0.12967984227239465
ROC train: 0.823891	val: 0.744188	test: 0.730800
PRC train: 0.366774	val: 0.222007	test: 0.144535

Epoch: 12
Loss: 0.12911610054671507
ROC train: 0.841719	val: 0.828912	test: 0.740441
PRC train: 0.373025	val: 0.274221	test: 0.145664

Epoch: 13
Loss: 0.12737177389135906
ROC train: 0.853901	val: 0.793280	test: 0.740084
PRC train: 0.415922	val: 0.333478	test: 0.174025

Epoch: 14
Loss: 0.12501026232365592
ROC train: 0.842522	val: 0.760943	test: 0.751135
PRC train: 0.383932	val: 0.259366	test: 0.167996

Epoch: 15
Loss: 0.12488590858768801
ROC train: 0.859436	val: 0.800424	test: 0.752413
PRC train: 0.421059	val: 0.254579	test: 0.170864

Epoch: 16
Loss: 0.1234583280071337
ROC train: 0.861527	val: 0.785794	test: 0.742538
PRC train: 0.427740	val: 0.313325	test: 0.162068

Epoch: 17
Loss: 0.121901153612077
ROC train: 0.854099	val: 0.814080	test: 0.739470
PRC train: 0.410039	val: 0.252650	test: 0.138842

Epoch: 18
Loss: 0.12220274211506606
ROC train: 0.867435	val: 0.798666	test: 0.739010
PRC train: 0.436897	val: 0.285619	test: 0.188028

Epoch: 19
Loss: 0.11851860027220085
ROC train: 0.880814	val: 0.784009	test: 0.759756
PRC train: 0.479544	val: 0.294420	test: 0.154307

Epoch: 20
Loss: 0.11752166032855035
ROC train: 0.885334	val: 0.801247	test: 0.764262
PRC train: 0.497467	val: 0.269340	test: 0.169683

Epoch: 21
Loss: 0.11675673494085304
ROC train: 0.879694	val: 0.792699	test: 0.768609
PRC train: 0.446613	val: 0.304365	test: 0.224028

Epoch: 22
Loss: 0.11494621456098128
ROC train: 0.876599	val: 0.818116	test: 0.761203
PRC train: 0.445397	val: 0.306586	test: 0.184786

Epoch: 23
Loss: 0.11470778854486834
ROC train: 0.902504	val: 0.783207	test: 0.752774
PRC train: 0.526189	val: 0.301473	test: 0.167754

Epoch: 24
Loss: 0.11221755742015864
ROC train: 0.888813	val: 0.806667	test: 0.757442
PRC train: 0.472949	val: 0.288904	test: 0.202691

Epoch: 25
Loss: 0.1136605695978923
ROC train: 0.909824	val: 0.822124	test: 0.736833
PRC train: 0.564282	val: 0.346019	test: 0.154901

Epoch: 26
Loss: 0.11165696648097279
ROC train: 0.902683	val: 0.824962	test: 0.759213
PRC train: 0.511271	val: 0.296389	test: 0.161891

Epoch: 27
Loss: 0.11236520775790922
ROC train: 0.904434	val: 0.786716	test: 0.727237
PRC train: 0.530593	val: 0.342276	test: 0.161078

Epoch: 28
Loss: 0.10835942870721339
ROC train: 0.916476	val: 0.804429	test: 0.764839
PRC train: 0.570718	val: 0.342040	test: 0.210815

Epoch: 29
Loss: 0.10942196919038755
ROC train: 0.913658	val: 0.770132	test: 0.731899
PRC train: 0.558955	val: 0.317107	test: 0.151462

Epoch: 30
Loss: 0.1079170036273118
ROC train: 0.913243	val: 0.782530	test: 0.751183
PRC train: 0.530419	val: 0.247116	test: 0.154723

Epoch: 31
Loss: 0.10622578755804278
ROC train: 0.923538	val: 0.809854	test: 0.757346
PRC train: 0.592467	val: 0.371717	test: 0.202632

Epoch: 32
Loss: 0.10479576612524186
ROC train: 0.924736	val: 0.797888	test: 0.755675Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/hiv/noise=0.2.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:3
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.2
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/hiv/noise=0.2
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/hiv/noise=0.2/hiv_scaff_5_26-05_11-19-07  ]
[ Using Seed :  5  ]
[ Using device :  cuda:3  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.25905780470175593
ROC train: 0.724115	val: 0.681263	test: 0.680732
PRC train: 0.124817	val: 0.139476	test: 0.130506

Epoch: 2
Loss: 0.1495579944445422
ROC train: 0.734402	val: 0.714050	test: 0.701282
PRC train: 0.164144	val: 0.148982	test: 0.159445

Epoch: 3
Loss: 0.14631708547981456
ROC train: 0.769873	val: 0.755732	test: 0.701427
PRC train: 0.187329	val: 0.168264	test: 0.109135

Epoch: 4
Loss: 0.14321158699093417
ROC train: 0.780809	val: 0.717966	test: 0.707468
PRC train: 0.229567	val: 0.181441	test: 0.166255

Epoch: 5
Loss: 0.13996025104825877
ROC train: 0.792716	val: 0.779361	test: 0.679787
PRC train: 0.260462	val: 0.181080	test: 0.140926

Epoch: 6
Loss: 0.13745584566830082
ROC train: 0.801580	val: 0.742468	test: 0.717785
PRC train: 0.291768	val: 0.168373	test: 0.159208

Epoch: 7
Loss: 0.1347060468772926
ROC train: 0.797693	val: 0.709368	test: 0.669055
PRC train: 0.300389	val: 0.218261	test: 0.143280

Epoch: 8
Loss: 0.13434090350715808
ROC train: 0.813098	val: 0.715014	test: 0.709658
PRC train: 0.321592	val: 0.213066	test: 0.158850

Epoch: 9
Loss: 0.13361996536611928
ROC train: 0.825792	val: 0.764899	test: 0.721710
PRC train: 0.348211	val: 0.240300	test: 0.162401

Epoch: 10
Loss: 0.1306890483683396
ROC train: 0.827739	val: 0.714742	test: 0.720010
PRC train: 0.374586	val: 0.225133	test: 0.187505

Epoch: 11
Loss: 0.13008345119342812
ROC train: 0.841546	val: 0.786630	test: 0.718314
PRC train: 0.365200	val: 0.255466	test: 0.165174

Epoch: 12
Loss: 0.12719744408639644
ROC train: 0.845196	val: 0.731573	test: 0.730178
PRC train: 0.378375	val: 0.252024	test: 0.233336

Epoch: 13
Loss: 0.12674407697645101
ROC train: 0.852500	val: 0.753533	test: 0.734954
PRC train: 0.411871	val: 0.268074	test: 0.226793

Epoch: 14
Loss: 0.1255629549274597
ROC train: 0.850949	val: 0.734341	test: 0.714533
PRC train: 0.413407	val: 0.246709	test: 0.208308

Epoch: 15
Loss: 0.1239886724616896
ROC train: 0.862334	val: 0.745618	test: 0.722380
PRC train: 0.413427	val: 0.237622	test: 0.139413

Epoch: 16
Loss: 0.12267355513320785
ROC train: 0.857237	val: 0.787343	test: 0.745768
PRC train: 0.377741	val: 0.273736	test: 0.193490

Epoch: 17
Loss: 0.12135362885350476
ROC train: 0.867452	val: 0.794756	test: 0.709761
PRC train: 0.443271	val: 0.273313	test: 0.155443

Epoch: 18
Loss: 0.11932630702133566
ROC train: 0.880774	val: 0.779958	test: 0.749885
PRC train: 0.476920	val: 0.297274	test: 0.233163

Epoch: 19
Loss: 0.11744263647228327
ROC train: 0.877072	val: 0.764636	test: 0.714842
PRC train: 0.466222	val: 0.285609	test: 0.155798

Epoch: 20
Loss: 0.11649190142569127
ROC train: 0.891892	val: 0.790702	test: 0.731483
PRC train: 0.491908	val: 0.231582	test: 0.179386

Epoch: 21
Loss: 0.11708654337180717
ROC train: 0.880680	val: 0.718872	test: 0.728989
PRC train: 0.482894	val: 0.250386	test: 0.181814

Epoch: 22
Loss: 0.11526662196775656
ROC train: 0.896651	val: 0.785996	test: 0.721172
PRC train: 0.524975	val: 0.269203	test: 0.201174

Epoch: 23
Loss: 0.11481121555428851
ROC train: 0.899826	val: 0.781795	test: 0.729943
PRC train: 0.514527	val: 0.265198	test: 0.136136

Epoch: 24
Loss: 0.11262917072322554
ROC train: 0.902660	val: 0.736283	test: 0.716020
PRC train: 0.530409	val: 0.234896	test: 0.134583

Epoch: 25
Loss: 0.11113237829459308
ROC train: 0.898863	val: 0.796566	test: 0.741362
PRC train: 0.520070	val: 0.273210	test: 0.140990

Epoch: 26
Loss: 0.11101680873281035
ROC train: 0.905466	val: 0.780313	test: 0.737175
PRC train: 0.549635	val: 0.278302	test: 0.209772

Epoch: 27
Loss: 0.11097391491858778
ROC train: 0.916621	val: 0.784790	test: 0.712646
PRC train: 0.584413	val: 0.266719	test: 0.133213

Epoch: 28
Loss: 0.10809214210544527
ROC train: 0.904323	val: 0.785840	test: 0.738759
PRC train: 0.511098	val: 0.193964	test: 0.161847

Epoch: 29
Loss: 0.10643367900338313
ROC train: 0.918659	val: 0.752241	test: 0.721990
PRC train: 0.574017	val: 0.246912	test: 0.168771

Epoch: 30
Loss: 0.10568266509702783
ROC train: 0.928649	val: 0.790078	test: 0.735248
PRC train: 0.615782	val: 0.307700	test: 0.191883

Epoch: 31
Loss: 0.10419423388398413
ROC train: 0.930425	val: 0.770778	test: 0.732558
PRC train: 0.635972	val: 0.241081	test: 0.171832

Epoch: 32
Loss: 0.1048829081982983
ROC train: 0.929632	val: 0.795632	test: 0.732878Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphMVP/hiv/noise=0.2.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:3
  input_data_dir: 
  dataset: hiv
  num_workers: 0
  noise_level: 0.2
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphMVP_classification.pth
  output_model_dir: ../runs/static-noise/GraphMVP/hiv/noise=0.2
  verbose: False
[ Logs to :  ../runs/static-noise/GraphMVP/hiv/noise=0.2/hiv_scaff_6_26-05_11-19-07  ]
[ Using Seed :  6  ]
[ Using device :  cuda:3  ]
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.2792650721135863
ROC train: 0.712017	val: 0.693808	test: 0.712816
PRC train: 0.134529	val: 0.120658	test: 0.150806

Epoch: 2
Loss: 0.149471255768786
ROC train: 0.752195	val: 0.726347	test: 0.678453
PRC train: 0.173965	val: 0.151157	test: 0.135790

Epoch: 3
Loss: 0.14459773002826803
ROC train: 0.762400	val: 0.731892	test: 0.673020
PRC train: 0.214195	val: 0.149811	test: 0.133988

Epoch: 4
Loss: 0.14236492649186946
ROC train: 0.783784	val: 0.731028	test: 0.670722
PRC train: 0.247953	val: 0.181847	test: 0.156532

Epoch: 5
Loss: 0.13842779985908069
ROC train: 0.785147	val: 0.732899	test: 0.692145
PRC train: 0.251767	val: 0.177261	test: 0.114451

Epoch: 6
Loss: 0.13622305657760994
ROC train: 0.801076	val: 0.769514	test: 0.667620
PRC train: 0.282840	val: 0.187596	test: 0.098709

Epoch: 7
Loss: 0.1334006894543672
ROC train: 0.808166	val: 0.752747	test: 0.731140
PRC train: 0.266834	val: 0.213226	test: 0.142896

Epoch: 8
Loss: 0.13250797135840575
ROC train: 0.821756	val: 0.752737	test: 0.690166
PRC train: 0.334977	val: 0.172415	test: 0.108838

Epoch: 9
Loss: 0.13135529755422912
ROC train: 0.835969	val: 0.751552	test: 0.705398
PRC train: 0.360045	val: 0.209418	test: 0.139900

Epoch: 10
Loss: 0.12838395991798862
ROC train: 0.834873	val: 0.759210	test: 0.706047
PRC train: 0.364739	val: 0.217394	test: 0.137983

Epoch: 11
Loss: 0.1265305903824785
ROC train: 0.855999	val: 0.794334	test: 0.716356
PRC train: 0.404677	val: 0.209543	test: 0.131186

Epoch: 12
Loss: 0.12660377751773555
ROC train: 0.856736	val: 0.772475	test: 0.737623
PRC train: 0.380688	val: 0.231976	test: 0.185490

Epoch: 13
Loss: 0.12448823817941734
ROC train: 0.856521	val: 0.801698	test: 0.746445
PRC train: 0.415127	val: 0.205250	test: 0.138110

Epoch: 14
Loss: 0.1218344770124154
ROC train: 0.851791	val: 0.744942	test: 0.706319
PRC train: 0.384355	val: 0.243516	test: 0.191095

Epoch: 15
Loss: 0.12124036198414752
ROC train: 0.882150	val: 0.778586	test: 0.702014
PRC train: 0.477107	val: 0.226455	test: 0.157808

Epoch: 16
Loss: 0.11832530871955588
ROC train: 0.886486	val: 0.805216	test: 0.725966
PRC train: 0.475713	val: 0.247976	test: 0.142566

Epoch: 17
Loss: 0.11814126077912737
ROC train: 0.872428	val: 0.742737	test: 0.749124
PRC train: 0.445670	val: 0.247303	test: 0.187072

Epoch: 18
Loss: 0.11755790609071956
ROC train: 0.895381	val: 0.739130	test: 0.709911
PRC train: 0.511424	val: 0.181669	test: 0.156539

Epoch: 19
Loss: 0.114244923398465
ROC train: 0.894954	val: 0.766093	test: 0.725101
PRC train: 0.511776	val: 0.240007	test: 0.181350

Epoch: 20
Loss: 0.11277426649486733
ROC train: 0.899525	val: 0.750135	test: 0.703747
PRC train: 0.532627	val: 0.245459	test: 0.211931

Epoch: 21
Loss: 0.11164364706453717
ROC train: 0.900244	val: 0.758898	test: 0.722615
PRC train: 0.514990	val: 0.228591	test: 0.196370

Epoch: 22
Loss: 0.11121294214475055
ROC train: 0.906416	val: 0.756011	test: 0.716619
PRC train: 0.529023	val: 0.265230	test: 0.222043

Epoch: 23
Loss: 0.1104375999351221
ROC train: 0.909489	val: 0.746632	test: 0.717271
PRC train: 0.549809	val: 0.253887	test: 0.206414

Epoch: 24
Loss: 0.10956152283052033
ROC train: 0.909697	val: 0.745199	test: 0.703843
PRC train: 0.557027	val: 0.175551	test: 0.166692

Epoch: 25
Loss: 0.10782720812386287
ROC train: 0.919826	val: 0.757734	test: 0.718707
PRC train: 0.570460	val: 0.234960	test: 0.200255

Epoch: 26
Loss: 0.1079543273526398
ROC train: 0.921734	val: 0.793887	test: 0.706568
PRC train: 0.588101	val: 0.230830	test: 0.124632

Epoch: 27
Loss: 0.10445998736231722
ROC train: 0.923215	val: 0.777438	test: 0.719419
PRC train: 0.611101	val: 0.237657	test: 0.171496

Epoch: 28
Loss: 0.10521478566981776
ROC train: 0.917067	val: 0.772318	test: 0.714436
PRC train: 0.542801	val: 0.184974	test: 0.129028

Epoch: 29
Loss: 0.10379664737227773
ROC train: 0.935196	val: 0.782221	test: 0.685911
PRC train: 0.617191	val: 0.256906	test: 0.157852

Epoch: 30
Loss: 0.09890938472168866
ROC train: 0.928358	val: 0.758696	test: 0.706972
PRC train: 0.622320	val: 0.238655	test: 0.194067

Epoch: 31
Loss: 0.10100511015082499
ROC train: 0.939953	val: 0.757419	test: 0.716010
PRC train: 0.657224	val: 0.285742	test: 0.201753

Epoch: 32
Loss: 0.09931340376294928
ROC train: 0.943936	val: 0.767260	test: 0.708772
ROC train: 0.921085	val: 0.800136	test: 0.753869
PRC train: 0.600056	val: 0.346563	test: 0.242260

Epoch: 34
Loss: 0.0998517099581487
ROC train: 0.923159	val: 0.810678	test: 0.759756
PRC train: 0.600741	val: 0.394826	test: 0.207442

Epoch: 35
Loss: 0.10034529756919346
ROC train: 0.922517	val: 0.815658	test: 0.766121
PRC train: 0.600507	val: 0.375334	test: 0.217752

Epoch: 36
Loss: 0.09936862563065024
ROC train: 0.919942	val: 0.797625	test: 0.747861
PRC train: 0.594768	val: 0.385535	test: 0.218936

Epoch: 37
Loss: 0.0996390127862174
ROC train: 0.921618	val: 0.814806	test: 0.773086
PRC train: 0.589626	val: 0.335270	test: 0.187466

Epoch: 38
Loss: 0.09815706056553056
ROC train: 0.925639	val: 0.815467	test: 0.753081
PRC train: 0.594756	val: 0.360571	test: 0.186691

Epoch: 39
Loss: 0.09870846213254993
ROC train: 0.931474	val: 0.817923	test: 0.777956
PRC train: 0.611051	val: 0.362588	test: 0.209028

Epoch: 40
Loss: 0.0975384257215329
ROC train: 0.923705	val: 0.825400	test: 0.753840
PRC train: 0.588234	val: 0.369592	test: 0.156138

Epoch: 41
Loss: 0.09707350781128685
ROC train: 0.937462	val: 0.814610	test: 0.771255
PRC train: 0.629996	val: 0.364256	test: 0.214433

Epoch: 42
Loss: 0.09601831453470978
ROC train: 0.929992	val: 0.815002	test: 0.764362
PRC train: 0.599014	val: 0.350193	test: 0.200089

Epoch: 43
Loss: 0.09643803445952961
ROC train: 0.935037	val: 0.802993	test: 0.765204
PRC train: 0.613973	val: 0.388254	test: 0.222001

Epoch: 44
Loss: 0.0955198419673787
ROC train: 0.936942	val: 0.816037	test: 0.768671
PRC train: 0.636699	val: 0.387329	test: 0.207207

Epoch: 45
Loss: 0.09516762904862265
ROC train: 0.940490	val: 0.825274	test: 0.752297
PRC train: 0.628770	val: 0.328754	test: 0.171043

Epoch: 46
Loss: 0.09564805293717833
ROC train: 0.937974	val: 0.816001	test: 0.762512
PRC train: 0.618677	val: 0.347667	test: 0.171635

Epoch: 47
Loss: 0.09439785173630917
ROC train: 0.939895	val: 0.808963	test: 0.761714
PRC train: 0.619107	val: 0.380869	test: 0.184889

Epoch: 48
Loss: 0.09332339577481366
ROC train: 0.944053	val: 0.794242	test: 0.757278
PRC train: 0.657268	val: 0.362774	test: 0.216521

Epoch: 49
Loss: 0.09357191063147122
ROC train: 0.945517	val: 0.828878	test: 0.773103
PRC train: 0.643334	val: 0.396090	test: 0.218513

Epoch: 50
Loss: 0.09343109109843406
ROC train: 0.946669	val: 0.809012	test: 0.766208
PRC train: 0.651024	val: 0.371898	test: 0.248972

Epoch: 51
Loss: 0.09205345383012081
ROC train: 0.946563	val: 0.811174	test: 0.771156
PRC train: 0.656789	val: 0.370768	test: 0.192031

Epoch: 52
Loss: 0.09319550790925102
ROC train: 0.932291	val: 0.786927	test: 0.742007
PRC train: 0.612017	val: 0.312833	test: 0.171150

Epoch: 53
Loss: 0.09154830490320309
ROC train: 0.943049	val: 0.806070	test: 0.768219
PRC train: 0.638510	val: 0.367204	test: 0.207135

Epoch: 54
Loss: 0.09161594531209062
ROC train: 0.949775	val: 0.810194	test: 0.769524
PRC train: 0.664983	val: 0.380503	test: 0.216342

Epoch: 55
Loss: 0.09146739073174051
ROC train: 0.951681	val: 0.806091	test: 0.765248
PRC train: 0.665731	val: 0.363666	test: 0.213882

Epoch: 56
Loss: 0.09022572548996505
ROC train: 0.947378	val: 0.795218	test: 0.747102
PRC train: 0.655852	val: 0.352718	test: 0.168292

Epoch: 57
Loss: 0.0902806117875423
ROC train: 0.950741	val: 0.795065	test: 0.784977
PRC train: 0.663832	val: 0.322690	test: 0.193107

Epoch: 58
Loss: 0.08859090547960234
ROC train: 0.952737	val: 0.811006	test: 0.773541
PRC train: 0.673240	val: 0.381121	test: 0.217609

Epoch: 59
Loss: 0.08940317426782722
ROC train: 0.947046	val: 0.789529	test: 0.753139
PRC train: 0.647944	val: 0.347056	test: 0.192978

Epoch: 60
Loss: 0.08976054998779147
ROC train: 0.951599	val: 0.800617	test: 0.759864
PRC train: 0.655121	val: 0.313269	test: 0.186652

Epoch: 61
Loss: 0.08799622548841907
ROC train: 0.949830	val: 0.808149	test: 0.751055
PRC train: 0.653708	val: 0.324519	test: 0.163477

Epoch: 62
Loss: 0.08744137442297834
ROC train: 0.953887	val: 0.801652	test: 0.755986
PRC train: 0.671932	val: 0.347273	test: 0.181935

Epoch: 63
Loss: 0.08801720093413325
ROC train: 0.953140	val: 0.797466	test: 0.736318
PRC train: 0.681245	val: 0.315767	test: 0.162137

Epoch: 64
Loss: 0.0877387796394635
ROC train: 0.958541	val: 0.814120	test: 0.764321
PRC train: 0.699193	val: 0.355564	test: 0.206823

Epoch: 65
Loss: 0.08698805104824027
ROC train: 0.944210	val: 0.808198	test: 0.738608
PRC train: 0.648001	val: 0.315109	test: 0.120970

Epoch: 66
Loss: 0.08577960352355327
ROC train: 0.956308	val: 0.786584	test: 0.751268
PRC train: 0.681667	val: 0.302172	test: 0.176259

Epoch: 67
Loss: 0.08602418126144072
ROC train: 0.959554	val: 0.808281	test: 0.772835
PRC train: 0.697663	val: 0.350040	test: 0.181359

Epoch: 68
Loss: 0.08521875177366668
ROC train: 0.958736	val: 0.807279	test: 0.769584
PRC train: 0.695802	val: 0.388550	test: 0.197089

Epoch: 69
Loss: 0.08493903247045773
ROC train: 0.949682	val: 0.804665	test: 0.771600
PRC train: 0.651992	val: 0.376445	test: 0.188707

Epoch: 70
Loss: 0.08603674696763865
ROC train: 0.963426	val: 0.803421	test: 0.763130
PRC train: 0.705003	val: 0.331039	test: 0.169491

Epoch: 71
Loss: 0.08499147886956153
ROC train: 0.965409	val: 0.799759	test: 0.766376
PRC train: 0.711808	val: 0.330433	test: 0.202554

Epoch: 72
Loss: 0.08433903215207715
ROC train: 0.960030	val: 0.783004	test: 0.754097
PRC train: 0.689704	val: 0.297121	test: 0.192238

Epoch: 73
Loss: 0.08381910524095695
ROC train: 0.951406	val: 0.809600	test: 0.748369
PRC train: 0.642524	val: 0.244587	test: 0.107081

Epoch: 74
Loss: 0.08267895713879439
ROC train: 0.966254	val: 0.797784	test: 0.761102
PRC train: 0.711013	val: 0.344076	test: 0.188378

Epoch: 75
Loss: 0.08320880547626505
ROC train: 0.967661	val: 0.791409	test: 0.772634
PRC train: 0.722845	val: 0.329649	test: 0.187356

Epoch: 76
Loss: 0.08263550424353112
ROC train: 0.971434	val: 0.804551	test: 0.758667
PRC train: 0.732547	val: 0.307701	test: 0.145071

Epoch: 77
Loss: 0.08262255388148818
ROC train: 0.970039	val: 0.823731	test: 0.775787
PRC train: 0.729468	val: 0.341611	test: 0.185592

Epoch: 78
Loss: 0.08214379088321186
ROC train: 0.967833	val: 0.816294	test: 0.777640
PRC train: 0.714277	val: 0.372316	test: 0.207237

Epoch: 79
Loss: 0.08186060089805118
ROC train: 0.970195	val: 0.811860	test: 0.756029
PRC train: 0.737593	val: 0.352565	test: 0.167141

Epoch: 80
Loss: 0.08120265363736878
ROC train: 0.970931	val: 0.814435	test: 0.763982
PRC train: 0.733894	val: 0.377595	test: 0.217293

Epoch: 81
Loss: 0.07996256739314074
ROC train: 0.971404	val: 0.806496	test: 0.770239
PRC train: 0.740047	val: 0.353117	test: 0.183858

Epoch: 82
Loss: 0.07975116653464262
ROC train: 0.967498	val: 0.826655	test: 0.771415
PRC train: 0.719822	val: 0.324196	test: 0.187967

Epoch: 83
Loss: 0.07961595401665059
ROC train: 0.968852	val: 0.788957	test: 0.747880
PRC train: 0.725008	val: 0.333267	test: 0.144793

Epoch: 84
Loss: 0.07951725165371099
ROC train: 0.970115	val: 0.797711	test: 0.768605
PRC train: 0.730048	val: 0.330961	test: 0.205747

Epoch: 85
Loss: 0.079401924843577
ROC train: 0.970344	val: 0.782432	test: 0.741078
PRC train: 0.741002	val: 0.312972	test: 0.149779

Epoch: 86
Loss: 0.07897849182993531
ROC train: 0.969582	val: 0.800265	test: 0.758004
PRC train: 0.736532	val: 0.326977	test: 0.138554

Epoch: 87
Loss: 0.07796179296992765
ROC train: 0.972919	val: 0.801012	test: 0.767778
PRC train: 0.739619	val: 0.295713	test: 0.183962

Epoch: 88
Loss: 0.07911796391089923
ROC train: 0.973326	val: 0.792910	test: 0.754464
PRC train: 0.744368	val: 0.309285	test: 0.170654

Epoch: 89
Loss: 0.07728457852182928
ROC train: 0.973076	val: 0.802604	test: 0.774096
PRC train: 0.740530	val: 0.315676	test: 0.210562

Epoch: 90
Loss: 0.0788972946978991
ROC train: 0.972665	val: 0.825440	test: 0.757411
PRC train: 0.743222	val: 0.324466	test: 0.175498

Epoch: 91
Loss: 0.07642282471651879
ROC train: 0.968699	val: 0.815736	test: 0.762498
PRC train: 0.738061	val: 0.333340	test: 0.199172

Epoch: 92
Loss: 0.07620380000519396
ROC train: 0.976376	val: 0.814267	test: 0.756849
PRC train: 0.759713	val: 0.305384	test: 0.171646

Epoch: 93
Loss: 0.07654340521055264
ROC train: 0.975609	val: 0.813027	test: 0.751117
PRC train: 0.756335	val: 0.314898	test: 0.169428

Epoch: 94
Loss: 0.07680663578666803
ROC train: 0.915217	val: 0.810020	test: 0.763524
PRC train: 0.583946	val: 0.303751	test: 0.192453

Epoch: 34
Loss: 0.09989119254068231
ROC train: 0.915898	val: 0.822672	test: 0.755214
PRC train: 0.575139	val: 0.308272	test: 0.178519

Epoch: 35
Loss: 0.10013955829259834
ROC train: 0.923463	val: 0.815654	test: 0.776946
PRC train: 0.602348	val: 0.354371	test: 0.229909

Epoch: 36
Loss: 0.10061068030239642
ROC train: 0.923754	val: 0.786498	test: 0.764238
PRC train: 0.585561	val: 0.321997	test: 0.196034

Epoch: 37
Loss: 0.09907431739706968
ROC train: 0.917645	val: 0.797181	test: 0.763781
PRC train: 0.583952	val: 0.320563	test: 0.212911

Epoch: 38
Loss: 0.09945093424955385
ROC train: 0.919809	val: 0.801551	test: 0.773661
PRC train: 0.583268	val: 0.304714	test: 0.193966

Epoch: 39
Loss: 0.0983309817915711
ROC train: 0.923964	val: 0.811661	test: 0.765345
PRC train: 0.599630	val: 0.325768	test: 0.194876

Epoch: 40
Loss: 0.09754101716463288
ROC train: 0.915581	val: 0.811900	test: 0.761405
PRC train: 0.587351	val: 0.309345	test: 0.153310

Epoch: 41
Loss: 0.0979533677463152
ROC train: 0.925734	val: 0.805007	test: 0.756919
PRC train: 0.601532	val: 0.295442	test: 0.181391

Epoch: 42
Loss: 0.09813457651395002
ROC train: 0.932664	val: 0.806532	test: 0.763263
PRC train: 0.616376	val: 0.289768	test: 0.175187

Epoch: 43
Loss: 0.09624430363638192
ROC train: 0.934058	val: 0.814502	test: 0.793708
PRC train: 0.618813	val: 0.351193	test: 0.228315

Epoch: 44
Loss: 0.09639189302075092
ROC train: 0.933439	val: 0.802292	test: 0.775708
PRC train: 0.629143	val: 0.317493	test: 0.192134

Epoch: 45
Loss: 0.09642496430137565
ROC train: 0.921059	val: 0.788957	test: 0.752624
PRC train: 0.583092	val: 0.273371	test: 0.171123

Epoch: 46
Loss: 0.09424503045995138
ROC train: 0.934595	val: 0.799156	test: 0.777309
PRC train: 0.621780	val: 0.323535	test: 0.205529

Epoch: 47
Loss: 0.09516503537128645
ROC train: 0.933164	val: 0.810090	test: 0.768265
PRC train: 0.620970	val: 0.293025	test: 0.153357

Epoch: 48
Loss: 0.09457951792068037
ROC train: 0.936423	val: 0.816732	test: 0.756523
PRC train: 0.636378	val: 0.298509	test: 0.195834

Epoch: 49
Loss: 0.093759564685391
ROC train: 0.930511	val: 0.813376	test: 0.783547
PRC train: 0.614692	val: 0.321331	test: 0.192721

Epoch: 50
Loss: 0.09318464301844176
ROC train: 0.935828	val: 0.809937	test: 0.777240
PRC train: 0.629874	val: 0.327558	test: 0.210580

Epoch: 51
Loss: 0.09254232796466651
ROC train: 0.935265	val: 0.788880	test: 0.747792
PRC train: 0.626094	val: 0.298193	test: 0.175027

Epoch: 52
Loss: 0.09235149505489185
ROC train: 0.944985	val: 0.794487	test: 0.779214
PRC train: 0.648034	val: 0.348835	test: 0.220205

Epoch: 53
Loss: 0.09201697067132689
ROC train: 0.939757	val: 0.816040	test: 0.774045
PRC train: 0.625850	val: 0.322887	test: 0.200359

Epoch: 54
Loss: 0.0918879176077882
ROC train: 0.941098	val: 0.816089	test: 0.762350
PRC train: 0.636348	val: 0.306287	test: 0.204998

Epoch: 55
Loss: 0.09258085936360447
ROC train: 0.948524	val: 0.809802	test: 0.762359
PRC train: 0.660069	val: 0.315101	test: 0.165367

Epoch: 56
Loss: 0.09176365635548134
ROC train: 0.946620	val: 0.813513	test: 0.774053
PRC train: 0.667328	val: 0.296737	test: 0.192132

Epoch: 57
Loss: 0.09054722653807197
ROC train: 0.953371	val: 0.794698	test: 0.767483
PRC train: 0.669347	val: 0.299985	test: 0.193776

Epoch: 58
Loss: 0.09020153697415012
ROC train: 0.951942	val: 0.790907	test: 0.753217
PRC train: 0.671554	val: 0.299945	test: 0.194126

Epoch: 59
Loss: 0.08986416469698685
ROC train: 0.953087	val: 0.802671	test: 0.757844
PRC train: 0.681215	val: 0.308195	test: 0.206271

Epoch: 60
Loss: 0.08841836167250638
ROC train: 0.951221	val: 0.811477	test: 0.760996
PRC train: 0.672036	val: 0.305935	test: 0.150816

Epoch: 61
Loss: 0.08980054176158819
ROC train: 0.950168	val: 0.806667	test: 0.762939
PRC train: 0.672442	val: 0.307209	test: 0.172247

Epoch: 62
Loss: 0.08930769309195646
ROC train: 0.949725	val: 0.813461	test: 0.762344
PRC train: 0.662640	val: 0.266188	test: 0.126350

Epoch: 63
Loss: 0.08733175979636479
ROC train: 0.948911	val: 0.805203	test: 0.772135
PRC train: 0.662741	val: 0.307008	test: 0.216674

Epoch: 64
Loss: 0.08813967233785666
ROC train: 0.954459	val: 0.803816	test: 0.767516
PRC train: 0.679533	val: 0.312604	test: 0.232190

Epoch: 65
Loss: 0.0875244925183809
ROC train: 0.958351	val: 0.792894	test: 0.763960
PRC train: 0.694533	val: 0.293278	test: 0.160100

Epoch: 66
Loss: 0.08697486381958139
ROC train: 0.958167	val: 0.793369	test: 0.765897
PRC train: 0.688017	val: 0.311219	test: 0.208374

Epoch: 67
Loss: 0.08682388504203187
ROC train: 0.956283	val: 0.802824	test: 0.755735
PRC train: 0.686938	val: 0.282461	test: 0.164040

Epoch: 68
Loss: 0.08764436859996542
ROC train: 0.959154	val: 0.786869	test: 0.752593
PRC train: 0.696935	val: 0.273424	test: 0.177992

Epoch: 69
Loss: 0.08613748352794859
ROC train: 0.961811	val: 0.799625	test: 0.762002
PRC train: 0.704257	val: 0.274362	test: 0.200213

Epoch: 70
Loss: 0.08473833744399223
ROC train: 0.962085	val: 0.816113	test: 0.757769
PRC train: 0.712616	val: 0.279520	test: 0.154959

Epoch: 71
Loss: 0.08492470315979515
ROC train: 0.959236	val: 0.798250	test: 0.754843
PRC train: 0.686372	val: 0.275400	test: 0.156405

Epoch: 72
Loss: 0.08494759871876692
ROC train: 0.962852	val: 0.783632	test: 0.763418
PRC train: 0.696777	val: 0.288328	test: 0.174463

Epoch: 73
Loss: 0.0838221147241446
ROC train: 0.961348	val: 0.802843	test: 0.747024
PRC train: 0.702333	val: 0.251457	test: 0.141509

Epoch: 74
Loss: 0.08350174442853149
ROC train: 0.961590	val: 0.788544	test: 0.761961
PRC train: 0.695076	val: 0.300626	test: 0.216192

Epoch: 75
Loss: 0.08511781309860024
ROC train: 0.963249	val: 0.823603	test: 0.767006
PRC train: 0.704809	val: 0.295311	test: 0.169842

Epoch: 76
Loss: 0.08343453604246687
ROC train: 0.964357	val: 0.819359	test: 0.780677
PRC train: 0.709695	val: 0.314565	test: 0.223993

Epoch: 77
Loss: 0.08287317782285222
ROC train: 0.965480	val: 0.791559	test: 0.768924
PRC train: 0.715932	val: 0.276603	test: 0.149759

Epoch: 78
Loss: 0.08434472227968133
ROC train: 0.968118	val: 0.809913	test: 0.762724
PRC train: 0.730413	val: 0.319816	test: 0.171166

Epoch: 79
Loss: 0.08098271059893243
ROC train: 0.969397	val: 0.814607	test: 0.763392
PRC train: 0.732657	val: 0.290195	test: 0.183655

Epoch: 80
Loss: 0.08102220374414801
ROC train: 0.967911	val: 0.821426	test: 0.772614
PRC train: 0.734901	val: 0.327360	test: 0.185150

Epoch: 81
Loss: 0.08095823819109682
ROC train: 0.968996	val: 0.787199	test: 0.766658
PRC train: 0.729739	val: 0.313498	test: 0.177623

Epoch: 82
Loss: 0.08114358430598044
ROC train: 0.969746	val: 0.808327	test: 0.761747
PRC train: 0.737272	val: 0.322959	test: 0.179703

Epoch: 83
Loss: 0.08126687710125373
ROC train: 0.971310	val: 0.819818	test: 0.777186
PRC train: 0.739029	val: 0.321966	test: 0.207626

Epoch: 84
Loss: 0.08015293905535109
ROC train: 0.973938	val: 0.804009	test: 0.781890
PRC train: 0.752272	val: 0.305031	test: 0.210886

Epoch: 85
Loss: 0.08096822827898648
ROC train: 0.970831	val: 0.801290	test: 0.770950
PRC train: 0.737400	val: 0.297060	test: 0.215044

Epoch: 86
Loss: 0.07803878230177341
ROC train: 0.974612	val: 0.803642	test: 0.767115
PRC train: 0.742125	val: 0.322901	test: 0.221937

Epoch: 87
Loss: 0.07930848801739696
ROC train: 0.973776	val: 0.804518	test: 0.759401
PRC train: 0.745677	val: 0.275614	test: 0.149713

Epoch: 88
Loss: 0.0791833817500372
ROC train: 0.968025	val: 0.791737	test: 0.753947
PRC train: 0.716048	val: 0.292395	test: 0.171020

Epoch: 89
Loss: 0.07733454154473535
ROC train: 0.972388	val: 0.795166	test: 0.762493
PRC train: 0.748486	val: 0.318080	test: 0.171060

Epoch: 90
Loss: 0.07750379475169639
ROC train: 0.973052	val: 0.791511	test: 0.754733
PRC train: 0.752906	val: 0.309147	test: 0.172233

Epoch: 91
Loss: 0.07708701925328036
ROC train: 0.971681	val: 0.770625	test: 0.768367
PRC train: 0.747531	val: 0.301916	test: 0.215576

Epoch: 92
Loss: 0.07775084131677365
ROC train: 0.973849	val: 0.802916	test: 0.767157
PRC train: 0.762236	val: 0.315755	test: 0.194949

Epoch: 93
Loss: 0.07591704656854678
ROC train: 0.972760	val: 0.812546	test: 0.758885
PRC train: 0.739911	val: 0.299438	test: 0.181820

Epoch: 94
Loss: 0.07624893651774355
PRC train: 0.627233	val: 0.355780	test: 0.214363

Epoch: 33
Loss: 0.09713324647620662
ROC train: 0.920292	val: 0.805889	test: 0.729160
PRC train: 0.616392	val: 0.337500	test: 0.160696

Epoch: 34
Loss: 0.09694203038151067
ROC train: 0.927407	val: 0.780267	test: 0.735632
PRC train: 0.622998	val: 0.366509	test: 0.226142

Epoch: 35
Loss: 0.09493874080483983
ROC train: 0.938189	val: 0.831637	test: 0.758537
PRC train: 0.663484	val: 0.370043	test: 0.199453

Epoch: 36
Loss: 0.0950957195194122
ROC train: 0.939838	val: 0.790396	test: 0.739321
PRC train: 0.657739	val: 0.281847	test: 0.184204

Epoch: 37
Loss: 0.09213567173875112
ROC train: 0.937815	val: 0.805451	test: 0.727822
PRC train: 0.671122	val: 0.379708	test: 0.185179

Epoch: 38
Loss: 0.09323409932035874
ROC train: 0.938928	val: 0.810825	test: 0.750188
PRC train: 0.656946	val: 0.395902	test: 0.223738

Epoch: 39
Loss: 0.09225964656867318
ROC train: 0.944540	val: 0.805670	test: 0.739663
PRC train: 0.674827	val: 0.357919	test: 0.189599

Epoch: 40
Loss: 0.09025779197890292
ROC train: 0.935774	val: 0.799784	test: 0.779666
PRC train: 0.666801	val: 0.385943	test: 0.235069

Epoch: 41
Loss: 0.09093836137742715
ROC train: 0.936125	val: 0.811024	test: 0.764256
PRC train: 0.624215	val: 0.343662	test: 0.222722

Epoch: 42
Loss: 0.09213028495560366
ROC train: 0.949934	val: 0.810204	test: 0.753574
PRC train: 0.689671	val: 0.361838	test: 0.204449

Epoch: 43
Loss: 0.08840106879504693
ROC train: 0.952907	val: 0.809313	test: 0.751400
PRC train: 0.697532	val: 0.381861	test: 0.228965

Epoch: 44
Loss: 0.08849700694387001
ROC train: 0.957247	val: 0.806018	test: 0.752270
PRC train: 0.726128	val: 0.362989	test: 0.211266

Epoch: 45
Loss: 0.08703381322834391
ROC train: 0.947255	val: 0.810032	test: 0.776021
PRC train: 0.707075	val: 0.403960	test: 0.228737

Epoch: 46
Loss: 0.08740873803762761
ROC train: 0.955809	val: 0.803192	test: 0.736940
PRC train: 0.716548	val: 0.350114	test: 0.206195

Epoch: 47
Loss: 0.08658672643232922
ROC train: 0.961123	val: 0.792108	test: 0.736289
PRC train: 0.730009	val: 0.364389	test: 0.210104

Epoch: 48
Loss: 0.08561292028820319
ROC train: 0.960034	val: 0.801835	test: 0.724330
PRC train: 0.736319	val: 0.339493	test: 0.208341

Epoch: 49
Loss: 0.0833073835038918
ROC train: 0.959717	val: 0.786777	test: 0.757462
PRC train: 0.733785	val: 0.378718	test: 0.213499

Epoch: 50
Loss: 0.0840446695157693
ROC train: 0.964039	val: 0.801382	test: 0.755942
PRC train: 0.745330	val: 0.386511	test: 0.223974

Epoch: 51
Loss: 0.08419015968848043
ROC train: 0.961064	val: 0.796100	test: 0.768113
PRC train: 0.726135	val: 0.391352	test: 0.241991

Epoch: 52
Loss: 0.0821949409911616
ROC train: 0.966346	val: 0.801670	test: 0.773449
PRC train: 0.753860	val: 0.389088	test: 0.200776

Epoch: 53
Loss: 0.0825113308950768
ROC train: 0.958476	val: 0.813367	test: 0.766797
PRC train: 0.725143	val: 0.406417	test: 0.223701

Epoch: 54
Loss: 0.08010641171720172
ROC train: 0.968008	val: 0.805179	test: 0.769760
PRC train: 0.766401	val: 0.384101	test: 0.195655

Epoch: 55
Loss: 0.07897008234054562
ROC train: 0.966463	val: 0.789378	test: 0.752595
PRC train: 0.754292	val: 0.375951	test: 0.195977

Epoch: 56
Loss: 0.07985101391720699
ROC train: 0.967519	val: 0.811104	test: 0.766627
PRC train: 0.772426	val: 0.379920	test: 0.208160

Epoch: 57
Loss: 0.07860505116011689
ROC train: 0.968522	val: 0.816462	test: 0.760669
PRC train: 0.765677	val: 0.370873	test: 0.164025

Epoch: 58
Loss: 0.0813447036286031
ROC train: 0.975605	val: 0.789793	test: 0.774911
PRC train: 0.800821	val: 0.357152	test: 0.224126

Epoch: 59
Loss: 0.07943074577064245
ROC train: 0.970833	val: 0.783133	test: 0.753105
PRC train: 0.759034	val: 0.352988	test: 0.227190

Epoch: 60
Loss: 0.0767431067689199
ROC train: 0.975085	val: 0.803816	test: 0.762041
PRC train: 0.806788	val: 0.371869	test: 0.192631

Epoch: 61
Loss: 0.07562968465328647
ROC train: 0.975849	val: 0.786685	test: 0.769947
PRC train: 0.807770	val: 0.356126	test: 0.196290

Epoch: 62
Loss: 0.07585185697352421
ROC train: 0.974562	val: 0.786180	test: 0.782931
PRC train: 0.787186	val: 0.396329	test: 0.231238

Epoch: 63
Loss: 0.07435033801067269
ROC train: 0.974821	val: 0.799135	test: 0.775936
PRC train: 0.778923	val: 0.363585	test: 0.228083

Epoch: 64
Loss: 0.07541706699928755
ROC train: 0.972871	val: 0.797518	test: 0.764686
PRC train: 0.789857	val: 0.392079	test: 0.143202

Epoch: 65
Loss: 0.0736435775960162
ROC train: 0.979258	val: 0.786544	test: 0.764497
PRC train: 0.816122	val: 0.330685	test: 0.205623

Epoch: 66
Loss: 0.07332372087681954
ROC train: 0.975639	val: 0.793256	test: 0.743023
PRC train: 0.804451	val: 0.324257	test: 0.194477

Epoch: 67
Loss: 0.07318946427794235
ROC train: 0.979834	val: 0.799392	test: 0.763939
PRC train: 0.815318	val: 0.363659	test: 0.181294

Epoch: 68
Loss: 0.07280605809504927
ROC train: 0.981605	val: 0.814460	test: 0.778769
PRC train: 0.835046	val: 0.352234	test: 0.203933

Epoch: 69
Loss: 0.06904852645869104
ROC train: 0.982565	val: 0.803544	test: 0.778584
PRC train: 0.840231	val: 0.366411	test: 0.214340

Epoch: 70
Loss: 0.07127054322637685
ROC train: 0.982826	val: 0.802230	test: 0.769337
PRC train: 0.847820	val: 0.392480	test: 0.190204

Epoch: 71
Loss: 0.06820922586821646
ROC train: 0.983087	val: 0.798945	test: 0.779204
PRC train: 0.837942	val: 0.389714	test: 0.241628

Epoch: 72
Loss: 0.06844536000878673
ROC train: 0.981350	val: 0.808602	test: 0.757460
PRC train: 0.826324	val: 0.359463	test: 0.182187

Epoch: 73
Loss: 0.06978051512345806
ROC train: 0.983401	val: 0.796997	test: 0.759449
PRC train: 0.843590	val: 0.328322	test: 0.173494

Epoch: 74
Loss: 0.06771803162553416
ROC train: 0.983868	val: 0.798406	test: 0.782325
PRC train: 0.848940	val: 0.354875	test: 0.205618

Epoch: 75
Loss: 0.06506016438716616
ROC train: 0.981722	val: 0.797855	test: 0.773837
PRC train: 0.836799	val: 0.355017	test: 0.197311

Epoch: 76
Loss: 0.06913011063517925
ROC train: 0.984968	val: 0.802928	test: 0.773381
PRC train: 0.855990	val: 0.361679	test: 0.200227

Epoch: 77
Loss: 0.06507671089068817
ROC train: 0.986865	val: 0.794419	test: 0.772707
PRC train: 0.859405	val: 0.323059	test: 0.141376

Epoch: 78
Loss: 0.06494198803696116
ROC train: 0.987819	val: 0.792692	test: 0.765559
PRC train: 0.870177	val: 0.397508	test: 0.231513

Epoch: 79
Loss: 0.06446184731632268
ROC train: 0.987926	val: 0.802687	test: 0.774486
PRC train: 0.876276	val: 0.399920	test: 0.225153

Epoch: 80
Loss: 0.0642064356722746
ROC train: 0.985721	val: 0.817714	test: 0.784351
PRC train: 0.859591	val: 0.342096	test: 0.184642

Epoch: 81
Loss: 0.06364254886472413
ROC train: 0.987666	val: 0.814071	test: 0.782891
PRC train: 0.863844	val: 0.362505	test: 0.174757

Epoch: 82
Loss: 0.06373528002594965
ROC train: 0.991683	val: 0.799401	test: 0.776434
PRC train: 0.902047	val: 0.373379	test: 0.203506

Epoch: 83
Loss: 0.06169324620130002
ROC train: 0.991003	val: 0.806943	test: 0.763628
PRC train: 0.894874	val: 0.368623	test: 0.192802

Epoch: 84
Loss: 0.06181089226718885
ROC train: 0.991508	val: 0.797625	test: 0.779428
PRC train: 0.894473	val: 0.362555	test: 0.225641

Epoch: 85
Loss: 0.05935926552758209
ROC train: 0.987438	val: 0.801955	test: 0.758802
PRC train: 0.874438	val: 0.359327	test: 0.158922

Epoch: 86
Loss: 0.060508063397663465
ROC train: 0.989263	val: 0.812035	test: 0.763006
PRC train: 0.875193	val: 0.352256	test: 0.158777

Epoch: 87
Loss: 0.059713194100974164
ROC train: 0.992862	val: 0.797686	test: 0.771740
PRC train: 0.905511	val: 0.355513	test: 0.174992

Epoch: 88
Loss: 0.06038502802610579
ROC train: 0.991600	val: 0.810657	test: 0.769320
PRC train: 0.901648	val: 0.376730	test: 0.203981

Epoch: 89
Loss: 0.06025780239382503
ROC train: 0.992957	val: 0.793917	test: 0.771465
PRC train: 0.912819	val: 0.336556	test: 0.171449

Epoch: 90
Loss: 0.0595652698253947
ROC train: 0.993154	val: 0.804306	test: 0.768899
PRC train: 0.914511	val: 0.350379	test: 0.190480

Epoch: 91
Loss: 0.057414214451458376
ROC train: 0.991989	val: 0.813520	test: 0.780021
PRC train: 0.900665	val: 0.364398	test: 0.214839

Epoch: 92
Loss: 0.05694975037960437
ROC train: 0.993011	val: 0.817571	test: 0.768022
PRC train: 0.913083	val: 0.354301	test: 0.211248

Epoch: 93
Loss: 0.05873342456525338
ROC train: 0.993796	val: 0.803841	test: 0.770343
ROC train: 0.912753	val: 0.783899	test: 0.749060
PRC train: 0.547445	val: 0.321038	test: 0.196360

Epoch: 34
Loss: 0.09993153422344296
ROC train: 0.916057	val: 0.825467	test: 0.766034
PRC train: 0.576898	val: 0.381890	test: 0.252419

Epoch: 35
Loss: 0.10109481718530557
ROC train: 0.921486	val: 0.798155	test: 0.753680
PRC train: 0.581603	val: 0.370716	test: 0.182025

Epoch: 36
Loss: 0.09925058967122666
ROC train: 0.922050	val: 0.846252	test: 0.759874
PRC train: 0.587221	val: 0.388691	test: 0.181898

Epoch: 37
Loss: 0.09808428512248758
ROC train: 0.927154	val: 0.823351	test: 0.770913
PRC train: 0.605367	val: 0.394498	test: 0.202860

Epoch: 38
Loss: 0.09881462728301203
ROC train: 0.926177	val: 0.825085	test: 0.778698
PRC train: 0.598278	val: 0.389239	test: 0.247041

Epoch: 39
Loss: 0.0992889645713325
ROC train: 0.932876	val: 0.811633	test: 0.770718
PRC train: 0.616844	val: 0.390438	test: 0.242790

Epoch: 40
Loss: 0.09722626708113101
ROC train: 0.923819	val: 0.824867	test: 0.694422
PRC train: 0.581407	val: 0.297963	test: 0.089131

Epoch: 41
Loss: 0.09677930866724999
ROC train: 0.931483	val: 0.810384	test: 0.765538
PRC train: 0.618536	val: 0.373803	test: 0.203012

Epoch: 42
Loss: 0.09623142590691358
ROC train: 0.934491	val: 0.796970	test: 0.766809
PRC train: 0.622492	val: 0.346308	test: 0.197018

Epoch: 43
Loss: 0.09639855927099086
ROC train: 0.936075	val: 0.823468	test: 0.777854
PRC train: 0.623726	val: 0.402164	test: 0.198103

Epoch: 44
Loss: 0.09461868866763852
ROC train: 0.933550	val: 0.808936	test: 0.774347
PRC train: 0.612680	val: 0.394085	test: 0.216894

Epoch: 45
Loss: 0.0951952931144264
ROC train: 0.937191	val: 0.834204	test: 0.766915
PRC train: 0.626723	val: 0.361646	test: 0.185588

Epoch: 46
Loss: 0.09386964539349708
ROC train: 0.937547	val: 0.812087	test: 0.721640
PRC train: 0.617689	val: 0.333291	test: 0.157442

Epoch: 47
Loss: 0.09384412879842476
ROC train: 0.944094	val: 0.815020	test: 0.757556
PRC train: 0.640383	val: 0.354165	test: 0.221373

Epoch: 48
Loss: 0.09350590636393097
ROC train: 0.937567	val: 0.810975	test: 0.765838
PRC train: 0.617599	val: 0.375108	test: 0.200820

Epoch: 49
Loss: 0.09406041966981667
ROC train: 0.942357	val: 0.812359	test: 0.757732
PRC train: 0.637120	val: 0.364672	test: 0.191601

Epoch: 50
Loss: 0.09209975893995453
ROC train: 0.937054	val: 0.793231	test: 0.779654
PRC train: 0.629087	val: 0.351300	test: 0.219031

Epoch: 51
Loss: 0.09292027796886662
ROC train: 0.945439	val: 0.826912	test: 0.751753
PRC train: 0.643834	val: 0.364353	test: 0.156289

Epoch: 52
Loss: 0.0929076882961427
ROC train: 0.936383	val: 0.825783	test: 0.750190
PRC train: 0.620478	val: 0.291819	test: 0.152614

Epoch: 53
Loss: 0.09240198466611317
ROC train: 0.941619	val: 0.812580	test: 0.757006
PRC train: 0.632540	val: 0.370713	test: 0.219958

Epoch: 54
Loss: 0.09301816296919055
ROC train: 0.948576	val: 0.813412	test: 0.753545
PRC train: 0.647385	val: 0.403858	test: 0.208334

Epoch: 55
Loss: 0.0904815176658989
ROC train: 0.945283	val: 0.823768	test: 0.732560
PRC train: 0.655442	val: 0.345070	test: 0.154305

Epoch: 56
Loss: 0.08978230655247744
ROC train: 0.939773	val: 0.820899	test: 0.746635
PRC train: 0.644247	val: 0.368661	test: 0.183278

Epoch: 57
Loss: 0.09009153891900794
ROC train: 0.950753	val: 0.817231	test: 0.745625
PRC train: 0.671134	val: 0.380403	test: 0.170516

Epoch: 58
Loss: 0.08875195321985821
ROC train: 0.938281	val: 0.814625	test: 0.758584
PRC train: 0.616140	val: 0.345067	test: 0.221843

Epoch: 59
Loss: 0.08984046775218182
ROC train: 0.952528	val: 0.820048	test: 0.738147
PRC train: 0.660089	val: 0.362527	test: 0.190975

Epoch: 60
Loss: 0.08933244788534216
ROC train: 0.951052	val: 0.816921	test: 0.754125
PRC train: 0.657040	val: 0.380725	test: 0.197171

Epoch: 61
Loss: 0.08786837051033708
ROC train: 0.952973	val: 0.819059	test: 0.746700
PRC train: 0.674368	val: 0.355764	test: 0.164270

Epoch: 62
Loss: 0.08782766757663692
ROC train: 0.953564	val: 0.818428	test: 0.759223
PRC train: 0.682393	val: 0.349884	test: 0.168348

Epoch: 63
Loss: 0.0858220504180115
ROC train: 0.956077	val: 0.817280	test: 0.744626
PRC train: 0.681732	val: 0.347969	test: 0.166336

Epoch: 64
Loss: 0.08731715710084839
ROC train: 0.955421	val: 0.818259	test: 0.754568
PRC train: 0.680907	val: 0.351065	test: 0.165868

Epoch: 65
Loss: 0.08677678777772256
ROC train: 0.959118	val: 0.791927	test: 0.740822
PRC train: 0.692859	val: 0.343935	test: 0.182968

Epoch: 66
Loss: 0.0868820593750181
ROC train: 0.959301	val: 0.808189	test: 0.779395
PRC train: 0.695351	val: 0.350919	test: 0.192434

Epoch: 67
Loss: 0.08538320989747895
ROC train: 0.960490	val: 0.832188	test: 0.783474
PRC train: 0.696142	val: 0.386132	test: 0.211327

Epoch: 68
Loss: 0.08712098139007107
ROC train: 0.957440	val: 0.812224	test: 0.765774
PRC train: 0.676817	val: 0.349478	test: 0.186477

Epoch: 69
Loss: 0.08554525198280645
ROC train: 0.961642	val: 0.802252	test: 0.741046
PRC train: 0.683653	val: 0.318855	test: 0.146404

Epoch: 70
Loss: 0.08346217945629218
ROC train: 0.962879	val: 0.818609	test: 0.749404
PRC train: 0.707101	val: 0.319805	test: 0.143932

Epoch: 71
Loss: 0.08370614739297809
ROC train: 0.963413	val: 0.814873	test: 0.746598
PRC train: 0.704675	val: 0.332203	test: 0.199126

Epoch: 72
Loss: 0.0837693355522935
ROC train: 0.963693	val: 0.820755	test: 0.761075
PRC train: 0.709776	val: 0.356213	test: 0.169179

Epoch: 73
Loss: 0.08317463211329425
ROC train: 0.963069	val: 0.819417	test: 0.751305
PRC train: 0.696636	val: 0.368385	test: 0.215236

Epoch: 74
Loss: 0.08219784978137812
ROC train: 0.966371	val: 0.815939	test: 0.753288
PRC train: 0.721583	val: 0.346617	test: 0.171436

Epoch: 75
Loss: 0.08323967617870626
ROC train: 0.961146	val: 0.787643	test: 0.742757
PRC train: 0.700151	val: 0.326802	test: 0.144915

Epoch: 76
Loss: 0.08383155473837922
ROC train: 0.963841	val: 0.794052	test: 0.768379
PRC train: 0.710904	val: 0.357201	test: 0.221148

Epoch: 77
Loss: 0.08184145762891289
ROC train: 0.970641	val: 0.804389	test: 0.741764
PRC train: 0.732360	val: 0.344995	test: 0.164592

Epoch: 78
Loss: 0.08333221372090163
ROC train: 0.963425	val: 0.785157	test: 0.762160
PRC train: 0.714167	val: 0.344477	test: 0.213061

Epoch: 79
Loss: 0.08053716612539091
ROC train: 0.968689	val: 0.820954	test: 0.773480
PRC train: 0.727017	val: 0.378828	test: 0.201925

Epoch: 80
Loss: 0.08045856931805219
ROC train: 0.969518	val: 0.802478	test: 0.755870
PRC train: 0.735261	val: 0.338063	test: 0.159694

Epoch: 81
Loss: 0.08215250752546364
ROC train: 0.958048	val: 0.795372	test: 0.747666
PRC train: 0.684954	val: 0.324619	test: 0.159804

Epoch: 82
Loss: 0.07953218236238711
ROC train: 0.973975	val: 0.805647	test: 0.760246
PRC train: 0.748168	val: 0.358523	test: 0.183620

Epoch: 83
Loss: 0.07978391273211881
ROC train: 0.971351	val: 0.807233	test: 0.755938
PRC train: 0.736517	val: 0.336901	test: 0.188485

Epoch: 84
Loss: 0.07796828184530494
ROC train: 0.974391	val: 0.793112	test: 0.758134
PRC train: 0.749767	val: 0.324532	test: 0.171997

Epoch: 85
Loss: 0.07949204199358048
ROC train: 0.969802	val: 0.798930	test: 0.738682
PRC train: 0.743956	val: 0.320038	test: 0.188311

Epoch: 86
Loss: 0.07886383043325253
ROC train: 0.968910	val: 0.797481	test: 0.764733
PRC train: 0.728663	val: 0.363012	test: 0.227522

Epoch: 87
Loss: 0.0785445489663547
ROC train: 0.977193	val: 0.814555	test: 0.742950
PRC train: 0.773478	val: 0.349976	test: 0.187988

Epoch: 88
Loss: 0.07812009531060263
ROC train: 0.974585	val: 0.799527	test: 0.767290
PRC train: 0.755991	val: 0.363380	test: 0.187100

Epoch: 89
Loss: 0.0768464870603839
ROC train: 0.973363	val: 0.821407	test: 0.762728
PRC train: 0.751842	val: 0.369874	test: 0.179716

Epoch: 90
Loss: 0.07742677472590494
ROC train: 0.974629	val: 0.805978	test: 0.760123
PRC train: 0.758782	val: 0.365264	test: 0.189957

Epoch: 91
Loss: 0.07832338938360654
ROC train: 0.973504	val: 0.818416	test: 0.767782
PRC train: 0.747257	val: 0.334077	test: 0.184116

Epoch: 92
Loss: 0.0765943861417152
ROC train: 0.977504	val: 0.803596	test: 0.754765
PRC train: 0.776077	val: 0.332662	test: 0.166366

Epoch: 93
Loss: 0.07548029411000151
ROC train: 0.977685	val: 0.821530	test: 0.762616
PRC train: 0.768477	val: 0.375325	test: 0.180961

Epoch: 94
Loss: 0.07622275165365004
PRC train: 0.623571	val: 0.377816	test: 0.193533

Epoch: 33
Loss: 0.09905779530684243
ROC train: 0.933482	val: 0.774529	test: 0.760509
PRC train: 0.654231	val: 0.351416	test: 0.162687

Epoch: 34
Loss: 0.09848221201642204
ROC train: 0.932585	val: 0.809444	test: 0.764219
PRC train: 0.636319	val: 0.380427	test: 0.194758

Epoch: 35
Loss: 0.09644079812290651
ROC train: 0.934648	val: 0.808967	test: 0.779729
PRC train: 0.636738	val: 0.381109	test: 0.159558

Epoch: 36
Loss: 0.09710168596713642
ROC train: 0.936723	val: 0.812567	test: 0.770270
PRC train: 0.651217	val: 0.369311	test: 0.210423

Epoch: 37
Loss: 0.0941977994052779
ROC train: 0.943508	val: 0.800258	test: 0.763300
PRC train: 0.674244	val: 0.364321	test: 0.200958

Epoch: 38
Loss: 0.09372859514481584
ROC train: 0.948672	val: 0.813158	test: 0.785172
PRC train: 0.673990	val: 0.394179	test: 0.253217

Epoch: 39
Loss: 0.0925309630349354
ROC train: 0.948584	val: 0.772854	test: 0.759899
PRC train: 0.675981	val: 0.334810	test: 0.173339

Epoch: 40
Loss: 0.09475616568730774
ROC train: 0.938152	val: 0.812276	test: 0.773723
PRC train: 0.648543	val: 0.376194	test: 0.241107

Epoch: 41
Loss: 0.0915341070193199
ROC train: 0.950748	val: 0.800078	test: 0.761206
PRC train: 0.692785	val: 0.307782	test: 0.180096

Epoch: 42
Loss: 0.0894265880417831
ROC train: 0.954913	val: 0.798103	test: 0.779063
PRC train: 0.713981	val: 0.377979	test: 0.213164

Epoch: 43
Loss: 0.08868776471234782
ROC train: 0.954992	val: 0.792683	test: 0.773858
PRC train: 0.719844	val: 0.344907	test: 0.181325

Epoch: 44
Loss: 0.09133164640842704
ROC train: 0.956606	val: 0.783222	test: 0.755862
PRC train: 0.725100	val: 0.307234	test: 0.199721

Epoch: 45
Loss: 0.08648998651934209
ROC train: 0.955378	val: 0.806192	test: 0.769213
PRC train: 0.714786	val: 0.329898	test: 0.166084

Epoch: 46
Loss: 0.086526385719339
ROC train: 0.950726	val: 0.796676	test: 0.774472
PRC train: 0.657081	val: 0.228789	test: 0.141869

Epoch: 47
Loss: 0.08629241102478477
ROC train: 0.965090	val: 0.807457	test: 0.773368
PRC train: 0.752034	val: 0.395802	test: 0.210786

Epoch: 48
Loss: 0.08501529706561613
ROC train: 0.959692	val: 0.779722	test: 0.772850
PRC train: 0.738976	val: 0.345136	test: 0.216307

Epoch: 49
Loss: 0.08565079029537605
ROC train: 0.966914	val: 0.806961	test: 0.769213
PRC train: 0.758373	val: 0.335780	test: 0.176128

Epoch: 50
Loss: 0.0831568384938925
ROC train: 0.967547	val: 0.801563	test: 0.766622
PRC train: 0.772195	val: 0.339058	test: 0.172763

Epoch: 51
Loss: 0.08383522713044758
ROC train: 0.969801	val: 0.800479	test: 0.775446
PRC train: 0.786876	val: 0.306943	test: 0.160257

Epoch: 52
Loss: 0.08226237106031765
ROC train: 0.968567	val: 0.798914	test: 0.764634
PRC train: 0.780935	val: 0.318377	test: 0.174583

Epoch: 53
Loss: 0.07943727589659268
ROC train: 0.971994	val: 0.788302	test: 0.767189
PRC train: 0.788670	val: 0.298317	test: 0.165165

Epoch: 54
Loss: 0.07968973912202672
ROC train: 0.973909	val: 0.796256	test: 0.753738
PRC train: 0.800625	val: 0.357196	test: 0.160083

Epoch: 55
Loss: 0.07853195038226451
ROC train: 0.976483	val: 0.778124	test: 0.769858
PRC train: 0.809370	val: 0.351565	test: 0.199379

Epoch: 56
Loss: 0.07776404012975117
ROC train: 0.977185	val: 0.784906	test: 0.765951
PRC train: 0.813562	val: 0.320027	test: 0.176138

Epoch: 57
Loss: 0.07699622417380758
ROC train: 0.976703	val: 0.789269	test: 0.788082
PRC train: 0.807024	val: 0.324832	test: 0.226302

Epoch: 58
Loss: 0.0757606327409117
ROC train: 0.978447	val: 0.790417	test: 0.769822
PRC train: 0.818699	val: 0.301228	test: 0.169014

Epoch: 59
Loss: 0.07675186833745803
ROC train: 0.975670	val: 0.798455	test: 0.778391
PRC train: 0.818457	val: 0.374495	test: 0.188607

Epoch: 60
Loss: 0.07449195707419061
ROC train: 0.977116	val: 0.780334	test: 0.769532
PRC train: 0.814115	val: 0.365471	test: 0.211711

Epoch: 61
Loss: 0.07492709582732766
ROC train: 0.979331	val: 0.789312	test: 0.769293
PRC train: 0.830488	val: 0.361915	test: 0.235428

Epoch: 62
Loss: 0.07420843473402307
ROC train: 0.981586	val: 0.794781	test: 0.764646
PRC train: 0.838851	val: 0.332843	test: 0.139133

Epoch: 63
Loss: 0.06994638421939592
ROC train: 0.980937	val: 0.783562	test: 0.758626
PRC train: 0.833134	val: 0.304322	test: 0.161657

Epoch: 64
Loss: 0.07094100566860151
ROC train: 0.980822	val: 0.796756	test: 0.749843
PRC train: 0.839882	val: 0.343722	test: 0.187156

Epoch: 65
Loss: 0.07147045303797216
ROC train: 0.984754	val: 0.785494	test: 0.755486
PRC train: 0.873266	val: 0.318849	test: 0.173181

Epoch: 66
Loss: 0.06699570712551273
ROC train: 0.985644	val: 0.793975	test: 0.766204
PRC train: 0.868820	val: 0.368019	test: 0.202551

Epoch: 67
Loss: 0.06882447437225919
ROC train: 0.983057	val: 0.798786	test: 0.761890
PRC train: 0.857055	val: 0.333365	test: 0.170901

Epoch: 68
Loss: 0.0691982735822009
ROC train: 0.986242	val: 0.799370	test: 0.775438
PRC train: 0.873486	val: 0.392651	test: 0.214892

Epoch: 69
Loss: 0.06803347897585281
ROC train: 0.987364	val: 0.788188	test: 0.751119
PRC train: 0.879407	val: 0.345690	test: 0.145605

Epoch: 70
Loss: 0.06723622106099486
ROC train: 0.980788	val: 0.771825	test: 0.745544
PRC train: 0.824068	val: 0.260491	test: 0.113818

Epoch: 71
Loss: 0.06442376542774778
ROC train: 0.984947	val: 0.773843	test: 0.764650
PRC train: 0.864436	val: 0.301213	test: 0.159801

Epoch: 72
Loss: 0.06274516177194978
ROC train: 0.991978	val: 0.808262	test: 0.773783
PRC train: 0.910210	val: 0.374831	test: 0.192846

Epoch: 73
Loss: 0.06349277999250132
ROC train: 0.986647	val: 0.768546	test: 0.775141
PRC train: 0.873230	val: 0.335112	test: 0.206426

Epoch: 74
Loss: 0.06251266483082671
ROC train: 0.986710	val: 0.791563	test: 0.762400
PRC train: 0.869772	val: 0.313712	test: 0.167887

Epoch: 75
Loss: 0.06280931295215528
ROC train: 0.991154	val: 0.800767	test: 0.760739
PRC train: 0.898808	val: 0.355859	test: 0.174464

Epoch: 76
Loss: 0.06377787324607001
ROC train: 0.991225	val: 0.796927	test: 0.767228
PRC train: 0.909304	val: 0.348562	test: 0.148613

Epoch: 77
Loss: 0.06102285902468659
ROC train: 0.991860	val: 0.786069	test: 0.772193
PRC train: 0.913899	val: 0.349103	test: 0.170722

Epoch: 78
Loss: 0.06039753583883512
ROC train: 0.990728	val: 0.789202	test: 0.775925
PRC train: 0.900028	val: 0.373686	test: 0.179010

Epoch: 79
Loss: 0.061009631042828825
ROC train: 0.991140	val: 0.799833	test: 0.762805
PRC train: 0.905510	val: 0.338816	test: 0.151423

Epoch: 80
Loss: 0.057751243434515515
ROC train: 0.992615	val: 0.783488	test: 0.774679
PRC train: 0.922552	val: 0.314525	test: 0.175017

Epoch: 81
Loss: 0.059465713937835896
ROC train: 0.992639	val: 0.810801	test: 0.781881
PRC train: 0.922903	val: 0.341996	test: 0.177048

Epoch: 82
Loss: 0.05740440649591248
ROC train: 0.993156	val: 0.770699	test: 0.775106
PRC train: 0.927120	val: 0.355979	test: 0.190783

Epoch: 83
Loss: 0.05513352025482031
ROC train: 0.990592	val: 0.779477	test: 0.762964
PRC train: 0.893261	val: 0.304180	test: 0.179773

Epoch: 84
Loss: 0.05618225090059667
ROC train: 0.993679	val: 0.816496	test: 0.777203
PRC train: 0.927832	val: 0.346601	test: 0.192493

Epoch: 85
Loss: 0.0558137849129607
ROC train: 0.993003	val: 0.772775	test: 0.776180
PRC train: 0.919423	val: 0.341230	test: 0.217316

Epoch: 86
Loss: 0.05675195971573051
ROC train: 0.995098	val: 0.796866	test: 0.764615
PRC train: 0.940884	val: 0.338479	test: 0.198803

Epoch: 87
Loss: 0.05409436061390442
ROC train: 0.994442	val: 0.783409	test: 0.774306
PRC train: 0.932069	val: 0.303640	test: 0.193612

Epoch: 88
Loss: 0.054442841979319936
ROC train: 0.994127	val: 0.794471	test: 0.776330
PRC train: 0.930265	val: 0.334568	test: 0.203897

Epoch: 89
Loss: 0.051454756736393326
ROC train: 0.996185	val: 0.794539	test: 0.772375
PRC train: 0.950592	val: 0.329645	test: 0.154380

Epoch: 90
Loss: 0.052481735856274234
ROC train: 0.995883	val: 0.771430	test: 0.763481
PRC train: 0.945290	val: 0.291854	test: 0.168793

Epoch: 91
Loss: 0.05361881178964981
ROC train: 0.995761	val: 0.789646	test: 0.779076
PRC train: 0.945227	val: 0.390075	test: 0.187890

Epoch: 92
Loss: 0.04954281953973888
ROC train: 0.996919	val: 0.782175	test: 0.767549
PRC train: 0.959765	val: 0.313800	test: 0.165809

Epoch: 93
Loss: 0.05141345159988726
ROC train: 0.996912	val: 0.791645	test: 0.767636
PRC train: 0.643056	val: 0.316512	test: 0.166658

Epoch: 33
Loss: 0.0973841441942461
ROC train: 0.939777	val: 0.793247	test: 0.705151
PRC train: 0.657161	val: 0.326514	test: 0.156710

Epoch: 34
Loss: 0.09640998069736756
ROC train: 0.946076	val: 0.790809	test: 0.725746
PRC train: 0.662224	val: 0.316614	test: 0.149445

Epoch: 35
Loss: 0.09522323763826052
ROC train: 0.944495	val: 0.784545	test: 0.733911
PRC train: 0.676083	val: 0.352433	test: 0.221175

Epoch: 36
Loss: 0.09445896893926928
ROC train: 0.948293	val: 0.764575	test: 0.732577
PRC train: 0.682536	val: 0.297903	test: 0.185848

Epoch: 37
Loss: 0.09322356244356629
ROC train: 0.947385	val: 0.783323	test: 0.727434
PRC train: 0.692417	val: 0.346431	test: 0.196233

Epoch: 38
Loss: 0.09385067900380681
ROC train: 0.951351	val: 0.780736	test: 0.715292
PRC train: 0.699612	val: 0.348927	test: 0.168698

Epoch: 39
Loss: 0.09141464007531436
ROC train: 0.953601	val: 0.810412	test: 0.739493
PRC train: 0.701539	val: 0.331501	test: 0.196601

Epoch: 40
Loss: 0.09087117144179227
ROC train: 0.953993	val: 0.759008	test: 0.727274
PRC train: 0.704672	val: 0.337449	test: 0.179469

Epoch: 41
Loss: 0.09133767631344832
ROC train: 0.949256	val: 0.797524	test: 0.736845
PRC train: 0.676232	val: 0.322026	test: 0.188832

Epoch: 42
Loss: 0.09035299659680808
ROC train: 0.955516	val: 0.769717	test: 0.702497
PRC train: 0.715390	val: 0.322418	test: 0.108346

Epoch: 43
Loss: 0.08694541237141266
ROC train: 0.955973	val: 0.799416	test: 0.717689
PRC train: 0.714662	val: 0.320897	test: 0.112376

Epoch: 44
Loss: 0.08713207969330565
ROC train: 0.957297	val: 0.779532	test: 0.729471
PRC train: 0.725379	val: 0.315397	test: 0.162770

Epoch: 45
Loss: 0.08795351825996302
ROC train: 0.962301	val: 0.803106	test: 0.722368
PRC train: 0.743932	val: 0.369073	test: 0.180535

Epoch: 46
Loss: 0.0844744218496573
ROC train: 0.955373	val: 0.777187	test: 0.701929
PRC train: 0.677738	val: 0.266388	test: 0.116606

Epoch: 47
Loss: 0.08366729610406567
ROC train: 0.968350	val: 0.787576	test: 0.717669
PRC train: 0.763967	val: 0.331397	test: 0.130382

Epoch: 48
Loss: 0.08352981866159945
ROC train: 0.971342	val: 0.789817	test: 0.726540
PRC train: 0.789286	val: 0.366464	test: 0.171881

Epoch: 49
Loss: 0.08124945780844586
ROC train: 0.969032	val: 0.791841	test: 0.742268
PRC train: 0.774305	val: 0.355921	test: 0.164052

Epoch: 50
Loss: 0.0817336245809364
ROC train: 0.966203	val: 0.791909	test: 0.712352
PRC train: 0.758731	val: 0.322035	test: 0.118379

Epoch: 51
Loss: 0.08137369374138996
ROC train: 0.972014	val: 0.784572	test: 0.757873
PRC train: 0.790267	val: 0.336162	test: 0.206941

Epoch: 52
Loss: 0.07995974868029619
ROC train: 0.970905	val: 0.805681	test: 0.705693
PRC train: 0.777537	val: 0.300122	test: 0.089543

Epoch: 53
Loss: 0.07998047999603289
ROC train: 0.973602	val: 0.768757	test: 0.753014
PRC train: 0.793475	val: 0.349177	test: 0.238415

Epoch: 54
Loss: 0.07842132217227084
ROC train: 0.978317	val: 0.787068	test: 0.729587
PRC train: 0.817252	val: 0.359109	test: 0.215214

Epoch: 55
Loss: 0.07667218300537726
ROC train: 0.975414	val: 0.768157	test: 0.718971
PRC train: 0.813870	val: 0.354486	test: 0.181321

Epoch: 56
Loss: 0.07477169977358732
ROC train: 0.978309	val: 0.802298	test: 0.747048
PRC train: 0.824625	val: 0.325086	test: 0.175035

Epoch: 57
Loss: 0.07476568825571055
ROC train: 0.979127	val: 0.779716	test: 0.733929
PRC train: 0.815483	val: 0.357404	test: 0.177023

Epoch: 58
Loss: 0.0768182743793476
ROC train: 0.977018	val: 0.770806	test: 0.733740
PRC train: 0.810782	val: 0.295464	test: 0.140254

Epoch: 59
Loss: 0.0764822683842801
ROC train: 0.977824	val: 0.773271	test: 0.749279
PRC train: 0.817681	val: 0.326611	test: 0.187558

Epoch: 60
Loss: 0.07171142396804142
ROC train: 0.980576	val: 0.801198	test: 0.725284
PRC train: 0.830278	val: 0.331531	test: 0.140187

Epoch: 61
Loss: 0.07458929150813741
ROC train: 0.983401	val: 0.764593	test: 0.727245
PRC train: 0.853539	val: 0.330453	test: 0.182273

Epoch: 62
Loss: 0.07070997215969967
ROC train: 0.981328	val: 0.789398	test: 0.747174
PRC train: 0.834729	val: 0.314674	test: 0.159203

Epoch: 63
Loss: 0.07094119502131267
ROC train: 0.982153	val: 0.794067	test: 0.739983
PRC train: 0.848348	val: 0.296831	test: 0.129141

Epoch: 64
Loss: 0.06852024313586555
ROC train: 0.984701	val: 0.778454	test: 0.733629
PRC train: 0.868098	val: 0.368333	test: 0.133021

Epoch: 65
Loss: 0.06978573096239232
ROC train: 0.982128	val: 0.781755	test: 0.735439
PRC train: 0.834713	val: 0.366777	test: 0.163669

Epoch: 66
Loss: 0.06703487849711201
ROC train: 0.986757	val: 0.790969	test: 0.710265
PRC train: 0.862734	val: 0.336994	test: 0.123497

Epoch: 67
Loss: 0.06709805847603569
ROC train: 0.986648	val: 0.771091	test: 0.722177
PRC train: 0.870957	val: 0.347500	test: 0.120105

Epoch: 68
Loss: 0.06771922365165513
ROC train: 0.989367	val: 0.793978	test: 0.725226
PRC train: 0.892101	val: 0.368850	test: 0.158168

Epoch: 69
Loss: 0.06327599435514078
ROC train: 0.988553	val: 0.769860	test: 0.730352
PRC train: 0.884374	val: 0.341526	test: 0.189286

Epoch: 70
Loss: 0.06510107251683747
ROC train: 0.987210	val: 0.779894	test: 0.733697
PRC train: 0.874564	val: 0.378321	test: 0.162682

Epoch: 71
Loss: 0.0645453641548827
ROC train: 0.989695	val: 0.779551	test: 0.724929
PRC train: 0.890867	val: 0.332094	test: 0.133285

Epoch: 72
Loss: 0.06268939541641205
ROC train: 0.987265	val: 0.792117	test: 0.727610
PRC train: 0.874157	val: 0.351495	test: 0.160275

Epoch: 73
Loss: 0.06202647282842624
ROC train: 0.988644	val: 0.784912	test: 0.726192
PRC train: 0.882742	val: 0.369118	test: 0.154977

Epoch: 74
Loss: 0.060366528518020934
ROC train: 0.990173	val: 0.773056	test: 0.715649
PRC train: 0.903144	val: 0.295328	test: 0.108039

Epoch: 75
Loss: 0.06171318831685363
ROC train: 0.991119	val: 0.776045	test: 0.732430
PRC train: 0.902709	val: 0.364026	test: 0.165222

Epoch: 76
Loss: 0.06227948663030553
ROC train: 0.990472	val: 0.768987	test: 0.719780
PRC train: 0.903021	val: 0.320434	test: 0.118172

Epoch: 77
Loss: 0.05923517445639336
ROC train: 0.989876	val: 0.741966	test: 0.728436
PRC train: 0.887644	val: 0.284864	test: 0.140764

Epoch: 78
Loss: 0.05759018041805637
ROC train: 0.991965	val: 0.776495	test: 0.749495
PRC train: 0.912240	val: 0.346907	test: 0.179030

Epoch: 79
Loss: 0.05896537741017887
ROC train: 0.993122	val: 0.786342	test: 0.742326
PRC train: 0.920338	val: 0.329873	test: 0.162053

Epoch: 80
Loss: 0.05587365625180684
ROC train: 0.994717	val: 0.753123	test: 0.714181
PRC train: 0.930323	val: 0.266789	test: 0.113496

Epoch: 81
Loss: 0.05629544296254398
ROC train: 0.991030	val: 0.792025	test: 0.735592
PRC train: 0.905169	val: 0.318300	test: 0.152306

Epoch: 82
Loss: 0.0567429260624133
ROC train: 0.994940	val: 0.771363	test: 0.725659
PRC train: 0.939092	val: 0.348078	test: 0.127307

Epoch: 83
Loss: 0.05509439922727327
ROC train: 0.995594	val: 0.758877	test: 0.732100
PRC train: 0.945070	val: 0.329762	test: 0.145408

Epoch: 84
Loss: 0.054553032867895895
ROC train: 0.993688	val: 0.763307	test: 0.742581
PRC train: 0.918580	val: 0.358627	test: 0.193720

Epoch: 85
Loss: 0.05477258592402667
ROC train: 0.990495	val: 0.766167	test: 0.719745
PRC train: 0.897107	val: 0.262596	test: 0.100007

Epoch: 86
Loss: 0.052725449509654784
ROC train: 0.994577	val: 0.775157	test: 0.728508
PRC train: 0.933904	val: 0.292671	test: 0.130063

Epoch: 87
Loss: 0.05349010027107658
ROC train: 0.996350	val: 0.769590	test: 0.712876
PRC train: 0.952565	val: 0.337141	test: 0.123489

Epoch: 88
Loss: 0.05079358542624923
ROC train: 0.995966	val: 0.754749	test: 0.734636
PRC train: 0.947659	val: 0.301936	test: 0.132888

Epoch: 89
Loss: 0.05432911142570223
ROC train: 0.995447	val: 0.774753	test: 0.709205
PRC train: 0.941921	val: 0.274949	test: 0.132439

Epoch: 90
Loss: 0.050780182774309984
ROC train: 0.996177	val: 0.762670	test: 0.724746
PRC train: 0.944897	val: 0.303556	test: 0.131838

Epoch: 91
Loss: 0.05193983933897409
ROC train: 0.996732	val: 0.764183	test: 0.739748
PRC train: 0.955592	val: 0.338383	test: 0.169711

Epoch: 92
Loss: 0.05179106952618088
ROC train: 0.996605	val: 0.757591	test: 0.751320
PRC train: 0.951461	val: 0.364978	test: 0.184060

Epoch: 93
Loss: 0.0504934440350145
ROC train: 0.996306	val: 0.766127	test: 0.718255
PRC train: 0.614108	val: 0.391560	test: 0.225505

Epoch: 33
Loss: 0.098842876037236
ROC train: 0.926238	val: 0.788703	test: 0.746926
PRC train: 0.612738	val: 0.373699	test: 0.146318

Epoch: 34
Loss: 0.09849929093314852
ROC train: 0.931466	val: 0.796994	test: 0.758767
PRC train: 0.624063	val: 0.365174	test: 0.151241

Epoch: 35
Loss: 0.09634158198329508
ROC train: 0.930023	val: 0.787579	test: 0.772466
PRC train: 0.634345	val: 0.369447	test: 0.180261

Epoch: 36
Loss: 0.09583329894819602
ROC train: 0.933769	val: 0.782913	test: 0.760629
PRC train: 0.652527	val: 0.363920	test: 0.220408

Epoch: 37
Loss: 0.09523649040823465
ROC train: 0.938214	val: 0.797074	test: 0.753244
PRC train: 0.665609	val: 0.368206	test: 0.199497

Epoch: 38
Loss: 0.09519539398048035
ROC train: 0.940849	val: 0.778837	test: 0.765221
PRC train: 0.672696	val: 0.355054	test: 0.237466

Epoch: 39
Loss: 0.0953794812652407
ROC train: 0.945160	val: 0.780004	test: 0.751513
PRC train: 0.678286	val: 0.335959	test: 0.206023

Epoch: 40
Loss: 0.09336483098064355
ROC train: 0.945528	val: 0.775350	test: 0.744203
PRC train: 0.665059	val: 0.387586	test: 0.237343

Epoch: 41
Loss: 0.0941555420320231
ROC train: 0.947123	val: 0.792371	test: 0.756538
PRC train: 0.677580	val: 0.384553	test: 0.199796

Epoch: 42
Loss: 0.09189861883701947
ROC train: 0.946803	val: 0.809383	test: 0.766197
PRC train: 0.673168	val: 0.367417	test: 0.205682

Epoch: 43
Loss: 0.09112480979649791
ROC train: 0.944679	val: 0.789349	test: 0.758618
PRC train: 0.685831	val: 0.380178	test: 0.253312

Epoch: 44
Loss: 0.09268348949681204
ROC train: 0.946675	val: 0.771718	test: 0.750905
PRC train: 0.678343	val: 0.330039	test: 0.239794

Epoch: 45
Loss: 0.0893822746743254
ROC train: 0.950577	val: 0.792646	test: 0.759854
PRC train: 0.692691	val: 0.351777	test: 0.157526

Epoch: 46
Loss: 0.0883328485320431
ROC train: 0.950877	val: 0.785362	test: 0.759370
PRC train: 0.708526	val: 0.333524	test: 0.201704

Epoch: 47
Loss: 0.08840381327066657
ROC train: 0.951109	val: 0.798283	test: 0.776589
PRC train: 0.692588	val: 0.391151	test: 0.231515

Epoch: 48
Loss: 0.08785627045789568
ROC train: 0.956499	val: 0.789649	test: 0.756401
PRC train: 0.721603	val: 0.403257	test: 0.257520

Epoch: 49
Loss: 0.08741420526268451
ROC train: 0.956682	val: 0.793002	test: 0.766028
PRC train: 0.718769	val: 0.281213	test: 0.183688

Epoch: 50
Loss: 0.08538539187713438
ROC train: 0.960368	val: 0.785491	test: 0.754447
PRC train: 0.743933	val: 0.361933	test: 0.192179

Epoch: 51
Loss: 0.08762029929429681
ROC train: 0.958363	val: 0.781072	test: 0.750723
PRC train: 0.719304	val: 0.342846	test: 0.213098

Epoch: 52
Loss: 0.08509022816539177
ROC train: 0.964135	val: 0.797307	test: 0.781939
PRC train: 0.754875	val: 0.384311	test: 0.204546

Epoch: 53
Loss: 0.08472636719930904
ROC train: 0.964019	val: 0.757251	test: 0.745658
PRC train: 0.748830	val: 0.330606	test: 0.164581

Epoch: 54
Loss: 0.08328296330204389
ROC train: 0.961302	val: 0.769587	test: 0.751952
PRC train: 0.737497	val: 0.373488	test: 0.230276

Epoch: 55
Loss: 0.08255707999364871
ROC train: 0.966651	val: 0.771369	test: 0.748311
PRC train: 0.758389	val: 0.334655	test: 0.188849

Epoch: 56
Loss: 0.08285650740106588
ROC train: 0.963595	val: 0.785016	test: 0.768665
PRC train: 0.749111	val: 0.356007	test: 0.235037

Epoch: 57
Loss: 0.07907598120019184
ROC train: 0.967382	val: 0.770102	test: 0.758327
PRC train: 0.761851	val: 0.346292	test: 0.239454

Epoch: 58
Loss: 0.08167406615713743
ROC train: 0.970931	val: 0.793017	test: 0.768912
PRC train: 0.776605	val: 0.347143	test: 0.193278

Epoch: 59
Loss: 0.08049708690338808
ROC train: 0.968576	val: 0.796606	test: 0.757324
PRC train: 0.766230	val: 0.349250	test: 0.235442

Epoch: 60
Loss: 0.08032290188137901
ROC train: 0.964215	val: 0.770668	test: 0.761745
PRC train: 0.752916	val: 0.383340	test: 0.215275

Epoch: 61
Loss: 0.07761937518746681
ROC train: 0.971218	val: 0.761562	test: 0.758698
PRC train: 0.780210	val: 0.367767	test: 0.200649

Epoch: 62
Loss: 0.07563115860566524
ROC train: 0.970098	val: 0.786158	test: 0.740625
PRC train: 0.766621	val: 0.374724	test: 0.182439

Epoch: 63
Loss: 0.07803706084776509
ROC train: 0.977976	val: 0.771734	test: 0.736563
PRC train: 0.820553	val: 0.301407	test: 0.133664

Epoch: 64
Loss: 0.07494478456856504
ROC train: 0.974736	val: 0.772732	test: 0.758885
PRC train: 0.798421	val: 0.337829	test: 0.224866

Epoch: 65
Loss: 0.07492435249596166
ROC train: 0.970222	val: 0.765772	test: 0.748379
PRC train: 0.788255	val: 0.338325	test: 0.218359

Epoch: 66
Loss: 0.07398582553980079
ROC train: 0.976714	val: 0.776896	test: 0.741310
PRC train: 0.814628	val: 0.329240	test: 0.204745

Epoch: 67
Loss: 0.07485777055022816
ROC train: 0.978256	val: 0.769808	test: 0.766440
PRC train: 0.818621	val: 0.352343	test: 0.228737

Epoch: 68
Loss: 0.07226254852839135
ROC train: 0.980197	val: 0.787071	test: 0.752077
PRC train: 0.828240	val: 0.361107	test: 0.168269

Epoch: 69
Loss: 0.07225859652268855
ROC train: 0.981607	val: 0.767998	test: 0.742911
PRC train: 0.834677	val: 0.358550	test: 0.202340

Epoch: 70
Loss: 0.07257335379573847
ROC train: 0.977691	val: 0.779869	test: 0.752270
PRC train: 0.801807	val: 0.353079	test: 0.216951

Epoch: 71
Loss: 0.07024817703483027
ROC train: 0.977236	val: 0.768653	test: 0.732171
PRC train: 0.812162	val: 0.294998	test: 0.185660

Epoch: 72
Loss: 0.0705733416992987
ROC train: 0.980733	val: 0.762477	test: 0.747168
PRC train: 0.828917	val: 0.336369	test: 0.205700

Epoch: 73
Loss: 0.0684886513630329
ROC train: 0.982684	val: 0.757199	test: 0.761896
PRC train: 0.848189	val: 0.352074	test: 0.222895

Epoch: 74
Loss: 0.06978101399411622
ROC train: 0.983596	val: 0.780959	test: 0.738828
PRC train: 0.851456	val: 0.353697	test: 0.184207

Epoch: 75
Loss: 0.07102673045534787
ROC train: 0.982918	val: 0.775218	test: 0.751581
PRC train: 0.850633	val: 0.314679	test: 0.150487

Epoch: 76
Loss: 0.0675362808880233
ROC train: 0.985508	val: 0.779085	test: 0.752054
PRC train: 0.852367	val: 0.316810	test: 0.173300

Epoch: 77
Loss: 0.06874299362759001
ROC train: 0.985609	val: 0.782312	test: 0.758678
PRC train: 0.858478	val: 0.364900	test: 0.215540

Epoch: 78
Loss: 0.0662295440338722
ROC train: 0.982039	val: 0.770953	test: 0.758377
PRC train: 0.844822	val: 0.324737	test: 0.187081

Epoch: 79
Loss: 0.06497906301403776
ROC train: 0.986038	val: 0.788372	test: 0.755551
PRC train: 0.861895	val: 0.380871	test: 0.212545

Epoch: 80
Loss: 0.06480712606424373
ROC train: 0.986191	val: 0.787677	test: 0.752960
PRC train: 0.861744	val: 0.291636	test: 0.159659

Epoch: 81
Loss: 0.06639530548806875
ROC train: 0.987465	val: 0.797405	test: 0.762502
PRC train: 0.869829	val: 0.382225	test: 0.231758

Epoch: 82
Loss: 0.06398699248585599
ROC train: 0.989889	val: 0.792380	test: 0.763265
PRC train: 0.887328	val: 0.358432	test: 0.185722

Epoch: 83
Loss: 0.06424883655116546
ROC train: 0.988439	val: 0.782447	test: 0.759885
PRC train: 0.883525	val: 0.379631	test: 0.237584

Epoch: 84
Loss: 0.06431245406930415
ROC train: 0.989759	val: 0.777943	test: 0.767773
PRC train: 0.891983	val: 0.327328	test: 0.211909

Epoch: 85
Loss: 0.06320876543577292
ROC train: 0.989807	val: 0.770187	test: 0.753688
PRC train: 0.893397	val: 0.349341	test: 0.218547

Epoch: 86
Loss: 0.061523654978158905
ROC train: 0.991103	val: 0.789526	test: 0.762653
PRC train: 0.904489	val: 0.365888	test: 0.209212

Epoch: 87
Loss: 0.061517557978939444
ROC train: 0.990480	val: 0.778145	test: 0.769853
PRC train: 0.898786	val: 0.362295	test: 0.206379

Epoch: 88
Loss: 0.06213832152538933
ROC train: 0.989636	val: 0.770215	test: 0.760756
PRC train: 0.887603	val: 0.339021	test: 0.227351

Epoch: 89
Loss: 0.06032754467789233
ROC train: 0.991115	val: 0.777680	test: 0.755557
PRC train: 0.899461	val: 0.369109	test: 0.186591

Epoch: 90
Loss: 0.059117870208926164
ROC train: 0.992030	val: 0.772964	test: 0.723805
PRC train: 0.911214	val: 0.285476	test: 0.146258

Epoch: 91
Loss: 0.061687606145040826
ROC train: 0.990252	val: 0.786063	test: 0.744659
PRC train: 0.898679	val: 0.356417	test: 0.138724

Epoch: 92
Loss: 0.05846844783319862
ROC train: 0.991514	val: 0.767738	test: 0.763226
PRC train: 0.904736	val: 0.346279	test: 0.199189

Epoch: 93
Loss: 0.05905585669341538
ROC train: 0.991164	val: 0.780904	test: 0.733896
PRC train: 0.645344	val: 0.370688	test: 0.187495

Epoch: 33
Loss: 0.09796785881776932
ROC train: 0.932267	val: 0.822972	test: 0.742257
PRC train: 0.623521	val: 0.310439	test: 0.193394

Epoch: 34
Loss: 0.09860263812618773
ROC train: 0.931281	val: 0.820332	test: 0.753280
PRC train: 0.616918	val: 0.360699	test: 0.155882

Epoch: 35
Loss: 0.09781479872332854
ROC train: 0.935711	val: 0.795424	test: 0.746106
PRC train: 0.639037	val: 0.394968	test: 0.231825

Epoch: 36
Loss: 0.09610461559760097
ROC train: 0.936721	val: 0.813961	test: 0.743352
PRC train: 0.648068	val: 0.374344	test: 0.187290

Epoch: 37
Loss: 0.09400303541453982
ROC train: 0.943786	val: 0.800537	test: 0.747944
PRC train: 0.669633	val: 0.377899	test: 0.197560

Epoch: 38
Loss: 0.09614029465317574
ROC train: 0.950149	val: 0.819423	test: 0.748767
PRC train: 0.695197	val: 0.335212	test: 0.200385

Epoch: 39
Loss: 0.09175519778907977
ROC train: 0.949233	val: 0.812849	test: 0.718917
PRC train: 0.694186	val: 0.336076	test: 0.171917

Epoch: 40
Loss: 0.09212526140108719
ROC train: 0.948548	val: 0.830033	test: 0.755044
PRC train: 0.706071	val: 0.357848	test: 0.201673

Epoch: 41
Loss: 0.09222950958714213
ROC train: 0.948304	val: 0.816089	test: 0.723537
PRC train: 0.668929	val: 0.297554	test: 0.189699

Epoch: 42
Loss: 0.09027454545397141
ROC train: 0.944237	val: 0.817007	test: 0.760544
PRC train: 0.672234	val: 0.362519	test: 0.209030

Epoch: 43
Loss: 0.08907480620017671
ROC train: 0.953955	val: 0.817503	test: 0.754010
PRC train: 0.710997	val: 0.377723	test: 0.196292

Epoch: 44
Loss: 0.08766312843991683
ROC train: 0.956091	val: 0.812313	test: 0.719933
PRC train: 0.706425	val: 0.385691	test: 0.170255

Epoch: 45
Loss: 0.08843155789227437
ROC train: 0.952852	val: 0.814362	test: 0.759213
PRC train: 0.709800	val: 0.389794	test: 0.234662

Epoch: 46
Loss: 0.08655251441329306
ROC train: 0.961188	val: 0.818866	test: 0.739020
PRC train: 0.751876	val: 0.389207	test: 0.195015

Epoch: 47
Loss: 0.08527932049942337
ROC train: 0.963158	val: 0.800323	test: 0.718903
PRC train: 0.748673	val: 0.374572	test: 0.161895

Epoch: 48
Loss: 0.08392217949970017
ROC train: 0.969244	val: 0.826478	test: 0.729356
PRC train: 0.772979	val: 0.371406	test: 0.191331

Epoch: 49
Loss: 0.08447625459171142
ROC train: 0.954858	val: 0.815369	test: 0.751303
PRC train: 0.732532	val: 0.358637	test: 0.176107

Epoch: 50
Loss: 0.08158533373892045
ROC train: 0.970754	val: 0.833379	test: 0.741486
PRC train: 0.787249	val: 0.383454	test: 0.140403

Epoch: 51
Loss: 0.08241865407050693
ROC train: 0.967906	val: 0.816183	test: 0.740086
PRC train: 0.773790	val: 0.395995	test: 0.187666

Epoch: 52
Loss: 0.07945956731104031
ROC train: 0.968746	val: 0.814209	test: 0.736030
PRC train: 0.793337	val: 0.344852	test: 0.172396

Epoch: 53
Loss: 0.07897760632668438
ROC train: 0.975514	val: 0.806894	test: 0.716370
PRC train: 0.801777	val: 0.337340	test: 0.156773

Epoch: 54
Loss: 0.07807176106523371
ROC train: 0.971362	val: 0.809074	test: 0.748278
PRC train: 0.784471	val: 0.336547	test: 0.163728

Epoch: 55
Loss: 0.07772354796895993
ROC train: 0.975496	val: 0.792855	test: 0.746772
PRC train: 0.798813	val: 0.337164	test: 0.202212

Epoch: 56
Loss: 0.0760602339016722
ROC train: 0.972758	val: 0.830131	test: 0.762747
PRC train: 0.803262	val: 0.355440	test: 0.184372

Epoch: 57
Loss: 0.07879760903514017
ROC train: 0.977237	val: 0.830048	test: 0.758027
PRC train: 0.816889	val: 0.363587	test: 0.182535

Epoch: 58
Loss: 0.0762401794229081
ROC train: 0.982819	val: 0.822607	test: 0.729045
PRC train: 0.845572	val: 0.363293	test: 0.176319

Epoch: 59
Loss: 0.07576718598391972
ROC train: 0.980099	val: 0.804049	test: 0.737762
PRC train: 0.827963	val: 0.337957	test: 0.137432

Epoch: 60
Loss: 0.07500403680016249
ROC train: 0.979331	val: 0.817041	test: 0.728579
PRC train: 0.825989	val: 0.323292	test: 0.190753

Epoch: 61
Loss: 0.07456962155787782
ROC train: 0.977045	val: 0.834941	test: 0.761886
PRC train: 0.819600	val: 0.342445	test: 0.213388

Epoch: 62
Loss: 0.07164054284787351
ROC train: 0.983701	val: 0.821141	test: 0.746438
PRC train: 0.857673	val: 0.336318	test: 0.176524

Epoch: 63
Loss: 0.07211109095737583
ROC train: 0.982259	val: 0.801293	test: 0.727333
PRC train: 0.841044	val: 0.363278	test: 0.193343

Epoch: 64
Loss: 0.07310929691450065
ROC train: 0.984541	val: 0.831796	test: 0.750213
PRC train: 0.853888	val: 0.348350	test: 0.190989

Epoch: 65
Loss: 0.07027102727069641
ROC train: 0.986136	val: 0.809720	test: 0.737519
PRC train: 0.866211	val: 0.389239	test: 0.152209

Epoch: 66
Loss: 0.07112525144351738
ROC train: 0.982258	val: 0.799211	test: 0.750725
PRC train: 0.840465	val: 0.376734	test: 0.202234

Epoch: 67
Loss: 0.06844165219481699
ROC train: 0.986447	val: 0.800286	test: 0.740725
PRC train: 0.865030	val: 0.336015	test: 0.148744

Epoch: 68
Loss: 0.06732320252726481
ROC train: 0.988189	val: 0.801312	test: 0.722179
PRC train: 0.879234	val: 0.340945	test: 0.167225

Epoch: 69
Loss: 0.06787038948749764
ROC train: 0.985835	val: 0.804790	test: 0.733537
PRC train: 0.865498	val: 0.347664	test: 0.185953

Epoch: 70
Loss: 0.06655800478140819
ROC train: 0.980299	val: 0.795843	test: 0.763974
PRC train: 0.816116	val: 0.331749	test: 0.191745

Epoch: 71
Loss: 0.06489935933850549
ROC train: 0.987289	val: 0.782263	test: 0.755179
PRC train: 0.875455	val: 0.331218	test: 0.194145

Epoch: 72
Loss: 0.06406533561496995
ROC train: 0.988826	val: 0.817641	test: 0.742591
PRC train: 0.897802	val: 0.306857	test: 0.131528

Epoch: 73
Loss: 0.06569230494517425
ROC train: 0.986250	val: 0.812748	test: 0.748819
PRC train: 0.889896	val: 0.354877	test: 0.193107

Epoch: 74
Loss: 0.062025352548331004
ROC train: 0.984814	val: 0.791596	test: 0.747579
PRC train: 0.857528	val: 0.318024	test: 0.196068

Epoch: 75
Loss: 0.06233252717853067
ROC train: 0.992159	val: 0.810461	test: 0.761751
PRC train: 0.910535	val: 0.330734	test: 0.181862

Epoch: 76
Loss: 0.061005613745049925
ROC train: 0.989839	val: 0.807864	test: 0.749047
PRC train: 0.896188	val: 0.330664	test: 0.160041

Epoch: 77
Loss: 0.062243897002214534
ROC train: 0.991423	val: 0.792270	test: 0.740835
PRC train: 0.905360	val: 0.315201	test: 0.164495

Epoch: 78
Loss: 0.05882392415100063
ROC train: 0.990912	val: 0.797432	test: 0.758767
PRC train: 0.905420	val: 0.343072	test: 0.209438

Epoch: 79
Loss: 0.05985900727929272
ROC train: 0.993209	val: 0.810700	test: 0.745686
PRC train: 0.925038	val: 0.346366	test: 0.184223

Epoch: 80
Loss: 0.05858483890916124
ROC train: 0.993537	val: 0.805687	test: 0.736107
PRC train: 0.932846	val: 0.305129	test: 0.158497

Epoch: 81
Loss: 0.057227968087997495
ROC train: 0.993533	val: 0.795494	test: 0.750067
PRC train: 0.932484	val: 0.295385	test: 0.141997

Epoch: 82
Loss: 0.05588209657498299
ROC train: 0.995317	val: 0.797821	test: 0.726630
PRC train: 0.942964	val: 0.296439	test: 0.118371

Epoch: 83
Loss: 0.05528178763680987
ROC train: 0.992902	val: 0.790779	test: 0.738265
PRC train: 0.919394	val: 0.310088	test: 0.176967

Epoch: 84
Loss: 0.05515921814052987
ROC train: 0.994325	val: 0.792849	test: 0.739139
PRC train: 0.933285	val: 0.365719	test: 0.158088

Epoch: 85
Loss: 0.05660567093023565
ROC train: 0.993302	val: 0.784961	test: 0.718535
PRC train: 0.923042	val: 0.311697	test: 0.189044

Epoch: 86
Loss: 0.05428697498584865
ROC train: 0.994650	val: 0.794673	test: 0.740455
PRC train: 0.934157	val: 0.388490	test: 0.189117

Epoch: 87
Loss: 0.05400401459761304
ROC train: 0.991653	val: 0.784404	test: 0.760905
PRC train: 0.917879	val: 0.346678	test: 0.196506

Epoch: 88
Loss: 0.05423480180952637
ROC train: 0.994335	val: 0.796293	test: 0.736567
PRC train: 0.936169	val: 0.339063	test: 0.190564

Epoch: 89
Loss: 0.05187033389334983
ROC train: 0.996288	val: 0.794474	test: 0.721204
PRC train: 0.949579	val: 0.304388	test: 0.124037

Epoch: 90
Loss: 0.05341035733804068
ROC train: 0.995948	val: 0.799720	test: 0.733629
PRC train: 0.950400	val: 0.350658	test: 0.165992

Epoch: 91
Loss: 0.05288649445814541
ROC train: 0.995937	val: 0.778470	test: 0.739047
PRC train: 0.945874	val: 0.313210	test: 0.163788

Epoch: 92
Loss: 0.05331015260488027
ROC train: 0.995469	val: 0.785053	test: 0.745099
PRC train: 0.945362	val: 0.344485	test: 0.181812

Epoch: 93
Loss: 0.050487717752539914
ROC train: 0.996663	val: 0.798571	test: 0.737187
PRC train: 0.622113	val: 0.398844	test: 0.151883

Epoch: 33
Loss: 0.09907576490421417
ROC train: 0.935368	val: 0.796180	test: 0.736638
PRC train: 0.640404	val: 0.386070	test: 0.191232

Epoch: 34
Loss: 0.09787200108817938
ROC train: 0.936629	val: 0.780840	test: 0.745287
PRC train: 0.620510	val: 0.381811	test: 0.180009

Epoch: 35
Loss: 0.09704858928530591
ROC train: 0.934864	val: 0.800310	test: 0.739895
PRC train: 0.630587	val: 0.402485	test: 0.196064

Epoch: 36
Loss: 0.0950874477722181
ROC train: 0.938858	val: 0.794076	test: 0.735963
PRC train: 0.662752	val: 0.359115	test: 0.185040

Epoch: 37
Loss: 0.09384558906073688
ROC train: 0.938075	val: 0.780261	test: 0.711715
PRC train: 0.661532	val: 0.374928	test: 0.161925

Epoch: 38
Loss: 0.09384665775313734
ROC train: 0.944709	val: 0.795718	test: 0.751942
PRC train: 0.673013	val: 0.367810	test: 0.185386

Epoch: 39
Loss: 0.09146446278697322
ROC train: 0.949608	val: 0.803642	test: 0.734933
PRC train: 0.697878	val: 0.369041	test: 0.146306

Epoch: 40
Loss: 0.09291552669710765
ROC train: 0.946876	val: 0.807763	test: 0.744746
PRC train: 0.691400	val: 0.375571	test: 0.174507

Epoch: 41
Loss: 0.09219378919457281
ROC train: 0.946413	val: 0.788184	test: 0.728577
PRC train: 0.674492	val: 0.373688	test: 0.211331

Epoch: 42
Loss: 0.09169840005782048
ROC train: 0.950121	val: 0.789698	test: 0.742031
PRC train: 0.664903	val: 0.378789	test: 0.199624

Epoch: 43
Loss: 0.09114345821005834
ROC train: 0.950202	val: 0.813517	test: 0.747156
PRC train: 0.685925	val: 0.407451	test: 0.190186

Epoch: 44
Loss: 0.08671439330369032
ROC train: 0.958266	val: 0.812528	test: 0.743010
PRC train: 0.719819	val: 0.406390	test: 0.172015

Epoch: 45
Loss: 0.08872845832015576
ROC train: 0.953520	val: 0.790675	test: 0.761197
PRC train: 0.699354	val: 0.402218	test: 0.199852

Epoch: 46
Loss: 0.0868564865824681
ROC train: 0.957009	val: 0.803363	test: 0.741594
PRC train: 0.718387	val: 0.406634	test: 0.156403

Epoch: 47
Loss: 0.08721979801863941
ROC train: 0.961949	val: 0.810957	test: 0.746038
PRC train: 0.722860	val: 0.412346	test: 0.178901

Epoch: 48
Loss: 0.08509478991504289
ROC train: 0.965288	val: 0.802123	test: 0.742813
PRC train: 0.743906	val: 0.394682	test: 0.170456

Epoch: 49
Loss: 0.0834448228616543
ROC train: 0.954528	val: 0.783935	test: 0.745105
PRC train: 0.702606	val: 0.339879	test: 0.128388

Epoch: 50
Loss: 0.08494506804644787
ROC train: 0.960355	val: 0.799150	test: 0.730288
PRC train: 0.729699	val: 0.336290	test: 0.120811

Epoch: 51
Loss: 0.08465663527621559
ROC train: 0.958686	val: 0.784263	test: 0.728347
PRC train: 0.725746	val: 0.327000	test: 0.120732

Epoch: 52
Loss: 0.08263455473035902
ROC train: 0.966878	val: 0.785335	test: 0.752583
PRC train: 0.762433	val: 0.322933	test: 0.168092

Epoch: 53
Loss: 0.08368333592279324
ROC train: 0.959433	val: 0.790809	test: 0.720418
PRC train: 0.717870	val: 0.379073	test: 0.156114

Epoch: 54
Loss: 0.08074025752218549
ROC train: 0.967666	val: 0.792457	test: 0.749958
PRC train: 0.762164	val: 0.387575	test: 0.191150

Epoch: 55
Loss: 0.08115041094862452
ROC train: 0.972372	val: 0.782466	test: 0.701043
PRC train: 0.769648	val: 0.346026	test: 0.170503

Epoch: 56
Loss: 0.07939705345086455
ROC train: 0.971328	val: 0.795898	test: 0.724697
PRC train: 0.770395	val: 0.377533	test: 0.176411

Epoch: 57
Loss: 0.08116123280443469
ROC train: 0.971162	val: 0.811979	test: 0.710800
PRC train: 0.779032	val: 0.351777	test: 0.116241

Epoch: 58
Loss: 0.07968995993252503
ROC train: 0.968324	val: 0.799723	test: 0.745698
PRC train: 0.753850	val: 0.381073	test: 0.175828

Epoch: 59
Loss: 0.07863804519040349
ROC train: 0.973064	val: 0.774511	test: 0.746691
PRC train: 0.785574	val: 0.316881	test: 0.166753

Epoch: 60
Loss: 0.07807254814707786
ROC train: 0.969346	val: 0.779906	test: 0.722988
PRC train: 0.759863	val: 0.341068	test: 0.185985

Epoch: 61
Loss: 0.07785566747477894
ROC train: 0.975171	val: 0.793602	test: 0.737961
PRC train: 0.800595	val: 0.374607	test: 0.187234

Epoch: 62
Loss: 0.0757822412310772
ROC train: 0.976203	val: 0.810170	test: 0.733467
PRC train: 0.800485	val: 0.350180	test: 0.178860

Epoch: 63
Loss: 0.07390373971476501
ROC train: 0.973260	val: 0.810874	test: 0.743408
PRC train: 0.792433	val: 0.402850	test: 0.178803

Epoch: 64
Loss: 0.07505562447500756
ROC train: 0.980162	val: 0.809882	test: 0.753162
PRC train: 0.824269	val: 0.383722	test: 0.176469

Epoch: 65
Loss: 0.07260493508529164
ROC train: 0.979533	val: 0.795206	test: 0.747187
PRC train: 0.820900	val: 0.384545	test: 0.161263

Epoch: 66
Loss: 0.0738717218717079
ROC train: 0.977368	val: 0.799034	test: 0.739701
PRC train: 0.799194	val: 0.400596	test: 0.164200

Epoch: 67
Loss: 0.0740674845052367
ROC train: 0.978396	val: 0.794392	test: 0.737531
PRC train: 0.793879	val: 0.326623	test: 0.156167

Epoch: 68
Loss: 0.07188432101342399
ROC train: 0.980379	val: 0.807380	test: 0.718676
PRC train: 0.831202	val: 0.371787	test: 0.139787

Epoch: 69
Loss: 0.06857636318361296
ROC train: 0.977748	val: 0.785834	test: 0.746411
PRC train: 0.802029	val: 0.333303	test: 0.166982

Epoch: 70
Loss: 0.07324387218122466
ROC train: 0.983966	val: 0.787322	test: 0.746388
PRC train: 0.851883	val: 0.332866	test: 0.173946

Epoch: 71
Loss: 0.06881986355324773
ROC train: 0.985428	val: 0.799554	test: 0.741374
PRC train: 0.855213	val: 0.357948	test: 0.159707

Epoch: 72
Loss: 0.06853830405503682
ROC train: 0.985904	val: 0.799860	test: 0.743871
PRC train: 0.860312	val: 0.347481	test: 0.162094

Epoch: 73
Loss: 0.06723025006413585
ROC train: 0.981389	val: 0.780797	test: 0.746229
PRC train: 0.840977	val: 0.329498	test: 0.165524

Epoch: 74
Loss: 0.06843652370623589
ROC train: 0.983003	val: 0.800338	test: 0.738025
PRC train: 0.849345	val: 0.360775	test: 0.145474

Epoch: 75
Loss: 0.06543407890430232
ROC train: 0.988512	val: 0.793847	test: 0.724838
PRC train: 0.873474	val: 0.327882	test: 0.162146

Epoch: 76
Loss: 0.06618021655664896
ROC train: 0.987750	val: 0.795310	test: 0.738575
PRC train: 0.872146	val: 0.366213	test: 0.145473

Epoch: 77
Loss: 0.06584734450849974
ROC train: 0.985424	val: 0.800644	test: 0.712803
PRC train: 0.862874	val: 0.326832	test: 0.160850

Epoch: 78
Loss: 0.06601990084342733
ROC train: 0.988613	val: 0.803323	test: 0.747400
PRC train: 0.882839	val: 0.348455	test: 0.176108

Epoch: 79
Loss: 0.0637345059191038
ROC train: 0.985413	val: 0.799891	test: 0.730453
PRC train: 0.857362	val: 0.344548	test: 0.129864

Epoch: 80
Loss: 0.0625637434029988
ROC train: 0.990963	val: 0.808088	test: 0.744236
PRC train: 0.895929	val: 0.358767	test: 0.157808

Epoch: 81
Loss: 0.06406791382581911
ROC train: 0.989444	val: 0.801575	test: 0.716563
PRC train: 0.886719	val: 0.344939	test: 0.135844

Epoch: 82
Loss: 0.060919946700684284
ROC train: 0.990974	val: 0.795613	test: 0.723233
PRC train: 0.896988	val: 0.373817	test: 0.159729

Epoch: 83
Loss: 0.062282203644279215
ROC train: 0.988208	val: 0.809738	test: 0.745746
PRC train: 0.877657	val: 0.375153	test: 0.163672

Epoch: 84
Loss: 0.05901702394606122
ROC train: 0.990343	val: 0.809346	test: 0.765695
PRC train: 0.897360	val: 0.333667	test: 0.156361

Epoch: 85
Loss: 0.06166053713123411
ROC train: 0.992131	val: 0.808697	test: 0.742251
PRC train: 0.907873	val: 0.310917	test: 0.125434

Epoch: 86
Loss: 0.05981639313140385
ROC train: 0.989541	val: 0.788250	test: 0.728913
PRC train: 0.882607	val: 0.340746	test: 0.155031

Epoch: 87
Loss: 0.05750350114846427
ROC train: 0.989805	val: 0.807579	test: 0.755028
PRC train: 0.884821	val: 0.366105	test: 0.163977

Epoch: 88
Loss: 0.0603645629515309
ROC train: 0.992537	val: 0.795004	test: 0.739489
PRC train: 0.909377	val: 0.370825	test: 0.165591

Epoch: 89
Loss: 0.059391907244009515
ROC train: 0.992179	val: 0.808504	test: 0.734562
PRC train: 0.907918	val: 0.338987	test: 0.138559

Epoch: 90
Loss: 0.06114364632522499
ROC train: 0.992344	val: 0.803495	test: 0.730678
PRC train: 0.909695	val: 0.391286	test: 0.167109

Epoch: 91
Loss: 0.05866556775048823
ROC train: 0.993455	val: 0.795917	test: 0.733960
PRC train: 0.922026	val: 0.322654	test: 0.142319

Epoch: 92
Loss: 0.056679010742098676
ROC train: 0.992289	val: 0.780249	test: 0.727303
PRC train: 0.911644	val: 0.317324	test: 0.140059

Epoch: 93
Loss: 0.05672744107484761
ROC train: 0.992959	val: 0.785662	test: 0.740078
PRC train: 0.606546	val: 0.353606	test: 0.171358

Epoch: 33
Loss: 0.10211715434525813
ROC train: 0.937377	val: 0.805666	test: 0.730030
PRC train: 0.659449	val: 0.357838	test: 0.155839

Epoch: 34
Loss: 0.10241342003992186
ROC train: 0.937431	val: 0.807748	test: 0.767311
PRC train: 0.640613	val: 0.335631	test: 0.175560

Epoch: 35
Loss: 0.10101121803702454
ROC train: 0.933910	val: 0.801566	test: 0.744383
PRC train: 0.625570	val: 0.323398	test: 0.201234

Epoch: 36
Loss: 0.09849378359829451
ROC train: 0.945353	val: 0.794713	test: 0.752309
PRC train: 0.680432	val: 0.345122	test: 0.214884

Epoch: 37
Loss: 0.09778971459267764
ROC train: 0.942160	val: 0.776048	test: 0.743576
PRC train: 0.658120	val: 0.321144	test: 0.178767

Epoch: 38
Loss: 0.09825812559180504
ROC train: 0.946793	val: 0.793308	test: 0.712754
PRC train: 0.663524	val: 0.310310	test: 0.122818

Epoch: 39
Loss: 0.09540025378831224
ROC train: 0.948938	val: 0.781523	test: 0.719581
PRC train: 0.670591	val: 0.286098	test: 0.145665

Epoch: 40
Loss: 0.09472703289400677
ROC train: 0.952383	val: 0.757416	test: 0.746138
PRC train: 0.698066	val: 0.359645	test: 0.155919

Epoch: 41
Loss: 0.09485037541494626
ROC train: 0.953256	val: 0.796220	test: 0.763474
PRC train: 0.700823	val: 0.348194	test: 0.220845

Epoch: 42
Loss: 0.09316104384935463
ROC train: 0.946791	val: 0.783761	test: 0.762844
PRC train: 0.660721	val: 0.321421	test: 0.251632

Epoch: 43
Loss: 0.09118120516559526
ROC train: 0.960147	val: 0.807622	test: 0.755320
PRC train: 0.731275	val: 0.334628	test: 0.167408

Epoch: 44
Loss: 0.0890703756139166
ROC train: 0.959383	val: 0.813385	test: 0.733230
PRC train: 0.713098	val: 0.319667	test: 0.176268

Epoch: 45
Loss: 0.0903113644687016
ROC train: 0.963920	val: 0.800684	test: 0.752502
PRC train: 0.736248	val: 0.372829	test: 0.221213

Epoch: 46
Loss: 0.08727540033201207
ROC train: 0.968226	val: 0.798005	test: 0.773126
PRC train: 0.768440	val: 0.310036	test: 0.200752

Epoch: 47
Loss: 0.08769202691778077
ROC train: 0.958323	val: 0.804022	test: 0.708502
PRC train: 0.710285	val: 0.348694	test: 0.145751

Epoch: 48
Loss: 0.08596339295318112
ROC train: 0.969397	val: 0.782870	test: 0.751409
PRC train: 0.776007	val: 0.304279	test: 0.205333

Epoch: 49
Loss: 0.08395233760129141
ROC train: 0.969377	val: 0.796651	test: 0.729904
PRC train: 0.768503	val: 0.322943	test: 0.140785

Epoch: 50
Loss: 0.08371424636782217
ROC train: 0.973371	val: 0.795656	test: 0.742307
PRC train: 0.801494	val: 0.347204	test: 0.135216

Epoch: 51
Loss: 0.08314880087399895
ROC train: 0.975347	val: 0.782159	test: 0.737411
PRC train: 0.797896	val: 0.352371	test: 0.188345

Epoch: 52
Loss: 0.08038656994107435
ROC train: 0.972673	val: 0.796149	test: 0.754744
PRC train: 0.789129	val: 0.255504	test: 0.163896

Epoch: 53
Loss: 0.08021446357912042
ROC train: 0.983076	val: 0.807757	test: 0.734220
PRC train: 0.857581	val: 0.354429	test: 0.163621

Epoch: 54
Loss: 0.07813826956920823
ROC train: 0.978819	val: 0.813523	test: 0.749460
PRC train: 0.822926	val: 0.357613	test: 0.196405

Epoch: 55
Loss: 0.07757397114887356
ROC train: 0.976625	val: 0.805087	test: 0.748464
PRC train: 0.789014	val: 0.343003	test: 0.172494

Epoch: 56
Loss: 0.07739754921793111
ROC train: 0.978240	val: 0.799576	test: 0.715908
PRC train: 0.815516	val: 0.360320	test: 0.144205

Epoch: 57
Loss: 0.07639596126093796
ROC train: 0.982478	val: 0.784471	test: 0.730931
PRC train: 0.836251	val: 0.369462	test: 0.180322

Epoch: 58
Loss: 0.07602640763099626
ROC train: 0.981344	val: 0.821343	test: 0.756695
PRC train: 0.842058	val: 0.365898	test: 0.172031

Epoch: 59
Loss: 0.07158385729516051
ROC train: 0.983191	val: 0.802010	test: 0.713894
PRC train: 0.862752	val: 0.287175	test: 0.118953

Epoch: 60
Loss: 0.07370525560438061
ROC train: 0.981966	val: 0.813709	test: 0.762655
PRC train: 0.839392	val: 0.345970	test: 0.213597

Epoch: 61
Loss: 0.07137944320695505
ROC train: 0.982885	val: 0.801704	test: 0.755414
PRC train: 0.850199	val: 0.355815	test: 0.177743

Epoch: 62
Loss: 0.0717064805241961
ROC train: 0.983765	val: 0.817157	test: 0.732465
PRC train: 0.854329	val: 0.311699	test: 0.174940

Epoch: 63
Loss: 0.06833395261005656
ROC train: 0.986395	val: 0.801673	test: 0.750144
PRC train: 0.881686	val: 0.364139	test: 0.191309

Epoch: 64
Loss: 0.06964804913441322
ROC train: 0.988713	val: 0.810877	test: 0.750356
PRC train: 0.891429	val: 0.340288	test: 0.168732

Epoch: 65
Loss: 0.06779466205535543
ROC train: 0.986839	val: 0.833670	test: 0.724844
PRC train: 0.874638	val: 0.322294	test: 0.129872

Epoch: 66
Loss: 0.06611389205825136
ROC train: 0.985676	val: 0.814288	test: 0.737990
PRC train: 0.865908	val: 0.360421	test: 0.176975

Epoch: 67
Loss: 0.06767354398636403
ROC train: 0.991543	val: 0.777579	test: 0.754022
PRC train: 0.907938	val: 0.315650	test: 0.168940

Epoch: 68
Loss: 0.0659639298346699
ROC train: 0.989877	val: 0.805601	test: 0.766421
PRC train: 0.895772	val: 0.347111	test: 0.193954

Epoch: 69
Loss: 0.06371887003180159
ROC train: 0.988373	val: 0.807414	test: 0.753087
PRC train: 0.873699	val: 0.337001	test: 0.185485

Epoch: 70
Loss: 0.06296873405418171
ROC train: 0.991058	val: 0.788877	test: 0.756967
PRC train: 0.912649	val: 0.348120	test: 0.206918

Epoch: 71
Loss: 0.0641572457699709
ROC train: 0.990801	val: 0.820302	test: 0.747092
PRC train: 0.905233	val: 0.310596	test: 0.164448

Epoch: 72
Loss: 0.06186200913337355
ROC train: 0.992114	val: 0.780631	test: 0.736478
PRC train: 0.917337	val: 0.269685	test: 0.152868

Epoch: 73
Loss: 0.06380705630975371
ROC train: 0.989938	val: 0.807362	test: 0.754246
PRC train: 0.894360	val: 0.279889	test: 0.158578

Epoch: 74
Loss: 0.05873692163683195
ROC train: 0.992113	val: 0.772698	test: 0.712111
PRC train: 0.908038	val: 0.285249	test: 0.093091

Epoch: 75
Loss: 0.058800774287215286
ROC train: 0.993598	val: 0.810476	test: 0.747344
PRC train: 0.932921	val: 0.298966	test: 0.152917

Epoch: 76
Loss: 0.06050895655751449
ROC train: 0.994817	val: 0.823658	test: 0.753429
PRC train: 0.939217	val: 0.335984	test: 0.161829

Epoch: 77
Loss: 0.055990162288151214
ROC train: 0.994385	val: 0.801306	test: 0.765845
PRC train: 0.939210	val: 0.324089	test: 0.195291

Epoch: 78
Loss: 0.05575966008317712
ROC train: 0.995074	val: 0.812950	test: 0.765610
PRC train: 0.944604	val: 0.316100	test: 0.140615

Epoch: 79
Loss: 0.05650534235391742
ROC train: 0.995489	val: 0.812218	test: 0.763557
PRC train: 0.941939	val: 0.297862	test: 0.170257

Epoch: 80
Loss: 0.055362443280538846
ROC train: 0.995514	val: 0.796186	test: 0.738154
PRC train: 0.943598	val: 0.290217	test: 0.176888

Epoch: 81
Loss: 0.05239753607417273
ROC train: 0.996062	val: 0.791480	test: 0.745088
PRC train: 0.946842	val: 0.289027	test: 0.132643

Epoch: 82
Loss: 0.053451425245771185
ROC train: 0.997417	val: 0.802953	test: 0.723627
PRC train: 0.967132	val: 0.236701	test: 0.111008

Epoch: 83
Loss: 0.05442408400568876
ROC train: 0.996994	val: 0.795852	test: 0.747927
PRC train: 0.962870	val: 0.298932	test: 0.131269

Epoch: 84
Loss: 0.05243296828019726
ROC train: 0.996884	val: 0.796749	test: 0.746409
PRC train: 0.963553	val: 0.319004	test: 0.161890

Epoch: 85
Loss: 0.050664701700551075
ROC train: 0.997683	val: 0.796783	test: 0.741405
PRC train: 0.971613	val: 0.277392	test: 0.136613

Epoch: 86
Loss: 0.04991374976001115
ROC train: 0.997454	val: 0.802837	test: 0.766674
PRC train: 0.964923	val: 0.281156	test: 0.152048

Epoch: 87
Loss: 0.050179753973456004
ROC train: 0.997262	val: 0.780631	test: 0.751957
PRC train: 0.961317	val: 0.314016	test: 0.176941

Epoch: 88
Loss: 0.05099529121432534
ROC train: 0.997099	val: 0.778384	test: 0.751025
PRC train: 0.962600	val: 0.312664	test: 0.178700

Epoch: 89
Loss: 0.04904315607579256
ROC train: 0.997282	val: 0.806658	test: 0.740742
PRC train: 0.962752	val: 0.323439	test: 0.150590

Epoch: 90
Loss: 0.04879696743636413
ROC train: 0.996157	val: 0.793271	test: 0.727150
PRC train: 0.944656	val: 0.313825	test: 0.135098

Epoch: 91
Loss: 0.04906701580144762
ROC train: 0.996240	val: 0.783776	test: 0.760766
PRC train: 0.957021	val: 0.300871	test: 0.194792

Epoch: 92
Loss: 0.05057321246416526
ROC train: 0.997687	val: 0.789484	test: 0.741704
PRC train: 0.968445	val: 0.282521	test: 0.167979

Epoch: 93
Loss: 0.046685362623754105
ROC train: 0.997133	val: 0.793801	test: 0.742005
PRC train: 0.658204	val: 0.245547	test: 0.155705

Epoch: 33
Loss: 0.09786319109861334
ROC train: 0.938232	val: 0.749853	test: 0.720091
PRC train: 0.631959	val: 0.199758	test: 0.118016

Epoch: 34
Loss: 0.09891985547238896
ROC train: 0.948639	val: 0.734620	test: 0.718390
PRC train: 0.668851	val: 0.261892	test: 0.198049

Epoch: 35
Loss: 0.09497322743803739
ROC train: 0.944033	val: 0.819239	test: 0.711665
PRC train: 0.628304	val: 0.255997	test: 0.197041

Epoch: 36
Loss: 0.09485066619279588
ROC train: 0.955544	val: 0.724433	test: 0.711568
PRC train: 0.714445	val: 0.232629	test: 0.185748

Epoch: 37
Loss: 0.09363397511501065
ROC train: 0.951454	val: 0.797500	test: 0.702737
PRC train: 0.691212	val: 0.299333	test: 0.209315

Epoch: 38
Loss: 0.09202496862429305
ROC train: 0.960373	val: 0.784434	test: 0.709792
PRC train: 0.743829	val: 0.286426	test: 0.205570

Epoch: 39
Loss: 0.09093857997954786
ROC train: 0.958945	val: 0.763077	test: 0.698316
PRC train: 0.732686	val: 0.242806	test: 0.146934

Epoch: 40
Loss: 0.08875240894957989
ROC train: 0.965605	val: 0.766544	test: 0.727424
PRC train: 0.753909	val: 0.276961	test: 0.173789

Epoch: 41
Loss: 0.08819261170114924
ROC train: 0.959325	val: 0.761283	test: 0.710041
PRC train: 0.734854	val: 0.262204	test: 0.202009

Epoch: 42
Loss: 0.0880827196438099
ROC train: 0.964784	val: 0.742786	test: 0.694289
PRC train: 0.760933	val: 0.276308	test: 0.203957

Epoch: 43
Loss: 0.08564435358644634
ROC train: 0.966216	val: 0.757762	test: 0.706366
PRC train: 0.736856	val: 0.225331	test: 0.189444

Epoch: 44
Loss: 0.08619382815199161
ROC train: 0.973638	val: 0.792307	test: 0.711369
PRC train: 0.799682	val: 0.236628	test: 0.189527

Epoch: 45
Loss: 0.08380137876403305
ROC train: 0.965931	val: 0.742446	test: 0.717561
PRC train: 0.746827	val: 0.300476	test: 0.227072

Epoch: 46
Loss: 0.08285455910703801
ROC train: 0.971045	val: 0.766896	test: 0.720690
PRC train: 0.783505	val: 0.264324	test: 0.178489

Epoch: 47
Loss: 0.08261108715488392
ROC train: 0.977780	val: 0.730731	test: 0.716733
PRC train: 0.819432	val: 0.279299	test: 0.205335

Epoch: 48
Loss: 0.07997577747812391
ROC train: 0.975564	val: 0.762548	test: 0.716625
PRC train: 0.805063	val: 0.215161	test: 0.162325

Epoch: 49
Loss: 0.07855884876087312
ROC train: 0.978569	val: 0.765460	test: 0.734307
PRC train: 0.836819	val: 0.289486	test: 0.203880

Epoch: 50
Loss: 0.07712626666470873
ROC train: 0.978537	val: 0.735070	test: 0.711051
PRC train: 0.824789	val: 0.270805	test: 0.147104

Epoch: 51
Loss: 0.0775358098445113
ROC train: 0.982439	val: 0.778684	test: 0.716455
PRC train: 0.848425	val: 0.278711	test: 0.179231

Epoch: 52
Loss: 0.07625600873879369
ROC train: 0.982827	val: 0.767107	test: 0.721151
PRC train: 0.855013	val: 0.278157	test: 0.218073

Epoch: 53
Loss: 0.07328914272783577
ROC train: 0.985248	val: 0.768356	test: 0.720060
PRC train: 0.866807	val: 0.312811	test: 0.195538

Epoch: 54
Loss: 0.07342728908117849
ROC train: 0.981968	val: 0.763025	test: 0.716399
PRC train: 0.852287	val: 0.276482	test: 0.218935

Epoch: 55
Loss: 0.07708114356582407
ROC train: 0.982870	val: 0.768372	test: 0.717712
PRC train: 0.848967	val: 0.255052	test: 0.206938

Epoch: 56
Loss: 0.07211119651458268
ROC train: 0.987394	val: 0.803752	test: 0.738450
PRC train: 0.881444	val: 0.268866	test: 0.204185

Epoch: 57
Loss: 0.07248561641709128
ROC train: 0.982541	val: 0.762447	test: 0.736750
PRC train: 0.844407	val: 0.258538	test: 0.224433

Epoch: 58
Loss: 0.07336299664895375
ROC train: 0.988950	val: 0.726916	test: 0.721729
PRC train: 0.901282	val: 0.270527	test: 0.174674

Epoch: 59
Loss: 0.06870530698577712
ROC train: 0.986274	val: 0.755493	test: 0.736640
PRC train: 0.866290	val: 0.310758	test: 0.222837

Epoch: 60
Loss: 0.06817542441152276
ROC train: 0.990544	val: 0.742042	test: 0.731366
PRC train: 0.909067	val: 0.244993	test: 0.177898

Epoch: 61
Loss: 0.06502006336859018
ROC train: 0.989959	val: 0.754795	test: 0.707963
PRC train: 0.900837	val: 0.276000	test: 0.201768

Epoch: 62
Loss: 0.06506075168316493
ROC train: 0.990408	val: 0.765937	test: 0.711926
PRC train: 0.907954	val: 0.301096	test: 0.213462

Epoch: 63
Loss: 0.06393966581971271
ROC train: 0.988581	val: 0.774791	test: 0.709413
PRC train: 0.883771	val: 0.236355	test: 0.134216

Epoch: 64
Loss: 0.06389020183470975
ROC train: 0.991167	val: 0.779113	test: 0.715516
PRC train: 0.915721	val: 0.238094	test: 0.172011

Epoch: 65
Loss: 0.06415215582908296
ROC train: 0.992936	val: 0.734249	test: 0.719450
PRC train: 0.923363	val: 0.249813	test: 0.188929

Epoch: 66
Loss: 0.06263148039309153
ROC train: 0.991181	val: 0.754311	test: 0.718890
PRC train: 0.905854	val: 0.276169	test: 0.189765

Epoch: 67
Loss: 0.06442341632677105
ROC train: 0.993426	val: 0.768408	test: 0.720159
PRC train: 0.929376	val: 0.235388	test: 0.170420

Epoch: 68
Loss: 0.06164163313069315
ROC train: 0.992884	val: 0.774266	test: 0.756339
PRC train: 0.921110	val: 0.276927	test: 0.216333

Epoch: 69
Loss: 0.05954882004109688
ROC train: 0.992527	val: 0.739231	test: 0.719475
PRC train: 0.921653	val: 0.222643	test: 0.161460

Epoch: 70
Loss: 0.058512025775336915
ROC train: 0.991111	val: 0.750132	test: 0.719811
PRC train: 0.904662	val: 0.230567	test: 0.151864

Epoch: 71
Loss: 0.05774036482875255
ROC train: 0.993526	val: 0.754642	test: 0.727082
PRC train: 0.922767	val: 0.276013	test: 0.147911

Epoch: 72
Loss: 0.05783087387922494
ROC train: 0.994499	val: 0.743674	test: 0.724659
PRC train: 0.939545	val: 0.261306	test: 0.199722

Epoch: 73
Loss: 0.05535747310778427
ROC train: 0.996000	val: 0.754651	test: 0.714295
PRC train: 0.951597	val: 0.236307	test: 0.179512

Epoch: 74
Loss: 0.05462774395116347
ROC train: 0.995794	val: 0.742207	test: 0.724236
PRC train: 0.944519	val: 0.246424	test: 0.170516

Epoch: 75
Loss: 0.05720868757559732
ROC train: 0.996396	val: 0.728848	test: 0.703449
PRC train: 0.957208	val: 0.260712	test: 0.183214

Epoch: 76
Loss: 0.05379238013482117
ROC train: 0.995839	val: 0.763090	test: 0.715365
PRC train: 0.952514	val: 0.246438	test: 0.126615

Epoch: 77
Loss: 0.05251730516648999
ROC train: 0.997009	val: 0.735796	test: 0.716935
PRC train: 0.962235	val: 0.176645	test: 0.137199

Epoch: 78
Loss: 0.05192966524431096
ROC train: 0.996112	val: 0.739580	test: 0.713695
PRC train: 0.954323	val: 0.261881	test: 0.213595

Epoch: 79
Loss: 0.050780012437715225
ROC train: 0.997095	val: 0.782858	test: 0.707752
PRC train: 0.963968	val: 0.303120	test: 0.204714

Epoch: 80
Loss: 0.04913284298483101
ROC train: 0.996047	val: 0.745092	test: 0.737815
PRC train: 0.954728	val: 0.260689	test: 0.170825

Epoch: 81
Loss: 0.049893777584872706
ROC train: 0.997456	val: 0.765469	test: 0.710195
PRC train: 0.967397	val: 0.247794	test: 0.187092

Epoch: 82
Loss: 0.05018322318844904
ROC train: 0.998195	val: 0.747278	test: 0.715462
PRC train: 0.976285	val: 0.185682	test: 0.127317

Epoch: 83
Loss: 0.04847588465456743
ROC train: 0.996614	val: 0.743754	test: 0.728052
PRC train: 0.963157	val: 0.259213	test: 0.211487

Epoch: 84
Loss: 0.048967040261419244
ROC train: 0.997435	val: 0.760181	test: 0.737243
PRC train: 0.965272	val: 0.255835	test: 0.210849

Epoch: 85
Loss: 0.04545720905047138
ROC train: 0.995817	val: 0.762961	test: 0.722704
PRC train: 0.947281	val: 0.173100	test: 0.120320

Epoch: 86
Loss: 0.04653620923698766
ROC train: 0.998119	val: 0.773188	test: 0.743568
PRC train: 0.976184	val: 0.221599	test: 0.172137

Epoch: 87
Loss: 0.04667011375369842
ROC train: 0.998212	val: 0.763515	test: 0.728179
PRC train: 0.974529	val: 0.259797	test: 0.218306

Epoch: 88
Loss: 0.04641436460143085
ROC train: 0.998134	val: 0.739828	test: 0.713042
PRC train: 0.975716	val: 0.214902	test: 0.161661

Epoch: 89
Loss: 0.046025346897455334
ROC train: 0.997705	val: 0.765796	test: 0.727882
PRC train: 0.969262	val: 0.248328	test: 0.182356

Epoch: 90
Loss: 0.043681688578997895
ROC train: 0.998833	val: 0.770163	test: 0.729398
PRC train: 0.984744	val: 0.227670	test: 0.160461

Epoch: 91
Loss: 0.04135407662703183
ROC train: 0.998605	val: 0.739464	test: 0.716520
PRC train: 0.980987	val: 0.252730	test: 0.225914

Epoch: 92
Loss: 0.04412402495950994
ROC train: 0.998236	val: 0.752131	test: 0.711074
PRC train: 0.978294	val: 0.271514	test: 0.222944

Epoch: 93
Loss: 0.04403542043527471
ROC train: 0.999011	val: 0.755374	test: 0.736741
PRC train: 0.635043	val: 0.271089	test: 0.212415

Epoch: 33
Loss: 0.10204233919952448
ROC train: 0.936271	val: 0.754302	test: 0.727436
PRC train: 0.642218	val: 0.252401	test: 0.170309

Epoch: 34
Loss: 0.10158715579119536
ROC train: 0.943631	val: 0.773007	test: 0.715564
PRC train: 0.660577	val: 0.294321	test: 0.207215

Epoch: 35
Loss: 0.0999213793584851
ROC train: 0.941303	val: 0.752385	test: 0.728774
PRC train: 0.662782	val: 0.257305	test: 0.197678

Epoch: 36
Loss: 0.09716874275995205
ROC train: 0.947820	val: 0.750438	test: 0.713672
PRC train: 0.686028	val: 0.276710	test: 0.209672

Epoch: 37
Loss: 0.09542329220495196
ROC train: 0.950383	val: 0.769434	test: 0.733631
PRC train: 0.682376	val: 0.259059	test: 0.208454

Epoch: 38
Loss: 0.09444621720004671
ROC train: 0.952709	val: 0.783014	test: 0.730771
PRC train: 0.693057	val: 0.279120	test: 0.243326

Epoch: 39
Loss: 0.09616624070337904
ROC train: 0.958055	val: 0.763687	test: 0.728842
PRC train: 0.716052	val: 0.240553	test: 0.188474

Epoch: 40
Loss: 0.09444965132253431
ROC train: 0.950417	val: 0.782392	test: 0.744638
PRC train: 0.694440	val: 0.318801	test: 0.218397

Epoch: 41
Loss: 0.09307993386057994
ROC train: 0.958678	val: 0.748962	test: 0.709535
PRC train: 0.709408	val: 0.204663	test: 0.148490

Epoch: 42
Loss: 0.09262614037039629
ROC train: 0.958709	val: 0.781232	test: 0.721076
PRC train: 0.740165	val: 0.277728	test: 0.177953

Epoch: 43
Loss: 0.09033462095866698
ROC train: 0.966845	val: 0.790616	test: 0.723896
PRC train: 0.769012	val: 0.262324	test: 0.171429

Epoch: 44
Loss: 0.08988182460598315
ROC train: 0.965080	val: 0.788452	test: 0.749874
PRC train: 0.745099	val: 0.291416	test: 0.223731

Epoch: 45
Loss: 0.0870759839780891
ROC train: 0.963718	val: 0.783109	test: 0.733823
PRC train: 0.750055	val: 0.294058	test: 0.200795

Epoch: 46
Loss: 0.08654989366657627
ROC train: 0.962046	val: 0.798605	test: 0.739779
PRC train: 0.723419	val: 0.241004	test: 0.179271

Epoch: 47
Loss: 0.08650457964288612
ROC train: 0.966301	val: 0.791860	test: 0.733994
PRC train: 0.756692	val: 0.298809	test: 0.159412

Epoch: 48
Loss: 0.08678225076938358
ROC train: 0.974362	val: 0.738227	test: 0.737759
PRC train: 0.790685	val: 0.276776	test: 0.207393

Epoch: 49
Loss: 0.08361125875202739
ROC train: 0.973438	val: 0.740634	test: 0.745623
PRC train: 0.790660	val: 0.224697	test: 0.146488

Epoch: 50
Loss: 0.08171201781409963
ROC train: 0.977737	val: 0.757661	test: 0.707727
PRC train: 0.804619	val: 0.215312	test: 0.145640

Epoch: 51
Loss: 0.08290023088792196
ROC train: 0.979188	val: 0.757826	test: 0.720528
PRC train: 0.825707	val: 0.261162	test: 0.152572

Epoch: 52
Loss: 0.08023344441505828
ROC train: 0.979899	val: 0.758139	test: 0.746921
PRC train: 0.830859	val: 0.239074	test: 0.207121

Epoch: 53
Loss: 0.07965859462180347
ROC train: 0.979920	val: 0.760025	test: 0.726405
PRC train: 0.824861	val: 0.252397	test: 0.198711

Epoch: 54
Loss: 0.08166048173505329
ROC train: 0.978941	val: 0.784869	test: 0.720371
PRC train: 0.826958	val: 0.254536	test: 0.173904

Epoch: 55
Loss: 0.07567905505429492
ROC train: 0.978678	val: 0.767854	test: 0.730767
PRC train: 0.831275	val: 0.248016	test: 0.182061

Epoch: 56
Loss: 0.07633642431422781
ROC train: 0.984876	val: 0.807123	test: 0.707059
PRC train: 0.865332	val: 0.249036	test: 0.148267

Epoch: 57
Loss: 0.07444673470248145
ROC train: 0.982240	val: 0.776608	test: 0.727164
PRC train: 0.840492	val: 0.277232	test: 0.226729

Epoch: 58
Loss: 0.07654159922275497
ROC train: 0.983483	val: 0.786823	test: 0.711186
PRC train: 0.855781	val: 0.242293	test: 0.200247

Epoch: 59
Loss: 0.07426060523834487
ROC train: 0.982988	val: 0.803357	test: 0.724632
PRC train: 0.853231	val: 0.293150	test: 0.229093

Epoch: 60
Loss: 0.07184922986915157
ROC train: 0.985116	val: 0.807785	test: 0.742687
PRC train: 0.861649	val: 0.273793	test: 0.187068

Epoch: 61
Loss: 0.07245718712379794
ROC train: 0.985023	val: 0.795436	test: 0.728036
PRC train: 0.864731	val: 0.268907	test: 0.228972

Epoch: 62
Loss: 0.0691819688974034
ROC train: 0.988313	val: 0.787509	test: 0.712629
PRC train: 0.886723	val: 0.285068	test: 0.173839

Epoch: 63
Loss: 0.06833959491230579
ROC train: 0.985052	val: 0.756369	test: 0.696925
PRC train: 0.850817	val: 0.222364	test: 0.120909

Epoch: 64
Loss: 0.06891562823059089
ROC train: 0.989358	val: 0.763427	test: 0.701900
PRC train: 0.896781	val: 0.231584	test: 0.189869

Epoch: 65
Loss: 0.0680583122067771
ROC train: 0.991634	val: 0.760986	test: 0.697833
PRC train: 0.911607	val: 0.234376	test: 0.169223

Epoch: 66
Loss: 0.06587948082782541
ROC train: 0.989929	val: 0.773571	test: 0.708156
PRC train: 0.897973	val: 0.234882	test: 0.193542

Epoch: 67
Loss: 0.06584819931663886
ROC train: 0.992108	val: 0.772652	test: 0.717308
PRC train: 0.912239	val: 0.277328	test: 0.222562

Epoch: 68
Loss: 0.06394672258928669
ROC train: 0.991031	val: 0.792570	test: 0.732550
PRC train: 0.904921	val: 0.271346	test: 0.185544

Epoch: 69
Loss: 0.06340797184051888
ROC train: 0.991945	val: 0.774486	test: 0.689998
PRC train: 0.906166	val: 0.265688	test: 0.160104

Epoch: 70
Loss: 0.06287867305195897
ROC train: 0.992494	val: 0.787000	test: 0.689457
PRC train: 0.921002	val: 0.261169	test: 0.167571

Epoch: 71
Loss: 0.05969301762702326
ROC train: 0.991086	val: 0.780684	test: 0.689615
PRC train: 0.901101	val: 0.245195	test: 0.208075

Epoch: 72
Loss: 0.0602728253861588
ROC train: 0.994059	val: 0.796247	test: 0.724639
PRC train: 0.926932	val: 0.259796	test: 0.147328

Epoch: 73
Loss: 0.05736521211196489
ROC train: 0.991577	val: 0.784505	test: 0.722532
PRC train: 0.910076	val: 0.310653	test: 0.218819

Epoch: 74
Loss: 0.05863104824668222
ROC train: 0.995654	val: 0.777104	test: 0.718511
PRC train: 0.943843	val: 0.245577	test: 0.174885

Epoch: 75
Loss: 0.057235821590060416
ROC train: 0.995033	val: 0.782083	test: 0.723409
PRC train: 0.935622	val: 0.314595	test: 0.202083

Epoch: 76
Loss: 0.05816704001487486
ROC train: 0.995225	val: 0.803082	test: 0.713235
PRC train: 0.941874	val: 0.259482	test: 0.170003

Epoch: 77
Loss: 0.057114739357048534
ROC train: 0.994827	val: 0.780711	test: 0.713592
PRC train: 0.930134	val: 0.327753	test: 0.234833

Epoch: 78
Loss: 0.05478061292493779
ROC train: 0.996634	val: 0.796119	test: 0.713747
PRC train: 0.960327	val: 0.288900	test: 0.212566

Epoch: 79
Loss: 0.053791195377227805
ROC train: 0.996105	val: 0.798280	test: 0.716456
PRC train: 0.951607	val: 0.295553	test: 0.191710

Epoch: 80
Loss: 0.052791986373016596
ROC train: 0.996244	val: 0.802129	test: 0.699183
PRC train: 0.954653	val: 0.251795	test: 0.184598

Epoch: 81
Loss: 0.05416769882826649
ROC train: 0.997160	val: 0.780956	test: 0.724017
PRC train: 0.959246	val: 0.245658	test: 0.144660

Epoch: 82
Loss: 0.05261626908130785
ROC train: 0.997145	val: 0.802622	test: 0.719004
PRC train: 0.962863	val: 0.279919	test: 0.168862

Epoch: 83
Loss: 0.05151174106112238
ROC train: 0.996547	val: 0.806633	test: 0.719715
PRC train: 0.955026	val: 0.306622	test: 0.211956

Epoch: 84
Loss: 0.05277184423776893
ROC train: 0.996790	val: 0.798721	test: 0.730644
PRC train: 0.955328	val: 0.297502	test: 0.199516

Epoch: 85
Loss: 0.051663844509988545
ROC train: 0.996927	val: 0.772202	test: 0.723591
PRC train: 0.959250	val: 0.301320	test: 0.232484

Epoch: 86
Loss: 0.049984341888206996
ROC train: 0.997798	val: 0.793412	test: 0.721970
PRC train: 0.973008	val: 0.284620	test: 0.215631

Epoch: 87
Loss: 0.04838343502893687
ROC train: 0.997268	val: 0.763289	test: 0.721990
PRC train: 0.964016	val: 0.267119	test: 0.192294

Epoch: 88
Loss: 0.05013778787646301
ROC train: 0.996518	val: 0.801352	test: 0.709288
PRC train: 0.948948	val: 0.305275	test: 0.189964

Epoch: 89
Loss: 0.05050975477688039
ROC train: 0.997145	val: 0.798731	test: 0.721431
PRC train: 0.962226	val: 0.286333	test: 0.199856

Epoch: 90
Loss: 0.04640635414358723
ROC train: 0.998720	val: 0.773978	test: 0.699309
PRC train: 0.981246	val: 0.288604	test: 0.206021

Epoch: 91
Loss: 0.04879750536905371
ROC train: 0.998526	val: 0.802794	test: 0.718579
PRC train: 0.978716	val: 0.304980	test: 0.179803

Epoch: 92
Loss: 0.04448390583163324
ROC train: 0.998721	val: 0.799490	test: 0.707781
PRC train: 0.979166	val: 0.299755	test: 0.173271

Epoch: 93
Loss: 0.04643112963367259
ROC train: 0.998637	val: 0.790895	test: 0.712845
ROC train: 0.974899	val: 0.800476	test: 0.747104
PRC train: 0.767631	val: 0.304442	test: 0.169425

Epoch: 95
Loss: 0.07708093177529374
ROC train: 0.980371	val: 0.786945	test: 0.745551
PRC train: 0.780584	val: 0.305897	test: 0.164900

Epoch: 96
Loss: 0.07495854373549143
ROC train: 0.975657	val: 0.809977	test: 0.772580
PRC train: 0.751910	val: 0.342727	test: 0.173336

Epoch: 97
Loss: 0.07505094876619746
ROC train: 0.977081	val: 0.801796	test: 0.757577
PRC train: 0.770308	val: 0.353333	test: 0.167366

Epoch: 98
Loss: 0.07438402773702825
ROC train: 0.977860	val: 0.809248	test: 0.751531
PRC train: 0.772533	val: 0.318266	test: 0.141315

Epoch: 99
Loss: 0.07232828477161504
ROC train: 0.978078	val: 0.802564	test: 0.736320
PRC train: 0.773669	val: 0.327653	test: 0.177298

Epoch: 100
Loss: 0.07514671955727432
ROC train: 0.980281	val: 0.808467	test: 0.752457
PRC train: 0.789210	val: 0.335192	test: 0.183845

Epoch: 101
Loss: 0.07370415621295608
ROC train: 0.981576	val: 0.782891	test: 0.757525
PRC train: 0.788746	val: 0.286242	test: 0.154372

Epoch: 102
Loss: 0.07270142780956584
ROC train: 0.981917	val: 0.792092	test: 0.782420
PRC train: 0.793756	val: 0.326761	test: 0.204884

Epoch: 103
Loss: 0.07333175385904955
ROC train: 0.980751	val: 0.790629	test: 0.775067
PRC train: 0.794611	val: 0.311462	test: 0.196443

Epoch: 104
Loss: 0.07281941666122704
ROC train: 0.982383	val: 0.805663	test: 0.760783
PRC train: 0.793919	val: 0.328097	test: 0.209552

Epoch: 105
Loss: 0.0713669514644251
ROC train: 0.977689	val: 0.804521	test: 0.738790
PRC train: 0.774849	val: 0.232467	test: 0.106484

Epoch: 106
Loss: 0.07202768498897902
ROC train: 0.983662	val: 0.783816	test: 0.748782
PRC train: 0.800331	val: 0.309515	test: 0.164912

Epoch: 107
Loss: 0.07107045538860549
ROC train: 0.979370	val: 0.772205	test: 0.745248
PRC train: 0.777151	val: 0.286084	test: 0.158413

Epoch: 108
Loss: 0.07138797053097255
ROC train: 0.984506	val: 0.789401	test: 0.763421
PRC train: 0.809405	val: 0.306495	test: 0.185000

Epoch: 109
Loss: 0.07251561703318737
ROC train: 0.983409	val: 0.789710	test: 0.739060
PRC train: 0.804719	val: 0.305578	test: 0.147226

Epoch: 110
Loss: 0.07133504510164584
ROC train: 0.983189	val: 0.806590	test: 0.765241
PRC train: 0.799560	val: 0.313672	test: 0.195409

Epoch: 111
Loss: 0.07104475520633675
ROC train: 0.983476	val: 0.789995	test: 0.767701
PRC train: 0.804631	val: 0.295936	test: 0.177232

Epoch: 112
Loss: 0.07130090697415875
ROC train: 0.984894	val: 0.815369	test: 0.763049
PRC train: 0.813245	val: 0.337012	test: 0.168498

Epoch: 113
Loss: 0.07096859959319796
ROC train: 0.985554	val: 0.802956	test: 0.752152
PRC train: 0.816816	val: 0.325059	test: 0.154365

Epoch: 114
Loss: 0.06977923562325787
ROC train: 0.985964	val: 0.798164	test: 0.757643
PRC train: 0.813071	val: 0.293257	test: 0.202931

Epoch: 115
Loss: 0.06854610629793652
ROC train: 0.986403	val: 0.811012	test: 0.773244
PRC train: 0.824831	val: 0.320142	test: 0.196350

Epoch: 116
Loss: 0.06805093713695562
ROC train: 0.981611	val: 0.815657	test: 0.774432
PRC train: 0.792193	val: 0.288932	test: 0.202301

Epoch: 117
Loss: 0.06876511704764422
ROC train: 0.980136	val: 0.815103	test: 0.755204
PRC train: 0.784137	val: 0.360972	test: 0.222307

Epoch: 118
Loss: 0.06978613208561033
ROC train: 0.986521	val: 0.821138	test: 0.744053
PRC train: 0.827769	val: 0.335302	test: 0.189267

Epoch: 119
Loss: 0.0670756176527515
ROC train: 0.986058	val: 0.786866	test: 0.736503
PRC train: 0.825085	val: 0.283086	test: 0.152084

Epoch: 120
Loss: 0.06753986010479608
ROC train: 0.987786	val: 0.802203	test: 0.748645
PRC train: 0.833532	val: 0.330972	test: 0.193144

Early stopping
Best (ROC):	 train: 0.897007	val: 0.829099	test: 0.735167
Best (PRC):	 train: 0.549914	val: 0.338078	test: 0.188887

ROC train: 0.977528	val: 0.824506	test: 0.761094
PRC train: 0.771154	val: 0.360396	test: 0.185702

Epoch: 95
Loss: 0.07501794640103228
ROC train: 0.975437	val: 0.812286	test: 0.753439
PRC train: 0.752728	val: 0.360899	test: 0.214864

Epoch: 96
Loss: 0.07603934167479978
ROC train: 0.978769	val: 0.805650	test: 0.734639
PRC train: 0.781661	val: 0.291508	test: 0.163887

Epoch: 97
Loss: 0.0744843545894907
ROC train: 0.977920	val: 0.820286	test: 0.768595
PRC train: 0.771598	val: 0.368282	test: 0.201864

Epoch: 98
Loss: 0.07477028322775885
ROC train: 0.972487	val: 0.790319	test: 0.761813
PRC train: 0.758492	val: 0.358593	test: 0.215683

Epoch: 99
Loss: 0.07414936141555395
ROC train: 0.971217	val: 0.807451	test: 0.748330
PRC train: 0.742794	val: 0.336434	test: 0.153230

Epoch: 100
Loss: 0.07439998820704706
ROC train: 0.977830	val: 0.809147	test: 0.740393
PRC train: 0.781298	val: 0.330369	test: 0.182603

Epoch: 101
Loss: 0.0743687853952139
ROC train: 0.980674	val: 0.789208	test: 0.767775
PRC train: 0.790328	val: 0.328020	test: 0.200502

Epoch: 102
Loss: 0.07502297183503517
ROC train: 0.980456	val: 0.789918	test: 0.772773
PRC train: 0.787418	val: 0.359161	test: 0.195245

Epoch: 103
Loss: 0.0750301780805056
ROC train: 0.981328	val: 0.813590	test: 0.753856
PRC train: 0.792312	val: 0.370846	test: 0.175190

Epoch: 104
Loss: 0.0736231824806852
ROC train: 0.980969	val: 0.808774	test: 0.754702
PRC train: 0.790105	val: 0.340273	test: 0.162809

Epoch: 105
Loss: 0.07178286308927871
ROC train: 0.978121	val: 0.808734	test: 0.761706
PRC train: 0.770495	val: 0.328135	test: 0.194315

Epoch: 106
Loss: 0.0714621218440903
ROC train: 0.981966	val: 0.799450	test: 0.756579
PRC train: 0.803761	val: 0.331890	test: 0.165159

Epoch: 107
Loss: 0.07162455384676726
ROC train: 0.978139	val: 0.794778	test: 0.760534
PRC train: 0.769929	val: 0.304689	test: 0.201317

Epoch: 108
Loss: 0.07321319541980185
ROC train: 0.982291	val: 0.805853	test: 0.752299
PRC train: 0.801977	val: 0.341941	test: 0.154745

Epoch: 109
Loss: 0.06944039264482818
ROC train: 0.983406	val: 0.807139	test: 0.757836
PRC train: 0.807813	val: 0.305709	test: 0.159339

Epoch: 110
Loss: 0.07233472123513728
ROC train: 0.983741	val: 0.795926	test: 0.762212
PRC train: 0.805767	val: 0.331317	test: 0.193007

Epoch: 111
Loss: 0.07056424500286242
ROC train: 0.982786	val: 0.793700	test: 0.744062
PRC train: 0.799968	val: 0.287323	test: 0.194467

Epoch: 112
Loss: 0.07086473198414134
ROC train: 0.983049	val: 0.822173	test: 0.784515
PRC train: 0.810003	val: 0.354464	test: 0.187203

Epoch: 113
Loss: 0.07235908686569183
ROC train: 0.985476	val: 0.806581	test: 0.742313
PRC train: 0.818209	val: 0.314322	test: 0.131728

Epoch: 114
Loss: 0.06801251265525958
ROC train: 0.983650	val: 0.798467	test: 0.751444
PRC train: 0.813905	val: 0.301344	test: 0.162132

Epoch: 115
Loss: 0.06928097653677605
ROC train: 0.980770	val: 0.784762	test: 0.771303
PRC train: 0.794501	val: 0.262724	test: 0.179584

Epoch: 116
Loss: 0.06886636182195854
ROC train: 0.981327	val: 0.796988	test: 0.750733
PRC train: 0.798407	val: 0.346393	test: 0.162313

Epoch: 117
Loss: 0.06931892039855585
ROC train: 0.983932	val: 0.800975	test: 0.741816
PRC train: 0.808054	val: 0.316921	test: 0.122423

Epoch: 118
Loss: 0.06739258295443953
ROC train: 0.986185	val: 0.793155	test: 0.768628
PRC train: 0.822618	val: 0.346060	test: 0.230536

Epoch: 119
Loss: 0.06932527649169258
ROC train: 0.986907	val: 0.793084	test: 0.753728
PRC train: 0.826797	val: 0.320003	test: 0.177219

Epoch: 120
Loss: 0.06774150613359811
ROC train: 0.985359	val: 0.785959	test: 0.748110
PRC train: 0.820192	val: 0.305448	test: 0.161428

Early stopping
Best (ROC):	 train: 0.922050	val: 0.846252	test: 0.759874
Best (PRC):	 train: 0.587221	val: 0.388691	test: 0.181898

PRC train: 0.958718	val: 0.330618	test: 0.176714

Epoch: 94
Loss: 0.04934898204820788
ROC train: 0.997000	val: 0.779303	test: 0.761768
PRC train: 0.961000	val: 0.340114	test: 0.158654

Epoch: 95
Loss: 0.05052013383168564
ROC train: 0.996882	val: 0.786657	test: 0.771597
PRC train: 0.961740	val: 0.322788	test: 0.177799

Epoch: 96
Loss: 0.04857380588058521
ROC train: 0.997634	val: 0.794474	test: 0.758437
PRC train: 0.968775	val: 0.326852	test: 0.158542

Epoch: 97
Loss: 0.04722762539552487
ROC train: 0.996419	val: 0.800145	test: 0.763045
PRC train: 0.955314	val: 0.352826	test: 0.169638

Epoch: 98
Loss: 0.04969360392051433
ROC train: 0.997060	val: 0.787089	test: 0.784482
PRC train: 0.960700	val: 0.340616	test: 0.170890

Epoch: 99
Loss: 0.048247105988744314
ROC train: 0.997418	val: 0.784741	test: 0.796292
PRC train: 0.965107	val: 0.315044	test: 0.177690

Epoch: 100
Loss: 0.0463969389689041
ROC train: 0.997133	val: 0.803486	test: 0.778569
PRC train: 0.962915	val: 0.331952	test: 0.201401

Epoch: 101
Loss: 0.047988198214611776
ROC train: 0.998193	val: 0.799787	test: 0.772228
PRC train: 0.974383	val: 0.326381	test: 0.195542

Epoch: 102
Loss: 0.044254134887497666
ROC train: 0.997693	val: 0.786670	test: 0.771264
PRC train: 0.965523	val: 0.313917	test: 0.180453

Epoch: 103
Loss: 0.04499461253666481
ROC train: 0.997206	val: 0.796287	test: 0.778582
PRC train: 0.961126	val: 0.321218	test: 0.166419

Epoch: 104
Loss: 0.044540178991709166
ROC train: 0.998276	val: 0.816312	test: 0.781257
PRC train: 0.973221	val: 0.360591	test: 0.199777

Epoch: 105
Loss: 0.04309837448697689
ROC train: 0.998627	val: 0.792420	test: 0.769470
PRC train: 0.979416	val: 0.303938	test: 0.150907

Epoch: 106
Loss: 0.042622584040186456
ROC train: 0.998278	val: 0.779407	test: 0.780079
PRC train: 0.974644	val: 0.310276	test: 0.156830

Epoch: 107
Loss: 0.04484595684395885
ROC train: 0.997788	val: 0.789321	test: 0.760357
PRC train: 0.969672	val: 0.323189	test: 0.142376

Epoch: 108
Loss: 0.04400941796286472
ROC train: 0.998467	val: 0.785506	test: 0.785942
PRC train: 0.977444	val: 0.342067	test: 0.206511

Epoch: 109
Loss: 0.040782349756969746
ROC train: 0.998532	val: 0.795004	test: 0.757989
PRC train: 0.976325	val: 0.356682	test: 0.171050

Epoch: 110
Loss: 0.04126859392860323
ROC train: 0.999049	val: 0.798213	test: 0.779606
PRC train: 0.983348	val: 0.318540	test: 0.171464

Epoch: 111
Loss: 0.042039044910214506
ROC train: 0.997368	val: 0.788060	test: 0.767958
PRC train: 0.963235	val: 0.306466	test: 0.148878

Epoch: 112
Loss: 0.039849226161822134
ROC train: 0.998418	val: 0.800549	test: 0.787508
PRC train: 0.973504	val: 0.312001	test: 0.204639

Epoch: 113
Loss: 0.039224978758640956
ROC train: 0.999042	val: 0.800277	test: 0.770531
PRC train: 0.983400	val: 0.313709	test: 0.185003

Epoch: 114
Loss: 0.038400321230788334
ROC train: 0.998581	val: 0.798069	test: 0.736739
PRC train: 0.975142	val: 0.261913	test: 0.109279

Epoch: 115
Loss: 0.041957687697898344
ROC train: 0.998917	val: 0.792101	test: 0.764710
PRC train: 0.981143	val: 0.335773	test: 0.198915

Epoch: 116
Loss: 0.03862620404050173
ROC train: 0.998990	val: 0.801955	test: 0.753580
PRC train: 0.984337	val: 0.322405	test: 0.168899

Epoch: 117
Loss: 0.04078780359622794
ROC train: 0.999136	val: 0.799554	test: 0.755501
PRC train: 0.984456	val: 0.342342	test: 0.183989

Epoch: 118
Loss: 0.03789954875384972
ROC train: 0.998890	val: 0.796783	test: 0.765621
PRC train: 0.983290	val: 0.345933	test: 0.200801

Epoch: 119
Loss: 0.03723897712580659
ROC train: 0.999305	val: 0.810868	test: 0.771077
PRC train: 0.988478	val: 0.332636	test: 0.202683

Epoch: 120
Loss: 0.0386550053602543
ROC train: 0.999335	val: 0.794778	test: 0.743968
PRC train: 0.988196	val: 0.315640	test: 0.132136

Early stopping
Best (ROC):	 train: 0.917902	val: 0.817659	test: 0.749072
Best (PRC):	 train: 0.577725	val: 0.375019	test: 0.168796

PRC train: 0.920753	val: 0.341969	test: 0.194930

Epoch: 94
Loss: 0.05480810717979571
ROC train: 0.994671	val: 0.818312	test: 0.768408
PRC train: 0.931010	val: 0.343539	test: 0.196692

Epoch: 95
Loss: 0.0549685522088186
ROC train: 0.992335	val: 0.796811	test: 0.776319
PRC train: 0.904888	val: 0.349950	test: 0.212653

Epoch: 96
Loss: 0.05588235696028167
ROC train: 0.994444	val: 0.797239	test: 0.765040
PRC train: 0.929608	val: 0.340748	test: 0.192806

Epoch: 97
Loss: 0.05494884266806296
ROC train: 0.993584	val: 0.793354	test: 0.762222
PRC train: 0.921371	val: 0.328778	test: 0.167973

Epoch: 98
Loss: 0.05419101506449495
ROC train: 0.994917	val: 0.789447	test: 0.780330
PRC train: 0.933665	val: 0.359843	test: 0.187091

Epoch: 99
Loss: 0.05609701471089852
ROC train: 0.994607	val: 0.803330	test: 0.742811
PRC train: 0.928791	val: 0.373931	test: 0.183294

Epoch: 100
Loss: 0.053019854704831185
ROC train: 0.994154	val: 0.787172	test: 0.747521
PRC train: 0.919650	val: 0.320793	test: 0.227220

Epoch: 101
Loss: 0.054786889305204096
ROC train: 0.994846	val: 0.797181	test: 0.764302
PRC train: 0.931279	val: 0.337734	test: 0.218123

Epoch: 102
Loss: 0.051655912720037576
ROC train: 0.994241	val: 0.782778	test: 0.748850
PRC train: 0.927667	val: 0.291112	test: 0.145903

Epoch: 103
Loss: 0.05256160962861131
ROC train: 0.996071	val: 0.803544	test: 0.758081
PRC train: 0.944976	val: 0.315695	test: 0.156425

Epoch: 104
Loss: 0.049010012065792107
ROC train: 0.995422	val: 0.811033	test: 0.750455
PRC train: 0.939787	val: 0.327228	test: 0.187710

Epoch: 105
Loss: 0.051472988043967535
ROC train: 0.996056	val: 0.802873	test: 0.758587
PRC train: 0.943880	val: 0.359253	test: 0.212079

Epoch: 106
Loss: 0.05044924959257465
ROC train: 0.995029	val: 0.813388	test: 0.766535
PRC train: 0.931969	val: 0.345169	test: 0.188877

Epoch: 107
Loss: 0.05169011541752881
ROC train: 0.996174	val: 0.804946	test: 0.784472
PRC train: 0.945041	val: 0.381161	test: 0.254086

Epoch: 108
Loss: 0.04718736344747842
ROC train: 0.996954	val: 0.782799	test: 0.757404
PRC train: 0.955194	val: 0.305632	test: 0.156596

Epoch: 109
Loss: 0.04942498656887177
ROC train: 0.996298	val: 0.806796	test: 0.754319
PRC train: 0.951018	val: 0.370255	test: 0.203184

Epoch: 110
Loss: 0.04855854400095083
ROC train: 0.997420	val: 0.777870	test: 0.767649
PRC train: 0.958610	val: 0.377055	test: 0.232347

Epoch: 111
Loss: 0.047880854488383987
ROC train: 0.997276	val: 0.780289	test: 0.770428
PRC train: 0.955128	val: 0.360512	test: 0.220091

Epoch: 112
Loss: 0.04705798770976006
ROC train: 0.996965	val: 0.801437	test: 0.762280
PRC train: 0.950606	val: 0.345514	test: 0.199913

Epoch: 113
Loss: 0.04652798263619205
ROC train: 0.996178	val: 0.806860	test: 0.766276
PRC train: 0.942557	val: 0.330256	test: 0.178897

Epoch: 114
Loss: 0.04674709836880343
ROC train: 0.995909	val: 0.812531	test: 0.787659
PRC train: 0.939823	val: 0.386425	test: 0.226722

Epoch: 115
Loss: 0.04616700303323827
ROC train: 0.996726	val: 0.811594	test: 0.777699
PRC train: 0.950545	val: 0.361075	test: 0.220770

Epoch: 116
Loss: 0.0486633222839099
ROC train: 0.997717	val: 0.826199	test: 0.759611
PRC train: 0.966232	val: 0.322733	test: 0.199989

Epoch: 117
Loss: 0.04627709480332156
ROC train: 0.997777	val: 0.818379	test: 0.764656
PRC train: 0.961914	val: 0.352814	test: 0.189650

Epoch: 118
Loss: 0.042574854957760463
ROC train: 0.991566	val: 0.783433	test: 0.773082
PRC train: 0.944987	val: 0.326545	test: 0.213793

Epoch: 119
Loss: 0.04618952595166623
ROC train: 0.997971	val: 0.799441	test: 0.774725
PRC train: 0.964497	val: 0.353460	test: 0.220824

Epoch: 120
Loss: 0.043550253422111454
ROC train: 0.997697	val: 0.803908	test: 0.763647
PRC train: 0.960721	val: 0.376302	test: 0.179391

Early stopping
Best (ROC):	 train: 0.833642	val: 0.834154	test: 0.726267
Best (PRC):	 train: 0.396190	val: 0.355566	test: 0.190893

PRC train: 0.955791	val: 0.319876	test: 0.110844

Epoch: 94
Loss: 0.04789333406132368
ROC train: 0.997001	val: 0.761905	test: 0.727737
PRC train: 0.958303	val: 0.303961	test: 0.145099

Epoch: 95
Loss: 0.04833924447600586
ROC train: 0.995988	val: 0.780812	test: 0.732202
PRC train: 0.949108	val: 0.337879	test: 0.147341

Epoch: 96
Loss: 0.04803305016693919
ROC train: 0.997854	val: 0.781357	test: 0.755756
PRC train: 0.966309	val: 0.347558	test: 0.187408

Epoch: 97
Loss: 0.04783604362321564
ROC train: 0.996912	val: 0.736855	test: 0.731721
PRC train: 0.955691	val: 0.322215	test: 0.143342

Epoch: 98
Loss: 0.04710626155558771
ROC train: 0.997853	val: 0.748931	test: 0.727753
PRC train: 0.968496	val: 0.306277	test: 0.154468

Epoch: 99
Loss: 0.04804085955648479
ROC train: 0.996765	val: 0.773001	test: 0.726134
PRC train: 0.957511	val: 0.306395	test: 0.193874

Epoch: 100
Loss: 0.04420604595914279
ROC train: 0.997829	val: 0.752002	test: 0.730628
PRC train: 0.971793	val: 0.343180	test: 0.176792

Epoch: 101
Loss: 0.047082969418406485
ROC train: 0.998181	val: 0.771452	test: 0.740659
PRC train: 0.968814	val: 0.314453	test: 0.162209

Epoch: 102
Loss: 0.04584526948424706
ROC train: 0.998525	val: 0.761553	test: 0.718289
PRC train: 0.977364	val: 0.294225	test: 0.134502

Epoch: 103
Loss: 0.043543505388714855
ROC train: 0.997457	val: 0.764455	test: 0.743941
PRC train: 0.963716	val: 0.339790	test: 0.171910

Epoch: 104
Loss: 0.04496882372584251
ROC train: 0.997948	val: 0.765356	test: 0.730043
PRC train: 0.965288	val: 0.302110	test: 0.167034

Epoch: 105
Loss: 0.04490887354852668
ROC train: 0.998580	val: 0.780680	test: 0.728761
PRC train: 0.976676	val: 0.359178	test: 0.133446

Epoch: 106
Loss: 0.04276698359046701
ROC train: 0.997665	val: 0.755487	test: 0.726406
PRC train: 0.961285	val: 0.327244	test: 0.153166

Epoch: 107
Loss: 0.04413990891579267
ROC train: 0.998636	val: 0.770671	test: 0.737583
PRC train: 0.978293	val: 0.345687	test: 0.145910

Epoch: 108
Loss: 0.04390741569344401
ROC train: 0.998743	val: 0.771455	test: 0.732560
PRC train: 0.978151	val: 0.300287	test: 0.140818

Epoch: 109
Loss: 0.0430060977225519
ROC train: 0.998537	val: 0.767202	test: 0.742110
PRC train: 0.976271	val: 0.332073	test: 0.152826

Epoch: 110
Loss: 0.039172414492771396
ROC train: 0.998992	val: 0.769826	test: 0.703322
PRC train: 0.982782	val: 0.329693	test: 0.131182

Epoch: 111
Loss: 0.040361658401727174
ROC train: 0.998463	val: 0.765444	test: 0.750528
PRC train: 0.980143	val: 0.362608	test: 0.195186

Epoch: 112
Loss: 0.04264681304659868
ROC train: 0.998883	val: 0.780475	test: 0.739446
PRC train: 0.980771	val: 0.348185	test: 0.143794

Epoch: 113
Loss: 0.04039062306845481
ROC train: 0.998556	val: 0.779854	test: 0.723861
PRC train: 0.974762	val: 0.311070	test: 0.143986

Epoch: 114
Loss: 0.040751545672254634
ROC train: 0.998843	val: 0.780641	test: 0.752537
PRC train: 0.979819	val: 0.325553	test: 0.182187

Epoch: 115
Loss: 0.03861036187729363
ROC train: 0.999063	val: 0.774520	test: 0.734929
PRC train: 0.983627	val: 0.322073	test: 0.168690

Epoch: 116
Loss: 0.04022172063773164
ROC train: 0.998604	val: 0.758350	test: 0.736495
PRC train: 0.976425	val: 0.365187	test: 0.180303

Epoch: 117
Loss: 0.03846493069166902
ROC train: 0.999317	val: 0.785644	test: 0.744197
PRC train: 0.988606	val: 0.307945	test: 0.151389

Epoch: 118
Loss: 0.03919698333019067
ROC train: 0.998892	val: 0.765594	test: 0.709056
PRC train: 0.983994	val: 0.343525	test: 0.136841

Epoch: 119
Loss: 0.03762363400677718
ROC train: 0.999249	val: 0.751491	test: 0.727247
PRC train: 0.987173	val: 0.306243	test: 0.151838

Epoch: 120
Loss: 0.03384618306518803
ROC train: 0.999523	val: 0.764737	test: 0.715923
PRC train: 0.990898	val: 0.331428	test: 0.172894

Early stopping
Best (ROC):	 train: 0.925438	val: 0.812647	test: 0.731743
Best (PRC):	 train: 0.611908	val: 0.368542	test: 0.217802

PRC train: 0.957973	val: 0.346381	test: 0.185515

Epoch: 94
Loss: 0.05150925130464478
ROC train: 0.996377	val: 0.799750	test: 0.738896
PRC train: 0.950278	val: 0.329026	test: 0.168323

Epoch: 95
Loss: 0.04853124067254633
ROC train: 0.996473	val: 0.787934	test: 0.738280
PRC train: 0.949688	val: 0.344563	test: 0.172945

Epoch: 96
Loss: 0.05000128416274479
ROC train: 0.995071	val: 0.805066	test: 0.746878
PRC train: 0.933283	val: 0.337085	test: 0.188500

Epoch: 97
Loss: 0.047958654308001475
ROC train: 0.996722	val: 0.791905	test: 0.759057
PRC train: 0.960540	val: 0.321437	test: 0.182236

Epoch: 98
Loss: 0.046129814304068074
ROC train: 0.997344	val: 0.784327	test: 0.750534
PRC train: 0.960937	val: 0.354347	test: 0.190038

Epoch: 99
Loss: 0.04750190531487943
ROC train: 0.997533	val: 0.805096	test: 0.745980
PRC train: 0.964569	val: 0.340931	test: 0.185563

Epoch: 100
Loss: 0.047347361998522165
ROC train: 0.997611	val: 0.785240	test: 0.739441
PRC train: 0.963589	val: 0.269415	test: 0.156556

Epoch: 101
Loss: 0.04741901385785231
ROC train: 0.998209	val: 0.785362	test: 0.711999
PRC train: 0.974388	val: 0.298212	test: 0.150196

Epoch: 102
Loss: 0.04487885751806562
ROC train: 0.997158	val: 0.796492	test: 0.744298
PRC train: 0.955667	val: 0.365961	test: 0.183081

Epoch: 103
Loss: 0.045781617714286515
ROC train: 0.997743	val: 0.767719	test: 0.734479
PRC train: 0.970377	val: 0.316644	test: 0.182425

Epoch: 104
Loss: 0.046596433128090746
ROC train: 0.996602	val: 0.772735	test: 0.749321
PRC train: 0.952160	val: 0.278095	test: 0.151755

Epoch: 105
Loss: 0.04480196550892615
ROC train: 0.998243	val: 0.793308	test: 0.741857
PRC train: 0.972689	val: 0.341852	test: 0.212009

Epoch: 106
Loss: 0.04380603702480565
ROC train: 0.997425	val: 0.771574	test: 0.726735
PRC train: 0.960909	val: 0.311710	test: 0.144110

Epoch: 107
Loss: 0.04192776684093015
ROC train: 0.998622	val: 0.781115	test: 0.725201
PRC train: 0.979512	val: 0.296974	test: 0.124898

Epoch: 108
Loss: 0.041942072708525804
ROC train: 0.996070	val: 0.785341	test: 0.735066
PRC train: 0.951096	val: 0.307446	test: 0.175586

Epoch: 109
Loss: 0.04352831084913197
ROC train: 0.998184	val: 0.778353	test: 0.728610
PRC train: 0.969676	val: 0.363054	test: 0.206622

Epoch: 110
Loss: 0.04182706211980131
ROC train: 0.998696	val: 0.779903	test: 0.733604
PRC train: 0.976812	val: 0.305830	test: 0.148152

Epoch: 111
Loss: 0.042242061984113496
ROC train: 0.998076	val: 0.783375	test: 0.731283
PRC train: 0.971560	val: 0.302324	test: 0.197414

Epoch: 112
Loss: 0.040569467216390986
ROC train: 0.998887	val: 0.802518	test: 0.740381
PRC train: 0.981244	val: 0.333399	test: 0.166878

Epoch: 113
Loss: 0.04034179450808993
ROC train: 0.997894	val: 0.794309	test: 0.734180
PRC train: 0.968994	val: 0.273553	test: 0.159094

Epoch: 114
Loss: 0.043317234261814545
ROC train: 0.998703	val: 0.805148	test: 0.748303
PRC train: 0.979447	val: 0.345513	test: 0.196563

Epoch: 115
Loss: 0.04032826396454899
ROC train: 0.999056	val: 0.771112	test: 0.718160
PRC train: 0.984267	val: 0.283958	test: 0.124785

Epoch: 116
Loss: 0.03889733957738078
ROC train: 0.998806	val: 0.766198	test: 0.754810
PRC train: 0.975536	val: 0.291884	test: 0.172494

Epoch: 117
Loss: 0.038881701039991765
ROC train: 0.998468	val: 0.782169	test: 0.734346
PRC train: 0.978498	val: 0.358638	test: 0.169370

Epoch: 118
Loss: 0.03999317995122253
ROC train: 0.998615	val: 0.784104	test: 0.732612
PRC train: 0.977750	val: 0.315156	test: 0.169985

Epoch: 119
Loss: 0.03939850089261556
ROC train: 0.998910	val: 0.771231	test: 0.748923
PRC train: 0.984327	val: 0.347511	test: 0.186869

Epoch: 120
Loss: 0.03857010582723684
ROC train: 0.999255	val: 0.762269	test: 0.720589
PRC train: 0.989793	val: 0.274746	test: 0.117731

Early stopping
Best (ROC):	 train: 0.977045	val: 0.834941	test: 0.761886
Best (PRC):	 train: 0.819600	val: 0.342445	test: 0.213388

PRC train: 0.899304	val: 0.287374	test: 0.141572

Epoch: 94
Loss: 0.05916486618749518
ROC train: 0.992649	val: 0.790506	test: 0.752272
PRC train: 0.914015	val: 0.322248	test: 0.195649

Epoch: 95
Loss: 0.05684608740358502
ROC train: 0.993974	val: 0.762425	test: 0.747546
PRC train: 0.927844	val: 0.326275	test: 0.196271

Epoch: 96
Loss: 0.05551211381873053
ROC train: 0.995170	val: 0.768016	test: 0.768564
PRC train: 0.941908	val: 0.309840	test: 0.198575

Epoch: 97
Loss: 0.0543768858193393
ROC train: 0.994045	val: 0.779695	test: 0.746451
PRC train: 0.930303	val: 0.327537	test: 0.177155

Epoch: 98
Loss: 0.05621446959580165
ROC train: 0.993793	val: 0.766274	test: 0.751554
PRC train: 0.928383	val: 0.263160	test: 0.158740

Epoch: 99
Loss: 0.0542142406134211
ROC train: 0.994379	val: 0.766023	test: 0.758972
PRC train: 0.928684	val: 0.293478	test: 0.196336

Epoch: 100
Loss: 0.05318963473176419
ROC train: 0.994989	val: 0.783448	test: 0.747709
PRC train: 0.935327	val: 0.299178	test: 0.190359

Epoch: 101
Loss: 0.05419104679063538
ROC train: 0.994223	val: 0.784575	test: 0.753276
PRC train: 0.923516	val: 0.313047	test: 0.218156

Epoch: 102
Loss: 0.05265726576095972
ROC train: 0.995107	val: 0.792135	test: 0.748274
PRC train: 0.933018	val: 0.362789	test: 0.204834

Epoch: 103
Loss: 0.05338984567357712
ROC train: 0.993891	val: 0.771433	test: 0.757265
PRC train: 0.927409	val: 0.294872	test: 0.197028

Epoch: 104
Loss: 0.052855281694471845
ROC train: 0.995851	val: 0.792879	test: 0.754820
PRC train: 0.944946	val: 0.341243	test: 0.247566

Epoch: 105
Loss: 0.053959233208330765
ROC train: 0.994925	val: 0.759192	test: 0.729000
PRC train: 0.928473	val: 0.320235	test: 0.153197

Epoch: 106
Loss: 0.0507691392234376
ROC train: 0.995686	val: 0.770065	test: 0.743827
PRC train: 0.939357	val: 0.337585	test: 0.187471

Epoch: 107
Loss: 0.05340860535133859
ROC train: 0.995237	val: 0.778868	test: 0.751283
PRC train: 0.941127	val: 0.311466	test: 0.202917

Epoch: 108
Loss: 0.051369311307828576
ROC train: 0.995833	val: 0.798835	test: 0.750005
PRC train: 0.942999	val: 0.338961	test: 0.205432

Epoch: 109
Loss: 0.05065261761079228
ROC train: 0.995810	val: 0.771734	test: 0.757315
PRC train: 0.944831	val: 0.310956	test: 0.180129

Epoch: 110
Loss: 0.04891037678625428
ROC train: 0.996831	val: 0.786523	test: 0.768991
PRC train: 0.950947	val: 0.302130	test: 0.189905

Epoch: 111
Loss: 0.04775392511561174
ROC train: 0.996862	val: 0.800868	test: 0.763383
PRC train: 0.956926	val: 0.317232	test: 0.163607

Epoch: 112
Loss: 0.050054016465582205
ROC train: 0.997204	val: 0.778010	test: 0.768595
PRC train: 0.959787	val: 0.324465	test: 0.223652

Epoch: 113
Loss: 0.04867292043994681
ROC train: 0.996016	val: 0.755879	test: 0.745634
PRC train: 0.947679	val: 0.262905	test: 0.160583

Epoch: 114
Loss: 0.04998522573241703
ROC train: 0.997436	val: 0.754461	test: 0.749688
PRC train: 0.960960	val: 0.306514	test: 0.191937

Epoch: 115
Loss: 0.049838542606188405
ROC train: 0.996803	val: 0.755233	test: 0.740426
PRC train: 0.959749	val: 0.343829	test: 0.162036

Epoch: 116
Loss: 0.04661899292472443
ROC train: 0.998061	val: 0.775690	test: 0.752506
PRC train: 0.969363	val: 0.317749	test: 0.200036

Epoch: 117
Loss: 0.04613690653075556
ROC train: 0.998262	val: 0.776630	test: 0.748585
PRC train: 0.972273	val: 0.325940	test: 0.185822

Epoch: 118
Loss: 0.046941820330193576
ROC train: 0.997571	val: 0.788109	test: 0.759439
PRC train: 0.964545	val: 0.348945	test: 0.238538

Epoch: 119
Loss: 0.04771695829111287
ROC train: 0.997291	val: 0.775515	test: 0.741592
PRC train: 0.959895	val: 0.300582	test: 0.154877

Epoch: 120
Loss: 0.04844626231499733
ROC train: 0.998022	val: 0.788874	test: 0.766819
PRC train: 0.970951	val: 0.313913	test: 0.186548

Early stopping
Best (ROC):	 train: 0.858329	val: 0.833091	test: 0.743973
Best (PRC):	 train: 0.442505	val: 0.338454	test: 0.183109
All runs completed.

PRC train: 0.911019	val: 0.326581	test: 0.167306

Epoch: 94
Loss: 0.05647420265472237
ROC train: 0.993119	val: 0.786103	test: 0.736754
PRC train: 0.917074	val: 0.336884	test: 0.151799

Epoch: 95
Loss: 0.05448538178301435
ROC train: 0.992761	val: 0.799876	test: 0.765664
PRC train: 0.916288	val: 0.353206	test: 0.175104

Epoch: 96
Loss: 0.054504435934770536
ROC train: 0.993556	val: 0.786562	test: 0.744906
PRC train: 0.916932	val: 0.323023	test: 0.169346

Epoch: 97
Loss: 0.053409774069454984
ROC train: 0.994050	val: 0.800941	test: 0.745534
PRC train: 0.928447	val: 0.398877	test: 0.164456

Epoch: 98
Loss: 0.054337916566756045
ROC train: 0.993369	val: 0.815831	test: 0.749228
PRC train: 0.915607	val: 0.378925	test: 0.139521

Epoch: 99
Loss: 0.05432114541835834
ROC train: 0.991853	val: 0.776486	test: 0.769688
PRC train: 0.915676	val: 0.355984	test: 0.212140

Epoch: 100
Loss: 0.05141504813926818
ROC train: 0.995203	val: 0.795711	test: 0.727662
PRC train: 0.934730	val: 0.330449	test: 0.125620

Epoch: 101
Loss: 0.05330815589295493
ROC train: 0.994087	val: 0.782622	test: 0.709120
PRC train: 0.925529	val: 0.288482	test: 0.110049

Epoch: 102
Loss: 0.05277522045335574
ROC train: 0.996307	val: 0.792570	test: 0.752937
PRC train: 0.948722	val: 0.353538	test: 0.149866

Epoch: 103
Loss: 0.05412493133758836
ROC train: 0.994540	val: 0.810185	test: 0.747838
PRC train: 0.932383	val: 0.333992	test: 0.142134

Epoch: 104
Loss: 0.04999952992876278
ROC train: 0.994718	val: 0.787098	test: 0.740663
PRC train: 0.930423	val: 0.337518	test: 0.178394

Epoch: 105
Loss: 0.05225458607285939
ROC train: 0.995322	val: 0.798421	test: 0.747485
PRC train: 0.939092	val: 0.327936	test: 0.181552

Epoch: 106
Loss: 0.05168537617198
ROC train: 0.994540	val: 0.794162	test: 0.749454
PRC train: 0.933469	val: 0.342916	test: 0.168375

Epoch: 107
Loss: 0.04945795437496461
ROC train: 0.997149	val: 0.801998	test: 0.741525
PRC train: 0.958055	val: 0.402465	test: 0.156950

Epoch: 108
Loss: 0.0496862285217565
ROC train: 0.993482	val: 0.801532	test: 0.751809
PRC train: 0.917599	val: 0.363474	test: 0.128143

Epoch: 109
Loss: 0.05033038199113067
ROC train: 0.997031	val: 0.804208	test: 0.747206
PRC train: 0.956954	val: 0.335357	test: 0.173262

Epoch: 110
Loss: 0.04961500533707277
ROC train: 0.996781	val: 0.806404	test: 0.749159
PRC train: 0.956964	val: 0.365463	test: 0.142124

Epoch: 111
Loss: 0.04649719392378259
ROC train: 0.996342	val: 0.774361	test: 0.737235
PRC train: 0.949837	val: 0.318153	test: 0.143682

Epoch: 112
Loss: 0.049375332059077785
ROC train: 0.996833	val: 0.818134	test: 0.742459
PRC train: 0.955253	val: 0.362405	test: 0.127185

Epoch: 113
Loss: 0.04624276626301006
ROC train: 0.997189	val: 0.802720	test: 0.751973
PRC train: 0.956293	val: 0.369302	test: 0.164222

Epoch: 114
Loss: 0.04521937911719552
ROC train: 0.996764	val: 0.810727	test: 0.757601
PRC train: 0.952735	val: 0.367087	test: 0.143193

Epoch: 115
Loss: 0.046905832788377205
ROC train: 0.997926	val: 0.792285	test: 0.737807
PRC train: 0.970697	val: 0.336285	test: 0.127527

Epoch: 116
Loss: 0.047381082471901245
ROC train: 0.996738	val: 0.806786	test: 0.750426
PRC train: 0.954498	val: 0.362987	test: 0.158103

Epoch: 117
Loss: 0.04365684240702706
ROC train: 0.997662	val: 0.799401	test: 0.762460
PRC train: 0.964566	val: 0.352790	test: 0.158391

Epoch: 118
Loss: 0.04501022167945796
ROC train: 0.995869	val: 0.784780	test: 0.757064
PRC train: 0.948034	val: 0.384933	test: 0.167184

Epoch: 119
Loss: 0.04525164986517259
ROC train: 0.997978	val: 0.801578	test: 0.756027
PRC train: 0.967010	val: 0.345681	test: 0.162887

Epoch: 120
Loss: 0.04426203181659818
ROC train: 0.997476	val: 0.801976	test: 0.746998
PRC train: 0.959585	val: 0.307352	test: 0.113502

Early stopping
Best (ROC):	 train: 0.862201	val: 0.823851	test: 0.742542
Best (PRC):	 train: 0.456677	val: 0.352636	test: 0.181850
All runs completed.

PRC train: 0.961465	val: 0.280265	test: 0.139809

Epoch: 94
Loss: 0.04315133346797598
ROC train: 0.997984	val: 0.788317	test: 0.759841
PRC train: 0.970884	val: 0.308979	test: 0.189277

Epoch: 95
Loss: 0.047684716499368604
ROC train: 0.998039	val: 0.820394	test: 0.741623
PRC train: 0.972313	val: 0.275854	test: 0.112138

Epoch: 96
Loss: 0.04654067642889487
ROC train: 0.998197	val: 0.785080	test: 0.741532
PRC train: 0.971243	val: 0.267230	test: 0.146168

Epoch: 97
Loss: 0.04529982820906342
ROC train: 0.997906	val: 0.780723	test: 0.736233
PRC train: 0.973163	val: 0.263027	test: 0.136687

Epoch: 98
Loss: 0.043442367459217014
ROC train: 0.998567	val: 0.798538	test: 0.740642
PRC train: 0.978715	val: 0.297005	test: 0.145766

Epoch: 99
Loss: 0.04202554873290009
ROC train: 0.997049	val: 0.766501	test: 0.763491
PRC train: 0.962662	val: 0.310017	test: 0.172968

Epoch: 100
Loss: 0.04577608816431284
ROC train: 0.998537	val: 0.797631	test: 0.740665
PRC train: 0.978969	val: 0.220800	test: 0.111355

Epoch: 101
Loss: 0.04420829911520816
ROC train: 0.998844	val: 0.774933	test: 0.722208
PRC train: 0.980947	val: 0.193591	test: 0.112448

Epoch: 102
Loss: 0.03877527341245055
ROC train: 0.999064	val: 0.801373	test: 0.712994
PRC train: 0.985209	val: 0.249256	test: 0.095750

Epoch: 103
Loss: 0.040442664442791286
ROC train: 0.999066	val: 0.796379	test: 0.752720
PRC train: 0.983854	val: 0.274087	test: 0.134533

Epoch: 104
Loss: 0.039541112575984506
ROC train: 0.999265	val: 0.792852	test: 0.752801
PRC train: 0.987448	val: 0.286196	test: 0.159742

Epoch: 105
Loss: 0.040291648418502565
ROC train: 0.999300	val: 0.781268	test: 0.747019
PRC train: 0.988644	val: 0.251398	test: 0.133762

Epoch: 106
Loss: 0.039685075897048616
ROC train: 0.998936	val: 0.810513	test: 0.748247
PRC train: 0.983745	val: 0.296592	test: 0.147103

Epoch: 107
Loss: 0.04052279909985904
ROC train: 0.999193	val: 0.802319	test: 0.750750
PRC train: 0.987791	val: 0.270250	test: 0.136488

Epoch: 108
Loss: 0.03978699705893148
ROC train: 0.999508	val: 0.785573	test: 0.746816
PRC train: 0.991296	val: 0.238353	test: 0.134787

Epoch: 109
Loss: 0.03795266608502197
ROC train: 0.999438	val: 0.770665	test: 0.755090
PRC train: 0.990336	val: 0.229052	test: 0.140074

Epoch: 110
Loss: 0.03694074701580135
ROC train: 0.999594	val: 0.814019	test: 0.758752
PRC train: 0.992719	val: 0.278243	test: 0.137918

Epoch: 111
Loss: 0.03801572252902519
ROC train: 0.999303	val: 0.784208	test: 0.729535
PRC train: 0.988792	val: 0.311347	test: 0.110482

Epoch: 112
Loss: 0.035834223556427125
ROC train: 0.999655	val: 0.814261	test: 0.748332
PRC train: 0.993529	val: 0.273717	test: 0.117903

Epoch: 113
Loss: 0.037888150052230056
ROC train: 0.999036	val: 0.817779	test: 0.754383
PRC train: 0.984205	val: 0.318253	test: 0.176460

Epoch: 114
Loss: 0.038132700287752175
ROC train: 0.999473	val: 0.821024	test: 0.747459
PRC train: 0.992054	val: 0.291965	test: 0.142990

Epoch: 115
Loss: 0.03805877151500287
ROC train: 0.999268	val: 0.777025	test: 0.734462
PRC train: 0.987638	val: 0.260449	test: 0.122451

Epoch: 116
Loss: 0.035237245525518185
ROC train: 0.999443	val: 0.803259	test: 0.741567
PRC train: 0.990571	val: 0.300969	test: 0.142157

Epoch: 117
Loss: 0.03381276830582731
ROC train: 0.999517	val: 0.813305	test: 0.768161
PRC train: 0.990745	val: 0.258451	test: 0.161424

Epoch: 118
Loss: 0.03675891045605874
ROC train: 0.999381	val: 0.806431	test: 0.768311
PRC train: 0.989267	val: 0.291871	test: 0.180393

Epoch: 119
Loss: 0.03248236633840833
ROC train: 0.999577	val: 0.791575	test: 0.741239
PRC train: 0.991934	val: 0.307478	test: 0.124193

Epoch: 120
Loss: 0.03405556158443804
ROC train: 0.999723	val: 0.793519	test: 0.762931
PRC train: 0.994905	val: 0.251659	test: 0.130232

Early stopping
Best (ROC):	 train: 0.986839	val: 0.833670	test: 0.724844
Best (PRC):	 train: 0.874638	val: 0.322294	test: 0.129872

PRC train: 0.985663	val: 0.269402	test: 0.185900

Epoch: 94
Loss: 0.04064944176648474
ROC train: 0.998857	val: 0.771681	test: 0.735640
PRC train: 0.984669	val: 0.280878	test: 0.214030

Epoch: 95
Loss: 0.03940675333681333
ROC train: 0.998482	val: 0.758316	test: 0.718896
PRC train: 0.979978	val: 0.241623	test: 0.189600

Epoch: 96
Loss: 0.0399301527214088
ROC train: 0.999185	val: 0.762646	test: 0.723013
PRC train: 0.989148	val: 0.227592	test: 0.178508

Epoch: 97
Loss: 0.04119125499958095
ROC train: 0.999324	val: 0.718542	test: 0.712594
PRC train: 0.987416	val: 0.194152	test: 0.123186

Epoch: 98
Loss: 0.04033600068963665
ROC train: 0.999271	val: 0.751880	test: 0.725505
PRC train: 0.989034	val: 0.218648	test: 0.175818

Epoch: 99
Loss: 0.039677598504084935
ROC train: 0.998783	val: 0.757964	test: 0.741847
PRC train: 0.983914	val: 0.197138	test: 0.146127

Epoch: 100
Loss: 0.03677648854365999
ROC train: 0.999470	val: 0.722519	test: 0.724406
PRC train: 0.991097	val: 0.221278	test: 0.159994

Epoch: 101
Loss: 0.038798742551462886
ROC train: 0.999458	val: 0.741062	test: 0.734106
PRC train: 0.992643	val: 0.212000	test: 0.136035

Epoch: 102
Loss: 0.0366388608048452
ROC train: 0.999573	val: 0.742538	test: 0.698725
PRC train: 0.994346	val: 0.250811	test: 0.190040

Epoch: 103
Loss: 0.03666322987257341
ROC train: 0.998913	val: 0.710651	test: 0.716165
PRC train: 0.986623	val: 0.205222	test: 0.167204

Epoch: 104
Loss: 0.03534524337621261
ROC train: 0.999383	val: 0.750187	test: 0.709884
PRC train: 0.989275	val: 0.241537	test: 0.148133

Epoch: 105
Loss: 0.03654927244311341
ROC train: 0.999628	val: 0.763123	test: 0.717812
PRC train: 0.992319	val: 0.212823	test: 0.163300

Epoch: 106
Loss: 0.03593259675241341
ROC train: 0.999639	val: 0.729445	test: 0.715715
PRC train: 0.993562	val: 0.197040	test: 0.139140

Epoch: 107
Loss: 0.0390241355939792
ROC train: 0.999595	val: 0.760677	test: 0.720900
PRC train: 0.992328	val: 0.254869	test: 0.162989

Epoch: 108
Loss: 0.03436007841112211
ROC train: 0.999719	val: 0.769817	test: 0.730632
PRC train: 0.994464	val: 0.231121	test: 0.232466

Epoch: 109
Loss: 0.03503591191697379
ROC train: 0.999788	val: 0.756305	test: 0.712094
PRC train: 0.996138	val: 0.210559	test: 0.163813

Epoch: 110
Loss: 0.034829885088962544
ROC train: 0.999703	val: 0.753475	test: 0.726783
PRC train: 0.995465	val: 0.232761	test: 0.138875

Epoch: 111
Loss: 0.03298051304989191
ROC train: 0.999703	val: 0.756660	test: 0.700116
PRC train: 0.994735	val: 0.211934	test: 0.169927

Epoch: 112
Loss: 0.034496142442103646
ROC train: 0.999538	val: 0.758837	test: 0.712412
PRC train: 0.994007	val: 0.171785	test: 0.107394

Epoch: 113
Loss: 0.031064869952778375
ROC train: 0.999863	val: 0.758160	test: 0.722528
PRC train: 0.997464	val: 0.205108	test: 0.159634

Epoch: 114
Loss: 0.03123696792941985
ROC train: 0.999707	val: 0.721151	test: 0.746094
PRC train: 0.994573	val: 0.210881	test: 0.207399

Epoch: 115
Loss: 0.03154031751654798
ROC train: 0.999638	val: 0.745220	test: 0.737871
PRC train: 0.991897	val: 0.213469	test: 0.158033

Epoch: 116
Loss: 0.03308813915117675
ROC train: 0.999865	val: 0.744761	test: 0.729678
PRC train: 0.997380	val: 0.197520	test: 0.165011

Epoch: 117
Loss: 0.03321386786499941
ROC train: 0.999799	val: 0.765478	test: 0.716412
PRC train: 0.996069	val: 0.253233	test: 0.172206

Epoch: 118
Loss: 0.03227494116684586
ROC train: 0.999832	val: 0.740551	test: 0.728720
PRC train: 0.996816	val: 0.241272	test: 0.192468

Epoch: 119
Loss: 0.03179548229348346
ROC train: 0.999836	val: 0.772171	test: 0.739553
PRC train: 0.996573	val: 0.281481	test: 0.188688

Epoch: 120
Loss: 0.030507499126292935
ROC train: 0.999691	val: 0.729601	test: 0.710958
PRC train: 0.994452	val: 0.291737	test: 0.215559

Early stopping
Best (ROC):	 train: 0.944033	val: 0.819239	test: 0.711665
Best (PRC):	 train: 0.628304	val: 0.255997	test: 0.197041

ROC train: 0.975418	val: 0.792533	test: 0.757713
PRC train: 0.757522	val: 0.288377	test: 0.169205

Epoch: 95
Loss: 0.07582828078413624
ROC train: 0.976341	val: 0.828345	test: 0.763352
PRC train: 0.759764	val: 0.284081	test: 0.160600

Epoch: 96
Loss: 0.0749252853986529
ROC train: 0.978975	val: 0.789863	test: 0.751994
PRC train: 0.778269	val: 0.290858	test: 0.154586

Epoch: 97
Loss: 0.07536148753677092
ROC train: 0.976672	val: 0.802530	test: 0.749901
PRC train: 0.767917	val: 0.301902	test: 0.160544

Epoch: 98
Loss: 0.07556199029230329
ROC train: 0.977891	val: 0.813174	test: 0.736880
PRC train: 0.772604	val: 0.277712	test: 0.147845

Epoch: 99
Loss: 0.07506552349004862
ROC train: 0.981211	val: 0.791327	test: 0.757361
PRC train: 0.785642	val: 0.300886	test: 0.169416

Epoch: 100
Loss: 0.07395531363502737
ROC train: 0.980301	val: 0.779783	test: 0.755468
PRC train: 0.790282	val: 0.286712	test: 0.170229

Epoch: 101
Loss: 0.07552959650818866
ROC train: 0.979552	val: 0.806045	test: 0.777236
PRC train: 0.784792	val: 0.279744	test: 0.191411

Epoch: 102
Loss: 0.07280708355725478
ROC train: 0.982294	val: 0.811012	test: 0.776226
PRC train: 0.797471	val: 0.294714	test: 0.206118

Epoch: 103
Loss: 0.07166238172100473
ROC train: 0.981519	val: 0.791321	test: 0.754244
PRC train: 0.791500	val: 0.284592	test: 0.187733

Epoch: 104
Loss: 0.07276723222020966
ROC train: 0.982303	val: 0.791569	test: 0.752564
PRC train: 0.801401	val: 0.285687	test: 0.176503

Epoch: 105
Loss: 0.07411808865491146
ROC train: 0.979729	val: 0.827981	test: 0.767411
PRC train: 0.788740	val: 0.311546	test: 0.195292

Epoch: 106
Loss: 0.07210212657303328
ROC train: 0.979193	val: 0.800445	test: 0.768578
PRC train: 0.783515	val: 0.320831	test: 0.176183

Epoch: 107
Loss: 0.07394330851561226
ROC train: 0.980517	val: 0.797203	test: 0.754557
PRC train: 0.789168	val: 0.283870	test: 0.140719

Epoch: 108
Loss: 0.07313090189998217
ROC train: 0.978927	val: 0.823557	test: 0.779588
PRC train: 0.783193	val: 0.316483	test: 0.210575

Epoch: 109
Loss: 0.0714247467885156
ROC train: 0.982348	val: 0.808795	test: 0.765751
PRC train: 0.802121	val: 0.308632	test: 0.193287

Epoch: 110
Loss: 0.07203648288637478
ROC train: 0.980925	val: 0.822485	test: 0.764785
PRC train: 0.789360	val: 0.315443	test: 0.143638

Epoch: 111
Loss: 0.0701474907333397
ROC train: 0.982937	val: 0.795283	test: 0.764194
PRC train: 0.805422	val: 0.310722	test: 0.206128

Epoch: 112
Loss: 0.0728888639978947
ROC train: 0.984678	val: 0.798522	test: 0.761417
PRC train: 0.812582	val: 0.311858	test: 0.190128

Epoch: 113
Loss: 0.07048218025105643
ROC train: 0.984384	val: 0.799110	test: 0.765301
PRC train: 0.810017	val: 0.296300	test: 0.172820

Epoch: 114
Loss: 0.06982669365494462
ROC train: 0.984544	val: 0.788482	test: 0.751803
PRC train: 0.815726	val: 0.270353	test: 0.168203

Epoch: 115
Loss: 0.07034825808126902
ROC train: 0.983670	val: 0.797475	test: 0.777122
PRC train: 0.803616	val: 0.323416	test: 0.217694

Epoch: 116
Loss: 0.06881476013832634
ROC train: 0.981324	val: 0.807558	test: 0.762313
PRC train: 0.791397	val: 0.263774	test: 0.149465

Epoch: 117
Loss: 0.06980856412933407
ROC train: 0.985253	val: 0.807555	test: 0.753518
PRC train: 0.815683	val: 0.272577	test: 0.120936

Epoch: 118
Loss: 0.06862803518037362
ROC train: 0.986593	val: 0.802755	test: 0.767160
PRC train: 0.835609	val: 0.285957	test: 0.180084

Epoch: 119
Loss: 0.06901856544323458
ROC train: 0.985261	val: 0.799701	test: 0.766235
PRC train: 0.817968	val: 0.281547	test: 0.198363

Epoch: 120
Loss: 0.06851395549881299
ROC train: 0.983593	val: 0.774691	test: 0.759366
PRC train: 0.804361	val: 0.282028	test: 0.216147

Epoch: 121
Loss: 0.06683436319242743
ROC train: 0.986366	val: 0.790139	test: 0.773559
PRC train: 0.831943	val: 0.304882	test: 0.209741

Epoch: 122
Loss: 0.06774452899221205
ROC train: 0.986825	val: 0.810941	test: 0.773510
PRC train: 0.834403	val: 0.300104	test: 0.183347

Epoch: 123
Loss: 0.06767143668634015
ROC train: 0.987836	val: 0.808201	test: 0.776743
PRC train: 0.838726	val: 0.321022	test: 0.208628

Epoch: 124
Loss: 0.06790172048322844
ROC train: 0.987333	val: 0.812273	test: 0.774316
PRC train: 0.837043	val: 0.278871	test: 0.178324

Epoch: 125
Loss: 0.06620562198299955
ROC train: 0.984745	val: 0.816670	test: 0.758495
PRC train: 0.820608	val: 0.300502	test: 0.170593

Epoch: 126
Loss: 0.06694333950513824
ROC train: 0.986916	val: 0.806318	test: 0.767844
PRC train: 0.832973	val: 0.291178	test: 0.184811

Epoch: 127
Loss: 0.06704663882712052
ROC train: 0.986638	val: 0.798516	test: 0.769105
PRC train: 0.833199	val: 0.305984	test: 0.190286

Epoch: 128
Loss: 0.0663207442993761
ROC train: 0.987315	val: 0.797555	test: 0.754713
PRC train: 0.830512	val: 0.293271	test: 0.188973

Epoch: 129
Loss: 0.06733114307649796
ROC train: 0.986725	val: 0.806021	test: 0.784913
PRC train: 0.834492	val: 0.288373	test: 0.192993

Epoch: 130
Loss: 0.06583762164770696
ROC train: 0.987823	val: 0.808746	test: 0.773113
PRC train: 0.839950	val: 0.298164	test: 0.192487

Early stopping
Best (ROC):	 train: 0.976341	val: 0.828345	test: 0.763352
Best (PRC):	 train: 0.759764	val: 0.284081	test: 0.160600
All runs completed.

PRC train: 0.980363	val: 0.229899	test: 0.205008

Epoch: 94
Loss: 0.04412023997474444
ROC train: 0.998797	val: 0.774094	test: 0.701989
PRC train: 0.979441	val: 0.266708	test: 0.171094

Epoch: 95
Loss: 0.043284425842585336
ROC train: 0.998966	val: 0.799894	test: 0.720829
PRC train: 0.983733	val: 0.294290	test: 0.236371

Epoch: 96
Loss: 0.04102937705542991
ROC train: 0.998671	val: 0.819037	test: 0.715220
PRC train: 0.978781	val: 0.228297	test: 0.159968

Epoch: 97
Loss: 0.04196134839801623
ROC train: 0.999452	val: 0.778866	test: 0.710923
PRC train: 0.989659	val: 0.272283	test: 0.176383

Epoch: 98
Loss: 0.04124354264439132
ROC train: 0.999292	val: 0.785347	test: 0.729112
PRC train: 0.988388	val: 0.261883	test: 0.194766

Epoch: 99
Loss: 0.04182391069541231
ROC train: 0.999115	val: 0.802515	test: 0.719386
PRC train: 0.985400	val: 0.256232	test: 0.195116

Epoch: 100
Loss: 0.04292810180993401
ROC train: 0.998833	val: 0.811805	test: 0.720591
PRC train: 0.980773	val: 0.306002	test: 0.243722

Epoch: 101
Loss: 0.04007127092690359
ROC train: 0.999132	val: 0.796201	test: 0.724307
PRC train: 0.985855	val: 0.294803	test: 0.218450

Epoch: 102
Loss: 0.04234887318511697
ROC train: 0.999304	val: 0.783366	test: 0.705552
PRC train: 0.987441	val: 0.238537	test: 0.195369

Epoch: 103
Loss: 0.043887785644923155
ROC train: 0.999376	val: 0.794790	test: 0.714751
PRC train: 0.989669	val: 0.268934	test: 0.167339

Epoch: 104
Loss: 0.03863216317904122
ROC train: 0.999662	val: 0.769091	test: 0.704596
PRC train: 0.993037	val: 0.251817	test: 0.168246

Epoch: 105
Loss: 0.03464753616809192
ROC train: 0.998315	val: 0.768491	test: 0.717499
PRC train: 0.970947	val: 0.186026	test: 0.102424

Epoch: 106
Loss: 0.040812200754504147
ROC train: 0.999500	val: 0.762520	test: 0.714774
PRC train: 0.991305	val: 0.259944	test: 0.203887

Epoch: 107
Loss: 0.03652277038275299
ROC train: 0.998229	val: 0.782049	test: 0.712538
PRC train: 0.965652	val: 0.291311	test: 0.183106

Epoch: 108
Loss: 0.03668172457100958
ROC train: 0.999793	val: 0.787040	test: 0.705713
PRC train: 0.995839	val: 0.238097	test: 0.172324

Epoch: 109
Loss: 0.037349257942102136
ROC train: 0.999582	val: 0.781146	test: 0.719017
PRC train: 0.991935	val: 0.249332	test: 0.151589

Epoch: 110
Loss: 0.041048400621073
ROC train: 0.999585	val: 0.759011	test: 0.717693
PRC train: 0.992601	val: 0.232161	test: 0.198560

Epoch: 111
Loss: 0.03434278382243199
ROC train: 0.999708	val: 0.782717	test: 0.709446
PRC train: 0.994032	val: 0.268314	test: 0.178732

Epoch: 112
Loss: 0.03665700139161596
ROC train: 0.998904	val: 0.804870	test: 0.729489
PRC train: 0.981781	val: 0.278722	test: 0.206265

Epoch: 113
Loss: 0.03582815356166617
ROC train: 0.999732	val: 0.777870	test: 0.716725
PRC train: 0.994711	val: 0.247015	test: 0.187487

Epoch: 114
Loss: 0.033768467558103525
ROC train: 0.999141	val: 0.798039	test: 0.735267
PRC train: 0.983460	val: 0.259533	test: 0.186513

Epoch: 115
Loss: 0.035638845247747554
ROC train: 0.999422	val: 0.798752	test: 0.730190
PRC train: 0.990011	val: 0.319274	test: 0.213548

Epoch: 116
Loss: 0.031291476715077496
ROC train: 0.999685	val: 0.803933	test: 0.727030
PRC train: 0.993622	val: 0.301584	test: 0.221627

Epoch: 117
Loss: 0.03543406750122781
ROC train: 0.999770	val: 0.806486	test: 0.717969
PRC train: 0.994925	val: 0.309846	test: 0.222282

Epoch: 118
Loss: 0.03458727301201212
ROC train: 0.999685	val: 0.782441	test: 0.723235
PRC train: 0.994015	val: 0.294706	test: 0.193295

Epoch: 119
Loss: 0.03438926544152202
ROC train: 0.999704	val: 0.799086	test: 0.716041
PRC train: 0.994370	val: 0.289333	test: 0.139632

Epoch: 120
Loss: 0.03202904457284723
ROC train: 0.999743	val: 0.764164	test: 0.694509
PRC train: 0.995004	val: 0.250526	test: 0.150732

Epoch: 121
Loss: 0.03328458784723132
ROC train: 0.999872	val: 0.753289	test: 0.708144
PRC train: 0.997232	val: 0.265350	test: 0.183269

Epoch: 122
Loss: 0.030733538835493533
ROC train: 0.999549	val: 0.775481	test: 0.706955
PRC train: 0.991900	val: 0.250620	test: 0.164940

Epoch: 123
Loss: 0.03281138231520146
ROC train: 0.999849	val: 0.782760	test: 0.709815
PRC train: 0.996597	val: 0.300038	test: 0.197237

Epoch: 124
Loss: 0.03143424674251136
ROC train: 0.999723	val: 0.783644	test: 0.712797
PRC train: 0.994378	val: 0.301875	test: 0.201770

Epoch: 125
Loss: 0.03077700192695343
ROC train: 0.999967	val: 0.782824	test: 0.712246
PRC train: 0.999213	val: 0.267794	test: 0.164077

Epoch: 126
Loss: 0.030658023817302402
ROC train: 0.999893	val: 0.777175	test: 0.722281
PRC train: 0.997644	val: 0.271817	test: 0.191975

Epoch: 127
Loss: 0.02907499600147566
ROC train: 0.999890	val: 0.793192	test: 0.722362
PRC train: 0.997650	val: 0.255218	test: 0.192851

Epoch: 128
Loss: 0.03141059120417436
ROC train: 0.999948	val: 0.795770	test: 0.716893
PRC train: 0.998753	val: 0.207028	test: 0.154711

Epoch: 129
Loss: 0.030876907375628326
ROC train: 0.999804	val: 0.768335	test: 0.706505
PRC train: 0.995484	val: 0.250595	test: 0.163188

Epoch: 130
Loss: 0.029455333729001304
ROC train: 0.998784	val: 0.757306	test: 0.672356
PRC train: 0.992136	val: 0.204918	test: 0.093426

Epoch: 131
Loss: 0.03210182817347842
ROC train: 0.999887	val: 0.804340	test: 0.715991
PRC train: 0.997197	val: 0.259689	test: 0.185893

Early stopping
Best (ROC):	 train: 0.998671	val: 0.819037	test: 0.715220
Best (PRC):	 train: 0.978781	val: 0.228297	test: 0.159968
All runs completed.
