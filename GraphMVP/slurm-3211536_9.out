>>> Starting run for dataset: tox21
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running RANDOM configs_split_experiments/GraphCL/tox21/random/train_prop=0.6.yml on cuda:0
Running RANDOM configs_split_experiments/GraphCL/tox21/random/train_prop=0.7.yml on cuda:1
Running RANDOM configs_split_experiments/GraphCL/tox21/random/train_prop=0.8.yml on cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.8.yml --runseed 4 --device cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.6.yml --runseed 4 --device cuda:0
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.6.yml --runseed 5 --device cuda:0
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.8.yml --runseed 5 --device cuda:2
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.7.yml --runseed 4 --device cuda:1
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.6.yml --runseed 6 --device cuda:0
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.8.yml --runseed 6 --device cuda:2
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.7.yml --runseed 5 --device cuda:1
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.7.yml --runseed 6 --device cuda:1
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: tox21
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/tox21/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/tox21/random/train_prop=0.6/tox21_random_4_26-05_09-58-59  ]
[ Using Seed :  4  ]
[ Using device :  cuda:0  ]
Dataset: tox21
Data: Data(edge_attr=[302190, 2], edge_index=[2, 302190], id=[7831], x=[145459, 2], y=[93972])
MoleculeDataset(7831)
randomly split
Data(edge_attr=[26, 2], edge_index=[2, 26], id=[1], x=[13, 2], y=[12])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=12, bias=True)
)
Epoch: 1
Loss: 0.5625693862306406
ROC train: 0.679293	val: 0.649099	test: 0.640878
PRC train: 0.196522	val: 0.208114	test: 0.164180

Epoch: 2
Loss: 0.3769370280329323
ROC train: 0.736288	val: 0.702304	test: 0.700811
PRC train: 0.267440	val: 0.272557	test: 0.221482

Epoch: 3
Loss: 0.2807204410080744
ROC train: 0.771768	val: 0.746543	test: 0.722013
PRC train: 0.301561	val: 0.296713	test: 0.243034

Epoch: 4
Loss: 0.23830968524346421
ROC train: 0.786493	val: 0.763027	test: 0.729432
PRC train: 0.327113	val: 0.319917	test: 0.258577

Epoch: 5
Loss: 0.21941880056397592
ROC train: 0.808097	val: 0.782891	test: 0.758484
PRC train: 0.365001	val: 0.333580	test: 0.295805

Epoch: 6
Loss: 0.21117017584390685
ROC train: 0.807738	val: 0.769998	test: 0.756033
PRC train: 0.366765	val: 0.322712	test: 0.286721

Epoch: 7
Loss: 0.20546543191437291
ROC train: 0.825719	val: 0.792691	test: 0.768611
PRC train: 0.391768	val: 0.349590	test: 0.318952

Epoch: 8
Loss: 0.2027194629358294
ROC train: 0.839077	val: 0.799785	test: 0.783792
PRC train: 0.402985	val: 0.342462	test: 0.321858

Epoch: 9
Loss: 0.19931085172772844
ROC train: 0.845149	val: 0.808989	test: 0.786252
PRC train: 0.427403	val: 0.372789	test: 0.328480

Epoch: 10
Loss: 0.19907869331377373
ROC train: 0.850768	val: 0.811858	test: 0.788847
PRC train: 0.433894	val: 0.365112	test: 0.322091

Epoch: 11
Loss: 0.195740869110588
ROC train: 0.858943	val: 0.814743	test: 0.786636
PRC train: 0.460700	val: 0.375540	test: 0.335101

Epoch: 12
Loss: 0.19065634116882485
ROC train: 0.861820	val: 0.805445	test: 0.790113
PRC train: 0.476074	val: 0.370148	test: 0.339799

Epoch: 13
Loss: 0.19076067662862864
ROC train: 0.868775	val: 0.821155	test: 0.803303
PRC train: 0.495780	val: 0.373967	test: 0.361850

Epoch: 14
Loss: 0.18826072828067966
ROC train: 0.873297	val: 0.818769	test: 0.800717
PRC train: 0.497807	val: 0.382334	test: 0.360719

Epoch: 15
Loss: 0.18772618117405143
ROC train: 0.870142	val: 0.816214	test: 0.799297
PRC train: 0.493826	val: 0.372218	test: 0.359880

Epoch: 16
Loss: 0.18401911419286926
ROC train: 0.877158	val: 0.823390	test: 0.803383
PRC train: 0.523399	val: 0.385216	test: 0.373952

Epoch: 17
Loss: 0.18195979843737667
ROC train: 0.875624	val: 0.805278	test: 0.798154
PRC train: 0.517418	val: 0.370202	test: 0.363864

Epoch: 18
Loss: 0.18553104050620328
ROC train: 0.876079	val: 0.804979	test: 0.796049
PRC train: 0.516594	val: 0.361873	test: 0.368767

Epoch: 19
Loss: 0.18377864377057304
ROC train: 0.880524	val: 0.820706	test: 0.807076
PRC train: 0.530639	val: 0.385063	test: 0.388496

Epoch: 20
Loss: 0.17745366667022963
ROC train: 0.884881	val: 0.816221	test: 0.803499
PRC train: 0.535518	val: 0.394633	test: 0.380364

Epoch: 21
Loss: 0.17531576553428763
ROC train: 0.893341	val: 0.823625	test: 0.812580
PRC train: 0.570231	val: 0.382858	test: 0.412931

Epoch: 22
Loss: 0.1741544451457192
ROC train: 0.891762	val: 0.821378	test: 0.813413
PRC train: 0.566571	val: 0.386677	test: 0.403721

Epoch: 23
Loss: 0.17408799618030438
ROC train: 0.893199	val: 0.816700	test: 0.803474
PRC train: 0.560065	val: 0.381428	test: 0.383757

Epoch: 24
Loss: 0.17471552882455543
ROC train: 0.895811	val: 0.815790	test: 0.806777
PRC train: 0.576812	val: 0.399369	test: 0.411749

Epoch: 25
Loss: 0.17517094096118344
ROC train: 0.896944	val: 0.824651	test: 0.809842
PRC train: 0.578574	val: 0.408645	test: 0.403926

Epoch: 26
Loss: 0.17284822166221966
ROC train: 0.900765	val: 0.827053	test: 0.808373
PRC train: 0.586100	val: 0.408012	test: 0.419467

Epoch: 27
Loss: 0.1674798984380901
ROC train: 0.903169	val: 0.821985	test: 0.812408
PRC train: 0.598655	val: 0.398461	test: 0.421182

Epoch: 28
Loss: 0.16941330563602364
ROC train: 0.904555	val: 0.823562	test: 0.813097
PRC train: 0.599094	val: 0.408786	test: 0.422460

Epoch: 29
Loss: 0.17053087838840075
ROC train: 0.908887	val: 0.827051	test: 0.818689
PRC train: 0.614887	val: 0.410379	test: 0.417543

Epoch: 30
Loss: 0.16562491219004744
ROC train: 0.910862	val: 0.828605	test: 0.817401
PRC train: 0.619374	val: 0.402720	test: 0.419938

Epoch: 31
Loss: 0.16440575981044878
ROC train: 0.911018	val: 0.817220	test: 0.813768
PRC train: 0.622523	val: 0.409472	test: 0.424668

Epoch: 32
Loss: 0.16515104471755618
ROC train: 0.915850	val: 0.830539	test: 0.810521
PRC train: 0.633177	val: 0.409449	test: 0.420869

Epoch: 33
Loss: 0.1621284580269711Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: tox21
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/tox21/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/tox21/random/train_prop=0.6/tox21_random_6_26-05_09-58-59  ]
[ Using Seed :  6  ]
[ Using device :  cuda:0  ]
Dataset: tox21
Data: Data(edge_attr=[302190, 2], edge_index=[2, 302190], id=[7831], x=[145459, 2], y=[93972])
MoleculeDataset(7831)
randomly split
Data(edge_attr=[26, 2], edge_index=[2, 26], id=[1], x=[13, 2], y=[12])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=12, bias=True)
)
Epoch: 1
Loss: 0.5698525135395075
ROC train: 0.687783	val: 0.657225	test: 0.651677
PRC train: 0.193927	val: 0.194207	test: 0.170919

Epoch: 2
Loss: 0.38432426594686714
ROC train: 0.754251	val: 0.708019	test: 0.705378
PRC train: 0.273763	val: 0.264037	test: 0.218593

Epoch: 3
Loss: 0.28311855394138413
ROC train: 0.765020	val: 0.739521	test: 0.711378
PRC train: 0.282079	val: 0.275860	test: 0.230897

Epoch: 4
Loss: 0.23847946729827205
ROC train: 0.783197	val: 0.760532	test: 0.726824
PRC train: 0.314901	val: 0.297279	test: 0.255283

Epoch: 5
Loss: 0.22038445628114148
ROC train: 0.804342	val: 0.776170	test: 0.753404
PRC train: 0.356631	val: 0.313520	test: 0.284304

Epoch: 6
Loss: 0.21029422455719485
ROC train: 0.810780	val: 0.774006	test: 0.761231
PRC train: 0.359981	val: 0.305057	test: 0.283557

Epoch: 7
Loss: 0.20829169232550726
ROC train: 0.827424	val: 0.798169	test: 0.773082
PRC train: 0.395040	val: 0.349577	test: 0.303652

Epoch: 8
Loss: 0.2038185296633522
ROC train: 0.832393	val: 0.800983	test: 0.775992
PRC train: 0.405403	val: 0.354595	test: 0.309845

Epoch: 9
Loss: 0.20236042122427333
ROC train: 0.838030	val: 0.801599	test: 0.778046
PRC train: 0.420608	val: 0.354842	test: 0.322710

Epoch: 10
Loss: 0.20033686426020747
ROC train: 0.846333	val: 0.812173	test: 0.786373
PRC train: 0.440623	val: 0.368568	test: 0.327555

Epoch: 11
Loss: 0.19580372164085863
ROC train: 0.852988	val: 0.818958	test: 0.785686
PRC train: 0.448753	val: 0.373687	test: 0.335005

Epoch: 12
Loss: 0.19152220582480525
ROC train: 0.862808	val: 0.817468	test: 0.793614
PRC train: 0.467577	val: 0.378630	test: 0.340641

Epoch: 13
Loss: 0.19252692193697726
ROC train: 0.857642	val: 0.811317	test: 0.791177
PRC train: 0.457992	val: 0.364088	test: 0.333427

Epoch: 14
Loss: 0.18986933944838852
ROC train: 0.866044	val: 0.818953	test: 0.793732
PRC train: 0.484751	val: 0.378640	test: 0.354167

Epoch: 15
Loss: 0.1859135139099047
ROC train: 0.869934	val: 0.825350	test: 0.794127
PRC train: 0.494995	val: 0.400430	test: 0.350454

Epoch: 16
Loss: 0.1876161348464771
ROC train: 0.870078	val: 0.827748	test: 0.795799
PRC train: 0.499235	val: 0.384916	test: 0.351337

Epoch: 17
Loss: 0.18446846349352514
ROC train: 0.874896	val: 0.827045	test: 0.798757
PRC train: 0.509662	val: 0.391988	test: 0.351906

Epoch: 18
Loss: 0.1882368607111936
ROC train: 0.873492	val: 0.827373	test: 0.802185
PRC train: 0.510284	val: 0.385522	test: 0.368510

Epoch: 19
Loss: 0.1839775879121736
ROC train: 0.879621	val: 0.825288	test: 0.803354
PRC train: 0.542363	val: 0.400492	test: 0.377285

Epoch: 20
Loss: 0.1812879865196483
ROC train: 0.883995	val: 0.826313	test: 0.804606
PRC train: 0.545971	val: 0.391788	test: 0.371937

Epoch: 21
Loss: 0.1774684514450125
ROC train: 0.887322	val: 0.832367	test: 0.805990
PRC train: 0.551833	val: 0.409945	test: 0.372153

Epoch: 22
Loss: 0.1753468194687002
ROC train: 0.888029	val: 0.827099	test: 0.813224
PRC train: 0.558965	val: 0.398610	test: 0.380689

Epoch: 23
Loss: 0.17644491736949494
ROC train: 0.890648	val: 0.832870	test: 0.811764
PRC train: 0.562367	val: 0.413214	test: 0.379686

Epoch: 24
Loss: 0.1747534469224552
ROC train: 0.894164	val: 0.823030	test: 0.807188
PRC train: 0.577732	val: 0.398805	test: 0.387368

Epoch: 25
Loss: 0.17396692579742332
ROC train: 0.896529	val: 0.827778	test: 0.812400
PRC train: 0.579667	val: 0.406065	test: 0.389738

Epoch: 26
Loss: 0.17302039213221576
ROC train: 0.899790	val: 0.831874	test: 0.814802
PRC train: 0.588886	val: 0.409479	test: 0.392184

Epoch: 27
Loss: 0.17014310120940257
ROC train: 0.900592	val: 0.827758	test: 0.811648
PRC train: 0.596954	val: 0.408732	test: 0.398531

Epoch: 28
Loss: 0.17324604177219372
ROC train: 0.899104	val: 0.833970	test: 0.814355
PRC train: 0.591758	val: 0.410853	test: 0.391018

Epoch: 29
Loss: 0.16895158543763691
ROC train: 0.904375	val: 0.827204	test: 0.811836
PRC train: 0.598195	val: 0.402199	test: 0.392548

Epoch: 30
Loss: 0.16732720939626014
ROC train: 0.905205	val: 0.833083	test: 0.811552
PRC train: 0.612584	val: 0.420888	test: 0.400630

Epoch: 31
Loss: 0.16877303856584444
ROC train: 0.907270	val: 0.826225	test: 0.814004
PRC train: 0.618560	val: 0.405221	test: 0.403855

Epoch: 32
Loss: 0.16729401133615304
ROC train: 0.910527	val: 0.828831	test: 0.809426
PRC train: 0.622611	val: 0.411207	test: 0.409813

Epoch: 33
Loss: 0.16726892305578236Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: tox21
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/tox21/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/tox21/random/train_prop=0.6/tox21_random_5_26-05_09-58-59  ]
[ Using Seed :  5  ]
[ Using device :  cuda:0  ]
Dataset: tox21
Data: Data(edge_attr=[302190, 2], edge_index=[2, 302190], id=[7831], x=[145459, 2], y=[93972])
MoleculeDataset(7831)
randomly split
Data(edge_attr=[26, 2], edge_index=[2, 26], id=[1], x=[13, 2], y=[12])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=12, bias=True)
)
Epoch: 1
Loss: 0.5616133783231497
ROC train: 0.688738	val: 0.665390	test: 0.659964
PRC train: 0.200397	val: 0.211914	test: 0.178813

Epoch: 2
Loss: 0.3770888447936254
ROC train: 0.733113	val: 0.694639	test: 0.676837
PRC train: 0.249452	val: 0.243799	test: 0.200247

Epoch: 3
Loss: 0.2799526259303732
ROC train: 0.766596	val: 0.746703	test: 0.714135
PRC train: 0.282017	val: 0.273881	test: 0.223500

Epoch: 4
Loss: 0.24009417339930678
ROC train: 0.787967	val: 0.754693	test: 0.730757
PRC train: 0.334807	val: 0.306415	test: 0.257587

Epoch: 5
Loss: 0.22060170665065107
ROC train: 0.807060	val: 0.781704	test: 0.756256
PRC train: 0.368076	val: 0.333471	test: 0.289972

Epoch: 6
Loss: 0.2117366391844832
ROC train: 0.818928	val: 0.792729	test: 0.756924
PRC train: 0.370466	val: 0.334187	test: 0.282120

Epoch: 7
Loss: 0.20921002451430118
ROC train: 0.829691	val: 0.802920	test: 0.772515
PRC train: 0.409156	val: 0.359866	test: 0.321586

Epoch: 8
Loss: 0.2023315193932084
ROC train: 0.832991	val: 0.804896	test: 0.771505
PRC train: 0.402792	val: 0.362518	test: 0.314956

Epoch: 9
Loss: 0.2024305818819899
ROC train: 0.838341	val: 0.806937	test: 0.768951
PRC train: 0.394188	val: 0.351013	test: 0.296869

Epoch: 10
Loss: 0.19907449996322546
ROC train: 0.847535	val: 0.813669	test: 0.783714
PRC train: 0.423567	val: 0.365889	test: 0.310219

Epoch: 11
Loss: 0.19447492891164
ROC train: 0.856349	val: 0.816490	test: 0.785525
PRC train: 0.446956	val: 0.381391	test: 0.335373

Epoch: 12
Loss: 0.19279921810806122
ROC train: 0.861612	val: 0.811780	test: 0.783473
PRC train: 0.465621	val: 0.370102	test: 0.336114

Epoch: 13
Loss: 0.18976960697950332
ROC train: 0.865918	val: 0.819903	test: 0.791381
PRC train: 0.487713	val: 0.394695	test: 0.350881

Epoch: 14
Loss: 0.18778249709110664
ROC train: 0.866956	val: 0.816826	test: 0.791473
PRC train: 0.465490	val: 0.359637	test: 0.340312

Epoch: 15
Loss: 0.18888421021613375
ROC train: 0.871137	val: 0.815072	test: 0.792675
PRC train: 0.499942	val: 0.380080	test: 0.343545

Epoch: 16
Loss: 0.1864880897474391
ROC train: 0.873808	val: 0.823008	test: 0.796872
PRC train: 0.505286	val: 0.387772	test: 0.353536

Epoch: 17
Loss: 0.18345837527117445
ROC train: 0.877196	val: 0.814934	test: 0.795282
PRC train: 0.517491	val: 0.385844	test: 0.366615

Epoch: 18
Loss: 0.18263736111313147
ROC train: 0.882575	val: 0.817505	test: 0.809171
PRC train: 0.536059	val: 0.390741	test: 0.369659

Epoch: 19
Loss: 0.18102490417400166
ROC train: 0.887583	val: 0.822042	test: 0.809234
PRC train: 0.552504	val: 0.390741	test: 0.384989

Epoch: 20
Loss: 0.1785271013789549
ROC train: 0.889772	val: 0.826110	test: 0.810625
PRC train: 0.559290	val: 0.402414	test: 0.393522

Epoch: 21
Loss: 0.1785083716949723
ROC train: 0.891121	val: 0.818708	test: 0.806552
PRC train: 0.557688	val: 0.392194	test: 0.375380

Epoch: 22
Loss: 0.17663786606607607
ROC train: 0.892613	val: 0.816416	test: 0.803853
PRC train: 0.564717	val: 0.393763	test: 0.386847

Epoch: 23
Loss: 0.17375279294649915
ROC train: 0.896114	val: 0.821732	test: 0.813458
PRC train: 0.579040	val: 0.397126	test: 0.401825

Epoch: 24
Loss: 0.17229122304226702
ROC train: 0.895703	val: 0.820980	test: 0.812263
PRC train: 0.577896	val: 0.393325	test: 0.407368

Epoch: 25
Loss: 0.17123091431174114
ROC train: 0.902671	val: 0.826185	test: 0.810480
PRC train: 0.594097	val: 0.407865	test: 0.413501

Epoch: 26
Loss: 0.17050872495583638
ROC train: 0.905452	val: 0.821186	test: 0.812509
PRC train: 0.613122	val: 0.412076	test: 0.412641

Epoch: 27
Loss: 0.16974417668968575
ROC train: 0.906363	val: 0.824035	test: 0.810458
PRC train: 0.604295	val: 0.398129	test: 0.398114

Epoch: 28
Loss: 0.16823601313924177
ROC train: 0.906566	val: 0.823633	test: 0.812482
PRC train: 0.610940	val: 0.416953	test: 0.420165

Epoch: 29
Loss: 0.16593288270366463
ROC train: 0.908309	val: 0.819131	test: 0.812854
PRC train: 0.608765	val: 0.392907	test: 0.403304

Epoch: 30
Loss: 0.16629661220686764
ROC train: 0.912397	val: 0.823061	test: 0.808486
PRC train: 0.627968	val: 0.409438	test: 0.420037

Epoch: 31
Loss: 0.16257213924952463
ROC train: 0.912122	val: 0.821811	test: 0.810738
PRC train: 0.625875	val: 0.414929	test: 0.426123

Epoch: 32
Loss: 0.15999524548936228
ROC train: 0.915278	val: 0.826412	test: 0.810495
PRC train: 0.637247	val: 0.420620	test: 0.431126

Epoch: 33
Loss: 0.16363027709207492Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: tox21
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/tox21/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/tox21/random/train_prop=0.7/tox21_random_6_26-05_09-58-59  ]
[ Using Seed :  6  ]
[ Using device :  cuda:1  ]
Dataset: tox21
Data: Data(edge_attr=[302190, 2], edge_index=[2, 302190], id=[7831], x=[145459, 2], y=[93972])
MoleculeDataset(7831)
randomly split
Data(edge_attr=[26, 2], edge_index=[2, 26], id=[1], x=[13, 2], y=[12])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=12, bias=True)
)
Epoch: 1
Loss: 0.5514321743480786
ROC train: 0.690849	val: 0.665153	test: 0.648941
PRC train: 0.189274	val: 0.200614	test: 0.166250

Epoch: 2
Loss: 0.3499608588730705
ROC train: 0.745078	val: 0.729841	test: 0.696187
PRC train: 0.254922	val: 0.254849	test: 0.207814

Epoch: 3
Loss: 0.2581169467958653
ROC train: 0.770499	val: 0.756812	test: 0.715715
PRC train: 0.267949	val: 0.259436	test: 0.218855

Epoch: 4
Loss: 0.22487530524962737
ROC train: 0.793267	val: 0.777064	test: 0.743558
PRC train: 0.331605	val: 0.304818	test: 0.271618

Epoch: 5
Loss: 0.2121277154337626
ROC train: 0.811355	val: 0.787318	test: 0.758439
PRC train: 0.357048	val: 0.330918	test: 0.280594

Epoch: 6
Loss: 0.20804374657396696
ROC train: 0.822611	val: 0.797514	test: 0.774517
PRC train: 0.359381	val: 0.326321	test: 0.308392

Epoch: 7
Loss: 0.20327083025734324
ROC train: 0.832915	val: 0.799195	test: 0.784800
PRC train: 0.388802	val: 0.336116	test: 0.302577

Epoch: 8
Loss: 0.2004038851157917
ROC train: 0.837648	val: 0.796498	test: 0.784118
PRC train: 0.404303	val: 0.350664	test: 0.332733

Epoch: 9
Loss: 0.1946792629333082
ROC train: 0.844971	val: 0.807876	test: 0.795114
PRC train: 0.429100	val: 0.361546	test: 0.325663

Epoch: 10
Loss: 0.19448628486590494
ROC train: 0.852080	val: 0.806417	test: 0.804013
PRC train: 0.442194	val: 0.359442	test: 0.334181

Epoch: 11
Loss: 0.1910580105728086
ROC train: 0.856298	val: 0.813639	test: 0.810594
PRC train: 0.461949	val: 0.376690	test: 0.359253

Epoch: 12
Loss: 0.18988519175966181
ROC train: 0.858359	val: 0.820857	test: 0.810170
PRC train: 0.456251	val: 0.378447	test: 0.352287

Epoch: 13
Loss: 0.18863951248934951
ROC train: 0.860537	val: 0.813190	test: 0.808943
PRC train: 0.469956	val: 0.384379	test: 0.344453

Epoch: 14
Loss: 0.18659086703605202
ROC train: 0.864160	val: 0.816505	test: 0.811351
PRC train: 0.497277	val: 0.408742	test: 0.368794

Epoch: 15
Loss: 0.18391897439927601
ROC train: 0.867970	val: 0.818157	test: 0.808141
PRC train: 0.491296	val: 0.394690	test: 0.362343

Epoch: 16
Loss: 0.18326151489894613
ROC train: 0.876878	val: 0.823193	test: 0.819232
PRC train: 0.517426	val: 0.409252	test: 0.389416

Epoch: 17
Loss: 0.1820503405997399
ROC train: 0.877449	val: 0.820804	test: 0.819493
PRC train: 0.518091	val: 0.409044	test: 0.394679

Epoch: 18
Loss: 0.17997501999032667
ROC train: 0.880934	val: 0.826928	test: 0.827198
PRC train: 0.540549	val: 0.418497	test: 0.406270

Epoch: 19
Loss: 0.17631973642385698
ROC train: 0.879747	val: 0.819191	test: 0.816401
PRC train: 0.535070	val: 0.408241	test: 0.407811

Epoch: 20
Loss: 0.17629609119079603
ROC train: 0.887201	val: 0.837634	test: 0.825748
PRC train: 0.543529	val: 0.413677	test: 0.421454

Epoch: 21
Loss: 0.17676267428149994
ROC train: 0.888786	val: 0.827229	test: 0.820477
PRC train: 0.557716	val: 0.414998	test: 0.414462

Epoch: 22
Loss: 0.1754721121149282
ROC train: 0.889997	val: 0.824006	test: 0.816500
PRC train: 0.560546	val: 0.412830	test: 0.410476

Epoch: 23
Loss: 0.17185027437565167
ROC train: 0.892214	val: 0.827555	test: 0.825349
PRC train: 0.573169	val: 0.415151	test: 0.427178

Epoch: 24
Loss: 0.1713161622672078
ROC train: 0.893348	val: 0.835260	test: 0.822007
PRC train: 0.573467	val: 0.424984	test: 0.431242

Epoch: 25
Loss: 0.16993409708149299
ROC train: 0.892268	val: 0.830141	test: 0.819609
PRC train: 0.575454	val: 0.431547	test: 0.422353

Epoch: 26
Loss: 0.1678866055088416
ROC train: 0.897424	val: 0.828625	test: 0.828378
PRC train: 0.578162	val: 0.421493	test: 0.435000

Epoch: 27
Loss: 0.1687384171781826
ROC train: 0.901220	val: 0.834526	test: 0.827291
PRC train: 0.596913	val: 0.422900	test: 0.433794

Epoch: 28
Loss: 0.16718015266247638
ROC train: 0.904205	val: 0.838768	test: 0.828188
PRC train: 0.604434	val: 0.433618	test: 0.439502

Epoch: 29
Loss: 0.16512272402059114
ROC train: 0.906505	val: 0.833505	test: 0.821651
PRC train: 0.610616	val: 0.431710	test: 0.441826

Epoch: 30
Loss: 0.16493481859214232
ROC train: 0.906471	val: 0.834736	test: 0.827951
PRC train: 0.613911	val: 0.428950	test: 0.444367

Epoch: 31
Loss: 0.1639120332498081
ROC train: 0.910231	val: 0.837099	test: 0.828532
PRC train: 0.617004	val: 0.431861	test: 0.453044

Epoch: 32
Loss: 0.16317675286046393
ROC train: 0.911439	val: 0.832396	test: 0.823894
PRC train: 0.621414	val: 0.426453	test: 0.444088

Epoch: 33
Loss: 0.16127023028497353Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: tox21
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/tox21/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/tox21/random/train_prop=0.7/tox21_random_4_26-05_09-58-59  ]
[ Using Seed :  4  ]
[ Using device :  cuda:1  ]
Dataset: tox21
Data: Data(edge_attr=[302190, 2], edge_index=[2, 302190], id=[7831], x=[145459, 2], y=[93972])
MoleculeDataset(7831)
randomly split
Data(edge_attr=[26, 2], edge_index=[2, 26], id=[1], x=[13, 2], y=[12])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=12, bias=True)
)
Epoch: 1
Loss: 0.5479765378692628
ROC train: 0.703888	val: 0.685342	test: 0.654022
PRC train: 0.219006	val: 0.234752	test: 0.182851

Epoch: 2
Loss: 0.34575435900385804
ROC train: 0.756932	val: 0.747142	test: 0.706018
PRC train: 0.276066	val: 0.290037	test: 0.232300

Epoch: 3
Loss: 0.2575965918630581
ROC train: 0.785376	val: 0.775642	test: 0.737361
PRC train: 0.330022	val: 0.334949	test: 0.269539

Epoch: 4
Loss: 0.21936904499015072
ROC train: 0.808442	val: 0.792640	test: 0.767134
PRC train: 0.356453	val: 0.345852	test: 0.297605

Epoch: 5
Loss: 0.20945539339176697
ROC train: 0.815665	val: 0.796531	test: 0.763476
PRC train: 0.377539	val: 0.358885	test: 0.307935

Epoch: 6
Loss: 0.20512596663737234
ROC train: 0.831686	val: 0.806503	test: 0.777609
PRC train: 0.388892	val: 0.368491	test: 0.301721

Epoch: 7
Loss: 0.2007068867637173
ROC train: 0.831885	val: 0.808596	test: 0.792145
PRC train: 0.397057	val: 0.369389	test: 0.322308

Epoch: 8
Loss: 0.1997696556038463
ROC train: 0.843504	val: 0.812145	test: 0.798676
PRC train: 0.414003	val: 0.373532	test: 0.336426

Epoch: 9
Loss: 0.19492747412013509
ROC train: 0.852291	val: 0.821862	test: 0.799833
PRC train: 0.436818	val: 0.382795	test: 0.340841

Epoch: 10
Loss: 0.19312452252247903
ROC train: 0.853218	val: 0.822379	test: 0.807857
PRC train: 0.443987	val: 0.388803	test: 0.360572

Epoch: 11
Loss: 0.19110764731850657
ROC train: 0.861856	val: 0.823651	test: 0.804096
PRC train: 0.467566	val: 0.394047	test: 0.359105

Epoch: 12
Loss: 0.1877021848349141
ROC train: 0.857377	val: 0.821762	test: 0.802112
PRC train: 0.468463	val: 0.398403	test: 0.365886

Epoch: 13
Loss: 0.18569492236229773
ROC train: 0.865185	val: 0.812129	test: 0.810010
PRC train: 0.490947	val: 0.400970	test: 0.384341

Epoch: 14
Loss: 0.18314958517277147
ROC train: 0.871001	val: 0.828213	test: 0.815357
PRC train: 0.497581	val: 0.391290	test: 0.383828

Epoch: 15
Loss: 0.18222038987809902
ROC train: 0.871940	val: 0.829993	test: 0.817212
PRC train: 0.510740	val: 0.412064	test: 0.387347

Epoch: 16
Loss: 0.18016290940362314
ROC train: 0.869477	val: 0.826479	test: 0.813392
PRC train: 0.505039	val: 0.404926	test: 0.383115

Epoch: 17
Loss: 0.18199072190876092
ROC train: 0.877973	val: 0.833809	test: 0.816069
PRC train: 0.526184	val: 0.420146	test: 0.395736

Epoch: 18
Loss: 0.18072663819174453
ROC train: 0.881512	val: 0.836586	test: 0.819376
PRC train: 0.543002	val: 0.425312	test: 0.416259

Epoch: 19
Loss: 0.1785936899919483
ROC train: 0.884570	val: 0.829931	test: 0.819066
PRC train: 0.542266	val: 0.422755	test: 0.418544

Epoch: 20
Loss: 0.17501102249241585
ROC train: 0.885949	val: 0.827123	test: 0.818227
PRC train: 0.547452	val: 0.424090	test: 0.414808

Epoch: 21
Loss: 0.1740299380593637
ROC train: 0.885207	val: 0.822967	test: 0.817467
PRC train: 0.546299	val: 0.411793	test: 0.395039

Epoch: 22
Loss: 0.17369709818064039
ROC train: 0.886648	val: 0.825469	test: 0.813525
PRC train: 0.552313	val: 0.417468	test: 0.419094

Epoch: 23
Loss: 0.17279626589576577
ROC train: 0.896140	val: 0.838591	test: 0.830357
PRC train: 0.578065	val: 0.431027	test: 0.430535

Epoch: 24
Loss: 0.16992899209881338
ROC train: 0.892479	val: 0.834467	test: 0.818931
PRC train: 0.567537	val: 0.427599	test: 0.432597

Epoch: 25
Loss: 0.17069190464304976
ROC train: 0.895345	val: 0.820917	test: 0.821312
PRC train: 0.585950	val: 0.419921	test: 0.431804

Epoch: 26
Loss: 0.1687846719505832
ROC train: 0.900505	val: 0.834664	test: 0.827474
PRC train: 0.583540	val: 0.428632	test: 0.424174

Epoch: 27
Loss: 0.16836090766214784
ROC train: 0.903472	val: 0.830856	test: 0.822760
PRC train: 0.597205	val: 0.429652	test: 0.435526

Epoch: 28
Loss: 0.1662999261996486
ROC train: 0.904595	val: 0.834216	test: 0.826383
PRC train: 0.599734	val: 0.436848	test: 0.447271

Epoch: 29
Loss: 0.16645078652553916
ROC train: 0.907622	val: 0.833733	test: 0.828046
PRC train: 0.602814	val: 0.431593	test: 0.446304

Epoch: 30
Loss: 0.1637180182684651
ROC train: 0.909651	val: 0.837717	test: 0.829648
PRC train: 0.618338	val: 0.433175	test: 0.450931

Epoch: 31
Loss: 0.1628951002096061
ROC train: 0.909101	val: 0.833909	test: 0.827245
PRC train: 0.608592	val: 0.438930	test: 0.444841

Epoch: 32
Loss: 0.1639710480685777
ROC train: 0.915258	val: 0.831801	test: 0.827003
PRC train: 0.636317	val: 0.437215	test: 0.455405

Epoch: 33
Loss: 0.16123512975069454Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: tox21
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/tox21/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/tox21/random/train_prop=0.7/tox21_random_5_26-05_09-58-59  ]
[ Using Seed :  5  ]
[ Using device :  cuda:1  ]
Dataset: tox21
Data: Data(edge_attr=[302190, 2], edge_index=[2, 302190], id=[7831], x=[145459, 2], y=[93972])
MoleculeDataset(7831)
randomly split
Data(edge_attr=[26, 2], edge_index=[2, 26], id=[1], x=[13, 2], y=[12])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=12, bias=True)
)
Epoch: 1
Loss: 0.5439912979602933
ROC train: 0.688970	val: 0.678141	test: 0.658582
PRC train: 0.216493	val: 0.232027	test: 0.190039

Epoch: 2
Loss: 0.35051233121746644
ROC train: 0.752767	val: 0.735932	test: 0.703778
PRC train: 0.284105	val: 0.288986	test: 0.218566

Epoch: 3
Loss: 0.2561085143947888
ROC train: 0.769961	val: 0.761502	test: 0.710496
PRC train: 0.306968	val: 0.309352	test: 0.245226

Epoch: 4
Loss: 0.22330405930809008
ROC train: 0.801664	val: 0.776651	test: 0.749477
PRC train: 0.358119	val: 0.338055	test: 0.282108

Epoch: 5
Loss: 0.20926523524070068
ROC train: 0.817466	val: 0.798216	test: 0.772574
PRC train: 0.376526	val: 0.352003	test: 0.311338

Epoch: 6
Loss: 0.20408777358253624
ROC train: 0.826681	val: 0.799848	test: 0.769341
PRC train: 0.393340	val: 0.356081	test: 0.303440

Epoch: 7
Loss: 0.2011509273344851
ROC train: 0.831974	val: 0.814008	test: 0.776790
PRC train: 0.402396	val: 0.363166	test: 0.325691

Epoch: 8
Loss: 0.19653991708535462
ROC train: 0.837522	val: 0.808311	test: 0.776997
PRC train: 0.407866	val: 0.368419	test: 0.321164

Epoch: 9
Loss: 0.1947299566069667
ROC train: 0.844936	val: 0.814080	test: 0.793353
PRC train: 0.429670	val: 0.377898	test: 0.341046

Epoch: 10
Loss: 0.19321464504613362
ROC train: 0.848892	val: 0.822244	test: 0.788476
PRC train: 0.436200	val: 0.395365	test: 0.341285

Epoch: 11
Loss: 0.1898906268654021
ROC train: 0.856973	val: 0.827676	test: 0.796406
PRC train: 0.460909	val: 0.393238	test: 0.353063

Epoch: 12
Loss: 0.18803765239535436
ROC train: 0.862586	val: 0.815424	test: 0.800893
PRC train: 0.475149	val: 0.403168	test: 0.356492

Epoch: 13
Loss: 0.18419282149331695
ROC train: 0.862324	val: 0.821041	test: 0.799963
PRC train: 0.480480	val: 0.398503	test: 0.351818

Epoch: 14
Loss: 0.18566441757326543
ROC train: 0.871827	val: 0.828370	test: 0.807865
PRC train: 0.503463	val: 0.414811	test: 0.361340

Epoch: 15
Loss: 0.18218101869174577
ROC train: 0.873055	val: 0.824733	test: 0.807908
PRC train: 0.513704	val: 0.403012	test: 0.390241

Epoch: 16
Loss: 0.18294830334573176
ROC train: 0.876711	val: 0.824569	test: 0.808883
PRC train: 0.523522	val: 0.413349	test: 0.391960

Epoch: 17
Loss: 0.18025389934198996
ROC train: 0.879351	val: 0.828399	test: 0.814536
PRC train: 0.531338	val: 0.420654	test: 0.377336

Epoch: 18
Loss: 0.17976914736735058
ROC train: 0.880024	val: 0.831836	test: 0.813721
PRC train: 0.534957	val: 0.425796	test: 0.381339

Epoch: 19
Loss: 0.17576006620060067
ROC train: 0.886403	val: 0.831755	test: 0.823665
PRC train: 0.552368	val: 0.423878	test: 0.408899

Epoch: 20
Loss: 0.17465548429341535
ROC train: 0.889319	val: 0.824711	test: 0.816073
PRC train: 0.559986	val: 0.428352	test: 0.397401

Epoch: 21
Loss: 0.17258264648965563
ROC train: 0.888061	val: 0.824779	test: 0.822667
PRC train: 0.556000	val: 0.420579	test: 0.398078

Epoch: 22
Loss: 0.17080288437412555
ROC train: 0.890979	val: 0.834813	test: 0.819960
PRC train: 0.558603	val: 0.431450	test: 0.399532

Epoch: 23
Loss: 0.17238591353691182
ROC train: 0.896132	val: 0.833280	test: 0.828059
PRC train: 0.584430	val: 0.432917	test: 0.416951

Epoch: 24
Loss: 0.1707953424221812
ROC train: 0.898139	val: 0.835877	test: 0.826062
PRC train: 0.584927	val: 0.433552	test: 0.430721

Epoch: 25
Loss: 0.17005415547830857
ROC train: 0.898434	val: 0.826119	test: 0.823910
PRC train: 0.581317	val: 0.425783	test: 0.412949

Epoch: 26
Loss: 0.16970447912165157
ROC train: 0.900604	val: 0.828323	test: 0.824359
PRC train: 0.595293	val: 0.436178	test: 0.416446

Epoch: 27
Loss: 0.16731159871193862
ROC train: 0.902501	val: 0.832265	test: 0.825304
PRC train: 0.602369	val: 0.434410	test: 0.428122

Epoch: 28
Loss: 0.1648355929048577
ROC train: 0.901849	val: 0.834265	test: 0.829328
PRC train: 0.598958	val: 0.446297	test: 0.419108

Epoch: 29
Loss: 0.16366393101197382
ROC train: 0.906082	val: 0.834475	test: 0.829757
PRC train: 0.611662	val: 0.433254	test: 0.421813

Epoch: 30
Loss: 0.16266572642124405
ROC train: 0.907007	val: 0.836235	test: 0.828989
PRC train: 0.615668	val: 0.443196	test: 0.428504

Epoch: 31
Loss: 0.16087826965030028
ROC train: 0.913771	val: 0.834495	test: 0.827253
PRC train: 0.632722	val: 0.439788	test: 0.443626

Epoch: 32
Loss: 0.16392425906602875
ROC train: 0.912593	val: 0.829071	test: 0.818020
PRC train: 0.630369	val: 0.442245	test: 0.433001

Epoch: 33
Loss: 0.16148478383857792Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: tox21
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/tox21/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/tox21/random/train_prop=0.8/tox21_random_5_26-05_09-58-59  ]
[ Using Seed :  5  ]
[ Using device :  cuda:2  ]
Dataset: tox21
Data: Data(edge_attr=[302190, 2], edge_index=[2, 302190], id=[7831], x=[145459, 2], y=[93972])
MoleculeDataset(7831)
randomly split
Data(edge_attr=[26, 2], edge_index=[2, 26], id=[1], x=[13, 2], y=[12])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=12, bias=True)
)
Epoch: 1
Loss: 0.5269959640547279
ROC train: 0.686684	val: 0.664425	test: 0.630712
PRC train: 0.212398	val: 0.210631	test: 0.174040

Epoch: 2
Loss: 0.3220176630031266
ROC train: 0.761732	val: 0.726185	test: 0.711127
PRC train: 0.300763	val: 0.296773	test: 0.223994

Epoch: 3
Loss: 0.24143683814014869
ROC train: 0.787425	val: 0.751465	test: 0.736854
PRC train: 0.331760	val: 0.309192	test: 0.250645

Epoch: 4
Loss: 0.21638643508893252
ROC train: 0.809350	val: 0.764137	test: 0.753807
PRC train: 0.369453	val: 0.338003	test: 0.275999

Epoch: 5
Loss: 0.20826531684431313
ROC train: 0.819771	val: 0.774602	test: 0.771586
PRC train: 0.380821	val: 0.344347	test: 0.300531

Epoch: 6
Loss: 0.2031091949665689
ROC train: 0.823733	val: 0.779905	test: 0.777964
PRC train: 0.386534	val: 0.349750	test: 0.294463

Epoch: 7
Loss: 0.20134133942036025
ROC train: 0.835257	val: 0.788090	test: 0.776698
PRC train: 0.410320	val: 0.352795	test: 0.309397

Epoch: 8
Loss: 0.19773238580039132
ROC train: 0.842946	val: 0.787646	test: 0.779235
PRC train: 0.418112	val: 0.361836	test: 0.314167

Epoch: 9
Loss: 0.19449506803249594
ROC train: 0.847490	val: 0.795836	test: 0.780175
PRC train: 0.433146	val: 0.377470	test: 0.318460

Epoch: 10
Loss: 0.19195101446116514
ROC train: 0.857706	val: 0.812918	test: 0.799903
PRC train: 0.458994	val: 0.404410	test: 0.337240

Epoch: 11
Loss: 0.18984074821325247
ROC train: 0.861007	val: 0.812040	test: 0.792010
PRC train: 0.474483	val: 0.407751	test: 0.350681

Epoch: 12
Loss: 0.1870667565289756
ROC train: 0.869725	val: 0.817771	test: 0.798032
PRC train: 0.490488	val: 0.424235	test: 0.365797

Epoch: 13
Loss: 0.1855470173123322
ROC train: 0.869175	val: 0.814486	test: 0.796608
PRC train: 0.496205	val: 0.413088	test: 0.363691

Epoch: 14
Loss: 0.18467411836149622
ROC train: 0.872301	val: 0.816378	test: 0.803717
PRC train: 0.502383	val: 0.443148	test: 0.370243

Epoch: 15
Loss: 0.1824462247305576
ROC train: 0.878408	val: 0.820468	test: 0.799269
PRC train: 0.522762	val: 0.440635	test: 0.364925

Epoch: 16
Loss: 0.18403775905580644
ROC train: 0.877225	val: 0.819890	test: 0.803777
PRC train: 0.515280	val: 0.434660	test: 0.356980

Epoch: 17
Loss: 0.17940267599124538
ROC train: 0.882674	val: 0.831262	test: 0.811672
PRC train: 0.529015	val: 0.456726	test: 0.369305

Epoch: 18
Loss: 0.17911210506980313
ROC train: 0.882255	val: 0.828618	test: 0.809927
PRC train: 0.533008	val: 0.447895	test: 0.379311

Epoch: 19
Loss: 0.178536924283092
ROC train: 0.888937	val: 0.827100	test: 0.816101
PRC train: 0.546781	val: 0.441823	test: 0.394754

Epoch: 20
Loss: 0.1748359803826604
ROC train: 0.889164	val: 0.829689	test: 0.828012
PRC train: 0.547939	val: 0.446753	test: 0.392249

Epoch: 21
Loss: 0.1752434127678194
ROC train: 0.890612	val: 0.826601	test: 0.826482
PRC train: 0.563241	val: 0.476440	test: 0.394854

Epoch: 22
Loss: 0.17310376832209232
ROC train: 0.895362	val: 0.833701	test: 0.823763
PRC train: 0.567729	val: 0.480361	test: 0.379289

Epoch: 23
Loss: 0.1702724511971893
ROC train: 0.896593	val: 0.824014	test: 0.821002
PRC train: 0.573297	val: 0.464585	test: 0.392028

Epoch: 24
Loss: 0.1730470992643078
ROC train: 0.896342	val: 0.825870	test: 0.826597
PRC train: 0.581776	val: 0.478611	test: 0.408568

Epoch: 25
Loss: 0.17087179708685407
ROC train: 0.903265	val: 0.832721	test: 0.830497
PRC train: 0.591692	val: 0.478009	test: 0.402421

Epoch: 26
Loss: 0.16729164108152833
ROC train: 0.900873	val: 0.827118	test: 0.820257
PRC train: 0.579534	val: 0.492234	test: 0.397312

Epoch: 27
Loss: 0.16739766735096828
ROC train: 0.906388	val: 0.830065	test: 0.829555
PRC train: 0.604069	val: 0.494697	test: 0.427452

Epoch: 28
Loss: 0.1656853814516791
ROC train: 0.908030	val: 0.828591	test: 0.827516
PRC train: 0.608079	val: 0.508791	test: 0.419186

Epoch: 29
Loss: 0.16649112670970317
ROC train: 0.908836	val: 0.831678	test: 0.830365
PRC train: 0.607450	val: 0.496513	test: 0.444495

Epoch: 30
Loss: 0.16492606797028173
ROC train: 0.909350	val: 0.832837	test: 0.823853
PRC train: 0.612765	val: 0.500723	test: 0.414102

Epoch: 31
Loss: 0.16480583350330702
ROC train: 0.914545	val: 0.831277	test: 0.831526
PRC train: 0.625751	val: 0.502441	test: 0.427668

Epoch: 32
Loss: 0.16282862115939714
ROC train: 0.915605	val: 0.830587	test: 0.833031
PRC train: 0.626933	val: 0.498292	test: 0.422748

Epoch: 33
Loss: 0.16122439073816267Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: tox21
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/tox21/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/tox21/random/train_prop=0.8/tox21_random_6_26-05_09-58-59  ]
[ Using Seed :  6  ]
[ Using device :  cuda:2  ]
Dataset: tox21
Data: Data(edge_attr=[302190, 2], edge_index=[2, 302190], id=[7831], x=[145459, 2], y=[93972])
MoleculeDataset(7831)
randomly split
Data(edge_attr=[26, 2], edge_index=[2, 26], id=[1], x=[13, 2], y=[12])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=12, bias=True)
)
Epoch: 1
Loss: 0.5364834218530923
ROC train: 0.690559	val: 0.678039	test: 0.637706
PRC train: 0.179505	val: 0.186142	test: 0.155619

Epoch: 2
Loss: 0.3275062448245518
ROC train: 0.741672	val: 0.718354	test: 0.677619
PRC train: 0.258335	val: 0.250293	test: 0.179903

Epoch: 3
Loss: 0.24446391811002977
ROC train: 0.787192	val: 0.758673	test: 0.745380
PRC train: 0.328565	val: 0.308887	test: 0.263666

Epoch: 4
Loss: 0.21801799068372724
ROC train: 0.810927	val: 0.768455	test: 0.772579
PRC train: 0.358943	val: 0.338298	test: 0.286710

Epoch: 5
Loss: 0.2095780593539513
ROC train: 0.816179	val: 0.770790	test: 0.767308
PRC train: 0.347813	val: 0.327277	test: 0.284710

Epoch: 6
Loss: 0.20438930975530828
ROC train: 0.832158	val: 0.779268	test: 0.779803
PRC train: 0.394628	val: 0.348191	test: 0.314744

Epoch: 7
Loss: 0.20028567263716326
ROC train: 0.837718	val: 0.785296	test: 0.787720
PRC train: 0.404467	val: 0.354056	test: 0.317232

Epoch: 8
Loss: 0.19929364750540668
ROC train: 0.844812	val: 0.795293	test: 0.797394
PRC train: 0.418584	val: 0.362919	test: 0.335971

Epoch: 9
Loss: 0.19644775076885268
ROC train: 0.852038	val: 0.801696	test: 0.795548
PRC train: 0.434547	val: 0.362078	test: 0.331215

Epoch: 10
Loss: 0.1932842949752404
ROC train: 0.857144	val: 0.806263	test: 0.793603
PRC train: 0.453309	val: 0.373577	test: 0.347964

Epoch: 11
Loss: 0.19084611195043608
ROC train: 0.855734	val: 0.805572	test: 0.791352
PRC train: 0.449701	val: 0.390842	test: 0.343454

Epoch: 12
Loss: 0.18908199165991832
ROC train: 0.862280	val: 0.801918	test: 0.796027
PRC train: 0.462545	val: 0.381541	test: 0.341291

Epoch: 13
Loss: 0.18725442517375432
ROC train: 0.867610	val: 0.809370	test: 0.802945
PRC train: 0.472515	val: 0.398865	test: 0.342049

Epoch: 14
Loss: 0.18768251592657603
ROC train: 0.869963	val: 0.812072	test: 0.800566
PRC train: 0.488757	val: 0.402562	test: 0.356124

Epoch: 15
Loss: 0.18497191054952297
ROC train: 0.873791	val: 0.819621	test: 0.813281
PRC train: 0.504758	val: 0.417641	test: 0.374434

Epoch: 16
Loss: 0.18312633658887725
ROC train: 0.876122	val: 0.820333	test: 0.803184
PRC train: 0.510091	val: 0.412164	test: 0.369737

Epoch: 17
Loss: 0.18034154577802813
ROC train: 0.877676	val: 0.820885	test: 0.808834
PRC train: 0.514601	val: 0.428449	test: 0.366589

Epoch: 18
Loss: 0.1803895718607509
ROC train: 0.883371	val: 0.824878	test: 0.818472
PRC train: 0.530686	val: 0.437341	test: 0.376590

Epoch: 19
Loss: 0.18094378979794776
ROC train: 0.882416	val: 0.822235	test: 0.801392
PRC train: 0.532206	val: 0.434335	test: 0.373166

Epoch: 20
Loss: 0.17841131316079145
ROC train: 0.888059	val: 0.825631	test: 0.825029
PRC train: 0.546341	val: 0.448524	test: 0.390318

Epoch: 21
Loss: 0.17662368694635103
ROC train: 0.890597	val: 0.822977	test: 0.819082
PRC train: 0.557300	val: 0.460950	test: 0.398659

Epoch: 22
Loss: 0.17380380208504134
ROC train: 0.895451	val: 0.830512	test: 0.823553
PRC train: 0.568305	val: 0.463278	test: 0.390847

Epoch: 23
Loss: 0.17287352037039982
ROC train: 0.898066	val: 0.831806	test: 0.822831
PRC train: 0.579151	val: 0.466391	test: 0.399708

Epoch: 24
Loss: 0.17234574738212818
ROC train: 0.894885	val: 0.821009	test: 0.813029
PRC train: 0.563106	val: 0.461311	test: 0.397694

Epoch: 25
Loss: 0.17282433844075826
ROC train: 0.898741	val: 0.829995	test: 0.821064
PRC train: 0.584651	val: 0.469067	test: 0.407244

Epoch: 26
Loss: 0.16809184868139623
ROC train: 0.905148	val: 0.832077	test: 0.823202
PRC train: 0.593635	val: 0.476751	test: 0.408409

Epoch: 27
Loss: 0.16661105275252827
ROC train: 0.905451	val: 0.832356	test: 0.827465
PRC train: 0.598852	val: 0.479534	test: 0.411456

Epoch: 28
Loss: 0.16802524591691487
ROC train: 0.908523	val: 0.828877	test: 0.828170
PRC train: 0.605350	val: 0.468484	test: 0.411046

Epoch: 29
Loss: 0.16673366731627948
ROC train: 0.907702	val: 0.829555	test: 0.828734
PRC train: 0.612300	val: 0.473493	test: 0.412436

Epoch: 30
Loss: 0.16565625591226993
ROC train: 0.911976	val: 0.828065	test: 0.822240
PRC train: 0.619786	val: 0.465952	test: 0.416432

Epoch: 31
Loss: 0.1639235541131001
ROC train: 0.912479	val: 0.826477	test: 0.819796
PRC train: 0.622382	val: 0.469622	test: 0.420108

Epoch: 32
Loss: 0.16327548954882218
ROC train: 0.914077	val: 0.825820	test: 0.821431
PRC train: 0.619700	val: 0.468006	test: 0.418836

Epoch: 33
Loss: 0.16060455364096857Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: tox21
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/tox21/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/tox21/random/train_prop=0.8/tox21_random_4_26-05_09-58-59  ]
[ Using Seed :  4  ]
[ Using device :  cuda:2  ]
Dataset: tox21
Data: Data(edge_attr=[302190, 2], edge_index=[2, 302190], id=[7831], x=[145459, 2], y=[93972])
MoleculeDataset(7831)
randomly split
Data(edge_attr=[26, 2], edge_index=[2, 26], id=[1], x=[13, 2], y=[12])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=12, bias=True)
)
Epoch: 1
Loss: 0.5301922044193603
ROC train: 0.698867	val: 0.682588	test: 0.651049
PRC train: 0.193004	val: 0.185961	test: 0.165269

Epoch: 2
Loss: 0.3225635072672538
ROC train: 0.762464	val: 0.727117	test: 0.709112
PRC train: 0.298308	val: 0.265343	test: 0.208275

Epoch: 3
Loss: 0.2426333754891262
ROC train: 0.792789	val: 0.755120	test: 0.746880
PRC train: 0.325288	val: 0.291500	test: 0.239994

Epoch: 4
Loss: 0.21626453229399165
ROC train: 0.802039	val: 0.758199	test: 0.752438
PRC train: 0.346174	val: 0.313740	test: 0.258055

Epoch: 5
Loss: 0.20823514205972984
ROC train: 0.819993	val: 0.770155	test: 0.774282
PRC train: 0.385354	val: 0.341811	test: 0.313373

Epoch: 6
Loss: 0.20369404501402177
ROC train: 0.824903	val: 0.782217	test: 0.777554
PRC train: 0.403487	val: 0.346257	test: 0.301966

Epoch: 7
Loss: 0.2005701198832391
ROC train: 0.833881	val: 0.784099	test: 0.785143
PRC train: 0.405979	val: 0.354055	test: 0.298905

Epoch: 8
Loss: 0.19720805050849274
ROC train: 0.841728	val: 0.789689	test: 0.795965
PRC train: 0.430194	val: 0.367551	test: 0.325797

Epoch: 9
Loss: 0.19511515502811277
ROC train: 0.848209	val: 0.794901	test: 0.804062
PRC train: 0.441921	val: 0.359342	test: 0.336659

Epoch: 10
Loss: 0.1927665032249859
ROC train: 0.856581	val: 0.794909	test: 0.800173
PRC train: 0.457614	val: 0.373858	test: 0.343505

Epoch: 11
Loss: 0.19155272900598175
ROC train: 0.863269	val: 0.805532	test: 0.807021
PRC train: 0.476424	val: 0.382049	test: 0.354544

Epoch: 12
Loss: 0.18867231978630958
ROC train: 0.864293	val: 0.801262	test: 0.802129
PRC train: 0.476965	val: 0.402905	test: 0.357271

Epoch: 13
Loss: 0.18684842352728437
ROC train: 0.867060	val: 0.804437	test: 0.812443
PRC train: 0.489678	val: 0.407830	test: 0.360075

Epoch: 14
Loss: 0.1859422256547338
ROC train: 0.869952	val: 0.804956	test: 0.804360
PRC train: 0.504373	val: 0.409940	test: 0.362443

Epoch: 15
Loss: 0.18282364343188806
ROC train: 0.876814	val: 0.811390	test: 0.811411
PRC train: 0.521403	val: 0.414184	test: 0.383860

Epoch: 16
Loss: 0.18086244314080818
ROC train: 0.877877	val: 0.809884	test: 0.811231
PRC train: 0.521534	val: 0.422793	test: 0.377415

Epoch: 17
Loss: 0.180357231929638
ROC train: 0.877855	val: 0.815920	test: 0.809002
PRC train: 0.530084	val: 0.430849	test: 0.379125

Epoch: 18
Loss: 0.18002276286141541
ROC train: 0.885589	val: 0.814602	test: 0.815163
PRC train: 0.550422	val: 0.433394	test: 0.378534

Epoch: 19
Loss: 0.1765389896137597
ROC train: 0.886303	val: 0.811025	test: 0.808218
PRC train: 0.552721	val: 0.435747	test: 0.377657

Epoch: 20
Loss: 0.176847488978873
ROC train: 0.887076	val: 0.811766	test: 0.817038
PRC train: 0.559009	val: 0.436215	test: 0.376976

Epoch: 21
Loss: 0.17494752969557406
ROC train: 0.890412	val: 0.817924	test: 0.816158
PRC train: 0.562323	val: 0.428153	test: 0.384630

Epoch: 22
Loss: 0.173313348859622
ROC train: 0.895164	val: 0.814783	test: 0.822881
PRC train: 0.581756	val: 0.432886	test: 0.391897

Epoch: 23
Loss: 0.17050312273724677
ROC train: 0.897319	val: 0.817707	test: 0.817331
PRC train: 0.581637	val: 0.441043	test: 0.382761

Epoch: 24
Loss: 0.17203501641687527
ROC train: 0.898140	val: 0.819526	test: 0.820268
PRC train: 0.589800	val: 0.456628	test: 0.395751

Epoch: 25
Loss: 0.16987114519237723
ROC train: 0.902088	val: 0.818263	test: 0.816394
PRC train: 0.596645	val: 0.449082	test: 0.393827

Epoch: 26
Loss: 0.16785130052753094
ROC train: 0.904442	val: 0.818527	test: 0.820723
PRC train: 0.607352	val: 0.461562	test: 0.389273

Epoch: 27
Loss: 0.1672877155982108
ROC train: 0.906272	val: 0.825835	test: 0.822416
PRC train: 0.615317	val: 0.476834	test: 0.402838

Epoch: 28
Loss: 0.16772504767767263
ROC train: 0.910493	val: 0.824446	test: 0.829330
PRC train: 0.626315	val: 0.475105	test: 0.407938

Epoch: 29
Loss: 0.16506443542386065
ROC train: 0.911843	val: 0.831372	test: 0.835054
PRC train: 0.627086	val: 0.491154	test: 0.428614

Epoch: 30
Loss: 0.16534454614402236
ROC train: 0.908193	val: 0.817842	test: 0.823103
PRC train: 0.615840	val: 0.458196	test: 0.413631

Epoch: 31
Loss: 0.1635707039404909
ROC train: 0.903912	val: 0.822159	test: 0.821017
PRC train: 0.591231	val: 0.459708	test: 0.406610

Epoch: 32
Loss: 0.1626655997881466
ROC train: 0.912252	val: 0.819390	test: 0.822819
PRC train: 0.631341	val: 0.467783	test: 0.407304

Epoch: 33
Loss: 0.16151207576983098
ROC train: 0.916561	val: 0.828440	test: 0.812847
PRC train: 0.631441	val: 0.417746	test: 0.423156

Epoch: 34
Loss: 0.16153686657329902
ROC train: 0.918513	val: 0.828023	test: 0.815153
PRC train: 0.643161	val: 0.411782	test: 0.417326

Epoch: 35
Loss: 0.161308988409164
ROC train: 0.921300	val: 0.829797	test: 0.816334
PRC train: 0.646438	val: 0.408808	test: 0.426706

Epoch: 36
Loss: 0.1596736328486814
ROC train: 0.922901	val: 0.836604	test: 0.818807
PRC train: 0.648696	val: 0.421654	test: 0.435588

Epoch: 37
Loss: 0.15943540451741617
ROC train: 0.922345	val: 0.831249	test: 0.817526
PRC train: 0.654746	val: 0.411416	test: 0.436986

Epoch: 38
Loss: 0.15673299431201207
ROC train: 0.922687	val: 0.825391	test: 0.815298
PRC train: 0.654365	val: 0.399842	test: 0.417295

Epoch: 39
Loss: 0.15707557221635615
ROC train: 0.925176	val: 0.830507	test: 0.819148
PRC train: 0.662906	val: 0.412166	test: 0.419158

Epoch: 40
Loss: 0.15931385215552493
ROC train: 0.924226	val: 0.829632	test: 0.810613
PRC train: 0.660301	val: 0.404429	test: 0.413353

Epoch: 41
Loss: 0.1582612628386801
ROC train: 0.926787	val: 0.830490	test: 0.814139
PRC train: 0.671826	val: 0.423097	test: 0.416539

Epoch: 42
Loss: 0.15620038226347405
ROC train: 0.925777	val: 0.818743	test: 0.812950
PRC train: 0.667469	val: 0.411436	test: 0.434195

Epoch: 43
Loss: 0.15479306568627205
ROC train: 0.933607	val: 0.831200	test: 0.816825
PRC train: 0.693185	val: 0.424447	test: 0.437699

Epoch: 44
Loss: 0.15294478928741442
ROC train: 0.934700	val: 0.832259	test: 0.819232
PRC train: 0.691904	val: 0.418398	test: 0.427240

Epoch: 45
Loss: 0.15532300947352254
ROC train: 0.932690	val: 0.823699	test: 0.813741
PRC train: 0.691030	val: 0.426010	test: 0.443050

Epoch: 46
Loss: 0.15181039856042014
ROC train: 0.935114	val: 0.831702	test: 0.814047
PRC train: 0.694903	val: 0.425249	test: 0.427122

Epoch: 47
Loss: 0.15046127396873302
ROC train: 0.938194	val: 0.835831	test: 0.815778
PRC train: 0.703506	val: 0.421486	test: 0.436373

Epoch: 48
Loss: 0.15002232666300266
ROC train: 0.939376	val: 0.828747	test: 0.810181
PRC train: 0.708270	val: 0.416041	test: 0.425279

Epoch: 49
Loss: 0.15129250809994935
ROC train: 0.938274	val: 0.826521	test: 0.818203
PRC train: 0.711163	val: 0.406855	test: 0.427815

Epoch: 50
Loss: 0.1491675371251809
ROC train: 0.943163	val: 0.831254	test: 0.817855
PRC train: 0.720374	val: 0.417537	test: 0.432011

Epoch: 51
Loss: 0.14516650363169417
ROC train: 0.940556	val: 0.828676	test: 0.815939
PRC train: 0.712718	val: 0.424775	test: 0.424513

Epoch: 52
Loss: 0.14427855952537977
ROC train: 0.943735	val: 0.835381	test: 0.817897
PRC train: 0.724681	val: 0.421586	test: 0.428540

Epoch: 53
Loss: 0.14593874434562112
ROC train: 0.944184	val: 0.827419	test: 0.810323
PRC train: 0.720901	val: 0.433523	test: 0.436483

Epoch: 54
Loss: 0.146685368022068
ROC train: 0.946282	val: 0.830187	test: 0.807923
PRC train: 0.731144	val: 0.427019	test: 0.419676

Epoch: 55
Loss: 0.1458179786337478
ROC train: 0.946920	val: 0.836743	test: 0.809610
PRC train: 0.735887	val: 0.451930	test: 0.431841

Epoch: 56
Loss: 0.14420120121491578
ROC train: 0.949886	val: 0.838413	test: 0.818417
PRC train: 0.745406	val: 0.433279	test: 0.432572

Epoch: 57
Loss: 0.14327304190910256
ROC train: 0.948921	val: 0.826822	test: 0.805445
PRC train: 0.734977	val: 0.422405	test: 0.429253

Epoch: 58
Loss: 0.14178404284381999
ROC train: 0.949900	val: 0.832302	test: 0.814511
PRC train: 0.747874	val: 0.437174	test: 0.442502

Epoch: 59
Loss: 0.14094550781071108
ROC train: 0.951888	val: 0.829727	test: 0.806720
PRC train: 0.754499	val: 0.426608	test: 0.425495

Epoch: 60
Loss: 0.13824967394639
ROC train: 0.951662	val: 0.832977	test: 0.811148
PRC train: 0.748881	val: 0.424301	test: 0.426131

Epoch: 61
Loss: 0.1433190862571637
ROC train: 0.953495	val: 0.832605	test: 0.808990
PRC train: 0.760427	val: 0.437405	test: 0.440425

Epoch: 62
Loss: 0.14190287101052834
ROC train: 0.952369	val: 0.828222	test: 0.813339
PRC train: 0.756965	val: 0.427676	test: 0.431151

Epoch: 63
Loss: 0.14042481561143522
ROC train: 0.955968	val: 0.829713	test: 0.808018
PRC train: 0.769001	val: 0.443733	test: 0.428903

Epoch: 64
Loss: 0.1375314599406023
ROC train: 0.957286	val: 0.821428	test: 0.810074
PRC train: 0.776100	val: 0.422694	test: 0.434582

Epoch: 65
Loss: 0.13649184673476167
ROC train: 0.955780	val: 0.837739	test: 0.809876
PRC train: 0.774390	val: 0.445565	test: 0.435207

Epoch: 66
Loss: 0.1343080193142244
ROC train: 0.958330	val: 0.829407	test: 0.808800
PRC train: 0.780171	val: 0.443879	test: 0.443277

Epoch: 67
Loss: 0.1364036875531
ROC train: 0.957650	val: 0.820403	test: 0.802926
PRC train: 0.769461	val: 0.430311	test: 0.427985

Epoch: 68
Loss: 0.13490107589063072
ROC train: 0.958913	val: 0.832909	test: 0.812118
PRC train: 0.782917	val: 0.442366	test: 0.448171

Epoch: 69
Loss: 0.1323329101857422
ROC train: 0.959770	val: 0.829317	test: 0.808117
PRC train: 0.781737	val: 0.436565	test: 0.430435

Epoch: 70
Loss: 0.1303911312155729
ROC train: 0.962153	val: 0.834647	test: 0.810200
PRC train: 0.797781	val: 0.443409	test: 0.441534

Epoch: 71
Loss: 0.13020454489999464
ROC train: 0.962503	val: 0.832818	test: 0.810182
PRC train: 0.799078	val: 0.447286	test: 0.436477

Epoch: 72
Loss: 0.1296367509846412
ROC train: 0.961352	val: 0.827389	test: 0.813564
PRC train: 0.788166	val: 0.416450	test: 0.428940

Epoch: 73
Loss: 0.12829437706470745
ROC train: 0.965729	val: 0.832726	test: 0.808468
PRC train: 0.810662	val: 0.451097	test: 0.427599

Epoch: 74
Loss: 0.12538184981807185
ROC train: 0.963933	val: 0.832590	test: 0.814573
PRC train: 0.796152	val: 0.414363	test: 0.419067

Epoch: 75
Loss: 0.12649367580429116
ROC train: 0.967737	val: 0.830602	test: 0.805714
PRC train: 0.816507	val: 0.449666	test: 0.427968

Epoch: 76
Loss: 0.12650067143211216
ROC train: 0.966986	val: 0.831570	test: 0.808244
PRC train: 0.816866	val: 0.430535	test: 0.423928

Epoch: 77
Loss: 0.12872956579778527
ROC train: 0.967909	val: 0.831609	test: 0.808714
PRC train: 0.821545	val: 0.438836	test: 0.433591

Epoch: 78
Loss: 0.12598416933763437
ROC train: 0.969215	val: 0.829001	test: 0.807475
PRC train: 0.825735	val: 0.446059	test: 0.431580

Epoch: 79
Loss: 0.12448087916339103
ROC train: 0.968719	val: 0.832860	test: 0.804908
PRC train: 0.818970	val: 0.444976	test: 0.431707

Epoch: 80
Loss: 0.12805318126148066
ROC train: 0.966959	val: 0.830570	test: 0.801465
PRC train: 0.805931	val: 0.439446	test: 0.431256

Epoch: 81
Loss: 0.12465374361191024
ROC train: 0.971492	val: 0.828433	test: 0.811201
PRC train: 0.832479	val: 0.434405	test: 0.443797

Epoch: 82
Loss: 0.12081740724196437
ROC train: 0.971326	val: 0.834637	test: 0.808498
PRC train: 0.831844	val: 0.453703	test: 0.448290

Epoch: 83
Loss: 0.1205614789970865
ROC train: 0.971740	val: 0.826007	test: 0.809774
PRC train: 0.835005	val: 0.434071	test: 0.436529

Epoch: 84
Loss: 0.12266158651622378
ROC train: 0.973303	val: 0.829760	test: 0.808080
PRC train: 0.844679	val: 0.457779	test: 0.437363

Epoch: 85
Loss: 0.12020957602837852
ROC train: 0.975494	val: 0.823127	test: 0.799902
PRC train: 0.848554	val: 0.448189	test: 0.438055

Epoch: 86
Loss: 0.12117008135237227
ROC train: 0.973658	val: 0.824620	test: 0.799551
PRC train: 0.838804	val: 0.450037	test: 0.432902

Epoch: 87
Loss: 0.12134670558583736
ROC train: 0.975786	val: 0.827959	test: 0.803589
PRC train: 0.848551	val: 0.453756	test: 0.436157

Epoch: 88
Loss: 0.11577422959850701
ROC train: 0.976641	val: 0.824794	test: 0.802561
PRC train: 0.853283	val: 0.445328	test: 0.438430

Epoch: 89
Loss: 0.11776151812754031
ROC train: 0.977410	val: 0.825753	test: 0.800302
PRC train: 0.862553	val: 0.454164	test: 0.439251

Epoch: 90
Loss: 0.11649106920727502
ROC train: 0.976311	val: 0.830052	test: 0.804059
PRC train: 0.850823	val: 0.451480	test: 0.431457

Epoch: 91
Loss: 0.11701873317271537
ROC train: 0.978397	val: 0.819954	test: 0.793301
PRC train: 0.860884	val: 0.452682	test: 0.435934

Epoch: 92
Loss: 0.11945503634902768
ROC train: 0.977845	val: 0.829099	test: 0.804583
PRC train: 0.864227	val: 0.447242	test: 0.448741

Epoch: 93
Loss: 0.11350660412871748
ROC train: 0.978518	val: 0.825560	test: 0.799163
PRC train: 0.864701	val: 0.445592	test: 0.441143

Epoch: 94
Loss: 0.11350466770677203
ROC train: 0.910833	val: 0.833508	test: 0.811401
PRC train: 0.626321	val: 0.421886	test: 0.407115

Epoch: 34
Loss: 0.16358288910035684
ROC train: 0.913124	val: 0.833817	test: 0.811953
PRC train: 0.628987	val: 0.419281	test: 0.404800

Epoch: 35
Loss: 0.16750479934251522
ROC train: 0.912794	val: 0.829460	test: 0.817210
PRC train: 0.630421	val: 0.411877	test: 0.405265

Epoch: 36
Loss: 0.16457934290564546
ROC train: 0.913768	val: 0.834048	test: 0.821062
PRC train: 0.635321	val: 0.416050	test: 0.403128

Epoch: 37
Loss: 0.16270462640438438
ROC train: 0.918798	val: 0.835065	test: 0.818391
PRC train: 0.648553	val: 0.423329	test: 0.409979

Epoch: 38
Loss: 0.15954354938252466
ROC train: 0.918054	val: 0.831030	test: 0.814669
PRC train: 0.652923	val: 0.420060	test: 0.411774

Epoch: 39
Loss: 0.15856125699367818
ROC train: 0.922223	val: 0.834445	test: 0.815470
PRC train: 0.662410	val: 0.425821	test: 0.416824

Epoch: 40
Loss: 0.1600879731599488
ROC train: 0.922910	val: 0.827486	test: 0.809424
PRC train: 0.657412	val: 0.422156	test: 0.410378

Epoch: 41
Loss: 0.1565733667739356
ROC train: 0.925634	val: 0.838568	test: 0.812946
PRC train: 0.665883	val: 0.427554	test: 0.412330

Epoch: 42
Loss: 0.15871672559102973
ROC train: 0.927757	val: 0.832080	test: 0.815689
PRC train: 0.671105	val: 0.415428	test: 0.409234

Epoch: 43
Loss: 0.1564047940714277
ROC train: 0.926566	val: 0.826009	test: 0.814091
PRC train: 0.661700	val: 0.413209	test: 0.410244

Epoch: 44
Loss: 0.15587326559040277
ROC train: 0.927522	val: 0.831363	test: 0.818054
PRC train: 0.667951	val: 0.425630	test: 0.421664

Epoch: 45
Loss: 0.15662174183356103
ROC train: 0.930525	val: 0.830016	test: 0.817976
PRC train: 0.684578	val: 0.408503	test: 0.413223

Epoch: 46
Loss: 0.1535692619243831
ROC train: 0.930785	val: 0.833362	test: 0.815462
PRC train: 0.685889	val: 0.420544	test: 0.420053

Epoch: 47
Loss: 0.15133174188180346
ROC train: 0.933600	val: 0.829893	test: 0.813682
PRC train: 0.691592	val: 0.426033	test: 0.429011

Epoch: 48
Loss: 0.1536175050778551
ROC train: 0.934669	val: 0.833505	test: 0.818825
PRC train: 0.695621	val: 0.412547	test: 0.412586

Epoch: 49
Loss: 0.1514731167586697
ROC train: 0.934523	val: 0.827126	test: 0.808523
PRC train: 0.696360	val: 0.420702	test: 0.430015

Epoch: 50
Loss: 0.15200787418208883
ROC train: 0.937307	val: 0.835897	test: 0.820157
PRC train: 0.709458	val: 0.427288	test: 0.435312

Epoch: 51
Loss: 0.14953169976111863
ROC train: 0.937321	val: 0.830168	test: 0.810252
PRC train: 0.699059	val: 0.426869	test: 0.417028

Epoch: 52
Loss: 0.14946964867092602
ROC train: 0.939903	val: 0.830117	test: 0.814467
PRC train: 0.714700	val: 0.420191	test: 0.416220

Epoch: 53
Loss: 0.14610537842987323
ROC train: 0.939793	val: 0.834159	test: 0.806519
PRC train: 0.709108	val: 0.433332	test: 0.412315

Epoch: 54
Loss: 0.14853811988428323
ROC train: 0.943361	val: 0.833327	test: 0.811623
PRC train: 0.722480	val: 0.433363	test: 0.423959

Epoch: 55
Loss: 0.14643781256490757
ROC train: 0.945493	val: 0.833278	test: 0.814007
PRC train: 0.737741	val: 0.432268	test: 0.429246

Epoch: 56
Loss: 0.1431101101374819
ROC train: 0.940491	val: 0.831599	test: 0.810873
PRC train: 0.722074	val: 0.430111	test: 0.411781

Epoch: 57
Loss: 0.1453274394562211
ROC train: 0.947471	val: 0.826431	test: 0.807289
PRC train: 0.744065	val: 0.417509	test: 0.414525

Epoch: 58
Loss: 0.1415434985334633
ROC train: 0.948654	val: 0.830347	test: 0.810489
PRC train: 0.748898	val: 0.409055	test: 0.401072

Epoch: 59
Loss: 0.14067813189200448
ROC train: 0.948819	val: 0.827486	test: 0.806487
PRC train: 0.741780	val: 0.432092	test: 0.411650

Epoch: 60
Loss: 0.14316734837937617
ROC train: 0.949323	val: 0.829836	test: 0.814026
PRC train: 0.747447	val: 0.439929	test: 0.429923

Epoch: 61
Loss: 0.14208467438176214
ROC train: 0.948481	val: 0.828109	test: 0.808099
PRC train: 0.740412	val: 0.425326	test: 0.416437

Epoch: 62
Loss: 0.1397873223477952
ROC train: 0.952830	val: 0.834956	test: 0.818893
PRC train: 0.762195	val: 0.431131	test: 0.426854

Epoch: 63
Loss: 0.13824225881489108
ROC train: 0.950087	val: 0.833360	test: 0.814621
PRC train: 0.754586	val: 0.438882	test: 0.427861

Epoch: 64
Loss: 0.14005948652494193
ROC train: 0.951316	val: 0.834228	test: 0.813666
PRC train: 0.754858	val: 0.433395	test: 0.413435

Epoch: 65
Loss: 0.14109256161824693
ROC train: 0.952548	val: 0.821857	test: 0.809283
PRC train: 0.763343	val: 0.417101	test: 0.410119

Epoch: 66
Loss: 0.1364169206441189
ROC train: 0.953564	val: 0.839322	test: 0.814563
PRC train: 0.763117	val: 0.446044	test: 0.427465

Epoch: 67
Loss: 0.1355691483700645
ROC train: 0.957993	val: 0.827369	test: 0.815566
PRC train: 0.780967	val: 0.425550	test: 0.436408

Epoch: 68
Loss: 0.13445884909348688
ROC train: 0.957609	val: 0.828454	test: 0.807951
PRC train: 0.770802	val: 0.440539	test: 0.423331

Epoch: 69
Loss: 0.1352958372406544
ROC train: 0.959884	val: 0.826558	test: 0.808704
PRC train: 0.788051	val: 0.424883	test: 0.427618

Epoch: 70
Loss: 0.1355311498076383
ROC train: 0.960786	val: 0.829751	test: 0.810129
PRC train: 0.791628	val: 0.427968	test: 0.421942

Epoch: 71
Loss: 0.13267657126283708
ROC train: 0.960801	val: 0.825820	test: 0.807204
PRC train: 0.791296	val: 0.433214	test: 0.431503

Epoch: 72
Loss: 0.1304310662029516
ROC train: 0.961132	val: 0.828144	test: 0.809861
PRC train: 0.792457	val: 0.429279	test: 0.416643

Epoch: 73
Loss: 0.13354895922936846
ROC train: 0.962254	val: 0.814349	test: 0.797433
PRC train: 0.793609	val: 0.415785	test: 0.414814

Epoch: 74
Loss: 0.13040070789554067
ROC train: 0.963933	val: 0.832645	test: 0.809479
PRC train: 0.803669	val: 0.438950	test: 0.418706

Epoch: 75
Loss: 0.13225961650734924
ROC train: 0.964045	val: 0.828597	test: 0.808565
PRC train: 0.802671	val: 0.431676	test: 0.413514

Epoch: 76
Loss: 0.12967439183690413
ROC train: 0.967100	val: 0.822848	test: 0.802233
PRC train: 0.815748	val: 0.439875	test: 0.418146

Epoch: 77
Loss: 0.13052163244123963
ROC train: 0.965506	val: 0.824724	test: 0.799042
PRC train: 0.809697	val: 0.443424	test: 0.418554

Epoch: 78
Loss: 0.12714510048604397
ROC train: 0.967960	val: 0.820047	test: 0.805912
PRC train: 0.815671	val: 0.422462	test: 0.409121

Epoch: 79
Loss: 0.12558696338131034
ROC train: 0.968146	val: 0.823204	test: 0.804080
PRC train: 0.826767	val: 0.436704	test: 0.411872

Epoch: 80
Loss: 0.12691038743465924
ROC train: 0.965549	val: 0.826523	test: 0.804951
PRC train: 0.812772	val: 0.438118	test: 0.420025

Epoch: 81
Loss: 0.12405136764505213
ROC train: 0.969640	val: 0.825094	test: 0.803315
PRC train: 0.823974	val: 0.428945	test: 0.419196

Epoch: 82
Loss: 0.12366208499025644
ROC train: 0.970744	val: 0.825431	test: 0.804049
PRC train: 0.834856	val: 0.440980	test: 0.424082

Epoch: 83
Loss: 0.12203068243377672
ROC train: 0.970546	val: 0.826752	test: 0.806066
PRC train: 0.836527	val: 0.437919	test: 0.427346

Epoch: 84
Loss: 0.12106096788891167
ROC train: 0.971330	val: 0.823491	test: 0.798623
PRC train: 0.835191	val: 0.437413	test: 0.418612

Epoch: 85
Loss: 0.12086721513351939
ROC train: 0.972853	val: 0.817506	test: 0.797259
PRC train: 0.843340	val: 0.428015	test: 0.426755

Epoch: 86
Loss: 0.1235504716364666
ROC train: 0.973369	val: 0.820678	test: 0.801556
PRC train: 0.844445	val: 0.430778	test: 0.418146

Epoch: 87
Loss: 0.12043062523970925
ROC train: 0.973154	val: 0.822709	test: 0.798413
PRC train: 0.843752	val: 0.432950	test: 0.408255

Epoch: 88
Loss: 0.1208042027624651
ROC train: 0.975186	val: 0.826029	test: 0.799140
PRC train: 0.857280	val: 0.437317	test: 0.427288

Epoch: 89
Loss: 0.11796955486907437
ROC train: 0.974332	val: 0.818596	test: 0.792218
PRC train: 0.849309	val: 0.446392	test: 0.412388

Epoch: 90
Loss: 0.1198498442946048
ROC train: 0.975517	val: 0.821022	test: 0.798707
PRC train: 0.855110	val: 0.435451	test: 0.418222

Epoch: 91
Loss: 0.11559573156281347
ROC train: 0.975583	val: 0.828989	test: 0.805965
PRC train: 0.857660	val: 0.435495	test: 0.420213

Epoch: 92
Loss: 0.11688346586813637
ROC train: 0.975782	val: 0.819077	test: 0.794464
PRC train: 0.855269	val: 0.439616	test: 0.419495

Epoch: 93
Loss: 0.11474916998594095
ROC train: 0.976204	val: 0.814677	test: 0.791879
PRC train: 0.859297	val: 0.415365	test: 0.393534

Epoch: 94
Loss: 0.11437837602809578
ROC train: 0.919096	val: 0.822815	test: 0.815520
PRC train: 0.642795	val: 0.412564	test: 0.432086

Epoch: 34
Loss: 0.16342186211587753
ROC train: 0.919610	val: 0.821364	test: 0.810491
PRC train: 0.646973	val: 0.417114	test: 0.434126

Epoch: 35
Loss: 0.15971524507598697
ROC train: 0.921812	val: 0.824612	test: 0.815103
PRC train: 0.659057	val: 0.411211	test: 0.427816

Epoch: 36
Loss: 0.1587095138741269
ROC train: 0.918362	val: 0.826253	test: 0.802102
PRC train: 0.641116	val: 0.435416	test: 0.415533

Epoch: 37
Loss: 0.1584141426607722
ROC train: 0.925639	val: 0.822686	test: 0.810987
PRC train: 0.657317	val: 0.407435	test: 0.423075

Epoch: 38
Loss: 0.15739282440291893
ROC train: 0.925390	val: 0.829426	test: 0.810957
PRC train: 0.666551	val: 0.428783	test: 0.431095

Epoch: 39
Loss: 0.1594455247504608
ROC train: 0.928004	val: 0.818594	test: 0.807962
PRC train: 0.674285	val: 0.422119	test: 0.428696

Epoch: 40
Loss: 0.15706672489558685
ROC train: 0.928733	val: 0.827848	test: 0.813681
PRC train: 0.674244	val: 0.423410	test: 0.440257

Epoch: 41
Loss: 0.1543761416673214
ROC train: 0.932429	val: 0.825365	test: 0.810834
PRC train: 0.680096	val: 0.418860	test: 0.435349

Epoch: 42
Loss: 0.1538251684879286
ROC train: 0.933222	val: 0.818755	test: 0.810101
PRC train: 0.681314	val: 0.414980	test: 0.425540

Epoch: 43
Loss: 0.15612616220039852
ROC train: 0.934510	val: 0.814219	test: 0.809317
PRC train: 0.695538	val: 0.417320	test: 0.439491

Epoch: 44
Loss: 0.15147432812082623
ROC train: 0.934201	val: 0.821239	test: 0.810057
PRC train: 0.690491	val: 0.428818	test: 0.432730

Epoch: 45
Loss: 0.15318923580318433
ROC train: 0.938457	val: 0.821851	test: 0.813138
PRC train: 0.700951	val: 0.421179	test: 0.450205

Epoch: 46
Loss: 0.14969565916649988
ROC train: 0.938791	val: 0.825476	test: 0.813725
PRC train: 0.705352	val: 0.423029	test: 0.439070

Epoch: 47
Loss: 0.15027102998713013
ROC train: 0.939624	val: 0.816106	test: 0.805979
PRC train: 0.709572	val: 0.410224	test: 0.425718

Epoch: 48
Loss: 0.1463611233760337
ROC train: 0.940399	val: 0.825985	test: 0.808059
PRC train: 0.715075	val: 0.436919	test: 0.440434

Epoch: 49
Loss: 0.14557328902926434
ROC train: 0.942786	val: 0.818535	test: 0.810490
PRC train: 0.723996	val: 0.410354	test: 0.431424

Epoch: 50
Loss: 0.14900804164765946
ROC train: 0.943639	val: 0.816928	test: 0.806787
PRC train: 0.729024	val: 0.416774	test: 0.445423

Epoch: 51
Loss: 0.14485911214470332
ROC train: 0.942878	val: 0.828544	test: 0.812444
PRC train: 0.728365	val: 0.423436	test: 0.445120

Epoch: 52
Loss: 0.14407737055363568
ROC train: 0.945488	val: 0.818229	test: 0.804230
PRC train: 0.732529	val: 0.432056	test: 0.441707

Epoch: 53
Loss: 0.14443265341837172
ROC train: 0.947218	val: 0.815952	test: 0.803079
PRC train: 0.737844	val: 0.427306	test: 0.444238

Epoch: 54
Loss: 0.1457151106134628
ROC train: 0.947080	val: 0.825128	test: 0.807285
PRC train: 0.738334	val: 0.427667	test: 0.435070

Epoch: 55
Loss: 0.14255982410149548
ROC train: 0.949338	val: 0.820929	test: 0.802227
PRC train: 0.750240	val: 0.427712	test: 0.440379

Epoch: 56
Loss: 0.14111027230157322
ROC train: 0.951545	val: 0.824469	test: 0.803015
PRC train: 0.756767	val: 0.438285	test: 0.437150

Epoch: 57
Loss: 0.14015764905617956
ROC train: 0.952722	val: 0.817835	test: 0.802529
PRC train: 0.760760	val: 0.439010	test: 0.437004

Epoch: 58
Loss: 0.1376558154752544
ROC train: 0.953882	val: 0.813284	test: 0.804651
PRC train: 0.759797	val: 0.411303	test: 0.426704

Epoch: 59
Loss: 0.13838345268442986
ROC train: 0.951902	val: 0.817635	test: 0.801866
PRC train: 0.753277	val: 0.438819	test: 0.430880

Epoch: 60
Loss: 0.13812027025916018
ROC train: 0.955685	val: 0.820497	test: 0.805247
PRC train: 0.770349	val: 0.439345	test: 0.428833

Epoch: 61
Loss: 0.13768437138496106
ROC train: 0.956349	val: 0.816193	test: 0.805437
PRC train: 0.767083	val: 0.428727	test: 0.439217

Epoch: 62
Loss: 0.13895764917605788
ROC train: 0.954834	val: 0.814368	test: 0.801897
PRC train: 0.766901	val: 0.429171	test: 0.439984

Epoch: 63
Loss: 0.1376565547301186
ROC train: 0.956780	val: 0.810340	test: 0.802326
PRC train: 0.774829	val: 0.418599	test: 0.434456

Epoch: 64
Loss: 0.13619644977765002
ROC train: 0.958796	val: 0.816835	test: 0.804564
PRC train: 0.780732	val: 0.427370	test: 0.442186

Epoch: 65
Loss: 0.1338855101260291
ROC train: 0.959710	val: 0.814194	test: 0.802892
PRC train: 0.783498	val: 0.425272	test: 0.438102

Epoch: 66
Loss: 0.1337010743209466
ROC train: 0.959971	val: 0.815047	test: 0.800694
PRC train: 0.787098	val: 0.420280	test: 0.438508

Epoch: 67
Loss: 0.13356299253435247
ROC train: 0.962796	val: 0.821534	test: 0.813181
PRC train: 0.799113	val: 0.431905	test: 0.446234

Epoch: 68
Loss: 0.1304400764609274
ROC train: 0.959756	val: 0.811798	test: 0.802471
PRC train: 0.780176	val: 0.425997	test: 0.436204

Epoch: 69
Loss: 0.13304250335719744
ROC train: 0.962706	val: 0.820745	test: 0.802461
PRC train: 0.796827	val: 0.438983	test: 0.441014

Epoch: 70
Loss: 0.1291236400774883
ROC train: 0.964437	val: 0.822659	test: 0.805035
PRC train: 0.801686	val: 0.435309	test: 0.440822

Epoch: 71
Loss: 0.1273169607151375
ROC train: 0.965021	val: 0.818948	test: 0.807032
PRC train: 0.810703	val: 0.426771	test: 0.441252

Epoch: 72
Loss: 0.12681802446718338
ROC train: 0.967038	val: 0.823496	test: 0.806315
PRC train: 0.818723	val: 0.445589	test: 0.443672

Epoch: 73
Loss: 0.12621834800027623
ROC train: 0.968604	val: 0.813120	test: 0.802070
PRC train: 0.817453	val: 0.427424	test: 0.441395

Epoch: 74
Loss: 0.1253057489069842
ROC train: 0.967660	val: 0.822162	test: 0.803737
PRC train: 0.819589	val: 0.433589	test: 0.435535

Epoch: 75
Loss: 0.1265833691582777
ROC train: 0.967579	val: 0.818013	test: 0.798122
PRC train: 0.817565	val: 0.438412	test: 0.440132

Epoch: 76
Loss: 0.12554026568338614
ROC train: 0.969242	val: 0.819536	test: 0.799888
PRC train: 0.824531	val: 0.422160	test: 0.433215

Epoch: 77
Loss: 0.12246563143946729
ROC train: 0.969454	val: 0.810686	test: 0.795457
PRC train: 0.826018	val: 0.434325	test: 0.445218

Epoch: 78
Loss: 0.12458293279145422
ROC train: 0.970341	val: 0.818058	test: 0.799936
PRC train: 0.830897	val: 0.429054	test: 0.440713

Epoch: 79
Loss: 0.12443151036676149
ROC train: 0.968102	val: 0.810756	test: 0.804657
PRC train: 0.818872	val: 0.415190	test: 0.437787

Epoch: 80
Loss: 0.12189539030542625
ROC train: 0.967972	val: 0.818226	test: 0.802688
PRC train: 0.825370	val: 0.424587	test: 0.442215

Epoch: 81
Loss: 0.1211634781275078
ROC train: 0.972372	val: 0.819120	test: 0.798007
PRC train: 0.835047	val: 0.428423	test: 0.436429

Epoch: 82
Loss: 0.12105177383708848
ROC train: 0.973472	val: 0.813284	test: 0.796299
PRC train: 0.841382	val: 0.421568	test: 0.432635

Epoch: 83
Loss: 0.11974930368233606
ROC train: 0.975442	val: 0.818257	test: 0.800840
PRC train: 0.851400	val: 0.422363	test: 0.442149

Epoch: 84
Loss: 0.11736980196073145
ROC train: 0.973684	val: 0.819177	test: 0.800057
PRC train: 0.839641	val: 0.413520	test: 0.434238

Epoch: 85
Loss: 0.11916464829571727
ROC train: 0.976156	val: 0.818226	test: 0.795308
PRC train: 0.853242	val: 0.436379	test: 0.426465

Epoch: 86
Loss: 0.11721037279909614
ROC train: 0.976866	val: 0.817123	test: 0.795455
PRC train: 0.854479	val: 0.439012	test: 0.435821

Epoch: 87
Loss: 0.11688555399257827
ROC train: 0.977443	val: 0.816342	test: 0.799521
PRC train: 0.858182	val: 0.433279	test: 0.435970

Epoch: 88
Loss: 0.11573212512789063
ROC train: 0.977325	val: 0.815966	test: 0.796151
PRC train: 0.860818	val: 0.437947	test: 0.441823

Epoch: 89
Loss: 0.11411807722597898
ROC train: 0.978538	val: 0.819914	test: 0.798529
PRC train: 0.865603	val: 0.448874	test: 0.440747

Epoch: 90
Loss: 0.11406400148155428
ROC train: 0.977749	val: 0.815069	test: 0.795134
PRC train: 0.858936	val: 0.443312	test: 0.429996

Epoch: 91
Loss: 0.11488307447897776
ROC train: 0.978308	val: 0.811087	test: 0.793759
PRC train: 0.859196	val: 0.422387	test: 0.432593

Epoch: 92
Loss: 0.1119245538346908
ROC train: 0.978497	val: 0.823755	test: 0.799174
PRC train: 0.864174	val: 0.435202	test: 0.432751

Epoch: 93
Loss: 0.11338213344972808
ROC train: 0.979919	val: 0.815983	test: 0.798558
PRC train: 0.873637	val: 0.435778	test: 0.434260

Epoch: 94
Loss: 0.11315515923450223
ROC train: 0.915720	val: 0.837271	test: 0.829666
PRC train: 0.634803	val: 0.434930	test: 0.450071

Epoch: 34
Loss: 0.1613186385471691
ROC train: 0.914108	val: 0.835002	test: 0.827578
PRC train: 0.628667	val: 0.431831	test: 0.440417

Epoch: 35
Loss: 0.16111470687840498
ROC train: 0.914637	val: 0.830676	test: 0.828070
PRC train: 0.632278	val: 0.433081	test: 0.443506

Epoch: 36
Loss: 0.15997500686358068
ROC train: 0.919512	val: 0.832915	test: 0.828840
PRC train: 0.646724	val: 0.439809	test: 0.458251

Epoch: 37
Loss: 0.15970251824692283
ROC train: 0.920862	val: 0.835921	test: 0.828463
PRC train: 0.644646	val: 0.438623	test: 0.459797

Epoch: 38
Loss: 0.15618645912827597
ROC train: 0.923115	val: 0.832296	test: 0.828070
PRC train: 0.654841	val: 0.442046	test: 0.459829

Epoch: 39
Loss: 0.1545232922541098
ROC train: 0.926384	val: 0.831137	test: 0.829916
PRC train: 0.669913	val: 0.436548	test: 0.456659

Epoch: 40
Loss: 0.15454684260024015
ROC train: 0.926424	val: 0.837131	test: 0.827866
PRC train: 0.667331	val: 0.435977	test: 0.451216

Epoch: 41
Loss: 0.1555798718005819
ROC train: 0.926637	val: 0.831230	test: 0.825783
PRC train: 0.671743	val: 0.428530	test: 0.458362

Epoch: 42
Loss: 0.15269947820357427
ROC train: 0.928456	val: 0.832151	test: 0.824860
PRC train: 0.674805	val: 0.436639	test: 0.460541

Epoch: 43
Loss: 0.15075361654960473
ROC train: 0.932271	val: 0.835369	test: 0.830555
PRC train: 0.683616	val: 0.442422	test: 0.461264

Epoch: 44
Loss: 0.15122126325160593
ROC train: 0.931236	val: 0.832671	test: 0.822735
PRC train: 0.678506	val: 0.437826	test: 0.453515

Epoch: 45
Loss: 0.14924214482341594
ROC train: 0.936242	val: 0.830579	test: 0.827099
PRC train: 0.701597	val: 0.431857	test: 0.460814

Epoch: 46
Loss: 0.14966855404225077
ROC train: 0.932525	val: 0.823398	test: 0.816312
PRC train: 0.689518	val: 0.442088	test: 0.461799

Epoch: 47
Loss: 0.1484560347319563
ROC train: 0.936937	val: 0.829801	test: 0.826175
PRC train: 0.696422	val: 0.438947	test: 0.465683

Epoch: 48
Loss: 0.14744031449522066
ROC train: 0.939032	val: 0.831942	test: 0.817909
PRC train: 0.701138	val: 0.429268	test: 0.456544

Epoch: 49
Loss: 0.1468501175190218
ROC train: 0.937659	val: 0.832926	test: 0.830622
PRC train: 0.702209	val: 0.443091	test: 0.466563

Epoch: 50
Loss: 0.1464821352968995
ROC train: 0.940534	val: 0.830567	test: 0.825195
PRC train: 0.717338	val: 0.437762	test: 0.463767

Epoch: 51
Loss: 0.14683352027865848
ROC train: 0.942228	val: 0.834842	test: 0.834250
PRC train: 0.718256	val: 0.433630	test: 0.461503

Epoch: 52
Loss: 0.14448540982170288
ROC train: 0.944143	val: 0.825214	test: 0.827475
PRC train: 0.730262	val: 0.435013	test: 0.470812

Epoch: 53
Loss: 0.1414184882271883
ROC train: 0.942891	val: 0.817842	test: 0.823498
PRC train: 0.718088	val: 0.426585	test: 0.464825

Epoch: 54
Loss: 0.14450810870922487
ROC train: 0.944494	val: 0.824740	test: 0.817626
PRC train: 0.726409	val: 0.426509	test: 0.445744

Epoch: 55
Loss: 0.1436554146997855
ROC train: 0.947719	val: 0.826971	test: 0.820878
PRC train: 0.737273	val: 0.435045	test: 0.461718

Epoch: 56
Loss: 0.14223183600043285
ROC train: 0.944940	val: 0.828897	test: 0.830153
PRC train: 0.715472	val: 0.420636	test: 0.460417

Epoch: 57
Loss: 0.1392742252706742
ROC train: 0.949852	val: 0.828070	test: 0.821962
PRC train: 0.748075	val: 0.431095	test: 0.460941

Epoch: 58
Loss: 0.13970431196506639
ROC train: 0.952106	val: 0.828913	test: 0.826985
PRC train: 0.754247	val: 0.448353	test: 0.471429

Epoch: 59
Loss: 0.1377098991597664
ROC train: 0.952422	val: 0.829933	test: 0.825413
PRC train: 0.754091	val: 0.440533	test: 0.468262

Epoch: 60
Loss: 0.13998656074584767
ROC train: 0.951649	val: 0.821509	test: 0.819797
PRC train: 0.754230	val: 0.427135	test: 0.458972

Epoch: 61
Loss: 0.1384380177000202
ROC train: 0.953807	val: 0.831441	test: 0.828268
PRC train: 0.760690	val: 0.441952	test: 0.479247

Epoch: 62
Loss: 0.13768892520124779
ROC train: 0.953016	val: 0.830688	test: 0.817276
PRC train: 0.757831	val: 0.449064	test: 0.463267

Epoch: 63
Loss: 0.13713859363828543
ROC train: 0.956635	val: 0.827115	test: 0.816920
PRC train: 0.770138	val: 0.450644	test: 0.467489

Epoch: 64
Loss: 0.1342864999230485
ROC train: 0.959061	val: 0.827055	test: 0.821208
PRC train: 0.780580	val: 0.442178	test: 0.468519

Epoch: 65
Loss: 0.13388784813328303
ROC train: 0.955229	val: 0.835459	test: 0.827216
PRC train: 0.772167	val: 0.459864	test: 0.469297

Epoch: 66
Loss: 0.13206278307747918
ROC train: 0.959644	val: 0.830876	test: 0.820165
PRC train: 0.780868	val: 0.440603	test: 0.465140

Epoch: 67
Loss: 0.13026130389667
ROC train: 0.958126	val: 0.830813	test: 0.818365
PRC train: 0.777732	val: 0.440618	test: 0.466850

Epoch: 68
Loss: 0.13227524182376077
ROC train: 0.961364	val: 0.827072	test: 0.818203
PRC train: 0.788345	val: 0.436068	test: 0.459098

Epoch: 69
Loss: 0.12968454973997365
ROC train: 0.962002	val: 0.823426	test: 0.820502
PRC train: 0.789462	val: 0.421481	test: 0.451871

Epoch: 70
Loss: 0.13103634180699258
ROC train: 0.961650	val: 0.824463	test: 0.822552
PRC train: 0.789693	val: 0.429178	test: 0.468946

Epoch: 71
Loss: 0.12811318149564777
ROC train: 0.960609	val: 0.828760	test: 0.820475
PRC train: 0.786300	val: 0.453731	test: 0.458593

Epoch: 72
Loss: 0.13161421674712695
ROC train: 0.963747	val: 0.829535	test: 0.818853
PRC train: 0.798212	val: 0.439497	test: 0.464253

Epoch: 73
Loss: 0.1273592127865393
ROC train: 0.962030	val: 0.824446	test: 0.820376
PRC train: 0.789655	val: 0.438017	test: 0.465064

Epoch: 74
Loss: 0.12662975752837194
ROC train: 0.965674	val: 0.829585	test: 0.822504
PRC train: 0.807785	val: 0.433276	test: 0.470749

Epoch: 75
Loss: 0.12650210839418202
ROC train: 0.966112	val: 0.827881	test: 0.819239
PRC train: 0.809028	val: 0.447709	test: 0.467781

Epoch: 76
Loss: 0.12583498047362915
ROC train: 0.964255	val: 0.824990	test: 0.808550
PRC train: 0.797146	val: 0.424896	test: 0.454118

Epoch: 77
Loss: 0.12430728405065557
ROC train: 0.968421	val: 0.833886	test: 0.819450
PRC train: 0.821063	val: 0.442681	test: 0.467173

Epoch: 78
Loss: 0.1266840175675844
ROC train: 0.969264	val: 0.830952	test: 0.823810
PRC train: 0.828248	val: 0.439925	test: 0.479232

Epoch: 79
Loss: 0.12389290032157238
ROC train: 0.966417	val: 0.825600	test: 0.819030
PRC train: 0.813127	val: 0.439324	test: 0.469821

Epoch: 80
Loss: 0.12380032254087804
ROC train: 0.970798	val: 0.833535	test: 0.820653
PRC train: 0.831695	val: 0.446666	test: 0.472797

Epoch: 81
Loss: 0.12204617484029055
ROC train: 0.969871	val: 0.827973	test: 0.814550
PRC train: 0.827270	val: 0.420630	test: 0.463059

Epoch: 82
Loss: 0.12178514418155477
ROC train: 0.970687	val: 0.828229	test: 0.814965
PRC train: 0.830641	val: 0.434457	test: 0.467947

Epoch: 83
Loss: 0.12032153432277445
ROC train: 0.970716	val: 0.825843	test: 0.817805
PRC train: 0.827676	val: 0.422886	test: 0.461226

Epoch: 84
Loss: 0.11966580436684296
ROC train: 0.972879	val: 0.828896	test: 0.812991
PRC train: 0.840320	val: 0.435836	test: 0.459534

Epoch: 85
Loss: 0.11992349195232936
ROC train: 0.972543	val: 0.829989	test: 0.813983
PRC train: 0.840726	val: 0.441204	test: 0.468651

Epoch: 86
Loss: 0.12023717641927423
ROC train: 0.973099	val: 0.826893	test: 0.813708
PRC train: 0.843271	val: 0.443122	test: 0.466332

Epoch: 87
Loss: 0.12165334738111229
ROC train: 0.973976	val: 0.826964	test: 0.813687
PRC train: 0.843286	val: 0.438872	test: 0.468396

Epoch: 88
Loss: 0.11787016190553214
ROC train: 0.972132	val: 0.823880	test: 0.815844
PRC train: 0.838223	val: 0.427504	test: 0.468960

Epoch: 89
Loss: 0.11827120861782271
ROC train: 0.975262	val: 0.832064	test: 0.816334
PRC train: 0.852001	val: 0.443119	test: 0.476156

Epoch: 90
Loss: 0.11613980555382698
ROC train: 0.975509	val: 0.823852	test: 0.810474
PRC train: 0.853996	val: 0.441008	test: 0.464070

Epoch: 91
Loss: 0.11459445926480857
ROC train: 0.975529	val: 0.820381	test: 0.810957
PRC train: 0.850518	val: 0.417939	test: 0.457165

Epoch: 92
Loss: 0.11549807035463501
ROC train: 0.975404	val: 0.826097	test: 0.810318
PRC train: 0.849988	val: 0.434326	test: 0.459586

Epoch: 93
Loss: 0.11485572964985287
ROC train: 0.977501	val: 0.828219	test: 0.805559
PRC train: 0.861423	val: 0.442508	test: 0.458608

Epoch: 94
Loss: 0.1129489130914175
ROC train: 0.914401	val: 0.836761	test: 0.821764
PRC train: 0.635222	val: 0.444412	test: 0.437238

Epoch: 34
Loss: 0.1599053936971253
ROC train: 0.916784	val: 0.828092	test: 0.824082
PRC train: 0.640443	val: 0.435642	test: 0.440579

Epoch: 35
Loss: 0.1601521647300353
ROC train: 0.919326	val: 0.835535	test: 0.823441
PRC train: 0.644457	val: 0.447675	test: 0.436885

Epoch: 36
Loss: 0.15942850215605175
ROC train: 0.916950	val: 0.834494	test: 0.820702
PRC train: 0.643909	val: 0.441612	test: 0.420229

Epoch: 37
Loss: 0.15819838332978065
ROC train: 0.921352	val: 0.840074	test: 0.828195
PRC train: 0.660373	val: 0.443671	test: 0.436186

Epoch: 38
Loss: 0.15604421069122867
ROC train: 0.924011	val: 0.833388	test: 0.832567
PRC train: 0.665754	val: 0.440862	test: 0.448585

Epoch: 39
Loss: 0.1556279331823471
ROC train: 0.924373	val: 0.834072	test: 0.824989
PRC train: 0.655620	val: 0.446460	test: 0.425582

Epoch: 40
Loss: 0.15567431557419234
ROC train: 0.928416	val: 0.831141	test: 0.828300
PRC train: 0.676710	val: 0.428742	test: 0.441780

Epoch: 41
Loss: 0.1509272008037456
ROC train: 0.928454	val: 0.831635	test: 0.824983
PRC train: 0.672311	val: 0.431122	test: 0.439749

Epoch: 42
Loss: 0.1510647474584417
ROC train: 0.931095	val: 0.828673	test: 0.819433
PRC train: 0.686670	val: 0.442957	test: 0.429723

Epoch: 43
Loss: 0.15268296217221686
ROC train: 0.933737	val: 0.838022	test: 0.828891
PRC train: 0.692650	val: 0.454383	test: 0.450063

Epoch: 44
Loss: 0.15047054218268288
ROC train: 0.934401	val: 0.833145	test: 0.822179
PRC train: 0.694584	val: 0.433934	test: 0.439635

Epoch: 45
Loss: 0.14948914207473207
ROC train: 0.932408	val: 0.833905	test: 0.822646
PRC train: 0.684476	val: 0.443827	test: 0.439879

Epoch: 46
Loss: 0.14827253114732908
ROC train: 0.932355	val: 0.828630	test: 0.827464
PRC train: 0.689523	val: 0.444859	test: 0.443032

Epoch: 47
Loss: 0.14883608125023223
ROC train: 0.936108	val: 0.832936	test: 0.821837
PRC train: 0.699715	val: 0.450465	test: 0.443121

Epoch: 48
Loss: 0.14806264944809278
ROC train: 0.938090	val: 0.831291	test: 0.820423
PRC train: 0.705960	val: 0.455787	test: 0.444563

Epoch: 49
Loss: 0.14459611416902268
ROC train: 0.942554	val: 0.832793	test: 0.827548
PRC train: 0.715803	val: 0.456965	test: 0.453967

Epoch: 50
Loss: 0.14349257278800656
ROC train: 0.942186	val: 0.838035	test: 0.827971
PRC train: 0.718876	val: 0.441960	test: 0.443863

Epoch: 51
Loss: 0.14231398801617867
ROC train: 0.944273	val: 0.837639	test: 0.825247
PRC train: 0.730373	val: 0.442050	test: 0.448673

Epoch: 52
Loss: 0.14403782734041545
ROC train: 0.944341	val: 0.836784	test: 0.825712
PRC train: 0.724484	val: 0.456423	test: 0.449039

Epoch: 53
Loss: 0.1423165761756987
ROC train: 0.944580	val: 0.831803	test: 0.822829
PRC train: 0.727444	val: 0.460432	test: 0.446018

Epoch: 54
Loss: 0.1422545714811478
ROC train: 0.946864	val: 0.830977	test: 0.828192
PRC train: 0.734157	val: 0.444675	test: 0.441236

Epoch: 55
Loss: 0.13996762421949008
ROC train: 0.948111	val: 0.841531	test: 0.824424
PRC train: 0.742539	val: 0.454234	test: 0.452511

Epoch: 56
Loss: 0.13860588768608617
ROC train: 0.947585	val: 0.831211	test: 0.821668
PRC train: 0.738926	val: 0.451744	test: 0.462088

Epoch: 57
Loss: 0.13913653032037357
ROC train: 0.951005	val: 0.839225	test: 0.828571
PRC train: 0.757973	val: 0.457882	test: 0.459867

Epoch: 58
Loss: 0.13784914620777577
ROC train: 0.951646	val: 0.834636	test: 0.822666
PRC train: 0.745054	val: 0.439598	test: 0.437664

Epoch: 59
Loss: 0.13650960438797444
ROC train: 0.952201	val: 0.832182	test: 0.820303
PRC train: 0.750681	val: 0.449159	test: 0.454773

Epoch: 60
Loss: 0.13728388094123395
ROC train: 0.955217	val: 0.839116	test: 0.823784
PRC train: 0.769471	val: 0.446247	test: 0.453510

Epoch: 61
Loss: 0.13587392215348584
ROC train: 0.952865	val: 0.819213	test: 0.816140
PRC train: 0.758986	val: 0.434663	test: 0.452814

Epoch: 62
Loss: 0.13651112100707088
ROC train: 0.955781	val: 0.836450	test: 0.824854
PRC train: 0.771906	val: 0.442419	test: 0.456442

Epoch: 63
Loss: 0.13499260979966643
ROC train: 0.958452	val: 0.827546	test: 0.820000
PRC train: 0.780728	val: 0.450737	test: 0.448562

Epoch: 64
Loss: 0.13244338300178682
ROC train: 0.959179	val: 0.830453	test: 0.822885
PRC train: 0.785908	val: 0.443183	test: 0.455688

Epoch: 65
Loss: 0.13097585708840986
ROC train: 0.958015	val: 0.830236	test: 0.823114
PRC train: 0.778502	val: 0.437266	test: 0.462074

Epoch: 66
Loss: 0.1307133776894975
ROC train: 0.959579	val: 0.830740	test: 0.819520
PRC train: 0.786494	val: 0.446314	test: 0.448040

Epoch: 67
Loss: 0.13294880803155207
ROC train: 0.959083	val: 0.833574	test: 0.818594
PRC train: 0.783803	val: 0.443581	test: 0.450753

Epoch: 68
Loss: 0.12870011476877494
ROC train: 0.963534	val: 0.833865	test: 0.817134
PRC train: 0.795357	val: 0.452644	test: 0.453045

Epoch: 69
Loss: 0.13031284737020044
ROC train: 0.961769	val: 0.824884	test: 0.818698
PRC train: 0.789727	val: 0.447950	test: 0.456752

Epoch: 70
Loss: 0.130067798043017
ROC train: 0.964722	val: 0.821529	test: 0.814535
PRC train: 0.805444	val: 0.444566	test: 0.445109

Epoch: 71
Loss: 0.12761451298486828
ROC train: 0.965570	val: 0.824504	test: 0.811997
PRC train: 0.806828	val: 0.454346	test: 0.447575

Epoch: 72
Loss: 0.12651892225607322
ROC train: 0.964874	val: 0.824550	test: 0.817948
PRC train: 0.803465	val: 0.438390	test: 0.451288

Epoch: 73
Loss: 0.12545365672093173
ROC train: 0.967928	val: 0.826104	test: 0.811753
PRC train: 0.816086	val: 0.452245	test: 0.452639

Epoch: 74
Loss: 0.12497574361151444
ROC train: 0.966006	val: 0.828082	test: 0.812225
PRC train: 0.814607	val: 0.453820	test: 0.445720

Epoch: 75
Loss: 0.12401183687836938
ROC train: 0.965756	val: 0.818884	test: 0.809845
PRC train: 0.805725	val: 0.451643	test: 0.449515

Epoch: 76
Loss: 0.1241963460109185
ROC train: 0.969389	val: 0.821227	test: 0.814044
PRC train: 0.822778	val: 0.449658	test: 0.447889

Epoch: 77
Loss: 0.1220613143868388
ROC train: 0.969615	val: 0.834305	test: 0.816385
PRC train: 0.825737	val: 0.443289	test: 0.448568

Epoch: 78
Loss: 0.12315424796405218
ROC train: 0.969772	val: 0.827381	test: 0.809294
PRC train: 0.823777	val: 0.443178	test: 0.446419

Epoch: 79
Loss: 0.12271805922602548
ROC train: 0.970451	val: 0.828354	test: 0.817337
PRC train: 0.826281	val: 0.454885	test: 0.453864

Epoch: 80
Loss: 0.12140927464330536
ROC train: 0.962237	val: 0.817697	test: 0.813704
PRC train: 0.786267	val: 0.443035	test: 0.446106

Epoch: 81
Loss: 0.12069556961415212
ROC train: 0.971044	val: 0.822944	test: 0.810703
PRC train: 0.833881	val: 0.452585	test: 0.449374

Epoch: 82
Loss: 0.11975522500856527
ROC train: 0.972944	val: 0.825897	test: 0.819177
PRC train: 0.840863	val: 0.448870	test: 0.460026

Epoch: 83
Loss: 0.11845033804599034
ROC train: 0.973640	val: 0.825146	test: 0.814732
PRC train: 0.839434	val: 0.455181	test: 0.460316

Epoch: 84
Loss: 0.1207560288196249
ROC train: 0.974431	val: 0.823984	test: 0.808624
PRC train: 0.843688	val: 0.470341	test: 0.455136

Epoch: 85
Loss: 0.11945407168121212
ROC train: 0.972229	val: 0.828599	test: 0.816045
PRC train: 0.834359	val: 0.446817	test: 0.452063

Epoch: 86
Loss: 0.1154726770514508
ROC train: 0.973536	val: 0.822056	test: 0.816260
PRC train: 0.840264	val: 0.457654	test: 0.455164

Epoch: 87
Loss: 0.11395986366446258
ROC train: 0.976094	val: 0.822953	test: 0.810243
PRC train: 0.854669	val: 0.452795	test: 0.441289

Epoch: 88
Loss: 0.11526092465190498
ROC train: 0.977339	val: 0.827005	test: 0.807497
PRC train: 0.856997	val: 0.463347	test: 0.451403

Epoch: 89
Loss: 0.1134652752236525
ROC train: 0.975224	val: 0.829953	test: 0.811481
PRC train: 0.847531	val: 0.457361	test: 0.442175

Epoch: 90
Loss: 0.11292061664390046
ROC train: 0.978393	val: 0.822162	test: 0.807354
PRC train: 0.861787	val: 0.453899	test: 0.449395

Epoch: 91
Loss: 0.11302823980439775
ROC train: 0.978768	val: 0.828475	test: 0.805667
PRC train: 0.866997	val: 0.462334	test: 0.449629

Epoch: 92
Loss: 0.11119574134819606
ROC train: 0.979168	val: 0.827310	test: 0.804813
PRC train: 0.867953	val: 0.458328	test: 0.449377

Epoch: 93
Loss: 0.11133725687150799
ROC train: 0.979250	val: 0.825333	test: 0.809862
PRC train: 0.870154	val: 0.449279	test: 0.448326

Epoch: 94
Loss: 0.11271138965840967
ROC train: 0.915587	val: 0.830851	test: 0.834826
PRC train: 0.629532	val: 0.432959	test: 0.460125

Epoch: 34
Loss: 0.16207807857893472
ROC train: 0.915274	val: 0.832195	test: 0.824690
PRC train: 0.631134	val: 0.431113	test: 0.455205

Epoch: 35
Loss: 0.16012243444423743
ROC train: 0.917565	val: 0.828022	test: 0.825626
PRC train: 0.640250	val: 0.414349	test: 0.443567

Epoch: 36
Loss: 0.15672669648663412
ROC train: 0.919505	val: 0.832583	test: 0.823420
PRC train: 0.642952	val: 0.436423	test: 0.454803

Epoch: 37
Loss: 0.157138183105245
ROC train: 0.922631	val: 0.830778	test: 0.825896
PRC train: 0.653380	val: 0.438891	test: 0.453671

Epoch: 38
Loss: 0.157642825326601
ROC train: 0.925013	val: 0.835443	test: 0.826951
PRC train: 0.652348	val: 0.447271	test: 0.453532

Epoch: 39
Loss: 0.1563115201832374
ROC train: 0.922386	val: 0.830604	test: 0.831494
PRC train: 0.658622	val: 0.438084	test: 0.454991

Epoch: 40
Loss: 0.15440642074738628
ROC train: 0.925887	val: 0.832901	test: 0.825366
PRC train: 0.661951	val: 0.437559	test: 0.450071

Epoch: 41
Loss: 0.1538186211010137
ROC train: 0.928293	val: 0.837673	test: 0.828388
PRC train: 0.673136	val: 0.429823	test: 0.448863

Epoch: 42
Loss: 0.15340506449536281
ROC train: 0.930350	val: 0.833075	test: 0.823886
PRC train: 0.674029	val: 0.431782	test: 0.441049

Epoch: 43
Loss: 0.15211495341674958
ROC train: 0.932446	val: 0.833332	test: 0.829296
PRC train: 0.690108	val: 0.445321	test: 0.454789

Epoch: 44
Loss: 0.14942894829205125
ROC train: 0.933491	val: 0.840059	test: 0.829337
PRC train: 0.691639	val: 0.446746	test: 0.457941

Epoch: 45
Loss: 0.15061030966699426
ROC train: 0.935638	val: 0.830475	test: 0.826008
PRC train: 0.692386	val: 0.432780	test: 0.446396

Epoch: 46
Loss: 0.15077602107122307
ROC train: 0.937876	val: 0.833143	test: 0.828176
PRC train: 0.699615	val: 0.449932	test: 0.443862

Epoch: 47
Loss: 0.1486762850814839
ROC train: 0.937716	val: 0.829905	test: 0.829139
PRC train: 0.706025	val: 0.446583	test: 0.450774

Epoch: 48
Loss: 0.14634238799934662
ROC train: 0.938659	val: 0.823696	test: 0.821994
PRC train: 0.699085	val: 0.449681	test: 0.452449

Epoch: 49
Loss: 0.14583730689278618
ROC train: 0.941365	val: 0.837422	test: 0.830320
PRC train: 0.717888	val: 0.441309	test: 0.453842

Epoch: 50
Loss: 0.1451893753154924
ROC train: 0.939355	val: 0.832451	test: 0.816867
PRC train: 0.709599	val: 0.438752	test: 0.445558

Epoch: 51
Loss: 0.14463650925053903
ROC train: 0.943334	val: 0.835931	test: 0.827772
PRC train: 0.714010	val: 0.454548	test: 0.453289

Epoch: 52
Loss: 0.14387519215133554
ROC train: 0.946792	val: 0.834616	test: 0.829567
PRC train: 0.737377	val: 0.451094	test: 0.461859

Epoch: 53
Loss: 0.14180858300380428
ROC train: 0.941896	val: 0.827156	test: 0.811039
PRC train: 0.713388	val: 0.439968	test: 0.440759

Epoch: 54
Loss: 0.1420120004661283
ROC train: 0.945935	val: 0.837887	test: 0.831536
PRC train: 0.725010	val: 0.438204	test: 0.460683

Epoch: 55
Loss: 0.14405191955527114
ROC train: 0.948117	val: 0.829287	test: 0.826969
PRC train: 0.735864	val: 0.439499	test: 0.460926

Epoch: 56
Loss: 0.13860042029867922
ROC train: 0.950487	val: 0.834455	test: 0.826727
PRC train: 0.741209	val: 0.436738	test: 0.458908

Epoch: 57
Loss: 0.14033837892379597
ROC train: 0.949327	val: 0.831654	test: 0.820875
PRC train: 0.741171	val: 0.454889	test: 0.457905

Epoch: 58
Loss: 0.13895678247461868
ROC train: 0.952310	val: 0.833327	test: 0.822755
PRC train: 0.753840	val: 0.457096	test: 0.454140

Epoch: 59
Loss: 0.13776180012619316
ROC train: 0.954178	val: 0.837967	test: 0.824002
PRC train: 0.751933	val: 0.439701	test: 0.448549

Epoch: 60
Loss: 0.1366094070799506
ROC train: 0.953749	val: 0.834885	test: 0.825978
PRC train: 0.757697	val: 0.462266	test: 0.455152

Epoch: 61
Loss: 0.13762274799362498
ROC train: 0.953648	val: 0.835580	test: 0.826336
PRC train: 0.754217	val: 0.438689	test: 0.455532

Epoch: 62
Loss: 0.13669808503742906
ROC train: 0.955985	val: 0.831910	test: 0.824470
PRC train: 0.764889	val: 0.456408	test: 0.454835

Epoch: 63
Loss: 0.13661500429551876
ROC train: 0.957009	val: 0.842995	test: 0.825785
PRC train: 0.770347	val: 0.464159	test: 0.450227

Epoch: 64
Loss: 0.13457935543589783
ROC train: 0.957226	val: 0.839551	test: 0.822845
PRC train: 0.776049	val: 0.452132	test: 0.452112

Epoch: 65
Loss: 0.1329339296005939
ROC train: 0.959041	val: 0.833443	test: 0.823253
PRC train: 0.781424	val: 0.457103	test: 0.460129

Epoch: 66
Loss: 0.13043971835657844
ROC train: 0.958904	val: 0.828688	test: 0.819595
PRC train: 0.776948	val: 0.450625	test: 0.447637

Epoch: 67
Loss: 0.1316162770247309
ROC train: 0.961049	val: 0.834939	test: 0.825189
PRC train: 0.786145	val: 0.457522	test: 0.457252

Epoch: 68
Loss: 0.13166112878965758
ROC train: 0.961260	val: 0.828667	test: 0.815219
PRC train: 0.789595	val: 0.456802	test: 0.457115

Epoch: 69
Loss: 0.13069558158721525
ROC train: 0.961450	val: 0.834057	test: 0.823981
PRC train: 0.791119	val: 0.454566	test: 0.463617

Epoch: 70
Loss: 0.12921696275926148
ROC train: 0.964503	val: 0.834086	test: 0.819257
PRC train: 0.798167	val: 0.452220	test: 0.456820

Epoch: 71
Loss: 0.12675914119747622
ROC train: 0.963098	val: 0.829338	test: 0.816814
PRC train: 0.797926	val: 0.461249	test: 0.444842

Epoch: 72
Loss: 0.12800744069596065
ROC train: 0.964880	val: 0.826061	test: 0.818949
PRC train: 0.800350	val: 0.456712	test: 0.458274

Epoch: 73
Loss: 0.12658229330822054
ROC train: 0.965061	val: 0.837394	test: 0.826950
PRC train: 0.802962	val: 0.454307	test: 0.449775

Epoch: 74
Loss: 0.12451146867874609
ROC train: 0.966672	val: 0.834554	test: 0.822235
PRC train: 0.809301	val: 0.450959	test: 0.450605

Epoch: 75
Loss: 0.12649528680095926
ROC train: 0.967627	val: 0.825882	test: 0.819061
PRC train: 0.809338	val: 0.457478	test: 0.455478

Epoch: 76
Loss: 0.12469368275623297
ROC train: 0.969245	val: 0.827769	test: 0.822421
PRC train: 0.825784	val: 0.453177	test: 0.461500

Epoch: 77
Loss: 0.12464461268238149
ROC train: 0.969221	val: 0.830254	test: 0.818292
PRC train: 0.816703	val: 0.463528	test: 0.467365

Epoch: 78
Loss: 0.12264625459173407
ROC train: 0.969682	val: 0.833467	test: 0.825881
PRC train: 0.821264	val: 0.451052	test: 0.450365

Epoch: 79
Loss: 0.12469266359143183
ROC train: 0.969626	val: 0.830635	test: 0.818986
PRC train: 0.823836	val: 0.460444	test: 0.456549

Epoch: 80
Loss: 0.11993082913451082
ROC train: 0.971045	val: 0.828187	test: 0.818180
PRC train: 0.830295	val: 0.461870	test: 0.450579

Epoch: 81
Loss: 0.12155832232035203
ROC train: 0.971682	val: 0.827760	test: 0.816807
PRC train: 0.829963	val: 0.435381	test: 0.453753

Epoch: 82
Loss: 0.12047046589249613
ROC train: 0.972718	val: 0.828049	test: 0.822332
PRC train: 0.837582	val: 0.449712	test: 0.463240

Epoch: 83
Loss: 0.11924384008468697
ROC train: 0.973858	val: 0.829973	test: 0.808232
PRC train: 0.840647	val: 0.452112	test: 0.450040

Epoch: 84
Loss: 0.11749560684081647
ROC train: 0.972747	val: 0.830181	test: 0.816928
PRC train: 0.841765	val: 0.447545	test: 0.456922

Epoch: 85
Loss: 0.1203958852951774
ROC train: 0.974306	val: 0.818377	test: 0.811586
PRC train: 0.846057	val: 0.446656	test: 0.455598

Epoch: 86
Loss: 0.11618136151655648
ROC train: 0.975009	val: 0.825253	test: 0.820569
PRC train: 0.850295	val: 0.454583	test: 0.470958

Epoch: 87
Loss: 0.11848267476853551
ROC train: 0.975415	val: 0.825274	test: 0.821217
PRC train: 0.848912	val: 0.455898	test: 0.462156

Epoch: 88
Loss: 0.11716866055600099
ROC train: 0.975981	val: 0.825576	test: 0.818127
PRC train: 0.854741	val: 0.445808	test: 0.462301

Epoch: 89
Loss: 0.11312354606432411
ROC train: 0.976681	val: 0.826749	test: 0.815400
PRC train: 0.858573	val: 0.456287	test: 0.459771

Epoch: 90
Loss: 0.11607630534308555
ROC train: 0.976168	val: 0.828308	test: 0.815877
PRC train: 0.856125	val: 0.435946	test: 0.456812

Epoch: 91
Loss: 0.11432046311538663
ROC train: 0.976795	val: 0.819231	test: 0.806777
PRC train: 0.854697	val: 0.434087	test: 0.446837

Epoch: 92
Loss: 0.11305368845159874
ROC train: 0.978439	val: 0.826188	test: 0.819769
PRC train: 0.868648	val: 0.450914	test: 0.462573

Epoch: 93
Loss: 0.1130013569427593
ROC train: 0.978464	val: 0.819795	test: 0.820178
PRC train: 0.866872	val: 0.436123	test: 0.460539

Epoch: 94
Loss: 0.11164180174147989
ROC train: 0.918406	val: 0.831160	test: 0.835904
PRC train: 0.638649	val: 0.506404	test: 0.440918

Epoch: 34
Loss: 0.16184965833465767
ROC train: 0.918295	val: 0.827813	test: 0.832611
PRC train: 0.631596	val: 0.487900	test: 0.420707

Epoch: 35
Loss: 0.16015105682110975
ROC train: 0.918497	val: 0.832490	test: 0.833844
PRC train: 0.642044	val: 0.517339	test: 0.441366

Epoch: 36
Loss: 0.1590320492045639
ROC train: 0.921391	val: 0.832980	test: 0.828534
PRC train: 0.651395	val: 0.510334	test: 0.444818

Epoch: 37
Loss: 0.1587218683123368
ROC train: 0.925011	val: 0.831118	test: 0.835667
PRC train: 0.656100	val: 0.499189	test: 0.443345

Epoch: 38
Loss: 0.1564138207750954
ROC train: 0.924457	val: 0.821621	test: 0.834056
PRC train: 0.652810	val: 0.498081	test: 0.437711

Epoch: 39
Loss: 0.15495108447914466
ROC train: 0.928046	val: 0.830436	test: 0.829487
PRC train: 0.670594	val: 0.506956	test: 0.434044

Epoch: 40
Loss: 0.15428173798799835
ROC train: 0.928599	val: 0.826712	test: 0.825898
PRC train: 0.670359	val: 0.502501	test: 0.431941

Epoch: 41
Loss: 0.15177919654326344
ROC train: 0.930884	val: 0.823877	test: 0.827446
PRC train: 0.672865	val: 0.499149	test: 0.437844

Epoch: 42
Loss: 0.15281363956337643
ROC train: 0.930893	val: 0.825859	test: 0.829829
PRC train: 0.671574	val: 0.508400	test: 0.432642

Epoch: 43
Loss: 0.15398626615209693
ROC train: 0.933900	val: 0.827593	test: 0.827159
PRC train: 0.686373	val: 0.496187	test: 0.426784

Epoch: 44
Loss: 0.15306337470404324
ROC train: 0.936764	val: 0.825133	test: 0.835893
PRC train: 0.692917	val: 0.484515	test: 0.436988

Epoch: 45
Loss: 0.15052785611916059
ROC train: 0.937344	val: 0.830370	test: 0.835097
PRC train: 0.699827	val: 0.501688	test: 0.453967

Epoch: 46
Loss: 0.14961043004818766
ROC train: 0.938305	val: 0.832360	test: 0.836417
PRC train: 0.698194	val: 0.502246	test: 0.449852

Epoch: 47
Loss: 0.1474027303960303
ROC train: 0.940559	val: 0.829616	test: 0.837225
PRC train: 0.705358	val: 0.506538	test: 0.445358

Epoch: 48
Loss: 0.14816910699243624
ROC train: 0.941697	val: 0.830462	test: 0.833521
PRC train: 0.710839	val: 0.507942	test: 0.438655

Epoch: 49
Loss: 0.1468825601706446
ROC train: 0.942259	val: 0.834566	test: 0.834422
PRC train: 0.717997	val: 0.513001	test: 0.455928

Epoch: 50
Loss: 0.14538366885020237
ROC train: 0.943352	val: 0.826884	test: 0.835246
PRC train: 0.720413	val: 0.504613	test: 0.446383

Epoch: 51
Loss: 0.1451427578827538
ROC train: 0.944839	val: 0.826711	test: 0.828942
PRC train: 0.725563	val: 0.501284	test: 0.439221

Epoch: 52
Loss: 0.14492662708286574
ROC train: 0.944306	val: 0.830279	test: 0.835220
PRC train: 0.721737	val: 0.501115	test: 0.453697

Epoch: 53
Loss: 0.14322686642726823
ROC train: 0.947279	val: 0.830360	test: 0.836756
PRC train: 0.731186	val: 0.505331	test: 0.451225

Epoch: 54
Loss: 0.14133830019751628
ROC train: 0.948416	val: 0.822068	test: 0.828407
PRC train: 0.736948	val: 0.494240	test: 0.443159

Epoch: 55
Loss: 0.14110236877361623
ROC train: 0.949632	val: 0.829525	test: 0.829692
PRC train: 0.744513	val: 0.506695	test: 0.441253

Epoch: 56
Loss: 0.13881758950272569
ROC train: 0.951293	val: 0.821993	test: 0.824678
PRC train: 0.749914	val: 0.509246	test: 0.436948

Epoch: 57
Loss: 0.13774928947215165
ROC train: 0.951984	val: 0.821649	test: 0.828034
PRC train: 0.754808	val: 0.516986	test: 0.434812

Epoch: 58
Loss: 0.13833001481393556
ROC train: 0.954700	val: 0.823063	test: 0.817251
PRC train: 0.759325	val: 0.509601	test: 0.430571

Epoch: 59
Loss: 0.13871209026672188
ROC train: 0.953117	val: 0.822085	test: 0.820871
PRC train: 0.759620	val: 0.507238	test: 0.435952

Epoch: 60
Loss: 0.1379981385586276
ROC train: 0.954468	val: 0.822593	test: 0.828252
PRC train: 0.763241	val: 0.505486	test: 0.440664

Epoch: 61
Loss: 0.13585062393498618
ROC train: 0.956424	val: 0.826884	test: 0.824581
PRC train: 0.767933	val: 0.497710	test: 0.438533

Epoch: 62
Loss: 0.13425615655069204
ROC train: 0.957180	val: 0.817497	test: 0.822331
PRC train: 0.771341	val: 0.502275	test: 0.442059

Epoch: 63
Loss: 0.13443495666242553
ROC train: 0.958024	val: 0.826042	test: 0.821187
PRC train: 0.779968	val: 0.516751	test: 0.444298

Epoch: 64
Loss: 0.13547667208305297
ROC train: 0.958294	val: 0.820860	test: 0.827750
PRC train: 0.777354	val: 0.509153	test: 0.440443

Epoch: 65
Loss: 0.1337394941582701
ROC train: 0.960338	val: 0.818425	test: 0.818563
PRC train: 0.786986	val: 0.504806	test: 0.440575

Epoch: 66
Loss: 0.1319130112802114
ROC train: 0.961631	val: 0.822548	test: 0.822081
PRC train: 0.794473	val: 0.517793	test: 0.456163

Epoch: 67
Loss: 0.13337842163531594
ROC train: 0.961931	val: 0.822540	test: 0.826595
PRC train: 0.791240	val: 0.513116	test: 0.439357

Epoch: 68
Loss: 0.13167016743465104
ROC train: 0.961704	val: 0.821554	test: 0.817292
PRC train: 0.788907	val: 0.503865	test: 0.439528

Epoch: 69
Loss: 0.13045793298463346
ROC train: 0.961036	val: 0.814784	test: 0.813042
PRC train: 0.785481	val: 0.507962	test: 0.436375

Epoch: 70
Loss: 0.12989385423794883
ROC train: 0.964691	val: 0.827633	test: 0.821650
PRC train: 0.806714	val: 0.511168	test: 0.452391

Epoch: 71
Loss: 0.12920680530379502
ROC train: 0.963843	val: 0.820896	test: 0.826563
PRC train: 0.798370	val: 0.499475	test: 0.444676

Epoch: 72
Loss: 0.12659976478897708
ROC train: 0.966062	val: 0.816760	test: 0.818839
PRC train: 0.812675	val: 0.504678	test: 0.448521

Epoch: 73
Loss: 0.12703619439802655
ROC train: 0.966283	val: 0.820995	test: 0.819073
PRC train: 0.814208	val: 0.495709	test: 0.453531

Epoch: 74
Loss: 0.12742582808844585
ROC train: 0.968501	val: 0.824989	test: 0.820475
PRC train: 0.822034	val: 0.505269	test: 0.458060

Epoch: 75
Loss: 0.12529438218332886
ROC train: 0.968150	val: 0.823658	test: 0.814481
PRC train: 0.817850	val: 0.502072	test: 0.453323

Epoch: 76
Loss: 0.12486318169551551
ROC train: 0.967552	val: 0.817565	test: 0.820543
PRC train: 0.818289	val: 0.509058	test: 0.456446

Epoch: 77
Loss: 0.12530580903440344
ROC train: 0.969295	val: 0.813195	test: 0.814849
PRC train: 0.823942	val: 0.497336	test: 0.448001

Epoch: 78
Loss: 0.12402697459204051
ROC train: 0.969906	val: 0.820458	test: 0.819361
PRC train: 0.827823	val: 0.501052	test: 0.452861

Epoch: 79
Loss: 0.12324789112433468
ROC train: 0.970780	val: 0.820781	test: 0.814241
PRC train: 0.832456	val: 0.501373	test: 0.455024

Epoch: 80
Loss: 0.12258075726834035
ROC train: 0.971045	val: 0.819014	test: 0.821198
PRC train: 0.833162	val: 0.498906	test: 0.449430

Epoch: 81
Loss: 0.12142197570406933
ROC train: 0.972316	val: 0.823901	test: 0.822165
PRC train: 0.838370	val: 0.520080	test: 0.445887

Epoch: 82
Loss: 0.120206525922213
ROC train: 0.972765	val: 0.817930	test: 0.818730
PRC train: 0.839725	val: 0.494395	test: 0.456393

Epoch: 83
Loss: 0.12020485545265741
ROC train: 0.972114	val: 0.816926	test: 0.817080
PRC train: 0.840737	val: 0.496991	test: 0.440503

Epoch: 84
Loss: 0.11907013174965381
ROC train: 0.974214	val: 0.818141	test: 0.815428
PRC train: 0.846328	val: 0.504910	test: 0.446593

Epoch: 85
Loss: 0.11957371160630449
ROC train: 0.973846	val: 0.826652	test: 0.823598
PRC train: 0.846705	val: 0.509633	test: 0.446013

Epoch: 86
Loss: 0.11643307644332994
ROC train: 0.975826	val: 0.826900	test: 0.810626
PRC train: 0.853947	val: 0.515939	test: 0.438842

Epoch: 87
Loss: 0.1171826313171881
ROC train: 0.975589	val: 0.821010	test: 0.816748
PRC train: 0.855962	val: 0.512779	test: 0.440501

Epoch: 88
Loss: 0.11439737689191697
ROC train: 0.973805	val: 0.815130	test: 0.810133
PRC train: 0.842097	val: 0.500149	test: 0.451473

Epoch: 89
Loss: 0.11650733234672445
ROC train: 0.976057	val: 0.815216	test: 0.812234
PRC train: 0.857556	val: 0.497391	test: 0.445523

Epoch: 90
Loss: 0.11706890522027416
ROC train: 0.976187	val: 0.825440	test: 0.806735
PRC train: 0.851522	val: 0.507879	test: 0.433085

Epoch: 91
Loss: 0.11671389160380874
ROC train: 0.975934	val: 0.813999	test: 0.821456
PRC train: 0.858255	val: 0.500626	test: 0.453108

Epoch: 92
Loss: 0.11344793419513456
ROC train: 0.977689	val: 0.823392	test: 0.818593
PRC train: 0.867103	val: 0.503898	test: 0.451026

Epoch: 93
Loss: 0.11266624558042267
ROC train: 0.979202	val: 0.821108	test: 0.806005
PRC train: 0.871301	val: 0.502972	test: 0.454680

Epoch: 94
Loss: 0.11314951838608359
ROC train: 0.915261	val: 0.831004	test: 0.825617
PRC train: 0.630873	val: 0.482307	test: 0.432473

Epoch: 34
Loss: 0.16145822946940847
ROC train: 0.916643	val: 0.817606	test: 0.817016
PRC train: 0.626288	val: 0.485730	test: 0.404152

Epoch: 35
Loss: 0.160964779609354
ROC train: 0.917440	val: 0.819786	test: 0.818253
PRC train: 0.638593	val: 0.473761	test: 0.412864

Epoch: 36
Loss: 0.15963447813523282
ROC train: 0.920726	val: 0.829844	test: 0.823309
PRC train: 0.637541	val: 0.474080	test: 0.431880

Epoch: 37
Loss: 0.15858687836882562
ROC train: 0.920632	val: 0.828888	test: 0.825305
PRC train: 0.650021	val: 0.487626	test: 0.424389

Epoch: 38
Loss: 0.15598014200797908
ROC train: 0.924801	val: 0.822396	test: 0.828347
PRC train: 0.661551	val: 0.471731	test: 0.439173

Epoch: 39
Loss: 0.15587437305803703
ROC train: 0.923668	val: 0.826198	test: 0.828373
PRC train: 0.646065	val: 0.480226	test: 0.429282

Epoch: 40
Loss: 0.1568923175746229
ROC train: 0.926288	val: 0.822796	test: 0.819492
PRC train: 0.659540	val: 0.486963	test: 0.434997

Epoch: 41
Loss: 0.15546779499864352
ROC train: 0.927737	val: 0.827420	test: 0.830420
PRC train: 0.671265	val: 0.499278	test: 0.449027

Epoch: 42
Loss: 0.15525664073169607
ROC train: 0.927390	val: 0.821603	test: 0.823629
PRC train: 0.667434	val: 0.485299	test: 0.417714

Epoch: 43
Loss: 0.1556609077915855
ROC train: 0.930856	val: 0.815529	test: 0.826149
PRC train: 0.679506	val: 0.482895	test: 0.430476

Epoch: 44
Loss: 0.15220486032674857
ROC train: 0.932905	val: 0.821343	test: 0.831599
PRC train: 0.685913	val: 0.496003	test: 0.449165

Epoch: 45
Loss: 0.1506858106646317
ROC train: 0.932630	val: 0.821087	test: 0.818597
PRC train: 0.679157	val: 0.492996	test: 0.430033

Epoch: 46
Loss: 0.15004512116949284
ROC train: 0.933054	val: 0.823142	test: 0.822681
PRC train: 0.684283	val: 0.488269	test: 0.438260

Epoch: 47
Loss: 0.14965302218842433
ROC train: 0.936110	val: 0.824588	test: 0.825942
PRC train: 0.692541	val: 0.488227	test: 0.449121

Epoch: 48
Loss: 0.15068535895412405
ROC train: 0.936331	val: 0.821681	test: 0.825762
PRC train: 0.698667	val: 0.497349	test: 0.440643

Epoch: 49
Loss: 0.14927285385407177
ROC train: 0.937753	val: 0.826099	test: 0.825048
PRC train: 0.704638	val: 0.505309	test: 0.439835

Epoch: 50
Loss: 0.14900090412187997
ROC train: 0.941273	val: 0.820470	test: 0.825418
PRC train: 0.706966	val: 0.503744	test: 0.434163

Epoch: 51
Loss: 0.1450053310194223
ROC train: 0.943219	val: 0.822099	test: 0.830375
PRC train: 0.722347	val: 0.501387	test: 0.459413

Epoch: 52
Loss: 0.14414729965457584
ROC train: 0.942907	val: 0.824808	test: 0.830017
PRC train: 0.725131	val: 0.504465	test: 0.445552

Epoch: 53
Loss: 0.14369280853885363
ROC train: 0.945538	val: 0.820639	test: 0.824466
PRC train: 0.733932	val: 0.504985	test: 0.442719

Epoch: 54
Loss: 0.1441887175150666
ROC train: 0.941281	val: 0.818271	test: 0.814796
PRC train: 0.711882	val: 0.487890	test: 0.433110

Epoch: 55
Loss: 0.1425796760839871
ROC train: 0.946732	val: 0.826411	test: 0.823967
PRC train: 0.741307	val: 0.500835	test: 0.445729

Epoch: 56
Loss: 0.14258699788362406
ROC train: 0.947782	val: 0.823019	test: 0.824451
PRC train: 0.739579	val: 0.509169	test: 0.436534

Epoch: 57
Loss: 0.14041736474911531
ROC train: 0.949401	val: 0.820897	test: 0.821726
PRC train: 0.747051	val: 0.506539	test: 0.441523

Epoch: 58
Loss: 0.14068907487484303
ROC train: 0.948197	val: 0.818931	test: 0.828436
PRC train: 0.735215	val: 0.492778	test: 0.442321

Epoch: 59
Loss: 0.1410623921522922
ROC train: 0.951448	val: 0.821718	test: 0.811941
PRC train: 0.753286	val: 0.491465	test: 0.434320

Epoch: 60
Loss: 0.1397670377052447
ROC train: 0.951547	val: 0.825294	test: 0.832266
PRC train: 0.756222	val: 0.487847	test: 0.449444

Epoch: 61
Loss: 0.13766298505405458
ROC train: 0.953112	val: 0.823277	test: 0.821862
PRC train: 0.760043	val: 0.502813	test: 0.443972

Epoch: 62
Loss: 0.13590448269142763
ROC train: 0.955951	val: 0.817746	test: 0.830060
PRC train: 0.768281	val: 0.491497	test: 0.451498

Epoch: 63
Loss: 0.13651491734874746
ROC train: 0.955440	val: 0.819603	test: 0.828347
PRC train: 0.768866	val: 0.500349	test: 0.448319

Epoch: 64
Loss: 0.1345181241683112
ROC train: 0.956856	val: 0.821130	test: 0.821825
PRC train: 0.776538	val: 0.501356	test: 0.437293

Epoch: 65
Loss: 0.13393582998472378
ROC train: 0.957235	val: 0.820310	test: 0.817137
PRC train: 0.775152	val: 0.502201	test: 0.438839

Epoch: 66
Loss: 0.13480713495373498
ROC train: 0.959409	val: 0.816899	test: 0.827636
PRC train: 0.780643	val: 0.502960	test: 0.442903

Epoch: 67
Loss: 0.1341196679456511
ROC train: 0.948015	val: 0.813516	test: 0.802561
PRC train: 0.732693	val: 0.481181	test: 0.415380

Epoch: 68
Loss: 0.13384048512692306
ROC train: 0.958796	val: 0.815051	test: 0.826902
PRC train: 0.781058	val: 0.513310	test: 0.446953

Epoch: 69
Loss: 0.13179731546815776
ROC train: 0.959327	val: 0.816395	test: 0.825670
PRC train: 0.784018	val: 0.513139	test: 0.433961

Epoch: 70
Loss: 0.13194899666862533
ROC train: 0.963188	val: 0.818577	test: 0.823699
PRC train: 0.799566	val: 0.513061	test: 0.445275

Epoch: 71
Loss: 0.1312269970039509
ROC train: 0.960951	val: 0.824832	test: 0.826974
PRC train: 0.788073	val: 0.506745	test: 0.435503

Epoch: 72
Loss: 0.1317273739828892
ROC train: 0.963753	val: 0.815597	test: 0.824274
PRC train: 0.799615	val: 0.507601	test: 0.437277

Epoch: 73
Loss: 0.1290770435980082
ROC train: 0.964156	val: 0.818611	test: 0.823595
PRC train: 0.801683	val: 0.518155	test: 0.455056

Epoch: 74
Loss: 0.12765244829638556
ROC train: 0.962927	val: 0.812932	test: 0.811868
PRC train: 0.796027	val: 0.498228	test: 0.433280

Epoch: 75
Loss: 0.1262809223510205
ROC train: 0.965371	val: 0.819225	test: 0.827076
PRC train: 0.808160	val: 0.505668	test: 0.443744

Epoch: 76
Loss: 0.12625089096993622
ROC train: 0.966661	val: 0.818633	test: 0.819771
PRC train: 0.811203	val: 0.503751	test: 0.444929

Epoch: 77
Loss: 0.1254517197141471
ROC train: 0.967292	val: 0.814526	test: 0.825856
PRC train: 0.819758	val: 0.496404	test: 0.453268

Epoch: 78
Loss: 0.12694484665804487
ROC train: 0.968134	val: 0.821667	test: 0.822111
PRC train: 0.816416	val: 0.509001	test: 0.436359

Epoch: 79
Loss: 0.12449094808901906
ROC train: 0.968453	val: 0.818434	test: 0.822947
PRC train: 0.822908	val: 0.520455	test: 0.442502

Epoch: 80
Loss: 0.1250835513564008
ROC train: 0.969587	val: 0.806398	test: 0.815447
PRC train: 0.821140	val: 0.506898	test: 0.445524

Epoch: 81
Loss: 0.12401234133103359
ROC train: 0.967874	val: 0.812555	test: 0.821441
PRC train: 0.814594	val: 0.500061	test: 0.445816

Epoch: 82
Loss: 0.12372626147754268
ROC train: 0.968235	val: 0.814948	test: 0.815038
PRC train: 0.813426	val: 0.496091	test: 0.435995

Epoch: 83
Loss: 0.12313951799401192
ROC train: 0.971886	val: 0.819068	test: 0.823111
PRC train: 0.835426	val: 0.514854	test: 0.449338

Epoch: 84
Loss: 0.12212895187795034
ROC train: 0.969521	val: 0.812493	test: 0.817657
PRC train: 0.825519	val: 0.492963	test: 0.443504

Epoch: 85
Loss: 0.11956426035277619
ROC train: 0.972456	val: 0.819779	test: 0.820972
PRC train: 0.838954	val: 0.504921	test: 0.444426

Epoch: 86
Loss: 0.12033614062033898
ROC train: 0.972974	val: 0.818345	test: 0.823209
PRC train: 0.842199	val: 0.515058	test: 0.452169

Epoch: 87
Loss: 0.1190226993502334
ROC train: 0.972429	val: 0.821581	test: 0.823329
PRC train: 0.839048	val: 0.502222	test: 0.452931

Epoch: 88
Loss: 0.1205491359849648
ROC train: 0.973021	val: 0.819961	test: 0.819992
PRC train: 0.843078	val: 0.504750	test: 0.442737

Epoch: 89
Loss: 0.11723924169222819
ROC train: 0.974699	val: 0.818522	test: 0.822124
PRC train: 0.848982	val: 0.509815	test: 0.445832

Epoch: 90
Loss: 0.11924865371643462
ROC train: 0.975163	val: 0.817111	test: 0.806133
PRC train: 0.848097	val: 0.500686	test: 0.445012

Epoch: 91
Loss: 0.11686030121198666
ROC train: 0.975921	val: 0.824297	test: 0.817123
PRC train: 0.855486	val: 0.509008	test: 0.438482

Epoch: 92
Loss: 0.1170823523793324
ROC train: 0.976134	val: 0.819983	test: 0.818475
PRC train: 0.856446	val: 0.506200	test: 0.449770

Epoch: 93
Loss: 0.11574408862845377
ROC train: 0.976694	val: 0.816595	test: 0.814315
PRC train: 0.857961	val: 0.513323	test: 0.440024

Epoch: 94
Loss: 0.11504045306735154
ROC train: 0.916479	val: 0.825174	test: 0.829572
PRC train: 0.645330	val: 0.492209	test: 0.420876

Epoch: 34
Loss: 0.1590717470717542
ROC train: 0.920764	val: 0.826358	test: 0.828736
PRC train: 0.654593	val: 0.494304	test: 0.430465

Epoch: 35
Loss: 0.15922247771973416
ROC train: 0.921080	val: 0.825027	test: 0.826457
PRC train: 0.653395	val: 0.476093	test: 0.424048

Epoch: 36
Loss: 0.15895869611633837
ROC train: 0.923417	val: 0.827333	test: 0.834960
PRC train: 0.665199	val: 0.488500	test: 0.436024

Epoch: 37
Loss: 0.15583267228735076
ROC train: 0.925216	val: 0.828675	test: 0.830782
PRC train: 0.664436	val: 0.482608	test: 0.419721

Epoch: 38
Loss: 0.15675212648355136
ROC train: 0.927131	val: 0.825168	test: 0.825807
PRC train: 0.671957	val: 0.492944	test: 0.423665

Epoch: 39
Loss: 0.1555507746008584
ROC train: 0.925414	val: 0.830396	test: 0.822095
PRC train: 0.667210	val: 0.491848	test: 0.428639

Epoch: 40
Loss: 0.15480333066124594
ROC train: 0.928873	val: 0.829247	test: 0.828812
PRC train: 0.676294	val: 0.486993	test: 0.423879

Epoch: 41
Loss: 0.15436165043463002
ROC train: 0.931061	val: 0.825086	test: 0.823972
PRC train: 0.684682	val: 0.493982	test: 0.427473

Epoch: 42
Loss: 0.153065962867647
ROC train: 0.934624	val: 0.826214	test: 0.833193
PRC train: 0.697305	val: 0.490616	test: 0.443251

Epoch: 43
Loss: 0.1495705271031638
ROC train: 0.935422	val: 0.826583	test: 0.831088
PRC train: 0.699519	val: 0.502506	test: 0.438792

Epoch: 44
Loss: 0.1524819783754202
ROC train: 0.935960	val: 0.823365	test: 0.827051
PRC train: 0.700439	val: 0.487927	test: 0.428251

Epoch: 45
Loss: 0.14949851702544473
ROC train: 0.934838	val: 0.826867	test: 0.828746
PRC train: 0.698854	val: 0.498104	test: 0.428607

Epoch: 46
Loss: 0.14728490819127907
ROC train: 0.935966	val: 0.822433	test: 0.822999
PRC train: 0.701135	val: 0.482311	test: 0.413345

Epoch: 47
Loss: 0.1502113439436446
ROC train: 0.940937	val: 0.824270	test: 0.824411
PRC train: 0.718562	val: 0.491090	test: 0.437914

Epoch: 48
Loss: 0.14787082225937676
ROC train: 0.940109	val: 0.821618	test: 0.824404
PRC train: 0.714139	val: 0.498530	test: 0.435831

Epoch: 49
Loss: 0.14516091213166285
ROC train: 0.940586	val: 0.827795	test: 0.820175
PRC train: 0.717718	val: 0.496373	test: 0.437102

Epoch: 50
Loss: 0.14486283732172134
ROC train: 0.942931	val: 0.823808	test: 0.819401
PRC train: 0.726089	val: 0.502929	test: 0.421245

Epoch: 51
Loss: 0.14527635239492656
ROC train: 0.944279	val: 0.828802	test: 0.823829
PRC train: 0.730542	val: 0.514167	test: 0.431890

Epoch: 52
Loss: 0.14490740368537583
ROC train: 0.945726	val: 0.827424	test: 0.824915
PRC train: 0.738289	val: 0.503633	test: 0.414132

Epoch: 53
Loss: 0.14077431650997105
ROC train: 0.947654	val: 0.828522	test: 0.824031
PRC train: 0.744413	val: 0.503538	test: 0.433862

Epoch: 54
Loss: 0.1415072885702187
ROC train: 0.948284	val: 0.828216	test: 0.815924
PRC train: 0.747681	val: 0.516385	test: 0.424765

Epoch: 55
Loss: 0.1425874301027822
ROC train: 0.949878	val: 0.831310	test: 0.823238
PRC train: 0.755224	val: 0.512670	test: 0.439405

Epoch: 56
Loss: 0.13904651098893067
ROC train: 0.948982	val: 0.825677	test: 0.813705
PRC train: 0.747230	val: 0.506750	test: 0.430262

Epoch: 57
Loss: 0.14001044850062808
ROC train: 0.952389	val: 0.826644	test: 0.820468
PRC train: 0.761955	val: 0.514367	test: 0.439788

Epoch: 58
Loss: 0.1368216011852265
ROC train: 0.952710	val: 0.820817	test: 0.820215
PRC train: 0.761414	val: 0.505614	test: 0.438142

Epoch: 59
Loss: 0.1376906681893807
ROC train: 0.953404	val: 0.818356	test: 0.822555
PRC train: 0.767432	val: 0.513858	test: 0.433401

Epoch: 60
Loss: 0.1367182617291005
ROC train: 0.953802	val: 0.828269	test: 0.817763
PRC train: 0.769989	val: 0.508031	test: 0.415656

Epoch: 61
Loss: 0.13622991746549146
ROC train: 0.956297	val: 0.825049	test: 0.818066
PRC train: 0.776387	val: 0.509019	test: 0.416944

Epoch: 62
Loss: 0.13613667916171088
ROC train: 0.955138	val: 0.822077	test: 0.826655
PRC train: 0.771098	val: 0.502138	test: 0.442695

Epoch: 63
Loss: 0.13571802439075467
ROC train: 0.957580	val: 0.832736	test: 0.820745
PRC train: 0.775545	val: 0.498361	test: 0.422798

Epoch: 64
Loss: 0.13489368126766632
ROC train: 0.957009	val: 0.822130	test: 0.814036
PRC train: 0.770120	val: 0.494537	test: 0.437456

Epoch: 65
Loss: 0.13361490727940645
ROC train: 0.955699	val: 0.825319	test: 0.820570
PRC train: 0.769742	val: 0.485832	test: 0.418222

Epoch: 66
Loss: 0.13532505457244828
ROC train: 0.960580	val: 0.818770	test: 0.817229
PRC train: 0.789250	val: 0.497209	test: 0.427401

Epoch: 67
Loss: 0.1320105305915323
ROC train: 0.958998	val: 0.822505	test: 0.826928
PRC train: 0.787624	val: 0.488615	test: 0.455115

Epoch: 68
Loss: 0.13126577044702592
ROC train: 0.963301	val: 0.823261	test: 0.818573
PRC train: 0.799026	val: 0.505459	test: 0.436889

Epoch: 69
Loss: 0.13175855099897502
ROC train: 0.962215	val: 0.821294	test: 0.818032
PRC train: 0.799176	val: 0.507365	test: 0.457142

Epoch: 70
Loss: 0.1291132215177948
ROC train: 0.964168	val: 0.822252	test: 0.820812
PRC train: 0.805729	val: 0.510891	test: 0.443904

Epoch: 71
Loss: 0.12844217089800775
ROC train: 0.963570	val: 0.822638	test: 0.817043
PRC train: 0.803646	val: 0.505399	test: 0.445361

Epoch: 72
Loss: 0.12786371164176885
ROC train: 0.964664	val: 0.817203	test: 0.818935
PRC train: 0.803624	val: 0.502357	test: 0.446111

Epoch: 73
Loss: 0.12744134435923454
ROC train: 0.965785	val: 0.824148	test: 0.822540
PRC train: 0.808067	val: 0.505498	test: 0.444583

Epoch: 74
Loss: 0.12741182370820503
ROC train: 0.968270	val: 0.820532	test: 0.824685
PRC train: 0.823251	val: 0.506870	test: 0.459671

Epoch: 75
Loss: 0.12679817266338234
ROC train: 0.967859	val: 0.822084	test: 0.817699
PRC train: 0.824629	val: 0.512054	test: 0.449373

Epoch: 76
Loss: 0.12424764878895385
ROC train: 0.967560	val: 0.827728	test: 0.815590
PRC train: 0.816736	val: 0.503139	test: 0.438373

Epoch: 77
Loss: 0.12321041500862734
ROC train: 0.967924	val: 0.823323	test: 0.813455
PRC train: 0.822867	val: 0.503821	test: 0.452506

Epoch: 78
Loss: 0.12518638950509017
ROC train: 0.969316	val: 0.821464	test: 0.816076
PRC train: 0.825197	val: 0.499916	test: 0.433961

Epoch: 79
Loss: 0.12286802727272801
ROC train: 0.968869	val: 0.822686	test: 0.822715
PRC train: 0.825689	val: 0.509731	test: 0.451410

Epoch: 80
Loss: 0.12408332678592993
ROC train: 0.971846	val: 0.822490	test: 0.821424
PRC train: 0.838059	val: 0.502509	test: 0.452757

Epoch: 81
Loss: 0.12220019336057787
ROC train: 0.970205	val: 0.825675	test: 0.819930
PRC train: 0.827220	val: 0.496080	test: 0.466939

Epoch: 82
Loss: 0.12203456967432416
ROC train: 0.970646	val: 0.818297	test: 0.823263
PRC train: 0.834823	val: 0.501609	test: 0.444198

Epoch: 83
Loss: 0.12067275115115794
ROC train: 0.969940	val: 0.817888	test: 0.815761
PRC train: 0.823995	val: 0.500302	test: 0.460030

Epoch: 84
Loss: 0.12019190411626948
ROC train: 0.973494	val: 0.815813	test: 0.812786
PRC train: 0.844490	val: 0.493751	test: 0.445945

Epoch: 85
Loss: 0.11890619408553701
ROC train: 0.972785	val: 0.814503	test: 0.813144
PRC train: 0.839772	val: 0.495402	test: 0.444250

Epoch: 86
Loss: 0.11933429235462632
ROC train: 0.974328	val: 0.817352	test: 0.823785
PRC train: 0.851673	val: 0.492187	test: 0.448549

Epoch: 87
Loss: 0.11777491376902706
ROC train: 0.975995	val: 0.818105	test: 0.808525
PRC train: 0.855518	val: 0.501049	test: 0.446560

Epoch: 88
Loss: 0.11604670185910301
ROC train: 0.975543	val: 0.825552	test: 0.814308
PRC train: 0.856127	val: 0.508735	test: 0.454515

Epoch: 89
Loss: 0.11635988942191908
ROC train: 0.976802	val: 0.819401	test: 0.814206
PRC train: 0.862780	val: 0.498620	test: 0.441793

Epoch: 90
Loss: 0.11391270129675908
ROC train: 0.976005	val: 0.823272	test: 0.815700
PRC train: 0.858381	val: 0.509887	test: 0.454093

Epoch: 91
Loss: 0.11548567582741995
ROC train: 0.977423	val: 0.819870	test: 0.815885
PRC train: 0.864006	val: 0.509863	test: 0.448141

Epoch: 92
Loss: 0.11590692775837562
ROC train: 0.978151	val: 0.817815	test: 0.813199
PRC train: 0.865587	val: 0.502154	test: 0.445772

Epoch: 93
Loss: 0.11536472459937241
ROC train: 0.977932	val: 0.822329	test: 0.817045
PRC train: 0.866912	val: 0.504204	test: 0.449035

Epoch: 94
Loss: 0.11587652950948701
ROC train: 0.980122	val: 0.818538	test: 0.797198
PRC train: 0.873312	val: 0.432364	test: 0.433382

Epoch: 95
Loss: 0.11578836715661751
ROC train: 0.980328	val: 0.820451	test: 0.798719
PRC train: 0.870796	val: 0.429056	test: 0.440118

Epoch: 96
Loss: 0.11091700265770707
ROC train: 0.975418	val: 0.824208	test: 0.798326
PRC train: 0.843718	val: 0.454875	test: 0.432205

Epoch: 97
Loss: 0.1100488120150239
ROC train: 0.981523	val: 0.820820	test: 0.799929
PRC train: 0.880019	val: 0.435853	test: 0.429577

Epoch: 98
Loss: 0.11042050555649574
ROC train: 0.981404	val: 0.824734	test: 0.799675
PRC train: 0.879101	val: 0.443611	test: 0.431435

Epoch: 99
Loss: 0.11114944222344154
ROC train: 0.982008	val: 0.824895	test: 0.797838
PRC train: 0.882379	val: 0.453868	test: 0.442787

Epoch: 100
Loss: 0.10977397123777302
ROC train: 0.982697	val: 0.820748	test: 0.796698
PRC train: 0.886027	val: 0.422528	test: 0.425868

Epoch: 101
Loss: 0.10892277905642384
ROC train: 0.982644	val: 0.823750	test: 0.798821
PRC train: 0.884351	val: 0.444186	test: 0.423769

Epoch: 102
Loss: 0.10835228623812583
ROC train: 0.984107	val: 0.822790	test: 0.800435
PRC train: 0.890674	val: 0.441161	test: 0.431522

Epoch: 103
Loss: 0.11025434482366774
ROC train: 0.983778	val: 0.821057	test: 0.799291
PRC train: 0.890989	val: 0.426464	test: 0.430067

Epoch: 104
Loss: 0.10727416770104393
ROC train: 0.982288	val: 0.828859	test: 0.803204
PRC train: 0.883784	val: 0.451618	test: 0.449422

Epoch: 105
Loss: 0.10611441021746232
ROC train: 0.983384	val: 0.830148	test: 0.801525
PRC train: 0.885496	val: 0.422292	test: 0.420595

Epoch: 106
Loss: 0.1050824647302043
ROC train: 0.985302	val: 0.822628	test: 0.800865
PRC train: 0.898130	val: 0.438207	test: 0.428748

Epoch: 107
Loss: 0.10493277658388332
ROC train: 0.985755	val: 0.824120	test: 0.801916
PRC train: 0.904133	val: 0.444929	test: 0.439698

Epoch: 108
Loss: 0.10525280397439335
ROC train: 0.984975	val: 0.825263	test: 0.799858
PRC train: 0.897737	val: 0.448127	test: 0.430787

Epoch: 109
Loss: 0.10260862166236326
ROC train: 0.985711	val: 0.818114	test: 0.798643
PRC train: 0.898589	val: 0.422591	test: 0.426307

Epoch: 110
Loss: 0.10460227068847479
ROC train: 0.984980	val: 0.825338	test: 0.797358
PRC train: 0.900810	val: 0.450230	test: 0.434749

Epoch: 111
Loss: 0.10201360148469324
ROC train: 0.986391	val: 0.823045	test: 0.800315
PRC train: 0.907644	val: 0.443845	test: 0.438427

Epoch: 112
Loss: 0.10403098876989472
ROC train: 0.986763	val: 0.823252	test: 0.794911
PRC train: 0.910172	val: 0.443153	test: 0.429620

Epoch: 113
Loss: 0.10315102465144206
ROC train: 0.987309	val: 0.816478	test: 0.794219
PRC train: 0.913688	val: 0.447997	test: 0.430897

Epoch: 114
Loss: 0.10360086714939759
ROC train: 0.986760	val: 0.824804	test: 0.801529
PRC train: 0.909519	val: 0.433130	test: 0.435069

Epoch: 115
Loss: 0.10057294575955511
ROC train: 0.986766	val: 0.822894	test: 0.791071
PRC train: 0.905718	val: 0.444752	test: 0.429337

Epoch: 116
Loss: 0.1011157793536988
ROC train: 0.988228	val: 0.818731	test: 0.791189
PRC train: 0.915304	val: 0.444831	test: 0.419353

Epoch: 117
Loss: 0.09928063782566238
ROC train: 0.987029	val: 0.822674	test: 0.789269
PRC train: 0.908023	val: 0.440044	test: 0.421063

Epoch: 118
Loss: 0.10050134510893781
ROC train: 0.989348	val: 0.819534	test: 0.790629
PRC train: 0.921062	val: 0.438108	test: 0.419515

Epoch: 119
Loss: 0.09741340143792945
ROC train: 0.988897	val: 0.822515	test: 0.799060
PRC train: 0.920281	val: 0.424131	test: 0.428857

Epoch: 120
Loss: 0.09382531655833938
ROC train: 0.988866	val: 0.823192	test: 0.793929
PRC train: 0.917855	val: 0.447029	test: 0.429528

Early stopping
Best (ROC):	 train: 0.949886	val: 0.838413	test: 0.818417
Best (PRC):	 train: 0.745406	val: 0.433279	test: 0.432572

ROC train: 0.976560	val: 0.824049	test: 0.798013
PRC train: 0.861038	val: 0.442644	test: 0.407642

Epoch: 95
Loss: 0.11587135090232208
ROC train: 0.976843	val: 0.812148	test: 0.797397
PRC train: 0.864029	val: 0.416064	test: 0.404652

Epoch: 96
Loss: 0.1137076089577006
ROC train: 0.979676	val: 0.820583	test: 0.799940
PRC train: 0.880316	val: 0.446568	test: 0.413037

Epoch: 97
Loss: 0.11297894110834389
ROC train: 0.978324	val: 0.815332	test: 0.794691
PRC train: 0.870042	val: 0.439595	test: 0.415935

Epoch: 98
Loss: 0.11254940940171797
ROC train: 0.978980	val: 0.818372	test: 0.801484
PRC train: 0.874853	val: 0.431329	test: 0.418537

Epoch: 99
Loss: 0.11376373356579993
ROC train: 0.980784	val: 0.818913	test: 0.797110
PRC train: 0.882224	val: 0.439134	test: 0.411789

Epoch: 100
Loss: 0.10939833944686006
ROC train: 0.980460	val: 0.820051	test: 0.799903
PRC train: 0.883450	val: 0.430977	test: 0.416574

Epoch: 101
Loss: 0.11130047139728438
ROC train: 0.980648	val: 0.820371	test: 0.796773
PRC train: 0.880167	val: 0.441057	test: 0.411330

Epoch: 102
Loss: 0.11109869358246274
ROC train: 0.981977	val: 0.816510	test: 0.794825
PRC train: 0.889960	val: 0.425627	test: 0.410226

Epoch: 103
Loss: 0.1088861488965698
ROC train: 0.981759	val: 0.821840	test: 0.802094
PRC train: 0.886226	val: 0.433944	test: 0.405278

Epoch: 104
Loss: 0.10691143126009062
ROC train: 0.982581	val: 0.812719	test: 0.791396
PRC train: 0.888352	val: 0.429111	test: 0.404789

Epoch: 105
Loss: 0.10790924558604188
ROC train: 0.982697	val: 0.820437	test: 0.794576
PRC train: 0.894656	val: 0.430823	test: 0.411307

Epoch: 106
Loss: 0.10890794605486573
ROC train: 0.983496	val: 0.818859	test: 0.793086
PRC train: 0.896298	val: 0.433272	test: 0.412393

Epoch: 107
Loss: 0.10528938530054661
ROC train: 0.983284	val: 0.819598	test: 0.800307
PRC train: 0.897329	val: 0.438734	test: 0.407747

Epoch: 108
Loss: 0.10715481501269963
ROC train: 0.981744	val: 0.815522	test: 0.791612
PRC train: 0.884319	val: 0.429178	test: 0.403489

Epoch: 109
Loss: 0.10625858257317318
ROC train: 0.984450	val: 0.815368	test: 0.794382
PRC train: 0.902432	val: 0.428978	test: 0.402560

Epoch: 110
Loss: 0.10512573507094329
ROC train: 0.984947	val: 0.813768	test: 0.795598
PRC train: 0.905291	val: 0.425684	test: 0.403965

Epoch: 111
Loss: 0.10618887665001893
ROC train: 0.980776	val: 0.814294	test: 0.792612
PRC train: 0.883531	val: 0.427305	test: 0.407009

Epoch: 112
Loss: 0.10310522438664078
ROC train: 0.985185	val: 0.817915	test: 0.795415
PRC train: 0.906817	val: 0.434452	test: 0.418709

Epoch: 113
Loss: 0.10454727210913829
ROC train: 0.985877	val: 0.814375	test: 0.790730
PRC train: 0.908725	val: 0.434166	test: 0.418287

Epoch: 114
Loss: 0.10236757702021056
ROC train: 0.984929	val: 0.813520	test: 0.788493
PRC train: 0.901371	val: 0.437247	test: 0.420013

Epoch: 115
Loss: 0.1014859792705414
ROC train: 0.985832	val: 0.815418	test: 0.796778
PRC train: 0.911640	val: 0.428510	test: 0.405959

Epoch: 116
Loss: 0.09952671136114859
ROC train: 0.986935	val: 0.813613	test: 0.790695
PRC train: 0.913587	val: 0.422936	test: 0.406159

Epoch: 117
Loss: 0.10174314752790953
ROC train: 0.987159	val: 0.819500	test: 0.793714
PRC train: 0.915819	val: 0.435419	test: 0.403968

Epoch: 118
Loss: 0.098776879877825
ROC train: 0.986764	val: 0.815876	test: 0.791044
PRC train: 0.910591	val: 0.436611	test: 0.402751

Epoch: 119
Loss: 0.09772652730472706
ROC train: 0.987629	val: 0.815687	test: 0.786063
PRC train: 0.919943	val: 0.437395	test: 0.405734

Epoch: 120
Loss: 0.09882271570554883
ROC train: 0.986896	val: 0.809522	test: 0.784995
PRC train: 0.913418	val: 0.431053	test: 0.399171

Early stopping
Best (ROC):	 train: 0.953564	val: 0.839322	test: 0.814563
Best (PRC):	 train: 0.763117	val: 0.446044	test: 0.427465

ROC train: 0.979032	val: 0.823294	test: 0.796100
PRC train: 0.869194	val: 0.448692	test: 0.428525

Epoch: 95
Loss: 0.11138183865306144
ROC train: 0.982021	val: 0.816167	test: 0.791554
PRC train: 0.883382	val: 0.439728	test: 0.441418

Epoch: 96
Loss: 0.1109571095776681
ROC train: 0.982475	val: 0.811631	test: 0.793252
PRC train: 0.887349	val: 0.436013	test: 0.435975

Epoch: 97
Loss: 0.10862493138540234
ROC train: 0.980823	val: 0.820546	test: 0.798040
PRC train: 0.880687	val: 0.438230	test: 0.435475

Epoch: 98
Loss: 0.1078563279391387
ROC train: 0.982264	val: 0.817310	test: 0.799333
PRC train: 0.886647	val: 0.431924	test: 0.449269

Epoch: 99
Loss: 0.10935539645460557
ROC train: 0.982185	val: 0.813743	test: 0.795693
PRC train: 0.881709	val: 0.449329	test: 0.433132

Epoch: 100
Loss: 0.10708544564590694
ROC train: 0.982673	val: 0.815428	test: 0.797980
PRC train: 0.886722	val: 0.451290	test: 0.445012

Epoch: 101
Loss: 0.1077744208550749
ROC train: 0.980061	val: 0.812457	test: 0.791425
PRC train: 0.876684	val: 0.445039	test: 0.428188

Epoch: 102
Loss: 0.10928532282664101
ROC train: 0.983035	val: 0.819354	test: 0.793777
PRC train: 0.889616	val: 0.453488	test: 0.443530

Epoch: 103
Loss: 0.10487662677734859
ROC train: 0.981989	val: 0.811667	test: 0.794081
PRC train: 0.878989	val: 0.417725	test: 0.427824

Epoch: 104
Loss: 0.10903910202282772
ROC train: 0.984402	val: 0.808326	test: 0.787108
PRC train: 0.895612	val: 0.431460	test: 0.434477

Epoch: 105
Loss: 0.10771182537892993
ROC train: 0.983754	val: 0.813781	test: 0.792117
PRC train: 0.892421	val: 0.443540	test: 0.431154

Epoch: 106
Loss: 0.11040813905715993
ROC train: 0.982928	val: 0.809545	test: 0.789864
PRC train: 0.887281	val: 0.431919	test: 0.434343

Epoch: 107
Loss: 0.10601848842656784
ROC train: 0.983849	val: 0.815820	test: 0.793987
PRC train: 0.890272	val: 0.452238	test: 0.421213

Epoch: 108
Loss: 0.10606417697135631
ROC train: 0.986327	val: 0.809239	test: 0.786915
PRC train: 0.905580	val: 0.441666	test: 0.430857

Epoch: 109
Loss: 0.10056375317756555
ROC train: 0.984291	val: 0.812716	test: 0.786835
PRC train: 0.893010	val: 0.446501	test: 0.440093

Epoch: 110
Loss: 0.10371556926492971
ROC train: 0.987223	val: 0.811209	test: 0.786331
PRC train: 0.914834	val: 0.440650	test: 0.434263

Epoch: 111
Loss: 0.09925874525245568
ROC train: 0.987138	val: 0.810721	test: 0.790175
PRC train: 0.908867	val: 0.440263	test: 0.439644

Epoch: 112
Loss: 0.10328862650954607
ROC train: 0.987612	val: 0.812084	test: 0.792703
PRC train: 0.916713	val: 0.444347	test: 0.446361

Epoch: 113
Loss: 0.09970387007706835
ROC train: 0.986156	val: 0.813718	test: 0.793875
PRC train: 0.906827	val: 0.448457	test: 0.433870

Epoch: 114
Loss: 0.10121656926952503
ROC train: 0.988228	val: 0.815241	test: 0.790957
PRC train: 0.919494	val: 0.447259	test: 0.447443

Epoch: 115
Loss: 0.09954202854212892
ROC train: 0.987453	val: 0.810929	test: 0.786603
PRC train: 0.915443	val: 0.442768	test: 0.432304

Epoch: 116
Loss: 0.09973293574799467
ROC train: 0.988400	val: 0.814187	test: 0.790692
PRC train: 0.919615	val: 0.447780	test: 0.444079

Epoch: 117
Loss: 0.09748209262205118
ROC train: 0.989035	val: 0.813415	test: 0.786667
PRC train: 0.922832	val: 0.427656	test: 0.438146

Epoch: 118
Loss: 0.09820366348043112
ROC train: 0.989074	val: 0.813669	test: 0.792577
PRC train: 0.924325	val: 0.435933	test: 0.448556

Epoch: 119
Loss: 0.09760270392330801
ROC train: 0.987579	val: 0.814083	test: 0.795977
PRC train: 0.913477	val: 0.440781	test: 0.444455

Epoch: 120
Loss: 0.09589164000303949
ROC train: 0.989203	val: 0.816563	test: 0.793108
PRC train: 0.923332	val: 0.440113	test: 0.431753

Early stopping
Best (ROC):	 train: 0.925390	val: 0.829426	test: 0.810957
Best (PRC):	 train: 0.666551	val: 0.428783	test: 0.431095
All runs completed.

ROC train: 0.978603	val: 0.821451	test: 0.807609
PRC train: 0.866007	val: 0.433187	test: 0.463783

Epoch: 95
Loss: 0.11483989819485328
ROC train: 0.978092	val: 0.830216	test: 0.810983
PRC train: 0.863569	val: 0.444515	test: 0.469726

Epoch: 96
Loss: 0.11255833265884871
ROC train: 0.979229	val: 0.828919	test: 0.813690
PRC train: 0.868560	val: 0.449831	test: 0.465133

Epoch: 97
Loss: 0.11190473731898684
ROC train: 0.977956	val: 0.828692	test: 0.802411
PRC train: 0.863652	val: 0.441196	test: 0.460721

Epoch: 98
Loss: 0.10911436400997614
ROC train: 0.979860	val: 0.826647	test: 0.808464
PRC train: 0.874299	val: 0.437665	test: 0.471789

Epoch: 99
Loss: 0.11169128806084933
ROC train: 0.980097	val: 0.822094	test: 0.809929
PRC train: 0.874701	val: 0.429083	test: 0.469187

Epoch: 100
Loss: 0.10982000912566182
ROC train: 0.981194	val: 0.824708	test: 0.807721
PRC train: 0.882177	val: 0.437311	test: 0.471440

Epoch: 101
Loss: 0.10800111292477199
ROC train: 0.981844	val: 0.822493	test: 0.809352
PRC train: 0.882944	val: 0.432976	test: 0.463611

Epoch: 102
Loss: 0.10722722153315467
ROC train: 0.981006	val: 0.820910	test: 0.806218
PRC train: 0.884601	val: 0.439111	test: 0.459933

Epoch: 103
Loss: 0.10719433151442082
ROC train: 0.981929	val: 0.824005	test: 0.813293
PRC train: 0.883773	val: 0.416688	test: 0.464730

Epoch: 104
Loss: 0.11065612446885842
ROC train: 0.980733	val: 0.826658	test: 0.809183
PRC train: 0.882842	val: 0.431600	test: 0.466988

Epoch: 105
Loss: 0.10681389786774155
ROC train: 0.981146	val: 0.825886	test: 0.805240
PRC train: 0.879855	val: 0.439508	test: 0.462120

Epoch: 106
Loss: 0.10797634244156294
ROC train: 0.982997	val: 0.827457	test: 0.804781
PRC train: 0.890048	val: 0.433529	test: 0.453108

Epoch: 107
Loss: 0.10634045059174603
ROC train: 0.982950	val: 0.829655	test: 0.802300
PRC train: 0.886389	val: 0.431801	test: 0.452044

Epoch: 108
Loss: 0.10744035297102852
ROC train: 0.980800	val: 0.825314	test: 0.809302
PRC train: 0.878625	val: 0.444426	test: 0.462833

Epoch: 109
Loss: 0.1039534989913753
ROC train: 0.983214	val: 0.825675	test: 0.808006
PRC train: 0.890821	val: 0.425791	test: 0.465214

Epoch: 110
Loss: 0.10329298652827412
ROC train: 0.984577	val: 0.820636	test: 0.798367
PRC train: 0.893583	val: 0.442723	test: 0.459476

Epoch: 111
Loss: 0.10480667600433748
ROC train: 0.984334	val: 0.827332	test: 0.807934
PRC train: 0.897860	val: 0.424766	test: 0.473200

Epoch: 112
Loss: 0.10105739924367524
ROC train: 0.982928	val: 0.822563	test: 0.798484
PRC train: 0.883661	val: 0.432979	test: 0.454546

Epoch: 113
Loss: 0.10307707310994846
ROC train: 0.984781	val: 0.828616	test: 0.803039
PRC train: 0.899997	val: 0.429204	test: 0.456193

Epoch: 114
Loss: 0.10385626379888718
ROC train: 0.985797	val: 0.823063	test: 0.803359
PRC train: 0.902488	val: 0.436850	test: 0.452829

Epoch: 115
Loss: 0.10132189036250322
ROC train: 0.985085	val: 0.827280	test: 0.806853
PRC train: 0.903535	val: 0.444607	test: 0.477422

Epoch: 116
Loss: 0.10077635113034521
ROC train: 0.986269	val: 0.826472	test: 0.803757
PRC train: 0.906006	val: 0.447947	test: 0.457416

Epoch: 117
Loss: 0.09905861086412777
ROC train: 0.985263	val: 0.824342	test: 0.807106
PRC train: 0.900625	val: 0.441574	test: 0.471983

Epoch: 118
Loss: 0.10102611247177105
ROC train: 0.985802	val: 0.822215	test: 0.801557
PRC train: 0.902230	val: 0.448050	test: 0.458070

Epoch: 119
Loss: 0.09935960394485775
ROC train: 0.986755	val: 0.823097	test: 0.803721
PRC train: 0.908838	val: 0.444563	test: 0.464018

Epoch: 120
Loss: 0.09780650212070524
ROC train: 0.988132	val: 0.824508	test: 0.804979
PRC train: 0.915416	val: 0.433803	test: 0.457671

Early stopping
Best (ROC):	 train: 0.904205	val: 0.838768	test: 0.828188
Best (PRC):	 train: 0.604434	val: 0.433618	test: 0.439502

ROC train: 0.979267	val: 0.819560	test: 0.814657
PRC train: 0.869354	val: 0.440043	test: 0.459619

Epoch: 95
Loss: 0.11031080713571378
ROC train: 0.980074	val: 0.817733	test: 0.812274
PRC train: 0.873441	val: 0.431167	test: 0.454302

Epoch: 96
Loss: 0.1088917716232527
ROC train: 0.980368	val: 0.812887	test: 0.812757
PRC train: 0.873112	val: 0.437962	test: 0.455264

Epoch: 97
Loss: 0.11015161632511376
ROC train: 0.980196	val: 0.818301	test: 0.813386
PRC train: 0.870700	val: 0.438396	test: 0.451630

Epoch: 98
Loss: 0.1137804565311177
ROC train: 0.976818	val: 0.815085	test: 0.804875
PRC train: 0.858540	val: 0.447874	test: 0.453048

Epoch: 99
Loss: 0.11102813455631265
ROC train: 0.979751	val: 0.822677	test: 0.816384
PRC train: 0.869674	val: 0.437714	test: 0.456584

Epoch: 100
Loss: 0.10840554301885669
ROC train: 0.980857	val: 0.819712	test: 0.812911
PRC train: 0.879444	val: 0.452782	test: 0.459951

Epoch: 101
Loss: 0.10783253828952005
ROC train: 0.980979	val: 0.818040	test: 0.818125
PRC train: 0.883276	val: 0.449762	test: 0.457746

Epoch: 102
Loss: 0.10691132726886257
ROC train: 0.982990	val: 0.822623	test: 0.815615
PRC train: 0.888218	val: 0.437341	test: 0.455446

Epoch: 103
Loss: 0.10694877163439148
ROC train: 0.983850	val: 0.813473	test: 0.808111
PRC train: 0.887934	val: 0.427818	test: 0.458824

Epoch: 104
Loss: 0.104819061539155
ROC train: 0.983344	val: 0.818977	test: 0.815316
PRC train: 0.892898	val: 0.439087	test: 0.450161

Epoch: 105
Loss: 0.10346572727463013
ROC train: 0.983235	val: 0.821924	test: 0.817361
PRC train: 0.890189	val: 0.445409	test: 0.458162

Epoch: 106
Loss: 0.10405184734949363
ROC train: 0.984715	val: 0.824909	test: 0.816038
PRC train: 0.902359	val: 0.437635	test: 0.461485

Epoch: 107
Loss: 0.10404593979794283
ROC train: 0.985011	val: 0.815138	test: 0.809924
PRC train: 0.894504	val: 0.438071	test: 0.456556

Epoch: 108
Loss: 0.1041579359487491
ROC train: 0.984941	val: 0.816388	test: 0.807219
PRC train: 0.902797	val: 0.444786	test: 0.458957

Epoch: 109
Loss: 0.10378581592706433
ROC train: 0.983367	val: 0.823278	test: 0.811177
PRC train: 0.893764	val: 0.430995	test: 0.457534

Epoch: 110
Loss: 0.10309647649702441
ROC train: 0.985492	val: 0.823095	test: 0.817810
PRC train: 0.902477	val: 0.443220	test: 0.463245

Epoch: 111
Loss: 0.10029542865264829
ROC train: 0.984808	val: 0.814979	test: 0.801371
PRC train: 0.898054	val: 0.447693	test: 0.453339

Epoch: 112
Loss: 0.10087618749941835
ROC train: 0.986493	val: 0.819139	test: 0.802934
PRC train: 0.907541	val: 0.436755	test: 0.450651

Epoch: 113
Loss: 0.10103336844612776
ROC train: 0.984861	val: 0.815083	test: 0.798681
PRC train: 0.897712	val: 0.427009	test: 0.431588

Epoch: 114
Loss: 0.0994010976939939
ROC train: 0.987018	val: 0.811190	test: 0.810336
PRC train: 0.906665	val: 0.420242	test: 0.438078

Epoch: 115
Loss: 0.1006724822622135
ROC train: 0.987679	val: 0.811601	test: 0.804466
PRC train: 0.914248	val: 0.434048	test: 0.436975

Epoch: 116
Loss: 0.09788916836639153
ROC train: 0.986994	val: 0.816578	test: 0.807788
PRC train: 0.909825	val: 0.428223	test: 0.449346

Epoch: 117
Loss: 0.09951476306414503
ROC train: 0.986912	val: 0.815709	test: 0.805121
PRC train: 0.906557	val: 0.436857	test: 0.454594

Epoch: 118
Loss: 0.09869390948415852
ROC train: 0.986244	val: 0.815606	test: 0.807584
PRC train: 0.905976	val: 0.427140	test: 0.453291

Epoch: 119
Loss: 0.10087494863425356
ROC train: 0.987240	val: 0.821749	test: 0.808841
PRC train: 0.908377	val: 0.450023	test: 0.456802

Epoch: 120
Loss: 0.09712753880208286
ROC train: 0.988007	val: 0.809802	test: 0.803203
PRC train: 0.914671	val: 0.434965	test: 0.447570

Early stopping
Best (ROC):	 train: 0.957009	val: 0.842995	test: 0.825785
Best (PRC):	 train: 0.770347	val: 0.464159	test: 0.450227

ROC train: 0.980421	val: 0.826150	test: 0.811696
PRC train: 0.875815	val: 0.446622	test: 0.448586

Epoch: 95
Loss: 0.11333637973443338
ROC train: 0.979571	val: 0.822247	test: 0.803297
PRC train: 0.867870	val: 0.450259	test: 0.449122

Epoch: 96
Loss: 0.11137221957453637
ROC train: 0.980177	val: 0.828220	test: 0.808419
PRC train: 0.874813	val: 0.464162	test: 0.450819

Epoch: 97
Loss: 0.11066951107576727
ROC train: 0.981917	val: 0.827411	test: 0.805832
PRC train: 0.883389	val: 0.460069	test: 0.445291

Epoch: 98
Loss: 0.10864571829171708
ROC train: 0.981296	val: 0.822239	test: 0.809896
PRC train: 0.878754	val: 0.447692	test: 0.465869

Epoch: 99
Loss: 0.109385171360159
ROC train: 0.981573	val: 0.817096	test: 0.808692
PRC train: 0.879274	val: 0.433966	test: 0.452422

Epoch: 100
Loss: 0.10654890799925426
ROC train: 0.982475	val: 0.821634	test: 0.804239
PRC train: 0.885545	val: 0.445316	test: 0.451108

Epoch: 101
Loss: 0.10551780620109286
ROC train: 0.982666	val: 0.818796	test: 0.802369
PRC train: 0.888061	val: 0.445056	test: 0.453991

Epoch: 102
Loss: 0.10560518315625461
ROC train: 0.983413	val: 0.814007	test: 0.809421
PRC train: 0.889843	val: 0.436664	test: 0.462620

Epoch: 103
Loss: 0.10457796354775793
ROC train: 0.983775	val: 0.815008	test: 0.808461
PRC train: 0.894192	val: 0.438328	test: 0.454988

Epoch: 104
Loss: 0.10525460230189866
ROC train: 0.983933	val: 0.820709	test: 0.806524
PRC train: 0.893424	val: 0.451833	test: 0.457978

Epoch: 105
Loss: 0.10308920589225128
ROC train: 0.982857	val: 0.817523	test: 0.809641
PRC train: 0.887735	val: 0.425839	test: 0.456393

Epoch: 106
Loss: 0.10222121458333903
ROC train: 0.983058	val: 0.819818	test: 0.810371
PRC train: 0.889285	val: 0.443070	test: 0.443856

Epoch: 107
Loss: 0.10446589267678079
ROC train: 0.985865	val: 0.813099	test: 0.807397
PRC train: 0.902044	val: 0.453851	test: 0.448496

Epoch: 108
Loss: 0.10283220504671772
ROC train: 0.985961	val: 0.818994	test: 0.805864
PRC train: 0.905662	val: 0.447752	test: 0.445065

Epoch: 109
Loss: 0.10297332002195758
ROC train: 0.986074	val: 0.812101	test: 0.800384
PRC train: 0.904786	val: 0.426630	test: 0.435145

Epoch: 110
Loss: 0.10412935244388956
ROC train: 0.984573	val: 0.820933	test: 0.803307
PRC train: 0.898526	val: 0.442755	test: 0.450184

Epoch: 111
Loss: 0.10325528178015037
ROC train: 0.986670	val: 0.817913	test: 0.804678
PRC train: 0.910561	val: 0.435078	test: 0.442038

Epoch: 112
Loss: 0.09998070578267897
ROC train: 0.987183	val: 0.806643	test: 0.803575
PRC train: 0.912419	val: 0.443333	test: 0.444555

Epoch: 113
Loss: 0.09934840338477721
ROC train: 0.986636	val: 0.822359	test: 0.807316
PRC train: 0.910058	val: 0.453324	test: 0.450176

Epoch: 114
Loss: 0.09962763371042146
ROC train: 0.986873	val: 0.815765	test: 0.807616
PRC train: 0.907503	val: 0.431432	test: 0.442493

Epoch: 115
Loss: 0.09500493939482134
ROC train: 0.987911	val: 0.819688	test: 0.809171
PRC train: 0.914984	val: 0.443411	test: 0.452430

Epoch: 116
Loss: 0.09513620060046389
ROC train: 0.988164	val: 0.812903	test: 0.806160
PRC train: 0.916044	val: 0.445925	test: 0.451544

Epoch: 117
Loss: 0.09652155594147965
ROC train: 0.988621	val: 0.821045	test: 0.812232
PRC train: 0.920199	val: 0.450302	test: 0.467188

Epoch: 118
Loss: 0.0932240432028352
ROC train: 0.989071	val: 0.817005	test: 0.804998
PRC train: 0.922745	val: 0.439586	test: 0.446088

Epoch: 119
Loss: 0.09537649087010877
ROC train: 0.988545	val: 0.805123	test: 0.796542
PRC train: 0.918829	val: 0.442625	test: 0.449335

Epoch: 120
Loss: 0.09696945865912664
ROC train: 0.988654	val: 0.813490	test: 0.805046
PRC train: 0.918970	val: 0.436626	test: 0.446142

Early stopping
Best (ROC):	 train: 0.948111	val: 0.841531	test: 0.824424
Best (PRC):	 train: 0.742539	val: 0.454234	test: 0.452511
All runs completed.

ROC train: 0.978356	val: 0.818348	test: 0.813202
PRC train: 0.867864	val: 0.504615	test: 0.452040

Epoch: 95
Loss: 0.11105258853174242
ROC train: 0.979984	val: 0.821009	test: 0.814781
PRC train: 0.876034	val: 0.501363	test: 0.462344

Epoch: 96
Loss: 0.11024944374988685
ROC train: 0.979048	val: 0.815307	test: 0.810108
PRC train: 0.872043	val: 0.492923	test: 0.446978

Epoch: 97
Loss: 0.11178512919078006
ROC train: 0.979958	val: 0.820481	test: 0.810666
PRC train: 0.871314	val: 0.504712	test: 0.433866

Epoch: 98
Loss: 0.1091525919463591
ROC train: 0.980404	val: 0.810526	test: 0.802389
PRC train: 0.875761	val: 0.493103	test: 0.416981

Epoch: 99
Loss: 0.11167235744689295
ROC train: 0.981130	val: 0.813414	test: 0.811449
PRC train: 0.880876	val: 0.484729	test: 0.425995

Epoch: 100
Loss: 0.10931642810862524
ROC train: 0.981519	val: 0.813000	test: 0.804181
PRC train: 0.884143	val: 0.501668	test: 0.417849

Epoch: 101
Loss: 0.10922587994274972
ROC train: 0.982546	val: 0.816122	test: 0.811278
PRC train: 0.889422	val: 0.511921	test: 0.435142

Epoch: 102
Loss: 0.10700202058149279
ROC train: 0.983439	val: 0.815658	test: 0.809414
PRC train: 0.893924	val: 0.497082	test: 0.438798

Epoch: 103
Loss: 0.10690095081510483
ROC train: 0.983697	val: 0.818965	test: 0.806611
PRC train: 0.894045	val: 0.485854	test: 0.429153

Epoch: 104
Loss: 0.1055774015272336
ROC train: 0.983438	val: 0.807729	test: 0.803508
PRC train: 0.893003	val: 0.488847	test: 0.430947

Epoch: 105
Loss: 0.10500258727654149
ROC train: 0.984005	val: 0.817321	test: 0.804264
PRC train: 0.899520	val: 0.494279	test: 0.431136

Epoch: 106
Loss: 0.10478083880859304
ROC train: 0.983712	val: 0.817752	test: 0.798189
PRC train: 0.898174	val: 0.490665	test: 0.419863

Epoch: 107
Loss: 0.10437699603798549
ROC train: 0.985137	val: 0.806952	test: 0.797759
PRC train: 0.901731	val: 0.494399	test: 0.418668

Epoch: 108
Loss: 0.10205959502853668
ROC train: 0.985012	val: 0.818491	test: 0.808384
PRC train: 0.903282	val: 0.504548	test: 0.435335

Epoch: 109
Loss: 0.10401579437636917
ROC train: 0.984892	val: 0.817435	test: 0.805930
PRC train: 0.899609	val: 0.497142	test: 0.435150

Epoch: 110
Loss: 0.10402872333585306
ROC train: 0.985329	val: 0.810238	test: 0.807653
PRC train: 0.899631	val: 0.498212	test: 0.438390

Epoch: 111
Loss: 0.102256110422202
ROC train: 0.985260	val: 0.808717	test: 0.807385
PRC train: 0.904774	val: 0.499468	test: 0.446269

Epoch: 112
Loss: 0.10237183497675369
ROC train: 0.985497	val: 0.817121	test: 0.803987
PRC train: 0.907016	val: 0.504266	test: 0.439146

Epoch: 113
Loss: 0.09976555033217392
ROC train: 0.986149	val: 0.812084	test: 0.810286
PRC train: 0.910097	val: 0.507182	test: 0.447765

Epoch: 114
Loss: 0.10140112875839502
ROC train: 0.986552	val: 0.813494	test: 0.809867
PRC train: 0.910601	val: 0.500914	test: 0.435722

Epoch: 115
Loss: 0.09899664053122433
ROC train: 0.986899	val: 0.805006	test: 0.802793
PRC train: 0.914414	val: 0.496586	test: 0.427516

Epoch: 116
Loss: 0.09908182187735635
ROC train: 0.986515	val: 0.804849	test: 0.803564
PRC train: 0.909437	val: 0.490069	test: 0.434506

Epoch: 117
Loss: 0.10050409505751919
ROC train: 0.987461	val: 0.808753	test: 0.801225
PRC train: 0.915428	val: 0.494440	test: 0.450080

Epoch: 118
Loss: 0.09814708723625575
ROC train: 0.986783	val: 0.815132	test: 0.811367
PRC train: 0.914241	val: 0.503882	test: 0.434509

Epoch: 119
Loss: 0.09951140287491411
ROC train: 0.987487	val: 0.807697	test: 0.803594
PRC train: 0.915662	val: 0.492625	test: 0.449430

Epoch: 120
Loss: 0.09711681598127558
ROC train: 0.988601	val: 0.807974	test: 0.801862
PRC train: 0.921702	val: 0.482904	test: 0.441936

Early stopping
Best (ROC):	 train: 0.942259	val: 0.834566	test: 0.834422
Best (PRC):	 train: 0.717997	val: 0.513001	test: 0.455928

ROC train: 0.976983	val: 0.815065	test: 0.817893
PRC train: 0.859354	val: 0.503094	test: 0.450942

Epoch: 95
Loss: 0.11370990933684691
ROC train: 0.978170	val: 0.823741	test: 0.820222
PRC train: 0.868514	val: 0.510940	test: 0.450411

Epoch: 96
Loss: 0.11262783013689953
ROC train: 0.978893	val: 0.816549	test: 0.812973
PRC train: 0.870740	val: 0.500007	test: 0.444651

Epoch: 97
Loss: 0.11260786036515244
ROC train: 0.978658	val: 0.815805	test: 0.821710
PRC train: 0.868442	val: 0.495296	test: 0.443671

Epoch: 98
Loss: 0.11175353685152929
ROC train: 0.979184	val: 0.822281	test: 0.819793
PRC train: 0.869280	val: 0.504478	test: 0.447734

Epoch: 99
Loss: 0.11165194466336117
ROC train: 0.979646	val: 0.810326	test: 0.812711
PRC train: 0.869263	val: 0.499006	test: 0.436118

Epoch: 100
Loss: 0.11092055590283739
ROC train: 0.979684	val: 0.821873	test: 0.823424
PRC train: 0.876726	val: 0.499548	test: 0.461667

Epoch: 101
Loss: 0.10986605341899675
ROC train: 0.980226	val: 0.818294	test: 0.814765
PRC train: 0.878788	val: 0.506657	test: 0.448805

Epoch: 102
Loss: 0.11151676751060774
ROC train: 0.979310	val: 0.817315	test: 0.813218
PRC train: 0.872774	val: 0.506667	test: 0.447390

Epoch: 103
Loss: 0.10990200391592211
ROC train: 0.980046	val: 0.815699	test: 0.810229
PRC train: 0.874241	val: 0.510231	test: 0.426105

Epoch: 104
Loss: 0.11047653077398392
ROC train: 0.980860	val: 0.818542	test: 0.822480
PRC train: 0.881055	val: 0.507793	test: 0.452088

Epoch: 105
Loss: 0.10679401227624437
ROC train: 0.981846	val: 0.820334	test: 0.821410
PRC train: 0.887636	val: 0.512114	test: 0.469805

Epoch: 106
Loss: 0.10852134010173056
ROC train: 0.982635	val: 0.822876	test: 0.816936
PRC train: 0.888402	val: 0.511576	test: 0.465289

Epoch: 107
Loss: 0.10499499024488353
ROC train: 0.982113	val: 0.820989	test: 0.819910
PRC train: 0.888989	val: 0.492951	test: 0.447949

Epoch: 108
Loss: 0.10496807472769074
ROC train: 0.983813	val: 0.812498	test: 0.810945
PRC train: 0.893239	val: 0.505901	test: 0.445471

Epoch: 109
Loss: 0.10554511335764274
ROC train: 0.983252	val: 0.819033	test: 0.816308
PRC train: 0.892686	val: 0.479696	test: 0.460549

Epoch: 110
Loss: 0.10567980975735061
ROC train: 0.983290	val: 0.814534	test: 0.819506
PRC train: 0.893494	val: 0.514833	test: 0.469457

Epoch: 111
Loss: 0.10351558013579322
ROC train: 0.984500	val: 0.821563	test: 0.814147
PRC train: 0.897660	val: 0.504250	test: 0.448771

Epoch: 112
Loss: 0.10186071553525103
ROC train: 0.982552	val: 0.822460	test: 0.815336
PRC train: 0.888740	val: 0.496997	test: 0.441977

Epoch: 113
Loss: 0.1034701400210411
ROC train: 0.984275	val: 0.810676	test: 0.809189
PRC train: 0.898198	val: 0.489034	test: 0.441315

Epoch: 114
Loss: 0.10213977631217322
ROC train: 0.985269	val: 0.816175	test: 0.808797
PRC train: 0.902142	val: 0.496634	test: 0.444349

Epoch: 115
Loss: 0.10453073806675076
ROC train: 0.984481	val: 0.812924	test: 0.816011
PRC train: 0.895663	val: 0.480917	test: 0.445247

Epoch: 116
Loss: 0.1021795747257304
ROC train: 0.985961	val: 0.812010	test: 0.809258
PRC train: 0.908200	val: 0.487151	test: 0.446281

Epoch: 117
Loss: 0.10035386352071772
ROC train: 0.986527	val: 0.818443	test: 0.816742
PRC train: 0.911416	val: 0.485591	test: 0.447544

Epoch: 118
Loss: 0.10219994532378615
ROC train: 0.983481	val: 0.818413	test: 0.808134
PRC train: 0.894427	val: 0.486743	test: 0.425895

Epoch: 119
Loss: 0.10022089259432448
ROC train: 0.986275	val: 0.813377	test: 0.807066
PRC train: 0.909292	val: 0.488110	test: 0.443292

Epoch: 120
Loss: 0.10002659361455128
ROC train: 0.986082	val: 0.816752	test: 0.810937
PRC train: 0.912000	val: 0.492016	test: 0.438863

Early stopping
Best (ROC):	 train: 0.905451	val: 0.832356	test: 0.827465
Best (PRC):	 train: 0.598852	val: 0.479534	test: 0.411456

ROC train: 0.978202	val: 0.819416	test: 0.813608
PRC train: 0.867096	val: 0.511312	test: 0.449793

Epoch: 95
Loss: 0.1136383634403316
ROC train: 0.980095	val: 0.821309	test: 0.815458
PRC train: 0.875393	val: 0.508054	test: 0.451239

Epoch: 96
Loss: 0.11067480799380873
ROC train: 0.977692	val: 0.816264	test: 0.818941
PRC train: 0.864631	val: 0.495131	test: 0.452342

Epoch: 97
Loss: 0.11375902629249234
ROC train: 0.979793	val: 0.822510	test: 0.813943
PRC train: 0.874849	val: 0.495282	test: 0.436076

Epoch: 98
Loss: 0.11125972180138018
ROC train: 0.979995	val: 0.818307	test: 0.814213
PRC train: 0.875359	val: 0.492456	test: 0.454367

Epoch: 99
Loss: 0.11266416510062398
ROC train: 0.979856	val: 0.819846	test: 0.816033
PRC train: 0.878108	val: 0.491267	test: 0.459169

Epoch: 100
Loss: 0.11199855702576571
ROC train: 0.981117	val: 0.820220	test: 0.810811
PRC train: 0.881648	val: 0.505798	test: 0.448438

Epoch: 101
Loss: 0.10823159141639221
ROC train: 0.981708	val: 0.819473	test: 0.807702
PRC train: 0.887091	val: 0.501256	test: 0.462041

Epoch: 102
Loss: 0.10689785968644407
ROC train: 0.982182	val: 0.814209	test: 0.812740
PRC train: 0.887946	val: 0.514967	test: 0.463756

Epoch: 103
Loss: 0.10686337893235506
ROC train: 0.982610	val: 0.818853	test: 0.813319
PRC train: 0.889851	val: 0.509003	test: 0.457106

Epoch: 104
Loss: 0.10613193486106468
ROC train: 0.983004	val: 0.814821	test: 0.808603
PRC train: 0.892881	val: 0.494082	test: 0.436880

Epoch: 105
Loss: 0.10656129405917886
ROC train: 0.983057	val: 0.816935	test: 0.812420
PRC train: 0.892526	val: 0.493554	test: 0.432116

Epoch: 106
Loss: 0.1066262891024621
ROC train: 0.983404	val: 0.819852	test: 0.810730
PRC train: 0.891773	val: 0.507276	test: 0.443082

Epoch: 107
Loss: 0.10651434979795207
ROC train: 0.983660	val: 0.815243	test: 0.809128
PRC train: 0.890771	val: 0.497233	test: 0.439514

Epoch: 108
Loss: 0.10846879621882691
ROC train: 0.984127	val: 0.819921	test: 0.813363
PRC train: 0.898736	val: 0.501411	test: 0.447400

Epoch: 109
Loss: 0.10350475385028371
ROC train: 0.984476	val: 0.816695	test: 0.812797
PRC train: 0.900524	val: 0.500998	test: 0.446977

Epoch: 110
Loss: 0.10427717207940676
ROC train: 0.984406	val: 0.816839	test: 0.817550
PRC train: 0.899206	val: 0.494623	test: 0.443556

Epoch: 111
Loss: 0.10624389313353864
ROC train: 0.984166	val: 0.814168	test: 0.807187
PRC train: 0.897409	val: 0.485515	test: 0.436601

Epoch: 112
Loss: 0.10318486957651263
ROC train: 0.985073	val: 0.815969	test: 0.807872
PRC train: 0.905711	val: 0.489930	test: 0.445941

Epoch: 113
Loss: 0.10317824437777869
ROC train: 0.985432	val: 0.813498	test: 0.807106
PRC train: 0.901614	val: 0.488730	test: 0.447291

Epoch: 114
Loss: 0.10108451606287559
ROC train: 0.985586	val: 0.805524	test: 0.805099
PRC train: 0.905119	val: 0.476643	test: 0.443611

Epoch: 115
Loss: 0.10125143361074697
ROC train: 0.986766	val: 0.811793	test: 0.808113
PRC train: 0.912099	val: 0.492971	test: 0.445742

Epoch: 116
Loss: 0.09952921738117436
ROC train: 0.986040	val: 0.812517	test: 0.804141
PRC train: 0.907979	val: 0.476681	test: 0.417929

Epoch: 117
Loss: 0.10107498195360598
ROC train: 0.987479	val: 0.814560	test: 0.804671
PRC train: 0.915177	val: 0.488411	test: 0.431355

Epoch: 118
Loss: 0.10030948154560171
ROC train: 0.987162	val: 0.811291	test: 0.806581
PRC train: 0.912826	val: 0.479906	test: 0.433512

Epoch: 119
Loss: 0.09869033544809463
ROC train: 0.987304	val: 0.811745	test: 0.806690
PRC train: 0.915699	val: 0.484147	test: 0.427157

Epoch: 120
Loss: 0.1006099224055215
ROC train: 0.986781	val: 0.818843	test: 0.815543
PRC train: 0.912464	val: 0.503249	test: 0.459868

Early stopping
Best (ROC):	 train: 0.957580	val: 0.832736	test: 0.820745
Best (PRC):	 train: 0.775545	val: 0.498361	test: 0.422798
All runs completed.
