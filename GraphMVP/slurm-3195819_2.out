>>> Starting run for dataset: bace
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running SCAFF configs_split_experiments/GraphCL/bace/scaff/train_prop=0.6.yml on cuda:0
Running SCAFF configs_split_experiments/GraphCL/bace/scaff/train_prop=0.7.yml on cuda:1
Running SCAFF configs_split_experiments/GraphCL/bace/scaff/train_prop=0.8.yml on cuda:2
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.7.yml --runseed 1 --device cuda:1
Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.7.yml --runseed 2 --device cuda:1
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.6.yml --runseed 1 --device cuda:0
Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.7.yml --runseed 3 --device cuda:1
Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.6.yml --runseed 2 --device cuda:0
Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.6.yml --runseed 3 --device cuda:0
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.8.yml --runseed 1 --device cuda:2
Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.8.yml --runseed 2 --device cuda:2
Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.8.yml --runseed 3 --device cuda:2
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:0
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/scaff/train_prop=0.6/bace_scaff_1_20-05_14-43-16  ]
[ Using Seed :  1  ]
[ Using device :  cuda:0  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
split via scaffold
Data(edge_attr=[66, 2], edge_index=[2, 66], id=[1], x=[31, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6832354779676957
ROC train: 0.691698	val: 0.511946	test: 0.650886
PRC train: 0.631710	val: 0.137128	test: 0.761959

Epoch: 2
Loss: 0.6459658374534061
ROC train: 0.770182	val: 0.581876	test: 0.679064
PRC train: 0.701523	val: 0.145965	test: 0.795945

Epoch: 3
Loss: 0.6093099149234678
ROC train: 0.797388	val: 0.655497	test: 0.713116
PRC train: 0.726304	val: 0.178729	test: 0.832527

Epoch: 4
Loss: 0.5621620781022527
ROC train: 0.839143	val: 0.726107	test: 0.751803
PRC train: 0.775934	val: 0.219771	test: 0.855707

Epoch: 5
Loss: 0.5504730240050434
ROC train: 0.854564	val: 0.728147	test: 0.769576
PRC train: 0.793126	val: 0.239039	test: 0.859747

Epoch: 6
Loss: 0.5189604206528659
ROC train: 0.862554	val: 0.759615	test: 0.782145
PRC train: 0.806491	val: 0.281509	test: 0.867795

Epoch: 7
Loss: 0.5092328969691777
ROC train: 0.866666	val: 0.798368	test: 0.766227
PRC train: 0.814544	val: 0.313352	test: 0.860366

Epoch: 8
Loss: 0.5046112390836528
ROC train: 0.868520	val: 0.780789	test: 0.761951
PRC train: 0.826045	val: 0.290632	test: 0.857290

Epoch: 9
Loss: 0.4675499481140199
ROC train: 0.873215	val: 0.787393	test: 0.747527
PRC train: 0.833408	val: 0.290316	test: 0.850503

Epoch: 10
Loss: 0.47777312836179797
ROC train: 0.883979	val: 0.814297	test: 0.739079
PRC train: 0.847061	val: 0.318677	test: 0.845861

Epoch: 11
Loss: 0.4664219373867624
ROC train: 0.889726	val: 0.811674	test: 0.747167
PRC train: 0.856866	val: 0.319484	test: 0.853371

Epoch: 12
Loss: 0.45814398303014364
ROC train: 0.894081	val: 0.827506	test: 0.747476
PRC train: 0.863119	val: 0.333422	test: 0.853379

Epoch: 13
Loss: 0.45410124932402124
ROC train: 0.894923	val: 0.831974	test: 0.732227
PRC train: 0.864686	val: 0.349778	test: 0.847900

Epoch: 14
Loss: 0.43621794114558904
ROC train: 0.898582	val: 0.847222	test: 0.732382
PRC train: 0.872912	val: 0.374169	test: 0.855065

Epoch: 15
Loss: 0.43119247820723755
ROC train: 0.903307	val: 0.858489	test: 0.736400
PRC train: 0.880086	val: 0.389216	test: 0.857097

Epoch: 16
Loss: 0.42809720416193064
ROC train: 0.909565	val: 0.850039	test: 0.746858
PRC train: 0.888327	val: 0.382397	test: 0.862169

Epoch: 17
Loss: 0.42231219829116273
ROC train: 0.912051	val: 0.844503	test: 0.738512
PRC train: 0.890152	val: 0.376290	test: 0.858623

Epoch: 18
Loss: 0.42351450493021553
ROC train: 0.910893	val: 0.861888	test: 0.734340
PRC train: 0.890786	val: 0.406038	test: 0.855721

Epoch: 19
Loss: 0.4197675722348207
ROC train: 0.914655	val: 0.861597	test: 0.750258
PRC train: 0.893697	val: 0.414431	test: 0.860848

Epoch: 20
Loss: 0.41953914508047907
ROC train: 0.918650	val: 0.854992	test: 0.750000
PRC train: 0.899304	val: 0.414220	test: 0.856341

Epoch: 21
Loss: 0.3946288390832453
ROC train: 0.922581	val: 0.857712	test: 0.751030
PRC train: 0.902629	val: 0.435286	test: 0.856397

Epoch: 22
Loss: 0.40870206641296974
ROC train: 0.922742	val: 0.871309	test: 0.743612
PRC train: 0.902474	val: 0.437441	test: 0.851202

Epoch: 23
Loss: 0.38830317702331396
ROC train: 0.920392	val: 0.879662	test: 0.738306
PRC train: 0.901917	val: 0.445796	test: 0.851133

Epoch: 24
Loss: 0.39941798366145287
ROC train: 0.920985	val: 0.868201	test: 0.749742
PRC train: 0.904152	val: 0.421578	test: 0.857238

Epoch: 25
Loss: 0.3912220817042895
ROC train: 0.923413	val: 0.835664	test: 0.753400
PRC train: 0.907337	val: 0.384355	test: 0.861572

Epoch: 26
Loss: 0.39340551599870804
ROC train: 0.926873	val: 0.826826	test: 0.750721
PRC train: 0.911575	val: 0.389741	test: 0.859633

Epoch: 27
Loss: 0.38563880078672613
ROC train: 0.928445	val: 0.837413	test: 0.743818
PRC train: 0.914669	val: 0.396362	test: 0.857515

Epoch: 28
Loss: 0.41177295509858436
ROC train: 0.929253	val: 0.851690	test: 0.736915
PRC train: 0.917514	val: 0.413771	test: 0.855869

Epoch: 29
Loss: 0.3813860513344318
ROC train: 0.930829	val: 0.848679	test: 0.736915
PRC train: 0.919284	val: 0.434240	test: 0.852798

Epoch: 30
Loss: 0.38359371732874237
ROC train: 0.931184	val: 0.842657	test: 0.736297
PRC train: 0.920173	val: 0.439438	test: 0.849585

Epoch: 31
Loss: 0.3797216957809418
ROC train: 0.932289	val: 0.853632	test: 0.732485
PRC train: 0.921316	val: 0.424532	test: 0.846963

Epoch: 32
Loss: 0.3779893350040217
ROC train: 0.932844	val: 0.873349	test: 0.733052
PRC train: 0.921987	val: 0.455191	test: 0.847584

Epoch: 33
Loss: 0.3604906886176678Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:0
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/scaff/train_prop=0.6/bace_scaff_2_20-05_14-43-16  ]
[ Using Seed :  2  ]
[ Using device :  cuda:0  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
split via scaffold
Data(edge_attr=[66, 2], edge_index=[2, 66], id=[1], x=[31, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.68989533900789
ROC train: 0.702315	val: 0.517288	test: 0.675871
PRC train: 0.658236	val: 0.142042	test: 0.801225

Epoch: 2
Loss: 0.6552263277922383
ROC train: 0.756849	val: 0.543998	test: 0.701988
PRC train: 0.707924	val: 0.146778	test: 0.818697

Epoch: 3
Loss: 0.6273307522111193
ROC train: 0.766527	val: 0.587121	test: 0.654028
PRC train: 0.719632	val: 0.154558	test: 0.794489

Epoch: 4
Loss: 0.5923381454624366
ROC train: 0.812395	val: 0.650447	test: 0.715022
PRC train: 0.777835	val: 0.239279	test: 0.835042

Epoch: 5
Loss: 0.553353415495985
ROC train: 0.830550	val: 0.679293	test: 0.739594
PRC train: 0.798560	val: 0.249124	test: 0.857905

Epoch: 6
Loss: 0.532301163191935
ROC train: 0.846905	val: 0.739996	test: 0.748094
PRC train: 0.810963	val: 0.246933	test: 0.863989

Epoch: 7
Loss: 0.5055803936949231
ROC train: 0.859693	val: 0.764375	test: 0.729188
PRC train: 0.820537	val: 0.268153	test: 0.852132

Epoch: 8
Loss: 0.48207505731596584
ROC train: 0.873254	val: 0.799048	test: 0.736091
PRC train: 0.832077	val: 0.308598	test: 0.858113

Epoch: 9
Loss: 0.47350372009181785
ROC train: 0.881546	val: 0.809052	test: 0.747476
PRC train: 0.842124	val: 0.325280	test: 0.858588

Epoch: 10
Loss: 0.4846320811736413
ROC train: 0.886003	val: 0.825175	test: 0.760200
PRC train: 0.854981	val: 0.332952	test: 0.877915

Epoch: 11
Loss: 0.4573597628605157
ROC train: 0.888602	val: 0.815657	test: 0.761333
PRC train: 0.861602	val: 0.323166	test: 0.879247

Epoch: 12
Loss: 0.4596582266933588
ROC train: 0.894650	val: 0.832751	test: 0.750721
PRC train: 0.870062	val: 0.349523	test: 0.876253

Epoch: 13
Loss: 0.43037631200472154
ROC train: 0.898256	val: 0.828380	test: 0.763394
PRC train: 0.879065	val: 0.338067	test: 0.879283

Epoch: 14
Loss: 0.4354758434942526
ROC train: 0.902806	val: 0.835859	test: 0.778591
PRC train: 0.886772	val: 0.360498	test: 0.885866

Epoch: 15
Loss: 0.4210283641485644
ROC train: 0.906801	val: 0.840229	test: 0.779312
PRC train: 0.891465	val: 0.379131	test: 0.883940

Epoch: 16
Loss: 0.4134423186160763
ROC train: 0.909531	val: 0.843434	test: 0.771121
PRC train: 0.896210	val: 0.388800	test: 0.876877

Epoch: 17
Loss: 0.4101638959394025
ROC train: 0.913613	val: 0.843823	test: 0.761900
PRC train: 0.900047	val: 0.381674	test: 0.873774

Epoch: 18
Loss: 0.40484840992622284
ROC train: 0.916708	val: 0.843823	test: 0.759891
PRC train: 0.904108	val: 0.386435	test: 0.871271

Epoch: 19
Loss: 0.39096260210629663
ROC train: 0.920903	val: 0.864608	test: 0.757161
PRC train: 0.908261	val: 0.411145	test: 0.872292

Epoch: 20
Loss: 0.3966794477408297
ROC train: 0.923671	val: 0.857129	test: 0.761745
PRC train: 0.910517	val: 0.406774	test: 0.875038

Epoch: 21
Loss: 0.40455756469388593
ROC train: 0.925472	val: 0.842172	test: 0.758654
PRC train: 0.912103	val: 0.392216	test: 0.874031

Epoch: 22
Loss: 0.39946900865445245
ROC train: 0.926635	val: 0.846154	test: 0.747785
PRC train: 0.914922	val: 0.413367	test: 0.866731

Epoch: 23
Loss: 0.3830628530381742
ROC train: 0.926664	val: 0.864996	test: 0.743973
PRC train: 0.916383	val: 0.439490	test: 0.865046

Epoch: 24
Loss: 0.4016421850467857
ROC train: 0.927525	val: 0.863831	test: 0.753245
PRC train: 0.917817	val: 0.434087	test: 0.867824

Epoch: 25
Loss: 0.368622174959758
ROC train: 0.929545	val: 0.856158	test: 0.752885
PRC train: 0.920276	val: 0.411441	test: 0.868765

Epoch: 26
Loss: 0.3668839262156818
ROC train: 0.931486	val: 0.840229	test: 0.754430
PRC train: 0.921813	val: 0.392352	test: 0.870312

Epoch: 27
Loss: 0.3668092226011556
ROC train: 0.931793	val: 0.845960	test: 0.744385
PRC train: 0.922554	val: 0.394264	test: 0.868236

Epoch: 28
Loss: 0.3540513509725549
ROC train: 0.933038	val: 0.845085	test: 0.747630
PRC train: 0.923714	val: 0.390904	test: 0.869431

Epoch: 29
Loss: 0.3598076581412697
ROC train: 0.936727	val: 0.842657	test: 0.754430
PRC train: 0.928294	val: 0.389047	test: 0.871339

Epoch: 30
Loss: 0.38794927808617585
ROC train: 0.938065	val: 0.834790	test: 0.755100
PRC train: 0.930930	val: 0.413866	test: 0.867527

Epoch: 31
Loss: 0.37980394110227333
ROC train: 0.940162	val: 0.842172	test: 0.745776
PRC train: 0.932720	val: 0.415441	test: 0.856838

Epoch: 32
Loss: 0.3534063651987904
ROC train: 0.941676	val: 0.860723	test: 0.745776
PRC train: 0.934711	val: 0.444717	test: 0.859376

Epoch: 33
Loss: 0.3509370717243915
ROC train: 0.943170	val: 0.856643	test: 0.746342Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:0
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/scaff/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/scaff/train_prop=0.6/bace_scaff_3_20-05_14-43-16  ]
[ Using Seed :  3  ]
[ Using device :  cuda:0  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
split via scaffold
Data(edge_attr=[66, 2], edge_index=[2, 66], id=[1], x=[31, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6814124640473878
ROC train: 0.694642	val: 0.521173	test: 0.573254
PRC train: 0.655753	val: 0.125112	test: 0.700669

Epoch: 2
Loss: 0.6438614791138417
ROC train: 0.770659	val: 0.562549	test: 0.599629
PRC train: 0.729425	val: 0.140822	test: 0.761883

Epoch: 3
Loss: 0.6107159734905978
ROC train: 0.787218	val: 0.606546	test: 0.608644
PRC train: 0.747820	val: 0.164480	test: 0.775643

Epoch: 4
Loss: 0.5756969759344912
ROC train: 0.808658	val: 0.647630	test: 0.625077
PRC train: 0.770295	val: 0.206861	test: 0.783484

Epoch: 5
Loss: 0.5594135008591036
ROC train: 0.832569	val: 0.688423	test: 0.618586
PRC train: 0.793680	val: 0.260831	test: 0.770086

Epoch: 6
Loss: 0.5408581539639277
ROC train: 0.849080	val: 0.713675	test: 0.633629
PRC train: 0.823888	val: 0.300109	test: 0.771523

Epoch: 7
Loss: 0.49999311297986837
ROC train: 0.863075	val: 0.730866	test: 0.665362
PRC train: 0.842824	val: 0.294288	test: 0.805252

Epoch: 8
Loss: 0.48133017855436255
ROC train: 0.874622	val: 0.764763	test: 0.681640
PRC train: 0.854585	val: 0.308426	test: 0.820505

Epoch: 9
Loss: 0.4714289564522552
ROC train: 0.881322	val: 0.813423	test: 0.687049
PRC train: 0.857809	val: 0.348620	test: 0.821610

Epoch: 10
Loss: 0.476590546804106
ROC train: 0.884563	val: 0.814588	test: 0.691222
PRC train: 0.860831	val: 0.359535	test: 0.829673

Epoch: 11
Loss: 0.4717312581138391
ROC train: 0.891667	val: 0.812743	test: 0.726406
PRC train: 0.872780	val: 0.343728	test: 0.859472

Epoch: 12
Loss: 0.440168818206855
ROC train: 0.897818	val: 0.820319	test: 0.728209
PRC train: 0.878889	val: 0.352433	test: 0.859566

Epoch: 13
Loss: 0.45196774676205
ROC train: 0.900392	val: 0.828866	test: 0.716619
PRC train: 0.881463	val: 0.375218	test: 0.852702

Epoch: 14
Loss: 0.4405195186180696
ROC train: 0.904942	val: 0.837898	test: 0.731506
PRC train: 0.886712	val: 0.381235	test: 0.860100

Epoch: 15
Loss: 0.4377885106448599
ROC train: 0.909078	val: 0.844114	test: 0.738461
PRC train: 0.892972	val: 0.400386	test: 0.862987

Epoch: 16
Loss: 0.4117830075673982
ROC train: 0.910212	val: 0.848679	test: 0.718937
PRC train: 0.897230	val: 0.410212	test: 0.850488

Epoch: 17
Loss: 0.41911831638019575
ROC train: 0.912260	val: 0.847611	test: 0.718061
PRC train: 0.901729	val: 0.405604	test: 0.844694

Epoch: 18
Loss: 0.40769048052508877
ROC train: 0.914119	val: 0.855284	test: 0.716722
PRC train: 0.903845	val: 0.412664	test: 0.836428

Epoch: 19
Loss: 0.4405129649649201
ROC train: 0.913954	val: 0.849650	test: 0.716052
PRC train: 0.903804	val: 0.405685	test: 0.836269

Epoch: 20
Loss: 0.39432705269049
ROC train: 0.916990	val: 0.841880	test: 0.722543
PRC train: 0.906570	val: 0.394123	test: 0.839416

Epoch: 21
Loss: 0.39457628260899097
ROC train: 0.920036	val: 0.853147	test: 0.717906
PRC train: 0.909921	val: 0.409681	test: 0.836790

Epoch: 22
Loss: 0.39948690091121103
ROC train: 0.919978	val: 0.861597	test: 0.718525
PRC train: 0.910140	val: 0.421674	test: 0.833471

Epoch: 23
Loss: 0.394143181237972
ROC train: 0.919594	val: 0.866162	test: 0.733876
PRC train: 0.909512	val: 0.422000	test: 0.846415

Epoch: 24
Loss: 0.3683491007716035
ROC train: 0.923715	val: 0.861985	test: 0.746445
PRC train: 0.913603	val: 0.417423	test: 0.859458

Epoch: 25
Loss: 0.3800970031706128
ROC train: 0.928966	val: 0.851301	test: 0.732897
PRC train: 0.918923	val: 0.412715	test: 0.853227

Epoch: 26
Loss: 0.38519287646481964
ROC train: 0.930343	val: 0.840326	test: 0.723109
PRC train: 0.920427	val: 0.401462	test: 0.850085

Epoch: 27
Loss: 0.364639093273111
ROC train: 0.932124	val: 0.830517	test: 0.731712
PRC train: 0.923433	val: 0.386091	test: 0.855913

Epoch: 28
Loss: 0.36778753171951106
ROC train: 0.933895	val: 0.845474	test: 0.723315
PRC train: 0.925386	val: 0.400815	test: 0.849722

Epoch: 29
Loss: 0.35273876556918243
ROC train: 0.937666	val: 0.860237	test: 0.718731
PRC train: 0.929708	val: 0.414208	test: 0.843898

Epoch: 30
Loss: 0.3651971671821596
ROC train: 0.941423	val: 0.848970	test: 0.739594
PRC train: 0.934060	val: 0.401970	test: 0.855890

Epoch: 31
Loss: 0.3499876561108229
ROC train: 0.942542	val: 0.841492	test: 0.740470
PRC train: 0.934545	val: 0.394645	test: 0.859584

Epoch: 32
Loss: 0.3596593405230917
ROC train: 0.942143	val: 0.852467	test: 0.738049
PRC train: 0.932367	val: 0.414657	test: 0.860514

Epoch: 33
Loss: 0.34343971781652627
ROC train: 0.944479	val: 0.853730	test: 0.729394Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:1
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/scaff/train_prop=0.7/bace_scaff_1_20-05_14-43-16  ]
[ Using Seed :  1  ]
[ Using device :  cuda:1  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
split via scaffold
Data(edge_attr=[66, 2], edge_index=[2, 66], id=[1], x=[31, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6793506419250669
ROC train: 0.739134	val: 0.505497	test: 0.806428
PRC train: 0.647590	val: 0.252392	test: 0.890006

Epoch: 2
Loss: 0.6386595767008492
ROC train: 0.787133	val: 0.609619	test: 0.746479
PRC train: 0.707039	val: 0.281118	test: 0.843659

Epoch: 3
Loss: 0.5844101417122658
ROC train: 0.819167	val: 0.604440	test: 0.773745
PRC train: 0.749083	val: 0.276902	test: 0.855857

Epoch: 4
Loss: 0.5498222498849243
ROC train: 0.830534	val: 0.598943	test: 0.811936
PRC train: 0.758368	val: 0.285384	test: 0.877423

Epoch: 5
Loss: 0.5447410174525691
ROC train: 0.843315	val: 0.628224	test: 0.792163
PRC train: 0.775670	val: 0.317703	test: 0.870126

Epoch: 6
Loss: 0.47009223433103803
ROC train: 0.867559	val: 0.658774	test: 0.785392
PRC train: 0.813294	val: 0.349806	test: 0.874807

Epoch: 7
Loss: 0.49057844969277575
ROC train: 0.877936	val: 0.672093	test: 0.791260
PRC train: 0.824371	val: 0.386131	test: 0.881973

Epoch: 8
Loss: 0.4804807758283084
ROC train: 0.879933	val: 0.660465	test: 0.802907
PRC train: 0.825982	val: 0.379969	test: 0.891986

Epoch: 9
Loss: 0.46442514376106026
ROC train: 0.886975	val: 0.677378	test: 0.804713
PRC train: 0.834394	val: 0.418852	test: 0.890619

Epoch: 10
Loss: 0.45149487382628595
ROC train: 0.885114	val: 0.680233	test: 0.790448
PRC train: 0.830489	val: 0.415970	test: 0.876158

Epoch: 11
Loss: 0.4307364503918284
ROC train: 0.890591	val: 0.682981	test: 0.806970
PRC train: 0.836901	val: 0.400024	test: 0.877066

Epoch: 12
Loss: 0.4497081142509387
ROC train: 0.887925	val: 0.673150	test: 0.840917
PRC train: 0.843054	val: 0.363275	test: 0.902019

Epoch: 13
Loss: 0.4716005474301044
ROC train: 0.891710	val: 0.676744	test: 0.827826
PRC train: 0.844655	val: 0.356365	test: 0.900407

Epoch: 14
Loss: 0.4104966942390921
ROC train: 0.902152	val: 0.703700	test: 0.786114
PRC train: 0.858703	val: 0.416583	test: 0.884883

Epoch: 15
Loss: 0.42571438572019005
ROC train: 0.902055	val: 0.706025	test: 0.741874
PRC train: 0.856149	val: 0.427015	test: 0.858153

Epoch: 16
Loss: 0.4222090506173669
ROC train: 0.908819	val: 0.714905	test: 0.767425
PRC train: 0.867622	val: 0.420145	test: 0.870761

Epoch: 17
Loss: 0.40669623090432117
ROC train: 0.906552	val: 0.695137	test: 0.783496
PRC train: 0.869630	val: 0.379649	test: 0.877461

Epoch: 18
Loss: 0.4452192735132229
ROC train: 0.913432	val: 0.707400	test: 0.779975
PRC train: 0.875832	val: 0.398595	test: 0.871834

Epoch: 19
Loss: 0.40037482155818604
ROC train: 0.920027	val: 0.718182	test: 0.753431
PRC train: 0.881137	val: 0.442060	test: 0.849602

Epoch: 20
Loss: 0.38284792061054385
ROC train: 0.922107	val: 0.727801	test: 0.763723
PRC train: 0.886333	val: 0.437846	test: 0.861471

Epoch: 21
Loss: 0.39308546993346644
ROC train: 0.919301	val: 0.711945	test: 0.774738
PRC train: 0.886240	val: 0.405870	test: 0.870933

Epoch: 22
Loss: 0.3898482414107679
ROC train: 0.925219	val: 0.713636	test: 0.771849
PRC train: 0.893892	val: 0.400691	test: 0.871276

Epoch: 23
Loss: 0.3948909124201287
ROC train: 0.926842	val: 0.717019	test: 0.758126
PRC train: 0.896552	val: 0.412888	test: 0.861358

Epoch: 24
Loss: 0.3839116650865608
ROC train: 0.928080	val: 0.721987	test: 0.763543
PRC train: 0.900011	val: 0.438430	test: 0.864364

Epoch: 25
Loss: 0.37659480200022244
ROC train: 0.926446	val: 0.720825	test: 0.760834
PRC train: 0.899294	val: 0.450119	test: 0.865134

Epoch: 26
Loss: 0.36671772864830815
ROC train: 0.929516	val: 0.717759	test: 0.759209
PRC train: 0.900375	val: 0.437791	test: 0.861355

Epoch: 27
Loss: 0.40499308727819167
ROC train: 0.932178	val: 0.715433	test: 0.763994
PRC train: 0.902773	val: 0.441253	test: 0.862629

Epoch: 28
Loss: 0.3847979706119672
ROC train: 0.931635	val: 0.721564	test: 0.761105
PRC train: 0.903381	val: 0.450050	test: 0.863753

Epoch: 29
Loss: 0.4054647807273435
ROC train: 0.931890	val: 0.715645	test: 0.756320
PRC train: 0.905814	val: 0.444950	test: 0.860503

Epoch: 30
Loss: 0.3553679809595228
ROC train: 0.935366	val: 0.728013	test: 0.778350
PRC train: 0.910241	val: 0.450099	test: 0.875758

Epoch: 31
Loss: 0.3477212168093503
ROC train: 0.934733	val: 0.736892	test: 0.788552
PRC train: 0.911554	val: 0.460991	test: 0.882739

Epoch: 32
Loss: 0.35706765094792386
ROC train: 0.935773	val: 0.742283	test: 0.787017
PRC train: 0.911756	val: 0.461244	test: 0.883470

Epoch: 33
Loss: 0.36554586446468973Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:2
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/scaff/train_prop=0.8/bace_scaff_1_20-05_14-43-16  ]
[ Using Seed :  1  ]
[ Using device :  cuda:2  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
split via scaffold
Data(edge_attr=[66, 2], edge_index=[2, 66], id=[1], x=[31, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6830632092918657
ROC train: 0.711493	val: 0.603663	test: 0.755173
PRC train: 0.606741	val: 0.916276	test: 0.778805

Epoch: 2
Loss: 0.6296461140129389
ROC train: 0.785300	val: 0.614286	test: 0.680230
PRC train: 0.680646	val: 0.908758	test: 0.660281

Epoch: 3
Loss: 0.5795452407581043
ROC train: 0.825368	val: 0.634432	test: 0.705616
PRC train: 0.714960	val: 0.909525	test: 0.696053

Epoch: 4
Loss: 0.5261972806066539
ROC train: 0.859683	val: 0.659707	test: 0.760216
PRC train: 0.755318	val: 0.916739	test: 0.758888

Epoch: 5
Loss: 0.5067006142292106
ROC train: 0.869897	val: 0.636996	test: 0.783864
PRC train: 0.769356	val: 0.906070	test: 0.771977

Epoch: 6
Loss: 0.4767091112531996
ROC train: 0.875947	val: 0.641026	test: 0.771866
PRC train: 0.779125	val: 0.902682	test: 0.754857

Epoch: 7
Loss: 0.46659511149770483
ROC train: 0.891099	val: 0.672894	test: 0.767693
PRC train: 0.809264	val: 0.928537	test: 0.759031

Epoch: 8
Loss: 0.4512123466597885
ROC train: 0.894264	val: 0.693773	test: 0.744914
PRC train: 0.815497	val: 0.934362	test: 0.748147

Epoch: 9
Loss: 0.4324209582986323
ROC train: 0.896227	val: 0.700366	test: 0.746479
PRC train: 0.828027	val: 0.938140	test: 0.753786

Epoch: 10
Loss: 0.4194086870231707
ROC train: 0.901681	val: 0.708791	test: 0.755173
PRC train: 0.839439	val: 0.941727	test: 0.758111

Epoch: 11
Loss: 0.4211597527885437
ROC train: 0.908950	val: 0.713553	test: 0.748739
PRC train: 0.844360	val: 0.945133	test: 0.761380

Epoch: 12
Loss: 0.42041958746845803
ROC train: 0.912997	val: 0.709158	test: 0.739176
PRC train: 0.850471	val: 0.944247	test: 0.744983

Epoch: 13
Loss: 0.3932996076721341
ROC train: 0.915725	val: 0.705128	test: 0.738654
PRC train: 0.860279	val: 0.943498	test: 0.746316

Epoch: 14
Loss: 0.4025543819728017
ROC train: 0.916276	val: 0.716850	test: 0.739002
PRC train: 0.863815	val: 0.946264	test: 0.748621

Epoch: 15
Loss: 0.39595220744946835
ROC train: 0.919923	val: 0.746520	test: 0.724048
PRC train: 0.867733	val: 0.950175	test: 0.724088

Epoch: 16
Loss: 0.39931285335197036
ROC train: 0.923428	val: 0.746520	test: 0.734655
PRC train: 0.870852	val: 0.953000	test: 0.725969

Epoch: 17
Loss: 0.38282435782720114
ROC train: 0.921738	val: 0.703663	test: 0.753956
PRC train: 0.868267	val: 0.943622	test: 0.744318

Epoch: 18
Loss: 0.3862364893967141
ROC train: 0.927237	val: 0.694872	test: 0.743871
PRC train: 0.876830	val: 0.937833	test: 0.736593

Epoch: 19
Loss: 0.3755079632297333
ROC train: 0.927691	val: 0.669597	test: 0.739697
PRC train: 0.879867	val: 0.927876	test: 0.709330

Epoch: 20
Loss: 0.37428424248563097
ROC train: 0.931099	val: 0.680220	test: 0.740741
PRC train: 0.884440	val: 0.930902	test: 0.712106

Epoch: 21
Loss: 0.3565139118032038
ROC train: 0.932249	val: 0.695604	test: 0.732394
PRC train: 0.887105	val: 0.936926	test: 0.708420

Epoch: 22
Loss: 0.36104994044796807
ROC train: 0.933616	val: 0.697802	test: 0.740915
PRC train: 0.890904	val: 0.937527	test: 0.719057

Epoch: 23
Loss: 0.36791405771279145
ROC train: 0.933507	val: 0.696337	test: 0.738132
PRC train: 0.890287	val: 0.935257	test: 0.722312

Epoch: 24
Loss: 0.35630081741645997
ROC train: 0.934635	val: 0.673993	test: 0.737263
PRC train: 0.891850	val: 0.930815	test: 0.723046

Epoch: 25
Loss: 0.3589511292253801
ROC train: 0.935494	val: 0.672161	test: 0.740567
PRC train: 0.894454	val: 0.932754	test: 0.732052

Epoch: 26
Loss: 0.35577258972910136
ROC train: 0.938636	val: 0.681685	test: 0.757260
PRC train: 0.899580	val: 0.932983	test: 0.747430

Epoch: 27
Loss: 0.35028426850868905
ROC train: 0.938034	val: 0.691209	test: 0.748044
PRC train: 0.899852	val: 0.935207	test: 0.722233

Epoch: 28
Loss: 0.33950282881399096
ROC train: 0.940183	val: 0.709158	test: 0.743349
PRC train: 0.901930	val: 0.939800	test: 0.718336

Epoch: 29
Loss: 0.34109861171788697
ROC train: 0.940808	val: 0.727106	test: 0.740045
PRC train: 0.903880	val: 0.940874	test: 0.716184

Epoch: 30
Loss: 0.33328559982427786
ROC train: 0.939914	val: 0.720879	test: 0.733612
PRC train: 0.904705	val: 0.938392	test: 0.713316

Epoch: 31
Loss: 0.34211471979137836
ROC train: 0.944743	val: 0.703297	test: 0.745957
PRC train: 0.910730	val: 0.937742	test: 0.721186

Epoch: 32
Loss: 0.3460276244013557
ROC train: 0.947235	val: 0.698901	test: 0.759346
PRC train: 0.914784	val: 0.936729	test: 0.735414

Epoch: 33
Loss: 0.3458538883942336Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:1
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/scaff/train_prop=0.7/bace_scaff_3_20-05_14-43-16  ]
[ Using Seed :  3  ]
[ Using device :  cuda:1  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
split via scaffold
Data(edge_attr=[66, 2], edge_index=[2, 66], id=[1], x=[31, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6834256007888503
ROC train: 0.711672	val: 0.521564	test: 0.566450
PRC train: 0.657560	val: 0.250521	test: 0.688368

Epoch: 2
Loss: 0.6381053288374524
ROC train: 0.778566	val: 0.590275	test: 0.605092
PRC train: 0.715205	val: 0.275410	test: 0.745250

Epoch: 3
Loss: 0.6195134469247052
ROC train: 0.802965	val: 0.624736	test: 0.649783
PRC train: 0.741947	val: 0.313533	test: 0.785928

Epoch: 4
Loss: 0.5750244144251699
ROC train: 0.818606	val: 0.641332	test: 0.708198
PRC train: 0.759589	val: 0.334420	test: 0.830461

Epoch: 5
Loss: 0.5284430438721126
ROC train: 0.843351	val: 0.647886	test: 0.754424
PRC train: 0.789254	val: 0.344943	test: 0.859583

Epoch: 6
Loss: 0.5209403763335916
ROC train: 0.860089	val: 0.656660	test: 0.763633
PRC train: 0.816674	val: 0.346916	test: 0.854940

Epoch: 7
Loss: 0.4838648996316973
ROC train: 0.865616	val: 0.657928	test: 0.753792
PRC train: 0.819321	val: 0.344003	test: 0.850832

Epoch: 8
Loss: 0.4831522402075724
ROC train: 0.882293	val: 0.664059	test: 0.806880
PRC train: 0.846819	val: 0.352721	test: 0.881835

Epoch: 9
Loss: 0.4678780067865687
ROC train: 0.888705	val: 0.660888	test: 0.788371
PRC train: 0.852209	val: 0.361272	test: 0.876438

Epoch: 10
Loss: 0.4641960584488385
ROC train: 0.892113	val: 0.663742	test: 0.781510
PRC train: 0.859481	val: 0.363766	test: 0.879597

Epoch: 11
Loss: 0.4726040006733897
ROC train: 0.894365	val: 0.667970	test: 0.752257
PRC train: 0.861055	val: 0.354089	test: 0.854522

Epoch: 12
Loss: 0.3938663637171196
ROC train: 0.902616	val: 0.668816	test: 0.763543
PRC train: 0.871419	val: 0.371052	test: 0.866067

Epoch: 13
Loss: 0.41322477233606014
ROC train: 0.902717	val: 0.686258	test: 0.761557
PRC train: 0.873580	val: 0.394428	test: 0.860441

Epoch: 14
Loss: 0.4834726378220508
ROC train: 0.907085	val: 0.697146	test: 0.778440
PRC train: 0.877846	val: 0.388946	test: 0.877181

Epoch: 15
Loss: 0.434457559059452
ROC train: 0.912173	val: 0.684567	test: 0.780336
PRC train: 0.884952	val: 0.386870	test: 0.879475

Epoch: 16
Loss: 0.4300166144674784
ROC train: 0.913597	val: 0.676533	test: 0.778350
PRC train: 0.891782	val: 0.390111	test: 0.877671

Epoch: 17
Loss: 0.40929851160902475
ROC train: 0.914713	val: 0.683298	test: 0.775370
PRC train: 0.893117	val: 0.397579	test: 0.875365

Epoch: 18
Loss: 0.4096155098406796
ROC train: 0.915339	val: 0.694397	test: 0.756862
PRC train: 0.892260	val: 0.409035	test: 0.865717

Epoch: 19
Loss: 0.4020770923017488
ROC train: 0.922866	val: 0.716490	test: 0.776815
PRC train: 0.899370	val: 0.418275	test: 0.875825

Epoch: 20
Loss: 0.3976271319271446
ROC train: 0.925392	val: 0.718076	test: 0.788010
PRC train: 0.901682	val: 0.409556	test: 0.885193

Epoch: 21
Loss: 0.38502394371193
ROC train: 0.924489	val: 0.698309	test: 0.772030
PRC train: 0.902369	val: 0.416952	test: 0.878060

Epoch: 22
Loss: 0.4653372006633451
ROC train: 0.925471	val: 0.692812	test: 0.779884
PRC train: 0.904273	val: 0.416782	test: 0.879743

Epoch: 23
Loss: 0.4108542627961538
ROC train: 0.925040	val: 0.717230	test: 0.790719
PRC train: 0.903451	val: 0.430988	test: 0.886005

Epoch: 24
Loss: 0.3917237753393705
ROC train: 0.924536	val: 0.726321	test: 0.796407
PRC train: 0.904248	val: 0.425670	test: 0.886635

Epoch: 25
Loss: 0.3585106921296213
ROC train: 0.926659	val: 0.718076	test: 0.781329
PRC train: 0.906996	val: 0.419849	test: 0.878442

Epoch: 26
Loss: 0.36391758065003293
ROC train: 0.926742	val: 0.705814	test: 0.758667
PRC train: 0.907848	val: 0.411319	test: 0.867108

Epoch: 27
Loss: 0.3543097463532986
ROC train: 0.928148	val: 0.708351	test: 0.751625
PRC train: 0.910030	val: 0.408701	test: 0.861041

Epoch: 28
Loss: 0.41304601012789793
ROC train: 0.932473	val: 0.721987	test: 0.769863
PRC train: 0.912222	val: 0.418201	test: 0.868254

Epoch: 29
Loss: 0.3748785490793738
ROC train: 0.930987	val: 0.715222	test: 0.768870
PRC train: 0.911004	val: 0.424241	test: 0.871986

Epoch: 30
Loss: 0.3546029685734765
ROC train: 0.933510	val: 0.692389	test: 0.748104
PRC train: 0.915941	val: 0.413239	test: 0.863481

Epoch: 31
Loss: 0.35946084226467623
ROC train: 0.932297	val: 0.681501	test: 0.755959
PRC train: 0.914625	val: 0.407823	test: 0.868046

Epoch: 32
Loss: 0.38723625634894127
ROC train: 0.935230	val: 0.708457	test: 0.766342
PRC train: 0.917221	val: 0.409952	test: 0.869961

Epoch: 33
Loss: 0.37739482472536884
ROC train: 0.934618	val: 0.716913	test: 0.781239Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:1
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/scaff/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/scaff/train_prop=0.7/bace_scaff_2_20-05_14-43-16  ]
[ Using Seed :  2  ]
[ Using device :  cuda:1  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
split via scaffold
Data(edge_attr=[66, 2], edge_index=[2, 66], id=[1], x=[31, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6811970691353207
ROC train: 0.710715	val: 0.597992	test: 0.725352
PRC train: 0.631950	val: 0.318902	test: 0.822617

Epoch: 2
Loss: 0.6376406554667982
ROC train: 0.776972	val: 0.587949	test: 0.786114
PRC train: 0.700946	val: 0.286466	test: 0.857067

Epoch: 3
Loss: 0.6019437441540051
ROC train: 0.800846	val: 0.605497	test: 0.782142
PRC train: 0.730818	val: 0.297324	test: 0.863575

Epoch: 4
Loss: 0.5431060857877215
ROC train: 0.828587	val: 0.636575	test: 0.794330
PRC train: 0.765339	val: 0.318980	test: 0.877929

Epoch: 5
Loss: 0.5230305106724167
ROC train: 0.851522	val: 0.658562	test: 0.804803
PRC train: 0.793215	val: 0.340224	test: 0.887561

Epoch: 6
Loss: 0.4950697871578226
ROC train: 0.866069	val: 0.661522	test: 0.820874
PRC train: 0.812115	val: 0.348092	test: 0.891222

Epoch: 7
Loss: 0.4676656210958373
ROC train: 0.874752	val: 0.670190	test: 0.826472
PRC train: 0.823335	val: 0.360830	test: 0.889510

Epoch: 8
Loss: 0.47458243786478266
ROC train: 0.881779	val: 0.663531	test: 0.837035
PRC train: 0.831332	val: 0.370323	test: 0.896596

Epoch: 9
Loss: 0.4685181342766085
ROC train: 0.887342	val: 0.675793	test: 0.816992
PRC train: 0.842433	val: 0.393676	test: 0.887946

Epoch: 10
Loss: 0.4795523013468889
ROC train: 0.892217	val: 0.691121	test: 0.830986
PRC train: 0.856112	val: 0.391159	test: 0.899824

Epoch: 11
Loss: 0.42943911049618066
ROC train: 0.895128	val: 0.680233	test: 0.835500
PRC train: 0.864034	val: 0.388617	test: 0.902758

Epoch: 12
Loss: 0.44517084481477376
ROC train: 0.898755	val: 0.670930	test: 0.821596
PRC train: 0.867440	val: 0.378469	test: 0.902873

Epoch: 13
Loss: 0.47233274212334225
ROC train: 0.901209	val: 0.676321	test: 0.819700
PRC train: 0.868804	val: 0.373201	test: 0.903295

Epoch: 14
Loss: 0.44062515232478755
ROC train: 0.899888	val: 0.690275	test: 0.809227
PRC train: 0.867694	val: 0.369835	test: 0.892825

Epoch: 15
Loss: 0.41489280598501493
ROC train: 0.903192	val: 0.715539	test: 0.823221
PRC train: 0.872863	val: 0.404030	test: 0.897285

Epoch: 16
Loss: 0.4321321338521611
ROC train: 0.907063	val: 0.720613	test: 0.821506
PRC train: 0.879501	val: 0.421250	test: 0.897564

Epoch: 17
Loss: 0.40408470823754755
ROC train: 0.910496	val: 0.702220	test: 0.799567
PRC train: 0.885250	val: 0.421640	test: 0.888936

Epoch: 18
Loss: 0.3732319474746256
ROC train: 0.910661	val: 0.688689	test: 0.799928
PRC train: 0.885910	val: 0.401458	test: 0.892332

Epoch: 19
Loss: 0.3824023195732134
ROC train: 0.916501	val: 0.685624	test: 0.807060
PRC train: 0.892175	val: 0.404273	test: 0.895193

Epoch: 20
Loss: 0.43549293393238686
ROC train: 0.920966	val: 0.689429	test: 0.821596
PRC train: 0.899308	val: 0.399570	test: 0.902392

Epoch: 21
Loss: 0.42429983476188166
ROC train: 0.920326	val: 0.681818	test: 0.831618
PRC train: 0.900434	val: 0.383613	test: 0.906453

Epoch: 22
Loss: 0.3865774818314883
ROC train: 0.926241	val: 0.709197	test: 0.824937
PRC train: 0.906299	val: 0.416557	test: 0.899076

Epoch: 23
Loss: 0.3822829812420646
ROC train: 0.924115	val: 0.706554	test: 0.807331
PRC train: 0.902848	val: 0.429655	test: 0.885988

Epoch: 24
Loss: 0.40183279745917266
ROC train: 0.920729	val: 0.688372	test: 0.792615
PRC train: 0.899083	val: 0.425934	test: 0.874621

Epoch: 25
Loss: 0.3701681037732712
ROC train: 0.919484	val: 0.678013	test: 0.790358
PRC train: 0.898128	val: 0.411974	test: 0.876704

Epoch: 26
Loss: 0.3762373018982987
ROC train: 0.922589	val: 0.694926	test: 0.799567
PRC train: 0.902018	val: 0.415232	test: 0.885786

Epoch: 27
Loss: 0.38976783965098316
ROC train: 0.925576	val: 0.709937	test: 0.808234
PRC train: 0.906609	val: 0.409712	test: 0.889645

Epoch: 28
Loss: 0.3537154964557506
ROC train: 0.929361	val: 0.706871	test: 0.813561
PRC train: 0.912016	val: 0.394475	test: 0.891345

Epoch: 29
Loss: 0.3650760004327997
ROC train: 0.931786	val: 0.708245	test: 0.817263
PRC train: 0.914568	val: 0.392145	test: 0.896173

Epoch: 30
Loss: 0.38216346830112313
ROC train: 0.933600	val: 0.718922	test: 0.820332
PRC train: 0.915910	val: 0.409184	test: 0.900757

Epoch: 31
Loss: 0.354949164693318
ROC train: 0.932905	val: 0.722199	test: 0.811033
PRC train: 0.914097	val: 0.411962	test: 0.898066

Epoch: 32
Loss: 0.37086930844341615
ROC train: 0.931329	val: 0.718710	test: 0.803449
PRC train: 0.911594	val: 0.404220	test: 0.893155

Epoch: 33
Loss: 0.36659077325785683Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:2
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/scaff/train_prop=0.8/bace_scaff_3_20-05_14-43-16  ]
[ Using Seed :  3  ]
[ Using device :  cuda:2  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
split via scaffold
Data(edge_attr=[66, 2], edge_index=[2, 66], id=[1], x=[31, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6786352505246442
ROC train: 0.703393	val: 0.666667	test: 0.582160
PRC train: 0.605625	val: 0.913759	test: 0.553861

Epoch: 2
Loss: 0.6326755482163049
ROC train: 0.769224	val: 0.658974	test: 0.586159
PRC train: 0.664003	val: 0.913846	test: 0.583159

Epoch: 3
Loss: 0.5709319009494208
ROC train: 0.803630	val: 0.624908	test: 0.615719
PRC train: 0.702869	val: 0.906528	test: 0.614330

Epoch: 4
Loss: 0.5576336095336336
ROC train: 0.832346	val: 0.631868	test: 0.646322
PRC train: 0.734870	val: 0.911591	test: 0.656709

Epoch: 5
Loss: 0.5159137055447134
ROC train: 0.851421	val: 0.639194	test: 0.688576
PRC train: 0.763115	val: 0.916172	test: 0.698052

Epoch: 6
Loss: 0.4797677744523224
ROC train: 0.870482	val: 0.660073	test: 0.740567
PRC train: 0.800397	val: 0.923740	test: 0.760446

Epoch: 7
Loss: 0.4741287483515566
ROC train: 0.880528	val: 0.663004	test: 0.761259
PRC train: 0.815853	val: 0.927781	test: 0.779552

Epoch: 8
Loss: 0.4328242483539265
ROC train: 0.893276	val: 0.656410	test: 0.788732
PRC train: 0.829816	val: 0.930945	test: 0.790782

Epoch: 9
Loss: 0.4464956108469316
ROC train: 0.899717	val: 0.662271	test: 0.797427
PRC train: 0.839438	val: 0.934351	test: 0.806691

Epoch: 10
Loss: 0.41746661189401146
ROC train: 0.904737	val: 0.668498	test: 0.777082
PRC train: 0.845786	val: 0.937074	test: 0.798317

Epoch: 11
Loss: 0.40580089538977315
ROC train: 0.909963	val: 0.674725	test: 0.788385
PRC train: 0.854644	val: 0.939409	test: 0.808071

Epoch: 12
Loss: 0.4237605413140605
ROC train: 0.913094	val: 0.674725	test: 0.788211
PRC train: 0.860381	val: 0.937564	test: 0.808607

Epoch: 13
Loss: 0.39681861688308084
ROC train: 0.917166	val: 0.661172	test: 0.776039
PRC train: 0.865464	val: 0.933675	test: 0.784181

Epoch: 14
Loss: 0.39247747860621923
ROC train: 0.919110	val: 0.663004	test: 0.771170
PRC train: 0.870431	val: 0.931565	test: 0.773328

Epoch: 15
Loss: 0.3918874850207147
ROC train: 0.919909	val: 0.663736	test: 0.763172
PRC train: 0.872695	val: 0.932673	test: 0.764036

Epoch: 16
Loss: 0.3824764862595669
ROC train: 0.919503	val: 0.636630	test: 0.767171
PRC train: 0.874530	val: 0.926333	test: 0.766183

Epoch: 17
Loss: 0.38723143506943725
ROC train: 0.924926	val: 0.651648	test: 0.770127
PRC train: 0.881071	val: 0.929229	test: 0.770998

Epoch: 18
Loss: 0.3873478464499098
ROC train: 0.926167	val: 0.653480	test: 0.771170
PRC train: 0.882153	val: 0.927738	test: 0.769721

Epoch: 19
Loss: 0.3553796410488995
ROC train: 0.929215	val: 0.647619	test: 0.772214
PRC train: 0.887329	val: 0.926447	test: 0.776723

Epoch: 20
Loss: 0.3713729331921211
ROC train: 0.932840	val: 0.639194	test: 0.782646
PRC train: 0.891993	val: 0.921236	test: 0.782604

Epoch: 21
Loss: 0.35552994560426865
ROC train: 0.935365	val: 0.654579	test: 0.786646
PRC train: 0.894684	val: 0.924093	test: 0.784373

Epoch: 22
Loss: 0.35673588686908914
ROC train: 0.938091	val: 0.647253	test: 0.780038
PRC train: 0.900169	val: 0.920306	test: 0.769209

Epoch: 23
Loss: 0.3383697806607117
ROC train: 0.939957	val: 0.644322	test: 0.769779
PRC train: 0.902542	val: 0.920269	test: 0.757003

Epoch: 24
Loss: 0.3499884653685382
ROC train: 0.940337	val: 0.643223	test: 0.763346
PRC train: 0.904491	val: 0.920634	test: 0.746584

Epoch: 25
Loss: 0.35714052364769006
ROC train: 0.939715	val: 0.662271	test: 0.762824
PRC train: 0.903501	val: 0.927717	test: 0.752223

Epoch: 26
Loss: 0.34087669098358286
ROC train: 0.944312	val: 0.665934	test: 0.765954
PRC train: 0.911022	val: 0.926103	test: 0.763983

Epoch: 27
Loss: 0.344607428047921
ROC train: 0.943365	val: 0.665201	test: 0.765258
PRC train: 0.909126	val: 0.923830	test: 0.763117

Epoch: 28
Loss: 0.3422233870057859
ROC train: 0.942717	val: 0.675092	test: 0.759520
PRC train: 0.907535	val: 0.926606	test: 0.757037

Epoch: 29
Loss: 0.3305772435998446
ROC train: 0.946136	val: 0.668498	test: 0.760563
PRC train: 0.913334	val: 0.926759	test: 0.756431

Epoch: 30
Loss: 0.3504042335435319
ROC train: 0.948793	val: 0.668132	test: 0.764737
PRC train: 0.917609	val: 0.927032	test: 0.765389

Epoch: 31
Loss: 0.32376651900884024
ROC train: 0.950465	val: 0.652747	test: 0.762824
PRC train: 0.921239	val: 0.921593	test: 0.761541

Epoch: 32
Loss: 0.3320217869729173
ROC train: 0.950756	val: 0.663004	test: 0.746305
PRC train: 0.921537	val: 0.924193	test: 0.736388

Epoch: 33
Loss: 0.32196055407990654
ROC train: 0.950245	val: 0.676557	test: 0.737437Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/bace/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:2
  input_data_dir: 
  dataset: bace
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/bace/scaff/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/bace/scaff/train_prop=0.8/bace_scaff_2_20-05_14-43-16  ]
[ Using Seed :  2  ]
[ Using device :  cuda:2  ]
Dataset: bace
Data: Data(edge_attr=[111536, 2], edge_index=[2, 111536], id=[1513], x=[51577, 2], y=[1513])
MoleculeDataset(1513)
split via scaffold
Data(edge_attr=[66, 2], edge_index=[2, 66], id=[1], x=[31, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.674567037665118
ROC train: 0.675188	val: 0.622711	test: 0.643192
PRC train: 0.576998	val: 0.910242	test: 0.603441

Epoch: 2
Loss: 0.6252738526854934
ROC train: 0.762731	val: 0.611722	test: 0.661624
PRC train: 0.655690	val: 0.907796	test: 0.621127

Epoch: 3
Loss: 0.5695561879532214
ROC train: 0.806396	val: 0.615385	test: 0.680577
PRC train: 0.707924	val: 0.896953	test: 0.642179

Epoch: 4
Loss: 0.5469529193557406
ROC train: 0.834857	val: 0.630037	test: 0.708225
PRC train: 0.734168	val: 0.899598	test: 0.693600

Epoch: 5
Loss: 0.5087387068496532
ROC train: 0.859729	val: 0.625641	test: 0.748739
PRC train: 0.762015	val: 0.902010	test: 0.746297

Epoch: 6
Loss: 0.48216946263720856
ROC train: 0.874209	val: 0.627839	test: 0.758477
PRC train: 0.787634	val: 0.899304	test: 0.749907

Epoch: 7
Loss: 0.4614073687194346
ROC train: 0.889489	val: 0.650916	test: 0.775170
PRC train: 0.818909	val: 0.925093	test: 0.761636

Epoch: 8
Loss: 0.4439990761895534
ROC train: 0.893650	val: 0.662637	test: 0.797079
PRC train: 0.822598	val: 0.933063	test: 0.789593

Epoch: 9
Loss: 0.43099318018218397
ROC train: 0.898838	val: 0.680952	test: 0.783168
PRC train: 0.830428	val: 0.938558	test: 0.778641

Epoch: 10
Loss: 0.4234911173813661
ROC train: 0.897763	val: 0.702930	test: 0.745609
PRC train: 0.830691	val: 0.944817	test: 0.736827

Epoch: 11
Loss: 0.4219398465015308
ROC train: 0.903727	val: 0.690842	test: 0.768040
PRC train: 0.839234	val: 0.942410	test: 0.749252

Epoch: 12
Loss: 0.41694317556068333
ROC train: 0.911524	val: 0.668864	test: 0.786124
PRC train: 0.852626	val: 0.934984	test: 0.771583

Epoch: 13
Loss: 0.39024245286437725
ROC train: 0.914053	val: 0.657509	test: 0.768040
PRC train: 0.855374	val: 0.929956	test: 0.761752

Epoch: 14
Loss: 0.3992104868436472
ROC train: 0.917643	val: 0.668132	test: 0.768910
PRC train: 0.861187	val: 0.933088	test: 0.761013

Epoch: 15
Loss: 0.4023159360488589
ROC train: 0.920268	val: 0.672161	test: 0.774300
PRC train: 0.865228	val: 0.933504	test: 0.763680

Epoch: 16
Loss: 0.3764095851860602
ROC train: 0.921715	val: 0.673260	test: 0.761433
PRC train: 0.870175	val: 0.934816	test: 0.751817

Epoch: 17
Loss: 0.3945847456640682
ROC train: 0.922842	val: 0.687179	test: 0.749783
PRC train: 0.872097	val: 0.937796	test: 0.743470

Epoch: 18
Loss: 0.3681240001352921
ROC train: 0.923642	val: 0.700733	test: 0.751695
PRC train: 0.874724	val: 0.940713	test: 0.751761

Epoch: 19
Loss: 0.3732301459407974
ROC train: 0.926318	val: 0.698535	test: 0.756564
PRC train: 0.879490	val: 0.939573	test: 0.759047

Epoch: 20
Loss: 0.3731886694083779
ROC train: 0.928610	val: 0.682418	test: 0.752739
PRC train: 0.883856	val: 0.934045	test: 0.754521

Epoch: 21
Loss: 0.35837532171593683
ROC train: 0.930848	val: 0.679853	test: 0.745957
PRC train: 0.887404	val: 0.932187	test: 0.740335

Epoch: 22
Loss: 0.37356576725858376
ROC train: 0.930380	val: 0.683150	test: 0.749783
PRC train: 0.885861	val: 0.932414	test: 0.738207

Epoch: 23
Loss: 0.3707546057751371
ROC train: 0.933716	val: 0.677289	test: 0.766649
PRC train: 0.893175	val: 0.931772	test: 0.754273

Epoch: 24
Loss: 0.3444528562937091
ROC train: 0.936436	val: 0.679853	test: 0.752565
PRC train: 0.896059	val: 0.932997	test: 0.747208

Epoch: 25
Loss: 0.3660735535876583
ROC train: 0.936378	val: 0.699634	test: 0.745957
PRC train: 0.895344	val: 0.937723	test: 0.743011

Epoch: 26
Loss: 0.34446579518704856
ROC train: 0.938936	val: 0.701832	test: 0.756042
PRC train: 0.898374	val: 0.939268	test: 0.740760

Epoch: 27
Loss: 0.3395771196030535
ROC train: 0.941932	val: 0.701832	test: 0.761085
PRC train: 0.905409	val: 0.937463	test: 0.748464

Epoch: 28
Loss: 0.34086727184792426
ROC train: 0.944192	val: 0.683150	test: 0.758825
PRC train: 0.909795	val: 0.932918	test: 0.743707

Epoch: 29
Loss: 0.34202592022458145
ROC train: 0.940131	val: 0.685714	test: 0.747348
PRC train: 0.905372	val: 0.934523	test: 0.742830

Epoch: 30
Loss: 0.33708061976334214
ROC train: 0.942534	val: 0.678755	test: 0.744045
PRC train: 0.909029	val: 0.928749	test: 0.743852

Epoch: 31
Loss: 0.33836474869895855
ROC train: 0.945654	val: 0.667033	test: 0.744218
PRC train: 0.913766	val: 0.923340	test: 0.736679

Epoch: 32
Loss: 0.3474402562000944
ROC train: 0.945788	val: 0.675824	test: 0.732742
PRC train: 0.913695	val: 0.926620	test: 0.731426

Epoch: 33
Loss: 0.32949539245768616
ROC train: 0.943582	val: 0.660440	test: 0.745957
ROC train: 0.936707	val: 0.868104	test: 0.740367
PRC train: 0.922880	val: 0.447817	test: 0.854560

Epoch: 34
Loss: 0.3601765185073681
ROC train: 0.936221	val: 0.871698	test: 0.739903
PRC train: 0.921838	val: 0.463500	test: 0.854929

Epoch: 35
Loss: 0.3619563736824312
ROC train: 0.938167	val: 0.867424	test: 0.734340
PRC train: 0.925105	val: 0.454871	test: 0.851932

Epoch: 36
Loss: 0.34120580745360657
ROC train: 0.940089	val: 0.864705	test: 0.734803
PRC train: 0.928106	val: 0.449671	test: 0.847775

Epoch: 37
Loss: 0.34377505078703396
ROC train: 0.940629	val: 0.859363	test: 0.733876
PRC train: 0.929113	val: 0.443229	test: 0.847096

Epoch: 38
Loss: 0.3542975940220259
ROC train: 0.943715	val: 0.856546	test: 0.726715
PRC train: 0.933476	val: 0.437826	test: 0.844753

Epoch: 39
Loss: 0.35525524430307837
ROC train: 0.945817	val: 0.861791	test: 0.718885
PRC train: 0.938141	val: 0.444232	test: 0.837293

Epoch: 40
Loss: 0.3192240741997786
ROC train: 0.943281	val: 0.869949	test: 0.707861
PRC train: 0.936004	val: 0.461533	test: 0.832561

Epoch: 41
Loss: 0.34227856636324144
ROC train: 0.945228	val: 0.875874	test: 0.720482
PRC train: 0.938541	val: 0.471616	test: 0.839027

Epoch: 42
Loss: 0.3498921529966905
ROC train: 0.946284	val: 0.864608	test: 0.736812
PRC train: 0.938111	val: 0.464715	test: 0.853024

Epoch: 43
Loss: 0.34891780556638846
ROC train: 0.947028	val: 0.842075	test: 0.743561
PRC train: 0.938682	val: 0.426532	test: 0.858609

Epoch: 44
Loss: 0.3441694504770565
ROC train: 0.945690	val: 0.829740	test: 0.743612
PRC train: 0.937596	val: 0.390039	test: 0.858326

Epoch: 45
Loss: 0.34466473921340984
ROC train: 0.948474	val: 0.837121	test: 0.738924
PRC train: 0.943004	val: 0.400767	test: 0.854725

Epoch: 46
Loss: 0.34660507225413273
ROC train: 0.950576	val: 0.857226	test: 0.729394
PRC train: 0.945627	val: 0.423284	test: 0.851456

Epoch: 47
Loss: 0.3353994363784445
ROC train: 0.951549	val: 0.873155	test: 0.725428
PRC train: 0.946584	val: 0.450478	test: 0.850751

Epoch: 48
Loss: 0.3203165308550816
ROC train: 0.952357	val: 0.875194	test: 0.730991
PRC train: 0.947777	val: 0.463419	test: 0.854245

Epoch: 49
Loss: 0.3183608205673622
ROC train: 0.954040	val: 0.859363	test: 0.745982
PRC train: 0.948798	val: 0.443886	test: 0.861013

Epoch: 50
Loss: 0.32936976976406906
ROC train: 0.957383	val: 0.839841	test: 0.757779
PRC train: 0.952182	val: 0.413817	test: 0.865371

Epoch: 51
Loss: 0.31968949942819413
ROC train: 0.956960	val: 0.838092	test: 0.758242
PRC train: 0.953033	val: 0.403018	test: 0.864595

Epoch: 52
Loss: 0.31605881372286393
ROC train: 0.956249	val: 0.837510	test: 0.752679
PRC train: 0.953004	val: 0.402204	test: 0.863987

Epoch: 53
Loss: 0.30378178835357794
ROC train: 0.956678	val: 0.846057	test: 0.739027
PRC train: 0.953032	val: 0.419019	test: 0.858441

Epoch: 54
Loss: 0.3266525632021124
ROC train: 0.957928	val: 0.849650	test: 0.731970
PRC train: 0.952876	val: 0.430890	test: 0.851489

Epoch: 55
Loss: 0.31760372278063115
ROC train: 0.955870	val: 0.850233	test: 0.723573
PRC train: 0.950617	val: 0.445554	test: 0.842294

Epoch: 56
Loss: 0.30768099964533885
ROC train: 0.958342	val: 0.846737	test: 0.718782
PRC train: 0.953547	val: 0.436592	test: 0.841598

Epoch: 57
Loss: 0.30573901974320317
ROC train: 0.959262	val: 0.841200	test: 0.727025
PRC train: 0.955571	val: 0.422618	test: 0.850806

Epoch: 58
Loss: 0.30483094411052175
ROC train: 0.960035	val: 0.832751	test: 0.741088
PRC train: 0.955994	val: 0.417247	test: 0.858425

Epoch: 59
Loss: 0.28485459420651593
ROC train: 0.962882	val: 0.829448	test: 0.752009
PRC train: 0.958243	val: 0.414994	test: 0.862903

Epoch: 60
Loss: 0.32044363465566833
ROC train: 0.963510	val: 0.839938	test: 0.744282
PRC train: 0.959208	val: 0.422751	test: 0.858030

Epoch: 61
Loss: 0.30910796507936394
ROC train: 0.961699	val: 0.854604	test: 0.733000
PRC train: 0.957853	val: 0.432835	test: 0.850271

Epoch: 62
Loss: 0.30316986283053515
ROC train: 0.962079	val: 0.854409	test: 0.726200
PRC train: 0.958938	val: 0.423201	test: 0.847340

Epoch: 63
Loss: 0.29550671722246125
ROC train: 0.964162	val: 0.844017	test: 0.722749
PRC train: 0.961485	val: 0.417408	test: 0.842637

Epoch: 64
Loss: 0.29174390229147273
ROC train: 0.966926	val: 0.838772	test: 0.727849
PRC train: 0.964124	val: 0.415281	test: 0.840811

Epoch: 65
Loss: 0.29157833236292185
ROC train: 0.967471	val: 0.838481	test: 0.733052
PRC train: 0.964612	val: 0.420451	test: 0.844661

Epoch: 66
Loss: 0.29610881013396684
ROC train: 0.967067	val: 0.850233	test: 0.728364
PRC train: 0.964223	val: 0.441085	test: 0.846329

Epoch: 67
Loss: 0.3118051992546059
ROC train: 0.966527	val: 0.841589	test: 0.733000
PRC train: 0.963342	val: 0.439689	test: 0.851835

Epoch: 68
Loss: 0.2945989046395935
ROC train: 0.964848	val: 0.832751	test: 0.742015
PRC train: 0.961107	val: 0.433095	test: 0.857680

Epoch: 69
Loss: 0.2942760067174346
ROC train: 0.966838	val: 0.836344	test: 0.739027
PRC train: 0.962943	val: 0.430402	test: 0.856518

Epoch: 70
Loss: 0.2909014295198395
ROC train: 0.968955	val: 0.833528	test: 0.737740
PRC train: 0.965937	val: 0.419092	test: 0.854103

Epoch: 71
Loss: 0.3046740613989151
ROC train: 0.966979	val: 0.837510	test: 0.729703
PRC train: 0.963669	val: 0.409470	test: 0.848332

Epoch: 72
Loss: 0.2837511794753965
ROC train: 0.966040	val: 0.842366	test: 0.727540
PRC train: 0.962995	val: 0.411739	test: 0.845687

Epoch: 73
Loss: 0.30081491624609147
ROC train: 0.969057	val: 0.834305	test: 0.734494
PRC train: 0.966802	val: 0.411836	test: 0.853290

Epoch: 74
Loss: 0.27933178364373246
ROC train: 0.969665	val: 0.827506	test: 0.743921
PRC train: 0.968042	val: 0.405640	test: 0.856420

Epoch: 75
Loss: 0.27671329916730747
ROC train: 0.970643	val: 0.835956	test: 0.733515
PRC train: 0.969219	val: 0.422643	test: 0.849287

Epoch: 76
Loss: 0.2740619621921447
ROC train: 0.969261	val: 0.842949	test: 0.722749
PRC train: 0.967575	val: 0.444375	test: 0.833545

Epoch: 77
Loss: 0.27522394418869633
ROC train: 0.969441	val: 0.840715	test: 0.721615
PRC train: 0.968134	val: 0.441336	test: 0.837189

Epoch: 78
Loss: 0.2698258431920335
ROC train: 0.972113	val: 0.841686	test: 0.718731
PRC train: 0.971239	val: 0.427859	test: 0.840347

Epoch: 79
Loss: 0.2826290150534485
ROC train: 0.971986	val: 0.837121	test: 0.720534
PRC train: 0.970458	val: 0.420386	test: 0.841130

Epoch: 80
Loss: 0.29521853215933386
ROC train: 0.972672	val: 0.835470	test: 0.735937
PRC train: 0.971380	val: 0.406677	test: 0.847940

Epoch: 81
Loss: 0.26112099733187244
ROC train: 0.973962	val: 0.829740	test: 0.743458
PRC train: 0.972324	val: 0.386278	test: 0.846303

Epoch: 82
Loss: 0.2673746680441093
ROC train: 0.971845	val: 0.818862	test: 0.744333
PRC train: 0.970552	val: 0.379254	test: 0.844573

Epoch: 83
Loss: 0.2921909799998198
ROC train: 0.968901	val: 0.805264	test: 0.736194
PRC train: 0.967214	val: 0.369261	test: 0.844621

Epoch: 84
Loss: 0.2725009301694376
ROC train: 0.968050	val: 0.792249	test: 0.720534
PRC train: 0.965996	val: 0.358418	test: 0.830571

Epoch: 85
Loss: 0.2766156700020451
ROC train: 0.972993	val: 0.815948	test: 0.711004
PRC train: 0.971084	val: 0.394543	test: 0.821306

Epoch: 86
Loss: 0.25496489638782777
ROC train: 0.973543	val: 0.821193	test: 0.719864
PRC train: 0.971502	val: 0.403752	test: 0.827740

Epoch: 87
Loss: 0.2622237066103614
ROC train: 0.974809	val: 0.826243	test: 0.725943
PRC train: 0.972930	val: 0.410579	test: 0.836631

Epoch: 88
Loss: 0.2738080224147479
ROC train: 0.974619	val: 0.813908	test: 0.718834
PRC train: 0.972807	val: 0.378347	test: 0.839639

Epoch: 89
Loss: 0.26225869390835027
ROC train: 0.975120	val: 0.825078	test: 0.693540
PRC train: 0.973709	val: 0.393502	test: 0.822827

Epoch: 90
Loss: 0.27089551836060055
ROC train: 0.978156	val: 0.853341	test: 0.682722
PRC train: 0.977121	val: 0.432048	test: 0.805402

Epoch: 91
Loss: 0.25325637237499
ROC train: 0.977806	val: 0.847222	test: 0.688234
PRC train: 0.977175	val: 0.429216	test: 0.809709

Epoch: 92
Loss: 0.25785788388116976
ROC train: 0.977616	val: 0.828477	test: 0.697764
PRC train: 0.977006	val: 0.408460	test: 0.822708

Epoch: 93
Loss: 0.25593571510561425
ROC train: 0.977748	val: 0.814977	test: 0.701731
PRC train: 0.977029	val: 0.401344	test: 0.828759

Epoch: 94
Loss: 0.2537384039600025
PRC train: 0.935946	val: 0.425287	test: 0.861011

Epoch: 34
Loss: 0.3494519504427024
ROC train: 0.944396	val: 0.853827	test: 0.747373
PRC train: 0.937001	val: 0.422670	test: 0.862808

Epoch: 35
Loss: 0.34969805519309055
ROC train: 0.944503	val: 0.861791	test: 0.746961
PRC train: 0.936866	val: 0.435661	test: 0.861000

Epoch: 36
Loss: 0.3444651502427363
ROC train: 0.944493	val: 0.873932	test: 0.740006
PRC train: 0.936630	val: 0.448083	test: 0.856933

Epoch: 37
Loss: 0.3458316870515046
ROC train: 0.944785	val: 0.862665	test: 0.753812
PRC train: 0.936702	val: 0.424762	test: 0.862737

Epoch: 38
Loss: 0.3466300314087732
ROC train: 0.947393	val: 0.851787	test: 0.762570
PRC train: 0.939475	val: 0.413053	test: 0.867950

Epoch: 39
Loss: 0.3193333289502811
ROC train: 0.948970	val: 0.841298	test: 0.756697
PRC train: 0.941441	val: 0.412414	test: 0.864002

Epoch: 40
Loss: 0.3312638232441637
ROC train: 0.949398	val: 0.844114	test: 0.758448
PRC train: 0.942722	val: 0.384253	test: 0.870404

Epoch: 41
Loss: 0.3264460113230375
ROC train: 0.950853	val: 0.849747	test: 0.766588
PRC train: 0.945323	val: 0.386969	test: 0.873859

Epoch: 42
Loss: 0.3340011089817533
ROC train: 0.953242	val: 0.853535	test: 0.762621
PRC train: 0.948805	val: 0.422724	test: 0.870576

Epoch: 43
Loss: 0.33972097748645297
ROC train: 0.955121	val: 0.864316	test: 0.739285
PRC train: 0.950187	val: 0.433164	test: 0.860070

Epoch: 44
Loss: 0.33665291101937933
ROC train: 0.956074	val: 0.863928	test: 0.736503
PRC train: 0.950766	val: 0.426580	test: 0.861744

Epoch: 45
Loss: 0.3226138343479279
ROC train: 0.953773	val: 0.864802	test: 0.735112
PRC train: 0.947386	val: 0.449712	test: 0.861659

Epoch: 46
Loss: 0.33495194690829977
ROC train: 0.951096	val: 0.861888	test: 0.740315
PRC train: 0.945157	val: 0.441503	test: 0.864247

Epoch: 47
Loss: 0.3277009966086294
ROC train: 0.955558	val: 0.858780	test: 0.751700
PRC train: 0.950550	val: 0.416575	test: 0.865217

Epoch: 48
Loss: 0.31251799148490494
ROC train: 0.956035	val: 0.852564	test: 0.758242
PRC train: 0.951239	val: 0.408868	test: 0.864357

Epoch: 49
Loss: 0.3149156249148496
ROC train: 0.954590	val: 0.854215	test: 0.751442
PRC train: 0.949639	val: 0.407453	test: 0.862677

Epoch: 50
Loss: 0.3333169017883431
ROC train: 0.954580	val: 0.863539	test: 0.737327
PRC train: 0.949528	val: 0.411235	test: 0.861844

Epoch: 51
Loss: 0.3088569306391401
ROC train: 0.956215	val: 0.866647	test: 0.725582
PRC train: 0.951058	val: 0.416764	test: 0.856610

Epoch: 52
Loss: 0.3210291184444153
ROC train: 0.958225	val: 0.865385	test: 0.739440
PRC train: 0.952732	val: 0.416519	test: 0.862185

Epoch: 53
Loss: 0.322011875655257
ROC train: 0.960337	val: 0.861888	test: 0.746600
PRC train: 0.954868	val: 0.418219	test: 0.860922

Epoch: 54
Loss: 0.30818223694766494
ROC train: 0.961948	val: 0.858683	test: 0.748815
PRC train: 0.957308	val: 0.415452	test: 0.859383

Epoch: 55
Loss: 0.29230721573257523
ROC train: 0.961271	val: 0.861985	test: 0.750412
PRC train: 0.957070	val: 0.419796	test: 0.857893

Epoch: 56
Loss: 0.30567461080648184
ROC train: 0.960887	val: 0.855672	test: 0.755821
PRC train: 0.956412	val: 0.401440	test: 0.864577

Epoch: 57
Loss: 0.30904174793298234
ROC train: 0.960843	val: 0.861888	test: 0.745312
PRC train: 0.956405	val: 0.412806	test: 0.860031

Epoch: 58
Loss: 0.3155771061680869
ROC train: 0.962609	val: 0.849068	test: 0.742273
PRC train: 0.959410	val: 0.398886	test: 0.848987

Epoch: 59
Loss: 0.3132343268050414
ROC train: 0.963208	val: 0.838287	test: 0.754121
PRC train: 0.960933	val: 0.384707	test: 0.849977

Epoch: 60
Loss: 0.3034777980875253
ROC train: 0.963505	val: 0.842949	test: 0.756388
PRC train: 0.960945	val: 0.393236	test: 0.850035

Epoch: 61
Loss: 0.28813329275268995
ROC train: 0.962142	val: 0.846931	test: 0.745312
PRC train: 0.959383	val: 0.385821	test: 0.848370

Epoch: 62
Loss: 0.29055750351464615
ROC train: 0.962176	val: 0.843629	test: 0.734391
PRC train: 0.958880	val: 0.383605	test: 0.846393

Epoch: 63
Loss: 0.287195839956848
ROC train: 0.958532	val: 0.837607	test: 0.724912
PRC train: 0.954157	val: 0.380361	test: 0.836781

Epoch: 64
Loss: 0.28357896275558836
ROC train: 0.966351	val: 0.841880	test: 0.728570
PRC train: 0.962289	val: 0.392472	test: 0.841494

Epoch: 65
Loss: 0.30663443645529076
ROC train: 0.969913	val: 0.855963	test: 0.733670
PRC train: 0.966673	val: 0.414338	test: 0.847131

Epoch: 66
Loss: 0.273229306725155
ROC train: 0.969368	val: 0.858877	test: 0.724294
PRC train: 0.966500	val: 0.417595	test: 0.844622

Epoch: 67
Loss: 0.2709799334714831
ROC train: 0.970123	val: 0.855769	test: 0.727334
PRC train: 0.967403	val: 0.418180	test: 0.844355

Epoch: 68
Loss: 0.28855599675984656
ROC train: 0.971646	val: 0.848873	test: 0.738255
PRC train: 0.968145	val: 0.413058	test: 0.848934

Epoch: 69
Loss: 0.2596767726152477
ROC train: 0.971577	val: 0.856546	test: 0.749227
PRC train: 0.967921	val: 0.425088	test: 0.853880

Epoch: 70
Loss: 0.275377273484691
ROC train: 0.969865	val: 0.864413	test: 0.752833
PRC train: 0.966746	val: 0.439765	test: 0.854758

Epoch: 71
Loss: 0.2761787539162155
ROC train: 0.970551	val: 0.865967	test: 0.746806
PRC train: 0.967535	val: 0.443967	test: 0.851404

Epoch: 72
Loss: 0.28577266019902325
ROC train: 0.972244	val: 0.854701	test: 0.740109
PRC train: 0.968966	val: 0.421788	test: 0.848203

Epoch: 73
Loss: 0.28242359731476674
ROC train: 0.971792	val: 0.853341	test: 0.733567
PRC train: 0.968699	val: 0.423434	test: 0.839235

Epoch: 74
Loss: 0.2862890569055285
ROC train: 0.970142	val: 0.854021	test: 0.737379
PRC train: 0.966668	val: 0.401200	test: 0.845081

Epoch: 75
Loss: 0.25739972203012285
ROC train: 0.969651	val: 0.858003	test: 0.726715
PRC train: 0.966158	val: 0.428500	test: 0.848567

Epoch: 76
Loss: 0.2665703344238429
ROC train: 0.970371	val: 0.856061	test: 0.724706
PRC train: 0.966811	val: 0.442413	test: 0.850054

Epoch: 77
Loss: 0.26442777478155566
ROC train: 0.971310	val: 0.847125	test: 0.715022
PRC train: 0.968430	val: 0.423445	test: 0.839368

Epoch: 78
Loss: 0.26601876115685524
ROC train: 0.974940	val: 0.860140	test: 0.715331
PRC train: 0.972515	val: 0.444889	test: 0.826958

Epoch: 79
Loss: 0.270614217295728
ROC train: 0.973986	val: 0.847902	test: 0.733000
PRC train: 0.971367	val: 0.417705	test: 0.854258

Epoch: 80
Loss: 0.2694280073773958
ROC train: 0.973748	val: 0.842852	test: 0.742324
PRC train: 0.971066	val: 0.391474	test: 0.860504

Epoch: 81
Loss: 0.26093469229721883
ROC train: 0.973388	val: 0.842754	test: 0.740264
PRC train: 0.970783	val: 0.393858	test: 0.860801

Epoch: 82
Loss: 0.2647101507980762
ROC train: 0.971514	val: 0.842463	test: 0.722234
PRC train: 0.968891	val: 0.398070	test: 0.852410

Epoch: 83
Loss: 0.26005651704651744
ROC train: 0.974585	val: 0.844017	test: 0.719040
PRC train: 0.972418	val: 0.397891	test: 0.848749

Epoch: 84
Loss: 0.2588761479091598
ROC train: 0.975830	val: 0.842366	test: 0.726046
PRC train: 0.973841	val: 0.389613	test: 0.851707

Epoch: 85
Loss: 0.2621648533026042
ROC train: 0.976901	val: 0.842463	test: 0.728931
PRC train: 0.975188	val: 0.393210	test: 0.850375

Epoch: 86
Loss: 0.2566812421731043
ROC train: 0.977461	val: 0.851981	test: 0.717237
PRC train: 0.975364	val: 0.406682	test: 0.835965

Epoch: 87
Loss: 0.24932296249313313
ROC train: 0.976662	val: 0.848193	test: 0.721564
PRC train: 0.974642	val: 0.400919	test: 0.838912

Epoch: 88
Loss: 0.26498947652049154
ROC train: 0.976984	val: 0.856061	test: 0.710900
PRC train: 0.975540	val: 0.409109	test: 0.828137

Epoch: 89
Loss: 0.2557332442214013
ROC train: 0.978541	val: 0.858974	test: 0.710591
PRC train: 0.977133	val: 0.411855	test: 0.824098

Epoch: 90
Loss: 0.2446667478923097
ROC train: 0.978920	val: 0.851204	test: 0.723831
PRC train: 0.977362	val: 0.397648	test: 0.836799

Epoch: 91
Loss: 0.2640829724355679
ROC train: 0.979241	val: 0.846348	test: 0.728261
PRC train: 0.977538	val: 0.398724	test: 0.842267

Epoch: 92
Loss: 0.24722723122454
ROC train: 0.979358	val: 0.846737	test: 0.727900
PRC train: 0.977566	val: 0.404948	test: 0.845061

Epoch: 93
Loss: 0.26352932761094067
ROC train: 0.978215	val: 0.846542	test: 0.723006
PRC train: 0.976718	val: 0.435048	test: 0.848438

Epoch: 94
Loss: 0.24668083875559982
ROC train: 0.979003	val: 0.850622	test: 0.718782

PRC train: 0.936484	val: 0.406787	test: 0.854904

Epoch: 34
Loss: 0.34529054431699124
ROC train: 0.947413	val: 0.858780	test: 0.726715
PRC train: 0.941517	val: 0.411845	test: 0.850461

Epoch: 35
Loss: 0.3383005812675603
ROC train: 0.945885	val: 0.860043	test: 0.735834
PRC train: 0.939067	val: 0.411248	test: 0.854173

Epoch: 36
Loss: 0.35301041571452707
ROC train: 0.943101	val: 0.862179	test: 0.729652
PRC train: 0.935733	val: 0.412380	test: 0.850017

Epoch: 37
Loss: 0.3695710397197917
ROC train: 0.944527	val: 0.865870	test: 0.743200
PRC train: 0.937684	val: 0.423320	test: 0.855996

Epoch: 38
Loss: 0.33800558241025686
ROC train: 0.948746	val: 0.869949	test: 0.737585
PRC train: 0.942452	val: 0.427052	test: 0.853568

Epoch: 39
Loss: 0.33942430726433526
ROC train: 0.949972	val: 0.873155	test: 0.727746
PRC train: 0.943257	val: 0.439758	test: 0.851535

Epoch: 40
Loss: 0.3442727704281552
ROC train: 0.950795	val: 0.864122	test: 0.714867
PRC train: 0.944271	val: 0.422301	test: 0.846912

Epoch: 41
Loss: 0.3431083728357802
ROC train: 0.948225	val: 0.861208	test: 0.726252
PRC train: 0.941181	val: 0.414623	test: 0.852048

Epoch: 42
Loss: 0.3208896977054896
ROC train: 0.948503	val: 0.853341	test: 0.744282
PRC train: 0.939751	val: 0.407590	test: 0.861093

Epoch: 43
Loss: 0.3436180042052259
ROC train: 0.951325	val: 0.848388	test: 0.742273
PRC train: 0.943292	val: 0.404995	test: 0.860849

Epoch: 44
Loss: 0.3328117998062993
ROC train: 0.953836	val: 0.853244	test: 0.716979
PRC train: 0.948062	val: 0.418616	test: 0.843706

Epoch: 45
Loss: 0.34579183690818166
ROC train: 0.955578	val: 0.850719	test: 0.725325
PRC train: 0.950108	val: 0.426240	test: 0.846045

Epoch: 46
Loss: 0.3441953037375702
ROC train: 0.955743	val: 0.845377	test: 0.732846
PRC train: 0.950231	val: 0.417887	test: 0.848409

Epoch: 47
Loss: 0.3192838735637519
ROC train: 0.955228	val: 0.847319	test: 0.724500
PRC train: 0.949775	val: 0.404026	test: 0.845292

Epoch: 48
Loss: 0.3286397402684994
ROC train: 0.956366	val: 0.850816	test: 0.718422
PRC train: 0.951060	val: 0.403205	test: 0.844608

Epoch: 49
Loss: 0.33056415755802826
ROC train: 0.957880	val: 0.860528	test: 0.728931
PRC train: 0.952717	val: 0.417139	test: 0.853215

Epoch: 50
Loss: 0.3418178290138272
ROC train: 0.959116	val: 0.860917	test: 0.727591
PRC train: 0.953977	val: 0.428810	test: 0.850026

Epoch: 51
Loss: 0.32508204256134643
ROC train: 0.959344	val: 0.860723	test: 0.723522
PRC train: 0.954019	val: 0.427356	test: 0.846398

Epoch: 52
Loss: 0.31809698440212314
ROC train: 0.959553	val: 0.862956	test: 0.722852
PRC train: 0.954335	val: 0.418622	test: 0.849481

Epoch: 53
Loss: 0.3118378735611861
ROC train: 0.956683	val: 0.862277	test: 0.716670
PRC train: 0.951335	val: 0.428668	test: 0.843438

Epoch: 54
Loss: 0.3109631567466805
ROC train: 0.957198	val: 0.852273	test: 0.722903
PRC train: 0.952396	val: 0.414972	test: 0.843978

Epoch: 55
Loss: 0.30389761333186793
ROC train: 0.959962	val: 0.849747	test: 0.721564
PRC train: 0.954997	val: 0.415218	test: 0.839016

Epoch: 56
Loss: 0.3009175065904812
ROC train: 0.960746	val: 0.852467	test: 0.721873
PRC train: 0.955919	val: 0.422647	test: 0.836498

Epoch: 57
Loss: 0.3172221026422902
ROC train: 0.963320	val: 0.848291	test: 0.709973
PRC train: 0.958963	val: 0.417577	test: 0.828432

Epoch: 58
Loss: 0.3097877297466985
ROC train: 0.963797	val: 0.831197	test: 0.706007
PRC train: 0.959565	val: 0.386713	test: 0.828108

Epoch: 59
Loss: 0.31948096984007635
ROC train: 0.965840	val: 0.845183	test: 0.714352
PRC train: 0.961821	val: 0.401868	test: 0.831286

Epoch: 60
Loss: 0.31021485579114805
ROC train: 0.966040	val: 0.856158	test: 0.712703
PRC train: 0.962211	val: 0.412612	test: 0.827948

Epoch: 61
Loss: 0.29560871401816885
ROC train: 0.966191	val: 0.845280	test: 0.709355
PRC train: 0.962404	val: 0.408116	test: 0.829426

Epoch: 62
Loss: 0.283641086108827
ROC train: 0.967067	val: 0.833722	test: 0.712600
PRC train: 0.963270	val: 0.386534	test: 0.836328

Epoch: 63
Loss: 0.2828268042496167
ROC train: 0.966137	val: 0.832168	test: 0.715382
PRC train: 0.962283	val: 0.384287	test: 0.840936

Epoch: 64
Loss: 0.29288905401455734
ROC train: 0.966152	val: 0.842657	test: 0.719246
PRC train: 0.962116	val: 0.399216	test: 0.841570

Epoch: 65
Loss: 0.2883616672264517
ROC train: 0.969047	val: 0.847416	test: 0.718834
PRC train: 0.965312	val: 0.406803	test: 0.838846

Epoch: 66
Loss: 0.2804397795282959
ROC train: 0.970458	val: 0.860140	test: 0.704976
PRC train: 0.967597	val: 0.430322	test: 0.827287

Epoch: 67
Loss: 0.2884989820933397
ROC train: 0.969305	val: 0.853244	test: 0.706625
PRC train: 0.966554	val: 0.418303	test: 0.826407

Epoch: 68
Loss: 0.2860450016038012
ROC train: 0.968526	val: 0.836830	test: 0.709407
PRC train: 0.965553	val: 0.395538	test: 0.838582

Epoch: 69
Loss: 0.28409589368203864
ROC train: 0.968089	val: 0.822844	test: 0.707758
PRC train: 0.964816	val: 0.375707	test: 0.834750

Epoch: 70
Loss: 0.28043371826874564
ROC train: 0.970030	val: 0.832848	test: 0.696528
PRC train: 0.966590	val: 0.382922	test: 0.819091

Epoch: 71
Loss: 0.2754193119054757
ROC train: 0.967996	val: 0.836344	test: 0.690398
PRC train: 0.964337	val: 0.384035	test: 0.817611

Epoch: 72
Loss: 0.2826674788002531
ROC train: 0.971777	val: 0.837704	test: 0.699310
PRC train: 0.968468	val: 0.382095	test: 0.818896

Epoch: 73
Loss: 0.2942782173657756
ROC train: 0.971928	val: 0.834110	test: 0.722079
PRC train: 0.968969	val: 0.376588	test: 0.832197

Epoch: 74
Loss: 0.24533972173476395
ROC train: 0.970882	val: 0.841977	test: 0.712343
PRC train: 0.968083	val: 0.397326	test: 0.827279

Epoch: 75
Loss: 0.27507865075761684
ROC train: 0.971227	val: 0.834110	test: 0.707655
PRC train: 0.968454	val: 0.390873	test: 0.828407

Epoch: 76
Loss: 0.2719822331931514
ROC train: 0.972278	val: 0.826437	test: 0.708222
PRC train: 0.969377	val: 0.374776	test: 0.828332

Epoch: 77
Loss: 0.26939542130002714
ROC train: 0.974405	val: 0.840229	test: 0.712034
PRC train: 0.972200	val: 0.390854	test: 0.827311

Epoch: 78
Loss: 0.27288429034805506
ROC train: 0.972210	val: 0.841880	test: 0.709870
PRC train: 0.970132	val: 0.398105	test: 0.820677

Epoch: 79
Loss: 0.2628582696933731
ROC train: 0.967899	val: 0.847902	test: 0.690243
PRC train: 0.965355	val: 0.403187	test: 0.815896

Epoch: 80
Loss: 0.2926572983860349
ROC train: 0.970760	val: 0.841200	test: 0.688389
PRC train: 0.968085	val: 0.374870	test: 0.825351

Epoch: 81
Loss: 0.26443664940161704
ROC train: 0.971373	val: 0.832653	test: 0.709458
PRC train: 0.968487	val: 0.372976	test: 0.842718

Epoch: 82
Loss: 0.27301008662001935
ROC train: 0.971918	val: 0.821581	test: 0.714764
PRC train: 0.969426	val: 0.365174	test: 0.840183

Epoch: 83
Loss: 0.2638431670959747
ROC train: 0.974867	val: 0.828283	test: 0.691325
PRC train: 0.972802	val: 0.364653	test: 0.820959

Epoch: 84
Loss: 0.2560802699954263
ROC train: 0.974974	val: 0.832459	test: 0.682361
PRC train: 0.973114	val: 0.367594	test: 0.808215

Epoch: 85
Loss: 0.2774612115797378
ROC train: 0.976843	val: 0.837898	test: 0.699567
PRC train: 0.975225	val: 0.376618	test: 0.809811

Epoch: 86
Loss: 0.2628054934794245
ROC train: 0.975475	val: 0.834596	test: 0.714558
PRC train: 0.972998	val: 0.371515	test: 0.822445

Epoch: 87
Loss: 0.24903470464292893
ROC train: 0.976667	val: 0.843240	test: 0.715846
PRC train: 0.973924	val: 0.383807	test: 0.820738

Epoch: 88
Loss: 0.24624572059922967
ROC train: 0.976497	val: 0.842075	test: 0.710540
PRC train: 0.973931	val: 0.392164	test: 0.818251

Epoch: 89
Loss: 0.2509514408165164
ROC train: 0.974171	val: 0.831197	test: 0.708170
PRC train: 0.971859	val: 0.381940	test: 0.812868

Epoch: 90
Loss: 0.2635261737797052
ROC train: 0.971198	val: 0.817696	test: 0.712034
PRC train: 0.969084	val: 0.377901	test: 0.817095

Epoch: 91
Loss: 0.25333798215097947
ROC train: 0.976030	val: 0.832653	test: 0.715846
PRC train: 0.974241	val: 0.380720	test: 0.824998

Epoch: 92
Loss: 0.25682745561756465
ROC train: 0.978341	val: 0.838869	test: 0.715691
PRC train: 0.976449	val: 0.390109	test: 0.824426

Epoch: 93
Loss: 0.2503095926295039
ROC train: 0.979066	val: 0.842754	test: 0.708891
PRC train: 0.977122	val: 0.399171	test: 0.817103

Epoch: 94
Loss: 0.2771894895691299
ROC train: 0.977913	val: 0.829934	test: 0.702452
ROC train: 0.935755	val: 0.739746	test: 0.780607
PRC train: 0.913434	val: 0.441224	test: 0.879486

Epoch: 34
Loss: 0.3695877213602133
ROC train: 0.934143	val: 0.733932	test: 0.774377
PRC train: 0.913209	val: 0.434458	test: 0.872702

Epoch: 35
Loss: 0.374261028529843
ROC train: 0.938205	val: 0.740803	test: 0.779252
PRC train: 0.919401	val: 0.440315	test: 0.871684

Epoch: 36
Loss: 0.36206726022461255
ROC train: 0.937784	val: 0.738795	test: 0.769863
PRC train: 0.920217	val: 0.446111	test: 0.870449

Epoch: 37
Loss: 0.3718777310994025
ROC train: 0.938723	val: 0.739958	test: 0.746569
PRC train: 0.921397	val: 0.439280	test: 0.852447

Epoch: 38
Loss: 0.37402477044727467
ROC train: 0.942793	val: 0.726850	test: 0.765349
PRC train: 0.925096	val: 0.427318	test: 0.855558

Epoch: 39
Loss: 0.37511250336835067
ROC train: 0.939393	val: 0.714271	test: 0.772571
PRC train: 0.919036	val: 0.423181	test: 0.859888

Epoch: 40
Loss: 0.370127909158724
ROC train: 0.938191	val: 0.708879	test: 0.776544
PRC train: 0.918513	val: 0.412425	test: 0.867162

Epoch: 41
Loss: 0.3644423312124866
ROC train: 0.938831	val: 0.717442	test: 0.744312
PRC train: 0.921500	val: 0.414689	test: 0.850379

Epoch: 42
Loss: 0.3427439575378878
ROC train: 0.937802	val: 0.719767	test: 0.760112
PRC train: 0.920529	val: 0.414021	test: 0.857785

Epoch: 43
Loss: 0.35431189759323267
ROC train: 0.943491	val: 0.723784	test: 0.794150
PRC train: 0.926921	val: 0.418578	test: 0.882227

Epoch: 44
Loss: 0.3523862676007821
ROC train: 0.942710	val: 0.730761	test: 0.803539
PRC train: 0.925115	val: 0.436770	test: 0.886971

Epoch: 45
Loss: 0.33731264564274677
ROC train: 0.944552	val: 0.725264	test: 0.790177
PRC train: 0.929671	val: 0.429207	test: 0.879742

Epoch: 46
Loss: 0.33187073372545967
ROC train: 0.948215	val: 0.715328	test: 0.787198
PRC train: 0.933926	val: 0.420485	test: 0.874538

Epoch: 47
Loss: 0.3714779147588388
ROC train: 0.949770	val: 0.712474	test: 0.779433
PRC train: 0.935585	val: 0.419164	test: 0.874604

Epoch: 48
Loss: 0.3364926857387463
ROC train: 0.949018	val: 0.724313	test: 0.770856
PRC train: 0.935738	val: 0.429708	test: 0.868701

Epoch: 49
Loss: 0.33051756134217314
ROC train: 0.950299	val: 0.713953	test: 0.779433
PRC train: 0.938501	val: 0.417567	test: 0.872004

Epoch: 50
Loss: 0.31100082208266167
ROC train: 0.950615	val: 0.714482	test: 0.786385
PRC train: 0.938445	val: 0.417944	test: 0.872048

Epoch: 51
Loss: 0.3214058286920306
ROC train: 0.949691	val: 0.725159	test: 0.794240
PRC train: 0.936038	val: 0.432873	test: 0.882113

Epoch: 52
Loss: 0.31514714165702146
ROC train: 0.948741	val: 0.718816	test: 0.779523
PRC train: 0.935118	val: 0.432658	test: 0.869634

Epoch: 53
Loss: 0.35478606529923257
ROC train: 0.951659	val: 0.713425	test: 0.772030
PRC train: 0.938717	val: 0.423426	test: 0.865623

Epoch: 54
Loss: 0.31466716669941486
ROC train: 0.952386	val: 0.710782	test: 0.764987
PRC train: 0.939068	val: 0.415286	test: 0.858704

Epoch: 55
Loss: 0.32195572974971365
ROC train: 0.952274	val: 0.722093	test: 0.765710
PRC train: 0.938474	val: 0.425341	test: 0.856777

Epoch: 56
Loss: 0.33044550029226993
ROC train: 0.953253	val: 0.720930	test: 0.752799
PRC train: 0.942006	val: 0.416038	test: 0.851131

Epoch: 57
Loss: 0.3402392614466194
ROC train: 0.953253	val: 0.729598	test: 0.748285
PRC train: 0.942457	val: 0.430318	test: 0.857030

Epoch: 58
Loss: 0.34752400812793527
ROC train: 0.951799	val: 0.727484	test: 0.732756
PRC train: 0.940476	val: 0.438573	test: 0.845000

Epoch: 59
Loss: 0.35323037261004275
ROC train: 0.954411	val: 0.722516	test: 0.747833
PRC train: 0.942948	val: 0.436217	test: 0.849468

Epoch: 60
Loss: 0.3085102598076034
ROC train: 0.952494	val: 0.726110	test: 0.763723
PRC train: 0.939861	val: 0.438315	test: 0.856957

Epoch: 61
Loss: 0.32159273140975225
ROC train: 0.953328	val: 0.724101	test: 0.768960
PRC train: 0.941275	val: 0.436874	test: 0.865444

Epoch: 62
Loss: 0.3237843676860796
ROC train: 0.955347	val: 0.727273	test: 0.771488
PRC train: 0.943238	val: 0.433365	test: 0.869311

Epoch: 63
Loss: 0.3234342647152816
ROC train: 0.956624	val: 0.727061	test: 0.792976
PRC train: 0.944338	val: 0.412366	test: 0.882469

Epoch: 64
Loss: 0.2956026804573164
ROC train: 0.955135	val: 0.734038	test: 0.781690
PRC train: 0.942162	val: 0.419955	test: 0.873150

Epoch: 65
Loss: 0.29855747425769497
ROC train: 0.953303	val: 0.733615	test: 0.755056
PRC train: 0.941078	val: 0.426058	test: 0.854925

Epoch: 66
Loss: 0.3436999715094588
ROC train: 0.951043	val: 0.721142	test: 0.739888
PRC train: 0.939724	val: 0.419731	test: 0.847709

Epoch: 67
Loss: 0.2996680060831948
ROC train: 0.949914	val: 0.712791	test: 0.748555
PRC train: 0.938883	val: 0.401514	test: 0.852041

Epoch: 68
Loss: 0.3186357443913982
ROC train: 0.958571	val: 0.738161	test: 0.764265
PRC train: 0.948304	val: 0.423595	test: 0.862013

Epoch: 69
Loss: 0.35331658523195114
ROC train: 0.958427	val: 0.726638	test: 0.762911
PRC train: 0.947399	val: 0.408321	test: 0.858054

Epoch: 70
Loss: 0.3381905770778603
ROC train: 0.960071	val: 0.721459	test: 0.785211
PRC train: 0.949426	val: 0.404210	test: 0.868489

Epoch: 71
Loss: 0.3088968526283307
ROC train: 0.959672	val: 0.733510	test: 0.793066
PRC train: 0.950561	val: 0.412617	test: 0.875850

Epoch: 72
Loss: 0.3442515299317698
ROC train: 0.960345	val: 0.727801	test: 0.767786
PRC train: 0.952324	val: 0.413336	test: 0.862222

Epoch: 73
Loss: 0.2953047237667699
ROC train: 0.960784	val: 0.722622	test: 0.743229
PRC train: 0.952012	val: 0.411620	test: 0.848511

Epoch: 74
Loss: 0.3033148650837578
ROC train: 0.958143	val: 0.714588	test: 0.737360
PRC train: 0.947482	val: 0.411681	test: 0.845690

Epoch: 75
Loss: 0.3389879835490856
ROC train: 0.956595	val: 0.717442	test: 0.752347
PRC train: 0.945688	val: 0.417029	test: 0.854679

Epoch: 76
Loss: 0.29512737037534487
ROC train: 0.962964	val: 0.716808	test: 0.762098
PRC train: 0.953317	val: 0.409251	test: 0.855853

Epoch: 77
Loss: 0.2898263846924028
ROC train: 0.963910	val: 0.716702	test: 0.769592
PRC train: 0.954544	val: 0.400324	test: 0.860797

Epoch: 78
Loss: 0.2919846245038987
ROC train: 0.964904	val: 0.717970	test: 0.785663
PRC train: 0.955706	val: 0.402387	test: 0.862714

Epoch: 79
Loss: 0.28874463891726887
ROC train: 0.964979	val: 0.719979	test: 0.787920
PRC train: 0.956878	val: 0.405053	test: 0.865130

Epoch: 80
Loss: 0.31242942277117663
ROC train: 0.965889	val: 0.727907	test: 0.766793
PRC train: 0.959041	val: 0.410834	test: 0.853745

Epoch: 81
Loss: 0.28266088678441087
ROC train: 0.966095	val: 0.731184	test: 0.751445
PRC train: 0.959772	val: 0.417580	test: 0.844520

Epoch: 82
Loss: 0.33293230176092065
ROC train: 0.967768	val: 0.740063	test: 0.763814
PRC train: 0.960789	val: 0.426504	test: 0.854703

Epoch: 83
Loss: 0.2840154759205463
ROC train: 0.966498	val: 0.732875	test: 0.743319
PRC train: 0.958522	val: 0.429334	test: 0.840358

Epoch: 84
Loss: 0.32218769514219364
ROC train: 0.966033	val: 0.732135	test: 0.729957
PRC train: 0.958411	val: 0.431659	test: 0.836597

Epoch: 85
Loss: 0.3134488220327747
ROC train: 0.965997	val: 0.721564	test: 0.739527
PRC train: 0.959578	val: 0.414440	test: 0.845842

Epoch: 86
Loss: 0.3252812062060447
ROC train: 0.967124	val: 0.725370	test: 0.738353
PRC train: 0.960456	val: 0.410122	test: 0.845655

Epoch: 87
Loss: 0.2687303263742735
ROC train: 0.965033	val: 0.725159	test: 0.745395
PRC train: 0.957513	val: 0.416287	test: 0.850267

Epoch: 88
Loss: 0.3010398161311192
ROC train: 0.964555	val: 0.732241	test: 0.765980
PRC train: 0.957316	val: 0.420001	test: 0.866557

Epoch: 89
Loss: 0.2849716308885485
ROC train: 0.967541	val: 0.740275	test: 0.774106
PRC train: 0.961140	val: 0.414516	test: 0.862922

Epoch: 90
Loss: 0.29468276274609606
ROC train: 0.965155	val: 0.740063	test: 0.764355
PRC train: 0.958844	val: 0.407873	test: 0.855324

Epoch: 91
Loss: 0.27902493723269506
ROC train: 0.965227	val: 0.749260	test: 0.762821
PRC train: 0.958523	val: 0.416766	test: 0.853919

Epoch: 92
Loss: 0.3032193153171314
ROC train: 0.968016	val: 0.743235	test: 0.741333
PRC train: 0.961209	val: 0.418644	test: 0.845045

Epoch: 93
Loss: 0.3177336025176218
ROC train: 0.970078	val: 0.740381	test: 0.752979
PRC train: 0.963554	val: 0.416352	test: 0.851902

Epoch: 94
Loss: 0.2758322333600901
PRC train: 0.915391	val: 0.413217	test: 0.876054

Epoch: 34
Loss: 0.348558877104471
ROC train: 0.937824	val: 0.719450	test: 0.777988
PRC train: 0.921006	val: 0.422611	test: 0.879027

Epoch: 35
Loss: 0.3301781287520611
ROC train: 0.938767	val: 0.713636	test: 0.776002
PRC train: 0.922959	val: 0.418121	test: 0.878708

Epoch: 36
Loss: 0.3475170401959141
ROC train: 0.939486	val: 0.708034	test: 0.775190
PRC train: 0.923896	val: 0.411025	test: 0.879420

Epoch: 37
Loss: 0.36300433775253915
ROC train: 0.939666	val: 0.701797	test: 0.774287
PRC train: 0.923495	val: 0.406894	test: 0.878287

Epoch: 38
Loss: 0.3462190467752497
ROC train: 0.936748	val: 0.700634	test: 0.772030
PRC train: 0.920232	val: 0.404581	test: 0.875752

Epoch: 39
Loss: 0.3379684875253852
ROC train: 0.934589	val: 0.714059	test: 0.766612
PRC train: 0.920411	val: 0.416959	test: 0.871780

Epoch: 40
Loss: 0.35053074117257566
ROC train: 0.928728	val: 0.714905	test: 0.771939
PRC train: 0.914956	val: 0.416318	test: 0.875631

Epoch: 41
Loss: 0.3289384533132748
ROC train: 0.940954	val: 0.722939	test: 0.777266
PRC train: 0.925875	val: 0.413006	test: 0.875816

Epoch: 42
Loss: 0.3177886239050887
ROC train: 0.945358	val: 0.716702	test: 0.769321
PRC train: 0.931682	val: 0.410632	test: 0.868035

Epoch: 43
Loss: 0.3541210402206669
ROC train: 0.947683	val: 0.712368	test: 0.770766
PRC train: 0.934656	val: 0.408217	test: 0.869967

Epoch: 44
Loss: 0.3514368440940113
ROC train: 0.944390	val: 0.720296	test: 0.776183
PRC train: 0.929178	val: 0.414696	test: 0.873250

Epoch: 45
Loss: 0.30839667326114245
ROC train: 0.943987	val: 0.726004	test: 0.778440
PRC train: 0.927830	val: 0.419009	test: 0.874859

Epoch: 46
Loss: 0.3434019113491544
ROC train: 0.949881	val: 0.721036	test: 0.786114
PRC train: 0.937420	val: 0.407764	test: 0.879691

Epoch: 47
Loss: 0.38685554501567543
ROC train: 0.951349	val: 0.719662	test: 0.775280
PRC train: 0.940182	val: 0.407018	test: 0.873514

Epoch: 48
Loss: 0.3172142801483012
ROC train: 0.951468	val: 0.711416	test: 0.768689
PRC train: 0.940409	val: 0.406122	test: 0.871734

Epoch: 49
Loss: 0.3427208638464193
ROC train: 0.951043	val: 0.709302	test: 0.763272
PRC train: 0.939486	val: 0.404911	test: 0.872836

Epoch: 50
Loss: 0.3378886250680983
ROC train: 0.952119	val: 0.709619	test: 0.770856
PRC train: 0.939810	val: 0.401987	test: 0.879270

Epoch: 51
Loss: 0.31897340013680503
ROC train: 0.949068	val: 0.718922	test: 0.777988
PRC train: 0.935580	val: 0.412372	test: 0.881979

Epoch: 52
Loss: 0.37368929381401117
ROC train: 0.949946	val: 0.715116	test: 0.772481
PRC train: 0.937768	val: 0.411164	test: 0.879099

Epoch: 53
Loss: 0.3184080282540305
ROC train: 0.952562	val: 0.705814	test: 0.757945
PRC train: 0.941390	val: 0.419853	test: 0.869938

Epoch: 54
Loss: 0.28961408611230816
ROC train: 0.954419	val: 0.695666	test: 0.765439
PRC train: 0.943748	val: 0.406506	test: 0.870321

Epoch: 55
Loss: 0.36214032482928166
ROC train: 0.951702	val: 0.681395	test: 0.769863
PRC train: 0.941168	val: 0.380560	test: 0.872423

Epoch: 56
Loss: 0.34327903301202717
ROC train: 0.955127	val: 0.706342	test: 0.760202
PRC train: 0.944931	val: 0.393086	test: 0.867033

Epoch: 57
Loss: 0.3507171861824285
ROC train: 0.958020	val: 0.697040	test: 0.753250
PRC train: 0.949171	val: 0.390636	test: 0.863235

Epoch: 58
Loss: 0.342358734694389
ROC train: 0.951918	val: 0.700000	test: 0.759299
PRC train: 0.941428	val: 0.395484	test: 0.867157

Epoch: 59
Loss: 0.31079927796562207
ROC train: 0.948406	val: 0.693446	test: 0.765078
PRC train: 0.937239	val: 0.390217	test: 0.873515

Epoch: 60
Loss: 0.32124174978273623
ROC train: 0.955063	val: 0.701374	test: 0.759931
PRC train: 0.945078	val: 0.392203	test: 0.871327

Epoch: 61
Loss: 0.294640771526284
ROC train: 0.959524	val: 0.700317	test: 0.751445
PRC train: 0.950705	val: 0.384247	test: 0.867975

Epoch: 62
Loss: 0.310638976148118
ROC train: 0.962075	val: 0.704545	test: 0.769772
PRC train: 0.953846	val: 0.395030	test: 0.878630

Epoch: 63
Loss: 0.2840071261300153
ROC train: 0.962378	val: 0.707188	test: 0.786566
PRC train: 0.954412	val: 0.395130	test: 0.887148

Epoch: 64
Loss: 0.3334421096015275
ROC train: 0.956005	val: 0.702854	test: 0.784489
PRC train: 0.946884	val: 0.394173	test: 0.887525

Epoch: 65
Loss: 0.3360191189472195
ROC train: 0.952677	val: 0.709091	test: 0.792615
PRC train: 0.944168	val: 0.390824	test: 0.890770

Epoch: 66
Loss: 0.2911216157377069
ROC train: 0.954314	val: 0.711839	test: 0.776815
PRC train: 0.943795	val: 0.403431	test: 0.879913

Epoch: 67
Loss: 0.29204693481582295
ROC train: 0.958506	val: 0.707505	test: 0.780246
PRC train: 0.949428	val: 0.394972	test: 0.881542

Epoch: 68
Loss: 0.3263646072103511
ROC train: 0.958988	val: 0.698309	test: 0.769050
PRC train: 0.949771	val: 0.379523	test: 0.874321

Epoch: 69
Loss: 0.3343378101049786
ROC train: 0.958765	val: 0.701268	test: 0.768599
PRC train: 0.950095	val: 0.386767	test: 0.874405

Epoch: 70
Loss: 0.28025790503821596
ROC train: 0.959096	val: 0.713002	test: 0.745305
PRC train: 0.950611	val: 0.396599	test: 0.858514

Epoch: 71
Loss: 0.30192936709808976
ROC train: 0.962428	val: 0.718922	test: 0.737721
PRC train: 0.953823	val: 0.406649	test: 0.848971

Epoch: 72
Loss: 0.3005197648767172
ROC train: 0.962889	val: 0.733510	test: 0.755959
PRC train: 0.954408	val: 0.414935	test: 0.856883

Epoch: 73
Loss: 0.2805184877664218
ROC train: 0.962622	val: 0.740063	test: 0.776995
PRC train: 0.953861	val: 0.416456	test: 0.871203

Epoch: 74
Loss: 0.3012925723873948
ROC train: 0.964724	val: 0.740592	test: 0.780426
PRC train: 0.957570	val: 0.412692	test: 0.875363

Epoch: 75
Loss: 0.26863971508563367
ROC train: 0.965173	val: 0.742495	test: 0.775099
PRC train: 0.957865	val: 0.422119	test: 0.876510

Epoch: 76
Loss: 0.31751590804570856
ROC train: 0.963939	val: 0.731712	test: 0.750181
PRC train: 0.957022	val: 0.411980	test: 0.860591

Epoch: 77
Loss: 0.30168336021326186
ROC train: 0.962302	val: 0.732241	test: 0.744944
PRC train: 0.955397	val: 0.413511	test: 0.852956

Epoch: 78
Loss: 0.3332791221845513
ROC train: 0.965476	val: 0.733510	test: 0.757133
PRC train: 0.958528	val: 0.410863	test: 0.859776

Epoch: 79
Loss: 0.3027338906141536
ROC train: 0.966523	val: 0.732558	test: 0.760473
PRC train: 0.959665	val: 0.396605	test: 0.854916

Epoch: 80
Loss: 0.3649388553257279
ROC train: 0.963209	val: 0.732347	test: 0.753882
PRC train: 0.955879	val: 0.409749	test: 0.852535

Epoch: 81
Loss: 0.27616072318539664
ROC train: 0.958927	val: 0.727590	test: 0.742416
PRC train: 0.949764	val: 0.419502	test: 0.850538

Epoch: 82
Loss: 0.3016586740336133
ROC train: 0.964144	val: 0.726533	test: 0.741242
PRC train: 0.956031	val: 0.408455	test: 0.850964

Epoch: 83
Loss: 0.3102561723359397
ROC train: 0.965220	val: 0.727167	test: 0.744583
PRC train: 0.957650	val: 0.406326	test: 0.850177

Epoch: 84
Loss: 0.27873486432690275
ROC train: 0.961100	val: 0.730021	test: 0.744493
PRC train: 0.952681	val: 0.417292	test: 0.849470

Epoch: 85
Loss: 0.3058324177887461
ROC train: 0.965199	val: 0.726956	test: 0.750813
PRC train: 0.958166	val: 0.409373	test: 0.851439

Epoch: 86
Loss: 0.26956952889942626
ROC train: 0.965274	val: 0.734038	test: 0.759390
PRC train: 0.958445	val: 0.410873	test: 0.856171

Epoch: 87
Loss: 0.29488555222992335
ROC train: 0.965933	val: 0.736575	test: 0.760654
PRC train: 0.959544	val: 0.415213	test: 0.854298

Epoch: 88
Loss: 0.28585709174650203
ROC train: 0.966278	val: 0.732770	test: 0.755869
PRC train: 0.959348	val: 0.413883	test: 0.846858

Epoch: 89
Loss: 0.28256816380504474
ROC train: 0.968048	val: 0.723996	test: 0.758397
PRC train: 0.961037	val: 0.407808	test: 0.846176

Epoch: 90
Loss: 0.2868642674021671
ROC train: 0.968228	val: 0.710254	test: 0.753882
PRC train: 0.961791	val: 0.388861	test: 0.844130

Epoch: 91
Loss: 0.3175571018571667
ROC train: 0.962338	val: 0.705074	test: 0.753070
PRC train: 0.956251	val: 0.375686	test: 0.852278

Epoch: 92
Loss: 0.27343831098385396
ROC train: 0.959064	val: 0.703594	test: 0.774106
PRC train: 0.952208	val: 0.371379	test: 0.871644

Epoch: 93
Loss: 0.3113198343869721
ROC train: 0.963749	val: 0.713214	test: 0.779704
PRC train: 0.957260	val: 0.378849	test: 0.871225

Epoch: 94
Loss: 0.3119412116706716
ROC train: 0.965346	val: 0.711628	test: 0.766342
PRC train: 0.921096	val: 0.926915	test: 0.728282

Epoch: 34
Loss: 0.3222563547407131
ROC train: 0.950639	val: 0.657509	test: 0.737959
PRC train: 0.920745	val: 0.926207	test: 0.730598

Epoch: 35
Loss: 0.3324038283126593
ROC train: 0.954264	val: 0.649451	test: 0.751174
PRC train: 0.928266	val: 0.925937	test: 0.751606

Epoch: 36
Loss: 0.31514611395899317
ROC train: 0.955303	val: 0.663004	test: 0.743523
PRC train: 0.929342	val: 0.927483	test: 0.741308

Epoch: 37
Loss: 0.3098874885333259
ROC train: 0.958419	val: 0.663736	test: 0.747522
PRC train: 0.934289	val: 0.924754	test: 0.746452

Epoch: 38
Loss: 0.32948486904879565
ROC train: 0.957808	val: 0.650916	test: 0.737611
PRC train: 0.933625	val: 0.921374	test: 0.744751

Epoch: 39
Loss: 0.2948432857243355
ROC train: 0.955805	val: 0.674359	test: 0.734133
PRC train: 0.932737	val: 0.927486	test: 0.733470

Epoch: 40
Loss: 0.3068154510748484
ROC train: 0.957594	val: 0.677289	test: 0.754999
PRC train: 0.934599	val: 0.930223	test: 0.739870

Epoch: 41
Loss: 0.3004763900193256
ROC train: 0.957058	val: 0.656044	test: 0.755347
PRC train: 0.932963	val: 0.922185	test: 0.747568

Epoch: 42
Loss: 0.3009477412774054
ROC train: 0.957985	val: 0.643590	test: 0.750652
PRC train: 0.932873	val: 0.917759	test: 0.750450

Epoch: 43
Loss: 0.3052719257600363
ROC train: 0.959189	val: 0.645055	test: 0.741089
PRC train: 0.934197	val: 0.918011	test: 0.745713

Epoch: 44
Loss: 0.3134768451851261
ROC train: 0.961107	val: 0.664103	test: 0.738132
PRC train: 0.938159	val: 0.921931	test: 0.760373

Epoch: 45
Loss: 0.29504380543308156
ROC train: 0.959763	val: 0.682418	test: 0.729786
PRC train: 0.937605	val: 0.925656	test: 0.744140

Epoch: 46
Loss: 0.30970917033666934
ROC train: 0.961875	val: 0.670330	test: 0.741089
PRC train: 0.939802	val: 0.925855	test: 0.751226

Epoch: 47
Loss: 0.29513473469011686
ROC train: 0.963379	val: 0.663004	test: 0.740219
PRC train: 0.942634	val: 0.926168	test: 0.748364

Epoch: 48
Loss: 0.2952084891640911
ROC train: 0.963025	val: 0.673260	test: 0.731177
PRC train: 0.941838	val: 0.929130	test: 0.737790

Epoch: 49
Loss: 0.2918878961717318
ROC train: 0.965599	val: 0.657143	test: 0.735524
PRC train: 0.945311	val: 0.921850	test: 0.744108

Epoch: 50
Loss: 0.2822071418653548
ROC train: 0.965888	val: 0.660440	test: 0.729786
PRC train: 0.945994	val: 0.922004	test: 0.741506

Epoch: 51
Loss: 0.288274536682031
ROC train: 0.965537	val: 0.649817	test: 0.712398
PRC train: 0.945611	val: 0.918803	test: 0.725368

Epoch: 52
Loss: 0.27638194795197596
ROC train: 0.968476	val: 0.647985	test: 0.704921
PRC train: 0.950766	val: 0.917970	test: 0.719455

Epoch: 53
Loss: 0.28882929158738674
ROC train: 0.968028	val: 0.650916	test: 0.696227
PRC train: 0.949961	val: 0.921630	test: 0.709052

Epoch: 54
Loss: 0.2827934496007827
ROC train: 0.967209	val: 0.660073	test: 0.703182
PRC train: 0.949226	val: 0.923985	test: 0.715657

Epoch: 55
Loss: 0.28272639154833223
ROC train: 0.969227	val: 0.642491	test: 0.718484
PRC train: 0.952774	val: 0.916265	test: 0.731476

Epoch: 56
Loss: 0.26511742814087386
ROC train: 0.968582	val: 0.670696	test: 0.715006
PRC train: 0.951250	val: 0.924244	test: 0.730602

Epoch: 57
Loss: 0.27269970129175
ROC train: 0.968125	val: 0.656044	test: 0.689619
PRC train: 0.950204	val: 0.920227	test: 0.699128

Epoch: 58
Loss: 0.2643189236221254
ROC train: 0.971030	val: 0.649451	test: 0.682664
PRC train: 0.955426	val: 0.921048	test: 0.692675

Epoch: 59
Loss: 0.26733298722173504
ROC train: 0.965559	val: 0.644689	test: 0.685968
PRC train: 0.947913	val: 0.918925	test: 0.695997

Epoch: 60
Loss: 0.26883921114282266
ROC train: 0.972003	val: 0.632967	test: 0.721961
PRC train: 0.957050	val: 0.916161	test: 0.737485

Epoch: 61
Loss: 0.27389889902696124
ROC train: 0.973256	val: 0.637363	test: 0.741089
PRC train: 0.958558	val: 0.905807	test: 0.754910

Epoch: 62
Loss: 0.2780286057510598
ROC train: 0.970146	val: 0.656044	test: 0.732742
PRC train: 0.953603	val: 0.913432	test: 0.741977

Epoch: 63
Loss: 0.2727778528895396
ROC train: 0.971938	val: 0.649084	test: 0.721440
PRC train: 0.955762	val: 0.914812	test: 0.737474

Epoch: 64
Loss: 0.25880213024065757
ROC train: 0.973276	val: 0.616117	test: 0.716919
PRC train: 0.957622	val: 0.905441	test: 0.728722

Epoch: 65
Loss: 0.2517808245686179
ROC train: 0.974615	val: 0.633700	test: 0.717614
PRC train: 0.959699	val: 0.909983	test: 0.716651

Epoch: 66
Loss: 0.2549991586812689
ROC train: 0.973567	val: 0.650549	test: 0.706138
PRC train: 0.958444	val: 0.918061	test: 0.702277

Epoch: 67
Loss: 0.2627525664932476
ROC train: 0.973818	val: 0.642857	test: 0.709616
PRC train: 0.960906	val: 0.916810	test: 0.707380

Epoch: 68
Loss: 0.2632174297036067
ROC train: 0.974752	val: 0.639560	test: 0.719875
PRC train: 0.962552	val: 0.913295	test: 0.724065

Epoch: 69
Loss: 0.25957071820952227
ROC train: 0.975277	val: 0.649451	test: 0.723700
PRC train: 0.963206	val: 0.908668	test: 0.733048

Epoch: 70
Loss: 0.26413566708040837
ROC train: 0.977454	val: 0.617216	test: 0.712398
PRC train: 0.966229	val: 0.900096	test: 0.714911

Epoch: 71
Loss: 0.25041711066781425
ROC train: 0.977072	val: 0.624176	test: 0.703530
PRC train: 0.965324	val: 0.903619	test: 0.709552

Epoch: 72
Loss: 0.24678750030891727
ROC train: 0.977997	val: 0.629670	test: 0.703356
PRC train: 0.965799	val: 0.908474	test: 0.705131

Epoch: 73
Loss: 0.25497046601071827
ROC train: 0.976929	val: 0.634066	test: 0.705964
PRC train: 0.964574	val: 0.909222	test: 0.708557

Epoch: 74
Loss: 0.26585183404190893
ROC train: 0.978368	val: 0.630403	test: 0.708051
PRC train: 0.967680	val: 0.908773	test: 0.705265

Epoch: 75
Loss: 0.25752539936264107
ROC train: 0.978533	val: 0.635531	test: 0.708746
PRC train: 0.967229	val: 0.910981	test: 0.706343

Epoch: 76
Loss: 0.24893320154813167
ROC train: 0.978650	val: 0.643590	test: 0.709268
PRC train: 0.967144	val: 0.915509	test: 0.707761

Epoch: 77
Loss: 0.24870770980822182
ROC train: 0.978519	val: 0.643956	test: 0.705964
PRC train: 0.967573	val: 0.916277	test: 0.710017

Epoch: 78
Loss: 0.2353197270800301
ROC train: 0.976921	val: 0.645788	test: 0.703182
PRC train: 0.965075	val: 0.914839	test: 0.711093

Epoch: 79
Loss: 0.23580191252292196
ROC train: 0.979389	val: 0.636264	test: 0.697270
PRC train: 0.969512	val: 0.907828	test: 0.701416

Epoch: 80
Loss: 0.24264206158928778
ROC train: 0.982426	val: 0.629304	test: 0.709616
PRC train: 0.974080	val: 0.905998	test: 0.702223

Epoch: 81
Loss: 0.23991795067880717
ROC train: 0.979897	val: 0.628571	test: 0.710485
PRC train: 0.969652	val: 0.912845	test: 0.698545

Epoch: 82
Loss: 0.23834085840364833
ROC train: 0.978005	val: 0.660440	test: 0.709442
PRC train: 0.966396	val: 0.920744	test: 0.712726

Epoch: 83
Loss: 0.22482070895300907
ROC train: 0.982725	val: 0.653114	test: 0.708746
PRC train: 0.974499	val: 0.918560	test: 0.706124

Epoch: 84
Loss: 0.24269177610047574
ROC train: 0.979737	val: 0.636996	test: 0.687706
PRC train: 0.970454	val: 0.913978	test: 0.685219

Epoch: 85
Loss: 0.258543144368458
ROC train: 0.978930	val: 0.647253	test: 0.688924
PRC train: 0.968756	val: 0.910125	test: 0.695618

Epoch: 86
Loss: 0.224810781514403
ROC train: 0.979623	val: 0.652747	test: 0.705616
PRC train: 0.969908	val: 0.902885	test: 0.710659

Epoch: 87
Loss: 0.23933446506560005
ROC train: 0.980905	val: 0.634066	test: 0.687533
PRC train: 0.971504	val: 0.899786	test: 0.684535

Epoch: 88
Loss: 0.23284484607456984
ROC train: 0.976404	val: 0.628938	test: 0.683186
PRC train: 0.965573	val: 0.908939	test: 0.680971

Epoch: 89
Loss: 0.22608085003807368
ROC train: 0.974732	val: 0.638828	test: 0.687011
PRC train: 0.964335	val: 0.916912	test: 0.687425

Epoch: 90
Loss: 0.2311677975671424
ROC train: 0.978439	val: 0.636996	test: 0.690315
PRC train: 0.968603	val: 0.914683	test: 0.685146

Epoch: 91
Loss: 0.22049238512360203
ROC train: 0.982012	val: 0.643223	test: 0.704225
PRC train: 0.973242	val: 0.903939	test: 0.709089

Epoch: 92
Loss: 0.21861311767861585
ROC train: 0.982412	val: 0.631136	test: 0.708225
PRC train: 0.973944	val: 0.897123	test: 0.705963

Epoch: 93
Loss: 0.23188176515984232
ROC train: 0.981299	val: 0.627473	test: 0.699357
PRC train: 0.972590	val: 0.898716	test: 0.694104

Epoch: 94
Loss: 0.2219982456066522
ROC train: 0.981045	val: 0.632967	test: 0.701443
ROC train: 0.948759	val: 0.706227	test: 0.745436
PRC train: 0.918663	val: 0.935854	test: 0.720255

Epoch: 34
Loss: 0.3303592082174966
ROC train: 0.948051	val: 0.686813	test: 0.728395
PRC train: 0.919227	val: 0.932377	test: 0.708293

Epoch: 35
Loss: 0.32456652099490385
ROC train: 0.951692	val: 0.705128	test: 0.743697
PRC train: 0.921548	val: 0.936184	test: 0.718932

Epoch: 36
Loss: 0.32681884831352526
ROC train: 0.952226	val: 0.698901	test: 0.744392
PRC train: 0.922140	val: 0.933673	test: 0.722347

Epoch: 37
Loss: 0.3373913926040252
ROC train: 0.950751	val: 0.726374	test: 0.738654
PRC train: 0.920909	val: 0.937496	test: 0.719324

Epoch: 38
Loss: 0.3347727496921815
ROC train: 0.953019	val: 0.697436	test: 0.738306
PRC train: 0.924360	val: 0.933269	test: 0.723002

Epoch: 39
Loss: 0.3119624297771497
ROC train: 0.954064	val: 0.663004	test: 0.733438
PRC train: 0.927063	val: 0.926262	test: 0.721024

Epoch: 40
Loss: 0.32802579029444445
ROC train: 0.953856	val: 0.682051	test: 0.729264
PRC train: 0.928510	val: 0.927758	test: 0.716107

Epoch: 41
Loss: 0.3150864996295753
ROC train: 0.956104	val: 0.686081	test: 0.737611
PRC train: 0.930135	val: 0.928446	test: 0.723081

Epoch: 42
Loss: 0.3126437852281325
ROC train: 0.953664	val: 0.675092	test: 0.732047
PRC train: 0.927572	val: 0.927260	test: 0.721504

Epoch: 43
Loss: 0.31940592172256943
ROC train: 0.956547	val: 0.680220	test: 0.732568
PRC train: 0.933233	val: 0.928832	test: 0.727968

Epoch: 44
Loss: 0.3039851379783082
ROC train: 0.958311	val: 0.697070	test: 0.745436
PRC train: 0.934064	val: 0.934808	test: 0.715044

Epoch: 45
Loss: 0.30144339095402334
ROC train: 0.958636	val: 0.695971	test: 0.748044
PRC train: 0.933199	val: 0.936658	test: 0.719295

Epoch: 46
Loss: 0.30753021362725474
ROC train: 0.958893	val: 0.686813	test: 0.733785
PRC train: 0.935238	val: 0.932187	test: 0.721458

Epoch: 47
Loss: 0.29823133948669744
ROC train: 0.958376	val: 0.687912	test: 0.737263
PRC train: 0.935520	val: 0.929917	test: 0.724074

Epoch: 48
Loss: 0.297821652129531
ROC train: 0.961276	val: 0.681319	test: 0.747348
PRC train: 0.939981	val: 0.931867	test: 0.726716

Epoch: 49
Loss: 0.30847839113957926
ROC train: 0.962671	val: 0.687912	test: 0.746653
PRC train: 0.943324	val: 0.933297	test: 0.735846

Epoch: 50
Loss: 0.29635609807495733
ROC train: 0.961156	val: 0.693773	test: 0.750304
PRC train: 0.942392	val: 0.935306	test: 0.746056

Epoch: 51
Loss: 0.29185886376826164
ROC train: 0.962925	val: 0.699634	test: 0.746653
PRC train: 0.943256	val: 0.935541	test: 0.738707

Epoch: 52
Loss: 0.2871548725124994
ROC train: 0.963975	val: 0.688278	test: 0.747522
PRC train: 0.943633	val: 0.931808	test: 0.740306

Epoch: 53
Loss: 0.3015936068348095
ROC train: 0.963285	val: 0.687179	test: 0.755521
PRC train: 0.942631	val: 0.929238	test: 0.743601

Epoch: 54
Loss: 0.2836839429930218
ROC train: 0.964138	val: 0.686447	test: 0.746827
PRC train: 0.945458	val: 0.930868	test: 0.738051

Epoch: 55
Loss: 0.2966256841192628
ROC train: 0.968513	val: 0.683883	test: 0.751348
PRC train: 0.951467	val: 0.928774	test: 0.742718

Epoch: 56
Loss: 0.29194301387752813
ROC train: 0.967229	val: 0.686813	test: 0.738654
PRC train: 0.948278	val: 0.928271	test: 0.738101

Epoch: 57
Loss: 0.2679985748248225
ROC train: 0.967061	val: 0.681319	test: 0.737089
PRC train: 0.948128	val: 0.929972	test: 0.727424

Epoch: 58
Loss: 0.28082034136261036
ROC train: 0.965748	val: 0.671429	test: 0.739524
PRC train: 0.945780	val: 0.923407	test: 0.731540

Epoch: 59
Loss: 0.28155861300471785
ROC train: 0.966190	val: 0.672527	test: 0.732394
PRC train: 0.946732	val: 0.923345	test: 0.727960

Epoch: 60
Loss: 0.2960968500521116
ROC train: 0.966444	val: 0.677289	test: 0.736220
PRC train: 0.949218	val: 0.929593	test: 0.729352

Epoch: 61
Loss: 0.26939540673837237
ROC train: 0.970331	val: 0.653846	test: 0.752043
PRC train: 0.954560	val: 0.924357	test: 0.727500

Epoch: 62
Loss: 0.27528106018972737
ROC train: 0.970562	val: 0.661172	test: 0.740045
PRC train: 0.954232	val: 0.920225	test: 0.716283

Epoch: 63
Loss: 0.2670195928479665
ROC train: 0.967486	val: 0.665568	test: 0.717614
PRC train: 0.949140	val: 0.917405	test: 0.701185

Epoch: 64
Loss: 0.28446585420393666
ROC train: 0.970676	val: 0.657509	test: 0.725265
PRC train: 0.954227	val: 0.916995	test: 0.712682

Epoch: 65
Loss: 0.2744537418779638
ROC train: 0.972223	val: 0.660073	test: 0.749435
PRC train: 0.955850	val: 0.918991	test: 0.741074

Epoch: 66
Loss: 0.2696893958782719
ROC train: 0.970146	val: 0.676190	test: 0.747001
PRC train: 0.953642	val: 0.926239	test: 0.734584

Epoch: 67
Loss: 0.25049346002810113
ROC train: 0.971398	val: 0.680952	test: 0.747174
PRC train: 0.955617	val: 0.926920	test: 0.731654

Epoch: 68
Loss: 0.2643122774275527
ROC train: 0.973556	val: 0.668132	test: 0.751521
PRC train: 0.958597	val: 0.921181	test: 0.741498

Epoch: 69
Loss: 0.25487302295040976
ROC train: 0.973930	val: 0.658242	test: 0.738654
PRC train: 0.959083	val: 0.914228	test: 0.732234

Epoch: 70
Loss: 0.2631906198440602
ROC train: 0.974050	val: 0.655678	test: 0.731525
PRC train: 0.958883	val: 0.912145	test: 0.718869

Epoch: 71
Loss: 0.2688472844745612
ROC train: 0.972300	val: 0.656044	test: 0.719179
PRC train: 0.956820	val: 0.915847	test: 0.710510

Epoch: 72
Loss: 0.2548045630706675
ROC train: 0.973821	val: 0.665568	test: 0.725091
PRC train: 0.959818	val: 0.921196	test: 0.719229

Epoch: 73
Loss: 0.2559390915836842
ROC train: 0.976344	val: 0.668132	test: 0.738480
PRC train: 0.963088	val: 0.926250	test: 0.714245

Epoch: 74
Loss: 0.27850218563879314
ROC train: 0.973225	val: 0.662271	test: 0.728221
PRC train: 0.958099	val: 0.924426	test: 0.702045

Epoch: 75
Loss: 0.24979250904785572
ROC train: 0.973958	val: 0.669963	test: 0.732568
PRC train: 0.959970	val: 0.923962	test: 0.733244

Epoch: 76
Loss: 0.24322044848749105
ROC train: 0.976852	val: 0.681685	test: 0.732220
PRC train: 0.964572	val: 0.927472	test: 0.734477

Epoch: 77
Loss: 0.2439405410385343
ROC train: 0.976769	val: 0.696703	test: 0.736568
PRC train: 0.964984	val: 0.934252	test: 0.729678

Epoch: 78
Loss: 0.2579445499421449
ROC train: 0.975405	val: 0.676557	test: 0.737611
PRC train: 0.962985	val: 0.928500	test: 0.732137

Epoch: 79
Loss: 0.24754672561607044
ROC train: 0.976162	val: 0.680586	test: 0.739524
PRC train: 0.963188	val: 0.925416	test: 0.746150

Epoch: 80
Loss: 0.23851117415569095
ROC train: 0.977314	val: 0.665201	test: 0.735698
PRC train: 0.965382	val: 0.920541	test: 0.741465

Epoch: 81
Loss: 0.24562794220833437
ROC train: 0.976824	val: 0.677289	test: 0.724048
PRC train: 0.964833	val: 0.926428	test: 0.727064

Epoch: 82
Loss: 0.23649990415049796
ROC train: 0.976678	val: 0.680586	test: 0.720918
PRC train: 0.964260	val: 0.928907	test: 0.720919

Epoch: 83
Loss: 0.2525815054860612
ROC train: 0.977195	val: 0.684615	test: 0.735350
PRC train: 0.964875	val: 0.928277	test: 0.740913

Epoch: 84
Loss: 0.24472648620787782
ROC train: 0.977791	val: 0.674725	test: 0.740219
PRC train: 0.965281	val: 0.923127	test: 0.744637

Epoch: 85
Loss: 0.24787498052619727
ROC train: 0.980086	val: 0.687912	test: 0.758825
PRC train: 0.969300	val: 0.925106	test: 0.751714

Epoch: 86
Loss: 0.22984239719411384
ROC train: 0.979729	val: 0.697436	test: 0.739524
PRC train: 0.969053	val: 0.933191	test: 0.731864

Epoch: 87
Loss: 0.23619767957902033
ROC train: 0.978111	val: 0.689011	test: 0.739002
PRC train: 0.965580	val: 0.933096	test: 0.733437

Epoch: 88
Loss: 0.2242293512384843
ROC train: 0.978445	val: 0.672894	test: 0.740915
PRC train: 0.965565	val: 0.930861	test: 0.739016

Epoch: 89
Loss: 0.2383294930361813
ROC train: 0.979138	val: 0.665934	test: 0.724396
PRC train: 0.966786	val: 0.925231	test: 0.720616

Epoch: 90
Loss: 0.2423401558081904
ROC train: 0.980693	val: 0.677289	test: 0.715354
PRC train: 0.970287	val: 0.923988	test: 0.715971

Epoch: 91
Loss: 0.2533295310200704
ROC train: 0.981162	val: 0.684982	test: 0.729264
PRC train: 0.970399	val: 0.923923	test: 0.725001

Epoch: 92
Loss: 0.22951152902209054
ROC train: 0.981978	val: 0.679487	test: 0.732394
PRC train: 0.972279	val: 0.922878	test: 0.724015

Epoch: 93
Loss: 0.23730949845909816
ROC train: 0.982323	val: 0.670696	test: 0.720049
PRC train: 0.973394	val: 0.921575	test: 0.722883

Epoch: 94
Loss: 0.2548830719532957
ROC train: 0.932563	val: 0.713636	test: 0.798303
PRC train: 0.915153	val: 0.400754	test: 0.885293

Epoch: 34
Loss: 0.34102083591354665
ROC train: 0.932786	val: 0.711522	test: 0.806699
PRC train: 0.914663	val: 0.405803	test: 0.890684

Epoch: 35
Loss: 0.3651957277570682
ROC train: 0.935633	val: 0.713214	test: 0.794691
PRC train: 0.917610	val: 0.415350	test: 0.886331

Epoch: 36
Loss: 0.34799800837153294
ROC train: 0.938248	val: 0.711416	test: 0.797941
PRC train: 0.921709	val: 0.407582	test: 0.891082

Epoch: 37
Loss: 0.4145539489706073
ROC train: 0.939274	val: 0.700211	test: 0.809769
PRC train: 0.923943	val: 0.395985	test: 0.897069

Epoch: 38
Loss: 0.36402269548930494
ROC train: 0.941548	val: 0.704863	test: 0.800740
PRC train: 0.926902	val: 0.400568	test: 0.887798

Epoch: 39
Loss: 0.32935917993897273
ROC train: 0.941015	val: 0.706237	test: 0.797490
PRC train: 0.926138	val: 0.412033	test: 0.885355

Epoch: 40
Loss: 0.3653838708647551
ROC train: 0.940004	val: 0.706237	test: 0.804713
PRC train: 0.924257	val: 0.413114	test: 0.887946

Epoch: 41
Loss: 0.33086613604416926
ROC train: 0.937241	val: 0.706660	test: 0.805255
PRC train: 0.921498	val: 0.403466	test: 0.885708

Epoch: 42
Loss: 0.3291223836712674
ROC train: 0.936640	val: 0.705074	test: 0.802546
PRC train: 0.920499	val: 0.399955	test: 0.885246

Epoch: 43
Loss: 0.3310412770833774
ROC train: 0.935467	val: 0.708774	test: 0.813019
PRC train: 0.919955	val: 0.398537	test: 0.891333

Epoch: 44
Loss: 0.3483723760151177
ROC train: 0.940119	val: 0.709725	test: 0.810311
PRC train: 0.924894	val: 0.411938	test: 0.891345

Epoch: 45
Loss: 0.3917373205314857
ROC train: 0.942030	val: 0.709197	test: 0.824215
PRC train: 0.926272	val: 0.410952	test: 0.900972

Epoch: 46
Loss: 0.3632006136931728
ROC train: 0.943106	val: 0.695560	test: 0.830896
PRC train: 0.928223	val: 0.387147	test: 0.904744

Epoch: 47
Loss: 0.32332410174430304
ROC train: 0.944596	val: 0.698414	test: 0.818436
PRC train: 0.928930	val: 0.378412	test: 0.898843

Epoch: 48
Loss: 0.3305041672658894
ROC train: 0.945711	val: 0.708985	test: 0.796678
PRC train: 0.929965	val: 0.386463	test: 0.886369

Epoch: 49
Loss: 0.32679703419779627
ROC train: 0.948539	val: 0.710994	test: 0.809949
PRC train: 0.934370	val: 0.386751	test: 0.891172

Epoch: 50
Loss: 0.3278758421576601
ROC train: 0.944653	val: 0.711205	test: 0.827736
PRC train: 0.930893	val: 0.392917	test: 0.900780

Epoch: 51
Loss: 0.35150432976924584
ROC train: 0.947222	val: 0.706025	test: 0.830805
PRC train: 0.934027	val: 0.392809	test: 0.902529

Epoch: 52
Loss: 0.3484002343355896
ROC train: 0.948546	val: 0.707505	test: 0.819068
PRC train: 0.935462	val: 0.390448	test: 0.896282

Epoch: 53
Loss: 0.33429579060154013
ROC train: 0.946423	val: 0.713742	test: 0.807421
PRC train: 0.932905	val: 0.400652	test: 0.892183

Epoch: 54
Loss: 0.3642584703818983
ROC train: 0.949532	val: 0.709725	test: 0.818256
PRC train: 0.936975	val: 0.401604	test: 0.899695

Epoch: 55
Loss: 0.3292405976144962
ROC train: 0.952558	val: 0.720825	test: 0.815728
PRC train: 0.940719	val: 0.401344	test: 0.899481

Epoch: 56
Loss: 0.32221101981138106
ROC train: 0.952857	val: 0.726956	test: 0.811213
PRC train: 0.940576	val: 0.401659	test: 0.894823

Epoch: 57
Loss: 0.32481306576496255
ROC train: 0.953951	val: 0.724736	test: 0.805525
PRC train: 0.941395	val: 0.395604	test: 0.892835

Epoch: 58
Loss: 0.3128158214404705
ROC train: 0.957491	val: 0.720085	test: 0.784489
PRC train: 0.946541	val: 0.397201	test: 0.879275

Epoch: 59
Loss: 0.3208684974795378
ROC train: 0.956725	val: 0.721776	test: 0.767606
PRC train: 0.945462	val: 0.396194	test: 0.863819

Epoch: 60
Loss: 0.31112723967189115
ROC train: 0.956232	val: 0.718710	test: 0.770043
PRC train: 0.945634	val: 0.389497	test: 0.860815

Epoch: 61
Loss: 0.3181721330138122
ROC train: 0.956059	val: 0.713425	test: 0.794330
PRC train: 0.944320	val: 0.386981	test: 0.883035

Epoch: 62
Loss: 0.35354676539259755
ROC train: 0.956606	val: 0.718710	test: 0.813380
PRC train: 0.944162	val: 0.394193	test: 0.900954

Epoch: 63
Loss: 0.32883896053536465
ROC train: 0.957225	val: 0.716808	test: 0.802185
PRC train: 0.946502	val: 0.385585	test: 0.891250

Epoch: 64
Loss: 0.2924605559895601
ROC train: 0.955879	val: 0.721142	test: 0.778530
PRC train: 0.946770	val: 0.394129	test: 0.869726

Epoch: 65
Loss: 0.3017069775240045
ROC train: 0.953710	val: 0.721142	test: 0.748646
PRC train: 0.945077	val: 0.392855	test: 0.849122

Epoch: 66
Loss: 0.2877049100913449
ROC train: 0.957567	val: 0.710254	test: 0.746027
PRC train: 0.948543	val: 0.386237	test: 0.850353

Epoch: 67
Loss: 0.3216564356806648
ROC train: 0.958387	val: 0.704651	test: 0.769682
PRC train: 0.948074	val: 0.386412	test: 0.868899

Epoch: 68
Loss: 0.2842717966037654
ROC train: 0.955365	val: 0.712896	test: 0.788100
PRC train: 0.945098	val: 0.388383	test: 0.881533

Epoch: 69
Loss: 0.3225442208453379
ROC train: 0.958628	val: 0.722304	test: 0.784760
PRC train: 0.950036	val: 0.393285	test: 0.876475

Epoch: 70
Loss: 0.3291943321415342
ROC train: 0.961421	val: 0.724630	test: 0.772481
PRC train: 0.952708	val: 0.394190	test: 0.862143

Epoch: 71
Loss: 0.3368284741863769
ROC train: 0.961798	val: 0.720930	test: 0.789003
PRC train: 0.953463	val: 0.396021	test: 0.877091

Epoch: 72
Loss: 0.32634321001150346
ROC train: 0.959276	val: 0.723996	test: 0.782322
PRC train: 0.950071	val: 0.398656	test: 0.869219

Epoch: 73
Loss: 0.31531634770099287
ROC train: 0.962928	val: 0.718816	test: 0.773294
PRC train: 0.954627	val: 0.394702	test: 0.863033

Epoch: 74
Loss: 0.32647912205933877
ROC train: 0.959449	val: 0.706977	test: 0.745395
PRC train: 0.949656	val: 0.391547	test: 0.827273

Epoch: 75
Loss: 0.3370732406648345
ROC train: 0.959028	val: 0.702960	test: 0.760202
PRC train: 0.949333	val: 0.396499	test: 0.851873

Epoch: 76
Loss: 0.2921939277178959
ROC train: 0.962910	val: 0.708351	test: 0.773384
PRC train: 0.953602	val: 0.395031	test: 0.868552

Epoch: 77
Loss: 0.28185011084445877
ROC train: 0.964195	val: 0.712156	test: 0.775190
PRC train: 0.955571	val: 0.396586	test: 0.871388

Epoch: 78
Loss: 0.298569015822019
ROC train: 0.964018	val: 0.725053	test: 0.782774
PRC train: 0.956019	val: 0.399427	test: 0.873824

Epoch: 79
Loss: 0.2986208659890563
ROC train: 0.964598	val: 0.735624	test: 0.785843
PRC train: 0.955887	val: 0.407397	test: 0.877809

Epoch: 80
Loss: 0.25779952284720686
ROC train: 0.965397	val: 0.741860	test: 0.779884
PRC train: 0.956989	val: 0.411126	test: 0.870393

Epoch: 81
Loss: 0.29349584064762324
ROC train: 0.966717	val: 0.744820	test: 0.778440
PRC train: 0.958638	val: 0.413141	test: 0.867819

Epoch: 82
Loss: 0.2743374206493318
ROC train: 0.966408	val: 0.746195	test: 0.780516
PRC train: 0.958533	val: 0.411650	test: 0.867974

Epoch: 83
Loss: 0.32333117133251565
ROC train: 0.965231	val: 0.745983	test: 0.785302
PRC train: 0.958354	val: 0.409060	test: 0.869023

Epoch: 84
Loss: 0.29383713847644927
ROC train: 0.961277	val: 0.736892	test: 0.765439
PRC train: 0.954196	val: 0.401503	test: 0.850911

Epoch: 85
Loss: 0.2723090392140209
ROC train: 0.966026	val: 0.720085	test: 0.742145
PRC train: 0.959601	val: 0.389083	test: 0.830636

Epoch: 86
Loss: 0.27904390002068075
ROC train: 0.968473	val: 0.729915	test: 0.763633
PRC train: 0.962408	val: 0.395897	test: 0.854682

Epoch: 87
Loss: 0.28283929230262267
ROC train: 0.968872	val: 0.735729	test: 0.789184
PRC train: 0.961503	val: 0.404200	test: 0.872647

Epoch: 88
Loss: 0.2730515927807236
ROC train: 0.966940	val: 0.725370	test: 0.771036
PRC train: 0.959123	val: 0.401619	test: 0.857984

Epoch: 89
Loss: 0.27174822734644444
ROC train: 0.967890	val: 0.725159	test: 0.767064
PRC train: 0.960979	val: 0.404201	test: 0.857881

Epoch: 90
Loss: 0.29266384967221654
ROC train: 0.966634	val: 0.727378	test: 0.787739
PRC train: 0.960320	val: 0.403375	test: 0.873942

Epoch: 91
Loss: 0.27545637774961207
ROC train: 0.968077	val: 0.724101	test: 0.774196
PRC train: 0.962476	val: 0.393495	test: 0.860916

Epoch: 92
Loss: 0.289985869430625
ROC train: 0.967861	val: 0.717442	test: 0.730589
PRC train: 0.961120	val: 0.380200	test: 0.809714

Epoch: 93
Loss: 0.31354909002371906
ROC train: 0.966994	val: 0.717442	test: 0.727158
PRC train: 0.959842	val: 0.377938	test: 0.796989

Epoch: 94
Loss: 0.28093434280777785
PRC train: 0.911251	val: 0.920680	test: 0.752240

Epoch: 34
Loss: 0.33076549478681394
ROC train: 0.947372	val: 0.654579	test: 0.755869
PRC train: 0.916989	val: 0.919141	test: 0.745942

Epoch: 35
Loss: 0.3263329116166988
ROC train: 0.945468	val: 0.668864	test: 0.745957
PRC train: 0.914388	val: 0.927643	test: 0.740498

Epoch: 36
Loss: 0.3309384383730521
ROC train: 0.945859	val: 0.679121	test: 0.739871
PRC train: 0.914504	val: 0.931009	test: 0.735709

Epoch: 37
Loss: 0.3258763295895418
ROC train: 0.950662	val: 0.665568	test: 0.747001
PRC train: 0.922556	val: 0.925035	test: 0.744520

Epoch: 38
Loss: 0.30650168773984204
ROC train: 0.953102	val: 0.668132	test: 0.738828
PRC train: 0.926350	val: 0.923714	test: 0.726520

Epoch: 39
Loss: 0.3131790208718374
ROC train: 0.955240	val: 0.669963	test: 0.729091
PRC train: 0.928343	val: 0.923445	test: 0.723822

Epoch: 40
Loss: 0.31964317741342096
ROC train: 0.955679	val: 0.684982	test: 0.709963
PRC train: 0.930099	val: 0.930422	test: 0.717079

Epoch: 41
Loss: 0.31042459074205214
ROC train: 0.954229	val: 0.693040	test: 0.718832
PRC train: 0.929226	val: 0.933153	test: 0.730322

Epoch: 42
Loss: 0.32403166517892784
ROC train: 0.956056	val: 0.692308	test: 0.727004
PRC train: 0.932307	val: 0.930691	test: 0.739251

Epoch: 43
Loss: 0.3061125378915592
ROC train: 0.954335	val: 0.668132	test: 0.747174
PRC train: 0.930624	val: 0.921883	test: 0.753074

Epoch: 44
Loss: 0.30917387513850586
ROC train: 0.954267	val: 0.660806	test: 0.733090
PRC train: 0.929276	val: 0.919609	test: 0.729881

Epoch: 45
Loss: 0.3045605355383165
ROC train: 0.956102	val: 0.682784	test: 0.737437
PRC train: 0.931484	val: 0.926813	test: 0.726736

Epoch: 46
Loss: 0.31722883441805594
ROC train: 0.957229	val: 0.678388	test: 0.736741
PRC train: 0.932488	val: 0.929157	test: 0.727425

Epoch: 47
Loss: 0.30058109830799457
ROC train: 0.958904	val: 0.685714	test: 0.736741
PRC train: 0.936355	val: 0.932155	test: 0.735275

Epoch: 48
Loss: 0.3000524668079224
ROC train: 0.961792	val: 0.660073	test: 0.730656
PRC train: 0.941314	val: 0.925102	test: 0.732482

Epoch: 49
Loss: 0.3012660049843562
ROC train: 0.962862	val: 0.660073	test: 0.719701
PRC train: 0.942519	val: 0.924055	test: 0.727364

Epoch: 50
Loss: 0.29195388774792236
ROC train: 0.962126	val: 0.671062	test: 0.713267
PRC train: 0.941219	val: 0.923633	test: 0.713144

Epoch: 51
Loss: 0.28540348599364407
ROC train: 0.959971	val: 0.654579	test: 0.705443
PRC train: 0.938676	val: 0.917801	test: 0.707828

Epoch: 52
Loss: 0.3082285608308553
ROC train: 0.964021	val: 0.662271	test: 0.715702
PRC train: 0.945717	val: 0.918558	test: 0.720794

Epoch: 53
Loss: 0.2934116224962069
ROC train: 0.964481	val: 0.666300	test: 0.720049
PRC train: 0.946978	val: 0.921043	test: 0.730695

Epoch: 54
Loss: 0.27839988923235437
ROC train: 0.965146	val: 0.665201	test: 0.725787
PRC train: 0.945034	val: 0.919797	test: 0.727938

Epoch: 55
Loss: 0.2861016444554315
ROC train: 0.964038	val: 0.669597	test: 0.721092
PRC train: 0.943071	val: 0.922317	test: 0.718444

Epoch: 56
Loss: 0.28271368104716477
ROC train: 0.965950	val: 0.664835	test: 0.724048
PRC train: 0.947588	val: 0.921678	test: 0.720981

Epoch: 57
Loss: 0.28073015192149225
ROC train: 0.959932	val: 0.654579	test: 0.690662
PRC train: 0.939985	val: 0.917977	test: 0.689227

Epoch: 58
Loss: 0.28573489508814526
ROC train: 0.954118	val: 0.656777	test: 0.679012
PRC train: 0.931479	val: 0.915518	test: 0.684973

Epoch: 59
Loss: 0.2818047614841709
ROC train: 0.968059	val: 0.672161	test: 0.725961
PRC train: 0.951815	val: 0.914040	test: 0.740498

Epoch: 60
Loss: 0.2810300537458824
ROC train: 0.970431	val: 0.668132	test: 0.722483
PRC train: 0.955277	val: 0.921716	test: 0.735323

Epoch: 61
Loss: 0.27478250033333373
ROC train: 0.966050	val: 0.668498	test: 0.711876
PRC train: 0.947847	val: 0.924137	test: 0.719750

Epoch: 62
Loss: 0.2921965164278125
ROC train: 0.966153	val: 0.663736	test: 0.713093
PRC train: 0.948102	val: 0.919456	test: 0.723622

Epoch: 63
Loss: 0.26998410434949865
ROC train: 0.969375	val: 0.666300	test: 0.731525
PRC train: 0.952062	val: 0.916988	test: 0.739847

Epoch: 64
Loss: 0.27887677595009513
ROC train: 0.971113	val: 0.655311	test: 0.729438
PRC train: 0.955212	val: 0.912675	test: 0.724600

Epoch: 65
Loss: 0.26949973366338403
ROC train: 0.968998	val: 0.673260	test: 0.715180
PRC train: 0.952829	val: 0.921573	test: 0.710227

Epoch: 66
Loss: 0.2701824769602302
ROC train: 0.969672	val: 0.718315	test: 0.720918
PRC train: 0.955197	val: 0.937331	test: 0.730795

Epoch: 67
Loss: 0.26666706405674123
ROC train: 0.970913	val: 0.704396	test: 0.738480
PRC train: 0.957096	val: 0.934169	test: 0.748094

Epoch: 68
Loss: 0.2793804696207869
ROC train: 0.974795	val: 0.678022	test: 0.729960
PRC train: 0.962429	val: 0.924215	test: 0.730580

Epoch: 69
Loss: 0.2589695304835433
ROC train: 0.975719	val: 0.670330	test: 0.714658
PRC train: 0.963152	val: 0.920900	test: 0.713610

Epoch: 70
Loss: 0.2484314016921932
ROC train: 0.973659	val: 0.645055	test: 0.713093
PRC train: 0.960223	val: 0.914564	test: 0.706364

Epoch: 71
Loss: 0.27590167957746015
ROC train: 0.975314	val: 0.663004	test: 0.712224
PRC train: 0.962154	val: 0.920157	test: 0.706128

Epoch: 72
Loss: 0.24595880306377702
ROC train: 0.973393	val: 0.690476	test: 0.693445
PRC train: 0.961041	val: 0.930495	test: 0.691182

Epoch: 73
Loss: 0.25720997953034486
ROC train: 0.973656	val: 0.691575	test: 0.698139
PRC train: 0.960429	val: 0.930619	test: 0.688540

Epoch: 74
Loss: 0.2637985124723935
ROC train: 0.975599	val: 0.669231	test: 0.720049
PRC train: 0.963028	val: 0.924053	test: 0.712175

Epoch: 75
Loss: 0.25123898261118366
ROC train: 0.974886	val: 0.664103	test: 0.706834
PRC train: 0.961774	val: 0.921251	test: 0.692466

Epoch: 76
Loss: 0.2501440287399927
ROC train: 0.977549	val: 0.660806	test: 0.702487
PRC train: 0.965829	val: 0.920581	test: 0.689779

Epoch: 77
Loss: 0.2609023593800499
ROC train: 0.975862	val: 0.683150	test: 0.700574
PRC train: 0.963025	val: 0.925635	test: 0.693454

Epoch: 78
Loss: 0.22919841010184028
ROC train: 0.975782	val: 0.675824	test: 0.707529
PRC train: 0.963539	val: 0.926329	test: 0.694699

Epoch: 79
Loss: 0.24567939314344614
ROC train: 0.978465	val: 0.669231	test: 0.728569
PRC train: 0.967574	val: 0.923044	test: 0.728910

Epoch: 80
Loss: 0.253750127340006
ROC train: 0.977780	val: 0.666667	test: 0.716397
PRC train: 0.967023	val: 0.920405	test: 0.721420

Epoch: 81
Loss: 0.2367043896279279
ROC train: 0.979289	val: 0.685714	test: 0.714658
PRC train: 0.968748	val: 0.927035	test: 0.720136

Epoch: 82
Loss: 0.26149371719972414
ROC train: 0.978259	val: 0.689377	test: 0.708746
PRC train: 0.967570	val: 0.929882	test: 0.701904

Epoch: 83
Loss: 0.24080280954790362
ROC train: 0.979261	val: 0.687546	test: 0.709442
PRC train: 0.969546	val: 0.928081	test: 0.709919

Epoch: 84
Loss: 0.2597434943606688
ROC train: 0.979292	val: 0.662637	test: 0.695357
PRC train: 0.969698	val: 0.922164	test: 0.695392

Epoch: 85
Loss: 0.24022909063597314
ROC train: 0.975545	val: 0.664469	test: 0.687185
PRC train: 0.963459	val: 0.922240	test: 0.689737

Epoch: 86
Loss: 0.2373336875404211
ROC train: 0.979369	val: 0.685714	test: 0.708399
PRC train: 0.968942	val: 0.927540	test: 0.702684

Epoch: 87
Loss: 0.2451064578572431
ROC train: 0.980528	val: 0.684615	test: 0.696401
PRC train: 0.971197	val: 0.927448	test: 0.688893

Epoch: 88
Loss: 0.24597610424958524
ROC train: 0.980029	val: 0.667033	test: 0.677621
PRC train: 0.971126	val: 0.921415	test: 0.675356

Epoch: 89
Loss: 0.23463899879090663
ROC train: 0.980773	val: 0.660440	test: 0.683707
PRC train: 0.971305	val: 0.917613	test: 0.674888

Epoch: 90
Loss: 0.24522778972424283
ROC train: 0.982249	val: 0.669963	test: 0.713963
PRC train: 0.973009	val: 0.920319	test: 0.706822

Epoch: 91
Loss: 0.23013164467824282
ROC train: 0.981182	val: 0.683150	test: 0.715702
PRC train: 0.971474	val: 0.921646	test: 0.704885

Epoch: 92
Loss: 0.23393218098479193
ROC train: 0.979107	val: 0.675092	test: 0.707703
PRC train: 0.968816	val: 0.920801	test: 0.698965

Epoch: 93
Loss: 0.22415371687051328
ROC train: 0.981356	val: 0.662637	test: 0.709790
PRC train: 0.972525	val: 0.920247	test: 0.702611

Epoch: 94
Loss: 0.22680231728411102
ROC train: 0.980674	val: 0.679121	test: 0.710137
ROC train: 0.979349	val: 0.813811	test: 0.696167
PRC train: 0.978682	val: 0.401842	test: 0.818880

Epoch: 95
Loss: 0.25303007663634675
ROC train: 0.979290	val: 0.826826	test: 0.688337
PRC train: 0.978865	val: 0.414721	test: 0.809968

Epoch: 96
Loss: 0.25571479281916476
ROC train: 0.979626	val: 0.833625	test: 0.695549
PRC train: 0.978510	val: 0.416750	test: 0.816573

Epoch: 97
Loss: 0.24860164871844892
ROC train: 0.976166	val: 0.828380	test: 0.702607
PRC train: 0.974936	val: 0.406611	test: 0.827663

Epoch: 98
Loss: 0.245472026946624
ROC train: 0.977470	val: 0.826340	test: 0.710952
PRC train: 0.976364	val: 0.400141	test: 0.831535

Epoch: 99
Loss: 0.23011503572719394
ROC train: 0.979962	val: 0.827894	test: 0.697919
PRC train: 0.979160	val: 0.397788	test: 0.819635

Epoch: 100
Loss: 0.2639579684526373
ROC train: 0.981373	val: 0.817113	test: 0.697764
PRC train: 0.980647	val: 0.399212	test: 0.816391

Epoch: 101
Loss: 0.2273914013404009
ROC train: 0.980998	val: 0.810995	test: 0.696992
PRC train: 0.980372	val: 0.396967	test: 0.819610

Epoch: 102
Loss: 0.2346358973087574
ROC train: 0.980872	val: 0.813908	test: 0.704770
PRC train: 0.980034	val: 0.393402	test: 0.831249

Epoch: 103
Loss: 0.2241830567346398
ROC train: 0.979957	val: 0.812937	test: 0.702658
PRC train: 0.978967	val: 0.401086	test: 0.831022

Epoch: 104
Loss: 0.25665202275267945
ROC train: 0.980993	val: 0.816045	test: 0.688955
PRC train: 0.980332	val: 0.396472	test: 0.814052

Epoch: 105
Loss: 0.24806563469336984
ROC train: 0.983441	val: 0.832945	test: 0.680816
PRC train: 0.983066	val: 0.414448	test: 0.808351

Epoch: 106
Loss: 0.2463058156753098
ROC train: 0.983480	val: 0.821775	test: 0.686122
PRC train: 0.982711	val: 0.402999	test: 0.818189

Epoch: 107
Loss: 0.22441078851715068
ROC train: 0.980828	val: 0.793221	test: 0.707397
PRC train: 0.979696	val: 0.363865	test: 0.830424

Epoch: 108
Loss: 0.25546691337617095
ROC train: 0.982740	val: 0.802156	test: 0.702916
PRC train: 0.981796	val: 0.372904	test: 0.824231

Epoch: 109
Loss: 0.2392765956742156
ROC train: 0.985577	val: 0.826729	test: 0.687977
PRC train: 0.985079	val: 0.400849	test: 0.806491

Epoch: 110
Loss: 0.22333862645187658
ROC train: 0.984176	val: 0.825855	test: 0.688698
PRC train: 0.984022	val: 0.408743	test: 0.803402

Epoch: 111
Loss: 0.22868766025084597
ROC train: 0.985378	val: 0.814782	test: 0.692098
PRC train: 0.985123	val: 0.404870	test: 0.802995

Epoch: 112
Loss: 0.2538152698211431
ROC train: 0.985232	val: 0.822164	test: 0.684267
PRC train: 0.984626	val: 0.418450	test: 0.804188

Epoch: 113
Loss: 0.2141739744434289
ROC train: 0.983592	val: 0.809052	test: 0.691325
PRC train: 0.982972	val: 0.409668	test: 0.810112

Epoch: 114
Loss: 0.2140692575301853
ROC train: 0.983441	val: 0.803710	test: 0.699567
PRC train: 0.982770	val: 0.402725	test: 0.816424

Epoch: 115
Loss: 0.23774483447847058
ROC train: 0.982687	val: 0.805070	test: 0.702298
PRC train: 0.981844	val: 0.400927	test: 0.814920

Epoch: 116
Loss: 0.2330484859714206
ROC train: 0.984137	val: 0.818862	test: 0.701731
PRC train: 0.983592	val: 0.391713	test: 0.808192

Epoch: 117
Loss: 0.21315611572284637
ROC train: 0.984302	val: 0.824883	test: 0.693386
PRC train: 0.983816	val: 0.390126	test: 0.805484

Epoch: 118
Loss: 0.23036299835275198
ROC train: 0.985743	val: 0.834499	test: 0.696579
PRC train: 0.985122	val: 0.416377	test: 0.808696

Epoch: 119
Loss: 0.238289909404677
ROC train: 0.982867	val: 0.830614	test: 0.700392
PRC train: 0.982418	val: 0.429715	test: 0.812975

Epoch: 120
Loss: 0.23507276726970577
ROC train: 0.981441	val: 0.818959	test: 0.693128
PRC train: 0.981379	val: 0.408846	test: 0.806287

Early stopping
Best (ROC):	 train: 0.920392	val: 0.879662	test: 0.738306
Best (PRC):	 train: 0.901917	val: 0.445796	test: 0.851133
PRC train: 0.977692	val: 0.434884	test: 0.845149

Epoch: 95
Loss: 0.2568431702230212
ROC train: 0.978765	val: 0.844697	test: 0.716052
PRC train: 0.977537	val: 0.435468	test: 0.835919

Epoch: 96
Loss: 0.2572900632709144
ROC train: 0.976351	val: 0.835859	test: 0.722079
PRC train: 0.974965	val: 0.423913	test: 0.833654

Epoch: 97
Loss: 0.24235103960828708
ROC train: 0.978044	val: 0.846445	test: 0.736246
PRC train: 0.977010	val: 0.446649	test: 0.839547

Epoch: 98
Loss: 0.26686773993781876
ROC train: 0.979047	val: 0.854895	test: 0.738203
PRC train: 0.978133	val: 0.451747	test: 0.844386

Epoch: 99
Loss: 0.2480622705307743
ROC train: 0.977397	val: 0.846931	test: 0.743252
PRC train: 0.976567	val: 0.428650	test: 0.851750

Epoch: 100
Loss: 0.2501553215009195
ROC train: 0.980254	val: 0.848582	test: 0.738461
PRC train: 0.978650	val: 0.433074	test: 0.846686

Epoch: 101
Loss: 0.24362511808934695
ROC train: 0.982229	val: 0.859460	test: 0.728982
PRC train: 0.980699	val: 0.461329	test: 0.835328

Epoch: 102
Loss: 0.233479924958783
ROC train: 0.982511	val: 0.852758	test: 0.723728
PRC train: 0.981287	val: 0.456719	test: 0.831483

Epoch: 103
Loss: 0.23332691788946355
ROC train: 0.981752	val: 0.851593	test: 0.713940
PRC train: 0.980562	val: 0.455037	test: 0.824269

Epoch: 104
Loss: 0.23747850863220255
ROC train: 0.982925	val: 0.864025	test: 0.711210
PRC train: 0.981933	val: 0.461575	test: 0.820913

Epoch: 105
Loss: 0.2249427202548555
ROC train: 0.983188	val: 0.870241	test: 0.707810
PRC train: 0.982285	val: 0.481687	test: 0.820031

Epoch: 106
Loss: 0.23172903088353186
ROC train: 0.982473	val: 0.864413	test: 0.718834
PRC train: 0.981360	val: 0.464127	test: 0.833636

Epoch: 107
Loss: 0.24316309866993466
ROC train: 0.982292	val: 0.853341	test: 0.719658
PRC train: 0.980938	val: 0.442525	test: 0.830147

Epoch: 108
Loss: 0.20975801036479097
ROC train: 0.983256	val: 0.833819	test: 0.715125
PRC train: 0.982041	val: 0.415646	test: 0.828513

Epoch: 109
Loss: 0.24652535742241974
ROC train: 0.984249	val: 0.839744	test: 0.723779
PRC train: 0.983232	val: 0.415074	test: 0.829889

Epoch: 110
Loss: 0.22687700528798183
ROC train: 0.984623	val: 0.846348	test: 0.727900
PRC train: 0.983496	val: 0.421620	test: 0.830328

Epoch: 111
Loss: 0.24136764794896737
ROC train: 0.984599	val: 0.858683	test: 0.720019
PRC train: 0.983311	val: 0.449861	test: 0.822342

Epoch: 112
Loss: 0.23663772516169862
ROC train: 0.983168	val: 0.845765	test: 0.715949
PRC train: 0.982300	val: 0.404552	test: 0.827354

Epoch: 113
Loss: 0.21794162752386093
ROC train: 0.981796	val: 0.837607	test: 0.712549
PRC train: 0.981076	val: 0.377252	test: 0.827728

Epoch: 114
Loss: 0.21562415640046886
ROC train: 0.981636	val: 0.844017	test: 0.696167
PRC train: 0.981180	val: 0.410431	test: 0.811802

Epoch: 115
Loss: 0.23368137058886407
ROC train: 0.982336	val: 0.846834	test: 0.688904
PRC train: 0.981554	val: 0.435839	test: 0.804889

Epoch: 116
Loss: 0.222394262204213
ROC train: 0.983344	val: 0.849553	test: 0.697816
PRC train: 0.982293	val: 0.452717	test: 0.812419

Epoch: 117
Loss: 0.23996706637171528
ROC train: 0.985699	val: 0.842172	test: 0.714610
PRC train: 0.984709	val: 0.432575	test: 0.829620

Epoch: 118
Loss: 0.22939713586020682
ROC train: 0.982784	val: 0.835082	test: 0.729703
PRC train: 0.982024	val: 0.408642	test: 0.840352

Epoch: 119
Loss: 0.2313151036984919
ROC train: 0.982039	val: 0.834984	test: 0.730888
PRC train: 0.981144	val: 0.413921	test: 0.838989

Epoch: 120
Loss: 0.23258940740429918
ROC train: 0.983056	val: 0.837024	test: 0.730270
PRC train: 0.981479	val: 0.422301	test: 0.835406

Early stopping
Best (ROC):	 train: 0.944493	val: 0.873932	test: 0.740006
Best (PRC):	 train: 0.936630	val: 0.448083	test: 0.856933

PRC train: 0.975935	val: 0.376464	test: 0.812144

Epoch: 95
Loss: 0.25962338029718
ROC train: 0.976862	val: 0.830517	test: 0.705852
PRC train: 0.974546	val: 0.377342	test: 0.824598

Epoch: 96
Loss: 0.2470156586108979
ROC train: 0.974930	val: 0.842852	test: 0.706213
PRC train: 0.972219	val: 0.393973	test: 0.824817

Epoch: 97
Loss: 0.250681182067971
ROC train: 0.976760	val: 0.836053	test: 0.703946
PRC train: 0.975266	val: 0.382326	test: 0.812943

Epoch: 98
Loss: 0.24755044786854205
ROC train: 0.975149	val: 0.821678	test: 0.698898
PRC train: 0.973844	val: 0.358943	test: 0.808293

Epoch: 99
Loss: 0.2353074339297993
ROC train: 0.977246	val: 0.823524	test: 0.703328
PRC train: 0.975757	val: 0.364753	test: 0.811199

Epoch: 100
Loss: 0.2437626998695273
ROC train: 0.978769	val: 0.829740	test: 0.710900
PRC train: 0.976818	val: 0.363610	test: 0.824926

Epoch: 101
Loss: 0.2408326683292826
ROC train: 0.981057	val: 0.842657	test: 0.720534
PRC train: 0.979450	val: 0.381186	test: 0.833527

Epoch: 102
Loss: 0.26159699041490414
ROC train: 0.980833	val: 0.844211	test: 0.718782
PRC train: 0.979231	val: 0.387098	test: 0.830813

Epoch: 103
Loss: 0.26322225405965927
ROC train: 0.981202	val: 0.842269	test: 0.709458
PRC train: 0.979741	val: 0.402020	test: 0.823295

Epoch: 104
Loss: 0.21986597044809236
ROC train: 0.982229	val: 0.841783	test: 0.707346
PRC train: 0.980959	val: 0.391708	test: 0.820398

Epoch: 105
Loss: 0.2403818501070292
ROC train: 0.982093	val: 0.853050	test: 0.710179
PRC train: 0.980851	val: 0.409432	test: 0.824289

Epoch: 106
Loss: 0.22826304860461802
ROC train: 0.983285	val: 0.851496	test: 0.704667
PRC train: 0.982313	val: 0.404500	test: 0.815718

Epoch: 107
Loss: 0.23353766935930673
ROC train: 0.982974	val: 0.837898	test: 0.697661
PRC train: 0.982044	val: 0.390333	test: 0.801016

Epoch: 108
Loss: 0.23470883300358836
ROC train: 0.983149	val: 0.806915	test: 0.699258
PRC train: 0.981759	val: 0.369953	test: 0.816450

Epoch: 109
Loss: 0.2418284162926164
ROC train: 0.981777	val: 0.809635	test: 0.695292
PRC train: 0.980252	val: 0.365275	test: 0.816436

Epoch: 110
Loss: 0.23954254841158093
ROC train: 0.983285	val: 0.823621	test: 0.696889
PRC train: 0.981578	val: 0.366945	test: 0.807815

Epoch: 111
Loss: 0.22645130849077744
ROC train: 0.984312	val: 0.840812	test: 0.691376
PRC train: 0.982768	val: 0.393883	test: 0.798038

Epoch: 112
Loss: 0.2200909397449898
ROC train: 0.981767	val: 0.833042	test: 0.691892
PRC train: 0.980176	val: 0.385312	test: 0.800863

Epoch: 113
Loss: 0.22052932318824703
ROC train: 0.981368	val: 0.825175	test: 0.697043
PRC train: 0.980619	val: 0.391275	test: 0.798824

Epoch: 114
Loss: 0.22081604929283877
ROC train: 0.984735	val: 0.820707	test: 0.699001
PRC train: 0.984166	val: 0.375477	test: 0.802558

Epoch: 115
Loss: 0.22249637058337093
ROC train: 0.986550	val: 0.824398	test: 0.696579
PRC train: 0.985710	val: 0.367285	test: 0.802686

Epoch: 116
Loss: 0.23065190025923493
ROC train: 0.986696	val: 0.834110	test: 0.697558
PRC train: 0.986195	val: 0.380651	test: 0.807025

Epoch: 117
Loss: 0.2335147929959654
ROC train: 0.986268	val: 0.840812	test: 0.712291
PRC train: 0.985608	val: 0.399093	test: 0.815397

Epoch: 118
Loss: 0.23526079323432586
ROC train: 0.987037	val: 0.837995	test: 0.703328
PRC train: 0.986367	val: 0.388376	test: 0.815581

Epoch: 119
Loss: 0.21711736780665442
ROC train: 0.986657	val: 0.838481	test: 0.697352
PRC train: 0.986258	val: 0.389391	test: 0.810393

Epoch: 120
Loss: 0.2015372206513271
ROC train: 0.987864	val: 0.844211	test: 0.696992
PRC train: 0.987621	val: 0.401637	test: 0.809218

Early stopping
Best (ROC):	 train: 0.949972	val: 0.873155	test: 0.727746
Best (PRC):	 train: 0.943257	val: 0.439758	test: 0.851535
All runs completed.

PRC train: 0.959120	val: 0.382336	test: 0.862811

Epoch: 95
Loss: 0.28487261574308975
ROC train: 0.965818	val: 0.713953	test: 0.761557
PRC train: 0.960014	val: 0.389723	test: 0.858422

Epoch: 96
Loss: 0.29376583016573454
ROC train: 0.966095	val: 0.728647	test: 0.764085
PRC train: 0.959294	val: 0.423347	test: 0.855925

Epoch: 97
Loss: 0.2855064077780386
ROC train: 0.966566	val: 0.722304	test: 0.750271
PRC train: 0.959845	val: 0.426638	test: 0.848512

Epoch: 98
Loss: 0.29062373700846134
ROC train: 0.969599	val: 0.706342	test: 0.734471
PRC train: 0.963947	val: 0.389652	test: 0.837305

Epoch: 99
Loss: 0.2947056931075919
ROC train: 0.969664	val: 0.703805	test: 0.727880
PRC train: 0.964239	val: 0.371382	test: 0.832509

Epoch: 100
Loss: 0.2674138068347528
ROC train: 0.969995	val: 0.713002	test: 0.740339
PRC train: 0.964428	val: 0.388617	test: 0.838784

Epoch: 101
Loss: 0.2799034158656566
ROC train: 0.968743	val: 0.719345	test: 0.755959
PRC train: 0.963161	val: 0.400406	test: 0.849341

Epoch: 102
Loss: 0.2769320601845478
ROC train: 0.971125	val: 0.725687	test: 0.763362
PRC train: 0.965838	val: 0.404239	test: 0.856051

Epoch: 103
Loss: 0.26952367290580176
ROC train: 0.967973	val: 0.720402	test: 0.750813
PRC train: 0.962334	val: 0.400514	test: 0.849049

Epoch: 104
Loss: 0.28660571361453774
ROC train: 0.965641	val: 0.718393	test: 0.744131
PRC train: 0.960309	val: 0.399914	test: 0.841919

Epoch: 105
Loss: 0.2911718095711484
ROC train: 0.966019	val: 0.725159	test: 0.757313
PRC train: 0.960477	val: 0.409877	test: 0.847971

Epoch: 106
Loss: 0.2516549316671006
ROC train: 0.963770	val: 0.720402	test: 0.753611
PRC train: 0.958627	val: 0.399379	test: 0.847829

Epoch: 107
Loss: 0.25863735956442224
ROC train: 0.967721	val: 0.718605	test: 0.748194
PRC train: 0.961891	val: 0.395381	test: 0.840180

Epoch: 108
Loss: 0.26405933028883827
ROC train: 0.971488	val: 0.726216	test: 0.752077
PRC train: 0.964235	val: 0.405392	test: 0.837587

Epoch: 109
Loss: 0.2661127859092653
ROC train: 0.968563	val: 0.734778	test: 0.758216
PRC train: 0.960243	val: 0.427070	test: 0.840259

Epoch: 110
Loss: 0.2683462374797732
ROC train: 0.970866	val: 0.735518	test: 0.760925
PRC train: 0.964397	val: 0.419792	test: 0.843745

Epoch: 111
Loss: 0.24024856687400603
ROC train: 0.971323	val: 0.726638	test: 0.756410
PRC train: 0.965014	val: 0.408769	test: 0.847633

Epoch: 112
Loss: 0.259527087875379
ROC train: 0.972838	val: 0.718816	test: 0.751083
PRC train: 0.967216	val: 0.406570	test: 0.843537

Epoch: 113
Loss: 0.31473448529882825
ROC train: 0.974906	val: 0.713848	test: 0.741423
PRC train: 0.969827	val: 0.396258	test: 0.830287

Epoch: 114
Loss: 0.26449091511409656
ROC train: 0.974550	val: 0.724524	test: 0.718671
PRC train: 0.969036	val: 0.397315	test: 0.810468

Epoch: 115
Loss: 0.25199725382446886
ROC train: 0.974942	val: 0.733087	test: 0.722373
PRC train: 0.969991	val: 0.400309	test: 0.819878

Epoch: 116
Loss: 0.26777098762035934
ROC train: 0.971916	val: 0.734672	test: 0.729325
PRC train: 0.966557	val: 0.411774	test: 0.830700

Epoch: 117
Loss: 0.2728031840664367
ROC train: 0.967203	val: 0.730444	test: 0.733568
PRC train: 0.961302	val: 0.420559	test: 0.844115

Epoch: 118
Loss: 0.27318129069290115
ROC train: 0.970783	val: 0.734249	test: 0.741694
PRC train: 0.965030	val: 0.422019	test: 0.847965

Epoch: 119
Loss: 0.267510222972394
ROC train: 0.968775	val: 0.715962	test: 0.733839
PRC train: 0.961992	val: 0.414882	test: 0.832455

Epoch: 120
Loss: 0.32129812866396856
ROC train: 0.972463	val: 0.710359	test: 0.727158
PRC train: 0.967027	val: 0.397808	test: 0.822439

Early stopping
Best (ROC):	 train: 0.965173	val: 0.742495	test: 0.775099
Best (PRC):	 train: 0.957865	val: 0.422119	test: 0.876510

PRC train: 0.972207	val: 0.905182	test: 0.689293

Epoch: 95
Loss: 0.22108222833904886
ROC train: 0.984104	val: 0.631868	test: 0.704921
PRC train: 0.977036	val: 0.898952	test: 0.695194

Epoch: 96
Loss: 0.22450047789051847
ROC train: 0.985020	val: 0.629670	test: 0.698313
PRC train: 0.977993	val: 0.895252	test: 0.682450

Epoch: 97
Loss: 0.19973907725921797
ROC train: 0.983964	val: 0.641758	test: 0.698139
PRC train: 0.976254	val: 0.892545	test: 0.682267

Epoch: 98
Loss: 0.221188507990809
ROC train: 0.984929	val: 0.640293	test: 0.709963
PRC train: 0.978102	val: 0.895438	test: 0.699692

Epoch: 99
Loss: 0.20586990921548956
ROC train: 0.985208	val: 0.647619	test: 0.714832
PRC train: 0.978424	val: 0.910603	test: 0.698278

Epoch: 100
Loss: 0.21776909920223333
ROC train: 0.983776	val: 0.646154	test: 0.701095
PRC train: 0.976271	val: 0.911227	test: 0.690396

Epoch: 101
Loss: 0.2252952275073857
ROC train: 0.981510	val: 0.644322	test: 0.691184
PRC train: 0.972567	val: 0.908985	test: 0.681704

Epoch: 102
Loss: 0.19995684347448767
ROC train: 0.978339	val: 0.657509	test: 0.672926
PRC train: 0.967463	val: 0.913802	test: 0.658723

Epoch: 103
Loss: 0.23525097677601536
ROC train: 0.984298	val: 0.634799	test: 0.689619
PRC train: 0.976434	val: 0.907338	test: 0.685852

Epoch: 104
Loss: 0.22160627181786924
ROC train: 0.984763	val: 0.604029	test: 0.698835
PRC train: 0.977566	val: 0.894940	test: 0.690715

Epoch: 105
Loss: 0.21748982781544596
ROC train: 0.985205	val: 0.627106	test: 0.696575
PRC train: 0.977958	val: 0.897164	test: 0.684226

Epoch: 106
Loss: 0.22504965327987758
ROC train: 0.986704	val: 0.640293	test: 0.706660
PRC train: 0.980110	val: 0.900331	test: 0.692579

Epoch: 107
Loss: 0.2124201219343263
ROC train: 0.987945	val: 0.630037	test: 0.715006
PRC train: 0.982067	val: 0.902287	test: 0.701881

Epoch: 108
Loss: 0.20252247817086527
ROC train: 0.987568	val: 0.623443	test: 0.710485
PRC train: 0.981871	val: 0.902089	test: 0.696018

Epoch: 109
Loss: 0.20103986724333986
ROC train: 0.986775	val: 0.626374	test: 0.701617
PRC train: 0.980739	val: 0.896335	test: 0.677980

Epoch: 110
Loss: 0.20873561944999489
ROC train: 0.984047	val: 0.638828	test: 0.682316
PRC train: 0.976270	val: 0.909042	test: 0.658821

Epoch: 111
Loss: 0.19113365786389852
ROC train: 0.983764	val: 0.634799	test: 0.669623
PRC train: 0.976118	val: 0.910977	test: 0.646896

Epoch: 112
Loss: 0.20080299695127585
ROC train: 0.985908	val: 0.609158	test: 0.688576
PRC train: 0.979641	val: 0.905780	test: 0.674653

Epoch: 113
Loss: 0.1878039721118347
ROC train: 0.988747	val: 0.617582	test: 0.720223
PRC train: 0.983991	val: 0.906615	test: 0.712679

Epoch: 114
Loss: 0.20664390678061792
ROC train: 0.988336	val: 0.638095	test: 0.713615
PRC train: 0.983209	val: 0.908939	test: 0.709894

Epoch: 115
Loss: 0.19406884893939133
ROC train: 0.987748	val: 0.630403	test: 0.710833
PRC train: 0.982429	val: 0.907469	test: 0.709159

Epoch: 116
Loss: 0.19645666365847053
ROC train: 0.987063	val: 0.650549	test: 0.716223
PRC train: 0.981000	val: 0.909301	test: 0.714241

Epoch: 117
Loss: 0.19407079927949647
ROC train: 0.988841	val: 0.660073	test: 0.718658
PRC train: 0.983736	val: 0.920852	test: 0.706721

Epoch: 118
Loss: 0.1953591704489961
ROC train: 0.987360	val: 0.647619	test: 0.703878
PRC train: 0.981766	val: 0.907378	test: 0.683443

Epoch: 119
Loss: 0.20152185602904313
ROC train: 0.988779	val: 0.627473	test: 0.704921
PRC train: 0.983792	val: 0.902566	test: 0.687866

Epoch: 120
Loss: 0.1898482374711008
ROC train: 0.986915	val: 0.657143	test: 0.696401
PRC train: 0.980924	val: 0.905399	test: 0.680723

Early stopping
Best (ROC):	 train: 0.959763	val: 0.682418	test: 0.729786
Best (PRC):	 train: 0.937605	val: 0.925656	test: 0.744140

ROC train: 0.981995	val: 0.664103	test: 0.716571
PRC train: 0.972514	val: 0.921318	test: 0.711544

Epoch: 95
Loss: 0.2223406516785628
ROC train: 0.978037	val: 0.676190	test: 0.715354
PRC train: 0.966438	val: 0.926161	test: 0.707985

Epoch: 96
Loss: 0.21922091458134768
ROC train: 0.978236	val: 0.685348	test: 0.707703
PRC train: 0.966153	val: 0.929342	test: 0.697375

Epoch: 97
Loss: 0.2331361816392032
ROC train: 0.981507	val: 0.686447	test: 0.714832
PRC train: 0.971670	val: 0.929314	test: 0.700200

Epoch: 98
Loss: 0.2307759171482066
ROC train: 0.981712	val: 0.700733	test: 0.726830
PRC train: 0.971897	val: 0.935868	test: 0.717859

Epoch: 99
Loss: 0.23229833376812442
ROC train: 0.983388	val: 0.700000	test: 0.745957
PRC train: 0.974892	val: 0.935973	test: 0.734170

Epoch: 100
Loss: 0.23326813966247836
ROC train: 0.983467	val: 0.698535	test: 0.743349
PRC train: 0.975431	val: 0.937244	test: 0.733074

Epoch: 101
Loss: 0.22908697763036492
ROC train: 0.983519	val: 0.693773	test: 0.720396
PRC train: 0.975295	val: 0.934249	test: 0.723631

Epoch: 102
Loss: 0.21937148056356232
ROC train: 0.983916	val: 0.679487	test: 0.721092
PRC train: 0.975708	val: 0.928501	test: 0.728058

Epoch: 103
Loss: 0.2099316743603231
ROC train: 0.984312	val: 0.675824	test: 0.728395
PRC train: 0.976285	val: 0.926599	test: 0.722148

Epoch: 104
Loss: 0.22420474677447427
ROC train: 0.982317	val: 0.658608	test: 0.725961
PRC train: 0.972998	val: 0.918514	test: 0.725607

Epoch: 105
Loss: 0.2042047296847873
ROC train: 0.984466	val: 0.653480	test: 0.731525
PRC train: 0.976110	val: 0.916777	test: 0.730216

Epoch: 106
Loss: 0.21968032271431745
ROC train: 0.984960	val: 0.681319	test: 0.733090
PRC train: 0.977755	val: 0.927839	test: 0.726285

Epoch: 107
Loss: 0.21836520880144814
ROC train: 0.981578	val: 0.695238	test: 0.721961
PRC train: 0.972638	val: 0.927263	test: 0.717481

Epoch: 108
Loss: 0.2182802137455247
ROC train: 0.983099	val: 0.669963	test: 0.707877
PRC train: 0.974838	val: 0.923597	test: 0.699010

Epoch: 109
Loss: 0.21907431806292466
ROC train: 0.978165	val: 0.665934	test: 0.698661
PRC train: 0.967947	val: 0.921897	test: 0.692133

Epoch: 110
Loss: 0.22023144966773173
ROC train: 0.981858	val: 0.663370	test: 0.715702
PRC train: 0.972449	val: 0.921617	test: 0.715397

Epoch: 111
Loss: 0.21981408875627523
ROC train: 0.985950	val: 0.664469	test: 0.727873
PRC train: 0.979620	val: 0.918784	test: 0.721992

Epoch: 112
Loss: 0.22108699520316813
ROC train: 0.985257	val: 0.673993	test: 0.723179
PRC train: 0.978931	val: 0.923985	test: 0.721561

Epoch: 113
Loss: 0.2091022323512362
ROC train: 0.983667	val: 0.661905	test: 0.735698
PRC train: 0.976256	val: 0.920366	test: 0.744164

Epoch: 114
Loss: 0.2107813667473331
ROC train: 0.983741	val: 0.647619	test: 0.741436
PRC train: 0.976060	val: 0.914730	test: 0.757110

Epoch: 115
Loss: 0.2110406166590956
ROC train: 0.985765	val: 0.638095	test: 0.739350
PRC train: 0.978935	val: 0.912388	test: 0.756231

Epoch: 116
Loss: 0.20913894164888616
ROC train: 0.983653	val: 0.666667	test: 0.729786
PRC train: 0.975897	val: 0.924799	test: 0.751376

Epoch: 117
Loss: 0.2170191775354624
ROC train: 0.981341	val: 0.667766	test: 0.707703
PRC train: 0.972198	val: 0.924018	test: 0.728029

Epoch: 118
Loss: 0.20582550779522438
ROC train: 0.984829	val: 0.656777	test: 0.718310
PRC train: 0.977145	val: 0.922182	test: 0.729042

Epoch: 119
Loss: 0.20772696452019268
ROC train: 0.985462	val: 0.652015	test: 0.727700
PRC train: 0.977695	val: 0.922071	test: 0.738844

Epoch: 120
Loss: 0.1938434093568492
ROC train: 0.982868	val: 0.665568	test: 0.711876
PRC train: 0.974092	val: 0.926803	test: 0.722797

Early stopping
Best (ROC):	 train: 0.919923	val: 0.746520	test: 0.724048
Best (PRC):	 train: 0.867733	val: 0.950175	test: 0.724088

PRC train: 0.970687	val: 0.923652	test: 0.704694

Epoch: 95
Loss: 0.23256280458070605
ROC train: 0.980531	val: 0.685714	test: 0.705616
PRC train: 0.971047	val: 0.925152	test: 0.706626

Epoch: 96
Loss: 0.2253756208266972
ROC train: 0.983505	val: 0.680220	test: 0.706486
PRC train: 0.975919	val: 0.924643	test: 0.703760

Epoch: 97
Loss: 0.2368353281017863
ROC train: 0.982163	val: 0.688278	test: 0.694836
PRC train: 0.973750	val: 0.927667	test: 0.700748

Epoch: 98
Loss: 0.240910786952161
ROC train: 0.981239	val: 0.672527	test: 0.682838
PRC train: 0.972238	val: 0.920776	test: 0.689712

Epoch: 99
Loss: 0.2312874044527668
ROC train: 0.984620	val: 0.656044	test: 0.703530
PRC train: 0.977970	val: 0.915926	test: 0.707209

Epoch: 100
Loss: 0.22681792857567745
ROC train: 0.985128	val: 0.670696	test: 0.699009
PRC train: 0.978668	val: 0.920510	test: 0.706108

Epoch: 101
Loss: 0.21675044616734906
ROC train: 0.984715	val: 0.691941	test: 0.698661
PRC train: 0.977818	val: 0.929226	test: 0.706614

Epoch: 102
Loss: 0.2193817610538491
ROC train: 0.984706	val: 0.689011	test: 0.690662
PRC train: 0.977407	val: 0.930755	test: 0.694087

Epoch: 103
Loss: 0.21401888225195628
ROC train: 0.985211	val: 0.678755	test: 0.704225
PRC train: 0.977913	val: 0.929640	test: 0.702057

Epoch: 104
Loss: 0.2075069933581873
ROC train: 0.984552	val: 0.671795	test: 0.711702
PRC train: 0.976629	val: 0.925963	test: 0.714503

Epoch: 105
Loss: 0.21125080470802815
ROC train: 0.982500	val: 0.682418	test: 0.673970
PRC train: 0.973944	val: 0.924811	test: 0.669365

Epoch: 106
Loss: 0.22616148674363937
ROC train: 0.985131	val: 0.673626	test: 0.675013
PRC train: 0.978444	val: 0.922254	test: 0.680667

Epoch: 107
Loss: 0.23145370723767966
ROC train: 0.986507	val: 0.664835	test: 0.690662
PRC train: 0.980539	val: 0.919723	test: 0.705863

Epoch: 108
Loss: 0.2258050905670399
ROC train: 0.982777	val: 0.659707	test: 0.708399
PRC train: 0.974405	val: 0.915945	test: 0.714460

Epoch: 109
Loss: 0.23524494268763524
ROC train: 0.983587	val: 0.669963	test: 0.717788
PRC train: 0.975579	val: 0.923205	test: 0.716403

Epoch: 110
Loss: 0.2345411527875147
ROC train: 0.985342	val: 0.689011	test: 0.702487
PRC train: 0.978591	val: 0.930102	test: 0.706918

Epoch: 111
Loss: 0.21041784193025723
ROC train: 0.985394	val: 0.660440	test: 0.695357
PRC train: 0.978975	val: 0.919609	test: 0.692608

Epoch: 112
Loss: 0.20130545372961167
ROC train: 0.984797	val: 0.651282	test: 0.703182
PRC train: 0.978326	val: 0.916960	test: 0.696461

Epoch: 113
Loss: 0.21271753621081774
ROC train: 0.987055	val: 0.656410	test: 0.720223
PRC train: 0.981464	val: 0.916456	test: 0.722176

Epoch: 114
Loss: 0.22524471399464135
ROC train: 0.985731	val: 0.679853	test: 0.703530
PRC train: 0.979171	val: 0.921174	test: 0.699097

Epoch: 115
Loss: 0.19836428910373863
ROC train: 0.985060	val: 0.669597	test: 0.686663
PRC train: 0.978571	val: 0.921200	test: 0.678275

Epoch: 116
Loss: 0.21145788119991504
ROC train: 0.986079	val: 0.676557	test: 0.692401
PRC train: 0.979898	val: 0.925148	test: 0.686639

Epoch: 117
Loss: 0.1999177164646932
ROC train: 0.987691	val: 0.676557	test: 0.704747
PRC train: 0.982312	val: 0.925663	test: 0.700370

Epoch: 118
Loss: 0.2192383119687312
ROC train: 0.989170	val: 0.689011	test: 0.712572
PRC train: 0.984780	val: 0.927738	test: 0.710205

Epoch: 119
Loss: 0.21026411438528228
ROC train: 0.987146	val: 0.704396	test: 0.699878
PRC train: 0.982398	val: 0.925709	test: 0.690102

Epoch: 120
Loss: 0.18528297502747626
ROC train: 0.987126	val: 0.708059	test: 0.699183
PRC train: 0.981722	val: 0.925481	test: 0.685882

Early stopping
Best (ROC):	 train: 0.969672	val: 0.718315	test: 0.720918
Best (PRC):	 train: 0.955197	val: 0.937331	test: 0.730795

ROC train: 0.969272	val: 0.738055	test: 0.767244
PRC train: 0.962753	val: 0.416368	test: 0.866454

Epoch: 95
Loss: 0.3089851757360458
ROC train: 0.969099	val: 0.734672	test: 0.776995
PRC train: 0.962759	val: 0.418377	test: 0.872636

Epoch: 96
Loss: 0.26856767038019286
ROC train: 0.968498	val: 0.735624	test: 0.783947
PRC train: 0.962434	val: 0.424696	test: 0.875046

Epoch: 97
Loss: 0.26743258103706014
ROC train: 0.970718	val: 0.735941	test: 0.779704
PRC train: 0.964884	val: 0.426109	test: 0.869268

Epoch: 98
Loss: 0.2464296144290718
ROC train: 0.970736	val: 0.736786	test: 0.751445
PRC train: 0.964600	val: 0.430560	test: 0.847885

Epoch: 99
Loss: 0.2628273545589632
ROC train: 0.971193	val: 0.737421	test: 0.754605
PRC train: 0.965419	val: 0.419864	test: 0.849012

Epoch: 100
Loss: 0.30452633509638155
ROC train: 0.970599	val: 0.739323	test: 0.753160
PRC train: 0.964640	val: 0.426118	test: 0.847558

Epoch: 101
Loss: 0.23659236890784685
ROC train: 0.971020	val: 0.739746	test: 0.751625
PRC train: 0.965868	val: 0.438653	test: 0.848750

Epoch: 102
Loss: 0.2539033282116202
ROC train: 0.973338	val: 0.741966	test: 0.768599
PRC train: 0.969099	val: 0.438857	test: 0.859271

Epoch: 103
Loss: 0.2802946684229469
ROC train: 0.974410	val: 0.735307	test: 0.766793
PRC train: 0.970463	val: 0.414798	test: 0.858394

Epoch: 104
Loss: 0.25797129659199547
ROC train: 0.971931	val: 0.732981	test: 0.777086
PRC train: 0.966913	val: 0.419719	test: 0.866459

Epoch: 105
Loss: 0.2698894007093492
ROC train: 0.973255	val: 0.740275	test: 0.773474
PRC train: 0.968457	val: 0.426173	test: 0.864983

Epoch: 106
Loss: 0.241946409352401
ROC train: 0.970589	val: 0.739429	test: 0.784670
PRC train: 0.965435	val: 0.421343	test: 0.873037

Epoch: 107
Loss: 0.27483388409746196
ROC train: 0.971880	val: 0.738795	test: 0.775551
PRC train: 0.966624	val: 0.421946	test: 0.867932

Epoch: 108
Loss: 0.2751812574331227
ROC train: 0.969786	val: 0.727696	test: 0.750722
PRC train: 0.964460	val: 0.422526	test: 0.846399

Epoch: 109
Loss: 0.3043325769979587
ROC train: 0.971740	val: 0.727696	test: 0.764536
PRC train: 0.966630	val: 0.419751	test: 0.856910

Epoch: 110
Loss: 0.27086825713148455
ROC train: 0.972989	val: 0.706660	test: 0.786566
PRC train: 0.967846	val: 0.386515	test: 0.873716

Epoch: 111
Loss: 0.25875230271368244
ROC train: 0.974514	val: 0.714271	test: 0.767244
PRC train: 0.970053	val: 0.392093	test: 0.859104

Epoch: 112
Loss: 0.28371913605278276
ROC train: 0.974953	val: 0.732558	test: 0.770495
PRC train: 0.970334	val: 0.404855	test: 0.862194

Epoch: 113
Loss: 0.24470701661404473
ROC train: 0.973755	val: 0.725793	test: 0.779704
PRC train: 0.969046	val: 0.398499	test: 0.866068

Epoch: 114
Loss: 0.2789629680477538
ROC train: 0.974025	val: 0.724207	test: 0.762459
PRC train: 0.969336	val: 0.405244	test: 0.857429

Epoch: 115
Loss: 0.22661741040398226
ROC train: 0.975338	val: 0.731607	test: 0.746569
PRC train: 0.970853	val: 0.416272	test: 0.849476

Epoch: 116
Loss: 0.26973362537066126
ROC train: 0.977015	val: 0.731395	test: 0.758306
PRC train: 0.972527	val: 0.411129	test: 0.860071

Epoch: 117
Loss: 0.2572132608893992
ROC train: 0.977270	val: 0.731607	test: 0.762730
PRC train: 0.972789	val: 0.412309	test: 0.855730

Epoch: 118
Loss: 0.2580636985357326
ROC train: 0.975378	val: 0.729070	test: 0.786295
PRC train: 0.969900	val: 0.416345	test: 0.866420

Epoch: 119
Loss: 0.2636269459046437
ROC train: 0.976475	val: 0.730867	test: 0.778079
PRC train: 0.971597	val: 0.418599	test: 0.860739

Epoch: 120
Loss: 0.25772405396820075
ROC train: 0.977393	val: 0.729598	test: 0.764626
PRC train: 0.972834	val: 0.413020	test: 0.851256

Epoch: 121
Loss: 0.23013944511179782
ROC train: 0.975299	val: 0.731290	test: 0.780426
PRC train: 0.971120	val: 0.411143	test: 0.860152

Epoch: 122
Loss: 0.2550889218191686
ROC train: 0.971898	val: 0.731712	test: 0.781780
PRC train: 0.966910	val: 0.415953	test: 0.866793

Epoch: 123
Loss: 0.26379461261744214
ROC train: 0.974557	val: 0.731078	test: 0.752889
PRC train: 0.969380	val: 0.417780	test: 0.846347

Epoch: 124
Loss: 0.2261962947390331
ROC train: 0.972931	val: 0.726956	test: 0.731221
PRC train: 0.967234	val: 0.399537	test: 0.831493

Epoch: 125
Loss: 0.25062178129587775
ROC train: 0.976795	val: 0.737104	test: 0.739527
PRC train: 0.971777	val: 0.423489	test: 0.837049

Epoch: 126
Loss: 0.2531966834644729
ROC train: 0.976875	val: 0.734249	test: 0.734651
PRC train: 0.971810	val: 0.418333	test: 0.835044

Early stopping
Best (ROC):	 train: 0.965227	val: 0.749260	test: 0.762821
Best (PRC):	 train: 0.958523	val: 0.416766	test: 0.853919
All runs completed.

ROC train: 0.969750	val: 0.714059	test: 0.758577
PRC train: 0.964410	val: 0.374954	test: 0.839768

Epoch: 95
Loss: 0.2724343372627864
ROC train: 0.969340	val: 0.707822	test: 0.759661
PRC train: 0.964116	val: 0.372194	test: 0.844280

Epoch: 96
Loss: 0.26209813952982425
ROC train: 0.970948	val: 0.727801	test: 0.751806
PRC train: 0.965802	val: 0.392059	test: 0.836657

Epoch: 97
Loss: 0.2905137106317205
ROC train: 0.971244	val: 0.736364	test: 0.758848
PRC train: 0.965416	val: 0.404554	test: 0.840451

Epoch: 98
Loss: 0.3087666563646762
ROC train: 0.968487	val: 0.734989	test: 0.771578
PRC train: 0.961759	val: 0.406729	test: 0.849713

Epoch: 99
Loss: 0.24993361676436274
ROC train: 0.966372	val: 0.721459	test: 0.754695
PRC train: 0.959516	val: 0.401715	test: 0.830650

Epoch: 100
Loss: 0.27181668030649
ROC train: 0.971938	val: 0.715222	test: 0.755327
PRC train: 0.966364	val: 0.396769	test: 0.832644

Epoch: 101
Loss: 0.2803212824368475
ROC train: 0.971704	val: 0.718499	test: 0.775551
PRC train: 0.965755	val: 0.394011	test: 0.860075

Epoch: 102
Loss: 0.27071731466826154
ROC train: 0.973626	val: 0.719027	test: 0.762730
PRC train: 0.968544	val: 0.389697	test: 0.846600

Epoch: 103
Loss: 0.27397734722564204
ROC train: 0.974252	val: 0.722833	test: 0.754063
PRC train: 0.969296	val: 0.389653	test: 0.832489

Epoch: 104
Loss: 0.28980398414746167
ROC train: 0.973201	val: 0.730444	test: 0.743409
PRC train: 0.968020	val: 0.402907	test: 0.814193

Epoch: 105
Loss: 0.264975801254706
ROC train: 0.972841	val: 0.739852	test: 0.745576
PRC train: 0.967023	val: 0.418417	test: 0.825345

Epoch: 106
Loss: 0.27121327085276675
ROC train: 0.972424	val: 0.735201	test: 0.769772
PRC train: 0.966287	val: 0.417966	test: 0.861507

Epoch: 107
Loss: 0.24115404919266598
ROC train: 0.972237	val: 0.725053	test: 0.770314
PRC train: 0.965927	val: 0.403360	test: 0.863459

Epoch: 108
Loss: 0.2931041240211717
ROC train: 0.971934	val: 0.715222	test: 0.752347
PRC train: 0.966259	val: 0.400336	test: 0.845408

Epoch: 109
Loss: 0.2412564930005316
ROC train: 0.969722	val: 0.732241	test: 0.740069
PRC train: 0.963002	val: 0.428062	test: 0.821456

Epoch: 110
Loss: 0.2425637528773799
ROC train: 0.972226	val: 0.741226	test: 0.749458
PRC train: 0.966365	val: 0.431744	test: 0.830613

Epoch: 111
Loss: 0.25584627444010083
ROC train: 0.975007	val: 0.743658	test: 0.750451
PRC train: 0.969759	val: 0.426842	test: 0.835897

Epoch: 112
Loss: 0.24853821363753054
ROC train: 0.975813	val: 0.739112	test: 0.750361
PRC train: 0.970998	val: 0.421001	test: 0.842453

Epoch: 113
Loss: 0.2721601442558086
ROC train: 0.974367	val: 0.741966	test: 0.738624
PRC train: 0.969222	val: 0.427965	test: 0.831263

Epoch: 114
Loss: 0.2643294529670045
ROC train: 0.974133	val: 0.741543	test: 0.738443
PRC train: 0.969039	val: 0.429963	test: 0.837657

Epoch: 115
Loss: 0.25946897476148073
ROC train: 0.974939	val: 0.740592	test: 0.758035
PRC train: 0.970131	val: 0.423592	test: 0.849158

Epoch: 116
Loss: 0.2556245584580968
ROC train: 0.974032	val: 0.722833	test: 0.744222
PRC train: 0.968815	val: 0.396217	test: 0.828386

Epoch: 117
Loss: 0.273476585617186
ROC train: 0.975000	val: 0.733510	test: 0.754875
PRC train: 0.970156	val: 0.404136	test: 0.838252

Epoch: 118
Loss: 0.2489849705750058
ROC train: 0.974273	val: 0.755180	test: 0.766342
PRC train: 0.969406	val: 0.430564	test: 0.850458

Epoch: 119
Loss: 0.2516152563564541
ROC train: 0.974421	val: 0.752748	test: 0.763814
PRC train: 0.969004	val: 0.432280	test: 0.852885

Epoch: 120
Loss: 0.25669948326296865
ROC train: 0.975094	val: 0.743552	test: 0.745486
PRC train: 0.970378	val: 0.412379	test: 0.833690

Epoch: 121
Loss: 0.2825787011688329
ROC train: 0.975450	val: 0.737104	test: 0.746298
PRC train: 0.971265	val: 0.400689	test: 0.833450

Epoch: 122
Loss: 0.28692154685568994
ROC train: 0.976655	val: 0.732347	test: 0.779884
PRC train: 0.973028	val: 0.392881	test: 0.861260

Epoch: 123
Loss: 0.25626570260192794
ROC train: 0.975655	val: 0.723150	test: 0.797039
PRC train: 0.971890	val: 0.385058	test: 0.884113

Epoch: 124
Loss: 0.28413720377355867
ROC train: 0.979134	val: 0.721987	test: 0.762189
PRC train: 0.975888	val: 0.384462	test: 0.849679

Epoch: 125
Loss: 0.24535422897180523
ROC train: 0.975806	val: 0.716808	test: 0.710455
PRC train: 0.971503	val: 0.384442	test: 0.789266

Epoch: 126
Loss: 0.2628822707792383
ROC train: 0.974759	val: 0.727696	test: 0.729686
PRC train: 0.970992	val: 0.404316	test: 0.823571

Epoch: 127
Loss: 0.23880780134673496
ROC train: 0.972089	val: 0.739006	test: 0.741694
PRC train: 0.967790	val: 0.410677	test: 0.841901

Epoch: 128
Loss: 0.23579810531683068
ROC train: 0.973262	val: 0.736575	test: 0.767696
PRC train: 0.969026	val: 0.404274	test: 0.861708

Epoch: 129
Loss: 0.25244094175802684
ROC train: 0.978810	val: 0.729070	test: 0.770495
PRC train: 0.975085	val: 0.388273	test: 0.860183

Epoch: 130
Loss: 0.26505235401824445
ROC train: 0.979001	val: 0.727590	test: 0.756320
PRC train: 0.974936	val: 0.389157	test: 0.845396

Epoch: 131
Loss: 0.33931294646721105
ROC train: 0.976749	val: 0.726744	test: 0.756952
PRC train: 0.971609	val: 0.389188	test: 0.846334

Epoch: 132
Loss: 0.26074687060787577
ROC train: 0.977274	val: 0.725370	test: 0.736547
PRC train: 0.972810	val: 0.387743	test: 0.830015

Epoch: 133
Loss: 0.2718119933745842
ROC train: 0.980088	val: 0.732981	test: 0.738624
PRC train: 0.976866	val: 0.393007	test: 0.831684

Epoch: 134
Loss: 0.24643717403519946
ROC train: 0.980937	val: 0.738689	test: 0.744763
PRC train: 0.978108	val: 0.396169	test: 0.835719

Epoch: 135
Loss: 0.26497093363879015
ROC train: 0.980322	val: 0.735729	test: 0.746298
PRC train: 0.977237	val: 0.400261	test: 0.833178

Epoch: 136
Loss: 0.23854816997606038
ROC train: 0.979163	val: 0.723044	test: 0.734200
PRC train: 0.975325	val: 0.396543	test: 0.826101

Epoch: 137
Loss: 0.2613027143155723
ROC train: 0.978555	val: 0.722199	test: 0.741603
PRC train: 0.973831	val: 0.397266	test: 0.833777

Epoch: 138
Loss: 0.2672239082129901
ROC train: 0.976903	val: 0.724101	test: 0.763453
PRC train: 0.972528	val: 0.397748	test: 0.861514

Epoch: 139
Loss: 0.26122711363464507
ROC train: 0.979573	val: 0.727061	test: 0.743409
PRC train: 0.975319	val: 0.391667	test: 0.842472

Epoch: 140
Loss: 0.2595587823455937
ROC train: 0.979933	val: 0.733192	test: 0.734290
PRC train: 0.975847	val: 0.398864	test: 0.830998

Epoch: 141
Loss: 0.2706680865071858
ROC train: 0.979289	val: 0.732241	test: 0.720567
PRC train: 0.975290	val: 0.391974	test: 0.807187

Epoch: 142
Loss: 0.24096548306564994
ROC train: 0.978713	val: 0.746089	test: 0.716504
PRC train: 0.974263	val: 0.405148	test: 0.791205

Epoch: 143
Loss: 0.25394753118530344
ROC train: 0.981106	val: 0.744926	test: 0.765078
PRC train: 0.977523	val: 0.407810	test: 0.848834

Epoch: 144
Loss: 0.26103413150249033
ROC train: 0.979660	val: 0.728964	test: 0.765529
PRC train: 0.975633	val: 0.403977	test: 0.862017

Epoch: 145
Loss: 0.2713488435859588
ROC train: 0.978595	val: 0.732875	test: 0.752167
PRC train: 0.973599	val: 0.421145	test: 0.850224

Epoch: 146
Loss: 0.2738848253735833
ROC train: 0.975551	val: 0.725159	test: 0.748465
PRC train: 0.968721	val: 0.420427	test: 0.833503

Epoch: 147
Loss: 0.23798341315021837
ROC train: 0.973928	val: 0.719450	test: 0.738443
PRC train: 0.967578	val: 0.411292	test: 0.815184

Epoch: 148
Loss: 0.2327587882850831
ROC train: 0.979642	val: 0.739323	test: 0.749549
PRC train: 0.975458	val: 0.420260	test: 0.837688

Epoch: 149
Loss: 0.2526255786265952
ROC train: 0.980548	val: 0.744926	test: 0.758938
PRC train: 0.977249	val: 0.420732	test: 0.850182

Epoch: 150
Loss: 0.25025908430768967
ROC train: 0.979980	val: 0.738584	test: 0.752347
PRC train: 0.976882	val: 0.416015	test: 0.845814

Epoch: 151
Loss: 0.2312933512841969
ROC train: 0.982222	val: 0.735307	test: 0.756862
PRC train: 0.979001	val: 0.409477	test: 0.850111

Epoch: 152
Loss: 0.2458608973304348
ROC train: 0.983420	val: 0.737421	test: 0.742055
PRC train: 0.980439	val: 0.412908	test: 0.830655

Epoch: 153
Loss: 0.2299444312093907
ROC train: 0.979264	val: 0.727801	test: 0.740159
PRC train: 0.976197	val: 0.405905	test: 0.829701

Early stopping
Best (ROC):	 train: 0.974273	val: 0.755180	test: 0.766342
Best (PRC):	 train: 0.969406	val: 0.430564	test: 0.850458
All runs completed.
