>>> Starting run for dataset: bbbp
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running RANDOM configs_static_noise_experiments/GraphCL/bbbp/noise=0.0.yml on cuda:0
Running RANDOM configs_static_noise_experiments/GraphCL/bbbp/noise=0.05.yml on cuda:1
Running RANDOM configs_static_noise_experiments/GraphCL/bbbp/noise=0.1.yml on cuda:2
Running RANDOM configs_static_noise_experiments/GraphCL/bbbp/noise=0.2.yml on cuda:3
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.05.yml --runseed 4 --device cuda:1
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.2.yml --runseed 4 --device cuda:3
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.05.yml --runseed 5 --device cuda:1
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.2.yml --runseed 5 --device cuda:3
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.05.yml --runseed 6 --device cuda:1
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.2.yml --runseed 6 --device cuda:3
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.0.yml --runseed 4 --device cuda:0
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.0.yml --runseed 5 --device cuda:0
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.0.yml --runseed 6 --device cuda:0
Starting process for seed 4: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.1.yml --runseed 4 --device cuda:2
Starting process for seed 5: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.1.yml --runseed 5 --device cuda:2
Starting process for seed 6: python molecule_finetune.py --config /workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.1.yml --runseed 6 --device cuda:2
[11:28:51] WARNING: not removing hydrogen atom without neighbors
[11:28:51] WARNING: not removing hydrogen atom without neighbors
[11:28:51] WARNING: not removing hydrogen atom without neighbors
[11:28:51] [11:28:51] WARNING: not removing hydrogen atom without neighborsWARNING: not removing hydrogen atom without neighbors

[11:28:51] WARNING: not removing hydrogen atom without neighbors
[11:28:51] WARNING: not removing hydrogen atom without neighbors
[11:28:51] WARNING: not removing hydrogen atom without neighbors
[11:28:51] WARNING: not removing hydrogen atom without neighbors
[11:28:51] WARNING: not removing hydrogen atom without neighbors
[11:28:51] WARNING: not removing hydrogen atom without neighbors
[11:28:51] WARNING: not removing hydrogen atom without neighbors
[11:28:51] WARNING: not removing hydrogen atom without neighbors
[11:28:51] WARNING: not removing hydrogen atom without neighbors
[11:28:51] WARNING: not removing hydrogen atom without neighbors
[11:28:51] WARNING: not removing hydrogen atom without neighbors
[11:28:51] WARNING: not removing hydrogen atom without neighbors
[11:28:51] WARNING: not removing hydrogen atom without neighbors
[11:28:51] WARNING: not removing hydrogen atom without neighbors
[11:28:51] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:52] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] [11:28:53] WARNING: not removing hydrogen atom without neighborsWARNING: not removing hydrogen atom without neighbors

[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:53] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
[11:28:54] WARNING: not removing hydrogen atom without neighbors
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.0.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/bbbp/noise=0.0
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/bbbp/noise=0.0/bbbp_scaff_6_26-05_11-28-51  ]
[ Using Seed :  6  ]
[ Using device :  cuda:0  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6083924856052312
ROC train: 0.804493	val: 0.866004	test: 0.630208
PRC train: 0.950682	val: 0.794615	test: 0.670434

Epoch: 2
Loss: 0.48042206062947584
ROC train: 0.841023	val: 0.878852	test: 0.630498
PRC train: 0.959587	val: 0.820337	test: 0.680301

Epoch: 3
Loss: 0.3938774765933681
ROC train: 0.868754	val: 0.909766	test: 0.635995
PRC train: 0.966543	val: 0.857463	test: 0.686753

Epoch: 4
Loss: 0.35801386731003865
ROC train: 0.890476	val: 0.907156	test: 0.648727
PRC train: 0.972087	val: 0.828273	test: 0.694694

Epoch: 5
Loss: 0.3067465358234311
ROC train: 0.909025	val: 0.910469	test: 0.654321
PRC train: 0.976645	val: 0.834954	test: 0.699706

Epoch: 6
Loss: 0.2792917188851519
ROC train: 0.919039	val: 0.917796	test: 0.659529
PRC train: 0.978942	val: 0.850949	test: 0.701839

Epoch: 7
Loss: 0.2748957980528765
ROC train: 0.932495	val: 0.925424	test: 0.673611
PRC train: 0.982330	val: 0.871848	test: 0.713850

Epoch: 8
Loss: 0.25277764060030766
ROC train: 0.939525	val: 0.905450	test: 0.671875
PRC train: 0.984498	val: 0.843990	test: 0.715319

Epoch: 9
Loss: 0.25803341476886027
ROC train: 0.942893	val: 0.907859	test: 0.692323
PRC train: 0.985424	val: 0.842647	test: 0.733832

Epoch: 10
Loss: 0.24536500674231645
ROC train: 0.950638	val: 0.897119	test: 0.703511
PRC train: 0.988235	val: 0.792411	test: 0.757588

Epoch: 11
Loss: 0.2263888915839068
ROC train: 0.951783	val: 0.877848	test: 0.696856
PRC train: 0.988571	val: 0.773290	test: 0.743887

Epoch: 12
Loss: 0.220129313194458
ROC train: 0.956713	val: 0.886179	test: 0.712770
PRC train: 0.989555	val: 0.782025	test: 0.761922

Epoch: 13
Loss: 0.21534454139802728
ROC train: 0.954598	val: 0.889090	test: 0.730035
PRC train: 0.988911	val: 0.775036	test: 0.778022

Epoch: 14
Loss: 0.2170055567883247
ROC train: 0.960740	val: 0.881060	test: 0.722222
PRC train: 0.990736	val: 0.796012	test: 0.768000

Epoch: 15
Loss: 0.2059851901396778
ROC train: 0.964717	val: 0.895413	test: 0.717785
PRC train: 0.991520	val: 0.832120	test: 0.768762

Epoch: 16
Loss: 0.19467543177223132
ROC train: 0.963877	val: 0.888889	test: 0.725405
PRC train: 0.991608	val: 0.807288	test: 0.780224

Epoch: 17
Loss: 0.19445919204702283
ROC train: 0.968353	val: 0.901536	test: 0.711034
PRC train: 0.992882	val: 0.839976	test: 0.759778

Epoch: 18
Loss: 0.19687472503211914
ROC train: 0.968768	val: 0.892000	test: 0.724344
PRC train: 0.992895	val: 0.816693	test: 0.757917

Epoch: 19
Loss: 0.19371349946448682
ROC train: 0.964115	val: 0.881662	test: 0.747878
PRC train: 0.991538	val: 0.772499	test: 0.781531

Epoch: 20
Loss: 0.18000865978906
ROC train: 0.969974	val: 0.870421	test: 0.730903
PRC train: 0.993124	val: 0.784794	test: 0.766280

Epoch: 21
Loss: 0.17442444490675516
ROC train: 0.970711	val: 0.892502	test: 0.734279
PRC train: 0.993299	val: 0.835226	test: 0.775919

Epoch: 22
Loss: 0.18210052983268418
ROC train: 0.973177	val: 0.888186	test: 0.729360
PRC train: 0.993900	val: 0.806135	test: 0.791222

Epoch: 23
Loss: 0.17918595063394946
ROC train: 0.974400	val: 0.885677	test: 0.729167
PRC train: 0.994256	val: 0.812621	test: 0.785318

Epoch: 24
Loss: 0.18758668528245698
ROC train: 0.975087	val: 0.876443	test: 0.696663
PRC train: 0.994597	val: 0.776693	test: 0.737259

Epoch: 25
Loss: 0.1832883463497081
ROC train: 0.976435	val: 0.883770	test: 0.711034
PRC train: 0.994829	val: 0.777663	test: 0.759243

Epoch: 26
Loss: 0.17204791559630359
ROC train: 0.975380	val: 0.878049	test: 0.732060
PRC train: 0.994523	val: 0.785859	test: 0.771309

Epoch: 27
Loss: 0.16300377298433627
ROC train: 0.975325	val: 0.864900	test: 0.730324
PRC train: 0.994553	val: 0.763335	test: 0.778849

Epoch: 28
Loss: 0.16729676315922062
ROC train: 0.978720	val: 0.879956	test: 0.722704
PRC train: 0.995231	val: 0.795333	test: 0.748338

Epoch: 29
Loss: 0.17120785212607328
ROC train: 0.979468	val: 0.895614	test: 0.732253
PRC train: 0.995558	val: 0.840686	test: 0.773610

Epoch: 30
Loss: 0.15149685306169905
ROC train: 0.981654	val: 0.878551	test: 0.725405
PRC train: 0.996160	val: 0.808331	test: 0.766997

Epoch: 31
Loss: 0.1485828935983742
ROC train: 0.984155	val: 0.880960	test: 0.722126
PRC train: 0.996699	val: 0.803483	test: 0.752781

Epoch: 32
Loss: 0.1486259739310331
ROC train: 0.982941	val: 0.876744	test: 0.721065
PRC train: 0.996371	val: 0.788842	test: 0.733875

Epoch: 33
Loss: 0.14747838948549122
ROC train: 0.984018	val: 0.884874	test: 0.724923Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.0.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/bbbp/noise=0.0
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/bbbp/noise=0.0/bbbp_scaff_5_26-05_11-28-51  ]
[ Using Seed :  5  ]
[ Using device :  cuda:0  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6024019779665831
ROC train: 0.799769	val: 0.877547	test: 0.615258
PRC train: 0.945619	val: 0.807616	test: 0.666628

Epoch: 2
Loss: 0.46830455532657717
ROC train: 0.843802	val: 0.890595	test: 0.635513
PRC train: 0.959879	val: 0.834304	test: 0.681053

Epoch: 3
Loss: 0.399250521338146
ROC train: 0.859935	val: 0.905249	test: 0.659240
PRC train: 0.964823	val: 0.825052	test: 0.706715

Epoch: 4
Loss: 0.34501345579004716
ROC train: 0.879445	val: 0.906956	test: 0.638889
PRC train: 0.969958	val: 0.800378	test: 0.684551

Epoch: 5
Loss: 0.3183973476239807
ROC train: 0.896214	val: 0.904547	test: 0.652199
PRC train: 0.974462	val: 0.782695	test: 0.702732

Epoch: 6
Loss: 0.29482006160924856
ROC train: 0.917527	val: 0.895012	test: 0.666184
PRC train: 0.979400	val: 0.762627	test: 0.704418

Epoch: 7
Loss: 0.2766349749150575
ROC train: 0.930856	val: 0.901536	test: 0.677180
PRC train: 0.982430	val: 0.795757	test: 0.723449

Epoch: 8
Loss: 0.2545577969032221
ROC train: 0.936527	val: 0.897220	test: 0.687596
PRC train: 0.983794	val: 0.768486	test: 0.728342

Epoch: 9
Loss: 0.23876703597284554
ROC train: 0.947000	val: 0.892502	test: 0.683835
PRC train: 0.986925	val: 0.766753	test: 0.738608

Epoch: 10
Loss: 0.241494788091349
ROC train: 0.941643	val: 0.897621	test: 0.670235
PRC train: 0.985274	val: 0.779348	test: 0.689292

Epoch: 11
Loss: 0.2363913966563169
ROC train: 0.954430	val: 0.907056	test: 0.678337
PRC train: 0.988590	val: 0.790564	test: 0.708075

Epoch: 12
Loss: 0.22639075697279806
ROC train: 0.953350	val: 0.891599	test: 0.684703
PRC train: 0.988370	val: 0.798794	test: 0.738084

Epoch: 13
Loss: 0.21379037722385252
ROC train: 0.954842	val: 0.893004	test: 0.690972
PRC train: 0.988880	val: 0.822835	test: 0.755085

Epoch: 14
Loss: 0.2026435747992164
ROC train: 0.959792	val: 0.894610	test: 0.692033
PRC train: 0.990570	val: 0.821088	test: 0.757466

Epoch: 15
Loss: 0.20648885797995092
ROC train: 0.960914	val: 0.905450	test: 0.709105
PRC train: 0.990980	val: 0.801844	test: 0.766700

Epoch: 16
Loss: 0.20409087890862923
ROC train: 0.966166	val: 0.893004	test: 0.682581
PRC train: 0.992277	val: 0.775370	test: 0.711956

Epoch: 17
Loss: 0.19121392000725684
ROC train: 0.963527	val: 0.901235	test: 0.684896
PRC train: 0.991200	val: 0.806265	test: 0.710783

Epoch: 18
Loss: 0.1904450172447057
ROC train: 0.967072	val: 0.886881	test: 0.702450
PRC train: 0.992237	val: 0.810636	test: 0.747916

Epoch: 19
Loss: 0.18284197760063142
ROC train: 0.969413	val: 0.892201	test: 0.714120
PRC train: 0.992539	val: 0.826369	test: 0.764971

Epoch: 20
Loss: 0.18831040382666414
ROC train: 0.973182	val: 0.886480	test: 0.695795
PRC train: 0.994079	val: 0.798041	test: 0.718710

Epoch: 21
Loss: 0.18680258237289135
ROC train: 0.968658	val: 0.875640	test: 0.698495
PRC train: 0.993021	val: 0.795983	test: 0.752555

Epoch: 22
Loss: 0.18091411542438848
ROC train: 0.973923	val: 0.887283	test: 0.691937
PRC train: 0.994296	val: 0.803526	test: 0.744860

Epoch: 23
Loss: 0.1732279746533874
ROC train: 0.973383	val: 0.886279	test: 0.703221
PRC train: 0.994038	val: 0.809888	test: 0.758470

Epoch: 24
Loss: 0.17775077810493972
ROC train: 0.971702	val: 0.911774	test: 0.714410
PRC train: 0.992640	val: 0.853035	test: 0.769194

Epoch: 25
Loss: 0.178478985448846
ROC train: 0.977724	val: 0.910168	test: 0.707948
PRC train: 0.994858	val: 0.857218	test: 0.750392

Epoch: 26
Loss: 0.16486505611581667
ROC train: 0.977232	val: 0.893004	test: 0.709587
PRC train: 0.995093	val: 0.803571	test: 0.742430

Epoch: 27
Loss: 0.16162097518649052
ROC train: 0.976387	val: 0.897922	test: 0.703125
PRC train: 0.995112	val: 0.793007	test: 0.716331

Epoch: 28
Loss: 0.16904362704848483
ROC train: 0.981510	val: 0.899528	test: 0.701100
PRC train: 0.996198	val: 0.811528	test: 0.728639

Epoch: 29
Loss: 0.15414293560878492
ROC train: 0.980187	val: 0.898525	test: 0.691262
PRC train: 0.995867	val: 0.812490	test: 0.725870

Epoch: 30
Loss: 0.15896829816462751
ROC train: 0.980528	val: 0.897621	test: 0.694830
PRC train: 0.995909	val: 0.797860	test: 0.724434

Epoch: 31
Loss: 0.16100329411273867
ROC train: 0.981942	val: 0.900231	test: 0.694927
PRC train: 0.996218	val: 0.796378	test: 0.721005

Epoch: 32
Loss: 0.1557324701722381
ROC train: 0.982712	val: 0.883870	test: 0.676408
PRC train: 0.996454	val: 0.789120	test: 0.693706

Epoch: 33
Loss: 0.1546147504651323
ROC train: 0.979261	val: 0.881662	test: 0.706115Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.0.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:0
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/bbbp/noise=0.0
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/bbbp/noise=0.0/bbbp_scaff_4_26-05_11-28-51  ]
[ Using Seed :  4  ]
[ Using device :  cuda:0  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6323188820999486
ROC train: 0.815842	val: 0.884573	test: 0.634066
PRC train: 0.951249	val: 0.821559	test: 0.693048

Epoch: 2
Loss: 0.5076909800632501
ROC train: 0.855768	val: 0.897722	test: 0.621431
PRC train: 0.963445	val: 0.821551	test: 0.679036

Epoch: 3
Loss: 0.41624436171939644
ROC train: 0.880090	val: 0.903543	test: 0.656539
PRC train: 0.969586	val: 0.812954	test: 0.698162

Epoch: 4
Loss: 0.36287652749189886
ROC train: 0.901622	val: 0.911673	test: 0.667535
PRC train: 0.976225	val: 0.822748	test: 0.709169

Epoch: 5
Loss: 0.3117856443765264
ROC train: 0.909629	val: 0.918398	test: 0.656539
PRC train: 0.977908	val: 0.839495	test: 0.696095

Epoch: 6
Loss: 0.3140384888133613
ROC train: 0.923407	val: 0.917394	test: 0.669464
PRC train: 0.981074	val: 0.836490	test: 0.701423

Epoch: 7
Loss: 0.2857736331430452
ROC train: 0.934451	val: 0.913681	test: 0.679688
PRC train: 0.983605	val: 0.824090	test: 0.719789

Epoch: 8
Loss: 0.26177835169684505
ROC train: 0.939427	val: 0.901736	test: 0.664062
PRC train: 0.985156	val: 0.779340	test: 0.708853

Epoch: 9
Loss: 0.24447170761511403
ROC train: 0.946750	val: 0.900532	test: 0.674286
PRC train: 0.987118	val: 0.761336	test: 0.718406

Epoch: 10
Loss: 0.23445368181044204
ROC train: 0.948485	val: 0.884673	test: 0.688368
PRC train: 0.987662	val: 0.754500	test: 0.729821

Epoch: 11
Loss: 0.23457015835013456
ROC train: 0.949290	val: 0.906554	test: 0.687789
PRC train: 0.987653	val: 0.782777	test: 0.731895

Epoch: 12
Loss: 0.22218461704870496
ROC train: 0.951456	val: 0.893707	test: 0.688368
PRC train: 0.988336	val: 0.756256	test: 0.728285

Epoch: 13
Loss: 0.21232204663034557
ROC train: 0.958565	val: 0.898826	test: 0.679302
PRC train: 0.989937	val: 0.786346	test: 0.721379

Epoch: 14
Loss: 0.21476060511071032
ROC train: 0.962922	val: 0.899026	test: 0.686439
PRC train: 0.990771	val: 0.810457	test: 0.735332

Epoch: 15
Loss: 0.20854649707892756
ROC train: 0.963340	val: 0.895313	test: 0.683256
PRC train: 0.991295	val: 0.788996	test: 0.696819

Epoch: 16
Loss: 0.20844609094554614
ROC train: 0.963974	val: 0.892703	test: 0.693673
PRC train: 0.991498	val: 0.791382	test: 0.738591

Epoch: 17
Loss: 0.2142357222478426
ROC train: 0.962992	val: 0.881763	test: 0.692805
PRC train: 0.991113	val: 0.768748	test: 0.732243

Epoch: 18
Loss: 0.19602696209043607
ROC train: 0.966163	val: 0.887584	test: 0.706790
PRC train: 0.992251	val: 0.773094	test: 0.744546

Epoch: 19
Loss: 0.19504178056454377
ROC train: 0.967921	val: 0.886480	test: 0.707176
PRC train: 0.992721	val: 0.775764	test: 0.728440

Epoch: 20
Loss: 0.19063722686556467
ROC train: 0.971434	val: 0.884071	test: 0.696084
PRC train: 0.993563	val: 0.778453	test: 0.715746

Epoch: 21
Loss: 0.18064035577054668
ROC train: 0.968348	val: 0.887785	test: 0.697917
PRC train: 0.992802	val: 0.783749	test: 0.711367

Epoch: 22
Loss: 0.1834750788871188
ROC train: 0.973726	val: 0.883469	test: 0.697434
PRC train: 0.994064	val: 0.782179	test: 0.717127

Epoch: 23
Loss: 0.16954304947337234
ROC train: 0.974567	val: 0.895614	test: 0.719618
PRC train: 0.994302	val: 0.804540	test: 0.755153

Epoch: 24
Loss: 0.18480828175502279
ROC train: 0.976650	val: 0.903443	test: 0.719232
PRC train: 0.994524	val: 0.845117	test: 0.763102

Epoch: 25
Loss: 0.1669793840308465
ROC train: 0.978257	val: 0.898424	test: 0.714988
PRC train: 0.994855	val: 0.845520	test: 0.780736

Epoch: 26
Loss: 0.16494973920459594
ROC train: 0.979874	val: 0.901937	test: 0.706501
PRC train: 0.995590	val: 0.819223	test: 0.752308

Epoch: 27
Loss: 0.17433477067659384
ROC train: 0.980203	val: 0.897822	test: 0.710455
PRC train: 0.995584	val: 0.807335	test: 0.745416

Epoch: 28
Loss: 0.16341794890139108
ROC train: 0.980954	val: 0.892101	test: 0.710841
PRC train: 0.995916	val: 0.789131	test: 0.736749

Epoch: 29
Loss: 0.16467686135233997
ROC train: 0.980510	val: 0.897420	test: 0.700521
PRC train: 0.995951	val: 0.813975	test: 0.712724

Epoch: 30
Loss: 0.16296326984012327
ROC train: 0.980932	val: 0.893907	test: 0.724633
PRC train: 0.995989	val: 0.816459	test: 0.763739

Epoch: 31
Loss: 0.15547979057510425
ROC train: 0.983547	val: 0.890696	test: 0.718171
PRC train: 0.996497	val: 0.820494	test: 0.752686

Epoch: 32
Loss: 0.15667884755879774
ROC train: 0.982567	val: 0.894409	test: 0.687404
PRC train: 0.996428	val: 0.806941	test: 0.701063

Epoch: 33
Loss: 0.16167905126714865Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.05.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.05
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/bbbp/noise=0.05
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/bbbp/noise=0.05/bbbp_scaff_5_26-05_11-28-51  ]
[ Using Seed :  5  ]
[ Using device :  cuda:1  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6142404370443656
ROC train: 0.757187	val: 0.866506	test: 0.640143
PRC train: 0.937493	val: 0.804244	test: 0.665153

Epoch: 2
Loss: 0.5101120593887599
ROC train: 0.815219	val: 0.867711	test: 0.633488
PRC train: 0.954432	val: 0.803055	test: 0.672784

Epoch: 3
Loss: 0.4330065506492288
ROC train: 0.844227	val: 0.881763	test: 0.649595
PRC train: 0.963093	val: 0.819695	test: 0.688518

Epoch: 4
Loss: 0.3850180534541879
ROC train: 0.870718	val: 0.882565	test: 0.659722
PRC train: 0.969712	val: 0.808150	test: 0.699942

Epoch: 5
Loss: 0.3494623077376503
ROC train: 0.898308	val: 0.878952	test: 0.649691
PRC train: 0.976206	val: 0.808461	test: 0.709131

Epoch: 6
Loss: 0.32611879094184804
ROC train: 0.907656	val: 0.874034	test: 0.648052
PRC train: 0.978154	val: 0.787676	test: 0.720509

Epoch: 7
Loss: 0.30911979209058355
ROC train: 0.926682	val: 0.860383	test: 0.652778
PRC train: 0.983126	val: 0.766991	test: 0.716587

Epoch: 8
Loss: 0.2964099875025066
ROC train: 0.932601	val: 0.831175	test: 0.634645
PRC train: 0.984800	val: 0.721566	test: 0.696020

Epoch: 9
Loss: 0.2713155033201288
ROC train: 0.939351	val: 0.846231	test: 0.646798
PRC train: 0.986014	val: 0.734760	test: 0.707629

Epoch: 10
Loss: 0.2741201325761655
ROC train: 0.953855	val: 0.880056	test: 0.684896
PRC train: 0.989329	val: 0.806136	test: 0.747671

Epoch: 11
Loss: 0.24716516106396688
ROC train: 0.960688	val: 0.863997	test: 0.665220
PRC train: 0.991529	val: 0.790927	test: 0.724145

Epoch: 12
Loss: 0.2177996340987636
ROC train: 0.961409	val: 0.868614	test: 0.680941
PRC train: 0.991231	val: 0.786478	test: 0.727953

Epoch: 13
Loss: 0.22727784269775206
ROC train: 0.967884	val: 0.861789	test: 0.679688
PRC train: 0.992833	val: 0.789791	test: 0.734977

Epoch: 14
Loss: 0.23503300427188417
ROC train: 0.972592	val: 0.848540	test: 0.691358
PRC train: 0.994134	val: 0.783825	test: 0.746011

Epoch: 15
Loss: 0.21562265400839326
ROC train: 0.969624	val: 0.871926	test: 0.693576
PRC train: 0.993207	val: 0.806341	test: 0.750119

Epoch: 16
Loss: 0.22355051670135295
ROC train: 0.978690	val: 0.862692	test: 0.695988
PRC train: 0.995486	val: 0.784163	test: 0.752182

Epoch: 17
Loss: 0.20457125524889438
ROC train: 0.981577	val: 0.857874	test: 0.699942
PRC train: 0.996164	val: 0.771888	test: 0.756253

Epoch: 18
Loss: 0.20346271229922516
ROC train: 0.986248	val: 0.857071	test: 0.689911
PRC train: 0.997204	val: 0.751816	test: 0.742302

Epoch: 19
Loss: 0.17438886985770802
ROC train: 0.985059	val: 0.850748	test: 0.702064
PRC train: 0.996905	val: 0.729822	test: 0.751107

Epoch: 20
Loss: 0.18485453763868756
ROC train: 0.986080	val: 0.832480	test: 0.693383
PRC train: 0.997177	val: 0.736904	test: 0.747026

Epoch: 21
Loss: 0.18025256897270753
ROC train: 0.986069	val: 0.857573	test: 0.699074
PRC train: 0.997075	val: 0.765090	test: 0.751559

Epoch: 22
Loss: 0.16452911539766277
ROC train: 0.989126	val: 0.851551	test: 0.709587
PRC train: 0.997787	val: 0.769997	test: 0.766605

Epoch: 23
Loss: 0.15824999170278847
ROC train: 0.990481	val: 0.851149	test: 0.708140
PRC train: 0.998052	val: 0.758460	test: 0.762544

Epoch: 24
Loss: 0.155975902527725
ROC train: 0.992257	val: 0.864298	test: 0.714988
PRC train: 0.998445	val: 0.784651	test: 0.767261

Epoch: 25
Loss: 0.1371770536944116
ROC train: 0.992734	val: 0.873733	test: 0.722029
PRC train: 0.998503	val: 0.787589	test: 0.757953

Epoch: 26
Loss: 0.1458922053892096
ROC train: 0.993607	val: 0.859380	test: 0.714024
PRC train: 0.998716	val: 0.750823	test: 0.738433

Epoch: 27
Loss: 0.14478812174659872
ROC train: 0.994493	val: 0.843923	test: 0.707562
PRC train: 0.998916	val: 0.717152	test: 0.728283

Epoch: 28
Loss: 0.1326120889013392
ROC train: 0.993503	val: 0.819231	test: 0.688947
PRC train: 0.998722	val: 0.719146	test: 0.728979

Epoch: 29
Loss: 0.12362003870291054
ROC train: 0.996962	val: 0.873331	test: 0.708430
PRC train: 0.999408	val: 0.782029	test: 0.745658

Epoch: 30
Loss: 0.12059910946555838
ROC train: 0.997470	val: 0.845729	test: 0.701100
PRC train: 0.999507	val: 0.736865	test: 0.747878

Epoch: 31
Loss: 0.1185865262611738
ROC train: 0.998482	val: 0.855766	test: 0.713445
PRC train: 0.999709	val: 0.752005	test: 0.748550

Epoch: 32
Loss: 0.09916964117332623
ROC train: 0.997478	val: 0.866205	test: 0.701100Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.05.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.05
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/bbbp/noise=0.05
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/bbbp/noise=0.05/bbbp_scaff_4_26-05_11-28-51  ]
[ Using Seed :  4  ]
[ Using device :  cuda:1  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.665176209653413
ROC train: 0.732466	val: 0.859380	test: 0.601562
PRC train: 0.926360	val: 0.785093	test: 0.628929

Epoch: 2
Loss: 0.5474609689526678
ROC train: 0.779880	val: 0.889491	test: 0.624807
PRC train: 0.943864	val: 0.822405	test: 0.666907

Epoch: 3
Loss: 0.4694123762231231
ROC train: 0.832517	val: 0.898926	test: 0.667438
PRC train: 0.958559	val: 0.830110	test: 0.711007

Epoch: 4
Loss: 0.40190425312177197
ROC train: 0.862386	val: 0.901837	test: 0.654417
PRC train: 0.968116	val: 0.830134	test: 0.708648

Epoch: 5
Loss: 0.36891955400996823
ROC train: 0.882077	val: 0.885376	test: 0.643326
PRC train: 0.972668	val: 0.786317	test: 0.690362

Epoch: 6
Loss: 0.31546494592589946
ROC train: 0.906323	val: 0.890595	test: 0.649306
PRC train: 0.978338	val: 0.798626	test: 0.697863

Epoch: 7
Loss: 0.2970314341722301
ROC train: 0.915070	val: 0.907257	test: 0.657986
PRC train: 0.980196	val: 0.829281	test: 0.700846

Epoch: 8
Loss: 0.27806683729133547
ROC train: 0.931987	val: 0.901335	test: 0.663773
PRC train: 0.984864	val: 0.817848	test: 0.706496

Epoch: 9
Loss: 0.269010239590037
ROC train: 0.948255	val: 0.903142	test: 0.658083
PRC train: 0.989124	val: 0.800011	test: 0.685812

Epoch: 10
Loss: 0.2489472448373729
ROC train: 0.956219	val: 0.884272	test: 0.659433
PRC train: 0.990647	val: 0.782973	test: 0.712997

Epoch: 11
Loss: 0.2454791025193956
ROC train: 0.953148	val: 0.853458	test: 0.647377
PRC train: 0.989734	val: 0.732581	test: 0.691545

Epoch: 12
Loss: 0.24262811113777932
ROC train: 0.957429	val: 0.882666	test: 0.654321
PRC train: 0.990139	val: 0.770863	test: 0.692382

Epoch: 13
Loss: 0.2135595356214893
ROC train: 0.964321	val: 0.884673	test: 0.655575
PRC train: 0.991735	val: 0.775111	test: 0.700019

Epoch: 14
Loss: 0.21694936236612244
ROC train: 0.973658	val: 0.884573	test: 0.656732
PRC train: 0.994166	val: 0.773829	test: 0.715350

Epoch: 15
Loss: 0.20237284539565503
ROC train: 0.975787	val: 0.900331	test: 0.664545
PRC train: 0.995073	val: 0.784964	test: 0.715338

Epoch: 16
Loss: 0.19545839283801417
ROC train: 0.971974	val: 0.882967	test: 0.654032
PRC train: 0.994424	val: 0.756376	test: 0.712768

Epoch: 17
Loss: 0.1870942786236461
ROC train: 0.984551	val: 0.895012	test: 0.673611
PRC train: 0.996975	val: 0.792964	test: 0.716021

Epoch: 18
Loss: 0.1787263149754565
ROC train: 0.984643	val: 0.893907	test: 0.673900
PRC train: 0.996984	val: 0.808564	test: 0.715044

Epoch: 19
Loss: 0.18863754197012048
ROC train: 0.979521	val: 0.883268	test: 0.666088
PRC train: 0.995959	val: 0.767450	test: 0.699488

Epoch: 20
Loss: 0.16806661240338655
ROC train: 0.987729	val: 0.883569	test: 0.647569
PRC train: 0.997614	val: 0.743309	test: 0.693671

Epoch: 21
Loss: 0.17727841885197995
ROC train: 0.988933	val: 0.896116	test: 0.655382
PRC train: 0.997808	val: 0.786218	test: 0.711029

Epoch: 22
Loss: 0.17954848454622993
ROC train: 0.988624	val: 0.907658	test: 0.669078
PRC train: 0.997796	val: 0.790115	test: 0.725189

Epoch: 23
Loss: 0.16419664119928598
ROC train: 0.987390	val: 0.876945	test: 0.651235
PRC train: 0.997555	val: 0.754203	test: 0.709256

Epoch: 24
Loss: 0.16222785590319977
ROC train: 0.988226	val: 0.902539	test: 0.666860
PRC train: 0.997671	val: 0.820547	test: 0.710263

Epoch: 25
Loss: 0.15751980358627238
ROC train: 0.989572	val: 0.904446	test: 0.668596
PRC train: 0.997984	val: 0.827489	test: 0.728793

Epoch: 26
Loss: 0.1399541015796081
ROC train: 0.991071	val: 0.885476	test: 0.667728
PRC train: 0.998299	val: 0.777973	test: 0.731755

Epoch: 27
Loss: 0.14426428723633777
ROC train: 0.989682	val: 0.893004	test: 0.672261
PRC train: 0.998018	val: 0.786172	test: 0.717548

Epoch: 28
Loss: 0.14170251054199848
ROC train: 0.993867	val: 0.895313	test: 0.669657
PRC train: 0.998830	val: 0.782087	test: 0.719882

Epoch: 29
Loss: 0.12613889145460747
ROC train: 0.993929	val: 0.891699	test: 0.655285
PRC train: 0.998830	val: 0.777910	test: 0.691105

Epoch: 30
Loss: 0.12109659487302094
ROC train: 0.992748	val: 0.859279	test: 0.637249
PRC train: 0.998589	val: 0.735242	test: 0.645152

Epoch: 31
Loss: 0.1181472375368497
ROC train: 0.996505	val: 0.878551	test: 0.652585
PRC train: 0.999328	val: 0.757232	test: 0.699343

Epoch: 32
Loss: 0.11300935586643257
ROC train: 0.997049	val: 0.888086	test: 0.655478Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.1.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.1
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/bbbp/noise=0.1
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/bbbp/noise=0.1/bbbp_scaff_5_26-05_11-28-51  ]
[ Using Seed :  5  ]
[ Using device :  cuda:2  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6187995182332715
ROC train: 0.720266	val: 0.861889	test: 0.605228
PRC train: 0.920994	val: 0.791079	test: 0.627857

Epoch: 2
Loss: 0.5201307903745348
ROC train: 0.783325	val: 0.879454	test: 0.610629
PRC train: 0.944657	val: 0.820844	test: 0.656724

Epoch: 3
Loss: 0.45464555571809834
ROC train: 0.822822	val: 0.894710	test: 0.636478
PRC train: 0.956160	val: 0.843708	test: 0.676569

Epoch: 4
Loss: 0.39960697291592256
ROC train: 0.843567	val: 0.900130	test: 0.656346
PRC train: 0.961768	val: 0.848667	test: 0.703727

Epoch: 5
Loss: 0.3703054500976309
ROC train: 0.870244	val: 0.899629	test: 0.649788
PRC train: 0.967234	val: 0.841477	test: 0.707357

Epoch: 6
Loss: 0.3434924943273069
ROC train: 0.893814	val: 0.892302	test: 0.648630
PRC train: 0.973395	val: 0.817708	test: 0.720694

Epoch: 7
Loss: 0.31553366190673077
ROC train: 0.903173	val: 0.900130	test: 0.660012
PRC train: 0.976731	val: 0.830267	test: 0.731116

Epoch: 8
Loss: 0.317139693534744
ROC train: 0.919520	val: 0.885075	test: 0.653164
PRC train: 0.980752	val: 0.826954	test: 0.717575

Epoch: 9
Loss: 0.29053083169375665
ROC train: 0.929807	val: 0.882164	test: 0.656925
PRC train: 0.983730	val: 0.813966	test: 0.722363

Epoch: 10
Loss: 0.30156902808626807
ROC train: 0.928876	val: 0.898223	test: 0.677951
PRC train: 0.983863	val: 0.835203	test: 0.747848

Epoch: 11
Loss: 0.27649107657117133
ROC train: 0.934927	val: 0.877145	test: 0.645255
PRC train: 0.985458	val: 0.810845	test: 0.721811

Epoch: 12
Loss: 0.24353150708765975
ROC train: 0.951448	val: 0.897119	test: 0.654514
PRC train: 0.989209	val: 0.825251	test: 0.716745

Epoch: 13
Loss: 0.2537336719118525
ROC train: 0.959193	val: 0.890796	test: 0.636285
PRC train: 0.991149	val: 0.829448	test: 0.687355

Epoch: 14
Loss: 0.2520580566333425
ROC train: 0.954747	val: 0.847436	test: 0.641975
PRC train: 0.990495	val: 0.742636	test: 0.691865

Epoch: 15
Loss: 0.23787226921105664
ROC train: 0.971666	val: 0.864800	test: 0.656829
PRC train: 0.994204	val: 0.781380	test: 0.710388

Epoch: 16
Loss: 0.219160453565578
ROC train: 0.978270	val: 0.871725	test: 0.653260
PRC train: 0.995600	val: 0.805291	test: 0.711089

Epoch: 17
Loss: 0.23069319914954342
ROC train: 0.978191	val: 0.882666	test: 0.660301
PRC train: 0.995542	val: 0.820601	test: 0.711105

Epoch: 18
Loss: 0.2055587909326469
ROC train: 0.980693	val: 0.881562	test: 0.668789
PRC train: 0.996044	val: 0.797522	test: 0.716656

Epoch: 19
Loss: 0.19617110374129848
ROC train: 0.983939	val: 0.870521	test: 0.666088
PRC train: 0.996771	val: 0.773570	test: 0.711578

Epoch: 20
Loss: 0.20170124167430137
ROC train: 0.987822	val: 0.881361	test: 0.663773
PRC train: 0.997540	val: 0.806387	test: 0.716150

Epoch: 21
Loss: 0.19288719232260557
ROC train: 0.988686	val: 0.877145	test: 0.652392
PRC train: 0.997752	val: 0.810567	test: 0.722457

Epoch: 22
Loss: 0.16785682559281573
ROC train: 0.989847	val: 0.874134	test: 0.660783
PRC train: 0.998010	val: 0.783259	test: 0.727964

Epoch: 23
Loss: 0.19073071346884923
ROC train: 0.992246	val: 0.894610	test: 0.656732
PRC train: 0.998466	val: 0.841314	test: 0.717919

Epoch: 24
Loss: 0.15807113817661783
ROC train: 0.994300	val: 0.859781	test: 0.646123
PRC train: 0.998905	val: 0.788110	test: 0.721636

Epoch: 25
Loss: 0.15042173573667456
ROC train: 0.992336	val: 0.900432	test: 0.648341
PRC train: 0.998494	val: 0.832180	test: 0.735760

Epoch: 26
Loss: 0.15167552056821534
ROC train: 0.995952	val: 0.882465	test: 0.629630
PRC train: 0.999229	val: 0.789173	test: 0.708297

Epoch: 27
Loss: 0.1634302020538792
ROC train: 0.996673	val: 0.874335	test: 0.644579
PRC train: 0.999339	val: 0.782857	test: 0.701458

Epoch: 28
Loss: 0.13658493913717845
ROC train: 0.996336	val: 0.848238	test: 0.649595
PRC train: 0.999297	val: 0.725414	test: 0.717592

Epoch: 29
Loss: 0.12130743724275452
ROC train: 0.996712	val: 0.865101	test: 0.658179
PRC train: 0.999369	val: 0.767715	test: 0.733536

Epoch: 30
Loss: 0.13055391981566525
ROC train: 0.997495	val: 0.865402	test: 0.644483
PRC train: 0.999523	val: 0.786537	test: 0.714298

Epoch: 31
Loss: 0.11706275072552018
ROC train: 0.998494	val: 0.872026	test: 0.656443
PRC train: 0.999714	val: 0.761248	test: 0.704030

Epoch: 32
Loss: 0.11430022375296471
ROC train: 0.999133	val: 0.876443	test: 0.654803Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.1.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.1
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/bbbp/noise=0.1
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/bbbp/noise=0.1/bbbp_scaff_6_26-05_11-28-51  ]
[ Using Seed :  6  ]
[ Using device :  cuda:2  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6234727196695434
ROC train: 0.721377	val: 0.853859	test: 0.633198
PRC train: 0.920426	val: 0.772295	test: 0.686353

Epoch: 2
Loss: 0.5381539959034198
ROC train: 0.775206	val: 0.869216	test: 0.623360
PRC train: 0.937779	val: 0.786471	test: 0.675660

Epoch: 3
Loss: 0.4619153640717183
ROC train: 0.787401	val: 0.874435	test: 0.656346
PRC train: 0.942511	val: 0.785655	test: 0.691668

Epoch: 4
Loss: 0.41054531573441555
ROC train: 0.839039	val: 0.874636	test: 0.669657
PRC train: 0.956854	val: 0.787492	test: 0.712985

Epoch: 5
Loss: 0.3728353057850095
ROC train: 0.857103	val: 0.891599	test: 0.683835
PRC train: 0.963499	val: 0.813431	test: 0.735387

Epoch: 6
Loss: 0.35445375783132693
ROC train: 0.862986	val: 0.898826	test: 0.676698
PRC train: 0.964696	val: 0.825177	test: 0.727845

Epoch: 7
Loss: 0.33673217463514604
ROC train: 0.886052	val: 0.888287	test: 0.671779
PRC train: 0.971560	val: 0.812638	test: 0.727320

Epoch: 8
Loss: 0.30666220327911436
ROC train: 0.904107	val: 0.876543	test: 0.660880
PRC train: 0.976486	val: 0.795753	test: 0.717756

Epoch: 9
Loss: 0.30261637933992064
ROC train: 0.914052	val: 0.885878	test: 0.686728
PRC train: 0.979380	val: 0.806493	test: 0.752227

Epoch: 10
Loss: 0.2679699658973042
ROC train: 0.926777	val: 0.890495	test: 0.692998
PRC train: 0.983102	val: 0.810291	test: 0.751923

Epoch: 11
Loss: 0.27371180977060766
ROC train: 0.943236	val: 0.877246	test: 0.699460
PRC train: 0.987281	val: 0.769375	test: 0.755295

Epoch: 12
Loss: 0.25216477919103686
ROC train: 0.939774	val: 0.881763	test: 0.686921
PRC train: 0.986412	val: 0.765351	test: 0.754679

Epoch: 13
Loss: 0.2525937381725681
ROC train: 0.959889	val: 0.865502	test: 0.686150
PRC train: 0.991603	val: 0.752307	test: 0.754740

Epoch: 14
Loss: 0.23650069916275854
ROC train: 0.958528	val: 0.873231	test: 0.688947
PRC train: 0.991428	val: 0.725690	test: 0.755933

Epoch: 15
Loss: 0.212706256616169
ROC train: 0.973088	val: 0.868313	test: 0.702257
PRC train: 0.994674	val: 0.748858	test: 0.775502

Epoch: 16
Loss: 0.21702053703873972
ROC train: 0.971512	val: 0.872026	test: 0.703029
PRC train: 0.994044	val: 0.746663	test: 0.778736

Epoch: 17
Loss: 0.1938751277328677
ROC train: 0.975058	val: 0.871826	test: 0.698206
PRC train: 0.994997	val: 0.728387	test: 0.757573

Epoch: 18
Loss: 0.19489970103206436
ROC train: 0.981546	val: 0.846733	test: 0.686150
PRC train: 0.996318	val: 0.688435	test: 0.755483

Epoch: 19
Loss: 0.1836092244857818
ROC train: 0.985754	val: 0.862190	test: 0.670139
PRC train: 0.997108	val: 0.751598	test: 0.746163

Epoch: 20
Loss: 0.19297730429838736
ROC train: 0.979947	val: 0.880157	test: 0.674961
PRC train: 0.995957	val: 0.761490	test: 0.744238

Epoch: 21
Loss: 0.1841335452804735
ROC train: 0.990061	val: 0.851751	test: 0.673418
PRC train: 0.998087	val: 0.700363	test: 0.731650

Epoch: 22
Loss: 0.169281649933545
ROC train: 0.990453	val: 0.856670	test: 0.688272
PRC train: 0.998170	val: 0.745058	test: 0.742025

Epoch: 23
Loss: 0.17340731787386066
ROC train: 0.992041	val: 0.863194	test: 0.691744
PRC train: 0.998479	val: 0.743538	test: 0.754831

Epoch: 24
Loss: 0.16789224769002734
ROC train: 0.991545	val: 0.847737	test: 0.673900
PRC train: 0.998326	val: 0.716407	test: 0.737961

Epoch: 25
Loss: 0.15960670754603976
ROC train: 0.991963	val: 0.851049	test: 0.682099
PRC train: 0.998358	val: 0.714639	test: 0.744794

Epoch: 26
Loss: 0.13910693060993695
ROC train: 0.996134	val: 0.854160	test: 0.686825
PRC train: 0.999257	val: 0.739090	test: 0.755226

Epoch: 27
Loss: 0.13672554445310917
ROC train: 0.995063	val: 0.838703	test: 0.689043
PRC train: 0.998986	val: 0.695405	test: 0.740610

Epoch: 28
Loss: 0.1395702278199871
ROC train: 0.998056	val: 0.865302	test: 0.702932
PRC train: 0.999634	val: 0.754266	test: 0.760033

Epoch: 29
Loss: 0.11453167465234422
ROC train: 0.997935	val: 0.876744	test: 0.707851
PRC train: 0.999605	val: 0.787923	test: 0.754128

Epoch: 30
Loss: 0.12397473049711236
ROC train: 0.998721	val: 0.850246	test: 0.699267
PRC train: 0.999757	val: 0.722445	test: 0.743177

Epoch: 31
Loss: 0.1054146718518781
ROC train: 0.998923	val: 0.859279	test: 0.702450
PRC train: 0.999796	val: 0.735168	test: 0.757632

Epoch: 32
Loss: 0.13136412192930783
ROC train: 0.999150	val: 0.886781	test: 0.707272Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.05.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:1
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.05
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/bbbp/noise=0.05
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/bbbp/noise=0.05/bbbp_scaff_6_26-05_11-28-51  ]
[ Using Seed :  6  ]
[ Using device :  cuda:1  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.617768632492212
ROC train: 0.762633	val: 0.877748	test: 0.630498
PRC train: 0.937561	val: 0.807886	test: 0.675752

Epoch: 2
Loss: 0.5161042799335621
ROC train: 0.802777	val: 0.880759	test: 0.610822
PRC train: 0.950077	val: 0.803389	test: 0.670098

Epoch: 3
Loss: 0.4383786828850676
ROC train: 0.840498	val: 0.900733	test: 0.650559
PRC train: 0.962108	val: 0.808859	test: 0.701754

Epoch: 4
Loss: 0.37931511065380635
ROC train: 0.874993	val: 0.899829	test: 0.658565
PRC train: 0.969887	val: 0.813551	test: 0.708156

Epoch: 5
Loss: 0.3424481715171762
ROC train: 0.883965	val: 0.915889	test: 0.661651
PRC train: 0.972593	val: 0.838160	test: 0.711670

Epoch: 6
Loss: 0.31682214660251157
ROC train: 0.892858	val: 0.914082	test: 0.660976
PRC train: 0.974734	val: 0.830342	test: 0.708242

Epoch: 7
Loss: 0.3020414939921749
ROC train: 0.917682	val: 0.886279	test: 0.660494
PRC train: 0.980708	val: 0.748837	test: 0.716567

Epoch: 8
Loss: 0.2805232397332485
ROC train: 0.934385	val: 0.886179	test: 0.665509
PRC train: 0.985100	val: 0.769513	test: 0.721187

Epoch: 9
Loss: 0.28823043323526065
ROC train: 0.944779	val: 0.890595	test: 0.674093
PRC train: 0.988107	val: 0.797165	test: 0.733936

Epoch: 10
Loss: 0.24153417225596183
ROC train: 0.939185	val: 0.900833	test: 0.693962
PRC train: 0.986917	val: 0.795227	test: 0.754721

Epoch: 11
Loss: 0.24404725610537653
ROC train: 0.954671	val: 0.882264	test: 0.688465
PRC train: 0.990615	val: 0.758916	test: 0.748810

Epoch: 12
Loss: 0.22270574822799225
ROC train: 0.955229	val: 0.873131	test: 0.685378
PRC train: 0.990423	val: 0.755473	test: 0.746761

Epoch: 13
Loss: 0.21939149864748964
ROC train: 0.963693	val: 0.874134	test: 0.679302
PRC train: 0.992327	val: 0.763659	test: 0.739844

Epoch: 14
Loss: 0.22002942803838246
ROC train: 0.967110	val: 0.873131	test: 0.688079
PRC train: 0.993026	val: 0.736100	test: 0.748146

Epoch: 15
Loss: 0.19471684255899632
ROC train: 0.976441	val: 0.862792	test: 0.673418
PRC train: 0.995208	val: 0.728873	test: 0.727718

Epoch: 16
Loss: 0.2007683086126348
ROC train: 0.972852	val: 0.877948	test: 0.672936
PRC train: 0.994432	val: 0.752619	test: 0.724986

Epoch: 17
Loss: 0.18713799410391485
ROC train: 0.969943	val: 0.875138	test: 0.676215
PRC train: 0.993687	val: 0.753838	test: 0.730151

Epoch: 18
Loss: 0.18359001660622884
ROC train: 0.980326	val: 0.877748	test: 0.695505
PRC train: 0.996090	val: 0.757899	test: 0.755289

Epoch: 19
Loss: 0.17419716994227316
ROC train: 0.983956	val: 0.884573	test: 0.695312
PRC train: 0.996841	val: 0.769783	test: 0.749406

Epoch: 20
Loss: 0.17860728834599146
ROC train: 0.984402	val: 0.890093	test: 0.696277
PRC train: 0.996902	val: 0.762531	test: 0.734203

Epoch: 21
Loss: 0.1804335711673457
ROC train: 0.988938	val: 0.883469	test: 0.697724
PRC train: 0.997835	val: 0.768450	test: 0.733780

Epoch: 22
Loss: 0.1646541110882334
ROC train: 0.988243	val: 0.888688	test: 0.704186
PRC train: 0.997699	val: 0.796180	test: 0.742088

Epoch: 23
Loss: 0.1754932917914484
ROC train: 0.990566	val: 0.882064	test: 0.693480
PRC train: 0.998131	val: 0.782748	test: 0.727331

Epoch: 24
Loss: 0.15019537028702187
ROC train: 0.990378	val: 0.880458	test: 0.696084
PRC train: 0.998110	val: 0.775673	test: 0.720715

Epoch: 25
Loss: 0.16316941673110835
ROC train: 0.988770	val: 0.889491	test: 0.713831
PRC train: 0.997779	val: 0.785010	test: 0.753105

Epoch: 26
Loss: 0.14239821689410437
ROC train: 0.990128	val: 0.886681	test: 0.712095
PRC train: 0.998044	val: 0.794665	test: 0.749331

Epoch: 27
Loss: 0.14565730737916008
ROC train: 0.993421	val: 0.880257	test: 0.680845
PRC train: 0.998714	val: 0.763150	test: 0.666681

Epoch: 28
Loss: 0.13221336379244142
ROC train: 0.994493	val: 0.880759	test: 0.695216
PRC train: 0.998934	val: 0.753321	test: 0.690673

Epoch: 29
Loss: 0.11753089163544461
ROC train: 0.994992	val: 0.884071	test: 0.700328
PRC train: 0.999030	val: 0.779054	test: 0.703175

Epoch: 30
Loss: 0.1185132109909592
ROC train: 0.995758	val: 0.893506	test: 0.712770
PRC train: 0.999172	val: 0.797998	test: 0.752796

Epoch: 31
Loss: 0.12628434504008038
ROC train: 0.995152	val: 0.894911	test: 0.699653
PRC train: 0.999034	val: 0.816478	test: 0.716596

Epoch: 32
Loss: 0.12657080905466708
ROC train: 0.995845	val: 0.901235	test: 0.705247Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.2.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 5
  multiple_seeds: [4, 5, 6]
  device: cuda:3
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.2
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/bbbp/noise=0.2
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/bbbp/noise=0.2/bbbp_scaff_5_26-05_11-28-51  ]
[ Using Seed :  5  ]
[ Using device :  cuda:3  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6316733187175829
ROC train: 0.665404	val: 0.828967	test: 0.589892
PRC train: 0.901108	val: 0.750431	test: 0.595088

Epoch: 2
Loss: 0.5495341148596341
ROC train: 0.723854	val: 0.874134	test: 0.623167
PRC train: 0.923434	val: 0.785888	test: 0.666447

Epoch: 3
Loss: 0.48371811782454766
ROC train: 0.769750	val: 0.870822	test: 0.624228
PRC train: 0.940457	val: 0.802815	test: 0.647940

Epoch: 4
Loss: 0.4332026216718881
ROC train: 0.803347	val: 0.876844	test: 0.643615
PRC train: 0.950678	val: 0.819239	test: 0.678657

Epoch: 5
Loss: 0.40809876527966055
ROC train: 0.830982	val: 0.879755	test: 0.647569
PRC train: 0.958281	val: 0.824359	test: 0.694032

Epoch: 6
Loss: 0.37235663253623114
ROC train: 0.855602	val: 0.879956	test: 0.649595
PRC train: 0.965853	val: 0.823312	test: 0.702865

Epoch: 7
Loss: 0.35264347421735553
ROC train: 0.864220	val: 0.879554	test: 0.660687
PRC train: 0.968141	val: 0.816595	test: 0.710037

Epoch: 8
Loss: 0.34442062138783136
ROC train: 0.883605	val: 0.870621	test: 0.641879
PRC train: 0.973085	val: 0.809648	test: 0.692902

Epoch: 9
Loss: 0.3255222777998991
ROC train: 0.900067	val: 0.871826	test: 0.622589
PRC train: 0.977340	val: 0.811721	test: 0.678140

Epoch: 10
Loss: 0.3358123458303917
ROC train: 0.907199	val: 0.873331	test: 0.638600
PRC train: 0.979319	val: 0.796390	test: 0.687497

Epoch: 11
Loss: 0.30303088949273743
ROC train: 0.927512	val: 0.846733	test: 0.631848
PRC train: 0.983666	val: 0.760252	test: 0.681224

Epoch: 12
Loss: 0.28472058707424014
ROC train: 0.931039	val: 0.871424	test: 0.656346
PRC train: 0.984685	val: 0.787874	test: 0.707766

Epoch: 13
Loss: 0.2788051846904759
ROC train: 0.941662	val: 0.869517	test: 0.663387
PRC train: 0.987030	val: 0.777578	test: 0.719229

Epoch: 14
Loss: 0.28881335012804854
ROC train: 0.960012	val: 0.853859	test: 0.635995
PRC train: 0.991433	val: 0.750046	test: 0.695783

Epoch: 15
Loss: 0.26023609643139406
ROC train: 0.965985	val: 0.847235	test: 0.627990
PRC train: 0.992966	val: 0.737175	test: 0.689522

Epoch: 16
Loss: 0.24986576916048162
ROC train: 0.970849	val: 0.814714	test: 0.603202
PRC train: 0.993962	val: 0.696903	test: 0.642202

Epoch: 17
Loss: 0.24068444911367354
ROC train: 0.981266	val: 0.834588	test: 0.608989
PRC train: 0.996286	val: 0.730407	test: 0.663338

Epoch: 18
Loss: 0.23036918359808456
ROC train: 0.981078	val: 0.831677	test: 0.600116
PRC train: 0.996256	val: 0.723197	test: 0.672572

Epoch: 19
Loss: 0.21614162339904813
ROC train: 0.985193	val: 0.848238	test: 0.604745
PRC train: 0.997059	val: 0.739695	test: 0.658715

Epoch: 20
Loss: 0.2211753930718665
ROC train: 0.981695	val: 0.815417	test: 0.606964
PRC train: 0.996306	val: 0.695129	test: 0.668468

Epoch: 21
Loss: 0.2119359147203283
ROC train: 0.988389	val: 0.839406	test: 0.638214
PRC train: 0.997688	val: 0.744507	test: 0.712730

Epoch: 22
Loss: 0.211001698726411
ROC train: 0.991343	val: 0.810700	test: 0.629823
PRC train: 0.998311	val: 0.707382	test: 0.693725

Epoch: 23
Loss: 0.17915081407406053
ROC train: 0.991721	val: 0.832279	test: 0.630112
PRC train: 0.998356	val: 0.723647	test: 0.692880

Epoch: 24
Loss: 0.18544159819729097
ROC train: 0.993710	val: 0.840309	test: 0.634742
PRC train: 0.998768	val: 0.710064	test: 0.697672

Epoch: 25
Loss: 0.16640304775081521
ROC train: 0.995646	val: 0.871123	test: 0.643711
PRC train: 0.999149	val: 0.769255	test: 0.726114

Epoch: 26
Loss: 0.1406795590844915
ROC train: 0.996740	val: 0.863194	test: 0.634645
PRC train: 0.999343	val: 0.759927	test: 0.707680

Epoch: 27
Loss: 0.165065142564998
ROC train: 0.997413	val: 0.849543	test: 0.647762
PRC train: 0.999492	val: 0.733220	test: 0.703125

Epoch: 28
Loss: 0.15514406884440546
ROC train: 0.997374	val: 0.841815	test: 0.636381
PRC train: 0.999490	val: 0.723523	test: 0.713797

Epoch: 29
Loss: 0.1566624090138959
ROC train: 0.997672	val: 0.851952	test: 0.646026
PRC train: 0.999537	val: 0.745948	test: 0.722148

Epoch: 30
Loss: 0.1499954762279895
ROC train: 0.998188	val: 0.821038	test: 0.625386
PRC train: 0.999643	val: 0.721495	test: 0.700283

Epoch: 31
Loss: 0.13461889600810112
ROC train: 0.998440	val: 0.793335	test: 0.617766
PRC train: 0.999705	val: 0.682448	test: 0.665491

Epoch: 32
Loss: 0.1286988002776008
ROC train: 0.998928	val: 0.832781	test: 0.617188Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.2.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 6
  multiple_seeds: [4, 5, 6]
  device: cuda:3
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.2
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/bbbp/noise=0.2
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/bbbp/noise=0.2/bbbp_scaff_6_26-05_11-28-51  ]
[ Using Seed :  6  ]
[ Using device :  cuda:3  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6311527067693335
ROC train: 0.667275	val: 0.850848	test: 0.600116
PRC train: 0.896684	val: 0.813294	test: 0.623114

Epoch: 2
Loss: 0.5491205563664123
ROC train: 0.729069	val: 0.901335	test: 0.626061
PRC train: 0.918830	val: 0.859290	test: 0.666425

Epoch: 3
Loss: 0.4795122922416976
ROC train: 0.762349	val: 0.893205	test: 0.620563
PRC train: 0.935310	val: 0.854655	test: 0.669777

Epoch: 4
Loss: 0.43111844399888566
ROC train: 0.791918	val: 0.883670	test: 0.628954
PRC train: 0.945434	val: 0.841356	test: 0.680291

Epoch: 5
Loss: 0.4013592742493969
ROC train: 0.821705	val: 0.881662	test: 0.621431
PRC train: 0.952312	val: 0.837096	test: 0.687729

Epoch: 6
Loss: 0.3825432849311546
ROC train: 0.831039	val: 0.890796	test: 0.622782
PRC train: 0.956938	val: 0.838350	test: 0.686626

Epoch: 7
Loss: 0.3666446292989093
ROC train: 0.854371	val: 0.887885	test: 0.618634
PRC train: 0.962896	val: 0.828114	test: 0.680860

Epoch: 8
Loss: 0.3329626977759474
ROC train: 0.872325	val: 0.884171	test: 0.626929
PRC train: 0.967681	val: 0.825407	test: 0.684617

Epoch: 9
Loss: 0.3361032196971821
ROC train: 0.891912	val: 0.883870	test: 0.630112
PRC train: 0.974153	val: 0.831947	test: 0.680237

Epoch: 10
Loss: 0.2958697829825069
ROC train: 0.901080	val: 0.879755	test: 0.637249
PRC train: 0.977441	val: 0.808740	test: 0.698601

Epoch: 11
Loss: 0.3035285094759161
ROC train: 0.916462	val: 0.875539	test: 0.643133
PRC train: 0.981047	val: 0.808514	test: 0.692274

Epoch: 12
Loss: 0.2777454543780354
ROC train: 0.922115	val: 0.841514	test: 0.623746
PRC train: 0.982310	val: 0.735809	test: 0.673469

Epoch: 13
Loss: 0.29174932796578945
ROC train: 0.941040	val: 0.852153	test: 0.644676
PRC train: 0.987048	val: 0.767001	test: 0.686103

Epoch: 14
Loss: 0.25361650052447654
ROC train: 0.943879	val: 0.864198	test: 0.653839
PRC train: 0.988055	val: 0.757044	test: 0.695742

Epoch: 15
Loss: 0.2462502089640137
ROC train: 0.958641	val: 0.837699	test: 0.640914
PRC train: 0.991286	val: 0.734023	test: 0.675119

Epoch: 16
Loss: 0.2426278502174333
ROC train: 0.955151	val: 0.888588	test: 0.641493
PRC train: 0.990377	val: 0.796682	test: 0.659722

Epoch: 17
Loss: 0.2497296355305488
ROC train: 0.971834	val: 0.841413	test: 0.643519
PRC train: 0.994047	val: 0.755224	test: 0.674965

Epoch: 18
Loss: 0.22914137612290753
ROC train: 0.975018	val: 0.816521	test: 0.657890
PRC train: 0.994856	val: 0.664380	test: 0.654873

Epoch: 19
Loss: 0.21764270806274372
ROC train: 0.978629	val: 0.821339	test: 0.641879
PRC train: 0.995674	val: 0.693619	test: 0.667883

Epoch: 20
Loss: 0.22345158540642268
ROC train: 0.979897	val: 0.857673	test: 0.654803
PRC train: 0.995961	val: 0.742692	test: 0.689034

Epoch: 21
Loss: 0.20320493841030715
ROC train: 0.987581	val: 0.835692	test: 0.649498
PRC train: 0.997513	val: 0.719725	test: 0.672633

Epoch: 22
Loss: 0.1885466097824001
ROC train: 0.988260	val: 0.840410	test: 0.652488
PRC train: 0.997630	val: 0.716552	test: 0.670986

Epoch: 23
Loss: 0.18668390546033933
ROC train: 0.988243	val: 0.833484	test: 0.637056
PRC train: 0.997639	val: 0.714617	test: 0.656762

Epoch: 24
Loss: 0.17247642684686734
ROC train: 0.988347	val: 0.821640	test: 0.646123
PRC train: 0.997693	val: 0.690288	test: 0.644255

Epoch: 25
Loss: 0.1783176632706603
ROC train: 0.992134	val: 0.792432	test: 0.648052
PRC train: 0.998459	val: 0.627414	test: 0.654256

Epoch: 26
Loss: 0.1762400936468383
ROC train: 0.992411	val: 0.790324	test: 0.648727
PRC train: 0.998498	val: 0.631229	test: 0.651698

Epoch: 27
Loss: 0.14834059007103403
ROC train: 0.994611	val: 0.862190	test: 0.656154
PRC train: 0.998948	val: 0.762123	test: 0.649144

Epoch: 28
Loss: 0.14710828812311263
ROC train: 0.997057	val: 0.851852	test: 0.646508
PRC train: 0.999423	val: 0.730608	test: 0.647931

Epoch: 29
Loss: 0.1337232693228191
ROC train: 0.997554	val: 0.839908	test: 0.645255
PRC train: 0.999526	val: 0.699948	test: 0.646470

Epoch: 30
Loss: 0.12339734374676427
ROC train: 0.998878	val: 0.838302	test: 0.662519
PRC train: 0.999786	val: 0.707988	test: 0.685687

Epoch: 31
Loss: 0.13184818929659223
ROC train: 0.998196	val: 0.866707	test: 0.669174
PRC train: 0.999656	val: 0.769753	test: 0.685934

Epoch: 32
Loss: 0.14142633476294403
ROC train: 0.998252	val: 0.865904	test: 0.661651Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.1.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:2
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.1
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/bbbp/noise=0.1
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/bbbp/noise=0.1/bbbp_scaff_4_26-05_11-28-51  ]
[ Using Seed :  4  ]
[ Using device :  cuda:2  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.675281715255953
ROC train: 0.717407	val: 0.857774	test: 0.636863
PRC train: 0.919020	val: 0.783839	test: 0.675289

Epoch: 2
Loss: 0.5725884684383885
ROC train: 0.776297	val: 0.894108	test: 0.671007
PRC train: 0.941647	val: 0.842447	test: 0.710013

Epoch: 3
Loss: 0.48592345116665187
ROC train: 0.813954	val: 0.900532	test: 0.669271
PRC train: 0.954159	val: 0.852524	test: 0.717134

Epoch: 4
Loss: 0.42821999002038735
ROC train: 0.845598	val: 0.895815	test: 0.664255
PRC train: 0.963344	val: 0.845441	test: 0.712505

Epoch: 5
Loss: 0.3870469421041287
ROC train: 0.866984	val: 0.902238	test: 0.666474
PRC train: 0.968964	val: 0.845174	test: 0.723118

Epoch: 6
Loss: 0.3423256568469105
ROC train: 0.882006	val: 0.899729	test: 0.657311
PRC train: 0.972384	val: 0.841880	test: 0.716287

Epoch: 7
Loss: 0.30807246681898354
ROC train: 0.894914	val: 0.898826	test: 0.659240
PRC train: 0.975242	val: 0.833938	test: 0.718681

Epoch: 8
Loss: 0.32437346739322465
ROC train: 0.905695	val: 0.878952	test: 0.643615
PRC train: 0.978882	val: 0.752323	test: 0.710480

Epoch: 9
Loss: 0.29634994236538414
ROC train: 0.923492	val: 0.905551	test: 0.676698
PRC train: 0.982681	val: 0.810500	test: 0.734362

Epoch: 10
Loss: 0.2685117442531938
ROC train: 0.923077	val: 0.897320	test: 0.685378
PRC train: 0.982426	val: 0.800255	test: 0.743185

Epoch: 11
Loss: 0.26580742186235934
ROC train: 0.938574	val: 0.873833	test: 0.669271
PRC train: 0.986518	val: 0.752318	test: 0.738101

Epoch: 12
Loss: 0.25111898024267704
ROC train: 0.946530	val: 0.883168	test: 0.684703
PRC train: 0.988160	val: 0.757555	test: 0.745115

Epoch: 13
Loss: 0.24834622483905727
ROC train: 0.951860	val: 0.875841	test: 0.683738
PRC train: 0.989329	val: 0.737537	test: 0.742105

Epoch: 14
Loss: 0.24738932273624936
ROC train: 0.962893	val: 0.854060	test: 0.672743
PRC train: 0.992134	val: 0.677883	test: 0.733516

Epoch: 15
Loss: 0.2157238447549156
ROC train: 0.966251	val: 0.874435	test: 0.674576
PRC train: 0.992970	val: 0.708845	test: 0.731318

Epoch: 16
Loss: 0.21021251137892713
ROC train: 0.968846	val: 0.882967	test: 0.670814
PRC train: 0.993466	val: 0.744521	test: 0.726605

Epoch: 17
Loss: 0.2028059174238447
ROC train: 0.978864	val: 0.874034	test: 0.665413
PRC train: 0.995745	val: 0.720500	test: 0.729824

Epoch: 18
Loss: 0.20898938615794313
ROC train: 0.984369	val: 0.868815	test: 0.680748
PRC train: 0.996904	val: 0.724262	test: 0.742440

Epoch: 19
Loss: 0.19451447176385686
ROC train: 0.979131	val: 0.874335	test: 0.677566
PRC train: 0.995841	val: 0.722494	test: 0.732891

Epoch: 20
Loss: 0.18208121453011095
ROC train: 0.980270	val: 0.879153	test: 0.680941
PRC train: 0.995987	val: 0.721177	test: 0.745968

Epoch: 21
Loss: 0.1734590258230786
ROC train: 0.986184	val: 0.883067	test: 0.673322
PRC train: 0.997120	val: 0.729658	test: 0.739392

Epoch: 22
Loss: 0.17947578227886776
ROC train: 0.980640	val: 0.881361	test: 0.667149
PRC train: 0.995901	val: 0.738244	test: 0.724584

Epoch: 23
Loss: 0.16394164940777545
ROC train: 0.989856	val: 0.875539	test: 0.675058
PRC train: 0.997982	val: 0.762766	test: 0.733799

Epoch: 24
Loss: 0.15547408983225938
ROC train: 0.985583	val: 0.893707	test: 0.679012
PRC train: 0.997189	val: 0.781364	test: 0.750850

Epoch: 25
Loss: 0.1598204690212956
ROC train: 0.991023	val: 0.885878	test: 0.674190
PRC train: 0.998235	val: 0.807684	test: 0.742709

Epoch: 26
Loss: 0.1473825639572945
ROC train: 0.989693	val: 0.884874	test: 0.678723
PRC train: 0.997979	val: 0.777177	test: 0.742154

Epoch: 27
Loss: 0.15189025869544442
ROC train: 0.990038	val: 0.875339	test: 0.681906
PRC train: 0.998070	val: 0.744460	test: 0.748457

Epoch: 28
Loss: 0.13255768691388486
ROC train: 0.993393	val: 0.869417	test: 0.677566
PRC train: 0.998718	val: 0.743737	test: 0.738925

Epoch: 29
Loss: 0.1399505361767822
ROC train: 0.991965	val: 0.882867	test: 0.685667
PRC train: 0.998418	val: 0.762381	test: 0.738172

Epoch: 30
Loss: 0.12178730816184577
ROC train: 0.995408	val: 0.885677	test: 0.681424
PRC train: 0.999099	val: 0.774645	test: 0.737670

Epoch: 31
Loss: 0.11145567088214108
ROC train: 0.997402	val: 0.881261	test: 0.681134
PRC train: 0.999493	val: 0.779381	test: 0.736988

Epoch: 32
Loss: 0.11106978333935649
ROC train: 0.997021	val: 0.887183	test: 0.669946Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_static_noise_experiments/GraphCL/bbbp/noise=0.2.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 4
  multiple_seeds: [4, 5, 6]
  device: cuda:3
  input_data_dir: 
  dataset: bbbp
  num_workers: 0
  noise_level: 0.2
  dynamic_noise: False
  train_prop: 0.8
  split: scaffold
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/static-noise/GraphCL/bbbp/noise=0.2
  verbose: False
[ Logs to :  ../runs/static-noise/GraphCL/bbbp/noise=0.2/bbbp_scaff_4_26-05_11-28-51  ]
[ Using Seed :  4  ]
[ Using device :  cuda:3  ]
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6819473134645089
ROC train: 0.665160	val: 0.803573	test: 0.584684
PRC train: 0.900661	val: 0.691024	test: 0.565263

Epoch: 2
Loss: 0.5925678863006058
ROC train: 0.708534	val: 0.888487	test: 0.680556
PRC train: 0.922251	val: 0.842392	test: 0.718000

Epoch: 3
Loss: 0.5220102456552115
ROC train: 0.748841	val: 0.885075	test: 0.651910
PRC train: 0.933111	val: 0.834089	test: 0.687963

Epoch: 4
Loss: 0.4638922418009347
ROC train: 0.775613	val: 0.877647	test: 0.638792
PRC train: 0.941399	val: 0.822060	test: 0.675175

Epoch: 5
Loss: 0.42698290202753114
ROC train: 0.797169	val: 0.895112	test: 0.624711
PRC train: 0.947275	val: 0.849757	test: 0.684450

Epoch: 6
Loss: 0.3861376809177283
ROC train: 0.831549	val: 0.895915	test: 0.617284
PRC train: 0.956973	val: 0.863902	test: 0.685882

Epoch: 7
Loss: 0.3555562978393895
ROC train: 0.845183	val: 0.897119	test: 0.626157
PRC train: 0.961379	val: 0.863501	test: 0.694552

Epoch: 8
Loss: 0.35098699870051275
ROC train: 0.866554	val: 0.886681	test: 0.605421
PRC train: 0.967596	val: 0.845290	test: 0.662978

Epoch: 9
Loss: 0.33501123952105355
ROC train: 0.888784	val: 0.883469	test: 0.601852
PRC train: 0.972664	val: 0.843410	test: 0.654112

Epoch: 10
Loss: 0.323277540091298
ROC train: 0.902227	val: 0.899729	test: 0.635706
PRC train: 0.977776	val: 0.849254	test: 0.676810

Epoch: 11
Loss: 0.2975100585279381
ROC train: 0.914972	val: 0.875640	test: 0.641397
PRC train: 0.980962	val: 0.804466	test: 0.707332

Epoch: 12
Loss: 0.29932074338999204
ROC train: 0.922204	val: 0.884974	test: 0.625675
PRC train: 0.982340	val: 0.814929	test: 0.675664

Epoch: 13
Loss: 0.2674321824966527
ROC train: 0.933583	val: 0.883971	test: 0.601466
PRC train: 0.985080	val: 0.827258	test: 0.623110

Epoch: 14
Loss: 0.287631139065668
ROC train: 0.950996	val: 0.894911	test: 0.584105
PRC train: 0.989407	val: 0.838637	test: 0.630096

Epoch: 15
Loss: 0.2502412993791746
ROC train: 0.960397	val: 0.895313	test: 0.597608
PRC train: 0.991647	val: 0.834959	test: 0.644229

Epoch: 16
Loss: 0.2461561852423557
ROC train: 0.962302	val: 0.893406	test: 0.592110
PRC train: 0.992248	val: 0.832649	test: 0.656224

Epoch: 17
Loss: 0.2341605061614719
ROC train: 0.968437	val: 0.882264	test: 0.594907
PRC train: 0.993652	val: 0.788021	test: 0.649765

Epoch: 18
Loss: 0.2396995064663677
ROC train: 0.982130	val: 0.901937	test: 0.605421
PRC train: 0.996519	val: 0.828161	test: 0.659991

Epoch: 19
Loss: 0.22721825910659227
ROC train: 0.984974	val: 0.903844	test: 0.613329
PRC train: 0.997061	val: 0.843001	test: 0.666134

Epoch: 20
Loss: 0.2191455861774017
ROC train: 0.972468	val: 0.882465	test: 0.617284
PRC train: 0.994469	val: 0.819612	test: 0.677215

Epoch: 21
Loss: 0.20116913353464203
ROC train: 0.986150	val: 0.904045	test: 0.614873
PRC train: 0.997269	val: 0.840399	test: 0.687395

Epoch: 22
Loss: 0.20360796350361055
ROC train: 0.984966	val: 0.903643	test: 0.606674
PRC train: 0.997022	val: 0.844240	test: 0.669369

Epoch: 23
Loss: 0.18390724420724838
ROC train: 0.988967	val: 0.885075	test: 0.597897
PRC train: 0.997851	val: 0.794995	test: 0.660918

Epoch: 24
Loss: 0.1732395201592539
ROC train: 0.991514	val: 0.876342	test: 0.599055
PRC train: 0.998314	val: 0.777697	test: 0.667593

Epoch: 25
Loss: 0.15806187833146249
ROC train: 0.992633	val: 0.877848	test: 0.616319
PRC train: 0.998582	val: 0.781073	test: 0.689772

Epoch: 26
Loss: 0.15421196931670725
ROC train: 0.993769	val: 0.876443	test: 0.594907
PRC train: 0.998810	val: 0.779520	test: 0.670904

Epoch: 27
Loss: 0.15966450812241867
ROC train: 0.995511	val: 0.903041	test: 0.604649
PRC train: 0.999135	val: 0.837743	test: 0.686662

Epoch: 28
Loss: 0.14992585730960187
ROC train: 0.996799	val: 0.889090	test: 0.585455
PRC train: 0.999391	val: 0.819008	test: 0.632867

Epoch: 29
Loss: 0.15936671627856833
ROC train: 0.997293	val: 0.873131	test: 0.581887
PRC train: 0.999488	val: 0.770422	test: 0.608868

Epoch: 30
Loss: 0.1322859945591513
ROC train: 0.997071	val: 0.891298	test: 0.608700
PRC train: 0.999436	val: 0.815144	test: 0.675528

Epoch: 31
Loss: 0.12388483063570413
ROC train: 0.999029	val: 0.884774	test: 0.624614
PRC train: 0.999817	val: 0.811959	test: 0.691722

Epoch: 32
Loss: 0.11465002701185838
ROC train: 0.998092	val: 0.864097	test: 0.617573
PRC train: 0.996604	val: 0.809680	test: 0.776605

Epoch: 34
Loss: 0.15456672648208708
ROC train: 0.983063	val: 0.890696	test: 0.729263
PRC train: 0.996425	val: 0.813432	test: 0.791304

Epoch: 35
Loss: 0.14653904133657633
ROC train: 0.983876	val: 0.866506	test: 0.722126
PRC train: 0.996605	val: 0.769001	test: 0.768190

Epoch: 36
Loss: 0.15474335178004026
ROC train: 0.987151	val: 0.866908	test: 0.717207
PRC train: 0.997311	val: 0.757506	test: 0.766464

Epoch: 37
Loss: 0.14234552809893383
ROC train: 0.987320	val: 0.847235	test: 0.719425
PRC train: 0.997369	val: 0.734495	test: 0.762290

Epoch: 38
Loss: 0.17247103328490582
ROC train: 0.987290	val: 0.871625	test: 0.735050
PRC train: 0.997346	val: 0.774356	test: 0.769467

Epoch: 39
Loss: 0.14393321411333465
ROC train: 0.988304	val: 0.869316	test: 0.731674
PRC train: 0.997641	val: 0.762108	test: 0.744074

Epoch: 40
Loss: 0.15466596490894122
ROC train: 0.988313	val: 0.881361	test: 0.734954
PRC train: 0.997633	val: 0.789091	test: 0.789177

Epoch: 41
Loss: 0.14265844973591074
ROC train: 0.986689	val: 0.873131	test: 0.723573
PRC train: 0.997308	val: 0.770790	test: 0.772219

Epoch: 42
Loss: 0.12895735510249326
ROC train: 0.988366	val: 0.874937	test: 0.716628
PRC train: 0.997680	val: 0.778304	test: 0.740237

Epoch: 43
Loss: 0.13886031205283159
ROC train: 0.989738	val: 0.872629	test: 0.710455
PRC train: 0.997957	val: 0.775730	test: 0.734356

Epoch: 44
Loss: 0.13330893750648162
ROC train: 0.988884	val: 0.874636	test: 0.711323
PRC train: 0.997780	val: 0.781844	test: 0.726542

Epoch: 45
Loss: 0.1271996823388748
ROC train: 0.989070	val: 0.874235	test: 0.716725
PRC train: 0.997834	val: 0.779818	test: 0.735911

Epoch: 46
Loss: 0.12698493931011817
ROC train: 0.991678	val: 0.867108	test: 0.716821
PRC train: 0.998366	val: 0.773002	test: 0.763110

Epoch: 47
Loss: 0.12870872364166736
ROC train: 0.991965	val: 0.874335	test: 0.718750
PRC train: 0.998423	val: 0.768663	test: 0.760702

Epoch: 48
Loss: 0.14253700097529418
ROC train: 0.990570	val: 0.866707	test: 0.708044
PRC train: 0.998136	val: 0.758040	test: 0.756119

Epoch: 49
Loss: 0.12415675769458727
ROC train: 0.991888	val: 0.869517	test: 0.704186
PRC train: 0.998413	val: 0.766016	test: 0.767811

Epoch: 50
Loss: 0.125262718898449
ROC train: 0.991967	val: 0.855867	test: 0.705922
PRC train: 0.998433	val: 0.748525	test: 0.759105

Epoch: 51
Loss: 0.12954312737259663
ROC train: 0.992145	val: 0.866105	test: 0.702450
PRC train: 0.998479	val: 0.749373	test: 0.735584

Epoch: 52
Loss: 0.10798793361710077
ROC train: 0.992957	val: 0.866004	test: 0.697434
PRC train: 0.998632	val: 0.770551	test: 0.725765

Epoch: 53
Loss: 0.12236760824792157
ROC train: 0.993232	val: 0.867711	test: 0.679591
PRC train: 0.998685	val: 0.776630	test: 0.702734

Epoch: 54
Loss: 0.1197248357690787
ROC train: 0.992923	val: 0.865001	test: 0.701003
PRC train: 0.998631	val: 0.775166	test: 0.727227

Epoch: 55
Loss: 0.12184805193550503
ROC train: 0.993165	val: 0.871324	test: 0.702257
PRC train: 0.998674	val: 0.765323	test: 0.728376

Epoch: 56
Loss: 0.110741060581088
ROC train: 0.994459	val: 0.878852	test: 0.696181
PRC train: 0.998934	val: 0.795628	test: 0.731714

Epoch: 57
Loss: 0.10348231277887333
ROC train: 0.993922	val: 0.876543	test: 0.699171
PRC train: 0.998817	val: 0.797383	test: 0.742167

Epoch: 58
Loss: 0.10147957933990318
ROC train: 0.994347	val: 0.876242	test: 0.685571
PRC train: 0.998910	val: 0.772877	test: 0.713299

Epoch: 59
Loss: 0.11335143932178052
ROC train: 0.995654	val: 0.871424	test: 0.684124
PRC train: 0.999170	val: 0.767567	test: 0.710662

Epoch: 60
Loss: 0.0997270155056985
ROC train: 0.995688	val: 0.878350	test: 0.715085
PRC train: 0.999174	val: 0.789671	test: 0.774045

Epoch: 61
Loss: 0.10887505970166551
ROC train: 0.996704	val: 0.872227	test: 0.682292
PRC train: 0.999372	val: 0.779007	test: 0.723888

Epoch: 62
Loss: 0.10450840900634487
ROC train: 0.996280	val: 0.871625	test: 0.686825
PRC train: 0.999287	val: 0.773688	test: 0.718497

Epoch: 63
Loss: 0.10160672402713097
ROC train: 0.995413	val: 0.885276	test: 0.702739
PRC train: 0.999124	val: 0.787585	test: 0.738541

Epoch: 64
Loss: 0.10597659495521036
ROC train: 0.995300	val: 0.863495	test: 0.687596
PRC train: 0.999100	val: 0.777581	test: 0.726056

Epoch: 65
Loss: 0.10143592457108129
ROC train: 0.996077	val: 0.881461	test: 0.697434
PRC train: 0.999249	val: 0.785862	test: 0.748245

Epoch: 66
Loss: 0.11234704840295424
ROC train: 0.993569	val: 0.865101	test: 0.717978
PRC train: 0.998734	val: 0.744927	test: 0.757773

Epoch: 67
Loss: 0.10999430357422595
ROC train: 0.993671	val: 0.870521	test: 0.716917
PRC train: 0.998782	val: 0.788381	test: 0.746081

Epoch: 68
Loss: 0.10760118315353517
ROC train: 0.996481	val: 0.879655	test: 0.711709
PRC train: 0.999324	val: 0.801024	test: 0.753715

Epoch: 69
Loss: 0.10753739379065043
ROC train: 0.996778	val: 0.877647	test: 0.710262
PRC train: 0.999386	val: 0.764324	test: 0.719220

Epoch: 70
Loss: 0.10651588824891242
ROC train: 0.996474	val: 0.858777	test: 0.694927
PRC train: 0.999327	val: 0.729818	test: 0.711964

Epoch: 71
Loss: 0.09081164951616567
ROC train: 0.996963	val: 0.877647	test: 0.700714
PRC train: 0.999420	val: 0.801948	test: 0.738226

Epoch: 72
Loss: 0.10846829566950952
ROC train: 0.996770	val: 0.875941	test: 0.704861
PRC train: 0.999385	val: 0.790347	test: 0.727794

Epoch: 73
Loss: 0.09565138746653888
ROC train: 0.996984	val: 0.856067	test: 0.690779
PRC train: 0.999423	val: 0.732773	test: 0.700882

Epoch: 74
Loss: 0.08963622367986664
ROC train: 0.997359	val: 0.860685	test: 0.716049
PRC train: 0.999497	val: 0.765923	test: 0.739137

Epoch: 75
Loss: 0.0868893232265348
ROC train: 0.997688	val: 0.869316	test: 0.705826
PRC train: 0.999563	val: 0.783932	test: 0.729126

Epoch: 76
Loss: 0.08312655385036363
ROC train: 0.997356	val: 0.876644	test: 0.689815
PRC train: 0.999486	val: 0.794971	test: 0.699694

Epoch: 77
Loss: 0.07862635664909016
ROC train: 0.996899	val: 0.860986	test: 0.700039
PRC train: 0.999399	val: 0.771383	test: 0.723648

Epoch: 78
Loss: 0.10378076632925258
ROC train: 0.997447	val: 0.853056	test: 0.713156
PRC train: 0.999512	val: 0.766626	test: 0.736677

Epoch: 79
Loss: 0.08872938219806467
ROC train: 0.996666	val: 0.865402	test: 0.709105
PRC train: 0.999362	val: 0.773063	test: 0.733720

Epoch: 80
Loss: 0.0951202482358138
ROC train: 0.997903	val: 0.869216	test: 0.700907
PRC train: 0.999604	val: 0.777304	test: 0.730735

Epoch: 81
Loss: 0.08441602278668225
ROC train: 0.997496	val: 0.857573	test: 0.697145
PRC train: 0.999526	val: 0.752372	test: 0.710459

Epoch: 82
Loss: 0.1062973306644039
ROC train: 0.997130	val: 0.855766	test: 0.692901
PRC train: 0.999453	val: 0.731398	test: 0.697920

Epoch: 83
Loss: 0.0934011733231107
ROC train: 0.996721	val: 0.859380	test: 0.692708
PRC train: 0.999370	val: 0.739757	test: 0.692348

Epoch: 84
Loss: 0.08732227101630295
ROC train: 0.997474	val: 0.861287	test: 0.675926
PRC train: 0.999519	val: 0.748597	test: 0.686893

Epoch: 85
Loss: 0.08129828507626558
ROC train: 0.997505	val: 0.851149	test: 0.669560
PRC train: 0.999519	val: 0.742603	test: 0.664728

Epoch: 86
Loss: 0.09257530517255093
ROC train: 0.997778	val: 0.844023	test: 0.686825
PRC train: 0.999580	val: 0.738799	test: 0.694791

Epoch: 87
Loss: 0.0945162034816968
ROC train: 0.998155	val: 0.852956	test: 0.697627
PRC train: 0.999648	val: 0.750126	test: 0.707145

Epoch: 88
Loss: 0.06868177429142582
ROC train: 0.998188	val: 0.873131	test: 0.692226
PRC train: 0.999655	val: 0.769030	test: 0.700530

Epoch: 89
Loss: 0.10208928965683774
ROC train: 0.998644	val: 0.862792	test: 0.681327
PRC train: 0.999742	val: 0.756191	test: 0.697182

Epoch: 90
Loss: 0.0802194095095137
ROC train: 0.997937	val: 0.850146	test: 0.698688
PRC train: 0.999606	val: 0.739740	test: 0.714815

Epoch: 91
Loss: 0.09116843690141907
ROC train: 0.998555	val: 0.856870	test: 0.685475
PRC train: 0.999723	val: 0.749947	test: 0.705726

Epoch: 92
Loss: 0.0688177719769896
ROC train: 0.997826	val: 0.830874	test: 0.675154
PRC train: 0.999571	val: 0.711303	test: 0.687213

Epoch: 93
Loss: 0.07985630109179014
ROC train: 0.997927	val: 0.855566	test: 0.681713
PRC train: 0.999607	val: 0.738016	test: 0.683747

Epoch: 94
Loss: 0.07859164376430552
ROC train: 0.997707	val: 0.835792	test: 0.681906
PRC train: 0.995779	val: 0.810146	test: 0.737832

Epoch: 34
Loss: 0.1507863609069456
ROC train: 0.984760	val: 0.878350	test: 0.706983
PRC train: 0.996950	val: 0.780640	test: 0.731358

Epoch: 35
Loss: 0.15318747599354274
ROC train: 0.986802	val: 0.884673	test: 0.707176
PRC train: 0.997368	val: 0.797953	test: 0.752279

Epoch: 36
Loss: 0.1549764445765575
ROC train: 0.985530	val: 0.881562	test: 0.707755
PRC train: 0.997020	val: 0.801691	test: 0.754439

Epoch: 37
Loss: 0.1451539736935472
ROC train: 0.985097	val: 0.893606	test: 0.711709
PRC train: 0.996941	val: 0.799886	test: 0.759847

Epoch: 38
Loss: 0.14439985492645252
ROC train: 0.985920	val: 0.866205	test: 0.708623
PRC train: 0.997209	val: 0.746290	test: 0.755489

Epoch: 39
Loss: 0.16161890461699654
ROC train: 0.987666	val: 0.882264	test: 0.715471
PRC train: 0.997547	val: 0.780199	test: 0.765742

Epoch: 40
Loss: 0.15044757731752917
ROC train: 0.988095	val: 0.891398	test: 0.710359
PRC train: 0.997641	val: 0.809497	test: 0.760009

Epoch: 41
Loss: 0.14226670030011232
ROC train: 0.983517	val: 0.864298	test: 0.701196
PRC train: 0.996763	val: 0.792452	test: 0.743075

Epoch: 42
Loss: 0.14135158260120456
ROC train: 0.988706	val: 0.864097	test: 0.701678
PRC train: 0.997747	val: 0.768809	test: 0.740975

Epoch: 43
Loss: 0.13443761397626386
ROC train: 0.988519	val: 0.874134	test: 0.708623
PRC train: 0.997720	val: 0.788034	test: 0.748644

Epoch: 44
Loss: 0.13087921423068574
ROC train: 0.985691	val: 0.857272	test: 0.702836
PRC train: 0.997168	val: 0.759342	test: 0.738980

Epoch: 45
Loss: 0.13105864845448742
ROC train: 0.990291	val: 0.855766	test: 0.705247
PRC train: 0.998121	val: 0.747547	test: 0.728182

Epoch: 46
Loss: 0.13607705082538565
ROC train: 0.990633	val: 0.861086	test: 0.708719
PRC train: 0.998175	val: 0.755738	test: 0.733706

Epoch: 47
Loss: 0.1332982172059988
ROC train: 0.990397	val: 0.861889	test: 0.703414
PRC train: 0.998125	val: 0.777010	test: 0.736373

Epoch: 48
Loss: 0.14419281645619558
ROC train: 0.991943	val: 0.856870	test: 0.687693
PRC train: 0.998426	val: 0.762160	test: 0.713739

Epoch: 49
Loss: 0.13065101991984399
ROC train: 0.991979	val: 0.883670	test: 0.711902
PRC train: 0.998450	val: 0.770830	test: 0.749819

Epoch: 50
Loss: 0.12177188772029586
ROC train: 0.991221	val: 0.880458	test: 0.708719
PRC train: 0.998291	val: 0.824179	test: 0.752698

Epoch: 51
Loss: 0.1273378268925
ROC train: 0.993379	val: 0.872930	test: 0.715085
PRC train: 0.998717	val: 0.799329	test: 0.752476

Epoch: 52
Loss: 0.1258376842830801
ROC train: 0.992034	val: 0.890394	test: 0.726273
PRC train: 0.998431	val: 0.828116	test: 0.783544

Epoch: 53
Loss: 0.12737489193175755
ROC train: 0.993221	val: 0.864800	test: 0.711034
PRC train: 0.998668	val: 0.792922	test: 0.746296

Epoch: 54
Loss: 0.12672407190016016
ROC train: 0.991653	val: 0.850246	test: 0.688465
PRC train: 0.998369	val: 0.756127	test: 0.725968

Epoch: 55
Loss: 0.11256100730772925
ROC train: 0.994163	val: 0.858376	test: 0.696759
PRC train: 0.998870	val: 0.753155	test: 0.731752

Epoch: 56
Loss: 0.10877119147764204
ROC train: 0.994116	val: 0.860383	test: 0.687404
PRC train: 0.998870	val: 0.758638	test: 0.712147

Epoch: 57
Loss: 0.10574256442524367
ROC train: 0.992741	val: 0.879454	test: 0.706019
PRC train: 0.998594	val: 0.795923	test: 0.717157

Epoch: 58
Loss: 0.11694014947378939
ROC train: 0.993069	val: 0.888989	test: 0.710166
PRC train: 0.998666	val: 0.794359	test: 0.742637

Epoch: 59
Loss: 0.11972704774488445
ROC train: 0.993837	val: 0.856670	test: 0.699171
PRC train: 0.998824	val: 0.750917	test: 0.720447

Epoch: 60
Loss: 0.11214187776000788
ROC train: 0.990790	val: 0.869818	test: 0.713156
PRC train: 0.998220	val: 0.771829	test: 0.720806

Epoch: 61
Loss: 0.11608310225501917
ROC train: 0.993231	val: 0.853659	test: 0.705247
PRC train: 0.998687	val: 0.746032	test: 0.713730

Epoch: 62
Loss: 0.12082222387145816
ROC train: 0.994305	val: 0.860785	test: 0.669850
PRC train: 0.998904	val: 0.757345	test: 0.682471

Epoch: 63
Loss: 0.11458566014293367
ROC train: 0.993269	val: 0.871424	test: 0.693962
PRC train: 0.998704	val: 0.759611	test: 0.700034

Epoch: 64
Loss: 0.11762302419464425
ROC train: 0.995049	val: 0.877145	test: 0.718364
PRC train: 0.999050	val: 0.761635	test: 0.739474

Epoch: 65
Loss: 0.10271683513889585
ROC train: 0.995259	val: 0.862893	test: 0.716435
PRC train: 0.999091	val: 0.742289	test: 0.737126

Epoch: 66
Loss: 0.10298898007027738
ROC train: 0.995900	val: 0.877848	test: 0.696373
PRC train: 0.999210	val: 0.771708	test: 0.727684

Epoch: 67
Loss: 0.11012955254189319
ROC train: 0.995100	val: 0.870521	test: 0.710166
PRC train: 0.999060	val: 0.753173	test: 0.729108

Epoch: 68
Loss: 0.11296289480528772
ROC train: 0.996165	val: 0.850848	test: 0.707755
PRC train: 0.999266	val: 0.726192	test: 0.724839

Epoch: 69
Loss: 0.11152106590379147
ROC train: 0.995768	val: 0.860383	test: 0.701196
PRC train: 0.999192	val: 0.745004	test: 0.741753

Epoch: 70
Loss: 0.11749471487097383
ROC train: 0.995626	val: 0.849945	test: 0.684028
PRC train: 0.999168	val: 0.742526	test: 0.716004

Epoch: 71
Loss: 0.11108838691815383
ROC train: 0.995172	val: 0.848038	test: 0.698302
PRC train: 0.999076	val: 0.729847	test: 0.708377

Epoch: 72
Loss: 0.10656358107958486
ROC train: 0.996085	val: 0.857975	test: 0.708044
PRC train: 0.999243	val: 0.742004	test: 0.739899

Epoch: 73
Loss: 0.1036863914441873
ROC train: 0.996018	val: 0.853659	test: 0.714024
PRC train: 0.999234	val: 0.732746	test: 0.752867

Epoch: 74
Loss: 0.10316277684662369
ROC train: 0.996639	val: 0.858677	test: 0.718171
PRC train: 0.999359	val: 0.751640	test: 0.756586

Epoch: 75
Loss: 0.10521977882443835
ROC train: 0.996988	val: 0.852354	test: 0.707079
PRC train: 0.999429	val: 0.737690	test: 0.731706

Epoch: 76
Loss: 0.09704242534283133
ROC train: 0.996158	val: 0.844725	test: 0.688754
PRC train: 0.999272	val: 0.708207	test: 0.707198

Epoch: 77
Loss: 0.08431922862720034
ROC train: 0.996737	val: 0.872528	test: 0.716242
PRC train: 0.999377	val: 0.750692	test: 0.760218

Epoch: 78
Loss: 0.09403887527256746
ROC train: 0.996635	val: 0.872528	test: 0.724537
PRC train: 0.999357	val: 0.742323	test: 0.777431

Epoch: 79
Loss: 0.09649005521130935
ROC train: 0.997171	val: 0.847937	test: 0.707851
PRC train: 0.999458	val: 0.706479	test: 0.733006

Epoch: 80
Loss: 0.0924053212126217
ROC train: 0.996893	val: 0.845930	test: 0.696277
PRC train: 0.999405	val: 0.709058	test: 0.728314

Epoch: 81
Loss: 0.10049318723631176
ROC train: 0.997115	val: 0.859681	test: 0.706501
PRC train: 0.999452	val: 0.735932	test: 0.750528

Epoch: 82
Loss: 0.1072065338607139
ROC train: 0.997186	val: 0.856067	test: 0.702064
PRC train: 0.999468	val: 0.727247	test: 0.725328

Epoch: 83
Loss: 0.09124975980899941
ROC train: 0.997176	val: 0.850246	test: 0.681809
PRC train: 0.999465	val: 0.723376	test: 0.696608

Epoch: 84
Loss: 0.09983703560325438
ROC train: 0.997535	val: 0.850647	test: 0.659722
PRC train: 0.999531	val: 0.732300	test: 0.674183

Epoch: 85
Loss: 0.09375718881018069
ROC train: 0.997608	val: 0.867209	test: 0.684317
PRC train: 0.999545	val: 0.761397	test: 0.710529

Epoch: 86
Loss: 0.09324199380794275
ROC train: 0.997721	val: 0.850949	test: 0.664738
PRC train: 0.999567	val: 0.721119	test: 0.680724

Epoch: 87
Loss: 0.0939095781879533
ROC train: 0.997568	val: 0.851250	test: 0.685957
PRC train: 0.999541	val: 0.735548	test: 0.705904

Epoch: 88
Loss: 0.08470108716483682
ROC train: 0.996157	val: 0.852153	test: 0.704186
PRC train: 0.999264	val: 0.738383	test: 0.750522

Epoch: 89
Loss: 0.09390561973761857
ROC train: 0.997791	val: 0.875640	test: 0.689718
PRC train: 0.999581	val: 0.762810	test: 0.722485

Epoch: 90
Loss: 0.08469186629796191
ROC train: 0.997740	val: 0.858476	test: 0.707465
PRC train: 0.999568	val: 0.728769	test: 0.728329

Epoch: 91
Loss: 0.09508358508678141
ROC train: 0.997134	val: 0.851952	test: 0.706790
PRC train: 0.999452	val: 0.726486	test: 0.741306

Epoch: 92
Loss: 0.09058512497121199
ROC train: 0.997690	val: 0.848238	test: 0.700039
PRC train: 0.999556	val: 0.741455	test: 0.722160

Epoch: 93
Loss: 0.07802016354998217
ROC train: 0.997604	val: 0.859480	test: 0.665509
PRC train: 0.999547	val: 0.745678	test: 0.687159

Epoch: 94
Loss: 0.06935239562357344
ROC train: 0.998053	val: 0.859179	test: 0.676312
ROC train: 0.986216	val: 0.894209	test: 0.697917
PRC train: 0.997214	val: 0.815439	test: 0.713915

Epoch: 34
Loss: 0.16976051674523918
ROC train: 0.984544	val: 0.900130	test: 0.704958
PRC train: 0.996827	val: 0.847564	test: 0.753997

Epoch: 35
Loss: 0.1529036627711396
ROC train: 0.983687	val: 0.905350	test: 0.718075
PRC train: 0.996698	val: 0.832990	test: 0.736609

Epoch: 36
Loss: 0.1437224840677028
ROC train: 0.984683	val: 0.898324	test: 0.695216
PRC train: 0.996971	val: 0.797208	test: 0.704922

Epoch: 37
Loss: 0.15425260953260314
ROC train: 0.986721	val: 0.890495	test: 0.690779
PRC train: 0.997342	val: 0.798944	test: 0.727876

Epoch: 38
Loss: 0.14418431499135445
ROC train: 0.985291	val: 0.880558	test: 0.679591
PRC train: 0.997035	val: 0.771370	test: 0.702363

Epoch: 39
Loss: 0.15622398043412658
ROC train: 0.989521	val: 0.890093	test: 0.693287
PRC train: 0.997923	val: 0.795918	test: 0.725812

Epoch: 40
Loss: 0.1417166712982905
ROC train: 0.989881	val: 0.895815	test: 0.691358
PRC train: 0.998001	val: 0.821673	test: 0.722712

Epoch: 41
Loss: 0.13522877132234265
ROC train: 0.990400	val: 0.899629	test: 0.707272
PRC train: 0.998093	val: 0.807489	test: 0.729031

Epoch: 42
Loss: 0.14036914389230198
ROC train: 0.990523	val: 0.894911	test: 0.701968
PRC train: 0.998124	val: 0.790294	test: 0.732299

Epoch: 43
Loss: 0.1273257572643029
ROC train: 0.989881	val: 0.888186	test: 0.701003
PRC train: 0.998001	val: 0.776776	test: 0.727511

Epoch: 44
Loss: 0.13733722164742942
ROC train: 0.990232	val: 0.878751	test: 0.695023
PRC train: 0.998072	val: 0.767916	test: 0.716195

Epoch: 45
Loss: 0.13261384203379473
ROC train: 0.991930	val: 0.888186	test: 0.703607
PRC train: 0.998423	val: 0.781567	test: 0.736972

Epoch: 46
Loss: 0.14094823335623216
ROC train: 0.990498	val: 0.881562	test: 0.684703
PRC train: 0.998123	val: 0.777580	test: 0.712519

Epoch: 47
Loss: 0.1356840708561399
ROC train: 0.991157	val: 0.881562	test: 0.682870
PRC train: 0.998257	val: 0.788830	test: 0.701353

Epoch: 48
Loss: 0.13134641194827437
ROC train: 0.991397	val: 0.890997	test: 0.705922
PRC train: 0.998324	val: 0.802485	test: 0.750338

Epoch: 49
Loss: 0.1428780477841387
ROC train: 0.991157	val: 0.872428	test: 0.691551
PRC train: 0.998280	val: 0.786698	test: 0.729591

Epoch: 50
Loss: 0.12118253792039797
ROC train: 0.990808	val: 0.885476	test: 0.687307
PRC train: 0.998170	val: 0.791508	test: 0.703477

Epoch: 51
Loss: 0.1240162403472392
ROC train: 0.992803	val: 0.882365	test: 0.680845
PRC train: 0.998578	val: 0.775420	test: 0.696785

Epoch: 52
Loss: 0.12023850640466334
ROC train: 0.993901	val: 0.865201	test: 0.686246
PRC train: 0.998803	val: 0.756841	test: 0.711255

Epoch: 53
Loss: 0.11645487341905061
ROC train: 0.992936	val: 0.868815	test: 0.671779
PRC train: 0.998607	val: 0.755953	test: 0.695473

Epoch: 54
Loss: 0.11370086920157099
ROC train: 0.994172	val: 0.867711	test: 0.673032
PRC train: 0.998870	val: 0.756290	test: 0.690693

Epoch: 55
Loss: 0.10209294590948699
ROC train: 0.994964	val: 0.876041	test: 0.684221
PRC train: 0.999030	val: 0.765663	test: 0.694724

Epoch: 56
Loss: 0.10609785257507985
ROC train: 0.995445	val: 0.886982	test: 0.679109
PRC train: 0.999127	val: 0.770624	test: 0.682832

Epoch: 57
Loss: 0.11730405975099753
ROC train: 0.995777	val: 0.870019	test: 0.659144
PRC train: 0.999197	val: 0.745562	test: 0.664413

Epoch: 58
Loss: 0.10483066640377602
ROC train: 0.995496	val: 0.883670	test: 0.685378
PRC train: 0.999130	val: 0.766298	test: 0.699054

Epoch: 59
Loss: 0.10869078613746126
ROC train: 0.994755	val: 0.882465	test: 0.705247
PRC train: 0.998990	val: 0.767937	test: 0.709254

Epoch: 60
Loss: 0.11049724766040081
ROC train: 0.995768	val: 0.870922	test: 0.679591
PRC train: 0.999189	val: 0.768619	test: 0.692320

Epoch: 61
Loss: 0.10952090278201472
ROC train: 0.994962	val: 0.872829	test: 0.683353
PRC train: 0.999027	val: 0.768918	test: 0.684722

Epoch: 62
Loss: 0.11101849754207141
ROC train: 0.996030	val: 0.873131	test: 0.684896
PRC train: 0.999235	val: 0.757184	test: 0.697154

Epoch: 63
Loss: 0.11571804317157146
ROC train: 0.995434	val: 0.882465	test: 0.690972
PRC train: 0.999127	val: 0.772094	test: 0.703696

Epoch: 64
Loss: 0.12358972277338041
ROC train: 0.995882	val: 0.871023	test: 0.676987
PRC train: 0.999205	val: 0.754560	test: 0.679024

Epoch: 65
Loss: 0.10142855206340554
ROC train: 0.996102	val: 0.877346	test: 0.681713
PRC train: 0.999246	val: 0.753153	test: 0.693254

Epoch: 66
Loss: 0.10803132287473817
ROC train: 0.995762	val: 0.886881	test: 0.691937
PRC train: 0.999181	val: 0.767851	test: 0.700570

Epoch: 67
Loss: 0.0985277525788428
ROC train: 0.994224	val: 0.861287	test: 0.693094
PRC train: 0.998903	val: 0.734205	test: 0.699465

Epoch: 68
Loss: 0.10586735810643712
ROC train: 0.995709	val: 0.869417	test: 0.681809
PRC train: 0.999183	val: 0.770844	test: 0.685322

Epoch: 69
Loss: 0.10372818221477183
ROC train: 0.994079	val: 0.878952	test: 0.658275
PRC train: 0.998831	val: 0.784966	test: 0.654937

Epoch: 70
Loss: 0.10380211165428711
ROC train: 0.995511	val: 0.883870	test: 0.674769
PRC train: 0.999130	val: 0.775709	test: 0.683866

Epoch: 71
Loss: 0.10953995287160787
ROC train: 0.996303	val: 0.874636	test: 0.694637
PRC train: 0.999295	val: 0.756024	test: 0.709726

Epoch: 72
Loss: 0.10241247835939103
ROC train: 0.992003	val: 0.863595	test: 0.657215
PRC train: 0.998425	val: 0.739278	test: 0.664402

Epoch: 73
Loss: 0.10821951511990255
ROC train: 0.997304	val: 0.880759	test: 0.660494
PRC train: 0.999487	val: 0.766804	test: 0.665745

Epoch: 74
Loss: 0.08885130700179024
ROC train: 0.997262	val: 0.889090	test: 0.660012
PRC train: 0.999479	val: 0.773659	test: 0.666146

Epoch: 75
Loss: 0.0975084588222921
ROC train: 0.997747	val: 0.886781	test: 0.668596
PRC train: 0.999573	val: 0.764717	test: 0.670758

Epoch: 76
Loss: 0.09665242450732574
ROC train: 0.997837	val: 0.880357	test: 0.668499
PRC train: 0.999588	val: 0.764910	test: 0.673917

Epoch: 77
Loss: 0.08838197189555697
ROC train: 0.997698	val: 0.887684	test: 0.669271
PRC train: 0.999564	val: 0.782625	test: 0.679702

Epoch: 78
Loss: 0.10039596561524997
ROC train: 0.996657	val: 0.887484	test: 0.676698
PRC train: 0.999351	val: 0.783506	test: 0.681206

Epoch: 79
Loss: 0.09585882172337469
ROC train: 0.997663	val: 0.883168	test: 0.670814
PRC train: 0.999554	val: 0.786767	test: 0.680748

Epoch: 80
Loss: 0.10061004181665102
ROC train: 0.996265	val: 0.863896	test: 0.659047
PRC train: 0.999281	val: 0.775825	test: 0.670594

Epoch: 81
Loss: 0.1044116701750455
ROC train: 0.995964	val: 0.879253	test: 0.700907
PRC train: 0.999196	val: 0.806802	test: 0.722659

Epoch: 82
Loss: 0.09918502090572637
ROC train: 0.997471	val: 0.873632	test: 0.704572
PRC train: 0.999512	val: 0.776848	test: 0.722711

Epoch: 83
Loss: 0.11610326097280765
ROC train: 0.995444	val: 0.852354	test: 0.684799
PRC train: 0.999092	val: 0.738022	test: 0.691476

Epoch: 84
Loss: 0.094445824667868
ROC train: 0.996080	val: 0.874134	test: 0.664834
PRC train: 0.999233	val: 0.770717	test: 0.675870

Epoch: 85
Loss: 0.0850245442621691
ROC train: 0.997889	val: 0.888487	test: 0.660012
PRC train: 0.999601	val: 0.784805	test: 0.673262

Epoch: 86
Loss: 0.09182290682797882
ROC train: 0.998526	val: 0.879855	test: 0.665123
PRC train: 0.999721	val: 0.767851	test: 0.674317

Epoch: 87
Loss: 0.08827554240745084
ROC train: 0.998332	val: 0.880157	test: 0.686825
PRC train: 0.999685	val: 0.765745	test: 0.697832

Epoch: 88
Loss: 0.08548248447130584
ROC train: 0.998418	val: 0.876744	test: 0.673997
PRC train: 0.999700	val: 0.762665	test: 0.682209

Epoch: 89
Loss: 0.06865455318163813
ROC train: 0.998310	val: 0.862090	test: 0.662230
PRC train: 0.999680	val: 0.744090	test: 0.664725

Epoch: 90
Loss: 0.07521087672613525
ROC train: 0.998286	val: 0.863495	test: 0.667149
PRC train: 0.999677	val: 0.742246	test: 0.672432

Epoch: 91
Loss: 0.08082516355840016
ROC train: 0.998627	val: 0.872026	test: 0.680170
PRC train: 0.999740	val: 0.753835	test: 0.687445

Epoch: 92
Loss: 0.0886608822423691
ROC train: 0.998074	val: 0.847837	test: 0.669657
PRC train: 0.999631	val: 0.745340	test: 0.700206

Epoch: 93
Loss: 0.09078743951559529
ROC train: 0.997903	val: 0.843923	test: 0.673611
PRC train: 0.999603	val: 0.713823	test: 0.678730

Epoch: 94
Loss: 0.09157369572941655
PRC train: 0.999504	val: 0.774237	test: 0.746686

Epoch: 33
Loss: 0.11305809895349571
ROC train: 0.998592	val: 0.847636	test: 0.702064
PRC train: 0.999729	val: 0.773452	test: 0.753648

Epoch: 34
Loss: 0.11293647556533913
ROC train: 0.998665	val: 0.849242	test: 0.714313
PRC train: 0.999742	val: 0.753114	test: 0.750538

Epoch: 35
Loss: 0.11266809720921649
ROC train: 0.999178	val: 0.827060	test: 0.698881
PRC train: 0.999843	val: 0.708573	test: 0.735220

Epoch: 36
Loss: 0.11024929154499404
ROC train: 0.998488	val: 0.843722	test: 0.708333
PRC train: 0.999713	val: 0.746630	test: 0.750555

Epoch: 37
Loss: 0.08459772293085659
ROC train: 0.998934	val: 0.845830	test: 0.706983
PRC train: 0.999796	val: 0.774514	test: 0.757869

Epoch: 38
Loss: 0.07658832189436818
ROC train: 0.998785	val: 0.847937	test: 0.705440
PRC train: 0.999765	val: 0.747880	test: 0.735179

Epoch: 39
Loss: 0.08585769539922716
ROC train: 0.999453	val: 0.827562	test: 0.696277
PRC train: 0.999895	val: 0.706162	test: 0.713182

Epoch: 40
Loss: 0.10284306822893517
ROC train: 0.999554	val: 0.827963	test: 0.700907
PRC train: 0.999915	val: 0.690556	test: 0.715304

Epoch: 41
Loss: 0.08872771938589122
ROC train: 0.999408	val: 0.837699	test: 0.708719
PRC train: 0.999887	val: 0.736064	test: 0.746867

Epoch: 42
Loss: 0.09026872174150993
ROC train: 0.999672	val: 0.844525	test: 0.710552
PRC train: 0.999938	val: 0.745924	test: 0.762556

Epoch: 43
Loss: 0.07437208466231059
ROC train: 0.999748	val: 0.826659	test: 0.682870
PRC train: 0.999952	val: 0.685486	test: 0.702975

Epoch: 44
Loss: 0.08166167672831391
ROC train: 0.999849	val: 0.828064	test: 0.684028
PRC train: 0.999971	val: 0.689367	test: 0.713410

Epoch: 45
Loss: 0.07694408986620971
ROC train: 0.999885	val: 0.841212	test: 0.684124
PRC train: 0.999978	val: 0.693767	test: 0.702059

Epoch: 46
Loss: 0.07615827758623335
ROC train: 0.999823	val: 0.836696	test: 0.676698
PRC train: 0.999966	val: 0.710623	test: 0.728550

Epoch: 47
Loss: 0.07547467256105277
ROC train: 0.999921	val: 0.838201	test: 0.698399
PRC train: 0.999985	val: 0.704547	test: 0.742062

Epoch: 48
Loss: 0.06468277270365443
ROC train: 0.999955	val: 0.836897	test: 0.702643
PRC train: 0.999992	val: 0.726490	test: 0.755403

Epoch: 49
Loss: 0.06309904156409349
ROC train: 0.999891	val: 0.831978	test: 0.712770
PRC train: 0.999979	val: 0.716472	test: 0.762299

Epoch: 50
Loss: 0.057314122519393315
ROC train: 0.999927	val: 0.824852	test: 0.705440
PRC train: 0.999986	val: 0.722298	test: 0.760381

Epoch: 51
Loss: 0.06778011643445556
ROC train: 0.999950	val: 0.812205	test: 0.694637
PRC train: 0.999990	val: 0.716177	test: 0.734968

Epoch: 52
Loss: 0.06448276154874605
ROC train: 0.999891	val: 0.834186	test: 0.690201
PRC train: 0.999979	val: 0.744254	test: 0.743111

Epoch: 53
Loss: 0.07061782612368353
ROC train: 0.999820	val: 0.819532	test: 0.704668
PRC train: 0.999966	val: 0.697008	test: 0.773911

Epoch: 54
Loss: 0.06987135759543366
ROC train: 0.999425	val: 0.810599	test: 0.698110
PRC train: 0.999896	val: 0.637692	test: 0.737108

Epoch: 55
Loss: 0.05071183086828718
ROC train: 0.999921	val: 0.819332	test: 0.690586
PRC train: 0.999985	val: 0.634841	test: 0.704103

Epoch: 56
Loss: 0.06106577101102944
ROC train: 0.999966	val: 0.842818	test: 0.689815
PRC train: 0.999994	val: 0.682509	test: 0.720320

Epoch: 57
Loss: 0.06087814065195243
ROC train: 0.999891	val: 0.835792	test: 0.714120
PRC train: 0.999979	val: 0.733418	test: 0.752671

Epoch: 58
Loss: 0.05426715472497672
ROC train: 0.999961	val: 0.845629	test: 0.706308
PRC train: 0.999993	val: 0.761691	test: 0.751901

Epoch: 59
Loss: 0.05091047235040543
ROC train: 0.999986	val: 0.845629	test: 0.708526
PRC train: 0.999997	val: 0.747349	test: 0.746378

Epoch: 60
Loss: 0.05914023593956164
ROC train: 0.999997	val: 0.826558	test: 0.696084
PRC train: 0.999999	val: 0.727368	test: 0.747549

Epoch: 61
Loss: 0.04342184847083865
ROC train: 0.999994	val: 0.836094	test: 0.702643
PRC train: 0.999999	val: 0.710385	test: 0.759648

Epoch: 62
Loss: 0.0417498280846172
ROC train: 0.999997	val: 0.828064	test: 0.698399
PRC train: 0.999999	val: 0.728755	test: 0.746188

Epoch: 63
Loss: 0.04479584708565963
ROC train: 0.999986	val: 0.821841	test: 0.695216
PRC train: 0.999997	val: 0.731033	test: 0.725471

Epoch: 64
Loss: 0.04443395903182914
ROC train: 0.999989	val: 0.852454	test: 0.704186
PRC train: 0.999998	val: 0.770320	test: 0.740233

Epoch: 65
Loss: 0.06407968896723794
ROC train: 0.999952	val: 0.832279	test: 0.700039
PRC train: 0.999991	val: 0.723985	test: 0.722175

Epoch: 66
Loss: 0.05790215262666369
ROC train: 0.999913	val: 0.824250	test: 0.708816
PRC train: 0.999983	val: 0.691860	test: 0.731537

Epoch: 67
Loss: 0.04992725736605967
ROC train: 0.999969	val: 0.837499	test: 0.704475
PRC train: 0.999994	val: 0.755483	test: 0.758984

Epoch: 68
Loss: 0.038302429256758815
ROC train: 1.000000	val: 0.857573	test: 0.696566
PRC train: 1.000000	val: 0.793625	test: 0.748593

Epoch: 69
Loss: 0.038939344889404585
ROC train: 0.999992	val: 0.846331	test: 0.694541
PRC train: 0.999998	val: 0.766229	test: 0.729761

Epoch: 70
Loss: 0.04569872618579491
ROC train: 0.999983	val: 0.855064	test: 0.696470
PRC train: 0.999997	val: 0.763212	test: 0.723627

Epoch: 71
Loss: 0.04437773768640333
ROC train: 0.999978	val: 0.815417	test: 0.688947
PRC train: 0.999996	val: 0.681841	test: 0.717523

Epoch: 72
Loss: 0.046660807236513877
ROC train: 1.000000	val: 0.835491	test: 0.697531
PRC train: 1.000000	val: 0.681685	test: 0.736645

Epoch: 73
Loss: 0.04810947010205447
ROC train: 1.000000	val: 0.854963	test: 0.700424
PRC train: 1.000000	val: 0.747348	test: 0.745445

Epoch: 74
Loss: 0.04843780933191761
ROC train: 1.000000	val: 0.823146	test: 0.686728
PRC train: 1.000000	val: 0.720623	test: 0.723332

Epoch: 75
Loss: 0.042312819584373176
ROC train: 1.000000	val: 0.849945	test: 0.696277
PRC train: 1.000000	val: 0.764672	test: 0.726341

Epoch: 76
Loss: 0.042350881882077494
ROC train: 1.000000	val: 0.849543	test: 0.705247
PRC train: 1.000000	val: 0.762779	test: 0.734809

Epoch: 77
Loss: 0.033525641853582325
ROC train: 1.000000	val: 0.849945	test: 0.698785
PRC train: 1.000000	val: 0.756601	test: 0.743230

Epoch: 78
Loss: 0.03640473104080083
ROC train: 1.000000	val: 0.849744	test: 0.698592
PRC train: 1.000000	val: 0.757936	test: 0.747155

Epoch: 79
Loss: 0.0322022396163502
ROC train: 1.000000	val: 0.846833	test: 0.695602
PRC train: 1.000000	val: 0.763735	test: 0.732790

Epoch: 80
Loss: 0.03512192925300547
ROC train: 1.000000	val: 0.859179	test: 0.699749
PRC train: 1.000000	val: 0.778442	test: 0.744164

Epoch: 81
Loss: 0.03438930214304494
ROC train: 1.000000	val: 0.850647	test: 0.712095
PRC train: 1.000000	val: 0.767870	test: 0.754306

Epoch: 82
Loss: 0.02775604413494139
ROC train: 0.999986	val: 0.857272	test: 0.718654
PRC train: 0.999997	val: 0.780846	test: 0.753483

Epoch: 83
Loss: 0.026996440197998333
ROC train: 1.000000	val: 0.847737	test: 0.705150
PRC train: 1.000000	val: 0.773632	test: 0.734589

Epoch: 84
Loss: 0.040587843388200935
ROC train: 1.000000	val: 0.835792	test: 0.697917
PRC train: 1.000000	val: 0.724817	test: 0.738679

Epoch: 85
Loss: 0.029731141223392342
ROC train: 0.999756	val: 0.815618	test: 0.704765
PRC train: 0.999955	val: 0.677084	test: 0.739544

Epoch: 86
Loss: 0.03900818824312385
ROC train: 0.999630	val: 0.816220	test: 0.701678
PRC train: 0.999928	val: 0.685204	test: 0.731994

Epoch: 87
Loss: 0.029905944667336346
ROC train: 1.000000	val: 0.834387	test: 0.706019
PRC train: 1.000000	val: 0.716054	test: 0.734670

Epoch: 88
Loss: 0.03166726783527728
ROC train: 1.000000	val: 0.852253	test: 0.695988
PRC train: 1.000000	val: 0.703510	test: 0.714138

Epoch: 89
Loss: 0.033495805617558064
ROC train: 1.000000	val: 0.849844	test: 0.691454
PRC train: 1.000000	val: 0.701503	test: 0.707509

Epoch: 90
Loss: 0.027849815609164975
ROC train: 1.000000	val: 0.834387	test: 0.690490
PRC train: 1.000000	val: 0.734715	test: 0.712970

Epoch: 91
Loss: 0.025643744835122224
ROC train: 1.000000	val: 0.823647	test: 0.692130
PRC train: 1.000000	val: 0.697069	test: 0.709551

Epoch: 92
Loss: 0.04187368199871395
ROC train: 1.000000	val: 0.824752	test: 0.687018
PRC train: 1.000000	val: 0.690751	test: 0.702603

Epoch: 93
Loss: 0.02557020549236528
PRC train: 0.999836	val: 0.784501	test: 0.727880

Epoch: 33
Loss: 0.11687986940682261
ROC train: 0.999029	val: 0.878450	test: 0.659626
PRC train: 0.999816	val: 0.762021	test: 0.734019

Epoch: 34
Loss: 0.13227400517725144
ROC train: 0.999383	val: 0.859781	test: 0.657022
PRC train: 0.999881	val: 0.774609	test: 0.708285

Epoch: 35
Loss: 0.10792601013744327
ROC train: 0.999015	val: 0.847737	test: 0.653356
PRC train: 0.999809	val: 0.734970	test: 0.683802

Epoch: 36
Loss: 0.10332679600259817
ROC train: 0.999254	val: 0.882565	test: 0.647666
PRC train: 0.999858	val: 0.796857	test: 0.699783

Epoch: 37
Loss: 0.09349085375266178
ROC train: 0.999818	val: 0.895012	test: 0.672261
PRC train: 0.999965	val: 0.838574	test: 0.705823

Epoch: 38
Loss: 0.08492040689184928
ROC train: 0.999787	val: 0.877748	test: 0.644676
PRC train: 0.999959	val: 0.809097	test: 0.686240

Epoch: 39
Loss: 0.09734810964042796
ROC train: 0.999888	val: 0.830071	test: 0.625000
PRC train: 0.999979	val: 0.720241	test: 0.656050

Epoch: 40
Loss: 0.10406401278738239
ROC train: 0.999849	val: 0.843822	test: 0.623650
PRC train: 0.999971	val: 0.739198	test: 0.658999

Epoch: 41
Loss: 0.07974831044273421
ROC train: 0.999826	val: 0.875941	test: 0.647762
PRC train: 0.999967	val: 0.786915	test: 0.705181

Epoch: 42
Loss: 0.0717758344793994
ROC train: 0.999888	val: 0.873632	test: 0.659144
PRC train: 0.999979	val: 0.787738	test: 0.735731

Epoch: 43
Loss: 0.06565669167666924
ROC train: 0.999604	val: 0.878250	test: 0.656346
PRC train: 0.999924	val: 0.802749	test: 0.728360

Epoch: 44
Loss: 0.0809926827781703
ROC train: 0.999694	val: 0.879554	test: 0.641011
PRC train: 0.999942	val: 0.774678	test: 0.678787

Epoch: 45
Loss: 0.08751046707782904
ROC train: 0.999961	val: 0.868413	test: 0.639564
PRC train: 0.999993	val: 0.751775	test: 0.698357

Epoch: 46
Loss: 0.07912436483604131
ROC train: 0.999947	val: 0.870822	test: 0.655768
PRC train: 0.999990	val: 0.773791	test: 0.734991

Epoch: 47
Loss: 0.08757623884570268
ROC train: 0.999958	val: 0.873934	test: 0.652585
PRC train: 0.999992	val: 0.765245	test: 0.739436

Epoch: 48
Loss: 0.08266379623716938
ROC train: 0.999834	val: 0.866105	test: 0.638310
PRC train: 0.999969	val: 0.727621	test: 0.685880

Epoch: 49
Loss: 0.07365232612528608
ROC train: 0.999947	val: 0.826358	test: 0.601852
PRC train: 0.999990	val: 0.688420	test: 0.635271

Epoch: 50
Loss: 0.06015401443568734
ROC train: 0.999964	val: 0.854763	test: 0.611786
PRC train: 0.999993	val: 0.761776	test: 0.644101

Epoch: 51
Loss: 0.07017181406658103
ROC train: 0.999896	val: 0.868313	test: 0.640046
PRC train: 0.999980	val: 0.768484	test: 0.701648

Epoch: 52
Loss: 0.057896382829685344
ROC train: 0.999975	val: 0.881963	test: 0.653646
PRC train: 0.999995	val: 0.811169	test: 0.726371

Epoch: 53
Loss: 0.0514112730248522
ROC train: 0.999972	val: 0.895915	test: 0.659722
PRC train: 0.999995	val: 0.811448	test: 0.720137

Epoch: 54
Loss: 0.07216841924364961
ROC train: 0.999941	val: 0.840008	test: 0.630883
PRC train: 0.999989	val: 0.718866	test: 0.697287

Epoch: 55
Loss: 0.05255703344550111
ROC train: 0.999964	val: 0.842718	test: 0.630112
PRC train: 0.999993	val: 0.723041	test: 0.701168

Epoch: 56
Loss: 0.047306114957752374
ROC train: 0.999935	val: 0.873833	test: 0.647473
PRC train: 0.999988	val: 0.765655	test: 0.726463

Epoch: 57
Loss: 0.055973074842947786
ROC train: 0.999927	val: 0.873030	test: 0.639660
PRC train: 0.999986	val: 0.750046	test: 0.724188

Epoch: 58
Loss: 0.053467691091251886
ROC train: 0.999882	val: 0.852956	test: 0.642361
PRC train: 0.999978	val: 0.728041	test: 0.713678

Epoch: 59
Loss: 0.047645710183483785
ROC train: 0.999992	val: 0.850146	test: 0.642843
PRC train: 0.999998	val: 0.752952	test: 0.713845

Epoch: 60
Loss: 0.06536804098968071
ROC train: 0.999983	val: 0.855465	test: 0.633005
PRC train: 0.999997	val: 0.769756	test: 0.718107

Epoch: 61
Loss: 0.05504425800529902
ROC train: 0.999994	val: 0.870421	test: 0.646026
PRC train: 0.999999	val: 0.781870	test: 0.713119

Epoch: 62
Loss: 0.05536834394889075
ROC train: 0.999994	val: 0.868614	test: 0.646026
PRC train: 0.999999	val: 0.780336	test: 0.716354

Epoch: 63
Loss: 0.04995928538965681
ROC train: 1.000000	val: 0.872829	test: 0.650077
PRC train: 1.000000	val: 0.784749	test: 0.715705

Epoch: 64
Loss: 0.04540700076509875
ROC train: 0.999952	val: 0.849242	test: 0.656250
PRC train: 0.999991	val: 0.734978	test: 0.722825

Epoch: 65
Loss: 0.0649435101200367
ROC train: 0.999992	val: 0.842919	test: 0.636092
PRC train: 0.999998	val: 0.744982	test: 0.703225

Epoch: 66
Loss: 0.04622374053370953
ROC train: 0.999585	val: 0.828867	test: 0.636960
PRC train: 0.999917	val: 0.689397	test: 0.695026

Epoch: 67
Loss: 0.04948388603190477
ROC train: 0.999950	val: 0.864800	test: 0.646123
PRC train: 0.999990	val: 0.771968	test: 0.731446

Epoch: 68
Loss: 0.03396151854783631
ROC train: 1.000000	val: 0.882465	test: 0.660204
PRC train: 1.000000	val: 0.821664	test: 0.728316

Epoch: 69
Loss: 0.05188345984346761
ROC train: 0.999997	val: 0.865502	test: 0.671489
PRC train: 0.999999	val: 0.797280	test: 0.750551

Epoch: 70
Loss: 0.04800556474692451
ROC train: 0.999994	val: 0.852454	test: 0.661651
PRC train: 0.999999	val: 0.725552	test: 0.722938

Epoch: 71
Loss: 0.04235618966609818
ROC train: 1.000000	val: 0.854060	test: 0.645737
PRC train: 1.000000	val: 0.729967	test: 0.674423

Epoch: 72
Loss: 0.040268803672611576
ROC train: 0.999997	val: 0.849443	test: 0.642554
PRC train: 0.999999	val: 0.715744	test: 0.662043

Epoch: 73
Loss: 0.029063896612339993
ROC train: 0.999975	val: 0.859480	test: 0.657697
PRC train: 0.999995	val: 0.711721	test: 0.706695

Epoch: 74
Loss: 0.040631757867208886
ROC train: 1.000000	val: 0.863294	test: 0.650463
PRC train: 1.000000	val: 0.741545	test: 0.725791

Epoch: 75
Loss: 0.03698181691050349
ROC train: 1.000000	val: 0.860484	test: 0.662519
PRC train: 1.000000	val: 0.758314	test: 0.733627

Epoch: 76
Loss: 0.04123341971558959
ROC train: 1.000000	val: 0.859580	test: 0.638310
PRC train: 1.000000	val: 0.748150	test: 0.713787

Epoch: 77
Loss: 0.035486910348081
ROC train: 0.999997	val: 0.853257	test: 0.621046
PRC train: 0.999999	val: 0.740854	test: 0.677951

Epoch: 78
Loss: 0.03799272773525409
ROC train: 1.000000	val: 0.860584	test: 0.629823
PRC train: 1.000000	val: 0.744886	test: 0.668439

Epoch: 79
Loss: 0.03230147265225428
ROC train: 1.000000	val: 0.856268	test: 0.617380
PRC train: 1.000000	val: 0.735564	test: 0.689040

Epoch: 80
Loss: 0.021947907162733284
ROC train: 1.000000	val: 0.863093	test: 0.629340
PRC train: 1.000000	val: 0.758452	test: 0.700843

Epoch: 81
Loss: 0.03271812721439389
ROC train: 1.000000	val: 0.867008	test: 0.641975
PRC train: 1.000000	val: 0.757479	test: 0.717528

Epoch: 82
Loss: 0.021048628783559488
ROC train: 1.000000	val: 0.854562	test: 0.634163
PRC train: 1.000000	val: 0.708100	test: 0.688648

Epoch: 83
Loss: 0.04480664932863284
ROC train: 1.000000	val: 0.852354	test: 0.646894
PRC train: 1.000000	val: 0.723927	test: 0.689807

Epoch: 84
Loss: 0.04047556540189098
ROC train: 1.000000	val: 0.842517	test: 0.638600
PRC train: 1.000000	val: 0.709532	test: 0.680636

Epoch: 85
Loss: 0.022575778114975083
ROC train: 1.000000	val: 0.866807	test: 0.643808
PRC train: 1.000000	val: 0.759510	test: 0.691538

Epoch: 86
Loss: 0.02344946912195713
ROC train: 1.000000	val: 0.868212	test: 0.648052
PRC train: 1.000000	val: 0.753058	test: 0.711561

Epoch: 87
Loss: 0.020842858182758356
ROC train: 1.000000	val: 0.864699	test: 0.650077
PRC train: 1.000000	val: 0.730882	test: 0.719773

Epoch: 88
Loss: 0.028912059185226102
ROC train: 1.000000	val: 0.846331	test: 0.620370
PRC train: 1.000000	val: 0.729034	test: 0.671635

Epoch: 89
Loss: 0.0223111386482735
ROC train: 1.000000	val: 0.848138	test: 0.604552
PRC train: 1.000000	val: 0.737635	test: 0.635595

Epoch: 90
Loss: 0.02630055836063031
ROC train: 1.000000	val: 0.857071	test: 0.631559
PRC train: 1.000000	val: 0.737322	test: 0.698870

Epoch: 91
Loss: 0.02721651401549477
ROC train: 1.000000	val: 0.863896	test: 0.630594
PRC train: 1.000000	val: 0.740076	test: 0.711118

Epoch: 92
Loss: 0.020739107491958324
ROC train: 1.000000	val: 0.862290	test: 0.631559
PRC train: 1.000000	val: 0.741662	test: 0.684181

Epoch: 93
Loss: 0.020586637908997226
PRC train: 0.999837	val: 0.780206	test: 0.768211

Epoch: 33
Loss: 0.11464294805825108
ROC train: 0.994945	val: 0.855365	test: 0.709105
PRC train: 0.998998	val: 0.731066	test: 0.761614

Epoch: 34
Loss: 0.12608121302073902
ROC train: 0.998718	val: 0.863294	test: 0.692130
PRC train: 0.999755	val: 0.732920	test: 0.749128

Epoch: 35
Loss: 0.111442938299077
ROC train: 0.999038	val: 0.824049	test: 0.675154
PRC train: 0.999817	val: 0.688659	test: 0.724329

Epoch: 36
Loss: 0.10654799686235124
ROC train: 0.999262	val: 0.847134	test: 0.688272
PRC train: 0.999860	val: 0.729437	test: 0.737999

Epoch: 37
Loss: 0.10543738123040265
ROC train: 0.999638	val: 0.871023	test: 0.705247
PRC train: 0.999931	val: 0.796414	test: 0.753278

Epoch: 38
Loss: 0.10572638856617464
ROC train: 0.999784	val: 0.860885	test: 0.709780
PRC train: 0.999959	val: 0.752454	test: 0.761034

Epoch: 39
Loss: 0.09053388298666662
ROC train: 0.998609	val: 0.852454	test: 0.692323
PRC train: 0.999722	val: 0.723960	test: 0.742309

Epoch: 40
Loss: 0.0838697899317793
ROC train: 0.999506	val: 0.860484	test: 0.697049
PRC train: 0.999905	val: 0.736552	test: 0.751628

Epoch: 41
Loss: 0.09270630486619481
ROC train: 0.999680	val: 0.855967	test: 0.699846
PRC train: 0.999938	val: 0.725043	test: 0.760863

Epoch: 42
Loss: 0.08783423858683508
ROC train: 0.999315	val: 0.835893	test: 0.704379
PRC train: 0.999866	val: 0.695960	test: 0.762405

Epoch: 43
Loss: 0.07764167831584241
ROC train: 0.999952	val: 0.857975	test: 0.706694
PRC train: 0.999991	val: 0.752899	test: 0.768606

Epoch: 44
Loss: 0.08587519803683621
ROC train: 0.999658	val: 0.851250	test: 0.694252
PRC train: 0.999935	val: 0.746617	test: 0.769662

Epoch: 45
Loss: 0.08139487632567934
ROC train: 0.999627	val: 0.870521	test: 0.722512
PRC train: 0.999929	val: 0.786964	test: 0.784992

Epoch: 46
Loss: 0.07000203503933504
ROC train: 0.999837	val: 0.863997	test: 0.721161
PRC train: 0.999970	val: 0.764126	test: 0.784179

Epoch: 47
Loss: 0.08177618698146485
ROC train: 0.997557	val: 0.841313	test: 0.709684
PRC train: 0.999521	val: 0.717429	test: 0.752899

Epoch: 48
Loss: 0.06427156077795898
ROC train: 0.999961	val: 0.877246	test: 0.719907
PRC train: 0.999993	val: 0.800943	test: 0.780070

Epoch: 49
Loss: 0.08442933254716656
ROC train: 0.999997	val: 0.866606	test: 0.714410
PRC train: 0.999999	val: 0.783627	test: 0.780182

Epoch: 50
Loss: 0.06732554290055377
ROC train: 0.999961	val: 0.843722	test: 0.701100
PRC train: 0.999993	val: 0.719630	test: 0.754576

Epoch: 51
Loss: 0.08217072589012905
ROC train: 0.999958	val: 0.825053	test: 0.706983
PRC train: 0.999992	val: 0.702914	test: 0.763618

Epoch: 52
Loss: 0.0669111815727629
ROC train: 0.999944	val: 0.833283	test: 0.701775
PRC train: 0.999989	val: 0.744521	test: 0.758256

Epoch: 53
Loss: 0.07138156652861596
ROC train: 0.999955	val: 0.859580	test: 0.703800
PRC train: 0.999992	val: 0.776574	test: 0.768497

Epoch: 54
Loss: 0.054199249285614814
ROC train: 1.000000	val: 0.837599	test: 0.687789
PRC train: 1.000000	val: 0.710470	test: 0.752902

Epoch: 55
Loss: 0.05521297170226431
ROC train: 1.000000	val: 0.841514	test: 0.693191
PRC train: 1.000000	val: 0.742679	test: 0.759901

Epoch: 56
Loss: 0.05895154373681322
ROC train: 0.999997	val: 0.856670	test: 0.699942
PRC train: 0.999999	val: 0.733671	test: 0.732799

Epoch: 57
Loss: 0.054069525350258156
ROC train: 0.999983	val: 0.874636	test: 0.703414
PRC train: 0.999997	val: 0.757924	test: 0.761704

Epoch: 58
Loss: 0.04810522253581549
ROC train: 0.999997	val: 0.877547	test: 0.710455
PRC train: 0.999999	val: 0.758987	test: 0.778298

Epoch: 59
Loss: 0.05371544663775753
ROC train: 0.999992	val: 0.878751	test: 0.715664
PRC train: 0.999998	val: 0.767426	test: 0.776444

Epoch: 60
Loss: 0.04740235743784902
ROC train: 0.999969	val: 0.882967	test: 0.707755
PRC train: 0.999994	val: 0.781804	test: 0.716095

Epoch: 61
Loss: 0.047703898787649086
ROC train: 0.999983	val: 0.854863	test: 0.714313
PRC train: 0.999997	val: 0.714248	test: 0.774800

Epoch: 62
Loss: 0.04793979375593597
ROC train: 0.999972	val: 0.867510	test: 0.711998
PRC train: 0.999995	val: 0.728387	test: 0.768690

Epoch: 63
Loss: 0.051650391142342
ROC train: 0.999955	val: 0.846131	test: 0.697049
PRC train: 0.999991	val: 0.718362	test: 0.759004

Epoch: 64
Loss: 0.05297700203639669
ROC train: 0.999997	val: 0.880357	test: 0.710552
PRC train: 0.999999	val: 0.753809	test: 0.770493

Epoch: 65
Loss: 0.048264739134220684
ROC train: 1.000000	val: 0.877848	test: 0.696084
PRC train: 1.000000	val: 0.781933	test: 0.749672

Epoch: 66
Loss: 0.06116903645106232
ROC train: 0.999885	val: 0.847536	test: 0.690779
PRC train: 0.999978	val: 0.721163	test: 0.741588

Epoch: 67
Loss: 0.05268008634050854
ROC train: 0.999989	val: 0.835491	test: 0.690586
PRC train: 0.999998	val: 0.736986	test: 0.730178

Epoch: 68
Loss: 0.04699011362955168
ROC train: 1.000000	val: 0.827863	test: 0.687982
PRC train: 1.000000	val: 0.734965	test: 0.748266

Epoch: 69
Loss: 0.031788131946154305
ROC train: 1.000000	val: 0.842517	test: 0.702160
PRC train: 1.000000	val: 0.742012	test: 0.759879

Epoch: 70
Loss: 0.03558858715220002
ROC train: 0.999997	val: 0.859781	test: 0.703607
PRC train: 0.999999	val: 0.763571	test: 0.764137

Epoch: 71
Loss: 0.039277112922872996
ROC train: 1.000000	val: 0.873532	test: 0.710069
PRC train: 1.000000	val: 0.786515	test: 0.768630

Epoch: 72
Loss: 0.052336924463348984
ROC train: 1.000000	val: 0.871725	test: 0.723765
PRC train: 1.000000	val: 0.783725	test: 0.781072

Epoch: 73
Loss: 0.04812158903402495
ROC train: 0.999997	val: 0.860283	test: 0.710648
PRC train: 0.999999	val: 0.745379	test: 0.769798

Epoch: 74
Loss: 0.03677011009398989
ROC train: 1.000000	val: 0.816521	test: 0.692998
PRC train: 1.000000	val: 0.689380	test: 0.742301

Epoch: 75
Loss: 0.0448089154465207
ROC train: 0.999975	val: 0.833283	test: 0.703318
PRC train: 0.999995	val: 0.701852	test: 0.750491

Epoch: 76
Loss: 0.04237779178692761
ROC train: 1.000000	val: 0.859279	test: 0.708333
PRC train: 1.000000	val: 0.768368	test: 0.757211

Epoch: 77
Loss: 0.04116115016764411
ROC train: 0.999980	val: 0.869015	test: 0.704475
PRC train: 0.999996	val: 0.807141	test: 0.758268

Epoch: 78
Loss: 0.026222885949524606
ROC train: 1.000000	val: 0.878049	test: 0.704282
PRC train: 1.000000	val: 0.795499	test: 0.757205

Epoch: 79
Loss: 0.030552878080236674
ROC train: 1.000000	val: 0.874536	test: 0.711516
PRC train: 1.000000	val: 0.809412	test: 0.766060

Epoch: 80
Loss: 0.03391021263316914
ROC train: 1.000000	val: 0.869316	test: 0.714217
PRC train: 1.000000	val: 0.802701	test: 0.776016

Epoch: 81
Loss: 0.03884439834153008
ROC train: 1.000000	val: 0.865302	test: 0.704090
PRC train: 1.000000	val: 0.779847	test: 0.752218

Epoch: 82
Loss: 0.023879623666231496
ROC train: 1.000000	val: 0.838101	test: 0.693866
PRC train: 1.000000	val: 0.725399	test: 0.747868

Epoch: 83
Loss: 0.031046186592301742
ROC train: 1.000000	val: 0.852454	test: 0.707272
PRC train: 1.000000	val: 0.732287	test: 0.770855

Epoch: 84
Loss: 0.03232960937807728
ROC train: 0.999969	val: 0.852053	test: 0.700135
PRC train: 0.999994	val: 0.728332	test: 0.768461

Epoch: 85
Loss: 0.03466594111471677
ROC train: 1.000000	val: 0.853759	test: 0.707369
PRC train: 1.000000	val: 0.727001	test: 0.777308

Epoch: 86
Loss: 0.03503501330884588
ROC train: 1.000000	val: 0.839305	test: 0.713735
PRC train: 1.000000	val: 0.731109	test: 0.783147

Epoch: 87
Loss: 0.034763659946701955
ROC train: 1.000000	val: 0.847235	test: 0.715181
PRC train: 1.000000	val: 0.731821	test: 0.789272

Epoch: 88
Loss: 0.026074396065222015
ROC train: 1.000000	val: 0.861287	test: 0.727141
PRC train: 1.000000	val: 0.750580	test: 0.800378

Epoch: 89
Loss: 0.029543807366495495
ROC train: 1.000000	val: 0.870822	test: 0.723380
PRC train: 1.000000	val: 0.773785	test: 0.789226

Epoch: 90
Loss: 0.02831587286187709
ROC train: 1.000000	val: 0.870922	test: 0.711806
PRC train: 1.000000	val: 0.774970	test: 0.776755

Epoch: 91
Loss: 0.02726343690288145
ROC train: 0.999669	val: 0.844023	test: 0.692612
PRC train: 0.999935	val: 0.715805	test: 0.750651

Epoch: 92
Loss: 0.02671345453086674
ROC train: 0.999722	val: 0.863395	test: 0.700617
PRC train: 0.999945	val: 0.723865	test: 0.761580

Epoch: 93
Loss: 0.03025396281865553
PRC train: 0.999798	val: 0.734934	test: 0.691401

Epoch: 33
Loss: 0.1216956640515616
ROC train: 0.999114	val: 0.852253	test: 0.609568
PRC train: 0.999832	val: 0.749462	test: 0.672355

Epoch: 34
Loss: 0.1274372850200631
ROC train: 0.999433	val: 0.824250	test: 0.587288
PRC train: 0.999892	val: 0.705275	test: 0.625997

Epoch: 35
Loss: 0.12080944102946058
ROC train: 0.999776	val: 0.794941	test: 0.580633
PRC train: 0.999958	val: 0.659393	test: 0.597555

Epoch: 36
Loss: 0.1169837874633477
ROC train: 0.999935	val: 0.822343	test: 0.592303
PRC train: 0.999988	val: 0.699121	test: 0.608719

Epoch: 37
Loss: 0.11551021678720609
ROC train: 0.999882	val: 0.828465	test: 0.609279
PRC train: 0.999978	val: 0.695908	test: 0.620490

Epoch: 38
Loss: 0.11230079754332192
ROC train: 0.999798	val: 0.824551	test: 0.622299
PRC train: 0.999962	val: 0.694334	test: 0.678510

Epoch: 39
Loss: 0.09285520719764273
ROC train: 0.999888	val: 0.844725	test: 0.633005
PRC train: 0.999979	val: 0.726029	test: 0.691745

Epoch: 40
Loss: 0.0952755865095253
ROC train: 0.999950	val: 0.813410	test: 0.606867
PRC train: 0.999990	val: 0.673427	test: 0.658908

Epoch: 41
Loss: 0.1035636756710555
ROC train: 0.999933	val: 0.791428	test: 0.602527
PRC train: 0.999987	val: 0.625049	test: 0.609230

Epoch: 42
Loss: 0.09602495266575296
ROC train: 0.999964	val: 0.822042	test: 0.619309
PRC train: 0.999993	val: 0.661256	test: 0.641917

Epoch: 43
Loss: 0.0884263829016904
ROC train: 0.999933	val: 0.809796	test: 0.636574
PRC train: 0.999987	val: 0.633809	test: 0.700169

Epoch: 44
Loss: 0.07723936624426485
ROC train: 0.999972	val: 0.840711	test: 0.654803
PRC train: 0.999995	val: 0.701157	test: 0.691378

Epoch: 45
Loss: 0.07876485019351229
ROC train: 0.999958	val: 0.852253	test: 0.637442
PRC train: 0.999992	val: 0.720987	test: 0.655988

Epoch: 46
Loss: 0.07584561500529792
ROC train: 0.999795	val: 0.843521	test: 0.651427
PRC train: 0.999963	val: 0.718768	test: 0.708863

Epoch: 47
Loss: 0.07356658844235252
ROC train: 0.999969	val: 0.837800	test: 0.627990
PRC train: 0.999994	val: 0.696085	test: 0.662163

Epoch: 48
Loss: 0.06675799576213821
ROC train: 0.999989	val: 0.817123	test: 0.611979
PRC train: 0.999998	val: 0.663013	test: 0.612579

Epoch: 49
Loss: 0.07361063940800176
ROC train: 0.999994	val: 0.840711	test: 0.625386
PRC train: 0.999999	val: 0.704445	test: 0.623014

Epoch: 50
Loss: 0.07124506365354107
ROC train: 1.000000	val: 0.847134	test: 0.635995
PRC train: 1.000000	val: 0.727599	test: 0.664246

Epoch: 51
Loss: 0.07239056538526203
ROC train: 1.000000	val: 0.822343	test: 0.626350
PRC train: 1.000000	val: 0.670129	test: 0.656875

Epoch: 52
Loss: 0.04872331079177739
ROC train: 1.000000	val: 0.804276	test: 0.633970
PRC train: 1.000000	val: 0.640726	test: 0.697553

Epoch: 53
Loss: 0.05785828518741951
ROC train: 0.999997	val: 0.795242	test: 0.608410
PRC train: 0.999999	val: 0.626869	test: 0.621677

Epoch: 54
Loss: 0.0700214468831905
ROC train: 1.000000	val: 0.805280	test: 0.608507
PRC train: 1.000000	val: 0.647129	test: 0.621075

Epoch: 55
Loss: 0.045276914220943085
ROC train: 1.000000	val: 0.824149	test: 0.612847
PRC train: 1.000000	val: 0.675426	test: 0.656864

Epoch: 56
Loss: 0.08343777519971463
ROC train: 1.000000	val: 0.835190	test: 0.620563
PRC train: 1.000000	val: 0.688423	test: 0.651471

Epoch: 57
Loss: 0.0494224407485661
ROC train: 0.999992	val: 0.825755	test: 0.629630
PRC train: 0.999998	val: 0.682126	test: 0.646858

Epoch: 58
Loss: 0.04929140146570255
ROC train: 0.999994	val: 0.794640	test: 0.596451
PRC train: 0.999999	val: 0.642160	test: 0.609656

Epoch: 59
Loss: 0.052415613388031024
ROC train: 1.000000	val: 0.828666	test: 0.634549
PRC train: 1.000000	val: 0.696391	test: 0.643111

Epoch: 60
Loss: 0.06293043768762865
ROC train: 1.000000	val: 0.794239	test: 0.623360
PRC train: 1.000000	val: 0.626856	test: 0.644490

Epoch: 61
Loss: 0.051283445548668996
ROC train: 1.000000	val: 0.795945	test: 0.637056
PRC train: 1.000000	val: 0.611916	test: 0.693269

Epoch: 62
Loss: 0.05695800606211671
ROC train: 1.000000	val: 0.814915	test: 0.630401
PRC train: 1.000000	val: 0.645369	test: 0.685599

Epoch: 63
Loss: 0.04954157595632994
ROC train: 1.000000	val: 0.785506	test: 0.579572
PRC train: 1.000000	val: 0.634098	test: 0.603969

Epoch: 64
Loss: 0.05529693190501266
ROC train: 1.000000	val: 0.812306	test: 0.610436
PRC train: 1.000000	val: 0.673375	test: 0.625069

Epoch: 65
Loss: 0.058800129963291266
ROC train: 1.000000	val: 0.786912	test: 0.599441
PRC train: 1.000000	val: 0.630771	test: 0.590661

Epoch: 66
Loss: 0.049854742830610595
ROC train: 1.000000	val: 0.810499	test: 0.584877
PRC train: 1.000000	val: 0.687380	test: 0.580780

Epoch: 67
Loss: 0.05234376823724694
ROC train: 1.000000	val: 0.828164	test: 0.630787
PRC train: 1.000000	val: 0.697801	test: 0.696386

Epoch: 68
Loss: 0.04560506824065772
ROC train: 1.000000	val: 0.833484	test: 0.659047
PRC train: 1.000000	val: 0.690407	test: 0.737343

Epoch: 69
Loss: 0.046818382762182545
ROC train: 1.000000	val: 0.825856	test: 0.640721
PRC train: 1.000000	val: 0.688821	test: 0.711806

Epoch: 70
Loss: 0.03891788922467324
ROC train: 1.000000	val: 0.830172	test: 0.626929
PRC train: 1.000000	val: 0.692145	test: 0.713098

Epoch: 71
Loss: 0.03952972892061485
ROC train: 1.000000	val: 0.827462	test: 0.615162
PRC train: 1.000000	val: 0.732633	test: 0.684838

Epoch: 72
Loss: 0.0477846261047926
ROC train: 1.000000	val: 0.817525	test: 0.597897
PRC train: 1.000000	val: 0.704643	test: 0.659369

Epoch: 73
Loss: 0.030671257993937405
ROC train: 1.000000	val: 0.800361	test: 0.600984
PRC train: 1.000000	val: 0.673115	test: 0.665651

Epoch: 74
Loss: 0.04655649860487875
ROC train: 1.000000	val: 0.805480	test: 0.592882
PRC train: 1.000000	val: 0.680767	test: 0.661425

Epoch: 75
Loss: 0.031023368687806
ROC train: 1.000000	val: 0.826358	test: 0.574171
PRC train: 1.000000	val: 0.704168	test: 0.629374

Epoch: 76
Loss: 0.039965113758376254
ROC train: 1.000000	val: 0.842116	test: 0.593846
PRC train: 1.000000	val: 0.720626	test: 0.636996

Epoch: 77
Loss: 0.03472522399529807
ROC train: 1.000000	val: 0.836495	test: 0.625965
PRC train: 1.000000	val: 0.720252	test: 0.693792

Epoch: 78
Loss: 0.027071767994441793
ROC train: 1.000000	val: 0.842015	test: 0.638889
PRC train: 1.000000	val: 0.713961	test: 0.700065

Epoch: 79
Loss: 0.030527469512347194
ROC train: 1.000000	val: 0.831276	test: 0.638021
PRC train: 1.000000	val: 0.690455	test: 0.715860

Epoch: 80
Loss: 0.040913716667266994
ROC train: 1.000000	val: 0.834186	test: 0.652006
PRC train: 1.000000	val: 0.708562	test: 0.745687

Epoch: 81
Loss: 0.03284556688000217
ROC train: 1.000000	val: 0.845027	test: 0.638889
PRC train: 1.000000	val: 0.714344	test: 0.693332

Epoch: 82
Loss: 0.032585991000869084
ROC train: 1.000000	val: 0.837699	test: 0.651427
PRC train: 1.000000	val: 0.704071	test: 0.731576

Epoch: 83
Loss: 0.043450515887022124
ROC train: 1.000000	val: 0.823547	test: 0.610918
PRC train: 1.000000	val: 0.706551	test: 0.655569

Epoch: 84
Loss: 0.03481049366801044
ROC train: 1.000000	val: 0.827261	test: 0.591435
PRC train: 1.000000	val: 0.701058	test: 0.618370

Epoch: 85
Loss: 0.02804984439363614
ROC train: 0.999994	val: 0.802770	test: 0.628376
PRC train: 0.999999	val: 0.638143	test: 0.695030

Epoch: 86
Loss: 0.03625065475445737
ROC train: 1.000000	val: 0.790123	test: 0.637731
PRC train: 1.000000	val: 0.628119	test: 0.705883

Epoch: 87
Loss: 0.019718464272230674
ROC train: 0.999986	val: 0.825555	test: 0.644483
PRC train: 0.999997	val: 0.694599	test: 0.721025

Epoch: 88
Loss: 0.028721749263685818
ROC train: 1.000000	val: 0.837499	test: 0.657311
PRC train: 1.000000	val: 0.698951	test: 0.746798

Epoch: 89
Loss: 0.03263136556440489
ROC train: 1.000000	val: 0.830573	test: 0.656250
PRC train: 1.000000	val: 0.682910	test: 0.731632

Epoch: 90
Loss: 0.029444857061530622
ROC train: 1.000000	val: 0.809897	test: 0.619888
PRC train: 1.000000	val: 0.652907	test: 0.641195

Epoch: 91
Loss: 0.025032374474695664
ROC train: 1.000000	val: 0.795744	test: 0.601370
PRC train: 1.000000	val: 0.639363	test: 0.618969

Epoch: 92
Loss: 0.028976849438778884
ROC train: 1.000000	val: 0.816621	test: 0.598765
PRC train: 1.000000	val: 0.669943	test: 0.649680

Epoch: 93
Loss: 0.03638665784802275
PRC train: 0.999668	val: 0.767062	test: 0.670188

Epoch: 33
Loss: 0.13230822577198237
ROC train: 0.999139	val: 0.807287	test: 0.644387
PRC train: 0.999838	val: 0.664443	test: 0.652937

Epoch: 34
Loss: 0.1277857652491261
ROC train: 0.996482	val: 0.803372	test: 0.628376
PRC train: 0.999292	val: 0.662709	test: 0.617014

Epoch: 35
Loss: 0.12467646489677049
ROC train: 0.999459	val: 0.840711	test: 0.652488
PRC train: 0.999898	val: 0.732431	test: 0.642489

Epoch: 36
Loss: 0.11859455597703104
ROC train: 0.999613	val: 0.864800	test: 0.676698
PRC train: 0.999927	val: 0.788110	test: 0.694460

Epoch: 37
Loss: 0.11440971178819327
ROC train: 0.999532	val: 0.851250	test: 0.668596
PRC train: 0.999911	val: 0.724544	test: 0.679555

Epoch: 38
Loss: 0.11019910911785893
ROC train: 0.999857	val: 0.835190	test: 0.658372
PRC train: 0.999973	val: 0.736132	test: 0.664429

Epoch: 39
Loss: 0.0955658510757256
ROC train: 0.999604	val: 0.851952	test: 0.655671
PRC train: 0.999924	val: 0.776055	test: 0.678842

Epoch: 40
Loss: 0.10459766170280722
ROC train: 0.999579	val: 0.847436	test: 0.659626
PRC train: 0.999920	val: 0.778754	test: 0.673006

Epoch: 41
Loss: 0.08321300838467495
ROC train: 0.999849	val: 0.823447	test: 0.668210
PRC train: 0.999971	val: 0.728844	test: 0.679181

Epoch: 42
Loss: 0.08842587105492264
ROC train: 0.999804	val: 0.807086	test: 0.657407
PRC train: 0.999963	val: 0.692630	test: 0.658572

Epoch: 43
Loss: 0.09094788241845975
ROC train: 0.999969	val: 0.848238	test: 0.674576
PRC train: 0.999994	val: 0.749005	test: 0.685556

Epoch: 44
Loss: 0.08210176032001851
ROC train: 0.999966	val: 0.831175	test: 0.669946
PRC train: 0.999994	val: 0.711609	test: 0.679836

Epoch: 45
Loss: 0.07591780124768086
ROC train: 0.999975	val: 0.830673	test: 0.669657
PRC train: 0.999995	val: 0.705372	test: 0.669834

Epoch: 46
Loss: 0.06383367858008689
ROC train: 0.999994	val: 0.851049	test: 0.663002
PRC train: 0.999999	val: 0.747903	test: 0.664060

Epoch: 47
Loss: 0.07340048228875892
ROC train: 0.999938	val: 0.859681	test: 0.664062
PRC train: 0.999988	val: 0.774923	test: 0.661469

Epoch: 48
Loss: 0.0705353003417669
ROC train: 0.999921	val: 0.855465	test: 0.654707
PRC train: 0.999985	val: 0.767402	test: 0.665865

Epoch: 49
Loss: 0.071881056649558
ROC train: 0.999910	val: 0.848238	test: 0.654514
PRC train: 0.999983	val: 0.754950	test: 0.671907

Epoch: 50
Loss: 0.0632616815486515
ROC train: 0.999964	val: 0.852956	test: 0.658565
PRC train: 0.999993	val: 0.773751	test: 0.676231

Epoch: 51
Loss: 0.057496381138067446
ROC train: 0.999969	val: 0.855465	test: 0.656732
PRC train: 0.999994	val: 0.772259	test: 0.665952

Epoch: 52
Loss: 0.057856645991029264
ROC train: 0.999885	val: 0.840410	test: 0.660783
PRC train: 0.999978	val: 0.744750	test: 0.652034

Epoch: 53
Loss: 0.0701092103785438
ROC train: 0.999958	val: 0.839105	test: 0.667535
PRC train: 0.999992	val: 0.729882	test: 0.671097

Epoch: 54
Loss: 0.08498778954299005
ROC train: 0.999868	val: 0.861989	test: 0.677566
PRC train: 0.999976	val: 0.773081	test: 0.710472

Epoch: 55
Loss: 0.05678632069644152
ROC train: 0.999955	val: 0.805882	test: 0.659529
PRC train: 0.999991	val: 0.682994	test: 0.669326

Epoch: 56
Loss: 0.07620943676806362
ROC train: 0.999983	val: 0.819532	test: 0.642168
PRC train: 0.999997	val: 0.703939	test: 0.665065

Epoch: 57
Loss: 0.06612560150712166
ROC train: 0.999964	val: 0.844224	test: 0.625000
PRC train: 0.999993	val: 0.725477	test: 0.637926

Epoch: 58
Loss: 0.04944645332242054
ROC train: 0.999989	val: 0.856168	test: 0.624421
PRC train: 0.999998	val: 0.749871	test: 0.623495

Epoch: 59
Loss: 0.0548241015700686
ROC train: 1.000000	val: 0.821540	test: 0.628665
PRC train: 1.000000	val: 0.687564	test: 0.622262

Epoch: 60
Loss: 0.04869936714700945
ROC train: 1.000000	val: 0.828265	test: 0.627508
PRC train: 1.000000	val: 0.704049	test: 0.636631

Epoch: 61
Loss: 0.05757978821659806
ROC train: 1.000000	val: 0.780287	test: 0.624421
PRC train: 1.000000	val: 0.630187	test: 0.636647

Epoch: 62
Loss: 0.048891987055221756
ROC train: 0.999910	val: 0.804978	test: 0.639660
PRC train: 0.999983	val: 0.681614	test: 0.648743

Epoch: 63
Loss: 0.04817641856302811
ROC train: 0.999961	val: 0.820235	test: 0.637731
PRC train: 0.999993	val: 0.700001	test: 0.655870

Epoch: 64
Loss: 0.06495474445180838
ROC train: 1.000000	val: 0.842417	test: 0.627025
PRC train: 1.000000	val: 0.742758	test: 0.660724

Epoch: 65
Loss: 0.0543563402058088
ROC train: 1.000000	val: 0.850447	test: 0.638117
PRC train: 1.000000	val: 0.752151	test: 0.661379

Epoch: 66
Loss: 0.048127233905744596
ROC train: 1.000000	val: 0.825153	test: 0.639660
PRC train: 1.000000	val: 0.712839	test: 0.660461

Epoch: 67
Loss: 0.05461991197249703
ROC train: 1.000000	val: 0.843019	test: 0.661651
PRC train: 1.000000	val: 0.728305	test: 0.695401

Epoch: 68
Loss: 0.028694483713448328
ROC train: 0.999829	val: 0.822142	test: 0.653067
PRC train: 0.999967	val: 0.707099	test: 0.682507

Epoch: 69
Loss: 0.04724065072078888
ROC train: 0.999994	val: 0.814112	test: 0.647087
PRC train: 0.999999	val: 0.693920	test: 0.683760

Epoch: 70
Loss: 0.03928268128754053
ROC train: 1.000000	val: 0.796848	test: 0.645351
PRC train: 1.000000	val: 0.658457	test: 0.674899

Epoch: 71
Loss: 0.042520752755081125
ROC train: 1.000000	val: 0.819532	test: 0.652778
PRC train: 1.000000	val: 0.690017	test: 0.667441

Epoch: 72
Loss: 0.03525909642472257
ROC train: 1.000000	val: 0.805982	test: 0.651524
PRC train: 1.000000	val: 0.688182	test: 0.655291

Epoch: 73
Loss: 0.02979027836841599
ROC train: 1.000000	val: 0.777979	test: 0.646123
PRC train: 1.000000	val: 0.639379	test: 0.651900

Epoch: 74
Loss: 0.03180644173983452
ROC train: 1.000000	val: 0.760715	test: 0.638310
PRC train: 1.000000	val: 0.599376	test: 0.639803

Epoch: 75
Loss: 0.03924353272290072
ROC train: 0.999997	val: 0.795945	test: 0.628762
PRC train: 0.999999	val: 0.661918	test: 0.635427

Epoch: 76
Loss: 0.045322464119834725
ROC train: 0.999986	val: 0.834186	test: 0.634452
PRC train: 0.999997	val: 0.725930	test: 0.662330

Epoch: 77
Loss: 0.040756744259862566
ROC train: 0.999773	val: 0.838804	test: 0.636381
PRC train: 0.999957	val: 0.742073	test: 0.649779

Epoch: 78
Loss: 0.046866536227043676
ROC train: 0.999919	val: 0.837499	test: 0.636381
PRC train: 0.999985	val: 0.742684	test: 0.649173

Epoch: 79
Loss: 0.03872952852711896
ROC train: 1.000000	val: 0.840711	test: 0.645544
PRC train: 1.000000	val: 0.748798	test: 0.677875

Epoch: 80
Loss: 0.02885915532600117
ROC train: 1.000000	val: 0.847436	test: 0.646219
PRC train: 1.000000	val: 0.756797	test: 0.677287

Epoch: 81
Loss: 0.03408581271559514
ROC train: 1.000000	val: 0.828164	test: 0.653356
PRC train: 1.000000	val: 0.745690	test: 0.676471

Epoch: 82
Loss: 0.033135564223906136
ROC train: 0.999576	val: 0.832781	test: 0.655864
PRC train: 0.999916	val: 0.722378	test: 0.676851

Epoch: 83
Loss: 0.03625805677431444
ROC train: 1.000000	val: 0.851952	test: 0.665123
PRC train: 1.000000	val: 0.782527	test: 0.696638

Epoch: 84
Loss: 0.03312993606391058
ROC train: 1.000000	val: 0.853357	test: 0.654128
PRC train: 1.000000	val: 0.772727	test: 0.680872

Epoch: 85
Loss: 0.026542349449967383
ROC train: 0.999997	val: 0.857372	test: 0.679784
PRC train: 0.999999	val: 0.785877	test: 0.697031

Epoch: 86
Loss: 0.029758698013083614
ROC train: 0.999978	val: 0.824952	test: 0.672647
PRC train: 0.999996	val: 0.715826	test: 0.692039

Epoch: 87
Loss: 0.03213101088556886
ROC train: 1.000000	val: 0.845629	test: 0.676794
PRC train: 1.000000	val: 0.727548	test: 0.693112

Epoch: 88
Loss: 0.02739035444353885
ROC train: 1.000000	val: 0.854662	test: 0.671103
PRC train: 1.000000	val: 0.743339	test: 0.693849

Epoch: 89
Loss: 0.027702266013162197
ROC train: 1.000000	val: 0.839406	test: 0.669753
PRC train: 1.000000	val: 0.721739	test: 0.691056

Epoch: 90
Loss: 0.02676206255870437
ROC train: 1.000000	val: 0.837198	test: 0.678916
PRC train: 1.000000	val: 0.722848	test: 0.701276

Epoch: 91
Loss: 0.04113765848960582
ROC train: 1.000000	val: 0.854261	test: 0.677373
PRC train: 1.000000	val: 0.769412	test: 0.702315

Epoch: 92
Loss: 0.030461931197186033
ROC train: 0.999992	val: 0.826759	test: 0.660494
PRC train: 0.999998	val: 0.722997	test: 0.674973

Epoch: 93
Loss: 0.03277125792363657
ROC train: 0.999994	val: 0.814915	test: 0.652199
PRC train: 0.999201	val: 0.818691	test: 0.725272

Epoch: 33
Loss: 0.11654989057572265
ROC train: 0.996869	val: 0.893506	test: 0.708623
PRC train: 0.999398	val: 0.778321	test: 0.725418

Epoch: 34
Loss: 0.11962273722392709
ROC train: 0.997775	val: 0.896216	test: 0.708912
PRC train: 0.999576	val: 0.790338	test: 0.730931

Epoch: 35
Loss: 0.11703518134511001
ROC train: 0.997397	val: 0.899729	test: 0.707948
PRC train: 0.999509	val: 0.815006	test: 0.729464

Epoch: 36
Loss: 0.11423037925075118
ROC train: 0.998168	val: 0.889090	test: 0.684414
PRC train: 0.999653	val: 0.808549	test: 0.688893

Epoch: 37
Loss: 0.10410639717950392
ROC train: 0.998738	val: 0.902138	test: 0.691551
PRC train: 0.999758	val: 0.831721	test: 0.716881

Epoch: 38
Loss: 0.10724094450565382
ROC train: 0.998696	val: 0.901536	test: 0.698592
PRC train: 0.999750	val: 0.846581	test: 0.743519

Epoch: 39
Loss: 0.10173992706431602
ROC train: 0.998712	val: 0.874837	test: 0.676215
PRC train: 0.999757	val: 0.786216	test: 0.694705

Epoch: 40
Loss: 0.09897992343195501
ROC train: 0.999391	val: 0.894108	test: 0.686150
PRC train: 0.999884	val: 0.794355	test: 0.704551

Epoch: 41
Loss: 0.09200933766495278
ROC train: 0.999066	val: 0.892603	test: 0.692419
PRC train: 0.999822	val: 0.787862	test: 0.662631

Epoch: 42
Loss: 0.09564191159486979
ROC train: 0.998479	val: 0.887082	test: 0.674576
PRC train: 0.999700	val: 0.784049	test: 0.645357

Epoch: 43
Loss: 0.09167298680726733
ROC train: 0.999285	val: 0.887684	test: 0.667342
PRC train: 0.999862	val: 0.800202	test: 0.651045

Epoch: 44
Loss: 0.0889152971954099
ROC train: 0.999273	val: 0.889491	test: 0.673708
PRC train: 0.999860	val: 0.780182	test: 0.639432

Epoch: 45
Loss: 0.07515726263974538
ROC train: 0.999360	val: 0.877647	test: 0.681617
PRC train: 0.999877	val: 0.779289	test: 0.684481

Epoch: 46
Loss: 0.09515318508998856
ROC train: 0.999523	val: 0.889491	test: 0.693673
PRC train: 0.999909	val: 0.799659	test: 0.701437

Epoch: 47
Loss: 0.08912427861917323
ROC train: 0.999431	val: 0.890294	test: 0.690297
PRC train: 0.999889	val: 0.804958	test: 0.707026

Epoch: 48
Loss: 0.07613935539025073
ROC train: 0.999877	val: 0.908060	test: 0.698013
PRC train: 0.999977	val: 0.831519	test: 0.729644

Epoch: 49
Loss: 0.07829891122703973
ROC train: 0.999537	val: 0.896316	test: 0.682195
PRC train: 0.999912	val: 0.798665	test: 0.679811

Epoch: 50
Loss: 0.07180863053622581
ROC train: 0.999787	val: 0.884071	test: 0.687693
PRC train: 0.999960	val: 0.775463	test: 0.713576

Epoch: 51
Loss: 0.07793695869269092
ROC train: 0.999823	val: 0.899328	test: 0.697338
PRC train: 0.999967	val: 0.794271	test: 0.726882

Epoch: 52
Loss: 0.08478584108412598
ROC train: 0.999851	val: 0.873934	test: 0.679880
PRC train: 0.999972	val: 0.746203	test: 0.668270

Epoch: 53
Loss: 0.06482678024826076
ROC train: 0.999652	val: 0.866506	test: 0.666474
PRC train: 0.999932	val: 0.755455	test: 0.683317

Epoch: 54
Loss: 0.06752732937488672
ROC train: 0.999512	val: 0.877447	test: 0.688175
PRC train: 0.999907	val: 0.780263	test: 0.731233

Epoch: 55
Loss: 0.06083966854440366
ROC train: 0.999694	val: 0.893104	test: 0.684703
PRC train: 0.999941	val: 0.812137	test: 0.697356

Epoch: 56
Loss: 0.0704333243598103
ROC train: 0.999983	val: 0.893406	test: 0.695409
PRC train: 0.999997	val: 0.809326	test: 0.712343

Epoch: 57
Loss: 0.06494908634914279
ROC train: 0.999865	val: 0.881562	test: 0.707562
PRC train: 0.999974	val: 0.797776	test: 0.744128

Epoch: 58
Loss: 0.07043135804883778
ROC train: 0.999989	val: 0.894008	test: 0.686825
PRC train: 0.999998	val: 0.811240	test: 0.684256

Epoch: 59
Loss: 0.0870757572771397
ROC train: 0.999907	val: 0.886580	test: 0.684124
PRC train: 0.999982	val: 0.805043	test: 0.672600

Epoch: 60
Loss: 0.06250761966829184
ROC train: 0.999966	val: 0.888889	test: 0.702739
PRC train: 0.999994	val: 0.802111	test: 0.710830

Epoch: 61
Loss: 0.06804906640748072
ROC train: 0.999994	val: 0.886179	test: 0.692901
PRC train: 0.999999	val: 0.785432	test: 0.711356

Epoch: 62
Loss: 0.06282000998721315
ROC train: 0.999969	val: 0.873432	test: 0.670718
PRC train: 0.999994	val: 0.750404	test: 0.666058

Epoch: 63
Loss: 0.0631663399107417
ROC train: 0.999975	val: 0.883067	test: 0.706308
PRC train: 0.999995	val: 0.774297	test: 0.726570

Epoch: 64
Loss: 0.06047625353908454
ROC train: 0.999986	val: 0.890997	test: 0.713638
PRC train: 0.999997	val: 0.806610	test: 0.746899

Epoch: 65
Loss: 0.0525256284621246
ROC train: 0.999958	val: 0.887785	test: 0.694830
PRC train: 0.999992	val: 0.797022	test: 0.715864

Epoch: 66
Loss: 0.07787889050829229
ROC train: 0.999874	val: 0.885075	test: 0.697049
PRC train: 0.999976	val: 0.799988	test: 0.722694

Epoch: 67
Loss: 0.051269782919934496
ROC train: 0.999921	val: 0.880558	test: 0.695120
PRC train: 0.999985	val: 0.793643	test: 0.720138

Epoch: 68
Loss: 0.05802609243126781
ROC train: 0.999829	val: 0.871525	test: 0.674865
PRC train: 0.999969	val: 0.764752	test: 0.670896

Epoch: 69
Loss: 0.06716284844686303
ROC train: 0.999966	val: 0.886078	test: 0.692323
PRC train: 0.999994	val: 0.777065	test: 0.703037

Epoch: 70
Loss: 0.05617341636023847
ROC train: 0.999966	val: 0.896919	test: 0.701582
PRC train: 0.999994	val: 0.814236	test: 0.717893

Epoch: 71
Loss: 0.04475759528761068
ROC train: 0.999938	val: 0.902841	test: 0.695602
PRC train: 0.999988	val: 0.825456	test: 0.686383

Epoch: 72
Loss: 0.05444621066608206
ROC train: 1.000000	val: 0.906554	test: 0.692033
PRC train: 1.000000	val: 0.832769	test: 0.701695

Epoch: 73
Loss: 0.04891952941889695
ROC train: 0.999978	val: 0.909766	test: 0.685571
PRC train: 0.999996	val: 0.836874	test: 0.727402

Epoch: 74
Loss: 0.058647608126448585
ROC train: 0.999975	val: 0.888989	test: 0.694059
PRC train: 0.999995	val: 0.805231	test: 0.726280

Epoch: 75
Loss: 0.04760038789033661
ROC train: 0.999888	val: 0.897119	test: 0.702546
PRC train: 0.999978	val: 0.808871	test: 0.716245

Epoch: 76
Loss: 0.050447510606947125
ROC train: 0.999857	val: 0.895212	test: 0.700810
PRC train: 0.999972	val: 0.807027	test: 0.724169

Epoch: 77
Loss: 0.04166659765350763
ROC train: 0.999997	val: 0.881863	test: 0.702546
PRC train: 0.999999	val: 0.776199	test: 0.715183

Epoch: 78
Loss: 0.03642863410825997
ROC train: 1.000000	val: 0.876242	test: 0.700424
PRC train: 1.000000	val: 0.751076	test: 0.702492

Epoch: 79
Loss: 0.03604474888779391
ROC train: 1.000000	val: 0.892101	test: 0.702739
PRC train: 1.000000	val: 0.772049	test: 0.692199

Epoch: 80
Loss: 0.03695923488104095
ROC train: 1.000000	val: 0.893707	test: 0.699460
PRC train: 1.000000	val: 0.775482	test: 0.690616

Epoch: 81
Loss: 0.033099056655005885
ROC train: 1.000000	val: 0.891298	test: 0.702160
PRC train: 1.000000	val: 0.779492	test: 0.700392

Epoch: 82
Loss: 0.03424067929006915
ROC train: 0.999997	val: 0.894309	test: 0.693094
PRC train: 0.999999	val: 0.792513	test: 0.683655

Epoch: 83
Loss: 0.031080235430440636
ROC train: 0.999994	val: 0.899930	test: 0.700039
PRC train: 0.999999	val: 0.797581	test: 0.693545

Epoch: 84
Loss: 0.028308751902881877
ROC train: 0.999950	val: 0.903643	test: 0.698978
PRC train: 0.999990	val: 0.794870	test: 0.686639

Epoch: 85
Loss: 0.037891734751301885
ROC train: 0.999492	val: 0.880558	test: 0.697434
PRC train: 0.999902	val: 0.768035	test: 0.680082

Epoch: 86
Loss: 0.03383604803911871
ROC train: 1.000000	val: 0.901235	test: 0.687114
PRC train: 1.000000	val: 0.795928	test: 0.673560

Epoch: 87
Loss: 0.03634695631845204
ROC train: 1.000000	val: 0.893506	test: 0.689622
PRC train: 1.000000	val: 0.800379	test: 0.698765

Epoch: 88
Loss: 0.032505041557067495
ROC train: 0.999992	val: 0.885175	test: 0.687596
PRC train: 0.999998	val: 0.785153	test: 0.656284

Epoch: 89
Loss: 0.04223819218851073
ROC train: 1.000000	val: 0.896417	test: 0.698013
PRC train: 1.000000	val: 0.807426	test: 0.689588

Epoch: 90
Loss: 0.033579000980161
ROC train: 0.999997	val: 0.887383	test: 0.696470
PRC train: 0.999999	val: 0.789078	test: 0.708402

Epoch: 91
Loss: 0.033551719106055734
ROC train: 0.999997	val: 0.887283	test: 0.696759
PRC train: 0.999999	val: 0.796643	test: 0.701492

Epoch: 92
Loss: 0.024428899369585488
ROC train: 0.999955	val: 0.881963	test: 0.700521
PRC train: 0.999991	val: 0.796088	test: 0.726690

Epoch: 93
Loss: 0.042314597038255505
ROC train: 1.000000	val: 0.882465	test: 0.703318
PRC train: 0.999418	val: 0.789210	test: 0.717041

Epoch: 33
Loss: 0.11904885039309675
ROC train: 0.998157	val: 0.892502	test: 0.664352
PRC train: 0.999640	val: 0.805911	test: 0.699815

Epoch: 34
Loss: 0.11088345992558109
ROC train: 0.996513	val: 0.883469	test: 0.661265
PRC train: 0.999306	val: 0.802955	test: 0.720883

Epoch: 35
Loss: 0.12195897981552774
ROC train: 0.997492	val: 0.898525	test: 0.672261
PRC train: 0.999513	val: 0.819888	test: 0.728874

Epoch: 36
Loss: 0.11067848141003642
ROC train: 0.999035	val: 0.900331	test: 0.671393
PRC train: 0.999816	val: 0.812099	test: 0.723958

Epoch: 37
Loss: 0.09762045970627711
ROC train: 0.997918	val: 0.904748	test: 0.674576
PRC train: 0.999602	val: 0.825207	test: 0.705703

Epoch: 38
Loss: 0.10204776198880118
ROC train: 0.998724	val: 0.878952	test: 0.672164
PRC train: 0.999754	val: 0.781783	test: 0.709817

Epoch: 39
Loss: 0.11316649289811202
ROC train: 0.998656	val: 0.883268	test: 0.668789
PRC train: 0.999745	val: 0.768766	test: 0.715348

Epoch: 40
Loss: 0.1084160104283003
ROC train: 0.999456	val: 0.892101	test: 0.677855
PRC train: 0.999896	val: 0.803567	test: 0.725845

Epoch: 41
Loss: 0.07717702609602992
ROC train: 0.999355	val: 0.899629	test: 0.673997
PRC train: 0.999876	val: 0.814410	test: 0.701430

Epoch: 42
Loss: 0.10577655163764137
ROC train: 0.999742	val: 0.894108	test: 0.668499
PRC train: 0.999952	val: 0.819386	test: 0.697619

Epoch: 43
Loss: 0.08648217824418522
ROC train: 0.999428	val: 0.901636	test: 0.670332
PRC train: 0.999889	val: 0.847707	test: 0.704410

Epoch: 44
Loss: 0.08647069053358199
ROC train: 0.998547	val: 0.898525	test: 0.681906
PRC train: 0.999716	val: 0.848673	test: 0.721221

Epoch: 45
Loss: 0.08633009121348566
ROC train: 0.999388	val: 0.900130	test: 0.687114
PRC train: 0.999881	val: 0.846886	test: 0.715395

Epoch: 46
Loss: 0.07514263968665794
ROC train: 0.998651	val: 0.892703	test: 0.670910
PRC train: 0.999745	val: 0.815958	test: 0.691333

Epoch: 47
Loss: 0.08470545157597238
ROC train: 0.999733	val: 0.880859	test: 0.665702
PRC train: 0.999950	val: 0.762378	test: 0.695927

Epoch: 48
Loss: 0.07045306867616849
ROC train: 0.999742	val: 0.880658	test: 0.667728
PRC train: 0.999951	val: 0.763316	test: 0.700078

Epoch: 49
Loss: 0.07519240227914294
ROC train: 0.998283	val: 0.904346	test: 0.670814
PRC train: 0.999666	val: 0.825354	test: 0.676055

Epoch: 50
Loss: 0.07947265773787655
ROC train: 0.999158	val: 0.890194	test: 0.683353
PRC train: 0.999837	val: 0.790455	test: 0.703881

Epoch: 51
Loss: 0.07348899562018492
ROC train: 0.999683	val: 0.881060	test: 0.679398
PRC train: 0.999939	val: 0.783913	test: 0.723187

Epoch: 52
Loss: 0.08330950054241607
ROC train: 0.999806	val: 0.857874	test: 0.674769
PRC train: 0.999963	val: 0.761246	test: 0.706311

Epoch: 53
Loss: 0.08274637278079097
ROC train: 0.999857	val: 0.898023	test: 0.679977
PRC train: 0.999973	val: 0.800351	test: 0.710356

Epoch: 54
Loss: 0.06661201841980836
ROC train: 0.999481	val: 0.885476	test: 0.669464
PRC train: 0.999902	val: 0.762620	test: 0.711895

Epoch: 55
Loss: 0.07216145221701209
ROC train: 0.999983	val: 0.879253	test: 0.672357
PRC train: 0.999997	val: 0.762752	test: 0.725228

Epoch: 56
Loss: 0.04847989894086861
ROC train: 0.999602	val: 0.883870	test: 0.692130
PRC train: 0.999928	val: 0.769879	test: 0.740679

Epoch: 57
Loss: 0.06480074454295094
ROC train: 0.999972	val: 0.890796	test: 0.685185
PRC train: 0.999995	val: 0.799573	test: 0.740412

Epoch: 58
Loss: 0.051074121136776944
ROC train: 0.999933	val: 0.884372	test: 0.687307
PRC train: 0.999987	val: 0.786469	test: 0.742680

Epoch: 59
Loss: 0.05386349170490472
ROC train: 1.000000	val: 0.891097	test: 0.698013
PRC train: 1.000000	val: 0.797880	test: 0.766896

Epoch: 60
Loss: 0.05490969184455569
ROC train: 0.999938	val: 0.893907	test: 0.698978
PRC train: 0.999988	val: 0.817572	test: 0.767946

Epoch: 61
Loss: 0.05555909698009819
ROC train: 1.000000	val: 0.893606	test: 0.684799
PRC train: 1.000000	val: 0.814010	test: 0.744749

Epoch: 62
Loss: 0.05855376910342069
ROC train: 0.999997	val: 0.894510	test: 0.680941
PRC train: 0.999999	val: 0.813752	test: 0.743292

Epoch: 63
Loss: 0.047836643092359896
ROC train: 0.999992	val: 0.897722	test: 0.687018
PRC train: 0.999998	val: 0.833342	test: 0.748045

Epoch: 64
Loss: 0.04848456120714219
ROC train: 1.000000	val: 0.895714	test: 0.678144
PRC train: 1.000000	val: 0.837634	test: 0.733528

Epoch: 65
Loss: 0.03327304779229836
ROC train: 0.999997	val: 0.899428	test: 0.679880
PRC train: 0.999999	val: 0.821409	test: 0.724964

Epoch: 66
Loss: 0.046918688345777775
ROC train: 0.999997	val: 0.915889	test: 0.686439
PRC train: 0.999999	val: 0.852505	test: 0.723696

Epoch: 67
Loss: 0.04627807011402867
ROC train: 1.000000	val: 0.898424	test: 0.679977
PRC train: 1.000000	val: 0.825528	test: 0.722486

Epoch: 68
Loss: 0.034441699939061446
ROC train: 0.999997	val: 0.890696	test: 0.682485
PRC train: 0.999999	val: 0.818343	test: 0.733758

Epoch: 69
Loss: 0.028470990337073093
ROC train: 1.000000	val: 0.896617	test: 0.687018
PRC train: 1.000000	val: 0.835914	test: 0.731448

Epoch: 70
Loss: 0.03461077552987049
ROC train: 1.000000	val: 0.886681	test: 0.679302
PRC train: 1.000000	val: 0.831631	test: 0.729595

Epoch: 71
Loss: 0.05034135600201412
ROC train: 0.999989	val: 0.882565	test: 0.676215
PRC train: 0.999998	val: 0.771693	test: 0.720401

Epoch: 72
Loss: 0.035616424546658206
ROC train: 1.000000	val: 0.895413	test: 0.687982
PRC train: 1.000000	val: 0.778405	test: 0.732702

Epoch: 73
Loss: 0.05007979808485019
ROC train: 0.999997	val: 0.898525	test: 0.707465
PRC train: 0.999999	val: 0.832322	test: 0.758746

Epoch: 74
Loss: 0.04330442530907238
ROC train: 0.999992	val: 0.884974	test: 0.693769
PRC train: 0.999998	val: 0.803967	test: 0.757120

Epoch: 75
Loss: 0.04967298121744931
ROC train: 0.999997	val: 0.878149	test: 0.682292
PRC train: 0.999999	val: 0.769217	test: 0.750315

Epoch: 76
Loss: 0.04250835397531124
ROC train: 0.999989	val: 0.887383	test: 0.681809
PRC train: 0.999998	val: 0.779552	test: 0.746865

Epoch: 77
Loss: 0.06828256068329998
ROC train: 1.000000	val: 0.872729	test: 0.675540
PRC train: 1.000000	val: 0.735187	test: 0.725007

Epoch: 78
Loss: 0.03952432220855099
ROC train: 0.999703	val: 0.859279	test: 0.670139
PRC train: 0.999943	val: 0.719235	test: 0.709861

Epoch: 79
Loss: 0.039683752627750084
ROC train: 0.999986	val: 0.861287	test: 0.684414
PRC train: 0.999997	val: 0.739482	test: 0.720705

Epoch: 80
Loss: 0.04375457068944315
ROC train: 1.000000	val: 0.867108	test: 0.689815
PRC train: 1.000000	val: 0.760551	test: 0.727641

Epoch: 81
Loss: 0.042976284459382064
ROC train: 1.000000	val: 0.882766	test: 0.692226
PRC train: 1.000000	val: 0.742596	test: 0.730999

Epoch: 82
Loss: 0.04638767666753624
ROC train: 0.999997	val: 0.885376	test: 0.682485
PRC train: 0.999999	val: 0.779958	test: 0.705587

Epoch: 83
Loss: 0.030804189032960973
ROC train: 1.000000	val: 0.887684	test: 0.682870
PRC train: 1.000000	val: 0.803890	test: 0.715047

Epoch: 84
Loss: 0.04375417467987842
ROC train: 1.000000	val: 0.899026	test: 0.689525
PRC train: 1.000000	val: 0.828355	test: 0.727046

Epoch: 85
Loss: 0.03857765839065391
ROC train: 0.999997	val: 0.895915	test: 0.687789
PRC train: 0.999999	val: 0.810675	test: 0.727366

Epoch: 86
Loss: 0.034408642640294154
ROC train: 1.000000	val: 0.885777	test: 0.690490
PRC train: 1.000000	val: 0.768966	test: 0.724426

Epoch: 87
Loss: 0.027468907287053434
ROC train: 1.000000	val: 0.885577	test: 0.694830
PRC train: 1.000000	val: 0.790448	test: 0.731650

Epoch: 88
Loss: 0.02085382845414126
ROC train: 1.000000	val: 0.885577	test: 0.698399
PRC train: 1.000000	val: 0.791487	test: 0.745921

Epoch: 89
Loss: 0.02366529715767956
ROC train: 1.000000	val: 0.882365	test: 0.690008
PRC train: 1.000000	val: 0.788188	test: 0.741192

Epoch: 90
Loss: 0.03127945924902958
ROC train: 0.999983	val: 0.882164	test: 0.687982
PRC train: 0.999997	val: 0.772610	test: 0.744263

Epoch: 91
Loss: 0.033850363352454026
ROC train: 1.000000	val: 0.889391	test: 0.686535
PRC train: 1.000000	val: 0.789615	test: 0.740734

Epoch: 92
Loss: 0.018051967895332983
ROC train: 1.000000	val: 0.903543	test: 0.692708
PRC train: 1.000000	val: 0.849202	test: 0.736722

Epoch: 93
Loss: 0.0411665011614201
PRC train: 0.999639	val: 0.767737	test: 0.672167

Epoch: 33
Loss: 0.1398530294848541
ROC train: 0.998721	val: 0.896417	test: 0.656154
PRC train: 0.999758	val: 0.813526	test: 0.733386

Epoch: 34
Loss: 0.10873792387811232
ROC train: 0.999254	val: 0.917093	test: 0.642650
PRC train: 0.999859	val: 0.853223	test: 0.689433

Epoch: 35
Loss: 0.11442471078589689
ROC train: 0.999537	val: 0.907859	test: 0.620756
PRC train: 0.999912	val: 0.855641	test: 0.673721

Epoch: 36
Loss: 0.11097490919888063
ROC train: 0.998120	val: 0.893205	test: 0.610725
PRC train: 0.999643	val: 0.815149	test: 0.668528

Epoch: 37
Loss: 0.09706541089185083
ROC train: 0.998998	val: 0.904647	test: 0.636863
PRC train: 0.999812	val: 0.812290	test: 0.693787

Epoch: 38
Loss: 0.09350588821228167
ROC train: 0.999621	val: 0.894008	test: 0.604263
PRC train: 0.999929	val: 0.798687	test: 0.669917

Epoch: 39
Loss: 0.0953132475571132
ROC train: 0.999632	val: 0.891599	test: 0.605324
PRC train: 0.999930	val: 0.814094	test: 0.665057

Epoch: 40
Loss: 0.09485597308247197
ROC train: 0.999891	val: 0.909264	test: 0.592110
PRC train: 0.999979	val: 0.846839	test: 0.635944

Epoch: 41
Loss: 0.09291995216068179
ROC train: 0.999489	val: 0.910770	test: 0.599537
PRC train: 0.999903	val: 0.851807	test: 0.672725

Epoch: 42
Loss: 0.11202124263723826
ROC train: 0.999801	val: 0.884272	test: 0.568866
PRC train: 0.999962	val: 0.808423	test: 0.609667

Epoch: 43
Loss: 0.08071785960682544
ROC train: 0.999969	val: 0.894811	test: 0.613619
PRC train: 0.999994	val: 0.827785	test: 0.674790

Epoch: 44
Loss: 0.08985210648798429
ROC train: 0.999935	val: 0.885577	test: 0.620177
PRC train: 0.999988	val: 0.808219	test: 0.684203

Epoch: 45
Loss: 0.06834163238708682
ROC train: 1.000000	val: 0.902138	test: 0.609182
PRC train: 1.000000	val: 0.847005	test: 0.668448

Epoch: 46
Loss: 0.07375271289399098
ROC train: 0.999750	val: 0.905952	test: 0.596740
PRC train: 0.999952	val: 0.853180	test: 0.654016

Epoch: 47
Loss: 0.0642476864206684
ROC train: 0.999776	val: 0.905751	test: 0.582079
PRC train: 0.999957	val: 0.870324	test: 0.641509

Epoch: 48
Loss: 0.07046519407921417
ROC train: 0.999992	val: 0.910669	test: 0.577643
PRC train: 0.999998	val: 0.878458	test: 0.634963

Epoch: 49
Loss: 0.06576827648131585
ROC train: 0.999902	val: 0.923116	test: 0.613329
PRC train: 0.999981	val: 0.877326	test: 0.669865

Epoch: 50
Loss: 0.06703835719723088
ROC train: 0.999994	val: 0.900231	test: 0.643133
PRC train: 0.999999	val: 0.838676	test: 0.698224

Epoch: 51
Loss: 0.06380956148724884
ROC train: 0.999933	val: 0.881461	test: 0.612076
PRC train: 0.999987	val: 0.810652	test: 0.638459

Epoch: 52
Loss: 0.06377909119752868
ROC train: 0.999952	val: 0.896617	test: 0.626061
PRC train: 0.999991	val: 0.832505	test: 0.674251

Epoch: 53
Loss: 0.06615193742700957
ROC train: 0.999955	val: 0.905751	test: 0.643904
PRC train: 0.999992	val: 0.844594	test: 0.686517

Epoch: 54
Loss: 0.07544663823165962
ROC train: 0.999992	val: 0.925725	test: 0.658468
PRC train: 0.999998	val: 0.891600	test: 0.697854

Epoch: 55
Loss: 0.06754048959232371
ROC train: 0.999851	val: 0.885677	test: 0.605517
PRC train: 0.999972	val: 0.837090	test: 0.638538

Epoch: 56
Loss: 0.0698962975043165
ROC train: 0.999980	val: 0.900733	test: 0.615837
PRC train: 0.999996	val: 0.845733	test: 0.660595

Epoch: 57
Loss: 0.06395734339138767
ROC train: 0.999874	val: 0.891599	test: 0.627894
PRC train: 0.999976	val: 0.806250	test: 0.685132

Epoch: 58
Loss: 0.056354988226947435
ROC train: 0.999986	val: 0.901837	test: 0.602623
PRC train: 0.999997	val: 0.821007	test: 0.652193

Epoch: 59
Loss: 0.0651637696381845
ROC train: 1.000000	val: 0.881562	test: 0.613522
PRC train: 1.000000	val: 0.784735	test: 0.665047

Epoch: 60
Loss: 0.05553871210089528
ROC train: 1.000000	val: 0.874235	test: 0.613233
PRC train: 1.000000	val: 0.774230	test: 0.664196

Epoch: 61
Loss: 0.05624900705111737
ROC train: 1.000000	val: 0.894710	test: 0.614487
PRC train: 1.000000	val: 0.802345	test: 0.664852

Epoch: 62
Loss: 0.05051981945279681
ROC train: 1.000000	val: 0.895112	test: 0.626640
PRC train: 1.000000	val: 0.810657	test: 0.682708

Epoch: 63
Loss: 0.049364593204421436
ROC train: 1.000000	val: 0.875339	test: 0.607446
PRC train: 1.000000	val: 0.801654	test: 0.649805

Epoch: 64
Loss: 0.03746687015801669
ROC train: 1.000000	val: 0.894710	test: 0.630208
PRC train: 1.000000	val: 0.828477	test: 0.692203

Epoch: 65
Loss: 0.05280233473265603
ROC train: 1.000000	val: 0.893907	test: 0.616030
PRC train: 1.000000	val: 0.824010	test: 0.661485

Epoch: 66
Loss: 0.04777134621282151
ROC train: 1.000000	val: 0.896617	test: 0.612076
PRC train: 1.000000	val: 0.824694	test: 0.661754

Epoch: 67
Loss: 0.04350604174506241
ROC train: 1.000000	val: 0.902339	test: 0.632523
PRC train: 1.000000	val: 0.834836	test: 0.680738

Epoch: 68
Loss: 0.03682792288731509
ROC train: 0.999952	val: 0.890796	test: 0.619213
PRC train: 0.999991	val: 0.850807	test: 0.693740

Epoch: 69
Loss: 0.03330318617106654
ROC train: 0.999989	val: 0.896417	test: 0.613715
PRC train: 0.999998	val: 0.854572	test: 0.684564

Epoch: 70
Loss: 0.041395186923079065
ROC train: 1.000000	val: 0.899026	test: 0.603588
PRC train: 1.000000	val: 0.843749	test: 0.658416

Epoch: 71
Loss: 0.056027031348346
ROC train: 1.000000	val: 0.898525	test: 0.604552
PRC train: 1.000000	val: 0.843042	test: 0.656497

Epoch: 72
Loss: 0.039329825466854
ROC train: 0.999997	val: 0.898123	test: 0.629533
PRC train: 0.999999	val: 0.847153	test: 0.696302

Epoch: 73
Loss: 0.05688954031524356
ROC train: 1.000000	val: 0.900331	test: 0.622203
PRC train: 1.000000	val: 0.859103	test: 0.681050

Epoch: 74
Loss: 0.03921251588026229
ROC train: 1.000000	val: 0.899026	test: 0.612558
PRC train: 1.000000	val: 0.849667	test: 0.645089

Epoch: 75
Loss: 0.03487814561764741
ROC train: 0.999997	val: 0.892302	test: 0.582465
PRC train: 0.999999	val: 0.832980	test: 0.604791

Epoch: 76
Loss: 0.0382378667020733
ROC train: 0.999972	val: 0.883469	test: 0.590471
PRC train: 0.999995	val: 0.816789	test: 0.628063

Epoch: 77
Loss: 0.04787454543707609
ROC train: 1.000000	val: 0.892302	test: 0.615355
PRC train: 1.000000	val: 0.833306	test: 0.655198

Epoch: 78
Loss: 0.03519855808238847
ROC train: 1.000000	val: 0.902339	test: 0.633777
PRC train: 1.000000	val: 0.849154	test: 0.673006

Epoch: 79
Loss: 0.05919847839735927
ROC train: 0.999994	val: 0.898023	test: 0.620370
PRC train: 0.999999	val: 0.829229	test: 0.655363

Epoch: 80
Loss: 0.0467649044720243
ROC train: 0.999989	val: 0.878651	test: 0.617091
PRC train: 0.999998	val: 0.810400	test: 0.661822

Epoch: 81
Loss: 0.027527891887193703
ROC train: 1.000000	val: 0.878852	test: 0.625772
PRC train: 1.000000	val: 0.809616	test: 0.671983

Epoch: 82
Loss: 0.03713265621225572
ROC train: 0.999997	val: 0.861287	test: 0.612172
PRC train: 0.999999	val: 0.786266	test: 0.656601

Epoch: 83
Loss: 0.024674995402936977
ROC train: 1.000000	val: 0.887785	test: 0.627315
PRC train: 1.000000	val: 0.815278	test: 0.667822

Epoch: 84
Loss: 0.047149080609303506
ROC train: 1.000000	val: 0.906755	test: 0.630498
PRC train: 1.000000	val: 0.845700	test: 0.682208

Epoch: 85
Loss: 0.025656201946341634
ROC train: 1.000000	val: 0.913480	test: 0.628858
PRC train: 1.000000	val: 0.856111	test: 0.680021

Epoch: 86
Loss: 0.029132896203557523
ROC train: 1.000000	val: 0.915186	test: 0.628376
PRC train: 1.000000	val: 0.870424	test: 0.679676

Epoch: 87
Loss: 0.02692804617897158
ROC train: 1.000000	val: 0.904246	test: 0.634066
PRC train: 1.000000	val: 0.847144	test: 0.693793

Epoch: 88
Loss: 0.038422321585051156
ROC train: 1.000000	val: 0.894710	test: 0.648148
PRC train: 1.000000	val: 0.812321	test: 0.701295

Epoch: 89
Loss: 0.022526446226599578
ROC train: 1.000000	val: 0.894309	test: 0.632909
PRC train: 1.000000	val: 0.795274	test: 0.680100

Epoch: 90
Loss: 0.024781426333351786
ROC train: 0.999997	val: 0.887484	test: 0.610436
PRC train: 0.999999	val: 0.796773	test: 0.661256

Epoch: 91
Loss: 0.04676518085908987
ROC train: 1.000000	val: 0.894510	test: 0.631655
PRC train: 1.000000	val: 0.812013	test: 0.685713

Epoch: 92
Loss: 0.03148960067399732
ROC train: 0.999997	val: 0.894510	test: 0.640432
PRC train: 0.999999	val: 0.828102	test: 0.678983

Epoch: 93
Loss: 0.038164400197711626
ROC train: 1.000000	val: 0.901435	test: 0.619213
PRC train: 0.999426	val: 0.792933	test: 0.723467

Epoch: 33
Loss: 0.1402084067382012
ROC train: 0.997057	val: 0.884372	test: 0.653839
PRC train: 0.999444	val: 0.785862	test: 0.708311

Epoch: 34
Loss: 0.10704894412151966
ROC train: 0.997632	val: 0.890696	test: 0.670621
PRC train: 0.999551	val: 0.807017	test: 0.732719

Epoch: 35
Loss: 0.10763558631354986
ROC train: 0.997686	val: 0.902640	test: 0.690876
PRC train: 0.999557	val: 0.815716	test: 0.757020

Epoch: 36
Loss: 0.11356049448695918
ROC train: 0.997845	val: 0.890394	test: 0.683642
PRC train: 0.999590	val: 0.794282	test: 0.743519

Epoch: 37
Loss: 0.08617780266309337
ROC train: 0.998841	val: 0.890495	test: 0.677758
PRC train: 0.999781	val: 0.785428	test: 0.719047

Epoch: 38
Loss: 0.09201837764175777
ROC train: 0.998589	val: 0.878049	test: 0.657118
PRC train: 0.999734	val: 0.763199	test: 0.705062

Epoch: 39
Loss: 0.10312381958554336
ROC train: 0.997879	val: 0.876844	test: 0.668403
PRC train: 0.999597	val: 0.765108	test: 0.719589

Epoch: 40
Loss: 0.10868393583531813
ROC train: 0.998886	val: 0.874636	test: 0.689429
PRC train: 0.999790	val: 0.773187	test: 0.736826

Epoch: 41
Loss: 0.07947319381634095
ROC train: 0.999024	val: 0.888588	test: 0.695988
PRC train: 0.999817	val: 0.792376	test: 0.760806

Epoch: 42
Loss: 0.11013397768137385
ROC train: 0.998429	val: 0.885978	test: 0.693287
PRC train: 0.999706	val: 0.784016	test: 0.752022

Epoch: 43
Loss: 0.08879937774985672
ROC train: 0.999408	val: 0.874737	test: 0.672068
PRC train: 0.999888	val: 0.759143	test: 0.710139

Epoch: 44
Loss: 0.08145871850432203
ROC train: 0.998721	val: 0.891699	test: 0.688175
PRC train: 0.999759	val: 0.790788	test: 0.727686

Epoch: 45
Loss: 0.0839568045327588
ROC train: 0.999170	val: 0.900733	test: 0.711998
PRC train: 0.999843	val: 0.803618	test: 0.776053

Epoch: 46
Loss: 0.0801378803198259
ROC train: 0.999153	val: 0.895413	test: 0.682581
PRC train: 0.999839	val: 0.792905	test: 0.750988

Epoch: 47
Loss: 0.07479550377712714
ROC train: 0.998956	val: 0.897922	test: 0.675251
PRC train: 0.999800	val: 0.801673	test: 0.738782

Epoch: 48
Loss: 0.07318922774777979
ROC train: 0.999492	val: 0.902640	test: 0.677276
PRC train: 0.999904	val: 0.820344	test: 0.740775

Epoch: 49
Loss: 0.07151446252512846
ROC train: 0.999700	val: 0.913380	test: 0.682677
PRC train: 0.999943	val: 0.846133	test: 0.734061

Epoch: 50
Loss: 0.08313828584079895
ROC train: 0.999745	val: 0.905249	test: 0.668210
PRC train: 0.999951	val: 0.832351	test: 0.698789

Epoch: 51
Loss: 0.0677780514691109
ROC train: 0.998502	val: 0.879153	test: 0.643711
PRC train: 0.999719	val: 0.773951	test: 0.707829

Epoch: 52
Loss: 0.0892006843129848
ROC train: 0.998996	val: 0.862993	test: 0.648245
PRC train: 0.999813	val: 0.711758	test: 0.719357

Epoch: 53
Loss: 0.07247392471196833
ROC train: 0.999731	val: 0.850547	test: 0.659819
PRC train: 0.999949	val: 0.686211	test: 0.706011

Epoch: 54
Loss: 0.06573159886302017
ROC train: 0.999742	val: 0.870119	test: 0.684510
PRC train: 0.999951	val: 0.757333	test: 0.736345

Epoch: 55
Loss: 0.06465621812793165
ROC train: 0.999902	val: 0.883368	test: 0.686825
PRC train: 0.999981	val: 0.786377	test: 0.739331

Epoch: 56
Loss: 0.07258281455663064
ROC train: 0.999815	val: 0.893606	test: 0.698302
PRC train: 0.999965	val: 0.797306	test: 0.746337

Epoch: 57
Loss: 0.059128703455131715
ROC train: 0.999871	val: 0.883971	test: 0.689043
PRC train: 0.999975	val: 0.786815	test: 0.743330

Epoch: 58
Loss: 0.05266025228149239
ROC train: 0.999885	val: 0.883670	test: 0.674093
PRC train: 0.999978	val: 0.799452	test: 0.737235

Epoch: 59
Loss: 0.05525340447494181
ROC train: 0.999955	val: 0.892000	test: 0.688754
PRC train: 0.999991	val: 0.803484	test: 0.743518

Epoch: 60
Loss: 0.044159522545840976
ROC train: 0.999950	val: 0.891800	test: 0.693383
PRC train: 0.999990	val: 0.795102	test: 0.760219

Epoch: 61
Loss: 0.059522064512631215
ROC train: 0.999924	val: 0.888186	test: 0.691165
PRC train: 0.999986	val: 0.799882	test: 0.760965

Epoch: 62
Loss: 0.05607816828979667
ROC train: 0.999795	val: 0.890394	test: 0.683738
PRC train: 0.999962	val: 0.802331	test: 0.747272

Epoch: 63
Loss: 0.05542552599219919
ROC train: 0.999801	val: 0.888789	test: 0.680073
PRC train: 0.999962	val: 0.809686	test: 0.738489

Epoch: 64
Loss: 0.05851269235823979
ROC train: 0.999935	val: 0.897521	test: 0.704958
PRC train: 0.999988	val: 0.803022	test: 0.760896

Epoch: 65
Loss: 0.059196216065793186
ROC train: 0.999952	val: 0.897320	test: 0.690201
PRC train: 0.999991	val: 0.822064	test: 0.750150

Epoch: 66
Loss: 0.05962917851610772
ROC train: 0.999257	val: 0.891900	test: 0.679398
PRC train: 0.999854	val: 0.798130	test: 0.727493

Epoch: 67
Loss: 0.0502087329928399
ROC train: 0.999994	val: 0.896216	test: 0.688465
PRC train: 0.999999	val: 0.783171	test: 0.729153

Epoch: 68
Loss: 0.048638394067600586
ROC train: 0.999885	val: 0.885476	test: 0.683546
PRC train: 0.999978	val: 0.775713	test: 0.745948

Epoch: 69
Loss: 0.05482306671332001
ROC train: 0.999806	val: 0.877647	test: 0.673708
PRC train: 0.999964	val: 0.770585	test: 0.744239

Epoch: 70
Loss: 0.050887977588998566
ROC train: 0.999952	val: 0.882264	test: 0.684992
PRC train: 0.999991	val: 0.787162	test: 0.753611

Epoch: 71
Loss: 0.053939324001825176
ROC train: 0.999983	val: 0.890796	test: 0.703125
PRC train: 0.999997	val: 0.800049	test: 0.761872

Epoch: 72
Loss: 0.045622032880722994
ROC train: 0.999964	val: 0.901636	test: 0.710359
PRC train: 0.999993	val: 0.805308	test: 0.761649

Epoch: 73
Loss: 0.04407793293758805
ROC train: 0.999992	val: 0.897320	test: 0.689333
PRC train: 0.999998	val: 0.813004	test: 0.735955

Epoch: 74
Loss: 0.04687821807584051
ROC train: 0.999978	val: 0.905751	test: 0.676312
PRC train: 0.999996	val: 0.839007	test: 0.725971

Epoch: 75
Loss: 0.04069763485291633
ROC train: 0.999992	val: 0.909264	test: 0.679205
PRC train: 0.999998	val: 0.829063	test: 0.730494

Epoch: 76
Loss: 0.03870825592461251
ROC train: 0.999978	val: 0.902740	test: 0.700328
PRC train: 0.999996	val: 0.820685	test: 0.745858

Epoch: 77
Loss: 0.04974173402872425
ROC train: 0.999966	val: 0.901034	test: 0.702064
PRC train: 0.999994	val: 0.816634	test: 0.743147

Epoch: 78
Loss: 0.0442372709587972
ROC train: 0.999997	val: 0.893707	test: 0.694830
PRC train: 0.999999	val: 0.809073	test: 0.747828

Epoch: 79
Loss: 0.04974637135806505
ROC train: 0.999986	val: 0.896517	test: 0.671489
PRC train: 0.999997	val: 0.807735	test: 0.724000

Epoch: 80
Loss: 0.04247910756893195
ROC train: 0.999992	val: 0.899026	test: 0.675251
PRC train: 0.999998	val: 0.812198	test: 0.723375

Epoch: 81
Loss: 0.03471104097800321
ROC train: 0.999969	val: 0.902238	test: 0.704861
PRC train: 0.999994	val: 0.821906	test: 0.741745

Epoch: 82
Loss: 0.04503306522818214
ROC train: 1.000000	val: 0.900331	test: 0.711034
PRC train: 1.000000	val: 0.829076	test: 0.752378

Epoch: 83
Loss: 0.03507259301811429
ROC train: 1.000000	val: 0.894911	test: 0.687307
PRC train: 1.000000	val: 0.819367	test: 0.736391

Epoch: 84
Loss: 0.04288908998826934
ROC train: 0.999961	val: 0.896116	test: 0.667921
PRC train: 0.999993	val: 0.798325	test: 0.716205

Epoch: 85
Loss: 0.04130946243069055
ROC train: 1.000000	val: 0.880759	test: 0.661941
PRC train: 1.000000	val: 0.763351	test: 0.715778

Epoch: 86
Loss: 0.02863762612133978
ROC train: 0.999964	val: 0.879554	test: 0.679784
PRC train: 0.999993	val: 0.762827	test: 0.739139

Epoch: 87
Loss: 0.03981271915807085
ROC train: 1.000000	val: 0.888688	test: 0.687211
PRC train: 1.000000	val: 0.780901	test: 0.750751

Epoch: 88
Loss: 0.0348219441243747
ROC train: 1.000000	val: 0.894610	test: 0.683353
PRC train: 1.000000	val: 0.789465	test: 0.740313

Epoch: 89
Loss: 0.04226918014830372
ROC train: 0.999992	val: 0.889090	test: 0.678819
PRC train: 0.999998	val: 0.786212	test: 0.730564

Epoch: 90
Loss: 0.022853684340405515
ROC train: 0.999994	val: 0.894209	test: 0.688079
PRC train: 0.999999	val: 0.809418	test: 0.740612

Epoch: 91
Loss: 0.035244386279349435
ROC train: 1.000000	val: 0.894610	test: 0.699074
PRC train: 1.000000	val: 0.808616	test: 0.749093

Epoch: 92
Loss: 0.03873464048721287
ROC train: 0.999994	val: 0.889692	test: 0.698785
PRC train: 0.999999	val: 0.792289	test: 0.742632

Epoch: 93
Loss: 0.02873960077767262
ROC train: 0.999975	val: 0.892703	test: 0.691069
PRC train: 0.999560	val: 0.710663	test: 0.690310

Epoch: 95
Loss: 0.07670336153069504
ROC train: 0.998444	val: 0.859681	test: 0.683546
PRC train: 0.999701	val: 0.732916	test: 0.693084

Epoch: 96
Loss: 0.08082417505675447
ROC train: 0.998471	val: 0.857272	test: 0.687307
PRC train: 0.999708	val: 0.739385	test: 0.679239

Epoch: 97
Loss: 0.07764963744457885
ROC train: 0.997977	val: 0.844625	test: 0.689525
PRC train: 0.999616	val: 0.729321	test: 0.688790

Epoch: 98
Loss: 0.0941797863649605
ROC train: 0.998059	val: 0.857272	test: 0.701871
PRC train: 0.999632	val: 0.745142	test: 0.726923

Epoch: 99
Loss: 0.08759758586282558
ROC train: 0.998743	val: 0.858978	test: 0.700810
PRC train: 0.999763	val: 0.733054	test: 0.728246

Epoch: 100
Loss: 0.08822931977494912
ROC train: 0.995720	val: 0.835893	test: 0.693094
PRC train: 0.999146	val: 0.694626	test: 0.708484

Epoch: 101
Loss: 0.0799765699410837
ROC train: 0.998963	val: 0.870521	test: 0.708526
PRC train: 0.999801	val: 0.749733	test: 0.709913

Epoch: 102
Loss: 0.08617435280078586
ROC train: 0.998620	val: 0.860785	test: 0.708623
PRC train: 0.999735	val: 0.720340	test: 0.718096

Epoch: 103
Loss: 0.0761511449466814
ROC train: 0.998460	val: 0.849343	test: 0.699846
PRC train: 0.999708	val: 0.712744	test: 0.712091

Epoch: 104
Loss: 0.07636286822223733
ROC train: 0.998886	val: 0.833584	test: 0.693673
PRC train: 0.999788	val: 0.698777	test: 0.702167

Epoch: 105
Loss: 0.07468130169954311
ROC train: 0.998648	val: 0.848138	test: 0.678627
PRC train: 0.999744	val: 0.718694	test: 0.693313

Epoch: 106
Loss: 0.06460887250296396
ROC train: 0.999008	val: 0.855967	test: 0.691165
PRC train: 0.999810	val: 0.723821	test: 0.709936

Epoch: 107
Loss: 0.06398692383304475
ROC train: 0.999115	val: 0.859882	test: 0.691647
PRC train: 0.999831	val: 0.744550	test: 0.712458

Epoch: 108
Loss: 0.07702249319871736
ROC train: 0.999245	val: 0.861387	test: 0.701871
PRC train: 0.999856	val: 0.739860	test: 0.735158

Epoch: 109
Loss: 0.07334800996489248
ROC train: 0.999104	val: 0.876041	test: 0.697049
PRC train: 0.999828	val: 0.759223	test: 0.733333

Epoch: 110
Loss: 0.07077185532463007
ROC train: 0.998042	val: 0.868012	test: 0.693962
PRC train: 0.999625	val: 0.756400	test: 0.713943

Epoch: 111
Loss: 0.06537498382613777
ROC train: 0.998733	val: 0.858075	test: 0.690876
PRC train: 0.999758	val: 0.754309	test: 0.711233

Epoch: 112
Loss: 0.07677777065477143
ROC train: 0.999007	val: 0.868614	test: 0.668113
PRC train: 0.999811	val: 0.778914	test: 0.695185

Epoch: 113
Loss: 0.06395594867883352
ROC train: 0.999177	val: 0.856971	test: 0.675347
PRC train: 0.999842	val: 0.763631	test: 0.709677

Epoch: 114
Loss: 0.06689451547264415
ROC train: 0.999250	val: 0.859279	test: 0.690104
PRC train: 0.999856	val: 0.744704	test: 0.724571

Epoch: 115
Loss: 0.05590783619156355
ROC train: 0.998804	val: 0.866305	test: 0.697917
PRC train: 0.999772	val: 0.745885	test: 0.722134

Epoch: 116
Loss: 0.06584201651233638
ROC train: 0.999112	val: 0.867811	test: 0.680845
PRC train: 0.999830	val: 0.759438	test: 0.715431

Epoch: 117
Loss: 0.06471612009621507
ROC train: 0.999222	val: 0.869116	test: 0.663387
PRC train: 0.999852	val: 0.762719	test: 0.694535

Epoch: 118
Loss: 0.06355349895717101
ROC train: 0.999182	val: 0.867811	test: 0.681134
PRC train: 0.999844	val: 0.745043	test: 0.718336

Epoch: 119
Loss: 0.06408205394236154
ROC train: 0.999150	val: 0.843521	test: 0.700039
PRC train: 0.999838	val: 0.705714	test: 0.718530

Epoch: 120
Loss: 0.07130990274819264
ROC train: 0.999064	val: 0.861287	test: 0.682099
PRC train: 0.999821	val: 0.731180	test: 0.684795

Early stopping
Best (ROC):	 train: 0.932495	val: 0.925424	test: 0.673611
Best (PRC):	 train: 0.982330	val: 0.871848	test: 0.713850

PRC train: 0.999629	val: 0.758106	test: 0.687000

Epoch: 95
Loss: 0.08074776646623374
ROC train: 0.998590	val: 0.860484	test: 0.703511
PRC train: 0.999732	val: 0.749461	test: 0.732409

Epoch: 96
Loss: 0.08630542277452713
ROC train: 0.998425	val: 0.862090	test: 0.706308
PRC train: 0.999703	val: 0.745293	test: 0.745751

Epoch: 97
Loss: 0.08838137647734942
ROC train: 0.997864	val: 0.861989	test: 0.704668
PRC train: 0.999597	val: 0.738311	test: 0.740531

Epoch: 98
Loss: 0.07086237129148251
ROC train: 0.998155	val: 0.845227	test: 0.686150
PRC train: 0.999651	val: 0.718378	test: 0.689532

Epoch: 99
Loss: 0.08883393830847942
ROC train: 0.998464	val: 0.859179	test: 0.680556
PRC train: 0.999707	val: 0.738751	test: 0.695955

Epoch: 100
Loss: 0.08732591536518441
ROC train: 0.997810	val: 0.882666	test: 0.689815
PRC train: 0.999589	val: 0.781067	test: 0.736548

Epoch: 101
Loss: 0.08308969226407097
ROC train: 0.998703	val: 0.860484	test: 0.702353
PRC train: 0.999753	val: 0.744209	test: 0.738990

Epoch: 102
Loss: 0.07015640318399605
ROC train: 0.998826	val: 0.858577	test: 0.688561
PRC train: 0.999776	val: 0.736535	test: 0.708746

Epoch: 103
Loss: 0.09167231467420997
ROC train: 0.998897	val: 0.864699	test: 0.683353
PRC train: 0.999790	val: 0.754171	test: 0.715014

Epoch: 104
Loss: 0.08313057307847475
ROC train: 0.998993	val: 0.875339	test: 0.693287
PRC train: 0.999808	val: 0.768836	test: 0.714519

Epoch: 105
Loss: 0.07060825933944846
ROC train: 0.998575	val: 0.878751	test: 0.696759
PRC train: 0.999730	val: 0.785554	test: 0.701544

Epoch: 106
Loss: 0.05974897477270658
ROC train: 0.998858	val: 0.867811	test: 0.690779
PRC train: 0.999781	val: 0.778269	test: 0.704199

Epoch: 107
Loss: 0.08216208182528476
ROC train: 0.998771	val: 0.856469	test: 0.698110
PRC train: 0.999767	val: 0.747470	test: 0.713265

Epoch: 108
Loss: 0.08164138806203973
ROC train: 0.998676	val: 0.855264	test: 0.690876
PRC train: 0.999748	val: 0.728629	test: 0.693321

Epoch: 109
Loss: 0.08719446981484191
ROC train: 0.998785	val: 0.846633	test: 0.683835
PRC train: 0.999769	val: 0.733732	test: 0.690827

Epoch: 110
Loss: 0.09576709307376317
ROC train: 0.998088	val: 0.831577	test: 0.639178
PRC train: 0.999638	val: 0.705124	test: 0.665141

Epoch: 111
Loss: 0.07070526997702643
ROC train: 0.998494	val: 0.846131	test: 0.684317
PRC train: 0.999714	val: 0.717649	test: 0.719102

Epoch: 112
Loss: 0.08145304016118644
ROC train: 0.998495	val: 0.848238	test: 0.693866
PRC train: 0.999712	val: 0.725435	test: 0.728187

Epoch: 113
Loss: 0.08532293836010127
ROC train: 0.998294	val: 0.828867	test: 0.695698
PRC train: 0.999675	val: 0.697893	test: 0.729640

Epoch: 114
Loss: 0.07914603527564652
ROC train: 0.998920	val: 0.840510	test: 0.696084
PRC train: 0.999794	val: 0.721544	test: 0.720913

Epoch: 115
Loss: 0.06833398340109342
ROC train: 0.998660	val: 0.845729	test: 0.690008
PRC train: 0.999744	val: 0.728531	test: 0.722475

Epoch: 116
Loss: 0.07337138625476076
ROC train: 0.998881	val: 0.834186	test: 0.691551
PRC train: 0.999786	val: 0.707716	test: 0.720873

Epoch: 117
Loss: 0.05813488627485813
ROC train: 0.999042	val: 0.832581	test: 0.695698
PRC train: 0.999816	val: 0.708954	test: 0.724863

Epoch: 118
Loss: 0.06759002436474527
ROC train: 0.999106	val: 0.848238	test: 0.684510
PRC train: 0.999829	val: 0.718612	test: 0.716305

Epoch: 119
Loss: 0.06521218966939189
ROC train: 0.998837	val: 0.854963	test: 0.675829
PRC train: 0.999779	val: 0.728177	test: 0.711682

Epoch: 120
Loss: 0.07741914201010992
ROC train: 0.998446	val: 0.851651	test: 0.661458
PRC train: 0.999702	val: 0.724991	test: 0.679017

Early stopping
Best (ROC):	 train: 0.971702	val: 0.911774	test: 0.714410
Best (PRC):	 train: 0.992640	val: 0.853035	test: 0.769194

ROC train: 0.997902	val: 0.850447	test: 0.657022
PRC train: 0.999602	val: 0.723148	test: 0.665777

Epoch: 95
Loss: 0.07746736106035244
ROC train: 0.998437	val: 0.857272	test: 0.677566
PRC train: 0.999703	val: 0.728319	test: 0.687141

Epoch: 96
Loss: 0.06987466738368259
ROC train: 0.998240	val: 0.863595	test: 0.668306
PRC train: 0.999664	val: 0.744209	test: 0.658271

Epoch: 97
Loss: 0.0730166858445203
ROC train: 0.998781	val: 0.877045	test: 0.648245
PRC train: 0.999768	val: 0.770271	test: 0.644031

Epoch: 98
Loss: 0.07042410256618128
ROC train: 0.999003	val: 0.876242	test: 0.656346
PRC train: 0.999810	val: 0.768014	test: 0.659646

Epoch: 99
Loss: 0.08074029241184615
ROC train: 0.998315	val: 0.854060	test: 0.666860
PRC train: 0.999679	val: 0.740961	test: 0.666183

Epoch: 100
Loss: 0.06738035167684185
ROC train: 0.998060	val: 0.853659	test: 0.655671
PRC train: 0.999631	val: 0.735438	test: 0.658719

Epoch: 101
Loss: 0.0743338750586755
ROC train: 0.998905	val: 0.862692	test: 0.671682
PRC train: 0.999793	val: 0.737207	test: 0.672985

Epoch: 102
Loss: 0.06497804379638443
ROC train: 0.999126	val: 0.872227	test: 0.675444
PRC train: 0.999834	val: 0.748439	test: 0.674494

Epoch: 103
Loss: 0.07204379100465763
ROC train: 0.998876	val: 0.877948	test: 0.678530
PRC train: 0.999787	val: 0.765522	test: 0.672456

Epoch: 104
Loss: 0.06958810559574259
ROC train: 0.999087	val: 0.882766	test: 0.679012
PRC train: 0.999827	val: 0.762354	test: 0.682137

Epoch: 105
Loss: 0.06140513922626268
ROC train: 0.998568	val: 0.869216	test: 0.676022
PRC train: 0.999729	val: 0.753488	test: 0.681827

Epoch: 106
Loss: 0.07847053642991988
ROC train: 0.998965	val: 0.870220	test: 0.675154
PRC train: 0.999803	val: 0.748842	test: 0.680843

Epoch: 107
Loss: 0.0769062846619617
ROC train: 0.999007	val: 0.874636	test: 0.671971
PRC train: 0.999811	val: 0.759605	test: 0.683989

Epoch: 108
Loss: 0.058863945851149194
ROC train: 0.998906	val: 0.875339	test: 0.645351
PRC train: 0.999793	val: 0.760536	test: 0.649613

Epoch: 109
Loss: 0.06881921061804645
ROC train: 0.998133	val: 0.858075	test: 0.645158
PRC train: 0.999646	val: 0.737880	test: 0.641596

Epoch: 110
Loss: 0.08035184296164961
ROC train: 0.998926	val: 0.870621	test: 0.683160
PRC train: 0.999795	val: 0.744910	test: 0.690212

Epoch: 111
Loss: 0.07222546074171607
ROC train: 0.999227	val: 0.873432	test: 0.690297
PRC train: 0.999852	val: 0.749743	test: 0.713200

Epoch: 112
Loss: 0.06870945015667407
ROC train: 0.999237	val: 0.869919	test: 0.673322
PRC train: 0.999853	val: 0.750270	test: 0.683980

Epoch: 113
Loss: 0.07632066454759283
ROC train: 0.998882	val: 0.877848	test: 0.675637
PRC train: 0.999787	val: 0.765585	test: 0.697405

Epoch: 114
Loss: 0.0733857202530929
ROC train: 0.998313	val: 0.871324	test: 0.690104
PRC train: 0.999679	val: 0.748559	test: 0.707140

Epoch: 115
Loss: 0.07350584513126836
ROC train: 0.999119	val: 0.866506	test: 0.665509
PRC train: 0.999832	val: 0.746937	test: 0.676354

Epoch: 116
Loss: 0.1047429295196358
ROC train: 0.999003	val: 0.857774	test: 0.657504
PRC train: 0.999809	val: 0.742772	test: 0.664716

Epoch: 117
Loss: 0.06672837055567041
ROC train: 0.997225	val: 0.840309	test: 0.664159
PRC train: 0.999466	val: 0.711524	test: 0.665766

Epoch: 118
Loss: 0.08444059202076024
ROC train: 0.998314	val: 0.864800	test: 0.677758
PRC train: 0.999677	val: 0.757066	test: 0.689189

Epoch: 119
Loss: 0.07117702109510858
ROC train: 0.998815	val: 0.882967	test: 0.679977
PRC train: 0.999774	val: 0.793953	test: 0.691220

Epoch: 120
Loss: 0.05416095555925662
ROC train: 0.998673	val: 0.876242	test: 0.670235
PRC train: 0.999748	val: 0.768805	test: 0.666031

Early stopping
Best (ROC):	 train: 0.909629	val: 0.918398	test: 0.656539
Best (PRC):	 train: 0.977908	val: 0.839495	test: 0.696095
All runs completed.

ROC train: 0.999994	val: 0.808793	test: 0.686728
PRC train: 0.999999	val: 0.654808	test: 0.698227

Epoch: 94
Loss: 0.032645433677765665
ROC train: 0.999997	val: 0.820335	test: 0.698688
PRC train: 0.999999	val: 0.666735	test: 0.714048

Epoch: 95
Loss: 0.028586213276107608
ROC train: 0.999980	val: 0.820034	test: 0.696181
PRC train: 0.999996	val: 0.663195	test: 0.719347

Epoch: 96
Loss: 0.0445430788578965
ROC train: 0.999997	val: 0.814514	test: 0.679398
PRC train: 0.999999	val: 0.683947	test: 0.714936

Epoch: 97
Loss: 0.02717435486997197
ROC train: 0.999997	val: 0.851450	test: 0.685378
PRC train: 0.999999	val: 0.748608	test: 0.712637

Epoch: 98
Loss: 0.03700784770715034
ROC train: 1.000000	val: 0.859279	test: 0.690394
PRC train: 1.000000	val: 0.770877	test: 0.709850

Epoch: 99
Loss: 0.03326908848728834
ROC train: 1.000000	val: 0.853357	test: 0.708623
PRC train: 1.000000	val: 0.767341	test: 0.742849

Epoch: 100
Loss: 0.033220492435186995
ROC train: 1.000000	val: 0.843019	test: 0.711613
PRC train: 1.000000	val: 0.751049	test: 0.758610

Epoch: 101
Loss: 0.0321746966554141
ROC train: 1.000000	val: 0.842015	test: 0.697531
PRC train: 1.000000	val: 0.722849	test: 0.719568

Epoch: 102
Loss: 0.03698334077036385
ROC train: 1.000000	val: 0.812807	test: 0.659047
PRC train: 1.000000	val: 0.637044	test: 0.681502

Epoch: 103
Loss: 0.03511360773775327
ROC train: 1.000000	val: 0.799157	test: 0.660590
PRC train: 1.000000	val: 0.619034	test: 0.682208

Epoch: 104
Loss: 0.023037939089801777
ROC train: 1.000000	val: 0.813008	test: 0.681231
PRC train: 1.000000	val: 0.656269	test: 0.706287

Epoch: 105
Loss: 0.022044701035666355
ROC train: 1.000000	val: 0.832581	test: 0.687886
PRC train: 1.000000	val: 0.694995	test: 0.724512

Epoch: 106
Loss: 0.020487077601949504
ROC train: 1.000000	val: 0.838001	test: 0.695602
PRC train: 1.000000	val: 0.705778	test: 0.731678

Epoch: 107
Loss: 0.026460411707930676
ROC train: 1.000000	val: 0.841212	test: 0.703704
PRC train: 1.000000	val: 0.719813	test: 0.722098

Epoch: 108
Loss: 0.026901366513371033
ROC train: 1.000000	val: 0.789622	test: 0.700714
PRC train: 1.000000	val: 0.608492	test: 0.722712

Epoch: 109
Loss: 0.03339828177894301
ROC train: 1.000000	val: 0.798354	test: 0.685667
PRC train: 1.000000	val: 0.620577	test: 0.715619

Epoch: 110
Loss: 0.022964920231844387
ROC train: 1.000000	val: 0.811101	test: 0.686246
PRC train: 1.000000	val: 0.631550	test: 0.709616

Epoch: 111
Loss: 0.02182923158216086
ROC train: 1.000000	val: 0.819432	test: 0.691647
PRC train: 1.000000	val: 0.649077	test: 0.698311

Epoch: 112
Loss: 0.01638033922140587
ROC train: 1.000000	val: 0.817123	test: 0.685475
PRC train: 1.000000	val: 0.652315	test: 0.693011

Epoch: 113
Loss: 0.026918678353333583
ROC train: 1.000000	val: 0.824852	test: 0.693383
PRC train: 1.000000	val: 0.662629	test: 0.708620

Epoch: 114
Loss: 0.028313576960333115
ROC train: 1.000000	val: 0.842216	test: 0.708430
PRC train: 1.000000	val: 0.691839	test: 0.721635

Epoch: 115
Loss: 0.020387110782668832
ROC train: 0.999961	val: 0.842818	test: 0.698110
PRC train: 0.999993	val: 0.710763	test: 0.702929

Epoch: 116
Loss: 0.03509748845018091
ROC train: 1.000000	val: 0.851149	test: 0.702450
PRC train: 1.000000	val: 0.725322	test: 0.715371

Epoch: 117
Loss: 0.03273317836291338
ROC train: 1.000000	val: 0.834588	test: 0.703607
PRC train: 1.000000	val: 0.704169	test: 0.736420

Epoch: 118
Loss: 0.02572853951792941
ROC train: 1.000000	val: 0.800261	test: 0.701003
PRC train: 1.000000	val: 0.638218	test: 0.716627

Epoch: 119
Loss: 0.019755836492634477
ROC train: 1.000000	val: 0.828365	test: 0.714024
PRC train: 1.000000	val: 0.674697	test: 0.729820

Epoch: 120
Loss: 0.023575987154588134
ROC train: 1.000000	val: 0.816019	test: 0.711709
PRC train: 1.000000	val: 0.656358	test: 0.731589

Early stopping
Best (ROC):	 train: 0.870718	val: 0.882565	test: 0.659722
Best (PRC):	 train: 0.969712	val: 0.808150	test: 0.699942

ROC train: 0.999975	val: 0.845830	test: 0.631655
PRC train: 0.999995	val: 0.721578	test: 0.664703

Epoch: 94
Loss: 0.027778402136693445
ROC train: 1.000000	val: 0.850447	test: 0.630980
PRC train: 1.000000	val: 0.727145	test: 0.665598

Epoch: 95
Loss: 0.021340833153019347
ROC train: 1.000000	val: 0.852153	test: 0.640239
PRC train: 1.000000	val: 0.710581	test: 0.680023

Epoch: 96
Loss: 0.031211237326268633
ROC train: 1.000000	val: 0.858677	test: 0.624228
PRC train: 1.000000	val: 0.718031	test: 0.670718

Epoch: 97
Loss: 0.028237403814499344
ROC train: 1.000000	val: 0.850647	test: 0.636285
PRC train: 1.000000	val: 0.715056	test: 0.684423

Epoch: 98
Loss: 0.03163179411883087
ROC train: 1.000000	val: 0.851450	test: 0.645158
PRC train: 1.000000	val: 0.725373	test: 0.687458

Epoch: 99
Loss: 0.04197187403177961
ROC train: 1.000000	val: 0.856971	test: 0.650559
PRC train: 1.000000	val: 0.713345	test: 0.676903

Epoch: 100
Loss: 0.02990012125662554
ROC train: 1.000000	val: 0.864499	test: 0.642168
PRC train: 1.000000	val: 0.749061	test: 0.674000

Epoch: 101
Loss: 0.03180034469701599
ROC train: 1.000000	val: 0.867309	test: 0.633102
PRC train: 1.000000	val: 0.758673	test: 0.649441

Epoch: 102
Loss: 0.0309092485252719
ROC train: 1.000000	val: 0.873131	test: 0.644387
PRC train: 1.000000	val: 0.753178	test: 0.668245

Epoch: 103
Loss: 0.021891957471512034
ROC train: 1.000000	val: 0.862491	test: 0.635899
PRC train: 1.000000	val: 0.738724	test: 0.670424

Epoch: 104
Loss: 0.019068532025357614
ROC train: 1.000000	val: 0.863093	test: 0.632716
PRC train: 1.000000	val: 0.743401	test: 0.661778

Epoch: 105
Loss: 0.022109986832089423
ROC train: 1.000000	val: 0.854160	test: 0.639468
PRC train: 1.000000	val: 0.725399	test: 0.686727

Epoch: 106
Loss: 0.02111086236469504
ROC train: 1.000000	val: 0.852655	test: 0.632716
PRC train: 1.000000	val: 0.721972	test: 0.671361

Epoch: 107
Loss: 0.022491319157089757
ROC train: 1.000000	val: 0.876142	test: 0.638214
PRC train: 1.000000	val: 0.752647	test: 0.689856

Epoch: 108
Loss: 0.02700815773045068
ROC train: 0.999997	val: 0.862391	test: 0.638310
PRC train: 0.999999	val: 0.720190	test: 0.682760

Epoch: 109
Loss: 0.023316856778318157
ROC train: 0.999997	val: 0.850748	test: 0.619695
PRC train: 0.999999	val: 0.700200	test: 0.653586

Epoch: 110
Loss: 0.015366418149394908
ROC train: 1.000000	val: 0.838804	test: 0.601177
PRC train: 1.000000	val: 0.716026	test: 0.609857

Epoch: 111
Loss: 0.020756283613683976
ROC train: 1.000000	val: 0.835792	test: 0.618441
PRC train: 1.000000	val: 0.687247	test: 0.633714

Epoch: 112
Loss: 0.02268922079184163
ROC train: 1.000000	val: 0.848339	test: 0.638503
PRC train: 1.000000	val: 0.693099	test: 0.696236

Epoch: 113
Loss: 0.024260684540838278
ROC train: 1.000000	val: 0.825053	test: 0.629147
PRC train: 1.000000	val: 0.667331	test: 0.691060

Epoch: 114
Loss: 0.0365506579773075
ROC train: 0.999994	val: 0.824149	test: 0.635031
PRC train: 0.999999	val: 0.663167	test: 0.676236

Epoch: 115
Loss: 0.027005683744550868
ROC train: 1.000000	val: 0.860584	test: 0.652874
PRC train: 1.000000	val: 0.717103	test: 0.698347

Epoch: 116
Loss: 0.03320967010974111
ROC train: 1.000000	val: 0.880658	test: 0.652874
PRC train: 1.000000	val: 0.764805	test: 0.684010

Epoch: 117
Loss: 0.03410031140564518
ROC train: 0.999997	val: 0.857071	test: 0.643808
PRC train: 0.999999	val: 0.740225	test: 0.652653

Epoch: 118
Loss: 0.03379282913641118
ROC train: 1.000000	val: 0.856971	test: 0.625289
PRC train: 1.000000	val: 0.743176	test: 0.632215

Epoch: 119
Loss: 0.03154162971186462
ROC train: 1.000000	val: 0.883971	test: 0.633584
PRC train: 1.000000	val: 0.783067	test: 0.670077

Epoch: 120
Loss: 0.017696575842351972
ROC train: 0.999992	val: 0.876543	test: 0.630691
PRC train: 0.999998	val: 0.752220	test: 0.692409

Early stopping
Best (ROC):	 train: 0.992336	val: 0.900432	test: 0.648341
Best (PRC):	 train: 0.998494	val: 0.832180	test: 0.735760

ROC train: 1.000000	val: 0.866707	test: 0.720968
PRC train: 1.000000	val: 0.743605	test: 0.785326

Epoch: 94
Loss: 0.012061234717356383
ROC train: 0.999997	val: 0.863093	test: 0.724730
PRC train: 0.999999	val: 0.761475	test: 0.795473

Epoch: 95
Loss: 0.029127258502757658
ROC train: 1.000000	val: 0.848038	test: 0.717689
PRC train: 1.000000	val: 0.728807	test: 0.788680

Epoch: 96
Loss: 0.019948747882503084
ROC train: 1.000000	val: 0.856369	test: 0.709780
PRC train: 1.000000	val: 0.737682	test: 0.774443

Epoch: 97
Loss: 0.023984875896040196
ROC train: 1.000000	val: 0.870421	test: 0.714796
PRC train: 1.000000	val: 0.769875	test: 0.779295

Epoch: 98
Loss: 0.028862404692348693
ROC train: 1.000000	val: 0.868212	test: 0.712191
PRC train: 1.000000	val: 0.779905	test: 0.765349

Epoch: 99
Loss: 0.027912887396789536
ROC train: 1.000000	val: 0.865904	test: 0.720679
PRC train: 1.000000	val: 0.760894	test: 0.785527

Epoch: 100
Loss: 0.03895337389633767
ROC train: 1.000000	val: 0.858376	test: 0.713059
PRC train: 1.000000	val: 0.743803	test: 0.787405

Epoch: 101
Loss: 0.022516907191177975
ROC train: 0.999994	val: 0.847837	test: 0.703704
PRC train: 0.999999	val: 0.746814	test: 0.769364

Epoch: 102
Loss: 0.03377521644004853
ROC train: 1.000000	val: 0.874034	test: 0.709684
PRC train: 1.000000	val: 0.771306	test: 0.771706

Epoch: 103
Loss: 0.03245043590789419
ROC train: 1.000000	val: 0.871625	test: 0.709587
PRC train: 1.000000	val: 0.792208	test: 0.772806

Epoch: 104
Loss: 0.03610651337724994
ROC train: 1.000000	val: 0.842517	test: 0.710359
PRC train: 1.000000	val: 0.735047	test: 0.780141

Epoch: 105
Loss: 0.026773192719565624
ROC train: 0.999989	val: 0.821239	test: 0.700907
PRC train: 0.999998	val: 0.709919	test: 0.764733

Epoch: 106
Loss: 0.028205822778035926
ROC train: 0.999997	val: 0.847134	test: 0.704282
PRC train: 0.999999	val: 0.743936	test: 0.775153

Epoch: 107
Loss: 0.030334189702080377
ROC train: 0.999994	val: 0.870722	test: 0.709877
PRC train: 0.999999	val: 0.793670	test: 0.771839

Epoch: 108
Loss: 0.020388931450787524
ROC train: 1.000000	val: 0.877145	test: 0.719136
PRC train: 1.000000	val: 0.778283	test: 0.780334

Epoch: 109
Loss: 0.028486315331835932
ROC train: 1.000000	val: 0.827060	test: 0.692226
PRC train: 1.000000	val: 0.722948	test: 0.749617

Epoch: 110
Loss: 0.02241202286776368
ROC train: 1.000000	val: 0.813711	test: 0.681231
PRC train: 1.000000	val: 0.700052	test: 0.742497

Epoch: 111
Loss: 0.02210691470405529
ROC train: 1.000000	val: 0.846733	test: 0.695312
PRC train: 1.000000	val: 0.741946	test: 0.763159

Epoch: 112
Loss: 0.030053477876078132
ROC train: 1.000000	val: 0.841514	test: 0.702257
PRC train: 1.000000	val: 0.750595	test: 0.769687

Epoch: 113
Loss: 0.022227139005304365
ROC train: 1.000000	val: 0.831677	test: 0.707176
PRC train: 1.000000	val: 0.733182	test: 0.775816

Epoch: 114
Loss: 0.01536116556986111
ROC train: 1.000000	val: 0.835090	test: 0.697338
PRC train: 1.000000	val: 0.715011	test: 0.763691

Epoch: 115
Loss: 0.028529459836363704
ROC train: 1.000000	val: 0.839908	test: 0.683835
PRC train: 1.000000	val: 0.724018	test: 0.751588

Epoch: 116
Loss: 0.023865211066544018
ROC train: 1.000000	val: 0.834588	test: 0.694252
PRC train: 1.000000	val: 0.729251	test: 0.772373

Epoch: 117
Loss: 0.021869048471973327
ROC train: 1.000000	val: 0.828766	test: 0.696277
PRC train: 1.000000	val: 0.706151	test: 0.774241

Epoch: 118
Loss: 0.016412381714519333
ROC train: 1.000000	val: 0.837800	test: 0.694059
PRC train: 1.000000	val: 0.705656	test: 0.759133

Epoch: 119
Loss: 0.024096168255327184
ROC train: 1.000000	val: 0.834488	test: 0.685957
PRC train: 1.000000	val: 0.730342	test: 0.736660

Epoch: 120
Loss: 0.019638609931677566
ROC train: 1.000000	val: 0.816320	test: 0.695120
PRC train: 1.000000	val: 0.698446	test: 0.769828

Early stopping
Best (ROC):	 train: 0.862986	val: 0.898826	test: 0.676698
Best (PRC):	 train: 0.964696	val: 0.825177	test: 0.727845

ROC train: 1.000000	val: 0.841413	test: 0.616416
PRC train: 1.000000	val: 0.720309	test: 0.661417

Epoch: 94
Loss: 0.0353093732183059
ROC train: 1.000000	val: 0.831075	test: 0.631752
PRC train: 1.000000	val: 0.714443	test: 0.697044

Epoch: 95
Loss: 0.033175521166778014
ROC train: 1.000000	val: 0.804276	test: 0.640336
PRC train: 1.000000	val: 0.647014	test: 0.697089

Epoch: 96
Loss: 0.03499933095320685
ROC train: 1.000000	val: 0.814112	test: 0.634838
PRC train: 1.000000	val: 0.645182	test: 0.699095

Epoch: 97
Loss: 0.02456581734436914
ROC train: 1.000000	val: 0.839707	test: 0.635417
PRC train: 1.000000	val: 0.688582	test: 0.702682

Epoch: 98
Loss: 0.030828602873996174
ROC train: 1.000000	val: 0.847235	test: 0.618924
PRC train: 1.000000	val: 0.701474	test: 0.669398

Epoch: 99
Loss: 0.019817718857491635
ROC train: 1.000000	val: 0.809596	test: 0.571759
PRC train: 1.000000	val: 0.653030	test: 0.593535

Epoch: 100
Loss: 0.03329372621045733
ROC train: 1.000000	val: 0.823146	test: 0.580922
PRC train: 1.000000	val: 0.680253	test: 0.608093

Epoch: 101
Loss: 0.021182208437392682
ROC train: 1.000000	val: 0.840008	test: 0.605131
PRC train: 1.000000	val: 0.707337	test: 0.645709

Epoch: 102
Loss: 0.0263620679786627
ROC train: 1.000000	val: 0.840610	test: 0.621528
PRC train: 1.000000	val: 0.695551	test: 0.671073

Epoch: 103
Loss: 0.025949070741450666
ROC train: 1.000000	val: 0.868915	test: 0.621528
PRC train: 1.000000	val: 0.732302	test: 0.641157

Epoch: 104
Loss: 0.025575528439410106
ROC train: 1.000000	val: 0.846432	test: 0.589410
PRC train: 1.000000	val: 0.694163	test: 0.618986

Epoch: 105
Loss: 0.0245474402526818
ROC train: 1.000000	val: 0.834186	test: 0.591049
PRC train: 1.000000	val: 0.687487	test: 0.612443

Epoch: 106
Loss: 0.023064258727627848
ROC train: 1.000000	val: 0.841212	test: 0.618441
PRC train: 1.000000	val: 0.694954	test: 0.655047

Epoch: 107
Loss: 0.021669965438130163
ROC train: 1.000000	val: 0.851350	test: 0.644676
PRC train: 1.000000	val: 0.711859	test: 0.681902

Epoch: 108
Loss: 0.028024048080911683
ROC train: 1.000000	val: 0.826157	test: 0.646508
PRC train: 1.000000	val: 0.657664	test: 0.694722

Epoch: 109
Loss: 0.024502105844552306
ROC train: 1.000000	val: 0.813109	test: 0.625386
PRC train: 1.000000	val: 0.642488	test: 0.670351

Epoch: 110
Loss: 0.02440000877478982
ROC train: 1.000000	val: 0.835893	test: 0.636671
PRC train: 1.000000	val: 0.683226	test: 0.682047

Epoch: 111
Loss: 0.024370078388715233
ROC train: 1.000000	val: 0.820636	test: 0.628762
PRC train: 1.000000	val: 0.707572	test: 0.679365

Epoch: 112
Loss: 0.01616104965221663
ROC train: 1.000000	val: 0.793938	test: 0.633681
PRC train: 1.000000	val: 0.649332	test: 0.696844

Epoch: 113
Loss: 0.026260900625663157
ROC train: 1.000000	val: 0.837499	test: 0.637731
PRC train: 1.000000	val: 0.735939	test: 0.691966

Epoch: 114
Loss: 0.035729483254794865
ROC train: 1.000000	val: 0.839205	test: 0.649209
PRC train: 1.000000	val: 0.734272	test: 0.702099

Epoch: 115
Loss: 0.021586778535234722
ROC train: 1.000000	val: 0.816722	test: 0.641204
PRC train: 1.000000	val: 0.688998	test: 0.722159

Epoch: 116
Loss: 0.021668343446847465
ROC train: 1.000000	val: 0.818529	test: 0.648534
PRC train: 1.000000	val: 0.699429	test: 0.730158

Epoch: 117
Loss: 0.01673717071027373
ROC train: 1.000000	val: 0.810499	test: 0.641686
PRC train: 1.000000	val: 0.672018	test: 0.718798

Epoch: 118
Loss: 0.017619638775261227
ROC train: 1.000000	val: 0.801265	test: 0.630208
PRC train: 1.000000	val: 0.640783	test: 0.669886

Epoch: 119
Loss: 0.01941169640347265
ROC train: 1.000000	val: 0.798454	test: 0.623843
PRC train: 1.000000	val: 0.644615	test: 0.640235

Epoch: 120
Loss: 0.015104710098820653
ROC train: 1.000000	val: 0.799257	test: 0.616802
PRC train: 1.000000	val: 0.646725	test: 0.631176

Early stopping
Best (ROC):	 train: 0.855602	val: 0.879956	test: 0.649595
Best (PRC):	 train: 0.965853	val: 0.823312	test: 0.702865

PRC train: 1.000000	val: 0.787119	test: 0.709700

Epoch: 94
Loss: 0.03017794159876728
ROC train: 1.000000	val: 0.892904	test: 0.704186
PRC train: 1.000000	val: 0.807004	test: 0.711387

Epoch: 95
Loss: 0.020393632606406052
ROC train: 1.000000	val: 0.898123	test: 0.691840
PRC train: 1.000000	val: 0.810719	test: 0.713500

Epoch: 96
Loss: 0.035616164674680234
ROC train: 1.000000	val: 0.891499	test: 0.684028
PRC train: 1.000000	val: 0.797798	test: 0.722563

Epoch: 97
Loss: 0.02791328856438981
ROC train: 1.000000	val: 0.889993	test: 0.703125
PRC train: 1.000000	val: 0.803151	test: 0.717492

Epoch: 98
Loss: 0.03842883585693751
ROC train: 1.000000	val: 0.888688	test: 0.695312
PRC train: 1.000000	val: 0.805026	test: 0.689554

Epoch: 99
Loss: 0.027434352038288732
ROC train: 1.000000	val: 0.896818	test: 0.696470
PRC train: 1.000000	val: 0.815962	test: 0.717998

Epoch: 100
Loss: 0.029730327315594097
ROC train: 1.000000	val: 0.890394	test: 0.684799
PRC train: 1.000000	val: 0.794051	test: 0.688485

Epoch: 101
Loss: 0.02267302248310099
ROC train: 0.999989	val: 0.882666	test: 0.677951
PRC train: 0.999998	val: 0.778008	test: 0.687129

Epoch: 102
Loss: 0.030190542337587927
ROC train: 1.000000	val: 0.892000	test: 0.684317
PRC train: 1.000000	val: 0.796522	test: 0.697101

Epoch: 103
Loss: 0.025870318587563022
ROC train: 1.000000	val: 0.896818	test: 0.694348
PRC train: 1.000000	val: 0.812412	test: 0.695742

Epoch: 104
Loss: 0.024063064143568506
ROC train: 1.000000	val: 0.881963	test: 0.692033
PRC train: 1.000000	val: 0.779675	test: 0.672252

Epoch: 105
Loss: 0.0338829691597926
ROC train: 1.000000	val: 0.877948	test: 0.696759
PRC train: 1.000000	val: 0.766745	test: 0.696976

Epoch: 106
Loss: 0.035337170215151696
ROC train: 1.000000	val: 0.895413	test: 0.698978
PRC train: 1.000000	val: 0.794885	test: 0.699715

Epoch: 107
Loss: 0.03307885115630692
ROC train: 0.999863	val: 0.884372	test: 0.683835
PRC train: 0.999974	val: 0.761753	test: 0.678599

Epoch: 108
Loss: 0.04269237196184234
ROC train: 1.000000	val: 0.902740	test: 0.694348
PRC train: 1.000000	val: 0.821795	test: 0.709624

Epoch: 109
Loss: 0.024523233047114686
ROC train: 1.000000	val: 0.902138	test: 0.709973
PRC train: 1.000000	val: 0.829633	test: 0.731659

Epoch: 110
Loss: 0.02677186480062733
ROC train: 1.000000	val: 0.886279	test: 0.708719
PRC train: 1.000000	val: 0.809743	test: 0.725976

Epoch: 111
Loss: 0.019685432757881826
ROC train: 1.000000	val: 0.884272	test: 0.701196
PRC train: 1.000000	val: 0.802136	test: 0.708524

Epoch: 112
Loss: 0.032128881305112926
ROC train: 1.000000	val: 0.886179	test: 0.694059
PRC train: 1.000000	val: 0.791534	test: 0.689345

Epoch: 113
Loss: 0.021556255660276663
ROC train: 1.000000	val: 0.889190	test: 0.692805
PRC train: 1.000000	val: 0.794337	test: 0.701655

Epoch: 114
Loss: 0.01587104580209011
ROC train: 1.000000	val: 0.891800	test: 0.709105
PRC train: 1.000000	val: 0.795767	test: 0.734171

Epoch: 115
Loss: 0.014280001825403508
ROC train: 1.000000	val: 0.889792	test: 0.711709
PRC train: 1.000000	val: 0.803607	test: 0.744952

Epoch: 116
Loss: 0.023379628482478154
ROC train: 1.000000	val: 0.895714	test: 0.711420
PRC train: 1.000000	val: 0.810658	test: 0.733220

Epoch: 117
Loss: 0.017158201551551063
ROC train: 1.000000	val: 0.899428	test: 0.707176
PRC train: 1.000000	val: 0.820149	test: 0.722075

Epoch: 118
Loss: 0.015919200593519724
ROC train: 1.000000	val: 0.894610	test: 0.709635
PRC train: 1.000000	val: 0.812096	test: 0.709406

Epoch: 119
Loss: 0.02203733773636155
ROC train: 1.000000	val: 0.887283	test: 0.714024
PRC train: 1.000000	val: 0.798052	test: 0.725741

Epoch: 120
Loss: 0.03021792700265922
ROC train: 1.000000	val: 0.885376	test: 0.710455
PRC train: 1.000000	val: 0.786403	test: 0.725089

Early stopping
Best (ROC):	 train: 0.883965	val: 0.915889	test: 0.661651
Best (PRC):	 train: 0.972593	val: 0.838160	test: 0.711670

PRC train: 0.999999	val: 0.700973	test: 0.661343

Epoch: 94
Loss: 0.027223332110401073
ROC train: 1.000000	val: 0.808090	test: 0.651138
PRC train: 1.000000	val: 0.710218	test: 0.656532

Epoch: 95
Loss: 0.02994166474613977
ROC train: 1.000000	val: 0.787614	test: 0.632234
PRC train: 1.000000	val: 0.648955	test: 0.639715

Epoch: 96
Loss: 0.03130095965885598
ROC train: 1.000000	val: 0.809696	test: 0.620081
PRC train: 1.000000	val: 0.680910	test: 0.642696

Epoch: 97
Loss: 0.022883339636171025
ROC train: 1.000000	val: 0.845127	test: 0.636381
PRC train: 1.000000	val: 0.730177	test: 0.661122

Epoch: 98
Loss: 0.02360123062217036
ROC train: 1.000000	val: 0.836194	test: 0.631752
PRC train: 1.000000	val: 0.715259	test: 0.643470

Epoch: 99
Loss: 0.027078270587789974
ROC train: 1.000000	val: 0.799960	test: 0.628762
PRC train: 1.000000	val: 0.672557	test: 0.635403

Epoch: 100
Loss: 0.028641106203889266
ROC train: 0.999997	val: 0.811001	test: 0.645930
PRC train: 0.999999	val: 0.693754	test: 0.659108

Epoch: 101
Loss: 0.03443080818291755
ROC train: 1.000000	val: 0.829369	test: 0.641204
PRC train: 1.000000	val: 0.728089	test: 0.653329

Epoch: 102
Loss: 0.02313333915022322
ROC train: 1.000000	val: 0.825755	test: 0.646605
PRC train: 1.000000	val: 0.728969	test: 0.660247

Epoch: 103
Loss: 0.026584986956309686
ROC train: 1.000000	val: 0.836796	test: 0.656539
PRC train: 1.000000	val: 0.736523	test: 0.678213

Epoch: 104
Loss: 0.03269824297265302
ROC train: 1.000000	val: 0.837097	test: 0.634934
PRC train: 1.000000	val: 0.723288	test: 0.666336

Epoch: 105
Loss: 0.01832014519002927
ROC train: 1.000000	val: 0.842015	test: 0.622782
PRC train: 1.000000	val: 0.752987	test: 0.656614

Epoch: 106
Loss: 0.015243454728041972
ROC train: 1.000000	val: 0.853157	test: 0.609182
PRC train: 1.000000	val: 0.780870	test: 0.645112

Epoch: 107
Loss: 0.03004396535318244
ROC train: 0.999994	val: 0.855064	test: 0.630594
PRC train: 0.999999	val: 0.768217	test: 0.650579

Epoch: 108
Loss: 0.03160162268005335
ROC train: 0.999972	val: 0.841012	test: 0.646123
PRC train: 0.999995	val: 0.756781	test: 0.661783

Epoch: 109
Loss: 0.01721633970007734
ROC train: 1.000000	val: 0.841815	test: 0.650849
PRC train: 1.000000	val: 0.735789	test: 0.682665

Epoch: 110
Loss: 0.025744107990895364
ROC train: 1.000000	val: 0.849343	test: 0.660687
PRC train: 1.000000	val: 0.756534	test: 0.688310

Epoch: 111
Loss: 0.014786587855975359
ROC train: 1.000000	val: 0.839105	test: 0.663387
PRC train: 1.000000	val: 0.751543	test: 0.687216

Epoch: 112
Loss: 0.02093018163871304
ROC train: 1.000000	val: 0.828365	test: 0.658372
PRC train: 1.000000	val: 0.733885	test: 0.684139

Epoch: 113
Loss: 0.014179109510206797
ROC train: 1.000000	val: 0.826960	test: 0.654321
PRC train: 1.000000	val: 0.715933	test: 0.686288

Epoch: 114
Loss: 0.019283850112081297
ROC train: 1.000000	val: 0.841112	test: 0.656539
PRC train: 1.000000	val: 0.737669	test: 0.692129

Epoch: 115
Loss: 0.021833938916256235
ROC train: 1.000000	val: 0.849945	test: 0.661651
PRC train: 1.000000	val: 0.759602	test: 0.693411

Epoch: 116
Loss: 0.01822755146848905
ROC train: 1.000000	val: 0.855566	test: 0.670718
PRC train: 1.000000	val: 0.769702	test: 0.703126

Epoch: 117
Loss: 0.0144754293353721
ROC train: 1.000000	val: 0.839908	test: 0.666763
PRC train: 1.000000	val: 0.752622	test: 0.690807

Epoch: 118
Loss: 0.024100094254181362
ROC train: 1.000000	val: 0.818428	test: 0.655382
PRC train: 1.000000	val: 0.721384	test: 0.689028

Epoch: 119
Loss: 0.022568489743688167
ROC train: 1.000000	val: 0.804878	test: 0.657793
PRC train: 1.000000	val: 0.702367	test: 0.676479

Epoch: 120
Loss: 0.014140723135109137
ROC train: 1.000000	val: 0.809495	test: 0.660397
PRC train: 1.000000	val: 0.714862	test: 0.675896

Early stopping
Best (ROC):	 train: 0.729069	val: 0.901335	test: 0.626061
Best (PRC):	 train: 0.918830	val: 0.859290	test: 0.666425

PRC train: 1.000000	val: 0.835083	test: 0.661867

Epoch: 94
Loss: 0.02230721374816056
ROC train: 1.000000	val: 0.894409	test: 0.592110
PRC train: 1.000000	val: 0.821681	test: 0.604208

Epoch: 95
Loss: 0.03530166253174425
ROC train: 1.000000	val: 0.887383	test: 0.606867
PRC train: 1.000000	val: 0.796523	test: 0.625566

Epoch: 96
Loss: 0.03411464971449007
ROC train: 1.000000	val: 0.877346	test: 0.618634
PRC train: 1.000000	val: 0.786333	test: 0.636500

Epoch: 97
Loss: 0.02430366892417036
ROC train: 1.000000	val: 0.884774	test: 0.622975
PRC train: 1.000000	val: 0.819543	test: 0.646123

Epoch: 98
Loss: 0.030208209266785444
ROC train: 1.000000	val: 0.900532	test: 0.644483
PRC train: 1.000000	val: 0.812722	test: 0.708052

Epoch: 99
Loss: 0.016362462765105872
ROC train: 1.000000	val: 0.901435	test: 0.638503
PRC train: 1.000000	val: 0.805122	test: 0.697351

Epoch: 100
Loss: 0.019025894507736625
ROC train: 1.000000	val: 0.908963	test: 0.632234
PRC train: 1.000000	val: 0.831163	test: 0.666325

Epoch: 101
Loss: 0.022447647902413482
ROC train: 1.000000	val: 0.901636	test: 0.634163
PRC train: 1.000000	val: 0.807547	test: 0.679480

Epoch: 102
Loss: 0.016873513928610966
ROC train: 1.000000	val: 0.892803	test: 0.625482
PRC train: 1.000000	val: 0.811501	test: 0.674957

Epoch: 103
Loss: 0.023844358843565554
ROC train: 0.999997	val: 0.865201	test: 0.605228
PRC train: 0.999999	val: 0.782077	test: 0.652949

Epoch: 104
Loss: 0.030295965621878387
ROC train: 1.000000	val: 0.881261	test: 0.640239
PRC train: 1.000000	val: 0.792795	test: 0.690066

Epoch: 105
Loss: 0.01960745859597061
ROC train: 0.999980	val: 0.870220	test: 0.654900
PRC train: 0.999996	val: 0.750106	test: 0.693861

Epoch: 106
Loss: 0.02686042552620627
ROC train: 1.000000	val: 0.884372	test: 0.646894
PRC train: 1.000000	val: 0.796611	test: 0.703783

Epoch: 107
Loss: 0.02182875644890365
ROC train: 1.000000	val: 0.884473	test: 0.637153
PRC train: 1.000000	val: 0.812226	test: 0.687169

Epoch: 108
Loss: 0.02852451084118813
ROC train: 1.000000	val: 0.878852	test: 0.642168
PRC train: 1.000000	val: 0.787612	test: 0.697900

Epoch: 109
Loss: 0.02821673106209651
ROC train: 1.000000	val: 0.867510	test: 0.624518
PRC train: 1.000000	val: 0.768811	test: 0.662216

Epoch: 110
Loss: 0.027284158423306858
ROC train: 1.000000	val: 0.883268	test: 0.614198
PRC train: 1.000000	val: 0.790206	test: 0.638202

Epoch: 111
Loss: 0.025857453078376374
ROC train: 1.000000	val: 0.895614	test: 0.608796
PRC train: 1.000000	val: 0.806526	test: 0.641534

Epoch: 112
Loss: 0.019037961869840598
ROC train: 1.000000	val: 0.891197	test: 0.612076
PRC train: 1.000000	val: 0.803607	test: 0.665763

Epoch: 113
Loss: 0.02192107195118243
ROC train: 1.000000	val: 0.898324	test: 0.641879
PRC train: 1.000000	val: 0.812344	test: 0.697811

Epoch: 114
Loss: 0.024307110254656917
ROC train: 1.000000	val: 0.899328	test: 0.647087
PRC train: 1.000000	val: 0.811618	test: 0.711414

Epoch: 115
Loss: 0.01723061508455974
ROC train: 1.000000	val: 0.888387	test: 0.644001
PRC train: 1.000000	val: 0.780863	test: 0.704216

Epoch: 116
Loss: 0.014865096658362139
ROC train: 1.000000	val: 0.870922	test: 0.621721
PRC train: 1.000000	val: 0.748785	test: 0.655367

Epoch: 117
Loss: 0.015112217989902879
ROC train: 1.000000	val: 0.892101	test: 0.616609
PRC train: 1.000000	val: 0.798997	test: 0.644457

Epoch: 118
Loss: 0.013534819166470277
ROC train: 1.000000	val: 0.891197	test: 0.614198
PRC train: 1.000000	val: 0.811735	test: 0.631546

Epoch: 119
Loss: 0.010734475633819181
ROC train: 1.000000	val: 0.889190	test: 0.606096
PRC train: 1.000000	val: 0.829191	test: 0.619916

Epoch: 120
Loss: 0.013880279007281417
ROC train: 1.000000	val: 0.899227	test: 0.608410
PRC train: 1.000000	val: 0.820913	test: 0.631587

Early stopping
Best (ROC):	 train: 0.999992	val: 0.925725	test: 0.658468
Best (PRC):	 train: 0.999998	val: 0.891600	test: 0.697854

PRC train: 0.999995	val: 0.789942	test: 0.735109

Epoch: 94
Loss: 0.03373303570680584
ROC train: 1.000000	val: 0.897320	test: 0.681231
PRC train: 1.000000	val: 0.814288	test: 0.723599

Epoch: 95
Loss: 0.02420872933448079
ROC train: 1.000000	val: 0.899930	test: 0.676408
PRC train: 1.000000	val: 0.823281	test: 0.717780

Epoch: 96
Loss: 0.025546566208757508
ROC train: 1.000000	val: 0.908361	test: 0.687211
PRC train: 1.000000	val: 0.828325	test: 0.729835

Epoch: 97
Loss: 0.037584807113801286
ROC train: 1.000000	val: 0.903041	test: 0.695409
PRC train: 1.000000	val: 0.820776	test: 0.738749

Epoch: 98
Loss: 0.028724659324951312
ROC train: 1.000000	val: 0.890194	test: 0.696663
PRC train: 1.000000	val: 0.808656	test: 0.738698

Epoch: 99
Loss: 0.021413777461330257
ROC train: 1.000000	val: 0.895815	test: 0.688272
PRC train: 1.000000	val: 0.813824	test: 0.729424

Epoch: 100
Loss: 0.019821319958140998
ROC train: 1.000000	val: 0.891097	test: 0.678241
PRC train: 1.000000	val: 0.790849	test: 0.713913

Epoch: 101
Loss: 0.03360032286001947
ROC train: 1.000000	val: 0.892904	test: 0.692901
PRC train: 1.000000	val: 0.779078	test: 0.736419

Epoch: 102
Loss: 0.02760106768341616
ROC train: 1.000000	val: 0.895413	test: 0.705247
PRC train: 1.000000	val: 0.789318	test: 0.745562

Epoch: 103
Loss: 0.02696762287466557
ROC train: 1.000000	val: 0.903041	test: 0.699171
PRC train: 1.000000	val: 0.804373	test: 0.750948

Epoch: 104
Loss: 0.02317174008073974
ROC train: 1.000000	val: 0.899629	test: 0.675540
PRC train: 1.000000	val: 0.804681	test: 0.728606

Epoch: 105
Loss: 0.019190066615526157
ROC train: 1.000000	val: 0.898223	test: 0.677469
PRC train: 1.000000	val: 0.811383	test: 0.731486

Epoch: 106
Loss: 0.021361190432646882
ROC train: 1.000000	val: 0.884071	test: 0.683160
PRC train: 1.000000	val: 0.783658	test: 0.741771

Epoch: 107
Loss: 0.020002018534841015
ROC train: 0.999997	val: 0.874837	test: 0.676794
PRC train: 0.999999	val: 0.768116	test: 0.737842

Epoch: 108
Loss: 0.027664769309772175
ROC train: 0.999997	val: 0.880558	test: 0.675829
PRC train: 0.999999	val: 0.773672	test: 0.727911

Epoch: 109
Loss: 0.020653875407364863
ROC train: 1.000000	val: 0.888889	test: 0.680073
PRC train: 1.000000	val: 0.778356	test: 0.727981

Epoch: 110
Loss: 0.026636800641588996
ROC train: 1.000000	val: 0.893305	test: 0.668499
PRC train: 1.000000	val: 0.782113	test: 0.716119

Epoch: 111
Loss: 0.02129393515740389
ROC train: 1.000000	val: 0.895313	test: 0.682774
PRC train: 1.000000	val: 0.784860	test: 0.729307

Epoch: 112
Loss: 0.03414805623583763
ROC train: 1.000000	val: 0.893807	test: 0.688175
PRC train: 1.000000	val: 0.773526	test: 0.733205

Epoch: 113
Loss: 0.036980058281774884
ROC train: 1.000000	val: 0.890595	test: 0.694444
PRC train: 1.000000	val: 0.764638	test: 0.735151

Epoch: 114
Loss: 0.04234547912157183
ROC train: 0.999913	val: 0.892904	test: 0.688175
PRC train: 0.999983	val: 0.766745	test: 0.704898

Epoch: 115
Loss: 0.03148943423384893
ROC train: 0.999992	val: 0.906956	test: 0.713542
PRC train: 0.999998	val: 0.811345	test: 0.735360

Epoch: 116
Loss: 0.02597312310880599
ROC train: 1.000000	val: 0.889290	test: 0.711034
PRC train: 1.000000	val: 0.787074	test: 0.742461

Epoch: 117
Loss: 0.026237879149334082
ROC train: 0.999997	val: 0.892402	test: 0.692419
PRC train: 0.999999	val: 0.805445	test: 0.725013

Epoch: 118
Loss: 0.02839162989577489
ROC train: 1.000000	val: 0.896316	test: 0.676022
PRC train: 1.000000	val: 0.812661	test: 0.715924

Epoch: 119
Loss: 0.0225383666825693
ROC train: 1.000000	val: 0.896417	test: 0.685475
PRC train: 1.000000	val: 0.810562	test: 0.723356

Epoch: 120
Loss: 0.03359532861096415
ROC train: 1.000000	val: 0.890394	test: 0.698302
PRC train: 1.000000	val: 0.805328	test: 0.732932

Early stopping
Best (ROC):	 train: 0.999700	val: 0.913380	test: 0.682677
Best (PRC):	 train: 0.999943	val: 0.846133	test: 0.734061

ROC train: 0.999994	val: 0.879755	test: 0.673032
PRC train: 0.999999	val: 0.752463	test: 0.700718

Epoch: 94
Loss: 0.020265289628493506
ROC train: 1.000000	val: 0.875941	test: 0.670428
PRC train: 1.000000	val: 0.747855	test: 0.707858

Epoch: 95
Loss: 0.027714593174760466
ROC train: 1.000000	val: 0.892603	test: 0.681809
PRC train: 1.000000	val: 0.793021	test: 0.723671

Epoch: 96
Loss: 0.038060250156040906
ROC train: 0.999997	val: 0.891197	test: 0.676794
PRC train: 0.999999	val: 0.815041	test: 0.726608

Epoch: 97
Loss: 0.033660327036157706
ROC train: 1.000000	val: 0.889190	test: 0.676601
PRC train: 1.000000	val: 0.796671	test: 0.721991

Epoch: 98
Loss: 0.023684790452069504
ROC train: 1.000000	val: 0.892302	test: 0.679784
PRC train: 1.000000	val: 0.788934	test: 0.723947

Epoch: 99
Loss: 0.028095413860619613
ROC train: 0.999958	val: 0.875941	test: 0.666281
PRC train: 0.999992	val: 0.747741	test: 0.704656

Epoch: 100
Loss: 0.028050746881668677
ROC train: 1.000000	val: 0.886580	test: 0.687500
PRC train: 1.000000	val: 0.771516	test: 0.731100

Epoch: 101
Loss: 0.028449693068283734
ROC train: 1.000000	val: 0.890194	test: 0.700039
PRC train: 1.000000	val: 0.784294	test: 0.747480

Epoch: 102
Loss: 0.02315480027779592
ROC train: 1.000000	val: 0.885175	test: 0.695409
PRC train: 1.000000	val: 0.787279	test: 0.747251

Epoch: 103
Loss: 0.043500141496214485
ROC train: 1.000000	val: 0.884874	test: 0.689429
PRC train: 1.000000	val: 0.790763	test: 0.739273

Epoch: 104
Loss: 0.02774725562435806
ROC train: 0.999467	val: 0.873632	test: 0.684124
PRC train: 0.999911	val: 0.762512	test: 0.727190

Epoch: 105
Loss: 0.036333452253814
ROC train: 0.999748	val: 0.869216	test: 0.676601
PRC train: 0.999952	val: 0.752862	test: 0.709872

Epoch: 106
Loss: 0.028462850913976098
ROC train: 0.999840	val: 0.873833	test: 0.678627
PRC train: 0.999970	val: 0.750740	test: 0.709337

Epoch: 107
Loss: 0.030283856819063298
ROC train: 1.000000	val: 0.885476	test: 0.682581
PRC train: 1.000000	val: 0.755996	test: 0.721342

Epoch: 108
Loss: 0.028172554139712012
ROC train: 1.000000	val: 0.876041	test: 0.680845
PRC train: 1.000000	val: 0.744879	test: 0.719890

Epoch: 109
Loss: 0.03584259372858944
ROC train: 1.000000	val: 0.883469	test: 0.689429
PRC train: 1.000000	val: 0.764394	test: 0.737866

Epoch: 110
Loss: 0.026289063714028765
ROC train: 1.000000	val: 0.891197	test: 0.701582
PRC train: 1.000000	val: 0.801074	test: 0.747107

Epoch: 111
Loss: 0.017060685607313043
ROC train: 1.000000	val: 0.884171	test: 0.693866
PRC train: 1.000000	val: 0.759483	test: 0.722150

Epoch: 112
Loss: 0.031371361571518215
ROC train: 0.999994	val: 0.885276	test: 0.682195
PRC train: 0.999999	val: 0.756135	test: 0.707328

Epoch: 113
Loss: 0.02881014178981791
ROC train: 1.000000	val: 0.886380	test: 0.671007
PRC train: 1.000000	val: 0.763567	test: 0.701583

Epoch: 114
Loss: 0.023251110696187415
ROC train: 0.999994	val: 0.892603	test: 0.671779
PRC train: 0.999999	val: 0.785438	test: 0.716601

Epoch: 115
Loss: 0.02869650281927661
ROC train: 1.000000	val: 0.896919	test: 0.683738
PRC train: 1.000000	val: 0.829689	test: 0.736673

Epoch: 116
Loss: 0.019291411674489944
ROC train: 1.000000	val: 0.890796	test: 0.681424
PRC train: 1.000000	val: 0.801472	test: 0.729104

Epoch: 117
Loss: 0.03458122969581585
ROC train: 1.000000	val: 0.899026	test: 0.675251
PRC train: 1.000000	val: 0.798338	test: 0.704456

Epoch: 118
Loss: 0.03191830743214479
ROC train: 1.000000	val: 0.900231	test: 0.676794
PRC train: 1.000000	val: 0.805248	test: 0.717507

Epoch: 119
Loss: 0.01042862750538673
ROC train: 1.000000	val: 0.904547	test: 0.681809
PRC train: 1.000000	val: 0.827710	test: 0.721309

Epoch: 120
Loss: 0.031003744946058405
ROC train: 1.000000	val: 0.905049	test: 0.690201
PRC train: 1.000000	val: 0.827103	test: 0.721631

Early stopping
Best (ROC):	 train: 0.999997	val: 0.915889	test: 0.686439
Best (PRC):	 train: 0.999999	val: 0.852505	test: 0.723696
All runs completed.
All runs completed.
All runs completed.
