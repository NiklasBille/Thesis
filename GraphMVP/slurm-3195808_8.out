>>> Starting run for dataset: tox21
FATAL:   Image file already exists: "graphmvp.sif" - will not overwrite
Running RANDOM configs_split_experiments/GraphCL/tox21/random/train_prop=0.6.yml on cuda:0
Running RANDOM configs_split_experiments/GraphCL/tox21/random/train_prop=0.7.yml on cuda:1
Running RANDOM configs_split_experiments/GraphCL/tox21/random/train_prop=0.8.yml on cuda:2
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.6.yml --runseed 1 --device cuda:0
Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.6.yml --runseed 2 --device cuda:0
Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.6.yml --runseed 3 --device cuda:0
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.7.yml --runseed 1 --device cuda:1
Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.7.yml --runseed 2 --device cuda:1
Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.7.yml --runseed 3 --device cuda:1
Starting process for seed 1: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.8.yml --runseed 1 --device cuda:2
Starting process for seed 2: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.8.yml --runseed 2 --device cuda:2
Starting process for seed 3: python molecule_finetune.py --config /workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.8.yml --runseed 3 --device cuda:2
Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:0
  input_data_dir: 
  dataset: tox21
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/tox21/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/tox21/random/train_prop=0.6/tox21_random_3_20-05_14-43-16  ]
[ Using Seed :  3  ]
[ Using device :  cuda:0  ]
Dataset: tox21
Data: Data(edge_attr=[302190, 2], edge_index=[2, 302190], id=[7831], x=[145459, 2], y=[93972])
MoleculeDataset(7831)
randomly split
Data(edge_attr=[26, 2], edge_index=[2, 26], id=[1], x=[13, 2], y=[12])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=12, bias=True)
)
Epoch: 1
Loss: 0.5666937135138538
ROC train: 0.693544	val: 0.664453	test: 0.660401
PRC train: 0.206150	val: 0.212408	test: 0.176832

Epoch: 2
Loss: 0.3794653927556623
ROC train: 0.743147	val: 0.717812	test: 0.694898
PRC train: 0.261922	val: 0.256268	test: 0.219353

Epoch: 3
Loss: 0.2849028424541327
ROC train: 0.759463	val: 0.728826	test: 0.718636
PRC train: 0.290823	val: 0.261185	test: 0.236551

Epoch: 4
Loss: 0.23787009606477666
ROC train: 0.776651	val: 0.765369	test: 0.718022
PRC train: 0.324295	val: 0.309115	test: 0.260702

Epoch: 5
Loss: 0.22187531802781463
ROC train: 0.804992	val: 0.782233	test: 0.751918
PRC train: 0.368524	val: 0.340319	test: 0.300077

Epoch: 6
Loss: 0.21270919721710116
ROC train: 0.818303	val: 0.789047	test: 0.758328
PRC train: 0.380483	val: 0.339848	test: 0.300061

Epoch: 7
Loss: 0.20747634864554154
ROC train: 0.816037	val: 0.788363	test: 0.760196
PRC train: 0.395569	val: 0.339326	test: 0.305486

Epoch: 8
Loss: 0.20214826553300472
ROC train: 0.832357	val: 0.812922	test: 0.774101
PRC train: 0.415618	val: 0.358022	test: 0.317586

Epoch: 9
Loss: 0.2025930745568302
ROC train: 0.840700	val: 0.806702	test: 0.775707
PRC train: 0.416920	val: 0.356465	test: 0.313141

Epoch: 10
Loss: 0.19878615741802447
ROC train: 0.842992	val: 0.820932	test: 0.773931
PRC train: 0.433864	val: 0.369797	test: 0.315648

Epoch: 11
Loss: 0.1963062552875251
ROC train: 0.848271	val: 0.810830	test: 0.784045
PRC train: 0.436907	val: 0.356543	test: 0.330609

Epoch: 12
Loss: 0.19544157735505835
ROC train: 0.857572	val: 0.823012	test: 0.797920
PRC train: 0.473840	val: 0.385757	test: 0.356913

Epoch: 13
Loss: 0.1933228541702968
ROC train: 0.855687	val: 0.820815	test: 0.792308
PRC train: 0.475667	val: 0.369307	test: 0.344216

Epoch: 14
Loss: 0.19381647007155375
ROC train: 0.858583	val: 0.824198	test: 0.789891
PRC train: 0.474979	val: 0.374875	test: 0.343935

Epoch: 15
Loss: 0.18831547391719528
ROC train: 0.868491	val: 0.825187	test: 0.801975
PRC train: 0.502094	val: 0.383733	test: 0.358893

Epoch: 16
Loss: 0.1860414940852493
ROC train: 0.868061	val: 0.821022	test: 0.801199
PRC train: 0.504931	val: 0.382145	test: 0.365713

Epoch: 17
Loss: 0.18927085061458526
ROC train: 0.876262	val: 0.824454	test: 0.801445
PRC train: 0.521815	val: 0.388294	test: 0.367983

Epoch: 18
Loss: 0.1823430251133001
ROC train: 0.879058	val: 0.829788	test: 0.807529
PRC train: 0.530438	val: 0.402405	test: 0.378563

Epoch: 19
Loss: 0.18272435226411649
ROC train: 0.873844	val: 0.830187	test: 0.803396
PRC train: 0.527086	val: 0.397057	test: 0.372386

Epoch: 20
Loss: 0.18548508117931775
ROC train: 0.882727	val: 0.828090	test: 0.804622
PRC train: 0.542327	val: 0.397099	test: 0.369340

Epoch: 21
Loss: 0.17697217511236657
ROC train: 0.881189	val: 0.807891	test: 0.802708
PRC train: 0.536097	val: 0.384935	test: 0.374610

Epoch: 22
Loss: 0.17843074527637265
ROC train: 0.888605	val: 0.832041	test: 0.810428
PRC train: 0.559094	val: 0.410655	test: 0.388577

Epoch: 23
Loss: 0.17553856954109995
ROC train: 0.893184	val: 0.825065	test: 0.808987
PRC train: 0.569891	val: 0.393517	test: 0.390273

Epoch: 24
Loss: 0.17533170631944472
ROC train: 0.894953	val: 0.826708	test: 0.811807
PRC train: 0.582970	val: 0.401035	test: 0.398976

Epoch: 25
Loss: 0.1735050700091425
ROC train: 0.895868	val: 0.822135	test: 0.813582
PRC train: 0.579375	val: 0.403301	test: 0.404792

Epoch: 26
Loss: 0.17274585663948586
ROC train: 0.898885	val: 0.834942	test: 0.812301
PRC train: 0.593179	val: 0.419772	test: 0.399739

Epoch: 27
Loss: 0.17059596333880106
ROC train: 0.900100	val: 0.835403	test: 0.817781
PRC train: 0.594672	val: 0.417109	test: 0.414369

Epoch: 28
Loss: 0.17277087829653243
ROC train: 0.898938	val: 0.829191	test: 0.806589
PRC train: 0.582522	val: 0.424221	test: 0.398895

Epoch: 29
Loss: 0.1664486292809569
ROC train: 0.904046	val: 0.828977	test: 0.811201
PRC train: 0.603743	val: 0.418508	test: 0.410807

Epoch: 30
Loss: 0.16920576628180609
ROC train: 0.905064	val: 0.823169	test: 0.804985
PRC train: 0.596563	val: 0.402736	test: 0.402366

Epoch: 31
Loss: 0.16704464170744165
ROC train: 0.906840	val: 0.836318	test: 0.812633
PRC train: 0.611234	val: 0.422271	test: 0.404340

Epoch: 32
Loss: 0.1658175148658605
ROC train: 0.912441	val: 0.829878	test: 0.814908
PRC train: 0.634823	val: 0.428036	test: 0.409097

Epoch: 33
Loss: 0.1629315307645566Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:0
  input_data_dir: 
  dataset: tox21
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/tox21/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/tox21/random/train_prop=0.6/tox21_random_1_20-05_14-43-16  ]
[ Using Seed :  1  ]
[ Using device :  cuda:0  ]
Dataset: tox21
Data: Data(edge_attr=[302190, 2], edge_index=[2, 302190], id=[7831], x=[145459, 2], y=[93972])
MoleculeDataset(7831)
randomly split
Data(edge_attr=[26, 2], edge_index=[2, 26], id=[1], x=[13, 2], y=[12])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=12, bias=True)
)
Epoch: 1
Loss: 0.5533876607306059
ROC train: 0.683858	val: 0.659872	test: 0.642684
PRC train: 0.197778	val: 0.209235	test: 0.158605

Epoch: 2
Loss: 0.36734423560518226
ROC train: 0.729311	val: 0.696050	test: 0.687916
PRC train: 0.226924	val: 0.227533	test: 0.194945

Epoch: 3
Loss: 0.2754104886590184
ROC train: 0.776204	val: 0.749420	test: 0.725645
PRC train: 0.323916	val: 0.299831	test: 0.252486

Epoch: 4
Loss: 0.23538161666525018
ROC train: 0.792126	val: 0.769192	test: 0.748339
PRC train: 0.353011	val: 0.320785	test: 0.283620

Epoch: 5
Loss: 0.2163676332615001
ROC train: 0.806887	val: 0.782194	test: 0.751531
PRC train: 0.365476	val: 0.332666	test: 0.280258

Epoch: 6
Loss: 0.2098605876639955
ROC train: 0.817726	val: 0.787310	test: 0.770486
PRC train: 0.382908	val: 0.341626	test: 0.298832

Epoch: 7
Loss: 0.20571187810780814
ROC train: 0.830399	val: 0.800050	test: 0.774138
PRC train: 0.399017	val: 0.355603	test: 0.313544

Epoch: 8
Loss: 0.20302354292522642
ROC train: 0.843448	val: 0.803028	test: 0.779325
PRC train: 0.416847	val: 0.356652	test: 0.304457

Epoch: 9
Loss: 0.19931000896286766
ROC train: 0.851268	val: 0.809396	test: 0.785702
PRC train: 0.442801	val: 0.374112	test: 0.331184

Epoch: 10
Loss: 0.1943617590622985
ROC train: 0.855970	val: 0.810297	test: 0.785189
PRC train: 0.448576	val: 0.375715	test: 0.324732

Epoch: 11
Loss: 0.19352981887937873
ROC train: 0.850852	val: 0.809021	test: 0.789033
PRC train: 0.450081	val: 0.360790	test: 0.327922

Epoch: 12
Loss: 0.1925481904202935
ROC train: 0.863746	val: 0.830068	test: 0.804264
PRC train: 0.484172	val: 0.397865	test: 0.354806

Epoch: 13
Loss: 0.19151997437670856
ROC train: 0.870254	val: 0.823168	test: 0.806462
PRC train: 0.496648	val: 0.385006	test: 0.364874

Epoch: 14
Loss: 0.18711619417571668
ROC train: 0.869055	val: 0.816880	test: 0.793965
PRC train: 0.480641	val: 0.372689	test: 0.342791

Epoch: 15
Loss: 0.1865761628266433
ROC train: 0.869463	val: 0.826354	test: 0.799897
PRC train: 0.501798	val: 0.389602	test: 0.369997

Epoch: 16
Loss: 0.1830685052578996
ROC train: 0.880418	val: 0.825962	test: 0.803916
PRC train: 0.527543	val: 0.388180	test: 0.379677

Epoch: 17
Loss: 0.18194771028083628
ROC train: 0.880752	val: 0.820983	test: 0.802887
PRC train: 0.528478	val: 0.388123	test: 0.375092

Epoch: 18
Loss: 0.17981677934770285
ROC train: 0.886472	val: 0.826837	test: 0.799515
PRC train: 0.544476	val: 0.397489	test: 0.366348

Epoch: 19
Loss: 0.17929425617541195
ROC train: 0.887572	val: 0.829270	test: 0.800450
PRC train: 0.546660	val: 0.409621	test: 0.388362

Epoch: 20
Loss: 0.17567558543211953
ROC train: 0.888565	val: 0.825220	test: 0.808274
PRC train: 0.557524	val: 0.403939	test: 0.384001

Epoch: 21
Loss: 0.1775405536617863
ROC train: 0.892949	val: 0.833136	test: 0.811005
PRC train: 0.565156	val: 0.411843	test: 0.396186

Epoch: 22
Loss: 0.17572023236864293
ROC train: 0.892765	val: 0.821658	test: 0.807436
PRC train: 0.557136	val: 0.387898	test: 0.383343

Epoch: 23
Loss: 0.17616221733300566
ROC train: 0.897222	val: 0.827615	test: 0.813194
PRC train: 0.578391	val: 0.399919	test: 0.386248

Epoch: 24
Loss: 0.17510795638366083
ROC train: 0.895947	val: 0.826246	test: 0.810825
PRC train: 0.575735	val: 0.403603	test: 0.388389

Epoch: 25
Loss: 0.1725326690023495
ROC train: 0.898727	val: 0.828144	test: 0.811273
PRC train: 0.585767	val: 0.417469	test: 0.398470

Epoch: 26
Loss: 0.1691731532397125
ROC train: 0.903607	val: 0.835559	test: 0.814693
PRC train: 0.593117	val: 0.416578	test: 0.406951

Epoch: 27
Loss: 0.1696779880288599
ROC train: 0.905023	val: 0.828988	test: 0.813002
PRC train: 0.597466	val: 0.401228	test: 0.404482

Epoch: 28
Loss: 0.16856496988567202
ROC train: 0.906947	val: 0.831405	test: 0.810582
PRC train: 0.609011	val: 0.430579	test: 0.414131

Epoch: 29
Loss: 0.16952668230653237
ROC train: 0.910880	val: 0.823057	test: 0.805031
PRC train: 0.612405	val: 0.403653	test: 0.402358

Epoch: 30
Loss: 0.16648843487669776
ROC train: 0.910789	val: 0.820977	test: 0.813176
PRC train: 0.615371	val: 0.395397	test: 0.399622

Epoch: 31
Loss: 0.16455095954419274
ROC train: 0.911098	val: 0.831616	test: 0.806241
PRC train: 0.616191	val: 0.437190	test: 0.397504

Epoch: 32
Loss: 0.16429356327298722
ROC train: 0.914078	val: 0.817063	test: 0.805112
PRC train: 0.625034	val: 0.405577	test: 0.408977

Epoch: 33
Loss: 0.16407870609111974Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:0
  input_data_dir: 
  dataset: tox21
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.6
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/tox21/random/train_prop=0.6
  verbose: False
[ Logs to :  ../runs/split/GraphCL/tox21/random/train_prop=0.6/tox21_random_2_20-05_14-43-16  ]
[ Using Seed :  2  ]
[ Using device :  cuda:0  ]
Dataset: tox21
Data: Data(edge_attr=[302190, 2], edge_index=[2, 302190], id=[7831], x=[145459, 2], y=[93972])
MoleculeDataset(7831)
randomly split
Data(edge_attr=[26, 2], edge_index=[2, 26], id=[1], x=[13, 2], y=[12])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=12, bias=True)
)
Epoch: 1
Loss: 0.5653199686054591
ROC train: 0.692517	val: 0.668419	test: 0.661405
PRC train: 0.216075	val: 0.222854	test: 0.174945

Epoch: 2
Loss: 0.37591306638350325
ROC train: 0.749215	val: 0.714770	test: 0.696746
PRC train: 0.286257	val: 0.275056	test: 0.217507

Epoch: 3
Loss: 0.2782672524995837
ROC train: 0.765222	val: 0.723183	test: 0.703942
PRC train: 0.300817	val: 0.278420	test: 0.230601

Epoch: 4
Loss: 0.23345119487521543
ROC train: 0.795818	val: 0.764263	test: 0.738397
PRC train: 0.351743	val: 0.302213	test: 0.287739

Epoch: 5
Loss: 0.21899465041178753
ROC train: 0.806984	val: 0.765131	test: 0.734634
PRC train: 0.371755	val: 0.317989	test: 0.280061

Epoch: 6
Loss: 0.20983361486362365
ROC train: 0.804308	val: 0.780938	test: 0.739483
PRC train: 0.367657	val: 0.333055	test: 0.278173

Epoch: 7
Loss: 0.20675286682758928
ROC train: 0.831525	val: 0.787257	test: 0.770667
PRC train: 0.418100	val: 0.347553	test: 0.317684

Epoch: 8
Loss: 0.20172907294028466
ROC train: 0.840386	val: 0.802887	test: 0.774821
PRC train: 0.426871	val: 0.347579	test: 0.324691

Epoch: 9
Loss: 0.19754110237583652
ROC train: 0.846040	val: 0.809361	test: 0.774838
PRC train: 0.435202	val: 0.354656	test: 0.324498

Epoch: 10
Loss: 0.19725416887263234
ROC train: 0.857085	val: 0.803800	test: 0.782627
PRC train: 0.464282	val: 0.367448	test: 0.344888

Epoch: 11
Loss: 0.19177327089048568
ROC train: 0.851929	val: 0.794162	test: 0.774672
PRC train: 0.456639	val: 0.379086	test: 0.344820

Epoch: 12
Loss: 0.1947732980695446
ROC train: 0.854304	val: 0.815016	test: 0.791565
PRC train: 0.458337	val: 0.373998	test: 0.331452

Epoch: 13
Loss: 0.18985167298992592
ROC train: 0.866027	val: 0.805234	test: 0.791456
PRC train: 0.488100	val: 0.367423	test: 0.355043

Epoch: 14
Loss: 0.18843490992899667
ROC train: 0.864723	val: 0.810196	test: 0.797424
PRC train: 0.492160	val: 0.380218	test: 0.347951

Epoch: 15
Loss: 0.1864455413788178
ROC train: 0.872191	val: 0.816769	test: 0.800847
PRC train: 0.511826	val: 0.398083	test: 0.367987

Epoch: 16
Loss: 0.18338737920206513
ROC train: 0.872713	val: 0.824273	test: 0.804464
PRC train: 0.513242	val: 0.400454	test: 0.365104

Epoch: 17
Loss: 0.18122671945834629
ROC train: 0.878292	val: 0.810247	test: 0.807348
PRC train: 0.530434	val: 0.383209	test: 0.378025

Epoch: 18
Loss: 0.18033948363557228
ROC train: 0.881783	val: 0.818510	test: 0.806430
PRC train: 0.546174	val: 0.396020	test: 0.375944

Epoch: 19
Loss: 0.17880529847849705
ROC train: 0.883579	val: 0.822035	test: 0.807803
PRC train: 0.548892	val: 0.415692	test: 0.385768

Epoch: 20
Loss: 0.17787431180912622
ROC train: 0.882407	val: 0.822522	test: 0.809685
PRC train: 0.545111	val: 0.417104	test: 0.387357

Epoch: 21
Loss: 0.1789499550305652
ROC train: 0.889795	val: 0.827209	test: 0.813925
PRC train: 0.563217	val: 0.409289	test: 0.401376

Epoch: 22
Loss: 0.17627386809306073
ROC train: 0.889458	val: 0.818049	test: 0.809509
PRC train: 0.563841	val: 0.413050	test: 0.383553

Epoch: 23
Loss: 0.17529142525317412
ROC train: 0.889656	val: 0.815529	test: 0.812569
PRC train: 0.562920	val: 0.391233	test: 0.372957

Epoch: 24
Loss: 0.17175741442250878
ROC train: 0.897449	val: 0.827841	test: 0.814685
PRC train: 0.584570	val: 0.418564	test: 0.398553

Epoch: 25
Loss: 0.16929109738408482
ROC train: 0.900352	val: 0.822259	test: 0.817654
PRC train: 0.592545	val: 0.407668	test: 0.395857

Epoch: 26
Loss: 0.17287881576057798
ROC train: 0.895056	val: 0.827880	test: 0.810191
PRC train: 0.569103	val: 0.426926	test: 0.388776

Epoch: 27
Loss: 0.1704429113808352
ROC train: 0.902549	val: 0.825134	test: 0.815548
PRC train: 0.596621	val: 0.415429	test: 0.393714

Epoch: 28
Loss: 0.16894327132777281
ROC train: 0.904124	val: 0.827460	test: 0.820915
PRC train: 0.611913	val: 0.421042	test: 0.405906

Epoch: 29
Loss: 0.1672948394674378
ROC train: 0.906811	val: 0.830765	test: 0.810873
PRC train: 0.616642	val: 0.441444	test: 0.416114

Epoch: 30
Loss: 0.16690954673462385
ROC train: 0.908292	val: 0.832475	test: 0.815540
PRC train: 0.616324	val: 0.437993	test: 0.415486

Epoch: 31
Loss: 0.1642975952550483
ROC train: 0.912296	val: 0.831379	test: 0.815231
PRC train: 0.629065	val: 0.435940	test: 0.419836

Epoch: 32
Loss: 0.162688020309542
ROC train: 0.910829	val: 0.834083	test: 0.814862
PRC train: 0.628317	val: 0.432892	test: 0.408983

Epoch: 33
Loss: 0.16419224595131765Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:1
  input_data_dir: 
  dataset: tox21
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/tox21/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/tox21/random/train_prop=0.7/tox21_random_3_20-05_14-43-16  ]
[ Using Seed :  3  ]
[ Using device :  cuda:1  ]
Dataset: tox21
Data: Data(edge_attr=[302190, 2], edge_index=[2, 302190], id=[7831], x=[145459, 2], y=[93972])
MoleculeDataset(7831)
randomly split
Data(edge_attr=[26, 2], edge_index=[2, 26], id=[1], x=[13, 2], y=[12])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=12, bias=True)
)
Epoch: 1
Loss: 0.5490300501879856
ROC train: 0.689535	val: 0.679096	test: 0.647369
PRC train: 0.203741	val: 0.211056	test: 0.169056

Epoch: 2
Loss: 0.34858588111503674
ROC train: 0.747878	val: 0.729337	test: 0.701555
PRC train: 0.281081	val: 0.277694	test: 0.224430

Epoch: 3
Loss: 0.25958296501823275
ROC train: 0.770188	val: 0.745384	test: 0.724278
PRC train: 0.312756	val: 0.314417	test: 0.261105

Epoch: 4
Loss: 0.2243119433921777
ROC train: 0.797166	val: 0.780951	test: 0.748428
PRC train: 0.354534	val: 0.337007	test: 0.289462

Epoch: 5
Loss: 0.2093931326418942
ROC train: 0.799468	val: 0.772310	test: 0.750937
PRC train: 0.359653	val: 0.337518	test: 0.282634

Epoch: 6
Loss: 0.20524507774806483
ROC train: 0.817579	val: 0.793759	test: 0.769079
PRC train: 0.385462	val: 0.353925	test: 0.309058

Epoch: 7
Loss: 0.20026609634487047
ROC train: 0.828390	val: 0.795378	test: 0.780056
PRC train: 0.397718	val: 0.352592	test: 0.315558

Epoch: 8
Loss: 0.1989026237262663
ROC train: 0.841211	val: 0.814087	test: 0.790416
PRC train: 0.429469	val: 0.367602	test: 0.333017

Epoch: 9
Loss: 0.19485813408838418
ROC train: 0.841100	val: 0.819098	test: 0.786563
PRC train: 0.423102	val: 0.375041	test: 0.327773

Epoch: 10
Loss: 0.19394046921565672
ROC train: 0.851439	val: 0.823133	test: 0.795606
PRC train: 0.453151	val: 0.387485	test: 0.342617

Epoch: 11
Loss: 0.1908712661952862
ROC train: 0.857479	val: 0.817156	test: 0.792771
PRC train: 0.470169	val: 0.390378	test: 0.348541

Epoch: 12
Loss: 0.18971913212046213
ROC train: 0.857326	val: 0.820202	test: 0.798029
PRC train: 0.487114	val: 0.386555	test: 0.360511

Epoch: 13
Loss: 0.18744226406096792
ROC train: 0.860759	val: 0.819830	test: 0.799731
PRC train: 0.482942	val: 0.383517	test: 0.342744

Epoch: 14
Loss: 0.1858954784813241
ROC train: 0.868194	val: 0.824242	test: 0.806621
PRC train: 0.495742	val: 0.399262	test: 0.367932

Epoch: 15
Loss: 0.18438652060434696
ROC train: 0.868844	val: 0.831258	test: 0.813994
PRC train: 0.504324	val: 0.398308	test: 0.388628

Epoch: 16
Loss: 0.18300789913264415
ROC train: 0.871988	val: 0.824614	test: 0.808494
PRC train: 0.522322	val: 0.411049	test: 0.372503

Epoch: 17
Loss: 0.17882743169767804
ROC train: 0.877310	val: 0.822258	test: 0.808548
PRC train: 0.527665	val: 0.404172	test: 0.376133

Epoch: 18
Loss: 0.17935971715463747
ROC train: 0.879868	val: 0.823500	test: 0.820436
PRC train: 0.539580	val: 0.407388	test: 0.400439

Epoch: 19
Loss: 0.17782581237218856
ROC train: 0.883270	val: 0.834798	test: 0.818443
PRC train: 0.546906	val: 0.414308	test: 0.410505

Epoch: 20
Loss: 0.17511104151538173
ROC train: 0.883797	val: 0.832289	test: 0.818355
PRC train: 0.548258	val: 0.421817	test: 0.409539

Epoch: 21
Loss: 0.17487320399742434
ROC train: 0.888105	val: 0.831413	test: 0.818779
PRC train: 0.564807	val: 0.423950	test: 0.408364

Epoch: 22
Loss: 0.1723207639013895
ROC train: 0.890701	val: 0.835644	test: 0.823216
PRC train: 0.568409	val: 0.430077	test: 0.411854

Epoch: 23
Loss: 0.17334803744943453
ROC train: 0.891493	val: 0.827774	test: 0.824873
PRC train: 0.573607	val: 0.426549	test: 0.415997

Epoch: 24
Loss: 0.17175011906151513
ROC train: 0.892605	val: 0.834120	test: 0.816627
PRC train: 0.574542	val: 0.436797	test: 0.417916

Epoch: 25
Loss: 0.17094002938112432
ROC train: 0.896748	val: 0.826952	test: 0.824189
PRC train: 0.586869	val: 0.424293	test: 0.427285

Epoch: 26
Loss: 0.16751339726359873
ROC train: 0.897551	val: 0.833366	test: 0.824879
PRC train: 0.591608	val: 0.427843	test: 0.423072

Epoch: 27
Loss: 0.16740358142514694
ROC train: 0.900577	val: 0.826771	test: 0.824332
PRC train: 0.596228	val: 0.436540	test: 0.416669

Epoch: 28
Loss: 0.1688683681806791
ROC train: 0.897811	val: 0.827562	test: 0.818460
PRC train: 0.601879	val: 0.436274	test: 0.421603

Epoch: 29
Loss: 0.16603190725126352
ROC train: 0.902886	val: 0.826614	test: 0.830418
PRC train: 0.606445	val: 0.430392	test: 0.429116

Epoch: 30
Loss: 0.16382620504588616
ROC train: 0.906366	val: 0.830002	test: 0.826644
PRC train: 0.619367	val: 0.438852	test: 0.444305

Epoch: 31
Loss: 0.16225997987901347
ROC train: 0.907667	val: 0.832433	test: 0.832935
PRC train: 0.618628	val: 0.446184	test: 0.441138

Epoch: 32
Loss: 0.16037713229443268
ROC train: 0.909445	val: 0.827626	test: 0.827586
PRC train: 0.619436	val: 0.431710	test: 0.435466

Epoch: 33
Loss: 0.16342265779481652Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:1
  input_data_dir: 
  dataset: tox21
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/tox21/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/tox21/random/train_prop=0.7/tox21_random_2_20-05_14-43-16  ]
[ Using Seed :  2  ]
[ Using device :  cuda:1  ]
Dataset: tox21
Data: Data(edge_attr=[302190, 2], edge_index=[2, 302190], id=[7831], x=[145459, 2], y=[93972])
MoleculeDataset(7831)
randomly split
Data(edge_attr=[26, 2], edge_index=[2, 26], id=[1], x=[13, 2], y=[12])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=12, bias=True)
)
Epoch: 1
Loss: 0.5490771524719438
ROC train: 0.691472	val: 0.671076	test: 0.641055
PRC train: 0.205428	val: 0.220365	test: 0.170204

Epoch: 2
Loss: 0.3470313805273696
ROC train: 0.754827	val: 0.734758	test: 0.708534
PRC train: 0.280417	val: 0.273192	test: 0.226940

Epoch: 3
Loss: 0.25863240647931224
ROC train: 0.778920	val: 0.763209	test: 0.728850
PRC train: 0.325349	val: 0.315905	test: 0.268432

Epoch: 4
Loss: 0.2247542614428606
ROC train: 0.797330	val: 0.784108	test: 0.744394
PRC train: 0.345368	val: 0.326405	test: 0.283047

Epoch: 5
Loss: 0.2115618832249253
ROC train: 0.810489	val: 0.789978	test: 0.760093
PRC train: 0.381339	val: 0.347581	test: 0.299908

Epoch: 6
Loss: 0.20214452643873784
ROC train: 0.825030	val: 0.803622	test: 0.776278
PRC train: 0.408643	val: 0.361223	test: 0.328562

Epoch: 7
Loss: 0.20082852146856833
ROC train: 0.830402	val: 0.793710	test: 0.765719
PRC train: 0.414411	val: 0.359352	test: 0.308125

Epoch: 8
Loss: 0.1971481627475953
ROC train: 0.840050	val: 0.816471	test: 0.785422
PRC train: 0.433708	val: 0.389473	test: 0.329183

Epoch: 9
Loss: 0.19628533416816707
ROC train: 0.842834	val: 0.815776	test: 0.782046
PRC train: 0.452845	val: 0.380063	test: 0.333972

Epoch: 10
Loss: 0.19429499953263898
ROC train: 0.851426	val: 0.816235	test: 0.798374
PRC train: 0.453413	val: 0.391619	test: 0.348463

Epoch: 11
Loss: 0.19052403693172978
ROC train: 0.858064	val: 0.816015	test: 0.799892
PRC train: 0.464400	val: 0.388367	test: 0.342038

Epoch: 12
Loss: 0.18871804813753476
ROC train: 0.860849	val: 0.816345	test: 0.800516
PRC train: 0.482757	val: 0.396897	test: 0.347637

Epoch: 13
Loss: 0.18630563656432136
ROC train: 0.865171	val: 0.816489	test: 0.806309
PRC train: 0.488941	val: 0.398677	test: 0.354233

Epoch: 14
Loss: 0.1835304001728055
ROC train: 0.869788	val: 0.826062	test: 0.802924
PRC train: 0.496424	val: 0.412937	test: 0.347766

Epoch: 15
Loss: 0.1825854928136561
ROC train: 0.874900	val: 0.825014	test: 0.814917
PRC train: 0.520167	val: 0.418960	test: 0.369576

Epoch: 16
Loss: 0.17844008230999756
ROC train: 0.876968	val: 0.827555	test: 0.813463
PRC train: 0.532037	val: 0.426935	test: 0.370367

Epoch: 17
Loss: 0.18083126683071515
ROC train: 0.879768	val: 0.832327	test: 0.817252
PRC train: 0.527347	val: 0.428084	test: 0.369768

Epoch: 18
Loss: 0.1777785607378498
ROC train: 0.882075	val: 0.820011	test: 0.818961
PRC train: 0.545122	val: 0.422132	test: 0.375097

Epoch: 19
Loss: 0.1762796477481698
ROC train: 0.882748	val: 0.829199	test: 0.818179
PRC train: 0.542122	val: 0.430050	test: 0.387062

Epoch: 20
Loss: 0.17503127753049394
ROC train: 0.888581	val: 0.830294	test: 0.826144
PRC train: 0.564312	val: 0.440760	test: 0.409429

Epoch: 21
Loss: 0.17503683649464466
ROC train: 0.892892	val: 0.833516	test: 0.824209
PRC train: 0.576877	val: 0.426901	test: 0.399470

Epoch: 22
Loss: 0.17133238360197697
ROC train: 0.891508	val: 0.831038	test: 0.818967
PRC train: 0.574129	val: 0.435774	test: 0.405004

Epoch: 23
Loss: 0.17216500961453404
ROC train: 0.896962	val: 0.829512	test: 0.822239
PRC train: 0.586840	val: 0.434704	test: 0.409214

Epoch: 24
Loss: 0.16864243474273397
ROC train: 0.898446	val: 0.837024	test: 0.821562
PRC train: 0.591950	val: 0.449925	test: 0.417125

Epoch: 25
Loss: 0.16729565051190645
ROC train: 0.899122	val: 0.829725	test: 0.823647
PRC train: 0.589927	val: 0.439138	test: 0.415696

Epoch: 26
Loss: 0.16868149210088082
ROC train: 0.900793	val: 0.829316	test: 0.826484
PRC train: 0.596245	val: 0.430950	test: 0.421939

Epoch: 27
Loss: 0.16785793143329142
ROC train: 0.904000	val: 0.827255	test: 0.823403
PRC train: 0.606677	val: 0.445991	test: 0.428169

Epoch: 28
Loss: 0.16575656896033109
ROC train: 0.899122	val: 0.828234	test: 0.820083
PRC train: 0.591627	val: 0.432872	test: 0.415869

Epoch: 29
Loss: 0.164354011934829
ROC train: 0.907636	val: 0.824387	test: 0.820492
PRC train: 0.616478	val: 0.436764	test: 0.404675

Epoch: 30
Loss: 0.16253239927600263
ROC train: 0.912721	val: 0.826822	test: 0.827303
PRC train: 0.635976	val: 0.449380	test: 0.426450

Epoch: 31
Loss: 0.16048000235236615
ROC train: 0.913758	val: 0.828900	test: 0.822787
PRC train: 0.631178	val: 0.454599	test: 0.427684

Epoch: 32
Loss: 0.1605591202261442
ROC train: 0.906502	val: 0.830768	test: 0.816186
PRC train: 0.610011	val: 0.450218	test: 0.413110

Epoch: 33
Loss: 0.16396999847695398Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:1
  input_data_dir: 
  dataset: tox21
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.7
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/tox21/random/train_prop=0.7
  verbose: False
[ Logs to :  ../runs/split/GraphCL/tox21/random/train_prop=0.7/tox21_random_1_20-05_14-43-16  ]
[ Using Seed :  1  ]
[ Using device :  cuda:1  ]
Dataset: tox21
Data: Data(edge_attr=[302190, 2], edge_index=[2, 302190], id=[7831], x=[145459, 2], y=[93972])
MoleculeDataset(7831)
randomly split
Data(edge_attr=[26, 2], edge_index=[2, 26], id=[1], x=[13, 2], y=[12])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=12, bias=True)
)
Epoch: 1
Loss: 0.5395015081075297
ROC train: 0.671952	val: 0.652912	test: 0.622736
PRC train: 0.172941	val: 0.182589	test: 0.149506

Epoch: 2
Loss: 0.3410639227320447
ROC train: 0.734651	val: 0.720715	test: 0.679895
PRC train: 0.232466	val: 0.231131	test: 0.195898

Epoch: 3
Loss: 0.2556250482692631
ROC train: 0.783957	val: 0.767448	test: 0.731882
PRC train: 0.321477	val: 0.300945	test: 0.259726

Epoch: 4
Loss: 0.22265114760433677
ROC train: 0.798487	val: 0.789038	test: 0.746865
PRC train: 0.333346	val: 0.325385	test: 0.272660

Epoch: 5
Loss: 0.21166574690554302
ROC train: 0.812241	val: 0.788935	test: 0.756950
PRC train: 0.362092	val: 0.344250	test: 0.282843

Epoch: 6
Loss: 0.2068096477563757
ROC train: 0.821423	val: 0.794547	test: 0.767251
PRC train: 0.382805	val: 0.349445	test: 0.311552

Epoch: 7
Loss: 0.20295400304427896
ROC train: 0.827283	val: 0.802230	test: 0.778238
PRC train: 0.391876	val: 0.360923	test: 0.319684

Epoch: 8
Loss: 0.19870393833116703
ROC train: 0.838670	val: 0.816181	test: 0.769429
PRC train: 0.409358	val: 0.370015	test: 0.313244

Epoch: 9
Loss: 0.1944437341520959
ROC train: 0.849386	val: 0.822477	test: 0.785770
PRC train: 0.442002	val: 0.385105	test: 0.333241

Epoch: 10
Loss: 0.19281819249537605
ROC train: 0.849968	val: 0.816693	test: 0.794733
PRC train: 0.441113	val: 0.376271	test: 0.333170

Epoch: 11
Loss: 0.1911171209363838
ROC train: 0.855720	val: 0.824054	test: 0.791050
PRC train: 0.441582	val: 0.380526	test: 0.319640

Epoch: 12
Loss: 0.18983317668854163
ROC train: 0.860278	val: 0.824034	test: 0.801203
PRC train: 0.460410	val: 0.384782	test: 0.335451

Epoch: 13
Loss: 0.18702411148295772
ROC train: 0.863782	val: 0.822804	test: 0.805961
PRC train: 0.476611	val: 0.391902	test: 0.339195

Epoch: 14
Loss: 0.18629612615958765
ROC train: 0.868244	val: 0.820406	test: 0.807750
PRC train: 0.482677	val: 0.395927	test: 0.370778

Epoch: 15
Loss: 0.18673081579335546
ROC train: 0.870245	val: 0.821718	test: 0.809064
PRC train: 0.493689	val: 0.395860	test: 0.353780

Epoch: 16
Loss: 0.1837563359432621
ROC train: 0.873495	val: 0.823728	test: 0.814675
PRC train: 0.506824	val: 0.397875	test: 0.360513

Epoch: 17
Loss: 0.18192072347631763
ROC train: 0.878133	val: 0.827045	test: 0.805944
PRC train: 0.515111	val: 0.403396	test: 0.355769

Epoch: 18
Loss: 0.17835064269103443
ROC train: 0.881645	val: 0.830804	test: 0.814353
PRC train: 0.529354	val: 0.412312	test: 0.372167

Epoch: 19
Loss: 0.1776632070794557
ROC train: 0.881449	val: 0.820213	test: 0.808038
PRC train: 0.520362	val: 0.405207	test: 0.374358

Epoch: 20
Loss: 0.1747901459863869
ROC train: 0.886340	val: 0.830014	test: 0.811395
PRC train: 0.547090	val: 0.417261	test: 0.382920

Epoch: 21
Loss: 0.17529789949709762
ROC train: 0.887420	val: 0.828454	test: 0.821427
PRC train: 0.548969	val: 0.418013	test: 0.391685

Epoch: 22
Loss: 0.175828984881695
ROC train: 0.893293	val: 0.829889	test: 0.823070
PRC train: 0.561775	val: 0.416157	test: 0.392276

Epoch: 23
Loss: 0.17350459485516853
ROC train: 0.895084	val: 0.827722	test: 0.825900
PRC train: 0.561476	val: 0.415383	test: 0.399751

Epoch: 24
Loss: 0.17293850274826641
ROC train: 0.893332	val: 0.825803	test: 0.823735
PRC train: 0.572349	val: 0.412454	test: 0.403686

Epoch: 25
Loss: 0.16925964881170005
ROC train: 0.898919	val: 0.833433	test: 0.822054
PRC train: 0.588082	val: 0.425509	test: 0.405812

Epoch: 26
Loss: 0.16992102088986993
ROC train: 0.900536	val: 0.828523	test: 0.820379
PRC train: 0.577218	val: 0.411466	test: 0.400085

Epoch: 27
Loss: 0.16700789472942112
ROC train: 0.900451	val: 0.831574	test: 0.822948
PRC train: 0.572556	val: 0.416904	test: 0.396379

Epoch: 28
Loss: 0.17013589429014092
ROC train: 0.899388	val: 0.830227	test: 0.821653
PRC train: 0.579203	val: 0.429863	test: 0.416119

Epoch: 29
Loss: 0.16662454469961074
ROC train: 0.907403	val: 0.831738	test: 0.821995
PRC train: 0.602722	val: 0.434100	test: 0.418915

Epoch: 30
Loss: 0.1656366370058009
ROC train: 0.908260	val: 0.834443	test: 0.816604
PRC train: 0.608318	val: 0.436902	test: 0.410723

Epoch: 31
Loss: 0.16428202962419095
ROC train: 0.910705	val: 0.833117	test: 0.819191
PRC train: 0.610159	val: 0.422474	test: 0.422792

Epoch: 32
Loss: 0.16359929929382902
ROC train: 0.909229	val: 0.834490	test: 0.818287
PRC train: 0.609964	val: 0.429896	test: 0.420272

Epoch: 33
Loss: 0.1623719118106481Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 3
  multiple_seeds: [1, 2, 3]
  device: cuda:2
  input_data_dir: 
  dataset: tox21
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/tox21/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/tox21/random/train_prop=0.8/tox21_random_3_20-05_14-43-16  ]
[ Using Seed :  3  ]
[ Using device :  cuda:2  ]
Dataset: tox21
Data: Data(edge_attr=[302190, 2], edge_index=[2, 302190], id=[7831], x=[145459, 2], y=[93972])
MoleculeDataset(7831)
randomly split
Data(edge_attr=[26, 2], edge_index=[2, 26], id=[1], x=[13, 2], y=[12])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=12, bias=True)
)
Epoch: 1
Loss: 0.534221557005688
ROC train: 0.700465	val: 0.679664	test: 0.640081
PRC train: 0.229020	val: 0.213435	test: 0.165748

Epoch: 2
Loss: 0.3251086251474342
ROC train: 0.762071	val: 0.728370	test: 0.714650
PRC train: 0.290713	val: 0.261772	test: 0.214903

Epoch: 3
Loss: 0.24499485359044829
ROC train: 0.785608	val: 0.740851	test: 0.728037
PRC train: 0.330299	val: 0.306277	test: 0.258225

Epoch: 4
Loss: 0.21901805706316257
ROC train: 0.802988	val: 0.761473	test: 0.741739
PRC train: 0.354466	val: 0.330349	test: 0.271589

Epoch: 5
Loss: 0.21009523776754213
ROC train: 0.821910	val: 0.780444	test: 0.762793
PRC train: 0.389423	val: 0.350435	test: 0.290644

Epoch: 6
Loss: 0.2045888805821754
ROC train: 0.831505	val: 0.768370	test: 0.775030
PRC train: 0.407573	val: 0.343403	test: 0.310750

Epoch: 7
Loss: 0.19935012265599475
ROC train: 0.830759	val: 0.772630	test: 0.770065
PRC train: 0.407337	val: 0.354049	test: 0.302370

Epoch: 8
Loss: 0.19834129333229797
ROC train: 0.839792	val: 0.785994	test: 0.786125
PRC train: 0.425986	val: 0.368796	test: 0.320141

Epoch: 9
Loss: 0.19641516532586945
ROC train: 0.840096	val: 0.784779	test: 0.768871
PRC train: 0.426938	val: 0.361684	test: 0.311623

Epoch: 10
Loss: 0.19414289865105414
ROC train: 0.851848	val: 0.793193	test: 0.792089
PRC train: 0.450887	val: 0.364730	test: 0.348198

Epoch: 11
Loss: 0.18999955901844168
ROC train: 0.859905	val: 0.804792	test: 0.790212
PRC train: 0.465585	val: 0.380232	test: 0.345251

Epoch: 12
Loss: 0.18918380988587544
ROC train: 0.860339	val: 0.796326	test: 0.804254
PRC train: 0.475115	val: 0.389381	test: 0.358463

Epoch: 13
Loss: 0.18510766026083417
ROC train: 0.862061	val: 0.802586	test: 0.799027
PRC train: 0.487028	val: 0.403036	test: 0.349115

Epoch: 14
Loss: 0.18429503794933746
ROC train: 0.868355	val: 0.806552	test: 0.806393
PRC train: 0.490566	val: 0.385940	test: 0.371312

Epoch: 15
Loss: 0.18498673175332153
ROC train: 0.872995	val: 0.807950	test: 0.801996
PRC train: 0.514991	val: 0.398276	test: 0.373470

Epoch: 16
Loss: 0.1828006928871157
ROC train: 0.876783	val: 0.817652	test: 0.812445
PRC train: 0.520647	val: 0.415761	test: 0.388981

Epoch: 17
Loss: 0.18226936276218364
ROC train: 0.879933	val: 0.811550	test: 0.811264
PRC train: 0.525590	val: 0.413255	test: 0.384197

Epoch: 18
Loss: 0.18044933411273228
ROC train: 0.883753	val: 0.817908	test: 0.820256
PRC train: 0.545325	val: 0.425081	test: 0.397937

Epoch: 19
Loss: 0.17759757372087726
ROC train: 0.886324	val: 0.816852	test: 0.815550
PRC train: 0.555840	val: 0.440356	test: 0.388124

Epoch: 20
Loss: 0.17752963037201958
ROC train: 0.888028	val: 0.820583	test: 0.813753
PRC train: 0.550957	val: 0.429438	test: 0.386307

Epoch: 21
Loss: 0.1756694027383701
ROC train: 0.885593	val: 0.813063	test: 0.803145
PRC train: 0.548986	val: 0.428105	test: 0.384942

Epoch: 22
Loss: 0.17544219629310281
ROC train: 0.890619	val: 0.814313	test: 0.815964
PRC train: 0.566733	val: 0.437570	test: 0.390334

Epoch: 23
Loss: 0.1736084765208488
ROC train: 0.895806	val: 0.829827	test: 0.827060
PRC train: 0.573120	val: 0.439705	test: 0.390330

Epoch: 24
Loss: 0.17161019325568894
ROC train: 0.894382	val: 0.817063	test: 0.812176
PRC train: 0.578764	val: 0.445076	test: 0.387321

Epoch: 25
Loss: 0.1716964652671651
ROC train: 0.897959	val: 0.824911	test: 0.827408
PRC train: 0.586739	val: 0.461623	test: 0.384095

Epoch: 26
Loss: 0.17001452279157614
ROC train: 0.901507	val: 0.822542	test: 0.828645
PRC train: 0.594482	val: 0.445320	test: 0.407770

Epoch: 27
Loss: 0.16910375663440153
ROC train: 0.902528	val: 0.824762	test: 0.836633
PRC train: 0.599690	val: 0.445886	test: 0.403586

Epoch: 28
Loss: 0.16950649031618603
ROC train: 0.901118	val: 0.818822	test: 0.827785
PRC train: 0.592224	val: 0.441742	test: 0.400495

Epoch: 29
Loss: 0.1665878816186744
ROC train: 0.908699	val: 0.821924	test: 0.829420
PRC train: 0.617348	val: 0.472989	test: 0.401564

Epoch: 30
Loss: 0.16526591363752904
ROC train: 0.907851	val: 0.829010	test: 0.825536
PRC train: 0.613054	val: 0.464940	test: 0.395212

Epoch: 31
Loss: 0.16306055290288982
ROC train: 0.915039	val: 0.822513	test: 0.836326
PRC train: 0.632017	val: 0.452269	test: 0.402885

Epoch: 32
Loss: 0.1642599982029678
ROC train: 0.912304	val: 0.823244	test: 0.829858
PRC train: 0.629588	val: 0.473238	test: 0.433029

Epoch: 33
Loss: 0.1613073544450942Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 1
  multiple_seeds: [1, 2, 3]
  device: cuda:2
  input_data_dir: 
  dataset: tox21
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/tox21/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/tox21/random/train_prop=0.8/tox21_random_1_20-05_14-43-16  ]
[ Using Seed :  1  ]
[ Using device :  cuda:2  ]
Dataset: tox21
Data: Data(edge_attr=[302190, 2], edge_index=[2, 302190], id=[7831], x=[145459, 2], y=[93972])
MoleculeDataset(7831)
randomly split
Data(edge_attr=[26, 2], edge_index=[2, 26], id=[1], x=[13, 2], y=[12])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=12, bias=True)
)
Epoch: 1
Loss: 0.5215071007855702
ROC train: 0.681764	val: 0.673861	test: 0.625501
PRC train: 0.203325	val: 0.198897	test: 0.155231

Epoch: 2
Loss: 0.31681470059036554
ROC train: 0.756886	val: 0.724006	test: 0.710167
PRC train: 0.288623	val: 0.261610	test: 0.221351

Epoch: 3
Loss: 0.23986119676145173
ROC train: 0.789666	val: 0.750251	test: 0.753171
PRC train: 0.344308	val: 0.314905	test: 0.271682

Epoch: 4
Loss: 0.21636165568246205
ROC train: 0.804256	val: 0.754480	test: 0.761228
PRC train: 0.361002	val: 0.322677	test: 0.282664

Epoch: 5
Loss: 0.20816520355930324
ROC train: 0.820817	val: 0.781377	test: 0.770903
PRC train: 0.388133	val: 0.337556	test: 0.308078

Epoch: 6
Loss: 0.20294777194760197
ROC train: 0.832490	val: 0.772309	test: 0.777443
PRC train: 0.404189	val: 0.351109	test: 0.317646

Epoch: 7
Loss: 0.20117486290346023
ROC train: 0.832292	val: 0.779248	test: 0.786241
PRC train: 0.402816	val: 0.354655	test: 0.312152

Epoch: 8
Loss: 0.19846544777433572
ROC train: 0.843763	val: 0.789691	test: 0.794648
PRC train: 0.419073	val: 0.357979	test: 0.321910

Epoch: 9
Loss: 0.1947554357108121
ROC train: 0.846508	val: 0.787850	test: 0.789707
PRC train: 0.436815	val: 0.372665	test: 0.330555

Epoch: 10
Loss: 0.19382504043924104
ROC train: 0.852098	val: 0.795224	test: 0.795068
PRC train: 0.441393	val: 0.375559	test: 0.338932

Epoch: 11
Loss: 0.19108348166609365
ROC train: 0.856379	val: 0.795384	test: 0.804588
PRC train: 0.455120	val: 0.375271	test: 0.351796

Epoch: 12
Loss: 0.18827715798181846
ROC train: 0.859909	val: 0.798043	test: 0.796596
PRC train: 0.464521	val: 0.379819	test: 0.335282

Epoch: 13
Loss: 0.18499803880661003
ROC train: 0.867850	val: 0.810897	test: 0.812251
PRC train: 0.494342	val: 0.402667	test: 0.355889

Epoch: 14
Loss: 0.1858640912459731
ROC train: 0.865225	val: 0.808277	test: 0.800515
PRC train: 0.486639	val: 0.382085	test: 0.350545

Epoch: 15
Loss: 0.18538248495806042
ROC train: 0.867178	val: 0.798923	test: 0.805747
PRC train: 0.496562	val: 0.407980	test: 0.361630

Epoch: 16
Loss: 0.1844809519756696
ROC train: 0.876429	val: 0.807612	test: 0.808041
PRC train: 0.516814	val: 0.412188	test: 0.363247

Epoch: 17
Loss: 0.17895415040873178
ROC train: 0.880017	val: 0.813782	test: 0.813693
PRC train: 0.521541	val: 0.409650	test: 0.384026

Epoch: 18
Loss: 0.17897717587486192
ROC train: 0.882170	val: 0.818520	test: 0.819886
PRC train: 0.543616	val: 0.422602	test: 0.385110

Epoch: 19
Loss: 0.17648192926853257
ROC train: 0.883570	val: 0.814797	test: 0.822492
PRC train: 0.544371	val: 0.431965	test: 0.387104

Epoch: 20
Loss: 0.17613269368365614
ROC train: 0.884919	val: 0.810351	test: 0.815836
PRC train: 0.538247	val: 0.430304	test: 0.368729

Epoch: 21
Loss: 0.17570372703067125
ROC train: 0.890276	val: 0.819631	test: 0.823957
PRC train: 0.564118	val: 0.437539	test: 0.400137

Epoch: 22
Loss: 0.17576793645379044
ROC train: 0.892908	val: 0.823135	test: 0.827593
PRC train: 0.569059	val: 0.429086	test: 0.413751

Epoch: 23
Loss: 0.1750504488084634
ROC train: 0.894605	val: 0.828244	test: 0.827121
PRC train: 0.578023	val: 0.450618	test: 0.396502

Epoch: 24
Loss: 0.1729656008115163
ROC train: 0.898245	val: 0.829171	test: 0.833058
PRC train: 0.585473	val: 0.459752	test: 0.403882

Epoch: 25
Loss: 0.16997579286637612
ROC train: 0.898800	val: 0.828132	test: 0.825438
PRC train: 0.590276	val: 0.473501	test: 0.406856

Epoch: 26
Loss: 0.16825456457140414
ROC train: 0.897518	val: 0.820163	test: 0.827118
PRC train: 0.589021	val: 0.447703	test: 0.422801

Epoch: 27
Loss: 0.16817543015371686
ROC train: 0.902452	val: 0.828020	test: 0.829616
PRC train: 0.596155	val: 0.461477	test: 0.404215

Epoch: 28
Loss: 0.16520045996468496
ROC train: 0.906645	val: 0.830378	test: 0.826574
PRC train: 0.607457	val: 0.474433	test: 0.416112

Epoch: 29
Loss: 0.1672084761835465
ROC train: 0.908597	val: 0.833047	test: 0.830530
PRC train: 0.612588	val: 0.473745	test: 0.400255

Epoch: 30
Loss: 0.16627642631389328
ROC train: 0.908582	val: 0.828937	test: 0.833030
PRC train: 0.621071	val: 0.472458	test: 0.415309

Epoch: 31
Loss: 0.1643515337691841
ROC train: 0.911780	val: 0.829381	test: 0.830189
PRC train: 0.623676	val: 0.479041	test: 0.407863

Epoch: 32
Loss: 0.1619430327491155
ROC train: 0.911679	val: 0.824477	test: 0.828181
PRC train: 0.624958	val: 0.484096	test: 0.414301

Epoch: 33
Loss: 0.16551230092718255Arguments:
  config: <_io.TextIOWrapper name='/workspace/configs_split_experiments/GraphCL/tox21/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
  seed: 42
  runseed: 2
  multiple_seeds: [1, 2, 3]
  device: cuda:2
  input_data_dir: 
  dataset: tox21
  num_workers: 0
  noise_level: 0.0
  dynamic_noise: True
  train_prop: 0.8
  split: random
  batch_size: 256
  epochs: 1000
  lr: 0.001
  lr_scale: 1
  decay: 0
  patience: 35
  minimum_epochs: 120
  gnn_type: gin
  num_layer: 5
  emb_dim: 300
  dropout_ratio: 0.5
  graph_pooling: mean
  JK: last
  gnn_lr_scale: 1
  model_3d: schnet
  mask_rate: 0.15
  mask_edge: 0
  csize: 3
  contextpred_neg_samples: 1
  num_filters: 128
  num_interactions: 6
  num_gaussians: 51
  cutoff: 10
  readout: mean
  schnet_lr_scale: 1
  CL_neg_samples: 1
  CL_similarity_metric: InfoNCE_dot_prod
  T: 0.1
  normalize: False
  SSL_masking_ratio: 0
  AE_model: AE
  AE_loss: l2
  detach_target: True
  beta: 1
  alpha_1: 1
  alpha_2: 1
  SSL_2D_mode: AM
  alpha_3: 0.1
  gamma_joao: 0.1
  gamma_joaov2: 0.1
  eval_train: True
  input_model_file: ../weights/pretrained/GraphCL_classification.pth
  output_model_dir: ../runs/split/GraphCL/tox21/random/train_prop=0.8
  verbose: False
[ Logs to :  ../runs/split/GraphCL/tox21/random/train_prop=0.8/tox21_random_2_20-05_14-43-16  ]
[ Using Seed :  2  ]
[ Using device :  cuda:2  ]
Dataset: tox21
Data: Data(edge_attr=[302190, 2], edge_index=[2, 302190], id=[7831], x=[145459, 2], y=[93972])
MoleculeDataset(7831)
randomly split
Data(edge_attr=[26, 2], edge_index=[2, 26], id=[1], x=[13, 2], y=[12])
GNN_graphpred(
  (molecule_model): GNN(
    (x_embedding1): Embedding(120, 300)
    (x_embedding2): Embedding(3, 300)
    (gnns): ModuleList(
      (0): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (1): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (2): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (3): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
      (4): GINConv(
        (mlp): Sequential(
          (0): Linear(in_features=300, out_features=600, bias=True)
          (1): ReLU()
          (2): Linear(in_features=600, out_features=300, bias=True)
        )
        (edge_embedding1): Embedding(6, 300)
        (edge_embedding2): Embedding(3, 300)
      )
    )
    (batch_norms): ModuleList(
      (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (graph_pred_linear): Linear(in_features=300, out_features=12, bias=True)
)
Epoch: 1
Loss: 0.5336147767891377
ROC train: 0.703459	val: 0.688252	test: 0.638506
PRC train: 0.237655	val: 0.213760	test: 0.177404

Epoch: 2
Loss: 0.3256810296033839
ROC train: 0.760819	val: 0.730124	test: 0.698250
PRC train: 0.279818	val: 0.271709	test: 0.193923

Epoch: 3
Loss: 0.2449195964174354
ROC train: 0.787196	val: 0.747464	test: 0.740428
PRC train: 0.331798	val: 0.315881	test: 0.267662

Epoch: 4
Loss: 0.21684778386062453
ROC train: 0.810183	val: 0.770443	test: 0.760739
PRC train: 0.357563	val: 0.333424	test: 0.278373

Epoch: 5
Loss: 0.21078823083159104
ROC train: 0.820300	val: 0.780286	test: 0.772480
PRC train: 0.393517	val: 0.355677	test: 0.295097

Epoch: 6
Loss: 0.20328083105447178
ROC train: 0.832215	val: 0.788109	test: 0.780793
PRC train: 0.402185	val: 0.356384	test: 0.303569

Epoch: 7
Loss: 0.20038241726204475
ROC train: 0.834144	val: 0.786451	test: 0.780248
PRC train: 0.413514	val: 0.374317	test: 0.310342

Epoch: 8
Loss: 0.19760303401156146
ROC train: 0.846983	val: 0.797962	test: 0.800997
PRC train: 0.428538	val: 0.361334	test: 0.329647

Epoch: 9
Loss: 0.19473043182629757
ROC train: 0.847241	val: 0.801609	test: 0.799994
PRC train: 0.443864	val: 0.362492	test: 0.305931

Epoch: 10
Loss: 0.19421089406342548
ROC train: 0.852858	val: 0.796120	test: 0.797936
PRC train: 0.464832	val: 0.387983	test: 0.336137

Epoch: 11
Loss: 0.18949224058659053
ROC train: 0.863097	val: 0.806810	test: 0.804673
PRC train: 0.488644	val: 0.399309	test: 0.344770

Epoch: 12
Loss: 0.1880134880204135
ROC train: 0.859088	val: 0.804580	test: 0.807529
PRC train: 0.479313	val: 0.396046	test: 0.347633

Epoch: 13
Loss: 0.1875533322239491
ROC train: 0.867265	val: 0.814853	test: 0.807935
PRC train: 0.496417	val: 0.404276	test: 0.369343

Epoch: 14
Loss: 0.18681198150026052
ROC train: 0.865823	val: 0.808921	test: 0.811924
PRC train: 0.504603	val: 0.417435	test: 0.368099

Epoch: 15
Loss: 0.18493691721559247
ROC train: 0.870506	val: 0.804139	test: 0.812322
PRC train: 0.512175	val: 0.418159	test: 0.373416

Epoch: 16
Loss: 0.18340325857623427
ROC train: 0.872264	val: 0.815392	test: 0.813195
PRC train: 0.513829	val: 0.429952	test: 0.378071

Epoch: 17
Loss: 0.18034183029710898
ROC train: 0.879776	val: 0.815225	test: 0.823516
PRC train: 0.540304	val: 0.435056	test: 0.390000

Epoch: 18
Loss: 0.17988938797820317
ROC train: 0.880833	val: 0.820194	test: 0.812628
PRC train: 0.536807	val: 0.439012	test: 0.377317

Epoch: 19
Loss: 0.17834967687175418
ROC train: 0.884565	val: 0.818546	test: 0.818359
PRC train: 0.555695	val: 0.437345	test: 0.396870

Epoch: 20
Loss: 0.17581466651595293
ROC train: 0.889186	val: 0.820380	test: 0.815414
PRC train: 0.562802	val: 0.444971	test: 0.395002

Epoch: 21
Loss: 0.17496405428992784
ROC train: 0.889762	val: 0.816542	test: 0.814565
PRC train: 0.571365	val: 0.451825	test: 0.393109

Epoch: 22
Loss: 0.17319273963690077
ROC train: 0.892569	val: 0.820408	test: 0.822887
PRC train: 0.575625	val: 0.452290	test: 0.395527

Epoch: 23
Loss: 0.17394995121207013
ROC train: 0.894021	val: 0.815567	test: 0.821565
PRC train: 0.583737	val: 0.445098	test: 0.382979

Epoch: 24
Loss: 0.17287798130589527
ROC train: 0.897084	val: 0.822682	test: 0.826901
PRC train: 0.586333	val: 0.467761	test: 0.396640

Epoch: 25
Loss: 0.1713745108040191
ROC train: 0.900664	val: 0.822405	test: 0.827589
PRC train: 0.592179	val: 0.455412	test: 0.404859

Epoch: 26
Loss: 0.16850721511036
ROC train: 0.897541	val: 0.823640	test: 0.824576
PRC train: 0.585196	val: 0.465626	test: 0.387225

Epoch: 27
Loss: 0.16848554345789712
ROC train: 0.903251	val: 0.822040	test: 0.830574
PRC train: 0.602980	val: 0.471284	test: 0.408015

Epoch: 28
Loss: 0.1665390628853517
ROC train: 0.903145	val: 0.822255	test: 0.824264
PRC train: 0.596873	val: 0.450876	test: 0.383264

Epoch: 29
Loss: 0.16643343341543626
ROC train: 0.907379	val: 0.819470	test: 0.830055
PRC train: 0.611873	val: 0.464329	test: 0.411012

Epoch: 30
Loss: 0.16350455117712506
ROC train: 0.912161	val: 0.823672	test: 0.837264
PRC train: 0.628081	val: 0.476665	test: 0.412646

Epoch: 31
Loss: 0.16294094011127214
ROC train: 0.912573	val: 0.825203	test: 0.829665
PRC train: 0.626625	val: 0.483615	test: 0.406285

Epoch: 32
Loss: 0.16199803302106042
ROC train: 0.917671	val: 0.831474	test: 0.835861
PRC train: 0.642813	val: 0.482644	test: 0.417267

Epoch: 33
Loss: 0.16255113380018088
ROC train: 0.914979	val: 0.832965	test: 0.820010
PRC train: 0.632032	val: 0.410070	test: 0.417280

Epoch: 34
Loss: 0.16166579736962383
ROC train: 0.914570	val: 0.829702	test: 0.815788
PRC train: 0.636687	val: 0.429056	test: 0.417531

Epoch: 35
Loss: 0.16464249171600462
ROC train: 0.918287	val: 0.837479	test: 0.812732
PRC train: 0.652213	val: 0.442465	test: 0.415183

Epoch: 36
Loss: 0.16115862850089413
ROC train: 0.917512	val: 0.832573	test: 0.814129
PRC train: 0.630539	val: 0.415411	test: 0.410819

Epoch: 37
Loss: 0.16276750730411224
ROC train: 0.918827	val: 0.827286	test: 0.811909
PRC train: 0.649677	val: 0.419446	test: 0.407614

Epoch: 38
Loss: 0.1589479790127349
ROC train: 0.923510	val: 0.836750	test: 0.816700
PRC train: 0.656058	val: 0.416021	test: 0.406731

Epoch: 39
Loss: 0.1587681156428405
ROC train: 0.921003	val: 0.832221	test: 0.810966
PRC train: 0.654938	val: 0.414961	test: 0.414661

Epoch: 40
Loss: 0.156497139037499
ROC train: 0.924635	val: 0.828866	test: 0.813766
PRC train: 0.663036	val: 0.407785	test: 0.407448

Epoch: 41
Loss: 0.15753864622891006
ROC train: 0.927657	val: 0.833503	test: 0.814064
PRC train: 0.676591	val: 0.428890	test: 0.406751

Epoch: 42
Loss: 0.15320598658727191
ROC train: 0.928017	val: 0.830624	test: 0.811390
PRC train: 0.683833	val: 0.416628	test: 0.425243

Epoch: 43
Loss: 0.15584484829308365
ROC train: 0.929044	val: 0.830929	test: 0.816911
PRC train: 0.685084	val: 0.417243	test: 0.422883

Epoch: 44
Loss: 0.15411111700174498
ROC train: 0.928987	val: 0.821590	test: 0.808856
PRC train: 0.680006	val: 0.391328	test: 0.409462

Epoch: 45
Loss: 0.15165196534248152
ROC train: 0.930594	val: 0.832366	test: 0.812765
PRC train: 0.680886	val: 0.437101	test: 0.412504

Epoch: 46
Loss: 0.15216689086730317
ROC train: 0.935342	val: 0.834024	test: 0.818737
PRC train: 0.700323	val: 0.421217	test: 0.425678

Epoch: 47
Loss: 0.1519550037296262
ROC train: 0.935176	val: 0.831803	test: 0.818190
PRC train: 0.701921	val: 0.405906	test: 0.419258

Epoch: 48
Loss: 0.1505047463091155
ROC train: 0.937051	val: 0.832626	test: 0.810414
PRC train: 0.703407	val: 0.419328	test: 0.428611

Epoch: 49
Loss: 0.1500454807275107
ROC train: 0.940039	val: 0.829146	test: 0.810495
PRC train: 0.712518	val: 0.419160	test: 0.423643

Epoch: 50
Loss: 0.1507882771360236
ROC train: 0.937215	val: 0.831609	test: 0.814864
PRC train: 0.708201	val: 0.412141	test: 0.423423

Epoch: 51
Loss: 0.14805574129201152
ROC train: 0.941417	val: 0.831889	test: 0.811890
PRC train: 0.721377	val: 0.432293	test: 0.431721

Epoch: 52
Loss: 0.14860548893728748
ROC train: 0.941687	val: 0.831229	test: 0.816605
PRC train: 0.721607	val: 0.413491	test: 0.434019

Epoch: 53
Loss: 0.1478372040175524
ROC train: 0.942407	val: 0.832467	test: 0.809594
PRC train: 0.720461	val: 0.414464	test: 0.425948

Epoch: 54
Loss: 0.14389816430583394
ROC train: 0.945269	val: 0.829187	test: 0.816923
PRC train: 0.732812	val: 0.407274	test: 0.425895

Epoch: 55
Loss: 0.14174424365304072
ROC train: 0.943045	val: 0.831852	test: 0.810398
PRC train: 0.729422	val: 0.430266	test: 0.420864

Epoch: 56
Loss: 0.14423499300897288
ROC train: 0.946759	val: 0.823298	test: 0.808900
PRC train: 0.736795	val: 0.410374	test: 0.428289

Epoch: 57
Loss: 0.14358542675390354
ROC train: 0.949455	val: 0.827264	test: 0.813690
PRC train: 0.747192	val: 0.411204	test: 0.434977

Epoch: 58
Loss: 0.1404482404529179
ROC train: 0.946196	val: 0.837031	test: 0.818255
PRC train: 0.747007	val: 0.422856	test: 0.429858

Epoch: 59
Loss: 0.14187145371534857
ROC train: 0.951440	val: 0.826263	test: 0.806759
PRC train: 0.754781	val: 0.421113	test: 0.426509

Epoch: 60
Loss: 0.1403746002525021
ROC train: 0.949660	val: 0.831828	test: 0.808554
PRC train: 0.747420	val: 0.443310	test: 0.420417

Epoch: 61
Loss: 0.14215064118931314
ROC train: 0.953436	val: 0.825400	test: 0.816100
PRC train: 0.764031	val: 0.432087	test: 0.428866

Epoch: 62
Loss: 0.138482366989296
ROC train: 0.953734	val: 0.833886	test: 0.816463
PRC train: 0.767431	val: 0.426193	test: 0.431889

Epoch: 63
Loss: 0.13702456525435078
ROC train: 0.954175	val: 0.836238	test: 0.817399
PRC train: 0.771437	val: 0.431452	test: 0.436366

Epoch: 64
Loss: 0.13629600083451002
ROC train: 0.956944	val: 0.828383	test: 0.806845
PRC train: 0.778074	val: 0.428699	test: 0.432659

Epoch: 65
Loss: 0.13519863476574875
ROC train: 0.959875	val: 0.833473	test: 0.809504
PRC train: 0.790906	val: 0.434218	test: 0.428182

Epoch: 66
Loss: 0.13532893005700625
ROC train: 0.960004	val: 0.829498	test: 0.810726
PRC train: 0.788546	val: 0.430648	test: 0.423804

Epoch: 67
Loss: 0.13396186219074666
ROC train: 0.959513	val: 0.833710	test: 0.813633
PRC train: 0.789442	val: 0.423250	test: 0.435194

Epoch: 68
Loss: 0.1357342528925487
ROC train: 0.960251	val: 0.835416	test: 0.809497
PRC train: 0.793977	val: 0.436103	test: 0.426348

Epoch: 69
Loss: 0.1323015536880793
ROC train: 0.961664	val: 0.827901	test: 0.806342
PRC train: 0.796595	val: 0.418189	test: 0.432353

Epoch: 70
Loss: 0.13520419372397113
ROC train: 0.961455	val: 0.829161	test: 0.803436
PRC train: 0.795169	val: 0.421192	test: 0.423393

Epoch: 71
Loss: 0.13227674770216444
ROC train: 0.958921	val: 0.827987	test: 0.800519
PRC train: 0.787501	val: 0.443897	test: 0.411606

Epoch: 72
Loss: 0.13148457243177666
ROC train: 0.964045	val: 0.828917	test: 0.810992
PRC train: 0.804422	val: 0.430311	test: 0.435533

Epoch: 73
Loss: 0.12880762633064208
ROC train: 0.964134	val: 0.828974	test: 0.803808
PRC train: 0.809329	val: 0.430560	test: 0.425124

Epoch: 74
Loss: 0.1258686452479396
ROC train: 0.965205	val: 0.831075	test: 0.810500
PRC train: 0.815731	val: 0.424255	test: 0.425748

Epoch: 75
Loss: 0.12592080370301972
ROC train: 0.966555	val: 0.827255	test: 0.808566
PRC train: 0.820261	val: 0.433666	test: 0.434758

Epoch: 76
Loss: 0.12418283175155426
ROC train: 0.966547	val: 0.830236	test: 0.803163
PRC train: 0.820158	val: 0.447862	test: 0.427905

Epoch: 77
Loss: 0.12281474108364403
ROC train: 0.967009	val: 0.826368	test: 0.806731
PRC train: 0.818376	val: 0.428316	test: 0.429645

Epoch: 78
Loss: 0.12737834944982862
ROC train: 0.968446	val: 0.829433	test: 0.808206
PRC train: 0.824687	val: 0.424050	test: 0.428624

Epoch: 79
Loss: 0.12500678743936441
ROC train: 0.967736	val: 0.823622	test: 0.803170
PRC train: 0.822336	val: 0.427448	test: 0.418463

Epoch: 80
Loss: 0.12475086545658978
ROC train: 0.970095	val: 0.831104	test: 0.809603
PRC train: 0.835793	val: 0.425018	test: 0.430330

Epoch: 81
Loss: 0.12688486555747772
ROC train: 0.967569	val: 0.830248	test: 0.803806
PRC train: 0.822013	val: 0.452347	test: 0.426532

Epoch: 82
Loss: 0.12245259437350307
ROC train: 0.973161	val: 0.823616	test: 0.800999
PRC train: 0.844270	val: 0.432505	test: 0.411796

Epoch: 83
Loss: 0.12338107672328054
ROC train: 0.970998	val: 0.833442	test: 0.798820
PRC train: 0.831074	val: 0.446015	test: 0.402732

Epoch: 84
Loss: 0.12258647494098061
ROC train: 0.973523	val: 0.825149	test: 0.803478
PRC train: 0.844458	val: 0.446935	test: 0.423888

Epoch: 85
Loss: 0.11887081524126261
ROC train: 0.972378	val: 0.827988	test: 0.798786
PRC train: 0.842427	val: 0.449231	test: 0.418872

Epoch: 86
Loss: 0.11928484945170595
ROC train: 0.972940	val: 0.826906	test: 0.799612
PRC train: 0.840681	val: 0.431609	test: 0.410948

Epoch: 87
Loss: 0.12023080819039007
ROC train: 0.975475	val: 0.834667	test: 0.802016
PRC train: 0.858624	val: 0.455112	test: 0.416629

Epoch: 88
Loss: 0.12045693857256677
ROC train: 0.975285	val: 0.826396	test: 0.801103
PRC train: 0.856081	val: 0.427146	test: 0.419525

Epoch: 89
Loss: 0.11591001633076012
ROC train: 0.976115	val: 0.825735	test: 0.799503
PRC train: 0.855799	val: 0.446056	test: 0.420352

Epoch: 90
Loss: 0.11561394462630291
ROC train: 0.976485	val: 0.822095	test: 0.801773
PRC train: 0.860581	val: 0.424641	test: 0.424130

Epoch: 91
Loss: 0.11801604214609732
ROC train: 0.974896	val: 0.828200	test: 0.796936
PRC train: 0.852672	val: 0.445429	test: 0.418525

Epoch: 92
Loss: 0.11716426200294343
ROC train: 0.977113	val: 0.830365	test: 0.798861
PRC train: 0.860414	val: 0.451053	test: 0.415613

Epoch: 93
Loss: 0.1157957248283477
ROC train: 0.976372	val: 0.831980	test: 0.802105
PRC train: 0.859262	val: 0.426963	test: 0.413975

Epoch: 94
Loss: 0.11315446960889557
ROC train: 0.915495	val: 0.825694	test: 0.807163
PRC train: 0.625453	val: 0.411346	test: 0.413044

Epoch: 34
Loss: 0.16432462800220238
ROC train: 0.917011	val: 0.825069	test: 0.810536
PRC train: 0.634147	val: 0.404908	test: 0.409201

Epoch: 35
Loss: 0.16095305360460732
ROC train: 0.918010	val: 0.821295	test: 0.810796
PRC train: 0.637081	val: 0.413319	test: 0.420172

Epoch: 36
Loss: 0.16191366247353306
ROC train: 0.920220	val: 0.829624	test: 0.811013
PRC train: 0.646769	val: 0.417538	test: 0.414166

Epoch: 37
Loss: 0.16221504408254564
ROC train: 0.920711	val: 0.822043	test: 0.806960
PRC train: 0.649220	val: 0.425333	test: 0.429719

Epoch: 38
Loss: 0.1597886653646404
ROC train: 0.922317	val: 0.818297	test: 0.804665
PRC train: 0.653606	val: 0.402422	test: 0.416276

Epoch: 39
Loss: 0.15756887928275817
ROC train: 0.922464	val: 0.823040	test: 0.814107
PRC train: 0.658006	val: 0.430867	test: 0.435510

Epoch: 40
Loss: 0.15877277856045924
ROC train: 0.928422	val: 0.828143	test: 0.809995
PRC train: 0.677197	val: 0.435069	test: 0.432186

Epoch: 41
Loss: 0.1566590493709387
ROC train: 0.929810	val: 0.825116	test: 0.815013
PRC train: 0.672539	val: 0.422679	test: 0.424421

Epoch: 42
Loss: 0.1545619293935824
ROC train: 0.931819	val: 0.822200	test: 0.813689
PRC train: 0.687130	val: 0.433971	test: 0.438160

Epoch: 43
Loss: 0.1533788005546391
ROC train: 0.930778	val: 0.834247	test: 0.813289
PRC train: 0.679435	val: 0.433727	test: 0.422275

Epoch: 44
Loss: 0.1528215130358853
ROC train: 0.935728	val: 0.822117	test: 0.810591
PRC train: 0.697745	val: 0.414718	test: 0.417516

Epoch: 45
Loss: 0.15127801743848543
ROC train: 0.932726	val: 0.830940	test: 0.810213
PRC train: 0.683035	val: 0.428780	test: 0.422781

Epoch: 46
Loss: 0.15065543603108694
ROC train: 0.936671	val: 0.826005	test: 0.809421
PRC train: 0.704456	val: 0.419992	test: 0.421895

Epoch: 47
Loss: 0.14849199956392256
ROC train: 0.939841	val: 0.833199	test: 0.810602
PRC train: 0.708453	val: 0.436399	test: 0.430545

Epoch: 48
Loss: 0.15086078876620906
ROC train: 0.939231	val: 0.829302	test: 0.810339
PRC train: 0.715534	val: 0.437218	test: 0.427683

Epoch: 49
Loss: 0.14905710066842956
ROC train: 0.942314	val: 0.824302	test: 0.808210
PRC train: 0.719384	val: 0.418360	test: 0.426151

Epoch: 50
Loss: 0.14568595456764216
ROC train: 0.939612	val: 0.817256	test: 0.803900
PRC train: 0.712284	val: 0.413569	test: 0.409865

Epoch: 51
Loss: 0.14577820553973783
ROC train: 0.942039	val: 0.828581	test: 0.807733
PRC train: 0.717350	val: 0.434718	test: 0.414600

Epoch: 52
Loss: 0.1463056297997365
ROC train: 0.943590	val: 0.823893	test: 0.808597
PRC train: 0.726825	val: 0.423755	test: 0.420227

Epoch: 53
Loss: 0.14438938166674334
ROC train: 0.947840	val: 0.826069	test: 0.811613
PRC train: 0.738828	val: 0.429501	test: 0.435312

Epoch: 54
Loss: 0.1451800509415766
ROC train: 0.945202	val: 0.827666	test: 0.809022
PRC train: 0.729445	val: 0.439124	test: 0.430716

Epoch: 55
Loss: 0.14170457909396797
ROC train: 0.948032	val: 0.820999	test: 0.804424
PRC train: 0.740805	val: 0.415294	test: 0.416155

Epoch: 56
Loss: 0.1408244980575091
ROC train: 0.949122	val: 0.823922	test: 0.805653
PRC train: 0.744274	val: 0.425836	test: 0.431281

Epoch: 57
Loss: 0.14260829443579665
ROC train: 0.949619	val: 0.820529	test: 0.807357
PRC train: 0.748863	val: 0.427803	test: 0.415895

Epoch: 58
Loss: 0.13988385508632972
ROC train: 0.952206	val: 0.823464	test: 0.813062
PRC train: 0.756415	val: 0.440418	test: 0.434787

Epoch: 59
Loss: 0.13865107183334333
ROC train: 0.954022	val: 0.817128	test: 0.802549
PRC train: 0.758160	val: 0.429591	test: 0.423966

Epoch: 60
Loss: 0.13854199160132158
ROC train: 0.950606	val: 0.822818	test: 0.803445
PRC train: 0.744320	val: 0.427039	test: 0.409889

Epoch: 61
Loss: 0.14038479632246614
ROC train: 0.955265	val: 0.828166	test: 0.810268
PRC train: 0.767799	val: 0.443308	test: 0.417202

Epoch: 62
Loss: 0.13728946238147843
ROC train: 0.955208	val: 0.824729	test: 0.806872
PRC train: 0.765286	val: 0.445947	test: 0.427553

Epoch: 63
Loss: 0.13835709101022234
ROC train: 0.955518	val: 0.824119	test: 0.809861
PRC train: 0.769919	val: 0.414497	test: 0.423485

Epoch: 64
Loss: 0.13762147229828173
ROC train: 0.958064	val: 0.826339	test: 0.811489
PRC train: 0.782968	val: 0.447367	test: 0.433479

Epoch: 65
Loss: 0.13546071576046895
ROC train: 0.957588	val: 0.821563	test: 0.810323
PRC train: 0.775553	val: 0.431204	test: 0.428006

Epoch: 66
Loss: 0.1354149590781936
ROC train: 0.958077	val: 0.827252	test: 0.808312
PRC train: 0.778190	val: 0.434759	test: 0.433727

Epoch: 67
Loss: 0.1314872049796281
ROC train: 0.960637	val: 0.826243	test: 0.807049
PRC train: 0.786935	val: 0.451400	test: 0.432430

Epoch: 68
Loss: 0.13090162047961926
ROC train: 0.961509	val: 0.826858	test: 0.806236
PRC train: 0.794995	val: 0.451175	test: 0.434145

Epoch: 69
Loss: 0.13160947462074615
ROC train: 0.963073	val: 0.827674	test: 0.805528
PRC train: 0.797837	val: 0.453905	test: 0.433460

Epoch: 70
Loss: 0.13173491858471661
ROC train: 0.963947	val: 0.822490	test: 0.807450
PRC train: 0.797343	val: 0.436985	test: 0.432290

Epoch: 71
Loss: 0.1329464062160111
ROC train: 0.962615	val: 0.831381	test: 0.811703
PRC train: 0.791481	val: 0.452375	test: 0.433467

Epoch: 72
Loss: 0.12874047992195792
ROC train: 0.966638	val: 0.823302	test: 0.805877
PRC train: 0.815476	val: 0.437022	test: 0.432059

Epoch: 73
Loss: 0.12742433413878276
ROC train: 0.966343	val: 0.824972	test: 0.811147
PRC train: 0.814937	val: 0.430115	test: 0.437146

Epoch: 74
Loss: 0.12582152278231679
ROC train: 0.967514	val: 0.822990	test: 0.807153
PRC train: 0.818576	val: 0.435808	test: 0.435196

Epoch: 75
Loss: 0.12850502950316223
ROC train: 0.967284	val: 0.820781	test: 0.803281
PRC train: 0.817255	val: 0.432230	test: 0.439501

Epoch: 76
Loss: 0.12529369836041546
ROC train: 0.968404	val: 0.825322	test: 0.805493
PRC train: 0.821960	val: 0.437948	test: 0.431631

Epoch: 77
Loss: 0.1240887749278499
ROC train: 0.969363	val: 0.826856	test: 0.807250
PRC train: 0.825040	val: 0.443268	test: 0.431961

Epoch: 78
Loss: 0.12427154625757723
ROC train: 0.969476	val: 0.824016	test: 0.808531
PRC train: 0.828022	val: 0.442706	test: 0.432776

Epoch: 79
Loss: 0.12231390823963165
ROC train: 0.970319	val: 0.819823	test: 0.802680
PRC train: 0.828047	val: 0.438291	test: 0.423774

Epoch: 80
Loss: 0.12298243158415245
ROC train: 0.971299	val: 0.822896	test: 0.802205
PRC train: 0.836755	val: 0.453348	test: 0.427333

Epoch: 81
Loss: 0.12140647047508764
ROC train: 0.970774	val: 0.822302	test: 0.805979
PRC train: 0.834826	val: 0.444964	test: 0.437370

Epoch: 82
Loss: 0.12115393310814412
ROC train: 0.973153	val: 0.823059	test: 0.806737
PRC train: 0.846043	val: 0.443394	test: 0.435994

Epoch: 83
Loss: 0.1177526160025944
ROC train: 0.973182	val: 0.826573	test: 0.804009
PRC train: 0.844227	val: 0.443618	test: 0.436621

Epoch: 84
Loss: 0.11766628964876576
ROC train: 0.974256	val: 0.824802	test: 0.807139
PRC train: 0.850282	val: 0.457012	test: 0.436768

Epoch: 85
Loss: 0.11819090844268942
ROC train: 0.973915	val: 0.821798	test: 0.797045
PRC train: 0.851219	val: 0.450508	test: 0.435167

Epoch: 86
Loss: 0.11776782263028551
ROC train: 0.973495	val: 0.819017	test: 0.799537
PRC train: 0.845837	val: 0.455300	test: 0.438659

Epoch: 87
Loss: 0.11686793799332769
ROC train: 0.975611	val: 0.817776	test: 0.802379
PRC train: 0.851996	val: 0.432298	test: 0.439196

Epoch: 88
Loss: 0.11937905940372652
ROC train: 0.974642	val: 0.820578	test: 0.797466
PRC train: 0.848604	val: 0.444125	test: 0.425058

Epoch: 89
Loss: 0.11581260058630476
ROC train: 0.977523	val: 0.820608	test: 0.801253
PRC train: 0.863424	val: 0.441836	test: 0.434585

Epoch: 90
Loss: 0.11594754096436821
ROC train: 0.976173	val: 0.826850	test: 0.800397
PRC train: 0.854268	val: 0.442740	test: 0.440038

Epoch: 91
Loss: 0.11378361337538814
ROC train: 0.978762	val: 0.819519	test: 0.802092
PRC train: 0.868159	val: 0.448032	test: 0.427074

Epoch: 92
Loss: 0.11461014859309449
ROC train: 0.978809	val: 0.818574	test: 0.799497
PRC train: 0.864437	val: 0.435056	test: 0.430395

Epoch: 93
Loss: 0.11294846329048153
ROC train: 0.978193	val: 0.824913	test: 0.800493
PRC train: 0.867731	val: 0.450240	test: 0.438866

Epoch: 94
Loss: 0.11324506868732793
ROC train: 0.914329	val: 0.831798	test: 0.813081
PRC train: 0.635356	val: 0.437495	test: 0.418980

Epoch: 34
Loss: 0.16248222537723217
ROC train: 0.915372	val: 0.825624	test: 0.814198
PRC train: 0.641912	val: 0.423429	test: 0.420693

Epoch: 35
Loss: 0.16556417220421504
ROC train: 0.917047	val: 0.836838	test: 0.822783
PRC train: 0.648582	val: 0.431071	test: 0.436264

Epoch: 36
Loss: 0.1614530550684854
ROC train: 0.920018	val: 0.832115	test: 0.819425
PRC train: 0.649517	val: 0.418084	test: 0.422053

Epoch: 37
Loss: 0.15957384132276609
ROC train: 0.922848	val: 0.838059	test: 0.815812
PRC train: 0.663545	val: 0.441724	test: 0.424102

Epoch: 38
Loss: 0.15614483756954603
ROC train: 0.925331	val: 0.836049	test: 0.822891
PRC train: 0.670351	val: 0.434368	test: 0.428538

Epoch: 39
Loss: 0.15881639577010084
ROC train: 0.924500	val: 0.833855	test: 0.821037
PRC train: 0.665277	val: 0.434442	test: 0.424880

Epoch: 40
Loss: 0.15519185699522706
ROC train: 0.925460	val: 0.832627	test: 0.820872
PRC train: 0.671953	val: 0.433623	test: 0.430375

Epoch: 41
Loss: 0.15351105809131382
ROC train: 0.931613	val: 0.836099	test: 0.818931
PRC train: 0.689724	val: 0.448369	test: 0.435750

Epoch: 42
Loss: 0.15150404405479523
ROC train: 0.931254	val: 0.837099	test: 0.820953
PRC train: 0.686754	val: 0.441675	test: 0.435210

Epoch: 43
Loss: 0.15412405867668244
ROC train: 0.931983	val: 0.829346	test: 0.807776
PRC train: 0.686272	val: 0.422864	test: 0.432217

Epoch: 44
Loss: 0.15032704739787828
ROC train: 0.930604	val: 0.832931	test: 0.814448
PRC train: 0.685186	val: 0.447287	test: 0.438609

Epoch: 45
Loss: 0.15119364330300353
ROC train: 0.933203	val: 0.830990	test: 0.805475
PRC train: 0.691276	val: 0.430103	test: 0.425857

Epoch: 46
Loss: 0.1509674502210837
ROC train: 0.932971	val: 0.833518	test: 0.819533
PRC train: 0.688024	val: 0.443733	test: 0.430744

Epoch: 47
Loss: 0.1508578191826456
ROC train: 0.935031	val: 0.841137	test: 0.820854
PRC train: 0.700135	val: 0.448770	test: 0.439352

Epoch: 48
Loss: 0.14765583357578252
ROC train: 0.941023	val: 0.835299	test: 0.815954
PRC train: 0.715371	val: 0.449736	test: 0.437568

Epoch: 49
Loss: 0.14692097249587946
ROC train: 0.942813	val: 0.835478	test: 0.818312
PRC train: 0.729635	val: 0.449764	test: 0.434213

Epoch: 50
Loss: 0.14435994182596137
ROC train: 0.942270	val: 0.840435	test: 0.813561
PRC train: 0.724462	val: 0.461758	test: 0.436091

Epoch: 51
Loss: 0.14627263598696122
ROC train: 0.945999	val: 0.837696	test: 0.816693
PRC train: 0.739836	val: 0.460001	test: 0.444924

Epoch: 52
Loss: 0.14452970245649238
ROC train: 0.947211	val: 0.839912	test: 0.819639
PRC train: 0.734721	val: 0.449212	test: 0.432700

Epoch: 53
Loss: 0.14414082728570443
ROC train: 0.946875	val: 0.837767	test: 0.814283
PRC train: 0.742934	val: 0.456437	test: 0.432724

Epoch: 54
Loss: 0.14475084109022038
ROC train: 0.946998	val: 0.835321	test: 0.811988
PRC train: 0.736643	val: 0.462840	test: 0.441096

Epoch: 55
Loss: 0.14285089587103583
ROC train: 0.949349	val: 0.837249	test: 0.814117
PRC train: 0.744488	val: 0.452695	test: 0.442920

Epoch: 56
Loss: 0.1418989615452354
ROC train: 0.950211	val: 0.836631	test: 0.817632
PRC train: 0.751623	val: 0.444395	test: 0.450286

Epoch: 57
Loss: 0.14204179687422674
ROC train: 0.952057	val: 0.835249	test: 0.810581
PRC train: 0.758486	val: 0.449468	test: 0.430726

Epoch: 58
Loss: 0.13967372600171435
ROC train: 0.951423	val: 0.833567	test: 0.816429
PRC train: 0.753746	val: 0.418424	test: 0.424643

Epoch: 59
Loss: 0.1411284243515637
ROC train: 0.954852	val: 0.831924	test: 0.808051
PRC train: 0.768747	val: 0.439054	test: 0.423343

Epoch: 60
Loss: 0.1376837720639981
ROC train: 0.953672	val: 0.837122	test: 0.813321
PRC train: 0.766103	val: 0.444425	test: 0.440184

Epoch: 61
Loss: 0.1369568039334185
ROC train: 0.956418	val: 0.835384	test: 0.811567
PRC train: 0.775771	val: 0.451202	test: 0.434071

Epoch: 62
Loss: 0.13694917843893997
ROC train: 0.954666	val: 0.828336	test: 0.805980
PRC train: 0.769154	val: 0.437198	test: 0.424354

Epoch: 63
Loss: 0.1364870157183551
ROC train: 0.956300	val: 0.836489	test: 0.816334
PRC train: 0.777001	val: 0.454179	test: 0.432036

Epoch: 64
Loss: 0.13475424827356164
ROC train: 0.956521	val: 0.829751	test: 0.807375
PRC train: 0.773864	val: 0.455154	test: 0.434364

Epoch: 65
Loss: 0.13337947034225514
ROC train: 0.960861	val: 0.834323	test: 0.813932
PRC train: 0.795291	val: 0.436384	test: 0.432749

Epoch: 66
Loss: 0.13229849196002857
ROC train: 0.961435	val: 0.829314	test: 0.808984
PRC train: 0.792470	val: 0.448846	test: 0.423890

Epoch: 67
Loss: 0.13271970976620356
ROC train: 0.961868	val: 0.833055	test: 0.813405
PRC train: 0.795436	val: 0.455474	test: 0.434217

Epoch: 68
Loss: 0.1303248323465664
ROC train: 0.961232	val: 0.832017	test: 0.811135
PRC train: 0.792026	val: 0.435686	test: 0.432973

Epoch: 69
Loss: 0.12959778971914923
ROC train: 0.963493	val: 0.833385	test: 0.811071
PRC train: 0.803934	val: 0.438421	test: 0.433548

Epoch: 70
Loss: 0.1295725830675142
ROC train: 0.965063	val: 0.837866	test: 0.811522
PRC train: 0.810047	val: 0.460967	test: 0.436287

Epoch: 71
Loss: 0.1299752196367278
ROC train: 0.965330	val: 0.834989	test: 0.811887
PRC train: 0.809342	val: 0.433468	test: 0.427831

Epoch: 72
Loss: 0.12512214548842637
ROC train: 0.963927	val: 0.831271	test: 0.812533
PRC train: 0.806475	val: 0.457773	test: 0.437322

Epoch: 73
Loss: 0.1296604292675388
ROC train: 0.967377	val: 0.826375	test: 0.808356
PRC train: 0.820096	val: 0.434939	test: 0.429083

Epoch: 74
Loss: 0.12820321979499671
ROC train: 0.968393	val: 0.827601	test: 0.809415
PRC train: 0.822636	val: 0.447270	test: 0.431640

Epoch: 75
Loss: 0.12434120586838475
ROC train: 0.968356	val: 0.829223	test: 0.804854
PRC train: 0.829098	val: 0.447215	test: 0.425880

Epoch: 76
Loss: 0.12450689257503846
ROC train: 0.967180	val: 0.840848	test: 0.814964
PRC train: 0.822354	val: 0.439297	test: 0.435371

Epoch: 77
Loss: 0.12201749629703831
ROC train: 0.969122	val: 0.827266	test: 0.810077
PRC train: 0.830795	val: 0.439197	test: 0.435170

Epoch: 78
Loss: 0.12340048896803606
ROC train: 0.970095	val: 0.828074	test: 0.807047
PRC train: 0.832428	val: 0.439559	test: 0.433164

Epoch: 79
Loss: 0.12282284354246487
ROC train: 0.969679	val: 0.832461	test: 0.803433
PRC train: 0.832345	val: 0.438276	test: 0.419579

Epoch: 80
Loss: 0.12179482760295335
ROC train: 0.969235	val: 0.823476	test: 0.797234
PRC train: 0.828764	val: 0.440102	test: 0.421110

Epoch: 81
Loss: 0.12397592009953963
ROC train: 0.971618	val: 0.826598	test: 0.800200
PRC train: 0.837372	val: 0.440165	test: 0.418676

Epoch: 82
Loss: 0.12372562258287681
ROC train: 0.970921	val: 0.831574	test: 0.799473
PRC train: 0.836491	val: 0.460562	test: 0.432851

Epoch: 83
Loss: 0.12078593909308678
ROC train: 0.973361	val: 0.825646	test: 0.802882
PRC train: 0.843036	val: 0.438099	test: 0.425533

Epoch: 84
Loss: 0.11939106422590644
ROC train: 0.972523	val: 0.830614	test: 0.807945
PRC train: 0.838962	val: 0.438305	test: 0.421318

Epoch: 85
Loss: 0.11999892295409213
ROC train: 0.974962	val: 0.823951	test: 0.803794
PRC train: 0.857484	val: 0.436265	test: 0.427147

Epoch: 86
Loss: 0.11939697646690912
ROC train: 0.973261	val: 0.825892	test: 0.799279
PRC train: 0.841645	val: 0.444108	test: 0.435232

Epoch: 87
Loss: 0.11778699845932311
ROC train: 0.974907	val: 0.832223	test: 0.802554
PRC train: 0.855261	val: 0.447945	test: 0.435505

Epoch: 88
Loss: 0.11599557048532057
ROC train: 0.976989	val: 0.826324	test: 0.806753
PRC train: 0.865695	val: 0.450855	test: 0.435871

Epoch: 89
Loss: 0.11657762660095501
ROC train: 0.977155	val: 0.833447	test: 0.805937
PRC train: 0.864247	val: 0.442851	test: 0.424243

Epoch: 90
Loss: 0.11353352958134337
ROC train: 0.976686	val: 0.830298	test: 0.802261
PRC train: 0.861785	val: 0.441150	test: 0.425651

Epoch: 91
Loss: 0.11701586700816347
ROC train: 0.977461	val: 0.831276	test: 0.803660
PRC train: 0.869340	val: 0.433682	test: 0.430693

Epoch: 92
Loss: 0.11370560727046285
ROC train: 0.978000	val: 0.829064	test: 0.802052
PRC train: 0.864797	val: 0.445771	test: 0.425941

Epoch: 93
Loss: 0.11373391792034729
ROC train: 0.979106	val: 0.829832	test: 0.802564
PRC train: 0.873492	val: 0.440745	test: 0.427242

Epoch: 94
Loss: 0.11522130027249147
ROC train: 0.909305	val: 0.826265	test: 0.825625
PRC train: 0.629176	val: 0.433694	test: 0.429593

Epoch: 34
Loss: 0.16061362350763433
ROC train: 0.913210	val: 0.828045	test: 0.821742
PRC train: 0.635134	val: 0.435845	test: 0.424413

Epoch: 35
Loss: 0.15984392244183396
ROC train: 0.914462	val: 0.828521	test: 0.823571
PRC train: 0.638016	val: 0.440283	test: 0.445635

Epoch: 36
Loss: 0.16039570861124533
ROC train: 0.916362	val: 0.823400	test: 0.836065
PRC train: 0.645322	val: 0.428148	test: 0.446890

Epoch: 37
Loss: 0.1575523017634374
ROC train: 0.920963	val: 0.826359	test: 0.833305
PRC train: 0.662744	val: 0.442145	test: 0.460775

Epoch: 38
Loss: 0.1567587250915143
ROC train: 0.920812	val: 0.822172	test: 0.831823
PRC train: 0.660660	val: 0.451144	test: 0.455982

Epoch: 39
Loss: 0.15536099659610228
ROC train: 0.923991	val: 0.825909	test: 0.829829
PRC train: 0.664875	val: 0.461448	test: 0.462202

Epoch: 40
Loss: 0.15401429420952398
ROC train: 0.923089	val: 0.827504	test: 0.824171
PRC train: 0.664519	val: 0.446034	test: 0.449582

Epoch: 41
Loss: 0.15309694070930446
ROC train: 0.929040	val: 0.821880	test: 0.827827
PRC train: 0.681617	val: 0.442286	test: 0.463982

Epoch: 42
Loss: 0.1531128480095876
ROC train: 0.929085	val: 0.832460	test: 0.831012
PRC train: 0.682815	val: 0.445877	test: 0.473311

Epoch: 43
Loss: 0.15099072433916402
ROC train: 0.928464	val: 0.826378	test: 0.827472
PRC train: 0.682880	val: 0.463051	test: 0.480871

Epoch: 44
Loss: 0.1494460945898129
ROC train: 0.930764	val: 0.832335	test: 0.828628
PRC train: 0.692358	val: 0.447790	test: 0.475299

Epoch: 45
Loss: 0.14937446392544343
ROC train: 0.934229	val: 0.824580	test: 0.823000
PRC train: 0.704089	val: 0.446214	test: 0.455023

Epoch: 46
Loss: 0.15164762635681325
ROC train: 0.934743	val: 0.819608	test: 0.821576
PRC train: 0.704238	val: 0.459846	test: 0.465061

Epoch: 47
Loss: 0.14790272773227958
ROC train: 0.936347	val: 0.825260	test: 0.828049
PRC train: 0.711484	val: 0.444524	test: 0.470156

Epoch: 48
Loss: 0.14675840693891526
ROC train: 0.937714	val: 0.826366	test: 0.825230
PRC train: 0.711869	val: 0.452399	test: 0.471254

Epoch: 49
Loss: 0.14540512350170529
ROC train: 0.940103	val: 0.824715	test: 0.826056
PRC train: 0.717356	val: 0.444127	test: 0.463371

Epoch: 50
Loss: 0.14446346594613327
ROC train: 0.935264	val: 0.831403	test: 0.825307
PRC train: 0.705462	val: 0.445797	test: 0.463762

Epoch: 51
Loss: 0.1476015788647921
ROC train: 0.942472	val: 0.826997	test: 0.824089
PRC train: 0.728496	val: 0.438245	test: 0.475569

Epoch: 52
Loss: 0.1429153279038217
ROC train: 0.939287	val: 0.816921	test: 0.818112
PRC train: 0.713554	val: 0.445162	test: 0.447099

Epoch: 53
Loss: 0.1413138756374969
ROC train: 0.942573	val: 0.822055	test: 0.830064
PRC train: 0.723234	val: 0.432879	test: 0.467675

Epoch: 54
Loss: 0.14532471324765095
ROC train: 0.943320	val: 0.814587	test: 0.816902
PRC train: 0.724785	val: 0.426051	test: 0.449917

Epoch: 55
Loss: 0.1408877703385784
ROC train: 0.946216	val: 0.822461	test: 0.824012
PRC train: 0.737719	val: 0.453115	test: 0.466309

Epoch: 56
Loss: 0.1404316345931367
ROC train: 0.947671	val: 0.825394	test: 0.822953
PRC train: 0.744157	val: 0.443893	test: 0.465670

Epoch: 57
Loss: 0.14016541453191197
ROC train: 0.945517	val: 0.821505	test: 0.817181
PRC train: 0.738664	val: 0.445684	test: 0.456906

Epoch: 58
Loss: 0.13913401843974585
ROC train: 0.945034	val: 0.810516	test: 0.802810
PRC train: 0.735135	val: 0.435944	test: 0.440023

Epoch: 59
Loss: 0.13835643018691965
ROC train: 0.950731	val: 0.831720	test: 0.823390
PRC train: 0.756247	val: 0.446559	test: 0.467354

Epoch: 60
Loss: 0.13649482116721143
ROC train: 0.953465	val: 0.826382	test: 0.818351
PRC train: 0.764109	val: 0.446390	test: 0.456262

Epoch: 61
Loss: 0.13699488241404165
ROC train: 0.951298	val: 0.822898	test: 0.807824
PRC train: 0.755040	val: 0.454022	test: 0.454173

Epoch: 62
Loss: 0.13538889460485037
ROC train: 0.953174	val: 0.820149	test: 0.819688
PRC train: 0.761528	val: 0.433996	test: 0.465222

Epoch: 63
Loss: 0.13541056326741296
ROC train: 0.953933	val: 0.821101	test: 0.818096
PRC train: 0.770097	val: 0.444673	test: 0.458874

Epoch: 64
Loss: 0.133718562031448
ROC train: 0.955931	val: 0.824442	test: 0.824824
PRC train: 0.774842	val: 0.473065	test: 0.478343

Epoch: 65
Loss: 0.1321370434412443
ROC train: 0.956940	val: 0.819885	test: 0.814866
PRC train: 0.777958	val: 0.448356	test: 0.469031

Epoch: 66
Loss: 0.13149330053340097
ROC train: 0.957297	val: 0.824478	test: 0.819757
PRC train: 0.777107	val: 0.458958	test: 0.472209

Epoch: 67
Loss: 0.13169448312696933
ROC train: 0.958896	val: 0.821502	test: 0.817302
PRC train: 0.783952	val: 0.444872	test: 0.468006

Epoch: 68
Loss: 0.13152964089541852
ROC train: 0.960294	val: 0.821832	test: 0.823862
PRC train: 0.790105	val: 0.442011	test: 0.472910

Epoch: 69
Loss: 0.12958546215324
ROC train: 0.961850	val: 0.818620	test: 0.818211
PRC train: 0.794637	val: 0.443788	test: 0.478474

Epoch: 70
Loss: 0.12940231909921673
ROC train: 0.961864	val: 0.819415	test: 0.821993
PRC train: 0.795749	val: 0.441140	test: 0.481025

Epoch: 71
Loss: 0.13016186152674097
ROC train: 0.962425	val: 0.818421	test: 0.816726
PRC train: 0.796570	val: 0.433965	test: 0.467413

Epoch: 72
Loss: 0.12842585242345364
ROC train: 0.964110	val: 0.820508	test: 0.815718
PRC train: 0.805447	val: 0.444743	test: 0.462995

Epoch: 73
Loss: 0.1271427330528493
ROC train: 0.962149	val: 0.816719	test: 0.817039
PRC train: 0.797870	val: 0.435924	test: 0.455738

Epoch: 74
Loss: 0.12755190777806039
ROC train: 0.964910	val: 0.824705	test: 0.819939
PRC train: 0.806877	val: 0.451674	test: 0.482327

Epoch: 75
Loss: 0.12392188140037354
ROC train: 0.963593	val: 0.819238	test: 0.816834
PRC train: 0.803249	val: 0.444279	test: 0.465370

Epoch: 76
Loss: 0.12507969481070316
ROC train: 0.967412	val: 0.824316	test: 0.820592
PRC train: 0.817248	val: 0.452296	test: 0.475396

Epoch: 77
Loss: 0.1227622535324456
ROC train: 0.968112	val: 0.818297	test: 0.814468
PRC train: 0.819169	val: 0.442955	test: 0.470334

Epoch: 78
Loss: 0.12340874677487701
ROC train: 0.968496	val: 0.820154	test: 0.819804
PRC train: 0.824056	val: 0.442405	test: 0.474322

Epoch: 79
Loss: 0.1225419861347946
ROC train: 0.970770	val: 0.816437	test: 0.815886
PRC train: 0.828383	val: 0.435573	test: 0.468557

Epoch: 80
Loss: 0.12380332277902362
ROC train: 0.965689	val: 0.818975	test: 0.818543
PRC train: 0.807845	val: 0.441473	test: 0.471618

Epoch: 81
Loss: 0.12336408737158973
ROC train: 0.970890	val: 0.810772	test: 0.814843
PRC train: 0.833442	val: 0.444398	test: 0.475413

Epoch: 82
Loss: 0.12046442222990374
ROC train: 0.971028	val: 0.819668	test: 0.815163
PRC train: 0.831368	val: 0.436769	test: 0.474115

Epoch: 83
Loss: 0.11991822725409719
ROC train: 0.971817	val: 0.820447	test: 0.819110
PRC train: 0.835214	val: 0.436252	test: 0.475757

Epoch: 84
Loss: 0.1199364834944602
ROC train: 0.972031	val: 0.818903	test: 0.809412
PRC train: 0.833432	val: 0.431184	test: 0.480359

Epoch: 85
Loss: 0.1194480713110047
ROC train: 0.968208	val: 0.815226	test: 0.807774
PRC train: 0.815891	val: 0.443624	test: 0.466474

Epoch: 86
Loss: 0.11978920837605452
ROC train: 0.973608	val: 0.810114	test: 0.812872
PRC train: 0.842277	val: 0.435677	test: 0.474395

Epoch: 87
Loss: 0.11761677266113066
ROC train: 0.973645	val: 0.819620	test: 0.813509
PRC train: 0.844880	val: 0.436589	test: 0.466298

Epoch: 88
Loss: 0.1165386058519746
ROC train: 0.974392	val: 0.818286	test: 0.810381
PRC train: 0.848848	val: 0.441024	test: 0.469619

Epoch: 89
Loss: 0.11665383832808794
ROC train: 0.974223	val: 0.823773	test: 0.813948
PRC train: 0.848036	val: 0.445893	test: 0.472804

Epoch: 90
Loss: 0.1155576761334102
ROC train: 0.975121	val: 0.810405	test: 0.810657
PRC train: 0.849273	val: 0.434176	test: 0.468782

Epoch: 91
Loss: 0.11446422480312207
ROC train: 0.977237	val: 0.821599	test: 0.811078
PRC train: 0.864193	val: 0.446805	test: 0.472139

Epoch: 92
Loss: 0.11373470507793244
ROC train: 0.977570	val: 0.822313	test: 0.814987
PRC train: 0.863091	val: 0.450348	test: 0.475983

Epoch: 93
Loss: 0.11249069772643455
ROC train: 0.977417	val: 0.823259	test: 0.814794
PRC train: 0.860996	val: 0.449795	test: 0.473707

Epoch: 94
Loss: 0.11230132152182569
ROC train: 0.910780	val: 0.830023	test: 0.830566
PRC train: 0.605335	val: 0.435566	test: 0.420669

Epoch: 34
Loss: 0.16130996495001745
ROC train: 0.915974	val: 0.833425	test: 0.826199
PRC train: 0.621874	val: 0.418241	test: 0.427596

Epoch: 35
Loss: 0.16120532390372438
ROC train: 0.915869	val: 0.830972	test: 0.818072
PRC train: 0.632220	val: 0.447464	test: 0.427242

Epoch: 36
Loss: 0.15915072048025983
ROC train: 0.919137	val: 0.830262	test: 0.825831
PRC train: 0.639947	val: 0.430837	test: 0.426716

Epoch: 37
Loss: 0.15878057626633188
ROC train: 0.918139	val: 0.827714	test: 0.830090
PRC train: 0.647377	val: 0.434604	test: 0.433877

Epoch: 38
Loss: 0.1564228015375699
ROC train: 0.920385	val: 0.833901	test: 0.823719
PRC train: 0.646195	val: 0.437653	test: 0.443865

Epoch: 39
Loss: 0.15645274917778926
ROC train: 0.924607	val: 0.832472	test: 0.826985
PRC train: 0.656973	val: 0.429310	test: 0.431644

Epoch: 40
Loss: 0.15479383119983267
ROC train: 0.926765	val: 0.834415	test: 0.826526
PRC train: 0.668672	val: 0.449120	test: 0.442455

Epoch: 41
Loss: 0.15442381277259898
ROC train: 0.925272	val: 0.831391	test: 0.825103
PRC train: 0.671805	val: 0.436739	test: 0.432711

Epoch: 42
Loss: 0.15405021002626298
ROC train: 0.927234	val: 0.830185	test: 0.830839
PRC train: 0.670910	val: 0.439375	test: 0.439756

Epoch: 43
Loss: 0.15065213280757306
ROC train: 0.930222	val: 0.828992	test: 0.827450
PRC train: 0.680793	val: 0.436247	test: 0.453282

Epoch: 44
Loss: 0.15280264517203593
ROC train: 0.931909	val: 0.827047	test: 0.823237
PRC train: 0.678813	val: 0.444033	test: 0.438079

Epoch: 45
Loss: 0.15164065168213853
ROC train: 0.932280	val: 0.835451	test: 0.828180
PRC train: 0.682520	val: 0.451468	test: 0.446205

Epoch: 46
Loss: 0.15008404711000353
ROC train: 0.934746	val: 0.839269	test: 0.829634
PRC train: 0.695088	val: 0.455479	test: 0.453644

Epoch: 47
Loss: 0.1466302204968526
ROC train: 0.936420	val: 0.833007	test: 0.826767
PRC train: 0.696247	val: 0.442084	test: 0.447402

Epoch: 48
Loss: 0.1491492906823056
ROC train: 0.938028	val: 0.833934	test: 0.825298
PRC train: 0.709648	val: 0.440470	test: 0.456990

Epoch: 49
Loss: 0.1468633064220963
ROC train: 0.934081	val: 0.832725	test: 0.820031
PRC train: 0.697541	val: 0.437155	test: 0.450898

Epoch: 50
Loss: 0.1466720434839241
ROC train: 0.937614	val: 0.828630	test: 0.823829
PRC train: 0.700860	val: 0.444800	test: 0.448974

Epoch: 51
Loss: 0.14733039089633027
ROC train: 0.939053	val: 0.830801	test: 0.821958
PRC train: 0.704101	val: 0.444071	test: 0.456443

Epoch: 52
Loss: 0.14358911730801627
ROC train: 0.942752	val: 0.832481	test: 0.822626
PRC train: 0.722681	val: 0.445638	test: 0.462415

Epoch: 53
Loss: 0.14200562840699166
ROC train: 0.941341	val: 0.834331	test: 0.823391
PRC train: 0.707700	val: 0.450868	test: 0.457313

Epoch: 54
Loss: 0.14224699283938905
ROC train: 0.945652	val: 0.834708	test: 0.824266
PRC train: 0.727954	val: 0.439992	test: 0.457432

Epoch: 55
Loss: 0.14286748959656417
ROC train: 0.944364	val: 0.834781	test: 0.828512
PRC train: 0.723775	val: 0.444729	test: 0.461640

Epoch: 56
Loss: 0.14020719162817882
ROC train: 0.946039	val: 0.833344	test: 0.824642
PRC train: 0.730971	val: 0.443987	test: 0.453066

Epoch: 57
Loss: 0.1416513517803237
ROC train: 0.949482	val: 0.834053	test: 0.826574
PRC train: 0.745167	val: 0.453028	test: 0.462890

Epoch: 58
Loss: 0.13930292169550546
ROC train: 0.949487	val: 0.836961	test: 0.825415
PRC train: 0.738863	val: 0.444309	test: 0.471629

Epoch: 59
Loss: 0.14011913064726542
ROC train: 0.948495	val: 0.832422	test: 0.821251
PRC train: 0.744399	val: 0.442737	test: 0.459757

Epoch: 60
Loss: 0.13704518562631635
ROC train: 0.950719	val: 0.834729	test: 0.823699
PRC train: 0.751495	val: 0.454881	test: 0.468668

Epoch: 61
Loss: 0.1389577844594909
ROC train: 0.953691	val: 0.832543	test: 0.818060
PRC train: 0.759636	val: 0.451882	test: 0.462272

Epoch: 62
Loss: 0.13693191174052444
ROC train: 0.952792	val: 0.833275	test: 0.823577
PRC train: 0.754956	val: 0.446920	test: 0.470182

Epoch: 63
Loss: 0.13690787976362898
ROC train: 0.953519	val: 0.829789	test: 0.811721
PRC train: 0.754578	val: 0.454413	test: 0.455024

Epoch: 64
Loss: 0.13640229086101519
ROC train: 0.954981	val: 0.840232	test: 0.821123
PRC train: 0.764093	val: 0.444857	test: 0.467202

Epoch: 65
Loss: 0.13320783186038726
ROC train: 0.958265	val: 0.832715	test: 0.822724
PRC train: 0.773286	val: 0.464560	test: 0.469184

Epoch: 66
Loss: 0.13276097583838775
ROC train: 0.957441	val: 0.831805	test: 0.813837
PRC train: 0.770017	val: 0.449629	test: 0.460325

Epoch: 67
Loss: 0.1319528762805236
ROC train: 0.957957	val: 0.836247	test: 0.819043
PRC train: 0.775981	val: 0.436907	test: 0.466800

Epoch: 68
Loss: 0.13337480662314885
ROC train: 0.958942	val: 0.828728	test: 0.813075
PRC train: 0.778606	val: 0.448015	test: 0.467226

Epoch: 69
Loss: 0.13131833236743265
ROC train: 0.959797	val: 0.835171	test: 0.820304
PRC train: 0.783183	val: 0.452981	test: 0.467398

Epoch: 70
Loss: 0.1325244448187869
ROC train: 0.962185	val: 0.836897	test: 0.816832
PRC train: 0.787921	val: 0.437235	test: 0.457702

Epoch: 71
Loss: 0.13193195269202593
ROC train: 0.961362	val: 0.829004	test: 0.822649
PRC train: 0.775391	val: 0.436400	test: 0.464489

Epoch: 72
Loss: 0.1297531651278918
ROC train: 0.962079	val: 0.832739	test: 0.824326
PRC train: 0.789719	val: 0.446507	test: 0.464363

Epoch: 73
Loss: 0.12807420340507752
ROC train: 0.964846	val: 0.834742	test: 0.816313
PRC train: 0.800271	val: 0.444599	test: 0.457519

Epoch: 74
Loss: 0.12901618775509985
ROC train: 0.963503	val: 0.830178	test: 0.820964
PRC train: 0.796216	val: 0.443820	test: 0.459994

Epoch: 75
Loss: 0.12785663672025294
ROC train: 0.965337	val: 0.837958	test: 0.824078
PRC train: 0.797376	val: 0.443183	test: 0.449490

Epoch: 76
Loss: 0.12621912545826391
ROC train: 0.965136	val: 0.830409	test: 0.811958
PRC train: 0.797245	val: 0.445813	test: 0.448442

Epoch: 77
Loss: 0.12505209414915042
ROC train: 0.966201	val: 0.828033	test: 0.814895
PRC train: 0.802738	val: 0.446465	test: 0.454302

Epoch: 78
Loss: 0.12461345416636797
ROC train: 0.967571	val: 0.834415	test: 0.809780
PRC train: 0.811878	val: 0.451343	test: 0.450884

Epoch: 79
Loss: 0.12267446184284178
ROC train: 0.967279	val: 0.831800	test: 0.819754
PRC train: 0.814184	val: 0.434097	test: 0.450766

Epoch: 80
Loss: 0.1229484488109684
ROC train: 0.968215	val: 0.831540	test: 0.818144
PRC train: 0.813510	val: 0.439841	test: 0.443770

Epoch: 81
Loss: 0.12069908494565983
ROC train: 0.968139	val: 0.831581	test: 0.809469
PRC train: 0.811827	val: 0.453586	test: 0.450292

Epoch: 82
Loss: 0.12369520439169782
ROC train: 0.969290	val: 0.827129	test: 0.811623
PRC train: 0.815308	val: 0.435984	test: 0.440667

Epoch: 83
Loss: 0.11965674039727035
ROC train: 0.972567	val: 0.832691	test: 0.815055
PRC train: 0.834414	val: 0.444053	test: 0.453563

Epoch: 84
Loss: 0.11885833764662901
ROC train: 0.972412	val: 0.832914	test: 0.812908
PRC train: 0.830651	val: 0.443671	test: 0.446389

Epoch: 85
Loss: 0.12112720785148917
ROC train: 0.973010	val: 0.831359	test: 0.813258
PRC train: 0.832271	val: 0.442196	test: 0.449673

Epoch: 86
Loss: 0.12043616825151432
ROC train: 0.973420	val: 0.840380	test: 0.813586
PRC train: 0.842097	val: 0.445942	test: 0.443306

Epoch: 87
Loss: 0.11781162654497185
ROC train: 0.974532	val: 0.833303	test: 0.811274
PRC train: 0.840902	val: 0.452046	test: 0.449685

Epoch: 88
Loss: 0.11666940935756398
ROC train: 0.975601	val: 0.825027	test: 0.810882
PRC train: 0.845581	val: 0.442508	test: 0.448676

Epoch: 89
Loss: 0.11846182412622994
ROC train: 0.974827	val: 0.830532	test: 0.810761
PRC train: 0.842595	val: 0.442805	test: 0.442814

Epoch: 90
Loss: 0.11767701093838821
ROC train: 0.975880	val: 0.826178	test: 0.814403
PRC train: 0.848195	val: 0.445370	test: 0.451030

Epoch: 91
Loss: 0.11470834691716002
ROC train: 0.977096	val: 0.834040	test: 0.814616
PRC train: 0.855003	val: 0.448513	test: 0.451261

Epoch: 92
Loss: 0.11482083422075694
ROC train: 0.977821	val: 0.829190	test: 0.812439
PRC train: 0.858651	val: 0.452756	test: 0.453509

Epoch: 93
Loss: 0.11235772411664283
ROC train: 0.978361	val: 0.829190	test: 0.814909
PRC train: 0.861123	val: 0.450658	test: 0.453747

Epoch: 94
Loss: 0.11294665838247225
ROC train: 0.916125	val: 0.838276	test: 0.831781
PRC train: 0.637289	val: 0.450706	test: 0.444840

Epoch: 34
Loss: 0.16133941338982605
ROC train: 0.916972	val: 0.831993	test: 0.828101
PRC train: 0.643804	val: 0.443205	test: 0.440245

Epoch: 35
Loss: 0.1615012370491163
ROC train: 0.918363	val: 0.831041	test: 0.828740
PRC train: 0.649510	val: 0.442190	test: 0.427164

Epoch: 36
Loss: 0.1600822834973617
ROC train: 0.920900	val: 0.830978	test: 0.828562
PRC train: 0.658598	val: 0.452706	test: 0.436993

Epoch: 37
Loss: 0.15756117463426084
ROC train: 0.923153	val: 0.831670	test: 0.828170
PRC train: 0.662769	val: 0.444239	test: 0.441649

Epoch: 38
Loss: 0.1550048012332742
ROC train: 0.922885	val: 0.821572	test: 0.826738
PRC train: 0.661161	val: 0.443748	test: 0.438803

Epoch: 39
Loss: 0.1548083247436117
ROC train: 0.925687	val: 0.827688	test: 0.828333
PRC train: 0.672384	val: 0.446826	test: 0.434850

Epoch: 40
Loss: 0.15518596159093623
ROC train: 0.925281	val: 0.831278	test: 0.824714
PRC train: 0.670109	val: 0.452084	test: 0.446817

Epoch: 41
Loss: 0.1541778617393257
ROC train: 0.929918	val: 0.823293	test: 0.824231
PRC train: 0.681629	val: 0.438896	test: 0.437236

Epoch: 42
Loss: 0.15194494496260635
ROC train: 0.925315	val: 0.819384	test: 0.824962
PRC train: 0.667690	val: 0.434749	test: 0.439441

Epoch: 43
Loss: 0.15290999635968786
ROC train: 0.926968	val: 0.834645	test: 0.827946
PRC train: 0.672035	val: 0.455344	test: 0.442754

Epoch: 44
Loss: 0.15074487663134412
ROC train: 0.932937	val: 0.830375	test: 0.823622
PRC train: 0.690676	val: 0.442844	test: 0.453624

Epoch: 45
Loss: 0.14840496988327284
ROC train: 0.934186	val: 0.834859	test: 0.829150
PRC train: 0.705387	val: 0.454757	test: 0.443597

Epoch: 46
Loss: 0.14790577652817818
ROC train: 0.938517	val: 0.831324	test: 0.829136
PRC train: 0.713025	val: 0.449645	test: 0.451330

Epoch: 47
Loss: 0.14467271142001203
ROC train: 0.937076	val: 0.829976	test: 0.826042
PRC train: 0.701996	val: 0.453951	test: 0.423258

Epoch: 48
Loss: 0.14692266687554578
ROC train: 0.940416	val: 0.827678	test: 0.828444
PRC train: 0.716104	val: 0.450220	test: 0.455449

Epoch: 49
Loss: 0.1452021727795279
ROC train: 0.939924	val: 0.834605	test: 0.831403
PRC train: 0.721496	val: 0.455557	test: 0.452713

Epoch: 50
Loss: 0.14426979035395415
ROC train: 0.941936	val: 0.829488	test: 0.824769
PRC train: 0.724961	val: 0.462118	test: 0.442151

Epoch: 51
Loss: 0.14465952501759077
ROC train: 0.944515	val: 0.830612	test: 0.826070
PRC train: 0.735096	val: 0.459727	test: 0.439294

Epoch: 52
Loss: 0.14281968996948613
ROC train: 0.943874	val: 0.818995	test: 0.826363
PRC train: 0.724815	val: 0.439551	test: 0.445178

Epoch: 53
Loss: 0.14310687148024237
ROC train: 0.945125	val: 0.826344	test: 0.819561
PRC train: 0.729806	val: 0.453956	test: 0.435186

Epoch: 54
Loss: 0.1421273311976088
ROC train: 0.947227	val: 0.827277	test: 0.820985
PRC train: 0.736513	val: 0.457204	test: 0.437183

Epoch: 55
Loss: 0.13849633406737358
ROC train: 0.948143	val: 0.828628	test: 0.829310
PRC train: 0.745399	val: 0.449825	test: 0.450557

Epoch: 56
Loss: 0.13808509570389355
ROC train: 0.948323	val: 0.827652	test: 0.825036
PRC train: 0.742880	val: 0.438440	test: 0.440991

Epoch: 57
Loss: 0.13838267099997947
ROC train: 0.949930	val: 0.826189	test: 0.827492
PRC train: 0.751284	val: 0.450541	test: 0.446053

Epoch: 58
Loss: 0.13709911972112565
ROC train: 0.952049	val: 0.829518	test: 0.823273
PRC train: 0.752257	val: 0.440672	test: 0.449061

Epoch: 59
Loss: 0.13700764237571714
ROC train: 0.953764	val: 0.826753	test: 0.826425
PRC train: 0.764663	val: 0.457025	test: 0.438143

Epoch: 60
Loss: 0.13708823210871351
ROC train: 0.953389	val: 0.833347	test: 0.829784
PRC train: 0.763551	val: 0.458553	test: 0.450132

Epoch: 61
Loss: 0.13553599151078732
ROC train: 0.956173	val: 0.830097	test: 0.823623
PRC train: 0.774697	val: 0.458581	test: 0.450200

Epoch: 62
Loss: 0.13611867209902445
ROC train: 0.955268	val: 0.829370	test: 0.830241
PRC train: 0.769076	val: 0.439351	test: 0.445396

Epoch: 63
Loss: 0.13393982787814426
ROC train: 0.958282	val: 0.831921	test: 0.820843
PRC train: 0.784780	val: 0.459120	test: 0.440271

Epoch: 64
Loss: 0.1338399116146792
ROC train: 0.954304	val: 0.830782	test: 0.825370
PRC train: 0.763693	val: 0.445471	test: 0.454190

Epoch: 65
Loss: 0.13377628935583033
ROC train: 0.958282	val: 0.839493	test: 0.822768
PRC train: 0.776291	val: 0.445561	test: 0.441774

Epoch: 66
Loss: 0.13409040842724954
ROC train: 0.960400	val: 0.834598	test: 0.830006
PRC train: 0.788286	val: 0.466477	test: 0.454380

Epoch: 67
Loss: 0.13118254711166538
ROC train: 0.960956	val: 0.830168	test: 0.832736
PRC train: 0.792044	val: 0.455333	test: 0.459603

Epoch: 68
Loss: 0.12954255393716477
ROC train: 0.962337	val: 0.830820	test: 0.825371
PRC train: 0.786689	val: 0.454750	test: 0.444490

Epoch: 69
Loss: 0.13027462811668947
ROC train: 0.962965	val: 0.834868	test: 0.825355
PRC train: 0.801467	val: 0.457317	test: 0.452446

Epoch: 70
Loss: 0.12779387171839807
ROC train: 0.964191	val: 0.834470	test: 0.826739
PRC train: 0.801224	val: 0.452049	test: 0.457177

Epoch: 71
Loss: 0.12876016539740637
ROC train: 0.965557	val: 0.831724	test: 0.824912
PRC train: 0.807755	val: 0.461114	test: 0.445332

Epoch: 72
Loss: 0.12726543905223228
ROC train: 0.965169	val: 0.829580	test: 0.822783
PRC train: 0.804760	val: 0.467211	test: 0.450968

Epoch: 73
Loss: 0.12603694435226875
ROC train: 0.965801	val: 0.822148	test: 0.822061
PRC train: 0.811865	val: 0.455714	test: 0.445878

Epoch: 74
Loss: 0.12817207894824947
ROC train: 0.966367	val: 0.832295	test: 0.828387
PRC train: 0.815162	val: 0.454921	test: 0.460681

Epoch: 75
Loss: 0.12500924188834783
ROC train: 0.965495	val: 0.832688	test: 0.819387
PRC train: 0.802350	val: 0.464237	test: 0.454285

Epoch: 76
Loss: 0.12499481266491799
ROC train: 0.969044	val: 0.834269	test: 0.822657
PRC train: 0.820299	val: 0.460979	test: 0.453573

Epoch: 77
Loss: 0.12377907444406538
ROC train: 0.970000	val: 0.830831	test: 0.824427
PRC train: 0.830150	val: 0.459523	test: 0.459084

Epoch: 78
Loss: 0.12253897493072817
ROC train: 0.969154	val: 0.836810	test: 0.819674
PRC train: 0.823725	val: 0.468627	test: 0.453193

Epoch: 79
Loss: 0.12155790709082236
ROC train: 0.968810	val: 0.837836	test: 0.817026
PRC train: 0.822749	val: 0.456086	test: 0.447465

Epoch: 80
Loss: 0.12034628996034061
ROC train: 0.971035	val: 0.829395	test: 0.817529
PRC train: 0.833515	val: 0.467519	test: 0.440633

Epoch: 81
Loss: 0.11990427207948721
ROC train: 0.971524	val: 0.831126	test: 0.814679
PRC train: 0.833612	val: 0.470584	test: 0.437347

Epoch: 82
Loss: 0.11996552167145111
ROC train: 0.972088	val: 0.824822	test: 0.818335
PRC train: 0.839235	val: 0.462593	test: 0.446057

Epoch: 83
Loss: 0.11813887348296982
ROC train: 0.973709	val: 0.830501	test: 0.822282
PRC train: 0.845799	val: 0.467713	test: 0.453380

Epoch: 84
Loss: 0.11714529553483516
ROC train: 0.972425	val: 0.821525	test: 0.816401
PRC train: 0.838422	val: 0.462396	test: 0.454614

Epoch: 85
Loss: 0.11748791109436563
ROC train: 0.973433	val: 0.825873	test: 0.820486
PRC train: 0.839719	val: 0.450641	test: 0.452040

Epoch: 86
Loss: 0.1149237031976083
ROC train: 0.974756	val: 0.830539	test: 0.816258
PRC train: 0.846197	val: 0.460091	test: 0.451315

Epoch: 87
Loss: 0.11743372432668243
ROC train: 0.975633	val: 0.829482	test: 0.816696
PRC train: 0.850046	val: 0.461898	test: 0.449632

Epoch: 88
Loss: 0.11699629758938089
ROC train: 0.975065	val: 0.825312	test: 0.818890
PRC train: 0.851273	val: 0.471252	test: 0.459292

Epoch: 89
Loss: 0.11673736592519815
ROC train: 0.976647	val: 0.828616	test: 0.818605
PRC train: 0.858051	val: 0.467513	test: 0.445337

Epoch: 90
Loss: 0.1175215757846996
ROC train: 0.973339	val: 0.822811	test: 0.803325
PRC train: 0.836741	val: 0.462812	test: 0.400689

Epoch: 91
Loss: 0.11671654450838918
ROC train: 0.976136	val: 0.823820	test: 0.815108
PRC train: 0.853274	val: 0.464558	test: 0.435695

Epoch: 92
Loss: 0.11504759737704466
ROC train: 0.977504	val: 0.824021	test: 0.811446
PRC train: 0.861484	val: 0.472567	test: 0.450214

Epoch: 93
Loss: 0.11189501982572635
ROC train: 0.979453	val: 0.816048	test: 0.811287
PRC train: 0.871497	val: 0.466120	test: 0.458614

Epoch: 94
Loss: 0.11246402119721996
ROC train: 0.914407	val: 0.820796	test: 0.834275
PRC train: 0.633706	val: 0.463868	test: 0.417435

Epoch: 34
Loss: 0.16038898690698794
ROC train: 0.910756	val: 0.819263	test: 0.829017
PRC train: 0.612752	val: 0.458579	test: 0.419018

Epoch: 35
Loss: 0.1604228308860141
ROC train: 0.918137	val: 0.825491	test: 0.833145
PRC train: 0.641853	val: 0.470169	test: 0.428973

Epoch: 36
Loss: 0.16003725630700713
ROC train: 0.921491	val: 0.826735	test: 0.829850
PRC train: 0.650007	val: 0.482342	test: 0.426114

Epoch: 37
Loss: 0.15944024448006328
ROC train: 0.923836	val: 0.821803	test: 0.830824
PRC train: 0.655229	val: 0.476930	test: 0.435268

Epoch: 38
Loss: 0.15758177912784946
ROC train: 0.923975	val: 0.829564	test: 0.831679
PRC train: 0.657901	val: 0.476554	test: 0.429338

Epoch: 39
Loss: 0.1576379461543499
ROC train: 0.926144	val: 0.819560	test: 0.830027
PRC train: 0.663185	val: 0.470847	test: 0.448886

Epoch: 40
Loss: 0.15595836428065876
ROC train: 0.923917	val: 0.827064	test: 0.840568
PRC train: 0.664853	val: 0.472430	test: 0.449658

Epoch: 41
Loss: 0.15380485337116323
ROC train: 0.923418	val: 0.822500	test: 0.822132
PRC train: 0.646061	val: 0.477547	test: 0.417666

Epoch: 42
Loss: 0.15483113655440447
ROC train: 0.927882	val: 0.820349	test: 0.830187
PRC train: 0.667162	val: 0.467866	test: 0.413225

Epoch: 43
Loss: 0.15458649119467704
ROC train: 0.931620	val: 0.825660	test: 0.825231
PRC train: 0.689316	val: 0.492745	test: 0.422544

Epoch: 44
Loss: 0.1530816549186366
ROC train: 0.931143	val: 0.830410	test: 0.834411
PRC train: 0.680326	val: 0.467824	test: 0.447210

Epoch: 45
Loss: 0.15137921588916015
ROC train: 0.931705	val: 0.822159	test: 0.823075
PRC train: 0.680491	val: 0.487964	test: 0.427411

Epoch: 46
Loss: 0.1522443826590133
ROC train: 0.937345	val: 0.831107	test: 0.824895
PRC train: 0.697451	val: 0.484208	test: 0.451153

Epoch: 47
Loss: 0.1514157574672576
ROC train: 0.933394	val: 0.820351	test: 0.822223
PRC train: 0.685370	val: 0.485923	test: 0.427409

Epoch: 48
Loss: 0.15060392926571423
ROC train: 0.938471	val: 0.829581	test: 0.824251
PRC train: 0.706787	val: 0.498618	test: 0.429412

Epoch: 49
Loss: 0.15049385678374352
ROC train: 0.941265	val: 0.820282	test: 0.828087
PRC train: 0.717362	val: 0.490275	test: 0.452570

Epoch: 50
Loss: 0.1484724228751177
ROC train: 0.940694	val: 0.826493	test: 0.817414
PRC train: 0.716026	val: 0.486453	test: 0.436463

Epoch: 51
Loss: 0.1460443958799759
ROC train: 0.941941	val: 0.820004	test: 0.830839
PRC train: 0.716966	val: 0.480437	test: 0.442442

Epoch: 52
Loss: 0.14379630474590446
ROC train: 0.942938	val: 0.826364	test: 0.829537
PRC train: 0.721583	val: 0.484260	test: 0.455928

Epoch: 53
Loss: 0.14346380074958323
ROC train: 0.944265	val: 0.830180	test: 0.823745
PRC train: 0.724541	val: 0.492041	test: 0.442988

Epoch: 54
Loss: 0.1436069773308529
ROC train: 0.946126	val: 0.822554	test: 0.830123
PRC train: 0.735171	val: 0.503957	test: 0.447035

Epoch: 55
Loss: 0.14280293835819752
ROC train: 0.944396	val: 0.826722	test: 0.829897
PRC train: 0.727662	val: 0.482882	test: 0.438982

Epoch: 56
Loss: 0.14246667398335475
ROC train: 0.949548	val: 0.831019	test: 0.830728
PRC train: 0.750461	val: 0.500333	test: 0.449169

Epoch: 57
Loss: 0.141246313579297
ROC train: 0.950159	val: 0.819244	test: 0.829920
PRC train: 0.751686	val: 0.501514	test: 0.450015

Epoch: 58
Loss: 0.14003693435912137
ROC train: 0.950040	val: 0.819006	test: 0.831269
PRC train: 0.745104	val: 0.500875	test: 0.451848

Epoch: 59
Loss: 0.13921151400121182
ROC train: 0.951635	val: 0.820908	test: 0.827623
PRC train: 0.751820	val: 0.491057	test: 0.442042

Epoch: 60
Loss: 0.14021235609010915
ROC train: 0.953643	val: 0.821001	test: 0.832654
PRC train: 0.762305	val: 0.473990	test: 0.448862

Epoch: 61
Loss: 0.1369494465385916
ROC train: 0.952413	val: 0.819234	test: 0.827523
PRC train: 0.759584	val: 0.491377	test: 0.449228

Epoch: 62
Loss: 0.13891074815139365
ROC train: 0.955853	val: 0.826209	test: 0.828178
PRC train: 0.769602	val: 0.490453	test: 0.453182

Epoch: 63
Loss: 0.13709253060034418
ROC train: 0.955411	val: 0.821086	test: 0.825113
PRC train: 0.770227	val: 0.487321	test: 0.447663

Epoch: 64
Loss: 0.13584947192676278
ROC train: 0.956101	val: 0.825600	test: 0.826869
PRC train: 0.774536	val: 0.508669	test: 0.444432

Epoch: 65
Loss: 0.13464876214751484
ROC train: 0.956938	val: 0.815000	test: 0.815020
PRC train: 0.773220	val: 0.497080	test: 0.458028

Epoch: 66
Loss: 0.13593997963372664
ROC train: 0.957357	val: 0.830834	test: 0.820306
PRC train: 0.777769	val: 0.506102	test: 0.437162

Epoch: 67
Loss: 0.13422878259179313
ROC train: 0.959432	val: 0.824644	test: 0.833648
PRC train: 0.785971	val: 0.489610	test: 0.455873

Epoch: 68
Loss: 0.13194979900635428
ROC train: 0.959190	val: 0.819203	test: 0.825820
PRC train: 0.782975	val: 0.493047	test: 0.449550

Epoch: 69
Loss: 0.1322885442419964
ROC train: 0.957550	val: 0.813854	test: 0.813220
PRC train: 0.779859	val: 0.489415	test: 0.433284

Epoch: 70
Loss: 0.13118030536019742
ROC train: 0.961525	val: 0.818858	test: 0.819921
PRC train: 0.791555	val: 0.495242	test: 0.452437

Epoch: 71
Loss: 0.13009420341184674
ROC train: 0.964486	val: 0.820033	test: 0.826943
PRC train: 0.807694	val: 0.495568	test: 0.460102

Epoch: 72
Loss: 0.12937054334847103
ROC train: 0.962975	val: 0.820451	test: 0.820758
PRC train: 0.794966	val: 0.502092	test: 0.440360

Epoch: 73
Loss: 0.1302160055970966
ROC train: 0.963485	val: 0.819049	test: 0.820439
PRC train: 0.797630	val: 0.503691	test: 0.443697

Epoch: 74
Loss: 0.1274111167821368
ROC train: 0.966016	val: 0.815081	test: 0.828019
PRC train: 0.807757	val: 0.472107	test: 0.441334

Epoch: 75
Loss: 0.12870244418441465
ROC train: 0.964649	val: 0.819979	test: 0.832236
PRC train: 0.799828	val: 0.476233	test: 0.449340

Epoch: 76
Loss: 0.12749015253857848
ROC train: 0.965986	val: 0.820933	test: 0.832007
PRC train: 0.813082	val: 0.493055	test: 0.460827

Epoch: 77
Loss: 0.12635129448151802
ROC train: 0.965761	val: 0.820952	test: 0.824593
PRC train: 0.808493	val: 0.499170	test: 0.465875

Epoch: 78
Loss: 0.125750950017269
ROC train: 0.968279	val: 0.821909	test: 0.824810
PRC train: 0.819759	val: 0.479271	test: 0.454361

Epoch: 79
Loss: 0.12346807736205051
ROC train: 0.969319	val: 0.820446	test: 0.826617
PRC train: 0.825337	val: 0.504637	test: 0.480222

Epoch: 80
Loss: 0.12241881333289906
ROC train: 0.969390	val: 0.817490	test: 0.830982
PRC train: 0.827256	val: 0.486314	test: 0.466153

Epoch: 81
Loss: 0.12237128417881941
ROC train: 0.969656	val: 0.818477	test: 0.819399
PRC train: 0.828192	val: 0.499700	test: 0.460822

Epoch: 82
Loss: 0.12432265034981765
ROC train: 0.970211	val: 0.805184	test: 0.812282
PRC train: 0.823989	val: 0.503063	test: 0.458213

Epoch: 83
Loss: 0.12278244706251593
ROC train: 0.969624	val: 0.820953	test: 0.821589
PRC train: 0.824490	val: 0.492860	test: 0.454723

Epoch: 84
Loss: 0.12039525914249864
ROC train: 0.972332	val: 0.817975	test: 0.820602
PRC train: 0.837653	val: 0.499209	test: 0.458860

Epoch: 85
Loss: 0.1200092968695994
ROC train: 0.971394	val: 0.812072	test: 0.817060
PRC train: 0.830008	val: 0.493413	test: 0.462969

Epoch: 86
Loss: 0.12210506812363377
ROC train: 0.972153	val: 0.819249	test: 0.825539
PRC train: 0.839048	val: 0.499554	test: 0.473441

Epoch: 87
Loss: 0.11916013091255083
ROC train: 0.972130	val: 0.813016	test: 0.822620
PRC train: 0.834421	val: 0.465996	test: 0.459171

Epoch: 88
Loss: 0.11779208459008114
ROC train: 0.973618	val: 0.819713	test: 0.825314
PRC train: 0.849314	val: 0.502541	test: 0.469639

Epoch: 89
Loss: 0.11728971558921034
ROC train: 0.974470	val: 0.819822	test: 0.817022
PRC train: 0.846919	val: 0.493899	test: 0.445723

Epoch: 90
Loss: 0.11590470862695408
ROC train: 0.975668	val: 0.817407	test: 0.812734
PRC train: 0.852416	val: 0.495005	test: 0.442289

Epoch: 91
Loss: 0.11534285104268069
ROC train: 0.976333	val: 0.814104	test: 0.822883
PRC train: 0.855092	val: 0.497169	test: 0.460963

Epoch: 92
Loss: 0.1182224026917198
ROC train: 0.975288	val: 0.816540	test: 0.819489
PRC train: 0.851290	val: 0.496668	test: 0.450046

Epoch: 93
Loss: 0.11648635306639267
ROC train: 0.977272	val: 0.820558	test: 0.818864
PRC train: 0.862188	val: 0.501551	test: 0.454442

Epoch: 94
Loss: 0.11178706155117103
ROC train: 0.915012	val: 0.828287	test: 0.834251
PRC train: 0.638766	val: 0.489148	test: 0.412502

Epoch: 34
Loss: 0.16097018053584494
ROC train: 0.918586	val: 0.823763	test: 0.827972
PRC train: 0.645973	val: 0.476418	test: 0.410461

Epoch: 35
Loss: 0.15778413923439077
ROC train: 0.920076	val: 0.826356	test: 0.830505
PRC train: 0.651486	val: 0.484694	test: 0.415370

Epoch: 36
Loss: 0.1572992513389702
ROC train: 0.922719	val: 0.822635	test: 0.823138
PRC train: 0.644912	val: 0.486542	test: 0.417170

Epoch: 37
Loss: 0.15711283446895696
ROC train: 0.925491	val: 0.823544	test: 0.836164
PRC train: 0.660436	val: 0.492707	test: 0.426854

Epoch: 38
Loss: 0.15625770152966095
ROC train: 0.924947	val: 0.823390	test: 0.829969
PRC train: 0.664606	val: 0.498967	test: 0.416002

Epoch: 39
Loss: 0.15523194612261895
ROC train: 0.928340	val: 0.827024	test: 0.840096
PRC train: 0.677560	val: 0.501330	test: 0.453718

Epoch: 40
Loss: 0.1526902418854421
ROC train: 0.927718	val: 0.817974	test: 0.839675
PRC train: 0.673831	val: 0.494067	test: 0.455627

Epoch: 41
Loss: 0.15476896169477433
ROC train: 0.926544	val: 0.822807	test: 0.831415
PRC train: 0.660070	val: 0.482728	test: 0.429016

Epoch: 42
Loss: 0.15186591263333932
ROC train: 0.932329	val: 0.826489	test: 0.837156
PRC train: 0.689859	val: 0.497287	test: 0.450557

Epoch: 43
Loss: 0.15239453795492874
ROC train: 0.933571	val: 0.828724	test: 0.835101
PRC train: 0.693846	val: 0.493763	test: 0.456283

Epoch: 44
Loss: 0.15110729586965552
ROC train: 0.936463	val: 0.826573	test: 0.834246
PRC train: 0.699976	val: 0.499902	test: 0.458169

Epoch: 45
Loss: 0.1499884756255586
ROC train: 0.936909	val: 0.820086	test: 0.831989
PRC train: 0.699546	val: 0.477939	test: 0.438250

Epoch: 46
Loss: 0.1491417480871608
ROC train: 0.937768	val: 0.821897	test: 0.835919
PRC train: 0.697933	val: 0.487507	test: 0.444011

Epoch: 47
Loss: 0.1488811325627257
ROC train: 0.940796	val: 0.823437	test: 0.831274
PRC train: 0.712154	val: 0.501177	test: 0.461084

Epoch: 48
Loss: 0.1466878149201481
ROC train: 0.940714	val: 0.825542	test: 0.831180
PRC train: 0.713190	val: 0.502121	test: 0.466338

Epoch: 49
Loss: 0.14586800368988195
ROC train: 0.942034	val: 0.823597	test: 0.827657
PRC train: 0.722156	val: 0.493609	test: 0.452052

Epoch: 50
Loss: 0.14502187796595062
ROC train: 0.943525	val: 0.825737	test: 0.830793
PRC train: 0.726250	val: 0.506061	test: 0.460507

Epoch: 51
Loss: 0.14565068536157033
ROC train: 0.945201	val: 0.827013	test: 0.828341
PRC train: 0.719830	val: 0.510384	test: 0.431439

Epoch: 52
Loss: 0.14553251801467051
ROC train: 0.943787	val: 0.825757	test: 0.829185
PRC train: 0.726209	val: 0.489905	test: 0.440763

Epoch: 53
Loss: 0.14328965694159737
ROC train: 0.948338	val: 0.823401	test: 0.827735
PRC train: 0.742666	val: 0.502781	test: 0.433538

Epoch: 54
Loss: 0.14183569996761589
ROC train: 0.947444	val: 0.831022	test: 0.827033
PRC train: 0.739738	val: 0.508041	test: 0.448405

Epoch: 55
Loss: 0.1423643649363133
ROC train: 0.949676	val: 0.825871	test: 0.830320
PRC train: 0.749293	val: 0.503268	test: 0.431551

Epoch: 56
Loss: 0.14044517283074986
ROC train: 0.949123	val: 0.827069	test: 0.826772
PRC train: 0.737227	val: 0.492634	test: 0.427897

Epoch: 57
Loss: 0.1404359541437742
ROC train: 0.951093	val: 0.823304	test: 0.830143
PRC train: 0.752387	val: 0.486719	test: 0.453041

Epoch: 58
Loss: 0.13768395162141153
ROC train: 0.951928	val: 0.826264	test: 0.831248
PRC train: 0.751039	val: 0.491965	test: 0.447256

Epoch: 59
Loss: 0.13905488660475335
ROC train: 0.951711	val: 0.818565	test: 0.831007
PRC train: 0.754258	val: 0.488240	test: 0.467523

Epoch: 60
Loss: 0.13822759217755526
ROC train: 0.952708	val: 0.827094	test: 0.825150
PRC train: 0.757011	val: 0.491784	test: 0.423639

Epoch: 61
Loss: 0.13809991382393866
ROC train: 0.950613	val: 0.822735	test: 0.820931
PRC train: 0.754390	val: 0.488038	test: 0.445329

Epoch: 62
Loss: 0.13796792312104966
ROC train: 0.956162	val: 0.815027	test: 0.831076
PRC train: 0.774177	val: 0.487325	test: 0.459041

Epoch: 63
Loss: 0.13451717659658008
ROC train: 0.957864	val: 0.822103	test: 0.824727
PRC train: 0.782808	val: 0.494296	test: 0.460597

Epoch: 64
Loss: 0.1336051041559317
ROC train: 0.957731	val: 0.825144	test: 0.827846
PRC train: 0.781125	val: 0.490388	test: 0.457475

Epoch: 65
Loss: 0.1352285759795418
ROC train: 0.958044	val: 0.826526	test: 0.826397
PRC train: 0.781964	val: 0.495368	test: 0.449129

Epoch: 66
Loss: 0.13184080562613942
ROC train: 0.960435	val: 0.821317	test: 0.823064
PRC train: 0.792062	val: 0.503815	test: 0.473830

Epoch: 67
Loss: 0.13041146322410696
ROC train: 0.960705	val: 0.829714	test: 0.827746
PRC train: 0.796494	val: 0.502702	test: 0.461457

Epoch: 68
Loss: 0.13126326040010589
ROC train: 0.960861	val: 0.822672	test: 0.829354
PRC train: 0.790888	val: 0.495385	test: 0.457949

Epoch: 69
Loss: 0.1275099841550168
ROC train: 0.963240	val: 0.824998	test: 0.824364
PRC train: 0.805965	val: 0.488867	test: 0.467054

Epoch: 70
Loss: 0.1280788254023156
ROC train: 0.964684	val: 0.822810	test: 0.818297
PRC train: 0.804870	val: 0.492542	test: 0.448510

Epoch: 71
Loss: 0.1292906481597721
ROC train: 0.963385	val: 0.821310	test: 0.822729
PRC train: 0.804247	val: 0.488401	test: 0.447285

Epoch: 72
Loss: 0.13106057986148228
ROC train: 0.964808	val: 0.824014	test: 0.817764
PRC train: 0.808265	val: 0.491545	test: 0.453316

Epoch: 73
Loss: 0.12712522708804552
ROC train: 0.965326	val: 0.818036	test: 0.831154
PRC train: 0.816773	val: 0.499016	test: 0.453256

Epoch: 74
Loss: 0.12647521629740907
ROC train: 0.963576	val: 0.821853	test: 0.828105
PRC train: 0.803927	val: 0.498942	test: 0.443499

Epoch: 75
Loss: 0.12676328265358236
ROC train: 0.967567	val: 0.817265	test: 0.824365
PRC train: 0.819534	val: 0.491684	test: 0.441550

Epoch: 76
Loss: 0.12315219302936443
ROC train: 0.967080	val: 0.816022	test: 0.823884
PRC train: 0.820110	val: 0.490488	test: 0.457757

Epoch: 77
Loss: 0.12506733260938432
ROC train: 0.968859	val: 0.821012	test: 0.828887
PRC train: 0.830260	val: 0.494128	test: 0.452964

Epoch: 78
Loss: 0.12325554932606698
ROC train: 0.969745	val: 0.821103	test: 0.833274
PRC train: 0.828861	val: 0.502230	test: 0.466118

Epoch: 79
Loss: 0.1248942033333099
ROC train: 0.971032	val: 0.820143	test: 0.818374
PRC train: 0.838801	val: 0.510852	test: 0.452268

Epoch: 80
Loss: 0.12227519077145727
ROC train: 0.968978	val: 0.818053	test: 0.827299
PRC train: 0.822464	val: 0.485677	test: 0.456418

Epoch: 81
Loss: 0.12209453681131102
ROC train: 0.971953	val: 0.816285	test: 0.826314
PRC train: 0.842254	val: 0.501072	test: 0.454274

Epoch: 82
Loss: 0.12174986628540387
ROC train: 0.971642	val: 0.819562	test: 0.819080
PRC train: 0.843657	val: 0.500946	test: 0.461030

Epoch: 83
Loss: 0.12175453690724199
ROC train: 0.971201	val: 0.821198	test: 0.818210
PRC train: 0.836249	val: 0.489101	test: 0.443417

Epoch: 84
Loss: 0.12107176763596644
ROC train: 0.974107	val: 0.825876	test: 0.824586
PRC train: 0.848699	val: 0.509465	test: 0.468203

Epoch: 85
Loss: 0.11958346057752968
ROC train: 0.973303	val: 0.822851	test: 0.819038
PRC train: 0.846239	val: 0.507865	test: 0.454634

Epoch: 86
Loss: 0.11892947151231482
ROC train: 0.973955	val: 0.828072	test: 0.825007
PRC train: 0.849585	val: 0.496389	test: 0.469887

Epoch: 87
Loss: 0.11679716572773689
ROC train: 0.975335	val: 0.816498	test: 0.817359
PRC train: 0.855952	val: 0.495698	test: 0.469353

Epoch: 88
Loss: 0.11582122807181264
ROC train: 0.976227	val: 0.825958	test: 0.821666
PRC train: 0.861026	val: 0.500653	test: 0.469599

Epoch: 89
Loss: 0.11619104937628036
ROC train: 0.974752	val: 0.823550	test: 0.821938
PRC train: 0.849018	val: 0.506830	test: 0.454117

Epoch: 90
Loss: 0.11555499063313404
ROC train: 0.976656	val: 0.820687	test: 0.816349
PRC train: 0.862678	val: 0.504072	test: 0.467807

Epoch: 91
Loss: 0.11295244741976332
ROC train: 0.976598	val: 0.816939	test: 0.821490
PRC train: 0.863367	val: 0.491218	test: 0.472435

Epoch: 92
Loss: 0.11450122772714347
ROC train: 0.978331	val: 0.815428	test: 0.821476
PRC train: 0.870961	val: 0.488878	test: 0.467186

Epoch: 93
Loss: 0.11521331686761754
ROC train: 0.977191	val: 0.817452	test: 0.811375
PRC train: 0.860948	val: 0.486087	test: 0.454816

Epoch: 94
Loss: 0.11149932569597136
ROC train: 0.911960	val: 0.828936	test: 0.832040
PRC train: 0.629045	val: 0.467460	test: 0.421889

Epoch: 34
Loss: 0.16233382428348442
ROC train: 0.912549	val: 0.824343	test: 0.827175
PRC train: 0.633347	val: 0.474357	test: 0.427412

Epoch: 35
Loss: 0.16113607576813865
ROC train: 0.916880	val: 0.833930	test: 0.824054
PRC train: 0.639401	val: 0.483275	test: 0.423445

Epoch: 36
Loss: 0.15858996586662125
ROC train: 0.919545	val: 0.828810	test: 0.835484
PRC train: 0.640396	val: 0.475657	test: 0.419670

Epoch: 37
Loss: 0.15954496623327596
ROC train: 0.921780	val: 0.831892	test: 0.834887
PRC train: 0.649144	val: 0.472574	test: 0.422890

Epoch: 38
Loss: 0.15659544993330243
ROC train: 0.923197	val: 0.835255	test: 0.831960
PRC train: 0.659415	val: 0.490770	test: 0.428517

Epoch: 39
Loss: 0.15538106525693715
ROC train: 0.924575	val: 0.825833	test: 0.827755
PRC train: 0.668880	val: 0.470574	test: 0.404363

Epoch: 40
Loss: 0.1548597425652839
ROC train: 0.928116	val: 0.825811	test: 0.825196
PRC train: 0.679032	val: 0.489412	test: 0.417580

Epoch: 41
Loss: 0.1540912496570962
ROC train: 0.927491	val: 0.828212	test: 0.826994
PRC train: 0.668996	val: 0.479620	test: 0.416050

Epoch: 42
Loss: 0.1521885424486281
ROC train: 0.928114	val: 0.824580	test: 0.825036
PRC train: 0.669511	val: 0.487808	test: 0.427295

Epoch: 43
Loss: 0.1533835566312613
ROC train: 0.932961	val: 0.826838	test: 0.830692
PRC train: 0.688526	val: 0.494976	test: 0.418853

Epoch: 44
Loss: 0.15187942794272646
ROC train: 0.932944	val: 0.820695	test: 0.831552
PRC train: 0.689720	val: 0.491892	test: 0.442034

Epoch: 45
Loss: 0.15008178370580294
ROC train: 0.935721	val: 0.825562	test: 0.829062
PRC train: 0.700726	val: 0.481985	test: 0.447952

Epoch: 46
Loss: 0.15041043509417448
ROC train: 0.934156	val: 0.824260	test: 0.816344
PRC train: 0.690533	val: 0.476995	test: 0.414043

Epoch: 47
Loss: 0.15132998120187444
ROC train: 0.936578	val: 0.819047	test: 0.823801
PRC train: 0.705489	val: 0.487689	test: 0.423169

Epoch: 48
Loss: 0.14970133152378745
ROC train: 0.938984	val: 0.827317	test: 0.814905
PRC train: 0.702050	val: 0.491408	test: 0.410198

Epoch: 49
Loss: 0.14775550565349604
ROC train: 0.939726	val: 0.829704	test: 0.823140
PRC train: 0.711898	val: 0.494936	test: 0.430622

Epoch: 50
Loss: 0.14803077342618734
ROC train: 0.941740	val: 0.827987	test: 0.827121
PRC train: 0.719139	val: 0.503759	test: 0.450365

Epoch: 51
Loss: 0.14592772878739046
ROC train: 0.941713	val: 0.823278	test: 0.825928
PRC train: 0.717898	val: 0.489247	test: 0.432746

Epoch: 52
Loss: 0.1448911933445757
ROC train: 0.943806	val: 0.822412	test: 0.829857
PRC train: 0.723559	val: 0.494987	test: 0.440107

Epoch: 53
Loss: 0.14311452799952407
ROC train: 0.944302	val: 0.822667	test: 0.824266
PRC train: 0.720250	val: 0.488681	test: 0.423900

Epoch: 54
Loss: 0.14170997164466287
ROC train: 0.945763	val: 0.829155	test: 0.832847
PRC train: 0.737738	val: 0.509078	test: 0.445615

Epoch: 55
Loss: 0.14331479174911274
ROC train: 0.947982	val: 0.823926	test: 0.826511
PRC train: 0.739521	val: 0.496507	test: 0.435540

Epoch: 56
Loss: 0.14192130822882462
ROC train: 0.946087	val: 0.823452	test: 0.820844
PRC train: 0.730652	val: 0.501767	test: 0.432279

Epoch: 57
Loss: 0.1420252692493063
ROC train: 0.948525	val: 0.818884	test: 0.825738
PRC train: 0.743311	val: 0.501817	test: 0.426706

Epoch: 58
Loss: 0.140645579272652
ROC train: 0.948159	val: 0.818660	test: 0.827898
PRC train: 0.735569	val: 0.488790	test: 0.428435

Epoch: 59
Loss: 0.13875626586825837
ROC train: 0.951563	val: 0.822546	test: 0.826529
PRC train: 0.757157	val: 0.509334	test: 0.426707

Epoch: 60
Loss: 0.13803208642735876
ROC train: 0.954237	val: 0.821630	test: 0.826168
PRC train: 0.761782	val: 0.501581	test: 0.439991

Epoch: 61
Loss: 0.13682361485309738
ROC train: 0.952870	val: 0.825401	test: 0.822139
PRC train: 0.765273	val: 0.506374	test: 0.442455

Epoch: 62
Loss: 0.1354363921975681
ROC train: 0.952781	val: 0.817419	test: 0.816151
PRC train: 0.757674	val: 0.501243	test: 0.429865

Epoch: 63
Loss: 0.1351358196227079
ROC train: 0.956524	val: 0.820190	test: 0.816699
PRC train: 0.776756	val: 0.505314	test: 0.444998

Epoch: 64
Loss: 0.1357165645566621
ROC train: 0.957757	val: 0.821930	test: 0.812394
PRC train: 0.780730	val: 0.502110	test: 0.437354

Epoch: 65
Loss: 0.13322971009370485
ROC train: 0.956882	val: 0.821126	test: 0.816381
PRC train: 0.774135	val: 0.494728	test: 0.430933

Epoch: 66
Loss: 0.1337971081987105
ROC train: 0.953861	val: 0.815401	test: 0.821316
PRC train: 0.754713	val: 0.492617	test: 0.436348

Epoch: 67
Loss: 0.13183298097048696
ROC train: 0.959563	val: 0.823952	test: 0.820220
PRC train: 0.788536	val: 0.512300	test: 0.458392

Epoch: 68
Loss: 0.12963332001657576
ROC train: 0.961439	val: 0.827978	test: 0.819261
PRC train: 0.793402	val: 0.501687	test: 0.446043

Epoch: 69
Loss: 0.13201304928248317
ROC train: 0.960149	val: 0.821428	test: 0.814848
PRC train: 0.791540	val: 0.490763	test: 0.425148

Epoch: 70
Loss: 0.12995522602534706
ROC train: 0.960588	val: 0.823692	test: 0.824095
PRC train: 0.793786	val: 0.508030	test: 0.436504

Epoch: 71
Loss: 0.12914542050121416
ROC train: 0.963461	val: 0.814068	test: 0.814993
PRC train: 0.800420	val: 0.497560	test: 0.444891

Epoch: 72
Loss: 0.12921181525838632
ROC train: 0.964939	val: 0.819054	test: 0.812601
PRC train: 0.803037	val: 0.507974	test: 0.429867

Epoch: 73
Loss: 0.12794071965557602
ROC train: 0.964824	val: 0.827258	test: 0.817189
PRC train: 0.807063	val: 0.499275	test: 0.427783

Epoch: 74
Loss: 0.12795801511826901
ROC train: 0.965285	val: 0.829582	test: 0.820007
PRC train: 0.810878	val: 0.520023	test: 0.442743

Epoch: 75
Loss: 0.12726700118158282
ROC train: 0.965084	val: 0.821416	test: 0.825417
PRC train: 0.808895	val: 0.510497	test: 0.465010

Epoch: 76
Loss: 0.12336033580242901
ROC train: 0.966649	val: 0.817442	test: 0.824626
PRC train: 0.815967	val: 0.503791	test: 0.440115

Epoch: 77
Loss: 0.12525160025769014
ROC train: 0.966338	val: 0.820478	test: 0.815721
PRC train: 0.818655	val: 0.507491	test: 0.440843

Epoch: 78
Loss: 0.12396001703763938
ROC train: 0.969661	val: 0.822614	test: 0.804352
PRC train: 0.827692	val: 0.514038	test: 0.438141

Epoch: 79
Loss: 0.12392113492344209
ROC train: 0.968854	val: 0.822884	test: 0.818022
PRC train: 0.823707	val: 0.504165	test: 0.437798

Epoch: 80
Loss: 0.12340680049532338
ROC train: 0.971197	val: 0.821808	test: 0.815832
PRC train: 0.834276	val: 0.514956	test: 0.460612

Epoch: 81
Loss: 0.121305645248716
ROC train: 0.970668	val: 0.819836	test: 0.814518
PRC train: 0.827437	val: 0.509505	test: 0.456571

Epoch: 82
Loss: 0.11915178003274736
ROC train: 0.970715	val: 0.819036	test: 0.814153
PRC train: 0.834443	val: 0.497755	test: 0.449278

Epoch: 83
Loss: 0.12110887038519891
ROC train: 0.970484	val: 0.820731	test: 0.810549
PRC train: 0.830236	val: 0.497855	test: 0.449052

Epoch: 84
Loss: 0.11990654778583877
ROC train: 0.973516	val: 0.822202	test: 0.809598
PRC train: 0.841293	val: 0.513400	test: 0.449350

Epoch: 85
Loss: 0.11787265004214788
ROC train: 0.973388	val: 0.812370	test: 0.808928
PRC train: 0.840836	val: 0.502533	test: 0.433656

Epoch: 86
Loss: 0.11888166588749204
ROC train: 0.974894	val: 0.815524	test: 0.808824
PRC train: 0.852289	val: 0.504181	test: 0.446722

Epoch: 87
Loss: 0.1178824770795518
ROC train: 0.974306	val: 0.815337	test: 0.803016
PRC train: 0.844015	val: 0.504409	test: 0.424921

Epoch: 88
Loss: 0.11841623231894387
ROC train: 0.975020	val: 0.813006	test: 0.809956
PRC train: 0.848883	val: 0.503331	test: 0.442556

Epoch: 89
Loss: 0.11722635699923262
ROC train: 0.974392	val: 0.812709	test: 0.810623
PRC train: 0.845550	val: 0.498273	test: 0.441686

Epoch: 90
Loss: 0.1148269865841982
ROC train: 0.975003	val: 0.809405	test: 0.813144
PRC train: 0.851424	val: 0.500768	test: 0.459551

Epoch: 91
Loss: 0.11513385727450878
ROC train: 0.977124	val: 0.817327	test: 0.815137
PRC train: 0.863027	val: 0.503014	test: 0.443904

Epoch: 92
Loss: 0.11387220534090485
ROC train: 0.977012	val: 0.820339	test: 0.813853
PRC train: 0.862354	val: 0.498573	test: 0.436584

Epoch: 93
Loss: 0.1153365674564589
ROC train: 0.977902	val: 0.817654	test: 0.818088
PRC train: 0.866472	val: 0.500882	test: 0.458739

Epoch: 94
Loss: 0.11434835130306836
ROC train: 0.978660	val: 0.825084	test: 0.800592
PRC train: 0.869428	val: 0.427660	test: 0.418232

Epoch: 95
Loss: 0.11339208909284573
ROC train: 0.979111	val: 0.827996	test: 0.795973
PRC train: 0.872286	val: 0.438560	test: 0.408462

Epoch: 96
Loss: 0.11380840904096445
ROC train: 0.979267	val: 0.825157	test: 0.794229
PRC train: 0.871133	val: 0.439567	test: 0.403282

Epoch: 97
Loss: 0.11165384241998959
ROC train: 0.976993	val: 0.830423	test: 0.794104
PRC train: 0.860913	val: 0.448444	test: 0.400718

Epoch: 98
Loss: 0.10903199990242936
ROC train: 0.981136	val: 0.822745	test: 0.800141
PRC train: 0.878622	val: 0.430797	test: 0.426059

Epoch: 99
Loss: 0.11142357779782139
ROC train: 0.981114	val: 0.829444	test: 0.802663
PRC train: 0.883021	val: 0.440132	test: 0.429112

Epoch: 100
Loss: 0.10984287435994919
ROC train: 0.981862	val: 0.824487	test: 0.802878
PRC train: 0.884642	val: 0.421969	test: 0.429008

Epoch: 101
Loss: 0.10805623528440109
ROC train: 0.982316	val: 0.820880	test: 0.799617
PRC train: 0.889576	val: 0.442978	test: 0.417816

Epoch: 102
Loss: 0.10938182440679656
ROC train: 0.981698	val: 0.824430	test: 0.795767
PRC train: 0.884159	val: 0.418982	test: 0.412454

Epoch: 103
Loss: 0.10773946973478232
ROC train: 0.982553	val: 0.820563	test: 0.801368
PRC train: 0.889146	val: 0.436028	test: 0.420560

Epoch: 104
Loss: 0.1066273001144388
ROC train: 0.982884	val: 0.827343	test: 0.796974
PRC train: 0.889336	val: 0.420943	test: 0.414402

Epoch: 105
Loss: 0.10826469606549721
ROC train: 0.983856	val: 0.819746	test: 0.791581
PRC train: 0.894125	val: 0.422701	test: 0.407649

Epoch: 106
Loss: 0.10374887859528523
ROC train: 0.983373	val: 0.827864	test: 0.799948
PRC train: 0.895728	val: 0.429571	test: 0.418529

Epoch: 107
Loss: 0.10464120248802626
ROC train: 0.985712	val: 0.822876	test: 0.795390
PRC train: 0.903291	val: 0.426742	test: 0.407806

Epoch: 108
Loss: 0.10298324341339055
ROC train: 0.985001	val: 0.823482	test: 0.795627
PRC train: 0.903604	val: 0.422218	test: 0.409951

Epoch: 109
Loss: 0.10516816385287646
ROC train: 0.985622	val: 0.815933	test: 0.788411
PRC train: 0.903813	val: 0.431535	test: 0.410499

Epoch: 110
Loss: 0.101828752423732
ROC train: 0.986107	val: 0.820291	test: 0.794824
PRC train: 0.908909	val: 0.428940	test: 0.412261

Epoch: 111
Loss: 0.10450393661280444
ROC train: 0.986276	val: 0.821013	test: 0.795700
PRC train: 0.907708	val: 0.421279	test: 0.398097

Epoch: 112
Loss: 0.10456399191055636
ROC train: 0.985617	val: 0.816152	test: 0.793811
PRC train: 0.902856	val: 0.404787	test: 0.400891

Epoch: 113
Loss: 0.10109169839446282
ROC train: 0.986366	val: 0.819216	test: 0.791628
PRC train: 0.910425	val: 0.408094	test: 0.398105

Epoch: 114
Loss: 0.10293226034098964
ROC train: 0.988067	val: 0.812968	test: 0.793611
PRC train: 0.918726	val: 0.432355	test: 0.412350

Epoch: 115
Loss: 0.10167418648912607
ROC train: 0.986874	val: 0.812934	test: 0.790143
PRC train: 0.910464	val: 0.418318	test: 0.401489

Epoch: 116
Loss: 0.10022953665383733
ROC train: 0.986586	val: 0.823134	test: 0.796234
PRC train: 0.908272	val: 0.448146	test: 0.401127

Epoch: 117
Loss: 0.10025013130310743
ROC train: 0.988296	val: 0.810114	test: 0.792264
PRC train: 0.916387	val: 0.415173	test: 0.408545

Epoch: 118
Loss: 0.0978140956076624
ROC train: 0.988890	val: 0.822313	test: 0.792332
PRC train: 0.923513	val: 0.431564	test: 0.404887

Epoch: 119
Loss: 0.09954034656397524
ROC train: 0.987499	val: 0.818021	test: 0.792123
PRC train: 0.911797	val: 0.424931	test: 0.402526

Epoch: 120
Loss: 0.0992689303962595
ROC train: 0.988640	val: 0.822942	test: 0.798087
PRC train: 0.923920	val: 0.450328	test: 0.424037

Early stopping
Best (ROC):	 train: 0.918287	val: 0.837479	test: 0.812732
Best (PRC):	 train: 0.652213	val: 0.442465	test: 0.415183

ROC train: 0.979209	val: 0.826125	test: 0.803435
PRC train: 0.872228	val: 0.449969	test: 0.446688

Epoch: 95
Loss: 0.11421370530043931
ROC train: 0.979615	val: 0.814052	test: 0.795559
PRC train: 0.871918	val: 0.435700	test: 0.439970

Epoch: 96
Loss: 0.11351131523229611
ROC train: 0.978654	val: 0.814967	test: 0.799501
PRC train: 0.871846	val: 0.420979	test: 0.434094

Epoch: 97
Loss: 0.11165740130413289
ROC train: 0.980060	val: 0.819935	test: 0.795057
PRC train: 0.869058	val: 0.446201	test: 0.413779

Epoch: 98
Loss: 0.11005367147385946
ROC train: 0.980888	val: 0.822264	test: 0.801839
PRC train: 0.883415	val: 0.448159	test: 0.432912

Epoch: 99
Loss: 0.10986408714340831
ROC train: 0.982027	val: 0.821266	test: 0.796012
PRC train: 0.886717	val: 0.454209	test: 0.435897

Epoch: 100
Loss: 0.10968469222031973
ROC train: 0.983033	val: 0.821812	test: 0.800158
PRC train: 0.890187	val: 0.454332	test: 0.435066

Epoch: 101
Loss: 0.10782602072326976
ROC train: 0.982627	val: 0.813486	test: 0.792683
PRC train: 0.888701	val: 0.414722	test: 0.418748

Epoch: 102
Loss: 0.11139679249633887
ROC train: 0.981068	val: 0.824771	test: 0.797315
PRC train: 0.881437	val: 0.429074	test: 0.424087

Epoch: 103
Loss: 0.10866374148985716
ROC train: 0.982486	val: 0.816741	test: 0.800945
PRC train: 0.889343	val: 0.428163	test: 0.435343

Epoch: 104
Loss: 0.10783760843607973
ROC train: 0.983109	val: 0.822440	test: 0.800356
PRC train: 0.893368	val: 0.438584	test: 0.424963

Epoch: 105
Loss: 0.1052621160646305
ROC train: 0.983620	val: 0.819651	test: 0.801027
PRC train: 0.895130	val: 0.427590	test: 0.429454

Epoch: 106
Loss: 0.10320877391896795
ROC train: 0.984161	val: 0.823221	test: 0.794585
PRC train: 0.898043	val: 0.448517	test: 0.427384

Epoch: 107
Loss: 0.1028237798479885
ROC train: 0.984645	val: 0.818191	test: 0.798076
PRC train: 0.900634	val: 0.446541	test: 0.431840

Epoch: 108
Loss: 0.10104982566477627
ROC train: 0.984548	val: 0.824497	test: 0.792758
PRC train: 0.895743	val: 0.451575	test: 0.428518

Epoch: 109
Loss: 0.10544175518347373
ROC train: 0.984330	val: 0.827019	test: 0.794978
PRC train: 0.899269	val: 0.456455	test: 0.430815

Epoch: 110
Loss: 0.10506102215952685
ROC train: 0.986274	val: 0.819191	test: 0.794637
PRC train: 0.907598	val: 0.444100	test: 0.435715

Epoch: 111
Loss: 0.10416511953065881
ROC train: 0.984771	val: 0.821247	test: 0.795815
PRC train: 0.899236	val: 0.454324	test: 0.432463

Epoch: 112
Loss: 0.10270437732187236
ROC train: 0.986438	val: 0.822913	test: 0.801307
PRC train: 0.909094	val: 0.443528	test: 0.439853

Epoch: 113
Loss: 0.10028963194791918
ROC train: 0.986810	val: 0.821645	test: 0.800403
PRC train: 0.912883	val: 0.451419	test: 0.444496

Epoch: 114
Loss: 0.09841473865955892
ROC train: 0.987767	val: 0.826521	test: 0.798292
PRC train: 0.919699	val: 0.450001	test: 0.437399

Epoch: 115
Loss: 0.09606729041570315
ROC train: 0.987455	val: 0.825633	test: 0.799416
PRC train: 0.915840	val: 0.448252	test: 0.431433

Epoch: 116
Loss: 0.09632434771177112
ROC train: 0.987800	val: 0.818377	test: 0.795690
PRC train: 0.917187	val: 0.434828	test: 0.434842

Epoch: 117
Loss: 0.0978330387557037
ROC train: 0.987090	val: 0.823510	test: 0.795960
PRC train: 0.913802	val: 0.428667	test: 0.422550

Epoch: 118
Loss: 0.10003280797157899
ROC train: 0.986578	val: 0.817162	test: 0.797871
PRC train: 0.911594	val: 0.441369	test: 0.437534

Epoch: 119
Loss: 0.09817081708972593
ROC train: 0.987956	val: 0.822562	test: 0.802994
PRC train: 0.918745	val: 0.435886	test: 0.429144

Epoch: 120
Loss: 0.09456756668536691
ROC train: 0.988987	val: 0.823913	test: 0.799032
PRC train: 0.925020	val: 0.441461	test: 0.431704

Early stopping
Best (ROC):	 train: 0.903607	val: 0.835559	test: 0.814693
Best (PRC):	 train: 0.593117	val: 0.416578	test: 0.406951

ROC train: 0.978981	val: 0.824975	test: 0.797444
PRC train: 0.869401	val: 0.442126	test: 0.431086

Epoch: 95
Loss: 0.11306938022549498
ROC train: 0.978638	val: 0.827376	test: 0.797938
PRC train: 0.868617	val: 0.458469	test: 0.437739

Epoch: 96
Loss: 0.11265095040652334
ROC train: 0.980677	val: 0.829734	test: 0.806794
PRC train: 0.882507	val: 0.442318	test: 0.441521

Epoch: 97
Loss: 0.10989567320993525
ROC train: 0.981101	val: 0.830212	test: 0.801083
PRC train: 0.886665	val: 0.438975	test: 0.439289

Epoch: 98
Loss: 0.1112137421630276
ROC train: 0.981689	val: 0.831238	test: 0.803677
PRC train: 0.889820	val: 0.444971	test: 0.442951

Epoch: 99
Loss: 0.10954616699461993
ROC train: 0.981919	val: 0.828398	test: 0.801576
PRC train: 0.889065	val: 0.433641	test: 0.433797

Epoch: 100
Loss: 0.11169055831353181
ROC train: 0.981905	val: 0.829465	test: 0.801022
PRC train: 0.887630	val: 0.448324	test: 0.424523

Epoch: 101
Loss: 0.10962527757931051
ROC train: 0.981760	val: 0.831653	test: 0.801706
PRC train: 0.886621	val: 0.454466	test: 0.436029

Epoch: 102
Loss: 0.10949295838797223
ROC train: 0.982904	val: 0.824952	test: 0.797479
PRC train: 0.893435	val: 0.443613	test: 0.435389

Epoch: 103
Loss: 0.10538483873818952
ROC train: 0.983413	val: 0.825578	test: 0.801803
PRC train: 0.897092	val: 0.457854	test: 0.439262

Epoch: 104
Loss: 0.10494367604811922
ROC train: 0.983750	val: 0.828294	test: 0.799023
PRC train: 0.898621	val: 0.450762	test: 0.437078

Epoch: 105
Loss: 0.10561555092295798
ROC train: 0.981474	val: 0.823084	test: 0.797347
PRC train: 0.886543	val: 0.443924	test: 0.421928

Epoch: 106
Loss: 0.1017429559814005
ROC train: 0.985215	val: 0.831158	test: 0.797119
PRC train: 0.908351	val: 0.439864	test: 0.425220

Epoch: 107
Loss: 0.10626164266175059
ROC train: 0.982575	val: 0.822219	test: 0.793159
PRC train: 0.888741	val: 0.453840	test: 0.419578

Epoch: 108
Loss: 0.10491567380840566
ROC train: 0.986085	val: 0.827926	test: 0.799010
PRC train: 0.910020	val: 0.453444	test: 0.436684

Epoch: 109
Loss: 0.10654039974838014
ROC train: 0.985154	val: 0.832321	test: 0.796982
PRC train: 0.905676	val: 0.458256	test: 0.426369

Epoch: 110
Loss: 0.10370531180876513
ROC train: 0.984187	val: 0.832227	test: 0.795837
PRC train: 0.899940	val: 0.444616	test: 0.428970

Epoch: 111
Loss: 0.10043744936340429
ROC train: 0.985861	val: 0.827238	test: 0.794869
PRC train: 0.908185	val: 0.455629	test: 0.433613

Epoch: 112
Loss: 0.10054480583751536
ROC train: 0.986738	val: 0.824360	test: 0.792932
PRC train: 0.915040	val: 0.443650	test: 0.420296

Epoch: 113
Loss: 0.09977140158160397
ROC train: 0.986408	val: 0.823203	test: 0.791876
PRC train: 0.910769	val: 0.448351	test: 0.431312

Epoch: 114
Loss: 0.09862252572263282
ROC train: 0.986496	val: 0.822973	test: 0.793690
PRC train: 0.911411	val: 0.450306	test: 0.437180

Epoch: 115
Loss: 0.09775449315156269
ROC train: 0.987042	val: 0.821553	test: 0.797888
PRC train: 0.912887	val: 0.437573	test: 0.416712

Epoch: 116
Loss: 0.09794324922716448
ROC train: 0.987900	val: 0.820355	test: 0.790441
PRC train: 0.919501	val: 0.444633	test: 0.425940

Epoch: 117
Loss: 0.09802603449651386
ROC train: 0.987921	val: 0.826783	test: 0.797932
PRC train: 0.921057	val: 0.436079	test: 0.432483

Epoch: 118
Loss: 0.09567278345191728
ROC train: 0.987610	val: 0.822307	test: 0.786718
PRC train: 0.917171	val: 0.451638	test: 0.418489

Epoch: 119
Loss: 0.09775286855544968
ROC train: 0.987452	val: 0.825757	test: 0.792292
PRC train: 0.918248	val: 0.447922	test: 0.425741

Epoch: 120
Loss: 0.098525887101288
ROC train: 0.988505	val: 0.824471	test: 0.791976
PRC train: 0.922080	val: 0.449045	test: 0.425374

Early stopping
Best (ROC):	 train: 0.935031	val: 0.841137	test: 0.820854
Best (PRC):	 train: 0.700135	val: 0.448770	test: 0.439352
All runs completed.

ROC train: 0.976533	val: 0.821921	test: 0.816168
PRC train: 0.859493	val: 0.447104	test: 0.472369

Epoch: 95
Loss: 0.11191343520112121
ROC train: 0.978069	val: 0.820360	test: 0.815111
PRC train: 0.864026	val: 0.455006	test: 0.468402

Epoch: 96
Loss: 0.11174219672450786
ROC train: 0.979321	val: 0.814409	test: 0.815143
PRC train: 0.872153	val: 0.439966	test: 0.477107

Epoch: 97
Loss: 0.11109407458734642
ROC train: 0.978553	val: 0.821347	test: 0.812896
PRC train: 0.862652	val: 0.447668	test: 0.470832

Epoch: 98
Loss: 0.10976716719677748
ROC train: 0.979492	val: 0.821957	test: 0.809776
PRC train: 0.871815	val: 0.439537	test: 0.476630

Epoch: 99
Loss: 0.11023321499229434
ROC train: 0.980008	val: 0.815832	test: 0.810416
PRC train: 0.876225	val: 0.456119	test: 0.478098

Epoch: 100
Loss: 0.10979951702926981
ROC train: 0.980891	val: 0.814581	test: 0.812076
PRC train: 0.877308	val: 0.450067	test: 0.483382

Epoch: 101
Loss: 0.10875455166646356
ROC train: 0.980065	val: 0.819106	test: 0.818948
PRC train: 0.878096	val: 0.447154	test: 0.474593

Epoch: 102
Loss: 0.10819797992958903
ROC train: 0.981947	val: 0.814121	test: 0.815254
PRC train: 0.884693	val: 0.449919	test: 0.471289

Epoch: 103
Loss: 0.10589232765462725
ROC train: 0.982090	val: 0.814384	test: 0.808953
PRC train: 0.885092	val: 0.444203	test: 0.470432

Epoch: 104
Loss: 0.103616413530509
ROC train: 0.982693	val: 0.819535	test: 0.818817
PRC train: 0.892100	val: 0.434560	test: 0.479412

Epoch: 105
Loss: 0.10509374573085774
ROC train: 0.983453	val: 0.818290	test: 0.813284
PRC train: 0.894083	val: 0.443164	test: 0.479882

Epoch: 106
Loss: 0.1031649193412209
ROC train: 0.983034	val: 0.810863	test: 0.810583
PRC train: 0.888890	val: 0.449733	test: 0.480071

Epoch: 107
Loss: 0.10328688017463684
ROC train: 0.984795	val: 0.813266	test: 0.809457
PRC train: 0.897946	val: 0.442937	test: 0.470655

Epoch: 108
Loss: 0.10610465684746338
ROC train: 0.984068	val: 0.819540	test: 0.811841
PRC train: 0.895362	val: 0.448263	test: 0.473951

Epoch: 109
Loss: 0.10308509177219945
ROC train: 0.984330	val: 0.814275	test: 0.814875
PRC train: 0.895937	val: 0.444966	test: 0.487056

Epoch: 110
Loss: 0.1037153779270191
ROC train: 0.983656	val: 0.812453	test: 0.811286
PRC train: 0.894478	val: 0.444121	test: 0.475721

Epoch: 111
Loss: 0.10312290332980022
ROC train: 0.984324	val: 0.813107	test: 0.804133
PRC train: 0.895822	val: 0.438448	test: 0.469416

Epoch: 112
Loss: 0.10151922116303623
ROC train: 0.986119	val: 0.813046	test: 0.810040
PRC train: 0.906173	val: 0.438405	test: 0.477485

Epoch: 113
Loss: 0.1000916377192646
ROC train: 0.984829	val: 0.814090	test: 0.806742
PRC train: 0.899823	val: 0.458663	test: 0.477780

Epoch: 114
Loss: 0.10020186019981252
ROC train: 0.986636	val: 0.814397	test: 0.813574
PRC train: 0.910376	val: 0.446759	test: 0.477784

Epoch: 115
Loss: 0.10157235790359116
ROC train: 0.986649	val: 0.814074	test: 0.808569
PRC train: 0.910400	val: 0.451448	test: 0.479353

Epoch: 116
Loss: 0.10031668215957668
ROC train: 0.986052	val: 0.814327	test: 0.812406
PRC train: 0.906653	val: 0.447501	test: 0.480488

Epoch: 117
Loss: 0.0994788153840279
ROC train: 0.987322	val: 0.818508	test: 0.806119
PRC train: 0.913688	val: 0.442979	test: 0.468528

Epoch: 118
Loss: 0.0991779197129
ROC train: 0.986386	val: 0.814847	test: 0.805144
PRC train: 0.905370	val: 0.429024	test: 0.468553

Epoch: 119
Loss: 0.10008115182051319
ROC train: 0.986543	val: 0.810001	test: 0.807571
PRC train: 0.912063	val: 0.443773	test: 0.465577

Epoch: 120
Loss: 0.09968251789373941
ROC train: 0.986671	val: 0.810811	test: 0.805036
PRC train: 0.910757	val: 0.445677	test: 0.471264

Early stopping
Best (ROC):	 train: 0.890701	val: 0.835644	test: 0.823216
Best (PRC):	 train: 0.568409	val: 0.430077	test: 0.411854

ROC train: 0.979804	val: 0.818593	test: 0.806828
PRC train: 0.872340	val: 0.454865	test: 0.454048

Epoch: 95
Loss: 0.11312691465631074
ROC train: 0.979392	val: 0.827718	test: 0.820132
PRC train: 0.869973	val: 0.459404	test: 0.457157

Epoch: 96
Loss: 0.11184136299900455
ROC train: 0.980664	val: 0.821061	test: 0.812483
PRC train: 0.874336	val: 0.461885	test: 0.456480

Epoch: 97
Loss: 0.1069364276604705
ROC train: 0.980214	val: 0.823760	test: 0.814533
PRC train: 0.875459	val: 0.461328	test: 0.455984

Epoch: 98
Loss: 0.10799904209742789
ROC train: 0.982631	val: 0.825887	test: 0.815053
PRC train: 0.887872	val: 0.473477	test: 0.455810

Epoch: 99
Loss: 0.1084474113026454
ROC train: 0.982839	val: 0.818649	test: 0.811263
PRC train: 0.885902	val: 0.467403	test: 0.457694

Epoch: 100
Loss: 0.1066288507245361
ROC train: 0.982338	val: 0.821999	test: 0.806144
PRC train: 0.885369	val: 0.464864	test: 0.447785

Epoch: 101
Loss: 0.10757750111637863
ROC train: 0.982080	val: 0.821647	test: 0.811053
PRC train: 0.884443	val: 0.464804	test: 0.444672

Epoch: 102
Loss: 0.1059996768901422
ROC train: 0.981432	val: 0.824510	test: 0.810416
PRC train: 0.878519	val: 0.468542	test: 0.453638

Epoch: 103
Loss: 0.10593535264182265
ROC train: 0.983123	val: 0.827916	test: 0.814973
PRC train: 0.889952	val: 0.466114	test: 0.449867

Epoch: 104
Loss: 0.10573524149064814
ROC train: 0.983086	val: 0.822357	test: 0.813318
PRC train: 0.891223	val: 0.457856	test: 0.452635

Epoch: 105
Loss: 0.10355733636056597
ROC train: 0.983758	val: 0.823808	test: 0.806458
PRC train: 0.891540	val: 0.470195	test: 0.445981

Epoch: 106
Loss: 0.10422620506046432
ROC train: 0.984767	val: 0.822310	test: 0.808664
PRC train: 0.898190	val: 0.458514	test: 0.453341

Epoch: 107
Loss: 0.10375994236347587
ROC train: 0.984660	val: 0.828087	test: 0.817426
PRC train: 0.899737	val: 0.460073	test: 0.456388

Epoch: 108
Loss: 0.10517234496721538
ROC train: 0.985561	val: 0.824171	test: 0.803217
PRC train: 0.904297	val: 0.459740	test: 0.440838

Epoch: 109
Loss: 0.10159409548945643
ROC train: 0.984783	val: 0.816407	test: 0.813044
PRC train: 0.899240	val: 0.451842	test: 0.450288

Epoch: 110
Loss: 0.09891921172959989
ROC train: 0.985962	val: 0.818323	test: 0.804042
PRC train: 0.905012	val: 0.469152	test: 0.454736

Epoch: 111
Loss: 0.10157186307480508
ROC train: 0.985477	val: 0.815855	test: 0.808211
PRC train: 0.904699	val: 0.445615	test: 0.454568

Epoch: 112
Loss: 0.09946544914945435
ROC train: 0.986546	val: 0.823124	test: 0.805193
PRC train: 0.909165	val: 0.450626	test: 0.447002

Epoch: 113
Loss: 0.10096327246734572
ROC train: 0.987183	val: 0.819942	test: 0.807318
PRC train: 0.912102	val: 0.456024	test: 0.448158

Epoch: 114
Loss: 0.0975917494070553
ROC train: 0.986042	val: 0.827848	test: 0.805455
PRC train: 0.905993	val: 0.465370	test: 0.451118

Epoch: 115
Loss: 0.09868075016986703
ROC train: 0.987899	val: 0.818570	test: 0.802019
PRC train: 0.917241	val: 0.464056	test: 0.452689

Epoch: 116
Loss: 0.1004715193505687
ROC train: 0.987335	val: 0.820726	test: 0.799668
PRC train: 0.909953	val: 0.472973	test: 0.453438

Epoch: 117
Loss: 0.09840211772444696
ROC train: 0.987472	val: 0.810258	test: 0.796620
PRC train: 0.908805	val: 0.446138	test: 0.438111

Epoch: 118
Loss: 0.09777512120145254
ROC train: 0.988288	val: 0.819066	test: 0.806842
PRC train: 0.918018	val: 0.458351	test: 0.447129

Epoch: 119
Loss: 0.09789873001478355
ROC train: 0.988180	val: 0.824952	test: 0.807450
PRC train: 0.913500	val: 0.465489	test: 0.454262

Epoch: 120
Loss: 0.09723170057677404
ROC train: 0.988882	val: 0.812660	test: 0.798769
PRC train: 0.921202	val: 0.453833	test: 0.446678

Early stopping
Best (ROC):	 train: 0.958282	val: 0.839493	test: 0.822768
Best (PRC):	 train: 0.776291	val: 0.445561	test: 0.441774

ROC train: 0.978402	val: 0.829747	test: 0.815086
PRC train: 0.863317	val: 0.459018	test: 0.459166

Epoch: 95
Loss: 0.11087653195619823
ROC train: 0.979875	val: 0.830396	test: 0.811178
PRC train: 0.865707	val: 0.429796	test: 0.444137

Epoch: 96
Loss: 0.11160178532064821
ROC train: 0.978865	val: 0.830810	test: 0.817612
PRC train: 0.866256	val: 0.452636	test: 0.469213

Epoch: 97
Loss: 0.10921823422786522
ROC train: 0.980481	val: 0.822910	test: 0.811468
PRC train: 0.871709	val: 0.436731	test: 0.462550

Epoch: 98
Loss: 0.11233382815310033
ROC train: 0.980703	val: 0.834354	test: 0.815010
PRC train: 0.874062	val: 0.447262	test: 0.456002

Epoch: 99
Loss: 0.11080730628282204
ROC train: 0.980074	val: 0.825885	test: 0.812602
PRC train: 0.870143	val: 0.428893	test: 0.440624

Epoch: 100
Loss: 0.110002387578619
ROC train: 0.980588	val: 0.831470	test: 0.812770
PRC train: 0.871550	val: 0.435989	test: 0.452716

Epoch: 101
Loss: 0.10874316482595296
ROC train: 0.980275	val: 0.825961	test: 0.814744
PRC train: 0.868124	val: 0.433833	test: 0.443117

Epoch: 102
Loss: 0.10943063649970171
ROC train: 0.981920	val: 0.830672	test: 0.809927
PRC train: 0.878822	val: 0.448384	test: 0.453507

Epoch: 103
Loss: 0.10853226823019631
ROC train: 0.981185	val: 0.830961	test: 0.818142
PRC train: 0.874491	val: 0.443781	test: 0.460454

Epoch: 104
Loss: 0.10841287001745938
ROC train: 0.982105	val: 0.826421	test: 0.808440
PRC train: 0.881204	val: 0.438760	test: 0.454243

Epoch: 105
Loss: 0.10670567580972454
ROC train: 0.983310	val: 0.824215	test: 0.810815
PRC train: 0.886760	val: 0.436468	test: 0.447362

Epoch: 106
Loss: 0.10714811170661
ROC train: 0.983469	val: 0.824278	test: 0.811777
PRC train: 0.887259	val: 0.451344	test: 0.455824

Epoch: 107
Loss: 0.10472231702393703
ROC train: 0.982912	val: 0.821944	test: 0.808336
PRC train: 0.884775	val: 0.438184	test: 0.449329

Epoch: 108
Loss: 0.10662556661915244
ROC train: 0.985283	val: 0.823330	test: 0.809655
PRC train: 0.897513	val: 0.441261	test: 0.455537

Epoch: 109
Loss: 0.10479272214573929
ROC train: 0.983806	val: 0.831529	test: 0.813666
PRC train: 0.890969	val: 0.454034	test: 0.447218

Epoch: 110
Loss: 0.10551644596635418
ROC train: 0.984324	val: 0.827061	test: 0.815947
PRC train: 0.894523	val: 0.448295	test: 0.465912

Epoch: 111
Loss: 0.10682291825478686
ROC train: 0.985430	val: 0.828105	test: 0.813263
PRC train: 0.898079	val: 0.439447	test: 0.448935

Epoch: 112
Loss: 0.10015398608857713
ROC train: 0.985609	val: 0.828192	test: 0.814227
PRC train: 0.902310	val: 0.451574	test: 0.462493

Epoch: 113
Loss: 0.10364262518846443
ROC train: 0.984984	val: 0.825551	test: 0.809782
PRC train: 0.899521	val: 0.437747	test: 0.450631

Epoch: 114
Loss: 0.10264651412446839
ROC train: 0.985821	val: 0.825895	test: 0.807769
PRC train: 0.902428	val: 0.446657	test: 0.459793

Epoch: 115
Loss: 0.10104276684471135
ROC train: 0.985877	val: 0.822232	test: 0.810825
PRC train: 0.901184	val: 0.439016	test: 0.448698

Epoch: 116
Loss: 0.09974241874066077
ROC train: 0.986848	val: 0.825438	test: 0.810070
PRC train: 0.906768	val: 0.426184	test: 0.438433

Epoch: 117
Loss: 0.09898024728581784
ROC train: 0.987030	val: 0.823637	test: 0.807787
PRC train: 0.907449	val: 0.442905	test: 0.445703

Epoch: 118
Loss: 0.09861149923238045
ROC train: 0.987727	val: 0.817269	test: 0.798439
PRC train: 0.911211	val: 0.429392	test: 0.432565

Epoch: 119
Loss: 0.09915948693041203
ROC train: 0.988014	val: 0.826033	test: 0.807308
PRC train: 0.914497	val: 0.436405	test: 0.447107

Epoch: 120
Loss: 0.09727257391064886
ROC train: 0.987672	val: 0.830244	test: 0.810481
PRC train: 0.912050	val: 0.435456	test: 0.454277

Epoch: 121
Loss: 0.09707484667349728
ROC train: 0.987893	val: 0.830096	test: 0.809244
PRC train: 0.916507	val: 0.453402	test: 0.463071

Early stopping
Best (ROC):	 train: 0.973420	val: 0.840380	test: 0.813586
Best (PRC):	 train: 0.842097	val: 0.445942	test: 0.443306
All runs completed.

ROC train: 0.977738	val: 0.815846	test: 0.823009
PRC train: 0.862215	val: 0.496455	test: 0.465557

Epoch: 95
Loss: 0.11496440996866408
ROC train: 0.977466	val: 0.816309	test: 0.815976
PRC train: 0.861009	val: 0.474735	test: 0.447399

Epoch: 96
Loss: 0.11267384449127554
ROC train: 0.978456	val: 0.811930	test: 0.815997
PRC train: 0.867835	val: 0.490682	test: 0.454609

Epoch: 97
Loss: 0.11202229786654161
ROC train: 0.978220	val: 0.819667	test: 0.828491
PRC train: 0.865369	val: 0.481995	test: 0.445170

Epoch: 98
Loss: 0.11345243367355584
ROC train: 0.979177	val: 0.808308	test: 0.816890
PRC train: 0.872255	val: 0.485017	test: 0.459296

Epoch: 99
Loss: 0.11016115547858513
ROC train: 0.979669	val: 0.815720	test: 0.822202
PRC train: 0.875213	val: 0.485907	test: 0.447696

Epoch: 100
Loss: 0.11126794959358235
ROC train: 0.977982	val: 0.809353	test: 0.810146
PRC train: 0.860539	val: 0.494001	test: 0.433716

Epoch: 101
Loss: 0.10777154185969488
ROC train: 0.980650	val: 0.813562	test: 0.816157
PRC train: 0.884482	val: 0.472870	test: 0.450160

Epoch: 102
Loss: 0.10789853633334494
ROC train: 0.980807	val: 0.814937	test: 0.824550
PRC train: 0.878461	val: 0.489004	test: 0.453333

Epoch: 103
Loss: 0.10897089488078976
ROC train: 0.980722	val: 0.819005	test: 0.820794
PRC train: 0.886178	val: 0.496638	test: 0.455350

Epoch: 104
Loss: 0.10825724030177591
ROC train: 0.981715	val: 0.817827	test: 0.822818
PRC train: 0.886804	val: 0.500396	test: 0.459807

Epoch: 105
Loss: 0.10622807002670898
ROC train: 0.982876	val: 0.816586	test: 0.820169
PRC train: 0.891575	val: 0.483522	test: 0.463358

Epoch: 106
Loss: 0.105772152866252
ROC train: 0.982765	val: 0.808989	test: 0.810457
PRC train: 0.889698	val: 0.492765	test: 0.446670

Epoch: 107
Loss: 0.10760557596718076
ROC train: 0.982559	val: 0.815108	test: 0.814939
PRC train: 0.889381	val: 0.481995	test: 0.439715

Epoch: 108
Loss: 0.10698129572209422
ROC train: 0.982507	val: 0.813873	test: 0.813603
PRC train: 0.888568	val: 0.496765	test: 0.457466

Epoch: 109
Loss: 0.1058114292613087
ROC train: 0.982234	val: 0.815575	test: 0.812117
PRC train: 0.883609	val: 0.492363	test: 0.453553

Epoch: 110
Loss: 0.10758290532450361
ROC train: 0.983923	val: 0.818563	test: 0.815284
PRC train: 0.898595	val: 0.489415	test: 0.461212

Epoch: 111
Loss: 0.10549064333342129
ROC train: 0.984801	val: 0.812144	test: 0.815012
PRC train: 0.902360	val: 0.486191	test: 0.455231

Epoch: 112
Loss: 0.10276749534420049
ROC train: 0.984814	val: 0.821589	test: 0.817669
PRC train: 0.903344	val: 0.487488	test: 0.454489

Epoch: 113
Loss: 0.10218837882687129
ROC train: 0.984744	val: 0.817888	test: 0.809648
PRC train: 0.900912	val: 0.496612	test: 0.452161

Epoch: 114
Loss: 0.10378239174158732
ROC train: 0.984975	val: 0.815756	test: 0.823402
PRC train: 0.900690	val: 0.493552	test: 0.466621

Epoch: 115
Loss: 0.10266880182000843
ROC train: 0.984647	val: 0.808500	test: 0.810600
PRC train: 0.900164	val: 0.479033	test: 0.462336

Epoch: 116
Loss: 0.0995525625963069
ROC train: 0.985764	val: 0.814536	test: 0.814286
PRC train: 0.905851	val: 0.493047	test: 0.448665

Epoch: 117
Loss: 0.10176147167850677
ROC train: 0.986146	val: 0.811977	test: 0.818927
PRC train: 0.908966	val: 0.488610	test: 0.460618

Epoch: 118
Loss: 0.10132583466369618
ROC train: 0.986790	val: 0.809514	test: 0.825849
PRC train: 0.909621	val: 0.463070	test: 0.434815

Epoch: 119
Loss: 0.1025708500951509
ROC train: 0.985926	val: 0.817579	test: 0.821403
PRC train: 0.907026	val: 0.487788	test: 0.458549

Epoch: 120
Loss: 0.1012982321235808
ROC train: 0.986215	val: 0.813224	test: 0.821207
PRC train: 0.909733	val: 0.480896	test: 0.471841

Early stopping
Best (ROC):	 train: 0.937345	val: 0.831107	test: 0.824895
Best (PRC):	 train: 0.697451	val: 0.484208	test: 0.451153

ROC train: 0.979069	val: 0.822111	test: 0.809214
PRC train: 0.871729	val: 0.501853	test: 0.454694

Epoch: 95
Loss: 0.11244265914246969
ROC train: 0.978293	val: 0.814780	test: 0.814646
PRC train: 0.869496	val: 0.488262	test: 0.448514

Epoch: 96
Loss: 0.11204878191792407
ROC train: 0.979339	val: 0.817594	test: 0.815308
PRC train: 0.874424	val: 0.489040	test: 0.435748

Epoch: 97
Loss: 0.10994797106918217
ROC train: 0.980415	val: 0.808705	test: 0.810737
PRC train: 0.879842	val: 0.490755	test: 0.450434

Epoch: 98
Loss: 0.11179193931093696
ROC train: 0.980204	val: 0.824084	test: 0.820044
PRC train: 0.881714	val: 0.497802	test: 0.469407

Epoch: 99
Loss: 0.10860366418313815
ROC train: 0.979387	val: 0.812916	test: 0.813691
PRC train: 0.870788	val: 0.492669	test: 0.465716

Epoch: 100
Loss: 0.11021376234879851
ROC train: 0.980404	val: 0.819800	test: 0.810962
PRC train: 0.879694	val: 0.491674	test: 0.466342

Epoch: 101
Loss: 0.10902888770039247
ROC train: 0.980752	val: 0.818507	test: 0.817012
PRC train: 0.882643	val: 0.471650	test: 0.464148

Epoch: 102
Loss: 0.10780446103127449
ROC train: 0.982040	val: 0.821571	test: 0.819902
PRC train: 0.888246	val: 0.471236	test: 0.469451

Epoch: 103
Loss: 0.1083085304603276
ROC train: 0.981401	val: 0.821389	test: 0.813422
PRC train: 0.886588	val: 0.494539	test: 0.451881

Epoch: 104
Loss: 0.105956950783745
ROC train: 0.982494	val: 0.809069	test: 0.811327
PRC train: 0.889114	val: 0.478099	test: 0.443826

Epoch: 105
Loss: 0.10496046040494324
ROC train: 0.983393	val: 0.813382	test: 0.816983
PRC train: 0.895941	val: 0.481255	test: 0.466909

Epoch: 106
Loss: 0.10513136258694968
ROC train: 0.983426	val: 0.816123	test: 0.818539
PRC train: 0.897232	val: 0.493455	test: 0.466317

Epoch: 107
Loss: 0.10675700679233485
ROC train: 0.983892	val: 0.817456	test: 0.816124
PRC train: 0.897444	val: 0.493508	test: 0.467242

Epoch: 108
Loss: 0.10471270290641359
ROC train: 0.984251	val: 0.819473	test: 0.815018
PRC train: 0.898834	val: 0.486065	test: 0.467823

Epoch: 109
Loss: 0.10518855561830186
ROC train: 0.984662	val: 0.818822	test: 0.811218
PRC train: 0.901806	val: 0.479662	test: 0.448297

Epoch: 110
Loss: 0.10410652003991547
ROC train: 0.984875	val: 0.815672	test: 0.808256
PRC train: 0.898893	val: 0.469870	test: 0.445826

Epoch: 111
Loss: 0.10310424666733266
ROC train: 0.985257	val: 0.812188	test: 0.808299
PRC train: 0.906321	val: 0.486950	test: 0.436880

Epoch: 112
Loss: 0.10317702916875307
ROC train: 0.985432	val: 0.815505	test: 0.812400
PRC train: 0.903947	val: 0.475769	test: 0.448682

Epoch: 113
Loss: 0.10360529470445569
ROC train: 0.985628	val: 0.810524	test: 0.807076
PRC train: 0.906474	val: 0.483471	test: 0.447691

Epoch: 114
Loss: 0.10238174033703212
ROC train: 0.985822	val: 0.818154	test: 0.813080
PRC train: 0.908931	val: 0.498456	test: 0.460273

Epoch: 115
Loss: 0.09998105121670013
ROC train: 0.986646	val: 0.809759	test: 0.810395
PRC train: 0.912248	val: 0.494594	test: 0.454327

Epoch: 116
Loss: 0.10028769321612495
ROC train: 0.986698	val: 0.815485	test: 0.812874
PRC train: 0.914094	val: 0.492116	test: 0.461137

Epoch: 117
Loss: 0.10031910445084807
ROC train: 0.986743	val: 0.816419	test: 0.801611
PRC train: 0.914787	val: 0.485864	test: 0.439706

Epoch: 118
Loss: 0.09852344804746738
ROC train: 0.986666	val: 0.818535	test: 0.809892
PRC train: 0.914446	val: 0.498105	test: 0.461935

Epoch: 119
Loss: 0.100122418003035
ROC train: 0.987642	val: 0.814132	test: 0.806346
PRC train: 0.919040	val: 0.492315	test: 0.460887

Epoch: 120
Loss: 0.09612639152216079
ROC train: 0.987819	val: 0.816313	test: 0.806977
PRC train: 0.920235	val: 0.484323	test: 0.450231

Early stopping
Best (ROC):	 train: 0.917671	val: 0.831474	test: 0.835861
Best (PRC):	 train: 0.642813	val: 0.482644	test: 0.417267

ROC train: 0.977854	val: 0.806220	test: 0.806795
PRC train: 0.863740	val: 0.498244	test: 0.450593

Epoch: 95
Loss: 0.1114188172379513
ROC train: 0.978451	val: 0.818964	test: 0.804013
PRC train: 0.868452	val: 0.505093	test: 0.427245

Epoch: 96
Loss: 0.11385021456227365
ROC train: 0.978359	val: 0.807604	test: 0.806654
PRC train: 0.868997	val: 0.498098	test: 0.440396

Epoch: 97
Loss: 0.11213363870556231
ROC train: 0.979831	val: 0.812709	test: 0.811119
PRC train: 0.873774	val: 0.506405	test: 0.442166

Epoch: 98
Loss: 0.10918377031853899
ROC train: 0.980679	val: 0.813698	test: 0.808811
PRC train: 0.879776	val: 0.512114	test: 0.449988

Epoch: 99
Loss: 0.10929651397356047
ROC train: 0.979157	val: 0.820629	test: 0.808454
PRC train: 0.874801	val: 0.514512	test: 0.438689

Epoch: 100
Loss: 0.10910366715552756
ROC train: 0.980792	val: 0.813665	test: 0.814786
PRC train: 0.881004	val: 0.501419	test: 0.446172

Epoch: 101
Loss: 0.10959929080090508
ROC train: 0.980974	val: 0.815738	test: 0.812569
PRC train: 0.878583	val: 0.502818	test: 0.459371

Epoch: 102
Loss: 0.11101521637965478
ROC train: 0.980998	val: 0.814679	test: 0.805748
PRC train: 0.881055	val: 0.498993	test: 0.422142

Epoch: 103
Loss: 0.10605192394390733
ROC train: 0.981813	val: 0.816171	test: 0.800292
PRC train: 0.884250	val: 0.495773	test: 0.429580

Epoch: 104
Loss: 0.10882918799455205
ROC train: 0.983028	val: 0.818738	test: 0.805284
PRC train: 0.893323	val: 0.503891	test: 0.444975

Epoch: 105
Loss: 0.10543917336794002
ROC train: 0.982617	val: 0.818677	test: 0.806443
PRC train: 0.888681	val: 0.498023	test: 0.433981

Epoch: 106
Loss: 0.10588134123379218
ROC train: 0.983437	val: 0.814328	test: 0.808390
PRC train: 0.892177	val: 0.495184	test: 0.451198

Epoch: 107
Loss: 0.10426419702749375
ROC train: 0.984322	val: 0.816092	test: 0.808162
PRC train: 0.897759	val: 0.500272	test: 0.438329

Epoch: 108
Loss: 0.10453075926145933
ROC train: 0.984639	val: 0.814994	test: 0.803565
PRC train: 0.898054	val: 0.497625	test: 0.436784

Epoch: 109
Loss: 0.10545440660121405
ROC train: 0.984258	val: 0.811704	test: 0.814346
PRC train: 0.900471	val: 0.493431	test: 0.457844

Epoch: 110
Loss: 0.10514096708391055
ROC train: 0.984170	val: 0.808817	test: 0.807451
PRC train: 0.893401	val: 0.483985	test: 0.438002

Epoch: 111
Loss: 0.10518617845242162
ROC train: 0.984170	val: 0.811857	test: 0.808897
PRC train: 0.898111	val: 0.484236	test: 0.443068

Epoch: 112
Loss: 0.10184203981608515
ROC train: 0.985244	val: 0.814871	test: 0.806843
PRC train: 0.906275	val: 0.499942	test: 0.461268

Epoch: 113
Loss: 0.10053239995003803
ROC train: 0.985671	val: 0.812891	test: 0.803696
PRC train: 0.904493	val: 0.503096	test: 0.455891

Epoch: 114
Loss: 0.10343277522687262
ROC train: 0.985857	val: 0.818396	test: 0.806947
PRC train: 0.907766	val: 0.498887	test: 0.441299

Epoch: 115
Loss: 0.09988653345415884
ROC train: 0.985427	val: 0.816615	test: 0.813944
PRC train: 0.906222	val: 0.501685	test: 0.454956

Epoch: 116
Loss: 0.10032960324177197
ROC train: 0.985909	val: 0.814004	test: 0.807260
PRC train: 0.907126	val: 0.496751	test: 0.449406

Epoch: 117
Loss: 0.1004444746047464
ROC train: 0.985515	val: 0.823486	test: 0.807251
PRC train: 0.906492	val: 0.497208	test: 0.434742

Epoch: 118
Loss: 0.09788860058531271
ROC train: 0.987276	val: 0.814323	test: 0.803955
PRC train: 0.916502	val: 0.497539	test: 0.445637

Epoch: 119
Loss: 0.09823114758524479
ROC train: 0.986927	val: 0.813068	test: 0.800602
PRC train: 0.911810	val: 0.495056	test: 0.456015

Epoch: 120
Loss: 0.09962937291170554
ROC train: 0.986332	val: 0.809457	test: 0.806671
PRC train: 0.909813	val: 0.498874	test: 0.448152

Early stopping
Best (ROC):	 train: 0.923197	val: 0.835255	test: 0.831960
Best (PRC):	 train: 0.659415	val: 0.490770	test: 0.428517
All runs completed.
