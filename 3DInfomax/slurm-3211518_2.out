>>> Starting run for dataset: clintox
Running SCAFF configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.6.yml on cuda:0
Running SCAFF configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.7.yml on cuda:1
Running SCAFF configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.8.yml on cuda:2
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
Starting process for seed 4: python train.py --config configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.7.yml --seed 4 --device cuda:1
Starting process for seed 4: python train.py --config configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.8.yml --seed 4 --device cuda:2
Starting process for seed 4: python train.py --config configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.6.yml --seed 4 --device cuda:0
Starting process for seed 5: python train.py --config configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.7.yml --seed 5 --device cuda:1
Starting process for seed 5: python train.py --config configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.8.yml --seed 5 --device cuda:2
Starting process for seed 5: python train.py --config configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.6.yml --seed 5 --device cuda:0
Starting process for seed 6: python train.py --config configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.8.yml --seed 6 --device cuda:2
Starting process for seed 6: python train.py --config configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.7.yml --seed 6 --device cuda:1
Starting process for seed 6: python train.py --config configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.6.yml --seed 6 --device cuda:0
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[ Using Seed :  4  ]
using device:  cuda:2
Log directory:  runs/split/GraphCL/clintox/scaff/train_prop=0.8/PNA_ogbg-molclintox_GraphCL_clintox_scaff=0.8_4_26-05_09-47-10
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_clintox_scaff=0.8
logdir: runs/split/GraphCL/clintox/scaff/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/   40] train: loss: 0.6932858
[Epoch 1] ogbg-molclintox: 0.404352 val loss: 0.692232
[Epoch 1] ogbg-molclintox: 0.533061 test loss: 0.692145
[Epoch 2; Iter    20/   40] train: loss: 0.6927287
[Epoch 2] ogbg-molclintox: 0.392249 val loss: 0.690143
[Epoch 2] ogbg-molclintox: 0.544580 test loss: 0.690392
[Epoch 3; Iter    10/   40] train: loss: 0.6929488
[Epoch 3; Iter    40/   40] train: loss: 0.6907994
[Epoch 3] ogbg-molclintox: 0.395595 val loss: 0.690195
[Epoch 3] ogbg-molclintox: 0.581320 test loss: 0.690197
[Epoch 4; Iter    30/   40] train: loss: 0.6926960
[Epoch 4] ogbg-molclintox: 0.401439 val loss: 0.689186
[Epoch 4] ogbg-molclintox: 0.577947 test loss: 0.689454
[Epoch 5; Iter    20/   40] train: loss: 0.6929329
[Epoch 5] ogbg-molclintox: 0.409855 val loss: 0.688996
[Epoch 5] ogbg-molclintox: 0.584417 test loss: 0.689058
[Epoch 6; Iter    10/   40] train: loss: 0.6910385
[Epoch 6; Iter    40/   40] train: loss: 0.6905471
[Epoch 6] ogbg-molclintox: 0.399278 val loss: 0.688083
[Epoch 6] ogbg-molclintox: 0.608278 test loss: 0.688689
[Epoch 7; Iter    30/   40] train: loss: 0.6899234
[Epoch 7] ogbg-molclintox: 0.418046 val loss: 0.687226
[Epoch 7] ogbg-molclintox: 0.587827 test loss: 0.687893
[Epoch 8; Iter    20/   40] train: loss: 0.6906822
[Epoch 8] ogbg-molclintox: 0.407894 val loss: 0.687078
[Epoch 8] ogbg-molclintox: 0.591088 test loss: 0.687514
[Epoch 9; Iter    10/   40] train: loss: 0.6886008
[Epoch 9; Iter    40/   40] train: loss: 0.6887452
[Epoch 9] ogbg-molclintox: 0.435940 val loss: 0.684786
[Epoch 9] ogbg-molclintox: 0.613761 test loss: 0.685874
[Epoch 10; Iter    30/   40] train: loss: 0.6881732
[Epoch 10] ogbg-molclintox: 0.442522 val loss: 0.683941
[Epoch 10] ogbg-molclintox: 0.614385 test loss: 0.685556
[Epoch 11; Iter    20/   40] train: loss: 0.6855643
[Epoch 11] ogbg-molclintox: 0.442209 val loss: 0.682257
[Epoch 11] ogbg-molclintox: 0.603205 test loss: 0.683534
[Epoch 12; Iter    10/   40] train: loss: 0.6838807
[Epoch 12; Iter    40/   40] train: loss: 0.6830626
[Epoch 12] ogbg-molclintox: 0.454009 val loss: 0.681486
[Epoch 12] ogbg-molclintox: 0.629102 test loss: 0.682910
[Epoch 13; Iter    30/   40] train: loss: 0.6830951
[Epoch 13] ogbg-molclintox: 0.452112 val loss: 0.679229
[Epoch 13] ogbg-molclintox: 0.609275 test loss: 0.680838
[Epoch 14; Iter    20/   40] train: loss: 0.6810161
[Epoch 14] ogbg-molclintox: 0.459129 val loss: 0.677468
[Epoch 14] ogbg-molclintox: 0.614497 test loss: 0.679055
[Epoch 15; Iter    10/   40] train: loss: 0.6794674
[Epoch 15; Iter    40/   40] train: loss: 0.6767147
[Epoch 15] ogbg-molclintox: 0.458093 val loss: 0.675848
[Epoch 15] ogbg-molclintox: 0.614785 test loss: 0.677744
[Epoch 16; Iter    30/   40] train: loss: 0.6761931
[Epoch 16] ogbg-molclintox: 0.476549 val loss: 0.674289
[Epoch 16] ogbg-molclintox: 0.634111 test loss: 0.676325
[Epoch 17; Iter    20/   40] train: loss: 0.6742786
[Epoch 17] ogbg-molclintox: 0.482192 val loss: 0.672268
[Epoch 17] ogbg-molclintox: 0.648626 test loss: 0.674849
[Epoch 18; Iter    10/   40] train: loss: 0.6714510
[Epoch 18; Iter    40/   40] train: loss: 0.6613396
[Epoch 18] ogbg-molclintox: 0.700814 val loss: 0.655544
[Epoch 18] ogbg-molclintox: 0.696698 test loss: 0.685536
[Epoch 19; Iter    30/   40] train: loss: 0.6361142
[Epoch 19] ogbg-molclintox: 0.880229 val loss: 0.590612
[Epoch 19] ogbg-molclintox: 0.677010 test loss: 0.597151
[Epoch 20; Iter    20/   40] train: loss: 0.6001445
[Epoch 20] ogbg-molclintox: 0.887946 val loss: 0.501754
[Epoch 20] ogbg-molclintox: 0.691562 test loss: 0.540164
[Epoch 21; Iter    10/   40] train: loss: 0.5393751
[Epoch 21; Iter    40/   40] train: loss: 0.4751354
[Epoch 21] ogbg-molclintox: 0.911768 val loss: 0.513294
[Epoch 21] ogbg-molclintox: 0.735497 test loss: 0.543605
[Epoch 22; Iter    30/   40] train: loss: 0.4427426
[Epoch 22] ogbg-molclintox: 0.897420 val loss: 0.340815
[Epoch 22] ogbg-molclintox: 0.825752 test loss: 0.451608
[Epoch 23; Iter    20/   40] train: loss: 0.3915509
[Epoch 23] ogbg-molclintox: 0.870773 val loss: 0.357392
[Epoch 23] ogbg-molclintox: 0.728762 test loss: 0.410176
[Epoch 24; Iter    10/   40] train: loss: 0.3157658
[Epoch 24; Iter    40/   40] train: loss: 0.3100341
[Epoch 24] ogbg-molclintox: 0.985016 val loss: 0.241064
[Epoch 24] ogbg-molclintox: 0.877430 test loss: 0.329937
[Epoch 25; Iter    30/   40] train: loss: 0.2836562
[Epoch 25] ogbg-molclintox: 0.989349 val loss: 0.157313
[Epoch 25] ogbg-molclintox: 0.828225 test loss: 0.242922
[Epoch 26; Iter    20/   40] train: loss: 0.2077828
[Epoch 26] ogbg-molclintox: 0.970819 val loss: 0.164187
[Epoch 26] ogbg-molclintox: 0.795422 test loss: 0.275852
[Epoch 27; Iter    10/   40] train: loss: 0.2200270
[Epoch 27; Iter    40/   40] train: loss: 0.1741571
[Epoch 27] ogbg-molclintox: 0.976350 val loss: 0.141696
[Epoch 27] ogbg-molclintox: 0.842991 test loss: 0.247607
[Epoch 28; Iter    30/   40] train: loss: 0.2126665
[Epoch 28] ogbg-molclintox: 0.902727 val loss: 0.131094
[Epoch 28] ogbg-molclintox: 0.811110 test loss: 0.208256
[Epoch 29; Iter    20/   40] train: loss: 0.3255654
[Epoch 29] ogbg-molclintox: 0.979422 val loss: 0.150702
[Epoch 29] ogbg-molclintox: 0.839330 test loss: 0.268605
[Epoch 30; Iter    10/   40] train: loss: 0.1971967
[Epoch 30; Iter    40/   40] train: loss: 0.0899969
[Epoch 30] ogbg-molclintox: 0.989711 val loss: 0.103431
[Epoch 30] ogbg-molclintox: 0.873658 test loss: 0.199864
[Epoch 31; Iter    30/   40] train: loss: 0.2055140
[Epoch 31] ogbg-molclintox: 0.849808 val loss: 0.128629
[ Using Seed :  5  ]
using device:  cuda:0
Log directory:  runs/split/GraphCL/clintox/scaff/train_prop=0.6/PNA_ogbg-molclintox_GraphCL_clintox_scaff=0.6_5_26-05_09-47-10
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_clintox_scaff=0.6
logdir: runs/split/GraphCL/clintox/scaff/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/   30] train: loss: 0.6904117
[Epoch 1] ogbg-molclintox: 0.417678 val loss: 0.693012
[Epoch 1] ogbg-molclintox: 0.515559 test loss: 0.692762
[Epoch 2; Iter    30/   30] train: loss: 0.6932125
[Epoch 2] ogbg-molclintox: 0.458068 val loss: 0.692902
[Epoch 2] ogbg-molclintox: 0.533204 test loss: 0.692505
[Epoch 3; Iter    30/   30] train: loss: 0.6922622
[Epoch 3] ogbg-molclintox: 0.468931 val loss: 0.693495
[Epoch 3] ogbg-molclintox: 0.530352 test loss: 0.692997
[Epoch 4; Iter    30/   30] train: loss: 0.6905591
[Epoch 4] ogbg-molclintox: 0.465781 val loss: 0.693044
[Epoch 4] ogbg-molclintox: 0.530645 test loss: 0.692435
[Epoch 5; Iter    30/   30] train: loss: 0.6931436
[Epoch 5] ogbg-molclintox: 0.462631 val loss: 0.693152
[Epoch 5] ogbg-molclintox: 0.526423 test loss: 0.692356
[Epoch 6; Iter    30/   30] train: loss: 0.6931591
[Epoch 6] ogbg-molclintox: 0.464456 val loss: 0.692481
[Epoch 6] ogbg-molclintox: 0.525378 test loss: 0.691736
[Epoch 7; Iter    30/   30] train: loss: 0.6915596
[Epoch 7] ogbg-molclintox: 0.458207 val loss: 0.692121
[Epoch 7] ogbg-molclintox: 0.523532 test loss: 0.691508
[Epoch 8; Iter    30/   30] train: loss: 0.6923522
[Epoch 8] ogbg-molclintox: 0.468246 val loss: 0.692001
[Epoch 8] ogbg-molclintox: 0.529621 test loss: 0.691236
[Epoch 9; Iter    30/   30] train: loss: 0.6905148
[Epoch 9] ogbg-molclintox: 0.468380 val loss: 0.692059
[Epoch 9] ogbg-molclintox: 0.528649 test loss: 0.691377
[Epoch 10; Iter    30/   30] train: loss: 0.6898126
[Epoch 10] ogbg-molclintox: 0.468407 val loss: 0.690924
[Epoch 10] ogbg-molclintox: 0.529555 test loss: 0.690282
[Epoch 11; Iter    30/   30] train: loss: 0.6898243
[Epoch 11] ogbg-molclintox: 0.464665 val loss: 0.690008
[Epoch 11] ogbg-molclintox: 0.530305 test loss: 0.689394
[Epoch 12; Iter    30/   30] train: loss: 0.6891179
[Epoch 12] ogbg-molclintox: 0.471456 val loss: 0.689442
[Epoch 12] ogbg-molclintox: 0.529527 test loss: 0.688735
[Epoch 13; Iter    30/   30] train: loss: 0.6898031
[Epoch 13] ogbg-molclintox: 0.472592 val loss: 0.688479
[Epoch 13] ogbg-molclintox: 0.533489 test loss: 0.687828
[Epoch 14; Iter    30/   30] train: loss: 0.6866857
[Epoch 14] ogbg-molclintox: 0.475942 val loss: 0.688298
[Epoch 14] ogbg-molclintox: 0.532871 test loss: 0.687701
[Epoch 15; Iter    30/   30] train: loss: 0.6876413
[Epoch 15] ogbg-molclintox: 0.473308 val loss: 0.686969
[Epoch 15] ogbg-molclintox: 0.527443 test loss: 0.686309
[Epoch 16; Iter    30/   30] train: loss: 0.6828123
[Epoch 16] ogbg-molclintox: 0.480508 val loss: 0.686946
[Epoch 16] ogbg-molclintox: 0.532262 test loss: 0.686244
[Epoch 17; Iter    30/   30] train: loss: 0.6841816
[Epoch 17] ogbg-molclintox: 0.481297 val loss: 0.685479
[Epoch 17] ogbg-molclintox: 0.540791 test loss: 0.684725
[Epoch 18; Iter    30/   30] train: loss: 0.6840526
[Epoch 18] ogbg-molclintox: 0.479425 val loss: 0.684575
[Epoch 18] ogbg-molclintox: 0.536175 test loss: 0.683831
[Epoch 19; Iter    30/   30] train: loss: 0.6811231
[Epoch 19] ogbg-molclintox: 0.481330 val loss: 0.684259
[Epoch 19] ogbg-molclintox: 0.531253 test loss: 0.683397
[Epoch 20; Iter    30/   30] train: loss: 0.6795328
[Epoch 20] ogbg-molclintox: 0.490087 val loss: 0.683093
[Epoch 20] ogbg-molclintox: 0.544972 test loss: 0.682229
[Epoch 21; Iter    30/   30] train: loss: 0.6793025
[Epoch 21] ogbg-molclintox: 0.488034 val loss: 0.681159
[Epoch 21] ogbg-molclintox: 0.543249 test loss: 0.680209
[Epoch 22; Iter    30/   30] train: loss: 0.6770641
[Epoch 22] ogbg-molclintox: 0.493082 val loss: 0.680595
[Epoch 22] ogbg-molclintox: 0.544794 test loss: 0.679786
[Epoch 23; Iter    30/   30] train: loss: 0.6794532
[Epoch 23] ogbg-molclintox: 0.541070 val loss: 0.686201
[Epoch 23] ogbg-molclintox: 0.604107 test loss: 0.684080
[Epoch 24; Iter    30/   30] train: loss: 0.6531996
[Epoch 24] ogbg-molclintox: 0.662082 val loss: 0.717770
[Epoch 24] ogbg-molclintox: 0.732943 test loss: 0.707686
[Epoch 25; Iter    30/   30] train: loss: 0.6304691
[Epoch 25] ogbg-molclintox: 0.699603 val loss: 0.686555
[Epoch 25] ogbg-molclintox: 0.762912 test loss: 0.661281
[Epoch 26; Iter    30/   30] train: loss: 0.5738118
[Epoch 26] ogbg-molclintox: 0.758263 val loss: 0.576778
[Epoch 26] ogbg-molclintox: 0.799472 test loss: 0.564326
[Epoch 27; Iter    30/   30] train: loss: 0.5261037
[Epoch 27] ogbg-molclintox: 0.749466 val loss: 0.633113
[Epoch 27] ogbg-molclintox: 0.790030 test loss: 0.580943
[Epoch 28; Iter    30/   30] train: loss: 0.5090152
[Epoch 28] ogbg-molclintox: 0.765583 val loss: 0.479445
[Epoch 28] ogbg-molclintox: 0.803312 test loss: 0.462191
[Epoch 29; Iter    30/   30] train: loss: 0.4062278
[Epoch 29] ogbg-molclintox: 0.809784 val loss: 0.432203
[Epoch 29] ogbg-molclintox: 0.827384 test loss: 0.390198
[Epoch 30; Iter    30/   30] train: loss: 0.3803668
[Epoch 30] ogbg-molclintox: 0.788947 val loss: 0.509641
[Epoch 30] ogbg-molclintox: 0.832399 test loss: 0.464557
[Epoch 31; Iter    30/   30] train: loss: 0.3607291
[Epoch 31] ogbg-molclintox: 0.815988 val loss: 0.303363
[Epoch 31] ogbg-molclintox: 0.853237 test loss: 0.255663
[Epoch 32; Iter    30/   30] train: loss: 0.2261252
[Epoch 32] ogbg-molclintox: 0.760236 val loss: 0.321288
[Epoch 32] ogbg-molclintox: 0.724737 test loss: 0.322150
[Epoch 33; Iter    30/   30] train: loss: 0.1764282
[Epoch 33] ogbg-molclintox: 0.853504 val loss: 0.254126
[Epoch 33] ogbg-molclintox: 0.826532 test loss: 0.223715
[Epoch 34; Iter    30/   30] train: loss: 0.1610388
[Epoch 34] ogbg-molclintox: 0.848209 val loss: 0.234013
[ Using Seed :  4  ]
using device:  cuda:0
Log directory:  runs/split/GraphCL/clintox/scaff/train_prop=0.6/PNA_ogbg-molclintox_GraphCL_clintox_scaff=0.6_4_26-05_09-47-11
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_clintox_scaff=0.6
logdir: runs/split/GraphCL/clintox/scaff/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/   30] train: loss: 0.6923931
[Epoch 1] ogbg-molclintox: 0.469738 val loss: 0.693400
[Epoch 1] ogbg-molclintox: 0.489253 test loss: 0.692623
[Epoch 2; Iter    30/   30] train: loss: 0.6934125
[Epoch 2] ogbg-molclintox: 0.470097 val loss: 0.693242
[Epoch 2] ogbg-molclintox: 0.486460 test loss: 0.691043
[Epoch 3; Iter    30/   30] train: loss: 0.6936180
[Epoch 3] ogbg-molclintox: 0.486435 val loss: 0.693164
[Epoch 3] ogbg-molclintox: 0.498857 test loss: 0.690184
[Epoch 4; Iter    30/   30] train: loss: 0.6917271
[Epoch 4] ogbg-molclintox: 0.488868 val loss: 0.693466
[Epoch 4] ogbg-molclintox: 0.505029 test loss: 0.690124
[Epoch 5; Iter    30/   30] train: loss: 0.6930377
[Epoch 5] ogbg-molclintox: 0.503669 val loss: 0.693015
[Epoch 5] ogbg-molclintox: 0.519147 test loss: 0.689859
[Epoch 6; Iter    30/   30] train: loss: 0.6912551
[Epoch 6] ogbg-molclintox: 0.498675 val loss: 0.692871
[Epoch 6] ogbg-molclintox: 0.522834 test loss: 0.689657
[Epoch 7; Iter    30/   30] train: loss: 0.6911712
[Epoch 7] ogbg-molclintox: 0.502700 val loss: 0.692457
[Epoch 7] ogbg-molclintox: 0.526967 test loss: 0.689271
[Epoch 8; Iter    30/   30] train: loss: 0.6912897
[Epoch 8] ogbg-molclintox: 0.506282 val loss: 0.691574
[Epoch 8] ogbg-molclintox: 0.533477 test loss: 0.688401
[Epoch 9; Iter    30/   30] train: loss: 0.6898062
[Epoch 9] ogbg-molclintox: 0.512112 val loss: 0.690627
[Epoch 9] ogbg-molclintox: 0.526878 test loss: 0.687565
[Epoch 10; Iter    30/   30] train: loss: 0.6909630
[Epoch 10] ogbg-molclintox: 0.507512 val loss: 0.690430
[Epoch 10] ogbg-molclintox: 0.531252 test loss: 0.687212
[Epoch 11; Iter    30/   30] train: loss: 0.6881429
[Epoch 11] ogbg-molclintox: 0.512226 val loss: 0.689259
[Epoch 11] ogbg-molclintox: 0.532526 test loss: 0.685896
[Epoch 12; Iter    30/   30] train: loss: 0.6897202
[Epoch 12] ogbg-molclintox: 0.506376 val loss: 0.688958
[Epoch 12] ogbg-molclintox: 0.531951 test loss: 0.685587
[Epoch 13; Iter    30/   30] train: loss: 0.6861423
[Epoch 13] ogbg-molclintox: 0.512694 val loss: 0.688690
[Epoch 13] ogbg-molclintox: 0.532144 test loss: 0.685266
[Epoch 14; Iter    30/   30] train: loss: 0.6859232
[Epoch 14] ogbg-molclintox: 0.525903 val loss: 0.687272
[Epoch 14] ogbg-molclintox: 0.548346 test loss: 0.683967
[Epoch 15; Iter    30/   30] train: loss: 0.6860970
[Epoch 15] ogbg-molclintox: 0.525936 val loss: 0.686287
[Epoch 15] ogbg-molclintox: 0.548536 test loss: 0.683129
[Epoch 16; Iter    30/   30] train: loss: 0.6825150
[Epoch 16] ogbg-molclintox: 0.523570 val loss: 0.685630
[Epoch 16] ogbg-molclintox: 0.544328 test loss: 0.682378
[Epoch 17; Iter    30/   30] train: loss: 0.6817230
[Epoch 17] ogbg-molclintox: 0.533363 val loss: 0.684163
[Epoch 17] ogbg-molclintox: 0.567229 test loss: 0.680669
[Epoch 18; Iter    30/   30] train: loss: 0.6843668
[Epoch 18] ogbg-molclintox: 0.532561 val loss: 0.683147
[Epoch 18] ogbg-molclintox: 0.570054 test loss: 0.679522
[Epoch 19; Iter    30/   30] train: loss: 0.6808163
[Epoch 19] ogbg-molclintox: 0.548532 val loss: 0.681574
[Epoch 19] ogbg-molclintox: 0.568501 test loss: 0.678168
[Epoch 20; Iter    30/   30] train: loss: 0.6791624
[Epoch 20] ogbg-molclintox: 0.541679 val loss: 0.681076
[Epoch 20] ogbg-molclintox: 0.583398 test loss: 0.677372
[Epoch 21; Iter    30/   30] train: loss: 0.6795676
[Epoch 21] ogbg-molclintox: 0.553183 val loss: 0.679326
[Epoch 21] ogbg-molclintox: 0.585454 test loss: 0.675786
[Epoch 22; Iter    30/   30] train: loss: 0.6785652
[Epoch 22] ogbg-molclintox: 0.567081 val loss: 0.678117
[Epoch 22] ogbg-molclintox: 0.583812 test loss: 0.674580
[Epoch 23; Iter    30/   30] train: loss: 0.6725131
[Epoch 23] ogbg-molclintox: 0.607373 val loss: 0.687894
[Epoch 23] ogbg-molclintox: 0.693476 test loss: 0.682112
[Epoch 24; Iter    30/   30] train: loss: 0.6609176
[Epoch 24] ogbg-molclintox: 0.660832 val loss: 0.715732
[Epoch 24] ogbg-molclintox: 0.693826 test loss: 0.704988
[Epoch 25; Iter    30/   30] train: loss: 0.6291072
[Epoch 25] ogbg-molclintox: 0.701636 val loss: 0.672235
[Epoch 25] ogbg-molclintox: 0.747473 test loss: 0.653977
[Epoch 26; Iter    30/   30] train: loss: 0.5742743
[Epoch 26] ogbg-molclintox: 0.746304 val loss: 0.649803
[Epoch 26] ogbg-molclintox: 0.803518 test loss: 0.615209
[Epoch 27; Iter    30/   30] train: loss: 0.5431898
[Epoch 27] ogbg-molclintox: 0.747215 val loss: 0.497247
[Epoch 27] ogbg-molclintox: 0.798616 test loss: 0.484892
[Epoch 28; Iter    30/   30] train: loss: 0.4763102
[Epoch 28] ogbg-molclintox: 0.785665 val loss: 0.500282
[Epoch 28] ogbg-molclintox: 0.842916 test loss: 0.473023
[Epoch 29; Iter    30/   30] train: loss: 0.4097358
[Epoch 29] ogbg-molclintox: 0.819477 val loss: 0.390298
[Epoch 29] ogbg-molclintox: 0.837580 test loss: 0.389803
[Epoch 30; Iter    30/   30] train: loss: 0.3635016
[Epoch 30] ogbg-molclintox: 0.799342 val loss: 0.388134
[Epoch 30] ogbg-molclintox: 0.861319 test loss: 0.347376
[Epoch 31; Iter    30/   30] train: loss: 0.3998141
[Epoch 31] ogbg-molclintox: 0.791635 val loss: 0.444756
[Epoch 31] ogbg-molclintox: 0.810729 test loss: 0.393918
[Epoch 32; Iter    30/   30] train: loss: 0.2317614
[Epoch 32] ogbg-molclintox: 0.805793 val loss: 0.306455
[Epoch 32] ogbg-molclintox: 0.868405 test loss: 0.254356
[Epoch 33; Iter    30/   30] train: loss: 0.2390431
[Epoch 33] ogbg-molclintox: 0.812512 val loss: 0.371399
[Epoch 33] ogbg-molclintox: 0.834307 test loss: 0.322020
[Epoch 34; Iter    30/   30] train: loss: 0.1887315
[Epoch 34] ogbg-molclintox: 0.806829 val loss: 0.374842
[ Using Seed :  6  ]
using device:  cuda:2
Log directory:  runs/split/GraphCL/clintox/scaff/train_prop=0.8/PNA_ogbg-molclintox_GraphCL_clintox_scaff=0.8_6_26-05_09-47-10
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_clintox_scaff=0.8
logdir: runs/split/GraphCL/clintox/scaff/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/   40] train: loss: 0.6939604
[Epoch 1] ogbg-molclintox: 0.403765 val loss: 0.689784
[Epoch 1] ogbg-molclintox: 0.646083 test loss: 0.692462
[Epoch 2; Iter    20/   40] train: loss: 0.6930832
[Epoch 2] ogbg-molclintox: 0.357252 val loss: 0.683971
[Epoch 2] ogbg-molclintox: 0.624729 test loss: 0.688730
[Epoch 3; Iter    10/   40] train: loss: 0.6920408
[Epoch 3; Iter    40/   40] train: loss: 0.6964488
[Epoch 3] ogbg-molclintox: 0.355379 val loss: 0.683406
[Epoch 3] ogbg-molclintox: 0.621524 test loss: 0.688951
[Epoch 4; Iter    30/   40] train: loss: 0.6945525
[Epoch 4] ogbg-molclintox: 0.364270 val loss: 0.683313
[Epoch 4] ogbg-molclintox: 0.621871 test loss: 0.688000
[Epoch 5; Iter    20/   40] train: loss: 0.6928284
[Epoch 5] ogbg-molclintox: 0.374946 val loss: 0.682587
[Epoch 5] ogbg-molclintox: 0.623709 test loss: 0.687441
[Epoch 6; Iter    10/   40] train: loss: 0.6905742
[Epoch 6; Iter    40/   40] train: loss: 0.6904730
[Epoch 6] ogbg-molclintox: 0.351159 val loss: 0.682434
[Epoch 6] ogbg-molclintox: 0.628654 test loss: 0.686939
[Epoch 7; Iter    30/   40] train: loss: 0.6905738
[Epoch 7] ogbg-molclintox: 0.365669 val loss: 0.681943
[Epoch 7] ogbg-molclintox: 0.625793 test loss: 0.686481
[Epoch 8; Iter    20/   40] train: loss: 0.6894931
[Epoch 8] ogbg-molclintox: 0.371288 val loss: 0.680915
[Epoch 8] ogbg-molclintox: 0.626693 test loss: 0.685304
[Epoch 9; Iter    10/   40] train: loss: 0.6896556
[Epoch 9; Iter    40/   40] train: loss: 0.6895282
[Epoch 9] ogbg-molclintox: 0.374422 val loss: 0.678845
[Epoch 9] ogbg-molclintox: 0.617673 test loss: 0.683732
[Epoch 10; Iter    30/   40] train: loss: 0.6884939
[Epoch 10] ogbg-molclintox: 0.388482 val loss: 0.677591
[Epoch 10] ogbg-molclintox: 0.629629 test loss: 0.682679
[Epoch 11; Iter    20/   40] train: loss: 0.6846946
[Epoch 11] ogbg-molclintox: 0.392404 val loss: 0.676830
[Epoch 11] ogbg-molclintox: 0.633888 test loss: 0.681978
[Epoch 12; Iter    10/   40] train: loss: 0.6857284
[Epoch 12; Iter    40/   40] train: loss: 0.6820987
[Epoch 12] ogbg-molclintox: 0.393128 val loss: 0.675110
[Epoch 12] ogbg-molclintox: 0.634089 test loss: 0.680817
[Epoch 13; Iter    30/   40] train: loss: 0.6851407
[Epoch 13] ogbg-molclintox: 0.396037 val loss: 0.673292
[Epoch 13] ogbg-molclintox: 0.633652 test loss: 0.678749
[Epoch 14; Iter    20/   40] train: loss: 0.6791525
[Epoch 14] ogbg-molclintox: 0.396624 val loss: 0.671768
[Epoch 14] ogbg-molclintox: 0.628767 test loss: 0.677019
[Epoch 15; Iter    10/   40] train: loss: 0.6799986
[Epoch 15; Iter    40/   40] train: loss: 0.6758305
[Epoch 15] ogbg-molclintox: 0.406302 val loss: 0.670434
[Epoch 15] ogbg-molclintox: 0.642609 test loss: 0.676418
[Epoch 16; Iter    30/   40] train: loss: 0.6751449
[Epoch 16] ogbg-molclintox: 0.405378 val loss: 0.666858
[Epoch 16] ogbg-molclintox: 0.638262 test loss: 0.673174
[Epoch 17; Iter    20/   40] train: loss: 0.6741731
[Epoch 17] ogbg-molclintox: 0.406826 val loss: 0.664478
[Epoch 17] ogbg-molclintox: 0.641310 test loss: 0.671427
[Epoch 18; Iter    10/   40] train: loss: 0.6707578
[Epoch 18; Iter    40/   40] train: loss: 0.6544307
[Epoch 18] ogbg-molclintox: 0.732304 val loss: 0.665512
[Epoch 18] ogbg-molclintox: 0.714814 test loss: 0.688749
[Epoch 19; Iter    30/   40] train: loss: 0.6279544
[Epoch 19] ogbg-molclintox: 0.707305 val loss: 0.573451
[Epoch 19] ogbg-molclintox: 0.708479 test loss: 0.637622
[Epoch 20; Iter    20/   40] train: loss: 0.6136516
[Epoch 20] ogbg-molclintox: 0.894960 val loss: 0.487512
[Epoch 20] ogbg-molclintox: 0.762193 test loss: 0.554374
[Epoch 21; Iter    10/   40] train: loss: 0.5444769
[Epoch 21; Iter    40/   40] train: loss: 0.4687817
[Epoch 21] ogbg-molclintox: 0.922683 val loss: 0.439673
[Epoch 21] ogbg-molclintox: 0.798593 test loss: 0.474945
[Epoch 22; Iter    30/   40] train: loss: 0.4402296
[Epoch 22] ogbg-molclintox: 0.838370 val loss: 0.400316
[Epoch 22] ogbg-molclintox: 0.783566 test loss: 0.489814
[Epoch 23; Iter    20/   40] train: loss: 0.3978947
[Epoch 23] ogbg-molclintox: 0.792929 val loss: 0.291729
[Epoch 23] ogbg-molclintox: 0.846338 test loss: 0.366278
[Epoch 24; Iter    10/   40] train: loss: 0.3722059
[Epoch 24; Iter    40/   40] train: loss: 0.2685770
[Epoch 24] ogbg-molclintox: 0.902864 val loss: 0.221455
[Epoch 24] ogbg-molclintox: 0.887885 test loss: 0.310620
[Epoch 25; Iter    30/   40] train: loss: 0.2199354
[Epoch 25] ogbg-molclintox: 0.954960 val loss: 0.208610
[Epoch 25] ogbg-molclintox: 0.864850 test loss: 0.283032
[Epoch 26; Iter    20/   40] train: loss: 0.2602497
[Epoch 26] ogbg-molclintox: 0.920620 val loss: 0.284766
[Epoch 26] ogbg-molclintox: 0.823291 test loss: 0.372848
[Epoch 27; Iter    10/   40] train: loss: 0.1999894
[Epoch 27; Iter    40/   40] train: loss: 0.1335052
[Epoch 27] ogbg-molclintox: 0.969470 val loss: 0.144060
[Epoch 27] ogbg-molclintox: 0.831961 test loss: 0.237999
[Epoch 28; Iter    30/   40] train: loss: 0.2335747
[Epoch 28] ogbg-molclintox: 0.859349 val loss: 0.163493
[Epoch 28] ogbg-molclintox: 0.768274 test loss: 0.228672
[Epoch 29; Iter    20/   40] train: loss: 0.2074621
[Epoch 29] ogbg-molclintox: 0.942661 val loss: 0.127252
[Epoch 29] ogbg-molclintox: 0.784616 test loss: 0.208116
[Epoch 30; Iter    10/   40] train: loss: 0.2047492
[Epoch 30; Iter    40/   40] train: loss: 0.1025933
[Epoch 30] ogbg-molclintox: 0.907723 val loss: 0.118636
[Epoch 30] ogbg-molclintox: 0.821591 test loss: 0.197195
[Epoch 31; Iter    30/   40] train: loss: 0.2687601
[Epoch 31] ogbg-molclintox: 0.965523 val loss: 0.114612
[ Using Seed :  5  ]
using device:  cuda:2
Log directory:  runs/split/GraphCL/clintox/scaff/train_prop=0.8/PNA_ogbg-molclintox_GraphCL_clintox_scaff=0.8_5_26-05_09-47-10
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_clintox_scaff=0.8
logdir: runs/split/GraphCL/clintox/scaff/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/   40] train: loss: 0.6942186
[Epoch 1] ogbg-molclintox: 0.462338 val loss: 0.692389
[Epoch 1] ogbg-molclintox: 0.545800 test loss: 0.693097
[Epoch 2; Iter    20/   40] train: loss: 0.6928378
[Epoch 2] ogbg-molclintox: 0.517045 val loss: 0.690763
[Epoch 2] ogbg-molclintox: 0.531106 test loss: 0.694808
[Epoch 3; Iter    10/   40] train: loss: 0.6924217
[Epoch 3; Iter    40/   40] train: loss: 0.6926721
[Epoch 3] ogbg-molclintox: 0.535002 val loss: 0.690142
[Epoch 3] ogbg-molclintox: 0.510651 test loss: 0.695703
[Epoch 4; Iter    30/   40] train: loss: 0.6927174
[Epoch 4] ogbg-molclintox: 0.541795 val loss: 0.689743
[Epoch 4] ogbg-molclintox: 0.510913 test loss: 0.695277
[Epoch 5; Iter    20/   40] train: loss: 0.6921130
[Epoch 5] ogbg-molclintox: 0.537124 val loss: 0.689136
[Epoch 5] ogbg-molclintox: 0.511989 test loss: 0.694738
[Epoch 6; Iter    10/   40] train: loss: 0.6912262
[Epoch 6; Iter    40/   40] train: loss: 0.6911170
[Epoch 6] ogbg-molclintox: 0.526185 val loss: 0.689044
[Epoch 6] ogbg-molclintox: 0.510002 test loss: 0.694375
[Epoch 7; Iter    30/   40] train: loss: 0.6916732
[Epoch 7] ogbg-molclintox: 0.526298 val loss: 0.688108
[Epoch 7] ogbg-molclintox: 0.512650 test loss: 0.693563
[Epoch 8; Iter    20/   40] train: loss: 0.6900567
[Epoch 8] ogbg-molclintox: 0.525011 val loss: 0.686754
[Epoch 8] ogbg-molclintox: 0.507267 test loss: 0.692336
[Epoch 9; Iter    10/   40] train: loss: 0.6901042
[Epoch 9; Iter    40/   40] train: loss: 0.6876632
[Epoch 9] ogbg-molclintox: 0.522028 val loss: 0.686678
[Epoch 9] ogbg-molclintox: 0.506180 test loss: 0.691987
[Epoch 10; Iter    30/   40] train: loss: 0.6898121
[Epoch 10] ogbg-molclintox: 0.544142 val loss: 0.685496
[Epoch 10] ogbg-molclintox: 0.515223 test loss: 0.691364
[Epoch 11; Iter    20/   40] train: loss: 0.6866023
[Epoch 11] ogbg-molclintox: 0.543193 val loss: 0.683703
[Epoch 11] ogbg-molclintox: 0.515810 test loss: 0.689572
[Epoch 12; Iter    10/   40] train: loss: 0.6885810
[Epoch 12; Iter    40/   40] train: loss: 0.6865059
[Epoch 12] ogbg-molclintox: 0.546964 val loss: 0.682835
[Epoch 12] ogbg-molclintox: 0.511989 test loss: 0.688988
[Epoch 13; Iter    30/   40] train: loss: 0.6865133
[Epoch 13] ogbg-molclintox: 0.557615 val loss: 0.681220
[Epoch 13] ogbg-molclintox: 0.515548 test loss: 0.687637
[Epoch 14; Iter    20/   40] train: loss: 0.6825012
[Epoch 14] ogbg-molclintox: 0.546802 val loss: 0.679525
[Epoch 14] ogbg-molclintox: 0.513162 test loss: 0.686067
[Epoch 15; Iter    10/   40] train: loss: 0.6828437
[Epoch 15; Iter    40/   40] train: loss: 0.6827788
[Epoch 15] ogbg-molclintox: 0.553845 val loss: 0.678825
[Epoch 15] ogbg-molclintox: 0.514349 test loss: 0.685593
[Epoch 16; Iter    30/   40] train: loss: 0.6787480
[Epoch 16] ogbg-molclintox: 0.554407 val loss: 0.676420
[Epoch 16] ogbg-molclintox: 0.512512 test loss: 0.683062
[Epoch 17; Iter    20/   40] train: loss: 0.6804053
[Epoch 17] ogbg-molclintox: 0.560999 val loss: 0.675173
[Epoch 17] ogbg-molclintox: 0.513711 test loss: 0.682280
[Epoch 18; Iter    10/   40] train: loss: 0.6765088
[Epoch 18; Iter    40/   40] train: loss: 0.6804767
[Epoch 18] ogbg-molclintox: 0.730456 val loss: 0.673999
[Epoch 18] ogbg-molclintox: 0.716999 test loss: 0.705552
[Epoch 19; Iter    30/   40] train: loss: 0.6407422
[Epoch 19] ogbg-molclintox: 0.858772 val loss: 0.683822
[Epoch 19] ogbg-molclintox: 0.722722 test loss: 0.713937
[Epoch 20; Iter    20/   40] train: loss: 0.5964442
[Epoch 20] ogbg-molclintox: 0.908711 val loss: 0.559918
[Epoch 20] ogbg-molclintox: 0.685156 test loss: 0.590074
[Epoch 21; Iter    10/   40] train: loss: 0.5590362
[Epoch 21; Iter    40/   40] train: loss: 0.4730608
[Epoch 21] ogbg-molclintox: 0.934733 val loss: 0.477496
[Epoch 21] ogbg-molclintox: 0.699646 test loss: 0.526698
[Epoch 22; Iter    30/   40] train: loss: 0.4587640
[Epoch 22] ogbg-molclintox: 0.950515 val loss: 0.353726
[Epoch 22] ogbg-molclintox: 0.819406 test loss: 0.428635
[Epoch 23; Iter    20/   40] train: loss: 0.3348340
[Epoch 23] ogbg-molclintox: 0.846923 val loss: 0.227159
[Epoch 23] ogbg-molclintox: 0.801843 test loss: 0.320861
[Epoch 24; Iter    10/   40] train: loss: 0.2853800
[Epoch 24; Iter    40/   40] train: loss: 0.4837876
[Epoch 24] ogbg-molclintox: 0.919710 val loss: 0.361750
[Epoch 24] ogbg-molclintox: 0.780529 test loss: 0.396580
[Epoch 25; Iter    30/   40] train: loss: 0.2644050
[Epoch 25] ogbg-molclintox: 0.871472 val loss: 0.209893
[Epoch 25] ogbg-molclintox: 0.835147 test loss: 0.326208
[Epoch 26; Iter    20/   40] train: loss: 0.2144746
[Epoch 26] ogbg-molclintox: 0.975651 val loss: 0.294552
[Epoch 26] ogbg-molclintox: 0.803991 test loss: 0.413479
[Epoch 27; Iter    10/   40] train: loss: 0.1950933
[Epoch 27; Iter    40/   40] train: loss: 0.0968612
[Epoch 27] ogbg-molclintox: 0.962702 val loss: 0.151148
[Epoch 27] ogbg-molclintox: 0.858593 test loss: 0.234134
[Epoch 28; Iter    30/   40] train: loss: 0.2578132
[Epoch 28] ogbg-molclintox: 0.918835 val loss: 0.147080
[Epoch 28] ogbg-molclintox: 0.813434 test loss: 0.217948
[Epoch 29; Iter    20/   40] train: loss: 0.1934852
[Epoch 29] ogbg-molclintox: 0.971842 val loss: 0.119780
[Epoch 29] ogbg-molclintox: 0.850174 test loss: 0.209238
[Epoch 30; Iter    10/   40] train: loss: 0.1587804
[Epoch 30; Iter    40/   40] train: loss: 0.2774376
[Epoch 30] ogbg-molclintox: 0.984317 val loss: 0.111408
[Epoch 30] ogbg-molclintox: 0.847824 test loss: 0.195894
[Epoch 31; Iter    30/   40] train: loss: 0.2124465
[Epoch 31] ogbg-molclintox: 0.931409 val loss: 0.107499
[ Using Seed :  4  ]
using device:  cuda:1
Log directory:  runs/split/GraphCL/clintox/scaff/train_prop=0.7/PNA_ogbg-molclintox_GraphCL_clintox_scaff=0.7_4_26-05_09-47-10
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_clintox_scaff=0.7
logdir: runs/split/GraphCL/clintox/scaff/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/   35] train: loss: 0.6924672
[Epoch 1] ogbg-molclintox: 0.461018 val loss: 0.693227
[Epoch 1] ogbg-molclintox: 0.517591 test loss: 0.692312
[Epoch 2; Iter    25/   35] train: loss: 0.6932046
[Epoch 2] ogbg-molclintox: 0.461022 val loss: 0.693160
[Epoch 2] ogbg-molclintox: 0.514655 test loss: 0.690326
[Epoch 3; Iter    20/   35] train: loss: 0.6930591
[Epoch 3] ogbg-molclintox: 0.500314 val loss: 0.692827
[Epoch 3] ogbg-molclintox: 0.536945 test loss: 0.689608
[Epoch 4; Iter    15/   35] train: loss: 0.6920688
[Epoch 4] ogbg-molclintox: 0.501120 val loss: 0.692831
[Epoch 4] ogbg-molclintox: 0.544400 test loss: 0.689739
[Epoch 5; Iter    10/   35] train: loss: 0.6921703
[Epoch 5] ogbg-molclintox: 0.503753 val loss: 0.691815
[Epoch 5] ogbg-molclintox: 0.556736 test loss: 0.688439
[Epoch 6; Iter     5/   35] train: loss: 0.6912168
[Epoch 6; Iter    35/   35] train: loss: 0.6911995
[Epoch 6] ogbg-molclintox: 0.510652 val loss: 0.691600
[Epoch 6] ogbg-molclintox: 0.553005 test loss: 0.688341
[Epoch 7; Iter    30/   35] train: loss: 0.6918086
[Epoch 7] ogbg-molclintox: 0.500350 val loss: 0.691321
[Epoch 7] ogbg-molclintox: 0.552478 test loss: 0.688078
[Epoch 8; Iter    25/   35] train: loss: 0.6914415
[Epoch 8] ogbg-molclintox: 0.516624 val loss: 0.690411
[Epoch 8] ogbg-molclintox: 0.560347 test loss: 0.687249
[Epoch 9; Iter    20/   35] train: loss: 0.6902903
[Epoch 9] ogbg-molclintox: 0.520687 val loss: 0.689957
[Epoch 9] ogbg-molclintox: 0.560755 test loss: 0.687000
[Epoch 10; Iter    15/   35] train: loss: 0.6881520
[Epoch 10] ogbg-molclintox: 0.527743 val loss: 0.689202
[Epoch 10] ogbg-molclintox: 0.567257 test loss: 0.686051
[Epoch 11; Iter    10/   35] train: loss: 0.6871689
[Epoch 11] ogbg-molclintox: 0.517751 val loss: 0.688130
[Epoch 11] ogbg-molclintox: 0.557354 test loss: 0.684753
[Epoch 12; Iter     5/   35] train: loss: 0.6867973
[Epoch 12; Iter    35/   35] train: loss: 0.6874821
[Epoch 12] ogbg-molclintox: 0.523733 val loss: 0.686916
[Epoch 12] ogbg-molclintox: 0.560602 test loss: 0.683722
[Epoch 13; Iter    30/   35] train: loss: 0.6838300
[Epoch 13] ogbg-molclintox: 0.527979 val loss: 0.685762
[Epoch 13] ogbg-molclintox: 0.564015 test loss: 0.682319
[Epoch 14; Iter    25/   35] train: loss: 0.6838685
[Epoch 14] ogbg-molclintox: 0.543528 val loss: 0.684660
[Epoch 14] ogbg-molclintox: 0.574310 test loss: 0.680982
[Epoch 15; Iter    20/   35] train: loss: 0.6833959
[Epoch 15] ogbg-molclintox: 0.533945 val loss: 0.683279
[Epoch 15] ogbg-molclintox: 0.574565 test loss: 0.679820
[Epoch 16; Iter    15/   35] train: loss: 0.6803601
[Epoch 16] ogbg-molclintox: 0.540544 val loss: 0.682106
[Epoch 16] ogbg-molclintox: 0.580619 test loss: 0.678539
[Epoch 17; Iter    10/   35] train: loss: 0.6803457
[Epoch 17] ogbg-molclintox: 0.555908 val loss: 0.680882
[Epoch 17] ogbg-molclintox: 0.595257 test loss: 0.677236
[Epoch 18; Iter     5/   35] train: loss: 0.6789749
[Epoch 18; Iter    35/   35] train: loss: 0.6749383
[Epoch 18] ogbg-molclintox: 0.553086 val loss: 0.679608
[Epoch 18] ogbg-molclintox: 0.599123 test loss: 0.675842
[Epoch 19; Iter    30/   35] train: loss: 0.6754648
[Epoch 19] ogbg-molclintox: 0.561433 val loss: 0.677610
[Epoch 19] ogbg-molclintox: 0.605500 test loss: 0.674004
[Epoch 20; Iter    25/   35] train: loss: 0.6716875
[Epoch 20] ogbg-molclintox: 0.692492 val loss: 0.692259
[Epoch 20] ogbg-molclintox: 0.649877 test loss: 0.685184
[Epoch 21; Iter    20/   35] train: loss: 0.6601140
[Epoch 21] ogbg-molclintox: 0.767717 val loss: 0.684263
[Epoch 21] ogbg-molclintox: 0.671617 test loss: 0.674689
[Epoch 22; Iter    15/   35] train: loss: 0.6386237
[Epoch 22] ogbg-molclintox: 0.782256 val loss: 0.695173
[Epoch 22] ogbg-molclintox: 0.707780 test loss: 0.691970
[Epoch 23; Iter    10/   35] train: loss: 0.5894276
[Epoch 23] ogbg-molclintox: 0.874699 val loss: 0.531587
[Epoch 23] ogbg-molclintox: 0.780785 test loss: 0.543754
[Epoch 24; Iter     5/   35] train: loss: 0.5344643
[Epoch 24; Iter    35/   35] train: loss: 0.5300177
[Epoch 24] ogbg-molclintox: 0.819048 val loss: 0.500293
[Epoch 24] ogbg-molclintox: 0.747803 test loss: 0.496715
[Epoch 25; Iter    30/   35] train: loss: 0.4555801
[Epoch 25] ogbg-molclintox: 0.876074 val loss: 0.408096
[Epoch 25] ogbg-molclintox: 0.758444 test loss: 0.431950
[Epoch 26; Iter    25/   35] train: loss: 0.3874337
[Epoch 26] ogbg-molclintox: 0.928528 val loss: 0.312527
[Epoch 26] ogbg-molclintox: 0.858099 test loss: 0.317470
[Epoch 27; Iter    20/   35] train: loss: 0.3171266
[Epoch 27] ogbg-molclintox: 0.879503 val loss: 0.293926
[Epoch 27] ogbg-molclintox: 0.803008 test loss: 0.284205
[Epoch 28; Iter    15/   35] train: loss: 0.4199892
[Epoch 28] ogbg-molclintox: 0.886140 val loss: 0.259870
[Epoch 28] ogbg-molclintox: 0.831047 test loss: 0.244416
[Epoch 29; Iter    10/   35] train: loss: 0.2437186
[Epoch 29] ogbg-molclintox: 0.899338 val loss: 0.246462
[Epoch 29] ogbg-molclintox: 0.843898 test loss: 0.230426
[Epoch 30; Iter     5/   35] train: loss: 0.2668662
[Epoch 30; Iter    35/   35] train: loss: 0.2225901
[Epoch 30] ogbg-molclintox: 0.885137 val loss: 0.221166
[Epoch 30] ogbg-molclintox: 0.776188 test loss: 0.204015
[Epoch 31; Iter    30/   35] train: loss: 0.2372706
[Epoch 31] ogbg-molclintox: 0.895947 val loss: 0.215272
[Epoch 31] ogbg-molclintox: 0.856484 test loss: 0.181573
[Epoch 32; Iter    25/   35] train: loss: 0.1883419
[Epoch 32] ogbg-molclintox: 0.893645 val loss: 0.224756
[Epoch 32] ogbg-molclintox: 0.831988 test loss: 0.207497
[Epoch 33; Iter    20/   35] train: loss: 0.1975975
[ Using Seed :  6  ]
using device:  cuda:1
Log directory:  runs/split/GraphCL/clintox/scaff/train_prop=0.7/PNA_ogbg-molclintox_GraphCL_clintox_scaff=0.7_6_26-05_09-47-11
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_clintox_scaff=0.7
logdir: runs/split/GraphCL/clintox/scaff/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/   35] train: loss: 0.6896309
[Epoch 1] ogbg-molclintox: 0.512914 val loss: 0.691906
[Epoch 1] ogbg-molclintox: 0.602230 test loss: 0.690583
[Epoch 2; Iter    25/   35] train: loss: 0.6931808
[Epoch 2] ogbg-molclintox: 0.524367 val loss: 0.688948
[Epoch 2] ogbg-molclintox: 0.586618 test loss: 0.685417
[Epoch 3; Iter    20/   35] train: loss: 0.6950068
[Epoch 3] ogbg-molclintox: 0.533932 val loss: 0.687769
[Epoch 3] ogbg-molclintox: 0.571386 test loss: 0.683823
[Epoch 4; Iter    15/   35] train: loss: 0.6942564
[Epoch 4] ogbg-molclintox: 0.534760 val loss: 0.687177
[Epoch 4] ogbg-molclintox: 0.573120 test loss: 0.683192
[Epoch 5; Iter    10/   35] train: loss: 0.6946892
[Epoch 5] ogbg-molclintox: 0.535963 val loss: 0.686599
[Epoch 5] ogbg-molclintox: 0.574300 test loss: 0.682808
[Epoch 6; Iter     5/   35] train: loss: 0.6918714
[Epoch 6; Iter    35/   35] train: loss: 0.6911184
[Epoch 6] ogbg-molclintox: 0.532766 val loss: 0.685406
[Epoch 6] ogbg-molclintox: 0.576227 test loss: 0.681097
[Epoch 7; Iter    30/   35] train: loss: 0.6945115
[Epoch 7] ogbg-molclintox: 0.537163 val loss: 0.685189
[Epoch 7] ogbg-molclintox: 0.581652 test loss: 0.681353
[Epoch 8; Iter    25/   35] train: loss: 0.6917744
[Epoch 8] ogbg-molclintox: 0.541189 val loss: 0.684712
[Epoch 8] ogbg-molclintox: 0.579844 test loss: 0.680373
[Epoch 9; Iter    20/   35] train: loss: 0.6902208
[Epoch 9] ogbg-molclintox: 0.545647 val loss: 0.683618
[Epoch 9] ogbg-molclintox: 0.573670 test loss: 0.679565
[Epoch 10; Iter    15/   35] train: loss: 0.6876462
[Epoch 10] ogbg-molclintox: 0.551368 val loss: 0.683404
[Epoch 10] ogbg-molclintox: 0.583977 test loss: 0.679265
[Epoch 11; Iter    10/   35] train: loss: 0.6895174
[Epoch 11] ogbg-molclintox: 0.548879 val loss: 0.682031
[Epoch 11] ogbg-molclintox: 0.581448 test loss: 0.677675
[Epoch 12; Iter     5/   35] train: loss: 0.6858634
[Epoch 12; Iter    35/   35] train: loss: 0.6840456
[Epoch 12] ogbg-molclintox: 0.547143 val loss: 0.680257
[Epoch 12] ogbg-molclintox: 0.582242 test loss: 0.675849
[Epoch 13; Iter    30/   35] train: loss: 0.6836123
[Epoch 13] ogbg-molclintox: 0.552109 val loss: 0.680108
[Epoch 13] ogbg-molclintox: 0.593172 test loss: 0.675524
[Epoch 14; Iter    25/   35] train: loss: 0.6831928
[Epoch 14] ogbg-molclintox: 0.549410 val loss: 0.678831
[Epoch 14] ogbg-molclintox: 0.591119 test loss: 0.674188
[Epoch 15; Iter    20/   35] train: loss: 0.6833792
[Epoch 15] ogbg-molclintox: 0.552656 val loss: 0.677246
[Epoch 15] ogbg-molclintox: 0.586063 test loss: 0.672846
[Epoch 16; Iter    15/   35] train: loss: 0.6827563
[Epoch 16] ogbg-molclintox: 0.560916 val loss: 0.675856
[Epoch 16] ogbg-molclintox: 0.594413 test loss: 0.671229
[Epoch 17; Iter    10/   35] train: loss: 0.6792097
[Epoch 17] ogbg-molclintox: 0.564460 val loss: 0.675189
[Epoch 17] ogbg-molclintox: 0.584243 test loss: 0.670883
[Epoch 18; Iter     5/   35] train: loss: 0.6781781
[Epoch 18; Iter    35/   35] train: loss: 0.6740807
[Epoch 18] ogbg-molclintox: 0.561572 val loss: 0.673315
[Epoch 18] ogbg-molclintox: 0.601233 test loss: 0.668588
[Epoch 19; Iter    30/   35] train: loss: 0.6738810
[Epoch 19] ogbg-molclintox: 0.564917 val loss: 0.670801
[Epoch 19] ogbg-molclintox: 0.590150 test loss: 0.665960
[Epoch 20; Iter    25/   35] train: loss: 0.6714663
[Epoch 20] ogbg-molclintox: 0.744157 val loss: 0.694884
[Epoch 20] ogbg-molclintox: 0.655603 test loss: 0.689505
[Epoch 21; Iter    20/   35] train: loss: 0.6607186
[Epoch 21] ogbg-molclintox: 0.815940 val loss: 0.664298
[Epoch 21] ogbg-molclintox: 0.687933 test loss: 0.661963
[Epoch 22; Iter    15/   35] train: loss: 0.6184227
[Epoch 22] ogbg-molclintox: 0.837189 val loss: 0.634747
[Epoch 22] ogbg-molclintox: 0.738387 test loss: 0.637648
[Epoch 23; Iter    10/   35] train: loss: 0.5856318
[Epoch 23] ogbg-molclintox: 0.863182 val loss: 0.475426
[Epoch 23] ogbg-molclintox: 0.758994 test loss: 0.477311
[Epoch 24; Iter     5/   35] train: loss: 0.5409558
[Epoch 24; Iter    35/   35] train: loss: 0.4782604
[Epoch 24] ogbg-molclintox: 0.864454 val loss: 0.461405
[Epoch 24] ogbg-molclintox: 0.762458 test loss: 0.452819
[Epoch 25; Iter    30/   35] train: loss: 0.4296883
[Epoch 25] ogbg-molclintox: 0.909356 val loss: 0.415747
[Epoch 25] ogbg-molclintox: 0.780009 test loss: 0.424227
[Epoch 26; Iter    25/   35] train: loss: 0.4189307
[Epoch 26] ogbg-molclintox: 0.774882 val loss: 0.306371
[Epoch 26] ogbg-molclintox: 0.748019 test loss: 0.297100
[Epoch 27; Iter    20/   35] train: loss: 0.2692892
[Epoch 27] ogbg-molclintox: 0.865410 val loss: 0.338608
[Epoch 27] ogbg-molclintox: 0.769039 test loss: 0.335723
[Epoch 28; Iter    15/   35] train: loss: 0.2417315
[Epoch 28] ogbg-molclintox: 0.877807 val loss: 0.265859
[Epoch 28] ogbg-molclintox: 0.793972 test loss: 0.258520
[Epoch 29; Iter    10/   35] train: loss: 0.2665786
[Epoch 29] ogbg-molclintox: 0.811426 val loss: 0.230217
[Epoch 29] ogbg-molclintox: 0.735553 test loss: 0.211382
[Epoch 30; Iter     5/   35] train: loss: 0.2358855
[Epoch 30; Iter    35/   35] train: loss: 0.1905035
[Epoch 30] ogbg-molclintox: 0.898574 val loss: 0.208666
[Epoch 30] ogbg-molclintox: 0.748501 test loss: 0.194257
[Epoch 31; Iter    30/   35] train: loss: 0.2735913
[Epoch 31] ogbg-molclintox: 0.895562 val loss: 0.213770
[Epoch 31] ogbg-molclintox: 0.854556 test loss: 0.193167
[Epoch 32; Iter    25/   35] train: loss: 0.2387252
[Epoch 32] ogbg-molclintox: 0.945801 val loss: 0.195320
[Epoch 32] ogbg-molclintox: 0.901773 test loss: 0.167073
[Epoch 33; Iter    20/   35] train: loss: 0.3066455
[ Using Seed :  5  ]
using device:  cuda:1
Log directory:  runs/split/GraphCL/clintox/scaff/train_prop=0.7/PNA_ogbg-molclintox_GraphCL_clintox_scaff=0.7_5_26-05_09-47-11
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_clintox_scaff=0.7
logdir: runs/split/GraphCL/clintox/scaff/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/   35] train: loss: 0.6938760
[Epoch 1] ogbg-molclintox: 0.487756 val loss: 0.693010
[Epoch 1] ogbg-molclintox: 0.508112 test loss: 0.693000
[Epoch 2; Iter    25/   35] train: loss: 0.6930848
[Epoch 2] ogbg-molclintox: 0.515684 val loss: 0.693048
[Epoch 2] ogbg-molclintox: 0.520198 test loss: 0.692932
[Epoch 3; Iter    20/   35] train: loss: 0.6927063
[Epoch 3] ogbg-molclintox: 0.520698 val loss: 0.692605
[Epoch 3] ogbg-molclintox: 0.509439 test loss: 0.692441
[Epoch 4; Iter    15/   35] train: loss: 0.6926550
[Epoch 4] ogbg-molclintox: 0.524806 val loss: 0.693626
[Epoch 4] ogbg-molclintox: 0.492982 test loss: 0.693575
[Epoch 5; Iter    10/   35] train: loss: 0.6925234
[Epoch 5] ogbg-molclintox: 0.520891 val loss: 0.692190
[Epoch 5] ogbg-molclintox: 0.509269 test loss: 0.691904
[Epoch 6; Iter     5/   35] train: loss: 0.6927680
[Epoch 6; Iter    35/   35] train: loss: 0.6915769
[Epoch 6] ogbg-molclintox: 0.530834 val loss: 0.692294
[Epoch 6] ogbg-molclintox: 0.501973 test loss: 0.691995
[Epoch 7; Iter    30/   35] train: loss: 0.6899028
[Epoch 7] ogbg-molclintox: 0.528446 val loss: 0.692265
[Epoch 7] ogbg-molclintox: 0.501910 test loss: 0.692167
[Epoch 8; Iter    25/   35] train: loss: 0.6915524
[Epoch 8] ogbg-molclintox: 0.540284 val loss: 0.692000
[Epoch 8] ogbg-molclintox: 0.513917 test loss: 0.691651
[Epoch 9; Iter    20/   35] train: loss: 0.6907550
[Epoch 9] ogbg-molclintox: 0.531280 val loss: 0.690354
[Epoch 9] ogbg-molclintox: 0.502182 test loss: 0.690168
[Epoch 10; Iter    15/   35] train: loss: 0.6902019
[Epoch 10] ogbg-molclintox: 0.525649 val loss: 0.690076
[Epoch 10] ogbg-molclintox: 0.500335 test loss: 0.689916
[Epoch 11; Iter    10/   35] train: loss: 0.6879985
[Epoch 11] ogbg-molclintox: 0.537351 val loss: 0.690049
[Epoch 11] ogbg-molclintox: 0.511338 test loss: 0.689823
[Epoch 12; Iter     5/   35] train: loss: 0.6893409
[Epoch 12; Iter    35/   35] train: loss: 0.6866464
[Epoch 12] ogbg-molclintox: 0.537647 val loss: 0.688775
[Epoch 12] ogbg-molclintox: 0.502971 test loss: 0.688442
[Epoch 13; Iter    30/   35] train: loss: 0.6864660
[Epoch 13] ogbg-molclintox: 0.547725 val loss: 0.687415
[Epoch 13] ogbg-molclintox: 0.525924 test loss: 0.686785
[Epoch 14; Iter    25/   35] train: loss: 0.6858284
[Epoch 14] ogbg-molclintox: 0.537783 val loss: 0.686376
[Epoch 14] ogbg-molclintox: 0.505476 test loss: 0.685933
[Epoch 15; Iter    20/   35] train: loss: 0.6834801
[Epoch 15] ogbg-molclintox: 0.543874 val loss: 0.685913
[Epoch 15] ogbg-molclintox: 0.514490 test loss: 0.685244
[Epoch 16; Iter    15/   35] train: loss: 0.6820610
[Epoch 16] ogbg-molclintox: 0.537711 val loss: 0.683904
[Epoch 16] ogbg-molclintox: 0.511718 test loss: 0.683423
[Epoch 17; Iter    10/   35] train: loss: 0.6834190
[Epoch 17] ogbg-molclintox: 0.553942 val loss: 0.683444
[Epoch 17] ogbg-molclintox: 0.520584 test loss: 0.682657
[Epoch 18; Iter     5/   35] train: loss: 0.6797612
[Epoch 18; Iter    35/   35] train: loss: 0.6822080
[Epoch 18] ogbg-molclintox: 0.542823 val loss: 0.682315
[Epoch 18] ogbg-molclintox: 0.516497 test loss: 0.681711
[Epoch 19; Iter    30/   35] train: loss: 0.6788809
[Epoch 19] ogbg-molclintox: 0.557285 val loss: 0.681370
[Epoch 19] ogbg-molclintox: 0.520749 test loss: 0.680501
[Epoch 20; Iter    25/   35] train: loss: 0.6761647
[Epoch 20] ogbg-molclintox: 0.697248 val loss: 0.687694
[Epoch 20] ogbg-molclintox: 0.606164 test loss: 0.686254
[Epoch 21; Iter    20/   35] train: loss: 0.6635399
[Epoch 21] ogbg-molclintox: 0.749105 val loss: 0.666097
[Epoch 21] ogbg-molclintox: 0.678732 test loss: 0.658289
[Epoch 22; Iter    15/   35] train: loss: 0.6293572
[Epoch 22] ogbg-molclintox: 0.819367 val loss: 0.655522
[Epoch 22] ogbg-molclintox: 0.738302 test loss: 0.650721
[Epoch 23; Iter    10/   35] train: loss: 0.5892742
[Epoch 23] ogbg-molclintox: 0.855929 val loss: 0.512147
[Epoch 23] ogbg-molclintox: 0.787673 test loss: 0.521501
[Epoch 24; Iter     5/   35] train: loss: 0.5357233
[Epoch 24; Iter    35/   35] train: loss: 0.4674593
[Epoch 24] ogbg-molclintox: 0.863775 val loss: 0.491752
[Epoch 24] ogbg-molclintox: 0.784300 test loss: 0.496681
[Epoch 25; Iter    30/   35] train: loss: 0.4228621
[Epoch 25] ogbg-molclintox: 0.872543 val loss: 0.512878
[Epoch 25] ogbg-molclintox: 0.804556 test loss: 0.528568
[Epoch 26; Iter    25/   35] train: loss: 0.3312604
[Epoch 26] ogbg-molclintox: 0.893582 val loss: 0.332757
[Epoch 26] ogbg-molclintox: 0.781976 test loss: 0.319199
[Epoch 27; Iter    20/   35] train: loss: 0.3302891
[Epoch 27] ogbg-molclintox: 0.889274 val loss: 0.305548
[Epoch 27] ogbg-molclintox: 0.850401 test loss: 0.288682
[Epoch 28; Iter    15/   35] train: loss: 0.3073174
[Epoch 28] ogbg-molclintox: 0.878534 val loss: 0.259081
[Epoch 28] ogbg-molclintox: 0.796772 test loss: 0.239158
[Epoch 29; Iter    10/   35] train: loss: 0.2629743
[Epoch 29] ogbg-molclintox: 0.918000 val loss: 0.250407
[Epoch 29] ogbg-molclintox: 0.836551 test loss: 0.242383
[Epoch 30; Iter     5/   35] train: loss: 0.2910685
[Epoch 30; Iter    35/   35] train: loss: 0.1209074
[Epoch 30] ogbg-molclintox: 0.876047 val loss: 0.266277
[Epoch 30] ogbg-molclintox: 0.824153 test loss: 0.254210
[Epoch 31; Iter    30/   35] train: loss: 0.1405086
[Epoch 31] ogbg-molclintox: 0.926424 val loss: 0.200745
[Epoch 31] ogbg-molclintox: 0.840882 test loss: 0.183519
[Epoch 32; Iter    25/   35] train: loss: 0.2562634
[Epoch 32] ogbg-molclintox: 0.901643 val loss: 0.220148
[Epoch 32] ogbg-molclintox: 0.790258 test loss: 0.218611
[Epoch 33; Iter    20/   35] train: loss: 0.1355601
[ Using Seed :  6  ]
using device:  cuda:0
Log directory:  runs/split/GraphCL/clintox/scaff/train_prop=0.6/PNA_ogbg-molclintox_GraphCL_clintox_scaff=0.6_6_26-05_09-47-10
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/clintox/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_clintox_scaff=0.6
logdir: runs/split/GraphCL/clintox/scaff/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/   30] train: loss: 0.6924642
[Epoch 1] ogbg-molclintox: 0.497630 val loss: 0.691012
[Epoch 1] ogbg-molclintox: 0.563671 test loss: 0.691048
[Epoch 2; Iter    30/   30] train: loss: 0.6926506
[Epoch 2] ogbg-molclintox: 0.501081 val loss: 0.687064
[Epoch 2] ogbg-molclintox: 0.538722 test loss: 0.687044
[Epoch 3; Iter    30/   30] train: loss: 0.6919362
[Epoch 3] ogbg-molclintox: 0.521732 val loss: 0.685435
[Epoch 3] ogbg-molclintox: 0.527693 test loss: 0.685333
[Epoch 4; Iter    30/   30] train: loss: 0.6926177
[Epoch 4] ogbg-molclintox: 0.531466 val loss: 0.683524
[Epoch 4] ogbg-molclintox: 0.524627 test loss: 0.683470
[Epoch 5; Iter    30/   30] train: loss: 0.6949190
[Epoch 5] ogbg-molclintox: 0.531318 val loss: 0.683163
[Epoch 5] ogbg-molclintox: 0.527812 test loss: 0.683156
[Epoch 6; Iter    30/   30] train: loss: 0.6917731
[Epoch 6] ogbg-molclintox: 0.530684 val loss: 0.682588
[Epoch 6] ogbg-molclintox: 0.526274 test loss: 0.682439
[Epoch 7; Iter    30/   30] train: loss: 0.6936369
[Epoch 7] ogbg-molclintox: 0.531305 val loss: 0.682110
[Epoch 7] ogbg-molclintox: 0.527390 test loss: 0.681897
[Epoch 8; Iter    30/   30] train: loss: 0.6889831
[Epoch 8] ogbg-molclintox: 0.536232 val loss: 0.682293
[Epoch 8] ogbg-molclintox: 0.530858 test loss: 0.682007
[Epoch 9; Iter    30/   30] train: loss: 0.6897148
[Epoch 9] ogbg-molclintox: 0.531606 val loss: 0.681752
[Epoch 9] ogbg-molclintox: 0.528671 test loss: 0.681539
[Epoch 10; Iter    30/   30] train: loss: 0.6909397
[Epoch 10] ogbg-molclintox: 0.533097 val loss: 0.680936
[Epoch 10] ogbg-molclintox: 0.537415 test loss: 0.680656
[Epoch 11; Iter    30/   30] train: loss: 0.6898791
[Epoch 11] ogbg-molclintox: 0.532682 val loss: 0.679835
[Epoch 11] ogbg-molclintox: 0.530674 test loss: 0.679511
[Epoch 12; Iter    30/   30] train: loss: 0.6930020
[Epoch 12] ogbg-molclintox: 0.543192 val loss: 0.680419
[Epoch 12] ogbg-molclintox: 0.527401 test loss: 0.680026
[Epoch 13; Iter    30/   30] train: loss: 0.6858683
[Epoch 13] ogbg-molclintox: 0.538438 val loss: 0.679347
[Epoch 13] ogbg-molclintox: 0.534185 test loss: 0.679113
[Epoch 14; Iter    30/   30] train: loss: 0.6880980
[Epoch 14] ogbg-molclintox: 0.535476 val loss: 0.676741
[Epoch 14] ogbg-molclintox: 0.533564 test loss: 0.676453
[Epoch 15; Iter    30/   30] train: loss: 0.6859633
[Epoch 15] ogbg-molclintox: 0.546547 val loss: 0.676940
[Epoch 15] ogbg-molclintox: 0.541843 test loss: 0.676639
[Epoch 16; Iter    30/   30] train: loss: 0.6842268
[Epoch 16] ogbg-molclintox: 0.541661 val loss: 0.675412
[Epoch 16] ogbg-molclintox: 0.541285 test loss: 0.675051
[Epoch 17; Iter    30/   30] train: loss: 0.6821877
[Epoch 17] ogbg-molclintox: 0.541668 val loss: 0.674134
[Epoch 17] ogbg-molclintox: 0.532867 test loss: 0.673676
[Epoch 18; Iter    30/   30] train: loss: 0.6790787
[Epoch 18] ogbg-molclintox: 0.550030 val loss: 0.674009
[Epoch 18] ogbg-molclintox: 0.540775 test loss: 0.673593
[Epoch 19; Iter    30/   30] train: loss: 0.6782957
[Epoch 19] ogbg-molclintox: 0.546467 val loss: 0.672351
[Epoch 19] ogbg-molclintox: 0.551459 test loss: 0.671867
[Epoch 20; Iter    30/   30] train: loss: 0.6756687
[Epoch 20] ogbg-molclintox: 0.550284 val loss: 0.671740
[Epoch 20] ogbg-molclintox: 0.549470 test loss: 0.671445
[Epoch 21; Iter    30/   30] train: loss: 0.6745341
[Epoch 21] ogbg-molclintox: 0.553199 val loss: 0.669753
[Epoch 21] ogbg-molclintox: 0.556248 test loss: 0.669398
[Epoch 22; Iter    30/   30] train: loss: 0.6768222
[Epoch 22] ogbg-molclintox: 0.548646 val loss: 0.668096
[Epoch 22] ogbg-molclintox: 0.556486 test loss: 0.667631
[Epoch 23; Iter    30/   30] train: loss: 0.6719500
[Epoch 23] ogbg-molclintox: 0.643015 val loss: 0.680693
[Epoch 23] ogbg-molclintox: 0.637117 test loss: 0.680062
[Epoch 24; Iter    30/   30] train: loss: 0.6614099
[Epoch 24] ogbg-molclintox: 0.694610 val loss: 0.681877
[Epoch 24] ogbg-molclintox: 0.725350 test loss: 0.676112
[Epoch 25; Iter    30/   30] train: loss: 0.6260518
[Epoch 25] ogbg-molclintox: 0.751672 val loss: 0.675231
[Epoch 25] ogbg-molclintox: 0.790414 test loss: 0.661526
[Epoch 26; Iter    30/   30] train: loss: 0.5644742
[Epoch 26] ogbg-molclintox: 0.738322 val loss: 0.634953
[Epoch 26] ogbg-molclintox: 0.760712 test loss: 0.618186
[Epoch 27; Iter    30/   30] train: loss: 0.5363598
[Epoch 27] ogbg-molclintox: 0.768953 val loss: 0.566022
[Epoch 27] ogbg-molclintox: 0.800011 test loss: 0.543911
[Epoch 28; Iter    30/   30] train: loss: 0.4635278
[Epoch 28] ogbg-molclintox: 0.800399 val loss: 0.397937
[Epoch 28] ogbg-molclintox: 0.839456 test loss: 0.366312
[Epoch 29; Iter    30/   30] train: loss: 0.4173655
[Epoch 29] ogbg-molclintox: 0.781059 val loss: 0.453584
[Epoch 29] ogbg-molclintox: 0.803278 test loss: 0.431898
[Epoch 30; Iter    30/   30] train: loss: 0.3551816
[Epoch 30] ogbg-molclintox: 0.827766 val loss: 0.427641
[Epoch 30] ogbg-molclintox: 0.875267 test loss: 0.403060
[Epoch 31; Iter    30/   30] train: loss: 0.3226017
[Epoch 31] ogbg-molclintox: 0.876243 val loss: 0.265189
[Epoch 31] ogbg-molclintox: 0.897034 test loss: 0.258989
[Epoch 32; Iter    30/   30] train: loss: 0.2237021
[Epoch 32] ogbg-molclintox: 0.803239 val loss: 0.355128
[Epoch 32] ogbg-molclintox: 0.809995 test loss: 0.365469
[Epoch 33; Iter    30/   30] train: loss: 0.2021866
[Epoch 33] ogbg-molclintox: 0.836932 val loss: 0.291265
[Epoch 33] ogbg-molclintox: 0.857613 test loss: 0.293457
[Epoch 34; Iter    30/   30] train: loss: 0.2944023
[Epoch 34] ogbg-molclintox: 0.835280 val loss: 0.258071
[Epoch 31] ogbg-molclintox: 0.764277 test loss: 0.208777
[Epoch 32; Iter    20/   40] train: loss: 0.2018348
[Epoch 32] ogbg-molclintox: 0.940412 val loss: 0.116561
[Epoch 32] ogbg-molclintox: 0.882327 test loss: 0.188560
[Epoch 33; Iter    10/   40] train: loss: 0.0825539
[Epoch 33; Iter    40/   40] train: loss: 0.1460862
[Epoch 33] ogbg-molclintox: 0.971880 val loss: 0.102980
[Epoch 33] ogbg-molclintox: 0.865537 test loss: 0.186093
[Epoch 34; Iter    30/   40] train: loss: 0.0957851
[Epoch 34] ogbg-molclintox: 0.951214 val loss: 0.140083
[Epoch 34] ogbg-molclintox: 0.824277 test loss: 0.236728
[Epoch 35; Iter    20/   40] train: loss: 0.2241222
[Epoch 35] ogbg-molclintox: 0.907984 val loss: 0.124945
[Epoch 35] ogbg-molclintox: 0.836021 test loss: 0.275135
[Epoch 36; Iter    10/   40] train: loss: 0.1396085
[Epoch 36; Iter    40/   40] train: loss: 0.2914232
[Epoch 36] ogbg-molclintox: 0.916126 val loss: 0.107221
[Epoch 36] ogbg-molclintox: 0.767762 test loss: 0.340533
[Epoch 37; Iter    30/   40] train: loss: 0.2241822
[Epoch 37] ogbg-molclintox: 0.909020 val loss: 0.113019
[Epoch 37] ogbg-molclintox: 0.841788 test loss: 0.188857
[Epoch 38; Iter    20/   40] train: loss: 0.0587421
[Epoch 38] ogbg-molclintox: 0.968408 val loss: 0.096694
[Epoch 38] ogbg-molclintox: 0.869097 test loss: 0.170143
[Epoch 39; Iter    10/   40] train: loss: 0.0993847
[Epoch 39; Iter    40/   40] train: loss: 0.1008605
[Epoch 39] ogbg-molclintox: 0.973465 val loss: 0.090320
[Epoch 39] ogbg-molclintox: 0.847036 test loss: 0.209215
[Epoch 40; Iter    30/   40] train: loss: 0.1393874
[Epoch 40] ogbg-molclintox: 0.922694 val loss: 0.093910
[Epoch 40] ogbg-molclintox: 0.828734 test loss: 0.170765
[Epoch 41; Iter    20/   40] train: loss: 0.0620950
[Epoch 41] ogbg-molclintox: 0.974302 val loss: 0.085602
[Epoch 41] ogbg-molclintox: 0.881013 test loss: 0.224347
[Epoch 42; Iter    10/   40] train: loss: 0.0985084
[Epoch 42; Iter    40/   40] train: loss: 0.0951557
[Epoch 42] ogbg-molclintox: 0.961078 val loss: 0.085423
[Epoch 42] ogbg-molclintox: 0.879178 test loss: 0.189650
[Epoch 43; Iter    30/   40] train: loss: 0.0787806
[Epoch 43] ogbg-molclintox: 0.908982 val loss: 0.094453
[Epoch 43] ogbg-molclintox: 0.878928 test loss: 0.193879
[Epoch 44; Iter    20/   40] train: loss: 0.0736350
[Epoch 44] ogbg-molclintox: 0.994630 val loss: 0.054883
[Epoch 44] ogbg-molclintox: 0.877737 test loss: 0.164612
[Epoch 45; Iter    10/   40] train: loss: 0.1252571
[Epoch 45; Iter    40/   40] train: loss: 0.0426074
[Epoch 45] ogbg-molclintox: 0.985740 val loss: 0.105519
[Epoch 45] ogbg-molclintox: 0.831908 test loss: 0.185972
[Epoch 46; Iter    30/   40] train: loss: 0.0448932
[Epoch 46] ogbg-molclintox: 0.980370 val loss: 0.062060
[Epoch 46] ogbg-molclintox: 0.895218 test loss: 0.176407
[Epoch 47; Iter    20/   40] train: loss: 0.1261697
[Epoch 47] ogbg-molclintox: 0.998601 val loss: 0.072223
[Epoch 47] ogbg-molclintox: 0.889234 test loss: 0.210827
[Epoch 48; Iter    10/   40] train: loss: 0.0374776
[Epoch 48; Iter    40/   40] train: loss: 0.0505906
[Epoch 48] ogbg-molclintox: 1.000000 val loss: 0.073077
[Epoch 48] ogbg-molclintox: 0.869246 test loss: 0.177460
[Epoch 49; Iter    30/   40] train: loss: 0.0906236
[Epoch 49] ogbg-molclintox: 0.942636 val loss: 0.145869
[Epoch 49] ogbg-molclintox: 0.812235 test loss: 0.217010
[Epoch 50; Iter    20/   40] train: loss: 0.1397348
[Epoch 50] ogbg-molclintox: 0.981857 val loss: 0.067185
[Epoch 50] ogbg-molclintox: 0.812758 test loss: 0.174756
[Epoch 51; Iter    10/   40] train: loss: 0.1173059
[Epoch 51; Iter    40/   40] train: loss: 0.0219361
[Epoch 51] ogbg-molclintox: 0.984478 val loss: 0.058487
[Epoch 51] ogbg-molclintox: 0.844638 test loss: 0.172014
[Epoch 52; Iter    30/   40] train: loss: 0.0703861
[Epoch 52] ogbg-molclintox: 0.996254 val loss: 0.051276
[Epoch 52] ogbg-molclintox: 0.786876 test loss: 0.204818
[Epoch 53; Iter    20/   40] train: loss: 0.0521784
[Epoch 53] ogbg-molclintox: 0.996142 val loss: 0.049344
[Epoch 53] ogbg-molclintox: 0.863165 test loss: 0.163316
[Epoch 54; Iter    10/   40] train: loss: 0.0274387
[Epoch 54; Iter    40/   40] train: loss: 0.0583106
[Epoch 54] ogbg-molclintox: 0.992283 val loss: 0.059729
[Epoch 54] ogbg-molclintox: 0.835158 test loss: 0.186783
[Epoch 55; Iter    30/   40] train: loss: 0.1894451
[Epoch 55] ogbg-molclintox: 0.979509 val loss: 0.070263
[Epoch 55] ogbg-molclintox: 0.842890 test loss: 0.203485
[Epoch 56; Iter    20/   40] train: loss: 0.0844222
[Epoch 56] ogbg-molclintox: 0.954710 val loss: 0.087923
[Epoch 56] ogbg-molclintox: 0.857405 test loss: 0.154945
[Epoch 57; Iter    10/   40] train: loss: 0.1039934
[Epoch 57; Iter    40/   40] train: loss: 0.0313361
[Epoch 57] ogbg-molclintox: 0.947717 val loss: 0.112429
[Epoch 57] ogbg-molclintox: 0.851444 test loss: 0.166543
[Epoch 58; Iter    30/   40] train: loss: 0.0897403
[Epoch 58] ogbg-molclintox: 0.997902 val loss: 0.056382
[Epoch 58] ogbg-molclintox: 0.844888 test loss: 0.183987
[Epoch 59; Iter    20/   40] train: loss: 0.0302594
[Epoch 59] ogbg-molclintox: 0.990161 val loss: 0.057188
[Epoch 59] ogbg-molclintox: 0.830298 test loss: 0.202033
[Epoch 60; Iter    10/   40] train: loss: 0.1214896
[Epoch 60; Iter    40/   40] train: loss: 0.2629426
[Epoch 60] ogbg-molclintox: 0.978086 val loss: 0.074091
[Epoch 60] ogbg-molclintox: 0.839816 test loss: 0.187953
[Epoch 61; Iter    30/   40] train: loss: 0.1324163
[Epoch 61] ogbg-molclintox: 0.926152 val loss: 0.074593
[Epoch 61] ogbg-molclintox: 0.887848 test loss: 0.160923
[Epoch 62; Iter    20/   40] train: loss: 0.0581530
[Epoch 62] ogbg-molclintox: 0.946993 val loss: 0.083934
[Epoch 62] ogbg-molclintox: 0.869997 test loss: 0.169179
[Epoch 63; Iter    10/   40] train: loss: 0.0431822
[Epoch 63; Iter    40/   40] train: loss: 0.0190334
[Epoch 63] ogbg-molclintox: 0.973802 val loss: 0.072475
[Epoch 63] ogbg-molclintox: 0.783391 test loss: 0.203841
[Epoch 64; Iter    30/   40] train: loss: 0.1627322
[Epoch 64] ogbg-molclintox: 0.946769 val loss: 0.098559
[Epoch 64] ogbg-molclintox: 0.841403 test loss: 0.189255
[Epoch 65; Iter    20/   40] train: loss: 0.0168990
[Epoch 65] ogbg-molclintox: 0.944534 val loss: 0.109159
[Epoch 65] ogbg-molclintox: 0.819702 test loss: 0.184779
[Epoch 66; Iter    10/   40] train: loss: 0.0463108
[Epoch 66; Iter    40/   40] train: loss: 0.0218432
[Epoch 66] ogbg-molclintox: 0.969357 val loss: 0.097890
[Epoch 66] ogbg-molclintox: 0.705753 test loss: 0.237031
[Epoch 67; Iter    30/   40] train: loss: 0.1085787
[Epoch 67] ogbg-molclintox: 0.980683 val loss: 0.067883
[Epoch 67] ogbg-molclintox: 0.837056 test loss: 0.184310
[Epoch 68; Iter    20/   40] train: loss: 0.1661635
[Epoch 68] ogbg-molclintox: 0.957694 val loss: 0.074411
[Epoch 68] ogbg-molclintox: 0.839117 test loss: 0.190522
[Epoch 69; Iter    10/   40] train: loss: 0.0546087
[Epoch 69; Iter    40/   40] train: loss: 0.1368582
[Epoch 69] ogbg-molclintox: 0.957058 val loss: 0.146919
[Epoch 69] ogbg-molclintox: 0.771311 test loss: 0.227807
[Epoch 70; Iter    30/   40] train: loss: 0.0670712
[Epoch 70] ogbg-molclintox: 0.970056 val loss: 0.084889
[Epoch 70] ogbg-molclintox: 0.842315 test loss: 0.192400
[Epoch 71; Iter    20/   40] train: loss: 0.0716703
[Epoch 71] ogbg-molclintox: 0.983730 val loss: 0.075409
[Epoch 71] ogbg-molclintox: 0.814408 test loss: 0.220062
[Epoch 72; Iter    10/   40] train: loss: 0.0192509
[Epoch 72; Iter    40/   40] train: loss: 0.0502482
[Epoch 72] ogbg-molclintox: 0.983730 val loss: 0.064461
[Epoch 72] ogbg-molclintox: 0.835095 test loss: 0.212283
[Epoch 73; Iter    30/   40] train: loss: 0.1652988
[Epoch 73] ogbg-molclintox: 0.977299 val loss: 0.065996
[Epoch 73] ogbg-molclintox: 0.795157 test loss: 0.199081
[Epoch 74; Iter    20/   40] train: loss: 0.0162839
[Epoch 74] ogbg-molclintox: 0.982556 val loss: 0.076329
[Epoch 74] ogbg-molclintox: 0.826675 test loss: 0.216603
[Epoch 75; Iter    10/   40] train: loss: 0.0487777
[Epoch 75; Iter    40/   40] train: loss: 0.0560513
[Epoch 75] ogbg-molclintox: 0.990161 val loss: 0.053590
[Epoch 75] ogbg-molclintox: 0.841478 test loss: 0.203596
[Epoch 76; Iter    30/   40] train: loss: 0.0148007
[Epoch 34] ogbg-molclintox: 0.842938 test loss: 0.208569
[Epoch 35; Iter    30/   30] train: loss: 0.2614519
[Epoch 35] ogbg-molclintox: 0.795966 val loss: 0.310442
[Epoch 35] ogbg-molclintox: 0.846374 test loss: 0.239166
[Epoch 36; Iter    30/   30] train: loss: 0.4875644
[Epoch 36] ogbg-molclintox: 0.838216 val loss: 0.206654
[Epoch 36] ogbg-molclintox: 0.845001 test loss: 0.176032
[Epoch 37; Iter    30/   30] train: loss: 0.2784549
[Epoch 37] ogbg-molclintox: 0.819885 val loss: 0.239316
[Epoch 37] ogbg-molclintox: 0.862304 test loss: 0.208312
[Epoch 38; Iter    30/   30] train: loss: 0.1580717
[Epoch 38] ogbg-molclintox: 0.822692 val loss: 0.268201
[Epoch 38] ogbg-molclintox: 0.877941 test loss: 0.210266
[Epoch 39; Iter    30/   30] train: loss: 0.2743159
[Epoch 39] ogbg-molclintox: 0.822144 val loss: 0.247914
[Epoch 39] ogbg-molclintox: 0.866883 test loss: 0.203030
[Epoch 40; Iter    30/   30] train: loss: 0.1101671
[Epoch 40] ogbg-molclintox: 0.785190 val loss: 0.279489
[Epoch 40] ogbg-molclintox: 0.819796 test loss: 0.238246
[Epoch 41; Iter    30/   30] train: loss: 0.1795405
[Epoch 41] ogbg-molclintox: 0.844365 val loss: 0.227220
[Epoch 41] ogbg-molclintox: 0.881305 test loss: 0.194721
[Epoch 42; Iter    30/   30] train: loss: 0.0985715
[Epoch 42] ogbg-molclintox: 0.853630 val loss: 0.230491
[Epoch 42] ogbg-molclintox: 0.894846 test loss: 0.173689
[Epoch 43; Iter    30/   30] train: loss: 0.1612907
[Epoch 43] ogbg-molclintox: 0.860636 val loss: 0.230492
[Epoch 43] ogbg-molclintox: 0.883655 test loss: 0.186651
[Epoch 44; Iter    30/   30] train: loss: 0.1341819
[Epoch 44] ogbg-molclintox: 0.865376 val loss: 0.200325
[Epoch 44] ogbg-molclintox: 0.897165 test loss: 0.153108
[Epoch 45; Iter    30/   30] train: loss: 0.1073644
[Epoch 45] ogbg-molclintox: 0.861919 val loss: 0.274330
[Epoch 45] ogbg-molclintox: 0.909940 test loss: 0.205966
[Epoch 46; Iter    30/   30] train: loss: 0.0645937
[Epoch 46] ogbg-molclintox: 0.866218 val loss: 0.220197
[Epoch 46] ogbg-molclintox: 0.917094 test loss: 0.157109
[Epoch 47; Iter    30/   30] train: loss: 0.2120302
[Epoch 47] ogbg-molclintox: 0.870135 val loss: 0.211006
[Epoch 47] ogbg-molclintox: 0.906587 test loss: 0.161892
[Epoch 48; Iter    30/   30] train: loss: 0.1864235
[Epoch 48] ogbg-molclintox: 0.827312 val loss: 0.294282
[Epoch 48] ogbg-molclintox: 0.873071 test loss: 0.244401
[Epoch 49; Iter    30/   30] train: loss: 0.1227667
[Epoch 49] ogbg-molclintox: 0.822130 val loss: 0.233339
[Epoch 49] ogbg-molclintox: 0.786923 test loss: 0.412640
[Epoch 50; Iter    30/   30] train: loss: 0.1775812
[Epoch 50] ogbg-molclintox: 0.843957 val loss: 0.288827
[Epoch 50] ogbg-molclintox: 0.825036 test loss: 0.249593
[Epoch 51; Iter    30/   30] train: loss: 0.1243293
[Epoch 51] ogbg-molclintox: 0.873658 val loss: 0.189745
[Epoch 51] ogbg-molclintox: 0.888322 test loss: 0.168560
[Epoch 52; Iter    30/   30] train: loss: 0.2691966
[Epoch 52] ogbg-molclintox: 0.913085 val loss: 0.205591
[Epoch 52] ogbg-molclintox: 0.896246 test loss: 0.200786
[Epoch 53; Iter    30/   30] train: loss: 0.1574228
[Epoch 53] ogbg-molclintox: 0.827865 val loss: 0.982735
[Epoch 53] ogbg-molclintox: 0.832224 test loss: 1.586864
[Epoch 54; Iter    30/   30] train: loss: 0.0759516
[Epoch 54] ogbg-molclintox: 0.906594 val loss: 0.203462
[Epoch 54] ogbg-molclintox: 0.940250 test loss: 0.171016
[Epoch 55; Iter    30/   30] train: loss: 0.2669725
[Epoch 55] ogbg-molclintox: 0.922752 val loss: 0.152513
[Epoch 55] ogbg-molclintox: 0.947705 test loss: 0.125115
[Epoch 56; Iter    30/   30] train: loss: 0.1236426
[Epoch 56] ogbg-molclintox: 0.779796 val loss: 0.351269
[Epoch 56] ogbg-molclintox: 0.753686 test loss: 0.307051
[Epoch 57; Iter    30/   30] train: loss: 0.1324326
[Epoch 57] ogbg-molclintox: 0.931542 val loss: 0.136152
[Epoch 57] ogbg-molclintox: 0.932420 test loss: 0.314323
[Epoch 58; Iter    30/   30] train: loss: 0.0743372
[Epoch 58] ogbg-molclintox: 0.872413 val loss: 0.339201
[Epoch 58] ogbg-molclintox: 0.898549 test loss: 0.263820
[Epoch 59; Iter    30/   30] train: loss: 0.1709074
[Epoch 59] ogbg-molclintox: 0.905057 val loss: 0.181510
[Epoch 59] ogbg-molclintox: 0.884437 test loss: 0.170129
[Epoch 60; Iter    30/   30] train: loss: 0.1445810
[Epoch 60] ogbg-molclintox: 0.845696 val loss: 0.335710
[Epoch 60] ogbg-molclintox: 0.871309 test loss: 0.645608
[Epoch 61; Iter    30/   30] train: loss: 0.0773968
[Epoch 61] ogbg-molclintox: 0.889475 val loss: 0.199517
[Epoch 61] ogbg-molclintox: 0.920086 test loss: 0.148176
[Epoch 62; Iter    30/   30] train: loss: 0.0541939
[Epoch 62] ogbg-molclintox: 0.830975 val loss: 0.518050
[Epoch 62] ogbg-molclintox: 0.800182 test loss: 0.207804
[Epoch 63; Iter    30/   30] train: loss: 0.1757290
[Epoch 63] ogbg-molclintox: 0.877823 val loss: 0.411987
[Epoch 63] ogbg-molclintox: 0.904622 test loss: 0.177576
[Epoch 64; Iter    30/   30] train: loss: 0.0754931
[Epoch 64] ogbg-molclintox: 0.877254 val loss: 0.246800
[Epoch 64] ogbg-molclintox: 0.912293 test loss: 0.196905
[Epoch 65; Iter    30/   30] train: loss: 0.0614366
[Epoch 65] ogbg-molclintox: 0.921227 val loss: 0.196143
[Epoch 65] ogbg-molclintox: 0.924120 test loss: 0.169988
[Epoch 66; Iter    30/   30] train: loss: 0.0222047
[Epoch 66] ogbg-molclintox: 0.882910 val loss: 0.185580
[Epoch 66] ogbg-molclintox: 0.887530 test loss: 0.167995
[Epoch 67; Iter    30/   30] train: loss: 0.1880171
[Epoch 67] ogbg-molclintox: 0.911342 val loss: 0.160835
[Epoch 67] ogbg-molclintox: 0.927507 test loss: 0.147110
[Epoch 68; Iter    30/   30] train: loss: 0.0954398
[Epoch 68] ogbg-molclintox: 0.891059 val loss: 0.194069
[Epoch 68] ogbg-molclintox: 0.893961 test loss: 0.192121
[Epoch 69; Iter    30/   30] train: loss: 0.0864771
[Epoch 69] ogbg-molclintox: 0.883185 val loss: 0.167358
[Epoch 69] ogbg-molclintox: 0.864423 test loss: 0.167728
[Epoch 70; Iter    30/   30] train: loss: 0.1605357
[Epoch 70] ogbg-molclintox: 0.901775 val loss: 0.149752
[Epoch 70] ogbg-molclintox: 0.920085 test loss: 0.145602
[Epoch 71; Iter    30/   30] train: loss: 0.3117389
[Epoch 71] ogbg-molclintox: 0.860202 val loss: 0.216771
[Epoch 71] ogbg-molclintox: 0.882509 test loss: 0.185564
[Epoch 72; Iter    30/   30] train: loss: 0.1992044
[Epoch 72] ogbg-molclintox: 0.906569 val loss: 0.171647
[Epoch 72] ogbg-molclintox: 0.917891 test loss: 0.162981
[Epoch 73; Iter    30/   30] train: loss: 0.1247694
[Epoch 73] ogbg-molclintox: 0.889562 val loss: 0.175772
[Epoch 73] ogbg-molclintox: 0.903231 test loss: 0.160672
[Epoch 74; Iter    30/   30] train: loss: 0.1869378
[Epoch 74] ogbg-molclintox: 0.906093 val loss: 0.201279
[Epoch 74] ogbg-molclintox: 0.914841 test loss: 0.163909
[Epoch 75; Iter    30/   30] train: loss: 0.1187484
[Epoch 75] ogbg-molclintox: 0.906133 val loss: 0.173028
[Epoch 75] ogbg-molclintox: 0.901601 test loss: 0.166908
[Epoch 76; Iter    30/   30] train: loss: 0.1193367
[Epoch 76] ogbg-molclintox: 0.886434 val loss: 0.183320
[Epoch 76] ogbg-molclintox: 0.905021 test loss: 0.168375
[Epoch 77; Iter    30/   30] train: loss: 0.0545583
[Epoch 77] ogbg-molclintox: 0.911796 val loss: 0.160410
[Epoch 77] ogbg-molclintox: 0.868577 test loss: 0.182770
[Epoch 78; Iter    30/   30] train: loss: 0.0349548
[Epoch 78] ogbg-molclintox: 0.909329 val loss: 0.261873
[Epoch 78] ogbg-molclintox: 0.909876 test loss: 0.219464
[Epoch 79; Iter    30/   30] train: loss: 0.0883677
[Epoch 79] ogbg-molclintox: 0.892110 val loss: 0.179445
[Epoch 79] ogbg-molclintox: 0.904198 test loss: 0.156777
[Epoch 80; Iter    30/   30] train: loss: 0.1089349
[Epoch 80] ogbg-molclintox: 0.904816 val loss: 0.174632
[Epoch 80] ogbg-molclintox: 0.901209 test loss: 0.172517
[Epoch 81; Iter    30/   30] train: loss: 0.0478875
[Epoch 81] ogbg-molclintox: 0.854399 val loss: 0.212408
[Epoch 81] ogbg-molclintox: 0.838778 test loss: 0.186978
[Epoch 82; Iter    30/   30] train: loss: 0.6142108
[Epoch 82] ogbg-molclintox: 0.909670 val loss: 0.202641
[Epoch 82] ogbg-molclintox: 0.905978 test loss: 0.157668
[Epoch 83; Iter    30/   30] train: loss: 0.1413128
[Epoch 83] ogbg-molclintox: 0.879835 val loss: 0.225707
[Epoch 83] ogbg-molclintox: 0.826897 test loss: 0.368162
[Epoch 33] ogbg-molclintox: 0.928230 val loss: 0.199283
[Epoch 33] ogbg-molclintox: 0.857192 test loss: 0.172116
[Epoch 34; Iter    15/   35] train: loss: 0.1216769
[Epoch 34] ogbg-molclintox: 0.913950 val loss: 0.190809
[Epoch 34] ogbg-molclintox: 0.879789 test loss: 0.162338
[Epoch 35; Iter    10/   35] train: loss: 0.0837777
[Epoch 35] ogbg-molclintox: 0.930731 val loss: 0.186105
[Epoch 35] ogbg-molclintox: 0.882102 test loss: 0.161643
[Epoch 36; Iter     5/   35] train: loss: 0.2046337
[Epoch 36; Iter    35/   35] train: loss: 0.0677677
[Epoch 36] ogbg-molclintox: 0.936253 val loss: 0.185046
[Epoch 36] ogbg-molclintox: 0.871779 test loss: 0.183855
[Epoch 37; Iter    30/   35] train: loss: 0.2014461
[Epoch 37] ogbg-molclintox: 0.911672 val loss: 0.204065
[Epoch 37] ogbg-molclintox: 0.883491 test loss: 0.184505
[Epoch 38; Iter    25/   35] train: loss: 0.2065731
[Epoch 38] ogbg-molclintox: 0.903029 val loss: 0.195430
[Epoch 38] ogbg-molclintox: 0.876643 test loss: 0.165690
[Epoch 39; Iter    20/   35] train: loss: 0.2594950
[Epoch 39] ogbg-molclintox: 0.914447 val loss: 0.184328
[Epoch 39] ogbg-molclintox: 0.868366 test loss: 0.216317
[Epoch 40; Iter    15/   35] train: loss: 0.0697552
[Epoch 40] ogbg-molclintox: 0.892889 val loss: 0.333574
[Epoch 40] ogbg-molclintox: 0.837311 test loss: 0.305378
[Epoch 41; Iter    10/   35] train: loss: 0.1697235
[Epoch 41] ogbg-molclintox: 0.870810 val loss: 0.247570
[Epoch 41] ogbg-molclintox: 0.799062 test loss: 0.299769
[Epoch 42; Iter     5/   35] train: loss: 0.1889638
[Epoch 42; Iter    35/   35] train: loss: 0.2082866
[Epoch 42] ogbg-molclintox: 0.899931 val loss: 0.263378
[Epoch 42] ogbg-molclintox: 0.851415 test loss: 0.318659
[Epoch 43; Iter    30/   35] train: loss: 0.1220114
[Epoch 43] ogbg-molclintox: 0.909664 val loss: 0.163582
[Epoch 43] ogbg-molclintox: 0.797435 test loss: 0.225713
[Epoch 44; Iter    25/   35] train: loss: 0.1917288
[Epoch 44] ogbg-molclintox: 0.870400 val loss: 0.512903
[Epoch 44] ogbg-molclintox: 0.828689 test loss: 0.486895
[Epoch 45; Iter    20/   35] train: loss: 0.1630178
[Epoch 45] ogbg-molclintox: 0.847208 val loss: 0.199056
[Epoch 45] ogbg-molclintox: 0.778240 test loss: 0.163628
[Epoch 46; Iter    15/   35] train: loss: 0.1343420
[Epoch 46] ogbg-molclintox: 0.926121 val loss: 0.189363
[Epoch 46] ogbg-molclintox: 0.823615 test loss: 0.165373
[Epoch 47; Iter    10/   35] train: loss: 0.1277014
[Epoch 47] ogbg-molclintox: 0.952537 val loss: 0.161156
[Epoch 47] ogbg-molclintox: 0.857510 test loss: 0.163660
[Epoch 48; Iter     5/   35] train: loss: 0.1882633
[Epoch 48; Iter    35/   35] train: loss: 0.2160965
[Epoch 48] ogbg-molclintox: 0.899616 val loss: 0.194937
[Epoch 48] ogbg-molclintox: 0.779788 test loss: 0.187221
[Epoch 49; Iter    30/   35] train: loss: 0.1803306
[Epoch 49] ogbg-molclintox: 0.955000 val loss: 0.135098
[Epoch 49] ogbg-molclintox: 0.843059 test loss: 0.166663
[Epoch 50; Iter    25/   35] train: loss: 0.0848888
[Epoch 50] ogbg-molclintox: 0.955706 val loss: 0.149884
[Epoch 50] ogbg-molclintox: 0.861161 test loss: 0.280206
[Epoch 51; Iter    20/   35] train: loss: 0.1130825
[Epoch 51] ogbg-molclintox: 0.962231 val loss: 0.129236
[Epoch 51] ogbg-molclintox: 0.827118 test loss: 0.181896
[Epoch 52; Iter    15/   35] train: loss: 0.1173147
[Epoch 52] ogbg-molclintox: 0.969674 val loss: 0.142630
[Epoch 52] ogbg-molclintox: 0.849460 test loss: 0.213511
[Epoch 53; Iter    10/   35] train: loss: 0.1101694
[Epoch 53] ogbg-molclintox: 0.936399 val loss: 0.179385
[Epoch 53] ogbg-molclintox: 0.874023 test loss: 0.209129
[Epoch 54; Iter     5/   35] train: loss: 0.1911306
[Epoch 54; Iter    35/   35] train: loss: 0.2530933
[Epoch 54] ogbg-molclintox: 0.919957 val loss: 0.202374
[Epoch 54] ogbg-molclintox: 0.909392 test loss: 0.154938
[Epoch 55; Iter    30/   35] train: loss: 0.1568002
[Epoch 55] ogbg-molclintox: 0.956772 val loss: 0.143462
[Epoch 55] ogbg-molclintox: 0.853598 test loss: 0.145242
[Epoch 56; Iter    25/   35] train: loss: 0.1603163
[Epoch 56] ogbg-molclintox: 0.981056 val loss: 0.096350
[Epoch 56] ogbg-molclintox: 0.875061 test loss: 0.142941
[Epoch 57; Iter    20/   35] train: loss: 0.0908688
[Epoch 57] ogbg-molclintox: 0.930521 val loss: 0.170665
[Epoch 57] ogbg-molclintox: 0.760162 test loss: 0.232584
[Epoch 58; Iter    15/   35] train: loss: 0.1039369
[Epoch 58] ogbg-molclintox: 0.928848 val loss: 0.150412
[Epoch 58] ogbg-molclintox: 0.864250 test loss: 0.146288
[Epoch 59; Iter    10/   35] train: loss: 0.0562638
[Epoch 59] ogbg-molclintox: 0.915969 val loss: 0.228340
[Epoch 59] ogbg-molclintox: 0.807282 test loss: 0.272011
[Epoch 60; Iter     5/   35] train: loss: 0.0870122
[Epoch 60; Iter    35/   35] train: loss: 0.0358706
[Epoch 60] ogbg-molclintox: 0.949814 val loss: 0.137449
[Epoch 60] ogbg-molclintox: 0.831223 test loss: 0.209660
[Epoch 61; Iter    30/   35] train: loss: 0.0953395
[Epoch 61] ogbg-molclintox: 0.971608 val loss: 0.100905
[Epoch 61] ogbg-molclintox: 0.887465 test loss: 0.118866
[Epoch 62; Iter    25/   35] train: loss: 0.1013882
[Epoch 62] ogbg-molclintox: 0.967906 val loss: 0.112149
[Epoch 62] ogbg-molclintox: 0.845237 test loss: 0.124048
[Epoch 63; Iter    20/   35] train: loss: 0.0767718
[Epoch 63] ogbg-molclintox: 0.963001 val loss: 0.168522
[Epoch 63] ogbg-molclintox: 0.899670 test loss: 0.173696
[Epoch 64; Iter    15/   35] train: loss: 0.1118634
[Epoch 64] ogbg-molclintox: 0.959855 val loss: 0.128437
[Epoch 64] ogbg-molclintox: 0.856716 test loss: 0.169337
[Epoch 65; Iter    10/   35] train: loss: 0.1194848
[Epoch 65] ogbg-molclintox: 0.957565 val loss: 0.135294
[Epoch 65] ogbg-molclintox: 0.832289 test loss: 0.158701
[Epoch 66; Iter     5/   35] train: loss: 0.0677105
[Epoch 66; Iter    35/   35] train: loss: 0.0142900
[Epoch 66] ogbg-molclintox: 0.952989 val loss: 0.124442
[Epoch 66] ogbg-molclintox: 0.861830 test loss: 0.131208
[Epoch 67; Iter    30/   35] train: loss: 0.1479962
[Epoch 67] ogbg-molclintox: 0.952140 val loss: 0.171900
[Epoch 67] ogbg-molclintox: 0.811302 test loss: 0.225958
[Epoch 68; Iter    25/   35] train: loss: 0.0494059
[Epoch 68] ogbg-molclintox: 0.968337 val loss: 0.106584
[Epoch 68] ogbg-molclintox: 0.870151 test loss: 0.163204
[Epoch 69; Iter    20/   35] train: loss: 0.0347422
[Epoch 69] ogbg-molclintox: 0.958034 val loss: 0.137473
[Epoch 69] ogbg-molclintox: 0.870622 test loss: 0.169061
[Epoch 70; Iter    15/   35] train: loss: 0.0638411
[Epoch 70] ogbg-molclintox: 0.952671 val loss: 0.143594
[Epoch 70] ogbg-molclintox: 0.847118 test loss: 0.197375
[Epoch 71; Iter    10/   35] train: loss: 0.0901264
[Epoch 71] ogbg-molclintox: 0.952871 val loss: 0.129225
[Epoch 71] ogbg-molclintox: 0.846087 test loss: 0.179656
[Epoch 72; Iter     5/   35] train: loss: 0.0403968
[Epoch 72; Iter    35/   35] train: loss: 0.1962645
[Epoch 72] ogbg-molclintox: 0.956290 val loss: 0.192423
[Epoch 72] ogbg-molclintox: 0.910804 test loss: 0.156996
[Epoch 73; Iter    30/   35] train: loss: 0.1652457
[Epoch 73] ogbg-molclintox: 0.956512 val loss: 0.141527
[Epoch 73] ogbg-molclintox: 0.896473 test loss: 0.171783
[Epoch 74; Iter    25/   35] train: loss: 0.1248118
[Epoch 74] ogbg-molclintox: 0.965365 val loss: 0.154627
[Epoch 74] ogbg-molclintox: 0.871512 test loss: 0.185830
[Epoch 75; Iter    20/   35] train: loss: 0.0540627
[Epoch 75] ogbg-molclintox: 0.947944 val loss: 0.127582
[Epoch 75] ogbg-molclintox: 0.842617 test loss: 0.186562
[Epoch 76; Iter    15/   35] train: loss: 0.0521434
[Epoch 76] ogbg-molclintox: 0.965117 val loss: 0.120829
[Epoch 76] ogbg-molclintox: 0.852550 test loss: 0.153328
[Epoch 77; Iter    10/   35] train: loss: 0.1145156
[Epoch 77] ogbg-molclintox: 0.929634 val loss: 0.212659
[Epoch 77] ogbg-molclintox: 0.848813 test loss: 0.323906
[Epoch 78; Iter     5/   35] train: loss: 0.0300151
[Epoch 78; Iter    35/   35] train: loss: 0.0123758
[Epoch 78] ogbg-molclintox: 0.960051 val loss: 0.147347
[Epoch 78] ogbg-molclintox: 0.836518 test loss: 0.212643
[Epoch 79; Iter    30/   35] train: loss: 0.1018343
[Epoch 79] ogbg-molclintox: 0.966356 val loss: 0.106744
[Epoch 79] ogbg-molclintox: 0.861665 test loss: 0.148544
[Epoch 80; Iter    25/   35] train: loss: 0.0227713
[Epoch 31] ogbg-molclintox: 0.860453 test loss: 0.201789
[Epoch 32; Iter    20/   40] train: loss: 0.1586776
[Epoch 32] ogbg-molclintox: 0.861671 val loss: 0.138309
[Epoch 32] ogbg-molclintox: 0.808537 test loss: 0.208537
[Epoch 33; Iter    10/   40] train: loss: 0.1973344
[Epoch 33; Iter    40/   40] train: loss: 0.6622324
[Epoch 33] ogbg-molclintox: 0.989486 val loss: 0.112288
[Epoch 33] ogbg-molclintox: 0.827762 test loss: 0.203577
[Epoch 34; Iter    30/   40] train: loss: 0.1815879
[Epoch 34] ogbg-molclintox: 0.974140 val loss: 0.116746
[Epoch 34] ogbg-molclintox: 0.854357 test loss: 0.195935
[Epoch 35; Iter    20/   40] train: loss: 0.1742542
[Epoch 35] ogbg-molclintox: 0.949165 val loss: 0.099087
[Epoch 35] ogbg-molclintox: 0.862003 test loss: 0.250633
[Epoch 36; Iter    10/   40] train: loss: 0.1955257
[Epoch 36; Iter    40/   40] train: loss: 0.2380027
[Epoch 36] ogbg-molclintox: 0.955933 val loss: 0.158903
[Epoch 36] ogbg-molclintox: 0.837881 test loss: 0.932325
[Epoch 37; Iter    30/   40] train: loss: 0.2788168
[Epoch 37] ogbg-molclintox: 0.924503 val loss: 0.102129
[Epoch 37] ogbg-molclintox: 0.871121 test loss: 0.433930
[Epoch 38; Iter    20/   40] train: loss: 0.2438206
[Epoch 38] ogbg-molclintox: 0.960516 val loss: 0.078048
[Epoch 38] ogbg-molclintox: 0.869048 test loss: 0.191935
[Epoch 39; Iter    10/   40] train: loss: 0.0988167
[Epoch 39; Iter    40/   40] train: loss: 0.0668840
[Epoch 39] ogbg-molclintox: 0.855652 val loss: 0.153667
[Epoch 39] ogbg-molclintox: 0.738560 test loss: 2.360707
[Epoch 40; Iter    30/   40] train: loss: 0.3096189
[Epoch 40] ogbg-molclintox: 0.973578 val loss: 0.137811
[Epoch 40] ogbg-molclintox: 0.812821 test loss: 31.592473
[Epoch 41; Iter    20/   40] train: loss: 0.2375076
[Epoch 41] ogbg-molclintox: 0.986776 val loss: 0.082267
[Epoch 41] ogbg-molclintox: 0.855370 test loss: 0.182198
[Epoch 42; Iter    10/   40] train: loss: 0.0574655
[Epoch 42; Iter    40/   40] train: loss: 0.1131026
[Epoch 42] ogbg-molclintox: 0.991584 val loss: 0.066349
[Epoch 42] ogbg-molclintox: 0.864488 test loss: 0.224851
[Epoch 43; Iter    30/   40] train: loss: 0.3236190
[Epoch 43] ogbg-molclintox: 0.994044 val loss: 0.076133
[Epoch 43] ogbg-molclintox: 0.848273 test loss: 0.173897
[Epoch 44; Iter    20/   40] train: loss: 0.0720191
[Epoch 44] ogbg-molclintox: 0.839220 val loss: 0.153483
[Epoch 44] ogbg-molclintox: 0.726361 test loss: 0.203786
[Epoch 45; Iter    10/   40] train: loss: 0.1914315
[Epoch 45; Iter    40/   40] train: loss: 0.2747357
[Epoch 45] ogbg-molclintox: 0.994269 val loss: 0.075445
[Epoch 45] ogbg-molclintox: 0.892506 test loss: 0.190014
[Epoch 46; Iter    30/   40] train: loss: 0.1053455
[Epoch 46] ogbg-molclintox: 0.984092 val loss: 0.096946
[Epoch 46] ogbg-molclintox: 0.869493 test loss: 0.187725
[Epoch 47; Iter    20/   40] train: loss: 0.1571699
[Epoch 47] ogbg-molclintox: 0.971655 val loss: 0.079113
[Epoch 47] ogbg-molclintox: 0.820740 test loss: 0.196560
[Epoch 48; Iter    10/   40] train: loss: 0.1008863
[Epoch 48; Iter    40/   40] train: loss: 0.1905752
[Epoch 48] ogbg-molclintox: 0.962652 val loss: 0.108964
[Epoch 48] ogbg-molclintox: 0.756605 test loss: 0.209449
[Epoch 49; Iter    30/   40] train: loss: 0.2189221
[Epoch 49] ogbg-molclintox: 0.886955 val loss: 0.127062
[Epoch 49] ogbg-molclintox: 0.798429 test loss: 0.430398
[Epoch 50; Iter    20/   40] train: loss: 0.1432959
[Epoch 50] ogbg-molclintox: 0.985353 val loss: 0.118810
[Epoch 50] ogbg-molclintox: 0.798967 test loss: 0.204189
[Epoch 51; Iter    10/   40] train: loss: 0.1692861
[Epoch 51; Iter    40/   40] train: loss: 0.0492690
[Epoch 51] ogbg-molclintox: 0.902140 val loss: 0.102749
[Epoch 51] ogbg-molclintox: 0.810434 test loss: 0.368501
[Epoch 52; Iter    30/   40] train: loss: 0.1433144
[Epoch 52] ogbg-molclintox: 0.982194 val loss: 0.084528
[Epoch 52] ogbg-molclintox: 0.892080 test loss: 0.872993
[Epoch 53; Iter    20/   40] train: loss: 0.0912163
[Epoch 53] ogbg-molclintox: 0.920659 val loss: 0.342263
[Epoch 53] ogbg-molclintox: 0.713537 test loss: 1.411958
[Epoch 54; Iter    10/   40] train: loss: 0.1293307
[Epoch 54; Iter    40/   40] train: loss: 0.0388866
[Epoch 54] ogbg-molclintox: 0.944084 val loss: 0.154431
[Epoch 54] ogbg-molclintox: 0.866684 test loss: 0.219438
[Epoch 55; Iter    30/   40] train: loss: 0.1644021
[Epoch 55] ogbg-molclintox: 0.936704 val loss: 0.280757
[Epoch 55] ogbg-molclintox: 0.859165 test loss: 0.172350
[Epoch 56; Iter    20/   40] train: loss: 0.2707117
[Epoch 56] ogbg-molclintox: 0.976737 val loss: 0.087926
[Epoch 56] ogbg-molclintox: 0.837579 test loss: 0.214396
[Epoch 57; Iter    10/   40] train: loss: 0.0869027
[Epoch 57; Iter    40/   40] train: loss: 0.1139342
[Epoch 57] ogbg-molclintox: 0.989461 val loss: 0.095525
[Epoch 57] ogbg-molclintox: 0.873818 test loss: 0.323217
[Epoch 58; Iter    30/   40] train: loss: 0.3266472
[Epoch 58] ogbg-molclintox: 0.968545 val loss: 0.116282
[Epoch 58] ogbg-molclintox: 0.862340 test loss: 0.267445
[Epoch 59; Iter    20/   40] train: loss: 0.0853465
[Epoch 59] ogbg-molclintox: 0.946431 val loss: 0.214116
[Epoch 59] ogbg-molclintox: 0.779641 test loss: 0.268738
[Epoch 60; Iter    10/   40] train: loss: 0.0481592
[Epoch 60; Iter    40/   40] train: loss: 0.0827351
[Epoch 60] ogbg-molclintox: 0.986776 val loss: 0.063212
[Epoch 60] ogbg-molclintox: 0.866647 test loss: 0.295922
[Epoch 61; Iter    30/   40] train: loss: 0.0805497
[Epoch 61] ogbg-molclintox: 0.848933 val loss: 0.118718
[Epoch 61] ogbg-molclintox: 0.787970 test loss: 0.228878
[Epoch 62; Iter    20/   40] train: loss: 0.0969136
[Epoch 62] ogbg-molclintox: 0.955860 val loss: 0.092530
[Epoch 62] ogbg-molclintox: 0.862049 test loss: 0.188696
[Epoch 63; Iter    10/   40] train: loss: 0.3364135
[Epoch 63; Iter    40/   40] train: loss: 0.0312899
[Epoch 63] ogbg-molclintox: 0.953287 val loss: 0.117635
[Epoch 63] ogbg-molclintox: 0.819463 test loss: 0.196372
[Epoch 64; Iter    30/   40] train: loss: 0.0454118
[Epoch 64] ogbg-molclintox: 0.998826 val loss: 0.051973
[Epoch 64] ogbg-molclintox: 0.834180 test loss: 0.226392
[Epoch 65; Iter    20/   40] train: loss: 0.0218674
[Epoch 65] ogbg-molclintox: 0.993344 val loss: 0.049859
[Epoch 65] ogbg-molclintox: 0.836268 test loss: 0.262891
[Epoch 66; Iter    10/   40] train: loss: 0.0561758
[Epoch 66; Iter    40/   40] train: loss: 0.1807697
[Epoch 66] ogbg-molclintox: 0.896869 val loss: 0.168148
[Epoch 66] ogbg-molclintox: 0.708498 test loss: 0.280607
[Epoch 67; Iter    30/   40] train: loss: 0.1239404
[Epoch 67] ogbg-molclintox: 0.966061 val loss: 0.081404
[Epoch 67] ogbg-molclintox: 0.759276 test loss: 0.223469
[Epoch 68; Iter    20/   40] train: loss: 0.0568833
[Epoch 68] ogbg-molclintox: 0.963376 val loss: 0.090602
[Epoch 68] ogbg-molclintox: 0.814566 test loss: 0.187397
[Epoch 69; Iter    10/   40] train: loss: 0.0465411
[Epoch 69; Iter    40/   40] train: loss: 0.1292638
[Epoch 69] ogbg-molclintox: 0.996254 val loss: 0.052953
[Epoch 69] ogbg-molclintox: 0.821024 test loss: 0.200302
[Epoch 70; Iter    30/   40] train: loss: 0.1456795
[Epoch 70] ogbg-molclintox: 0.979260 val loss: 0.082642
[Epoch 70] ogbg-molclintox: 0.843238 test loss: 0.200101
[Epoch 71; Iter    20/   40] train: loss: 0.0237824
[Epoch 71] ogbg-molclintox: 0.987838 val loss: 0.067236
[Epoch 71] ogbg-molclintox: 0.831083 test loss: 0.211732
[Epoch 72; Iter    10/   40] train: loss: 0.0193401
[Epoch 72; Iter    40/   40] train: loss: 0.0643628
[Epoch 72] ogbg-molclintox: 0.985016 val loss: 0.068067
[Epoch 72] ogbg-molclintox: 0.816542 test loss: 0.203213
[Epoch 73; Iter    30/   40] train: loss: 0.0564372
[Epoch 73] ogbg-molclintox: 0.986864 val loss: 0.064673
[Epoch 73] ogbg-molclintox: 0.816403 test loss: 0.208428
[Epoch 74; Iter    20/   40] train: loss: 0.0961481
[Epoch 74] ogbg-molclintox: 0.987676 val loss: 0.065069
[Epoch 74] ogbg-molclintox: 0.810644 test loss: 0.296999
[Epoch 75; Iter    10/   40] train: loss: 0.0540665
[Epoch 75; Iter    40/   40] train: loss: 0.0156227
[Epoch 75] ogbg-molclintox: 0.982307 val loss: 0.064468
[Epoch 75] ogbg-molclintox: 0.787746 test loss: 0.219839
[Epoch 76; Iter    30/   40] train: loss: 0.0092626
[Epoch 34] ogbg-molclintox: 0.852358 test loss: 0.330212
[Epoch 35; Iter    30/   30] train: loss: 0.2437460
[Epoch 35] ogbg-molclintox: 0.835314 val loss: 0.309177
[Epoch 35] ogbg-molclintox: 0.893621 test loss: 0.254295
[Epoch 36; Iter    30/   30] train: loss: 0.1187016
[Epoch 36] ogbg-molclintox: 0.826195 val loss: 0.257265
[Epoch 36] ogbg-molclintox: 0.849668 test loss: 0.220591
[Epoch 37; Iter    30/   30] train: loss: 0.3728649
[Epoch 37] ogbg-molclintox: 0.834070 val loss: 0.240172
[Epoch 37] ogbg-molclintox: 0.875833 test loss: 0.183622
[Epoch 38; Iter    30/   30] train: loss: 0.1401884
[Epoch 38] ogbg-molclintox: 0.803133 val loss: 0.205805
[Epoch 38] ogbg-molclintox: 0.796378 test loss: 0.179769
[Epoch 39; Iter    30/   30] train: loss: 0.1004440
[Epoch 39] ogbg-molclintox: 0.866766 val loss: 0.236751
[Epoch 39] ogbg-molclintox: 0.884799 test loss: 0.198084
[Epoch 40; Iter    30/   30] train: loss: 0.0790117
[Epoch 40] ogbg-molclintox: 0.861765 val loss: 0.203874
[Epoch 40] ogbg-molclintox: 0.897864 test loss: 0.159735
[Epoch 41; Iter    30/   30] train: loss: 0.0982154
[Epoch 41] ogbg-molclintox: 0.823281 val loss: 0.418312
[Epoch 41] ogbg-molclintox: 0.880360 test loss: 0.316739
[Epoch 42; Iter    30/   30] train: loss: 0.2059475
[Epoch 42] ogbg-molclintox: 0.849278 val loss: 0.238368
[Epoch 42] ogbg-molclintox: 0.910082 test loss: 0.159643
[Epoch 43; Iter    30/   30] train: loss: 0.1153708
[Epoch 43] ogbg-molclintox: 0.833047 val loss: 0.240625
[Epoch 43] ogbg-molclintox: 0.877611 test loss: 0.197558
[Epoch 44; Iter    30/   30] train: loss: 0.3377429
[Epoch 44] ogbg-molclintox: 0.837493 val loss: 0.216719
[Epoch 44] ogbg-molclintox: 0.887662 test loss: 0.165526
[Epoch 45; Iter    30/   30] train: loss: 0.0648298
[Epoch 45] ogbg-molclintox: 0.780364 val loss: 0.618074
[Epoch 45] ogbg-molclintox: 0.878394 test loss: 0.796728
[Epoch 46; Iter    30/   30] train: loss: 0.0720372
[Epoch 46] ogbg-molclintox: 0.856652 val loss: 0.208607
[Epoch 46] ogbg-molclintox: 0.893186 test loss: 0.173932
[Epoch 47; Iter    30/   30] train: loss: 0.1902873
[Epoch 47] ogbg-molclintox: 0.852127 val loss: 0.194427
[Epoch 47] ogbg-molclintox: 0.865473 test loss: 0.148944
[Epoch 48; Iter    30/   30] train: loss: 0.2252308
[Epoch 48] ogbg-molclintox: 0.830854 val loss: 0.451668
[Epoch 48] ogbg-molclintox: 0.855105 test loss: 0.412531
[Epoch 49; Iter    30/   30] train: loss: 0.2584188
[Epoch 49] ogbg-molclintox: 0.856431 val loss: 0.225130
[Epoch 49] ogbg-molclintox: 0.884681 test loss: 0.198183
[Epoch 50; Iter    30/   30] train: loss: 0.0709788
[Epoch 50] ogbg-molclintox: 0.900725 val loss: 0.270087
[Epoch 50] ogbg-molclintox: 0.924075 test loss: 0.178108
[Epoch 51; Iter    30/   30] train: loss: 0.3083857
[Epoch 51] ogbg-molclintox: 0.915806 val loss: 0.165829
[Epoch 51] ogbg-molclintox: 0.931419 test loss: 0.182225
[Epoch 52; Iter    30/   30] train: loss: 0.1254724
[Epoch 52] ogbg-molclintox: 0.915832 val loss: 0.166373
[Epoch 52] ogbg-molclintox: 0.951164 test loss: 0.118830
[Epoch 53; Iter    30/   30] train: loss: 0.1258167
[Epoch 53] ogbg-molclintox: 0.833729 val loss: 0.338441
[Epoch 53] ogbg-molclintox: 0.838778 test loss: 0.551967
[Epoch 54; Iter    30/   30] train: loss: 0.0834748
[Epoch 54] ogbg-molclintox: 0.852186 val loss: 0.266051
[Epoch 54] ogbg-molclintox: 0.908641 test loss: 0.195312
[Epoch 55; Iter    30/   30] train: loss: 0.1541563
[Epoch 55] ogbg-molclintox: 0.865476 val loss: 0.209456
[Epoch 55] ogbg-molclintox: 0.905510 test loss: 0.151561
[Epoch 56; Iter    30/   30] train: loss: 0.2866324
[Epoch 56] ogbg-molclintox: 0.818162 val loss: 0.199122
[Epoch 56] ogbg-molclintox: 0.850517 test loss: 0.152879
[Epoch 57; Iter    30/   30] train: loss: 0.1355101
[Epoch 57] ogbg-molclintox: 0.840019 val loss: 0.320856
[Epoch 57] ogbg-molclintox: 0.891133 test loss: 0.236385
[Epoch 58; Iter    30/   30] train: loss: 0.1992680
[Epoch 58] ogbg-molclintox: 0.895364 val loss: 0.165918
[Epoch 58] ogbg-molclintox: 0.890649 test loss: 0.134030
[Epoch 59; Iter    30/   30] train: loss: 0.1159092
[Epoch 59] ogbg-molclintox: 0.851103 val loss: 0.220939
[Epoch 59] ogbg-molclintox: 0.873408 test loss: 0.196546
[Epoch 60; Iter    30/   30] train: loss: 0.1983709
[Epoch 60] ogbg-molclintox: 0.940746 val loss: 0.160217
[Epoch 60] ogbg-molclintox: 0.956878 test loss: 0.883794
[Epoch 61; Iter    30/   30] train: loss: 0.4075261
[Epoch 61] ogbg-molclintox: 0.889708 val loss: 0.839565
[Epoch 61] ogbg-molclintox: 0.864647 test loss: 7.769963
[Epoch 62; Iter    30/   30] train: loss: 0.0647497
[Epoch 62] ogbg-molclintox: 0.917777 val loss: 0.176565
[Epoch 62] ogbg-molclintox: 0.911120 test loss: 1.628176
[Epoch 63; Iter    30/   30] train: loss: 0.1041437
[Epoch 63] ogbg-molclintox: 0.872408 val loss: 0.403757
[Epoch 63] ogbg-molclintox: 0.903798 test loss: 0.818185
[Epoch 64; Iter    30/   30] train: loss: 0.1124047
[Epoch 64] ogbg-molclintox: 0.904662 val loss: 0.262420
[Epoch 64] ogbg-molclintox: 0.916180 test loss: 0.190060
[Epoch 65; Iter    30/   30] train: loss: 0.0750161
[Epoch 65] ogbg-molclintox: 0.902403 val loss: 0.203170
[Epoch 65] ogbg-molclintox: 0.946432 test loss: 0.156071
[Epoch 66; Iter    30/   30] train: loss: 0.1957377
[Epoch 66] ogbg-molclintox: 0.916814 val loss: 0.175235
[Epoch 66] ogbg-molclintox: 0.946086 test loss: 0.130404
[Epoch 67; Iter    30/   30] train: loss: 0.0249583
[Epoch 67] ogbg-molclintox: 0.768237 val loss: 0.267076
[Epoch 67] ogbg-molclintox: 0.807759 test loss: 0.208587
[Epoch 68; Iter    30/   30] train: loss: 0.0953939
[Epoch 68] ogbg-molclintox: 0.903325 val loss: 0.178280
[Epoch 68] ogbg-molclintox: 0.925747 test loss: 0.137377
[Epoch 69; Iter    30/   30] train: loss: 0.1860832
[Epoch 69] ogbg-molclintox: 0.845081 val loss: 0.227329
[Epoch 69] ogbg-molclintox: 0.889297 test loss: 0.153608
[Epoch 70; Iter    30/   30] train: loss: 0.3305411
[Epoch 70] ogbg-molclintox: 0.901788 val loss: 0.162059
[Epoch 70] ogbg-molclintox: 0.941838 test loss: 0.109534
[Epoch 71; Iter    30/   30] train: loss: 0.2623318
[Epoch 71] ogbg-molclintox: 0.879648 val loss: 0.172744
[Epoch 71] ogbg-molclintox: 0.926930 test loss: 0.122750
[Epoch 72; Iter    30/   30] train: loss: 0.0155346
[Epoch 72] ogbg-molclintox: 0.888552 val loss: 0.181182
[Epoch 72] ogbg-molclintox: 0.917114 test loss: 0.140997
[Epoch 73; Iter    30/   30] train: loss: 0.1248858
[Epoch 73] ogbg-molclintox: 0.860221 val loss: 0.208117
[Epoch 73] ogbg-molclintox: 0.908667 test loss: 0.150165
[Epoch 74; Iter    30/   30] train: loss: 0.0574480
[Epoch 74] ogbg-molclintox: 0.905505 val loss: 0.160420
[Epoch 74] ogbg-molclintox: 0.923345 test loss: 0.111574
[Epoch 75; Iter    30/   30] train: loss: 0.0870513
[Epoch 75] ogbg-molclintox: 0.903660 val loss: 0.186885
[Epoch 75] ogbg-molclintox: 0.926861 test loss: 0.137855
[Epoch 76; Iter    30/   30] train: loss: 0.0642330
[Epoch 76] ogbg-molclintox: 0.908185 val loss: 0.235572
[Epoch 76] ogbg-molclintox: 0.905145 test loss: 0.185705
[Epoch 77; Iter    30/   30] train: loss: 0.0442990
[Epoch 77] ogbg-molclintox: 0.914329 val loss: 0.187077
[Epoch 77] ogbg-molclintox: 0.927060 test loss: 0.147850
[Epoch 78; Iter    30/   30] train: loss: 0.1771550
[Epoch 78] ogbg-molclintox: 0.923186 val loss: 0.159066
[Epoch 78] ogbg-molclintox: 0.904350 test loss: 0.123144
[Epoch 79; Iter    30/   30] train: loss: 0.1947432
[Epoch 79] ogbg-molclintox: 0.883839 val loss: 0.189389
[Epoch 79] ogbg-molclintox: 0.914193 test loss: 0.168375
[Epoch 80; Iter    30/   30] train: loss: 0.1579671
[Epoch 80] ogbg-molclintox: 0.889027 val loss: 0.201778
[Epoch 80] ogbg-molclintox: 0.880558 test loss: 0.155758
[Epoch 81; Iter    30/   30] train: loss: 0.1392349
[Epoch 81] ogbg-molclintox: 0.875911 val loss: 0.201837
[Epoch 81] ogbg-molclintox: 0.884274 test loss: 0.145084
[Epoch 82; Iter    30/   30] train: loss: 0.0955564
[Epoch 82] ogbg-molclintox: 0.885263 val loss: 0.212753
[Epoch 82] ogbg-molclintox: 0.925045 test loss: 0.150935
[Epoch 83; Iter    30/   30] train: loss: 0.0445192
[Epoch 83] ogbg-molclintox: 0.897576 val loss: 0.246370
[Epoch 83] ogbg-molclintox: 0.914021 test loss: 0.179062
[Epoch 33] ogbg-molclintox: 0.892886 val loss: 0.248547
[Epoch 33] ogbg-molclintox: 0.811421 test loss: 0.232638
[Epoch 34; Iter    15/   35] train: loss: 0.1245500
[Epoch 34] ogbg-molclintox: 0.896985 val loss: 0.204083
[Epoch 34] ogbg-molclintox: 0.830259 test loss: 0.182795
[Epoch 35; Iter    10/   35] train: loss: 0.0979559
[Epoch 35] ogbg-molclintox: 0.889804 val loss: 0.206343
[Epoch 35] ogbg-molclintox: 0.812861 test loss: 0.185225
[Epoch 36; Iter     5/   35] train: loss: 0.1443152
[Epoch 36; Iter    35/   35] train: loss: 0.1182307
[Epoch 36] ogbg-molclintox: 0.885036 val loss: 0.200173
[Epoch 36] ogbg-molclintox: 0.819590 test loss: 0.183863
[Epoch 37; Iter    30/   35] train: loss: 0.1369534
[Epoch 37] ogbg-molclintox: 0.874686 val loss: 0.197875
[Epoch 37] ogbg-molclintox: 0.813189 test loss: 0.171790
[Epoch 38; Iter    25/   35] train: loss: 0.1336668
[Epoch 38] ogbg-molclintox: 0.916824 val loss: 0.189989
[Epoch 38] ogbg-molclintox: 0.865911 test loss: 0.177756
[Epoch 39; Iter    20/   35] train: loss: 0.2207245
[Epoch 39] ogbg-molclintox: 0.907115 val loss: 0.198065
[Epoch 39] ogbg-molclintox: 0.868927 test loss: 0.172311
[Epoch 40; Iter    15/   35] train: loss: 0.1207132
[Epoch 40] ogbg-molclintox: 0.923957 val loss: 0.174352
[Epoch 40] ogbg-molclintox: 0.836926 test loss: 0.196133
[Epoch 41; Iter    10/   35] train: loss: 0.0892966
[Epoch 41] ogbg-molclintox: 0.921442 val loss: 0.198890
[Epoch 41] ogbg-molclintox: 0.843598 test loss: 0.200387
[Epoch 42; Iter     5/   35] train: loss: 0.2660763
[Epoch 42; Iter    35/   35] train: loss: 0.4274379
[Epoch 42] ogbg-molclintox: 0.857385 val loss: 0.203473
[Epoch 42] ogbg-molclintox: 0.782537 test loss: 0.229895
[Epoch 43; Iter    30/   35] train: loss: 0.2174116
[Epoch 43] ogbg-molclintox: 0.953875 val loss: 0.156864
[Epoch 43] ogbg-molclintox: 0.781568 test loss: 0.195386
[Epoch 44; Iter    25/   35] train: loss: 0.2123637
[Epoch 44] ogbg-molclintox: 0.958764 val loss: 0.164524
[Epoch 44] ogbg-molclintox: 0.870713 test loss: 0.175730
[Epoch 45; Iter    20/   35] train: loss: 0.2046228
[Epoch 45] ogbg-molclintox: 0.927883 val loss: 0.166628
[Epoch 45] ogbg-molclintox: 0.733404 test loss: 0.173091
[Epoch 46; Iter    15/   35] train: loss: 0.1148268
[Epoch 46] ogbg-molclintox: 0.918037 val loss: 0.172943
[Epoch 46] ogbg-molclintox: 0.814119 test loss: 0.172924
[Epoch 47; Iter    10/   35] train: loss: 0.0935944
[Epoch 47] ogbg-molclintox: 0.909479 val loss: 0.345026
[Epoch 47] ogbg-molclintox: 0.871728 test loss: 0.683103
[Epoch 48; Iter     5/   35] train: loss: 0.1017153
[Epoch 48; Iter    35/   35] train: loss: 0.5150598
[Epoch 48] ogbg-molclintox: 0.817350 val loss: 1.281260
[Epoch 48] ogbg-molclintox: 0.736953 test loss: 3.029558
[Epoch 49; Iter    30/   35] train: loss: 0.0619748
[Epoch 49] ogbg-molclintox: 0.955781 val loss: 0.155418
[Epoch 49] ogbg-molclintox: 0.887074 test loss: 0.156413
[Epoch 50; Iter    25/   35] train: loss: 0.0721273
[Epoch 50] ogbg-molclintox: 0.905679 val loss: 0.162632
[Epoch 50] ogbg-molclintox: 0.820514 test loss: 0.168441
[Epoch 51; Iter    20/   35] train: loss: 0.1299770
[Epoch 51] ogbg-molclintox: 0.961859 val loss: 0.154567
[Epoch 51] ogbg-molclintox: 0.880792 test loss: 0.243294
[Epoch 52; Iter    15/   35] train: loss: 0.1040096
[Epoch 52] ogbg-molclintox: 0.908898 val loss: 0.160567
[Epoch 52] ogbg-molclintox: 0.881348 test loss: 0.142665
[Epoch 53; Iter    10/   35] train: loss: 0.0725868
[Epoch 53] ogbg-molclintox: 0.928403 val loss: 0.138294
[Epoch 53] ogbg-molclintox: 0.844193 test loss: 0.141187
[Epoch 54; Iter     5/   35] train: loss: 0.0480667
[Epoch 54; Iter    35/   35] train: loss: 0.2379652
[Epoch 54] ogbg-molclintox: 0.962294 val loss: 0.207155
[Epoch 54] ogbg-molclintox: 0.880832 test loss: 0.237449
[Epoch 55; Iter    30/   35] train: loss: 0.2054239
[Epoch 55] ogbg-molclintox: 0.918262 val loss: 0.186276
[Epoch 55] ogbg-molclintox: 0.810905 test loss: 0.216229
[Epoch 56; Iter    25/   35] train: loss: 0.1133405
[Epoch 56] ogbg-molclintox: 0.964030 val loss: 0.128811
[Epoch 56] ogbg-molclintox: 0.907482 test loss: 0.144519
[Epoch 57; Iter    20/   35] train: loss: 0.0875313
[Epoch 57] ogbg-molclintox: 0.936983 val loss: 0.148222
[Epoch 57] ogbg-molclintox: 0.883105 test loss: 0.129896
[Epoch 58; Iter    15/   35] train: loss: 0.0980598
[Epoch 58] ogbg-molclintox: 0.949242 val loss: 0.199860
[Epoch 58] ogbg-molclintox: 0.925878 test loss: 0.172944
[Epoch 59; Iter    10/   35] train: loss: 0.1583222
[Epoch 59] ogbg-molclintox: 0.855204 val loss: 0.227149
[Epoch 59] ogbg-molclintox: 0.807878 test loss: 2.703986
[Epoch 60; Iter     5/   35] train: loss: 0.0383265
[Epoch 60; Iter    35/   35] train: loss: 0.2354796
[Epoch 60] ogbg-molclintox: 0.954765 val loss: 0.135834
[Epoch 60] ogbg-molclintox: 0.870237 test loss: 0.252925
[Epoch 61; Iter    30/   35] train: loss: 0.0711868
[Epoch 61] ogbg-molclintox: 0.877954 val loss: 0.207158
[Epoch 61] ogbg-molclintox: 0.806483 test loss: 0.269013
[Epoch 62; Iter    25/   35] train: loss: 0.0655803
[Epoch 62] ogbg-molclintox: 0.960696 val loss: 0.128473
[Epoch 62] ogbg-molclintox: 0.876325 test loss: 0.167480
[Epoch 63; Iter    20/   35] train: loss: 0.0705960
[Epoch 63] ogbg-molclintox: 0.952932 val loss: 0.135578
[Epoch 63] ogbg-molclintox: 0.852974 test loss: 0.164445
[Epoch 64; Iter    15/   35] train: loss: 0.2366992
[Epoch 64] ogbg-molclintox: 0.976807 val loss: 0.132390
[Epoch 64] ogbg-molclintox: 0.809142 test loss: 0.166323
[Epoch 65; Iter    10/   35] train: loss: 0.0731880
[Epoch 65] ogbg-molclintox: 0.967025 val loss: 0.118752
[Epoch 65] ogbg-molclintox: 0.789402 test loss: 1.820305
[Epoch 66; Iter     5/   35] train: loss: 0.0820950
[Epoch 66; Iter    35/   35] train: loss: 0.1369202
[Epoch 66] ogbg-molclintox: 0.981696 val loss: 0.128379
[Epoch 66] ogbg-molclintox: 0.884687 test loss: 0.180134
[Epoch 67; Iter    30/   35] train: loss: 0.2896720
[Epoch 67] ogbg-molclintox: 0.970060 val loss: 0.113241
[Epoch 67] ogbg-molclintox: 0.853870 test loss: 0.148720
[Epoch 68; Iter    25/   35] train: loss: 0.1305705
[Epoch 68] ogbg-molclintox: 0.959940 val loss: 0.132828
[Epoch 68] ogbg-molclintox: 0.905997 test loss: 0.133100
[Epoch 69; Iter    20/   35] train: loss: 0.0525411
[Epoch 69] ogbg-molclintox: 0.962713 val loss: 0.136763
[Epoch 69] ogbg-molclintox: 0.870792 test loss: 0.378005
[Epoch 70; Iter    15/   35] train: loss: 0.0341683
[Epoch 70] ogbg-molclintox: 0.949043 val loss: 0.168833
[Epoch 70] ogbg-molclintox: 0.886750 test loss: 1.847593
[Epoch 71; Iter    10/   35] train: loss: 0.1629074
[Epoch 71] ogbg-molclintox: 0.946061 val loss: 0.142473
[Epoch 71] ogbg-molclintox: 0.887692 test loss: 0.796264
[Epoch 72; Iter     5/   35] train: loss: 0.0176910
[Epoch 72; Iter    35/   35] train: loss: 0.0194178
[Epoch 72] ogbg-molclintox: 0.944500 val loss: 0.140212
[Epoch 72] ogbg-molclintox: 0.868865 test loss: 0.153813
[Epoch 73; Iter    30/   35] train: loss: 0.0969529
[Epoch 73] ogbg-molclintox: 0.955681 val loss: 0.141075
[Epoch 73] ogbg-molclintox: 0.897918 test loss: 1.134367
[Epoch 74; Iter    25/   35] train: loss: 0.0797669
[Epoch 74] ogbg-molclintox: 0.943890 val loss: 0.171707
[Epoch 74] ogbg-molclintox: 0.886756 test loss: 0.348600
[Epoch 75; Iter    20/   35] train: loss: 0.0618937
[Epoch 75] ogbg-molclintox: 0.941143 val loss: 0.181507
[Epoch 75] ogbg-molclintox: 0.898514 test loss: 0.570481
[Epoch 76; Iter    15/   35] train: loss: 0.0727702
[Epoch 76] ogbg-molclintox: 0.944995 val loss: 0.212529
[Epoch 76] ogbg-molclintox: 0.870197 test loss: 0.281388
[Epoch 77; Iter    10/   35] train: loss: 0.0839623
[Epoch 77] ogbg-molclintox: 0.947532 val loss: 0.147765
[Epoch 77] ogbg-molclintox: 0.918435 test loss: 0.160604
[Epoch 78; Iter     5/   35] train: loss: 0.0411701
[Epoch 78; Iter    35/   35] train: loss: 0.0090043
[Epoch 78] ogbg-molclintox: 0.938631 val loss: 0.153670
[Epoch 78] ogbg-molclintox: 0.802532 test loss: 2.228206
[Epoch 79; Iter    30/   35] train: loss: 0.1936228
[Epoch 79] ogbg-molclintox: 0.954368 val loss: 0.202946
[Epoch 79] ogbg-molclintox: 0.899630 test loss: 0.168415
[Epoch 80; Iter    25/   35] train: loss: 0.0165453
[Epoch 31] ogbg-molclintox: 0.865787 test loss: 0.200150
[Epoch 32; Iter    20/   40] train: loss: 0.2297032
[Epoch 32] ogbg-molclintox: 0.975563 val loss: 0.130555
[Epoch 32] ogbg-molclintox: 0.869411 test loss: 0.227947
[Epoch 33; Iter    10/   40] train: loss: 0.3050676
[Epoch 33; Iter    40/   40] train: loss: 0.3276593
[Epoch 33] ogbg-molclintox: 0.881087 val loss: 0.141401
[Epoch 33] ogbg-molclintox: 0.808974 test loss: 0.208196
[Epoch 34; Iter    30/   40] train: loss: 0.1163705
[Epoch 34] ogbg-molclintox: 0.957806 val loss: 0.101790
[Epoch 34] ogbg-molclintox: 0.856819 test loss: 0.411761
[Epoch 35; Iter    20/   40] train: loss: 0.1654755
[Epoch 35] ogbg-molclintox: 0.921471 val loss: 0.152293
[Epoch 35] ogbg-molclintox: 0.848698 test loss: 0.213458
[Epoch 36; Iter    10/   40] train: loss: 0.2245532
[Epoch 36; Iter    40/   40] train: loss: 0.2917740
[Epoch 36] ogbg-molclintox: 0.810960 val loss: 0.173590
[Epoch 36] ogbg-molclintox: 0.748795 test loss: 0.514338
[Epoch 37; Iter    30/   40] train: loss: 0.1252732
[Epoch 37] ogbg-molclintox: 0.890364 val loss: 0.229176
[Epoch 37] ogbg-molclintox: 0.827751 test loss: 0.576738
[Epoch 38; Iter    20/   40] train: loss: 0.2409561
[Epoch 38] ogbg-molclintox: 0.869287 val loss: 0.115614
[Epoch 38] ogbg-molclintox: 0.817692 test loss: 0.203968
[Epoch 39; Iter    10/   40] train: loss: 0.0894077
[Epoch 39; Iter    40/   40] train: loss: 0.1694465
[Epoch 39] ogbg-molclintox: 0.842664 val loss: 0.340921
[Epoch 39] ogbg-molclintox: 0.854794 test loss: 1.893434
[Epoch 40; Iter    30/   40] train: loss: 0.2009077
[Epoch 40] ogbg-molclintox: 0.942123 val loss: 0.293059
[Epoch 40] ogbg-molclintox: 0.715360 test loss: 0.441583
[Epoch 41; Iter    20/   40] train: loss: 0.0587601
[Epoch 41] ogbg-molclintox: 0.954872 val loss: 0.142799
[Epoch 41] ogbg-molclintox: 0.922452 test loss: 0.171771
[Epoch 42; Iter    10/   40] train: loss: 0.0754601
[Epoch 42; Iter    40/   40] train: loss: 0.0803262
[Epoch 42] ogbg-molclintox: 0.940861 val loss: 0.086686
[Epoch 42] ogbg-molclintox: 0.811932 test loss: 0.179531
[Epoch 43; Iter    30/   40] train: loss: 0.2321632
[Epoch 43] ogbg-molclintox: 0.902839 val loss: 0.107430
[Epoch 43] ogbg-molclintox: 0.824651 test loss: 0.198411
[Epoch 44; Iter    20/   40] train: loss: 0.0895336
[Epoch 44] ogbg-molclintox: 0.795276 val loss: 0.206845
[Epoch 44] ogbg-molclintox: 0.778554 test loss: 0.679918
[Epoch 45; Iter    10/   40] train: loss: 0.2626065
[Epoch 45; Iter    40/   40] train: loss: 0.1635024
[Epoch 45] ogbg-molclintox: 0.989261 val loss: 0.074935
[Epoch 45] ogbg-molclintox: 0.889906 test loss: 0.843870
[Epoch 46; Iter    30/   40] train: loss: 0.1610825
[Epoch 46] ogbg-molclintox: 0.997902 val loss: 0.071707
[Epoch 46] ogbg-molclintox: 0.812907 test loss: 0.203972
[Epoch 47; Iter    20/   40] train: loss: 0.0610085
[Epoch 47] ogbg-molclintox: 0.999301 val loss: 0.055721
[Epoch 47] ogbg-molclintox: 0.850745 test loss: 0.201276
[Epoch 48; Iter    10/   40] train: loss: 0.0670668
[Epoch 48; Iter    40/   40] train: loss: 0.1273030
[Epoch 48] ogbg-molclintox: 0.993432 val loss: 0.079849
[Epoch 48] ogbg-molclintox: 0.880041 test loss: 0.208108
[Epoch 49; Iter    30/   40] train: loss: 0.1741082
[Epoch 49] ogbg-molclintox: 0.806964 val loss: 0.116741
[Epoch 49] ogbg-molclintox: 0.712420 test loss: 0.228388
[Epoch 50; Iter    20/   40] train: loss: 0.0570102
[Epoch 50] ogbg-molclintox: 0.957943 val loss: 0.075041
[Epoch 50] ogbg-molclintox: 0.920502 test loss: 0.166380
[Epoch 51; Iter    10/   40] train: loss: 0.1879561
[Epoch 51; Iter    40/   40] train: loss: 0.6038517
[Epoch 51] ogbg-molclintox: 0.985290 val loss: 0.070391
[Epoch 51] ogbg-molclintox: 0.858791 test loss: 0.173477
[Epoch 52; Iter    30/   40] train: loss: 0.1979793
[Epoch 52] ogbg-molclintox: 0.992533 val loss: 0.087729
[Epoch 52] ogbg-molclintox: 0.786913 test loss: 0.203955
[Epoch 53; Iter    20/   40] train: loss: 0.0694837
[Epoch 53] ogbg-molclintox: 0.975813 val loss: 0.086420
[Epoch 53] ogbg-molclintox: 0.850970 test loss: 0.242570
[Epoch 54; Iter    10/   40] train: loss: 0.1213567
[Epoch 54; Iter    40/   40] train: loss: 0.0906530
[Epoch 54] ogbg-molclintox: 0.994855 val loss: 0.054326
[Epoch 54] ogbg-molclintox: 0.872870 test loss: 0.375097
[Epoch 55; Iter    30/   40] train: loss: 0.1067288
[Epoch 55] ogbg-molclintox: 0.942622 val loss: 0.092871
[Epoch 55] ogbg-molclintox: 0.890893 test loss: 0.195430
[Epoch 56; Iter    20/   40] train: loss: 0.0528772
[Epoch 56] ogbg-molclintox: 0.971367 val loss: 0.079831
[Epoch 56] ogbg-molclintox: 0.772081 test loss: 0.196100
[Epoch 57; Iter    10/   40] train: loss: 0.0840015
[Epoch 57; Iter    40/   40] train: loss: 0.1770222
[Epoch 57] ogbg-molclintox: 0.872383 val loss: 0.096909
[Epoch 57] ogbg-molclintox: 0.830097 test loss: 0.183003
[Epoch 58; Iter    30/   40] train: loss: 0.0608071
[Epoch 58] ogbg-molclintox: 0.991584 val loss: 0.068297
[Epoch 58] ogbg-molclintox: 0.876142 test loss: 0.170299
[Epoch 59; Iter    20/   40] train: loss: 0.0200942
[Epoch 59] ogbg-molclintox: 0.984791 val loss: 0.067508
[Epoch 59] ogbg-molclintox: 0.845273 test loss: 0.175755
[Epoch 60; Iter    10/   40] train: loss: 0.0498676
[Epoch 60; Iter    40/   40] train: loss: 0.0282621
[Epoch 60] ogbg-molclintox: 0.957831 val loss: 0.070193
[Epoch 60] ogbg-molclintox: 0.848635 test loss: 0.359914
[Epoch 61; Iter    30/   40] train: loss: 0.1002248
[Epoch 61] ogbg-molclintox: 0.921432 val loss: 0.093303
[Epoch 61] ogbg-molclintox: 0.802751 test loss: 0.220708
[Epoch 62; Iter    20/   40] train: loss: 0.0612399
[Epoch 62] ogbg-molclintox: 0.970780 val loss: 0.064821
[Epoch 62] ogbg-molclintox: 0.864387 test loss: 0.204711
[Epoch 63; Iter    10/   40] train: loss: 0.0980502
[Epoch 63; Iter    40/   40] train: loss: 0.1700541
[Epoch 63] ogbg-molclintox: 0.992870 val loss: 0.055482
[Epoch 63] ogbg-molclintox: 0.783417 test loss: 0.231787
[Epoch 64; Iter    30/   40] train: loss: 0.0947831
[Epoch 64] ogbg-molclintox: 0.985965 val loss: 0.205333
[Epoch 64] ogbg-molclintox: 0.864574 test loss: 0.534216
[Epoch 65; Iter    20/   40] train: loss: 0.1939677
[Epoch 65] ogbg-molclintox: 0.973103 val loss: 0.094186
[Epoch 65] ogbg-molclintox: 0.834355 test loss: 0.227688
[Epoch 66; Iter    10/   40] train: loss: 0.0712563
[Epoch 66; Iter    40/   40] train: loss: 0.0172286
[Epoch 66] ogbg-molclintox: 0.973827 val loss: 0.079286
[Epoch 66] ogbg-molclintox: 0.841759 test loss: 0.217498
[Epoch 67; Iter    30/   40] train: loss: 0.0213537
[Epoch 67] ogbg-molclintox: 0.964037 val loss: 0.117493
[Epoch 67] ogbg-molclintox: 0.850245 test loss: 0.208836
[Epoch 68; Iter    20/   40] train: loss: 0.0820612
[Epoch 68] ogbg-molclintox: 0.964712 val loss: 0.119284
[Epoch 68] ogbg-molclintox: 0.825450 test loss: 0.208034
[Epoch 69; Iter    10/   40] train: loss: 0.0521735
[Epoch 69; Iter    40/   40] train: loss: 0.0848315
[Epoch 69] ogbg-molclintox: 0.977910 val loss: 0.063014
[Epoch 69] ogbg-molclintox: 0.831270 test loss: 0.190528
[Epoch 70; Iter    30/   40] train: loss: 0.0736723
[Epoch 70] ogbg-molclintox: 0.983754 val loss: 0.064446
[Epoch 70] ogbg-molclintox: 0.844960 test loss: 0.193163
[Epoch 71; Iter    20/   40] train: loss: 0.0864967
[Epoch 71] ogbg-molclintox: 0.956770 val loss: 0.067724
[Epoch 71] ogbg-molclintox: 0.822126 test loss: 0.221558
[Epoch 72; Iter    10/   40] train: loss: 0.0082988
[Epoch 72; Iter    40/   40] train: loss: 0.0273249
[Epoch 72] ogbg-molclintox: 0.976287 val loss: 0.063153
[Epoch 72] ogbg-molclintox: 0.773593 test loss: 0.222386
[Epoch 73; Iter    30/   40] train: loss: 0.1299094
[Epoch 73] ogbg-molclintox: 0.984679 val loss: 0.073087
[Epoch 73] ogbg-molclintox: 0.817364 test loss: 0.224079
[Epoch 74; Iter    20/   40] train: loss: 0.0517179
[Epoch 74] ogbg-molclintox: 0.976175 val loss: 0.062170
[Epoch 74] ogbg-molclintox: 0.774542 test loss: 0.207993
[Epoch 75; Iter    10/   40] train: loss: 0.0447759
[Epoch 75; Iter    40/   40] train: loss: 0.0336912
[Epoch 75] ogbg-molclintox: 0.980209 val loss: 0.066287
[Epoch 75] ogbg-molclintox: 0.779775 test loss: 0.218153
[Epoch 76; Iter    30/   40] train: loss: 0.0313020
[Epoch 33] ogbg-molclintox: 0.912652 val loss: 0.234891
[Epoch 33] ogbg-molclintox: 0.840650 test loss: 0.223429
[Epoch 34; Iter    15/   35] train: loss: 0.1352035
[Epoch 34] ogbg-molclintox: 0.846726 val loss: 0.224303
[Epoch 34] ogbg-molclintox: 0.749980 test loss: 0.220559
[Epoch 35; Iter    10/   35] train: loss: 0.2060148
[Epoch 35] ogbg-molclintox: 0.920900 val loss: 0.207545
[Epoch 35] ogbg-molclintox: 0.805400 test loss: 0.168776
[Epoch 36; Iter     5/   35] train: loss: 0.1508793
[Epoch 36; Iter    35/   35] train: loss: 0.2939811
[Epoch 36] ogbg-molclintox: 0.913804 val loss: 0.193916
[Epoch 36] ogbg-molclintox: 0.896586 test loss: 0.162944
[Epoch 37; Iter    30/   35] train: loss: 0.2248138
[Epoch 37] ogbg-molclintox: 0.925541 val loss: 0.189656
[Epoch 37] ogbg-molclintox: 0.877017 test loss: 0.164554
[Epoch 38; Iter    25/   35] train: loss: 0.2260654
[Epoch 38] ogbg-molclintox: 0.884913 val loss: 0.199864
[Epoch 38] ogbg-molclintox: 0.858927 test loss: 0.171526
[Epoch 39; Iter    20/   35] train: loss: 0.1717489
[Epoch 39] ogbg-molclintox: 0.892281 val loss: 0.198002
[Epoch 39] ogbg-molclintox: 0.819147 test loss: 0.178882
[Epoch 40; Iter    15/   35] train: loss: 0.0834242
[Epoch 40] ogbg-molclintox: 0.869202 val loss: 0.196952
[Epoch 40] ogbg-molclintox: 0.762469 test loss: 0.194187
[Epoch 41; Iter    10/   35] train: loss: 0.2029305
[Epoch 41] ogbg-molclintox: 0.936215 val loss: 0.177487
[Epoch 41] ogbg-molclintox: 0.886280 test loss: 0.251802
[Epoch 42; Iter     5/   35] train: loss: 0.0784302
[Epoch 42; Iter    35/   35] train: loss: 0.0835715
[Epoch 42] ogbg-molclintox: 0.928971 val loss: 0.294439
[Epoch 42] ogbg-molclintox: 0.855287 test loss: 0.582386
[Epoch 43; Iter    30/   35] train: loss: 0.0809937
[Epoch 43] ogbg-molclintox: 0.843208 val loss: 0.759380
[Epoch 43] ogbg-molclintox: 0.782186 test loss: 1.017896
[Epoch 44; Iter    25/   35] train: loss: 0.2426621
[Epoch 44] ogbg-molclintox: 0.937641 val loss: 0.174077
[Epoch 44] ogbg-molclintox: 0.864454 test loss: 0.172185
[Epoch 45; Iter    20/   35] train: loss: 0.1144114
[Epoch 45] ogbg-molclintox: 0.943521 val loss: 0.166325
[Epoch 45] ogbg-molclintox: 0.900957 test loss: 0.272814
[Epoch 46; Iter    15/   35] train: loss: 0.1382656
[Epoch 46] ogbg-molclintox: 0.897382 val loss: 2.399338
[Epoch 46] ogbg-molclintox: 0.817798 test loss: 6.050659
[Epoch 47; Iter    10/   35] train: loss: 0.1535876
[Epoch 47] ogbg-molclintox: 0.941095 val loss: 0.156974
[Epoch 47] ogbg-molclintox: 0.854012 test loss: 0.169003
[Epoch 48; Iter     5/   35] train: loss: 0.1314305
[Epoch 48; Iter    35/   35] train: loss: 0.0751626
[Epoch 48] ogbg-molclintox: 0.962554 val loss: 0.122786
[Epoch 48] ogbg-molclintox: 0.929217 test loss: 0.139985
[Epoch 49; Iter    30/   35] train: loss: 0.1016880
[Epoch 49] ogbg-molclintox: 0.961676 val loss: 0.149769
[Epoch 49] ogbg-molclintox: 0.890809 test loss: 0.150658
[Epoch 50; Iter    25/   35] train: loss: 0.1124219
[Epoch 50] ogbg-molclintox: 0.976709 val loss: 0.132881
[Epoch 50] ogbg-molclintox: 0.896586 test loss: 0.221408
[Epoch 51; Iter    20/   35] train: loss: 0.1506596
[Epoch 51] ogbg-molclintox: 0.922832 val loss: 0.150227
[Epoch 51] ogbg-molclintox: 0.845174 test loss: 0.164918
[Epoch 52; Iter    15/   35] train: loss: 0.0784560
[Epoch 52] ogbg-molclintox: 0.959347 val loss: 0.139888
[Epoch 52] ogbg-molclintox: 0.883774 test loss: 0.132228
[Epoch 53; Iter    10/   35] train: loss: 0.0696734
[Epoch 53] ogbg-molclintox: 0.968163 val loss: 0.156260
[Epoch 53] ogbg-molclintox: 0.924160 test loss: 0.151145
[Epoch 54; Iter     5/   35] train: loss: 0.2468065
[Epoch 54; Iter    35/   35] train: loss: 0.0651122
[Epoch 54] ogbg-molclintox: 0.947090 val loss: 0.139154
[Epoch 54] ogbg-molclintox: 0.922374 test loss: 0.130423
[Epoch 55; Iter    30/   35] train: loss: 0.0621701
[Epoch 55] ogbg-molclintox: 0.961477 val loss: 0.134841
[Epoch 55] ogbg-molclintox: 0.888128 test loss: 0.157656
[Epoch 56; Iter    25/   35] train: loss: 0.0859285
[Epoch 56] ogbg-molclintox: 0.964796 val loss: 0.119689
[Epoch 56] ogbg-molclintox: 0.866070 test loss: 0.193296
[Epoch 57; Iter    20/   35] train: loss: 0.0546994
[Epoch 57] ogbg-molclintox: 0.942951 val loss: 0.164774
[Epoch 57] ogbg-molclintox: 0.867198 test loss: 0.297451
[Epoch 58; Iter    15/   35] train: loss: 0.0250192
[Epoch 58] ogbg-molclintox: 0.920933 val loss: 0.435825
[Epoch 58] ogbg-molclintox: 0.846875 test loss: 0.683755
[Epoch 59; Iter    10/   35] train: loss: 0.1199379
[Epoch 59] ogbg-molclintox: 0.967718 val loss: 0.109958
[Epoch 59] ogbg-molclintox: 0.876064 test loss: 0.168466
[Epoch 60; Iter     5/   35] train: loss: 0.0478055
[Epoch 60; Iter    35/   35] train: loss: 0.0311377
[Epoch 60] ogbg-molclintox: 0.972225 val loss: 0.117054
[Epoch 60] ogbg-molclintox: 0.926405 test loss: 0.387591
[Epoch 61; Iter    30/   35] train: loss: 0.0525349
[Epoch 61] ogbg-molclintox: 0.904723 val loss: 0.205976
[Epoch 61] ogbg-molclintox: 0.694260 test loss: 0.367171
[Epoch 62; Iter    25/   35] train: loss: 0.4027873
[Epoch 62] ogbg-molclintox: 0.936002 val loss: 0.264950
[Epoch 62] ogbg-molclintox: 0.838984 test loss: 0.556678
[Epoch 63; Iter    20/   35] train: loss: 0.2634605
[Epoch 63] ogbg-molclintox: 0.965438 val loss: 0.139690
[Epoch 63] ogbg-molclintox: 0.862958 test loss: 0.420096
[Epoch 64; Iter    15/   35] train: loss: 0.1072096
[Epoch 64] ogbg-molclintox: 0.966393 val loss: 0.147944
[Epoch 64] ogbg-molclintox: 0.897680 test loss: 0.197287
[Epoch 65; Iter    10/   35] train: loss: 0.0551367
[Epoch 65] ogbg-molclintox: 0.977426 val loss: 0.095956
[Epoch 65] ogbg-molclintox: 0.914523 test loss: 0.198207
[Epoch 66; Iter     5/   35] train: loss: 0.0489930
[Epoch 66; Iter    35/   35] train: loss: 0.1450289
[Epoch 66] ogbg-molclintox: 0.968659 val loss: 0.116902
[Epoch 66] ogbg-molclintox: 0.801801 test loss: 0.445625
[Epoch 67; Iter    30/   35] train: loss: 0.0748786
[Epoch 67] ogbg-molclintox: 0.952042 val loss: 0.122913
[Epoch 67] ogbg-molclintox: 0.832391 test loss: 0.264769
[Epoch 68; Iter    25/   35] train: loss: 0.0423499
[Epoch 68] ogbg-molclintox: 0.965799 val loss: 0.121342
[Epoch 68] ogbg-molclintox: 0.746256 test loss: 0.269098
[Epoch 69; Iter    20/   35] train: loss: 0.0877999
[Epoch 69] ogbg-molclintox: 0.975334 val loss: 0.097497
[Epoch 69] ogbg-molclintox: 0.906229 test loss: 0.142781
[Epoch 70; Iter    15/   35] train: loss: 0.1112580
[Epoch 70] ogbg-molclintox: 0.965204 val loss: 0.187300
[Epoch 70] ogbg-molclintox: 0.912289 test loss: 0.153549
[Epoch 71; Iter    10/   35] train: loss: 0.1807767
[Epoch 71] ogbg-molclintox: 0.940486 val loss: 0.137626
[Epoch 71] ogbg-molclintox: 0.825134 test loss: 0.202526
[Epoch 72; Iter     5/   35] train: loss: 0.0284265
[Epoch 72; Iter    35/   35] train: loss: 0.0325495
[Epoch 72] ogbg-molclintox: 0.951620 val loss: 0.529395
[Epoch 72] ogbg-molclintox: 0.908673 test loss: 0.722770
[Epoch 73; Iter    30/   35] train: loss: 0.0587091
[Epoch 73] ogbg-molclintox: 0.963842 val loss: 0.130224
[Epoch 73] ogbg-molclintox: 0.869653 test loss: 0.289888
[Epoch 74; Iter    25/   35] train: loss: 0.1193582
[Epoch 74] ogbg-molclintox: 0.939996 val loss: 0.150992
[Epoch 74] ogbg-molclintox: 0.887232 test loss: 0.974228
[Epoch 75; Iter    20/   35] train: loss: 0.0627048
[Epoch 75] ogbg-molclintox: 0.940671 val loss: 0.275703
[Epoch 75] ogbg-molclintox: 0.871688 test loss: 0.574290
[Epoch 76; Iter    15/   35] train: loss: 0.0902694
[Epoch 76] ogbg-molclintox: 0.957960 val loss: 0.141521
[Epoch 76] ogbg-molclintox: 0.905090 test loss: 0.587278
[Epoch 77; Iter    10/   35] train: loss: 0.0764779
[Epoch 77] ogbg-molclintox: 0.966058 val loss: 0.106838
[Epoch 77] ogbg-molclintox: 0.892374 test loss: 0.316098
[Epoch 78; Iter     5/   35] train: loss: 0.0421108
[Epoch 78; Iter    35/   35] train: loss: 0.0995995
[Epoch 78] ogbg-molclintox: 0.965996 val loss: 0.120978
[Epoch 78] ogbg-molclintox: 0.889001 test loss: 0.590572
[Epoch 79; Iter    30/   35] train: loss: 0.0654435
[Epoch 79] ogbg-molclintox: 0.946580 val loss: 0.341602
[Epoch 79] ogbg-molclintox: 0.853445 test loss: 1.329033
[Epoch 80; Iter    25/   35] train: loss: 0.0711565
[Epoch 34] ogbg-molclintox: 0.862416 test loss: 0.264489
[Epoch 35; Iter    30/   30] train: loss: 0.1294052
[Epoch 35] ogbg-molclintox: 0.839338 val loss: 0.245320
[Epoch 35] ogbg-molclintox: 0.857746 test loss: 0.249496
[Epoch 36; Iter    30/   30] train: loss: 0.4952261
[Epoch 36] ogbg-molclintox: 0.832125 val loss: 0.278240
[Epoch 36] ogbg-molclintox: 0.839901 test loss: 0.279429
[Epoch 37; Iter    30/   30] train: loss: 0.3405626
[Epoch 37] ogbg-molclintox: 0.825112 val loss: 0.248687
[Epoch 37] ogbg-molclintox: 0.855835 test loss: 0.246575
[Epoch 38; Iter    30/   30] train: loss: 0.1147439
[Epoch 38] ogbg-molclintox: 0.820687 val loss: 0.260250
[Epoch 38] ogbg-molclintox: 0.844489 test loss: 0.276287
[Epoch 39; Iter    30/   30] train: loss: 0.2684641
[Epoch 39] ogbg-molclintox: 0.831690 val loss: 0.253988
[Epoch 39] ogbg-molclintox: 0.860989 test loss: 0.254711
[Epoch 40; Iter    30/   30] train: loss: 0.1563993
[Epoch 40] ogbg-molclintox: 0.850441 val loss: 0.224664
[Epoch 40] ogbg-molclintox: 0.897173 test loss: 0.224139
[Epoch 41; Iter    30/   30] train: loss: 0.3108467
[Epoch 41] ogbg-molclintox: 0.857360 val loss: 0.224064
[Epoch 41] ogbg-molclintox: 0.884767 test loss: 0.229049
[Epoch 42; Iter    30/   30] train: loss: 0.2651673
[Epoch 42] ogbg-molclintox: 0.850361 val loss: 0.210751
[Epoch 42] ogbg-molclintox: 0.904563 test loss: 0.196820
[Epoch 43; Iter    30/   30] train: loss: 0.1093018
[Epoch 43] ogbg-molclintox: 0.869634 val loss: 0.192860
[Epoch 43] ogbg-molclintox: 0.914385 test loss: 0.185435
[Epoch 44; Iter    30/   30] train: loss: 0.1216142
[Epoch 44] ogbg-molclintox: 0.831302 val loss: 0.331670
[Epoch 44] ogbg-molclintox: 0.908635 test loss: 0.280809
[Epoch 45; Iter    30/   30] train: loss: 0.3240920
[Epoch 45] ogbg-molclintox: 0.880777 val loss: 0.189188
[Epoch 45] ogbg-molclintox: 0.908025 test loss: 0.198608
[Epoch 46; Iter    30/   30] train: loss: 0.3046412
[Epoch 46] ogbg-molclintox: 0.808601 val loss: 0.230579
[Epoch 46] ogbg-molclintox: 0.806252 test loss: 0.264372
[Epoch 47; Iter    30/   30] train: loss: 0.1033232
[Epoch 47] ogbg-molclintox: 0.833943 val loss: 0.224650
[Epoch 47] ogbg-molclintox: 0.853807 test loss: 0.268945
[Epoch 48; Iter    30/   30] train: loss: 0.1048356
[Epoch 48] ogbg-molclintox: 0.814143 val loss: 0.211858
[Epoch 48] ogbg-molclintox: 0.811729 test loss: 0.317787
[Epoch 49; Iter    30/   30] train: loss: 0.0714526
[Epoch 49] ogbg-molclintox: 0.769073 val loss: 0.278297
[Epoch 49] ogbg-molclintox: 0.693862 test loss: 0.821832
[Epoch 50; Iter    30/   30] train: loss: 0.1363930
[Epoch 50] ogbg-molclintox: 0.874025 val loss: 0.237589
[Epoch 50] ogbg-molclintox: 0.894200 test loss: 0.290606
[Epoch 51; Iter    30/   30] train: loss: 0.1335012
[Epoch 51] ogbg-molclintox: 0.861899 val loss: 0.421756
[Epoch 51] ogbg-molclintox: 0.883500 test loss: 0.453882
[Epoch 52; Iter    30/   30] train: loss: 0.1106040
[Epoch 52] ogbg-molclintox: 0.889795 val loss: 0.168315
[Epoch 52] ogbg-molclintox: 0.862297 test loss: 0.195945
[Epoch 53; Iter    30/   30] train: loss: 0.0905421
[Epoch 53] ogbg-molclintox: 0.787984 val loss: 0.371624
[Epoch 53] ogbg-molclintox: 0.778883 test loss: 0.853092
[Epoch 54; Iter    30/   30] train: loss: 0.1778251
[Epoch 54] ogbg-molclintox: 0.902389 val loss: 0.160295
[Epoch 54] ogbg-molclintox: 0.906536 test loss: 0.188525
[Epoch 55; Iter    30/   30] train: loss: 0.1626874
[Epoch 55] ogbg-molclintox: 0.902396 val loss: 0.248673
[Epoch 55] ogbg-molclintox: 0.920971 test loss: 0.209559
[Epoch 56; Iter    30/   30] train: loss: 0.3161542
[Epoch 56] ogbg-molclintox: 0.887102 val loss: 0.160169
[Epoch 56] ogbg-molclintox: 0.896718 test loss: 0.140628
[Epoch 57; Iter    30/   30] train: loss: 0.1073155
[Epoch 57] ogbg-molclintox: 0.863971 val loss: 0.461947
[Epoch 57] ogbg-molclintox: 0.826447 test loss: 0.597883
[Epoch 58; Iter    30/   30] train: loss: 0.2071669
[Epoch 58] ogbg-molclintox: 0.913599 val loss: 0.146377
[Epoch 58] ogbg-molclintox: 0.879243 test loss: 0.141745
[Epoch 59; Iter    30/   30] train: loss: 0.1341601
[Epoch 59] ogbg-molclintox: 0.794133 val loss: 0.250380
[Epoch 59] ogbg-molclintox: 0.864456 test loss: 0.686739
[Epoch 60; Iter    30/   30] train: loss: 0.1328536
[Epoch 60] ogbg-molclintox: 0.871638 val loss: 0.197426
[Epoch 60] ogbg-molclintox: 0.877295 test loss: 0.159831
[Epoch 61; Iter    30/   30] train: loss: 0.0849124
[Epoch 61] ogbg-molclintox: 0.903799 val loss: 0.188153
[Epoch 61] ogbg-molclintox: 0.892762 test loss: 0.154623
[Epoch 62; Iter    30/   30] train: loss: 0.2530445
[Epoch 62] ogbg-molclintox: 0.832185 val loss: 0.212743
[Epoch 62] ogbg-molclintox: 0.851502 test loss: 0.166450
[Epoch 63; Iter    30/   30] train: loss: 0.1034369
[Epoch 63] ogbg-molclintox: 0.853370 val loss: 0.224916
[Epoch 63] ogbg-molclintox: 0.862101 test loss: 0.216552
[Epoch 64; Iter    30/   30] train: loss: 0.0337759
[Epoch 64] ogbg-molclintox: 0.891313 val loss: 0.266464
[Epoch 64] ogbg-molclintox: 0.874301 test loss: 0.350266
[Epoch 65; Iter    30/   30] train: loss: 0.1624917
[Epoch 65] ogbg-molclintox: 0.881085 val loss: 0.174756
[Epoch 65] ogbg-molclintox: 0.892381 test loss: 0.266041
[Epoch 66; Iter    30/   30] train: loss: 0.1992363
[Epoch 66] ogbg-molclintox: 0.883632 val loss: 0.227994
[Epoch 66] ogbg-molclintox: 0.854463 test loss: 0.342463
[Epoch 67; Iter    30/   30] train: loss: 0.4882749
[Epoch 67] ogbg-molclintox: 0.849393 val loss: 0.184534
[Epoch 67] ogbg-molclintox: 0.835129 test loss: 0.166121
[Epoch 68; Iter    30/   30] train: loss: 0.2075943
[Epoch 68] ogbg-molclintox: 0.817827 val loss: 0.241799
[Epoch 68] ogbg-molclintox: 0.829662 test loss: 0.202693
[Epoch 69; Iter    30/   30] train: loss: 0.0534583
[Epoch 69] ogbg-molclintox: 0.895284 val loss: 0.252382
[Epoch 69] ogbg-molclintox: 0.865402 test loss: 0.319789
[Epoch 70; Iter    30/   30] train: loss: 0.1467095
[Epoch 70] ogbg-molclintox: 0.886908 val loss: 0.185482
[Epoch 70] ogbg-molclintox: 0.903658 test loss: 0.155907
[Epoch 71; Iter    30/   30] train: loss: 0.1675806
[Epoch 71] ogbg-molclintox: 0.874394 val loss: 0.264635
[Epoch 71] ogbg-molclintox: 0.821627 test loss: 0.258638
[Epoch 72; Iter    30/   30] train: loss: 0.1191265
[Epoch 72] ogbg-molclintox: 0.885070 val loss: 0.174352
[Epoch 72] ogbg-molclintox: 0.888373 test loss: 0.159513
[Epoch 73; Iter    30/   30] train: loss: 0.0641937
[Epoch 73] ogbg-molclintox: 0.855362 val loss: 0.190101
[Epoch 73] ogbg-molclintox: 0.856514 test loss: 0.175874
[Epoch 74; Iter    30/   30] train: loss: 0.2684451
[Epoch 74] ogbg-molclintox: 0.839378 val loss: 0.274858
[Epoch 74] ogbg-molclintox: 0.824006 test loss: 0.244560
[Epoch 75; Iter    30/   30] train: loss: 0.1664717
[Epoch 75] ogbg-molclintox: 0.900271 val loss: 0.185011
[Epoch 75] ogbg-molclintox: 0.928753 test loss: 0.145507
[Epoch 76; Iter    30/   30] train: loss: 0.0223215
[Epoch 76] ogbg-molclintox: 0.886988 val loss: 0.196324
[Epoch 76] ogbg-molclintox: 0.852461 test loss: 0.223396
[Epoch 77; Iter    30/   30] train: loss: 0.0549078
[Epoch 77] ogbg-molclintox: 0.876995 val loss: 0.181597
[Epoch 77] ogbg-molclintox: 0.873464 test loss: 0.157264
[Epoch 78; Iter    30/   30] train: loss: 0.0240567
[Epoch 78] ogbg-molclintox: 0.845048 val loss: 0.235472
[Epoch 78] ogbg-molclintox: 0.801444 test loss: 0.239228
[Epoch 79; Iter    30/   30] train: loss: 0.0184413
[Epoch 79] ogbg-molclintox: 0.875684 val loss: 0.182640
[Epoch 79] ogbg-molclintox: 0.862984 test loss: 0.185256
[Epoch 80; Iter    30/   30] train: loss: 0.1784430
[Epoch 80] ogbg-molclintox: 0.861840 val loss: 0.276816
[Epoch 80] ogbg-molclintox: 0.843778 test loss: 0.222507
[Epoch 81; Iter    30/   30] train: loss: 0.1181130
[Epoch 81] ogbg-molclintox: 0.858578 val loss: 0.229184
[Epoch 81] ogbg-molclintox: 0.859687 test loss: 0.207283
[Epoch 82; Iter    30/   30] train: loss: 0.1143393
[Epoch 82] ogbg-molclintox: 0.890779 val loss: 0.240932
[Epoch 82] ogbg-molclintox: 0.892170 test loss: 0.246276
[Epoch 83; Iter    30/   30] train: loss: 0.2416905
[Epoch 83] ogbg-molclintox: 0.822199 val loss: 0.218876
[Epoch 83] ogbg-molclintox: 0.866691 test loss: 0.160737
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 84; Iter    30/   30] train: loss: 0.1649417
[Epoch 84] ogbg-molclintox: 0.913320 val loss: 0.353972
[Epoch 84] ogbg-molclintox: 0.894566 test loss: 0.149656
[Epoch 85; Iter    30/   30] train: loss: 0.0780383
[Epoch 85] ogbg-molclintox: 0.846103 val loss: 0.317267
[Epoch 85] ogbg-molclintox: 0.878419 test loss: 0.171527
[Epoch 86; Iter    30/   30] train: loss: 0.1495100
[Epoch 86] ogbg-molclintox: 0.901602 val loss: 1.301414
[Epoch 86] ogbg-molclintox: 0.915455 test loss: 0.181511
[Epoch 87; Iter    30/   30] train: loss: 0.0310677
[Epoch 87] ogbg-molclintox: 0.876086 val loss: 4.670619
[Epoch 87] ogbg-molclintox: 0.903405 test loss: 3.846791
[Epoch 88; Iter    30/   30] train: loss: 0.1676334
[Epoch 88] ogbg-molclintox: 0.890009 val loss: 0.983186
[Epoch 88] ogbg-molclintox: 0.888981 test loss: 0.209711
[Epoch 89; Iter    30/   30] train: loss: 0.0806876
[Epoch 89] ogbg-molclintox: 0.872228 val loss: 0.457977
[Epoch 89] ogbg-molclintox: 0.893207 test loss: 0.170996
[Epoch 90; Iter    30/   30] train: loss: 0.0142830
[Epoch 90] ogbg-molclintox: 0.877322 val loss: 1.151809
[Epoch 90] ogbg-molclintox: 0.889790 test loss: 0.148329
[Epoch 91; Iter    30/   30] train: loss: 0.2658925
[Epoch 91] ogbg-molclintox: 0.900853 val loss: 0.885855
[Epoch 91] ogbg-molclintox: 0.917852 test loss: 0.150736
[Epoch 92; Iter    30/   30] train: loss: 0.0123436
[Epoch 92] ogbg-molclintox: 0.866934 val loss: 0.461171
[Epoch 92] ogbg-molclintox: 0.887198 test loss: 0.184387
[Epoch 93; Iter    30/   30] train: loss: 0.0186123
[Epoch 93] ogbg-molclintox: 0.893299 val loss: 0.192563
[Epoch 93] ogbg-molclintox: 0.919490 test loss: 0.156583
[Epoch 94; Iter    30/   30] train: loss: 0.1504009
[Epoch 94] ogbg-molclintox: 0.859467 val loss: 0.211912
[Epoch 94] ogbg-molclintox: 0.887289 test loss: 0.175426
[Epoch 95; Iter    30/   30] train: loss: 0.0145305
[Epoch 95] ogbg-molclintox: 0.888052 val loss: 0.219474
[Epoch 95] ogbg-molclintox: 0.912838 test loss: 0.179469
[Epoch 96; Iter    30/   30] train: loss: 0.0232471
[Epoch 96] ogbg-molclintox: 0.889990 val loss: 0.192935
[Epoch 96] ogbg-molclintox: 0.916936 test loss: 0.159466
[Epoch 97; Iter    30/   30] train: loss: 0.0126442
[Epoch 97] ogbg-molclintox: 0.882355 val loss: 0.203360
[Epoch 97] ogbg-molclintox: 0.921076 test loss: 0.165839
[Epoch 98; Iter    30/   30] train: loss: 0.0242460
[Epoch 98] ogbg-molclintox: 0.885063 val loss: 0.189132
[Epoch 98] ogbg-molclintox: 0.909449 test loss: 0.160773
[Epoch 99; Iter    30/   30] train: loss: 0.4054300
[Epoch 99] ogbg-molclintox: 0.894843 val loss: 0.186804
[Epoch 99] ogbg-molclintox: 0.908919 test loss: 0.161981
[Epoch 100; Iter    30/   30] train: loss: 0.0147877
[Epoch 100] ogbg-molclintox: 0.887128 val loss: 0.192889
[Epoch 100] ogbg-molclintox: 0.906766 test loss: 0.176708
[Epoch 101; Iter    30/   30] train: loss: 0.0174710
[Epoch 101] ogbg-molclintox: 0.867803 val loss: 0.193955
[Epoch 101] ogbg-molclintox: 0.900400 test loss: 0.161671
[Epoch 102; Iter    30/   30] train: loss: 0.2238723
[Epoch 102] ogbg-molclintox: 0.877683 val loss: 0.191902
[Epoch 102] ogbg-molclintox: 0.903666 test loss: 0.189057
[Epoch 103; Iter    30/   30] train: loss: 0.0069898
[Epoch 103] ogbg-molclintox: 0.880190 val loss: 0.209088
[Epoch 103] ogbg-molclintox: 0.900636 test loss: 0.182187
[Epoch 104; Iter    30/   30] train: loss: 0.0422646
[Epoch 104] ogbg-molclintox: 0.890564 val loss: 0.228629
[Epoch 104] ogbg-molclintox: 0.909812 test loss: 0.234972
[Epoch 105; Iter    30/   30] train: loss: 0.0783085
[Epoch 105] ogbg-molclintox: 0.901253 val loss: 0.181065
[Epoch 105] ogbg-molclintox: 0.915693 test loss: 0.205709
[Epoch 106; Iter    30/   30] train: loss: 0.0413508
[Epoch 106] ogbg-molclintox: 0.879180 val loss: 0.229032
[Epoch 106] ogbg-molclintox: 0.896334 test loss: 0.432078
[Epoch 107; Iter    30/   30] train: loss: 0.0476259
[Epoch 107] ogbg-molclintox: 0.890010 val loss: 0.385420
[Epoch 107] ogbg-molclintox: 0.902903 test loss: 0.163841
[Epoch 108; Iter    30/   30] train: loss: 0.0063469
[Epoch 108] ogbg-molclintox: 0.888325 val loss: 1.080537
[Epoch 108] ogbg-molclintox: 0.901061 test loss: 0.139916
[Epoch 109; Iter    30/   30] train: loss: 0.0508594
[Epoch 109] ogbg-molclintox: 0.896293 val loss: 1.015381
[Epoch 109] ogbg-molclintox: 0.918758 test loss: 0.152495
[Epoch 110; Iter    30/   30] train: loss: 0.0336441
[Epoch 110] ogbg-molclintox: 0.874334 val loss: 0.941056
[Epoch 110] ogbg-molclintox: 0.896303 test loss: 0.161514
[Epoch 111; Iter    30/   30] train: loss: 0.1093150
[Epoch 111] ogbg-molclintox: 0.875257 val loss: 0.781845
[Epoch 111] ogbg-molclintox: 0.896423 test loss: 0.170034
[Epoch 112; Iter    30/   30] train: loss: 0.0707386
[Epoch 112] ogbg-molclintox: 0.876199 val loss: 1.093802
[Epoch 112] ogbg-molclintox: 0.909395 test loss: 0.194055
[Epoch 113; Iter    30/   30] train: loss: 0.1123317
[Epoch 113] ogbg-molclintox: 0.876561 val loss: 0.583251
[Epoch 113] ogbg-molclintox: 0.905053 test loss: 0.165259
[Epoch 114; Iter    30/   30] train: loss: 0.0506887
[Epoch 114] ogbg-molclintox: 0.869802 val loss: 0.930252
[Epoch 114] ogbg-molclintox: 0.899245 test loss: 0.158976
[Epoch 115; Iter    30/   30] train: loss: 0.1008532
[Epoch 115] ogbg-molclintox: 0.861693 val loss: 0.792812
[Epoch 115] ogbg-molclintox: 0.895171 test loss: 0.162345
[Epoch 116; Iter    30/   30] train: loss: 0.0389881
[Epoch 116] ogbg-molclintox: 0.874641 val loss: 0.443479
[Epoch 116] ogbg-molclintox: 0.906386 test loss: 0.160619
[Epoch 117; Iter    30/   30] train: loss: 0.0167375
[Epoch 117] ogbg-molclintox: 0.871038 val loss: 0.446564
[Epoch 117] ogbg-molclintox: 0.896437 test loss: 0.159456
[Epoch 118; Iter    30/   30] train: loss: 0.1781912
[Epoch 118] ogbg-molclintox: 0.856639 val loss: 0.309820
[Epoch 118] ogbg-molclintox: 0.888798 test loss: 0.156201
[Epoch 119; Iter    30/   30] train: loss: 0.0094082
[Epoch 119] ogbg-molclintox: 0.863077 val loss: 0.218154
[Epoch 119] ogbg-molclintox: 0.892685 test loss: 0.152531
[Epoch 120; Iter    30/   30] train: loss: 0.0261950
[Epoch 120] ogbg-molclintox: 0.873565 val loss: 0.222961
[Epoch 120] ogbg-molclintox: 0.895723 test loss: 0.159891
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 120 epochs. Best model checkpoint was in epoch 57.
Statistics on  val_best_checkpoint
mean_pred: 0.08811201900243759
std_pred: 4.706870079040527
mean_targets: 0.505084753036499
std_targets: 0.5003983974456787
prcauc: 0.8174184420598256
rocauc: 0.9315418939453828
ogbg-molclintox: 0.9315418939453828
OGBNanLabelBCEWithLogitsLoss: 0.13615226447582246
Statistics on  test
mean_pred: 0.08921069651842117
std_pred: 5.699143409729004
mean_targets: 0.5033783912658691
std_targets: 0.5004113912582397
prcauc: 0.7080174621199393
rocauc: 0.9324198961499492
ogbg-molclintox: 0.9324198961499492
OGBNanLabelBCEWithLogitsLoss: 0.3143233429407701
Statistics on  train
mean_pred: 0.11941719800233841
std_pred: 9.596549987792969
mean_targets: 0.5073363780975342
std_targets: 0.500087320804596
prcauc: 0.8865622091663602
rocauc: 0.9734116330658839
ogbg-molclintox: 0.9734116330658839
OGBNanLabelBCEWithLogitsLoss: 0.1179690534248948
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 84; Iter    30/   30] train: loss: 0.2613111
[Epoch 84] ogbg-molclintox: 0.860462 val loss: 0.212849
[Epoch 84] ogbg-molclintox: 0.867175 test loss: 0.156082
[Epoch 85; Iter    30/   30] train: loss: 0.0618187
[Epoch 85] ogbg-molclintox: 0.895858 val loss: 0.206730
[Epoch 85] ogbg-molclintox: 0.908855 test loss: 0.175389
[Epoch 86; Iter    30/   30] train: loss: 0.0362386
[Epoch 86] ogbg-molclintox: 0.909863 val loss: 0.162064
[Epoch 86] ogbg-molclintox: 0.934009 test loss: 0.114751
[Epoch 87; Iter    30/   30] train: loss: 0.1543975
[Epoch 87] ogbg-molclintox: 0.869152 val loss: 0.220089
[Epoch 87] ogbg-molclintox: 0.946462 test loss: 0.131839
[Epoch 88; Iter    30/   30] train: loss: 0.0911393
[Epoch 88] ogbg-molclintox: 0.926870 val loss: 0.178710
[Epoch 88] ogbg-molclintox: 0.926109 test loss: 0.120200
[Epoch 89; Iter    30/   30] train: loss: 0.1062055
[Epoch 89] ogbg-molclintox: 0.879734 val loss: 0.184153
[Epoch 89] ogbg-molclintox: 0.917052 test loss: 0.119831
[Epoch 90; Iter    30/   30] train: loss: 0.3290038
[Epoch 90] ogbg-molclintox: 0.898814 val loss: 0.172463
[Epoch 90] ogbg-molclintox: 0.929325 test loss: 0.124923
[Epoch 91; Iter    30/   30] train: loss: 0.2709730
[Epoch 91] ogbg-molclintox: 0.902549 val loss: 0.178633
[Epoch 91] ogbg-molclintox: 0.931796 test loss: 0.135578
[Epoch 92; Iter    30/   30] train: loss: 0.1670889
[Epoch 92] ogbg-molclintox: 0.901225 val loss: 0.186560
[Epoch 92] ogbg-molclintox: 0.939703 test loss: 0.137036
[Epoch 93; Iter    30/   30] train: loss: 0.4063644
[Epoch 93] ogbg-molclintox: 0.881346 val loss: 0.188167
[Epoch 93] ogbg-molclintox: 0.911265 test loss: 0.138614
[Epoch 94; Iter    30/   30] train: loss: 0.1683423
[Epoch 94] ogbg-molclintox: 0.920853 val loss: 0.160355
[Epoch 94] ogbg-molclintox: 0.930158 test loss: 0.125939
[Epoch 95; Iter    30/   30] train: loss: 0.1899692
[Epoch 95] ogbg-molclintox: 0.880243 val loss: 0.189963
[Epoch 95] ogbg-molclintox: 0.911565 test loss: 0.142832
[Epoch 96; Iter    30/   30] train: loss: 0.0121782
[Epoch 96] ogbg-molclintox: 0.863952 val loss: 0.199864
[Epoch 96] ogbg-molclintox: 0.914652 test loss: 0.124985
[Epoch 97; Iter    30/   30] train: loss: 0.5628548
[Epoch 97] ogbg-molclintox: 0.862521 val loss: 0.194958
[Epoch 97] ogbg-molclintox: 0.910737 test loss: 0.135509
[Epoch 98; Iter    30/   30] train: loss: 0.0067946
[Epoch 98] ogbg-molclintox: 0.872207 val loss: 0.219955
[Epoch 98] ogbg-molclintox: 0.906435 test loss: 0.166082
[Epoch 99; Iter    30/   30] train: loss: 0.0710376
[Epoch 99] ogbg-molclintox: 0.873137 val loss: 0.193787
[Epoch 99] ogbg-molclintox: 0.913830 test loss: 0.138820
[Epoch 100; Iter    30/   30] train: loss: 0.0914034
[Epoch 100] ogbg-molclintox: 0.874688 val loss: 0.190866
[Epoch 100] ogbg-molclintox: 0.902205 test loss: 0.147872
[Epoch 101; Iter    30/   30] train: loss: 0.0445312
[Epoch 101] ogbg-molclintox: 0.876553 val loss: 0.210796
[Epoch 101] ogbg-molclintox: 0.913326 test loss: 0.141921
[Epoch 102; Iter    30/   30] train: loss: 0.1275491
[Epoch 102] ogbg-molclintox: 0.888325 val loss: 0.189593
[Epoch 102] ogbg-molclintox: 0.914100 test loss: 0.142451
[Epoch 103; Iter    30/   30] train: loss: 0.0709788
[Epoch 103] ogbg-molclintox: 0.877322 val loss: 0.217370
[Epoch 103] ogbg-molclintox: 0.911761 test loss: 0.165853
[Epoch 104; Iter    30/   30] train: loss: 0.1049101
[Epoch 104] ogbg-molclintox: 0.865997 val loss: 0.200752
[Epoch 104] ogbg-molclintox: 0.911576 test loss: 0.153112
[Epoch 105; Iter    30/   30] train: loss: 0.0251814
[Epoch 105] ogbg-molclintox: 0.873097 val loss: 0.206693
[Epoch 105] ogbg-molclintox: 0.914038 test loss: 0.147677
[Epoch 106; Iter    30/   30] train: loss: 0.0049729
[Epoch 106] ogbg-molclintox: 0.883859 val loss: 0.216717
[Epoch 106] ogbg-molclintox: 0.909662 test loss: 0.169691
[Epoch 107; Iter    30/   30] train: loss: 0.0681662
[Epoch 107] ogbg-molclintox: 0.898667 val loss: 0.188628
[Epoch 107] ogbg-molclintox: 0.918331 test loss: 0.136493
[Epoch 108; Iter    30/   30] train: loss: 0.1947636
[Epoch 108] ogbg-molclintox: 0.883565 val loss: 0.214984
[Epoch 108] ogbg-molclintox: 0.922132 test loss: 0.138027
[Epoch 109; Iter    30/   30] train: loss: 0.0301420
[Epoch 109] ogbg-molclintox: 0.889969 val loss: 0.191473
[Epoch 109] ogbg-molclintox: 0.930421 test loss: 0.137631
[Epoch 110; Iter    30/   30] train: loss: 0.1049390
[Epoch 110] ogbg-molclintox: 0.875156 val loss: 0.214719
[Epoch 110] ogbg-molclintox: 0.940128 test loss: 0.129717
[Epoch 111; Iter    30/   30] train: loss: 0.0146121
[Epoch 111] ogbg-molclintox: 0.878812 val loss: 0.225631
[Epoch 111] ogbg-molclintox: 0.934890 test loss: 0.140228
[Epoch 112; Iter    30/   30] train: loss: 0.0064592
[Epoch 112] ogbg-molclintox: 0.870817 val loss: 0.219741
[Epoch 112] ogbg-molclintox: 0.913664 test loss: 0.152159
[Epoch 113; Iter    30/   30] train: loss: 0.0262870
[Epoch 113] ogbg-molclintox: 0.875369 val loss: 0.191718
[Epoch 113] ogbg-molclintox: 0.913800 test loss: 0.134802
[Epoch 114; Iter    30/   30] train: loss: 0.0662658
[Epoch 114] ogbg-molclintox: 0.852480 val loss: 0.226625
[Epoch 114] ogbg-molclintox: 0.867521 test loss: 0.179673
[Epoch 115; Iter    30/   30] train: loss: 0.0532811
[Epoch 115] ogbg-molclintox: 0.885604 val loss: 0.201270
[Epoch 115] ogbg-molclintox: 0.905343 test loss: 0.138945
[Epoch 116; Iter    30/   30] train: loss: 0.0566355
[Epoch 116] ogbg-molclintox: 0.882996 val loss: 0.200864
[Epoch 116] ogbg-molclintox: 0.925656 test loss: 0.125671
[Epoch 117; Iter    30/   30] train: loss: 0.0203133
[Epoch 117] ogbg-molclintox: 0.887489 val loss: 0.199672
[Epoch 117] ogbg-molclintox: 0.933150 test loss: 0.137565
[Epoch 118; Iter    30/   30] train: loss: 0.0128803
[Epoch 118] ogbg-molclintox: 0.869874 val loss: 0.210137
[Epoch 118] ogbg-molclintox: 0.922802 test loss: 0.144788
[Epoch 119; Iter    30/   30] train: loss: 0.0225073
[Epoch 119] ogbg-molclintox: 0.836945 val loss: 0.222623
[Epoch 119] ogbg-molclintox: 0.893293 test loss: 0.154829
[Epoch 120; Iter    30/   30] train: loss: 0.0077197
[Epoch 120] ogbg-molclintox: 0.881573 val loss: 0.212254
[Epoch 120] ogbg-molclintox: 0.916580 test loss: 0.144583
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 120 epochs. Best model checkpoint was in epoch 60.
Statistics on  val_best_checkpoint
mean_pred: 0.09463974088430405
std_pred: 4.4651360511779785
mean_targets: 0.505084753036499
std_targets: 0.5003983974456787
prcauc: 0.8368432498541074
rocauc: 0.9407462898200467
ogbg-molclintox: 0.9407462898200467
OGBNanLabelBCEWithLogitsLoss: 0.16021687015891076
Statistics on  test
mean_pred: 0.06773298233747482
std_pred: 14.266582489013672
mean_targets: 0.5033783912658691
std_targets: 0.5004113912582397
prcauc: 0.7975970346964655
rocauc: 0.9568784827760891
ogbg-molclintox: 0.9568784827760891
OGBNanLabelBCEWithLogitsLoss: 0.8837942817714065
Statistics on  train
mean_pred: 0.1336485892534256
std_pred: 5.095597743988037
mean_targets: 0.5073363780975342
std_targets: 0.500087320804596
prcauc: 0.8860424927853663
rocauc: 0.9749888318395576
ogbg-molclintox: 0.9749888318395576
OGBNanLabelBCEWithLogitsLoss: 0.11473737247288227
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 84; Iter    30/   30] train: loss: 0.2041776
[Epoch 84] ogbg-molclintox: 0.884455 val loss: 0.173086
[Epoch 84] ogbg-molclintox: 0.861120 test loss: 0.188296
[Epoch 85; Iter    30/   30] train: loss: 0.0394458
[Epoch 85] ogbg-molclintox: 0.835756 val loss: 0.210201
[Epoch 85] ogbg-molclintox: 0.876703 test loss: 0.175880
[Epoch 86; Iter    30/   30] train: loss: 0.0589605
[Epoch 86] ogbg-molclintox: 0.857442 val loss: 0.212871
[Epoch 86] ogbg-molclintox: 0.896790 test loss: 0.167467
[Epoch 87; Iter    30/   30] train: loss: 0.1377483
[Epoch 87] ogbg-molclintox: 0.829713 val loss: 0.249613
[Epoch 87] ogbg-molclintox: 0.841219 test loss: 0.219019
[Epoch 88; Iter    30/   30] train: loss: 0.1028310
[Epoch 88] ogbg-molclintox: 0.863418 val loss: 0.213713
[Epoch 88] ogbg-molclintox: 0.889958 test loss: 0.176612
[Epoch 89; Iter    30/   30] train: loss: 0.0796436
[Epoch 89] ogbg-molclintox: 0.850596 val loss: 0.209656
[Epoch 89] ogbg-molclintox: 0.877492 test loss: 0.164505
[Epoch 90; Iter    30/   30] train: loss: 0.0637052
[Epoch 90] ogbg-molclintox: 0.861279 val loss: 0.230605
[Epoch 90] ogbg-molclintox: 0.886751 test loss: 0.193498
[Epoch 91; Iter    30/   30] train: loss: 0.1586985
[Epoch 91] ogbg-molclintox: 0.840095 val loss: 0.221107
[Epoch 91] ogbg-molclintox: 0.867569 test loss: 0.197669
[Epoch 92; Iter    30/   30] train: loss: 0.0824426
[Epoch 92] ogbg-molclintox: 0.863124 val loss: 0.208184
[Epoch 92] ogbg-molclintox: 0.900697 test loss: 0.169392
[Epoch 93; Iter    30/   30] train: loss: 0.2358299
[Epoch 93] ogbg-molclintox: 0.871199 val loss: 0.207326
[Epoch 93] ogbg-molclintox: 0.884734 test loss: 0.192689
[Epoch 94; Iter    30/   30] train: loss: 0.1657996
[Epoch 94] ogbg-molclintox: 0.857081 val loss: 0.208748
[Epoch 94] ogbg-molclintox: 0.867174 test loss: 0.177961
[Epoch 95; Iter    30/   30] train: loss: 0.0182321
[Epoch 95] ogbg-molclintox: 0.856232 val loss: 0.212628
[Epoch 95] ogbg-molclintox: 0.888464 test loss: 0.165271
[Epoch 96; Iter    30/   30] train: loss: 0.0443440
[Epoch 96] ogbg-molclintox: 0.870150 val loss: 0.195111
[Epoch 96] ogbg-molclintox: 0.892892 test loss: 0.158582
[Epoch 97; Iter    30/   30] train: loss: 0.1150288
[Epoch 97] ogbg-molclintox: 0.851974 val loss: 0.213510
[Epoch 97] ogbg-molclintox: 0.911145 test loss: 0.147707
[Epoch 98; Iter    30/   30] train: loss: 0.0173830
[Epoch 98] ogbg-molclintox: 0.853170 val loss: 0.213699
[Epoch 98] ogbg-molclintox: 0.890802 test loss: 0.184205
[Epoch 99; Iter    30/   30] train: loss: 0.2826458
[Epoch 99] ogbg-molclintox: 0.838698 val loss: 0.206334
[Epoch 99] ogbg-molclintox: 0.894056 test loss: 0.153325
[Epoch 100; Iter    30/   30] train: loss: 0.0628233
[Epoch 100] ogbg-molclintox: 0.821885 val loss: 0.222159
[Epoch 100] ogbg-molclintox: 0.872497 test loss: 0.166452
[Epoch 101; Iter    30/   30] train: loss: 0.0173729
[Epoch 101] ogbg-molclintox: 0.839460 val loss: 0.219796
[Epoch 101] ogbg-molclintox: 0.880110 test loss: 0.173708
[Epoch 102; Iter    30/   30] train: loss: 0.0560213
[Epoch 102] ogbg-molclintox: 0.853377 val loss: 0.210148
[Epoch 102] ogbg-molclintox: 0.882370 test loss: 0.181913
[Epoch 103; Iter    30/   30] train: loss: 0.1236582
[Epoch 103] ogbg-molclintox: 0.865925 val loss: 0.199102
[Epoch 103] ogbg-molclintox: 0.897629 test loss: 0.159048
[Epoch 104; Iter    30/   30] train: loss: 0.0290757
[Epoch 104] ogbg-molclintox: 0.839727 val loss: 0.228198
[Epoch 104] ogbg-molclintox: 0.895725 test loss: 0.169107
[Epoch 105; Iter    30/   30] train: loss: 0.1790783
[Epoch 105] ogbg-molclintox: 0.844594 val loss: 0.212134
[Epoch 105] ogbg-molclintox: 0.901819 test loss: 0.154348
[Epoch 106; Iter    30/   30] train: loss: 0.0104128
[Epoch 106] ogbg-molclintox: 0.840824 val loss: 0.218434
[Epoch 106] ogbg-molclintox: 0.905201 test loss: 0.154149
[Epoch 107; Iter    30/   30] train: loss: 0.0603738
[Epoch 107] ogbg-molclintox: 0.860904 val loss: 0.216361
[Epoch 107] ogbg-molclintox: 0.893396 test loss: 0.169885
[Epoch 108; Iter    30/   30] train: loss: 0.0138288
[Epoch 108] ogbg-molclintox: 0.865303 val loss: 0.224071
[Epoch 108] ogbg-molclintox: 0.901720 test loss: 0.195446
[Epoch 109; Iter    30/   30] train: loss: 0.0481589
[Epoch 109] ogbg-molclintox: 0.853030 val loss: 0.208696
[Epoch 109] ogbg-molclintox: 0.905839 test loss: 0.169188
[Epoch 110; Iter    30/   30] train: loss: 0.0475249
[Epoch 110] ogbg-molclintox: 0.848244 val loss: 0.195514
[Epoch 110] ogbg-molclintox: 0.872349 test loss: 0.165165
[Epoch 111; Iter    30/   30] train: loss: 0.0152021
[Epoch 111] ogbg-molclintox: 0.833316 val loss: 0.242530
[Epoch 111] ogbg-molclintox: 0.892542 test loss: 0.177556
[Epoch 112; Iter    30/   30] train: loss: 0.2828662
[Epoch 112] ogbg-molclintox: 0.828082 val loss: 0.224915
[Epoch 112] ogbg-molclintox: 0.877378 test loss: 0.163305
[Epoch 113; Iter    30/   30] train: loss: 0.0096171
[Epoch 113] ogbg-molclintox: 0.830943 val loss: 0.224424
[Epoch 113] ogbg-molclintox: 0.883467 test loss: 0.163077
[Epoch 114; Iter    30/   30] train: loss: 0.0760106
[Epoch 114] ogbg-molclintox: 0.831973 val loss: 0.223084
[Epoch 114] ogbg-molclintox: 0.890705 test loss: 0.166053
[Epoch 115; Iter    30/   30] train: loss: 0.0306496
[Epoch 115] ogbg-molclintox: 0.825629 val loss: 0.228667
[Epoch 115] ogbg-molclintox: 0.871967 test loss: 0.178367
[Epoch 116; Iter    30/   30] train: loss: 0.1751254
[Epoch 116] ogbg-molclintox: 0.831786 val loss: 0.232220
[Epoch 116] ogbg-molclintox: 0.895760 test loss: 0.164002
[Epoch 117; Iter    30/   30] train: loss: 0.3104573
[Epoch 117] ogbg-molclintox: 0.841605 val loss: 0.223080
[Epoch 117] ogbg-molclintox: 0.909256 test loss: 0.152533
[Epoch 118; Iter    30/   30] train: loss: 0.1439157
[Epoch 118] ogbg-molclintox: 0.841820 val loss: 0.219166
[Epoch 118] ogbg-molclintox: 0.902208 test loss: 0.158061
[Epoch 119; Iter    30/   30] train: loss: 0.1843329
[Epoch 119] ogbg-molclintox: 0.838584 val loss: 0.238544
[Epoch 119] ogbg-molclintox: 0.897910 test loss: 0.180800
[Epoch 120; Iter    30/   30] train: loss: 0.0461068
[Epoch 120] ogbg-molclintox: 0.842829 val loss: 0.224689
[Epoch 120] ogbg-molclintox: 0.907429 test loss: 0.167542
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 120 epochs. Best model checkpoint was in epoch 58.
Statistics on  val_best_checkpoint
mean_pred: 0.09337250143289566
std_pred: 5.297288417816162
mean_targets: 0.505084753036499
std_targets: 0.5003983974456787
prcauc: 0.785761371847582
rocauc: 0.9135994758211416
ogbg-molclintox: 0.9135994758211416
OGBNanLabelBCEWithLogitsLoss: 0.14637733083218335
Statistics on  test
mean_pred: 0.07288945466279984
std_pred: 5.399859428405762
mean_targets: 0.5033783912658691
std_targets: 0.5004113912582397
prcauc: 0.6976734605659496
rocauc: 0.8792426545086118
ogbg-molclintox: 0.8792426545086118
OGBNanLabelBCEWithLogitsLoss: 0.1417449661064893
Statistics on  train
mean_pred: 0.13213789463043213
std_pred: 5.754748344421387
mean_targets: 0.5073363780975342
std_targets: 0.500087320804596
prcauc: 0.8876225261892481
rocauc: 0.9701440040791296
ogbg-molclintox: 0.9701440040791296
OGBNanLabelBCEWithLogitsLoss: 0.12049108352512121
All runs completed.
[Epoch 76] ogbg-molclintox: 0.969220 val loss: 0.080703
[Epoch 76] ogbg-molclintox: 0.812821 test loss: 0.224729
[Epoch 77; Iter    20/   40] train: loss: 0.0183359
[Epoch 77] ogbg-molclintox: 0.982444 val loss: 0.064930
[Epoch 77] ogbg-molclintox: 0.816493 test loss: 0.220159
[Epoch 78; Iter    10/   40] train: loss: 0.0077401
[Epoch 78; Iter    40/   40] train: loss: 0.0050406
[Epoch 78] ogbg-molclintox: 0.978810 val loss: 0.091045
[Epoch 78] ogbg-molclintox: 0.814633 test loss: 0.251806
[Epoch 79; Iter    30/   40] train: loss: 0.0865549
[Epoch 79] ogbg-molclintox: 0.956945 val loss: 0.094143
[Epoch 79] ogbg-molclintox: 0.799318 test loss: 0.243682
[Epoch 80; Iter    20/   40] train: loss: 0.0536749
[Epoch 80] ogbg-molclintox: 0.976463 val loss: 0.065908
[Epoch 80] ogbg-molclintox: 0.788325 test loss: 0.256483
[Epoch 81; Iter    10/   40] train: loss: 0.0292201
[Epoch 81; Iter    40/   40] train: loss: 0.0093906
[Epoch 81] ogbg-molclintox: 0.967621 val loss: 0.073041
[Epoch 81] ogbg-molclintox: 0.784291 test loss: 0.230824
[Epoch 82; Iter    30/   40] train: loss: 0.0181183
[Epoch 82] ogbg-molclintox: 0.975201 val loss: 0.066528
[Epoch 82] ogbg-molclintox: 0.776832 test loss: 0.263269
[Epoch 83; Iter    20/   40] train: loss: 0.0114132
[Epoch 83] ogbg-molclintox: 0.958007 val loss: 0.092500
[Epoch 83] ogbg-molclintox: 0.783253 test loss: 0.241918
[Epoch 84; Iter    10/   40] train: loss: 0.0163525
[Epoch 84; Iter    40/   40] train: loss: 0.0147301
[Epoch 84] ogbg-molclintox: 0.955884 val loss: 0.086553
[Epoch 84] ogbg-molclintox: 0.815682 test loss: 0.230067
[Epoch 85; Iter    30/   40] train: loss: 0.0231001
[Epoch 85] ogbg-molclintox: 0.950040 val loss: 0.087200
[Epoch 85] ogbg-molclintox: 0.754782 test loss: 0.235533
[Epoch 86; Iter    20/   40] train: loss: 0.0373843
[Epoch 86] ogbg-molclintox: 0.949541 val loss: 0.090277
[Epoch 86] ogbg-molclintox: 0.812672 test loss: 0.217940
[Epoch 87; Iter    10/   40] train: loss: 0.0976380
[Epoch 87; Iter    40/   40] train: loss: 0.0120754
[Epoch 87] ogbg-molclintox: 0.976712 val loss: 0.075200
[Epoch 87] ogbg-molclintox: 0.841153 test loss: 0.244442
[Epoch 88; Iter    30/   40] train: loss: 0.0380908
[Epoch 88] ogbg-molclintox: 0.960242 val loss: 0.080930
[Epoch 88] ogbg-molclintox: 0.822951 test loss: 0.234477
[Epoch 89; Iter    20/   40] train: loss: 0.0494428
[Epoch 89] ogbg-molclintox: 0.956021 val loss: 0.104168
[Epoch 89] ogbg-molclintox: 0.792621 test loss: 0.233482
[Epoch 90; Iter    10/   40] train: loss: 0.0232002
[Epoch 90; Iter    40/   40] train: loss: 0.0352879
[Epoch 90] ogbg-molclintox: 0.958955 val loss: 0.082025
[Epoch 90] ogbg-molclintox: 0.804977 test loss: 0.250367
[Epoch 91; Iter    30/   40] train: loss: 0.0212057
[Epoch 91] ogbg-molclintox: 0.962926 val loss: 0.086324
[Epoch 91] ogbg-molclintox: 0.808787 test loss: 0.256607
[Epoch 92; Iter    20/   40] train: loss: 0.0315185
[Epoch 92] ogbg-molclintox: 0.966086 val loss: 0.085476
[Epoch 92] ogbg-molclintox: 0.810823 test loss: 0.246806
[Epoch 93; Iter    10/   40] train: loss: 0.0146942
[Epoch 93; Iter    40/   40] train: loss: 0.2332588
[Epoch 93] ogbg-molclintox: 0.970893 val loss: 0.078549
[Epoch 93] ogbg-molclintox: 0.789860 test loss: 0.265820
[Epoch 94; Iter    30/   40] train: loss: 0.0604744
[Epoch 94] ogbg-molclintox: 0.993907 val loss: 0.048824
[Epoch 94] ogbg-molclintox: 0.824800 test loss: 0.236859
[Epoch 95; Iter    20/   40] train: loss: 0.0049837
[Epoch 95] ogbg-molclintox: 0.952412 val loss: 0.105389
[Epoch 95] ogbg-molclintox: 0.791410 test loss: 0.275207
[Epoch 96; Iter    10/   40] train: loss: 0.0363946
[Epoch 96; Iter    40/   40] train: loss: 0.0284595
[Epoch 96] ogbg-molclintox: 0.959992 val loss: 0.111039
[Epoch 96] ogbg-molclintox: 0.800655 test loss: 0.285302
[Epoch 97; Iter    30/   40] train: loss: 0.0293601
[Epoch 97] ogbg-molclintox: 0.961753 val loss: 0.097494
[Epoch 97] ogbg-molclintox: 0.804327 test loss: 0.276407
[Epoch 98; Iter    20/   40] train: loss: 0.0355522
[Epoch 98] ogbg-molclintox: 0.898331 val loss: 0.124518
[Epoch 98] ogbg-molclintox: 0.776469 test loss: 0.263875
[Epoch 99; Iter    10/   40] train: loss: 0.0096982
[Epoch 99; Iter    40/   40] train: loss: 0.0343329
[Epoch 99] ogbg-molclintox: 0.959518 val loss: 0.109385
[Epoch 99] ogbg-molclintox: 0.800666 test loss: 0.263614
[Epoch 100; Iter    30/   40] train: loss: 0.0287008
[Epoch 100] ogbg-molclintox: 0.941761 val loss: 0.101279
[Epoch 100] ogbg-molclintox: 0.797043 test loss: 0.266722
[Epoch 101; Iter    20/   40] train: loss: 0.0276246
[Epoch 101] ogbg-molclintox: 0.946431 val loss: 0.093477
[Epoch 101] ogbg-molclintox: 0.794821 test loss: 0.263705
[Epoch 102; Iter    10/   40] train: loss: 0.0579837
[Epoch 102; Iter    40/   40] train: loss: 0.0064685
[Epoch 102] ogbg-molclintox: 0.927775 val loss: 0.102855
[Epoch 102] ogbg-molclintox: 0.751645 test loss: 0.258916
[Epoch 103; Iter    30/   40] train: loss: 0.0893345
[Epoch 103] ogbg-molclintox: 0.944021 val loss: 0.100404
[Epoch 103] ogbg-molclintox: 0.784601 test loss: 0.284275
[Epoch 104; Iter    20/   40] train: loss: 0.0313924
[Epoch 104] ogbg-molclintox: 0.914263 val loss: 0.124887
[Epoch 104] ogbg-molclintox: 0.799378 test loss: 0.275137
[Epoch 105; Iter    10/   40] train: loss: 0.0098173
[Epoch 105; Iter    40/   40] train: loss: 0.0435181
[Epoch 105] ogbg-molclintox: 0.908982 val loss: 0.106313
[Epoch 105] ogbg-molclintox: 0.765514 test loss: 0.258451
[Epoch 106; Iter    30/   40] train: loss: 0.1041549
[Epoch 106] ogbg-molclintox: 0.922293 val loss: 0.102133
[Epoch 106] ogbg-molclintox: 0.761528 test loss: 0.262506
[Epoch 107; Iter    20/   40] train: loss: 0.0276143
[Epoch 107] ogbg-molclintox: 0.930372 val loss: 0.097628
[Epoch 107] ogbg-molclintox: 0.762428 test loss: 0.266576
[Epoch 108; Iter    10/   40] train: loss: 0.0062586
[Epoch 108; Iter    40/   40] train: loss: 0.0352811
[Epoch 108] ogbg-molclintox: 0.941898 val loss: 0.122747
[Epoch 108] ogbg-molclintox: 0.747812 test loss: 0.269464
[Epoch 109; Iter    30/   40] train: loss: 0.0788406
[Epoch 109] ogbg-molclintox: 0.898018 val loss: 0.114894
[Epoch 109] ogbg-molclintox: 0.744290 test loss: 0.261506
[Epoch 110; Iter    20/   40] train: loss: 0.0610634
[Epoch 110] ogbg-molclintox: 0.882222 val loss: 0.122153
[Epoch 110] ogbg-molclintox: 0.811734 test loss: 0.256122
[Epoch 111; Iter    10/   40] train: loss: 0.0212433
[Epoch 111; Iter    40/   40] train: loss: 0.0230184
[Epoch 111] ogbg-molclintox: 0.956882 val loss: 0.093144
[Epoch 111] ogbg-molclintox: 0.791485 test loss: 0.270908
[Epoch 112; Iter    30/   40] train: loss: 0.0530958
[Epoch 112] ogbg-molclintox: 0.941448 val loss: 0.099952
[Epoch 112] ogbg-molclintox: 0.790510 test loss: 0.257412
[Epoch 113; Iter    20/   40] train: loss: 0.2574820
[Epoch 113] ogbg-molclintox: 0.955209 val loss: 0.104411
[Epoch 113] ogbg-molclintox: 0.769410 test loss: 0.273811
[Epoch 114; Iter    10/   40] train: loss: 0.0034365
[Epoch 114; Iter    40/   40] train: loss: 0.0026629
[Epoch 114] ogbg-molclintox: 0.925227 val loss: 0.100496
[Epoch 114] ogbg-molclintox: 0.807924 test loss: 0.270813
[Epoch 115; Iter    30/   40] train: loss: 0.0115262
[Epoch 115] ogbg-molclintox: 0.944133 val loss: 0.092078
[Epoch 115] ogbg-molclintox: 0.796169 test loss: 0.282126
[Epoch 116; Iter    20/   40] train: loss: 0.0558471
[Epoch 116] ogbg-molclintox: 0.955933 val loss: 0.085728
[Epoch 116] ogbg-molclintox: 0.784239 test loss: 0.266487
[Epoch 117; Iter    10/   40] train: loss: 0.0994785
[Epoch 117; Iter    40/   40] train: loss: 0.0040721
[Epoch 117] ogbg-molclintox: 0.946256 val loss: 0.092756
[Epoch 117] ogbg-molclintox: 0.813882 test loss: 0.254845
[Epoch 118; Iter    30/   40] train: loss: 0.0423102
[Epoch 118] ogbg-molclintox: 0.932582 val loss: 0.091675
[Epoch 118] ogbg-molclintox: 0.807248 test loss: 0.243379
[Epoch 119; Iter    20/   40] train: loss: 0.0249867
[Epoch 119] ogbg-molclintox: 0.895108 val loss: 0.120206
[Epoch 119] ogbg-molclintox: 0.815331 test loss: 0.253251
[Epoch 120; Iter    10/   40] train: loss: 0.0776350
[Epoch 120; Iter    40/   40] train: loss: 0.0046950
[Epoch 120] ogbg-molclintox: 0.932108 val loss: 0.107819
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 120] ogbg-molclintox: 0.822002 test loss: 0.259192
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 120 epochs. Best model checkpoint was in epoch 48.
Statistics on  val_best_checkpoint
mean_pred: 0.18293479084968567
std_pred: 4.282137870788574
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 1.0
rocauc: 1.0
ogbg-molclintox: 1.0
OGBNanLabelBCEWithLogitsLoss: 0.0730767128057778
Statistics on  test
mean_pred: 0.15773430466651917
std_pred: 4.3739519119262695
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.7452966028884309
rocauc: 0.8692463420567893
ogbg-molclintox: 0.8692463420567893
OGBNanLabelBCEWithLogitsLoss: 0.17745999097824097
Statistics on  train
mean_pred: 0.19540813565254211
std_pred: 4.842502593994141
mean_targets: 0.5067738890647888
std_targets: 0.500059962272644
prcauc: 0.92890319568282
rocauc: 0.9835921117480129
ogbg-molclintox: 0.9835921117480129
OGBNanLabelBCEWithLogitsLoss: 0.09488755678758025
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 80] ogbg-molclintox: 0.949420 val loss: 0.129813
[Epoch 80] ogbg-molclintox: 0.804930 test loss: 0.155016
[Epoch 81; Iter    20/   35] train: loss: 0.0257594
[Epoch 81] ogbg-molclintox: 0.962159 val loss: 0.132569
[Epoch 81] ogbg-molclintox: 0.861331 test loss: 0.184385
[Epoch 82; Iter    15/   35] train: loss: 0.0923475
[Epoch 82] ogbg-molclintox: 0.957180 val loss: 0.140698
[Epoch 82] ogbg-molclintox: 0.867487 test loss: 0.174633
[Epoch 83; Iter    10/   35] train: loss: 0.1467022
[Epoch 83] ogbg-molclintox: 0.964883 val loss: 0.140391
[Epoch 83] ogbg-molclintox: 0.901087 test loss: 0.165450
[Epoch 84; Iter     5/   35] train: loss: 0.0694848
[Epoch 84; Iter    35/   35] train: loss: 0.0239079
[Epoch 84] ogbg-molclintox: 0.956725 val loss: 0.115398
[Epoch 84] ogbg-molclintox: 0.789181 test loss: 0.165549
[Epoch 85; Iter    30/   35] train: loss: 0.1096800
[Epoch 85] ogbg-molclintox: 0.954186 val loss: 0.126721
[Epoch 85] ogbg-molclintox: 0.826801 test loss: 0.166575
[Epoch 86; Iter    25/   35] train: loss: 0.0625431
[Epoch 86] ogbg-molclintox: 0.975731 val loss: 0.116313
[Epoch 86] ogbg-molclintox: 0.866149 test loss: 0.153522
[Epoch 87; Iter    20/   35] train: loss: 0.0307393
[Epoch 87] ogbg-molclintox: 0.965206 val loss: 0.117053
[Epoch 87] ogbg-molclintox: 0.825140 test loss: 0.166588
[Epoch 88; Iter    15/   35] train: loss: 0.0504058
[Epoch 88] ogbg-molclintox: 0.960910 val loss: 0.125423
[Epoch 88] ogbg-molclintox: 0.844052 test loss: 0.178660
[Epoch 89; Iter    10/   35] train: loss: 0.0105378
[Epoch 89] ogbg-molclintox: 0.953929 val loss: 0.143095
[Epoch 89] ogbg-molclintox: 0.885838 test loss: 0.152713
[Epoch 90; Iter     5/   35] train: loss: 0.0660720
[Epoch 90; Iter    35/   35] train: loss: 0.0272594
[Epoch 90] ogbg-molclintox: 0.963817 val loss: 0.113615
[Epoch 90] ogbg-molclintox: 0.847419 test loss: 0.189582
[Epoch 91; Iter    30/   35] train: loss: 0.1764477
[Epoch 91] ogbg-molclintox: 0.974232 val loss: 0.106515
[Epoch 91] ogbg-molclintox: 0.855310 test loss: 0.156317
[Epoch 92; Iter    25/   35] train: loss: 0.1291039
[Epoch 92] ogbg-molclintox: 0.967209 val loss: 0.118140
[Epoch 92] ogbg-molclintox: 0.840849 test loss: 0.175019
[Epoch 93; Iter    20/   35] train: loss: 0.0222869
[Epoch 93] ogbg-molclintox: 0.968646 val loss: 0.108588
[Epoch 93] ogbg-molclintox: 0.858774 test loss: 0.158362
[Epoch 94; Iter    15/   35] train: loss: 0.1396934
[Epoch 94] ogbg-molclintox: 0.967235 val loss: 0.117515
[Epoch 94] ogbg-molclintox: 0.870424 test loss: 0.137731
[Epoch 95; Iter    10/   35] train: loss: 0.0196505
[Epoch 95] ogbg-molclintox: 0.968238 val loss: 0.109533
[Epoch 95] ogbg-molclintox: 0.861263 test loss: 0.160374
[Epoch 96; Iter     5/   35] train: loss: 0.0765037
[Epoch 96; Iter    35/   35] train: loss: 0.0048980
[Epoch 96] ogbg-molclintox: 0.965848 val loss: 0.111201
[Epoch 96] ogbg-molclintox: 0.843213 test loss: 0.160262
[Epoch 97; Iter    30/   35] train: loss: 0.0241616
[Epoch 97] ogbg-molclintox: 0.970677 val loss: 0.118253
[Epoch 97] ogbg-molclintox: 0.858077 test loss: 0.153359
[Epoch 98; Iter    25/   35] train: loss: 0.0295929
[Epoch 98] ogbg-molclintox: 0.972621 val loss: 0.108037
[Epoch 98] ogbg-molclintox: 0.880940 test loss: 0.136492
[Epoch 99; Iter    20/   35] train: loss: 0.1368926
[Epoch 99] ogbg-molclintox: 0.971012 val loss: 0.110019
[Epoch 99] ogbg-molclintox: 0.859692 test loss: 0.168044
[Epoch 100; Iter    15/   35] train: loss: 0.0384503
[Epoch 100] ogbg-molclintox: 0.955944 val loss: 0.134142
[Epoch 100] ogbg-molclintox: 0.852697 test loss: 0.162772
[Epoch 101; Iter    10/   35] train: loss: 0.0091472
[Epoch 101] ogbg-molclintox: 0.964190 val loss: 0.120322
[Epoch 101] ogbg-molclintox: 0.855962 test loss: 0.170538
[Epoch 102; Iter     5/   35] train: loss: 0.0205583
[Epoch 102; Iter    35/   35] train: loss: 0.1058970
[Epoch 102] ogbg-molclintox: 0.969971 val loss: 0.121166
[Epoch 102] ogbg-molclintox: 0.859545 test loss: 0.155887
[Epoch 103; Iter    30/   35] train: loss: 0.0771624
[Epoch 103] ogbg-molclintox: 0.966617 val loss: 0.117961
[Epoch 103] ogbg-molclintox: 0.880101 test loss: 0.152261
[Epoch 104; Iter    25/   35] train: loss: 0.1442990
[Epoch 104] ogbg-molclintox: 0.961340 val loss: 0.130843
[Epoch 104] ogbg-molclintox: 0.841013 test loss: 0.181323
[Epoch 105; Iter    20/   35] train: loss: 0.0569208
[Epoch 105] ogbg-molclintox: 0.966542 val loss: 0.113003
[Epoch 105] ogbg-molclintox: 0.874647 test loss: 0.178536
[Epoch 106; Iter    15/   35] train: loss: 0.0042383
[Epoch 106] ogbg-molclintox: 0.965502 val loss: 0.110426
[Epoch 106] ogbg-molclintox: 0.861433 test loss: 0.153530
[Epoch 107; Iter    10/   35] train: loss: 0.0169651
[Epoch 107] ogbg-molclintox: 0.970776 val loss: 0.102321
[Epoch 107] ogbg-molclintox: 0.867850 test loss: 0.176531
[Epoch 108; Iter     5/   35] train: loss: 0.0963636
[Epoch 108; Iter    35/   35] train: loss: 0.0047191
[Epoch 108] ogbg-molclintox: 0.962644 val loss: 0.117120
[Epoch 108] ogbg-molclintox: 0.868989 test loss: 0.161780
[Epoch 109; Iter    30/   35] train: loss: 0.0929283
[Epoch 109] ogbg-molclintox: 0.958298 val loss: 0.119622
[Epoch 109] ogbg-molclintox: 0.863258 test loss: 0.154821
[Epoch 110; Iter    25/   35] train: loss: 0.0145448
[Epoch 110] ogbg-molclintox: 0.972931 val loss: 0.109117
[Epoch 110] ogbg-molclintox: 0.858105 test loss: 0.158977
[Epoch 111; Iter    20/   35] train: loss: 0.1543647
[Epoch 111] ogbg-molclintox: 0.953680 val loss: 0.109971
[Epoch 111] ogbg-molclintox: 0.854244 test loss: 0.151300
[Epoch 112; Iter    15/   35] train: loss: 0.0929738
[Epoch 112] ogbg-molclintox: 0.964525 val loss: 0.108001
[Epoch 112] ogbg-molclintox: 0.866109 test loss: 0.156596
[Epoch 113; Iter    10/   35] train: loss: 0.0060203
[Epoch 113] ogbg-molclintox: 0.969129 val loss: 0.113695
[Epoch 113] ogbg-molclintox: 0.865866 test loss: 0.162340
[Epoch 114; Iter     5/   35] train: loss: 0.0400559
[Epoch 114; Iter    35/   35] train: loss: 0.2441487
[Epoch 114] ogbg-molclintox: 0.967100 val loss: 0.108186
[Epoch 114] ogbg-molclintox: 0.864840 test loss: 0.145186
[Epoch 115; Iter    30/   35] train: loss: 0.0164370
[Epoch 115] ogbg-molclintox: 0.960203 val loss: 0.120960
[Epoch 115] ogbg-molclintox: 0.879624 test loss: 0.175996
[Epoch 116; Iter    25/   35] train: loss: 0.0242817
[Epoch 116] ogbg-molclintox: 0.955648 val loss: 0.118418
[Epoch 116] ogbg-molclintox: 0.857260 test loss: 0.161866
[Epoch 117; Iter    20/   35] train: loss: 0.0783810
[Epoch 117] ogbg-molclintox: 0.963670 val loss: 0.122334
[Epoch 117] ogbg-molclintox: 0.862051 test loss: 0.159098
[Epoch 118; Iter    15/   35] train: loss: 0.0263046
[Epoch 118] ogbg-molclintox: 0.965576 val loss: 0.119742
[Epoch 118] ogbg-molclintox: 0.878582 test loss: 0.147241
[Epoch 119; Iter    10/   35] train: loss: 0.0094977
[Epoch 119] ogbg-molclintox: 0.963335 val loss: 0.129983
[Epoch 119] ogbg-molclintox: 0.870923 test loss: 0.153341
[Epoch 120; Iter     5/   35] train: loss: 0.0242920
[Epoch 120; Iter    35/   35] train: loss: 0.1851068
[Epoch 120] ogbg-molclintox: 0.960748 val loss: 0.127048
[Epoch 120] ogbg-molclintox: 0.869840 test loss: 0.152580
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 120 epochs. Best model checkpoint was in epoch 56.
Statistics on  val_best_checkpoint
mean_pred: 0.15839356184005737
std_pred: 4.775620937347412
mean_targets: 0.5067567825317383
std_targets: 0.500518262386322
prcauc: 0.9311068273060157
rocauc: 0.9810564080704747
ogbg-molclintox: 0.9810564080704747
OGBNanLabelBCEWithLogitsLoss: 0.09635040408466011
Statistics on  test
mean_pred: 0.20918437838554382
std_pred: 5.8289103507995605
mean_targets: 0.5022522807121277
std_targets: 0.5005589127540588
prcauc: 0.7117009420660843
rocauc: 0.8750609514235107
ogbg-molclintox: 0.8750609514235107
OGBNanLabelBCEWithLogitsLoss: 0.14294111914932728
Statistics on  train
mean_pred: 0.221796452999115
std_pred: 5.325804710388184
mean_targets: 0.5067763924598694
std_targets: 0.500075101852417
prcauc: 0.9163939886563051
rocauc: 0.9806418851876594
ogbg-molclintox: 0.9806418851876594
OGBNanLabelBCEWithLogitsLoss: 0.09933664037712983
[Epoch 76] ogbg-molclintox: 0.984092 val loss: 0.059361
[Epoch 76] ogbg-molclintox: 0.814442 test loss: 0.249873
[Epoch 77; Iter    20/   40] train: loss: 0.0138852
[Epoch 77] ogbg-molclintox: 0.965161 val loss: 0.087848
[Epoch 77] ogbg-molclintox: 0.797589 test loss: 0.215704
[Epoch 78; Iter    10/   40] train: loss: 0.0905093
[Epoch 78; Iter    40/   40] train: loss: 0.0253500
[Epoch 78] ogbg-molclintox: 0.986327 val loss: 0.055537
[Epoch 78] ogbg-molclintox: 0.768823 test loss: 0.263303
[Epoch 79; Iter    30/   40] train: loss: 0.0246280
[Epoch 79] ogbg-molclintox: 0.987251 val loss: 0.055801
[Epoch 79] ogbg-molclintox: 0.837340 test loss: 0.239500
[Epoch 80; Iter    20/   40] train: loss: 0.0411764
[Epoch 80] ogbg-molclintox: 0.961415 val loss: 0.089251
[Epoch 80] ogbg-molclintox: 0.811742 test loss: 0.211325
[Epoch 81; Iter    10/   40] train: loss: 0.0558172
[Epoch 81; Iter    40/   40] train: loss: 0.0160279
[Epoch 81] ogbg-molclintox: 0.983505 val loss: 0.061122
[Epoch 81] ogbg-molclintox: 0.803498 test loss: 0.207512
[Epoch 82; Iter    30/   40] train: loss: 0.0485769
[Epoch 82] ogbg-molclintox: 0.984292 val loss: 0.082334
[Epoch 82] ogbg-molclintox: 0.823049 test loss: 0.234239
[Epoch 83; Iter    20/   40] train: loss: 0.0281424
[Epoch 83] ogbg-molclintox: 0.992396 val loss: 0.047356
[Epoch 83] ogbg-molclintox: 0.826436 test loss: 1.299254
[Epoch 84; Iter    10/   40] train: loss: 0.0367499
[Epoch 84; Iter    40/   40] train: loss: 0.3329104
[Epoch 84] ogbg-molclintox: 0.991197 val loss: 0.059853
[Epoch 84] ogbg-molclintox: 0.815014 test loss: 0.221243
[Epoch 85; Iter    30/   40] train: loss: 0.0098026
[Epoch 85] ogbg-molclintox: 0.984067 val loss: 0.078080
[Epoch 85] ogbg-molclintox: 0.805485 test loss: 0.576500
[Epoch 86; Iter    20/   40] train: loss: 0.0424321
[Epoch 86] ogbg-molclintox: 0.982219 val loss: 0.063494
[Epoch 86] ogbg-molclintox: 0.822074 test loss: 0.233688
[Epoch 87; Iter    10/   40] train: loss: 0.0571198
[Epoch 87; Iter    40/   40] train: loss: 0.0469389
[Epoch 87] ogbg-molclintox: 0.952637 val loss: 0.097030
[Epoch 87] ogbg-molclintox: 0.805620 test loss: 0.240672
[Epoch 88; Iter    30/   40] train: loss: 0.0214151
[Epoch 88] ogbg-molclintox: 0.942710 val loss: 0.074920
[Epoch 88] ogbg-molclintox: 0.820837 test loss: 0.265465
[Epoch 89; Iter    20/   40] train: loss: 0.0580124
[Epoch 89] ogbg-molclintox: 0.972291 val loss: 0.068593
[Epoch 89] ogbg-molclintox: 0.815216 test loss: 0.265904
[Epoch 90; Iter    10/   40] train: loss: 0.0687742
[Epoch 90; Iter    40/   40] train: loss: 0.2527331
[Epoch 90] ogbg-molclintox: 0.961503 val loss: 0.081781
[Epoch 90] ogbg-molclintox: 0.794328 test loss: 0.212907
[Epoch 91; Iter    30/   40] train: loss: 0.0658782
[Epoch 91] ogbg-molclintox: 0.963176 val loss: 0.073732
[Epoch 91] ogbg-molclintox: 0.777489 test loss: 0.223820
[Epoch 92; Iter    20/   40] train: loss: 0.0463087
[Epoch 92] ogbg-molclintox: 0.968770 val loss: 0.079284
[Epoch 92] ogbg-molclintox: 0.804671 test loss: 0.214753
[Epoch 93; Iter    10/   40] train: loss: 0.0197342
[Epoch 93; Iter    40/   40] train: loss: 0.0189065
[Epoch 93] ogbg-molclintox: 0.957694 val loss: 0.070832
[Epoch 93] ogbg-molclintox: 0.810644 test loss: 0.248149
[Epoch 94; Iter    30/   40] train: loss: 0.0285151
[Epoch 94] ogbg-molclintox: 0.958281 val loss: 0.078357
[Epoch 94] ogbg-molclintox: 0.821312 test loss: 0.240966
[Epoch 95; Iter    20/   40] train: loss: 0.0227829
[Epoch 95] ogbg-molclintox: 0.967034 val loss: 0.074732
[Epoch 95] ogbg-molclintox: 0.827008 test loss: 0.212702
[Epoch 96; Iter    10/   40] train: loss: 0.0259368
[Epoch 96; Iter    40/   40] train: loss: 0.0263231
[Epoch 96] ogbg-molclintox: 0.961415 val loss: 0.074868
[Epoch 96] ogbg-molclintox: 0.848546 test loss: 0.229214
[Epoch 97; Iter    30/   40] train: loss: 0.0212325
[Epoch 97] ogbg-molclintox: 0.968208 val loss: 0.075307
[Epoch 97] ogbg-molclintox: 0.807446 test loss: 0.221065
[Epoch 98; Iter    20/   40] train: loss: 0.0207501
[Epoch 98] ogbg-molclintox: 0.963763 val loss: 0.074787
[Epoch 98] ogbg-molclintox: 0.805773 test loss: 0.234499
[Epoch 99; Iter    10/   40] train: loss: 0.0806550
[Epoch 99; Iter    40/   40] train: loss: 0.0083069
[Epoch 99] ogbg-molclintox: 0.971954 val loss: 0.072332
[Epoch 99] ogbg-molclintox: 0.816303 test loss: 0.231961
[Epoch 100; Iter    30/   40] train: loss: 0.0084483
[Epoch 100] ogbg-molclintox: 0.973465 val loss: 0.074206
[Epoch 100] ogbg-molclintox: 0.820512 test loss: 0.211605
[Epoch 101; Iter    20/   40] train: loss: 0.0440671
[Epoch 101] ogbg-molclintox: 0.963151 val loss: 0.093682
[Epoch 101] ogbg-molclintox: 0.795015 test loss: 0.229003
[Epoch 102; Iter    10/   40] train: loss: 0.0958575
[Epoch 102; Iter    40/   40] train: loss: 0.1103909
[Epoch 102] ogbg-molclintox: 0.961166 val loss: 0.085624
[Epoch 102] ogbg-molclintox: 0.801836 test loss: 0.235927
[Epoch 103; Iter    30/   40] train: loss: 0.0962715
[Epoch 103] ogbg-molclintox: 0.965836 val loss: 0.080657
[Epoch 103] ogbg-molclintox: 0.796252 test loss: 0.237295
[Epoch 104; Iter    20/   40] train: loss: 0.0324187
[Epoch 104] ogbg-molclintox: 0.974751 val loss: 0.074705
[Epoch 104] ogbg-molclintox: 0.814554 test loss: 0.233972
[Epoch 105; Iter    10/   40] train: loss: 0.0253811
[Epoch 105; Iter    40/   40] train: loss: 0.0117484
[Epoch 105] ogbg-molclintox: 0.971118 val loss: 0.078656
[Epoch 105] ogbg-molclintox: 0.812967 test loss: 0.246608
[Epoch 106; Iter    30/   40] train: loss: 0.0967817
[Epoch 106] ogbg-molclintox: 0.975813 val loss: 0.066309
[Epoch 106] ogbg-molclintox: 0.829032 test loss: 0.245242
[Epoch 107; Iter    20/   40] train: loss: 0.0960646
[Epoch 107] ogbg-molclintox: 0.956383 val loss: 0.106287
[Epoch 107] ogbg-molclintox: 0.768308 test loss: 0.239524
[Epoch 108; Iter    10/   40] train: loss: 0.0075437
[Epoch 108; Iter    40/   40] train: loss: 0.0331048
[Epoch 108] ogbg-molclintox: 0.974976 val loss: 0.079199
[Epoch 108] ogbg-molclintox: 0.817214 test loss: 0.226836
[Epoch 109; Iter    30/   40] train: loss: 0.0679747
[Epoch 109] ogbg-molclintox: 0.961890 val loss: 0.084554
[Epoch 109] ogbg-molclintox: 0.832517 test loss: 0.238675
[Epoch 110; Iter    20/   40] train: loss: 0.0862597
[Epoch 110] ogbg-molclintox: 0.958843 val loss: 0.100806
[Epoch 110] ogbg-molclintox: 0.774180 test loss: 0.260002
[Epoch 111; Iter    10/   40] train: loss: 0.0679746
[Epoch 111; Iter    40/   40] train: loss: 0.1385207
[Epoch 111] ogbg-molclintox: 0.960716 val loss: 0.084187
[Epoch 111] ogbg-molclintox: 0.804522 test loss: 0.224621
[Epoch 112; Iter    30/   40] train: loss: 0.2692289
[Epoch 112] ogbg-molclintox: 0.969357 val loss: 0.086776
[Epoch 112] ogbg-molclintox: 0.818450 test loss: 0.235261
[Epoch 113; Iter    20/   40] train: loss: 0.0182391
[Epoch 113] ogbg-molclintox: 0.979896 val loss: 0.071045
[Epoch 113] ogbg-molclintox: 0.803935 test loss: 0.247380
[Epoch 114; Iter    10/   40] train: loss: 0.0856504
[Epoch 114; Iter    40/   40] train: loss: 0.0078403
[Epoch 114] ogbg-molclintox: 0.962115 val loss: 0.084698
[Epoch 114] ogbg-molclintox: 0.820912 test loss: 0.250469
[Epoch 115; Iter    30/   40] train: loss: 0.0210759
[Epoch 115] ogbg-molclintox: 0.965386 val loss: 0.102644
[Epoch 115] ogbg-molclintox: 0.799001 test loss: 0.242431
[Epoch 116; Iter    20/   40] train: loss: 0.0156544
[Epoch 116] ogbg-molclintox: 0.969494 val loss: 0.080824
[Epoch 116] ogbg-molclintox: 0.782674 test loss: 0.787126
[Epoch 117; Iter    10/   40] train: loss: 0.0518676
[Epoch 117; Iter    40/   40] train: loss: 0.0034500
[Epoch 117] ogbg-molclintox: 0.968883 val loss: 0.081177
[Epoch 117] ogbg-molclintox: 0.797327 test loss: 1.083747
[Epoch 118; Iter    30/   40] train: loss: 0.1496315
[Epoch 118] ogbg-molclintox: 0.978135 val loss: 0.067725
[Epoch 118] ogbg-molclintox: 0.793405 test loss: 2.873065
[Epoch 119; Iter    20/   40] train: loss: 0.0269173
[Epoch 119] ogbg-molclintox: 0.969944 val loss: 0.079039
[Epoch 119] ogbg-molclintox: 0.779839 test loss: 1.597396
[Epoch 120; Iter    10/   40] train: loss: 0.0388280
[Epoch 120; Iter    40/   40] train: loss: 0.0091178
[Epoch 120] ogbg-molclintox: 0.952050 val loss: 0.086120
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 80] ogbg-molclintox: 0.965303 val loss: 0.123589
[Epoch 80] ogbg-molclintox: 0.882090 test loss: 0.777880
[Epoch 81; Iter    20/   35] train: loss: 0.0874500
[Epoch 81] ogbg-molclintox: 0.965736 val loss: 0.139257
[Epoch 81] ogbg-molclintox: 0.892221 test loss: 0.422302
[Epoch 82; Iter    15/   35] train: loss: 0.0868381
[Epoch 82] ogbg-molclintox: 0.967173 val loss: 0.119748
[Epoch 82] ogbg-molclintox: 0.874574 test loss: 0.554379
[Epoch 83; Iter    10/   35] train: loss: 0.0135427
[Epoch 83] ogbg-molclintox: 0.963470 val loss: 0.127445
[Epoch 83] ogbg-molclintox: 0.915747 test loss: 0.446601
[Epoch 84; Iter     5/   35] train: loss: 0.0420478
[Epoch 84; Iter    35/   35] train: loss: 0.0277907
[Epoch 84] ogbg-molclintox: 0.973116 val loss: 0.108852
[Epoch 84] ogbg-molclintox: 0.886971 test loss: 0.211939
[Epoch 85; Iter    30/   35] train: loss: 0.1206611
[Epoch 85] ogbg-molclintox: 0.961786 val loss: 0.123438
[Epoch 85] ogbg-molclintox: 0.886218 test loss: 0.305131
[Epoch 86; Iter    25/   35] train: loss: 0.1675816
[Epoch 86] ogbg-molclintox: 0.970652 val loss: 0.104608
[Epoch 86] ogbg-molclintox: 0.875843 test loss: 0.203699
[Epoch 87; Iter    20/   35] train: loss: 0.1107792
[Epoch 87] ogbg-molclintox: 0.958394 val loss: 0.139140
[Epoch 87] ogbg-molclintox: 0.899829 test loss: 0.154523
[Epoch 88; Iter    15/   35] train: loss: 0.0194067
[Epoch 88] ogbg-molclintox: 0.967917 val loss: 0.113874
[Epoch 88] ogbg-molclintox: 0.911150 test loss: 0.141336
[Epoch 89; Iter    10/   35] train: loss: 0.0174178
[Epoch 89] ogbg-molclintox: 0.959966 val loss: 0.123487
[Epoch 89] ogbg-molclintox: 0.903559 test loss: 0.121585
[Epoch 90; Iter     5/   35] train: loss: 0.0971417
[Epoch 90; Iter    35/   35] train: loss: 0.0060988
[Epoch 90] ogbg-molclintox: 0.965328 val loss: 0.128082
[Epoch 90] ogbg-molclintox: 0.901717 test loss: 0.134513
[Epoch 91; Iter    30/   35] train: loss: 0.0137969
[Epoch 91] ogbg-molclintox: 0.958900 val loss: 0.106215
[Epoch 91] ogbg-molclintox: 0.885872 test loss: 0.144287
[Epoch 92; Iter    25/   35] train: loss: 0.1133935
[Epoch 92] ogbg-molclintox: 0.958356 val loss: 0.118054
[Epoch 92] ogbg-molclintox: 0.887085 test loss: 0.151309
[Epoch 93; Iter    20/   35] train: loss: 0.0642959
[Epoch 93] ogbg-molclintox: 0.962579 val loss: 0.118606
[Epoch 93] ogbg-molclintox: 0.875231 test loss: 0.157056
[Epoch 94; Iter    15/   35] train: loss: 0.0828606
[Epoch 94] ogbg-molclintox: 0.957526 val loss: 0.127418
[Epoch 94] ogbg-molclintox: 0.832549 test loss: 0.165965
[Epoch 95; Iter    10/   35] train: loss: 0.1128352
[Epoch 95] ogbg-molclintox: 0.963631 val loss: 0.138440
[Epoch 95] ogbg-molclintox: 0.900112 test loss: 0.151566
[Epoch 96; Iter     5/   35] train: loss: 0.0453460
[Epoch 96; Iter    35/   35] train: loss: 0.4881585
[Epoch 96] ogbg-molclintox: 0.955508 val loss: 0.126273
[Epoch 96] ogbg-molclintox: 0.872380 test loss: 0.162810
[Epoch 97; Iter    30/   35] train: loss: 0.0903004
[Epoch 97] ogbg-molclintox: 0.963184 val loss: 0.114205
[Epoch 97] ogbg-molclintox: 0.858921 test loss: 0.187503
[Epoch 98; Iter    25/   35] train: loss: 0.0619375
[Epoch 98] ogbg-molclintox: 0.942940 val loss: 0.124886
[Epoch 98] ogbg-molclintox: 0.840803 test loss: 0.170041
[Epoch 99; Iter    20/   35] train: loss: 0.0801926
[Epoch 99] ogbg-molclintox: 0.959347 val loss: 0.110499
[Epoch 99] ogbg-molclintox: 0.863275 test loss: 0.190074
[Epoch 100; Iter    15/   35] train: loss: 0.0255062
[Epoch 100] ogbg-molclintox: 0.962022 val loss: 0.114948
[Epoch 100] ogbg-molclintox: 0.878740 test loss: 0.154406
[Epoch 101; Iter    10/   35] train: loss: 0.0275841
[Epoch 101] ogbg-molclintox: 0.969748 val loss: 0.100972
[Epoch 101] ogbg-molclintox: 0.873383 test loss: 0.166687
[Epoch 102; Iter     5/   35] train: loss: 0.0303428
[Epoch 102; Iter    35/   35] train: loss: 0.0680097
[Epoch 102] ogbg-molclintox: 0.963173 val loss: 0.119340
[Epoch 102] ogbg-molclintox: 0.872754 test loss: 0.174252
[Epoch 103; Iter    30/   35] train: loss: 0.1124811
[Epoch 103] ogbg-molclintox: 0.963012 val loss: 0.124359
[Epoch 103] ogbg-molclintox: 0.879001 test loss: 0.164019
[Epoch 104; Iter    25/   35] train: loss: 0.0433198
[Epoch 104] ogbg-molclintox: 0.953056 val loss: 0.136274
[Epoch 104] ogbg-molclintox: 0.862300 test loss: 0.188397
[Epoch 105; Iter    20/   35] train: loss: 0.1423017
[Epoch 105] ogbg-molclintox: 0.956362 val loss: 0.125138
[Epoch 105] ogbg-molclintox: 0.903633 test loss: 0.139668
[Epoch 106; Iter    15/   35] train: loss: 0.0053919
[Epoch 106] ogbg-molclintox: 0.959098 val loss: 0.141046
[Epoch 106] ogbg-molclintox: 0.892708 test loss: 0.181321
[Epoch 107; Iter    10/   35] train: loss: 0.1394925
[Epoch 107] ogbg-molclintox: 0.967891 val loss: 0.105770
[Epoch 107] ogbg-molclintox: 0.864420 test loss: 0.162028
[Epoch 108; Iter     5/   35] train: loss: 0.0326142
[Epoch 108; Iter    35/   35] train: loss: 0.0060609
[Epoch 108] ogbg-molclintox: 0.968535 val loss: 0.110572
[Epoch 108] ogbg-molclintox: 0.894727 test loss: 0.165414
[Epoch 109; Iter    30/   35] train: loss: 0.0479133
[Epoch 109] ogbg-molclintox: 0.939275 val loss: 0.156218
[Epoch 109] ogbg-molclintox: 0.858661 test loss: 0.166925
[Epoch 110; Iter    25/   35] train: loss: 0.0072161
[Epoch 110] ogbg-molclintox: 0.946257 val loss: 0.131069
[Epoch 110] ogbg-molclintox: 0.867357 test loss: 0.186500
[Epoch 111; Iter    20/   35] train: loss: 0.0786167
[Epoch 111] ogbg-molclintox: 0.950529 val loss: 0.148291
[Epoch 111] ogbg-molclintox: 0.896921 test loss: 0.161681
[Epoch 112; Iter    15/   35] train: loss: 0.0408670
[Epoch 112] ogbg-molclintox: 0.963669 val loss: 0.118210
[Epoch 112] ogbg-molclintox: 0.889970 test loss: 0.157935
[Epoch 113; Iter    10/   35] train: loss: 0.0393934
[Epoch 113] ogbg-molclintox: 0.958890 val loss: 0.126581
[Epoch 113] ogbg-molclintox: 0.888060 test loss: 0.144811
[Epoch 114; Iter     5/   35] train: loss: 0.0452802
[Epoch 114; Iter    35/   35] train: loss: 0.0644298
[Epoch 114] ogbg-molclintox: 0.961329 val loss: 0.130240
[Epoch 114] ogbg-molclintox: 0.890362 test loss: 0.152666
[Epoch 115; Iter    30/   35] train: loss: 0.0696506
[Epoch 115] ogbg-molclintox: 0.958629 val loss: 0.131020
[Epoch 115] ogbg-molclintox: 0.882998 test loss: 0.157224
[Epoch 116; Iter    25/   35] train: loss: 0.0627648
[Epoch 116] ogbg-molclintox: 0.960388 val loss: 0.130540
[Epoch 116] ogbg-molclintox: 0.893173 test loss: 0.150752
[Epoch 117; Iter    20/   35] train: loss: 0.1375563
[Epoch 117] ogbg-molclintox: 0.961391 val loss: 0.132082
[Epoch 117] ogbg-molclintox: 0.888956 test loss: 0.155774
[Epoch 118; Iter    15/   35] train: loss: 0.1115954
[Epoch 118] ogbg-molclintox: 0.956735 val loss: 0.148916
[Epoch 118] ogbg-molclintox: 0.890923 test loss: 0.172437
[Epoch 119; Iter    10/   35] train: loss: 0.1423308
[Epoch 119] ogbg-molclintox: 0.957465 val loss: 0.134087
[Epoch 119] ogbg-molclintox: 0.884330 test loss: 0.175747
[Epoch 120; Iter     5/   35] train: loss: 0.0951574
[Epoch 120; Iter    35/   35] train: loss: 0.1249233
[Epoch 120] ogbg-molclintox: 0.953924 val loss: 0.143699
[Epoch 120] ogbg-molclintox: 0.887663 test loss: 0.170397
[Epoch 121; Iter    30/   35] train: loss: 0.0342849
[Epoch 121] ogbg-molclintox: 0.955299 val loss: 0.147085
[Epoch 121] ogbg-molclintox: 0.893026 test loss: 0.173675
[Epoch 122; Iter    25/   35] train: loss: 0.0731903
[Epoch 122] ogbg-molclintox: 0.934260 val loss: 0.166603
[Epoch 122] ogbg-molclintox: 0.857958 test loss: 0.177622
[Epoch 123; Iter    20/   35] train: loss: 0.0671412
[Epoch 123] ogbg-molclintox: 0.953999 val loss: 0.134046
[Epoch 123] ogbg-molclintox: 0.890294 test loss: 0.167149
[Epoch 124; Iter    15/   35] train: loss: 0.0121652
[Epoch 124] ogbg-molclintox: 0.951164 val loss: 0.135881
[Epoch 124] ogbg-molclintox: 0.883275 test loss: 0.160331
[Epoch 125; Iter    10/   35] train: loss: 0.0499701
[Epoch 125] ogbg-molclintox: 0.961243 val loss: 0.124784
[Epoch 125] ogbg-molclintox: 0.896002 test loss: 0.158070
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 125 epochs. Best model checkpoint was in epoch 65.
Statistics on  val_best_checkpoint
mean_pred: 0.15080426633358002
std_pred: 6.187067031860352
mean_targets: 0.5067567825317383
std_targets: 0.500518262386322
prcauc: 0.9268264446325771
rocauc: 0.9774261153736857
ogbg-molclintox: 0.9774261153736857
OGBNanLabelBCEWithLogitsLoss: 0.09595575142884627
Statistics on  test
mean_pred: 0.17871622741222382
std_pred: 5.51044225692749
mean_targets: 0.5022522807121277
std_targets: 0.5005589127540588
prcauc: 0.7227761428042119
rocauc: 0.9145228520820938
ogbg-molclintox: 0.9145228520820938
OGBNanLabelBCEWithLogitsLoss: 0.19820668874308467
Statistics on  train
mean_pred: 0.22034816443920135
std_pred: 6.823380470275879
mean_targets: 0.5067763924598694
std_targets: 0.500075101852417
prcauc: 0.9261004991930011
rocauc: 0.9852364659586532
ogbg-molclintox: 0.9852364659586532
OGBNanLabelBCEWithLogitsLoss: 0.08310293283845697
[Epoch 80] ogbg-molclintox: 0.958529 val loss: 0.140245
[Epoch 80] ogbg-molclintox: 0.848694 test loss: 0.650115
[Epoch 81; Iter    20/   35] train: loss: 0.2944558
[Epoch 81] ogbg-molclintox: 0.928511 val loss: 0.170411
[Epoch 81] ogbg-molclintox: 0.846381 test loss: 0.174024
[Epoch 82; Iter    15/   35] train: loss: 0.0738870
[Epoch 82] ogbg-molclintox: 0.962987 val loss: 0.166798
[Epoch 82] ogbg-molclintox: 0.903434 test loss: 0.175108
[Epoch 83; Iter    10/   35] train: loss: 0.0943172
[Epoch 83] ogbg-molclintox: 0.956499 val loss: 0.146841
[Epoch 83] ogbg-molclintox: 0.853995 test loss: 0.175525
[Epoch 84; Iter     5/   35] train: loss: 0.0768650
[Epoch 84; Iter    35/   35] train: loss: 0.0485624
[Epoch 84] ogbg-molclintox: 0.917268 val loss: 0.191086
[Epoch 84] ogbg-molclintox: 0.865554 test loss: 0.206199
[Epoch 85; Iter    30/   35] train: loss: 0.1150112
[Epoch 85] ogbg-molclintox: 0.913443 val loss: 0.172327
[Epoch 85] ogbg-molclintox: 0.841166 test loss: 0.176276
[Epoch 86; Iter    25/   35] train: loss: 0.0295507
[Epoch 86] ogbg-molclintox: 0.950641 val loss: 0.144108
[Epoch 86] ogbg-molclintox: 0.894608 test loss: 0.151653
[Epoch 87; Iter    20/   35] train: loss: 0.0393326
[Epoch 87] ogbg-molclintox: 0.950071 val loss: 0.164897
[Epoch 87] ogbg-molclintox: 0.907091 test loss: 0.172930
[Epoch 88; Iter    15/   35] train: loss: 0.0131229
[Epoch 88] ogbg-molclintox: 0.961179 val loss: 0.140386
[Epoch 88] ogbg-molclintox: 0.885333 test loss: 0.179532
[Epoch 89; Iter    10/   35] train: loss: 0.1092803
[Epoch 89] ogbg-molclintox: 0.949281 val loss: 0.143526
[Epoch 89] ogbg-molclintox: 0.901609 test loss: 0.152725
[Epoch 90; Iter     5/   35] train: loss: 0.0399931
[Epoch 90; Iter    35/   35] train: loss: 0.0336808
[Epoch 90] ogbg-molclintox: 0.949749 val loss: 0.149976
[Epoch 90] ogbg-molclintox: 0.885430 test loss: 0.184431
[Epoch 91; Iter    30/   35] train: loss: 0.0796120
[Epoch 91] ogbg-molclintox: 0.959680 val loss: 0.146629
[Epoch 91] ogbg-molclintox: 0.906019 test loss: 0.164605
[Epoch 92; Iter    25/   35] train: loss: 0.0058931
[Epoch 92] ogbg-molclintox: 0.953637 val loss: 0.147114
[Epoch 92] ogbg-molclintox: 0.902567 test loss: 0.170268
[Epoch 93; Iter    20/   35] train: loss: 0.0302417
[Epoch 93] ogbg-molclintox: 0.960224 val loss: 0.155625
[Epoch 93] ogbg-molclintox: 0.912737 test loss: 0.168078
[Epoch 94; Iter    15/   35] train: loss: 0.1308365
[Epoch 94] ogbg-molclintox: 0.958577 val loss: 0.136813
[Epoch 94] ogbg-molclintox: 0.918729 test loss: 0.148296
[Epoch 95; Iter    10/   35] train: loss: 0.1183731
[Epoch 95] ogbg-molclintox: 0.934307 val loss: 0.179696
[Epoch 95] ogbg-molclintox: 0.879936 test loss: 0.204533
[Epoch 96; Iter     5/   35] train: loss: 0.0609976
[Epoch 96; Iter    35/   35] train: loss: 0.1037079
[Epoch 96] ogbg-molclintox: 0.955656 val loss: 0.140122
[Epoch 96] ogbg-molclintox: 0.926728 test loss: 0.142951
[Epoch 97; Iter    30/   35] train: loss: 0.0618522
[Epoch 97] ogbg-molclintox: 0.949601 val loss: 0.155899
[Epoch 97] ogbg-molclintox: 0.920113 test loss: 0.159416
[Epoch 98; Iter    25/   35] train: loss: 0.2310023
[Epoch 98] ogbg-molclintox: 0.949749 val loss: 0.162945
[Epoch 98] ogbg-molclintox: 0.922924 test loss: 0.156201
[Epoch 99; Iter    20/   35] train: loss: 0.0649963
[Epoch 99] ogbg-molclintox: 0.950937 val loss: 0.173429
[Epoch 99] ogbg-molclintox: 0.928083 test loss: 0.170118
[Epoch 100; Iter    15/   35] train: loss: 0.0084479
[Epoch 100] ogbg-molclintox: 0.952636 val loss: 0.140298
[Epoch 100] ogbg-molclintox: 0.920555 test loss: 0.144849
[Epoch 101; Iter    10/   35] train: loss: 0.0083052
[Epoch 101] ogbg-molclintox: 0.953835 val loss: 0.173904
[Epoch 101] ogbg-molclintox: 0.898003 test loss: 0.184649
[Epoch 102; Iter     5/   35] train: loss: 0.0122724
[Epoch 102; Iter    35/   35] train: loss: 0.0763636
[Epoch 102] ogbg-molclintox: 0.962627 val loss: 0.129747
[Epoch 102] ogbg-molclintox: 0.917459 test loss: 0.148559
[Epoch 103; Iter    30/   35] train: loss: 0.0739051
[Epoch 103] ogbg-molclintox: 0.948200 val loss: 0.139822
[Epoch 103] ogbg-molclintox: 0.894511 test loss: 0.153970
[Epoch 104; Iter    25/   35] train: loss: 0.0049000
[Epoch 104] ogbg-molclintox: 0.956646 val loss: 0.138288
[Epoch 104] ogbg-molclintox: 0.908973 test loss: 0.143696
[Epoch 105; Iter    20/   35] train: loss: 0.0620589
[Epoch 105] ogbg-molclintox: 0.949537 val loss: 0.158870
[Epoch 105] ogbg-molclintox: 0.892918 test loss: 0.164575
[Epoch 106; Iter    15/   35] train: loss: 0.1288880
[Epoch 106] ogbg-molclintox: 0.951630 val loss: 0.139517
[Epoch 106] ogbg-molclintox: 0.885583 test loss: 0.163633
[Epoch 107; Iter    10/   35] train: loss: 0.0342510
[Epoch 107] ogbg-molclintox: 0.957230 val loss: 0.147627
[Epoch 107] ogbg-molclintox: 0.915742 test loss: 0.133615
[Epoch 108; Iter     5/   35] train: loss: 0.0146427
[Epoch 108; Iter    35/   35] train: loss: 0.2217306
[Epoch 108] ogbg-molclintox: 0.948362 val loss: 0.149687
[Epoch 108] ogbg-molclintox: 0.881240 test loss: 0.179036
[Epoch 109; Iter    30/   35] train: loss: 0.0760773
[Epoch 109] ogbg-molclintox: 0.951818 val loss: 0.143357
[Epoch 109] ogbg-molclintox: 0.908202 test loss: 0.143910
[Epoch 110; Iter    25/   35] train: loss: 0.0075353
[Epoch 110] ogbg-molclintox: 0.948709 val loss: 0.150456
[Epoch 110] ogbg-molclintox: 0.922017 test loss: 0.145494
[Epoch 111; Iter    20/   35] train: loss: 0.0445416
[Epoch 111] ogbg-molclintox: 0.951992 val loss: 0.151847
[Epoch 111] ogbg-molclintox: 0.912975 test loss: 0.164440
[Epoch 112; Iter    15/   35] train: loss: 0.0477050
[Epoch 112] ogbg-molclintox: 0.954390 val loss: 0.145197
[Epoch 112] ogbg-molclintox: 0.912981 test loss: 0.141481
[Epoch 113; Iter    10/   35] train: loss: 0.0305435
[Epoch 113] ogbg-molclintox: 0.957563 val loss: 0.136126
[Epoch 113] ogbg-molclintox: 0.916377 test loss: 0.140016
[Epoch 114; Iter     5/   35] train: loss: 0.0064681
[Epoch 114; Iter    35/   35] train: loss: 0.0672611
[Epoch 114] ogbg-molclintox: 0.951471 val loss: 0.152880
[Epoch 114] ogbg-molclintox: 0.905339 test loss: 0.159965
[Epoch 115; Iter    30/   35] train: loss: 0.0081743
[Epoch 115] ogbg-molclintox: 0.952336 val loss: 0.150930
[Epoch 115] ogbg-molclintox: 0.914551 test loss: 0.148777
[Epoch 116; Iter    25/   35] train: loss: 0.0410042
[Epoch 116] ogbg-molclintox: 0.951730 val loss: 0.141152
[Epoch 116] ogbg-molclintox: 0.908548 test loss: 0.148568
[Epoch 117; Iter    20/   35] train: loss: 0.0196783
[Epoch 117] ogbg-molclintox: 0.950442 val loss: 0.147688
[Epoch 117] ogbg-molclintox: 0.906904 test loss: 0.166643
[Epoch 118; Iter    15/   35] train: loss: 0.0790554
[Epoch 118] ogbg-molclintox: 0.949959 val loss: 0.143017
[Epoch 118] ogbg-molclintox: 0.905067 test loss: 0.165942
[Epoch 119; Iter    10/   35] train: loss: 0.0951714
[Epoch 119] ogbg-molclintox: 0.948857 val loss: 0.152386
[Epoch 119] ogbg-molclintox: 0.904075 test loss: 0.175028
[Epoch 120; Iter     5/   35] train: loss: 0.0164037
[Epoch 120; Iter    35/   35] train: loss: 0.0068774
[Epoch 120] ogbg-molclintox: 0.957464 val loss: 0.147948
[Epoch 120] ogbg-molclintox: 0.910424 test loss: 0.167106
[Epoch 121; Iter    30/   35] train: loss: 0.0057440
[Epoch 121] ogbg-molclintox: 0.957452 val loss: 0.137983
[Epoch 121] ogbg-molclintox: 0.922352 test loss: 0.133129
[Epoch 122; Iter    25/   35] train: loss: 0.0471969
[Epoch 122] ogbg-molclintox: 0.953390 val loss: 0.145584
[Epoch 122] ogbg-molclintox: 0.912386 test loss: 0.136995
[Epoch 123; Iter    20/   35] train: loss: 0.0576274
[Epoch 123] ogbg-molclintox: 0.949166 val loss: 0.149765
[Epoch 123] ogbg-molclintox: 0.906830 test loss: 0.145939
[Epoch 124; Iter    15/   35] train: loss: 0.0242383
[Epoch 124] ogbg-molclintox: 0.961909 val loss: 0.129232
[Epoch 124] ogbg-molclintox: 0.922017 test loss: 0.134985
[Epoch 125; Iter    10/   35] train: loss: 0.0576336
[Epoch 125] ogbg-molclintox: 0.947680 val loss: 0.151386
[Epoch 125] ogbg-molclintox: 0.897748 test loss: 0.138971
[Epoch 126; Iter     5/   35] train: loss: 0.0088861
[Epoch 126; Iter    35/   35] train: loss: 0.0439730
[Epoch 126] ogbg-molclintox: 0.949909 val loss: 0.155115
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 126] ogbg-molclintox: 0.908899 test loss: 0.139710
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 126 epochs. Best model checkpoint was in epoch 66.
Statistics on  val_best_checkpoint
mean_pred: 0.20060232281684875
std_pred: 5.570401668548584
mean_targets: 0.5067567825317383
std_targets: 0.500518262386322
prcauc: 0.9450814419692022
rocauc: 0.9816957942597329
ogbg-molclintox: 0.9816957942597329
OGBNanLabelBCEWithLogitsLoss: 0.12837890174705535
Statistics on  test
mean_pred: 0.23943838477134705
std_pred: 5.111087799072266
mean_targets: 0.5022522807121277
std_targets: 0.5005589127540588
prcauc: 0.7048547275352126
rocauc: 0.8846868310730871
ogbg-molclintox: 0.8846868310730871
OGBNanLabelBCEWithLogitsLoss: 0.18013412784785032
Statistics on  train
mean_pred: 0.2799988090991974
std_pred: 5.975767612457275
mean_targets: 0.5067763924598694
std_targets: 0.500075101852417
prcauc: 0.930288154574586
rocauc: 0.9875237189286901
ogbg-molclintox: 0.9875237189286901
OGBNanLabelBCEWithLogitsLoss: 0.08681902278746878
[Epoch 76] ogbg-molclintox: 0.987276 val loss: 0.052430
[Epoch 76] ogbg-molclintox: 0.836951 test loss: 0.205426
[Epoch 77; Iter    20/   40] train: loss: 0.0140063
[Epoch 77] ogbg-molclintox: 0.981207 val loss: 0.056472
[Epoch 77] ogbg-molclintox: 0.841762 test loss: 0.193828
[Epoch 78; Iter    10/   40] train: loss: 0.0656557
[Epoch 78; Iter    40/   40] train: loss: 0.2616974
[Epoch 78] ogbg-molclintox: 0.989373 val loss: 0.048586
[Epoch 78] ogbg-molclintox: 0.831244 test loss: 0.193857
[Epoch 79; Iter    30/   40] train: loss: 0.1405250
[Epoch 79] ogbg-molclintox: 0.984317 val loss: 0.058857
[Epoch 79] ogbg-molclintox: 0.797077 test loss: 0.212887
[Epoch 80; Iter    20/   40] train: loss: 0.0264617
[Epoch 80] ogbg-molclintox: 0.932009 val loss: 0.093928
[Epoch 80] ogbg-molclintox: 0.730507 test loss: 0.225095
[Epoch 81; Iter    10/   40] train: loss: 0.0976350
[Epoch 81; Iter    40/   40] train: loss: 0.0777568
[Epoch 81] ogbg-molclintox: 0.982106 val loss: 0.065228
[Epoch 81] ogbg-molclintox: 0.831143 test loss: 0.198373
[Epoch 82; Iter    30/   40] train: loss: 0.0745839
[Epoch 82] ogbg-molclintox: 0.954085 val loss: 0.090860
[Epoch 82] ogbg-molclintox: 0.775278 test loss: 0.233103
[Epoch 83; Iter    20/   40] train: loss: 0.0627878
[Epoch 83] ogbg-molclintox: 0.968271 val loss: 0.075763
[Epoch 83] ogbg-molclintox: 0.722711 test loss: 0.233167
[Epoch 84; Iter    10/   40] train: loss: 0.0405877
[Epoch 84; Iter    40/   40] train: loss: 0.1033799
[Epoch 84] ogbg-molclintox: 0.986439 val loss: 0.057420
[Epoch 84] ogbg-molclintox: 0.843111 test loss: 0.200586
[Epoch 85; Iter    30/   40] train: loss: 0.0332754
[Epoch 85] ogbg-molclintox: 0.954173 val loss: 0.086339
[Epoch 85] ogbg-molclintox: 0.746658 test loss: 0.214044
[Epoch 86; Iter    20/   40] train: loss: 0.0428752
[Epoch 86] ogbg-molclintox: 0.972091 val loss: 0.081365
[Epoch 86] ogbg-molclintox: 0.799214 test loss: 0.230142
[Epoch 87; Iter    10/   40] train: loss: 0.0256927
[Epoch 87; Iter    40/   40] train: loss: 0.0573903
[Epoch 87] ogbg-molclintox: 0.979060 val loss: 0.068019
[Epoch 87] ogbg-molclintox: 0.782398 test loss: 0.243935
[Epoch 88; Iter    30/   40] train: loss: 0.0687884
[Epoch 88] ogbg-molclintox: 0.968071 val loss: 0.077866
[Epoch 88] ogbg-molclintox: 0.783735 test loss: 0.227051
[Epoch 89; Iter    20/   40] train: loss: 0.1917157
[Epoch 89] ogbg-molclintox: 0.976849 val loss: 0.065900
[Epoch 89] ogbg-molclintox: 0.821749 test loss: 0.221164
[Epoch 90; Iter    10/   40] train: loss: 0.1062596
[Epoch 90; Iter    40/   40] train: loss: 0.0146580
[Epoch 90] ogbg-molclintox: 0.969695 val loss: 0.084922
[Epoch 90] ogbg-molclintox: 0.791217 test loss: 0.227457
[Epoch 91; Iter    30/   40] train: loss: 0.0050559
[Epoch 91] ogbg-molclintox: 0.980008 val loss: 0.073957
[Epoch 91] ogbg-molclintox: 0.838651 test loss: 0.219481
[Epoch 92; Iter    20/   40] train: loss: 0.0382268
[Epoch 92] ogbg-molclintox: 0.964437 val loss: 0.065971
[Epoch 92] ogbg-molclintox: 0.824558 test loss: 0.212416
[Epoch 93; Iter    10/   40] train: loss: 0.0241363
[Epoch 93; Iter    40/   40] train: loss: 0.0113882
[Epoch 93] ogbg-molclintox: 0.984591 val loss: 0.060068
[Epoch 93] ogbg-molclintox: 0.830392 test loss: 0.223042
[Epoch 94; Iter    30/   40] train: loss: 0.0034688
[Epoch 94] ogbg-molclintox: 0.972316 val loss: 0.075400
[Epoch 94] ogbg-molclintox: 0.855714 test loss: 0.211520
[Epoch 95; Iter    20/   40] train: loss: 0.0983119
[Epoch 95] ogbg-molclintox: 0.985965 val loss: 0.069318
[Epoch 95] ogbg-molclintox: 0.812728 test loss: 0.226148
[Epoch 96; Iter    10/   40] train: loss: 0.0647696
[Epoch 96; Iter    40/   40] train: loss: 0.2170579
[Epoch 96] ogbg-molclintox: 0.974189 val loss: 0.070929
[Epoch 96] ogbg-molclintox: 0.804533 test loss: 0.232849
[Epoch 97; Iter    30/   40] train: loss: 0.0170494
[Epoch 97] ogbg-molclintox: 0.969656 val loss: 0.069706
[Epoch 97] ogbg-molclintox: 0.854675 test loss: 0.209049
[Epoch 98; Iter    20/   40] train: loss: 0.0185838
[Epoch 98] ogbg-molclintox: 0.939962 val loss: 0.079926
[Epoch 98] ogbg-molclintox: 0.794926 test loss: 0.227443
[Epoch 99; Iter    10/   40] train: loss: 0.0590154
[Epoch 99; Iter    40/   40] train: loss: 0.0147822
[Epoch 99] ogbg-molclintox: 0.965049 val loss: 0.081078
[Epoch 99] ogbg-molclintox: 0.803296 test loss: 0.223332
[Epoch 100; Iter    30/   40] train: loss: 0.0501106
[Epoch 100] ogbg-molclintox: 0.970106 val loss: 0.071110
[Epoch 100] ogbg-molclintox: 0.811503 test loss: 0.226330
[Epoch 101; Iter    20/   40] train: loss: 0.0815192
[Epoch 101] ogbg-molclintox: 0.957894 val loss: 0.081059
[Epoch 101] ogbg-molclintox: 0.798698 test loss: 0.229484
[Epoch 102; Iter    10/   40] train: loss: 0.0051017
[Epoch 102; Iter    40/   40] train: loss: 0.1027002
[Epoch 102] ogbg-molclintox: 0.974077 val loss: 0.066124
[Epoch 102] ogbg-molclintox: 0.822634 test loss: 0.213695
[Epoch 103; Iter    30/   40] train: loss: 0.0092200
[Epoch 103] ogbg-molclintox: 0.957757 val loss: 0.080697
[Epoch 103] ogbg-molclintox: 0.795139 test loss: 0.216537
[Epoch 104; Iter    20/   40] train: loss: 0.0344428
[Epoch 104] ogbg-molclintox: 0.972130 val loss: 0.077131
[Epoch 104] ogbg-molclintox: 0.796151 test loss: 0.236187
[Epoch 105; Iter    10/   40] train: loss: 0.0064170
[Epoch 105; Iter    40/   40] train: loss: 0.0136243
[Epoch 105] ogbg-molclintox: 0.976600 val loss: 0.069745
[Epoch 105] ogbg-molclintox: 0.857899 test loss: 0.206915
[Epoch 106; Iter    30/   40] train: loss: 0.0207234
[Epoch 106] ogbg-molclintox: 0.962427 val loss: 0.079340
[Epoch 106] ogbg-molclintox: 0.831741 test loss: 0.222713
[Epoch 107; Iter    20/   40] train: loss: 0.0472075
[Epoch 107] ogbg-molclintox: 0.972291 val loss: 0.064031
[Epoch 107] ogbg-molclintox: 0.832977 test loss: 0.219566
[Epoch 108; Iter    10/   40] train: loss: 0.0224746
[Epoch 108; Iter    40/   40] train: loss: 0.0071914
[Epoch 108] ogbg-molclintox: 0.965137 val loss: 0.082508
[Epoch 108] ogbg-molclintox: 0.797824 test loss: 0.237544
[Epoch 109; Iter    30/   40] train: loss: 0.0407027
[Epoch 109] ogbg-molclintox: 0.953386 val loss: 0.080210
[Epoch 109] ogbg-molclintox: 0.817061 test loss: 0.227727
[Epoch 110; Iter    20/   40] train: loss: 0.0401822
[Epoch 110] ogbg-molclintox: 0.941898 val loss: 0.087652
[Epoch 110] ogbg-molclintox: 0.802833 test loss: 0.225602
[Epoch 111; Iter    10/   40] train: loss: 0.0116380
[Epoch 111; Iter    40/   40] train: loss: 0.0013054
[Epoch 111] ogbg-molclintox: 0.949777 val loss: 0.080565
[Epoch 111] ogbg-molclintox: 0.828767 test loss: 0.222384
[Epoch 112; Iter    30/   40] train: loss: 0.0307370
[Epoch 112] ogbg-molclintox: 0.975001 val loss: 0.067953
[Epoch 112] ogbg-molclintox: 0.819661 test loss: 0.227208
[Epoch 113; Iter    20/   40] train: loss: 0.1088191
[Epoch 113] ogbg-molclintox: 0.961103 val loss: 0.079590
[Epoch 113] ogbg-molclintox: 0.826194 test loss: 0.221770
[Epoch 114; Iter    10/   40] train: loss: 0.0182720
[Epoch 114; Iter    40/   40] train: loss: 0.2321128
[Epoch 114] ogbg-molclintox: 0.966697 val loss: 0.073182
[Epoch 114] ogbg-molclintox: 0.822858 test loss: 0.228453
[Epoch 115; Iter    30/   40] train: loss: 0.1026571
[Epoch 115] ogbg-molclintox: 0.965411 val loss: 0.072223
[Epoch 115] ogbg-molclintox: 0.808817 test loss: 0.232180
[Epoch 116; Iter    20/   40] train: loss: 0.0372707
[Epoch 116] ogbg-molclintox: 0.969856 val loss: 0.079409
[Epoch 116] ogbg-molclintox: 0.833739 test loss: 0.220285
[Epoch 117; Iter    10/   40] train: loss: 0.0509687
[Epoch 117; Iter    40/   40] train: loss: 0.0093757
[Epoch 117] ogbg-molclintox: 0.978947 val loss: 0.073072
[Epoch 117] ogbg-molclintox: 0.801362 test loss: 0.233982
[Epoch 118; Iter    30/   40] train: loss: 0.0377989
[Epoch 118] ogbg-molclintox: 0.966423 val loss: 0.079394
[Epoch 118] ogbg-molclintox: 0.834090 test loss: 0.219370
[Epoch 119; Iter    20/   40] train: loss: 0.0497565
[Epoch 119] ogbg-molclintox: 0.957033 val loss: 0.084826
[Epoch 119] ogbg-molclintox: 0.811914 test loss: 0.224965
[Epoch 120; Iter    10/   40] train: loss: 0.1437366
[Epoch 120; Iter    40/   40] train: loss: 0.0055138
[Epoch 120] ogbg-molclintox: 0.973602 val loss: 0.067955
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
All runs completed.
[Epoch 120] ogbg-molclintox: 0.869530 test loss: 0.212148
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 120 epochs. Best model checkpoint was in epoch 47.
Statistics on  val_best_checkpoint
mean_pred: 0.222097709774971
std_pred: 5.602169036865234
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.9999757187257187
rocauc: 0.9993006993006993
ogbg-molclintox: 0.9993006993006993
OGBNanLabelBCEWithLogitsLoss: 0.05572129786014557
Statistics on  test
mean_pred: 0.16637589037418365
std_pred: 4.990085124969482
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.693798424321
rocauc: 0.8507454905640705
ogbg-molclintox: 0.8507454905640705
OGBNanLabelBCEWithLogitsLoss: 0.20127553939819337
Statistics on  train
mean_pred: 0.2020862102508545
std_pred: 5.751931667327881
mean_targets: 0.5067738890647888
std_targets: 0.500059962272644
prcauc: 0.90256110181349
rocauc: 0.9767087720317098
ogbg-molclintox: 0.9767087720317098
OGBNanLabelBCEWithLogitsLoss: 0.10188012951985001
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 120] ogbg-molclintox: 0.791493 test loss: 0.905753
[Epoch 121; Iter    30/   40] train: loss: 0.0211537
[Epoch 121] ogbg-molclintox: 0.955596 val loss: 0.082402
[Epoch 121] ogbg-molclintox: 0.790981 test loss: 0.229632
[Epoch 122; Iter    20/   40] train: loss: 0.0221092
[Epoch 122] ogbg-molclintox: 0.952637 val loss: 0.090249
[Epoch 122] ogbg-molclintox: 0.831180 test loss: 0.223796
[Epoch 123; Iter    10/   40] train: loss: 0.0335577
[Epoch 123; Iter    40/   40] train: loss: 0.0079199
[Epoch 123] ogbg-molclintox: 0.947268 val loss: 0.090672
[Epoch 123] ogbg-molclintox: 0.802998 test loss: 0.238709
[Epoch 124; Iter    30/   40] train: loss: 0.0410254
[Epoch 124] ogbg-molclintox: 0.936054 val loss: 0.086622
[Epoch 124] ogbg-molclintox: 0.802960 test loss: 0.233181
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 124 epochs. Best model checkpoint was in epoch 64.
Statistics on  val_best_checkpoint
mean_pred: 0.2575280964374542
std_pred: 5.276273250579834
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.9742063492063491
rocauc: 0.9988262910798122
ogbg-molclintox: 0.9988262910798122
OGBNanLabelBCEWithLogitsLoss: 0.05197263262234628
Statistics on  test
mean_pred: 0.200507253408432
std_pred: 6.063806533813477
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.7193785387731777
rocauc: 0.8341796128314739
ogbg-molclintox: 0.8341796128314739
OGBNanLabelBCEWithLogitsLoss: 0.22639201804995537
Statistics on  train
mean_pred: 0.2541411221027374
std_pred: 6.205709934234619
mean_targets: 0.5067738890647888
std_targets: 0.500059962272644
prcauc: 0.9377951835469049
rocauc: 0.9889947986643897
ogbg-molclintox: 0.9889947986643897
OGBNanLabelBCEWithLogitsLoss: 0.0743236402864568
All runs completed.
