>>> Starting run for dataset: toxcast
Running SCAFF configs_split_experiments/3DInfomax/toxcast/scaff/train_prop=0.6.yml on cuda:0
Running SCAFF configs_split_experiments/3DInfomax/toxcast/scaff/train_prop=0.7.yml on cuda:1
Running SCAFF configs_split_experiments/3DInfomax/toxcast/scaff/train_prop=0.8.yml on cuda:2
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
Starting process for seed 4: python train.py --config configs_split_experiments/3DInfomax/toxcast/scaff/train_prop=0.7.yml --seed 4 --device cuda:1
Starting process for seed 4: python train.py --config configs_split_experiments/3DInfomax/toxcast/scaff/train_prop=0.6.yml --seed 4 --device cuda:0
Starting process for seed 4: python train.py --config configs_split_experiments/3DInfomax/toxcast/scaff/train_prop=0.8.yml --seed 4 --device cuda:2
Starting process for seed 5: python train.py --config configs_split_experiments/3DInfomax/toxcast/scaff/train_prop=0.7.yml --seed 5 --device cuda:1
Starting process for seed 5: python train.py --config configs_split_experiments/3DInfomax/toxcast/scaff/train_prop=0.6.yml --seed 5 --device cuda:0
Starting process for seed 5: python train.py --config configs_split_experiments/3DInfomax/toxcast/scaff/train_prop=0.8.yml --seed 5 --device cuda:2
Starting process for seed 6: python train.py --config configs_split_experiments/3DInfomax/toxcast/scaff/train_prop=0.6.yml --seed 6 --device cuda:0
Starting process for seed 6: python train.py --config configs_split_experiments/3DInfomax/toxcast/scaff/train_prop=0.7.yml --seed 6 --device cuda:1
Starting process for seed 6: python train.py --config configs_split_experiments/3DInfomax/toxcast/scaff/train_prop=0.8.yml --seed 6 --device cuda:2
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[ Using Seed :  6  ]
using device:  cuda:2
Log directory:  runs/split/3DInfomax/toxcast/scaff/train_prop=0.8/PNA_ogbg-moltoxcast_3DInfomax_toxcast_scaff=0.8_6_26-05_09-18-15
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/toxcast/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_scaff=0.8
logdir: runs/split/3DInfomax/toxcast/scaff/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6931990
[Epoch 1; Iter    60/  229] train: loss: 0.6931769
[Epoch 1; Iter    90/  229] train: loss: 0.6931234
[Epoch 1; Iter   120/  229] train: loss: 0.6931630
[Epoch 1; Iter   150/  229] train: loss: 0.6931223
[Epoch 1; Iter   180/  229] train: loss: 0.6931464
[Epoch 1; Iter   210/  229] train: loss: 0.6931865
[Epoch 1] ogbg-moltoxcast: 0.500342 val loss: 0.693128
[Epoch 1] ogbg-moltoxcast: 0.501094 test loss: 0.693198
[Epoch 2; Iter    11/  229] train: loss: 0.6931514
[Epoch 2; Iter    41/  229] train: loss: 0.6931424
[Epoch 2; Iter    71/  229] train: loss: 0.6931203
[Epoch 2; Iter   101/  229] train: loss: 0.6930810
[Epoch 2; Iter   131/  229] train: loss: 0.6931149
[Epoch 2; Iter   161/  229] train: loss: 0.6930590
[Epoch 2; Iter   191/  229] train: loss: 0.6930009
[Epoch 2; Iter   221/  229] train: loss: 0.6930940
[Epoch 2] ogbg-moltoxcast: 0.499315 val loss: 0.692992
[Epoch 2] ogbg-moltoxcast: 0.499730 test loss: 0.693070
[Epoch 3; Iter    22/  229] train: loss: 0.6930192
[Epoch 3; Iter    52/  229] train: loss: 0.6928627
[Epoch 3; Iter    82/  229] train: loss: 0.6930284
[Epoch 3; Iter   112/  229] train: loss: 0.6928737
[Epoch 3; Iter   142/  229] train: loss: 0.6929584
[Epoch 3; Iter   172/  229] train: loss: 0.6928675
[Epoch 3; Iter   202/  229] train: loss: 0.6928354
[Epoch 3] ogbg-moltoxcast: 0.500357 val loss: 0.692828
[Epoch 3] ogbg-moltoxcast: 0.499211 test loss: 0.692920
[Epoch 4; Iter     3/  229] train: loss: 0.6928297
[Epoch 4; Iter    33/  229] train: loss: 0.6893287
[Epoch 4; Iter    63/  229] train: loss: 0.6754724
[Epoch 4; Iter    93/  229] train: loss: 0.6367443
[Epoch 4; Iter   123/  229] train: loss: 0.6319019
[Epoch 4; Iter   153/  229] train: loss: 0.5503996
[Epoch 4; Iter   183/  229] train: loss: 0.5637560
[Epoch 4; Iter   213/  229] train: loss: 0.4364411
[Epoch 4] ogbg-moltoxcast: 0.587679 val loss: 0.533462
[Epoch 4] ogbg-moltoxcast: 0.548748 test loss: 0.552674
[Epoch 5; Iter    14/  229] train: loss: 0.4367556
[Epoch 5; Iter    44/  229] train: loss: 0.3703630
[Epoch 5; Iter    74/  229] train: loss: 0.3196850
[Epoch 5; Iter   104/  229] train: loss: 0.3113112
[Epoch 5; Iter   134/  229] train: loss: 0.2936954
[Epoch 5; Iter   164/  229] train: loss: 0.2523015
[Epoch 5; Iter   194/  229] train: loss: 0.2533822
[Epoch 5; Iter   224/  229] train: loss: 0.3194701
[Epoch 5] ogbg-moltoxcast: 0.608778 val loss: 0.276554
[Epoch 5] ogbg-moltoxcast: 0.591518 test loss: 0.312403
[Epoch 6; Iter    25/  229] train: loss: 0.3062823
[Epoch 6; Iter    55/  229] train: loss: 0.1831358
[Epoch 6; Iter    85/  229] train: loss: 0.2405998
[Epoch 6; Iter   115/  229] train: loss: 0.2379148
[Epoch 6; Iter   145/  229] train: loss: 0.2161494
[Epoch 6; Iter   175/  229] train: loss: 0.1743811
[Epoch 6; Iter   205/  229] train: loss: 0.1421014
[Epoch 6] ogbg-moltoxcast: 0.637210 val loss: 0.301821
[Epoch 6] ogbg-moltoxcast: 0.615930 test loss: 0.309482
[Epoch 7; Iter     6/  229] train: loss: 0.1714376
[Epoch 7; Iter    36/  229] train: loss: 0.1497109
[Epoch 7; Iter    66/  229] train: loss: 0.1932446
[Epoch 7; Iter    96/  229] train: loss: 0.2713951
[Epoch 7; Iter   126/  229] train: loss: 0.1875435
[Epoch 7; Iter   156/  229] train: loss: 0.2266914
[Epoch 7; Iter   186/  229] train: loss: 0.1966444
[Epoch 7; Iter   216/  229] train: loss: 0.1987741
[Epoch 7] ogbg-moltoxcast: 0.589783 val loss: 0.383740
[Epoch 7] ogbg-moltoxcast: 0.570603 test loss: 0.536004
[Epoch 8; Iter    17/  229] train: loss: 0.1576000
[Epoch 8; Iter    47/  229] train: loss: 0.1801026
[Epoch 8; Iter    77/  229] train: loss: 0.1677228
[Epoch 8; Iter   107/  229] train: loss: 0.2247710
[Epoch 8; Iter   137/  229] train: loss: 0.2426333
[Epoch 8; Iter   167/  229] train: loss: 0.1950423
[Epoch 8; Iter   197/  229] train: loss: 0.2389660
[Epoch 8; Iter   227/  229] train: loss: 0.3861101
[Epoch 8] ogbg-moltoxcast: 0.670779 val loss: 0.597964
[Epoch 8] ogbg-moltoxcast: 0.635102 test loss: 1.098664
[Epoch 9; Iter    28/  229] train: loss: 0.1615864
[Epoch 9; Iter    58/  229] train: loss: 0.1378249
[Epoch 9; Iter    88/  229] train: loss: 0.1690536
[Epoch 9; Iter   118/  229] train: loss: 0.2334437
[Epoch 9; Iter   148/  229] train: loss: 0.3078712
[Epoch 9; Iter   178/  229] train: loss: 0.1536472
[Epoch 9; Iter   208/  229] train: loss: 0.2403599
[Epoch 9] ogbg-moltoxcast: 0.676267 val loss: 0.261137
[Epoch 9] ogbg-moltoxcast: 0.623733 test loss: 0.477997
[Epoch 10; Iter     9/  229] train: loss: 0.2207012
[Epoch 10; Iter    39/  229] train: loss: 0.1760369
[Epoch 10; Iter    69/  229] train: loss: 0.1571287
[Epoch 10; Iter    99/  229] train: loss: 0.1119093
[Epoch 10; Iter   129/  229] train: loss: 0.1666767
[Epoch 10; Iter   159/  229] train: loss: 0.2315529
[Epoch 10; Iter   189/  229] train: loss: 0.1916263
[Epoch 10; Iter   219/  229] train: loss: 0.2319539
[Epoch 10] ogbg-moltoxcast: 0.662164 val loss: 0.267484
[Epoch 10] ogbg-moltoxcast: 0.619454 test loss: 0.326196
[Epoch 11; Iter    20/  229] train: loss: 0.1537399
[Epoch 11; Iter    50/  229] train: loss: 0.1873964
[Epoch 11; Iter    80/  229] train: loss: 0.1419551
[Epoch 11; Iter   110/  229] train: loss: 0.1329388
[Epoch 11; Iter   140/  229] train: loss: 0.2204871
[Epoch 11; Iter   170/  229] train: loss: 0.2857477
[Epoch 11; Iter   200/  229] train: loss: 0.1415604
[Epoch 11] ogbg-moltoxcast: 0.659300 val loss: 0.258260
[Epoch 11] ogbg-moltoxcast: 0.635099 test loss: 0.300422
[Epoch 12; Iter     1/  229] train: loss: 0.2017725
[ Using Seed :  5  ]
using device:  cuda:2
Log directory:  runs/split/3DInfomax/toxcast/scaff/train_prop=0.8/PNA_ogbg-moltoxcast_3DInfomax_toxcast_scaff=0.8_5_26-05_09-18-15
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/toxcast/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_scaff=0.8
logdir: runs/split/3DInfomax/toxcast/scaff/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6930988
[Epoch 1; Iter    60/  229] train: loss: 0.6931993
[Epoch 1; Iter    90/  229] train: loss: 0.6931190
[Epoch 1; Iter   120/  229] train: loss: 0.6931419
[Epoch 1; Iter   150/  229] train: loss: 0.6931109
[Epoch 1; Iter   180/  229] train: loss: 0.6931548
[Epoch 1; Iter   210/  229] train: loss: 0.6931753
[Epoch 1] ogbg-moltoxcast: 0.501206 val loss: 0.693057
[Epoch 1] ogbg-moltoxcast: 0.509942 test loss: 0.693054
[Epoch 2; Iter    11/  229] train: loss: 0.6930524
[Epoch 2; Iter    41/  229] train: loss: 0.6930988
[Epoch 2; Iter    71/  229] train: loss: 0.6931013
[Epoch 2; Iter   101/  229] train: loss: 0.6930381
[Epoch 2; Iter   131/  229] train: loss: 0.6930550
[Epoch 2; Iter   161/  229] train: loss: 0.6929770
[Epoch 2; Iter   191/  229] train: loss: 0.6929557
[Epoch 2; Iter   221/  229] train: loss: 0.6929542
[Epoch 2] ogbg-moltoxcast: 0.503132 val loss: 0.692918
[Epoch 2] ogbg-moltoxcast: 0.510113 test loss: 0.692932
[Epoch 3; Iter    22/  229] train: loss: 0.6928390
[Epoch 3; Iter    52/  229] train: loss: 0.6928915
[Epoch 3; Iter    82/  229] train: loss: 0.6928974
[Epoch 3; Iter   112/  229] train: loss: 0.6928214
[Epoch 3; Iter   142/  229] train: loss: 0.6927980
[Epoch 3; Iter   172/  229] train: loss: 0.6927325
[Epoch 3; Iter   202/  229] train: loss: 0.6927986
[Epoch 3] ogbg-moltoxcast: 0.503337 val loss: 0.692694
[Epoch 3] ogbg-moltoxcast: 0.509008 test loss: 0.692728
[Epoch 4; Iter     3/  229] train: loss: 0.6928788
[Epoch 4; Iter    33/  229] train: loss: 0.6901041
[Epoch 4; Iter    63/  229] train: loss: 0.6744521
[Epoch 4; Iter    93/  229] train: loss: 0.6292068
[Epoch 4; Iter   123/  229] train: loss: 0.5908689
[Epoch 4; Iter   153/  229] train: loss: 0.5394905
[Epoch 4; Iter   183/  229] train: loss: 0.5012987
[Epoch 4; Iter   213/  229] train: loss: 0.4347972
[Epoch 4] ogbg-moltoxcast: 0.583533 val loss: 0.527340
[Epoch 4] ogbg-moltoxcast: 0.554626 test loss: 0.551154
[Epoch 5; Iter    14/  229] train: loss: 0.4106595
[Epoch 5; Iter    44/  229] train: loss: 0.3131006
[Epoch 5; Iter    74/  229] train: loss: 0.3435227
[Epoch 5; Iter   104/  229] train: loss: 0.2776832
[Epoch 5; Iter   134/  229] train: loss: 0.2531861
[Epoch 5; Iter   164/  229] train: loss: 0.2095482
[Epoch 5; Iter   194/  229] train: loss: 0.2280537
[Epoch 5; Iter   224/  229] train: loss: 0.1577146
[Epoch 5] ogbg-moltoxcast: 0.621260 val loss: 0.280607
[Epoch 5] ogbg-moltoxcast: 0.591398 test loss: 0.314749
[Epoch 6; Iter    25/  229] train: loss: 0.2844442
[Epoch 6; Iter    55/  229] train: loss: 0.1939869
[Epoch 6; Iter    85/  229] train: loss: 0.1760120
[Epoch 6; Iter   115/  229] train: loss: 0.1952102
[Epoch 6; Iter   145/  229] train: loss: 0.2557704
[Epoch 6; Iter   175/  229] train: loss: 0.2210647
[Epoch 6; Iter   205/  229] train: loss: 0.1912959
[Epoch 6] ogbg-moltoxcast: 0.619717 val loss: 0.330902
[Epoch 6] ogbg-moltoxcast: 0.605554 test loss: 0.305000
[Epoch 7; Iter     6/  229] train: loss: 0.1711201
[Epoch 7; Iter    36/  229] train: loss: 0.1449659
[Epoch 7; Iter    66/  229] train: loss: 0.2177381
[Epoch 7; Iter    96/  229] train: loss: 0.2375477
[Epoch 7; Iter   126/  229] train: loss: 0.2781695
[Epoch 7; Iter   156/  229] train: loss: 0.1683366
[Epoch 7; Iter   186/  229] train: loss: 0.3428908
[Epoch 7; Iter   216/  229] train: loss: 0.1975360
[Epoch 7] ogbg-moltoxcast: 0.583513 val loss: 0.271364
[Epoch 7] ogbg-moltoxcast: 0.584080 test loss: 0.310245
[Epoch 8; Iter    17/  229] train: loss: 0.2308771
[Epoch 8; Iter    47/  229] train: loss: 0.1677667
[Epoch 8; Iter    77/  229] train: loss: 0.1826683
[Epoch 8; Iter   107/  229] train: loss: 0.2006824
[Epoch 8; Iter   137/  229] train: loss: 0.2190251
[Epoch 8; Iter   167/  229] train: loss: 0.1483873
[Epoch 8; Iter   197/  229] train: loss: 0.1972670
[Epoch 8; Iter   227/  229] train: loss: 0.1463623
[Epoch 8] ogbg-moltoxcast: 0.649885 val loss: 0.270206
[Epoch 8] ogbg-moltoxcast: 0.606202 test loss: 0.304148
[Epoch 9; Iter    28/  229] train: loss: 0.1597957
[Epoch 9; Iter    58/  229] train: loss: 0.1899338
[Epoch 9; Iter    88/  229] train: loss: 0.2077401
[Epoch 9; Iter   118/  229] train: loss: 0.1617757
[Epoch 9; Iter   148/  229] train: loss: 0.2148169
[Epoch 9; Iter   178/  229] train: loss: 0.1884713
[Epoch 9; Iter   208/  229] train: loss: 0.1938856
[Epoch 9] ogbg-moltoxcast: 0.649697 val loss: 0.336409
[Epoch 9] ogbg-moltoxcast: 0.628366 test loss: 0.601700
[Epoch 10; Iter     9/  229] train: loss: 0.1439960
[Epoch 10; Iter    39/  229] train: loss: 0.1202352
[Epoch 10; Iter    69/  229] train: loss: 0.2384914
[Epoch 10; Iter    99/  229] train: loss: 0.1499597
[Epoch 10; Iter   129/  229] train: loss: 0.1635785
[Epoch 10; Iter   159/  229] train: loss: 0.1696745
[Epoch 10; Iter   189/  229] train: loss: 0.2720908
[Epoch 10; Iter   219/  229] train: loss: 0.1605616
[Epoch 10] ogbg-moltoxcast: 0.655417 val loss: 0.263601
[Epoch 10] ogbg-moltoxcast: 0.638149 test loss: 0.303696
[Epoch 11; Iter    20/  229] train: loss: 0.1702254
[Epoch 11; Iter    50/  229] train: loss: 0.1676452
[Epoch 11; Iter    80/  229] train: loss: 0.1864584
[Epoch 11; Iter   110/  229] train: loss: 0.1822253
[Epoch 11; Iter   140/  229] train: loss: 0.2158639
[Epoch 11; Iter   170/  229] train: loss: 0.1386620
[Epoch 11; Iter   200/  229] train: loss: 0.2066491
[Epoch 11] ogbg-moltoxcast: 0.668707 val loss: 0.270609
[Epoch 11] ogbg-moltoxcast: 0.639256 test loss: 0.324879
[Epoch 12; Iter     1/  229] train: loss: 0.2084816
[ Using Seed :  4  ]
using device:  cuda:2
Log directory:  runs/split/3DInfomax/toxcast/scaff/train_prop=0.8/PNA_ogbg-moltoxcast_3DInfomax_toxcast_scaff=0.8_4_26-05_09-18-15
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/toxcast/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_scaff=0.8
logdir: runs/split/3DInfomax/toxcast/scaff/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6931715
[Epoch 1; Iter    60/  229] train: loss: 0.6931896
[Epoch 1; Iter    90/  229] train: loss: 0.6931353
[Epoch 1; Iter   120/  229] train: loss: 0.6931071
[Epoch 1; Iter   150/  229] train: loss: 0.6931202
[Epoch 1; Iter   180/  229] train: loss: 0.6931241
[Epoch 1; Iter   210/  229] train: loss: 0.6931379
[Epoch 1] ogbg-moltoxcast: 0.504053 val loss: 0.693148
[Epoch 1] ogbg-moltoxcast: 0.500634 test loss: 0.693155
[Epoch 2; Iter    11/  229] train: loss: 0.6931756
[Epoch 2; Iter    41/  229] train: loss: 0.6931081
[Epoch 2; Iter    71/  229] train: loss: 0.6930705
[Epoch 2; Iter   101/  229] train: loss: 0.6930866
[Epoch 2; Iter   131/  229] train: loss: 0.6930298
[Epoch 2; Iter   161/  229] train: loss: 0.6930939
[Epoch 2; Iter   191/  229] train: loss: 0.6930686
[Epoch 2; Iter   221/  229] train: loss: 0.6930038
[Epoch 2] ogbg-moltoxcast: 0.503096 val loss: 0.693045
[Epoch 2] ogbg-moltoxcast: 0.499497 test loss: 0.693066
[Epoch 3; Iter    22/  229] train: loss: 0.6930162
[Epoch 3; Iter    52/  229] train: loss: 0.6930234
[Epoch 3; Iter    82/  229] train: loss: 0.6929821
[Epoch 3; Iter   112/  229] train: loss: 0.6929579
[Epoch 3; Iter   142/  229] train: loss: 0.6929533
[Epoch 3; Iter   172/  229] train: loss: 0.6929307
[Epoch 3; Iter   202/  229] train: loss: 0.6929398
[Epoch 3] ogbg-moltoxcast: 0.503084 val loss: 0.692872
[Epoch 3] ogbg-moltoxcast: 0.500348 test loss: 0.692905
[Epoch 4; Iter     3/  229] train: loss: 0.6928313
[Epoch 4; Iter    33/  229] train: loss: 0.6903687
[Epoch 4; Iter    63/  229] train: loss: 0.6758286
[Epoch 4; Iter    93/  229] train: loss: 0.6587858
[Epoch 4; Iter   123/  229] train: loss: 0.6129633
[Epoch 4; Iter   153/  229] train: loss: 0.5957923
[Epoch 4; Iter   183/  229] train: loss: 0.5264485
[Epoch 4; Iter   213/  229] train: loss: 0.4520765
[Epoch 4] ogbg-moltoxcast: 0.594532 val loss: 0.439000
[Epoch 4] ogbg-moltoxcast: 0.559944 test loss: 0.466451
[Epoch 5; Iter    14/  229] train: loss: 0.4362020
[Epoch 5; Iter    44/  229] train: loss: 0.3540535
[Epoch 5; Iter    74/  229] train: loss: 0.2867922
[Epoch 5; Iter   104/  229] train: loss: 0.3235494
[Epoch 5; Iter   134/  229] train: loss: 0.3178131
[Epoch 5; Iter   164/  229] train: loss: 0.2557105
[Epoch 5; Iter   194/  229] train: loss: 0.2501344
[Epoch 5; Iter   224/  229] train: loss: 0.1684435
[Epoch 5] ogbg-moltoxcast: 0.618959 val loss: 0.276367
[Epoch 5] ogbg-moltoxcast: 0.583531 test loss: 0.314204
[Epoch 6; Iter    25/  229] train: loss: 0.2574765
[Epoch 6; Iter    55/  229] train: loss: 0.2045357
[Epoch 6; Iter    85/  229] train: loss: 0.3053266
[Epoch 6; Iter   115/  229] train: loss: 0.2201587
[Epoch 6; Iter   145/  229] train: loss: 0.2130118
[Epoch 6; Iter   175/  229] train: loss: 0.1915605
[Epoch 6; Iter   205/  229] train: loss: 0.1833916
[Epoch 6] ogbg-moltoxcast: 0.624673 val loss: 0.267673
[Epoch 6] ogbg-moltoxcast: 0.616278 test loss: 0.299798
[Epoch 7; Iter     6/  229] train: loss: 0.1313613
[Epoch 7; Iter    36/  229] train: loss: 0.2326269
[Epoch 7; Iter    66/  229] train: loss: 0.2063138
[Epoch 7; Iter    96/  229] train: loss: 0.1924702
[Epoch 7; Iter   126/  229] train: loss: 0.2930489
[Epoch 7; Iter   156/  229] train: loss: 0.1820037
[Epoch 7; Iter   186/  229] train: loss: 0.3105771
[Epoch 7; Iter   216/  229] train: loss: 0.1878702
[Epoch 7] ogbg-moltoxcast: 0.636078 val loss: 0.270734
[Epoch 7] ogbg-moltoxcast: 0.601252 test loss: 0.310217
[Epoch 8; Iter    17/  229] train: loss: 0.1616474
[Epoch 8; Iter    47/  229] train: loss: 0.3220731
[Epoch 8; Iter    77/  229] train: loss: 0.1799117
[Epoch 8; Iter   107/  229] train: loss: 0.2549069
[Epoch 8; Iter   137/  229] train: loss: 0.1835513
[Epoch 8; Iter   167/  229] train: loss: 0.1670410
[Epoch 8; Iter   197/  229] train: loss: 0.2228290
[Epoch 8; Iter   227/  229] train: loss: 0.2108891
[Epoch 8] ogbg-moltoxcast: 0.639826 val loss: 0.269251
[Epoch 8] ogbg-moltoxcast: 0.619010 test loss: 0.311716
[Epoch 9; Iter    28/  229] train: loss: 0.1314045
[Epoch 9; Iter    58/  229] train: loss: 0.1288737
[Epoch 9; Iter    88/  229] train: loss: 0.2005192
[Epoch 9; Iter   118/  229] train: loss: 0.1108831
[Epoch 9; Iter   148/  229] train: loss: 0.2147911
[Epoch 9; Iter   178/  229] train: loss: 0.2144908
[Epoch 9; Iter   208/  229] train: loss: 0.1940026
[Epoch 9] ogbg-moltoxcast: 0.640634 val loss: 0.272069
[Epoch 9] ogbg-moltoxcast: 0.606122 test loss: 0.313973
[Epoch 10; Iter     9/  229] train: loss: 0.1464138
[Epoch 10; Iter    39/  229] train: loss: 0.1479093
[Epoch 10; Iter    69/  229] train: loss: 0.2476139
[Epoch 10; Iter    99/  229] train: loss: 0.2678275
[Epoch 10; Iter   129/  229] train: loss: 0.1654354
[Epoch 10; Iter   159/  229] train: loss: 0.2201822
[Epoch 10; Iter   189/  229] train: loss: 0.2289595
[Epoch 10; Iter   219/  229] train: loss: 0.2478369
[Epoch 10] ogbg-moltoxcast: 0.645162 val loss: 0.260854
[Epoch 10] ogbg-moltoxcast: 0.623797 test loss: 0.298926
[Epoch 11; Iter    20/  229] train: loss: 0.1640974
[Epoch 11; Iter    50/  229] train: loss: 0.1980154
[Epoch 11; Iter    80/  229] train: loss: 0.1749891
[Epoch 11; Iter   110/  229] train: loss: 0.1652089
[Epoch 11; Iter   140/  229] train: loss: 0.2630669
[Epoch 11; Iter   170/  229] train: loss: 0.2178090
[Epoch 11; Iter   200/  229] train: loss: 0.2766529
[Epoch 11] ogbg-moltoxcast: 0.666304 val loss: 0.259244
[Epoch 11] ogbg-moltoxcast: 0.621899 test loss: 0.307424
[Epoch 12; Iter     1/  229] train: loss: 0.1601509
[ Using Seed :  4  ]
using device:  cuda:1
Log directory:  runs/split/3DInfomax/toxcast/scaff/train_prop=0.7/PNA_ogbg-moltoxcast_3DInfomax_toxcast_scaff=0.7_4_26-05_09-18-15
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/toxcast/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_scaff=0.7
logdir: runs/split/3DInfomax/toxcast/scaff/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  201] train: loss: 0.6931764
[Epoch 1; Iter    60/  201] train: loss: 0.6931921
[Epoch 1; Iter    90/  201] train: loss: 0.6932734
[Epoch 1; Iter   120/  201] train: loss: 0.6932137
[Epoch 1; Iter   150/  201] train: loss: 0.6930702
[Epoch 1; Iter   180/  201] train: loss: 0.6931100
[Epoch 1] ogbg-moltoxcast: 0.498796 val loss: 0.693125
[Epoch 1] ogbg-moltoxcast: 0.498051 test loss: 0.693160
[Epoch 2; Iter     9/  201] train: loss: 0.6931164
[Epoch 2; Iter    39/  201] train: loss: 0.6930934
[Epoch 2; Iter    69/  201] train: loss: 0.6930957
[Epoch 2; Iter    99/  201] train: loss: 0.6930916
[Epoch 2; Iter   129/  201] train: loss: 0.6931193
[Epoch 2; Iter   159/  201] train: loss: 0.6930575
[Epoch 2; Iter   189/  201] train: loss: 0.6930237
[Epoch 2] ogbg-moltoxcast: 0.498174 val loss: 0.693065
[Epoch 2] ogbg-moltoxcast: 0.499700 test loss: 0.693100
[Epoch 3; Iter    18/  201] train: loss: 0.6930412
[Epoch 3; Iter    48/  201] train: loss: 0.6930447
[Epoch 3; Iter    78/  201] train: loss: 0.6929965
[Epoch 3; Iter   108/  201] train: loss: 0.6929765
[Epoch 3; Iter   138/  201] train: loss: 0.6930453
[Epoch 3; Iter   168/  201] train: loss: 0.6929687
[Epoch 3; Iter   198/  201] train: loss: 0.6930219
[Epoch 3] ogbg-moltoxcast: 0.498944 val loss: 0.692937
[Epoch 3] ogbg-moltoxcast: 0.499627 test loss: 0.692984
[Epoch 4; Iter    27/  201] train: loss: 0.6928704
[Epoch 4; Iter    57/  201] train: loss: 0.6928479
[Epoch 4; Iter    87/  201] train: loss: 0.6927889
[Epoch 4; Iter   117/  201] train: loss: 0.6898966
[Epoch 4; Iter   147/  201] train: loss: 0.6731837
[Epoch 4; Iter   177/  201] train: loss: 0.6528947
[Epoch 4] ogbg-moltoxcast: 0.591835 val loss: 0.764661
[Epoch 4] ogbg-moltoxcast: 0.576471 test loss: 0.785590
[Epoch 5; Iter     6/  201] train: loss: 0.6210250
[Epoch 5; Iter    36/  201] train: loss: 0.5933447
[Epoch 5; Iter    66/  201] train: loss: 0.5417720
[Epoch 5; Iter    96/  201] train: loss: 0.4729361
[Epoch 5; Iter   126/  201] train: loss: 0.4034968
[Epoch 5; Iter   156/  201] train: loss: 0.3197396
[Epoch 5; Iter   186/  201] train: loss: 0.3140885
[Epoch 5] ogbg-moltoxcast: 0.592378 val loss: 0.351072
[Epoch 5] ogbg-moltoxcast: 0.570531 test loss: 0.385367
[Epoch 6; Iter    15/  201] train: loss: 0.3145657
[Epoch 6; Iter    45/  201] train: loss: 0.3036280
[Epoch 6; Iter    75/  201] train: loss: 0.2515612
[Epoch 6; Iter   105/  201] train: loss: 0.3228738
[Epoch 6; Iter   135/  201] train: loss: 0.2625003
[Epoch 6; Iter   165/  201] train: loss: 0.3285089
[Epoch 6; Iter   195/  201] train: loss: 0.2431039
[Epoch 6] ogbg-moltoxcast: 0.627725 val loss: 0.266539
[Epoch 6] ogbg-moltoxcast: 0.600988 test loss: 0.344785
[Epoch 7; Iter    24/  201] train: loss: 0.1757647
[Epoch 7; Iter    54/  201] train: loss: 0.1559581
[Epoch 7; Iter    84/  201] train: loss: 0.1956230
[Epoch 7; Iter   114/  201] train: loss: 0.1467399
[Epoch 7; Iter   144/  201] train: loss: 0.1949589
[Epoch 7; Iter   174/  201] train: loss: 0.1970321
[Epoch 7] ogbg-moltoxcast: 0.643083 val loss: 0.257710
[Epoch 7] ogbg-moltoxcast: 0.605868 test loss: 0.353347
[Epoch 8; Iter     3/  201] train: loss: 0.1758562
[Epoch 8; Iter    33/  201] train: loss: 0.2415508
[Epoch 8; Iter    63/  201] train: loss: 0.2885755
[Epoch 8; Iter    93/  201] train: loss: 0.2100076
[Epoch 8; Iter   123/  201] train: loss: 0.1845510
[Epoch 8; Iter   153/  201] train: loss: 0.2850005
[Epoch 8; Iter   183/  201] train: loss: 0.2107964
[Epoch 8] ogbg-moltoxcast: 0.638551 val loss: 0.258717
[Epoch 8] ogbg-moltoxcast: 0.615494 test loss: 0.329631
[Epoch 9; Iter    12/  201] train: loss: 0.2268130
[Epoch 9; Iter    42/  201] train: loss: 0.2763329
[Epoch 9; Iter    72/  201] train: loss: 0.1192402
[Epoch 9; Iter   102/  201] train: loss: 0.2475074
[Epoch 9; Iter   132/  201] train: loss: 0.2133452
[Epoch 9; Iter   162/  201] train: loss: 0.1985470
[Epoch 9; Iter   192/  201] train: loss: 0.1526365
[Epoch 9] ogbg-moltoxcast: 0.631266 val loss: 0.316607
[Epoch 9] ogbg-moltoxcast: 0.598221 test loss: 0.501959
[Epoch 10; Iter    21/  201] train: loss: 0.1068453
[Epoch 10; Iter    51/  201] train: loss: 0.1784023
[Epoch 10; Iter    81/  201] train: loss: 0.1154224
[Epoch 10; Iter   111/  201] train: loss: 0.1932646
[Epoch 10; Iter   141/  201] train: loss: 0.1497308
[Epoch 10; Iter   171/  201] train: loss: 0.2219860
[Epoch 10; Iter   201/  201] train: loss: 0.1337444
[Epoch 10] ogbg-moltoxcast: 0.656514 val loss: 0.261643
[Epoch 10] ogbg-moltoxcast: 0.624142 test loss: 0.307886
[Epoch 11; Iter    30/  201] train: loss: 0.2078565
[Epoch 11; Iter    60/  201] train: loss: 0.1930964
[Epoch 11; Iter    90/  201] train: loss: 0.1766294
[Epoch 11; Iter   120/  201] train: loss: 0.1876835
[Epoch 11; Iter   150/  201] train: loss: 0.2037632
[Epoch 11; Iter   180/  201] train: loss: 0.1090483
[Epoch 11] ogbg-moltoxcast: 0.635286 val loss: 0.289003
[Epoch 11] ogbg-moltoxcast: 0.619150 test loss: 0.336104
[Epoch 12; Iter     9/  201] train: loss: 0.1633974
[Epoch 12; Iter    39/  201] train: loss: 0.2428802
[Epoch 12; Iter    69/  201] train: loss: 0.1861165
[Epoch 12; Iter    99/  201] train: loss: 0.1709439
[Epoch 12; Iter   129/  201] train: loss: 0.1390717
[Epoch 12; Iter   159/  201] train: loss: 0.1793382
[Epoch 12; Iter   189/  201] train: loss: 0.1605721
[Epoch 12] ogbg-moltoxcast: 0.651189 val loss: 0.267503
[Epoch 12] ogbg-moltoxcast: 0.627533 test loss: 0.319582
[Epoch 13; Iter    18/  201] train: loss: 0.1170072
[Epoch 13; Iter    48/  201] train: loss: 0.1709099
[ Using Seed :  6  ]
using device:  cuda:1
Log directory:  runs/split/3DInfomax/toxcast/scaff/train_prop=0.7/PNA_ogbg-moltoxcast_3DInfomax_toxcast_scaff=0.7_6_26-05_09-18-15
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/toxcast/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_scaff=0.7
logdir: runs/split/3DInfomax/toxcast/scaff/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  201] train: loss: 0.6931739
[Epoch 1; Iter    60/  201] train: loss: 0.6931318
[Epoch 1; Iter    90/  201] train: loss: 0.6931168
[Epoch 1; Iter   120/  201] train: loss: 0.6931500
[Epoch 1; Iter   150/  201] train: loss: 0.6931026
[Epoch 1; Iter   180/  201] train: loss: 0.6931353
[Epoch 1] ogbg-moltoxcast: 0.503985 val loss: 0.693142
[Epoch 1] ogbg-moltoxcast: 0.502920 test loss: 0.693192
[Epoch 2; Iter     9/  201] train: loss: 0.6930848
[Epoch 2; Iter    39/  201] train: loss: 0.6930996
[Epoch 2; Iter    69/  201] train: loss: 0.6930937
[Epoch 2; Iter    99/  201] train: loss: 0.6931560
[Epoch 2; Iter   129/  201] train: loss: 0.6931362
[Epoch 2; Iter   159/  201] train: loss: 0.6930821
[Epoch 2; Iter   189/  201] train: loss: 0.6931120
[Epoch 2] ogbg-moltoxcast: 0.501468 val loss: 0.693038
[Epoch 2] ogbg-moltoxcast: 0.502556 test loss: 0.693085
[Epoch 3; Iter    18/  201] train: loss: 0.6930312
[Epoch 3; Iter    48/  201] train: loss: 0.6930032
[Epoch 3; Iter    78/  201] train: loss: 0.6930206
[Epoch 3; Iter   108/  201] train: loss: 0.6930301
[Epoch 3; Iter   138/  201] train: loss: 0.6929721
[Epoch 3; Iter   168/  201] train: loss: 0.6928037
[Epoch 3; Iter   198/  201] train: loss: 0.6929449
[Epoch 3] ogbg-moltoxcast: 0.503451 val loss: 0.692924
[Epoch 3] ogbg-moltoxcast: 0.502324 test loss: 0.692984
[Epoch 4; Iter    27/  201] train: loss: 0.6929319
[Epoch 4; Iter    57/  201] train: loss: 0.6928325
[Epoch 4; Iter    87/  201] train: loss: 0.6928834
[Epoch 4; Iter   117/  201] train: loss: 0.6895223
[Epoch 4; Iter   147/  201] train: loss: 0.6723052
[Epoch 4; Iter   177/  201] train: loss: 0.6443105
[Epoch 4] ogbg-moltoxcast: 0.577669 val loss: 0.748128
[Epoch 4] ogbg-moltoxcast: 0.566401 test loss: 0.763597
[Epoch 5; Iter     6/  201] train: loss: 0.6044395
[Epoch 5; Iter    36/  201] train: loss: 0.5370222
[Epoch 5; Iter    66/  201] train: loss: 0.5439047
[Epoch 5; Iter    96/  201] train: loss: 0.4488243
[Epoch 5; Iter   126/  201] train: loss: 0.3953014
[Epoch 5; Iter   156/  201] train: loss: 0.3754940
[Epoch 5; Iter   186/  201] train: loss: 0.2797651
[Epoch 5] ogbg-moltoxcast: 0.605833 val loss: 0.389729
[Epoch 5] ogbg-moltoxcast: 0.562654 test loss: 0.450851
[Epoch 6; Iter    15/  201] train: loss: 0.2348716
[Epoch 6; Iter    45/  201] train: loss: 0.2388231
[Epoch 6; Iter    75/  201] train: loss: 0.2052616
[Epoch 6; Iter   105/  201] train: loss: 0.1970520
[Epoch 6; Iter   135/  201] train: loss: 0.2594165
[Epoch 6; Iter   165/  201] train: loss: 0.2594312
[Epoch 6; Iter   195/  201] train: loss: 0.2092772
[Epoch 6] ogbg-moltoxcast: 0.618859 val loss: 0.282394
[Epoch 6] ogbg-moltoxcast: 0.604533 test loss: 0.316886
[Epoch 7; Iter    24/  201] train: loss: 0.1711975
[Epoch 7; Iter    54/  201] train: loss: 0.1627139
[Epoch 7; Iter    84/  201] train: loss: 0.2004604
[Epoch 7; Iter   114/  201] train: loss: 0.2093799
[Epoch 7; Iter   144/  201] train: loss: 0.2346055
[Epoch 7; Iter   174/  201] train: loss: 0.2359598
[Epoch 7] ogbg-moltoxcast: 0.626511 val loss: 0.261426
[Epoch 7] ogbg-moltoxcast: 0.596062 test loss: 0.311148
[Epoch 8; Iter     3/  201] train: loss: 0.2136027
[Epoch 8; Iter    33/  201] train: loss: 0.1453763
[Epoch 8; Iter    63/  201] train: loss: 0.3329154
[Epoch 8; Iter    93/  201] train: loss: 0.2096882
[Epoch 8; Iter   123/  201] train: loss: 0.1785556
[Epoch 8; Iter   153/  201] train: loss: 0.1152712
[Epoch 8; Iter   183/  201] train: loss: 0.2488278
[Epoch 8] ogbg-moltoxcast: 0.614771 val loss: 0.333391
[Epoch 8] ogbg-moltoxcast: 0.588285 test loss: 0.515825
[Epoch 9; Iter    12/  201] train: loss: 0.1423153
[Epoch 9; Iter    42/  201] train: loss: 0.1801864
[Epoch 9; Iter    72/  201] train: loss: 0.1840362
[Epoch 9; Iter   102/  201] train: loss: 0.2048681
[Epoch 9; Iter   132/  201] train: loss: 0.1891996
[Epoch 9; Iter   162/  201] train: loss: 0.1633014
[Epoch 9; Iter   192/  201] train: loss: 0.1585345
[Epoch 9] ogbg-moltoxcast: 0.623986 val loss: 0.265074
[Epoch 9] ogbg-moltoxcast: 0.618455 test loss: 0.358550
[Epoch 10; Iter    21/  201] train: loss: 0.1467796
[Epoch 10; Iter    51/  201] train: loss: 0.2048053
[Epoch 10; Iter    81/  201] train: loss: 0.2298808
[Epoch 10; Iter   111/  201] train: loss: 0.1432774
[Epoch 10; Iter   141/  201] train: loss: 0.2078215
[Epoch 10; Iter   171/  201] train: loss: 0.1234946
[Epoch 10; Iter   201/  201] train: loss: 0.0805994
[Epoch 10] ogbg-moltoxcast: 0.645434 val loss: 0.353452
[Epoch 10] ogbg-moltoxcast: 0.605197 test loss: 1.184891
[Epoch 11; Iter    30/  201] train: loss: 0.2414588
[Epoch 11; Iter    60/  201] train: loss: 0.1702457
[Epoch 11; Iter    90/  201] train: loss: 0.1337749
[Epoch 11; Iter   120/  201] train: loss: 0.2033830
[Epoch 11; Iter   150/  201] train: loss: 0.2034684
[Epoch 11; Iter   180/  201] train: loss: 0.2579798
[Epoch 11] ogbg-moltoxcast: 0.641963 val loss: 0.335045
[Epoch 11] ogbg-moltoxcast: 0.621961 test loss: 0.575928
[Epoch 12; Iter     9/  201] train: loss: 0.1908909
[Epoch 12; Iter    39/  201] train: loss: 0.2247525
[Epoch 12; Iter    69/  201] train: loss: 0.1431478
[Epoch 12; Iter    99/  201] train: loss: 0.2053853
[Epoch 12; Iter   129/  201] train: loss: 0.1917844
[Epoch 12; Iter   159/  201] train: loss: 0.2385899
[Epoch 12; Iter   189/  201] train: loss: 0.1235590
[Epoch 12] ogbg-moltoxcast: 0.653925 val loss: 0.260836
[Epoch 12] ogbg-moltoxcast: 0.639761 test loss: 0.715805
[Epoch 13; Iter    18/  201] train: loss: 0.2224593
[Epoch 13; Iter    48/  201] train: loss: 0.1841304
[ Using Seed :  5  ]
using device:  cuda:1
Log directory:  runs/split/3DInfomax/toxcast/scaff/train_prop=0.7/PNA_ogbg-moltoxcast_3DInfomax_toxcast_scaff=0.7_5_26-05_09-18-14
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/toxcast/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_scaff=0.7
logdir: runs/split/3DInfomax/toxcast/scaff/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  201] train: loss: 0.6931477
[Epoch 1; Iter    60/  201] train: loss: 0.6931397
[Epoch 1; Iter    90/  201] train: loss: 0.6930625
[Epoch 1; Iter   120/  201] train: loss: 0.6930983
[Epoch 1; Iter   150/  201] train: loss: 0.6931506
[Epoch 1; Iter   180/  201] train: loss: 0.6931610
[Epoch 1] ogbg-moltoxcast: 0.499479 val loss: 0.693070
[Epoch 1] ogbg-moltoxcast: 0.505926 test loss: 0.693058
[Epoch 2; Iter     9/  201] train: loss: 0.6931227
[Epoch 2; Iter    39/  201] train: loss: 0.6931149
[Epoch 2; Iter    69/  201] train: loss: 0.6930809
[Epoch 2; Iter    99/  201] train: loss: 0.6930507
[Epoch 2; Iter   129/  201] train: loss: 0.6930755
[Epoch 2; Iter   159/  201] train: loss: 0.6930950
[Epoch 2; Iter   189/  201] train: loss: 0.6930457
[Epoch 2] ogbg-moltoxcast: 0.501669 val loss: 0.692947
[Epoch 2] ogbg-moltoxcast: 0.506434 test loss: 0.692943
[Epoch 3; Iter    18/  201] train: loss: 0.6930293
[Epoch 3; Iter    48/  201] train: loss: 0.6929899
[Epoch 3; Iter    78/  201] train: loss: 0.6929682
[Epoch 3; Iter   108/  201] train: loss: 0.6928618
[Epoch 3; Iter   138/  201] train: loss: 0.6929758
[Epoch 3; Iter   168/  201] train: loss: 0.6927312
[Epoch 3; Iter   198/  201] train: loss: 0.6927755
[Epoch 3] ogbg-moltoxcast: 0.501011 val loss: 0.692758
[Epoch 3] ogbg-moltoxcast: 0.506928 test loss: 0.692760
[Epoch 4; Iter    27/  201] train: loss: 0.6928044
[Epoch 4; Iter    57/  201] train: loss: 0.6928706
[Epoch 4; Iter    87/  201] train: loss: 0.6926804
[Epoch 4; Iter   117/  201] train: loss: 0.6900803
[Epoch 4; Iter   147/  201] train: loss: 0.6689004
[Epoch 4; Iter   177/  201] train: loss: 0.6421003
[Epoch 4] ogbg-moltoxcast: 0.579002 val loss: 0.719062
[Epoch 4] ogbg-moltoxcast: 0.559277 test loss: 0.729037
[Epoch 5; Iter     6/  201] train: loss: 0.6115545
[Epoch 5; Iter    36/  201] train: loss: 0.5624492
[Epoch 5; Iter    66/  201] train: loss: 0.5139093
[Epoch 5; Iter    96/  201] train: loss: 0.4234719
[Epoch 5; Iter   126/  201] train: loss: 0.4264149
[Epoch 5; Iter   156/  201] train: loss: 0.3268250
[Epoch 5; Iter   186/  201] train: loss: 0.2765487
[Epoch 5] ogbg-moltoxcast: 0.601204 val loss: 0.368770
[Epoch 5] ogbg-moltoxcast: 0.563490 test loss: 0.404752
[Epoch 6; Iter    15/  201] train: loss: 0.2363212
[Epoch 6; Iter    45/  201] train: loss: 0.2438973
[Epoch 6; Iter    75/  201] train: loss: 0.2027809
[Epoch 6; Iter   105/  201] train: loss: 0.2130247
[Epoch 6; Iter   135/  201] train: loss: 0.1890179
[Epoch 6; Iter   165/  201] train: loss: 0.1970520
[Epoch 6; Iter   195/  201] train: loss: 0.2685313
[Epoch 6] ogbg-moltoxcast: 0.629079 val loss: 0.265314
[Epoch 6] ogbg-moltoxcast: 0.600698 test loss: 0.299569
[Epoch 7; Iter    24/  201] train: loss: 0.1749841
[Epoch 7; Iter    54/  201] train: loss: 0.2428146
[Epoch 7; Iter    84/  201] train: loss: 0.2543885
[Epoch 7; Iter   114/  201] train: loss: 0.2546221
[Epoch 7; Iter   144/  201] train: loss: 0.2451433
[Epoch 7; Iter   174/  201] train: loss: 0.1779761
[Epoch 7] ogbg-moltoxcast: 0.630800 val loss: 0.262370
[Epoch 7] ogbg-moltoxcast: 0.611908 test loss: 0.293904
[Epoch 8; Iter     3/  201] train: loss: 0.1774119
[Epoch 8; Iter    33/  201] train: loss: 0.1884917
[Epoch 8; Iter    63/  201] train: loss: 0.2717349
[Epoch 8; Iter    93/  201] train: loss: 0.2280590
[Epoch 8; Iter   123/  201] train: loss: 0.2328560
[Epoch 8; Iter   153/  201] train: loss: 0.1467999
[Epoch 8; Iter   183/  201] train: loss: 0.1602377
[Epoch 8] ogbg-moltoxcast: 0.627487 val loss: 0.270013
[Epoch 8] ogbg-moltoxcast: 0.606715 test loss: 0.323290
[Epoch 9; Iter    12/  201] train: loss: 0.1304741
[Epoch 9; Iter    42/  201] train: loss: 0.2959827
[Epoch 9; Iter    72/  201] train: loss: 0.2461743
[Epoch 9; Iter   102/  201] train: loss: 0.2159240
[Epoch 9; Iter   132/  201] train: loss: 0.1737328
[Epoch 9; Iter   162/  201] train: loss: 0.1773140
[Epoch 9; Iter   192/  201] train: loss: 0.1952624
[Epoch 9] ogbg-moltoxcast: 0.625012 val loss: 0.283618
[Epoch 9] ogbg-moltoxcast: 0.610576 test loss: 0.320161
[Epoch 10; Iter    21/  201] train: loss: 0.2127047
[Epoch 10; Iter    51/  201] train: loss: 0.1451973
[Epoch 10; Iter    81/  201] train: loss: 0.1584763
[Epoch 10; Iter   111/  201] train: loss: 0.1653498
[Epoch 10; Iter   141/  201] train: loss: 0.1468356
[Epoch 10; Iter   171/  201] train: loss: 0.2133586
[Epoch 10; Iter   201/  201] train: loss: 0.2591564
[Epoch 10] ogbg-moltoxcast: 0.645326 val loss: 0.263561
[Epoch 10] ogbg-moltoxcast: 0.614045 test loss: 0.303544
[Epoch 11; Iter    30/  201] train: loss: 0.2774233
[Epoch 11; Iter    60/  201] train: loss: 0.1704350
[Epoch 11; Iter    90/  201] train: loss: 0.1934844
[Epoch 11; Iter   120/  201] train: loss: 0.1031568
[Epoch 11; Iter   150/  201] train: loss: 0.1981769
[Epoch 11; Iter   180/  201] train: loss: 0.1488385
[Epoch 11] ogbg-moltoxcast: 0.658415 val loss: 0.264039
[Epoch 11] ogbg-moltoxcast: 0.624242 test loss: 0.307540
[Epoch 12; Iter     9/  201] train: loss: 0.1765817
[Epoch 12; Iter    39/  201] train: loss: 0.2026534
[Epoch 12; Iter    69/  201] train: loss: 0.1535020
[Epoch 12; Iter    99/  201] train: loss: 0.1284997
[Epoch 12; Iter   129/  201] train: loss: 0.1455608
[Epoch 12; Iter   159/  201] train: loss: 0.1808739
[Epoch 12; Iter   189/  201] train: loss: 0.1548777
[Epoch 12] ogbg-moltoxcast: 0.657787 val loss: 0.279497
[Epoch 12] ogbg-moltoxcast: 0.637497 test loss: 0.324233
[Epoch 13; Iter    18/  201] train: loss: 0.1255042
[Epoch 13; Iter    48/  201] train: loss: 0.1695654
[ Using Seed :  6  ]
using device:  cuda:0
Log directory:  runs/split/3DInfomax/toxcast/scaff/train_prop=0.6/PNA_ogbg-moltoxcast_3DInfomax_toxcast_scaff=0.6_6_26-05_09-18-15
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/toxcast/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_scaff=0.6
logdir: runs/split/3DInfomax/toxcast/scaff/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  172] train: loss: 0.6931700
[Epoch 1; Iter    60/  172] train: loss: 0.6931667
[Epoch 1; Iter    90/  172] train: loss: 0.6931286
[Epoch 1; Iter   120/  172] train: loss: 0.6931568
[Epoch 1; Iter   150/  172] train: loss: 0.6930514
[Epoch 1] ogbg-moltoxcast: 0.499573 val loss: 0.693149
[Epoch 1] ogbg-moltoxcast: 0.504549 test loss: 0.693165
[Epoch 2; Iter     8/  172] train: loss: 0.6931760
[Epoch 2; Iter    38/  172] train: loss: 0.6931744
[Epoch 2; Iter    68/  172] train: loss: 0.6931177
[Epoch 2; Iter    98/  172] train: loss: 0.6930615
[Epoch 2; Iter   128/  172] train: loss: 0.6930640
[Epoch 2; Iter   158/  172] train: loss: 0.6930938
[Epoch 2] ogbg-moltoxcast: 0.498617 val loss: 0.693083
[Epoch 2] ogbg-moltoxcast: 0.503868 test loss: 0.693095
[Epoch 3; Iter    16/  172] train: loss: 0.6930535
[Epoch 3; Iter    46/  172] train: loss: 0.6930997
[Epoch 3; Iter    76/  172] train: loss: 0.6930373
[Epoch 3; Iter   106/  172] train: loss: 0.6930082
[Epoch 3; Iter   136/  172] train: loss: 0.6929784
[Epoch 3; Iter   166/  172] train: loss: 0.6930401
[Epoch 3] ogbg-moltoxcast: 0.498625 val loss: 0.692987
[Epoch 3] ogbg-moltoxcast: 0.504688 test loss: 0.693003
[Epoch 4; Iter    24/  172] train: loss: 0.6928762
[Epoch 4; Iter    54/  172] train: loss: 0.6929187
[Epoch 4; Iter    84/  172] train: loss: 0.6929795
[Epoch 4; Iter   114/  172] train: loss: 0.6928329
[Epoch 4; Iter   144/  172] train: loss: 0.6929299
[Epoch 4] ogbg-moltoxcast: 0.498651 val loss: 0.692850
[Epoch 4] ogbg-moltoxcast: 0.504002 test loss: 0.692868
[Epoch 5; Iter     2/  172] train: loss: 0.6928361
[Epoch 5; Iter    32/  172] train: loss: 0.6893982
[Epoch 5; Iter    62/  172] train: loss: 0.6727195
[Epoch 5; Iter    92/  172] train: loss: 0.6317225
[Epoch 5; Iter   122/  172] train: loss: 0.6244318
[Epoch 5; Iter   152/  172] train: loss: 0.5674757
[Epoch 5] ogbg-moltoxcast: 0.590848 val loss: 0.799292
[Epoch 5] ogbg-moltoxcast: 0.567200 test loss: 0.862617
[Epoch 6; Iter    10/  172] train: loss: 0.5071920
[Epoch 6; Iter    40/  172] train: loss: 0.4840398
[Epoch 6; Iter    70/  172] train: loss: 0.4082601
[Epoch 6; Iter   100/  172] train: loss: 0.3145817
[Epoch 6; Iter   130/  172] train: loss: 0.3204888
[Epoch 6; Iter   160/  172] train: loss: 0.2510276
[Epoch 6] ogbg-moltoxcast: 0.576171 val loss: 0.349797
[Epoch 6] ogbg-moltoxcast: 0.537392 test loss: 0.430744
[Epoch 7; Iter    18/  172] train: loss: 0.2288828
[Epoch 7; Iter    48/  172] train: loss: 0.2438694
[Epoch 7; Iter    78/  172] train: loss: 0.1948698
[Epoch 7; Iter   108/  172] train: loss: 0.2078660
[Epoch 7; Iter   138/  172] train: loss: 0.2518977
[Epoch 7; Iter   168/  172] train: loss: 0.1295207
[Epoch 7] ogbg-moltoxcast: 0.641485 val loss: 0.281795
[Epoch 7] ogbg-moltoxcast: 0.594490 test loss: 0.341581
[Epoch 8; Iter    26/  172] train: loss: 0.2261470
[Epoch 8; Iter    56/  172] train: loss: 0.1864713
[Epoch 8; Iter    86/  172] train: loss: 0.1161548
[Epoch 8; Iter   116/  172] train: loss: 0.1563147
[Epoch 8; Iter   146/  172] train: loss: 0.1486837
[Epoch 8] ogbg-moltoxcast: 0.644888 val loss: 0.283410
[Epoch 8] ogbg-moltoxcast: 0.597712 test loss: 0.340076
[Epoch 9; Iter     4/  172] train: loss: 0.2774563
[Epoch 9; Iter    34/  172] train: loss: 0.1214978
[Epoch 9; Iter    64/  172] train: loss: 0.1782630
[Epoch 9; Iter    94/  172] train: loss: 0.2507934
[Epoch 9; Iter   124/  172] train: loss: 0.1999871
[Epoch 9; Iter   154/  172] train: loss: 0.1687275
[Epoch 9] ogbg-moltoxcast: 0.664783 val loss: 0.285950
[Epoch 9] ogbg-moltoxcast: 0.602814 test loss: 0.366013
[Epoch 10; Iter    12/  172] train: loss: 0.2091468
[Epoch 10; Iter    42/  172] train: loss: 0.1774957
[Epoch 10; Iter    72/  172] train: loss: 0.2288566
[Epoch 10; Iter   102/  172] train: loss: 0.2624189
[Epoch 10; Iter   132/  172] train: loss: 0.2053386
[Epoch 10; Iter   162/  172] train: loss: 0.1665864
[Epoch 10] ogbg-moltoxcast: 0.630577 val loss: 0.276955
[Epoch 10] ogbg-moltoxcast: 0.604943 test loss: 0.322420
[Epoch 11; Iter    20/  172] train: loss: 0.2261814
[Epoch 11; Iter    50/  172] train: loss: 0.1769548
[Epoch 11; Iter    80/  172] train: loss: 0.1797951
[Epoch 11; Iter   110/  172] train: loss: 0.1575774
[Epoch 11; Iter   140/  172] train: loss: 0.2367588
[Epoch 11; Iter   170/  172] train: loss: 0.1467733
[Epoch 11] ogbg-moltoxcast: 0.665867 val loss: 0.263134
[Epoch 11] ogbg-moltoxcast: 0.619841 test loss: 0.311667
[Epoch 12; Iter    28/  172] train: loss: 0.2181028
[Epoch 12; Iter    58/  172] train: loss: 0.2723539
[Epoch 12; Iter    88/  172] train: loss: 0.1668069
[Epoch 12; Iter   118/  172] train: loss: 0.1545203
[Epoch 12; Iter   148/  172] train: loss: 0.1998160
[Epoch 12] ogbg-moltoxcast: 0.670312 val loss: 0.269614
[Epoch 12] ogbg-moltoxcast: 0.615794 test loss: 0.353201
[Epoch 13; Iter     6/  172] train: loss: 0.1953368
[Epoch 13; Iter    36/  172] train: loss: 0.2467407
[Epoch 13; Iter    66/  172] train: loss: 0.1787355
[Epoch 13; Iter    96/  172] train: loss: 0.1548886
[Epoch 13; Iter   126/  172] train: loss: 0.1448053
[Epoch 13; Iter   156/  172] train: loss: 0.1453286
[Epoch 13] ogbg-moltoxcast: 0.673729 val loss: 0.258266
[Epoch 13] ogbg-moltoxcast: 0.620413 test loss: 0.322990
[Epoch 14; Iter    14/  172] train: loss: 0.1321127
[Epoch 14; Iter    44/  172] train: loss: 0.1644667
[Epoch 14; Iter    74/  172] train: loss: 0.1597274
[Epoch 14; Iter   104/  172] train: loss: 0.1763526
[Epoch 14; Iter   134/  172] train: loss: 0.1523325
[Epoch 14; Iter   164/  172] train: loss: 0.2235186[ Using Seed :  4  ]
using device:  cuda:0
Log directory:  runs/split/3DInfomax/toxcast/scaff/train_prop=0.6/PNA_ogbg-moltoxcast_3DInfomax_toxcast_scaff=0.6_4_26-05_09-18-14
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/toxcast/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_scaff=0.6
logdir: runs/split/3DInfomax/toxcast/scaff/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  172] train: loss: 0.6931692
[Epoch 1; Iter    60/  172] train: loss: 0.6931961
[Epoch 1; Iter    90/  172] train: loss: 0.6931525
[Epoch 1; Iter   120/  172] train: loss: 0.6931477
[Epoch 1; Iter   150/  172] train: loss: 0.6931518
[Epoch 1] ogbg-moltoxcast: 0.496207 val loss: 0.693118
[Epoch 1] ogbg-moltoxcast: 0.498936 test loss: 0.693158
[Epoch 2; Iter     8/  172] train: loss: 0.6931201
[Epoch 2; Iter    38/  172] train: loss: 0.6931651
[Epoch 2; Iter    68/  172] train: loss: 0.6931372
[Epoch 2; Iter    98/  172] train: loss: 0.6931100
[Epoch 2; Iter   128/  172] train: loss: 0.6930715
[Epoch 2; Iter   158/  172] train: loss: 0.6930743
[Epoch 2] ogbg-moltoxcast: 0.495631 val loss: 0.693085
[Epoch 2] ogbg-moltoxcast: 0.498616 test loss: 0.693125
[Epoch 3; Iter    16/  172] train: loss: 0.6930436
[Epoch 3; Iter    46/  172] train: loss: 0.6930583
[Epoch 3; Iter    76/  172] train: loss: 0.6931252
[Epoch 3; Iter   106/  172] train: loss: 0.6929758
[Epoch 3; Iter   136/  172] train: loss: 0.6930455
[Epoch 3; Iter   166/  172] train: loss: 0.6930017
[Epoch 3] ogbg-moltoxcast: 0.496473 val loss: 0.693001
[Epoch 3] ogbg-moltoxcast: 0.499294 test loss: 0.693047
[Epoch 4; Iter    24/  172] train: loss: 0.6929757
[Epoch 4; Iter    54/  172] train: loss: 0.6929340
[Epoch 4; Iter    84/  172] train: loss: 0.6928214
[Epoch 4; Iter   114/  172] train: loss: 0.6929610
[Epoch 4; Iter   144/  172] train: loss: 0.6928568
[Epoch 4] ogbg-moltoxcast: 0.496644 val loss: 0.692868
[Epoch 4] ogbg-moltoxcast: 0.499337 test loss: 0.692919
[Epoch 5; Iter     2/  172] train: loss: 0.6928873
[Epoch 5; Iter    32/  172] train: loss: 0.6902369
[Epoch 5; Iter    62/  172] train: loss: 0.6734524
[Epoch 5; Iter    92/  172] train: loss: 0.6473625
[Epoch 5; Iter   122/  172] train: loss: 0.6159148
[Epoch 5; Iter   152/  172] train: loss: 0.5710424
[Epoch 5] ogbg-moltoxcast: 0.583367 val loss: 0.645492
[Epoch 5] ogbg-moltoxcast: 0.558017 test loss: 0.676891
[Epoch 6; Iter    10/  172] train: loss: 0.5067384
[Epoch 6; Iter    40/  172] train: loss: 0.4755147
[Epoch 6; Iter    70/  172] train: loss: 0.4035341
[Epoch 6; Iter   100/  172] train: loss: 0.3556499
[Epoch 6; Iter   130/  172] train: loss: 0.3004720
[Epoch 6; Iter   160/  172] train: loss: 0.2358062
[Epoch 6] ogbg-moltoxcast: 0.615111 val loss: 0.331188
[Epoch 6] ogbg-moltoxcast: 0.566775 test loss: 0.360218
[Epoch 7; Iter    18/  172] train: loss: 0.2627079
[Epoch 7; Iter    48/  172] train: loss: 0.2442823
[Epoch 7; Iter    78/  172] train: loss: 0.1747592
[Epoch 7; Iter   108/  172] train: loss: 0.3286450
[Epoch 7; Iter   138/  172] train: loss: 0.1860238
[Epoch 7; Iter   168/  172] train: loss: 0.2204819
[Epoch 7] ogbg-moltoxcast: 0.611145 val loss: 0.296395
[Epoch 7] ogbg-moltoxcast: 0.573414 test loss: 0.346013
[Epoch 8; Iter    26/  172] train: loss: 0.2028875
[Epoch 8; Iter    56/  172] train: loss: 0.1991134
[Epoch 8; Iter    86/  172] train: loss: 0.1774491
[Epoch 8; Iter   116/  172] train: loss: 0.1715116
[Epoch 8; Iter   146/  172] train: loss: 0.2670805
[Epoch 8] ogbg-moltoxcast: 0.648785 val loss: 0.267971
[Epoch 8] ogbg-moltoxcast: 0.591444 test loss: 0.329153
[Epoch 9; Iter     4/  172] train: loss: 0.1171785
[Epoch 9; Iter    34/  172] train: loss: 0.2578481
[Epoch 9; Iter    64/  172] train: loss: 0.1629304
[Epoch 9; Iter    94/  172] train: loss: 0.1680748
[Epoch 9; Iter   124/  172] train: loss: 0.2216757
[Epoch 9; Iter   154/  172] train: loss: 0.2338394
[Epoch 9] ogbg-moltoxcast: 0.616353 val loss: 0.276571
[Epoch 9] ogbg-moltoxcast: 0.572681 test loss: 0.339577
[Epoch 10; Iter    12/  172] train: loss: 0.1738061
[Epoch 10; Iter    42/  172] train: loss: 0.2332056
[Epoch 10; Iter    72/  172] train: loss: 0.2021857
[Epoch 10; Iter   102/  172] train: loss: 0.1507104
[Epoch 10; Iter   132/  172] train: loss: 0.2410191
[Epoch 10; Iter   162/  172] train: loss: 0.1670689
[Epoch 10] ogbg-moltoxcast: 0.599623 val loss: 0.285967
[Epoch 10] ogbg-moltoxcast: 0.565579 test loss: 0.335344
[Epoch 11; Iter    20/  172] train: loss: 0.1750664
[Epoch 11; Iter    50/  172] train: loss: 0.1960780
[Epoch 11; Iter    80/  172] train: loss: 0.2000316
[Epoch 11; Iter   110/  172] train: loss: 0.2152891
[Epoch 11; Iter   140/  172] train: loss: 0.2294074
[Epoch 11; Iter   170/  172] train: loss: 0.1395064
[Epoch 11] ogbg-moltoxcast: 0.657813 val loss: 0.265244
[Epoch 11] ogbg-moltoxcast: 0.616548 test loss: 0.319279
[Epoch 12; Iter    28/  172] train: loss: 0.1424483
[Epoch 12; Iter    58/  172] train: loss: 0.1263165
[Epoch 12; Iter    88/  172] train: loss: 0.2212201
[Epoch 12; Iter   118/  172] train: loss: 0.1852688
[Epoch 12; Iter   148/  172] train: loss: 0.2212671
[Epoch 12] ogbg-moltoxcast: 0.653347 val loss: 0.266298
[Epoch 12] ogbg-moltoxcast: 0.593981 test loss: 0.313181
[Epoch 13; Iter     6/  172] train: loss: 0.2026406
[Epoch 13; Iter    36/  172] train: loss: 0.1657812
[Epoch 13; Iter    66/  172] train: loss: 0.2200558
[Epoch 13; Iter    96/  172] train: loss: 0.1743215
[Epoch 13; Iter   126/  172] train: loss: 0.1056292
[Epoch 13; Iter   156/  172] train: loss: 0.1619301
[Epoch 13] ogbg-moltoxcast: 0.632725 val loss: 0.355211
[Epoch 13] ogbg-moltoxcast: 0.586593 test loss: 0.440135
[Epoch 14; Iter    14/  172] train: loss: 0.1550668
[Epoch 14; Iter    44/  172] train: loss: 0.1621910
[Epoch 14; Iter    74/  172] train: loss: 0.1597313
[Epoch 14; Iter   104/  172] train: loss: 0.1042100
[Epoch 14; Iter   134/  172] train: loss: 0.2482550
[Epoch 14; Iter   164/  172] train: loss: 0.1702819[ Using Seed :  5  ]
using device:  cuda:0
Log directory:  runs/split/3DInfomax/toxcast/scaff/train_prop=0.6/PNA_ogbg-moltoxcast_3DInfomax_toxcast_scaff=0.6_5_26-05_09-18-15
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/toxcast/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_scaff=0.6
logdir: runs/split/3DInfomax/toxcast/scaff/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  172] train: loss: 0.6931472
[Epoch 1; Iter    60/  172] train: loss: 0.6931545
[Epoch 1; Iter    90/  172] train: loss: 0.6932083
[Epoch 1; Iter   120/  172] train: loss: 0.6932214
[Epoch 1; Iter   150/  172] train: loss: 0.6931341
[Epoch 1] ogbg-moltoxcast: 0.500601 val loss: 0.693042
[Epoch 1] ogbg-moltoxcast: 0.506693 test loss: 0.693038
[Epoch 2; Iter     8/  172] train: loss: 0.6931388
[Epoch 2; Iter    38/  172] train: loss: 0.6931550
[Epoch 2; Iter    68/  172] train: loss: 0.6930550
[Epoch 2; Iter    98/  172] train: loss: 0.6931044
[Epoch 2; Iter   128/  172] train: loss: 0.6930868
[Epoch 2; Iter   158/  172] train: loss: 0.6930407
[Epoch 2] ogbg-moltoxcast: 0.500120 val loss: 0.692988
[Epoch 2] ogbg-moltoxcast: 0.505720 test loss: 0.692991
[Epoch 3; Iter    16/  172] train: loss: 0.6929574
[Epoch 3; Iter    46/  172] train: loss: 0.6930544
[Epoch 3; Iter    76/  172] train: loss: 0.6930085
[Epoch 3; Iter   106/  172] train: loss: 0.6929851
[Epoch 3; Iter   136/  172] train: loss: 0.6928933
[Epoch 3; Iter   166/  172] train: loss: 0.6929333
[Epoch 3] ogbg-moltoxcast: 0.501436 val loss: 0.692844
[Epoch 3] ogbg-moltoxcast: 0.506777 test loss: 0.692844
[Epoch 4; Iter    24/  172] train: loss: 0.6929512
[Epoch 4; Iter    54/  172] train: loss: 0.6928070
[Epoch 4; Iter    84/  172] train: loss: 0.6928403
[Epoch 4; Iter   114/  172] train: loss: 0.6927904
[Epoch 4; Iter   144/  172] train: loss: 0.6928814
[Epoch 4] ogbg-moltoxcast: 0.501551 val loss: 0.692671
[Epoch 4] ogbg-moltoxcast: 0.508065 test loss: 0.692673
[Epoch 5; Iter     2/  172] train: loss: 0.6927867
[Epoch 5; Iter    32/  172] train: loss: 0.6894829
[Epoch 5; Iter    62/  172] train: loss: 0.6686968
[Epoch 5; Iter    92/  172] train: loss: 0.6392679
[Epoch 5; Iter   122/  172] train: loss: 0.6048712
[Epoch 5; Iter   152/  172] train: loss: 0.5961457
[Epoch 5] ogbg-moltoxcast: 0.594517 val loss: 0.703214
[Epoch 5] ogbg-moltoxcast: 0.570765 test loss: 0.758942
[Epoch 6; Iter    10/  172] train: loss: 0.4785360
[Epoch 6; Iter    40/  172] train: loss: 0.4392312
[Epoch 6; Iter    70/  172] train: loss: 0.3728944
[Epoch 6; Iter   100/  172] train: loss: 0.3622099
[Epoch 6; Iter   130/  172] train: loss: 0.3130246
[Epoch 6; Iter   160/  172] train: loss: 0.2377215
[Epoch 6] ogbg-moltoxcast: 0.628944 val loss: 0.332453
[Epoch 6] ogbg-moltoxcast: 0.567613 test loss: 0.371113
[Epoch 7; Iter    18/  172] train: loss: 0.2353648
[Epoch 7; Iter    48/  172] train: loss: 0.2415763
[Epoch 7; Iter    78/  172] train: loss: 0.2143677
[Epoch 7; Iter   108/  172] train: loss: 0.2652431
[Epoch 7; Iter   138/  172] train: loss: 0.1894261
[Epoch 7; Iter   168/  172] train: loss: 0.1564374
[Epoch 7] ogbg-moltoxcast: 0.647141 val loss: 0.279938
[Epoch 7] ogbg-moltoxcast: 0.588739 test loss: 0.315222
[Epoch 8; Iter    26/  172] train: loss: 0.2003192
[Epoch 8; Iter    56/  172] train: loss: 0.1407207
[Epoch 8; Iter    86/  172] train: loss: 0.1553888
[Epoch 8; Iter   116/  172] train: loss: 0.2640887
[Epoch 8; Iter   146/  172] train: loss: 0.1614975
[Epoch 8] ogbg-moltoxcast: 0.633894 val loss: 0.301148
[Epoch 8] ogbg-moltoxcast: 0.598870 test loss: 0.315286
[Epoch 9; Iter     4/  172] train: loss: 0.2012529
[Epoch 9; Iter    34/  172] train: loss: 0.2090890
[Epoch 9; Iter    64/  172] train: loss: 0.1403386
[Epoch 9; Iter    94/  172] train: loss: 0.2464580
[Epoch 9; Iter   124/  172] train: loss: 0.1910416
[Epoch 9; Iter   154/  172] train: loss: 0.2424593
[Epoch 9] ogbg-moltoxcast: 0.599014 val loss: 0.301828
[Epoch 9] ogbg-moltoxcast: 0.586849 test loss: 0.344337
[Epoch 10; Iter    12/  172] train: loss: 0.2176273
[Epoch 10; Iter    42/  172] train: loss: 0.2025657
[Epoch 10; Iter    72/  172] train: loss: 0.2044164
[Epoch 10; Iter   102/  172] train: loss: 0.2534487
[Epoch 10; Iter   132/  172] train: loss: 0.1659643
[Epoch 10; Iter   162/  172] train: loss: 0.1702277
[Epoch 10] ogbg-moltoxcast: 0.648903 val loss: 0.263006
[Epoch 10] ogbg-moltoxcast: 0.621244 test loss: 0.418410
[Epoch 11; Iter    20/  172] train: loss: 0.2057745
[Epoch 11; Iter    50/  172] train: loss: 0.1753908
[Epoch 11; Iter    80/  172] train: loss: 0.1991578
[Epoch 11; Iter   110/  172] train: loss: 0.1554626
[Epoch 11; Iter   140/  172] train: loss: 0.1804584
[Epoch 11; Iter   170/  172] train: loss: 0.1990475
[Epoch 11] ogbg-moltoxcast: 0.646533 val loss: 0.270829
[Epoch 11] ogbg-moltoxcast: 0.606636 test loss: 0.351777
[Epoch 12; Iter    28/  172] train: loss: 0.1270824
[Epoch 12; Iter    58/  172] train: loss: 0.2154685
[Epoch 12; Iter    88/  172] train: loss: 0.1125991
[Epoch 12; Iter   118/  172] train: loss: 0.1279520
[Epoch 12; Iter   148/  172] train: loss: 0.2189534
[Epoch 12] ogbg-moltoxcast: 0.649892 val loss: 0.268389
[Epoch 12] ogbg-moltoxcast: 0.606862 test loss: 0.313878
[Epoch 13; Iter     6/  172] train: loss: 0.1728027
[Epoch 13; Iter    36/  172] train: loss: 0.2482625
[Epoch 13; Iter    66/  172] train: loss: 0.1929238
[Epoch 13; Iter    96/  172] train: loss: 0.2322394
[Epoch 13; Iter   126/  172] train: loss: 0.1527495
[Epoch 13; Iter   156/  172] train: loss: 0.1299468
[Epoch 13] ogbg-moltoxcast: 0.649275 val loss: 0.273147
[Epoch 13] ogbg-moltoxcast: 0.613615 test loss: 0.326390
[Epoch 14; Iter    14/  172] train: loss: 0.1654081
[Epoch 14; Iter    44/  172] train: loss: 0.1825924
[Epoch 14; Iter    74/  172] train: loss: 0.1608674
[Epoch 14; Iter   104/  172] train: loss: 0.1654995
[Epoch 14; Iter   134/  172] train: loss: 0.1686742
[Epoch 14; Iter   164/  172] train: loss: 0.2116007[Epoch 12; Iter    31/  229] train: loss: 0.2007382
[Epoch 12; Iter    61/  229] train: loss: 0.1673197
[Epoch 12; Iter    91/  229] train: loss: 0.1543065
[Epoch 12; Iter   121/  229] train: loss: 0.3532020
[Epoch 12; Iter   151/  229] train: loss: 0.2008342
[Epoch 12; Iter   181/  229] train: loss: 0.2175816
[Epoch 12; Iter   211/  229] train: loss: 0.3208523
[Epoch 12] ogbg-moltoxcast: 0.675698 val loss: 0.258676
[Epoch 12] ogbg-moltoxcast: 0.644608 test loss: 0.385292
[Epoch 13; Iter    12/  229] train: loss: 0.2292189
[Epoch 13; Iter    42/  229] train: loss: 0.1812212
[Epoch 13; Iter    72/  229] train: loss: 0.1836475
[Epoch 13; Iter   102/  229] train: loss: 0.2250268
[Epoch 13; Iter   132/  229] train: loss: 0.1354567
[Epoch 13; Iter   162/  229] train: loss: 0.2290454
[Epoch 13; Iter   192/  229] train: loss: 0.1358550
[Epoch 13; Iter   222/  229] train: loss: 0.1864329
[Epoch 13] ogbg-moltoxcast: 0.683505 val loss: 0.257924
[Epoch 13] ogbg-moltoxcast: 0.629605 test loss: 0.382772
[Epoch 14; Iter    23/  229] train: loss: 0.1786875
[Epoch 14; Iter    53/  229] train: loss: 0.1477623
[Epoch 14; Iter    83/  229] train: loss: 0.1762610
[Epoch 14; Iter   113/  229] train: loss: 0.1487720
[Epoch 14; Iter   143/  229] train: loss: 0.2702462
[Epoch 14; Iter   173/  229] train: loss: 0.1277969
[Epoch 14; Iter   203/  229] train: loss: 0.1913571
[Epoch 14] ogbg-moltoxcast: 0.692302 val loss: 0.316794
[Epoch 14] ogbg-moltoxcast: 0.640922 test loss: 0.323408
[Epoch 15; Iter     4/  229] train: loss: 0.1615789
[Epoch 15; Iter    34/  229] train: loss: 0.2446562
[Epoch 15; Iter    64/  229] train: loss: 0.1900892
[Epoch 15; Iter    94/  229] train: loss: 0.1718556
[Epoch 15; Iter   124/  229] train: loss: 0.1359981
[Epoch 15; Iter   154/  229] train: loss: 0.2166224
[Epoch 15; Iter   184/  229] train: loss: 0.1660468
[Epoch 15; Iter   214/  229] train: loss: 0.1261993
[Epoch 15] ogbg-moltoxcast: 0.680261 val loss: 0.257235
[Epoch 15] ogbg-moltoxcast: 0.650821 test loss: 0.325449
[Epoch 16; Iter    15/  229] train: loss: 0.1999948
[Epoch 16; Iter    45/  229] train: loss: 0.1222343
[Epoch 16; Iter    75/  229] train: loss: 0.1735404
[Epoch 16; Iter   105/  229] train: loss: 0.1497072
[Epoch 16; Iter   135/  229] train: loss: 0.1718704
[Epoch 16; Iter   165/  229] train: loss: 0.1295434
[Epoch 16; Iter   195/  229] train: loss: 0.1568273
[Epoch 16; Iter   225/  229] train: loss: 0.2137468
[Epoch 16] ogbg-moltoxcast: 0.658569 val loss: 0.259151
[Epoch 16] ogbg-moltoxcast: 0.643344 test loss: 0.376373
[Epoch 17; Iter    26/  229] train: loss: 0.1628953
[Epoch 17; Iter    56/  229] train: loss: 0.1066003
[Epoch 17; Iter    86/  229] train: loss: 0.2319468
[Epoch 17; Iter   116/  229] train: loss: 0.2022229
[Epoch 17; Iter   146/  229] train: loss: 0.1779830
[Epoch 17; Iter   176/  229] train: loss: 0.2428921
[Epoch 17; Iter   206/  229] train: loss: 0.1462208
[Epoch 17] ogbg-moltoxcast: 0.679881 val loss: 0.246749
[Epoch 17] ogbg-moltoxcast: 0.641934 test loss: 0.289975
[Epoch 18; Iter     7/  229] train: loss: 0.1693438
[Epoch 18; Iter    37/  229] train: loss: 0.1917929
[Epoch 18; Iter    67/  229] train: loss: 0.1678631
[Epoch 18; Iter    97/  229] train: loss: 0.1335271
[Epoch 18; Iter   127/  229] train: loss: 0.1548674
[Epoch 18; Iter   157/  229] train: loss: 0.1894158
[Epoch 18; Iter   187/  229] train: loss: 0.1651431
[Epoch 18; Iter   217/  229] train: loss: 0.2454378
[Epoch 18] ogbg-moltoxcast: 0.674417 val loss: 0.252098
[Epoch 18] ogbg-moltoxcast: 0.657156 test loss: 0.298960
[Epoch 19; Iter    18/  229] train: loss: 0.1066049
[Epoch 19; Iter    48/  229] train: loss: 0.2101282
[Epoch 19; Iter    78/  229] train: loss: 0.1507247
[Epoch 19; Iter   108/  229] train: loss: 0.1581109
[Epoch 19; Iter   138/  229] train: loss: 0.1929882
[Epoch 19; Iter   168/  229] train: loss: 0.2536812
[Epoch 19; Iter   198/  229] train: loss: 0.1543634
[Epoch 19; Iter   228/  229] train: loss: 0.2020245
[Epoch 19] ogbg-moltoxcast: 0.680117 val loss: 0.256982
[Epoch 19] ogbg-moltoxcast: 0.661937 test loss: 0.296080
[Epoch 20; Iter    29/  229] train: loss: 0.1439648
[Epoch 20; Iter    59/  229] train: loss: 0.1585248
[Epoch 20; Iter    89/  229] train: loss: 0.1953825
[Epoch 20; Iter   119/  229] train: loss: 0.1218407
[Epoch 20; Iter   149/  229] train: loss: 0.1958628
[Epoch 20; Iter   179/  229] train: loss: 0.1844960
[Epoch 20; Iter   209/  229] train: loss: 0.1478062
[Epoch 20] ogbg-moltoxcast: 0.696914 val loss: 0.246250
[Epoch 20] ogbg-moltoxcast: 0.654863 test loss: 0.291469
[Epoch 21; Iter    10/  229] train: loss: 0.1930964
[Epoch 21; Iter    40/  229] train: loss: 0.1369815
[Epoch 21; Iter    70/  229] train: loss: 0.1852321
[Epoch 21; Iter   100/  229] train: loss: 0.1613900
[Epoch 21; Iter   130/  229] train: loss: 0.1942872
[Epoch 21; Iter   160/  229] train: loss: 0.1706649
[Epoch 21; Iter   190/  229] train: loss: 0.1856991
[Epoch 21; Iter   220/  229] train: loss: 0.1399449
[Epoch 21] ogbg-moltoxcast: 0.686991 val loss: 0.248634
[Epoch 21] ogbg-moltoxcast: 0.653416 test loss: 0.294079
[Epoch 22; Iter    21/  229] train: loss: 0.1123079
[Epoch 22; Iter    51/  229] train: loss: 0.2165178
[Epoch 22; Iter    81/  229] train: loss: 0.1338756
[Epoch 22; Iter   111/  229] train: loss: 0.1913882
[Epoch 22; Iter   141/  229] train: loss: 0.1594043
[Epoch 22; Iter   171/  229] train: loss: 0.2052035
[Epoch 22; Iter   201/  229] train: loss: 0.1579872
[Epoch 22] ogbg-moltoxcast: 0.697184 val loss: 0.249448
[Epoch 22] ogbg-moltoxcast: 0.661811 test loss: 0.289591
[Epoch 23; Iter     2/  229] train: loss: 0.1334273
[Epoch 23; Iter    32/  229] train: loss: 0.1577085
[Epoch 23; Iter    62/  229] train: loss: 0.1440805
[Epoch 23; Iter    92/  229] train: loss: 0.1158061
[Epoch 23; Iter   122/  229] train: loss: 0.1439263
[Epoch 23; Iter   152/  229] train: loss: 0.2291654
[Epoch 23; Iter   182/  229] train: loss: 0.1655005
[Epoch 23; Iter   212/  229] train: loss: 0.1375645
[Epoch 23] ogbg-moltoxcast: 0.685643 val loss: 0.258869
[Epoch 23] ogbg-moltoxcast: 0.652828 test loss: 0.308120
[Epoch 24; Iter    13/  229] train: loss: 0.1222173
[Epoch 24; Iter    43/  229] train: loss: 0.1986633
[Epoch 24; Iter    73/  229] train: loss: 0.1159442
[Epoch 24; Iter   103/  229] train: loss: 0.2629160
[Epoch 24; Iter   133/  229] train: loss: 0.1308785
[Epoch 24; Iter   163/  229] train: loss: 0.1334915
[Epoch 24; Iter   193/  229] train: loss: 0.1910657
[Epoch 24; Iter   223/  229] train: loss: 0.1303268
[Epoch 24] ogbg-moltoxcast: 0.688980 val loss: 0.251641
[Epoch 24] ogbg-moltoxcast: 0.659332 test loss: 0.300749
[Epoch 25; Iter    24/  229] train: loss: 0.1078549
[Epoch 25; Iter    54/  229] train: loss: 0.1101586
[Epoch 25; Iter    84/  229] train: loss: 0.1328299
[Epoch 25; Iter   114/  229] train: loss: 0.2342317
[Epoch 25; Iter   144/  229] train: loss: 0.1956033
[Epoch 25; Iter   174/  229] train: loss: 0.1461672
[Epoch 25; Iter   204/  229] train: loss: 0.1303619
[Epoch 25] ogbg-moltoxcast: 0.686738 val loss: 0.245506
[Epoch 25] ogbg-moltoxcast: 0.667460 test loss: 0.285432
[Epoch 26; Iter     5/  229] train: loss: 0.1585633
[Epoch 26; Iter    35/  229] train: loss: 0.1519640
[Epoch 26; Iter    65/  229] train: loss: 0.1979327
[Epoch 26; Iter    95/  229] train: loss: 0.1950569
[Epoch 26; Iter   125/  229] train: loss: 0.2068257
[Epoch 26; Iter   155/  229] train: loss: 0.1540111
[Epoch 26; Iter   185/  229] train: loss: 0.1125027
[Epoch 26; Iter   215/  229] train: loss: 0.1565053
[Epoch 26] ogbg-moltoxcast: 0.692879 val loss: 0.249147
[Epoch 26] ogbg-moltoxcast: 0.664104 test loss: 0.292657
[Epoch 27; Iter    16/  229] train: loss: 0.1144449
[Epoch 27; Iter    46/  229] train: loss: 0.1467837
[Epoch 27; Iter    76/  229] train: loss: 0.1460315
[Epoch 27; Iter   106/  229] train: loss: 0.0956502
[Epoch 27; Iter   136/  229] train: loss: 0.1848004
[Epoch 27; Iter   166/  229] train: loss: 0.1479623
[Epoch 27; Iter   196/  229] train: loss: 0.2187181
[Epoch 27; Iter   226/  229] train: loss: 0.1352014
[Epoch 27] ogbg-moltoxcast: 0.684415 val loss: 0.251368
[Epoch 27] ogbg-moltoxcast: 0.660984 test loss: 0.291569
[Epoch 12; Iter    31/  229] train: loss: 0.2118589
[Epoch 12; Iter    61/  229] train: loss: 0.1467315
[Epoch 12; Iter    91/  229] train: loss: 0.2005523
[Epoch 12; Iter   121/  229] train: loss: 0.2077833
[Epoch 12; Iter   151/  229] train: loss: 0.1265927
[Epoch 12; Iter   181/  229] train: loss: 0.2203169
[Epoch 12; Iter   211/  229] train: loss: 0.1862215
[Epoch 12] ogbg-moltoxcast: 0.675502 val loss: 0.375039
[Epoch 12] ogbg-moltoxcast: 0.645507 test loss: 0.348359
[Epoch 13; Iter    12/  229] train: loss: 0.1455438
[Epoch 13; Iter    42/  229] train: loss: 0.1321454
[Epoch 13; Iter    72/  229] train: loss: 0.1664638
[Epoch 13; Iter   102/  229] train: loss: 0.2591974
[Epoch 13; Iter   132/  229] train: loss: 0.2078002
[Epoch 13; Iter   162/  229] train: loss: 0.1437155
[Epoch 13; Iter   192/  229] train: loss: 0.1865539
[Epoch 13; Iter   222/  229] train: loss: 0.2233900
[Epoch 13] ogbg-moltoxcast: 0.653495 val loss: 0.339716
[Epoch 13] ogbg-moltoxcast: 0.642024 test loss: 0.332631
[Epoch 14; Iter    23/  229] train: loss: 0.1820682
[Epoch 14; Iter    53/  229] train: loss: 0.2162380
[Epoch 14; Iter    83/  229] train: loss: 0.2370409
[Epoch 14; Iter   113/  229] train: loss: 0.1735759
[Epoch 14; Iter   143/  229] train: loss: 0.1831619
[Epoch 14; Iter   173/  229] train: loss: 0.1924773
[Epoch 14; Iter   203/  229] train: loss: 0.1837923
[Epoch 14] ogbg-moltoxcast: 0.673511 val loss: 0.375411
[Epoch 14] ogbg-moltoxcast: 0.653034 test loss: 0.289623
[Epoch 15; Iter     4/  229] train: loss: 0.1730273
[Epoch 15; Iter    34/  229] train: loss: 0.1093547
[Epoch 15; Iter    64/  229] train: loss: 0.1607091
[Epoch 15; Iter    94/  229] train: loss: 0.2792548
[Epoch 15; Iter   124/  229] train: loss: 0.1580409
[Epoch 15; Iter   154/  229] train: loss: 0.1647048
[Epoch 15; Iter   184/  229] train: loss: 0.1573270
[Epoch 15; Iter   214/  229] train: loss: 0.2081334
[Epoch 15] ogbg-moltoxcast: 0.673343 val loss: 0.288070
[Epoch 15] ogbg-moltoxcast: 0.652850 test loss: 0.296245
[Epoch 16; Iter    15/  229] train: loss: 0.2500049
[Epoch 16; Iter    45/  229] train: loss: 0.1430530
[Epoch 16; Iter    75/  229] train: loss: 0.1191725
[Epoch 16; Iter   105/  229] train: loss: 0.1536439
[Epoch 16; Iter   135/  229] train: loss: 0.1573121
[Epoch 16; Iter   165/  229] train: loss: 0.1868204
[Epoch 16; Iter   195/  229] train: loss: 0.2152833
[Epoch 16; Iter   225/  229] train: loss: 0.1591581
[Epoch 16] ogbg-moltoxcast: 0.676597 val loss: 0.275748
[Epoch 16] ogbg-moltoxcast: 0.647454 test loss: 0.307052
[Epoch 17; Iter    26/  229] train: loss: 0.1532710
[Epoch 17; Iter    56/  229] train: loss: 0.2053413
[Epoch 17; Iter    86/  229] train: loss: 0.1609664
[Epoch 17; Iter   116/  229] train: loss: 0.1953726
[Epoch 17; Iter   146/  229] train: loss: 0.1767074
[Epoch 17; Iter   176/  229] train: loss: 0.2601382
[Epoch 17; Iter   206/  229] train: loss: 0.1931226
[Epoch 17] ogbg-moltoxcast: 0.683136 val loss: 0.423793
[Epoch 17] ogbg-moltoxcast: 0.675516 test loss: 0.294374
[Epoch 18; Iter     7/  229] train: loss: 0.1246155
[Epoch 18; Iter    37/  229] train: loss: 0.1741051
[Epoch 18; Iter    67/  229] train: loss: 0.1630815
[Epoch 18; Iter    97/  229] train: loss: 0.2773285
[Epoch 18; Iter   127/  229] train: loss: 0.1701397
[Epoch 18; Iter   157/  229] train: loss: 0.1671238
[Epoch 18; Iter   187/  229] train: loss: 0.0995727
[Epoch 18; Iter   217/  229] train: loss: 0.2183383
[Epoch 18] ogbg-moltoxcast: 0.687017 val loss: 0.252751
[Epoch 18] ogbg-moltoxcast: 0.661225 test loss: 0.299073
[Epoch 19; Iter    18/  229] train: loss: 0.2228177
[Epoch 19; Iter    48/  229] train: loss: 0.1803865
[Epoch 19; Iter    78/  229] train: loss: 0.0948842
[Epoch 19; Iter   108/  229] train: loss: 0.1523848
[Epoch 19; Iter   138/  229] train: loss: 0.1041345
[Epoch 19; Iter   168/  229] train: loss: 0.1968846
[Epoch 19; Iter   198/  229] train: loss: 0.2071229
[Epoch 19; Iter   228/  229] train: loss: 0.1410848
[Epoch 19] ogbg-moltoxcast: 0.698727 val loss: 0.249467
[Epoch 19] ogbg-moltoxcast: 0.659595 test loss: 0.334698
[Epoch 20; Iter    29/  229] train: loss: 0.1857728
[Epoch 20; Iter    59/  229] train: loss: 0.2147033
[Epoch 20; Iter    89/  229] train: loss: 0.1494665
[Epoch 20; Iter   119/  229] train: loss: 0.1616623
[Epoch 20; Iter   149/  229] train: loss: 0.2465791
[Epoch 20; Iter   179/  229] train: loss: 0.1092972
[Epoch 20; Iter   209/  229] train: loss: 0.1690019
[Epoch 20] ogbg-moltoxcast: 0.678588 val loss: 0.286607
[Epoch 20] ogbg-moltoxcast: 0.664151 test loss: 0.291989
[Epoch 21; Iter    10/  229] train: loss: 0.1989457
[Epoch 21; Iter    40/  229] train: loss: 0.1075507
[Epoch 21; Iter    70/  229] train: loss: 0.1959660
[Epoch 21; Iter   100/  229] train: loss: 0.2272790
[Epoch 21; Iter   130/  229] train: loss: 0.1883979
[Epoch 21; Iter   160/  229] train: loss: 0.1824367
[Epoch 21; Iter   190/  229] train: loss: 0.1474655
[Epoch 21; Iter   220/  229] train: loss: 0.1931077
[Epoch 21] ogbg-moltoxcast: 0.689788 val loss: 0.395609
[Epoch 21] ogbg-moltoxcast: 0.669131 test loss: 0.289434
[Epoch 22; Iter    21/  229] train: loss: 0.1659045
[Epoch 22; Iter    51/  229] train: loss: 0.1759109
[Epoch 22; Iter    81/  229] train: loss: 0.1528360
[Epoch 22; Iter   111/  229] train: loss: 0.2118071
[Epoch 22; Iter   141/  229] train: loss: 0.1469911
[Epoch 22; Iter   171/  229] train: loss: 0.1827427
[Epoch 22; Iter   201/  229] train: loss: 0.1562542
[Epoch 22] ogbg-moltoxcast: 0.680007 val loss: 0.281923
[Epoch 22] ogbg-moltoxcast: 0.665166 test loss: 0.298994
[Epoch 23; Iter     2/  229] train: loss: 0.1886830
[Epoch 23; Iter    32/  229] train: loss: 0.1189982
[Epoch 23; Iter    62/  229] train: loss: 0.0886116
[Epoch 23; Iter    92/  229] train: loss: 0.1095589
[Epoch 23; Iter   122/  229] train: loss: 0.1538980
[Epoch 23; Iter   152/  229] train: loss: 0.1060064
[Epoch 23; Iter   182/  229] train: loss: 0.1637954
[Epoch 23; Iter   212/  229] train: loss: 0.1918259
[Epoch 23] ogbg-moltoxcast: 0.686036 val loss: 0.384256
[Epoch 23] ogbg-moltoxcast: 0.668743 test loss: 0.289306
[Epoch 24; Iter    13/  229] train: loss: 0.1301392
[Epoch 24; Iter    43/  229] train: loss: 0.2069915
[Epoch 24; Iter    73/  229] train: loss: 0.1576980
[Epoch 24; Iter   103/  229] train: loss: 0.1983469
[Epoch 24; Iter   133/  229] train: loss: 0.2026091
[Epoch 24; Iter   163/  229] train: loss: 0.1970458
[Epoch 24; Iter   193/  229] train: loss: 0.1616729
[Epoch 24; Iter   223/  229] train: loss: 0.1369482
[Epoch 24] ogbg-moltoxcast: 0.688490 val loss: 0.276921
[Epoch 24] ogbg-moltoxcast: 0.664604 test loss: 0.367954
[Epoch 25; Iter    24/  229] train: loss: 0.1635925
[Epoch 25; Iter    54/  229] train: loss: 0.1872970
[Epoch 25; Iter    84/  229] train: loss: 0.1770814
[Epoch 25; Iter   114/  229] train: loss: 0.2910537
[Epoch 25; Iter   144/  229] train: loss: 0.1318561
[Epoch 25; Iter   174/  229] train: loss: 0.2089138
[Epoch 25; Iter   204/  229] train: loss: 0.1227358
[Epoch 25] ogbg-moltoxcast: 0.670668 val loss: 0.255500
[Epoch 25] ogbg-moltoxcast: 0.663458 test loss: 0.302111
[Epoch 26; Iter     5/  229] train: loss: 0.1477102
[Epoch 26; Iter    35/  229] train: loss: 0.1648618
[Epoch 26; Iter    65/  229] train: loss: 0.1208117
[Epoch 26; Iter    95/  229] train: loss: 0.1395408
[Epoch 26; Iter   125/  229] train: loss: 0.1718608
[Epoch 26; Iter   155/  229] train: loss: 0.1663467
[Epoch 26; Iter   185/  229] train: loss: 0.1524388
[Epoch 26; Iter   215/  229] train: loss: 0.1734725
[Epoch 26] ogbg-moltoxcast: 0.672190 val loss: 0.265311
[Epoch 26] ogbg-moltoxcast: 0.651414 test loss: 0.300554
[Epoch 27; Iter    16/  229] train: loss: 0.0755554
[Epoch 27; Iter    46/  229] train: loss: 0.1863478
[Epoch 27; Iter    76/  229] train: loss: 0.1288826
[Epoch 27; Iter   106/  229] train: loss: 0.1867319
[Epoch 27; Iter   136/  229] train: loss: 0.1656977
[Epoch 27; Iter   166/  229] train: loss: 0.2201071
[Epoch 27; Iter   196/  229] train: loss: 0.1891336
[Epoch 27; Iter   226/  229] train: loss: 0.1813248
[Epoch 27] ogbg-moltoxcast: 0.684364 val loss: 0.251612
[Epoch 27] ogbg-moltoxcast: 0.667423 test loss: 0.298689
[Epoch 12; Iter    31/  229] train: loss: 0.2335263
[Epoch 12; Iter    61/  229] train: loss: 0.2561061
[Epoch 12; Iter    91/  229] train: loss: 0.1438891
[Epoch 12; Iter   121/  229] train: loss: 0.1253368
[Epoch 12; Iter   151/  229] train: loss: 0.1526208
[Epoch 12; Iter   181/  229] train: loss: 0.1791225
[Epoch 12; Iter   211/  229] train: loss: 0.1295592
[Epoch 12] ogbg-moltoxcast: 0.669758 val loss: 0.251883
[Epoch 12] ogbg-moltoxcast: 0.648823 test loss: 0.293961
[Epoch 13; Iter    12/  229] train: loss: 0.1796040
[Epoch 13; Iter    42/  229] train: loss: 0.1976059
[Epoch 13; Iter    72/  229] train: loss: 0.1811148
[Epoch 13; Iter   102/  229] train: loss: 0.2110807
[Epoch 13; Iter   132/  229] train: loss: 0.1974685
[Epoch 13; Iter   162/  229] train: loss: 0.1918893
[Epoch 13; Iter   192/  229] train: loss: 0.1937756
[Epoch 13; Iter   222/  229] train: loss: 0.1289081
[Epoch 13] ogbg-moltoxcast: 0.676769 val loss: 0.258237
[Epoch 13] ogbg-moltoxcast: 0.648034 test loss: 0.301315
[Epoch 14; Iter    23/  229] train: loss: 0.2600629
[Epoch 14; Iter    53/  229] train: loss: 0.1414414
[Epoch 14; Iter    83/  229] train: loss: 0.1525834
[Epoch 14; Iter   113/  229] train: loss: 0.1635841
[Epoch 14; Iter   143/  229] train: loss: 0.1632823
[Epoch 14; Iter   173/  229] train: loss: 0.1603794
[Epoch 14; Iter   203/  229] train: loss: 0.1491567
[Epoch 14] ogbg-moltoxcast: 0.681188 val loss: 0.254633
[Epoch 14] ogbg-moltoxcast: 0.649839 test loss: 0.294190
[Epoch 15; Iter     4/  229] train: loss: 0.2700990
[Epoch 15; Iter    34/  229] train: loss: 0.1516345
[Epoch 15; Iter    64/  229] train: loss: 0.1279671
[Epoch 15; Iter    94/  229] train: loss: 0.2240714
[Epoch 15; Iter   124/  229] train: loss: 0.1502310
[Epoch 15; Iter   154/  229] train: loss: 0.2671205
[Epoch 15; Iter   184/  229] train: loss: 0.2021152
[Epoch 15; Iter   214/  229] train: loss: 0.1704889
[Epoch 15] ogbg-moltoxcast: 0.676135 val loss: 0.258574
[Epoch 15] ogbg-moltoxcast: 0.654149 test loss: 0.308233
[Epoch 16; Iter    15/  229] train: loss: 0.1198229
[Epoch 16; Iter    45/  229] train: loss: 0.1851993
[Epoch 16; Iter    75/  229] train: loss: 0.1611927
[Epoch 16; Iter   105/  229] train: loss: 0.2229148
[Epoch 16; Iter   135/  229] train: loss: 0.1241680
[Epoch 16; Iter   165/  229] train: loss: 0.1669296
[Epoch 16; Iter   195/  229] train: loss: 0.2044176
[Epoch 16; Iter   225/  229] train: loss: 0.1539141
[Epoch 16] ogbg-moltoxcast: 0.678782 val loss: 0.256439
[Epoch 16] ogbg-moltoxcast: 0.656771 test loss: 0.298601
[Epoch 17; Iter    26/  229] train: loss: 0.1245075
[Epoch 17; Iter    56/  229] train: loss: 0.1624744
[Epoch 17; Iter    86/  229] train: loss: 0.0944053
[Epoch 17; Iter   116/  229] train: loss: 0.1146617
[Epoch 17; Iter   146/  229] train: loss: 0.2134984
[Epoch 17; Iter   176/  229] train: loss: 0.1558056
[Epoch 17; Iter   206/  229] train: loss: 0.2054020
[Epoch 17] ogbg-moltoxcast: 0.681094 val loss: 0.251644
[Epoch 17] ogbg-moltoxcast: 0.656512 test loss: 0.296202
[Epoch 18; Iter     7/  229] train: loss: 0.1814273
[Epoch 18; Iter    37/  229] train: loss: 0.1944243
[Epoch 18; Iter    67/  229] train: loss: 0.2186399
[Epoch 18; Iter    97/  229] train: loss: 0.2949595
[Epoch 18; Iter   127/  229] train: loss: 0.1557896
[Epoch 18; Iter   157/  229] train: loss: 0.1874436
[Epoch 18; Iter   187/  229] train: loss: 0.2500891
[Epoch 18; Iter   217/  229] train: loss: 0.2120162
[Epoch 18] ogbg-moltoxcast: 0.675133 val loss: 0.253262
[Epoch 18] ogbg-moltoxcast: 0.672092 test loss: 0.294201
[Epoch 19; Iter    18/  229] train: loss: 0.1255296
[Epoch 19; Iter    48/  229] train: loss: 0.2135598
[Epoch 19; Iter    78/  229] train: loss: 0.1943118
[Epoch 19; Iter   108/  229] train: loss: 0.1668977
[Epoch 19; Iter   138/  229] train: loss: 0.1599129
[Epoch 19; Iter   168/  229] train: loss: 0.1483502
[Epoch 19; Iter   198/  229] train: loss: 0.2340676
[Epoch 19; Iter   228/  229] train: loss: 0.2621804
[Epoch 19] ogbg-moltoxcast: 0.682726 val loss: 0.253644
[Epoch 19] ogbg-moltoxcast: 0.657060 test loss: 0.310058
[Epoch 20; Iter    29/  229] train: loss: 0.1732492
[Epoch 20; Iter    59/  229] train: loss: 0.1331951
[Epoch 20; Iter    89/  229] train: loss: 0.2448409
[Epoch 20; Iter   119/  229] train: loss: 0.1329736
[Epoch 20; Iter   149/  229] train: loss: 0.2141422
[Epoch 20; Iter   179/  229] train: loss: 0.1800529
[Epoch 20; Iter   209/  229] train: loss: 0.1591575
[Epoch 20] ogbg-moltoxcast: 0.675974 val loss: 0.264199
[Epoch 20] ogbg-moltoxcast: 0.653822 test loss: 0.307080
[Epoch 21; Iter    10/  229] train: loss: 0.2214023
[Epoch 21; Iter    40/  229] train: loss: 0.1919970
[Epoch 21; Iter    70/  229] train: loss: 0.2069708
[Epoch 21; Iter   100/  229] train: loss: 0.1782589
[Epoch 21; Iter   130/  229] train: loss: 0.1992408
[Epoch 21; Iter   160/  229] train: loss: 0.1994733
[Epoch 21; Iter   190/  229] train: loss: 0.1753055
[Epoch 21; Iter   220/  229] train: loss: 0.1222336
[Epoch 21] ogbg-moltoxcast: 0.669916 val loss: 0.264413
[Epoch 21] ogbg-moltoxcast: 0.657279 test loss: 0.301014
[Epoch 22; Iter    21/  229] train: loss: 0.0951467
[Epoch 22; Iter    51/  229] train: loss: 0.1924822
[Epoch 22; Iter    81/  229] train: loss: 0.1076572
[Epoch 22; Iter   111/  229] train: loss: 0.1977032
[Epoch 22; Iter   141/  229] train: loss: 0.2453439
[Epoch 22; Iter   171/  229] train: loss: 0.1168542
[Epoch 22; Iter   201/  229] train: loss: 0.1733469
[Epoch 22] ogbg-moltoxcast: 0.688545 val loss: 0.256657
[Epoch 22] ogbg-moltoxcast: 0.663853 test loss: 0.300859
[Epoch 23; Iter     2/  229] train: loss: 0.2518626
[Epoch 23; Iter    32/  229] train: loss: 0.1435932
[Epoch 23; Iter    62/  229] train: loss: 0.1808889
[Epoch 23; Iter    92/  229] train: loss: 0.1482929
[Epoch 23; Iter   122/  229] train: loss: 0.1640840
[Epoch 23; Iter   152/  229] train: loss: 0.2731405
[Epoch 23; Iter   182/  229] train: loss: 0.2087274
[Epoch 23; Iter   212/  229] train: loss: 0.1750222
[Epoch 23] ogbg-moltoxcast: 0.683931 val loss: 0.246545
[Epoch 23] ogbg-moltoxcast: 0.670518 test loss: 0.301725
[Epoch 24; Iter    13/  229] train: loss: 0.1737010
[Epoch 24; Iter    43/  229] train: loss: 0.1499515
[Epoch 24; Iter    73/  229] train: loss: 0.1276971
[Epoch 24; Iter   103/  229] train: loss: 0.1286276
[Epoch 24; Iter   133/  229] train: loss: 0.2209936
[Epoch 24; Iter   163/  229] train: loss: 0.2137771
[Epoch 24; Iter   193/  229] train: loss: 0.1327551
[Epoch 24; Iter   223/  229] train: loss: 0.1653231
[Epoch 24] ogbg-moltoxcast: 0.687229 val loss: 0.249414
[Epoch 24] ogbg-moltoxcast: 0.668780 test loss: 0.297171
[Epoch 25; Iter    24/  229] train: loss: 0.2400003
[Epoch 25; Iter    54/  229] train: loss: 0.1727409
[Epoch 25; Iter    84/  229] train: loss: 0.2279033
[Epoch 25; Iter   114/  229] train: loss: 0.1919265
[Epoch 25; Iter   144/  229] train: loss: 0.1041986
[Epoch 25; Iter   174/  229] train: loss: 0.1442903
[Epoch 25; Iter   204/  229] train: loss: 0.1654949
[Epoch 25] ogbg-moltoxcast: 0.696444 val loss: 0.246964
[Epoch 25] ogbg-moltoxcast: 0.666105 test loss: 0.296021
[Epoch 26; Iter     5/  229] train: loss: 0.1414600
[Epoch 26; Iter    35/  229] train: loss: 0.2359726
[Epoch 26; Iter    65/  229] train: loss: 0.1959195
[Epoch 26; Iter    95/  229] train: loss: 0.1899955
[Epoch 26; Iter   125/  229] train: loss: 0.1505470
[Epoch 26; Iter   155/  229] train: loss: 0.1548911
[Epoch 26; Iter   185/  229] train: loss: 0.1514853
[Epoch 26; Iter   215/  229] train: loss: 0.1188160
[Epoch 26] ogbg-moltoxcast: 0.689516 val loss: 0.252039
[Epoch 26] ogbg-moltoxcast: 0.668191 test loss: 0.296765
[Epoch 27; Iter    16/  229] train: loss: 0.1674517
[Epoch 27; Iter    46/  229] train: loss: 0.1611902
[Epoch 27; Iter    76/  229] train: loss: 0.1319077
[Epoch 27; Iter   106/  229] train: loss: 0.2041671
[Epoch 27; Iter   136/  229] train: loss: 0.1946836
[Epoch 27; Iter   166/  229] train: loss: 0.1322130
[Epoch 27; Iter   196/  229] train: loss: 0.1331484
[Epoch 27; Iter   226/  229] train: loss: 0.1724955
[Epoch 27] ogbg-moltoxcast: 0.696608 val loss: 0.251798
[Epoch 27] ogbg-moltoxcast: 0.666318 test loss: 0.299696
[Epoch 13; Iter    78/  201] train: loss: 0.1549429
[Epoch 13; Iter   108/  201] train: loss: 0.2186544
[Epoch 13; Iter   138/  201] train: loss: 0.1847571
[Epoch 13; Iter   168/  201] train: loss: 0.1953667
[Epoch 13; Iter   198/  201] train: loss: 0.1532937
[Epoch 13] ogbg-moltoxcast: 0.658758 val loss: 0.262603
[Epoch 13] ogbg-moltoxcast: 0.637280 test loss: 0.302176
[Epoch 14; Iter    27/  201] train: loss: 0.2028710
[Epoch 14; Iter    57/  201] train: loss: 0.1707913
[Epoch 14; Iter    87/  201] train: loss: 0.1583228
[Epoch 14; Iter   117/  201] train: loss: 0.1215074
[Epoch 14; Iter   147/  201] train: loss: 0.1601439
[Epoch 14; Iter   177/  201] train: loss: 0.1607905
[Epoch 14] ogbg-moltoxcast: 0.628071 val loss: 0.266875
[Epoch 14] ogbg-moltoxcast: 0.619119 test loss: 0.303352
[Epoch 15; Iter     6/  201] train: loss: 0.1488836
[Epoch 15; Iter    36/  201] train: loss: 0.1668024
[Epoch 15; Iter    66/  201] train: loss: 0.1952620
[Epoch 15; Iter    96/  201] train: loss: 0.1628159
[Epoch 15; Iter   126/  201] train: loss: 0.1385050
[Epoch 15; Iter   156/  201] train: loss: 0.0990132
[Epoch 15; Iter   186/  201] train: loss: 0.1717560
[Epoch 15] ogbg-moltoxcast: 0.653811 val loss: 0.272827
[Epoch 15] ogbg-moltoxcast: 0.628942 test loss: 0.315388
[Epoch 16; Iter    15/  201] train: loss: 0.2257048
[Epoch 16; Iter    45/  201] train: loss: 0.1529908
[Epoch 16; Iter    75/  201] train: loss: 0.2421295
[Epoch 16; Iter   105/  201] train: loss: 0.2042695
[Epoch 16; Iter   135/  201] train: loss: 0.1804946
[Epoch 16; Iter   165/  201] train: loss: 0.2433695
[Epoch 16; Iter   195/  201] train: loss: 0.1405741
[Epoch 16] ogbg-moltoxcast: 0.647362 val loss: 0.260403
[Epoch 16] ogbg-moltoxcast: 0.646661 test loss: 0.299839
[Epoch 17; Iter    24/  201] train: loss: 0.1468191
[Epoch 17; Iter    54/  201] train: loss: 0.1606025
[Epoch 17; Iter    84/  201] train: loss: 0.2100854
[Epoch 17; Iter   114/  201] train: loss: 0.2158460
[Epoch 17; Iter   144/  201] train: loss: 0.1506129
[Epoch 17; Iter   174/  201] train: loss: 0.1816968
[Epoch 17] ogbg-moltoxcast: 0.651546 val loss: 0.262708
[Epoch 17] ogbg-moltoxcast: 0.640458 test loss: 0.297818
[Epoch 18; Iter     3/  201] train: loss: 0.1822708
[Epoch 18; Iter    33/  201] train: loss: 0.1954264
[Epoch 18; Iter    63/  201] train: loss: 0.2077503
[Epoch 18; Iter    93/  201] train: loss: 0.1585539
[Epoch 18; Iter   123/  201] train: loss: 0.1763372
[Epoch 18; Iter   153/  201] train: loss: 0.1546251
[Epoch 18; Iter   183/  201] train: loss: 0.1886060
[Epoch 18] ogbg-moltoxcast: 0.638979 val loss: 0.270012
[Epoch 18] ogbg-moltoxcast: 0.609254 test loss: 0.318550
[Epoch 19; Iter    12/  201] train: loss: 0.1629243
[Epoch 19; Iter    42/  201] train: loss: 0.2707507
[Epoch 19; Iter    72/  201] train: loss: 0.1735208
[Epoch 19; Iter   102/  201] train: loss: 0.2888411
[Epoch 19; Iter   132/  201] train: loss: 0.1821514
[Epoch 19; Iter   162/  201] train: loss: 0.1606201
[Epoch 19; Iter   192/  201] train: loss: 0.2048425
[Epoch 19] ogbg-moltoxcast: 0.641913 val loss: 0.260428
[Epoch 19] ogbg-moltoxcast: 0.617136 test loss: 0.305642
[Epoch 20; Iter    21/  201] train: loss: 0.1201161
[Epoch 20; Iter    51/  201] train: loss: 0.2360947
[Epoch 20; Iter    81/  201] train: loss: 0.1488354
[Epoch 20; Iter   111/  201] train: loss: 0.1917226
[Epoch 20; Iter   141/  201] train: loss: 0.1324134
[Epoch 20; Iter   171/  201] train: loss: 0.2455987
[Epoch 20; Iter   201/  201] train: loss: 0.0651427
[Epoch 20] ogbg-moltoxcast: 0.663206 val loss: 0.263138
[Epoch 20] ogbg-moltoxcast: 0.643125 test loss: 0.314837
[Epoch 21; Iter    30/  201] train: loss: 0.2961500
[Epoch 21; Iter    60/  201] train: loss: 0.2188470
[Epoch 21; Iter    90/  201] train: loss: 0.2220759
[Epoch 21; Iter   120/  201] train: loss: 0.1578316
[Epoch 21; Iter   150/  201] train: loss: 0.1427212
[Epoch 21; Iter   180/  201] train: loss: 0.1421950
[Epoch 21] ogbg-moltoxcast: 0.650832 val loss: 0.259067
[Epoch 21] ogbg-moltoxcast: 0.644298 test loss: 0.294158
[Epoch 22; Iter     9/  201] train: loss: 0.1188023
[Epoch 22; Iter    39/  201] train: loss: 0.2028535
[Epoch 22; Iter    69/  201] train: loss: 0.1261138
[Epoch 22; Iter    99/  201] train: loss: 0.1540235
[Epoch 22; Iter   129/  201] train: loss: 0.1311055
[Epoch 22; Iter   159/  201] train: loss: 0.1222943
[Epoch 22; Iter   189/  201] train: loss: 0.1515939
[Epoch 22] ogbg-moltoxcast: 0.671153 val loss: 0.254961
[Epoch 22] ogbg-moltoxcast: 0.649192 test loss: 0.291293
[Epoch 23; Iter    18/  201] train: loss: 0.2282791
[Epoch 23; Iter    48/  201] train: loss: 0.1804190
[Epoch 23; Iter    78/  201] train: loss: 0.1999283
[Epoch 23; Iter   108/  201] train: loss: 0.1210460
[Epoch 23; Iter   138/  201] train: loss: 0.1618698
[Epoch 23; Iter   168/  201] train: loss: 0.1836066
[Epoch 23; Iter   198/  201] train: loss: 0.1536610
[Epoch 23] ogbg-moltoxcast: 0.660140 val loss: 0.259058
[Epoch 23] ogbg-moltoxcast: 0.654677 test loss: 0.298336
[Epoch 24; Iter    27/  201] train: loss: 0.1698925
[Epoch 24; Iter    57/  201] train: loss: 0.1877575
[Epoch 24; Iter    87/  201] train: loss: 0.1387720
[Epoch 24; Iter   117/  201] train: loss: 0.1763622
[Epoch 24; Iter   147/  201] train: loss: 0.1972253
[Epoch 24; Iter   177/  201] train: loss: 0.1887029
[Epoch 24] ogbg-moltoxcast: 0.661555 val loss: 0.265540
[Epoch 24] ogbg-moltoxcast: 0.655117 test loss: 0.304752
[Epoch 25; Iter     6/  201] train: loss: 0.2142022
[Epoch 25; Iter    36/  201] train: loss: 0.1259617
[Epoch 25; Iter    66/  201] train: loss: 0.1288932
[Epoch 25; Iter    96/  201] train: loss: 0.1341136
[Epoch 25; Iter   126/  201] train: loss: 0.1810386
[Epoch 25; Iter   156/  201] train: loss: 0.2073365
[Epoch 25; Iter   186/  201] train: loss: 0.1182089
[Epoch 25] ogbg-moltoxcast: 0.672199 val loss: 0.252394
[Epoch 25] ogbg-moltoxcast: 0.662724 test loss: 0.288792
[Epoch 26; Iter    15/  201] train: loss: 0.1808630
[Epoch 26; Iter    45/  201] train: loss: 0.1860144
[Epoch 26; Iter    75/  201] train: loss: 0.1307822
[Epoch 26; Iter   105/  201] train: loss: 0.1392832
[Epoch 26; Iter   135/  201] train: loss: 0.1957998
[Epoch 26; Iter   165/  201] train: loss: 0.1917662
[Epoch 26; Iter   195/  201] train: loss: 0.1186310
[Epoch 26] ogbg-moltoxcast: 0.661189 val loss: 0.257243
[Epoch 26] ogbg-moltoxcast: 0.657155 test loss: 0.294758
[Epoch 27; Iter    24/  201] train: loss: 0.1385297
[Epoch 27; Iter    54/  201] train: loss: 0.1493904
[Epoch 27; Iter    84/  201] train: loss: 0.1532878
[Epoch 27; Iter   114/  201] train: loss: 0.1207743
[Epoch 27; Iter   144/  201] train: loss: 0.2001034
[Epoch 27; Iter   174/  201] train: loss: 0.0987280
[Epoch 27] ogbg-moltoxcast: 0.671966 val loss: 0.252733
[Epoch 27] ogbg-moltoxcast: 0.661165 test loss: 0.292841
[Epoch 28; Iter     3/  201] train: loss: 0.1474686
[Epoch 28; Iter    33/  201] train: loss: 0.2332692
[Epoch 28; Iter    63/  201] train: loss: 0.1719521
[Epoch 28; Iter    93/  201] train: loss: 0.1840093
[Epoch 28; Iter   123/  201] train: loss: 0.1368955
[Epoch 28; Iter   153/  201] train: loss: 0.1577086
[Epoch 28; Iter   183/  201] train: loss: 0.1365893
[Epoch 28] ogbg-moltoxcast: 0.662352 val loss: 0.265550
[Epoch 28] ogbg-moltoxcast: 0.657885 test loss: 0.307906
[Epoch 29; Iter    12/  201] train: loss: 0.1835533
[Epoch 29; Iter    42/  201] train: loss: 0.1031391
[Epoch 29; Iter    72/  201] train: loss: 0.2120237
[Epoch 29; Iter   102/  201] train: loss: 0.1835849
[Epoch 29; Iter   132/  201] train: loss: 0.1916012
[Epoch 29; Iter   162/  201] train: loss: 0.1739891
[Epoch 29; Iter   192/  201] train: loss: 0.1979939
[Epoch 29] ogbg-moltoxcast: 0.662104 val loss: 0.261202
[Epoch 29] ogbg-moltoxcast: 0.645743 test loss: 0.303090
[Epoch 30; Iter    21/  201] train: loss: 0.1963216
[Epoch 30; Iter    51/  201] train: loss: 0.2095811
[Epoch 30; Iter    81/  201] train: loss: 0.2140874
[Epoch 30; Iter   111/  201] train: loss: 0.1924613
[Epoch 30; Iter   141/  201] train: loss: 0.1749522
[Epoch 30; Iter   171/  201] train: loss: 0.1947140
[Epoch 30; Iter   201/  201] train: loss: 0.1243671
[Epoch 30] ogbg-moltoxcast: 0.669129 val loss: 0.256928
[Epoch 13; Iter    78/  201] train: loss: 0.1950103
[Epoch 13; Iter   108/  201] train: loss: 0.2303898
[Epoch 13; Iter   138/  201] train: loss: 0.1906065
[Epoch 13; Iter   168/  201] train: loss: 0.2409341
[Epoch 13; Iter   198/  201] train: loss: 0.1677605
[Epoch 13] ogbg-moltoxcast: 0.656167 val loss: 0.262125
[Epoch 13] ogbg-moltoxcast: 0.636102 test loss: 0.307681
[Epoch 14; Iter    27/  201] train: loss: 0.1896666
[Epoch 14; Iter    57/  201] train: loss: 0.1430698
[Epoch 14; Iter    87/  201] train: loss: 0.2182246
[Epoch 14; Iter   117/  201] train: loss: 0.1535571
[Epoch 14; Iter   147/  201] train: loss: 0.1526940
[Epoch 14; Iter   177/  201] train: loss: 0.1691048
[Epoch 14] ogbg-moltoxcast: 0.650736 val loss: 0.302280
[Epoch 14] ogbg-moltoxcast: 0.629735 test loss: 0.310745
[Epoch 15; Iter     6/  201] train: loss: 0.1708911
[Epoch 15; Iter    36/  201] train: loss: 0.1378222
[Epoch 15; Iter    66/  201] train: loss: 0.1399057
[Epoch 15; Iter    96/  201] train: loss: 0.1985079
[Epoch 15; Iter   126/  201] train: loss: 0.2029635
[Epoch 15; Iter   156/  201] train: loss: 0.2118599
[Epoch 15; Iter   186/  201] train: loss: 0.1855227
[Epoch 15] ogbg-moltoxcast: 0.623883 val loss: 0.297657
[Epoch 15] ogbg-moltoxcast: 0.605001 test loss: 0.350641
[Epoch 16; Iter    15/  201] train: loss: 0.2003558
[Epoch 16; Iter    45/  201] train: loss: 0.2009578
[Epoch 16; Iter    75/  201] train: loss: 0.2188169
[Epoch 16; Iter   105/  201] train: loss: 0.2027015
[Epoch 16; Iter   135/  201] train: loss: 0.1480728
[Epoch 16; Iter   165/  201] train: loss: 0.1516662
[Epoch 16; Iter   195/  201] train: loss: 0.1773109
[Epoch 16] ogbg-moltoxcast: 0.647716 val loss: 0.264308
[Epoch 16] ogbg-moltoxcast: 0.643218 test loss: 0.300678
[Epoch 17; Iter    24/  201] train: loss: 0.2575682
[Epoch 17; Iter    54/  201] train: loss: 0.1495724
[Epoch 17; Iter    84/  201] train: loss: 0.1642916
[Epoch 17; Iter   114/  201] train: loss: 0.1308346
[Epoch 17; Iter   144/  201] train: loss: 0.1516341
[Epoch 17; Iter   174/  201] train: loss: 0.1503893
[Epoch 17] ogbg-moltoxcast: 0.658587 val loss: 0.272708
[Epoch 17] ogbg-moltoxcast: 0.640869 test loss: 0.313575
[Epoch 18; Iter     3/  201] train: loss: 0.1256324
[Epoch 18; Iter    33/  201] train: loss: 0.1527042
[Epoch 18; Iter    63/  201] train: loss: 0.1830241
[Epoch 18; Iter    93/  201] train: loss: 0.1411695
[Epoch 18; Iter   123/  201] train: loss: 0.1823306
[Epoch 18; Iter   153/  201] train: loss: 0.1941327
[Epoch 18; Iter   183/  201] train: loss: 0.2062770
[Epoch 18] ogbg-moltoxcast: 0.667403 val loss: 0.257713
[Epoch 18] ogbg-moltoxcast: 0.653302 test loss: 0.295990
[Epoch 19; Iter    12/  201] train: loss: 0.2529110
[Epoch 19; Iter    42/  201] train: loss: 0.2194040
[Epoch 19; Iter    72/  201] train: loss: 0.1895338
[Epoch 19; Iter   102/  201] train: loss: 0.1496054
[Epoch 19; Iter   132/  201] train: loss: 0.1377015
[Epoch 19; Iter   162/  201] train: loss: 0.2135042
[Epoch 19; Iter   192/  201] train: loss: 0.1976993
[Epoch 19] ogbg-moltoxcast: 0.667223 val loss: 0.254793
[Epoch 19] ogbg-moltoxcast: 0.645867 test loss: 0.321873
[Epoch 20; Iter    21/  201] train: loss: 0.2469884
[Epoch 20; Iter    51/  201] train: loss: 0.1647340
[Epoch 20; Iter    81/  201] train: loss: 0.1667811
[Epoch 20; Iter   111/  201] train: loss: 0.1061683
[Epoch 20; Iter   141/  201] train: loss: 0.1498403
[Epoch 20; Iter   171/  201] train: loss: 0.1784892
[Epoch 20; Iter   201/  201] train: loss: 0.0712892
[Epoch 20] ogbg-moltoxcast: 0.664234 val loss: 0.264946
[Epoch 20] ogbg-moltoxcast: 0.658249 test loss: 0.298860
[Epoch 21; Iter    30/  201] train: loss: 0.1614583
[Epoch 21; Iter    60/  201] train: loss: 0.1683790
[Epoch 21; Iter    90/  201] train: loss: 0.1667607
[Epoch 21; Iter   120/  201] train: loss: 0.1255319
[Epoch 21; Iter   150/  201] train: loss: 0.2020048
[Epoch 21; Iter   180/  201] train: loss: 0.1221106
[Epoch 21] ogbg-moltoxcast: 0.669837 val loss: 0.271887
[Epoch 21] ogbg-moltoxcast: 0.647909 test loss: 0.308934
[Epoch 22; Iter     9/  201] train: loss: 0.1934933
[Epoch 22; Iter    39/  201] train: loss: 0.1919202
[Epoch 22; Iter    69/  201] train: loss: 0.1178673
[Epoch 22; Iter    99/  201] train: loss: 0.2081286
[Epoch 22; Iter   129/  201] train: loss: 0.2277301
[Epoch 22; Iter   159/  201] train: loss: 0.1862351
[Epoch 22; Iter   189/  201] train: loss: 0.1956792
[Epoch 22] ogbg-moltoxcast: 0.654641 val loss: 0.260763
[Epoch 22] ogbg-moltoxcast: 0.645617 test loss: 0.424776
[Epoch 23; Iter    18/  201] train: loss: 0.1336664
[Epoch 23; Iter    48/  201] train: loss: 0.1582318
[Epoch 23; Iter    78/  201] train: loss: 0.1021894
[Epoch 23; Iter   108/  201] train: loss: 0.1495287
[Epoch 23; Iter   138/  201] train: loss: 0.1690774
[Epoch 23; Iter   168/  201] train: loss: 0.1482346
[Epoch 23; Iter   198/  201] train: loss: 0.1815476
[Epoch 23] ogbg-moltoxcast: 0.672661 val loss: 0.263725
[Epoch 23] ogbg-moltoxcast: 0.652601 test loss: 0.317724
[Epoch 24; Iter    27/  201] train: loss: 0.1481817
[Epoch 24; Iter    57/  201] train: loss: 0.1646984
[Epoch 24; Iter    87/  201] train: loss: 0.1786715
[Epoch 24; Iter   117/  201] train: loss: 0.1846588
[Epoch 24; Iter   147/  201] train: loss: 0.1680896
[Epoch 24; Iter   177/  201] train: loss: 0.2051478
[Epoch 24] ogbg-moltoxcast: 0.666840 val loss: 0.268880
[Epoch 24] ogbg-moltoxcast: 0.645267 test loss: 0.331444
[Epoch 25; Iter     6/  201] train: loss: 0.1422682
[Epoch 25; Iter    36/  201] train: loss: 0.2255473
[Epoch 25; Iter    66/  201] train: loss: 0.1692943
[Epoch 25; Iter    96/  201] train: loss: 0.1745952
[Epoch 25; Iter   126/  201] train: loss: 0.1451821
[Epoch 25; Iter   156/  201] train: loss: 0.1863012
[Epoch 25; Iter   186/  201] train: loss: 0.1250091
[Epoch 25] ogbg-moltoxcast: 0.654179 val loss: 0.282018
[Epoch 25] ogbg-moltoxcast: 0.641985 test loss: 0.326135
[Epoch 26; Iter    15/  201] train: loss: 0.1879840
[Epoch 26; Iter    45/  201] train: loss: 0.2273560
[Epoch 26; Iter    75/  201] train: loss: 0.1563319
[Epoch 26; Iter   105/  201] train: loss: 0.1514412
[Epoch 26; Iter   135/  201] train: loss: 0.2003758
[Epoch 26; Iter   165/  201] train: loss: 0.1455112
[Epoch 26; Iter   195/  201] train: loss: 0.1197997
[Epoch 26] ogbg-moltoxcast: 0.661214 val loss: 0.292042
[Epoch 26] ogbg-moltoxcast: 0.657307 test loss: 0.301217
[Epoch 27; Iter    24/  201] train: loss: 0.1889711
[Epoch 27; Iter    54/  201] train: loss: 0.1703108
[Epoch 27; Iter    84/  201] train: loss: 0.2183727
[Epoch 27; Iter   114/  201] train: loss: 0.1707467
[Epoch 27; Iter   144/  201] train: loss: 0.1693532
[Epoch 27; Iter   174/  201] train: loss: 0.1972593
[Epoch 27] ogbg-moltoxcast: 0.664636 val loss: 0.263478
[Epoch 27] ogbg-moltoxcast: 0.659453 test loss: 0.301065
[Epoch 28; Iter     3/  201] train: loss: 0.1325951
[Epoch 28; Iter    33/  201] train: loss: 0.1434790
[Epoch 28; Iter    63/  201] train: loss: 0.2147502
[Epoch 28; Iter    93/  201] train: loss: 0.1544396
[Epoch 28; Iter   123/  201] train: loss: 0.1894196
[Epoch 28; Iter   153/  201] train: loss: 0.1403228
[Epoch 28; Iter   183/  201] train: loss: 0.1443310
[Epoch 28] ogbg-moltoxcast: 0.672908 val loss: 0.258658
[Epoch 28] ogbg-moltoxcast: 0.664162 test loss: 0.302741
[Epoch 29; Iter    12/  201] train: loss: 0.1890736
[Epoch 29; Iter    42/  201] train: loss: 0.1193347
[Epoch 29; Iter    72/  201] train: loss: 0.2088245
[Epoch 29; Iter   102/  201] train: loss: 0.1592504
[Epoch 29; Iter   132/  201] train: loss: 0.1840898
[Epoch 29; Iter   162/  201] train: loss: 0.2370832
[Epoch 29; Iter   192/  201] train: loss: 0.1407642
[Epoch 29] ogbg-moltoxcast: 0.679622 val loss: 0.255942
[Epoch 29] ogbg-moltoxcast: 0.667289 test loss: 0.310365
[Epoch 30; Iter    21/  201] train: loss: 0.2207766
[Epoch 30; Iter    51/  201] train: loss: 0.1873513
[Epoch 30; Iter    81/  201] train: loss: 0.1242749
[Epoch 30; Iter   111/  201] train: loss: 0.1638217
[Epoch 30; Iter   141/  201] train: loss: 0.1114430
[Epoch 30; Iter   171/  201] train: loss: 0.1516318
[Epoch 30; Iter   201/  201] train: loss: 0.1266812
[Epoch 30] ogbg-moltoxcast: 0.661850 val loss: 0.263472
[Epoch 13; Iter    78/  201] train: loss: 0.1182079
[Epoch 13; Iter   108/  201] train: loss: 0.1446149
[Epoch 13; Iter   138/  201] train: loss: 0.1859566
[Epoch 13; Iter   168/  201] train: loss: 0.1795280
[Epoch 13; Iter   198/  201] train: loss: 0.1362591
[Epoch 13] ogbg-moltoxcast: 0.660126 val loss: 0.263567
[Epoch 13] ogbg-moltoxcast: 0.645008 test loss: 0.307411
[Epoch 14; Iter    27/  201] train: loss: 0.2236432
[Epoch 14; Iter    57/  201] train: loss: 0.2193989
[Epoch 14; Iter    87/  201] train: loss: 0.1559491
[Epoch 14; Iter   117/  201] train: loss: 0.1409245
[Epoch 14; Iter   147/  201] train: loss: 0.2050166
[Epoch 14; Iter   177/  201] train: loss: 0.2067587
[Epoch 14] ogbg-moltoxcast: 0.670891 val loss: 0.260756
[Epoch 14] ogbg-moltoxcast: 0.643912 test loss: 0.308652
[Epoch 15; Iter     6/  201] train: loss: 0.1745656
[Epoch 15; Iter    36/  201] train: loss: 0.2120869
[Epoch 15; Iter    66/  201] train: loss: 0.2438549
[Epoch 15; Iter    96/  201] train: loss: 0.2333079
[Epoch 15; Iter   126/  201] train: loss: 0.1647728
[Epoch 15; Iter   156/  201] train: loss: 0.1614671
[Epoch 15; Iter   186/  201] train: loss: 0.1754703
[Epoch 15] ogbg-moltoxcast: 0.666018 val loss: 0.272089
[Epoch 15] ogbg-moltoxcast: 0.648215 test loss: 0.314967
[Epoch 16; Iter    15/  201] train: loss: 0.1556611
[Epoch 16; Iter    45/  201] train: loss: 0.1431662
[Epoch 16; Iter    75/  201] train: loss: 0.1709106
[Epoch 16; Iter   105/  201] train: loss: 0.1060179
[Epoch 16; Iter   135/  201] train: loss: 0.1235498
[Epoch 16; Iter   165/  201] train: loss: 0.1764152
[Epoch 16; Iter   195/  201] train: loss: 0.1516931
[Epoch 16] ogbg-moltoxcast: 0.656408 val loss: 0.262307
[Epoch 16] ogbg-moltoxcast: 0.645550 test loss: 0.319693
[Epoch 17; Iter    24/  201] train: loss: 0.2240784
[Epoch 17; Iter    54/  201] train: loss: 0.1530672
[Epoch 17; Iter    84/  201] train: loss: 0.1170913
[Epoch 17; Iter   114/  201] train: loss: 0.2559470
[Epoch 17; Iter   144/  201] train: loss: 0.1471483
[Epoch 17; Iter   174/  201] train: loss: 0.1295902
[Epoch 17] ogbg-moltoxcast: 0.660277 val loss: 0.263298
[Epoch 17] ogbg-moltoxcast: 0.646534 test loss: 0.312812
[Epoch 18; Iter     3/  201] train: loss: 0.1616943
[Epoch 18; Iter    33/  201] train: loss: 0.1667017
[Epoch 18; Iter    63/  201] train: loss: 0.1179035
[Epoch 18; Iter    93/  201] train: loss: 0.1646667
[Epoch 18; Iter   123/  201] train: loss: 0.1194546
[Epoch 18; Iter   153/  201] train: loss: 0.1434555
[Epoch 18; Iter   183/  201] train: loss: 0.2191307
[Epoch 18] ogbg-moltoxcast: 0.671729 val loss: 0.270182
[Epoch 18] ogbg-moltoxcast: 0.646468 test loss: 0.305026
[Epoch 19; Iter    12/  201] train: loss: 0.1733348
[Epoch 19; Iter    42/  201] train: loss: 0.1533951
[Epoch 19; Iter    72/  201] train: loss: 0.1463547
[Epoch 19; Iter   102/  201] train: loss: 0.1147790
[Epoch 19; Iter   132/  201] train: loss: 0.2403522
[Epoch 19; Iter   162/  201] train: loss: 0.1645231
[Epoch 19; Iter   192/  201] train: loss: 0.2351944
[Epoch 19] ogbg-moltoxcast: 0.652116 val loss: 0.293823
[Epoch 19] ogbg-moltoxcast: 0.635084 test loss: 0.312148
[Epoch 20; Iter    21/  201] train: loss: 0.1637872
[Epoch 20; Iter    51/  201] train: loss: 0.1677832
[Epoch 20; Iter    81/  201] train: loss: 0.1563043
[Epoch 20; Iter   111/  201] train: loss: 0.2048787
[Epoch 20; Iter   141/  201] train: loss: 0.1881450
[Epoch 20; Iter   171/  201] train: loss: 0.2484501
[Epoch 20; Iter   201/  201] train: loss: 0.0749847
[Epoch 20] ogbg-moltoxcast: 0.656537 val loss: 0.263476
[Epoch 20] ogbg-moltoxcast: 0.646449 test loss: 0.298750
[Epoch 21; Iter    30/  201] train: loss: 0.1379460
[Epoch 21; Iter    60/  201] train: loss: 0.1110195
[Epoch 21; Iter    90/  201] train: loss: 0.1697767
[Epoch 21; Iter   120/  201] train: loss: 0.1676556
[Epoch 21; Iter   150/  201] train: loss: 0.1878129
[Epoch 21; Iter   180/  201] train: loss: 0.2285264
[Epoch 21] ogbg-moltoxcast: 0.659231 val loss: 0.258133
[Epoch 21] ogbg-moltoxcast: 0.650186 test loss: 0.295977
[Epoch 22; Iter     9/  201] train: loss: 0.1047743
[Epoch 22; Iter    39/  201] train: loss: 0.1587289
[Epoch 22; Iter    69/  201] train: loss: 0.1727696
[Epoch 22; Iter    99/  201] train: loss: 0.1302879
[Epoch 22; Iter   129/  201] train: loss: 0.2523058
[Epoch 22; Iter   159/  201] train: loss: 0.1784249
[Epoch 22; Iter   189/  201] train: loss: 0.1487125
[Epoch 22] ogbg-moltoxcast: 0.661341 val loss: 0.272181
[Epoch 22] ogbg-moltoxcast: 0.646435 test loss: 0.320715
[Epoch 23; Iter    18/  201] train: loss: 0.1947071
[Epoch 23; Iter    48/  201] train: loss: 0.1537906
[Epoch 23; Iter    78/  201] train: loss: 0.1929922
[Epoch 23; Iter   108/  201] train: loss: 0.2494804
[Epoch 23; Iter   138/  201] train: loss: 0.1618647
[Epoch 23; Iter   168/  201] train: loss: 0.1454127
[Epoch 23; Iter   198/  201] train: loss: 0.1817907
[Epoch 23] ogbg-moltoxcast: 0.637078 val loss: 0.397487
[Epoch 23] ogbg-moltoxcast: 0.605662 test loss: 0.444277
[Epoch 24; Iter    27/  201] train: loss: 0.1049568
[Epoch 24; Iter    57/  201] train: loss: 0.1192023
[Epoch 24; Iter    87/  201] train: loss: 0.2066693
[Epoch 24; Iter   117/  201] train: loss: 0.2024898
[Epoch 24; Iter   147/  201] train: loss: 0.1793119
[Epoch 24; Iter   177/  201] train: loss: 0.1487372
[Epoch 24] ogbg-moltoxcast: 0.673236 val loss: 0.255161
[Epoch 24] ogbg-moltoxcast: 0.655105 test loss: 0.286082
[Epoch 25; Iter     6/  201] train: loss: 0.1773251
[Epoch 25; Iter    36/  201] train: loss: 0.1292330
[Epoch 25; Iter    66/  201] train: loss: 0.2245407
[Epoch 25; Iter    96/  201] train: loss: 0.1493148
[Epoch 25; Iter   126/  201] train: loss: 0.1810899
[Epoch 25; Iter   156/  201] train: loss: 0.1457718
[Epoch 25; Iter   186/  201] train: loss: 0.1517950
[Epoch 25] ogbg-moltoxcast: 0.667068 val loss: 0.259153
[Epoch 25] ogbg-moltoxcast: 0.649155 test loss: 0.304220
[Epoch 26; Iter    15/  201] train: loss: 0.2159994
[Epoch 26; Iter    45/  201] train: loss: 0.1492795
[Epoch 26; Iter    75/  201] train: loss: 0.2015342
[Epoch 26; Iter   105/  201] train: loss: 0.2016043
[Epoch 26; Iter   135/  201] train: loss: 0.1636052
[Epoch 26; Iter   165/  201] train: loss: 0.1513305
[Epoch 26; Iter   195/  201] train: loss: 0.1395567
[Epoch 26] ogbg-moltoxcast: 0.673161 val loss: 0.268276
[Epoch 26] ogbg-moltoxcast: 0.655816 test loss: 0.301131
[Epoch 27; Iter    24/  201] train: loss: 0.1481903
[Epoch 27; Iter    54/  201] train: loss: 0.2412952
[Epoch 27; Iter    84/  201] train: loss: 0.1500409
[Epoch 27; Iter   114/  201] train: loss: 0.1232558
[Epoch 27; Iter   144/  201] train: loss: 0.1622269
[Epoch 27; Iter   174/  201] train: loss: 0.1603229
[Epoch 27] ogbg-moltoxcast: 0.668861 val loss: 0.265175
[Epoch 27] ogbg-moltoxcast: 0.648295 test loss: 0.305008
[Epoch 28; Iter     3/  201] train: loss: 0.1564734
[Epoch 28; Iter    33/  201] train: loss: 0.1516841
[Epoch 28; Iter    63/  201] train: loss: 0.1437445
[Epoch 28; Iter    93/  201] train: loss: 0.1346307
[Epoch 28; Iter   123/  201] train: loss: 0.1409290
[Epoch 28; Iter   153/  201] train: loss: 0.1377964
[Epoch 28; Iter   183/  201] train: loss: 0.1397660
[Epoch 28] ogbg-moltoxcast: 0.663977 val loss: 0.286917
[Epoch 28] ogbg-moltoxcast: 0.661272 test loss: 0.311223
[Epoch 29; Iter    12/  201] train: loss: 0.1761015
[Epoch 29; Iter    42/  201] train: loss: 0.1572004
[Epoch 29; Iter    72/  201] train: loss: 0.1227981
[Epoch 29; Iter   102/  201] train: loss: 0.1975214
[Epoch 29; Iter   132/  201] train: loss: 0.1686018
[Epoch 29; Iter   162/  201] train: loss: 0.1625966
[Epoch 29; Iter   192/  201] train: loss: 0.1652066
[Epoch 29] ogbg-moltoxcast: 0.680601 val loss: 0.265513
[Epoch 29] ogbg-moltoxcast: 0.663276 test loss: 0.305434
[Epoch 30; Iter    21/  201] train: loss: 0.1579267
[Epoch 30; Iter    51/  201] train: loss: 0.1754462
[Epoch 30; Iter    81/  201] train: loss: 0.1240391
[Epoch 30; Iter   111/  201] train: loss: 0.2003089
[Epoch 30; Iter   141/  201] train: loss: 0.1087223
[Epoch 30; Iter   171/  201] train: loss: 0.1746536
[Epoch 30; Iter   201/  201] train: loss: 0.1761956
[Epoch 30] ogbg-moltoxcast: 0.664997 val loss: 0.266648

[Epoch 14] ogbg-moltoxcast: 0.671584 val loss: 0.265823
[Epoch 14] ogbg-moltoxcast: 0.620176 test loss: 0.335964
[Epoch 15; Iter    22/  172] train: loss: 0.1267420
[Epoch 15; Iter    52/  172] train: loss: 0.1191134
[Epoch 15; Iter    82/  172] train: loss: 0.1605584
[Epoch 15; Iter   112/  172] train: loss: 0.2102112
[Epoch 15; Iter   142/  172] train: loss: 0.1726418
[Epoch 15; Iter   172/  172] train: loss: 0.0939624
[Epoch 15] ogbg-moltoxcast: 0.674750 val loss: 0.263740
[Epoch 15] ogbg-moltoxcast: 0.626550 test loss: 0.324232
[Epoch 16; Iter    30/  172] train: loss: 0.2204039
[Epoch 16; Iter    60/  172] train: loss: 0.1044176
[Epoch 16; Iter    90/  172] train: loss: 0.2855762
[Epoch 16; Iter   120/  172] train: loss: 0.1495004
[Epoch 16; Iter   150/  172] train: loss: 0.2278987
[Epoch 16] ogbg-moltoxcast: 0.650661 val loss: 0.273672
[Epoch 16] ogbg-moltoxcast: 0.613128 test loss: 0.344656
[Epoch 17; Iter     8/  172] train: loss: 0.1593739
[Epoch 17; Iter    38/  172] train: loss: 0.1555050
[Epoch 17; Iter    68/  172] train: loss: 0.1471626
[Epoch 17; Iter    98/  172] train: loss: 0.2139556
[Epoch 17; Iter   128/  172] train: loss: 0.1728462
[Epoch 17; Iter   158/  172] train: loss: 0.1237233
[Epoch 17] ogbg-moltoxcast: 0.675378 val loss: 0.263865
[Epoch 17] ogbg-moltoxcast: 0.628470 test loss: 0.316304
[Epoch 18; Iter    16/  172] train: loss: 0.1147418
[Epoch 18; Iter    46/  172] train: loss: 0.1700460
[Epoch 18; Iter    76/  172] train: loss: 0.2537788
[Epoch 18; Iter   106/  172] train: loss: 0.1672262
[Epoch 18; Iter   136/  172] train: loss: 0.1526449
[Epoch 18; Iter   166/  172] train: loss: 0.1988090
[Epoch 18] ogbg-moltoxcast: 0.663719 val loss: 0.270016
[Epoch 18] ogbg-moltoxcast: 0.618460 test loss: 0.327774
[Epoch 19; Iter    24/  172] train: loss: 0.1036955
[Epoch 19; Iter    54/  172] train: loss: 0.1867977
[Epoch 19; Iter    84/  172] train: loss: 0.1905986
[Epoch 19; Iter   114/  172] train: loss: 0.0923290
[Epoch 19; Iter   144/  172] train: loss: 0.1738552
[Epoch 19] ogbg-moltoxcast: 0.676459 val loss: 0.260302
[Epoch 19] ogbg-moltoxcast: 0.636236 test loss: 0.327089
[Epoch 20; Iter     2/  172] train: loss: 0.1570247
[Epoch 20; Iter    32/  172] train: loss: 0.1490124
[Epoch 20; Iter    62/  172] train: loss: 0.1431874
[Epoch 20; Iter    92/  172] train: loss: 0.1292441
[Epoch 20; Iter   122/  172] train: loss: 0.1563962
[Epoch 20; Iter   152/  172] train: loss: 0.1556954
[Epoch 20] ogbg-moltoxcast: 0.666806 val loss: 0.268626
[Epoch 20] ogbg-moltoxcast: 0.620748 test loss: 0.323873
[Epoch 21; Iter    10/  172] train: loss: 0.1471527
[Epoch 21; Iter    40/  172] train: loss: 0.1342359
[Epoch 21; Iter    70/  172] train: loss: 0.1192441
[Epoch 21; Iter   100/  172] train: loss: 0.1609758
[Epoch 21; Iter   130/  172] train: loss: 0.1354462
[Epoch 21; Iter   160/  172] train: loss: 0.0978345
[Epoch 21] ogbg-moltoxcast: 0.676470 val loss: 0.269773
[Epoch 21] ogbg-moltoxcast: 0.627432 test loss: 0.327796
[Epoch 22; Iter    18/  172] train: loss: 0.1555196
[Epoch 22; Iter    48/  172] train: loss: 0.1731178
[Epoch 22; Iter    78/  172] train: loss: 0.1637562
[Epoch 22; Iter   108/  172] train: loss: 0.1894284
[Epoch 22; Iter   138/  172] train: loss: 0.1260534
[Epoch 22; Iter   168/  172] train: loss: 0.1052877
[Epoch 22] ogbg-moltoxcast: 0.674161 val loss: 0.268708
[Epoch 22] ogbg-moltoxcast: 0.622261 test loss: 0.330416
[Epoch 23; Iter    26/  172] train: loss: 0.1346722
[Epoch 23; Iter    56/  172] train: loss: 0.2258832
[Epoch 23; Iter    86/  172] train: loss: 0.1809198
[Epoch 23; Iter   116/  172] train: loss: 0.1392878
[Epoch 23; Iter   146/  172] train: loss: 0.1258832
[Epoch 23] ogbg-moltoxcast: 0.666829 val loss: 0.266998
[Epoch 23] ogbg-moltoxcast: 0.626254 test loss: 0.323618
[Epoch 24; Iter     4/  172] train: loss: 0.1411202
[Epoch 24; Iter    34/  172] train: loss: 0.1191566
[Epoch 24; Iter    64/  172] train: loss: 0.2072131
[Epoch 24; Iter    94/  172] train: loss: 0.1611511
[Epoch 24; Iter   124/  172] train: loss: 0.1896930
[Epoch 24; Iter   154/  172] train: loss: 0.1012200
[Epoch 24] ogbg-moltoxcast: 0.668023 val loss: 0.290792
[Epoch 24] ogbg-moltoxcast: 0.622209 test loss: 0.353625
[Epoch 25; Iter    12/  172] train: loss: 0.1348035
[Epoch 25; Iter    42/  172] train: loss: 0.1448396
[Epoch 25; Iter    72/  172] train: loss: 0.1363785
[Epoch 25; Iter   102/  172] train: loss: 0.1915220
[Epoch 25; Iter   132/  172] train: loss: 0.1828452
[Epoch 25; Iter   162/  172] train: loss: 0.1350672
[Epoch 25] ogbg-moltoxcast: 0.668140 val loss: 0.269614
[Epoch 25] ogbg-moltoxcast: 0.622936 test loss: 0.322873
[Epoch 26; Iter    20/  172] train: loss: 0.1294995
[Epoch 26; Iter    50/  172] train: loss: 0.1175963
[Epoch 26; Iter    80/  172] train: loss: 0.1671889
[Epoch 26; Iter   110/  172] train: loss: 0.0903949
[Epoch 26; Iter   140/  172] train: loss: 0.1206432
[Epoch 26; Iter   170/  172] train: loss: 0.1289161
[Epoch 26] ogbg-moltoxcast: 0.657308 val loss: 0.267594
[Epoch 26] ogbg-moltoxcast: 0.609096 test loss: 0.319274
[Epoch 27; Iter    28/  172] train: loss: 0.1759139
[Epoch 27; Iter    58/  172] train: loss: 0.1287918
[Epoch 27; Iter    88/  172] train: loss: 0.1891169
[Epoch 27; Iter   118/  172] train: loss: 0.1254215
[Epoch 27; Iter   148/  172] train: loss: 0.1264794
[Epoch 27] ogbg-moltoxcast: 0.657610 val loss: 0.274597
[Epoch 27] ogbg-moltoxcast: 0.620754 test loss: 0.329376
[Epoch 28; Iter     6/  172] train: loss: 0.1795513
[Epoch 28; Iter    36/  172] train: loss: 0.2253468
[Epoch 28; Iter    66/  172] train: loss: 0.2265075
[Epoch 28; Iter    96/  172] train: loss: 0.1882168
[Epoch 28; Iter   126/  172] train: loss: 0.1434552
[Epoch 28; Iter   156/  172] train: loss: 0.1689232
[Epoch 28] ogbg-moltoxcast: 0.677638 val loss: 0.263638
[Epoch 28] ogbg-moltoxcast: 0.624693 test loss: 0.322066
[Epoch 29; Iter    14/  172] train: loss: 0.1499790
[Epoch 29; Iter    44/  172] train: loss: 0.1403289
[Epoch 29; Iter    74/  172] train: loss: 0.1156948
[Epoch 29; Iter   104/  172] train: loss: 0.1817482
[Epoch 29; Iter   134/  172] train: loss: 0.1215695
[Epoch 29; Iter   164/  172] train: loss: 0.1218483
[Epoch 29] ogbg-moltoxcast: 0.657461 val loss: 0.277500
[Epoch 29] ogbg-moltoxcast: 0.623474 test loss: 0.337238
[Epoch 30; Iter    22/  172] train: loss: 0.1222100
[Epoch 30; Iter    52/  172] train: loss: 0.1521262
[Epoch 30; Iter    82/  172] train: loss: 0.1324765
[Epoch 30; Iter   112/  172] train: loss: 0.1232132
[Epoch 30; Iter   142/  172] train: loss: 0.1126227
[Epoch 30; Iter   172/  172] train: loss: 0.1258760
[Epoch 30] ogbg-moltoxcast: 0.674837 val loss: 0.261368
[Epoch 30] ogbg-moltoxcast: 0.624860 test loss: 0.313726
[Epoch 31; Iter    30/  172] train: loss: 0.2004738
[Epoch 31; Iter    60/  172] train: loss: 0.2026443
[Epoch 31; Iter    90/  172] train: loss: 0.1279256
[Epoch 31; Iter   120/  172] train: loss: 0.1234614
[Epoch 31; Iter   150/  172] train: loss: 0.1780947
[Epoch 31] ogbg-moltoxcast: 0.674447 val loss: 0.269731
[Epoch 31] ogbg-moltoxcast: 0.628533 test loss: 0.325552
[Epoch 32; Iter     8/  172] train: loss: 0.0911915
[Epoch 32; Iter    38/  172] train: loss: 0.1068129
[Epoch 32; Iter    68/  172] train: loss: 0.1604552
[Epoch 32; Iter    98/  172] train: loss: 0.1342685
[Epoch 32; Iter   128/  172] train: loss: 0.1259850
[Epoch 32; Iter   158/  172] train: loss: 0.1818194
[Epoch 32] ogbg-moltoxcast: 0.647700 val loss: 0.279831
[Epoch 32] ogbg-moltoxcast: 0.618177 test loss: 0.331906
[Epoch 33; Iter    16/  172] train: loss: 0.1303098
[Epoch 33; Iter    46/  172] train: loss: 0.1329962
[Epoch 33; Iter    76/  172] train: loss: 0.2457004
[Epoch 33; Iter   106/  172] train: loss: 0.1052680
[Epoch 33; Iter   136/  172] train: loss: 0.1573122
[Epoch 33; Iter   166/  172] train: loss: 0.1269005
[Epoch 33] ogbg-moltoxcast: 0.664536 val loss: 0.274759
[Epoch 33] ogbg-moltoxcast: 0.617056 test loss: 0.330658
[Epoch 34; Iter    24/  172] train: loss: 0.1366642
[Epoch 34; Iter    54/  172] train: loss: 0.1204937
[Epoch 34; Iter    84/  172] train: loss: 0.1416426
[Epoch 34; Iter   114/  172] train: loss: 0.0987402
[Epoch 34; Iter   144/  172] train: loss: 0.1085576

[Epoch 14] ogbg-moltoxcast: 0.670641 val loss: 0.261994
[Epoch 14] ogbg-moltoxcast: 0.628136 test loss: 0.308670
[Epoch 15; Iter    22/  172] train: loss: 0.1575776
[Epoch 15; Iter    52/  172] train: loss: 0.1405782
[Epoch 15; Iter    82/  172] train: loss: 0.2502379
[Epoch 15; Iter   112/  172] train: loss: 0.1605217
[Epoch 15; Iter   142/  172] train: loss: 0.1601034
[Epoch 15; Iter   172/  172] train: loss: 0.2330296
[Epoch 15] ogbg-moltoxcast: 0.655026 val loss: 0.272941
[Epoch 15] ogbg-moltoxcast: 0.615074 test loss: 0.326490
[Epoch 16; Iter    30/  172] train: loss: 0.2711033
[Epoch 16; Iter    60/  172] train: loss: 0.1536255
[Epoch 16; Iter    90/  172] train: loss: 0.1172888
[Epoch 16; Iter   120/  172] train: loss: 0.2262576
[Epoch 16; Iter   150/  172] train: loss: 0.1870200
[Epoch 16] ogbg-moltoxcast: 0.680180 val loss: 0.259887
[Epoch 16] ogbg-moltoxcast: 0.631122 test loss: 0.314549
[Epoch 17; Iter     8/  172] train: loss: 0.1663285
[Epoch 17; Iter    38/  172] train: loss: 0.1070358
[Epoch 17; Iter    68/  172] train: loss: 0.1581914
[Epoch 17; Iter    98/  172] train: loss: 0.1576921
[Epoch 17; Iter   128/  172] train: loss: 0.1629614
[Epoch 17; Iter   158/  172] train: loss: 0.1587968
[Epoch 17] ogbg-moltoxcast: 0.664758 val loss: 0.268189
[Epoch 17] ogbg-moltoxcast: 0.612109 test loss: 0.320821
[Epoch 18; Iter    16/  172] train: loss: 0.0992692
[Epoch 18; Iter    46/  172] train: loss: 0.1588617
[Epoch 18; Iter    76/  172] train: loss: 0.1246077
[Epoch 18; Iter   106/  172] train: loss: 0.1331702
[Epoch 18; Iter   136/  172] train: loss: 0.1515758
[Epoch 18; Iter   166/  172] train: loss: 0.0761304
[Epoch 18] ogbg-moltoxcast: 0.657881 val loss: 0.272597
[Epoch 18] ogbg-moltoxcast: 0.617498 test loss: 0.342897
[Epoch 19; Iter    24/  172] train: loss: 0.1326204
[Epoch 19; Iter    54/  172] train: loss: 0.1520626
[Epoch 19; Iter    84/  172] train: loss: 0.1791214
[Epoch 19; Iter   114/  172] train: loss: 0.1355783
[Epoch 19; Iter   144/  172] train: loss: 0.1597371
[Epoch 19] ogbg-moltoxcast: 0.657141 val loss: 0.260636
[Epoch 19] ogbg-moltoxcast: 0.612127 test loss: 0.302068
[Epoch 20; Iter     2/  172] train: loss: 0.1479002
[Epoch 20; Iter    32/  172] train: loss: 0.1991411
[Epoch 20; Iter    62/  172] train: loss: 0.1502255
[Epoch 20; Iter    92/  172] train: loss: 0.1276725
[Epoch 20; Iter   122/  172] train: loss: 0.2711608
[Epoch 20; Iter   152/  172] train: loss: 0.1489043
[Epoch 20] ogbg-moltoxcast: 0.655397 val loss: 0.266887
[Epoch 20] ogbg-moltoxcast: 0.614990 test loss: 0.313363
[Epoch 21; Iter    10/  172] train: loss: 0.1383987
[Epoch 21; Iter    40/  172] train: loss: 0.1191641
[Epoch 21; Iter    70/  172] train: loss: 0.2059113
[Epoch 21; Iter   100/  172] train: loss: 0.1876189
[Epoch 21; Iter   130/  172] train: loss: 0.1384826
[Epoch 21; Iter   160/  172] train: loss: 0.1201353
[Epoch 21] ogbg-moltoxcast: 0.668996 val loss: 0.269401
[Epoch 21] ogbg-moltoxcast: 0.619745 test loss: 0.322149
[Epoch 22; Iter    18/  172] train: loss: 0.1647521
[Epoch 22; Iter    48/  172] train: loss: 0.1925331
[Epoch 22; Iter    78/  172] train: loss: 0.1005004
[Epoch 22; Iter   108/  172] train: loss: 0.1733374
[Epoch 22; Iter   138/  172] train: loss: 0.1338944
[Epoch 22; Iter   168/  172] train: loss: 0.1839129
[Epoch 22] ogbg-moltoxcast: 0.683510 val loss: 0.260645
[Epoch 22] ogbg-moltoxcast: 0.626828 test loss: 0.309619
[Epoch 23; Iter    26/  172] train: loss: 0.1461281
[Epoch 23; Iter    56/  172] train: loss: 0.1879025
[Epoch 23; Iter    86/  172] train: loss: 0.1117050
[Epoch 23; Iter   116/  172] train: loss: 0.1337804
[Epoch 23; Iter   146/  172] train: loss: 0.1634401
[Epoch 23] ogbg-moltoxcast: 0.673913 val loss: 0.275283
[Epoch 23] ogbg-moltoxcast: 0.626912 test loss: 0.322942
[Epoch 24; Iter     4/  172] train: loss: 0.1713814
[Epoch 24; Iter    34/  172] train: loss: 0.1789863
[Epoch 24; Iter    64/  172] train: loss: 0.1602572
[Epoch 24; Iter    94/  172] train: loss: 0.1406241
[Epoch 24; Iter   124/  172] train: loss: 0.1561196
[Epoch 24; Iter   154/  172] train: loss: 0.1795580
[Epoch 24] ogbg-moltoxcast: 0.687255 val loss: 0.259130
[Epoch 24] ogbg-moltoxcast: 0.628724 test loss: 0.311670
[Epoch 25; Iter    12/  172] train: loss: 0.1495527
[Epoch 25; Iter    42/  172] train: loss: 0.1986690
[Epoch 25; Iter    72/  172] train: loss: 0.1885060
[Epoch 25; Iter   102/  172] train: loss: 0.2389421
[Epoch 25; Iter   132/  172] train: loss: 0.1666425
[Epoch 25; Iter   162/  172] train: loss: 0.0804911
[Epoch 25] ogbg-moltoxcast: 0.668152 val loss: 0.276003
[Epoch 25] ogbg-moltoxcast: 0.625442 test loss: 0.329878
[Epoch 26; Iter    20/  172] train: loss: 0.1949499
[Epoch 26; Iter    50/  172] train: loss: 0.1890886
[Epoch 26; Iter    80/  172] train: loss: 0.1576861
[Epoch 26; Iter   110/  172] train: loss: 0.1671198
[Epoch 26; Iter   140/  172] train: loss: 0.1502869
[Epoch 26; Iter   170/  172] train: loss: 0.1709889
[Epoch 26] ogbg-moltoxcast: 0.682004 val loss: 0.261057
[Epoch 26] ogbg-moltoxcast: 0.632203 test loss: 0.302775
[Epoch 27; Iter    28/  172] train: loss: 0.1229601
[Epoch 27; Iter    58/  172] train: loss: 0.1525711
[Epoch 27; Iter    88/  172] train: loss: 0.1434905
[Epoch 27; Iter   118/  172] train: loss: 0.0848308
[Epoch 27; Iter   148/  172] train: loss: 0.1391799
[Epoch 27] ogbg-moltoxcast: 0.665928 val loss: 0.303643
[Epoch 27] ogbg-moltoxcast: 0.625768 test loss: 0.363983
[Epoch 28; Iter     6/  172] train: loss: 0.0992703
[Epoch 28; Iter    36/  172] train: loss: 0.1210925
[Epoch 28; Iter    66/  172] train: loss: 0.1208203
[Epoch 28; Iter    96/  172] train: loss: 0.1924931
[Epoch 28; Iter   126/  172] train: loss: 0.1204109
[Epoch 28; Iter   156/  172] train: loss: 0.1438288
[Epoch 28] ogbg-moltoxcast: 0.657351 val loss: 0.270917
[Epoch 28] ogbg-moltoxcast: 0.619496 test loss: 0.318793
[Epoch 29; Iter    14/  172] train: loss: 0.1369165
[Epoch 29; Iter    44/  172] train: loss: 0.2178499
[Epoch 29; Iter    74/  172] train: loss: 0.1570849
[Epoch 29; Iter   104/  172] train: loss: 0.1573705
[Epoch 29; Iter   134/  172] train: loss: 0.1447576
[Epoch 29; Iter   164/  172] train: loss: 0.1264996
[Epoch 29] ogbg-moltoxcast: 0.675608 val loss: 0.264365
[Epoch 29] ogbg-moltoxcast: 0.624809 test loss: 0.314743
[Epoch 30; Iter    22/  172] train: loss: 0.1406916
[Epoch 30; Iter    52/  172] train: loss: 0.1516297
[Epoch 30; Iter    82/  172] train: loss: 0.1583733
[Epoch 30; Iter   112/  172] train: loss: 0.1599825
[Epoch 30; Iter   142/  172] train: loss: 0.1402475
[Epoch 30; Iter   172/  172] train: loss: 0.2211394
[Epoch 30] ogbg-moltoxcast: 0.668489 val loss: 0.272566
[Epoch 30] ogbg-moltoxcast: 0.618837 test loss: 0.326526
[Epoch 31; Iter    30/  172] train: loss: 0.1239608
[Epoch 31; Iter    60/  172] train: loss: 0.0717924
[Epoch 31; Iter    90/  172] train: loss: 0.1715072
[Epoch 31; Iter   120/  172] train: loss: 0.1222527
[Epoch 31; Iter   150/  172] train: loss: 0.1278783
[Epoch 31] ogbg-moltoxcast: 0.673688 val loss: 0.270244
[Epoch 31] ogbg-moltoxcast: 0.630933 test loss: 0.319878
[Epoch 32; Iter     8/  172] train: loss: 0.1880846
[Epoch 32; Iter    38/  172] train: loss: 0.1736532
[Epoch 32; Iter    68/  172] train: loss: 0.1359286
[Epoch 32; Iter    98/  172] train: loss: 0.1247213
[Epoch 32; Iter   128/  172] train: loss: 0.1195565
[Epoch 32; Iter   158/  172] train: loss: 0.1733728
[Epoch 32] ogbg-moltoxcast: 0.677827 val loss: 0.275167
[Epoch 32] ogbg-moltoxcast: 0.628690 test loss: 0.327535
[Epoch 33; Iter    16/  172] train: loss: 0.2278478
[Epoch 33; Iter    46/  172] train: loss: 0.1165098
[Epoch 33; Iter    76/  172] train: loss: 0.1427192
[Epoch 33; Iter   106/  172] train: loss: 0.1542656
[Epoch 33; Iter   136/  172] train: loss: 0.1148225
[Epoch 33; Iter   166/  172] train: loss: 0.1665761
[Epoch 33] ogbg-moltoxcast: 0.683379 val loss: 0.268554
[Epoch 33] ogbg-moltoxcast: 0.632455 test loss: 0.316674
[Epoch 34; Iter    24/  172] train: loss: 0.1498985
[Epoch 34; Iter    54/  172] train: loss: 0.1277008
[Epoch 34; Iter    84/  172] train: loss: 0.1893871
[Epoch 34; Iter   114/  172] train: loss: 0.1660615
[Epoch 34; Iter   144/  172] train: loss: 0.1250864

[Epoch 14] ogbg-moltoxcast: 0.662292 val loss: 0.269146
[Epoch 14] ogbg-moltoxcast: 0.620511 test loss: 0.333019
[Epoch 15; Iter    22/  172] train: loss: 0.2015424
[Epoch 15; Iter    52/  172] train: loss: 0.1393955
[Epoch 15; Iter    82/  172] train: loss: 0.1499703
[Epoch 15; Iter   112/  172] train: loss: 0.1529817
[Epoch 15; Iter   142/  172] train: loss: 0.2202943
[Epoch 15; Iter   172/  172] train: loss: 0.1225950
[Epoch 15] ogbg-moltoxcast: 0.656913 val loss: 0.267861
[Epoch 15] ogbg-moltoxcast: 0.617365 test loss: 0.374234
[Epoch 16; Iter    30/  172] train: loss: 0.2566852
[Epoch 16; Iter    60/  172] train: loss: 0.1663021
[Epoch 16; Iter    90/  172] train: loss: 0.1142136
[Epoch 16; Iter   120/  172] train: loss: 0.2006611
[Epoch 16; Iter   150/  172] train: loss: 0.1761614
[Epoch 16] ogbg-moltoxcast: 0.658462 val loss: 0.295884
[Epoch 16] ogbg-moltoxcast: 0.624169 test loss: 0.399275
[Epoch 17; Iter     8/  172] train: loss: 0.2828061
[Epoch 17; Iter    38/  172] train: loss: 0.1310750
[Epoch 17; Iter    68/  172] train: loss: 0.1007636
[Epoch 17; Iter    98/  172] train: loss: 0.1079177
[Epoch 17; Iter   128/  172] train: loss: 0.1949019
[Epoch 17; Iter   158/  172] train: loss: 0.1292919
[Epoch 17] ogbg-moltoxcast: 0.666210 val loss: 0.466543
[Epoch 17] ogbg-moltoxcast: 0.630683 test loss: 0.527599
[Epoch 18; Iter    16/  172] train: loss: 0.1784227
[Epoch 18; Iter    46/  172] train: loss: 0.1526180
[Epoch 18; Iter    76/  172] train: loss: 0.1618390
[Epoch 18; Iter   106/  172] train: loss: 0.1795006
[Epoch 18; Iter   136/  172] train: loss: 0.1306277
[Epoch 18; Iter   166/  172] train: loss: 0.1276419
[Epoch 18] ogbg-moltoxcast: 0.659424 val loss: 0.264840
[Epoch 18] ogbg-moltoxcast: 0.627684 test loss: 0.317530
[Epoch 19; Iter    24/  172] train: loss: 0.1860716
[Epoch 19; Iter    54/  172] train: loss: 0.1127940
[Epoch 19; Iter    84/  172] train: loss: 0.2316182
[Epoch 19; Iter   114/  172] train: loss: 0.0871240
[Epoch 19; Iter   144/  172] train: loss: 0.1696100
[Epoch 19] ogbg-moltoxcast: 0.669069 val loss: 0.270674
[Epoch 19] ogbg-moltoxcast: 0.623290 test loss: 0.322718
[Epoch 20; Iter     2/  172] train: loss: 0.1322174
[Epoch 20; Iter    32/  172] train: loss: 0.1894654
[Epoch 20; Iter    62/  172] train: loss: 0.1312689
[Epoch 20; Iter    92/  172] train: loss: 0.1778805
[Epoch 20; Iter   122/  172] train: loss: 0.1852971
[Epoch 20; Iter   152/  172] train: loss: 0.1512598
[Epoch 20] ogbg-moltoxcast: 0.663498 val loss: 0.269090
[Epoch 20] ogbg-moltoxcast: 0.623497 test loss: 0.325199
[Epoch 21; Iter    10/  172] train: loss: 0.1532734
[Epoch 21; Iter    40/  172] train: loss: 0.2036817
[Epoch 21; Iter    70/  172] train: loss: 0.1252925
[Epoch 21; Iter   100/  172] train: loss: 0.2138268
[Epoch 21; Iter   130/  172] train: loss: 0.1995581
[Epoch 21; Iter   160/  172] train: loss: 0.1188730
[Epoch 21] ogbg-moltoxcast: 0.635372 val loss: 0.276604
[Epoch 21] ogbg-moltoxcast: 0.614642 test loss: 0.331143
[Epoch 22; Iter    18/  172] train: loss: 0.1101588
[Epoch 22; Iter    48/  172] train: loss: 0.2070078
[Epoch 22; Iter    78/  172] train: loss: 0.0859141
[Epoch 22; Iter   108/  172] train: loss: 0.1924165
[Epoch 22; Iter   138/  172] train: loss: 0.1323946
[Epoch 22; Iter   168/  172] train: loss: 0.1801153
[Epoch 22] ogbg-moltoxcast: 0.665523 val loss: 0.266069
[Epoch 22] ogbg-moltoxcast: 0.623639 test loss: 0.320467
[Epoch 23; Iter    26/  172] train: loss: 0.1312263
[Epoch 23; Iter    56/  172] train: loss: 0.1282759
[Epoch 23; Iter    86/  172] train: loss: 0.1834482
[Epoch 23; Iter   116/  172] train: loss: 0.1620329
[Epoch 23; Iter   146/  172] train: loss: 0.1876968
[Epoch 23] ogbg-moltoxcast: 0.660362 val loss: 0.279340
[Epoch 23] ogbg-moltoxcast: 0.626789 test loss: 0.340313
[Epoch 24; Iter     4/  172] train: loss: 0.1351995
[Epoch 24; Iter    34/  172] train: loss: 0.2141435
[Epoch 24; Iter    64/  172] train: loss: 0.0906116
[Epoch 24; Iter    94/  172] train: loss: 0.1292407
[Epoch 24; Iter   124/  172] train: loss: 0.1641819
[Epoch 24; Iter   154/  172] train: loss: 0.1545452
[Epoch 24] ogbg-moltoxcast: 0.667773 val loss: 0.269802
[Epoch 24] ogbg-moltoxcast: 0.621293 test loss: 0.329700
[Epoch 25; Iter    12/  172] train: loss: 0.1121433
[Epoch 25; Iter    42/  172] train: loss: 0.2097134
[Epoch 25; Iter    72/  172] train: loss: 0.1585652
[Epoch 25; Iter   102/  172] train: loss: 0.1436595
[Epoch 25; Iter   132/  172] train: loss: 0.1996179
[Epoch 25; Iter   162/  172] train: loss: 0.2638857
[Epoch 25] ogbg-moltoxcast: 0.671529 val loss: 0.264193
[Epoch 25] ogbg-moltoxcast: 0.626604 test loss: 0.317618
[Epoch 26; Iter    20/  172] train: loss: 0.1826057
[Epoch 26; Iter    50/  172] train: loss: 0.1636050
[Epoch 26; Iter    80/  172] train: loss: 0.1690717
[Epoch 26; Iter   110/  172] train: loss: 0.1482108
[Epoch 26; Iter   140/  172] train: loss: 0.2405000
[Epoch 26; Iter   170/  172] train: loss: 0.1433123
[Epoch 26] ogbg-moltoxcast: 0.670757 val loss: 0.263570
[Epoch 26] ogbg-moltoxcast: 0.632513 test loss: 0.309573
[Epoch 27; Iter    28/  172] train: loss: 0.1604391
[Epoch 27; Iter    58/  172] train: loss: 0.1180682
[Epoch 27; Iter    88/  172] train: loss: 0.1351531
[Epoch 27; Iter   118/  172] train: loss: 0.1565110
[Epoch 27; Iter   148/  172] train: loss: 0.1934561
[Epoch 27] ogbg-moltoxcast: 0.676936 val loss: 0.262912
[Epoch 27] ogbg-moltoxcast: 0.631538 test loss: 0.313565
[Epoch 28; Iter     6/  172] train: loss: 0.1788540
[Epoch 28; Iter    36/  172] train: loss: 0.1188077
[Epoch 28; Iter    66/  172] train: loss: 0.1560735
[Epoch 28; Iter    96/  172] train: loss: 0.2334503
[Epoch 28; Iter   126/  172] train: loss: 0.1383169
[Epoch 28; Iter   156/  172] train: loss: 0.1090232
[Epoch 28] ogbg-moltoxcast: 0.677699 val loss: 0.264432
[Epoch 28] ogbg-moltoxcast: 0.630928 test loss: 0.321012
[Epoch 29; Iter    14/  172] train: loss: 0.0970337
[Epoch 29; Iter    44/  172] train: loss: 0.1150256
[Epoch 29; Iter    74/  172] train: loss: 0.1483878
[Epoch 29; Iter   104/  172] train: loss: 0.1386917
[Epoch 29; Iter   134/  172] train: loss: 0.1039529
[Epoch 29; Iter   164/  172] train: loss: 0.0876900
[Epoch 29] ogbg-moltoxcast: 0.667788 val loss: 0.264852
[Epoch 29] ogbg-moltoxcast: 0.626405 test loss: 0.317977
[Epoch 30; Iter    22/  172] train: loss: 0.1243122
[Epoch 30; Iter    52/  172] train: loss: 0.1229472
[Epoch 30; Iter    82/  172] train: loss: 0.1647173
[Epoch 30; Iter   112/  172] train: loss: 0.1034388
[Epoch 30; Iter   142/  172] train: loss: 0.1501105
[Epoch 30; Iter   172/  172] train: loss: 0.1315389
[Epoch 30] ogbg-moltoxcast: 0.673686 val loss: 0.262460
[Epoch 30] ogbg-moltoxcast: 0.637472 test loss: 0.310511
[Epoch 31; Iter    30/  172] train: loss: 0.1483556
[Epoch 31; Iter    60/  172] train: loss: 0.0926633
[Epoch 31; Iter    90/  172] train: loss: 0.1520899
[Epoch 31; Iter   120/  172] train: loss: 0.1259075
[Epoch 31; Iter   150/  172] train: loss: 0.1232679
[Epoch 31] ogbg-moltoxcast: 0.669818 val loss: 0.268602
[Epoch 31] ogbg-moltoxcast: 0.624989 test loss: 0.329870
[Epoch 32; Iter     8/  172] train: loss: 0.1750211
[Epoch 32; Iter    38/  172] train: loss: 0.1586870
[Epoch 32; Iter    68/  172] train: loss: 0.1422875
[Epoch 32; Iter    98/  172] train: loss: 0.1254036
[Epoch 32; Iter   128/  172] train: loss: 0.1210700
[Epoch 32; Iter   158/  172] train: loss: 0.1391806
[Epoch 32] ogbg-moltoxcast: 0.650467 val loss: 0.269907
[Epoch 32] ogbg-moltoxcast: 0.617611 test loss: 0.312502
[Epoch 33; Iter    16/  172] train: loss: 0.1045931
[Epoch 33; Iter    46/  172] train: loss: 0.1417174
[Epoch 33; Iter    76/  172] train: loss: 0.1628345
[Epoch 33; Iter   106/  172] train: loss: 0.2353264
[Epoch 33; Iter   136/  172] train: loss: 0.1392428
[Epoch 33; Iter   166/  172] train: loss: 0.1346288
[Epoch 33] ogbg-moltoxcast: 0.657034 val loss: 0.269002
[Epoch 33] ogbg-moltoxcast: 0.614859 test loss: 0.317841
[Epoch 34; Iter    24/  172] train: loss: 0.1120373
[Epoch 34; Iter    54/  172] train: loss: 0.2299826
[Epoch 34; Iter    84/  172] train: loss: 0.1127118
[Epoch 34; Iter   114/  172] train: loss: 0.1263394
[Epoch 34; Iter   144/  172] train: loss: 0.1708637
[Epoch 28; Iter    27/  229] train: loss: 0.1790460
[Epoch 28; Iter    57/  229] train: loss: 0.1986490
[Epoch 28; Iter    87/  229] train: loss: 0.1602496
[Epoch 28; Iter   117/  229] train: loss: 0.2493118
[Epoch 28; Iter   147/  229] train: loss: 0.1444479
[Epoch 28; Iter   177/  229] train: loss: 0.1421567
[Epoch 28; Iter   207/  229] train: loss: 0.1872873
[Epoch 28] ogbg-moltoxcast: 0.691581 val loss: 0.250606
[Epoch 28] ogbg-moltoxcast: 0.662091 test loss: 0.293135
[Epoch 29; Iter     8/  229] train: loss: 0.2870984
[Epoch 29; Iter    38/  229] train: loss: 0.2045125
[Epoch 29; Iter    68/  229] train: loss: 0.3094443
[Epoch 29; Iter    98/  229] train: loss: 0.1583353
[Epoch 29; Iter   128/  229] train: loss: 0.1384906
[Epoch 29; Iter   158/  229] train: loss: 0.2032971
[Epoch 29; Iter   188/  229] train: loss: 0.1245771
[Epoch 29; Iter   218/  229] train: loss: 0.1727782
[Epoch 29] ogbg-moltoxcast: 0.694532 val loss: 0.247336
[Epoch 29] ogbg-moltoxcast: 0.665329 test loss: 0.293810
[Epoch 30; Iter    19/  229] train: loss: 0.1232011
[Epoch 30; Iter    49/  229] train: loss: 0.1250397
[Epoch 30; Iter    79/  229] train: loss: 0.2349822
[Epoch 30; Iter   109/  229] train: loss: 0.1455162
[Epoch 30; Iter   139/  229] train: loss: 0.1551632
[Epoch 30; Iter   169/  229] train: loss: 0.1904644
[Epoch 30; Iter   199/  229] train: loss: 0.1782329
[Epoch 30; Iter   229/  229] train: loss: 0.1499897
[Epoch 30] ogbg-moltoxcast: 0.696595 val loss: 0.251648
[Epoch 30] ogbg-moltoxcast: 0.665778 test loss: 0.296981
[Epoch 31; Iter    30/  229] train: loss: 0.0982737
[Epoch 31; Iter    60/  229] train: loss: 0.1396996
[Epoch 31; Iter    90/  229] train: loss: 0.1386452
[Epoch 31; Iter   120/  229] train: loss: 0.0723554
[Epoch 31; Iter   150/  229] train: loss: 0.1746413
[Epoch 31; Iter   180/  229] train: loss: 0.1514926
[Epoch 31; Iter   210/  229] train: loss: 0.1850777
[Epoch 31] ogbg-moltoxcast: 0.691662 val loss: 0.249360
[Epoch 31] ogbg-moltoxcast: 0.661277 test loss: 0.290987
[Epoch 32; Iter    11/  229] train: loss: 0.1700425
[Epoch 32; Iter    41/  229] train: loss: 0.1386934
[Epoch 32; Iter    71/  229] train: loss: 0.1388481
[Epoch 32; Iter   101/  229] train: loss: 0.1497203
[Epoch 32; Iter   131/  229] train: loss: 0.2235831
[Epoch 32; Iter   161/  229] train: loss: 0.1488180
[Epoch 32; Iter   191/  229] train: loss: 0.1327229
[Epoch 32; Iter   221/  229] train: loss: 0.1083281
[Epoch 32] ogbg-moltoxcast: 0.696934 val loss: 0.261527
[Epoch 32] ogbg-moltoxcast: 0.664597 test loss: 0.305524
[Epoch 33; Iter    22/  229] train: loss: 0.1565834
[Epoch 33; Iter    52/  229] train: loss: 0.1602587
[Epoch 33; Iter    82/  229] train: loss: 0.1540859
[Epoch 33; Iter   112/  229] train: loss: 0.1841396
[Epoch 33; Iter   142/  229] train: loss: 0.1612906
[Epoch 33; Iter   172/  229] train: loss: 0.1589728
[Epoch 33; Iter   202/  229] train: loss: 0.1570744
[Epoch 33] ogbg-moltoxcast: 0.684399 val loss: 0.250623
[Epoch 33] ogbg-moltoxcast: 0.672929 test loss: 0.291152
[Epoch 34; Iter     3/  229] train: loss: 0.1953977
[Epoch 34; Iter    33/  229] train: loss: 0.1509764
[Epoch 34; Iter    63/  229] train: loss: 0.1973323
[Epoch 34; Iter    93/  229] train: loss: 0.1799742
[Epoch 34; Iter   123/  229] train: loss: 0.1700823
[Epoch 34; Iter   153/  229] train: loss: 0.1337826
[Epoch 34; Iter   183/  229] train: loss: 0.1525400
[Epoch 34; Iter   213/  229] train: loss: 0.1860618
[Epoch 34] ogbg-moltoxcast: 0.689954 val loss: 0.249421
[Epoch 34] ogbg-moltoxcast: 0.671256 test loss: 0.290250
[Epoch 35; Iter    14/  229] train: loss: 0.1450029
[Epoch 35; Iter    44/  229] train: loss: 0.1189924
[Epoch 35; Iter    74/  229] train: loss: 0.1061334
[Epoch 35; Iter   104/  229] train: loss: 0.1636902
[Epoch 35; Iter   134/  229] train: loss: 0.1531298
[Epoch 35; Iter   164/  229] train: loss: 0.1503328
[Epoch 35; Iter   194/  229] train: loss: 0.1753497
[Epoch 35; Iter   224/  229] train: loss: 0.1501774
[Epoch 35] ogbg-moltoxcast: 0.686322 val loss: 0.248191
[Epoch 35] ogbg-moltoxcast: 0.667609 test loss: 0.291083
[Epoch 36; Iter    25/  229] train: loss: 0.1445355
[Epoch 36; Iter    55/  229] train: loss: 0.1663438
[Epoch 36; Iter    85/  229] train: loss: 0.1574570
[Epoch 36; Iter   115/  229] train: loss: 0.1195872
[Epoch 36; Iter   145/  229] train: loss: 0.1943477
[Epoch 36; Iter   175/  229] train: loss: 0.1261163
[Epoch 36; Iter   205/  229] train: loss: 0.1519021
[Epoch 36] ogbg-moltoxcast: 0.692499 val loss: 0.254015
[Epoch 36] ogbg-moltoxcast: 0.667079 test loss: 0.302758
[Epoch 37; Iter     6/  229] train: loss: 0.1529378
[Epoch 37; Iter    36/  229] train: loss: 0.1404096
[Epoch 37; Iter    66/  229] train: loss: 0.2377665
[Epoch 37; Iter    96/  229] train: loss: 0.1183988
[Epoch 37; Iter   126/  229] train: loss: 0.1700810
[Epoch 37; Iter   156/  229] train: loss: 0.1904110
[Epoch 37; Iter   186/  229] train: loss: 0.1885583
[Epoch 37; Iter   216/  229] train: loss: 0.1849855
[Epoch 37] ogbg-moltoxcast: 0.691795 val loss: 0.248591
[Epoch 37] ogbg-moltoxcast: 0.666991 test loss: 0.292364
[Epoch 38; Iter    17/  229] train: loss: 0.1392455
[Epoch 38; Iter    47/  229] train: loss: 0.1650255
[Epoch 38; Iter    77/  229] train: loss: 0.1256486
[Epoch 38; Iter   107/  229] train: loss: 0.1346839
[Epoch 38; Iter   137/  229] train: loss: 0.1742089
[Epoch 38; Iter   167/  229] train: loss: 0.1211724
[Epoch 38; Iter   197/  229] train: loss: 0.1594487
[Epoch 38; Iter   227/  229] train: loss: 0.1384096
[Epoch 38] ogbg-moltoxcast: 0.689068 val loss: 0.250929
[Epoch 38] ogbg-moltoxcast: 0.665988 test loss: 0.297780
[Epoch 39; Iter    28/  229] train: loss: 0.1861466
[Epoch 39; Iter    58/  229] train: loss: 0.1269662
[Epoch 39; Iter    88/  229] train: loss: 0.1543289
[Epoch 39; Iter   118/  229] train: loss: 0.2015901
[Epoch 39; Iter   148/  229] train: loss: 0.1713288
[Epoch 39; Iter   178/  229] train: loss: 0.1305706
[Epoch 39; Iter   208/  229] train: loss: 0.1360605
[Epoch 39] ogbg-moltoxcast: 0.684843 val loss: 0.250668
[Epoch 39] ogbg-moltoxcast: 0.666376 test loss: 0.291575
[Epoch 40; Iter     9/  229] train: loss: 0.1672038
[Epoch 40; Iter    39/  229] train: loss: 0.1274047
[Epoch 40; Iter    69/  229] train: loss: 0.1627624
[Epoch 40; Iter    99/  229] train: loss: 0.1218903
[Epoch 40; Iter   129/  229] train: loss: 0.1741276
[Epoch 40; Iter   159/  229] train: loss: 0.1396164
[Epoch 40; Iter   189/  229] train: loss: 0.1671051
[Epoch 40; Iter   219/  229] train: loss: 0.1407655
[Epoch 40] ogbg-moltoxcast: 0.685796 val loss: 0.251633
[Epoch 40] ogbg-moltoxcast: 0.662090 test loss: 0.303175
[Epoch 41; Iter    20/  229] train: loss: 0.1873267
[Epoch 41; Iter    50/  229] train: loss: 0.1310445
[Epoch 41; Iter    80/  229] train: loss: 0.2098837
[Epoch 41; Iter   110/  229] train: loss: 0.0722515
[Epoch 41; Iter   140/  229] train: loss: 0.1866476
[Epoch 41; Iter   170/  229] train: loss: 0.2077371
[Epoch 41; Iter   200/  229] train: loss: 0.1599756
[Epoch 41] ogbg-moltoxcast: 0.694633 val loss: 0.254139
[Epoch 41] ogbg-moltoxcast: 0.669849 test loss: 1.105596
[Epoch 42; Iter     1/  229] train: loss: 0.1692366
[Epoch 42; Iter    31/  229] train: loss: 0.1138185
[Epoch 42; Iter    61/  229] train: loss: 0.1220196
[Epoch 42; Iter    91/  229] train: loss: 0.1828826
[Epoch 42; Iter   121/  229] train: loss: 0.1912168
[Epoch 42; Iter   151/  229] train: loss: 0.1305746
[Epoch 42; Iter   181/  229] train: loss: 0.1453868
[Epoch 42; Iter   211/  229] train: loss: 0.1457099
[Epoch 42] ogbg-moltoxcast: 0.683275 val loss: 0.255963
[Epoch 42] ogbg-moltoxcast: 0.670448 test loss: 0.386390
[Epoch 43; Iter    12/  229] train: loss: 0.0914099
[Epoch 43; Iter    42/  229] train: loss: 0.1813908
[Epoch 43; Iter    72/  229] train: loss: 0.1343511
[Epoch 43; Iter   102/  229] train: loss: 0.1673117
[Epoch 43; Iter   132/  229] train: loss: 0.1175426
[Epoch 43; Iter   162/  229] train: loss: 0.1043368
[Epoch 43; Iter   192/  229] train: loss: 0.1670898
[Epoch 43; Iter   222/  229] train: loss: 0.1335157
[Epoch 43] ogbg-moltoxcast: 0.694624 val loss: 0.248835
[Epoch 43] ogbg-moltoxcast: 0.671253 test loss: 0.622946
[Epoch 28; Iter    27/  229] train: loss: 0.1855075
[Epoch 28; Iter    57/  229] train: loss: 0.1598896
[Epoch 28; Iter    87/  229] train: loss: 0.1749478
[Epoch 28; Iter   117/  229] train: loss: 0.1828023
[Epoch 28; Iter   147/  229] train: loss: 0.1821766
[Epoch 28; Iter   177/  229] train: loss: 0.1500360
[Epoch 28; Iter   207/  229] train: loss: 0.1711401
[Epoch 28] ogbg-moltoxcast: 0.685853 val loss: 0.248030
[Epoch 28] ogbg-moltoxcast: 0.664699 test loss: 0.295415
[Epoch 29; Iter     8/  229] train: loss: 0.1083306
[Epoch 29; Iter    38/  229] train: loss: 0.1384963
[Epoch 29; Iter    68/  229] train: loss: 0.1320235
[Epoch 29; Iter    98/  229] train: loss: 0.1805936
[Epoch 29; Iter   128/  229] train: loss: 0.1409564
[Epoch 29; Iter   158/  229] train: loss: 0.1064970
[Epoch 29; Iter   188/  229] train: loss: 0.1483300
[Epoch 29; Iter   218/  229] train: loss: 0.1336750
[Epoch 29] ogbg-moltoxcast: 0.672825 val loss: 0.250373
[Epoch 29] ogbg-moltoxcast: 0.661215 test loss: 0.296191
[Epoch 30; Iter    19/  229] train: loss: 0.1379382
[Epoch 30; Iter    49/  229] train: loss: 0.1925321
[Epoch 30; Iter    79/  229] train: loss: 0.1324834
[Epoch 30; Iter   109/  229] train: loss: 0.2169789
[Epoch 30; Iter   139/  229] train: loss: 0.1860103
[Epoch 30; Iter   169/  229] train: loss: 0.1832720
[Epoch 30; Iter   199/  229] train: loss: 0.1535371
[Epoch 30; Iter   229/  229] train: loss: 0.1808221
[Epoch 30] ogbg-moltoxcast: 0.691449 val loss: 0.256544
[Epoch 30] ogbg-moltoxcast: 0.666804 test loss: 0.303380
[Epoch 31; Iter    30/  229] train: loss: 0.2135554
[Epoch 31; Iter    60/  229] train: loss: 0.1782224
[Epoch 31; Iter    90/  229] train: loss: 0.1698233
[Epoch 31; Iter   120/  229] train: loss: 0.1696356
[Epoch 31; Iter   150/  229] train: loss: 0.1618139
[Epoch 31; Iter   180/  229] train: loss: 0.2339075
[Epoch 31; Iter   210/  229] train: loss: 0.1516824
[Epoch 31] ogbg-moltoxcast: 0.693651 val loss: 0.296237
[Epoch 31] ogbg-moltoxcast: 0.674519 test loss: 0.305618
[Epoch 32; Iter    11/  229] train: loss: 0.1417970
[Epoch 32; Iter    41/  229] train: loss: 0.1461168
[Epoch 32; Iter    71/  229] train: loss: 0.1730558
[Epoch 32; Iter   101/  229] train: loss: 0.2119187
[Epoch 32; Iter   131/  229] train: loss: 0.1171269
[Epoch 32; Iter   161/  229] train: loss: 0.1940539
[Epoch 32; Iter   191/  229] train: loss: 0.0996163
[Epoch 32; Iter   221/  229] train: loss: 0.1483048
[Epoch 32] ogbg-moltoxcast: 0.690600 val loss: 0.281336
[Epoch 32] ogbg-moltoxcast: 0.675464 test loss: 0.297517
[Epoch 33; Iter    22/  229] train: loss: 0.1204520
[Epoch 33; Iter    52/  229] train: loss: 0.1181248
[Epoch 33; Iter    82/  229] train: loss: 0.1400352
[Epoch 33; Iter   112/  229] train: loss: 0.1975360
[Epoch 33; Iter   142/  229] train: loss: 0.1117472
[Epoch 33; Iter   172/  229] train: loss: 0.1608855
[Epoch 33; Iter   202/  229] train: loss: 0.1119102
[Epoch 33] ogbg-moltoxcast: 0.686423 val loss: 0.253412
[Epoch 33] ogbg-moltoxcast: 0.672137 test loss: 0.298643
[Epoch 34; Iter     3/  229] train: loss: 0.1970259
[Epoch 34; Iter    33/  229] train: loss: 0.1649926
[Epoch 34; Iter    63/  229] train: loss: 0.1646804
[Epoch 34; Iter    93/  229] train: loss: 0.1619196
[Epoch 34; Iter   123/  229] train: loss: 0.1369142
[Epoch 34; Iter   153/  229] train: loss: 0.1296877
[Epoch 34; Iter   183/  229] train: loss: 0.1151156
[Epoch 34; Iter   213/  229] train: loss: 0.2323763
[Epoch 34] ogbg-moltoxcast: 0.687826 val loss: 0.298817
[Epoch 34] ogbg-moltoxcast: 0.657316 test loss: 0.304204
[Epoch 35; Iter    14/  229] train: loss: 0.0826665
[Epoch 35; Iter    44/  229] train: loss: 0.1580323
[Epoch 35; Iter    74/  229] train: loss: 0.1375480
[Epoch 35; Iter   104/  229] train: loss: 0.2199214
[Epoch 35; Iter   134/  229] train: loss: 0.2161713
[Epoch 35; Iter   164/  229] train: loss: 0.1577606
[Epoch 35; Iter   194/  229] train: loss: 0.1287750
[Epoch 35; Iter   224/  229] train: loss: 0.1280906
[Epoch 35] ogbg-moltoxcast: 0.701362 val loss: 0.263386
[Epoch 35] ogbg-moltoxcast: 0.671810 test loss: 0.303089
[Epoch 36; Iter    25/  229] train: loss: 0.1858377
[Epoch 36; Iter    55/  229] train: loss: 0.1810277
[Epoch 36; Iter    85/  229] train: loss: 0.1275243
[Epoch 36; Iter   115/  229] train: loss: 0.1171900
[Epoch 36; Iter   145/  229] train: loss: 0.1663174
[Epoch 36; Iter   175/  229] train: loss: 0.1687751
[Epoch 36; Iter   205/  229] train: loss: 0.1817003
[Epoch 36] ogbg-moltoxcast: 0.696123 val loss: 0.249593
[Epoch 36] ogbg-moltoxcast: 0.670771 test loss: 0.304263
[Epoch 37; Iter     6/  229] train: loss: 0.1219592
[Epoch 37; Iter    36/  229] train: loss: 0.0997235
[Epoch 37; Iter    66/  229] train: loss: 0.1363299
[Epoch 37; Iter    96/  229] train: loss: 0.1384143
[Epoch 37; Iter   126/  229] train: loss: 0.1314305
[Epoch 37; Iter   156/  229] train: loss: 0.1284504
[Epoch 37; Iter   186/  229] train: loss: 0.1606195
[Epoch 37; Iter   216/  229] train: loss: 0.1585929
[Epoch 37] ogbg-moltoxcast: 0.693393 val loss: 0.251957
[Epoch 37] ogbg-moltoxcast: 0.666778 test loss: 0.305447
[Epoch 38; Iter    17/  229] train: loss: 0.1897010
[Epoch 38; Iter    47/  229] train: loss: 0.1603931
[Epoch 38; Iter    77/  229] train: loss: 0.1326812
[Epoch 38; Iter   107/  229] train: loss: 0.1431563
[Epoch 38; Iter   137/  229] train: loss: 0.1798945
[Epoch 38; Iter   167/  229] train: loss: 0.1431915
[Epoch 38; Iter   197/  229] train: loss: 0.1580312
[Epoch 38; Iter   227/  229] train: loss: 0.1708863
[Epoch 38] ogbg-moltoxcast: 0.686255 val loss: 0.317839
[Epoch 38] ogbg-moltoxcast: 0.664559 test loss: 0.309724
[Epoch 39; Iter    28/  229] train: loss: 0.1879898
[Epoch 39; Iter    58/  229] train: loss: 0.1140220
[Epoch 39; Iter    88/  229] train: loss: 0.1266986
[Epoch 39; Iter   118/  229] train: loss: 0.2387316
[Epoch 39; Iter   148/  229] train: loss: 0.1413826
[Epoch 39; Iter   178/  229] train: loss: 0.1698583
[Epoch 39; Iter   208/  229] train: loss: 0.1891805
[Epoch 39] ogbg-moltoxcast: 0.698111 val loss: 0.244798
[Epoch 39] ogbg-moltoxcast: 0.675060 test loss: 0.302505
[Epoch 40; Iter     9/  229] train: loss: 0.1434652
[Epoch 40; Iter    39/  229] train: loss: 0.1272049
[Epoch 40; Iter    69/  229] train: loss: 0.1124617
[Epoch 40; Iter    99/  229] train: loss: 0.1782527
[Epoch 40; Iter   129/  229] train: loss: 0.1396888
[Epoch 40; Iter   159/  229] train: loss: 0.1349757
[Epoch 40; Iter   189/  229] train: loss: 0.1490623
[Epoch 40; Iter   219/  229] train: loss: 0.2024214
[Epoch 40] ogbg-moltoxcast: 0.695455 val loss: 0.256672
[Epoch 40] ogbg-moltoxcast: 0.665592 test loss: 0.309462
[Epoch 41; Iter    20/  229] train: loss: 0.1457418
[Epoch 41; Iter    50/  229] train: loss: 0.1187125
[Epoch 41; Iter    80/  229] train: loss: 0.0880024
[Epoch 41; Iter   110/  229] train: loss: 0.1058652
[Epoch 41; Iter   140/  229] train: loss: 0.1224957
[Epoch 41; Iter   170/  229] train: loss: 0.1014958
[Epoch 41; Iter   200/  229] train: loss: 0.1667781
[Epoch 41] ogbg-moltoxcast: 0.686850 val loss: 0.254595
[Epoch 41] ogbg-moltoxcast: 0.668022 test loss: 0.309091
[Epoch 42; Iter     1/  229] train: loss: 0.1849604
[Epoch 42; Iter    31/  229] train: loss: 0.1363837
[Epoch 42; Iter    61/  229] train: loss: 0.1778834
[Epoch 42; Iter    91/  229] train: loss: 0.1226527
[Epoch 42; Iter   121/  229] train: loss: 0.1779989
[Epoch 42; Iter   151/  229] train: loss: 0.1209562
[Epoch 42; Iter   181/  229] train: loss: 0.1381554
[Epoch 42; Iter   211/  229] train: loss: 0.1729339
[Epoch 42] ogbg-moltoxcast: 0.686341 val loss: 0.273298
[Epoch 42] ogbg-moltoxcast: 0.664200 test loss: 0.318468
[Epoch 43; Iter    12/  229] train: loss: 0.1806666
[Epoch 43; Iter    42/  229] train: loss: 0.1629197
[Epoch 43; Iter    72/  229] train: loss: 0.1769907
[Epoch 43; Iter   102/  229] train: loss: 0.1576435
[Epoch 43; Iter   132/  229] train: loss: 0.1200630
[Epoch 43; Iter   162/  229] train: loss: 0.1813323
[Epoch 43; Iter   192/  229] train: loss: 0.1086441
[Epoch 43; Iter   222/  229] train: loss: 0.1453402
[Epoch 43] ogbg-moltoxcast: 0.691405 val loss: 0.262435
[Epoch 43] ogbg-moltoxcast: 0.674789 test loss: 0.316845
[Epoch 28; Iter    27/  229] train: loss: 0.1925786
[Epoch 28; Iter    57/  229] train: loss: 0.1595028
[Epoch 28; Iter    87/  229] train: loss: 0.1800554
[Epoch 28; Iter   117/  229] train: loss: 0.2105516
[Epoch 28; Iter   147/  229] train: loss: 0.1822723
[Epoch 28; Iter   177/  229] train: loss: 0.1791518
[Epoch 28; Iter   207/  229] train: loss: 0.1925781
[Epoch 28] ogbg-moltoxcast: 0.684553 val loss: 0.259030
[Epoch 28] ogbg-moltoxcast: 0.653608 test loss: 0.363917
[Epoch 29; Iter     8/  229] train: loss: 0.1429334
[Epoch 29; Iter    38/  229] train: loss: 0.1437615
[Epoch 29; Iter    68/  229] train: loss: 0.2161614
[Epoch 29; Iter    98/  229] train: loss: 0.2025835
[Epoch 29; Iter   128/  229] train: loss: 0.2481279
[Epoch 29; Iter   158/  229] train: loss: 0.1660324
[Epoch 29; Iter   188/  229] train: loss: 0.2363467
[Epoch 29; Iter   218/  229] train: loss: 0.1465586
[Epoch 29] ogbg-moltoxcast: 0.698469 val loss: 0.254121
[Epoch 29] ogbg-moltoxcast: 0.650189 test loss: 0.307441
[Epoch 30; Iter    19/  229] train: loss: 0.1608950
[Epoch 30; Iter    49/  229] train: loss: 0.1969116
[Epoch 30; Iter    79/  229] train: loss: 0.1226632
[Epoch 30; Iter   109/  229] train: loss: 0.1326018
[Epoch 30; Iter   139/  229] train: loss: 0.1446076
[Epoch 30; Iter   169/  229] train: loss: 0.1511888
[Epoch 30; Iter   199/  229] train: loss: 0.1247353
[Epoch 30; Iter   229/  229] train: loss: 0.2397972
[Epoch 30] ogbg-moltoxcast: 0.700574 val loss: 0.254013
[Epoch 30] ogbg-moltoxcast: 0.660823 test loss: 0.327957
[Epoch 31; Iter    30/  229] train: loss: 0.1524153
[Epoch 31; Iter    60/  229] train: loss: 0.1648215
[Epoch 31; Iter    90/  229] train: loss: 0.1324331
[Epoch 31; Iter   120/  229] train: loss: 0.1061300
[Epoch 31; Iter   150/  229] train: loss: 0.2193903
[Epoch 31; Iter   180/  229] train: loss: 0.1447937
[Epoch 31; Iter   210/  229] train: loss: 0.0742751
[Epoch 31] ogbg-moltoxcast: 0.697360 val loss: 0.256777
[Epoch 31] ogbg-moltoxcast: 0.657457 test loss: 0.676623
[Epoch 32; Iter    11/  229] train: loss: 0.1755378
[Epoch 32; Iter    41/  229] train: loss: 0.1258533
[Epoch 32; Iter    71/  229] train: loss: 0.1098543
[Epoch 32; Iter   101/  229] train: loss: 0.1419703
[Epoch 32; Iter   131/  229] train: loss: 0.1656282
[Epoch 32; Iter   161/  229] train: loss: 0.1377203
[Epoch 32; Iter   191/  229] train: loss: 0.1608735
[Epoch 32; Iter   221/  229] train: loss: 0.1027992
[Epoch 32] ogbg-moltoxcast: 0.709292 val loss: 0.247067
[Epoch 32] ogbg-moltoxcast: 0.666236 test loss: 0.303336
[Epoch 33; Iter    22/  229] train: loss: 0.1957885
[Epoch 33; Iter    52/  229] train: loss: 0.1651648
[Epoch 33; Iter    82/  229] train: loss: 0.1596077
[Epoch 33; Iter   112/  229] train: loss: 0.1456908
[Epoch 33; Iter   142/  229] train: loss: 0.1558498
[Epoch 33; Iter   172/  229] train: loss: 0.1175703
[Epoch 33; Iter   202/  229] train: loss: 0.1267032
[Epoch 33] ogbg-moltoxcast: 0.702301 val loss: 0.252022
[Epoch 33] ogbg-moltoxcast: 0.662137 test loss: 0.360103
[Epoch 34; Iter     3/  229] train: loss: 0.1381051
[Epoch 34; Iter    33/  229] train: loss: 0.2097383
[Epoch 34; Iter    63/  229] train: loss: 0.1704188
[Epoch 34; Iter    93/  229] train: loss: 0.1946779
[Epoch 34; Iter   123/  229] train: loss: 0.1210318
[Epoch 34; Iter   153/  229] train: loss: 0.1254593
[Epoch 34; Iter   183/  229] train: loss: 0.1811996
[Epoch 34; Iter   213/  229] train: loss: 0.1864676
[Epoch 34] ogbg-moltoxcast: 0.696641 val loss: 0.259101
[Epoch 34] ogbg-moltoxcast: 0.663382 test loss: 0.306652
[Epoch 35; Iter    14/  229] train: loss: 0.1731301
[Epoch 35; Iter    44/  229] train: loss: 0.1325494
[Epoch 35; Iter    74/  229] train: loss: 0.1587889
[Epoch 35; Iter   104/  229] train: loss: 0.2859164
[Epoch 35; Iter   134/  229] train: loss: 0.1382793
[Epoch 35; Iter   164/  229] train: loss: 0.1638472
[Epoch 35; Iter   194/  229] train: loss: 0.1513724
[Epoch 35; Iter   224/  229] train: loss: 0.1326578
[Epoch 35] ogbg-moltoxcast: 0.692356 val loss: 0.254148
[Epoch 35] ogbg-moltoxcast: 0.662300 test loss: 0.334874
[Epoch 36; Iter    25/  229] train: loss: 0.1489340
[Epoch 36; Iter    55/  229] train: loss: 0.1811849
[Epoch 36; Iter    85/  229] train: loss: 0.1455876
[Epoch 36; Iter   115/  229] train: loss: 0.1224791
[Epoch 36; Iter   145/  229] train: loss: 0.1271771
[Epoch 36; Iter   175/  229] train: loss: 0.1363749
[Epoch 36; Iter   205/  229] train: loss: 0.1791421
[Epoch 36] ogbg-moltoxcast: 0.704920 val loss: 0.256072
[Epoch 36] ogbg-moltoxcast: 0.657872 test loss: 0.444895
[Epoch 37; Iter     6/  229] train: loss: 0.1558123
[Epoch 37; Iter    36/  229] train: loss: 0.2190409
[Epoch 37; Iter    66/  229] train: loss: 0.1351099
[Epoch 37; Iter    96/  229] train: loss: 0.1627539
[Epoch 37; Iter   126/  229] train: loss: 0.1355573
[Epoch 37; Iter   156/  229] train: loss: 0.1610435
[Epoch 37; Iter   186/  229] train: loss: 0.1156839
[Epoch 37; Iter   216/  229] train: loss: 0.1389119
[Epoch 37] ogbg-moltoxcast: 0.707058 val loss: 0.248334
[Epoch 37] ogbg-moltoxcast: 0.661654 test loss: 0.764672
[Epoch 38; Iter    17/  229] train: loss: 0.1749801
[Epoch 38; Iter    47/  229] train: loss: 0.1478483
[Epoch 38; Iter    77/  229] train: loss: 0.1395016
[Epoch 38; Iter   107/  229] train: loss: 0.1592984
[Epoch 38; Iter   137/  229] train: loss: 0.1198601
[Epoch 38; Iter   167/  229] train: loss: 0.1211964
[Epoch 38; Iter   197/  229] train: loss: 0.1942409
[Epoch 38; Iter   227/  229] train: loss: 0.1259851
[Epoch 38] ogbg-moltoxcast: 0.705648 val loss: 0.244387
[Epoch 38] ogbg-moltoxcast: 0.661154 test loss: 0.397628
[Epoch 39; Iter    28/  229] train: loss: 0.1733765
[Epoch 39; Iter    58/  229] train: loss: 0.1468811
[Epoch 39; Iter    88/  229] train: loss: 0.1492733
[Epoch 39; Iter   118/  229] train: loss: 0.1970173
[Epoch 39; Iter   148/  229] train: loss: 0.1517946
[Epoch 39; Iter   178/  229] train: loss: 0.1643281
[Epoch 39; Iter   208/  229] train: loss: 0.1558961
[Epoch 39] ogbg-moltoxcast: 0.703943 val loss: 0.249078
[Epoch 39] ogbg-moltoxcast: 0.667134 test loss: 0.647120
[Epoch 40; Iter     9/  229] train: loss: 0.1373290
[Epoch 40; Iter    39/  229] train: loss: 0.1916775
[Epoch 40; Iter    69/  229] train: loss: 0.1680588
[Epoch 40; Iter    99/  229] train: loss: 0.0845104
[Epoch 40; Iter   129/  229] train: loss: 0.1726379
[Epoch 40; Iter   159/  229] train: loss: 0.1111011
[Epoch 40; Iter   189/  229] train: loss: 0.1177795
[Epoch 40; Iter   219/  229] train: loss: 0.1661480
[Epoch 40] ogbg-moltoxcast: 0.704174 val loss: 0.252424
[Epoch 40] ogbg-moltoxcast: 0.660712 test loss: 0.403787
[Epoch 41; Iter    20/  229] train: loss: 0.1311546
[Epoch 41; Iter    50/  229] train: loss: 0.1675302
[Epoch 41; Iter    80/  229] train: loss: 0.1647170
[Epoch 41; Iter   110/  229] train: loss: 0.1752301
[Epoch 41; Iter   140/  229] train: loss: 0.1451851
[Epoch 41; Iter   170/  229] train: loss: 0.1321089
[Epoch 41; Iter   200/  229] train: loss: 0.1755046
[Epoch 41] ogbg-moltoxcast: 0.705373 val loss: 0.247146
[Epoch 41] ogbg-moltoxcast: 0.667655 test loss: 0.310026
[Epoch 42; Iter     1/  229] train: loss: 0.1893726
[Epoch 42; Iter    31/  229] train: loss: 0.1154804
[Epoch 42; Iter    61/  229] train: loss: 0.1242655
[Epoch 42; Iter    91/  229] train: loss: 0.1738638
[Epoch 42; Iter   121/  229] train: loss: 0.1230159
[Epoch 42; Iter   151/  229] train: loss: 0.1372776
[Epoch 42; Iter   181/  229] train: loss: 0.2454573
[Epoch 42; Iter   211/  229] train: loss: 0.1222537
[Epoch 42] ogbg-moltoxcast: 0.708702 val loss: 0.252773
[Epoch 42] ogbg-moltoxcast: 0.657834 test loss: 0.596618
[Epoch 43; Iter    12/  229] train: loss: 0.1338737
[Epoch 43; Iter    42/  229] train: loss: 0.1459155
[Epoch 43; Iter    72/  229] train: loss: 0.1951755
[Epoch 43; Iter   102/  229] train: loss: 0.1437195
[Epoch 43; Iter   132/  229] train: loss: 0.1309483
[Epoch 43; Iter   162/  229] train: loss: 0.1499796
[Epoch 43; Iter   192/  229] train: loss: 0.1712449
[Epoch 43; Iter   222/  229] train: loss: 0.1594795
[Epoch 43] ogbg-moltoxcast: 0.708289 val loss: 0.247027
[Epoch 43] ogbg-moltoxcast: 0.664654 test loss: 0.419051
[Epoch 30] ogbg-moltoxcast: 0.653075 test loss: 0.301535
[Epoch 31; Iter    30/  201] train: loss: 0.1349077
[Epoch 31; Iter    60/  201] train: loss: 0.1785483
[Epoch 31; Iter    90/  201] train: loss: 0.1869231
[Epoch 31; Iter   120/  201] train: loss: 0.1561372
[Epoch 31; Iter   150/  201] train: loss: 0.1436585
[Epoch 31; Iter   180/  201] train: loss: 0.1596130
[Epoch 31] ogbg-moltoxcast: 0.674685 val loss: 0.260128
[Epoch 31] ogbg-moltoxcast: 0.657924 test loss: 0.753443
[Epoch 32; Iter     9/  201] train: loss: 0.1422248
[Epoch 32; Iter    39/  201] train: loss: 0.1671970
[Epoch 32; Iter    69/  201] train: loss: 0.2543828
[Epoch 32; Iter    99/  201] train: loss: 0.2026253
[Epoch 32; Iter   129/  201] train: loss: 0.1397339
[Epoch 32; Iter   159/  201] train: loss: 0.0990367
[Epoch 32; Iter   189/  201] train: loss: 0.0968363
[Epoch 32] ogbg-moltoxcast: 0.661432 val loss: 0.262248
[Epoch 32] ogbg-moltoxcast: 0.653360 test loss: 0.298195
[Epoch 33; Iter    18/  201] train: loss: 0.1638627
[Epoch 33; Iter    48/  201] train: loss: 0.1649436
[Epoch 33; Iter    78/  201] train: loss: 0.1375486
[Epoch 33; Iter   108/  201] train: loss: 0.0916255
[Epoch 33; Iter   138/  201] train: loss: 0.1617803
[Epoch 33; Iter   168/  201] train: loss: 0.1186188
[Epoch 33; Iter   198/  201] train: loss: 0.1739926
[Epoch 33] ogbg-moltoxcast: 0.663415 val loss: 0.287726
[Epoch 33] ogbg-moltoxcast: 0.654956 test loss: 0.443903
[Epoch 34; Iter    27/  201] train: loss: 0.1273060
[Epoch 34; Iter    57/  201] train: loss: 0.1319183
[Epoch 34; Iter    87/  201] train: loss: 0.1478988
[Epoch 34; Iter   117/  201] train: loss: 0.2103287
[Epoch 34; Iter   147/  201] train: loss: 0.1673116
[Epoch 34; Iter   177/  201] train: loss: 0.1021651
[Epoch 34] ogbg-moltoxcast: 0.671395 val loss: 0.272371
[Epoch 34] ogbg-moltoxcast: 0.663577 test loss: 0.546319
[Epoch 35; Iter     6/  201] train: loss: 0.1565456
[Epoch 35; Iter    36/  201] train: loss: 0.2069083
[Epoch 35; Iter    66/  201] train: loss: 0.1712554
[Epoch 35; Iter    96/  201] train: loss: 0.2354042
[Epoch 35; Iter   126/  201] train: loss: 0.1292305
[Epoch 35; Iter   156/  201] train: loss: 0.1911213
[Epoch 35; Iter   186/  201] train: loss: 0.1563479
[Epoch 35] ogbg-moltoxcast: 0.672339 val loss: 0.301094
[Epoch 35] ogbg-moltoxcast: 0.662312 test loss: 0.431077
[Epoch 36; Iter    15/  201] train: loss: 0.2391632
[Epoch 36; Iter    45/  201] train: loss: 0.1244710
[Epoch 36; Iter    75/  201] train: loss: 0.1067054
[Epoch 36; Iter   105/  201] train: loss: 0.1495923
[Epoch 36; Iter   135/  201] train: loss: 0.1351116
[Epoch 36; Iter   165/  201] train: loss: 0.1345189
[Epoch 36; Iter   195/  201] train: loss: 0.1350667
[Epoch 36] ogbg-moltoxcast: 0.680305 val loss: 0.255677
[Epoch 36] ogbg-moltoxcast: 0.671427 test loss: 0.292071
[Epoch 37; Iter    24/  201] train: loss: 0.2317511
[Epoch 37; Iter    54/  201] train: loss: 0.1655882
[Epoch 37; Iter    84/  201] train: loss: 0.1803028
[Epoch 37; Iter   114/  201] train: loss: 0.1548048
[Epoch 37; Iter   144/  201] train: loss: 0.1509542
[Epoch 37; Iter   174/  201] train: loss: 0.1744068
[Epoch 37] ogbg-moltoxcast: 0.668753 val loss: 0.257469
[Epoch 37] ogbg-moltoxcast: 0.668031 test loss: 0.294249
[Epoch 38; Iter     3/  201] train: loss: 0.1180123
[Epoch 38; Iter    33/  201] train: loss: 0.1670281
[Epoch 38; Iter    63/  201] train: loss: 0.1842815
[Epoch 38; Iter    93/  201] train: loss: 0.1395422
[Epoch 38; Iter   123/  201] train: loss: 0.2016085
[Epoch 38; Iter   153/  201] train: loss: 0.1285151
[Epoch 38; Iter   183/  201] train: loss: 0.0943102
[Epoch 38] ogbg-moltoxcast: 0.666533 val loss: 0.258604
[Epoch 38] ogbg-moltoxcast: 0.664126 test loss: 0.297710
[Epoch 39; Iter    12/  201] train: loss: 0.1960222
[Epoch 39; Iter    42/  201] train: loss: 0.1084858
[Epoch 39; Iter    72/  201] train: loss: 0.1841392
[Epoch 39; Iter   102/  201] train: loss: 0.1482271
[Epoch 39; Iter   132/  201] train: loss: 0.1606217
[Epoch 39; Iter   162/  201] train: loss: 0.1932800
[Epoch 39; Iter   192/  201] train: loss: 0.1676017
[Epoch 39] ogbg-moltoxcast: 0.672309 val loss: 0.260181
[Epoch 39] ogbg-moltoxcast: 0.666407 test loss: 0.302693
[Epoch 40; Iter    21/  201] train: loss: 0.0956633
[Epoch 40; Iter    51/  201] train: loss: 0.1315005
[Epoch 40; Iter    81/  201] train: loss: 0.1116414
[Epoch 40; Iter   111/  201] train: loss: 0.1420451
[Epoch 40; Iter   141/  201] train: loss: 0.1462461
[Epoch 40; Iter   171/  201] train: loss: 0.1320076
[Epoch 40; Iter   201/  201] train: loss: 0.0638187
[Epoch 40] ogbg-moltoxcast: 0.666783 val loss: 0.257945
[Epoch 40] ogbg-moltoxcast: 0.661217 test loss: 0.297354
[Epoch 41; Iter    30/  201] train: loss: 0.1525488
[Epoch 41; Iter    60/  201] train: loss: 0.1899808
[Epoch 41; Iter    90/  201] train: loss: 0.1687406
[Epoch 41; Iter   120/  201] train: loss: 0.1627865
[Epoch 41; Iter   150/  201] train: loss: 0.2032976
[Epoch 41; Iter   180/  201] train: loss: 0.1676707
[Epoch 41] ogbg-moltoxcast: 0.673808 val loss: 0.257866
[Epoch 41] ogbg-moltoxcast: 0.665483 test loss: 0.293406
[Epoch 42; Iter     9/  201] train: loss: 0.1859229
[Epoch 42; Iter    39/  201] train: loss: 0.1064594
[Epoch 42; Iter    69/  201] train: loss: 0.1244264
[Epoch 42; Iter    99/  201] train: loss: 0.1152194
[Epoch 42; Iter   129/  201] train: loss: 0.1519613
[Epoch 42; Iter   159/  201] train: loss: 0.1657865
[Epoch 42; Iter   189/  201] train: loss: 0.1098394
[Epoch 42] ogbg-moltoxcast: 0.675429 val loss: 0.260253
[Epoch 42] ogbg-moltoxcast: 0.673547 test loss: 0.299178
[Epoch 43; Iter    18/  201] train: loss: 0.1208373
[Epoch 43; Iter    48/  201] train: loss: 0.1123296
[Epoch 43; Iter    78/  201] train: loss: 0.1665764
[Epoch 43; Iter   108/  201] train: loss: 0.1682539
[Epoch 43; Iter   138/  201] train: loss: 0.1193453
[Epoch 43; Iter   168/  201] train: loss: 0.1511735
[Epoch 43; Iter   198/  201] train: loss: 0.1729790
[Epoch 43] ogbg-moltoxcast: 0.677018 val loss: 0.261243
[Epoch 43] ogbg-moltoxcast: 0.669291 test loss: 0.303378
[Epoch 44; Iter    27/  201] train: loss: 0.1050576
[Epoch 44; Iter    57/  201] train: loss: 0.1426675
[Epoch 44; Iter    87/  201] train: loss: 0.1651552
[Epoch 44; Iter   117/  201] train: loss: 0.1608884
[Epoch 44; Iter   147/  201] train: loss: 0.1503179
[Epoch 44; Iter   177/  201] train: loss: 0.1143195
[Epoch 44] ogbg-moltoxcast: 0.670155 val loss: 0.257275
[Epoch 44] ogbg-moltoxcast: 0.673602 test loss: 0.295099
[Epoch 45; Iter     6/  201] train: loss: 0.2427990
[Epoch 45; Iter    36/  201] train: loss: 0.1380974
[Epoch 45; Iter    66/  201] train: loss: 0.1489415
[Epoch 45; Iter    96/  201] train: loss: 0.1463504
[Epoch 45; Iter   126/  201] train: loss: 0.1345072
[Epoch 45; Iter   156/  201] train: loss: 0.1186405
[Epoch 45; Iter   186/  201] train: loss: 0.1415967
[Epoch 45] ogbg-moltoxcast: 0.670043 val loss: 0.266297
[Epoch 45] ogbg-moltoxcast: 0.669262 test loss: 0.304378
[Epoch 46; Iter    15/  201] train: loss: 0.1128030
[Epoch 46; Iter    45/  201] train: loss: 0.1032193
[Epoch 46; Iter    75/  201] train: loss: 0.1095535
[Epoch 46; Iter   105/  201] train: loss: 0.1935004
[Epoch 46; Iter   135/  201] train: loss: 0.1181539
[Epoch 46; Iter   165/  201] train: loss: 0.1388338
[Epoch 46; Iter   195/  201] train: loss: 0.1440270
[Epoch 46] ogbg-moltoxcast: 0.676667 val loss: 0.260411
[Epoch 46] ogbg-moltoxcast: 0.672024 test loss: 0.300163
[Epoch 47; Iter    24/  201] train: loss: 0.1793540
[Epoch 47; Iter    54/  201] train: loss: 0.1248166
[Epoch 47; Iter    84/  201] train: loss: 0.1728128
[Epoch 47; Iter   114/  201] train: loss: 0.1087281
[Epoch 47; Iter   144/  201] train: loss: 0.1784940
[Epoch 47; Iter   174/  201] train: loss: 0.1612852
[Epoch 47] ogbg-moltoxcast: 0.677352 val loss: 0.263917
[Epoch 47] ogbg-moltoxcast: 0.674178 test loss: 0.305122
[Epoch 48; Iter     3/  201] train: loss: 0.1677035
[Epoch 48; Iter    33/  201] train: loss: 0.1540843
[Epoch 48; Iter    63/  201] train: loss: 0.1202508
[Epoch 48; Iter    93/  201] train: loss: 0.1143404
[Epoch 48; Iter   123/  201] train: loss: 0.1905120
[Epoch 48; Iter   153/  201] train: loss: 0.1420972
[Epoch 30] ogbg-moltoxcast: 0.653203 test loss: 0.292756
[Epoch 31; Iter    30/  201] train: loss: 0.1279023
[Epoch 31; Iter    60/  201] train: loss: 0.1737037
[Epoch 31; Iter    90/  201] train: loss: 0.2130272
[Epoch 31; Iter   120/  201] train: loss: 0.1429501
[Epoch 31; Iter   150/  201] train: loss: 0.1253574
[Epoch 31; Iter   180/  201] train: loss: 0.1816168
[Epoch 31] ogbg-moltoxcast: 0.675646 val loss: 0.255498
[Epoch 31] ogbg-moltoxcast: 0.661366 test loss: 0.296859
[Epoch 32; Iter     9/  201] train: loss: 0.1255436
[Epoch 32; Iter    39/  201] train: loss: 0.1229460
[Epoch 32; Iter    69/  201] train: loss: 0.1416730
[Epoch 32; Iter    99/  201] train: loss: 0.1656782
[Epoch 32; Iter   129/  201] train: loss: 0.1723502
[Epoch 32; Iter   159/  201] train: loss: 0.1450029
[Epoch 32; Iter   189/  201] train: loss: 0.1415044
[Epoch 32] ogbg-moltoxcast: 0.668309 val loss: 0.258779
[Epoch 32] ogbg-moltoxcast: 0.671464 test loss: 0.295660
[Epoch 33; Iter    18/  201] train: loss: 0.1485158
[Epoch 33; Iter    48/  201] train: loss: 0.1443649
[Epoch 33; Iter    78/  201] train: loss: 0.1827679
[Epoch 33; Iter   108/  201] train: loss: 0.1424340
[Epoch 33; Iter   138/  201] train: loss: 0.1060497
[Epoch 33; Iter   168/  201] train: loss: 0.1794114
[Epoch 33; Iter   198/  201] train: loss: 0.1637506
[Epoch 33] ogbg-moltoxcast: 0.663871 val loss: 0.261986
[Epoch 33] ogbg-moltoxcast: 0.670313 test loss: 0.301447
[Epoch 34; Iter    27/  201] train: loss: 0.1561125
[Epoch 34; Iter    57/  201] train: loss: 0.1691313
[Epoch 34; Iter    87/  201] train: loss: 0.1877515
[Epoch 34; Iter   117/  201] train: loss: 0.1107324
[Epoch 34; Iter   147/  201] train: loss: 0.1876383
[Epoch 34; Iter   177/  201] train: loss: 0.1059746
[Epoch 34] ogbg-moltoxcast: 0.666217 val loss: 0.254789
[Epoch 34] ogbg-moltoxcast: 0.663755 test loss: 0.289541
[Epoch 35; Iter     6/  201] train: loss: 0.1271706
[Epoch 35; Iter    36/  201] train: loss: 0.1454865
[Epoch 35; Iter    66/  201] train: loss: 0.2313440
[Epoch 35; Iter    96/  201] train: loss: 0.1118171
[Epoch 35; Iter   126/  201] train: loss: 0.1795884
[Epoch 35; Iter   156/  201] train: loss: 0.1093653
[Epoch 35; Iter   186/  201] train: loss: 0.1195431
[Epoch 35] ogbg-moltoxcast: 0.666663 val loss: 0.278065
[Epoch 35] ogbg-moltoxcast: 0.670756 test loss: 0.321173
[Epoch 36; Iter    15/  201] train: loss: 0.1861091
[Epoch 36; Iter    45/  201] train: loss: 0.1080825
[Epoch 36; Iter    75/  201] train: loss: 0.1622558
[Epoch 36; Iter   105/  201] train: loss: 0.1148501
[Epoch 36; Iter   135/  201] train: loss: 0.1383303
[Epoch 36; Iter   165/  201] train: loss: 0.1310602
[Epoch 36; Iter   195/  201] train: loss: 0.1092530
[Epoch 36] ogbg-moltoxcast: 0.669025 val loss: 0.258710
[Epoch 36] ogbg-moltoxcast: 0.666869 test loss: 0.299571
[Epoch 37; Iter    24/  201] train: loss: 0.1711422
[Epoch 37; Iter    54/  201] train: loss: 0.1351967
[Epoch 37; Iter    84/  201] train: loss: 0.1678590
[Epoch 37; Iter   114/  201] train: loss: 0.1497502
[Epoch 37; Iter   144/  201] train: loss: 0.1874523
[Epoch 37; Iter   174/  201] train: loss: 0.1446887
[Epoch 37] ogbg-moltoxcast: 0.672712 val loss: 0.261299
[Epoch 37] ogbg-moltoxcast: 0.668850 test loss: 0.299279
[Epoch 38; Iter     3/  201] train: loss: 0.1320684
[Epoch 38; Iter    33/  201] train: loss: 0.1470233
[Epoch 38; Iter    63/  201] train: loss: 0.1478698
[Epoch 38; Iter    93/  201] train: loss: 0.1420962
[Epoch 38; Iter   123/  201] train: loss: 0.1521166
[Epoch 38; Iter   153/  201] train: loss: 0.2129186
[Epoch 38; Iter   183/  201] train: loss: 0.1955484
[Epoch 38] ogbg-moltoxcast: 0.676328 val loss: 0.253813
[Epoch 38] ogbg-moltoxcast: 0.673097 test loss: 0.292385
[Epoch 39; Iter    12/  201] train: loss: 0.1273626
[Epoch 39; Iter    42/  201] train: loss: 0.1778345
[Epoch 39; Iter    72/  201] train: loss: 0.2623248
[Epoch 39; Iter   102/  201] train: loss: 0.1789201
[Epoch 39; Iter   132/  201] train: loss: 0.1391675
[Epoch 39; Iter   162/  201] train: loss: 0.2135305
[Epoch 39; Iter   192/  201] train: loss: 0.1101759
[Epoch 39] ogbg-moltoxcast: 0.676971 val loss: 0.253952
[Epoch 39] ogbg-moltoxcast: 0.672220 test loss: 0.287090
[Epoch 40; Iter    21/  201] train: loss: 0.1718353
[Epoch 40; Iter    51/  201] train: loss: 0.1216961
[Epoch 40; Iter    81/  201] train: loss: 0.1913460
[Epoch 40; Iter   111/  201] train: loss: 0.1182912
[Epoch 40; Iter   141/  201] train: loss: 0.1475062
[Epoch 40; Iter   171/  201] train: loss: 0.1509900
[Epoch 40; Iter   201/  201] train: loss: 0.3264777
[Epoch 40] ogbg-moltoxcast: 0.674310 val loss: 0.260869
[Epoch 40] ogbg-moltoxcast: 0.658827 test loss: 0.305342
[Epoch 41; Iter    30/  201] train: loss: 0.2150025
[Epoch 41; Iter    60/  201] train: loss: 0.1950141
[Epoch 41; Iter    90/  201] train: loss: 0.1003707
[Epoch 41; Iter   120/  201] train: loss: 0.1479614
[Epoch 41; Iter   150/  201] train: loss: 0.1257506
[Epoch 41; Iter   180/  201] train: loss: 0.1610249
[Epoch 41] ogbg-moltoxcast: 0.678341 val loss: 0.256336
[Epoch 41] ogbg-moltoxcast: 0.670421 test loss: 0.294929
[Epoch 42; Iter     9/  201] train: loss: 0.1345588
[Epoch 42; Iter    39/  201] train: loss: 0.1256607
[Epoch 42; Iter    69/  201] train: loss: 0.1720155
[Epoch 42; Iter    99/  201] train: loss: 0.0998073
[Epoch 42; Iter   129/  201] train: loss: 0.1396591
[Epoch 42; Iter   159/  201] train: loss: 0.1211679
[Epoch 42; Iter   189/  201] train: loss: 0.1842895
[Epoch 42] ogbg-moltoxcast: 0.685789 val loss: 0.251563
[Epoch 42] ogbg-moltoxcast: 0.677632 test loss: 0.290383
[Epoch 43; Iter    18/  201] train: loss: 0.1759563
[Epoch 43; Iter    48/  201] train: loss: 0.1472149
[Epoch 43; Iter    78/  201] train: loss: 0.1133577
[Epoch 43; Iter   108/  201] train: loss: 0.1408519
[Epoch 43; Iter   138/  201] train: loss: 0.1361007
[Epoch 43; Iter   168/  201] train: loss: 0.1108990
[Epoch 43; Iter   198/  201] train: loss: 0.1837204
[Epoch 43] ogbg-moltoxcast: 0.678944 val loss: 0.261449
[Epoch 43] ogbg-moltoxcast: 0.677454 test loss: 0.300385
[Epoch 44; Iter    27/  201] train: loss: 0.1123593
[Epoch 44; Iter    57/  201] train: loss: 0.1284339
[Epoch 44; Iter    87/  201] train: loss: 0.1587468
[Epoch 44; Iter   117/  201] train: loss: 0.2072860
[Epoch 44; Iter   147/  201] train: loss: 0.1529536
[Epoch 44; Iter   177/  201] train: loss: 0.1206299
[Epoch 44] ogbg-moltoxcast: 0.671815 val loss: 0.267449
[Epoch 44] ogbg-moltoxcast: 0.674858 test loss: 0.304308
[Epoch 45; Iter     6/  201] train: loss: 0.2029961
[Epoch 45; Iter    36/  201] train: loss: 0.1371141
[Epoch 45; Iter    66/  201] train: loss: 0.1141235
[Epoch 45; Iter    96/  201] train: loss: 0.1968583
[Epoch 45; Iter   126/  201] train: loss: 0.1526414
[Epoch 45; Iter   156/  201] train: loss: 0.1202954
[Epoch 45; Iter   186/  201] train: loss: 0.1600466
[Epoch 45] ogbg-moltoxcast: 0.675401 val loss: 0.266266
[Epoch 45] ogbg-moltoxcast: 0.664892 test loss: 0.304655
[Epoch 46; Iter    15/  201] train: loss: 0.1504273
[Epoch 46; Iter    45/  201] train: loss: 0.1105684
[Epoch 46; Iter    75/  201] train: loss: 0.1458830
[Epoch 46; Iter   105/  201] train: loss: 0.1664170
[Epoch 46; Iter   135/  201] train: loss: 0.1666453
[Epoch 46; Iter   165/  201] train: loss: 0.1528931
[Epoch 46; Iter   195/  201] train: loss: 0.1982198
[Epoch 46] ogbg-moltoxcast: 0.677255 val loss: 0.263961
[Epoch 46] ogbg-moltoxcast: 0.675463 test loss: 0.301133
[Epoch 47; Iter    24/  201] train: loss: 0.1631580
[Epoch 47; Iter    54/  201] train: loss: 0.1448291
[Epoch 47; Iter    84/  201] train: loss: 0.1506904
[Epoch 47; Iter   114/  201] train: loss: 0.1342854
[Epoch 47; Iter   144/  201] train: loss: 0.1376385
[Epoch 47; Iter   174/  201] train: loss: 0.1282530
[Epoch 47] ogbg-moltoxcast: 0.680355 val loss: 0.261506
[Epoch 47] ogbg-moltoxcast: 0.671880 test loss: 0.301897
[Epoch 48; Iter     3/  201] train: loss: 0.1073458
[Epoch 48; Iter    33/  201] train: loss: 0.1569900
[Epoch 48; Iter    63/  201] train: loss: 0.0950912
[Epoch 48; Iter    93/  201] train: loss: 0.1156482
[Epoch 48; Iter   123/  201] train: loss: 0.1647917
[Epoch 48; Iter   153/  201] train: loss: 0.1942589
[Epoch 30] ogbg-moltoxcast: 0.657665 test loss: 0.323520
[Epoch 31; Iter    30/  201] train: loss: 0.1200328
[Epoch 31; Iter    60/  201] train: loss: 0.1428767
[Epoch 31; Iter    90/  201] train: loss: 0.1479161
[Epoch 31; Iter   120/  201] train: loss: 0.1357256
[Epoch 31; Iter   150/  201] train: loss: 0.1840937
[Epoch 31; Iter   180/  201] train: loss: 0.1698062
[Epoch 31] ogbg-moltoxcast: 0.673338 val loss: 0.272275
[Epoch 31] ogbg-moltoxcast: 0.662519 test loss: 0.322147
[Epoch 32; Iter     9/  201] train: loss: 0.1372816
[Epoch 32; Iter    39/  201] train: loss: 0.1311632
[Epoch 32; Iter    69/  201] train: loss: 0.1203666
[Epoch 32; Iter    99/  201] train: loss: 0.1064263
[Epoch 32; Iter   129/  201] train: loss: 0.1615882
[Epoch 32; Iter   159/  201] train: loss: 0.1187931
[Epoch 32; Iter   189/  201] train: loss: 0.1328267
[Epoch 32] ogbg-moltoxcast: 0.669635 val loss: 0.257175
[Epoch 32] ogbg-moltoxcast: 0.662333 test loss: 0.303358
[Epoch 33; Iter    18/  201] train: loss: 0.1438982
[Epoch 33; Iter    48/  201] train: loss: 0.1517566
[Epoch 33; Iter    78/  201] train: loss: 0.1225227
[Epoch 33; Iter   108/  201] train: loss: 0.0969940
[Epoch 33; Iter   138/  201] train: loss: 0.1583531
[Epoch 33; Iter   168/  201] train: loss: 0.2103582
[Epoch 33; Iter   198/  201] train: loss: 0.1672643
[Epoch 33] ogbg-moltoxcast: 0.649169 val loss: 0.316232
[Epoch 33] ogbg-moltoxcast: 0.646375 test loss: 0.342726
[Epoch 34; Iter    27/  201] train: loss: 0.1570318
[Epoch 34; Iter    57/  201] train: loss: 0.1777488
[Epoch 34; Iter    87/  201] train: loss: 0.0980912
[Epoch 34; Iter   117/  201] train: loss: 0.1513090
[Epoch 34; Iter   147/  201] train: loss: 0.1713646
[Epoch 34; Iter   177/  201] train: loss: 0.1085828
[Epoch 34] ogbg-moltoxcast: 0.659381 val loss: 0.277552
[Epoch 34] ogbg-moltoxcast: 0.633752 test loss: 0.323012
[Epoch 35; Iter     6/  201] train: loss: 0.1752784
[Epoch 35; Iter    36/  201] train: loss: 0.1260176
[Epoch 35; Iter    66/  201] train: loss: 0.1387964
[Epoch 35; Iter    96/  201] train: loss: 0.1691031
[Epoch 35; Iter   126/  201] train: loss: 0.1423852
[Epoch 35; Iter   156/  201] train: loss: 0.1910751
[Epoch 35; Iter   186/  201] train: loss: 0.1107742
[Epoch 35] ogbg-moltoxcast: 0.662740 val loss: 0.269896
[Epoch 35] ogbg-moltoxcast: 0.658999 test loss: 0.311430
[Epoch 36; Iter    15/  201] train: loss: 0.1197497
[Epoch 36; Iter    45/  201] train: loss: 0.1895054
[Epoch 36; Iter    75/  201] train: loss: 0.2414328
[Epoch 36; Iter   105/  201] train: loss: 0.1501316
[Epoch 36; Iter   135/  201] train: loss: 0.1103217
[Epoch 36; Iter   165/  201] train: loss: 0.1153396
[Epoch 36; Iter   195/  201] train: loss: 0.1106458
[Epoch 36] ogbg-moltoxcast: 0.654481 val loss: 0.262978
[Epoch 36] ogbg-moltoxcast: 0.649171 test loss: 0.302438
[Epoch 37; Iter    24/  201] train: loss: 0.1476970
[Epoch 37; Iter    54/  201] train: loss: 0.1798614
[Epoch 37; Iter    84/  201] train: loss: 0.1123572
[Epoch 37; Iter   114/  201] train: loss: 0.1555146
[Epoch 37; Iter   144/  201] train: loss: 0.1467288
[Epoch 37; Iter   174/  201] train: loss: 0.1646599
[Epoch 37] ogbg-moltoxcast: 0.676079 val loss: 0.257725
[Epoch 37] ogbg-moltoxcast: 0.664192 test loss: 0.297050
[Epoch 38; Iter     3/  201] train: loss: 0.1582519
[Epoch 38; Iter    33/  201] train: loss: 0.1255321
[Epoch 38; Iter    63/  201] train: loss: 0.1347210
[Epoch 38; Iter    93/  201] train: loss: 0.1019186
[Epoch 38; Iter   123/  201] train: loss: 0.0964418
[Epoch 38; Iter   153/  201] train: loss: 0.0781499
[Epoch 38; Iter   183/  201] train: loss: 0.1400404
[Epoch 38] ogbg-moltoxcast: 0.675637 val loss: 0.261360
[Epoch 38] ogbg-moltoxcast: 0.660080 test loss: 0.306761
[Epoch 39; Iter    12/  201] train: loss: 0.1306550
[Epoch 39; Iter    42/  201] train: loss: 0.1221765
[Epoch 39; Iter    72/  201] train: loss: 0.1234283
[Epoch 39; Iter   102/  201] train: loss: 0.1088276
[Epoch 39; Iter   132/  201] train: loss: 0.1618659
[Epoch 39; Iter   162/  201] train: loss: 0.1665809
[Epoch 39; Iter   192/  201] train: loss: 0.1190958
[Epoch 39] ogbg-moltoxcast: 0.672144 val loss: 0.263753
[Epoch 39] ogbg-moltoxcast: 0.665026 test loss: 0.305037
[Epoch 40; Iter    21/  201] train: loss: 0.1286049
[Epoch 40; Iter    51/  201] train: loss: 0.1371669
[Epoch 40; Iter    81/  201] train: loss: 0.1691844
[Epoch 40; Iter   111/  201] train: loss: 0.1443544
[Epoch 40; Iter   141/  201] train: loss: 0.1574655
[Epoch 40; Iter   171/  201] train: loss: 0.1536779
[Epoch 40; Iter   201/  201] train: loss: 0.2037623
[Epoch 40] ogbg-moltoxcast: 0.681605 val loss: 0.258156
[Epoch 40] ogbg-moltoxcast: 0.656799 test loss: 0.302563
[Epoch 41; Iter    30/  201] train: loss: 0.1645053
[Epoch 41; Iter    60/  201] train: loss: 0.1142282
[Epoch 41; Iter    90/  201] train: loss: 0.1705566
[Epoch 41; Iter   120/  201] train: loss: 0.1185699
[Epoch 41; Iter   150/  201] train: loss: 0.1132527
[Epoch 41; Iter   180/  201] train: loss: 0.1482989
[Epoch 41] ogbg-moltoxcast: 0.672494 val loss: 0.264820
[Epoch 41] ogbg-moltoxcast: 0.657806 test loss: 0.312212
[Epoch 42; Iter     9/  201] train: loss: 0.1135632
[Epoch 42; Iter    39/  201] train: loss: 0.1445758
[Epoch 42; Iter    69/  201] train: loss: 0.1394769
[Epoch 42; Iter    99/  201] train: loss: 0.1437586
[Epoch 42; Iter   129/  201] train: loss: 0.1408376
[Epoch 42; Iter   159/  201] train: loss: 0.1383599
[Epoch 42; Iter   189/  201] train: loss: 0.1620972
[Epoch 42] ogbg-moltoxcast: 0.677074 val loss: 0.256519
[Epoch 42] ogbg-moltoxcast: 0.656785 test loss: 0.300845
[Epoch 43; Iter    18/  201] train: loss: 0.1316209
[Epoch 43; Iter    48/  201] train: loss: 0.1230047
[Epoch 43; Iter    78/  201] train: loss: 0.1452729
[Epoch 43; Iter   108/  201] train: loss: 0.1236037
[Epoch 43; Iter   138/  201] train: loss: 0.1083187
[Epoch 43; Iter   168/  201] train: loss: 0.2013816
[Epoch 43; Iter   198/  201] train: loss: 0.1123443
[Epoch 43] ogbg-moltoxcast: 0.677558 val loss: 0.257730
[Epoch 43] ogbg-moltoxcast: 0.661944 test loss: 0.298904
[Epoch 44; Iter    27/  201] train: loss: 0.1409082
[Epoch 44; Iter    57/  201] train: loss: 0.1412186
[Epoch 44; Iter    87/  201] train: loss: 0.1261058
[Epoch 44; Iter   117/  201] train: loss: 0.1409095
[Epoch 44; Iter   147/  201] train: loss: 0.1001142
[Epoch 44; Iter   177/  201] train: loss: 0.2101613
[Epoch 44] ogbg-moltoxcast: 0.668596 val loss: 0.257770
[Epoch 44] ogbg-moltoxcast: 0.654990 test loss: 0.299141
[Epoch 45; Iter     6/  201] train: loss: 0.1930514
[Epoch 45; Iter    36/  201] train: loss: 0.0607328
[Epoch 45; Iter    66/  201] train: loss: 0.1506491
[Epoch 45; Iter    96/  201] train: loss: 0.1734928
[Epoch 45; Iter   126/  201] train: loss: 0.1428803
[Epoch 45; Iter   156/  201] train: loss: 0.1183584
[Epoch 45; Iter   186/  201] train: loss: 0.1926261
[Epoch 45] ogbg-moltoxcast: 0.665062 val loss: 0.270730
[Epoch 45] ogbg-moltoxcast: 0.655836 test loss: 0.318296
[Epoch 46; Iter    15/  201] train: loss: 0.1789130
[Epoch 46; Iter    45/  201] train: loss: 0.1328781
[Epoch 46; Iter    75/  201] train: loss: 0.1696428
[Epoch 46; Iter   105/  201] train: loss: 0.1787542
[Epoch 46; Iter   135/  201] train: loss: 0.1774361
[Epoch 46; Iter   165/  201] train: loss: 0.1516821
[Epoch 46; Iter   195/  201] train: loss: 0.1410384
[Epoch 46] ogbg-moltoxcast: 0.681381 val loss: 0.266592
[Epoch 46] ogbg-moltoxcast: 0.657927 test loss: 0.315539
[Epoch 47; Iter    24/  201] train: loss: 0.1520126
[Epoch 47; Iter    54/  201] train: loss: 0.1211313
[Epoch 47; Iter    84/  201] train: loss: 0.1038388
[Epoch 47; Iter   114/  201] train: loss: 0.1118404
[Epoch 47; Iter   144/  201] train: loss: 0.1337551
[Epoch 47; Iter   174/  201] train: loss: 0.1735707
[Epoch 47] ogbg-moltoxcast: 0.669430 val loss: 0.264653
[Epoch 47] ogbg-moltoxcast: 0.659859 test loss: 0.305621
[Epoch 48; Iter     3/  201] train: loss: 0.1170233
[Epoch 48; Iter    33/  201] train: loss: 0.1167407
[Epoch 48; Iter    63/  201] train: loss: 0.1576397
[Epoch 48; Iter    93/  201] train: loss: 0.1279390
[Epoch 48; Iter   123/  201] train: loss: 0.1843419
[Epoch 48; Iter   153/  201] train: loss: 0.1364025
[Epoch 34] ogbg-moltoxcast: 0.679558 val loss: 0.268887
[Epoch 34] ogbg-moltoxcast: 0.630578 test loss: 0.326952
[Epoch 35; Iter     2/  172] train: loss: 0.0994415
[Epoch 35; Iter    32/  172] train: loss: 0.1381845
[Epoch 35; Iter    62/  172] train: loss: 0.1106116
[Epoch 35; Iter    92/  172] train: loss: 0.1555085
[Epoch 35; Iter   122/  172] train: loss: 0.1155399
[Epoch 35; Iter   152/  172] train: loss: 0.0959022
[Epoch 35] ogbg-moltoxcast: 0.670167 val loss: 0.268495
[Epoch 35] ogbg-moltoxcast: 0.626414 test loss: 0.321179
[Epoch 36; Iter    10/  172] train: loss: 0.1436831
[Epoch 36; Iter    40/  172] train: loss: 0.1297876
[Epoch 36; Iter    70/  172] train: loss: 0.1317643
[Epoch 36; Iter   100/  172] train: loss: 0.2195952
[Epoch 36; Iter   130/  172] train: loss: 0.0858699
[Epoch 36; Iter   160/  172] train: loss: 0.1696890
[Epoch 36] ogbg-moltoxcast: 0.667911 val loss: 0.274410
[Epoch 36] ogbg-moltoxcast: 0.619980 test loss: 0.341653
[Epoch 37; Iter    18/  172] train: loss: 0.1327765
[Epoch 37; Iter    48/  172] train: loss: 0.1593432
[Epoch 37; Iter    78/  172] train: loss: 0.1111588
[Epoch 37; Iter   108/  172] train: loss: 0.1454724
[Epoch 37; Iter   138/  172] train: loss: 0.1627312
[Epoch 37; Iter   168/  172] train: loss: 0.1041993
[Epoch 37] ogbg-moltoxcast: 0.659531 val loss: 0.276021
[Epoch 37] ogbg-moltoxcast: 0.620898 test loss: 0.331514
[Epoch 38; Iter    26/  172] train: loss: 0.0975177
[Epoch 38; Iter    56/  172] train: loss: 0.1710770
[Epoch 38; Iter    86/  172] train: loss: 0.1148410
[Epoch 38; Iter   116/  172] train: loss: 0.1461851
[Epoch 38; Iter   146/  172] train: loss: 0.1278407
[Epoch 38] ogbg-moltoxcast: 0.672979 val loss: 0.272053
[Epoch 38] ogbg-moltoxcast: 0.628399 test loss: 0.334562
[Epoch 39; Iter     4/  172] train: loss: 0.1082201
[Epoch 39; Iter    34/  172] train: loss: 0.1114569
[Epoch 39; Iter    64/  172] train: loss: 0.1449340
[Epoch 39; Iter    94/  172] train: loss: 0.1464246
[Epoch 39; Iter   124/  172] train: loss: 0.1200896
[Epoch 39; Iter   154/  172] train: loss: 0.1343929
[Epoch 39] ogbg-moltoxcast: 0.668896 val loss: 0.272491
[Epoch 39] ogbg-moltoxcast: 0.626900 test loss: 0.334634
[Epoch 40; Iter    12/  172] train: loss: 0.1371830
[Epoch 40; Iter    42/  172] train: loss: 0.1646749
[Epoch 40; Iter    72/  172] train: loss: 0.1735785
[Epoch 40; Iter   102/  172] train: loss: 0.1401790
[Epoch 40; Iter   132/  172] train: loss: 0.1380336
[Epoch 40; Iter   162/  172] train: loss: 0.1152803
[Epoch 40] ogbg-moltoxcast: 0.659365 val loss: 0.275314
[Epoch 40] ogbg-moltoxcast: 0.615841 test loss: 0.328424
[Epoch 41; Iter    20/  172] train: loss: 0.1160864
[Epoch 41; Iter    50/  172] train: loss: 0.1513562
[Epoch 41; Iter    80/  172] train: loss: 0.1420603
[Epoch 41; Iter   110/  172] train: loss: 0.2286274
[Epoch 41; Iter   140/  172] train: loss: 0.1675383
[Epoch 41; Iter   170/  172] train: loss: 0.1103688
[Epoch 41] ogbg-moltoxcast: 0.666969 val loss: 0.276086
[Epoch 41] ogbg-moltoxcast: 0.622529 test loss: 0.336074
[Epoch 42; Iter    28/  172] train: loss: 0.1018704
[Epoch 42; Iter    58/  172] train: loss: 0.1079870
[Epoch 42; Iter    88/  172] train: loss: 0.1394087
[Epoch 42; Iter   118/  172] train: loss: 0.1229795
[Epoch 42; Iter   148/  172] train: loss: 0.1968680
[Epoch 42] ogbg-moltoxcast: 0.660599 val loss: 0.279856
[Epoch 42] ogbg-moltoxcast: 0.628361 test loss: 0.330772
[Epoch 43; Iter     6/  172] train: loss: 0.2271262
[Epoch 43; Iter    36/  172] train: loss: 0.0958071
[Epoch 43; Iter    66/  172] train: loss: 0.0751575
[Epoch 43; Iter    96/  172] train: loss: 0.0918028
[Epoch 43; Iter   126/  172] train: loss: 0.1831412
[Epoch 43; Iter   156/  172] train: loss: 0.1137737
[Epoch 43] ogbg-moltoxcast: 0.644451 val loss: 0.280824
[Epoch 43] ogbg-moltoxcast: 0.605284 test loss: 0.336850
[Epoch 44; Iter    14/  172] train: loss: 0.1241905
[Epoch 44; Iter    44/  172] train: loss: 0.1654272
[Epoch 44; Iter    74/  172] train: loss: 0.1519642
[Epoch 44; Iter   104/  172] train: loss: 0.0843956
[Epoch 44; Iter   134/  172] train: loss: 0.1404749
[Epoch 44; Iter   164/  172] train: loss: 0.1246655
[Epoch 44] ogbg-moltoxcast: 0.632870 val loss: 0.331060
[Epoch 44] ogbg-moltoxcast: 0.607630 test loss: 0.428781
[Epoch 45; Iter    22/  172] train: loss: 0.1511019
[Epoch 45; Iter    52/  172] train: loss: 0.2208015
[Epoch 45; Iter    82/  172] train: loss: 0.1645277
[Epoch 45; Iter   112/  172] train: loss: 0.1572255
[Epoch 45; Iter   142/  172] train: loss: 0.1901973
[Epoch 45; Iter   172/  172] train: loss: 0.1926385
[Epoch 45] ogbg-moltoxcast: 0.641587 val loss: 0.298732
[Epoch 45] ogbg-moltoxcast: 0.607256 test loss: 0.475884
[Epoch 46; Iter    30/  172] train: loss: 0.1845238
[Epoch 46; Iter    60/  172] train: loss: 0.1108747
[Epoch 46; Iter    90/  172] train: loss: 0.1165993
[Epoch 46; Iter   120/  172] train: loss: 0.1977008
[Epoch 46; Iter   150/  172] train: loss: 0.1585879
[Epoch 46] ogbg-moltoxcast: 0.673068 val loss: 0.294911
[Epoch 46] ogbg-moltoxcast: 0.622420 test loss: 0.434866
[Epoch 47; Iter     8/  172] train: loss: 0.1332667
[Epoch 47; Iter    38/  172] train: loss: 0.1395605
[Epoch 47; Iter    68/  172] train: loss: 0.1453119
[Epoch 47; Iter    98/  172] train: loss: 0.1064652
[Epoch 47; Iter   128/  172] train: loss: 0.1090074
[Epoch 47; Iter   158/  172] train: loss: 0.1378359
[Epoch 47] ogbg-moltoxcast: 0.665132 val loss: 0.274568
[Epoch 47] ogbg-moltoxcast: 0.622735 test loss: 0.341986
[Epoch 48; Iter    16/  172] train: loss: 0.1093776
[Epoch 48; Iter    46/  172] train: loss: 0.1306334
[Epoch 48; Iter    76/  172] train: loss: 0.1318333
[Epoch 48; Iter   106/  172] train: loss: 0.1717477
[Epoch 48; Iter   136/  172] train: loss: 0.1035308
[Epoch 48; Iter   166/  172] train: loss: 0.1426941
[Epoch 48] ogbg-moltoxcast: 0.669748 val loss: 0.281607
[Epoch 48] ogbg-moltoxcast: 0.617227 test loss: 0.532037
[Epoch 49; Iter    24/  172] train: loss: 0.1003223
[Epoch 49; Iter    54/  172] train: loss: 0.1495135
[Epoch 49; Iter    84/  172] train: loss: 0.1030098
[Epoch 49; Iter   114/  172] train: loss: 0.1494634
[Epoch 49; Iter   144/  172] train: loss: 0.1186335
[Epoch 49] ogbg-moltoxcast: 0.663972 val loss: 0.274461
[Epoch 49] ogbg-moltoxcast: 0.621166 test loss: 0.328140
[Epoch 50; Iter     2/  172] train: loss: 0.1225794
[Epoch 50; Iter    32/  172] train: loss: 0.1400835
[Epoch 50; Iter    62/  172] train: loss: 0.1325106
[Epoch 50; Iter    92/  172] train: loss: 0.1517919
[Epoch 50; Iter   122/  172] train: loss: 0.1018828
[Epoch 50; Iter   152/  172] train: loss: 0.1452526
[Epoch 50] ogbg-moltoxcast: 0.672615 val loss: 0.287835
[Epoch 50] ogbg-moltoxcast: 0.630696 test loss: 0.340242
[Epoch 51; Iter    10/  172] train: loss: 0.1013213
[Epoch 51; Iter    40/  172] train: loss: 0.1110572
[Epoch 51; Iter    70/  172] train: loss: 0.1431569
[Epoch 51; Iter   100/  172] train: loss: 0.1210037
[Epoch 51; Iter   130/  172] train: loss: 0.1698963
[Epoch 51; Iter   160/  172] train: loss: 0.1288198
[Epoch 51] ogbg-moltoxcast: 0.673091 val loss: 0.270643
[Epoch 51] ogbg-moltoxcast: 0.627688 test loss: 0.329055
[Epoch 52; Iter    18/  172] train: loss: 0.1304463
[Epoch 52; Iter    48/  172] train: loss: 0.0787773
[Epoch 52; Iter    78/  172] train: loss: 0.1150997
[Epoch 52; Iter   108/  172] train: loss: 0.1667193
[Epoch 52; Iter   138/  172] train: loss: 0.1342410
[Epoch 52; Iter   168/  172] train: loss: 0.1014650
[Epoch 52] ogbg-moltoxcast: 0.668156 val loss: 0.284271
[Epoch 52] ogbg-moltoxcast: 0.618072 test loss: 0.343788
[Epoch 53; Iter    26/  172] train: loss: 0.1433882
[Epoch 53; Iter    56/  172] train: loss: 0.1532878
[Epoch 53; Iter    86/  172] train: loss: 0.1544154
[Epoch 53; Iter   116/  172] train: loss: 0.0999210
[Epoch 53; Iter   146/  172] train: loss: 0.1532702
[Epoch 53] ogbg-moltoxcast: 0.653046 val loss: 0.296476
[Epoch 53] ogbg-moltoxcast: 0.612644 test loss: 0.350798
[Epoch 54; Iter     4/  172] train: loss: 0.1862848
[Epoch 54; Iter    34/  172] train: loss: 0.1223882
[Epoch 54; Iter    64/  172] train: loss: 0.1493082
[Epoch 54; Iter    94/  172] train: loss: 0.1750778
[Epoch 54; Iter   124/  172] train: loss: 0.1265638
[Epoch 34] ogbg-moltoxcast: 0.677858 val loss: 0.267353
[Epoch 34] ogbg-moltoxcast: 0.627710 test loss: 0.318915
[Epoch 35; Iter     2/  172] train: loss: 0.1712696
[Epoch 35; Iter    32/  172] train: loss: 0.1429483
[Epoch 35; Iter    62/  172] train: loss: 0.1352519
[Epoch 35; Iter    92/  172] train: loss: 0.1577956
[Epoch 35; Iter   122/  172] train: loss: 0.0990996
[Epoch 35; Iter   152/  172] train: loss: 0.1023458
[Epoch 35] ogbg-moltoxcast: 0.664617 val loss: 0.279360
[Epoch 35] ogbg-moltoxcast: 0.613546 test loss: 0.328949
[Epoch 36; Iter    10/  172] train: loss: 0.1773701
[Epoch 36; Iter    40/  172] train: loss: 0.1331790
[Epoch 36; Iter    70/  172] train: loss: 0.1036338
[Epoch 36; Iter   100/  172] train: loss: 0.1440291
[Epoch 36; Iter   130/  172] train: loss: 0.1303790
[Epoch 36; Iter   160/  172] train: loss: 0.1603004
[Epoch 36] ogbg-moltoxcast: 0.661275 val loss: 0.273152
[Epoch 36] ogbg-moltoxcast: 0.613980 test loss: 0.329381
[Epoch 37; Iter    18/  172] train: loss: 0.1184805
[Epoch 37; Iter    48/  172] train: loss: 0.1859254
[Epoch 37; Iter    78/  172] train: loss: 0.1552091
[Epoch 37; Iter   108/  172] train: loss: 0.1381026
[Epoch 37; Iter   138/  172] train: loss: 0.1555492
[Epoch 37; Iter   168/  172] train: loss: 0.0830625
[Epoch 37] ogbg-moltoxcast: 0.667470 val loss: 0.279470
[Epoch 37] ogbg-moltoxcast: 0.618755 test loss: 0.326466
[Epoch 38; Iter    26/  172] train: loss: 0.1265711
[Epoch 38; Iter    56/  172] train: loss: 0.1147019
[Epoch 38; Iter    86/  172] train: loss: 0.0953631
[Epoch 38; Iter   116/  172] train: loss: 0.1305622
[Epoch 38; Iter   146/  172] train: loss: 0.1541203
[Epoch 38] ogbg-moltoxcast: 0.674892 val loss: 0.268413
[Epoch 38] ogbg-moltoxcast: 0.625363 test loss: 0.329060
[Epoch 39; Iter     4/  172] train: loss: 0.1453941
[Epoch 39; Iter    34/  172] train: loss: 0.1343053
[Epoch 39; Iter    64/  172] train: loss: 0.1663130
[Epoch 39; Iter    94/  172] train: loss: 0.1328733
[Epoch 39; Iter   124/  172] train: loss: 0.1475881
[Epoch 39; Iter   154/  172] train: loss: 0.1156190
[Epoch 39] ogbg-moltoxcast: 0.665765 val loss: 0.288331
[Epoch 39] ogbg-moltoxcast: 0.616564 test loss: 0.346498
[Epoch 40; Iter    12/  172] train: loss: 0.1323173
[Epoch 40; Iter    42/  172] train: loss: 0.1081619
[Epoch 40; Iter    72/  172] train: loss: 0.1701985
[Epoch 40; Iter   102/  172] train: loss: 0.1517228
[Epoch 40; Iter   132/  172] train: loss: 0.1255501
[Epoch 40; Iter   162/  172] train: loss: 0.1289594
[Epoch 40] ogbg-moltoxcast: 0.670647 val loss: 0.266954
[Epoch 40] ogbg-moltoxcast: 0.621155 test loss: 0.318574
[Epoch 41; Iter    20/  172] train: loss: 0.1506998
[Epoch 41; Iter    50/  172] train: loss: 0.1341596
[Epoch 41; Iter    80/  172] train: loss: 0.1510015
[Epoch 41; Iter   110/  172] train: loss: 0.1272150
[Epoch 41; Iter   140/  172] train: loss: 0.1366512
[Epoch 41; Iter   170/  172] train: loss: 0.1484245
[Epoch 41] ogbg-moltoxcast: 0.673211 val loss: 0.269488
[Epoch 41] ogbg-moltoxcast: 0.625688 test loss: 0.320381
[Epoch 42; Iter    28/  172] train: loss: 0.1967123
[Epoch 42; Iter    58/  172] train: loss: 0.1657963
[Epoch 42; Iter    88/  172] train: loss: 0.1233102
[Epoch 42; Iter   118/  172] train: loss: 0.1661130
[Epoch 42; Iter   148/  172] train: loss: 0.1354577
[Epoch 42] ogbg-moltoxcast: 0.665728 val loss: 0.277595
[Epoch 42] ogbg-moltoxcast: 0.624639 test loss: 0.334835
[Epoch 43; Iter     6/  172] train: loss: 0.1358877
[Epoch 43; Iter    36/  172] train: loss: 0.1521556
[Epoch 43; Iter    66/  172] train: loss: 0.1253045
[Epoch 43; Iter    96/  172] train: loss: 0.1375432
[Epoch 43; Iter   126/  172] train: loss: 0.1413734
[Epoch 43; Iter   156/  172] train: loss: 0.1395556
[Epoch 43] ogbg-moltoxcast: 0.667798 val loss: 0.269729
[Epoch 43] ogbg-moltoxcast: 0.617946 test loss: 0.316830
[Epoch 44; Iter    14/  172] train: loss: 0.1199526
[Epoch 44; Iter    44/  172] train: loss: 0.1372859
[Epoch 44; Iter    74/  172] train: loss: 0.1163369
[Epoch 44; Iter   104/  172] train: loss: 0.1043611
[Epoch 44; Iter   134/  172] train: loss: 0.1520335
[Epoch 44; Iter   164/  172] train: loss: 0.1406475
[Epoch 44] ogbg-moltoxcast: 0.663376 val loss: 0.279327
[Epoch 44] ogbg-moltoxcast: 0.622416 test loss: 0.336853
[Epoch 45; Iter    22/  172] train: loss: 0.1267796
[Epoch 45; Iter    52/  172] train: loss: 0.1451936
[Epoch 45; Iter    82/  172] train: loss: 0.1346062
[Epoch 45; Iter   112/  172] train: loss: 0.1190674
[Epoch 45; Iter   142/  172] train: loss: 0.1118232
[Epoch 45; Iter   172/  172] train: loss: 0.0908688
[Epoch 45] ogbg-moltoxcast: 0.665300 val loss: 0.273601
[Epoch 45] ogbg-moltoxcast: 0.627350 test loss: 0.322741
[Epoch 46; Iter    30/  172] train: loss: 0.1603882
[Epoch 46; Iter    60/  172] train: loss: 0.1053844
[Epoch 46; Iter    90/  172] train: loss: 0.1003779
[Epoch 46; Iter   120/  172] train: loss: 0.1254551
[Epoch 46; Iter   150/  172] train: loss: 0.1290005
[Epoch 46] ogbg-moltoxcast: 0.666853 val loss: 0.279037
[Epoch 46] ogbg-moltoxcast: 0.627171 test loss: 0.325798
[Epoch 47; Iter     8/  172] train: loss: 0.0930673
[Epoch 47; Iter    38/  172] train: loss: 0.1022043
[Epoch 47; Iter    68/  172] train: loss: 0.1622615
[Epoch 47; Iter    98/  172] train: loss: 0.1060166
[Epoch 47; Iter   128/  172] train: loss: 0.1553114
[Epoch 47; Iter   158/  172] train: loss: 0.1401475
[Epoch 47] ogbg-moltoxcast: 0.668402 val loss: 0.275961
[Epoch 47] ogbg-moltoxcast: 0.622860 test loss: 0.328848
[Epoch 48; Iter    16/  172] train: loss: 0.1245981
[Epoch 48; Iter    46/  172] train: loss: 0.1604551
[Epoch 48; Iter    76/  172] train: loss: 0.0939959
[Epoch 48; Iter   106/  172] train: loss: 0.2035516
[Epoch 48; Iter   136/  172] train: loss: 0.1227676
[Epoch 48; Iter   166/  172] train: loss: 0.1087379
[Epoch 48] ogbg-moltoxcast: 0.668162 val loss: 0.274966
[Epoch 48] ogbg-moltoxcast: 0.627537 test loss: 0.327161
[Epoch 49; Iter    24/  172] train: loss: 0.1575084
[Epoch 49; Iter    54/  172] train: loss: 0.2012992
[Epoch 49; Iter    84/  172] train: loss: 0.1362489
[Epoch 49; Iter   114/  172] train: loss: 0.1402309
[Epoch 49; Iter   144/  172] train: loss: 0.1199951
[Epoch 49] ogbg-moltoxcast: 0.664460 val loss: 0.277599
[Epoch 49] ogbg-moltoxcast: 0.624119 test loss: 0.327626
[Epoch 50; Iter     2/  172] train: loss: 0.1533839
[Epoch 50; Iter    32/  172] train: loss: 0.1013860
[Epoch 50; Iter    62/  172] train: loss: 0.1381823
[Epoch 50; Iter    92/  172] train: loss: 0.1530626
[Epoch 50; Iter   122/  172] train: loss: 0.1190781
[Epoch 50; Iter   152/  172] train: loss: 0.1202781
[Epoch 50] ogbg-moltoxcast: 0.659433 val loss: 0.273435
[Epoch 50] ogbg-moltoxcast: 0.622780 test loss: 0.318909
[Epoch 51; Iter    10/  172] train: loss: 0.1555814
[Epoch 51; Iter    40/  172] train: loss: 0.1462635
[Epoch 51; Iter    70/  172] train: loss: 0.1153005
[Epoch 51; Iter   100/  172] train: loss: 0.1494401
[Epoch 51; Iter   130/  172] train: loss: 0.1560167
[Epoch 51; Iter   160/  172] train: loss: 0.1270630
[Epoch 51] ogbg-moltoxcast: 0.663590 val loss: 0.284297
[Epoch 51] ogbg-moltoxcast: 0.619687 test loss: 0.338170
[Epoch 52; Iter    18/  172] train: loss: 0.1223183
[Epoch 52; Iter    48/  172] train: loss: 0.1320106
[Epoch 52; Iter    78/  172] train: loss: 0.1337263
[Epoch 52; Iter   108/  172] train: loss: 0.1252360
[Epoch 52; Iter   138/  172] train: loss: 0.1261049
[Epoch 52; Iter   168/  172] train: loss: 0.1279388
[Epoch 52] ogbg-moltoxcast: 0.664354 val loss: 0.283299
[Epoch 52] ogbg-moltoxcast: 0.619929 test loss: 0.338811
[Epoch 53; Iter    26/  172] train: loss: 0.1259747
[Epoch 53; Iter    56/  172] train: loss: 0.0829576
[Epoch 53; Iter    86/  172] train: loss: 0.0806445
[Epoch 53; Iter   116/  172] train: loss: 0.1161775
[Epoch 53; Iter   146/  172] train: loss: 0.1318317
[Epoch 53] ogbg-moltoxcast: 0.663093 val loss: 0.286706
[Epoch 53] ogbg-moltoxcast: 0.625881 test loss: 0.341296
[Epoch 54; Iter     4/  172] train: loss: 0.1349553
[Epoch 54; Iter    34/  172] train: loss: 0.1118457
[Epoch 54; Iter    64/  172] train: loss: 0.1351486
[Epoch 54; Iter    94/  172] train: loss: 0.1880935
[Epoch 54; Iter   124/  172] train: loss: 0.1368410
[Epoch 34] ogbg-moltoxcast: 0.684137 val loss: 0.259831
[Epoch 34] ogbg-moltoxcast: 0.631456 test loss: 0.314230
[Epoch 35; Iter     2/  172] train: loss: 0.1838257
[Epoch 35; Iter    32/  172] train: loss: 0.1325342
[Epoch 35; Iter    62/  172] train: loss: 0.1606873
[Epoch 35; Iter    92/  172] train: loss: 0.1780104
[Epoch 35; Iter   122/  172] train: loss: 0.2015309
[Epoch 35; Iter   152/  172] train: loss: 0.2188133
[Epoch 35] ogbg-moltoxcast: 0.670626 val loss: 0.263038
[Epoch 35] ogbg-moltoxcast: 0.629872 test loss: 0.318651
[Epoch 36; Iter    10/  172] train: loss: 0.1125013
[Epoch 36; Iter    40/  172] train: loss: 0.1183153
[Epoch 36; Iter    70/  172] train: loss: 0.1463428
[Epoch 36; Iter   100/  172] train: loss: 0.1333363
[Epoch 36; Iter   130/  172] train: loss: 0.1761671
[Epoch 36; Iter   160/  172] train: loss: 0.1663929
[Epoch 36] ogbg-moltoxcast: 0.672747 val loss: 0.267160
[Epoch 36] ogbg-moltoxcast: 0.637427 test loss: 0.318834
[Epoch 37; Iter    18/  172] train: loss: 0.1525522
[Epoch 37; Iter    48/  172] train: loss: 0.1375019
[Epoch 37; Iter    78/  172] train: loss: 0.1435117
[Epoch 37; Iter   108/  172] train: loss: 0.2025911
[Epoch 37; Iter   138/  172] train: loss: 0.1332971
[Epoch 37; Iter   168/  172] train: loss: 0.1859864
[Epoch 37] ogbg-moltoxcast: 0.683527 val loss: 0.266372
[Epoch 37] ogbg-moltoxcast: 0.637087 test loss: 0.334301
[Epoch 38; Iter    26/  172] train: loss: 0.1404726
[Epoch 38; Iter    56/  172] train: loss: 0.1282054
[Epoch 38; Iter    86/  172] train: loss: 0.1284201
[Epoch 38; Iter   116/  172] train: loss: 0.1257841
[Epoch 38; Iter   146/  172] train: loss: 0.1710427
[Epoch 38] ogbg-moltoxcast: 0.656936 val loss: 0.281121
[Epoch 38] ogbg-moltoxcast: 0.619210 test loss: 0.336129
[Epoch 39; Iter     4/  172] train: loss: 0.1426883
[Epoch 39; Iter    34/  172] train: loss: 0.1238324
[Epoch 39; Iter    64/  172] train: loss: 0.1477839
[Epoch 39; Iter    94/  172] train: loss: 0.1459649
[Epoch 39; Iter   124/  172] train: loss: 0.1477186
[Epoch 39; Iter   154/  172] train: loss: 0.1059690
[Epoch 39] ogbg-moltoxcast: 0.670651 val loss: 0.276104
[Epoch 39] ogbg-moltoxcast: 0.627605 test loss: 0.336908
[Epoch 40; Iter    12/  172] train: loss: 0.1808381
[Epoch 40; Iter    42/  172] train: loss: 0.1384927
[Epoch 40; Iter    72/  172] train: loss: 0.1546615
[Epoch 40; Iter   102/  172] train: loss: 0.1641337
[Epoch 40; Iter   132/  172] train: loss: 0.1165976
[Epoch 40; Iter   162/  172] train: loss: 0.1491789
[Epoch 40] ogbg-moltoxcast: 0.671708 val loss: 0.271674
[Epoch 40] ogbg-moltoxcast: 0.625133 test loss: 0.334326
[Epoch 41; Iter    20/  172] train: loss: 0.1343739
[Epoch 41; Iter    50/  172] train: loss: 0.0942221
[Epoch 41; Iter    80/  172] train: loss: 0.1574851
[Epoch 41; Iter   110/  172] train: loss: 0.1277739
[Epoch 41; Iter   140/  172] train: loss: 0.1124416
[Epoch 41; Iter   170/  172] train: loss: 0.1326952
[Epoch 41] ogbg-moltoxcast: 0.673039 val loss: 0.263558
[Epoch 41] ogbg-moltoxcast: 0.622534 test loss: 0.327290
[Epoch 42; Iter    28/  172] train: loss: 0.0962485
[Epoch 42; Iter    58/  172] train: loss: 0.1714601
[Epoch 42; Iter    88/  172] train: loss: 0.1887608
[Epoch 42; Iter   118/  172] train: loss: 0.0937431
[Epoch 42; Iter   148/  172] train: loss: 0.1569836
[Epoch 42] ogbg-moltoxcast: 0.672886 val loss: 0.267746
[Epoch 42] ogbg-moltoxcast: 0.633398 test loss: 0.320679
[Epoch 43; Iter     6/  172] train: loss: 0.0973370
[Epoch 43; Iter    36/  172] train: loss: 0.1109549
[Epoch 43; Iter    66/  172] train: loss: 0.0971409
[Epoch 43; Iter    96/  172] train: loss: 0.0908109
[Epoch 43; Iter   126/  172] train: loss: 0.1273011
[Epoch 43; Iter   156/  172] train: loss: 0.1846423
[Epoch 43] ogbg-moltoxcast: 0.672110 val loss: 0.272894
[Epoch 43] ogbg-moltoxcast: 0.639020 test loss: 0.316855
[Epoch 44; Iter    14/  172] train: loss: 0.1158425
[Epoch 44; Iter    44/  172] train: loss: 0.2277170
[Epoch 44; Iter    74/  172] train: loss: 0.1158130
[Epoch 44; Iter   104/  172] train: loss: 0.1417418
[Epoch 44; Iter   134/  172] train: loss: 0.1469349
[Epoch 44; Iter   164/  172] train: loss: 0.1749664
[Epoch 44] ogbg-moltoxcast: 0.666493 val loss: 0.268716
[Epoch 44] ogbg-moltoxcast: 0.622933 test loss: 0.331774
[Epoch 45; Iter    22/  172] train: loss: 0.1624647
[Epoch 45; Iter    52/  172] train: loss: 0.1321102
[Epoch 45; Iter    82/  172] train: loss: 0.1890809
[Epoch 45; Iter   112/  172] train: loss: 0.0980384
[Epoch 45; Iter   142/  172] train: loss: 0.1522689
[Epoch 45; Iter   172/  172] train: loss: 0.0968821
[Epoch 45] ogbg-moltoxcast: 0.667757 val loss: 0.285150
[Epoch 45] ogbg-moltoxcast: 0.638485 test loss: 0.335589
[Epoch 46; Iter    30/  172] train: loss: 0.1143497
[Epoch 46; Iter    60/  172] train: loss: 0.1039068
[Epoch 46; Iter    90/  172] train: loss: 0.1576366
[Epoch 46; Iter   120/  172] train: loss: 0.1507318
[Epoch 46; Iter   150/  172] train: loss: 0.1088451
[Epoch 46] ogbg-moltoxcast: 0.676707 val loss: 0.263549
[Epoch 46] ogbg-moltoxcast: 0.632274 test loss: 0.319213
[Epoch 47; Iter     8/  172] train: loss: 0.1642846
[Epoch 47; Iter    38/  172] train: loss: 0.1615196
[Epoch 47; Iter    68/  172] train: loss: 0.1047071
[Epoch 47; Iter    98/  172] train: loss: 0.1216435
[Epoch 47; Iter   128/  172] train: loss: 0.1171860
[Epoch 47; Iter   158/  172] train: loss: 0.1037870
[Epoch 47] ogbg-moltoxcast: 0.661808 val loss: 0.282083
[Epoch 47] ogbg-moltoxcast: 0.629859 test loss: 0.336757
[Epoch 48; Iter    16/  172] train: loss: 0.1518848
[Epoch 48; Iter    46/  172] train: loss: 0.1642966
[Epoch 48; Iter    76/  172] train: loss: 0.0947290
[Epoch 48; Iter   106/  172] train: loss: 0.1221821
[Epoch 48; Iter   136/  172] train: loss: 0.1583421
[Epoch 48; Iter   166/  172] train: loss: 0.1362109
[Epoch 48] ogbg-moltoxcast: 0.665347 val loss: 0.275644
[Epoch 48] ogbg-moltoxcast: 0.629648 test loss: 0.324920
[Epoch 49; Iter    24/  172] train: loss: 0.1540238
[Epoch 49; Iter    54/  172] train: loss: 0.1313348
[Epoch 49; Iter    84/  172] train: loss: 0.1766829
[Epoch 49; Iter   114/  172] train: loss: 0.1193335
[Epoch 49; Iter   144/  172] train: loss: 0.1259104
[Epoch 49] ogbg-moltoxcast: 0.667234 val loss: 0.278113
[Epoch 49] ogbg-moltoxcast: 0.627172 test loss: 0.334072
[Epoch 50; Iter     2/  172] train: loss: 0.1536164
[Epoch 50; Iter    32/  172] train: loss: 0.0867498
[Epoch 50; Iter    62/  172] train: loss: 0.1168314
[Epoch 50; Iter    92/  172] train: loss: 0.1284257
[Epoch 50; Iter   122/  172] train: loss: 0.1715170
[Epoch 50; Iter   152/  172] train: loss: 0.1040267
[Epoch 50] ogbg-moltoxcast: 0.663599 val loss: 0.274627
[Epoch 50] ogbg-moltoxcast: 0.627839 test loss: 0.326923
[Epoch 51; Iter    10/  172] train: loss: 0.1328213
[Epoch 51; Iter    40/  172] train: loss: 0.1468363
[Epoch 51; Iter    70/  172] train: loss: 0.1275384
[Epoch 51; Iter   100/  172] train: loss: 0.1461336
[Epoch 51; Iter   130/  172] train: loss: 0.0612484
[Epoch 51; Iter   160/  172] train: loss: 0.1121803
[Epoch 51] ogbg-moltoxcast: 0.665410 val loss: 0.275033
[Epoch 51] ogbg-moltoxcast: 0.629699 test loss: 0.325899
[Epoch 52; Iter    18/  172] train: loss: 0.1099667
[Epoch 52; Iter    48/  172] train: loss: 0.1106445
[Epoch 52; Iter    78/  172] train: loss: 0.1813480
[Epoch 52; Iter   108/  172] train: loss: 0.0946702
[Epoch 52; Iter   138/  172] train: loss: 0.1645935
[Epoch 52; Iter   168/  172] train: loss: 0.1121060
[Epoch 52] ogbg-moltoxcast: 0.663198 val loss: 0.275037
[Epoch 52] ogbg-moltoxcast: 0.627754 test loss: 0.324992
[Epoch 53; Iter    26/  172] train: loss: 0.1476447
[Epoch 53; Iter    56/  172] train: loss: 0.1187563
[Epoch 53; Iter    86/  172] train: loss: 0.1281063
[Epoch 53; Iter   116/  172] train: loss: 0.1400735
[Epoch 53; Iter   146/  172] train: loss: 0.1162219
[Epoch 53] ogbg-moltoxcast: 0.660921 val loss: 0.281444
[Epoch 53] ogbg-moltoxcast: 0.627006 test loss: 0.337646
[Epoch 54; Iter     4/  172] train: loss: 0.1170762
[Epoch 54; Iter    34/  172] train: loss: 0.1208097
[Epoch 54; Iter    64/  172] train: loss: 0.0837586
[Epoch 54; Iter    94/  172] train: loss: 0.0908377
[Epoch 54; Iter   124/  172] train: loss: 0.1643286
[Epoch 44; Iter    23/  229] train: loss: 0.2024272
[Epoch 44; Iter    53/  229] train: loss: 0.0935960
[Epoch 44; Iter    83/  229] train: loss: 0.1399722
[Epoch 44; Iter   113/  229] train: loss: 0.1331251
[Epoch 44; Iter   143/  229] train: loss: 0.1836324
[Epoch 44; Iter   173/  229] train: loss: 0.1924439
[Epoch 44; Iter   203/  229] train: loss: 0.1436955
[Epoch 44] ogbg-moltoxcast: 0.690610 val loss: 0.255974
[Epoch 44] ogbg-moltoxcast: 0.662126 test loss: 0.313458
[Epoch 45; Iter     4/  229] train: loss: 0.1292220
[Epoch 45; Iter    34/  229] train: loss: 0.1247926
[Epoch 45; Iter    64/  229] train: loss: 0.1679946
[Epoch 45; Iter    94/  229] train: loss: 0.1064766
[Epoch 45; Iter   124/  229] train: loss: 0.1571608
[Epoch 45; Iter   154/  229] train: loss: 0.1292481
[Epoch 45; Iter   184/  229] train: loss: 0.1160372
[Epoch 45; Iter   214/  229] train: loss: 0.1026854
[Epoch 45] ogbg-moltoxcast: 0.687078 val loss: 0.256658
[Epoch 45] ogbg-moltoxcast: 0.660393 test loss: 0.313392
[Epoch 46; Iter    15/  229] train: loss: 0.1797510
[Epoch 46; Iter    45/  229] train: loss: 0.1904905
[Epoch 46; Iter    75/  229] train: loss: 0.1345359
[Epoch 46; Iter   105/  229] train: loss: 0.1833178
[Epoch 46; Iter   135/  229] train: loss: 0.1685269
[Epoch 46; Iter   165/  229] train: loss: 0.1404244
[Epoch 46; Iter   195/  229] train: loss: 0.1568916
[Epoch 46; Iter   225/  229] train: loss: 0.1558651
[Epoch 46] ogbg-moltoxcast: 0.690805 val loss: 0.260710
[Epoch 46] ogbg-moltoxcast: 0.663953 test loss: 0.326314
[Epoch 47; Iter    26/  229] train: loss: 0.1597084
[Epoch 47; Iter    56/  229] train: loss: 0.1623590
[Epoch 47; Iter    86/  229] train: loss: 0.1528548
[Epoch 47; Iter   116/  229] train: loss: 0.1292478
[Epoch 47; Iter   146/  229] train: loss: 0.1287019
[Epoch 47; Iter   176/  229] train: loss: 0.1073935
[Epoch 47; Iter   206/  229] train: loss: 0.1285604
[Epoch 47] ogbg-moltoxcast: 0.688581 val loss: 0.265320
[Epoch 47] ogbg-moltoxcast: 0.667952 test loss: 0.316818
[Epoch 48; Iter     7/  229] train: loss: 0.1675615
[Epoch 48; Iter    37/  229] train: loss: 0.1348593
[Epoch 48; Iter    67/  229] train: loss: 0.1222495
[Epoch 48; Iter    97/  229] train: loss: 0.1472065
[Epoch 48; Iter   127/  229] train: loss: 0.1552047
[Epoch 48; Iter   157/  229] train: loss: 0.1215137
[Epoch 48; Iter   187/  229] train: loss: 0.1574955
[Epoch 48; Iter   217/  229] train: loss: 0.1414225
[Epoch 48] ogbg-moltoxcast: 0.695559 val loss: 0.259605
[Epoch 48] ogbg-moltoxcast: 0.666732 test loss: 0.315968
[Epoch 49; Iter    18/  229] train: loss: 0.1577211
[Epoch 49; Iter    48/  229] train: loss: 0.1450423
[Epoch 49; Iter    78/  229] train: loss: 0.0926313
[Epoch 49; Iter   108/  229] train: loss: 0.1322452
[Epoch 49; Iter   138/  229] train: loss: 0.1253738
[Epoch 49; Iter   168/  229] train: loss: 0.1410504
[Epoch 49; Iter   198/  229] train: loss: 0.1539551
[Epoch 49; Iter   228/  229] train: loss: 0.1590019
[Epoch 49] ogbg-moltoxcast: 0.700162 val loss: 0.263926
[Epoch 49] ogbg-moltoxcast: 0.666636 test loss: 0.328840
[Epoch 50; Iter    29/  229] train: loss: 0.1119598
[Epoch 50; Iter    59/  229] train: loss: 0.1487122
[Epoch 50; Iter    89/  229] train: loss: 0.0814970
[Epoch 50; Iter   119/  229] train: loss: 0.1775964
[Epoch 50; Iter   149/  229] train: loss: 0.1370545
[Epoch 50; Iter   179/  229] train: loss: 0.1329087
[Epoch 50; Iter   209/  229] train: loss: 0.1149244
[Epoch 50] ogbg-moltoxcast: 0.688389 val loss: 0.257856
[Epoch 50] ogbg-moltoxcast: 0.666993 test loss: 0.317374
[Epoch 51; Iter    10/  229] train: loss: 0.1632353
[Epoch 51; Iter    40/  229] train: loss: 0.1044531
[Epoch 51; Iter    70/  229] train: loss: 0.1622415
[Epoch 51; Iter   100/  229] train: loss: 0.1651646
[Epoch 51; Iter   130/  229] train: loss: 0.1166638
[Epoch 51; Iter   160/  229] train: loss: 0.1156843
[Epoch 51; Iter   190/  229] train: loss: 0.1421680
[Epoch 51; Iter   220/  229] train: loss: 0.1643930
[Epoch 51] ogbg-moltoxcast: 0.690903 val loss: 0.259162
[Epoch 51] ogbg-moltoxcast: 0.664234 test loss: 0.324118
[Epoch 52; Iter    21/  229] train: loss: 0.1388944
[Epoch 52; Iter    51/  229] train: loss: 0.1551399
[Epoch 52; Iter    81/  229] train: loss: 0.1246506
[Epoch 52; Iter   111/  229] train: loss: 0.1862890
[Epoch 52; Iter   141/  229] train: loss: 0.1478611
[Epoch 52; Iter   171/  229] train: loss: 0.1678051
[Epoch 52; Iter   201/  229] train: loss: 0.1349944
[Epoch 52] ogbg-moltoxcast: 0.690683 val loss: 0.271223
[Epoch 52] ogbg-moltoxcast: 0.666782 test loss: 0.326167
[Epoch 53; Iter     2/  229] train: loss: 0.0919144
[Epoch 53; Iter    32/  229] train: loss: 0.1276449
[Epoch 53; Iter    62/  229] train: loss: 0.1416850
[Epoch 53; Iter    92/  229] train: loss: 0.1893394
[Epoch 53; Iter   122/  229] train: loss: 0.0952373
[Epoch 53; Iter   152/  229] train: loss: 0.1200866
[Epoch 53; Iter   182/  229] train: loss: 0.1339296
[Epoch 53; Iter   212/  229] train: loss: 0.1190953
[Epoch 53] ogbg-moltoxcast: 0.687942 val loss: 0.268220
[Epoch 53] ogbg-moltoxcast: 0.663064 test loss: 0.325362
[Epoch 54; Iter    13/  229] train: loss: 0.0848577
[Epoch 54; Iter    43/  229] train: loss: 0.1607537
[Epoch 54; Iter    73/  229] train: loss: 0.1189907
[Epoch 54; Iter   103/  229] train: loss: 0.1283818
[Epoch 54; Iter   133/  229] train: loss: 0.1427297
[Epoch 54; Iter   163/  229] train: loss: 0.1709823
[Epoch 54; Iter   193/  229] train: loss: 0.1564913
[Epoch 54; Iter   223/  229] train: loss: 0.1657722
[Epoch 54] ogbg-moltoxcast: 0.699692 val loss: 0.263342
[Epoch 54] ogbg-moltoxcast: 0.667041 test loss: 0.327742
[Epoch 55; Iter    24/  229] train: loss: 0.1906286
[Epoch 55; Iter    54/  229] train: loss: 0.1933802
[Epoch 55; Iter    84/  229] train: loss: 0.1063599
[Epoch 55; Iter   114/  229] train: loss: 0.1879022
[Epoch 55; Iter   144/  229] train: loss: 0.1614139
[Epoch 55; Iter   174/  229] train: loss: 0.1673428
[Epoch 55; Iter   204/  229] train: loss: 0.1086097
[Epoch 55] ogbg-moltoxcast: 0.687732 val loss: 0.261925
[Epoch 55] ogbg-moltoxcast: 0.666856 test loss: 0.319289
[Epoch 56; Iter     5/  229] train: loss: 0.1179126
[Epoch 56; Iter    35/  229] train: loss: 0.1481559
[Epoch 56; Iter    65/  229] train: loss: 0.1321439
[Epoch 56; Iter    95/  229] train: loss: 0.1336938
[Epoch 56; Iter   125/  229] train: loss: 0.0934900
[Epoch 56; Iter   155/  229] train: loss: 0.1162054
[Epoch 56; Iter   185/  229] train: loss: 0.1405246
[Epoch 56; Iter   215/  229] train: loss: 0.1354382
[Epoch 56] ogbg-moltoxcast: 0.696044 val loss: 0.259441
[Epoch 56] ogbg-moltoxcast: 0.660201 test loss: 0.337942
[Epoch 57; Iter    16/  229] train: loss: 0.1149134
[Epoch 57; Iter    46/  229] train: loss: 0.1171896
[Epoch 57; Iter    76/  229] train: loss: 0.1870612
[Epoch 57; Iter   106/  229] train: loss: 0.1522208
[Epoch 57; Iter   136/  229] train: loss: 0.1371303
[Epoch 57; Iter   166/  229] train: loss: 0.1047602
[Epoch 57; Iter   196/  229] train: loss: 0.1682969
[Epoch 57; Iter   226/  229] train: loss: 0.1898647
[Epoch 57] ogbg-moltoxcast: 0.699432 val loss: 0.263906
[Epoch 57] ogbg-moltoxcast: 0.665014 test loss: 0.416052
[Epoch 58; Iter    27/  229] train: loss: 0.1133788
[Epoch 58; Iter    57/  229] train: loss: 0.1013357
[Epoch 58; Iter    87/  229] train: loss: 0.1221114
[Epoch 58; Iter   117/  229] train: loss: 0.1062656
[Epoch 58; Iter   147/  229] train: loss: 0.1365677
[Epoch 58; Iter   177/  229] train: loss: 0.1726350
[Epoch 58; Iter   207/  229] train: loss: 0.1227789
[Epoch 58] ogbg-moltoxcast: 0.684409 val loss: 0.263218
[Epoch 58] ogbg-moltoxcast: 0.658822 test loss: 0.330532
[Epoch 59; Iter     8/  229] train: loss: 0.1236497
[Epoch 59; Iter    38/  229] train: loss: 0.1360795
[Epoch 59; Iter    68/  229] train: loss: 0.1191841
[Epoch 59; Iter    98/  229] train: loss: 0.1713986
[Epoch 59; Iter   128/  229] train: loss: 0.1648114
[Epoch 59; Iter   158/  229] train: loss: 0.1205565
[Epoch 59; Iter   188/  229] train: loss: 0.1295499
[Epoch 59; Iter   218/  229] train: loss: 0.1142327
[Epoch 59] ogbg-moltoxcast: 0.691561 val loss: 0.262509
[Epoch 59] ogbg-moltoxcast: 0.665132 test loss: 0.330515
[Epoch 44; Iter    23/  229] train: loss: 0.1791002
[Epoch 44; Iter    53/  229] train: loss: 0.1107022
[Epoch 44; Iter    83/  229] train: loss: 0.1522142
[Epoch 44; Iter   113/  229] train: loss: 0.0949176
[Epoch 44; Iter   143/  229] train: loss: 0.1433580
[Epoch 44; Iter   173/  229] train: loss: 0.1250710
[Epoch 44; Iter   203/  229] train: loss: 0.1447780
[Epoch 44] ogbg-moltoxcast: 0.697657 val loss: 0.246804
[Epoch 44] ogbg-moltoxcast: 0.667518 test loss: 0.686567
[Epoch 45; Iter     4/  229] train: loss: 0.1184669
[Epoch 45; Iter    34/  229] train: loss: 0.1209145
[Epoch 45; Iter    64/  229] train: loss: 0.1632782
[Epoch 45; Iter    94/  229] train: loss: 0.1181754
[Epoch 45; Iter   124/  229] train: loss: 0.1430256
[Epoch 45; Iter   154/  229] train: loss: 0.1288806
[Epoch 45; Iter   184/  229] train: loss: 0.1584612
[Epoch 45; Iter   214/  229] train: loss: 0.1547520
[Epoch 45] ogbg-moltoxcast: 0.692858 val loss: 0.253663
[Epoch 45] ogbg-moltoxcast: 0.669456 test loss: 0.487239
[Epoch 46; Iter    15/  229] train: loss: 0.1295178
[Epoch 46; Iter    45/  229] train: loss: 0.1485665
[Epoch 46; Iter    75/  229] train: loss: 0.1938541
[Epoch 46; Iter   105/  229] train: loss: 0.1466680
[Epoch 46; Iter   135/  229] train: loss: 0.1464661
[Epoch 46; Iter   165/  229] train: loss: 0.1303964
[Epoch 46; Iter   195/  229] train: loss: 0.1475601
[Epoch 46; Iter   225/  229] train: loss: 0.1565688
[Epoch 46] ogbg-moltoxcast: 0.691879 val loss: 0.252750
[Epoch 46] ogbg-moltoxcast: 0.665890 test loss: 0.521864
[Epoch 47; Iter    26/  229] train: loss: 0.1518242
[Epoch 47; Iter    56/  229] train: loss: 0.1566202
[Epoch 47; Iter    86/  229] train: loss: 0.1308439
[Epoch 47; Iter   116/  229] train: loss: 0.0953083
[Epoch 47; Iter   146/  229] train: loss: 0.1253033
[Epoch 47; Iter   176/  229] train: loss: 0.1568027
[Epoch 47; Iter   206/  229] train: loss: 0.1361268
[Epoch 47] ogbg-moltoxcast: 0.695338 val loss: 0.253233
[Epoch 47] ogbg-moltoxcast: 0.661839 test loss: 0.305616
[Epoch 48; Iter     7/  229] train: loss: 0.1175816
[Epoch 48; Iter    37/  229] train: loss: 0.1221079
[Epoch 48; Iter    67/  229] train: loss: 0.1453349
[Epoch 48; Iter    97/  229] train: loss: 0.1665476
[Epoch 48; Iter   127/  229] train: loss: 0.1600605
[Epoch 48; Iter   157/  229] train: loss: 0.1116599
[Epoch 48; Iter   187/  229] train: loss: 0.1875800
[Epoch 48; Iter   217/  229] train: loss: 0.1439140
[Epoch 48] ogbg-moltoxcast: 0.689268 val loss: 0.271221
[Epoch 48] ogbg-moltoxcast: 0.660930 test loss: 0.375195
[Epoch 49; Iter    18/  229] train: loss: 0.1785034
[Epoch 49; Iter    48/  229] train: loss: 0.1145172
[Epoch 49; Iter    78/  229] train: loss: 0.1836678
[Epoch 49; Iter   108/  229] train: loss: 0.1357104
[Epoch 49; Iter   138/  229] train: loss: 0.1771442
[Epoch 49; Iter   168/  229] train: loss: 0.1204861
[Epoch 49; Iter   198/  229] train: loss: 0.1458541
[Epoch 49; Iter   228/  229] train: loss: 0.1341928
[Epoch 49] ogbg-moltoxcast: 0.695274 val loss: 0.256901
[Epoch 49] ogbg-moltoxcast: 0.668070 test loss: 0.308216
[Epoch 50; Iter    29/  229] train: loss: 0.1582262
[Epoch 50; Iter    59/  229] train: loss: 0.1335657
[Epoch 50; Iter    89/  229] train: loss: 0.1622506
[Epoch 50; Iter   119/  229] train: loss: 0.1198618
[Epoch 50; Iter   149/  229] train: loss: 0.1620804
[Epoch 50; Iter   179/  229] train: loss: 0.1748853
[Epoch 50; Iter   209/  229] train: loss: 0.1921981
[Epoch 50] ogbg-moltoxcast: 0.686641 val loss: 0.254473
[Epoch 50] ogbg-moltoxcast: 0.669089 test loss: 0.304047
[Epoch 51; Iter    10/  229] train: loss: 0.1440641
[Epoch 51; Iter    40/  229] train: loss: 0.1008747
[Epoch 51; Iter    70/  229] train: loss: 0.1616855
[Epoch 51; Iter   100/  229] train: loss: 0.1479655
[Epoch 51; Iter   130/  229] train: loss: 0.1240890
[Epoch 51; Iter   160/  229] train: loss: 0.1119079
[Epoch 51; Iter   190/  229] train: loss: 0.1122495
[Epoch 51; Iter   220/  229] train: loss: 0.1609735
[Epoch 51] ogbg-moltoxcast: 0.693294 val loss: 0.250172
[Epoch 51] ogbg-moltoxcast: 0.661630 test loss: 0.305768
[Epoch 52; Iter    21/  229] train: loss: 0.1444761
[Epoch 52; Iter    51/  229] train: loss: 0.1396688
[Epoch 52; Iter    81/  229] train: loss: 0.1536615
[Epoch 52; Iter   111/  229] train: loss: 0.1183983
[Epoch 52; Iter   141/  229] train: loss: 0.1277084
[Epoch 52; Iter   171/  229] train: loss: 0.0862149
[Epoch 52; Iter   201/  229] train: loss: 0.1276479
[Epoch 52] ogbg-moltoxcast: 0.694172 val loss: 0.257646
[Epoch 52] ogbg-moltoxcast: 0.663372 test loss: 0.313235
[Epoch 53; Iter     2/  229] train: loss: 0.1076729
[Epoch 53; Iter    32/  229] train: loss: 0.0901919
[Epoch 53; Iter    62/  229] train: loss: 0.1287464
[Epoch 53; Iter    92/  229] train: loss: 0.1076525
[Epoch 53; Iter   122/  229] train: loss: 0.1006750
[Epoch 53; Iter   152/  229] train: loss: 0.1527351
[Epoch 53; Iter   182/  229] train: loss: 0.1317712
[Epoch 53; Iter   212/  229] train: loss: 0.1518115
[Epoch 53] ogbg-moltoxcast: 0.686842 val loss: 0.259411
[Epoch 53] ogbg-moltoxcast: 0.663549 test loss: 0.310494
[Epoch 54; Iter    13/  229] train: loss: 0.0951837
[Epoch 54; Iter    43/  229] train: loss: 0.1050995
[Epoch 54; Iter    73/  229] train: loss: 0.1108566
[Epoch 54; Iter   103/  229] train: loss: 0.1018848
[Epoch 54; Iter   133/  229] train: loss: 0.1148023
[Epoch 54; Iter   163/  229] train: loss: 0.1269765
[Epoch 54; Iter   193/  229] train: loss: 0.1575610
[Epoch 54; Iter   223/  229] train: loss: 0.1700579
[Epoch 54] ogbg-moltoxcast: 0.681899 val loss: 0.265972
[Epoch 54] ogbg-moltoxcast: 0.659637 test loss: 0.316145
[Epoch 55; Iter    24/  229] train: loss: 0.1661241
[Epoch 55; Iter    54/  229] train: loss: 0.1574782
[Epoch 55; Iter    84/  229] train: loss: 0.1227632
[Epoch 55; Iter   114/  229] train: loss: 0.1333293
[Epoch 55; Iter   144/  229] train: loss: 0.1343172
[Epoch 55; Iter   174/  229] train: loss: 0.1401025
[Epoch 55; Iter   204/  229] train: loss: 0.1618001
[Epoch 55] ogbg-moltoxcast: 0.688653 val loss: 0.259729
[Epoch 55] ogbg-moltoxcast: 0.661731 test loss: 0.310012
[Epoch 56; Iter     5/  229] train: loss: 0.1426630
[Epoch 56; Iter    35/  229] train: loss: 0.1088578
[Epoch 56; Iter    65/  229] train: loss: 0.1847078
[Epoch 56; Iter    95/  229] train: loss: 0.1322597
[Epoch 56; Iter   125/  229] train: loss: 0.1378444
[Epoch 56; Iter   155/  229] train: loss: 0.1446277
[Epoch 56; Iter   185/  229] train: loss: 0.1643006
[Epoch 56; Iter   215/  229] train: loss: 0.1191485
[Epoch 56] ogbg-moltoxcast: 0.691519 val loss: 0.266318
[Epoch 56] ogbg-moltoxcast: 0.665388 test loss: 0.317797
[Epoch 57; Iter    16/  229] train: loss: 0.2162948
[Epoch 57; Iter    46/  229] train: loss: 0.1314263
[Epoch 57; Iter    76/  229] train: loss: 0.1051785
[Epoch 57; Iter   106/  229] train: loss: 0.1558141
[Epoch 57; Iter   136/  229] train: loss: 0.1135354
[Epoch 57; Iter   166/  229] train: loss: 0.0930768
[Epoch 57; Iter   196/  229] train: loss: 0.1393746
[Epoch 57; Iter   226/  229] train: loss: 0.2072682
[Epoch 57] ogbg-moltoxcast: 0.687384 val loss: 0.263555
[Epoch 57] ogbg-moltoxcast: 0.656534 test loss: 0.311264
[Epoch 58; Iter    27/  229] train: loss: 0.1436257
[Epoch 58; Iter    57/  229] train: loss: 0.1546088
[Epoch 58; Iter    87/  229] train: loss: 0.1352113
[Epoch 58; Iter   117/  229] train: loss: 0.1474544
[Epoch 58; Iter   147/  229] train: loss: 0.1947463
[Epoch 58; Iter   177/  229] train: loss: 0.1973221
[Epoch 58; Iter   207/  229] train: loss: 0.1269834
[Epoch 58] ogbg-moltoxcast: 0.679508 val loss: 0.260957
[Epoch 58] ogbg-moltoxcast: 0.663125 test loss: 0.317543
[Epoch 59; Iter     8/  229] train: loss: 0.1369350
[Epoch 59; Iter    38/  229] train: loss: 0.1151389
[Epoch 59; Iter    68/  229] train: loss: 0.1302811
[Epoch 59; Iter    98/  229] train: loss: 0.1078759
[Epoch 59; Iter   128/  229] train: loss: 0.1206573
[Epoch 59; Iter   158/  229] train: loss: 0.1319760
[Epoch 59; Iter   188/  229] train: loss: 0.1309283
[Epoch 59; Iter   218/  229] train: loss: 0.1297205
[Epoch 59] ogbg-moltoxcast: 0.687369 val loss: 0.259958
[Epoch 59] ogbg-moltoxcast: 0.666969 test loss: 0.310356
[Epoch 44; Iter    23/  229] train: loss: 0.1123303
[Epoch 44; Iter    53/  229] train: loss: 0.1210035
[Epoch 44; Iter    83/  229] train: loss: 0.1259242
[Epoch 44; Iter   113/  229] train: loss: 0.1270293
[Epoch 44; Iter   143/  229] train: loss: 0.1420903
[Epoch 44; Iter   173/  229] train: loss: 0.1375053
[Epoch 44; Iter   203/  229] train: loss: 0.0878360
[Epoch 44] ogbg-moltoxcast: 0.705429 val loss: 0.252700
[Epoch 44] ogbg-moltoxcast: 0.673082 test loss: 0.502259
[Epoch 45; Iter     4/  229] train: loss: 0.1218942
[Epoch 45; Iter    34/  229] train: loss: 0.1589136
[Epoch 45; Iter    64/  229] train: loss: 0.1072425
[Epoch 45; Iter    94/  229] train: loss: 0.1660531
[Epoch 45; Iter   124/  229] train: loss: 0.2057233
[Epoch 45; Iter   154/  229] train: loss: 0.1425097
[Epoch 45; Iter   184/  229] train: loss: 0.1825354
[Epoch 45; Iter   214/  229] train: loss: 0.1353815
[Epoch 45] ogbg-moltoxcast: 0.703304 val loss: 0.253786
[Epoch 45] ogbg-moltoxcast: 0.664219 test loss: 0.458941
[Epoch 46; Iter    15/  229] train: loss: 0.1650475
[Epoch 46; Iter    45/  229] train: loss: 0.1751006
[Epoch 46; Iter    75/  229] train: loss: 0.1950061
[Epoch 46; Iter   105/  229] train: loss: 0.1269898
[Epoch 46; Iter   135/  229] train: loss: 0.1541665
[Epoch 46; Iter   165/  229] train: loss: 0.1083480
[Epoch 46; Iter   195/  229] train: loss: 0.1606539
[Epoch 46; Iter   225/  229] train: loss: 0.1175481
[Epoch 46] ogbg-moltoxcast: 0.696982 val loss: 0.259385
[Epoch 46] ogbg-moltoxcast: 0.669326 test loss: 0.484177
[Epoch 47; Iter    26/  229] train: loss: 0.1247457
[Epoch 47; Iter    56/  229] train: loss: 0.1429607
[Epoch 47; Iter    86/  229] train: loss: 0.1110494
[Epoch 47; Iter   116/  229] train: loss: 0.1469483
[Epoch 47; Iter   146/  229] train: loss: 0.1100663
[Epoch 47; Iter   176/  229] train: loss: 0.1373704
[Epoch 47; Iter   206/  229] train: loss: 0.1618945
[Epoch 47] ogbg-moltoxcast: 0.696051 val loss: 0.261485
[Epoch 47] ogbg-moltoxcast: 0.664527 test loss: 0.527320
[Epoch 48; Iter     7/  229] train: loss: 0.1856919
[Epoch 48; Iter    37/  229] train: loss: 0.1180905
[Epoch 48; Iter    67/  229] train: loss: 0.1735233
[Epoch 48; Iter    97/  229] train: loss: 0.1499248
[Epoch 48; Iter   127/  229] train: loss: 0.2178590
[Epoch 48; Iter   157/  229] train: loss: 0.1583561
[Epoch 48; Iter   187/  229] train: loss: 0.1510170
[Epoch 48; Iter   217/  229] train: loss: 0.1019757
[Epoch 48] ogbg-moltoxcast: 0.708849 val loss: 0.255084
[Epoch 48] ogbg-moltoxcast: 0.671420 test loss: 0.435481
[Epoch 49; Iter    18/  229] train: loss: 0.1343421
[Epoch 49; Iter    48/  229] train: loss: 0.1327264
[Epoch 49; Iter    78/  229] train: loss: 0.1091292
[Epoch 49; Iter   108/  229] train: loss: 0.2653774
[Epoch 49; Iter   138/  229] train: loss: 0.1390121
[Epoch 49; Iter   168/  229] train: loss: 0.1162476
[Epoch 49; Iter   198/  229] train: loss: 0.1641736
[Epoch 49; Iter   228/  229] train: loss: 0.1115878
[Epoch 49] ogbg-moltoxcast: 0.705306 val loss: 0.252989
[Epoch 49] ogbg-moltoxcast: 0.662964 test loss: 0.381344
[Epoch 50; Iter    29/  229] train: loss: 0.1277355
[Epoch 50; Iter    59/  229] train: loss: 0.1147359
[Epoch 50; Iter    89/  229] train: loss: 0.1033860
[Epoch 50; Iter   119/  229] train: loss: 0.1360527
[Epoch 50; Iter   149/  229] train: loss: 0.1056459
[Epoch 50; Iter   179/  229] train: loss: 0.1727440
[Epoch 50; Iter   209/  229] train: loss: 0.1215593
[Epoch 50] ogbg-moltoxcast: 0.699816 val loss: 0.258641
[Epoch 50] ogbg-moltoxcast: 0.664828 test loss: 0.380686
[Epoch 51; Iter    10/  229] train: loss: 0.1108524
[Epoch 51; Iter    40/  229] train: loss: 0.1390020
[Epoch 51; Iter    70/  229] train: loss: 0.1300679
[Epoch 51; Iter   100/  229] train: loss: 0.1345446
[Epoch 51; Iter   130/  229] train: loss: 0.1160828
[Epoch 51; Iter   160/  229] train: loss: 0.1268274
[Epoch 51; Iter   190/  229] train: loss: 0.1386392
[Epoch 51; Iter   220/  229] train: loss: 0.0916795
[Epoch 51] ogbg-moltoxcast: 0.699290 val loss: 0.260049
[Epoch 51] ogbg-moltoxcast: 0.667167 test loss: 0.416024
[Epoch 52; Iter    21/  229] train: loss: 0.1932610
[Epoch 52; Iter    51/  229] train: loss: 0.1458805
[Epoch 52; Iter    81/  229] train: loss: 0.1608481
[Epoch 52; Iter   111/  229] train: loss: 0.1317167
[Epoch 52; Iter   141/  229] train: loss: 0.1127878
[Epoch 52; Iter   171/  229] train: loss: 0.1602206
[Epoch 52; Iter   201/  229] train: loss: 0.1441847
[Epoch 52] ogbg-moltoxcast: 0.696034 val loss: 0.254848
[Epoch 52] ogbg-moltoxcast: 0.670679 test loss: 0.364385
[Epoch 53; Iter     2/  229] train: loss: 0.1198471
[Epoch 53; Iter    32/  229] train: loss: 0.1420175
[Epoch 53; Iter    62/  229] train: loss: 0.1449426
[Epoch 53; Iter    92/  229] train: loss: 0.1155688
[Epoch 53; Iter   122/  229] train: loss: 0.1597206
[Epoch 53; Iter   152/  229] train: loss: 0.1545125
[Epoch 53; Iter   182/  229] train: loss: 0.1394321
[Epoch 53; Iter   212/  229] train: loss: 0.1661325
[Epoch 53] ogbg-moltoxcast: 0.698209 val loss: 0.255991
[Epoch 53] ogbg-moltoxcast: 0.661058 test loss: 0.637928
[Epoch 54; Iter    13/  229] train: loss: 0.0877364
[Epoch 54; Iter    43/  229] train: loss: 0.1416303
[Epoch 54; Iter    73/  229] train: loss: 0.1034669
[Epoch 54; Iter   103/  229] train: loss: 0.1564030
[Epoch 54; Iter   133/  229] train: loss: 0.1745578
[Epoch 54; Iter   163/  229] train: loss: 0.1725564
[Epoch 54; Iter   193/  229] train: loss: 0.1964550
[Epoch 54; Iter   223/  229] train: loss: 0.1899232
[Epoch 54] ogbg-moltoxcast: 0.694584 val loss: 0.251255
[Epoch 54] ogbg-moltoxcast: 0.662185 test loss: 0.424622
[Epoch 55; Iter    24/  229] train: loss: 0.1257832
[Epoch 55; Iter    54/  229] train: loss: 0.1809217
[Epoch 55; Iter    84/  229] train: loss: 0.1335083
[Epoch 55; Iter   114/  229] train: loss: 0.1264865
[Epoch 55; Iter   144/  229] train: loss: 0.1315909
[Epoch 55; Iter   174/  229] train: loss: 0.1454550
[Epoch 55; Iter   204/  229] train: loss: 0.0911184
[Epoch 55] ogbg-moltoxcast: 0.691855 val loss: 0.269963
[Epoch 55] ogbg-moltoxcast: 0.661263 test loss: 0.546877
[Epoch 56; Iter     5/  229] train: loss: 0.1375457
[Epoch 56; Iter    35/  229] train: loss: 0.1232678
[Epoch 56; Iter    65/  229] train: loss: 0.1147866
[Epoch 56; Iter    95/  229] train: loss: 0.1142300
[Epoch 56; Iter   125/  229] train: loss: 0.1527572
[Epoch 56; Iter   155/  229] train: loss: 0.1356679
[Epoch 56; Iter   185/  229] train: loss: 0.1424558
[Epoch 56; Iter   215/  229] train: loss: 0.1340842
[Epoch 56] ogbg-moltoxcast: 0.693318 val loss: 0.267269
[Epoch 56] ogbg-moltoxcast: 0.661538 test loss: 0.391923
[Epoch 57; Iter    16/  229] train: loss: 0.1490760
[Epoch 57; Iter    46/  229] train: loss: 0.1144811
[Epoch 57; Iter    76/  229] train: loss: 0.1541462
[Epoch 57; Iter   106/  229] train: loss: 0.1088014
[Epoch 57; Iter   136/  229] train: loss: 0.1229801
[Epoch 57; Iter   166/  229] train: loss: 0.1295734
[Epoch 57; Iter   196/  229] train: loss: 0.1466262
[Epoch 57; Iter   226/  229] train: loss: 0.1547676
[Epoch 57] ogbg-moltoxcast: 0.702661 val loss: 0.261785
[Epoch 57] ogbg-moltoxcast: 0.658082 test loss: 0.330792
[Epoch 58; Iter    27/  229] train: loss: 0.1528757
[Epoch 58; Iter    57/  229] train: loss: 0.1492877
[Epoch 58; Iter    87/  229] train: loss: 0.1127641
[Epoch 58; Iter   117/  229] train: loss: 0.1129559
[Epoch 58; Iter   147/  229] train: loss: 0.1445134
[Epoch 58; Iter   177/  229] train: loss: 0.2055900
[Epoch 58; Iter   207/  229] train: loss: 0.1540873
[Epoch 58] ogbg-moltoxcast: 0.703561 val loss: 0.260691
[Epoch 58] ogbg-moltoxcast: 0.664441 test loss: 0.412440
[Epoch 59; Iter     8/  229] train: loss: 0.1135763
[Epoch 59; Iter    38/  229] train: loss: 0.1492689
[Epoch 59; Iter    68/  229] train: loss: 0.1098963
[Epoch 59; Iter    98/  229] train: loss: 0.1518555
[Epoch 59; Iter   128/  229] train: loss: 0.1529997
[Epoch 59; Iter   158/  229] train: loss: 0.1305115
[Epoch 59; Iter   188/  229] train: loss: 0.1068003
[Epoch 59; Iter   218/  229] train: loss: 0.1775779
[Epoch 59] ogbg-moltoxcast: 0.692431 val loss: 0.262233
[Epoch 59] ogbg-moltoxcast: 0.659982 test loss: 0.484243
[Epoch 48; Iter   183/  201] train: loss: 0.1378175
[Epoch 48] ogbg-moltoxcast: 0.666962 val loss: 0.269243
[Epoch 48] ogbg-moltoxcast: 0.660466 test loss: 0.310218
[Epoch 49; Iter    12/  201] train: loss: 0.1345390
[Epoch 49; Iter    42/  201] train: loss: 0.1133053
[Epoch 49; Iter    72/  201] train: loss: 0.1184327
[Epoch 49; Iter   102/  201] train: loss: 0.1461476
[Epoch 49; Iter   132/  201] train: loss: 0.1548494
[Epoch 49; Iter   162/  201] train: loss: 0.1623173
[Epoch 49; Iter   192/  201] train: loss: 0.1578326
[Epoch 49] ogbg-moltoxcast: 0.675730 val loss: 0.257988
[Epoch 49] ogbg-moltoxcast: 0.667056 test loss: 0.297061
[Epoch 50; Iter    21/  201] train: loss: 0.1478714
[Epoch 50; Iter    51/  201] train: loss: 0.1126693
[Epoch 50; Iter    81/  201] train: loss: 0.0775370
[Epoch 50; Iter   111/  201] train: loss: 0.0889700
[Epoch 50; Iter   141/  201] train: loss: 0.1371769
[Epoch 50; Iter   171/  201] train: loss: 0.1427080
[Epoch 50; Iter   201/  201] train: loss: 0.1194635
[Epoch 50] ogbg-moltoxcast: 0.665830 val loss: 0.272182
[Epoch 50] ogbg-moltoxcast: 0.660206 test loss: 0.311962
[Epoch 51; Iter    30/  201] train: loss: 0.1501224
[Epoch 51; Iter    60/  201] train: loss: 0.1556660
[Epoch 51; Iter    90/  201] train: loss: 0.1184874
[Epoch 51; Iter   120/  201] train: loss: 0.1226613
[Epoch 51; Iter   150/  201] train: loss: 0.1250044
[Epoch 51; Iter   180/  201] train: loss: 0.1894255
[Epoch 51] ogbg-moltoxcast: 0.664780 val loss: 0.260979
[Epoch 51] ogbg-moltoxcast: 0.657918 test loss: 0.301787
[Epoch 52; Iter     9/  201] train: loss: 0.2119417
[Epoch 52; Iter    39/  201] train: loss: 0.1435315
[Epoch 52; Iter    69/  201] train: loss: 0.1421328
[Epoch 52; Iter    99/  201] train: loss: 0.0766725
[Epoch 52; Iter   129/  201] train: loss: 0.1275520
[Epoch 52; Iter   159/  201] train: loss: 0.1161517
[Epoch 52; Iter   189/  201] train: loss: 0.1284928
[Epoch 52] ogbg-moltoxcast: 0.672085 val loss: 0.271321
[Epoch 52] ogbg-moltoxcast: 0.666109 test loss: 0.315933
[Epoch 53; Iter    18/  201] train: loss: 0.1448602
[Epoch 53; Iter    48/  201] train: loss: 0.1386546
[Epoch 53; Iter    78/  201] train: loss: 0.0929623
[Epoch 53; Iter   108/  201] train: loss: 0.0779172
[Epoch 53; Iter   138/  201] train: loss: 0.1317146
[Epoch 53; Iter   168/  201] train: loss: 0.1668526
[Epoch 53; Iter   198/  201] train: loss: 0.1585814
[Epoch 53] ogbg-moltoxcast: 0.681270 val loss: 0.262693
[Epoch 53] ogbg-moltoxcast: 0.669203 test loss: 0.309381
[Epoch 54; Iter    27/  201] train: loss: 0.1484352
[Epoch 54; Iter    57/  201] train: loss: 0.1297641
[Epoch 54; Iter    87/  201] train: loss: 0.1112119
[Epoch 54; Iter   117/  201] train: loss: 0.1747528
[Epoch 54; Iter   147/  201] train: loss: 0.1125537
[Epoch 54; Iter   177/  201] train: loss: 0.2588346
[Epoch 54] ogbg-moltoxcast: 0.674213 val loss: 0.258858
[Epoch 54] ogbg-moltoxcast: 0.665836 test loss: 0.300292
[Epoch 55; Iter     6/  201] train: loss: 0.1103935
[Epoch 55; Iter    36/  201] train: loss: 0.1479827
[Epoch 55; Iter    66/  201] train: loss: 0.1651879
[Epoch 55; Iter    96/  201] train: loss: 0.1700457
[Epoch 55; Iter   126/  201] train: loss: 0.1556710
[Epoch 55; Iter   156/  201] train: loss: 0.1189280
[Epoch 55; Iter   186/  201] train: loss: 0.1816284
[Epoch 55] ogbg-moltoxcast: 0.676288 val loss: 0.270522
[Epoch 55] ogbg-moltoxcast: 0.671418 test loss: 0.311909
[Epoch 56; Iter    15/  201] train: loss: 0.1153026
[Epoch 56; Iter    45/  201] train: loss: 0.1649463
[Epoch 56; Iter    75/  201] train: loss: 0.1054691
[Epoch 56; Iter   105/  201] train: loss: 0.1542513
[Epoch 56; Iter   135/  201] train: loss: 0.1481423
[Epoch 56; Iter   165/  201] train: loss: 0.2051420
[Epoch 56; Iter   195/  201] train: loss: 0.1859836
[Epoch 56] ogbg-moltoxcast: 0.667901 val loss: 0.272859
[Epoch 56] ogbg-moltoxcast: 0.666894 test loss: 0.311688
[Epoch 57; Iter    24/  201] train: loss: 0.1302986
[Epoch 57; Iter    54/  201] train: loss: 0.1600175
[Epoch 57; Iter    84/  201] train: loss: 0.1093885
[Epoch 57; Iter   114/  201] train: loss: 0.1216030
[Epoch 57; Iter   144/  201] train: loss: 0.1559678
[Epoch 57; Iter   174/  201] train: loss: 0.0933664
[Epoch 57] ogbg-moltoxcast: 0.676079 val loss: 0.269650
[Epoch 57] ogbg-moltoxcast: 0.666845 test loss: 0.311782
[Epoch 58; Iter     3/  201] train: loss: 0.1402477
[Epoch 58; Iter    33/  201] train: loss: 0.1106578
[Epoch 58; Iter    63/  201] train: loss: 0.1276699
[Epoch 58; Iter    93/  201] train: loss: 0.1679706
[Epoch 58; Iter   123/  201] train: loss: 0.0803093
[Epoch 58; Iter   153/  201] train: loss: 0.1696510
[Epoch 58; Iter   183/  201] train: loss: 0.1629606
[Epoch 58] ogbg-moltoxcast: 0.675070 val loss: 0.263640
[Epoch 58] ogbg-moltoxcast: 0.667566 test loss: 0.302416
[Epoch 59; Iter    12/  201] train: loss: 0.1672351
[Epoch 59; Iter    42/  201] train: loss: 0.1673703
[Epoch 59; Iter    72/  201] train: loss: 0.0935460
[Epoch 59; Iter   102/  201] train: loss: 0.1081937
[Epoch 59; Iter   132/  201] train: loss: 0.0908083
[Epoch 59; Iter   162/  201] train: loss: 0.1431094
[Epoch 59; Iter   192/  201] train: loss: 0.1846864
[Epoch 59] ogbg-moltoxcast: 0.678336 val loss: 0.270541
[Epoch 59] ogbg-moltoxcast: 0.665664 test loss: 0.312304
[Epoch 60; Iter    21/  201] train: loss: 0.1269995
[Epoch 60; Iter    51/  201] train: loss: 0.0716682
[Epoch 60; Iter    81/  201] train: loss: 0.1848748
[Epoch 60; Iter   111/  201] train: loss: 0.1098929
[Epoch 60; Iter   141/  201] train: loss: 0.1194285
[Epoch 60; Iter   171/  201] train: loss: 0.1110987
[Epoch 60; Iter   201/  201] train: loss: 0.0412312
[Epoch 60] ogbg-moltoxcast: 0.665838 val loss: 0.270482
[Epoch 60] ogbg-moltoxcast: 0.661956 test loss: 0.306160
[Epoch 61; Iter    30/  201] train: loss: 0.0665867
[Epoch 61; Iter    60/  201] train: loss: 0.0889410
[Epoch 61; Iter    90/  201] train: loss: 0.1311928
[Epoch 61; Iter   120/  201] train: loss: 0.1559092
[Epoch 61; Iter   150/  201] train: loss: 0.1793448
[Epoch 61; Iter   180/  201] train: loss: 0.1227461
[Epoch 61] ogbg-moltoxcast: 0.667402 val loss: 0.275195
[Epoch 61] ogbg-moltoxcast: 0.658079 test loss: 0.313017
[Epoch 62; Iter     9/  201] train: loss: 0.1365401
[Epoch 62; Iter    39/  201] train: loss: 0.1143160
[Epoch 62; Iter    69/  201] train: loss: 0.1300354
[Epoch 62; Iter    99/  201] train: loss: 0.1116130
[Epoch 62; Iter   129/  201] train: loss: 0.1226650
[Epoch 62; Iter   159/  201] train: loss: 0.1427520
[Epoch 62; Iter   189/  201] train: loss: 0.1220955
[Epoch 62] ogbg-moltoxcast: 0.671565 val loss: 0.264818
[Epoch 62] ogbg-moltoxcast: 0.660718 test loss: 0.302916
[Epoch 63; Iter    18/  201] train: loss: 0.1944599
[Epoch 63; Iter    48/  201] train: loss: 0.1345987
[Epoch 63; Iter    78/  201] train: loss: 0.1472140
[Epoch 63; Iter   108/  201] train: loss: 0.1808535
[Epoch 63; Iter   138/  201] train: loss: 0.1559686
[Epoch 63; Iter   168/  201] train: loss: 0.1019580
[Epoch 63; Iter   198/  201] train: loss: 0.2198473
[Epoch 63] ogbg-moltoxcast: 0.671869 val loss: 0.268479
[Epoch 63] ogbg-moltoxcast: 0.663329 test loss: 0.307606
[Epoch 64; Iter    27/  201] train: loss: 0.1321509
[Epoch 64; Iter    57/  201] train: loss: 0.1206692
[Epoch 64; Iter    87/  201] train: loss: 0.1086070
[Epoch 64; Iter   117/  201] train: loss: 0.1931501
[Epoch 64; Iter   147/  201] train: loss: 0.1164279
[Epoch 64; Iter   177/  201] train: loss: 0.0971589
[Epoch 64] ogbg-moltoxcast: 0.673156 val loss: 0.264028
[Epoch 64] ogbg-moltoxcast: 0.661100 test loss: 0.303854
[Epoch 65; Iter     6/  201] train: loss: 0.1545327
[Epoch 65; Iter    36/  201] train: loss: 0.1875192
[Epoch 65; Iter    66/  201] train: loss: 0.2202439
[Epoch 65; Iter    96/  201] train: loss: 0.1247583
[Epoch 65; Iter   126/  201] train: loss: 0.1203445
[Epoch 65; Iter   156/  201] train: loss: 0.1200379
[Epoch 65; Iter   186/  201] train: loss: 0.1171257
[Epoch 65] ogbg-moltoxcast: 0.671479 val loss: 0.267783
[Epoch 65] ogbg-moltoxcast: 0.671088 test loss: 0.308872
[Epoch 66; Iter    15/  201] train: loss: 0.0958831
[Epoch 66; Iter    45/  201] train: loss: 0.0846308
[Epoch 66; Iter    75/  201] train: loss: 0.1474011
[Epoch 48; Iter   183/  201] train: loss: 0.1124519
[Epoch 48] ogbg-moltoxcast: 0.679487 val loss: 0.267139
[Epoch 48] ogbg-moltoxcast: 0.670847 test loss: 0.308751
[Epoch 49; Iter    12/  201] train: loss: 0.1117404
[Epoch 49; Iter    42/  201] train: loss: 0.0939574
[Epoch 49; Iter    72/  201] train: loss: 0.1439884
[Epoch 49; Iter   102/  201] train: loss: 0.1227845
[Epoch 49; Iter   132/  201] train: loss: 0.1425943
[Epoch 49; Iter   162/  201] train: loss: 0.1256366
[Epoch 49; Iter   192/  201] train: loss: 0.1171816
[Epoch 49] ogbg-moltoxcast: 0.673338 val loss: 0.268962
[Epoch 49] ogbg-moltoxcast: 0.663585 test loss: 0.312176
[Epoch 50; Iter    21/  201] train: loss: 0.1728342
[Epoch 50; Iter    51/  201] train: loss: 0.1472530
[Epoch 50; Iter    81/  201] train: loss: 0.1233974
[Epoch 50; Iter   111/  201] train: loss: 0.1290063
[Epoch 50; Iter   141/  201] train: loss: 0.0853370
[Epoch 50; Iter   171/  201] train: loss: 0.1562104
[Epoch 50; Iter   201/  201] train: loss: 0.1307386
[Epoch 50] ogbg-moltoxcast: 0.672106 val loss: 0.277700
[Epoch 50] ogbg-moltoxcast: 0.659141 test loss: 0.316667
[Epoch 51; Iter    30/  201] train: loss: 0.1390024
[Epoch 51; Iter    60/  201] train: loss: 0.1682982
[Epoch 51; Iter    90/  201] train: loss: 0.1524680
[Epoch 51; Iter   120/  201] train: loss: 0.1521735
[Epoch 51; Iter   150/  201] train: loss: 0.1452567
[Epoch 51; Iter   180/  201] train: loss: 0.1062614
[Epoch 51] ogbg-moltoxcast: 0.674677 val loss: 0.264341
[Epoch 51] ogbg-moltoxcast: 0.671456 test loss: 0.300902
[Epoch 52; Iter     9/  201] train: loss: 0.1096137
[Epoch 52; Iter    39/  201] train: loss: 0.1511699
[Epoch 52; Iter    69/  201] train: loss: 0.1571425
[Epoch 52; Iter    99/  201] train: loss: 0.0985997
[Epoch 52; Iter   129/  201] train: loss: 0.1769874
[Epoch 52; Iter   159/  201] train: loss: 0.1602889
[Epoch 52; Iter   189/  201] train: loss: 0.1444037
[Epoch 52] ogbg-moltoxcast: 0.675250 val loss: 0.270203
[Epoch 52] ogbg-moltoxcast: 0.674838 test loss: 0.311606
[Epoch 53; Iter    18/  201] train: loss: 0.1246461
[Epoch 53; Iter    48/  201] train: loss: 0.1452882
[Epoch 53; Iter    78/  201] train: loss: 0.2051248
[Epoch 53; Iter   108/  201] train: loss: 0.1339499
[Epoch 53; Iter   138/  201] train: loss: 0.1784066
[Epoch 53; Iter   168/  201] train: loss: 0.1629723
[Epoch 53; Iter   198/  201] train: loss: 0.1443852
[Epoch 53] ogbg-moltoxcast: 0.683320 val loss: 0.262266
[Epoch 53] ogbg-moltoxcast: 0.668340 test loss: 0.300893
[Epoch 54; Iter    27/  201] train: loss: 0.1213426
[Epoch 54; Iter    57/  201] train: loss: 0.1249961
[Epoch 54; Iter    87/  201] train: loss: 0.1989647
[Epoch 54; Iter   117/  201] train: loss: 0.1673429
[Epoch 54; Iter   147/  201] train: loss: 0.0873167
[Epoch 54; Iter   177/  201] train: loss: 0.1391366
[Epoch 54] ogbg-moltoxcast: 0.680466 val loss: 0.266300
[Epoch 54] ogbg-moltoxcast: 0.674803 test loss: 0.306113
[Epoch 55; Iter     6/  201] train: loss: 0.1293674
[Epoch 55; Iter    36/  201] train: loss: 0.1565564
[Epoch 55; Iter    66/  201] train: loss: 0.1865498
[Epoch 55; Iter    96/  201] train: loss: 0.0885615
[Epoch 55; Iter   126/  201] train: loss: 0.1742651
[Epoch 55; Iter   156/  201] train: loss: 0.1678670
[Epoch 55; Iter   186/  201] train: loss: 0.1574303
[Epoch 55] ogbg-moltoxcast: 0.679253 val loss: 0.277422
[Epoch 55] ogbg-moltoxcast: 0.667873 test loss: 0.322647
[Epoch 56; Iter    15/  201] train: loss: 0.1220828
[Epoch 56; Iter    45/  201] train: loss: 0.1307226
[Epoch 56; Iter    75/  201] train: loss: 0.1657445
[Epoch 56; Iter   105/  201] train: loss: 0.1094143
[Epoch 56; Iter   135/  201] train: loss: 0.1173283
[Epoch 56; Iter   165/  201] train: loss: 0.1194575
[Epoch 56; Iter   195/  201] train: loss: 0.1714960
[Epoch 56] ogbg-moltoxcast: 0.684472 val loss: 0.262245
[Epoch 56] ogbg-moltoxcast: 0.665648 test loss: 0.306075
[Epoch 57; Iter    24/  201] train: loss: 0.1252008
[Epoch 57; Iter    54/  201] train: loss: 0.1023544
[Epoch 57; Iter    84/  201] train: loss: 0.1157828
[Epoch 57; Iter   114/  201] train: loss: 0.0996622
[Epoch 57; Iter   144/  201] train: loss: 0.1017548
[Epoch 57; Iter   174/  201] train: loss: 0.2035140
[Epoch 57] ogbg-moltoxcast: 0.674803 val loss: 0.264612
[Epoch 57] ogbg-moltoxcast: 0.666607 test loss: 0.305219
[Epoch 58; Iter     3/  201] train: loss: 0.1448033
[Epoch 58; Iter    33/  201] train: loss: 0.1257032
[Epoch 58; Iter    63/  201] train: loss: 0.1291288
[Epoch 58; Iter    93/  201] train: loss: 0.1759522
[Epoch 58; Iter   123/  201] train: loss: 0.1321638
[Epoch 58; Iter   153/  201] train: loss: 0.1207895
[Epoch 58; Iter   183/  201] train: loss: 0.1513442
[Epoch 58] ogbg-moltoxcast: 0.676544 val loss: 0.265415
[Epoch 58] ogbg-moltoxcast: 0.672194 test loss: 0.306072
[Epoch 59; Iter    12/  201] train: loss: 0.1233997
[Epoch 59; Iter    42/  201] train: loss: 0.1256236
[Epoch 59; Iter    72/  201] train: loss: 0.1111076
[Epoch 59; Iter   102/  201] train: loss: 0.1804305
[Epoch 59; Iter   132/  201] train: loss: 0.1316906
[Epoch 59; Iter   162/  201] train: loss: 0.1049862
[Epoch 59; Iter   192/  201] train: loss: 0.1248057
[Epoch 59] ogbg-moltoxcast: 0.677745 val loss: 0.261924
[Epoch 59] ogbg-moltoxcast: 0.664633 test loss: 0.300447
[Epoch 60; Iter    21/  201] train: loss: 0.1391059
[Epoch 60; Iter    51/  201] train: loss: 0.1506283
[Epoch 60; Iter    81/  201] train: loss: 0.1310273
[Epoch 60; Iter   111/  201] train: loss: 0.0857771
[Epoch 60; Iter   141/  201] train: loss: 0.1041175
[Epoch 60; Iter   171/  201] train: loss: 0.1493229
[Epoch 60; Iter   201/  201] train: loss: 0.9402049
[Epoch 60] ogbg-moltoxcast: 0.677230 val loss: 0.279330
[Epoch 60] ogbg-moltoxcast: 0.671339 test loss: 0.320876
[Epoch 61; Iter    30/  201] train: loss: 0.1663492
[Epoch 61; Iter    60/  201] train: loss: 0.1352250
[Epoch 61; Iter    90/  201] train: loss: 0.1499672
[Epoch 61; Iter   120/  201] train: loss: 0.1246981
[Epoch 61; Iter   150/  201] train: loss: 0.1569048
[Epoch 61; Iter   180/  201] train: loss: 0.1059931
[Epoch 61] ogbg-moltoxcast: 0.676556 val loss: 0.274466
[Epoch 61] ogbg-moltoxcast: 0.668988 test loss: 0.319199
[Epoch 62; Iter     9/  201] train: loss: 0.1255130
[Epoch 62; Iter    39/  201] train: loss: 0.1102400
[Epoch 62; Iter    69/  201] train: loss: 0.1305022
[Epoch 62; Iter    99/  201] train: loss: 0.1335130
[Epoch 62; Iter   129/  201] train: loss: 0.1772861
[Epoch 62; Iter   159/  201] train: loss: 0.1468358
[Epoch 62; Iter   189/  201] train: loss: 0.1318088
[Epoch 62] ogbg-moltoxcast: 0.677808 val loss: 0.267331
[Epoch 62] ogbg-moltoxcast: 0.671433 test loss: 0.309088
[Epoch 63; Iter    18/  201] train: loss: 0.0899693
[Epoch 63; Iter    48/  201] train: loss: 0.1242559
[Epoch 63; Iter    78/  201] train: loss: 0.0982457
[Epoch 63; Iter   108/  201] train: loss: 0.1629052
[Epoch 63; Iter   138/  201] train: loss: 0.1158334
[Epoch 63; Iter   168/  201] train: loss: 0.1329244
[Epoch 63; Iter   198/  201] train: loss: 0.1474301
[Epoch 63] ogbg-moltoxcast: 0.682992 val loss: 0.261009
[Epoch 63] ogbg-moltoxcast: 0.667109 test loss: 0.303928
[Epoch 64; Iter    27/  201] train: loss: 0.1342938
[Epoch 64; Iter    57/  201] train: loss: 0.1331784
[Epoch 64; Iter    87/  201] train: loss: 0.0916735
[Epoch 64; Iter   117/  201] train: loss: 0.1004771
[Epoch 64; Iter   147/  201] train: loss: 0.1441895
[Epoch 64; Iter   177/  201] train: loss: 0.1864482
[Epoch 64] ogbg-moltoxcast: 0.683904 val loss: 0.269904
[Epoch 64] ogbg-moltoxcast: 0.665974 test loss: 0.315827
[Epoch 65; Iter     6/  201] train: loss: 0.1117662
[Epoch 65; Iter    36/  201] train: loss: 0.1653094
[Epoch 65; Iter    66/  201] train: loss: 0.1600028
[Epoch 65; Iter    96/  201] train: loss: 0.1468490
[Epoch 65; Iter   126/  201] train: loss: 0.1132652
[Epoch 65; Iter   156/  201] train: loss: 0.1502270
[Epoch 65; Iter   186/  201] train: loss: 0.1001864
[Epoch 65] ogbg-moltoxcast: 0.682628 val loss: 0.265628
[Epoch 65] ogbg-moltoxcast: 0.660961 test loss: 0.315402
[Epoch 66; Iter    15/  201] train: loss: 0.1649910
[Epoch 66; Iter    45/  201] train: loss: 0.1640869
[Epoch 66; Iter    75/  201] train: loss: 0.1873898
[Epoch 48; Iter   183/  201] train: loss: 0.1241377
[Epoch 48] ogbg-moltoxcast: 0.673482 val loss: 0.268425
[Epoch 48] ogbg-moltoxcast: 0.657617 test loss: 0.314595
[Epoch 49; Iter    12/  201] train: loss: 0.1822032
[Epoch 49; Iter    42/  201] train: loss: 0.1057000
[Epoch 49; Iter    72/  201] train: loss: 0.2773225
[Epoch 49; Iter   102/  201] train: loss: 0.1081228
[Epoch 49; Iter   132/  201] train: loss: 0.1462318
[Epoch 49; Iter   162/  201] train: loss: 0.1150975
[Epoch 49; Iter   192/  201] train: loss: 0.1021708
[Epoch 49] ogbg-moltoxcast: 0.672580 val loss: 0.268069
[Epoch 49] ogbg-moltoxcast: 0.656544 test loss: 0.313292
[Epoch 50; Iter    21/  201] train: loss: 0.1205334
[Epoch 50; Iter    51/  201] train: loss: 0.1543946
[Epoch 50; Iter    81/  201] train: loss: 0.1298906
[Epoch 50; Iter   111/  201] train: loss: 0.1062253
[Epoch 50; Iter   141/  201] train: loss: 0.1104911
[Epoch 50; Iter   171/  201] train: loss: 0.1600135
[Epoch 50; Iter   201/  201] train: loss: 0.1682434
[Epoch 50] ogbg-moltoxcast: 0.666195 val loss: 0.269607
[Epoch 50] ogbg-moltoxcast: 0.657385 test loss: 0.314024
[Epoch 51; Iter    30/  201] train: loss: 0.2207127
[Epoch 51; Iter    60/  201] train: loss: 0.1286789
[Epoch 51; Iter    90/  201] train: loss: 0.1438403
[Epoch 51; Iter   120/  201] train: loss: 0.1118038
[Epoch 51; Iter   150/  201] train: loss: 0.1312519
[Epoch 51; Iter   180/  201] train: loss: 0.1727908
[Epoch 51] ogbg-moltoxcast: 0.675986 val loss: 0.263957
[Epoch 51] ogbg-moltoxcast: 0.654960 test loss: 0.309453
[Epoch 52; Iter     9/  201] train: loss: 0.1084089
[Epoch 52; Iter    39/  201] train: loss: 0.0988513
[Epoch 52; Iter    69/  201] train: loss: 0.1046485
[Epoch 52; Iter    99/  201] train: loss: 0.1121395
[Epoch 52; Iter   129/  201] train: loss: 0.1508502
[Epoch 52; Iter   159/  201] train: loss: 0.1077534
[Epoch 52; Iter   189/  201] train: loss: 0.1362393
[Epoch 52] ogbg-moltoxcast: 0.672100 val loss: 0.271993
[Epoch 52] ogbg-moltoxcast: 0.654777 test loss: 0.316921
[Epoch 53; Iter    18/  201] train: loss: 0.1449578
[Epoch 53; Iter    48/  201] train: loss: 0.1245764
[Epoch 53; Iter    78/  201] train: loss: 0.1568099
[Epoch 53; Iter   108/  201] train: loss: 0.1481626
[Epoch 53; Iter   138/  201] train: loss: 0.0777461
[Epoch 53; Iter   168/  201] train: loss: 0.1519838
[Epoch 53; Iter   198/  201] train: loss: 0.1038730
[Epoch 53] ogbg-moltoxcast: 0.670832 val loss: 0.270053
[Epoch 53] ogbg-moltoxcast: 0.651233 test loss: 0.319222
[Epoch 54; Iter    27/  201] train: loss: 0.1184145
[Epoch 54; Iter    57/  201] train: loss: 0.1635282
[Epoch 54; Iter    87/  201] train: loss: 0.1346345
[Epoch 54; Iter   117/  201] train: loss: 0.1915842
[Epoch 54; Iter   147/  201] train: loss: 0.1483808
[Epoch 54; Iter   177/  201] train: loss: 0.1107905
[Epoch 54] ogbg-moltoxcast: 0.670427 val loss: 0.267802
[Epoch 54] ogbg-moltoxcast: 0.651670 test loss: 0.315067
[Epoch 55; Iter     6/  201] train: loss: 0.1457991
[Epoch 55; Iter    36/  201] train: loss: 0.1511876
[Epoch 55; Iter    66/  201] train: loss: 0.1029241
[Epoch 55; Iter    96/  201] train: loss: 0.1202449
[Epoch 55; Iter   126/  201] train: loss: 0.1222657
[Epoch 55; Iter   156/  201] train: loss: 0.1020956
[Epoch 55; Iter   186/  201] train: loss: 0.1266455
[Epoch 55] ogbg-moltoxcast: 0.667133 val loss: 0.278698
[Epoch 55] ogbg-moltoxcast: 0.662346 test loss: 0.322173
[Epoch 56; Iter    15/  201] train: loss: 0.1426747
[Epoch 56; Iter    45/  201] train: loss: 0.1313355
[Epoch 56; Iter    75/  201] train: loss: 0.1422637
[Epoch 56; Iter   105/  201] train: loss: 0.1138672
[Epoch 56; Iter   135/  201] train: loss: 0.1257695
[Epoch 56; Iter   165/  201] train: loss: 0.1157407
[Epoch 56; Iter   195/  201] train: loss: 0.1404849
[Epoch 56] ogbg-moltoxcast: 0.658791 val loss: 0.280428
[Epoch 56] ogbg-moltoxcast: 0.661749 test loss: 0.322799
[Epoch 57; Iter    24/  201] train: loss: 0.1261229
[Epoch 57; Iter    54/  201] train: loss: 0.1535379
[Epoch 57; Iter    84/  201] train: loss: 0.1375793
[Epoch 57; Iter   114/  201] train: loss: 0.1208263
[Epoch 57; Iter   144/  201] train: loss: 0.1174598
[Epoch 57; Iter   174/  201] train: loss: 0.0903657
[Epoch 57] ogbg-moltoxcast: 0.669848 val loss: 0.273773
[Epoch 57] ogbg-moltoxcast: 0.662649 test loss: 0.318186
[Epoch 58; Iter     3/  201] train: loss: 0.1471278
[Epoch 58; Iter    33/  201] train: loss: 0.1167482
[Epoch 58; Iter    63/  201] train: loss: 0.0972032
[Epoch 58; Iter    93/  201] train: loss: 0.1590019
[Epoch 58; Iter   123/  201] train: loss: 0.1091677
[Epoch 58; Iter   153/  201] train: loss: 0.0849453
[Epoch 58; Iter   183/  201] train: loss: 0.1937982
[Epoch 58] ogbg-moltoxcast: 0.672120 val loss: 0.277232
[Epoch 58] ogbg-moltoxcast: 0.662502 test loss: 0.325855
[Epoch 59; Iter    12/  201] train: loss: 0.1329000
[Epoch 59; Iter    42/  201] train: loss: 0.1105600
[Epoch 59; Iter    72/  201] train: loss: 0.1783276
[Epoch 59; Iter   102/  201] train: loss: 0.1147567
[Epoch 59; Iter   132/  201] train: loss: 0.1286701
[Epoch 59; Iter   162/  201] train: loss: 0.1293104
[Epoch 59; Iter   192/  201] train: loss: 0.1291512
[Epoch 59] ogbg-moltoxcast: 0.666115 val loss: 0.281034
[Epoch 59] ogbg-moltoxcast: 0.655392 test loss: 0.327641
[Epoch 60; Iter    21/  201] train: loss: 0.1609518
[Epoch 60; Iter    51/  201] train: loss: 0.0994927
[Epoch 60; Iter    81/  201] train: loss: 0.1180114
[Epoch 60; Iter   111/  201] train: loss: 0.1494361
[Epoch 60; Iter   141/  201] train: loss: 0.1229845
[Epoch 60; Iter   171/  201] train: loss: 0.1323169
[Epoch 60; Iter   201/  201] train: loss: 0.0388322
[Epoch 60] ogbg-moltoxcast: 0.665832 val loss: 0.280299
[Epoch 60] ogbg-moltoxcast: 0.658857 test loss: 0.333575
[Epoch 61; Iter    30/  201] train: loss: 0.1120060
[Epoch 61; Iter    60/  201] train: loss: 0.0998748
[Epoch 61; Iter    90/  201] train: loss: 0.0862271
[Epoch 61; Iter   120/  201] train: loss: 0.1299638
[Epoch 61; Iter   150/  201] train: loss: 0.0982690
[Epoch 61; Iter   180/  201] train: loss: 0.1334798
[Epoch 61] ogbg-moltoxcast: 0.670168 val loss: 0.272033
[Epoch 61] ogbg-moltoxcast: 0.662095 test loss: 0.319990
[Epoch 62; Iter     9/  201] train: loss: 0.0940288
[Epoch 62; Iter    39/  201] train: loss: 0.1365373
[Epoch 62; Iter    69/  201] train: loss: 0.1067464
[Epoch 62; Iter    99/  201] train: loss: 0.1577016
[Epoch 62; Iter   129/  201] train: loss: 0.1361497
[Epoch 62; Iter   159/  201] train: loss: 0.1230411
[Epoch 62; Iter   189/  201] train: loss: 0.1136012
[Epoch 62] ogbg-moltoxcast: 0.673208 val loss: 0.272492
[Epoch 62] ogbg-moltoxcast: 0.663673 test loss: 0.320952
[Epoch 63; Iter    18/  201] train: loss: 0.1230381
[Epoch 63; Iter    48/  201] train: loss: 0.1329736
[Epoch 63; Iter    78/  201] train: loss: 0.1037271
[Epoch 63; Iter   108/  201] train: loss: 0.1067002
[Epoch 63; Iter   138/  201] train: loss: 0.1317290
[Epoch 63; Iter   168/  201] train: loss: 0.0996472
[Epoch 63; Iter   198/  201] train: loss: 0.1058765
[Epoch 63] ogbg-moltoxcast: 0.676581 val loss: 0.270095
[Epoch 63] ogbg-moltoxcast: 0.662960 test loss: 0.319711
[Epoch 64; Iter    27/  201] train: loss: 0.1210841
[Epoch 64; Iter    57/  201] train: loss: 0.1367543
[Epoch 64; Iter    87/  201] train: loss: 0.1084724
[Epoch 64; Iter   117/  201] train: loss: 0.1390139
[Epoch 64; Iter   147/  201] train: loss: 0.1295651
[Epoch 64; Iter   177/  201] train: loss: 0.1085377
[Epoch 64] ogbg-moltoxcast: 0.666359 val loss: 0.274577
[Epoch 64] ogbg-moltoxcast: 0.652647 test loss: 0.325227
[Epoch 65; Iter     6/  201] train: loss: 0.1109939
[Epoch 65; Iter    36/  201] train: loss: 0.1296778
[Epoch 65; Iter    66/  201] train: loss: 0.1280348
[Epoch 65; Iter    96/  201] train: loss: 0.1322293
[Epoch 65; Iter   126/  201] train: loss: 0.1068554
[Epoch 65; Iter   156/  201] train: loss: 0.1170673
[Epoch 65; Iter   186/  201] train: loss: 0.1181540
[Epoch 65] ogbg-moltoxcast: 0.674488 val loss: 0.269662
[Epoch 65] ogbg-moltoxcast: 0.658348 test loss: 0.320325
[Epoch 66; Iter    15/  201] train: loss: 0.1363831
[Epoch 66; Iter    45/  201] train: loss: 0.1383158
[Epoch 66; Iter    75/  201] train: loss: 0.1232582
[Epoch 54; Iter   154/  172] train: loss: 0.1300612
[Epoch 54] ogbg-moltoxcast: 0.656369 val loss: 0.287068
[Epoch 54] ogbg-moltoxcast: 0.609215 test loss: 0.343230
[Epoch 55; Iter    12/  172] train: loss: 0.1224993
[Epoch 55; Iter    42/  172] train: loss: 0.1385914
[Epoch 55; Iter    72/  172] train: loss: 0.1320451
[Epoch 55; Iter   102/  172] train: loss: 0.1379589
[Epoch 55; Iter   132/  172] train: loss: 0.1348758
[Epoch 55; Iter   162/  172] train: loss: 0.1507569
[Epoch 55] ogbg-moltoxcast: 0.663995 val loss: 0.299154
[Epoch 55] ogbg-moltoxcast: 0.615999 test loss: 0.359520
[Epoch 56; Iter    20/  172] train: loss: 0.0929637
[Epoch 56; Iter    50/  172] train: loss: 0.1361145
[Epoch 56; Iter    80/  172] train: loss: 0.1533922
[Epoch 56; Iter   110/  172] train: loss: 0.1351057
[Epoch 56; Iter   140/  172] train: loss: 0.1773990
[Epoch 56; Iter   170/  172] train: loss: 0.1544625
[Epoch 56] ogbg-moltoxcast: 0.666163 val loss: 0.291300
[Epoch 56] ogbg-moltoxcast: 0.617559 test loss: 0.344056
[Epoch 57; Iter    28/  172] train: loss: 0.0949967
[Epoch 57; Iter    58/  172] train: loss: 0.1092103
[Epoch 57; Iter    88/  172] train: loss: 0.2469186
[Epoch 57; Iter   118/  172] train: loss: 0.1798087
[Epoch 57; Iter   148/  172] train: loss: 0.0767041
[Epoch 57] ogbg-moltoxcast: 0.646524 val loss: 0.386437
[Epoch 57] ogbg-moltoxcast: 0.614833 test loss: 0.500077
[Epoch 58; Iter     6/  172] train: loss: 0.1263348
[Epoch 58; Iter    36/  172] train: loss: 0.0933498
[Epoch 58; Iter    66/  172] train: loss: 0.1494996
[Epoch 58; Iter    96/  172] train: loss: 0.1167637
[Epoch 58; Iter   126/  172] train: loss: 0.1781179
[Epoch 58; Iter   156/  172] train: loss: 0.1461425
[Epoch 58] ogbg-moltoxcast: 0.674588 val loss: 1.988722
[Epoch 58] ogbg-moltoxcast: 0.631460 test loss: 5.683899
[Epoch 59; Iter    14/  172] train: loss: 0.1914195
[Epoch 59; Iter    44/  172] train: loss: 0.1031846
[Epoch 59; Iter    74/  172] train: loss: 0.1061334
[Epoch 59; Iter   104/  172] train: loss: 0.1766738
[Epoch 59; Iter   134/  172] train: loss: 0.1271328
[Epoch 59; Iter   164/  172] train: loss: 0.1193900
[Epoch 59] ogbg-moltoxcast: 0.658614 val loss: 0.325294
[Epoch 59] ogbg-moltoxcast: 0.621928 test loss: 0.740120
[Epoch 60; Iter    22/  172] train: loss: 0.1610008
[Epoch 60; Iter    52/  172] train: loss: 0.1073143
[Epoch 60; Iter    82/  172] train: loss: 0.1315902
[Epoch 60; Iter   112/  172] train: loss: 0.1773882
[Epoch 60; Iter   142/  172] train: loss: 0.1914559
[Epoch 60; Iter   172/  172] train: loss: 0.2070527
[Epoch 60] ogbg-moltoxcast: 0.664369 val loss: 2.028394
[Epoch 60] ogbg-moltoxcast: 0.618751 test loss: 3.833644
[Epoch 61; Iter    30/  172] train: loss: 0.1492668
[Epoch 61; Iter    60/  172] train: loss: 0.1275031
[Epoch 61; Iter    90/  172] train: loss: 0.1180455
[Epoch 61; Iter   120/  172] train: loss: 0.1420908
[Epoch 61; Iter   150/  172] train: loss: 0.1691939
[Epoch 61] ogbg-moltoxcast: 0.665350 val loss: 0.988101
[Epoch 61] ogbg-moltoxcast: 0.624124 test loss: 4.000537
[Epoch 62; Iter     8/  172] train: loss: 0.1031002
[Epoch 62; Iter    38/  172] train: loss: 0.1527889
[Epoch 62; Iter    68/  172] train: loss: 0.1377082
[Epoch 62; Iter    98/  172] train: loss: 0.1277384
[Epoch 62; Iter   128/  172] train: loss: 0.1139439
[Epoch 62; Iter   158/  172] train: loss: 0.1682544
[Epoch 62] ogbg-moltoxcast: 0.656717 val loss: 0.413300
[Epoch 62] ogbg-moltoxcast: 0.614715 test loss: 2.143941
[Epoch 63; Iter    16/  172] train: loss: 0.1421846
[Epoch 63; Iter    46/  172] train: loss: 0.1249178
[Epoch 63; Iter    76/  172] train: loss: 0.1250154
[Epoch 63; Iter   106/  172] train: loss: 0.1069038
[Epoch 63; Iter   136/  172] train: loss: 0.1352104
[Epoch 63; Iter   166/  172] train: loss: 0.1048496
[Epoch 63] ogbg-moltoxcast: 0.671334 val loss: 1.301482
[Epoch 63] ogbg-moltoxcast: 0.619640 test loss: 1.723256
[Epoch 64; Iter    24/  172] train: loss: 0.1487038
[Epoch 64; Iter    54/  172] train: loss: 0.1248168
[Epoch 64; Iter    84/  172] train: loss: 0.1267186
[Epoch 64; Iter   114/  172] train: loss: 0.0829019
[Epoch 64; Iter   144/  172] train: loss: 0.0916195
[Epoch 64] ogbg-moltoxcast: 0.662870 val loss: 1.113679
[Epoch 64] ogbg-moltoxcast: 0.619911 test loss: 3.495758
[Epoch 65; Iter     2/  172] train: loss: 0.1299239
[Epoch 65; Iter    32/  172] train: loss: 0.1446158
[Epoch 65; Iter    62/  172] train: loss: 0.1443470
[Epoch 65; Iter    92/  172] train: loss: 0.1182207
[Epoch 65; Iter   122/  172] train: loss: 0.1243758
[Epoch 65; Iter   152/  172] train: loss: 0.1449218
[Epoch 65] ogbg-moltoxcast: 0.656826 val loss: 0.541080
[Epoch 65] ogbg-moltoxcast: 0.617467 test loss: 0.555839
[Epoch 66; Iter    10/  172] train: loss: 0.1026830
[Epoch 66; Iter    40/  172] train: loss: 0.1728000
[Epoch 66; Iter    70/  172] train: loss: 0.1357065
[Epoch 66; Iter   100/  172] train: loss: 0.1166478
[Epoch 66; Iter   130/  172] train: loss: 0.1224411
[Epoch 66; Iter   160/  172] train: loss: 0.1133685
[Epoch 66] ogbg-moltoxcast: 0.669284 val loss: 0.361811
[Epoch 66] ogbg-moltoxcast: 0.625098 test loss: 0.909062
[Epoch 67; Iter    18/  172] train: loss: 0.1436567
[Epoch 67; Iter    48/  172] train: loss: 0.1323357
[Epoch 67; Iter    78/  172] train: loss: 0.0979246
[Epoch 67; Iter   108/  172] train: loss: 0.1080871
[Epoch 67; Iter   138/  172] train: loss: 0.1409461
[Epoch 67; Iter   168/  172] train: loss: 0.1658973
[Epoch 67] ogbg-moltoxcast: 0.658622 val loss: 0.314275
[Epoch 67] ogbg-moltoxcast: 0.621049 test loss: 1.227827
[Epoch 68; Iter    26/  172] train: loss: 0.1027939
[Epoch 68; Iter    56/  172] train: loss: 0.1003182
[Epoch 68; Iter    86/  172] train: loss: 0.1336064
[Epoch 68; Iter   116/  172] train: loss: 0.1638683
[Epoch 68; Iter   146/  172] train: loss: 0.1069461
[Epoch 68] ogbg-moltoxcast: 0.665239 val loss: 0.649484
[Epoch 68] ogbg-moltoxcast: 0.619032 test loss: 2.350966
[Epoch 69; Iter     4/  172] train: loss: 0.1033783
[Epoch 69; Iter    34/  172] train: loss: 0.1015247
[Epoch 69; Iter    64/  172] train: loss: 0.1007128
[Epoch 69; Iter    94/  172] train: loss: 0.1326839
[Epoch 69; Iter   124/  172] train: loss: 0.1337324
[Epoch 69; Iter   154/  172] train: loss: 0.1133136
[Epoch 69] ogbg-moltoxcast: 0.666996 val loss: 0.677161
[Epoch 69] ogbg-moltoxcast: 0.621335 test loss: 3.382524
[Epoch 70; Iter    12/  172] train: loss: 0.1318977
[Epoch 70; Iter    42/  172] train: loss: 0.1286440
[Epoch 70; Iter    72/  172] train: loss: 0.1604400
[Epoch 70; Iter   102/  172] train: loss: 0.1073827
[Epoch 70; Iter   132/  172] train: loss: 0.1004899
[Epoch 70; Iter   162/  172] train: loss: 0.2056465
[Epoch 70] ogbg-moltoxcast: 0.655931 val loss: 0.445865
[Epoch 70] ogbg-moltoxcast: 0.608363 test loss: 0.419534
[Epoch 71; Iter    20/  172] train: loss: 0.1553935
[Epoch 71; Iter    50/  172] train: loss: 0.1955840
[Epoch 71; Iter    80/  172] train: loss: 0.1426053
[Epoch 71; Iter   110/  172] train: loss: 0.1225582
[Epoch 71; Iter   140/  172] train: loss: 0.1019284
[Epoch 71; Iter   170/  172] train: loss: 0.1389799
[Epoch 71] ogbg-moltoxcast: 0.662307 val loss: 0.385696
[Epoch 71] ogbg-moltoxcast: 0.615528 test loss: 0.439911
[Epoch 72; Iter    28/  172] train: loss: 0.0891446
[Epoch 72; Iter    58/  172] train: loss: 0.1183377
[Epoch 72; Iter    88/  172] train: loss: 0.1000990
[Epoch 72; Iter   118/  172] train: loss: 0.1176007
[Epoch 72; Iter   148/  172] train: loss: 0.1030815
[Epoch 72] ogbg-moltoxcast: 0.663827 val loss: 0.299699
[Epoch 72] ogbg-moltoxcast: 0.615227 test loss: 0.395817
[Epoch 73; Iter     6/  172] train: loss: 0.1918544
[Epoch 73; Iter    36/  172] train: loss: 0.0978086
[Epoch 73; Iter    66/  172] train: loss: 0.1371037
[Epoch 73; Iter    96/  172] train: loss: 0.1703506
[Epoch 73; Iter   126/  172] train: loss: 0.0876428
[Epoch 73; Iter   156/  172] train: loss: 0.1116800
[Epoch 73] ogbg-moltoxcast: 0.659577 val loss: 0.360852
[Epoch 73] ogbg-moltoxcast: 0.618233 test loss: 0.434237
[Epoch 74; Iter    14/  172] train: loss: 0.1587562
[Epoch 74; Iter    44/  172] train: loss: 0.0850685
[Epoch 74; Iter    74/  172] train: loss: 0.1564508
[Epoch 74; Iter   104/  172] train: loss: 0.0931343
[Epoch 54; Iter   154/  172] train: loss: 0.0936448
[Epoch 54] ogbg-moltoxcast: 0.660808 val loss: 0.279324
[Epoch 54] ogbg-moltoxcast: 0.615907 test loss: 0.329303
[Epoch 55; Iter    12/  172] train: loss: 0.0980247
[Epoch 55; Iter    42/  172] train: loss: 0.1817989
[Epoch 55; Iter    72/  172] train: loss: 0.0930021
[Epoch 55; Iter   102/  172] train: loss: 0.1753325
[Epoch 55; Iter   132/  172] train: loss: 0.1164555
[Epoch 55; Iter   162/  172] train: loss: 0.1280006
[Epoch 55] ogbg-moltoxcast: 0.666024 val loss: 0.279954
[Epoch 55] ogbg-moltoxcast: 0.623045 test loss: 0.332372
[Epoch 56; Iter    20/  172] train: loss: 0.1508651
[Epoch 56; Iter    50/  172] train: loss: 0.1420545
[Epoch 56; Iter    80/  172] train: loss: 0.1811516
[Epoch 56; Iter   110/  172] train: loss: 0.0781246
[Epoch 56; Iter   140/  172] train: loss: 0.1219249
[Epoch 56; Iter   170/  172] train: loss: 0.0894719
[Epoch 56] ogbg-moltoxcast: 0.671086 val loss: 0.286395
[Epoch 56] ogbg-moltoxcast: 0.630851 test loss: 0.337702
[Epoch 57; Iter    28/  172] train: loss: 0.1166868
[Epoch 57; Iter    58/  172] train: loss: 0.1379323
[Epoch 57; Iter    88/  172] train: loss: 0.1440466
[Epoch 57; Iter   118/  172] train: loss: 0.1422572
[Epoch 57; Iter   148/  172] train: loss: 0.1313715
[Epoch 57] ogbg-moltoxcast: 0.662323 val loss: 0.289622
[Epoch 57] ogbg-moltoxcast: 0.625083 test loss: 0.343571
[Epoch 58; Iter     6/  172] train: loss: 0.1368330
[Epoch 58; Iter    36/  172] train: loss: 0.1107542
[Epoch 58; Iter    66/  172] train: loss: 0.1492167
[Epoch 58; Iter    96/  172] train: loss: 0.1254685
[Epoch 58; Iter   126/  172] train: loss: 0.1766462
[Epoch 58; Iter   156/  172] train: loss: 0.1352012
[Epoch 58] ogbg-moltoxcast: 0.659060 val loss: 0.282388
[Epoch 58] ogbg-moltoxcast: 0.619760 test loss: 0.328662
[Epoch 59; Iter    14/  172] train: loss: 0.1184072
[Epoch 59; Iter    44/  172] train: loss: 0.0939954
[Epoch 59; Iter    74/  172] train: loss: 0.1276427
[Epoch 59; Iter   104/  172] train: loss: 0.1678121
[Epoch 59; Iter   134/  172] train: loss: 0.1372202
[Epoch 59; Iter   164/  172] train: loss: 0.1206443
[Epoch 59] ogbg-moltoxcast: 0.657973 val loss: 0.286648
[Epoch 59] ogbg-moltoxcast: 0.615876 test loss: 0.334509
[Epoch 60; Iter    22/  172] train: loss: 0.0847521
[Epoch 60; Iter    52/  172] train: loss: 0.1239061
[Epoch 60; Iter    82/  172] train: loss: 0.1800721
[Epoch 60; Iter   112/  172] train: loss: 0.1372932
[Epoch 60; Iter   142/  172] train: loss: 0.1485903
[Epoch 60; Iter   172/  172] train: loss: 0.1445217
[Epoch 60] ogbg-moltoxcast: 0.667399 val loss: 0.287806
[Epoch 60] ogbg-moltoxcast: 0.628053 test loss: 0.337509
[Epoch 61; Iter    30/  172] train: loss: 0.1048542
[Epoch 61; Iter    60/  172] train: loss: 0.1332666
[Epoch 61; Iter    90/  172] train: loss: 0.1373896
[Epoch 61; Iter   120/  172] train: loss: 0.0971480
[Epoch 61; Iter   150/  172] train: loss: 0.1716755
[Epoch 61] ogbg-moltoxcast: 0.662035 val loss: 0.284050
[Epoch 61] ogbg-moltoxcast: 0.625210 test loss: 0.332963
[Epoch 62; Iter     8/  172] train: loss: 0.1457218
[Epoch 62; Iter    38/  172] train: loss: 0.1264209
[Epoch 62; Iter    68/  172] train: loss: 0.1106442
[Epoch 62; Iter    98/  172] train: loss: 0.1176713
[Epoch 62; Iter   128/  172] train: loss: 0.1131629
[Epoch 62; Iter   158/  172] train: loss: 0.1636581
[Epoch 62] ogbg-moltoxcast: 0.672710 val loss: 0.281916
[Epoch 62] ogbg-moltoxcast: 0.626319 test loss: 0.332925
[Epoch 63; Iter    16/  172] train: loss: 0.1104567
[Epoch 63; Iter    46/  172] train: loss: 0.1497258
[Epoch 63; Iter    76/  172] train: loss: 0.0743025
[Epoch 63; Iter   106/  172] train: loss: 0.1122163
[Epoch 63; Iter   136/  172] train: loss: 0.1361780
[Epoch 63; Iter   166/  172] train: loss: 0.1117873
[Epoch 63] ogbg-moltoxcast: 0.655060 val loss: 0.292620
[Epoch 63] ogbg-moltoxcast: 0.617263 test loss: 0.341489
[Epoch 64; Iter    24/  172] train: loss: 0.0701677
[Epoch 64; Iter    54/  172] train: loss: 0.1664427
[Epoch 64; Iter    84/  172] train: loss: 0.1457442
[Epoch 64; Iter   114/  172] train: loss: 0.1250918
[Epoch 64; Iter   144/  172] train: loss: 0.1651465
[Epoch 64] ogbg-moltoxcast: 0.644633 val loss: 0.297486
[Epoch 64] ogbg-moltoxcast: 0.611379 test loss: 0.341677
[Epoch 65; Iter     2/  172] train: loss: 0.1325769
[Epoch 65; Iter    32/  172] train: loss: 0.1624894
[Epoch 65; Iter    62/  172] train: loss: 0.1481784
[Epoch 65; Iter    92/  172] train: loss: 0.1462055
[Epoch 65; Iter   122/  172] train: loss: 0.0974287
[Epoch 65; Iter   152/  172] train: loss: 0.1522890
[Epoch 65] ogbg-moltoxcast: 0.656367 val loss: 0.286128
[Epoch 65] ogbg-moltoxcast: 0.623876 test loss: 0.333864
[Epoch 66; Iter    10/  172] train: loss: 0.1268867
[Epoch 66; Iter    40/  172] train: loss: 0.1277794
[Epoch 66; Iter    70/  172] train: loss: 0.1172214
[Epoch 66; Iter   100/  172] train: loss: 0.0962298
[Epoch 66; Iter   130/  172] train: loss: 0.0933940
[Epoch 66; Iter   160/  172] train: loss: 0.1175823
[Epoch 66] ogbg-moltoxcast: 0.659265 val loss: 0.290813
[Epoch 66] ogbg-moltoxcast: 0.618887 test loss: 0.338916
[Epoch 67; Iter    18/  172] train: loss: 0.1150907
[Epoch 67; Iter    48/  172] train: loss: 0.1510596
[Epoch 67; Iter    78/  172] train: loss: 0.0840414
[Epoch 67; Iter   108/  172] train: loss: 0.1392169
[Epoch 67; Iter   138/  172] train: loss: 0.1329599
[Epoch 67; Iter   168/  172] train: loss: 0.1189308
[Epoch 67] ogbg-moltoxcast: 0.662902 val loss: 0.287115
[Epoch 67] ogbg-moltoxcast: 0.621880 test loss: 0.336034
[Epoch 68; Iter    26/  172] train: loss: 0.1003395
[Epoch 68; Iter    56/  172] train: loss: 0.1227928
[Epoch 68; Iter    86/  172] train: loss: 0.0779679
[Epoch 68; Iter   116/  172] train: loss: 0.1345136
[Epoch 68; Iter   146/  172] train: loss: 0.1193816
[Epoch 68] ogbg-moltoxcast: 0.653943 val loss: 0.294366
[Epoch 68] ogbg-moltoxcast: 0.614617 test loss: 0.343675
[Epoch 69; Iter     4/  172] train: loss: 0.1004282
[Epoch 69; Iter    34/  172] train: loss: 0.1140164
[Epoch 69; Iter    64/  172] train: loss: 0.0955842
[Epoch 69; Iter    94/  172] train: loss: 0.1207702
[Epoch 69; Iter   124/  172] train: loss: 0.1136216
[Epoch 69; Iter   154/  172] train: loss: 0.1649599
[Epoch 69] ogbg-moltoxcast: 0.657412 val loss: 0.295780
[Epoch 69] ogbg-moltoxcast: 0.615099 test loss: 0.349206
[Epoch 70; Iter    12/  172] train: loss: 0.1100719
[Epoch 70; Iter    42/  172] train: loss: 0.0786335
[Epoch 70; Iter    72/  172] train: loss: 0.1155465
[Epoch 70; Iter   102/  172] train: loss: 0.0995017
[Epoch 70; Iter   132/  172] train: loss: 0.0987549
[Epoch 70; Iter   162/  172] train: loss: 0.0885424
[Epoch 70] ogbg-moltoxcast: 0.658098 val loss: 0.290786
[Epoch 70] ogbg-moltoxcast: 0.623494 test loss: 0.340251
[Epoch 71; Iter    20/  172] train: loss: 0.1478549
[Epoch 71; Iter    50/  172] train: loss: 0.1225316
[Epoch 71; Iter    80/  172] train: loss: 0.0936432
[Epoch 71; Iter   110/  172] train: loss: 0.0973051
[Epoch 71; Iter   140/  172] train: loss: 0.1078956
[Epoch 71; Iter   170/  172] train: loss: 0.1204224
[Epoch 71] ogbg-moltoxcast: 0.660037 val loss: 0.299396
[Epoch 71] ogbg-moltoxcast: 0.616592 test loss: 0.351072
[Epoch 72; Iter    28/  172] train: loss: 0.1097507
[Epoch 72; Iter    58/  172] train: loss: 0.1445977
[Epoch 72; Iter    88/  172] train: loss: 0.1159837
[Epoch 72; Iter   118/  172] train: loss: 0.1109428
[Epoch 72; Iter   148/  172] train: loss: 0.1325749
[Epoch 72] ogbg-moltoxcast: 0.653126 val loss: 0.299817
[Epoch 72] ogbg-moltoxcast: 0.619928 test loss: 0.346236
[Epoch 73; Iter     6/  172] train: loss: 0.1009745
[Epoch 73; Iter    36/  172] train: loss: 0.0906049
[Epoch 73; Iter    66/  172] train: loss: 0.1835024
[Epoch 73; Iter    96/  172] train: loss: 0.1278990
[Epoch 73; Iter   126/  172] train: loss: 0.1427368
[Epoch 73; Iter   156/  172] train: loss: 0.1147576
[Epoch 73] ogbg-moltoxcast: 0.656350 val loss: 0.289878
[Epoch 73] ogbg-moltoxcast: 0.618800 test loss: 0.343771
[Epoch 74; Iter    14/  172] train: loss: 0.0828187
[Epoch 74; Iter    44/  172] train: loss: 0.1168421
[Epoch 74; Iter    74/  172] train: loss: 0.0964151
[Epoch 74; Iter   104/  172] train: loss: 0.1171364
[Epoch 54; Iter   154/  172] train: loss: 0.0847770
[Epoch 54] ogbg-moltoxcast: 0.672223 val loss: 0.276386
[Epoch 54] ogbg-moltoxcast: 0.636562 test loss: 0.331602
[Epoch 55; Iter    12/  172] train: loss: 0.0689397
[Epoch 55; Iter    42/  172] train: loss: 0.0707126
[Epoch 55; Iter    72/  172] train: loss: 0.1134278
[Epoch 55; Iter   102/  172] train: loss: 0.1607978
[Epoch 55; Iter   132/  172] train: loss: 0.0908642
[Epoch 55; Iter   162/  172] train: loss: 0.1727071
[Epoch 55] ogbg-moltoxcast: 0.657716 val loss: 0.277107
[Epoch 55] ogbg-moltoxcast: 0.621734 test loss: 0.330641
[Epoch 56; Iter    20/  172] train: loss: 0.1137682
[Epoch 56; Iter    50/  172] train: loss: 0.1018507
[Epoch 56; Iter    80/  172] train: loss: 0.1648910
[Epoch 56; Iter   110/  172] train: loss: 0.1338209
[Epoch 56; Iter   140/  172] train: loss: 0.1108758
[Epoch 56; Iter   170/  172] train: loss: 0.1405074
[Epoch 56] ogbg-moltoxcast: 0.661887 val loss: 0.285615
[Epoch 56] ogbg-moltoxcast: 0.622613 test loss: 0.343164
[Epoch 57; Iter    28/  172] train: loss: 0.0923704
[Epoch 57; Iter    58/  172] train: loss: 0.1109902
[Epoch 57; Iter    88/  172] train: loss: 0.1164969
[Epoch 57; Iter   118/  172] train: loss: 0.1615330
[Epoch 57; Iter   148/  172] train: loss: 0.0965288
[Epoch 57] ogbg-moltoxcast: 0.670513 val loss: 0.275647
[Epoch 57] ogbg-moltoxcast: 0.629314 test loss: 0.329443
[Epoch 58; Iter     6/  172] train: loss: 0.1209643
[Epoch 58; Iter    36/  172] train: loss: 0.0840566
[Epoch 58; Iter    66/  172] train: loss: 0.1548054
[Epoch 58; Iter    96/  172] train: loss: 0.1316207
[Epoch 58; Iter   126/  172] train: loss: 0.1121006
[Epoch 58; Iter   156/  172] train: loss: 0.1331031
[Epoch 58] ogbg-moltoxcast: 0.670636 val loss: 0.279108
[Epoch 58] ogbg-moltoxcast: 0.632546 test loss: 0.334605
[Epoch 59; Iter    14/  172] train: loss: 0.0970242
[Epoch 59; Iter    44/  172] train: loss: 0.0829683
[Epoch 59; Iter    74/  172] train: loss: 0.0957430
[Epoch 59; Iter   104/  172] train: loss: 0.0811913
[Epoch 59; Iter   134/  172] train: loss: 0.1326110
[Epoch 59; Iter   164/  172] train: loss: 0.0874205
[Epoch 59] ogbg-moltoxcast: 0.675440 val loss: 0.276808
[Epoch 59] ogbg-moltoxcast: 0.637426 test loss: 0.334442
[Epoch 60; Iter    22/  172] train: loss: 0.1502835
[Epoch 60; Iter    52/  172] train: loss: 0.1201958
[Epoch 60; Iter    82/  172] train: loss: 0.0860793
[Epoch 60; Iter   112/  172] train: loss: 0.1066572
[Epoch 60; Iter   142/  172] train: loss: 0.0880269
[Epoch 60; Iter   172/  172] train: loss: 0.1173884
[Epoch 60] ogbg-moltoxcast: 0.666213 val loss: 0.281904
[Epoch 60] ogbg-moltoxcast: 0.635143 test loss: 0.333531
[Epoch 61; Iter    30/  172] train: loss: 0.0961842
[Epoch 61; Iter    60/  172] train: loss: 0.1633959
[Epoch 61; Iter    90/  172] train: loss: 0.1143361
[Epoch 61; Iter   120/  172] train: loss: 0.1443327
[Epoch 61; Iter   150/  172] train: loss: 0.1321785
[Epoch 61] ogbg-moltoxcast: 0.663271 val loss: 0.284279
[Epoch 61] ogbg-moltoxcast: 0.621720 test loss: 0.345356
[Epoch 62; Iter     8/  172] train: loss: 0.0912152
[Epoch 62; Iter    38/  172] train: loss: 0.0953045
[Epoch 62; Iter    68/  172] train: loss: 0.1360750
[Epoch 62; Iter    98/  172] train: loss: 0.1111733
[Epoch 62; Iter   128/  172] train: loss: 0.1389219
[Epoch 62; Iter   158/  172] train: loss: 0.1111156
[Epoch 62] ogbg-moltoxcast: 0.656561 val loss: 0.290947
[Epoch 62] ogbg-moltoxcast: 0.620965 test loss: 0.349894
[Epoch 63; Iter    16/  172] train: loss: 0.1113133
[Epoch 63; Iter    46/  172] train: loss: 0.1267412
[Epoch 63; Iter    76/  172] train: loss: 0.1667312
[Epoch 63; Iter   106/  172] train: loss: 0.1299209
[Epoch 63; Iter   136/  172] train: loss: 0.0971282
[Epoch 63; Iter   166/  172] train: loss: 0.1090782
[Epoch 63] ogbg-moltoxcast: 0.663826 val loss: 0.289540
[Epoch 63] ogbg-moltoxcast: 0.629373 test loss: 0.351695
[Epoch 64; Iter    24/  172] train: loss: 0.1285716
[Epoch 64; Iter    54/  172] train: loss: 0.1518148
[Epoch 64; Iter    84/  172] train: loss: 0.0966761
[Epoch 64; Iter   114/  172] train: loss: 0.1155736
[Epoch 64; Iter   144/  172] train: loss: 0.1444343
[Epoch 64] ogbg-moltoxcast: 0.659090 val loss: 0.288799
[Epoch 64] ogbg-moltoxcast: 0.627220 test loss: 0.339430
[Epoch 65; Iter     2/  172] train: loss: 0.1334084
[Epoch 65; Iter    32/  172] train: loss: 0.1230847
[Epoch 65; Iter    62/  172] train: loss: 0.1314033
[Epoch 65; Iter    92/  172] train: loss: 0.1184763
[Epoch 65; Iter   122/  172] train: loss: 0.1363823
[Epoch 65; Iter   152/  172] train: loss: 0.1179042
[Epoch 65] ogbg-moltoxcast: 0.670785 val loss: 0.294403
[Epoch 65] ogbg-moltoxcast: 0.631592 test loss: 0.352827
[Epoch 66; Iter    10/  172] train: loss: 0.1480877
[Epoch 66; Iter    40/  172] train: loss: 0.1009199
[Epoch 66; Iter    70/  172] train: loss: 0.1193391
[Epoch 66; Iter   100/  172] train: loss: 0.0789285
[Epoch 66; Iter   130/  172] train: loss: 0.1105243
[Epoch 66; Iter   160/  172] train: loss: 0.1208265
[Epoch 66] ogbg-moltoxcast: 0.663012 val loss: 0.295786
[Epoch 66] ogbg-moltoxcast: 0.630884 test loss: 0.352350
[Epoch 67; Iter    18/  172] train: loss: 0.1752192
[Epoch 67; Iter    48/  172] train: loss: 0.1313912
[Epoch 67; Iter    78/  172] train: loss: 0.1375727
[Epoch 67; Iter   108/  172] train: loss: 0.1558793
[Epoch 67; Iter   138/  172] train: loss: 0.1409940
[Epoch 67; Iter   168/  172] train: loss: 0.0828905
[Epoch 67] ogbg-moltoxcast: 0.654818 val loss: 0.296019
[Epoch 67] ogbg-moltoxcast: 0.621364 test loss: 0.347307
[Epoch 68; Iter    26/  172] train: loss: 0.0840466
[Epoch 68; Iter    56/  172] train: loss: 0.0887467
[Epoch 68; Iter    86/  172] train: loss: 0.0973759
[Epoch 68; Iter   116/  172] train: loss: 0.0999607
[Epoch 68; Iter   146/  172] train: loss: 0.1485344
[Epoch 68] ogbg-moltoxcast: 0.662475 val loss: 0.297633
[Epoch 68] ogbg-moltoxcast: 0.629574 test loss: 0.350868
[Epoch 69; Iter     4/  172] train: loss: 0.0709434
[Epoch 69; Iter    34/  172] train: loss: 0.1127472
[Epoch 69; Iter    64/  172] train: loss: 0.1079458
[Epoch 69; Iter    94/  172] train: loss: 0.0861526
[Epoch 69; Iter   124/  172] train: loss: 0.1316527
[Epoch 69; Iter   154/  172] train: loss: 0.1243001
[Epoch 69] ogbg-moltoxcast: 0.651669 val loss: 0.292768
[Epoch 69] ogbg-moltoxcast: 0.618483 test loss: 0.344242
[Epoch 70; Iter    12/  172] train: loss: 0.1699579
[Epoch 70; Iter    42/  172] train: loss: 0.1132718
[Epoch 70; Iter    72/  172] train: loss: 0.0927146
[Epoch 70; Iter   102/  172] train: loss: 0.1007554
[Epoch 70; Iter   132/  172] train: loss: 0.1449951
[Epoch 70; Iter   162/  172] train: loss: 0.0936363
[Epoch 70] ogbg-moltoxcast: 0.670652 val loss: 0.285721
[Epoch 70] ogbg-moltoxcast: 0.630590 test loss: 0.342393
[Epoch 71; Iter    20/  172] train: loss: 0.1262200
[Epoch 71; Iter    50/  172] train: loss: 0.1189774
[Epoch 71; Iter    80/  172] train: loss: 0.1370374
[Epoch 71; Iter   110/  172] train: loss: 0.1211480
[Epoch 71; Iter   140/  172] train: loss: 0.1138619
[Epoch 71; Iter   170/  172] train: loss: 0.1444067
[Epoch 71] ogbg-moltoxcast: 0.650184 val loss: 0.292776
[Epoch 71] ogbg-moltoxcast: 0.624232 test loss: 0.345227
[Epoch 72; Iter    28/  172] train: loss: 0.1121067
[Epoch 72; Iter    58/  172] train: loss: 0.1273561
[Epoch 72; Iter    88/  172] train: loss: 0.1492648
[Epoch 72; Iter   118/  172] train: loss: 0.0855310
[Epoch 72; Iter   148/  172] train: loss: 0.1173566
[Epoch 72] ogbg-moltoxcast: 0.655370 val loss: 0.293770
[Epoch 72] ogbg-moltoxcast: 0.624703 test loss: 0.346834
[Epoch 73; Iter     6/  172] train: loss: 0.0859654
[Epoch 73; Iter    36/  172] train: loss: 0.0972343
[Epoch 73; Iter    66/  172] train: loss: 0.1091527
[Epoch 73; Iter    96/  172] train: loss: 0.0971063
[Epoch 73; Iter   126/  172] train: loss: 0.1559534
[Epoch 73; Iter   156/  172] train: loss: 0.1322556
[Epoch 73] ogbg-moltoxcast: 0.650938 val loss: 0.299583
[Epoch 73] ogbg-moltoxcast: 0.623410 test loss: 0.360774
[Epoch 74; Iter    14/  172] train: loss: 0.1169858
[Epoch 74; Iter    44/  172] train: loss: 0.0963465
[Epoch 74; Iter    74/  172] train: loss: 0.1152572
[Epoch 74; Iter   104/  172] train: loss: 0.1130182
[Epoch 60; Iter    19/  229] train: loss: 0.1542323
[Epoch 60; Iter    49/  229] train: loss: 0.1310938
[Epoch 60; Iter    79/  229] train: loss: 0.1052022
[Epoch 60; Iter   109/  229] train: loss: 0.1306812
[Epoch 60; Iter   139/  229] train: loss: 0.1342141
[Epoch 60; Iter   169/  229] train: loss: 0.1718327
[Epoch 60; Iter   199/  229] train: loss: 0.0967549
[Epoch 60; Iter   229/  229] train: loss: 0.1215161
[Epoch 60] ogbg-moltoxcast: 0.702493 val loss: 0.251080
[Epoch 60] ogbg-moltoxcast: 0.663453 test loss: 0.592989
[Epoch 61; Iter    30/  229] train: loss: 0.1313337
[Epoch 61; Iter    60/  229] train: loss: 0.1544064
[Epoch 61; Iter    90/  229] train: loss: 0.0978587
[Epoch 61; Iter   120/  229] train: loss: 0.1493787
[Epoch 61; Iter   150/  229] train: loss: 0.1015933
[Epoch 61; Iter   180/  229] train: loss: 0.1874299
[Epoch 61; Iter   210/  229] train: loss: 0.1207081
[Epoch 61] ogbg-moltoxcast: 0.696590 val loss: 0.260080
[Epoch 61] ogbg-moltoxcast: 0.658762 test loss: 0.513248
[Epoch 62; Iter    11/  229] train: loss: 0.1223164
[Epoch 62; Iter    41/  229] train: loss: 0.1745731
[Epoch 62; Iter    71/  229] train: loss: 0.1662116
[Epoch 62; Iter   101/  229] train: loss: 0.1889188
[Epoch 62; Iter   131/  229] train: loss: 0.1084678
[Epoch 62; Iter   161/  229] train: loss: 0.1255533
[Epoch 62; Iter   191/  229] train: loss: 0.0920681
[Epoch 62; Iter   221/  229] train: loss: 0.1883475
[Epoch 62] ogbg-moltoxcast: 0.700005 val loss: 0.258774
[Epoch 62] ogbg-moltoxcast: 0.669255 test loss: 0.457700
[Epoch 63; Iter    22/  229] train: loss: 0.1085509
[Epoch 63; Iter    52/  229] train: loss: 0.1234603
[Epoch 63; Iter    82/  229] train: loss: 0.0822503
[Epoch 63; Iter   112/  229] train: loss: 0.1302315
[Epoch 63; Iter   142/  229] train: loss: 0.1487306
[Epoch 63; Iter   172/  229] train: loss: 0.1741722
[Epoch 63; Iter   202/  229] train: loss: 0.1137511
[Epoch 63] ogbg-moltoxcast: 0.700823 val loss: 0.257929
[Epoch 63] ogbg-moltoxcast: 0.664582 test loss: 0.499298
[Epoch 64; Iter     3/  229] train: loss: 0.1464462
[Epoch 64; Iter    33/  229] train: loss: 0.1430602
[Epoch 64; Iter    63/  229] train: loss: 0.1171487
[Epoch 64; Iter    93/  229] train: loss: 0.1063663
[Epoch 64; Iter   123/  229] train: loss: 0.1470912
[Epoch 64; Iter   153/  229] train: loss: 0.1350906
[Epoch 64; Iter   183/  229] train: loss: 0.1782551
[Epoch 64; Iter   213/  229] train: loss: 0.1144996
[Epoch 64] ogbg-moltoxcast: 0.698057 val loss: 0.264981
[Epoch 64] ogbg-moltoxcast: 0.665097 test loss: 0.456242
[Epoch 65; Iter    14/  229] train: loss: 0.0941224
[Epoch 65; Iter    44/  229] train: loss: 0.1020027
[Epoch 65; Iter    74/  229] train: loss: 0.0989852
[Epoch 65; Iter   104/  229] train: loss: 0.1192819
[Epoch 65; Iter   134/  229] train: loss: 0.1812298
[Epoch 65; Iter   164/  229] train: loss: 0.1567906
[Epoch 65; Iter   194/  229] train: loss: 0.1266956
[Epoch 65; Iter   224/  229] train: loss: 0.2059927
[Epoch 65] ogbg-moltoxcast: 0.702921 val loss: 0.260532
[Epoch 65] ogbg-moltoxcast: 0.664260 test loss: 0.494835
[Epoch 66; Iter    25/  229] train: loss: 0.0978939
[Epoch 66; Iter    55/  229] train: loss: 0.0997615
[Epoch 66; Iter    85/  229] train: loss: 0.1425445
[Epoch 66; Iter   115/  229] train: loss: 0.1822572
[Epoch 66; Iter   145/  229] train: loss: 0.1209060
[Epoch 66; Iter   175/  229] train: loss: 0.1590258
[Epoch 66; Iter   205/  229] train: loss: 0.1624294
[Epoch 66] ogbg-moltoxcast: 0.696950 val loss: 0.261285
[Epoch 66] ogbg-moltoxcast: 0.660058 test loss: 0.496431
[Epoch 67; Iter     6/  229] train: loss: 0.1397914
[Epoch 67; Iter    36/  229] train: loss: 0.1514843
[Epoch 67; Iter    66/  229] train: loss: 0.1155730
[Epoch 67; Iter    96/  229] train: loss: 0.1225555
[Epoch 67; Iter   126/  229] train: loss: 0.1539034
[Epoch 67; Iter   156/  229] train: loss: 0.1554629
[Epoch 67; Iter   186/  229] train: loss: 0.1617815
[Epoch 67; Iter   216/  229] train: loss: 0.1342166
[Epoch 67] ogbg-moltoxcast: 0.703228 val loss: 0.261660
[Epoch 67] ogbg-moltoxcast: 0.667365 test loss: 0.564302
[Epoch 68; Iter    17/  229] train: loss: 0.1851913
[Epoch 68; Iter    47/  229] train: loss: 0.1187372
[Epoch 68; Iter    77/  229] train: loss: 0.1141812
[Epoch 68; Iter   107/  229] train: loss: 0.1223177
[Epoch 68; Iter   137/  229] train: loss: 0.1069556
[Epoch 68; Iter   167/  229] train: loss: 0.1135312
[Epoch 68; Iter   197/  229] train: loss: 0.1390160
[Epoch 68; Iter   227/  229] train: loss: 0.1260734
[Epoch 68] ogbg-moltoxcast: 0.699555 val loss: 0.260820
[Epoch 68] ogbg-moltoxcast: 0.663202 test loss: 0.624026
[Epoch 69; Iter    28/  229] train: loss: 0.1359747
[Epoch 69; Iter    58/  229] train: loss: 0.1765109
[Epoch 69; Iter    88/  229] train: loss: 0.0981701
[Epoch 69; Iter   118/  229] train: loss: 0.0892449
[Epoch 69; Iter   148/  229] train: loss: 0.1428292
[Epoch 69; Iter   178/  229] train: loss: 0.1619066
[Epoch 69; Iter   208/  229] train: loss: 0.0946649
[Epoch 69] ogbg-moltoxcast: 0.706159 val loss: 0.270451
[Epoch 69] ogbg-moltoxcast: 0.663240 test loss: 0.623713
[Epoch 70; Iter     9/  229] train: loss: 0.0997897
[Epoch 70; Iter    39/  229] train: loss: 0.1089624
[Epoch 70; Iter    69/  229] train: loss: 0.1261842
[Epoch 70; Iter    99/  229] train: loss: 0.1472033
[Epoch 70; Iter   129/  229] train: loss: 0.1302933
[Epoch 70; Iter   159/  229] train: loss: 0.1345295
[Epoch 70; Iter   189/  229] train: loss: 0.1394396
[Epoch 70; Iter   219/  229] train: loss: 0.1263137
[Epoch 70] ogbg-moltoxcast: 0.700080 val loss: 0.261709
[Epoch 70] ogbg-moltoxcast: 0.659237 test loss: 0.559763
[Epoch 71; Iter    20/  229] train: loss: 0.1439854
[Epoch 71; Iter    50/  229] train: loss: 0.1470306
[Epoch 71; Iter    80/  229] train: loss: 0.1012756
[Epoch 71; Iter   110/  229] train: loss: 0.1525462
[Epoch 71; Iter   140/  229] train: loss: 0.1213999
[Epoch 71; Iter   170/  229] train: loss: 0.0856995
[Epoch 71; Iter   200/  229] train: loss: 0.1232339
[Epoch 71] ogbg-moltoxcast: 0.703166 val loss: 0.262566
[Epoch 71] ogbg-moltoxcast: 0.668313 test loss: 0.597810
[Epoch 72; Iter     1/  229] train: loss: 0.1134679
[Epoch 72; Iter    31/  229] train: loss: 0.1749926
[Epoch 72; Iter    61/  229] train: loss: 0.1409515
[Epoch 72; Iter    91/  229] train: loss: 0.1402976
[Epoch 72; Iter   121/  229] train: loss: 0.1569306
[Epoch 72; Iter   151/  229] train: loss: 0.1709525
[Epoch 72; Iter   181/  229] train: loss: 0.1167839
[Epoch 72; Iter   211/  229] train: loss: 0.1286988
[Epoch 72] ogbg-moltoxcast: 0.701791 val loss: 0.265463
[Epoch 72] ogbg-moltoxcast: 0.664390 test loss: 0.613910
[Epoch 73; Iter    12/  229] train: loss: 0.1196199
[Epoch 73; Iter    42/  229] train: loss: 0.1601529
[Epoch 73; Iter    72/  229] train: loss: 0.1750733
[Epoch 73; Iter   102/  229] train: loss: 0.1130952
[Epoch 73; Iter   132/  229] train: loss: 0.1392693
[Epoch 73; Iter   162/  229] train: loss: 0.1342060
[Epoch 73; Iter   192/  229] train: loss: 0.1188826
[Epoch 73; Iter   222/  229] train: loss: 0.1261041
[Epoch 73] ogbg-moltoxcast: 0.702295 val loss: 0.266473
[Epoch 73] ogbg-moltoxcast: 0.664319 test loss: 0.398636
[Epoch 74; Iter    23/  229] train: loss: 0.1271460
[Epoch 74; Iter    53/  229] train: loss: 0.1141898
[Epoch 74; Iter    83/  229] train: loss: 0.0923075
[Epoch 74; Iter   113/  229] train: loss: 0.1136875
[Epoch 74; Iter   143/  229] train: loss: 0.1525585
[Epoch 74; Iter   173/  229] train: loss: 0.1055699
[Epoch 74; Iter   203/  229] train: loss: 0.0934357
[Epoch 74] ogbg-moltoxcast: 0.701270 val loss: 0.264389
[Epoch 74] ogbg-moltoxcast: 0.657050 test loss: 0.421286
[Epoch 75; Iter     4/  229] train: loss: 0.0937124
[Epoch 75; Iter    34/  229] train: loss: 0.1622307
[Epoch 75; Iter    64/  229] train: loss: 0.1347511
[Epoch 75; Iter    94/  229] train: loss: 0.1170115
[Epoch 75; Iter   124/  229] train: loss: 0.1226886
[Epoch 75; Iter   154/  229] train: loss: 0.1423039
[Epoch 75; Iter   184/  229] train: loss: 0.1236264
[Epoch 75; Iter   214/  229] train: loss: 0.1324188
[Epoch 75] ogbg-moltoxcast: 0.694260 val loss: 0.267605
[Epoch 75] ogbg-moltoxcast: 0.658653 test loss: 0.740202
[Epoch 60; Iter    19/  229] train: loss: 0.1119747
[Epoch 60; Iter    49/  229] train: loss: 0.1225258
[Epoch 60; Iter    79/  229] train: loss: 0.2034575
[Epoch 60; Iter   109/  229] train: loss: 0.2294214
[Epoch 60; Iter   139/  229] train: loss: 0.1596386
[Epoch 60; Iter   169/  229] train: loss: 0.1399772
[Epoch 60; Iter   199/  229] train: loss: 0.1800115
[Epoch 60; Iter   229/  229] train: loss: 0.1414906
[Epoch 60] ogbg-moltoxcast: 0.685178 val loss: 0.264054
[Epoch 60] ogbg-moltoxcast: 0.662314 test loss: 0.329977
[Epoch 61; Iter    30/  229] train: loss: 0.1441782
[Epoch 61; Iter    60/  229] train: loss: 0.1583206
[Epoch 61; Iter    90/  229] train: loss: 0.0874108
[Epoch 61; Iter   120/  229] train: loss: 0.0834687
[Epoch 61; Iter   150/  229] train: loss: 0.1608816
[Epoch 61; Iter   180/  229] train: loss: 0.1082566
[Epoch 61; Iter   210/  229] train: loss: 0.1117896
[Epoch 61] ogbg-moltoxcast: 0.696518 val loss: 0.263056
[Epoch 61] ogbg-moltoxcast: 0.666315 test loss: 0.328520
[Epoch 62; Iter    11/  229] train: loss: 0.1154613
[Epoch 62; Iter    41/  229] train: loss: 0.1439602
[Epoch 62; Iter    71/  229] train: loss: 0.0978562
[Epoch 62; Iter   101/  229] train: loss: 0.1142733
[Epoch 62; Iter   131/  229] train: loss: 0.1014301
[Epoch 62; Iter   161/  229] train: loss: 0.1231209
[Epoch 62; Iter   191/  229] train: loss: 0.1184041
[Epoch 62; Iter   221/  229] train: loss: 0.1262497
[Epoch 62] ogbg-moltoxcast: 0.696142 val loss: 0.288363
[Epoch 62] ogbg-moltoxcast: 0.664221 test loss: 0.381693
[Epoch 63; Iter    22/  229] train: loss: 0.1598996
[Epoch 63; Iter    52/  229] train: loss: 0.1533343
[Epoch 63; Iter    82/  229] train: loss: 0.1080234
[Epoch 63; Iter   112/  229] train: loss: 0.1348258
[Epoch 63; Iter   142/  229] train: loss: 0.1170248
[Epoch 63; Iter   172/  229] train: loss: 0.1697757
[Epoch 63; Iter   202/  229] train: loss: 0.0878157
[Epoch 63] ogbg-moltoxcast: 0.686500 val loss: 0.264511
[Epoch 63] ogbg-moltoxcast: 0.659501 test loss: 0.336547
[Epoch 64; Iter     3/  229] train: loss: 0.2037446
[Epoch 64; Iter    33/  229] train: loss: 0.1413174
[Epoch 64; Iter    63/  229] train: loss: 0.1765458
[Epoch 64; Iter    93/  229] train: loss: 0.1877593
[Epoch 64; Iter   123/  229] train: loss: 0.1544060
[Epoch 64; Iter   153/  229] train: loss: 0.1595870
[Epoch 64; Iter   183/  229] train: loss: 0.1708489
[Epoch 64; Iter   213/  229] train: loss: 0.1004611
[Epoch 64] ogbg-moltoxcast: 0.691753 val loss: 0.268756
[Epoch 64] ogbg-moltoxcast: 0.664136 test loss: 0.329959
[Epoch 65; Iter    14/  229] train: loss: 0.1058129
[Epoch 65; Iter    44/  229] train: loss: 0.1272512
[Epoch 65; Iter    74/  229] train: loss: 0.1286574
[Epoch 65; Iter   104/  229] train: loss: 0.1450304
[Epoch 65; Iter   134/  229] train: loss: 0.0971327
[Epoch 65; Iter   164/  229] train: loss: 0.1426886
[Epoch 65; Iter   194/  229] train: loss: 0.1037972
[Epoch 65; Iter   224/  229] train: loss: 0.1375312
[Epoch 65] ogbg-moltoxcast: 0.696254 val loss: 0.271869
[Epoch 65] ogbg-moltoxcast: 0.663077 test loss: 0.336812
[Epoch 66; Iter    25/  229] train: loss: 0.1250610
[Epoch 66; Iter    55/  229] train: loss: 0.1613565
[Epoch 66; Iter    85/  229] train: loss: 0.1000092
[Epoch 66; Iter   115/  229] train: loss: 0.1583545
[Epoch 66; Iter   145/  229] train: loss: 0.1126953
[Epoch 66; Iter   175/  229] train: loss: 0.1090591
[Epoch 66; Iter   205/  229] train: loss: 0.1584821
[Epoch 66] ogbg-moltoxcast: 0.693867 val loss: 0.271435
[Epoch 66] ogbg-moltoxcast: 0.664696 test loss: 0.338654
[Epoch 67; Iter     6/  229] train: loss: 0.0779336
[Epoch 67; Iter    36/  229] train: loss: 0.1168511
[Epoch 67; Iter    66/  229] train: loss: 0.1527141
[Epoch 67; Iter    96/  229] train: loss: 0.1153477
[Epoch 67; Iter   126/  229] train: loss: 0.1604919
[Epoch 67; Iter   156/  229] train: loss: 0.1128507
[Epoch 67; Iter   186/  229] train: loss: 0.1233111
[Epoch 67; Iter   216/  229] train: loss: 0.1076603
[Epoch 67] ogbg-moltoxcast: 0.693012 val loss: 0.271554
[Epoch 67] ogbg-moltoxcast: 0.662110 test loss: 0.373814
[Epoch 68; Iter    17/  229] train: loss: 0.1358141
[Epoch 68; Iter    47/  229] train: loss: 0.1352849
[Epoch 68; Iter    77/  229] train: loss: 0.1968662
[Epoch 68; Iter   107/  229] train: loss: 0.1243029
[Epoch 68; Iter   137/  229] train: loss: 0.1205506
[Epoch 68; Iter   167/  229] train: loss: 0.1485035
[Epoch 68; Iter   197/  229] train: loss: 0.1462125
[Epoch 68; Iter   227/  229] train: loss: 0.1407450
[Epoch 68] ogbg-moltoxcast: 0.690895 val loss: 0.275461
[Epoch 68] ogbg-moltoxcast: 0.661346 test loss: 0.354126
[Epoch 69; Iter    28/  229] train: loss: 0.1650994
[Epoch 69; Iter    58/  229] train: loss: 0.1499086
[Epoch 69; Iter    88/  229] train: loss: 0.1498950
[Epoch 69; Iter   118/  229] train: loss: 0.1944469
[Epoch 69; Iter   148/  229] train: loss: 0.1670500
[Epoch 69; Iter   178/  229] train: loss: 0.0964927
[Epoch 69; Iter   208/  229] train: loss: 0.1005937
[Epoch 69] ogbg-moltoxcast: 0.692831 val loss: 0.407599
[Epoch 69] ogbg-moltoxcast: 0.661262 test loss: 0.390721
[Epoch 70; Iter     9/  229] train: loss: 0.1582737
[Epoch 70; Iter    39/  229] train: loss: 0.1394164
[Epoch 70; Iter    69/  229] train: loss: 0.1326834
[Epoch 70; Iter    99/  229] train: loss: 0.1810748
[Epoch 70; Iter   129/  229] train: loss: 0.1401256
[Epoch 70; Iter   159/  229] train: loss: 0.1227886
[Epoch 70; Iter   189/  229] train: loss: 0.1222322
[Epoch 70; Iter   219/  229] train: loss: 0.1811301
[Epoch 70] ogbg-moltoxcast: 0.681762 val loss: 0.381222
[Epoch 70] ogbg-moltoxcast: 0.660367 test loss: 0.438437
[Epoch 71; Iter    20/  229] train: loss: 0.1322941
[Epoch 71; Iter    50/  229] train: loss: 0.1007069
[Epoch 71; Iter    80/  229] train: loss: 0.1531507
[Epoch 71; Iter   110/  229] train: loss: 0.1423987
[Epoch 71; Iter   140/  229] train: loss: 0.1340823
[Epoch 71; Iter   170/  229] train: loss: 0.1768515
[Epoch 71; Iter   200/  229] train: loss: 0.1458552
[Epoch 71] ogbg-moltoxcast: 0.692151 val loss: 0.294878
[Epoch 71] ogbg-moltoxcast: 0.659746 test loss: 0.377617
[Epoch 72; Iter     1/  229] train: loss: 0.1448610
[Epoch 72; Iter    31/  229] train: loss: 0.1341274
[Epoch 72; Iter    61/  229] train: loss: 0.1765406
[Epoch 72; Iter    91/  229] train: loss: 0.1046973
[Epoch 72; Iter   121/  229] train: loss: 0.0944695
[Epoch 72; Iter   151/  229] train: loss: 0.1551936
[Epoch 72; Iter   181/  229] train: loss: 0.1917780
[Epoch 72; Iter   211/  229] train: loss: 0.0990384
[Epoch 72] ogbg-moltoxcast: 0.687880 val loss: 0.448647
[Epoch 72] ogbg-moltoxcast: 0.661642 test loss: 0.390283
[Epoch 73; Iter    12/  229] train: loss: 0.1025853
[Epoch 73; Iter    42/  229] train: loss: 0.1433413
[Epoch 73; Iter    72/  229] train: loss: 0.1466885
[Epoch 73; Iter   102/  229] train: loss: 0.1387951
[Epoch 73; Iter   132/  229] train: loss: 0.1199259
[Epoch 73; Iter   162/  229] train: loss: 0.1365975
[Epoch 73; Iter   192/  229] train: loss: 0.1053217
[Epoch 73; Iter   222/  229] train: loss: 0.1235794
[Epoch 73] ogbg-moltoxcast: 0.682419 val loss: 0.270392
[Epoch 73] ogbg-moltoxcast: 0.657305 test loss: 0.342271
[Epoch 74; Iter    23/  229] train: loss: 0.0967902
[Epoch 74; Iter    53/  229] train: loss: 0.1506002
[Epoch 74; Iter    83/  229] train: loss: 0.1262255
[Epoch 74; Iter   113/  229] train: loss: 0.0982656
[Epoch 74; Iter   143/  229] train: loss: 0.1342710
[Epoch 74; Iter   173/  229] train: loss: 0.1406512
[Epoch 74; Iter   203/  229] train: loss: 0.1412755
[Epoch 74] ogbg-moltoxcast: 0.690690 val loss: 0.267792
[Epoch 74] ogbg-moltoxcast: 0.658682 test loss: 0.341558
[Epoch 75; Iter     4/  229] train: loss: 0.0902480
[Epoch 75; Iter    34/  229] train: loss: 0.1523512
[Epoch 75; Iter    64/  229] train: loss: 0.1878658
[Epoch 75; Iter    94/  229] train: loss: 0.1313857
[Epoch 75; Iter   124/  229] train: loss: 0.1317156
[Epoch 75; Iter   154/  229] train: loss: 0.1189958
[Epoch 75; Iter   184/  229] train: loss: 0.1780942
[Epoch 75; Iter   214/  229] train: loss: 0.1344871
[Epoch 75] ogbg-moltoxcast: 0.681633 val loss: 0.274282
[Epoch 75] ogbg-moltoxcast: 0.657068 test loss: 0.344265
[Epoch 60; Iter    19/  229] train: loss: 0.1052893
[Epoch 60; Iter    49/  229] train: loss: 0.1382830
[Epoch 60; Iter    79/  229] train: loss: 0.1715361
[Epoch 60; Iter   109/  229] train: loss: 0.1243260
[Epoch 60; Iter   139/  229] train: loss: 0.1453148
[Epoch 60; Iter   169/  229] train: loss: 0.1066597
[Epoch 60; Iter   199/  229] train: loss: 0.1706438
[Epoch 60; Iter   229/  229] train: loss: 0.1440695
[Epoch 60] ogbg-moltoxcast: 0.680676 val loss: 0.263891
[Epoch 60] ogbg-moltoxcast: 0.663686 test loss: 0.312992
[Epoch 61; Iter    30/  229] train: loss: 0.1546526
[Epoch 61; Iter    60/  229] train: loss: 0.1699293
[Epoch 61; Iter    90/  229] train: loss: 0.1679543
[Epoch 61; Iter   120/  229] train: loss: 0.1431461
[Epoch 61; Iter   150/  229] train: loss: 0.1540174
[Epoch 61; Iter   180/  229] train: loss: 0.1548989
[Epoch 61; Iter   210/  229] train: loss: 0.0964673
[Epoch 61] ogbg-moltoxcast: 0.690735 val loss: 0.258672
[Epoch 61] ogbg-moltoxcast: 0.653785 test loss: 0.317651
[Epoch 62; Iter    11/  229] train: loss: 0.0871723
[Epoch 62; Iter    41/  229] train: loss: 0.1904455
[Epoch 62; Iter    71/  229] train: loss: 0.1390020
[Epoch 62; Iter   101/  229] train: loss: 0.1347384
[Epoch 62; Iter   131/  229] train: loss: 0.1700384
[Epoch 62; Iter   161/  229] train: loss: 0.1265365
[Epoch 62; Iter   191/  229] train: loss: 0.1345536
[Epoch 62; Iter   221/  229] train: loss: 0.1538222
[Epoch 62] ogbg-moltoxcast: 0.687369 val loss: 0.262966
[Epoch 62] ogbg-moltoxcast: 0.659979 test loss: 0.317122
[Epoch 63; Iter    22/  229] train: loss: 0.1446202
[Epoch 63; Iter    52/  229] train: loss: 0.0920061
[Epoch 63; Iter    82/  229] train: loss: 0.0963764
[Epoch 63; Iter   112/  229] train: loss: 0.1042341
[Epoch 63; Iter   142/  229] train: loss: 0.1877607
[Epoch 63; Iter   172/  229] train: loss: 0.1734943
[Epoch 63; Iter   202/  229] train: loss: 0.1199587
[Epoch 63] ogbg-moltoxcast: 0.684739 val loss: 0.266703
[Epoch 63] ogbg-moltoxcast: 0.661704 test loss: 0.316623
[Epoch 64; Iter     3/  229] train: loss: 0.0878137
[Epoch 64; Iter    33/  229] train: loss: 0.1345836
[Epoch 64; Iter    63/  229] train: loss: 0.1493922
[Epoch 64; Iter    93/  229] train: loss: 0.1197392
[Epoch 64; Iter   123/  229] train: loss: 0.1215433
[Epoch 64; Iter   153/  229] train: loss: 0.1065945
[Epoch 64; Iter   183/  229] train: loss: 0.1069023
[Epoch 64; Iter   213/  229] train: loss: 0.1475694
[Epoch 64] ogbg-moltoxcast: 0.684447 val loss: 0.261863
[Epoch 64] ogbg-moltoxcast: 0.652373 test loss: 0.320612
[Epoch 65; Iter    14/  229] train: loss: 0.1518037
[Epoch 65; Iter    44/  229] train: loss: 0.1479393
[Epoch 65; Iter    74/  229] train: loss: 0.1273460
[Epoch 65; Iter   104/  229] train: loss: 0.1512254
[Epoch 65; Iter   134/  229] train: loss: 0.1198662
[Epoch 65; Iter   164/  229] train: loss: 0.1499154
[Epoch 65; Iter   194/  229] train: loss: 0.1108398
[Epoch 65; Iter   224/  229] train: loss: 0.1419921
[Epoch 65] ogbg-moltoxcast: 0.677513 val loss: 0.264688
[Epoch 65] ogbg-moltoxcast: 0.651260 test loss: 0.312984
[Epoch 66; Iter    25/  229] train: loss: 0.1232823
[Epoch 66; Iter    55/  229] train: loss: 0.1650721
[Epoch 66; Iter    85/  229] train: loss: 0.1481225
[Epoch 66; Iter   115/  229] train: loss: 0.1080192
[Epoch 66; Iter   145/  229] train: loss: 0.1146108
[Epoch 66; Iter   175/  229] train: loss: 0.1483571
[Epoch 66; Iter   205/  229] train: loss: 0.1124983
[Epoch 66] ogbg-moltoxcast: 0.677657 val loss: 0.267604
[Epoch 66] ogbg-moltoxcast: 0.654900 test loss: 0.322123
[Epoch 67; Iter     6/  229] train: loss: 0.1360413
[Epoch 67; Iter    36/  229] train: loss: 0.1603491
[Epoch 67; Iter    66/  229] train: loss: 0.1036206
[Epoch 67; Iter    96/  229] train: loss: 0.1741377
[Epoch 67; Iter   126/  229] train: loss: 0.1032191
[Epoch 67; Iter   156/  229] train: loss: 0.1129147
[Epoch 67; Iter   186/  229] train: loss: 0.1165991
[Epoch 67; Iter   216/  229] train: loss: 0.1048849
[Epoch 67] ogbg-moltoxcast: 0.680913 val loss: 0.265692
[Epoch 67] ogbg-moltoxcast: 0.657364 test loss: 0.317749
[Epoch 68; Iter    17/  229] train: loss: 0.1726883
[Epoch 68; Iter    47/  229] train: loss: 0.1119024
[Epoch 68; Iter    77/  229] train: loss: 0.1238806
[Epoch 68; Iter   107/  229] train: loss: 0.1617974
[Epoch 68; Iter   137/  229] train: loss: 0.1230146
[Epoch 68; Iter   167/  229] train: loss: 0.1153042
[Epoch 68; Iter   197/  229] train: loss: 0.1590849
[Epoch 68; Iter   227/  229] train: loss: 0.1473707
[Epoch 68] ogbg-moltoxcast: 0.676686 val loss: 0.265314
[Epoch 68] ogbg-moltoxcast: 0.650139 test loss: 0.322172
[Epoch 69; Iter    28/  229] train: loss: 0.1378272
[Epoch 69; Iter    58/  229] train: loss: 0.0974192
[Epoch 69; Iter    88/  229] train: loss: 0.1158581
[Epoch 69; Iter   118/  229] train: loss: 0.1109054
[Epoch 69; Iter   148/  229] train: loss: 0.0973588
[Epoch 69; Iter   178/  229] train: loss: 0.1876103
[Epoch 69; Iter   208/  229] train: loss: 0.1233593
[Epoch 69] ogbg-moltoxcast: 0.683183 val loss: 0.264373
[Epoch 69] ogbg-moltoxcast: 0.653301 test loss: 0.319730
[Epoch 70; Iter     9/  229] train: loss: 0.1180462
[Epoch 70; Iter    39/  229] train: loss: 0.1396370
[Epoch 70; Iter    69/  229] train: loss: 0.1292971
[Epoch 70; Iter    99/  229] train: loss: 0.1639905
[Epoch 70; Iter   129/  229] train: loss: 0.1205600
[Epoch 70; Iter   159/  229] train: loss: 0.1466064
[Epoch 70; Iter   189/  229] train: loss: 0.1774166
[Epoch 70; Iter   219/  229] train: loss: 0.1436445
[Epoch 70] ogbg-moltoxcast: 0.684787 val loss: 0.262492
[Epoch 70] ogbg-moltoxcast: 0.659257 test loss: 0.313200
[Epoch 71; Iter    20/  229] train: loss: 0.1090135
[Epoch 71; Iter    50/  229] train: loss: 0.1027311
[Epoch 71; Iter    80/  229] train: loss: 0.1332763
[Epoch 71; Iter   110/  229] train: loss: 0.1157025
[Epoch 71; Iter   140/  229] train: loss: 0.1001629
[Epoch 71; Iter   170/  229] train: loss: 0.1342543
[Epoch 71; Iter   200/  229] train: loss: 0.1211980
[Epoch 71] ogbg-moltoxcast: 0.680942 val loss: 0.265803
[Epoch 71] ogbg-moltoxcast: 0.655805 test loss: 0.319834
[Epoch 72; Iter     1/  229] train: loss: 0.0917563
[Epoch 72; Iter    31/  229] train: loss: 0.1001609
[Epoch 72; Iter    61/  229] train: loss: 0.1176942
[Epoch 72; Iter    91/  229] train: loss: 0.1304271
[Epoch 72; Iter   121/  229] train: loss: 0.1210254
[Epoch 72; Iter   151/  229] train: loss: 0.1403514
[Epoch 72; Iter   181/  229] train: loss: 0.1079917
[Epoch 72; Iter   211/  229] train: loss: 0.1340210
[Epoch 72] ogbg-moltoxcast: 0.687377 val loss: 0.268768
[Epoch 72] ogbg-moltoxcast: 0.655611 test loss: 0.324287
[Epoch 73; Iter    12/  229] train: loss: 0.1612344
[Epoch 73; Iter    42/  229] train: loss: 0.1152197
[Epoch 73; Iter    72/  229] train: loss: 0.0924409
[Epoch 73; Iter   102/  229] train: loss: 0.1313921
[Epoch 73; Iter   132/  229] train: loss: 0.1767948
[Epoch 73; Iter   162/  229] train: loss: 0.1339218
[Epoch 73; Iter   192/  229] train: loss: 0.1208854
[Epoch 73; Iter   222/  229] train: loss: 0.1408392
[Epoch 73] ogbg-moltoxcast: 0.679797 val loss: 0.266860
[Epoch 73] ogbg-moltoxcast: 0.655613 test loss: 0.318528
[Epoch 74; Iter    23/  229] train: loss: 0.0897734
[Epoch 74; Iter    53/  229] train: loss: 0.1869816
[Epoch 74; Iter    83/  229] train: loss: 0.0920560
[Epoch 74; Iter   113/  229] train: loss: 0.1502191
[Epoch 74; Iter   143/  229] train: loss: 0.1747283
[Epoch 74; Iter   173/  229] train: loss: 0.0872198
[Epoch 74; Iter   203/  229] train: loss: 0.1084594
[Epoch 74] ogbg-moltoxcast: 0.679357 val loss: 0.269375
[Epoch 74] ogbg-moltoxcast: 0.655834 test loss: 0.323506
[Epoch 75; Iter     4/  229] train: loss: 0.0929282
[Epoch 75; Iter    34/  229] train: loss: 0.1408789
[Epoch 75; Iter    64/  229] train: loss: 0.0998494
[Epoch 75; Iter    94/  229] train: loss: 0.1438004
[Epoch 75; Iter   124/  229] train: loss: 0.1480836
[Epoch 75; Iter   154/  229] train: loss: 0.1047398
[Epoch 75; Iter   184/  229] train: loss: 0.1340009
[Epoch 75; Iter   214/  229] train: loss: 0.1082161
[Epoch 75] ogbg-moltoxcast: 0.683029 val loss: 0.267563
[Epoch 75] ogbg-moltoxcast: 0.655354 test loss: 0.323486
[Epoch 66; Iter   105/  201] train: loss: 0.1409021
[Epoch 66; Iter   135/  201] train: loss: 0.1421078
[Epoch 66; Iter   165/  201] train: loss: 0.1079472
[Epoch 66; Iter   195/  201] train: loss: 0.1454563
[Epoch 66] ogbg-moltoxcast: 0.667594 val loss: 0.270266
[Epoch 66] ogbg-moltoxcast: 0.667063 test loss: 0.307515
[Epoch 67; Iter    24/  201] train: loss: 0.1403828
[Epoch 67; Iter    54/  201] train: loss: 0.1405910
[Epoch 67; Iter    84/  201] train: loss: 0.1362159
[Epoch 67; Iter   114/  201] train: loss: 0.1120084
[Epoch 67; Iter   144/  201] train: loss: 0.1187111
[Epoch 67; Iter   174/  201] train: loss: 0.1450907
[Epoch 67] ogbg-moltoxcast: 0.674808 val loss: 0.270108
[Epoch 67] ogbg-moltoxcast: 0.668681 test loss: 0.307001
[Epoch 68; Iter     3/  201] train: loss: 0.0898614
[Epoch 68; Iter    33/  201] train: loss: 0.1459091
[Epoch 68; Iter    63/  201] train: loss: 0.1287360
[Epoch 68; Iter    93/  201] train: loss: 0.1481129
[Epoch 68; Iter   123/  201] train: loss: 0.1107788
[Epoch 68; Iter   153/  201] train: loss: 0.1175933
[Epoch 68; Iter   183/  201] train: loss: 0.1415535
[Epoch 68] ogbg-moltoxcast: 0.671048 val loss: 0.267991
[Epoch 68] ogbg-moltoxcast: 0.665765 test loss: 0.307259
[Epoch 69; Iter    12/  201] train: loss: 0.1396473
[Epoch 69; Iter    42/  201] train: loss: 0.1559546
[Epoch 69; Iter    72/  201] train: loss: 0.1115453
[Epoch 69; Iter   102/  201] train: loss: 0.1105434
[Epoch 69; Iter   132/  201] train: loss: 0.1162308
[Epoch 69; Iter   162/  201] train: loss: 0.1023222
[Epoch 69; Iter   192/  201] train: loss: 0.1042939
[Epoch 69] ogbg-moltoxcast: 0.665304 val loss: 0.269401
[Epoch 69] ogbg-moltoxcast: 0.662230 test loss: 0.308088
[Epoch 70; Iter    21/  201] train: loss: 0.1260118
[Epoch 70; Iter    51/  201] train: loss: 0.1114172
[Epoch 70; Iter    81/  201] train: loss: 0.1008983
[Epoch 70; Iter   111/  201] train: loss: 0.1151880
[Epoch 70; Iter   141/  201] train: loss: 0.1582710
[Epoch 70; Iter   171/  201] train: loss: 0.1359931
[Epoch 70; Iter   201/  201] train: loss: 0.2337779
[Epoch 70] ogbg-moltoxcast: 0.671294 val loss: 0.273720
[Epoch 70] ogbg-moltoxcast: 0.667587 test loss: 0.311903
[Epoch 71; Iter    30/  201] train: loss: 0.1239451
[Epoch 71; Iter    60/  201] train: loss: 0.1058063
[Epoch 71; Iter    90/  201] train: loss: 0.1058393
[Epoch 71; Iter   120/  201] train: loss: 0.1288312
[Epoch 71; Iter   150/  201] train: loss: 0.1462014
[Epoch 71; Iter   180/  201] train: loss: 0.1612786
[Epoch 71] ogbg-moltoxcast: 0.673387 val loss: 0.270622
[Epoch 71] ogbg-moltoxcast: 0.667827 test loss: 0.314049
[Epoch 72; Iter     9/  201] train: loss: 0.1276003
[Epoch 72; Iter    39/  201] train: loss: 0.1296522
[Epoch 72; Iter    69/  201] train: loss: 0.1455619
[Epoch 72; Iter    99/  201] train: loss: 0.1295450
[Epoch 72; Iter   129/  201] train: loss: 0.1267602
[Epoch 72; Iter   159/  201] train: loss: 0.1105960
[Epoch 72; Iter   189/  201] train: loss: 0.0911333
[Epoch 72] ogbg-moltoxcast: 0.670756 val loss: 0.269657
[Epoch 72] ogbg-moltoxcast: 0.659541 test loss: 0.309823
[Epoch 73; Iter    18/  201] train: loss: 0.1431446
[Epoch 73; Iter    48/  201] train: loss: 0.1728265
[Epoch 73; Iter    78/  201] train: loss: 0.1124376
[Epoch 73; Iter   108/  201] train: loss: 0.1639186
[Epoch 73; Iter   138/  201] train: loss: 0.1061899
[Epoch 73; Iter   168/  201] train: loss: 0.1194596
[Epoch 73; Iter   198/  201] train: loss: 0.1432380
[Epoch 73] ogbg-moltoxcast: 0.668849 val loss: 0.277367
[Epoch 73] ogbg-moltoxcast: 0.661803 test loss: 0.318800
[Epoch 74; Iter    27/  201] train: loss: 0.1231581
[Epoch 74; Iter    57/  201] train: loss: 0.0989395
[Epoch 74; Iter    87/  201] train: loss: 0.1209552
[Epoch 74; Iter   117/  201] train: loss: 0.1601084
[Epoch 74; Iter   147/  201] train: loss: 0.1053191
[Epoch 74; Iter   177/  201] train: loss: 0.1251649
[Epoch 74] ogbg-moltoxcast: 0.671478 val loss: 0.272652
[Epoch 74] ogbg-moltoxcast: 0.664154 test loss: 0.310679
[Epoch 75; Iter     6/  201] train: loss: 0.1209750
[Epoch 75; Iter    36/  201] train: loss: 0.1360864
[Epoch 75; Iter    66/  201] train: loss: 0.1382876
[Epoch 75; Iter    96/  201] train: loss: 0.1025901
[Epoch 75; Iter   126/  201] train: loss: 0.1039028
[Epoch 75; Iter   156/  201] train: loss: 0.1334072
[Epoch 75; Iter   186/  201] train: loss: 0.0943087
[Epoch 75] ogbg-moltoxcast: 0.671782 val loss: 0.269694
[Epoch 75] ogbg-moltoxcast: 0.660886 test loss: 0.311809
[Epoch 76; Iter    15/  201] train: loss: 0.0922244
[Epoch 76; Iter    45/  201] train: loss: 0.1154173
[Epoch 76; Iter    75/  201] train: loss: 0.1433887
[Epoch 76; Iter   105/  201] train: loss: 0.1105812
[Epoch 76; Iter   135/  201] train: loss: 0.1223353
[Epoch 76; Iter   165/  201] train: loss: 0.0905647
[Epoch 76; Iter   195/  201] train: loss: 0.0963139
[Epoch 76] ogbg-moltoxcast: 0.668968 val loss: 0.270009
[Epoch 76] ogbg-moltoxcast: 0.657806 test loss: 0.311245
[Epoch 77; Iter    24/  201] train: loss: 0.1811088
[Epoch 77; Iter    54/  201] train: loss: 0.1046549
[Epoch 77; Iter    84/  201] train: loss: 0.1039646
[Epoch 77; Iter   114/  201] train: loss: 0.1221336
[Epoch 77; Iter   144/  201] train: loss: 0.1136074
[Epoch 77; Iter   174/  201] train: loss: 0.1341194
[Epoch 77] ogbg-moltoxcast: 0.671396 val loss: 0.270412
[Epoch 77] ogbg-moltoxcast: 0.663829 test loss: 0.309305
[Epoch 78; Iter     3/  201] train: loss: 0.1312395
[Epoch 78; Iter    33/  201] train: loss: 0.1169445
[Epoch 78; Iter    63/  201] train: loss: 0.1184883
[Epoch 78; Iter    93/  201] train: loss: 0.1146877
[Epoch 78; Iter   123/  201] train: loss: 0.1835458
[Epoch 78; Iter   153/  201] train: loss: 0.1144163
[Epoch 78; Iter   183/  201] train: loss: 0.1395331
[Epoch 78] ogbg-moltoxcast: 0.673362 val loss: 0.275659
[Epoch 78] ogbg-moltoxcast: 0.662165 test loss: 0.318839
[Epoch 79; Iter    12/  201] train: loss: 0.1081999
[Epoch 79; Iter    42/  201] train: loss: 0.0936565
[Epoch 79; Iter    72/  201] train: loss: 0.1350063
[Epoch 79; Iter   102/  201] train: loss: 0.0852617
[Epoch 79; Iter   132/  201] train: loss: 0.1646811
[Epoch 79; Iter   162/  201] train: loss: 0.1483033
[Epoch 79; Iter   192/  201] train: loss: 0.0979970
[Epoch 79] ogbg-moltoxcast: 0.668815 val loss: 0.281776
[Epoch 79] ogbg-moltoxcast: 0.660259 test loss: 0.328485
[Epoch 80; Iter    21/  201] train: loss: 0.1675169
[Epoch 80; Iter    51/  201] train: loss: 0.1379432
[Epoch 80; Iter    81/  201] train: loss: 0.1351208
[Epoch 80; Iter   111/  201] train: loss: 0.0872458
[Epoch 80; Iter   141/  201] train: loss: 0.1798965
[Epoch 80; Iter   171/  201] train: loss: 0.0947469
[Epoch 80; Iter   201/  201] train: loss: 0.5088309
[Epoch 80] ogbg-moltoxcast: 0.660957 val loss: 0.285126
[Epoch 80] ogbg-moltoxcast: 0.659614 test loss: 0.325976
[Epoch 81; Iter    30/  201] train: loss: 0.2093466
[Epoch 81; Iter    60/  201] train: loss: 0.1106111
[Epoch 81; Iter    90/  201] train: loss: 0.1077102
[Epoch 81; Iter   120/  201] train: loss: 0.1898013
[Epoch 81; Iter   150/  201] train: loss: 0.1317202
[Epoch 81; Iter   180/  201] train: loss: 0.1607920
[Epoch 81] ogbg-moltoxcast: 0.663764 val loss: 0.279765
[Epoch 81] ogbg-moltoxcast: 0.658749 test loss: 0.320008
[Epoch 82; Iter     9/  201] train: loss: 0.1512273
[Epoch 82; Iter    39/  201] train: loss: 0.1032341
[Epoch 82; Iter    69/  201] train: loss: 0.1085619
[Epoch 82; Iter    99/  201] train: loss: 0.1506419
[Epoch 82; Iter   129/  201] train: loss: 0.1109230
[Epoch 82; Iter   159/  201] train: loss: 0.1169789
[Epoch 82; Iter   189/  201] train: loss: 0.1252566
[Epoch 82] ogbg-moltoxcast: 0.666609 val loss: 0.279703
[Epoch 82] ogbg-moltoxcast: 0.660976 test loss: 0.320291
[Epoch 83; Iter    18/  201] train: loss: 0.1019572
[Epoch 83; Iter    48/  201] train: loss: 0.0951615
[Epoch 83; Iter    78/  201] train: loss: 0.1058683
[Epoch 83; Iter   108/  201] train: loss: 0.0971896
[Epoch 83; Iter   138/  201] train: loss: 0.1179041
[Epoch 83; Iter   168/  201] train: loss: 0.1666434
[Epoch 83; Iter   198/  201] train: loss: 0.1068212
[Epoch 83] ogbg-moltoxcast: 0.658857 val loss: 0.276163
[Epoch 83] ogbg-moltoxcast: 0.659929 test loss: 0.315276
[Epoch 66; Iter   105/  201] train: loss: 0.0789096
[Epoch 66; Iter   135/  201] train: loss: 0.1094449
[Epoch 66; Iter   165/  201] train: loss: 0.1264496
[Epoch 66; Iter   195/  201] train: loss: 0.1711427
[Epoch 66] ogbg-moltoxcast: 0.675486 val loss: 0.283651
[Epoch 66] ogbg-moltoxcast: 0.667899 test loss: 0.332983
[Epoch 67; Iter    24/  201] train: loss: 0.2031253
[Epoch 67; Iter    54/  201] train: loss: 0.1466878
[Epoch 67; Iter    84/  201] train: loss: 0.1283422
[Epoch 67; Iter   114/  201] train: loss: 0.0973232
[Epoch 67; Iter   144/  201] train: loss: 0.1289602
[Epoch 67; Iter   174/  201] train: loss: 0.1006613
[Epoch 67] ogbg-moltoxcast: 0.686696 val loss: 0.263733
[Epoch 67] ogbg-moltoxcast: 0.667602 test loss: 0.312118
[Epoch 68; Iter     3/  201] train: loss: 0.1328528
[Epoch 68; Iter    33/  201] train: loss: 0.1183088
[Epoch 68; Iter    63/  201] train: loss: 0.1429061
[Epoch 68; Iter    93/  201] train: loss: 0.1626942
[Epoch 68; Iter   123/  201] train: loss: 0.0777047
[Epoch 68; Iter   153/  201] train: loss: 0.1442357
[Epoch 68; Iter   183/  201] train: loss: 0.2206543
[Epoch 68] ogbg-moltoxcast: 0.687904 val loss: 0.264313
[Epoch 68] ogbg-moltoxcast: 0.667304 test loss: 0.311939
[Epoch 69; Iter    12/  201] train: loss: 0.0868179
[Epoch 69; Iter    42/  201] train: loss: 0.1439732
[Epoch 69; Iter    72/  201] train: loss: 0.1532701
[Epoch 69; Iter   102/  201] train: loss: 0.1520946
[Epoch 69; Iter   132/  201] train: loss: 0.1002763
[Epoch 69; Iter   162/  201] train: loss: 0.1387939
[Epoch 69; Iter   192/  201] train: loss: 0.0909079
[Epoch 69] ogbg-moltoxcast: 0.685485 val loss: 0.272569
[Epoch 69] ogbg-moltoxcast: 0.669832 test loss: 0.319507
[Epoch 70; Iter    21/  201] train: loss: 0.1468927
[Epoch 70; Iter    51/  201] train: loss: 0.1201165
[Epoch 70; Iter    81/  201] train: loss: 0.1249545
[Epoch 70; Iter   111/  201] train: loss: 0.1245784
[Epoch 70; Iter   141/  201] train: loss: 0.1434973
[Epoch 70; Iter   171/  201] train: loss: 0.1267286
[Epoch 70; Iter   201/  201] train: loss: 0.5202211
[Epoch 70] ogbg-moltoxcast: 0.682099 val loss: 0.266334
[Epoch 70] ogbg-moltoxcast: 0.664234 test loss: 0.312008
[Epoch 71; Iter    30/  201] train: loss: 0.0718149
[Epoch 71; Iter    60/  201] train: loss: 0.2199058
[Epoch 71; Iter    90/  201] train: loss: 0.1087915
[Epoch 71; Iter   120/  201] train: loss: 0.1322456
[Epoch 71; Iter   150/  201] train: loss: 0.1711435
[Epoch 71; Iter   180/  201] train: loss: 0.1598331
[Epoch 71] ogbg-moltoxcast: 0.681437 val loss: 0.276584
[Epoch 71] ogbg-moltoxcast: 0.665360 test loss: 0.325481
[Epoch 72; Iter     9/  201] train: loss: 0.2543934
[Epoch 72; Iter    39/  201] train: loss: 0.1210743
[Epoch 72; Iter    69/  201] train: loss: 0.1434095
[Epoch 72; Iter    99/  201] train: loss: 0.1160527
[Epoch 72; Iter   129/  201] train: loss: 0.1155276
[Epoch 72; Iter   159/  201] train: loss: 0.1264682
[Epoch 72; Iter   189/  201] train: loss: 0.1213594
[Epoch 72] ogbg-moltoxcast: 0.689206 val loss: 0.264945
[Epoch 72] ogbg-moltoxcast: 0.668971 test loss: 0.312592
[Epoch 73; Iter    18/  201] train: loss: 0.1396161
[Epoch 73; Iter    48/  201] train: loss: 0.0804506
[Epoch 73; Iter    78/  201] train: loss: 0.1283382
[Epoch 73; Iter   108/  201] train: loss: 0.1315459
[Epoch 73; Iter   138/  201] train: loss: 0.1609967
[Epoch 73; Iter   168/  201] train: loss: 0.1354818
[Epoch 73; Iter   198/  201] train: loss: 0.1294408
[Epoch 73] ogbg-moltoxcast: 0.685083 val loss: 0.270913
[Epoch 73] ogbg-moltoxcast: 0.664168 test loss: 0.320699
[Epoch 74; Iter    27/  201] train: loss: 0.0956146
[Epoch 74; Iter    57/  201] train: loss: 0.1482122
[Epoch 74; Iter    87/  201] train: loss: 0.1196199
[Epoch 74; Iter   117/  201] train: loss: 0.1110266
[Epoch 74; Iter   147/  201] train: loss: 0.1101887
[Epoch 74; Iter   177/  201] train: loss: 0.1400462
[Epoch 74] ogbg-moltoxcast: 0.686567 val loss: 0.266315
[Epoch 74] ogbg-moltoxcast: 0.666612 test loss: 0.311507
[Epoch 75; Iter     6/  201] train: loss: 0.1777493
[Epoch 75; Iter    36/  201] train: loss: 0.1646449
[Epoch 75; Iter    66/  201] train: loss: 0.1025945
[Epoch 75; Iter    96/  201] train: loss: 0.1089395
[Epoch 75; Iter   126/  201] train: loss: 0.1466475
[Epoch 75; Iter   156/  201] train: loss: 0.1421405
[Epoch 75; Iter   186/  201] train: loss: 0.1773405
[Epoch 75] ogbg-moltoxcast: 0.680786 val loss: 0.276413
[Epoch 75] ogbg-moltoxcast: 0.663299 test loss: 0.319457
[Epoch 76; Iter    15/  201] train: loss: 0.1493147
[Epoch 76; Iter    45/  201] train: loss: 0.1937900
[Epoch 76; Iter    75/  201] train: loss: 0.1703672
[Epoch 76; Iter   105/  201] train: loss: 0.1291242
[Epoch 76; Iter   135/  201] train: loss: 0.1362836
[Epoch 76; Iter   165/  201] train: loss: 0.1151827
[Epoch 76; Iter   195/  201] train: loss: 0.1088227
[Epoch 76] ogbg-moltoxcast: 0.681728 val loss: 0.271832
[Epoch 76] ogbg-moltoxcast: 0.661529 test loss: 0.316636
[Epoch 77; Iter    24/  201] train: loss: 0.0960932
[Epoch 77; Iter    54/  201] train: loss: 0.1116539
[Epoch 77; Iter    84/  201] train: loss: 0.1372814
[Epoch 77; Iter   114/  201] train: loss: 0.1048657
[Epoch 77; Iter   144/  201] train: loss: 0.1095439
[Epoch 77; Iter   174/  201] train: loss: 0.1163516
[Epoch 77] ogbg-moltoxcast: 0.683688 val loss: 0.268504
[Epoch 77] ogbg-moltoxcast: 0.662275 test loss: 0.311737
[Epoch 78; Iter     3/  201] train: loss: 0.1379842
[Epoch 78; Iter    33/  201] train: loss: 0.2052467
[Epoch 78; Iter    63/  201] train: loss: 0.1510954
[Epoch 78; Iter    93/  201] train: loss: 0.1229580
[Epoch 78; Iter   123/  201] train: loss: 0.1418550
[Epoch 78; Iter   153/  201] train: loss: 0.1176147
[Epoch 78; Iter   183/  201] train: loss: 0.1468771
[Epoch 78] ogbg-moltoxcast: 0.682971 val loss: 0.279152
[Epoch 78] ogbg-moltoxcast: 0.665560 test loss: 0.325228
[Epoch 79; Iter    12/  201] train: loss: 0.1152638
[Epoch 79; Iter    42/  201] train: loss: 0.1141264
[Epoch 79; Iter    72/  201] train: loss: 0.1558726
[Epoch 79; Iter   102/  201] train: loss: 0.1386348
[Epoch 79; Iter   132/  201] train: loss: 0.1063734
[Epoch 79; Iter   162/  201] train: loss: 0.1097363
[Epoch 79; Iter   192/  201] train: loss: 0.1205048
[Epoch 79] ogbg-moltoxcast: 0.682152 val loss: 0.270622
[Epoch 79] ogbg-moltoxcast: 0.660642 test loss: 0.313904
[Epoch 80; Iter    21/  201] train: loss: 0.1485464
[Epoch 80; Iter    51/  201] train: loss: 0.1149892
[Epoch 80; Iter    81/  201] train: loss: 0.0943164
[Epoch 80; Iter   111/  201] train: loss: 0.1161481
[Epoch 80; Iter   141/  201] train: loss: 0.1401996
[Epoch 80; Iter   171/  201] train: loss: 0.1393612
[Epoch 80; Iter   201/  201] train: loss: 0.1691652
[Epoch 80] ogbg-moltoxcast: 0.685585 val loss: 0.266693
[Epoch 80] ogbg-moltoxcast: 0.665462 test loss: 0.310692
[Epoch 81; Iter    30/  201] train: loss: 0.1148268
[Epoch 81; Iter    60/  201] train: loss: 0.1110279
[Epoch 81; Iter    90/  201] train: loss: 0.1222915
[Epoch 81; Iter   120/  201] train: loss: 0.1279069
[Epoch 81; Iter   150/  201] train: loss: 0.1169454
[Epoch 81; Iter   180/  201] train: loss: 0.1091614
[Epoch 81] ogbg-moltoxcast: 0.677469 val loss: 0.275393
[Epoch 81] ogbg-moltoxcast: 0.655968 test loss: 0.320362
[Epoch 82; Iter     9/  201] train: loss: 0.0971628
[Epoch 82; Iter    39/  201] train: loss: 0.0853076
[Epoch 82; Iter    69/  201] train: loss: 0.0897095
[Epoch 82; Iter    99/  201] train: loss: 0.0743937
[Epoch 82; Iter   129/  201] train: loss: 0.1797153
[Epoch 82; Iter   159/  201] train: loss: 0.1308162
[Epoch 82; Iter   189/  201] train: loss: 0.0834323
[Epoch 82] ogbg-moltoxcast: 0.685508 val loss: 0.275589
[Epoch 82] ogbg-moltoxcast: 0.670375 test loss: 0.321784
[Epoch 83; Iter    18/  201] train: loss: 0.1167941
[Epoch 83; Iter    48/  201] train: loss: 0.1236673
[Epoch 83; Iter    78/  201] train: loss: 0.1400981
[Epoch 83; Iter   108/  201] train: loss: 0.1209569
[Epoch 83; Iter   138/  201] train: loss: 0.1030721
[Epoch 83; Iter   168/  201] train: loss: 0.1865772
[Epoch 83; Iter   198/  201] train: loss: 0.1751241
[Epoch 83] ogbg-moltoxcast: 0.682124 val loss: 0.273166
[Epoch 83] ogbg-moltoxcast: 0.663450 test loss: 0.318626
[Epoch 66; Iter   105/  201] train: loss: 0.1459522
[Epoch 66; Iter   135/  201] train: loss: 0.1029747
[Epoch 66; Iter   165/  201] train: loss: 0.1915507
[Epoch 66; Iter   195/  201] train: loss: 0.1113690
[Epoch 66] ogbg-moltoxcast: 0.667253 val loss: 0.279359
[Epoch 66] ogbg-moltoxcast: 0.657035 test loss: 0.328053
[Epoch 67; Iter    24/  201] train: loss: 0.1302249
[Epoch 67; Iter    54/  201] train: loss: 0.1449790
[Epoch 67; Iter    84/  201] train: loss: 0.1599191
[Epoch 67; Iter   114/  201] train: loss: 0.1207462
[Epoch 67; Iter   144/  201] train: loss: 0.1418024
[Epoch 67; Iter   174/  201] train: loss: 0.0881449
[Epoch 67] ogbg-moltoxcast: 0.670858 val loss: 0.274631
[Epoch 67] ogbg-moltoxcast: 0.657048 test loss: 0.324150
[Epoch 68; Iter     3/  201] train: loss: 0.1079719
[Epoch 68; Iter    33/  201] train: loss: 0.1027528
[Epoch 68; Iter    63/  201] train: loss: 0.1225416
[Epoch 68; Iter    93/  201] train: loss: 0.1250596
[Epoch 68; Iter   123/  201] train: loss: 0.1260287
[Epoch 68; Iter   153/  201] train: loss: 0.1313671
[Epoch 68; Iter   183/  201] train: loss: 0.1270081
[Epoch 68] ogbg-moltoxcast: 0.670950 val loss: 0.277455
[Epoch 68] ogbg-moltoxcast: 0.658735 test loss: 0.327138
[Epoch 69; Iter    12/  201] train: loss: 0.1600643
[Epoch 69; Iter    42/  201] train: loss: 0.0966331
[Epoch 69; Iter    72/  201] train: loss: 0.1184714
[Epoch 69; Iter   102/  201] train: loss: 0.1062001
[Epoch 69; Iter   132/  201] train: loss: 0.1035131
[Epoch 69; Iter   162/  201] train: loss: 0.1274069
[Epoch 69; Iter   192/  201] train: loss: 0.0730248
[Epoch 69] ogbg-moltoxcast: 0.671861 val loss: 0.270112
[Epoch 69] ogbg-moltoxcast: 0.657690 test loss: 0.317875
[Epoch 70; Iter    21/  201] train: loss: 0.1170225
[Epoch 70; Iter    51/  201] train: loss: 0.1102557
[Epoch 70; Iter    81/  201] train: loss: 0.1202359
[Epoch 70; Iter   111/  201] train: loss: 0.0862731
[Epoch 70; Iter   141/  201] train: loss: 0.1545894
[Epoch 70; Iter   171/  201] train: loss: 0.1439205
[Epoch 70; Iter   201/  201] train: loss: 0.3201150
[Epoch 70] ogbg-moltoxcast: 0.671529 val loss: 0.275958
[Epoch 70] ogbg-moltoxcast: 0.660001 test loss: 0.327764
[Epoch 71; Iter    30/  201] train: loss: 0.1180120
[Epoch 71; Iter    60/  201] train: loss: 0.1122338
[Epoch 71; Iter    90/  201] train: loss: 0.1179941
[Epoch 71; Iter   120/  201] train: loss: 0.1057225
[Epoch 71; Iter   150/  201] train: loss: 0.1451704
[Epoch 71; Iter   180/  201] train: loss: 0.0818620
[Epoch 71] ogbg-moltoxcast: 0.668395 val loss: 0.275672
[Epoch 71] ogbg-moltoxcast: 0.660021 test loss: 0.324343
[Epoch 72; Iter     9/  201] train: loss: 0.1076365
[Epoch 72; Iter    39/  201] train: loss: 0.1108565
[Epoch 72; Iter    69/  201] train: loss: 0.1181081
[Epoch 72; Iter    99/  201] train: loss: 0.1019104
[Epoch 72; Iter   129/  201] train: loss: 0.1238901
[Epoch 72; Iter   159/  201] train: loss: 0.1503712
[Epoch 72; Iter   189/  201] train: loss: 0.1812572
[Epoch 72] ogbg-moltoxcast: 0.667234 val loss: 0.281042
[Epoch 72] ogbg-moltoxcast: 0.660673 test loss: 0.330165
[Epoch 73; Iter    18/  201] train: loss: 0.1179892
[Epoch 73; Iter    48/  201] train: loss: 0.1123115
[Epoch 73; Iter    78/  201] train: loss: 0.1183061
[Epoch 73; Iter   108/  201] train: loss: 0.0900466
[Epoch 73; Iter   138/  201] train: loss: 0.0978498
[Epoch 73; Iter   168/  201] train: loss: 0.1139651
[Epoch 73; Iter   198/  201] train: loss: 0.1054560
[Epoch 73] ogbg-moltoxcast: 0.665735 val loss: 0.282312
[Epoch 73] ogbg-moltoxcast: 0.650225 test loss: 0.337706
[Epoch 74; Iter    27/  201] train: loss: 0.1253651
[Epoch 74; Iter    57/  201] train: loss: 0.1085082
[Epoch 74; Iter    87/  201] train: loss: 0.1084657
[Epoch 74; Iter   117/  201] train: loss: 0.1490785
[Epoch 74; Iter   147/  201] train: loss: 0.1665839
[Epoch 74; Iter   177/  201] train: loss: 0.0894490
[Epoch 74] ogbg-moltoxcast: 0.673721 val loss: 0.279532
[Epoch 74] ogbg-moltoxcast: 0.656946 test loss: 0.329274
[Epoch 75; Iter     6/  201] train: loss: 0.0857658
[Epoch 75; Iter    36/  201] train: loss: 0.1024221
[Epoch 75; Iter    66/  201] train: loss: 0.1217646
[Epoch 75; Iter    96/  201] train: loss: 0.2056899
[Epoch 75; Iter   126/  201] train: loss: 0.1532797
[Epoch 75; Iter   156/  201] train: loss: 0.1522013
[Epoch 75; Iter   186/  201] train: loss: 0.1387064
[Epoch 75] ogbg-moltoxcast: 0.664822 val loss: 0.281112
[Epoch 75] ogbg-moltoxcast: 0.658930 test loss: 0.326144
[Epoch 76; Iter    15/  201] train: loss: 0.1769064
[Epoch 76; Iter    45/  201] train: loss: 0.1438594
[Epoch 76; Iter    75/  201] train: loss: 0.1205079
[Epoch 76; Iter   105/  201] train: loss: 0.1086585
[Epoch 76; Iter   135/  201] train: loss: 0.1467336
[Epoch 76; Iter   165/  201] train: loss: 0.0721836
[Epoch 76; Iter   195/  201] train: loss: 0.1301233
[Epoch 76] ogbg-moltoxcast: 0.661761 val loss: 0.285609
[Epoch 76] ogbg-moltoxcast: 0.652843 test loss: 0.336661
[Epoch 77; Iter    24/  201] train: loss: 0.1265187
[Epoch 77; Iter    54/  201] train: loss: 0.1363699
[Epoch 77; Iter    84/  201] train: loss: 0.1265656
[Epoch 77; Iter   114/  201] train: loss: 0.0835453
[Epoch 77; Iter   144/  201] train: loss: 0.1596381
[Epoch 77; Iter   174/  201] train: loss: 0.1946641
[Epoch 77] ogbg-moltoxcast: 0.664451 val loss: 0.280685
[Epoch 77] ogbg-moltoxcast: 0.658589 test loss: 0.327425
[Epoch 78; Iter     3/  201] train: loss: 0.1695352
[Epoch 78; Iter    33/  201] train: loss: 0.1159448
[Epoch 78; Iter    63/  201] train: loss: 0.1537166
[Epoch 78; Iter    93/  201] train: loss: 0.1123800
[Epoch 78; Iter   123/  201] train: loss: 0.1520233
[Epoch 78; Iter   153/  201] train: loss: 0.0966958
[Epoch 78; Iter   183/  201] train: loss: 0.1620715
[Epoch 78] ogbg-moltoxcast: 0.669933 val loss: 0.278850
[Epoch 78] ogbg-moltoxcast: 0.662326 test loss: 0.326816
[Epoch 79; Iter    12/  201] train: loss: 0.1831395
[Epoch 79; Iter    42/  201] train: loss: 0.1187458
[Epoch 79; Iter    72/  201] train: loss: 0.1179339
[Epoch 79; Iter   102/  201] train: loss: 0.0988793
[Epoch 79; Iter   132/  201] train: loss: 0.1141205
[Epoch 79; Iter   162/  201] train: loss: 0.1959694
[Epoch 79; Iter   192/  201] train: loss: 0.1097727
[Epoch 79] ogbg-moltoxcast: 0.663069 val loss: 0.284184
[Epoch 79] ogbg-moltoxcast: 0.658901 test loss: 0.331436
[Epoch 80; Iter    21/  201] train: loss: 0.1201473
[Epoch 80; Iter    51/  201] train: loss: 0.1253390
[Epoch 80; Iter    81/  201] train: loss: 0.0855594
[Epoch 80; Iter   111/  201] train: loss: 0.1681364
[Epoch 80; Iter   141/  201] train: loss: 0.1278412
[Epoch 80; Iter   171/  201] train: loss: 0.0904261
[Epoch 80; Iter   201/  201] train: loss: 0.1418532
[Epoch 80] ogbg-moltoxcast: 0.664385 val loss: 0.285167
[Epoch 80] ogbg-moltoxcast: 0.651366 test loss: 0.335430
[Epoch 81; Iter    30/  201] train: loss: 0.1288115
[Epoch 81; Iter    60/  201] train: loss: 0.1367017
[Epoch 81; Iter    90/  201] train: loss: 0.1358021
[Epoch 81; Iter   120/  201] train: loss: 0.0895057
[Epoch 81; Iter   150/  201] train: loss: 0.1056034
[Epoch 81; Iter   180/  201] train: loss: 0.1221029
[Epoch 81] ogbg-moltoxcast: 0.663622 val loss: 0.283983
[Epoch 81] ogbg-moltoxcast: 0.650233 test loss: 0.337304
[Epoch 82; Iter     9/  201] train: loss: 0.1420143
[Epoch 82; Iter    39/  201] train: loss: 0.1105107
[Epoch 82; Iter    69/  201] train: loss: 0.1247488
[Epoch 82; Iter    99/  201] train: loss: 0.1205174
[Epoch 82; Iter   129/  201] train: loss: 0.0644519
[Epoch 82; Iter   159/  201] train: loss: 0.1041610
[Epoch 82; Iter   189/  201] train: loss: 0.1241192
[Epoch 82] ogbg-moltoxcast: 0.670025 val loss: 0.278898
[Epoch 82] ogbg-moltoxcast: 0.655842 test loss: 0.331601
[Epoch 83; Iter    18/  201] train: loss: 0.0816619
[Epoch 83; Iter    48/  201] train: loss: 0.1268135
[Epoch 83; Iter    78/  201] train: loss: 0.1068254
[Epoch 83; Iter   108/  201] train: loss: 0.1425352
[Epoch 83; Iter   138/  201] train: loss: 0.1632416
[Epoch 83; Iter   168/  201] train: loss: 0.0914256
[Epoch 83; Iter   198/  201] train: loss: 0.1250764
[Epoch 83] ogbg-moltoxcast: 0.669887 val loss: 0.282333
[Epoch 83] ogbg-moltoxcast: 0.662048 test loss: 0.331882
[Epoch 74; Iter   134/  172] train: loss: 0.1657804
[Epoch 74; Iter   164/  172] train: loss: 0.1372599
[Epoch 74] ogbg-moltoxcast: 0.662882 val loss: 0.355399
[Epoch 74] ogbg-moltoxcast: 0.617919 test loss: 0.488640
[Epoch 75; Iter    22/  172] train: loss: 0.1280475
[Epoch 75; Iter    52/  172] train: loss: 0.1140566
[Epoch 75; Iter    82/  172] train: loss: 0.1054717
[Epoch 75; Iter   112/  172] train: loss: 0.0917995
[Epoch 75; Iter   142/  172] train: loss: 0.1272606
[Epoch 75; Iter   172/  172] train: loss: 0.1267563
[Epoch 75] ogbg-moltoxcast: 0.661455 val loss: 0.584099
[Epoch 75] ogbg-moltoxcast: 0.613516 test loss: 1.089128
[Epoch 76; Iter    30/  172] train: loss: 0.0846459
[Epoch 76; Iter    60/  172] train: loss: 0.1266186
[Epoch 76; Iter    90/  172] train: loss: 0.1029499
[Epoch 76; Iter   120/  172] train: loss: 0.1327220
[Epoch 76; Iter   150/  172] train: loss: 0.1322560
[Epoch 76] ogbg-moltoxcast: 0.658110 val loss: 0.523375
[Epoch 76] ogbg-moltoxcast: 0.613834 test loss: 1.052712
[Epoch 77; Iter     8/  172] train: loss: 0.1154747
[Epoch 77; Iter    38/  172] train: loss: 0.0887725
[Epoch 77; Iter    68/  172] train: loss: 0.1123079
[Epoch 77; Iter    98/  172] train: loss: 0.1611425
[Epoch 77; Iter   128/  172] train: loss: 0.0886952
[Epoch 77; Iter   158/  172] train: loss: 0.1173621
[Epoch 77] ogbg-moltoxcast: 0.656516 val loss: 0.300199
[Epoch 77] ogbg-moltoxcast: 0.606328 test loss: 0.367723
[Epoch 78; Iter    16/  172] train: loss: 0.1201715
[Epoch 78; Iter    46/  172] train: loss: 0.1065783
[Epoch 78; Iter    76/  172] train: loss: 0.1408541
[Epoch 78; Iter   106/  172] train: loss: 0.0836535
[Epoch 78; Iter   136/  172] train: loss: 0.1142637
[Epoch 78; Iter   166/  172] train: loss: 0.1016117
[Epoch 78] ogbg-moltoxcast: 0.654772 val loss: 0.339360
[Epoch 78] ogbg-moltoxcast: 0.609682 test loss: 0.694214
[Epoch 79; Iter    24/  172] train: loss: 0.1275485
[Epoch 79; Iter    54/  172] train: loss: 0.1498857
[Epoch 79; Iter    84/  172] train: loss: 0.1389028
[Epoch 79; Iter   114/  172] train: loss: 0.0760097
[Epoch 79; Iter   144/  172] train: loss: 0.1087797
[Epoch 79] ogbg-moltoxcast: 0.653870 val loss: 0.296778
[Epoch 79] ogbg-moltoxcast: 0.608810 test loss: 0.375409
[Epoch 80; Iter     2/  172] train: loss: 0.0694381
[Epoch 80; Iter    32/  172] train: loss: 0.1356699
[Epoch 80; Iter    62/  172] train: loss: 0.1171575
[Epoch 80; Iter    92/  172] train: loss: 0.1659002
[Epoch 80; Iter   122/  172] train: loss: 0.0810233
[Epoch 80; Iter   152/  172] train: loss: 0.1134742
[Epoch 80] ogbg-moltoxcast: 0.651818 val loss: 0.307102
[Epoch 80] ogbg-moltoxcast: 0.611676 test loss: 0.407074
[Epoch 81; Iter    10/  172] train: loss: 0.1762887
[Epoch 81; Iter    40/  172] train: loss: 0.1226258
[Epoch 81; Iter    70/  172] train: loss: 0.1002434
[Epoch 81; Iter   100/  172] train: loss: 0.1191086
[Epoch 81; Iter   130/  172] train: loss: 0.1324370
[Epoch 81; Iter   160/  172] train: loss: 0.1551335
[Epoch 81] ogbg-moltoxcast: 0.653638 val loss: 0.528176
[Epoch 81] ogbg-moltoxcast: 0.615731 test loss: 1.086144
[Epoch 82; Iter    18/  172] train: loss: 0.0981216
[Epoch 82; Iter    48/  172] train: loss: 0.0887129
[Epoch 82; Iter    78/  172] train: loss: 0.1621505
[Epoch 82; Iter   108/  172] train: loss: 0.1452124
[Epoch 82; Iter   138/  172] train: loss: 0.1530615
[Epoch 82; Iter   168/  172] train: loss: 0.1171395
[Epoch 82] ogbg-moltoxcast: 0.662557 val loss: 0.341730
[Epoch 82] ogbg-moltoxcast: 0.616588 test loss: 1.543833
[Epoch 83; Iter    26/  172] train: loss: 0.0794072
[Epoch 83; Iter    56/  172] train: loss: 0.1225825
[Epoch 83; Iter    86/  172] train: loss: 0.0766848
[Epoch 83; Iter   116/  172] train: loss: 0.1370684
[Epoch 83; Iter   146/  172] train: loss: 0.1428360
[Epoch 83] ogbg-moltoxcast: 0.658019 val loss: 0.301899
[Epoch 83] ogbg-moltoxcast: 0.616390 test loss: 0.372063
[Epoch 84; Iter     4/  172] train: loss: 0.1358046
[Epoch 84; Iter    34/  172] train: loss: 0.0829317
[Epoch 84; Iter    64/  172] train: loss: 0.1198916
[Epoch 84; Iter    94/  172] train: loss: 0.1153574
[Epoch 84; Iter   124/  172] train: loss: 0.1169881
[Epoch 84; Iter   154/  172] train: loss: 0.1427804
[Epoch 84] ogbg-moltoxcast: 0.654652 val loss: 0.299786
[Epoch 84] ogbg-moltoxcast: 0.613123 test loss: 0.367257
[Epoch 85; Iter    12/  172] train: loss: 0.2084616
[Epoch 85; Iter    42/  172] train: loss: 0.0907492
[Epoch 85; Iter    72/  172] train: loss: 0.1159099
[Epoch 85; Iter   102/  172] train: loss: 0.1170972
[Epoch 85; Iter   132/  172] train: loss: 0.1079373
[Epoch 85; Iter   162/  172] train: loss: 0.1073979
[Epoch 85] ogbg-moltoxcast: 0.658431 val loss: 0.303039
[Epoch 85] ogbg-moltoxcast: 0.613742 test loss: 0.539201
[Epoch 86; Iter    20/  172] train: loss: 0.1119875
[Epoch 86; Iter    50/  172] train: loss: 0.1287308
[Epoch 86; Iter    80/  172] train: loss: 0.1483728
[Epoch 86; Iter   110/  172] train: loss: 0.1292553
[Epoch 86; Iter   140/  172] train: loss: 0.1291670
[Epoch 86; Iter   170/  172] train: loss: 0.0755347
[Epoch 86] ogbg-moltoxcast: 0.648117 val loss: 0.368308
[Epoch 86] ogbg-moltoxcast: 0.606243 test loss: 0.486947
[Epoch 87; Iter    28/  172] train: loss: 0.1359469
[Epoch 87; Iter    58/  172] train: loss: 0.0965962
[Epoch 87; Iter    88/  172] train: loss: 0.0931582
[Epoch 87; Iter   118/  172] train: loss: 0.1411261
[Epoch 87; Iter   148/  172] train: loss: 0.1291835
[Epoch 87] ogbg-moltoxcast: 0.657188 val loss: 0.303758
[Epoch 87] ogbg-moltoxcast: 0.620589 test loss: 0.384106
[Epoch 88; Iter     6/  172] train: loss: 0.0911412
[Epoch 88; Iter    36/  172] train: loss: 0.0908628
[Epoch 88; Iter    66/  172] train: loss: 0.1134470
[Epoch 88; Iter    96/  172] train: loss: 0.1024724
[Epoch 88; Iter   126/  172] train: loss: 0.0727279
[Epoch 88; Iter   156/  172] train: loss: 0.1130060
[Epoch 88] ogbg-moltoxcast: 0.650894 val loss: 0.304251
[Epoch 88] ogbg-moltoxcast: 0.613079 test loss: 0.421200
[Epoch 89; Iter    14/  172] train: loss: 0.0816923
[Epoch 89; Iter    44/  172] train: loss: 0.0959107
[Epoch 89; Iter    74/  172] train: loss: 0.0966972
[Epoch 89; Iter   104/  172] train: loss: 0.0901707
[Epoch 89; Iter   134/  172] train: loss: 0.1454991
[Epoch 89; Iter   164/  172] train: loss: 0.0848602
[Epoch 89] ogbg-moltoxcast: 0.649322 val loss: 0.322654
[Epoch 89] ogbg-moltoxcast: 0.609019 test loss: 0.460281
[Epoch 90; Iter    22/  172] train: loss: 0.1455066
[Epoch 90; Iter    52/  172] train: loss: 0.0816143
[Epoch 90; Iter    82/  172] train: loss: 0.1182513
[Epoch 90; Iter   112/  172] train: loss: 0.1402746
[Epoch 90; Iter   142/  172] train: loss: 0.1095834
[Epoch 90; Iter   172/  172] train: loss: 0.0717553
[Epoch 90] ogbg-moltoxcast: 0.648338 val loss: 0.311127
[Epoch 90] ogbg-moltoxcast: 0.611705 test loss: 0.389638
[Epoch 91; Iter    30/  172] train: loss: 0.1159412
[Epoch 91; Iter    60/  172] train: loss: 0.1322120
[Epoch 91; Iter    90/  172] train: loss: 0.1963669
[Epoch 91; Iter   120/  172] train: loss: 0.1050079
[Epoch 91; Iter   150/  172] train: loss: 0.1120691
[Epoch 91] ogbg-moltoxcast: 0.651622 val loss: 0.302699
[Epoch 91] ogbg-moltoxcast: 0.613071 test loss: 0.411322
[Epoch 92; Iter     8/  172] train: loss: 0.1222574
[Epoch 92; Iter    38/  172] train: loss: 0.1147727
[Epoch 92; Iter    68/  172] train: loss: 0.1268044
[Epoch 92; Iter    98/  172] train: loss: 0.1047151
[Epoch 92; Iter   128/  172] train: loss: 0.1015237
[Epoch 92; Iter   158/  172] train: loss: 0.0983177
[Epoch 92] ogbg-moltoxcast: 0.651800 val loss: 0.397887
[Epoch 92] ogbg-moltoxcast: 0.617662 test loss: 0.487910
[Epoch 93; Iter    16/  172] train: loss: 0.1044382
[Epoch 93; Iter    46/  172] train: loss: 0.1374303
[Epoch 93; Iter    76/  172] train: loss: 0.1338232
[Epoch 93; Iter   106/  172] train: loss: 0.1242240
[Epoch 93; Iter   136/  172] train: loss: 0.0995472
[Epoch 93; Iter   166/  172] train: loss: 0.1664436
[Epoch 93] ogbg-moltoxcast: 0.653634 val loss: 0.305489
[Epoch 93] ogbg-moltoxcast: 0.616793 test loss: 0.386182
[Epoch 94; Iter    24/  172] train: loss: 0.0927988
[Epoch 94; Iter    54/  172] train: loss: 0.1335342
[Epoch 94; Iter    84/  172] train: loss: 0.1201010
[Epoch 74; Iter   134/  172] train: loss: 0.0780846
[Epoch 74; Iter   164/  172] train: loss: 0.1471165
[Epoch 74] ogbg-moltoxcast: 0.648605 val loss: 0.295636
[Epoch 74] ogbg-moltoxcast: 0.624826 test loss: 0.347017
[Epoch 75; Iter    22/  172] train: loss: 0.1385623
[Epoch 75; Iter    52/  172] train: loss: 0.1200130
[Epoch 75; Iter    82/  172] train: loss: 0.0746745
[Epoch 75; Iter   112/  172] train: loss: 0.1081032
[Epoch 75; Iter   142/  172] train: loss: 0.1089016
[Epoch 75; Iter   172/  172] train: loss: 0.1310947
[Epoch 75] ogbg-moltoxcast: 0.655264 val loss: 0.291723
[Epoch 75] ogbg-moltoxcast: 0.625773 test loss: 0.345062
[Epoch 76; Iter    30/  172] train: loss: 0.0874438
[Epoch 76; Iter    60/  172] train: loss: 0.0948976
[Epoch 76; Iter    90/  172] train: loss: 0.1530184
[Epoch 76; Iter   120/  172] train: loss: 0.1024880
[Epoch 76; Iter   150/  172] train: loss: 0.0874461
[Epoch 76] ogbg-moltoxcast: 0.654547 val loss: 0.296035
[Epoch 76] ogbg-moltoxcast: 0.627317 test loss: 0.350013
[Epoch 77; Iter     8/  172] train: loss: 0.1056023
[Epoch 77; Iter    38/  172] train: loss: 0.0905003
[Epoch 77; Iter    68/  172] train: loss: 0.1011807
[Epoch 77; Iter    98/  172] train: loss: 0.1281197
[Epoch 77; Iter   128/  172] train: loss: 0.0884349
[Epoch 77; Iter   158/  172] train: loss: 0.1132565
[Epoch 77] ogbg-moltoxcast: 0.652457 val loss: 0.297133
[Epoch 77] ogbg-moltoxcast: 0.623294 test loss: 0.350842
[Epoch 78; Iter    16/  172] train: loss: 0.0910274
[Epoch 78; Iter    46/  172] train: loss: 0.1266205
[Epoch 78; Iter    76/  172] train: loss: 0.0959443
[Epoch 78; Iter   106/  172] train: loss: 0.1135086
[Epoch 78; Iter   136/  172] train: loss: 0.1097271
[Epoch 78; Iter   166/  172] train: loss: 0.0737484
[Epoch 78] ogbg-moltoxcast: 0.653702 val loss: 0.297924
[Epoch 78] ogbg-moltoxcast: 0.626585 test loss: 0.351874
[Epoch 79; Iter    24/  172] train: loss: 0.1237584
[Epoch 79; Iter    54/  172] train: loss: 0.1082920
[Epoch 79; Iter    84/  172] train: loss: 0.1189315
[Epoch 79; Iter   114/  172] train: loss: 0.1138211
[Epoch 79; Iter   144/  172] train: loss: 0.1160292
[Epoch 79] ogbg-moltoxcast: 0.651021 val loss: 0.305244
[Epoch 79] ogbg-moltoxcast: 0.627741 test loss: 0.360126
[Epoch 80; Iter     2/  172] train: loss: 0.1623462
[Epoch 80; Iter    32/  172] train: loss: 0.1529104
[Epoch 80; Iter    62/  172] train: loss: 0.1202068
[Epoch 80; Iter    92/  172] train: loss: 0.0997028
[Epoch 80; Iter   122/  172] train: loss: 0.1267270
[Epoch 80; Iter   152/  172] train: loss: 0.1335858
[Epoch 80] ogbg-moltoxcast: 0.648273 val loss: 0.299512
[Epoch 80] ogbg-moltoxcast: 0.622293 test loss: 0.354643
[Epoch 81; Iter    10/  172] train: loss: 0.1501894
[Epoch 81; Iter    40/  172] train: loss: 0.1498646
[Epoch 81; Iter    70/  172] train: loss: 0.1346979
[Epoch 81; Iter   100/  172] train: loss: 0.0993667
[Epoch 81; Iter   130/  172] train: loss: 0.1051701
[Epoch 81; Iter   160/  172] train: loss: 0.0853489
[Epoch 81] ogbg-moltoxcast: 0.645584 val loss: 0.301791
[Epoch 81] ogbg-moltoxcast: 0.622626 test loss: 0.356555
[Epoch 82; Iter    18/  172] train: loss: 0.0810228
[Epoch 82; Iter    48/  172] train: loss: 0.1043789
[Epoch 82; Iter    78/  172] train: loss: 0.0851784
[Epoch 82; Iter   108/  172] train: loss: 0.1715461
[Epoch 82; Iter   138/  172] train: loss: 0.0822314
[Epoch 82; Iter   168/  172] train: loss: 0.1289539
[Epoch 82] ogbg-moltoxcast: 0.645863 val loss: 0.312230
[Epoch 82] ogbg-moltoxcast: 0.622459 test loss: 0.373560
[Epoch 83; Iter    26/  172] train: loss: 0.1160247
[Epoch 83; Iter    56/  172] train: loss: 0.1109228
[Epoch 83; Iter    86/  172] train: loss: 0.1252796
[Epoch 83; Iter   116/  172] train: loss: 0.0972767
[Epoch 83; Iter   146/  172] train: loss: 0.0672988
[Epoch 83] ogbg-moltoxcast: 0.647387 val loss: 0.307571
[Epoch 83] ogbg-moltoxcast: 0.624412 test loss: 0.358319
[Epoch 84; Iter     4/  172] train: loss: 0.1433285
[Epoch 84; Iter    34/  172] train: loss: 0.0884055
[Epoch 84; Iter    64/  172] train: loss: 0.0902205
[Epoch 84; Iter    94/  172] train: loss: 0.1068194
[Epoch 84; Iter   124/  172] train: loss: 0.1101043
[Epoch 84; Iter   154/  172] train: loss: 0.1298566
[Epoch 84] ogbg-moltoxcast: 0.646038 val loss: 0.306028
[Epoch 84] ogbg-moltoxcast: 0.624004 test loss: 0.362853
[Epoch 85; Iter    12/  172] train: loss: 0.0970013
[Epoch 85; Iter    42/  172] train: loss: 0.0869872
[Epoch 85; Iter    72/  172] train: loss: 0.1043277
[Epoch 85; Iter   102/  172] train: loss: 0.0918482
[Epoch 85; Iter   132/  172] train: loss: 0.1602515
[Epoch 85; Iter   162/  172] train: loss: 0.1237186
[Epoch 85] ogbg-moltoxcast: 0.652503 val loss: 0.304032
[Epoch 85] ogbg-moltoxcast: 0.629354 test loss: 0.361032
[Epoch 86; Iter    20/  172] train: loss: 0.0934379
[Epoch 86; Iter    50/  172] train: loss: 0.1146970
[Epoch 86; Iter    80/  172] train: loss: 0.0970850
[Epoch 86; Iter   110/  172] train: loss: 0.1016915
[Epoch 86; Iter   140/  172] train: loss: 0.1641817
[Epoch 86; Iter   170/  172] train: loss: 0.1082258
[Epoch 86] ogbg-moltoxcast: 0.648169 val loss: 0.301526
[Epoch 86] ogbg-moltoxcast: 0.626666 test loss: 0.354824
[Epoch 87; Iter    28/  172] train: loss: 0.1073310
[Epoch 87; Iter    58/  172] train: loss: 0.0849451
[Epoch 87; Iter    88/  172] train: loss: 0.0883908
[Epoch 87; Iter   118/  172] train: loss: 0.1098145
[Epoch 87; Iter   148/  172] train: loss: 0.0783155
[Epoch 87] ogbg-moltoxcast: 0.645061 val loss: 0.306046
[Epoch 87] ogbg-moltoxcast: 0.622332 test loss: 0.358429
[Epoch 88; Iter     6/  172] train: loss: 0.1455580
[Epoch 88; Iter    36/  172] train: loss: 0.1228494
[Epoch 88; Iter    66/  172] train: loss: 0.1159114
[Epoch 88; Iter    96/  172] train: loss: 0.1059293
[Epoch 88; Iter   126/  172] train: loss: 0.0784543
[Epoch 88; Iter   156/  172] train: loss: 0.1347851
[Epoch 88] ogbg-moltoxcast: 0.643970 val loss: 0.307844
[Epoch 88] ogbg-moltoxcast: 0.618947 test loss: 0.362591
[Epoch 89; Iter    14/  172] train: loss: 0.1057283
[Epoch 89; Iter    44/  172] train: loss: 0.1159173
[Epoch 89; Iter    74/  172] train: loss: 0.1038114
[Epoch 89; Iter   104/  172] train: loss: 0.1301670
[Epoch 89; Iter   134/  172] train: loss: 0.1033769
[Epoch 89; Iter   164/  172] train: loss: 0.1162847
[Epoch 89] ogbg-moltoxcast: 0.647228 val loss: 0.307724
[Epoch 89] ogbg-moltoxcast: 0.621690 test loss: 0.361002
[Epoch 90; Iter    22/  172] train: loss: 0.0974228
[Epoch 90; Iter    52/  172] train: loss: 0.1477467
[Epoch 90; Iter    82/  172] train: loss: 0.0731145
[Epoch 90; Iter   112/  172] train: loss: 0.0795905
[Epoch 90; Iter   142/  172] train: loss: 0.1424673
[Epoch 90; Iter   172/  172] train: loss: 0.1113790
[Epoch 90] ogbg-moltoxcast: 0.641040 val loss: 0.311294
[Epoch 90] ogbg-moltoxcast: 0.622362 test loss: 0.364065
[Epoch 91; Iter    30/  172] train: loss: 0.0973929
[Epoch 91; Iter    60/  172] train: loss: 0.0988900
[Epoch 91; Iter    90/  172] train: loss: 0.1294107
[Epoch 91; Iter   120/  172] train: loss: 0.1064675
[Epoch 91; Iter   150/  172] train: loss: 0.1236672
[Epoch 91] ogbg-moltoxcast: 0.633646 val loss: 0.316375
[Epoch 91] ogbg-moltoxcast: 0.618435 test loss: 0.370669
[Epoch 92; Iter     8/  172] train: loss: 0.1147652
[Epoch 92; Iter    38/  172] train: loss: 0.0795234
[Epoch 92; Iter    68/  172] train: loss: 0.1181334
[Epoch 92; Iter    98/  172] train: loss: 0.1015300
[Epoch 92; Iter   128/  172] train: loss: 0.1411458
[Epoch 92; Iter   158/  172] train: loss: 0.1609123
[Epoch 92] ogbg-moltoxcast: 0.634061 val loss: 0.318654
[Epoch 92] ogbg-moltoxcast: 0.617869 test loss: 0.371407
[Epoch 93; Iter    16/  172] train: loss: 0.1029578
[Epoch 93; Iter    46/  172] train: loss: 0.1475597
[Epoch 93; Iter    76/  172] train: loss: 0.1255947
[Epoch 93; Iter   106/  172] train: loss: 0.1188581
[Epoch 93; Iter   136/  172] train: loss: 0.1129532
[Epoch 93; Iter   166/  172] train: loss: 0.1147372
[Epoch 93] ogbg-moltoxcast: 0.640318 val loss: 0.310246
[Epoch 93] ogbg-moltoxcast: 0.623680 test loss: 0.362528
[Epoch 94; Iter    24/  172] train: loss: 0.1385923
[Epoch 94; Iter    54/  172] train: loss: 0.1057193
[Epoch 94; Iter    84/  172] train: loss: 0.1066163
[Epoch 74; Iter   134/  172] train: loss: 0.0843090
[Epoch 74; Iter   164/  172] train: loss: 0.1233473
[Epoch 74] ogbg-moltoxcast: 0.657063 val loss: 0.294635
[Epoch 74] ogbg-moltoxcast: 0.620446 test loss: 0.349665
[Epoch 75; Iter    22/  172] train: loss: 0.1274240
[Epoch 75; Iter    52/  172] train: loss: 0.1039218
[Epoch 75; Iter    82/  172] train: loss: 0.1157772
[Epoch 75; Iter   112/  172] train: loss: 0.0904265
[Epoch 75; Iter   142/  172] train: loss: 0.1242897
[Epoch 75; Iter   172/  172] train: loss: 0.1345076
[Epoch 75] ogbg-moltoxcast: 0.653592 val loss: 0.297335
[Epoch 75] ogbg-moltoxcast: 0.619427 test loss: 0.351090
[Epoch 76; Iter    30/  172] train: loss: 0.0958387
[Epoch 76; Iter    60/  172] train: loss: 0.0792952
[Epoch 76; Iter    90/  172] train: loss: 0.1478075
[Epoch 76; Iter   120/  172] train: loss: 0.0878694
[Epoch 76; Iter   150/  172] train: loss: 0.1377444
[Epoch 76] ogbg-moltoxcast: 0.655756 val loss: 0.302409
[Epoch 76] ogbg-moltoxcast: 0.616211 test loss: 0.355509
[Epoch 77; Iter     8/  172] train: loss: 0.1296420
[Epoch 77; Iter    38/  172] train: loss: 0.1136282
[Epoch 77; Iter    68/  172] train: loss: 0.1066251
[Epoch 77; Iter    98/  172] train: loss: 0.1113169
[Epoch 77; Iter   128/  172] train: loss: 0.0718378
[Epoch 77; Iter   158/  172] train: loss: 0.0994964
[Epoch 77] ogbg-moltoxcast: 0.659943 val loss: 0.292992
[Epoch 77] ogbg-moltoxcast: 0.616359 test loss: 0.345168
[Epoch 78; Iter    16/  172] train: loss: 0.1637294
[Epoch 78; Iter    46/  172] train: loss: 0.1782342
[Epoch 78; Iter    76/  172] train: loss: 0.1926204
[Epoch 78; Iter   106/  172] train: loss: 0.1080363
[Epoch 78; Iter   136/  172] train: loss: 0.1388940
[Epoch 78; Iter   166/  172] train: loss: 0.1739561
[Epoch 78] ogbg-moltoxcast: 0.660624 val loss: 0.305325
[Epoch 78] ogbg-moltoxcast: 0.616763 test loss: 0.361322
[Epoch 79; Iter    24/  172] train: loss: 0.1472065
[Epoch 79; Iter    54/  172] train: loss: 0.1122487
[Epoch 79; Iter    84/  172] train: loss: 0.1530182
[Epoch 79; Iter   114/  172] train: loss: 0.0769369
[Epoch 79; Iter   144/  172] train: loss: 0.1064373
[Epoch 79] ogbg-moltoxcast: 0.658915 val loss: 0.296498
[Epoch 79] ogbg-moltoxcast: 0.618040 test loss: 0.348930
[Epoch 80; Iter     2/  172] train: loss: 0.1200143
[Epoch 80; Iter    32/  172] train: loss: 0.1030544
[Epoch 80; Iter    62/  172] train: loss: 0.1644573
[Epoch 80; Iter    92/  172] train: loss: 0.1453186
[Epoch 80; Iter   122/  172] train: loss: 0.1223569
[Epoch 80; Iter   152/  172] train: loss: 0.1036676
[Epoch 80] ogbg-moltoxcast: 0.657064 val loss: 0.295970
[Epoch 80] ogbg-moltoxcast: 0.613725 test loss: 0.348838
[Epoch 81; Iter    10/  172] train: loss: 0.1213691
[Epoch 81; Iter    40/  172] train: loss: 0.1013770
[Epoch 81; Iter    70/  172] train: loss: 0.1465526
[Epoch 81; Iter   100/  172] train: loss: 0.1049921
[Epoch 81; Iter   130/  172] train: loss: 0.1569086
[Epoch 81; Iter   160/  172] train: loss: 0.0849012
[Epoch 81] ogbg-moltoxcast: 0.657136 val loss: 0.299151
[Epoch 81] ogbg-moltoxcast: 0.617542 test loss: 0.348856
[Epoch 82; Iter    18/  172] train: loss: 0.1064491
[Epoch 82; Iter    48/  172] train: loss: 0.1537607
[Epoch 82; Iter    78/  172] train: loss: 0.1366392
[Epoch 82; Iter   108/  172] train: loss: 0.1525159
[Epoch 82; Iter   138/  172] train: loss: 0.1196013
[Epoch 82; Iter   168/  172] train: loss: 0.0863476
[Epoch 82] ogbg-moltoxcast: 0.659494 val loss: 0.298801
[Epoch 82] ogbg-moltoxcast: 0.615895 test loss: 0.351833
[Epoch 83; Iter    26/  172] train: loss: 0.1253794
[Epoch 83; Iter    56/  172] train: loss: 0.0914278
[Epoch 83; Iter    86/  172] train: loss: 0.1186207
[Epoch 83; Iter   116/  172] train: loss: 0.1028153
[Epoch 83; Iter   146/  172] train: loss: 0.0830165
[Epoch 83] ogbg-moltoxcast: 0.651818 val loss: 0.302155
[Epoch 83] ogbg-moltoxcast: 0.614318 test loss: 0.354546
[Epoch 84; Iter     4/  172] train: loss: 0.1642566
[Epoch 84; Iter    34/  172] train: loss: 0.0951942
[Epoch 84; Iter    64/  172] train: loss: 0.1129179
[Epoch 84; Iter    94/  172] train: loss: 0.1065360
[Epoch 84; Iter   124/  172] train: loss: 0.0985616
[Epoch 84; Iter   154/  172] train: loss: 0.1195464
[Epoch 84] ogbg-moltoxcast: 0.652703 val loss: 0.303868
[Epoch 84] ogbg-moltoxcast: 0.613259 test loss: 0.352168
[Epoch 85; Iter    12/  172] train: loss: 0.1101916
[Epoch 85; Iter    42/  172] train: loss: 0.1425243
[Epoch 85; Iter    72/  172] train: loss: 0.1062905
[Epoch 85; Iter   102/  172] train: loss: 0.1041524
[Epoch 85; Iter   132/  172] train: loss: 0.0987385
[Epoch 85; Iter   162/  172] train: loss: 0.1305884
[Epoch 85] ogbg-moltoxcast: 0.649129 val loss: 0.301239
[Epoch 85] ogbg-moltoxcast: 0.608151 test loss: 0.352623
[Epoch 86; Iter    20/  172] train: loss: 0.1271925
[Epoch 86; Iter    50/  172] train: loss: 0.1072555
[Epoch 86; Iter    80/  172] train: loss: 0.1105994
[Epoch 86; Iter   110/  172] train: loss: 0.0999036
[Epoch 86; Iter   140/  172] train: loss: 0.0916427
[Epoch 86; Iter   170/  172] train: loss: 0.1164881
[Epoch 86] ogbg-moltoxcast: 0.653543 val loss: 0.300754
[Epoch 86] ogbg-moltoxcast: 0.610708 test loss: 0.352729
[Epoch 87; Iter    28/  172] train: loss: 0.0945725
[Epoch 87; Iter    58/  172] train: loss: 0.1310958
[Epoch 87; Iter    88/  172] train: loss: 0.1175680
[Epoch 87; Iter   118/  172] train: loss: 0.0797484
[Epoch 87; Iter   148/  172] train: loss: 0.1303729
[Epoch 87] ogbg-moltoxcast: 0.650637 val loss: 0.307335
[Epoch 87] ogbg-moltoxcast: 0.612364 test loss: 0.357744
[Epoch 88; Iter     6/  172] train: loss: 0.1339377
[Epoch 88; Iter    36/  172] train: loss: 0.1442394
[Epoch 88; Iter    66/  172] train: loss: 0.1754520
[Epoch 88; Iter    96/  172] train: loss: 0.0867697
[Epoch 88; Iter   126/  172] train: loss: 0.1222288
[Epoch 88; Iter   156/  172] train: loss: 0.1091838
[Epoch 88] ogbg-moltoxcast: 0.650861 val loss: 0.302495
[Epoch 88] ogbg-moltoxcast: 0.618846 test loss: 0.348705
[Epoch 89; Iter    14/  172] train: loss: 0.1377202
[Epoch 89; Iter    44/  172] train: loss: 0.1366991
[Epoch 89; Iter    74/  172] train: loss: 0.0884310
[Epoch 89; Iter   104/  172] train: loss: 0.1174422
[Epoch 89; Iter   134/  172] train: loss: 0.0929386
[Epoch 89; Iter   164/  172] train: loss: 0.1181214
[Epoch 89] ogbg-moltoxcast: 0.648351 val loss: 0.304353
[Epoch 89] ogbg-moltoxcast: 0.612259 test loss: 0.355193
[Epoch 90; Iter    22/  172] train: loss: 0.1455796
[Epoch 90; Iter    52/  172] train: loss: 0.1297590
[Epoch 90; Iter    82/  172] train: loss: 0.1288424
[Epoch 90; Iter   112/  172] train: loss: 0.1124175
[Epoch 90; Iter   142/  172] train: loss: 0.0988214
[Epoch 90; Iter   172/  172] train: loss: 0.1874378
[Epoch 90] ogbg-moltoxcast: 0.655650 val loss: 0.306445
[Epoch 90] ogbg-moltoxcast: 0.612294 test loss: 0.365427
[Epoch 91; Iter    30/  172] train: loss: 0.0613616
[Epoch 91; Iter    60/  172] train: loss: 0.1626424
[Epoch 91; Iter    90/  172] train: loss: 0.1074690
[Epoch 91; Iter   120/  172] train: loss: 0.1149627
[Epoch 91; Iter   150/  172] train: loss: 0.1210744
[Epoch 91] ogbg-moltoxcast: 0.662509 val loss: 0.302655
[Epoch 91] ogbg-moltoxcast: 0.622100 test loss: 0.360892
[Epoch 92; Iter     8/  172] train: loss: 0.1290669
[Epoch 92; Iter    38/  172] train: loss: 0.0937886
[Epoch 92; Iter    68/  172] train: loss: 0.0698078
[Epoch 92; Iter    98/  172] train: loss: 0.1164824
[Epoch 92; Iter   128/  172] train: loss: 0.1611343
[Epoch 92; Iter   158/  172] train: loss: 0.1502003
[Epoch 92] ogbg-moltoxcast: 0.658229 val loss: 0.302399
[Epoch 92] ogbg-moltoxcast: 0.616643 test loss: 0.360239
[Epoch 93; Iter    16/  172] train: loss: 0.1164424
[Epoch 93; Iter    46/  172] train: loss: 0.0595129
[Epoch 93; Iter    76/  172] train: loss: 0.1001854
[Epoch 93; Iter   106/  172] train: loss: 0.0890368
[Epoch 93; Iter   136/  172] train: loss: 0.1120094
[Epoch 93; Iter   166/  172] train: loss: 0.1224537
[Epoch 93] ogbg-moltoxcast: 0.655855 val loss: 0.307641
[Epoch 93] ogbg-moltoxcast: 0.613563 test loss: 0.365741
[Epoch 94; Iter    24/  172] train: loss: 0.1197278
[Epoch 94; Iter    54/  172] train: loss: 0.0765789
[Epoch 94; Iter    84/  172] train: loss: 0.1117443
[Epoch 76; Iter    15/  229] train: loss: 0.1591403
[Epoch 76; Iter    45/  229] train: loss: 0.1221368
[Epoch 76; Iter    75/  229] train: loss: 0.2052324
[Epoch 76; Iter   105/  229] train: loss: 0.1191099
[Epoch 76; Iter   135/  229] train: loss: 0.1021846
[Epoch 76; Iter   165/  229] train: loss: 0.1502329
[Epoch 76; Iter   195/  229] train: loss: 0.0845501
[Epoch 76; Iter   225/  229] train: loss: 0.1228068
[Epoch 76] ogbg-moltoxcast: 0.691042 val loss: 0.274956
[Epoch 76] ogbg-moltoxcast: 0.657686 test loss: 0.344309
[Epoch 77; Iter    26/  229] train: loss: 0.1368767
[Epoch 77; Iter    56/  229] train: loss: 0.1168119
[Epoch 77; Iter    86/  229] train: loss: 0.0972781
[Epoch 77; Iter   116/  229] train: loss: 0.1542259
[Epoch 77; Iter   146/  229] train: loss: 0.1159636
[Epoch 77; Iter   176/  229] train: loss: 0.1300671
[Epoch 77; Iter   206/  229] train: loss: 0.1538050
[Epoch 77] ogbg-moltoxcast: 0.688818 val loss: 0.271530
[Epoch 77] ogbg-moltoxcast: 0.659080 test loss: 0.345856
[Epoch 78; Iter     7/  229] train: loss: 0.1446424
[Epoch 78; Iter    37/  229] train: loss: 0.1393215
[Epoch 78; Iter    67/  229] train: loss: 0.0981677
[Epoch 78; Iter    97/  229] train: loss: 0.1513539
[Epoch 78; Iter   127/  229] train: loss: 0.1302273
[Epoch 78; Iter   157/  229] train: loss: 0.1133083
[Epoch 78; Iter   187/  229] train: loss: 0.1138042
[Epoch 78; Iter   217/  229] train: loss: 0.1150947
[Epoch 78] ogbg-moltoxcast: 0.687063 val loss: 0.279893
[Epoch 78] ogbg-moltoxcast: 0.658457 test loss: 0.346967
[Epoch 79; Iter    18/  229] train: loss: 0.0936840
[Epoch 79; Iter    48/  229] train: loss: 0.1312722
[Epoch 79; Iter    78/  229] train: loss: 0.0976777
[Epoch 79; Iter   108/  229] train: loss: 0.1312663
[Epoch 79; Iter   138/  229] train: loss: 0.1089966
[Epoch 79; Iter   168/  229] train: loss: 0.0845434
[Epoch 79; Iter   198/  229] train: loss: 0.0746638
[Epoch 79; Iter   228/  229] train: loss: 0.1610322
[Epoch 79] ogbg-moltoxcast: 0.683365 val loss: 0.278209
[Epoch 79] ogbg-moltoxcast: 0.651163 test loss: 0.350224
[Epoch 80; Iter    29/  229] train: loss: 0.1423945
[Epoch 80; Iter    59/  229] train: loss: 0.1148654
[Epoch 80; Iter    89/  229] train: loss: 0.1014051
[Epoch 80; Iter   119/  229] train: loss: 0.1428927
[Epoch 80; Iter   149/  229] train: loss: 0.1473071
[Epoch 80; Iter   179/  229] train: loss: 0.2388369
[Epoch 80; Iter   209/  229] train: loss: 0.1291369
[Epoch 80] ogbg-moltoxcast: 0.690647 val loss: 0.276261
[Epoch 80] ogbg-moltoxcast: 0.655594 test loss: 0.346096
[Epoch 81; Iter    10/  229] train: loss: 0.0889898
[Epoch 81; Iter    40/  229] train: loss: 0.1217370
[Epoch 81; Iter    70/  229] train: loss: 0.1546275
[Epoch 81; Iter   100/  229] train: loss: 0.1280941
[Epoch 81; Iter   130/  229] train: loss: 0.1101626
[Epoch 81; Iter   160/  229] train: loss: 0.1487417
[Epoch 81; Iter   190/  229] train: loss: 0.1703202
[Epoch 81; Iter   220/  229] train: loss: 0.0935772
[Epoch 81] ogbg-moltoxcast: 0.687765 val loss: 0.277390
[Epoch 81] ogbg-moltoxcast: 0.662960 test loss: 0.339307
[Epoch 82; Iter    21/  229] train: loss: 0.0695858
[Epoch 82; Iter    51/  229] train: loss: 0.1275556
[Epoch 82; Iter    81/  229] train: loss: 0.1136096
[Epoch 82; Iter   111/  229] train: loss: 0.1040103
[Epoch 82; Iter   141/  229] train: loss: 0.1522497
[Epoch 82; Iter   171/  229] train: loss: 0.1114586
[Epoch 82; Iter   201/  229] train: loss: 0.0929510
[Epoch 82] ogbg-moltoxcast: 0.686893 val loss: 0.280433
[Epoch 82] ogbg-moltoxcast: 0.660246 test loss: 0.344997
[Epoch 83; Iter     2/  229] train: loss: 0.0934188
[Epoch 83; Iter    32/  229] train: loss: 0.1548204
[Epoch 83; Iter    62/  229] train: loss: 0.1603989
[Epoch 83; Iter    92/  229] train: loss: 0.0999783
[Epoch 83; Iter   122/  229] train: loss: 0.1085229
[Epoch 83; Iter   152/  229] train: loss: 0.1014833
[Epoch 83; Iter   182/  229] train: loss: 0.1485527
[Epoch 83; Iter   212/  229] train: loss: 0.0847635
[Epoch 83] ogbg-moltoxcast: 0.681620 val loss: 0.280431
[Epoch 83] ogbg-moltoxcast: 0.655322 test loss: 0.351469
[Epoch 84; Iter    13/  229] train: loss: 0.1904245
[Epoch 84; Iter    43/  229] train: loss: 0.1346700
[Epoch 84; Iter    73/  229] train: loss: 0.1825027
[Epoch 84; Iter   103/  229] train: loss: 0.0987236
[Epoch 84; Iter   133/  229] train: loss: 0.1044594
[Epoch 84; Iter   163/  229] train: loss: 0.0909659
[Epoch 84; Iter   193/  229] train: loss: 0.1544612
[Epoch 84; Iter   223/  229] train: loss: 0.1314057
[Epoch 84] ogbg-moltoxcast: 0.684705 val loss: 0.279256
[Epoch 84] ogbg-moltoxcast: 0.652984 test loss: 0.352239
[Epoch 85; Iter    24/  229] train: loss: 0.0744242
[Epoch 85; Iter    54/  229] train: loss: 0.1285471
[Epoch 85; Iter    84/  229] train: loss: 0.1274362
[Epoch 85; Iter   114/  229] train: loss: 0.0863363
[Epoch 85; Iter   144/  229] train: loss: 0.1067813
[Epoch 85; Iter   174/  229] train: loss: 0.1482307
[Epoch 85; Iter   204/  229] train: loss: 0.1308206
[Epoch 85] ogbg-moltoxcast: 0.687148 val loss: 0.277349
[Epoch 85] ogbg-moltoxcast: 0.654894 test loss: 0.347218
[Epoch 86; Iter     5/  229] train: loss: 0.0952719
[Epoch 86; Iter    35/  229] train: loss: 0.1646080
[Epoch 86; Iter    65/  229] train: loss: 0.1466808
[Epoch 86; Iter    95/  229] train: loss: 0.1471272
[Epoch 86; Iter   125/  229] train: loss: 0.1113929
[Epoch 86; Iter   155/  229] train: loss: 0.1480480
[Epoch 86; Iter   185/  229] train: loss: 0.1738462
[Epoch 86; Iter   215/  229] train: loss: 0.1340940
[Epoch 86] ogbg-moltoxcast: 0.688960 val loss: 0.280751
[Epoch 86] ogbg-moltoxcast: 0.652050 test loss: 0.353020
[Epoch 87; Iter    16/  229] train: loss: 0.1311250
[Epoch 87; Iter    46/  229] train: loss: 0.1455969
[Epoch 87; Iter    76/  229] train: loss: 0.0797048
[Epoch 87; Iter   106/  229] train: loss: 0.0986052
[Epoch 87; Iter   136/  229] train: loss: 0.0997811
[Epoch 87; Iter   166/  229] train: loss: 0.1179620
[Epoch 87; Iter   196/  229] train: loss: 0.1652144
[Epoch 87; Iter   226/  229] train: loss: 0.1424360
[Epoch 87] ogbg-moltoxcast: 0.691305 val loss: 0.279223
[Epoch 87] ogbg-moltoxcast: 0.656510 test loss: 0.350115
[Epoch 88; Iter    27/  229] train: loss: 0.1068683
[Epoch 88; Iter    57/  229] train: loss: 0.0795169
[Epoch 88; Iter    87/  229] train: loss: 0.0996526
[Epoch 88; Iter   117/  229] train: loss: 0.1181063
[Epoch 88; Iter   147/  229] train: loss: 0.1375043
[Epoch 88; Iter   177/  229] train: loss: 0.1006973
[Epoch 88; Iter   207/  229] train: loss: 0.1148057
[Epoch 88] ogbg-moltoxcast: 0.688506 val loss: 0.281701
[Epoch 88] ogbg-moltoxcast: 0.656983 test loss: 0.352474
[Epoch 89; Iter     8/  229] train: loss: 0.1204951
[Epoch 89; Iter    38/  229] train: loss: 0.1368503
[Epoch 89; Iter    68/  229] train: loss: 0.1117419
[Epoch 89; Iter    98/  229] train: loss: 0.1321575
[Epoch 89; Iter   128/  229] train: loss: 0.1678845
[Epoch 89; Iter   158/  229] train: loss: 0.1207215
[Epoch 89; Iter   188/  229] train: loss: 0.0724169
[Epoch 89; Iter   218/  229] train: loss: 0.1256797
[Epoch 89] ogbg-moltoxcast: 0.685162 val loss: 0.279814
[Epoch 89] ogbg-moltoxcast: 0.654407 test loss: 0.352837
[Epoch 90; Iter    19/  229] train: loss: 0.0924297
[Epoch 90; Iter    49/  229] train: loss: 0.1049061
[Epoch 90; Iter    79/  229] train: loss: 0.0873945
[Epoch 90; Iter   109/  229] train: loss: 0.1137536
[Epoch 90; Iter   139/  229] train: loss: 0.1697378
[Epoch 90; Iter   169/  229] train: loss: 0.1522288
[Epoch 90; Iter   199/  229] train: loss: 0.1477569
[Epoch 90; Iter   229/  229] train: loss: 0.1629815
[Epoch 90] ogbg-moltoxcast: 0.688442 val loss: 0.278449
[Epoch 90] ogbg-moltoxcast: 0.656251 test loss: 0.348499
[Epoch 91; Iter    30/  229] train: loss: 0.0935340
[Epoch 91; Iter    60/  229] train: loss: 0.1158818
[Epoch 91; Iter    90/  229] train: loss: 0.1153236
[Epoch 91; Iter   120/  229] train: loss: 0.1288293
[Epoch 91; Iter   150/  229] train: loss: 0.0837887
[Epoch 91; Iter   180/  229] train: loss: 0.1499879
[Epoch 91; Iter   210/  229] train: loss: 0.1431995
[Epoch 91] ogbg-moltoxcast: 0.688043 val loss: 0.279007
[Epoch 91] ogbg-moltoxcast: 0.655024 test loss: 0.347979
[Epoch 76; Iter    15/  229] train: loss: 0.1118852
[Epoch 76; Iter    45/  229] train: loss: 0.1271188
[Epoch 76; Iter    75/  229] train: loss: 0.1357581
[Epoch 76; Iter   105/  229] train: loss: 0.0927877
[Epoch 76; Iter   135/  229] train: loss: 0.1792913
[Epoch 76; Iter   165/  229] train: loss: 0.1007014
[Epoch 76; Iter   195/  229] train: loss: 0.1184313
[Epoch 76; Iter   225/  229] train: loss: 0.1023809
[Epoch 76] ogbg-moltoxcast: 0.702961 val loss: 0.272379
[Epoch 76] ogbg-moltoxcast: 0.652260 test loss: 0.643793
[Epoch 77; Iter    26/  229] train: loss: 0.1426074
[Epoch 77; Iter    56/  229] train: loss: 0.1020672
[Epoch 77; Iter    86/  229] train: loss: 0.1977137
[Epoch 77; Iter   116/  229] train: loss: 0.1594800
[Epoch 77; Iter   146/  229] train: loss: 0.1357716
[Epoch 77; Iter   176/  229] train: loss: 0.1487202
[Epoch 77; Iter   206/  229] train: loss: 0.1577878
[Epoch 77] ogbg-moltoxcast: 0.702475 val loss: 0.267800
[Epoch 77] ogbg-moltoxcast: 0.655645 test loss: 0.355037
[Epoch 78; Iter     7/  229] train: loss: 0.1303145
[Epoch 78; Iter    37/  229] train: loss: 0.1209770
[Epoch 78; Iter    67/  229] train: loss: 0.1224688
[Epoch 78; Iter    97/  229] train: loss: 0.0932851
[Epoch 78; Iter   127/  229] train: loss: 0.1224918
[Epoch 78; Iter   157/  229] train: loss: 0.1139715
[Epoch 78; Iter   187/  229] train: loss: 0.1591884
[Epoch 78; Iter   217/  229] train: loss: 0.1476395
[Epoch 78] ogbg-moltoxcast: 0.699381 val loss: 0.271619
[Epoch 78] ogbg-moltoxcast: 0.649827 test loss: 0.428789
[Epoch 79; Iter    18/  229] train: loss: 0.1203049
[Epoch 79; Iter    48/  229] train: loss: 0.1330837
[Epoch 79; Iter    78/  229] train: loss: 0.1583391
[Epoch 79; Iter   108/  229] train: loss: 0.1620776
[Epoch 79; Iter   138/  229] train: loss: 0.1729651
[Epoch 79; Iter   168/  229] train: loss: 0.1588737
[Epoch 79; Iter   198/  229] train: loss: 0.1398601
[Epoch 79; Iter   228/  229] train: loss: 0.1372934
[Epoch 79] ogbg-moltoxcast: 0.698355 val loss: 0.268817
[Epoch 79] ogbg-moltoxcast: 0.655941 test loss: 0.586907
[Epoch 80; Iter    29/  229] train: loss: 0.1412157
[Epoch 80; Iter    59/  229] train: loss: 0.1346979
[Epoch 80; Iter    89/  229] train: loss: 0.1522589
[Epoch 80; Iter   119/  229] train: loss: 0.1205814
[Epoch 80; Iter   149/  229] train: loss: 0.1336537
[Epoch 80; Iter   179/  229] train: loss: 0.1459859
[Epoch 80; Iter   209/  229] train: loss: 0.1426712
[Epoch 80] ogbg-moltoxcast: 0.700311 val loss: 0.272236
[Epoch 80] ogbg-moltoxcast: 0.656923 test loss: 0.824631
[Epoch 81; Iter    10/  229] train: loss: 0.0995166
[Epoch 81; Iter    40/  229] train: loss: 0.1433766
[Epoch 81; Iter    70/  229] train: loss: 0.1419362
[Epoch 81; Iter   100/  229] train: loss: 0.0773886
[Epoch 81; Iter   130/  229] train: loss: 0.0926350
[Epoch 81; Iter   160/  229] train: loss: 0.1498210
[Epoch 81; Iter   190/  229] train: loss: 0.1322970
[Epoch 81; Iter   220/  229] train: loss: 0.1318002
[Epoch 81] ogbg-moltoxcast: 0.701890 val loss: 0.265256
[Epoch 81] ogbg-moltoxcast: 0.659241 test loss: 0.343017
[Epoch 82; Iter    21/  229] train: loss: 0.1455306
[Epoch 82; Iter    51/  229] train: loss: 0.1393759
[Epoch 82; Iter    81/  229] train: loss: 0.1035631
[Epoch 82; Iter   111/  229] train: loss: 0.0993392
[Epoch 82; Iter   141/  229] train: loss: 0.1430258
[Epoch 82; Iter   171/  229] train: loss: 0.1129306
[Epoch 82; Iter   201/  229] train: loss: 0.1448172
[Epoch 82] ogbg-moltoxcast: 0.706392 val loss: 0.267990
[Epoch 82] ogbg-moltoxcast: 0.665486 test loss: 0.334314
[Epoch 83; Iter     2/  229] train: loss: 0.1143824
[Epoch 83; Iter    32/  229] train: loss: 0.1176393
[Epoch 83; Iter    62/  229] train: loss: 0.0903726
[Epoch 83; Iter    92/  229] train: loss: 0.1576170
[Epoch 83; Iter   122/  229] train: loss: 0.1176828
[Epoch 83; Iter   152/  229] train: loss: 0.1556148
[Epoch 83; Iter   182/  229] train: loss: 0.1636814
[Epoch 83; Iter   212/  229] train: loss: 0.1232413
[Epoch 83] ogbg-moltoxcast: 0.699658 val loss: 0.268966
[Epoch 83] ogbg-moltoxcast: 0.665240 test loss: 0.333814
[Epoch 84; Iter    13/  229] train: loss: 0.1430044
[Epoch 84; Iter    43/  229] train: loss: 0.1257149
[Epoch 84; Iter    73/  229] train: loss: 0.1507265
[Epoch 84; Iter   103/  229] train: loss: 0.1081243
[Epoch 84; Iter   133/  229] train: loss: 0.1359213
[Epoch 84; Iter   163/  229] train: loss: 0.0910617
[Epoch 84; Iter   193/  229] train: loss: 0.1372401
[Epoch 84; Iter   223/  229] train: loss: 0.1058311
[Epoch 84] ogbg-moltoxcast: 0.698032 val loss: 0.276811
[Epoch 84] ogbg-moltoxcast: 0.651607 test loss: 0.349245
[Epoch 85; Iter    24/  229] train: loss: 0.1207024
[Epoch 85; Iter    54/  229] train: loss: 0.1069610
[Epoch 85; Iter    84/  229] train: loss: 0.1093680
[Epoch 85; Iter   114/  229] train: loss: 0.0983058
[Epoch 85; Iter   144/  229] train: loss: 0.1359516
[Epoch 85; Iter   174/  229] train: loss: 0.1421224
[Epoch 85; Iter   204/  229] train: loss: 0.1481471
[Epoch 85] ogbg-moltoxcast: 0.699846 val loss: 0.271144
[Epoch 85] ogbg-moltoxcast: 0.663230 test loss: 0.334278
[Epoch 86; Iter     5/  229] train: loss: 0.1755453
[Epoch 86; Iter    35/  229] train: loss: 0.1541865
[Epoch 86; Iter    65/  229] train: loss: 0.1252592
[Epoch 86; Iter    95/  229] train: loss: 0.1510932
[Epoch 86; Iter   125/  229] train: loss: 0.1278473
[Epoch 86; Iter   155/  229] train: loss: 0.1211921
[Epoch 86; Iter   185/  229] train: loss: 0.1354544
[Epoch 86; Iter   215/  229] train: loss: 0.1418975
[Epoch 86] ogbg-moltoxcast: 0.700355 val loss: 0.271738
[Epoch 86] ogbg-moltoxcast: 0.664949 test loss: 0.364220
[Epoch 87; Iter    16/  229] train: loss: 0.1171171
[Epoch 87; Iter    46/  229] train: loss: 0.1156031
[Epoch 87; Iter    76/  229] train: loss: 0.1085448
[Epoch 87; Iter   106/  229] train: loss: 0.1160100
[Epoch 87; Iter   136/  229] train: loss: 0.1269710
[Epoch 87; Iter   166/  229] train: loss: 0.1375933
[Epoch 87; Iter   196/  229] train: loss: 0.1378732
[Epoch 87; Iter   226/  229] train: loss: 0.1250590
[Epoch 87] ogbg-moltoxcast: 0.698760 val loss: 0.274528
[Epoch 87] ogbg-moltoxcast: 0.662861 test loss: 0.339643
[Epoch 88; Iter    27/  229] train: loss: 0.1809412
[Epoch 88; Iter    57/  229] train: loss: 0.1094280
[Epoch 88; Iter    87/  229] train: loss: 0.1118567
[Epoch 88; Iter   117/  229] train: loss: 0.1246099
[Epoch 88; Iter   147/  229] train: loss: 0.1055875
[Epoch 88; Iter   177/  229] train: loss: 0.1299812
[Epoch 88; Iter   207/  229] train: loss: 0.1273268
[Epoch 88] ogbg-moltoxcast: 0.695356 val loss: 0.274094
[Epoch 88] ogbg-moltoxcast: 0.661018 test loss: 0.337575
[Epoch 89; Iter     8/  229] train: loss: 0.1125461
[Epoch 89; Iter    38/  229] train: loss: 0.1066835
[Epoch 89; Iter    68/  229] train: loss: 0.1394695
[Epoch 89; Iter    98/  229] train: loss: 0.1011439
[Epoch 89; Iter   128/  229] train: loss: 0.1211206
[Epoch 89; Iter   158/  229] train: loss: 0.1247365
[Epoch 89; Iter   188/  229] train: loss: 0.1156010
[Epoch 89; Iter   218/  229] train: loss: 0.0975586
[Epoch 89] ogbg-moltoxcast: 0.698281 val loss: 0.278393
[Epoch 89] ogbg-moltoxcast: 0.662433 test loss: 0.342477
[Epoch 90; Iter    19/  229] train: loss: 0.1182172
[Epoch 90; Iter    49/  229] train: loss: 0.1574136
[Epoch 90; Iter    79/  229] train: loss: 0.1500582
[Epoch 90; Iter   109/  229] train: loss: 0.1684411
[Epoch 90; Iter   139/  229] train: loss: 0.1462765
[Epoch 90; Iter   169/  229] train: loss: 0.1308855
[Epoch 90; Iter   199/  229] train: loss: 0.0887470
[Epoch 90; Iter   229/  229] train: loss: 0.1217314
[Epoch 90] ogbg-moltoxcast: 0.694647 val loss: 0.271741
[Epoch 90] ogbg-moltoxcast: 0.662456 test loss: 0.334497
[Epoch 91; Iter    30/  229] train: loss: 0.1326642
[Epoch 91; Iter    60/  229] train: loss: 0.0973978
[Epoch 91; Iter    90/  229] train: loss: 0.1232337
[Epoch 91; Iter   120/  229] train: loss: 0.1038244
[Epoch 91; Iter   150/  229] train: loss: 0.1284190
[Epoch 91; Iter   180/  229] train: loss: 0.1291274
[Epoch 91; Iter   210/  229] train: loss: 0.1404429
[Epoch 91] ogbg-moltoxcast: 0.698050 val loss: 0.270471
[Epoch 91] ogbg-moltoxcast: 0.661062 test loss: 0.336717
[Epoch 76; Iter    15/  229] train: loss: 0.1151571
[Epoch 76; Iter    45/  229] train: loss: 0.1283423
[Epoch 76; Iter    75/  229] train: loss: 0.1417337
[Epoch 76; Iter   105/  229] train: loss: 0.1466343
[Epoch 76; Iter   135/  229] train: loss: 0.1000869
[Epoch 76; Iter   165/  229] train: loss: 0.1331076
[Epoch 76; Iter   195/  229] train: loss: 0.1243510
[Epoch 76; Iter   225/  229] train: loss: 0.1376567
[Epoch 76] ogbg-moltoxcast: 0.683843 val loss: 0.270130
[Epoch 76] ogbg-moltoxcast: 0.654010 test loss: 0.323323
[Epoch 77; Iter    26/  229] train: loss: 0.1265360
[Epoch 77; Iter    56/  229] train: loss: 0.1063200
[Epoch 77; Iter    86/  229] train: loss: 0.1803938
[Epoch 77; Iter   116/  229] train: loss: 0.1287435
[Epoch 77; Iter   146/  229] train: loss: 0.1123881
[Epoch 77; Iter   176/  229] train: loss: 0.1451810
[Epoch 77; Iter   206/  229] train: loss: 0.1393062
[Epoch 77] ogbg-moltoxcast: 0.678777 val loss: 0.273703
[Epoch 77] ogbg-moltoxcast: 0.649364 test loss: 0.328698
[Epoch 78; Iter     7/  229] train: loss: 0.1230371
[Epoch 78; Iter    37/  229] train: loss: 0.1096138
[Epoch 78; Iter    67/  229] train: loss: 0.0947607
[Epoch 78; Iter    97/  229] train: loss: 0.1286956
[Epoch 78; Iter   127/  229] train: loss: 0.1759204
[Epoch 78; Iter   157/  229] train: loss: 0.1084597
[Epoch 78; Iter   187/  229] train: loss: 0.1327952
[Epoch 78; Iter   217/  229] train: loss: 0.1108351
[Epoch 78] ogbg-moltoxcast: 0.677997 val loss: 0.272642
[Epoch 78] ogbg-moltoxcast: 0.650554 test loss: 0.328117
[Epoch 79; Iter    18/  229] train: loss: 0.1812875
[Epoch 79; Iter    48/  229] train: loss: 0.1384533
[Epoch 79; Iter    78/  229] train: loss: 0.1573519
[Epoch 79; Iter   108/  229] train: loss: 0.1452908
[Epoch 79; Iter   138/  229] train: loss: 0.1534475
[Epoch 79; Iter   168/  229] train: loss: 0.1405265
[Epoch 79; Iter   198/  229] train: loss: 0.0922265
[Epoch 79; Iter   228/  229] train: loss: 0.1473809
[Epoch 79] ogbg-moltoxcast: 0.675606 val loss: 0.274693
[Epoch 79] ogbg-moltoxcast: 0.647245 test loss: 0.331184
[Epoch 80; Iter    29/  229] train: loss: 0.1129396
[Epoch 80; Iter    59/  229] train: loss: 0.1119050
[Epoch 80; Iter    89/  229] train: loss: 0.1321395
[Epoch 80; Iter   119/  229] train: loss: 0.1140672
[Epoch 80; Iter   149/  229] train: loss: 0.1251972
[Epoch 80; Iter   179/  229] train: loss: 0.1245987
[Epoch 80; Iter   209/  229] train: loss: 0.1338363
[Epoch 80] ogbg-moltoxcast: 0.680542 val loss: 0.268853
[Epoch 80] ogbg-moltoxcast: 0.652345 test loss: 0.322547
[Epoch 81; Iter    10/  229] train: loss: 0.1279725
[Epoch 81; Iter    40/  229] train: loss: 0.1394478
[Epoch 81; Iter    70/  229] train: loss: 0.1345273
[Epoch 81; Iter   100/  229] train: loss: 0.1400827
[Epoch 81; Iter   130/  229] train: loss: 0.1488638
[Epoch 81; Iter   160/  229] train: loss: 0.1461283
[Epoch 81; Iter   190/  229] train: loss: 0.1368959
[Epoch 81; Iter   220/  229] train: loss: 0.1077044
[Epoch 81] ogbg-moltoxcast: 0.679927 val loss: 0.272395
[Epoch 81] ogbg-moltoxcast: 0.654265 test loss: 0.322861
[Epoch 82; Iter    21/  229] train: loss: 0.0905062
[Epoch 82; Iter    51/  229] train: loss: 0.1303954
[Epoch 82; Iter    81/  229] train: loss: 0.1403043
[Epoch 82; Iter   111/  229] train: loss: 0.1007099
[Epoch 82; Iter   141/  229] train: loss: 0.1024760
[Epoch 82; Iter   171/  229] train: loss: 0.1215543
[Epoch 82; Iter   201/  229] train: loss: 0.1197404
[Epoch 82] ogbg-moltoxcast: 0.676238 val loss: 0.273219
[Epoch 82] ogbg-moltoxcast: 0.649710 test loss: 0.327495
[Epoch 83; Iter     2/  229] train: loss: 0.1782888
[Epoch 83; Iter    32/  229] train: loss: 0.0946526
[Epoch 83; Iter    62/  229] train: loss: 0.1128557
[Epoch 83; Iter    92/  229] train: loss: 0.1360793
[Epoch 83; Iter   122/  229] train: loss: 0.1121998
[Epoch 83; Iter   152/  229] train: loss: 0.1049407
[Epoch 83; Iter   182/  229] train: loss: 0.0870176
[Epoch 83; Iter   212/  229] train: loss: 0.1611674
[Epoch 83] ogbg-moltoxcast: 0.681724 val loss: 0.272158
[Epoch 83] ogbg-moltoxcast: 0.652018 test loss: 0.327460
[Epoch 84; Iter    13/  229] train: loss: 0.1144210
[Epoch 84; Iter    43/  229] train: loss: 0.1148792
[Epoch 84; Iter    73/  229] train: loss: 0.0977819
[Epoch 84; Iter   103/  229] train: loss: 0.1140227
[Epoch 84; Iter   133/  229] train: loss: 0.0770107
[Epoch 84; Iter   163/  229] train: loss: 0.1140648
[Epoch 84; Iter   193/  229] train: loss: 0.1468832
[Epoch 84; Iter   223/  229] train: loss: 0.1064928
[Epoch 84] ogbg-moltoxcast: 0.676825 val loss: 0.276458
[Epoch 84] ogbg-moltoxcast: 0.654831 test loss: 0.325589
[Epoch 85; Iter    24/  229] train: loss: 0.1305324
[Epoch 85; Iter    54/  229] train: loss: 0.1166155
[Epoch 85; Iter    84/  229] train: loss: 0.1170349
[Epoch 85; Iter   114/  229] train: loss: 0.0925986
[Epoch 85; Iter   144/  229] train: loss: 0.1184323
[Epoch 85; Iter   174/  229] train: loss: 0.1693849
[Epoch 85; Iter   204/  229] train: loss: 0.1437136
[Epoch 85] ogbg-moltoxcast: 0.673991 val loss: 0.274568
[Epoch 85] ogbg-moltoxcast: 0.646673 test loss: 0.329811
[Epoch 86; Iter     5/  229] train: loss: 0.1086740
[Epoch 86; Iter    35/  229] train: loss: 0.1331170
[Epoch 86; Iter    65/  229] train: loss: 0.0781709
[Epoch 86; Iter    95/  229] train: loss: 0.1407747
[Epoch 86; Iter   125/  229] train: loss: 0.0833792
[Epoch 86; Iter   155/  229] train: loss: 0.1247793
[Epoch 86; Iter   185/  229] train: loss: 0.1178722
[Epoch 86; Iter   215/  229] train: loss: 0.1529627
[Epoch 86] ogbg-moltoxcast: 0.674177 val loss: 0.274295
[Epoch 86] ogbg-moltoxcast: 0.651588 test loss: 0.329340
[Epoch 87; Iter    16/  229] train: loss: 0.0869194
[Epoch 87; Iter    46/  229] train: loss: 0.1031726
[Epoch 87; Iter    76/  229] train: loss: 0.1340073
[Epoch 87; Iter   106/  229] train: loss: 0.1153333
[Epoch 87; Iter   136/  229] train: loss: 0.1859045
[Epoch 87; Iter   166/  229] train: loss: 0.1116052
[Epoch 87; Iter   196/  229] train: loss: 0.1219653
[Epoch 87; Iter   226/  229] train: loss: 0.0961392
[Epoch 87] ogbg-moltoxcast: 0.680464 val loss: 0.275305
[Epoch 87] ogbg-moltoxcast: 0.646318 test loss: 0.333262
[Epoch 88; Iter    27/  229] train: loss: 0.1316994
[Epoch 88; Iter    57/  229] train: loss: 0.1189736
[Epoch 88; Iter    87/  229] train: loss: 0.1196243
[Epoch 88; Iter   117/  229] train: loss: 0.1503918
[Epoch 88; Iter   147/  229] train: loss: 0.1257997
[Epoch 88; Iter   177/  229] train: loss: 0.1305791
[Epoch 88; Iter   207/  229] train: loss: 0.0952406
[Epoch 88] ogbg-moltoxcast: 0.680733 val loss: 0.272137
[Epoch 88] ogbg-moltoxcast: 0.651164 test loss: 0.326785
[Epoch 89; Iter     8/  229] train: loss: 0.1288529
[Epoch 89; Iter    38/  229] train: loss: 0.1464738
[Epoch 89; Iter    68/  229] train: loss: 0.1509837
[Epoch 89; Iter    98/  229] train: loss: 0.1076823
[Epoch 89; Iter   128/  229] train: loss: 0.1050572
[Epoch 89; Iter   158/  229] train: loss: 0.1082092
[Epoch 89; Iter   188/  229] train: loss: 0.0958544
[Epoch 89; Iter   218/  229] train: loss: 0.1430730
[Epoch 89] ogbg-moltoxcast: 0.682168 val loss: 0.273404
[Epoch 89] ogbg-moltoxcast: 0.652238 test loss: 0.327865
[Epoch 90; Iter    19/  229] train: loss: 0.1232965
[Epoch 90; Iter    49/  229] train: loss: 0.1157584
[Epoch 90; Iter    79/  229] train: loss: 0.1028298
[Epoch 90; Iter   109/  229] train: loss: 0.0868232
[Epoch 90; Iter   139/  229] train: loss: 0.0912908
[Epoch 90; Iter   169/  229] train: loss: 0.1152942
[Epoch 90; Iter   199/  229] train: loss: 0.1747612
[Epoch 90; Iter   229/  229] train: loss: 0.1323428
[Epoch 90] ogbg-moltoxcast: 0.676071 val loss: 0.276523
[Epoch 90] ogbg-moltoxcast: 0.651215 test loss: 0.330266
[Epoch 91; Iter    30/  229] train: loss: 0.1206705
[Epoch 91; Iter    60/  229] train: loss: 0.1470986
[Epoch 91; Iter    90/  229] train: loss: 0.1415262
[Epoch 91; Iter   120/  229] train: loss: 0.1152016
[Epoch 91; Iter   150/  229] train: loss: 0.1585384
[Epoch 91; Iter   180/  229] train: loss: 0.1747189
[Epoch 91; Iter   210/  229] train: loss: 0.1797763
[Epoch 91] ogbg-moltoxcast: 0.670873 val loss: 0.275664
[Epoch 91] ogbg-moltoxcast: 0.646185 test loss: 0.333897
[Epoch 84; Iter    27/  201] train: loss: 0.0756996
[Epoch 84; Iter    57/  201] train: loss: 0.1543460
[Epoch 84; Iter    87/  201] train: loss: 0.1750150
[Epoch 84; Iter   117/  201] train: loss: 0.1442608
[Epoch 84; Iter   147/  201] train: loss: 0.1403140
[Epoch 84; Iter   177/  201] train: loss: 0.1287569
[Epoch 84] ogbg-moltoxcast: 0.668319 val loss: 0.278087
[Epoch 84] ogbg-moltoxcast: 0.659946 test loss: 0.318532
[Epoch 85; Iter     6/  201] train: loss: 0.1615628
[Epoch 85; Iter    36/  201] train: loss: 0.0898023
[Epoch 85; Iter    66/  201] train: loss: 0.1396966
[Epoch 85; Iter    96/  201] train: loss: 0.1202443
[Epoch 85; Iter   126/  201] train: loss: 0.1208108
[Epoch 85; Iter   156/  201] train: loss: 0.1503363
[Epoch 85; Iter   186/  201] train: loss: 0.1482012
[Epoch 85] ogbg-moltoxcast: 0.667126 val loss: 0.278564
[Epoch 85] ogbg-moltoxcast: 0.657950 test loss: 0.320344
[Epoch 86; Iter    15/  201] train: loss: 0.1001066
[Epoch 86; Iter    45/  201] train: loss: 0.1620800
[Epoch 86; Iter    75/  201] train: loss: 0.0993908
[Epoch 86; Iter   105/  201] train: loss: 0.1348333
[Epoch 86; Iter   135/  201] train: loss: 0.1556454
[Epoch 86; Iter   165/  201] train: loss: 0.1140393
[Epoch 86; Iter   195/  201] train: loss: 0.1288272
[Epoch 86] ogbg-moltoxcast: 0.672736 val loss: 0.278478
[Epoch 86] ogbg-moltoxcast: 0.658298 test loss: 0.321301
[Epoch 87; Iter    24/  201] train: loss: 0.1141296
[Epoch 87; Iter    54/  201] train: loss: 0.1408347
[Epoch 87; Iter    84/  201] train: loss: 0.1230174
[Epoch 87; Iter   114/  201] train: loss: 0.1234509
[Epoch 87; Iter   144/  201] train: loss: 0.1124497
[Epoch 87; Iter   174/  201] train: loss: 0.1169470
[Epoch 87] ogbg-moltoxcast: 0.670668 val loss: 0.278301
[Epoch 87] ogbg-moltoxcast: 0.658238 test loss: 0.320806
[Epoch 88; Iter     3/  201] train: loss: 0.0850892
[Epoch 88; Iter    33/  201] train: loss: 0.1351929
[Epoch 88; Iter    63/  201] train: loss: 0.1204493
[Epoch 88; Iter    93/  201] train: loss: 0.1206004
[Epoch 88; Iter   123/  201] train: loss: 0.1184461
[Epoch 88; Iter   153/  201] train: loss: 0.1139005
[Epoch 88; Iter   183/  201] train: loss: 0.1291806
[Epoch 88] ogbg-moltoxcast: 0.665236 val loss: 0.278487
[Epoch 88] ogbg-moltoxcast: 0.654190 test loss: 0.319205
[Epoch 89; Iter    12/  201] train: loss: 0.0951376
[Epoch 89; Iter    42/  201] train: loss: 0.1306168
[Epoch 89; Iter    72/  201] train: loss: 0.1122678
[Epoch 89; Iter   102/  201] train: loss: 0.0894311
[Epoch 89; Iter   132/  201] train: loss: 0.0773668
[Epoch 89; Iter   162/  201] train: loss: 0.1564904
[Epoch 89; Iter   192/  201] train: loss: 0.1085945
[Epoch 89] ogbg-moltoxcast: 0.665170 val loss: 0.278875
[Epoch 89] ogbg-moltoxcast: 0.656182 test loss: 0.318917
[Epoch 90; Iter    21/  201] train: loss: 0.1340056
[Epoch 90; Iter    51/  201] train: loss: 0.1205335
[Epoch 90; Iter    81/  201] train: loss: 0.1114121
[Epoch 90; Iter   111/  201] train: loss: 0.1337734
[Epoch 90; Iter   141/  201] train: loss: 0.1324648
[Epoch 90; Iter   171/  201] train: loss: 0.0910978
[Epoch 90; Iter   201/  201] train: loss: 0.0501514
[Epoch 90] ogbg-moltoxcast: 0.663876 val loss: 0.283076
[Epoch 90] ogbg-moltoxcast: 0.662270 test loss: 0.321030
[Epoch 91; Iter    30/  201] train: loss: 0.1449162
[Epoch 91; Iter    60/  201] train: loss: 0.1095978
[Epoch 91; Iter    90/  201] train: loss: 0.1091471
[Epoch 91; Iter   120/  201] train: loss: 0.1119009
[Epoch 91; Iter   150/  201] train: loss: 0.0794874
[Epoch 91; Iter   180/  201] train: loss: 0.1526641
[Epoch 91] ogbg-moltoxcast: 0.664664 val loss: 0.279584
[Epoch 91] ogbg-moltoxcast: 0.658466 test loss: 0.319287
[Epoch 92; Iter     9/  201] train: loss: 0.0752942
[Epoch 92; Iter    39/  201] train: loss: 0.1087203
[Epoch 92; Iter    69/  201] train: loss: 0.1193056
[Epoch 92; Iter    99/  201] train: loss: 0.1176692
[Epoch 92; Iter   129/  201] train: loss: 0.1321066
[Epoch 92; Iter   159/  201] train: loss: 0.1059215
[Epoch 92; Iter   189/  201] train: loss: 0.1672288
[Epoch 92] ogbg-moltoxcast: 0.664130 val loss: 0.284611
[Epoch 92] ogbg-moltoxcast: 0.657055 test loss: 0.326723
[Epoch 93; Iter    18/  201] train: loss: 0.0842241
[Epoch 93; Iter    48/  201] train: loss: 0.1254077
[Epoch 93; Iter    78/  201] train: loss: 0.1182583
[Epoch 93; Iter   108/  201] train: loss: 0.0989531
[Epoch 93; Iter   138/  201] train: loss: 0.1159506
[Epoch 93; Iter   168/  201] train: loss: 0.1201768
[Epoch 93; Iter   198/  201] train: loss: 0.0994869
[Epoch 93] ogbg-moltoxcast: 0.666096 val loss: 0.287710
[Epoch 93] ogbg-moltoxcast: 0.657065 test loss: 0.330238
[Epoch 94; Iter    27/  201] train: loss: 0.1358776
[Epoch 94; Iter    57/  201] train: loss: 0.1086933
[Epoch 94; Iter    87/  201] train: loss: 0.1493231
[Epoch 94; Iter   117/  201] train: loss: 0.1102980
[Epoch 94; Iter   147/  201] train: loss: 0.1307293
[Epoch 94; Iter   177/  201] train: loss: 0.1161572
[Epoch 94] ogbg-moltoxcast: 0.664626 val loss: 0.281270
[Epoch 94] ogbg-moltoxcast: 0.653901 test loss: 0.323643
[Epoch 95; Iter     6/  201] train: loss: 0.1183185
[Epoch 95; Iter    36/  201] train: loss: 0.1158295
[Epoch 95; Iter    66/  201] train: loss: 0.1086556
[Epoch 95; Iter    96/  201] train: loss: 0.1249109
[Epoch 95; Iter   126/  201] train: loss: 0.0956446
[Epoch 95; Iter   156/  201] train: loss: 0.1204801
[Epoch 95; Iter   186/  201] train: loss: 0.1544244
[Epoch 95] ogbg-moltoxcast: 0.664820 val loss: 0.284524
[Epoch 95] ogbg-moltoxcast: 0.655881 test loss: 0.325390
[Epoch 96; Iter    15/  201] train: loss: 0.1765143
[Epoch 96; Iter    45/  201] train: loss: 0.0971749
[Epoch 96; Iter    75/  201] train: loss: 0.1454836
[Epoch 96; Iter   105/  201] train: loss: 0.0971221
[Epoch 96; Iter   135/  201] train: loss: 0.1340203
[Epoch 96; Iter   165/  201] train: loss: 0.1175454
[Epoch 96; Iter   195/  201] train: loss: 0.1102277
[Epoch 96] ogbg-moltoxcast: 0.662045 val loss: 0.280112
[Epoch 96] ogbg-moltoxcast: 0.653611 test loss: 0.319774
[Epoch 97; Iter    24/  201] train: loss: 0.1278174
[Epoch 97; Iter    54/  201] train: loss: 0.1514143
[Epoch 97; Iter    84/  201] train: loss: 0.1822246
[Epoch 97; Iter   114/  201] train: loss: 0.1157750
[Epoch 97; Iter   144/  201] train: loss: 0.1148501
[Epoch 97; Iter   174/  201] train: loss: 0.0884845
[Epoch 97] ogbg-moltoxcast: 0.660615 val loss: 0.285077
[Epoch 97] ogbg-moltoxcast: 0.653639 test loss: 0.327384
[Epoch 98; Iter     3/  201] train: loss: 0.0982786
[Epoch 98; Iter    33/  201] train: loss: 0.1201654
[Epoch 98; Iter    63/  201] train: loss: 0.0937398
[Epoch 98; Iter    93/  201] train: loss: 0.1223475
[Epoch 98; Iter   123/  201] train: loss: 0.1205717
[Epoch 98; Iter   153/  201] train: loss: 0.0900197
[Epoch 98; Iter   183/  201] train: loss: 0.1269492
[Epoch 98] ogbg-moltoxcast: 0.663318 val loss: 0.278358
[Epoch 98] ogbg-moltoxcast: 0.653237 test loss: 0.317335
[Epoch 99; Iter    12/  201] train: loss: 0.1655945
[Epoch 99; Iter    42/  201] train: loss: 0.1526850
[Epoch 99; Iter    72/  201] train: loss: 0.1595824
[Epoch 99; Iter   102/  201] train: loss: 0.1238052
[Epoch 99; Iter   132/  201] train: loss: 0.1379672
[Epoch 99; Iter   162/  201] train: loss: 0.0895246
[Epoch 99; Iter   192/  201] train: loss: 0.1185526
[Epoch 99] ogbg-moltoxcast: 0.666202 val loss: 0.276798
[Epoch 99] ogbg-moltoxcast: 0.654441 test loss: 0.319113
[Epoch 100; Iter    21/  201] train: loss: 0.1175487
[Epoch 100; Iter    51/  201] train: loss: 0.1290049
[Epoch 100; Iter    81/  201] train: loss: 0.0978905
[Epoch 100; Iter   111/  201] train: loss: 0.1407716
[Epoch 100; Iter   141/  201] train: loss: 0.1254129
[Epoch 100; Iter   171/  201] train: loss: 0.1113715
[Epoch 100; Iter   201/  201] train: loss: 0.1883139
[Epoch 100] ogbg-moltoxcast: 0.664271 val loss: 0.280664
[Epoch 100] ogbg-moltoxcast: 0.654823 test loss: 0.320570
[Epoch 101; Iter    30/  201] train: loss: 0.0801317
[Epoch 101; Iter    60/  201] train: loss: 0.1317483
[Epoch 101; Iter    90/  201] train: loss: 0.1058153
[Epoch 101; Iter   120/  201] train: loss: 0.0997330
[Epoch 101; Iter   150/  201] train: loss: 0.0868058
[Epoch 101; Iter   180/  201] train: loss: 0.1045156
[Epoch 84; Iter    27/  201] train: loss: 0.0979275
[Epoch 84; Iter    57/  201] train: loss: 0.0952543
[Epoch 84; Iter    87/  201] train: loss: 0.0912742
[Epoch 84; Iter   117/  201] train: loss: 0.0915372
[Epoch 84; Iter   147/  201] train: loss: 0.1175340
[Epoch 84; Iter   177/  201] train: loss: 0.1189943
[Epoch 84] ogbg-moltoxcast: 0.685828 val loss: 0.271223
[Epoch 84] ogbg-moltoxcast: 0.664627 test loss: 0.317098
[Epoch 85; Iter     6/  201] train: loss: 0.0744958
[Epoch 85; Iter    36/  201] train: loss: 0.1737444
[Epoch 85; Iter    66/  201] train: loss: 0.0939847
[Epoch 85; Iter    96/  201] train: loss: 0.0915750
[Epoch 85; Iter   126/  201] train: loss: 0.1611524
[Epoch 85; Iter   156/  201] train: loss: 0.0985942
[Epoch 85; Iter   186/  201] train: loss: 0.1415960
[Epoch 85] ogbg-moltoxcast: 0.682330 val loss: 0.278592
[Epoch 85] ogbg-moltoxcast: 0.660963 test loss: 0.323532
[Epoch 86; Iter    15/  201] train: loss: 0.1748524
[Epoch 86; Iter    45/  201] train: loss: 0.0842803
[Epoch 86; Iter    75/  201] train: loss: 0.1061356
[Epoch 86; Iter   105/  201] train: loss: 0.1200399
[Epoch 86; Iter   135/  201] train: loss: 0.1740165
[Epoch 86; Iter   165/  201] train: loss: 0.1389759
[Epoch 86; Iter   195/  201] train: loss: 0.1251225
[Epoch 86] ogbg-moltoxcast: 0.682438 val loss: 0.271271
[Epoch 86] ogbg-moltoxcast: 0.659245 test loss: 0.315068
[Epoch 87; Iter    24/  201] train: loss: 0.1488836
[Epoch 87; Iter    54/  201] train: loss: 0.1616973
[Epoch 87; Iter    84/  201] train: loss: 0.1302795
[Epoch 87; Iter   114/  201] train: loss: 0.1332946
[Epoch 87; Iter   144/  201] train: loss: 0.1833502
[Epoch 87; Iter   174/  201] train: loss: 0.1185370
[Epoch 87] ogbg-moltoxcast: 0.680037 val loss: 0.279488
[Epoch 87] ogbg-moltoxcast: 0.657123 test loss: 0.328671
[Epoch 88; Iter     3/  201] train: loss: 0.1084819
[Epoch 88; Iter    33/  201] train: loss: 0.1077412
[Epoch 88; Iter    63/  201] train: loss: 0.1220389
[Epoch 88; Iter    93/  201] train: loss: 0.1122465
[Epoch 88; Iter   123/  201] train: loss: 0.1236229
[Epoch 88; Iter   153/  201] train: loss: 0.0883273
[Epoch 88; Iter   183/  201] train: loss: 0.1150161
[Epoch 88] ogbg-moltoxcast: 0.681730 val loss: 0.278397
[Epoch 88] ogbg-moltoxcast: 0.658619 test loss: 0.321720
[Epoch 89; Iter    12/  201] train: loss: 0.1051990
[Epoch 89; Iter    42/  201] train: loss: 0.1196338
[Epoch 89; Iter    72/  201] train: loss: 0.0802807
[Epoch 89; Iter   102/  201] train: loss: 0.1307032
[Epoch 89; Iter   132/  201] train: loss: 0.1087671
[Epoch 89; Iter   162/  201] train: loss: 0.1078111
[Epoch 89; Iter   192/  201] train: loss: 0.1055994
[Epoch 89] ogbg-moltoxcast: 0.681896 val loss: 0.277902
[Epoch 89] ogbg-moltoxcast: 0.658951 test loss: 0.321503
[Epoch 90; Iter    21/  201] train: loss: 0.1593337
[Epoch 90; Iter    51/  201] train: loss: 0.1158204
[Epoch 90; Iter    81/  201] train: loss: 0.1529946
[Epoch 90; Iter   111/  201] train: loss: 0.1243382
[Epoch 90; Iter   141/  201] train: loss: 0.1346366
[Epoch 90; Iter   171/  201] train: loss: 0.1164969
[Epoch 90; Iter   201/  201] train: loss: 0.0607131
[Epoch 90] ogbg-moltoxcast: 0.684999 val loss: 0.280340
[Epoch 90] ogbg-moltoxcast: 0.663547 test loss: 0.326672
[Epoch 91; Iter    30/  201] train: loss: 0.1187126
[Epoch 91; Iter    60/  201] train: loss: 0.1042735
[Epoch 91; Iter    90/  201] train: loss: 0.1415914
[Epoch 91; Iter   120/  201] train: loss: 0.0936685
[Epoch 91; Iter   150/  201] train: loss: 0.1176649
[Epoch 91; Iter   180/  201] train: loss: 0.1215595
[Epoch 91] ogbg-moltoxcast: 0.678752 val loss: 0.281673
[Epoch 91] ogbg-moltoxcast: 0.660772 test loss: 0.324004
[Epoch 92; Iter     9/  201] train: loss: 0.1486423
[Epoch 92; Iter    39/  201] train: loss: 0.1432219
[Epoch 92; Iter    69/  201] train: loss: 0.1035868
[Epoch 92; Iter    99/  201] train: loss: 0.1945008
[Epoch 92; Iter   129/  201] train: loss: 0.1512747
[Epoch 92; Iter   159/  201] train: loss: 0.0823288
[Epoch 92; Iter   189/  201] train: loss: 0.1634118
[Epoch 92] ogbg-moltoxcast: 0.679271 val loss: 0.276676
[Epoch 92] ogbg-moltoxcast: 0.657525 test loss: 0.322821
[Epoch 93; Iter    18/  201] train: loss: 0.1128008
[Epoch 93; Iter    48/  201] train: loss: 0.1277951
[Epoch 93; Iter    78/  201] train: loss: 0.1031212
[Epoch 93; Iter   108/  201] train: loss: 0.1537654
[Epoch 93; Iter   138/  201] train: loss: 0.0950938
[Epoch 93; Iter   168/  201] train: loss: 0.1227275
[Epoch 93; Iter   198/  201] train: loss: 0.1159673
[Epoch 93] ogbg-moltoxcast: 0.683477 val loss: 0.277168
[Epoch 93] ogbg-moltoxcast: 0.663020 test loss: 0.326545
[Epoch 94; Iter    27/  201] train: loss: 0.1161424
[Epoch 94; Iter    57/  201] train: loss: 0.0893260
[Epoch 94; Iter    87/  201] train: loss: 0.1340731
[Epoch 94; Iter   117/  201] train: loss: 0.1489024
[Epoch 94; Iter   147/  201] train: loss: 0.1271740
[Epoch 94; Iter   177/  201] train: loss: 0.0758683
[Epoch 94] ogbg-moltoxcast: 0.682632 val loss: 0.275018
[Epoch 94] ogbg-moltoxcast: 0.658935 test loss: 0.323399
[Epoch 95; Iter     6/  201] train: loss: 0.0998207
[Epoch 95; Iter    36/  201] train: loss: 0.1398545
[Epoch 95; Iter    66/  201] train: loss: 0.0910117
[Epoch 95; Iter    96/  201] train: loss: 0.1538827
[Epoch 95; Iter   126/  201] train: loss: 0.1071472
[Epoch 95; Iter   156/  201] train: loss: 0.1367971
[Epoch 95; Iter   186/  201] train: loss: 0.1128138
[Epoch 95] ogbg-moltoxcast: 0.681051 val loss: 0.279105
[Epoch 95] ogbg-moltoxcast: 0.659551 test loss: 0.325849
[Epoch 96; Iter    15/  201] train: loss: 0.1354285
[Epoch 96; Iter    45/  201] train: loss: 0.1019025
[Epoch 96; Iter    75/  201] train: loss: 0.1387622
[Epoch 96; Iter   105/  201] train: loss: 0.1160218
[Epoch 96; Iter   135/  201] train: loss: 0.0875731
[Epoch 96; Iter   165/  201] train: loss: 0.1406230
[Epoch 96; Iter   195/  201] train: loss: 0.1455331
[Epoch 96] ogbg-moltoxcast: 0.679694 val loss: 0.275787
[Epoch 96] ogbg-moltoxcast: 0.656768 test loss: 0.323338
[Epoch 97; Iter    24/  201] train: loss: 0.1329637
[Epoch 97; Iter    54/  201] train: loss: 0.1352712
[Epoch 97; Iter    84/  201] train: loss: 0.1202846
[Epoch 97; Iter   114/  201] train: loss: 0.1015373
[Epoch 97; Iter   144/  201] train: loss: 0.1078866
[Epoch 97; Iter   174/  201] train: loss: 0.1269949
[Epoch 97] ogbg-moltoxcast: 0.680754 val loss: 0.279270
[Epoch 97] ogbg-moltoxcast: 0.662783 test loss: 0.325890
[Epoch 98; Iter     3/  201] train: loss: 0.1241115
[Epoch 98; Iter    33/  201] train: loss: 0.0746361
[Epoch 98; Iter    63/  201] train: loss: 0.0841922
[Epoch 98; Iter    93/  201] train: loss: 0.1257118
[Epoch 98; Iter   123/  201] train: loss: 0.1384069
[Epoch 98; Iter   153/  201] train: loss: 0.1282177
[Epoch 98; Iter   183/  201] train: loss: 0.1026205
[Epoch 98] ogbg-moltoxcast: 0.680077 val loss: 0.280213
[Epoch 98] ogbg-moltoxcast: 0.663600 test loss: 0.323943
[Epoch 99; Iter    12/  201] train: loss: 0.0989938
[Epoch 99; Iter    42/  201] train: loss: 0.1190034
[Epoch 99; Iter    72/  201] train: loss: 0.1278443
[Epoch 99; Iter   102/  201] train: loss: 0.1177940
[Epoch 99; Iter   132/  201] train: loss: 0.1302099
[Epoch 99; Iter   162/  201] train: loss: 0.1567331
[Epoch 99; Iter   192/  201] train: loss: 0.0923497
[Epoch 99] ogbg-moltoxcast: 0.679324 val loss: 0.280191
[Epoch 99] ogbg-moltoxcast: 0.660753 test loss: 0.324547
[Epoch 100; Iter    21/  201] train: loss: 0.1087842
[Epoch 100; Iter    51/  201] train: loss: 0.1412365
[Epoch 100; Iter    81/  201] train: loss: 0.0509208
[Epoch 100; Iter   111/  201] train: loss: 0.1143527
[Epoch 100; Iter   141/  201] train: loss: 0.0952388
[Epoch 100; Iter   171/  201] train: loss: 0.0838874
[Epoch 100; Iter   201/  201] train: loss: 0.2084233
[Epoch 100] ogbg-moltoxcast: 0.683199 val loss: 0.284715
[Epoch 100] ogbg-moltoxcast: 0.663117 test loss: 0.333634
[Epoch 101; Iter    30/  201] train: loss: 0.0890368
[Epoch 101; Iter    60/  201] train: loss: 0.0963766
[Epoch 101; Iter    90/  201] train: loss: 0.1531164
[Epoch 101; Iter   120/  201] train: loss: 0.1785638
[Epoch 101; Iter   150/  201] train: loss: 0.1282402
[Epoch 101; Iter   180/  201] train: loss: 0.1239972
[Epoch 84; Iter    27/  201] train: loss: 0.1322257
[Epoch 84; Iter    57/  201] train: loss: 0.1177427
[Epoch 84; Iter    87/  201] train: loss: 0.1225177
[Epoch 84; Iter   117/  201] train: loss: 0.1812384
[Epoch 84; Iter   147/  201] train: loss: 0.0924563
[Epoch 84; Iter   177/  201] train: loss: 0.1319383
[Epoch 84] ogbg-moltoxcast: 0.659548 val loss: 0.289711
[Epoch 84] ogbg-moltoxcast: 0.656866 test loss: 0.339866
[Epoch 85; Iter     6/  201] train: loss: 0.1239159
[Epoch 85; Iter    36/  201] train: loss: 0.1469202
[Epoch 85; Iter    66/  201] train: loss: 0.1242911
[Epoch 85; Iter    96/  201] train: loss: 0.1151621
[Epoch 85; Iter   126/  201] train: loss: 0.1283667
[Epoch 85; Iter   156/  201] train: loss: 0.0933967
[Epoch 85; Iter   186/  201] train: loss: 0.1211452
[Epoch 85] ogbg-moltoxcast: 0.664600 val loss: 0.282348
[Epoch 85] ogbg-moltoxcast: 0.658571 test loss: 0.332317
[Epoch 86; Iter    15/  201] train: loss: 0.0969033
[Epoch 86; Iter    45/  201] train: loss: 0.1264317
[Epoch 86; Iter    75/  201] train: loss: 0.0805059
[Epoch 86; Iter   105/  201] train: loss: 0.1211092
[Epoch 86; Iter   135/  201] train: loss: 0.1861514
[Epoch 86; Iter   165/  201] train: loss: 0.0893156
[Epoch 86; Iter   195/  201] train: loss: 0.0809571
[Epoch 86] ogbg-moltoxcast: 0.670264 val loss: 0.282281
[Epoch 86] ogbg-moltoxcast: 0.662811 test loss: 0.333490
[Epoch 87; Iter    24/  201] train: loss: 0.1004190
[Epoch 87; Iter    54/  201] train: loss: 0.1191865
[Epoch 87; Iter    84/  201] train: loss: 0.1498165
[Epoch 87; Iter   114/  201] train: loss: 0.1575697
[Epoch 87; Iter   144/  201] train: loss: 0.0986200
[Epoch 87; Iter   174/  201] train: loss: 0.0823293
[Epoch 87] ogbg-moltoxcast: 0.658037 val loss: 0.287522
[Epoch 87] ogbg-moltoxcast: 0.650540 test loss: 0.341137
[Epoch 88; Iter     3/  201] train: loss: 0.0996054
[Epoch 88; Iter    33/  201] train: loss: 0.1224815
[Epoch 88; Iter    63/  201] train: loss: 0.1241754
[Epoch 88; Iter    93/  201] train: loss: 0.1084710
[Epoch 88; Iter   123/  201] train: loss: 0.1164064
[Epoch 88; Iter   153/  201] train: loss: 0.1103541
[Epoch 88; Iter   183/  201] train: loss: 0.1111132
[Epoch 88] ogbg-moltoxcast: 0.667885 val loss: 0.284103
[Epoch 88] ogbg-moltoxcast: 0.658225 test loss: 0.335907
[Epoch 89; Iter    12/  201] train: loss: 0.1278492
[Epoch 89; Iter    42/  201] train: loss: 0.1351844
[Epoch 89; Iter    72/  201] train: loss: 0.1539491
[Epoch 89; Iter   102/  201] train: loss: 0.1301956
[Epoch 89; Iter   132/  201] train: loss: 0.1502298
[Epoch 89; Iter   162/  201] train: loss: 0.1175938
[Epoch 89; Iter   192/  201] train: loss: 0.1022524
[Epoch 89] ogbg-moltoxcast: 0.666057 val loss: 0.283073
[Epoch 89] ogbg-moltoxcast: 0.653901 test loss: 0.338584
[Epoch 90; Iter    21/  201] train: loss: 0.1643689
[Epoch 90; Iter    51/  201] train: loss: 0.0876179
[Epoch 90; Iter    81/  201] train: loss: 0.1034197
[Epoch 90; Iter   111/  201] train: loss: 0.1409272
[Epoch 90; Iter   141/  201] train: loss: 0.1332197
[Epoch 90; Iter   171/  201] train: loss: 0.1363686
[Epoch 90; Iter   201/  201] train: loss: 0.0414407
[Epoch 90] ogbg-moltoxcast: 0.667831 val loss: 0.279623
[Epoch 90] ogbg-moltoxcast: 0.657268 test loss: 0.330298
[Epoch 91; Iter    30/  201] train: loss: 0.1243663
[Epoch 91; Iter    60/  201] train: loss: 0.1018757
[Epoch 91; Iter    90/  201] train: loss: 0.1106284
[Epoch 91; Iter   120/  201] train: loss: 0.1064860
[Epoch 91; Iter   150/  201] train: loss: 0.1304826
[Epoch 91; Iter   180/  201] train: loss: 0.1026780
[Epoch 91] ogbg-moltoxcast: 0.667687 val loss: 0.285756
[Epoch 91] ogbg-moltoxcast: 0.657967 test loss: 0.337609
[Epoch 92; Iter     9/  201] train: loss: 0.1203736
[Epoch 92; Iter    39/  201] train: loss: 0.0642946
[Epoch 92; Iter    69/  201] train: loss: 0.1392100
[Epoch 92; Iter    99/  201] train: loss: 0.0773126
[Epoch 92; Iter   129/  201] train: loss: 0.1529626
[Epoch 92; Iter   159/  201] train: loss: 0.1357014
[Epoch 92; Iter   189/  201] train: loss: 0.1488529
[Epoch 92] ogbg-moltoxcast: 0.665615 val loss: 0.284196
[Epoch 92] ogbg-moltoxcast: 0.653605 test loss: 0.337973
[Epoch 93; Iter    18/  201] train: loss: 0.1304463
[Epoch 93; Iter    48/  201] train: loss: 0.1320930
[Epoch 93; Iter    78/  201] train: loss: 0.0900216
[Epoch 93; Iter   108/  201] train: loss: 0.1319007
[Epoch 93; Iter   138/  201] train: loss: 0.1416851
[Epoch 93; Iter   168/  201] train: loss: 0.1039810
[Epoch 93; Iter   198/  201] train: loss: 0.1137909
[Epoch 93] ogbg-moltoxcast: 0.666951 val loss: 0.280902
[Epoch 93] ogbg-moltoxcast: 0.657532 test loss: 0.330916
[Epoch 94; Iter    27/  201] train: loss: 0.1321570
[Epoch 94; Iter    57/  201] train: loss: 0.1074656
[Epoch 94; Iter    87/  201] train: loss: 0.1039020
[Epoch 94; Iter   117/  201] train: loss: 0.1206402
[Epoch 94; Iter   147/  201] train: loss: 0.1365827
[Epoch 94; Iter   177/  201] train: loss: 0.1474055
[Epoch 94] ogbg-moltoxcast: 0.662150 val loss: 0.287747
[Epoch 94] ogbg-moltoxcast: 0.656944 test loss: 0.340857
[Epoch 95; Iter     6/  201] train: loss: 0.1097757
[Epoch 95; Iter    36/  201] train: loss: 0.1259798
[Epoch 95; Iter    66/  201] train: loss: 0.1152183
[Epoch 95; Iter    96/  201] train: loss: 0.1598041
[Epoch 95; Iter   126/  201] train: loss: 0.1198233
[Epoch 95; Iter   156/  201] train: loss: 0.1216557
[Epoch 95; Iter   186/  201] train: loss: 0.1319640
[Epoch 95] ogbg-moltoxcast: 0.667009 val loss: 0.285596
[Epoch 95] ogbg-moltoxcast: 0.656368 test loss: 0.338711
[Epoch 96; Iter    15/  201] train: loss: 0.1302898
[Epoch 96; Iter    45/  201] train: loss: 0.1718143
[Epoch 96; Iter    75/  201] train: loss: 0.0958718
[Epoch 96; Iter   105/  201] train: loss: 0.1187131
[Epoch 96; Iter   135/  201] train: loss: 0.1276048
[Epoch 96; Iter   165/  201] train: loss: 0.1403027
[Epoch 96; Iter   195/  201] train: loss: 0.0911399
[Epoch 96] ogbg-moltoxcast: 0.661469 val loss: 0.285751
[Epoch 96] ogbg-moltoxcast: 0.651694 test loss: 0.336754
[Epoch 97; Iter    24/  201] train: loss: 0.1282812
[Epoch 97; Iter    54/  201] train: loss: 0.0985954
[Epoch 97; Iter    84/  201] train: loss: 0.1487948
[Epoch 97; Iter   114/  201] train: loss: 0.1106730
[Epoch 97; Iter   144/  201] train: loss: 0.1124628
[Epoch 97; Iter   174/  201] train: loss: 0.1110208
[Epoch 97] ogbg-moltoxcast: 0.661868 val loss: 0.287614
[Epoch 97] ogbg-moltoxcast: 0.653003 test loss: 0.336156
[Epoch 98; Iter     3/  201] train: loss: 0.1112594
[Epoch 98; Iter    33/  201] train: loss: 0.1158977
[Epoch 98; Iter    63/  201] train: loss: 0.1587796
[Epoch 98; Iter    93/  201] train: loss: 0.1337738
[Epoch 98; Iter   123/  201] train: loss: 0.0795926
[Epoch 98; Iter   153/  201] train: loss: 0.0699316
[Epoch 98; Iter   183/  201] train: loss: 0.0953132
[Epoch 98] ogbg-moltoxcast: 0.667788 val loss: 0.289440
[Epoch 98] ogbg-moltoxcast: 0.656570 test loss: 0.343463
[Epoch 99; Iter    12/  201] train: loss: 0.1214008
[Epoch 99; Iter    42/  201] train: loss: 0.1064844
[Epoch 99; Iter    72/  201] train: loss: 0.1073263
[Epoch 99; Iter   102/  201] train: loss: 0.0852575
[Epoch 99; Iter   132/  201] train: loss: 0.1149872
[Epoch 99; Iter   162/  201] train: loss: 0.0876881
[Epoch 99; Iter   192/  201] train: loss: 0.0822803
[Epoch 99] ogbg-moltoxcast: 0.662328 val loss: 0.287342
[Epoch 99] ogbg-moltoxcast: 0.656310 test loss: 0.335625
[Epoch 100; Iter    21/  201] train: loss: 0.1123556
[Epoch 100; Iter    51/  201] train: loss: 0.1108198
[Epoch 100; Iter    81/  201] train: loss: 0.0991524
[Epoch 100; Iter   111/  201] train: loss: 0.1323060
[Epoch 100; Iter   141/  201] train: loss: 0.0882972
[Epoch 100; Iter   171/  201] train: loss: 0.1561879
[Epoch 100; Iter   201/  201] train: loss: 0.0509812
[Epoch 100] ogbg-moltoxcast: 0.666555 val loss: 0.282295
[Epoch 100] ogbg-moltoxcast: 0.655706 test loss: 0.334439
[Epoch 101; Iter    30/  201] train: loss: 0.1434039
[Epoch 101; Iter    60/  201] train: loss: 0.0990352
[Epoch 101; Iter    90/  201] train: loss: 0.1040300
[Epoch 101; Iter   120/  201] train: loss: 0.0781161
[Epoch 101; Iter   150/  201] train: loss: 0.1395406
[Epoch 101; Iter   180/  201] train: loss: 0.1120044
[Epoch 94; Iter   114/  172] train: loss: 0.1028119
[Epoch 94; Iter   144/  172] train: loss: 0.0751219
[Epoch 94] ogbg-moltoxcast: 0.646481 val loss: 0.305811
[Epoch 94] ogbg-moltoxcast: 0.609351 test loss: 0.418801
[Epoch 95; Iter     2/  172] train: loss: 0.0948712
[Epoch 95; Iter    32/  172] train: loss: 0.0829968
[Epoch 95; Iter    62/  172] train: loss: 0.1076981
[Epoch 95; Iter    92/  172] train: loss: 0.1682707
[Epoch 95; Iter   122/  172] train: loss: 0.1041804
[Epoch 95; Iter   152/  172] train: loss: 0.0896644
[Epoch 95] ogbg-moltoxcast: 0.644669 val loss: 0.306564
[Epoch 95] ogbg-moltoxcast: 0.614010 test loss: 0.365919
[Epoch 96; Iter    10/  172] train: loss: 0.1257652
[Epoch 96; Iter    40/  172] train: loss: 0.1213949
[Epoch 96; Iter    70/  172] train: loss: 0.1232344
[Epoch 96; Iter   100/  172] train: loss: 0.0903989
[Epoch 96; Iter   130/  172] train: loss: 0.1043744
[Epoch 96; Iter   160/  172] train: loss: 0.1373252
[Epoch 96] ogbg-moltoxcast: 0.642776 val loss: 0.364877
[Epoch 96] ogbg-moltoxcast: 0.606336 test loss: 1.031309
[Epoch 97; Iter    18/  172] train: loss: 0.1558202
[Epoch 97; Iter    48/  172] train: loss: 0.1138560
[Epoch 97; Iter    78/  172] train: loss: 0.1070821
[Epoch 97; Iter   108/  172] train: loss: 0.1269044
[Epoch 97; Iter   138/  172] train: loss: 0.1066210
[Epoch 97; Iter   168/  172] train: loss: 0.1017131
[Epoch 97] ogbg-moltoxcast: 0.645623 val loss: 0.313860
[Epoch 97] ogbg-moltoxcast: 0.607411 test loss: 0.380461
[Epoch 98; Iter    26/  172] train: loss: 0.0813409
[Epoch 98; Iter    56/  172] train: loss: 0.1080479
[Epoch 98; Iter    86/  172] train: loss: 0.1428960
[Epoch 98; Iter   116/  172] train: loss: 0.1162842
[Epoch 98; Iter   146/  172] train: loss: 0.1253353
[Epoch 98] ogbg-moltoxcast: 0.646132 val loss: 0.307571
[Epoch 98] ogbg-moltoxcast: 0.612542 test loss: 0.399284
[Epoch 99; Iter     4/  172] train: loss: 0.0970686
[Epoch 99; Iter    34/  172] train: loss: 0.1139041
[Epoch 99; Iter    64/  172] train: loss: 0.0830328
[Epoch 99; Iter    94/  172] train: loss: 0.1386104
[Epoch 99; Iter   124/  172] train: loss: 0.1321161
[Epoch 99; Iter   154/  172] train: loss: 0.1040977
[Epoch 99] ogbg-moltoxcast: 0.649648 val loss: 0.315742
[Epoch 99] ogbg-moltoxcast: 0.616352 test loss: 0.950435
[Epoch 100; Iter    12/  172] train: loss: 0.1186826
[Epoch 100; Iter    42/  172] train: loss: 0.1109648
[Epoch 100; Iter    72/  172] train: loss: 0.1169890
[Epoch 100; Iter   102/  172] train: loss: 0.1570388
[Epoch 100; Iter   132/  172] train: loss: 0.1099864
[Epoch 100; Iter   162/  172] train: loss: 0.0810615
[Epoch 100] ogbg-moltoxcast: 0.650269 val loss: 0.339797
[Epoch 100] ogbg-moltoxcast: 0.611740 test loss: 1.316909
[Epoch 101; Iter    20/  172] train: loss: 0.1561009
[Epoch 101; Iter    50/  172] train: loss: 0.1474701
[Epoch 101; Iter    80/  172] train: loss: 0.1001369
[Epoch 101; Iter   110/  172] train: loss: 0.1309872
[Epoch 101; Iter   140/  172] train: loss: 0.1063103
[Epoch 101; Iter   170/  172] train: loss: 0.0848489
[Epoch 101] ogbg-moltoxcast: 0.643236 val loss: 0.315933
[Epoch 101] ogbg-moltoxcast: 0.608361 test loss: 0.627196
[Epoch 102; Iter    28/  172] train: loss: 0.1149040
[Epoch 102; Iter    58/  172] train: loss: 0.0853075
[Epoch 102; Iter    88/  172] train: loss: 0.1177583
[Epoch 102; Iter   118/  172] train: loss: 0.1004601
[Epoch 102; Iter   148/  172] train: loss: 0.1176785
[Epoch 102] ogbg-moltoxcast: 0.645232 val loss: 0.324636
[Epoch 102] ogbg-moltoxcast: 0.612914 test loss: 0.422250
[Epoch 103; Iter     6/  172] train: loss: 0.1101751
[Epoch 103; Iter    36/  172] train: loss: 0.1237631
[Epoch 103; Iter    66/  172] train: loss: 0.1418256
[Epoch 103; Iter    96/  172] train: loss: 0.0987468
[Epoch 103; Iter   126/  172] train: loss: 0.1063005
[Epoch 103; Iter   156/  172] train: loss: 0.1486250
[Epoch 103] ogbg-moltoxcast: 0.646032 val loss: 0.313987
[Epoch 103] ogbg-moltoxcast: 0.609920 test loss: 0.378891
[Epoch 104; Iter    14/  172] train: loss: 0.1706713
[Epoch 104; Iter    44/  172] train: loss: 0.0834073
[Epoch 104; Iter    74/  172] train: loss: 0.1428607
[Epoch 104; Iter   104/  172] train: loss: 0.1128836
[Epoch 104; Iter   134/  172] train: loss: 0.1339157
[Epoch 104; Iter   164/  172] train: loss: 0.1241014
[Epoch 104] ogbg-moltoxcast: 0.645202 val loss: 0.318384
[Epoch 104] ogbg-moltoxcast: 0.609190 test loss: 0.417389
[Epoch 105; Iter    22/  172] train: loss: 0.0801440
[Epoch 105; Iter    52/  172] train: loss: 0.0872857
[Epoch 105; Iter    82/  172] train: loss: 0.1106050
[Epoch 105; Iter   112/  172] train: loss: 0.1139813
[Epoch 105; Iter   142/  172] train: loss: 0.1376647
[Epoch 105; Iter   172/  172] train: loss: 0.2171451
[Epoch 105] ogbg-moltoxcast: 0.643845 val loss: 0.320834
[Epoch 105] ogbg-moltoxcast: 0.611113 test loss: 0.452366
[Epoch 106; Iter    30/  172] train: loss: 0.1301780
[Epoch 106; Iter    60/  172] train: loss: 0.1238155
[Epoch 106; Iter    90/  172] train: loss: 0.1078583
[Epoch 106; Iter   120/  172] train: loss: 0.1036157
[Epoch 106; Iter   150/  172] train: loss: 0.0823379
[Epoch 106] ogbg-moltoxcast: 0.643756 val loss: 0.318637
[Epoch 106] ogbg-moltoxcast: 0.609427 test loss: 0.418667
[Epoch 107; Iter     8/  172] train: loss: 0.1052976
[Epoch 107; Iter    38/  172] train: loss: 0.0774074
[Epoch 107; Iter    68/  172] train: loss: 0.0771040
[Epoch 107; Iter    98/  172] train: loss: 0.1333873
[Epoch 107; Iter   128/  172] train: loss: 0.0944502
[Epoch 107; Iter   158/  172] train: loss: 0.1211426
[Epoch 107] ogbg-moltoxcast: 0.644351 val loss: 0.319695
[Epoch 107] ogbg-moltoxcast: 0.610513 test loss: 0.427031
[Epoch 108; Iter    16/  172] train: loss: 0.1419373
[Epoch 108; Iter    46/  172] train: loss: 0.1231316
[Epoch 108; Iter    76/  172] train: loss: 0.1124446
[Epoch 108; Iter   106/  172] train: loss: 0.0921182
[Epoch 108; Iter   136/  172] train: loss: 0.1237424
[Epoch 108; Iter   166/  172] train: loss: 0.1403173
[Epoch 108] ogbg-moltoxcast: 0.647077 val loss: 0.315374
[Epoch 108] ogbg-moltoxcast: 0.610411 test loss: 0.383154
[Epoch 109; Iter    24/  172] train: loss: 0.0945333
[Epoch 109; Iter    54/  172] train: loss: 0.1025784
[Epoch 109; Iter    84/  172] train: loss: 0.0758733
[Epoch 109; Iter   114/  172] train: loss: 0.1208875
[Epoch 109; Iter   144/  172] train: loss: 0.1100830
[Epoch 109] ogbg-moltoxcast: 0.635839 val loss: 0.321813
[Epoch 109] ogbg-moltoxcast: 0.605441 test loss: 0.386811
[Epoch 110; Iter     2/  172] train: loss: 0.1195572
[Epoch 110; Iter    32/  172] train: loss: 0.1152912
[Epoch 110; Iter    62/  172] train: loss: 0.1553815
[Epoch 110; Iter    92/  172] train: loss: 0.1047856
[Epoch 110; Iter   122/  172] train: loss: 0.1241542
[Epoch 110; Iter   152/  172] train: loss: 0.1288033
[Epoch 110] ogbg-moltoxcast: 0.643223 val loss: 0.316902
[Epoch 110] ogbg-moltoxcast: 0.607300 test loss: 0.381569
[Epoch 111; Iter    10/  172] train: loss: 0.1217806
[Epoch 111; Iter    40/  172] train: loss: 0.0736607
[Epoch 111; Iter    70/  172] train: loss: 0.1039076
[Epoch 111; Iter   100/  172] train: loss: 0.1286106
[Epoch 111; Iter   130/  172] train: loss: 0.1008501
[Epoch 111; Iter   160/  172] train: loss: 0.1520102
[Epoch 111] ogbg-moltoxcast: 0.645840 val loss: 0.315642
[Epoch 111] ogbg-moltoxcast: 0.609363 test loss: 0.384119
[Epoch 112; Iter    18/  172] train: loss: 0.1096794
[Epoch 112; Iter    48/  172] train: loss: 0.0858788
[Epoch 112; Iter    78/  172] train: loss: 0.1355031
[Epoch 112; Iter   108/  172] train: loss: 0.1154934
[Epoch 112; Iter   138/  172] train: loss: 0.0900060
[Epoch 112; Iter   168/  172] train: loss: 0.0755466
[Epoch 112] ogbg-moltoxcast: 0.643789 val loss: 0.325437
[Epoch 112] ogbg-moltoxcast: 0.608150 test loss: 0.396860
[Epoch 113; Iter    26/  172] train: loss: 0.1067551
[Epoch 113; Iter    56/  172] train: loss: 0.0988045
[Epoch 113; Iter    86/  172] train: loss: 0.0892871
[Epoch 113; Iter   116/  172] train: loss: 0.0910604
[Epoch 113; Iter   146/  172] train: loss: 0.1076534
[Epoch 113] ogbg-moltoxcast: 0.641454 val loss: 0.319537
[Epoch 113] ogbg-moltoxcast: 0.607632 test loss: 0.385975
[Epoch 114; Iter     4/  172] train: loss: 0.0757090[Epoch 92; Iter    11/  229] train: loss: 0.1187560
[Epoch 92; Iter    41/  229] train: loss: 0.1083223
[Epoch 92; Iter    71/  229] train: loss: 0.1271501
[Epoch 92; Iter   101/  229] train: loss: 0.1049524
[Epoch 92; Iter   131/  229] train: loss: 0.0908673
[Epoch 92; Iter   161/  229] train: loss: 0.0775348
[Epoch 92; Iter   191/  229] train: loss: 0.1054518
[Epoch 92; Iter   221/  229] train: loss: 0.1250457
[Epoch 92] ogbg-moltoxcast: 0.687975 val loss: 0.281624
[Epoch 92] ogbg-moltoxcast: 0.653814 test loss: 0.354392
[Epoch 93; Iter    22/  229] train: loss: 0.0858270
[Epoch 93; Iter    52/  229] train: loss: 0.0764178
[Epoch 93; Iter    82/  229] train: loss: 0.1104727
[Epoch 93; Iter   112/  229] train: loss: 0.1184279
[Epoch 93; Iter   142/  229] train: loss: 0.0947430
[Epoch 93; Iter   172/  229] train: loss: 0.1488714
[Epoch 93; Iter   202/  229] train: loss: 0.1205499
[Epoch 93] ogbg-moltoxcast: 0.689803 val loss: 0.280226
[Epoch 93] ogbg-moltoxcast: 0.650039 test loss: 0.353568
[Epoch 94; Iter     3/  229] train: loss: 0.1801305
[Epoch 94; Iter    33/  229] train: loss: 0.1550138
[Epoch 94; Iter    63/  229] train: loss: 0.1454501
[Epoch 94; Iter    93/  229] train: loss: 0.0816113
[Epoch 94; Iter   123/  229] train: loss: 0.1003719
[Epoch 94; Iter   153/  229] train: loss: 0.1179535
[Epoch 94; Iter   183/  229] train: loss: 0.1263321
[Epoch 94; Iter   213/  229] train: loss: 0.1569184
[Epoch 94] ogbg-moltoxcast: 0.681612 val loss: 0.283587
[Epoch 94] ogbg-moltoxcast: 0.652845 test loss: 0.351415
[Epoch 95; Iter    14/  229] train: loss: 0.1205516
[Epoch 95; Iter    44/  229] train: loss: 0.1258911
[Epoch 95; Iter    74/  229] train: loss: 0.1626422
[Epoch 95; Iter   104/  229] train: loss: 0.1205065
[Epoch 95; Iter   134/  229] train: loss: 0.1357758
[Epoch 95; Iter   164/  229] train: loss: 0.1032801
[Epoch 95; Iter   194/  229] train: loss: 0.0807499
[Epoch 95; Iter   224/  229] train: loss: 0.1182271
[Epoch 95] ogbg-moltoxcast: 0.689940 val loss: 0.280148
[Epoch 95] ogbg-moltoxcast: 0.650740 test loss: 0.354748
[Epoch 96; Iter    25/  229] train: loss: 0.1257520
[Epoch 96; Iter    55/  229] train: loss: 0.0626119
[Epoch 96; Iter    85/  229] train: loss: 0.1287304
[Epoch 96; Iter   115/  229] train: loss: 0.1421489
[Epoch 96; Iter   145/  229] train: loss: 0.1330744
[Epoch 96; Iter   175/  229] train: loss: 0.1357942
[Epoch 96; Iter   205/  229] train: loss: 0.1083229
[Epoch 96] ogbg-moltoxcast: 0.687390 val loss: 0.283075
[Epoch 96] ogbg-moltoxcast: 0.651912 test loss: 0.355423
[Epoch 97; Iter     6/  229] train: loss: 0.1168026
[Epoch 97; Iter    36/  229] train: loss: 0.0982032
[Epoch 97; Iter    66/  229] train: loss: 0.0993629
[Epoch 97; Iter    96/  229] train: loss: 0.1005053
[Epoch 97; Iter   126/  229] train: loss: 0.1368974
[Epoch 97; Iter   156/  229] train: loss: 0.1155998
[Epoch 97; Iter   186/  229] train: loss: 0.0894902
[Epoch 97; Iter   216/  229] train: loss: 0.1242502
[Epoch 97] ogbg-moltoxcast: 0.687281 val loss: 0.279917
[Epoch 97] ogbg-moltoxcast: 0.653492 test loss: 0.351600
[Epoch 98; Iter    17/  229] train: loss: 0.1256465
[Epoch 98; Iter    47/  229] train: loss: 0.1160738
[Epoch 98; Iter    77/  229] train: loss: 0.1003441
[Epoch 98; Iter   107/  229] train: loss: 0.1063578
[Epoch 98; Iter   137/  229] train: loss: 0.1102688
[Epoch 98; Iter   167/  229] train: loss: 0.1401103
[Epoch 98; Iter   197/  229] train: loss: 0.1430339
[Epoch 98; Iter   227/  229] train: loss: 0.1162082
[Epoch 98] ogbg-moltoxcast: 0.685714 val loss: 0.281041
[Epoch 98] ogbg-moltoxcast: 0.650095 test loss: 0.355155
[Epoch 99; Iter    28/  229] train: loss: 0.1362960
[Epoch 99; Iter    58/  229] train: loss: 0.1349351
[Epoch 99; Iter    88/  229] train: loss: 0.1526707
[Epoch 99; Iter   118/  229] train: loss: 0.1354601
[Epoch 99; Iter   148/  229] train: loss: 0.1380927
[Epoch 99; Iter   178/  229] train: loss: 0.1880792
[Epoch 99; Iter   208/  229] train: loss: 0.0595065
[Epoch 99] ogbg-moltoxcast: 0.687208 val loss: 0.283173
[Epoch 99] ogbg-moltoxcast: 0.651791 test loss: 0.354508
[Epoch 100; Iter     9/  229] train: loss: 0.0926916
[Epoch 100; Iter    39/  229] train: loss: 0.1129283
[Epoch 100; Iter    69/  229] train: loss: 0.0910338
[Epoch 100; Iter    99/  229] train: loss: 0.1042823
[Epoch 100; Iter   129/  229] train: loss: 0.1083554
[Epoch 100; Iter   159/  229] train: loss: 0.0997846
[Epoch 100; Iter   189/  229] train: loss: 0.1146813
[Epoch 100; Iter   219/  229] train: loss: 0.1092638
[Epoch 100] ogbg-moltoxcast: 0.687717 val loss: 0.286664
[Epoch 100] ogbg-moltoxcast: 0.654862 test loss: 0.358876
[Epoch 101; Iter    20/  229] train: loss: 0.1467869
[Epoch 101; Iter    50/  229] train: loss: 0.1130927
[Epoch 101; Iter    80/  229] train: loss: 0.0923104
[Epoch 101; Iter   110/  229] train: loss: 0.1141167
[Epoch 101; Iter   140/  229] train: loss: 0.1281588
[Epoch 101; Iter   170/  229] train: loss: 0.1181900
[Epoch 101; Iter   200/  229] train: loss: 0.1611459
[Epoch 101] ogbg-moltoxcast: 0.685723 val loss: 0.281134
[Epoch 101] ogbg-moltoxcast: 0.647766 test loss: 0.357932
[Epoch 102; Iter     1/  229] train: loss: 0.1015825
[Epoch 102; Iter    31/  229] train: loss: 0.1120223
[Epoch 102; Iter    61/  229] train: loss: 0.1630802
[Epoch 102; Iter    91/  229] train: loss: 0.1520686
[Epoch 102; Iter   121/  229] train: loss: 0.1271277
[Epoch 102; Iter   151/  229] train: loss: 0.1083720
[Epoch 102; Iter   181/  229] train: loss: 0.1612492
[Epoch 102; Iter   211/  229] train: loss: 0.1118623
[Epoch 102] ogbg-moltoxcast: 0.684656 val loss: 0.284447
[Epoch 102] ogbg-moltoxcast: 0.648591 test loss: 0.355419
[Epoch 103; Iter    12/  229] train: loss: 0.1008544
[Epoch 103; Iter    42/  229] train: loss: 0.1160339
[Epoch 103; Iter    72/  229] train: loss: 0.0947421
[Epoch 103; Iter   102/  229] train: loss: 0.1655592
[Epoch 103; Iter   132/  229] train: loss: 0.1478126
[Epoch 103; Iter   162/  229] train: loss: 0.0744369
[Epoch 103; Iter   192/  229] train: loss: 0.1246017
[Epoch 103; Iter   222/  229] train: loss: 0.1483020
[Epoch 103] ogbg-moltoxcast: 0.684532 val loss: 0.286259
[Epoch 103] ogbg-moltoxcast: 0.651813 test loss: 0.355733
[Epoch 104; Iter    23/  229] train: loss: 0.1208400
[Epoch 104; Iter    53/  229] train: loss: 0.0773816
[Epoch 104; Iter    83/  229] train: loss: 0.1090814
[Epoch 104; Iter   113/  229] train: loss: 0.1750838
[Epoch 104; Iter   143/  229] train: loss: 0.1399985
[Epoch 104; Iter   173/  229] train: loss: 0.1254979
[Epoch 104; Iter   203/  229] train: loss: 0.1128108
[Epoch 104] ogbg-moltoxcast: 0.684639 val loss: 0.282655
[Epoch 104] ogbg-moltoxcast: 0.650477 test loss: 0.355385
[Epoch 105; Iter     4/  229] train: loss: 0.1139829
[Epoch 105; Iter    34/  229] train: loss: 0.1104883
[Epoch 105; Iter    64/  229] train: loss: 0.1123291
[Epoch 105; Iter    94/  229] train: loss: 0.1132484
[Epoch 105; Iter   124/  229] train: loss: 0.1404185
[Epoch 105; Iter   154/  229] train: loss: 0.1000932
[Epoch 105; Iter   184/  229] train: loss: 0.1066381
[Epoch 105; Iter   214/  229] train: loss: 0.1340756
[Epoch 105] ogbg-moltoxcast: 0.685478 val loss: 0.285610
[Epoch 105] ogbg-moltoxcast: 0.648855 test loss: 0.360349
[Epoch 106; Iter    15/  229] train: loss: 0.1069446
[Epoch 106; Iter    45/  229] train: loss: 0.0980514
[Epoch 106; Iter    75/  229] train: loss: 0.1583915
[Epoch 106; Iter   105/  229] train: loss: 0.1349980
[Epoch 106; Iter   135/  229] train: loss: 0.1233341
[Epoch 106; Iter   165/  229] train: loss: 0.1350639
[Epoch 106; Iter   195/  229] train: loss: 0.1270922
[Epoch 106; Iter   225/  229] train: loss: 0.1252269
[Epoch 106] ogbg-moltoxcast: 0.684026 val loss: 0.285599
[Epoch 106] ogbg-moltoxcast: 0.645578 test loss: 0.361130
[Epoch 107; Iter    26/  229] train: loss: 0.0982574
[Epoch 107; Iter    56/  229] train: loss: 0.1094523
[Epoch 107; Iter    86/  229] train: loss: 0.1076241
[Epoch 107; Iter   116/  229] train: loss: 0.1167659
[Epoch 107; Iter   146/  229] train: loss: 0.0968785
[Epoch 107; Iter   176/  229] train: loss: 0.1119969
[Epoch 107; Iter   206/  229] train: loss: 0.1601965
[Epoch 107] ogbg-moltoxcast: 0.684408 val loss: 0.288222
[Epoch 94; Iter   114/  172] train: loss: 0.1718433
[Epoch 94; Iter   144/  172] train: loss: 0.1246967
[Epoch 94] ogbg-moltoxcast: 0.644899 val loss: 0.308938
[Epoch 94] ogbg-moltoxcast: 0.618856 test loss: 0.364091
[Epoch 95; Iter     2/  172] train: loss: 0.0816337
[Epoch 95; Iter    32/  172] train: loss: 0.1214687
[Epoch 95; Iter    62/  172] train: loss: 0.1245865
[Epoch 95; Iter    92/  172] train: loss: 0.1272558
[Epoch 95; Iter   122/  172] train: loss: 0.0976347
[Epoch 95; Iter   152/  172] train: loss: 0.1535678
[Epoch 95] ogbg-moltoxcast: 0.638800 val loss: 0.314358
[Epoch 95] ogbg-moltoxcast: 0.617430 test loss: 0.370359
[Epoch 96; Iter    10/  172] train: loss: 0.0933600
[Epoch 96; Iter    40/  172] train: loss: 0.1104776
[Epoch 96; Iter    70/  172] train: loss: 0.1263929
[Epoch 96; Iter   100/  172] train: loss: 0.1155598
[Epoch 96; Iter   130/  172] train: loss: 0.0901435
[Epoch 96; Iter   160/  172] train: loss: 0.0747045
[Epoch 96] ogbg-moltoxcast: 0.640051 val loss: 0.312601
[Epoch 96] ogbg-moltoxcast: 0.618125 test loss: 0.367639
[Epoch 97; Iter    18/  172] train: loss: 0.1181134
[Epoch 97; Iter    48/  172] train: loss: 0.1661023
[Epoch 97; Iter    78/  172] train: loss: 0.0882383
[Epoch 97; Iter   108/  172] train: loss: 0.1293540
[Epoch 97; Iter   138/  172] train: loss: 0.1121104
[Epoch 97; Iter   168/  172] train: loss: 0.0965599
[Epoch 97] ogbg-moltoxcast: 0.634258 val loss: 0.312295
[Epoch 97] ogbg-moltoxcast: 0.617915 test loss: 0.366892
[Epoch 98; Iter    26/  172] train: loss: 0.0868915
[Epoch 98; Iter    56/  172] train: loss: 0.1370656
[Epoch 98; Iter    86/  172] train: loss: 0.1023866
[Epoch 98; Iter   116/  172] train: loss: 0.1066096
[Epoch 98; Iter   146/  172] train: loss: 0.0686595
[Epoch 98] ogbg-moltoxcast: 0.637924 val loss: 0.318234
[Epoch 98] ogbg-moltoxcast: 0.617818 test loss: 0.376218
[Epoch 99; Iter     4/  172] train: loss: 0.1075372
[Epoch 99; Iter    34/  172] train: loss: 0.1014154
[Epoch 99; Iter    64/  172] train: loss: 0.1236814
[Epoch 99; Iter    94/  172] train: loss: 0.0850300
[Epoch 99; Iter   124/  172] train: loss: 0.1398002
[Epoch 99; Iter   154/  172] train: loss: 0.1052496
[Epoch 99] ogbg-moltoxcast: 0.642707 val loss: 0.314924
[Epoch 99] ogbg-moltoxcast: 0.619304 test loss: 0.371447
[Epoch 100; Iter    12/  172] train: loss: 0.1276316
[Epoch 100; Iter    42/  172] train: loss: 0.0898390
[Epoch 100; Iter    72/  172] train: loss: 0.0942238
[Epoch 100; Iter   102/  172] train: loss: 0.1199136
[Epoch 100; Iter   132/  172] train: loss: 0.1143987
[Epoch 100; Iter   162/  172] train: loss: 0.0969821
[Epoch 100] ogbg-moltoxcast: 0.640326 val loss: 0.316087
[Epoch 100] ogbg-moltoxcast: 0.620367 test loss: 0.374401
[Epoch 101; Iter    20/  172] train: loss: 0.0805194
[Epoch 101; Iter    50/  172] train: loss: 0.1467161
[Epoch 101; Iter    80/  172] train: loss: 0.0793572
[Epoch 101; Iter   110/  172] train: loss: 0.0952490
[Epoch 101; Iter   140/  172] train: loss: 0.1067511
[Epoch 101; Iter   170/  172] train: loss: 0.0993425
[Epoch 101] ogbg-moltoxcast: 0.643668 val loss: 0.310454
[Epoch 101] ogbg-moltoxcast: 0.623055 test loss: 0.367145
[Epoch 102; Iter    28/  172] train: loss: 0.1316867
[Epoch 102; Iter    58/  172] train: loss: 0.1165559
[Epoch 102; Iter    88/  172] train: loss: 0.1404157
[Epoch 102; Iter   118/  172] train: loss: 0.0714140
[Epoch 102; Iter   148/  172] train: loss: 0.1341256
[Epoch 102] ogbg-moltoxcast: 0.636894 val loss: 0.316430
[Epoch 102] ogbg-moltoxcast: 0.619284 test loss: 0.370261
[Epoch 103; Iter     6/  172] train: loss: 0.0819252
[Epoch 103; Iter    36/  172] train: loss: 0.1264754
[Epoch 103; Iter    66/  172] train: loss: 0.1074419
[Epoch 103; Iter    96/  172] train: loss: 0.0779705
[Epoch 103; Iter   126/  172] train: loss: 0.1093859
[Epoch 103; Iter   156/  172] train: loss: 0.0754335
[Epoch 103] ogbg-moltoxcast: 0.634817 val loss: 0.308501
[Epoch 103] ogbg-moltoxcast: 0.619552 test loss: 0.357114
[Epoch 104; Iter    14/  172] train: loss: 0.1131391
[Epoch 104; Iter    44/  172] train: loss: 0.0653982
[Epoch 104; Iter    74/  172] train: loss: 0.0961413
[Epoch 104; Iter   104/  172] train: loss: 0.1001022
[Epoch 104; Iter   134/  172] train: loss: 0.0741664
[Epoch 104; Iter   164/  172] train: loss: 0.0695778
[Epoch 104] ogbg-moltoxcast: 0.634662 val loss: 0.320829
[Epoch 104] ogbg-moltoxcast: 0.618081 test loss: 0.375245
[Epoch 105; Iter    22/  172] train: loss: 0.1076212
[Epoch 105; Iter    52/  172] train: loss: 0.0933906
[Epoch 105; Iter    82/  172] train: loss: 0.0860875
[Epoch 105; Iter   112/  172] train: loss: 0.0962641
[Epoch 105; Iter   142/  172] train: loss: 0.0923360
[Epoch 105; Iter   172/  172] train: loss: 0.1230888
[Epoch 105] ogbg-moltoxcast: 0.639882 val loss: 0.323890
[Epoch 105] ogbg-moltoxcast: 0.616868 test loss: 0.381897
[Epoch 106; Iter    30/  172] train: loss: 0.1098454
[Epoch 106; Iter    60/  172] train: loss: 0.1103398
[Epoch 106; Iter    90/  172] train: loss: 0.1173288
[Epoch 106; Iter   120/  172] train: loss: 0.1359365
[Epoch 106; Iter   150/  172] train: loss: 0.1357787
[Epoch 106] ogbg-moltoxcast: 0.639865 val loss: 0.320962
[Epoch 106] ogbg-moltoxcast: 0.620592 test loss: 0.376746
[Epoch 107; Iter     8/  172] train: loss: 0.1239606
[Epoch 107; Iter    38/  172] train: loss: 0.0869155
[Epoch 107; Iter    68/  172] train: loss: 0.1129766
[Epoch 107; Iter    98/  172] train: loss: 0.1189094
[Epoch 107; Iter   128/  172] train: loss: 0.1259802
[Epoch 107; Iter   158/  172] train: loss: 0.0652240
[Epoch 107] ogbg-moltoxcast: 0.635873 val loss: 0.315793
[Epoch 107] ogbg-moltoxcast: 0.616036 test loss: 0.371594
[Epoch 108; Iter    16/  172] train: loss: 0.1258253
[Epoch 108; Iter    46/  172] train: loss: 0.1031365
[Epoch 108; Iter    76/  172] train: loss: 0.0971882
[Epoch 108; Iter   106/  172] train: loss: 0.0887827
[Epoch 108; Iter   136/  172] train: loss: 0.1067098
[Epoch 108; Iter   166/  172] train: loss: 0.1160154
[Epoch 108] ogbg-moltoxcast: 0.640445 val loss: 0.325181
[Epoch 108] ogbg-moltoxcast: 0.620282 test loss: 0.384053
[Epoch 109; Iter    24/  172] train: loss: 0.0880104
[Epoch 109; Iter    54/  172] train: loss: 0.1070055
[Epoch 109; Iter    84/  172] train: loss: 0.1168817
[Epoch 109; Iter   114/  172] train: loss: 0.0812501
[Epoch 109; Iter   144/  172] train: loss: 0.1169410
[Epoch 109] ogbg-moltoxcast: 0.639822 val loss: 0.319154
[Epoch 109] ogbg-moltoxcast: 0.618342 test loss: 0.376879
[Epoch 110; Iter     2/  172] train: loss: 0.1006089
[Epoch 110; Iter    32/  172] train: loss: 0.0918965
[Epoch 110; Iter    62/  172] train: loss: 0.1126867
[Epoch 110; Iter    92/  172] train: loss: 0.0881182
[Epoch 110; Iter   122/  172] train: loss: 0.1015027
[Epoch 110; Iter   152/  172] train: loss: 0.0894282
[Epoch 110] ogbg-moltoxcast: 0.633576 val loss: 0.325198
[Epoch 110] ogbg-moltoxcast: 0.614528 test loss: 0.385741
[Epoch 111; Iter    10/  172] train: loss: 0.0880032
[Epoch 111; Iter    40/  172] train: loss: 0.1360781
[Epoch 111; Iter    70/  172] train: loss: 0.1030789
[Epoch 111; Iter   100/  172] train: loss: 0.1248451
[Epoch 111; Iter   130/  172] train: loss: 0.0959401
[Epoch 111; Iter   160/  172] train: loss: 0.1058341
[Epoch 111] ogbg-moltoxcast: 0.627650 val loss: 0.328491
[Epoch 111] ogbg-moltoxcast: 0.611887 test loss: 0.387972
[Epoch 112; Iter    18/  172] train: loss: 0.1211967
[Epoch 112; Iter    48/  172] train: loss: 0.1506756
[Epoch 112; Iter    78/  172] train: loss: 0.1144979
[Epoch 112; Iter   108/  172] train: loss: 0.1067746
[Epoch 112; Iter   138/  172] train: loss: 0.0879585
[Epoch 112; Iter   168/  172] train: loss: 0.1171494
[Epoch 112] ogbg-moltoxcast: 0.639395 val loss: 0.327082
[Epoch 112] ogbg-moltoxcast: 0.618859 test loss: 0.386672
[Epoch 113; Iter    26/  172] train: loss: 0.0956932
[Epoch 113; Iter    56/  172] train: loss: 0.0793928
[Epoch 113; Iter    86/  172] train: loss: 0.1128175
[Epoch 113; Iter   116/  172] train: loss: 0.1087380
[Epoch 113; Iter   146/  172] train: loss: 0.1618960
[Epoch 113] ogbg-moltoxcast: 0.637642 val loss: 0.328411
[Epoch 113] ogbg-moltoxcast: 0.615615 test loss: 0.396716
[Epoch 114; Iter     4/  172] train: loss: 0.1951432[Epoch 92; Iter    11/  229] train: loss: 0.1292294
[Epoch 92; Iter    41/  229] train: loss: 0.1217996
[Epoch 92; Iter    71/  229] train: loss: 0.1165971
[Epoch 92; Iter   101/  229] train: loss: 0.1308777
[Epoch 92; Iter   131/  229] train: loss: 0.1256213
[Epoch 92; Iter   161/  229] train: loss: 0.0992934
[Epoch 92; Iter   191/  229] train: loss: 0.1210916
[Epoch 92; Iter   221/  229] train: loss: 0.1497909
[Epoch 92] ogbg-moltoxcast: 0.696858 val loss: 0.273744
[Epoch 92] ogbg-moltoxcast: 0.656875 test loss: 0.351118
[Epoch 93; Iter    22/  229] train: loss: 0.1074449
[Epoch 93; Iter    52/  229] train: loss: 0.1101982
[Epoch 93; Iter    82/  229] train: loss: 0.1647516
[Epoch 93; Iter   112/  229] train: loss: 0.1459069
[Epoch 93; Iter   142/  229] train: loss: 0.1202926
[Epoch 93; Iter   172/  229] train: loss: 0.1177341
[Epoch 93; Iter   202/  229] train: loss: 0.0934053
[Epoch 93] ogbg-moltoxcast: 0.695380 val loss: 0.279105
[Epoch 93] ogbg-moltoxcast: 0.654635 test loss: 0.349247
[Epoch 94; Iter     3/  229] train: loss: 0.1118335
[Epoch 94; Iter    33/  229] train: loss: 0.1171726
[Epoch 94; Iter    63/  229] train: loss: 0.1317889
[Epoch 94; Iter    93/  229] train: loss: 0.1112961
[Epoch 94; Iter   123/  229] train: loss: 0.1246783
[Epoch 94; Iter   153/  229] train: loss: 0.1907266
[Epoch 94; Iter   183/  229] train: loss: 0.1418182
[Epoch 94; Iter   213/  229] train: loss: 0.1046147
[Epoch 94] ogbg-moltoxcast: 0.698508 val loss: 0.276805
[Epoch 94] ogbg-moltoxcast: 0.660298 test loss: 0.345893
[Epoch 95; Iter    14/  229] train: loss: 0.1252926
[Epoch 95; Iter    44/  229] train: loss: 0.0963469
[Epoch 95; Iter    74/  229] train: loss: 0.1356076
[Epoch 95; Iter   104/  229] train: loss: 0.1327126
[Epoch 95; Iter   134/  229] train: loss: 0.0935210
[Epoch 95; Iter   164/  229] train: loss: 0.1122153
[Epoch 95; Iter   194/  229] train: loss: 0.1352840
[Epoch 95; Iter   224/  229] train: loss: 0.1489986
[Epoch 95] ogbg-moltoxcast: 0.697341 val loss: 0.279076
[Epoch 95] ogbg-moltoxcast: 0.660162 test loss: 0.342788
[Epoch 96; Iter    25/  229] train: loss: 0.1271013
[Epoch 96; Iter    55/  229] train: loss: 0.1098771
[Epoch 96; Iter    85/  229] train: loss: 0.0982753
[Epoch 96; Iter   115/  229] train: loss: 0.1451966
[Epoch 96; Iter   145/  229] train: loss: 0.1112264
[Epoch 96; Iter   175/  229] train: loss: 0.0945392
[Epoch 96; Iter   205/  229] train: loss: 0.1511129
[Epoch 96] ogbg-moltoxcast: 0.697155 val loss: 0.276000
[Epoch 96] ogbg-moltoxcast: 0.656811 test loss: 0.356574
[Epoch 97; Iter     6/  229] train: loss: 0.1268300
[Epoch 97; Iter    36/  229] train: loss: 0.1048533
[Epoch 97; Iter    66/  229] train: loss: 0.0884014
[Epoch 97; Iter    96/  229] train: loss: 0.0980792
[Epoch 97; Iter   126/  229] train: loss: 0.1274617
[Epoch 97; Iter   156/  229] train: loss: 0.1046612
[Epoch 97; Iter   186/  229] train: loss: 0.0979596
[Epoch 97; Iter   216/  229] train: loss: 0.1940637
[Epoch 97] ogbg-moltoxcast: 0.694454 val loss: 0.277427
[Epoch 97] ogbg-moltoxcast: 0.658643 test loss: 0.343222
[Epoch 98; Iter    17/  229] train: loss: 0.1241342
[Epoch 98; Iter    47/  229] train: loss: 0.1263150
[Epoch 98; Iter    77/  229] train: loss: 0.1251816
[Epoch 98; Iter   107/  229] train: loss: 0.1048472
[Epoch 98; Iter   137/  229] train: loss: 0.1554283
[Epoch 98; Iter   167/  229] train: loss: 0.1035106
[Epoch 98; Iter   197/  229] train: loss: 0.1085134
[Epoch 98; Iter   227/  229] train: loss: 0.1403935
[Epoch 98] ogbg-moltoxcast: 0.698509 val loss: 0.276734
[Epoch 98] ogbg-moltoxcast: 0.660846 test loss: 0.341685
[Epoch 99; Iter    28/  229] train: loss: 0.1300303
[Epoch 99; Iter    58/  229] train: loss: 0.1389899
[Epoch 99; Iter    88/  229] train: loss: 0.1168287
[Epoch 99; Iter   118/  229] train: loss: 0.1037012
[Epoch 99; Iter   148/  229] train: loss: 0.1957542
[Epoch 99; Iter   178/  229] train: loss: 0.1533561
[Epoch 99; Iter   208/  229] train: loss: 0.1239918
[Epoch 99] ogbg-moltoxcast: 0.697250 val loss: 0.274337
[Epoch 99] ogbg-moltoxcast: 0.661823 test loss: 0.340489
[Epoch 100; Iter     9/  229] train: loss: 0.0897937
[Epoch 100; Iter    39/  229] train: loss: 0.1362778
[Epoch 100; Iter    69/  229] train: loss: 0.1195849
[Epoch 100; Iter    99/  229] train: loss: 0.1131742
[Epoch 100; Iter   129/  229] train: loss: 0.1713758
[Epoch 100; Iter   159/  229] train: loss: 0.1240049
[Epoch 100; Iter   189/  229] train: loss: 0.1191873
[Epoch 100; Iter   219/  229] train: loss: 0.1165839
[Epoch 100] ogbg-moltoxcast: 0.698208 val loss: 0.278804
[Epoch 100] ogbg-moltoxcast: 0.663291 test loss: 0.343395
[Epoch 101; Iter    20/  229] train: loss: 0.1200845
[Epoch 101; Iter    50/  229] train: loss: 0.0953071
[Epoch 101; Iter    80/  229] train: loss: 0.1123767
[Epoch 101; Iter   110/  229] train: loss: 0.1219688
[Epoch 101; Iter   140/  229] train: loss: 0.0753057
[Epoch 101; Iter   170/  229] train: loss: 0.1277515
[Epoch 101; Iter   200/  229] train: loss: 0.1023848
[Epoch 101] ogbg-moltoxcast: 0.699500 val loss: 0.277094
[Epoch 101] ogbg-moltoxcast: 0.657860 test loss: 0.343886
[Epoch 102; Iter     1/  229] train: loss: 0.1338391
[Epoch 102; Iter    31/  229] train: loss: 0.0829448
[Epoch 102; Iter    61/  229] train: loss: 0.0889985
[Epoch 102; Iter    91/  229] train: loss: 0.1127202
[Epoch 102; Iter   121/  229] train: loss: 0.1149739
[Epoch 102; Iter   151/  229] train: loss: 0.1148907
[Epoch 102; Iter   181/  229] train: loss: 0.1201207
[Epoch 102; Iter   211/  229] train: loss: 0.1184935
[Epoch 102] ogbg-moltoxcast: 0.698984 val loss: 0.277711
[Epoch 102] ogbg-moltoxcast: 0.661524 test loss: 0.342663
[Epoch 103; Iter    12/  229] train: loss: 0.0811435
[Epoch 103; Iter    42/  229] train: loss: 0.1197675
[Epoch 103; Iter    72/  229] train: loss: 0.1259901
[Epoch 103; Iter   102/  229] train: loss: 0.1344966
[Epoch 103; Iter   132/  229] train: loss: 0.1185766
[Epoch 103; Iter   162/  229] train: loss: 0.1153123
[Epoch 103; Iter   192/  229] train: loss: 0.1375139
[Epoch 103; Iter   222/  229] train: loss: 0.1252893
[Epoch 103] ogbg-moltoxcast: 0.693877 val loss: 0.284432
[Epoch 103] ogbg-moltoxcast: 0.660840 test loss: 0.348813
[Epoch 104; Iter    23/  229] train: loss: 0.1121428
[Epoch 104; Iter    53/  229] train: loss: 0.1168635
[Epoch 104; Iter    83/  229] train: loss: 0.0966497
[Epoch 104; Iter   113/  229] train: loss: 0.1457310
[Epoch 104; Iter   143/  229] train: loss: 0.1126435
[Epoch 104; Iter   173/  229] train: loss: 0.1058182
[Epoch 104; Iter   203/  229] train: loss: 0.0994456
[Epoch 104] ogbg-moltoxcast: 0.696131 val loss: 0.278759
[Epoch 104] ogbg-moltoxcast: 0.659999 test loss: 0.345285
[Epoch 105; Iter     4/  229] train: loss: 0.1354399
[Epoch 105; Iter    34/  229] train: loss: 0.1122510
[Epoch 105; Iter    64/  229] train: loss: 0.0988998
[Epoch 105; Iter    94/  229] train: loss: 0.1118054
[Epoch 105; Iter   124/  229] train: loss: 0.1418675
[Epoch 105; Iter   154/  229] train: loss: 0.1136611
[Epoch 105; Iter   184/  229] train: loss: 0.1092121
[Epoch 105; Iter   214/  229] train: loss: 0.1079423
[Epoch 105] ogbg-moltoxcast: 0.698401 val loss: 0.276385
[Epoch 105] ogbg-moltoxcast: 0.660506 test loss: 0.343412
[Epoch 106; Iter    15/  229] train: loss: 0.1182580
[Epoch 106; Iter    45/  229] train: loss: 0.0964439
[Epoch 106; Iter    75/  229] train: loss: 0.1335349
[Epoch 106; Iter   105/  229] train: loss: 0.1133113
[Epoch 106; Iter   135/  229] train: loss: 0.1209641
[Epoch 106; Iter   165/  229] train: loss: 0.1368629
[Epoch 106; Iter   195/  229] train: loss: 0.1139708
[Epoch 106; Iter   225/  229] train: loss: 0.1269635
[Epoch 106] ogbg-moltoxcast: 0.695461 val loss: 0.277264
[Epoch 106] ogbg-moltoxcast: 0.653466 test loss: 0.344373
[Epoch 107; Iter    26/  229] train: loss: 0.1320250
[Epoch 107; Iter    56/  229] train: loss: 0.1172779
[Epoch 107; Iter    86/  229] train: loss: 0.1039138
[Epoch 107; Iter   116/  229] train: loss: 0.1036017
[Epoch 107; Iter   146/  229] train: loss: 0.0851003
[Epoch 107; Iter   176/  229] train: loss: 0.1340282
[Epoch 107; Iter   206/  229] train: loss: 0.0934973
[Epoch 107] ogbg-moltoxcast: 0.699680 val loss: 0.279455
[Epoch 94; Iter   114/  172] train: loss: 0.0930114
[Epoch 94; Iter   144/  172] train: loss: 0.1349640
[Epoch 94] ogbg-moltoxcast: 0.654295 val loss: 0.306559
[Epoch 94] ogbg-moltoxcast: 0.611916 test loss: 0.360589
[Epoch 95; Iter     2/  172] train: loss: 0.0947751
[Epoch 95; Iter    32/  172] train: loss: 0.0885863
[Epoch 95; Iter    62/  172] train: loss: 0.1285686
[Epoch 95; Iter    92/  172] train: loss: 0.1103886
[Epoch 95; Iter   122/  172] train: loss: 0.1374469
[Epoch 95; Iter   152/  172] train: loss: 0.0830267
[Epoch 95] ogbg-moltoxcast: 0.654424 val loss: 0.306200
[Epoch 95] ogbg-moltoxcast: 0.614254 test loss: 0.357895
[Epoch 96; Iter    10/  172] train: loss: 0.0849071
[Epoch 96; Iter    40/  172] train: loss: 0.1627127
[Epoch 96; Iter    70/  172] train: loss: 0.1049144
[Epoch 96; Iter   100/  172] train: loss: 0.1096470
[Epoch 96; Iter   130/  172] train: loss: 0.1006606
[Epoch 96; Iter   160/  172] train: loss: 0.0962139
[Epoch 96] ogbg-moltoxcast: 0.652804 val loss: 0.305515
[Epoch 96] ogbg-moltoxcast: 0.614493 test loss: 0.355799
[Epoch 97; Iter    18/  172] train: loss: 0.1653357
[Epoch 97; Iter    48/  172] train: loss: 0.0943008
[Epoch 97; Iter    78/  172] train: loss: 0.1276248
[Epoch 97; Iter   108/  172] train: loss: 0.0895104
[Epoch 97; Iter   138/  172] train: loss: 0.1232873
[Epoch 97; Iter   168/  172] train: loss: 0.1119114
[Epoch 97] ogbg-moltoxcast: 0.657523 val loss: 0.306270
[Epoch 97] ogbg-moltoxcast: 0.616440 test loss: 0.359546
[Epoch 98; Iter    26/  172] train: loss: 0.1321415
[Epoch 98; Iter    56/  172] train: loss: 0.1872543
[Epoch 98; Iter    86/  172] train: loss: 0.1271824
[Epoch 98; Iter   116/  172] train: loss: 0.1104318
[Epoch 98; Iter   146/  172] train: loss: 0.1324452
[Epoch 98] ogbg-moltoxcast: 0.655645 val loss: 0.304394
[Epoch 98] ogbg-moltoxcast: 0.615178 test loss: 0.360285
[Epoch 99; Iter     4/  172] train: loss: 0.1000945
[Epoch 99; Iter    34/  172] train: loss: 0.0738490
[Epoch 99; Iter    64/  172] train: loss: 0.1171929
[Epoch 99; Iter    94/  172] train: loss: 0.1043988
[Epoch 99; Iter   124/  172] train: loss: 0.0787329
[Epoch 99; Iter   154/  172] train: loss: 0.1104489
[Epoch 99] ogbg-moltoxcast: 0.652455 val loss: 0.306555
[Epoch 99] ogbg-moltoxcast: 0.613931 test loss: 0.361597
[Epoch 100; Iter    12/  172] train: loss: 0.1018855
[Epoch 100; Iter    42/  172] train: loss: 0.1453809
[Epoch 100; Iter    72/  172] train: loss: 0.0885887
[Epoch 100; Iter   102/  172] train: loss: 0.0853919
[Epoch 100; Iter   132/  172] train: loss: 0.0954854
[Epoch 100; Iter   162/  172] train: loss: 0.1069722
[Epoch 100] ogbg-moltoxcast: 0.651602 val loss: 0.306680
[Epoch 100] ogbg-moltoxcast: 0.613720 test loss: 0.357961
[Epoch 101; Iter    20/  172] train: loss: 0.1279285
[Epoch 101; Iter    50/  172] train: loss: 0.1131157
[Epoch 101; Iter    80/  172] train: loss: 0.1088223
[Epoch 101; Iter   110/  172] train: loss: 0.1231191
[Epoch 101; Iter   140/  172] train: loss: 0.1231018
[Epoch 101; Iter   170/  172] train: loss: 0.1133663
[Epoch 101] ogbg-moltoxcast: 0.650174 val loss: 0.312426
[Epoch 101] ogbg-moltoxcast: 0.612613 test loss: 0.361306
[Epoch 102; Iter    28/  172] train: loss: 0.1320421
[Epoch 102; Iter    58/  172] train: loss: 0.0941063
[Epoch 102; Iter    88/  172] train: loss: 0.0980652
[Epoch 102; Iter   118/  172] train: loss: 0.1142885
[Epoch 102; Iter   148/  172] train: loss: 0.1182054
[Epoch 102] ogbg-moltoxcast: 0.650287 val loss: 0.310589
[Epoch 102] ogbg-moltoxcast: 0.612019 test loss: 0.360345
[Epoch 103; Iter     6/  172] train: loss: 0.1136140
[Epoch 103; Iter    36/  172] train: loss: 0.1457178
[Epoch 103; Iter    66/  172] train: loss: 0.1500393
[Epoch 103; Iter    96/  172] train: loss: 0.0841497
[Epoch 103; Iter   126/  172] train: loss: 0.0691678
[Epoch 103; Iter   156/  172] train: loss: 0.0819587
[Epoch 103] ogbg-moltoxcast: 0.651842 val loss: 0.308002
[Epoch 103] ogbg-moltoxcast: 0.612187 test loss: 0.358828
[Epoch 104; Iter    14/  172] train: loss: 0.1084236
[Epoch 104; Iter    44/  172] train: loss: 0.1008824
[Epoch 104; Iter    74/  172] train: loss: 0.1223605
[Epoch 104; Iter   104/  172] train: loss: 0.0991657
[Epoch 104; Iter   134/  172] train: loss: 0.1368114
[Epoch 104; Iter   164/  172] train: loss: 0.0863265
[Epoch 104] ogbg-moltoxcast: 0.652695 val loss: 0.311123
[Epoch 104] ogbg-moltoxcast: 0.616487 test loss: 0.359974
[Epoch 105; Iter    22/  172] train: loss: 0.0965327
[Epoch 105; Iter    52/  172] train: loss: 0.1108132
[Epoch 105; Iter    82/  172] train: loss: 0.1156299
[Epoch 105; Iter   112/  172] train: loss: 0.0963623
[Epoch 105; Iter   142/  172] train: loss: 0.0935854
[Epoch 105; Iter   172/  172] train: loss: 0.1110926
[Epoch 105] ogbg-moltoxcast: 0.649146 val loss: 0.315339
[Epoch 105] ogbg-moltoxcast: 0.610888 test loss: 0.365393
[Epoch 106; Iter    30/  172] train: loss: 0.1633396
[Epoch 106; Iter    60/  172] train: loss: 0.1083826
[Epoch 106; Iter    90/  172] train: loss: 0.1042911
[Epoch 106; Iter   120/  172] train: loss: 0.1050538
[Epoch 106; Iter   150/  172] train: loss: 0.0919221
[Epoch 106] ogbg-moltoxcast: 0.649190 val loss: 0.312093
[Epoch 106] ogbg-moltoxcast: 0.612130 test loss: 0.364348
[Epoch 107; Iter     8/  172] train: loss: 0.1158762
[Epoch 107; Iter    38/  172] train: loss: 0.1155933
[Epoch 107; Iter    68/  172] train: loss: 0.1073100
[Epoch 107; Iter    98/  172] train: loss: 0.1688728
[Epoch 107; Iter   128/  172] train: loss: 0.1105404
[Epoch 107; Iter   158/  172] train: loss: 0.0899848
[Epoch 107] ogbg-moltoxcast: 0.648448 val loss: 0.319385
[Epoch 107] ogbg-moltoxcast: 0.613402 test loss: 0.375957
[Epoch 108; Iter    16/  172] train: loss: 0.1252891
[Epoch 108; Iter    46/  172] train: loss: 0.1220952
[Epoch 108; Iter    76/  172] train: loss: 0.1065844
[Epoch 108; Iter   106/  172] train: loss: 0.1226225
[Epoch 108; Iter   136/  172] train: loss: 0.0893747
[Epoch 108; Iter   166/  172] train: loss: 0.0935504
[Epoch 108] ogbg-moltoxcast: 0.653359 val loss: 0.310388
[Epoch 108] ogbg-moltoxcast: 0.618050 test loss: 0.360382
[Epoch 109; Iter    24/  172] train: loss: 0.0942318
[Epoch 109; Iter    54/  172] train: loss: 0.0836735
[Epoch 109; Iter    84/  172] train: loss: 0.0923235
[Epoch 109; Iter   114/  172] train: loss: 0.1289548
[Epoch 109; Iter   144/  172] train: loss: 0.1272281
[Epoch 109] ogbg-moltoxcast: 0.649263 val loss: 0.310636
[Epoch 109] ogbg-moltoxcast: 0.615639 test loss: 0.358678
[Epoch 110; Iter     2/  172] train: loss: 0.0971279
[Epoch 110; Iter    32/  172] train: loss: 0.1062988
[Epoch 110; Iter    62/  172] train: loss: 0.0721666
[Epoch 110; Iter    92/  172] train: loss: 0.0966103
[Epoch 110; Iter   122/  172] train: loss: 0.0820755
[Epoch 110; Iter   152/  172] train: loss: 0.1505661
[Epoch 110] ogbg-moltoxcast: 0.651630 val loss: 0.308113
[Epoch 110] ogbg-moltoxcast: 0.616374 test loss: 0.353837
[Epoch 111; Iter    10/  172] train: loss: 0.1371999
[Epoch 111; Iter    40/  172] train: loss: 0.1234697
[Epoch 111; Iter    70/  172] train: loss: 0.1477842
[Epoch 111; Iter   100/  172] train: loss: 0.0883605
[Epoch 111; Iter   130/  172] train: loss: 0.1170289
[Epoch 111; Iter   160/  172] train: loss: 0.1362884
[Epoch 111] ogbg-moltoxcast: 0.650516 val loss: 0.314353
[Epoch 111] ogbg-moltoxcast: 0.615816 test loss: 0.366887
[Epoch 112; Iter    18/  172] train: loss: 0.1135280
[Epoch 112; Iter    48/  172] train: loss: 0.1383489
[Epoch 112; Iter    78/  172] train: loss: 0.1425878
[Epoch 112; Iter   108/  172] train: loss: 0.0920404
[Epoch 112; Iter   138/  172] train: loss: 0.1125549
[Epoch 112; Iter   168/  172] train: loss: 0.1555239
[Epoch 112] ogbg-moltoxcast: 0.648507 val loss: 0.314987
[Epoch 112] ogbg-moltoxcast: 0.615052 test loss: 0.368501
[Epoch 113; Iter    26/  172] train: loss: 0.0937677
[Epoch 113; Iter    56/  172] train: loss: 0.1031484
[Epoch 113; Iter    86/  172] train: loss: 0.1276779
[Epoch 113; Iter   116/  172] train: loss: 0.1281887
[Epoch 113; Iter   146/  172] train: loss: 0.0777691
[Epoch 113] ogbg-moltoxcast: 0.650894 val loss: 0.309065
[Epoch 113] ogbg-moltoxcast: 0.616972 test loss: 0.360067
[Epoch 114; Iter     4/  172] train: loss: 0.1009688[Epoch 92; Iter    11/  229] train: loss: 0.1343376
[Epoch 92; Iter    41/  229] train: loss: 0.1488078
[Epoch 92; Iter    71/  229] train: loss: 0.0998321
[Epoch 92; Iter   101/  229] train: loss: 0.1397156
[Epoch 92; Iter   131/  229] train: loss: 0.1029089
[Epoch 92; Iter   161/  229] train: loss: 0.1209492
[Epoch 92; Iter   191/  229] train: loss: 0.1100992
[Epoch 92; Iter   221/  229] train: loss: 0.1160488
[Epoch 92] ogbg-moltoxcast: 0.674236 val loss: 0.277983
[Epoch 92] ogbg-moltoxcast: 0.652017 test loss: 0.330460
[Epoch 93; Iter    22/  229] train: loss: 0.1291258
[Epoch 93; Iter    52/  229] train: loss: 0.1197693
[Epoch 93; Iter    82/  229] train: loss: 0.0794206
[Epoch 93; Iter   112/  229] train: loss: 0.1223762
[Epoch 93; Iter   142/  229] train: loss: 0.1485756
[Epoch 93; Iter   172/  229] train: loss: 0.1047859
[Epoch 93; Iter   202/  229] train: loss: 0.1086555
[Epoch 93] ogbg-moltoxcast: 0.677078 val loss: 0.276343
[Epoch 93] ogbg-moltoxcast: 0.650457 test loss: 0.332866
[Epoch 94; Iter     3/  229] train: loss: 0.1150509
[Epoch 94; Iter    33/  229] train: loss: 0.1267194
[Epoch 94; Iter    63/  229] train: loss: 0.1007092
[Epoch 94; Iter    93/  229] train: loss: 0.1639745
[Epoch 94; Iter   123/  229] train: loss: 0.1418233
[Epoch 94; Iter   153/  229] train: loss: 0.0831223
[Epoch 94; Iter   183/  229] train: loss: 0.0984886
[Epoch 94; Iter   213/  229] train: loss: 0.1093151
[Epoch 94] ogbg-moltoxcast: 0.671472 val loss: 0.279045
[Epoch 94] ogbg-moltoxcast: 0.645580 test loss: 0.332893
[Epoch 95; Iter    14/  229] train: loss: 0.1318354
[Epoch 95; Iter    44/  229] train: loss: 0.1238549
[Epoch 95; Iter    74/  229] train: loss: 0.1092536
[Epoch 95; Iter   104/  229] train: loss: 0.1025706
[Epoch 95; Iter   134/  229] train: loss: 0.0818360
[Epoch 95; Iter   164/  229] train: loss: 0.1456510
[Epoch 95; Iter   194/  229] train: loss: 0.1263645
[Epoch 95; Iter   224/  229] train: loss: 0.1133200
[Epoch 95] ogbg-moltoxcast: 0.675151 val loss: 0.279519
[Epoch 95] ogbg-moltoxcast: 0.651530 test loss: 0.330729
[Epoch 96; Iter    25/  229] train: loss: 0.1332174
[Epoch 96; Iter    55/  229] train: loss: 0.1213979
[Epoch 96; Iter    85/  229] train: loss: 0.1243257
[Epoch 96; Iter   115/  229] train: loss: 0.0975164
[Epoch 96; Iter   145/  229] train: loss: 0.1215164
[Epoch 96; Iter   175/  229] train: loss: 0.1081564
[Epoch 96; Iter   205/  229] train: loss: 0.1174897
[Epoch 96] ogbg-moltoxcast: 0.677136 val loss: 0.276421
[Epoch 96] ogbg-moltoxcast: 0.653364 test loss: 0.333792
[Epoch 97; Iter     6/  229] train: loss: 0.0740147
[Epoch 97; Iter    36/  229] train: loss: 0.1342587
[Epoch 97; Iter    66/  229] train: loss: 0.0983376
[Epoch 97; Iter    96/  229] train: loss: 0.1689702
[Epoch 97; Iter   126/  229] train: loss: 0.0919800
[Epoch 97; Iter   156/  229] train: loss: 0.0955745
[Epoch 97; Iter   186/  229] train: loss: 0.1192633
[Epoch 97; Iter   216/  229] train: loss: 0.0963531
[Epoch 97] ogbg-moltoxcast: 0.680207 val loss: 0.276447
[Epoch 97] ogbg-moltoxcast: 0.652296 test loss: 0.332253
[Epoch 98; Iter    17/  229] train: loss: 0.1776854
[Epoch 98; Iter    47/  229] train: loss: 0.1291455
[Epoch 98; Iter    77/  229] train: loss: 0.1400002
[Epoch 98; Iter   107/  229] train: loss: 0.1215900
[Epoch 98; Iter   137/  229] train: loss: 0.1000035
[Epoch 98; Iter   167/  229] train: loss: 0.0694948
[Epoch 98; Iter   197/  229] train: loss: 0.1109997
[Epoch 98; Iter   227/  229] train: loss: 0.1538204
[Epoch 98] ogbg-moltoxcast: 0.673415 val loss: 0.279635
[Epoch 98] ogbg-moltoxcast: 0.651171 test loss: 0.332961
[Epoch 99; Iter    28/  229] train: loss: 0.1431453
[Epoch 99; Iter    58/  229] train: loss: 0.0874426
[Epoch 99; Iter    88/  229] train: loss: 0.1198438
[Epoch 99; Iter   118/  229] train: loss: 0.1429842
[Epoch 99; Iter   148/  229] train: loss: 0.1617392
[Epoch 99; Iter   178/  229] train: loss: 0.1198614
[Epoch 99; Iter   208/  229] train: loss: 0.1315317
[Epoch 99] ogbg-moltoxcast: 0.678720 val loss: 0.278894
[Epoch 99] ogbg-moltoxcast: 0.653458 test loss: 0.333954
[Epoch 100; Iter     9/  229] train: loss: 0.0954384
[Epoch 100; Iter    39/  229] train: loss: 0.1378721
[Epoch 100; Iter    69/  229] train: loss: 0.1192183
[Epoch 100; Iter    99/  229] train: loss: 0.1078755
[Epoch 100; Iter   129/  229] train: loss: 0.1360901
[Epoch 100; Iter   159/  229] train: loss: 0.1196422
[Epoch 100; Iter   189/  229] train: loss: 0.1319164
[Epoch 100; Iter   219/  229] train: loss: 0.2074473
[Epoch 100] ogbg-moltoxcast: 0.678233 val loss: 0.280988
[Epoch 100] ogbg-moltoxcast: 0.653861 test loss: 0.335180
[Epoch 101; Iter    20/  229] train: loss: 0.1104443
[Epoch 101; Iter    50/  229] train: loss: 0.1270816
[Epoch 101; Iter    80/  229] train: loss: 0.1002885
[Epoch 101; Iter   110/  229] train: loss: 0.1416470
[Epoch 101; Iter   140/  229] train: loss: 0.1310685
[Epoch 101; Iter   170/  229] train: loss: 0.0981144
[Epoch 101; Iter   200/  229] train: loss: 0.1125111
[Epoch 101] ogbg-moltoxcast: 0.678647 val loss: 0.283661
[Epoch 101] ogbg-moltoxcast: 0.655443 test loss: 0.337416
[Epoch 102; Iter     1/  229] train: loss: 0.1285636
[Epoch 102; Iter    31/  229] train: loss: 0.1005315
[Epoch 102; Iter    61/  229] train: loss: 0.1450377
[Epoch 102; Iter    91/  229] train: loss: 0.1110113
[Epoch 102; Iter   121/  229] train: loss: 0.1071288
[Epoch 102; Iter   151/  229] train: loss: 0.1099132
[Epoch 102; Iter   181/  229] train: loss: 0.0937910
[Epoch 102; Iter   211/  229] train: loss: 0.1359316
[Epoch 102] ogbg-moltoxcast: 0.677565 val loss: 0.283097
[Epoch 102] ogbg-moltoxcast: 0.650440 test loss: 0.337269
[Epoch 103; Iter    12/  229] train: loss: 0.1084981
[Epoch 103; Iter    42/  229] train: loss: 0.1235829
[Epoch 103; Iter    72/  229] train: loss: 0.1105831
[Epoch 103; Iter   102/  229] train: loss: 0.1327784
[Epoch 103; Iter   132/  229] train: loss: 0.1035737
[Epoch 103; Iter   162/  229] train: loss: 0.1647682
[Epoch 103; Iter   192/  229] train: loss: 0.1112699
[Epoch 103; Iter   222/  229] train: loss: 0.1304161
[Epoch 103] ogbg-moltoxcast: 0.673402 val loss: 0.284103
[Epoch 103] ogbg-moltoxcast: 0.649747 test loss: 0.340163
[Epoch 104; Iter    23/  229] train: loss: 0.1076276
[Epoch 104; Iter    53/  229] train: loss: 0.0949390
[Epoch 104; Iter    83/  229] train: loss: 0.1174227
[Epoch 104; Iter   113/  229] train: loss: 0.0989882
[Epoch 104; Iter   143/  229] train: loss: 0.0895317
[Epoch 104; Iter   173/  229] train: loss: 0.1014163
[Epoch 104; Iter   203/  229] train: loss: 0.1345701
[Epoch 104] ogbg-moltoxcast: 0.677900 val loss: 0.282162
[Epoch 104] ogbg-moltoxcast: 0.651199 test loss: 0.340231
[Epoch 105; Iter     4/  229] train: loss: 0.1128015
[Epoch 105; Iter    34/  229] train: loss: 0.1002705
[Epoch 105; Iter    64/  229] train: loss: 0.1120539
[Epoch 105; Iter    94/  229] train: loss: 0.1147564
[Epoch 105; Iter   124/  229] train: loss: 0.0827798
[Epoch 105; Iter   154/  229] train: loss: 0.1031407
[Epoch 105; Iter   184/  229] train: loss: 0.1251205
[Epoch 105; Iter   214/  229] train: loss: 0.1382466
[Epoch 105] ogbg-moltoxcast: 0.679742 val loss: 0.286865
[Epoch 105] ogbg-moltoxcast: 0.652860 test loss: 0.342653
[Epoch 106; Iter    15/  229] train: loss: 0.0833461
[Epoch 106; Iter    45/  229] train: loss: 0.0869712
[Epoch 106; Iter    75/  229] train: loss: 0.1097369
[Epoch 106; Iter   105/  229] train: loss: 0.0960715
[Epoch 106; Iter   135/  229] train: loss: 0.1145002
[Epoch 106; Iter   165/  229] train: loss: 0.1020369
[Epoch 106; Iter   195/  229] train: loss: 0.1667242
[Epoch 106; Iter   225/  229] train: loss: 0.1341731
[Epoch 106] ogbg-moltoxcast: 0.676824 val loss: 0.284237
[Epoch 106] ogbg-moltoxcast: 0.652277 test loss: 0.338768
[Epoch 107; Iter    26/  229] train: loss: 0.0978217
[Epoch 107; Iter    56/  229] train: loss: 0.1169086
[Epoch 107; Iter    86/  229] train: loss: 0.1175827
[Epoch 107; Iter   116/  229] train: loss: 0.1275808
[Epoch 107; Iter   146/  229] train: loss: 0.1106245
[Epoch 107; Iter   176/  229] train: loss: 0.1559236
[Epoch 107; Iter   206/  229] train: loss: 0.1246511
[Epoch 107] ogbg-moltoxcast: 0.676298 val loss: 0.280204
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 101] ogbg-moltoxcast: 0.662640 val loss: 0.284652
[Epoch 101] ogbg-moltoxcast: 0.654456 test loss: 0.326881
[Epoch 102; Iter     9/  201] train: loss: 0.1194587
[Epoch 102; Iter    39/  201] train: loss: 0.1148837
[Epoch 102; Iter    69/  201] train: loss: 0.0773786
[Epoch 102; Iter    99/  201] train: loss: 0.1463531
[Epoch 102; Iter   129/  201] train: loss: 0.1268575
[Epoch 102; Iter   159/  201] train: loss: 0.1270765
[Epoch 102; Iter   189/  201] train: loss: 0.1237359
[Epoch 102] ogbg-moltoxcast: 0.662434 val loss: 0.285970
[Epoch 102] ogbg-moltoxcast: 0.653173 test loss: 0.327247
[Epoch 103; Iter    18/  201] train: loss: 0.0848064
[Epoch 103; Iter    48/  201] train: loss: 0.1310468
[Epoch 103; Iter    78/  201] train: loss: 0.0870860
[Epoch 103; Iter   108/  201] train: loss: 0.1441924
[Epoch 103; Iter   138/  201] train: loss: 0.1154249
[Epoch 103; Iter   168/  201] train: loss: 0.1461528
[Epoch 103; Iter   198/  201] train: loss: 0.1521482
[Epoch 103] ogbg-moltoxcast: 0.660104 val loss: 0.291139
[Epoch 103] ogbg-moltoxcast: 0.652056 test loss: 0.332267
[Epoch 104; Iter    27/  201] train: loss: 0.1204336
[Epoch 104; Iter    57/  201] train: loss: 0.1345518
[Epoch 104; Iter    87/  201] train: loss: 0.1311380
[Epoch 104; Iter   117/  201] train: loss: 0.0971060
[Epoch 104; Iter   147/  201] train: loss: 0.1533248
[Epoch 104; Iter   177/  201] train: loss: 0.1197801
[Epoch 104] ogbg-moltoxcast: 0.657563 val loss: 0.293517
[Epoch 104] ogbg-moltoxcast: 0.651592 test loss: 0.337551
[Epoch 105; Iter     6/  201] train: loss: 0.1123877
[Epoch 105; Iter    36/  201] train: loss: 0.1063335
[Epoch 105; Iter    66/  201] train: loss: 0.0941759
[Epoch 105; Iter    96/  201] train: loss: 0.0995319
[Epoch 105; Iter   126/  201] train: loss: 0.1556590
[Epoch 105; Iter   156/  201] train: loss: 0.0658477
[Epoch 105; Iter   186/  201] train: loss: 0.1438695
[Epoch 105] ogbg-moltoxcast: 0.662443 val loss: 0.289261
[Epoch 105] ogbg-moltoxcast: 0.650314 test loss: 0.333328
[Epoch 106; Iter    15/  201] train: loss: 0.1439832
[Epoch 106; Iter    45/  201] train: loss: 0.0889348
[Epoch 106; Iter    75/  201] train: loss: 0.1077910
[Epoch 106; Iter   105/  201] train: loss: 0.1246084
[Epoch 106; Iter   135/  201] train: loss: 0.1187257
[Epoch 106; Iter   165/  201] train: loss: 0.1113568
[Epoch 106; Iter   195/  201] train: loss: 0.1471216
[Epoch 106] ogbg-moltoxcast: 0.661787 val loss: 0.285851
[Epoch 106] ogbg-moltoxcast: 0.652708 test loss: 0.327375
[Epoch 107; Iter    24/  201] train: loss: 0.0774399
[Epoch 107; Iter    54/  201] train: loss: 0.1125599
[Epoch 107; Iter    84/  201] train: loss: 0.1236487
[Epoch 107; Iter   114/  201] train: loss: 0.1577407
[Epoch 107; Iter   144/  201] train: loss: 0.1350849
[Epoch 107; Iter   174/  201] train: loss: 0.1228268
[Epoch 107] ogbg-moltoxcast: 0.663869 val loss: 0.283721
[Epoch 107] ogbg-moltoxcast: 0.651673 test loss: 0.325831
[Epoch 108; Iter     3/  201] train: loss: 0.0712477
[Epoch 108; Iter    33/  201] train: loss: 0.1198898
[Epoch 108; Iter    63/  201] train: loss: 0.0973222
[Epoch 108; Iter    93/  201] train: loss: 0.1079789
[Epoch 108; Iter   123/  201] train: loss: 0.0802871
[Epoch 108; Iter   153/  201] train: loss: 0.0915730
[Epoch 108; Iter   183/  201] train: loss: 0.1155263
[Epoch 108] ogbg-moltoxcast: 0.659095 val loss: 0.281219
[Epoch 108] ogbg-moltoxcast: 0.650580 test loss: 0.321912
[Epoch 109; Iter    12/  201] train: loss: 0.1138978
[Epoch 109; Iter    42/  201] train: loss: 0.1216321
[Epoch 109; Iter    72/  201] train: loss: 0.1187119
[Epoch 109; Iter   102/  201] train: loss: 0.0847044
[Epoch 109; Iter   132/  201] train: loss: 0.0952847
[Epoch 109; Iter   162/  201] train: loss: 0.1012429
[Epoch 109; Iter   192/  201] train: loss: 0.1107372
[Epoch 109] ogbg-moltoxcast: 0.656569 val loss: 0.294352
[Epoch 109] ogbg-moltoxcast: 0.651947 test loss: 0.337213
[Epoch 110; Iter    21/  201] train: loss: 0.1071033
[Epoch 110; Iter    51/  201] train: loss: 0.1158621
[Epoch 110; Iter    81/  201] train: loss: 0.1465751
[Epoch 110; Iter   111/  201] train: loss: 0.1083726
[Epoch 110; Iter   141/  201] train: loss: 0.1099684
[Epoch 110; Iter   171/  201] train: loss: 0.1194856
[Epoch 110; Iter   201/  201] train: loss: 0.2909099
[Epoch 110] ogbg-moltoxcast: 0.661783 val loss: 0.286515
[Epoch 110] ogbg-moltoxcast: 0.652888 test loss: 0.328473
[Epoch 111; Iter    30/  201] train: loss: 0.0998874
[Epoch 111; Iter    60/  201] train: loss: 0.0910323
[Epoch 111; Iter    90/  201] train: loss: 0.1363249
[Epoch 111; Iter   120/  201] train: loss: 0.1177538
[Epoch 111; Iter   150/  201] train: loss: 0.1107564
[Epoch 111; Iter   180/  201] train: loss: 0.0907138
[Epoch 111] ogbg-moltoxcast: 0.660099 val loss: 0.288933
[Epoch 111] ogbg-moltoxcast: 0.651189 test loss: 0.334396
[Epoch 112; Iter     9/  201] train: loss: 0.1136274
[Epoch 112; Iter    39/  201] train: loss: 0.1285517
[Epoch 112; Iter    69/  201] train: loss: 0.1171712
[Epoch 112; Iter    99/  201] train: loss: 0.0920506
[Epoch 112; Iter   129/  201] train: loss: 0.0849203
[Epoch 112; Iter   159/  201] train: loss: 0.1735286
[Epoch 112; Iter   189/  201] train: loss: 0.1225106
[Epoch 112] ogbg-moltoxcast: 0.658760 val loss: 0.290165
[Epoch 112] ogbg-moltoxcast: 0.649584 test loss: 0.332805
[Epoch 113; Iter    18/  201] train: loss: 0.0985645
[Epoch 113; Iter    48/  201] train: loss: 0.1005660
[Epoch 113; Iter    78/  201] train: loss: 0.1533504
[Epoch 113; Iter   108/  201] train: loss: 0.1286652
[Epoch 113; Iter   138/  201] train: loss: 0.1066292
[Epoch 113; Iter   168/  201] train: loss: 0.1365600
[Epoch 113; Iter   198/  201] train: loss: 0.1415145
[Epoch 113] ogbg-moltoxcast: 0.658949 val loss: 0.289275
[Epoch 113] ogbg-moltoxcast: 0.651945 test loss: 0.332389
[Epoch 114; Iter    27/  201] train: loss: 0.1462889
[Epoch 114; Iter    57/  201] train: loss: 0.1288055
[Epoch 114; Iter    87/  201] train: loss: 0.1115293
[Epoch 114; Iter   117/  201] train: loss: 0.1199098
[Epoch 114; Iter   147/  201] train: loss: 0.0801805
[Epoch 114; Iter   177/  201] train: loss: 0.1421339
[Epoch 114] ogbg-moltoxcast: 0.658342 val loss: 0.287421
[Epoch 114] ogbg-moltoxcast: 0.654734 test loss: 0.327384
[Epoch 115; Iter     6/  201] train: loss: 0.1123170
[Epoch 115; Iter    36/  201] train: loss: 0.1521015
[Epoch 115; Iter    66/  201] train: loss: 0.1080367
[Epoch 115; Iter    96/  201] train: loss: 0.1335892
[Epoch 115; Iter   126/  201] train: loss: 0.1793602
[Epoch 115; Iter   156/  201] train: loss: 0.0837162
[Epoch 115; Iter   186/  201] train: loss: 0.0900894
[Epoch 115] ogbg-moltoxcast: 0.656621 val loss: 0.294653
[Epoch 115] ogbg-moltoxcast: 0.651332 test loss: 0.336501
[Epoch 116; Iter    15/  201] train: loss: 0.1372625
[Epoch 116; Iter    45/  201] train: loss: 0.0928565
[Epoch 116; Iter    75/  201] train: loss: 0.0662039
[Epoch 116; Iter   105/  201] train: loss: 0.1031862
[Epoch 116; Iter   135/  201] train: loss: 0.1193978
[Epoch 116; Iter   165/  201] train: loss: 0.0819664
[Epoch 116; Iter   195/  201] train: loss: 0.1166036
[Epoch 116] ogbg-moltoxcast: 0.661622 val loss: 0.288652
[Epoch 116] ogbg-moltoxcast: 0.651398 test loss: 0.334458
[Epoch 117; Iter    24/  201] train: loss: 0.1246879
[Epoch 117; Iter    54/  201] train: loss: 0.1177379
[Epoch 117; Iter    84/  201] train: loss: 0.1891085
[Epoch 117; Iter   114/  201] train: loss: 0.1354396
[Epoch 117; Iter   144/  201] train: loss: 0.0800629
[Epoch 117; Iter   174/  201] train: loss: 0.1291790
[Epoch 117] ogbg-moltoxcast: 0.658031 val loss: 0.290578
[Epoch 117] ogbg-moltoxcast: 0.649611 test loss: 0.333687
[Epoch 118; Iter     3/  201] train: loss: 0.1015833
[Epoch 118; Iter    33/  201] train: loss: 0.1159492
[Epoch 118; Iter    63/  201] train: loss: 0.1094119
[Epoch 118; Iter    93/  201] train: loss: 0.0973198
[Epoch 118; Iter   123/  201] train: loss: 0.1387282
[Epoch 118; Iter   153/  201] train: loss: 0.1232050
[Epoch 118; Iter   183/  201] train: loss: 0.1198996
[Epoch 118] ogbg-moltoxcast: 0.657455 val loss: 0.289287
[Epoch 118] ogbg-moltoxcast: 0.648097 test loss: 0.331410
[Epoch 119; Iter    12/  201] train: loss: 0.1293916

[Epoch 114; Iter    34/  172] train: loss: 0.0911371
[Epoch 114; Iter    64/  172] train: loss: 0.0803499
[Epoch 114; Iter    94/  172] train: loss: 0.1051656
[Epoch 114; Iter   124/  172] train: loss: 0.1624168
[Epoch 114; Iter   154/  172] train: loss: 0.0879018
[Epoch 114] ogbg-moltoxcast: 0.647263 val loss: 0.322831
[Epoch 114] ogbg-moltoxcast: 0.615057 test loss: 0.403985
[Epoch 115; Iter    12/  172] train: loss: 0.1338831
[Epoch 115; Iter    42/  172] train: loss: 0.0901214
[Epoch 115; Iter    72/  172] train: loss: 0.0843870
[Epoch 115; Iter   102/  172] train: loss: 0.0896117
[Epoch 115; Iter   132/  172] train: loss: 0.1034509
[Epoch 115; Iter   162/  172] train: loss: 0.0953092
[Epoch 115] ogbg-moltoxcast: 0.641178 val loss: 0.317343
[Epoch 115] ogbg-moltoxcast: 0.608296 test loss: 0.384245
[Epoch 116; Iter    20/  172] train: loss: 0.1003311
[Epoch 116; Iter    50/  172] train: loss: 0.0893320
[Epoch 116; Iter    80/  172] train: loss: 0.0941397
[Epoch 116; Iter   110/  172] train: loss: 0.1118277
[Epoch 116; Iter   140/  172] train: loss: 0.1007845
[Epoch 116; Iter   170/  172] train: loss: 0.0950753
[Epoch 116] ogbg-moltoxcast: 0.643607 val loss: 0.321149
[Epoch 116] ogbg-moltoxcast: 0.610753 test loss: 0.390455
[Epoch 117; Iter    28/  172] train: loss: 0.0845844
[Epoch 117; Iter    58/  172] train: loss: 0.1116263
[Epoch 117; Iter    88/  172] train: loss: 0.1430014
[Epoch 117; Iter   118/  172] train: loss: 0.0899246
[Epoch 117; Iter   148/  172] train: loss: 0.1190499
[Epoch 117] ogbg-moltoxcast: 0.637997 val loss: 0.326156
[Epoch 117] ogbg-moltoxcast: 0.605081 test loss: 0.394885
[Epoch 118; Iter     6/  172] train: loss: 0.0945372
[Epoch 118; Iter    36/  172] train: loss: 0.1288777
[Epoch 118; Iter    66/  172] train: loss: 0.0926697
[Epoch 118; Iter    96/  172] train: loss: 0.0807243
[Epoch 118; Iter   126/  172] train: loss: 0.0884307
[Epoch 118; Iter   156/  172] train: loss: 0.1181351
[Epoch 118] ogbg-moltoxcast: 0.643668 val loss: 0.321444
[Epoch 118] ogbg-moltoxcast: 0.607377 test loss: 0.393341
[Epoch 119; Iter    14/  172] train: loss: 0.1164136
[Epoch 119; Iter    44/  172] train: loss: 0.0698977
[Epoch 119; Iter    74/  172] train: loss: 0.0823277
[Epoch 119; Iter   104/  172] train: loss: 0.1161013
[Epoch 119; Iter   134/  172] train: loss: 0.0844011
[Epoch 119; Iter   164/  172] train: loss: 0.0796419
[Epoch 119] ogbg-moltoxcast: 0.635353 val loss: 0.324517
[Epoch 119] ogbg-moltoxcast: 0.605391 test loss: 0.393712
[Epoch 120; Iter    22/  172] train: loss: 0.0948405
[Epoch 120; Iter    52/  172] train: loss: 0.1019260
[Epoch 120; Iter    82/  172] train: loss: 0.0828249
[Epoch 120; Iter   112/  172] train: loss: 0.0891029
[Epoch 120; Iter   142/  172] train: loss: 0.0938205
[Epoch 120; Iter   172/  172] train: loss: 0.0747673
[Epoch 120] ogbg-moltoxcast: 0.640056 val loss: 0.319228
[Epoch 120] ogbg-moltoxcast: 0.611570 test loss: 0.384671
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 34.
Statistics on  val_best_checkpoint
mean_pred: -2.5925772190093994
std_pred: 2.631866931915283
mean_targets: nan
std_targets: nan
prcauc: 0.374818239757403
rocauc: 0.6795579603189206
ogbg-moltoxcast: 0.6795579603189206
OGBNanLabelBCEWithLogitsLoss: 0.2688866129209255
Statistics on  test
mean_pred: -2.4318020343780518
std_pred: 2.8074951171875
mean_targets: nan
std_targets: nan
prcauc: 0.32011199114448563
rocauc: 0.6305783387041614
ogbg-moltoxcast: 0.6305783387041614
OGBNanLabelBCEWithLogitsLoss: 0.3269516689510181
Statistics on  train
mean_pred: -3.203321695327759
std_pred: 2.3937079906463623
mean_targets: nan
std_targets: nan
prcauc: 0.5387973756972761
rocauc: 0.8617813509231991
ogbg-moltoxcast: 0.8617813509231991
OGBNanLabelBCEWithLogitsLoss: 0.13938858303739582
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)

[Epoch 114; Iter    34/  172] train: loss: 0.0793886
[Epoch 114; Iter    64/  172] train: loss: 0.0741001
[Epoch 114; Iter    94/  172] train: loss: 0.1030432
[Epoch 114; Iter   124/  172] train: loss: 0.0828413
[Epoch 114; Iter   154/  172] train: loss: 0.1332365
[Epoch 114] ogbg-moltoxcast: 0.639005 val loss: 0.325422
[Epoch 114] ogbg-moltoxcast: 0.620776 test loss: 0.388096
[Epoch 115; Iter    12/  172] train: loss: 0.1313688
[Epoch 115; Iter    42/  172] train: loss: 0.0826625
[Epoch 115; Iter    72/  172] train: loss: 0.1378886
[Epoch 115; Iter   102/  172] train: loss: 0.0974846
[Epoch 115; Iter   132/  172] train: loss: 0.1184529
[Epoch 115; Iter   162/  172] train: loss: 0.0676729
[Epoch 115] ogbg-moltoxcast: 0.643712 val loss: 0.315850
[Epoch 115] ogbg-moltoxcast: 0.621266 test loss: 0.374361
[Epoch 116; Iter    20/  172] train: loss: 0.1103866
[Epoch 116; Iter    50/  172] train: loss: 0.1534911
[Epoch 116; Iter    80/  172] train: loss: 0.1051759
[Epoch 116; Iter   110/  172] train: loss: 0.0816797
[Epoch 116; Iter   140/  172] train: loss: 0.1006163
[Epoch 116; Iter   170/  172] train: loss: 0.1182912
[Epoch 116] ogbg-moltoxcast: 0.640021 val loss: 0.320169
[Epoch 116] ogbg-moltoxcast: 0.616363 test loss: 0.380774
[Epoch 117; Iter    28/  172] train: loss: 0.0948211
[Epoch 117; Iter    58/  172] train: loss: 0.1141143
[Epoch 117; Iter    88/  172] train: loss: 0.1398453
[Epoch 117; Iter   118/  172] train: loss: 0.1052073
[Epoch 117; Iter   148/  172] train: loss: 0.0760086
[Epoch 117] ogbg-moltoxcast: 0.634123 val loss: 0.325103
[Epoch 117] ogbg-moltoxcast: 0.614070 test loss: 0.384908
[Epoch 118; Iter     6/  172] train: loss: 0.1451866
[Epoch 118; Iter    36/  172] train: loss: 0.1040631
[Epoch 118; Iter    66/  172] train: loss: 0.1325275
[Epoch 118; Iter    96/  172] train: loss: 0.1097986
[Epoch 118; Iter   126/  172] train: loss: 0.0598472
[Epoch 118; Iter   156/  172] train: loss: 0.1311389
[Epoch 118] ogbg-moltoxcast: 0.637726 val loss: 0.316971
[Epoch 118] ogbg-moltoxcast: 0.617597 test loss: 0.373935
[Epoch 119; Iter    14/  172] train: loss: 0.1103336
[Epoch 119; Iter    44/  172] train: loss: 0.1070458
[Epoch 119; Iter    74/  172] train: loss: 0.0834829
[Epoch 119; Iter   104/  172] train: loss: 0.0759377
[Epoch 119; Iter   134/  172] train: loss: 0.1063811
[Epoch 119; Iter   164/  172] train: loss: 0.0927238
[Epoch 119] ogbg-moltoxcast: 0.643434 val loss: 0.325878
[Epoch 119] ogbg-moltoxcast: 0.621462 test loss: 0.385293
[Epoch 120; Iter    22/  172] train: loss: 0.1522473
[Epoch 120; Iter    52/  172] train: loss: 0.1004301
[Epoch 120; Iter    82/  172] train: loss: 0.1206172
[Epoch 120; Iter   112/  172] train: loss: 0.0962719
[Epoch 120; Iter   142/  172] train: loss: 0.0999362
[Epoch 120; Iter   172/  172] train: loss: 0.0829825
[Epoch 120] ogbg-moltoxcast: 0.635614 val loss: 0.329390
[Epoch 120] ogbg-moltoxcast: 0.614549 test loss: 0.393220
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 34.
Statistics on  val_best_checkpoint
mean_pred: -2.849344491958618
std_pred: 2.378847122192383
mean_targets: nan
std_targets: nan
prcauc: 0.3924097022988107
rocauc: 0.6841371967543953
ogbg-moltoxcast: 0.6841371967543953
OGBNanLabelBCEWithLogitsLoss: 0.2598310308209781
Statistics on  test
mean_pred: -2.761155605316162
std_pred: 2.4802184104919434
mean_targets: nan
std_targets: nan
prcauc: 0.32179771076886077
rocauc: 0.631456002624153
ogbg-moltoxcast: 0.631456002624153
OGBNanLabelBCEWithLogitsLoss: 0.3142297578782871
Statistics on  train
mean_pred: -3.312044143676758
std_pred: 2.3038864135742188
mean_targets: nan
std_targets: nan
prcauc: 0.5359072006047354
rocauc: 0.8604995166961882
ogbg-moltoxcast: 0.8604995166961882
OGBNanLabelBCEWithLogitsLoss: 0.14050235122788785

[Epoch 114; Iter    34/  172] train: loss: 0.1404002
[Epoch 114; Iter    64/  172] train: loss: 0.1358950
[Epoch 114; Iter    94/  172] train: loss: 0.0789868
[Epoch 114; Iter   124/  172] train: loss: 0.1405486
[Epoch 114; Iter   154/  172] train: loss: 0.1097312
[Epoch 114] ogbg-moltoxcast: 0.647415 val loss: 0.315926
[Epoch 114] ogbg-moltoxcast: 0.612103 test loss: 0.366310
[Epoch 115; Iter    12/  172] train: loss: 0.0743227
[Epoch 115; Iter    42/  172] train: loss: 0.1265185
[Epoch 115; Iter    72/  172] train: loss: 0.1259923
[Epoch 115; Iter   102/  172] train: loss: 0.1156163
[Epoch 115; Iter   132/  172] train: loss: 0.1287399
[Epoch 115; Iter   162/  172] train: loss: 0.0974727
[Epoch 115] ogbg-moltoxcast: 0.651140 val loss: 0.314732
[Epoch 115] ogbg-moltoxcast: 0.613193 test loss: 0.368788
[Epoch 116; Iter    20/  172] train: loss: 0.1543048
[Epoch 116; Iter    50/  172] train: loss: 0.1307772
[Epoch 116; Iter    80/  172] train: loss: 0.1107679
[Epoch 116; Iter   110/  172] train: loss: 0.1495840
[Epoch 116; Iter   140/  172] train: loss: 0.1145595
[Epoch 116; Iter   170/  172] train: loss: 0.1169927
[Epoch 116] ogbg-moltoxcast: 0.647538 val loss: 0.314913
[Epoch 116] ogbg-moltoxcast: 0.613889 test loss: 0.372769
[Epoch 117; Iter    28/  172] train: loss: 0.1152887
[Epoch 117; Iter    58/  172] train: loss: 0.1107864
[Epoch 117; Iter    88/  172] train: loss: 0.1155864
[Epoch 117; Iter   118/  172] train: loss: 0.1268174
[Epoch 117; Iter   148/  172] train: loss: 0.0810449
[Epoch 117] ogbg-moltoxcast: 0.652085 val loss: 0.313852
[Epoch 117] ogbg-moltoxcast: 0.614076 test loss: 0.373846
[Epoch 118; Iter     6/  172] train: loss: 0.1365736
[Epoch 118; Iter    36/  172] train: loss: 0.1024133
[Epoch 118; Iter    66/  172] train: loss: 0.1339396
[Epoch 118; Iter    96/  172] train: loss: 0.0791677
[Epoch 118; Iter   126/  172] train: loss: 0.0940828
[Epoch 118; Iter   156/  172] train: loss: 0.1174213
[Epoch 118] ogbg-moltoxcast: 0.649332 val loss: 0.311996
[Epoch 118] ogbg-moltoxcast: 0.614853 test loss: 0.364934
[Epoch 119; Iter    14/  172] train: loss: 0.1355267
[Epoch 119; Iter    44/  172] train: loss: 0.0763959
[Epoch 119; Iter    74/  172] train: loss: 0.0880426
[Epoch 119; Iter   104/  172] train: loss: 0.0751868
[Epoch 119; Iter   134/  172] train: loss: 0.1033634
[Epoch 119; Iter   164/  172] train: loss: 0.1396734
[Epoch 119] ogbg-moltoxcast: 0.651346 val loss: 0.313270
[Epoch 119] ogbg-moltoxcast: 0.617660 test loss: 0.366867
[Epoch 120; Iter    22/  172] train: loss: 0.1287159
[Epoch 120; Iter    52/  172] train: loss: 0.0970092
[Epoch 120; Iter    82/  172] train: loss: 0.1179105
[Epoch 120; Iter   112/  172] train: loss: 0.0845399
[Epoch 120; Iter   142/  172] train: loss: 0.1154909
[Epoch 120; Iter   172/  172] train: loss: 0.1195956
[Epoch 120] ogbg-moltoxcast: 0.647738 val loss: 0.314997
[Epoch 120] ogbg-moltoxcast: 0.613256 test loss: 0.368731
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 24.
Statistics on  val_best_checkpoint
mean_pred: -2.4931681156158447
std_pred: 2.233327627182007
mean_targets: nan
std_targets: nan
prcauc: 0.3770152393873853
rocauc: 0.6872554084426488
ogbg-moltoxcast: 0.6872554084426488
OGBNanLabelBCEWithLogitsLoss: 0.2591297848728196
Statistics on  test
mean_pred: -2.3444793224334717
std_pred: 2.322842836380005
mean_targets: nan
std_targets: nan
prcauc: 0.31683713624046994
rocauc: 0.6287242630459643
ogbg-moltoxcast: 0.6287242630459643
OGBNanLabelBCEWithLogitsLoss: 0.311669889195212
Statistics on  train
mean_pred: -2.9835379123687744
std_pred: 2.139775037765503
mean_targets: nan
std_targets: nan
prcauc: 0.4783185467641915
rocauc: 0.8309949872692814
ogbg-moltoxcast: 0.8309949872692814
OGBNanLabelBCEWithLogitsLoss: 0.1516875449654668
All runs completed.
[Epoch 101] ogbg-moltoxcast: 0.661117 val loss: 0.288524
[Epoch 101] ogbg-moltoxcast: 0.657463 test loss: 0.339204
[Epoch 102; Iter     9/  201] train: loss: 0.1077299
[Epoch 102; Iter    39/  201] train: loss: 0.1259150
[Epoch 102; Iter    69/  201] train: loss: 0.1629103
[Epoch 102; Iter    99/  201] train: loss: 0.1203435
[Epoch 102; Iter   129/  201] train: loss: 0.1451703
[Epoch 102; Iter   159/  201] train: loss: 0.1203511
[Epoch 102; Iter   189/  201] train: loss: 0.0926453
[Epoch 102] ogbg-moltoxcast: 0.662533 val loss: 0.289096
[Epoch 102] ogbg-moltoxcast: 0.651811 test loss: 0.339060
[Epoch 103; Iter    18/  201] train: loss: 0.0772934
[Epoch 103; Iter    48/  201] train: loss: 0.1102802
[Epoch 103; Iter    78/  201] train: loss: 0.1102226
[Epoch 103; Iter   108/  201] train: loss: 0.1204231
[Epoch 103; Iter   138/  201] train: loss: 0.0774852
[Epoch 103; Iter   168/  201] train: loss: 0.1406797
[Epoch 103; Iter   198/  201] train: loss: 0.1019864
[Epoch 103] ogbg-moltoxcast: 0.663355 val loss: 0.289141
[Epoch 103] ogbg-moltoxcast: 0.650805 test loss: 0.342155
[Epoch 104; Iter    27/  201] train: loss: 0.0811227
[Epoch 104; Iter    57/  201] train: loss: 0.1125060
[Epoch 104; Iter    87/  201] train: loss: 0.0959674
[Epoch 104; Iter   117/  201] train: loss: 0.0836050
[Epoch 104; Iter   147/  201] train: loss: 0.1305815
[Epoch 104; Iter   177/  201] train: loss: 0.1390808
[Epoch 104] ogbg-moltoxcast: 0.657870 val loss: 0.291452
[Epoch 104] ogbg-moltoxcast: 0.650464 test loss: 0.343734
[Epoch 105; Iter     6/  201] train: loss: 0.1464745
[Epoch 105; Iter    36/  201] train: loss: 0.1422524
[Epoch 105; Iter    66/  201] train: loss: 0.1003990
[Epoch 105; Iter    96/  201] train: loss: 0.1196050
[Epoch 105; Iter   126/  201] train: loss: 0.1284921
[Epoch 105; Iter   156/  201] train: loss: 0.1038893
[Epoch 105; Iter   186/  201] train: loss: 0.0778266
[Epoch 105] ogbg-moltoxcast: 0.660438 val loss: 0.288892
[Epoch 105] ogbg-moltoxcast: 0.651800 test loss: 0.342943
[Epoch 106; Iter    15/  201] train: loss: 0.0750247
[Epoch 106; Iter    45/  201] train: loss: 0.0984549
[Epoch 106; Iter    75/  201] train: loss: 0.0959277
[Epoch 106; Iter   105/  201] train: loss: 0.1183881
[Epoch 106; Iter   135/  201] train: loss: 0.0647206
[Epoch 106; Iter   165/  201] train: loss: 0.1328658
[Epoch 106; Iter   195/  201] train: loss: 0.1376460
[Epoch 106] ogbg-moltoxcast: 0.652971 val loss: 0.304444
[Epoch 106] ogbg-moltoxcast: 0.649044 test loss: 0.359132
[Epoch 107; Iter    24/  201] train: loss: 0.0806371
[Epoch 107; Iter    54/  201] train: loss: 0.1092233
[Epoch 107; Iter    84/  201] train: loss: 0.1163911
[Epoch 107; Iter   114/  201] train: loss: 0.1300527
[Epoch 107; Iter   144/  201] train: loss: 0.1271256
[Epoch 107; Iter   174/  201] train: loss: 0.1269902
[Epoch 107] ogbg-moltoxcast: 0.661895 val loss: 0.295606
[Epoch 107] ogbg-moltoxcast: 0.650366 test loss: 0.351910
[Epoch 108; Iter     3/  201] train: loss: 0.1036741
[Epoch 108; Iter    33/  201] train: loss: 0.1143240
[Epoch 108; Iter    63/  201] train: loss: 0.1205388
[Epoch 108; Iter    93/  201] train: loss: 0.1351389
[Epoch 108; Iter   123/  201] train: loss: 0.1726610
[Epoch 108; Iter   153/  201] train: loss: 0.1728006
[Epoch 108; Iter   183/  201] train: loss: 0.1057810
[Epoch 108] ogbg-moltoxcast: 0.660902 val loss: 0.294200
[Epoch 108] ogbg-moltoxcast: 0.654124 test loss: 0.348764
[Epoch 109; Iter    12/  201] train: loss: 0.1263282
[Epoch 109; Iter    42/  201] train: loss: 0.1002218
[Epoch 109; Iter    72/  201] train: loss: 0.1034237
[Epoch 109; Iter   102/  201] train: loss: 0.1172032
[Epoch 109; Iter   132/  201] train: loss: 0.1139802
[Epoch 109; Iter   162/  201] train: loss: 0.1412292
[Epoch 109; Iter   192/  201] train: loss: 0.1002418
[Epoch 109] ogbg-moltoxcast: 0.660583 val loss: 0.290501
[Epoch 109] ogbg-moltoxcast: 0.650191 test loss: 0.340799
[Epoch 110; Iter    21/  201] train: loss: 0.1574638
[Epoch 110; Iter    51/  201] train: loss: 0.0874340
[Epoch 110; Iter    81/  201] train: loss: 0.1323628
[Epoch 110; Iter   111/  201] train: loss: 0.1604934
[Epoch 110; Iter   141/  201] train: loss: 0.0918173
[Epoch 110; Iter   171/  201] train: loss: 0.1425754
[Epoch 110; Iter   201/  201] train: loss: 0.1483385
[Epoch 110] ogbg-moltoxcast: 0.663544 val loss: 0.289905
[Epoch 110] ogbg-moltoxcast: 0.652530 test loss: 0.341897
[Epoch 111; Iter    30/  201] train: loss: 0.1222160
[Epoch 111; Iter    60/  201] train: loss: 0.0996333
[Epoch 111; Iter    90/  201] train: loss: 0.1160094
[Epoch 111; Iter   120/  201] train: loss: 0.0919758
[Epoch 111; Iter   150/  201] train: loss: 0.0687095
[Epoch 111; Iter   180/  201] train: loss: 0.1001723
[Epoch 111] ogbg-moltoxcast: 0.654952 val loss: 0.296350
[Epoch 111] ogbg-moltoxcast: 0.642440 test loss: 0.350149
[Epoch 112; Iter     9/  201] train: loss: 0.1019254
[Epoch 112; Iter    39/  201] train: loss: 0.1214180
[Epoch 112; Iter    69/  201] train: loss: 0.1178585
[Epoch 112; Iter    99/  201] train: loss: 0.1248242
[Epoch 112; Iter   129/  201] train: loss: 0.1066650
[Epoch 112; Iter   159/  201] train: loss: 0.1428390
[Epoch 112; Iter   189/  201] train: loss: 0.0777920
[Epoch 112] ogbg-moltoxcast: 0.657877 val loss: 0.299935
[Epoch 112] ogbg-moltoxcast: 0.650900 test loss: 0.355680
[Epoch 113; Iter    18/  201] train: loss: 0.0918602
[Epoch 113; Iter    48/  201] train: loss: 0.1027280
[Epoch 113; Iter    78/  201] train: loss: 0.1431616
[Epoch 113; Iter   108/  201] train: loss: 0.1521159
[Epoch 113; Iter   138/  201] train: loss: 0.1075666
[Epoch 113; Iter   168/  201] train: loss: 0.0831174
[Epoch 113; Iter   198/  201] train: loss: 0.1104526
[Epoch 113] ogbg-moltoxcast: 0.665194 val loss: 0.287278
[Epoch 113] ogbg-moltoxcast: 0.654329 test loss: 0.340559
[Epoch 114; Iter    27/  201] train: loss: 0.1200192
[Epoch 114; Iter    57/  201] train: loss: 0.1144541
[Epoch 114; Iter    87/  201] train: loss: 0.1024757
[Epoch 114; Iter   117/  201] train: loss: 0.1419910
[Epoch 114; Iter   147/  201] train: loss: 0.1006318
[Epoch 114; Iter   177/  201] train: loss: 0.1098972
[Epoch 114] ogbg-moltoxcast: 0.664967 val loss: 0.290428
[Epoch 114] ogbg-moltoxcast: 0.650485 test loss: 0.343275
[Epoch 115; Iter     6/  201] train: loss: 0.0928642
[Epoch 115; Iter    36/  201] train: loss: 0.1714305
[Epoch 115; Iter    66/  201] train: loss: 0.1362175
[Epoch 115; Iter    96/  201] train: loss: 0.0993934
[Epoch 115; Iter   126/  201] train: loss: 0.1476654
[Epoch 115; Iter   156/  201] train: loss: 0.1067474
[Epoch 115; Iter   186/  201] train: loss: 0.1124386
[Epoch 115] ogbg-moltoxcast: 0.662866 val loss: 0.294709
[Epoch 115] ogbg-moltoxcast: 0.651656 test loss: 0.348985
[Epoch 116; Iter    15/  201] train: loss: 0.0814532
[Epoch 116; Iter    45/  201] train: loss: 0.0953660
[Epoch 116; Iter    75/  201] train: loss: 0.1082156
[Epoch 116; Iter   105/  201] train: loss: 0.1017202
[Epoch 116; Iter   135/  201] train: loss: 0.0955284
[Epoch 116; Iter   165/  201] train: loss: 0.1118741
[Epoch 116; Iter   195/  201] train: loss: 0.1653389
[Epoch 116] ogbg-moltoxcast: 0.662796 val loss: 0.292124
[Epoch 116] ogbg-moltoxcast: 0.653491 test loss: 0.347348
[Epoch 117; Iter    24/  201] train: loss: 0.1267992
[Epoch 117; Iter    54/  201] train: loss: 0.1254782
[Epoch 117; Iter    84/  201] train: loss: 0.0637475
[Epoch 117; Iter   114/  201] train: loss: 0.1177745
[Epoch 117; Iter   144/  201] train: loss: 0.1388984
[Epoch 117; Iter   174/  201] train: loss: 0.0833206
[Epoch 117] ogbg-moltoxcast: 0.664907 val loss: 0.293869
[Epoch 117] ogbg-moltoxcast: 0.653452 test loss: 0.348482
[Epoch 118; Iter     3/  201] train: loss: 0.1012783
[Epoch 118; Iter    33/  201] train: loss: 0.1471494
[Epoch 118; Iter    63/  201] train: loss: 0.1007360
[Epoch 118; Iter    93/  201] train: loss: 0.0993602
[Epoch 118; Iter   123/  201] train: loss: 0.1324962
[Epoch 118; Iter   153/  201] train: loss: 0.1062128
[Epoch 118; Iter   183/  201] train: loss: 0.1866353
[Epoch 118] ogbg-moltoxcast: 0.662548 val loss: 0.291252
[Epoch 118] ogbg-moltoxcast: 0.646630 test loss: 0.347652
[Epoch 119; Iter    12/  201] train: loss: 0.1434015
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 101] ogbg-moltoxcast: 0.679347 val loss: 0.276775
[Epoch 101] ogbg-moltoxcast: 0.653984 test loss: 0.323478
[Epoch 102; Iter     9/  201] train: loss: 0.1727341
[Epoch 102; Iter    39/  201] train: loss: 0.1235181
[Epoch 102; Iter    69/  201] train: loss: 0.1182950
[Epoch 102; Iter    99/  201] train: loss: 0.1519257
[Epoch 102; Iter   129/  201] train: loss: 0.1034446
[Epoch 102; Iter   159/  201] train: loss: 0.1032255
[Epoch 102; Iter   189/  201] train: loss: 0.1186648
[Epoch 102] ogbg-moltoxcast: 0.678770 val loss: 0.290500
[Epoch 102] ogbg-moltoxcast: 0.656969 test loss: 0.335967
[Epoch 103; Iter    18/  201] train: loss: 0.1035190
[Epoch 103; Iter    48/  201] train: loss: 0.1432987
[Epoch 103; Iter    78/  201] train: loss: 0.1122522
[Epoch 103; Iter   108/  201] train: loss: 0.1416356
[Epoch 103; Iter   138/  201] train: loss: 0.1042731
[Epoch 103; Iter   168/  201] train: loss: 0.1312875
[Epoch 103; Iter   198/  201] train: loss: 0.1015809
[Epoch 103] ogbg-moltoxcast: 0.680629 val loss: 0.287138
[Epoch 103] ogbg-moltoxcast: 0.664002 test loss: 0.335148
[Epoch 104; Iter    27/  201] train: loss: 0.1122810
[Epoch 104; Iter    57/  201] train: loss: 0.1620586
[Epoch 104; Iter    87/  201] train: loss: 0.0901992
[Epoch 104; Iter   117/  201] train: loss: 0.1104658
[Epoch 104; Iter   147/  201] train: loss: 0.1357346
[Epoch 104; Iter   177/  201] train: loss: 0.1141150
[Epoch 104] ogbg-moltoxcast: 0.677596 val loss: 0.283272
[Epoch 104] ogbg-moltoxcast: 0.661607 test loss: 0.329378
[Epoch 105; Iter     6/  201] train: loss: 0.1061574
[Epoch 105; Iter    36/  201] train: loss: 0.2281302
[Epoch 105; Iter    66/  201] train: loss: 0.1312291
[Epoch 105; Iter    96/  201] train: loss: 0.1099534
[Epoch 105; Iter   126/  201] train: loss: 0.1153528
[Epoch 105; Iter   156/  201] train: loss: 0.1097682
[Epoch 105; Iter   186/  201] train: loss: 0.1006919
[Epoch 105] ogbg-moltoxcast: 0.678151 val loss: 0.285189
[Epoch 105] ogbg-moltoxcast: 0.655980 test loss: 0.332907
[Epoch 106; Iter    15/  201] train: loss: 0.1374632
[Epoch 106; Iter    45/  201] train: loss: 0.1109448
[Epoch 106; Iter    75/  201] train: loss: 0.1095325
[Epoch 106; Iter   105/  201] train: loss: 0.1292788
[Epoch 106; Iter   135/  201] train: loss: 0.1253790
[Epoch 106; Iter   165/  201] train: loss: 0.0908720
[Epoch 106; Iter   195/  201] train: loss: 0.0988541
[Epoch 106] ogbg-moltoxcast: 0.675878 val loss: 0.288484
[Epoch 106] ogbg-moltoxcast: 0.658196 test loss: 0.339233
[Epoch 107; Iter    24/  201] train: loss: 0.1255001
[Epoch 107; Iter    54/  201] train: loss: 0.1052417
[Epoch 107; Iter    84/  201] train: loss: 0.1338087
[Epoch 107; Iter   114/  201] train: loss: 0.1041345
[Epoch 107; Iter   144/  201] train: loss: 0.1547344
[Epoch 107; Iter   174/  201] train: loss: 0.1247924
[Epoch 107] ogbg-moltoxcast: 0.678486 val loss: 0.283854
[Epoch 107] ogbg-moltoxcast: 0.656544 test loss: 0.329218
[Epoch 108; Iter     3/  201] train: loss: 0.1087141
[Epoch 108; Iter    33/  201] train: loss: 0.1113366
[Epoch 108; Iter    63/  201] train: loss: 0.1252683
[Epoch 108; Iter    93/  201] train: loss: 0.0912462
[Epoch 108; Iter   123/  201] train: loss: 0.1004352
[Epoch 108; Iter   153/  201] train: loss: 0.1173243
[Epoch 108; Iter   183/  201] train: loss: 0.1114480
[Epoch 108] ogbg-moltoxcast: 0.678834 val loss: 0.281072
[Epoch 108] ogbg-moltoxcast: 0.656661 test loss: 0.328769
[Epoch 109; Iter    12/  201] train: loss: 0.1077388
[Epoch 109; Iter    42/  201] train: loss: 0.1574522
[Epoch 109; Iter    72/  201] train: loss: 0.1029967
[Epoch 109; Iter   102/  201] train: loss: 0.1148841
[Epoch 109; Iter   132/  201] train: loss: 0.1063985
[Epoch 109; Iter   162/  201] train: loss: 0.1010103
[Epoch 109; Iter   192/  201] train: loss: 0.1295109
[Epoch 109] ogbg-moltoxcast: 0.679638 val loss: 0.295144
[Epoch 109] ogbg-moltoxcast: 0.663873 test loss: 0.344894
[Epoch 110; Iter    21/  201] train: loss: 0.1196674
[Epoch 110; Iter    51/  201] train: loss: 0.1094460
[Epoch 110; Iter    81/  201] train: loss: 0.1069122
[Epoch 110; Iter   111/  201] train: loss: 0.1094141
[Epoch 110; Iter   141/  201] train: loss: 0.1369289
[Epoch 110; Iter   171/  201] train: loss: 0.1095212
[Epoch 110; Iter   201/  201] train: loss: 0.0788624
[Epoch 110] ogbg-moltoxcast: 0.681929 val loss: 0.284977
[Epoch 110] ogbg-moltoxcast: 0.659426 test loss: 0.331252
[Epoch 111; Iter    30/  201] train: loss: 0.1280860
[Epoch 111; Iter    60/  201] train: loss: 0.1141152
[Epoch 111; Iter    90/  201] train: loss: 0.1077267
[Epoch 111; Iter   120/  201] train: loss: 0.1342780
[Epoch 111; Iter   150/  201] train: loss: 0.1184875
[Epoch 111; Iter   180/  201] train: loss: 0.1124109
[Epoch 111] ogbg-moltoxcast: 0.678548 val loss: 0.281286
[Epoch 111] ogbg-moltoxcast: 0.659122 test loss: 0.327097
[Epoch 112; Iter     9/  201] train: loss: 0.1143929
[Epoch 112; Iter    39/  201] train: loss: 0.1091820
[Epoch 112; Iter    69/  201] train: loss: 0.1423226
[Epoch 112; Iter    99/  201] train: loss: 0.1449465
[Epoch 112; Iter   129/  201] train: loss: 0.0915540
[Epoch 112; Iter   159/  201] train: loss: 0.1456504
[Epoch 112; Iter   189/  201] train: loss: 0.1168050
[Epoch 112] ogbg-moltoxcast: 0.681032 val loss: 0.285279
[Epoch 112] ogbg-moltoxcast: 0.657348 test loss: 0.335474
[Epoch 113; Iter    18/  201] train: loss: 0.1297261
[Epoch 113; Iter    48/  201] train: loss: 0.0978664
[Epoch 113; Iter    78/  201] train: loss: 0.1160222
[Epoch 113; Iter   108/  201] train: loss: 0.1157564
[Epoch 113; Iter   138/  201] train: loss: 0.1122572
[Epoch 113; Iter   168/  201] train: loss: 0.0992875
[Epoch 113; Iter   198/  201] train: loss: 0.0822174
[Epoch 113] ogbg-moltoxcast: 0.674930 val loss: 0.289823
[Epoch 113] ogbg-moltoxcast: 0.658256 test loss: 0.336887
[Epoch 114; Iter    27/  201] train: loss: 0.1121109
[Epoch 114; Iter    57/  201] train: loss: 0.0996802
[Epoch 114; Iter    87/  201] train: loss: 0.1099318
[Epoch 114; Iter   117/  201] train: loss: 0.1595160
[Epoch 114; Iter   147/  201] train: loss: 0.1080786
[Epoch 114; Iter   177/  201] train: loss: 0.1063181
[Epoch 114] ogbg-moltoxcast: 0.677678 val loss: 0.292110
[Epoch 114] ogbg-moltoxcast: 0.659488 test loss: 0.340677
[Epoch 115; Iter     6/  201] train: loss: 0.1355531
[Epoch 115; Iter    36/  201] train: loss: 0.0958689
[Epoch 115; Iter    66/  201] train: loss: 0.1260232
[Epoch 115; Iter    96/  201] train: loss: 0.1151652
[Epoch 115; Iter   126/  201] train: loss: 0.1123987
[Epoch 115; Iter   156/  201] train: loss: 0.1347544
[Epoch 115; Iter   186/  201] train: loss: 0.1209901
[Epoch 115] ogbg-moltoxcast: 0.676077 val loss: 0.297763
[Epoch 115] ogbg-moltoxcast: 0.657034 test loss: 0.344431
[Epoch 116; Iter    15/  201] train: loss: 0.0865374
[Epoch 116; Iter    45/  201] train: loss: 0.0835970
[Epoch 116; Iter    75/  201] train: loss: 0.1560238
[Epoch 116; Iter   105/  201] train: loss: 0.0952389
[Epoch 116; Iter   135/  201] train: loss: 0.1378198
[Epoch 116; Iter   165/  201] train: loss: 0.1261973
[Epoch 116; Iter   195/  201] train: loss: 0.1361997
[Epoch 116] ogbg-moltoxcast: 0.672898 val loss: 0.287949
[Epoch 116] ogbg-moltoxcast: 0.656246 test loss: 0.334871
[Epoch 117; Iter    24/  201] train: loss: 0.1171970
[Epoch 117; Iter    54/  201] train: loss: 0.0948872
[Epoch 117; Iter    84/  201] train: loss: 0.1156219
[Epoch 117; Iter   114/  201] train: loss: 0.1038971
[Epoch 117; Iter   144/  201] train: loss: 0.0992292
[Epoch 117; Iter   174/  201] train: loss: 0.1343615
[Epoch 117] ogbg-moltoxcast: 0.677715 val loss: 0.285471
[Epoch 117] ogbg-moltoxcast: 0.656143 test loss: 0.332655
[Epoch 118; Iter     3/  201] train: loss: 0.1409750
[Epoch 118; Iter    33/  201] train: loss: 0.1508631
[Epoch 118; Iter    63/  201] train: loss: 0.0818374
[Epoch 118; Iter    93/  201] train: loss: 0.1761900
[Epoch 118; Iter   123/  201] train: loss: 0.1064737
[Epoch 118; Iter   153/  201] train: loss: 0.1293975
[Epoch 118; Iter   183/  201] train: loss: 0.0795217
[Epoch 118] ogbg-moltoxcast: 0.678274 val loss: 0.286974
[Epoch 118] ogbg-moltoxcast: 0.655010 test loss: 0.336110
[Epoch 119; Iter    12/  201] train: loss: 0.1268046
[Epoch 119; Iter    42/  201] train: loss: 0.1538921
[Epoch 119; Iter    72/  201] train: loss: 0.1308288
[Epoch 119; Iter   102/  201] train: loss: 0.1279753
[Epoch 119; Iter   132/  201] train: loss: 0.0892894
[Epoch 119; Iter   162/  201] train: loss: 0.1248097
[Epoch 119; Iter   192/  201] train: loss: 0.1154464
[Epoch 119] ogbg-moltoxcast: 0.657443 val loss: 0.298530
[Epoch 119] ogbg-moltoxcast: 0.649782 test loss: 0.344592
[Epoch 120; Iter    21/  201] train: loss: 0.1523640
[Epoch 120; Iter    51/  201] train: loss: 0.0777975
[Epoch 120; Iter    81/  201] train: loss: 0.1201422
[Epoch 120; Iter   111/  201] train: loss: 0.1042271
[Epoch 120; Iter   141/  201] train: loss: 0.0854748
[Epoch 120; Iter   171/  201] train: loss: 0.0950930
[Epoch 120; Iter   201/  201] train: loss: 0.0324174
[Epoch 120] ogbg-moltoxcast: 0.653289 val loss: 0.289133
[Epoch 120] ogbg-moltoxcast: 0.645763 test loss: 0.332401
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 53.
Statistics on  val_best_checkpoint
mean_pred: -2.6201107501983643
std_pred: 2.6365110874176025
mean_targets: nan
std_targets: nan
prcauc: 0.37684309435466556
rocauc: 0.6812696081097834
ogbg-moltoxcast: 0.6812696081097834
OGBNanLabelBCEWithLogitsLoss: 0.2626929692057676
Statistics on  test
mean_pred: -2.446377992630005
std_pred: 2.701554536819458
mean_targets: nan
std_targets: nan
prcauc: 0.35151693522970195
rocauc: 0.6692032188770672
ogbg-moltoxcast: 0.6692032188770672
OGBNanLabelBCEWithLogitsLoss: 0.3093805372021919
Statistics on  train
mean_pred: -3.390676259994507
std_pred: 2.7063136100769043
mean_targets: nan
std_targets: nan
prcauc: 0.5901762114425768
rocauc: 0.8894631820077317
ogbg-moltoxcast: 0.8894631820077317
OGBNanLabelBCEWithLogitsLoss: 0.1348900710098186
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 119; Iter    42/  201] train: loss: 0.0971523
[Epoch 119; Iter    72/  201] train: loss: 0.0952721
[Epoch 119; Iter   102/  201] train: loss: 0.0915717
[Epoch 119; Iter   132/  201] train: loss: 0.0732855
[Epoch 119; Iter   162/  201] train: loss: 0.1393944
[Epoch 119; Iter   192/  201] train: loss: 0.1008834
[Epoch 119] ogbg-moltoxcast: 0.664939 val loss: 0.291559
[Epoch 119] ogbg-moltoxcast: 0.649272 test loss: 0.349172
[Epoch 120; Iter    21/  201] train: loss: 0.0930767
[Epoch 120; Iter    51/  201] train: loss: 0.1246406
[Epoch 120; Iter    81/  201] train: loss: 0.0816989
[Epoch 120; Iter   111/  201] train: loss: 0.0957080
[Epoch 120; Iter   141/  201] train: loss: 0.1178011
[Epoch 120; Iter   171/  201] train: loss: 0.1196491
[Epoch 120; Iter   201/  201] train: loss: 0.0420432
[Epoch 120] ogbg-moltoxcast: 0.663862 val loss: 0.288533
[Epoch 120] ogbg-moltoxcast: 0.649355 test loss: 0.343140
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 40.
Statistics on  val_best_checkpoint
mean_pred: -2.750521659851074
std_pred: 2.447742462158203
mean_targets: nan
std_targets: nan
prcauc: 0.37611925178416267
rocauc: 0.6816050121551266
ogbg-moltoxcast: 0.6816050121551266
OGBNanLabelBCEWithLogitsLoss: 0.2581556255734244
Statistics on  test
mean_pred: -2.58707857131958
std_pred: 2.470388174057007
mean_targets: nan
std_targets: nan
prcauc: 0.3426715782392611
rocauc: 0.656799237744099
ogbg-moltoxcast: 0.656799237744099
OGBNanLabelBCEWithLogitsLoss: 0.3025629211996877
Statistics on  train
mean_pred: -3.341057538986206
std_pred: 2.419692039489746
mean_targets: nan
std_targets: nan
prcauc: 0.5712366035481147
rocauc: 0.8781151706551388
ogbg-moltoxcast: 0.8781151706551388
OGBNanLabelBCEWithLogitsLoss: 0.13608996214261695
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 107] ogbg-moltoxcast: 0.649823 test loss: 0.361441
[Epoch 108; Iter     7/  229] train: loss: 0.1295482
[Epoch 108; Iter    37/  229] train: loss: 0.1703346
[Epoch 108; Iter    67/  229] train: loss: 0.1289140
[Epoch 108; Iter    97/  229] train: loss: 0.0898151
[Epoch 108; Iter   127/  229] train: loss: 0.1037718
[Epoch 108; Iter   157/  229] train: loss: 0.1046155
[Epoch 108; Iter   187/  229] train: loss: 0.1257621
[Epoch 108; Iter   217/  229] train: loss: 0.1233439
[Epoch 108] ogbg-moltoxcast: 0.684184 val loss: 0.286079
[Epoch 108] ogbg-moltoxcast: 0.647392 test loss: 0.359154
[Epoch 109; Iter    18/  229] train: loss: 0.1189270
[Epoch 109; Iter    48/  229] train: loss: 0.1206146
[Epoch 109; Iter    78/  229] train: loss: 0.0748817
[Epoch 109; Iter   108/  229] train: loss: 0.1753489
[Epoch 109; Iter   138/  229] train: loss: 0.1856261
[Epoch 109; Iter   168/  229] train: loss: 0.1666553
[Epoch 109; Iter   198/  229] train: loss: 0.1097112
[Epoch 109; Iter   228/  229] train: loss: 0.1649202
[Epoch 109] ogbg-moltoxcast: 0.682343 val loss: 0.284668
[Epoch 109] ogbg-moltoxcast: 0.645623 test loss: 0.360136
[Epoch 110; Iter    29/  229] train: loss: 0.1101121
[Epoch 110; Iter    59/  229] train: loss: 0.1192386
[Epoch 110; Iter    89/  229] train: loss: 0.1912151
[Epoch 110; Iter   119/  229] train: loss: 0.1951673
[Epoch 110; Iter   149/  229] train: loss: 0.1250139
[Epoch 110; Iter   179/  229] train: loss: 0.1638096
[Epoch 110; Iter   209/  229] train: loss: 0.1062724
[Epoch 110] ogbg-moltoxcast: 0.681678 val loss: 0.286017
[Epoch 110] ogbg-moltoxcast: 0.645600 test loss: 0.368186
[Epoch 111; Iter    10/  229] train: loss: 0.1378860
[Epoch 111; Iter    40/  229] train: loss: 0.0877629
[Epoch 111; Iter    70/  229] train: loss: 0.0918862
[Epoch 111; Iter   100/  229] train: loss: 0.1174737
[Epoch 111; Iter   130/  229] train: loss: 0.1332206
[Epoch 111; Iter   160/  229] train: loss: 0.1242308
[Epoch 111; Iter   190/  229] train: loss: 0.1101197
[Epoch 111; Iter   220/  229] train: loss: 0.1354147
[Epoch 111] ogbg-moltoxcast: 0.680846 val loss: 0.287985
[Epoch 111] ogbg-moltoxcast: 0.646896 test loss: 0.365263
[Epoch 112; Iter    21/  229] train: loss: 0.0974706
[Epoch 112; Iter    51/  229] train: loss: 0.0976093
[Epoch 112; Iter    81/  229] train: loss: 0.1173530
[Epoch 112; Iter   111/  229] train: loss: 0.1304151
[Epoch 112; Iter   141/  229] train: loss: 0.1260408
[Epoch 112; Iter   171/  229] train: loss: 0.1019684
[Epoch 112; Iter   201/  229] train: loss: 0.1162441
[Epoch 112] ogbg-moltoxcast: 0.680856 val loss: 0.286571
[Epoch 112] ogbg-moltoxcast: 0.644480 test loss: 0.361047
[Epoch 113; Iter     2/  229] train: loss: 0.0580140
[Epoch 113; Iter    32/  229] train: loss: 0.1047760
[Epoch 113; Iter    62/  229] train: loss: 0.1245346
[Epoch 113; Iter    92/  229] train: loss: 0.1791042
[Epoch 113; Iter   122/  229] train: loss: 0.0698573
[Epoch 113; Iter   152/  229] train: loss: 0.1461161
[Epoch 113; Iter   182/  229] train: loss: 0.0989838
[Epoch 113; Iter   212/  229] train: loss: 0.1191552
[Epoch 113] ogbg-moltoxcast: 0.678899 val loss: 0.290246
[Epoch 113] ogbg-moltoxcast: 0.647959 test loss: 0.363980
[Epoch 114; Iter    13/  229] train: loss: 0.1124856
[Epoch 114; Iter    43/  229] train: loss: 0.1053168
[Epoch 114; Iter    73/  229] train: loss: 0.1128063
[Epoch 114; Iter   103/  229] train: loss: 0.1014392
[Epoch 114; Iter   133/  229] train: loss: 0.1367390
[Epoch 114; Iter   163/  229] train: loss: 0.0893710
[Epoch 114; Iter   193/  229] train: loss: 0.1090340
[Epoch 114; Iter   223/  229] train: loss: 0.0950943
[Epoch 114] ogbg-moltoxcast: 0.680011 val loss: 0.289264
[Epoch 114] ogbg-moltoxcast: 0.644371 test loss: 0.364448
[Epoch 115; Iter    24/  229] train: loss: 0.1101512
[Epoch 115; Iter    54/  229] train: loss: 0.1068343
[Epoch 115; Iter    84/  229] train: loss: 0.1477613
[Epoch 115; Iter   114/  229] train: loss: 0.1147432
[Epoch 115; Iter   144/  229] train: loss: 0.1211757
[Epoch 115; Iter   174/  229] train: loss: 0.0759022
[Epoch 115; Iter   204/  229] train: loss: 0.1420362
[Epoch 115] ogbg-moltoxcast: 0.678467 val loss: 0.289919
[Epoch 115] ogbg-moltoxcast: 0.644977 test loss: 0.366186
[Epoch 116; Iter     5/  229] train: loss: 0.1207002
[Epoch 116; Iter    35/  229] train: loss: 0.0951219
[Epoch 116; Iter    65/  229] train: loss: 0.2125710
[Epoch 116; Iter    95/  229] train: loss: 0.1144960
[Epoch 116; Iter   125/  229] train: loss: 0.1340651
[Epoch 116; Iter   155/  229] train: loss: 0.1383714
[Epoch 116; Iter   185/  229] train: loss: 0.1072424
[Epoch 116; Iter   215/  229] train: loss: 0.0997998
[Epoch 116] ogbg-moltoxcast: 0.681346 val loss: 0.297888
[Epoch 116] ogbg-moltoxcast: 0.648570 test loss: 0.363904
[Epoch 117; Iter    16/  229] train: loss: 0.1482317
[Epoch 117; Iter    46/  229] train: loss: 0.1592590
[Epoch 117; Iter    76/  229] train: loss: 0.1075210
[Epoch 117; Iter   106/  229] train: loss: 0.1432603
[Epoch 117; Iter   136/  229] train: loss: 0.0960932
[Epoch 117; Iter   166/  229] train: loss: 0.0665796
[Epoch 117; Iter   196/  229] train: loss: 0.1939565
[Epoch 117; Iter   226/  229] train: loss: 0.0951410
[Epoch 117] ogbg-moltoxcast: 0.680253 val loss: 0.313702
[Epoch 117] ogbg-moltoxcast: 0.648064 test loss: 0.365517
[Epoch 118; Iter    27/  229] train: loss: 0.0732477
[Epoch 118; Iter    57/  229] train: loss: 0.1162577
[Epoch 118; Iter    87/  229] train: loss: 0.0767014
[Epoch 118; Iter   117/  229] train: loss: 0.1324076
[Epoch 118; Iter   147/  229] train: loss: 0.1122084
[Epoch 118; Iter   177/  229] train: loss: 0.1210394
[Epoch 118; Iter   207/  229] train: loss: 0.1853324
[Epoch 118] ogbg-moltoxcast: 0.682714 val loss: 0.287313
[Epoch 118] ogbg-moltoxcast: 0.646297 test loss: 0.362547
[Epoch 119; Iter     8/  229] train: loss: 0.1325813
[Epoch 119; Iter    38/  229] train: loss: 0.0940929
[Epoch 119; Iter    68/  229] train: loss: 0.1391073
[Epoch 119; Iter    98/  229] train: loss: 0.0772763
[Epoch 119; Iter   128/  229] train: loss: 0.1150841
[Epoch 119; Iter   158/  229] train: loss: 0.0982311
[Epoch 119; Iter   188/  229] train: loss: 0.1587889
[Epoch 119; Iter   218/  229] train: loss: 0.1496623
[Epoch 119] ogbg-moltoxcast: 0.685849 val loss: 0.398717
[Epoch 119] ogbg-moltoxcast: 0.647147 test loss: 0.418213
[Epoch 120; Iter    19/  229] train: loss: 0.1174398
[Epoch 120; Iter    49/  229] train: loss: 0.1263184
[Epoch 120; Iter    79/  229] train: loss: 0.1016576
[Epoch 120; Iter   109/  229] train: loss: 0.1396154
[Epoch 120; Iter   139/  229] train: loss: 0.1309980
[Epoch 120; Iter   169/  229] train: loss: 0.1382586
[Epoch 120; Iter   199/  229] train: loss: 0.0969290
[Epoch 120; Iter   229/  229] train: loss: 0.1798895
[Epoch 120] ogbg-moltoxcast: 0.682604 val loss: 0.305485
[Epoch 120] ogbg-moltoxcast: 0.648078 test loss: 0.373314
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 35.
Statistics on  val_best_checkpoint
mean_pred: -2.435811758041382
std_pred: 2.7228522300720215
mean_targets: nan
std_targets: nan
prcauc: 0.41107659292810556
rocauc: 0.7013623065203907
ogbg-moltoxcast: 0.7013623065203907
OGBNanLabelBCEWithLogitsLoss: 0.26338551733000526
Statistics on  test
mean_pred: -2.2502336502075195
std_pred: 2.4846580028533936
mean_targets: nan
std_targets: nan
prcauc: 0.3642832961184139
rocauc: 0.6718100547041667
ogbg-moltoxcast: 0.6718100547041667
OGBNanLabelBCEWithLogitsLoss: 0.3030893386437975
Statistics on  train
mean_pred: -3.010913848876953
std_pred: 2.42403244972229
mean_targets: nan
std_targets: nan
prcauc: 0.549104838490988
rocauc: 0.8706602366535622
ogbg-moltoxcast: 0.8706602366535622
OGBNanLabelBCEWithLogitsLoss: 0.14844571193883513
[Epoch 107] ogbg-moltoxcast: 0.656100 test loss: 0.349696
[Epoch 108; Iter     7/  229] train: loss: 0.1093826
[Epoch 108; Iter    37/  229] train: loss: 0.1545057
[Epoch 108; Iter    67/  229] train: loss: 0.1144582
[Epoch 108; Iter    97/  229] train: loss: 0.1260127
[Epoch 108; Iter   127/  229] train: loss: 0.1844225
[Epoch 108; Iter   157/  229] train: loss: 0.0932831
[Epoch 108; Iter   187/  229] train: loss: 0.0908078
[Epoch 108; Iter   217/  229] train: loss: 0.0975915
[Epoch 108] ogbg-moltoxcast: 0.694173 val loss: 0.281820
[Epoch 108] ogbg-moltoxcast: 0.657137 test loss: 0.349019
[Epoch 109; Iter    18/  229] train: loss: 0.1239836
[Epoch 109; Iter    48/  229] train: loss: 0.1197812
[Epoch 109; Iter    78/  229] train: loss: 0.1150939
[Epoch 109; Iter   108/  229] train: loss: 0.1421224
[Epoch 109; Iter   138/  229] train: loss: 0.1122934
[Epoch 109; Iter   168/  229] train: loss: 0.1406339
[Epoch 109; Iter   198/  229] train: loss: 0.1068403
[Epoch 109; Iter   228/  229] train: loss: 0.0812738
[Epoch 109] ogbg-moltoxcast: 0.687831 val loss: 0.281707
[Epoch 109] ogbg-moltoxcast: 0.656116 test loss: 0.347876
[Epoch 110; Iter    29/  229] train: loss: 0.0716366
[Epoch 110; Iter    59/  229] train: loss: 0.0878100
[Epoch 110; Iter    89/  229] train: loss: 0.0813315
[Epoch 110; Iter   119/  229] train: loss: 0.1226335
[Epoch 110; Iter   149/  229] train: loss: 0.0926206
[Epoch 110; Iter   179/  229] train: loss: 0.1556730
[Epoch 110; Iter   209/  229] train: loss: 0.0933196
[Epoch 110] ogbg-moltoxcast: 0.690002 val loss: 0.283472
[Epoch 110] ogbg-moltoxcast: 0.661304 test loss: 0.347495
[Epoch 111; Iter    10/  229] train: loss: 0.1298303
[Epoch 111; Iter    40/  229] train: loss: 0.0860884
[Epoch 111; Iter    70/  229] train: loss: 0.1024432
[Epoch 111; Iter   100/  229] train: loss: 0.1321451
[Epoch 111; Iter   130/  229] train: loss: 0.1062815
[Epoch 111; Iter   160/  229] train: loss: 0.1432560
[Epoch 111; Iter   190/  229] train: loss: 0.1075261
[Epoch 111; Iter   220/  229] train: loss: 0.1010944
[Epoch 111] ogbg-moltoxcast: 0.693433 val loss: 0.284304
[Epoch 111] ogbg-moltoxcast: 0.660315 test loss: 0.352119
[Epoch 112; Iter    21/  229] train: loss: 0.1171107
[Epoch 112; Iter    51/  229] train: loss: 0.1109782
[Epoch 112; Iter    81/  229] train: loss: 0.0879602
[Epoch 112; Iter   111/  229] train: loss: 0.1062869
[Epoch 112; Iter   141/  229] train: loss: 0.1080300
[Epoch 112; Iter   171/  229] train: loss: 0.1382726
[Epoch 112; Iter   201/  229] train: loss: 0.0934282
[Epoch 112] ogbg-moltoxcast: 0.695096 val loss: 0.284531
[Epoch 112] ogbg-moltoxcast: 0.660379 test loss: 0.349659
[Epoch 113; Iter     2/  229] train: loss: 0.1567269
[Epoch 113; Iter    32/  229] train: loss: 0.0917371
[Epoch 113; Iter    62/  229] train: loss: 0.1440369
[Epoch 113; Iter    92/  229] train: loss: 0.1065491
[Epoch 113; Iter   122/  229] train: loss: 0.1272752
[Epoch 113; Iter   152/  229] train: loss: 0.0947036
[Epoch 113; Iter   182/  229] train: loss: 0.1117293
[Epoch 113; Iter   212/  229] train: loss: 0.1695380
[Epoch 113] ogbg-moltoxcast: 0.693276 val loss: 0.284106
[Epoch 113] ogbg-moltoxcast: 0.660048 test loss: 0.348388
[Epoch 114; Iter    13/  229] train: loss: 0.0884683
[Epoch 114; Iter    43/  229] train: loss: 0.1271594
[Epoch 114; Iter    73/  229] train: loss: 0.1479566
[Epoch 114; Iter   103/  229] train: loss: 0.1074242
[Epoch 114; Iter   133/  229] train: loss: 0.1340284
[Epoch 114; Iter   163/  229] train: loss: 0.1286047
[Epoch 114; Iter   193/  229] train: loss: 0.1492399
[Epoch 114; Iter   223/  229] train: loss: 0.1114055
[Epoch 114] ogbg-moltoxcast: 0.694700 val loss: 0.279977
[Epoch 114] ogbg-moltoxcast: 0.656661 test loss: 0.347548
[Epoch 115; Iter    24/  229] train: loss: 0.0853916
[Epoch 115; Iter    54/  229] train: loss: 0.1147871
[Epoch 115; Iter    84/  229] train: loss: 0.1398143
[Epoch 115; Iter   114/  229] train: loss: 0.0858750
[Epoch 115; Iter   144/  229] train: loss: 0.1475741
[Epoch 115; Iter   174/  229] train: loss: 0.1036015
[Epoch 115; Iter   204/  229] train: loss: 0.0906309
[Epoch 115] ogbg-moltoxcast: 0.691846 val loss: 0.285877
[Epoch 115] ogbg-moltoxcast: 0.660485 test loss: 0.348524
[Epoch 116; Iter     5/  229] train: loss: 0.1548829
[Epoch 116; Iter    35/  229] train: loss: 0.1103596
[Epoch 116; Iter    65/  229] train: loss: 0.1065252
[Epoch 116; Iter    95/  229] train: loss: 0.1157200
[Epoch 116; Iter   125/  229] train: loss: 0.1205877
[Epoch 116; Iter   155/  229] train: loss: 0.1270905
[Epoch 116; Iter   185/  229] train: loss: 0.0870894
[Epoch 116; Iter   215/  229] train: loss: 0.0853482
[Epoch 116] ogbg-moltoxcast: 0.695856 val loss: 0.282429
[Epoch 116] ogbg-moltoxcast: 0.653863 test loss: 0.368675
[Epoch 117; Iter    16/  229] train: loss: 0.1208634
[Epoch 117; Iter    46/  229] train: loss: 0.1352323
[Epoch 117; Iter    76/  229] train: loss: 0.1096218
[Epoch 117; Iter   106/  229] train: loss: 0.1281855
[Epoch 117; Iter   136/  229] train: loss: 0.1227061
[Epoch 117; Iter   166/  229] train: loss: 0.0874000
[Epoch 117; Iter   196/  229] train: loss: 0.1074142
[Epoch 117; Iter   226/  229] train: loss: 0.1068795
[Epoch 117] ogbg-moltoxcast: 0.694041 val loss: 0.283338
[Epoch 117] ogbg-moltoxcast: 0.649012 test loss: 0.459380
[Epoch 118; Iter    27/  229] train: loss: 0.1096490
[Epoch 118; Iter    57/  229] train: loss: 0.0792564
[Epoch 118; Iter    87/  229] train: loss: 0.1171779
[Epoch 118; Iter   117/  229] train: loss: 0.0878875
[Epoch 118; Iter   147/  229] train: loss: 0.1059378
[Epoch 118; Iter   177/  229] train: loss: 0.1393209
[Epoch 118; Iter   207/  229] train: loss: 0.0976134
[Epoch 118] ogbg-moltoxcast: 0.695058 val loss: 0.284981
[Epoch 118] ogbg-moltoxcast: 0.654934 test loss: 0.353108
[Epoch 119; Iter     8/  229] train: loss: 0.0740592
[Epoch 119; Iter    38/  229] train: loss: 0.1042380
[Epoch 119; Iter    68/  229] train: loss: 0.1298449
[Epoch 119; Iter    98/  229] train: loss: 0.0868381
[Epoch 119; Iter   128/  229] train: loss: 0.1413154
[Epoch 119; Iter   158/  229] train: loss: 0.1282663
[Epoch 119; Iter   188/  229] train: loss: 0.1395167
[Epoch 119; Iter   218/  229] train: loss: 0.1773216
[Epoch 119] ogbg-moltoxcast: 0.696563 val loss: 0.286515
[Epoch 119] ogbg-moltoxcast: 0.660353 test loss: 0.351459
[Epoch 120; Iter    19/  229] train: loss: 0.0856374
[Epoch 120; Iter    49/  229] train: loss: 0.1159040
[Epoch 120; Iter    79/  229] train: loss: 0.0850993
[Epoch 120; Iter   109/  229] train: loss: 0.0689937
[Epoch 120; Iter   139/  229] train: loss: 0.1393282
[Epoch 120; Iter   169/  229] train: loss: 0.0867655
[Epoch 120; Iter   199/  229] train: loss: 0.0882579
[Epoch 120; Iter   229/  229] train: loss: 0.1035811
[Epoch 120] ogbg-moltoxcast: 0.695007 val loss: 0.283723
[Epoch 120] ogbg-moltoxcast: 0.660180 test loss: 0.346172
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 32.
Statistics on  val_best_checkpoint
mean_pred: -2.593364953994751
std_pred: 3.040371894836426
mean_targets: nan
std_targets: nan
prcauc: 0.41194904316014197
rocauc: 0.7092922869536786
ogbg-moltoxcast: 0.7092922869536786
OGBNanLabelBCEWithLogitsLoss: 0.247067391872406
Statistics on  test
mean_pred: -2.4286415576934814
std_pred: 4.93789529800415
mean_targets: nan
std_targets: nan
prcauc: 0.357652098028169
rocauc: 0.6662355235139678
ogbg-moltoxcast: 0.6662355235139678
OGBNanLabelBCEWithLogitsLoss: 0.3033360294226942
Statistics on  train
mean_pred: -2.9168319702148438
std_pred: 2.837611675262451
mean_targets: nan
std_targets: nan
prcauc: 0.521692586250905
rocauc: 0.8517365121345547
ogbg-moltoxcast: 0.8517365121345547
OGBNanLabelBCEWithLogitsLoss: 0.1625967767561367
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 107] ogbg-moltoxcast: 0.650335 test loss: 0.338445
[Epoch 108; Iter     7/  229] train: loss: 0.1074460
[Epoch 108; Iter    37/  229] train: loss: 0.1820838
[Epoch 108; Iter    67/  229] train: loss: 0.1153267
[Epoch 108; Iter    97/  229] train: loss: 0.1553825
[Epoch 108; Iter   127/  229] train: loss: 0.1294846
[Epoch 108; Iter   157/  229] train: loss: 0.1201566
[Epoch 108; Iter   187/  229] train: loss: 0.1249817
[Epoch 108; Iter   217/  229] train: loss: 0.1081234
[Epoch 108] ogbg-moltoxcast: 0.677565 val loss: 0.284479
[Epoch 108] ogbg-moltoxcast: 0.652366 test loss: 0.340875
[Epoch 109; Iter    18/  229] train: loss: 0.0970332
[Epoch 109; Iter    48/  229] train: loss: 0.1249766
[Epoch 109; Iter    78/  229] train: loss: 0.0882727
[Epoch 109; Iter   108/  229] train: loss: 0.1154062
[Epoch 109; Iter   138/  229] train: loss: 0.0757624
[Epoch 109; Iter   168/  229] train: loss: 0.1252176
[Epoch 109; Iter   198/  229] train: loss: 0.1122961
[Epoch 109; Iter   228/  229] train: loss: 0.1320325
[Epoch 109] ogbg-moltoxcast: 0.671636 val loss: 0.284198
[Epoch 109] ogbg-moltoxcast: 0.652364 test loss: 0.337500
[Epoch 110; Iter    29/  229] train: loss: 0.1301693
[Epoch 110; Iter    59/  229] train: loss: 0.1306993
[Epoch 110; Iter    89/  229] train: loss: 0.1347765
[Epoch 110; Iter   119/  229] train: loss: 0.1564492
[Epoch 110; Iter   149/  229] train: loss: 0.1518348
[Epoch 110; Iter   179/  229] train: loss: 0.1462157
[Epoch 110; Iter   209/  229] train: loss: 0.0975783
[Epoch 110] ogbg-moltoxcast: 0.676106 val loss: 0.284170
[Epoch 110] ogbg-moltoxcast: 0.649344 test loss: 0.337437
[Epoch 111; Iter    10/  229] train: loss: 0.0892234
[Epoch 111; Iter    40/  229] train: loss: 0.1252337
[Epoch 111; Iter    70/  229] train: loss: 0.1493266
[Epoch 111; Iter   100/  229] train: loss: 0.1051901
[Epoch 111; Iter   130/  229] train: loss: 0.1313197
[Epoch 111; Iter   160/  229] train: loss: 0.1695821
[Epoch 111; Iter   190/  229] train: loss: 0.0927044
[Epoch 111; Iter   220/  229] train: loss: 0.1140180
[Epoch 111] ogbg-moltoxcast: 0.677866 val loss: 0.281934
[Epoch 111] ogbg-moltoxcast: 0.651410 test loss: 0.339070
[Epoch 112; Iter    21/  229] train: loss: 0.1078625
[Epoch 112; Iter    51/  229] train: loss: 0.1280213
[Epoch 112; Iter    81/  229] train: loss: 0.0799112
[Epoch 112; Iter   111/  229] train: loss: 0.1114427
[Epoch 112; Iter   141/  229] train: loss: 0.1128440
[Epoch 112; Iter   171/  229] train: loss: 0.1174840
[Epoch 112; Iter   201/  229] train: loss: 0.0914476
[Epoch 112] ogbg-moltoxcast: 0.678540 val loss: 0.283160
[Epoch 112] ogbg-moltoxcast: 0.651225 test loss: 0.337904
[Epoch 113; Iter     2/  229] train: loss: 0.1402586
[Epoch 113; Iter    32/  229] train: loss: 0.1421957
[Epoch 113; Iter    62/  229] train: loss: 0.1225803
[Epoch 113; Iter    92/  229] train: loss: 0.1439787
[Epoch 113; Iter   122/  229] train: loss: 0.1625514
[Epoch 113; Iter   152/  229] train: loss: 0.1119919
[Epoch 113; Iter   182/  229] train: loss: 0.1128788
[Epoch 113; Iter   212/  229] train: loss: 0.1057228
[Epoch 113] ogbg-moltoxcast: 0.685352 val loss: 0.288156
[Epoch 113] ogbg-moltoxcast: 0.654035 test loss: 0.340661
[Epoch 114; Iter    13/  229] train: loss: 0.0704573
[Epoch 114; Iter    43/  229] train: loss: 0.1209067
[Epoch 114; Iter    73/  229] train: loss: 0.1112037
[Epoch 114; Iter   103/  229] train: loss: 0.1423222
[Epoch 114; Iter   133/  229] train: loss: 0.1241141
[Epoch 114; Iter   163/  229] train: loss: 0.0897861
[Epoch 114; Iter   193/  229] train: loss: 0.1359558
[Epoch 114; Iter   223/  229] train: loss: 0.0859372
[Epoch 114] ogbg-moltoxcast: 0.678213 val loss: 0.285451
[Epoch 114] ogbg-moltoxcast: 0.651250 test loss: 0.342088
[Epoch 115; Iter    24/  229] train: loss: 0.0937245
[Epoch 115; Iter    54/  229] train: loss: 0.1281175
[Epoch 115; Iter    84/  229] train: loss: 0.1177669
[Epoch 115; Iter   114/  229] train: loss: 0.0781371
[Epoch 115; Iter   144/  229] train: loss: 0.0756657
[Epoch 115; Iter   174/  229] train: loss: 0.1323804
[Epoch 115; Iter   204/  229] train: loss: 0.1503330
[Epoch 115] ogbg-moltoxcast: 0.674829 val loss: 0.287812
[Epoch 115] ogbg-moltoxcast: 0.650552 test loss: 0.344274
[Epoch 116; Iter     5/  229] train: loss: 0.1246040
[Epoch 116; Iter    35/  229] train: loss: 0.1171412
[Epoch 116; Iter    65/  229] train: loss: 0.1081394
[Epoch 116; Iter    95/  229] train: loss: 0.1529792
[Epoch 116; Iter   125/  229] train: loss: 0.0926413
[Epoch 116; Iter   155/  229] train: loss: 0.1657045
[Epoch 116; Iter   185/  229] train: loss: 0.1000724
[Epoch 116; Iter   215/  229] train: loss: 0.1375865
[Epoch 116] ogbg-moltoxcast: 0.679656 val loss: 0.287813
[Epoch 116] ogbg-moltoxcast: 0.651628 test loss: 0.343298
[Epoch 117; Iter    16/  229] train: loss: 0.0998787
[Epoch 117; Iter    46/  229] train: loss: 0.0864745
[Epoch 117; Iter    76/  229] train: loss: 0.0921409
[Epoch 117; Iter   106/  229] train: loss: 0.1152746
[Epoch 117; Iter   136/  229] train: loss: 0.1438354
[Epoch 117; Iter   166/  229] train: loss: 0.1221551
[Epoch 117; Iter   196/  229] train: loss: 0.1459799
[Epoch 117; Iter   226/  229] train: loss: 0.1250599
[Epoch 117] ogbg-moltoxcast: 0.675120 val loss: 0.284201
[Epoch 117] ogbg-moltoxcast: 0.650077 test loss: 0.339606
[Epoch 118; Iter    27/  229] train: loss: 0.0881056
[Epoch 118; Iter    57/  229] train: loss: 0.1030974
[Epoch 118; Iter    87/  229] train: loss: 0.1171104
[Epoch 118; Iter   117/  229] train: loss: 0.1119182
[Epoch 118; Iter   147/  229] train: loss: 0.1226251
[Epoch 118; Iter   177/  229] train: loss: 0.1370755
[Epoch 118; Iter   207/  229] train: loss: 0.1025072
[Epoch 118] ogbg-moltoxcast: 0.681572 val loss: 0.285214
[Epoch 118] ogbg-moltoxcast: 0.651744 test loss: 0.342437
[Epoch 119; Iter     8/  229] train: loss: 0.1077856
[Epoch 119; Iter    38/  229] train: loss: 0.0894402
[Epoch 119; Iter    68/  229] train: loss: 0.1027510
[Epoch 119; Iter    98/  229] train: loss: 0.1121392
[Epoch 119; Iter   128/  229] train: loss: 0.1244608
[Epoch 119; Iter   158/  229] train: loss: 0.1376155
[Epoch 119; Iter   188/  229] train: loss: 0.1151968
[Epoch 119; Iter   218/  229] train: loss: 0.0725317
[Epoch 119] ogbg-moltoxcast: 0.675895 val loss: 0.286055
[Epoch 119] ogbg-moltoxcast: 0.648752 test loss: 0.341482
[Epoch 120; Iter    19/  229] train: loss: 0.1067829
[Epoch 120; Iter    49/  229] train: loss: 0.1056143
[Epoch 120; Iter    79/  229] train: loss: 0.1144412
[Epoch 120; Iter   109/  229] train: loss: 0.1879582
[Epoch 120; Iter   139/  229] train: loss: 0.1027813
[Epoch 120; Iter   169/  229] train: loss: 0.0930089
[Epoch 120; Iter   199/  229] train: loss: 0.0703086
[Epoch 120; Iter   229/  229] train: loss: 0.1226328
[Epoch 120] ogbg-moltoxcast: 0.672610 val loss: 0.286671
[Epoch 120] ogbg-moltoxcast: 0.649615 test loss: 0.339673
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 44.
Statistics on  val_best_checkpoint
mean_pred: -2.6632332801818848
std_pred: 2.494525194168091
mean_targets: nan
std_targets: nan
prcauc: 0.4183730866727941
rocauc: 0.6976572359946955
ogbg-moltoxcast: 0.6976572359946955
OGBNanLabelBCEWithLogitsLoss: 0.24680417416424588
Statistics on  test
mean_pred: -1.9630831480026245
std_pred: 17.21059799194336
mean_targets: nan
std_targets: nan
prcauc: 0.35976589523074026
rocauc: 0.667518444414898
ogbg-moltoxcast: 0.667518444414898
OGBNanLabelBCEWithLogitsLoss: 0.6865674200756796
Statistics on  train
mean_pred: -3.205219268798828
std_pred: 3.547107219696045
mean_targets: nan
std_targets: nan
prcauc: 0.5806601482727322
rocauc: 0.8827871558051926
ogbg-moltoxcast: 0.8827871558051926
OGBNanLabelBCEWithLogitsLoss: 0.15353279160620345
All runs completed.
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 119; Iter    42/  201] train: loss: 0.1565852
[Epoch 119; Iter    72/  201] train: loss: 0.1466147
[Epoch 119; Iter   102/  201] train: loss: 0.2171788
[Epoch 119; Iter   132/  201] train: loss: 0.1597381
[Epoch 119; Iter   162/  201] train: loss: 0.1343568
[Epoch 119; Iter   192/  201] train: loss: 0.1020523
[Epoch 119] ogbg-moltoxcast: 0.675706 val loss: 0.290648
[Epoch 119] ogbg-moltoxcast: 0.655821 test loss: 0.338651
[Epoch 120; Iter    21/  201] train: loss: 0.1779009
[Epoch 120; Iter    51/  201] train: loss: 0.0993404
[Epoch 120; Iter    81/  201] train: loss: 0.1171516
[Epoch 120; Iter   111/  201] train: loss: 0.1219073
[Epoch 120; Iter   141/  201] train: loss: 0.0918834
[Epoch 120; Iter   171/  201] train: loss: 0.0880138
[Epoch 120; Iter   201/  201] train: loss: 0.0428696
[Epoch 120] ogbg-moltoxcast: 0.676810 val loss: 0.285812
[Epoch 120] ogbg-moltoxcast: 0.657104 test loss: 0.333752
[Epoch 121; Iter    30/  201] train: loss: 0.0973853
[Epoch 121; Iter    60/  201] train: loss: 0.1386236
[Epoch 121; Iter    90/  201] train: loss: 0.1107551
[Epoch 121; Iter   120/  201] train: loss: 0.1076454
[Epoch 121; Iter   150/  201] train: loss: 0.1476472
[Epoch 121; Iter   180/  201] train: loss: 0.1093152
[Epoch 121] ogbg-moltoxcast: 0.679169 val loss: 0.290633
[Epoch 121] ogbg-moltoxcast: 0.658789 test loss: 0.339822
[Epoch 122; Iter     9/  201] train: loss: 0.1529173
[Epoch 122; Iter    39/  201] train: loss: 0.1162065
[Epoch 122; Iter    69/  201] train: loss: 0.1749904
[Epoch 122; Iter    99/  201] train: loss: 0.0877454
[Epoch 122; Iter   129/  201] train: loss: 0.1237774
[Epoch 122; Iter   159/  201] train: loss: 0.0864212
[Epoch 122; Iter   189/  201] train: loss: 0.1567393
[Epoch 122] ogbg-moltoxcast: 0.676427 val loss: 0.295079
[Epoch 122] ogbg-moltoxcast: 0.655488 test loss: 0.343846
[Epoch 123; Iter    18/  201] train: loss: 0.0985582
[Epoch 123; Iter    48/  201] train: loss: 0.1758862
[Epoch 123; Iter    78/  201] train: loss: 0.0983403
[Epoch 123; Iter   108/  201] train: loss: 0.1097000
[Epoch 123; Iter   138/  201] train: loss: 0.1166652
[Epoch 123; Iter   168/  201] train: loss: 0.1300649
[Epoch 123; Iter   198/  201] train: loss: 0.0794892
[Epoch 123] ogbg-moltoxcast: 0.676034 val loss: 0.288732
[Epoch 123] ogbg-moltoxcast: 0.654841 test loss: 0.336030
[Epoch 124; Iter    27/  201] train: loss: 0.1137194
[Epoch 124; Iter    57/  201] train: loss: 0.0829770
[Epoch 124; Iter    87/  201] train: loss: 0.0880777
[Epoch 124; Iter   117/  201] train: loss: 0.1179534
[Epoch 124; Iter   147/  201] train: loss: 0.1182733
[Epoch 124; Iter   177/  201] train: loss: 0.1311138
[Epoch 124] ogbg-moltoxcast: 0.678161 val loss: 0.287838
[Epoch 124] ogbg-moltoxcast: 0.659172 test loss: 0.336071
[Epoch 125; Iter     6/  201] train: loss: 0.1058599
[Epoch 125; Iter    36/  201] train: loss: 0.1134677
[Epoch 125; Iter    66/  201] train: loss: 0.1228040
[Epoch 125; Iter    96/  201] train: loss: 0.1094416
[Epoch 125; Iter   126/  201] train: loss: 0.1881567
[Epoch 125; Iter   156/  201] train: loss: 0.1517689
[Epoch 125; Iter   186/  201] train: loss: 0.1627175
[Epoch 125] ogbg-moltoxcast: 0.678791 val loss: 0.287604
[Epoch 125] ogbg-moltoxcast: 0.659251 test loss: 0.333833
[Epoch 126; Iter    15/  201] train: loss: 0.0796627
[Epoch 126; Iter    45/  201] train: loss: 0.1264183
[Epoch 126; Iter    75/  201] train: loss: 0.1100656
[Epoch 126; Iter   105/  201] train: loss: 0.1046619
[Epoch 126; Iter   135/  201] train: loss: 0.0901194
[Epoch 126; Iter   165/  201] train: loss: 0.0845876
[Epoch 126; Iter   195/  201] train: loss: 0.0765307
[Epoch 126] ogbg-moltoxcast: 0.678542 val loss: 0.285985
[Epoch 126] ogbg-moltoxcast: 0.657638 test loss: 0.335873
[Epoch 127; Iter    24/  201] train: loss: 0.0997986
[Epoch 127; Iter    54/  201] train: loss: 0.1086294
[Epoch 127; Iter    84/  201] train: loss: 0.1568892
[Epoch 127; Iter   114/  201] train: loss: 0.1331585
[Epoch 127; Iter   144/  201] train: loss: 0.1068574
[Epoch 127; Iter   174/  201] train: loss: 0.0714478
[Epoch 127] ogbg-moltoxcast: 0.678270 val loss: 0.289714
[Epoch 127] ogbg-moltoxcast: 0.658943 test loss: 0.339157
[Epoch 128; Iter     3/  201] train: loss: 0.1005613
[Epoch 128; Iter    33/  201] train: loss: 0.0972271
[Epoch 128; Iter    63/  201] train: loss: 0.1312303
[Epoch 128; Iter    93/  201] train: loss: 0.1276475
[Epoch 128; Iter   123/  201] train: loss: 0.1514984
[Epoch 128; Iter   153/  201] train: loss: 0.1023157
[Epoch 128; Iter   183/  201] train: loss: 0.1143600
[Epoch 128] ogbg-moltoxcast: 0.673207 val loss: 0.294463
[Epoch 128] ogbg-moltoxcast: 0.655424 test loss: 0.344178
[Epoch 129; Iter    12/  201] train: loss: 0.1521571
[Epoch 129; Iter    42/  201] train: loss: 0.1166341
[Epoch 129; Iter    72/  201] train: loss: 0.1252768
[Epoch 129; Iter   102/  201] train: loss: 0.0942590
[Epoch 129; Iter   132/  201] train: loss: 0.0915306
[Epoch 129; Iter   162/  201] train: loss: 0.1296999
[Epoch 129; Iter   192/  201] train: loss: 0.1043307
[Epoch 129] ogbg-moltoxcast: 0.674515 val loss: 0.292695
[Epoch 129] ogbg-moltoxcast: 0.654147 test loss: 0.341335
[Epoch 130; Iter    21/  201] train: loss: 0.1350444
[Epoch 130; Iter    51/  201] train: loss: 0.1064765
[Epoch 130; Iter    81/  201] train: loss: 0.0779042
[Epoch 130; Iter   111/  201] train: loss: 0.1171984
[Epoch 130; Iter   141/  201] train: loss: 0.0995684
[Epoch 130; Iter   171/  201] train: loss: 0.1493131
[Epoch 130; Iter   201/  201] train: loss: 0.1661162
[Epoch 130] ogbg-moltoxcast: 0.674316 val loss: 0.291380
[Epoch 130] ogbg-moltoxcast: 0.652583 test loss: 0.339743
[Epoch 131; Iter    30/  201] train: loss: 0.1113057
[Epoch 131; Iter    60/  201] train: loss: 0.1194036
[Epoch 131; Iter    90/  201] train: loss: 0.1314724
[Epoch 131; Iter   120/  201] train: loss: 0.0982737
[Epoch 131; Iter   150/  201] train: loss: 0.1086529
[Epoch 131; Iter   180/  201] train: loss: 0.1042615
[Epoch 131] ogbg-moltoxcast: 0.676811 val loss: 0.287739
[Epoch 131] ogbg-moltoxcast: 0.650584 test loss: 0.338146
[Epoch 132; Iter     9/  201] train: loss: 0.0993373
[Epoch 132; Iter    39/  201] train: loss: 0.1195558
[Epoch 132; Iter    69/  201] train: loss: 0.1124936
[Epoch 132; Iter    99/  201] train: loss: 0.1349981
[Epoch 132; Iter   129/  201] train: loss: 0.1269655
[Epoch 132; Iter   159/  201] train: loss: 0.1309094
[Epoch 132; Iter   189/  201] train: loss: 0.1483162
[Epoch 132] ogbg-moltoxcast: 0.676140 val loss: 0.289323
[Epoch 132] ogbg-moltoxcast: 0.653313 test loss: 0.339286
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 132 epochs. Best model checkpoint was in epoch 72.
Statistics on  val_best_checkpoint
mean_pred: -2.8686413764953613
std_pred: 2.803924560546875
mean_targets: nan
std_targets: nan
prcauc: 0.37844925874466046
rocauc: 0.6892058261671681
ogbg-moltoxcast: 0.6892058261671681
OGBNanLabelBCEWithLogitsLoss: 0.26494522843250007
Statistics on  test
mean_pred: -2.7506232261657715
std_pred: 2.871541976928711
mean_targets: nan
std_targets: nan
prcauc: 0.3523332117901463
rocauc: 0.6689710142930355
ogbg-moltoxcast: 0.6689710142930355
OGBNanLabelBCEWithLogitsLoss: 0.31259206457193506
Statistics on  train
mean_pred: -3.5015406608581543
std_pred: 2.7223334312438965
mean_targets: nan
std_targets: nan
prcauc: 0.6147536503518688
rocauc: 0.9016895512592072
ogbg-moltoxcast: 0.9016895512592072
OGBNanLabelBCEWithLogitsLoss: 0.1278787622626741
All runs completed.
