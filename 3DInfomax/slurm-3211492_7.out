>>> Starting run for dataset: toxcast
Running RANDOM configs_split_experiments/3DInfomax/toxcast/random/train_prop=0.6.yml on cuda:0
Running RANDOM configs_split_experiments/3DInfomax/toxcast/random/train_prop=0.7.yml on cuda:1
Running RANDOM configs_split_experiments/3DInfomax/toxcast/random/train_prop=0.8.yml on cuda:2
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
Starting process for seed 4: python train.py --config configs_split_experiments/3DInfomax/toxcast/random/train_prop=0.7.yml --seed 4 --device cuda:1
Starting process for seed 4: python train.py --config configs_split_experiments/3DInfomax/toxcast/random/train_prop=0.8.yml --seed 4 --device cuda:2
Starting process for seed 4: python train.py --config configs_split_experiments/3DInfomax/toxcast/random/train_prop=0.6.yml --seed 4 --device cuda:0
Starting process for seed 5: python train.py --config configs_split_experiments/3DInfomax/toxcast/random/train_prop=0.8.yml --seed 5 --device cuda:2
Starting process for seed 5: python train.py --config configs_split_experiments/3DInfomax/toxcast/random/train_prop=0.7.yml --seed 5 --device cuda:1
Starting process for seed 5: python train.py --config configs_split_experiments/3DInfomax/toxcast/random/train_prop=0.6.yml --seed 5 --device cuda:0
Starting process for seed 6: python train.py --config configs_split_experiments/3DInfomax/toxcast/random/train_prop=0.8.yml --seed 6 --device cuda:2
Starting process for seed 6: python train.py --config configs_split_experiments/3DInfomax/toxcast/random/train_prop=0.7.yml --seed 6 --device cuda:1
Starting process for seed 6: python train.py --config configs_split_experiments/3DInfomax/toxcast/random/train_prop=0.6.yml --seed 6 --device cuda:0
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[ Using Seed :  6  ]
using device:  cuda:2
Log directory:  runs/split/3DInfomax/toxcast/random/train_prop=0.8/PNA_ogbg-moltoxcast_3DInfomax_toxcast_random=0.8_6_26-05_09-18-13
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/toxcast/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_random=0.8
logdir: runs/split/3DInfomax/toxcast/random/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6931788
[Epoch 1; Iter    60/  229] train: loss: 0.6931460
[Epoch 1; Iter    90/  229] train: loss: 0.6931366
[Epoch 1; Iter   120/  229] train: loss: 0.6932276
[Epoch 1; Iter   150/  229] train: loss: 0.6932239
[Epoch 1; Iter   180/  229] train: loss: 0.6931089
[Epoch 1; Iter   210/  229] train: loss: 0.6931284
[Epoch 1] ogbg-moltoxcast: 0.491627 val loss: 0.693123
[Epoch 1] ogbg-moltoxcast: 0.500472 test loss: 0.693130
[Epoch 2; Iter    11/  229] train: loss: 0.6930389
[Epoch 2; Iter    41/  229] train: loss: 0.6931258
[Epoch 2; Iter    71/  229] train: loss: 0.6931186
[Epoch 2; Iter   101/  229] train: loss: 0.6930926
[Epoch 2; Iter   131/  229] train: loss: 0.6930554
[Epoch 2; Iter   161/  229] train: loss: 0.6930845
[Epoch 2; Iter   191/  229] train: loss: 0.6930025
[Epoch 2; Iter   221/  229] train: loss: 0.6930366
[Epoch 2] ogbg-moltoxcast: 0.492202 val loss: 0.693019
[Epoch 2] ogbg-moltoxcast: 0.500771 test loss: 0.693031
[Epoch 3; Iter    22/  229] train: loss: 0.6930031
[Epoch 3; Iter    52/  229] train: loss: 0.6930095
[Epoch 3; Iter    82/  229] train: loss: 0.6929638
[Epoch 3; Iter   112/  229] train: loss: 0.6929320
[Epoch 3; Iter   142/  229] train: loss: 0.6928087
[Epoch 3; Iter   172/  229] train: loss: 0.6928830
[Epoch 3; Iter   202/  229] train: loss: 0.6928654
[Epoch 3] ogbg-moltoxcast: 0.492347 val loss: 0.692853
[Epoch 3] ogbg-moltoxcast: 0.500717 test loss: 0.692871
[Epoch 4; Iter     3/  229] train: loss: 0.6928537
[Epoch 4; Iter    33/  229] train: loss: 0.6900105
[Epoch 4; Iter    63/  229] train: loss: 0.6801848
[Epoch 4; Iter    93/  229] train: loss: 0.6494016
[Epoch 4; Iter   123/  229] train: loss: 0.5923449
[Epoch 4; Iter   153/  229] train: loss: 0.5638236
[Epoch 4; Iter   183/  229] train: loss: 0.5367810
[Epoch 4; Iter   213/  229] train: loss: 0.4321197
[Epoch 4] ogbg-moltoxcast: 0.580875 val loss: 0.439888
[Epoch 4] ogbg-moltoxcast: 0.626469 test loss: 0.450612
[Epoch 5; Iter    14/  229] train: loss: 0.3986375
[Epoch 5; Iter    44/  229] train: loss: 0.3317568
[Epoch 5; Iter    74/  229] train: loss: 0.3690832
[Epoch 5; Iter   104/  229] train: loss: 0.3428389
[Epoch 5; Iter   134/  229] train: loss: 0.2862787
[Epoch 5; Iter   164/  229] train: loss: 0.3002030
[Epoch 5; Iter   194/  229] train: loss: 0.2122002
[Epoch 5; Iter   224/  229] train: loss: 0.2347521
[Epoch 5] ogbg-moltoxcast: 0.633384 val loss: 0.236266
[Epoch 5] ogbg-moltoxcast: 0.674612 test loss: 0.250043
[Epoch 6; Iter    25/  229] train: loss: 0.1994040
[Epoch 6; Iter    55/  229] train: loss: 0.2004227
[Epoch 6; Iter    85/  229] train: loss: 0.2552568
[Epoch 6; Iter   115/  229] train: loss: 0.2261930
[Epoch 6; Iter   145/  229] train: loss: 0.2335375
[Epoch 6; Iter   175/  229] train: loss: 0.2861608
[Epoch 6; Iter   205/  229] train: loss: 0.1808553
[Epoch 6] ogbg-moltoxcast: 0.671823 val loss: 0.214496
[Epoch 6] ogbg-moltoxcast: 0.701490 test loss: 0.230988
[Epoch 7; Iter     6/  229] train: loss: 0.2888328
[Epoch 7; Iter    36/  229] train: loss: 0.1544703
[Epoch 7; Iter    66/  229] train: loss: 0.1626804
[Epoch 7; Iter    96/  229] train: loss: 0.1660831
[Epoch 7; Iter   126/  229] train: loss: 0.2374270
[Epoch 7; Iter   156/  229] train: loss: 0.2189942
[Epoch 7; Iter   186/  229] train: loss: 0.4208139
[Epoch 7; Iter   216/  229] train: loss: 0.2654547
[Epoch 7] ogbg-moltoxcast: 0.661127 val loss: 0.214132
[Epoch 7] ogbg-moltoxcast: 0.697772 test loss: 0.226578
[Epoch 8; Iter    17/  229] train: loss: 0.1751430
[Epoch 8; Iter    47/  229] train: loss: 0.1797038
[Epoch 8; Iter    77/  229] train: loss: 0.2390825
[Epoch 8; Iter   107/  229] train: loss: 0.1796372
[Epoch 8; Iter   137/  229] train: loss: 0.2049380
[Epoch 8; Iter   167/  229] train: loss: 0.1747316
[Epoch 8; Iter   197/  229] train: loss: 0.2814902
[Epoch 8; Iter   227/  229] train: loss: 0.1518185
[Epoch 8] ogbg-moltoxcast: 0.653285 val loss: 0.213506
[Epoch 8] ogbg-moltoxcast: 0.662351 test loss: 0.238233
[Epoch 9; Iter    28/  229] train: loss: 0.1818726
[Epoch 9; Iter    58/  229] train: loss: 0.1617695
[Epoch 9; Iter    88/  229] train: loss: 0.1462974
[Epoch 9; Iter   118/  229] train: loss: 0.2539654
[Epoch 9; Iter   148/  229] train: loss: 0.2695508
[Epoch 9; Iter   178/  229] train: loss: 0.1438095
[Epoch 9; Iter   208/  229] train: loss: 0.2468628
[Epoch 9] ogbg-moltoxcast: 0.674645 val loss: 0.208598
[Epoch 9] ogbg-moltoxcast: 0.709439 test loss: 0.222024
[Epoch 10; Iter     9/  229] train: loss: 0.3395422
[Epoch 10; Iter    39/  229] train: loss: 0.2212044
[Epoch 10; Iter    69/  229] train: loss: 0.2339983
[Epoch 10; Iter    99/  229] train: loss: 0.3512126
[Epoch 10; Iter   129/  229] train: loss: 0.1569066
[Epoch 10; Iter   159/  229] train: loss: 0.1962295
[Epoch 10; Iter   189/  229] train: loss: 0.2427195
[Epoch 10; Iter   219/  229] train: loss: 0.2116889
[Epoch 10] ogbg-moltoxcast: 0.676343 val loss: 0.207558
[Epoch 10] ogbg-moltoxcast: 0.703918 test loss: 0.221968
[Epoch 11; Iter    20/  229] train: loss: 0.2247483
[Epoch 11; Iter    50/  229] train: loss: 0.2440455
[Epoch 11; Iter    80/  229] train: loss: 0.1637354
[Epoch 11; Iter   110/  229] train: loss: 0.1366900
[Epoch 11; Iter   140/  229] train: loss: 0.3089436
[Epoch 11; Iter   170/  229] train: loss: 0.1938435
[Epoch 11; Iter   200/  229] train: loss: 0.2176722
[Epoch 11] ogbg-moltoxcast: 0.701886 val loss: 0.207950
[Epoch 11] ogbg-moltoxcast: 0.717660 test loss: 0.220147
[Epoch 12; Iter     1/  229] train: loss: 0.2683589
[ Using Seed :  5  ]
using device:  cuda:2
Log directory:  runs/split/3DInfomax/toxcast/random/train_prop=0.8/PNA_ogbg-moltoxcast_3DInfomax_toxcast_random=0.8_5_26-05_09-18-12
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/toxcast/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_random=0.8
logdir: runs/split/3DInfomax/toxcast/random/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6931801
[Epoch 1; Iter    60/  229] train: loss: 0.6932552
[Epoch 1; Iter    90/  229] train: loss: 0.6931607
[Epoch 1; Iter   120/  229] train: loss: 0.6931440
[Epoch 1; Iter   150/  229] train: loss: 0.6931209
[Epoch 1; Iter   180/  229] train: loss: 0.6931264
[Epoch 1; Iter   210/  229] train: loss: 0.6931499
[Epoch 1] ogbg-moltoxcast: 0.492839 val loss: 0.693108
[Epoch 1] ogbg-moltoxcast: 0.498249 test loss: 0.693103
[Epoch 2; Iter    11/  229] train: loss: 0.6930435
[Epoch 2; Iter    41/  229] train: loss: 0.6930563
[Epoch 2; Iter    71/  229] train: loss: 0.6931022
[Epoch 2; Iter   101/  229] train: loss: 0.6930713
[Epoch 2; Iter   131/  229] train: loss: 0.6931159
[Epoch 2; Iter   161/  229] train: loss: 0.6929587
[Epoch 2; Iter   191/  229] train: loss: 0.6929834
[Epoch 2; Iter   221/  229] train: loss: 0.6929175
[Epoch 2] ogbg-moltoxcast: 0.491505 val loss: 0.692974
[Epoch 2] ogbg-moltoxcast: 0.498637 test loss: 0.692967
[Epoch 3; Iter    22/  229] train: loss: 0.6929271
[Epoch 3; Iter    52/  229] train: loss: 0.6929829
[Epoch 3; Iter    82/  229] train: loss: 0.6929284
[Epoch 3; Iter   112/  229] train: loss: 0.6928884
[Epoch 3; Iter   142/  229] train: loss: 0.6928640
[Epoch 3; Iter   172/  229] train: loss: 0.6927779
[Epoch 3; Iter   202/  229] train: loss: 0.6927608
[Epoch 3] ogbg-moltoxcast: 0.491256 val loss: 0.692750
[Epoch 3] ogbg-moltoxcast: 0.498680 test loss: 0.692750
[Epoch 4; Iter     3/  229] train: loss: 0.6927848
[Epoch 4; Iter    33/  229] train: loss: 0.6901317
[Epoch 4; Iter    63/  229] train: loss: 0.6746194
[Epoch 4; Iter    93/  229] train: loss: 0.6397315
[Epoch 4; Iter   123/  229] train: loss: 0.6087247
[Epoch 4; Iter   153/  229] train: loss: 0.5613760
[Epoch 4; Iter   183/  229] train: loss: 0.5204883
[Epoch 4; Iter   213/  229] train: loss: 0.4888295
[Epoch 4] ogbg-moltoxcast: 0.588814 val loss: 0.427996
[Epoch 4] ogbg-moltoxcast: 0.612639 test loss: 0.446529
[Epoch 5; Iter    14/  229] train: loss: 0.3929101
[Epoch 5; Iter    44/  229] train: loss: 0.3581495
[Epoch 5; Iter    74/  229] train: loss: 0.3314231
[Epoch 5; Iter   104/  229] train: loss: 0.3081104
[Epoch 5; Iter   134/  229] train: loss: 0.2814184
[Epoch 5; Iter   164/  229] train: loss: 0.3271089
[Epoch 5; Iter   194/  229] train: loss: 0.2027876
[Epoch 5; Iter   224/  229] train: loss: 0.2599589
[Epoch 5] ogbg-moltoxcast: 0.630005 val loss: 0.235482
[Epoch 5] ogbg-moltoxcast: 0.668870 test loss: 0.251836
[Epoch 6; Iter    25/  229] train: loss: 0.2220829
[Epoch 6; Iter    55/  229] train: loss: 0.2198989
[Epoch 6; Iter    85/  229] train: loss: 0.1925599
[Epoch 6; Iter   115/  229] train: loss: 0.2242750
[Epoch 6; Iter   145/  229] train: loss: 0.2500751
[Epoch 6; Iter   175/  229] train: loss: 0.2026988
[Epoch 6; Iter   205/  229] train: loss: 0.2072404
[Epoch 6] ogbg-moltoxcast: 0.649547 val loss: 0.239086
[Epoch 6] ogbg-moltoxcast: 0.703111 test loss: 0.230822
[Epoch 7; Iter     6/  229] train: loss: 0.2636691
[Epoch 7; Iter    36/  229] train: loss: 0.2418026
[Epoch 7; Iter    66/  229] train: loss: 0.1816541
[Epoch 7; Iter    96/  229] train: loss: 0.2738905
[Epoch 7; Iter   126/  229] train: loss: 0.1521897
[Epoch 7; Iter   156/  229] train: loss: 0.1814965
[Epoch 7; Iter   186/  229] train: loss: 0.2944939
[Epoch 7; Iter   216/  229] train: loss: 0.1719215
[Epoch 7] ogbg-moltoxcast: 0.588083 val loss: 0.664490
[Epoch 7] ogbg-moltoxcast: 0.619346 test loss: 0.293929
[Epoch 8; Iter    17/  229] train: loss: 0.2523619
[Epoch 8; Iter    47/  229] train: loss: 0.1600137
[Epoch 8; Iter    77/  229] train: loss: 0.2094868
[Epoch 8; Iter   107/  229] train: loss: 0.3082146
[Epoch 8; Iter   137/  229] train: loss: 0.1518105
[Epoch 8; Iter   167/  229] train: loss: 0.1529182
[Epoch 8; Iter   197/  229] train: loss: 0.1869366
[Epoch 8; Iter   227/  229] train: loss: 0.2598697
[Epoch 8] ogbg-moltoxcast: 0.652671 val loss: 0.219729
[Epoch 8] ogbg-moltoxcast: 0.665199 test loss: 0.228633
[Epoch 9; Iter    28/  229] train: loss: 0.2297329
[Epoch 9; Iter    58/  229] train: loss: 0.2687735
[Epoch 9; Iter    88/  229] train: loss: 0.2313066
[Epoch 9; Iter   118/  229] train: loss: 0.1885139
[Epoch 9; Iter   148/  229] train: loss: 0.2132842
[Epoch 9; Iter   178/  229] train: loss: 0.2481251
[Epoch 9; Iter   208/  229] train: loss: 0.2388931
[Epoch 9] ogbg-moltoxcast: 0.664381 val loss: 0.211806
[Epoch 9] ogbg-moltoxcast: 0.684016 test loss: 0.229611
[Epoch 10; Iter     9/  229] train: loss: 0.2236681
[Epoch 10; Iter    39/  229] train: loss: 0.2630742
[Epoch 10; Iter    69/  229] train: loss: 0.1954615
[Epoch 10; Iter    99/  229] train: loss: 0.2602096
[Epoch 10; Iter   129/  229] train: loss: 0.2060094
[Epoch 10; Iter   159/  229] train: loss: 0.2747006
[Epoch 10; Iter   189/  229] train: loss: 0.2454577
[Epoch 10; Iter   219/  229] train: loss: 0.1800030
[Epoch 10] ogbg-moltoxcast: 0.685890 val loss: 0.206757
[Epoch 10] ogbg-moltoxcast: 0.704089 test loss: 0.223782
[Epoch 11; Iter    20/  229] train: loss: 0.2559393
[Epoch 11; Iter    50/  229] train: loss: 0.2569113
[Epoch 11; Iter    80/  229] train: loss: 0.2499347
[Epoch 11; Iter   110/  229] train: loss: 0.1994797
[Epoch 11; Iter   140/  229] train: loss: 0.1976914
[Epoch 11; Iter   170/  229] train: loss: 0.2127533
[Epoch 11; Iter   200/  229] train: loss: 0.1684627
[Epoch 11] ogbg-moltoxcast: 0.692018 val loss: 0.204104
[Epoch 11] ogbg-moltoxcast: 0.718456 test loss: 0.219767
[Epoch 12; Iter     1/  229] train: loss: 0.2310351
[ Using Seed :  4  ]
using device:  cuda:2
Log directory:  runs/split/3DInfomax/toxcast/random/train_prop=0.8/PNA_ogbg-moltoxcast_3DInfomax_toxcast_random=0.8_4_26-05_09-18-12
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/toxcast/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_random=0.8
logdir: runs/split/3DInfomax/toxcast/random/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6931514
[Epoch 1; Iter    60/  229] train: loss: 0.6932130
[Epoch 1; Iter    90/  229] train: loss: 0.6930983
[Epoch 1; Iter   120/  229] train: loss: 0.6931549
[Epoch 1; Iter   150/  229] train: loss: 0.6931662
[Epoch 1; Iter   180/  229] train: loss: 0.6930815
[Epoch 1; Iter   210/  229] train: loss: 0.6930970
[Epoch 1] ogbg-moltoxcast: 0.498421 val loss: 0.693126
[Epoch 1] ogbg-moltoxcast: 0.501601 test loss: 0.693131
[Epoch 2; Iter    11/  229] train: loss: 0.6931472
[Epoch 2; Iter    41/  229] train: loss: 0.6931570
[Epoch 2; Iter    71/  229] train: loss: 0.6930882
[Epoch 2; Iter   101/  229] train: loss: 0.6931639
[Epoch 2; Iter   131/  229] train: loss: 0.6931036
[Epoch 2; Iter   161/  229] train: loss: 0.6931000
[Epoch 2; Iter   191/  229] train: loss: 0.6930582
[Epoch 2; Iter   221/  229] train: loss: 0.6930650
[Epoch 2] ogbg-moltoxcast: 0.499082 val loss: 0.693033
[Epoch 2] ogbg-moltoxcast: 0.500708 test loss: 0.693036
[Epoch 3; Iter    22/  229] train: loss: 0.6929793
[Epoch 3; Iter    52/  229] train: loss: 0.6929587
[Epoch 3; Iter    82/  229] train: loss: 0.6930295
[Epoch 3; Iter   112/  229] train: loss: 0.6929811
[Epoch 3; Iter   142/  229] train: loss: 0.6928869
[Epoch 3; Iter   172/  229] train: loss: 0.6928288
[Epoch 3; Iter   202/  229] train: loss: 0.6929541
[Epoch 3] ogbg-moltoxcast: 0.499292 val loss: 0.692854
[Epoch 3] ogbg-moltoxcast: 0.501748 test loss: 0.692859
[Epoch 4; Iter     3/  229] train: loss: 0.6929007
[Epoch 4; Iter    33/  229] train: loss: 0.6901366
[Epoch 4; Iter    63/  229] train: loss: 0.6729978
[Epoch 4; Iter    93/  229] train: loss: 0.6432790
[Epoch 4; Iter   123/  229] train: loss: 0.6289551
[Epoch 4; Iter   153/  229] train: loss: 0.5802628
[Epoch 4; Iter   183/  229] train: loss: 0.5320462
[Epoch 4; Iter   213/  229] train: loss: 0.4974035
[Epoch 4] ogbg-moltoxcast: 0.616977 val loss: 0.415990
[Epoch 4] ogbg-moltoxcast: 0.605437 test loss: 0.429590
[Epoch 5; Iter    14/  229] train: loss: 0.4086069
[Epoch 5; Iter    44/  229] train: loss: 0.3613911
[Epoch 5; Iter    74/  229] train: loss: 0.3531468
[Epoch 5; Iter   104/  229] train: loss: 0.2648413
[Epoch 5; Iter   134/  229] train: loss: 0.2921884
[Epoch 5; Iter   164/  229] train: loss: 0.2446813
[Epoch 5; Iter   194/  229] train: loss: 0.1723609
[Epoch 5; Iter   224/  229] train: loss: 0.1751573
[Epoch 5] ogbg-moltoxcast: 0.652138 val loss: 0.235908
[Epoch 5] ogbg-moltoxcast: 0.683957 test loss: 0.254307
[Epoch 6; Iter    25/  229] train: loss: 0.2943676
[Epoch 6; Iter    55/  229] train: loss: 0.2604450
[Epoch 6; Iter    85/  229] train: loss: 0.1956261
[Epoch 6; Iter   115/  229] train: loss: 0.1888031
[Epoch 6; Iter   145/  229] train: loss: 0.1527554
[Epoch 6; Iter   175/  229] train: loss: 0.3118581
[Epoch 6; Iter   205/  229] train: loss: 0.2688909
[Epoch 6] ogbg-moltoxcast: 0.652596 val loss: 0.223961
[Epoch 6] ogbg-moltoxcast: 0.692261 test loss: 0.236179
[Epoch 7; Iter     6/  229] train: loss: 0.1853624
[Epoch 7; Iter    36/  229] train: loss: 0.2382738
[Epoch 7; Iter    66/  229] train: loss: 0.2004212
[Epoch 7; Iter    96/  229] train: loss: 0.2811667
[Epoch 7; Iter   126/  229] train: loss: 0.1958926
[Epoch 7; Iter   156/  229] train: loss: 0.2181467
[Epoch 7; Iter   186/  229] train: loss: 0.2388474
[Epoch 7; Iter   216/  229] train: loss: 0.1965439
[Epoch 7] ogbg-moltoxcast: 0.655515 val loss: 0.214627
[Epoch 7] ogbg-moltoxcast: 0.674949 test loss: 0.230858
[Epoch 8; Iter    17/  229] train: loss: 0.2742469
[Epoch 8; Iter    47/  229] train: loss: 0.1735038
[Epoch 8; Iter    77/  229] train: loss: 0.1935741
[Epoch 8; Iter   107/  229] train: loss: 0.1588502
[Epoch 8; Iter   137/  229] train: loss: 0.1931566
[Epoch 8; Iter   167/  229] train: loss: 0.2464166
[Epoch 8; Iter   197/  229] train: loss: 0.3387541
[Epoch 8; Iter   227/  229] train: loss: 0.1772216
[Epoch 8] ogbg-moltoxcast: 0.582819 val loss: 0.256648
[Epoch 8] ogbg-moltoxcast: 0.586469 test loss: 0.305793
[Epoch 9; Iter    28/  229] train: loss: 0.2284994
[Epoch 9; Iter    58/  229] train: loss: 0.1986130
[Epoch 9; Iter    88/  229] train: loss: 0.1902504
[Epoch 9; Iter   118/  229] train: loss: 0.2118371
[Epoch 9; Iter   148/  229] train: loss: 0.2418615
[Epoch 9; Iter   178/  229] train: loss: 0.2537162
[Epoch 9; Iter   208/  229] train: loss: 0.3029515
[Epoch 9] ogbg-moltoxcast: 0.680148 val loss: 0.207402
[Epoch 9] ogbg-moltoxcast: 0.695442 test loss: 0.224683
[Epoch 10; Iter     9/  229] train: loss: 0.1364246
[Epoch 10; Iter    39/  229] train: loss: 0.1231662
[Epoch 10; Iter    69/  229] train: loss: 0.2055487
[Epoch 10; Iter    99/  229] train: loss: 0.2244408
[Epoch 10; Iter   129/  229] train: loss: 0.2089697
[Epoch 10; Iter   159/  229] train: loss: 0.1985605
[Epoch 10; Iter   189/  229] train: loss: 0.2089083
[Epoch 10; Iter   219/  229] train: loss: 0.1693342
[Epoch 10] ogbg-moltoxcast: 0.682198 val loss: 0.212897
[Epoch 10] ogbg-moltoxcast: 0.660845 test loss: 0.237878
[Epoch 11; Iter    20/  229] train: loss: 0.2233308
[Epoch 11; Iter    50/  229] train: loss: 0.1805397
[Epoch 11; Iter    80/  229] train: loss: 0.1696305
[Epoch 11; Iter   110/  229] train: loss: 0.1897271
[Epoch 11; Iter   140/  229] train: loss: 0.1804637
[Epoch 11; Iter   170/  229] train: loss: 0.2284605
[Epoch 11; Iter   200/  229] train: loss: 0.2372004
[Epoch 11] ogbg-moltoxcast: 0.691408 val loss: 0.205424
[Epoch 11] ogbg-moltoxcast: 0.693235 test loss: 0.223727
[Epoch 12; Iter     1/  229] train: loss: 0.2215039
[ Using Seed :  4  ]
using device:  cuda:1
Log directory:  runs/split/3DInfomax/toxcast/random/train_prop=0.7/PNA_ogbg-moltoxcast_3DInfomax_toxcast_random=0.7_4_26-05_09-18-11
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/toxcast/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_random=0.7
logdir: runs/split/3DInfomax/toxcast/random/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  201] train: loss: 0.6930865
[Epoch 1; Iter    60/  201] train: loss: 0.6931561
[Epoch 1; Iter    90/  201] train: loss: 0.6931591
[Epoch 1; Iter   120/  201] train: loss: 0.6931301
[Epoch 1; Iter   150/  201] train: loss: 0.6931846
[Epoch 1; Iter   180/  201] train: loss: 0.6931734
[Epoch 1] ogbg-moltoxcast: 0.496076 val loss: 0.693143
[Epoch 1] ogbg-moltoxcast: 0.502896 test loss: 0.693130
[Epoch 2; Iter     9/  201] train: loss: 0.6931198
[Epoch 2; Iter    39/  201] train: loss: 0.6931216
[Epoch 2; Iter    69/  201] train: loss: 0.6931483
[Epoch 2; Iter    99/  201] train: loss: 0.6930338
[Epoch 2; Iter   129/  201] train: loss: 0.6930567
[Epoch 2; Iter   159/  201] train: loss: 0.6930192
[Epoch 2; Iter   189/  201] train: loss: 0.6930687
[Epoch 2] ogbg-moltoxcast: 0.497167 val loss: 0.693057
[Epoch 2] ogbg-moltoxcast: 0.504600 test loss: 0.693043
[Epoch 3; Iter    18/  201] train: loss: 0.6930486
[Epoch 3; Iter    48/  201] train: loss: 0.6929465
[Epoch 3; Iter    78/  201] train: loss: 0.6930248
[Epoch 3; Iter   108/  201] train: loss: 0.6929364
[Epoch 3; Iter   138/  201] train: loss: 0.6929920
[Epoch 3; Iter   168/  201] train: loss: 0.6928647
[Epoch 3; Iter   198/  201] train: loss: 0.6929805
[Epoch 3] ogbg-moltoxcast: 0.495536 val loss: 0.692937
[Epoch 3] ogbg-moltoxcast: 0.503459 test loss: 0.692925
[Epoch 4; Iter    27/  201] train: loss: 0.6929253
[Epoch 4; Iter    57/  201] train: loss: 0.6928659
[Epoch 4; Iter    87/  201] train: loss: 0.6928048
[Epoch 4; Iter   117/  201] train: loss: 0.6898093
[Epoch 4; Iter   147/  201] train: loss: 0.6722651
[Epoch 4; Iter   177/  201] train: loss: 0.6505401
[Epoch 4] ogbg-moltoxcast: 0.593661 val loss: 0.627882
[Epoch 4] ogbg-moltoxcast: 0.611025 test loss: 0.629012
[Epoch 5; Iter     6/  201] train: loss: 0.6319317
[Epoch 5; Iter    36/  201] train: loss: 0.5556167
[Epoch 5; Iter    66/  201] train: loss: 0.4873443
[Epoch 5; Iter    96/  201] train: loss: 0.4587567
[Epoch 5; Iter   126/  201] train: loss: 0.4146344
[Epoch 5; Iter   156/  201] train: loss: 0.3851064
[Epoch 5; Iter   186/  201] train: loss: 0.3679346
[Epoch 5] ogbg-moltoxcast: 0.567721 val loss: 0.305321
[Epoch 5] ogbg-moltoxcast: 0.588508 test loss: 0.307786
[Epoch 6; Iter    15/  201] train: loss: 0.2247573
[Epoch 6; Iter    45/  201] train: loss: 0.2640434
[Epoch 6; Iter    75/  201] train: loss: 0.2569501
[Epoch 6; Iter   105/  201] train: loss: 0.2557940
[Epoch 6; Iter   135/  201] train: loss: 0.2261228
[Epoch 6; Iter   165/  201] train: loss: 0.2214247
[Epoch 6; Iter   195/  201] train: loss: 0.2193565
[Epoch 6] ogbg-moltoxcast: 0.654153 val loss: 0.232518
[Epoch 6] ogbg-moltoxcast: 0.674189 test loss: 0.236882
[Epoch 7; Iter    24/  201] train: loss: 0.2312000
[Epoch 7; Iter    54/  201] train: loss: 0.1660340
[Epoch 7; Iter    84/  201] train: loss: 0.2396077
[Epoch 7; Iter   114/  201] train: loss: 0.1551339
[Epoch 7; Iter   144/  201] train: loss: 0.2018401
[Epoch 7; Iter   174/  201] train: loss: 0.1746152
[Epoch 7] ogbg-moltoxcast: 0.665044 val loss: 0.228321
[Epoch 7] ogbg-moltoxcast: 0.691321 test loss: 0.228291
[Epoch 8; Iter     3/  201] train: loss: 0.1659549
[Epoch 8; Iter    33/  201] train: loss: 0.2613463
[Epoch 8; Iter    63/  201] train: loss: 0.2083469
[Epoch 8; Iter    93/  201] train: loss: 0.1844418
[Epoch 8; Iter   123/  201] train: loss: 0.2044886
[Epoch 8; Iter   153/  201] train: loss: 0.1804338
[Epoch 8; Iter   183/  201] train: loss: 0.1950422
[Epoch 8] ogbg-moltoxcast: 0.656313 val loss: 0.226681
[Epoch 8] ogbg-moltoxcast: 0.682337 test loss: 0.234272
[Epoch 9; Iter    12/  201] train: loss: 0.2518280
[Epoch 9; Iter    42/  201] train: loss: 0.1694472
[Epoch 9; Iter    72/  201] train: loss: 0.2038974
[Epoch 9; Iter   102/  201] train: loss: 0.2350974
[Epoch 9; Iter   132/  201] train: loss: 0.1935940
[Epoch 9; Iter   162/  201] train: loss: 0.1299273
[Epoch 9; Iter   192/  201] train: loss: 0.1664938
[Epoch 9] ogbg-moltoxcast: 0.670735 val loss: 0.217662
[Epoch 9] ogbg-moltoxcast: 0.692543 test loss: 0.222482
[Epoch 10; Iter    21/  201] train: loss: 0.2835166
[Epoch 10; Iter    51/  201] train: loss: 0.2194473
[Epoch 10; Iter    81/  201] train: loss: 0.2472618
[Epoch 10; Iter   111/  201] train: loss: 0.1907167
[Epoch 10; Iter   141/  201] train: loss: 0.2012539
[Epoch 10; Iter   171/  201] train: loss: 0.1613696
[Epoch 10; Iter   201/  201] train: loss: 0.0645661
[Epoch 10] ogbg-moltoxcast: 0.676703 val loss: 0.221124
[Epoch 10] ogbg-moltoxcast: 0.694814 test loss: 0.225653
[Epoch 11; Iter    30/  201] train: loss: 0.1916566
[Epoch 11; Iter    60/  201] train: loss: 0.2449663
[Epoch 11; Iter    90/  201] train: loss: 0.1256666
[Epoch 11; Iter   120/  201] train: loss: 0.2824495
[Epoch 11; Iter   150/  201] train: loss: 0.1641816
[Epoch 11; Iter   180/  201] train: loss: 0.1730721
[Epoch 11] ogbg-moltoxcast: 0.667504 val loss: 0.218027
[Epoch 11] ogbg-moltoxcast: 0.697128 test loss: 0.220711
[Epoch 12; Iter     9/  201] train: loss: 0.2238299
[Epoch 12; Iter    39/  201] train: loss: 0.1721453
[Epoch 12; Iter    69/  201] train: loss: 0.2687218
[Epoch 12; Iter    99/  201] train: loss: 0.1988385
[Epoch 12; Iter   129/  201] train: loss: 0.1472555
[Epoch 12; Iter   159/  201] train: loss: 0.1458275
[Epoch 12; Iter   189/  201] train: loss: 0.1829503
[Epoch 12] ogbg-moltoxcast: 0.696961 val loss: 0.292245
[Epoch 12] ogbg-moltoxcast: 0.727289 test loss: 0.377205
[Epoch 13; Iter    18/  201] train: loss: 0.1728111
[Epoch 13; Iter    48/  201] train: loss: 0.2158082
[ Using Seed :  5  ]
using device:  cuda:1
Log directory:  runs/split/3DInfomax/toxcast/random/train_prop=0.7/PNA_ogbg-moltoxcast_3DInfomax_toxcast_random=0.7_5_26-05_09-18-13
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/toxcast/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_random=0.7
logdir: runs/split/3DInfomax/toxcast/random/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  201] train: loss: 0.6931600
[Epoch 1; Iter    60/  201] train: loss: 0.6931186
[Epoch 1; Iter    90/  201] train: loss: 0.6931281
[Epoch 1; Iter   120/  201] train: loss: 0.6931796
[Epoch 1; Iter   150/  201] train: loss: 0.6931868
[Epoch 1; Iter   180/  201] train: loss: 0.6931587
[Epoch 1] ogbg-moltoxcast: 0.494989 val loss: 0.693105
[Epoch 1] ogbg-moltoxcast: 0.494889 test loss: 0.693102
[Epoch 2; Iter     9/  201] train: loss: 0.6930975
[Epoch 2; Iter    39/  201] train: loss: 0.6930788
[Epoch 2; Iter    69/  201] train: loss: 0.6930203
[Epoch 2; Iter    99/  201] train: loss: 0.6930847
[Epoch 2; Iter   129/  201] train: loss: 0.6931636
[Epoch 2; Iter   159/  201] train: loss: 0.6930177
[Epoch 2; Iter   189/  201] train: loss: 0.6929802
[Epoch 2] ogbg-moltoxcast: 0.495315 val loss: 0.693019
[Epoch 2] ogbg-moltoxcast: 0.494805 test loss: 0.693010
[Epoch 3; Iter    18/  201] train: loss: 0.6930081
[Epoch 3; Iter    48/  201] train: loss: 0.6929846
[Epoch 3; Iter    78/  201] train: loss: 0.6930014
[Epoch 3; Iter   108/  201] train: loss: 0.6929708
[Epoch 3; Iter   138/  201] train: loss: 0.6929011
[Epoch 3; Iter   168/  201] train: loss: 0.6928877
[Epoch 3; Iter   198/  201] train: loss: 0.6927991
[Epoch 3] ogbg-moltoxcast: 0.496558 val loss: 0.692837
[Epoch 3] ogbg-moltoxcast: 0.494686 test loss: 0.692829
[Epoch 4; Iter    27/  201] train: loss: 0.6928396
[Epoch 4; Iter    57/  201] train: loss: 0.6927873
[Epoch 4; Iter    87/  201] train: loss: 0.6927760
[Epoch 4; Iter   117/  201] train: loss: 0.6902300
[Epoch 4; Iter   147/  201] train: loss: 0.6700588
[Epoch 4; Iter   177/  201] train: loss: 0.6418327
[Epoch 4] ogbg-moltoxcast: 0.597675 val loss: 0.636712
[Epoch 4] ogbg-moltoxcast: 0.629343 test loss: 0.636491
[Epoch 5; Iter     6/  201] train: loss: 0.6248421
[Epoch 5; Iter    36/  201] train: loss: 0.5823501
[Epoch 5; Iter    66/  201] train: loss: 0.5393612
[Epoch 5; Iter    96/  201] train: loss: 0.4361289
[Epoch 5; Iter   126/  201] train: loss: 0.4466866
[Epoch 5; Iter   156/  201] train: loss: 0.3714369
[Epoch 5; Iter   186/  201] train: loss: 0.3047595
[Epoch 5] ogbg-moltoxcast: 0.617381 val loss: 0.322533
[Epoch 5] ogbg-moltoxcast: 0.654905 test loss: 0.320505
[Epoch 6; Iter    15/  201] train: loss: 0.3263749
[Epoch 6; Iter    45/  201] train: loss: 0.3082652
[Epoch 6; Iter    75/  201] train: loss: 0.2832278
[Epoch 6; Iter   105/  201] train: loss: 0.2993347
[Epoch 6; Iter   135/  201] train: loss: 0.1807210
[Epoch 6; Iter   165/  201] train: loss: 0.2170638
[Epoch 6; Iter   195/  201] train: loss: 0.2670362
[Epoch 6] ogbg-moltoxcast: 0.654967 val loss: 0.234256
[Epoch 6] ogbg-moltoxcast: 0.686321 test loss: 0.236322
[Epoch 7; Iter    24/  201] train: loss: 0.1970953
[Epoch 7; Iter    54/  201] train: loss: 0.2822925
[Epoch 7; Iter    84/  201] train: loss: 0.1994931
[Epoch 7; Iter   114/  201] train: loss: 0.1890124
[Epoch 7; Iter   144/  201] train: loss: 0.1801295
[Epoch 7; Iter   174/  201] train: loss: 0.2242100
[Epoch 7] ogbg-moltoxcast: 0.659938 val loss: 0.227412
[Epoch 7] ogbg-moltoxcast: 0.685772 test loss: 0.230714
[Epoch 8; Iter     3/  201] train: loss: 0.1828526
[Epoch 8; Iter    33/  201] train: loss: 0.2251917
[Epoch 8; Iter    63/  201] train: loss: 0.2417760
[Epoch 8; Iter    93/  201] train: loss: 0.1710167
[Epoch 8; Iter   123/  201] train: loss: 0.1996228
[Epoch 8; Iter   153/  201] train: loss: 0.2562775
[Epoch 8; Iter   183/  201] train: loss: 0.1600966
[Epoch 8] ogbg-moltoxcast: 0.630266 val loss: 0.229668
[Epoch 8] ogbg-moltoxcast: 0.657673 test loss: 0.233376
[Epoch 9; Iter    12/  201] train: loss: 0.2944499
[Epoch 9; Iter    42/  201] train: loss: 0.2277286
[Epoch 9; Iter    72/  201] train: loss: 0.2082598
[Epoch 9; Iter   102/  201] train: loss: 0.2041223
[Epoch 9; Iter   132/  201] train: loss: 0.1772747
[Epoch 9; Iter   162/  201] train: loss: 0.2374664
[Epoch 9; Iter   192/  201] train: loss: 0.1692040
[Epoch 9] ogbg-moltoxcast: 0.644709 val loss: 0.223833
[Epoch 9] ogbg-moltoxcast: 0.675470 test loss: 0.226175
[Epoch 10; Iter    21/  201] train: loss: 0.3021536
[Epoch 10; Iter    51/  201] train: loss: 0.1499565
[Epoch 10; Iter    81/  201] train: loss: 0.2197478
[Epoch 10; Iter   111/  201] train: loss: 0.1930677
[Epoch 10; Iter   141/  201] train: loss: 0.2271488
[Epoch 10; Iter   171/  201] train: loss: 0.2567315
[Epoch 10; Iter   201/  201] train: loss: 0.1337318
[Epoch 10] ogbg-moltoxcast: 0.676352 val loss: 0.219621
[Epoch 10] ogbg-moltoxcast: 0.709431 test loss: 0.222998
[Epoch 11; Iter    30/  201] train: loss: 0.3034561
[Epoch 11; Iter    60/  201] train: loss: 0.1637588
[Epoch 11; Iter    90/  201] train: loss: 0.2222630
[Epoch 11; Iter   120/  201] train: loss: 0.1987261
[Epoch 11; Iter   150/  201] train: loss: 0.1642316
[Epoch 11; Iter   180/  201] train: loss: 0.3130759
[Epoch 11] ogbg-moltoxcast: 0.664499 val loss: 0.222222
[Epoch 11] ogbg-moltoxcast: 0.701592 test loss: 0.219163
[Epoch 12; Iter     9/  201] train: loss: 0.1655857
[Epoch 12; Iter    39/  201] train: loss: 0.2249089
[Epoch 12; Iter    69/  201] train: loss: 0.1820332
[Epoch 12; Iter    99/  201] train: loss: 0.1829662
[Epoch 12; Iter   129/  201] train: loss: 0.1844368
[Epoch 12; Iter   159/  201] train: loss: 0.1796995
[Epoch 12; Iter   189/  201] train: loss: 0.2468975
[Epoch 12] ogbg-moltoxcast: 0.675339 val loss: 0.222598
[Epoch 12] ogbg-moltoxcast: 0.701211 test loss: 0.221627
[Epoch 13; Iter    18/  201] train: loss: 0.1905538
[Epoch 13; Iter    48/  201] train: loss: 0.1586006
[ Using Seed :  6  ]
using device:  cuda:1
Log directory:  runs/split/3DInfomax/toxcast/random/train_prop=0.7/PNA_ogbg-moltoxcast_3DInfomax_toxcast_random=0.7_6_26-05_09-18-12
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/toxcast/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_random=0.7
logdir: runs/split/3DInfomax/toxcast/random/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  201] train: loss: 0.6931601
[Epoch 1; Iter    60/  201] train: loss: 0.6931234
[Epoch 1; Iter    90/  201] train: loss: 0.6931405
[Epoch 1; Iter   120/  201] train: loss: 0.6932274
[Epoch 1; Iter   150/  201] train: loss: 0.6930450
[Epoch 1; Iter   180/  201] train: loss: 0.6931450
[Epoch 1] ogbg-moltoxcast: 0.495888 val loss: 0.693136
[Epoch 1] ogbg-moltoxcast: 0.503540 test loss: 0.693133
[Epoch 2; Iter     9/  201] train: loss: 0.6931891
[Epoch 2; Iter    39/  201] train: loss: 0.6931152
[Epoch 2; Iter    69/  201] train: loss: 0.6931226
[Epoch 2; Iter    99/  201] train: loss: 0.6930859
[Epoch 2; Iter   129/  201] train: loss: 0.6931177
[Epoch 2; Iter   159/  201] train: loss: 0.6931084
[Epoch 2; Iter   189/  201] train: loss: 0.6930663
[Epoch 2] ogbg-moltoxcast: 0.495916 val loss: 0.693064
[Epoch 2] ogbg-moltoxcast: 0.503159 test loss: 0.693059
[Epoch 3; Iter    18/  201] train: loss: 0.6929802
[Epoch 3; Iter    48/  201] train: loss: 0.6930054
[Epoch 3; Iter    78/  201] train: loss: 0.6930089
[Epoch 3; Iter   108/  201] train: loss: 0.6929421
[Epoch 3; Iter   138/  201] train: loss: 0.6929521
[Epoch 3; Iter   168/  201] train: loss: 0.6928958
[Epoch 3; Iter   198/  201] train: loss: 0.6929138
[Epoch 3] ogbg-moltoxcast: 0.496040 val loss: 0.692923
[Epoch 3] ogbg-moltoxcast: 0.503301 test loss: 0.692919
[Epoch 4; Iter    27/  201] train: loss: 0.6928647
[Epoch 4; Iter    57/  201] train: loss: 0.6928130
[Epoch 4; Iter    87/  201] train: loss: 0.6928285
[Epoch 4; Iter   117/  201] train: loss: 0.6902425
[Epoch 4; Iter   147/  201] train: loss: 0.6727521
[Epoch 4; Iter   177/  201] train: loss: 0.6332878
[Epoch 4] ogbg-moltoxcast: 0.554751 val loss: 0.631022
[Epoch 4] ogbg-moltoxcast: 0.585662 test loss: 0.628657
[Epoch 5; Iter     6/  201] train: loss: 0.6214728
[Epoch 5; Iter    36/  201] train: loss: 0.5616882
[Epoch 5; Iter    66/  201] train: loss: 0.5151988
[Epoch 5; Iter    96/  201] train: loss: 0.4626308
[Epoch 5; Iter   126/  201] train: loss: 0.4403873
[Epoch 5; Iter   156/  201] train: loss: 0.3743241
[Epoch 5; Iter   186/  201] train: loss: 0.3003400
[Epoch 5] ogbg-moltoxcast: 0.627413 val loss: 0.320389
[Epoch 5] ogbg-moltoxcast: 0.653680 test loss: 0.318611
[Epoch 6; Iter    15/  201] train: loss: 0.3393688
[Epoch 6; Iter    45/  201] train: loss: 0.2738240
[Epoch 6; Iter    75/  201] train: loss: 0.2373066
[Epoch 6; Iter   105/  201] train: loss: 0.2509451
[Epoch 6; Iter   135/  201] train: loss: 0.2910459
[Epoch 6; Iter   165/  201] train: loss: 0.1953913
[Epoch 6; Iter   195/  201] train: loss: 0.2058221
[Epoch 6] ogbg-moltoxcast: 0.646090 val loss: 0.235691
[Epoch 6] ogbg-moltoxcast: 0.678688 test loss: 0.239332
[Epoch 7; Iter    24/  201] train: loss: 0.1144027
[Epoch 7; Iter    54/  201] train: loss: 0.1887663
[Epoch 7; Iter    84/  201] train: loss: 0.2431062
[Epoch 7; Iter   114/  201] train: loss: 0.2210332
[Epoch 7; Iter   144/  201] train: loss: 0.1979805
[Epoch 7; Iter   174/  201] train: loss: 0.1731427
[Epoch 7] ogbg-moltoxcast: 0.668342 val loss: 0.223699
[Epoch 7] ogbg-moltoxcast: 0.697117 test loss: 0.227806
[Epoch 8; Iter     3/  201] train: loss: 0.2102990
[Epoch 8; Iter    33/  201] train: loss: 0.1873351
[Epoch 8; Iter    63/  201] train: loss: 0.2026292
[Epoch 8; Iter    93/  201] train: loss: 0.2220262
[Epoch 8; Iter   123/  201] train: loss: 0.2452055
[Epoch 8; Iter   153/  201] train: loss: 0.1497800
[Epoch 8; Iter   183/  201] train: loss: 0.2018383
[Epoch 8] ogbg-moltoxcast: 0.626163 val loss: 0.227899
[Epoch 8] ogbg-moltoxcast: 0.650199 test loss: 0.235640
[Epoch 9; Iter    12/  201] train: loss: 0.1964914
[Epoch 9; Iter    42/  201] train: loss: 0.1664509
[Epoch 9; Iter    72/  201] train: loss: 0.1351710
[Epoch 9; Iter   102/  201] train: loss: 0.2100081
[Epoch 9; Iter   132/  201] train: loss: 0.2501521
[Epoch 9; Iter   162/  201] train: loss: 0.1988483
[Epoch 9; Iter   192/  201] train: loss: 0.1466790
[Epoch 9] ogbg-moltoxcast: 0.634687 val loss: 0.226112
[Epoch 9] ogbg-moltoxcast: 0.681839 test loss: 0.229137
[Epoch 10; Iter    21/  201] train: loss: 0.2159938
[Epoch 10; Iter    51/  201] train: loss: 0.2131095
[Epoch 10; Iter    81/  201] train: loss: 0.2038975
[Epoch 10; Iter   111/  201] train: loss: 0.2974305
[Epoch 10; Iter   141/  201] train: loss: 0.2161099
[Epoch 10; Iter   171/  201] train: loss: 0.1275619
[Epoch 10; Iter   201/  201] train: loss: 0.1937024
[Epoch 10] ogbg-moltoxcast: 0.687218 val loss: 0.214560
[Epoch 10] ogbg-moltoxcast: 0.707579 test loss: 0.219277
[Epoch 11; Iter    30/  201] train: loss: 0.1996867
[Epoch 11; Iter    60/  201] train: loss: 0.2498549
[Epoch 11; Iter    90/  201] train: loss: 0.1627425
[Epoch 11; Iter   120/  201] train: loss: 0.1558657
[Epoch 11; Iter   150/  201] train: loss: 0.2490797
[Epoch 11; Iter   180/  201] train: loss: 0.2098757
[Epoch 11] ogbg-moltoxcast: 0.647917 val loss: 0.227680
[Epoch 11] ogbg-moltoxcast: 0.661827 test loss: 0.234464
[Epoch 12; Iter     9/  201] train: loss: 0.2317077
[Epoch 12; Iter    39/  201] train: loss: 0.2709287
[Epoch 12; Iter    69/  201] train: loss: 0.2060565
[Epoch 12; Iter    99/  201] train: loss: 0.1673520
[Epoch 12; Iter   129/  201] train: loss: 0.2045932
[Epoch 12; Iter   159/  201] train: loss: 0.2403579
[Epoch 12; Iter   189/  201] train: loss: 0.1897637
[Epoch 12] ogbg-moltoxcast: 0.693324 val loss: 0.213030
[Epoch 12] ogbg-moltoxcast: 0.714946 test loss: 0.219117
[Epoch 13; Iter    18/  201] train: loss: 0.1688605
[Epoch 13; Iter    48/  201] train: loss: 0.1528877
[ Using Seed :  5  ]
using device:  cuda:0
Log directory:  runs/split/3DInfomax/toxcast/random/train_prop=0.6/PNA_ogbg-moltoxcast_3DInfomax_toxcast_random=0.6_5_26-05_09-18-13
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/toxcast/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_random=0.6
logdir: runs/split/3DInfomax/toxcast/random/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  172] train: loss: 0.6931836
[Epoch 1; Iter    60/  172] train: loss: 0.6931117
[Epoch 1; Iter    90/  172] train: loss: 0.6932032
[Epoch 1; Iter   120/  172] train: loss: 0.6930667
[Epoch 1; Iter   150/  172] train: loss: 0.6931327
[Epoch 1] ogbg-moltoxcast: 0.501292 val loss: 0.693123
[Epoch 1] ogbg-moltoxcast: 0.494263 test loss: 0.693121
[Epoch 2; Iter     8/  172] train: loss: 0.6931673
[Epoch 2; Iter    38/  172] train: loss: 0.6930566
[Epoch 2; Iter    68/  172] train: loss: 0.6930401
[Epoch 2; Iter    98/  172] train: loss: 0.6931280
[Epoch 2; Iter   128/  172] train: loss: 0.6930819
[Epoch 2; Iter   158/  172] train: loss: 0.6930943
[Epoch 2] ogbg-moltoxcast: 0.501332 val loss: 0.693057
[Epoch 2] ogbg-moltoxcast: 0.494213 test loss: 0.693055
[Epoch 3; Iter    16/  172] train: loss: 0.6929840
[Epoch 3; Iter    46/  172] train: loss: 0.6929898
[Epoch 3; Iter    76/  172] train: loss: 0.6930656
[Epoch 3; Iter   106/  172] train: loss: 0.6929657
[Epoch 3; Iter   136/  172] train: loss: 0.6929396
[Epoch 3; Iter   166/  172] train: loss: 0.6928911
[Epoch 3] ogbg-moltoxcast: 0.502145 val loss: 0.692920
[Epoch 3] ogbg-moltoxcast: 0.494139 test loss: 0.692917
[Epoch 4; Iter    24/  172] train: loss: 0.6928554
[Epoch 4; Iter    54/  172] train: loss: 0.6927629
[Epoch 4; Iter    84/  172] train: loss: 0.6928929
[Epoch 4; Iter   114/  172] train: loss: 0.6927636
[Epoch 4; Iter   144/  172] train: loss: 0.6928284
[Epoch 4] ogbg-moltoxcast: 0.502088 val loss: 0.692745
[Epoch 4] ogbg-moltoxcast: 0.495709 test loss: 0.692739
[Epoch 5; Iter     2/  172] train: loss: 0.6926480
[Epoch 5; Iter    32/  172] train: loss: 0.6894609
[Epoch 5; Iter    62/  172] train: loss: 0.6692464
[Epoch 5; Iter    92/  172] train: loss: 0.6338484
[Epoch 5; Iter   122/  172] train: loss: 0.5966560
[Epoch 5; Iter   152/  172] train: loss: 0.5629320
[Epoch 5] ogbg-moltoxcast: 0.606884 val loss: 0.528398
[Epoch 5] ogbg-moltoxcast: 0.632357 test loss: 0.527528
[Epoch 6; Iter    10/  172] train: loss: 0.5240203
[Epoch 6; Iter    40/  172] train: loss: 0.4655605
[Epoch 6; Iter    70/  172] train: loss: 0.3943735
[Epoch 6; Iter   100/  172] train: loss: 0.3537075
[Epoch 6; Iter   130/  172] train: loss: 0.3005144
[Epoch 6; Iter   160/  172] train: loss: 0.2681495
[Epoch 6] ogbg-moltoxcast: 0.628548 val loss: 0.273785
[Epoch 6] ogbg-moltoxcast: 0.638846 test loss: 0.271705
[Epoch 7; Iter    18/  172] train: loss: 0.3186908
[Epoch 7; Iter    48/  172] train: loss: 0.2927375
[Epoch 7; Iter    78/  172] train: loss: 0.2340822
[Epoch 7; Iter   108/  172] train: loss: 0.1800440
[Epoch 7; Iter   138/  172] train: loss: 0.2796787
[Epoch 7; Iter   168/  172] train: loss: 0.2038646
[Epoch 7] ogbg-moltoxcast: 0.662087 val loss: 0.232099
[Epoch 7] ogbg-moltoxcast: 0.677184 test loss: 0.230630
[Epoch 8; Iter    26/  172] train: loss: 0.1540370
[Epoch 8; Iter    56/  172] train: loss: 0.2744943
[Epoch 8; Iter    86/  172] train: loss: 0.2119281
[Epoch 8; Iter   116/  172] train: loss: 0.2185257
[Epoch 8; Iter   146/  172] train: loss: 0.1999180
[Epoch 8] ogbg-moltoxcast: 0.650695 val loss: 0.230270
[Epoch 8] ogbg-moltoxcast: 0.658258 test loss: 0.230443
[Epoch 9; Iter     4/  172] train: loss: 0.2811898
[Epoch 9; Iter    34/  172] train: loss: 0.2098740
[Epoch 9; Iter    64/  172] train: loss: 0.3176813
[Epoch 9; Iter    94/  172] train: loss: 0.1945031
[Epoch 9; Iter   124/  172] train: loss: 0.1913508
[Epoch 9; Iter   154/  172] train: loss: 0.1698610
[Epoch 9] ogbg-moltoxcast: 0.645703 val loss: 0.230355
[Epoch 9] ogbg-moltoxcast: 0.668163 test loss: 0.231063
[Epoch 10; Iter    12/  172] train: loss: 0.2489811
[Epoch 10; Iter    42/  172] train: loss: 0.1852382
[Epoch 10; Iter    72/  172] train: loss: 0.1881035
[Epoch 10; Iter   102/  172] train: loss: 0.2372228
[Epoch 10; Iter   132/  172] train: loss: 0.2564780
[Epoch 10; Iter   162/  172] train: loss: 0.1567592
[Epoch 10] ogbg-moltoxcast: 0.626523 val loss: 0.236256
[Epoch 10] ogbg-moltoxcast: 0.627317 test loss: 0.231617
[Epoch 11; Iter    20/  172] train: loss: 0.2375071
[Epoch 11; Iter    50/  172] train: loss: 0.1787932
[Epoch 11; Iter    80/  172] train: loss: 0.3231958
[Epoch 11; Iter   110/  172] train: loss: 0.2794236
[Epoch 11; Iter   140/  172] train: loss: 0.2535854
[Epoch 11; Iter   170/  172] train: loss: 0.1887736
[Epoch 11] ogbg-moltoxcast: 0.643260 val loss: 0.243425
[Epoch 11] ogbg-moltoxcast: 0.656618 test loss: 0.222855
[Epoch 12; Iter    28/  172] train: loss: 0.1868205
[Epoch 12; Iter    58/  172] train: loss: 0.1955010
[Epoch 12; Iter    88/  172] train: loss: 0.2109948
[Epoch 12; Iter   118/  172] train: loss: 0.1578224
[Epoch 12; Iter   148/  172] train: loss: 0.1454148
[Epoch 12] ogbg-moltoxcast: 0.667073 val loss: 0.224764
[Epoch 12] ogbg-moltoxcast: 0.685710 test loss: 0.216001
[Epoch 13; Iter     6/  172] train: loss: 0.2461070
[Epoch 13; Iter    36/  172] train: loss: 0.3442595
[Epoch 13; Iter    66/  172] train: loss: 0.1722114
[Epoch 13; Iter    96/  172] train: loss: 0.2722487
[Epoch 13; Iter   126/  172] train: loss: 0.1681134
[Epoch 13; Iter   156/  172] train: loss: 0.1750008
[Epoch 13] ogbg-moltoxcast: 0.678832 val loss: 0.217809
[Epoch 13] ogbg-moltoxcast: 0.691432 test loss: 0.216478
[Epoch 14; Iter    14/  172] train: loss: 0.1907107
[Epoch 14; Iter    44/  172] train: loss: 0.2134857
[Epoch 14; Iter    74/  172] train: loss: 0.1417212
[Epoch 14; Iter   104/  172] train: loss: 0.2491678
[Epoch 14; Iter   134/  172] train: loss: 0.2334426
[ Using Seed :  4  ]
using device:  cuda:0
Log directory:  runs/split/3DInfomax/toxcast/random/train_prop=0.6/PNA_ogbg-moltoxcast_3DInfomax_toxcast_random=0.6_4_26-05_09-18-12
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/toxcast/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_random=0.6
logdir: runs/split/3DInfomax/toxcast/random/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  172] train: loss: 0.6932088
[Epoch 1; Iter    60/  172] train: loss: 0.6931821
[Epoch 1; Iter    90/  172] train: loss: 0.6931480
[Epoch 1; Iter   120/  172] train: loss: 0.6930978
[Epoch 1; Iter   150/  172] train: loss: 0.6931264
[Epoch 1] ogbg-moltoxcast: 0.499432 val loss: 0.693139
[Epoch 1] ogbg-moltoxcast: 0.501779 test loss: 0.693134
[Epoch 2; Iter     8/  172] train: loss: 0.6930962
[Epoch 2; Iter    38/  172] train: loss: 0.6931618
[Epoch 2; Iter    68/  172] train: loss: 0.6931872
[Epoch 2; Iter    98/  172] train: loss: 0.6931515
[Epoch 2; Iter   128/  172] train: loss: 0.6930948
[Epoch 2; Iter   158/  172] train: loss: 0.6930455
[Epoch 2] ogbg-moltoxcast: 0.499099 val loss: 0.693086
[Epoch 2] ogbg-moltoxcast: 0.502190 test loss: 0.693082
[Epoch 3; Iter    16/  172] train: loss: 0.6930494
[Epoch 3; Iter    46/  172] train: loss: 0.6930851
[Epoch 3; Iter    76/  172] train: loss: 0.6930629
[Epoch 3; Iter   106/  172] train: loss: 0.6930191
[Epoch 3; Iter   136/  172] train: loss: 0.6930367
[Epoch 3; Iter   166/  172] train: loss: 0.6929733
[Epoch 3] ogbg-moltoxcast: 0.499549 val loss: 0.693001
[Epoch 3] ogbg-moltoxcast: 0.502211 test loss: 0.692996
[Epoch 4; Iter    24/  172] train: loss: 0.6929813
[Epoch 4; Iter    54/  172] train: loss: 0.6929599
[Epoch 4; Iter    84/  172] train: loss: 0.6929537
[Epoch 4; Iter   114/  172] train: loss: 0.6929289
[Epoch 4; Iter   144/  172] train: loss: 0.6928965
[Epoch 4] ogbg-moltoxcast: 0.499246 val loss: 0.692866
[Epoch 4] ogbg-moltoxcast: 0.501662 test loss: 0.692859
[Epoch 5; Iter     2/  172] train: loss: 0.6928300
[Epoch 5; Iter    32/  172] train: loss: 0.6897044
[Epoch 5; Iter    62/  172] train: loss: 0.6725266
[Epoch 5; Iter    92/  172] train: loss: 0.6374114
[Epoch 5; Iter   122/  172] train: loss: 0.5956186
[Epoch 5; Iter   152/  172] train: loss: 0.5751129
[Epoch 5] ogbg-moltoxcast: 0.598273 val loss: 0.511790
[Epoch 5] ogbg-moltoxcast: 0.608672 test loss: 0.510130
[Epoch 6; Iter    10/  172] train: loss: 0.5265989
[Epoch 6; Iter    40/  172] train: loss: 0.4855338
[Epoch 6; Iter    70/  172] train: loss: 0.3947841
[Epoch 6; Iter   100/  172] train: loss: 0.3842209
[Epoch 6; Iter   130/  172] train: loss: 0.3045633
[Epoch 6; Iter   160/  172] train: loss: 0.3248924
[Epoch 6] ogbg-moltoxcast: 0.626451 val loss: 0.298450
[Epoch 6] ogbg-moltoxcast: 0.639718 test loss: 0.294419
[Epoch 7; Iter    18/  172] train: loss: 0.2125653
[Epoch 7; Iter    48/  172] train: loss: 0.2147783
[Epoch 7; Iter    78/  172] train: loss: 0.2199757
[Epoch 7; Iter   108/  172] train: loss: 0.3951791
[Epoch 7; Iter   138/  172] train: loss: 0.2442593
[Epoch 7; Iter   168/  172] train: loss: 0.2045421
[Epoch 7] ogbg-moltoxcast: 0.649816 val loss: 0.236899
[Epoch 7] ogbg-moltoxcast: 0.665065 test loss: 0.233313
[Epoch 8; Iter    26/  172] train: loss: 0.1785009
[Epoch 8; Iter    56/  172] train: loss: 0.1491559
[Epoch 8; Iter    86/  172] train: loss: 0.2294700
[Epoch 8; Iter   116/  172] train: loss: 0.1589602
[Epoch 8; Iter   146/  172] train: loss: 0.2022809
[Epoch 8] ogbg-moltoxcast: 0.664285 val loss: 0.231746
[Epoch 8] ogbg-moltoxcast: 0.679301 test loss: 0.222002
[Epoch 9; Iter     4/  172] train: loss: 0.2263578
[Epoch 9; Iter    34/  172] train: loss: 0.2319157
[Epoch 9; Iter    64/  172] train: loss: 0.2533536
[Epoch 9; Iter    94/  172] train: loss: 0.2958394
[Epoch 9; Iter   124/  172] train: loss: 0.1718359
[Epoch 9; Iter   154/  172] train: loss: 0.2015655
[Epoch 9] ogbg-moltoxcast: 0.659343 val loss: 0.223790
[Epoch 9] ogbg-moltoxcast: 0.674279 test loss: 0.265683
[Epoch 10; Iter    12/  172] train: loss: 0.3028587
[Epoch 10; Iter    42/  172] train: loss: 0.1726413
[Epoch 10; Iter    72/  172] train: loss: 0.1731779
[Epoch 10; Iter   102/  172] train: loss: 0.2013277
[Epoch 10; Iter   132/  172] train: loss: 0.2211881
[Epoch 10; Iter   162/  172] train: loss: 0.2406296
[Epoch 10] ogbg-moltoxcast: 0.655584 val loss: 0.226621
[Epoch 10] ogbg-moltoxcast: 0.663932 test loss: 0.229397
[Epoch 11; Iter    20/  172] train: loss: 0.2233244
[Epoch 11; Iter    50/  172] train: loss: 0.1817635
[Epoch 11; Iter    80/  172] train: loss: 0.1959225
[Epoch 11; Iter   110/  172] train: loss: 0.1615126
[Epoch 11; Iter   140/  172] train: loss: 0.2287995
[Epoch 11; Iter   170/  172] train: loss: 0.2281593
[Epoch 11] ogbg-moltoxcast: 0.632757 val loss: 0.283113
[Epoch 11] ogbg-moltoxcast: 0.646050 test loss: 0.279423
[Epoch 12; Iter    28/  172] train: loss: 0.2334431
[Epoch 12; Iter    58/  172] train: loss: 0.2273716
[Epoch 12; Iter    88/  172] train: loss: 0.2385385
[Epoch 12; Iter   118/  172] train: loss: 0.2413040
[Epoch 12; Iter   148/  172] train: loss: 0.2238733
[Epoch 12] ogbg-moltoxcast: 0.670806 val loss: 0.266625
[Epoch 12] ogbg-moltoxcast: 0.679286 test loss: 0.217504
[Epoch 13; Iter     6/  172] train: loss: 0.1305327
[Epoch 13; Iter    36/  172] train: loss: 0.1378369
[Epoch 13; Iter    66/  172] train: loss: 0.1765524
[Epoch 13; Iter    96/  172] train: loss: 0.1344959
[Epoch 13; Iter   126/  172] train: loss: 0.1429686
[Epoch 13; Iter   156/  172] train: loss: 0.2975947
[Epoch 13] ogbg-moltoxcast: 0.676037 val loss: 0.296410
[Epoch 13] ogbg-moltoxcast: 0.692051 test loss: 0.216258
[Epoch 14; Iter    14/  172] train: loss: 0.1588514
[Epoch 14; Iter    44/  172] train: loss: 0.2463221
[Epoch 14; Iter    74/  172] train: loss: 0.1939452
[Epoch 14; Iter   104/  172] train: loss: 0.1316648
[Epoch 14; Iter   134/  172] train: loss: 0.2570696
[ Using Seed :  6  ]
using device:  cuda:0
Log directory:  runs/split/3DInfomax/toxcast/random/train_prop=0.6/PNA_ogbg-moltoxcast_3DInfomax_toxcast_random=0.6_6_26-05_09-18-12
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/toxcast/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_random=0.6
logdir: runs/split/3DInfomax/toxcast/random/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  172] train: loss: 0.6930207
[Epoch 1; Iter    60/  172] train: loss: 0.6931787
[Epoch 1; Iter    90/  172] train: loss: 0.6931299
[Epoch 1; Iter   120/  172] train: loss: 0.6931233
[Epoch 1; Iter   150/  172] train: loss: 0.6931795
[Epoch 1] ogbg-moltoxcast: 0.500592 val loss: 0.693140
[Epoch 1] ogbg-moltoxcast: 0.500083 test loss: 0.693145
[Epoch 2; Iter     8/  172] train: loss: 0.6931852
[Epoch 2; Iter    38/  172] train: loss: 0.6931217
[Epoch 2; Iter    68/  172] train: loss: 0.6930933
[Epoch 2; Iter    98/  172] train: loss: 0.6931087
[Epoch 2; Iter   128/  172] train: loss: 0.6930317
[Epoch 2; Iter   158/  172] train: loss: 0.6931147
[Epoch 2] ogbg-moltoxcast: 0.500366 val loss: 0.693077
[Epoch 2] ogbg-moltoxcast: 0.500448 test loss: 0.693080
[Epoch 3; Iter    16/  172] train: loss: 0.6931221
[Epoch 3; Iter    46/  172] train: loss: 0.6930223
[Epoch 3; Iter    76/  172] train: loss: 0.6930151
[Epoch 3; Iter   106/  172] train: loss: 0.6930119
[Epoch 3; Iter   136/  172] train: loss: 0.6929703
[Epoch 3; Iter   166/  172] train: loss: 0.6930119
[Epoch 3] ogbg-moltoxcast: 0.500935 val loss: 0.692991
[Epoch 3] ogbg-moltoxcast: 0.499435 test loss: 0.692994
[Epoch 4; Iter    24/  172] train: loss: 0.6929691
[Epoch 4; Iter    54/  172] train: loss: 0.6929125
[Epoch 4; Iter    84/  172] train: loss: 0.6928595
[Epoch 4; Iter   114/  172] train: loss: 0.6929388
[Epoch 4; Iter   144/  172] train: loss: 0.6928435
[Epoch 4] ogbg-moltoxcast: 0.500635 val loss: 0.692841
[Epoch 4] ogbg-moltoxcast: 0.498905 test loss: 0.692842
[Epoch 5; Iter     2/  172] train: loss: 0.6928513
[Epoch 5; Iter    32/  172] train: loss: 0.6898894
[Epoch 5; Iter    62/  172] train: loss: 0.6703661
[Epoch 5; Iter    92/  172] train: loss: 0.6399954
[Epoch 5; Iter   122/  172] train: loss: 0.6121445
[Epoch 5; Iter   152/  172] train: loss: 0.5507747
[Epoch 5] ogbg-moltoxcast: 0.602832 val loss: 0.516214
[Epoch 5] ogbg-moltoxcast: 0.615428 test loss: 0.511446
[Epoch 6; Iter    10/  172] train: loss: 0.5025983
[Epoch 6; Iter    40/  172] train: loss: 0.4701598
[Epoch 6; Iter    70/  172] train: loss: 0.4130636
[Epoch 6; Iter   100/  172] train: loss: 0.3860034
[Epoch 6; Iter   130/  172] train: loss: 0.2944878
[Epoch 6; Iter   160/  172] train: loss: 0.2267552
[Epoch 6] ogbg-moltoxcast: 0.627597 val loss: 0.308003
[Epoch 6] ogbg-moltoxcast: 0.638928 test loss: 0.305983
[Epoch 7; Iter    18/  172] train: loss: 0.3341492
[Epoch 7; Iter    48/  172] train: loss: 0.3077288
[Epoch 7; Iter    78/  172] train: loss: 0.2101500
[Epoch 7; Iter   108/  172] train: loss: 0.2266356
[Epoch 7; Iter   138/  172] train: loss: 0.1888222
[Epoch 7; Iter   168/  172] train: loss: 0.2700397
[Epoch 7] ogbg-moltoxcast: 0.648446 val loss: 0.236833
[Epoch 7] ogbg-moltoxcast: 0.670188 test loss: 0.233650
[Epoch 8; Iter    26/  172] train: loss: 0.2203217
[Epoch 8; Iter    56/  172] train: loss: 0.1472711
[Epoch 8; Iter    86/  172] train: loss: 0.2573929
[Epoch 8; Iter   116/  172] train: loss: 0.1368181
[Epoch 8; Iter   146/  172] train: loss: 0.1635935
[Epoch 8] ogbg-moltoxcast: 0.663110 val loss: 0.233168
[Epoch 8] ogbg-moltoxcast: 0.679942 test loss: 0.229768
[Epoch 9; Iter     4/  172] train: loss: 0.2766598
[Epoch 9; Iter    34/  172] train: loss: 0.2011028
[Epoch 9; Iter    64/  172] train: loss: 0.1503993
[Epoch 9; Iter    94/  172] train: loss: 0.2007715
[Epoch 9; Iter   124/  172] train: loss: 0.1705735
[Epoch 9; Iter   154/  172] train: loss: 0.2043525
[Epoch 9] ogbg-moltoxcast: 0.657547 val loss: 0.231322
[Epoch 9] ogbg-moltoxcast: 0.678234 test loss: 0.226883
[Epoch 10; Iter    12/  172] train: loss: 0.2338204
[Epoch 10; Iter    42/  172] train: loss: 0.1480103
[Epoch 10; Iter    72/  172] train: loss: 0.1891505
[Epoch 10; Iter   102/  172] train: loss: 0.1874269
[Epoch 10; Iter   132/  172] train: loss: 0.1634954
[Epoch 10; Iter   162/  172] train: loss: 0.2102747
[Epoch 10] ogbg-moltoxcast: 0.652164 val loss: 0.262565
[Epoch 10] ogbg-moltoxcast: 0.659053 test loss: 0.260953
[Epoch 11; Iter    20/  172] train: loss: 0.3011027
[Epoch 11; Iter    50/  172] train: loss: 0.1938979
[Epoch 11; Iter    80/  172] train: loss: 0.2190918
[Epoch 11; Iter   110/  172] train: loss: 0.1874549
[Epoch 11; Iter   140/  172] train: loss: 0.3688462
[Epoch 11; Iter   170/  172] train: loss: 0.1830870
[Epoch 11] ogbg-moltoxcast: 0.662312 val loss: 0.227380
[Epoch 11] ogbg-moltoxcast: 0.684282 test loss: 0.224104
[Epoch 12; Iter    28/  172] train: loss: 0.1396311
[Epoch 12; Iter    58/  172] train: loss: 0.1812933
[Epoch 12; Iter    88/  172] train: loss: 0.2769860
[Epoch 12; Iter   118/  172] train: loss: 0.2295048
[Epoch 12; Iter   148/  172] train: loss: 0.1900786
[Epoch 12] ogbg-moltoxcast: 0.668354 val loss: 0.252902
[Epoch 12] ogbg-moltoxcast: 0.670035 test loss: 0.221300
[Epoch 13; Iter     6/  172] train: loss: 0.2357895
[Epoch 13; Iter    36/  172] train: loss: 0.1492977
[Epoch 13; Iter    66/  172] train: loss: 0.1800965
[Epoch 13; Iter    96/  172] train: loss: 0.1961612
[Epoch 13; Iter   126/  172] train: loss: 0.1629369
[Epoch 13; Iter   156/  172] train: loss: 0.1857203
[Epoch 13] ogbg-moltoxcast: 0.685997 val loss: 0.216488
[Epoch 13] ogbg-moltoxcast: 0.695799 test loss: 0.214023
[Epoch 14; Iter    14/  172] train: loss: 0.2526077
[Epoch 14; Iter    44/  172] train: loss: 0.2049816
[Epoch 14; Iter    74/  172] train: loss: 0.2147188
[Epoch 14; Iter   104/  172] train: loss: 0.2308539
[Epoch 14; Iter   134/  172] train: loss: 0.2157621
[Epoch 12; Iter    31/  229] train: loss: 0.1706381
[Epoch 12; Iter    61/  229] train: loss: 0.1954122
[Epoch 12; Iter    91/  229] train: loss: 0.2292284
[Epoch 12; Iter   121/  229] train: loss: 0.1238118
[Epoch 12; Iter   151/  229] train: loss: 0.2733593
[Epoch 12; Iter   181/  229] train: loss: 0.2779361
[Epoch 12; Iter   211/  229] train: loss: 0.1610413
[Epoch 12] ogbg-moltoxcast: 0.675826 val loss: 0.211692
[Epoch 12] ogbg-moltoxcast: 0.707230 test loss: 0.231171
[Epoch 13; Iter    12/  229] train: loss: 0.1234035
[Epoch 13; Iter    42/  229] train: loss: 0.2514220
[Epoch 13; Iter    72/  229] train: loss: 0.1480343
[Epoch 13; Iter   102/  229] train: loss: 0.1886470
[Epoch 13; Iter   132/  229] train: loss: 0.1771874
[Epoch 13; Iter   162/  229] train: loss: 0.2080589
[Epoch 13; Iter   192/  229] train: loss: 0.2284467
[Epoch 13; Iter   222/  229] train: loss: 0.1463589
[Epoch 13] ogbg-moltoxcast: 0.700327 val loss: 0.214116
[Epoch 13] ogbg-moltoxcast: 0.719195 test loss: 0.240316
[Epoch 14; Iter    23/  229] train: loss: 0.2094642
[Epoch 14; Iter    53/  229] train: loss: 0.2259430
[Epoch 14; Iter    83/  229] train: loss: 0.2538317
[Epoch 14; Iter   113/  229] train: loss: 0.1463123
[Epoch 14; Iter   143/  229] train: loss: 0.1550447
[Epoch 14; Iter   173/  229] train: loss: 0.2249017
[Epoch 14; Iter   203/  229] train: loss: 0.1899014
[Epoch 14] ogbg-moltoxcast: 0.704911 val loss: 0.202755
[Epoch 14] ogbg-moltoxcast: 0.721157 test loss: 0.223867
[Epoch 15; Iter     4/  229] train: loss: 0.1146761
[Epoch 15; Iter    34/  229] train: loss: 0.1735396
[Epoch 15; Iter    64/  229] train: loss: 0.1343322
[Epoch 15; Iter    94/  229] train: loss: 0.2104661
[Epoch 15; Iter   124/  229] train: loss: 0.1905273
[Epoch 15; Iter   154/  229] train: loss: 0.2149788
[Epoch 15; Iter   184/  229] train: loss: 0.2345431
[Epoch 15; Iter   214/  229] train: loss: 0.2127706
[Epoch 15] ogbg-moltoxcast: 0.696892 val loss: 0.199942
[Epoch 15] ogbg-moltoxcast: 0.729798 test loss: 0.212304
[Epoch 16; Iter    15/  229] train: loss: 0.2294340
[Epoch 16; Iter    45/  229] train: loss: 0.1881907
[Epoch 16; Iter    75/  229] train: loss: 0.2800927
[Epoch 16; Iter   105/  229] train: loss: 0.2501905
[Epoch 16; Iter   135/  229] train: loss: 0.1894989
[Epoch 16; Iter   165/  229] train: loss: 0.2284814
[Epoch 16; Iter   195/  229] train: loss: 0.1854932
[Epoch 16; Iter   225/  229] train: loss: 0.1430514
[Epoch 16] ogbg-moltoxcast: 0.705555 val loss: 0.203282
[Epoch 16] ogbg-moltoxcast: 0.712380 test loss: 0.223999
[Epoch 17; Iter    26/  229] train: loss: 0.1888228
[Epoch 17; Iter    56/  229] train: loss: 0.1792386
[Epoch 17; Iter    86/  229] train: loss: 0.1971292
[Epoch 17; Iter   116/  229] train: loss: 0.1749914
[Epoch 17; Iter   146/  229] train: loss: 0.1724711
[Epoch 17; Iter   176/  229] train: loss: 0.1878487
[Epoch 17; Iter   206/  229] train: loss: 0.2460549
[Epoch 17] ogbg-moltoxcast: 0.686404 val loss: 0.217612
[Epoch 17] ogbg-moltoxcast: 0.694380 test loss: 0.234444
[Epoch 18; Iter     7/  229] train: loss: 0.2366505
[Epoch 18; Iter    37/  229] train: loss: 0.1895918
[Epoch 18; Iter    67/  229] train: loss: 0.2152472
[Epoch 18; Iter    97/  229] train: loss: 0.2593601
[Epoch 18; Iter   127/  229] train: loss: 0.2093532
[Epoch 18; Iter   157/  229] train: loss: 0.2956882
[Epoch 18; Iter   187/  229] train: loss: 0.1819874
[Epoch 18; Iter   217/  229] train: loss: 0.1881202
[Epoch 18] ogbg-moltoxcast: 0.709955 val loss: 0.204310
[Epoch 18] ogbg-moltoxcast: 0.730132 test loss: 0.221154
[Epoch 19; Iter    18/  229] train: loss: 0.1470104
[Epoch 19; Iter    48/  229] train: loss: 0.2509039
[Epoch 19; Iter    78/  229] train: loss: 0.2257633
[Epoch 19; Iter   108/  229] train: loss: 0.1654377
[Epoch 19; Iter   138/  229] train: loss: 0.1984936
[Epoch 19; Iter   168/  229] train: loss: 0.2002232
[Epoch 19; Iter   198/  229] train: loss: 0.1520241
[Epoch 19; Iter   228/  229] train: loss: 0.2257204
[Epoch 19] ogbg-moltoxcast: 0.709114 val loss: 0.202076
[Epoch 19] ogbg-moltoxcast: 0.726957 test loss: 0.236204
[Epoch 20; Iter    29/  229] train: loss: 0.1857268
[Epoch 20; Iter    59/  229] train: loss: 0.2598110
[Epoch 20; Iter    89/  229] train: loss: 0.1285929
[Epoch 20; Iter   119/  229] train: loss: 0.1366952
[Epoch 20; Iter   149/  229] train: loss: 0.2338266
[Epoch 20; Iter   179/  229] train: loss: 0.2012451
[Epoch 20; Iter   209/  229] train: loss: 0.1729478
[Epoch 20] ogbg-moltoxcast: 0.716227 val loss: 0.197762
[Epoch 20] ogbg-moltoxcast: 0.726764 test loss: 0.243155
[Epoch 21; Iter    10/  229] train: loss: 0.2347180
[Epoch 21; Iter    40/  229] train: loss: 0.1369527
[Epoch 21; Iter    70/  229] train: loss: 0.1064980
[Epoch 21; Iter   100/  229] train: loss: 0.1655079
[Epoch 21; Iter   130/  229] train: loss: 0.1548405
[Epoch 21; Iter   160/  229] train: loss: 0.1628061
[Epoch 21; Iter   190/  229] train: loss: 0.2777909
[Epoch 21; Iter   220/  229] train: loss: 0.2265190
[Epoch 21] ogbg-moltoxcast: 0.718649 val loss: 0.196919
[Epoch 21] ogbg-moltoxcast: 0.742253 test loss: 0.211359
[Epoch 22; Iter    21/  229] train: loss: 0.1679916
[Epoch 22; Iter    51/  229] train: loss: 0.1711953
[Epoch 22; Iter    81/  229] train: loss: 0.1856260
[Epoch 22; Iter   111/  229] train: loss: 0.1641674
[Epoch 22; Iter   141/  229] train: loss: 0.1436402
[Epoch 22; Iter   171/  229] train: loss: 0.1186731
[Epoch 22; Iter   201/  229] train: loss: 0.2481701
[Epoch 22] ogbg-moltoxcast: 0.725060 val loss: 0.198587
[Epoch 22] ogbg-moltoxcast: 0.744079 test loss: 0.243428
[Epoch 23; Iter     2/  229] train: loss: 0.2026391
[Epoch 23; Iter    32/  229] train: loss: 0.1485127
[Epoch 23; Iter    62/  229] train: loss: 0.2638978
[Epoch 23; Iter    92/  229] train: loss: 0.1601968
[Epoch 23; Iter   122/  229] train: loss: 0.2274999
[Epoch 23; Iter   152/  229] train: loss: 0.1844675
[Epoch 23; Iter   182/  229] train: loss: 0.1952765
[Epoch 23; Iter   212/  229] train: loss: 0.1450870
[Epoch 23] ogbg-moltoxcast: 0.709113 val loss: 0.206006
[Epoch 23] ogbg-moltoxcast: 0.746727 test loss: 0.217624
[Epoch 24; Iter    13/  229] train: loss: 0.1990356
[Epoch 24; Iter    43/  229] train: loss: 0.1595987
[Epoch 24; Iter    73/  229] train: loss: 0.1562663
[Epoch 24; Iter   103/  229] train: loss: 0.2514317
[Epoch 24; Iter   133/  229] train: loss: 0.1965276
[Epoch 24; Iter   163/  229] train: loss: 0.1589523
[Epoch 24; Iter   193/  229] train: loss: 0.2179020
[Epoch 24; Iter   223/  229] train: loss: 0.1722672
[Epoch 24] ogbg-moltoxcast: 0.734072 val loss: 0.196158
[Epoch 24] ogbg-moltoxcast: 0.740646 test loss: 0.214728
[Epoch 25; Iter    24/  229] train: loss: 0.1881413
[Epoch 25; Iter    54/  229] train: loss: 0.2086974
[Epoch 25; Iter    84/  229] train: loss: 0.2292250
[Epoch 25; Iter   114/  229] train: loss: 0.1835170
[Epoch 25; Iter   144/  229] train: loss: 0.2054227
[Epoch 25; Iter   174/  229] train: loss: 0.1571976
[Epoch 25; Iter   204/  229] train: loss: 0.1765847
[Epoch 25] ogbg-moltoxcast: 0.730832 val loss: 0.196974
[Epoch 25] ogbg-moltoxcast: 0.745598 test loss: 0.213126
[Epoch 26; Iter     5/  229] train: loss: 0.2407183
[Epoch 26; Iter    35/  229] train: loss: 0.1462780
[Epoch 26; Iter    65/  229] train: loss: 0.1688094
[Epoch 26; Iter    95/  229] train: loss: 0.2208858
[Epoch 26; Iter   125/  229] train: loss: 0.2008490
[Epoch 26; Iter   155/  229] train: loss: 0.2321340
[Epoch 26; Iter   185/  229] train: loss: 0.1585206
[Epoch 26; Iter   215/  229] train: loss: 0.1994306
[Epoch 26] ogbg-moltoxcast: 0.732337 val loss: 0.198398
[Epoch 26] ogbg-moltoxcast: 0.754815 test loss: 0.204910
[Epoch 27; Iter    16/  229] train: loss: 0.2266993
[Epoch 27; Iter    46/  229] train: loss: 0.1879669
[Epoch 27; Iter    76/  229] train: loss: 0.1846927
[Epoch 27; Iter   106/  229] train: loss: 0.1683207
[Epoch 27; Iter   136/  229] train: loss: 0.1563445
[Epoch 27; Iter   166/  229] train: loss: 0.2406139
[Epoch 27; Iter   196/  229] train: loss: 0.1804248
[Epoch 27; Iter   226/  229] train: loss: 0.1776722
[Epoch 27] ogbg-moltoxcast: 0.727312 val loss: 0.198540
[Epoch 27] ogbg-moltoxcast: 0.727251 test loss: 0.342565
[Epoch 12; Iter    31/  229] train: loss: 0.2865481
[Epoch 12; Iter    61/  229] train: loss: 0.1584757
[Epoch 12; Iter    91/  229] train: loss: 0.2055502
[Epoch 12; Iter   121/  229] train: loss: 0.2382084
[Epoch 12; Iter   151/  229] train: loss: 0.2614117
[Epoch 12; Iter   181/  229] train: loss: 0.2711321
[Epoch 12; Iter   211/  229] train: loss: 0.2248702
[Epoch 12] ogbg-moltoxcast: 0.701730 val loss: 0.214306
[Epoch 12] ogbg-moltoxcast: 0.735951 test loss: 0.213311
[Epoch 13; Iter    12/  229] train: loss: 0.2138523
[Epoch 13; Iter    42/  229] train: loss: 0.1748790
[Epoch 13; Iter    72/  229] train: loss: 0.1872989
[Epoch 13; Iter   102/  229] train: loss: 0.1707201
[Epoch 13; Iter   132/  229] train: loss: 0.1519558
[Epoch 13; Iter   162/  229] train: loss: 0.1931797
[Epoch 13; Iter   192/  229] train: loss: 0.1401326
[Epoch 13; Iter   222/  229] train: loss: 0.2582678
[Epoch 13] ogbg-moltoxcast: 0.707692 val loss: 0.206709
[Epoch 13] ogbg-moltoxcast: 0.727339 test loss: 0.222372
[Epoch 14; Iter    23/  229] train: loss: 0.1815599
[Epoch 14; Iter    53/  229] train: loss: 0.2524159
[Epoch 14; Iter    83/  229] train: loss: 0.2269693
[Epoch 14; Iter   113/  229] train: loss: 0.1636987
[Epoch 14; Iter   143/  229] train: loss: 0.2069476
[Epoch 14; Iter   173/  229] train: loss: 0.1801694
[Epoch 14; Iter   203/  229] train: loss: 0.1709317
[Epoch 14] ogbg-moltoxcast: 0.705298 val loss: 0.213776
[Epoch 14] ogbg-moltoxcast: 0.729755 test loss: 0.225647
[Epoch 15; Iter     4/  229] train: loss: 0.1203133
[Epoch 15; Iter    34/  229] train: loss: 0.1538491
[Epoch 15; Iter    64/  229] train: loss: 0.2093990
[Epoch 15; Iter    94/  229] train: loss: 0.2790696
[Epoch 15; Iter   124/  229] train: loss: 0.1522939
[Epoch 15; Iter   154/  229] train: loss: 0.2049549
[Epoch 15; Iter   184/  229] train: loss: 0.2163580
[Epoch 15; Iter   214/  229] train: loss: 0.1521576
[Epoch 15] ogbg-moltoxcast: 0.714079 val loss: 0.201669
[Epoch 15] ogbg-moltoxcast: 0.733546 test loss: 0.219865
[Epoch 16; Iter    15/  229] train: loss: 0.1607205
[Epoch 16; Iter    45/  229] train: loss: 0.1461403
[Epoch 16; Iter    75/  229] train: loss: 0.1718937
[Epoch 16; Iter   105/  229] train: loss: 0.1839034
[Epoch 16; Iter   135/  229] train: loss: 0.1966825
[Epoch 16; Iter   165/  229] train: loss: 0.1856722
[Epoch 16; Iter   195/  229] train: loss: 0.1921850
[Epoch 16; Iter   225/  229] train: loss: 0.1427394
[Epoch 16] ogbg-moltoxcast: 0.706367 val loss: 0.208377
[Epoch 16] ogbg-moltoxcast: 0.729857 test loss: 0.267904
[Epoch 17; Iter    26/  229] train: loss: 0.1774874
[Epoch 17; Iter    56/  229] train: loss: 0.2445343
[Epoch 17; Iter    86/  229] train: loss: 0.1647885
[Epoch 17; Iter   116/  229] train: loss: 0.1940931
[Epoch 17; Iter   146/  229] train: loss: 0.1748519
[Epoch 17; Iter   176/  229] train: loss: 0.1995291
[Epoch 17; Iter   206/  229] train: loss: 0.1618059
[Epoch 17] ogbg-moltoxcast: 0.703918 val loss: 0.214486
[Epoch 17] ogbg-moltoxcast: 0.729123 test loss: 0.218267
[Epoch 18; Iter     7/  229] train: loss: 0.1575341
[Epoch 18; Iter    37/  229] train: loss: 0.1496664
[Epoch 18; Iter    67/  229] train: loss: 0.1268072
[Epoch 18; Iter    97/  229] train: loss: 0.1999555
[Epoch 18; Iter   127/  229] train: loss: 0.2337209
[Epoch 18; Iter   157/  229] train: loss: 0.1533549
[Epoch 18; Iter   187/  229] train: loss: 0.1474938
[Epoch 18; Iter   217/  229] train: loss: 0.1779365
[Epoch 18] ogbg-moltoxcast: 0.714705 val loss: 0.267198
[Epoch 18] ogbg-moltoxcast: 0.735617 test loss: 0.216992
[Epoch 19; Iter    18/  229] train: loss: 0.1555620
[Epoch 19; Iter    48/  229] train: loss: 0.1663576
[Epoch 19; Iter    78/  229] train: loss: 0.1501951
[Epoch 19; Iter   108/  229] train: loss: 0.2851948
[Epoch 19; Iter   138/  229] train: loss: 0.1906003
[Epoch 19; Iter   168/  229] train: loss: 0.2028839
[Epoch 19; Iter   198/  229] train: loss: 0.2095326
[Epoch 19; Iter   228/  229] train: loss: 0.1472960
[Epoch 19] ogbg-moltoxcast: 0.694619 val loss: 0.204591
[Epoch 19] ogbg-moltoxcast: 0.717061 test loss: 0.224879
[Epoch 20; Iter    29/  229] train: loss: 0.1674513
[Epoch 20; Iter    59/  229] train: loss: 0.1595382
[Epoch 20; Iter    89/  229] train: loss: 0.2561734
[Epoch 20; Iter   119/  229] train: loss: 0.2133931
[Epoch 20; Iter   149/  229] train: loss: 0.1503901
[Epoch 20; Iter   179/  229] train: loss: 0.3034239
[Epoch 20; Iter   209/  229] train: loss: 0.2350641
[Epoch 20] ogbg-moltoxcast: 0.709602 val loss: 0.206524
[Epoch 20] ogbg-moltoxcast: 0.731296 test loss: 0.227345
[Epoch 21; Iter    10/  229] train: loss: 0.1950659
[Epoch 21; Iter    40/  229] train: loss: 0.2217779
[Epoch 21; Iter    70/  229] train: loss: 0.2380960
[Epoch 21; Iter   100/  229] train: loss: 0.1614598
[Epoch 21; Iter   130/  229] train: loss: 0.1779103
[Epoch 21; Iter   160/  229] train: loss: 0.1836359
[Epoch 21; Iter   190/  229] train: loss: 0.2160271
[Epoch 21; Iter   220/  229] train: loss: 0.1922887
[Epoch 21] ogbg-moltoxcast: 0.723329 val loss: 0.241777
[Epoch 21] ogbg-moltoxcast: 0.735237 test loss: 0.208686
[Epoch 22; Iter    21/  229] train: loss: 0.1682818
[Epoch 22; Iter    51/  229] train: loss: 0.2110268
[Epoch 22; Iter    81/  229] train: loss: 0.2525895
[Epoch 22; Iter   111/  229] train: loss: 0.2271857
[Epoch 22; Iter   141/  229] train: loss: 0.1690406
[Epoch 22; Iter   171/  229] train: loss: 0.2762560
[Epoch 22; Iter   201/  229] train: loss: 0.1410739
[Epoch 22] ogbg-moltoxcast: 0.727685 val loss: 0.231164
[Epoch 22] ogbg-moltoxcast: 0.744478 test loss: 0.383724
[Epoch 23; Iter     2/  229] train: loss: 0.1505992
[Epoch 23; Iter    32/  229] train: loss: 0.2006340
[Epoch 23; Iter    62/  229] train: loss: 0.1937535
[Epoch 23; Iter    92/  229] train: loss: 0.1472535
[Epoch 23; Iter   122/  229] train: loss: 0.2022969
[Epoch 23; Iter   152/  229] train: loss: 0.1679226
[Epoch 23; Iter   182/  229] train: loss: 0.2618519
[Epoch 23; Iter   212/  229] train: loss: 0.3071415
[Epoch 23] ogbg-moltoxcast: 0.672716 val loss: 0.224761
[Epoch 23] ogbg-moltoxcast: 0.706710 test loss: 0.244065
[Epoch 24; Iter    13/  229] train: loss: 0.1998007
[Epoch 24; Iter    43/  229] train: loss: 0.2351442
[Epoch 24; Iter    73/  229] train: loss: 0.2100290
[Epoch 24; Iter   103/  229] train: loss: 0.1983059
[Epoch 24; Iter   133/  229] train: loss: 0.2271927
[Epoch 24; Iter   163/  229] train: loss: 0.1716042
[Epoch 24; Iter   193/  229] train: loss: 0.1691867
[Epoch 24; Iter   223/  229] train: loss: 0.2007718
[Epoch 24] ogbg-moltoxcast: 0.713394 val loss: 0.200848
[Epoch 24] ogbg-moltoxcast: 0.744777 test loss: 0.214332
[Epoch 25; Iter    24/  229] train: loss: 0.2313715
[Epoch 25; Iter    54/  229] train: loss: 0.1859234
[Epoch 25; Iter    84/  229] train: loss: 0.2090574
[Epoch 25; Iter   114/  229] train: loss: 0.2650647
[Epoch 25; Iter   144/  229] train: loss: 0.2779393
[Epoch 25; Iter   174/  229] train: loss: 0.2331350
[Epoch 25; Iter   204/  229] train: loss: 0.1885763
[Epoch 25] ogbg-moltoxcast: 0.718783 val loss: 0.202540
[Epoch 25] ogbg-moltoxcast: 0.752321 test loss: 0.220201
[Epoch 26; Iter     5/  229] train: loss: 0.1633130
[Epoch 26; Iter    35/  229] train: loss: 0.2124870
[Epoch 26; Iter    65/  229] train: loss: 0.1466691
[Epoch 26; Iter    95/  229] train: loss: 0.1547915
[Epoch 26; Iter   125/  229] train: loss: 0.1406923
[Epoch 26; Iter   155/  229] train: loss: 0.1989779
[Epoch 26; Iter   185/  229] train: loss: 0.1486968
[Epoch 26; Iter   215/  229] train: loss: 0.2126167
[Epoch 26] ogbg-moltoxcast: 0.714254 val loss: 0.208588
[Epoch 26] ogbg-moltoxcast: 0.743837 test loss: 0.220390
[Epoch 27; Iter    16/  229] train: loss: 0.1156034
[Epoch 27; Iter    46/  229] train: loss: 0.1419690
[Epoch 27; Iter    76/  229] train: loss: 0.1429115
[Epoch 27; Iter   106/  229] train: loss: 0.1219317
[Epoch 27; Iter   136/  229] train: loss: 0.2397497
[Epoch 27; Iter   166/  229] train: loss: 0.2112841
[Epoch 27; Iter   196/  229] train: loss: 0.1998210
[Epoch 27; Iter   226/  229] train: loss: 0.2528716
[Epoch 27] ogbg-moltoxcast: 0.714740 val loss: 0.201923
[Epoch 27] ogbg-moltoxcast: 0.746958 test loss: 0.206349
[Epoch 12; Iter    31/  229] train: loss: 0.2184066
[Epoch 12; Iter    61/  229] train: loss: 0.2448475
[Epoch 12; Iter    91/  229] train: loss: 0.2001875
[Epoch 12; Iter   121/  229] train: loss: 0.1359690
[Epoch 12; Iter   151/  229] train: loss: 0.1740025
[Epoch 12; Iter   181/  229] train: loss: 0.1586141
[Epoch 12; Iter   211/  229] train: loss: 0.1966160
[Epoch 12] ogbg-moltoxcast: 0.712747 val loss: 0.201876
[Epoch 12] ogbg-moltoxcast: 0.707769 test loss: 0.223335
[Epoch 13; Iter    12/  229] train: loss: 0.1668251
[Epoch 13; Iter    42/  229] train: loss: 0.1567225
[Epoch 13; Iter    72/  229] train: loss: 0.2001460
[Epoch 13; Iter   102/  229] train: loss: 0.2409254
[Epoch 13; Iter   132/  229] train: loss: 0.2682750
[Epoch 13; Iter   162/  229] train: loss: 0.2520682
[Epoch 13; Iter   192/  229] train: loss: 0.1842901
[Epoch 13; Iter   222/  229] train: loss: 0.1751790
[Epoch 13] ogbg-moltoxcast: 0.709641 val loss: 0.199308
[Epoch 13] ogbg-moltoxcast: 0.719573 test loss: 0.215257
[Epoch 14; Iter    23/  229] train: loss: 0.2574446
[Epoch 14; Iter    53/  229] train: loss: 0.1533737
[Epoch 14; Iter    83/  229] train: loss: 0.2094178
[Epoch 14; Iter   113/  229] train: loss: 0.2223029
[Epoch 14; Iter   143/  229] train: loss: 0.2029021
[Epoch 14; Iter   173/  229] train: loss: 0.2126504
[Epoch 14; Iter   203/  229] train: loss: 0.2732600
[Epoch 14] ogbg-moltoxcast: 0.693498 val loss: 0.202842
[Epoch 14] ogbg-moltoxcast: 0.705692 test loss: 0.222577
[Epoch 15; Iter     4/  229] train: loss: 0.1854724
[Epoch 15; Iter    34/  229] train: loss: 0.1785132
[Epoch 15; Iter    64/  229] train: loss: 0.1384157
[Epoch 15; Iter    94/  229] train: loss: 0.2015994
[Epoch 15; Iter   124/  229] train: loss: 0.1050764
[Epoch 15; Iter   154/  229] train: loss: 0.2031563
[Epoch 15; Iter   184/  229] train: loss: 0.2018795
[Epoch 15; Iter   214/  229] train: loss: 0.2007127
[Epoch 15] ogbg-moltoxcast: 0.706498 val loss: 0.200316
[Epoch 15] ogbg-moltoxcast: 0.711321 test loss: 0.218305
[Epoch 16; Iter    15/  229] train: loss: 0.1953958
[Epoch 16; Iter    45/  229] train: loss: 0.1373866
[Epoch 16; Iter    75/  229] train: loss: 0.1442094
[Epoch 16; Iter   105/  229] train: loss: 0.1967560
[Epoch 16; Iter   135/  229] train: loss: 0.2523094
[Epoch 16; Iter   165/  229] train: loss: 0.1832464
[Epoch 16; Iter   195/  229] train: loss: 0.1919632
[Epoch 16; Iter   225/  229] train: loss: 0.1449725
[Epoch 16] ogbg-moltoxcast: 0.710485 val loss: 0.200698
[Epoch 16] ogbg-moltoxcast: 0.738521 test loss: 0.211699
[Epoch 17; Iter    26/  229] train: loss: 0.2409636
[Epoch 17; Iter    56/  229] train: loss: 0.1404478
[Epoch 17; Iter    86/  229] train: loss: 0.1972378
[Epoch 17; Iter   116/  229] train: loss: 0.2271434
[Epoch 17; Iter   146/  229] train: loss: 0.1704367
[Epoch 17; Iter   176/  229] train: loss: 0.1694994
[Epoch 17; Iter   206/  229] train: loss: 0.1872673
[Epoch 17] ogbg-moltoxcast: 0.720086 val loss: 0.199862
[Epoch 17] ogbg-moltoxcast: 0.731868 test loss: 0.214533
[Epoch 18; Iter     7/  229] train: loss: 0.1922459
[Epoch 18; Iter    37/  229] train: loss: 0.2415048
[Epoch 18; Iter    67/  229] train: loss: 0.1271785
[Epoch 18; Iter    97/  229] train: loss: 0.2429852
[Epoch 18; Iter   127/  229] train: loss: 0.1844895
[Epoch 18; Iter   157/  229] train: loss: 0.1458180
[Epoch 18; Iter   187/  229] train: loss: 0.2393198
[Epoch 18; Iter   217/  229] train: loss: 0.1351457
[Epoch 18] ogbg-moltoxcast: 0.715364 val loss: 0.199480
[Epoch 18] ogbg-moltoxcast: 0.742655 test loss: 0.210180
[Epoch 19; Iter    18/  229] train: loss: 0.1927537
[Epoch 19; Iter    48/  229] train: loss: 0.1820810
[Epoch 19; Iter    78/  229] train: loss: 0.1959650
[Epoch 19; Iter   108/  229] train: loss: 0.1968812
[Epoch 19; Iter   138/  229] train: loss: 0.1693223
[Epoch 19; Iter   168/  229] train: loss: 0.1966820
[Epoch 19; Iter   198/  229] train: loss: 0.1508382
[Epoch 19; Iter   228/  229] train: loss: 0.1693299
[Epoch 19] ogbg-moltoxcast: 0.718137 val loss: 0.197663
[Epoch 19] ogbg-moltoxcast: 0.727079 test loss: 0.222119
[Epoch 20; Iter    29/  229] train: loss: 0.2768759
[Epoch 20; Iter    59/  229] train: loss: 0.1803134
[Epoch 20; Iter    89/  229] train: loss: 0.2180187
[Epoch 20; Iter   119/  229] train: loss: 0.1670938
[Epoch 20; Iter   149/  229] train: loss: 0.2169925
[Epoch 20; Iter   179/  229] train: loss: 0.1907784
[Epoch 20; Iter   209/  229] train: loss: 0.1743123
[Epoch 20] ogbg-moltoxcast: 0.725371 val loss: 0.195436
[Epoch 20] ogbg-moltoxcast: 0.744141 test loss: 0.221584
[Epoch 21; Iter    10/  229] train: loss: 0.2804667
[Epoch 21; Iter    40/  229] train: loss: 0.1660098
[Epoch 21; Iter    70/  229] train: loss: 0.2221188
[Epoch 21; Iter   100/  229] train: loss: 0.2092486
[Epoch 21; Iter   130/  229] train: loss: 0.1466678
[Epoch 21; Iter   160/  229] train: loss: 0.1776950
[Epoch 21; Iter   190/  229] train: loss: 0.2037475
[Epoch 21; Iter   220/  229] train: loss: 0.2117748
[Epoch 21] ogbg-moltoxcast: 0.728881 val loss: 0.197219
[Epoch 21] ogbg-moltoxcast: 0.736573 test loss: 0.211532
[Epoch 22; Iter    21/  229] train: loss: 0.2154788
[Epoch 22; Iter    51/  229] train: loss: 0.1442509
[Epoch 22; Iter    81/  229] train: loss: 0.1646551
[Epoch 22; Iter   111/  229] train: loss: 0.1773538
[Epoch 22; Iter   141/  229] train: loss: 0.1922364
[Epoch 22; Iter   171/  229] train: loss: 0.1029942
[Epoch 22; Iter   201/  229] train: loss: 0.1760937
[Epoch 22] ogbg-moltoxcast: 0.729706 val loss: 0.197056
[Epoch 22] ogbg-moltoxcast: 0.737442 test loss: 0.225866
[Epoch 23; Iter     2/  229] train: loss: 0.2288999
[Epoch 23; Iter    32/  229] train: loss: 0.1838370
[Epoch 23; Iter    62/  229] train: loss: 0.1523436
[Epoch 23; Iter    92/  229] train: loss: 0.1406334
[Epoch 23; Iter   122/  229] train: loss: 0.2497755
[Epoch 23; Iter   152/  229] train: loss: 0.1459361
[Epoch 23; Iter   182/  229] train: loss: 0.1489488
[Epoch 23; Iter   212/  229] train: loss: 0.2134419
[Epoch 23] ogbg-moltoxcast: 0.720993 val loss: 0.197474
[Epoch 23] ogbg-moltoxcast: 0.736163 test loss: 0.210543
[Epoch 24; Iter    13/  229] train: loss: 0.1531097
[Epoch 24; Iter    43/  229] train: loss: 0.1319143
[Epoch 24; Iter    73/  229] train: loss: 0.2040064
[Epoch 24; Iter   103/  229] train: loss: 0.2350216
[Epoch 24; Iter   133/  229] train: loss: 0.1692530
[Epoch 24; Iter   163/  229] train: loss: 0.1886250
[Epoch 24; Iter   193/  229] train: loss: 0.2194114
[Epoch 24; Iter   223/  229] train: loss: 0.1853338
[Epoch 24] ogbg-moltoxcast: 0.734271 val loss: 0.192955
[Epoch 24] ogbg-moltoxcast: 0.745370 test loss: 0.208895
[Epoch 25; Iter    24/  229] train: loss: 0.1671276
[Epoch 25; Iter    54/  229] train: loss: 0.1553730
[Epoch 25; Iter    84/  229] train: loss: 0.1663818
[Epoch 25; Iter   114/  229] train: loss: 0.1852158
[Epoch 25; Iter   144/  229] train: loss: 0.1872026
[Epoch 25; Iter   174/  229] train: loss: 0.1345744
[Epoch 25; Iter   204/  229] train: loss: 0.1689174
[Epoch 25] ogbg-moltoxcast: 0.733417 val loss: 0.194435
[Epoch 25] ogbg-moltoxcast: 0.755791 test loss: 0.204390
[Epoch 26; Iter     5/  229] train: loss: 0.1154234
[Epoch 26; Iter    35/  229] train: loss: 0.1333765
[Epoch 26; Iter    65/  229] train: loss: 0.1607176
[Epoch 26; Iter    95/  229] train: loss: 0.2449775
[Epoch 26; Iter   125/  229] train: loss: 0.1820473
[Epoch 26; Iter   155/  229] train: loss: 0.1891277
[Epoch 26; Iter   185/  229] train: loss: 0.1603219
[Epoch 26; Iter   215/  229] train: loss: 0.1553263
[Epoch 26] ogbg-moltoxcast: 0.728074 val loss: 0.194627
[Epoch 26] ogbg-moltoxcast: 0.747878 test loss: 0.208106
[Epoch 27; Iter    16/  229] train: loss: 0.1597705
[Epoch 27; Iter    46/  229] train: loss: 0.1679856
[Epoch 27; Iter    76/  229] train: loss: 0.1991800
[Epoch 27; Iter   106/  229] train: loss: 0.1249189
[Epoch 27; Iter   136/  229] train: loss: 0.2324624
[Epoch 27; Iter   166/  229] train: loss: 0.1723989
[Epoch 27; Iter   196/  229] train: loss: 0.1721002
[Epoch 27; Iter   226/  229] train: loss: 0.1935644
[Epoch 27] ogbg-moltoxcast: 0.730490 val loss: 0.194280
[Epoch 27] ogbg-moltoxcast: 0.746577 test loss: 0.209922
[Epoch 13; Iter    78/  201] train: loss: 0.1586309
[Epoch 13; Iter   108/  201] train: loss: 0.2256225
[Epoch 13; Iter   138/  201] train: loss: 0.2032724
[Epoch 13; Iter   168/  201] train: loss: 0.1376951
[Epoch 13; Iter   198/  201] train: loss: 0.2359936
[Epoch 13] ogbg-moltoxcast: 0.697624 val loss: 0.214427
[Epoch 13] ogbg-moltoxcast: 0.718552 test loss: 0.212696
[Epoch 14; Iter    27/  201] train: loss: 0.1399475
[Epoch 14; Iter    57/  201] train: loss: 0.2117657
[Epoch 14; Iter    87/  201] train: loss: 0.1516669
[Epoch 14; Iter   117/  201] train: loss: 0.2041525
[Epoch 14; Iter   147/  201] train: loss: 0.2282139
[Epoch 14; Iter   177/  201] train: loss: 0.2724394
[Epoch 14] ogbg-moltoxcast: 0.687776 val loss: 0.216085
[Epoch 14] ogbg-moltoxcast: 0.702416 test loss: 0.221006
[Epoch 15; Iter     6/  201] train: loss: 0.2085244
[Epoch 15; Iter    36/  201] train: loss: 0.2008543
[Epoch 15; Iter    66/  201] train: loss: 0.2000011
[Epoch 15; Iter    96/  201] train: loss: 0.2244270
[Epoch 15; Iter   126/  201] train: loss: 0.2275096
[Epoch 15; Iter   156/  201] train: loss: 0.1922521
[Epoch 15; Iter   186/  201] train: loss: 0.1999033
[Epoch 15] ogbg-moltoxcast: 0.700501 val loss: 0.212428
[Epoch 15] ogbg-moltoxcast: 0.717595 test loss: 0.214139
[Epoch 16; Iter    15/  201] train: loss: 0.1917699
[Epoch 16; Iter    45/  201] train: loss: 0.1738955
[Epoch 16; Iter    75/  201] train: loss: 0.1811096
[Epoch 16; Iter   105/  201] train: loss: 0.2610085
[Epoch 16; Iter   135/  201] train: loss: 0.2068853
[Epoch 16; Iter   165/  201] train: loss: 0.1586732
[Epoch 16; Iter   195/  201] train: loss: 0.1219906
[Epoch 16] ogbg-moltoxcast: 0.706765 val loss: 0.209706
[Epoch 16] ogbg-moltoxcast: 0.726217 test loss: 0.213775
[Epoch 17; Iter    24/  201] train: loss: 0.2059008
[Epoch 17; Iter    54/  201] train: loss: 0.1429058
[Epoch 17; Iter    84/  201] train: loss: 0.3041016
[Epoch 17; Iter   114/  201] train: loss: 0.1600156
[Epoch 17; Iter   144/  201] train: loss: 0.2306628
[Epoch 17; Iter   174/  201] train: loss: 0.2441527
[Epoch 17] ogbg-moltoxcast: 0.692990 val loss: 0.220823
[Epoch 17] ogbg-moltoxcast: 0.725170 test loss: 0.224855
[Epoch 18; Iter     3/  201] train: loss: 0.1707669
[Epoch 18; Iter    33/  201] train: loss: 0.1614958
[Epoch 18; Iter    63/  201] train: loss: 0.1563013
[Epoch 18; Iter    93/  201] train: loss: 0.1745931
[Epoch 18; Iter   123/  201] train: loss: 0.3355245
[Epoch 18; Iter   153/  201] train: loss: 0.1827186
[Epoch 18; Iter   183/  201] train: loss: 0.2269142
[Epoch 18] ogbg-moltoxcast: 0.711573 val loss: 0.244858
[Epoch 18] ogbg-moltoxcast: 0.728871 test loss: 0.235657
[Epoch 19; Iter    12/  201] train: loss: 0.2054668
[Epoch 19; Iter    42/  201] train: loss: 0.1758638
[Epoch 19; Iter    72/  201] train: loss: 0.2588459
[Epoch 19; Iter   102/  201] train: loss: 0.2135445
[Epoch 19; Iter   132/  201] train: loss: 0.1276398
[Epoch 19; Iter   162/  201] train: loss: 0.1649190
[Epoch 19; Iter   192/  201] train: loss: 0.2404523
[Epoch 19] ogbg-moltoxcast: 0.704041 val loss: 0.213875
[Epoch 19] ogbg-moltoxcast: 0.717574 test loss: 0.221961
[Epoch 20; Iter    21/  201] train: loss: 0.1963226
[Epoch 20; Iter    51/  201] train: loss: 0.1221881
[Epoch 20; Iter    81/  201] train: loss: 0.2301297
[Epoch 20; Iter   111/  201] train: loss: 0.1558919
[Epoch 20; Iter   141/  201] train: loss: 0.2204662
[Epoch 20; Iter   171/  201] train: loss: 0.1954848
[Epoch 20; Iter   201/  201] train: loss: 0.1964693
[Epoch 20] ogbg-moltoxcast: 0.714618 val loss: 0.284366
[Epoch 20] ogbg-moltoxcast: 0.737230 test loss: 0.209922
[Epoch 21; Iter    30/  201] train: loss: 0.3197842
[Epoch 21; Iter    60/  201] train: loss: 0.1315710
[Epoch 21; Iter    90/  201] train: loss: 0.1915321
[Epoch 21; Iter   120/  201] train: loss: 0.2595702
[Epoch 21; Iter   150/  201] train: loss: 0.1988230
[Epoch 21; Iter   180/  201] train: loss: 0.2447422
[Epoch 21] ogbg-moltoxcast: 0.713983 val loss: 0.328189
[Epoch 21] ogbg-moltoxcast: 0.721976 test loss: 0.335972
[Epoch 22; Iter     9/  201] train: loss: 0.1688203
[Epoch 22; Iter    39/  201] train: loss: 0.2216896
[Epoch 22; Iter    69/  201] train: loss: 0.1707672
[Epoch 22; Iter    99/  201] train: loss: 0.1648486
[Epoch 22; Iter   129/  201] train: loss: 0.2404668
[Epoch 22; Iter   159/  201] train: loss: 0.1955205
[Epoch 22; Iter   189/  201] train: loss: 0.2204444
[Epoch 22] ogbg-moltoxcast: 0.722101 val loss: 0.220221
[Epoch 22] ogbg-moltoxcast: 0.739595 test loss: 0.211372
[Epoch 23; Iter    18/  201] train: loss: 0.2067865
[Epoch 23; Iter    48/  201] train: loss: 0.1637207
[Epoch 23; Iter    78/  201] train: loss: 0.2708217
[Epoch 23; Iter   108/  201] train: loss: 0.1231953
[Epoch 23; Iter   138/  201] train: loss: 0.1849593
[Epoch 23; Iter   168/  201] train: loss: 0.1305469
[Epoch 23; Iter   198/  201] train: loss: 0.1473866
[Epoch 23] ogbg-moltoxcast: 0.706067 val loss: 0.235590
[Epoch 23] ogbg-moltoxcast: 0.733203 test loss: 0.215255
[Epoch 24; Iter    27/  201] train: loss: 0.1902853
[Epoch 24; Iter    57/  201] train: loss: 0.1628375
[Epoch 24; Iter    87/  201] train: loss: 0.1927035
[Epoch 24; Iter   117/  201] train: loss: 0.1792094
[Epoch 24; Iter   147/  201] train: loss: 0.2678839
[Epoch 24; Iter   177/  201] train: loss: 0.1312683
[Epoch 24] ogbg-moltoxcast: 0.716631 val loss: 0.210218
[Epoch 24] ogbg-moltoxcast: 0.735225 test loss: 0.210323
[Epoch 25; Iter     6/  201] train: loss: 0.2174100
[Epoch 25; Iter    36/  201] train: loss: 0.1559443
[Epoch 25; Iter    66/  201] train: loss: 0.2066689
[Epoch 25; Iter    96/  201] train: loss: 0.2503780
[Epoch 25; Iter   126/  201] train: loss: 0.1447853
[Epoch 25; Iter   156/  201] train: loss: 0.1915789
[Epoch 25; Iter   186/  201] train: loss: 0.1477796
[Epoch 25] ogbg-moltoxcast: 0.729583 val loss: 0.203161
[Epoch 25] ogbg-moltoxcast: 0.742779 test loss: 0.205327
[Epoch 26; Iter    15/  201] train: loss: 0.1631012
[Epoch 26; Iter    45/  201] train: loss: 0.2386909
[Epoch 26; Iter    75/  201] train: loss: 0.1851681
[Epoch 26; Iter   105/  201] train: loss: 0.1904595
[Epoch 26; Iter   135/  201] train: loss: 0.2467889
[Epoch 26; Iter   165/  201] train: loss: 0.1312006
[Epoch 26; Iter   195/  201] train: loss: 0.1636084
[Epoch 26] ogbg-moltoxcast: 0.724291 val loss: 0.207054
[Epoch 26] ogbg-moltoxcast: 0.741624 test loss: 0.206158
[Epoch 27; Iter    24/  201] train: loss: 0.1952799
[Epoch 27; Iter    54/  201] train: loss: 0.1760425
[Epoch 27; Iter    84/  201] train: loss: 0.1870007
[Epoch 27; Iter   114/  201] train: loss: 0.1744530
[Epoch 27; Iter   144/  201] train: loss: 0.1785793
[Epoch 27; Iter   174/  201] train: loss: 0.2446101
[Epoch 27] ogbg-moltoxcast: 0.726121 val loss: 0.205484
[Epoch 27] ogbg-moltoxcast: 0.743544 test loss: 0.207188
[Epoch 28; Iter     3/  201] train: loss: 0.2952085
[Epoch 28; Iter    33/  201] train: loss: 0.2642395
[Epoch 28; Iter    63/  201] train: loss: 0.2089224
[Epoch 28; Iter    93/  201] train: loss: 0.1877894
[Epoch 28; Iter   123/  201] train: loss: 0.1758377
[Epoch 28; Iter   153/  201] train: loss: 0.2064688
[Epoch 28; Iter   183/  201] train: loss: 0.1919288
[Epoch 28] ogbg-moltoxcast: 0.697730 val loss: 0.215513
[Epoch 28] ogbg-moltoxcast: 0.725103 test loss: 0.233702
[Epoch 29; Iter    12/  201] train: loss: 0.1090030
[Epoch 29; Iter    42/  201] train: loss: 0.1656064
[Epoch 29; Iter    72/  201] train: loss: 0.1756734
[Epoch 29; Iter   102/  201] train: loss: 0.1595810
[Epoch 29; Iter   132/  201] train: loss: 0.1541714
[Epoch 29; Iter   162/  201] train: loss: 0.1863085
[Epoch 29; Iter   192/  201] train: loss: 0.2081003
[Epoch 29] ogbg-moltoxcast: 0.723084 val loss: 0.227235
[Epoch 29] ogbg-moltoxcast: 0.736334 test loss: 0.425192
[Epoch 30; Iter    21/  201] train: loss: 0.1418922
[Epoch 30; Iter    51/  201] train: loss: 0.1963182
[Epoch 30; Iter    81/  201] train: loss: 0.1857749
[Epoch 30; Iter   111/  201] train: loss: 0.1894170
[Epoch 30; Iter   141/  201] train: loss: 0.1814410
[Epoch 30; Iter   171/  201] train: loss: 0.1486902
[Epoch 30; Iter   201/  201] train: loss: 0.2415808
[Epoch 30] ogbg-moltoxcast: 0.722783 val loss: 0.211891
[Epoch 13; Iter    78/  201] train: loss: 0.1713965
[Epoch 13; Iter   108/  201] train: loss: 0.3248962
[Epoch 13; Iter   138/  201] train: loss: 0.1899338
[Epoch 13; Iter   168/  201] train: loss: 0.1739817
[Epoch 13; Iter   198/  201] train: loss: 0.2331542
[Epoch 13] ogbg-moltoxcast: 0.702806 val loss: 0.222709
[Epoch 13] ogbg-moltoxcast: 0.720358 test loss: 0.368891
[Epoch 14; Iter    27/  201] train: loss: 0.1667395
[Epoch 14; Iter    57/  201] train: loss: 0.2329076
[Epoch 14; Iter    87/  201] train: loss: 0.2011521
[Epoch 14; Iter   117/  201] train: loss: 0.2597862
[Epoch 14; Iter   147/  201] train: loss: 0.2412585
[Epoch 14; Iter   177/  201] train: loss: 0.2403445
[Epoch 14] ogbg-moltoxcast: 0.702123 val loss: 0.211189
[Epoch 14] ogbg-moltoxcast: 0.720048 test loss: 0.269445
[Epoch 15; Iter     6/  201] train: loss: 0.1543211
[Epoch 15; Iter    36/  201] train: loss: 0.1814835
[Epoch 15; Iter    66/  201] train: loss: 0.2235660
[Epoch 15; Iter    96/  201] train: loss: 0.2134394
[Epoch 15; Iter   126/  201] train: loss: 0.1219619
[Epoch 15; Iter   156/  201] train: loss: 0.1677660
[Epoch 15; Iter   186/  201] train: loss: 0.1574204
[Epoch 15] ogbg-moltoxcast: 0.701455 val loss: 0.209643
[Epoch 15] ogbg-moltoxcast: 0.735836 test loss: 0.216016
[Epoch 16; Iter    15/  201] train: loss: 0.2285238
[Epoch 16; Iter    45/  201] train: loss: 0.1685436
[Epoch 16; Iter    75/  201] train: loss: 0.2258011
[Epoch 16; Iter   105/  201] train: loss: 0.1728868
[Epoch 16; Iter   135/  201] train: loss: 0.2315365
[Epoch 16; Iter   165/  201] train: loss: 0.2024993
[Epoch 16; Iter   195/  201] train: loss: 0.2114718
[Epoch 16] ogbg-moltoxcast: 0.704034 val loss: 0.216026
[Epoch 16] ogbg-moltoxcast: 0.728243 test loss: 0.304092
[Epoch 17; Iter    24/  201] train: loss: 0.2552481
[Epoch 17; Iter    54/  201] train: loss: 0.1958413
[Epoch 17; Iter    84/  201] train: loss: 0.3437731
[Epoch 17; Iter   114/  201] train: loss: 0.2245615
[Epoch 17; Iter   144/  201] train: loss: 0.1843933
[Epoch 17; Iter   174/  201] train: loss: 0.2223130
[Epoch 17] ogbg-moltoxcast: 0.723449 val loss: 0.206528
[Epoch 17] ogbg-moltoxcast: 0.735489 test loss: 0.210748
[Epoch 18; Iter     3/  201] train: loss: 0.1232297
[Epoch 18; Iter    33/  201] train: loss: 0.1716647
[Epoch 18; Iter    63/  201] train: loss: 0.2003894
[Epoch 18; Iter    93/  201] train: loss: 0.1447169
[Epoch 18; Iter   123/  201] train: loss: 0.2307616
[Epoch 18; Iter   153/  201] train: loss: 0.2042128
[Epoch 18; Iter   183/  201] train: loss: 0.2041098
[Epoch 18] ogbg-moltoxcast: 0.709582 val loss: 0.208869
[Epoch 18] ogbg-moltoxcast: 0.734959 test loss: 0.211131
[Epoch 19; Iter    12/  201] train: loss: 0.2167547
[Epoch 19; Iter    42/  201] train: loss: 0.1182680
[Epoch 19; Iter    72/  201] train: loss: 0.1500183
[Epoch 19; Iter   102/  201] train: loss: 0.1825864
[Epoch 19; Iter   132/  201] train: loss: 0.1591899
[Epoch 19; Iter   162/  201] train: loss: 0.1425230
[Epoch 19; Iter   192/  201] train: loss: 0.1834429
[Epoch 19] ogbg-moltoxcast: 0.718478 val loss: 0.205395
[Epoch 19] ogbg-moltoxcast: 0.741599 test loss: 0.207020
[Epoch 20; Iter    21/  201] train: loss: 0.1765031
[Epoch 20; Iter    51/  201] train: loss: 0.1790496
[Epoch 20; Iter    81/  201] train: loss: 0.2442917
[Epoch 20; Iter   111/  201] train: loss: 0.2658982
[Epoch 20; Iter   141/  201] train: loss: 0.2109766
[Epoch 20; Iter   171/  201] train: loss: 0.1577959
[Epoch 20; Iter   201/  201] train: loss: 0.1545141
[Epoch 20] ogbg-moltoxcast: 0.708278 val loss: 0.211092
[Epoch 20] ogbg-moltoxcast: 0.732962 test loss: 0.210731
[Epoch 21; Iter    30/  201] train: loss: 0.1477213
[Epoch 21; Iter    60/  201] train: loss: 0.1653480
[Epoch 21; Iter    90/  201] train: loss: 0.2181869
[Epoch 21; Iter   120/  201] train: loss: 0.1901675
[Epoch 21; Iter   150/  201] train: loss: 0.2070673
[Epoch 21; Iter   180/  201] train: loss: 0.1962944
[Epoch 21] ogbg-moltoxcast: 0.714626 val loss: 0.211433
[Epoch 21] ogbg-moltoxcast: 0.747834 test loss: 0.204132
[Epoch 22; Iter     9/  201] train: loss: 0.1576265
[Epoch 22; Iter    39/  201] train: loss: 0.1503974
[Epoch 22; Iter    69/  201] train: loss: 0.1777197
[Epoch 22; Iter    99/  201] train: loss: 0.1247579
[Epoch 22; Iter   129/  201] train: loss: 0.1602125
[Epoch 22; Iter   159/  201] train: loss: 0.2130897
[Epoch 22; Iter   189/  201] train: loss: 0.1819415
[Epoch 22] ogbg-moltoxcast: 0.691931 val loss: 0.214987
[Epoch 22] ogbg-moltoxcast: 0.733122 test loss: 0.213281
[Epoch 23; Iter    18/  201] train: loss: 0.2102835
[Epoch 23; Iter    48/  201] train: loss: 0.2180328
[Epoch 23; Iter    78/  201] train: loss: 0.1754780
[Epoch 23; Iter   108/  201] train: loss: 0.2516417
[Epoch 23; Iter   138/  201] train: loss: 0.1691864
[Epoch 23; Iter   168/  201] train: loss: 0.1362183
[Epoch 23; Iter   198/  201] train: loss: 0.1577557
[Epoch 23] ogbg-moltoxcast: 0.722860 val loss: 0.208057
[Epoch 23] ogbg-moltoxcast: 0.740628 test loss: 0.206840
[Epoch 24; Iter    27/  201] train: loss: 0.2338312
[Epoch 24; Iter    57/  201] train: loss: 0.1315541
[Epoch 24; Iter    87/  201] train: loss: 0.2714156
[Epoch 24; Iter   117/  201] train: loss: 0.2470435
[Epoch 24; Iter   147/  201] train: loss: 0.2036185
[Epoch 24; Iter   177/  201] train: loss: 0.1492086
[Epoch 24] ogbg-moltoxcast: 0.717699 val loss: 0.216166
[Epoch 24] ogbg-moltoxcast: 0.743943 test loss: 0.207095
[Epoch 25; Iter     6/  201] train: loss: 0.2035962
[Epoch 25; Iter    36/  201] train: loss: 0.1477436
[Epoch 25; Iter    66/  201] train: loss: 0.1732770
[Epoch 25; Iter    96/  201] train: loss: 0.2854861
[Epoch 25; Iter   126/  201] train: loss: 0.1687585
[Epoch 25; Iter   156/  201] train: loss: 0.1215111
[Epoch 25; Iter   186/  201] train: loss: 0.1653615
[Epoch 25] ogbg-moltoxcast: 0.723276 val loss: 0.210054
[Epoch 25] ogbg-moltoxcast: 0.749273 test loss: 0.205647
[Epoch 26; Iter    15/  201] train: loss: 0.1532654
[Epoch 26; Iter    45/  201] train: loss: 0.1706881
[Epoch 26; Iter    75/  201] train: loss: 0.1369049
[Epoch 26; Iter   105/  201] train: loss: 0.1655239
[Epoch 26; Iter   135/  201] train: loss: 0.2198558
[Epoch 26; Iter   165/  201] train: loss: 0.1358574
[Epoch 26; Iter   195/  201] train: loss: 0.1754565
[Epoch 26] ogbg-moltoxcast: 0.723990 val loss: 0.208342
[Epoch 26] ogbg-moltoxcast: 0.741310 test loss: 0.206666
[Epoch 27; Iter    24/  201] train: loss: 0.2012171
[Epoch 27; Iter    54/  201] train: loss: 0.2106522
[Epoch 27; Iter    84/  201] train: loss: 0.2798866
[Epoch 27; Iter   114/  201] train: loss: 0.1509338
[Epoch 27; Iter   144/  201] train: loss: 0.1201668
[Epoch 27; Iter   174/  201] train: loss: 0.2131315
[Epoch 27] ogbg-moltoxcast: 0.731943 val loss: 0.203713
[Epoch 27] ogbg-moltoxcast: 0.750587 test loss: 0.201831
[Epoch 28; Iter     3/  201] train: loss: 0.2387947
[Epoch 28; Iter    33/  201] train: loss: 0.1733710
[Epoch 28; Iter    63/  201] train: loss: 0.1388364
[Epoch 28; Iter    93/  201] train: loss: 0.1480021
[Epoch 28; Iter   123/  201] train: loss: 0.2424717
[Epoch 28; Iter   153/  201] train: loss: 0.1937735
[Epoch 28; Iter   183/  201] train: loss: 0.2196659
[Epoch 28] ogbg-moltoxcast: 0.729191 val loss: 0.203986
[Epoch 28] ogbg-moltoxcast: 0.735963 test loss: 0.206831
[Epoch 29; Iter    12/  201] train: loss: 0.1102067
[Epoch 29; Iter    42/  201] train: loss: 0.2289568
[Epoch 29; Iter    72/  201] train: loss: 0.1363020
[Epoch 29; Iter   102/  201] train: loss: 0.1376580
[Epoch 29; Iter   132/  201] train: loss: 0.1242227
[Epoch 29; Iter   162/  201] train: loss: 0.1397527
[Epoch 29; Iter   192/  201] train: loss: 0.2074978
[Epoch 29] ogbg-moltoxcast: 0.712719 val loss: 0.207355
[Epoch 29] ogbg-moltoxcast: 0.729752 test loss: 0.209555
[Epoch 30; Iter    21/  201] train: loss: 0.2048593
[Epoch 30; Iter    51/  201] train: loss: 0.2061190
[Epoch 30; Iter    81/  201] train: loss: 0.1357109
[Epoch 30; Iter   111/  201] train: loss: 0.1634941
[Epoch 30; Iter   141/  201] train: loss: 0.2350183
[Epoch 30; Iter   171/  201] train: loss: 0.1373044
[Epoch 30; Iter   201/  201] train: loss: 0.0795995
[Epoch 30] ogbg-moltoxcast: 0.731375 val loss: 0.204581
[Epoch 13; Iter    78/  201] train: loss: 0.2448065
[Epoch 13; Iter   108/  201] train: loss: 0.1920689
[Epoch 13; Iter   138/  201] train: loss: 0.2561564
[Epoch 13; Iter   168/  201] train: loss: 0.2363044
[Epoch 13; Iter   198/  201] train: loss: 0.1663339
[Epoch 13] ogbg-moltoxcast: 0.686014 val loss: 0.253920
[Epoch 13] ogbg-moltoxcast: 0.708874 test loss: 0.262665
[Epoch 14; Iter    27/  201] train: loss: 0.2465118
[Epoch 14; Iter    57/  201] train: loss: 0.1719432
[Epoch 14; Iter    87/  201] train: loss: 0.1310657
[Epoch 14; Iter   117/  201] train: loss: 0.1271833
[Epoch 14; Iter   147/  201] train: loss: 0.2064790
[Epoch 14; Iter   177/  201] train: loss: 0.1669416
[Epoch 14] ogbg-moltoxcast: 0.677948 val loss: 0.217827
[Epoch 14] ogbg-moltoxcast: 0.713341 test loss: 0.224482
[Epoch 15; Iter     6/  201] train: loss: 0.1349256
[Epoch 15; Iter    36/  201] train: loss: 0.1219102
[Epoch 15; Iter    66/  201] train: loss: 0.1950481
[Epoch 15; Iter    96/  201] train: loss: 0.1786370
[Epoch 15; Iter   126/  201] train: loss: 0.2518761
[Epoch 15; Iter   156/  201] train: loss: 0.1541680
[Epoch 15; Iter   186/  201] train: loss: 0.2374433
[Epoch 15] ogbg-moltoxcast: 0.700125 val loss: 0.211736
[Epoch 15] ogbg-moltoxcast: 0.722316 test loss: 0.214064
[Epoch 16; Iter    15/  201] train: loss: 0.1829508
[Epoch 16; Iter    45/  201] train: loss: 0.1364752
[Epoch 16; Iter    75/  201] train: loss: 0.2424032
[Epoch 16; Iter   105/  201] train: loss: 0.1944222
[Epoch 16; Iter   135/  201] train: loss: 0.1758632
[Epoch 16; Iter   165/  201] train: loss: 0.1509677
[Epoch 16; Iter   195/  201] train: loss: 0.1958384
[Epoch 16] ogbg-moltoxcast: 0.699631 val loss: 0.210665
[Epoch 16] ogbg-moltoxcast: 0.722670 test loss: 0.215698
[Epoch 17; Iter    24/  201] train: loss: 0.1654009
[Epoch 17; Iter    54/  201] train: loss: 0.1954593
[Epoch 17; Iter    84/  201] train: loss: 0.1990714
[Epoch 17; Iter   114/  201] train: loss: 0.2191686
[Epoch 17; Iter   144/  201] train: loss: 0.2455125
[Epoch 17; Iter   174/  201] train: loss: 0.2272594
[Epoch 17] ogbg-moltoxcast: 0.682347 val loss: 0.216687
[Epoch 17] ogbg-moltoxcast: 0.705590 test loss: 0.219889
[Epoch 18; Iter     3/  201] train: loss: 0.2433471
[Epoch 18; Iter    33/  201] train: loss: 0.1411980
[Epoch 18; Iter    63/  201] train: loss: 0.2840273
[Epoch 18; Iter    93/  201] train: loss: 0.1604333
[Epoch 18; Iter   123/  201] train: loss: 0.1408016
[Epoch 18; Iter   153/  201] train: loss: 0.1571294
[Epoch 18; Iter   183/  201] train: loss: 0.2687211
[Epoch 18] ogbg-moltoxcast: 0.702615 val loss: 0.255153
[Epoch 18] ogbg-moltoxcast: 0.723105 test loss: 0.299739
[Epoch 19; Iter    12/  201] train: loss: 0.1805796
[Epoch 19; Iter    42/  201] train: loss: 0.2639073
[Epoch 19; Iter    72/  201] train: loss: 0.2353286
[Epoch 19; Iter   102/  201] train: loss: 0.1445267
[Epoch 19; Iter   132/  201] train: loss: 0.1299349
[Epoch 19; Iter   162/  201] train: loss: 0.1876835
[Epoch 19; Iter   192/  201] train: loss: 0.1466092
[Epoch 19] ogbg-moltoxcast: 0.715963 val loss: 0.246400
[Epoch 19] ogbg-moltoxcast: 0.722804 test loss: 0.263271
[Epoch 20; Iter    21/  201] train: loss: 0.2329323
[Epoch 20; Iter    51/  201] train: loss: 0.2649984
[Epoch 20; Iter    81/  201] train: loss: 0.1669192
[Epoch 20; Iter   111/  201] train: loss: 0.1582933
[Epoch 20; Iter   141/  201] train: loss: 0.2049646
[Epoch 20; Iter   171/  201] train: loss: 0.2288535
[Epoch 20; Iter   201/  201] train: loss: 0.0459162
[Epoch 20] ogbg-moltoxcast: 0.706944 val loss: 0.263316
[Epoch 20] ogbg-moltoxcast: 0.739629 test loss: 0.268623
[Epoch 21; Iter    30/  201] train: loss: 0.1634510
[Epoch 21; Iter    60/  201] train: loss: 0.1896238
[Epoch 21; Iter    90/  201] train: loss: 0.1864049
[Epoch 21; Iter   120/  201] train: loss: 0.2106538
[Epoch 21; Iter   150/  201] train: loss: 0.1452556
[Epoch 21; Iter   180/  201] train: loss: 0.1809792
[Epoch 21] ogbg-moltoxcast: 0.714816 val loss: 0.217236
[Epoch 21] ogbg-moltoxcast: 0.735935 test loss: 0.219330
[Epoch 22; Iter     9/  201] train: loss: 0.3138298
[Epoch 22; Iter    39/  201] train: loss: 0.1893407
[Epoch 22; Iter    69/  201] train: loss: 0.2125469
[Epoch 22; Iter    99/  201] train: loss: 0.1905011
[Epoch 22; Iter   129/  201] train: loss: 0.2429820
[Epoch 22; Iter   159/  201] train: loss: 0.1929295
[Epoch 22; Iter   189/  201] train: loss: 0.2059607
[Epoch 22] ogbg-moltoxcast: 0.712225 val loss: 0.263089
[Epoch 22] ogbg-moltoxcast: 0.730262 test loss: 0.246959
[Epoch 23; Iter    18/  201] train: loss: 0.1970575
[Epoch 23; Iter    48/  201] train: loss: 0.1720293
[Epoch 23; Iter    78/  201] train: loss: 0.1975056
[Epoch 23; Iter   108/  201] train: loss: 0.1371160
[Epoch 23; Iter   138/  201] train: loss: 0.1977700
[Epoch 23; Iter   168/  201] train: loss: 0.2276125
[Epoch 23; Iter   198/  201] train: loss: 0.1320213
[Epoch 23] ogbg-moltoxcast: 0.718722 val loss: 0.658198
[Epoch 23] ogbg-moltoxcast: 0.736268 test loss: 0.768435
[Epoch 24; Iter    27/  201] train: loss: 0.1640927
[Epoch 24; Iter    57/  201] train: loss: 0.1546046
[Epoch 24; Iter    87/  201] train: loss: 0.2647768
[Epoch 24; Iter   117/  201] train: loss: 0.2155092
[Epoch 24; Iter   147/  201] train: loss: 0.1155112
[Epoch 24; Iter   177/  201] train: loss: 0.1620313
[Epoch 24] ogbg-moltoxcast: 0.726366 val loss: 0.332049
[Epoch 24] ogbg-moltoxcast: 0.740888 test loss: 0.263751
[Epoch 25; Iter     6/  201] train: loss: 0.2667339
[Epoch 25; Iter    36/  201] train: loss: 0.1828991
[Epoch 25; Iter    66/  201] train: loss: 0.2148619
[Epoch 25; Iter    96/  201] train: loss: 0.2228716
[Epoch 25; Iter   126/  201] train: loss: 0.1309543
[Epoch 25; Iter   156/  201] train: loss: 0.2105176
[Epoch 25; Iter   186/  201] train: loss: 0.2468168
[Epoch 25] ogbg-moltoxcast: 0.713234 val loss: 0.219930
[Epoch 25] ogbg-moltoxcast: 0.751108 test loss: 0.214986
[Epoch 26; Iter    15/  201] train: loss: 0.1595156
[Epoch 26; Iter    45/  201] train: loss: 0.2012914
[Epoch 26; Iter    75/  201] train: loss: 0.1352701
[Epoch 26; Iter   105/  201] train: loss: 0.2059366
[Epoch 26; Iter   135/  201] train: loss: 0.2181577
[Epoch 26; Iter   165/  201] train: loss: 0.1837326
[Epoch 26; Iter   195/  201] train: loss: 0.1917384
[Epoch 26] ogbg-moltoxcast: 0.719671 val loss: 0.210384
[Epoch 26] ogbg-moltoxcast: 0.741865 test loss: 0.213035
[Epoch 27; Iter    24/  201] train: loss: 0.1348877
[Epoch 27; Iter    54/  201] train: loss: 0.2281039
[Epoch 27; Iter    84/  201] train: loss: 0.1528528
[Epoch 27; Iter   114/  201] train: loss: 0.2049682
[Epoch 27; Iter   144/  201] train: loss: 0.1865827
[Epoch 27; Iter   174/  201] train: loss: 0.2587622
[Epoch 27] ogbg-moltoxcast: 0.717808 val loss: 0.210525
[Epoch 27] ogbg-moltoxcast: 0.737346 test loss: 0.210532
[Epoch 28; Iter     3/  201] train: loss: 0.1931409
[Epoch 28; Iter    33/  201] train: loss: 0.1854410
[Epoch 28; Iter    63/  201] train: loss: 0.1571610
[Epoch 28; Iter    93/  201] train: loss: 0.1598135
[Epoch 28; Iter   123/  201] train: loss: 0.1519042
[Epoch 28; Iter   153/  201] train: loss: 0.2069810
[Epoch 28; Iter   183/  201] train: loss: 0.1866953
[Epoch 28] ogbg-moltoxcast: 0.716261 val loss: 0.210120
[Epoch 28] ogbg-moltoxcast: 0.743447 test loss: 0.210736
[Epoch 29; Iter    12/  201] train: loss: 0.1955057
[Epoch 29; Iter    42/  201] train: loss: 0.1780617
[Epoch 29; Iter    72/  201] train: loss: 0.1629417
[Epoch 29; Iter   102/  201] train: loss: 0.1907184
[Epoch 29; Iter   132/  201] train: loss: 0.1302830
[Epoch 29; Iter   162/  201] train: loss: 0.1539832
[Epoch 29; Iter   192/  201] train: loss: 0.1492188
[Epoch 29] ogbg-moltoxcast: 0.720775 val loss: 0.223905
[Epoch 29] ogbg-moltoxcast: 0.735619 test loss: 0.224562
[Epoch 30; Iter    21/  201] train: loss: 0.1631020
[Epoch 30; Iter    51/  201] train: loss: 0.1645111
[Epoch 30; Iter    81/  201] train: loss: 0.1315494
[Epoch 30; Iter   111/  201] train: loss: 0.1773884
[Epoch 30; Iter   141/  201] train: loss: 0.1971477
[Epoch 30; Iter   171/  201] train: loss: 0.1781583
[Epoch 30; Iter   201/  201] train: loss: 0.3937603
[Epoch 30] ogbg-moltoxcast: 0.726627 val loss: 0.208138
[Epoch 14; Iter   164/  172] train: loss: 0.1839373
[Epoch 14] ogbg-moltoxcast: 0.682571 val loss: 0.216316
[Epoch 14] ogbg-moltoxcast: 0.700432 test loss: 0.215265
[Epoch 15; Iter    22/  172] train: loss: 0.2282928
[Epoch 15; Iter    52/  172] train: loss: 0.2410196
[Epoch 15; Iter    82/  172] train: loss: 0.1349777
[Epoch 15; Iter   112/  172] train: loss: 0.1757304
[Epoch 15; Iter   142/  172] train: loss: 0.2522493
[Epoch 15; Iter   172/  172] train: loss: 0.2557031
[Epoch 15] ogbg-moltoxcast: 0.690459 val loss: 0.213465
[Epoch 15] ogbg-moltoxcast: 0.694725 test loss: 0.213992
[Epoch 16; Iter    30/  172] train: loss: 0.2100922
[Epoch 16; Iter    60/  172] train: loss: 0.2584362
[Epoch 16; Iter    90/  172] train: loss: 0.1422157
[Epoch 16; Iter   120/  172] train: loss: 0.1655588
[Epoch 16; Iter   150/  172] train: loss: 0.2426898
[Epoch 16] ogbg-moltoxcast: 0.704600 val loss: 0.211715
[Epoch 16] ogbg-moltoxcast: 0.706421 test loss: 0.212377
[Epoch 17; Iter     8/  172] train: loss: 0.2555667
[Epoch 17; Iter    38/  172] train: loss: 0.1466113
[Epoch 17; Iter    68/  172] train: loss: 0.1610352
[Epoch 17; Iter    98/  172] train: loss: 0.2170987
[Epoch 17; Iter   128/  172] train: loss: 0.1955754
[Epoch 17; Iter   158/  172] train: loss: 0.2110349
[Epoch 17] ogbg-moltoxcast: 0.701571 val loss: 0.212321
[Epoch 17] ogbg-moltoxcast: 0.719832 test loss: 0.206842
[Epoch 18; Iter    16/  172] train: loss: 0.1576510
[Epoch 18; Iter    46/  172] train: loss: 0.1913631
[Epoch 18; Iter    76/  172] train: loss: 0.1973778
[Epoch 18; Iter   106/  172] train: loss: 0.1616898
[Epoch 18; Iter   136/  172] train: loss: 0.1951665
[Epoch 18; Iter   166/  172] train: loss: 0.2240829
[Epoch 18] ogbg-moltoxcast: 0.697055 val loss: 0.221229
[Epoch 18] ogbg-moltoxcast: 0.696900 test loss: 0.222090
[Epoch 19; Iter    24/  172] train: loss: 0.2098721
[Epoch 19; Iter    54/  172] train: loss: 0.1715149
[Epoch 19; Iter    84/  172] train: loss: 0.1462820
[Epoch 19; Iter   114/  172] train: loss: 0.2485114
[Epoch 19; Iter   144/  172] train: loss: 0.1701369
[Epoch 19] ogbg-moltoxcast: 0.709562 val loss: 0.209022
[Epoch 19] ogbg-moltoxcast: 0.722362 test loss: 0.205085
[Epoch 20; Iter     2/  172] train: loss: 0.1285612
[Epoch 20; Iter    32/  172] train: loss: 0.1931366
[Epoch 20; Iter    62/  172] train: loss: 0.1722206
[Epoch 20; Iter    92/  172] train: loss: 0.1378626
[Epoch 20; Iter   122/  172] train: loss: 0.2298909
[Epoch 20; Iter   152/  172] train: loss: 0.1472458
[Epoch 20] ogbg-moltoxcast: 0.722639 val loss: 0.202919
[Epoch 20] ogbg-moltoxcast: 0.732822 test loss: 0.201504
[Epoch 21; Iter    10/  172] train: loss: 0.2103557
[Epoch 21; Iter    40/  172] train: loss: 0.1605347
[Epoch 21; Iter    70/  172] train: loss: 0.2006362
[Epoch 21; Iter   100/  172] train: loss: 0.1752419
[Epoch 21; Iter   130/  172] train: loss: 0.1393129
[Epoch 21; Iter   160/  172] train: loss: 0.1601425
[Epoch 21] ogbg-moltoxcast: 0.718634 val loss: 0.204235
[Epoch 21] ogbg-moltoxcast: 0.725261 test loss: 0.204487
[Epoch 22; Iter    18/  172] train: loss: 0.1549157
[Epoch 22; Iter    48/  172] train: loss: 0.2069959
[Epoch 22; Iter    78/  172] train: loss: 0.1454139
[Epoch 22; Iter   108/  172] train: loss: 0.1783637
[Epoch 22; Iter   138/  172] train: loss: 0.1895403
[Epoch 22; Iter   168/  172] train: loss: 0.2024688
[Epoch 22] ogbg-moltoxcast: 0.698756 val loss: 0.227894
[Epoch 22] ogbg-moltoxcast: 0.704093 test loss: 0.238284
[Epoch 23; Iter    26/  172] train: loss: 0.1566237
[Epoch 23; Iter    56/  172] train: loss: 0.1690561
[Epoch 23; Iter    86/  172] train: loss: 0.1060174
[Epoch 23; Iter   116/  172] train: loss: 0.1787522
[Epoch 23; Iter   146/  172] train: loss: 0.1681695
[Epoch 23] ogbg-moltoxcast: 0.717779 val loss: 0.308981
[Epoch 23] ogbg-moltoxcast: 0.727457 test loss: 0.306343
[Epoch 24; Iter     4/  172] train: loss: 0.2255694
[Epoch 24; Iter    34/  172] train: loss: 0.2005919
[Epoch 24; Iter    64/  172] train: loss: 0.2182921
[Epoch 24; Iter    94/  172] train: loss: 0.1995307
[Epoch 24; Iter   124/  172] train: loss: 0.2413094
[Epoch 24; Iter   154/  172] train: loss: 0.1755547
[Epoch 24] ogbg-moltoxcast: 0.721952 val loss: 0.317475
[Epoch 24] ogbg-moltoxcast: 0.722476 test loss: 0.388438
[Epoch 25; Iter    12/  172] train: loss: 0.1595735
[Epoch 25; Iter    42/  172] train: loss: 0.1777788
[Epoch 25; Iter    72/  172] train: loss: 0.1894249
[Epoch 25; Iter   102/  172] train: loss: 0.1792752
[Epoch 25; Iter   132/  172] train: loss: 0.2187396
[Epoch 25; Iter   162/  172] train: loss: 0.2271913
[Epoch 25] ogbg-moltoxcast: 0.720730 val loss: 0.205105
[Epoch 25] ogbg-moltoxcast: 0.731132 test loss: 0.235148
[Epoch 26; Iter    20/  172] train: loss: 0.1588802
[Epoch 26; Iter    50/  172] train: loss: 0.1464032
[Epoch 26; Iter    80/  172] train: loss: 0.2202602
[Epoch 26; Iter   110/  172] train: loss: 0.1846775
[Epoch 26; Iter   140/  172] train: loss: 0.2319262
[Epoch 26; Iter   170/  172] train: loss: 0.1338468
[Epoch 26] ogbg-moltoxcast: 0.716304 val loss: 0.207687
[Epoch 26] ogbg-moltoxcast: 0.728705 test loss: 0.206292
[Epoch 27; Iter    28/  172] train: loss: 0.2097718
[Epoch 27; Iter    58/  172] train: loss: 0.1887850
[Epoch 27; Iter    88/  172] train: loss: 0.1528673
[Epoch 27; Iter   118/  172] train: loss: 0.2061935
[Epoch 27; Iter   148/  172] train: loss: 0.1585828
[Epoch 27] ogbg-moltoxcast: 0.726991 val loss: 0.203160
[Epoch 27] ogbg-moltoxcast: 0.724908 test loss: 0.204889
[Epoch 28; Iter     6/  172] train: loss: 0.1442937
[Epoch 28; Iter    36/  172] train: loss: 0.2351803
[Epoch 28; Iter    66/  172] train: loss: 0.1887341
[Epoch 28; Iter    96/  172] train: loss: 0.1705853
[Epoch 28; Iter   126/  172] train: loss: 0.1561185
[Epoch 28; Iter   156/  172] train: loss: 0.2388892
[Epoch 28] ogbg-moltoxcast: 0.720348 val loss: 0.205437
[Epoch 28] ogbg-moltoxcast: 0.733882 test loss: 0.201684
[Epoch 29; Iter    14/  172] train: loss: 0.1988871
[Epoch 29; Iter    44/  172] train: loss: 0.1793876
[Epoch 29; Iter    74/  172] train: loss: 0.1520720
[Epoch 29; Iter   104/  172] train: loss: 0.1137430
[Epoch 29; Iter   134/  172] train: loss: 0.2282710
[Epoch 29; Iter   164/  172] train: loss: 0.1819548
[Epoch 29] ogbg-moltoxcast: 0.724979 val loss: 0.207450
[Epoch 29] ogbg-moltoxcast: 0.725030 test loss: 0.225146
[Epoch 30; Iter    22/  172] train: loss: 0.1440485
[Epoch 30; Iter    52/  172] train: loss: 0.2072947
[Epoch 30; Iter    82/  172] train: loss: 0.1834298
[Epoch 30; Iter   112/  172] train: loss: 0.1968865
[Epoch 30; Iter   142/  172] train: loss: 0.2444814
[Epoch 30; Iter   172/  172] train: loss: 0.1210233
[Epoch 30] ogbg-moltoxcast: 0.719385 val loss: 0.222729
[Epoch 30] ogbg-moltoxcast: 0.728659 test loss: 0.212777
[Epoch 31; Iter    30/  172] train: loss: 0.1688770
[Epoch 31; Iter    60/  172] train: loss: 0.2691221
[Epoch 31; Iter    90/  172] train: loss: 0.1287139
[Epoch 31; Iter   120/  172] train: loss: 0.1668024
[Epoch 31; Iter   150/  172] train: loss: 0.1868269
[Epoch 31] ogbg-moltoxcast: 0.728151 val loss: 0.205774
[Epoch 31] ogbg-moltoxcast: 0.737523 test loss: 0.236665
[Epoch 32; Iter     8/  172] train: loss: 0.1612783
[Epoch 32; Iter    38/  172] train: loss: 0.1663244
[Epoch 32; Iter    68/  172] train: loss: 0.1236509
[Epoch 32; Iter    98/  172] train: loss: 0.1824020
[Epoch 32; Iter   128/  172] train: loss: 0.1906947
[Epoch 32; Iter   158/  172] train: loss: 0.1455848
[Epoch 32] ogbg-moltoxcast: 0.722172 val loss: 0.208271
[Epoch 32] ogbg-moltoxcast: 0.738528 test loss: 0.207376
[Epoch 33; Iter    16/  172] train: loss: 0.1131789
[Epoch 33; Iter    46/  172] train: loss: 0.1797604
[Epoch 33; Iter    76/  172] train: loss: 0.1279791
[Epoch 33; Iter   106/  172] train: loss: 0.1728071
[Epoch 33; Iter   136/  172] train: loss: 0.1947119
[Epoch 33; Iter   166/  172] train: loss: 0.1565612
[Epoch 33] ogbg-moltoxcast: 0.714391 val loss: 0.207579
[Epoch 33] ogbg-moltoxcast: 0.723681 test loss: 0.207127
[Epoch 34; Iter    24/  172] train: loss: 0.1337507
[Epoch 34; Iter    54/  172] train: loss: 0.1459286
[Epoch 34; Iter    84/  172] train: loss: 0.2318794
[Epoch 34; Iter   114/  172] train: loss: 0.2167421
[Epoch 14; Iter   164/  172] train: loss: 0.1730449
[Epoch 14] ogbg-moltoxcast: 0.689145 val loss: 0.217024
[Epoch 14] ogbg-moltoxcast: 0.696062 test loss: 0.215921
[Epoch 15; Iter    22/  172] train: loss: 0.2227152
[Epoch 15; Iter    52/  172] train: loss: 0.1615137
[Epoch 15; Iter    82/  172] train: loss: 0.2219016
[Epoch 15; Iter   112/  172] train: loss: 0.1767357
[Epoch 15; Iter   142/  172] train: loss: 0.1956444
[Epoch 15; Iter   172/  172] train: loss: 0.2502374
[Epoch 15] ogbg-moltoxcast: 0.698277 val loss: 0.213154
[Epoch 15] ogbg-moltoxcast: 0.705249 test loss: 0.210079
[Epoch 16; Iter    30/  172] train: loss: 0.2417494
[Epoch 16; Iter    60/  172] train: loss: 0.1293063
[Epoch 16; Iter    90/  172] train: loss: 0.2357226
[Epoch 16; Iter   120/  172] train: loss: 0.2227449
[Epoch 16; Iter   150/  172] train: loss: 0.1669085
[Epoch 16] ogbg-moltoxcast: 0.698419 val loss: 0.214559
[Epoch 16] ogbg-moltoxcast: 0.702988 test loss: 0.214661
[Epoch 17; Iter     8/  172] train: loss: 0.1240453
[Epoch 17; Iter    38/  172] train: loss: 0.1378734
[Epoch 17; Iter    68/  172] train: loss: 0.2042781
[Epoch 17; Iter    98/  172] train: loss: 0.2033609
[Epoch 17; Iter   128/  172] train: loss: 0.2359796
[Epoch 17; Iter   158/  172] train: loss: 0.2451605
[Epoch 17] ogbg-moltoxcast: 0.702647 val loss: 0.213786
[Epoch 17] ogbg-moltoxcast: 0.703765 test loss: 0.211463
[Epoch 18; Iter    16/  172] train: loss: 0.1088148
[Epoch 18; Iter    46/  172] train: loss: 0.1998648
[Epoch 18; Iter    76/  172] train: loss: 0.2208508
[Epoch 18; Iter   106/  172] train: loss: 0.2408306
[Epoch 18; Iter   136/  172] train: loss: 0.1718220
[Epoch 18; Iter   166/  172] train: loss: 0.1392666
[Epoch 18] ogbg-moltoxcast: 0.711995 val loss: 0.210523
[Epoch 18] ogbg-moltoxcast: 0.719904 test loss: 0.210162
[Epoch 19; Iter    24/  172] train: loss: 0.2177940
[Epoch 19; Iter    54/  172] train: loss: 0.1786529
[Epoch 19; Iter    84/  172] train: loss: 0.1644981
[Epoch 19; Iter   114/  172] train: loss: 0.2194181
[Epoch 19; Iter   144/  172] train: loss: 0.2031720
[Epoch 19] ogbg-moltoxcast: 0.708551 val loss: 0.207073
[Epoch 19] ogbg-moltoxcast: 0.721268 test loss: 0.205358
[Epoch 20; Iter     2/  172] train: loss: 0.1806667
[Epoch 20; Iter    32/  172] train: loss: 0.1729524
[Epoch 20; Iter    62/  172] train: loss: 0.1424913
[Epoch 20; Iter    92/  172] train: loss: 0.2340670
[Epoch 20; Iter   122/  172] train: loss: 0.1668405
[Epoch 20; Iter   152/  172] train: loss: 0.1720615
[Epoch 20] ogbg-moltoxcast: 0.713125 val loss: 0.206302
[Epoch 20] ogbg-moltoxcast: 0.726042 test loss: 0.205507
[Epoch 21; Iter    10/  172] train: loss: 0.2162652
[Epoch 21; Iter    40/  172] train: loss: 0.1244982
[Epoch 21; Iter    70/  172] train: loss: 0.2456835
[Epoch 21; Iter   100/  172] train: loss: 0.1903642
[Epoch 21; Iter   130/  172] train: loss: 0.1658174
[Epoch 21; Iter   160/  172] train: loss: 0.1723568
[Epoch 21] ogbg-moltoxcast: 0.712801 val loss: 0.209317
[Epoch 21] ogbg-moltoxcast: 0.728702 test loss: 0.204494
[Epoch 22; Iter    18/  172] train: loss: 0.1290307
[Epoch 22; Iter    48/  172] train: loss: 0.1590297
[Epoch 22; Iter    78/  172] train: loss: 0.1889760
[Epoch 22; Iter   108/  172] train: loss: 0.1731617
[Epoch 22; Iter   138/  172] train: loss: 0.1985971
[Epoch 22; Iter   168/  172] train: loss: 0.2216096
[Epoch 22] ogbg-moltoxcast: 0.709549 val loss: 0.208148
[Epoch 22] ogbg-moltoxcast: 0.718985 test loss: 0.208134
[Epoch 23; Iter    26/  172] train: loss: 0.1699474
[Epoch 23; Iter    56/  172] train: loss: 0.1634174
[Epoch 23; Iter    86/  172] train: loss: 0.1921892
[Epoch 23; Iter   116/  172] train: loss: 0.2408610
[Epoch 23; Iter   146/  172] train: loss: 0.1804492
[Epoch 23] ogbg-moltoxcast: 0.716465 val loss: 0.206265
[Epoch 23] ogbg-moltoxcast: 0.723201 test loss: 0.206411
[Epoch 24; Iter     4/  172] train: loss: 0.1465328
[Epoch 24; Iter    34/  172] train: loss: 0.1700827
[Epoch 24; Iter    64/  172] train: loss: 0.2057753
[Epoch 24; Iter    94/  172] train: loss: 0.2098047
[Epoch 24; Iter   124/  172] train: loss: 0.2069836
[Epoch 24; Iter   154/  172] train: loss: 0.1578301
[Epoch 24] ogbg-moltoxcast: 0.710371 val loss: 0.207166
[Epoch 24] ogbg-moltoxcast: 0.731804 test loss: 0.202766
[Epoch 25; Iter    12/  172] train: loss: 0.1808769
[Epoch 25; Iter    42/  172] train: loss: 0.1034501
[Epoch 25; Iter    72/  172] train: loss: 0.1507142
[Epoch 25; Iter   102/  172] train: loss: 0.1686661
[Epoch 25; Iter   132/  172] train: loss: 0.0953681
[Epoch 25; Iter   162/  172] train: loss: 0.2003956
[Epoch 25] ogbg-moltoxcast: 0.714546 val loss: 0.205604
[Epoch 25] ogbg-moltoxcast: 0.720771 test loss: 0.204820
[Epoch 26; Iter    20/  172] train: loss: 0.1954808
[Epoch 26; Iter    50/  172] train: loss: 0.1527818
[Epoch 26; Iter    80/  172] train: loss: 0.1866767
[Epoch 26; Iter   110/  172] train: loss: 0.1967542
[Epoch 26; Iter   140/  172] train: loss: 0.1342703
[Epoch 26; Iter   170/  172] train: loss: 0.1671377
[Epoch 26] ogbg-moltoxcast: 0.715751 val loss: 0.204324
[Epoch 26] ogbg-moltoxcast: 0.727487 test loss: 0.202275
[Epoch 27; Iter    28/  172] train: loss: 0.1606129
[Epoch 27; Iter    58/  172] train: loss: 0.1191701
[Epoch 27; Iter    88/  172] train: loss: 0.2172945
[Epoch 27; Iter   118/  172] train: loss: 0.2530108
[Epoch 27; Iter   148/  172] train: loss: 0.1543332
[Epoch 27] ogbg-moltoxcast: 0.719562 val loss: 0.207790
[Epoch 27] ogbg-moltoxcast: 0.724460 test loss: 0.209475
[Epoch 28; Iter     6/  172] train: loss: 0.1908370
[Epoch 28; Iter    36/  172] train: loss: 0.2256878
[Epoch 28; Iter    66/  172] train: loss: 0.2184686
[Epoch 28; Iter    96/  172] train: loss: 0.2202842
[Epoch 28; Iter   126/  172] train: loss: 0.1917275
[Epoch 28; Iter   156/  172] train: loss: 0.1206016
[Epoch 28] ogbg-moltoxcast: 0.721661 val loss: 0.211592
[Epoch 28] ogbg-moltoxcast: 0.722368 test loss: 0.215419
[Epoch 29; Iter    14/  172] train: loss: 0.2385271
[Epoch 29; Iter    44/  172] train: loss: 0.1842376
[Epoch 29; Iter    74/  172] train: loss: 0.2728553
[Epoch 29; Iter   104/  172] train: loss: 0.1909262
[Epoch 29; Iter   134/  172] train: loss: 0.2395352
[Epoch 29; Iter   164/  172] train: loss: 0.1369197
[Epoch 29] ogbg-moltoxcast: 0.716291 val loss: 0.242010
[Epoch 29] ogbg-moltoxcast: 0.722021 test loss: 0.334428
[Epoch 30; Iter    22/  172] train: loss: 0.1703762
[Epoch 30; Iter    52/  172] train: loss: 0.1988526
[Epoch 30; Iter    82/  172] train: loss: 0.1276625
[Epoch 30; Iter   112/  172] train: loss: 0.1336159
[Epoch 30; Iter   142/  172] train: loss: 0.2031796
[Epoch 30; Iter   172/  172] train: loss: 0.1878926
[Epoch 30] ogbg-moltoxcast: 0.727798 val loss: 0.251624
[Epoch 30] ogbg-moltoxcast: 0.729220 test loss: 0.312762
[Epoch 31; Iter    30/  172] train: loss: 0.1258176
[Epoch 31; Iter    60/  172] train: loss: 0.1596496
[Epoch 31; Iter    90/  172] train: loss: 0.1661536
[Epoch 31; Iter   120/  172] train: loss: 0.1830838
[Epoch 31; Iter   150/  172] train: loss: 0.2153440
[Epoch 31] ogbg-moltoxcast: 0.712693 val loss: 0.219510
[Epoch 31] ogbg-moltoxcast: 0.722786 test loss: 0.235490
[Epoch 32; Iter     8/  172] train: loss: 0.1386667
[Epoch 32; Iter    38/  172] train: loss: 0.2224083
[Epoch 32; Iter    68/  172] train: loss: 0.1414989
[Epoch 32; Iter    98/  172] train: loss: 0.1794830
[Epoch 32; Iter   128/  172] train: loss: 0.1860022
[Epoch 32; Iter   158/  172] train: loss: 0.1837336
[Epoch 32] ogbg-moltoxcast: 0.724368 val loss: 0.428674
[Epoch 32] ogbg-moltoxcast: 0.735620 test loss: 0.787360
[Epoch 33; Iter    16/  172] train: loss: 0.1886214
[Epoch 33; Iter    46/  172] train: loss: 0.2237352
[Epoch 33; Iter    76/  172] train: loss: 0.1829451
[Epoch 33; Iter   106/  172] train: loss: 0.1645013
[Epoch 33; Iter   136/  172] train: loss: 0.1610186
[Epoch 33; Iter   166/  172] train: loss: 0.1840803
[Epoch 33] ogbg-moltoxcast: 0.725192 val loss: 0.211829
[Epoch 33] ogbg-moltoxcast: 0.737229 test loss: 0.210160
[Epoch 34; Iter    24/  172] train: loss: 0.1016932
[Epoch 34; Iter    54/  172] train: loss: 0.1328993
[Epoch 34; Iter    84/  172] train: loss: 0.2349197
[Epoch 34; Iter   114/  172] train: loss: 0.1210969
[Epoch 14; Iter   164/  172] train: loss: 0.1896133
[Epoch 14] ogbg-moltoxcast: 0.681937 val loss: 0.289660
[Epoch 14] ogbg-moltoxcast: 0.702274 test loss: 0.215113
[Epoch 15; Iter    22/  172] train: loss: 0.1903869
[Epoch 15; Iter    52/  172] train: loss: 0.2031049
[Epoch 15; Iter    82/  172] train: loss: 0.1083471
[Epoch 15; Iter   112/  172] train: loss: 0.1543514
[Epoch 15; Iter   142/  172] train: loss: 0.1560565
[Epoch 15; Iter   172/  172] train: loss: 0.1822561
[Epoch 15] ogbg-moltoxcast: 0.687244 val loss: 0.219260
[Epoch 15] ogbg-moltoxcast: 0.707705 test loss: 0.212450
[Epoch 16; Iter    30/  172] train: loss: 0.1728211
[Epoch 16; Iter    60/  172] train: loss: 0.1713545
[Epoch 16; Iter    90/  172] train: loss: 0.2184727
[Epoch 16; Iter   120/  172] train: loss: 0.2453929
[Epoch 16; Iter   150/  172] train: loss: 0.1622429
[Epoch 16] ogbg-moltoxcast: 0.690796 val loss: 0.243524
[Epoch 16] ogbg-moltoxcast: 0.705043 test loss: 0.216120
[Epoch 17; Iter     8/  172] train: loss: 0.1931231
[Epoch 17; Iter    38/  172] train: loss: 0.1607849
[Epoch 17; Iter    68/  172] train: loss: 0.2197920
[Epoch 17; Iter    98/  172] train: loss: 0.2603036
[Epoch 17; Iter   128/  172] train: loss: 0.2193437
[Epoch 17; Iter   158/  172] train: loss: 0.1791816
[Epoch 17] ogbg-moltoxcast: 0.690241 val loss: 0.223380
[Epoch 17] ogbg-moltoxcast: 0.700921 test loss: 0.216009
[Epoch 18; Iter    16/  172] train: loss: 0.2104854
[Epoch 18; Iter    46/  172] train: loss: 0.2161022
[Epoch 18; Iter    76/  172] train: loss: 0.2712820
[Epoch 18; Iter   106/  172] train: loss: 0.2055877
[Epoch 18; Iter   136/  172] train: loss: 0.1688799
[Epoch 18; Iter   166/  172] train: loss: 0.1236237
[Epoch 18] ogbg-moltoxcast: 0.697213 val loss: 0.220242
[Epoch 18] ogbg-moltoxcast: 0.712469 test loss: 0.213653
[Epoch 19; Iter    24/  172] train: loss: 0.2794598
[Epoch 19; Iter    54/  172] train: loss: 0.1593336
[Epoch 19; Iter    84/  172] train: loss: 0.2662636
[Epoch 19; Iter   114/  172] train: loss: 0.1801077
[Epoch 19; Iter   144/  172] train: loss: 0.2287892
[Epoch 19] ogbg-moltoxcast: 0.715635 val loss: 0.207519
[Epoch 19] ogbg-moltoxcast: 0.713896 test loss: 0.209535
[Epoch 20; Iter     2/  172] train: loss: 0.1534330
[Epoch 20; Iter    32/  172] train: loss: 0.1441502
[Epoch 20; Iter    62/  172] train: loss: 0.2164112
[Epoch 20; Iter    92/  172] train: loss: 0.1443263
[Epoch 20; Iter   122/  172] train: loss: 0.1639494
[Epoch 20; Iter   152/  172] train: loss: 0.1918753
[Epoch 20] ogbg-moltoxcast: 0.715105 val loss: 0.208055
[Epoch 20] ogbg-moltoxcast: 0.714356 test loss: 0.208304
[Epoch 21; Iter    10/  172] train: loss: 0.1822143
[Epoch 21; Iter    40/  172] train: loss: 0.2173031
[Epoch 21; Iter    70/  172] train: loss: 0.2252245
[Epoch 21; Iter   100/  172] train: loss: 0.1912898
[Epoch 21; Iter   130/  172] train: loss: 0.1661867
[Epoch 21; Iter   160/  172] train: loss: 0.1943754
[Epoch 21] ogbg-moltoxcast: 0.714109 val loss: 0.210721
[Epoch 21] ogbg-moltoxcast: 0.722346 test loss: 0.204638
[Epoch 22; Iter    18/  172] train: loss: 0.2325478
[Epoch 22; Iter    48/  172] train: loss: 0.2002980
[Epoch 22; Iter    78/  172] train: loss: 0.1593863
[Epoch 22; Iter   108/  172] train: loss: 0.1746902
[Epoch 22; Iter   138/  172] train: loss: 0.1633234
[Epoch 22; Iter   168/  172] train: loss: 0.1247445
[Epoch 22] ogbg-moltoxcast: 0.710203 val loss: 0.217738
[Epoch 22] ogbg-moltoxcast: 0.722617 test loss: 0.206904
[Epoch 23; Iter    26/  172] train: loss: 0.2240795
[Epoch 23; Iter    56/  172] train: loss: 0.1580586
[Epoch 23; Iter    86/  172] train: loss: 0.1889962
[Epoch 23; Iter   116/  172] train: loss: 0.2225451
[Epoch 23; Iter   146/  172] train: loss: 0.1849537
[Epoch 23] ogbg-moltoxcast: 0.709523 val loss: 0.250677
[Epoch 23] ogbg-moltoxcast: 0.726867 test loss: 0.205003
[Epoch 24; Iter     4/  172] train: loss: 0.1458515
[Epoch 24; Iter    34/  172] train: loss: 0.1951938
[Epoch 24; Iter    64/  172] train: loss: 0.1892549
[Epoch 24; Iter    94/  172] train: loss: 0.1755201
[Epoch 24; Iter   124/  172] train: loss: 0.1661999
[Epoch 24; Iter   154/  172] train: loss: 0.2425950
[Epoch 24] ogbg-moltoxcast: 0.705832 val loss: 0.242029
[Epoch 24] ogbg-moltoxcast: 0.709467 test loss: 0.209343
[Epoch 25; Iter    12/  172] train: loss: 0.2061707
[Epoch 25; Iter    42/  172] train: loss: 0.2035919
[Epoch 25; Iter    72/  172] train: loss: 0.2017235
[Epoch 25; Iter   102/  172] train: loss: 0.1706757
[Epoch 25; Iter   132/  172] train: loss: 0.2038478
[Epoch 25; Iter   162/  172] train: loss: 0.1789634
[Epoch 25] ogbg-moltoxcast: 0.717813 val loss: 0.202938
[Epoch 25] ogbg-moltoxcast: 0.730083 test loss: 0.202545
[Epoch 26; Iter    20/  172] train: loss: 0.1566607
[Epoch 26; Iter    50/  172] train: loss: 0.1391396
[Epoch 26; Iter    80/  172] train: loss: 0.1611083
[Epoch 26; Iter   110/  172] train: loss: 0.1776969
[Epoch 26; Iter   140/  172] train: loss: 0.2359564
[Epoch 26; Iter   170/  172] train: loss: 0.2301068
[Epoch 26] ogbg-moltoxcast: 0.721762 val loss: 0.204565
[Epoch 26] ogbg-moltoxcast: 0.727499 test loss: 0.204258
[Epoch 27; Iter    28/  172] train: loss: 0.2527463
[Epoch 27; Iter    58/  172] train: loss: 0.2508628
[Epoch 27; Iter    88/  172] train: loss: 0.2189255
[Epoch 27; Iter   118/  172] train: loss: 0.1916348
[Epoch 27; Iter   148/  172] train: loss: 0.1597792
[Epoch 27] ogbg-moltoxcast: 0.715363 val loss: 0.206330
[Epoch 27] ogbg-moltoxcast: 0.724633 test loss: 0.203765
[Epoch 28; Iter     6/  172] train: loss: 0.1489860
[Epoch 28; Iter    36/  172] train: loss: 0.1786756
[Epoch 28; Iter    66/  172] train: loss: 0.2098253
[Epoch 28; Iter    96/  172] train: loss: 0.1970402
[Epoch 28; Iter   126/  172] train: loss: 0.2155120
[Epoch 28; Iter   156/  172] train: loss: 0.2157637
[Epoch 28] ogbg-moltoxcast: 0.723578 val loss: 0.212394
[Epoch 28] ogbg-moltoxcast: 0.734491 test loss: 0.204014
[Epoch 29; Iter    14/  172] train: loss: 0.1861936
[Epoch 29; Iter    44/  172] train: loss: 0.1790873
[Epoch 29; Iter    74/  172] train: loss: 0.1737064
[Epoch 29; Iter   104/  172] train: loss: 0.1974178
[Epoch 29; Iter   134/  172] train: loss: 0.2277509
[Epoch 29; Iter   164/  172] train: loss: 0.1419583
[Epoch 29] ogbg-moltoxcast: 0.724773 val loss: 0.203747
[Epoch 29] ogbg-moltoxcast: 0.733855 test loss: 0.202466
[Epoch 30; Iter    22/  172] train: loss: 0.1702990
[Epoch 30; Iter    52/  172] train: loss: 0.2179635
[Epoch 30; Iter    82/  172] train: loss: 0.1657366
[Epoch 30; Iter   112/  172] train: loss: 0.1602848
[Epoch 30; Iter   142/  172] train: loss: 0.2306769
[Epoch 30; Iter   172/  172] train: loss: 0.0908286
[Epoch 30] ogbg-moltoxcast: 0.723565 val loss: 0.203764
[Epoch 30] ogbg-moltoxcast: 0.731330 test loss: 0.201730
[Epoch 31; Iter    30/  172] train: loss: 0.1712563
[Epoch 31; Iter    60/  172] train: loss: 0.1607259
[Epoch 31; Iter    90/  172] train: loss: 0.1908803
[Epoch 31; Iter   120/  172] train: loss: 0.1925478
[Epoch 31; Iter   150/  172] train: loss: 0.1769396
[Epoch 31] ogbg-moltoxcast: 0.728644 val loss: 0.203534
[Epoch 31] ogbg-moltoxcast: 0.732496 test loss: 0.203496
[Epoch 32; Iter     8/  172] train: loss: 0.1348158
[Epoch 32; Iter    38/  172] train: loss: 0.1833032
[Epoch 32; Iter    68/  172] train: loss: 0.2090703
[Epoch 32; Iter    98/  172] train: loss: 0.1917531
[Epoch 32; Iter   128/  172] train: loss: 0.1946725
[Epoch 32; Iter   158/  172] train: loss: 0.1661715
[Epoch 32] ogbg-moltoxcast: 0.726654 val loss: 0.404451
[Epoch 32] ogbg-moltoxcast: 0.731874 test loss: 0.258171
[Epoch 33; Iter    16/  172] train: loss: 0.1886924
[Epoch 33; Iter    46/  172] train: loss: 0.2070102
[Epoch 33; Iter    76/  172] train: loss: 0.2027031
[Epoch 33; Iter   106/  172] train: loss: 0.1207627
[Epoch 33; Iter   136/  172] train: loss: 0.1616192
[Epoch 33; Iter   166/  172] train: loss: 0.1330259
[Epoch 33] ogbg-moltoxcast: 0.727830 val loss: 0.212596
[Epoch 33] ogbg-moltoxcast: 0.734046 test loss: 0.203966
[Epoch 34; Iter    24/  172] train: loss: 0.1776937
[Epoch 34; Iter    54/  172] train: loss: 0.1608715
[Epoch 34; Iter    84/  172] train: loss: 0.1244891
[Epoch 34; Iter   114/  172] train: loss: 0.1498032
[Epoch 28; Iter    27/  229] train: loss: 0.2519533
[Epoch 28; Iter    57/  229] train: loss: 0.1796488
[Epoch 28; Iter    87/  229] train: loss: 0.2286853
[Epoch 28; Iter   117/  229] train: loss: 0.1450122
[Epoch 28; Iter   147/  229] train: loss: 0.1549263
[Epoch 28; Iter   177/  229] train: loss: 0.1453546
[Epoch 28; Iter   207/  229] train: loss: 0.1305711
[Epoch 28] ogbg-moltoxcast: 0.718899 val loss: 0.202291
[Epoch 28] ogbg-moltoxcast: 0.725214 test loss: 0.365177
[Epoch 29; Iter     8/  229] train: loss: 0.1900620
[Epoch 29; Iter    38/  229] train: loss: 0.1875213
[Epoch 29; Iter    68/  229] train: loss: 0.2469308
[Epoch 29; Iter    98/  229] train: loss: 0.1977458
[Epoch 29; Iter   128/  229] train: loss: 0.2093623
[Epoch 29; Iter   158/  229] train: loss: 0.1890972
[Epoch 29; Iter   188/  229] train: loss: 0.1925855
[Epoch 29; Iter   218/  229] train: loss: 0.1663593
[Epoch 29] ogbg-moltoxcast: 0.740216 val loss: 0.194947
[Epoch 29] ogbg-moltoxcast: 0.748277 test loss: 0.318726
[Epoch 30; Iter    19/  229] train: loss: 0.1019026
[Epoch 30; Iter    49/  229] train: loss: 0.2240961
[Epoch 30; Iter    79/  229] train: loss: 0.2302153
[Epoch 30; Iter   109/  229] train: loss: 0.1604418
[Epoch 30; Iter   139/  229] train: loss: 0.1497745
[Epoch 30; Iter   169/  229] train: loss: 0.1126316
[Epoch 30; Iter   199/  229] train: loss: 0.1916404
[Epoch 30; Iter   229/  229] train: loss: 0.1048669
[Epoch 30] ogbg-moltoxcast: 0.730352 val loss: 0.198048
[Epoch 30] ogbg-moltoxcast: 0.749852 test loss: 0.205995
[Epoch 31; Iter    30/  229] train: loss: 0.1371186
[Epoch 31; Iter    60/  229] train: loss: 0.1201118
[Epoch 31; Iter    90/  229] train: loss: 0.2533552
[Epoch 31; Iter   120/  229] train: loss: 0.2027202
[Epoch 31; Iter   150/  229] train: loss: 0.1196584
[Epoch 31; Iter   180/  229] train: loss: 0.1501421
[Epoch 31; Iter   210/  229] train: loss: 0.1927697
[Epoch 31] ogbg-moltoxcast: 0.724647 val loss: 0.202835
[Epoch 31] ogbg-moltoxcast: 0.750819 test loss: 0.298075
[Epoch 32; Iter    11/  229] train: loss: 0.1939070
[Epoch 32; Iter    41/  229] train: loss: 0.1518657
[Epoch 32; Iter    71/  229] train: loss: 0.1143050
[Epoch 32; Iter   101/  229] train: loss: 0.1771042
[Epoch 32; Iter   131/  229] train: loss: 0.2337962
[Epoch 32; Iter   161/  229] train: loss: 0.1864109
[Epoch 32; Iter   191/  229] train: loss: 0.1774648
[Epoch 32; Iter   221/  229] train: loss: 0.1449588
[Epoch 32] ogbg-moltoxcast: 0.736131 val loss: 0.198185
[Epoch 32] ogbg-moltoxcast: 0.745916 test loss: 0.446495
[Epoch 33; Iter    22/  229] train: loss: 0.1877566
[Epoch 33; Iter    52/  229] train: loss: 0.2608408
[Epoch 33; Iter    82/  229] train: loss: 0.1741638
[Epoch 33; Iter   112/  229] train: loss: 0.1626807
[Epoch 33; Iter   142/  229] train: loss: 0.1366978
[Epoch 33; Iter   172/  229] train: loss: 0.2245759
[Epoch 33; Iter   202/  229] train: loss: 0.1705458
[Epoch 33] ogbg-moltoxcast: 0.735942 val loss: 0.235598
[Epoch 33] ogbg-moltoxcast: 0.750584 test loss: 1.523526
[Epoch 34; Iter     3/  229] train: loss: 0.2286361
[Epoch 34; Iter    33/  229] train: loss: 0.1512554
[Epoch 34; Iter    63/  229] train: loss: 0.1870361
[Epoch 34; Iter    93/  229] train: loss: 0.2819723
[Epoch 34; Iter   123/  229] train: loss: 0.1658959
[Epoch 34; Iter   153/  229] train: loss: 0.2117893
[Epoch 34; Iter   183/  229] train: loss: 0.1627639
[Epoch 34; Iter   213/  229] train: loss: 0.1995351
[Epoch 34] ogbg-moltoxcast: 0.730632 val loss: 0.200596
[Epoch 34] ogbg-moltoxcast: 0.748943 test loss: 0.217785
[Epoch 35; Iter    14/  229] train: loss: 0.1768680
[Epoch 35; Iter    44/  229] train: loss: 0.1646689
[Epoch 35; Iter    74/  229] train: loss: 0.2540756
[Epoch 35; Iter   104/  229] train: loss: 0.2115335
[Epoch 35; Iter   134/  229] train: loss: 0.1913438
[Epoch 35; Iter   164/  229] train: loss: 0.1441572
[Epoch 35; Iter   194/  229] train: loss: 0.1677274
[Epoch 35; Iter   224/  229] train: loss: 0.2621931
[Epoch 35] ogbg-moltoxcast: 0.734631 val loss: 0.195903
[Epoch 35] ogbg-moltoxcast: 0.757863 test loss: 0.228866
[Epoch 36; Iter    25/  229] train: loss: 0.2081847
[Epoch 36; Iter    55/  229] train: loss: 0.1197679
[Epoch 36; Iter    85/  229] train: loss: 0.0947201
[Epoch 36; Iter   115/  229] train: loss: 0.1802484
[Epoch 36; Iter   145/  229] train: loss: 0.2117266
[Epoch 36; Iter   175/  229] train: loss: 0.1514961
[Epoch 36; Iter   205/  229] train: loss: 0.1501104
[Epoch 36] ogbg-moltoxcast: 0.742248 val loss: 0.195458
[Epoch 36] ogbg-moltoxcast: 0.759347 test loss: 0.305461
[Epoch 37; Iter     6/  229] train: loss: 0.1186527
[Epoch 37; Iter    36/  229] train: loss: 0.2532912
[Epoch 37; Iter    66/  229] train: loss: 0.1766654
[Epoch 37; Iter    96/  229] train: loss: 0.2137905
[Epoch 37; Iter   126/  229] train: loss: 0.1473817
[Epoch 37; Iter   156/  229] train: loss: 0.1537236
[Epoch 37; Iter   186/  229] train: loss: 0.1439167
[Epoch 37; Iter   216/  229] train: loss: 0.2321978
[Epoch 37] ogbg-moltoxcast: 0.733303 val loss: 0.198238
[Epoch 37] ogbg-moltoxcast: 0.756340 test loss: 0.311370
[Epoch 38; Iter    17/  229] train: loss: 0.1241342
[Epoch 38; Iter    47/  229] train: loss: 0.1454528
[Epoch 38; Iter    77/  229] train: loss: 0.1386342
[Epoch 38; Iter   107/  229] train: loss: 0.1131163
[Epoch 38; Iter   137/  229] train: loss: 0.1745511
[Epoch 38; Iter   167/  229] train: loss: 0.1626976
[Epoch 38; Iter   197/  229] train: loss: 0.2387986
[Epoch 38; Iter   227/  229] train: loss: 0.1691026
[Epoch 38] ogbg-moltoxcast: 0.735502 val loss: 0.198018
[Epoch 38] ogbg-moltoxcast: 0.756685 test loss: 0.279796
[Epoch 39; Iter    28/  229] train: loss: 0.1715369
[Epoch 39; Iter    58/  229] train: loss: 0.1460740
[Epoch 39; Iter    88/  229] train: loss: 0.1076755
[Epoch 39; Iter   118/  229] train: loss: 0.1060065
[Epoch 39; Iter   148/  229] train: loss: 0.2335870
[Epoch 39; Iter   178/  229] train: loss: 0.2243698
[Epoch 39; Iter   208/  229] train: loss: 0.1787590
[Epoch 39] ogbg-moltoxcast: 0.741690 val loss: 0.196954
[Epoch 39] ogbg-moltoxcast: 0.752399 test loss: 0.441564
[Epoch 40; Iter     9/  229] train: loss: 0.1671408
[Epoch 40; Iter    39/  229] train: loss: 0.1633365
[Epoch 40; Iter    69/  229] train: loss: 0.1578795
[Epoch 40; Iter    99/  229] train: loss: 0.1466681
[Epoch 40; Iter   129/  229] train: loss: 0.2161595
[Epoch 40; Iter   159/  229] train: loss: 0.1676844
[Epoch 40; Iter   189/  229] train: loss: 0.1400029
[Epoch 40; Iter   219/  229] train: loss: 0.1652873
[Epoch 40] ogbg-moltoxcast: 0.747946 val loss: 0.196536
[Epoch 40] ogbg-moltoxcast: 0.759253 test loss: 0.357618
[Epoch 41; Iter    20/  229] train: loss: 0.1648683
[Epoch 41; Iter    50/  229] train: loss: 0.1644146
[Epoch 41; Iter    80/  229] train: loss: 0.2092437
[Epoch 41; Iter   110/  229] train: loss: 0.1649299
[Epoch 41; Iter   140/  229] train: loss: 0.1616789
[Epoch 41; Iter   170/  229] train: loss: 0.2184745
[Epoch 41; Iter   200/  229] train: loss: 0.1977209
[Epoch 41] ogbg-moltoxcast: 0.745488 val loss: 0.195849
[Epoch 41] ogbg-moltoxcast: 0.758670 test loss: 0.200197
[Epoch 42; Iter     1/  229] train: loss: 0.1340258
[Epoch 42; Iter    31/  229] train: loss: 0.1755177
[Epoch 42; Iter    61/  229] train: loss: 0.1803799
[Epoch 42; Iter    91/  229] train: loss: 0.1627167
[Epoch 42; Iter   121/  229] train: loss: 0.1657544
[Epoch 42; Iter   151/  229] train: loss: 0.1583464
[Epoch 42; Iter   181/  229] train: loss: 0.1737589
[Epoch 42; Iter   211/  229] train: loss: 0.1388235
[Epoch 42] ogbg-moltoxcast: 0.739035 val loss: 0.198745
[Epoch 42] ogbg-moltoxcast: 0.758509 test loss: 0.202313
[Epoch 43; Iter    12/  229] train: loss: 0.1496245
[Epoch 43; Iter    42/  229] train: loss: 0.2581950
[Epoch 43; Iter    72/  229] train: loss: 0.1585494
[Epoch 43; Iter   102/  229] train: loss: 0.1480923
[Epoch 43; Iter   132/  229] train: loss: 0.1187230
[Epoch 43; Iter   162/  229] train: loss: 0.1266591
[Epoch 43; Iter   192/  229] train: loss: 0.1898727
[Epoch 43; Iter   222/  229] train: loss: 0.2311214
[Epoch 43] ogbg-moltoxcast: 0.745258 val loss: 0.198387
[Epoch 43] ogbg-moltoxcast: 0.759046 test loss: 0.202672
[Epoch 28; Iter    27/  229] train: loss: 0.2127663
[Epoch 28; Iter    57/  229] train: loss: 0.1255140
[Epoch 28; Iter    87/  229] train: loss: 0.1291467
[Epoch 28; Iter   117/  229] train: loss: 0.1978515
[Epoch 28; Iter   147/  229] train: loss: 0.1850632
[Epoch 28; Iter   177/  229] train: loss: 0.1096625
[Epoch 28; Iter   207/  229] train: loss: 0.1888030
[Epoch 28] ogbg-moltoxcast: 0.731283 val loss: 0.215397
[Epoch 28] ogbg-moltoxcast: 0.753341 test loss: 0.205098
[Epoch 29; Iter     8/  229] train: loss: 0.1652751
[Epoch 29; Iter    38/  229] train: loss: 0.1218608
[Epoch 29; Iter    68/  229] train: loss: 0.2154730
[Epoch 29; Iter    98/  229] train: loss: 0.1866601
[Epoch 29; Iter   128/  229] train: loss: 0.2683945
[Epoch 29; Iter   158/  229] train: loss: 0.1932657
[Epoch 29; Iter   188/  229] train: loss: 0.2025533
[Epoch 29; Iter   218/  229] train: loss: 0.1731383
[Epoch 29] ogbg-moltoxcast: 0.729908 val loss: 0.199573
[Epoch 29] ogbg-moltoxcast: 0.755966 test loss: 0.205828
[Epoch 30; Iter    19/  229] train: loss: 0.1794129
[Epoch 30; Iter    49/  229] train: loss: 0.2003617
[Epoch 30; Iter    79/  229] train: loss: 0.1762704
[Epoch 30; Iter   109/  229] train: loss: 0.1426648
[Epoch 30; Iter   139/  229] train: loss: 0.2490603
[Epoch 30; Iter   169/  229] train: loss: 0.1321531
[Epoch 30; Iter   199/  229] train: loss: 0.1557234
[Epoch 30; Iter   229/  229] train: loss: 0.2226964
[Epoch 30] ogbg-moltoxcast: 0.721067 val loss: 0.199843
[Epoch 30] ogbg-moltoxcast: 0.751555 test loss: 0.206927
[Epoch 31; Iter    30/  229] train: loss: 0.1653420
[Epoch 31; Iter    60/  229] train: loss: 0.1541993
[Epoch 31; Iter    90/  229] train: loss: 0.1138005
[Epoch 31; Iter   120/  229] train: loss: 0.2050352
[Epoch 31; Iter   150/  229] train: loss: 0.1936467
[Epoch 31; Iter   180/  229] train: loss: 0.1880622
[Epoch 31; Iter   210/  229] train: loss: 0.1957678
[Epoch 31] ogbg-moltoxcast: 0.724845 val loss: 0.202718
[Epoch 31] ogbg-moltoxcast: 0.764969 test loss: 0.202398
[Epoch 32; Iter    11/  229] train: loss: 0.1549011
[Epoch 32; Iter    41/  229] train: loss: 0.1511907
[Epoch 32; Iter    71/  229] train: loss: 0.1423492
[Epoch 32; Iter   101/  229] train: loss: 0.2596382
[Epoch 32; Iter   131/  229] train: loss: 0.1904281
[Epoch 32; Iter   161/  229] train: loss: 0.2136317
[Epoch 32; Iter   191/  229] train: loss: 0.2250484
[Epoch 32; Iter   221/  229] train: loss: 0.1769941
[Epoch 32] ogbg-moltoxcast: 0.729511 val loss: 0.197342
[Epoch 32] ogbg-moltoxcast: 0.755988 test loss: 0.203559
[Epoch 33; Iter    22/  229] train: loss: 0.1370259
[Epoch 33; Iter    52/  229] train: loss: 0.1360061
[Epoch 33; Iter    82/  229] train: loss: 0.1496347
[Epoch 33; Iter   112/  229] train: loss: 0.1692010
[Epoch 33; Iter   142/  229] train: loss: 0.1798818
[Epoch 33; Iter   172/  229] train: loss: 0.2378392
[Epoch 33; Iter   202/  229] train: loss: 0.1591646
[Epoch 33] ogbg-moltoxcast: 0.724199 val loss: 0.198371
[Epoch 33] ogbg-moltoxcast: 0.757787 test loss: 0.204549
[Epoch 34; Iter     3/  229] train: loss: 0.1392750
[Epoch 34; Iter    33/  229] train: loss: 0.1408487
[Epoch 34; Iter    63/  229] train: loss: 0.1660178
[Epoch 34; Iter    93/  229] train: loss: 0.1330367
[Epoch 34; Iter   123/  229] train: loss: 0.2204846
[Epoch 34; Iter   153/  229] train: loss: 0.1265087
[Epoch 34; Iter   183/  229] train: loss: 0.1158272
[Epoch 34; Iter   213/  229] train: loss: 0.1288537
[Epoch 34] ogbg-moltoxcast: 0.724888 val loss: 0.200209
[Epoch 34] ogbg-moltoxcast: 0.757774 test loss: 0.207222
[Epoch 35; Iter    14/  229] train: loss: 0.2259644
[Epoch 35; Iter    44/  229] train: loss: 0.1648057
[Epoch 35; Iter    74/  229] train: loss: 0.1636627
[Epoch 35; Iter   104/  229] train: loss: 0.2025448
[Epoch 35; Iter   134/  229] train: loss: 0.2168952
[Epoch 35; Iter   164/  229] train: loss: 0.1570362
[Epoch 35; Iter   194/  229] train: loss: 0.1247595
[Epoch 35; Iter   224/  229] train: loss: 0.1984964
[Epoch 35] ogbg-moltoxcast: 0.731032 val loss: 0.196623
[Epoch 35] ogbg-moltoxcast: 0.757196 test loss: 0.203903
[Epoch 36; Iter    25/  229] train: loss: 0.1696309
[Epoch 36; Iter    55/  229] train: loss: 0.1361817
[Epoch 36; Iter    85/  229] train: loss: 0.1207179
[Epoch 36; Iter   115/  229] train: loss: 0.1376428
[Epoch 36; Iter   145/  229] train: loss: 0.2004141
[Epoch 36; Iter   175/  229] train: loss: 0.1723331
[Epoch 36; Iter   205/  229] train: loss: 0.1781712
[Epoch 36] ogbg-moltoxcast: 0.727101 val loss: 0.198632
[Epoch 36] ogbg-moltoxcast: 0.747052 test loss: 0.207314
[Epoch 37; Iter     6/  229] train: loss: 0.1530864
[Epoch 37; Iter    36/  229] train: loss: 0.1702627
[Epoch 37; Iter    66/  229] train: loss: 0.1259359
[Epoch 37; Iter    96/  229] train: loss: 0.2360634
[Epoch 37; Iter   126/  229] train: loss: 0.1874356
[Epoch 37; Iter   156/  229] train: loss: 0.1890467
[Epoch 37; Iter   186/  229] train: loss: 0.2114528
[Epoch 37; Iter   216/  229] train: loss: 0.1533397
[Epoch 37] ogbg-moltoxcast: 0.731033 val loss: 0.196076
[Epoch 37] ogbg-moltoxcast: 0.758626 test loss: 0.201606
[Epoch 38; Iter    17/  229] train: loss: 0.1605646
[Epoch 38; Iter    47/  229] train: loss: 0.2032749
[Epoch 38; Iter    77/  229] train: loss: 0.1660630
[Epoch 38; Iter   107/  229] train: loss: 0.1791915
[Epoch 38; Iter   137/  229] train: loss: 0.1394231
[Epoch 38; Iter   167/  229] train: loss: 0.1503756
[Epoch 38; Iter   197/  229] train: loss: 0.1437769
[Epoch 38; Iter   227/  229] train: loss: 0.2125070
[Epoch 38] ogbg-moltoxcast: 0.729146 val loss: 0.200913
[Epoch 38] ogbg-moltoxcast: 0.757616 test loss: 0.202765
[Epoch 39; Iter    28/  229] train: loss: 0.1600755
[Epoch 39; Iter    58/  229] train: loss: 0.1447024
[Epoch 39; Iter    88/  229] train: loss: 0.1423126
[Epoch 39; Iter   118/  229] train: loss: 0.1748162
[Epoch 39; Iter   148/  229] train: loss: 0.2295337
[Epoch 39; Iter   178/  229] train: loss: 0.1049619
[Epoch 39; Iter   208/  229] train: loss: 0.1094958
[Epoch 39] ogbg-moltoxcast: 0.731465 val loss: 0.197777
[Epoch 39] ogbg-moltoxcast: 0.759259 test loss: 0.199334
[Epoch 40; Iter     9/  229] train: loss: 0.1817829
[Epoch 40; Iter    39/  229] train: loss: 0.1934987
[Epoch 40; Iter    69/  229] train: loss: 0.1070184
[Epoch 40; Iter    99/  229] train: loss: 0.1449603
[Epoch 40; Iter   129/  229] train: loss: 0.1541025
[Epoch 40; Iter   159/  229] train: loss: 0.1864148
[Epoch 40; Iter   189/  229] train: loss: 0.1627392
[Epoch 40; Iter   219/  229] train: loss: 0.1525138
[Epoch 40] ogbg-moltoxcast: 0.735839 val loss: 0.198693
[Epoch 40] ogbg-moltoxcast: 0.761343 test loss: 0.201534
[Epoch 41; Iter    20/  229] train: loss: 0.1254456
[Epoch 41; Iter    50/  229] train: loss: 0.1618850
[Epoch 41; Iter    80/  229] train: loss: 0.1741582
[Epoch 41; Iter   110/  229] train: loss: 0.1510274
[Epoch 41; Iter   140/  229] train: loss: 0.1652082
[Epoch 41; Iter   170/  229] train: loss: 0.1493787
[Epoch 41; Iter   200/  229] train: loss: 0.2084375
[Epoch 41] ogbg-moltoxcast: 0.733986 val loss: 0.196784
[Epoch 41] ogbg-moltoxcast: 0.755670 test loss: 0.201774
[Epoch 42; Iter     1/  229] train: loss: 0.1684144
[Epoch 42; Iter    31/  229] train: loss: 0.2012952
[Epoch 42; Iter    61/  229] train: loss: 0.1262706
[Epoch 42; Iter    91/  229] train: loss: 0.1704622
[Epoch 42; Iter   121/  229] train: loss: 0.1613970
[Epoch 42; Iter   151/  229] train: loss: 0.1210962
[Epoch 42; Iter   181/  229] train: loss: 0.1636882
[Epoch 42; Iter   211/  229] train: loss: 0.2417179
[Epoch 42] ogbg-moltoxcast: 0.735958 val loss: 0.195088
[Epoch 42] ogbg-moltoxcast: 0.758471 test loss: 0.202113
[Epoch 43; Iter    12/  229] train: loss: 0.1586571
[Epoch 43; Iter    42/  229] train: loss: 0.1790731
[Epoch 43; Iter    72/  229] train: loss: 0.1216037
[Epoch 43; Iter   102/  229] train: loss: 0.1577000
[Epoch 43; Iter   132/  229] train: loss: 0.1318817
[Epoch 43; Iter   162/  229] train: loss: 0.1123878
[Epoch 43; Iter   192/  229] train: loss: 0.1619749
[Epoch 43; Iter   222/  229] train: loss: 0.1156855
[Epoch 43] ogbg-moltoxcast: 0.736708 val loss: 0.196282
[Epoch 43] ogbg-moltoxcast: 0.757572 test loss: 0.200982
[Epoch 28; Iter    27/  229] train: loss: 0.2422730
[Epoch 28; Iter    57/  229] train: loss: 0.1993684
[Epoch 28; Iter    87/  229] train: loss: 0.1140757
[Epoch 28; Iter   117/  229] train: loss: 0.1951390
[Epoch 28; Iter   147/  229] train: loss: 0.1373012
[Epoch 28; Iter   177/  229] train: loss: 0.1735375
[Epoch 28; Iter   207/  229] train: loss: 0.1966203
[Epoch 28] ogbg-moltoxcast: 0.730882 val loss: 0.194932
[Epoch 28] ogbg-moltoxcast: 0.746011 test loss: 0.207689
[Epoch 29; Iter     8/  229] train: loss: 0.1840849
[Epoch 29; Iter    38/  229] train: loss: 0.1239563
[Epoch 29; Iter    68/  229] train: loss: 0.2253812
[Epoch 29; Iter    98/  229] train: loss: 0.1577554
[Epoch 29; Iter   128/  229] train: loss: 0.1785646
[Epoch 29; Iter   158/  229] train: loss: 0.1885130
[Epoch 29; Iter   188/  229] train: loss: 0.1814482
[Epoch 29; Iter   218/  229] train: loss: 0.1969434
[Epoch 29] ogbg-moltoxcast: 0.745783 val loss: 0.190281
[Epoch 29] ogbg-moltoxcast: 0.756901 test loss: 0.205359
[Epoch 30; Iter    19/  229] train: loss: 0.1712715
[Epoch 30; Iter    49/  229] train: loss: 0.1809334
[Epoch 30; Iter    79/  229] train: loss: 0.2016968
[Epoch 30; Iter   109/  229] train: loss: 0.2123894
[Epoch 30; Iter   139/  229] train: loss: 0.1799547
[Epoch 30; Iter   169/  229] train: loss: 0.1517545
[Epoch 30; Iter   199/  229] train: loss: 0.1276166
[Epoch 30; Iter   229/  229] train: loss: 0.1775587
[Epoch 30] ogbg-moltoxcast: 0.736588 val loss: 0.196465
[Epoch 30] ogbg-moltoxcast: 0.754509 test loss: 0.206659
[Epoch 31; Iter    30/  229] train: loss: 0.1884251
[Epoch 31; Iter    60/  229] train: loss: 0.1373395
[Epoch 31; Iter    90/  229] train: loss: 0.1914184
[Epoch 31; Iter   120/  229] train: loss: 0.1412369
[Epoch 31; Iter   150/  229] train: loss: 0.1236268
[Epoch 31; Iter   180/  229] train: loss: 0.1532807
[Epoch 31; Iter   210/  229] train: loss: 0.1833080
[Epoch 31] ogbg-moltoxcast: 0.730339 val loss: 0.196834
[Epoch 31] ogbg-moltoxcast: 0.760564 test loss: 0.204258
[Epoch 32; Iter    11/  229] train: loss: 0.1650931
[Epoch 32; Iter    41/  229] train: loss: 0.2002448
[Epoch 32; Iter    71/  229] train: loss: 0.1658281
[Epoch 32; Iter   101/  229] train: loss: 0.1379390
[Epoch 32; Iter   131/  229] train: loss: 0.1708413
[Epoch 32; Iter   161/  229] train: loss: 0.1520410
[Epoch 32; Iter   191/  229] train: loss: 0.1162381
[Epoch 32; Iter   221/  229] train: loss: 0.2267420
[Epoch 32] ogbg-moltoxcast: 0.741756 val loss: 0.191855
[Epoch 32] ogbg-moltoxcast: 0.759051 test loss: 0.203946
[Epoch 33; Iter    22/  229] train: loss: 0.2331300
[Epoch 33; Iter    52/  229] train: loss: 0.1839464
[Epoch 33; Iter    82/  229] train: loss: 0.1375375
[Epoch 33; Iter   112/  229] train: loss: 0.2616702
[Epoch 33; Iter   142/  229] train: loss: 0.2445351
[Epoch 33; Iter   172/  229] train: loss: 0.1675438
[Epoch 33; Iter   202/  229] train: loss: 0.1941721
[Epoch 33] ogbg-moltoxcast: 0.733141 val loss: 0.196283
[Epoch 33] ogbg-moltoxcast: 0.749247 test loss: 0.210369
[Epoch 34; Iter     3/  229] train: loss: 0.1519110
[Epoch 34; Iter    33/  229] train: loss: 0.1546819
[Epoch 34; Iter    63/  229] train: loss: 0.1836356
[Epoch 34; Iter    93/  229] train: loss: 0.1691896
[Epoch 34; Iter   123/  229] train: loss: 0.2065261
[Epoch 34; Iter   153/  229] train: loss: 0.1652986
[Epoch 34; Iter   183/  229] train: loss: 0.1475337
[Epoch 34; Iter   213/  229] train: loss: 0.1579165
[Epoch 34] ogbg-moltoxcast: 0.744927 val loss: 0.193321
[Epoch 34] ogbg-moltoxcast: 0.749785 test loss: 0.207259
[Epoch 35; Iter    14/  229] train: loss: 0.2308310
[Epoch 35; Iter    44/  229] train: loss: 0.1929740
[Epoch 35; Iter    74/  229] train: loss: 0.1403067
[Epoch 35; Iter   104/  229] train: loss: 0.1412594
[Epoch 35; Iter   134/  229] train: loss: 0.2325300
[Epoch 35; Iter   164/  229] train: loss: 0.1048234
[Epoch 35; Iter   194/  229] train: loss: 0.1515970
[Epoch 35; Iter   224/  229] train: loss: 0.1514225
[Epoch 35] ogbg-moltoxcast: 0.748252 val loss: 0.189952
[Epoch 35] ogbg-moltoxcast: 0.761353 test loss: 0.202416
[Epoch 36; Iter    25/  229] train: loss: 0.1566558
[Epoch 36; Iter    55/  229] train: loss: 0.1638642
[Epoch 36; Iter    85/  229] train: loss: 0.2030458
[Epoch 36; Iter   115/  229] train: loss: 0.1486221
[Epoch 36; Iter   145/  229] train: loss: 0.1442548
[Epoch 36; Iter   175/  229] train: loss: 0.1481417
[Epoch 36; Iter   205/  229] train: loss: 0.1346944
[Epoch 36] ogbg-moltoxcast: 0.747802 val loss: 0.192777
[Epoch 36] ogbg-moltoxcast: 0.760761 test loss: 0.202410
[Epoch 37; Iter     6/  229] train: loss: 0.2066573
[Epoch 37; Iter    36/  229] train: loss: 0.1546903
[Epoch 37; Iter    66/  229] train: loss: 0.2088918
[Epoch 37; Iter    96/  229] train: loss: 0.1529267
[Epoch 37; Iter   126/  229] train: loss: 0.1304070
[Epoch 37; Iter   156/  229] train: loss: 0.1541220
[Epoch 37; Iter   186/  229] train: loss: 0.2335742
[Epoch 37; Iter   216/  229] train: loss: 0.1344127
[Epoch 37] ogbg-moltoxcast: 0.747506 val loss: 0.191095
[Epoch 37] ogbg-moltoxcast: 0.754302 test loss: 0.206249
[Epoch 38; Iter    17/  229] train: loss: 0.1395091
[Epoch 38; Iter    47/  229] train: loss: 0.1104830
[Epoch 38; Iter    77/  229] train: loss: 0.1756306
[Epoch 38; Iter   107/  229] train: loss: 0.1773608
[Epoch 38; Iter   137/  229] train: loss: 0.1887656
[Epoch 38; Iter   167/  229] train: loss: 0.1627427
[Epoch 38; Iter   197/  229] train: loss: 0.1761935
[Epoch 38; Iter   227/  229] train: loss: 0.1944436
[Epoch 38] ogbg-moltoxcast: 0.737993 val loss: 0.193173
[Epoch 38] ogbg-moltoxcast: 0.755509 test loss: 0.209136
[Epoch 39; Iter    28/  229] train: loss: 0.1464573
[Epoch 39; Iter    58/  229] train: loss: 0.1610979
[Epoch 39; Iter    88/  229] train: loss: 0.2261866
[Epoch 39; Iter   118/  229] train: loss: 0.1499975
[Epoch 39; Iter   148/  229] train: loss: 0.2207118
[Epoch 39; Iter   178/  229] train: loss: 0.1507211
[Epoch 39; Iter   208/  229] train: loss: 0.2311397
[Epoch 39] ogbg-moltoxcast: 0.741769 val loss: 0.191730
[Epoch 39] ogbg-moltoxcast: 0.747630 test loss: 0.209830
[Epoch 40; Iter     9/  229] train: loss: 0.1739608
[Epoch 40; Iter    39/  229] train: loss: 0.1672659
[Epoch 40; Iter    69/  229] train: loss: 0.1906012
[Epoch 40; Iter    99/  229] train: loss: 0.1509822
[Epoch 40; Iter   129/  229] train: loss: 0.1511960
[Epoch 40; Iter   159/  229] train: loss: 0.1428861
[Epoch 40; Iter   189/  229] train: loss: 0.2124402
[Epoch 40; Iter   219/  229] train: loss: 0.1385353
[Epoch 40] ogbg-moltoxcast: 0.748606 val loss: 0.190606
[Epoch 40] ogbg-moltoxcast: 0.760155 test loss: 0.203739
[Epoch 41; Iter    20/  229] train: loss: 0.1997748
[Epoch 41; Iter    50/  229] train: loss: 0.1759314
[Epoch 41; Iter    80/  229] train: loss: 0.2059616
[Epoch 41; Iter   110/  229] train: loss: 0.1294874
[Epoch 41; Iter   140/  229] train: loss: 0.1462644
[Epoch 41; Iter   170/  229] train: loss: 0.1478411
[Epoch 41; Iter   200/  229] train: loss: 0.1662244
[Epoch 41] ogbg-moltoxcast: 0.742349 val loss: 0.190379
[Epoch 41] ogbg-moltoxcast: 0.762592 test loss: 0.202848
[Epoch 42; Iter     1/  229] train: loss: 0.2148886
[Epoch 42; Iter    31/  229] train: loss: 0.1970213
[Epoch 42; Iter    61/  229] train: loss: 0.1324862
[Epoch 42; Iter    91/  229] train: loss: 0.1141827
[Epoch 42; Iter   121/  229] train: loss: 0.1780706
[Epoch 42; Iter   151/  229] train: loss: 0.1912315
[Epoch 42; Iter   181/  229] train: loss: 0.2198225
[Epoch 42; Iter   211/  229] train: loss: 0.1523049
[Epoch 42] ogbg-moltoxcast: 0.736761 val loss: 0.194906
[Epoch 42] ogbg-moltoxcast: 0.755615 test loss: 0.205371
[Epoch 43; Iter    12/  229] train: loss: 0.1050321
[Epoch 43; Iter    42/  229] train: loss: 0.1521601
[Epoch 43; Iter    72/  229] train: loss: 0.1179844
[Epoch 43; Iter   102/  229] train: loss: 0.1464220
[Epoch 43; Iter   132/  229] train: loss: 0.1956276
[Epoch 43; Iter   162/  229] train: loss: 0.2341022
[Epoch 43; Iter   192/  229] train: loss: 0.2005009
[Epoch 43; Iter   222/  229] train: loss: 0.0997069
[Epoch 43] ogbg-moltoxcast: 0.740156 val loss: 0.190479
[Epoch 43] ogbg-moltoxcast: 0.764899 test loss: 0.201865
[Epoch 30] ogbg-moltoxcast: 0.736416 test loss: 0.228028
[Epoch 31; Iter    30/  201] train: loss: 0.1509456
[Epoch 31; Iter    60/  201] train: loss: 0.1590540
[Epoch 31; Iter    90/  201] train: loss: 0.1779669
[Epoch 31; Iter   120/  201] train: loss: 0.2369894
[Epoch 31; Iter   150/  201] train: loss: 0.1475732
[Epoch 31; Iter   180/  201] train: loss: 0.1727136
[Epoch 31] ogbg-moltoxcast: 0.720593 val loss: 0.207722
[Epoch 31] ogbg-moltoxcast: 0.735732 test loss: 0.207314
[Epoch 32; Iter     9/  201] train: loss: 0.1233396
[Epoch 32; Iter    39/  201] train: loss: 0.2059111
[Epoch 32; Iter    69/  201] train: loss: 0.2071086
[Epoch 32; Iter    99/  201] train: loss: 0.1464341
[Epoch 32; Iter   129/  201] train: loss: 0.1597711
[Epoch 32; Iter   159/  201] train: loss: 0.1919696
[Epoch 32; Iter   189/  201] train: loss: 0.1390729
[Epoch 32] ogbg-moltoxcast: 0.727761 val loss: 0.205968
[Epoch 32] ogbg-moltoxcast: 0.738179 test loss: 0.228518
[Epoch 33; Iter    18/  201] train: loss: 0.2036736
[Epoch 33; Iter    48/  201] train: loss: 0.1738280
[Epoch 33; Iter    78/  201] train: loss: 0.1681643
[Epoch 33; Iter   108/  201] train: loss: 0.1844304
[Epoch 33; Iter   138/  201] train: loss: 0.1459120
[Epoch 33; Iter   168/  201] train: loss: 0.1770225
[Epoch 33; Iter   198/  201] train: loss: 0.1985956
[Epoch 33] ogbg-moltoxcast: 0.733880 val loss: 0.201458
[Epoch 33] ogbg-moltoxcast: 0.742538 test loss: 0.202998
[Epoch 34; Iter    27/  201] train: loss: 0.1608162
[Epoch 34; Iter    57/  201] train: loss: 0.1384193
[Epoch 34; Iter    87/  201] train: loss: 0.1310191
[Epoch 34; Iter   117/  201] train: loss: 0.2230035
[Epoch 34; Iter   147/  201] train: loss: 0.1260434
[Epoch 34; Iter   177/  201] train: loss: 0.2227254
[Epoch 34] ogbg-moltoxcast: 0.733220 val loss: 0.202672
[Epoch 34] ogbg-moltoxcast: 0.738209 test loss: 0.205041
[Epoch 35; Iter     6/  201] train: loss: 0.1750167
[Epoch 35; Iter    36/  201] train: loss: 0.1835099
[Epoch 35; Iter    66/  201] train: loss: 0.1174087
[Epoch 35; Iter    96/  201] train: loss: 0.1883553
[Epoch 35; Iter   126/  201] train: loss: 0.1344582
[Epoch 35; Iter   156/  201] train: loss: 0.2024055
[Epoch 35; Iter   186/  201] train: loss: 0.1879781
[Epoch 35] ogbg-moltoxcast: 0.731076 val loss: 0.203311
[Epoch 35] ogbg-moltoxcast: 0.748252 test loss: 0.205474
[Epoch 36; Iter    15/  201] train: loss: 0.1263620
[Epoch 36; Iter    45/  201] train: loss: 0.1830998
[Epoch 36; Iter    75/  201] train: loss: 0.1238864
[Epoch 36; Iter   105/  201] train: loss: 0.1378006
[Epoch 36; Iter   135/  201] train: loss: 0.1770218
[Epoch 36; Iter   165/  201] train: loss: 0.1324226
[Epoch 36; Iter   195/  201] train: loss: 0.1505510
[Epoch 36] ogbg-moltoxcast: 0.737196 val loss: 0.201464
[Epoch 36] ogbg-moltoxcast: 0.755969 test loss: 0.199737
[Epoch 37; Iter    24/  201] train: loss: 0.1345279
[Epoch 37; Iter    54/  201] train: loss: 0.1540957
[Epoch 37; Iter    84/  201] train: loss: 0.2015930
[Epoch 37; Iter   114/  201] train: loss: 0.1393847
[Epoch 37; Iter   144/  201] train: loss: 0.1355244
[Epoch 37; Iter   174/  201] train: loss: 0.1281988
[Epoch 37] ogbg-moltoxcast: 0.737172 val loss: 0.199681
[Epoch 37] ogbg-moltoxcast: 0.751406 test loss: 0.202324
[Epoch 38; Iter     3/  201] train: loss: 0.1922572
[Epoch 38; Iter    33/  201] train: loss: 0.1428797
[Epoch 38; Iter    63/  201] train: loss: 0.1723645
[Epoch 38; Iter    93/  201] train: loss: 0.0823004
[Epoch 38; Iter   123/  201] train: loss: 0.2444250
[Epoch 38; Iter   153/  201] train: loss: 0.1054447
[Epoch 38; Iter   183/  201] train: loss: 0.1200754
[Epoch 38] ogbg-moltoxcast: 0.736958 val loss: 0.200603
[Epoch 38] ogbg-moltoxcast: 0.751901 test loss: 0.201863
[Epoch 39; Iter    12/  201] train: loss: 0.2601642
[Epoch 39; Iter    42/  201] train: loss: 0.1717661
[Epoch 39; Iter    72/  201] train: loss: 0.1458331
[Epoch 39; Iter   102/  201] train: loss: 0.1632679
[Epoch 39; Iter   132/  201] train: loss: 0.1393862
[Epoch 39; Iter   162/  201] train: loss: 0.2073005
[Epoch 39; Iter   192/  201] train: loss: 0.1658301
[Epoch 39] ogbg-moltoxcast: 0.735328 val loss: 0.202834
[Epoch 39] ogbg-moltoxcast: 0.748560 test loss: 0.202402
[Epoch 40; Iter    21/  201] train: loss: 0.1274677
[Epoch 40; Iter    51/  201] train: loss: 0.1492390
[Epoch 40; Iter    81/  201] train: loss: 0.1707962
[Epoch 40; Iter   111/  201] train: loss: 0.1392814
[Epoch 40; Iter   141/  201] train: loss: 0.1423225
[Epoch 40; Iter   171/  201] train: loss: 0.1702867
[Epoch 40; Iter   201/  201] train: loss: 0.0756970
[Epoch 40] ogbg-moltoxcast: 0.735637 val loss: 0.202416
[Epoch 40] ogbg-moltoxcast: 0.748400 test loss: 0.201123
[Epoch 41; Iter    30/  201] train: loss: 0.1851347
[Epoch 41; Iter    60/  201] train: loss: 0.2718864
[Epoch 41; Iter    90/  201] train: loss: 0.1588491
[Epoch 41; Iter   120/  201] train: loss: 0.1637131
[Epoch 41; Iter   150/  201] train: loss: 0.0955709
[Epoch 41; Iter   180/  201] train: loss: 0.1920281
[Epoch 41] ogbg-moltoxcast: 0.733493 val loss: 0.203372
[Epoch 41] ogbg-moltoxcast: 0.746680 test loss: 0.202794
[Epoch 42; Iter     9/  201] train: loss: 0.1642955
[Epoch 42; Iter    39/  201] train: loss: 0.1548948
[Epoch 42; Iter    69/  201] train: loss: 0.1608844
[Epoch 42; Iter    99/  201] train: loss: 0.1716748
[Epoch 42; Iter   129/  201] train: loss: 0.1787657
[Epoch 42; Iter   159/  201] train: loss: 0.2201231
[Epoch 42; Iter   189/  201] train: loss: 0.1571414
[Epoch 42] ogbg-moltoxcast: 0.739374 val loss: 0.202221
[Epoch 42] ogbg-moltoxcast: 0.753160 test loss: 0.203401
[Epoch 43; Iter    18/  201] train: loss: 0.1695007
[Epoch 43; Iter    48/  201] train: loss: 0.2425944
[Epoch 43; Iter    78/  201] train: loss: 0.1234916
[Epoch 43; Iter   108/  201] train: loss: 0.1782673
[Epoch 43; Iter   138/  201] train: loss: 0.2024359
[Epoch 43; Iter   168/  201] train: loss: 0.1495809
[Epoch 43; Iter   198/  201] train: loss: 0.1719968
[Epoch 43] ogbg-moltoxcast: 0.739176 val loss: 0.203790
[Epoch 43] ogbg-moltoxcast: 0.749972 test loss: 0.204087
[Epoch 44; Iter    27/  201] train: loss: 0.1311397
[Epoch 44; Iter    57/  201] train: loss: 0.1413205
[Epoch 44; Iter    87/  201] train: loss: 0.1873772
[Epoch 44; Iter   117/  201] train: loss: 0.1049773
[Epoch 44; Iter   147/  201] train: loss: 0.0786343
[Epoch 44; Iter   177/  201] train: loss: 0.1968332
[Epoch 44] ogbg-moltoxcast: 0.736292 val loss: 0.204649
[Epoch 44] ogbg-moltoxcast: 0.747832 test loss: 0.202750
[Epoch 45; Iter     6/  201] train: loss: 0.1509346
[Epoch 45; Iter    36/  201] train: loss: 0.1736366
[Epoch 45; Iter    66/  201] train: loss: 0.1738406
[Epoch 45; Iter    96/  201] train: loss: 0.1738361
[Epoch 45; Iter   126/  201] train: loss: 0.1782313
[Epoch 45; Iter   156/  201] train: loss: 0.2230476
[Epoch 45; Iter   186/  201] train: loss: 0.1048868
[Epoch 45] ogbg-moltoxcast: 0.729381 val loss: 0.204756
[Epoch 45] ogbg-moltoxcast: 0.742401 test loss: 0.203676
[Epoch 46; Iter    15/  201] train: loss: 0.1544542
[Epoch 46; Iter    45/  201] train: loss: 0.1820770
[Epoch 46; Iter    75/  201] train: loss: 0.1768890
[Epoch 46; Iter   105/  201] train: loss: 0.1481676
[Epoch 46; Iter   135/  201] train: loss: 0.1428712
[Epoch 46; Iter   165/  201] train: loss: 0.1381210
[Epoch 46; Iter   195/  201] train: loss: 0.1447434
[Epoch 46] ogbg-moltoxcast: 0.742169 val loss: 0.204927
[Epoch 46] ogbg-moltoxcast: 0.749416 test loss: 0.202508
[Epoch 47; Iter    24/  201] train: loss: 0.1418366
[Epoch 47; Iter    54/  201] train: loss: 0.0901207
[Epoch 47; Iter    84/  201] train: loss: 0.1972594
[Epoch 47; Iter   114/  201] train: loss: 0.1274697
[Epoch 47; Iter   144/  201] train: loss: 0.1081362
[Epoch 47; Iter   174/  201] train: loss: 0.1527320
[Epoch 47] ogbg-moltoxcast: 0.735964 val loss: 0.205890
[Epoch 47] ogbg-moltoxcast: 0.748857 test loss: 0.203431
[Epoch 48; Iter     3/  201] train: loss: 0.1858265
[Epoch 48; Iter    33/  201] train: loss: 0.2117577
[Epoch 48; Iter    63/  201] train: loss: 0.1417430
[Epoch 48; Iter    93/  201] train: loss: 0.1707048
[Epoch 48; Iter   123/  201] train: loss: 0.1995284
[Epoch 48; Iter   153/  201] train: loss: 0.1638600
[Epoch 30] ogbg-moltoxcast: 0.746601 test loss: 0.204320
[Epoch 31; Iter    30/  201] train: loss: 0.2611160
[Epoch 31; Iter    60/  201] train: loss: 0.1746363
[Epoch 31; Iter    90/  201] train: loss: 0.2494676
[Epoch 31; Iter   120/  201] train: loss: 0.2019815
[Epoch 31; Iter   150/  201] train: loss: 0.1559834
[Epoch 31; Iter   180/  201] train: loss: 0.1839846
[Epoch 31] ogbg-moltoxcast: 0.722814 val loss: 0.205606
[Epoch 31] ogbg-moltoxcast: 0.731859 test loss: 0.209682
[Epoch 32; Iter     9/  201] train: loss: 0.1420881
[Epoch 32; Iter    39/  201] train: loss: 0.1445966
[Epoch 32; Iter    69/  201] train: loss: 0.1482445
[Epoch 32; Iter    99/  201] train: loss: 0.2164126
[Epoch 32; Iter   129/  201] train: loss: 0.1418245
[Epoch 32; Iter   159/  201] train: loss: 0.1312575
[Epoch 32; Iter   189/  201] train: loss: 0.1600387
[Epoch 32] ogbg-moltoxcast: 0.731342 val loss: 0.204823
[Epoch 32] ogbg-moltoxcast: 0.745685 test loss: 0.205453
[Epoch 33; Iter    18/  201] train: loss: 0.2629002
[Epoch 33; Iter    48/  201] train: loss: 0.1590584
[Epoch 33; Iter    78/  201] train: loss: 0.1921553
[Epoch 33; Iter   108/  201] train: loss: 0.1459363
[Epoch 33; Iter   138/  201] train: loss: 0.3039612
[Epoch 33; Iter   168/  201] train: loss: 0.1087298
[Epoch 33; Iter   198/  201] train: loss: 0.1638555
[Epoch 33] ogbg-moltoxcast: 0.730995 val loss: 0.206524
[Epoch 33] ogbg-moltoxcast: 0.746422 test loss: 0.206688
[Epoch 34; Iter    27/  201] train: loss: 0.1926970
[Epoch 34; Iter    57/  201] train: loss: 0.1841598
[Epoch 34; Iter    87/  201] train: loss: 0.1241956
[Epoch 34; Iter   117/  201] train: loss: 0.1300264
[Epoch 34; Iter   147/  201] train: loss: 0.1408607
[Epoch 34; Iter   177/  201] train: loss: 0.2004517
[Epoch 34] ogbg-moltoxcast: 0.721803 val loss: 0.208490
[Epoch 34] ogbg-moltoxcast: 0.730939 test loss: 0.213122
[Epoch 35; Iter     6/  201] train: loss: 0.1919384
[Epoch 35; Iter    36/  201] train: loss: 0.1588347
[Epoch 35; Iter    66/  201] train: loss: 0.1260327
[Epoch 35; Iter    96/  201] train: loss: 0.1227840
[Epoch 35; Iter   126/  201] train: loss: 0.1438808
[Epoch 35; Iter   156/  201] train: loss: 0.1963000
[Epoch 35; Iter   186/  201] train: loss: 0.1977459
[Epoch 35] ogbg-moltoxcast: 0.730578 val loss: 0.208573
[Epoch 35] ogbg-moltoxcast: 0.751960 test loss: 0.201502
[Epoch 36; Iter    15/  201] train: loss: 0.1058705
[Epoch 36; Iter    45/  201] train: loss: 0.1542367
[Epoch 36; Iter    75/  201] train: loss: 0.1972795
[Epoch 36; Iter   105/  201] train: loss: 0.1427582
[Epoch 36; Iter   135/  201] train: loss: 0.1291369
[Epoch 36; Iter   165/  201] train: loss: 0.2003387
[Epoch 36; Iter   195/  201] train: loss: 0.1333912
[Epoch 36] ogbg-moltoxcast: 0.707323 val loss: 0.216104
[Epoch 36] ogbg-moltoxcast: 0.737687 test loss: 0.216318
[Epoch 37; Iter    24/  201] train: loss: 0.1367424
[Epoch 37; Iter    54/  201] train: loss: 0.1690041
[Epoch 37; Iter    84/  201] train: loss: 0.2005839
[Epoch 37; Iter   114/  201] train: loss: 0.2196656
[Epoch 37; Iter   144/  201] train: loss: 0.2189085
[Epoch 37; Iter   174/  201] train: loss: 0.2110379
[Epoch 37] ogbg-moltoxcast: 0.724423 val loss: 0.203448
[Epoch 37] ogbg-moltoxcast: 0.745330 test loss: 0.204652
[Epoch 38; Iter     3/  201] train: loss: 0.2025188
[Epoch 38; Iter    33/  201] train: loss: 0.1950673
[Epoch 38; Iter    63/  201] train: loss: 0.1611013
[Epoch 38; Iter    93/  201] train: loss: 0.1871200
[Epoch 38; Iter   123/  201] train: loss: 0.1722307
[Epoch 38; Iter   153/  201] train: loss: 0.1468294
[Epoch 38; Iter   183/  201] train: loss: 0.2090906
[Epoch 38] ogbg-moltoxcast: 0.727341 val loss: 0.245319
[Epoch 38] ogbg-moltoxcast: 0.750701 test loss: 0.204534
[Epoch 39; Iter    12/  201] train: loss: 0.1358605
[Epoch 39; Iter    42/  201] train: loss: 0.1630284
[Epoch 39; Iter    72/  201] train: loss: 0.1760458
[Epoch 39; Iter   102/  201] train: loss: 0.1584505
[Epoch 39; Iter   132/  201] train: loss: 0.1170433
[Epoch 39; Iter   162/  201] train: loss: 0.1569675
[Epoch 39; Iter   192/  201] train: loss: 0.1545457
[Epoch 39] ogbg-moltoxcast: 0.729887 val loss: 0.248607
[Epoch 39] ogbg-moltoxcast: 0.749820 test loss: 0.210122
[Epoch 40; Iter    21/  201] train: loss: 0.2029491
[Epoch 40; Iter    51/  201] train: loss: 0.1614522
[Epoch 40; Iter    81/  201] train: loss: 0.1870790
[Epoch 40; Iter   111/  201] train: loss: 0.1760959
[Epoch 40; Iter   141/  201] train: loss: 0.1580444
[Epoch 40; Iter   171/  201] train: loss: 0.1877067
[Epoch 40; Iter   201/  201] train: loss: 0.1648675
[Epoch 40] ogbg-moltoxcast: 0.729009 val loss: 0.250100
[Epoch 40] ogbg-moltoxcast: 0.750376 test loss: 0.202668
[Epoch 41; Iter    30/  201] train: loss: 0.2487834
[Epoch 41; Iter    60/  201] train: loss: 0.1161106
[Epoch 41; Iter    90/  201] train: loss: 0.1223300
[Epoch 41; Iter   120/  201] train: loss: 0.2100336
[Epoch 41; Iter   150/  201] train: loss: 0.2450996
[Epoch 41; Iter   180/  201] train: loss: 0.2415535
[Epoch 41] ogbg-moltoxcast: 0.725551 val loss: 0.205560
[Epoch 41] ogbg-moltoxcast: 0.751623 test loss: 0.202677
[Epoch 42; Iter     9/  201] train: loss: 0.1407133
[Epoch 42; Iter    39/  201] train: loss: 0.1418947
[Epoch 42; Iter    69/  201] train: loss: 0.1451365
[Epoch 42; Iter    99/  201] train: loss: 0.1254177
[Epoch 42; Iter   129/  201] train: loss: 0.1621251
[Epoch 42; Iter   159/  201] train: loss: 0.2161648
[Epoch 42; Iter   189/  201] train: loss: 0.1386793
[Epoch 42] ogbg-moltoxcast: 0.731201 val loss: 0.216830
[Epoch 42] ogbg-moltoxcast: 0.751337 test loss: 0.204703
[Epoch 43; Iter    18/  201] train: loss: 0.1122055
[Epoch 43; Iter    48/  201] train: loss: 0.1284142
[Epoch 43; Iter    78/  201] train: loss: 0.1213252
[Epoch 43; Iter   108/  201] train: loss: 0.1792577
[Epoch 43; Iter   138/  201] train: loss: 0.1620309
[Epoch 43; Iter   168/  201] train: loss: 0.2073566
[Epoch 43; Iter   198/  201] train: loss: 0.1823997
[Epoch 43] ogbg-moltoxcast: 0.727611 val loss: 0.215529
[Epoch 43] ogbg-moltoxcast: 0.752463 test loss: 0.203461
[Epoch 44; Iter    27/  201] train: loss: 0.1430428
[Epoch 44; Iter    57/  201] train: loss: 0.1245303
[Epoch 44; Iter    87/  201] train: loss: 0.1773098
[Epoch 44; Iter   117/  201] train: loss: 0.1727214
[Epoch 44; Iter   147/  201] train: loss: 0.1391126
[Epoch 44; Iter   177/  201] train: loss: 0.1712134
[Epoch 44] ogbg-moltoxcast: 0.727586 val loss: 0.274351
[Epoch 44] ogbg-moltoxcast: 0.750895 test loss: 0.203287
[Epoch 45; Iter     6/  201] train: loss: 0.1208234
[Epoch 45; Iter    36/  201] train: loss: 0.1809180
[Epoch 45; Iter    66/  201] train: loss: 0.1695176
[Epoch 45; Iter    96/  201] train: loss: 0.1247674
[Epoch 45; Iter   126/  201] train: loss: 0.1815744
[Epoch 45; Iter   156/  201] train: loss: 0.1291424
[Epoch 45; Iter   186/  201] train: loss: 0.1518250
[Epoch 45] ogbg-moltoxcast: 0.722432 val loss: 0.206922
[Epoch 45] ogbg-moltoxcast: 0.750920 test loss: 0.203710
[Epoch 46; Iter    15/  201] train: loss: 0.1836860
[Epoch 46; Iter    45/  201] train: loss: 0.1595665
[Epoch 46; Iter    75/  201] train: loss: 0.1033536
[Epoch 46; Iter   105/  201] train: loss: 0.1545713
[Epoch 46; Iter   135/  201] train: loss: 0.1613001
[Epoch 46; Iter   165/  201] train: loss: 0.1694587
[Epoch 46; Iter   195/  201] train: loss: 0.1003038
[Epoch 46] ogbg-moltoxcast: 0.731473 val loss: 0.225984
[Epoch 46] ogbg-moltoxcast: 0.751691 test loss: 0.218979
[Epoch 47; Iter    24/  201] train: loss: 0.1430631
[Epoch 47; Iter    54/  201] train: loss: 0.1739985
[Epoch 47; Iter    84/  201] train: loss: 0.1971037
[Epoch 47; Iter   114/  201] train: loss: 0.1617615
[Epoch 47; Iter   144/  201] train: loss: 0.1132932
[Epoch 47; Iter   174/  201] train: loss: 0.1480297
[Epoch 47] ogbg-moltoxcast: 0.726713 val loss: 0.243403
[Epoch 47] ogbg-moltoxcast: 0.742165 test loss: 0.211571
[Epoch 48; Iter     3/  201] train: loss: 0.2031256
[Epoch 48; Iter    33/  201] train: loss: 0.1207042
[Epoch 48; Iter    63/  201] train: loss: 0.2555267
[Epoch 48; Iter    93/  201] train: loss: 0.1296957
[Epoch 48; Iter   123/  201] train: loss: 0.1229298
[Epoch 48; Iter   153/  201] train: loss: 0.1998778
[Epoch 30] ogbg-moltoxcast: 0.744680 test loss: 0.209727
[Epoch 31; Iter    30/  201] train: loss: 0.1421691
[Epoch 31; Iter    60/  201] train: loss: 0.1820833
[Epoch 31; Iter    90/  201] train: loss: 0.1468990
[Epoch 31; Iter   120/  201] train: loss: 0.1565371
[Epoch 31; Iter   150/  201] train: loss: 0.1743675
[Epoch 31; Iter   180/  201] train: loss: 0.2273001
[Epoch 31] ogbg-moltoxcast: 0.730764 val loss: 0.227228
[Epoch 31] ogbg-moltoxcast: 0.742953 test loss: 0.241138
[Epoch 32; Iter     9/  201] train: loss: 0.1737951
[Epoch 32; Iter    39/  201] train: loss: 0.2280118
[Epoch 32; Iter    69/  201] train: loss: 0.1918621
[Epoch 32; Iter    99/  201] train: loss: 0.2232351
[Epoch 32; Iter   129/  201] train: loss: 0.2405068
[Epoch 32; Iter   159/  201] train: loss: 0.1605897
[Epoch 32; Iter   189/  201] train: loss: 0.1732042
[Epoch 32] ogbg-moltoxcast: 0.725804 val loss: 0.207329
[Epoch 32] ogbg-moltoxcast: 0.741785 test loss: 0.211036
[Epoch 33; Iter    18/  201] train: loss: 0.1414268
[Epoch 33; Iter    48/  201] train: loss: 0.1652661
[Epoch 33; Iter    78/  201] train: loss: 0.1261673
[Epoch 33; Iter   108/  201] train: loss: 0.1316787
[Epoch 33; Iter   138/  201] train: loss: 0.2227964
[Epoch 33; Iter   168/  201] train: loss: 0.2533504
[Epoch 33; Iter   198/  201] train: loss: 0.1769083
[Epoch 33] ogbg-moltoxcast: 0.728972 val loss: 0.207276
[Epoch 33] ogbg-moltoxcast: 0.751203 test loss: 0.206585
[Epoch 34; Iter    27/  201] train: loss: 0.2016073
[Epoch 34; Iter    57/  201] train: loss: 0.2050870
[Epoch 34; Iter    87/  201] train: loss: 0.1786114
[Epoch 34; Iter   117/  201] train: loss: 0.1669139
[Epoch 34; Iter   147/  201] train: loss: 0.2602434
[Epoch 34; Iter   177/  201] train: loss: 0.1605908
[Epoch 34] ogbg-moltoxcast: 0.730575 val loss: 0.206567
[Epoch 34] ogbg-moltoxcast: 0.741407 test loss: 0.209081
[Epoch 35; Iter     6/  201] train: loss: 0.1166620
[Epoch 35; Iter    36/  201] train: loss: 0.1373491
[Epoch 35; Iter    66/  201] train: loss: 0.1326935
[Epoch 35; Iter    96/  201] train: loss: 0.1500444
[Epoch 35; Iter   126/  201] train: loss: 0.1373348
[Epoch 35; Iter   156/  201] train: loss: 0.1716435
[Epoch 35; Iter   186/  201] train: loss: 0.1558596
[Epoch 35] ogbg-moltoxcast: 0.728798 val loss: 0.208760
[Epoch 35] ogbg-moltoxcast: 0.749512 test loss: 0.211339
[Epoch 36; Iter    15/  201] train: loss: 0.2201222
[Epoch 36; Iter    45/  201] train: loss: 0.1342795
[Epoch 36; Iter    75/  201] train: loss: 0.2148754
[Epoch 36; Iter   105/  201] train: loss: 0.1692803
[Epoch 36; Iter   135/  201] train: loss: 0.2155823
[Epoch 36; Iter   165/  201] train: loss: 0.1440716
[Epoch 36; Iter   195/  201] train: loss: 0.1262446
[Epoch 36] ogbg-moltoxcast: 0.734236 val loss: 0.203383
[Epoch 36] ogbg-moltoxcast: 0.754844 test loss: 0.202838
[Epoch 37; Iter    24/  201] train: loss: 0.1324567
[Epoch 37; Iter    54/  201] train: loss: 0.1767180
[Epoch 37; Iter    84/  201] train: loss: 0.1648897
[Epoch 37; Iter   114/  201] train: loss: 0.1544146
[Epoch 37; Iter   144/  201] train: loss: 0.1594568
[Epoch 37; Iter   174/  201] train: loss: 0.1301548
[Epoch 37] ogbg-moltoxcast: 0.732053 val loss: 0.206568
[Epoch 37] ogbg-moltoxcast: 0.748879 test loss: 0.208249
[Epoch 38; Iter     3/  201] train: loss: 0.2006228
[Epoch 38; Iter    33/  201] train: loss: 0.1494992
[Epoch 38; Iter    63/  201] train: loss: 0.1365202
[Epoch 38; Iter    93/  201] train: loss: 0.1644590
[Epoch 38; Iter   123/  201] train: loss: 0.1395388
[Epoch 38; Iter   153/  201] train: loss: 0.1371833
[Epoch 38; Iter   183/  201] train: loss: 0.2276337
[Epoch 38] ogbg-moltoxcast: 0.725074 val loss: 0.205087
[Epoch 38] ogbg-moltoxcast: 0.751514 test loss: 0.205546
[Epoch 39; Iter    12/  201] train: loss: 0.1397075
[Epoch 39; Iter    42/  201] train: loss: 0.1919575
[Epoch 39; Iter    72/  201] train: loss: 0.1387905
[Epoch 39; Iter   102/  201] train: loss: 0.1621953
[Epoch 39; Iter   132/  201] train: loss: 0.1515420
[Epoch 39; Iter   162/  201] train: loss: 0.1318018
[Epoch 39; Iter   192/  201] train: loss: 0.1613705
[Epoch 39] ogbg-moltoxcast: 0.726229 val loss: 0.207482
[Epoch 39] ogbg-moltoxcast: 0.752673 test loss: 0.204403
[Epoch 40; Iter    21/  201] train: loss: 0.1269780
[Epoch 40; Iter    51/  201] train: loss: 0.1795411
[Epoch 40; Iter    81/  201] train: loss: 0.1527140
[Epoch 40; Iter   111/  201] train: loss: 0.2042839
[Epoch 40; Iter   141/  201] train: loss: 0.2208574
[Epoch 40; Iter   171/  201] train: loss: 0.1374466
[Epoch 40; Iter   201/  201] train: loss: 0.0983625
[Epoch 40] ogbg-moltoxcast: 0.726382 val loss: 0.211913
[Epoch 40] ogbg-moltoxcast: 0.750696 test loss: 0.222734
[Epoch 41; Iter    30/  201] train: loss: 0.1221558
[Epoch 41; Iter    60/  201] train: loss: 0.1757492
[Epoch 41; Iter    90/  201] train: loss: 0.1801903
[Epoch 41; Iter   120/  201] train: loss: 0.1789014
[Epoch 41; Iter   150/  201] train: loss: 0.1394739
[Epoch 41; Iter   180/  201] train: loss: 0.2228348
[Epoch 41] ogbg-moltoxcast: 0.729934 val loss: 0.216691
[Epoch 41] ogbg-moltoxcast: 0.750037 test loss: 0.238333
[Epoch 42; Iter     9/  201] train: loss: 0.1897976
[Epoch 42; Iter    39/  201] train: loss: 0.1762981
[Epoch 42; Iter    69/  201] train: loss: 0.1695581
[Epoch 42; Iter    99/  201] train: loss: 0.1655640
[Epoch 42; Iter   129/  201] train: loss: 0.2179647
[Epoch 42; Iter   159/  201] train: loss: 0.1583642
[Epoch 42; Iter   189/  201] train: loss: 0.1368498
[Epoch 42] ogbg-moltoxcast: 0.725307 val loss: 0.207235
[Epoch 42] ogbg-moltoxcast: 0.755495 test loss: 0.207723
[Epoch 43; Iter    18/  201] train: loss: 0.1429909
[Epoch 43; Iter    48/  201] train: loss: 0.1739674
[Epoch 43; Iter    78/  201] train: loss: 0.1806682
[Epoch 43; Iter   108/  201] train: loss: 0.1080342
[Epoch 43; Iter   138/  201] train: loss: 0.2063051
[Epoch 43; Iter   168/  201] train: loss: 0.0815239
[Epoch 43; Iter   198/  201] train: loss: 0.2327406
[Epoch 43] ogbg-moltoxcast: 0.728037 val loss: 0.204469
[Epoch 43] ogbg-moltoxcast: 0.753015 test loss: 0.204106
[Epoch 44; Iter    27/  201] train: loss: 0.2157014
[Epoch 44; Iter    57/  201] train: loss: 0.1477535
[Epoch 44; Iter    87/  201] train: loss: 0.1539875
[Epoch 44; Iter   117/  201] train: loss: 0.1947982
[Epoch 44; Iter   147/  201] train: loss: 0.1844505
[Epoch 44; Iter   177/  201] train: loss: 0.1636277
[Epoch 44] ogbg-moltoxcast: 0.727515 val loss: 0.209579
[Epoch 44] ogbg-moltoxcast: 0.747134 test loss: 0.211436
[Epoch 45; Iter     6/  201] train: loss: 0.2237630
[Epoch 45; Iter    36/  201] train: loss: 0.1670197
[Epoch 45; Iter    66/  201] train: loss: 0.1743899
[Epoch 45; Iter    96/  201] train: loss: 0.1748968
[Epoch 45; Iter   126/  201] train: loss: 0.1693009
[Epoch 45; Iter   156/  201] train: loss: 0.1635892
[Epoch 45; Iter   186/  201] train: loss: 0.1578646
[Epoch 45] ogbg-moltoxcast: 0.730233 val loss: 0.210964
[Epoch 45] ogbg-moltoxcast: 0.754997 test loss: 0.227982
[Epoch 46; Iter    15/  201] train: loss: 0.1614676
[Epoch 46; Iter    45/  201] train: loss: 0.1343378
[Epoch 46; Iter    75/  201] train: loss: 0.1406760
[Epoch 46; Iter   105/  201] train: loss: 0.1327806
[Epoch 46; Iter   135/  201] train: loss: 0.2382402
[Epoch 46; Iter   165/  201] train: loss: 0.1307498
[Epoch 46; Iter   195/  201] train: loss: 0.1387747
[Epoch 46] ogbg-moltoxcast: 0.734642 val loss: 0.208279
[Epoch 46] ogbg-moltoxcast: 0.755546 test loss: 0.238009
[Epoch 47; Iter    24/  201] train: loss: 0.1386425
[Epoch 47; Iter    54/  201] train: loss: 0.1565201
[Epoch 47; Iter    84/  201] train: loss: 0.1180810
[Epoch 47; Iter   114/  201] train: loss: 0.1442218
[Epoch 47; Iter   144/  201] train: loss: 0.2383739
[Epoch 47; Iter   174/  201] train: loss: 0.1761048
[Epoch 47] ogbg-moltoxcast: 0.730287 val loss: 0.204641
[Epoch 47] ogbg-moltoxcast: 0.752281 test loss: 0.219998
[Epoch 48; Iter     3/  201] train: loss: 0.0957447
[Epoch 48; Iter    33/  201] train: loss: 0.1890164
[Epoch 48; Iter    63/  201] train: loss: 0.1927373
[Epoch 48; Iter    93/  201] train: loss: 0.1675611
[Epoch 48; Iter   123/  201] train: loss: 0.1724981
[Epoch 48; Iter   153/  201] train: loss: 0.1610924
[Epoch 34; Iter   144/  172] train: loss: 0.1995469
[Epoch 34] ogbg-moltoxcast: 0.732541 val loss: 0.226888
[Epoch 34] ogbg-moltoxcast: 0.736062 test loss: 0.200842
[Epoch 35; Iter     2/  172] train: loss: 0.1717522
[Epoch 35; Iter    32/  172] train: loss: 0.1743380
[Epoch 35; Iter    62/  172] train: loss: 0.1250098
[Epoch 35; Iter    92/  172] train: loss: 0.1239682
[Epoch 35; Iter   122/  172] train: loss: 0.1017338
[Epoch 35; Iter   152/  172] train: loss: 0.1031648
[Epoch 35] ogbg-moltoxcast: 0.729920 val loss: 0.311459
[Epoch 35] ogbg-moltoxcast: 0.733957 test loss: 0.236793
[Epoch 36; Iter    10/  172] train: loss: 0.1705156
[Epoch 36; Iter    40/  172] train: loss: 0.1342918
[Epoch 36; Iter    70/  172] train: loss: 0.1342882
[Epoch 36; Iter   100/  172] train: loss: 0.1505124
[Epoch 36; Iter   130/  172] train: loss: 0.1633235
[Epoch 36; Iter   160/  172] train: loss: 0.1200311
[Epoch 36] ogbg-moltoxcast: 0.734286 val loss: 0.203987
[Epoch 36] ogbg-moltoxcast: 0.732838 test loss: 0.206057
[Epoch 37; Iter    18/  172] train: loss: 0.1123030
[Epoch 37; Iter    48/  172] train: loss: 0.1321227
[Epoch 37; Iter    78/  172] train: loss: 0.1603067
[Epoch 37; Iter   108/  172] train: loss: 0.1045511
[Epoch 37; Iter   138/  172] train: loss: 0.2313041
[Epoch 37; Iter   168/  172] train: loss: 0.1794461
[Epoch 37] ogbg-moltoxcast: 0.722285 val loss: 0.219007
[Epoch 37] ogbg-moltoxcast: 0.730830 test loss: 0.204643
[Epoch 38; Iter    26/  172] train: loss: 0.2005109
[Epoch 38; Iter    56/  172] train: loss: 0.2008024
[Epoch 38; Iter    86/  172] train: loss: 0.1161661
[Epoch 38; Iter   116/  172] train: loss: 0.1471232
[Epoch 38; Iter   146/  172] train: loss: 0.1513952
[Epoch 38] ogbg-moltoxcast: 0.731409 val loss: 0.201705
[Epoch 38] ogbg-moltoxcast: 0.736235 test loss: 0.200946
[Epoch 39; Iter     4/  172] train: loss: 0.1923341
[Epoch 39; Iter    34/  172] train: loss: 0.1256704
[Epoch 39; Iter    64/  172] train: loss: 0.1093950
[Epoch 39; Iter    94/  172] train: loss: 0.1439230
[Epoch 39; Iter   124/  172] train: loss: 0.2045354
[Epoch 39; Iter   154/  172] train: loss: 0.1551801
[Epoch 39] ogbg-moltoxcast: 0.736077 val loss: 0.199158
[Epoch 39] ogbg-moltoxcast: 0.738432 test loss: 0.200763
[Epoch 40; Iter    12/  172] train: loss: 0.2301107
[Epoch 40; Iter    42/  172] train: loss: 0.1864584
[Epoch 40; Iter    72/  172] train: loss: 0.1412241
[Epoch 40; Iter   102/  172] train: loss: 0.2045140
[Epoch 40; Iter   132/  172] train: loss: 0.1354972
[Epoch 40; Iter   162/  172] train: loss: 0.2180430
[Epoch 40] ogbg-moltoxcast: 0.734922 val loss: 0.212646
[Epoch 40] ogbg-moltoxcast: 0.734572 test loss: 0.202678
[Epoch 41; Iter    20/  172] train: loss: 0.2126728
[Epoch 41; Iter    50/  172] train: loss: 0.1651901
[Epoch 41; Iter    80/  172] train: loss: 0.2335021
[Epoch 41; Iter   110/  172] train: loss: 0.1572652
[Epoch 41; Iter   140/  172] train: loss: 0.1551178
[Epoch 41; Iter   170/  172] train: loss: 0.1578950
[Epoch 41] ogbg-moltoxcast: 0.727500 val loss: 0.202543
[Epoch 41] ogbg-moltoxcast: 0.733850 test loss: 0.204392
[Epoch 42; Iter    28/  172] train: loss: 0.1788513
[Epoch 42; Iter    58/  172] train: loss: 0.1533192
[Epoch 42; Iter    88/  172] train: loss: 0.2194761
[Epoch 42; Iter   118/  172] train: loss: 0.1817518
[Epoch 42; Iter   148/  172] train: loss: 0.1536840
[Epoch 42] ogbg-moltoxcast: 0.730865 val loss: 0.217692
[Epoch 42] ogbg-moltoxcast: 0.733771 test loss: 0.201218
[Epoch 43; Iter     6/  172] train: loss: 0.0979360
[Epoch 43; Iter    36/  172] train: loss: 0.1680547
[Epoch 43; Iter    66/  172] train: loss: 0.1039498
[Epoch 43; Iter    96/  172] train: loss: 0.1556628
[Epoch 43; Iter   126/  172] train: loss: 0.1448394
[Epoch 43; Iter   156/  172] train: loss: 0.2281542
[Epoch 43] ogbg-moltoxcast: 0.728649 val loss: 0.204016
[Epoch 43] ogbg-moltoxcast: 0.741359 test loss: 0.201460
[Epoch 44; Iter    14/  172] train: loss: 0.1276331
[Epoch 44; Iter    44/  172] train: loss: 0.1560111
[Epoch 44; Iter    74/  172] train: loss: 0.1916408
[Epoch 44; Iter   104/  172] train: loss: 0.2358775
[Epoch 44; Iter   134/  172] train: loss: 0.2083900
[Epoch 44; Iter   164/  172] train: loss: 0.2834355
[Epoch 44] ogbg-moltoxcast: 0.731114 val loss: 0.207772
[Epoch 44] ogbg-moltoxcast: 0.737993 test loss: 0.204374
[Epoch 45; Iter    22/  172] train: loss: 0.2386248
[Epoch 45; Iter    52/  172] train: loss: 0.1452807
[Epoch 45; Iter    82/  172] train: loss: 0.1613059
[Epoch 45; Iter   112/  172] train: loss: 0.1770175
[Epoch 45; Iter   142/  172] train: loss: 0.1710382
[Epoch 45; Iter   172/  172] train: loss: 0.1250752
[Epoch 45] ogbg-moltoxcast: 0.734822 val loss: 0.203517
[Epoch 45] ogbg-moltoxcast: 0.738970 test loss: 0.201459
[Epoch 46; Iter    30/  172] train: loss: 0.1977706
[Epoch 46; Iter    60/  172] train: loss: 0.1702991
[Epoch 46; Iter    90/  172] train: loss: 0.1273054
[Epoch 46; Iter   120/  172] train: loss: 0.2138245
[Epoch 46; Iter   150/  172] train: loss: 0.2378184
[Epoch 46] ogbg-moltoxcast: 0.728653 val loss: 0.250446
[Epoch 46] ogbg-moltoxcast: 0.738413 test loss: 0.208677
[Epoch 47; Iter     8/  172] train: loss: 0.1564302
[Epoch 47; Iter    38/  172] train: loss: 0.1442804
[Epoch 47; Iter    68/  172] train: loss: 0.1052370
[Epoch 47; Iter    98/  172] train: loss: 0.1670032
[Epoch 47; Iter   128/  172] train: loss: 0.1347046
[Epoch 47; Iter   158/  172] train: loss: 0.1427616
[Epoch 47] ogbg-moltoxcast: 0.727611 val loss: 0.233365
[Epoch 47] ogbg-moltoxcast: 0.732443 test loss: 0.206382
[Epoch 48; Iter    16/  172] train: loss: 0.1354343
[Epoch 48; Iter    46/  172] train: loss: 0.1649847
[Epoch 48; Iter    76/  172] train: loss: 0.1760561
[Epoch 48; Iter   106/  172] train: loss: 0.1673912
[Epoch 48; Iter   136/  172] train: loss: 0.1670068
[Epoch 48; Iter   166/  172] train: loss: 0.1885144
[Epoch 48] ogbg-moltoxcast: 0.729327 val loss: 0.203719
[Epoch 48] ogbg-moltoxcast: 0.735528 test loss: 0.204605
[Epoch 49; Iter    24/  172] train: loss: 0.1388419
[Epoch 49; Iter    54/  172] train: loss: 0.1384528
[Epoch 49; Iter    84/  172] train: loss: 0.1876784
[Epoch 49; Iter   114/  172] train: loss: 0.1254868
[Epoch 49; Iter   144/  172] train: loss: 0.1948563
[Epoch 49] ogbg-moltoxcast: 0.729802 val loss: 0.205424
[Epoch 49] ogbg-moltoxcast: 0.734505 test loss: 0.205944
[Epoch 50; Iter     2/  172] train: loss: 0.1321007
[Epoch 50; Iter    32/  172] train: loss: 0.1557302
[Epoch 50; Iter    62/  172] train: loss: 0.1107133
[Epoch 50; Iter    92/  172] train: loss: 0.1271297
[Epoch 50; Iter   122/  172] train: loss: 0.1435395
[Epoch 50; Iter   152/  172] train: loss: 0.1452846
[Epoch 50] ogbg-moltoxcast: 0.728859 val loss: 0.227473
[Epoch 50] ogbg-moltoxcast: 0.732919 test loss: 0.205986
[Epoch 51; Iter    10/  172] train: loss: 0.1453982
[Epoch 51; Iter    40/  172] train: loss: 0.1445943
[Epoch 51; Iter    70/  172] train: loss: 0.1877398
[Epoch 51; Iter   100/  172] train: loss: 0.1423730
[Epoch 51; Iter   130/  172] train: loss: 0.1721808
[Epoch 51; Iter   160/  172] train: loss: 0.1821244
[Epoch 51] ogbg-moltoxcast: 0.736945 val loss: 0.205609
[Epoch 51] ogbg-moltoxcast: 0.735859 test loss: 0.205440
[Epoch 52; Iter    18/  172] train: loss: 0.1546064
[Epoch 52; Iter    48/  172] train: loss: 0.1384046
[Epoch 52; Iter    78/  172] train: loss: 0.1584442
[Epoch 52; Iter   108/  172] train: loss: 0.0910971
[Epoch 52; Iter   138/  172] train: loss: 0.1471737
[Epoch 52; Iter   168/  172] train: loss: 0.1518817
[Epoch 52] ogbg-moltoxcast: 0.726523 val loss: 0.210504
[Epoch 52] ogbg-moltoxcast: 0.734339 test loss: 0.205126
[Epoch 53; Iter    26/  172] train: loss: 0.1146997
[Epoch 53; Iter    56/  172] train: loss: 0.1525187
[Epoch 53; Iter    86/  172] train: loss: 0.1259679
[Epoch 53; Iter   116/  172] train: loss: 0.1665086
[Epoch 53; Iter   146/  172] train: loss: 0.1909400
[Epoch 53] ogbg-moltoxcast: 0.729622 val loss: 0.238271
[Epoch 53] ogbg-moltoxcast: 0.733540 test loss: 0.208149
[Epoch 54; Iter     4/  172] train: loss: 0.1742141
[Epoch 54; Iter    34/  172] train: loss: 0.1360111
[Epoch 54; Iter    64/  172] train: loss: 0.1358206
[Epoch 54; Iter    94/  172] train: loss: 0.1471646
[Epoch 34; Iter   144/  172] train: loss: 0.1442356
[Epoch 34] ogbg-moltoxcast: 0.726602 val loss: 0.205592
[Epoch 34] ogbg-moltoxcast: 0.738214 test loss: 0.203471
[Epoch 35; Iter     2/  172] train: loss: 0.1599788
[Epoch 35; Iter    32/  172] train: loss: 0.1860729
[Epoch 35; Iter    62/  172] train: loss: 0.1866863
[Epoch 35; Iter    92/  172] train: loss: 0.1498526
[Epoch 35; Iter   122/  172] train: loss: 0.1618873
[Epoch 35; Iter   152/  172] train: loss: 0.2095106
[Epoch 35] ogbg-moltoxcast: 0.724841 val loss: 0.201618
[Epoch 35] ogbg-moltoxcast: 0.734359 test loss: 0.203542
[Epoch 36; Iter    10/  172] train: loss: 0.1353143
[Epoch 36; Iter    40/  172] train: loss: 0.1649179
[Epoch 36; Iter    70/  172] train: loss: 0.1638594
[Epoch 36; Iter   100/  172] train: loss: 0.1159356
[Epoch 36; Iter   130/  172] train: loss: 0.1802505
[Epoch 36; Iter   160/  172] train: loss: 0.1413414
[Epoch 36] ogbg-moltoxcast: 0.724207 val loss: 0.204622
[Epoch 36] ogbg-moltoxcast: 0.732909 test loss: 0.205308
[Epoch 37; Iter    18/  172] train: loss: 0.1230759
[Epoch 37; Iter    48/  172] train: loss: 0.1675835
[Epoch 37; Iter    78/  172] train: loss: 0.1544178
[Epoch 37; Iter   108/  172] train: loss: 0.1045171
[Epoch 37; Iter   138/  172] train: loss: 0.1546766
[Epoch 37; Iter   168/  172] train: loss: 0.2284541
[Epoch 37] ogbg-moltoxcast: 0.726821 val loss: 0.208420
[Epoch 37] ogbg-moltoxcast: 0.736985 test loss: 0.208024
[Epoch 38; Iter    26/  172] train: loss: 0.1710221
[Epoch 38; Iter    56/  172] train: loss: 0.1315962
[Epoch 38; Iter    86/  172] train: loss: 0.1257557
[Epoch 38; Iter   116/  172] train: loss: 0.1749422
[Epoch 38; Iter   146/  172] train: loss: 0.1914484
[Epoch 38] ogbg-moltoxcast: 0.723113 val loss: 0.207659
[Epoch 38] ogbg-moltoxcast: 0.739601 test loss: 0.204154
[Epoch 39; Iter     4/  172] train: loss: 0.2320495
[Epoch 39; Iter    34/  172] train: loss: 0.2030231
[Epoch 39; Iter    64/  172] train: loss: 0.1463380
[Epoch 39; Iter    94/  172] train: loss: 0.1703092
[Epoch 39; Iter   124/  172] train: loss: 0.2278285
[Epoch 39; Iter   154/  172] train: loss: 0.1829577
[Epoch 39] ogbg-moltoxcast: 0.729422 val loss: 0.202617
[Epoch 39] ogbg-moltoxcast: 0.742181 test loss: 0.201056
[Epoch 40; Iter    12/  172] train: loss: 0.1631149
[Epoch 40; Iter    42/  172] train: loss: 0.1193368
[Epoch 40; Iter    72/  172] train: loss: 0.1916880
[Epoch 40; Iter   102/  172] train: loss: 0.1712572
[Epoch 40; Iter   132/  172] train: loss: 0.1297084
[Epoch 40; Iter   162/  172] train: loss: 0.1375459
[Epoch 40] ogbg-moltoxcast: 0.723735 val loss: 0.204915
[Epoch 40] ogbg-moltoxcast: 0.736710 test loss: 0.203022
[Epoch 41; Iter    20/  172] train: loss: 0.1979191
[Epoch 41; Iter    50/  172] train: loss: 0.2022121
[Epoch 41; Iter    80/  172] train: loss: 0.0682678
[Epoch 41; Iter   110/  172] train: loss: 0.1801650
[Epoch 41; Iter   140/  172] train: loss: 0.1444767
[Epoch 41; Iter   170/  172] train: loss: 0.2755047
[Epoch 41] ogbg-moltoxcast: 0.727141 val loss: 0.207187
[Epoch 41] ogbg-moltoxcast: 0.735506 test loss: 0.222580
[Epoch 42; Iter    28/  172] train: loss: 0.1778766
[Epoch 42; Iter    58/  172] train: loss: 0.2151267
[Epoch 42; Iter    88/  172] train: loss: 0.1750990
[Epoch 42; Iter   118/  172] train: loss: 0.1227363
[Epoch 42; Iter   148/  172] train: loss: 0.1121222
[Epoch 42] ogbg-moltoxcast: 0.727295 val loss: 0.205415
[Epoch 42] ogbg-moltoxcast: 0.743761 test loss: 0.202456
[Epoch 43; Iter     6/  172] train: loss: 0.1374400
[Epoch 43; Iter    36/  172] train: loss: 0.1533340
[Epoch 43; Iter    66/  172] train: loss: 0.1213829
[Epoch 43; Iter    96/  172] train: loss: 0.1630913
[Epoch 43; Iter   126/  172] train: loss: 0.1060443
[Epoch 43; Iter   156/  172] train: loss: 0.1518451
[Epoch 43] ogbg-moltoxcast: 0.728081 val loss: 0.209558
[Epoch 43] ogbg-moltoxcast: 0.739010 test loss: 0.221556
[Epoch 44; Iter    14/  172] train: loss: 0.2230901
[Epoch 44; Iter    44/  172] train: loss: 0.1302189
[Epoch 44; Iter    74/  172] train: loss: 0.1344269
[Epoch 44; Iter   104/  172] train: loss: 0.1693998
[Epoch 44; Iter   134/  172] train: loss: 0.1411487
[Epoch 44; Iter   164/  172] train: loss: 0.1950752
[Epoch 44] ogbg-moltoxcast: 0.732135 val loss: 0.203724
[Epoch 44] ogbg-moltoxcast: 0.743132 test loss: 0.203620
[Epoch 45; Iter    22/  172] train: loss: 0.1358291
[Epoch 45; Iter    52/  172] train: loss: 0.1710972
[Epoch 45; Iter    82/  172] train: loss: 0.1583578
[Epoch 45; Iter   112/  172] train: loss: 0.1632508
[Epoch 45; Iter   142/  172] train: loss: 0.1369292
[Epoch 45; Iter   172/  172] train: loss: 0.2409364
[Epoch 45] ogbg-moltoxcast: 0.723335 val loss: 0.206748
[Epoch 45] ogbg-moltoxcast: 0.733490 test loss: 0.205361
[Epoch 46; Iter    30/  172] train: loss: 0.1215773
[Epoch 46; Iter    60/  172] train: loss: 0.1164027
[Epoch 46; Iter    90/  172] train: loss: 0.0859340
[Epoch 46; Iter   120/  172] train: loss: 0.1419467
[Epoch 46; Iter   150/  172] train: loss: 0.1630187
[Epoch 46] ogbg-moltoxcast: 0.727217 val loss: 0.208368
[Epoch 46] ogbg-moltoxcast: 0.732231 test loss: 0.207603
[Epoch 47; Iter     8/  172] train: loss: 0.1267875
[Epoch 47; Iter    38/  172] train: loss: 0.1316186
[Epoch 47; Iter    68/  172] train: loss: 0.1513087
[Epoch 47; Iter    98/  172] train: loss: 0.1132049
[Epoch 47; Iter   128/  172] train: loss: 0.1200587
[Epoch 47; Iter   158/  172] train: loss: 0.1743311
[Epoch 47] ogbg-moltoxcast: 0.728279 val loss: 0.212230
[Epoch 47] ogbg-moltoxcast: 0.738374 test loss: 0.212606
[Epoch 48; Iter    16/  172] train: loss: 0.1909844
[Epoch 48; Iter    46/  172] train: loss: 0.1419515
[Epoch 48; Iter    76/  172] train: loss: 0.1340077
[Epoch 48; Iter   106/  172] train: loss: 0.1810843
[Epoch 48; Iter   136/  172] train: loss: 0.1545819
[Epoch 48; Iter   166/  172] train: loss: 0.1423950
[Epoch 48] ogbg-moltoxcast: 0.724767 val loss: 0.208480
[Epoch 48] ogbg-moltoxcast: 0.739036 test loss: 0.206866
[Epoch 49; Iter    24/  172] train: loss: 0.1200166
[Epoch 49; Iter    54/  172] train: loss: 0.1607169
[Epoch 49; Iter    84/  172] train: loss: 0.1234947
[Epoch 49; Iter   114/  172] train: loss: 0.1077987
[Epoch 49; Iter   144/  172] train: loss: 0.1763747
[Epoch 49] ogbg-moltoxcast: 0.729746 val loss: 0.207562
[Epoch 49] ogbg-moltoxcast: 0.742405 test loss: 0.205927
[Epoch 50; Iter     2/  172] train: loss: 0.1300139
[Epoch 50; Iter    32/  172] train: loss: 0.1746791
[Epoch 50; Iter    62/  172] train: loss: 0.1497038
[Epoch 50; Iter    92/  172] train: loss: 0.2093377
[Epoch 50; Iter   122/  172] train: loss: 0.1616140
[Epoch 50; Iter   152/  172] train: loss: 0.1401113
[Epoch 50] ogbg-moltoxcast: 0.732465 val loss: 0.207001
[Epoch 50] ogbg-moltoxcast: 0.737893 test loss: 0.208132
[Epoch 51; Iter    10/  172] train: loss: 0.1001779
[Epoch 51; Iter    40/  172] train: loss: 0.1738279
[Epoch 51; Iter    70/  172] train: loss: 0.1341915
[Epoch 51; Iter   100/  172] train: loss: 0.1281927
[Epoch 51; Iter   130/  172] train: loss: 0.1921428
[Epoch 51; Iter   160/  172] train: loss: 0.1726973
[Epoch 51] ogbg-moltoxcast: 0.730769 val loss: 0.208925
[Epoch 51] ogbg-moltoxcast: 0.734209 test loss: 0.209548
[Epoch 52; Iter    18/  172] train: loss: 0.1337121
[Epoch 52; Iter    48/  172] train: loss: 0.1347988
[Epoch 52; Iter    78/  172] train: loss: 0.1620759
[Epoch 52; Iter   108/  172] train: loss: 0.1506061
[Epoch 52; Iter   138/  172] train: loss: 0.1599515
[Epoch 52; Iter   168/  172] train: loss: 0.1500638
[Epoch 52] ogbg-moltoxcast: 0.735769 val loss: 0.207307
[Epoch 52] ogbg-moltoxcast: 0.736904 test loss: 0.209455
[Epoch 53; Iter    26/  172] train: loss: 0.1427391
[Epoch 53; Iter    56/  172] train: loss: 0.1270972
[Epoch 53; Iter    86/  172] train: loss: 0.1538795
[Epoch 53; Iter   116/  172] train: loss: 0.2020296
[Epoch 53; Iter   146/  172] train: loss: 0.1197775
[Epoch 53] ogbg-moltoxcast: 0.729104 val loss: 0.212648
[Epoch 53] ogbg-moltoxcast: 0.735714 test loss: 0.211257
[Epoch 54; Iter     4/  172] train: loss: 0.1243123
[Epoch 54; Iter    34/  172] train: loss: 0.1422685
[Epoch 54; Iter    64/  172] train: loss: 0.1880109
[Epoch 54; Iter    94/  172] train: loss: 0.1575508
[Epoch 34; Iter   144/  172] train: loss: 0.1294615
[Epoch 34] ogbg-moltoxcast: 0.725213 val loss: 0.251040
[Epoch 34] ogbg-moltoxcast: 0.727443 test loss: 0.222019
[Epoch 35; Iter     2/  172] train: loss: 0.1753557
[Epoch 35; Iter    32/  172] train: loss: 0.1788106
[Epoch 35; Iter    62/  172] train: loss: 0.1814003
[Epoch 35; Iter    92/  172] train: loss: 0.1813483
[Epoch 35; Iter   122/  172] train: loss: 0.1006925
[Epoch 35; Iter   152/  172] train: loss: 0.2348963
[Epoch 35] ogbg-moltoxcast: 0.724744 val loss: 0.253620
[Epoch 35] ogbg-moltoxcast: 0.726102 test loss: 0.358091
[Epoch 36; Iter    10/  172] train: loss: 0.1702916
[Epoch 36; Iter    40/  172] train: loss: 0.1799296
[Epoch 36; Iter    70/  172] train: loss: 0.1353758
[Epoch 36; Iter   100/  172] train: loss: 0.1313252
[Epoch 36; Iter   130/  172] train: loss: 0.1933574
[Epoch 36; Iter   160/  172] train: loss: 0.2303173
[Epoch 36] ogbg-moltoxcast: 0.727653 val loss: 0.211535
[Epoch 36] ogbg-moltoxcast: 0.733570 test loss: 0.207017
[Epoch 37; Iter    18/  172] train: loss: 0.1545022
[Epoch 37; Iter    48/  172] train: loss: 0.1711350
[Epoch 37; Iter    78/  172] train: loss: 0.2126298
[Epoch 37; Iter   108/  172] train: loss: 0.1572261
[Epoch 37; Iter   138/  172] train: loss: 0.1634461
[Epoch 37; Iter   168/  172] train: loss: 0.1156192
[Epoch 37] ogbg-moltoxcast: 0.726588 val loss: 0.214655
[Epoch 37] ogbg-moltoxcast: 0.741541 test loss: 0.238796
[Epoch 38; Iter    26/  172] train: loss: 0.1775914
[Epoch 38; Iter    56/  172] train: loss: 0.1447272
[Epoch 38; Iter    86/  172] train: loss: 0.1571724
[Epoch 38; Iter   116/  172] train: loss: 0.1635228
[Epoch 38; Iter   146/  172] train: loss: 0.1366555
[Epoch 38] ogbg-moltoxcast: 0.726031 val loss: 0.213118
[Epoch 38] ogbg-moltoxcast: 0.736886 test loss: 0.238621
[Epoch 39; Iter     4/  172] train: loss: 0.1714900
[Epoch 39; Iter    34/  172] train: loss: 0.1701874
[Epoch 39; Iter    64/  172] train: loss: 0.1478206
[Epoch 39; Iter    94/  172] train: loss: 0.1440522
[Epoch 39; Iter   124/  172] train: loss: 0.1629319
[Epoch 39; Iter   154/  172] train: loss: 0.1419519
[Epoch 39] ogbg-moltoxcast: 0.722426 val loss: 0.240290
[Epoch 39] ogbg-moltoxcast: 0.733074 test loss: 0.219110
[Epoch 40; Iter    12/  172] train: loss: 0.2053923
[Epoch 40; Iter    42/  172] train: loss: 0.1286954
[Epoch 40; Iter    72/  172] train: loss: 0.1520853
[Epoch 40; Iter   102/  172] train: loss: 0.1725215
[Epoch 40; Iter   132/  172] train: loss: 0.1818692
[Epoch 40; Iter   162/  172] train: loss: 0.1550290
[Epoch 40] ogbg-moltoxcast: 0.730243 val loss: 0.201387
[Epoch 40] ogbg-moltoxcast: 0.739664 test loss: 0.201584
[Epoch 41; Iter    20/  172] train: loss: 0.1661366
[Epoch 41; Iter    50/  172] train: loss: 0.1280790
[Epoch 41; Iter    80/  172] train: loss: 0.1560932
[Epoch 41; Iter   110/  172] train: loss: 0.1434594
[Epoch 41; Iter   140/  172] train: loss: 0.1253994
[Epoch 41; Iter   170/  172] train: loss: 0.1504977
[Epoch 41] ogbg-moltoxcast: 0.725578 val loss: 0.205656
[Epoch 41] ogbg-moltoxcast: 0.736633 test loss: 0.202917
[Epoch 42; Iter    28/  172] train: loss: 0.2181783
[Epoch 42; Iter    58/  172] train: loss: 0.1356073
[Epoch 42; Iter    88/  172] train: loss: 0.1271948
[Epoch 42; Iter   118/  172] train: loss: 0.1073464
[Epoch 42; Iter   148/  172] train: loss: 0.1970944
[Epoch 42] ogbg-moltoxcast: 0.729393 val loss: 0.265797
[Epoch 42] ogbg-moltoxcast: 0.737243 test loss: 0.223537
[Epoch 43; Iter     6/  172] train: loss: 0.1900782
[Epoch 43; Iter    36/  172] train: loss: 0.2021470
[Epoch 43; Iter    66/  172] train: loss: 0.1680493
[Epoch 43; Iter    96/  172] train: loss: 0.1420867
[Epoch 43; Iter   126/  172] train: loss: 0.1877262
[Epoch 43; Iter   156/  172] train: loss: 0.1015328
[Epoch 43] ogbg-moltoxcast: 0.731584 val loss: 0.204357
[Epoch 43] ogbg-moltoxcast: 0.740068 test loss: 0.202090
[Epoch 44; Iter    14/  172] train: loss: 0.2397086
[Epoch 44; Iter    44/  172] train: loss: 0.1317742
[Epoch 44; Iter    74/  172] train: loss: 0.1799435
[Epoch 44; Iter   104/  172] train: loss: 0.1742311
[Epoch 44; Iter   134/  172] train: loss: 0.1162325
[Epoch 44; Iter   164/  172] train: loss: 0.1862378
[Epoch 44] ogbg-moltoxcast: 0.725183 val loss: 0.206945
[Epoch 44] ogbg-moltoxcast: 0.737347 test loss: 0.203389
[Epoch 45; Iter    22/  172] train: loss: 0.2708777
[Epoch 45; Iter    52/  172] train: loss: 0.1451426
[Epoch 45; Iter    82/  172] train: loss: 0.1575620
[Epoch 45; Iter   112/  172] train: loss: 0.1403666
[Epoch 45; Iter   142/  172] train: loss: 0.1786608
[Epoch 45; Iter   172/  172] train: loss: 0.2129681
[Epoch 45] ogbg-moltoxcast: 0.722507 val loss: 0.297509
[Epoch 45] ogbg-moltoxcast: 0.737508 test loss: 0.232665
[Epoch 46; Iter    30/  172] train: loss: 0.1963561
[Epoch 46; Iter    60/  172] train: loss: 0.1916754
[Epoch 46; Iter    90/  172] train: loss: 0.1560058
[Epoch 46; Iter   120/  172] train: loss: 0.1483389
[Epoch 46; Iter   150/  172] train: loss: 0.2442400
[Epoch 46] ogbg-moltoxcast: 0.719723 val loss: 0.207637
[Epoch 46] ogbg-moltoxcast: 0.735781 test loss: 0.205206
[Epoch 47; Iter     8/  172] train: loss: 0.2615560
[Epoch 47; Iter    38/  172] train: loss: 0.1884515
[Epoch 47; Iter    68/  172] train: loss: 0.1918751
[Epoch 47; Iter    98/  172] train: loss: 0.1650763
[Epoch 47; Iter   128/  172] train: loss: 0.1195754
[Epoch 47; Iter   158/  172] train: loss: 0.1590641
[Epoch 47] ogbg-moltoxcast: 0.732910 val loss: 0.205293
[Epoch 47] ogbg-moltoxcast: 0.742914 test loss: 0.202045
[Epoch 48; Iter    16/  172] train: loss: 0.1588085
[Epoch 48; Iter    46/  172] train: loss: 0.1611659
[Epoch 48; Iter    76/  172] train: loss: 0.1741490
[Epoch 48; Iter   106/  172] train: loss: 0.1299862
[Epoch 48; Iter   136/  172] train: loss: 0.1678151
[Epoch 48; Iter   166/  172] train: loss: 0.1610758
[Epoch 48] ogbg-moltoxcast: 0.728549 val loss: 0.213615
[Epoch 48] ogbg-moltoxcast: 0.739745 test loss: 0.205713
[Epoch 49; Iter    24/  172] train: loss: 0.1821953
[Epoch 49; Iter    54/  172] train: loss: 0.1361151
[Epoch 49; Iter    84/  172] train: loss: 0.1521975
[Epoch 49; Iter   114/  172] train: loss: 0.1055136
[Epoch 49; Iter   144/  172] train: loss: 0.1317572
[Epoch 49] ogbg-moltoxcast: 0.732896 val loss: 0.204562
[Epoch 49] ogbg-moltoxcast: 0.744333 test loss: 0.200928
[Epoch 50; Iter     2/  172] train: loss: 0.1450529
[Epoch 50; Iter    32/  172] train: loss: 0.1088657
[Epoch 50; Iter    62/  172] train: loss: 0.1349811
[Epoch 50; Iter    92/  172] train: loss: 0.1509341
[Epoch 50; Iter   122/  172] train: loss: 0.1481302
[Epoch 50; Iter   152/  172] train: loss: 0.1030587
[Epoch 50] ogbg-moltoxcast: 0.727530 val loss: 0.206435
[Epoch 50] ogbg-moltoxcast: 0.741039 test loss: 0.201881
[Epoch 51; Iter    10/  172] train: loss: 0.1369733
[Epoch 51; Iter    40/  172] train: loss: 0.1821982
[Epoch 51; Iter    70/  172] train: loss: 0.1440599
[Epoch 51; Iter   100/  172] train: loss: 0.1090748
[Epoch 51; Iter   130/  172] train: loss: 0.2151642
[Epoch 51; Iter   160/  172] train: loss: 0.1521369
[Epoch 51] ogbg-moltoxcast: 0.730750 val loss: 0.206120
[Epoch 51] ogbg-moltoxcast: 0.738081 test loss: 0.202841
[Epoch 52; Iter    18/  172] train: loss: 0.1413436
[Epoch 52; Iter    48/  172] train: loss: 0.1324364
[Epoch 52; Iter    78/  172] train: loss: 0.1508867
[Epoch 52; Iter   108/  172] train: loss: 0.1456962
[Epoch 52; Iter   138/  172] train: loss: 0.1445651
[Epoch 52; Iter   168/  172] train: loss: 0.1243505
[Epoch 52] ogbg-moltoxcast: 0.723211 val loss: 0.210475
[Epoch 52] ogbg-moltoxcast: 0.733649 test loss: 0.204847
[Epoch 53; Iter    26/  172] train: loss: 0.1232527
[Epoch 53; Iter    56/  172] train: loss: 0.1930896
[Epoch 53; Iter    86/  172] train: loss: 0.1912693
[Epoch 53; Iter   116/  172] train: loss: 0.2345875
[Epoch 53; Iter   146/  172] train: loss: 0.2695019
[Epoch 53] ogbg-moltoxcast: 0.730505 val loss: 0.205991
[Epoch 53] ogbg-moltoxcast: 0.741151 test loss: 0.206428
[Epoch 54; Iter     4/  172] train: loss: 0.1614058
[Epoch 54; Iter    34/  172] train: loss: 0.1637385
[Epoch 54; Iter    64/  172] train: loss: 0.1256846
[Epoch 54; Iter    94/  172] train: loss: 0.1873224
[Epoch 44; Iter    23/  229] train: loss: 0.1890281
[Epoch 44; Iter    53/  229] train: loss: 0.1493466
[Epoch 44; Iter    83/  229] train: loss: 0.1130424
[Epoch 44; Iter   113/  229] train: loss: 0.2139988
[Epoch 44; Iter   143/  229] train: loss: 0.1463471
[Epoch 44; Iter   173/  229] train: loss: 0.1108031
[Epoch 44; Iter   203/  229] train: loss: 0.1571999
[Epoch 44] ogbg-moltoxcast: 0.748622 val loss: 0.193100
[Epoch 44] ogbg-moltoxcast: 0.761589 test loss: 0.200931
[Epoch 45; Iter     4/  229] train: loss: 0.1939098
[Epoch 45; Iter    34/  229] train: loss: 0.1571309
[Epoch 45; Iter    64/  229] train: loss: 0.1239584
[Epoch 45; Iter    94/  229] train: loss: 0.2282471
[Epoch 45; Iter   124/  229] train: loss: 0.1542917
[Epoch 45; Iter   154/  229] train: loss: 0.1756270
[Epoch 45; Iter   184/  229] train: loss: 0.1772258
[Epoch 45; Iter   214/  229] train: loss: 0.1715476
[Epoch 45] ogbg-moltoxcast: 0.739715 val loss: 0.196549
[Epoch 45] ogbg-moltoxcast: 0.755682 test loss: 0.203481
[Epoch 46; Iter    15/  229] train: loss: 0.1754398
[Epoch 46; Iter    45/  229] train: loss: 0.1653250
[Epoch 46; Iter    75/  229] train: loss: 0.1341495
[Epoch 46; Iter   105/  229] train: loss: 0.1621811
[Epoch 46; Iter   135/  229] train: loss: 0.1469283
[Epoch 46; Iter   165/  229] train: loss: 0.1818570
[Epoch 46; Iter   195/  229] train: loss: 0.1612010
[Epoch 46; Iter   225/  229] train: loss: 0.1475801
[Epoch 46] ogbg-moltoxcast: 0.748199 val loss: 0.194433
[Epoch 46] ogbg-moltoxcast: 0.758366 test loss: 0.204555
[Epoch 47; Iter    26/  229] train: loss: 0.1919546
[Epoch 47; Iter    56/  229] train: loss: 0.1638327
[Epoch 47; Iter    86/  229] train: loss: 0.1991184
[Epoch 47; Iter   116/  229] train: loss: 0.1361164
[Epoch 47; Iter   146/  229] train: loss: 0.1066293
[Epoch 47; Iter   176/  229] train: loss: 0.1697418
[Epoch 47; Iter   206/  229] train: loss: 0.1557809
[Epoch 47] ogbg-moltoxcast: 0.747201 val loss: 0.196129
[Epoch 47] ogbg-moltoxcast: 0.753905 test loss: 0.207457
[Epoch 48; Iter     7/  229] train: loss: 0.1897811
[Epoch 48; Iter    37/  229] train: loss: 0.1479079
[Epoch 48; Iter    67/  229] train: loss: 0.1266826
[Epoch 48; Iter    97/  229] train: loss: 0.1973360
[Epoch 48; Iter   127/  229] train: loss: 0.1632140
[Epoch 48; Iter   157/  229] train: loss: 0.1966767
[Epoch 48; Iter   187/  229] train: loss: 0.1641156
[Epoch 48; Iter   217/  229] train: loss: 0.1261929
[Epoch 48] ogbg-moltoxcast: 0.748962 val loss: 0.196019
[Epoch 48] ogbg-moltoxcast: 0.747156 test loss: 0.211376
[Epoch 49; Iter    18/  229] train: loss: 0.1963506
[Epoch 49; Iter    48/  229] train: loss: 0.1324127
[Epoch 49; Iter    78/  229] train: loss: 0.1595088
[Epoch 49; Iter   108/  229] train: loss: 0.1397100
[Epoch 49; Iter   138/  229] train: loss: 0.1830155
[Epoch 49; Iter   168/  229] train: loss: 0.2468516
[Epoch 49; Iter   198/  229] train: loss: 0.1284733
[Epoch 49; Iter   228/  229] train: loss: 0.1861925
[Epoch 49] ogbg-moltoxcast: 0.752508 val loss: 0.191274
[Epoch 49] ogbg-moltoxcast: 0.760477 test loss: 0.204040
[Epoch 50; Iter    29/  229] train: loss: 0.2130626
[Epoch 50; Iter    59/  229] train: loss: 0.1541888
[Epoch 50; Iter    89/  229] train: loss: 0.1760112
[Epoch 50; Iter   119/  229] train: loss: 0.1718327
[Epoch 50; Iter   149/  229] train: loss: 0.1476509
[Epoch 50; Iter   179/  229] train: loss: 0.1785723
[Epoch 50; Iter   209/  229] train: loss: 0.1367751
[Epoch 50] ogbg-moltoxcast: 0.750820 val loss: 0.194175
[Epoch 50] ogbg-moltoxcast: 0.765579 test loss: 0.201776
[Epoch 51; Iter    10/  229] train: loss: 0.1506139
[Epoch 51; Iter    40/  229] train: loss: 0.1507858
[Epoch 51; Iter    70/  229] train: loss: 0.1148433
[Epoch 51; Iter   100/  229] train: loss: 0.2106158
[Epoch 51; Iter   130/  229] train: loss: 0.1576570
[Epoch 51; Iter   160/  229] train: loss: 0.2050826
[Epoch 51; Iter   190/  229] train: loss: 0.1644165
[Epoch 51; Iter   220/  229] train: loss: 0.1392669
[Epoch 51] ogbg-moltoxcast: 0.749837 val loss: 0.195326
[Epoch 51] ogbg-moltoxcast: 0.756955 test loss: 0.206040
[Epoch 52; Iter    21/  229] train: loss: 0.1785177
[Epoch 52; Iter    51/  229] train: loss: 0.1361360
[Epoch 52; Iter    81/  229] train: loss: 0.1786982
[Epoch 52; Iter   111/  229] train: loss: 0.1584984
[Epoch 52; Iter   141/  229] train: loss: 0.1616153
[Epoch 52; Iter   171/  229] train: loss: 0.1654806
[Epoch 52; Iter   201/  229] train: loss: 0.1100979
[Epoch 52] ogbg-moltoxcast: 0.744456 val loss: 0.198883
[Epoch 52] ogbg-moltoxcast: 0.756335 test loss: 0.202774
[Epoch 53; Iter     2/  229] train: loss: 0.1786269
[Epoch 53; Iter    32/  229] train: loss: 0.2027216
[Epoch 53; Iter    62/  229] train: loss: 0.1717074
[Epoch 53; Iter    92/  229] train: loss: 0.1817142
[Epoch 53; Iter   122/  229] train: loss: 0.1984915
[Epoch 53; Iter   152/  229] train: loss: 0.1049323
[Epoch 53; Iter   182/  229] train: loss: 0.1281588
[Epoch 53; Iter   212/  229] train: loss: 0.1203053
[Epoch 53] ogbg-moltoxcast: 0.749153 val loss: 0.197266
[Epoch 53] ogbg-moltoxcast: 0.753263 test loss: 0.213723
[Epoch 54; Iter    13/  229] train: loss: 0.1517297
[Epoch 54; Iter    43/  229] train: loss: 0.1599251
[Epoch 54; Iter    73/  229] train: loss: 0.1567576
[Epoch 54; Iter   103/  229] train: loss: 0.2177882
[Epoch 54; Iter   133/  229] train: loss: 0.2050184
[Epoch 54; Iter   163/  229] train: loss: 0.1489122
[Epoch 54; Iter   193/  229] train: loss: 0.1345968
[Epoch 54; Iter   223/  229] train: loss: 0.1329492
[Epoch 54] ogbg-moltoxcast: 0.755091 val loss: 0.193123
[Epoch 54] ogbg-moltoxcast: 0.757946 test loss: 0.202211
[Epoch 55; Iter    24/  229] train: loss: 0.1677197
[Epoch 55; Iter    54/  229] train: loss: 0.1917771
[Epoch 55; Iter    84/  229] train: loss: 0.1341505
[Epoch 55; Iter   114/  229] train: loss: 0.0936526
[Epoch 55; Iter   144/  229] train: loss: 0.1770650
[Epoch 55; Iter   174/  229] train: loss: 0.1648944
[Epoch 55; Iter   204/  229] train: loss: 0.1804130
[Epoch 55] ogbg-moltoxcast: 0.746884 val loss: 0.195794
[Epoch 55] ogbg-moltoxcast: 0.747595 test loss: 0.210353
[Epoch 56; Iter     5/  229] train: loss: 0.2468056
[Epoch 56; Iter    35/  229] train: loss: 0.2675411
[Epoch 56; Iter    65/  229] train: loss: 0.1681802
[Epoch 56; Iter    95/  229] train: loss: 0.1514409
[Epoch 56; Iter   125/  229] train: loss: 0.1778710
[Epoch 56; Iter   155/  229] train: loss: 0.1218843
[Epoch 56; Iter   185/  229] train: loss: 0.1547955
[Epoch 56; Iter   215/  229] train: loss: 0.1583244
[Epoch 56] ogbg-moltoxcast: 0.749651 val loss: 0.197605
[Epoch 56] ogbg-moltoxcast: 0.758337 test loss: 0.201112
[Epoch 57; Iter    16/  229] train: loss: 0.1276726
[Epoch 57; Iter    46/  229] train: loss: 0.1916974
[Epoch 57; Iter    76/  229] train: loss: 0.1299148
[Epoch 57; Iter   106/  229] train: loss: 0.1180123
[Epoch 57; Iter   136/  229] train: loss: 0.1771047
[Epoch 57; Iter   166/  229] train: loss: 0.1894413
[Epoch 57; Iter   196/  229] train: loss: 0.1405600
[Epoch 57; Iter   226/  229] train: loss: 0.1558607
[Epoch 57] ogbg-moltoxcast: 0.752238 val loss: 0.196876
[Epoch 57] ogbg-moltoxcast: 0.762555 test loss: 0.198860
[Epoch 58; Iter    27/  229] train: loss: 0.1414421
[Epoch 58; Iter    57/  229] train: loss: 0.0977654
[Epoch 58; Iter    87/  229] train: loss: 0.1558827
[Epoch 58; Iter   117/  229] train: loss: 0.2610653
[Epoch 58; Iter   147/  229] train: loss: 0.1971760
[Epoch 58; Iter   177/  229] train: loss: 0.1147204
[Epoch 58; Iter   207/  229] train: loss: 0.1501278
[Epoch 58] ogbg-moltoxcast: 0.753440 val loss: 0.194910
[Epoch 58] ogbg-moltoxcast: 0.761341 test loss: 0.200611
[Epoch 59; Iter     8/  229] train: loss: 0.1879723
[Epoch 59; Iter    38/  229] train: loss: 0.0925066
[Epoch 59; Iter    68/  229] train: loss: 0.1421139
[Epoch 59; Iter    98/  229] train: loss: 0.1200841
[Epoch 59; Iter   128/  229] train: loss: 0.1854166
[Epoch 59; Iter   158/  229] train: loss: 0.1471101
[Epoch 59; Iter   188/  229] train: loss: 0.1406090
[Epoch 59; Iter   218/  229] train: loss: 0.1340735
[Epoch 59] ogbg-moltoxcast: 0.757185 val loss: 0.195925
[Epoch 59] ogbg-moltoxcast: 0.757299 test loss: 0.206610
[Epoch 44; Iter    23/  229] train: loss: 0.1024674
[Epoch 44; Iter    53/  229] train: loss: 0.1825619
[Epoch 44; Iter    83/  229] train: loss: 0.1184820
[Epoch 44; Iter   113/  229] train: loss: 0.1713518
[Epoch 44; Iter   143/  229] train: loss: 0.1401878
[Epoch 44; Iter   173/  229] train: loss: 0.1024679
[Epoch 44; Iter   203/  229] train: loss: 0.1578576
[Epoch 44] ogbg-moltoxcast: 0.734877 val loss: 0.196647
[Epoch 44] ogbg-moltoxcast: 0.754027 test loss: 0.204986
[Epoch 45; Iter     4/  229] train: loss: 0.1387582
[Epoch 45; Iter    34/  229] train: loss: 0.1405527
[Epoch 45; Iter    64/  229] train: loss: 0.1185628
[Epoch 45; Iter    94/  229] train: loss: 0.1863011
[Epoch 45; Iter   124/  229] train: loss: 0.1143214
[Epoch 45; Iter   154/  229] train: loss: 0.1614245
[Epoch 45; Iter   184/  229] train: loss: 0.1780841
[Epoch 45; Iter   214/  229] train: loss: 0.1704227
[Epoch 45] ogbg-moltoxcast: 0.738341 val loss: 0.195526
[Epoch 45] ogbg-moltoxcast: 0.758855 test loss: 0.200772
[Epoch 46; Iter    15/  229] train: loss: 0.1814554
[Epoch 46; Iter    45/  229] train: loss: 0.1565805
[Epoch 46; Iter    75/  229] train: loss: 0.1769335
[Epoch 46; Iter   105/  229] train: loss: 0.1685248
[Epoch 46; Iter   135/  229] train: loss: 0.1668668
[Epoch 46; Iter   165/  229] train: loss: 0.1387015
[Epoch 46; Iter   195/  229] train: loss: 0.1198894
[Epoch 46; Iter   225/  229] train: loss: 0.1186571
[Epoch 46] ogbg-moltoxcast: 0.731985 val loss: 0.205732
[Epoch 46] ogbg-moltoxcast: 0.760618 test loss: 0.200825
[Epoch 47; Iter    26/  229] train: loss: 0.1927169
[Epoch 47; Iter    56/  229] train: loss: 0.1616502
[Epoch 47; Iter    86/  229] train: loss: 0.1565476
[Epoch 47; Iter   116/  229] train: loss: 0.2002133
[Epoch 47; Iter   146/  229] train: loss: 0.1039695
[Epoch 47; Iter   176/  229] train: loss: 0.1803505
[Epoch 47; Iter   206/  229] train: loss: 0.2006730
[Epoch 47] ogbg-moltoxcast: 0.738951 val loss: 0.194894
[Epoch 47] ogbg-moltoxcast: 0.761333 test loss: 0.202636
[Epoch 48; Iter     7/  229] train: loss: 0.1953470
[Epoch 48; Iter    37/  229] train: loss: 0.1505941
[Epoch 48; Iter    67/  229] train: loss: 0.1214540
[Epoch 48; Iter    97/  229] train: loss: 0.1904528
[Epoch 48; Iter   127/  229] train: loss: 0.1228948
[Epoch 48; Iter   157/  229] train: loss: 0.1412487
[Epoch 48; Iter   187/  229] train: loss: 0.1740339
[Epoch 48; Iter   217/  229] train: loss: 0.1869919
[Epoch 48] ogbg-moltoxcast: 0.741223 val loss: 0.195621
[Epoch 48] ogbg-moltoxcast: 0.754656 test loss: 0.206765
[Epoch 49; Iter    18/  229] train: loss: 0.1871040
[Epoch 49; Iter    48/  229] train: loss: 0.1447835
[Epoch 49; Iter    78/  229] train: loss: 0.1307280
[Epoch 49; Iter   108/  229] train: loss: 0.1873184
[Epoch 49; Iter   138/  229] train: loss: 0.1558269
[Epoch 49; Iter   168/  229] train: loss: 0.1368399
[Epoch 49; Iter   198/  229] train: loss: 0.2049189
[Epoch 49; Iter   228/  229] train: loss: 0.1724921
[Epoch 49] ogbg-moltoxcast: 0.743242 val loss: 0.197802
[Epoch 49] ogbg-moltoxcast: 0.759282 test loss: 0.205667
[Epoch 50; Iter    29/  229] train: loss: 0.1707923
[Epoch 50; Iter    59/  229] train: loss: 0.2069107
[Epoch 50; Iter    89/  229] train: loss: 0.1690523
[Epoch 50; Iter   119/  229] train: loss: 0.1604031
[Epoch 50; Iter   149/  229] train: loss: 0.1451550
[Epoch 50; Iter   179/  229] train: loss: 0.1409775
[Epoch 50; Iter   209/  229] train: loss: 0.1039098
[Epoch 50] ogbg-moltoxcast: 0.743211 val loss: 0.196814
[Epoch 50] ogbg-moltoxcast: 0.761597 test loss: 0.201017
[Epoch 51; Iter    10/  229] train: loss: 0.1636447
[Epoch 51; Iter    40/  229] train: loss: 0.1441835
[Epoch 51; Iter    70/  229] train: loss: 0.1292243
[Epoch 51; Iter   100/  229] train: loss: 0.1944392
[Epoch 51; Iter   130/  229] train: loss: 0.1726947
[Epoch 51; Iter   160/  229] train: loss: 0.1767208
[Epoch 51; Iter   190/  229] train: loss: 0.1252983
[Epoch 51; Iter   220/  229] train: loss: 0.1819037
[Epoch 51] ogbg-moltoxcast: 0.740722 val loss: 0.205095
[Epoch 51] ogbg-moltoxcast: 0.762960 test loss: 0.210892
[Epoch 52; Iter    21/  229] train: loss: 0.1407628
[Epoch 52; Iter    51/  229] train: loss: 0.1667903
[Epoch 52; Iter    81/  229] train: loss: 0.1355047
[Epoch 52; Iter   111/  229] train: loss: 0.1210534
[Epoch 52; Iter   141/  229] train: loss: 0.1787083
[Epoch 52; Iter   171/  229] train: loss: 0.1537260
[Epoch 52; Iter   201/  229] train: loss: 0.1297535
[Epoch 52] ogbg-moltoxcast: 0.745697 val loss: 0.193174
[Epoch 52] ogbg-moltoxcast: 0.755509 test loss: 0.205013
[Epoch 53; Iter     2/  229] train: loss: 0.1105155
[Epoch 53; Iter    32/  229] train: loss: 0.1464920
[Epoch 53; Iter    62/  229] train: loss: 0.1456006
[Epoch 53; Iter    92/  229] train: loss: 0.2463830
[Epoch 53; Iter   122/  229] train: loss: 0.1741913
[Epoch 53; Iter   152/  229] train: loss: 0.1292569
[Epoch 53; Iter   182/  229] train: loss: 0.1071894
[Epoch 53; Iter   212/  229] train: loss: 0.1531924
[Epoch 53] ogbg-moltoxcast: 0.738998 val loss: 0.201515
[Epoch 53] ogbg-moltoxcast: 0.756849 test loss: 0.207307
[Epoch 54; Iter    13/  229] train: loss: 0.1537886
[Epoch 54; Iter    43/  229] train: loss: 0.0933696
[Epoch 54; Iter    73/  229] train: loss: 0.1385127
[Epoch 54; Iter   103/  229] train: loss: 0.1854677
[Epoch 54; Iter   133/  229] train: loss: 0.1384974
[Epoch 54; Iter   163/  229] train: loss: 0.1293840
[Epoch 54; Iter   193/  229] train: loss: 0.1026992
[Epoch 54; Iter   223/  229] train: loss: 0.1702945
[Epoch 54] ogbg-moltoxcast: 0.744805 val loss: 0.198829
[Epoch 54] ogbg-moltoxcast: 0.763799 test loss: 0.204204
[Epoch 55; Iter    24/  229] train: loss: 0.1492878
[Epoch 55; Iter    54/  229] train: loss: 0.1763484
[Epoch 55; Iter    84/  229] train: loss: 0.1042968
[Epoch 55; Iter   114/  229] train: loss: 0.1156578
[Epoch 55; Iter   144/  229] train: loss: 0.1973917
[Epoch 55; Iter   174/  229] train: loss: 0.1257947
[Epoch 55; Iter   204/  229] train: loss: 0.0826184
[Epoch 55] ogbg-moltoxcast: 0.743788 val loss: 0.197763
[Epoch 55] ogbg-moltoxcast: 0.761648 test loss: 0.205280
[Epoch 56; Iter     5/  229] train: loss: 0.1382680
[Epoch 56; Iter    35/  229] train: loss: 0.1374866
[Epoch 56; Iter    65/  229] train: loss: 0.1556878
[Epoch 56; Iter    95/  229] train: loss: 0.1228898
[Epoch 56; Iter   125/  229] train: loss: 0.2073123
[Epoch 56; Iter   155/  229] train: loss: 0.1751786
[Epoch 56; Iter   185/  229] train: loss: 0.1766878
[Epoch 56; Iter   215/  229] train: loss: 0.1645613
[Epoch 56] ogbg-moltoxcast: 0.741334 val loss: 0.193614
[Epoch 56] ogbg-moltoxcast: 0.752168 test loss: 0.207656
[Epoch 57; Iter    16/  229] train: loss: 0.1581466
[Epoch 57; Iter    46/  229] train: loss: 0.1238672
[Epoch 57; Iter    76/  229] train: loss: 0.1413329
[Epoch 57; Iter   106/  229] train: loss: 0.1820117
[Epoch 57; Iter   136/  229] train: loss: 0.1661911
[Epoch 57; Iter   166/  229] train: loss: 0.2240723
[Epoch 57; Iter   196/  229] train: loss: 0.2108123
[Epoch 57; Iter   226/  229] train: loss: 0.1232074
[Epoch 57] ogbg-moltoxcast: 0.738103 val loss: 0.200668
[Epoch 57] ogbg-moltoxcast: 0.756705 test loss: 0.207184
[Epoch 58; Iter    27/  229] train: loss: 0.1777986
[Epoch 58; Iter    57/  229] train: loss: 0.1401609
[Epoch 58; Iter    87/  229] train: loss: 0.1335230
[Epoch 58; Iter   117/  229] train: loss: 0.1646829
[Epoch 58; Iter   147/  229] train: loss: 0.1609820
[Epoch 58; Iter   177/  229] train: loss: 0.1575316
[Epoch 58; Iter   207/  229] train: loss: 0.1089852
[Epoch 58] ogbg-moltoxcast: 0.737625 val loss: 0.194907
[Epoch 58] ogbg-moltoxcast: 0.756326 test loss: 0.205386
[Epoch 59; Iter     8/  229] train: loss: 0.2186232
[Epoch 59; Iter    38/  229] train: loss: 0.1784024
[Epoch 59; Iter    68/  229] train: loss: 0.1481067
[Epoch 59; Iter    98/  229] train: loss: 0.1305421
[Epoch 59; Iter   128/  229] train: loss: 0.1308769
[Epoch 59; Iter   158/  229] train: loss: 0.1825756
[Epoch 59; Iter   188/  229] train: loss: 0.1559063
[Epoch 59; Iter   218/  229] train: loss: 0.1916703
[Epoch 59] ogbg-moltoxcast: 0.735427 val loss: 0.201451
[Epoch 59] ogbg-moltoxcast: 0.755101 test loss: 0.208929
[Epoch 44; Iter    23/  229] train: loss: 0.1791602
[Epoch 44; Iter    53/  229] train: loss: 0.1538291
[Epoch 44; Iter    83/  229] train: loss: 0.1791925
[Epoch 44; Iter   113/  229] train: loss: 0.1563628
[Epoch 44; Iter   143/  229] train: loss: 0.1686467
[Epoch 44; Iter   173/  229] train: loss: 0.1649907
[Epoch 44; Iter   203/  229] train: loss: 0.1228644
[Epoch 44] ogbg-moltoxcast: 0.738892 val loss: 0.191770
[Epoch 44] ogbg-moltoxcast: 0.759218 test loss: 0.206333
[Epoch 45; Iter     4/  229] train: loss: 0.1076221
[Epoch 45; Iter    34/  229] train: loss: 0.1768958
[Epoch 45; Iter    64/  229] train: loss: 0.1745180
[Epoch 45; Iter    94/  229] train: loss: 0.1600797
[Epoch 45; Iter   124/  229] train: loss: 0.1587407
[Epoch 45; Iter   154/  229] train: loss: 0.2305325
[Epoch 45; Iter   184/  229] train: loss: 0.1105493
[Epoch 45; Iter   214/  229] train: loss: 0.1928594
[Epoch 45] ogbg-moltoxcast: 0.741926 val loss: 0.195858
[Epoch 45] ogbg-moltoxcast: 0.750018 test loss: 0.209528
[Epoch 46; Iter    15/  229] train: loss: 0.1403925
[Epoch 46; Iter    45/  229] train: loss: 0.1650612
[Epoch 46; Iter    75/  229] train: loss: 0.1289552
[Epoch 46; Iter   105/  229] train: loss: 0.1417460
[Epoch 46; Iter   135/  229] train: loss: 0.1076315
[Epoch 46; Iter   165/  229] train: loss: 0.1431414
[Epoch 46; Iter   195/  229] train: loss: 0.1363191
[Epoch 46; Iter   225/  229] train: loss: 0.1962747
[Epoch 46] ogbg-moltoxcast: 0.737361 val loss: 0.195224
[Epoch 46] ogbg-moltoxcast: 0.755253 test loss: 0.209397
[Epoch 47; Iter    26/  229] train: loss: 0.1123713
[Epoch 47; Iter    56/  229] train: loss: 0.1126008
[Epoch 47; Iter    86/  229] train: loss: 0.2021888
[Epoch 47; Iter   116/  229] train: loss: 0.2127906
[Epoch 47; Iter   146/  229] train: loss: 0.1549537
[Epoch 47; Iter   176/  229] train: loss: 0.1648909
[Epoch 47; Iter   206/  229] train: loss: 0.1870649
[Epoch 47] ogbg-moltoxcast: 0.744354 val loss: 0.193075
[Epoch 47] ogbg-moltoxcast: 0.754678 test loss: 0.210793
[Epoch 48; Iter     7/  229] train: loss: 0.2079721
[Epoch 48; Iter    37/  229] train: loss: 0.1654635
[Epoch 48; Iter    67/  229] train: loss: 0.2335599
[Epoch 48; Iter    97/  229] train: loss: 0.1232795
[Epoch 48; Iter   127/  229] train: loss: 0.2055659
[Epoch 48; Iter   157/  229] train: loss: 0.1648919
[Epoch 48; Iter   187/  229] train: loss: 0.1811039
[Epoch 48; Iter   217/  229] train: loss: 0.1666446
[Epoch 48] ogbg-moltoxcast: 0.747592 val loss: 0.191705
[Epoch 48] ogbg-moltoxcast: 0.759186 test loss: 0.208767
[Epoch 49; Iter    18/  229] train: loss: 0.1352793
[Epoch 49; Iter    48/  229] train: loss: 0.1198327
[Epoch 49; Iter    78/  229] train: loss: 0.2228835
[Epoch 49; Iter   108/  229] train: loss: 0.1214540
[Epoch 49; Iter   138/  229] train: loss: 0.1894162
[Epoch 49; Iter   168/  229] train: loss: 0.1972693
[Epoch 49; Iter   198/  229] train: loss: 0.1198525
[Epoch 49; Iter   228/  229] train: loss: 0.1746637
[Epoch 49] ogbg-moltoxcast: 0.738372 val loss: 0.196189
[Epoch 49] ogbg-moltoxcast: 0.759549 test loss: 0.207463
[Epoch 50; Iter    29/  229] train: loss: 0.1674758
[Epoch 50; Iter    59/  229] train: loss: 0.1669492
[Epoch 50; Iter    89/  229] train: loss: 0.2090078
[Epoch 50; Iter   119/  229] train: loss: 0.1352306
[Epoch 50; Iter   149/  229] train: loss: 0.1005620
[Epoch 50; Iter   179/  229] train: loss: 0.1221150
[Epoch 50; Iter   209/  229] train: loss: 0.1895270
[Epoch 50] ogbg-moltoxcast: 0.742315 val loss: 0.195196
[Epoch 50] ogbg-moltoxcast: 0.765626 test loss: 0.203276
[Epoch 51; Iter    10/  229] train: loss: 0.1565035
[Epoch 51; Iter    40/  229] train: loss: 0.1101841
[Epoch 51; Iter    70/  229] train: loss: 0.1498396
[Epoch 51; Iter   100/  229] train: loss: 0.1973603
[Epoch 51; Iter   130/  229] train: loss: 0.2055317
[Epoch 51; Iter   160/  229] train: loss: 0.1202414
[Epoch 51; Iter   190/  229] train: loss: 0.1397452
[Epoch 51; Iter   220/  229] train: loss: 0.1702607
[Epoch 51] ogbg-moltoxcast: 0.738515 val loss: 0.197720
[Epoch 51] ogbg-moltoxcast: 0.756933 test loss: 0.209887
[Epoch 52; Iter    21/  229] train: loss: 0.1415449
[Epoch 52; Iter    51/  229] train: loss: 0.1606116
[Epoch 52; Iter    81/  229] train: loss: 0.1126359
[Epoch 52; Iter   111/  229] train: loss: 0.1531429
[Epoch 52; Iter   141/  229] train: loss: 0.1672523
[Epoch 52; Iter   171/  229] train: loss: 0.1323222
[Epoch 52; Iter   201/  229] train: loss: 0.1585493
[Epoch 52] ogbg-moltoxcast: 0.737681 val loss: 0.195859
[Epoch 52] ogbg-moltoxcast: 0.752414 test loss: 0.211009
[Epoch 53; Iter     2/  229] train: loss: 0.1529058
[Epoch 53; Iter    32/  229] train: loss: 0.1380481
[Epoch 53; Iter    62/  229] train: loss: 0.2622670
[Epoch 53; Iter    92/  229] train: loss: 0.0889319
[Epoch 53; Iter   122/  229] train: loss: 0.1536752
[Epoch 53; Iter   152/  229] train: loss: 0.1496304
[Epoch 53; Iter   182/  229] train: loss: 0.0962410
[Epoch 53; Iter   212/  229] train: loss: 0.1845973
[Epoch 53] ogbg-moltoxcast: 0.735195 val loss: 0.194840
[Epoch 53] ogbg-moltoxcast: 0.759326 test loss: 0.208788
[Epoch 54; Iter    13/  229] train: loss: 0.1439665
[Epoch 54; Iter    43/  229] train: loss: 0.1651068
[Epoch 54; Iter    73/  229] train: loss: 0.1961943
[Epoch 54; Iter   103/  229] train: loss: 0.1216515
[Epoch 54; Iter   133/  229] train: loss: 0.1693222
[Epoch 54; Iter   163/  229] train: loss: 0.2255336
[Epoch 54; Iter   193/  229] train: loss: 0.1439146
[Epoch 54; Iter   223/  229] train: loss: 0.1447177
[Epoch 54] ogbg-moltoxcast: 0.734810 val loss: 0.198344
[Epoch 54] ogbg-moltoxcast: 0.761370 test loss: 0.210234
[Epoch 55; Iter    24/  229] train: loss: 0.1808624
[Epoch 55; Iter    54/  229] train: loss: 0.1482936
[Epoch 55; Iter    84/  229] train: loss: 0.0930407
[Epoch 55; Iter   114/  229] train: loss: 0.2071616
[Epoch 55; Iter   144/  229] train: loss: 0.1530431
[Epoch 55; Iter   174/  229] train: loss: 0.2051327
[Epoch 55; Iter   204/  229] train: loss: 0.1734054
[Epoch 55] ogbg-moltoxcast: 0.738454 val loss: 0.193876
[Epoch 55] ogbg-moltoxcast: 0.757165 test loss: 0.209943
[Epoch 56; Iter     5/  229] train: loss: 0.1738517
[Epoch 56; Iter    35/  229] train: loss: 0.1415650
[Epoch 56; Iter    65/  229] train: loss: 0.1009640
[Epoch 56; Iter    95/  229] train: loss: 0.1264911
[Epoch 56; Iter   125/  229] train: loss: 0.1398220
[Epoch 56; Iter   155/  229] train: loss: 0.1396851
[Epoch 56; Iter   185/  229] train: loss: 0.1662177
[Epoch 56; Iter   215/  229] train: loss: 0.1524823
[Epoch 56] ogbg-moltoxcast: 0.741920 val loss: 0.194048
[Epoch 56] ogbg-moltoxcast: 0.761060 test loss: 0.206630
[Epoch 57; Iter    16/  229] train: loss: 0.2015004
[Epoch 57; Iter    46/  229] train: loss: 0.1760726
[Epoch 57; Iter    76/  229] train: loss: 0.1215597
[Epoch 57; Iter   106/  229] train: loss: 0.1219033
[Epoch 57; Iter   136/  229] train: loss: 0.2234236
[Epoch 57; Iter   166/  229] train: loss: 0.2388115
[Epoch 57; Iter   196/  229] train: loss: 0.0962576
[Epoch 57; Iter   226/  229] train: loss: 0.1153776
[Epoch 57] ogbg-moltoxcast: 0.741092 val loss: 0.195627
[Epoch 57] ogbg-moltoxcast: 0.762649 test loss: 0.209546
[Epoch 58; Iter    27/  229] train: loss: 0.1043046
[Epoch 58; Iter    57/  229] train: loss: 0.1876166
[Epoch 58; Iter    87/  229] train: loss: 0.1367570
[Epoch 58; Iter   117/  229] train: loss: 0.1669575
[Epoch 58; Iter   147/  229] train: loss: 0.1672506
[Epoch 58; Iter   177/  229] train: loss: 0.1401244
[Epoch 58; Iter   207/  229] train: loss: 0.1645146
[Epoch 58] ogbg-moltoxcast: 0.743308 val loss: 0.192667
[Epoch 58] ogbg-moltoxcast: 0.767305 test loss: 0.205319
[Epoch 59; Iter     8/  229] train: loss: 0.1263757
[Epoch 59; Iter    38/  229] train: loss: 0.1367880
[Epoch 59; Iter    68/  229] train: loss: 0.1744109
[Epoch 59; Iter    98/  229] train: loss: 0.1270744
[Epoch 59; Iter   128/  229] train: loss: 0.1508842
[Epoch 59; Iter   158/  229] train: loss: 0.1670928
[Epoch 59; Iter   188/  229] train: loss: 0.1157136
[Epoch 59; Iter   218/  229] train: loss: 0.2304901
[Epoch 59] ogbg-moltoxcast: 0.737675 val loss: 0.193946
[Epoch 59] ogbg-moltoxcast: 0.763461 test loss: 0.207299
[Epoch 48; Iter   183/  201] train: loss: 0.1097356
[Epoch 48] ogbg-moltoxcast: 0.740272 val loss: 0.207248
[Epoch 48] ogbg-moltoxcast: 0.749670 test loss: 0.203444
[Epoch 49; Iter    12/  201] train: loss: 0.1383171
[Epoch 49; Iter    42/  201] train: loss: 0.1817761
[Epoch 49; Iter    72/  201] train: loss: 0.1636215
[Epoch 49; Iter   102/  201] train: loss: 0.1823207
[Epoch 49; Iter   132/  201] train: loss: 0.0999352
[Epoch 49; Iter   162/  201] train: loss: 0.1456103
[Epoch 49; Iter   192/  201] train: loss: 0.1819734
[Epoch 49] ogbg-moltoxcast: 0.739509 val loss: 0.202874
[Epoch 49] ogbg-moltoxcast: 0.753398 test loss: 0.202090
[Epoch 50; Iter    21/  201] train: loss: 0.0801097
[Epoch 50; Iter    51/  201] train: loss: 0.1611938
[Epoch 50; Iter    81/  201] train: loss: 0.1642581
[Epoch 50; Iter   111/  201] train: loss: 0.1598299
[Epoch 50; Iter   141/  201] train: loss: 0.1350509
[Epoch 50; Iter   171/  201] train: loss: 0.1128899
[Epoch 50; Iter   201/  201] train: loss: 0.2557977
[Epoch 50] ogbg-moltoxcast: 0.727695 val loss: 0.209168
[Epoch 50] ogbg-moltoxcast: 0.742741 test loss: 0.208573
[Epoch 51; Iter    30/  201] train: loss: 0.1640445
[Epoch 51; Iter    60/  201] train: loss: 0.2157682
[Epoch 51; Iter    90/  201] train: loss: 0.1699867
[Epoch 51; Iter   120/  201] train: loss: 0.2035749
[Epoch 51; Iter   150/  201] train: loss: 0.1262092
[Epoch 51; Iter   180/  201] train: loss: 0.1652312
[Epoch 51] ogbg-moltoxcast: 0.733788 val loss: 0.207524
[Epoch 51] ogbg-moltoxcast: 0.746059 test loss: 0.204350
[Epoch 52; Iter     9/  201] train: loss: 0.1429274
[Epoch 52; Iter    39/  201] train: loss: 0.1693630
[Epoch 52; Iter    69/  201] train: loss: 0.1513327
[Epoch 52; Iter    99/  201] train: loss: 0.1495143
[Epoch 52; Iter   129/  201] train: loss: 0.1621514
[Epoch 52; Iter   159/  201] train: loss: 0.1227923
[Epoch 52; Iter   189/  201] train: loss: 0.1483811
[Epoch 52] ogbg-moltoxcast: 0.726021 val loss: 0.206184
[Epoch 52] ogbg-moltoxcast: 0.750739 test loss: 0.201463
[Epoch 53; Iter    18/  201] train: loss: 0.1321164
[Epoch 53; Iter    48/  201] train: loss: 0.1311090
[Epoch 53; Iter    78/  201] train: loss: 0.1093928
[Epoch 53; Iter   108/  201] train: loss: 0.1684114
[Epoch 53; Iter   138/  201] train: loss: 0.1738655
[Epoch 53; Iter   168/  201] train: loss: 0.1337399
[Epoch 53; Iter   198/  201] train: loss: 0.1474776
[Epoch 53] ogbg-moltoxcast: 0.734944 val loss: 0.205804
[Epoch 53] ogbg-moltoxcast: 0.757148 test loss: 0.200544
[Epoch 54; Iter    27/  201] train: loss: 0.2146265
[Epoch 54; Iter    57/  201] train: loss: 0.1314421
[Epoch 54; Iter    87/  201] train: loss: 0.1268873
[Epoch 54; Iter   117/  201] train: loss: 0.1896655
[Epoch 54; Iter   147/  201] train: loss: 0.1490062
[Epoch 54; Iter   177/  201] train: loss: 0.1317613
[Epoch 54] ogbg-moltoxcast: 0.724358 val loss: 0.208036
[Epoch 54] ogbg-moltoxcast: 0.753293 test loss: 0.203272
[Epoch 55; Iter     6/  201] train: loss: 0.1380743
[Epoch 55; Iter    36/  201] train: loss: 0.1885292
[Epoch 55; Iter    66/  201] train: loss: 0.1393535
[Epoch 55; Iter    96/  201] train: loss: 0.1437613
[Epoch 55; Iter   126/  201] train: loss: 0.2330316
[Epoch 55; Iter   156/  201] train: loss: 0.1266967
[Epoch 55; Iter   186/  201] train: loss: 0.1778693
[Epoch 55] ogbg-moltoxcast: 0.732056 val loss: 0.208229
[Epoch 55] ogbg-moltoxcast: 0.753484 test loss: 0.204060
[Epoch 56; Iter    15/  201] train: loss: 0.1186411
[Epoch 56; Iter    45/  201] train: loss: 0.1517169
[Epoch 56; Iter    75/  201] train: loss: 0.1252881
[Epoch 56; Iter   105/  201] train: loss: 0.1404442
[Epoch 56; Iter   135/  201] train: loss: 0.1354860
[Epoch 56; Iter   165/  201] train: loss: 0.1512264
[Epoch 56; Iter   195/  201] train: loss: 0.1527839
[Epoch 56] ogbg-moltoxcast: 0.739183 val loss: 0.206567
[Epoch 56] ogbg-moltoxcast: 0.755172 test loss: 0.204407
[Epoch 57; Iter    24/  201] train: loss: 0.1898420
[Epoch 57; Iter    54/  201] train: loss: 0.1828571
[Epoch 57; Iter    84/  201] train: loss: 0.2123581
[Epoch 57; Iter   114/  201] train: loss: 0.1356182
[Epoch 57; Iter   144/  201] train: loss: 0.1232069
[Epoch 57; Iter   174/  201] train: loss: 0.1397943
[Epoch 57] ogbg-moltoxcast: 0.738330 val loss: 0.202111
[Epoch 57] ogbg-moltoxcast: 0.750993 test loss: 0.204389
[Epoch 58; Iter     3/  201] train: loss: 0.1634894
[Epoch 58; Iter    33/  201] train: loss: 0.1106761
[Epoch 58; Iter    63/  201] train: loss: 0.1930263
[Epoch 58; Iter    93/  201] train: loss: 0.1546605
[Epoch 58; Iter   123/  201] train: loss: 0.1506892
[Epoch 58; Iter   153/  201] train: loss: 0.1754978
[Epoch 58; Iter   183/  201] train: loss: 0.1488097
[Epoch 58] ogbg-moltoxcast: 0.736992 val loss: 0.205344
[Epoch 58] ogbg-moltoxcast: 0.754619 test loss: 0.203654
[Epoch 59; Iter    12/  201] train: loss: 0.1756723
[Epoch 59; Iter    42/  201] train: loss: 0.1533540
[Epoch 59; Iter    72/  201] train: loss: 0.0981123
[Epoch 59; Iter   102/  201] train: loss: 0.1576684
[Epoch 59; Iter   132/  201] train: loss: 0.1036839
[Epoch 59; Iter   162/  201] train: loss: 0.0991204
[Epoch 59; Iter   192/  201] train: loss: 0.1091282
[Epoch 59] ogbg-moltoxcast: 0.736482 val loss: 0.206187
[Epoch 59] ogbg-moltoxcast: 0.752738 test loss: 0.202647
[Epoch 60; Iter    21/  201] train: loss: 0.1293857
[Epoch 60; Iter    51/  201] train: loss: 0.1203951
[Epoch 60; Iter    81/  201] train: loss: 0.1917239
[Epoch 60; Iter   111/  201] train: loss: 0.1233158
[Epoch 60; Iter   141/  201] train: loss: 0.1799783
[Epoch 60; Iter   171/  201] train: loss: 0.1499847
[Epoch 60; Iter   201/  201] train: loss: 0.5454942
[Epoch 60] ogbg-moltoxcast: 0.736202 val loss: 0.208330
[Epoch 60] ogbg-moltoxcast: 0.749846 test loss: 0.206273
[Epoch 61; Iter    30/  201] train: loss: 0.2573599
[Epoch 61; Iter    60/  201] train: loss: 0.1282066
[Epoch 61; Iter    90/  201] train: loss: 0.2126354
[Epoch 61; Iter   120/  201] train: loss: 0.1807122
[Epoch 61; Iter   150/  201] train: loss: 0.1093915
[Epoch 61; Iter   180/  201] train: loss: 0.1485960
[Epoch 61] ogbg-moltoxcast: 0.742580 val loss: 0.203104
[Epoch 61] ogbg-moltoxcast: 0.752580 test loss: 0.203746
[Epoch 62; Iter     9/  201] train: loss: 0.1555737
[Epoch 62; Iter    39/  201] train: loss: 0.1447425
[Epoch 62; Iter    69/  201] train: loss: 0.1594348
[Epoch 62; Iter    99/  201] train: loss: 0.1095760
[Epoch 62; Iter   129/  201] train: loss: 0.1319011
[Epoch 62; Iter   159/  201] train: loss: 0.1656938
[Epoch 62; Iter   189/  201] train: loss: 0.1408522
[Epoch 62] ogbg-moltoxcast: 0.741096 val loss: 0.203751
[Epoch 62] ogbg-moltoxcast: 0.752714 test loss: 0.204141
[Epoch 63; Iter    18/  201] train: loss: 0.1016540
[Epoch 63; Iter    48/  201] train: loss: 0.1287566
[Epoch 63; Iter    78/  201] train: loss: 0.1404217
[Epoch 63; Iter   108/  201] train: loss: 0.1507269
[Epoch 63; Iter   138/  201] train: loss: 0.1400261
[Epoch 63; Iter   168/  201] train: loss: 0.1450630
[Epoch 63; Iter   198/  201] train: loss: 0.1149648
[Epoch 63] ogbg-moltoxcast: 0.739766 val loss: 0.202240
[Epoch 63] ogbg-moltoxcast: 0.751854 test loss: 0.202942
[Epoch 64; Iter    27/  201] train: loss: 0.1505606
[Epoch 64; Iter    57/  201] train: loss: 0.1150350
[Epoch 64; Iter    87/  201] train: loss: 0.1527335
[Epoch 64; Iter   117/  201] train: loss: 0.1690390
[Epoch 64; Iter   147/  201] train: loss: 0.2057053
[Epoch 64; Iter   177/  201] train: loss: 0.1135989
[Epoch 64] ogbg-moltoxcast: 0.740061 val loss: 0.204201
[Epoch 64] ogbg-moltoxcast: 0.753307 test loss: 0.203117
[Epoch 65; Iter     6/  201] train: loss: 0.1669869
[Epoch 65; Iter    36/  201] train: loss: 0.1727537
[Epoch 65; Iter    66/  201] train: loss: 0.1024965
[Epoch 65; Iter    96/  201] train: loss: 0.1289661
[Epoch 65; Iter   126/  201] train: loss: 0.1952959
[Epoch 65; Iter   156/  201] train: loss: 0.1256669
[Epoch 65; Iter   186/  201] train: loss: 0.1371594
[Epoch 65] ogbg-moltoxcast: 0.738342 val loss: 0.203812
[Epoch 65] ogbg-moltoxcast: 0.754414 test loss: 0.202396
[Epoch 66; Iter    15/  201] train: loss: 0.2037724
[Epoch 66; Iter    45/  201] train: loss: 0.1260747
[Epoch 66; Iter    75/  201] train: loss: 0.1573006
[Epoch 48; Iter   183/  201] train: loss: 0.1544978
[Epoch 48] ogbg-moltoxcast: 0.729770 val loss: 0.238183
[Epoch 48] ogbg-moltoxcast: 0.751203 test loss: 0.202925
[Epoch 49; Iter    12/  201] train: loss: 0.1713751
[Epoch 49; Iter    42/  201] train: loss: 0.1919000
[Epoch 49; Iter    72/  201] train: loss: 0.1333104
[Epoch 49; Iter   102/  201] train: loss: 0.1736471
[Epoch 49; Iter   132/  201] train: loss: 0.1267256
[Epoch 49; Iter   162/  201] train: loss: 0.1320283
[Epoch 49; Iter   192/  201] train: loss: 0.1509795
[Epoch 49] ogbg-moltoxcast: 0.730391 val loss: 0.205995
[Epoch 49] ogbg-moltoxcast: 0.751777 test loss: 0.203735
[Epoch 50; Iter    21/  201] train: loss: 0.1191596
[Epoch 50; Iter    51/  201] train: loss: 0.1306466
[Epoch 50; Iter    81/  201] train: loss: 0.1199479
[Epoch 50; Iter   111/  201] train: loss: 0.1349408
[Epoch 50; Iter   141/  201] train: loss: 0.1177334
[Epoch 50; Iter   171/  201] train: loss: 0.1207306
[Epoch 50; Iter   201/  201] train: loss: 0.1650728
[Epoch 50] ogbg-moltoxcast: 0.733396 val loss: 0.205678
[Epoch 50] ogbg-moltoxcast: 0.758351 test loss: 0.203055
[Epoch 51; Iter    30/  201] train: loss: 0.1457724
[Epoch 51; Iter    60/  201] train: loss: 0.1376109
[Epoch 51; Iter    90/  201] train: loss: 0.1509014
[Epoch 51; Iter   120/  201] train: loss: 0.1421641
[Epoch 51; Iter   150/  201] train: loss: 0.1320123
[Epoch 51; Iter   180/  201] train: loss: 0.1166670
[Epoch 51] ogbg-moltoxcast: 0.729080 val loss: 0.208796
[Epoch 51] ogbg-moltoxcast: 0.748872 test loss: 0.208674
[Epoch 52; Iter     9/  201] train: loss: 0.1794470
[Epoch 52; Iter    39/  201] train: loss: 0.1439979
[Epoch 52; Iter    69/  201] train: loss: 0.1930019
[Epoch 52; Iter    99/  201] train: loss: 0.1478510
[Epoch 52; Iter   129/  201] train: loss: 0.1968821
[Epoch 52; Iter   159/  201] train: loss: 0.1455026
[Epoch 52; Iter   189/  201] train: loss: 0.1548286
[Epoch 52] ogbg-moltoxcast: 0.719320 val loss: 0.213202
[Epoch 52] ogbg-moltoxcast: 0.751037 test loss: 0.208447
[Epoch 53; Iter    18/  201] train: loss: 0.1880596
[Epoch 53; Iter    48/  201] train: loss: 0.1109217
[Epoch 53; Iter    78/  201] train: loss: 0.1136211
[Epoch 53; Iter   108/  201] train: loss: 0.1267031
[Epoch 53; Iter   138/  201] train: loss: 0.1452980
[Epoch 53; Iter   168/  201] train: loss: 0.1413288
[Epoch 53; Iter   198/  201] train: loss: 0.1837141
[Epoch 53] ogbg-moltoxcast: 0.732476 val loss: 0.208187
[Epoch 53] ogbg-moltoxcast: 0.750800 test loss: 0.203412
[Epoch 54; Iter    27/  201] train: loss: 0.1536638
[Epoch 54; Iter    57/  201] train: loss: 0.1693872
[Epoch 54; Iter    87/  201] train: loss: 0.1470078
[Epoch 54; Iter   117/  201] train: loss: 0.1589320
[Epoch 54; Iter   147/  201] train: loss: 0.1497244
[Epoch 54; Iter   177/  201] train: loss: 0.1676277
[Epoch 54] ogbg-moltoxcast: 0.733496 val loss: 0.206728
[Epoch 54] ogbg-moltoxcast: 0.749383 test loss: 0.205417
[Epoch 55; Iter     6/  201] train: loss: 0.1737846
[Epoch 55; Iter    36/  201] train: loss: 0.1362050
[Epoch 55; Iter    66/  201] train: loss: 0.1840342
[Epoch 55; Iter    96/  201] train: loss: 0.1527963
[Epoch 55; Iter   126/  201] train: loss: 0.1721380
[Epoch 55; Iter   156/  201] train: loss: 0.1780251
[Epoch 55; Iter   186/  201] train: loss: 0.1557035
[Epoch 55] ogbg-moltoxcast: 0.726480 val loss: 0.210748
[Epoch 55] ogbg-moltoxcast: 0.747890 test loss: 0.205894
[Epoch 56; Iter    15/  201] train: loss: 0.1301818
[Epoch 56; Iter    45/  201] train: loss: 0.1607121
[Epoch 56; Iter    75/  201] train: loss: 0.1101868
[Epoch 56; Iter   105/  201] train: loss: 0.1760849
[Epoch 56; Iter   135/  201] train: loss: 0.1389350
[Epoch 56; Iter   165/  201] train: loss: 0.2085525
[Epoch 56; Iter   195/  201] train: loss: 0.1277138
[Epoch 56] ogbg-moltoxcast: 0.733887 val loss: 0.207618
[Epoch 56] ogbg-moltoxcast: 0.755378 test loss: 0.201720
[Epoch 57; Iter    24/  201] train: loss: 0.1681178
[Epoch 57; Iter    54/  201] train: loss: 0.1583135
[Epoch 57; Iter    84/  201] train: loss: 0.1358813
[Epoch 57; Iter   114/  201] train: loss: 0.1092254
[Epoch 57; Iter   144/  201] train: loss: 0.1403364
[Epoch 57; Iter   174/  201] train: loss: 0.1664795
[Epoch 57] ogbg-moltoxcast: 0.728251 val loss: 0.209004
[Epoch 57] ogbg-moltoxcast: 0.748297 test loss: 0.204315
[Epoch 58; Iter     3/  201] train: loss: 0.2027607
[Epoch 58; Iter    33/  201] train: loss: 0.1588717
[Epoch 58; Iter    63/  201] train: loss: 0.1946089
[Epoch 58; Iter    93/  201] train: loss: 0.1606097
[Epoch 58; Iter   123/  201] train: loss: 0.1017786
[Epoch 58; Iter   153/  201] train: loss: 0.1175333
[Epoch 58; Iter   183/  201] train: loss: 0.1047415
[Epoch 58] ogbg-moltoxcast: 0.732978 val loss: 0.212298
[Epoch 58] ogbg-moltoxcast: 0.755081 test loss: 0.204569
[Epoch 59; Iter    12/  201] train: loss: 0.1287211
[Epoch 59; Iter    42/  201] train: loss: 0.2117849
[Epoch 59; Iter    72/  201] train: loss: 0.1553784
[Epoch 59; Iter   102/  201] train: loss: 0.1619124
[Epoch 59; Iter   132/  201] train: loss: 0.1827026
[Epoch 59; Iter   162/  201] train: loss: 0.1696152
[Epoch 59; Iter   192/  201] train: loss: 0.1363551
[Epoch 59] ogbg-moltoxcast: 0.730228 val loss: 0.209364
[Epoch 59] ogbg-moltoxcast: 0.748464 test loss: 0.206791
[Epoch 60; Iter    21/  201] train: loss: 0.1568711
[Epoch 60; Iter    51/  201] train: loss: 0.1394576
[Epoch 60; Iter    81/  201] train: loss: 0.1614795
[Epoch 60; Iter   111/  201] train: loss: 0.1539907
[Epoch 60; Iter   141/  201] train: loss: 0.1332604
[Epoch 60; Iter   171/  201] train: loss: 0.0958416
[Epoch 60; Iter   201/  201] train: loss: 0.0915529
[Epoch 60] ogbg-moltoxcast: 0.729255 val loss: 0.210539
[Epoch 60] ogbg-moltoxcast: 0.755456 test loss: 0.201349
[Epoch 61; Iter    30/  201] train: loss: 0.1031048
[Epoch 61; Iter    60/  201] train: loss: 0.1499364
[Epoch 61; Iter    90/  201] train: loss: 0.1975643
[Epoch 61; Iter   120/  201] train: loss: 0.1449577
[Epoch 61; Iter   150/  201] train: loss: 0.1074674
[Epoch 61; Iter   180/  201] train: loss: 0.1787294
[Epoch 61] ogbg-moltoxcast: 0.729071 val loss: 0.210151
[Epoch 61] ogbg-moltoxcast: 0.748494 test loss: 0.205320
[Epoch 62; Iter     9/  201] train: loss: 0.1368390
[Epoch 62; Iter    39/  201] train: loss: 0.1648198
[Epoch 62; Iter    69/  201] train: loss: 0.1156658
[Epoch 62; Iter    99/  201] train: loss: 0.1628368
[Epoch 62; Iter   129/  201] train: loss: 0.1277491
[Epoch 62; Iter   159/  201] train: loss: 0.1424022
[Epoch 62; Iter   189/  201] train: loss: 0.1436600
[Epoch 62] ogbg-moltoxcast: 0.735591 val loss: 0.209379
[Epoch 62] ogbg-moltoxcast: 0.755099 test loss: 0.202441
[Epoch 63; Iter    18/  201] train: loss: 0.1856154
[Epoch 63; Iter    48/  201] train: loss: 0.1423713
[Epoch 63; Iter    78/  201] train: loss: 0.1670342
[Epoch 63; Iter   108/  201] train: loss: 0.1573498
[Epoch 63; Iter   138/  201] train: loss: 0.1808651
[Epoch 63; Iter   168/  201] train: loss: 0.1812115
[Epoch 63; Iter   198/  201] train: loss: 0.1668372
[Epoch 63] ogbg-moltoxcast: 0.730449 val loss: 0.211098
[Epoch 63] ogbg-moltoxcast: 0.757582 test loss: 0.203333
[Epoch 64; Iter    27/  201] train: loss: 0.1727951
[Epoch 64; Iter    57/  201] train: loss: 0.1891040
[Epoch 64; Iter    87/  201] train: loss: 0.1217862
[Epoch 64; Iter   117/  201] train: loss: 0.1518217
[Epoch 64; Iter   147/  201] train: loss: 0.1543012
[Epoch 64; Iter   177/  201] train: loss: 0.1526359
[Epoch 64] ogbg-moltoxcast: 0.735266 val loss: 0.208382
[Epoch 64] ogbg-moltoxcast: 0.755500 test loss: 0.204933
[Epoch 65; Iter     6/  201] train: loss: 0.1125930
[Epoch 65; Iter    36/  201] train: loss: 0.1654212
[Epoch 65; Iter    66/  201] train: loss: 0.1613608
[Epoch 65; Iter    96/  201] train: loss: 0.1694766
[Epoch 65; Iter   126/  201] train: loss: 0.1646095
[Epoch 65; Iter   156/  201] train: loss: 0.1101228
[Epoch 65; Iter   186/  201] train: loss: 0.1806280
[Epoch 65] ogbg-moltoxcast: 0.733888 val loss: 0.209755
[Epoch 65] ogbg-moltoxcast: 0.754064 test loss: 0.204672
[Epoch 66; Iter    15/  201] train: loss: 0.1200591
[Epoch 66; Iter    45/  201] train: loss: 0.1612829
[Epoch 66; Iter    75/  201] train: loss: 0.0871067
[Epoch 48; Iter   183/  201] train: loss: 0.1440192
[Epoch 48] ogbg-moltoxcast: 0.724615 val loss: 0.206843
[Epoch 48] ogbg-moltoxcast: 0.745391 test loss: 0.207180
[Epoch 49; Iter    12/  201] train: loss: 0.1563009
[Epoch 49; Iter    42/  201] train: loss: 0.1431820
[Epoch 49; Iter    72/  201] train: loss: 0.0988811
[Epoch 49; Iter   102/  201] train: loss: 0.1675837
[Epoch 49; Iter   132/  201] train: loss: 0.1737438
[Epoch 49; Iter   162/  201] train: loss: 0.1698977
[Epoch 49; Iter   192/  201] train: loss: 0.1042089
[Epoch 49] ogbg-moltoxcast: 0.727946 val loss: 0.206259
[Epoch 49] ogbg-moltoxcast: 0.749794 test loss: 0.227953
[Epoch 50; Iter    21/  201] train: loss: 0.1932703
[Epoch 50; Iter    51/  201] train: loss: 0.1619974
[Epoch 50; Iter    81/  201] train: loss: 0.1528186
[Epoch 50; Iter   111/  201] train: loss: 0.1523640
[Epoch 50; Iter   141/  201] train: loss: 0.2219671
[Epoch 50; Iter   171/  201] train: loss: 0.1738151
[Epoch 50; Iter   201/  201] train: loss: 0.2905644
[Epoch 50] ogbg-moltoxcast: 0.725850 val loss: 0.209694
[Epoch 50] ogbg-moltoxcast: 0.743837 test loss: 0.213617
[Epoch 51; Iter    30/  201] train: loss: 0.1647230
[Epoch 51; Iter    60/  201] train: loss: 0.1319216
[Epoch 51; Iter    90/  201] train: loss: 0.1959886
[Epoch 51; Iter   120/  201] train: loss: 0.1492283
[Epoch 51; Iter   150/  201] train: loss: 0.2115893
[Epoch 51; Iter   180/  201] train: loss: 0.2074194
[Epoch 51] ogbg-moltoxcast: 0.728878 val loss: 0.208964
[Epoch 51] ogbg-moltoxcast: 0.749334 test loss: 0.221684
[Epoch 52; Iter     9/  201] train: loss: 0.1551446
[Epoch 52; Iter    39/  201] train: loss: 0.1491194
[Epoch 52; Iter    69/  201] train: loss: 0.1629166
[Epoch 52; Iter    99/  201] train: loss: 0.1801529
[Epoch 52; Iter   129/  201] train: loss: 0.1235244
[Epoch 52; Iter   159/  201] train: loss: 0.1210899
[Epoch 52; Iter   189/  201] train: loss: 0.1726038
[Epoch 52] ogbg-moltoxcast: 0.719921 val loss: 0.211195
[Epoch 52] ogbg-moltoxcast: 0.743067 test loss: 0.217277
[Epoch 53; Iter    18/  201] train: loss: 0.1385519
[Epoch 53; Iter    48/  201] train: loss: 0.1399670
[Epoch 53; Iter    78/  201] train: loss: 0.1988444
[Epoch 53; Iter   108/  201] train: loss: 0.1561881
[Epoch 53; Iter   138/  201] train: loss: 0.1224934
[Epoch 53; Iter   168/  201] train: loss: 0.1725612
[Epoch 53; Iter   198/  201] train: loss: 0.2140425
[Epoch 53] ogbg-moltoxcast: 0.730396 val loss: 0.207105
[Epoch 53] ogbg-moltoxcast: 0.748937 test loss: 0.220788
[Epoch 54; Iter    27/  201] train: loss: 0.1685174
[Epoch 54; Iter    57/  201] train: loss: 0.1648795
[Epoch 54; Iter    87/  201] train: loss: 0.1773446
[Epoch 54; Iter   117/  201] train: loss: 0.1020690
[Epoch 54; Iter   147/  201] train: loss: 0.1322172
[Epoch 54; Iter   177/  201] train: loss: 0.1683544
[Epoch 54] ogbg-moltoxcast: 0.737440 val loss: 0.209982
[Epoch 54] ogbg-moltoxcast: 0.750809 test loss: 0.216697
[Epoch 55; Iter     6/  201] train: loss: 0.1100251
[Epoch 55; Iter    36/  201] train: loss: 0.1288840
[Epoch 55; Iter    66/  201] train: loss: 0.1914011
[Epoch 55; Iter    96/  201] train: loss: 0.1566042
[Epoch 55; Iter   126/  201] train: loss: 0.1690881
[Epoch 55; Iter   156/  201] train: loss: 0.1951791
[Epoch 55; Iter   186/  201] train: loss: 0.2185070
[Epoch 55] ogbg-moltoxcast: 0.733034 val loss: 0.208556
[Epoch 55] ogbg-moltoxcast: 0.753149 test loss: 0.204719
[Epoch 56; Iter    15/  201] train: loss: 0.1826458
[Epoch 56; Iter    45/  201] train: loss: 0.1916738
[Epoch 56; Iter    75/  201] train: loss: 0.2118844
[Epoch 56; Iter   105/  201] train: loss: 0.2028010
[Epoch 56; Iter   135/  201] train: loss: 0.1658468
[Epoch 56; Iter   165/  201] train: loss: 0.1630234
[Epoch 56; Iter   195/  201] train: loss: 0.1409117
[Epoch 56] ogbg-moltoxcast: 0.727531 val loss: 0.216634
[Epoch 56] ogbg-moltoxcast: 0.747984 test loss: 0.211969
[Epoch 57; Iter    24/  201] train: loss: 0.1637729
[Epoch 57; Iter    54/  201] train: loss: 0.1184534
[Epoch 57; Iter    84/  201] train: loss: 0.1662729
[Epoch 57; Iter   114/  201] train: loss: 0.1606919
[Epoch 57; Iter   144/  201] train: loss: 0.1491915
[Epoch 57; Iter   174/  201] train: loss: 0.1476697
[Epoch 57] ogbg-moltoxcast: 0.727752 val loss: 0.216307
[Epoch 57] ogbg-moltoxcast: 0.750493 test loss: 0.214785
[Epoch 58; Iter     3/  201] train: loss: 0.1566378
[Epoch 58; Iter    33/  201] train: loss: 0.1785523
[Epoch 58; Iter    63/  201] train: loss: 0.1076956
[Epoch 58; Iter    93/  201] train: loss: 0.1261414
[Epoch 58; Iter   123/  201] train: loss: 0.1785106
[Epoch 58; Iter   153/  201] train: loss: 0.1473902
[Epoch 58; Iter   183/  201] train: loss: 0.1333874
[Epoch 58] ogbg-moltoxcast: 0.730485 val loss: 0.355397
[Epoch 58] ogbg-moltoxcast: 0.750171 test loss: 0.416767
[Epoch 59; Iter    12/  201] train: loss: 0.1278369
[Epoch 59; Iter    42/  201] train: loss: 0.1152545
[Epoch 59; Iter    72/  201] train: loss: 0.1944648
[Epoch 59; Iter   102/  201] train: loss: 0.1192827
[Epoch 59; Iter   132/  201] train: loss: 0.1317115
[Epoch 59; Iter   162/  201] train: loss: 0.1123173
[Epoch 59; Iter   192/  201] train: loss: 0.1493950
[Epoch 59] ogbg-moltoxcast: 0.729188 val loss: 0.215344
[Epoch 59] ogbg-moltoxcast: 0.748680 test loss: 0.212615
[Epoch 60; Iter    21/  201] train: loss: 0.2077105
[Epoch 60; Iter    51/  201] train: loss: 0.1560838
[Epoch 60; Iter    81/  201] train: loss: 0.2239839
[Epoch 60; Iter   111/  201] train: loss: 0.1650565
[Epoch 60; Iter   141/  201] train: loss: 0.1279825
[Epoch 60; Iter   171/  201] train: loss: 0.1432764
[Epoch 60; Iter   201/  201] train: loss: 0.0490850
[Epoch 60] ogbg-moltoxcast: 0.729771 val loss: 0.218880
[Epoch 60] ogbg-moltoxcast: 0.750887 test loss: 0.217697
[Epoch 61; Iter    30/  201] train: loss: 0.1322902
[Epoch 61; Iter    60/  201] train: loss: 0.1426077
[Epoch 61; Iter    90/  201] train: loss: 0.1964859
[Epoch 61; Iter   120/  201] train: loss: 0.0874958
[Epoch 61; Iter   150/  201] train: loss: 0.1636238
[Epoch 61; Iter   180/  201] train: loss: 0.1680829
[Epoch 61] ogbg-moltoxcast: 0.728288 val loss: 0.214074
[Epoch 61] ogbg-moltoxcast: 0.753433 test loss: 0.206945
[Epoch 62; Iter     9/  201] train: loss: 0.1429869
[Epoch 62; Iter    39/  201] train: loss: 0.1982129
[Epoch 62; Iter    69/  201] train: loss: 0.1219587
[Epoch 62; Iter    99/  201] train: loss: 0.1247379
[Epoch 62; Iter   129/  201] train: loss: 0.1173957
[Epoch 62; Iter   159/  201] train: loss: 0.1412331
[Epoch 62; Iter   189/  201] train: loss: 0.1150631
[Epoch 62] ogbg-moltoxcast: 0.729853 val loss: 0.210961
[Epoch 62] ogbg-moltoxcast: 0.751629 test loss: 0.207244
[Epoch 63; Iter    18/  201] train: loss: 0.1191795
[Epoch 63; Iter    48/  201] train: loss: 0.1263995
[Epoch 63; Iter    78/  201] train: loss: 0.1713924
[Epoch 63; Iter   108/  201] train: loss: 0.1689801
[Epoch 63; Iter   138/  201] train: loss: 0.1491864
[Epoch 63; Iter   168/  201] train: loss: 0.1421701
[Epoch 63; Iter   198/  201] train: loss: 0.1421561
[Epoch 63] ogbg-moltoxcast: 0.726955 val loss: 0.217017
[Epoch 63] ogbg-moltoxcast: 0.749874 test loss: 0.209337
[Epoch 64; Iter    27/  201] train: loss: 0.1567008
[Epoch 64; Iter    57/  201] train: loss: 0.1739572
[Epoch 64; Iter    87/  201] train: loss: 0.1509316
[Epoch 64; Iter   117/  201] train: loss: 0.1225300
[Epoch 64; Iter   147/  201] train: loss: 0.1162170
[Epoch 64; Iter   177/  201] train: loss: 0.1089453
[Epoch 64] ogbg-moltoxcast: 0.729663 val loss: 0.215696
[Epoch 64] ogbg-moltoxcast: 0.751800 test loss: 0.214267
[Epoch 65; Iter     6/  201] train: loss: 0.1067117
[Epoch 65; Iter    36/  201] train: loss: 0.1767387
[Epoch 65; Iter    66/  201] train: loss: 0.1422830
[Epoch 65; Iter    96/  201] train: loss: 0.1564776
[Epoch 65; Iter   126/  201] train: loss: 0.1488893
[Epoch 65; Iter   156/  201] train: loss: 0.0928598
[Epoch 65; Iter   186/  201] train: loss: 0.1186839
[Epoch 65] ogbg-moltoxcast: 0.729774 val loss: 0.251759
[Epoch 65] ogbg-moltoxcast: 0.747916 test loss: 0.266986
[Epoch 66; Iter    15/  201] train: loss: 0.1373067
[Epoch 66; Iter    45/  201] train: loss: 0.1545489
[Epoch 66; Iter    75/  201] train: loss: 0.1251456
[Epoch 54; Iter   124/  172] train: loss: 0.1625429
[Epoch 54; Iter   154/  172] train: loss: 0.1277449
[Epoch 54] ogbg-moltoxcast: 0.724491 val loss: 0.219597
[Epoch 54] ogbg-moltoxcast: 0.736180 test loss: 0.207313
[Epoch 55; Iter    12/  172] train: loss: 0.1508054
[Epoch 55; Iter    42/  172] train: loss: 0.1339165
[Epoch 55; Iter    72/  172] train: loss: 0.1582349
[Epoch 55; Iter   102/  172] train: loss: 0.1394777
[Epoch 55; Iter   132/  172] train: loss: 0.1632579
[Epoch 55; Iter   162/  172] train: loss: 0.1404086
[Epoch 55] ogbg-moltoxcast: 0.726810 val loss: 0.213722
[Epoch 55] ogbg-moltoxcast: 0.740347 test loss: 0.204952
[Epoch 56; Iter    20/  172] train: loss: 0.0966516
[Epoch 56; Iter    50/  172] train: loss: 0.1487052
[Epoch 56; Iter    80/  172] train: loss: 0.1756551
[Epoch 56; Iter   110/  172] train: loss: 0.1475955
[Epoch 56; Iter   140/  172] train: loss: 0.1061939
[Epoch 56; Iter   170/  172] train: loss: 0.1777056
[Epoch 56] ogbg-moltoxcast: 0.728082 val loss: 0.208168
[Epoch 56] ogbg-moltoxcast: 0.739071 test loss: 0.206249
[Epoch 57; Iter    28/  172] train: loss: 0.1696610
[Epoch 57; Iter    58/  172] train: loss: 0.1579589
[Epoch 57; Iter    88/  172] train: loss: 0.1828967
[Epoch 57; Iter   118/  172] train: loss: 0.2187276
[Epoch 57; Iter   148/  172] train: loss: 0.1687268
[Epoch 57] ogbg-moltoxcast: 0.735007 val loss: 0.212756
[Epoch 57] ogbg-moltoxcast: 0.745242 test loss: 0.203914
[Epoch 58; Iter     6/  172] train: loss: 0.1495503
[Epoch 58; Iter    36/  172] train: loss: 0.1514595
[Epoch 58; Iter    66/  172] train: loss: 0.1623359
[Epoch 58; Iter    96/  172] train: loss: 0.1305079
[Epoch 58; Iter   126/  172] train: loss: 0.1663197
[Epoch 58; Iter   156/  172] train: loss: 0.1409679
[Epoch 58] ogbg-moltoxcast: 0.735730 val loss: 0.204822
[Epoch 58] ogbg-moltoxcast: 0.743570 test loss: 0.203289
[Epoch 59; Iter    14/  172] train: loss: 0.1918859
[Epoch 59; Iter    44/  172] train: loss: 0.1562417
[Epoch 59; Iter    74/  172] train: loss: 0.1414514
[Epoch 59; Iter   104/  172] train: loss: 0.1679804
[Epoch 59; Iter   134/  172] train: loss: 0.1005118
[Epoch 59; Iter   164/  172] train: loss: 0.1606089
[Epoch 59] ogbg-moltoxcast: 0.734013 val loss: 0.206967
[Epoch 59] ogbg-moltoxcast: 0.744045 test loss: 0.203124
[Epoch 60; Iter    22/  172] train: loss: 0.2025302
[Epoch 60; Iter    52/  172] train: loss: 0.1280812
[Epoch 60; Iter    82/  172] train: loss: 0.1310581
[Epoch 60; Iter   112/  172] train: loss: 0.0807608
[Epoch 60; Iter   142/  172] train: loss: 0.1341254
[Epoch 60; Iter   172/  172] train: loss: 0.1156010
[Epoch 60] ogbg-moltoxcast: 0.722774 val loss: 0.209110
[Epoch 60] ogbg-moltoxcast: 0.734947 test loss: 0.208243
[Epoch 61; Iter    30/  172] train: loss: 0.1103333
[Epoch 61; Iter    60/  172] train: loss: 0.1348003
[Epoch 61; Iter    90/  172] train: loss: 0.1436191
[Epoch 61; Iter   120/  172] train: loss: 0.1216276
[Epoch 61; Iter   150/  172] train: loss: 0.1511139
[Epoch 61] ogbg-moltoxcast: 0.736970 val loss: 0.205211
[Epoch 61] ogbg-moltoxcast: 0.743074 test loss: 0.204486
[Epoch 62; Iter     8/  172] train: loss: 0.1648537
[Epoch 62; Iter    38/  172] train: loss: 0.1774150
[Epoch 62; Iter    68/  172] train: loss: 0.0903716
[Epoch 62; Iter    98/  172] train: loss: 0.1367985
[Epoch 62; Iter   128/  172] train: loss: 0.1242325
[Epoch 62; Iter   158/  172] train: loss: 0.1425160
[Epoch 62] ogbg-moltoxcast: 0.731406 val loss: 0.204645
[Epoch 62] ogbg-moltoxcast: 0.742081 test loss: 0.203569
[Epoch 63; Iter    16/  172] train: loss: 0.1232192
[Epoch 63; Iter    46/  172] train: loss: 0.1580835
[Epoch 63; Iter    76/  172] train: loss: 0.0929364
[Epoch 63; Iter   106/  172] train: loss: 0.1258043
[Epoch 63; Iter   136/  172] train: loss: 0.1731157
[Epoch 63; Iter   166/  172] train: loss: 0.2020048
[Epoch 63] ogbg-moltoxcast: 0.733212 val loss: 0.206794
[Epoch 63] ogbg-moltoxcast: 0.740851 test loss: 0.204780
[Epoch 64; Iter    24/  172] train: loss: 0.1961661
[Epoch 64; Iter    54/  172] train: loss: 0.1415720
[Epoch 64; Iter    84/  172] train: loss: 0.1355967
[Epoch 64; Iter   114/  172] train: loss: 0.1422256
[Epoch 64; Iter   144/  172] train: loss: 0.1539701
[Epoch 64] ogbg-moltoxcast: 0.737521 val loss: 0.204951
[Epoch 64] ogbg-moltoxcast: 0.745546 test loss: 0.202150
[Epoch 65; Iter     2/  172] train: loss: 0.1844666
[Epoch 65; Iter    32/  172] train: loss: 0.1545523
[Epoch 65; Iter    62/  172] train: loss: 0.2118886
[Epoch 65; Iter    92/  172] train: loss: 0.0923563
[Epoch 65; Iter   122/  172] train: loss: 0.0944107
[Epoch 65; Iter   152/  172] train: loss: 0.0908177
[Epoch 65] ogbg-moltoxcast: 0.734045 val loss: 0.207303
[Epoch 65] ogbg-moltoxcast: 0.743070 test loss: 0.205319
[Epoch 66; Iter    10/  172] train: loss: 0.1035015
[Epoch 66; Iter    40/  172] train: loss: 0.2020741
[Epoch 66; Iter    70/  172] train: loss: 0.2004692
[Epoch 66; Iter   100/  172] train: loss: 0.1234800
[Epoch 66; Iter   130/  172] train: loss: 0.1804893
[Epoch 66; Iter   160/  172] train: loss: 0.1021515
[Epoch 66] ogbg-moltoxcast: 0.734536 val loss: 0.206083
[Epoch 66] ogbg-moltoxcast: 0.742171 test loss: 0.204129
[Epoch 67; Iter    18/  172] train: loss: 0.1481299
[Epoch 67; Iter    48/  172] train: loss: 0.0870926
[Epoch 67; Iter    78/  172] train: loss: 0.1250514
[Epoch 67; Iter   108/  172] train: loss: 0.1207904
[Epoch 67; Iter   138/  172] train: loss: 0.1106067
[Epoch 67; Iter   168/  172] train: loss: 0.1268055
[Epoch 67] ogbg-moltoxcast: 0.738199 val loss: 0.205201
[Epoch 67] ogbg-moltoxcast: 0.746098 test loss: 0.202136
[Epoch 68; Iter    26/  172] train: loss: 0.1682467
[Epoch 68; Iter    56/  172] train: loss: 0.1416180
[Epoch 68; Iter    86/  172] train: loss: 0.1281166
[Epoch 68; Iter   116/  172] train: loss: 0.1824951
[Epoch 68; Iter   146/  172] train: loss: 0.1898910
[Epoch 68] ogbg-moltoxcast: 0.734537 val loss: 0.206686
[Epoch 68] ogbg-moltoxcast: 0.745850 test loss: 0.203952
[Epoch 69; Iter     4/  172] train: loss: 0.1879943
[Epoch 69; Iter    34/  172] train: loss: 0.1618803
[Epoch 69; Iter    64/  172] train: loss: 0.1719861
[Epoch 69; Iter    94/  172] train: loss: 0.1515733
[Epoch 69; Iter   124/  172] train: loss: 0.1046530
[Epoch 69; Iter   154/  172] train: loss: 0.1362964
[Epoch 69] ogbg-moltoxcast: 0.735827 val loss: 0.206831
[Epoch 69] ogbg-moltoxcast: 0.746512 test loss: 0.202967
[Epoch 70; Iter    12/  172] train: loss: 0.1127090
[Epoch 70; Iter    42/  172] train: loss: 0.1559402
[Epoch 70; Iter    72/  172] train: loss: 0.1348032
[Epoch 70; Iter   102/  172] train: loss: 0.1395762
[Epoch 70; Iter   132/  172] train: loss: 0.1649484
[Epoch 70; Iter   162/  172] train: loss: 0.1572741
[Epoch 70] ogbg-moltoxcast: 0.737891 val loss: 0.206969
[Epoch 70] ogbg-moltoxcast: 0.746342 test loss: 0.204755
[Epoch 71; Iter    20/  172] train: loss: 0.1744318
[Epoch 71; Iter    50/  172] train: loss: 0.1523087
[Epoch 71; Iter    80/  172] train: loss: 0.1143909
[Epoch 71; Iter   110/  172] train: loss: 0.1179109
[Epoch 71; Iter   140/  172] train: loss: 0.1807778
[Epoch 71; Iter   170/  172] train: loss: 0.1837757
[Epoch 71] ogbg-moltoxcast: 0.736961 val loss: 0.208473
[Epoch 71] ogbg-moltoxcast: 0.742094 test loss: 0.205165
[Epoch 72; Iter    28/  172] train: loss: 0.1673168
[Epoch 72; Iter    58/  172] train: loss: 0.1656554
[Epoch 72; Iter    88/  172] train: loss: 0.1501100
[Epoch 72; Iter   118/  172] train: loss: 0.1503685
[Epoch 72; Iter   148/  172] train: loss: 0.1192290
[Epoch 72] ogbg-moltoxcast: 0.733262 val loss: 0.211211
[Epoch 72] ogbg-moltoxcast: 0.737359 test loss: 0.210139
[Epoch 73; Iter     6/  172] train: loss: 0.1158145
[Epoch 73; Iter    36/  172] train: loss: 0.1089941
[Epoch 73; Iter    66/  172] train: loss: 0.1658938
[Epoch 73; Iter    96/  172] train: loss: 0.1058287
[Epoch 73; Iter   126/  172] train: loss: 0.1099776
[Epoch 73; Iter   156/  172] train: loss: 0.1377250
[Epoch 73] ogbg-moltoxcast: 0.737693 val loss: 0.208075
[Epoch 73] ogbg-moltoxcast: 0.742084 test loss: 0.207702
[Epoch 74; Iter    14/  172] train: loss: 0.1322874
[Epoch 74; Iter    44/  172] train: loss: 0.1153273
[Epoch 74; Iter    74/  172] train: loss: 0.1917435
[Epoch 54; Iter   124/  172] train: loss: 0.2008594
[Epoch 54; Iter   154/  172] train: loss: 0.2009922
[Epoch 54] ogbg-moltoxcast: 0.725717 val loss: 0.224223
[Epoch 54] ogbg-moltoxcast: 0.728798 test loss: 0.207500
[Epoch 55; Iter    12/  172] train: loss: 0.1512482
[Epoch 55; Iter    42/  172] train: loss: 0.1319254
[Epoch 55; Iter    72/  172] train: loss: 0.1786904
[Epoch 55; Iter   102/  172] train: loss: 0.1561304
[Epoch 55; Iter   132/  172] train: loss: 0.2032901
[Epoch 55; Iter   162/  172] train: loss: 0.1273301
[Epoch 55] ogbg-moltoxcast: 0.724033 val loss: 0.207406
[Epoch 55] ogbg-moltoxcast: 0.734344 test loss: 0.207541
[Epoch 56; Iter    20/  172] train: loss: 0.1381144
[Epoch 56; Iter    50/  172] train: loss: 0.1172702
[Epoch 56; Iter    80/  172] train: loss: 0.1342171
[Epoch 56; Iter   110/  172] train: loss: 0.1284834
[Epoch 56; Iter   140/  172] train: loss: 0.1709435
[Epoch 56; Iter   170/  172] train: loss: 0.1356341
[Epoch 56] ogbg-moltoxcast: 0.730542 val loss: 0.206131
[Epoch 56] ogbg-moltoxcast: 0.740797 test loss: 0.202410
[Epoch 57; Iter    28/  172] train: loss: 0.1912341
[Epoch 57; Iter    58/  172] train: loss: 0.1431759
[Epoch 57; Iter    88/  172] train: loss: 0.1373630
[Epoch 57; Iter   118/  172] train: loss: 0.1611789
[Epoch 57; Iter   148/  172] train: loss: 0.1424765
[Epoch 57] ogbg-moltoxcast: 0.724673 val loss: 0.208730
[Epoch 57] ogbg-moltoxcast: 0.733732 test loss: 0.207508
[Epoch 58; Iter     6/  172] train: loss: 0.1373294
[Epoch 58; Iter    36/  172] train: loss: 0.1553292
[Epoch 58; Iter    66/  172] train: loss: 0.2319979
[Epoch 58; Iter    96/  172] train: loss: 0.1232120
[Epoch 58; Iter   126/  172] train: loss: 0.1203700
[Epoch 58; Iter   156/  172] train: loss: 0.1585596
[Epoch 58] ogbg-moltoxcast: 0.730828 val loss: 0.208667
[Epoch 58] ogbg-moltoxcast: 0.735369 test loss: 0.208506
[Epoch 59; Iter    14/  172] train: loss: 0.1565597
[Epoch 59; Iter    44/  172] train: loss: 0.2070857
[Epoch 59; Iter    74/  172] train: loss: 0.1541353
[Epoch 59; Iter   104/  172] train: loss: 0.1646614
[Epoch 59; Iter   134/  172] train: loss: 0.1217550
[Epoch 59; Iter   164/  172] train: loss: 0.1137318
[Epoch 59] ogbg-moltoxcast: 0.730366 val loss: 0.205732
[Epoch 59] ogbg-moltoxcast: 0.737771 test loss: 0.205613
[Epoch 60; Iter    22/  172] train: loss: 0.1435317
[Epoch 60; Iter    52/  172] train: loss: 0.1338742
[Epoch 60; Iter    82/  172] train: loss: 0.1616116
[Epoch 60; Iter   112/  172] train: loss: 0.0889438
[Epoch 60; Iter   142/  172] train: loss: 0.1643054
[Epoch 60; Iter   172/  172] train: loss: 0.1176344
[Epoch 60] ogbg-moltoxcast: 0.731291 val loss: 0.207497
[Epoch 60] ogbg-moltoxcast: 0.735073 test loss: 0.205708
[Epoch 61; Iter    30/  172] train: loss: 0.1467171
[Epoch 61; Iter    60/  172] train: loss: 0.1653497
[Epoch 61; Iter    90/  172] train: loss: 0.1457511
[Epoch 61; Iter   120/  172] train: loss: 0.1158176
[Epoch 61; Iter   150/  172] train: loss: 0.1527870
[Epoch 61] ogbg-moltoxcast: 0.726317 val loss: 0.206663
[Epoch 61] ogbg-moltoxcast: 0.734218 test loss: 0.207584
[Epoch 62; Iter     8/  172] train: loss: 0.1524861
[Epoch 62; Iter    38/  172] train: loss: 0.1102772
[Epoch 62; Iter    68/  172] train: loss: 0.1783243
[Epoch 62; Iter    98/  172] train: loss: 0.1644370
[Epoch 62; Iter   128/  172] train: loss: 0.1913534
[Epoch 62; Iter   158/  172] train: loss: 0.1847271
[Epoch 62] ogbg-moltoxcast: 0.729879 val loss: 0.302322
[Epoch 62] ogbg-moltoxcast: 0.735662 test loss: 0.260715
[Epoch 63; Iter    16/  172] train: loss: 0.1084442
[Epoch 63; Iter    46/  172] train: loss: 0.1432318
[Epoch 63; Iter    76/  172] train: loss: 0.2151416
[Epoch 63; Iter   106/  172] train: loss: 0.1177880
[Epoch 63; Iter   136/  172] train: loss: 0.2096822
[Epoch 63; Iter   166/  172] train: loss: 0.1162794
[Epoch 63] ogbg-moltoxcast: 0.729317 val loss: 0.207615
[Epoch 63] ogbg-moltoxcast: 0.734523 test loss: 0.206312
[Epoch 64; Iter    24/  172] train: loss: 0.1019019
[Epoch 64; Iter    54/  172] train: loss: 0.1373321
[Epoch 64; Iter    84/  172] train: loss: 0.1369951
[Epoch 64; Iter   114/  172] train: loss: 0.1645287
[Epoch 64; Iter   144/  172] train: loss: 0.1567766
[Epoch 64] ogbg-moltoxcast: 0.729565 val loss: 0.207900
[Epoch 64] ogbg-moltoxcast: 0.737231 test loss: 0.205722
[Epoch 65; Iter     2/  172] train: loss: 0.1155858
[Epoch 65; Iter    32/  172] train: loss: 0.1596126
[Epoch 65; Iter    62/  172] train: loss: 0.1301755
[Epoch 65; Iter    92/  172] train: loss: 0.1838367
[Epoch 65; Iter   122/  172] train: loss: 0.1364137
[Epoch 65; Iter   152/  172] train: loss: 0.1098430
[Epoch 65] ogbg-moltoxcast: 0.728136 val loss: 0.208448
[Epoch 65] ogbg-moltoxcast: 0.734997 test loss: 0.207016
[Epoch 66; Iter    10/  172] train: loss: 0.1728323
[Epoch 66; Iter    40/  172] train: loss: 0.1781489
[Epoch 66; Iter    70/  172] train: loss: 0.1630047
[Epoch 66; Iter   100/  172] train: loss: 0.1037936
[Epoch 66; Iter   130/  172] train: loss: 0.1578882
[Epoch 66; Iter   160/  172] train: loss: 0.0946434
[Epoch 66] ogbg-moltoxcast: 0.731307 val loss: 0.206847
[Epoch 66] ogbg-moltoxcast: 0.737949 test loss: 0.205785
[Epoch 67; Iter    18/  172] train: loss: 0.1186217
[Epoch 67; Iter    48/  172] train: loss: 0.1118748
[Epoch 67; Iter    78/  172] train: loss: 0.1672340
[Epoch 67; Iter   108/  172] train: loss: 0.1131558
[Epoch 67; Iter   138/  172] train: loss: 0.1256717
[Epoch 67; Iter   168/  172] train: loss: 0.1594622
[Epoch 67] ogbg-moltoxcast: 0.730043 val loss: 0.210304
[Epoch 67] ogbg-moltoxcast: 0.737929 test loss: 0.206621
[Epoch 68; Iter    26/  172] train: loss: 0.1073417
[Epoch 68; Iter    56/  172] train: loss: 0.1712469
[Epoch 68; Iter    86/  172] train: loss: 0.1571474
[Epoch 68; Iter   116/  172] train: loss: 0.1153851
[Epoch 68; Iter   146/  172] train: loss: 0.1509786
[Epoch 68] ogbg-moltoxcast: 0.728632 val loss: 0.209649
[Epoch 68] ogbg-moltoxcast: 0.735316 test loss: 0.207744
[Epoch 69; Iter     4/  172] train: loss: 0.0991472
[Epoch 69; Iter    34/  172] train: loss: 0.1701069
[Epoch 69; Iter    64/  172] train: loss: 0.1173869
[Epoch 69; Iter    94/  172] train: loss: 0.1576991
[Epoch 69; Iter   124/  172] train: loss: 0.1168326
[Epoch 69; Iter   154/  172] train: loss: 0.1585723
[Epoch 69] ogbg-moltoxcast: 0.733466 val loss: 0.214509
[Epoch 69] ogbg-moltoxcast: 0.730657 test loss: 0.228627
[Epoch 70; Iter    12/  172] train: loss: 0.1396973
[Epoch 70; Iter    42/  172] train: loss: 0.1576258
[Epoch 70; Iter    72/  172] train: loss: 0.1563966
[Epoch 70; Iter   102/  172] train: loss: 0.1150990
[Epoch 70; Iter   132/  172] train: loss: 0.1233644
[Epoch 70; Iter   162/  172] train: loss: 0.1366931
[Epoch 70] ogbg-moltoxcast: 0.727378 val loss: 0.211226
[Epoch 70] ogbg-moltoxcast: 0.730408 test loss: 0.209154
[Epoch 71; Iter    20/  172] train: loss: 0.1634494
[Epoch 71; Iter    50/  172] train: loss: 0.0780623
[Epoch 71; Iter    80/  172] train: loss: 0.1654057
[Epoch 71; Iter   110/  172] train: loss: 0.1723420
[Epoch 71; Iter   140/  172] train: loss: 0.1658394
[Epoch 71; Iter   170/  172] train: loss: 0.1532656
[Epoch 71] ogbg-moltoxcast: 0.731009 val loss: 0.212477
[Epoch 71] ogbg-moltoxcast: 0.733155 test loss: 0.213028
[Epoch 72; Iter    28/  172] train: loss: 0.1666432
[Epoch 72; Iter    58/  172] train: loss: 0.1193594
[Epoch 72; Iter    88/  172] train: loss: 0.1244031
[Epoch 72; Iter   118/  172] train: loss: 0.1377095
[Epoch 72; Iter   148/  172] train: loss: 0.1497215
[Epoch 72] ogbg-moltoxcast: 0.727384 val loss: 0.212583
[Epoch 72] ogbg-moltoxcast: 0.733650 test loss: 0.210775
[Epoch 73; Iter     6/  172] train: loss: 0.1160748
[Epoch 73; Iter    36/  172] train: loss: 0.1415322
[Epoch 73; Iter    66/  172] train: loss: 0.1110568
[Epoch 73; Iter    96/  172] train: loss: 0.1114931
[Epoch 73; Iter   126/  172] train: loss: 0.1143970
[Epoch 73; Iter   156/  172] train: loss: 0.1750156
[Epoch 73] ogbg-moltoxcast: 0.728987 val loss: 0.212665
[Epoch 73] ogbg-moltoxcast: 0.732429 test loss: 0.210892
[Epoch 74; Iter    14/  172] train: loss: 0.1570172
[Epoch 74; Iter    44/  172] train: loss: 0.1630101
[Epoch 74; Iter    74/  172] train: loss: 0.1425112
[Epoch 54; Iter   124/  172] train: loss: 0.1485182
[Epoch 54; Iter   154/  172] train: loss: 0.1857773
[Epoch 54] ogbg-moltoxcast: 0.727166 val loss: 0.211309
[Epoch 54] ogbg-moltoxcast: 0.742960 test loss: 0.206473
[Epoch 55; Iter    12/  172] train: loss: 0.1628506
[Epoch 55; Iter    42/  172] train: loss: 0.1259068
[Epoch 55; Iter    72/  172] train: loss: 0.1638157
[Epoch 55; Iter   102/  172] train: loss: 0.1456796
[Epoch 55; Iter   132/  172] train: loss: 0.1452424
[Epoch 55; Iter   162/  172] train: loss: 0.1316358
[Epoch 55] ogbg-moltoxcast: 0.736787 val loss: 0.206180
[Epoch 55] ogbg-moltoxcast: 0.745139 test loss: 0.205329
[Epoch 56; Iter    20/  172] train: loss: 0.1348942
[Epoch 56; Iter    50/  172] train: loss: 0.1765290
[Epoch 56; Iter    80/  172] train: loss: 0.1516003
[Epoch 56; Iter   110/  172] train: loss: 0.1858507
[Epoch 56; Iter   140/  172] train: loss: 0.1768160
[Epoch 56; Iter   170/  172] train: loss: 0.1606694
[Epoch 56] ogbg-moltoxcast: 0.729570 val loss: 0.207731
[Epoch 56] ogbg-moltoxcast: 0.740204 test loss: 0.205978
[Epoch 57; Iter    28/  172] train: loss: 0.1593852
[Epoch 57; Iter    58/  172] train: loss: 0.1139767
[Epoch 57; Iter    88/  172] train: loss: 0.1161008
[Epoch 57; Iter   118/  172] train: loss: 0.1933228
[Epoch 57; Iter   148/  172] train: loss: 0.1460627
[Epoch 57] ogbg-moltoxcast: 0.730105 val loss: 0.208867
[Epoch 57] ogbg-moltoxcast: 0.738852 test loss: 0.208801
[Epoch 58; Iter     6/  172] train: loss: 0.1565276
[Epoch 58; Iter    36/  172] train: loss: 0.1247037
[Epoch 58; Iter    66/  172] train: loss: 0.1651562
[Epoch 58; Iter    96/  172] train: loss: 0.1419857
[Epoch 58; Iter   126/  172] train: loss: 0.1057490
[Epoch 58; Iter   156/  172] train: loss: 0.1943245
[Epoch 58] ogbg-moltoxcast: 0.723279 val loss: 0.215827
[Epoch 58] ogbg-moltoxcast: 0.735805 test loss: 0.215316
[Epoch 59; Iter    14/  172] train: loss: 0.2115076
[Epoch 59; Iter    44/  172] train: loss: 0.1471053
[Epoch 59; Iter    74/  172] train: loss: 0.1767612
[Epoch 59; Iter   104/  172] train: loss: 0.1550012
[Epoch 59; Iter   134/  172] train: loss: 0.1492215
[Epoch 59; Iter   164/  172] train: loss: 0.1161586
[Epoch 59] ogbg-moltoxcast: 0.726802 val loss: 0.210757
[Epoch 59] ogbg-moltoxcast: 0.740311 test loss: 0.206874
[Epoch 60; Iter    22/  172] train: loss: 0.1502281
[Epoch 60; Iter    52/  172] train: loss: 0.1640261
[Epoch 60; Iter    82/  172] train: loss: 0.1143342
[Epoch 60; Iter   112/  172] train: loss: 0.1685041
[Epoch 60; Iter   142/  172] train: loss: 0.1509435
[Epoch 60; Iter   172/  172] train: loss: 0.0843426
[Epoch 60] ogbg-moltoxcast: 0.724659 val loss: 0.212376
[Epoch 60] ogbg-moltoxcast: 0.742240 test loss: 0.208264
[Epoch 61; Iter    30/  172] train: loss: 0.1504335
[Epoch 61; Iter    60/  172] train: loss: 0.1458308
[Epoch 61; Iter    90/  172] train: loss: 0.1556280
[Epoch 61; Iter   120/  172] train: loss: 0.1587102
[Epoch 61; Iter   150/  172] train: loss: 0.1093735
[Epoch 61] ogbg-moltoxcast: 0.729899 val loss: 0.211215
[Epoch 61] ogbg-moltoxcast: 0.743031 test loss: 0.207748
[Epoch 62; Iter     8/  172] train: loss: 0.1252967
[Epoch 62; Iter    38/  172] train: loss: 0.1177299
[Epoch 62; Iter    68/  172] train: loss: 0.0988016
[Epoch 62; Iter    98/  172] train: loss: 0.1444504
[Epoch 62; Iter   128/  172] train: loss: 0.1269386
[Epoch 62; Iter   158/  172] train: loss: 0.1263333
[Epoch 62] ogbg-moltoxcast: 0.726148 val loss: 0.212197
[Epoch 62] ogbg-moltoxcast: 0.735980 test loss: 0.209599
[Epoch 63; Iter    16/  172] train: loss: 0.1412478
[Epoch 63; Iter    46/  172] train: loss: 0.0986741
[Epoch 63; Iter    76/  172] train: loss: 0.1872316
[Epoch 63; Iter   106/  172] train: loss: 0.1247611
[Epoch 63; Iter   136/  172] train: loss: 0.1084172
[Epoch 63; Iter   166/  172] train: loss: 0.1505389
[Epoch 63] ogbg-moltoxcast: 0.729040 val loss: 0.212797
[Epoch 63] ogbg-moltoxcast: 0.747415 test loss: 0.206799
[Epoch 64; Iter    24/  172] train: loss: 0.1269738
[Epoch 64; Iter    54/  172] train: loss: 0.1001265
[Epoch 64; Iter    84/  172] train: loss: 0.1087994
[Epoch 64; Iter   114/  172] train: loss: 0.1204403
[Epoch 64; Iter   144/  172] train: loss: 0.1006757
[Epoch 64] ogbg-moltoxcast: 0.729382 val loss: 0.210856
[Epoch 64] ogbg-moltoxcast: 0.744908 test loss: 0.205963
[Epoch 65; Iter     2/  172] train: loss: 0.1160649
[Epoch 65; Iter    32/  172] train: loss: 0.0896262
[Epoch 65; Iter    62/  172] train: loss: 0.1392839
[Epoch 65; Iter    92/  172] train: loss: 0.1540627
[Epoch 65; Iter   122/  172] train: loss: 0.1134064
[Epoch 65; Iter   152/  172] train: loss: 0.1567808
[Epoch 65] ogbg-moltoxcast: 0.730482 val loss: 0.210149
[Epoch 65] ogbg-moltoxcast: 0.741710 test loss: 0.206610
[Epoch 66; Iter    10/  172] train: loss: 0.1309280
[Epoch 66; Iter    40/  172] train: loss: 0.1517960
[Epoch 66; Iter    70/  172] train: loss: 0.1112359
[Epoch 66; Iter   100/  172] train: loss: 0.1139563
[Epoch 66; Iter   130/  172] train: loss: 0.1771097
[Epoch 66; Iter   160/  172] train: loss: 0.1759673
[Epoch 66] ogbg-moltoxcast: 0.730222 val loss: 0.209371
[Epoch 66] ogbg-moltoxcast: 0.743176 test loss: 0.206373
[Epoch 67; Iter    18/  172] train: loss: 0.1110933
[Epoch 67; Iter    48/  172] train: loss: 0.1570316
[Epoch 67; Iter    78/  172] train: loss: 0.1925073
[Epoch 67; Iter   108/  172] train: loss: 0.1009876
[Epoch 67; Iter   138/  172] train: loss: 0.1367117
[Epoch 67; Iter   168/  172] train: loss: 0.0825178
[Epoch 67] ogbg-moltoxcast: 0.733164 val loss: 0.211793
[Epoch 67] ogbg-moltoxcast: 0.740787 test loss: 0.211291
[Epoch 68; Iter    26/  172] train: loss: 0.1158086
[Epoch 68; Iter    56/  172] train: loss: 0.1327556
[Epoch 68; Iter    86/  172] train: loss: 0.1276320
[Epoch 68; Iter   116/  172] train: loss: 0.1280321
[Epoch 68; Iter   146/  172] train: loss: 0.0986361
[Epoch 68] ogbg-moltoxcast: 0.729630 val loss: 0.216811
[Epoch 68] ogbg-moltoxcast: 0.737174 test loss: 0.215862
[Epoch 69; Iter     4/  172] train: loss: 0.1525073
[Epoch 69; Iter    34/  172] train: loss: 0.1341758
[Epoch 69; Iter    64/  172] train: loss: 0.1722956
[Epoch 69; Iter    94/  172] train: loss: 0.1821681
[Epoch 69; Iter   124/  172] train: loss: 0.1305331
[Epoch 69; Iter   154/  172] train: loss: 0.1064015
[Epoch 69] ogbg-moltoxcast: 0.729403 val loss: 0.211155
[Epoch 69] ogbg-moltoxcast: 0.742627 test loss: 0.208745
[Epoch 70; Iter    12/  172] train: loss: 0.1264950
[Epoch 70; Iter    42/  172] train: loss: 0.0960845
[Epoch 70; Iter    72/  172] train: loss: 0.1863106
[Epoch 70; Iter   102/  172] train: loss: 0.1338479
[Epoch 70; Iter   132/  172] train: loss: 0.1561072
[Epoch 70; Iter   162/  172] train: loss: 0.1297396
[Epoch 70] ogbg-moltoxcast: 0.727000 val loss: 0.214789
[Epoch 70] ogbg-moltoxcast: 0.738106 test loss: 0.213045
[Epoch 71; Iter    20/  172] train: loss: 0.1021105
[Epoch 71; Iter    50/  172] train: loss: 0.1256877
[Epoch 71; Iter    80/  172] train: loss: 0.1692653
[Epoch 71; Iter   110/  172] train: loss: 0.1395319
[Epoch 71; Iter   140/  172] train: loss: 0.1378068
[Epoch 71; Iter   170/  172] train: loss: 0.0781459
[Epoch 71] ogbg-moltoxcast: 0.728677 val loss: 0.213104
[Epoch 71] ogbg-moltoxcast: 0.742438 test loss: 0.209393
[Epoch 72; Iter    28/  172] train: loss: 0.1255063
[Epoch 72; Iter    58/  172] train: loss: 0.1511904
[Epoch 72; Iter    88/  172] train: loss: 0.1118593
[Epoch 72; Iter   118/  172] train: loss: 0.1156466
[Epoch 72; Iter   148/  172] train: loss: 0.1259461
[Epoch 72] ogbg-moltoxcast: 0.727099 val loss: 0.218743
[Epoch 72] ogbg-moltoxcast: 0.740648 test loss: 0.214924
[Epoch 73; Iter     6/  172] train: loss: 0.1796718
[Epoch 73; Iter    36/  172] train: loss: 0.1505301
[Epoch 73; Iter    66/  172] train: loss: 0.1436444
[Epoch 73; Iter    96/  172] train: loss: 0.1422827
[Epoch 73; Iter   126/  172] train: loss: 0.1190340
[Epoch 73; Iter   156/  172] train: loss: 0.1567199
[Epoch 73] ogbg-moltoxcast: 0.733732 val loss: 0.213513
[Epoch 73] ogbg-moltoxcast: 0.742986 test loss: 0.212911
[Epoch 74; Iter    14/  172] train: loss: 0.1319511
[Epoch 74; Iter    44/  172] train: loss: 0.1456097
[Epoch 74; Iter    74/  172] train: loss: 0.1035154
[Epoch 60; Iter    19/  229] train: loss: 0.1520156
[Epoch 60; Iter    49/  229] train: loss: 0.1875364
[Epoch 60; Iter    79/  229] train: loss: 0.1125086
[Epoch 60; Iter   109/  229] train: loss: 0.1394137
[Epoch 60; Iter   139/  229] train: loss: 0.1834160
[Epoch 60; Iter   169/  229] train: loss: 0.2594039
[Epoch 60; Iter   199/  229] train: loss: 0.1706222
[Epoch 60; Iter   229/  229] train: loss: 0.1043188
[Epoch 60] ogbg-moltoxcast: 0.739973 val loss: 0.195444
[Epoch 60] ogbg-moltoxcast: 0.745690 test loss: 0.216827
[Epoch 61; Iter    30/  229] train: loss: 0.1734905
[Epoch 61; Iter    60/  229] train: loss: 0.0941446
[Epoch 61; Iter    90/  229] train: loss: 0.1707166
[Epoch 61; Iter   120/  229] train: loss: 0.1820155
[Epoch 61; Iter   150/  229] train: loss: 0.0857965
[Epoch 61; Iter   180/  229] train: loss: 0.1604747
[Epoch 61; Iter   210/  229] train: loss: 0.1051456
[Epoch 61] ogbg-moltoxcast: 0.743306 val loss: 0.194394
[Epoch 61] ogbg-moltoxcast: 0.756347 test loss: 0.206328
[Epoch 62; Iter    11/  229] train: loss: 0.2296216
[Epoch 62; Iter    41/  229] train: loss: 0.1618302
[Epoch 62; Iter    71/  229] train: loss: 0.1308571
[Epoch 62; Iter   101/  229] train: loss: 0.1170727
[Epoch 62; Iter   131/  229] train: loss: 0.1251509
[Epoch 62; Iter   161/  229] train: loss: 0.1960657
[Epoch 62; Iter   191/  229] train: loss: 0.1210251
[Epoch 62; Iter   221/  229] train: loss: 0.1418096
[Epoch 62] ogbg-moltoxcast: 0.740122 val loss: 0.194015
[Epoch 62] ogbg-moltoxcast: 0.759631 test loss: 0.204195
[Epoch 63; Iter    22/  229] train: loss: 0.1289149
[Epoch 63; Iter    52/  229] train: loss: 0.1744339
[Epoch 63; Iter    82/  229] train: loss: 0.1496978
[Epoch 63; Iter   112/  229] train: loss: 0.1490544
[Epoch 63; Iter   142/  229] train: loss: 0.1142984
[Epoch 63; Iter   172/  229] train: loss: 0.1555883
[Epoch 63; Iter   202/  229] train: loss: 0.1095908
[Epoch 63] ogbg-moltoxcast: 0.743765 val loss: 0.194293
[Epoch 63] ogbg-moltoxcast: 0.754296 test loss: 0.207919
[Epoch 64; Iter     3/  229] train: loss: 0.1404647
[Epoch 64; Iter    33/  229] train: loss: 0.1245909
[Epoch 64; Iter    63/  229] train: loss: 0.1389069
[Epoch 64; Iter    93/  229] train: loss: 0.1491788
[Epoch 64; Iter   123/  229] train: loss: 0.1685935
[Epoch 64; Iter   153/  229] train: loss: 0.1789809
[Epoch 64; Iter   183/  229] train: loss: 0.1182458
[Epoch 64; Iter   213/  229] train: loss: 0.1619959
[Epoch 64] ogbg-moltoxcast: 0.740633 val loss: 0.193303
[Epoch 64] ogbg-moltoxcast: 0.754173 test loss: 0.212121
[Epoch 65; Iter    14/  229] train: loss: 0.1578675
[Epoch 65; Iter    44/  229] train: loss: 0.1524230
[Epoch 65; Iter    74/  229] train: loss: 0.1531938
[Epoch 65; Iter   104/  229] train: loss: 0.1347428
[Epoch 65; Iter   134/  229] train: loss: 0.1540320
[Epoch 65; Iter   164/  229] train: loss: 0.1236658
[Epoch 65; Iter   194/  229] train: loss: 0.1308688
[Epoch 65; Iter   224/  229] train: loss: 0.1695974
[Epoch 65] ogbg-moltoxcast: 0.744633 val loss: 0.195110
[Epoch 65] ogbg-moltoxcast: 0.754177 test loss: 0.210886
[Epoch 66; Iter    25/  229] train: loss: 0.1195866
[Epoch 66; Iter    55/  229] train: loss: 0.1497583
[Epoch 66; Iter    85/  229] train: loss: 0.0872546
[Epoch 66; Iter   115/  229] train: loss: 0.1512153
[Epoch 66; Iter   145/  229] train: loss: 0.0947110
[Epoch 66; Iter   175/  229] train: loss: 0.1166592
[Epoch 66; Iter   205/  229] train: loss: 0.1160733
[Epoch 66] ogbg-moltoxcast: 0.743739 val loss: 0.198511
[Epoch 66] ogbg-moltoxcast: 0.755374 test loss: 0.208059
[Epoch 67; Iter     6/  229] train: loss: 0.1652541
[Epoch 67; Iter    36/  229] train: loss: 0.1615085
[Epoch 67; Iter    66/  229] train: loss: 0.1241157
[Epoch 67; Iter    96/  229] train: loss: 0.1402774
[Epoch 67; Iter   126/  229] train: loss: 0.1962541
[Epoch 67; Iter   156/  229] train: loss: 0.1380972
[Epoch 67; Iter   186/  229] train: loss: 0.1593622
[Epoch 67; Iter   216/  229] train: loss: 0.1129239
[Epoch 67] ogbg-moltoxcast: 0.743667 val loss: 0.196079
[Epoch 67] ogbg-moltoxcast: 0.754053 test loss: 0.207861
[Epoch 68; Iter    17/  229] train: loss: 0.1761784
[Epoch 68; Iter    47/  229] train: loss: 0.1075906
[Epoch 68; Iter    77/  229] train: loss: 0.1257119
[Epoch 68; Iter   107/  229] train: loss: 0.1570257
[Epoch 68; Iter   137/  229] train: loss: 0.1344732
[Epoch 68; Iter   167/  229] train: loss: 0.1381879
[Epoch 68; Iter   197/  229] train: loss: 0.1275980
[Epoch 68; Iter   227/  229] train: loss: 0.1174786
[Epoch 68] ogbg-moltoxcast: 0.741959 val loss: 0.195041
[Epoch 68] ogbg-moltoxcast: 0.760747 test loss: 0.207690
[Epoch 69; Iter    28/  229] train: loss: 0.1990994
[Epoch 69; Iter    58/  229] train: loss: 0.0948278
[Epoch 69; Iter    88/  229] train: loss: 0.1338307
[Epoch 69; Iter   118/  229] train: loss: 0.2084173
[Epoch 69; Iter   148/  229] train: loss: 0.1001633
[Epoch 69; Iter   178/  229] train: loss: 0.1250599
[Epoch 69; Iter   208/  229] train: loss: 0.1677459
[Epoch 69] ogbg-moltoxcast: 0.743594 val loss: 0.194661
[Epoch 69] ogbg-moltoxcast: 0.755908 test loss: 0.211182
[Epoch 70; Iter     9/  229] train: loss: 0.1686419
[Epoch 70; Iter    39/  229] train: loss: 0.1594886
[Epoch 70; Iter    69/  229] train: loss: 0.1496737
[Epoch 70; Iter    99/  229] train: loss: 0.1375737
[Epoch 70; Iter   129/  229] train: loss: 0.1107411
[Epoch 70; Iter   159/  229] train: loss: 0.1250727
[Epoch 70; Iter   189/  229] train: loss: 0.1597905
[Epoch 70; Iter   219/  229] train: loss: 0.1457363
[Epoch 70] ogbg-moltoxcast: 0.738723 val loss: 0.200900
[Epoch 70] ogbg-moltoxcast: 0.752027 test loss: 0.212225
[Epoch 71; Iter    20/  229] train: loss: 0.1224208
[Epoch 71; Iter    50/  229] train: loss: 0.1546292
[Epoch 71; Iter    80/  229] train: loss: 0.1534862
[Epoch 71; Iter   110/  229] train: loss: 0.1278934
[Epoch 71; Iter   140/  229] train: loss: 0.1187076
[Epoch 71; Iter   170/  229] train: loss: 0.1311362
[Epoch 71; Iter   200/  229] train: loss: 0.1906603
[Epoch 71] ogbg-moltoxcast: 0.740561 val loss: 0.199703
[Epoch 71] ogbg-moltoxcast: 0.753832 test loss: 0.213140
[Epoch 72; Iter     1/  229] train: loss: 0.1981631
[Epoch 72; Iter    31/  229] train: loss: 0.1497122
[Epoch 72; Iter    61/  229] train: loss: 0.1212277
[Epoch 72; Iter    91/  229] train: loss: 0.1158463
[Epoch 72; Iter   121/  229] train: loss: 0.1334105
[Epoch 72; Iter   151/  229] train: loss: 0.1418508
[Epoch 72; Iter   181/  229] train: loss: 0.1472379
[Epoch 72; Iter   211/  229] train: loss: 0.1487179
[Epoch 72] ogbg-moltoxcast: 0.745129 val loss: 0.199180
[Epoch 72] ogbg-moltoxcast: 0.755202 test loss: 0.212462
[Epoch 73; Iter    12/  229] train: loss: 0.1848411
[Epoch 73; Iter    42/  229] train: loss: 0.1310411
[Epoch 73; Iter    72/  229] train: loss: 0.1192765
[Epoch 73; Iter   102/  229] train: loss: 0.1294413
[Epoch 73; Iter   132/  229] train: loss: 0.1448101
[Epoch 73; Iter   162/  229] train: loss: 0.0955684
[Epoch 73; Iter   192/  229] train: loss: 0.1523857
[Epoch 73; Iter   222/  229] train: loss: 0.1552392
[Epoch 73] ogbg-moltoxcast: 0.743497 val loss: 0.195963
[Epoch 73] ogbg-moltoxcast: 0.755160 test loss: 0.211035
[Epoch 74; Iter    23/  229] train: loss: 0.1708242
[Epoch 74; Iter    53/  229] train: loss: 0.1671626
[Epoch 74; Iter    83/  229] train: loss: 0.1716063
[Epoch 74; Iter   113/  229] train: loss: 0.1495063
[Epoch 74; Iter   143/  229] train: loss: 0.0865454
[Epoch 74; Iter   173/  229] train: loss: 0.1024946
[Epoch 74; Iter   203/  229] train: loss: 0.1415464
[Epoch 74] ogbg-moltoxcast: 0.741692 val loss: 0.248634
[Epoch 74] ogbg-moltoxcast: 0.752062 test loss: 0.222816
[Epoch 75; Iter     4/  229] train: loss: 0.1240622
[Epoch 75; Iter    34/  229] train: loss: 0.1182494
[Epoch 75; Iter    64/  229] train: loss: 0.1758528
[Epoch 75; Iter    94/  229] train: loss: 0.1626222
[Epoch 75; Iter   124/  229] train: loss: 0.1136875
[Epoch 75; Iter   154/  229] train: loss: 0.1768680
[Epoch 75; Iter   184/  229] train: loss: 0.1170391
[Epoch 75; Iter   214/  229] train: loss: 0.1578774
[Epoch 75] ogbg-moltoxcast: 0.739895 val loss: 0.197860
[Epoch 75] ogbg-moltoxcast: 0.755698 test loss: 0.209958
[Epoch 60; Iter    19/  229] train: loss: 0.1174994
[Epoch 60; Iter    49/  229] train: loss: 0.1788259
[Epoch 60; Iter    79/  229] train: loss: 0.1592382
[Epoch 60; Iter   109/  229] train: loss: 0.1773747
[Epoch 60; Iter   139/  229] train: loss: 0.1200794
[Epoch 60; Iter   169/  229] train: loss: 0.1106639
[Epoch 60; Iter   199/  229] train: loss: 0.2103455
[Epoch 60; Iter   229/  229] train: loss: 0.1783905
[Epoch 60] ogbg-moltoxcast: 0.752549 val loss: 0.198755
[Epoch 60] ogbg-moltoxcast: 0.755678 test loss: 0.209547
[Epoch 61; Iter    30/  229] train: loss: 0.1741975
[Epoch 61; Iter    60/  229] train: loss: 0.1158728
[Epoch 61; Iter    90/  229] train: loss: 0.1056973
[Epoch 61; Iter   120/  229] train: loss: 0.1149362
[Epoch 61; Iter   150/  229] train: loss: 0.1353874
[Epoch 61; Iter   180/  229] train: loss: 0.1442562
[Epoch 61; Iter   210/  229] train: loss: 0.1852237
[Epoch 61] ogbg-moltoxcast: 0.753118 val loss: 0.195488
[Epoch 61] ogbg-moltoxcast: 0.761295 test loss: 0.200864
[Epoch 62; Iter    11/  229] train: loss: 0.1795753
[Epoch 62; Iter    41/  229] train: loss: 0.1183134
[Epoch 62; Iter    71/  229] train: loss: 0.1390288
[Epoch 62; Iter   101/  229] train: loss: 0.1705063
[Epoch 62; Iter   131/  229] train: loss: 0.1159750
[Epoch 62; Iter   161/  229] train: loss: 0.1192573
[Epoch 62; Iter   191/  229] train: loss: 0.1661711
[Epoch 62; Iter   221/  229] train: loss: 0.2207522
[Epoch 62] ogbg-moltoxcast: 0.754478 val loss: 0.194953
[Epoch 62] ogbg-moltoxcast: 0.765527 test loss: 0.201974
[Epoch 63; Iter    22/  229] train: loss: 0.1576996
[Epoch 63; Iter    52/  229] train: loss: 0.1568026
[Epoch 63; Iter    82/  229] train: loss: 0.1433697
[Epoch 63; Iter   112/  229] train: loss: 0.1122703
[Epoch 63; Iter   142/  229] train: loss: 0.1761771
[Epoch 63; Iter   172/  229] train: loss: 0.1478601
[Epoch 63; Iter   202/  229] train: loss: 0.1271182
[Epoch 63] ogbg-moltoxcast: 0.755610 val loss: 0.195780
[Epoch 63] ogbg-moltoxcast: 0.763407 test loss: 0.201966
[Epoch 64; Iter     3/  229] train: loss: 0.1586590
[Epoch 64; Iter    33/  229] train: loss: 0.1714804
[Epoch 64; Iter    63/  229] train: loss: 0.1685315
[Epoch 64; Iter    93/  229] train: loss: 0.1842662
[Epoch 64; Iter   123/  229] train: loss: 0.1033839
[Epoch 64; Iter   153/  229] train: loss: 0.1448914
[Epoch 64; Iter   183/  229] train: loss: 0.1304070
[Epoch 64; Iter   213/  229] train: loss: 0.1443744
[Epoch 64] ogbg-moltoxcast: 0.759243 val loss: 0.194411
[Epoch 64] ogbg-moltoxcast: 0.760503 test loss: 0.206988
[Epoch 65; Iter    14/  229] train: loss: 0.1375651
[Epoch 65; Iter    44/  229] train: loss: 0.1028638
[Epoch 65; Iter    74/  229] train: loss: 0.1642527
[Epoch 65; Iter   104/  229] train: loss: 0.1260473
[Epoch 65; Iter   134/  229] train: loss: 0.1595318
[Epoch 65; Iter   164/  229] train: loss: 0.1322658
[Epoch 65; Iter   194/  229] train: loss: 0.1127522
[Epoch 65; Iter   224/  229] train: loss: 0.1534315
[Epoch 65] ogbg-moltoxcast: 0.755227 val loss: 0.195004
[Epoch 65] ogbg-moltoxcast: 0.762044 test loss: 0.205133
[Epoch 66; Iter    25/  229] train: loss: 0.1546614
[Epoch 66; Iter    55/  229] train: loss: 0.1774586
[Epoch 66; Iter    85/  229] train: loss: 0.1077834
[Epoch 66; Iter   115/  229] train: loss: 0.1935320
[Epoch 66; Iter   145/  229] train: loss: 0.1504649
[Epoch 66; Iter   175/  229] train: loss: 0.1632051
[Epoch 66; Iter   205/  229] train: loss: 0.1606010
[Epoch 66] ogbg-moltoxcast: 0.754372 val loss: 0.196156
[Epoch 66] ogbg-moltoxcast: 0.759892 test loss: 0.205690
[Epoch 67; Iter     6/  229] train: loss: 0.1688005
[Epoch 67; Iter    36/  229] train: loss: 0.1364718
[Epoch 67; Iter    66/  229] train: loss: 0.1690697
[Epoch 67; Iter    96/  229] train: loss: 0.1209970
[Epoch 67; Iter   126/  229] train: loss: 0.1885860
[Epoch 67; Iter   156/  229] train: loss: 0.1207340
[Epoch 67; Iter   186/  229] train: loss: 0.1232906
[Epoch 67; Iter   216/  229] train: loss: 0.1523449
[Epoch 67] ogbg-moltoxcast: 0.757749 val loss: 0.195600
[Epoch 67] ogbg-moltoxcast: 0.758190 test loss: 0.203294
[Epoch 68; Iter    17/  229] train: loss: 0.1574688
[Epoch 68; Iter    47/  229] train: loss: 0.1674386
[Epoch 68; Iter    77/  229] train: loss: 0.1908490
[Epoch 68; Iter   107/  229] train: loss: 0.1688129
[Epoch 68; Iter   137/  229] train: loss: 0.1109518
[Epoch 68; Iter   167/  229] train: loss: 0.1361087
[Epoch 68; Iter   197/  229] train: loss: 0.0940994
[Epoch 68; Iter   227/  229] train: loss: 0.1301970
[Epoch 68] ogbg-moltoxcast: 0.761315 val loss: 0.192839
[Epoch 68] ogbg-moltoxcast: 0.761274 test loss: 0.203226
[Epoch 69; Iter    28/  229] train: loss: 0.1211333
[Epoch 69; Iter    58/  229] train: loss: 0.1199020
[Epoch 69; Iter    88/  229] train: loss: 0.1137576
[Epoch 69; Iter   118/  229] train: loss: 0.1144128
[Epoch 69; Iter   148/  229] train: loss: 0.1647684
[Epoch 69; Iter   178/  229] train: loss: 0.1062005
[Epoch 69; Iter   208/  229] train: loss: 0.1659899
[Epoch 69] ogbg-moltoxcast: 0.756098 val loss: 0.196135
[Epoch 69] ogbg-moltoxcast: 0.759381 test loss: 0.205096
[Epoch 70; Iter     9/  229] train: loss: 0.1589122
[Epoch 70; Iter    39/  229] train: loss: 0.1576592
[Epoch 70; Iter    69/  229] train: loss: 0.1098190
[Epoch 70; Iter    99/  229] train: loss: 0.1406173
[Epoch 70; Iter   129/  229] train: loss: 0.1871999
[Epoch 70; Iter   159/  229] train: loss: 0.1092546
[Epoch 70; Iter   189/  229] train: loss: 0.1651746
[Epoch 70; Iter   219/  229] train: loss: 0.1783782
[Epoch 70] ogbg-moltoxcast: 0.758579 val loss: 0.194862
[Epoch 70] ogbg-moltoxcast: 0.762326 test loss: 0.206319
[Epoch 71; Iter    20/  229] train: loss: 0.1404228
[Epoch 71; Iter    50/  229] train: loss: 0.1281607
[Epoch 71; Iter    80/  229] train: loss: 0.1029755
[Epoch 71; Iter   110/  229] train: loss: 0.1196352
[Epoch 71; Iter   140/  229] train: loss: 0.1113137
[Epoch 71; Iter   170/  229] train: loss: 0.1931720
[Epoch 71; Iter   200/  229] train: loss: 0.1362601
[Epoch 71] ogbg-moltoxcast: 0.758832 val loss: 0.196682
[Epoch 71] ogbg-moltoxcast: 0.762579 test loss: 0.202390
[Epoch 72; Iter     1/  229] train: loss: 0.0918375
[Epoch 72; Iter    31/  229] train: loss: 0.1330441
[Epoch 72; Iter    61/  229] train: loss: 0.2188465
[Epoch 72; Iter    91/  229] train: loss: 0.2011621
[Epoch 72; Iter   121/  229] train: loss: 0.1941080
[Epoch 72; Iter   151/  229] train: loss: 0.1177242
[Epoch 72; Iter   181/  229] train: loss: 0.1394167
[Epoch 72; Iter   211/  229] train: loss: 0.1217756
[Epoch 72] ogbg-moltoxcast: 0.757758 val loss: 0.196203
[Epoch 72] ogbg-moltoxcast: 0.763399 test loss: 0.202636
[Epoch 73; Iter    12/  229] train: loss: 0.1371939
[Epoch 73; Iter    42/  229] train: loss: 0.0703044
[Epoch 73; Iter    72/  229] train: loss: 0.1424868
[Epoch 73; Iter   102/  229] train: loss: 0.1505882
[Epoch 73; Iter   132/  229] train: loss: 0.1738236
[Epoch 73; Iter   162/  229] train: loss: 0.1549258
[Epoch 73; Iter   192/  229] train: loss: 0.2114836
[Epoch 73; Iter   222/  229] train: loss: 0.1929906
[Epoch 73] ogbg-moltoxcast: 0.758054 val loss: 0.195176
[Epoch 73] ogbg-moltoxcast: 0.761735 test loss: 0.201898
[Epoch 74; Iter    23/  229] train: loss: 0.1546507
[Epoch 74; Iter    53/  229] train: loss: 0.1441330
[Epoch 74; Iter    83/  229] train: loss: 0.0904844
[Epoch 74; Iter   113/  229] train: loss: 0.1641424
[Epoch 74; Iter   143/  229] train: loss: 0.1477615
[Epoch 74; Iter   173/  229] train: loss: 0.1730783
[Epoch 74; Iter   203/  229] train: loss: 0.1134693
[Epoch 74] ogbg-moltoxcast: 0.762560 val loss: 0.193823
[Epoch 74] ogbg-moltoxcast: 0.759885 test loss: 0.204728
[Epoch 75; Iter     4/  229] train: loss: 0.1402663
[Epoch 75; Iter    34/  229] train: loss: 0.0955697
[Epoch 75; Iter    64/  229] train: loss: 0.1515653
[Epoch 75; Iter    94/  229] train: loss: 0.1648058
[Epoch 75; Iter   124/  229] train: loss: 0.1362526
[Epoch 75; Iter   154/  229] train: loss: 0.1454563
[Epoch 75; Iter   184/  229] train: loss: 0.1581049
[Epoch 75; Iter   214/  229] train: loss: 0.1600338
[Epoch 75] ogbg-moltoxcast: 0.760679 val loss: 0.193812
[Epoch 75] ogbg-moltoxcast: 0.757152 test loss: 0.206581
[Epoch 60; Iter    19/  229] train: loss: 0.1051529
[Epoch 60; Iter    49/  229] train: loss: 0.0852103
[Epoch 60; Iter    79/  229] train: loss: 0.1530317
[Epoch 60; Iter   109/  229] train: loss: 0.2137884
[Epoch 60; Iter   139/  229] train: loss: 0.1822275
[Epoch 60; Iter   169/  229] train: loss: 0.2082976
[Epoch 60; Iter   199/  229] train: loss: 0.1605374
[Epoch 60; Iter   229/  229] train: loss: 0.1583149
[Epoch 60] ogbg-moltoxcast: 0.739494 val loss: 0.196437
[Epoch 60] ogbg-moltoxcast: 0.762659 test loss: 0.213885
[Epoch 61; Iter    30/  229] train: loss: 0.1450777
[Epoch 61; Iter    60/  229] train: loss: 0.1609160
[Epoch 61; Iter    90/  229] train: loss: 0.1437228
[Epoch 61; Iter   120/  229] train: loss: 0.1750993
[Epoch 61; Iter   150/  229] train: loss: 0.1634916
[Epoch 61; Iter   180/  229] train: loss: 0.2083449
[Epoch 61; Iter   210/  229] train: loss: 0.1704660
[Epoch 61] ogbg-moltoxcast: 0.737192 val loss: 0.195323
[Epoch 61] ogbg-moltoxcast: 0.763944 test loss: 0.205681
[Epoch 62; Iter    11/  229] train: loss: 0.1359857
[Epoch 62; Iter    41/  229] train: loss: 0.0858559
[Epoch 62; Iter    71/  229] train: loss: 0.1087280
[Epoch 62; Iter   101/  229] train: loss: 0.1560490
[Epoch 62; Iter   131/  229] train: loss: 0.1635737
[Epoch 62; Iter   161/  229] train: loss: 0.1522199
[Epoch 62; Iter   191/  229] train: loss: 0.1644447
[Epoch 62; Iter   221/  229] train: loss: 0.1195181
[Epoch 62] ogbg-moltoxcast: 0.742282 val loss: 0.193239
[Epoch 62] ogbg-moltoxcast: 0.762929 test loss: 0.207765
[Epoch 63; Iter    22/  229] train: loss: 0.1581654
[Epoch 63; Iter    52/  229] train: loss: 0.1321223
[Epoch 63; Iter    82/  229] train: loss: 0.1319272
[Epoch 63; Iter   112/  229] train: loss: 0.1781669
[Epoch 63; Iter   142/  229] train: loss: 0.1506602
[Epoch 63; Iter   172/  229] train: loss: 0.1826031
[Epoch 63; Iter   202/  229] train: loss: 0.1444454
[Epoch 63] ogbg-moltoxcast: 0.742513 val loss: 0.194119
[Epoch 63] ogbg-moltoxcast: 0.767270 test loss: 0.207884
[Epoch 64; Iter     3/  229] train: loss: 0.1472239
[Epoch 64; Iter    33/  229] train: loss: 0.1472603
[Epoch 64; Iter    63/  229] train: loss: 0.1508907
[Epoch 64; Iter    93/  229] train: loss: 0.1047985
[Epoch 64; Iter   123/  229] train: loss: 0.1005637
[Epoch 64; Iter   153/  229] train: loss: 0.1582503
[Epoch 64; Iter   183/  229] train: loss: 0.1217698
[Epoch 64; Iter   213/  229] train: loss: 0.1312948
[Epoch 64] ogbg-moltoxcast: 0.744565 val loss: 0.194212
[Epoch 64] ogbg-moltoxcast: 0.763461 test loss: 0.208166
[Epoch 65; Iter    14/  229] train: loss: 0.1795790
[Epoch 65; Iter    44/  229] train: loss: 0.1322270
[Epoch 65; Iter    74/  229] train: loss: 0.1384638
[Epoch 65; Iter   104/  229] train: loss: 0.1790143
[Epoch 65; Iter   134/  229] train: loss: 0.1382021
[Epoch 65; Iter   164/  229] train: loss: 0.1317889
[Epoch 65; Iter   194/  229] train: loss: 0.1797658
[Epoch 65; Iter   224/  229] train: loss: 0.1362212
[Epoch 65] ogbg-moltoxcast: 0.744810 val loss: 0.194401
[Epoch 65] ogbg-moltoxcast: 0.763167 test loss: 0.211442
[Epoch 66; Iter    25/  229] train: loss: 0.1554578
[Epoch 66; Iter    55/  229] train: loss: 0.1885328
[Epoch 66; Iter    85/  229] train: loss: 0.1515891
[Epoch 66; Iter   115/  229] train: loss: 0.1258719
[Epoch 66; Iter   145/  229] train: loss: 0.1094618
[Epoch 66; Iter   175/  229] train: loss: 0.1571993
[Epoch 66; Iter   205/  229] train: loss: 0.1736975
[Epoch 66] ogbg-moltoxcast: 0.739322 val loss: 0.192142
[Epoch 66] ogbg-moltoxcast: 0.760128 test loss: 0.208510
[Epoch 67; Iter     6/  229] train: loss: 0.1036737
[Epoch 67; Iter    36/  229] train: loss: 0.1212174
[Epoch 67; Iter    66/  229] train: loss: 0.1558601
[Epoch 67; Iter    96/  229] train: loss: 0.1510218
[Epoch 67; Iter   126/  229] train: loss: 0.1097449
[Epoch 67; Iter   156/  229] train: loss: 0.1246593
[Epoch 67; Iter   186/  229] train: loss: 0.1237054
[Epoch 67; Iter   216/  229] train: loss: 0.1745888
[Epoch 67] ogbg-moltoxcast: 0.742490 val loss: 0.193778
[Epoch 67] ogbg-moltoxcast: 0.767369 test loss: 0.208656
[Epoch 68; Iter    17/  229] train: loss: 0.1573025
[Epoch 68; Iter    47/  229] train: loss: 0.1186075
[Epoch 68; Iter    77/  229] train: loss: 0.1167812
[Epoch 68; Iter   107/  229] train: loss: 0.2184468
[Epoch 68; Iter   137/  229] train: loss: 0.1203473
[Epoch 68; Iter   167/  229] train: loss: 0.1448606
[Epoch 68; Iter   197/  229] train: loss: 0.1833297
[Epoch 68; Iter   227/  229] train: loss: 0.1373246
[Epoch 68] ogbg-moltoxcast: 0.748284 val loss: 0.191482
[Epoch 68] ogbg-moltoxcast: 0.765708 test loss: 0.212378
[Epoch 69; Iter    28/  229] train: loss: 0.1359338
[Epoch 69; Iter    58/  229] train: loss: 0.1978173
[Epoch 69; Iter    88/  229] train: loss: 0.1192094
[Epoch 69; Iter   118/  229] train: loss: 0.1658810
[Epoch 69; Iter   148/  229] train: loss: 0.1518079
[Epoch 69; Iter   178/  229] train: loss: 0.1373406
[Epoch 69; Iter   208/  229] train: loss: 0.1027103
[Epoch 69] ogbg-moltoxcast: 0.741359 val loss: 0.196386
[Epoch 69] ogbg-moltoxcast: 0.768673 test loss: 0.210879
[Epoch 70; Iter     9/  229] train: loss: 0.1419436
[Epoch 70; Iter    39/  229] train: loss: 0.0974709
[Epoch 70; Iter    69/  229] train: loss: 0.1085450
[Epoch 70; Iter    99/  229] train: loss: 0.1957603
[Epoch 70; Iter   129/  229] train: loss: 0.1401770
[Epoch 70; Iter   159/  229] train: loss: 0.2166131
[Epoch 70; Iter   189/  229] train: loss: 0.0940480
[Epoch 70; Iter   219/  229] train: loss: 0.1465173
[Epoch 70] ogbg-moltoxcast: 0.740746 val loss: 0.197641
[Epoch 70] ogbg-moltoxcast: 0.765199 test loss: 0.211336
[Epoch 71; Iter    20/  229] train: loss: 0.1285582
[Epoch 71; Iter    50/  229] train: loss: 0.1748140
[Epoch 71; Iter    80/  229] train: loss: 0.1397704
[Epoch 71; Iter   110/  229] train: loss: 0.1611385
[Epoch 71; Iter   140/  229] train: loss: 0.1613942
[Epoch 71; Iter   170/  229] train: loss: 0.1369586
[Epoch 71; Iter   200/  229] train: loss: 0.1136569
[Epoch 71] ogbg-moltoxcast: 0.743348 val loss: 0.196173
[Epoch 71] ogbg-moltoxcast: 0.769625 test loss: 0.210469
[Epoch 72; Iter     1/  229] train: loss: 0.1663071
[Epoch 72; Iter    31/  229] train: loss: 0.1292934
[Epoch 72; Iter    61/  229] train: loss: 0.0857083
[Epoch 72; Iter    91/  229] train: loss: 0.1499139
[Epoch 72; Iter   121/  229] train: loss: 0.1643718
[Epoch 72; Iter   151/  229] train: loss: 0.1266222
[Epoch 72; Iter   181/  229] train: loss: 0.1813371
[Epoch 72; Iter   211/  229] train: loss: 0.1514200
[Epoch 72] ogbg-moltoxcast: 0.737178 val loss: 0.197720
[Epoch 72] ogbg-moltoxcast: 0.768104 test loss: 0.210214
[Epoch 73; Iter    12/  229] train: loss: 0.1224240
[Epoch 73; Iter    42/  229] train: loss: 0.1336596
[Epoch 73; Iter    72/  229] train: loss: 0.1057761
[Epoch 73; Iter   102/  229] train: loss: 0.1325941
[Epoch 73; Iter   132/  229] train: loss: 0.1266801
[Epoch 73; Iter   162/  229] train: loss: 0.1315077
[Epoch 73; Iter   192/  229] train: loss: 0.1920998
[Epoch 73; Iter   222/  229] train: loss: 0.1163761
[Epoch 73] ogbg-moltoxcast: 0.741936 val loss: 0.196562
[Epoch 73] ogbg-moltoxcast: 0.768114 test loss: 0.211510
[Epoch 74; Iter    23/  229] train: loss: 0.1240026
[Epoch 74; Iter    53/  229] train: loss: 0.1182155
[Epoch 74; Iter    83/  229] train: loss: 0.1389958
[Epoch 74; Iter   113/  229] train: loss: 0.1537350
[Epoch 74; Iter   143/  229] train: loss: 0.1586577
[Epoch 74; Iter   173/  229] train: loss: 0.1222727
[Epoch 74; Iter   203/  229] train: loss: 0.1611703
[Epoch 74] ogbg-moltoxcast: 0.739760 val loss: 0.196493
[Epoch 74] ogbg-moltoxcast: 0.762267 test loss: 0.214265
[Epoch 75; Iter     4/  229] train: loss: 0.1445854
[Epoch 75; Iter    34/  229] train: loss: 0.1170553
[Epoch 75; Iter    64/  229] train: loss: 0.1209132
[Epoch 75; Iter    94/  229] train: loss: 0.1170987
[Epoch 75; Iter   124/  229] train: loss: 0.1322363
[Epoch 75; Iter   154/  229] train: loss: 0.1274292
[Epoch 75; Iter   184/  229] train: loss: 0.1306583
[Epoch 75; Iter   214/  229] train: loss: 0.2057976
[Epoch 75] ogbg-moltoxcast: 0.735166 val loss: 0.198300
[Epoch 75] ogbg-moltoxcast: 0.764754 test loss: 0.214130
[Epoch 66; Iter   105/  201] train: loss: 0.1782869
[Epoch 66; Iter   135/  201] train: loss: 0.1414526
[Epoch 66; Iter   165/  201] train: loss: 0.0851154
[Epoch 66; Iter   195/  201] train: loss: 0.1251576
[Epoch 66] ogbg-moltoxcast: 0.737706 val loss: 0.202773
[Epoch 66] ogbg-moltoxcast: 0.752856 test loss: 0.201734
[Epoch 67; Iter    24/  201] train: loss: 0.1304318
[Epoch 67; Iter    54/  201] train: loss: 0.1493077
[Epoch 67; Iter    84/  201] train: loss: 0.1255990
[Epoch 67; Iter   114/  201] train: loss: 0.1154543
[Epoch 67; Iter   144/  201] train: loss: 0.1164287
[Epoch 67; Iter   174/  201] train: loss: 0.1095148
[Epoch 67] ogbg-moltoxcast: 0.740440 val loss: 0.204532
[Epoch 67] ogbg-moltoxcast: 0.756501 test loss: 0.205197
[Epoch 68; Iter     3/  201] train: loss: 0.1222603
[Epoch 68; Iter    33/  201] train: loss: 0.1360142
[Epoch 68; Iter    63/  201] train: loss: 0.1178091
[Epoch 68; Iter    93/  201] train: loss: 0.1492040
[Epoch 68; Iter   123/  201] train: loss: 0.1661409
[Epoch 68; Iter   153/  201] train: loss: 0.1698297
[Epoch 68; Iter   183/  201] train: loss: 0.1368696
[Epoch 68] ogbg-moltoxcast: 0.738978 val loss: 0.205169
[Epoch 68] ogbg-moltoxcast: 0.757734 test loss: 0.202828
[Epoch 69; Iter    12/  201] train: loss: 0.1505550
[Epoch 69; Iter    42/  201] train: loss: 0.1512244
[Epoch 69; Iter    72/  201] train: loss: 0.1405295
[Epoch 69; Iter   102/  201] train: loss: 0.1779882
[Epoch 69; Iter   132/  201] train: loss: 0.1690336
[Epoch 69; Iter   162/  201] train: loss: 0.1402605
[Epoch 69; Iter   192/  201] train: loss: 0.1918014
[Epoch 69] ogbg-moltoxcast: 0.740325 val loss: 0.204687
[Epoch 69] ogbg-moltoxcast: 0.753701 test loss: 0.204460
[Epoch 70; Iter    21/  201] train: loss: 0.1847557
[Epoch 70; Iter    51/  201] train: loss: 0.1292180
[Epoch 70; Iter    81/  201] train: loss: 0.1153154
[Epoch 70; Iter   111/  201] train: loss: 0.1221737
[Epoch 70; Iter   141/  201] train: loss: 0.1605844
[Epoch 70; Iter   171/  201] train: loss: 0.1608745
[Epoch 70; Iter   201/  201] train: loss: 0.2857817
[Epoch 70] ogbg-moltoxcast: 0.739640 val loss: 0.205851
[Epoch 70] ogbg-moltoxcast: 0.757762 test loss: 0.204481
[Epoch 71; Iter    30/  201] train: loss: 0.1367618
[Epoch 71; Iter    60/  201] train: loss: 0.1277789
[Epoch 71; Iter    90/  201] train: loss: 0.1481681
[Epoch 71; Iter   120/  201] train: loss: 0.1301869
[Epoch 71; Iter   150/  201] train: loss: 0.2318104
[Epoch 71; Iter   180/  201] train: loss: 0.1563658
[Epoch 71] ogbg-moltoxcast: 0.740633 val loss: 0.203696
[Epoch 71] ogbg-moltoxcast: 0.757521 test loss: 0.202069
[Epoch 72; Iter     9/  201] train: loss: 0.1290656
[Epoch 72; Iter    39/  201] train: loss: 0.1472629
[Epoch 72; Iter    69/  201] train: loss: 0.1539986
[Epoch 72; Iter    99/  201] train: loss: 0.1733794
[Epoch 72; Iter   129/  201] train: loss: 0.1116672
[Epoch 72; Iter   159/  201] train: loss: 0.1751557
[Epoch 72; Iter   189/  201] train: loss: 0.1818793
[Epoch 72] ogbg-moltoxcast: 0.736502 val loss: 0.208175
[Epoch 72] ogbg-moltoxcast: 0.754673 test loss: 0.205606
[Epoch 73; Iter    18/  201] train: loss: 0.1114025
[Epoch 73; Iter    48/  201] train: loss: 0.1227596
[Epoch 73; Iter    78/  201] train: loss: 0.1283337
[Epoch 73; Iter   108/  201] train: loss: 0.1567507
[Epoch 73; Iter   138/  201] train: loss: 0.1401768
[Epoch 73; Iter   168/  201] train: loss: 0.1489876
[Epoch 73; Iter   198/  201] train: loss: 0.2140582
[Epoch 73] ogbg-moltoxcast: 0.738933 val loss: 0.207315
[Epoch 73] ogbg-moltoxcast: 0.759317 test loss: 0.204874
[Epoch 74; Iter    27/  201] train: loss: 0.1609515
[Epoch 74; Iter    57/  201] train: loss: 0.1561518
[Epoch 74; Iter    87/  201] train: loss: 0.1418263
[Epoch 74; Iter   117/  201] train: loss: 0.1382981
[Epoch 74; Iter   147/  201] train: loss: 0.1639789
[Epoch 74; Iter   177/  201] train: loss: 0.1227544
[Epoch 74] ogbg-moltoxcast: 0.742331 val loss: 0.207260
[Epoch 74] ogbg-moltoxcast: 0.758391 test loss: 0.205035
[Epoch 75; Iter     6/  201] train: loss: 0.1333897
[Epoch 75; Iter    36/  201] train: loss: 0.1325766
[Epoch 75; Iter    66/  201] train: loss: 0.1473954
[Epoch 75; Iter    96/  201] train: loss: 0.1745598
[Epoch 75; Iter   126/  201] train: loss: 0.0942608
[Epoch 75; Iter   156/  201] train: loss: 0.1679212
[Epoch 75; Iter   186/  201] train: loss: 0.1644691
[Epoch 75] ogbg-moltoxcast: 0.740614 val loss: 0.205741
[Epoch 75] ogbg-moltoxcast: 0.754644 test loss: 0.205631
[Epoch 76; Iter    15/  201] train: loss: 0.1736254
[Epoch 76; Iter    45/  201] train: loss: 0.1079603
[Epoch 76; Iter    75/  201] train: loss: 0.1108909
[Epoch 76; Iter   105/  201] train: loss: 0.1576243
[Epoch 76; Iter   135/  201] train: loss: 0.1346740
[Epoch 76; Iter   165/  201] train: loss: 0.1482514
[Epoch 76; Iter   195/  201] train: loss: 0.1187596
[Epoch 76] ogbg-moltoxcast: 0.738085 val loss: 0.205765
[Epoch 76] ogbg-moltoxcast: 0.752907 test loss: 0.205012
[Epoch 77; Iter    24/  201] train: loss: 0.1684460
[Epoch 77; Iter    54/  201] train: loss: 0.1544423
[Epoch 77; Iter    84/  201] train: loss: 0.1707937
[Epoch 77; Iter   114/  201] train: loss: 0.1270126
[Epoch 77; Iter   144/  201] train: loss: 0.1025272
[Epoch 77; Iter   174/  201] train: loss: 0.1315255
[Epoch 77] ogbg-moltoxcast: 0.743088 val loss: 0.204653
[Epoch 77] ogbg-moltoxcast: 0.755217 test loss: 0.205310
[Epoch 78; Iter     3/  201] train: loss: 0.1316209
[Epoch 78; Iter    33/  201] train: loss: 0.1179213
[Epoch 78; Iter    63/  201] train: loss: 0.1915506
[Epoch 78; Iter    93/  201] train: loss: 0.1219045
[Epoch 78; Iter   123/  201] train: loss: 0.1430371
[Epoch 78; Iter   153/  201] train: loss: 0.1342958
[Epoch 78; Iter   183/  201] train: loss: 0.1648168
[Epoch 78] ogbg-moltoxcast: 0.742857 val loss: 0.205327
[Epoch 78] ogbg-moltoxcast: 0.758256 test loss: 0.207074
[Epoch 79; Iter    12/  201] train: loss: 0.0987613
[Epoch 79; Iter    42/  201] train: loss: 0.2641404
[Epoch 79; Iter    72/  201] train: loss: 0.1695347
[Epoch 79; Iter   102/  201] train: loss: 0.1375712
[Epoch 79; Iter   132/  201] train: loss: 0.1854632
[Epoch 79; Iter   162/  201] train: loss: 0.1616841
[Epoch 79; Iter   192/  201] train: loss: 0.1678524
[Epoch 79] ogbg-moltoxcast: 0.741434 val loss: 0.207703
[Epoch 79] ogbg-moltoxcast: 0.754943 test loss: 0.208277
[Epoch 80; Iter    21/  201] train: loss: 0.1805736
[Epoch 80; Iter    51/  201] train: loss: 0.1515771
[Epoch 80; Iter    81/  201] train: loss: 0.1543805
[Epoch 80; Iter   111/  201] train: loss: 0.1709236
[Epoch 80; Iter   141/  201] train: loss: 0.1456954
[Epoch 80; Iter   171/  201] train: loss: 0.1905381
[Epoch 80; Iter   201/  201] train: loss: 0.1505074
[Epoch 80] ogbg-moltoxcast: 0.736899 val loss: 0.206457
[Epoch 80] ogbg-moltoxcast: 0.754303 test loss: 0.205533
[Epoch 81; Iter    30/  201] train: loss: 0.1337236
[Epoch 81; Iter    60/  201] train: loss: 0.1318935
[Epoch 81; Iter    90/  201] train: loss: 0.1383162
[Epoch 81; Iter   120/  201] train: loss: 0.1683186
[Epoch 81; Iter   150/  201] train: loss: 0.1392019
[Epoch 81; Iter   180/  201] train: loss: 0.1286608
[Epoch 81] ogbg-moltoxcast: 0.739680 val loss: 0.204951
[Epoch 81] ogbg-moltoxcast: 0.754616 test loss: 0.203843
[Epoch 82; Iter     9/  201] train: loss: 0.0947350
[Epoch 82; Iter    39/  201] train: loss: 0.0984699
[Epoch 82; Iter    69/  201] train: loss: 0.1194606
[Epoch 82; Iter    99/  201] train: loss: 0.1352666
[Epoch 82; Iter   129/  201] train: loss: 0.1466783
[Epoch 82; Iter   159/  201] train: loss: 0.1465275
[Epoch 82; Iter   189/  201] train: loss: 0.1164078
[Epoch 82] ogbg-moltoxcast: 0.739741 val loss: 0.207160
[Epoch 82] ogbg-moltoxcast: 0.754817 test loss: 0.207614
[Epoch 83; Iter    18/  201] train: loss: 0.1770939
[Epoch 83; Iter    48/  201] train: loss: 0.0980487
[Epoch 83; Iter    78/  201] train: loss: 0.1246046
[Epoch 83; Iter   108/  201] train: loss: 0.1171157
[Epoch 83; Iter   138/  201] train: loss: 0.1610773
[Epoch 83; Iter   168/  201] train: loss: 0.1267693
[Epoch 83; Iter   198/  201] train: loss: 0.1418535
[Epoch 83] ogbg-moltoxcast: 0.736205 val loss: 0.207723
[Epoch 83] ogbg-moltoxcast: 0.746530 test loss: 0.208358
[Epoch 66; Iter   105/  201] train: loss: 0.1007514
[Epoch 66; Iter   135/  201] train: loss: 0.1279882
[Epoch 66; Iter   165/  201] train: loss: 0.1166313
[Epoch 66; Iter   195/  201] train: loss: 0.2006099
[Epoch 66] ogbg-moltoxcast: 0.731664 val loss: 0.208743
[Epoch 66] ogbg-moltoxcast: 0.753490 test loss: 0.204527
[Epoch 67; Iter    24/  201] train: loss: 0.1346651
[Epoch 67; Iter    54/  201] train: loss: 0.1230706
[Epoch 67; Iter    84/  201] train: loss: 0.1897108
[Epoch 67; Iter   114/  201] train: loss: 0.1414304
[Epoch 67; Iter   144/  201] train: loss: 0.1380081
[Epoch 67; Iter   174/  201] train: loss: 0.1083776
[Epoch 67] ogbg-moltoxcast: 0.735548 val loss: 0.208232
[Epoch 67] ogbg-moltoxcast: 0.752773 test loss: 0.205196
[Epoch 68; Iter     3/  201] train: loss: 0.1371586
[Epoch 68; Iter    33/  201] train: loss: 0.1697268
[Epoch 68; Iter    63/  201] train: loss: 0.1762203
[Epoch 68; Iter    93/  201] train: loss: 0.1088098
[Epoch 68; Iter   123/  201] train: loss: 0.1198701
[Epoch 68; Iter   153/  201] train: loss: 0.1462865
[Epoch 68; Iter   183/  201] train: loss: 0.1682471
[Epoch 68] ogbg-moltoxcast: 0.735218 val loss: 0.208371
[Epoch 68] ogbg-moltoxcast: 0.754733 test loss: 0.203667
[Epoch 69; Iter    12/  201] train: loss: 0.1941657
[Epoch 69; Iter    42/  201] train: loss: 0.1615859
[Epoch 69; Iter    72/  201] train: loss: 0.1256555
[Epoch 69; Iter   102/  201] train: loss: 0.1200819
[Epoch 69; Iter   132/  201] train: loss: 0.1084034
[Epoch 69; Iter   162/  201] train: loss: 0.1558679
[Epoch 69; Iter   192/  201] train: loss: 0.1249312
[Epoch 69] ogbg-moltoxcast: 0.736528 val loss: 0.211228
[Epoch 69] ogbg-moltoxcast: 0.754909 test loss: 0.207828
[Epoch 70; Iter    21/  201] train: loss: 0.1368117
[Epoch 70; Iter    51/  201] train: loss: 0.1591989
[Epoch 70; Iter    81/  201] train: loss: 0.1502475
[Epoch 70; Iter   111/  201] train: loss: 0.1139076
[Epoch 70; Iter   141/  201] train: loss: 0.1589283
[Epoch 70; Iter   171/  201] train: loss: 0.1203301
[Epoch 70; Iter   201/  201] train: loss: 0.0753149
[Epoch 70] ogbg-moltoxcast: 0.731934 val loss: 0.210718
[Epoch 70] ogbg-moltoxcast: 0.753673 test loss: 0.205913
[Epoch 71; Iter    30/  201] train: loss: 0.1074549
[Epoch 71; Iter    60/  201] train: loss: 0.1758237
[Epoch 71; Iter    90/  201] train: loss: 0.1836079
[Epoch 71; Iter   120/  201] train: loss: 0.1470205
[Epoch 71; Iter   150/  201] train: loss: 0.1656387
[Epoch 71; Iter   180/  201] train: loss: 0.1559403
[Epoch 71] ogbg-moltoxcast: 0.736139 val loss: 0.212647
[Epoch 71] ogbg-moltoxcast: 0.750768 test loss: 0.210674
[Epoch 72; Iter     9/  201] train: loss: 0.1736215
[Epoch 72; Iter    39/  201] train: loss: 0.1266705
[Epoch 72; Iter    69/  201] train: loss: 0.0961543
[Epoch 72; Iter    99/  201] train: loss: 0.1825684
[Epoch 72; Iter   129/  201] train: loss: 0.1463565
[Epoch 72; Iter   159/  201] train: loss: 0.1543412
[Epoch 72; Iter   189/  201] train: loss: 0.1922283
[Epoch 72] ogbg-moltoxcast: 0.735030 val loss: 0.210392
[Epoch 72] ogbg-moltoxcast: 0.753577 test loss: 0.208413
[Epoch 73; Iter    18/  201] train: loss: 0.1783919
[Epoch 73; Iter    48/  201] train: loss: 0.1365698
[Epoch 73; Iter    78/  201] train: loss: 0.1538903
[Epoch 73; Iter   108/  201] train: loss: 0.1506202
[Epoch 73; Iter   138/  201] train: loss: 0.1609369
[Epoch 73; Iter   168/  201] train: loss: 0.1245124
[Epoch 73; Iter   198/  201] train: loss: 0.0928623
[Epoch 73] ogbg-moltoxcast: 0.737084 val loss: 0.211696
[Epoch 73] ogbg-moltoxcast: 0.755709 test loss: 0.209844
[Epoch 74; Iter    27/  201] train: loss: 0.1400179
[Epoch 74; Iter    57/  201] train: loss: 0.1342359
[Epoch 74; Iter    87/  201] train: loss: 0.1499594
[Epoch 74; Iter   117/  201] train: loss: 0.1492896
[Epoch 74; Iter   147/  201] train: loss: 0.1422886
[Epoch 74; Iter   177/  201] train: loss: 0.1500683
[Epoch 74] ogbg-moltoxcast: 0.732909 val loss: 0.212903
[Epoch 74] ogbg-moltoxcast: 0.755371 test loss: 0.206744
[Epoch 75; Iter     6/  201] train: loss: 0.1615650
[Epoch 75; Iter    36/  201] train: loss: 0.1706292
[Epoch 75; Iter    66/  201] train: loss: 0.1626979
[Epoch 75; Iter    96/  201] train: loss: 0.1225274
[Epoch 75; Iter   126/  201] train: loss: 0.1377439
[Epoch 75; Iter   156/  201] train: loss: 0.1302777
[Epoch 75; Iter   186/  201] train: loss: 0.1274940
[Epoch 75] ogbg-moltoxcast: 0.734346 val loss: 0.211117
[Epoch 75] ogbg-moltoxcast: 0.749295 test loss: 0.209918
[Epoch 76; Iter    15/  201] train: loss: 0.1444432
[Epoch 76; Iter    45/  201] train: loss: 0.0894046
[Epoch 76; Iter    75/  201] train: loss: 0.1460892
[Epoch 76; Iter   105/  201] train: loss: 0.1195114
[Epoch 76; Iter   135/  201] train: loss: 0.1700239
[Epoch 76; Iter   165/  201] train: loss: 0.1616544
[Epoch 76; Iter   195/  201] train: loss: 0.0897290
[Epoch 76] ogbg-moltoxcast: 0.731878 val loss: 0.212645
[Epoch 76] ogbg-moltoxcast: 0.754632 test loss: 0.206743
[Epoch 77; Iter    24/  201] train: loss: 0.1575127
[Epoch 77; Iter    54/  201] train: loss: 0.1353888
[Epoch 77; Iter    84/  201] train: loss: 0.1215127
[Epoch 77; Iter   114/  201] train: loss: 0.0722331
[Epoch 77; Iter   144/  201] train: loss: 0.1203527
[Epoch 77; Iter   174/  201] train: loss: 0.0998542
[Epoch 77] ogbg-moltoxcast: 0.731101 val loss: 0.213676
[Epoch 77] ogbg-moltoxcast: 0.754061 test loss: 0.209147
[Epoch 78; Iter     3/  201] train: loss: 0.1321708
[Epoch 78; Iter    33/  201] train: loss: 0.1121236
[Epoch 78; Iter    63/  201] train: loss: 0.1132542
[Epoch 78; Iter    93/  201] train: loss: 0.1870970
[Epoch 78; Iter   123/  201] train: loss: 0.1018584
[Epoch 78; Iter   153/  201] train: loss: 0.1127928
[Epoch 78; Iter   183/  201] train: loss: 0.1905476
[Epoch 78] ogbg-moltoxcast: 0.731115 val loss: 0.213607
[Epoch 78] ogbg-moltoxcast: 0.756327 test loss: 0.205924
[Epoch 79; Iter    12/  201] train: loss: 0.1378782
[Epoch 79; Iter    42/  201] train: loss: 0.1169069
[Epoch 79; Iter    72/  201] train: loss: 0.1220527
[Epoch 79; Iter   102/  201] train: loss: 0.0729173
[Epoch 79; Iter   132/  201] train: loss: 0.1234207
[Epoch 79; Iter   162/  201] train: loss: 0.1707241
[Epoch 79; Iter   192/  201] train: loss: 0.0894771
[Epoch 79] ogbg-moltoxcast: 0.731201 val loss: 0.214430
[Epoch 79] ogbg-moltoxcast: 0.754286 test loss: 0.207746
[Epoch 80; Iter    21/  201] train: loss: 0.1242317
[Epoch 80; Iter    51/  201] train: loss: 0.1345354
[Epoch 80; Iter    81/  201] train: loss: 0.1404982
[Epoch 80; Iter   111/  201] train: loss: 0.1180034
[Epoch 80; Iter   141/  201] train: loss: 0.1464982
[Epoch 80; Iter   171/  201] train: loss: 0.1479204
[Epoch 80; Iter   201/  201] train: loss: 0.0875508
[Epoch 80] ogbg-moltoxcast: 0.734218 val loss: 0.210842
[Epoch 80] ogbg-moltoxcast: 0.756529 test loss: 0.206919
[Epoch 81; Iter    30/  201] train: loss: 0.1318690
[Epoch 81; Iter    60/  201] train: loss: 0.1074982
[Epoch 81; Iter    90/  201] train: loss: 0.1335048
[Epoch 81; Iter   120/  201] train: loss: 0.1220027
[Epoch 81; Iter   150/  201] train: loss: 0.1320328
[Epoch 81; Iter   180/  201] train: loss: 0.1364998
[Epoch 81] ogbg-moltoxcast: 0.733751 val loss: 0.216447
[Epoch 81] ogbg-moltoxcast: 0.754166 test loss: 0.210410
[Epoch 82; Iter     9/  201] train: loss: 0.1433680
[Epoch 82; Iter    39/  201] train: loss: 0.1314473
[Epoch 82; Iter    69/  201] train: loss: 0.1371711
[Epoch 82; Iter    99/  201] train: loss: 0.1423998
[Epoch 82; Iter   129/  201] train: loss: 0.1343598
[Epoch 82; Iter   159/  201] train: loss: 0.1248776
[Epoch 82; Iter   189/  201] train: loss: 0.1613410
[Epoch 82] ogbg-moltoxcast: 0.733273 val loss: 0.213874
[Epoch 82] ogbg-moltoxcast: 0.755990 test loss: 0.208632
[Epoch 83; Iter    18/  201] train: loss: 0.1072594
[Epoch 83; Iter    48/  201] train: loss: 0.1575029
[Epoch 83; Iter    78/  201] train: loss: 0.1142034
[Epoch 83; Iter   108/  201] train: loss: 0.1386812
[Epoch 83; Iter   138/  201] train: loss: 0.1851115
[Epoch 83; Iter   168/  201] train: loss: 0.1591581
[Epoch 83; Iter   198/  201] train: loss: 0.0993783
[Epoch 83] ogbg-moltoxcast: 0.727737 val loss: 0.217447
[Epoch 83] ogbg-moltoxcast: 0.756543 test loss: 0.208771
[Epoch 66; Iter   105/  201] train: loss: 0.1484787
[Epoch 66; Iter   135/  201] train: loss: 0.1349598
[Epoch 66; Iter   165/  201] train: loss: 0.1457669
[Epoch 66; Iter   195/  201] train: loss: 0.1577092
[Epoch 66] ogbg-moltoxcast: 0.729296 val loss: 0.216127
[Epoch 66] ogbg-moltoxcast: 0.753021 test loss: 0.211396
[Epoch 67; Iter    24/  201] train: loss: 0.1303574
[Epoch 67; Iter    54/  201] train: loss: 0.1137097
[Epoch 67; Iter    84/  201] train: loss: 0.1782685
[Epoch 67; Iter   114/  201] train: loss: 0.1716215
[Epoch 67; Iter   144/  201] train: loss: 0.1728651
[Epoch 67; Iter   174/  201] train: loss: 0.1419229
[Epoch 67] ogbg-moltoxcast: 0.728860 val loss: 0.227290
[Epoch 67] ogbg-moltoxcast: 0.750872 test loss: 0.228983
[Epoch 68; Iter     3/  201] train: loss: 0.1776190
[Epoch 68; Iter    33/  201] train: loss: 0.1307603
[Epoch 68; Iter    63/  201] train: loss: 0.1517301
[Epoch 68; Iter    93/  201] train: loss: 0.1265881
[Epoch 68; Iter   123/  201] train: loss: 0.1525186
[Epoch 68; Iter   153/  201] train: loss: 0.1190885
[Epoch 68; Iter   183/  201] train: loss: 0.1848658
[Epoch 68] ogbg-moltoxcast: 0.732200 val loss: 0.212431
[Epoch 68] ogbg-moltoxcast: 0.747864 test loss: 0.210195
[Epoch 69; Iter    12/  201] train: loss: 0.1124906
[Epoch 69; Iter    42/  201] train: loss: 0.1203612
[Epoch 69; Iter    72/  201] train: loss: 0.1738276
[Epoch 69; Iter   102/  201] train: loss: 0.1219038
[Epoch 69; Iter   132/  201] train: loss: 0.1601289
[Epoch 69; Iter   162/  201] train: loss: 0.1170013
[Epoch 69; Iter   192/  201] train: loss: 0.1313439
[Epoch 69] ogbg-moltoxcast: 0.730697 val loss: 0.220317
[Epoch 69] ogbg-moltoxcast: 0.749693 test loss: 0.217076
[Epoch 70; Iter    21/  201] train: loss: 0.1501292
[Epoch 70; Iter    51/  201] train: loss: 0.1065100
[Epoch 70; Iter    81/  201] train: loss: 0.1592004
[Epoch 70; Iter   111/  201] train: loss: 0.1687499
[Epoch 70; Iter   141/  201] train: loss: 0.1308614
[Epoch 70; Iter   171/  201] train: loss: 0.1649166
[Epoch 70; Iter   201/  201] train: loss: 0.0474130
[Epoch 70] ogbg-moltoxcast: 0.729155 val loss: 0.296997
[Epoch 70] ogbg-moltoxcast: 0.753769 test loss: 0.327916
[Epoch 71; Iter    30/  201] train: loss: 0.1636235
[Epoch 71; Iter    60/  201] train: loss: 0.1029349
[Epoch 71; Iter    90/  201] train: loss: 0.2016455
[Epoch 71; Iter   120/  201] train: loss: 0.1105775
[Epoch 71; Iter   150/  201] train: loss: 0.1937588
[Epoch 71; Iter   180/  201] train: loss: 0.1482795
[Epoch 71] ogbg-moltoxcast: 0.728761 val loss: 0.214573
[Epoch 71] ogbg-moltoxcast: 0.751569 test loss: 0.207467
[Epoch 72; Iter     9/  201] train: loss: 0.1121507
[Epoch 72; Iter    39/  201] train: loss: 0.1132132
[Epoch 72; Iter    69/  201] train: loss: 0.1452816
[Epoch 72; Iter    99/  201] train: loss: 0.1557227
[Epoch 72; Iter   129/  201] train: loss: 0.1662547
[Epoch 72; Iter   159/  201] train: loss: 0.1630064
[Epoch 72; Iter   189/  201] train: loss: 0.1366609
[Epoch 72] ogbg-moltoxcast: 0.731407 val loss: 0.219292
[Epoch 72] ogbg-moltoxcast: 0.751688 test loss: 0.219567
[Epoch 73; Iter    18/  201] train: loss: 0.1374692
[Epoch 73; Iter    48/  201] train: loss: 0.1364695
[Epoch 73; Iter    78/  201] train: loss: 0.1524505
[Epoch 73; Iter   108/  201] train: loss: 0.1855728
[Epoch 73; Iter   138/  201] train: loss: 0.1449178
[Epoch 73; Iter   168/  201] train: loss: 0.1656715
[Epoch 73; Iter   198/  201] train: loss: 0.1262630
[Epoch 73] ogbg-moltoxcast: 0.724557 val loss: 0.219565
[Epoch 73] ogbg-moltoxcast: 0.750292 test loss: 0.216026
[Epoch 74; Iter    27/  201] train: loss: 0.2533580
[Epoch 74; Iter    57/  201] train: loss: 0.1230335
[Epoch 74; Iter    87/  201] train: loss: 0.1314661
[Epoch 74; Iter   117/  201] train: loss: 0.1277573
[Epoch 74; Iter   147/  201] train: loss: 0.1284217
[Epoch 74; Iter   177/  201] train: loss: 0.1178166
[Epoch 74] ogbg-moltoxcast: 0.729945 val loss: 0.242987
[Epoch 74] ogbg-moltoxcast: 0.755403 test loss: 0.247829
[Epoch 75; Iter     6/  201] train: loss: 0.1301602
[Epoch 75; Iter    36/  201] train: loss: 0.1388808
[Epoch 75; Iter    66/  201] train: loss: 0.1171435
[Epoch 75; Iter    96/  201] train: loss: 0.1117703
[Epoch 75; Iter   126/  201] train: loss: 0.1283902
[Epoch 75; Iter   156/  201] train: loss: 0.1619680
[Epoch 75; Iter   186/  201] train: loss: 0.1364021
[Epoch 75] ogbg-moltoxcast: 0.729132 val loss: 0.216791
[Epoch 75] ogbg-moltoxcast: 0.749707 test loss: 0.207714
[Epoch 76; Iter    15/  201] train: loss: 0.1820232
[Epoch 76; Iter    45/  201] train: loss: 0.1262204
[Epoch 76; Iter    75/  201] train: loss: 0.1032424
[Epoch 76; Iter   105/  201] train: loss: 0.1041753
[Epoch 76; Iter   135/  201] train: loss: 0.1111575
[Epoch 76; Iter   165/  201] train: loss: 0.1207866
[Epoch 76; Iter   195/  201] train: loss: 0.2063504
[Epoch 76] ogbg-moltoxcast: 0.734692 val loss: 0.236191
[Epoch 76] ogbg-moltoxcast: 0.749987 test loss: 0.242614
[Epoch 77; Iter    24/  201] train: loss: 0.2020079
[Epoch 77; Iter    54/  201] train: loss: 0.0966783
[Epoch 77; Iter    84/  201] train: loss: 0.1476100
[Epoch 77; Iter   114/  201] train: loss: 0.1191956
[Epoch 77; Iter   144/  201] train: loss: 0.2559524
[Epoch 77; Iter   174/  201] train: loss: 0.2385741
[Epoch 77] ogbg-moltoxcast: 0.729156 val loss: 0.228305
[Epoch 77] ogbg-moltoxcast: 0.745956 test loss: 0.233523
[Epoch 78; Iter     3/  201] train: loss: 0.1527060
[Epoch 78; Iter    33/  201] train: loss: 0.1622794
[Epoch 78; Iter    63/  201] train: loss: 0.1485691
[Epoch 78; Iter    93/  201] train: loss: 0.1667824
[Epoch 78; Iter   123/  201] train: loss: 0.1492870
[Epoch 78; Iter   153/  201] train: loss: 0.1265935
[Epoch 78; Iter   183/  201] train: loss: 0.1400129
[Epoch 78] ogbg-moltoxcast: 0.723621 val loss: 0.220881
[Epoch 78] ogbg-moltoxcast: 0.745947 test loss: 0.218506
[Epoch 79; Iter    12/  201] train: loss: 0.2118849
[Epoch 79; Iter    42/  201] train: loss: 0.1345726
[Epoch 79; Iter    72/  201] train: loss: 0.1191069
[Epoch 79; Iter   102/  201] train: loss: 0.1576104
[Epoch 79; Iter   132/  201] train: loss: 0.1673949
[Epoch 79; Iter   162/  201] train: loss: 0.1408371
[Epoch 79; Iter   192/  201] train: loss: 0.1389745
[Epoch 79] ogbg-moltoxcast: 0.731220 val loss: 0.217025
[Epoch 79] ogbg-moltoxcast: 0.750615 test loss: 0.215694
[Epoch 80; Iter    21/  201] train: loss: 0.0915431
[Epoch 80; Iter    51/  201] train: loss: 0.1389436
[Epoch 80; Iter    81/  201] train: loss: 0.1395503
[Epoch 80; Iter   111/  201] train: loss: 0.1468032
[Epoch 80; Iter   141/  201] train: loss: 0.2014593
[Epoch 80; Iter   171/  201] train: loss: 0.1441277
[Epoch 80; Iter   201/  201] train: loss: 0.0830328
[Epoch 80] ogbg-moltoxcast: 0.730210 val loss: 0.231891
[Epoch 80] ogbg-moltoxcast: 0.749927 test loss: 0.238078
[Epoch 81; Iter    30/  201] train: loss: 0.1606722
[Epoch 81; Iter    60/  201] train: loss: 0.1520961
[Epoch 81; Iter    90/  201] train: loss: 0.1415247
[Epoch 81; Iter   120/  201] train: loss: 0.1475204
[Epoch 81; Iter   150/  201] train: loss: 0.1441376
[Epoch 81; Iter   180/  201] train: loss: 0.1915744
[Epoch 81] ogbg-moltoxcast: 0.732839 val loss: 0.232427
[Epoch 81] ogbg-moltoxcast: 0.746824 test loss: 0.234597
[Epoch 82; Iter     9/  201] train: loss: 0.1702066
[Epoch 82; Iter    39/  201] train: loss: 0.1597462
[Epoch 82; Iter    69/  201] train: loss: 0.1656034
[Epoch 82; Iter    99/  201] train: loss: 0.1223717
[Epoch 82; Iter   129/  201] train: loss: 0.1484705
[Epoch 82; Iter   159/  201] train: loss: 0.1811988
[Epoch 82; Iter   189/  201] train: loss: 0.1669282
[Epoch 82] ogbg-moltoxcast: 0.727855 val loss: 0.219557
[Epoch 82] ogbg-moltoxcast: 0.748108 test loss: 0.216576
[Epoch 83; Iter    18/  201] train: loss: 0.1636860
[Epoch 83; Iter    48/  201] train: loss: 0.1444776
[Epoch 83; Iter    78/  201] train: loss: 0.1470247
[Epoch 83; Iter   108/  201] train: loss: 0.1181516
[Epoch 83; Iter   138/  201] train: loss: 0.1583037
[Epoch 83; Iter   168/  201] train: loss: 0.1244204
[Epoch 83; Iter   198/  201] train: loss: 0.1502679
[Epoch 83] ogbg-moltoxcast: 0.730327 val loss: 0.222887
[Epoch 83] ogbg-moltoxcast: 0.747562 test loss: 0.223780
[Epoch 74; Iter   104/  172] train: loss: 0.1145342
[Epoch 74; Iter   134/  172] train: loss: 0.1910470
[Epoch 74; Iter   164/  172] train: loss: 0.1548125
[Epoch 74] ogbg-moltoxcast: 0.731359 val loss: 0.210594
[Epoch 74] ogbg-moltoxcast: 0.739036 test loss: 0.207297
[Epoch 75; Iter    22/  172] train: loss: 0.1341026
[Epoch 75; Iter    52/  172] train: loss: 0.1344336
[Epoch 75; Iter    82/  172] train: loss: 0.1730784
[Epoch 75; Iter   112/  172] train: loss: 0.0962594
[Epoch 75; Iter   142/  172] train: loss: 0.1668972
[Epoch 75; Iter   172/  172] train: loss: 0.1374952
[Epoch 75] ogbg-moltoxcast: 0.733134 val loss: 0.209641
[Epoch 75] ogbg-moltoxcast: 0.737643 test loss: 0.207900
[Epoch 76; Iter    30/  172] train: loss: 0.1075553
[Epoch 76; Iter    60/  172] train: loss: 0.1354131
[Epoch 76; Iter    90/  172] train: loss: 0.1317945
[Epoch 76; Iter   120/  172] train: loss: 0.1306112
[Epoch 76; Iter   150/  172] train: loss: 0.1147886
[Epoch 76] ogbg-moltoxcast: 0.727597 val loss: 0.214905
[Epoch 76] ogbg-moltoxcast: 0.735667 test loss: 0.210480
[Epoch 77; Iter     8/  172] train: loss: 0.1271858
[Epoch 77; Iter    38/  172] train: loss: 0.1203395
[Epoch 77; Iter    68/  172] train: loss: 0.1466411
[Epoch 77; Iter    98/  172] train: loss: 0.0847679
[Epoch 77; Iter   128/  172] train: loss: 0.1277801
[Epoch 77; Iter   158/  172] train: loss: 0.1197483
[Epoch 77] ogbg-moltoxcast: 0.735124 val loss: 0.210378
[Epoch 77] ogbg-moltoxcast: 0.736847 test loss: 0.210612
[Epoch 78; Iter    16/  172] train: loss: 0.1245704
[Epoch 78; Iter    46/  172] train: loss: 0.1462251
[Epoch 78; Iter    76/  172] train: loss: 0.1166869
[Epoch 78; Iter   106/  172] train: loss: 0.1327379
[Epoch 78; Iter   136/  172] train: loss: 0.1264352
[Epoch 78; Iter   166/  172] train: loss: 0.1270092
[Epoch 78] ogbg-moltoxcast: 0.733509 val loss: 0.211782
[Epoch 78] ogbg-moltoxcast: 0.737717 test loss: 0.209191
[Epoch 79; Iter    24/  172] train: loss: 0.1063221
[Epoch 79; Iter    54/  172] train: loss: 0.1449348
[Epoch 79; Iter    84/  172] train: loss: 0.1419774
[Epoch 79; Iter   114/  172] train: loss: 0.0881262
[Epoch 79; Iter   144/  172] train: loss: 0.1167493
[Epoch 79] ogbg-moltoxcast: 0.733133 val loss: 0.213083
[Epoch 79] ogbg-moltoxcast: 0.739867 test loss: 0.210252
[Epoch 80; Iter     2/  172] train: loss: 0.1149894
[Epoch 80; Iter    32/  172] train: loss: 0.1549899
[Epoch 80; Iter    62/  172] train: loss: 0.1500613
[Epoch 80; Iter    92/  172] train: loss: 0.1038734
[Epoch 80; Iter   122/  172] train: loss: 0.1109512
[Epoch 80; Iter   152/  172] train: loss: 0.1231516
[Epoch 80] ogbg-moltoxcast: 0.737154 val loss: 0.208157
[Epoch 80] ogbg-moltoxcast: 0.739081 test loss: 0.209697
[Epoch 81; Iter    10/  172] train: loss: 0.1320402
[Epoch 81; Iter    40/  172] train: loss: 0.1676574
[Epoch 81; Iter    70/  172] train: loss: 0.1010620
[Epoch 81; Iter   100/  172] train: loss: 0.1106855
[Epoch 81; Iter   130/  172] train: loss: 0.1420849
[Epoch 81; Iter   160/  172] train: loss: 0.1424938
[Epoch 81] ogbg-moltoxcast: 0.733967 val loss: 0.211604
[Epoch 81] ogbg-moltoxcast: 0.739258 test loss: 0.208648
[Epoch 82; Iter    18/  172] train: loss: 0.1179833
[Epoch 82; Iter    48/  172] train: loss: 0.1745863
[Epoch 82; Iter    78/  172] train: loss: 0.1116838
[Epoch 82; Iter   108/  172] train: loss: 0.1274461
[Epoch 82; Iter   138/  172] train: loss: 0.1269349
[Epoch 82; Iter   168/  172] train: loss: 0.1226164
[Epoch 82] ogbg-moltoxcast: 0.736650 val loss: 0.212082
[Epoch 82] ogbg-moltoxcast: 0.737267 test loss: 0.210121
[Epoch 83; Iter    26/  172] train: loss: 0.1435454
[Epoch 83; Iter    56/  172] train: loss: 0.1326987
[Epoch 83; Iter    86/  172] train: loss: 0.1482489
[Epoch 83; Iter   116/  172] train: loss: 0.1097398
[Epoch 83; Iter   146/  172] train: loss: 0.1227812
[Epoch 83] ogbg-moltoxcast: 0.734675 val loss: 0.213866
[Epoch 83] ogbg-moltoxcast: 0.742088 test loss: 0.209907
[Epoch 84; Iter     4/  172] train: loss: 0.1246756
[Epoch 84; Iter    34/  172] train: loss: 0.1417991
[Epoch 84; Iter    64/  172] train: loss: 0.1104735
[Epoch 84; Iter    94/  172] train: loss: 0.1331301
[Epoch 84; Iter   124/  172] train: loss: 0.1328101
[Epoch 84; Iter   154/  172] train: loss: 0.1117638
[Epoch 84] ogbg-moltoxcast: 0.735217 val loss: 0.210776
[Epoch 84] ogbg-moltoxcast: 0.742744 test loss: 0.207450
[Epoch 85; Iter    12/  172] train: loss: 0.1242250
[Epoch 85; Iter    42/  172] train: loss: 0.1283981
[Epoch 85; Iter    72/  172] train: loss: 0.1452561
[Epoch 85; Iter   102/  172] train: loss: 0.1723973
[Epoch 85; Iter   132/  172] train: loss: 0.1689157
[Epoch 85; Iter   162/  172] train: loss: 0.1443182
[Epoch 85] ogbg-moltoxcast: 0.733309 val loss: 0.214520
[Epoch 85] ogbg-moltoxcast: 0.735122 test loss: 0.211954
[Epoch 86; Iter    20/  172] train: loss: 0.1398106
[Epoch 86; Iter    50/  172] train: loss: 0.1617269
[Epoch 86; Iter    80/  172] train: loss: 0.1385481
[Epoch 86; Iter   110/  172] train: loss: 0.1875990
[Epoch 86; Iter   140/  172] train: loss: 0.1654861
[Epoch 86; Iter   170/  172] train: loss: 0.1671359
[Epoch 86] ogbg-moltoxcast: 0.734523 val loss: 0.210291
[Epoch 86] ogbg-moltoxcast: 0.738128 test loss: 0.208453
[Epoch 87; Iter    28/  172] train: loss: 0.1493743
[Epoch 87; Iter    58/  172] train: loss: 0.1286424
[Epoch 87; Iter    88/  172] train: loss: 0.1549939
[Epoch 87; Iter   118/  172] train: loss: 0.1689540
[Epoch 87; Iter   148/  172] train: loss: 0.1185497
[Epoch 87] ogbg-moltoxcast: 0.728760 val loss: 0.216330
[Epoch 87] ogbg-moltoxcast: 0.737742 test loss: 0.213319
[Epoch 88; Iter     6/  172] train: loss: 0.2023721
[Epoch 88; Iter    36/  172] train: loss: 0.1342920
[Epoch 88; Iter    66/  172] train: loss: 0.1393450
[Epoch 88; Iter    96/  172] train: loss: 0.1599596
[Epoch 88; Iter   126/  172] train: loss: 0.1253063
[Epoch 88; Iter   156/  172] train: loss: 0.1109314
[Epoch 88] ogbg-moltoxcast: 0.727593 val loss: 0.217008
[Epoch 88] ogbg-moltoxcast: 0.733199 test loss: 0.215671
[Epoch 89; Iter    14/  172] train: loss: 0.0941125
[Epoch 89; Iter    44/  172] train: loss: 0.1489151
[Epoch 89; Iter    74/  172] train: loss: 0.1683485
[Epoch 89; Iter   104/  172] train: loss: 0.1160400
[Epoch 89; Iter   134/  172] train: loss: 0.0952778
[Epoch 89; Iter   164/  172] train: loss: 0.1129813
[Epoch 89] ogbg-moltoxcast: 0.731994 val loss: 0.214871
[Epoch 89] ogbg-moltoxcast: 0.738498 test loss: 0.212567
[Epoch 90; Iter    22/  172] train: loss: 0.1554215
[Epoch 90; Iter    52/  172] train: loss: 0.1294383
[Epoch 90; Iter    82/  172] train: loss: 0.0947688
[Epoch 90; Iter   112/  172] train: loss: 0.1076604
[Epoch 90; Iter   142/  172] train: loss: 0.1194664
[Epoch 90; Iter   172/  172] train: loss: 0.1689852
[Epoch 90] ogbg-moltoxcast: 0.731223 val loss: 0.216476
[Epoch 90] ogbg-moltoxcast: 0.735333 test loss: 0.214049
[Epoch 91; Iter    30/  172] train: loss: 0.1520378
[Epoch 91; Iter    60/  172] train: loss: 0.1323695
[Epoch 91; Iter    90/  172] train: loss: 0.1492583
[Epoch 91; Iter   120/  172] train: loss: 0.0867449
[Epoch 91; Iter   150/  172] train: loss: 0.1521952
[Epoch 91] ogbg-moltoxcast: 0.734059 val loss: 0.213403
[Epoch 91] ogbg-moltoxcast: 0.739864 test loss: 0.210506
[Epoch 92; Iter     8/  172] train: loss: 0.1186575
[Epoch 92; Iter    38/  172] train: loss: 0.1140773
[Epoch 92; Iter    68/  172] train: loss: 0.1531562
[Epoch 92; Iter    98/  172] train: loss: 0.1533935
[Epoch 92; Iter   128/  172] train: loss: 0.1255831
[Epoch 92; Iter   158/  172] train: loss: 0.1146708
[Epoch 92] ogbg-moltoxcast: 0.736049 val loss: 0.210857
[Epoch 92] ogbg-moltoxcast: 0.738848 test loss: 0.209850
[Epoch 93; Iter    16/  172] train: loss: 0.1275046
[Epoch 93; Iter    46/  172] train: loss: 0.1604708
[Epoch 93; Iter    76/  172] train: loss: 0.1512113
[Epoch 93; Iter   106/  172] train: loss: 0.1589272
[Epoch 93; Iter   136/  172] train: loss: 0.1328331
[Epoch 93; Iter   166/  172] train: loss: 0.1592870
[Epoch 93] ogbg-moltoxcast: 0.733485 val loss: 0.215853
[Epoch 93] ogbg-moltoxcast: 0.738377 test loss: 0.212868
[Epoch 94; Iter    24/  172] train: loss: 0.1063776
[Epoch 94; Iter    54/  172] train: loss: 0.1547944
[Epoch 74; Iter   104/  172] train: loss: 0.1486038
[Epoch 74; Iter   134/  172] train: loss: 0.2079776
[Epoch 74; Iter   164/  172] train: loss: 0.1326849
[Epoch 74] ogbg-moltoxcast: 0.726962 val loss: 0.214225
[Epoch 74] ogbg-moltoxcast: 0.733961 test loss: 0.210726
[Epoch 75; Iter    22/  172] train: loss: 0.1598163
[Epoch 75; Iter    52/  172] train: loss: 0.1057417
[Epoch 75; Iter    82/  172] train: loss: 0.1546207
[Epoch 75; Iter   112/  172] train: loss: 0.1515673
[Epoch 75; Iter   142/  172] train: loss: 0.1818693
[Epoch 75; Iter   172/  172] train: loss: 0.1833965
[Epoch 75] ogbg-moltoxcast: 0.727052 val loss: 0.211602
[Epoch 75] ogbg-moltoxcast: 0.732996 test loss: 0.212819
[Epoch 76; Iter    30/  172] train: loss: 0.1576092
[Epoch 76; Iter    60/  172] train: loss: 0.1195415
[Epoch 76; Iter    90/  172] train: loss: 0.1805521
[Epoch 76; Iter   120/  172] train: loss: 0.1802249
[Epoch 76; Iter   150/  172] train: loss: 0.1681106
[Epoch 76] ogbg-moltoxcast: 0.731677 val loss: 0.211440
[Epoch 76] ogbg-moltoxcast: 0.737584 test loss: 0.208610
[Epoch 77; Iter     8/  172] train: loss: 0.1187532
[Epoch 77; Iter    38/  172] train: loss: 0.0951544
[Epoch 77; Iter    68/  172] train: loss: 0.1112412
[Epoch 77; Iter    98/  172] train: loss: 0.1440738
[Epoch 77; Iter   128/  172] train: loss: 0.1812183
[Epoch 77; Iter   158/  172] train: loss: 0.0928504
[Epoch 77] ogbg-moltoxcast: 0.731965 val loss: 0.211314
[Epoch 77] ogbg-moltoxcast: 0.732977 test loss: 0.211703
[Epoch 78; Iter    16/  172] train: loss: 0.1492480
[Epoch 78; Iter    46/  172] train: loss: 0.0931336
[Epoch 78; Iter    76/  172] train: loss: 0.1410955
[Epoch 78; Iter   106/  172] train: loss: 0.1896749
[Epoch 78; Iter   136/  172] train: loss: 0.1223468
[Epoch 78; Iter   166/  172] train: loss: 0.1510137
[Epoch 78] ogbg-moltoxcast: 0.730335 val loss: 0.223038
[Epoch 78] ogbg-moltoxcast: 0.730307 test loss: 0.213805
[Epoch 79; Iter    24/  172] train: loss: 0.1135700
[Epoch 79; Iter    54/  172] train: loss: 0.1587100
[Epoch 79; Iter    84/  172] train: loss: 0.1327661
[Epoch 79; Iter   114/  172] train: loss: 0.1415568
[Epoch 79; Iter   144/  172] train: loss: 0.1784382
[Epoch 79] ogbg-moltoxcast: 0.729276 val loss: 0.212960
[Epoch 79] ogbg-moltoxcast: 0.732602 test loss: 0.211214
[Epoch 80; Iter     2/  172] train: loss: 0.1319811
[Epoch 80; Iter    32/  172] train: loss: 0.1416841
[Epoch 80; Iter    62/  172] train: loss: 0.1454051
[Epoch 80; Iter    92/  172] train: loss: 0.1736368
[Epoch 80; Iter   122/  172] train: loss: 0.1651438
[Epoch 80; Iter   152/  172] train: loss: 0.1659529
[Epoch 80] ogbg-moltoxcast: 0.735068 val loss: 0.215315
[Epoch 80] ogbg-moltoxcast: 0.737369 test loss: 0.210449
[Epoch 81; Iter    10/  172] train: loss: 0.1608707
[Epoch 81; Iter    40/  172] train: loss: 0.0798325
[Epoch 81; Iter    70/  172] train: loss: 0.1364828
[Epoch 81; Iter   100/  172] train: loss: 0.1502870
[Epoch 81; Iter   130/  172] train: loss: 0.1388201
[Epoch 81; Iter   160/  172] train: loss: 0.1544038
[Epoch 81] ogbg-moltoxcast: 0.729972 val loss: 0.212642
[Epoch 81] ogbg-moltoxcast: 0.732997 test loss: 0.213524
[Epoch 82; Iter    18/  172] train: loss: 0.1529829
[Epoch 82; Iter    48/  172] train: loss: 0.1189813
[Epoch 82; Iter    78/  172] train: loss: 0.1801487
[Epoch 82; Iter   108/  172] train: loss: 0.1714037
[Epoch 82; Iter   138/  172] train: loss: 0.1441265
[Epoch 82; Iter   168/  172] train: loss: 0.1330715
[Epoch 82] ogbg-moltoxcast: 0.725994 val loss: 0.215334
[Epoch 82] ogbg-moltoxcast: 0.733473 test loss: 0.212809
[Epoch 83; Iter    26/  172] train: loss: 0.0966072
[Epoch 83; Iter    56/  172] train: loss: 0.1117112
[Epoch 83; Iter    86/  172] train: loss: 0.1171251
[Epoch 83; Iter   116/  172] train: loss: 0.1826608
[Epoch 83; Iter   146/  172] train: loss: 0.0953670
[Epoch 83] ogbg-moltoxcast: 0.729971 val loss: 0.211254
[Epoch 83] ogbg-moltoxcast: 0.731765 test loss: 0.211470
[Epoch 84; Iter     4/  172] train: loss: 0.1164648
[Epoch 84; Iter    34/  172] train: loss: 0.1944016
[Epoch 84; Iter    64/  172] train: loss: 0.1042877
[Epoch 84; Iter    94/  172] train: loss: 0.1207022
[Epoch 84; Iter   124/  172] train: loss: 0.1039644
[Epoch 84; Iter   154/  172] train: loss: 0.1264693
[Epoch 84] ogbg-moltoxcast: 0.729801 val loss: 0.213297
[Epoch 84] ogbg-moltoxcast: 0.734380 test loss: 0.213108
[Epoch 85; Iter    12/  172] train: loss: 0.1311163
[Epoch 85; Iter    42/  172] train: loss: 0.1437536
[Epoch 85; Iter    72/  172] train: loss: 0.0983441
[Epoch 85; Iter   102/  172] train: loss: 0.1747995
[Epoch 85; Iter   132/  172] train: loss: 0.1116596
[Epoch 85; Iter   162/  172] train: loss: 0.1313406
[Epoch 85] ogbg-moltoxcast: 0.732117 val loss: 0.211269
[Epoch 85] ogbg-moltoxcast: 0.733474 test loss: 0.211274
[Epoch 86; Iter    20/  172] train: loss: 0.1925490
[Epoch 86; Iter    50/  172] train: loss: 0.1075758
[Epoch 86; Iter    80/  172] train: loss: 0.1583274
[Epoch 86; Iter   110/  172] train: loss: 0.1202778
[Epoch 86; Iter   140/  172] train: loss: 0.1366838
[Epoch 86; Iter   170/  172] train: loss: 0.1617859
[Epoch 86] ogbg-moltoxcast: 0.727568 val loss: 0.213787
[Epoch 86] ogbg-moltoxcast: 0.727182 test loss: 0.215923
[Epoch 87; Iter    28/  172] train: loss: 0.1767127
[Epoch 87; Iter    58/  172] train: loss: 0.1252771
[Epoch 87; Iter    88/  172] train: loss: 0.1412106
[Epoch 87; Iter   118/  172] train: loss: 0.1129024
[Epoch 87; Iter   148/  172] train: loss: 0.1285174
[Epoch 87] ogbg-moltoxcast: 0.728879 val loss: 0.215028
[Epoch 87] ogbg-moltoxcast: 0.730062 test loss: 0.214869
[Epoch 88; Iter     6/  172] train: loss: 0.1024967
[Epoch 88; Iter    36/  172] train: loss: 0.1597220
[Epoch 88; Iter    66/  172] train: loss: 0.1942063
[Epoch 88; Iter    96/  172] train: loss: 0.1388779
[Epoch 88; Iter   126/  172] train: loss: 0.1343479
[Epoch 88; Iter   156/  172] train: loss: 0.1220039
[Epoch 88] ogbg-moltoxcast: 0.723229 val loss: 0.222472
[Epoch 88] ogbg-moltoxcast: 0.726357 test loss: 0.216852
[Epoch 89; Iter    14/  172] train: loss: 0.1289610
[Epoch 89; Iter    44/  172] train: loss: 0.1397795
[Epoch 89; Iter    74/  172] train: loss: 0.1164145
[Epoch 89; Iter   104/  172] train: loss: 0.0950966
[Epoch 89; Iter   134/  172] train: loss: 0.1592142
[Epoch 89; Iter   164/  172] train: loss: 0.1627944
[Epoch 89] ogbg-moltoxcast: 0.729395 val loss: 0.215171
[Epoch 89] ogbg-moltoxcast: 0.735804 test loss: 0.215362
[Epoch 90; Iter    22/  172] train: loss: 0.1471243
[Epoch 90; Iter    52/  172] train: loss: 0.0939318
[Epoch 90; Iter    82/  172] train: loss: 0.0897594
[Epoch 90; Iter   112/  172] train: loss: 0.1504821
[Epoch 90; Iter   142/  172] train: loss: 0.1564768
[Epoch 90; Iter   172/  172] train: loss: 0.1270045
[Epoch 90] ogbg-moltoxcast: 0.730449 val loss: 0.214856
[Epoch 90] ogbg-moltoxcast: 0.731230 test loss: 0.215399
[Epoch 91; Iter    30/  172] train: loss: 0.1244041
[Epoch 91; Iter    60/  172] train: loss: 0.1193174
[Epoch 91; Iter    90/  172] train: loss: 0.1012415
[Epoch 91; Iter   120/  172] train: loss: 0.1231593
[Epoch 91; Iter   150/  172] train: loss: 0.1509220
[Epoch 91] ogbg-moltoxcast: 0.729084 val loss: 0.214500
[Epoch 91] ogbg-moltoxcast: 0.729296 test loss: 0.215925
[Epoch 92; Iter     8/  172] train: loss: 0.1080246
[Epoch 92; Iter    38/  172] train: loss: 0.1326488
[Epoch 92; Iter    68/  172] train: loss: 0.0980066
[Epoch 92; Iter    98/  172] train: loss: 0.1381539
[Epoch 92; Iter   128/  172] train: loss: 0.1807059
[Epoch 92; Iter   158/  172] train: loss: 0.1044676
[Epoch 92] ogbg-moltoxcast: 0.733545 val loss: 0.213308
[Epoch 92] ogbg-moltoxcast: 0.728370 test loss: 0.217861
[Epoch 93; Iter    16/  172] train: loss: 0.1407093
[Epoch 93; Iter    46/  172] train: loss: 0.1666606
[Epoch 93; Iter    76/  172] train: loss: 0.1706524
[Epoch 93; Iter   106/  172] train: loss: 0.0994582
[Epoch 93; Iter   136/  172] train: loss: 0.1178036
[Epoch 93; Iter   166/  172] train: loss: 0.1250250
[Epoch 93] ogbg-moltoxcast: 0.732184 val loss: 0.215030
[Epoch 93] ogbg-moltoxcast: 0.729783 test loss: 0.217026
[Epoch 94; Iter    24/  172] train: loss: 0.0939990
[Epoch 94; Iter    54/  172] train: loss: 0.1123574
[Epoch 74; Iter   104/  172] train: loss: 0.1425094
[Epoch 74; Iter   134/  172] train: loss: 0.1069335
[Epoch 74; Iter   164/  172] train: loss: 0.1184936
[Epoch 74] ogbg-moltoxcast: 0.728138 val loss: 0.217815
[Epoch 74] ogbg-moltoxcast: 0.740259 test loss: 0.214035
[Epoch 75; Iter    22/  172] train: loss: 0.1469981
[Epoch 75; Iter    52/  172] train: loss: 0.1435646
[Epoch 75; Iter    82/  172] train: loss: 0.0771474
[Epoch 75; Iter   112/  172] train: loss: 0.1270178
[Epoch 75; Iter   142/  172] train: loss: 0.1437692
[Epoch 75; Iter   172/  172] train: loss: 0.1806413
[Epoch 75] ogbg-moltoxcast: 0.723568 val loss: 0.217300
[Epoch 75] ogbg-moltoxcast: 0.737657 test loss: 0.215636
[Epoch 76; Iter    30/  172] train: loss: 0.1693297
[Epoch 76; Iter    60/  172] train: loss: 0.1634178
[Epoch 76; Iter    90/  172] train: loss: 0.1279486
[Epoch 76; Iter   120/  172] train: loss: 0.1499233
[Epoch 76; Iter   150/  172] train: loss: 0.1243024
[Epoch 76] ogbg-moltoxcast: 0.731239 val loss: 0.215304
[Epoch 76] ogbg-moltoxcast: 0.739590 test loss: 0.213701
[Epoch 77; Iter     8/  172] train: loss: 0.1088120
[Epoch 77; Iter    38/  172] train: loss: 0.1460517
[Epoch 77; Iter    68/  172] train: loss: 0.1160281
[Epoch 77; Iter    98/  172] train: loss: 0.1347377
[Epoch 77; Iter   128/  172] train: loss: 0.1676942
[Epoch 77; Iter   158/  172] train: loss: 0.1292855
[Epoch 77] ogbg-moltoxcast: 0.728664 val loss: 0.217101
[Epoch 77] ogbg-moltoxcast: 0.739636 test loss: 0.214707
[Epoch 78; Iter    16/  172] train: loss: 0.0730143
[Epoch 78; Iter    46/  172] train: loss: 0.1031026
[Epoch 78; Iter    76/  172] train: loss: 0.1102122
[Epoch 78; Iter   106/  172] train: loss: 0.1530961
[Epoch 78; Iter   136/  172] train: loss: 0.1774202
[Epoch 78; Iter   166/  172] train: loss: 0.1125567
[Epoch 78] ogbg-moltoxcast: 0.727754 val loss: 0.219887
[Epoch 78] ogbg-moltoxcast: 0.741919 test loss: 0.216312
[Epoch 79; Iter    24/  172] train: loss: 0.1104577
[Epoch 79; Iter    54/  172] train: loss: 0.0949084
[Epoch 79; Iter    84/  172] train: loss: 0.1260891
[Epoch 79; Iter   114/  172] train: loss: 0.1629882
[Epoch 79; Iter   144/  172] train: loss: 0.1270065
[Epoch 79] ogbg-moltoxcast: 0.727381 val loss: 0.215400
[Epoch 79] ogbg-moltoxcast: 0.742250 test loss: 0.212409
[Epoch 80; Iter     2/  172] train: loss: 0.1260506
[Epoch 80; Iter    32/  172] train: loss: 0.1373502
[Epoch 80; Iter    62/  172] train: loss: 0.1556465
[Epoch 80; Iter    92/  172] train: loss: 0.1423010
[Epoch 80; Iter   122/  172] train: loss: 0.1330812
[Epoch 80; Iter   152/  172] train: loss: 0.1102671
[Epoch 80] ogbg-moltoxcast: 0.726597 val loss: 0.215756
[Epoch 80] ogbg-moltoxcast: 0.737777 test loss: 0.214599
[Epoch 81; Iter    10/  172] train: loss: 0.1590759
[Epoch 81; Iter    40/  172] train: loss: 0.1141483
[Epoch 81; Iter    70/  172] train: loss: 0.1217641
[Epoch 81; Iter   100/  172] train: loss: 0.1276916
[Epoch 81; Iter   130/  172] train: loss: 0.1387682
[Epoch 81; Iter   160/  172] train: loss: 0.1796433
[Epoch 81] ogbg-moltoxcast: 0.730266 val loss: 0.217405
[Epoch 81] ogbg-moltoxcast: 0.743466 test loss: 0.215354
[Epoch 82; Iter    18/  172] train: loss: 0.1277721
[Epoch 82; Iter    48/  172] train: loss: 0.1324105
[Epoch 82; Iter    78/  172] train: loss: 0.1366575
[Epoch 82; Iter   108/  172] train: loss: 0.1227155
[Epoch 82; Iter   138/  172] train: loss: 0.1520593
[Epoch 82; Iter   168/  172] train: loss: 0.1259804
[Epoch 82] ogbg-moltoxcast: 0.727944 val loss: 0.216653
[Epoch 82] ogbg-moltoxcast: 0.739312 test loss: 0.215849
[Epoch 83; Iter    26/  172] train: loss: 0.0935447
[Epoch 83; Iter    56/  172] train: loss: 0.1431512
[Epoch 83; Iter    86/  172] train: loss: 0.1955898
[Epoch 83; Iter   116/  172] train: loss: 0.1306254
[Epoch 83; Iter   146/  172] train: loss: 0.1293134
[Epoch 83] ogbg-moltoxcast: 0.727071 val loss: 0.220353
[Epoch 83] ogbg-moltoxcast: 0.741752 test loss: 0.217013
[Epoch 84; Iter     4/  172] train: loss: 0.1276384
[Epoch 84; Iter    34/  172] train: loss: 0.1340024
[Epoch 84; Iter    64/  172] train: loss: 0.1042500
[Epoch 84; Iter    94/  172] train: loss: 0.1222334
[Epoch 84; Iter   124/  172] train: loss: 0.1162684
[Epoch 84; Iter   154/  172] train: loss: 0.1632909
[Epoch 84] ogbg-moltoxcast: 0.728558 val loss: 0.220130
[Epoch 84] ogbg-moltoxcast: 0.739945 test loss: 0.216959
[Epoch 85; Iter    12/  172] train: loss: 0.1453791
[Epoch 85; Iter    42/  172] train: loss: 0.1220559
[Epoch 85; Iter    72/  172] train: loss: 0.1172391
[Epoch 85; Iter   102/  172] train: loss: 0.1017403
[Epoch 85; Iter   132/  172] train: loss: 0.1391884
[Epoch 85; Iter   162/  172] train: loss: 0.1604711
[Epoch 85] ogbg-moltoxcast: 0.726777 val loss: 0.218333
[Epoch 85] ogbg-moltoxcast: 0.736635 test loss: 0.217359
[Epoch 86; Iter    20/  172] train: loss: 0.1506068
[Epoch 86; Iter    50/  172] train: loss: 0.0770691
[Epoch 86; Iter    80/  172] train: loss: 0.1411858
[Epoch 86; Iter   110/  172] train: loss: 0.1558718
[Epoch 86; Iter   140/  172] train: loss: 0.1602915
[Epoch 86; Iter   170/  172] train: loss: 0.0905437
[Epoch 86] ogbg-moltoxcast: 0.723215 val loss: 0.221277
[Epoch 86] ogbg-moltoxcast: 0.738960 test loss: 0.217716
[Epoch 87; Iter    28/  172] train: loss: 0.1733190
[Epoch 87; Iter    58/  172] train: loss: 0.0848350
[Epoch 87; Iter    88/  172] train: loss: 0.1384513
[Epoch 87; Iter   118/  172] train: loss: 0.1340111
[Epoch 87; Iter   148/  172] train: loss: 0.1208003
[Epoch 87] ogbg-moltoxcast: 0.727530 val loss: 0.218540
[Epoch 87] ogbg-moltoxcast: 0.740826 test loss: 0.215367
[Epoch 88; Iter     6/  172] train: loss: 0.1685626
[Epoch 88; Iter    36/  172] train: loss: 0.0951834
[Epoch 88; Iter    66/  172] train: loss: 0.0991966
[Epoch 88; Iter    96/  172] train: loss: 0.1889835
[Epoch 88; Iter   126/  172] train: loss: 0.1592069
[Epoch 88; Iter   156/  172] train: loss: 0.1138912
[Epoch 88] ogbg-moltoxcast: 0.726522 val loss: 0.219967
[Epoch 88] ogbg-moltoxcast: 0.739695 test loss: 0.218054
[Epoch 89; Iter    14/  172] train: loss: 0.1595647
[Epoch 89; Iter    44/  172] train: loss: 0.0898408
[Epoch 89; Iter    74/  172] train: loss: 0.1731350
[Epoch 89; Iter   104/  172] train: loss: 0.1259298
[Epoch 89; Iter   134/  172] train: loss: 0.1321714
[Epoch 89; Iter   164/  172] train: loss: 0.1400570
[Epoch 89] ogbg-moltoxcast: 0.722783 val loss: 0.221563
[Epoch 89] ogbg-moltoxcast: 0.737694 test loss: 0.216545
[Epoch 90; Iter    22/  172] train: loss: 0.1163721
[Epoch 90; Iter    52/  172] train: loss: 0.1464374
[Epoch 90; Iter    82/  172] train: loss: 0.1208859
[Epoch 90; Iter   112/  172] train: loss: 0.1609511
[Epoch 90; Iter   142/  172] train: loss: 0.1054457
[Epoch 90; Iter   172/  172] train: loss: 0.1226829
[Epoch 90] ogbg-moltoxcast: 0.724214 val loss: 0.223074
[Epoch 90] ogbg-moltoxcast: 0.741266 test loss: 0.218013
[Epoch 91; Iter    30/  172] train: loss: 0.1057107
[Epoch 91; Iter    60/  172] train: loss: 0.0941444
[Epoch 91; Iter    90/  172] train: loss: 0.1667280
[Epoch 91; Iter   120/  172] train: loss: 0.1029738
[Epoch 91; Iter   150/  172] train: loss: 0.1262595
[Epoch 91] ogbg-moltoxcast: 0.722365 val loss: 0.222595
[Epoch 91] ogbg-moltoxcast: 0.739170 test loss: 0.218208
[Epoch 92; Iter     8/  172] train: loss: 0.1193266
[Epoch 92; Iter    38/  172] train: loss: 0.1060096
[Epoch 92; Iter    68/  172] train: loss: 0.1259424
[Epoch 92; Iter    98/  172] train: loss: 0.0824744
[Epoch 92; Iter   128/  172] train: loss: 0.1034689
[Epoch 92; Iter   158/  172] train: loss: 0.1485842
[Epoch 92] ogbg-moltoxcast: 0.727114 val loss: 0.221806
[Epoch 92] ogbg-moltoxcast: 0.740774 test loss: 0.218160
[Epoch 93; Iter    16/  172] train: loss: 0.0982253
[Epoch 93; Iter    46/  172] train: loss: 0.1718283
[Epoch 93; Iter    76/  172] train: loss: 0.1806743
[Epoch 93; Iter   106/  172] train: loss: 0.1033256
[Epoch 93; Iter   136/  172] train: loss: 0.1187018
[Epoch 93; Iter   166/  172] train: loss: 0.1081243
[Epoch 93] ogbg-moltoxcast: 0.725029 val loss: 0.220427
[Epoch 93] ogbg-moltoxcast: 0.741309 test loss: 0.215647
[Epoch 94; Iter    24/  172] train: loss: 0.1404900
[Epoch 94; Iter    54/  172] train: loss: 0.1346254
[Epoch 76; Iter    15/  229] train: loss: 0.1142944
[Epoch 76; Iter    45/  229] train: loss: 0.2112593
[Epoch 76; Iter    75/  229] train: loss: 0.1526041
[Epoch 76; Iter   105/  229] train: loss: 0.1420414
[Epoch 76; Iter   135/  229] train: loss: 0.1155828
[Epoch 76; Iter   165/  229] train: loss: 0.1776162
[Epoch 76; Iter   195/  229] train: loss: 0.1171905
[Epoch 76; Iter   225/  229] train: loss: 0.1647594
[Epoch 76] ogbg-moltoxcast: 0.743451 val loss: 0.196053
[Epoch 76] ogbg-moltoxcast: 0.754864 test loss: 0.211358
[Epoch 77; Iter    26/  229] train: loss: 0.1387389
[Epoch 77; Iter    56/  229] train: loss: 0.1196159
[Epoch 77; Iter    86/  229] train: loss: 0.2070694
[Epoch 77; Iter   116/  229] train: loss: 0.1484632
[Epoch 77; Iter   146/  229] train: loss: 0.1398766
[Epoch 77; Iter   176/  229] train: loss: 0.1333279
[Epoch 77; Iter   206/  229] train: loss: 0.1130381
[Epoch 77] ogbg-moltoxcast: 0.741933 val loss: 0.198485
[Epoch 77] ogbg-moltoxcast: 0.757196 test loss: 0.211196
[Epoch 78; Iter     7/  229] train: loss: 0.1007266
[Epoch 78; Iter    37/  229] train: loss: 0.1772920
[Epoch 78; Iter    67/  229] train: loss: 0.1264240
[Epoch 78; Iter    97/  229] train: loss: 0.1668444
[Epoch 78; Iter   127/  229] train: loss: 0.1264758
[Epoch 78; Iter   157/  229] train: loss: 0.1317229
[Epoch 78; Iter   187/  229] train: loss: 0.1044232
[Epoch 78; Iter   217/  229] train: loss: 0.1206082
[Epoch 78] ogbg-moltoxcast: 0.741986 val loss: 0.197193
[Epoch 78] ogbg-moltoxcast: 0.756754 test loss: 0.213587
[Epoch 79; Iter    18/  229] train: loss: 0.1796977
[Epoch 79; Iter    48/  229] train: loss: 0.1621632
[Epoch 79; Iter    78/  229] train: loss: 0.1566721
[Epoch 79; Iter   108/  229] train: loss: 0.1049797
[Epoch 79; Iter   138/  229] train: loss: 0.1478655
[Epoch 79; Iter   168/  229] train: loss: 0.0899840
[Epoch 79; Iter   198/  229] train: loss: 0.1507329
[Epoch 79; Iter   228/  229] train: loss: 0.1421821
[Epoch 79] ogbg-moltoxcast: 0.740081 val loss: 0.197124
[Epoch 79] ogbg-moltoxcast: 0.755063 test loss: 0.211899
[Epoch 80; Iter    29/  229] train: loss: 0.1346463
[Epoch 80; Iter    59/  229] train: loss: 0.1326639
[Epoch 80; Iter    89/  229] train: loss: 0.0935276
[Epoch 80; Iter   119/  229] train: loss: 0.1629231
[Epoch 80; Iter   149/  229] train: loss: 0.1492864
[Epoch 80; Iter   179/  229] train: loss: 0.1399455
[Epoch 80; Iter   209/  229] train: loss: 0.1268759
[Epoch 80] ogbg-moltoxcast: 0.745232 val loss: 0.196143
[Epoch 80] ogbg-moltoxcast: 0.757334 test loss: 0.212546
[Epoch 81; Iter    10/  229] train: loss: 0.1966459
[Epoch 81; Iter    40/  229] train: loss: 0.1346352
[Epoch 81; Iter    70/  229] train: loss: 0.0914322
[Epoch 81; Iter   100/  229] train: loss: 0.1189266
[Epoch 81; Iter   130/  229] train: loss: 0.1596941
[Epoch 81; Iter   160/  229] train: loss: 0.1257013
[Epoch 81; Iter   190/  229] train: loss: 0.1277531
[Epoch 81; Iter   220/  229] train: loss: 0.1426823
[Epoch 81] ogbg-moltoxcast: 0.742324 val loss: 0.199824
[Epoch 81] ogbg-moltoxcast: 0.757556 test loss: 0.213083
[Epoch 82; Iter    21/  229] train: loss: 0.1176000
[Epoch 82; Iter    51/  229] train: loss: 0.1189897
[Epoch 82; Iter    81/  229] train: loss: 0.1740770
[Epoch 82; Iter   111/  229] train: loss: 0.1552755
[Epoch 82; Iter   141/  229] train: loss: 0.1273300
[Epoch 82; Iter   171/  229] train: loss: 0.1574417
[Epoch 82; Iter   201/  229] train: loss: 0.1320136
[Epoch 82] ogbg-moltoxcast: 0.741013 val loss: 0.198153
[Epoch 82] ogbg-moltoxcast: 0.750810 test loss: 0.212178
[Epoch 83; Iter     2/  229] train: loss: 0.1923776
[Epoch 83; Iter    32/  229] train: loss: 0.1427582
[Epoch 83; Iter    62/  229] train: loss: 0.1473968
[Epoch 83; Iter    92/  229] train: loss: 0.1741714
[Epoch 83; Iter   122/  229] train: loss: 0.1378298
[Epoch 83; Iter   152/  229] train: loss: 0.1452253
[Epoch 83; Iter   182/  229] train: loss: 0.0934860
[Epoch 83; Iter   212/  229] train: loss: 0.1359141
[Epoch 83] ogbg-moltoxcast: 0.738489 val loss: 0.197374
[Epoch 83] ogbg-moltoxcast: 0.748864 test loss: 0.212724
[Epoch 84; Iter    13/  229] train: loss: 0.1118189
[Epoch 84; Iter    43/  229] train: loss: 0.1453193
[Epoch 84; Iter    73/  229] train: loss: 0.1185132
[Epoch 84; Iter   103/  229] train: loss: 0.1297977
[Epoch 84; Iter   133/  229] train: loss: 0.1581254
[Epoch 84; Iter   163/  229] train: loss: 0.1365207
[Epoch 84; Iter   193/  229] train: loss: 0.1549676
[Epoch 84; Iter   223/  229] train: loss: 0.1180061
[Epoch 84] ogbg-moltoxcast: 0.738272 val loss: 0.200996
[Epoch 84] ogbg-moltoxcast: 0.754260 test loss: 0.213853
[Epoch 85; Iter    24/  229] train: loss: 0.2159144
[Epoch 85; Iter    54/  229] train: loss: 0.1766998
[Epoch 85; Iter    84/  229] train: loss: 0.1609280
[Epoch 85; Iter   114/  229] train: loss: 0.1374637
[Epoch 85; Iter   144/  229] train: loss: 0.1170719
[Epoch 85; Iter   174/  229] train: loss: 0.1396412
[Epoch 85; Iter   204/  229] train: loss: 0.1191437
[Epoch 85] ogbg-moltoxcast: 0.742766 val loss: 0.196628
[Epoch 85] ogbg-moltoxcast: 0.755858 test loss: 0.214443
[Epoch 86; Iter     5/  229] train: loss: 0.1762262
[Epoch 86; Iter    35/  229] train: loss: 0.0846636
[Epoch 86; Iter    65/  229] train: loss: 0.2392417
[Epoch 86; Iter    95/  229] train: loss: 0.1454801
[Epoch 86; Iter   125/  229] train: loss: 0.1424186
[Epoch 86; Iter   155/  229] train: loss: 0.1495537
[Epoch 86; Iter   185/  229] train: loss: 0.1453447
[Epoch 86; Iter   215/  229] train: loss: 0.1375958
[Epoch 86] ogbg-moltoxcast: 0.741985 val loss: 0.197538
[Epoch 86] ogbg-moltoxcast: 0.754362 test loss: 0.212545
[Epoch 87; Iter    16/  229] train: loss: 0.1055297
[Epoch 87; Iter    46/  229] train: loss: 0.1330590
[Epoch 87; Iter    76/  229] train: loss: 0.1350861
[Epoch 87; Iter   106/  229] train: loss: 0.1807814
[Epoch 87; Iter   136/  229] train: loss: 0.1736901
[Epoch 87; Iter   166/  229] train: loss: 0.1744621
[Epoch 87; Iter   196/  229] train: loss: 0.1048949
[Epoch 87; Iter   226/  229] train: loss: 0.1441813
[Epoch 87] ogbg-moltoxcast: 0.743298 val loss: 0.196781
[Epoch 87] ogbg-moltoxcast: 0.752784 test loss: 0.212975
[Epoch 88; Iter    27/  229] train: loss: 0.1290780
[Epoch 88; Iter    57/  229] train: loss: 0.1199042
[Epoch 88; Iter    87/  229] train: loss: 0.1314516
[Epoch 88; Iter   117/  229] train: loss: 0.1343913
[Epoch 88; Iter   147/  229] train: loss: 0.1503288
[Epoch 88; Iter   177/  229] train: loss: 0.1180965
[Epoch 88; Iter   207/  229] train: loss: 0.1228810
[Epoch 88] ogbg-moltoxcast: 0.747213 val loss: 0.195695
[Epoch 88] ogbg-moltoxcast: 0.754456 test loss: 0.214502
[Epoch 89; Iter     8/  229] train: loss: 0.1163206
[Epoch 89; Iter    38/  229] train: loss: 0.1368038
[Epoch 89; Iter    68/  229] train: loss: 0.1523474
[Epoch 89; Iter    98/  229] train: loss: 0.1173141
[Epoch 89; Iter   128/  229] train: loss: 0.1130348
[Epoch 89; Iter   158/  229] train: loss: 0.1385417
[Epoch 89; Iter   188/  229] train: loss: 0.1478347
[Epoch 89; Iter   218/  229] train: loss: 0.1519054
[Epoch 89] ogbg-moltoxcast: 0.741757 val loss: 0.197895
[Epoch 89] ogbg-moltoxcast: 0.750289 test loss: 0.215192
[Epoch 90; Iter    19/  229] train: loss: 0.1722757
[Epoch 90; Iter    49/  229] train: loss: 0.1422217
[Epoch 90; Iter    79/  229] train: loss: 0.1246537
[Epoch 90; Iter   109/  229] train: loss: 0.1656174
[Epoch 90; Iter   139/  229] train: loss: 0.1654003
[Epoch 90; Iter   169/  229] train: loss: 0.1580938
[Epoch 90; Iter   199/  229] train: loss: 0.1870124
[Epoch 90; Iter   229/  229] train: loss: 0.1313974
[Epoch 90] ogbg-moltoxcast: 0.743557 val loss: 0.196176
[Epoch 90] ogbg-moltoxcast: 0.753425 test loss: 0.214395
[Epoch 91; Iter    30/  229] train: loss: 0.1573337
[Epoch 91; Iter    60/  229] train: loss: 0.1518001
[Epoch 91; Iter    90/  229] train: loss: 0.1065845
[Epoch 91; Iter   120/  229] train: loss: 0.1588173
[Epoch 91; Iter   150/  229] train: loss: 0.1443001
[Epoch 91; Iter   180/  229] train: loss: 0.1311159
[Epoch 91; Iter   210/  229] train: loss: 0.1223418
[Epoch 91] ogbg-moltoxcast: 0.741595 val loss: 0.205219
[Epoch 91] ogbg-moltoxcast: 0.754579 test loss: 0.217157
[Epoch 76; Iter    15/  229] train: loss: 0.1583114
[Epoch 76; Iter    45/  229] train: loss: 0.1043554
[Epoch 76; Iter    75/  229] train: loss: 0.1095557
[Epoch 76; Iter   105/  229] train: loss: 0.1251812
[Epoch 76; Iter   135/  229] train: loss: 0.1098903
[Epoch 76; Iter   165/  229] train: loss: 0.1492149
[Epoch 76; Iter   195/  229] train: loss: 0.1168089
[Epoch 76; Iter   225/  229] train: loss: 0.1661735
[Epoch 76] ogbg-moltoxcast: 0.758298 val loss: 0.201687
[Epoch 76] ogbg-moltoxcast: 0.754925 test loss: 0.214628
[Epoch 77; Iter    26/  229] train: loss: 0.1568779
[Epoch 77; Iter    56/  229] train: loss: 0.2010325
[Epoch 77; Iter    86/  229] train: loss: 0.1375517
[Epoch 77; Iter   116/  229] train: loss: 0.1354613
[Epoch 77; Iter   146/  229] train: loss: 0.1412544
[Epoch 77; Iter   176/  229] train: loss: 0.1298892
[Epoch 77; Iter   206/  229] train: loss: 0.1331889
[Epoch 77] ogbg-moltoxcast: 0.756399 val loss: 0.197137
[Epoch 77] ogbg-moltoxcast: 0.762087 test loss: 0.203707
[Epoch 78; Iter     7/  229] train: loss: 0.1478272
[Epoch 78; Iter    37/  229] train: loss: 0.1728460
[Epoch 78; Iter    67/  229] train: loss: 0.1828455
[Epoch 78; Iter    97/  229] train: loss: 0.1551328
[Epoch 78; Iter   127/  229] train: loss: 0.1702526
[Epoch 78; Iter   157/  229] train: loss: 0.1920669
[Epoch 78; Iter   187/  229] train: loss: 0.1508167
[Epoch 78; Iter   217/  229] train: loss: 0.1172458
[Epoch 78] ogbg-moltoxcast: 0.764023 val loss: 0.192674
[Epoch 78] ogbg-moltoxcast: 0.762768 test loss: 0.203869
[Epoch 79; Iter    18/  229] train: loss: 0.1124261
[Epoch 79; Iter    48/  229] train: loss: 0.1069881
[Epoch 79; Iter    78/  229] train: loss: 0.1520724
[Epoch 79; Iter   108/  229] train: loss: 0.1158983
[Epoch 79; Iter   138/  229] train: loss: 0.1728727
[Epoch 79; Iter   168/  229] train: loss: 0.1115627
[Epoch 79; Iter   198/  229] train: loss: 0.1241485
[Epoch 79; Iter   228/  229] train: loss: 0.2204599
[Epoch 79] ogbg-moltoxcast: 0.756969 val loss: 0.200125
[Epoch 79] ogbg-moltoxcast: 0.763501 test loss: 0.210236
[Epoch 80; Iter    29/  229] train: loss: 0.1260243
[Epoch 80; Iter    59/  229] train: loss: 0.1547717
[Epoch 80; Iter    89/  229] train: loss: 0.1140040
[Epoch 80; Iter   119/  229] train: loss: 0.0988753
[Epoch 80; Iter   149/  229] train: loss: 0.1741561
[Epoch 80; Iter   179/  229] train: loss: 0.1761816
[Epoch 80; Iter   209/  229] train: loss: 0.1612720
[Epoch 80] ogbg-moltoxcast: 0.757400 val loss: 0.198842
[Epoch 80] ogbg-moltoxcast: 0.757025 test loss: 0.209056
[Epoch 81; Iter    10/  229] train: loss: 0.1310295
[Epoch 81; Iter    40/  229] train: loss: 0.1349552
[Epoch 81; Iter    70/  229] train: loss: 0.1627432
[Epoch 81; Iter   100/  229] train: loss: 0.1024373
[Epoch 81; Iter   130/  229] train: loss: 0.1453942
[Epoch 81; Iter   160/  229] train: loss: 0.1506267
[Epoch 81; Iter   190/  229] train: loss: 0.1249591
[Epoch 81; Iter   220/  229] train: loss: 0.1111404
[Epoch 81] ogbg-moltoxcast: 0.757573 val loss: 0.196672
[Epoch 81] ogbg-moltoxcast: 0.762080 test loss: 0.207323
[Epoch 82; Iter    21/  229] train: loss: 0.1495355
[Epoch 82; Iter    51/  229] train: loss: 0.1172378
[Epoch 82; Iter    81/  229] train: loss: 0.1976747
[Epoch 82; Iter   111/  229] train: loss: 0.1397474
[Epoch 82; Iter   141/  229] train: loss: 0.1591524
[Epoch 82; Iter   171/  229] train: loss: 0.1643135
[Epoch 82; Iter   201/  229] train: loss: 0.1903917
[Epoch 82] ogbg-moltoxcast: 0.752767 val loss: 0.200622
[Epoch 82] ogbg-moltoxcast: 0.754468 test loss: 0.208932
[Epoch 83; Iter     2/  229] train: loss: 0.1314935
[Epoch 83; Iter    32/  229] train: loss: 0.1423919
[Epoch 83; Iter    62/  229] train: loss: 0.1298749
[Epoch 83; Iter    92/  229] train: loss: 0.1125050
[Epoch 83; Iter   122/  229] train: loss: 0.1063286
[Epoch 83; Iter   152/  229] train: loss: 0.1065818
[Epoch 83; Iter   182/  229] train: loss: 0.1718839
[Epoch 83; Iter   212/  229] train: loss: 0.1235006
[Epoch 83] ogbg-moltoxcast: 0.759144 val loss: 0.199604
[Epoch 83] ogbg-moltoxcast: 0.763875 test loss: 0.208030
[Epoch 84; Iter    13/  229] train: loss: 0.0806194
[Epoch 84; Iter    43/  229] train: loss: 0.1203182
[Epoch 84; Iter    73/  229] train: loss: 0.2109884
[Epoch 84; Iter   103/  229] train: loss: 0.1379097
[Epoch 84; Iter   133/  229] train: loss: 0.1761421
[Epoch 84; Iter   163/  229] train: loss: 0.1247764
[Epoch 84; Iter   193/  229] train: loss: 0.2001916
[Epoch 84; Iter   223/  229] train: loss: 0.1385275
[Epoch 84] ogbg-moltoxcast: 0.761990 val loss: 0.196330
[Epoch 84] ogbg-moltoxcast: 0.760626 test loss: 0.209929
[Epoch 85; Iter    24/  229] train: loss: 0.1582373
[Epoch 85; Iter    54/  229] train: loss: 0.1344106
[Epoch 85; Iter    84/  229] train: loss: 0.1616302
[Epoch 85; Iter   114/  229] train: loss: 0.1364212
[Epoch 85; Iter   144/  229] train: loss: 0.1321264
[Epoch 85; Iter   174/  229] train: loss: 0.1631034
[Epoch 85; Iter   204/  229] train: loss: 0.1684601
[Epoch 85] ogbg-moltoxcast: 0.757761 val loss: 0.200348
[Epoch 85] ogbg-moltoxcast: 0.758431 test loss: 0.211554
[Epoch 86; Iter     5/  229] train: loss: 0.1265965
[Epoch 86; Iter    35/  229] train: loss: 0.1289913
[Epoch 86; Iter    65/  229] train: loss: 0.1857867
[Epoch 86; Iter    95/  229] train: loss: 0.1256952
[Epoch 86; Iter   125/  229] train: loss: 0.0763016
[Epoch 86; Iter   155/  229] train: loss: 0.1280702
[Epoch 86; Iter   185/  229] train: loss: 0.1244850
[Epoch 86; Iter   215/  229] train: loss: 0.1257559
[Epoch 86] ogbg-moltoxcast: 0.758556 val loss: 0.200343
[Epoch 86] ogbg-moltoxcast: 0.764287 test loss: 0.209806
[Epoch 87; Iter    16/  229] train: loss: 0.1212454
[Epoch 87; Iter    46/  229] train: loss: 0.1647844
[Epoch 87; Iter    76/  229] train: loss: 0.1582776
[Epoch 87; Iter   106/  229] train: loss: 0.1554181
[Epoch 87; Iter   136/  229] train: loss: 0.1049876
[Epoch 87; Iter   166/  229] train: loss: 0.1809836
[Epoch 87; Iter   196/  229] train: loss: 0.1802823
[Epoch 87; Iter   226/  229] train: loss: 0.1492309
[Epoch 87] ogbg-moltoxcast: 0.762893 val loss: 0.195646
[Epoch 87] ogbg-moltoxcast: 0.762066 test loss: 0.207585
[Epoch 88; Iter    27/  229] train: loss: 0.1276346
[Epoch 88; Iter    57/  229] train: loss: 0.1391045
[Epoch 88; Iter    87/  229] train: loss: 0.1836835
[Epoch 88; Iter   117/  229] train: loss: 0.1536482
[Epoch 88; Iter   147/  229] train: loss: 0.1207363
[Epoch 88; Iter   177/  229] train: loss: 0.1091628
[Epoch 88; Iter   207/  229] train: loss: 0.1769322
[Epoch 88] ogbg-moltoxcast: 0.759424 val loss: 0.198887
[Epoch 88] ogbg-moltoxcast: 0.763012 test loss: 0.206618
[Epoch 89; Iter     8/  229] train: loss: 0.0805653
[Epoch 89; Iter    38/  229] train: loss: 0.1117336
[Epoch 89; Iter    68/  229] train: loss: 0.0971649
[Epoch 89; Iter    98/  229] train: loss: 0.1184502
[Epoch 89; Iter   128/  229] train: loss: 0.1406679
[Epoch 89; Iter   158/  229] train: loss: 0.1795617
[Epoch 89; Iter   188/  229] train: loss: 0.1334306
[Epoch 89; Iter   218/  229] train: loss: 0.1907077
[Epoch 89] ogbg-moltoxcast: 0.761515 val loss: 0.197967
[Epoch 89] ogbg-moltoxcast: 0.758280 test loss: 0.210873
[Epoch 90; Iter    19/  229] train: loss: 0.1577646
[Epoch 90; Iter    49/  229] train: loss: 0.2165291
[Epoch 90; Iter    79/  229] train: loss: 0.1824754
[Epoch 90; Iter   109/  229] train: loss: 0.1004036
[Epoch 90; Iter   139/  229] train: loss: 0.1237629
[Epoch 90; Iter   169/  229] train: loss: 0.0780589
[Epoch 90; Iter   199/  229] train: loss: 0.1424360
[Epoch 90; Iter   229/  229] train: loss: 0.1201981
[Epoch 90] ogbg-moltoxcast: 0.757617 val loss: 0.200257
[Epoch 90] ogbg-moltoxcast: 0.758831 test loss: 0.208891
[Epoch 91; Iter    30/  229] train: loss: 0.1124897
[Epoch 91; Iter    60/  229] train: loss: 0.1726692
[Epoch 91; Iter    90/  229] train: loss: 0.1962274
[Epoch 91; Iter   120/  229] train: loss: 0.2141333
[Epoch 91; Iter   150/  229] train: loss: 0.0998984
[Epoch 91; Iter   180/  229] train: loss: 0.1374773
[Epoch 91; Iter   210/  229] train: loss: 0.1501721
[Epoch 91] ogbg-moltoxcast: 0.761044 val loss: 0.197615
[Epoch 91] ogbg-moltoxcast: 0.760574 test loss: 0.211551
[Epoch 76; Iter    15/  229] train: loss: 0.1403728
[Epoch 76; Iter    45/  229] train: loss: 0.0888908
[Epoch 76; Iter    75/  229] train: loss: 0.1659000
[Epoch 76; Iter   105/  229] train: loss: 0.1738744
[Epoch 76; Iter   135/  229] train: loss: 0.1289633
[Epoch 76; Iter   165/  229] train: loss: 0.1456913
[Epoch 76; Iter   195/  229] train: loss: 0.1075385
[Epoch 76; Iter   225/  229] train: loss: 0.1137324
[Epoch 76] ogbg-moltoxcast: 0.737951 val loss: 0.197404
[Epoch 76] ogbg-moltoxcast: 0.762321 test loss: 0.214423
[Epoch 77; Iter    26/  229] train: loss: 0.1260185
[Epoch 77; Iter    56/  229] train: loss: 0.1733701
[Epoch 77; Iter    86/  229] train: loss: 0.0724584
[Epoch 77; Iter   116/  229] train: loss: 0.1488887
[Epoch 77; Iter   146/  229] train: loss: 0.1064443
[Epoch 77; Iter   176/  229] train: loss: 0.1195639
[Epoch 77; Iter   206/  229] train: loss: 0.0977706
[Epoch 77] ogbg-moltoxcast: 0.732659 val loss: 0.199514
[Epoch 77] ogbg-moltoxcast: 0.767670 test loss: 0.213740
[Epoch 78; Iter     7/  229] train: loss: 0.1336820
[Epoch 78; Iter    37/  229] train: loss: 0.1084431
[Epoch 78; Iter    67/  229] train: loss: 0.1016885
[Epoch 78; Iter    97/  229] train: loss: 0.1629001
[Epoch 78; Iter   127/  229] train: loss: 0.1871686
[Epoch 78; Iter   157/  229] train: loss: 0.1354081
[Epoch 78; Iter   187/  229] train: loss: 0.1314505
[Epoch 78; Iter   217/  229] train: loss: 0.1978547
[Epoch 78] ogbg-moltoxcast: 0.739850 val loss: 0.195116
[Epoch 78] ogbg-moltoxcast: 0.769927 test loss: 0.209945
[Epoch 79; Iter    18/  229] train: loss: 0.1412092
[Epoch 79; Iter    48/  229] train: loss: 0.1114730
[Epoch 79; Iter    78/  229] train: loss: 0.1091529
[Epoch 79; Iter   108/  229] train: loss: 0.1535595
[Epoch 79; Iter   138/  229] train: loss: 0.2108529
[Epoch 79; Iter   168/  229] train: loss: 0.1346442
[Epoch 79; Iter   198/  229] train: loss: 0.1250973
[Epoch 79; Iter   228/  229] train: loss: 0.1790181
[Epoch 79] ogbg-moltoxcast: 0.736925 val loss: 0.198330
[Epoch 79] ogbg-moltoxcast: 0.762046 test loss: 0.214260
[Epoch 80; Iter    29/  229] train: loss: 0.2119730
[Epoch 80; Iter    59/  229] train: loss: 0.1190326
[Epoch 80; Iter    89/  229] train: loss: 0.1059810
[Epoch 80; Iter   119/  229] train: loss: 0.1165992
[Epoch 80; Iter   149/  229] train: loss: 0.1609450
[Epoch 80; Iter   179/  229] train: loss: 0.1610013
[Epoch 80; Iter   209/  229] train: loss: 0.1237815
[Epoch 80] ogbg-moltoxcast: 0.739467 val loss: 0.197057
[Epoch 80] ogbg-moltoxcast: 0.763265 test loss: 0.213821
[Epoch 81; Iter    10/  229] train: loss: 0.2435188
[Epoch 81; Iter    40/  229] train: loss: 0.0927229
[Epoch 81; Iter    70/  229] train: loss: 0.1387449
[Epoch 81; Iter   100/  229] train: loss: 0.1170048
[Epoch 81; Iter   130/  229] train: loss: 0.0979411
[Epoch 81; Iter   160/  229] train: loss: 0.1401776
[Epoch 81; Iter   190/  229] train: loss: 0.1613016
[Epoch 81; Iter   220/  229] train: loss: 0.1590712
[Epoch 81] ogbg-moltoxcast: 0.738635 val loss: 0.196952
[Epoch 81] ogbg-moltoxcast: 0.764315 test loss: 0.212976
[Epoch 82; Iter    21/  229] train: loss: 0.1643220
[Epoch 82; Iter    51/  229] train: loss: 0.1386046
[Epoch 82; Iter    81/  229] train: loss: 0.1342836
[Epoch 82; Iter   111/  229] train: loss: 0.1472820
[Epoch 82; Iter   141/  229] train: loss: 0.0996853
[Epoch 82; Iter   171/  229] train: loss: 0.1613502
[Epoch 82; Iter   201/  229] train: loss: 0.1309316
[Epoch 82] ogbg-moltoxcast: 0.737377 val loss: 0.198780
[Epoch 82] ogbg-moltoxcast: 0.764100 test loss: 0.216612
[Epoch 83; Iter     2/  229] train: loss: 0.1406056
[Epoch 83; Iter    32/  229] train: loss: 0.1002176
[Epoch 83; Iter    62/  229] train: loss: 0.1392215
[Epoch 83; Iter    92/  229] train: loss: 0.0914603
[Epoch 83; Iter   122/  229] train: loss: 0.0888611
[Epoch 83; Iter   152/  229] train: loss: 0.0992632
[Epoch 83; Iter   182/  229] train: loss: 0.1527561
[Epoch 83; Iter   212/  229] train: loss: 0.1675729
[Epoch 83] ogbg-moltoxcast: 0.742340 val loss: 0.196223
[Epoch 83] ogbg-moltoxcast: 0.768129 test loss: 0.214325
[Epoch 84; Iter    13/  229] train: loss: 0.0911038
[Epoch 84; Iter    43/  229] train: loss: 0.1872114
[Epoch 84; Iter    73/  229] train: loss: 0.1519223
[Epoch 84; Iter   103/  229] train: loss: 0.1342902
[Epoch 84; Iter   133/  229] train: loss: 0.1317261
[Epoch 84; Iter   163/  229] train: loss: 0.1632992
[Epoch 84; Iter   193/  229] train: loss: 0.1640888
[Epoch 84; Iter   223/  229] train: loss: 0.1286184
[Epoch 84] ogbg-moltoxcast: 0.740771 val loss: 0.198082
[Epoch 84] ogbg-moltoxcast: 0.762561 test loss: 0.214895
[Epoch 85; Iter    24/  229] train: loss: 0.1858461
[Epoch 85; Iter    54/  229] train: loss: 0.1439391
[Epoch 85; Iter    84/  229] train: loss: 0.1157166
[Epoch 85; Iter   114/  229] train: loss: 0.1378895
[Epoch 85; Iter   144/  229] train: loss: 0.1726186
[Epoch 85; Iter   174/  229] train: loss: 0.1640380
[Epoch 85; Iter   204/  229] train: loss: 0.1688907
[Epoch 85] ogbg-moltoxcast: 0.736583 val loss: 0.199239
[Epoch 85] ogbg-moltoxcast: 0.761417 test loss: 0.213433
[Epoch 86; Iter     5/  229] train: loss: 0.1115186
[Epoch 86; Iter    35/  229] train: loss: 0.1024870
[Epoch 86; Iter    65/  229] train: loss: 0.1615814
[Epoch 86; Iter    95/  229] train: loss: 0.1727188
[Epoch 86; Iter   125/  229] train: loss: 0.0828250
[Epoch 86; Iter   155/  229] train: loss: 0.1565951
[Epoch 86; Iter   185/  229] train: loss: 0.0978922
[Epoch 86; Iter   215/  229] train: loss: 0.1478257
[Epoch 86] ogbg-moltoxcast: 0.738135 val loss: 0.196451
[Epoch 86] ogbg-moltoxcast: 0.763440 test loss: 0.214485
[Epoch 87; Iter    16/  229] train: loss: 0.1150022
[Epoch 87; Iter    46/  229] train: loss: 0.1312162
[Epoch 87; Iter    76/  229] train: loss: 0.1696852
[Epoch 87; Iter   106/  229] train: loss: 0.1741360
[Epoch 87; Iter   136/  229] train: loss: 0.1088374
[Epoch 87; Iter   166/  229] train: loss: 0.1273755
[Epoch 87; Iter   196/  229] train: loss: 0.0855868
[Epoch 87; Iter   226/  229] train: loss: 0.1595536
[Epoch 87] ogbg-moltoxcast: 0.740085 val loss: 0.196945
[Epoch 87] ogbg-moltoxcast: 0.765597 test loss: 0.213370
[Epoch 88; Iter    27/  229] train: loss: 0.0962530
[Epoch 88; Iter    57/  229] train: loss: 0.1520142
[Epoch 88; Iter    87/  229] train: loss: 0.1695510
[Epoch 88; Iter   117/  229] train: loss: 0.1723760
[Epoch 88; Iter   147/  229] train: loss: 0.1272579
[Epoch 88; Iter   177/  229] train: loss: 0.1332784
[Epoch 88; Iter   207/  229] train: loss: 0.1183034
[Epoch 88] ogbg-moltoxcast: 0.737252 val loss: 0.198663
[Epoch 88] ogbg-moltoxcast: 0.765883 test loss: 0.213071
[Epoch 89; Iter     8/  229] train: loss: 0.1531693
[Epoch 89; Iter    38/  229] train: loss: 0.1512457
[Epoch 89; Iter    68/  229] train: loss: 0.1656531
[Epoch 89; Iter    98/  229] train: loss: 0.1234975
[Epoch 89; Iter   128/  229] train: loss: 0.1627585
[Epoch 89; Iter   158/  229] train: loss: 0.0874345
[Epoch 89; Iter   188/  229] train: loss: 0.1724483
[Epoch 89; Iter   218/  229] train: loss: 0.1479692
[Epoch 89] ogbg-moltoxcast: 0.740677 val loss: 0.199547
[Epoch 89] ogbg-moltoxcast: 0.770765 test loss: 0.216685
[Epoch 90; Iter    19/  229] train: loss: 0.1251124
[Epoch 90; Iter    49/  229] train: loss: 0.1633403
[Epoch 90; Iter    79/  229] train: loss: 0.1104913
[Epoch 90; Iter   109/  229] train: loss: 0.1583014
[Epoch 90; Iter   139/  229] train: loss: 0.1701786
[Epoch 90; Iter   169/  229] train: loss: 0.1055437
[Epoch 90; Iter   199/  229] train: loss: 0.1003521
[Epoch 90; Iter   229/  229] train: loss: 0.1448012
[Epoch 90] ogbg-moltoxcast: 0.742838 val loss: 0.196921
[Epoch 90] ogbg-moltoxcast: 0.767387 test loss: 0.214853
[Epoch 91; Iter    30/  229] train: loss: 0.1417733
[Epoch 91; Iter    60/  229] train: loss: 0.1127545
[Epoch 91; Iter    90/  229] train: loss: 0.1372044
[Epoch 91; Iter   120/  229] train: loss: 0.1412032
[Epoch 91; Iter   150/  229] train: loss: 0.1600111
[Epoch 91; Iter   180/  229] train: loss: 0.1359895
[Epoch 91; Iter   210/  229] train: loss: 0.1235765
[Epoch 91] ogbg-moltoxcast: 0.739930 val loss: 0.197725
[Epoch 91] ogbg-moltoxcast: 0.767245 test loss: 0.213555
[Epoch 84; Iter    27/  201] train: loss: 0.1251226
[Epoch 84; Iter    57/  201] train: loss: 0.1423526
[Epoch 84; Iter    87/  201] train: loss: 0.1311042
[Epoch 84; Iter   117/  201] train: loss: 0.1041228
[Epoch 84; Iter   147/  201] train: loss: 0.1382272
[Epoch 84; Iter   177/  201] train: loss: 0.1296516
[Epoch 84] ogbg-moltoxcast: 0.729735 val loss: 0.214336
[Epoch 84] ogbg-moltoxcast: 0.751440 test loss: 0.209265
[Epoch 85; Iter     6/  201] train: loss: 0.1455080
[Epoch 85; Iter    36/  201] train: loss: 0.1204624
[Epoch 85; Iter    66/  201] train: loss: 0.1790275
[Epoch 85; Iter    96/  201] train: loss: 0.1356602
[Epoch 85; Iter   126/  201] train: loss: 0.1792353
[Epoch 85; Iter   156/  201] train: loss: 0.1077932
[Epoch 85; Iter   186/  201] train: loss: 0.1776195
[Epoch 85] ogbg-moltoxcast: 0.732128 val loss: 0.213315
[Epoch 85] ogbg-moltoxcast: 0.756021 test loss: 0.209446
[Epoch 86; Iter    15/  201] train: loss: 0.1628952
[Epoch 86; Iter    45/  201] train: loss: 0.1423241
[Epoch 86; Iter    75/  201] train: loss: 0.1161126
[Epoch 86; Iter   105/  201] train: loss: 0.1072026
[Epoch 86; Iter   135/  201] train: loss: 0.1458535
[Epoch 86; Iter   165/  201] train: loss: 0.1246278
[Epoch 86; Iter   195/  201] train: loss: 0.1234514
[Epoch 86] ogbg-moltoxcast: 0.732743 val loss: 0.215084
[Epoch 86] ogbg-moltoxcast: 0.752873 test loss: 0.208103
[Epoch 87; Iter    24/  201] train: loss: 0.1441156
[Epoch 87; Iter    54/  201] train: loss: 0.1418851
[Epoch 87; Iter    84/  201] train: loss: 0.1323672
[Epoch 87; Iter   114/  201] train: loss: 0.1035404
[Epoch 87; Iter   144/  201] train: loss: 0.1292600
[Epoch 87; Iter   174/  201] train: loss: 0.1201732
[Epoch 87] ogbg-moltoxcast: 0.728033 val loss: 0.219741
[Epoch 87] ogbg-moltoxcast: 0.751038 test loss: 0.213754
[Epoch 88; Iter     3/  201] train: loss: 0.1418955
[Epoch 88; Iter    33/  201] train: loss: 0.0908322
[Epoch 88; Iter    63/  201] train: loss: 0.1261844
[Epoch 88; Iter    93/  201] train: loss: 0.1754011
[Epoch 88; Iter   123/  201] train: loss: 0.1568283
[Epoch 88; Iter   153/  201] train: loss: 0.1701182
[Epoch 88; Iter   183/  201] train: loss: 0.0979089
[Epoch 88] ogbg-moltoxcast: 0.732966 val loss: 0.213285
[Epoch 88] ogbg-moltoxcast: 0.749547 test loss: 0.211599
[Epoch 89; Iter    12/  201] train: loss: 0.0871541
[Epoch 89; Iter    42/  201] train: loss: 0.1565311
[Epoch 89; Iter    72/  201] train: loss: 0.1392944
[Epoch 89; Iter   102/  201] train: loss: 0.1439780
[Epoch 89; Iter   132/  201] train: loss: 0.0926841
[Epoch 89; Iter   162/  201] train: loss: 0.1462949
[Epoch 89; Iter   192/  201] train: loss: 0.1609557
[Epoch 89] ogbg-moltoxcast: 0.728713 val loss: 0.216475
[Epoch 89] ogbg-moltoxcast: 0.751094 test loss: 0.210107
[Epoch 90; Iter    21/  201] train: loss: 0.1389428
[Epoch 90; Iter    51/  201] train: loss: 0.1438800
[Epoch 90; Iter    81/  201] train: loss: 0.1018023
[Epoch 90; Iter   111/  201] train: loss: 0.1569953
[Epoch 90; Iter   141/  201] train: loss: 0.1058338
[Epoch 90; Iter   171/  201] train: loss: 0.1068516
[Epoch 90; Iter   201/  201] train: loss: 0.1372794
[Epoch 90] ogbg-moltoxcast: 0.729822 val loss: 0.215167
[Epoch 90] ogbg-moltoxcast: 0.750804 test loss: 0.211696
[Epoch 91; Iter    30/  201] train: loss: 0.1196816
[Epoch 91; Iter    60/  201] train: loss: 0.1421892
[Epoch 91; Iter    90/  201] train: loss: 0.1111230
[Epoch 91; Iter   120/  201] train: loss: 0.1217678
[Epoch 91; Iter   150/  201] train: loss: 0.1198230
[Epoch 91; Iter   180/  201] train: loss: 0.1342275
[Epoch 91] ogbg-moltoxcast: 0.727590 val loss: 0.215836
[Epoch 91] ogbg-moltoxcast: 0.749530 test loss: 0.210391
[Epoch 92; Iter     9/  201] train: loss: 0.1682252
[Epoch 92; Iter    39/  201] train: loss: 0.1405921
[Epoch 92; Iter    69/  201] train: loss: 0.1507032
[Epoch 92; Iter    99/  201] train: loss: 0.0891807
[Epoch 92; Iter   129/  201] train: loss: 0.1179704
[Epoch 92; Iter   159/  201] train: loss: 0.1332144
[Epoch 92; Iter   189/  201] train: loss: 0.1987987
[Epoch 92] ogbg-moltoxcast: 0.729973 val loss: 0.214373
[Epoch 92] ogbg-moltoxcast: 0.750161 test loss: 0.211450
[Epoch 93; Iter    18/  201] train: loss: 0.1648280
[Epoch 93; Iter    48/  201] train: loss: 0.0941602
[Epoch 93; Iter    78/  201] train: loss: 0.1357162
[Epoch 93; Iter   108/  201] train: loss: 0.1307143
[Epoch 93; Iter   138/  201] train: loss: 0.0999801
[Epoch 93; Iter   168/  201] train: loss: 0.1159131
[Epoch 93; Iter   198/  201] train: loss: 0.1745830
[Epoch 93] ogbg-moltoxcast: 0.730089 val loss: 0.215791
[Epoch 93] ogbg-moltoxcast: 0.752941 test loss: 0.211426
[Epoch 94; Iter    27/  201] train: loss: 0.1087823
[Epoch 94; Iter    57/  201] train: loss: 0.0960707
[Epoch 94; Iter    87/  201] train: loss: 0.1701863
[Epoch 94; Iter   117/  201] train: loss: 0.1041265
[Epoch 94; Iter   147/  201] train: loss: 0.1648389
[Epoch 94; Iter   177/  201] train: loss: 0.1219432
[Epoch 94] ogbg-moltoxcast: 0.731203 val loss: 0.215339
[Epoch 94] ogbg-moltoxcast: 0.748595 test loss: 0.211756
[Epoch 95; Iter     6/  201] train: loss: 0.1261436
[Epoch 95; Iter    36/  201] train: loss: 0.1833585
[Epoch 95; Iter    66/  201] train: loss: 0.1602488
[Epoch 95; Iter    96/  201] train: loss: 0.1161613
[Epoch 95; Iter   126/  201] train: loss: 0.1096551
[Epoch 95; Iter   156/  201] train: loss: 0.1290329
[Epoch 95; Iter   186/  201] train: loss: 0.0870423
[Epoch 95] ogbg-moltoxcast: 0.731738 val loss: 0.217354
[Epoch 95] ogbg-moltoxcast: 0.750351 test loss: 0.213599
[Epoch 96; Iter    15/  201] train: loss: 0.1564861
[Epoch 96; Iter    45/  201] train: loss: 0.1112029
[Epoch 96; Iter    75/  201] train: loss: 0.0914684
[Epoch 96; Iter   105/  201] train: loss: 0.1504964
[Epoch 96; Iter   135/  201] train: loss: 0.1069119
[Epoch 96; Iter   165/  201] train: loss: 0.1184079
[Epoch 96; Iter   195/  201] train: loss: 0.1647886
[Epoch 96] ogbg-moltoxcast: 0.731154 val loss: 0.215354
[Epoch 96] ogbg-moltoxcast: 0.752247 test loss: 0.211283
[Epoch 97; Iter    24/  201] train: loss: 0.1207436
[Epoch 97; Iter    54/  201] train: loss: 0.0917747
[Epoch 97; Iter    84/  201] train: loss: 0.1614918
[Epoch 97; Iter   114/  201] train: loss: 0.1860743
[Epoch 97; Iter   144/  201] train: loss: 0.1325258
[Epoch 97; Iter   174/  201] train: loss: 0.1989779
[Epoch 97] ogbg-moltoxcast: 0.731352 val loss: 0.215993
[Epoch 97] ogbg-moltoxcast: 0.753601 test loss: 0.210881
[Epoch 98; Iter     3/  201] train: loss: 0.1289238
[Epoch 98; Iter    33/  201] train: loss: 0.1859583
[Epoch 98; Iter    63/  201] train: loss: 0.1434091
[Epoch 98; Iter    93/  201] train: loss: 0.1065479
[Epoch 98; Iter   123/  201] train: loss: 0.1316502
[Epoch 98; Iter   153/  201] train: loss: 0.1165539
[Epoch 98; Iter   183/  201] train: loss: 0.1732115
[Epoch 98] ogbg-moltoxcast: 0.730782 val loss: 0.217938
[Epoch 98] ogbg-moltoxcast: 0.754087 test loss: 0.214574
[Epoch 99; Iter    12/  201] train: loss: 0.1832543
[Epoch 99; Iter    42/  201] train: loss: 0.1169705
[Epoch 99; Iter    72/  201] train: loss: 0.1264289
[Epoch 99; Iter   102/  201] train: loss: 0.1376787
[Epoch 99; Iter   132/  201] train: loss: 0.1501205
[Epoch 99; Iter   162/  201] train: loss: 0.1552747
[Epoch 99; Iter   192/  201] train: loss: 0.1102873
[Epoch 99] ogbg-moltoxcast: 0.730217 val loss: 0.216594
[Epoch 99] ogbg-moltoxcast: 0.750394 test loss: 0.214294
[Epoch 100; Iter    21/  201] train: loss: 0.1319579
[Epoch 100; Iter    51/  201] train: loss: 0.1262677
[Epoch 100; Iter    81/  201] train: loss: 0.1929157
[Epoch 100; Iter   111/  201] train: loss: 0.1403713
[Epoch 100; Iter   141/  201] train: loss: 0.0826333
[Epoch 100; Iter   171/  201] train: loss: 0.1880725
[Epoch 100; Iter   201/  201] train: loss: 0.6845205
[Epoch 100] ogbg-moltoxcast: 0.732838 val loss: 0.219215
[Epoch 100] ogbg-moltoxcast: 0.751944 test loss: 0.217855
[Epoch 101; Iter    30/  201] train: loss: 0.1538306
[Epoch 101; Iter    60/  201] train: loss: 0.1378742
[Epoch 101; Iter    90/  201] train: loss: 0.1099461
[Epoch 101; Iter   120/  201] train: loss: 0.0978667
[Epoch 101; Iter   150/  201] train: loss: 0.1035137
[Epoch 101; Iter   180/  201] train: loss: 0.1616656
[Epoch 84; Iter    27/  201] train: loss: 0.1066338
[Epoch 84; Iter    57/  201] train: loss: 0.1663261
[Epoch 84; Iter    87/  201] train: loss: 0.1160453
[Epoch 84; Iter   117/  201] train: loss: 0.1696878
[Epoch 84; Iter   147/  201] train: loss: 0.1794479
[Epoch 84; Iter   177/  201] train: loss: 0.1406790
[Epoch 84] ogbg-moltoxcast: 0.739326 val loss: 0.206393
[Epoch 84] ogbg-moltoxcast: 0.752973 test loss: 0.207948
[Epoch 85; Iter     6/  201] train: loss: 0.1398046
[Epoch 85; Iter    36/  201] train: loss: 0.1544710
[Epoch 85; Iter    66/  201] train: loss: 0.1360525
[Epoch 85; Iter    96/  201] train: loss: 0.1313093
[Epoch 85; Iter   126/  201] train: loss: 0.1224123
[Epoch 85; Iter   156/  201] train: loss: 0.1246637
[Epoch 85; Iter   186/  201] train: loss: 0.1254812
[Epoch 85] ogbg-moltoxcast: 0.735085 val loss: 0.209130
[Epoch 85] ogbg-moltoxcast: 0.751034 test loss: 0.209678
[Epoch 86; Iter    15/  201] train: loss: 0.1225234
[Epoch 86; Iter    45/  201] train: loss: 0.1397458
[Epoch 86; Iter    75/  201] train: loss: 0.1420751
[Epoch 86; Iter   105/  201] train: loss: 0.1823178
[Epoch 86; Iter   135/  201] train: loss: 0.0954541
[Epoch 86; Iter   165/  201] train: loss: 0.1017156
[Epoch 86; Iter   195/  201] train: loss: 0.2645260
[Epoch 86] ogbg-moltoxcast: 0.735633 val loss: 0.210120
[Epoch 86] ogbg-moltoxcast: 0.750947 test loss: 0.211063
[Epoch 87; Iter    24/  201] train: loss: 0.1633304
[Epoch 87; Iter    54/  201] train: loss: 0.1197704
[Epoch 87; Iter    84/  201] train: loss: 0.1787565
[Epoch 87; Iter   114/  201] train: loss: 0.1607189
[Epoch 87; Iter   144/  201] train: loss: 0.1628744
[Epoch 87; Iter   174/  201] train: loss: 0.1524556
[Epoch 87] ogbg-moltoxcast: 0.739914 val loss: 0.206947
[Epoch 87] ogbg-moltoxcast: 0.757381 test loss: 0.206669
[Epoch 88; Iter     3/  201] train: loss: 0.0958836
[Epoch 88; Iter    33/  201] train: loss: 0.1184402
[Epoch 88; Iter    63/  201] train: loss: 0.1888558
[Epoch 88; Iter    93/  201] train: loss: 0.1691837
[Epoch 88; Iter   123/  201] train: loss: 0.1034170
[Epoch 88; Iter   153/  201] train: loss: 0.1002185
[Epoch 88; Iter   183/  201] train: loss: 0.1582353
[Epoch 88] ogbg-moltoxcast: 0.735827 val loss: 0.208379
[Epoch 88] ogbg-moltoxcast: 0.754520 test loss: 0.206047
[Epoch 89; Iter    12/  201] train: loss: 0.1371287
[Epoch 89; Iter    42/  201] train: loss: 0.1313944
[Epoch 89; Iter    72/  201] train: loss: 0.2026527
[Epoch 89; Iter   102/  201] train: loss: 0.1457362
[Epoch 89; Iter   132/  201] train: loss: 0.1155331
[Epoch 89; Iter   162/  201] train: loss: 0.1762360
[Epoch 89; Iter   192/  201] train: loss: 0.1403487
[Epoch 89] ogbg-moltoxcast: 0.731871 val loss: 0.210833
[Epoch 89] ogbg-moltoxcast: 0.752194 test loss: 0.208241
[Epoch 90; Iter    21/  201] train: loss: 0.0869018
[Epoch 90; Iter    51/  201] train: loss: 0.1914522
[Epoch 90; Iter    81/  201] train: loss: 0.1357614
[Epoch 90; Iter   111/  201] train: loss: 0.1260577
[Epoch 90; Iter   141/  201] train: loss: 0.1235251
[Epoch 90; Iter   171/  201] train: loss: 0.1143624
[Epoch 90; Iter   201/  201] train: loss: 0.1440023
[Epoch 90] ogbg-moltoxcast: 0.736232 val loss: 0.208477
[Epoch 90] ogbg-moltoxcast: 0.752565 test loss: 0.206747
[Epoch 91; Iter    30/  201] train: loss: 0.1173999
[Epoch 91; Iter    60/  201] train: loss: 0.1126162
[Epoch 91; Iter    90/  201] train: loss: 0.0962896
[Epoch 91; Iter   120/  201] train: loss: 0.1511676
[Epoch 91; Iter   150/  201] train: loss: 0.1403889
[Epoch 91; Iter   180/  201] train: loss: 0.0943227
[Epoch 91] ogbg-moltoxcast: 0.739787 val loss: 0.210213
[Epoch 91] ogbg-moltoxcast: 0.751386 test loss: 0.214448
[Epoch 92; Iter     9/  201] train: loss: 0.1103659
[Epoch 92; Iter    39/  201] train: loss: 0.1307604
[Epoch 92; Iter    69/  201] train: loss: 0.1382489
[Epoch 92; Iter    99/  201] train: loss: 0.1081516
[Epoch 92; Iter   129/  201] train: loss: 0.1135558
[Epoch 92; Iter   159/  201] train: loss: 0.1087857
[Epoch 92; Iter   189/  201] train: loss: 0.1330224
[Epoch 92] ogbg-moltoxcast: 0.737684 val loss: 0.208589
[Epoch 92] ogbg-moltoxcast: 0.752824 test loss: 0.210264
[Epoch 93; Iter    18/  201] train: loss: 0.1025579
[Epoch 93; Iter    48/  201] train: loss: 0.1605362
[Epoch 93; Iter    78/  201] train: loss: 0.0865992
[Epoch 93; Iter   108/  201] train: loss: 0.1144742
[Epoch 93; Iter   138/  201] train: loss: 0.1517006
[Epoch 93; Iter   168/  201] train: loss: 0.1929374
[Epoch 93; Iter   198/  201] train: loss: 0.1379474
[Epoch 93] ogbg-moltoxcast: 0.737351 val loss: 0.211022
[Epoch 93] ogbg-moltoxcast: 0.752437 test loss: 0.210002
[Epoch 94; Iter    27/  201] train: loss: 0.1146679
[Epoch 94; Iter    57/  201] train: loss: 0.1247374
[Epoch 94; Iter    87/  201] train: loss: 0.2096289
[Epoch 94; Iter   117/  201] train: loss: 0.1259197
[Epoch 94; Iter   147/  201] train: loss: 0.1359877
[Epoch 94; Iter   177/  201] train: loss: 0.1350506
[Epoch 94] ogbg-moltoxcast: 0.735487 val loss: 0.209535
[Epoch 94] ogbg-moltoxcast: 0.754584 test loss: 0.208073
[Epoch 95; Iter     6/  201] train: loss: 0.1373284
[Epoch 95; Iter    36/  201] train: loss: 0.0908634
[Epoch 95; Iter    66/  201] train: loss: 0.1088739
[Epoch 95; Iter    96/  201] train: loss: 0.1191261
[Epoch 95; Iter   126/  201] train: loss: 0.1455549
[Epoch 95; Iter   156/  201] train: loss: 0.1530108
[Epoch 95; Iter   186/  201] train: loss: 0.1687280
[Epoch 95] ogbg-moltoxcast: 0.737122 val loss: 0.208011
[Epoch 95] ogbg-moltoxcast: 0.754544 test loss: 0.208612
[Epoch 96; Iter    15/  201] train: loss: 0.1445387
[Epoch 96; Iter    45/  201] train: loss: 0.1068150
[Epoch 96; Iter    75/  201] train: loss: 0.1219992
[Epoch 96; Iter   105/  201] train: loss: 0.1046272
[Epoch 96; Iter   135/  201] train: loss: 0.1588264
[Epoch 96; Iter   165/  201] train: loss: 0.1353858
[Epoch 96; Iter   195/  201] train: loss: 0.1264414
[Epoch 96] ogbg-moltoxcast: 0.738988 val loss: 0.210115
[Epoch 96] ogbg-moltoxcast: 0.756806 test loss: 0.211754
[Epoch 97; Iter    24/  201] train: loss: 0.0841548
[Epoch 97; Iter    54/  201] train: loss: 0.1092620
[Epoch 97; Iter    84/  201] train: loss: 0.1414750
[Epoch 97; Iter   114/  201] train: loss: 0.1290788
[Epoch 97; Iter   144/  201] train: loss: 0.1352335
[Epoch 97; Iter   174/  201] train: loss: 0.2068782
[Epoch 97] ogbg-moltoxcast: 0.737568 val loss: 0.211222
[Epoch 97] ogbg-moltoxcast: 0.754397 test loss: 0.213655
[Epoch 98; Iter     3/  201] train: loss: 0.1628997
[Epoch 98; Iter    33/  201] train: loss: 0.1762917
[Epoch 98; Iter    63/  201] train: loss: 0.1347542
[Epoch 98; Iter    93/  201] train: loss: 0.1417111
[Epoch 98; Iter   123/  201] train: loss: 0.1258842
[Epoch 98; Iter   153/  201] train: loss: 0.1764361
[Epoch 98; Iter   183/  201] train: loss: 0.1234065
[Epoch 98] ogbg-moltoxcast: 0.736205 val loss: 0.209148
[Epoch 98] ogbg-moltoxcast: 0.755114 test loss: 0.208529
[Epoch 99; Iter    12/  201] train: loss: 0.1340236
[Epoch 99; Iter    42/  201] train: loss: 0.1167280
[Epoch 99; Iter    72/  201] train: loss: 0.1144284
[Epoch 99; Iter   102/  201] train: loss: 0.1429678
[Epoch 99; Iter   132/  201] train: loss: 0.0917840
[Epoch 99; Iter   162/  201] train: loss: 0.1699940
[Epoch 99; Iter   192/  201] train: loss: 0.1557569
[Epoch 99] ogbg-moltoxcast: 0.735938 val loss: 0.210274
[Epoch 99] ogbg-moltoxcast: 0.755512 test loss: 0.209443
[Epoch 100; Iter    21/  201] train: loss: 0.1575703
[Epoch 100; Iter    51/  201] train: loss: 0.1405035
[Epoch 100; Iter    81/  201] train: loss: 0.1239867
[Epoch 100; Iter   111/  201] train: loss: 0.1490549
[Epoch 100; Iter   141/  201] train: loss: 0.1482998
[Epoch 100; Iter   171/  201] train: loss: 0.1760402
[Epoch 100; Iter   201/  201] train: loss: 0.4944055
[Epoch 100] ogbg-moltoxcast: 0.738993 val loss: 0.211475
[Epoch 100] ogbg-moltoxcast: 0.753657 test loss: 0.215465
[Epoch 101; Iter    30/  201] train: loss: 0.1620729
[Epoch 101; Iter    60/  201] train: loss: 0.1583211
[Epoch 101; Iter    90/  201] train: loss: 0.1264407
[Epoch 101; Iter   120/  201] train: loss: 0.1572136
[Epoch 101; Iter   150/  201] train: loss: 0.1399372
[Epoch 101; Iter   180/  201] train: loss: 0.1405621
[Epoch 84; Iter    27/  201] train: loss: 0.1646636
[Epoch 84; Iter    57/  201] train: loss: 0.1288463
[Epoch 84; Iter    87/  201] train: loss: 0.1380065
[Epoch 84; Iter   117/  201] train: loss: 0.1210475
[Epoch 84; Iter   147/  201] train: loss: 0.1385961
[Epoch 84; Iter   177/  201] train: loss: 0.1464351
[Epoch 84] ogbg-moltoxcast: 0.732929 val loss: 0.223873
[Epoch 84] ogbg-moltoxcast: 0.748063 test loss: 0.227670
[Epoch 85; Iter     6/  201] train: loss: 0.0914986
[Epoch 85; Iter    36/  201] train: loss: 0.1040073
[Epoch 85; Iter    66/  201] train: loss: 0.1327123
[Epoch 85; Iter    96/  201] train: loss: 0.1365099
[Epoch 85; Iter   126/  201] train: loss: 0.1365024
[Epoch 85; Iter   156/  201] train: loss: 0.1354113
[Epoch 85; Iter   186/  201] train: loss: 0.1208090
[Epoch 85] ogbg-moltoxcast: 0.728644 val loss: 0.217663
[Epoch 85] ogbg-moltoxcast: 0.745844 test loss: 0.212622
[Epoch 86; Iter    15/  201] train: loss: 0.1523940
[Epoch 86; Iter    45/  201] train: loss: 0.1207575
[Epoch 86; Iter    75/  201] train: loss: 0.1265510
[Epoch 86; Iter   105/  201] train: loss: 0.1266939
[Epoch 86; Iter   135/  201] train: loss: 0.1238493
[Epoch 86; Iter   165/  201] train: loss: 0.1342616
[Epoch 86; Iter   195/  201] train: loss: 0.0887836
[Epoch 86] ogbg-moltoxcast: 0.731717 val loss: 0.216900
[Epoch 86] ogbg-moltoxcast: 0.747664 test loss: 0.217203
[Epoch 87; Iter    24/  201] train: loss: 0.1977179
[Epoch 87; Iter    54/  201] train: loss: 0.1336993
[Epoch 87; Iter    84/  201] train: loss: 0.1337595
[Epoch 87; Iter   114/  201] train: loss: 0.1257943
[Epoch 87; Iter   144/  201] train: loss: 0.1482615
[Epoch 87; Iter   174/  201] train: loss: 0.1721277
[Epoch 87] ogbg-moltoxcast: 0.733122 val loss: 0.223915
[Epoch 87] ogbg-moltoxcast: 0.749064 test loss: 0.224311
[Epoch 88; Iter     3/  201] train: loss: 0.1278642
[Epoch 88; Iter    33/  201] train: loss: 0.1115921
[Epoch 88; Iter    63/  201] train: loss: 0.1150406
[Epoch 88; Iter    93/  201] train: loss: 0.1435321
[Epoch 88; Iter   123/  201] train: loss: 0.1708974
[Epoch 88; Iter   153/  201] train: loss: 0.1083946
[Epoch 88; Iter   183/  201] train: loss: 0.1601844
[Epoch 88] ogbg-moltoxcast: 0.731518 val loss: 0.229368
[Epoch 88] ogbg-moltoxcast: 0.749112 test loss: 0.231221
[Epoch 89; Iter    12/  201] train: loss: 0.1005238
[Epoch 89; Iter    42/  201] train: loss: 0.1580811
[Epoch 89; Iter    72/  201] train: loss: 0.1206253
[Epoch 89; Iter   102/  201] train: loss: 0.1009284
[Epoch 89; Iter   132/  201] train: loss: 0.1163865
[Epoch 89; Iter   162/  201] train: loss: 0.1733914
[Epoch 89; Iter   192/  201] train: loss: 0.1145210
[Epoch 89] ogbg-moltoxcast: 0.730019 val loss: 0.224360
[Epoch 89] ogbg-moltoxcast: 0.743493 test loss: 0.225108
[Epoch 90; Iter    21/  201] train: loss: 0.1783772
[Epoch 90; Iter    51/  201] train: loss: 0.1032888
[Epoch 90; Iter    81/  201] train: loss: 0.1144780
[Epoch 90; Iter   111/  201] train: loss: 0.0808166
[Epoch 90; Iter   141/  201] train: loss: 0.1480075
[Epoch 90; Iter   171/  201] train: loss: 0.0942551
[Epoch 90; Iter   201/  201] train: loss: 0.4147282
[Epoch 90] ogbg-moltoxcast: 0.733515 val loss: 0.219209
[Epoch 90] ogbg-moltoxcast: 0.747586 test loss: 0.217657
[Epoch 91; Iter    30/  201] train: loss: 0.1616147
[Epoch 91; Iter    60/  201] train: loss: 0.0849810
[Epoch 91; Iter    90/  201] train: loss: 0.1452854
[Epoch 91; Iter   120/  201] train: loss: 0.0693896
[Epoch 91; Iter   150/  201] train: loss: 0.1619581
[Epoch 91; Iter   180/  201] train: loss: 0.1727886
[Epoch 91] ogbg-moltoxcast: 0.732203 val loss: 0.217855
[Epoch 91] ogbg-moltoxcast: 0.746442 test loss: 0.216259
[Epoch 92; Iter     9/  201] train: loss: 0.1296230
[Epoch 92; Iter    39/  201] train: loss: 0.1884956
[Epoch 92; Iter    69/  201] train: loss: 0.1637132
[Epoch 92; Iter    99/  201] train: loss: 0.1136226
[Epoch 92; Iter   129/  201] train: loss: 0.1481169
[Epoch 92; Iter   159/  201] train: loss: 0.1607265
[Epoch 92; Iter   189/  201] train: loss: 0.1674273
[Epoch 92] ogbg-moltoxcast: 0.730617 val loss: 0.229348
[Epoch 92] ogbg-moltoxcast: 0.749514 test loss: 0.231504
[Epoch 93; Iter    18/  201] train: loss: 0.1493299
[Epoch 93; Iter    48/  201] train: loss: 0.1336706
[Epoch 93; Iter    78/  201] train: loss: 0.2024768
[Epoch 93; Iter   108/  201] train: loss: 0.1386619
[Epoch 93; Iter   138/  201] train: loss: 0.1434359
[Epoch 93; Iter   168/  201] train: loss: 0.0931416
[Epoch 93; Iter   198/  201] train: loss: 0.1508542
[Epoch 93] ogbg-moltoxcast: 0.731401 val loss: 0.221844
[Epoch 93] ogbg-moltoxcast: 0.747195 test loss: 0.221982
[Epoch 94; Iter    27/  201] train: loss: 0.1679689
[Epoch 94; Iter    57/  201] train: loss: 0.1251659
[Epoch 94; Iter    87/  201] train: loss: 0.1532889
[Epoch 94; Iter   117/  201] train: loss: 0.1370164
[Epoch 94; Iter   147/  201] train: loss: 0.1327337
[Epoch 94; Iter   177/  201] train: loss: 0.1111056
[Epoch 94] ogbg-moltoxcast: 0.727452 val loss: 0.221584
[Epoch 94] ogbg-moltoxcast: 0.745624 test loss: 0.219572
[Epoch 95; Iter     6/  201] train: loss: 0.1508629
[Epoch 95; Iter    36/  201] train: loss: 0.1108192
[Epoch 95; Iter    66/  201] train: loss: 0.1401113
[Epoch 95; Iter    96/  201] train: loss: 0.1656026
[Epoch 95; Iter   126/  201] train: loss: 0.1191020
[Epoch 95; Iter   156/  201] train: loss: 0.1051278
[Epoch 95; Iter   186/  201] train: loss: 0.1010060
[Epoch 95] ogbg-moltoxcast: 0.730472 val loss: 0.217109
[Epoch 95] ogbg-moltoxcast: 0.748749 test loss: 0.213026
[Epoch 96; Iter    15/  201] train: loss: 0.1332626
[Epoch 96; Iter    45/  201] train: loss: 0.1696756
[Epoch 96; Iter    75/  201] train: loss: 0.1892340
[Epoch 96; Iter   105/  201] train: loss: 0.1574395
[Epoch 96; Iter   135/  201] train: loss: 0.1027771
[Epoch 96; Iter   165/  201] train: loss: 0.1674546
[Epoch 96; Iter   195/  201] train: loss: 0.0682194
[Epoch 96] ogbg-moltoxcast: 0.730117 val loss: 0.221345
[Epoch 96] ogbg-moltoxcast: 0.747054 test loss: 0.221506
[Epoch 97; Iter    24/  201] train: loss: 0.1777514
[Epoch 97; Iter    54/  201] train: loss: 0.1196461
[Epoch 97; Iter    84/  201] train: loss: 0.1300011
[Epoch 97; Iter   114/  201] train: loss: 0.1197028
[Epoch 97; Iter   144/  201] train: loss: 0.1395364
[Epoch 97; Iter   174/  201] train: loss: 0.1270260
[Epoch 97] ogbg-moltoxcast: 0.732015 val loss: 0.216328
[Epoch 97] ogbg-moltoxcast: 0.745905 test loss: 0.216915
[Epoch 98; Iter     3/  201] train: loss: 0.1373077
[Epoch 98; Iter    33/  201] train: loss: 0.1499613
[Epoch 98; Iter    63/  201] train: loss: 0.1279581
[Epoch 98; Iter    93/  201] train: loss: 0.1823088
[Epoch 98; Iter   123/  201] train: loss: 0.0881354
[Epoch 98; Iter   153/  201] train: loss: 0.1276899
[Epoch 98; Iter   183/  201] train: loss: 0.1028349
[Epoch 98] ogbg-moltoxcast: 0.730253 val loss: 0.217203
[Epoch 98] ogbg-moltoxcast: 0.746023 test loss: 0.215872
[Epoch 99; Iter    12/  201] train: loss: 0.2060363
[Epoch 99; Iter    42/  201] train: loss: 0.0834459
[Epoch 99; Iter    72/  201] train: loss: 0.1399440
[Epoch 99; Iter   102/  201] train: loss: 0.1853337
[Epoch 99; Iter   132/  201] train: loss: 0.1320045
[Epoch 99; Iter   162/  201] train: loss: 0.1273968
[Epoch 99; Iter   192/  201] train: loss: 0.1075051
[Epoch 99] ogbg-moltoxcast: 0.729611 val loss: 0.234889
[Epoch 99] ogbg-moltoxcast: 0.743977 test loss: 0.238331
[Epoch 100; Iter    21/  201] train: loss: 0.1427272
[Epoch 100; Iter    51/  201] train: loss: 0.1202697
[Epoch 100; Iter    81/  201] train: loss: 0.1324510
[Epoch 100; Iter   111/  201] train: loss: 0.1252505
[Epoch 100; Iter   141/  201] train: loss: 0.1365745
[Epoch 100; Iter   171/  201] train: loss: 0.1236741
[Epoch 100; Iter   201/  201] train: loss: 0.2059138
[Epoch 100] ogbg-moltoxcast: 0.726843 val loss: 0.280543
[Epoch 100] ogbg-moltoxcast: 0.744988 test loss: 0.300933
[Epoch 101; Iter    30/  201] train: loss: 0.1311022
[Epoch 101; Iter    60/  201] train: loss: 0.1084447
[Epoch 101; Iter    90/  201] train: loss: 0.1369806
[Epoch 101; Iter   120/  201] train: loss: 0.2052806
[Epoch 101; Iter   150/  201] train: loss: 0.1009902
[Epoch 101; Iter   180/  201] train: loss: 0.1205145
[Epoch 92; Iter    11/  229] train: loss: 0.1268455
[Epoch 92; Iter    41/  229] train: loss: 0.1136560
[Epoch 92; Iter    71/  229] train: loss: 0.1101220
[Epoch 92; Iter   101/  229] train: loss: 0.1699403
[Epoch 92; Iter   131/  229] train: loss: 0.1065029
[Epoch 92; Iter   161/  229] train: loss: 0.1189507
[Epoch 92; Iter   191/  229] train: loss: 0.1441751
[Epoch 92; Iter   221/  229] train: loss: 0.1734901
[Epoch 92] ogbg-moltoxcast: 0.744593 val loss: 0.204077
[Epoch 92] ogbg-moltoxcast: 0.754487 test loss: 0.216992
[Epoch 93; Iter    22/  229] train: loss: 0.1618265
[Epoch 93; Iter    52/  229] train: loss: 0.0965742
[Epoch 93; Iter    82/  229] train: loss: 0.1061437
[Epoch 93; Iter   112/  229] train: loss: 0.1492218
[Epoch 93; Iter   142/  229] train: loss: 0.1153738
[Epoch 93; Iter   172/  229] train: loss: 0.0844439
[Epoch 93; Iter   202/  229] train: loss: 0.1518369
[Epoch 93] ogbg-moltoxcast: 0.743636 val loss: 0.221539
[Epoch 93] ogbg-moltoxcast: 0.753458 test loss: 0.231038
[Epoch 94; Iter     3/  229] train: loss: 0.1406444
[Epoch 94; Iter    33/  229] train: loss: 0.1412400
[Epoch 94; Iter    63/  229] train: loss: 0.1312916
[Epoch 94; Iter    93/  229] train: loss: 0.1476493
[Epoch 94; Iter   123/  229] train: loss: 0.1117785
[Epoch 94; Iter   153/  229] train: loss: 0.1084263
[Epoch 94; Iter   183/  229] train: loss: 0.1193727
[Epoch 94; Iter   213/  229] train: loss: 0.1248860
[Epoch 94] ogbg-moltoxcast: 0.745693 val loss: 0.198504
[Epoch 94] ogbg-moltoxcast: 0.754456 test loss: 0.215487
[Epoch 95; Iter    14/  229] train: loss: 0.1137622
[Epoch 95; Iter    44/  229] train: loss: 0.1747209
[Epoch 95; Iter    74/  229] train: loss: 0.1469702
[Epoch 95; Iter   104/  229] train: loss: 0.1509643
[Epoch 95; Iter   134/  229] train: loss: 0.1491272
[Epoch 95; Iter   164/  229] train: loss: 0.1244050
[Epoch 95; Iter   194/  229] train: loss: 0.1165782
[Epoch 95; Iter   224/  229] train: loss: 0.1511632
[Epoch 95] ogbg-moltoxcast: 0.743964 val loss: 0.198509
[Epoch 95] ogbg-moltoxcast: 0.755654 test loss: 0.211797
[Epoch 96; Iter    25/  229] train: loss: 0.1083084
[Epoch 96; Iter    55/  229] train: loss: 0.1276615
[Epoch 96; Iter    85/  229] train: loss: 0.1407495
[Epoch 96; Iter   115/  229] train: loss: 0.1327749
[Epoch 96; Iter   145/  229] train: loss: 0.1438010
[Epoch 96; Iter   175/  229] train: loss: 0.1194173
[Epoch 96; Iter   205/  229] train: loss: 0.1433512
[Epoch 96] ogbg-moltoxcast: 0.739974 val loss: 0.199703
[Epoch 96] ogbg-moltoxcast: 0.752416 test loss: 0.215890
[Epoch 97; Iter     6/  229] train: loss: 0.1166172
[Epoch 97; Iter    36/  229] train: loss: 0.1208646
[Epoch 97; Iter    66/  229] train: loss: 0.1664101
[Epoch 97; Iter    96/  229] train: loss: 0.1231436
[Epoch 97; Iter   126/  229] train: loss: 0.1457674
[Epoch 97; Iter   156/  229] train: loss: 0.0752488
[Epoch 97; Iter   186/  229] train: loss: 0.1720754
[Epoch 97; Iter   216/  229] train: loss: 0.1469448
[Epoch 97] ogbg-moltoxcast: 0.743200 val loss: 0.198381
[Epoch 97] ogbg-moltoxcast: 0.753864 test loss: 0.216133
[Epoch 98; Iter    17/  229] train: loss: 0.1595052
[Epoch 98; Iter    47/  229] train: loss: 0.1563756
[Epoch 98; Iter    77/  229] train: loss: 0.1185507
[Epoch 98; Iter   107/  229] train: loss: 0.1532428
[Epoch 98; Iter   137/  229] train: loss: 0.1065958
[Epoch 98; Iter   167/  229] train: loss: 0.1579157
[Epoch 98; Iter   197/  229] train: loss: 0.1345308
[Epoch 98; Iter   227/  229] train: loss: 0.1718145
[Epoch 98] ogbg-moltoxcast: 0.739851 val loss: 0.200995
[Epoch 98] ogbg-moltoxcast: 0.749371 test loss: 0.215294
[Epoch 99; Iter    28/  229] train: loss: 0.1577343
[Epoch 99; Iter    58/  229] train: loss: 0.1358737
[Epoch 99; Iter    88/  229] train: loss: 0.1427113
[Epoch 99; Iter   118/  229] train: loss: 0.1367166
[Epoch 99; Iter   148/  229] train: loss: 0.1444567
[Epoch 99; Iter   178/  229] train: loss: 0.2071131
[Epoch 99; Iter   208/  229] train: loss: 0.1501485
[Epoch 99] ogbg-moltoxcast: 0.743585 val loss: 0.198124
[Epoch 99] ogbg-moltoxcast: 0.755975 test loss: 0.215437
[Epoch 100; Iter     9/  229] train: loss: 0.1651218
[Epoch 100; Iter    39/  229] train: loss: 0.0968899
[Epoch 100; Iter    69/  229] train: loss: 0.1008192
[Epoch 100; Iter    99/  229] train: loss: 0.1051851
[Epoch 100; Iter   129/  229] train: loss: 0.1606961
[Epoch 100; Iter   159/  229] train: loss: 0.1384105
[Epoch 100; Iter   189/  229] train: loss: 0.1220253
[Epoch 100; Iter   219/  229] train: loss: 0.1428522
[Epoch 100] ogbg-moltoxcast: 0.741308 val loss: 0.199694
[Epoch 100] ogbg-moltoxcast: 0.750927 test loss: 0.215814
[Epoch 101; Iter    20/  229] train: loss: 0.1258929
[Epoch 101; Iter    50/  229] train: loss: 0.0939649
[Epoch 101; Iter    80/  229] train: loss: 0.1196857
[Epoch 101; Iter   110/  229] train: loss: 0.1413551
[Epoch 101; Iter   140/  229] train: loss: 0.1599202
[Epoch 101; Iter   170/  229] train: loss: 0.0923798
[Epoch 101; Iter   200/  229] train: loss: 0.1454666
[Epoch 101] ogbg-moltoxcast: 0.746200 val loss: 0.196974
[Epoch 101] ogbg-moltoxcast: 0.752245 test loss: 0.218898
[Epoch 102; Iter     1/  229] train: loss: 0.1498125
[Epoch 102; Iter    31/  229] train: loss: 0.1379889
[Epoch 102; Iter    61/  229] train: loss: 0.1489353
[Epoch 102; Iter    91/  229] train: loss: 0.1700063
[Epoch 102; Iter   121/  229] train: loss: 0.1144668
[Epoch 102; Iter   151/  229] train: loss: 0.1485391
[Epoch 102; Iter   181/  229] train: loss: 0.1517500
[Epoch 102; Iter   211/  229] train: loss: 0.1528639
[Epoch 102] ogbg-moltoxcast: 0.743889 val loss: 0.202837
[Epoch 102] ogbg-moltoxcast: 0.751809 test loss: 0.220801
[Epoch 103; Iter    12/  229] train: loss: 0.1092912
[Epoch 103; Iter    42/  229] train: loss: 0.1463657
[Epoch 103; Iter    72/  229] train: loss: 0.1618722
[Epoch 103; Iter   102/  229] train: loss: 0.0897888
[Epoch 103; Iter   132/  229] train: loss: 0.1115336
[Epoch 103; Iter   162/  229] train: loss: 0.1266797
[Epoch 103; Iter   192/  229] train: loss: 0.1301617
[Epoch 103; Iter   222/  229] train: loss: 0.1215040
[Epoch 103] ogbg-moltoxcast: 0.740507 val loss: 0.236690
[Epoch 103] ogbg-moltoxcast: 0.750706 test loss: 0.242338
[Epoch 104; Iter    23/  229] train: loss: 0.1213656
[Epoch 104; Iter    53/  229] train: loss: 0.1258013
[Epoch 104; Iter    83/  229] train: loss: 0.1365713
[Epoch 104; Iter   113/  229] train: loss: 0.1435041
[Epoch 104; Iter   143/  229] train: loss: 0.1491769
[Epoch 104; Iter   173/  229] train: loss: 0.1232861
[Epoch 104; Iter   203/  229] train: loss: 0.1374747
[Epoch 104] ogbg-moltoxcast: 0.743387 val loss: 0.197672
[Epoch 104] ogbg-moltoxcast: 0.751403 test loss: 0.217076
[Epoch 105; Iter     4/  229] train: loss: 0.1250497
[Epoch 105; Iter    34/  229] train: loss: 0.1168034
[Epoch 105; Iter    64/  229] train: loss: 0.1290220
[Epoch 105; Iter    94/  229] train: loss: 0.1191843
[Epoch 105; Iter   124/  229] train: loss: 0.1162252
[Epoch 105; Iter   154/  229] train: loss: 0.1313542
[Epoch 105; Iter   184/  229] train: loss: 0.1574547
[Epoch 105; Iter   214/  229] train: loss: 0.0897324
[Epoch 105] ogbg-moltoxcast: 0.737502 val loss: 0.203641
[Epoch 105] ogbg-moltoxcast: 0.748689 test loss: 0.223484
[Epoch 106; Iter    15/  229] train: loss: 0.1259452
[Epoch 106; Iter    45/  229] train: loss: 0.2352113
[Epoch 106; Iter    75/  229] train: loss: 0.1263645
[Epoch 106; Iter   105/  229] train: loss: 0.1357366
[Epoch 106; Iter   135/  229] train: loss: 0.1125504
[Epoch 106; Iter   165/  229] train: loss: 0.1456813
[Epoch 106; Iter   195/  229] train: loss: 0.1302124
[Epoch 106; Iter   225/  229] train: loss: 0.1230764
[Epoch 106] ogbg-moltoxcast: 0.742377 val loss: 0.199133
[Epoch 106] ogbg-moltoxcast: 0.749656 test loss: 0.220687
[Epoch 107; Iter    26/  229] train: loss: 0.0968289
[Epoch 107; Iter    56/  229] train: loss: 0.1071258
[Epoch 107; Iter    86/  229] train: loss: 0.1515713
[Epoch 107; Iter   116/  229] train: loss: 0.1016129
[Epoch 107; Iter   146/  229] train: loss: 0.1263975
[Epoch 107; Iter   176/  229] train: loss: 0.1966403
[Epoch 107; Iter   206/  229] train: loss: 0.1077988
[Epoch 107] ogbg-moltoxcast: 0.737528 val loss: 0.202975
[Epoch 94; Iter    84/  172] train: loss: 0.0902612
[Epoch 94; Iter   114/  172] train: loss: 0.1244010
[Epoch 94; Iter   144/  172] train: loss: 0.1553122
[Epoch 94] ogbg-moltoxcast: 0.733494 val loss: 0.216013
[Epoch 94] ogbg-moltoxcast: 0.738727 test loss: 0.212313
[Epoch 95; Iter     2/  172] train: loss: 0.1437896
[Epoch 95; Iter    32/  172] train: loss: 0.0897582
[Epoch 95; Iter    62/  172] train: loss: 0.0983705
[Epoch 95; Iter    92/  172] train: loss: 0.1176273
[Epoch 95; Iter   122/  172] train: loss: 0.1567862
[Epoch 95; Iter   152/  172] train: loss: 0.1715667
[Epoch 95] ogbg-moltoxcast: 0.735785 val loss: 0.212727
[Epoch 95] ogbg-moltoxcast: 0.737868 test loss: 0.211833
[Epoch 96; Iter    10/  172] train: loss: 0.0820661
[Epoch 96; Iter    40/  172] train: loss: 0.1182712
[Epoch 96; Iter    70/  172] train: loss: 0.1516970
[Epoch 96; Iter   100/  172] train: loss: 0.1369242
[Epoch 96; Iter   130/  172] train: loss: 0.1179380
[Epoch 96; Iter   160/  172] train: loss: 0.1480772
[Epoch 96] ogbg-moltoxcast: 0.734158 val loss: 0.214312
[Epoch 96] ogbg-moltoxcast: 0.738660 test loss: 0.212287
[Epoch 97; Iter    18/  172] train: loss: 0.1147337
[Epoch 97; Iter    48/  172] train: loss: 0.1014325
[Epoch 97; Iter    78/  172] train: loss: 0.1881229
[Epoch 97; Iter   108/  172] train: loss: 0.1252068
[Epoch 97; Iter   138/  172] train: loss: 0.1801411
[Epoch 97; Iter   168/  172] train: loss: 0.1152963
[Epoch 97] ogbg-moltoxcast: 0.733270 val loss: 0.214790
[Epoch 97] ogbg-moltoxcast: 0.737435 test loss: 0.212834
[Epoch 98; Iter    26/  172] train: loss: 0.1249750
[Epoch 98; Iter    56/  172] train: loss: 0.1165465
[Epoch 98; Iter    86/  172] train: loss: 0.1603590
[Epoch 98; Iter   116/  172] train: loss: 0.0812456
[Epoch 98; Iter   146/  172] train: loss: 0.1173837
[Epoch 98] ogbg-moltoxcast: 0.734762 val loss: 0.214195
[Epoch 98] ogbg-moltoxcast: 0.736655 test loss: 0.213006
[Epoch 99; Iter     4/  172] train: loss: 0.1231841
[Epoch 99; Iter    34/  172] train: loss: 0.1305609
[Epoch 99; Iter    64/  172] train: loss: 0.1496265
[Epoch 99; Iter    94/  172] train: loss: 0.1078400
[Epoch 99; Iter   124/  172] train: loss: 0.1220475
[Epoch 99; Iter   154/  172] train: loss: 0.1136726
[Epoch 99] ogbg-moltoxcast: 0.735569 val loss: 0.213044
[Epoch 99] ogbg-moltoxcast: 0.739243 test loss: 0.211433
[Epoch 100; Iter    12/  172] train: loss: 0.0862817
[Epoch 100; Iter    42/  172] train: loss: 0.1346302
[Epoch 100; Iter    72/  172] train: loss: 0.1151377
[Epoch 100; Iter   102/  172] train: loss: 0.0961380
[Epoch 100; Iter   132/  172] train: loss: 0.1290834
[Epoch 100; Iter   162/  172] train: loss: 0.1349189
[Epoch 100] ogbg-moltoxcast: 0.732171 val loss: 0.217405
[Epoch 100] ogbg-moltoxcast: 0.735999 test loss: 0.215310
[Epoch 101; Iter    20/  172] train: loss: 0.1635470
[Epoch 101; Iter    50/  172] train: loss: 0.1135244
[Epoch 101; Iter    80/  172] train: loss: 0.1756909
[Epoch 101; Iter   110/  172] train: loss: 0.1161568
[Epoch 101; Iter   140/  172] train: loss: 0.1356380
[Epoch 101; Iter   170/  172] train: loss: 0.1851542
[Epoch 101] ogbg-moltoxcast: 0.732699 val loss: 0.215753
[Epoch 101] ogbg-moltoxcast: 0.736645 test loss: 0.212292
[Epoch 102; Iter    28/  172] train: loss: 0.1370780
[Epoch 102; Iter    58/  172] train: loss: 0.1482455
[Epoch 102; Iter    88/  172] train: loss: 0.1172271
[Epoch 102; Iter   118/  172] train: loss: 0.1505671
[Epoch 102; Iter   148/  172] train: loss: 0.1435455
[Epoch 102] ogbg-moltoxcast: 0.732019 val loss: 0.215328
[Epoch 102] ogbg-moltoxcast: 0.735992 test loss: 0.213979
[Epoch 103; Iter     6/  172] train: loss: 0.1362900
[Epoch 103; Iter    36/  172] train: loss: 0.1341206
[Epoch 103; Iter    66/  172] train: loss: 0.0993738
[Epoch 103; Iter    96/  172] train: loss: 0.1382779
[Epoch 103; Iter   126/  172] train: loss: 0.1313559
[Epoch 103; Iter   156/  172] train: loss: 0.1029842
[Epoch 103] ogbg-moltoxcast: 0.728718 val loss: 0.218246
[Epoch 103] ogbg-moltoxcast: 0.733208 test loss: 0.216647
[Epoch 104; Iter    14/  172] train: loss: 0.1156146
[Epoch 104; Iter    44/  172] train: loss: 0.1107073
[Epoch 104; Iter    74/  172] train: loss: 0.1479928
[Epoch 104; Iter   104/  172] train: loss: 0.1373206
[Epoch 104; Iter   134/  172] train: loss: 0.1745976
[Epoch 104; Iter   164/  172] train: loss: 0.0968345
[Epoch 104] ogbg-moltoxcast: 0.732079 val loss: 0.216507
[Epoch 104] ogbg-moltoxcast: 0.734127 test loss: 0.215181
[Epoch 105; Iter    22/  172] train: loss: 0.1896669
[Epoch 105; Iter    52/  172] train: loss: 0.1300500
[Epoch 105; Iter    82/  172] train: loss: 0.1579036
[Epoch 105; Iter   112/  172] train: loss: 0.1385939
[Epoch 105; Iter   142/  172] train: loss: 0.1575040
[Epoch 105; Iter   172/  172] train: loss: 0.1152022
[Epoch 105] ogbg-moltoxcast: 0.734406 val loss: 0.216704
[Epoch 105] ogbg-moltoxcast: 0.737712 test loss: 0.215572
[Epoch 106; Iter    30/  172] train: loss: 0.1117270
[Epoch 106; Iter    60/  172] train: loss: 0.1514821
[Epoch 106; Iter    90/  172] train: loss: 0.1208164
[Epoch 106; Iter   120/  172] train: loss: 0.1398850
[Epoch 106; Iter   150/  172] train: loss: 0.1019430
[Epoch 106] ogbg-moltoxcast: 0.732607 val loss: 0.218834
[Epoch 106] ogbg-moltoxcast: 0.735851 test loss: 0.216945
[Epoch 107; Iter     8/  172] train: loss: 0.1676301
[Epoch 107; Iter    38/  172] train: loss: 0.1553978
[Epoch 107; Iter    68/  172] train: loss: 0.1120472
[Epoch 107; Iter    98/  172] train: loss: 0.1287586
[Epoch 107; Iter   128/  172] train: loss: 0.1220717
[Epoch 107; Iter   158/  172] train: loss: 0.1058977
[Epoch 107] ogbg-moltoxcast: 0.734373 val loss: 0.218820
[Epoch 107] ogbg-moltoxcast: 0.733524 test loss: 0.217696
[Epoch 108; Iter    16/  172] train: loss: 0.1433633
[Epoch 108; Iter    46/  172] train: loss: 0.1425834
[Epoch 108; Iter    76/  172] train: loss: 0.1167892
[Epoch 108; Iter   106/  172] train: loss: 0.1429043
[Epoch 108; Iter   136/  172] train: loss: 0.1310630
[Epoch 108; Iter   166/  172] train: loss: 0.1723654
[Epoch 108] ogbg-moltoxcast: 0.729528 val loss: 0.217784
[Epoch 108] ogbg-moltoxcast: 0.733896 test loss: 0.216745
[Epoch 109; Iter    24/  172] train: loss: 0.1742970
[Epoch 109; Iter    54/  172] train: loss: 0.1008105
[Epoch 109; Iter    84/  172] train: loss: 0.1054185
[Epoch 109; Iter   114/  172] train: loss: 0.1582263
[Epoch 109; Iter   144/  172] train: loss: 0.1043963
[Epoch 109] ogbg-moltoxcast: 0.727674 val loss: 0.217963
[Epoch 109] ogbg-moltoxcast: 0.733977 test loss: 0.216535
[Epoch 110; Iter     2/  172] train: loss: 0.1258452
[Epoch 110; Iter    32/  172] train: loss: 0.1797480
[Epoch 110; Iter    62/  172] train: loss: 0.1083485
[Epoch 110; Iter    92/  172] train: loss: 0.1614084
[Epoch 110; Iter   122/  172] train: loss: 0.1624307
[Epoch 110; Iter   152/  172] train: loss: 0.1667403
[Epoch 110] ogbg-moltoxcast: 0.732111 val loss: 0.216248
[Epoch 110] ogbg-moltoxcast: 0.736586 test loss: 0.214037
[Epoch 111; Iter    10/  172] train: loss: 0.1296601
[Epoch 111; Iter    40/  172] train: loss: 0.1597798
[Epoch 111; Iter    70/  172] train: loss: 0.1320561
[Epoch 111; Iter   100/  172] train: loss: 0.1093637
[Epoch 111; Iter   130/  172] train: loss: 0.1167962
[Epoch 111; Iter   160/  172] train: loss: 0.1378958
[Epoch 111] ogbg-moltoxcast: 0.730609 val loss: 0.218782
[Epoch 111] ogbg-moltoxcast: 0.733275 test loss: 0.217499
[Epoch 112; Iter    18/  172] train: loss: 0.1508403
[Epoch 112; Iter    48/  172] train: loss: 0.1297239
[Epoch 112; Iter    78/  172] train: loss: 0.1736103
[Epoch 112; Iter   108/  172] train: loss: 0.1112351
[Epoch 112; Iter   138/  172] train: loss: 0.1202331
[Epoch 112; Iter   168/  172] train: loss: 0.1100665
[Epoch 112] ogbg-moltoxcast: 0.730724 val loss: 0.219510
[Epoch 112] ogbg-moltoxcast: 0.733618 test loss: 0.216529
[Epoch 113; Iter    26/  172] train: loss: 0.1144669
[Epoch 113; Iter    56/  172] train: loss: 0.1186226
[Epoch 113; Iter    86/  172] train: loss: 0.1216802
[Epoch 113; Iter   116/  172] train: loss: 0.1336885
[Epoch 113; Iter   146/  172] train: loss: 0.1550777
[Epoch 113] ogbg-moltoxcast: 0.731644 val loss: 0.217808
[Epoch 113] ogbg-moltoxcast: 0.733980 test loss: 0.217616
[Epoch 92; Iter    11/  229] train: loss: 0.1515661
[Epoch 92; Iter    41/  229] train: loss: 0.1539287
[Epoch 92; Iter    71/  229] train: loss: 0.1276458
[Epoch 92; Iter   101/  229] train: loss: 0.1965919
[Epoch 92; Iter   131/  229] train: loss: 0.1440486
[Epoch 92; Iter   161/  229] train: loss: 0.1292208
[Epoch 92; Iter   191/  229] train: loss: 0.1169001
[Epoch 92; Iter   221/  229] train: loss: 0.1355348
[Epoch 92] ogbg-moltoxcast: 0.761837 val loss: 0.197218
[Epoch 92] ogbg-moltoxcast: 0.760619 test loss: 0.207797
[Epoch 93; Iter    22/  229] train: loss: 0.1426938
[Epoch 93; Iter    52/  229] train: loss: 0.1505390
[Epoch 93; Iter    82/  229] train: loss: 0.1467350
[Epoch 93; Iter   112/  229] train: loss: 0.1770639
[Epoch 93; Iter   142/  229] train: loss: 0.1422891
[Epoch 93; Iter   172/  229] train: loss: 0.1613674
[Epoch 93; Iter   202/  229] train: loss: 0.1510271
[Epoch 93] ogbg-moltoxcast: 0.759770 val loss: 0.199859
[Epoch 93] ogbg-moltoxcast: 0.762832 test loss: 0.205736
[Epoch 94; Iter     3/  229] train: loss: 0.1684187
[Epoch 94; Iter    33/  229] train: loss: 0.1256297
[Epoch 94; Iter    63/  229] train: loss: 0.0916546
[Epoch 94; Iter    93/  229] train: loss: 0.1981379
[Epoch 94; Iter   123/  229] train: loss: 0.1360780
[Epoch 94; Iter   153/  229] train: loss: 0.1470462
[Epoch 94; Iter   183/  229] train: loss: 0.1339946
[Epoch 94; Iter   213/  229] train: loss: 0.0679953
[Epoch 94] ogbg-moltoxcast: 0.762837 val loss: 0.196558
[Epoch 94] ogbg-moltoxcast: 0.763649 test loss: 0.206485
[Epoch 95; Iter    14/  229] train: loss: 0.1295036
[Epoch 95; Iter    44/  229] train: loss: 0.1322999
[Epoch 95; Iter    74/  229] train: loss: 0.1353284
[Epoch 95; Iter   104/  229] train: loss: 0.1605425
[Epoch 95; Iter   134/  229] train: loss: 0.1151498
[Epoch 95; Iter   164/  229] train: loss: 0.2258164
[Epoch 95; Iter   194/  229] train: loss: 0.1399317
[Epoch 95; Iter   224/  229] train: loss: 0.2211171
[Epoch 95] ogbg-moltoxcast: 0.762562 val loss: 0.196739
[Epoch 95] ogbg-moltoxcast: 0.764636 test loss: 0.206674
[Epoch 96; Iter    25/  229] train: loss: 0.1328840
[Epoch 96; Iter    55/  229] train: loss: 0.1590653
[Epoch 96; Iter    85/  229] train: loss: 0.1271724
[Epoch 96; Iter   115/  229] train: loss: 0.1439594
[Epoch 96; Iter   145/  229] train: loss: 0.1240690
[Epoch 96; Iter   175/  229] train: loss: 0.1777045
[Epoch 96; Iter   205/  229] train: loss: 0.1830320
[Epoch 96] ogbg-moltoxcast: 0.759923 val loss: 0.198359
[Epoch 96] ogbg-moltoxcast: 0.764182 test loss: 0.207996
[Epoch 97; Iter     6/  229] train: loss: 0.1579376
[Epoch 97; Iter    36/  229] train: loss: 0.1190688
[Epoch 97; Iter    66/  229] train: loss: 0.1141276
[Epoch 97; Iter    96/  229] train: loss: 0.1687320
[Epoch 97; Iter   126/  229] train: loss: 0.1427267
[Epoch 97; Iter   156/  229] train: loss: 0.1345643
[Epoch 97; Iter   186/  229] train: loss: 0.0941129
[Epoch 97; Iter   216/  229] train: loss: 0.1558490
[Epoch 97] ogbg-moltoxcast: 0.762074 val loss: 0.198918
[Epoch 97] ogbg-moltoxcast: 0.764029 test loss: 0.209433
[Epoch 98; Iter    17/  229] train: loss: 0.1675421
[Epoch 98; Iter    47/  229] train: loss: 0.1327798
[Epoch 98; Iter    77/  229] train: loss: 0.1296301
[Epoch 98; Iter   107/  229] train: loss: 0.1579438
[Epoch 98; Iter   137/  229] train: loss: 0.1516629
[Epoch 98; Iter   167/  229] train: loss: 0.1048813
[Epoch 98; Iter   197/  229] train: loss: 0.1338497
[Epoch 98; Iter   227/  229] train: loss: 0.1329525
[Epoch 98] ogbg-moltoxcast: 0.761796 val loss: 0.197868
[Epoch 98] ogbg-moltoxcast: 0.763465 test loss: 0.209369
[Epoch 99; Iter    28/  229] train: loss: 0.1371451
[Epoch 99; Iter    58/  229] train: loss: 0.1299621
[Epoch 99; Iter    88/  229] train: loss: 0.1658682
[Epoch 99; Iter   118/  229] train: loss: 0.1029460
[Epoch 99; Iter   148/  229] train: loss: 0.0731199
[Epoch 99; Iter   178/  229] train: loss: 0.1713869
[Epoch 99; Iter   208/  229] train: loss: 0.1426663
[Epoch 99] ogbg-moltoxcast: 0.763792 val loss: 0.196939
[Epoch 99] ogbg-moltoxcast: 0.762322 test loss: 0.209265
[Epoch 100; Iter     9/  229] train: loss: 0.1275226
[Epoch 100; Iter    39/  229] train: loss: 0.1448706
[Epoch 100; Iter    69/  229] train: loss: 0.1189978
[Epoch 100; Iter    99/  229] train: loss: 0.2085276
[Epoch 100; Iter   129/  229] train: loss: 0.2030992
[Epoch 100; Iter   159/  229] train: loss: 0.1519412
[Epoch 100; Iter   189/  229] train: loss: 0.1044170
[Epoch 100; Iter   219/  229] train: loss: 0.1648496
[Epoch 100] ogbg-moltoxcast: 0.764585 val loss: 0.197704
[Epoch 100] ogbg-moltoxcast: 0.762299 test loss: 0.209374
[Epoch 101; Iter    20/  229] train: loss: 0.1480391
[Epoch 101; Iter    50/  229] train: loss: 0.1435169
[Epoch 101; Iter    80/  229] train: loss: 0.1118050
[Epoch 101; Iter   110/  229] train: loss: 0.1870448
[Epoch 101; Iter   140/  229] train: loss: 0.1396027
[Epoch 101; Iter   170/  229] train: loss: 0.2024024
[Epoch 101; Iter   200/  229] train: loss: 0.1244290
[Epoch 101] ogbg-moltoxcast: 0.762072 val loss: 0.197629
[Epoch 101] ogbg-moltoxcast: 0.763353 test loss: 0.208384
[Epoch 102; Iter     1/  229] train: loss: 0.1389236
[Epoch 102; Iter    31/  229] train: loss: 0.1285439
[Epoch 102; Iter    61/  229] train: loss: 0.1970183
[Epoch 102; Iter    91/  229] train: loss: 0.1684024
[Epoch 102; Iter   121/  229] train: loss: 0.1464411
[Epoch 102; Iter   151/  229] train: loss: 0.1325682
[Epoch 102; Iter   181/  229] train: loss: 0.0869107
[Epoch 102; Iter   211/  229] train: loss: 0.0876971
[Epoch 102] ogbg-moltoxcast: 0.758708 val loss: 0.198623
[Epoch 102] ogbg-moltoxcast: 0.761091 test loss: 0.208271
[Epoch 103; Iter    12/  229] train: loss: 0.1540781
[Epoch 103; Iter    42/  229] train: loss: 0.2058938
[Epoch 103; Iter    72/  229] train: loss: 0.1381323
[Epoch 103; Iter   102/  229] train: loss: 0.1216869
[Epoch 103; Iter   132/  229] train: loss: 0.1732791
[Epoch 103; Iter   162/  229] train: loss: 0.1644156
[Epoch 103; Iter   192/  229] train: loss: 0.0865080
[Epoch 103; Iter   222/  229] train: loss: 0.1379612
[Epoch 103] ogbg-moltoxcast: 0.762688 val loss: 0.197278
[Epoch 103] ogbg-moltoxcast: 0.763952 test loss: 0.210440
[Epoch 104; Iter    23/  229] train: loss: 0.1304019
[Epoch 104; Iter    53/  229] train: loss: 0.1268669
[Epoch 104; Iter    83/  229] train: loss: 0.1567325
[Epoch 104; Iter   113/  229] train: loss: 0.1252845
[Epoch 104; Iter   143/  229] train: loss: 0.1223118
[Epoch 104; Iter   173/  229] train: loss: 0.1375301
[Epoch 104; Iter   203/  229] train: loss: 0.1235522
[Epoch 104] ogbg-moltoxcast: 0.762183 val loss: 0.197982
[Epoch 104] ogbg-moltoxcast: 0.762795 test loss: 0.210240
[Epoch 105; Iter     4/  229] train: loss: 0.1075031
[Epoch 105; Iter    34/  229] train: loss: 0.2125169
[Epoch 105; Iter    64/  229] train: loss: 0.1311698
[Epoch 105; Iter    94/  229] train: loss: 0.1596935
[Epoch 105; Iter   124/  229] train: loss: 0.1555226
[Epoch 105; Iter   154/  229] train: loss: 0.1414725
[Epoch 105; Iter   184/  229] train: loss: 0.1518583
[Epoch 105; Iter   214/  229] train: loss: 0.1173449
[Epoch 105] ogbg-moltoxcast: 0.760988 val loss: 0.200169
[Epoch 105] ogbg-moltoxcast: 0.764332 test loss: 0.211432
[Epoch 106; Iter    15/  229] train: loss: 0.2593298
[Epoch 106; Iter    45/  229] train: loss: 0.1529725
[Epoch 106; Iter    75/  229] train: loss: 0.0869232
[Epoch 106; Iter   105/  229] train: loss: 0.1226843
[Epoch 106; Iter   135/  229] train: loss: 0.1375064
[Epoch 106; Iter   165/  229] train: loss: 0.1647189
[Epoch 106; Iter   195/  229] train: loss: 0.1205580
[Epoch 106; Iter   225/  229] train: loss: 0.1183987
[Epoch 106] ogbg-moltoxcast: 0.760610 val loss: 0.200252
[Epoch 106] ogbg-moltoxcast: 0.763479 test loss: 0.209693
[Epoch 107; Iter    26/  229] train: loss: 0.1063025
[Epoch 107; Iter    56/  229] train: loss: 0.1512491
[Epoch 107; Iter    86/  229] train: loss: 0.1043394
[Epoch 107; Iter   116/  229] train: loss: 0.1316779
[Epoch 107; Iter   146/  229] train: loss: 0.1192205
[Epoch 107; Iter   176/  229] train: loss: 0.1177860
[Epoch 107; Iter   206/  229] train: loss: 0.1014126
[Epoch 107] ogbg-moltoxcast: 0.760794 val loss: 0.199079
[Epoch 94; Iter    84/  172] train: loss: 0.1701388
[Epoch 94; Iter   114/  172] train: loss: 0.1307704
[Epoch 94; Iter   144/  172] train: loss: 0.1592766
[Epoch 94] ogbg-moltoxcast: 0.732350 val loss: 0.214891
[Epoch 94] ogbg-moltoxcast: 0.729439 test loss: 0.215935
[Epoch 95; Iter     2/  172] train: loss: 0.1077867
[Epoch 95; Iter    32/  172] train: loss: 0.1476158
[Epoch 95; Iter    62/  172] train: loss: 0.1133187
[Epoch 95; Iter    92/  172] train: loss: 0.1237837
[Epoch 95; Iter   122/  172] train: loss: 0.1831221
[Epoch 95; Iter   152/  172] train: loss: 0.1289739
[Epoch 95] ogbg-moltoxcast: 0.729059 val loss: 0.214273
[Epoch 95] ogbg-moltoxcast: 0.729386 test loss: 0.215827
[Epoch 96; Iter    10/  172] train: loss: 0.1311754
[Epoch 96; Iter    40/  172] train: loss: 0.1304486
[Epoch 96; Iter    70/  172] train: loss: 0.0952420
[Epoch 96; Iter   100/  172] train: loss: 0.1546934
[Epoch 96; Iter   130/  172] train: loss: 0.0898606
[Epoch 96; Iter   160/  172] train: loss: 0.1657047
[Epoch 96] ogbg-moltoxcast: 0.730983 val loss: 0.214632
[Epoch 96] ogbg-moltoxcast: 0.727064 test loss: 0.217742
[Epoch 97; Iter    18/  172] train: loss: 0.0904143
[Epoch 97; Iter    48/  172] train: loss: 0.1265376
[Epoch 97; Iter    78/  172] train: loss: 0.1865311
[Epoch 97; Iter   108/  172] train: loss: 0.1739558
[Epoch 97; Iter   138/  172] train: loss: 0.1431074
[Epoch 97; Iter   168/  172] train: loss: 0.1463148
[Epoch 97] ogbg-moltoxcast: 0.730764 val loss: 0.215813
[Epoch 97] ogbg-moltoxcast: 0.731280 test loss: 0.217379
[Epoch 98; Iter    26/  172] train: loss: 0.1071180
[Epoch 98; Iter    56/  172] train: loss: 0.1828139
[Epoch 98; Iter    86/  172] train: loss: 0.1148959
[Epoch 98; Iter   116/  172] train: loss: 0.1313964
[Epoch 98; Iter   146/  172] train: loss: 0.1032187
[Epoch 98] ogbg-moltoxcast: 0.729524 val loss: 0.214876
[Epoch 98] ogbg-moltoxcast: 0.727426 test loss: 0.216396
[Epoch 99; Iter     4/  172] train: loss: 0.1494271
[Epoch 99; Iter    34/  172] train: loss: 0.1135282
[Epoch 99; Iter    64/  172] train: loss: 0.1466302
[Epoch 99; Iter    94/  172] train: loss: 0.1497427
[Epoch 99; Iter   124/  172] train: loss: 0.1531814
[Epoch 99; Iter   154/  172] train: loss: 0.1636784
[Epoch 99] ogbg-moltoxcast: 0.733637 val loss: 0.216714
[Epoch 99] ogbg-moltoxcast: 0.729569 test loss: 0.219671
[Epoch 100; Iter    12/  172] train: loss: 0.1334068
[Epoch 100; Iter    42/  172] train: loss: 0.0850249
[Epoch 100; Iter    72/  172] train: loss: 0.1448654
[Epoch 100; Iter   102/  172] train: loss: 0.1192134
[Epoch 100; Iter   132/  172] train: loss: 0.1089291
[Epoch 100; Iter   162/  172] train: loss: 0.1483639
[Epoch 100] ogbg-moltoxcast: 0.730824 val loss: 0.215841
[Epoch 100] ogbg-moltoxcast: 0.729339 test loss: 0.216948
[Epoch 101; Iter    20/  172] train: loss: 0.1241507
[Epoch 101; Iter    50/  172] train: loss: 0.1476339
[Epoch 101; Iter    80/  172] train: loss: 0.1246992
[Epoch 101; Iter   110/  172] train: loss: 0.0792684
[Epoch 101; Iter   140/  172] train: loss: 0.1356371
[Epoch 101; Iter   170/  172] train: loss: 0.1488936
[Epoch 101] ogbg-moltoxcast: 0.730754 val loss: 0.215188
[Epoch 101] ogbg-moltoxcast: 0.728018 test loss: 0.218037
[Epoch 102; Iter    28/  172] train: loss: 0.1177961
[Epoch 102; Iter    58/  172] train: loss: 0.0970227
[Epoch 102; Iter    88/  172] train: loss: 0.1576435
[Epoch 102; Iter   118/  172] train: loss: 0.1588572
[Epoch 102; Iter   148/  172] train: loss: 0.1484492
[Epoch 102] ogbg-moltoxcast: 0.731231 val loss: 0.218261
[Epoch 102] ogbg-moltoxcast: 0.728660 test loss: 0.219517
[Epoch 103; Iter     6/  172] train: loss: 0.1280979
[Epoch 103; Iter    36/  172] train: loss: 0.0919503
[Epoch 103; Iter    66/  172] train: loss: 0.1205438
[Epoch 103; Iter    96/  172] train: loss: 0.1113110
[Epoch 103; Iter   126/  172] train: loss: 0.1820983
[Epoch 103; Iter   156/  172] train: loss: 0.0961435
[Epoch 103] ogbg-moltoxcast: 0.728324 val loss: 0.218285
[Epoch 103] ogbg-moltoxcast: 0.728754 test loss: 0.220117
[Epoch 104; Iter    14/  172] train: loss: 0.1434473
[Epoch 104; Iter    44/  172] train: loss: 0.1187446
[Epoch 104; Iter    74/  172] train: loss: 0.1505098
[Epoch 104; Iter   104/  172] train: loss: 0.0977071
[Epoch 104; Iter   134/  172] train: loss: 0.1745906
[Epoch 104; Iter   164/  172] train: loss: 0.1756758
[Epoch 104] ogbg-moltoxcast: 0.727380 val loss: 0.216217
[Epoch 104] ogbg-moltoxcast: 0.727875 test loss: 0.217697
[Epoch 105; Iter    22/  172] train: loss: 0.1203417
[Epoch 105; Iter    52/  172] train: loss: 0.1445483
[Epoch 105; Iter    82/  172] train: loss: 0.1248401
[Epoch 105; Iter   112/  172] train: loss: 0.1149956
[Epoch 105; Iter   142/  172] train: loss: 0.1331315
[Epoch 105; Iter   172/  172] train: loss: 0.1599152
[Epoch 105] ogbg-moltoxcast: 0.728628 val loss: 0.216275
[Epoch 105] ogbg-moltoxcast: 0.728432 test loss: 0.218386
[Epoch 106; Iter    30/  172] train: loss: 0.1106251
[Epoch 106; Iter    60/  172] train: loss: 0.1413991
[Epoch 106; Iter    90/  172] train: loss: 0.1317193
[Epoch 106; Iter   120/  172] train: loss: 0.1190828
[Epoch 106; Iter   150/  172] train: loss: 0.1387570
[Epoch 106] ogbg-moltoxcast: 0.731622 val loss: 0.214696
[Epoch 106] ogbg-moltoxcast: 0.733375 test loss: 0.216050
[Epoch 107; Iter     8/  172] train: loss: 0.1789397
[Epoch 107; Iter    38/  172] train: loss: 0.1203812
[Epoch 107; Iter    68/  172] train: loss: 0.0792160
[Epoch 107; Iter    98/  172] train: loss: 0.1541691
[Epoch 107; Iter   128/  172] train: loss: 0.1185445
[Epoch 107; Iter   158/  172] train: loss: 0.1614705
[Epoch 107] ogbg-moltoxcast: 0.728843 val loss: 0.216373
[Epoch 107] ogbg-moltoxcast: 0.728009 test loss: 0.220103
[Epoch 108; Iter    16/  172] train: loss: 0.1696629
[Epoch 108; Iter    46/  172] train: loss: 0.1366755
[Epoch 108; Iter    76/  172] train: loss: 0.1243195
[Epoch 108; Iter   106/  172] train: loss: 0.1688161
[Epoch 108; Iter   136/  172] train: loss: 0.1466576
[Epoch 108; Iter   166/  172] train: loss: 0.1422838
[Epoch 108] ogbg-moltoxcast: 0.727828 val loss: 0.216755
[Epoch 108] ogbg-moltoxcast: 0.727391 test loss: 0.220504
[Epoch 109; Iter    24/  172] train: loss: 0.1030513
[Epoch 109; Iter    54/  172] train: loss: 0.1459004
[Epoch 109; Iter    84/  172] train: loss: 0.1245641
[Epoch 109; Iter   114/  172] train: loss: 0.1500770
[Epoch 109; Iter   144/  172] train: loss: 0.1105489
[Epoch 109] ogbg-moltoxcast: 0.730872 val loss: 0.216239
[Epoch 109] ogbg-moltoxcast: 0.728374 test loss: 0.220154
[Epoch 110; Iter     2/  172] train: loss: 0.1994837
[Epoch 110; Iter    32/  172] train: loss: 0.1465651
[Epoch 110; Iter    62/  172] train: loss: 0.1440911
[Epoch 110; Iter    92/  172] train: loss: 0.0870729
[Epoch 110; Iter   122/  172] train: loss: 0.1287615
[Epoch 110; Iter   152/  172] train: loss: 0.1202846
[Epoch 110] ogbg-moltoxcast: 0.727356 val loss: 0.218113
[Epoch 110] ogbg-moltoxcast: 0.725870 test loss: 0.220871
[Epoch 111; Iter    10/  172] train: loss: 0.1221519
[Epoch 111; Iter    40/  172] train: loss: 0.1607420
[Epoch 111; Iter    70/  172] train: loss: 0.1349081
[Epoch 111; Iter   100/  172] train: loss: 0.1185487
[Epoch 111; Iter   130/  172] train: loss: 0.1159321
[Epoch 111; Iter   160/  172] train: loss: 0.1428578
[Epoch 111] ogbg-moltoxcast: 0.731401 val loss: 0.216096
[Epoch 111] ogbg-moltoxcast: 0.728970 test loss: 0.218486
[Epoch 112; Iter    18/  172] train: loss: 0.1261527
[Epoch 112; Iter    48/  172] train: loss: 0.1315098
[Epoch 112; Iter    78/  172] train: loss: 0.2235513
[Epoch 112; Iter   108/  172] train: loss: 0.1240899
[Epoch 112; Iter   138/  172] train: loss: 0.1248784
[Epoch 112; Iter   168/  172] train: loss: 0.0899927
[Epoch 112] ogbg-moltoxcast: 0.731886 val loss: 0.215817
[Epoch 112] ogbg-moltoxcast: 0.730109 test loss: 0.219658
[Epoch 113; Iter    26/  172] train: loss: 0.1271842
[Epoch 113; Iter    56/  172] train: loss: 0.1848907
[Epoch 113; Iter    86/  172] train: loss: 0.1591493
[Epoch 113; Iter   116/  172] train: loss: 0.0982838
[Epoch 113; Iter   146/  172] train: loss: 0.1383942
[Epoch 113] ogbg-moltoxcast: 0.729157 val loss: 0.218577
[Epoch 113] ogbg-moltoxcast: 0.726980 test loss: 0.220158
[Epoch 92; Iter    11/  229] train: loss: 0.1353893
[Epoch 92; Iter    41/  229] train: loss: 0.1292666
[Epoch 92; Iter    71/  229] train: loss: 0.1467344
[Epoch 92; Iter   101/  229] train: loss: 0.1720518
[Epoch 92; Iter   131/  229] train: loss: 0.1123808
[Epoch 92; Iter   161/  229] train: loss: 0.0949047
[Epoch 92; Iter   191/  229] train: loss: 0.1802943
[Epoch 92; Iter   221/  229] train: loss: 0.1019134
[Epoch 92] ogbg-moltoxcast: 0.738660 val loss: 0.198076
[Epoch 92] ogbg-moltoxcast: 0.766100 test loss: 0.214168
[Epoch 93; Iter    22/  229] train: loss: 0.0939512
[Epoch 93; Iter    52/  229] train: loss: 0.0867565
[Epoch 93; Iter    82/  229] train: loss: 0.1320300
[Epoch 93; Iter   112/  229] train: loss: 0.1568852
[Epoch 93; Iter   142/  229] train: loss: 0.0694024
[Epoch 93; Iter   172/  229] train: loss: 0.1444767
[Epoch 93; Iter   202/  229] train: loss: 0.1394675
[Epoch 93] ogbg-moltoxcast: 0.740533 val loss: 0.197503
[Epoch 93] ogbg-moltoxcast: 0.767436 test loss: 0.213154
[Epoch 94; Iter     3/  229] train: loss: 0.1439962
[Epoch 94; Iter    33/  229] train: loss: 0.1352742
[Epoch 94; Iter    63/  229] train: loss: 0.0818177
[Epoch 94; Iter    93/  229] train: loss: 0.1900218
[Epoch 94; Iter   123/  229] train: loss: 0.1259779
[Epoch 94; Iter   153/  229] train: loss: 0.1479443
[Epoch 94; Iter   183/  229] train: loss: 0.1608853
[Epoch 94; Iter   213/  229] train: loss: 0.1546848
[Epoch 94] ogbg-moltoxcast: 0.738416 val loss: 0.199174
[Epoch 94] ogbg-moltoxcast: 0.766406 test loss: 0.215264
[Epoch 95; Iter    14/  229] train: loss: 0.1061396
[Epoch 95; Iter    44/  229] train: loss: 0.1926263
[Epoch 95; Iter    74/  229] train: loss: 0.1069383
[Epoch 95; Iter   104/  229] train: loss: 0.1616901
[Epoch 95; Iter   134/  229] train: loss: 0.1300559
[Epoch 95; Iter   164/  229] train: loss: 0.1500448
[Epoch 95; Iter   194/  229] train: loss: 0.1578013
[Epoch 95; Iter   224/  229] train: loss: 0.0958746
[Epoch 95] ogbg-moltoxcast: 0.739558 val loss: 0.199531
[Epoch 95] ogbg-moltoxcast: 0.770375 test loss: 0.214871
[Epoch 96; Iter    25/  229] train: loss: 0.1349318
[Epoch 96; Iter    55/  229] train: loss: 0.1289717
[Epoch 96; Iter    85/  229] train: loss: 0.1082225
[Epoch 96; Iter   115/  229] train: loss: 0.1131933
[Epoch 96; Iter   145/  229] train: loss: 0.1035209
[Epoch 96; Iter   175/  229] train: loss: 0.1526184
[Epoch 96; Iter   205/  229] train: loss: 0.1227218
[Epoch 96] ogbg-moltoxcast: 0.737897 val loss: 0.197270
[Epoch 96] ogbg-moltoxcast: 0.767220 test loss: 0.213091
[Epoch 97; Iter     6/  229] train: loss: 0.1365906
[Epoch 97; Iter    36/  229] train: loss: 0.1149576
[Epoch 97; Iter    66/  229] train: loss: 0.1080598
[Epoch 97; Iter    96/  229] train: loss: 0.1376059
[Epoch 97; Iter   126/  229] train: loss: 0.1419508
[Epoch 97; Iter   156/  229] train: loss: 0.1625330
[Epoch 97; Iter   186/  229] train: loss: 0.1160734
[Epoch 97; Iter   216/  229] train: loss: 0.0815021
[Epoch 97] ogbg-moltoxcast: 0.737030 val loss: 0.199414
[Epoch 97] ogbg-moltoxcast: 0.761748 test loss: 0.215788
[Epoch 98; Iter    17/  229] train: loss: 0.1597137
[Epoch 98; Iter    47/  229] train: loss: 0.1603014
[Epoch 98; Iter    77/  229] train: loss: 0.1620945
[Epoch 98; Iter   107/  229] train: loss: 0.0907001
[Epoch 98; Iter   137/  229] train: loss: 0.1907653
[Epoch 98; Iter   167/  229] train: loss: 0.1175505
[Epoch 98; Iter   197/  229] train: loss: 0.1822028
[Epoch 98; Iter   227/  229] train: loss: 0.1428168
[Epoch 98] ogbg-moltoxcast: 0.737058 val loss: 0.200285
[Epoch 98] ogbg-moltoxcast: 0.764126 test loss: 0.217160
[Epoch 99; Iter    28/  229] train: loss: 0.2029113
[Epoch 99; Iter    58/  229] train: loss: 0.1225932
[Epoch 99; Iter    88/  229] train: loss: 0.1394107
[Epoch 99; Iter   118/  229] train: loss: 0.1608928
[Epoch 99; Iter   148/  229] train: loss: 0.1233623
[Epoch 99; Iter   178/  229] train: loss: 0.1498323
[Epoch 99; Iter   208/  229] train: loss: 0.1624204
[Epoch 99] ogbg-moltoxcast: 0.737059 val loss: 0.200058
[Epoch 99] ogbg-moltoxcast: 0.762253 test loss: 0.216470
[Epoch 100; Iter     9/  229] train: loss: 0.1294917
[Epoch 100; Iter    39/  229] train: loss: 0.1269520
[Epoch 100; Iter    69/  229] train: loss: 0.1614016
[Epoch 100; Iter    99/  229] train: loss: 0.0907617
[Epoch 100; Iter   129/  229] train: loss: 0.1492490
[Epoch 100; Iter   159/  229] train: loss: 0.1326057
[Epoch 100; Iter   189/  229] train: loss: 0.1998890
[Epoch 100; Iter   219/  229] train: loss: 0.1017747
[Epoch 100] ogbg-moltoxcast: 0.735547 val loss: 0.199809
[Epoch 100] ogbg-moltoxcast: 0.763044 test loss: 0.216863
[Epoch 101; Iter    20/  229] train: loss: 0.1469081
[Epoch 101; Iter    50/  229] train: loss: 0.0820030
[Epoch 101; Iter    80/  229] train: loss: 0.1615593
[Epoch 101; Iter   110/  229] train: loss: 0.1450531
[Epoch 101; Iter   140/  229] train: loss: 0.1495313
[Epoch 101; Iter   170/  229] train: loss: 0.1162818
[Epoch 101; Iter   200/  229] train: loss: 0.1969569
[Epoch 101] ogbg-moltoxcast: 0.741093 val loss: 0.199070
[Epoch 101] ogbg-moltoxcast: 0.768046 test loss: 0.214690
[Epoch 102; Iter     1/  229] train: loss: 0.1045728
[Epoch 102; Iter    31/  229] train: loss: 0.1309244
[Epoch 102; Iter    61/  229] train: loss: 0.1969383
[Epoch 102; Iter    91/  229] train: loss: 0.1313670
[Epoch 102; Iter   121/  229] train: loss: 0.1154143
[Epoch 102; Iter   151/  229] train: loss: 0.0963298
[Epoch 102; Iter   181/  229] train: loss: 0.0701616
[Epoch 102; Iter   211/  229] train: loss: 0.1202200
[Epoch 102] ogbg-moltoxcast: 0.737846 val loss: 0.200801
[Epoch 102] ogbg-moltoxcast: 0.765973 test loss: 0.216592
[Epoch 103; Iter    12/  229] train: loss: 0.1200445
[Epoch 103; Iter    42/  229] train: loss: 0.1492526
[Epoch 103; Iter    72/  229] train: loss: 0.1652033
[Epoch 103; Iter   102/  229] train: loss: 0.1367601
[Epoch 103; Iter   132/  229] train: loss: 0.1451708
[Epoch 103; Iter   162/  229] train: loss: 0.1195486
[Epoch 103; Iter   192/  229] train: loss: 0.1555401
[Epoch 103; Iter   222/  229] train: loss: 0.1158953
[Epoch 103] ogbg-moltoxcast: 0.734367 val loss: 0.201981
[Epoch 103] ogbg-moltoxcast: 0.761123 test loss: 0.218845
[Epoch 104; Iter    23/  229] train: loss: 0.1312629
[Epoch 104; Iter    53/  229] train: loss: 0.1537243
[Epoch 104; Iter    83/  229] train: loss: 0.1406961
[Epoch 104; Iter   113/  229] train: loss: 0.1240166
[Epoch 104; Iter   143/  229] train: loss: 0.1281758
[Epoch 104; Iter   173/  229] train: loss: 0.1394386
[Epoch 104; Iter   203/  229] train: loss: 0.1008135
[Epoch 104] ogbg-moltoxcast: 0.734795 val loss: 0.203085
[Epoch 104] ogbg-moltoxcast: 0.762701 test loss: 0.220235
[Epoch 105; Iter     4/  229] train: loss: 0.1534854
[Epoch 105; Iter    34/  229] train: loss: 0.1579214
[Epoch 105; Iter    64/  229] train: loss: 0.1351595
[Epoch 105; Iter    94/  229] train: loss: 0.1066189
[Epoch 105; Iter   124/  229] train: loss: 0.1430775
[Epoch 105; Iter   154/  229] train: loss: 0.1592210
[Epoch 105; Iter   184/  229] train: loss: 0.1813711
[Epoch 105; Iter   214/  229] train: loss: 0.1697113
[Epoch 105] ogbg-moltoxcast: 0.739073 val loss: 0.201402
[Epoch 105] ogbg-moltoxcast: 0.766937 test loss: 0.216308
[Epoch 106; Iter    15/  229] train: loss: 0.0959099
[Epoch 106; Iter    45/  229] train: loss: 0.1663395
[Epoch 106; Iter    75/  229] train: loss: 0.1794981
[Epoch 106; Iter   105/  229] train: loss: 0.1527093
[Epoch 106; Iter   135/  229] train: loss: 0.1734946
[Epoch 106; Iter   165/  229] train: loss: 0.1508173
[Epoch 106; Iter   195/  229] train: loss: 0.1306574
[Epoch 106; Iter   225/  229] train: loss: 0.1243849
[Epoch 106] ogbg-moltoxcast: 0.734933 val loss: 0.201001
[Epoch 106] ogbg-moltoxcast: 0.764529 test loss: 0.216603
[Epoch 107; Iter    26/  229] train: loss: 0.1490202
[Epoch 107; Iter    56/  229] train: loss: 0.1209334
[Epoch 107; Iter    86/  229] train: loss: 0.1050854
[Epoch 107; Iter   116/  229] train: loss: 0.1298811
[Epoch 107; Iter   146/  229] train: loss: 0.1412223
[Epoch 107; Iter   176/  229] train: loss: 0.0903548
[Epoch 107; Iter   206/  229] train: loss: 0.1569540
[Epoch 107] ogbg-moltoxcast: 0.733000 val loss: 0.203500
[Epoch 94; Iter    84/  172] train: loss: 0.1740130
[Epoch 94; Iter   114/  172] train: loss: 0.1073387
[Epoch 94; Iter   144/  172] train: loss: 0.1335309
[Epoch 94] ogbg-moltoxcast: 0.724155 val loss: 0.222630
[Epoch 94] ogbg-moltoxcast: 0.740157 test loss: 0.218421
[Epoch 95; Iter     2/  172] train: loss: 0.1435110
[Epoch 95; Iter    32/  172] train: loss: 0.1201885
[Epoch 95; Iter    62/  172] train: loss: 0.1614481
[Epoch 95; Iter    92/  172] train: loss: 0.1233443
[Epoch 95; Iter   122/  172] train: loss: 0.1234679
[Epoch 95; Iter   152/  172] train: loss: 0.1559355
[Epoch 95] ogbg-moltoxcast: 0.719218 val loss: 0.224628
[Epoch 95] ogbg-moltoxcast: 0.738014 test loss: 0.218061
[Epoch 96; Iter    10/  172] train: loss: 0.1367096
[Epoch 96; Iter    40/  172] train: loss: 0.1249559
[Epoch 96; Iter    70/  172] train: loss: 0.1206069
[Epoch 96; Iter   100/  172] train: loss: 0.1133541
[Epoch 96; Iter   130/  172] train: loss: 0.1155795
[Epoch 96; Iter   160/  172] train: loss: 0.0924722
[Epoch 96] ogbg-moltoxcast: 0.725140 val loss: 0.222349
[Epoch 96] ogbg-moltoxcast: 0.740733 test loss: 0.219605
[Epoch 97; Iter    18/  172] train: loss: 0.1045220
[Epoch 97; Iter    48/  172] train: loss: 0.1166724
[Epoch 97; Iter    78/  172] train: loss: 0.1353511
[Epoch 97; Iter   108/  172] train: loss: 0.1392914
[Epoch 97; Iter   138/  172] train: loss: 0.1048236
[Epoch 97; Iter   168/  172] train: loss: 0.1349373
[Epoch 97] ogbg-moltoxcast: 0.723824 val loss: 0.223442
[Epoch 97] ogbg-moltoxcast: 0.738336 test loss: 0.219488
[Epoch 98; Iter    26/  172] train: loss: 0.1129475
[Epoch 98; Iter    56/  172] train: loss: 0.1452887
[Epoch 98; Iter    86/  172] train: loss: 0.1017753
[Epoch 98; Iter   116/  172] train: loss: 0.1408316
[Epoch 98; Iter   146/  172] train: loss: 0.1223159
[Epoch 98] ogbg-moltoxcast: 0.723690 val loss: 0.222778
[Epoch 98] ogbg-moltoxcast: 0.740688 test loss: 0.219370
[Epoch 99; Iter     4/  172] train: loss: 0.1332226
[Epoch 99; Iter    34/  172] train: loss: 0.1629448
[Epoch 99; Iter    64/  172] train: loss: 0.1242634
[Epoch 99; Iter    94/  172] train: loss: 0.1150225
[Epoch 99; Iter   124/  172] train: loss: 0.1119616
[Epoch 99; Iter   154/  172] train: loss: 0.1452204
[Epoch 99] ogbg-moltoxcast: 0.725641 val loss: 0.223615
[Epoch 99] ogbg-moltoxcast: 0.740663 test loss: 0.219711
[Epoch 100; Iter    12/  172] train: loss: 0.0856430
[Epoch 100; Iter    42/  172] train: loss: 0.1203418
[Epoch 100; Iter    72/  172] train: loss: 0.1975825
[Epoch 100; Iter   102/  172] train: loss: 0.0937429
[Epoch 100; Iter   132/  172] train: loss: 0.1437011
[Epoch 100; Iter   162/  172] train: loss: 0.1236378
[Epoch 100] ogbg-moltoxcast: 0.726522 val loss: 0.221578
[Epoch 100] ogbg-moltoxcast: 0.739165 test loss: 0.218468
[Epoch 101; Iter    20/  172] train: loss: 0.1325542
[Epoch 101; Iter    50/  172] train: loss: 0.1169907
[Epoch 101; Iter    80/  172] train: loss: 0.1255031
[Epoch 101; Iter   110/  172] train: loss: 0.1229649
[Epoch 101; Iter   140/  172] train: loss: 0.1158853
[Epoch 101; Iter   170/  172] train: loss: 0.1471832
[Epoch 101] ogbg-moltoxcast: 0.727535 val loss: 0.220520
[Epoch 101] ogbg-moltoxcast: 0.739334 test loss: 0.219312
[Epoch 102; Iter    28/  172] train: loss: 0.1882971
[Epoch 102; Iter    58/  172] train: loss: 0.1038996
[Epoch 102; Iter    88/  172] train: loss: 0.1098082
[Epoch 102; Iter   118/  172] train: loss: 0.1518513
[Epoch 102; Iter   148/  172] train: loss: 0.1386615
[Epoch 102] ogbg-moltoxcast: 0.727187 val loss: 0.222067
[Epoch 102] ogbg-moltoxcast: 0.741962 test loss: 0.218725
[Epoch 103; Iter     6/  172] train: loss: 0.1315000
[Epoch 103; Iter    36/  172] train: loss: 0.0936884
[Epoch 103; Iter    66/  172] train: loss: 0.1079142
[Epoch 103; Iter    96/  172] train: loss: 0.1448806
[Epoch 103; Iter   126/  172] train: loss: 0.1098646
[Epoch 103; Iter   156/  172] train: loss: 0.1491428
[Epoch 103] ogbg-moltoxcast: 0.727753 val loss: 0.222446
[Epoch 103] ogbg-moltoxcast: 0.738595 test loss: 0.221186
[Epoch 104; Iter    14/  172] train: loss: 0.2093814
[Epoch 104; Iter    44/  172] train: loss: 0.1375111
[Epoch 104; Iter    74/  172] train: loss: 0.0931897
[Epoch 104; Iter   104/  172] train: loss: 0.1347381
[Epoch 104; Iter   134/  172] train: loss: 0.0962863
[Epoch 104; Iter   164/  172] train: loss: 0.1390209
[Epoch 104] ogbg-moltoxcast: 0.728324 val loss: 0.222433
[Epoch 104] ogbg-moltoxcast: 0.739759 test loss: 0.221003
[Epoch 105; Iter    22/  172] train: loss: 0.0928156
[Epoch 105; Iter    52/  172] train: loss: 0.1791078
[Epoch 105; Iter    82/  172] train: loss: 0.1376277
[Epoch 105; Iter   112/  172] train: loss: 0.1402973
[Epoch 105; Iter   142/  172] train: loss: 0.1411139
[Epoch 105; Iter   172/  172] train: loss: 0.0821430
[Epoch 105] ogbg-moltoxcast: 0.727165 val loss: 0.221903
[Epoch 105] ogbg-moltoxcast: 0.739110 test loss: 0.220182
[Epoch 106; Iter    30/  172] train: loss: 0.1538445
[Epoch 106; Iter    60/  172] train: loss: 0.1310451
[Epoch 106; Iter    90/  172] train: loss: 0.1636451
[Epoch 106; Iter   120/  172] train: loss: 0.1685779
[Epoch 106; Iter   150/  172] train: loss: 0.1465856
[Epoch 106] ogbg-moltoxcast: 0.724606 val loss: 0.225264
[Epoch 106] ogbg-moltoxcast: 0.734683 test loss: 0.224523
[Epoch 107; Iter     8/  172] train: loss: 0.1540339
[Epoch 107; Iter    38/  172] train: loss: 0.1395339
[Epoch 107; Iter    68/  172] train: loss: 0.1124845
[Epoch 107; Iter    98/  172] train: loss: 0.1201340
[Epoch 107; Iter   128/  172] train: loss: 0.1151783
[Epoch 107; Iter   158/  172] train: loss: 0.1329126
[Epoch 107] ogbg-moltoxcast: 0.726613 val loss: 0.222779
[Epoch 107] ogbg-moltoxcast: 0.738910 test loss: 0.221607
[Epoch 108; Iter    16/  172] train: loss: 0.1596164
[Epoch 108; Iter    46/  172] train: loss: 0.1563423
[Epoch 108; Iter    76/  172] train: loss: 0.1885276
[Epoch 108; Iter   106/  172] train: loss: 0.1189047
[Epoch 108; Iter   136/  172] train: loss: 0.1236258
[Epoch 108; Iter   166/  172] train: loss: 0.1751080
[Epoch 108] ogbg-moltoxcast: 0.724794 val loss: 0.225820
[Epoch 108] ogbg-moltoxcast: 0.739896 test loss: 0.223235
[Epoch 109; Iter    24/  172] train: loss: 0.1430004
[Epoch 109; Iter    54/  172] train: loss: 0.1098291
[Epoch 109; Iter    84/  172] train: loss: 0.1041767
[Epoch 109; Iter   114/  172] train: loss: 0.1227206
[Epoch 109; Iter   144/  172] train: loss: 0.1488356
[Epoch 109] ogbg-moltoxcast: 0.727049 val loss: 0.223105
[Epoch 109] ogbg-moltoxcast: 0.739201 test loss: 0.219973
[Epoch 110; Iter     2/  172] train: loss: 0.1206142
[Epoch 110; Iter    32/  172] train: loss: 0.1540640
[Epoch 110; Iter    62/  172] train: loss: 0.0783606
[Epoch 110; Iter    92/  172] train: loss: 0.0898747
[Epoch 110; Iter   122/  172] train: loss: 0.0818801
[Epoch 110; Iter   152/  172] train: loss: 0.1306962
[Epoch 110] ogbg-moltoxcast: 0.727568 val loss: 0.223099
[Epoch 110] ogbg-moltoxcast: 0.738987 test loss: 0.221588
[Epoch 111; Iter    10/  172] train: loss: 0.1389308
[Epoch 111; Iter    40/  172] train: loss: 0.1263760
[Epoch 111; Iter    70/  172] train: loss: 0.1133191
[Epoch 111; Iter   100/  172] train: loss: 0.1122882
[Epoch 111; Iter   130/  172] train: loss: 0.1346713
[Epoch 111; Iter   160/  172] train: loss: 0.0877397
[Epoch 111] ogbg-moltoxcast: 0.727931 val loss: 0.223608
[Epoch 111] ogbg-moltoxcast: 0.740549 test loss: 0.220456
[Epoch 112; Iter    18/  172] train: loss: 0.1398212
[Epoch 112; Iter    48/  172] train: loss: 0.1377732
[Epoch 112; Iter    78/  172] train: loss: 0.1604571
[Epoch 112; Iter   108/  172] train: loss: 0.1382698
[Epoch 112; Iter   138/  172] train: loss: 0.1282577
[Epoch 112; Iter   168/  172] train: loss: 0.1481840
[Epoch 112] ogbg-moltoxcast: 0.722388 val loss: 0.224771
[Epoch 112] ogbg-moltoxcast: 0.737235 test loss: 0.222003
[Epoch 113; Iter    26/  172] train: loss: 0.1222923
[Epoch 113; Iter    56/  172] train: loss: 0.1165740
[Epoch 113; Iter    86/  172] train: loss: 0.1522067
[Epoch 113; Iter   116/  172] train: loss: 0.1323843
[Epoch 113; Iter   146/  172] train: loss: 0.1304850
[Epoch 113] ogbg-moltoxcast: 0.725320 val loss: 0.224543
[Epoch 113] ogbg-moltoxcast: 0.736412 test loss: 0.224270
[Epoch 101] ogbg-moltoxcast: 0.729681 val loss: 0.216810
[Epoch 101] ogbg-moltoxcast: 0.748242 test loss: 0.212749
[Epoch 102; Iter     9/  201] train: loss: 0.1397156
[Epoch 102; Iter    39/  201] train: loss: 0.1606785
[Epoch 102; Iter    69/  201] train: loss: 0.1110403
[Epoch 102; Iter    99/  201] train: loss: 0.1172165
[Epoch 102; Iter   129/  201] train: loss: 0.1961806
[Epoch 102; Iter   159/  201] train: loss: 0.1465038
[Epoch 102; Iter   189/  201] train: loss: 0.1522995
[Epoch 102] ogbg-moltoxcast: 0.731067 val loss: 0.221425
[Epoch 102] ogbg-moltoxcast: 0.748095 test loss: 0.219581
[Epoch 103; Iter    18/  201] train: loss: 0.1451727
[Epoch 103; Iter    48/  201] train: loss: 0.1462858
[Epoch 103; Iter    78/  201] train: loss: 0.1660181
[Epoch 103; Iter   108/  201] train: loss: 0.1793192
[Epoch 103; Iter   138/  201] train: loss: 0.1199632
[Epoch 103; Iter   168/  201] train: loss: 0.1401377
[Epoch 103; Iter   198/  201] train: loss: 0.1687782
[Epoch 103] ogbg-moltoxcast: 0.730689 val loss: 0.215543
[Epoch 103] ogbg-moltoxcast: 0.749632 test loss: 0.213517
[Epoch 104; Iter    27/  201] train: loss: 0.1453332
[Epoch 104; Iter    57/  201] train: loss: 0.1089667
[Epoch 104; Iter    87/  201] train: loss: 0.1045850
[Epoch 104; Iter   117/  201] train: loss: 0.1052620
[Epoch 104; Iter   147/  201] train: loss: 0.1084319
[Epoch 104; Iter   177/  201] train: loss: 0.1195712
[Epoch 104] ogbg-moltoxcast: 0.731081 val loss: 0.219977
[Epoch 104] ogbg-moltoxcast: 0.751280 test loss: 0.216297
[Epoch 105; Iter     6/  201] train: loss: 0.1579811
[Epoch 105; Iter    36/  201] train: loss: 0.1681430
[Epoch 105; Iter    66/  201] train: loss: 0.1323726
[Epoch 105; Iter    96/  201] train: loss: 0.1388248
[Epoch 105; Iter   126/  201] train: loss: 0.1432093
[Epoch 105; Iter   156/  201] train: loss: 0.1947927
[Epoch 105; Iter   186/  201] train: loss: 0.1802837
[Epoch 105] ogbg-moltoxcast: 0.731928 val loss: 0.222531
[Epoch 105] ogbg-moltoxcast: 0.751592 test loss: 0.220163
[Epoch 106; Iter    15/  201] train: loss: 0.1299567
[Epoch 106; Iter    45/  201] train: loss: 0.1325750
[Epoch 106; Iter    75/  201] train: loss: 0.1312447
[Epoch 106; Iter   105/  201] train: loss: 0.1417711
[Epoch 106; Iter   135/  201] train: loss: 0.1062832
[Epoch 106; Iter   165/  201] train: loss: 0.1224408
[Epoch 106; Iter   195/  201] train: loss: 0.1105074
[Epoch 106] ogbg-moltoxcast: 0.729032 val loss: 0.218676
[Epoch 106] ogbg-moltoxcast: 0.748706 test loss: 0.215465
[Epoch 107; Iter    24/  201] train: loss: 0.1093436
[Epoch 107; Iter    54/  201] train: loss: 0.1373353
[Epoch 107; Iter    84/  201] train: loss: 0.0985846
[Epoch 107; Iter   114/  201] train: loss: 0.1339401
[Epoch 107; Iter   144/  201] train: loss: 0.0886642
[Epoch 107; Iter   174/  201] train: loss: 0.1551866
[Epoch 107] ogbg-moltoxcast: 0.730279 val loss: 0.215551
[Epoch 107] ogbg-moltoxcast: 0.748569 test loss: 0.213748
[Epoch 108; Iter     3/  201] train: loss: 0.1339351
[Epoch 108; Iter    33/  201] train: loss: 0.1354793
[Epoch 108; Iter    63/  201] train: loss: 0.1207653
[Epoch 108; Iter    93/  201] train: loss: 0.1828754
[Epoch 108; Iter   123/  201] train: loss: 0.0960389
[Epoch 108; Iter   153/  201] train: loss: 0.1455127
[Epoch 108; Iter   183/  201] train: loss: 0.1267999
[Epoch 108] ogbg-moltoxcast: 0.729460 val loss: 0.221302
[Epoch 108] ogbg-moltoxcast: 0.746404 test loss: 0.219952
[Epoch 109; Iter    12/  201] train: loss: 0.1285758
[Epoch 109; Iter    42/  201] train: loss: 0.0962399
[Epoch 109; Iter    72/  201] train: loss: 0.1146499
[Epoch 109; Iter   102/  201] train: loss: 0.1438412
[Epoch 109; Iter   132/  201] train: loss: 0.1120923
[Epoch 109; Iter   162/  201] train: loss: 0.1154314
[Epoch 109; Iter   192/  201] train: loss: 0.0785371
[Epoch 109] ogbg-moltoxcast: 0.731510 val loss: 0.216680
[Epoch 109] ogbg-moltoxcast: 0.751164 test loss: 0.217045
[Epoch 110; Iter    21/  201] train: loss: 0.1930686
[Epoch 110; Iter    51/  201] train: loss: 0.1217284
[Epoch 110; Iter    81/  201] train: loss: 0.1137840
[Epoch 110; Iter   111/  201] train: loss: 0.1575707
[Epoch 110; Iter   141/  201] train: loss: 0.0986350
[Epoch 110; Iter   171/  201] train: loss: 0.1196539
[Epoch 110; Iter   201/  201] train: loss: 0.3977000
[Epoch 110] ogbg-moltoxcast: 0.727629 val loss: 0.219837
[Epoch 110] ogbg-moltoxcast: 0.748353 test loss: 0.216187
[Epoch 111; Iter    30/  201] train: loss: 0.1310128
[Epoch 111; Iter    60/  201] train: loss: 0.1072733
[Epoch 111; Iter    90/  201] train: loss: 0.1200280
[Epoch 111; Iter   120/  201] train: loss: 0.0968982
[Epoch 111; Iter   150/  201] train: loss: 0.1323123
[Epoch 111; Iter   180/  201] train: loss: 0.1057027
[Epoch 111] ogbg-moltoxcast: 0.731145 val loss: 0.220935
[Epoch 111] ogbg-moltoxcast: 0.754005 test loss: 0.219559
[Epoch 112; Iter     9/  201] train: loss: 0.1472220
[Epoch 112; Iter    39/  201] train: loss: 0.1020419
[Epoch 112; Iter    69/  201] train: loss: 0.1313444
[Epoch 112; Iter    99/  201] train: loss: 0.1350928
[Epoch 112; Iter   129/  201] train: loss: 0.1110887
[Epoch 112; Iter   159/  201] train: loss: 0.1457103
[Epoch 112; Iter   189/  201] train: loss: 0.1131587
[Epoch 112] ogbg-moltoxcast: 0.727945 val loss: 0.218392
[Epoch 112] ogbg-moltoxcast: 0.747098 test loss: 0.215986
[Epoch 113; Iter    18/  201] train: loss: 0.1468900
[Epoch 113; Iter    48/  201] train: loss: 0.1532099
[Epoch 113; Iter    78/  201] train: loss: 0.1436334
[Epoch 113; Iter   108/  201] train: loss: 0.1090694
[Epoch 113; Iter   138/  201] train: loss: 0.1493402
[Epoch 113; Iter   168/  201] train: loss: 0.1436217
[Epoch 113; Iter   198/  201] train: loss: 0.1192464
[Epoch 113] ogbg-moltoxcast: 0.731394 val loss: 0.219660
[Epoch 113] ogbg-moltoxcast: 0.750332 test loss: 0.216822
[Epoch 114; Iter    27/  201] train: loss: 0.1986703
[Epoch 114; Iter    57/  201] train: loss: 0.1771714
[Epoch 114; Iter    87/  201] train: loss: 0.1040386
[Epoch 114; Iter   117/  201] train: loss: 0.0882035
[Epoch 114; Iter   147/  201] train: loss: 0.1247582
[Epoch 114; Iter   177/  201] train: loss: 0.0909230
[Epoch 114] ogbg-moltoxcast: 0.729897 val loss: 0.216536
[Epoch 114] ogbg-moltoxcast: 0.750264 test loss: 0.213562
[Epoch 115; Iter     6/  201] train: loss: 0.1336667
[Epoch 115; Iter    36/  201] train: loss: 0.1290730
[Epoch 115; Iter    66/  201] train: loss: 0.1568584
[Epoch 115; Iter    96/  201] train: loss: 0.1080500
[Epoch 115; Iter   126/  201] train: loss: 0.1032626
[Epoch 115; Iter   156/  201] train: loss: 0.1571103
[Epoch 115; Iter   186/  201] train: loss: 0.0886616
[Epoch 115] ogbg-moltoxcast: 0.727939 val loss: 0.220196
[Epoch 115] ogbg-moltoxcast: 0.747001 test loss: 0.218808
[Epoch 116; Iter    15/  201] train: loss: 0.1490910
[Epoch 116; Iter    45/  201] train: loss: 0.1215469
[Epoch 116; Iter    75/  201] train: loss: 0.1314115
[Epoch 116; Iter   105/  201] train: loss: 0.1565014
[Epoch 116; Iter   135/  201] train: loss: 0.1209648
[Epoch 116; Iter   165/  201] train: loss: 0.0807740
[Epoch 116; Iter   195/  201] train: loss: 0.1796463
[Epoch 116] ogbg-moltoxcast: 0.729104 val loss: 0.219425
[Epoch 116] ogbg-moltoxcast: 0.747762 test loss: 0.218582
[Epoch 117; Iter    24/  201] train: loss: 0.1450190
[Epoch 117; Iter    54/  201] train: loss: 0.1315905
[Epoch 117; Iter    84/  201] train: loss: 0.1484202
[Epoch 117; Iter   114/  201] train: loss: 0.1816925
[Epoch 117; Iter   144/  201] train: loss: 0.1362415
[Epoch 117; Iter   174/  201] train: loss: 0.0961704
[Epoch 117] ogbg-moltoxcast: 0.729437 val loss: 0.220702
[Epoch 117] ogbg-moltoxcast: 0.748697 test loss: 0.218130
[Epoch 118; Iter     3/  201] train: loss: 0.1694002
[Epoch 118; Iter    33/  201] train: loss: 0.1506677
[Epoch 118; Iter    63/  201] train: loss: 0.1193314
[Epoch 118; Iter    93/  201] train: loss: 0.1674097
[Epoch 118; Iter   123/  201] train: loss: 0.1680393
[Epoch 118; Iter   153/  201] train: loss: 0.1080499
[Epoch 118; Iter   183/  201] train: loss: 0.1636241
[Epoch 118] ogbg-moltoxcast: 0.728284 val loss: 0.219253
[Epoch 118] ogbg-moltoxcast: 0.748355 test loss: 0.214773
[Epoch 119; Iter    12/  201] train: loss: 0.1415986
[Epoch 101] ogbg-moltoxcast: 0.739280 val loss: 0.209031
[Epoch 101] ogbg-moltoxcast: 0.757279 test loss: 0.211425
[Epoch 102; Iter     9/  201] train: loss: 0.1156709
[Epoch 102; Iter    39/  201] train: loss: 0.1805793
[Epoch 102; Iter    69/  201] train: loss: 0.1260293
[Epoch 102; Iter    99/  201] train: loss: 0.1145772
[Epoch 102; Iter   129/  201] train: loss: 0.1217718
[Epoch 102; Iter   159/  201] train: loss: 0.1796758
[Epoch 102; Iter   189/  201] train: loss: 0.1190363
[Epoch 102] ogbg-moltoxcast: 0.740547 val loss: 0.212957
[Epoch 102] ogbg-moltoxcast: 0.756653 test loss: 0.213879
[Epoch 103; Iter    18/  201] train: loss: 0.1168326
[Epoch 103; Iter    48/  201] train: loss: 0.1469917
[Epoch 103; Iter    78/  201] train: loss: 0.1593374
[Epoch 103; Iter   108/  201] train: loss: 0.1342117
[Epoch 103; Iter   138/  201] train: loss: 0.1586953
[Epoch 103; Iter   168/  201] train: loss: 0.1141090
[Epoch 103; Iter   198/  201] train: loss: 0.1280373
[Epoch 103] ogbg-moltoxcast: 0.739960 val loss: 0.208385
[Epoch 103] ogbg-moltoxcast: 0.757646 test loss: 0.208979
[Epoch 104; Iter    27/  201] train: loss: 0.1276043
[Epoch 104; Iter    57/  201] train: loss: 0.1172089
[Epoch 104; Iter    87/  201] train: loss: 0.1144432
[Epoch 104; Iter   117/  201] train: loss: 0.0998387
[Epoch 104; Iter   147/  201] train: loss: 0.1275889
[Epoch 104; Iter   177/  201] train: loss: 0.1360529
[Epoch 104] ogbg-moltoxcast: 0.740110 val loss: 0.208700
[Epoch 104] ogbg-moltoxcast: 0.755515 test loss: 0.209729
[Epoch 105; Iter     6/  201] train: loss: 0.1385958
[Epoch 105; Iter    36/  201] train: loss: 0.1571768
[Epoch 105; Iter    66/  201] train: loss: 0.1257398
[Epoch 105; Iter    96/  201] train: loss: 0.0971790
[Epoch 105; Iter   126/  201] train: loss: 0.1279274
[Epoch 105; Iter   156/  201] train: loss: 0.1557506
[Epoch 105; Iter   186/  201] train: loss: 0.1243796
[Epoch 105] ogbg-moltoxcast: 0.736263 val loss: 0.213378
[Epoch 105] ogbg-moltoxcast: 0.751635 test loss: 0.213169
[Epoch 106; Iter    15/  201] train: loss: 0.1236792
[Epoch 106; Iter    45/  201] train: loss: 0.1042476
[Epoch 106; Iter    75/  201] train: loss: 0.1251996
[Epoch 106; Iter   105/  201] train: loss: 0.1688938
[Epoch 106; Iter   135/  201] train: loss: 0.1569697
[Epoch 106; Iter   165/  201] train: loss: 0.1518257
[Epoch 106; Iter   195/  201] train: loss: 0.1436870
[Epoch 106] ogbg-moltoxcast: 0.741307 val loss: 0.210689
[Epoch 106] ogbg-moltoxcast: 0.755720 test loss: 0.211773
[Epoch 107; Iter    24/  201] train: loss: 0.1877527
[Epoch 107; Iter    54/  201] train: loss: 0.1080778
[Epoch 107; Iter    84/  201] train: loss: 0.0945513
[Epoch 107; Iter   114/  201] train: loss: 0.0950487
[Epoch 107; Iter   144/  201] train: loss: 0.1223417
[Epoch 107; Iter   174/  201] train: loss: 0.1058074
[Epoch 107] ogbg-moltoxcast: 0.733154 val loss: 0.214312
[Epoch 107] ogbg-moltoxcast: 0.749847 test loss: 0.213616
[Epoch 108; Iter     3/  201] train: loss: 0.1132146
[Epoch 108; Iter    33/  201] train: loss: 0.1355641
[Epoch 108; Iter    63/  201] train: loss: 0.1195395
[Epoch 108; Iter    93/  201] train: loss: 0.0952206
[Epoch 108; Iter   123/  201] train: loss: 0.1376986
[Epoch 108; Iter   153/  201] train: loss: 0.0843809
[Epoch 108; Iter   183/  201] train: loss: 0.1090302
[Epoch 108] ogbg-moltoxcast: 0.736942 val loss: 0.211442
[Epoch 108] ogbg-moltoxcast: 0.757740 test loss: 0.210209
[Epoch 109; Iter    12/  201] train: loss: 0.0975651
[Epoch 109; Iter    42/  201] train: loss: 0.1823236
[Epoch 109; Iter    72/  201] train: loss: 0.1020707
[Epoch 109; Iter   102/  201] train: loss: 0.1191786
[Epoch 109; Iter   132/  201] train: loss: 0.1632546
[Epoch 109; Iter   162/  201] train: loss: 0.1385891
[Epoch 109; Iter   192/  201] train: loss: 0.1247409
[Epoch 109] ogbg-moltoxcast: 0.737625 val loss: 0.209396
[Epoch 109] ogbg-moltoxcast: 0.753736 test loss: 0.210298
[Epoch 110; Iter    21/  201] train: loss: 0.1553456
[Epoch 110; Iter    51/  201] train: loss: 0.1277786
[Epoch 110; Iter    81/  201] train: loss: 0.1666267
[Epoch 110; Iter   111/  201] train: loss: 0.1313344
[Epoch 110; Iter   141/  201] train: loss: 0.1775380
[Epoch 110; Iter   171/  201] train: loss: 0.1424513
[Epoch 110; Iter   201/  201] train: loss: 0.2004774
[Epoch 110] ogbg-moltoxcast: 0.736018 val loss: 0.212004
[Epoch 110] ogbg-moltoxcast: 0.754150 test loss: 0.212670
[Epoch 111; Iter    30/  201] train: loss: 0.1038919
[Epoch 111; Iter    60/  201] train: loss: 0.1621686
[Epoch 111; Iter    90/  201] train: loss: 0.1000548
[Epoch 111; Iter   120/  201] train: loss: 0.1734970
[Epoch 111; Iter   150/  201] train: loss: 0.1395639
[Epoch 111; Iter   180/  201] train: loss: 0.1066216
[Epoch 111] ogbg-moltoxcast: 0.737398 val loss: 0.208860
[Epoch 111] ogbg-moltoxcast: 0.757196 test loss: 0.207879
[Epoch 112; Iter     9/  201] train: loss: 0.1431353
[Epoch 112; Iter    39/  201] train: loss: 0.1094253
[Epoch 112; Iter    69/  201] train: loss: 0.1045719
[Epoch 112; Iter    99/  201] train: loss: 0.1156170
[Epoch 112; Iter   129/  201] train: loss: 0.0890684
[Epoch 112; Iter   159/  201] train: loss: 0.1613754
[Epoch 112; Iter   189/  201] train: loss: 0.1111259
[Epoch 112] ogbg-moltoxcast: 0.737701 val loss: 0.208727
[Epoch 112] ogbg-moltoxcast: 0.753582 test loss: 0.208460
[Epoch 113; Iter    18/  201] train: loss: 0.1191362
[Epoch 113; Iter    48/  201] train: loss: 0.1138087
[Epoch 113; Iter    78/  201] train: loss: 0.1157197
[Epoch 113; Iter   108/  201] train: loss: 0.1643502
[Epoch 113; Iter   138/  201] train: loss: 0.1850437
[Epoch 113; Iter   168/  201] train: loss: 0.1107145
[Epoch 113; Iter   198/  201] train: loss: 0.1410621
[Epoch 113] ogbg-moltoxcast: 0.739306 val loss: 0.209098
[Epoch 113] ogbg-moltoxcast: 0.755516 test loss: 0.210789
[Epoch 114; Iter    27/  201] train: loss: 0.1270076
[Epoch 114; Iter    57/  201] train: loss: 0.1269613
[Epoch 114; Iter    87/  201] train: loss: 0.1319448
[Epoch 114; Iter   117/  201] train: loss: 0.1358597
[Epoch 114; Iter   147/  201] train: loss: 0.1376625
[Epoch 114; Iter   177/  201] train: loss: 0.1152982
[Epoch 114] ogbg-moltoxcast: 0.738791 val loss: 0.208383
[Epoch 114] ogbg-moltoxcast: 0.758449 test loss: 0.209113
[Epoch 115; Iter     6/  201] train: loss: 0.1554769
[Epoch 115; Iter    36/  201] train: loss: 0.1063040
[Epoch 115; Iter    66/  201] train: loss: 0.2298499
[Epoch 115; Iter    96/  201] train: loss: 0.1128145
[Epoch 115; Iter   126/  201] train: loss: 0.1256729
[Epoch 115; Iter   156/  201] train: loss: 0.1006423
[Epoch 115; Iter   186/  201] train: loss: 0.1560239
[Epoch 115] ogbg-moltoxcast: 0.736969 val loss: 0.210125
[Epoch 115] ogbg-moltoxcast: 0.755107 test loss: 0.210780
[Epoch 116; Iter    15/  201] train: loss: 0.1591618
[Epoch 116; Iter    45/  201] train: loss: 0.0908587
[Epoch 116; Iter    75/  201] train: loss: 0.1552192
[Epoch 116; Iter   105/  201] train: loss: 0.1719593
[Epoch 116; Iter   135/  201] train: loss: 0.1602461
[Epoch 116; Iter   165/  201] train: loss: 0.1377885
[Epoch 116; Iter   195/  201] train: loss: 0.1932130
[Epoch 116] ogbg-moltoxcast: 0.737726 val loss: 0.209871
[Epoch 116] ogbg-moltoxcast: 0.758295 test loss: 0.209653
[Epoch 117; Iter    24/  201] train: loss: 0.1597778
[Epoch 117; Iter    54/  201] train: loss: 0.1589049
[Epoch 117; Iter    84/  201] train: loss: 0.1642505
[Epoch 117; Iter   114/  201] train: loss: 0.1406185
[Epoch 117; Iter   144/  201] train: loss: 0.1340696
[Epoch 117; Iter   174/  201] train: loss: 0.1030831
[Epoch 117] ogbg-moltoxcast: 0.739226 val loss: 0.209765
[Epoch 117] ogbg-moltoxcast: 0.757284 test loss: 0.211138
[Epoch 118; Iter     3/  201] train: loss: 0.1738559
[Epoch 118; Iter    33/  201] train: loss: 0.0858395
[Epoch 118; Iter    63/  201] train: loss: 0.1297791
[Epoch 118; Iter    93/  201] train: loss: 0.1290842
[Epoch 118; Iter   123/  201] train: loss: 0.1424305
[Epoch 118; Iter   153/  201] train: loss: 0.2026733
[Epoch 118; Iter   183/  201] train: loss: 0.2060870
[Epoch 118] ogbg-moltoxcast: 0.736588 val loss: 0.212469
[Epoch 118] ogbg-moltoxcast: 0.757444 test loss: 0.212052
[Epoch 119; Iter    12/  201] train: loss: 0.1663046
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 114; Iter     4/  172] train: loss: 0.1276463
[Epoch 114; Iter    34/  172] train: loss: 0.1114499
[Epoch 114; Iter    64/  172] train: loss: 0.1308141
[Epoch 114; Iter    94/  172] train: loss: 0.1189821
[Epoch 114; Iter   124/  172] train: loss: 0.1257880
[Epoch 114; Iter   154/  172] train: loss: 0.1289928
[Epoch 114] ogbg-moltoxcast: 0.728696 val loss: 0.218854
[Epoch 114] ogbg-moltoxcast: 0.725810 test loss: 0.221881
[Epoch 115; Iter    12/  172] train: loss: 0.1468973
[Epoch 115; Iter    42/  172] train: loss: 0.0867057
[Epoch 115; Iter    72/  172] train: loss: 0.1154720
[Epoch 115; Iter   102/  172] train: loss: 0.1421095
[Epoch 115; Iter   132/  172] train: loss: 0.1069483
[Epoch 115; Iter   162/  172] train: loss: 0.1326391
[Epoch 115] ogbg-moltoxcast: 0.725998 val loss: 0.219544
[Epoch 115] ogbg-moltoxcast: 0.725443 test loss: 0.222860
[Epoch 116; Iter    20/  172] train: loss: 0.1654093
[Epoch 116; Iter    50/  172] train: loss: 0.1025929
[Epoch 116; Iter    80/  172] train: loss: 0.0889816
[Epoch 116; Iter   110/  172] train: loss: 0.1505956
[Epoch 116; Iter   140/  172] train: loss: 0.1510453
[Epoch 116; Iter   170/  172] train: loss: 0.0982424
[Epoch 116] ogbg-moltoxcast: 0.727628 val loss: 0.216795
[Epoch 116] ogbg-moltoxcast: 0.727147 test loss: 0.219625
[Epoch 117; Iter    28/  172] train: loss: 0.1189183
[Epoch 117; Iter    58/  172] train: loss: 0.1437399
[Epoch 117; Iter    88/  172] train: loss: 0.1153059
[Epoch 117; Iter   118/  172] train: loss: 0.1411321
[Epoch 117; Iter   148/  172] train: loss: 0.1414185
[Epoch 117] ogbg-moltoxcast: 0.730906 val loss: 0.219806
[Epoch 117] ogbg-moltoxcast: 0.728725 test loss: 0.223387
[Epoch 118; Iter     6/  172] train: loss: 0.1341918
[Epoch 118; Iter    36/  172] train: loss: 0.1395710
[Epoch 118; Iter    66/  172] train: loss: 0.1219503
[Epoch 118; Iter    96/  172] train: loss: 0.1170274
[Epoch 118; Iter   126/  172] train: loss: 0.1522807
[Epoch 118; Iter   156/  172] train: loss: 0.1163607
[Epoch 118] ogbg-moltoxcast: 0.727483 val loss: 0.218990
[Epoch 118] ogbg-moltoxcast: 0.726713 test loss: 0.222554
[Epoch 119; Iter    14/  172] train: loss: 0.1432970
[Epoch 119; Iter    44/  172] train: loss: 0.1518935
[Epoch 119; Iter    74/  172] train: loss: 0.1545369
[Epoch 119; Iter   104/  172] train: loss: 0.1778539
[Epoch 119; Iter   134/  172] train: loss: 0.1312481
[Epoch 119; Iter   164/  172] train: loss: 0.1268053
[Epoch 119] ogbg-moltoxcast: 0.729338 val loss: 0.219272
[Epoch 119] ogbg-moltoxcast: 0.725863 test loss: 0.222880
[Epoch 120; Iter    22/  172] train: loss: 0.1285072
[Epoch 120; Iter    52/  172] train: loss: 0.0970589
[Epoch 120; Iter    82/  172] train: loss: 0.0726082
[Epoch 120; Iter   112/  172] train: loss: 0.1039850
[Epoch 120; Iter   142/  172] train: loss: 0.1070859
[Epoch 120; Iter   172/  172] train: loss: 0.0739378
[Epoch 120] ogbg-moltoxcast: 0.726898 val loss: 0.219126
[Epoch 120] ogbg-moltoxcast: 0.725282 test loss: 0.222300
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 51.
Statistics on  val_best_checkpoint
mean_pred: -3.2017955780029297
std_pred: 2.933439016342163
mean_targets: nan
std_targets: nan
prcauc: 0.40970020292864967
rocauc: 0.7369454873986621
ogbg-moltoxcast: 0.7369454873986621
OGBNanLabelBCEWithLogitsLoss: 0.20560924522578716
Statistics on  test
mean_pred: -3.1625475883483887
std_pred: 2.4813320636749268
mean_targets: nan
std_targets: nan
prcauc: 0.4024153705223887
rocauc: 0.7358588184343068
ogbg-moltoxcast: 0.7358588184343068
OGBNanLabelBCEWithLogitsLoss: 0.20543990656733513
Statistics on  train
mean_pred: -3.186553478240967
std_pred: 2.5213263034820557
mean_targets: nan
std_targets: nan
prcauc: 0.5703485257963423
rocauc: 0.8771325901496472
ogbg-moltoxcast: 0.8771325901496472
OGBNanLabelBCEWithLogitsLoss: 0.14971283710626668
[Epoch 114; Iter     4/  172] train: loss: 0.1062833
[Epoch 114; Iter    34/  172] train: loss: 0.1426846
[Epoch 114; Iter    64/  172] train: loss: 0.1654955
[Epoch 114; Iter    94/  172] train: loss: 0.1299688
[Epoch 114; Iter   124/  172] train: loss: 0.1213003
[Epoch 114; Iter   154/  172] train: loss: 0.1328274
[Epoch 114] ogbg-moltoxcast: 0.725970 val loss: 0.226547
[Epoch 114] ogbg-moltoxcast: 0.736759 test loss: 0.226862
[Epoch 115; Iter    12/  172] train: loss: 0.0920468
[Epoch 115; Iter    42/  172] train: loss: 0.1170918
[Epoch 115; Iter    72/  172] train: loss: 0.1414450
[Epoch 115; Iter   102/  172] train: loss: 0.1393859
[Epoch 115; Iter   132/  172] train: loss: 0.1598658
[Epoch 115; Iter   162/  172] train: loss: 0.1285755
[Epoch 115] ogbg-moltoxcast: 0.727022 val loss: 0.221742
[Epoch 115] ogbg-moltoxcast: 0.737818 test loss: 0.221998
[Epoch 116; Iter    20/  172] train: loss: 0.1271503
[Epoch 116; Iter    50/  172] train: loss: 0.1409101
[Epoch 116; Iter    80/  172] train: loss: 0.1335616
[Epoch 116; Iter   110/  172] train: loss: 0.1486616
[Epoch 116; Iter   140/  172] train: loss: 0.1369574
[Epoch 116; Iter   170/  172] train: loss: 0.1141842
[Epoch 116] ogbg-moltoxcast: 0.727737 val loss: 0.221671
[Epoch 116] ogbg-moltoxcast: 0.736866 test loss: 0.221755
[Epoch 117; Iter    28/  172] train: loss: 0.0898045
[Epoch 117; Iter    58/  172] train: loss: 0.1071973
[Epoch 117; Iter    88/  172] train: loss: 0.1023660
[Epoch 117; Iter   118/  172] train: loss: 0.1371955
[Epoch 117; Iter   148/  172] train: loss: 0.1039066
[Epoch 117] ogbg-moltoxcast: 0.725323 val loss: 0.224585
[Epoch 117] ogbg-moltoxcast: 0.737943 test loss: 0.223520
[Epoch 118; Iter     6/  172] train: loss: 0.1595881
[Epoch 118; Iter    36/  172] train: loss: 0.1424472
[Epoch 118; Iter    66/  172] train: loss: 0.1546185
[Epoch 118; Iter    96/  172] train: loss: 0.1322035
[Epoch 118; Iter   126/  172] train: loss: 0.1298137
[Epoch 118; Iter   156/  172] train: loss: 0.1165975
[Epoch 118] ogbg-moltoxcast: 0.726084 val loss: 0.223141
[Epoch 118] ogbg-moltoxcast: 0.737958 test loss: 0.221877
[Epoch 119; Iter    14/  172] train: loss: 0.0985904
[Epoch 119; Iter    44/  172] train: loss: 0.0829560
[Epoch 119; Iter    74/  172] train: loss: 0.1169698
[Epoch 119; Iter   104/  172] train: loss: 0.0778467
[Epoch 119; Iter   134/  172] train: loss: 0.1405414
[Epoch 119; Iter   164/  172] train: loss: 0.1103937
[Epoch 119] ogbg-moltoxcast: 0.725161 val loss: 0.224571
[Epoch 119] ogbg-moltoxcast: 0.738217 test loss: 0.222666
[Epoch 120; Iter    22/  172] train: loss: 0.1491870
[Epoch 120; Iter    52/  172] train: loss: 0.1319409
[Epoch 120; Iter    82/  172] train: loss: 0.0861351
[Epoch 120; Iter   112/  172] train: loss: 0.1720349
[Epoch 120; Iter   142/  172] train: loss: 0.0913566
[Epoch 120; Iter   172/  172] train: loss: 0.0992751
[Epoch 120] ogbg-moltoxcast: 0.724012 val loss: 0.224102
[Epoch 120] ogbg-moltoxcast: 0.738936 test loss: 0.221340
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 55.
Statistics on  val_best_checkpoint
mean_pred: -3.3292839527130127
std_pred: 2.7041170597076416
mean_targets: nan
std_targets: nan
prcauc: 0.4198584942013056
rocauc: 0.7367866729949322
ogbg-moltoxcast: 0.7367866729949322
OGBNanLabelBCEWithLogitsLoss: 0.20618034828582715
Statistics on  test
mean_pred: -3.284837484359741
std_pred: 2.6936662197113037
mean_targets: nan
std_targets: nan
prcauc: 0.42022381624290456
rocauc: 0.7451388907204075
ogbg-moltoxcast: 0.7451388907204075
OGBNanLabelBCEWithLogitsLoss: 0.20532856791697698
Statistics on  train
mean_pred: -3.3175201416015625
std_pred: 2.7318103313446045
mean_targets: nan
std_targets: nan
prcauc: 0.6017883018607877
rocauc: 0.892960546831117
ogbg-moltoxcast: 0.892960546831117
OGBNanLabelBCEWithLogitsLoss: 0.14112645357327405
[Epoch 101] ogbg-moltoxcast: 0.727866 val loss: 0.225963
[Epoch 101] ogbg-moltoxcast: 0.745837 test loss: 0.224052
[Epoch 102; Iter     9/  201] train: loss: 0.1528755
[Epoch 102; Iter    39/  201] train: loss: 0.1331566
[Epoch 102; Iter    69/  201] train: loss: 0.1258348
[Epoch 102; Iter    99/  201] train: loss: 0.1170684
[Epoch 102; Iter   129/  201] train: loss: 0.1589470
[Epoch 102; Iter   159/  201] train: loss: 0.1627194
[Epoch 102; Iter   189/  201] train: loss: 0.1576746
[Epoch 102] ogbg-moltoxcast: 0.727080 val loss: 0.219597
[Epoch 102] ogbg-moltoxcast: 0.741639 test loss: 0.220835
[Epoch 103; Iter    18/  201] train: loss: 0.1392872
[Epoch 103; Iter    48/  201] train: loss: 0.1584892
[Epoch 103; Iter    78/  201] train: loss: 0.1563784
[Epoch 103; Iter   108/  201] train: loss: 0.1152880
[Epoch 103; Iter   138/  201] train: loss: 0.1736054
[Epoch 103; Iter   168/  201] train: loss: 0.1563271
[Epoch 103; Iter   198/  201] train: loss: 0.1217983
[Epoch 103] ogbg-moltoxcast: 0.726720 val loss: 0.225687
[Epoch 103] ogbg-moltoxcast: 0.746020 test loss: 0.225729
[Epoch 104; Iter    27/  201] train: loss: 0.1262752
[Epoch 104; Iter    57/  201] train: loss: 0.1199745
[Epoch 104; Iter    87/  201] train: loss: 0.1488595
[Epoch 104; Iter   117/  201] train: loss: 0.1453227
[Epoch 104; Iter   147/  201] train: loss: 0.1597706
[Epoch 104; Iter   177/  201] train: loss: 0.1036461
[Epoch 104] ogbg-moltoxcast: 0.729056 val loss: 0.220564
[Epoch 104] ogbg-moltoxcast: 0.743776 test loss: 0.219002
[Epoch 105; Iter     6/  201] train: loss: 0.1520275
[Epoch 105; Iter    36/  201] train: loss: 0.1313796
[Epoch 105; Iter    66/  201] train: loss: 0.1251172
[Epoch 105; Iter    96/  201] train: loss: 0.1662064
[Epoch 105; Iter   126/  201] train: loss: 0.1148441
[Epoch 105; Iter   156/  201] train: loss: 0.1157420
[Epoch 105; Iter   186/  201] train: loss: 0.1288069
[Epoch 105] ogbg-moltoxcast: 0.730466 val loss: 0.229875
[Epoch 105] ogbg-moltoxcast: 0.748558 test loss: 0.230441
[Epoch 106; Iter    15/  201] train: loss: 0.1141840
[Epoch 106; Iter    45/  201] train: loss: 0.1162263
[Epoch 106; Iter    75/  201] train: loss: 0.1109559
[Epoch 106; Iter   105/  201] train: loss: 0.1159718
[Epoch 106; Iter   135/  201] train: loss: 0.1036264
[Epoch 106; Iter   165/  201] train: loss: 0.1538301
[Epoch 106; Iter   195/  201] train: loss: 0.1734667
[Epoch 106] ogbg-moltoxcast: 0.728216 val loss: 0.219770
[Epoch 106] ogbg-moltoxcast: 0.747244 test loss: 0.217569
[Epoch 107; Iter    24/  201] train: loss: 0.1211960
[Epoch 107; Iter    54/  201] train: loss: 0.1224404
[Epoch 107; Iter    84/  201] train: loss: 0.1341739
[Epoch 107; Iter   114/  201] train: loss: 0.1096198
[Epoch 107; Iter   144/  201] train: loss: 0.1191378
[Epoch 107; Iter   174/  201] train: loss: 0.1486188
[Epoch 107] ogbg-moltoxcast: 0.728821 val loss: 0.226569
[Epoch 107] ogbg-moltoxcast: 0.747678 test loss: 0.227324
[Epoch 108; Iter     3/  201] train: loss: 0.1291782
[Epoch 108; Iter    33/  201] train: loss: 0.1009470
[Epoch 108; Iter    63/  201] train: loss: 0.1424323
[Epoch 108; Iter    93/  201] train: loss: 0.0973857
[Epoch 108; Iter   123/  201] train: loss: 0.1562513
[Epoch 108; Iter   153/  201] train: loss: 0.1632684
[Epoch 108; Iter   183/  201] train: loss: 0.0916070
[Epoch 108] ogbg-moltoxcast: 0.733163 val loss: 0.237193
[Epoch 108] ogbg-moltoxcast: 0.748455 test loss: 0.245530
[Epoch 109; Iter    12/  201] train: loss: 0.1888487
[Epoch 109; Iter    42/  201] train: loss: 0.1429338
[Epoch 109; Iter    72/  201] train: loss: 0.1742280
[Epoch 109; Iter   102/  201] train: loss: 0.1101952
[Epoch 109; Iter   132/  201] train: loss: 0.2107258
[Epoch 109; Iter   162/  201] train: loss: 0.1607341
[Epoch 109; Iter   192/  201] train: loss: 0.1213761
[Epoch 109] ogbg-moltoxcast: 0.729923 val loss: 0.227986
[Epoch 109] ogbg-moltoxcast: 0.745820 test loss: 0.231549
[Epoch 110; Iter    21/  201] train: loss: 0.1121956
[Epoch 110; Iter    51/  201] train: loss: 0.1621171
[Epoch 110; Iter    81/  201] train: loss: 0.1939649
[Epoch 110; Iter   111/  201] train: loss: 0.1190212
[Epoch 110; Iter   141/  201] train: loss: 0.1156141
[Epoch 110; Iter   171/  201] train: loss: 0.0787466
[Epoch 110; Iter   201/  201] train: loss: 0.2136864
[Epoch 110] ogbg-moltoxcast: 0.731085 val loss: 0.220989
[Epoch 110] ogbg-moltoxcast: 0.744021 test loss: 0.222761
[Epoch 111; Iter    30/  201] train: loss: 0.1258512
[Epoch 111; Iter    60/  201] train: loss: 0.1248836
[Epoch 111; Iter    90/  201] train: loss: 0.0878332
[Epoch 111; Iter   120/  201] train: loss: 0.1740750
[Epoch 111; Iter   150/  201] train: loss: 0.1527292
[Epoch 111; Iter   180/  201] train: loss: 0.1629303
[Epoch 111] ogbg-moltoxcast: 0.730026 val loss: 0.230868
[Epoch 111] ogbg-moltoxcast: 0.745135 test loss: 0.233919
[Epoch 112; Iter     9/  201] train: loss: 0.1087330
[Epoch 112; Iter    39/  201] train: loss: 0.1418008
[Epoch 112; Iter    69/  201] train: loss: 0.1397881
[Epoch 112; Iter    99/  201] train: loss: 0.1052744
[Epoch 112; Iter   129/  201] train: loss: 0.1570619
[Epoch 112; Iter   159/  201] train: loss: 0.0950023
[Epoch 112; Iter   189/  201] train: loss: 0.0708361
[Epoch 112] ogbg-moltoxcast: 0.728476 val loss: 0.217788
[Epoch 112] ogbg-moltoxcast: 0.744911 test loss: 0.217688
[Epoch 113; Iter    18/  201] train: loss: 0.1192449
[Epoch 113; Iter    48/  201] train: loss: 0.1159605
[Epoch 113; Iter    78/  201] train: loss: 0.0927462
[Epoch 113; Iter   108/  201] train: loss: 0.1669075
[Epoch 113; Iter   138/  201] train: loss: 0.1104364
[Epoch 113; Iter   168/  201] train: loss: 0.1363333
[Epoch 113; Iter   198/  201] train: loss: 0.1115986
[Epoch 113] ogbg-moltoxcast: 0.728332 val loss: 0.253243
[Epoch 113] ogbg-moltoxcast: 0.745890 test loss: 0.262896
[Epoch 114; Iter    27/  201] train: loss: 0.1510564
[Epoch 114; Iter    57/  201] train: loss: 0.1866387
[Epoch 114; Iter    87/  201] train: loss: 0.1354339
[Epoch 114; Iter   117/  201] train: loss: 0.1222361
[Epoch 114; Iter   147/  201] train: loss: 0.0907995
[Epoch 114; Iter   177/  201] train: loss: 0.1215957
[Epoch 114] ogbg-moltoxcast: 0.726681 val loss: 0.220808
[Epoch 114] ogbg-moltoxcast: 0.742828 test loss: 0.220201
[Epoch 115; Iter     6/  201] train: loss: 0.1148380
[Epoch 115; Iter    36/  201] train: loss: 0.1515650
[Epoch 115; Iter    66/  201] train: loss: 0.1724981
[Epoch 115; Iter    96/  201] train: loss: 0.1473881
[Epoch 115; Iter   126/  201] train: loss: 0.1526980
[Epoch 115; Iter   156/  201] train: loss: 0.1118009
[Epoch 115; Iter   186/  201] train: loss: 0.1672859
[Epoch 115] ogbg-moltoxcast: 0.727673 val loss: 0.264451
[Epoch 115] ogbg-moltoxcast: 0.745337 test loss: 0.282251
[Epoch 116; Iter    15/  201] train: loss: 0.1434972
[Epoch 116; Iter    45/  201] train: loss: 0.1518650
[Epoch 116; Iter    75/  201] train: loss: 0.1667715
[Epoch 116; Iter   105/  201] train: loss: 0.1096938
[Epoch 116; Iter   135/  201] train: loss: 0.1427374
[Epoch 116; Iter   165/  201] train: loss: 0.1255900
[Epoch 116; Iter   195/  201] train: loss: 0.1053231
[Epoch 116] ogbg-moltoxcast: 0.731364 val loss: 0.262323
[Epoch 116] ogbg-moltoxcast: 0.745472 test loss: 0.281227
[Epoch 117; Iter    24/  201] train: loss: 0.1076077
[Epoch 117; Iter    54/  201] train: loss: 0.0723628
[Epoch 117; Iter    84/  201] train: loss: 0.1393048
[Epoch 117; Iter   114/  201] train: loss: 0.1112037
[Epoch 117; Iter   144/  201] train: loss: 0.1292625
[Epoch 117; Iter   174/  201] train: loss: 0.1271316
[Epoch 117] ogbg-moltoxcast: 0.728147 val loss: 0.275153
[Epoch 117] ogbg-moltoxcast: 0.743977 test loss: 0.299244
[Epoch 118; Iter     3/  201] train: loss: 0.1222536
[Epoch 118; Iter    33/  201] train: loss: 0.1352891
[Epoch 118; Iter    63/  201] train: loss: 0.1813679
[Epoch 118; Iter    93/  201] train: loss: 0.1715571
[Epoch 118; Iter   123/  201] train: loss: 0.1137971
[Epoch 118; Iter   153/  201] train: loss: 0.1581097
[Epoch 118; Iter   183/  201] train: loss: 0.1396414
[Epoch 118] ogbg-moltoxcast: 0.730996 val loss: 0.261466
[Epoch 118] ogbg-moltoxcast: 0.748863 test loss: 0.288530
[Epoch 119; Iter    12/  201] train: loss: 0.1592853
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 114; Iter     4/  172] train: loss: 0.0923740
[Epoch 114; Iter    34/  172] train: loss: 0.1457456
[Epoch 114; Iter    64/  172] train: loss: 0.1398453
[Epoch 114; Iter    94/  172] train: loss: 0.0869742
[Epoch 114; Iter   124/  172] train: loss: 0.1246092
[Epoch 114; Iter   154/  172] train: loss: 0.1436712
[Epoch 114] ogbg-moltoxcast: 0.731040 val loss: 0.217999
[Epoch 114] ogbg-moltoxcast: 0.733665 test loss: 0.216866
[Epoch 115; Iter    12/  172] train: loss: 0.1204778
[Epoch 115; Iter    42/  172] train: loss: 0.0960643
[Epoch 115; Iter    72/  172] train: loss: 0.1336413
[Epoch 115; Iter   102/  172] train: loss: 0.1451742
[Epoch 115; Iter   132/  172] train: loss: 0.1334458
[Epoch 115; Iter   162/  172] train: loss: 0.1905001
[Epoch 115] ogbg-moltoxcast: 0.730528 val loss: 0.218667
[Epoch 115] ogbg-moltoxcast: 0.733005 test loss: 0.218027
[Epoch 116; Iter    20/  172] train: loss: 0.1358664
[Epoch 116; Iter    50/  172] train: loss: 0.1512959
[Epoch 116; Iter    80/  172] train: loss: 0.1210722
[Epoch 116; Iter   110/  172] train: loss: 0.1360669
[Epoch 116; Iter   140/  172] train: loss: 0.0915526
[Epoch 116; Iter   170/  172] train: loss: 0.1402284
[Epoch 116] ogbg-moltoxcast: 0.730427 val loss: 0.219606
[Epoch 116] ogbg-moltoxcast: 0.733149 test loss: 0.219306
[Epoch 117; Iter    28/  172] train: loss: 0.1451638
[Epoch 117; Iter    58/  172] train: loss: 0.1497929
[Epoch 117; Iter    88/  172] train: loss: 0.1051524
[Epoch 117; Iter   118/  172] train: loss: 0.1441884
[Epoch 117; Iter   148/  172] train: loss: 0.1313584
[Epoch 117] ogbg-moltoxcast: 0.731538 val loss: 0.217451
[Epoch 117] ogbg-moltoxcast: 0.733481 test loss: 0.217335
[Epoch 118; Iter     6/  172] train: loss: 0.1002414
[Epoch 118; Iter    36/  172] train: loss: 0.0876006
[Epoch 118; Iter    66/  172] train: loss: 0.1523204
[Epoch 118; Iter    96/  172] train: loss: 0.1208918
[Epoch 118; Iter   126/  172] train: loss: 0.1232060
[Epoch 118; Iter   156/  172] train: loss: 0.1178351
[Epoch 118] ogbg-moltoxcast: 0.733059 val loss: 0.218720
[Epoch 118] ogbg-moltoxcast: 0.733945 test loss: 0.218563
[Epoch 119; Iter    14/  172] train: loss: 0.1272471
[Epoch 119; Iter    44/  172] train: loss: 0.1573216
[Epoch 119; Iter    74/  172] train: loss: 0.1660152
[Epoch 119; Iter   104/  172] train: loss: 0.1334851
[Epoch 119; Iter   134/  172] train: loss: 0.1653877
[Epoch 119; Iter   164/  172] train: loss: 0.0859432
[Epoch 119] ogbg-moltoxcast: 0.731837 val loss: 0.217252
[Epoch 119] ogbg-moltoxcast: 0.733005 test loss: 0.217801
[Epoch 120; Iter    22/  172] train: loss: 0.0909379
[Epoch 120; Iter    52/  172] train: loss: 0.0945646
[Epoch 120; Iter    82/  172] train: loss: 0.1731719
[Epoch 120; Iter   112/  172] train: loss: 0.1427044
[Epoch 120; Iter   142/  172] train: loss: 0.0871223
[Epoch 120; Iter   172/  172] train: loss: 0.1501888
[Epoch 120] ogbg-moltoxcast: 0.730599 val loss: 0.218117
[Epoch 120] ogbg-moltoxcast: 0.730972 test loss: 0.217270
[Epoch 121; Iter    30/  172] train: loss: 0.1123641
[Epoch 121; Iter    60/  172] train: loss: 0.1223653
[Epoch 121; Iter    90/  172] train: loss: 0.1444273
[Epoch 121; Iter   120/  172] train: loss: 0.1485859
[Epoch 121; Iter   150/  172] train: loss: 0.1368265
[Epoch 121] ogbg-moltoxcast: 0.732183 val loss: 0.218251
[Epoch 121] ogbg-moltoxcast: 0.731307 test loss: 0.219141
[Epoch 122; Iter     8/  172] train: loss: 0.1144217
[Epoch 122; Iter    38/  172] train: loss: 0.1164920
[Epoch 122; Iter    68/  172] train: loss: 0.0942358
[Epoch 122; Iter    98/  172] train: loss: 0.0918637
[Epoch 122; Iter   128/  172] train: loss: 0.0936998
[Epoch 122; Iter   158/  172] train: loss: 0.1200379
[Epoch 122] ogbg-moltoxcast: 0.730491 val loss: 0.220503
[Epoch 122] ogbg-moltoxcast: 0.730120 test loss: 0.220942
[Epoch 123; Iter    16/  172] train: loss: 0.1287328
[Epoch 123; Iter    46/  172] train: loss: 0.0890120
[Epoch 123; Iter    76/  172] train: loss: 0.1377354
[Epoch 123; Iter   106/  172] train: loss: 0.1234634
[Epoch 123; Iter   136/  172] train: loss: 0.1075322
[Epoch 123; Iter   166/  172] train: loss: 0.1276557
[Epoch 123] ogbg-moltoxcast: 0.727866 val loss: 0.221306
[Epoch 123] ogbg-moltoxcast: 0.728129 test loss: 0.222103
[Epoch 124; Iter    24/  172] train: loss: 0.0945313
[Epoch 124; Iter    54/  172] train: loss: 0.1037418
[Epoch 124; Iter    84/  172] train: loss: 0.1171947
[Epoch 124; Iter   114/  172] train: loss: 0.1328612
[Epoch 124; Iter   144/  172] train: loss: 0.1193355
[Epoch 124] ogbg-moltoxcast: 0.732219 val loss: 0.219240
[Epoch 124] ogbg-moltoxcast: 0.732586 test loss: 0.218983
[Epoch 125; Iter     2/  172] train: loss: 0.1179469
[Epoch 125; Iter    32/  172] train: loss: 0.1595425
[Epoch 125; Iter    62/  172] train: loss: 0.1674352
[Epoch 125; Iter    92/  172] train: loss: 0.1502193
[Epoch 125; Iter   122/  172] train: loss: 0.1436003
[Epoch 125; Iter   152/  172] train: loss: 0.1234656
[Epoch 125] ogbg-moltoxcast: 0.731392 val loss: 0.217973
[Epoch 125] ogbg-moltoxcast: 0.732993 test loss: 0.218029
[Epoch 126; Iter    10/  172] train: loss: 0.0952157
[Epoch 126; Iter    40/  172] train: loss: 0.1532773
[Epoch 126; Iter    70/  172] train: loss: 0.1339438
[Epoch 126; Iter   100/  172] train: loss: 0.1205029
[Epoch 126; Iter   130/  172] train: loss: 0.1282954
[Epoch 126; Iter   160/  172] train: loss: 0.1291706
[Epoch 126] ogbg-moltoxcast: 0.730441 val loss: 0.219264
[Epoch 126] ogbg-moltoxcast: 0.729949 test loss: 0.220279
[Epoch 127; Iter    18/  172] train: loss: 0.0839713
[Epoch 127; Iter    48/  172] train: loss: 0.1349904
[Epoch 127; Iter    78/  172] train: loss: 0.0887605
[Epoch 127; Iter   108/  172] train: loss: 0.1241597
[Epoch 127; Iter   138/  172] train: loss: 0.1176810
[Epoch 127; Iter   168/  172] train: loss: 0.1412769
[Epoch 127] ogbg-moltoxcast: 0.727988 val loss: 0.219344
[Epoch 127] ogbg-moltoxcast: 0.729206 test loss: 0.220149
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 127 epochs. Best model checkpoint was in epoch 67.
Statistics on  val_best_checkpoint
mean_pred: -3.1971817016601562
std_pred: 2.5755839347839355
mean_targets: nan
std_targets: nan
prcauc: 0.41419150815189315
rocauc: 0.7381985975879906
ogbg-moltoxcast: 0.7381985975879906
OGBNanLabelBCEWithLogitsLoss: 0.20520095668476204
Statistics on  test
mean_pred: -3.217466115951538
std_pred: 2.587921142578125
mean_targets: nan
std_targets: nan
prcauc: 0.41785252018766855
rocauc: 0.7460981077864458
ogbg-moltoxcast: 0.7460981077864458
OGBNanLabelBCEWithLogitsLoss: 0.2021356019480475
Statistics on  train
mean_pred: -3.241403579711914
std_pred: 2.624589204788208
mean_targets: nan
std_targets: nan
prcauc: 0.6204792735287451
rocauc: 0.9006319164453519
ogbg-moltoxcast: 0.9006319164453519
OGBNanLabelBCEWithLogitsLoss: 0.13590738077669642
All runs completed.
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 119; Iter    42/  201] train: loss: 0.0966913
[Epoch 119; Iter    72/  201] train: loss: 0.1020361
[Epoch 119; Iter   102/  201] train: loss: 0.1237254
[Epoch 119; Iter   132/  201] train: loss: 0.1613470
[Epoch 119; Iter   162/  201] train: loss: 0.1182118
[Epoch 119; Iter   192/  201] train: loss: 0.1697574
[Epoch 119] ogbg-moltoxcast: 0.730190 val loss: 0.235895
[Epoch 119] ogbg-moltoxcast: 0.746351 test loss: 0.244444
[Epoch 120; Iter    21/  201] train: loss: 0.1568428
[Epoch 120; Iter    51/  201] train: loss: 0.1458178
[Epoch 120; Iter    81/  201] train: loss: 0.0848400
[Epoch 120; Iter   111/  201] train: loss: 0.0639244
[Epoch 120; Iter   141/  201] train: loss: 0.1363313
[Epoch 120; Iter   171/  201] train: loss: 0.1133068
[Epoch 120; Iter   201/  201] train: loss: 0.0645359
[Epoch 120] ogbg-moltoxcast: 0.728102 val loss: 0.221238
[Epoch 120] ogbg-moltoxcast: 0.744353 test loss: 0.220810
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 54.
Statistics on  val_best_checkpoint
mean_pred: -3.1105470657348633
std_pred: 2.5987303256988525
mean_targets: nan
std_targets: nan
prcauc: 0.41033857081405833
rocauc: 0.7374403531816675
ogbg-moltoxcast: 0.7374403531816675
OGBNanLabelBCEWithLogitsLoss: 0.20998190551303153
Statistics on  test
mean_pred: -3.1341209411621094
std_pred: 2.750746011734009
mean_targets: nan
std_targets: nan
prcauc: 0.4241994868281355
rocauc: 0.7508092161266681
ogbg-moltoxcast: 0.7508092161266681
OGBNanLabelBCEWithLogitsLoss: 0.216696789964687
Statistics on  train
mean_pred: -3.1700916290283203
std_pred: 2.7813570499420166
mean_targets: nan
std_targets: nan
prcauc: 0.5665239155112456
rocauc: 0.8757466340529453
ogbg-moltoxcast: 0.8757466340529453
OGBNanLabelBCEWithLogitsLoss: 0.15374323236408519
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 107] ogbg-moltoxcast: 0.748108 test loss: 0.220483
[Epoch 108; Iter     7/  229] train: loss: 0.1447274
[Epoch 108; Iter    37/  229] train: loss: 0.1152272
[Epoch 108; Iter    67/  229] train: loss: 0.1811453
[Epoch 108; Iter    97/  229] train: loss: 0.1257903
[Epoch 108; Iter   127/  229] train: loss: 0.1322760
[Epoch 108; Iter   157/  229] train: loss: 0.1268562
[Epoch 108; Iter   187/  229] train: loss: 0.1218119
[Epoch 108; Iter   217/  229] train: loss: 0.1808046
[Epoch 108] ogbg-moltoxcast: 0.740709 val loss: 0.202286
[Epoch 108] ogbg-moltoxcast: 0.749901 test loss: 0.219564
[Epoch 109; Iter    18/  229] train: loss: 0.1259352
[Epoch 109; Iter    48/  229] train: loss: 0.1416835
[Epoch 109; Iter    78/  229] train: loss: 0.1603102
[Epoch 109; Iter   108/  229] train: loss: 0.1137764
[Epoch 109; Iter   138/  229] train: loss: 0.1255118
[Epoch 109; Iter   168/  229] train: loss: 0.1801092
[Epoch 109; Iter   198/  229] train: loss: 0.1258645
[Epoch 109; Iter   228/  229] train: loss: 0.1554813
[Epoch 109] ogbg-moltoxcast: 0.736670 val loss: 0.201690
[Epoch 109] ogbg-moltoxcast: 0.747912 test loss: 0.220556
[Epoch 110; Iter    29/  229] train: loss: 0.1113346
[Epoch 110; Iter    59/  229] train: loss: 0.1414300
[Epoch 110; Iter    89/  229] train: loss: 0.1269488
[Epoch 110; Iter   119/  229] train: loss: 0.1182560
[Epoch 110; Iter   149/  229] train: loss: 0.1124081
[Epoch 110; Iter   179/  229] train: loss: 0.1283327
[Epoch 110; Iter   209/  229] train: loss: 0.0872225
[Epoch 110] ogbg-moltoxcast: 0.741978 val loss: 0.203157
[Epoch 110] ogbg-moltoxcast: 0.751852 test loss: 0.219450
[Epoch 111; Iter    10/  229] train: loss: 0.1340912
[Epoch 111; Iter    40/  229] train: loss: 0.1791450
[Epoch 111; Iter    70/  229] train: loss: 0.1282276
[Epoch 111; Iter   100/  229] train: loss: 0.0817584
[Epoch 111; Iter   130/  229] train: loss: 0.1662746
[Epoch 111; Iter   160/  229] train: loss: 0.1417261
[Epoch 111; Iter   190/  229] train: loss: 0.1336109
[Epoch 111; Iter   220/  229] train: loss: 0.1129027
[Epoch 111] ogbg-moltoxcast: 0.739733 val loss: 0.203042
[Epoch 111] ogbg-moltoxcast: 0.749639 test loss: 0.221084
[Epoch 112; Iter    21/  229] train: loss: 0.0899080
[Epoch 112; Iter    51/  229] train: loss: 0.1448678
[Epoch 112; Iter    81/  229] train: loss: 0.1736466
[Epoch 112; Iter   111/  229] train: loss: 0.1497773
[Epoch 112; Iter   141/  229] train: loss: 0.1250803
[Epoch 112; Iter   171/  229] train: loss: 0.1330499
[Epoch 112; Iter   201/  229] train: loss: 0.1466820
[Epoch 112] ogbg-moltoxcast: 0.742875 val loss: 0.200213
[Epoch 112] ogbg-moltoxcast: 0.750075 test loss: 0.217871
[Epoch 113; Iter     2/  229] train: loss: 0.1234815
[Epoch 113; Iter    32/  229] train: loss: 0.1624834
[Epoch 113; Iter    62/  229] train: loss: 0.1392747
[Epoch 113; Iter    92/  229] train: loss: 0.1016266
[Epoch 113; Iter   122/  229] train: loss: 0.1614837
[Epoch 113; Iter   152/  229] train: loss: 0.1171833
[Epoch 113; Iter   182/  229] train: loss: 0.1347344
[Epoch 113; Iter   212/  229] train: loss: 0.1509992
[Epoch 113] ogbg-moltoxcast: 0.739411 val loss: 0.203154
[Epoch 113] ogbg-moltoxcast: 0.749826 test loss: 0.217798
[Epoch 114; Iter    13/  229] train: loss: 0.1117363
[Epoch 114; Iter    43/  229] train: loss: 0.1234749
[Epoch 114; Iter    73/  229] train: loss: 0.1049098
[Epoch 114; Iter   103/  229] train: loss: 0.1339919
[Epoch 114; Iter   133/  229] train: loss: 0.1449693
[Epoch 114; Iter   163/  229] train: loss: 0.1287766
[Epoch 114; Iter   193/  229] train: loss: 0.1033330
[Epoch 114; Iter   223/  229] train: loss: 0.1190402
[Epoch 114] ogbg-moltoxcast: 0.737982 val loss: 0.201623
[Epoch 114] ogbg-moltoxcast: 0.749327 test loss: 0.217535
[Epoch 115; Iter    24/  229] train: loss: 0.1212023
[Epoch 115; Iter    54/  229] train: loss: 0.1744397
[Epoch 115; Iter    84/  229] train: loss: 0.1184238
[Epoch 115; Iter   114/  229] train: loss: 0.0838213
[Epoch 115; Iter   144/  229] train: loss: 0.1579190
[Epoch 115; Iter   174/  229] train: loss: 0.1205292
[Epoch 115; Iter   204/  229] train: loss: 0.1610785
[Epoch 115] ogbg-moltoxcast: 0.740942 val loss: 0.201876
[Epoch 115] ogbg-moltoxcast: 0.752218 test loss: 0.219944
[Epoch 116; Iter     5/  229] train: loss: 0.1656993
[Epoch 116; Iter    35/  229] train: loss: 0.0991097
[Epoch 116; Iter    65/  229] train: loss: 0.1269750
[Epoch 116; Iter    95/  229] train: loss: 0.1080464
[Epoch 116; Iter   125/  229] train: loss: 0.1481896
[Epoch 116; Iter   155/  229] train: loss: 0.1151930
[Epoch 116; Iter   185/  229] train: loss: 0.1582539
[Epoch 116; Iter   215/  229] train: loss: 0.1643154
[Epoch 116] ogbg-moltoxcast: 0.742704 val loss: 0.199698
[Epoch 116] ogbg-moltoxcast: 0.749482 test loss: 0.219689
[Epoch 117; Iter    16/  229] train: loss: 0.1505986
[Epoch 117; Iter    46/  229] train: loss: 0.1102006
[Epoch 117; Iter    76/  229] train: loss: 0.1242051
[Epoch 117; Iter   106/  229] train: loss: 0.1411461
[Epoch 117; Iter   136/  229] train: loss: 0.1577239
[Epoch 117; Iter   166/  229] train: loss: 0.1133210
[Epoch 117; Iter   196/  229] train: loss: 0.1434046
[Epoch 117; Iter   226/  229] train: loss: 0.1027551
[Epoch 117] ogbg-moltoxcast: 0.742258 val loss: 0.199546
[Epoch 117] ogbg-moltoxcast: 0.748310 test loss: 0.220646
[Epoch 118; Iter    27/  229] train: loss: 0.1714088
[Epoch 118; Iter    57/  229] train: loss: 0.1250716
[Epoch 118; Iter    87/  229] train: loss: 0.0972216
[Epoch 118; Iter   117/  229] train: loss: 0.1257279
[Epoch 118; Iter   147/  229] train: loss: 0.1516533
[Epoch 118; Iter   177/  229] train: loss: 0.1103600
[Epoch 118; Iter   207/  229] train: loss: 0.1207301
[Epoch 118] ogbg-moltoxcast: 0.739162 val loss: 0.202314
[Epoch 118] ogbg-moltoxcast: 0.749020 test loss: 0.220188
[Epoch 119; Iter     8/  229] train: loss: 0.1573456
[Epoch 119; Iter    38/  229] train: loss: 0.1052855
[Epoch 119; Iter    68/  229] train: loss: 0.1235910
[Epoch 119; Iter    98/  229] train: loss: 0.1295721
[Epoch 119; Iter   128/  229] train: loss: 0.1601922
[Epoch 119; Iter   158/  229] train: loss: 0.1223166
[Epoch 119; Iter   188/  229] train: loss: 0.1201065
[Epoch 119; Iter   218/  229] train: loss: 0.1238507
[Epoch 119] ogbg-moltoxcast: 0.740586 val loss: 0.202086
[Epoch 119] ogbg-moltoxcast: 0.745492 test loss: 0.223310
[Epoch 120; Iter    19/  229] train: loss: 0.1009172
[Epoch 120; Iter    49/  229] train: loss: 0.1352890
[Epoch 120; Iter    79/  229] train: loss: 0.1417823
[Epoch 120; Iter   109/  229] train: loss: 0.0901826
[Epoch 120; Iter   139/  229] train: loss: 0.0948848
[Epoch 120; Iter   169/  229] train: loss: 0.1813464
[Epoch 120; Iter   199/  229] train: loss: 0.1308341
[Epoch 120; Iter   229/  229] train: loss: 0.1613506
[Epoch 120] ogbg-moltoxcast: 0.741990 val loss: 0.200291
[Epoch 120] ogbg-moltoxcast: 0.748561 test loss: 0.219473
[Epoch 121; Iter    30/  229] train: loss: 0.0951807
[Epoch 121; Iter    60/  229] train: loss: 0.1911296
[Epoch 121; Iter    90/  229] train: loss: 0.1434434
[Epoch 121; Iter   120/  229] train: loss: 0.1486934
[Epoch 121; Iter   150/  229] train: loss: 0.1282207
[Epoch 121; Iter   180/  229] train: loss: 0.1053269
[Epoch 121; Iter   210/  229] train: loss: 0.1175342
[Epoch 121] ogbg-moltoxcast: 0.740653 val loss: 0.201391
[Epoch 121] ogbg-moltoxcast: 0.752665 test loss: 0.218029
[Epoch 122; Iter    11/  229] train: loss: 0.1591660
[Epoch 122; Iter    41/  229] train: loss: 0.1380862
[Epoch 122; Iter    71/  229] train: loss: 0.1551524
[Epoch 122; Iter   101/  229] train: loss: 0.1126196
[Epoch 122; Iter   131/  229] train: loss: 0.1445961
[Epoch 122; Iter   161/  229] train: loss: 0.1238471
[Epoch 122; Iter   191/  229] train: loss: 0.1369950
[Epoch 122; Iter   221/  229] train: loss: 0.1568127
[Epoch 122] ogbg-moltoxcast: 0.742835 val loss: 0.202160
[Epoch 122] ogbg-moltoxcast: 0.751737 test loss: 0.219325
[Epoch 123; Iter    22/  229] train: loss: 0.1170770
[Epoch 123; Iter    52/  229] train: loss: 0.1187326
[Epoch 123; Iter    82/  229] train: loss: 0.1073213
[Epoch 123; Iter   112/  229] train: loss: 0.1409983
[Epoch 123; Iter   142/  229] train: loss: 0.0941943
[Epoch 107] ogbg-moltoxcast: 0.762701 test loss: 0.218222
[Epoch 108; Iter     7/  229] train: loss: 0.1302361
[Epoch 108; Iter    37/  229] train: loss: 0.1253899
[Epoch 108; Iter    67/  229] train: loss: 0.1400288
[Epoch 108; Iter    97/  229] train: loss: 0.1308812
[Epoch 108; Iter   127/  229] train: loss: 0.0836229
[Epoch 108; Iter   157/  229] train: loss: 0.1294662
[Epoch 108; Iter   187/  229] train: loss: 0.1222011
[Epoch 108; Iter   217/  229] train: loss: 0.1205105
[Epoch 108] ogbg-moltoxcast: 0.736940 val loss: 0.199878
[Epoch 108] ogbg-moltoxcast: 0.763286 test loss: 0.217085
[Epoch 109; Iter    18/  229] train: loss: 0.1145100
[Epoch 109; Iter    48/  229] train: loss: 0.0990474
[Epoch 109; Iter    78/  229] train: loss: 0.1105317
[Epoch 109; Iter   108/  229] train: loss: 0.1364178
[Epoch 109; Iter   138/  229] train: loss: 0.1290515
[Epoch 109; Iter   168/  229] train: loss: 0.1089903
[Epoch 109; Iter   198/  229] train: loss: 0.1489586
[Epoch 109; Iter   228/  229] train: loss: 0.0889279
[Epoch 109] ogbg-moltoxcast: 0.736422 val loss: 0.203075
[Epoch 109] ogbg-moltoxcast: 0.762141 test loss: 0.220534
[Epoch 110; Iter    29/  229] train: loss: 0.0999347
[Epoch 110; Iter    59/  229] train: loss: 0.1335998
[Epoch 110; Iter    89/  229] train: loss: 0.1646443
[Epoch 110; Iter   119/  229] train: loss: 0.1068271
[Epoch 110; Iter   149/  229] train: loss: 0.0894343
[Epoch 110; Iter   179/  229] train: loss: 0.1432460
[Epoch 110; Iter   209/  229] train: loss: 0.1610068
[Epoch 110] ogbg-moltoxcast: 0.735935 val loss: 0.201232
[Epoch 110] ogbg-moltoxcast: 0.763243 test loss: 0.217725
[Epoch 111; Iter    10/  229] train: loss: 0.1328625
[Epoch 111; Iter    40/  229] train: loss: 0.1125398
[Epoch 111; Iter    70/  229] train: loss: 0.0935205
[Epoch 111; Iter   100/  229] train: loss: 0.0792008
[Epoch 111; Iter   130/  229] train: loss: 0.1351695
[Epoch 111; Iter   160/  229] train: loss: 0.1146910
[Epoch 111; Iter   190/  229] train: loss: 0.1589117
[Epoch 111; Iter   220/  229] train: loss: 0.1076522
[Epoch 111] ogbg-moltoxcast: 0.735124 val loss: 0.200451
[Epoch 111] ogbg-moltoxcast: 0.762242 test loss: 0.216627
[Epoch 112; Iter    21/  229] train: loss: 0.1287895
[Epoch 112; Iter    51/  229] train: loss: 0.1846724
[Epoch 112; Iter    81/  229] train: loss: 0.0876911
[Epoch 112; Iter   111/  229] train: loss: 0.1182706
[Epoch 112; Iter   141/  229] train: loss: 0.1763427
[Epoch 112; Iter   171/  229] train: loss: 0.1655575
[Epoch 112; Iter   201/  229] train: loss: 0.1174999
[Epoch 112] ogbg-moltoxcast: 0.733569 val loss: 0.203356
[Epoch 112] ogbg-moltoxcast: 0.761784 test loss: 0.218547
[Epoch 113; Iter     2/  229] train: loss: 0.1571655
[Epoch 113; Iter    32/  229] train: loss: 0.1301929
[Epoch 113; Iter    62/  229] train: loss: 0.1010473
[Epoch 113; Iter    92/  229] train: loss: 0.1646263
[Epoch 113; Iter   122/  229] train: loss: 0.1253072
[Epoch 113; Iter   152/  229] train: loss: 0.1163297
[Epoch 113; Iter   182/  229] train: loss: 0.1263496
[Epoch 113; Iter   212/  229] train: loss: 0.1501261
[Epoch 113] ogbg-moltoxcast: 0.733239 val loss: 0.202894
[Epoch 113] ogbg-moltoxcast: 0.761565 test loss: 0.218785
[Epoch 114; Iter    13/  229] train: loss: 0.1154149
[Epoch 114; Iter    43/  229] train: loss: 0.1094817
[Epoch 114; Iter    73/  229] train: loss: 0.1139699
[Epoch 114; Iter   103/  229] train: loss: 0.1221096
[Epoch 114; Iter   133/  229] train: loss: 0.0954880
[Epoch 114; Iter   163/  229] train: loss: 0.1602585
[Epoch 114; Iter   193/  229] train: loss: 0.1295451
[Epoch 114; Iter   223/  229] train: loss: 0.2372784
[Epoch 114] ogbg-moltoxcast: 0.738208 val loss: 0.203459
[Epoch 114] ogbg-moltoxcast: 0.764846 test loss: 0.218950
[Epoch 115; Iter    24/  229] train: loss: 0.1628151
[Epoch 115; Iter    54/  229] train: loss: 0.1491516
[Epoch 115; Iter    84/  229] train: loss: 0.1270717
[Epoch 115; Iter   114/  229] train: loss: 0.1669878
[Epoch 115; Iter   144/  229] train: loss: 0.1320391
[Epoch 115; Iter   174/  229] train: loss: 0.1660150
[Epoch 115; Iter   204/  229] train: loss: 0.1188842
[Epoch 115] ogbg-moltoxcast: 0.736692 val loss: 0.201418
[Epoch 115] ogbg-moltoxcast: 0.762445 test loss: 0.219368
[Epoch 116; Iter     5/  229] train: loss: 0.1382103
[Epoch 116; Iter    35/  229] train: loss: 0.1742628
[Epoch 116; Iter    65/  229] train: loss: 0.1049810
[Epoch 116; Iter    95/  229] train: loss: 0.1369750
[Epoch 116; Iter   125/  229] train: loss: 0.1385874
[Epoch 116; Iter   155/  229] train: loss: 0.1434277
[Epoch 116; Iter   185/  229] train: loss: 0.1399126
[Epoch 116; Iter   215/  229] train: loss: 0.1517068
[Epoch 116] ogbg-moltoxcast: 0.736361 val loss: 0.202625
[Epoch 116] ogbg-moltoxcast: 0.762734 test loss: 0.217929
[Epoch 117; Iter    16/  229] train: loss: 0.1294015
[Epoch 117; Iter    46/  229] train: loss: 0.1439889
[Epoch 117; Iter    76/  229] train: loss: 0.1433323
[Epoch 117; Iter   106/  229] train: loss: 0.0965909
[Epoch 117; Iter   136/  229] train: loss: 0.1370912
[Epoch 117; Iter   166/  229] train: loss: 0.1228551
[Epoch 117; Iter   196/  229] train: loss: 0.1355297
[Epoch 117; Iter   226/  229] train: loss: 0.0795576
[Epoch 117] ogbg-moltoxcast: 0.735634 val loss: 0.203085
[Epoch 117] ogbg-moltoxcast: 0.762690 test loss: 0.217971
[Epoch 118; Iter    27/  229] train: loss: 0.1420411
[Epoch 118; Iter    57/  229] train: loss: 0.1248172
[Epoch 118; Iter    87/  229] train: loss: 0.1793269
[Epoch 118; Iter   117/  229] train: loss: 0.1160080
[Epoch 118; Iter   147/  229] train: loss: 0.1076762
[Epoch 118; Iter   177/  229] train: loss: 0.1286661
[Epoch 118; Iter   207/  229] train: loss: 0.0845380
[Epoch 118] ogbg-moltoxcast: 0.735961 val loss: 0.202629
[Epoch 118] ogbg-moltoxcast: 0.763390 test loss: 0.218113
[Epoch 119; Iter     8/  229] train: loss: 0.1240531
[Epoch 119; Iter    38/  229] train: loss: 0.1129948
[Epoch 119; Iter    68/  229] train: loss: 0.1238661
[Epoch 119; Iter    98/  229] train: loss: 0.1766596
[Epoch 119; Iter   128/  229] train: loss: 0.1492070
[Epoch 119; Iter   158/  229] train: loss: 0.1208376
[Epoch 119; Iter   188/  229] train: loss: 0.1261856
[Epoch 119; Iter   218/  229] train: loss: 0.1344208
[Epoch 119] ogbg-moltoxcast: 0.734452 val loss: 0.203364
[Epoch 119] ogbg-moltoxcast: 0.761697 test loss: 0.216701
[Epoch 120; Iter    19/  229] train: loss: 0.0664769
[Epoch 120; Iter    49/  229] train: loss: 0.1359550
[Epoch 120; Iter    79/  229] train: loss: 0.1756835
[Epoch 120; Iter   109/  229] train: loss: 0.0886570
[Epoch 120; Iter   139/  229] train: loss: 0.1171671
[Epoch 120; Iter   169/  229] train: loss: 0.1249497
[Epoch 120; Iter   199/  229] train: loss: 0.1388533
[Epoch 120; Iter   229/  229] train: loss: 0.0968516
[Epoch 120] ogbg-moltoxcast: 0.734676 val loss: 0.202520
[Epoch 120] ogbg-moltoxcast: 0.762768 test loss: 0.218520
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 40.
Statistics on  val_best_checkpoint
mean_pred: -2.934304714202881
std_pred: 2.3847198486328125
mean_targets: nan
std_targets: nan
prcauc: 0.4273841526401845
rocauc: 0.7486058059347019
ogbg-moltoxcast: 0.7486058059347019
OGBNanLabelBCEWithLogitsLoss: 0.1906060427427292
Statistics on  test
mean_pred: -2.9326553344726562
std_pred: 2.4200387001037598
mean_targets: nan
std_targets: nan
prcauc: 0.45637660739182484
rocauc: 0.7601549371664563
ogbg-moltoxcast: 0.7601549371664563
OGBNanLabelBCEWithLogitsLoss: 0.2037387009838532
Statistics on  train
mean_pred: -2.990091562271118
std_pred: 3.51702618598938
mean_targets: nan
std_targets: nan
prcauc: 0.5485162414711424
rocauc: 0.8655921387758794
ogbg-moltoxcast: 0.8655921387758794
OGBNanLabelBCEWithLogitsLoss: 0.15761878292633458
[Epoch 107] ogbg-moltoxcast: 0.762584 test loss: 0.211556
[Epoch 108; Iter     7/  229] train: loss: 0.0954915
[Epoch 108; Iter    37/  229] train: loss: 0.1558655
[Epoch 108; Iter    67/  229] train: loss: 0.1468226
[Epoch 108; Iter    97/  229] train: loss: 0.1125469
[Epoch 108; Iter   127/  229] train: loss: 0.1410537
[Epoch 108; Iter   157/  229] train: loss: 0.1183259
[Epoch 108; Iter   187/  229] train: loss: 0.1163826
[Epoch 108; Iter   217/  229] train: loss: 0.1424414
[Epoch 108] ogbg-moltoxcast: 0.762621 val loss: 0.197391
[Epoch 108] ogbg-moltoxcast: 0.759864 test loss: 0.210610
[Epoch 109; Iter    18/  229] train: loss: 0.1542153
[Epoch 109; Iter    48/  229] train: loss: 0.1270588
[Epoch 109; Iter    78/  229] train: loss: 0.1102854
[Epoch 109; Iter   108/  229] train: loss: 0.1586831
[Epoch 109; Iter   138/  229] train: loss: 0.1089878
[Epoch 109; Iter   168/  229] train: loss: 0.0955076
[Epoch 109; Iter   198/  229] train: loss: 0.1425711
[Epoch 109; Iter   228/  229] train: loss: 0.1971536
[Epoch 109] ogbg-moltoxcast: 0.759437 val loss: 0.199380
[Epoch 109] ogbg-moltoxcast: 0.762194 test loss: 0.210447
[Epoch 110; Iter    29/  229] train: loss: 0.1545483
[Epoch 110; Iter    59/  229] train: loss: 0.1968907
[Epoch 110; Iter    89/  229] train: loss: 0.1286368
[Epoch 110; Iter   119/  229] train: loss: 0.1317921
[Epoch 110; Iter   149/  229] train: loss: 0.0909293
[Epoch 110; Iter   179/  229] train: loss: 0.1210490
[Epoch 110; Iter   209/  229] train: loss: 0.1764643
[Epoch 110] ogbg-moltoxcast: 0.760929 val loss: 0.201743
[Epoch 110] ogbg-moltoxcast: 0.761196 test loss: 0.211458
[Epoch 111; Iter    10/  229] train: loss: 0.1116574
[Epoch 111; Iter    40/  229] train: loss: 0.0982205
[Epoch 111; Iter    70/  229] train: loss: 0.1747333
[Epoch 111; Iter   100/  229] train: loss: 0.1673256
[Epoch 111; Iter   130/  229] train: loss: 0.1348528
[Epoch 111; Iter   160/  229] train: loss: 0.1534038
[Epoch 111; Iter   190/  229] train: loss: 0.1431066
[Epoch 111; Iter   220/  229] train: loss: 0.1472140
[Epoch 111] ogbg-moltoxcast: 0.762401 val loss: 0.198697
[Epoch 111] ogbg-moltoxcast: 0.760307 test loss: 0.210412
[Epoch 112; Iter    21/  229] train: loss: 0.1283776
[Epoch 112; Iter    51/  229] train: loss: 0.1448808
[Epoch 112; Iter    81/  229] train: loss: 0.1158487
[Epoch 112; Iter   111/  229] train: loss: 0.1296355
[Epoch 112; Iter   141/  229] train: loss: 0.1348935
[Epoch 112; Iter   171/  229] train: loss: 0.1664458
[Epoch 112; Iter   201/  229] train: loss: 0.1438769
[Epoch 112] ogbg-moltoxcast: 0.760030 val loss: 0.201477
[Epoch 112] ogbg-moltoxcast: 0.759933 test loss: 0.213756
[Epoch 113; Iter     2/  229] train: loss: 0.1167760
[Epoch 113; Iter    32/  229] train: loss: 0.1125894
[Epoch 113; Iter    62/  229] train: loss: 0.1253497
[Epoch 113; Iter    92/  229] train: loss: 0.1617130
[Epoch 113; Iter   122/  229] train: loss: 0.1223836
[Epoch 113; Iter   152/  229] train: loss: 0.1598619
[Epoch 113; Iter   182/  229] train: loss: 0.1465138
[Epoch 113; Iter   212/  229] train: loss: 0.1281677
[Epoch 113] ogbg-moltoxcast: 0.765269 val loss: 0.198396
[Epoch 113] ogbg-moltoxcast: 0.760164 test loss: 0.212172
[Epoch 114; Iter    13/  229] train: loss: 0.2297558
[Epoch 114; Iter    43/  229] train: loss: 0.1261657
[Epoch 114; Iter    73/  229] train: loss: 0.1111690
[Epoch 114; Iter   103/  229] train: loss: 0.1328256
[Epoch 114; Iter   133/  229] train: loss: 0.1607842
[Epoch 114; Iter   163/  229] train: loss: 0.1468369
[Epoch 114; Iter   193/  229] train: loss: 0.0830096
[Epoch 114; Iter   223/  229] train: loss: 0.1000264
[Epoch 114] ogbg-moltoxcast: 0.760568 val loss: 0.200265
[Epoch 114] ogbg-moltoxcast: 0.760111 test loss: 0.212773
[Epoch 115; Iter    24/  229] train: loss: 0.1567260
[Epoch 115; Iter    54/  229] train: loss: 0.1297942
[Epoch 115; Iter    84/  229] train: loss: 0.1832056
[Epoch 115; Iter   114/  229] train: loss: 0.0923061
[Epoch 115; Iter   144/  229] train: loss: 0.1162716
[Epoch 115; Iter   174/  229] train: loss: 0.1378263
[Epoch 115; Iter   204/  229] train: loss: 0.1285020
[Epoch 115] ogbg-moltoxcast: 0.762930 val loss: 0.200722
[Epoch 115] ogbg-moltoxcast: 0.762791 test loss: 0.211905
[Epoch 116; Iter     5/  229] train: loss: 0.1389616
[Epoch 116; Iter    35/  229] train: loss: 0.1315799
[Epoch 116; Iter    65/  229] train: loss: 0.1623679
[Epoch 116; Iter    95/  229] train: loss: 0.1485896
[Epoch 116; Iter   125/  229] train: loss: 0.1189417
[Epoch 116; Iter   155/  229] train: loss: 0.1450652
[Epoch 116; Iter   185/  229] train: loss: 0.1435611
[Epoch 116; Iter   215/  229] train: loss: 0.1326894
[Epoch 116] ogbg-moltoxcast: 0.760203 val loss: 0.200310
[Epoch 116] ogbg-moltoxcast: 0.761656 test loss: 0.211574
[Epoch 117; Iter    16/  229] train: loss: 0.1467969
[Epoch 117; Iter    46/  229] train: loss: 0.1138092
[Epoch 117; Iter    76/  229] train: loss: 0.1501947
[Epoch 117; Iter   106/  229] train: loss: 0.0962176
[Epoch 117; Iter   136/  229] train: loss: 0.1467795
[Epoch 117; Iter   166/  229] train: loss: 0.1330506
[Epoch 117; Iter   196/  229] train: loss: 0.1111936
[Epoch 117; Iter   226/  229] train: loss: 0.1190826
[Epoch 117] ogbg-moltoxcast: 0.762135 val loss: 0.200913
[Epoch 117] ogbg-moltoxcast: 0.761515 test loss: 0.211606
[Epoch 118; Iter    27/  229] train: loss: 0.1781634
[Epoch 118; Iter    57/  229] train: loss: 0.1383082
[Epoch 118; Iter    87/  229] train: loss: 0.1190441
[Epoch 118; Iter   117/  229] train: loss: 0.1477429
[Epoch 118; Iter   147/  229] train: loss: 0.1061407
[Epoch 118; Iter   177/  229] train: loss: 0.1512417
[Epoch 118; Iter   207/  229] train: loss: 0.1042423
[Epoch 118] ogbg-moltoxcast: 0.760423 val loss: 0.200888
[Epoch 118] ogbg-moltoxcast: 0.760891 test loss: 0.211325
[Epoch 119; Iter     8/  229] train: loss: 0.1540104
[Epoch 119; Iter    38/  229] train: loss: 0.1307801
[Epoch 119; Iter    68/  229] train: loss: 0.1109041
[Epoch 119; Iter    98/  229] train: loss: 0.1229175
[Epoch 119; Iter   128/  229] train: loss: 0.1289176
[Epoch 119; Iter   158/  229] train: loss: 0.1274451
[Epoch 119; Iter   188/  229] train: loss: 0.0805975
[Epoch 119; Iter   218/  229] train: loss: 0.1609516
[Epoch 119] ogbg-moltoxcast: 0.761014 val loss: 0.200672
[Epoch 119] ogbg-moltoxcast: 0.761171 test loss: 0.213304
[Epoch 120; Iter    19/  229] train: loss: 0.1154459
[Epoch 120; Iter    49/  229] train: loss: 0.1611458
[Epoch 120; Iter    79/  229] train: loss: 0.1537836
[Epoch 120; Iter   109/  229] train: loss: 0.1420065
[Epoch 120; Iter   139/  229] train: loss: 0.1388490
[Epoch 120; Iter   169/  229] train: loss: 0.1536195
[Epoch 120; Iter   199/  229] train: loss: 0.1497399
[Epoch 120; Iter   229/  229] train: loss: 0.1885879
[Epoch 120] ogbg-moltoxcast: 0.763115 val loss: 0.200698
[Epoch 120] ogbg-moltoxcast: 0.762621 test loss: 0.213686
[Epoch 121; Iter    30/  229] train: loss: 0.1215400
[Epoch 121; Iter    60/  229] train: loss: 0.1373325
[Epoch 121; Iter    90/  229] train: loss: 0.1739751
[Epoch 121; Iter   120/  229] train: loss: 0.1355716
[Epoch 121; Iter   150/  229] train: loss: 0.1411790
[Epoch 121; Iter   180/  229] train: loss: 0.0869931
[Epoch 121; Iter   210/  229] train: loss: 0.2257567
[Epoch 121] ogbg-moltoxcast: 0.760727 val loss: 0.200347
[Epoch 121] ogbg-moltoxcast: 0.763065 test loss: 0.211279
[Epoch 122; Iter    11/  229] train: loss: 0.1276128
[Epoch 122; Iter    41/  229] train: loss: 0.1151255
[Epoch 122; Iter    71/  229] train: loss: 0.1582017
[Epoch 122; Iter   101/  229] train: loss: 0.1744371
[Epoch 122; Iter   131/  229] train: loss: 0.1877184
[Epoch 122; Iter   161/  229] train: loss: 0.1336570
[Epoch 122; Iter   191/  229] train: loss: 0.1505664
[Epoch 122; Iter   221/  229] train: loss: 0.1508006
[Epoch 122] ogbg-moltoxcast: 0.761082 val loss: 0.201975
[Epoch 122] ogbg-moltoxcast: 0.763486 test loss: 0.214867
[Epoch 123; Iter    22/  229] train: loss: 0.1377697
[Epoch 123; Iter    52/  229] train: loss: 0.1357021
[Epoch 123; Iter    82/  229] train: loss: 0.1123724
[Epoch 123; Iter   112/  229] train: loss: 0.1502430
[Epoch 123; Iter   142/  229] train: loss: 0.1237691
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 119; Iter    42/  201] train: loss: 0.1091233
[Epoch 119; Iter    72/  201] train: loss: 0.0992338
[Epoch 119; Iter   102/  201] train: loss: 0.1265505
[Epoch 119; Iter   132/  201] train: loss: 0.1254033
[Epoch 119; Iter   162/  201] train: loss: 0.1395984
[Epoch 119; Iter   192/  201] train: loss: 0.1638134
[Epoch 119] ogbg-moltoxcast: 0.728449 val loss: 0.219037
[Epoch 119] ogbg-moltoxcast: 0.748189 test loss: 0.216021
[Epoch 120; Iter    21/  201] train: loss: 0.1142058
[Epoch 120; Iter    51/  201] train: loss: 0.1389700
[Epoch 120; Iter    81/  201] train: loss: 0.1188024
[Epoch 120; Iter   111/  201] train: loss: 0.1716953
[Epoch 120; Iter   141/  201] train: loss: 0.1338926
[Epoch 120; Iter   171/  201] train: loss: 0.1268861
[Epoch 120; Iter   201/  201] train: loss: 0.2981822
[Epoch 120] ogbg-moltoxcast: 0.729581 val loss: 0.222074
[Epoch 120] ogbg-moltoxcast: 0.750536 test loss: 0.218564
[Epoch 121; Iter    30/  201] train: loss: 0.1205688
[Epoch 121; Iter    60/  201] train: loss: 0.1421879
[Epoch 121; Iter    90/  201] train: loss: 0.0715895
[Epoch 121; Iter   120/  201] train: loss: 0.1349198
[Epoch 121; Iter   150/  201] train: loss: 0.0866489
[Epoch 121; Iter   180/  201] train: loss: 0.0738116
[Epoch 121] ogbg-moltoxcast: 0.724739 val loss: 0.219504
[Epoch 121] ogbg-moltoxcast: 0.744976 test loss: 0.217031
[Epoch 122; Iter     9/  201] train: loss: 0.1103666
[Epoch 122; Iter    39/  201] train: loss: 0.1483831
[Epoch 122; Iter    69/  201] train: loss: 0.1098274
[Epoch 122; Iter    99/  201] train: loss: 0.0961468
[Epoch 122; Iter   129/  201] train: loss: 0.1214726
[Epoch 122; Iter   159/  201] train: loss: 0.1140260
[Epoch 122; Iter   189/  201] train: loss: 0.1292077
[Epoch 122] ogbg-moltoxcast: 0.727837 val loss: 0.221669
[Epoch 122] ogbg-moltoxcast: 0.749906 test loss: 0.217208
[Epoch 123; Iter    18/  201] train: loss: 0.0742209
[Epoch 123; Iter    48/  201] train: loss: 0.1087063
[Epoch 123; Iter    78/  201] train: loss: 0.1192750
[Epoch 123; Iter   108/  201] train: loss: 0.1276435
[Epoch 123; Iter   138/  201] train: loss: 0.1088968
[Epoch 123; Iter   168/  201] train: loss: 0.1231127
[Epoch 123; Iter   198/  201] train: loss: 0.1556814
[Epoch 123] ogbg-moltoxcast: 0.728275 val loss: 0.218879
[Epoch 123] ogbg-moltoxcast: 0.751357 test loss: 0.214653
[Epoch 124; Iter    27/  201] train: loss: 0.0963921
[Epoch 124; Iter    57/  201] train: loss: 0.1222931
[Epoch 124; Iter    87/  201] train: loss: 0.0973347
[Epoch 124; Iter   117/  201] train: loss: 0.1523887
[Epoch 124; Iter   147/  201] train: loss: 0.2000519
[Epoch 124; Iter   177/  201] train: loss: 0.1754552
[Epoch 124] ogbg-moltoxcast: 0.726151 val loss: 0.222319
[Epoch 124] ogbg-moltoxcast: 0.748260 test loss: 0.217681
[Epoch 125; Iter     6/  201] train: loss: 0.1858170
[Epoch 125; Iter    36/  201] train: loss: 0.1580515
[Epoch 125; Iter    66/  201] train: loss: 0.1569573
[Epoch 125; Iter    96/  201] train: loss: 0.1631178
[Epoch 125; Iter   126/  201] train: loss: 0.1453280
[Epoch 125; Iter   156/  201] train: loss: 0.1121627
[Epoch 125; Iter   186/  201] train: loss: 0.0967357
[Epoch 125] ogbg-moltoxcast: 0.728009 val loss: 0.222891
[Epoch 125] ogbg-moltoxcast: 0.748652 test loss: 0.217574
[Epoch 126; Iter    15/  201] train: loss: 0.1380401
[Epoch 126; Iter    45/  201] train: loss: 0.1008051
[Epoch 126; Iter    75/  201] train: loss: 0.1160285
[Epoch 126; Iter   105/  201] train: loss: 0.1527217
[Epoch 126; Iter   135/  201] train: loss: 0.1744235
[Epoch 126; Iter   165/  201] train: loss: 0.1092456
[Epoch 126; Iter   195/  201] train: loss: 0.1443314
[Epoch 126] ogbg-moltoxcast: 0.730135 val loss: 0.224113
[Epoch 126] ogbg-moltoxcast: 0.748685 test loss: 0.222356
[Epoch 127; Iter    24/  201] train: loss: 0.1894515
[Epoch 127; Iter    54/  201] train: loss: 0.1698422
[Epoch 127; Iter    84/  201] train: loss: 0.1519570
[Epoch 127; Iter   114/  201] train: loss: 0.1198404
[Epoch 127; Iter   144/  201] train: loss: 0.0972356
[Epoch 127; Iter   174/  201] train: loss: 0.0940212
[Epoch 127] ogbg-moltoxcast: 0.731135 val loss: 0.219754
[Epoch 127] ogbg-moltoxcast: 0.750595 test loss: 0.216701
[Epoch 128; Iter     3/  201] train: loss: 0.1228303
[Epoch 128; Iter    33/  201] train: loss: 0.1319326
[Epoch 128; Iter    63/  201] train: loss: 0.1347434
[Epoch 128; Iter    93/  201] train: loss: 0.0947999
[Epoch 128; Iter   123/  201] train: loss: 0.1203119
[Epoch 128; Iter   153/  201] train: loss: 0.1166444
[Epoch 128; Iter   183/  201] train: loss: 0.1539584
[Epoch 128] ogbg-moltoxcast: 0.727836 val loss: 0.221823
[Epoch 128] ogbg-moltoxcast: 0.748503 test loss: 0.217460
[Epoch 129; Iter    12/  201] train: loss: 0.0746000
[Epoch 129; Iter    42/  201] train: loss: 0.1353071
[Epoch 129; Iter    72/  201] train: loss: 0.1216804
[Epoch 129; Iter   102/  201] train: loss: 0.1340185
[Epoch 129; Iter   132/  201] train: loss: 0.1540358
[Epoch 129; Iter   162/  201] train: loss: 0.1110515
[Epoch 129; Iter   192/  201] train: loss: 0.1455400
[Epoch 129] ogbg-moltoxcast: 0.728620 val loss: 0.221663
[Epoch 129] ogbg-moltoxcast: 0.752013 test loss: 0.216756
[Epoch 130; Iter    21/  201] train: loss: 0.1305121
[Epoch 130; Iter    51/  201] train: loss: 0.0984488
[Epoch 130; Iter    81/  201] train: loss: 0.1164544
[Epoch 130; Iter   111/  201] train: loss: 0.0621795
[Epoch 130; Iter   141/  201] train: loss: 0.1418102
[Epoch 130; Iter   171/  201] train: loss: 0.1468332
[Epoch 130; Iter   201/  201] train: loss: 0.1720823
[Epoch 130] ogbg-moltoxcast: 0.729750 val loss: 0.220420
[Epoch 130] ogbg-moltoxcast: 0.750187 test loss: 0.219859
[Epoch 131; Iter    30/  201] train: loss: 0.1768596
[Epoch 131; Iter    60/  201] train: loss: 0.0825638
[Epoch 131; Iter    90/  201] train: loss: 0.1202831
[Epoch 131; Iter   120/  201] train: loss: 0.1450790
[Epoch 131; Iter   150/  201] train: loss: 0.1782967
[Epoch 131; Iter   180/  201] train: loss: 0.0834502
[Epoch 131] ogbg-moltoxcast: 0.730051 val loss: 0.220456
[Epoch 131] ogbg-moltoxcast: 0.750702 test loss: 0.218476
[Epoch 132; Iter     9/  201] train: loss: 0.1345565
[Epoch 132; Iter    39/  201] train: loss: 0.0995580
[Epoch 132; Iter    69/  201] train: loss: 0.1780958
[Epoch 132; Iter    99/  201] train: loss: 0.1033518
[Epoch 132; Iter   129/  201] train: loss: 0.1391736
[Epoch 132; Iter   159/  201] train: loss: 0.1102852
[Epoch 132; Iter   189/  201] train: loss: 0.1613689
[Epoch 132] ogbg-moltoxcast: 0.730661 val loss: 0.223651
[Epoch 132] ogbg-moltoxcast: 0.750450 test loss: 0.221805
[Epoch 133; Iter    18/  201] train: loss: 0.1254638
[Epoch 133; Iter    48/  201] train: loss: 0.1129433
[Epoch 133; Iter    78/  201] train: loss: 0.1709388
[Epoch 133; Iter   108/  201] train: loss: 0.1272651
[Epoch 133; Iter   138/  201] train: loss: 0.1493740
[Epoch 133; Iter   168/  201] train: loss: 0.1695990
[Epoch 133; Iter   198/  201] train: loss: 0.0975954
[Epoch 133] ogbg-moltoxcast: 0.731095 val loss: 0.220528
[Epoch 133] ogbg-moltoxcast: 0.749137 test loss: 0.218606
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 133 epochs. Best model checkpoint was in epoch 73.
Statistics on  val_best_checkpoint
mean_pred: -3.5111875534057617
std_pred: 2.7411131858825684
mean_targets: nan
std_targets: nan
prcauc: 0.42070027778660485
rocauc: 0.7370840040200206
ogbg-moltoxcast: 0.7370840040200206
OGBNanLabelBCEWithLogitsLoss: 0.21169569897790289
Statistics on  test
mean_pred: -3.535936117172241
std_pred: 2.7621066570281982
mean_targets: nan
std_targets: nan
prcauc: 0.440429585319
rocauc: 0.7557092407841534
ogbg-moltoxcast: 0.7557092407841534
OGBNanLabelBCEWithLogitsLoss: 0.20984426643266235
Statistics on  train
mean_pred: -3.582679033279419
std_pred: 2.8109490871429443
mean_targets: nan
std_targets: nan
prcauc: 0.6323384996982474
rocauc: 0.9051742246618786
ogbg-moltoxcast: 0.9051742246618786
OGBNanLabelBCEWithLogitsLoss: 0.13324726343303178
[Epoch 119; Iter    42/  201] train: loss: 0.1138509
[Epoch 119; Iter    72/  201] train: loss: 0.1492353
[Epoch 119; Iter   102/  201] train: loss: 0.1606925
[Epoch 119; Iter   132/  201] train: loss: 0.1395868
[Epoch 119; Iter   162/  201] train: loss: 0.1059236
[Epoch 119; Iter   192/  201] train: loss: 0.1088110
[Epoch 119] ogbg-moltoxcast: 0.736287 val loss: 0.211309
[Epoch 119] ogbg-moltoxcast: 0.754322 test loss: 0.210500
[Epoch 120; Iter    21/  201] train: loss: 0.0852779
[Epoch 120; Iter    51/  201] train: loss: 0.1224314
[Epoch 120; Iter    81/  201] train: loss: 0.1095156
[Epoch 120; Iter   111/  201] train: loss: 0.1192637
[Epoch 120; Iter   141/  201] train: loss: 0.0970040
[Epoch 120; Iter   171/  201] train: loss: 0.0926446
[Epoch 120; Iter   201/  201] train: loss: 0.2850429
[Epoch 120] ogbg-moltoxcast: 0.737313 val loss: 0.213489
[Epoch 120] ogbg-moltoxcast: 0.757227 test loss: 0.212083
[Epoch 121; Iter    30/  201] train: loss: 0.1644469
[Epoch 121; Iter    60/  201] train: loss: 0.1007882
[Epoch 121; Iter    90/  201] train: loss: 0.1483783
[Epoch 121; Iter   120/  201] train: loss: 0.1310202
[Epoch 121; Iter   150/  201] train: loss: 0.1331055
[Epoch 121; Iter   180/  201] train: loss: 0.1536477
[Epoch 121] ogbg-moltoxcast: 0.736437 val loss: 0.211547
[Epoch 121] ogbg-moltoxcast: 0.758029 test loss: 0.210927
[Epoch 122; Iter     9/  201] train: loss: 0.1786094
[Epoch 122; Iter    39/  201] train: loss: 0.1275753
[Epoch 122; Iter    69/  201] train: loss: 0.1047983
[Epoch 122; Iter    99/  201] train: loss: 0.0876966
[Epoch 122; Iter   129/  201] train: loss: 0.1407064
[Epoch 122; Iter   159/  201] train: loss: 0.1375548
[Epoch 122; Iter   189/  201] train: loss: 0.0752743
[Epoch 122] ogbg-moltoxcast: 0.735719 val loss: 0.210409
[Epoch 122] ogbg-moltoxcast: 0.757364 test loss: 0.209071
[Epoch 123; Iter    18/  201] train: loss: 0.1056858
[Epoch 123; Iter    48/  201] train: loss: 0.1527568
[Epoch 123; Iter    78/  201] train: loss: 0.1572710
[Epoch 123; Iter   108/  201] train: loss: 0.1088252
[Epoch 123; Iter   138/  201] train: loss: 0.1976168
[Epoch 123; Iter   168/  201] train: loss: 0.1194860
[Epoch 123; Iter   198/  201] train: loss: 0.0976672
[Epoch 123] ogbg-moltoxcast: 0.734776 val loss: 0.211902
[Epoch 123] ogbg-moltoxcast: 0.756497 test loss: 0.209929
[Epoch 124; Iter    27/  201] train: loss: 0.0960959
[Epoch 124; Iter    57/  201] train: loss: 0.1573471
[Epoch 124; Iter    87/  201] train: loss: 0.1394750
[Epoch 124; Iter   117/  201] train: loss: 0.1444409
[Epoch 124; Iter   147/  201] train: loss: 0.1432114
[Epoch 124; Iter   177/  201] train: loss: 0.1194385
[Epoch 124] ogbg-moltoxcast: 0.735450 val loss: 0.212970
[Epoch 124] ogbg-moltoxcast: 0.756175 test loss: 0.212296
[Epoch 125; Iter     6/  201] train: loss: 0.1431379
[Epoch 125; Iter    36/  201] train: loss: 0.1168700
[Epoch 125; Iter    66/  201] train: loss: 0.1031324
[Epoch 125; Iter    96/  201] train: loss: 0.1072422
[Epoch 125; Iter   126/  201] train: loss: 0.1787056
[Epoch 125; Iter   156/  201] train: loss: 0.1013374
[Epoch 125; Iter   186/  201] train: loss: 0.1187738
[Epoch 125] ogbg-moltoxcast: 0.734570 val loss: 0.211128
[Epoch 125] ogbg-moltoxcast: 0.753677 test loss: 0.210621
[Epoch 126; Iter    15/  201] train: loss: 0.1072053
[Epoch 126; Iter    45/  201] train: loss: 0.1673164
[Epoch 126; Iter    75/  201] train: loss: 0.1489840
[Epoch 126; Iter   105/  201] train: loss: 0.0741538
[Epoch 126; Iter   135/  201] train: loss: 0.1202786
[Epoch 126; Iter   165/  201] train: loss: 0.1324409
[Epoch 126; Iter   195/  201] train: loss: 0.1008323
[Epoch 126] ogbg-moltoxcast: 0.737502 val loss: 0.212194
[Epoch 126] ogbg-moltoxcast: 0.755324 test loss: 0.211201
[Epoch 127; Iter    24/  201] train: loss: 0.0864956
[Epoch 127; Iter    54/  201] train: loss: 0.1205786
[Epoch 127; Iter    84/  201] train: loss: 0.1357411
[Epoch 127; Iter   114/  201] train: loss: 0.1942834
[Epoch 127; Iter   144/  201] train: loss: 0.1414080
[Epoch 127; Iter   174/  201] train: loss: 0.1414187
[Epoch 127] ogbg-moltoxcast: 0.736010 val loss: 0.211723
[Epoch 127] ogbg-moltoxcast: 0.756615 test loss: 0.211826
[Epoch 128; Iter     3/  201] train: loss: 0.1197336
[Epoch 128; Iter    33/  201] train: loss: 0.0991906
[Epoch 128; Iter    63/  201] train: loss: 0.1590675
[Epoch 128; Iter    93/  201] train: loss: 0.1257790
[Epoch 128; Iter   123/  201] train: loss: 0.1119739
[Epoch 128; Iter   153/  201] train: loss: 0.1151709
[Epoch 128; Iter   183/  201] train: loss: 0.1117102
[Epoch 128] ogbg-moltoxcast: 0.737622 val loss: 0.218308
[Epoch 128] ogbg-moltoxcast: 0.758745 test loss: 0.217653
[Epoch 129; Iter    12/  201] train: loss: 0.1385037
[Epoch 129; Iter    42/  201] train: loss: 0.1508368
[Epoch 129; Iter    72/  201] train: loss: 0.1309562
[Epoch 129; Iter   102/  201] train: loss: 0.1079657
[Epoch 129; Iter   132/  201] train: loss: 0.1075243
[Epoch 129; Iter   162/  201] train: loss: 0.1647586
[Epoch 129; Iter   192/  201] train: loss: 0.1547561
[Epoch 129] ogbg-moltoxcast: 0.732164 val loss: 0.211863
[Epoch 129] ogbg-moltoxcast: 0.756471 test loss: 0.211159
[Epoch 130; Iter    21/  201] train: loss: 0.1319229
[Epoch 130; Iter    51/  201] train: loss: 0.0838626
[Epoch 130; Iter    81/  201] train: loss: 0.0841101
[Epoch 130; Iter   111/  201] train: loss: 0.1315207
[Epoch 130; Iter   141/  201] train: loss: 0.1045827
[Epoch 130; Iter   171/  201] train: loss: 0.1182109
[Epoch 130; Iter   201/  201] train: loss: 0.0875822
[Epoch 130] ogbg-moltoxcast: 0.735036 val loss: 0.211888
[Epoch 130] ogbg-moltoxcast: 0.757409 test loss: 0.210995
[Epoch 131; Iter    30/  201] train: loss: 0.1414092
[Epoch 131; Iter    60/  201] train: loss: 0.1050948
[Epoch 131; Iter    90/  201] train: loss: 0.1423317
[Epoch 131; Iter   120/  201] train: loss: 0.1038658
[Epoch 131; Iter   150/  201] train: loss: 0.1186580
[Epoch 131; Iter   180/  201] train: loss: 0.1277109
[Epoch 131] ogbg-moltoxcast: 0.735418 val loss: 0.214936
[Epoch 131] ogbg-moltoxcast: 0.753856 test loss: 0.215542
[Epoch 132; Iter     9/  201] train: loss: 0.1049913
[Epoch 132; Iter    39/  201] train: loss: 0.1420344
[Epoch 132; Iter    69/  201] train: loss: 0.1272846
[Epoch 132; Iter    99/  201] train: loss: 0.1369463
[Epoch 132; Iter   129/  201] train: loss: 0.1620094
[Epoch 132; Iter   159/  201] train: loss: 0.1365223
[Epoch 132; Iter   189/  201] train: loss: 0.0869190
[Epoch 132] ogbg-moltoxcast: 0.734122 val loss: 0.213145
[Epoch 132] ogbg-moltoxcast: 0.754983 test loss: 0.212160
[Epoch 133; Iter    18/  201] train: loss: 0.1448376
[Epoch 133; Iter    48/  201] train: loss: 0.1090176
[Epoch 133; Iter    78/  201] train: loss: 0.1729501
[Epoch 133; Iter   108/  201] train: loss: 0.1337771
[Epoch 133; Iter   138/  201] train: loss: 0.1526877
[Epoch 133; Iter   168/  201] train: loss: 0.1073311
[Epoch 133; Iter   198/  201] train: loss: 0.1368486
[Epoch 133] ogbg-moltoxcast: 0.736084 val loss: 0.212285
[Epoch 133] ogbg-moltoxcast: 0.756385 test loss: 0.211838
[Epoch 134; Iter    27/  201] train: loss: 0.1650391
[Epoch 134; Iter    57/  201] train: loss: 0.1263853
[Epoch 134; Iter    87/  201] train: loss: 0.1489612
[Epoch 134; Iter   117/  201] train: loss: 0.1393594
[Epoch 134; Iter   147/  201] train: loss: 0.1160888
[Epoch 134; Iter   177/  201] train: loss: 0.1125769
[Epoch 134] ogbg-moltoxcast: 0.736203 val loss: 0.211307
[Epoch 134] ogbg-moltoxcast: 0.754990 test loss: 0.211335
[Epoch 135; Iter     6/  201] train: loss: 0.1311967
[Epoch 135; Iter    36/  201] train: loss: 0.1138521
[Epoch 135; Iter    66/  201] train: loss: 0.1265347
[Epoch 135; Iter    96/  201] train: loss: 0.0861837
[Epoch 135; Iter   126/  201] train: loss: 0.1429217
[Epoch 135; Iter   156/  201] train: loss: 0.1217500
[Epoch 135; Iter   186/  201] train: loss: 0.1320476
[Epoch 135] ogbg-moltoxcast: 0.731208 val loss: 0.215140
[Epoch 135] ogbg-moltoxcast: 0.752738 test loss: 0.214093
[Epoch 136; Iter    15/  201] train: loss: 0.1359120
[Epoch 136; Iter    45/  201] train: loss: 0.0839091
[Epoch 136; Iter    75/  201] train: loss: 0.1297085
[Epoch 136; Iter   105/  201] train: loss: 0.1715955
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 136; Iter   135/  201] train: loss: 0.1319012
[Epoch 136; Iter   165/  201] train: loss: 0.1424282
[Epoch 136; Iter   195/  201] train: loss: 0.1132337
[Epoch 136] ogbg-moltoxcast: 0.736201 val loss: 0.213437
[Epoch 136] ogbg-moltoxcast: 0.755440 test loss: 0.212666
[Epoch 137; Iter    24/  201] train: loss: 0.1237708
[Epoch 137; Iter    54/  201] train: loss: 0.1278477
[Epoch 137; Iter    84/  201] train: loss: 0.1133572
[Epoch 137; Iter   114/  201] train: loss: 0.1399101
[Epoch 137; Iter   144/  201] train: loss: 0.1154220
[Epoch 137; Iter   174/  201] train: loss: 0.1385493
[Epoch 137] ogbg-moltoxcast: 0.732149 val loss: 0.213427
[Epoch 137] ogbg-moltoxcast: 0.753462 test loss: 0.213339
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 137 epochs. Best model checkpoint was in epoch 77.
Statistics on  val_best_checkpoint
mean_pred: -3.290405035018921
std_pred: 2.6442930698394775
mean_targets: nan
std_targets: nan
prcauc: 0.43042652631918243
rocauc: 0.7430883011587284
ogbg-moltoxcast: 0.7430883011587284
OGBNanLabelBCEWithLogitsLoss: 0.20465278348257376
Statistics on  test
mean_pred: -3.3000595569610596
std_pred: 2.6585726737976074
mean_targets: nan
std_targets: nan
prcauc: 0.4354334527744196
rocauc: 0.7552167223782601
ogbg-moltoxcast: 0.7552167223782601
OGBNanLabelBCEWithLogitsLoss: 0.20531013157478598
Statistics on  train
mean_pred: -3.340742588043213
std_pred: 2.7138452529907227
mean_targets: nan
std_targets: nan
prcauc: 0.6199768499566319
rocauc: 0.899587429554113
ogbg-moltoxcast: 0.899587429554113
OGBNanLabelBCEWithLogitsLoss: 0.1348311076802549
All runs completed.
[Epoch 123; Iter   172/  229] train: loss: 0.1236997
[Epoch 123; Iter   202/  229] train: loss: 0.1312455
[Epoch 123] ogbg-moltoxcast: 0.741810 val loss: 0.201873
[Epoch 123] ogbg-moltoxcast: 0.750650 test loss: 0.218855
[Epoch 124; Iter     3/  229] train: loss: 0.1856297
[Epoch 124; Iter    33/  229] train: loss: 0.0934316
[Epoch 124; Iter    63/  229] train: loss: 0.1002549
[Epoch 124; Iter    93/  229] train: loss: 0.1382491
[Epoch 124; Iter   123/  229] train: loss: 0.1136892
[Epoch 124; Iter   153/  229] train: loss: 0.0830638
[Epoch 124; Iter   183/  229] train: loss: 0.1253370
[Epoch 124; Iter   213/  229] train: loss: 0.1042892
[Epoch 124] ogbg-moltoxcast: 0.739472 val loss: 0.202247
[Epoch 124] ogbg-moltoxcast: 0.747165 test loss: 0.219528
[Epoch 125; Iter    14/  229] train: loss: 0.1028314
[Epoch 125; Iter    44/  229] train: loss: 0.1271537
[Epoch 125; Iter    74/  229] train: loss: 0.1474891
[Epoch 125; Iter   104/  229] train: loss: 0.1263366
[Epoch 125; Iter   134/  229] train: loss: 0.1377501
[Epoch 125; Iter   164/  229] train: loss: 0.1458191
[Epoch 125; Iter   194/  229] train: loss: 0.1388835
[Epoch 125; Iter   224/  229] train: loss: 0.1422496
[Epoch 125] ogbg-moltoxcast: 0.739090 val loss: 0.203485
[Epoch 125] ogbg-moltoxcast: 0.747544 test loss: 0.219941
[Epoch 126; Iter    25/  229] train: loss: 0.1052688
[Epoch 126; Iter    55/  229] train: loss: 0.1270116
[Epoch 126; Iter    85/  229] train: loss: 0.1310558
[Epoch 126; Iter   115/  229] train: loss: 0.1431927
[Epoch 126; Iter   145/  229] train: loss: 0.1147414
[Epoch 126; Iter   175/  229] train: loss: 0.1102530
[Epoch 126; Iter   205/  229] train: loss: 0.1274850
[Epoch 126] ogbg-moltoxcast: 0.740544 val loss: 0.201137
[Epoch 126] ogbg-moltoxcast: 0.748235 test loss: 0.220755
[Epoch 127; Iter     6/  229] train: loss: 0.1100897
[Epoch 127; Iter    36/  229] train: loss: 0.1696965
[Epoch 127; Iter    66/  229] train: loss: 0.1115470
[Epoch 127; Iter    96/  229] train: loss: 0.0985714
[Epoch 127; Iter   126/  229] train: loss: 0.1109329
[Epoch 127; Iter   156/  229] train: loss: 0.1393936
[Epoch 127; Iter   186/  229] train: loss: 0.1307080
[Epoch 127; Iter   216/  229] train: loss: 0.1147980
[Epoch 127] ogbg-moltoxcast: 0.740236 val loss: 0.201590
[Epoch 127] ogbg-moltoxcast: 0.750356 test loss: 0.220781
[Epoch 128; Iter    17/  229] train: loss: 0.1305754
[Epoch 128; Iter    47/  229] train: loss: 0.1547344
[Epoch 128; Iter    77/  229] train: loss: 0.1113809
[Epoch 128; Iter   107/  229] train: loss: 0.1305719
[Epoch 128; Iter   137/  229] train: loss: 0.1216059
[Epoch 128; Iter   167/  229] train: loss: 0.1238308
[Epoch 128; Iter   197/  229] train: loss: 0.1068934
[Epoch 128; Iter   227/  229] train: loss: 0.1200875
[Epoch 128] ogbg-moltoxcast: 0.741079 val loss: 0.203005
[Epoch 128] ogbg-moltoxcast: 0.747305 test loss: 0.221216
[Epoch 129; Iter    28/  229] train: loss: 0.0833533
[Epoch 129; Iter    58/  229] train: loss: 0.0953683
[Epoch 129; Iter    88/  229] train: loss: 0.1054455
[Epoch 129; Iter   118/  229] train: loss: 0.1130012
[Epoch 129; Iter   148/  229] train: loss: 0.1316461
[Epoch 129; Iter   178/  229] train: loss: 0.1353638
[Epoch 129; Iter   208/  229] train: loss: 0.1031458
[Epoch 129] ogbg-moltoxcast: 0.740336 val loss: 0.202126
[Epoch 129] ogbg-moltoxcast: 0.746984 test loss: 0.221601
[Epoch 130; Iter     9/  229] train: loss: 0.1065420
[Epoch 130; Iter    39/  229] train: loss: 0.1422141
[Epoch 130; Iter    69/  229] train: loss: 0.1244115
[Epoch 130; Iter    99/  229] train: loss: 0.0917613
[Epoch 130; Iter   129/  229] train: loss: 0.1612113
[Epoch 130; Iter   159/  229] train: loss: 0.1353740
[Epoch 130; Iter   189/  229] train: loss: 0.1224473
[Epoch 130; Iter   219/  229] train: loss: 0.1544998
[Epoch 130] ogbg-moltoxcast: 0.738793 val loss: 0.205332
[Epoch 130] ogbg-moltoxcast: 0.745905 test loss: 0.222495
[Epoch 131; Iter    20/  229] train: loss: 0.1788969
[Epoch 131; Iter    50/  229] train: loss: 0.1772386
[Epoch 131; Iter    80/  229] train: loss: 0.1149413
[Epoch 131; Iter   110/  229] train: loss: 0.1045476
[Epoch 131; Iter   140/  229] train: loss: 0.1030874
[Epoch 131; Iter   170/  229] train: loss: 0.1488659
[Epoch 131; Iter   200/  229] train: loss: 0.1439223
[Epoch 131] ogbg-moltoxcast: 0.738673 val loss: 0.202462
[Epoch 131] ogbg-moltoxcast: 0.747901 test loss: 0.220810
[Epoch 132; Iter     1/  229] train: loss: 0.1003504
[Epoch 132; Iter    31/  229] train: loss: 0.1239169
[Epoch 132; Iter    61/  229] train: loss: 0.1111467
[Epoch 132; Iter    91/  229] train: loss: 0.1323111
[Epoch 132; Iter   121/  229] train: loss: 0.0911092
[Epoch 132; Iter   151/  229] train: loss: 0.0964411
[Epoch 132; Iter   181/  229] train: loss: 0.1696965
[Epoch 132; Iter   211/  229] train: loss: 0.1018326
[Epoch 132] ogbg-moltoxcast: 0.742609 val loss: 0.199201
[Epoch 132] ogbg-moltoxcast: 0.749849 test loss: 0.220849
[Epoch 133; Iter    12/  229] train: loss: 0.1511595
[Epoch 133; Iter    42/  229] train: loss: 0.0871828
[Epoch 133; Iter    72/  229] train: loss: 0.1257244
[Epoch 133; Iter   102/  229] train: loss: 0.1652321
[Epoch 133; Iter   132/  229] train: loss: 0.1805903
[Epoch 133; Iter   162/  229] train: loss: 0.1078910
[Epoch 133; Iter   192/  229] train: loss: 0.0972972
[Epoch 133; Iter   222/  229] train: loss: 0.1102269
[Epoch 133] ogbg-moltoxcast: 0.737985 val loss: 0.205473
[Epoch 133] ogbg-moltoxcast: 0.748254 test loss: 0.222235
[Epoch 134; Iter    23/  229] train: loss: 0.1473224
[Epoch 134; Iter    53/  229] train: loss: 0.1802579
[Epoch 134; Iter    83/  229] train: loss: 0.1443745
[Epoch 134; Iter   113/  229] train: loss: 0.1051470
[Epoch 134; Iter   143/  229] train: loss: 0.1618343
[Epoch 134; Iter   173/  229] train: loss: 0.1457326
[Epoch 134; Iter   203/  229] train: loss: 0.1271832
[Epoch 134] ogbg-moltoxcast: 0.741608 val loss: 0.201953
[Epoch 134] ogbg-moltoxcast: 0.751803 test loss: 0.220128
[Epoch 135; Iter     4/  229] train: loss: 0.1449583
[Epoch 135; Iter    34/  229] train: loss: 0.1060390
[Epoch 135; Iter    64/  229] train: loss: 0.1545718
[Epoch 135; Iter    94/  229] train: loss: 0.1511312
[Epoch 135; Iter   124/  229] train: loss: 0.1257134
[Epoch 135; Iter   154/  229] train: loss: 0.1002487
[Epoch 135; Iter   184/  229] train: loss: 0.1344079
[Epoch 135; Iter   214/  229] train: loss: 0.1758126
[Epoch 135] ogbg-moltoxcast: 0.741004 val loss: 0.201799
[Epoch 135] ogbg-moltoxcast: 0.748382 test loss: 0.221394
[Epoch 136; Iter    15/  229] train: loss: 0.1417537
[Epoch 136; Iter    45/  229] train: loss: 0.1562108
[Epoch 136; Iter    75/  229] train: loss: 0.1350328
[Epoch 136; Iter   105/  229] train: loss: 0.1190741
[Epoch 136; Iter   135/  229] train: loss: 0.1614043
[Epoch 136; Iter   165/  229] train: loss: 0.1185129
[Epoch 136; Iter   195/  229] train: loss: 0.1717133
[Epoch 136; Iter   225/  229] train: loss: 0.1005337
[Epoch 136] ogbg-moltoxcast: 0.738689 val loss: 0.204342
[Epoch 136] ogbg-moltoxcast: 0.745703 test loss: 0.222798
[Epoch 137; Iter    26/  229] train: loss: 0.1551054
[Epoch 137; Iter    56/  229] train: loss: 0.0908598
[Epoch 137; Iter    86/  229] train: loss: 0.1000185
[Epoch 137; Iter   116/  229] train: loss: 0.1106719
[Epoch 137; Iter   146/  229] train: loss: 0.1582588
[Epoch 137; Iter   176/  229] train: loss: 0.0845887
[Epoch 137; Iter   206/  229] train: loss: 0.1457023
[Epoch 137] ogbg-moltoxcast: 0.740930 val loss: 0.202006
[Epoch 137] ogbg-moltoxcast: 0.747483 test loss: 0.221067
[Epoch 138; Iter     7/  229] train: loss: 0.1555504
[Epoch 138; Iter    37/  229] train: loss: 0.1908505
[Epoch 138; Iter    67/  229] train: loss: 0.1311998
[Epoch 138; Iter    97/  229] train: loss: 0.1013159
[Epoch 138; Iter   127/  229] train: loss: 0.1169654
[Epoch 138; Iter   157/  229] train: loss: 0.2332061
[Epoch 138; Iter   187/  229] train: loss: 0.1059733
[Epoch 138; Iter   217/  229] train: loss: 0.1376524
[Epoch 138] ogbg-moltoxcast: 0.740049 val loss: 0.203416
[Epoch 138] ogbg-moltoxcast: 0.749084 test loss: 0.222891
[Epoch 139; Iter    18/  229] train: loss: 0.1423489
[Epoch 139; Iter    48/  229] train: loss: 0.1570710
[Epoch 123; Iter   172/  229] train: loss: 0.1166822
[Epoch 123; Iter   202/  229] train: loss: 0.1326469
[Epoch 123] ogbg-moltoxcast: 0.760056 val loss: 0.200964
[Epoch 123] ogbg-moltoxcast: 0.758093 test loss: 0.212983
[Epoch 124; Iter     3/  229] train: loss: 0.1802787
[Epoch 124; Iter    33/  229] train: loss: 0.1631133
[Epoch 124; Iter    63/  229] train: loss: 0.1407463
[Epoch 124; Iter    93/  229] train: loss: 0.1961188
[Epoch 124; Iter   123/  229] train: loss: 0.1530228
[Epoch 124; Iter   153/  229] train: loss: 0.1313193
[Epoch 124; Iter   183/  229] train: loss: 0.1075715
[Epoch 124; Iter   213/  229] train: loss: 0.1167702
[Epoch 124] ogbg-moltoxcast: 0.758608 val loss: 0.204396
[Epoch 124] ogbg-moltoxcast: 0.762184 test loss: 0.211845
[Epoch 125; Iter    14/  229] train: loss: 0.1061895
[Epoch 125; Iter    44/  229] train: loss: 0.1288043
[Epoch 125; Iter    74/  229] train: loss: 0.1161022
[Epoch 125; Iter   104/  229] train: loss: 0.1280755
[Epoch 125; Iter   134/  229] train: loss: 0.1461056
[Epoch 125; Iter   164/  229] train: loss: 0.1225837
[Epoch 125; Iter   194/  229] train: loss: 0.1446282
[Epoch 125; Iter   224/  229] train: loss: 0.1270472
[Epoch 125] ogbg-moltoxcast: 0.760625 val loss: 0.201355
[Epoch 125] ogbg-moltoxcast: 0.763505 test loss: 0.213299
[Epoch 126; Iter    25/  229] train: loss: 0.1028510
[Epoch 126; Iter    55/  229] train: loss: 0.1301672
[Epoch 126; Iter    85/  229] train: loss: 0.1343651
[Epoch 126; Iter   115/  229] train: loss: 0.1473214
[Epoch 126; Iter   145/  229] train: loss: 0.1447599
[Epoch 126; Iter   175/  229] train: loss: 0.1362882
[Epoch 126; Iter   205/  229] train: loss: 0.1170388
[Epoch 126] ogbg-moltoxcast: 0.758620 val loss: 0.201301
[Epoch 126] ogbg-moltoxcast: 0.760255 test loss: 0.212214
[Epoch 127; Iter     6/  229] train: loss: 0.1163658
[Epoch 127; Iter    36/  229] train: loss: 0.1512640
[Epoch 127; Iter    66/  229] train: loss: 0.2125740
[Epoch 127; Iter    96/  229] train: loss: 0.1211878
[Epoch 127; Iter   126/  229] train: loss: 0.1030668
[Epoch 127; Iter   156/  229] train: loss: 0.1584990
[Epoch 127; Iter   186/  229] train: loss: 0.1115062
[Epoch 127; Iter   216/  229] train: loss: 0.0910808
[Epoch 127] ogbg-moltoxcast: 0.761552 val loss: 0.200833
[Epoch 127] ogbg-moltoxcast: 0.761282 test loss: 0.213034
[Epoch 128; Iter    17/  229] train: loss: 0.1156874
[Epoch 128; Iter    47/  229] train: loss: 0.1205302
[Epoch 128; Iter    77/  229] train: loss: 0.1362280
[Epoch 128; Iter   107/  229] train: loss: 0.1088883
[Epoch 128; Iter   137/  229] train: loss: 0.1865750
[Epoch 128; Iter   167/  229] train: loss: 0.1667742
[Epoch 128; Iter   197/  229] train: loss: 0.1222190
[Epoch 128; Iter   227/  229] train: loss: 0.1171228
[Epoch 128] ogbg-moltoxcast: 0.760944 val loss: 0.201129
[Epoch 128] ogbg-moltoxcast: 0.761534 test loss: 0.215479
[Epoch 129; Iter    28/  229] train: loss: 0.1384211
[Epoch 129; Iter    58/  229] train: loss: 0.1195538
[Epoch 129; Iter    88/  229] train: loss: 0.1472211
[Epoch 129; Iter   118/  229] train: loss: 0.1150395
[Epoch 129; Iter   148/  229] train: loss: 0.1745775
[Epoch 129; Iter   178/  229] train: loss: 0.1160553
[Epoch 129; Iter   208/  229] train: loss: 0.1383170
[Epoch 129] ogbg-moltoxcast: 0.761989 val loss: 0.199929
[Epoch 129] ogbg-moltoxcast: 0.761098 test loss: 0.212678
[Epoch 130; Iter     9/  229] train: loss: 0.1022977
[Epoch 130; Iter    39/  229] train: loss: 0.1129994
[Epoch 130; Iter    69/  229] train: loss: 0.1360785
[Epoch 130; Iter    99/  229] train: loss: 0.1016173
[Epoch 130; Iter   129/  229] train: loss: 0.1233091
[Epoch 130; Iter   159/  229] train: loss: 0.0962446
[Epoch 130; Iter   189/  229] train: loss: 0.1131328
[Epoch 130; Iter   219/  229] train: loss: 0.0910760
[Epoch 130] ogbg-moltoxcast: 0.761695 val loss: 0.201209
[Epoch 130] ogbg-moltoxcast: 0.761030 test loss: 0.212554
[Epoch 131; Iter    20/  229] train: loss: 0.1225321
[Epoch 131; Iter    50/  229] train: loss: 0.1227795
[Epoch 131; Iter    80/  229] train: loss: 0.1361016
[Epoch 131; Iter   110/  229] train: loss: 0.1717535
[Epoch 131; Iter   140/  229] train: loss: 0.1844907
[Epoch 131; Iter   170/  229] train: loss: 0.1557050
[Epoch 131; Iter   200/  229] train: loss: 0.1272712
[Epoch 131] ogbg-moltoxcast: 0.759483 val loss: 0.202327
[Epoch 131] ogbg-moltoxcast: 0.763763 test loss: 0.211033
[Epoch 132; Iter     1/  229] train: loss: 0.0900930
[Epoch 132; Iter    31/  229] train: loss: 0.1216601
[Epoch 132; Iter    61/  229] train: loss: 0.1354133
[Epoch 132; Iter    91/  229] train: loss: 0.1040659
[Epoch 132; Iter   121/  229] train: loss: 0.1043365
[Epoch 132; Iter   151/  229] train: loss: 0.0954346
[Epoch 132; Iter   181/  229] train: loss: 0.1559185
[Epoch 132; Iter   211/  229] train: loss: 0.1042104
[Epoch 132] ogbg-moltoxcast: 0.757987 val loss: 0.202618
[Epoch 132] ogbg-moltoxcast: 0.760074 test loss: 0.214502
[Epoch 133; Iter    12/  229] train: loss: 0.1975464
[Epoch 133; Iter    42/  229] train: loss: 0.1524184
[Epoch 133; Iter    72/  229] train: loss: 0.1201320
[Epoch 133; Iter   102/  229] train: loss: 0.0898017
[Epoch 133; Iter   132/  229] train: loss: 0.1464920
[Epoch 133; Iter   162/  229] train: loss: 0.1105874
[Epoch 133; Iter   192/  229] train: loss: 0.1924511
[Epoch 133; Iter   222/  229] train: loss: 0.1260322
[Epoch 133] ogbg-moltoxcast: 0.760108 val loss: 0.202448
[Epoch 133] ogbg-moltoxcast: 0.762438 test loss: 0.213244
[Epoch 134; Iter    23/  229] train: loss: 0.1232737
[Epoch 134; Iter    53/  229] train: loss: 0.0899955
[Epoch 134; Iter    83/  229] train: loss: 0.1934376
[Epoch 134; Iter   113/  229] train: loss: 0.1382616
[Epoch 134; Iter   143/  229] train: loss: 0.1395559
[Epoch 134; Iter   173/  229] train: loss: 0.1030409
[Epoch 134; Iter   203/  229] train: loss: 0.1639712
[Epoch 134] ogbg-moltoxcast: 0.759346 val loss: 0.201884
[Epoch 134] ogbg-moltoxcast: 0.764513 test loss: 0.210379
[Epoch 135; Iter     4/  229] train: loss: 0.1019636
[Epoch 135; Iter    34/  229] train: loss: 0.1809271
[Epoch 135; Iter    64/  229] train: loss: 0.1393923
[Epoch 135; Iter    94/  229] train: loss: 0.1406819
[Epoch 135; Iter   124/  229] train: loss: 0.0862296
[Epoch 135; Iter   154/  229] train: loss: 0.1342732
[Epoch 135; Iter   184/  229] train: loss: 0.1237675
[Epoch 135; Iter   214/  229] train: loss: 0.1607405
[Epoch 135] ogbg-moltoxcast: 0.759416 val loss: 0.203538
[Epoch 135] ogbg-moltoxcast: 0.761267 test loss: 0.211728
[Epoch 136; Iter    15/  229] train: loss: 0.0909643
[Epoch 136; Iter    45/  229] train: loss: 0.1760895
[Epoch 136; Iter    75/  229] train: loss: 0.1209797
[Epoch 136; Iter   105/  229] train: loss: 0.1365164
[Epoch 136; Iter   135/  229] train: loss: 0.0746769
[Epoch 136; Iter   165/  229] train: loss: 0.1516391
[Epoch 136; Iter   195/  229] train: loss: 0.1548056
[Epoch 136; Iter   225/  229] train: loss: 0.1542128
[Epoch 136] ogbg-moltoxcast: 0.763551 val loss: 0.200568
[Epoch 136] ogbg-moltoxcast: 0.763086 test loss: 0.213530
[Epoch 137; Iter    26/  229] train: loss: 0.1566147
[Epoch 137; Iter    56/  229] train: loss: 0.1556026
[Epoch 137; Iter    86/  229] train: loss: 0.1548642
[Epoch 137; Iter   116/  229] train: loss: 0.1487202
[Epoch 137; Iter   146/  229] train: loss: 0.1231248
[Epoch 137; Iter   176/  229] train: loss: 0.1114661
[Epoch 137; Iter   206/  229] train: loss: 0.0880985
[Epoch 137] ogbg-moltoxcast: 0.762214 val loss: 0.199967
[Epoch 137] ogbg-moltoxcast: 0.758807 test loss: 0.213557
[Epoch 138; Iter     7/  229] train: loss: 0.1544924
[Epoch 138; Iter    37/  229] train: loss: 0.1024363
[Epoch 138; Iter    67/  229] train: loss: 0.1850279
[Epoch 138; Iter    97/  229] train: loss: 0.1333381
[Epoch 138; Iter   127/  229] train: loss: 0.0960044
[Epoch 138; Iter   157/  229] train: loss: 0.1404859
[Epoch 138; Iter   187/  229] train: loss: 0.1845792
[Epoch 138; Iter   217/  229] train: loss: 0.1080819
[Epoch 138] ogbg-moltoxcast: 0.762081 val loss: 0.200468
[Epoch 138] ogbg-moltoxcast: 0.760620 test loss: 0.212785
[Epoch 139; Iter    18/  229] train: loss: 0.1795594
[Epoch 139; Iter    48/  229] train: loss: 0.1390445
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 139; Iter    78/  229] train: loss: 0.2067007
[Epoch 139; Iter   108/  229] train: loss: 0.1660697
[Epoch 139; Iter   138/  229] train: loss: 0.1813161
[Epoch 139; Iter   168/  229] train: loss: 0.0979516
[Epoch 139; Iter   198/  229] train: loss: 0.1933730
[Epoch 139; Iter   228/  229] train: loss: 0.1313782
[Epoch 139] ogbg-moltoxcast: 0.741512 val loss: 0.202368
[Epoch 139] ogbg-moltoxcast: 0.747428 test loss: 0.224602
[Epoch 140; Iter    29/  229] train: loss: 0.1315501
[Epoch 140; Iter    59/  229] train: loss: 0.1649463
[Epoch 140; Iter    89/  229] train: loss: 0.1079142
[Epoch 140; Iter   119/  229] train: loss: 0.0791615
[Epoch 140; Iter   149/  229] train: loss: 0.1488079
[Epoch 140; Iter   179/  229] train: loss: 0.0869043
[Epoch 140; Iter   209/  229] train: loss: 0.1456996
[Epoch 140] ogbg-moltoxcast: 0.741245 val loss: 0.202274
[Epoch 140] ogbg-moltoxcast: 0.748815 test loss: 0.221937
[Epoch 141; Iter    10/  229] train: loss: 0.0992042
[Epoch 141; Iter    40/  229] train: loss: 0.1623982
[Epoch 141; Iter    70/  229] train: loss: 0.1125200
[Epoch 141; Iter   100/  229] train: loss: 0.1513894
[Epoch 141; Iter   130/  229] train: loss: 0.0988446
[Epoch 141; Iter   160/  229] train: loss: 0.1192895
[Epoch 141; Iter   190/  229] train: loss: 0.1532403
[Epoch 141; Iter   220/  229] train: loss: 0.1479962
[Epoch 141] ogbg-moltoxcast: 0.740527 val loss: 0.204181
[Epoch 141] ogbg-moltoxcast: 0.747289 test loss: 0.224694
[Epoch 142; Iter    21/  229] train: loss: 0.0938514
[Epoch 142; Iter    51/  229] train: loss: 0.1218846
[Epoch 142; Iter    81/  229] train: loss: 0.1412654
[Epoch 142; Iter   111/  229] train: loss: 0.1050507
[Epoch 142; Iter   141/  229] train: loss: 0.1512373
[Epoch 142; Iter   171/  229] train: loss: 0.1182571
[Epoch 142; Iter   201/  229] train: loss: 0.1096496
[Epoch 142] ogbg-moltoxcast: 0.740494 val loss: 0.203378
[Epoch 142] ogbg-moltoxcast: 0.751227 test loss: 0.223829
[Epoch 143; Iter     2/  229] train: loss: 0.1223554
[Epoch 143; Iter    32/  229] train: loss: 0.1104424
[Epoch 143; Iter    62/  229] train: loss: 0.0866815
[Epoch 143; Iter    92/  229] train: loss: 0.1077573
[Epoch 143; Iter   122/  229] train: loss: 0.0840090
[Epoch 143; Iter   152/  229] train: loss: 0.1000018
[Epoch 143; Iter   182/  229] train: loss: 0.1625241
[Epoch 143; Iter   212/  229] train: loss: 0.0775986
[Epoch 143] ogbg-moltoxcast: 0.739734 val loss: 0.202932
[Epoch 143] ogbg-moltoxcast: 0.748071 test loss: 0.221562
[Epoch 144; Iter    13/  229] train: loss: 0.1489449
[Epoch 144; Iter    43/  229] train: loss: 0.1351072
[Epoch 144; Iter    73/  229] train: loss: 0.1684225
[Epoch 144; Iter   103/  229] train: loss: 0.1386928
[Epoch 144; Iter   133/  229] train: loss: 0.1810036
[Epoch 144; Iter   163/  229] train: loss: 0.1464611
[Epoch 144; Iter   193/  229] train: loss: 0.1315793
[Epoch 144; Iter   223/  229] train: loss: 0.0994134
[Epoch 144] ogbg-moltoxcast: 0.740966 val loss: 0.201884
[Epoch 144] ogbg-moltoxcast: 0.748412 test loss: 0.221689
[Epoch 145; Iter    24/  229] train: loss: 0.1269137
[Epoch 145; Iter    54/  229] train: loss: 0.1010163
[Epoch 145; Iter    84/  229] train: loss: 0.1032630
[Epoch 145; Iter   114/  229] train: loss: 0.1016729
[Epoch 145; Iter   144/  229] train: loss: 0.1332472
[Epoch 145; Iter   174/  229] train: loss: 0.1665174
[Epoch 145; Iter   204/  229] train: loss: 0.1057989
[Epoch 145] ogbg-moltoxcast: 0.740058 val loss: 0.203325
[Epoch 145] ogbg-moltoxcast: 0.748871 test loss: 0.224108
[Epoch 146; Iter     5/  229] train: loss: 0.1191408
[Epoch 146; Iter    35/  229] train: loss: 0.1443407
[Epoch 146; Iter    65/  229] train: loss: 0.1949752
[Epoch 146; Iter    95/  229] train: loss: 0.1312161
[Epoch 146; Iter   125/  229] train: loss: 0.1539323
[Epoch 146; Iter   155/  229] train: loss: 0.1314418
[Epoch 146; Iter   185/  229] train: loss: 0.1475903
[Epoch 146; Iter   215/  229] train: loss: 0.1144107
[Epoch 146] ogbg-moltoxcast: 0.739009 val loss: 0.204224
[Epoch 146] ogbg-moltoxcast: 0.749595 test loss: 0.222110
[Epoch 147; Iter    16/  229] train: loss: 0.1352322
[Epoch 147; Iter    46/  229] train: loss: 0.1665785
[Epoch 147; Iter    76/  229] train: loss: 0.1283240
[Epoch 147; Iter   106/  229] train: loss: 0.1390334
[Epoch 147; Iter   136/  229] train: loss: 0.1402860
[Epoch 147; Iter   166/  229] train: loss: 0.1273464
[Epoch 147; Iter   196/  229] train: loss: 0.0685446
[Epoch 147; Iter   226/  229] train: loss: 0.1607278
[Epoch 147] ogbg-moltoxcast: 0.740768 val loss: 0.203140
[Epoch 147] ogbg-moltoxcast: 0.747406 test loss: 0.225046
[Epoch 148; Iter    27/  229] train: loss: 0.0964799
[Epoch 148; Iter    57/  229] train: loss: 0.1529222
[Epoch 148; Iter    87/  229] train: loss: 0.1397810
[Epoch 148; Iter   117/  229] train: loss: 0.1320129
[Epoch 148; Iter   147/  229] train: loss: 0.1705499
[Epoch 148; Iter   177/  229] train: loss: 0.1681378
[Epoch 148; Iter   207/  229] train: loss: 0.1378200
[Epoch 148] ogbg-moltoxcast: 0.741373 val loss: 0.202165
[Epoch 148] ogbg-moltoxcast: 0.748940 test loss: 0.223795
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 148 epochs. Best model checkpoint was in epoch 88.
Statistics on  val_best_checkpoint
mean_pred: -3.4785354137420654
std_pred: 2.771526336669922
mean_targets: nan
std_targets: nan
prcauc: 0.4394467970207956
rocauc: 0.7472134894512598
ogbg-moltoxcast: 0.7472134894512598
OGBNanLabelBCEWithLogitsLoss: 0.1956948465828238
Statistics on  test
mean_pred: -3.503873348236084
std_pred: 2.8153703212738037
mean_targets: nan
std_targets: nan
prcauc: 0.45040763217112545
rocauc: 0.7544564385633447
ogbg-moltoxcast: 0.7544564385633447
OGBNanLabelBCEWithLogitsLoss: 0.21450227704541436
Statistics on  train
mean_pred: -3.528459072113037
std_pred: 2.8851006031036377
mean_targets: nan
std_targets: nan
prcauc: 0.6309936024409563
rocauc: 0.9033112472219506
ogbg-moltoxcast: 0.9033112472219506
OGBNanLabelBCEWithLogitsLoss: 0.13253076895095375
[Epoch 139; Iter    78/  229] train: loss: 0.1038143
[Epoch 139; Iter   108/  229] train: loss: 0.1457851
[Epoch 139; Iter   138/  229] train: loss: 0.1479639
[Epoch 139; Iter   168/  229] train: loss: 0.1099715
[Epoch 139; Iter   198/  229] train: loss: 0.1116674
[Epoch 139; Iter   228/  229] train: loss: 0.1344272
[Epoch 139] ogbg-moltoxcast: 0.759809 val loss: 0.201744
[Epoch 139] ogbg-moltoxcast: 0.759247 test loss: 0.211902
[Epoch 140; Iter    29/  229] train: loss: 0.1202944
[Epoch 140; Iter    59/  229] train: loss: 0.1357211
[Epoch 140; Iter    89/  229] train: loss: 0.0947852
[Epoch 140; Iter   119/  229] train: loss: 0.1247751
[Epoch 140; Iter   149/  229] train: loss: 0.0931499
[Epoch 140; Iter   179/  229] train: loss: 0.1474266
[Epoch 140; Iter   209/  229] train: loss: 0.0983573
[Epoch 140] ogbg-moltoxcast: 0.758295 val loss: 0.201509
[Epoch 140] ogbg-moltoxcast: 0.758449 test loss: 0.214990
[Epoch 141; Iter    10/  229] train: loss: 0.1132450
[Epoch 141; Iter    40/  229] train: loss: 0.1469550
[Epoch 141; Iter    70/  229] train: loss: 0.1609155
[Epoch 141; Iter   100/  229] train: loss: 0.1671124
[Epoch 141; Iter   130/  229] train: loss: 0.1217591
[Epoch 141; Iter   160/  229] train: loss: 0.1767399
[Epoch 141; Iter   190/  229] train: loss: 0.1571548
[Epoch 141; Iter   220/  229] train: loss: 0.1419015
[Epoch 141] ogbg-moltoxcast: 0.762128 val loss: 0.200607
[Epoch 141] ogbg-moltoxcast: 0.758856 test loss: 0.216311
[Epoch 142; Iter    21/  229] train: loss: 0.1426459
[Epoch 142; Iter    51/  229] train: loss: 0.1767011
[Epoch 142; Iter    81/  229] train: loss: 0.0949232
[Epoch 142; Iter   111/  229] train: loss: 0.0968971
[Epoch 142; Iter   141/  229] train: loss: 0.1404764
[Epoch 142; Iter   171/  229] train: loss: 0.1329159
[Epoch 142; Iter   201/  229] train: loss: 0.1535396
[Epoch 142] ogbg-moltoxcast: 0.760548 val loss: 0.200023
[Epoch 142] ogbg-moltoxcast: 0.758459 test loss: 0.214100
[Epoch 143; Iter     2/  229] train: loss: 0.1643645
[Epoch 143; Iter    32/  229] train: loss: 0.1318529
[Epoch 143; Iter    62/  229] train: loss: 0.1329751
[Epoch 143; Iter    92/  229] train: loss: 0.0698039
[Epoch 143; Iter   122/  229] train: loss: 0.1398019
[Epoch 143; Iter   152/  229] train: loss: 0.0879565
[Epoch 143; Iter   182/  229] train: loss: 0.1685303
[Epoch 143; Iter   212/  229] train: loss: 0.1288789
[Epoch 143] ogbg-moltoxcast: 0.760622 val loss: 0.202365
[Epoch 143] ogbg-moltoxcast: 0.760496 test loss: 0.213262
[Epoch 144; Iter    13/  229] train: loss: 0.2093139
[Epoch 144; Iter    43/  229] train: loss: 0.0839997
[Epoch 144; Iter    73/  229] train: loss: 0.1193614
[Epoch 144; Iter   103/  229] train: loss: 0.1616275
[Epoch 144; Iter   133/  229] train: loss: 0.1399770
[Epoch 144; Iter   163/  229] train: loss: 0.1749618
[Epoch 144; Iter   193/  229] train: loss: 0.1630804
[Epoch 144; Iter   223/  229] train: loss: 0.1231443
[Epoch 144] ogbg-moltoxcast: 0.760583 val loss: 0.201546
[Epoch 144] ogbg-moltoxcast: 0.761210 test loss: 0.212882
[Epoch 145; Iter    24/  229] train: loss: 0.1581979
[Epoch 145; Iter    54/  229] train: loss: 0.1781734
[Epoch 145; Iter    84/  229] train: loss: 0.1234991
[Epoch 145; Iter   114/  229] train: loss: 0.1441331
[Epoch 145; Iter   144/  229] train: loss: 0.0908952
[Epoch 145; Iter   174/  229] train: loss: 0.0992793
[Epoch 145; Iter   204/  229] train: loss: 0.0984397
[Epoch 145] ogbg-moltoxcast: 0.762273 val loss: 0.200722
[Epoch 145] ogbg-moltoxcast: 0.759282 test loss: 0.214575
[Epoch 146; Iter     5/  229] train: loss: 0.1391454
[Epoch 146; Iter    35/  229] train: loss: 0.1221765
[Epoch 146; Iter    65/  229] train: loss: 0.0984533
[Epoch 146; Iter    95/  229] train: loss: 0.1399764
[Epoch 146; Iter   125/  229] train: loss: 0.1059704
[Epoch 146; Iter   155/  229] train: loss: 0.1289204
[Epoch 146; Iter   185/  229] train: loss: 0.1865090
[Epoch 146; Iter   215/  229] train: loss: 0.1273902
[Epoch 146] ogbg-moltoxcast: 0.762521 val loss: 0.202807
[Epoch 146] ogbg-moltoxcast: 0.761134 test loss: 0.215709
[Epoch 147; Iter    16/  229] train: loss: 0.1299574
[Epoch 147; Iter    46/  229] train: loss: 0.0944298
[Epoch 147; Iter    76/  229] train: loss: 0.1415853
[Epoch 147; Iter   106/  229] train: loss: 0.1185334
[Epoch 147; Iter   136/  229] train: loss: 0.1302512
[Epoch 147; Iter   166/  229] train: loss: 0.1251516
[Epoch 147; Iter   196/  229] train: loss: 0.1477022
[Epoch 147; Iter   226/  229] train: loss: 0.1433820
[Epoch 147] ogbg-moltoxcast: 0.761150 val loss: 0.201653
[Epoch 147] ogbg-moltoxcast: 0.762222 test loss: 0.214163
[Epoch 148; Iter    27/  229] train: loss: 0.1652598
[Epoch 148; Iter    57/  229] train: loss: 0.1070895
[Epoch 148; Iter    87/  229] train: loss: 0.1646657
[Epoch 148; Iter   117/  229] train: loss: 0.1283907
[Epoch 148; Iter   147/  229] train: loss: 0.1381353
[Epoch 148; Iter   177/  229] train: loss: 0.1373707
[Epoch 148; Iter   207/  229] train: loss: 0.1698005
[Epoch 148] ogbg-moltoxcast: 0.759956 val loss: 0.202178
[Epoch 148] ogbg-moltoxcast: 0.760963 test loss: 0.215099
[Epoch 149; Iter     8/  229] train: loss: 0.1515038
[Epoch 149; Iter    38/  229] train: loss: 0.1512741
[Epoch 149; Iter    68/  229] train: loss: 0.1501570
[Epoch 149; Iter    98/  229] train: loss: 0.1909493
[Epoch 149; Iter   128/  229] train: loss: 0.0837077
[Epoch 149; Iter   158/  229] train: loss: 0.1488899
[Epoch 149; Iter   188/  229] train: loss: 0.1621384
[Epoch 149; Iter   218/  229] train: loss: 0.1494986
[Epoch 149] ogbg-moltoxcast: 0.759877 val loss: 0.202210
[Epoch 149] ogbg-moltoxcast: 0.760063 test loss: 0.213612
[Epoch 150; Iter    19/  229] train: loss: 0.0998413
[Epoch 150; Iter    49/  229] train: loss: 0.1292455
[Epoch 150; Iter    79/  229] train: loss: 0.1515717
[Epoch 150; Iter   109/  229] train: loss: 0.1564339
[Epoch 150; Iter   139/  229] train: loss: 0.1661682
[Epoch 150; Iter   169/  229] train: loss: 0.1122620
[Epoch 150; Iter   199/  229] train: loss: 0.0944796
[Epoch 150; Iter   229/  229] train: loss: 0.1434126
[Epoch 150] ogbg-moltoxcast: 0.760736 val loss: 0.203378
[Epoch 150] ogbg-moltoxcast: 0.762834 test loss: 0.214564
[Epoch 151; Iter    30/  229] train: loss: 0.1153617
[Epoch 151; Iter    60/  229] train: loss: 0.1277900
[Epoch 151; Iter    90/  229] train: loss: 0.1537645
[Epoch 151; Iter   120/  229] train: loss: 0.1388679
[Epoch 151; Iter   150/  229] train: loss: 0.1046874
[Epoch 151; Iter   180/  229] train: loss: 0.1130497
[Epoch 151; Iter   210/  229] train: loss: 0.1923859
[Epoch 151] ogbg-moltoxcast: 0.761286 val loss: 0.202422
[Epoch 151] ogbg-moltoxcast: 0.760923 test loss: 0.215429
[Epoch 152; Iter    11/  229] train: loss: 0.1064717
[Epoch 152; Iter    41/  229] train: loss: 0.1904516
[Epoch 152; Iter    71/  229] train: loss: 0.1713728
[Epoch 152; Iter   101/  229] train: loss: 0.1460902
[Epoch 152; Iter   131/  229] train: loss: 0.1307857
[Epoch 152; Iter   161/  229] train: loss: 0.1618370
[Epoch 152; Iter   191/  229] train: loss: 0.0883349
[Epoch 152; Iter   221/  229] train: loss: 0.1115853
[Epoch 152] ogbg-moltoxcast: 0.760770 val loss: 0.202516
[Epoch 152] ogbg-moltoxcast: 0.760156 test loss: 0.215062
[Epoch 153; Iter    22/  229] train: loss: 0.1585561
[Epoch 153; Iter    52/  229] train: loss: 0.1365295
[Epoch 153; Iter    82/  229] train: loss: 0.1326519
[Epoch 153; Iter   112/  229] train: loss: 0.1444471
[Epoch 153; Iter   142/  229] train: loss: 0.0928381
[Epoch 153; Iter   172/  229] train: loss: 0.1244800
[Epoch 153; Iter   202/  229] train: loss: 0.1738166
[Epoch 153] ogbg-moltoxcast: 0.761297 val loss: 0.201459
[Epoch 153] ogbg-moltoxcast: 0.760594 test loss: 0.213479
[Epoch 154; Iter     3/  229] train: loss: 0.1485042
[Epoch 154; Iter    33/  229] train: loss: 0.1686192
[Epoch 154; Iter    63/  229] train: loss: 0.1230062
[Epoch 154; Iter    93/  229] train: loss: 0.1153574
[Epoch 154; Iter   123/  229] train: loss: 0.1230392
[Epoch 154; Iter   153/  229] train: loss: 0.1127698
[Epoch 154; Iter   183/  229] train: loss: 0.1523607
[Epoch 154; Iter   213/  229] train: loss: 0.0836730
[Epoch 154] ogbg-moltoxcast: 0.760411 val loss: 0.202917
[Epoch 154] ogbg-moltoxcast: 0.760708 test loss: 0.213783
[Epoch 155; Iter    14/  229] train: loss: 0.1258662
[Epoch 155; Iter    44/  229] train: loss: 0.1312680
[Epoch 155; Iter    74/  229] train: loss: 0.1335799
[Epoch 155; Iter   104/  229] train: loss: 0.2060150
[Epoch 155; Iter   134/  229] train: loss: 0.1095303
[Epoch 155; Iter   164/  229] train: loss: 0.0982031
[Epoch 155; Iter   194/  229] train: loss: 0.1347486
[Epoch 155; Iter   224/  229] train: loss: 0.1562553
[Epoch 155] ogbg-moltoxcast: 0.761099 val loss: 0.202836
[Epoch 155] ogbg-moltoxcast: 0.760582 test loss: 0.215517
[Epoch 156; Iter    25/  229] train: loss: 0.1913222
[Epoch 156; Iter    55/  229] train: loss: 0.1275697
[Epoch 156; Iter    85/  229] train: loss: 0.1026233
[Epoch 156; Iter   115/  229] train: loss: 0.1791285
[Epoch 156; Iter   145/  229] train: loss: 0.0890086
[Epoch 156; Iter   175/  229] train: loss: 0.1135594
[Epoch 156; Iter   205/  229] train: loss: 0.1211783
[Epoch 156] ogbg-moltoxcast: 0.760624 val loss: 0.202111
[Epoch 156] ogbg-moltoxcast: 0.759909 test loss: 0.215014
[Epoch 157; Iter     6/  229] train: loss: 0.1352243
[Epoch 157; Iter    36/  229] train: loss: 0.1111867
[Epoch 157; Iter    66/  229] train: loss: 0.1116281
[Epoch 157; Iter    96/  229] train: loss: 0.1469253
[Epoch 157; Iter   126/  229] train: loss: 0.1294056
[Epoch 157; Iter   156/  229] train: loss: 0.0991433
[Epoch 157; Iter   186/  229] train: loss: 0.1556294
[Epoch 157; Iter   216/  229] train: loss: 0.1291810
[Epoch 157] ogbg-moltoxcast: 0.760037 val loss: 0.202671
[Epoch 157] ogbg-moltoxcast: 0.761189 test loss: 0.214549
[Epoch 158; Iter    17/  229] train: loss: 0.1070353
[Epoch 158; Iter    47/  229] train: loss: 0.1853060
[Epoch 158; Iter    77/  229] train: loss: 0.1324266
[Epoch 158; Iter   107/  229] train: loss: 0.1083339
[Epoch 158; Iter   137/  229] train: loss: 0.1221095
[Epoch 158; Iter   167/  229] train: loss: 0.0859455
[Epoch 158; Iter   197/  229] train: loss: 0.1583746
[Epoch 158; Iter   227/  229] train: loss: 0.1125709
[Epoch 158] ogbg-moltoxcast: 0.760546 val loss: 0.202228
[Epoch 158] ogbg-moltoxcast: 0.761487 test loss: 0.214611
[Epoch 159; Iter    28/  229] train: loss: 0.1350823
[Epoch 159; Iter    58/  229] train: loss: 0.1019040
[Epoch 159; Iter    88/  229] train: loss: 0.1142737
[Epoch 159; Iter   118/  229] train: loss: 0.0794733
[Epoch 159; Iter   148/  229] train: loss: 0.1266865
[Epoch 159; Iter   178/  229] train: loss: 0.1038641
[Epoch 159; Iter   208/  229] train: loss: 0.1654411
[Epoch 159] ogbg-moltoxcast: 0.760886 val loss: 0.203623
[Epoch 159] ogbg-moltoxcast: 0.760703 test loss: 0.217935
[Epoch 160; Iter     9/  229] train: loss: 0.1635931
[Epoch 160; Iter    39/  229] train: loss: 0.1174141
[Epoch 160; Iter    69/  229] train: loss: 0.1238568
[Epoch 160; Iter    99/  229] train: loss: 0.1378782
[Epoch 160; Iter   129/  229] train: loss: 0.1375480
[Epoch 160; Iter   159/  229] train: loss: 0.1442568
[Epoch 160; Iter   189/  229] train: loss: 0.1546565
[Epoch 160; Iter   219/  229] train: loss: 0.1016364
[Epoch 160] ogbg-moltoxcast: 0.759653 val loss: 0.202954
[Epoch 160] ogbg-moltoxcast: 0.761024 test loss: 0.214934
[Epoch 161; Iter    20/  229] train: loss: 0.1322308
[Epoch 161; Iter    50/  229] train: loss: 0.1584982
[Epoch 161; Iter    80/  229] train: loss: 0.1147875
[Epoch 161; Iter   110/  229] train: loss: 0.1189979
[Epoch 161; Iter   140/  229] train: loss: 0.1516143
[Epoch 161; Iter   170/  229] train: loss: 0.1399507
[Epoch 161; Iter   200/  229] train: loss: 0.1301829
[Epoch 161] ogbg-moltoxcast: 0.756915 val loss: 0.204204
[Epoch 161] ogbg-moltoxcast: 0.758032 test loss: 0.215170
[Epoch 162; Iter     1/  229] train: loss: 0.1493196
[Epoch 162; Iter    31/  229] train: loss: 0.0953421
[Epoch 162; Iter    61/  229] train: loss: 0.1358586
[Epoch 162; Iter    91/  229] train: loss: 0.1023366
[Epoch 162; Iter   121/  229] train: loss: 0.0996314
[Epoch 162; Iter   151/  229] train: loss: 0.1278648
[Epoch 162; Iter   181/  229] train: loss: 0.1283407
[Epoch 162; Iter   211/  229] train: loss: 0.1179839
[Epoch 162] ogbg-moltoxcast: 0.761502 val loss: 0.202889
[Epoch 162] ogbg-moltoxcast: 0.760531 test loss: 0.214067
[Epoch 163; Iter    12/  229] train: loss: 0.1161498
[Epoch 163; Iter    42/  229] train: loss: 0.1265886
[Epoch 163; Iter    72/  229] train: loss: 0.1035619
[Epoch 163; Iter   102/  229] train: loss: 0.1309320
[Epoch 163; Iter   132/  229] train: loss: 0.1409040
[Epoch 163; Iter   162/  229] train: loss: 0.1263667
[Epoch 163; Iter   192/  229] train: loss: 0.1185978
[Epoch 163; Iter   222/  229] train: loss: 0.1903322
[Epoch 163] ogbg-moltoxcast: 0.759411 val loss: 0.203624
[Epoch 163] ogbg-moltoxcast: 0.760356 test loss: 0.215694
[Epoch 164; Iter    23/  229] train: loss: 0.1503301
[Epoch 164; Iter    53/  229] train: loss: 0.1199522
[Epoch 164; Iter    83/  229] train: loss: 0.1831094
[Epoch 164; Iter   113/  229] train: loss: 0.1666120
[Epoch 164; Iter   143/  229] train: loss: 0.1388356
[Epoch 164; Iter   173/  229] train: loss: 0.0955375
[Epoch 164; Iter   203/  229] train: loss: 0.1806217
[Epoch 164] ogbg-moltoxcast: 0.761370 val loss: 0.203805
[Epoch 164] ogbg-moltoxcast: 0.760083 test loss: 0.217483
[Epoch 165; Iter     4/  229] train: loss: 0.0980772
[Epoch 165; Iter    34/  229] train: loss: 0.1658024
[Epoch 165; Iter    64/  229] train: loss: 0.1836012
[Epoch 165; Iter    94/  229] train: loss: 0.1325933
[Epoch 165; Iter   124/  229] train: loss: 0.1336175
[Epoch 165; Iter   154/  229] train: loss: 0.1193288
[Epoch 165; Iter   184/  229] train: loss: 0.1798585
[Epoch 165; Iter   214/  229] train: loss: 0.1964119
[Epoch 165] ogbg-moltoxcast: 0.757785 val loss: 0.203662
[Epoch 165] ogbg-moltoxcast: 0.760701 test loss: 0.214390
[Epoch 166; Iter    15/  229] train: loss: 0.1310051
[Epoch 166; Iter    45/  229] train: loss: 0.1511935
[Epoch 166; Iter    75/  229] train: loss: 0.1689805
[Epoch 166; Iter   105/  229] train: loss: 0.1050184
[Epoch 166; Iter   135/  229] train: loss: 0.0884059
[Epoch 166; Iter   165/  229] train: loss: 0.1236428
[Epoch 166; Iter   195/  229] train: loss: 0.1382407
[Epoch 166; Iter   225/  229] train: loss: 0.1313843
[Epoch 166] ogbg-moltoxcast: 0.757733 val loss: 0.203850
[Epoch 166] ogbg-moltoxcast: 0.759655 test loss: 0.215222
[Epoch 167; Iter    26/  229] train: loss: 0.1428535
[Epoch 167; Iter    56/  229] train: loss: 0.1407500
[Epoch 167; Iter    86/  229] train: loss: 0.0879811
[Epoch 167; Iter   116/  229] train: loss: 0.1524241
[Epoch 167; Iter   146/  229] train: loss: 0.1406438
[Epoch 167; Iter   176/  229] train: loss: 0.1247619
[Epoch 167; Iter   206/  229] train: loss: 0.1606775
[Epoch 167] ogbg-moltoxcast: 0.760585 val loss: 0.202770
[Epoch 167] ogbg-moltoxcast: 0.761166 test loss: 0.213784
[Epoch 168; Iter     7/  229] train: loss: 0.1380306
[Epoch 168; Iter    37/  229] train: loss: 0.1276316
[Epoch 168; Iter    67/  229] train: loss: 0.1193915
[Epoch 168; Iter    97/  229] train: loss: 0.1276296
[Epoch 168; Iter   127/  229] train: loss: 0.1142547
[Epoch 168; Iter   157/  229] train: loss: 0.0744119
[Epoch 168; Iter   187/  229] train: loss: 0.1159954
[Epoch 168; Iter   217/  229] train: loss: 0.1348177
[Epoch 168] ogbg-moltoxcast: 0.759994 val loss: 0.203079
[Epoch 168] ogbg-moltoxcast: 0.760413 test loss: 0.215960
[Epoch 169; Iter    18/  229] train: loss: 0.1480125
[Epoch 169; Iter    48/  229] train: loss: 0.1173290
[Epoch 169; Iter    78/  229] train: loss: 0.1287834
[Epoch 169; Iter   108/  229] train: loss: 0.1306074
[Epoch 169; Iter   138/  229] train: loss: 0.1695897
[Epoch 169; Iter   168/  229] train: loss: 0.1406405
[Epoch 169; Iter   198/  229] train: loss: 0.1309064
[Epoch 169; Iter   228/  229] train: loss: 0.1383104
[Epoch 169] ogbg-moltoxcast: 0.760781 val loss: 0.203306
[Epoch 169] ogbg-moltoxcast: 0.761839 test loss: 0.215662
[Epoch 170; Iter    29/  229] train: loss: 0.1795380
[Epoch 170; Iter    59/  229] train: loss: 0.1637224
[Epoch 170; Iter    89/  229] train: loss: 0.1237029
[Epoch 170; Iter   119/  229] train: loss: 0.1087247
[Epoch 170; Iter   149/  229] train: loss: 0.1511679
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 170; Iter   179/  229] train: loss: 0.1389794
[Epoch 170; Iter   209/  229] train: loss: 0.1254006
[Epoch 170] ogbg-moltoxcast: 0.761873 val loss: 0.201924
[Epoch 170] ogbg-moltoxcast: 0.762448 test loss: 0.215492
[Epoch 171; Iter    10/  229] train: loss: 0.1266632
[Epoch 171; Iter    40/  229] train: loss: 0.1234374
[Epoch 171; Iter    70/  229] train: loss: 0.1640539
[Epoch 171; Iter   100/  229] train: loss: 0.1323405
[Epoch 171; Iter   130/  229] train: loss: 0.1460680
[Epoch 171; Iter   160/  229] train: loss: 0.1584532
[Epoch 171; Iter   190/  229] train: loss: 0.1061625
[Epoch 171; Iter   220/  229] train: loss: 0.1086021
[Epoch 171] ogbg-moltoxcast: 0.758668 val loss: 0.204070
[Epoch 171] ogbg-moltoxcast: 0.760742 test loss: 0.216273
[Epoch 172; Iter    21/  229] train: loss: 0.0754830
[Epoch 172; Iter    51/  229] train: loss: 0.1086607
[Epoch 172; Iter    81/  229] train: loss: 0.1168789
[Epoch 172; Iter   111/  229] train: loss: 0.0962478
[Epoch 172; Iter   141/  229] train: loss: 0.1550832
[Epoch 172; Iter   171/  229] train: loss: 0.1597165
[Epoch 172; Iter   201/  229] train: loss: 0.1264754
[Epoch 172] ogbg-moltoxcast: 0.760111 val loss: 0.203114
[Epoch 172] ogbg-moltoxcast: 0.760827 test loss: 0.215826
[Epoch 173; Iter     2/  229] train: loss: 0.1389476
[Epoch 173; Iter    32/  229] train: loss: 0.0787946
[Epoch 173; Iter    62/  229] train: loss: 0.1081673
[Epoch 173; Iter    92/  229] train: loss: 0.1380502
[Epoch 173; Iter   122/  229] train: loss: 0.1705585
[Epoch 173; Iter   152/  229] train: loss: 0.1169545
[Epoch 173; Iter   182/  229] train: loss: 0.1346585
[Epoch 173; Iter   212/  229] train: loss: 0.2155432
[Epoch 173] ogbg-moltoxcast: 0.759416 val loss: 0.202636
[Epoch 173] ogbg-moltoxcast: 0.760156 test loss: 0.216047
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 173 epochs. Best model checkpoint was in epoch 113.
Statistics on  val_best_checkpoint
mean_pred: -3.5211660861968994
std_pred: 2.830402135848999
mean_targets: nan
std_targets: nan
prcauc: 0.44514163167249765
rocauc: 0.7652694976105672
ogbg-moltoxcast: 0.7652694976105672
OGBNanLabelBCEWithLogitsLoss: 0.19839621104043106
Statistics on  test
mean_pred: -3.5447998046875
std_pred: 2.870033025741577
mean_targets: nan
std_targets: nan
prcauc: 0.45447765172782956
rocauc: 0.7601637536792215
ogbg-moltoxcast: 0.7601637536792215
OGBNanLabelBCEWithLogitsLoss: 0.21217223231134744
Statistics on  train
mean_pred: -3.53171968460083
std_pred: 2.8837180137634277
mean_targets: nan
std_targets: nan
prcauc: 0.6404037620628342
rocauc: 0.9063245876138651
ogbg-moltoxcast: 0.9063245876138651
OGBNanLabelBCEWithLogitsLoss: 0.12988433544422343
All runs completed.
