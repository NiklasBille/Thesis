>>> Starting run for dataset: hiv
Running RANDOM configs_split_experiments/GraphCL/hiv/random/train_prop=0.6.yml on cuda:0
Running RANDOM configs_split_experiments/GraphCL/hiv/random/train_prop=0.7.yml on cuda:1
Running RANDOM configs_split_experiments/GraphCL/hiv/random/train_prop=0.8.yml on cuda:2
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
Starting process for seed 4: python train.py --config configs_split_experiments/GraphCL/hiv/random/train_prop=0.7.yml --seed 4 --device cuda:1
Starting process for seed 4: python train.py --config configs_split_experiments/GraphCL/hiv/random/train_prop=0.8.yml --seed 4 --device cuda:2
Starting process for seed 4: python train.py --config configs_split_experiments/GraphCL/hiv/random/train_prop=0.6.yml --seed 4 --device cuda:0
Starting process for seed 5: python train.py --config configs_split_experiments/GraphCL/hiv/random/train_prop=0.7.yml --seed 5 --device cuda:1
Starting process for seed 5: python train.py --config configs_split_experiments/GraphCL/hiv/random/train_prop=0.8.yml --seed 5 --device cuda:2
Starting process for seed 5: python train.py --config configs_split_experiments/GraphCL/hiv/random/train_prop=0.6.yml --seed 5 --device cuda:0
Starting process for seed 6: python train.py --config configs_split_experiments/GraphCL/hiv/random/train_prop=0.7.yml --seed 6 --device cuda:1
Starting process for seed 6: python train.py --config configs_split_experiments/GraphCL/hiv/random/train_prop=0.8.yml --seed 6 --device cuda:2
Starting process for seed 6: python train.py --config configs_split_experiments/GraphCL/hiv/random/train_prop=0.6.yml --seed 6 --device cuda:0
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[ Using Seed :  5  ]
using device:  cuda:2
Log directory:  runs/split/GraphCL/hiv/random/train_prop=0.8/PNA_ogbg-molhiv_GraphCL_hiv_random=0.8_5_26-05_09-40-08
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/hiv/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_random=0.8
logdir: runs/split/GraphCL/hiv/random/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6934489
[Epoch 1; Iter    60/ 1097] train: loss: 0.6927769
[Epoch 1; Iter    90/ 1097] train: loss: 0.6927131
[Epoch 1; Iter   120/ 1097] train: loss: 0.6923739
[Epoch 1; Iter   150/ 1097] train: loss: 0.6918777
[Epoch 1; Iter   180/ 1097] train: loss: 0.6913303
[Epoch 1; Iter   210/ 1097] train: loss: 0.6887515
[Epoch 1; Iter   240/ 1097] train: loss: 0.6896744
[Epoch 1; Iter   270/ 1097] train: loss: 0.6887583
[Epoch 1; Iter   300/ 1097] train: loss: 0.6900058
[Epoch 1; Iter   330/ 1097] train: loss: 0.6866614
[Epoch 1; Iter   360/ 1097] train: loss: 0.6857262
[Epoch 1; Iter   390/ 1097] train: loss: 0.6842610
[Epoch 1; Iter   420/ 1097] train: loss: 0.6829965
[Epoch 1; Iter   450/ 1097] train: loss: 0.6824360
[Epoch 1; Iter   480/ 1097] train: loss: 0.6798598
[Epoch 1; Iter   510/ 1097] train: loss: 0.6803747
[Epoch 1; Iter   540/ 1097] train: loss: 0.6785796
[Epoch 1; Iter   570/ 1097] train: loss: 0.6742396
[Epoch 1; Iter   600/ 1097] train: loss: 0.6730872
[Epoch 1; Iter   630/ 1097] train: loss: 0.6713898
[Epoch 1; Iter   660/ 1097] train: loss: 0.6690471
[Epoch 1; Iter   690/ 1097] train: loss: 0.6656206
[Epoch 1; Iter   720/ 1097] train: loss: 0.6610130
[Epoch 1; Iter   750/ 1097] train: loss: 0.6393986
[Epoch 1; Iter   780/ 1097] train: loss: 0.6008306
[Epoch 1; Iter   810/ 1097] train: loss: 0.5823091
[Epoch 1; Iter   840/ 1097] train: loss: 0.4972654
[Epoch 1; Iter   870/ 1097] train: loss: 0.4600354
[Epoch 1; Iter   900/ 1097] train: loss: 0.3585913
[Epoch 1; Iter   930/ 1097] train: loss: 0.2889368
[Epoch 1; Iter   960/ 1097] train: loss: 0.2464934
[Epoch 1; Iter   990/ 1097] train: loss: 0.2107903
[Epoch 1; Iter  1020/ 1097] train: loss: 0.2825617
[Epoch 1; Iter  1050/ 1097] train: loss: 0.2258119
[Epoch 1; Iter  1080/ 1097] train: loss: 0.0889441
[Epoch 1] ogbg-molhiv: 0.694015 val loss: 0.183016
[Epoch 1] ogbg-molhiv: 0.672991 test loss: 0.183882
[Epoch 2; Iter    13/ 1097] train: loss: 0.0969922
[Epoch 2; Iter    43/ 1097] train: loss: 0.1607029
[Epoch 2; Iter    73/ 1097] train: loss: 0.0559061
[Epoch 2; Iter   103/ 1097] train: loss: 0.1449233
[Epoch 2; Iter   133/ 1097] train: loss: 0.1561148
[Epoch 2; Iter   163/ 1097] train: loss: 0.1623912
[Epoch 2; Iter   193/ 1097] train: loss: 0.0628352
[Epoch 2; Iter   223/ 1097] train: loss: 0.1222545
[Epoch 2; Iter   253/ 1097] train: loss: 0.1582648
[Epoch 2; Iter   283/ 1097] train: loss: 0.1324154
[Epoch 2; Iter   313/ 1097] train: loss: 0.1537557
[Epoch 2; Iter   343/ 1097] train: loss: 0.0434509
[Epoch 2; Iter   373/ 1097] train: loss: 0.0365743
[Epoch 2; Iter   403/ 1097] train: loss: 0.1824494
[Epoch 2; Iter   433/ 1097] train: loss: 0.0422191
[Epoch 2; Iter   463/ 1097] train: loss: 0.0362967
[Epoch 2; Iter   493/ 1097] train: loss: 0.1698765
[Epoch 2; Iter   523/ 1097] train: loss: 0.1023951
[Epoch 2; Iter   553/ 1097] train: loss: 0.1503475
[Epoch 2; Iter   583/ 1097] train: loss: 0.1470854
[Epoch 2; Iter   613/ 1097] train: loss: 0.3614227
[Epoch 2; Iter   643/ 1097] train: loss: 0.0792115
[Epoch 2; Iter   673/ 1097] train: loss: 0.0386090
[Epoch 2; Iter   703/ 1097] train: loss: 0.0864064
[Epoch 2; Iter   733/ 1097] train: loss: 0.2522296
[Epoch 2; Iter   763/ 1097] train: loss: 0.0381012
[Epoch 2; Iter   793/ 1097] train: loss: 0.0949872
[Epoch 2; Iter   823/ 1097] train: loss: 0.2170609
[Epoch 2; Iter   853/ 1097] train: loss: 0.4466196
[Epoch 2; Iter   883/ 1097] train: loss: 0.0349190
[Epoch 2; Iter   913/ 1097] train: loss: 0.0329812
[Epoch 2; Iter   943/ 1097] train: loss: 0.2356670
[Epoch 2; Iter   973/ 1097] train: loss: 0.0357035
[Epoch 2; Iter  1003/ 1097] train: loss: 0.1672356
[Epoch 2; Iter  1033/ 1097] train: loss: 0.1802441
[Epoch 2; Iter  1063/ 1097] train: loss: 0.3700400
[Epoch 2; Iter  1093/ 1097] train: loss: 0.1356426
[Epoch 2] ogbg-molhiv: 0.684923 val loss: 0.198414
[Epoch 2] ogbg-molhiv: 0.650956 test loss: 0.217107
[Epoch 3; Iter    26/ 1097] train: loss: 0.1270991
[Epoch 3; Iter    56/ 1097] train: loss: 0.2218823
[Epoch 3; Iter    86/ 1097] train: loss: 0.0377995
[Epoch 3; Iter   116/ 1097] train: loss: 0.4400070
[Epoch 3; Iter   146/ 1097] train: loss: 0.3117019
[Epoch 3; Iter   176/ 1097] train: loss: 0.0479920
[Epoch 3; Iter   206/ 1097] train: loss: 0.1660641
[Epoch 3; Iter   236/ 1097] train: loss: 0.1164652
[Epoch 3; Iter   266/ 1097] train: loss: 0.2373281
[Epoch 3; Iter   296/ 1097] train: loss: 0.0333896
[Epoch 3; Iter   326/ 1097] train: loss: 0.1234927
[Epoch 3; Iter   356/ 1097] train: loss: 0.0380234
[Epoch 3; Iter   386/ 1097] train: loss: 0.0342591
[Epoch 3; Iter   416/ 1097] train: loss: 0.1316502
[Epoch 3; Iter   446/ 1097] train: loss: 0.2174191
[Epoch 3; Iter   476/ 1097] train: loss: 0.2134515
[Epoch 3; Iter   506/ 1097] train: loss: 0.0292807
[Epoch 3; Iter   536/ 1097] train: loss: 0.0357905
[Epoch 3; Iter   566/ 1097] train: loss: 0.1318923
[Epoch 3; Iter   596/ 1097] train: loss: 0.1397050
[Epoch 3; Iter   626/ 1097] train: loss: 0.1328144
[Epoch 3; Iter   656/ 1097] train: loss: 0.0973680
[Epoch 3; Iter   686/ 1097] train: loss: 0.1587541
[Epoch 3; Iter   716/ 1097] train: loss: 0.0342799
[Epoch 3; Iter   746/ 1097] train: loss: 0.1496814
[Epoch 3; Iter   776/ 1097] train: loss: 0.0366537
[Epoch 3; Iter   806/ 1097] train: loss: 0.1608126
[Epoch 3; Iter   836/ 1097] train: loss: 0.0328005
[Epoch 3; Iter   866/ 1097] train: loss: 0.0267121
[Epoch 3; Iter   896/ 1097] train: loss: 0.0323504
[Epoch 3; Iter   926/ 1097] train: loss: 0.1322703
[Epoch 3; Iter   956/ 1097] train: loss: 0.1917902
[Epoch 3; Iter   986/ 1097] train: loss: 0.2062273
[ Using Seed :  6  ]
using device:  cuda:2
Log directory:  runs/split/GraphCL/hiv/random/train_prop=0.8/PNA_ogbg-molhiv_GraphCL_hiv_random=0.8_6_26-05_09-40-09
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/hiv/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_random=0.8
logdir: runs/split/GraphCL/hiv/random/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6926442
[Epoch 1; Iter    60/ 1097] train: loss: 0.6952227
[Epoch 1; Iter    90/ 1097] train: loss: 0.6917699
[Epoch 1; Iter   120/ 1097] train: loss: 0.6923998
[Epoch 1; Iter   150/ 1097] train: loss: 0.6971690
[Epoch 1; Iter   180/ 1097] train: loss: 0.6906233
[Epoch 1; Iter   210/ 1097] train: loss: 0.6909928
[Epoch 1; Iter   240/ 1097] train: loss: 0.6898748
[Epoch 1; Iter   270/ 1097] train: loss: 0.6906122
[Epoch 1; Iter   300/ 1097] train: loss: 0.6880645
[Epoch 1; Iter   330/ 1097] train: loss: 0.6868608
[Epoch 1; Iter   360/ 1097] train: loss: 0.6860489
[Epoch 1; Iter   390/ 1097] train: loss: 0.6848063
[Epoch 1; Iter   420/ 1097] train: loss: 0.6829495
[Epoch 1; Iter   450/ 1097] train: loss: 0.6859100
[Epoch 1; Iter   480/ 1097] train: loss: 0.6797769
[Epoch 1; Iter   510/ 1097] train: loss: 0.6781390
[Epoch 1; Iter   540/ 1097] train: loss: 0.6769711
[Epoch 1; Iter   570/ 1097] train: loss: 0.6744296
[Epoch 1; Iter   600/ 1097] train: loss: 0.6787753
[Epoch 1; Iter   630/ 1097] train: loss: 0.6703255
[Epoch 1; Iter   660/ 1097] train: loss: 0.6681280
[Epoch 1; Iter   690/ 1097] train: loss: 0.6701167
[Epoch 1; Iter   720/ 1097] train: loss: 0.6703604
[Epoch 1; Iter   750/ 1097] train: loss: 0.6405485
[Epoch 1; Iter   780/ 1097] train: loss: 0.6042578
[Epoch 1; Iter   810/ 1097] train: loss: 0.5634677
[Epoch 1; Iter   840/ 1097] train: loss: 0.5156381
[Epoch 1; Iter   870/ 1097] train: loss: 0.4214790
[Epoch 1; Iter   900/ 1097] train: loss: 0.3704845
[Epoch 1; Iter   930/ 1097] train: loss: 0.3061981
[Epoch 1; Iter   960/ 1097] train: loss: 0.2259747
[Epoch 1; Iter   990/ 1097] train: loss: 0.4476485
[Epoch 1; Iter  1020/ 1097] train: loss: 0.2167709
[Epoch 1; Iter  1050/ 1097] train: loss: 0.1980836
[Epoch 1; Iter  1080/ 1097] train: loss: 0.0905289
[Epoch 1] ogbg-molhiv: 0.665960 val loss: 0.165119
[Epoch 1] ogbg-molhiv: 0.669894 test loss: 0.162753
[Epoch 2; Iter    13/ 1097] train: loss: 0.0794833
[Epoch 2; Iter    43/ 1097] train: loss: 0.0671039
[Epoch 2; Iter    73/ 1097] train: loss: 0.0589830
[Epoch 2; Iter   103/ 1097] train: loss: 0.0523371
[Epoch 2; Iter   133/ 1097] train: loss: 0.0495980
[Epoch 2; Iter   163/ 1097] train: loss: 0.1466558
[Epoch 2; Iter   193/ 1097] train: loss: 0.1446544
[Epoch 2; Iter   223/ 1097] train: loss: 0.2579900
[Epoch 2; Iter   253/ 1097] train: loss: 0.1433063
[Epoch 2; Iter   283/ 1097] train: loss: 0.3775017
[Epoch 2; Iter   313/ 1097] train: loss: 0.0356073
[Epoch 2; Iter   343/ 1097] train: loss: 0.0375512
[Epoch 2; Iter   373/ 1097] train: loss: 0.2980006
[Epoch 2; Iter   403/ 1097] train: loss: 0.0701493
[Epoch 2; Iter   433/ 1097] train: loss: 0.2649986
[Epoch 2; Iter   463/ 1097] train: loss: 0.0338365
[Epoch 2; Iter   493/ 1097] train: loss: 0.0408712
[Epoch 2; Iter   523/ 1097] train: loss: 0.0435388
[Epoch 2; Iter   553/ 1097] train: loss: 0.2290579
[Epoch 2; Iter   583/ 1097] train: loss: 0.1202052
[Epoch 2; Iter   613/ 1097] train: loss: 0.2722018
[Epoch 2; Iter   643/ 1097] train: loss: 0.4026048
[Epoch 2; Iter   673/ 1097] train: loss: 0.1584948
[Epoch 2; Iter   703/ 1097] train: loss: 0.2497634
[Epoch 2; Iter   733/ 1097] train: loss: 0.0426711
[Epoch 2; Iter   763/ 1097] train: loss: 0.1697571
[Epoch 2; Iter   793/ 1097] train: loss: 0.1725481
[Epoch 2; Iter   823/ 1097] train: loss: 0.0275562
[Epoch 2; Iter   853/ 1097] train: loss: 0.2225864
[Epoch 2; Iter   883/ 1097] train: loss: 0.1115496
[Epoch 2; Iter   913/ 1097] train: loss: 0.0640357
[Epoch 2; Iter   943/ 1097] train: loss: 0.1252162
[Epoch 2; Iter   973/ 1097] train: loss: 0.1508549
[Epoch 2; Iter  1003/ 1097] train: loss: 0.1778125
[Epoch 2; Iter  1033/ 1097] train: loss: 0.2446061
[Epoch 2; Iter  1063/ 1097] train: loss: 0.2773112
[Epoch 2; Iter  1093/ 1097] train: loss: 0.1980079
[Epoch 2] ogbg-molhiv: 0.687561 val loss: 0.164813
[Epoch 2] ogbg-molhiv: 0.644723 test loss: 0.181055
[Epoch 3; Iter    26/ 1097] train: loss: 0.2797793
[Epoch 3; Iter    56/ 1097] train: loss: 0.0280242
[Epoch 3; Iter    86/ 1097] train: loss: 0.0804541
[Epoch 3; Iter   116/ 1097] train: loss: 0.0357189
[Epoch 3; Iter   146/ 1097] train: loss: 0.3787132
[Epoch 3; Iter   176/ 1097] train: loss: 0.0295371
[Epoch 3; Iter   206/ 1097] train: loss: 0.0377511
[Epoch 3; Iter   236/ 1097] train: loss: 0.0698535
[Epoch 3; Iter   266/ 1097] train: loss: 0.0251116
[Epoch 3; Iter   296/ 1097] train: loss: 0.0383024
[Epoch 3; Iter   326/ 1097] train: loss: 0.1644760
[Epoch 3; Iter   356/ 1097] train: loss: 0.1683796
[Epoch 3; Iter   386/ 1097] train: loss: 0.2446849
[Epoch 3; Iter   416/ 1097] train: loss: 0.0345245
[Epoch 3; Iter   446/ 1097] train: loss: 0.1783384
[Epoch 3; Iter   476/ 1097] train: loss: 0.0316840
[Epoch 3; Iter   506/ 1097] train: loss: 0.0771214
[Epoch 3; Iter   536/ 1097] train: loss: 0.0949000
[Epoch 3; Iter   566/ 1097] train: loss: 0.4945037
[Epoch 3; Iter   596/ 1097] train: loss: 0.0324570
[Epoch 3; Iter   626/ 1097] train: loss: 0.0362528
[Epoch 3; Iter   656/ 1097] train: loss: 0.2620816
[Epoch 3; Iter   686/ 1097] train: loss: 0.2265628
[Epoch 3; Iter   716/ 1097] train: loss: 0.0285522
[Epoch 3; Iter   746/ 1097] train: loss: 0.2201047
[Epoch 3; Iter   776/ 1097] train: loss: 0.0434942
[Epoch 3; Iter   806/ 1097] train: loss: 0.0387683
[Epoch 3; Iter   836/ 1097] train: loss: 0.1417464
[Epoch 3; Iter   866/ 1097] train: loss: 0.1317629
[Epoch 3; Iter   896/ 1097] train: loss: 0.0324144
[Epoch 3; Iter   926/ 1097] train: loss: 0.3365462
[Epoch 3; Iter   956/ 1097] train: loss: 0.0554938
[Epoch 3; Iter   986/ 1097] train: loss: 0.0317009
[ Using Seed :  4  ]
using device:  cuda:2
Log directory:  runs/split/GraphCL/hiv/random/train_prop=0.8/PNA_ogbg-molhiv_GraphCL_hiv_random=0.8_4_26-05_09-40-08
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/hiv/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_random=0.8
logdir: runs/split/GraphCL/hiv/random/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6947584
[Epoch 1; Iter    60/ 1097] train: loss: 0.6930615
[Epoch 1; Iter    90/ 1097] train: loss: 0.6920658
[Epoch 1; Iter   120/ 1097] train: loss: 0.6924284
[Epoch 1; Iter   150/ 1097] train: loss: 0.6919079
[Epoch 1; Iter   180/ 1097] train: loss: 0.6912990
[Epoch 1; Iter   210/ 1097] train: loss: 0.6912468
[Epoch 1; Iter   240/ 1097] train: loss: 0.6898127
[Epoch 1; Iter   270/ 1097] train: loss: 0.6902652
[Epoch 1; Iter   300/ 1097] train: loss: 0.6889179
[Epoch 1; Iter   330/ 1097] train: loss: 0.6884982
[Epoch 1; Iter   360/ 1097] train: loss: 0.6855156
[Epoch 1; Iter   390/ 1097] train: loss: 0.6884235
[Epoch 1; Iter   420/ 1097] train: loss: 0.6826560
[Epoch 1; Iter   450/ 1097] train: loss: 0.6820530
[Epoch 1; Iter   480/ 1097] train: loss: 0.6805411
[Epoch 1; Iter   510/ 1097] train: loss: 0.6762411
[Epoch 1; Iter   540/ 1097] train: loss: 0.6757940
[Epoch 1; Iter   570/ 1097] train: loss: 0.6751680
[Epoch 1; Iter   600/ 1097] train: loss: 0.6717318
[Epoch 1; Iter   630/ 1097] train: loss: 0.6695500
[Epoch 1; Iter   660/ 1097] train: loss: 0.6683190
[Epoch 1; Iter   690/ 1097] train: loss: 0.6660173
[Epoch 1; Iter   720/ 1097] train: loss: 0.6604481
[Epoch 1; Iter   750/ 1097] train: loss: 0.6477438
[Epoch 1; Iter   780/ 1097] train: loss: 0.6045534
[Epoch 1; Iter   810/ 1097] train: loss: 0.5558917
[Epoch 1; Iter   840/ 1097] train: loss: 0.4941819
[Epoch 1; Iter   870/ 1097] train: loss: 0.4247514
[Epoch 1; Iter   900/ 1097] train: loss: 0.4157398
[Epoch 1; Iter   930/ 1097] train: loss: 0.2885764
[Epoch 1; Iter   960/ 1097] train: loss: 0.2658584
[Epoch 1; Iter   990/ 1097] train: loss: 0.2499752
[Epoch 1; Iter  1020/ 1097] train: loss: 0.2125162
[Epoch 1; Iter  1050/ 1097] train: loss: 0.1640764
[Epoch 1; Iter  1080/ 1097] train: loss: 0.0965770
[Epoch 1] ogbg-molhiv: 0.715532 val loss: 0.165980
[Epoch 1] ogbg-molhiv: 0.704064 test loss: 0.166632
[Epoch 2; Iter    13/ 1097] train: loss: 0.1257207
[Epoch 2; Iter    43/ 1097] train: loss: 0.0743557
[Epoch 2; Iter    73/ 1097] train: loss: 0.0575617
[Epoch 2; Iter   103/ 1097] train: loss: 0.1251680
[Epoch 2; Iter   133/ 1097] train: loss: 0.2349723
[Epoch 2; Iter   163/ 1097] train: loss: 0.0423608
[Epoch 2; Iter   193/ 1097] train: loss: 0.3404807
[Epoch 2; Iter   223/ 1097] train: loss: 0.2609521
[Epoch 2; Iter   253/ 1097] train: loss: 0.0907214
[Epoch 2; Iter   283/ 1097] train: loss: 0.2133082
[Epoch 2; Iter   313/ 1097] train: loss: 0.1640965
[Epoch 2; Iter   343/ 1097] train: loss: 0.0378270
[Epoch 2; Iter   373/ 1097] train: loss: 0.0344363
[Epoch 2; Iter   403/ 1097] train: loss: 0.1449641
[Epoch 2; Iter   433/ 1097] train: loss: 0.1639405
[Epoch 2; Iter   463/ 1097] train: loss: 0.1132871
[Epoch 2; Iter   493/ 1097] train: loss: 0.0306941
[Epoch 2; Iter   523/ 1097] train: loss: 0.0426719
[Epoch 2; Iter   553/ 1097] train: loss: 0.0333766
[Epoch 2; Iter   583/ 1097] train: loss: 0.2942168
[Epoch 2; Iter   613/ 1097] train: loss: 0.2548287
[Epoch 2; Iter   643/ 1097] train: loss: 0.4412168
[Epoch 2; Iter   673/ 1097] train: loss: 0.0464460
[Epoch 2; Iter   703/ 1097] train: loss: 0.0323915
[Epoch 2; Iter   733/ 1097] train: loss: 0.0425449
[Epoch 2; Iter   763/ 1097] train: loss: 0.3896714
[Epoch 2; Iter   793/ 1097] train: loss: 0.0405534
[Epoch 2; Iter   823/ 1097] train: loss: 0.0644631
[Epoch 2; Iter   853/ 1097] train: loss: 0.0350790
[Epoch 2; Iter   883/ 1097] train: loss: 0.0507410
[Epoch 2; Iter   913/ 1097] train: loss: 0.0540389
[Epoch 2; Iter   943/ 1097] train: loss: 0.0463099
[Epoch 2; Iter   973/ 1097] train: loss: 0.0302773
[Epoch 2; Iter  1003/ 1097] train: loss: 0.0429512
[Epoch 2; Iter  1033/ 1097] train: loss: 0.1388405
[Epoch 2; Iter  1063/ 1097] train: loss: 0.0283145
[Epoch 2; Iter  1093/ 1097] train: loss: 0.2032648
[Epoch 2] ogbg-molhiv: 0.705526 val loss: 0.140613
[Epoch 2] ogbg-molhiv: 0.728697 test loss: 0.133984
[Epoch 3; Iter    26/ 1097] train: loss: 0.0404177
[Epoch 3; Iter    56/ 1097] train: loss: 0.1416248
[Epoch 3; Iter    86/ 1097] train: loss: 0.1562515
[Epoch 3; Iter   116/ 1097] train: loss: 0.2830561
[Epoch 3; Iter   146/ 1097] train: loss: 0.1326302
[Epoch 3; Iter   176/ 1097] train: loss: 0.1131130
[Epoch 3; Iter   206/ 1097] train: loss: 0.0301249
[Epoch 3; Iter   236/ 1097] train: loss: 0.2461530
[Epoch 3; Iter   266/ 1097] train: loss: 0.3392441
[Epoch 3; Iter   296/ 1097] train: loss: 0.2493000
[Epoch 3; Iter   326/ 1097] train: loss: 0.3145582
[Epoch 3; Iter   356/ 1097] train: loss: 0.2555623
[Epoch 3; Iter   386/ 1097] train: loss: 0.0277596
[Epoch 3; Iter   416/ 1097] train: loss: 0.0486533
[Epoch 3; Iter   446/ 1097] train: loss: 0.0644327
[Epoch 3; Iter   476/ 1097] train: loss: 0.0298514
[Epoch 3; Iter   506/ 1097] train: loss: 0.1135373
[Epoch 3; Iter   536/ 1097] train: loss: 0.1782254
[Epoch 3; Iter   566/ 1097] train: loss: 0.2299464
[Epoch 3; Iter   596/ 1097] train: loss: 0.0277136
[Epoch 3; Iter   626/ 1097] train: loss: 0.1531626
[Epoch 3; Iter   656/ 1097] train: loss: 0.0376706
[Epoch 3; Iter   686/ 1097] train: loss: 0.0278594
[Epoch 3; Iter   716/ 1097] train: loss: 0.0342707
[Epoch 3; Iter   746/ 1097] train: loss: 0.1091990
[Epoch 3; Iter   776/ 1097] train: loss: 0.1876019
[Epoch 3; Iter   806/ 1097] train: loss: 0.1475007
[Epoch 3; Iter   836/ 1097] train: loss: 0.1897436
[Epoch 3; Iter   866/ 1097] train: loss: 0.1541973
[Epoch 3; Iter   896/ 1097] train: loss: 0.5461108
[Epoch 3; Iter   926/ 1097] train: loss: 0.1494085
[Epoch 3; Iter   956/ 1097] train: loss: 0.0406534
[Epoch 3; Iter   986/ 1097] train: loss: 0.1814968
[ Using Seed :  6  ]
using device:  cuda:1
Log directory:  runs/split/GraphCL/hiv/random/train_prop=0.7/PNA_ogbg-molhiv_GraphCL_hiv_random=0.7_6_26-05_09-40-09
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/hiv/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_random=0.7
logdir: runs/split/GraphCL/hiv/random/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  960] train: loss: 0.6931221
[Epoch 1; Iter    60/  960] train: loss: 0.6930544
[Epoch 1; Iter    90/  960] train: loss: 0.6927500
[Epoch 1; Iter   120/  960] train: loss: 0.6935827
[Epoch 1; Iter   150/  960] train: loss: 0.6941646
[Epoch 1; Iter   180/  960] train: loss: 0.6918275
[Epoch 1; Iter   210/  960] train: loss: 0.6921807
[Epoch 1; Iter   240/  960] train: loss: 0.6962923
[Epoch 1; Iter   270/  960] train: loss: 0.6906859
[Epoch 1; Iter   300/  960] train: loss: 0.6879958
[Epoch 1; Iter   330/  960] train: loss: 0.6919045
[Epoch 1; Iter   360/  960] train: loss: 0.6857241
[Epoch 1; Iter   390/  960] train: loss: 0.6844431
[Epoch 1; Iter   420/  960] train: loss: 0.6848578
[Epoch 1; Iter   450/  960] train: loss: 0.6815403
[Epoch 1; Iter   480/  960] train: loss: 0.6799505
[Epoch 1; Iter   510/  960] train: loss: 0.6786178
[Epoch 1; Iter   540/  960] train: loss: 0.6763578
[Epoch 1; Iter   570/  960] train: loss: 0.6758675
[Epoch 1; Iter   600/  960] train: loss: 0.6724247
[Epoch 1; Iter   630/  960] train: loss: 0.6716187
[Epoch 1; Iter   660/  960] train: loss: 0.6681214
[Epoch 1; Iter   690/  960] train: loss: 0.6658703
[Epoch 1; Iter   720/  960] train: loss: 0.6645451
[Epoch 1; Iter   750/  960] train: loss: 0.6410127
[Epoch 1; Iter   780/  960] train: loss: 0.6051100
[Epoch 1; Iter   810/  960] train: loss: 0.5705498
[Epoch 1; Iter   840/  960] train: loss: 0.5056155
[Epoch 1; Iter   870/  960] train: loss: 0.4390304
[Epoch 1; Iter   900/  960] train: loss: 0.4116372
[Epoch 1; Iter   930/  960] train: loss: 0.2901950
[Epoch 1; Iter   960/  960] train: loss: 0.2262231
[Epoch 1] ogbg-molhiv: 0.657940 val loss: 0.276740
[Epoch 1] ogbg-molhiv: 0.693665 test loss: 0.273038
[Epoch 2; Iter    30/  960] train: loss: 0.1805630
[Epoch 2; Iter    60/  960] train: loss: 0.2213072
[Epoch 2; Iter    90/  960] train: loss: 0.1138555
[Epoch 2; Iter   120/  960] train: loss: 0.2241658
[Epoch 2; Iter   150/  960] train: loss: 0.1392596
[Epoch 2; Iter   180/  960] train: loss: 0.1455664
[Epoch 2; Iter   210/  960] train: loss: 0.0654247
[Epoch 2; Iter   240/  960] train: loss: 0.0692547
[Epoch 2; Iter   270/  960] train: loss: 0.0495056
[Epoch 2; Iter   300/  960] train: loss: 0.1567942
[Epoch 2; Iter   330/  960] train: loss: 0.0929818
[Epoch 2; Iter   360/  960] train: loss: 0.1836112
[Epoch 2; Iter   390/  960] train: loss: 0.1058680
[Epoch 2; Iter   420/  960] train: loss: 0.0340458
[Epoch 2; Iter   450/  960] train: loss: 0.2026565
[Epoch 2; Iter   480/  960] train: loss: 0.1581122
[Epoch 2; Iter   510/  960] train: loss: 0.1927898
[Epoch 2; Iter   540/  960] train: loss: 0.2765684
[Epoch 2; Iter   570/  960] train: loss: 0.3079660
[Epoch 2; Iter   600/  960] train: loss: 0.0398599
[Epoch 2; Iter   630/  960] train: loss: 0.0277179
[Epoch 2; Iter   660/  960] train: loss: 0.0875947
[Epoch 2; Iter   690/  960] train: loss: 0.1922374
[Epoch 2; Iter   720/  960] train: loss: 0.0372442
[Epoch 2; Iter   750/  960] train: loss: 0.2043698
[Epoch 2; Iter   780/  960] train: loss: 0.0508255
[Epoch 2; Iter   810/  960] train: loss: 0.1308080
[Epoch 2; Iter   840/  960] train: loss: 0.1577799
[Epoch 2; Iter   870/  960] train: loss: 0.1683490
[Epoch 2; Iter   900/  960] train: loss: 0.1142468
[Epoch 2; Iter   930/  960] train: loss: 0.1483065
[Epoch 2; Iter   960/  960] train: loss: 0.0315644
[Epoch 2] ogbg-molhiv: 0.700312 val loss: 0.149421
[Epoch 2] ogbg-molhiv: 0.682813 test loss: 0.143007
[Epoch 3; Iter    30/  960] train: loss: 0.1437749
[Epoch 3; Iter    60/  960] train: loss: 0.0499215
[Epoch 3; Iter    90/  960] train: loss: 0.1697594
[Epoch 3; Iter   120/  960] train: loss: 0.1739813
[Epoch 3; Iter   150/  960] train: loss: 0.1684622
[Epoch 3; Iter   180/  960] train: loss: 0.1305242
[Epoch 3; Iter   210/  960] train: loss: 0.0373341
[Epoch 3; Iter   240/  960] train: loss: 0.0406103
[Epoch 3; Iter   270/  960] train: loss: 0.1900294
[Epoch 3; Iter   300/  960] train: loss: 0.2650757
[Epoch 3; Iter   330/  960] train: loss: 0.2848505
[Epoch 3; Iter   360/  960] train: loss: 0.0289709
[Epoch 3; Iter   390/  960] train: loss: 0.0633635
[Epoch 3; Iter   420/  960] train: loss: 0.1527452
[Epoch 3; Iter   450/  960] train: loss: 0.0276714
[Epoch 3; Iter   480/  960] train: loss: 0.1197191
[Epoch 3; Iter   510/  960] train: loss: 0.1123386
[Epoch 3; Iter   540/  960] train: loss: 0.0286852
[Epoch 3; Iter   570/  960] train: loss: 0.1419161
[Epoch 3; Iter   600/  960] train: loss: 0.2016389
[Epoch 3; Iter   630/  960] train: loss: 0.2058395
[Epoch 3; Iter   660/  960] train: loss: 0.1786614
[Epoch 3; Iter   690/  960] train: loss: 0.0876205
[Epoch 3; Iter   720/  960] train: loss: 0.0302834
[Epoch 3; Iter   750/  960] train: loss: 0.2423417
[Epoch 3; Iter   780/  960] train: loss: 0.0400926
[Epoch 3; Iter   810/  960] train: loss: 0.0233090
[Epoch 3; Iter   840/  960] train: loss: 0.0230840
[Epoch 3; Iter   870/  960] train: loss: 0.0396896
[Epoch 3; Iter   900/  960] train: loss: 0.0261537
[Epoch 3; Iter   930/  960] train: loss: 0.0440760
[Epoch 3; Iter   960/  960] train: loss: 0.0328680
[Epoch 3] ogbg-molhiv: 0.699697 val loss: 0.164151
[Epoch 3] ogbg-molhiv: 0.710052 test loss: 0.150443
[Epoch 4; Iter    30/  960] train: loss: 0.1255587
[Epoch 4; Iter    60/  960] train: loss: 0.1580859
[Epoch 4; Iter    90/  960] train: loss: 0.0559109
[Epoch 4; Iter   120/  960] train: loss: 0.0509296
[Epoch 4; Iter   150/  960] train: loss: 0.1718819
[Epoch 4; Iter   180/  960] train: loss: 0.0276616
[Epoch 4; Iter   210/  960] train: loss: 0.0297103
[Epoch 4; Iter   240/  960] train: loss: 0.1662452[ Using Seed :  5  ]
using device:  cuda:1
Log directory:  runs/split/GraphCL/hiv/random/train_prop=0.7/PNA_ogbg-molhiv_GraphCL_hiv_random=0.7_5_26-05_09-40-08
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/hiv/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_random=0.7
logdir: runs/split/GraphCL/hiv/random/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  960] train: loss: 0.6950808
[Epoch 1; Iter    60/  960] train: loss: 0.6933433
[Epoch 1; Iter    90/  960] train: loss: 0.6927552
[Epoch 1; Iter   120/  960] train: loss: 0.6923700
[Epoch 1; Iter   150/  960] train: loss: 0.6918921
[Epoch 1; Iter   180/  960] train: loss: 0.6928959
[Epoch 1; Iter   210/  960] train: loss: 0.6909716
[Epoch 1; Iter   240/  960] train: loss: 0.6889312
[Epoch 1; Iter   270/  960] train: loss: 0.6889448
[Epoch 1; Iter   300/  960] train: loss: 0.6886354
[Epoch 1; Iter   330/  960] train: loss: 0.6873901
[Epoch 1; Iter   360/  960] train: loss: 0.6856291
[Epoch 1; Iter   390/  960] train: loss: 0.6840268
[Epoch 1; Iter   420/  960] train: loss: 0.6827875
[Epoch 1; Iter   450/  960] train: loss: 0.6813579
[Epoch 1; Iter   480/  960] train: loss: 0.6796964
[Epoch 1; Iter   510/  960] train: loss: 0.6801865
[Epoch 1; Iter   540/  960] train: loss: 0.6778806
[Epoch 1; Iter   570/  960] train: loss: 0.6787404
[Epoch 1; Iter   600/  960] train: loss: 0.6722245
[Epoch 1; Iter   630/  960] train: loss: 0.6700927
[Epoch 1; Iter   660/  960] train: loss: 0.6690115
[Epoch 1; Iter   690/  960] train: loss: 0.6687624
[Epoch 1; Iter   720/  960] train: loss: 0.6610394
[Epoch 1; Iter   750/  960] train: loss: 0.6494238
[Epoch 1; Iter   780/  960] train: loss: 0.6134797
[Epoch 1; Iter   810/  960] train: loss: 0.5546563
[Epoch 1; Iter   840/  960] train: loss: 0.5177014
[Epoch 1; Iter   870/  960] train: loss: 0.4758312
[Epoch 1; Iter   900/  960] train: loss: 0.3868777
[Epoch 1; Iter   930/  960] train: loss: 0.3491366
[Epoch 1; Iter   960/  960] train: loss: 0.2224247
[Epoch 1] ogbg-molhiv: 0.680139 val loss: 0.261275
[Epoch 1] ogbg-molhiv: 0.657906 test loss: 0.257935
[Epoch 2; Iter    30/  960] train: loss: 0.1804269
[Epoch 2; Iter    60/  960] train: loss: 0.2104548
[Epoch 2; Iter    90/  960] train: loss: 0.1122620
[Epoch 2; Iter   120/  960] train: loss: 0.1601851
[Epoch 2; Iter   150/  960] train: loss: 0.1785386
[Epoch 2; Iter   180/  960] train: loss: 0.1626121
[Epoch 2; Iter   210/  960] train: loss: 0.0633738
[Epoch 2; Iter   240/  960] train: loss: 0.0640578
[Epoch 2; Iter   270/  960] train: loss: 0.1609623
[Epoch 2; Iter   300/  960] train: loss: 0.1056762
[Epoch 2; Iter   330/  960] train: loss: 0.0436777
[Epoch 2; Iter   360/  960] train: loss: 0.5700745
[Epoch 2; Iter   390/  960] train: loss: 0.0486854
[Epoch 2; Iter   420/  960] train: loss: 0.1389208
[Epoch 2; Iter   450/  960] train: loss: 0.1691841
[Epoch 2; Iter   480/  960] train: loss: 0.0395996
[Epoch 2; Iter   510/  960] train: loss: 0.1506494
[Epoch 2; Iter   540/  960] train: loss: 0.0413034
[Epoch 2; Iter   570/  960] train: loss: 0.1790319
[Epoch 2; Iter   600/  960] train: loss: 0.0330026
[Epoch 2; Iter   630/  960] train: loss: 0.1584971
[Epoch 2; Iter   660/  960] train: loss: 0.0837229
[Epoch 2; Iter   690/  960] train: loss: 0.2974898
[Epoch 2; Iter   720/  960] train: loss: 0.0342944
[Epoch 2; Iter   750/  960] train: loss: 0.4301601
[Epoch 2; Iter   780/  960] train: loss: 0.0293712
[Epoch 2; Iter   810/  960] train: loss: 0.0311552
[Epoch 2; Iter   840/  960] train: loss: 0.0302001
[Epoch 2; Iter   870/  960] train: loss: 0.1395462
[Epoch 2; Iter   900/  960] train: loss: 0.2110918
[Epoch 2; Iter   930/  960] train: loss: 0.1562722
[Epoch 2; Iter   960/  960] train: loss: 0.0264419
[Epoch 2] ogbg-molhiv: 0.691143 val loss: 0.154271
[Epoch 2] ogbg-molhiv: 0.697637 test loss: 0.146049
[Epoch 3; Iter    30/  960] train: loss: 0.2242941
[Epoch 3; Iter    60/  960] train: loss: 0.0706140
[Epoch 3; Iter    90/  960] train: loss: 0.0518444
[Epoch 3; Iter   120/  960] train: loss: 0.1677475
[Epoch 3; Iter   150/  960] train: loss: 0.2358103
[Epoch 3; Iter   180/  960] train: loss: 0.1103721
[Epoch 3; Iter   210/  960] train: loss: 0.0382186
[Epoch 3; Iter   240/  960] train: loss: 0.1670456
[Epoch 3; Iter   270/  960] train: loss: 0.0360462
[Epoch 3; Iter   300/  960] train: loss: 0.1475368
[Epoch 3; Iter   330/  960] train: loss: 0.0255410
[Epoch 3; Iter   360/  960] train: loss: 0.1482527
[Epoch 3; Iter   390/  960] train: loss: 0.0341966
[Epoch 3; Iter   420/  960] train: loss: 0.0887925
[Epoch 3; Iter   450/  960] train: loss: 0.2268573
[Epoch 3; Iter   480/  960] train: loss: 0.2737169
[Epoch 3; Iter   510/  960] train: loss: 0.1751031
[Epoch 3; Iter   540/  960] train: loss: 0.0271001
[Epoch 3; Iter   570/  960] train: loss: 0.0290538
[Epoch 3; Iter   600/  960] train: loss: 0.1664951
[Epoch 3; Iter   630/  960] train: loss: 0.0608367
[Epoch 3; Iter   660/  960] train: loss: 0.1593586
[Epoch 3; Iter   690/  960] train: loss: 0.0369197
[Epoch 3; Iter   720/  960] train: loss: 0.0692739
[Epoch 3; Iter   750/  960] train: loss: 0.0296303
[Epoch 3; Iter   780/  960] train: loss: 0.2795648
[Epoch 3; Iter   810/  960] train: loss: 0.1135042
[Epoch 3; Iter   840/  960] train: loss: 0.2103750
[Epoch 3; Iter   870/  960] train: loss: 0.3374764
[Epoch 3; Iter   900/  960] train: loss: 0.0346951
[Epoch 3; Iter   930/  960] train: loss: 0.0656058
[Epoch 3; Iter   960/  960] train: loss: 0.3276380
[Epoch 3] ogbg-molhiv: 0.714067 val loss: 0.149481
[Epoch 3] ogbg-molhiv: 0.668920 test loss: 0.147670
[Epoch 4; Iter    30/  960] train: loss: 0.0575749
[Epoch 4; Iter    60/  960] train: loss: 0.0350459
[Epoch 4; Iter    90/  960] train: loss: 0.0261891
[Epoch 4; Iter   120/  960] train: loss: 0.0334312
[Epoch 4; Iter   150/  960] train: loss: 0.1131352
[Epoch 4; Iter   180/  960] train: loss: 0.1987303
[Epoch 4; Iter   210/  960] train: loss: 0.1537443
[Epoch 4; Iter   240/  960] train: loss: 0.1802671[ Using Seed :  4  ]
using device:  cuda:1
Log directory:  runs/split/GraphCL/hiv/random/train_prop=0.7/PNA_ogbg-molhiv_GraphCL_hiv_random=0.7_4_26-05_09-40-09
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/hiv/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_random=0.7
logdir: runs/split/GraphCL/hiv/random/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  960] train: loss: 0.6931745
[Epoch 1; Iter    60/  960] train: loss: 0.6930766
[Epoch 1; Iter    90/  960] train: loss: 0.6920098
[Epoch 1; Iter   120/  960] train: loss: 0.6925789
[Epoch 1; Iter   150/  960] train: loss: 0.6917626
[Epoch 1; Iter   180/  960] train: loss: 0.6909534
[Epoch 1; Iter   210/  960] train: loss: 0.6910671
[Epoch 1; Iter   240/  960] train: loss: 0.6898322
[Epoch 1; Iter   270/  960] train: loss: 0.6897534
[Epoch 1; Iter   300/  960] train: loss: 0.6885035
[Epoch 1; Iter   330/  960] train: loss: 0.6874634
[Epoch 1; Iter   360/  960] train: loss: 0.6858495
[Epoch 1; Iter   390/  960] train: loss: 0.6841341
[Epoch 1; Iter   420/  960] train: loss: 0.6809217
[Epoch 1; Iter   450/  960] train: loss: 0.6830016
[Epoch 1; Iter   480/  960] train: loss: 0.6803129
[Epoch 1; Iter   510/  960] train: loss: 0.6776710
[Epoch 1; Iter   540/  960] train: loss: 0.6761764
[Epoch 1; Iter   570/  960] train: loss: 0.6747358
[Epoch 1; Iter   600/  960] train: loss: 0.6726519
[Epoch 1; Iter   630/  960] train: loss: 0.6708122
[Epoch 1; Iter   660/  960] train: loss: 0.6691320
[Epoch 1; Iter   690/  960] train: loss: 0.6649060
[Epoch 1; Iter   720/  960] train: loss: 0.6628976
[Epoch 1; Iter   750/  960] train: loss: 0.6411530
[Epoch 1; Iter   780/  960] train: loss: 0.6144215
[Epoch 1; Iter   810/  960] train: loss: 0.5588645
[Epoch 1; Iter   840/  960] train: loss: 0.4997583
[Epoch 1; Iter   870/  960] train: loss: 0.4898554
[Epoch 1; Iter   900/  960] train: loss: 0.3773448
[Epoch 1; Iter   930/  960] train: loss: 0.2901801
[Epoch 1; Iter   960/  960] train: loss: 0.2759682
[Epoch 1] ogbg-molhiv: 0.692771 val loss: 0.264970
[Epoch 1] ogbg-molhiv: 0.672654 test loss: 0.262047
[Epoch 2; Iter    30/  960] train: loss: 0.4066832
[Epoch 2; Iter    60/  960] train: loss: 0.2735022
[Epoch 2; Iter    90/  960] train: loss: 0.1152306
[Epoch 2; Iter   120/  960] train: loss: 0.1666192
[Epoch 2; Iter   150/  960] train: loss: 0.1973728
[Epoch 2; Iter   180/  960] train: loss: 0.0631287
[Epoch 2; Iter   210/  960] train: loss: 0.2423106
[Epoch 2; Iter   240/  960] train: loss: 0.2469640
[Epoch 2; Iter   270/  960] train: loss: 0.1800408
[Epoch 2; Iter   300/  960] train: loss: 0.0416505
[Epoch 2; Iter   330/  960] train: loss: 0.0378191
[Epoch 2; Iter   360/  960] train: loss: 0.0380563
[Epoch 2; Iter   390/  960] train: loss: 0.5219272
[Epoch 2; Iter   420/  960] train: loss: 0.2432767
[Epoch 2; Iter   450/  960] train: loss: 0.0851849
[Epoch 2; Iter   480/  960] train: loss: 0.2100702
[Epoch 2; Iter   510/  960] train: loss: 0.2433985
[Epoch 2; Iter   540/  960] train: loss: 0.0342105
[Epoch 2; Iter   570/  960] train: loss: 0.0341653
[Epoch 2; Iter   600/  960] train: loss: 0.0743729
[Epoch 2; Iter   630/  960] train: loss: 0.0440448
[Epoch 2; Iter   660/  960] train: loss: 0.0313611
[Epoch 2; Iter   690/  960] train: loss: 0.0405864
[Epoch 2; Iter   720/  960] train: loss: 0.1695401
[Epoch 2; Iter   750/  960] train: loss: 0.1952935
[Epoch 2; Iter   780/  960] train: loss: 0.0257996
[Epoch 2; Iter   810/  960] train: loss: 0.0363987
[Epoch 2; Iter   840/  960] train: loss: 0.0306515
[Epoch 2; Iter   870/  960] train: loss: 0.0366757
[Epoch 2; Iter   900/  960] train: loss: 0.2714091
[Epoch 2; Iter   930/  960] train: loss: 0.1142151
[Epoch 2; Iter   960/  960] train: loss: 0.3694291
[Epoch 2] ogbg-molhiv: 0.605890 val loss: 0.406427
[Epoch 2] ogbg-molhiv: 0.642636 test loss: 0.414199
[Epoch 3; Iter    30/  960] train: loss: 0.0331805
[Epoch 3; Iter    60/  960] train: loss: 0.0997881
[Epoch 3; Iter    90/  960] train: loss: 0.1587745
[Epoch 3; Iter   120/  960] train: loss: 0.2120764
[Epoch 3; Iter   150/  960] train: loss: 0.2499190
[Epoch 3; Iter   180/  960] train: loss: 0.2189330
[Epoch 3; Iter   210/  960] train: loss: 0.0402121
[Epoch 3; Iter   240/  960] train: loss: 0.1648232
[Epoch 3; Iter   270/  960] train: loss: 0.2130415
[Epoch 3; Iter   300/  960] train: loss: 0.1260864
[Epoch 3; Iter   330/  960] train: loss: 0.0908152
[Epoch 3; Iter   360/  960] train: loss: 0.1545085
[Epoch 3; Iter   390/  960] train: loss: 0.1295291
[Epoch 3; Iter   420/  960] train: loss: 0.0318303
[Epoch 3; Iter   450/  960] train: loss: 0.0402276
[Epoch 3; Iter   480/  960] train: loss: 0.0661166
[Epoch 3; Iter   510/  960] train: loss: 0.0501513
[Epoch 3; Iter   540/  960] train: loss: 0.0288789
[Epoch 3; Iter   570/  960] train: loss: 0.0434968
[Epoch 3; Iter   600/  960] train: loss: 0.4822484
[Epoch 3; Iter   630/  960] train: loss: 0.0349100
[Epoch 3; Iter   660/  960] train: loss: 0.1070169
[Epoch 3; Iter   690/  960] train: loss: 0.1872682
[Epoch 3; Iter   720/  960] train: loss: 0.0397505
[Epoch 3; Iter   750/  960] train: loss: 0.2698291
[Epoch 3; Iter   780/  960] train: loss: 0.1264113
[Epoch 3; Iter   810/  960] train: loss: 0.0299251
[Epoch 3; Iter   840/  960] train: loss: 0.0710574
[Epoch 3; Iter   870/  960] train: loss: 0.3509566
[Epoch 3; Iter   900/  960] train: loss: 0.2185784
[Epoch 3; Iter   930/  960] train: loss: 0.0390755
[Epoch 3; Iter   960/  960] train: loss: 0.2493771
[Epoch 3] ogbg-molhiv: 0.676729 val loss: 0.165645
[Epoch 3] ogbg-molhiv: 0.685956 test loss: 0.148799
[Epoch 4; Iter    30/  960] train: loss: 0.3355858
[Epoch 4; Iter    60/  960] train: loss: 0.0493739
[Epoch 4; Iter    90/  960] train: loss: 0.1629488
[Epoch 4; Iter   120/  960] train: loss: 0.1647354
[Epoch 4; Iter   150/  960] train: loss: 0.1788576
[Epoch 4; Iter   180/  960] train: loss: 0.1535857
[Epoch 4; Iter   210/  960] train: loss: 0.0291910
[Epoch 4; Iter   240/  960] train: loss: 0.0285564[ Using Seed :  6  ]
using device:  cuda:0
Log directory:  runs/split/GraphCL/hiv/random/train_prop=0.6/PNA_ogbg-molhiv_GraphCL_hiv_random=0.6_6_26-05_09-40-09
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/hiv/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_random=0.6
logdir: runs/split/GraphCL/hiv/random/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  823] train: loss: 0.6940826
[Epoch 1; Iter    60/  823] train: loss: 0.6957303
[Epoch 1; Iter    90/  823] train: loss: 0.6927918
[Epoch 1; Iter   120/  823] train: loss: 0.6956185
[Epoch 1; Iter   150/  823] train: loss: 0.6933348
[Epoch 1; Iter   180/  823] train: loss: 0.6913296
[Epoch 1; Iter   210/  823] train: loss: 0.6907937
[Epoch 1; Iter   240/  823] train: loss: 0.6900871
[Epoch 1; Iter   270/  823] train: loss: 0.6889383
[Epoch 1; Iter   300/  823] train: loss: 0.6879273
[Epoch 1; Iter   330/  823] train: loss: 0.6868633
[Epoch 1; Iter   360/  823] train: loss: 0.6883980
[Epoch 1; Iter   390/  823] train: loss: 0.6843687
[Epoch 1; Iter   420/  823] train: loss: 0.6835534
[Epoch 1; Iter   450/  823] train: loss: 0.6814657
[Epoch 1; Iter   480/  823] train: loss: 0.6797942
[Epoch 1; Iter   510/  823] train: loss: 0.6801375
[Epoch 1; Iter   540/  823] train: loss: 0.6784438
[Epoch 1; Iter   570/  823] train: loss: 0.6743563
[Epoch 1; Iter   600/  823] train: loss: 0.6723729
[Epoch 1; Iter   630/  823] train: loss: 0.6702018
[Epoch 1; Iter   660/  823] train: loss: 0.6680649
[Epoch 1; Iter   690/  823] train: loss: 0.6657948
[Epoch 1; Iter   720/  823] train: loss: 0.6641289
[Epoch 1; Iter   750/  823] train: loss: 0.6446182
[Epoch 1; Iter   780/  823] train: loss: 0.6042725
[Epoch 1; Iter   810/  823] train: loss: 0.5757071
[Epoch 1] ogbg-molhiv: 0.651645 val loss: 0.565696
[Epoch 1] ogbg-molhiv: 0.640552 test loss: 0.566219
[Epoch 2; Iter    17/  823] train: loss: 0.4976459
[Epoch 2; Iter    47/  823] train: loss: 0.4216581
[Epoch 2; Iter    77/  823] train: loss: 0.3504124
[Epoch 2; Iter   107/  823] train: loss: 0.3378813
[Epoch 2; Iter   137/  823] train: loss: 0.2673827
[Epoch 2; Iter   167/  823] train: loss: 0.2411434
[Epoch 2; Iter   197/  823] train: loss: 0.1973947
[Epoch 2; Iter   227/  823] train: loss: 0.2626860
[Epoch 2; Iter   257/  823] train: loss: 0.1695396
[Epoch 2; Iter   287/  823] train: loss: 0.0788490
[Epoch 2; Iter   317/  823] train: loss: 0.1672126
[Epoch 2; Iter   347/  823] train: loss: 0.0632382
[Epoch 2; Iter   377/  823] train: loss: 0.1775854
[Epoch 2; Iter   407/  823] train: loss: 0.3540565
[Epoch 2; Iter   437/  823] train: loss: 0.2801736
[Epoch 2; Iter   467/  823] train: loss: 0.0440780
[Epoch 2; Iter   497/  823] train: loss: 0.1558799
[Epoch 2; Iter   527/  823] train: loss: 0.0352415
[Epoch 2; Iter   557/  823] train: loss: 0.0770926
[Epoch 2; Iter   587/  823] train: loss: 0.1557689
[Epoch 2; Iter   617/  823] train: loss: 0.0380920
[Epoch 2; Iter   647/  823] train: loss: 0.0378890
[Epoch 2; Iter   677/  823] train: loss: 0.0371747
[Epoch 2; Iter   707/  823] train: loss: 0.1537912
[Epoch 2; Iter   737/  823] train: loss: 0.0432984
[Epoch 2; Iter   767/  823] train: loss: 0.0352329
[Epoch 2; Iter   797/  823] train: loss: 0.1289129
[Epoch 2] ogbg-molhiv: 0.648617 val loss: 0.171226
[Epoch 2] ogbg-molhiv: 0.633763 test loss: 0.165269
[Epoch 3; Iter     4/  823] train: loss: 0.1880341
[Epoch 3; Iter    34/  823] train: loss: 0.1515812
[Epoch 3; Iter    64/  823] train: loss: 0.1590781
[Epoch 3; Iter    94/  823] train: loss: 0.0660357
[Epoch 3; Iter   124/  823] train: loss: 0.0353515
[Epoch 3; Iter   154/  823] train: loss: 0.0447044
[Epoch 3; Iter   184/  823] train: loss: 0.0335205
[Epoch 3; Iter   214/  823] train: loss: 0.0333126
[Epoch 3; Iter   244/  823] train: loss: 0.0318839
[Epoch 3; Iter   274/  823] train: loss: 0.0397218
[Epoch 3; Iter   304/  823] train: loss: 0.2866093
[Epoch 3; Iter   334/  823] train: loss: 0.2398796
[Epoch 3; Iter   364/  823] train: loss: 0.4067708
[Epoch 3; Iter   394/  823] train: loss: 0.1817068
[Epoch 3; Iter   424/  823] train: loss: 0.1767039
[Epoch 3; Iter   454/  823] train: loss: 0.2099250
[Epoch 3; Iter   484/  823] train: loss: 0.0693777
[Epoch 3; Iter   514/  823] train: loss: 0.1491274
[Epoch 3; Iter   544/  823] train: loss: 0.3362542
[Epoch 3; Iter   574/  823] train: loss: 0.3026689
[Epoch 3; Iter   604/  823] train: loss: 0.0422582
[Epoch 3; Iter   634/  823] train: loss: 0.0311713
[Epoch 3; Iter   664/  823] train: loss: 0.3308831
[Epoch 3; Iter   694/  823] train: loss: 0.4279157
[Epoch 3; Iter   724/  823] train: loss: 0.0376230
[Epoch 3; Iter   754/  823] train: loss: 0.0305826
[Epoch 3; Iter   784/  823] train: loss: 0.0365158
[Epoch 3; Iter   814/  823] train: loss: 0.0531897
[Epoch 3] ogbg-molhiv: 0.736059 val loss: 0.137882
[Epoch 3] ogbg-molhiv: 0.709340 test loss: 0.139419
[Epoch 4; Iter    21/  823] train: loss: 0.0356318
[Epoch 4; Iter    51/  823] train: loss: 0.0262028
[Epoch 4; Iter    81/  823] train: loss: 0.1498200
[Epoch 4; Iter   111/  823] train: loss: 0.0333828
[Epoch 4; Iter   141/  823] train: loss: 0.1849975
[Epoch 4; Iter   171/  823] train: loss: 0.2828385
[Epoch 4; Iter   201/  823] train: loss: 0.0408486
[Epoch 4; Iter   231/  823] train: loss: 0.0368108
[Epoch 4; Iter   261/  823] train: loss: 0.4810444
[Epoch 4; Iter   291/  823] train: loss: 0.3225240
[Epoch 4; Iter   321/  823] train: loss: 0.1284842
[Epoch 4; Iter   351/  823] train: loss: 0.1404045
[Epoch 4; Iter   381/  823] train: loss: 0.0375672
[Epoch 4; Iter   411/  823] train: loss: 0.0324575
[Epoch 4; Iter   441/  823] train: loss: 0.2888611
[Epoch 4; Iter   471/  823] train: loss: 0.2566728
[Epoch 4; Iter   501/  823] train: loss: 0.1374657
[Epoch 4; Iter   531/  823] train: loss: 0.1320619
[Epoch 4; Iter   561/  823] train: loss: 0.2223749
[Epoch 4; Iter   591/  823] train: loss: 0.0408347
[Epoch 4; Iter   621/  823] train: loss: 0.1795832
[Epoch 4; Iter   651/  823] train: loss: 0.0395486[ Using Seed :  4  ]
using device:  cuda:0
Log directory:  runs/split/GraphCL/hiv/random/train_prop=0.6/PNA_ogbg-molhiv_GraphCL_hiv_random=0.6_4_26-05_09-40-08
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/hiv/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_random=0.6
logdir: runs/split/GraphCL/hiv/random/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  823] train: loss: 0.6932152
[Epoch 1; Iter    60/  823] train: loss: 0.6930666
[Epoch 1; Iter    90/  823] train: loss: 0.6926542
[Epoch 1; Iter   120/  823] train: loss: 0.6923667
[Epoch 1; Iter   150/  823] train: loss: 0.6918321
[Epoch 1; Iter   180/  823] train: loss: 0.6918144
[Epoch 1; Iter   210/  823] train: loss: 0.6890434
[Epoch 1; Iter   240/  823] train: loss: 0.6907008
[Epoch 1; Iter   270/  823] train: loss: 0.6888645
[Epoch 1; Iter   300/  823] train: loss: 0.6881530
[Epoch 1; Iter   330/  823] train: loss: 0.6869489
[Epoch 1; Iter   360/  823] train: loss: 0.6858119
[Epoch 1; Iter   390/  823] train: loss: 0.6841558
[Epoch 1; Iter   420/  823] train: loss: 0.6846339
[Epoch 1; Iter   450/  823] train: loss: 0.6833091
[Epoch 1; Iter   480/  823] train: loss: 0.6794493
[Epoch 1; Iter   510/  823] train: loss: 0.6799549
[Epoch 1; Iter   540/  823] train: loss: 0.6781010
[Epoch 1; Iter   570/  823] train: loss: 0.6735628
[Epoch 1; Iter   600/  823] train: loss: 0.6718391
[Epoch 1; Iter   630/  823] train: loss: 0.6714597
[Epoch 1; Iter   660/  823] train: loss: 0.6680356
[Epoch 1; Iter   690/  823] train: loss: 0.6673365
[Epoch 1; Iter   720/  823] train: loss: 0.6634389
[Epoch 1; Iter   750/  823] train: loss: 0.6479921
[Epoch 1; Iter   780/  823] train: loss: 0.6048871
[Epoch 1; Iter   810/  823] train: loss: 0.5564882
[Epoch 1] ogbg-molhiv: 0.664569 val loss: 0.510937
[Epoch 1] ogbg-molhiv: 0.656877 test loss: 0.511765
[Epoch 2; Iter    17/  823] train: loss: 0.5045117
[Epoch 2; Iter    47/  823] train: loss: 0.4303384
[Epoch 2; Iter    77/  823] train: loss: 0.4024409
[Epoch 2; Iter   107/  823] train: loss: 0.2943643
[Epoch 2; Iter   137/  823] train: loss: 0.3030167
[Epoch 2; Iter   167/  823] train: loss: 0.1815652
[Epoch 2; Iter   197/  823] train: loss: 0.2590920
[Epoch 2; Iter   227/  823] train: loss: 0.1702404
[Epoch 2; Iter   257/  823] train: loss: 0.1725137
[Epoch 2; Iter   287/  823] train: loss: 0.0800763
[Epoch 2; Iter   317/  823] train: loss: 0.2345428
[Epoch 2; Iter   347/  823] train: loss: 0.1533054
[Epoch 2; Iter   377/  823] train: loss: 0.0490515
[Epoch 2; Iter   407/  823] train: loss: 0.0522854
[Epoch 2; Iter   437/  823] train: loss: 0.2599160
[Epoch 2; Iter   467/  823] train: loss: 0.0382603
[Epoch 2; Iter   497/  823] train: loss: 0.0363967
[Epoch 2; Iter   527/  823] train: loss: 0.2243548
[Epoch 2; Iter   557/  823] train: loss: 0.1828428
[Epoch 2; Iter   587/  823] train: loss: 0.1585313
[Epoch 2; Iter   617/  823] train: loss: 0.1641221
[Epoch 2; Iter   647/  823] train: loss: 0.0428108
[Epoch 2; Iter   677/  823] train: loss: 0.2744464
[Epoch 2; Iter   707/  823] train: loss: 0.2671812
[Epoch 2; Iter   737/  823] train: loss: 0.1362076
[Epoch 2; Iter   767/  823] train: loss: 0.3074194
[Epoch 2; Iter   797/  823] train: loss: 0.0495843
[Epoch 2] ogbg-molhiv: 0.638198 val loss: 0.381374
[Epoch 2] ogbg-molhiv: 0.611326 test loss: 0.395602
[Epoch 3; Iter     4/  823] train: loss: 0.0367752
[Epoch 3; Iter    34/  823] train: loss: 0.0822672
[Epoch 3; Iter    64/  823] train: loss: 0.0307470
[Epoch 3; Iter    94/  823] train: loss: 0.0405860
[Epoch 3; Iter   124/  823] train: loss: 0.1552657
[Epoch 3; Iter   154/  823] train: loss: 0.0300660
[Epoch 3; Iter   184/  823] train: loss: 0.3292382
[Epoch 3; Iter   214/  823] train: loss: 0.3337326
[Epoch 3; Iter   244/  823] train: loss: 0.0829656
[Epoch 3; Iter   274/  823] train: loss: 0.1981875
[Epoch 3; Iter   304/  823] train: loss: 0.0327064
[Epoch 3; Iter   334/  823] train: loss: 0.3273386
[Epoch 3; Iter   364/  823] train: loss: 0.0408572
[Epoch 3; Iter   394/  823] train: loss: 0.0902431
[Epoch 3; Iter   424/  823] train: loss: 0.2879456
[Epoch 3; Iter   454/  823] train: loss: 0.0856920
[Epoch 3; Iter   484/  823] train: loss: 0.3701356
[Epoch 3; Iter   514/  823] train: loss: 0.0356962
[Epoch 3; Iter   544/  823] train: loss: 0.2508917
[Epoch 3; Iter   574/  823] train: loss: 0.0635346
[Epoch 3; Iter   604/  823] train: loss: 0.5224375
[Epoch 3; Iter   634/  823] train: loss: 0.0326765
[Epoch 3; Iter   664/  823] train: loss: 0.2446110
[Epoch 3; Iter   694/  823] train: loss: 0.1537562
[Epoch 3; Iter   724/  823] train: loss: 0.1935222
[Epoch 3; Iter   754/  823] train: loss: 0.3277437
[Epoch 3; Iter   784/  823] train: loss: 0.0490268
[Epoch 3; Iter   814/  823] train: loss: 0.0305002
[Epoch 3] ogbg-molhiv: 0.677676 val loss: 0.146290
[Epoch 3] ogbg-molhiv: 0.665384 test loss: 0.151030
[Epoch 4; Iter    21/  823] train: loss: 0.2861581
[Epoch 4; Iter    51/  823] train: loss: 0.0419416
[Epoch 4; Iter    81/  823] train: loss: 0.2056941
[Epoch 4; Iter   111/  823] train: loss: 0.1724346
[Epoch 4; Iter   141/  823] train: loss: 0.0312284
[Epoch 4; Iter   171/  823] train: loss: 0.1469094
[Epoch 4; Iter   201/  823] train: loss: 0.1294362
[Epoch 4; Iter   231/  823] train: loss: 0.2140022
[Epoch 4; Iter   261/  823] train: loss: 0.2069367
[Epoch 4; Iter   291/  823] train: loss: 0.1067591
[Epoch 4; Iter   321/  823] train: loss: 0.0282411
[Epoch 4; Iter   351/  823] train: loss: 0.1760122
[Epoch 4; Iter   381/  823] train: loss: 0.0892041
[Epoch 4; Iter   411/  823] train: loss: 0.0284088
[Epoch 4; Iter   441/  823] train: loss: 0.1678910
[Epoch 4; Iter   471/  823] train: loss: 0.0272803
[Epoch 4; Iter   501/  823] train: loss: 0.1909935
[Epoch 4; Iter   531/  823] train: loss: 0.2347821
[Epoch 4; Iter   561/  823] train: loss: 0.1717032
[Epoch 4; Iter   591/  823] train: loss: 0.1948782
[Epoch 4; Iter   621/  823] train: loss: 0.0433209
[Epoch 4; Iter   651/  823] train: loss: 0.0389533[ Using Seed :  5  ]
using device:  cuda:0
Log directory:  runs/split/GraphCL/hiv/random/train_prop=0.6/PNA_ogbg-molhiv_GraphCL_hiv_random=0.6_5_26-05_09-40-08
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/hiv/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_random=0.6
logdir: runs/split/GraphCL/hiv/random/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  823] train: loss: 0.6922702
[Epoch 1; Iter    60/  823] train: loss: 0.6919308
[Epoch 1; Iter    90/  823] train: loss: 0.6953924
[Epoch 1; Iter   120/  823] train: loss: 0.6947583
[Epoch 1; Iter   150/  823] train: loss: 0.6907884
[Epoch 1; Iter   180/  823] train: loss: 0.6912435
[Epoch 1; Iter   210/  823] train: loss: 0.6906430
[Epoch 1; Iter   240/  823] train: loss: 0.6927214
[Epoch 1; Iter   270/  823] train: loss: 0.6889308
[Epoch 1; Iter   300/  823] train: loss: 0.6879088
[Epoch 1; Iter   330/  823] train: loss: 0.6871088
[Epoch 1; Iter   360/  823] train: loss: 0.6859624
[Epoch 1; Iter   390/  823] train: loss: 0.6842621
[Epoch 1; Iter   420/  823] train: loss: 0.6828276
[Epoch 1; Iter   450/  823] train: loss: 0.6812891
[Epoch 1; Iter   480/  823] train: loss: 0.6800192
[Epoch 1; Iter   510/  823] train: loss: 0.6781490
[Epoch 1; Iter   540/  823] train: loss: 0.6768780
[Epoch 1; Iter   570/  823] train: loss: 0.6742211
[Epoch 1; Iter   600/  823] train: loss: 0.6729119
[Epoch 1; Iter   630/  823] train: loss: 0.6753790
[Epoch 1; Iter   660/  823] train: loss: 0.6678896
[Epoch 1; Iter   690/  823] train: loss: 0.6675649
[Epoch 1; Iter   720/  823] train: loss: 0.6634002
[Epoch 1; Iter   750/  823] train: loss: 0.6443152
[Epoch 1; Iter   780/  823] train: loss: 0.6059877
[Epoch 1; Iter   810/  823] train: loss: 0.5706279
[Epoch 1] ogbg-molhiv: 0.674539 val loss: 0.561804
[Epoch 1] ogbg-molhiv: 0.664742 test loss: 0.561924
[Epoch 2; Iter    17/  823] train: loss: 0.4931634
[Epoch 2; Iter    47/  823] train: loss: 0.4446682
[Epoch 2; Iter    77/  823] train: loss: 0.3680227
[Epoch 2; Iter   107/  823] train: loss: 0.3222705
[Epoch 2; Iter   137/  823] train: loss: 0.2377977
[Epoch 2; Iter   167/  823] train: loss: 0.2948169
[Epoch 2; Iter   197/  823] train: loss: 0.1838312
[Epoch 2; Iter   227/  823] train: loss: 0.2982241
[Epoch 2; Iter   257/  823] train: loss: 0.1622520
[Epoch 2; Iter   287/  823] train: loss: 0.1304259
[Epoch 2; Iter   317/  823] train: loss: 0.1665664
[Epoch 2; Iter   347/  823] train: loss: 0.0631562
[Epoch 2; Iter   377/  823] train: loss: 0.0578307
[Epoch 2; Iter   407/  823] train: loss: 0.1917659
[Epoch 2; Iter   437/  823] train: loss: 0.2999719
[Epoch 2; Iter   467/  823] train: loss: 0.0741166
[Epoch 2; Iter   497/  823] train: loss: 0.0390431
[Epoch 2; Iter   527/  823] train: loss: 0.2123274
[Epoch 2; Iter   557/  823] train: loss: 0.2221209
[Epoch 2; Iter   587/  823] train: loss: 0.0456520
[Epoch 2; Iter   617/  823] train: loss: 0.2421828
[Epoch 2; Iter   647/  823] train: loss: 0.1217707
[Epoch 2; Iter   677/  823] train: loss: 0.1552291
[Epoch 2; Iter   707/  823] train: loss: 0.2354419
[Epoch 2; Iter   737/  823] train: loss: 0.0365850
[Epoch 2; Iter   767/  823] train: loss: 0.2450530
[Epoch 2; Iter   797/  823] train: loss: 0.1594969
[Epoch 2] ogbg-molhiv: 0.654491 val loss: 0.148313
[Epoch 2] ogbg-molhiv: 0.640894 test loss: 0.153510
[Epoch 3; Iter     4/  823] train: loss: 0.2688124
[Epoch 3; Iter    34/  823] train: loss: 0.0275839
[Epoch 3; Iter    64/  823] train: loss: 0.0676945
[Epoch 3; Iter    94/  823] train: loss: 0.1834215
[Epoch 3; Iter   124/  823] train: loss: 0.3797829
[Epoch 3; Iter   154/  823] train: loss: 0.0320049
[Epoch 3; Iter   184/  823] train: loss: 0.1294991
[Epoch 3; Iter   214/  823] train: loss: 0.2830827
[Epoch 3; Iter   244/  823] train: loss: 0.2533953
[Epoch 3; Iter   274/  823] train: loss: 0.3066975
[Epoch 3; Iter   304/  823] train: loss: 0.1573444
[Epoch 3; Iter   334/  823] train: loss: 0.2074532
[Epoch 3; Iter   364/  823] train: loss: 0.1309693
[Epoch 3; Iter   394/  823] train: loss: 0.1006661
[Epoch 3; Iter   424/  823] train: loss: 0.1958225
[Epoch 3; Iter   454/  823] train: loss: 0.0402583
[Epoch 3; Iter   484/  823] train: loss: 0.2466479
[Epoch 3; Iter   514/  823] train: loss: 0.1447384
[Epoch 3; Iter   544/  823] train: loss: 0.1415868
[Epoch 3; Iter   574/  823] train: loss: 0.1379820
[Epoch 3; Iter   604/  823] train: loss: 0.1062740
[Epoch 3; Iter   634/  823] train: loss: 0.0365279
[Epoch 3; Iter   664/  823] train: loss: 0.0322071
[Epoch 3; Iter   694/  823] train: loss: 0.1500950
[Epoch 3; Iter   724/  823] train: loss: 0.1591018
[Epoch 3; Iter   754/  823] train: loss: 0.0947709
[Epoch 3; Iter   784/  823] train: loss: 0.0303692
[Epoch 3; Iter   814/  823] train: loss: 0.0993170
[Epoch 3] ogbg-molhiv: 0.738602 val loss: 0.131782
[Epoch 3] ogbg-molhiv: 0.712588 test loss: 0.138643
[Epoch 4; Iter    21/  823] train: loss: 0.0400864
[Epoch 4; Iter    51/  823] train: loss: 0.1100683
[Epoch 4; Iter    81/  823] train: loss: 0.0289736
[Epoch 4; Iter   111/  823] train: loss: 0.1572999
[Epoch 4; Iter   141/  823] train: loss: 0.0290443
[Epoch 4; Iter   171/  823] train: loss: 0.1344973
[Epoch 4; Iter   201/  823] train: loss: 0.1301694
[Epoch 4; Iter   231/  823] train: loss: 0.0327747
[Epoch 4; Iter   261/  823] train: loss: 0.1013719
[Epoch 4; Iter   291/  823] train: loss: 0.1135901
[Epoch 4; Iter   321/  823] train: loss: 0.0329298
[Epoch 4; Iter   351/  823] train: loss: 0.1693590
[Epoch 4; Iter   381/  823] train: loss: 0.0322408
[Epoch 4; Iter   411/  823] train: loss: 0.2103185
[Epoch 4; Iter   441/  823] train: loss: 0.1222274
[Epoch 4; Iter   471/  823] train: loss: 0.0353389
[Epoch 4; Iter   501/  823] train: loss: 0.3314518
[Epoch 4; Iter   531/  823] train: loss: 0.1061719
[Epoch 4; Iter   561/  823] train: loss: 0.0528338
[Epoch 4; Iter   591/  823] train: loss: 0.1241900
[Epoch 4; Iter   621/  823] train: loss: 0.0328959
[Epoch 4; Iter   651/  823] train: loss: 0.3113479[Epoch 3; Iter  1016/ 1097] train: loss: 0.1117132
[Epoch 3; Iter  1046/ 1097] train: loss: 0.1251338
[Epoch 3; Iter  1076/ 1097] train: loss: 0.0511048
[Epoch 3] ogbg-molhiv: 0.714984 val loss: 0.318168
[Epoch 3] ogbg-molhiv: 0.669181 test loss: 0.353671
[Epoch 4; Iter     9/ 1097] train: loss: 0.0317034
[Epoch 4; Iter    39/ 1097] train: loss: 0.0969799
[Epoch 4; Iter    69/ 1097] train: loss: 0.1566737
[Epoch 4; Iter    99/ 1097] train: loss: 0.0342167
[Epoch 4; Iter   129/ 1097] train: loss: 0.1671901
[Epoch 4; Iter   159/ 1097] train: loss: 0.0329291
[Epoch 4; Iter   189/ 1097] train: loss: 0.0754618
[Epoch 4; Iter   219/ 1097] train: loss: 0.0256671
[Epoch 4; Iter   249/ 1097] train: loss: 0.0431122
[Epoch 4; Iter   279/ 1097] train: loss: 0.1661476
[Epoch 4; Iter   309/ 1097] train: loss: 0.0418827
[Epoch 4; Iter   339/ 1097] train: loss: 0.1776767
[Epoch 4; Iter   369/ 1097] train: loss: 0.1985271
[Epoch 4; Iter   399/ 1097] train: loss: 0.1223724
[Epoch 4; Iter   429/ 1097] train: loss: 0.0976946
[Epoch 4; Iter   459/ 1097] train: loss: 0.3036037
[Epoch 4; Iter   489/ 1097] train: loss: 0.1231014
[Epoch 4; Iter   519/ 1097] train: loss: 0.1251704
[Epoch 4; Iter   549/ 1097] train: loss: 0.1004042
[Epoch 4; Iter   579/ 1097] train: loss: 0.0403813
[Epoch 4; Iter   609/ 1097] train: loss: 0.2231817
[Epoch 4; Iter   639/ 1097] train: loss: 0.0433671
[Epoch 4; Iter   669/ 1097] train: loss: 0.1173781
[Epoch 4; Iter   699/ 1097] train: loss: 0.0554407
[Epoch 4; Iter   729/ 1097] train: loss: 0.0322850
[Epoch 4; Iter   759/ 1097] train: loss: 0.2547470
[Epoch 4; Iter   789/ 1097] train: loss: 0.0782590
[Epoch 4; Iter   819/ 1097] train: loss: 0.1149343
[Epoch 4; Iter   849/ 1097] train: loss: 0.0257185
[Epoch 4; Iter   879/ 1097] train: loss: 0.0348597
[Epoch 4; Iter   909/ 1097] train: loss: 0.1645344
[Epoch 4; Iter   939/ 1097] train: loss: 0.0309460
[Epoch 4; Iter   969/ 1097] train: loss: 0.0276907
[Epoch 4; Iter   999/ 1097] train: loss: 0.1843646
[Epoch 4; Iter  1029/ 1097] train: loss: 0.4314297
[Epoch 4; Iter  1059/ 1097] train: loss: 0.1603041
[Epoch 4; Iter  1089/ 1097] train: loss: 0.0298783
[Epoch 4] ogbg-molhiv: 0.674910 val loss: 0.141173
[Epoch 4] ogbg-molhiv: 0.708407 test loss: 0.136549
[Epoch 5; Iter    22/ 1097] train: loss: 0.0405538
[Epoch 5; Iter    52/ 1097] train: loss: 0.0249002
[Epoch 5; Iter    82/ 1097] train: loss: 0.0842884
[Epoch 5; Iter   112/ 1097] train: loss: 0.2915212
[Epoch 5; Iter   142/ 1097] train: loss: 0.0638127
[Epoch 5; Iter   172/ 1097] train: loss: 0.0436815
[Epoch 5; Iter   202/ 1097] train: loss: 0.1422183
[Epoch 5; Iter   232/ 1097] train: loss: 0.3038321
[Epoch 5; Iter   262/ 1097] train: loss: 0.0267502
[Epoch 5; Iter   292/ 1097] train: loss: 0.1074948
[Epoch 5; Iter   322/ 1097] train: loss: 0.0427909
[Epoch 5; Iter   352/ 1097] train: loss: 0.0952841
[Epoch 5; Iter   382/ 1097] train: loss: 0.0450780
[Epoch 5; Iter   412/ 1097] train: loss: 0.0405415
[Epoch 5; Iter   442/ 1097] train: loss: 0.1528517
[Epoch 5; Iter   472/ 1097] train: loss: 0.0348680
[Epoch 5; Iter   502/ 1097] train: loss: 0.2967887
[Epoch 5; Iter   532/ 1097] train: loss: 0.1314828
[Epoch 5; Iter   562/ 1097] train: loss: 0.1421013
[Epoch 5; Iter   592/ 1097] train: loss: 0.0376991
[Epoch 5; Iter   622/ 1097] train: loss: 0.1518029
[Epoch 5; Iter   652/ 1097] train: loss: 0.0303857
[Epoch 5; Iter   682/ 1097] train: loss: 0.1555358
[Epoch 5; Iter   712/ 1097] train: loss: 0.0917746
[Epoch 5; Iter   742/ 1097] train: loss: 0.1567164
[Epoch 5; Iter   772/ 1097] train: loss: 0.2476123
[Epoch 5; Iter   802/ 1097] train: loss: 0.0393249
[Epoch 5; Iter   832/ 1097] train: loss: 0.0354855
[Epoch 5; Iter   862/ 1097] train: loss: 0.1618251
[Epoch 5; Iter   892/ 1097] train: loss: 0.0256377
[Epoch 5; Iter   922/ 1097] train: loss: 0.0583738
[Epoch 5; Iter   952/ 1097] train: loss: 0.0364075
[Epoch 5; Iter   982/ 1097] train: loss: 0.1659510
[Epoch 5; Iter  1012/ 1097] train: loss: 0.0391611
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2035110
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0253557
[Epoch 5] ogbg-molhiv: 0.716931 val loss: 0.206684
[Epoch 5] ogbg-molhiv: 0.721044 test loss: 0.196301
[Epoch 6; Iter     5/ 1097] train: loss: 0.1047743
[Epoch 6; Iter    35/ 1097] train: loss: 0.0351393
[Epoch 6; Iter    65/ 1097] train: loss: 0.1990878
[Epoch 6; Iter    95/ 1097] train: loss: 0.0556999
[Epoch 6; Iter   125/ 1097] train: loss: 0.0396119
[Epoch 6; Iter   155/ 1097] train: loss: 0.0981853
[Epoch 6; Iter   185/ 1097] train: loss: 0.2698246
[Epoch 6; Iter   215/ 1097] train: loss: 0.1358074
[Epoch 6; Iter   245/ 1097] train: loss: 0.0283616
[Epoch 6; Iter   275/ 1097] train: loss: 0.4495473
[Epoch 6; Iter   305/ 1097] train: loss: 0.1874772
[Epoch 6; Iter   335/ 1097] train: loss: 0.0323305
[Epoch 6; Iter   365/ 1097] train: loss: 0.1272715
[Epoch 6; Iter   395/ 1097] train: loss: 0.0348178
[Epoch 6; Iter   425/ 1097] train: loss: 0.0774877
[Epoch 6; Iter   455/ 1097] train: loss: 0.0630222
[Epoch 6; Iter   485/ 1097] train: loss: 0.0379579
[Epoch 6; Iter   515/ 1097] train: loss: 0.1013064
[Epoch 6; Iter   545/ 1097] train: loss: 0.1484751
[Epoch 6; Iter   575/ 1097] train: loss: 0.4253669
[Epoch 6; Iter   605/ 1097] train: loss: 0.1482210
[Epoch 6; Iter   635/ 1097] train: loss: 0.5348361
[Epoch 6; Iter   665/ 1097] train: loss: 0.0744882
[Epoch 6; Iter   695/ 1097] train: loss: 0.0305688
[Epoch 6; Iter   725/ 1097] train: loss: 0.2584174
[Epoch 6; Iter   755/ 1097] train: loss: 0.0343891
[Epoch 6; Iter   785/ 1097] train: loss: 0.1664431
[Epoch 6; Iter   815/ 1097] train: loss: 0.1869768
[Epoch 6; Iter   845/ 1097] train: loss: 0.0469348
[Epoch 6; Iter   875/ 1097] train: loss: 0.1220659
[Epoch 6; Iter   905/ 1097] train: loss: 0.1710736
[Epoch 6; Iter   935/ 1097] train: loss: 0.0284619
[Epoch 6; Iter   965/ 1097] train: loss: 0.1977800
[Epoch 6; Iter   995/ 1097] train: loss: 0.0297697
[Epoch 6; Iter  1025/ 1097] train: loss: 0.1209929
[Epoch 6; Iter  1055/ 1097] train: loss: 0.0248894
[Epoch 6; Iter  1085/ 1097] train: loss: 0.0361274
[Epoch 6] ogbg-molhiv: 0.735617 val loss: 0.134253
[Epoch 6] ogbg-molhiv: 0.676467 test loss: 0.136320
[Epoch 7; Iter    18/ 1097] train: loss: 0.2779030
[Epoch 7; Iter    48/ 1097] train: loss: 0.0336032
[Epoch 7; Iter    78/ 1097] train: loss: 0.1836297
[Epoch 7; Iter   108/ 1097] train: loss: 0.2576155
[Epoch 7; Iter   138/ 1097] train: loss: 0.1431435
[Epoch 7; Iter   168/ 1097] train: loss: 0.1390825
[Epoch 7; Iter   198/ 1097] train: loss: 0.0279148
[Epoch 7; Iter   228/ 1097] train: loss: 0.0398547
[Epoch 7; Iter   258/ 1097] train: loss: 0.1847132
[Epoch 7; Iter   288/ 1097] train: loss: 0.0309443
[Epoch 7; Iter   318/ 1097] train: loss: 0.0386507
[Epoch 7; Iter   348/ 1097] train: loss: 0.2250088
[Epoch 7; Iter   378/ 1097] train: loss: 0.0317335
[Epoch 7; Iter   408/ 1097] train: loss: 0.2387205
[Epoch 7; Iter   438/ 1097] train: loss: 0.1684007
[Epoch 7; Iter   468/ 1097] train: loss: 0.1688510
[Epoch 7; Iter   498/ 1097] train: loss: 0.2310156
[Epoch 7; Iter   528/ 1097] train: loss: 0.0758396
[Epoch 7; Iter   558/ 1097] train: loss: 0.0380663
[Epoch 7; Iter   588/ 1097] train: loss: 0.0365913
[Epoch 7; Iter   618/ 1097] train: loss: 0.1136558
[Epoch 7; Iter   648/ 1097] train: loss: 0.2571785
[Epoch 7; Iter   678/ 1097] train: loss: 0.0355917
[Epoch 7; Iter   708/ 1097] train: loss: 0.0407950
[Epoch 7; Iter   738/ 1097] train: loss: 0.0346453
[Epoch 7; Iter   768/ 1097] train: loss: 0.0511996
[Epoch 7; Iter   798/ 1097] train: loss: 0.1099645
[Epoch 7; Iter   828/ 1097] train: loss: 0.1558031
[Epoch 7; Iter   858/ 1097] train: loss: 0.2103878
[Epoch 7; Iter   888/ 1097] train: loss: 0.0663934
[Epoch 7; Iter   918/ 1097] train: loss: 0.0406488
[Epoch 7; Iter   948/ 1097] train: loss: 0.1106982
[Epoch 7; Iter   978/ 1097] train: loss: 0.0468140
[Epoch 7; Iter  1008/ 1097] train: loss: 0.1596841
[Epoch 7; Iter  1038/ 1097] train: loss: 0.1074699
[Epoch 7; Iter  1068/ 1097] train: loss: 0.0420482
[Epoch 7] ogbg-molhiv: 0.719900 val loss: 2.790168
[Epoch 7] ogbg-molhiv: 0.713715 test loss: 0.178791
[Epoch 8; Iter     1/ 1097] train: loss: 0.2097434
[Epoch 3; Iter  1016/ 1097] train: loss: 0.0682514
[Epoch 3; Iter  1046/ 1097] train: loss: 0.0374060
[Epoch 3; Iter  1076/ 1097] train: loss: 0.0483566
[Epoch 3] ogbg-molhiv: 0.688016 val loss: 0.150512
[Epoch 3] ogbg-molhiv: 0.712938 test loss: 0.147555
[Epoch 4; Iter     9/ 1097] train: loss: 0.0394622
[Epoch 4; Iter    39/ 1097] train: loss: 0.2109008
[Epoch 4; Iter    69/ 1097] train: loss: 0.0724555
[Epoch 4; Iter    99/ 1097] train: loss: 0.1221539
[Epoch 4; Iter   129/ 1097] train: loss: 0.2477194
[Epoch 4; Iter   159/ 1097] train: loss: 0.0359942
[Epoch 4; Iter   189/ 1097] train: loss: 0.0444552
[Epoch 4; Iter   219/ 1097] train: loss: 0.0654573
[Epoch 4; Iter   249/ 1097] train: loss: 0.1865720
[Epoch 4; Iter   279/ 1097] train: loss: 0.1766035
[Epoch 4; Iter   309/ 1097] train: loss: 0.0583112
[Epoch 4; Iter   339/ 1097] train: loss: 0.0773777
[Epoch 4; Iter   369/ 1097] train: loss: 0.1780672
[Epoch 4; Iter   399/ 1097] train: loss: 0.0530367
[Epoch 4; Iter   429/ 1097] train: loss: 0.0428096
[Epoch 4; Iter   459/ 1097] train: loss: 0.0275620
[Epoch 4; Iter   489/ 1097] train: loss: 0.0889317
[Epoch 4; Iter   519/ 1097] train: loss: 0.1245884
[Epoch 4; Iter   549/ 1097] train: loss: 0.0274047
[Epoch 4; Iter   579/ 1097] train: loss: 0.2865506
[Epoch 4; Iter   609/ 1097] train: loss: 0.1777260
[Epoch 4; Iter   639/ 1097] train: loss: 0.0800086
[Epoch 4; Iter   669/ 1097] train: loss: 0.0566632
[Epoch 4; Iter   699/ 1097] train: loss: 0.0249895
[Epoch 4; Iter   729/ 1097] train: loss: 0.1316305
[Epoch 4; Iter   759/ 1097] train: loss: 0.0262198
[Epoch 4; Iter   789/ 1097] train: loss: 0.0410494
[Epoch 4; Iter   819/ 1097] train: loss: 0.0403089
[Epoch 4; Iter   849/ 1097] train: loss: 0.1336378
[Epoch 4; Iter   879/ 1097] train: loss: 0.1650527
[Epoch 4; Iter   909/ 1097] train: loss: 0.1665540
[Epoch 4; Iter   939/ 1097] train: loss: 0.0335798
[Epoch 4; Iter   969/ 1097] train: loss: 0.0342841
[Epoch 4; Iter   999/ 1097] train: loss: 0.1809556
[Epoch 4; Iter  1029/ 1097] train: loss: 0.0278254
[Epoch 4; Iter  1059/ 1097] train: loss: 0.1605808
[Epoch 4; Iter  1089/ 1097] train: loss: 0.3546251
[Epoch 4] ogbg-molhiv: 0.735827 val loss: 0.146658
[Epoch 4] ogbg-molhiv: 0.710656 test loss: 0.152415
[Epoch 5; Iter    22/ 1097] train: loss: 0.1374814
[Epoch 5; Iter    52/ 1097] train: loss: 0.0250083
[Epoch 5; Iter    82/ 1097] train: loss: 0.0392355
[Epoch 5; Iter   112/ 1097] train: loss: 0.3430957
[Epoch 5; Iter   142/ 1097] train: loss: 0.0326380
[Epoch 5; Iter   172/ 1097] train: loss: 0.0376099
[Epoch 5; Iter   202/ 1097] train: loss: 0.3014298
[Epoch 5; Iter   232/ 1097] train: loss: 0.4228733
[Epoch 5; Iter   262/ 1097] train: loss: 0.0275527
[Epoch 5; Iter   292/ 1097] train: loss: 0.0662068
[Epoch 5; Iter   322/ 1097] train: loss: 0.0270847
[Epoch 5; Iter   352/ 1097] train: loss: 0.1914815
[Epoch 5; Iter   382/ 1097] train: loss: 0.0322066
[Epoch 5; Iter   412/ 1097] train: loss: 0.0374698
[Epoch 5; Iter   442/ 1097] train: loss: 0.1047166
[Epoch 5; Iter   472/ 1097] train: loss: 0.0451247
[Epoch 5; Iter   502/ 1097] train: loss: 0.1625032
[Epoch 5; Iter   532/ 1097] train: loss: 0.2783514
[Epoch 5; Iter   562/ 1097] train: loss: 0.1897481
[Epoch 5; Iter   592/ 1097] train: loss: 0.3062309
[Epoch 5; Iter   622/ 1097] train: loss: 0.0351715
[Epoch 5; Iter   652/ 1097] train: loss: 0.2115400
[Epoch 5; Iter   682/ 1097] train: loss: 0.0542868
[Epoch 5; Iter   712/ 1097] train: loss: 0.0579981
[Epoch 5; Iter   742/ 1097] train: loss: 0.0526094
[Epoch 5; Iter   772/ 1097] train: loss: 0.1208174
[Epoch 5; Iter   802/ 1097] train: loss: 0.0329056
[Epoch 5; Iter   832/ 1097] train: loss: 0.1693968
[Epoch 5; Iter   862/ 1097] train: loss: 0.0762064
[Epoch 5; Iter   892/ 1097] train: loss: 0.0310637
[Epoch 5; Iter   922/ 1097] train: loss: 0.0243202
[Epoch 5; Iter   952/ 1097] train: loss: 0.1983347
[Epoch 5; Iter   982/ 1097] train: loss: 0.0262394
[Epoch 5; Iter  1012/ 1097] train: loss: 0.2090235
[Epoch 5; Iter  1042/ 1097] train: loss: 0.0455680
[Epoch 5; Iter  1072/ 1097] train: loss: 0.1804481
[Epoch 5] ogbg-molhiv: 0.754576 val loss: 0.214981
[Epoch 5] ogbg-molhiv: 0.739810 test loss: 0.252721
[Epoch 6; Iter     5/ 1097] train: loss: 0.0219995
[Epoch 6; Iter    35/ 1097] train: loss: 0.0383990
[Epoch 6; Iter    65/ 1097] train: loss: 0.1643502
[Epoch 6; Iter    95/ 1097] train: loss: 0.3864056
[Epoch 6; Iter   125/ 1097] train: loss: 0.3023614
[Epoch 6; Iter   155/ 1097] train: loss: 0.0359893
[Epoch 6; Iter   185/ 1097] train: loss: 0.1596206
[Epoch 6; Iter   215/ 1097] train: loss: 0.0277236
[Epoch 6; Iter   245/ 1097] train: loss: 0.1710250
[Epoch 6; Iter   275/ 1097] train: loss: 0.0304750
[Epoch 6; Iter   305/ 1097] train: loss: 0.0237156
[Epoch 6; Iter   335/ 1097] train: loss: 0.0200670
[Epoch 6; Iter   365/ 1097] train: loss: 0.0229712
[Epoch 6; Iter   395/ 1097] train: loss: 0.0197238
[Epoch 6; Iter   425/ 1097] train: loss: 0.1640237
[Epoch 6; Iter   455/ 1097] train: loss: 0.0216453
[Epoch 6; Iter   485/ 1097] train: loss: 0.1551134
[Epoch 6; Iter   515/ 1097] train: loss: 0.1157973
[Epoch 6; Iter   545/ 1097] train: loss: 0.0712367
[Epoch 6; Iter   575/ 1097] train: loss: 0.0312745
[Epoch 6; Iter   605/ 1097] train: loss: 0.1697032
[Epoch 6; Iter   635/ 1097] train: loss: 0.0442073
[Epoch 6; Iter   665/ 1097] train: loss: 0.0787150
[Epoch 6; Iter   695/ 1097] train: loss: 0.1913401
[Epoch 6; Iter   725/ 1097] train: loss: 0.1645242
[Epoch 6; Iter   755/ 1097] train: loss: 0.0577125
[Epoch 6; Iter   785/ 1097] train: loss: 0.2364935
[Epoch 6; Iter   815/ 1097] train: loss: 0.0900857
[Epoch 6; Iter   845/ 1097] train: loss: 0.0306533
[Epoch 6; Iter   875/ 1097] train: loss: 0.1810426
[Epoch 6; Iter   905/ 1097] train: loss: 0.2352017
[Epoch 6; Iter   935/ 1097] train: loss: 0.2126044
[Epoch 6; Iter   965/ 1097] train: loss: 0.0876513
[Epoch 6; Iter   995/ 1097] train: loss: 0.0428263
[Epoch 6; Iter  1025/ 1097] train: loss: 0.1757157
[Epoch 6; Iter  1055/ 1097] train: loss: 0.0300273
[Epoch 6; Iter  1085/ 1097] train: loss: 0.0292797
[Epoch 6] ogbg-molhiv: 0.752167 val loss: 0.133933
[Epoch 6] ogbg-molhiv: 0.756846 test loss: 0.145655
[Epoch 7; Iter    18/ 1097] train: loss: 0.0380445
[Epoch 7; Iter    48/ 1097] train: loss: 0.2044297
[Epoch 7; Iter    78/ 1097] train: loss: 0.0349278
[Epoch 7; Iter   108/ 1097] train: loss: 0.2423123
[Epoch 7; Iter   138/ 1097] train: loss: 0.2284808
[Epoch 7; Iter   168/ 1097] train: loss: 0.1290656
[Epoch 7; Iter   198/ 1097] train: loss: 0.2107568
[Epoch 7; Iter   228/ 1097] train: loss: 0.0218481
[Epoch 7; Iter   258/ 1097] train: loss: 0.1494197
[Epoch 7; Iter   288/ 1097] train: loss: 0.0247442
[Epoch 7; Iter   318/ 1097] train: loss: 0.2425712
[Epoch 7; Iter   348/ 1097] train: loss: 0.2171832
[Epoch 7; Iter   378/ 1097] train: loss: 0.0351517
[Epoch 7; Iter   408/ 1097] train: loss: 0.1589082
[Epoch 7; Iter   438/ 1097] train: loss: 0.0853061
[Epoch 7; Iter   468/ 1097] train: loss: 0.0354520
[Epoch 7; Iter   498/ 1097] train: loss: 0.0698485
[Epoch 7; Iter   528/ 1097] train: loss: 0.0306349
[Epoch 7; Iter   558/ 1097] train: loss: 0.0912922
[Epoch 7; Iter   588/ 1097] train: loss: 0.0253092
[Epoch 7; Iter   618/ 1097] train: loss: 0.2788364
[Epoch 7; Iter   648/ 1097] train: loss: 0.1967506
[Epoch 7; Iter   678/ 1097] train: loss: 0.3318310
[Epoch 7; Iter   708/ 1097] train: loss: 0.0288673
[Epoch 7; Iter   738/ 1097] train: loss: 0.1950067
[Epoch 7; Iter   768/ 1097] train: loss: 0.2792305
[Epoch 7; Iter   798/ 1097] train: loss: 0.1670311
[Epoch 7; Iter   828/ 1097] train: loss: 0.0335387
[Epoch 7; Iter   858/ 1097] train: loss: 0.1670727
[Epoch 7; Iter   888/ 1097] train: loss: 0.0310088
[Epoch 7; Iter   918/ 1097] train: loss: 0.1115531
[Epoch 7; Iter   948/ 1097] train: loss: 0.0304888
[Epoch 7; Iter   978/ 1097] train: loss: 0.1505857
[Epoch 7; Iter  1008/ 1097] train: loss: 0.0265715
[Epoch 7; Iter  1038/ 1097] train: loss: 0.0323170
[Epoch 7; Iter  1068/ 1097] train: loss: 0.1558449
[Epoch 7] ogbg-molhiv: 0.784537 val loss: 0.188724
[Epoch 7] ogbg-molhiv: 0.776038 test loss: 0.129604
[Epoch 8; Iter     1/ 1097] train: loss: 0.0525413
[Epoch 3; Iter  1016/ 1097] train: loss: 0.1642905
[Epoch 3; Iter  1046/ 1097] train: loss: 0.2102703
[Epoch 3; Iter  1076/ 1097] train: loss: 0.0449088
[Epoch 3] ogbg-molhiv: 0.736566 val loss: 0.132347
[Epoch 3] ogbg-molhiv: 0.694019 test loss: 0.136155
[Epoch 4; Iter     9/ 1097] train: loss: 0.0653638
[Epoch 4; Iter    39/ 1097] train: loss: 0.0359973
[Epoch 4; Iter    69/ 1097] train: loss: 0.1525798
[Epoch 4; Iter    99/ 1097] train: loss: 0.0611836
[Epoch 4; Iter   129/ 1097] train: loss: 0.2210340
[Epoch 4; Iter   159/ 1097] train: loss: 0.0372647
[Epoch 4; Iter   189/ 1097] train: loss: 0.0441057
[Epoch 4; Iter   219/ 1097] train: loss: 0.1572141
[Epoch 4; Iter   249/ 1097] train: loss: 0.1508474
[Epoch 4; Iter   279/ 1097] train: loss: 0.1503158
[Epoch 4; Iter   309/ 1097] train: loss: 0.0307152
[Epoch 4; Iter   339/ 1097] train: loss: 0.0467720
[Epoch 4; Iter   369/ 1097] train: loss: 0.1309597
[Epoch 4; Iter   399/ 1097] train: loss: 0.0448893
[Epoch 4; Iter   429/ 1097] train: loss: 0.3658367
[Epoch 4; Iter   459/ 1097] train: loss: 0.0256504
[Epoch 4; Iter   489/ 1097] train: loss: 0.1274606
[Epoch 4; Iter   519/ 1097] train: loss: 0.1595148
[Epoch 4; Iter   549/ 1097] train: loss: 0.0460927
[Epoch 4; Iter   579/ 1097] train: loss: 0.0458784
[Epoch 4; Iter   609/ 1097] train: loss: 0.3004471
[Epoch 4; Iter   639/ 1097] train: loss: 0.0363361
[Epoch 4; Iter   669/ 1097] train: loss: 0.1306607
[Epoch 4; Iter   699/ 1097] train: loss: 0.2239093
[Epoch 4; Iter   729/ 1097] train: loss: 0.1876247
[Epoch 4; Iter   759/ 1097] train: loss: 0.0321201
[Epoch 4; Iter   789/ 1097] train: loss: 0.0404117
[Epoch 4; Iter   819/ 1097] train: loss: 0.0360078
[Epoch 4; Iter   849/ 1097] train: loss: 0.1234873
[Epoch 4; Iter   879/ 1097] train: loss: 0.0355086
[Epoch 4; Iter   909/ 1097] train: loss: 0.0277843
[Epoch 4; Iter   939/ 1097] train: loss: 0.0382466
[Epoch 4; Iter   969/ 1097] train: loss: 0.1182972
[Epoch 4; Iter   999/ 1097] train: loss: 0.1662093
[Epoch 4; Iter  1029/ 1097] train: loss: 0.1970481
[Epoch 4; Iter  1059/ 1097] train: loss: 0.2135207
[Epoch 4; Iter  1089/ 1097] train: loss: 0.0738956
[Epoch 4] ogbg-molhiv: 0.753591 val loss: 0.129452
[Epoch 4] ogbg-molhiv: 0.739302 test loss: 0.127152
[Epoch 5; Iter    22/ 1097] train: loss: 0.1837964
[Epoch 5; Iter    52/ 1097] train: loss: 0.0265028
[Epoch 5; Iter    82/ 1097] train: loss: 0.0313399
[Epoch 5; Iter   112/ 1097] train: loss: 0.4835786
[Epoch 5; Iter   142/ 1097] train: loss: 0.1423482
[Epoch 5; Iter   172/ 1097] train: loss: 0.1248136
[Epoch 5; Iter   202/ 1097] train: loss: 0.0632376
[Epoch 5; Iter   232/ 1097] train: loss: 0.2961144
[Epoch 5; Iter   262/ 1097] train: loss: 0.0412309
[Epoch 5; Iter   292/ 1097] train: loss: 0.1777400
[Epoch 5; Iter   322/ 1097] train: loss: 0.0254483
[Epoch 5; Iter   352/ 1097] train: loss: 0.0350661
[Epoch 5; Iter   382/ 1097] train: loss: 0.1403665
[Epoch 5; Iter   412/ 1097] train: loss: 0.0831804
[Epoch 5; Iter   442/ 1097] train: loss: 0.1879638
[Epoch 5; Iter   472/ 1097] train: loss: 0.0740752
[Epoch 5; Iter   502/ 1097] train: loss: 0.0307462
[Epoch 5; Iter   532/ 1097] train: loss: 0.2413585
[Epoch 5; Iter   562/ 1097] train: loss: 0.0344944
[Epoch 5; Iter   592/ 1097] train: loss: 0.0921976
[Epoch 5; Iter   622/ 1097] train: loss: 0.2709489
[Epoch 5; Iter   652/ 1097] train: loss: 0.1353932
[Epoch 5; Iter   682/ 1097] train: loss: 0.0342488
[Epoch 5; Iter   712/ 1097] train: loss: 0.1807642
[Epoch 5; Iter   742/ 1097] train: loss: 0.1582712
[Epoch 5; Iter   772/ 1097] train: loss: 0.0292764
[Epoch 5; Iter   802/ 1097] train: loss: 0.1166538
[Epoch 5; Iter   832/ 1097] train: loss: 0.0368294
[Epoch 5; Iter   862/ 1097] train: loss: 0.0503288
[Epoch 5; Iter   892/ 1097] train: loss: 0.0289100
[Epoch 5; Iter   922/ 1097] train: loss: 0.2732551
[Epoch 5; Iter   952/ 1097] train: loss: 0.0267109
[Epoch 5; Iter   982/ 1097] train: loss: 0.0313786
[Epoch 5; Iter  1012/ 1097] train: loss: 0.1691484
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2309085
[Epoch 5; Iter  1072/ 1097] train: loss: 0.2608081
[Epoch 5] ogbg-molhiv: 0.741563 val loss: 0.131870
[Epoch 5] ogbg-molhiv: 0.718724 test loss: 0.130594
[Epoch 6; Iter     5/ 1097] train: loss: 0.0929485
[Epoch 6; Iter    35/ 1097] train: loss: 0.1589927
[Epoch 6; Iter    65/ 1097] train: loss: 0.0547192
[Epoch 6; Iter    95/ 1097] train: loss: 0.2821932
[Epoch 6; Iter   125/ 1097] train: loss: 0.1375853
[Epoch 6; Iter   155/ 1097] train: loss: 0.1643945
[Epoch 6; Iter   185/ 1097] train: loss: 0.0337184
[Epoch 6; Iter   215/ 1097] train: loss: 0.2017368
[Epoch 6; Iter   245/ 1097] train: loss: 0.0478594
[Epoch 6; Iter   275/ 1097] train: loss: 0.1819254
[Epoch 6; Iter   305/ 1097] train: loss: 0.1680624
[Epoch 6; Iter   335/ 1097] train: loss: 0.0246069
[Epoch 6; Iter   365/ 1097] train: loss: 0.1718532
[Epoch 6; Iter   395/ 1097] train: loss: 0.1125154
[Epoch 6; Iter   425/ 1097] train: loss: 0.0421273
[Epoch 6; Iter   455/ 1097] train: loss: 0.0777279
[Epoch 6; Iter   485/ 1097] train: loss: 0.0685007
[Epoch 6; Iter   515/ 1097] train: loss: 0.3532822
[Epoch 6; Iter   545/ 1097] train: loss: 0.0760159
[Epoch 6; Iter   575/ 1097] train: loss: 0.0735835
[Epoch 6; Iter   605/ 1097] train: loss: 0.3020952
[Epoch 6; Iter   635/ 1097] train: loss: 0.2535560
[Epoch 6; Iter   665/ 1097] train: loss: 0.2686456
[Epoch 6; Iter   695/ 1097] train: loss: 0.2688639
[Epoch 6; Iter   725/ 1097] train: loss: 0.2744259
[Epoch 6; Iter   755/ 1097] train: loss: 0.1508558
[Epoch 6; Iter   785/ 1097] train: loss: 0.0713734
[Epoch 6; Iter   815/ 1097] train: loss: 0.3556697
[Epoch 6; Iter   845/ 1097] train: loss: 0.0514873
[Epoch 6; Iter   875/ 1097] train: loss: 0.3106322
[Epoch 6; Iter   905/ 1097] train: loss: 0.1364647
[Epoch 6; Iter   935/ 1097] train: loss: 0.1096334
[Epoch 6; Iter   965/ 1097] train: loss: 0.1029731
[Epoch 6; Iter   995/ 1097] train: loss: 0.0812995
[Epoch 6; Iter  1025/ 1097] train: loss: 0.0764603
[Epoch 6; Iter  1055/ 1097] train: loss: 0.1021548
[Epoch 6; Iter  1085/ 1097] train: loss: 0.1280492
[Epoch 6] ogbg-molhiv: 0.759757 val loss: 0.129700
[Epoch 6] ogbg-molhiv: 0.760906 test loss: 0.126636
[Epoch 7; Iter    18/ 1097] train: loss: 0.0574722
[Epoch 7; Iter    48/ 1097] train: loss: 0.1470349
[Epoch 7; Iter    78/ 1097] train: loss: 0.3230153
[Epoch 7; Iter   108/ 1097] train: loss: 0.3566244
[Epoch 7; Iter   138/ 1097] train: loss: 0.1552260
[Epoch 7; Iter   168/ 1097] train: loss: 0.1611693
[Epoch 7; Iter   198/ 1097] train: loss: 0.3069504
[Epoch 7; Iter   228/ 1097] train: loss: 0.2798422
[Epoch 7; Iter   258/ 1097] train: loss: 0.3154814
[Epoch 7; Iter   288/ 1097] train: loss: 0.3141105
[Epoch 7; Iter   318/ 1097] train: loss: 0.0844377
[Epoch 7; Iter   348/ 1097] train: loss: 0.0381826
[Epoch 7; Iter   378/ 1097] train: loss: 0.1904260
[Epoch 7; Iter   408/ 1097] train: loss: 0.1372437
[Epoch 7; Iter   438/ 1097] train: loss: 0.1841727
[Epoch 7; Iter   468/ 1097] train: loss: 0.0275776
[Epoch 7; Iter   498/ 1097] train: loss: 0.0256893
[Epoch 7; Iter   528/ 1097] train: loss: 0.1657695
[Epoch 7; Iter   558/ 1097] train: loss: 0.0260738
[Epoch 7; Iter   588/ 1097] train: loss: 0.0265409
[Epoch 7; Iter   618/ 1097] train: loss: 0.1545373
[Epoch 7; Iter   648/ 1097] train: loss: 0.1679951
[Epoch 7; Iter   678/ 1097] train: loss: 0.0268421
[Epoch 7; Iter   708/ 1097] train: loss: 0.0632071
[Epoch 7; Iter   738/ 1097] train: loss: 0.0266981
[Epoch 7; Iter   768/ 1097] train: loss: 0.0283644
[Epoch 7; Iter   798/ 1097] train: loss: 0.3491012
[Epoch 7; Iter   828/ 1097] train: loss: 0.0481399
[Epoch 7; Iter   858/ 1097] train: loss: 0.2187474
[Epoch 7; Iter   888/ 1097] train: loss: 0.1849958
[Epoch 7; Iter   918/ 1097] train: loss: 0.0628180
[Epoch 7; Iter   948/ 1097] train: loss: 0.1583644
[Epoch 7; Iter   978/ 1097] train: loss: 0.2375531
[Epoch 7; Iter  1008/ 1097] train: loss: 0.1654895
[Epoch 7; Iter  1038/ 1097] train: loss: 0.1523440
[Epoch 7; Iter  1068/ 1097] train: loss: 0.1351161
[Epoch 7] ogbg-molhiv: 0.769965 val loss: 0.129339
[Epoch 7] ogbg-molhiv: 0.757364 test loss: 0.249679
[Epoch 8; Iter     1/ 1097] train: loss: 0.0391133

[Epoch 4; Iter   270/  960] train: loss: 0.1233111
[Epoch 4; Iter   300/  960] train: loss: 0.1172574
[Epoch 4; Iter   330/  960] train: loss: 0.1810079
[Epoch 4; Iter   360/  960] train: loss: 0.2442069
[Epoch 4; Iter   390/  960] train: loss: 0.3638186
[Epoch 4; Iter   420/  960] train: loss: 0.1260754
[Epoch 4; Iter   450/  960] train: loss: 0.0344800
[Epoch 4; Iter   480/  960] train: loss: 0.0239798
[Epoch 4; Iter   510/  960] train: loss: 0.1650230
[Epoch 4; Iter   540/  960] train: loss: 0.1095705
[Epoch 4; Iter   570/  960] train: loss: 0.3830692
[Epoch 4; Iter   600/  960] train: loss: 0.2807695
[Epoch 4; Iter   630/  960] train: loss: 0.1601033
[Epoch 4; Iter   660/  960] train: loss: 0.3166634
[Epoch 4; Iter   690/  960] train: loss: 0.0274614
[Epoch 4; Iter   720/  960] train: loss: 0.0252129
[Epoch 4; Iter   750/  960] train: loss: 0.2983409
[Epoch 4; Iter   780/  960] train: loss: 0.0876606
[Epoch 4; Iter   810/  960] train: loss: 0.1608825
[Epoch 4; Iter   840/  960] train: loss: 0.1329067
[Epoch 4; Iter   870/  960] train: loss: 0.3471535
[Epoch 4; Iter   900/  960] train: loss: 0.0331176
[Epoch 4; Iter   930/  960] train: loss: 0.1541249
[Epoch 4; Iter   960/  960] train: loss: 0.0270819
[Epoch 4] ogbg-molhiv: 0.727689 val loss: 0.142694
[Epoch 4] ogbg-molhiv: 0.714839 test loss: 0.135386
[Epoch 5; Iter    30/  960] train: loss: 0.0277275
[Epoch 5; Iter    60/  960] train: loss: 0.0442785
[Epoch 5; Iter    90/  960] train: loss: 0.0290950
[Epoch 5; Iter   120/  960] train: loss: 0.1617316
[Epoch 5; Iter   150/  960] train: loss: 0.0727588
[Epoch 5; Iter   180/  960] train: loss: 0.2140194
[Epoch 5; Iter   210/  960] train: loss: 0.0301470
[Epoch 5; Iter   240/  960] train: loss: 0.0320723
[Epoch 5; Iter   270/  960] train: loss: 0.0461232
[Epoch 5; Iter   300/  960] train: loss: 0.0373213
[Epoch 5; Iter   330/  960] train: loss: 0.0356193
[Epoch 5; Iter   360/  960] train: loss: 0.1515487
[Epoch 5; Iter   390/  960] train: loss: 0.1112671
[Epoch 5; Iter   420/  960] train: loss: 0.1943214
[Epoch 5; Iter   450/  960] train: loss: 0.3111005
[Epoch 5; Iter   480/  960] train: loss: 0.0296741
[Epoch 5; Iter   510/  960] train: loss: 0.1528119
[Epoch 5; Iter   540/  960] train: loss: 0.2878702
[Epoch 5; Iter   570/  960] train: loss: 0.0480527
[Epoch 5; Iter   600/  960] train: loss: 0.1774703
[Epoch 5; Iter   630/  960] train: loss: 0.2316895
[Epoch 5; Iter   660/  960] train: loss: 0.0275449
[Epoch 5; Iter   690/  960] train: loss: 0.1806791
[Epoch 5; Iter   720/  960] train: loss: 0.2022184
[Epoch 5; Iter   750/  960] train: loss: 0.3726546
[Epoch 5; Iter   780/  960] train: loss: 0.3967430
[Epoch 5; Iter   810/  960] train: loss: 0.0449161
[Epoch 5; Iter   840/  960] train: loss: 0.0382186
[Epoch 5; Iter   870/  960] train: loss: 0.2590234
[Epoch 5; Iter   900/  960] train: loss: 0.0219050
[Epoch 5; Iter   930/  960] train: loss: 0.0312698
[Epoch 5; Iter   960/  960] train: loss: 0.0239995
[Epoch 5] ogbg-molhiv: 0.729064 val loss: 0.142961
[Epoch 5] ogbg-molhiv: 0.719416 test loss: 0.136449
[Epoch 6; Iter    30/  960] train: loss: 0.1599525
[Epoch 6; Iter    60/  960] train: loss: 0.0267247
[Epoch 6; Iter    90/  960] train: loss: 0.1148484
[Epoch 6; Iter   120/  960] train: loss: 0.0344607
[Epoch 6; Iter   150/  960] train: loss: 0.0419881
[Epoch 6; Iter   180/  960] train: loss: 0.3250152
[Epoch 6; Iter   210/  960] train: loss: 0.2782559
[Epoch 6; Iter   240/  960] train: loss: 0.0264942
[Epoch 6; Iter   270/  960] train: loss: 0.0843646
[Epoch 6; Iter   300/  960] train: loss: 0.0472137
[Epoch 6; Iter   330/  960] train: loss: 0.2970579
[Epoch 6; Iter   360/  960] train: loss: 0.0448723
[Epoch 6; Iter   390/  960] train: loss: 0.0318017
[Epoch 6; Iter   420/  960] train: loss: 0.0253783
[Epoch 6; Iter   450/  960] train: loss: 0.3231627
[Epoch 6; Iter   480/  960] train: loss: 0.0792065
[Epoch 6; Iter   510/  960] train: loss: 0.5719872
[Epoch 6; Iter   540/  960] train: loss: 0.0792157
[Epoch 6; Iter   570/  960] train: loss: 0.2949205
[Epoch 6; Iter   600/  960] train: loss: 0.1180588
[Epoch 6; Iter   630/  960] train: loss: 0.0308426
[Epoch 6; Iter   660/  960] train: loss: 0.3503213
[Epoch 6; Iter   690/  960] train: loss: 0.0234020
[Epoch 6; Iter   720/  960] train: loss: 0.0304032
[Epoch 6; Iter   750/  960] train: loss: 0.0736436
[Epoch 6; Iter   780/  960] train: loss: 0.0329552
[Epoch 6; Iter   810/  960] train: loss: 0.1861239
[Epoch 6; Iter   840/  960] train: loss: 0.0408490
[Epoch 6; Iter   870/  960] train: loss: 0.1922643
[Epoch 6; Iter   900/  960] train: loss: 0.2645339
[Epoch 6; Iter   930/  960] train: loss: 0.3482198
[Epoch 6; Iter   960/  960] train: loss: 0.4662985
[Epoch 6] ogbg-molhiv: 0.753913 val loss: 0.138054
[Epoch 6] ogbg-molhiv: 0.744261 test loss: 0.133508
[Epoch 7; Iter    30/  960] train: loss: 0.1387224
[Epoch 7; Iter    60/  960] train: loss: 0.1099623
[Epoch 7; Iter    90/  960] train: loss: 0.1513338
[Epoch 7; Iter   120/  960] train: loss: 0.0570951
[Epoch 7; Iter   150/  960] train: loss: 0.0674373
[Epoch 7; Iter   180/  960] train: loss: 0.0748112
[Epoch 7; Iter   210/  960] train: loss: 0.0442431
[Epoch 7; Iter   240/  960] train: loss: 0.0426973
[Epoch 7; Iter   270/  960] train: loss: 0.2752560
[Epoch 7; Iter   300/  960] train: loss: 0.0394299
[Epoch 7; Iter   330/  960] train: loss: 0.3098784
[Epoch 7; Iter   360/  960] train: loss: 0.3119847
[Epoch 7; Iter   390/  960] train: loss: 0.1981084
[Epoch 7; Iter   420/  960] train: loss: 0.1856293
[Epoch 7; Iter   450/  960] train: loss: 0.5077790
[Epoch 7; Iter   480/  960] train: loss: 0.0804275
[Epoch 7; Iter   510/  960] train: loss: 0.0360548
[Epoch 7; Iter   540/  960] train: loss: 0.0654943
[Epoch 7; Iter   570/  960] train: loss: 0.0277680
[Epoch 7; Iter   600/  960] train: loss: 0.0361435
[Epoch 7; Iter   630/  960] train: loss: 0.0225470
[Epoch 7; Iter   660/  960] train: loss: 0.3019900
[Epoch 7; Iter   690/  960] train: loss: 0.1237836
[Epoch 7; Iter   720/  960] train: loss: 0.0946164
[Epoch 7; Iter   750/  960] train: loss: 0.6748540
[Epoch 7; Iter   780/  960] train: loss: 0.1122639
[Epoch 7; Iter   810/  960] train: loss: 0.1151536
[Epoch 7; Iter   840/  960] train: loss: 0.2518210
[Epoch 7; Iter   870/  960] train: loss: 0.1592072
[Epoch 7; Iter   900/  960] train: loss: 0.1263910
[Epoch 7; Iter   930/  960] train: loss: 0.1763650
[Epoch 7; Iter   960/  960] train: loss: 0.0588111
[Epoch 7] ogbg-molhiv: 0.765574 val loss: 0.134786
[Epoch 7] ogbg-molhiv: 0.728235 test loss: 0.132724
[Epoch 8; Iter    30/  960] train: loss: 0.0406081
[Epoch 8; Iter    60/  960] train: loss: 0.0309717
[Epoch 8; Iter    90/  960] train: loss: 0.1265388
[Epoch 8; Iter   120/  960] train: loss: 0.0389554
[Epoch 8; Iter   150/  960] train: loss: 0.4173983
[Epoch 8; Iter   180/  960] train: loss: 0.1349374
[Epoch 8; Iter   210/  960] train: loss: 0.1983449
[Epoch 8; Iter   240/  960] train: loss: 0.0773403
[Epoch 8; Iter   270/  960] train: loss: 0.0384322
[Epoch 8; Iter   300/  960] train: loss: 0.0299383
[Epoch 8; Iter   330/  960] train: loss: 0.0559672
[Epoch 8; Iter   360/  960] train: loss: 0.2873736
[Epoch 8; Iter   390/  960] train: loss: 0.0639124
[Epoch 8; Iter   420/  960] train: loss: 0.0223896
[Epoch 8; Iter   450/  960] train: loss: 0.1316356
[Epoch 8; Iter   480/  960] train: loss: 0.0282296
[Epoch 8; Iter   510/  960] train: loss: 0.1341830
[Epoch 8; Iter   540/  960] train: loss: 0.1618381
[Epoch 8; Iter   570/  960] train: loss: 0.0672107
[Epoch 8; Iter   600/  960] train: loss: 0.0325714
[Epoch 8; Iter   630/  960] train: loss: 0.0309414
[Epoch 8; Iter   660/  960] train: loss: 0.3686627
[Epoch 8; Iter   690/  960] train: loss: 0.1938558
[Epoch 8; Iter   720/  960] train: loss: 0.0328135
[Epoch 8; Iter   750/  960] train: loss: 0.0269445
[Epoch 8; Iter   780/  960] train: loss: 0.0426325
[Epoch 8; Iter   810/  960] train: loss: 0.0252767
[Epoch 8; Iter   840/  960] train: loss: 0.1145675
[Epoch 8; Iter   870/  960] train: loss: 0.2843153
[Epoch 8; Iter   900/  960] train: loss: 0.2074995
[Epoch 8; Iter   930/  960] train: loss: 0.1331040
[Epoch 8; Iter   960/  960] train: loss: 0.0292843

[Epoch 4; Iter   270/  960] train: loss: 0.0449796
[Epoch 4; Iter   300/  960] train: loss: 0.3761827
[Epoch 4; Iter   330/  960] train: loss: 0.0320271
[Epoch 4; Iter   360/  960] train: loss: 0.0306676
[Epoch 4; Iter   390/  960] train: loss: 0.0524327
[Epoch 4; Iter   420/  960] train: loss: 0.2261635
[Epoch 4; Iter   450/  960] train: loss: 0.2783045
[Epoch 4; Iter   480/  960] train: loss: 0.0281084
[Epoch 4; Iter   510/  960] train: loss: 0.0296116
[Epoch 4; Iter   540/  960] train: loss: 0.1456208
[Epoch 4; Iter   570/  960] train: loss: 0.1679153
[Epoch 4; Iter   600/  960] train: loss: 0.1426695
[Epoch 4; Iter   630/  960] train: loss: 0.2876152
[Epoch 4; Iter   660/  960] train: loss: 0.0940337
[Epoch 4; Iter   690/  960] train: loss: 0.0289074
[Epoch 4; Iter   720/  960] train: loss: 0.1882774
[Epoch 4; Iter   750/  960] train: loss: 0.4226685
[Epoch 4; Iter   780/  960] train: loss: 0.2178066
[Epoch 4; Iter   810/  960] train: loss: 0.1296830
[Epoch 4; Iter   840/  960] train: loss: 0.0302616
[Epoch 4; Iter   870/  960] train: loss: 0.1721947
[Epoch 4; Iter   900/  960] train: loss: 0.1793240
[Epoch 4; Iter   930/  960] train: loss: 0.0385752
[Epoch 4; Iter   960/  960] train: loss: 0.0330469
[Epoch 4] ogbg-molhiv: 0.734898 val loss: 0.144083
[Epoch 4] ogbg-molhiv: 0.708068 test loss: 0.139346
[Epoch 5; Iter    30/  960] train: loss: 0.0273421
[Epoch 5; Iter    60/  960] train: loss: 0.1294610
[Epoch 5; Iter    90/  960] train: loss: 0.2598651
[Epoch 5; Iter   120/  960] train: loss: 0.2937138
[Epoch 5; Iter   150/  960] train: loss: 0.1687391
[Epoch 5; Iter   180/  960] train: loss: 0.0360012
[Epoch 5; Iter   210/  960] train: loss: 0.1546128
[Epoch 5; Iter   240/  960] train: loss: 0.2200602
[Epoch 5; Iter   270/  960] train: loss: 0.0748804
[Epoch 5; Iter   300/  960] train: loss: 0.3992064
[Epoch 5; Iter   330/  960] train: loss: 0.0434329
[Epoch 5; Iter   360/  960] train: loss: 0.1712525
[Epoch 5; Iter   390/  960] train: loss: 0.0392129
[Epoch 5; Iter   420/  960] train: loss: 0.1340270
[Epoch 5; Iter   450/  960] train: loss: 0.0382615
[Epoch 5; Iter   480/  960] train: loss: 0.2228098
[Epoch 5; Iter   510/  960] train: loss: 0.3283292
[Epoch 5; Iter   540/  960] train: loss: 0.0635463
[Epoch 5; Iter   570/  960] train: loss: 0.0325743
[Epoch 5; Iter   600/  960] train: loss: 0.2000364
[Epoch 5; Iter   630/  960] train: loss: 0.0882754
[Epoch 5; Iter   660/  960] train: loss: 0.3851708
[Epoch 5; Iter   690/  960] train: loss: 0.1405772
[Epoch 5; Iter   720/  960] train: loss: 0.0279717
[Epoch 5; Iter   750/  960] train: loss: 0.1781271
[Epoch 5; Iter   780/  960] train: loss: 0.1708207
[Epoch 5; Iter   810/  960] train: loss: 0.0303730
[Epoch 5; Iter   840/  960] train: loss: 0.0298032
[Epoch 5; Iter   870/  960] train: loss: 0.3712946
[Epoch 5; Iter   900/  960] train: loss: 0.0263021
[Epoch 5; Iter   930/  960] train: loss: 0.1759951
[Epoch 5; Iter   960/  960] train: loss: 0.2877389
[Epoch 5] ogbg-molhiv: 0.745851 val loss: 0.145297
[Epoch 5] ogbg-molhiv: 0.746226 test loss: 0.137851
[Epoch 6; Iter    30/  960] train: loss: 0.1727280
[Epoch 6; Iter    60/  960] train: loss: 0.0329224
[Epoch 6; Iter    90/  960] train: loss: 0.1214964
[Epoch 6; Iter   120/  960] train: loss: 0.0292304
[Epoch 6; Iter   150/  960] train: loss: 0.0760182
[Epoch 6; Iter   180/  960] train: loss: 0.2291151
[Epoch 6; Iter   210/  960] train: loss: 0.1494881
[Epoch 6; Iter   240/  960] train: loss: 0.0634218
[Epoch 6; Iter   270/  960] train: loss: 0.0908647
[Epoch 6; Iter   300/  960] train: loss: 0.0354268
[Epoch 6; Iter   330/  960] train: loss: 0.4091501
[Epoch 6; Iter   360/  960] train: loss: 0.0336600
[Epoch 6; Iter   390/  960] train: loss: 0.0253127
[Epoch 6; Iter   420/  960] train: loss: 0.1319095
[Epoch 6; Iter   450/  960] train: loss: 0.3029251
[Epoch 6; Iter   480/  960] train: loss: 0.0456106
[Epoch 6; Iter   510/  960] train: loss: 0.1411215
[Epoch 6; Iter   540/  960] train: loss: 0.1853200
[Epoch 6; Iter   570/  960] train: loss: 0.1010560
[Epoch 6; Iter   600/  960] train: loss: 0.2850837
[Epoch 6; Iter   630/  960] train: loss: 0.0267611
[Epoch 6; Iter   660/  960] train: loss: 0.3059514
[Epoch 6; Iter   690/  960] train: loss: 0.2021895
[Epoch 6; Iter   720/  960] train: loss: 0.0636119
[Epoch 6; Iter   750/  960] train: loss: 0.1415620
[Epoch 6; Iter   780/  960] train: loss: 0.2344182
[Epoch 6; Iter   810/  960] train: loss: 0.0404902
[Epoch 6; Iter   840/  960] train: loss: 0.0291701
[Epoch 6; Iter   870/  960] train: loss: 0.5602519
[Epoch 6; Iter   900/  960] train: loss: 0.0862141
[Epoch 6; Iter   930/  960] train: loss: 0.0414598
[Epoch 6; Iter   960/  960] train: loss: 0.0402799
[Epoch 6] ogbg-molhiv: 0.766049 val loss: 0.137013
[Epoch 6] ogbg-molhiv: 0.732150 test loss: 0.137424
[Epoch 7; Iter    30/  960] train: loss: 0.0492824
[Epoch 7; Iter    60/  960] train: loss: 0.2405480
[Epoch 7; Iter    90/  960] train: loss: 0.1412826
[Epoch 7; Iter   120/  960] train: loss: 0.0336231
[Epoch 7; Iter   150/  960] train: loss: 0.0370142
[Epoch 7; Iter   180/  960] train: loss: 0.0210017
[Epoch 7; Iter   210/  960] train: loss: 0.2744201
[Epoch 7; Iter   240/  960] train: loss: 0.1799138
[Epoch 7; Iter   270/  960] train: loss: 0.0678324
[Epoch 7; Iter   300/  960] train: loss: 0.1003155
[Epoch 7; Iter   330/  960] train: loss: 0.1852305
[Epoch 7; Iter   360/  960] train: loss: 0.0269113
[Epoch 7; Iter   390/  960] train: loss: 0.1251020
[Epoch 7; Iter   420/  960] train: loss: 0.0252196
[Epoch 7; Iter   450/  960] train: loss: 0.0927592
[Epoch 7; Iter   480/  960] train: loss: 0.2057328
[Epoch 7; Iter   510/  960] train: loss: 0.0280455
[Epoch 7; Iter   540/  960] train: loss: 0.1190898
[Epoch 7; Iter   570/  960] train: loss: 0.0511056
[Epoch 7; Iter   600/  960] train: loss: 0.1745610
[Epoch 7; Iter   630/  960] train: loss: 0.1576003
[Epoch 7; Iter   660/  960] train: loss: 0.0299647
[Epoch 7; Iter   690/  960] train: loss: 0.1186358
[Epoch 7; Iter   720/  960] train: loss: 0.1941232
[Epoch 7; Iter   750/  960] train: loss: 0.0317265
[Epoch 7; Iter   780/  960] train: loss: 0.3299760
[Epoch 7; Iter   810/  960] train: loss: 0.1114990
[Epoch 7; Iter   840/  960] train: loss: 0.2519526
[Epoch 7; Iter   870/  960] train: loss: 0.1851339
[Epoch 7; Iter   900/  960] train: loss: 0.1340777
[Epoch 7; Iter   930/  960] train: loss: 0.2271985
[Epoch 7; Iter   960/  960] train: loss: 0.0279730
[Epoch 7] ogbg-molhiv: 0.773498 val loss: 0.134358
[Epoch 7] ogbg-molhiv: 0.760586 test loss: 0.133297
[Epoch 8; Iter    30/  960] train: loss: 0.0445303
[Epoch 8; Iter    60/  960] train: loss: 0.2026783
[Epoch 8; Iter    90/  960] train: loss: 0.0319809
[Epoch 8; Iter   120/  960] train: loss: 0.0584663
[Epoch 8; Iter   150/  960] train: loss: 0.1576381
[Epoch 8; Iter   180/  960] train: loss: 0.0269622
[Epoch 8; Iter   210/  960] train: loss: 0.0272775
[Epoch 8; Iter   240/  960] train: loss: 0.0400744
[Epoch 8; Iter   270/  960] train: loss: 0.1649203
[Epoch 8; Iter   300/  960] train: loss: 0.0411661
[Epoch 8; Iter   330/  960] train: loss: 0.1711142
[Epoch 8; Iter   360/  960] train: loss: 0.0897066
[Epoch 8; Iter   390/  960] train: loss: 0.1008907
[Epoch 8; Iter   420/  960] train: loss: 0.1287735
[Epoch 8; Iter   450/  960] train: loss: 0.0730046
[Epoch 8; Iter   480/  960] train: loss: 0.0645402
[Epoch 8; Iter   510/  960] train: loss: 0.2736446
[Epoch 8; Iter   540/  960] train: loss: 0.1329120
[Epoch 8; Iter   570/  960] train: loss: 0.0395856
[Epoch 8; Iter   600/  960] train: loss: 0.0340521
[Epoch 8; Iter   630/  960] train: loss: 0.0423672
[Epoch 8; Iter   660/  960] train: loss: 0.0253960
[Epoch 8; Iter   690/  960] train: loss: 0.0552795
[Epoch 8; Iter   720/  960] train: loss: 0.2207711
[Epoch 8; Iter   750/  960] train: loss: 0.0245518
[Epoch 8; Iter   780/  960] train: loss: 0.1928340
[Epoch 8; Iter   810/  960] train: loss: 0.0423836
[Epoch 8; Iter   840/  960] train: loss: 0.0462574
[Epoch 8; Iter   870/  960] train: loss: 0.1554151
[Epoch 8; Iter   900/  960] train: loss: 0.3775770
[Epoch 8; Iter   930/  960] train: loss: 0.0265170
[Epoch 8; Iter   960/  960] train: loss: 0.0348342

[Epoch 4; Iter   270/  960] train: loss: 0.0284709
[Epoch 4; Iter   300/  960] train: loss: 0.1134653
[Epoch 4; Iter   330/  960] train: loss: 0.1373375
[Epoch 4; Iter   360/  960] train: loss: 0.1543104
[Epoch 4; Iter   390/  960] train: loss: 0.0314048
[Epoch 4; Iter   420/  960] train: loss: 0.0717501
[Epoch 4; Iter   450/  960] train: loss: 0.0280156
[Epoch 4; Iter   480/  960] train: loss: 0.0816335
[Epoch 4; Iter   510/  960] train: loss: 0.1184893
[Epoch 4; Iter   540/  960] train: loss: 0.0516876
[Epoch 4; Iter   570/  960] train: loss: 0.0935204
[Epoch 4; Iter   600/  960] train: loss: 0.1322425
[Epoch 4; Iter   630/  960] train: loss: 0.2598520
[Epoch 4; Iter   660/  960] train: loss: 0.0335211
[Epoch 4; Iter   690/  960] train: loss: 0.0510637
[Epoch 4; Iter   720/  960] train: loss: 0.0295191
[Epoch 4; Iter   750/  960] train: loss: 0.1591169
[Epoch 4; Iter   780/  960] train: loss: 0.0252756
[Epoch 4; Iter   810/  960] train: loss: 0.0259797
[Epoch 4; Iter   840/  960] train: loss: 0.0290797
[Epoch 4; Iter   870/  960] train: loss: 0.1750903
[Epoch 4; Iter   900/  960] train: loss: 0.1870824
[Epoch 4; Iter   930/  960] train: loss: 0.1445997
[Epoch 4; Iter   960/  960] train: loss: 0.2404771
[Epoch 4] ogbg-molhiv: 0.716777 val loss: 0.165651
[Epoch 4] ogbg-molhiv: 0.708959 test loss: 0.162955
[Epoch 5; Iter    30/  960] train: loss: 0.0399838
[Epoch 5; Iter    60/  960] train: loss: 0.0981384
[Epoch 5; Iter    90/  960] train: loss: 0.0857954
[Epoch 5; Iter   120/  960] train: loss: 0.2813022
[Epoch 5; Iter   150/  960] train: loss: 0.0896722
[Epoch 5; Iter   180/  960] train: loss: 0.0321659
[Epoch 5; Iter   210/  960] train: loss: 0.0365409
[Epoch 5; Iter   240/  960] train: loss: 0.1340275
[Epoch 5; Iter   270/  960] train: loss: 0.1861112
[Epoch 5; Iter   300/  960] train: loss: 0.0525756
[Epoch 5; Iter   330/  960] train: loss: 0.0658408
[Epoch 5; Iter   360/  960] train: loss: 0.0340840
[Epoch 5; Iter   390/  960] train: loss: 0.2347426
[Epoch 5; Iter   420/  960] train: loss: 0.1634518
[Epoch 5; Iter   450/  960] train: loss: 0.2067979
[Epoch 5; Iter   480/  960] train: loss: 0.0319118
[Epoch 5; Iter   510/  960] train: loss: 0.0244878
[Epoch 5; Iter   540/  960] train: loss: 0.3835493
[Epoch 5; Iter   570/  960] train: loss: 0.0954864
[Epoch 5; Iter   600/  960] train: loss: 0.1377745
[Epoch 5; Iter   630/  960] train: loss: 0.0237779
[Epoch 5; Iter   660/  960] train: loss: 0.1155966
[Epoch 5; Iter   690/  960] train: loss: 0.0488078
[Epoch 5; Iter   720/  960] train: loss: 0.0776646
[Epoch 5; Iter   750/  960] train: loss: 0.1412237
[Epoch 5; Iter   780/  960] train: loss: 0.0463383
[Epoch 5; Iter   810/  960] train: loss: 0.1551006
[Epoch 5; Iter   840/  960] train: loss: 0.0302631
[Epoch 5; Iter   870/  960] train: loss: 0.1304870
[Epoch 5; Iter   900/  960] train: loss: 0.0248834
[Epoch 5; Iter   930/  960] train: loss: 0.0607307
[Epoch 5; Iter   960/  960] train: loss: 0.1240776
[Epoch 5] ogbg-molhiv: 0.755352 val loss: 0.287858
[Epoch 5] ogbg-molhiv: 0.748361 test loss: 0.302126
[Epoch 6; Iter    30/  960] train: loss: 0.0410250
[Epoch 6; Iter    60/  960] train: loss: 0.3109032
[Epoch 6; Iter    90/  960] train: loss: 0.0314029
[Epoch 6; Iter   120/  960] train: loss: 0.0308873
[Epoch 6; Iter   150/  960] train: loss: 0.0680199
[Epoch 6; Iter   180/  960] train: loss: 0.0737501
[Epoch 6; Iter   210/  960] train: loss: 0.0253255
[Epoch 6; Iter   240/  960] train: loss: 0.5467865
[Epoch 6; Iter   270/  960] train: loss: 0.2796783
[Epoch 6; Iter   300/  960] train: loss: 0.0286884
[Epoch 6; Iter   330/  960] train: loss: 0.0288870
[Epoch 6; Iter   360/  960] train: loss: 0.1286892
[Epoch 6; Iter   390/  960] train: loss: 0.2632892
[Epoch 6; Iter   420/  960] train: loss: 0.1615039
[Epoch 6; Iter   450/  960] train: loss: 0.4416344
[Epoch 6; Iter   480/  960] train: loss: 0.1612561
[Epoch 6; Iter   510/  960] train: loss: 0.3157795
[Epoch 6; Iter   540/  960] train: loss: 0.1703684
[Epoch 6; Iter   570/  960] train: loss: 0.0575900
[Epoch 6; Iter   600/  960] train: loss: 0.1416019
[Epoch 6; Iter   630/  960] train: loss: 0.0363679
[Epoch 6; Iter   660/  960] train: loss: 0.0502563
[Epoch 6; Iter   690/  960] train: loss: 0.0228986
[Epoch 6; Iter   720/  960] train: loss: 0.0271778
[Epoch 6; Iter   750/  960] train: loss: 0.4865172
[Epoch 6; Iter   780/  960] train: loss: 0.0534314
[Epoch 6; Iter   810/  960] train: loss: 0.1239866
[Epoch 6; Iter   840/  960] train: loss: 0.0343530
[Epoch 6; Iter   870/  960] train: loss: 0.2835650
[Epoch 6; Iter   900/  960] train: loss: 0.0333296
[Epoch 6; Iter   930/  960] train: loss: 0.0264452
[Epoch 6; Iter   960/  960] train: loss: 0.1975922
[Epoch 6] ogbg-molhiv: 0.769905 val loss: 0.158599
[Epoch 6] ogbg-molhiv: 0.775780 test loss: 0.154907
[Epoch 7; Iter    30/  960] train: loss: 0.0281284
[Epoch 7; Iter    60/  960] train: loss: 0.1302449
[Epoch 7; Iter    90/  960] train: loss: 0.0344056
[Epoch 7; Iter   120/  960] train: loss: 0.0240559
[Epoch 7; Iter   150/  960] train: loss: 0.0266984
[Epoch 7; Iter   180/  960] train: loss: 0.1550326
[Epoch 7; Iter   210/  960] train: loss: 0.0788329
[Epoch 7; Iter   240/  960] train: loss: 0.0265404
[Epoch 7; Iter   270/  960] train: loss: 0.0298388
[Epoch 7; Iter   300/  960] train: loss: 0.1652550
[Epoch 7; Iter   330/  960] train: loss: 0.0819293
[Epoch 7; Iter   360/  960] train: loss: 0.0303547
[Epoch 7; Iter   390/  960] train: loss: 0.0645140
[Epoch 7; Iter   420/  960] train: loss: 0.1052449
[Epoch 7; Iter   450/  960] train: loss: 0.3197338
[Epoch 7; Iter   480/  960] train: loss: 0.1258271
[Epoch 7; Iter   510/  960] train: loss: 0.0829820
[Epoch 7; Iter   540/  960] train: loss: 0.0286990
[Epoch 7; Iter   570/  960] train: loss: 0.1308067
[Epoch 7; Iter   600/  960] train: loss: 0.0471051
[Epoch 7; Iter   630/  960] train: loss: 0.0321440
[Epoch 7; Iter   660/  960] train: loss: 0.0700032
[Epoch 7; Iter   690/  960] train: loss: 0.0197980
[Epoch 7; Iter   720/  960] train: loss: 0.5256373
[Epoch 7; Iter   750/  960] train: loss: 0.0282884
[Epoch 7; Iter   780/  960] train: loss: 0.1400234
[Epoch 7; Iter   810/  960] train: loss: 0.1193919
[Epoch 7; Iter   840/  960] train: loss: 0.0979734
[Epoch 7; Iter   870/  960] train: loss: 0.0648815
[Epoch 7; Iter   900/  960] train: loss: 0.0413486
[Epoch 7; Iter   930/  960] train: loss: 0.2449245
[Epoch 7; Iter   960/  960] train: loss: 0.2089997
[Epoch 7] ogbg-molhiv: 0.763761 val loss: 0.196244
[Epoch 7] ogbg-molhiv: 0.783899 test loss: 0.130679
[Epoch 8; Iter    30/  960] train: loss: 0.0382753
[Epoch 8; Iter    60/  960] train: loss: 0.2551388
[Epoch 8; Iter    90/  960] train: loss: 0.2695018
[Epoch 8; Iter   120/  960] train: loss: 0.2793244
[Epoch 8; Iter   150/  960] train: loss: 0.0413140
[Epoch 8; Iter   180/  960] train: loss: 0.0496721
[Epoch 8; Iter   210/  960] train: loss: 0.0472093
[Epoch 8; Iter   240/  960] train: loss: 0.1342291
[Epoch 8; Iter   270/  960] train: loss: 0.0283480
[Epoch 8; Iter   300/  960] train: loss: 0.0199903
[Epoch 8; Iter   330/  960] train: loss: 0.0552445
[Epoch 8; Iter   360/  960] train: loss: 0.1552418
[Epoch 8; Iter   390/  960] train: loss: 0.2009387
[Epoch 8; Iter   420/  960] train: loss: 0.0716608
[Epoch 8; Iter   450/  960] train: loss: 0.1648812
[Epoch 8; Iter   480/  960] train: loss: 0.3062159
[Epoch 8; Iter   510/  960] train: loss: 0.1490322
[Epoch 8; Iter   540/  960] train: loss: 0.1160566
[Epoch 8; Iter   570/  960] train: loss: 0.0348456
[Epoch 8; Iter   600/  960] train: loss: 0.3164678
[Epoch 8; Iter   630/  960] train: loss: 0.1302112
[Epoch 8; Iter   660/  960] train: loss: 0.1149525
[Epoch 8; Iter   690/  960] train: loss: 0.1785017
[Epoch 8; Iter   720/  960] train: loss: 0.0337365
[Epoch 8; Iter   750/  960] train: loss: 0.2682430
[Epoch 8; Iter   780/  960] train: loss: 0.0266597
[Epoch 8; Iter   810/  960] train: loss: 0.0339017
[Epoch 8; Iter   840/  960] train: loss: 0.0383524
[Epoch 8; Iter   870/  960] train: loss: 0.0951050
[Epoch 8; Iter   900/  960] train: loss: 0.1633680
[Epoch 8; Iter   930/  960] train: loss: 0.1536729
[Epoch 8; Iter   960/  960] train: loss: 0.0331305

[Epoch 4; Iter   681/  823] train: loss: 0.1196800
[Epoch 4; Iter   711/  823] train: loss: 0.0380571
[Epoch 4; Iter   741/  823] train: loss: 0.2901117
[Epoch 4; Iter   771/  823] train: loss: 0.1745390
[Epoch 4; Iter   801/  823] train: loss: 0.3781570
[Epoch 4] ogbg-molhiv: 0.711813 val loss: 0.218239
[Epoch 4] ogbg-molhiv: 0.705535 test loss: 0.201663
[Epoch 5; Iter     8/  823] train: loss: 0.0458746
[Epoch 5; Iter    38/  823] train: loss: 0.1513654
[Epoch 5; Iter    68/  823] train: loss: 0.0871999
[Epoch 5; Iter    98/  823] train: loss: 0.0345763
[Epoch 5; Iter   128/  823] train: loss: 0.0304407
[Epoch 5; Iter   158/  823] train: loss: 0.0300878
[Epoch 5; Iter   188/  823] train: loss: 0.1480069
[Epoch 5; Iter   218/  823] train: loss: 0.1336972
[Epoch 5; Iter   248/  823] train: loss: 0.0393464
[Epoch 5; Iter   278/  823] train: loss: 0.0350594
[Epoch 5; Iter   308/  823] train: loss: 0.1133875
[Epoch 5; Iter   338/  823] train: loss: 0.0274032
[Epoch 5; Iter   368/  823] train: loss: 0.1412205
[Epoch 5; Iter   398/  823] train: loss: 0.2569691
[Epoch 5; Iter   428/  823] train: loss: 0.0301314
[Epoch 5; Iter   458/  823] train: loss: 0.1364374
[Epoch 5; Iter   488/  823] train: loss: 0.2023197
[Epoch 5; Iter   518/  823] train: loss: 0.1754918
[Epoch 5; Iter   548/  823] train: loss: 0.0290051
[Epoch 5; Iter   578/  823] train: loss: 0.2162798
[Epoch 5; Iter   608/  823] train: loss: 0.1638888
[Epoch 5; Iter   638/  823] train: loss: 0.3224982
[Epoch 5; Iter   668/  823] train: loss: 0.0320302
[Epoch 5; Iter   698/  823] train: loss: 0.3081441
[Epoch 5; Iter   728/  823] train: loss: 0.0289083
[Epoch 5; Iter   758/  823] train: loss: 0.0280715
[Epoch 5; Iter   788/  823] train: loss: 0.0500435
[Epoch 5; Iter   818/  823] train: loss: 0.1473949
[Epoch 5] ogbg-molhiv: 0.742751 val loss: 0.195169
[Epoch 5] ogbg-molhiv: 0.731772 test loss: 0.179362
[Epoch 6; Iter    25/  823] train: loss: 0.1739780
[Epoch 6; Iter    55/  823] train: loss: 0.1781581
[Epoch 6; Iter    85/  823] train: loss: 0.0305530
[Epoch 6; Iter   115/  823] train: loss: 0.1813958
[Epoch 6; Iter   145/  823] train: loss: 0.2433979
[Epoch 6; Iter   175/  823] train: loss: 0.0699495
[Epoch 6; Iter   205/  823] train: loss: 0.2349497
[Epoch 6; Iter   235/  823] train: loss: 0.1206779
[Epoch 6; Iter   265/  823] train: loss: 0.3921178
[Epoch 6; Iter   295/  823] train: loss: 0.0323586
[Epoch 6; Iter   325/  823] train: loss: 0.1154850
[Epoch 6; Iter   355/  823] train: loss: 0.2275791
[Epoch 6; Iter   385/  823] train: loss: 0.1616837
[Epoch 6; Iter   415/  823] train: loss: 0.0401234
[Epoch 6; Iter   445/  823] train: loss: 0.0291756
[Epoch 6; Iter   475/  823] train: loss: 0.2447058
[Epoch 6; Iter   505/  823] train: loss: 0.0405377
[Epoch 6; Iter   535/  823] train: loss: 0.1635803
[Epoch 6; Iter   565/  823] train: loss: 0.0353219
[Epoch 6; Iter   595/  823] train: loss: 0.0443994
[Epoch 6; Iter   625/  823] train: loss: 0.1413208
[Epoch 6; Iter   655/  823] train: loss: 0.1621133
[Epoch 6; Iter   685/  823] train: loss: 0.1202887
[Epoch 6; Iter   715/  823] train: loss: 0.0342590
[Epoch 6; Iter   745/  823] train: loss: 0.1215247
[Epoch 6; Iter   775/  823] train: loss: 0.2761021
[Epoch 6; Iter   805/  823] train: loss: 0.0967066
[Epoch 6] ogbg-molhiv: 0.759763 val loss: 0.181688
[Epoch 6] ogbg-molhiv: 0.736425 test loss: 0.163770
[Epoch 7; Iter    12/  823] train: loss: 0.0665066
[Epoch 7; Iter    42/  823] train: loss: 0.2219363
[Epoch 7; Iter    72/  823] train: loss: 0.1722963
[Epoch 7; Iter   102/  823] train: loss: 0.1707343
[Epoch 7; Iter   132/  823] train: loss: 0.1919141
[Epoch 7; Iter   162/  823] train: loss: 0.0347904
[Epoch 7; Iter   192/  823] train: loss: 0.1568397
[Epoch 7; Iter   222/  823] train: loss: 0.1992313
[Epoch 7; Iter   252/  823] train: loss: 0.1578574
[Epoch 7; Iter   282/  823] train: loss: 0.1354851
[Epoch 7; Iter   312/  823] train: loss: 0.1783371
[Epoch 7; Iter   342/  823] train: loss: 0.3274020
[Epoch 7; Iter   372/  823] train: loss: 0.0284140
[Epoch 7; Iter   402/  823] train: loss: 0.0613342
[Epoch 7; Iter   432/  823] train: loss: 0.1227261
[Epoch 7; Iter   462/  823] train: loss: 0.0249800
[Epoch 7; Iter   492/  823] train: loss: 0.1661812
[Epoch 7; Iter   522/  823] train: loss: 0.3048035
[Epoch 7; Iter   552/  823] train: loss: 0.0260500
[Epoch 7; Iter   582/  823] train: loss: 0.1220713
[Epoch 7; Iter   612/  823] train: loss: 0.1515587
[Epoch 7; Iter   642/  823] train: loss: 0.1502203
[Epoch 7; Iter   672/  823] train: loss: 0.0349736
[Epoch 7; Iter   702/  823] train: loss: 0.0381826
[Epoch 7; Iter   732/  823] train: loss: 0.1581356
[Epoch 7; Iter   762/  823] train: loss: 0.1800074
[Epoch 7; Iter   792/  823] train: loss: 0.1482110
[Epoch 7; Iter   822/  823] train: loss: 0.1545287
[Epoch 7] ogbg-molhiv: 0.768729 val loss: 0.245698
[Epoch 7] ogbg-molhiv: 0.744074 test loss: 0.263180
[Epoch 8; Iter    29/  823] train: loss: 0.1403274
[Epoch 8; Iter    59/  823] train: loss: 0.3116798
[Epoch 8; Iter    89/  823] train: loss: 0.0981143
[Epoch 8; Iter   119/  823] train: loss: 0.0925287
[Epoch 8; Iter   149/  823] train: loss: 0.0306605
[Epoch 8; Iter   179/  823] train: loss: 0.0784949
[Epoch 8; Iter   209/  823] train: loss: 0.1874860
[Epoch 8; Iter   239/  823] train: loss: 0.0361619
[Epoch 8; Iter   269/  823] train: loss: 0.0385188
[Epoch 8; Iter   299/  823] train: loss: 0.0935099
[Epoch 8; Iter   329/  823] train: loss: 0.1555345
[Epoch 8; Iter   359/  823] train: loss: 0.2177889
[Epoch 8; Iter   389/  823] train: loss: 0.1109823
[Epoch 8; Iter   419/  823] train: loss: 0.2858149
[Epoch 8; Iter   449/  823] train: loss: 0.2185175
[Epoch 8; Iter   479/  823] train: loss: 0.0298067
[Epoch 8; Iter   509/  823] train: loss: 0.0257088
[Epoch 8; Iter   539/  823] train: loss: 0.0237031
[Epoch 8; Iter   569/  823] train: loss: 0.0249040
[Epoch 8; Iter   599/  823] train: loss: 0.2345175
[Epoch 8; Iter   629/  823] train: loss: 0.1524863
[Epoch 8; Iter   659/  823] train: loss: 0.0276506
[Epoch 8; Iter   689/  823] train: loss: 0.0281682
[Epoch 8; Iter   719/  823] train: loss: 0.1571220
[Epoch 8; Iter   749/  823] train: loss: 0.0745585
[Epoch 8; Iter   779/  823] train: loss: 0.1888627
[Epoch 8; Iter   809/  823] train: loss: 0.0478523
[Epoch 8] ogbg-molhiv: 0.779267 val loss: 1.258271
[Epoch 8] ogbg-molhiv: 0.753353 test loss: 1.301887
[Epoch 9; Iter    16/  823] train: loss: 0.1776505
[Epoch 9; Iter    46/  823] train: loss: 0.0269211
[Epoch 9; Iter    76/  823] train: loss: 0.0591798
[Epoch 9; Iter   106/  823] train: loss: 0.1389506
[Epoch 9; Iter   136/  823] train: loss: 0.0933169
[Epoch 9; Iter   166/  823] train: loss: 0.0242814
[Epoch 9; Iter   196/  823] train: loss: 0.2427521
[Epoch 9; Iter   226/  823] train: loss: 0.0257856
[Epoch 9; Iter   256/  823] train: loss: 0.0376293
[Epoch 9; Iter   286/  823] train: loss: 0.1399366
[Epoch 9; Iter   316/  823] train: loss: 0.0394025
[Epoch 9; Iter   346/  823] train: loss: 0.0245377
[Epoch 9; Iter   376/  823] train: loss: 0.2638527
[Epoch 9; Iter   406/  823] train: loss: 0.0331105
[Epoch 9; Iter   436/  823] train: loss: 0.1002998
[Epoch 9; Iter   466/  823] train: loss: 0.2668571
[Epoch 9; Iter   496/  823] train: loss: 0.0384201
[Epoch 9; Iter   526/  823] train: loss: 0.0403591
[Epoch 9; Iter   556/  823] train: loss: 0.4121992
[Epoch 9; Iter   586/  823] train: loss: 0.0250941
[Epoch 9; Iter   616/  823] train: loss: 0.0385654
[Epoch 9; Iter   646/  823] train: loss: 0.0246288
[Epoch 9; Iter   676/  823] train: loss: 0.0767141
[Epoch 9; Iter   706/  823] train: loss: 0.0630049
[Epoch 9; Iter   736/  823] train: loss: 0.0293720
[Epoch 9; Iter   766/  823] train: loss: 0.0350941
[Epoch 9; Iter   796/  823] train: loss: 0.0251954
[Epoch 9] ogbg-molhiv: 0.779103 val loss: 0.154440
[Epoch 9] ogbg-molhiv: 0.751206 test loss: 0.174972
[Epoch 10; Iter     3/  823] train: loss: 0.1507873
[Epoch 10; Iter    33/  823] train: loss: 0.0345815
[Epoch 10; Iter    63/  823] train: loss: 0.0243195
[Epoch 10; Iter    93/  823] train: loss: 0.1287373
[Epoch 10; Iter   123/  823] train: loss: 0.2482342
[Epoch 10; Iter   153/  823] train: loss: 0.0282158

[Epoch 4; Iter   681/  823] train: loss: 0.2021262
[Epoch 4; Iter   711/  823] train: loss: 0.0771344
[Epoch 4; Iter   741/  823] train: loss: 0.1607600
[Epoch 4; Iter   771/  823] train: loss: 0.1467920
[Epoch 4; Iter   801/  823] train: loss: 0.0353015
[Epoch 4] ogbg-molhiv: 0.703068 val loss: 0.163634
[Epoch 4] ogbg-molhiv: 0.710003 test loss: 0.178174
[Epoch 5; Iter     8/  823] train: loss: 0.0302218
[Epoch 5; Iter    38/  823] train: loss: 0.0809052
[Epoch 5; Iter    68/  823] train: loss: 0.1465179
[Epoch 5; Iter    98/  823] train: loss: 0.1670991
[Epoch 5; Iter   128/  823] train: loss: 0.1218661
[Epoch 5; Iter   158/  823] train: loss: 0.1971760
[Epoch 5; Iter   188/  823] train: loss: 0.0496035
[Epoch 5; Iter   218/  823] train: loss: 0.0350988
[Epoch 5; Iter   248/  823] train: loss: 0.1769216
[Epoch 5; Iter   278/  823] train: loss: 0.1986956
[Epoch 5; Iter   308/  823] train: loss: 0.0250097
[Epoch 5; Iter   338/  823] train: loss: 0.1297491
[Epoch 5; Iter   368/  823] train: loss: 0.1501627
[Epoch 5; Iter   398/  823] train: loss: 0.0254829
[Epoch 5; Iter   428/  823] train: loss: 0.0264774
[Epoch 5; Iter   458/  823] train: loss: 0.2383386
[Epoch 5; Iter   488/  823] train: loss: 0.0381015
[Epoch 5; Iter   518/  823] train: loss: 0.0446127
[Epoch 5; Iter   548/  823] train: loss: 0.3942834
[Epoch 5; Iter   578/  823] train: loss: 0.0934214
[Epoch 5; Iter   608/  823] train: loss: 0.0523529
[Epoch 5; Iter   638/  823] train: loss: 0.0806235
[Epoch 5; Iter   668/  823] train: loss: 0.1913931
[Epoch 5; Iter   698/  823] train: loss: 0.5361577
[Epoch 5; Iter   728/  823] train: loss: 0.2635087
[Epoch 5; Iter   758/  823] train: loss: 0.0322250
[Epoch 5; Iter   788/  823] train: loss: 0.1365845
[Epoch 5; Iter   818/  823] train: loss: 0.1287416
[Epoch 5] ogbg-molhiv: 0.743275 val loss: 0.198674
[Epoch 5] ogbg-molhiv: 0.717657 test loss: 0.214093
[Epoch 6; Iter    25/  823] train: loss: 0.1911440
[Epoch 6; Iter    55/  823] train: loss: 0.4751559
[Epoch 6; Iter    85/  823] train: loss: 0.1038490
[Epoch 6; Iter   115/  823] train: loss: 0.0852825
[Epoch 6; Iter   145/  823] train: loss: 0.2573299
[Epoch 6; Iter   175/  823] train: loss: 0.0312464
[Epoch 6; Iter   205/  823] train: loss: 0.0288465
[Epoch 6; Iter   235/  823] train: loss: 0.0258990
[Epoch 6; Iter   265/  823] train: loss: 0.1490675
[Epoch 6; Iter   295/  823] train: loss: 0.2767094
[Epoch 6; Iter   325/  823] train: loss: 0.1925196
[Epoch 6; Iter   355/  823] train: loss: 0.2998389
[Epoch 6; Iter   385/  823] train: loss: 0.2599501
[Epoch 6; Iter   415/  823] train: loss: 0.1246265
[Epoch 6; Iter   445/  823] train: loss: 0.0317718
[Epoch 6; Iter   475/  823] train: loss: 0.1445353
[Epoch 6; Iter   505/  823] train: loss: 0.1015118
[Epoch 6; Iter   535/  823] train: loss: 0.1138615
[Epoch 6; Iter   565/  823] train: loss: 0.1450102
[Epoch 6; Iter   595/  823] train: loss: 0.0273650
[Epoch 6; Iter   625/  823] train: loss: 0.1283490
[Epoch 6; Iter   655/  823] train: loss: 0.1134191
[Epoch 6; Iter   685/  823] train: loss: 0.0327837
[Epoch 6; Iter   715/  823] train: loss: 0.2295872
[Epoch 6; Iter   745/  823] train: loss: 0.0349218
[Epoch 6; Iter   775/  823] train: loss: 0.0906642
[Epoch 6; Iter   805/  823] train: loss: 0.0287184
[Epoch 6] ogbg-molhiv: 0.759118 val loss: 0.402581
[Epoch 6] ogbg-molhiv: 0.741774 test loss: 0.521155
[Epoch 7; Iter    12/  823] train: loss: 0.2741120
[Epoch 7; Iter    42/  823] train: loss: 0.0316012
[Epoch 7; Iter    72/  823] train: loss: 0.0227935
[Epoch 7; Iter   102/  823] train: loss: 0.1851745
[Epoch 7; Iter   132/  823] train: loss: 0.0274347
[Epoch 7; Iter   162/  823] train: loss: 0.0285177
[Epoch 7; Iter   192/  823] train: loss: 0.1275774
[Epoch 7; Iter   222/  823] train: loss: 0.1831300
[Epoch 7; Iter   252/  823] train: loss: 0.0350051
[Epoch 7; Iter   282/  823] train: loss: 0.1552589
[Epoch 7; Iter   312/  823] train: loss: 0.1100653
[Epoch 7; Iter   342/  823] train: loss: 0.0415553
[Epoch 7; Iter   372/  823] train: loss: 0.0301608
[Epoch 7; Iter   402/  823] train: loss: 0.0304789
[Epoch 7; Iter   432/  823] train: loss: 0.1395204
[Epoch 7; Iter   462/  823] train: loss: 0.0300396
[Epoch 7; Iter   492/  823] train: loss: 0.0795126
[Epoch 7; Iter   522/  823] train: loss: 0.1710968
[Epoch 7; Iter   552/  823] train: loss: 0.0270309
[Epoch 7; Iter   582/  823] train: loss: 0.1101648
[Epoch 7; Iter   612/  823] train: loss: 0.1130473
[Epoch 7; Iter   642/  823] train: loss: 0.1244409
[Epoch 7; Iter   672/  823] train: loss: 0.0295057
[Epoch 7; Iter   702/  823] train: loss: 0.0770991
[Epoch 7; Iter   732/  823] train: loss: 0.0359349
[Epoch 7; Iter   762/  823] train: loss: 0.1267400
[Epoch 7; Iter   792/  823] train: loss: 0.2865408
[Epoch 7; Iter   822/  823] train: loss: 0.0371664
[Epoch 7] ogbg-molhiv: 0.769116 val loss: 0.131670
[Epoch 7] ogbg-molhiv: 0.729474 test loss: 0.139470
[Epoch 8; Iter    29/  823] train: loss: 0.0357996
[Epoch 8; Iter    59/  823] train: loss: 0.0467788
[Epoch 8; Iter    89/  823] train: loss: 0.0282592
[Epoch 8; Iter   119/  823] train: loss: 0.0764601
[Epoch 8; Iter   149/  823] train: loss: 0.2422405
[Epoch 8; Iter   179/  823] train: loss: 0.0248498
[Epoch 8; Iter   209/  823] train: loss: 0.2632995
[Epoch 8; Iter   239/  823] train: loss: 0.0359863
[Epoch 8; Iter   269/  823] train: loss: 0.3048200
[Epoch 8; Iter   299/  823] train: loss: 0.2448094
[Epoch 8; Iter   329/  823] train: loss: 0.0266791
[Epoch 8; Iter   359/  823] train: loss: 0.2837483
[Epoch 8; Iter   389/  823] train: loss: 0.2200311
[Epoch 8; Iter   419/  823] train: loss: 0.1401193
[Epoch 8; Iter   449/  823] train: loss: 0.1792596
[Epoch 8; Iter   479/  823] train: loss: 0.1179725
[Epoch 8; Iter   509/  823] train: loss: 0.0288749
[Epoch 8; Iter   539/  823] train: loss: 0.0287297
[Epoch 8; Iter   569/  823] train: loss: 0.0281747
[Epoch 8; Iter   599/  823] train: loss: 0.1825259
[Epoch 8; Iter   629/  823] train: loss: 0.1401409
[Epoch 8; Iter   659/  823] train: loss: 0.1273494
[Epoch 8; Iter   689/  823] train: loss: 0.0325351
[Epoch 8; Iter   719/  823] train: loss: 0.0326578
[Epoch 8; Iter   749/  823] train: loss: 0.0297834
[Epoch 8; Iter   779/  823] train: loss: 0.0312064
[Epoch 8; Iter   809/  823] train: loss: 0.1975104
[Epoch 8] ogbg-molhiv: 0.769990 val loss: 0.165167
[Epoch 8] ogbg-molhiv: 0.733759 test loss: 0.181217
[Epoch 9; Iter    16/  823] train: loss: 0.0400793
[Epoch 9; Iter    46/  823] train: loss: 0.0788262
[Epoch 9; Iter    76/  823] train: loss: 0.1726931
[Epoch 9; Iter   106/  823] train: loss: 0.0357649
[Epoch 9; Iter   136/  823] train: loss: 0.2436865
[Epoch 9; Iter   166/  823] train: loss: 0.0302649
[Epoch 9; Iter   196/  823] train: loss: 0.0280748
[Epoch 9; Iter   226/  823] train: loss: 0.3515157
[Epoch 9; Iter   256/  823] train: loss: 0.2994061
[Epoch 9; Iter   286/  823] train: loss: 0.0229848
[Epoch 9; Iter   316/  823] train: loss: 0.0746152
[Epoch 9; Iter   346/  823] train: loss: 0.1040285
[Epoch 9; Iter   376/  823] train: loss: 0.6280761
[Epoch 9; Iter   406/  823] train: loss: 0.0237361
[Epoch 9; Iter   436/  823] train: loss: 0.0255703
[Epoch 9; Iter   466/  823] train: loss: 0.0646009
[Epoch 9; Iter   496/  823] train: loss: 0.0291781
[Epoch 9; Iter   526/  823] train: loss: 0.1273542
[Epoch 9; Iter   556/  823] train: loss: 0.1622416
[Epoch 9; Iter   586/  823] train: loss: 0.0985179
[Epoch 9; Iter   616/  823] train: loss: 0.0356375
[Epoch 9; Iter   646/  823] train: loss: 0.0350928
[Epoch 9; Iter   676/  823] train: loss: 0.0322092
[Epoch 9; Iter   706/  823] train: loss: 0.3783916
[Epoch 9; Iter   736/  823] train: loss: 0.0350432
[Epoch 9; Iter   766/  823] train: loss: 0.2226482
[Epoch 9; Iter   796/  823] train: loss: 0.0324594
[Epoch 9] ogbg-molhiv: 0.791459 val loss: 0.419394
[Epoch 9] ogbg-molhiv: 0.748934 test loss: 0.527719
[Epoch 10; Iter     3/  823] train: loss: 0.3615864
[Epoch 10; Iter    33/  823] train: loss: 0.0287780
[Epoch 10; Iter    63/  823] train: loss: 0.0481567
[Epoch 10; Iter    93/  823] train: loss: 0.1111508
[Epoch 10; Iter   123/  823] train: loss: 0.1182373
[Epoch 10; Iter   153/  823] train: loss: 0.1007363

[Epoch 4; Iter   681/  823] train: loss: 0.1423160
[Epoch 4; Iter   711/  823] train: loss: 0.0339263
[Epoch 4; Iter   741/  823] train: loss: 0.1467065
[Epoch 4; Iter   771/  823] train: loss: 0.0291358
[Epoch 4; Iter   801/  823] train: loss: 0.1772834
[Epoch 4] ogbg-molhiv: 0.756162 val loss: 0.135538
[Epoch 4] ogbg-molhiv: 0.728002 test loss: 0.135145
[Epoch 5; Iter     8/  823] train: loss: 0.0491293
[Epoch 5; Iter    38/  823] train: loss: 0.0430901
[Epoch 5; Iter    68/  823] train: loss: 0.0298448
[Epoch 5; Iter    98/  823] train: loss: 0.1286359
[Epoch 5; Iter   128/  823] train: loss: 0.1610944
[Epoch 5; Iter   158/  823] train: loss: 0.3079898
[Epoch 5; Iter   188/  823] train: loss: 0.0325679
[Epoch 5; Iter   218/  823] train: loss: 0.1341639
[Epoch 5; Iter   248/  823] train: loss: 0.0488834
[Epoch 5; Iter   278/  823] train: loss: 0.1243063
[Epoch 5; Iter   308/  823] train: loss: 0.0322759
[Epoch 5; Iter   338/  823] train: loss: 0.2156399
[Epoch 5; Iter   368/  823] train: loss: 0.1316639
[Epoch 5; Iter   398/  823] train: loss: 0.1805554
[Epoch 5; Iter   428/  823] train: loss: 0.0262734
[Epoch 5; Iter   458/  823] train: loss: 0.2341687
[Epoch 5; Iter   488/  823] train: loss: 0.1514937
[Epoch 5; Iter   518/  823] train: loss: 0.1112607
[Epoch 5; Iter   548/  823] train: loss: 0.0281262
[Epoch 5; Iter   578/  823] train: loss: 0.2692810
[Epoch 5; Iter   608/  823] train: loss: 0.0303450
[Epoch 5; Iter   638/  823] train: loss: 0.0483832
[Epoch 5; Iter   668/  823] train: loss: 0.0299336
[Epoch 5; Iter   698/  823] train: loss: 0.0326122
[Epoch 5; Iter   728/  823] train: loss: 0.0349304
[Epoch 5; Iter   758/  823] train: loss: 0.0276337
[Epoch 5; Iter   788/  823] train: loss: 0.0267491
[Epoch 5; Iter   818/  823] train: loss: 0.2202308
[Epoch 5] ogbg-molhiv: 0.769532 val loss: 0.174931
[Epoch 5] ogbg-molhiv: 0.746193 test loss: 0.149055
[Epoch 6; Iter    25/  823] train: loss: 0.2726830
[Epoch 6; Iter    55/  823] train: loss: 0.0344215
[Epoch 6; Iter    85/  823] train: loss: 0.0796589
[Epoch 6; Iter   115/  823] train: loss: 0.0888455
[Epoch 6; Iter   145/  823] train: loss: 0.0297638
[Epoch 6; Iter   175/  823] train: loss: 0.0281472
[Epoch 6; Iter   205/  823] train: loss: 0.1042251
[Epoch 6; Iter   235/  823] train: loss: 0.0287984
[Epoch 6; Iter   265/  823] train: loss: 0.0333638
[Epoch 6; Iter   295/  823] train: loss: 0.0732815
[Epoch 6; Iter   325/  823] train: loss: 0.0340039
[Epoch 6; Iter   355/  823] train: loss: 0.2889361
[Epoch 6; Iter   385/  823] train: loss: 0.0269976
[Epoch 6; Iter   415/  823] train: loss: 0.1462693
[Epoch 6; Iter   445/  823] train: loss: 0.0252245
[Epoch 6; Iter   475/  823] train: loss: 0.2036556
[Epoch 6; Iter   505/  823] train: loss: 0.1480359
[Epoch 6; Iter   535/  823] train: loss: 0.0376792
[Epoch 6; Iter   565/  823] train: loss: 0.0408982
[Epoch 6; Iter   595/  823] train: loss: 0.4242136
[Epoch 6; Iter   625/  823] train: loss: 0.1581614
[Epoch 6; Iter   655/  823] train: loss: 0.3665372
[Epoch 6; Iter   685/  823] train: loss: 0.0658527
[Epoch 6; Iter   715/  823] train: loss: 0.0369135
[Epoch 6; Iter   745/  823] train: loss: 0.2708049
[Epoch 6; Iter   775/  823] train: loss: 0.0281962
[Epoch 6; Iter   805/  823] train: loss: 0.0288509
[Epoch 6] ogbg-molhiv: 0.759132 val loss: 0.362344
[Epoch 6] ogbg-molhiv: 0.743065 test loss: 0.448115
[Epoch 7; Iter    12/  823] train: loss: 0.1399096
[Epoch 7; Iter    42/  823] train: loss: 0.1199653
[Epoch 7; Iter    72/  823] train: loss: 0.0790683
[Epoch 7; Iter   102/  823] train: loss: 0.2887841
[Epoch 7; Iter   132/  823] train: loss: 0.2134575
[Epoch 7; Iter   162/  823] train: loss: 0.0259825
[Epoch 7; Iter   192/  823] train: loss: 0.2193582
[Epoch 7; Iter   222/  823] train: loss: 0.1510869
[Epoch 7; Iter   252/  823] train: loss: 0.2477340
[Epoch 7; Iter   282/  823] train: loss: 0.1575073
[Epoch 7; Iter   312/  823] train: loss: 0.1723039
[Epoch 7; Iter   342/  823] train: loss: 0.0337621
[Epoch 7; Iter   372/  823] train: loss: 0.0343574
[Epoch 7; Iter   402/  823] train: loss: 0.1308619
[Epoch 7; Iter   432/  823] train: loss: 0.2142412
[Epoch 7; Iter   462/  823] train: loss: 0.0339107
[Epoch 7; Iter   492/  823] train: loss: 0.0260138
[Epoch 7; Iter   522/  823] train: loss: 0.1834773
[Epoch 7; Iter   552/  823] train: loss: 0.0275020
[Epoch 7; Iter   582/  823] train: loss: 0.0771593
[Epoch 7; Iter   612/  823] train: loss: 0.2379224
[Epoch 7; Iter   642/  823] train: loss: 0.1345531
[Epoch 7; Iter   672/  823] train: loss: 0.0270462
[Epoch 7; Iter   702/  823] train: loss: 0.1704868
[Epoch 7; Iter   732/  823] train: loss: 0.0328128
[Epoch 7; Iter   762/  823] train: loss: 0.0270223
[Epoch 7; Iter   792/  823] train: loss: 0.0271771
[Epoch 7; Iter   822/  823] train: loss: 0.0925430
[Epoch 7] ogbg-molhiv: 0.774691 val loss: 0.152388
[Epoch 7] ogbg-molhiv: 0.753013 test loss: 0.168006
[Epoch 8; Iter    29/  823] train: loss: 0.1670114
[Epoch 8; Iter    59/  823] train: loss: 0.1753901
[Epoch 8; Iter    89/  823] train: loss: 0.1588914
[Epoch 8; Iter   119/  823] train: loss: 0.1661444
[Epoch 8; Iter   149/  823] train: loss: 0.0303653
[Epoch 8; Iter   179/  823] train: loss: 0.1075680
[Epoch 8; Iter   209/  823] train: loss: 0.0591001
[Epoch 8; Iter   239/  823] train: loss: 0.0396694
[Epoch 8; Iter   269/  823] train: loss: 0.2112192
[Epoch 8; Iter   299/  823] train: loss: 0.1700927
[Epoch 8; Iter   329/  823] train: loss: 0.1542514
[Epoch 8; Iter   359/  823] train: loss: 0.1445539
[Epoch 8; Iter   389/  823] train: loss: 0.0257704
[Epoch 8; Iter   419/  823] train: loss: 0.1803324
[Epoch 8; Iter   449/  823] train: loss: 0.0279524
[Epoch 8; Iter   479/  823] train: loss: 0.1502238
[Epoch 8; Iter   509/  823] train: loss: 0.1279093
[Epoch 8; Iter   539/  823] train: loss: 0.0443614
[Epoch 8; Iter   569/  823] train: loss: 0.2776822
[Epoch 8; Iter   599/  823] train: loss: 0.1243289
[Epoch 8; Iter   629/  823] train: loss: 0.1806648
[Epoch 8; Iter   659/  823] train: loss: 0.2169760
[Epoch 8; Iter   689/  823] train: loss: 0.1822965
[Epoch 8; Iter   719/  823] train: loss: 0.2166663
[Epoch 8; Iter   749/  823] train: loss: 0.1395122
[Epoch 8; Iter   779/  823] train: loss: 0.0847577
[Epoch 8; Iter   809/  823] train: loss: 0.0218579
[Epoch 8] ogbg-molhiv: 0.777515 val loss: 0.128094
[Epoch 8] ogbg-molhiv: 0.772209 test loss: 0.127624
[Epoch 9; Iter    16/  823] train: loss: 0.0205196
[Epoch 9; Iter    46/  823] train: loss: 0.1615141
[Epoch 9; Iter    76/  823] train: loss: 0.0332599
[Epoch 9; Iter   106/  823] train: loss: 0.2011553
[Epoch 9; Iter   136/  823] train: loss: 0.0973066
[Epoch 9; Iter   166/  823] train: loss: 0.0574417
[Epoch 9; Iter   196/  823] train: loss: 0.0364707
[Epoch 9; Iter   226/  823] train: loss: 0.1550431
[Epoch 9; Iter   256/  823] train: loss: 0.0289190
[Epoch 9; Iter   286/  823] train: loss: 0.0246108
[Epoch 9; Iter   316/  823] train: loss: 0.1247019
[Epoch 9; Iter   346/  823] train: loss: 0.2075366
[Epoch 9; Iter   376/  823] train: loss: 0.0596859
[Epoch 9; Iter   406/  823] train: loss: 0.1129369
[Epoch 9; Iter   436/  823] train: loss: 0.1649407
[Epoch 9; Iter   466/  823] train: loss: 0.0527640
[Epoch 9; Iter   496/  823] train: loss: 0.1236969
[Epoch 9; Iter   526/  823] train: loss: 0.0818462
[Epoch 9; Iter   556/  823] train: loss: 0.1087390
[Epoch 9; Iter   586/  823] train: loss: 0.3495972
[Epoch 9; Iter   616/  823] train: loss: 0.0713839
[Epoch 9; Iter   646/  823] train: loss: 0.1080061
[Epoch 9; Iter   676/  823] train: loss: 0.1629254
[Epoch 9; Iter   706/  823] train: loss: 0.1890575
[Epoch 9; Iter   736/  823] train: loss: 0.1063701
[Epoch 9; Iter   766/  823] train: loss: 0.0349951
[Epoch 9; Iter   796/  823] train: loss: 0.0324430
[Epoch 9] ogbg-molhiv: 0.773843 val loss: 0.133121
[Epoch 9] ogbg-molhiv: 0.752392 test loss: 0.132907
[Epoch 10; Iter     3/  823] train: loss: 0.0300080
[Epoch 10; Iter    33/  823] train: loss: 0.0608624
[Epoch 10; Iter    63/  823] train: loss: 0.4635494
[Epoch 10; Iter    93/  823] train: loss: 0.0551577
[Epoch 10; Iter   123/  823] train: loss: 0.1099659
[Epoch 10; Iter   153/  823] train: loss: 0.1341175
[Epoch 8; Iter    31/ 1097] train: loss: 0.1941547
[Epoch 8; Iter    61/ 1097] train: loss: 0.0311377
[Epoch 8; Iter    91/ 1097] train: loss: 0.2703020
[Epoch 8; Iter   121/ 1097] train: loss: 0.0385319
[Epoch 8; Iter   151/ 1097] train: loss: 0.0586549
[Epoch 8; Iter   181/ 1097] train: loss: 0.0505985
[Epoch 8; Iter   211/ 1097] train: loss: 0.0548898
[Epoch 8; Iter   241/ 1097] train: loss: 0.0902547
[Epoch 8; Iter   271/ 1097] train: loss: 0.0338374
[Epoch 8; Iter   301/ 1097] train: loss: 0.3176697
[Epoch 8; Iter   331/ 1097] train: loss: 0.5264553
[Epoch 8; Iter   361/ 1097] train: loss: 0.0321425
[Epoch 8; Iter   391/ 1097] train: loss: 0.0964219
[Epoch 8; Iter   421/ 1097] train: loss: 0.2197242
[Epoch 8; Iter   451/ 1097] train: loss: 0.0298485
[Epoch 8; Iter   481/ 1097] train: loss: 0.2427925
[Epoch 8; Iter   511/ 1097] train: loss: 0.1911824
[Epoch 8; Iter   541/ 1097] train: loss: 0.1115200
[Epoch 8; Iter   571/ 1097] train: loss: 0.2707869
[Epoch 8; Iter   601/ 1097] train: loss: 0.0456406
[Epoch 8; Iter   631/ 1097] train: loss: 0.0578109
[Epoch 8; Iter   661/ 1097] train: loss: 0.2443627
[Epoch 8; Iter   691/ 1097] train: loss: 0.0350875
[Epoch 8; Iter   721/ 1097] train: loss: 0.0501133
[Epoch 8; Iter   751/ 1097] train: loss: 0.1738593
[Epoch 8; Iter   781/ 1097] train: loss: 0.0427534
[Epoch 8; Iter   811/ 1097] train: loss: 0.1514996
[Epoch 8; Iter   841/ 1097] train: loss: 0.3019008
[Epoch 8; Iter   871/ 1097] train: loss: 0.0272301
[Epoch 8; Iter   901/ 1097] train: loss: 0.0238069
[Epoch 8; Iter   931/ 1097] train: loss: 0.1191053
[Epoch 8; Iter   961/ 1097] train: loss: 0.3445500
[Epoch 8; Iter   991/ 1097] train: loss: 0.1552407
[Epoch 8; Iter  1021/ 1097] train: loss: 0.0291737
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0323065
[Epoch 8; Iter  1081/ 1097] train: loss: 0.2845577
[Epoch 8] ogbg-molhiv: 0.736020 val loss: 0.302541
[Epoch 8] ogbg-molhiv: 0.719949 test loss: 0.295085
[Epoch 9; Iter    14/ 1097] train: loss: 0.0390429
[Epoch 9; Iter    44/ 1097] train: loss: 0.0333500
[Epoch 9; Iter    74/ 1097] train: loss: 0.1253961
[Epoch 9; Iter   104/ 1097] train: loss: 0.0332781
[Epoch 9; Iter   134/ 1097] train: loss: 0.0991904
[Epoch 9; Iter   164/ 1097] train: loss: 0.3062119
[Epoch 9; Iter   194/ 1097] train: loss: 0.0256480
[Epoch 9; Iter   224/ 1097] train: loss: 0.0371706
[Epoch 9; Iter   254/ 1097] train: loss: 0.1593671
[Epoch 9; Iter   284/ 1097] train: loss: 0.0609696
[Epoch 9; Iter   314/ 1097] train: loss: 0.0308764
[Epoch 9; Iter   344/ 1097] train: loss: 0.0313226
[Epoch 9; Iter   374/ 1097] train: loss: 0.1421676
[Epoch 9; Iter   404/ 1097] train: loss: 0.0287366
[Epoch 9; Iter   434/ 1097] train: loss: 0.1863375
[Epoch 9; Iter   464/ 1097] train: loss: 0.1105032
[Epoch 9; Iter   494/ 1097] train: loss: 0.1567560
[Epoch 9; Iter   524/ 1097] train: loss: 0.2180745
[Epoch 9; Iter   554/ 1097] train: loss: 0.0710711
[Epoch 9; Iter   584/ 1097] train: loss: 0.0315734
[Epoch 9; Iter   614/ 1097] train: loss: 0.1514631
[Epoch 9; Iter   644/ 1097] train: loss: 0.1658182
[Epoch 9; Iter   674/ 1097] train: loss: 0.0285415
[Epoch 9; Iter   704/ 1097] train: loss: 0.0361014
[Epoch 9; Iter   734/ 1097] train: loss: 0.0622491
[Epoch 9; Iter   764/ 1097] train: loss: 0.0401018
[Epoch 9; Iter   794/ 1097] train: loss: 0.2479218
[Epoch 9; Iter   824/ 1097] train: loss: 0.1576729
[Epoch 9; Iter   854/ 1097] train: loss: 0.2847629
[Epoch 9; Iter   884/ 1097] train: loss: 0.1086312
[Epoch 9; Iter   914/ 1097] train: loss: 0.1576485
[Epoch 9; Iter   944/ 1097] train: loss: 0.1363323
[Epoch 9; Iter   974/ 1097] train: loss: 0.0274929
[Epoch 9; Iter  1004/ 1097] train: loss: 0.1690305
[Epoch 9; Iter  1034/ 1097] train: loss: 0.2603113
[Epoch 9; Iter  1064/ 1097] train: loss: 0.1527553
[Epoch 9; Iter  1094/ 1097] train: loss: 0.0350255
[Epoch 9] ogbg-molhiv: 0.752333 val loss: 0.202298
[Epoch 9] ogbg-molhiv: 0.711629 test loss: 0.181286
[Epoch 10; Iter    27/ 1097] train: loss: 0.0329426
[Epoch 10; Iter    57/ 1097] train: loss: 0.0490571
[Epoch 10; Iter    87/ 1097] train: loss: 0.2930936
[Epoch 10; Iter   117/ 1097] train: loss: 0.1998841
[Epoch 10; Iter   147/ 1097] train: loss: 0.1432824
[Epoch 10; Iter   177/ 1097] train: loss: 0.1567754
[Epoch 10; Iter   207/ 1097] train: loss: 0.0322970
[Epoch 10; Iter   237/ 1097] train: loss: 0.4961925
[Epoch 10; Iter   267/ 1097] train: loss: 0.2488281
[Epoch 10; Iter   297/ 1097] train: loss: 0.0972438
[Epoch 10; Iter   327/ 1097] train: loss: 0.1461262
[Epoch 10; Iter   357/ 1097] train: loss: 0.0991177
[Epoch 10; Iter   387/ 1097] train: loss: 0.0423763
[Epoch 10; Iter   417/ 1097] train: loss: 0.1808870
[Epoch 10; Iter   447/ 1097] train: loss: 0.2019520
[Epoch 10; Iter   477/ 1097] train: loss: 0.0388733
[Epoch 10; Iter   507/ 1097] train: loss: 0.0303420
[Epoch 10; Iter   537/ 1097] train: loss: 0.2437311
[Epoch 10; Iter   567/ 1097] train: loss: 0.4000198
[Epoch 10; Iter   597/ 1097] train: loss: 0.2427234
[Epoch 10; Iter   627/ 1097] train: loss: 0.0596942
[Epoch 10; Iter   657/ 1097] train: loss: 0.0462212
[Epoch 10; Iter   687/ 1097] train: loss: 0.1339200
[Epoch 10; Iter   717/ 1097] train: loss: 0.2033521
[Epoch 10; Iter   747/ 1097] train: loss: 0.2716007
[Epoch 10; Iter   777/ 1097] train: loss: 0.1612414
[Epoch 10; Iter   807/ 1097] train: loss: 0.0296360
[Epoch 10; Iter   837/ 1097] train: loss: 0.1507604
[Epoch 10; Iter   867/ 1097] train: loss: 0.1705593
[Epoch 10; Iter   897/ 1097] train: loss: 0.0863351
[Epoch 10; Iter   927/ 1097] train: loss: 0.0396453
[Epoch 10; Iter   957/ 1097] train: loss: 0.0664002
[Epoch 10; Iter   987/ 1097] train: loss: 0.0588139
[Epoch 10; Iter  1017/ 1097] train: loss: 0.1207488
[Epoch 10; Iter  1047/ 1097] train: loss: 0.0325513
[Epoch 10; Iter  1077/ 1097] train: loss: 0.0438646
[Epoch 10] ogbg-molhiv: 0.743124 val loss: 12.159240
[Epoch 10] ogbg-molhiv: 0.718915 test loss: 8.631881
[Epoch 11; Iter    10/ 1097] train: loss: 0.0374292
[Epoch 11; Iter    40/ 1097] train: loss: 0.0424727
[Epoch 11; Iter    70/ 1097] train: loss: 0.1326275
[Epoch 11; Iter   100/ 1097] train: loss: 0.1597312
[Epoch 11; Iter   130/ 1097] train: loss: 0.0457301
[Epoch 11; Iter   160/ 1097] train: loss: 0.0629392
[Epoch 11; Iter   190/ 1097] train: loss: 0.1176074
[Epoch 11; Iter   220/ 1097] train: loss: 0.2921843
[Epoch 11; Iter   250/ 1097] train: loss: 0.2187755
[Epoch 11; Iter   280/ 1097] train: loss: 0.2753111
[Epoch 11; Iter   310/ 1097] train: loss: 0.1731878
[Epoch 11; Iter   340/ 1097] train: loss: 0.2268361
[Epoch 11; Iter   370/ 1097] train: loss: 0.0735428
[Epoch 11; Iter   400/ 1097] train: loss: 0.1639447
[Epoch 11; Iter   430/ 1097] train: loss: 0.2572975
[Epoch 11; Iter   460/ 1097] train: loss: 0.0267662
[Epoch 11; Iter   490/ 1097] train: loss: 0.2618290
[Epoch 11; Iter   520/ 1097] train: loss: 0.0282960
[Epoch 11; Iter   550/ 1097] train: loss: 0.1742907
[Epoch 11; Iter   580/ 1097] train: loss: 0.0513852
[Epoch 11; Iter   610/ 1097] train: loss: 0.0250694
[Epoch 11; Iter   640/ 1097] train: loss: 0.1431528
[Epoch 11; Iter   670/ 1097] train: loss: 0.1139858
[Epoch 11; Iter   700/ 1097] train: loss: 0.0669483
[Epoch 11; Iter   730/ 1097] train: loss: 0.1592225
[Epoch 11; Iter   760/ 1097] train: loss: 0.0339970
[Epoch 11; Iter   790/ 1097] train: loss: 0.1977001
[Epoch 11; Iter   820/ 1097] train: loss: 0.0441409
[Epoch 11; Iter   850/ 1097] train: loss: 0.1729669
[Epoch 11; Iter   880/ 1097] train: loss: 0.3026944
[Epoch 11; Iter   910/ 1097] train: loss: 0.0384385
[Epoch 11; Iter   940/ 1097] train: loss: 0.2828401
[Epoch 11; Iter   970/ 1097] train: loss: 0.1790210
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0970023
[Epoch 11; Iter  1030/ 1097] train: loss: 0.0277599
[Epoch 11; Iter  1060/ 1097] train: loss: 0.2073539
[Epoch 11; Iter  1090/ 1097] train: loss: 0.0430455
[Epoch 11] ogbg-molhiv: 0.764823 val loss: 0.276623
[Epoch 11] ogbg-molhiv: 0.734526 test loss: 10.906107
[Epoch 12; Iter    23/ 1097] train: loss: 0.0631469
[Epoch 12; Iter    53/ 1097] train: loss: 0.0314044
[Epoch 12; Iter    83/ 1097] train: loss: 0.1124784
[Epoch 12; Iter   113/ 1097] train: loss: 0.1116884
[Epoch 8; Iter    31/ 1097] train: loss: 0.0837538
[Epoch 8; Iter    61/ 1097] train: loss: 0.2645692
[Epoch 8; Iter    91/ 1097] train: loss: 0.0868220
[Epoch 8; Iter   121/ 1097] train: loss: 0.0826923
[Epoch 8; Iter   151/ 1097] train: loss: 0.0218095
[Epoch 8; Iter   181/ 1097] train: loss: 0.2283473
[Epoch 8; Iter   211/ 1097] train: loss: 0.0425851
[Epoch 8; Iter   241/ 1097] train: loss: 0.2070582
[Epoch 8; Iter   271/ 1097] train: loss: 0.1798224
[Epoch 8; Iter   301/ 1097] train: loss: 0.0790351
[Epoch 8; Iter   331/ 1097] train: loss: 0.1562428
[Epoch 8; Iter   361/ 1097] train: loss: 0.1452921
[Epoch 8; Iter   391/ 1097] train: loss: 0.0416953
[Epoch 8; Iter   421/ 1097] train: loss: 0.0437135
[Epoch 8; Iter   451/ 1097] train: loss: 0.2218540
[Epoch 8; Iter   481/ 1097] train: loss: 0.0434407
[Epoch 8; Iter   511/ 1097] train: loss: 0.0384463
[Epoch 8; Iter   541/ 1097] train: loss: 0.0432152
[Epoch 8; Iter   571/ 1097] train: loss: 0.0249050
[Epoch 8; Iter   601/ 1097] train: loss: 0.0464564
[Epoch 8; Iter   631/ 1097] train: loss: 0.2848221
[Epoch 8; Iter   661/ 1097] train: loss: 0.0363954
[Epoch 8; Iter   691/ 1097] train: loss: 0.0252869
[Epoch 8; Iter   721/ 1097] train: loss: 0.0505178
[Epoch 8; Iter   751/ 1097] train: loss: 0.0276835
[Epoch 8; Iter   781/ 1097] train: loss: 0.0282028
[Epoch 8; Iter   811/ 1097] train: loss: 0.0336471
[Epoch 8; Iter   841/ 1097] train: loss: 0.1113495
[Epoch 8; Iter   871/ 1097] train: loss: 0.0922977
[Epoch 8; Iter   901/ 1097] train: loss: 0.1591002
[Epoch 8; Iter   931/ 1097] train: loss: 0.1423572
[Epoch 8; Iter   961/ 1097] train: loss: 0.1415186
[Epoch 8; Iter   991/ 1097] train: loss: 0.1852477
[Epoch 8; Iter  1021/ 1097] train: loss: 0.0293856
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0302312
[Epoch 8; Iter  1081/ 1097] train: loss: 0.1837332
[Epoch 8] ogbg-molhiv: 0.780515 val loss: 0.144830
[Epoch 8] ogbg-molhiv: 0.769960 test loss: 0.242511
[Epoch 9; Iter    14/ 1097] train: loss: 0.0199849
[Epoch 9; Iter    44/ 1097] train: loss: 0.0251277
[Epoch 9; Iter    74/ 1097] train: loss: 0.1604632
[Epoch 9; Iter   104/ 1097] train: loss: 0.0543478
[Epoch 9; Iter   134/ 1097] train: loss: 0.1708831
[Epoch 9; Iter   164/ 1097] train: loss: 0.0279938
[Epoch 9; Iter   194/ 1097] train: loss: 0.0981260
[Epoch 9; Iter   224/ 1097] train: loss: 0.1328673
[Epoch 9; Iter   254/ 1097] train: loss: 0.2635899
[Epoch 9; Iter   284/ 1097] train: loss: 0.0345069
[Epoch 9; Iter   314/ 1097] train: loss: 0.0718606
[Epoch 9; Iter   344/ 1097] train: loss: 0.2121856
[Epoch 9; Iter   374/ 1097] train: loss: 0.3169091
[Epoch 9; Iter   404/ 1097] train: loss: 0.1172028
[Epoch 9; Iter   434/ 1097] train: loss: 0.1080007
[Epoch 9; Iter   464/ 1097] train: loss: 0.3953389
[Epoch 9; Iter   494/ 1097] train: loss: 0.2672064
[Epoch 9; Iter   524/ 1097] train: loss: 0.0772489
[Epoch 9; Iter   554/ 1097] train: loss: 0.0872370
[Epoch 9; Iter   584/ 1097] train: loss: 0.0233285
[Epoch 9; Iter   614/ 1097] train: loss: 0.0370310
[Epoch 9; Iter   644/ 1097] train: loss: 0.2997254
[Epoch 9; Iter   674/ 1097] train: loss: 0.0274738
[Epoch 9; Iter   704/ 1097] train: loss: 0.0237635
[Epoch 9; Iter   734/ 1097] train: loss: 0.1910309
[Epoch 9; Iter   764/ 1097] train: loss: 0.0317631
[Epoch 9; Iter   794/ 1097] train: loss: 0.0299803
[Epoch 9; Iter   824/ 1097] train: loss: 0.0890638
[Epoch 9; Iter   854/ 1097] train: loss: 0.2137996
[Epoch 9; Iter   884/ 1097] train: loss: 0.0388456
[Epoch 9; Iter   914/ 1097] train: loss: 0.0190224
[Epoch 9; Iter   944/ 1097] train: loss: 0.0420589
[Epoch 9; Iter   974/ 1097] train: loss: 0.0449534
[Epoch 9; Iter  1004/ 1097] train: loss: 0.1370381
[Epoch 9; Iter  1034/ 1097] train: loss: 0.1752156
[Epoch 9; Iter  1064/ 1097] train: loss: 0.0935256
[Epoch 9; Iter  1094/ 1097] train: loss: 0.2676571
[Epoch 9] ogbg-molhiv: 0.795487 val loss: 0.152690
[Epoch 9] ogbg-molhiv: 0.804670 test loss: 0.232697
[Epoch 10; Iter    27/ 1097] train: loss: 0.1739077
[Epoch 10; Iter    57/ 1097] train: loss: 0.1670627
[Epoch 10; Iter    87/ 1097] train: loss: 0.0263805
[Epoch 10; Iter   117/ 1097] train: loss: 0.1169926
[Epoch 10; Iter   147/ 1097] train: loss: 0.0221373
[Epoch 10; Iter   177/ 1097] train: loss: 0.0782921
[Epoch 10; Iter   207/ 1097] train: loss: 0.0488039
[Epoch 10; Iter   237/ 1097] train: loss: 0.1225044
[Epoch 10; Iter   267/ 1097] train: loss: 0.1664847
[Epoch 10; Iter   297/ 1097] train: loss: 0.0285770
[Epoch 10; Iter   327/ 1097] train: loss: 0.0487716
[Epoch 10; Iter   357/ 1097] train: loss: 0.0394235
[Epoch 10; Iter   387/ 1097] train: loss: 0.0511053
[Epoch 10; Iter   417/ 1097] train: loss: 0.1738212
[Epoch 10; Iter   447/ 1097] train: loss: 0.2753516
[Epoch 10; Iter   477/ 1097] train: loss: 0.0490472
[Epoch 10; Iter   507/ 1097] train: loss: 0.0285948
[Epoch 10; Iter   537/ 1097] train: loss: 0.0322152
[Epoch 10; Iter   567/ 1097] train: loss: 0.0201039
[Epoch 10; Iter   597/ 1097] train: loss: 0.0196358
[Epoch 10; Iter   627/ 1097] train: loss: 0.0507266
[Epoch 10; Iter   657/ 1097] train: loss: 0.0309057
[Epoch 10; Iter   687/ 1097] train: loss: 0.2305681
[Epoch 10; Iter   717/ 1097] train: loss: 0.0351071
[Epoch 10; Iter   747/ 1097] train: loss: 0.0380460
[Epoch 10; Iter   777/ 1097] train: loss: 0.0414118
[Epoch 10; Iter   807/ 1097] train: loss: 0.0318103
[Epoch 10; Iter   837/ 1097] train: loss: 0.0984674
[Epoch 10; Iter   867/ 1097] train: loss: 0.1076955
[Epoch 10; Iter   897/ 1097] train: loss: 0.2607701
[Epoch 10; Iter   927/ 1097] train: loss: 0.0293677
[Epoch 10; Iter   957/ 1097] train: loss: 0.0275432
[Epoch 10; Iter   987/ 1097] train: loss: 0.0350155
[Epoch 10; Iter  1017/ 1097] train: loss: 0.2313279
[Epoch 10; Iter  1047/ 1097] train: loss: 0.1253282
[Epoch 10; Iter  1077/ 1097] train: loss: 0.0243038
[Epoch 10] ogbg-molhiv: 0.774535 val loss: 0.169780
[Epoch 10] ogbg-molhiv: 0.771703 test loss: 0.156362
[Epoch 11; Iter    10/ 1097] train: loss: 0.0229695
[Epoch 11; Iter    40/ 1097] train: loss: 0.0420949
[Epoch 11; Iter    70/ 1097] train: loss: 0.0211796
[Epoch 11; Iter   100/ 1097] train: loss: 0.0270738
[Epoch 11; Iter   130/ 1097] train: loss: 0.0172623
[Epoch 11; Iter   160/ 1097] train: loss: 0.0989059
[Epoch 11; Iter   190/ 1097] train: loss: 0.1234494
[Epoch 11; Iter   220/ 1097] train: loss: 0.0212355
[Epoch 11; Iter   250/ 1097] train: loss: 0.0286955
[Epoch 11; Iter   280/ 1097] train: loss: 0.0770793
[Epoch 11; Iter   310/ 1097] train: loss: 0.0256163
[Epoch 11; Iter   340/ 1097] train: loss: 0.1332754
[Epoch 11; Iter   370/ 1097] train: loss: 0.1827385
[Epoch 11; Iter   400/ 1097] train: loss: 0.0471437
[Epoch 11; Iter   430/ 1097] train: loss: 0.1715040
[Epoch 11; Iter   460/ 1097] train: loss: 0.0477694
[Epoch 11; Iter   490/ 1097] train: loss: 0.2169035
[Epoch 11; Iter   520/ 1097] train: loss: 0.2969579
[Epoch 11; Iter   550/ 1097] train: loss: 0.0953044
[Epoch 11; Iter   580/ 1097] train: loss: 0.0264035
[Epoch 11; Iter   610/ 1097] train: loss: 0.0372734
[Epoch 11; Iter   640/ 1097] train: loss: 0.0421780
[Epoch 11; Iter   670/ 1097] train: loss: 0.0244041
[Epoch 11; Iter   700/ 1097] train: loss: 0.0225174
[Epoch 11; Iter   730/ 1097] train: loss: 0.0679810
[Epoch 11; Iter   760/ 1097] train: loss: 0.2804177
[Epoch 11; Iter   790/ 1097] train: loss: 0.1591576
[Epoch 11; Iter   820/ 1097] train: loss: 0.0555384
[Epoch 11; Iter   850/ 1097] train: loss: 0.0242381
[Epoch 11; Iter   880/ 1097] train: loss: 0.1531605
[Epoch 11; Iter   910/ 1097] train: loss: 0.0600198
[Epoch 11; Iter   940/ 1097] train: loss: 0.0287340
[Epoch 11; Iter   970/ 1097] train: loss: 0.0273712
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0308172
[Epoch 11; Iter  1030/ 1097] train: loss: 0.3283008
[Epoch 11; Iter  1060/ 1097] train: loss: 0.0730896
[Epoch 11; Iter  1090/ 1097] train: loss: 0.0269716
[Epoch 11] ogbg-molhiv: 0.780780 val loss: 0.171716
[Epoch 11] ogbg-molhiv: 0.778397 test loss: 0.428310
[Epoch 12; Iter    23/ 1097] train: loss: 0.2236727
[Epoch 12; Iter    53/ 1097] train: loss: 0.0674845
[Epoch 12; Iter    83/ 1097] train: loss: 0.1493661
[Epoch 12; Iter   113/ 1097] train: loss: 0.0600036
[Epoch 8; Iter    31/ 1097] train: loss: 0.0762548
[Epoch 8; Iter    61/ 1097] train: loss: 0.0310324
[Epoch 8; Iter    91/ 1097] train: loss: 0.0279994
[Epoch 8; Iter   121/ 1097] train: loss: 0.0224295
[Epoch 8; Iter   151/ 1097] train: loss: 0.1402670
[Epoch 8; Iter   181/ 1097] train: loss: 0.0242118
[Epoch 8; Iter   211/ 1097] train: loss: 0.0241511
[Epoch 8; Iter   241/ 1097] train: loss: 0.1207524
[Epoch 8; Iter   271/ 1097] train: loss: 0.0581082
[Epoch 8; Iter   301/ 1097] train: loss: 0.0976331
[Epoch 8; Iter   331/ 1097] train: loss: 0.0330062
[Epoch 8; Iter   361/ 1097] train: loss: 0.3915999
[Epoch 8; Iter   391/ 1097] train: loss: 0.0778527
[Epoch 8; Iter   421/ 1097] train: loss: 0.1492818
[Epoch 8; Iter   451/ 1097] train: loss: 0.0293473
[Epoch 8; Iter   481/ 1097] train: loss: 0.1717898
[Epoch 8; Iter   511/ 1097] train: loss: 0.0787114
[Epoch 8; Iter   541/ 1097] train: loss: 0.0902449
[Epoch 8; Iter   571/ 1097] train: loss: 0.0297386
[Epoch 8; Iter   601/ 1097] train: loss: 0.2379826
[Epoch 8; Iter   631/ 1097] train: loss: 0.0292863
[Epoch 8; Iter   661/ 1097] train: loss: 0.0738320
[Epoch 8; Iter   691/ 1097] train: loss: 0.0335544
[Epoch 8; Iter   721/ 1097] train: loss: 0.1991706
[Epoch 8; Iter   751/ 1097] train: loss: 0.1274026
[Epoch 8; Iter   781/ 1097] train: loss: 0.0717251
[Epoch 8; Iter   811/ 1097] train: loss: 0.0374372
[Epoch 8; Iter   841/ 1097] train: loss: 0.1668163
[Epoch 8; Iter   871/ 1097] train: loss: 0.0356212
[Epoch 8; Iter   901/ 1097] train: loss: 0.0724613
[Epoch 8; Iter   931/ 1097] train: loss: 0.0299249
[Epoch 8; Iter   961/ 1097] train: loss: 0.1930449
[Epoch 8; Iter   991/ 1097] train: loss: 0.0258993
[Epoch 8; Iter  1021/ 1097] train: loss: 0.1249504
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0310604
[Epoch 8; Iter  1081/ 1097] train: loss: 0.0245323
[Epoch 8] ogbg-molhiv: 0.780940 val loss: 0.127158
[Epoch 8] ogbg-molhiv: 0.787434 test loss: 0.124426
[Epoch 9; Iter    14/ 1097] train: loss: 0.0305897
[Epoch 9; Iter    44/ 1097] train: loss: 0.1420798
[Epoch 9; Iter    74/ 1097] train: loss: 0.0725772
[Epoch 9; Iter   104/ 1097] train: loss: 0.0330486
[Epoch 9; Iter   134/ 1097] train: loss: 0.0448806
[Epoch 9; Iter   164/ 1097] train: loss: 0.1751618
[Epoch 9; Iter   194/ 1097] train: loss: 0.0345257
[Epoch 9; Iter   224/ 1097] train: loss: 0.0335989
[Epoch 9; Iter   254/ 1097] train: loss: 0.1806735
[Epoch 9; Iter   284/ 1097] train: loss: 0.0232021
[Epoch 9; Iter   314/ 1097] train: loss: 0.1431828
[Epoch 9; Iter   344/ 1097] train: loss: 0.1225754
[Epoch 9; Iter   374/ 1097] train: loss: 0.1413930
[Epoch 9; Iter   404/ 1097] train: loss: 0.0305388
[Epoch 9; Iter   434/ 1097] train: loss: 0.3230054
[Epoch 9; Iter   464/ 1097] train: loss: 0.0378579
[Epoch 9; Iter   494/ 1097] train: loss: 0.1695280
[Epoch 9; Iter   524/ 1097] train: loss: 0.0284036
[Epoch 9; Iter   554/ 1097] train: loss: 0.0309724
[Epoch 9; Iter   584/ 1097] train: loss: 0.0879274
[Epoch 9; Iter   614/ 1097] train: loss: 0.1858880
[Epoch 9; Iter   644/ 1097] train: loss: 0.1094737
[Epoch 9; Iter   674/ 1097] train: loss: 0.0364194
[Epoch 9; Iter   704/ 1097] train: loss: 0.3376992
[Epoch 9; Iter   734/ 1097] train: loss: 0.2250055
[Epoch 9; Iter   764/ 1097] train: loss: 0.0722984
[Epoch 9; Iter   794/ 1097] train: loss: 0.0384312
[Epoch 9; Iter   824/ 1097] train: loss: 0.0268125
[Epoch 9; Iter   854/ 1097] train: loss: 0.0875776
[Epoch 9; Iter   884/ 1097] train: loss: 0.1036619
[Epoch 9; Iter   914/ 1097] train: loss: 0.2691363
[Epoch 9; Iter   944/ 1097] train: loss: 0.1195572
[Epoch 9; Iter   974/ 1097] train: loss: 0.0347471
[Epoch 9; Iter  1004/ 1097] train: loss: 0.0341362
[Epoch 9; Iter  1034/ 1097] train: loss: 0.0634594
[Epoch 9; Iter  1064/ 1097] train: loss: 0.0879180
[Epoch 9; Iter  1094/ 1097] train: loss: 0.0296949
[Epoch 9] ogbg-molhiv: 0.757218 val loss: 0.127532
[Epoch 9] ogbg-molhiv: 0.774593 test loss: 0.125550
[Epoch 10; Iter    27/ 1097] train: loss: 0.3319490
[Epoch 10; Iter    57/ 1097] train: loss: 0.1510960
[Epoch 10; Iter    87/ 1097] train: loss: 0.1589924
[Epoch 10; Iter   117/ 1097] train: loss: 0.0451821
[Epoch 10; Iter   147/ 1097] train: loss: 0.1860100
[Epoch 10; Iter   177/ 1097] train: loss: 0.0594554
[Epoch 10; Iter   207/ 1097] train: loss: 0.0364600
[Epoch 10; Iter   237/ 1097] train: loss: 0.1823126
[Epoch 10; Iter   267/ 1097] train: loss: 0.1163639
[Epoch 10; Iter   297/ 1097] train: loss: 0.2035533
[Epoch 10; Iter   327/ 1097] train: loss: 0.0300390
[Epoch 10; Iter   357/ 1097] train: loss: 0.0215978
[Epoch 10; Iter   387/ 1097] train: loss: 0.2540613
[Epoch 10; Iter   417/ 1097] train: loss: 0.0916406
[Epoch 10; Iter   447/ 1097] train: loss: 0.1010063
[Epoch 10; Iter   477/ 1097] train: loss: 0.1826060
[Epoch 10; Iter   507/ 1097] train: loss: 0.0546149
[Epoch 10; Iter   537/ 1097] train: loss: 0.1680765
[Epoch 10; Iter   567/ 1097] train: loss: 0.1161232
[Epoch 10; Iter   597/ 1097] train: loss: 0.2127421
[Epoch 10; Iter   627/ 1097] train: loss: 0.0772564
[Epoch 10; Iter   657/ 1097] train: loss: 0.0280521
[Epoch 10; Iter   687/ 1097] train: loss: 0.0664078
[Epoch 10; Iter   717/ 1097] train: loss: 0.4403315
[Epoch 10; Iter   747/ 1097] train: loss: 0.0346718
[Epoch 10; Iter   777/ 1097] train: loss: 0.0520016
[Epoch 10; Iter   807/ 1097] train: loss: 0.0493978
[Epoch 10; Iter   837/ 1097] train: loss: 0.0270177
[Epoch 10; Iter   867/ 1097] train: loss: 0.0226472
[Epoch 10; Iter   897/ 1097] train: loss: 0.1844882
[Epoch 10; Iter   927/ 1097] train: loss: 0.0365697
[Epoch 10; Iter   957/ 1097] train: loss: 0.0214154
[Epoch 10; Iter   987/ 1097] train: loss: 0.0457875
[Epoch 10; Iter  1017/ 1097] train: loss: 0.2597693
[Epoch 10; Iter  1047/ 1097] train: loss: 0.0895771
[Epoch 10; Iter  1077/ 1097] train: loss: 0.0988254
[Epoch 10] ogbg-molhiv: 0.767595 val loss: 0.124589
[Epoch 10] ogbg-molhiv: 0.777072 test loss: 0.119686
[Epoch 11; Iter    10/ 1097] train: loss: 0.1326390
[Epoch 11; Iter    40/ 1097] train: loss: 0.0378199
[Epoch 11; Iter    70/ 1097] train: loss: 0.0292384
[Epoch 11; Iter   100/ 1097] train: loss: 0.0985208
[Epoch 11; Iter   130/ 1097] train: loss: 0.1643389
[Epoch 11; Iter   160/ 1097] train: loss: 0.0174548
[Epoch 11; Iter   190/ 1097] train: loss: 0.0212400
[Epoch 11; Iter   220/ 1097] train: loss: 0.0410473
[Epoch 11; Iter   250/ 1097] train: loss: 0.0466405
[Epoch 11; Iter   280/ 1097] train: loss: 0.2031380
[Epoch 11; Iter   310/ 1097] train: loss: 0.0483463
[Epoch 11; Iter   340/ 1097] train: loss: 0.2572173
[Epoch 11; Iter   370/ 1097] train: loss: 0.1346654
[Epoch 11; Iter   400/ 1097] train: loss: 0.1599164
[Epoch 11; Iter   430/ 1097] train: loss: 0.0296373
[Epoch 11; Iter   460/ 1097] train: loss: 0.0859910
[Epoch 11; Iter   490/ 1097] train: loss: 0.2119493
[Epoch 11; Iter   520/ 1097] train: loss: 0.0260308
[Epoch 11; Iter   550/ 1097] train: loss: 0.0815306
[Epoch 11; Iter   580/ 1097] train: loss: 0.0307215
[Epoch 11; Iter   610/ 1097] train: loss: 0.1589064
[Epoch 11; Iter   640/ 1097] train: loss: 0.0211602
[Epoch 11; Iter   670/ 1097] train: loss: 0.1524514
[Epoch 11; Iter   700/ 1097] train: loss: 0.0224134
[Epoch 11; Iter   730/ 1097] train: loss: 0.0398417
[Epoch 11; Iter   760/ 1097] train: loss: 0.0634030
[Epoch 11; Iter   790/ 1097] train: loss: 0.0332164
[Epoch 11; Iter   820/ 1097] train: loss: 0.0334549
[Epoch 11; Iter   850/ 1097] train: loss: 0.1370674
[Epoch 11; Iter   880/ 1097] train: loss: 0.1217349
[Epoch 11; Iter   910/ 1097] train: loss: 0.2004284
[Epoch 11; Iter   940/ 1097] train: loss: 0.0283560
[Epoch 11; Iter   970/ 1097] train: loss: 0.0685313
[Epoch 11; Iter  1000/ 1097] train: loss: 0.1454601
[Epoch 11; Iter  1030/ 1097] train: loss: 0.0248394
[Epoch 11; Iter  1060/ 1097] train: loss: 0.0460424
[Epoch 11; Iter  1090/ 1097] train: loss: 0.0565644
[Epoch 11] ogbg-molhiv: 0.771137 val loss: 0.221686
[Epoch 11] ogbg-molhiv: 0.775961 test loss: 0.128223
[Epoch 12; Iter    23/ 1097] train: loss: 0.0980749
[Epoch 12; Iter    53/ 1097] train: loss: 0.1369395
[Epoch 12; Iter    83/ 1097] train: loss: 0.1315986
[Epoch 12; Iter   113/ 1097] train: loss: 0.0317164
[Epoch 8] ogbg-molhiv: 0.767038 val loss: 0.140924
[Epoch 8] ogbg-molhiv: 0.735772 test loss: 0.135294
[Epoch 9; Iter    30/  960] train: loss: 0.0344030
[Epoch 9; Iter    60/  960] train: loss: 0.0278985
[Epoch 9; Iter    90/  960] train: loss: 0.2253844
[Epoch 9; Iter   120/  960] train: loss: 0.2083069
[Epoch 9; Iter   150/  960] train: loss: 0.3971561
[Epoch 9; Iter   180/  960] train: loss: 0.1889802
[Epoch 9; Iter   210/  960] train: loss: 0.1430953
[Epoch 9; Iter   240/  960] train: loss: 0.1146228
[Epoch 9; Iter   270/  960] train: loss: 0.0263367
[Epoch 9; Iter   300/  960] train: loss: 0.1298260
[Epoch 9; Iter   330/  960] train: loss: 0.1867590
[Epoch 9; Iter   360/  960] train: loss: 0.0263154
[Epoch 9; Iter   390/  960] train: loss: 0.0248117
[Epoch 9; Iter   420/  960] train: loss: 0.2777964
[Epoch 9; Iter   450/  960] train: loss: 0.0727572
[Epoch 9; Iter   480/  960] train: loss: 0.2989557
[Epoch 9; Iter   510/  960] train: loss: 0.1520301
[Epoch 9; Iter   540/  960] train: loss: 0.1536855
[Epoch 9; Iter   570/  960] train: loss: 0.0402137
[Epoch 9; Iter   600/  960] train: loss: 0.2323766
[Epoch 9; Iter   630/  960] train: loss: 0.0382231
[Epoch 9; Iter   660/  960] train: loss: 0.0502430
[Epoch 9; Iter   690/  960] train: loss: 0.0245765
[Epoch 9; Iter   720/  960] train: loss: 0.1465181
[Epoch 9; Iter   750/  960] train: loss: 0.0340009
[Epoch 9; Iter   780/  960] train: loss: 0.1533152
[Epoch 9; Iter   810/  960] train: loss: 0.0355808
[Epoch 9; Iter   840/  960] train: loss: 0.1599946
[Epoch 9; Iter   870/  960] train: loss: 0.1355710
[Epoch 9; Iter   900/  960] train: loss: 0.0274449
[Epoch 9; Iter   930/  960] train: loss: 0.0442402
[Epoch 9; Iter   960/  960] train: loss: 0.2513498
[Epoch 9] ogbg-molhiv: 0.760194 val loss: 0.149272
[Epoch 9] ogbg-molhiv: 0.764228 test loss: 0.144697
[Epoch 10; Iter    30/  960] train: loss: 0.0322857
[Epoch 10; Iter    60/  960] train: loss: 0.0350451
[Epoch 10; Iter    90/  960] train: loss: 0.3618721
[Epoch 10; Iter   120/  960] train: loss: 0.0209345
[Epoch 10; Iter   150/  960] train: loss: 0.1750917
[Epoch 10; Iter   180/  960] train: loss: 0.2205684
[Epoch 10; Iter   210/  960] train: loss: 0.0857964
[Epoch 10; Iter   240/  960] train: loss: 0.0399765
[Epoch 10; Iter   270/  960] train: loss: 0.1890598
[Epoch 10; Iter   300/  960] train: loss: 0.0200032
[Epoch 10; Iter   330/  960] train: loss: 0.0637250
[Epoch 10; Iter   360/  960] train: loss: 0.1587534
[Epoch 10; Iter   390/  960] train: loss: 0.0280317
[Epoch 10; Iter   420/  960] train: loss: 0.0256043
[Epoch 10; Iter   450/  960] train: loss: 0.1252353
[Epoch 10; Iter   480/  960] train: loss: 0.1938675
[Epoch 10; Iter   510/  960] train: loss: 0.0371281
[Epoch 10; Iter   540/  960] train: loss: 0.0608345
[Epoch 10; Iter   570/  960] train: loss: 0.1690764
[Epoch 10; Iter   600/  960] train: loss: 0.0353628
[Epoch 10; Iter   630/  960] train: loss: 0.0572900
[Epoch 10; Iter   660/  960] train: loss: 0.1586234
[Epoch 10; Iter   690/  960] train: loss: 0.3184861
[Epoch 10; Iter   720/  960] train: loss: 0.1186555
[Epoch 10; Iter   750/  960] train: loss: 0.1576456
[Epoch 10; Iter   780/  960] train: loss: 0.1597361
[Epoch 10; Iter   810/  960] train: loss: 0.0297093
[Epoch 10; Iter   840/  960] train: loss: 0.0296937
[Epoch 10; Iter   870/  960] train: loss: 0.1042707
[Epoch 10; Iter   900/  960] train: loss: 0.1614729
[Epoch 10; Iter   930/  960] train: loss: 0.0376644
[Epoch 10; Iter   960/  960] train: loss: 0.1955538
[Epoch 10] ogbg-molhiv: 0.769598 val loss: 0.203241
[Epoch 10] ogbg-molhiv: 0.754156 test loss: 0.252603
[Epoch 11; Iter    30/  960] train: loss: 0.1418271
[Epoch 11; Iter    60/  960] train: loss: 0.0451100
[Epoch 11; Iter    90/  960] train: loss: 0.1497300
[Epoch 11; Iter   120/  960] train: loss: 0.2414943
[Epoch 11; Iter   150/  960] train: loss: 0.2622627
[Epoch 11; Iter   180/  960] train: loss: 0.2156841
[Epoch 11; Iter   210/  960] train: loss: 0.0317060
[Epoch 11; Iter   240/  960] train: loss: 0.0289610
[Epoch 11; Iter   270/  960] train: loss: 0.2064369
[Epoch 11; Iter   300/  960] train: loss: 0.3155626
[Epoch 11; Iter   330/  960] train: loss: 0.0303701
[Epoch 11; Iter   360/  960] train: loss: 0.1573963
[Epoch 11; Iter   390/  960] train: loss: 0.1008247
[Epoch 11; Iter   420/  960] train: loss: 0.2139567
[Epoch 11; Iter   450/  960] train: loss: 0.1842218
[Epoch 11; Iter   480/  960] train: loss: 0.0277837
[Epoch 11; Iter   510/  960] train: loss: 0.0230176
[Epoch 11; Iter   540/  960] train: loss: 0.0262364
[Epoch 11; Iter   570/  960] train: loss: 0.0419433
[Epoch 11; Iter   600/  960] train: loss: 0.0218038
[Epoch 11; Iter   630/  960] train: loss: 0.3497232
[Epoch 11; Iter   660/  960] train: loss: 0.1463340
[Epoch 11; Iter   690/  960] train: loss: 0.1350931
[Epoch 11; Iter   720/  960] train: loss: 0.0853412
[Epoch 11; Iter   750/  960] train: loss: 0.1794140
[Epoch 11; Iter   780/  960] train: loss: 0.3195173
[Epoch 11; Iter   810/  960] train: loss: 0.2929279
[Epoch 11; Iter   840/  960] train: loss: 0.0276844
[Epoch 11; Iter   870/  960] train: loss: 0.0260312
[Epoch 11; Iter   900/  960] train: loss: 0.1044865
[Epoch 11; Iter   930/  960] train: loss: 0.2994423
[Epoch 11; Iter   960/  960] train: loss: 0.2968315
[Epoch 11] ogbg-molhiv: 0.778334 val loss: 0.134485
[Epoch 11] ogbg-molhiv: 0.762667 test loss: 0.126836
[Epoch 12; Iter    30/  960] train: loss: 0.1061727
[Epoch 12; Iter    60/  960] train: loss: 0.1513633
[Epoch 12; Iter    90/  960] train: loss: 0.0263037
[Epoch 12; Iter   120/  960] train: loss: 0.2460248
[Epoch 12; Iter   150/  960] train: loss: 0.1890295
[Epoch 12; Iter   180/  960] train: loss: 0.0848709
[Epoch 12; Iter   210/  960] train: loss: 0.2572672
[Epoch 12; Iter   240/  960] train: loss: 0.1515432
[Epoch 12; Iter   270/  960] train: loss: 0.1297649
[Epoch 12; Iter   300/  960] train: loss: 0.1842069
[Epoch 12; Iter   330/  960] train: loss: 0.0357032
[Epoch 12; Iter   360/  960] train: loss: 0.1256206
[Epoch 12; Iter   390/  960] train: loss: 0.0307170
[Epoch 12; Iter   420/  960] train: loss: 0.0250785
[Epoch 12; Iter   450/  960] train: loss: 0.1138483
[Epoch 12; Iter   480/  960] train: loss: 0.0313167
[Epoch 12; Iter   510/  960] train: loss: 0.0513993
[Epoch 12; Iter   540/  960] train: loss: 0.0235739
[Epoch 12; Iter   570/  960] train: loss: 0.0282463
[Epoch 12; Iter   600/  960] train: loss: 0.0219964
[Epoch 12; Iter   630/  960] train: loss: 0.0592472
[Epoch 12; Iter   660/  960] train: loss: 0.0249082
[Epoch 12; Iter   690/  960] train: loss: 0.0221344
[Epoch 12; Iter   720/  960] train: loss: 0.1636248
[Epoch 12; Iter   750/  960] train: loss: 0.2884351
[Epoch 12; Iter   780/  960] train: loss: 0.3941130
[Epoch 12; Iter   810/  960] train: loss: 0.0661518
[Epoch 12; Iter   840/  960] train: loss: 0.2908876
[Epoch 12; Iter   870/  960] train: loss: 0.3756893
[Epoch 12; Iter   900/  960] train: loss: 0.1101813
[Epoch 12; Iter   930/  960] train: loss: 0.0308040
[Epoch 12; Iter   960/  960] train: loss: 0.0330887
[Epoch 12] ogbg-molhiv: 0.775799 val loss: 0.134087
[Epoch 12] ogbg-molhiv: 0.766594 test loss: 0.128362
[Epoch 13; Iter    30/  960] train: loss: 0.0400500
[Epoch 13; Iter    60/  960] train: loss: 0.2042319
[Epoch 13; Iter    90/  960] train: loss: 0.2097621
[Epoch 13; Iter   120/  960] train: loss: 0.3061669
[Epoch 13; Iter   150/  960] train: loss: 0.0325250
[Epoch 13; Iter   180/  960] train: loss: 0.2851441
[Epoch 13; Iter   210/  960] train: loss: 0.0333754
[Epoch 13; Iter   240/  960] train: loss: 0.0338162
[Epoch 13; Iter   270/  960] train: loss: 0.2495433
[Epoch 13; Iter   300/  960] train: loss: 0.1719885
[Epoch 13; Iter   330/  960] train: loss: 0.3996266
[Epoch 13; Iter   360/  960] train: loss: 0.0327724
[Epoch 13; Iter   390/  960] train: loss: 0.2592614
[Epoch 13; Iter   420/  960] train: loss: 0.0298879
[Epoch 13; Iter   450/  960] train: loss: 0.1148713
[Epoch 13; Iter   480/  960] train: loss: 0.0237642
[Epoch 13; Iter   510/  960] train: loss: 0.1331193
[Epoch 13; Iter   540/  960] train: loss: 0.1791229
[Epoch 13; Iter   570/  960] train: loss: 0.0286669
[Epoch 13; Iter   600/  960] train: loss: 0.1698145
[Epoch 8] ogbg-molhiv: 0.772615 val loss: 0.233979
[Epoch 8] ogbg-molhiv: 0.764784 test loss: 0.129598
[Epoch 9; Iter    30/  960] train: loss: 0.1177909
[Epoch 9; Iter    60/  960] train: loss: 0.1740687
[Epoch 9; Iter    90/  960] train: loss: 0.3039283
[Epoch 9; Iter   120/  960] train: loss: 0.1801362
[Epoch 9; Iter   150/  960] train: loss: 0.0312898
[Epoch 9; Iter   180/  960] train: loss: 0.0303871
[Epoch 9; Iter   210/  960] train: loss: 0.0297214
[Epoch 9; Iter   240/  960] train: loss: 0.3021257
[Epoch 9; Iter   270/  960] train: loss: 0.0361106
[Epoch 9; Iter   300/  960] train: loss: 0.3076622
[Epoch 9; Iter   330/  960] train: loss: 0.0227137
[Epoch 9; Iter   360/  960] train: loss: 0.0338031
[Epoch 9; Iter   390/  960] train: loss: 0.4795357
[Epoch 9; Iter   420/  960] train: loss: 0.1910460
[Epoch 9; Iter   450/  960] train: loss: 0.1803180
[Epoch 9; Iter   480/  960] train: loss: 0.0274741
[Epoch 9; Iter   510/  960] train: loss: 0.1265964
[Epoch 9; Iter   540/  960] train: loss: 0.0857831
[Epoch 9; Iter   570/  960] train: loss: 0.0643314
[Epoch 9; Iter   600/  960] train: loss: 0.2378139
[Epoch 9; Iter   630/  960] train: loss: 0.0319790
[Epoch 9; Iter   660/  960] train: loss: 0.0503792
[Epoch 9; Iter   690/  960] train: loss: 0.2189896
[Epoch 9; Iter   720/  960] train: loss: 0.1687343
[Epoch 9; Iter   750/  960] train: loss: 0.1879317
[Epoch 9; Iter   780/  960] train: loss: 0.5180000
[Epoch 9; Iter   810/  960] train: loss: 0.0532869
[Epoch 9; Iter   840/  960] train: loss: 0.1734428
[Epoch 9; Iter   870/  960] train: loss: 0.0285205
[Epoch 9; Iter   900/  960] train: loss: 0.2113518
[Epoch 9; Iter   930/  960] train: loss: 0.0890091
[Epoch 9; Iter   960/  960] train: loss: 0.0330959
[Epoch 9] ogbg-molhiv: 0.762697 val loss: 0.216550
[Epoch 9] ogbg-molhiv: 0.753838 test loss: 0.149572
[Epoch 10; Iter    30/  960] train: loss: 0.0382583
[Epoch 10; Iter    60/  960] train: loss: 0.1546900
[Epoch 10; Iter    90/  960] train: loss: 0.0256340
[Epoch 10; Iter   120/  960] train: loss: 0.1075040
[Epoch 10; Iter   150/  960] train: loss: 0.0284074
[Epoch 10; Iter   180/  960] train: loss: 0.1611459
[Epoch 10; Iter   210/  960] train: loss: 0.0227887
[Epoch 10; Iter   240/  960] train: loss: 0.0559230
[Epoch 10; Iter   270/  960] train: loss: 0.0951695
[Epoch 10; Iter   300/  960] train: loss: 0.0356083
[Epoch 10; Iter   330/  960] train: loss: 0.2118539
[Epoch 10; Iter   360/  960] train: loss: 0.1946319
[Epoch 10; Iter   390/  960] train: loss: 0.0311339
[Epoch 10; Iter   420/  960] train: loss: 0.1607042
[Epoch 10; Iter   450/  960] train: loss: 0.0339261
[Epoch 10; Iter   480/  960] train: loss: 0.1717290
[Epoch 10; Iter   510/  960] train: loss: 0.0793090
[Epoch 10; Iter   540/  960] train: loss: 0.0669014
[Epoch 10; Iter   570/  960] train: loss: 0.1012653
[Epoch 10; Iter   600/  960] train: loss: 0.1383360
[Epoch 10; Iter   630/  960] train: loss: 0.0331797
[Epoch 10; Iter   660/  960] train: loss: 0.1096954
[Epoch 10; Iter   690/  960] train: loss: 0.1573178
[Epoch 10; Iter   720/  960] train: loss: 0.0374188
[Epoch 10; Iter   750/  960] train: loss: 0.0218171
[Epoch 10; Iter   780/  960] train: loss: 0.0864723
[Epoch 10; Iter   810/  960] train: loss: 0.0312052
[Epoch 10; Iter   840/  960] train: loss: 0.1841944
[Epoch 10; Iter   870/  960] train: loss: 0.1329610
[Epoch 10; Iter   900/  960] train: loss: 0.2061586
[Epoch 10; Iter   930/  960] train: loss: 0.1382710
[Epoch 10; Iter   960/  960] train: loss: 0.0346831
[Epoch 10] ogbg-molhiv: 0.773501 val loss: 0.547482
[Epoch 10] ogbg-molhiv: 0.762103 test loss: 0.779880
[Epoch 11; Iter    30/  960] train: loss: 0.0669626
[Epoch 11; Iter    60/  960] train: loss: 0.4221663
[Epoch 11; Iter    90/  960] train: loss: 0.1140733
[Epoch 11; Iter   120/  960] train: loss: 0.0423889
[Epoch 11; Iter   150/  960] train: loss: 0.0268947
[Epoch 11; Iter   180/  960] train: loss: 0.0275378
[Epoch 11; Iter   210/  960] train: loss: 0.2924447
[Epoch 11; Iter   240/  960] train: loss: 0.0589874
[Epoch 11; Iter   270/  960] train: loss: 0.1778641
[Epoch 11; Iter   300/  960] train: loss: 0.1790791
[Epoch 11; Iter   330/  960] train: loss: 0.0250718
[Epoch 11; Iter   360/  960] train: loss: 0.2627296
[Epoch 11; Iter   390/  960] train: loss: 0.1225906
[Epoch 11; Iter   420/  960] train: loss: 0.0392927
[Epoch 11; Iter   450/  960] train: loss: 0.0816854
[Epoch 11; Iter   480/  960] train: loss: 0.0285274
[Epoch 11; Iter   510/  960] train: loss: 0.1380037
[Epoch 11; Iter   540/  960] train: loss: 0.0966668
[Epoch 11; Iter   570/  960] train: loss: 0.0581538
[Epoch 11; Iter   600/  960] train: loss: 0.3366132
[Epoch 11; Iter   630/  960] train: loss: 0.0989599
[Epoch 11; Iter   660/  960] train: loss: 0.0523142
[Epoch 11; Iter   690/  960] train: loss: 0.0291859
[Epoch 11; Iter   720/  960] train: loss: 0.1200746
[Epoch 11; Iter   750/  960] train: loss: 0.0848938
[Epoch 11; Iter   780/  960] train: loss: 0.0257349
[Epoch 11; Iter   810/  960] train: loss: 0.0460411
[Epoch 11; Iter   840/  960] train: loss: 0.0389890
[Epoch 11; Iter   870/  960] train: loss: 0.0249182
[Epoch 11; Iter   900/  960] train: loss: 0.0220842
[Epoch 11; Iter   930/  960] train: loss: 0.0279418
[Epoch 11; Iter   960/  960] train: loss: 0.0284064
[Epoch 11] ogbg-molhiv: 0.791043 val loss: 0.323608
[Epoch 11] ogbg-molhiv: 0.787509 test loss: 0.386105
[Epoch 12; Iter    30/  960] train: loss: 0.0293301
[Epoch 12; Iter    60/  960] train: loss: 0.0237424
[Epoch 12; Iter    90/  960] train: loss: 0.1023232
[Epoch 12; Iter   120/  960] train: loss: 0.0337050
[Epoch 12; Iter   150/  960] train: loss: 0.2138702
[Epoch 12; Iter   180/  960] train: loss: 0.0284371
[Epoch 12; Iter   210/  960] train: loss: 0.1404679
[Epoch 12; Iter   240/  960] train: loss: 0.0776147
[Epoch 12; Iter   270/  960] train: loss: 0.2226684
[Epoch 12; Iter   300/  960] train: loss: 0.1109254
[Epoch 12; Iter   330/  960] train: loss: 0.2733104
[Epoch 12; Iter   360/  960] train: loss: 0.0424559
[Epoch 12; Iter   390/  960] train: loss: 0.0301648
[Epoch 12; Iter   420/  960] train: loss: 0.0548447
[Epoch 12; Iter   450/  960] train: loss: 0.0770514
[Epoch 12; Iter   480/  960] train: loss: 0.0320853
[Epoch 12; Iter   510/  960] train: loss: 0.0912914
[Epoch 12; Iter   540/  960] train: loss: 0.1674488
[Epoch 12; Iter   570/  960] train: loss: 0.0591246
[Epoch 12; Iter   600/  960] train: loss: 0.0731575
[Epoch 12; Iter   630/  960] train: loss: 0.0328933
[Epoch 12; Iter   660/  960] train: loss: 0.3043759
[Epoch 12; Iter   690/  960] train: loss: 0.2256217
[Epoch 12; Iter   720/  960] train: loss: 0.0242986
[Epoch 12; Iter   750/  960] train: loss: 0.1303050
[Epoch 12; Iter   780/  960] train: loss: 0.0285410
[Epoch 12; Iter   810/  960] train: loss: 0.0297144
[Epoch 12; Iter   840/  960] train: loss: 0.0384904
[Epoch 12; Iter   870/  960] train: loss: 0.0664671
[Epoch 12; Iter   900/  960] train: loss: 0.0366813
[Epoch 12; Iter   930/  960] train: loss: 0.0556274
[Epoch 12; Iter   960/  960] train: loss: 0.0257039
[Epoch 12] ogbg-molhiv: 0.788658 val loss: 0.494637
[Epoch 12] ogbg-molhiv: 0.798224 test loss: 0.620559
[Epoch 13; Iter    30/  960] train: loss: 0.1126309
[Epoch 13; Iter    60/  960] train: loss: 0.0264149
[Epoch 13; Iter    90/  960] train: loss: 0.0659899
[Epoch 13; Iter   120/  960] train: loss: 0.0658867
[Epoch 13; Iter   150/  960] train: loss: 0.1293135
[Epoch 13; Iter   180/  960] train: loss: 0.1849679
[Epoch 13; Iter   210/  960] train: loss: 0.0323499
[Epoch 13; Iter   240/  960] train: loss: 0.1601856
[Epoch 13; Iter   270/  960] train: loss: 0.0295461
[Epoch 13; Iter   300/  960] train: loss: 0.1362183
[Epoch 13; Iter   330/  960] train: loss: 0.0661077
[Epoch 13; Iter   360/  960] train: loss: 0.1623302
[Epoch 13; Iter   390/  960] train: loss: 0.0256965
[Epoch 13; Iter   420/  960] train: loss: 0.0306535
[Epoch 13; Iter   450/  960] train: loss: 0.0693442
[Epoch 13; Iter   480/  960] train: loss: 0.0210465
[Epoch 13; Iter   510/  960] train: loss: 0.0237280
[Epoch 13; Iter   540/  960] train: loss: 0.0263582
[Epoch 13; Iter   570/  960] train: loss: 0.3444520
[Epoch 13; Iter   600/  960] train: loss: 0.0267340
[Epoch 8] ogbg-molhiv: 0.770962 val loss: 0.137500
[Epoch 8] ogbg-molhiv: 0.780958 test loss: 0.132239
[Epoch 9; Iter    30/  960] train: loss: 0.1402825
[Epoch 9; Iter    60/  960] train: loss: 0.0309378
[Epoch 9; Iter    90/  960] train: loss: 0.0818775
[Epoch 9; Iter   120/  960] train: loss: 0.0213952
[Epoch 9; Iter   150/  960] train: loss: 0.0430776
[Epoch 9; Iter   180/  960] train: loss: 0.0291923
[Epoch 9; Iter   210/  960] train: loss: 0.1126943
[Epoch 9; Iter   240/  960] train: loss: 0.2037298
[Epoch 9; Iter   270/  960] train: loss: 0.1701711
[Epoch 9; Iter   300/  960] train: loss: 0.0251849
[Epoch 9; Iter   330/  960] train: loss: 0.1622620
[Epoch 9; Iter   360/  960] train: loss: 0.1942458
[Epoch 9; Iter   390/  960] train: loss: 0.3548656
[Epoch 9; Iter   420/  960] train: loss: 0.1318467
[Epoch 9; Iter   450/  960] train: loss: 0.0742784
[Epoch 9; Iter   480/  960] train: loss: 0.0295764
[Epoch 9; Iter   510/  960] train: loss: 0.1757374
[Epoch 9; Iter   540/  960] train: loss: 0.0907625
[Epoch 9; Iter   570/  960] train: loss: 0.1185680
[Epoch 9; Iter   600/  960] train: loss: 0.1625620
[Epoch 9; Iter   630/  960] train: loss: 0.1954278
[Epoch 9; Iter   660/  960] train: loss: 0.0368270
[Epoch 9; Iter   690/  960] train: loss: 0.0282675
[Epoch 9; Iter   720/  960] train: loss: 0.2062148
[Epoch 9; Iter   750/  960] train: loss: 0.0244576
[Epoch 9; Iter   780/  960] train: loss: 0.3080999
[Epoch 9; Iter   810/  960] train: loss: 0.1304904
[Epoch 9; Iter   840/  960] train: loss: 0.1063302
[Epoch 9; Iter   870/  960] train: loss: 0.1613612
[Epoch 9; Iter   900/  960] train: loss: 0.1161583
[Epoch 9; Iter   930/  960] train: loss: 0.3326141
[Epoch 9; Iter   960/  960] train: loss: 0.0302304
[Epoch 9] ogbg-molhiv: 0.784978 val loss: 0.158325
[Epoch 9] ogbg-molhiv: 0.771926 test loss: 0.167671
[Epoch 10; Iter    30/  960] train: loss: 0.0490167
[Epoch 10; Iter    60/  960] train: loss: 0.2709303
[Epoch 10; Iter    90/  960] train: loss: 0.0236290
[Epoch 10; Iter   120/  960] train: loss: 0.0300724
[Epoch 10; Iter   150/  960] train: loss: 0.1881285
[Epoch 10; Iter   180/  960] train: loss: 0.0248308
[Epoch 10; Iter   210/  960] train: loss: 0.0306673
[Epoch 10; Iter   240/  960] train: loss: 0.1707115
[Epoch 10; Iter   270/  960] train: loss: 0.1918130
[Epoch 10; Iter   300/  960] train: loss: 0.0218144
[Epoch 10; Iter   330/  960] train: loss: 0.2217164
[Epoch 10; Iter   360/  960] train: loss: 0.0302441
[Epoch 10; Iter   390/  960] train: loss: 0.3315465
[Epoch 10; Iter   420/  960] train: loss: 0.1274041
[Epoch 10; Iter   450/  960] train: loss: 0.0981875
[Epoch 10; Iter   480/  960] train: loss: 0.0998433
[Epoch 10; Iter   510/  960] train: loss: 0.2623134
[Epoch 10; Iter   540/  960] train: loss: 0.5008458
[Epoch 10; Iter   570/  960] train: loss: 0.1875133
[Epoch 10; Iter   600/  960] train: loss: 0.0255876
[Epoch 10; Iter   630/  960] train: loss: 0.0294686
[Epoch 10; Iter   660/  960] train: loss: 0.0257073
[Epoch 10; Iter   690/  960] train: loss: 0.1717432
[Epoch 10; Iter   720/  960] train: loss: 0.0309816
[Epoch 10; Iter   750/  960] train: loss: 0.3126103
[Epoch 10; Iter   780/  960] train: loss: 0.0590624
[Epoch 10; Iter   810/  960] train: loss: 0.1533702
[Epoch 10; Iter   840/  960] train: loss: 0.1349607
[Epoch 10; Iter   870/  960] train: loss: 0.0816933
[Epoch 10; Iter   900/  960] train: loss: 0.2214609
[Epoch 10; Iter   930/  960] train: loss: 0.1006383
[Epoch 10; Iter   960/  960] train: loss: 0.0883241
[Epoch 10] ogbg-molhiv: 0.798441 val loss: 0.229274
[Epoch 10] ogbg-molhiv: 0.807292 test loss: 0.164072
[Epoch 11; Iter    30/  960] train: loss: 0.1770196
[Epoch 11; Iter    60/  960] train: loss: 0.3688494
[Epoch 11; Iter    90/  960] train: loss: 0.0965927
[Epoch 11; Iter   120/  960] train: loss: 0.0337203
[Epoch 11; Iter   150/  960] train: loss: 0.0274695
[Epoch 11; Iter   180/  960] train: loss: 0.0229263
[Epoch 11; Iter   210/  960] train: loss: 0.1467691
[Epoch 11; Iter   240/  960] train: loss: 0.0357071
[Epoch 11; Iter   270/  960] train: loss: 0.2582192
[Epoch 11; Iter   300/  960] train: loss: 0.1183387
[Epoch 11; Iter   330/  960] train: loss: 0.1988676
[Epoch 11; Iter   360/  960] train: loss: 0.0578095
[Epoch 11; Iter   390/  960] train: loss: 0.1479874
[Epoch 11; Iter   420/  960] train: loss: 0.1053170
[Epoch 11; Iter   450/  960] train: loss: 0.1454524
[Epoch 11; Iter   480/  960] train: loss: 0.0335379
[Epoch 11; Iter   510/  960] train: loss: 0.0660999
[Epoch 11; Iter   540/  960] train: loss: 0.0329853
[Epoch 11; Iter   570/  960] train: loss: 0.1818842
[Epoch 11; Iter   600/  960] train: loss: 0.0234956
[Epoch 11; Iter   630/  960] train: loss: 0.2078916
[Epoch 11; Iter   660/  960] train: loss: 0.0399004
[Epoch 11; Iter   690/  960] train: loss: 0.0712098
[Epoch 11; Iter   720/  960] train: loss: 0.3379028
[Epoch 11; Iter   750/  960] train: loss: 0.0272549
[Epoch 11; Iter   780/  960] train: loss: 0.0222530
[Epoch 11; Iter   810/  960] train: loss: 0.1711552
[Epoch 11; Iter   840/  960] train: loss: 0.3803363
[Epoch 11; Iter   870/  960] train: loss: 0.0238645
[Epoch 11; Iter   900/  960] train: loss: 0.1188002
[Epoch 11; Iter   930/  960] train: loss: 0.0238971
[Epoch 11; Iter   960/  960] train: loss: 0.0304261
[Epoch 11] ogbg-molhiv: 0.780680 val loss: 0.129507
[Epoch 11] ogbg-molhiv: 0.790264 test loss: 0.125176
[Epoch 12; Iter    30/  960] train: loss: 0.2919281
[Epoch 12; Iter    60/  960] train: loss: 0.0720305
[Epoch 12; Iter    90/  960] train: loss: 0.2315670
[Epoch 12; Iter   120/  960] train: loss: 0.0206533
[Epoch 12; Iter   150/  960] train: loss: 0.0257834
[Epoch 12; Iter   180/  960] train: loss: 0.0860590
[Epoch 12; Iter   210/  960] train: loss: 0.0194015
[Epoch 12; Iter   240/  960] train: loss: 0.0233591
[Epoch 12; Iter   270/  960] train: loss: 0.1324125
[Epoch 12; Iter   300/  960] train: loss: 0.0280804
[Epoch 12; Iter   330/  960] train: loss: 0.0361991
[Epoch 12; Iter   360/  960] train: loss: 0.1521212
[Epoch 12; Iter   390/  960] train: loss: 0.1928346
[Epoch 12; Iter   420/  960] train: loss: 0.0466450
[Epoch 12; Iter   450/  960] train: loss: 0.0613246
[Epoch 12; Iter   480/  960] train: loss: 0.0304885
[Epoch 12; Iter   510/  960] train: loss: 0.0256279
[Epoch 12; Iter   540/  960] train: loss: 0.2096055
[Epoch 12; Iter   570/  960] train: loss: 0.0915909
[Epoch 12; Iter   600/  960] train: loss: 0.1292547
[Epoch 12; Iter   630/  960] train: loss: 0.1112958
[Epoch 12; Iter   660/  960] train: loss: 0.2484789
[Epoch 12; Iter   690/  960] train: loss: 0.2436064
[Epoch 12; Iter   720/  960] train: loss: 0.0659305
[Epoch 12; Iter   750/  960] train: loss: 0.1553530
[Epoch 12; Iter   780/  960] train: loss: 0.0580464
[Epoch 12; Iter   810/  960] train: loss: 0.0794539
[Epoch 12; Iter   840/  960] train: loss: 0.1399475
[Epoch 12; Iter   870/  960] train: loss: 0.2925146
[Epoch 12; Iter   900/  960] train: loss: 0.0869734
[Epoch 12; Iter   930/  960] train: loss: 0.0525832
[Epoch 12; Iter   960/  960] train: loss: 0.0300681
[Epoch 12] ogbg-molhiv: 0.802321 val loss: 0.194263
[Epoch 12] ogbg-molhiv: 0.798233 test loss: 0.136211
[Epoch 13; Iter    30/  960] train: loss: 0.0401329
[Epoch 13; Iter    60/  960] train: loss: 0.1827387
[Epoch 13; Iter    90/  960] train: loss: 0.3494852
[Epoch 13; Iter   120/  960] train: loss: 0.1528160
[Epoch 13; Iter   150/  960] train: loss: 0.2779600
[Epoch 13; Iter   180/  960] train: loss: 0.0829513
[Epoch 13; Iter   210/  960] train: loss: 0.2148846
[Epoch 13; Iter   240/  960] train: loss: 0.1853302
[Epoch 13; Iter   270/  960] train: loss: 0.1104721
[Epoch 13; Iter   300/  960] train: loss: 0.2791699
[Epoch 13; Iter   330/  960] train: loss: 0.0393684
[Epoch 13; Iter   360/  960] train: loss: 0.0368494
[Epoch 13; Iter   390/  960] train: loss: 0.0215992
[Epoch 13; Iter   420/  960] train: loss: 0.2576767
[Epoch 13; Iter   450/  960] train: loss: 0.1808950
[Epoch 13; Iter   480/  960] train: loss: 0.0401094
[Epoch 13; Iter   510/  960] train: loss: 0.2011086
[Epoch 13; Iter   540/  960] train: loss: 0.1440116
[Epoch 13; Iter   570/  960] train: loss: 0.1090975
[Epoch 13; Iter   600/  960] train: loss: 0.0304465
[Epoch 10; Iter   183/  823] train: loss: 0.2693801
[Epoch 10; Iter   213/  823] train: loss: 0.0414778
[Epoch 10; Iter   243/  823] train: loss: 0.2265297
[Epoch 10; Iter   273/  823] train: loss: 0.0273409
[Epoch 10; Iter   303/  823] train: loss: 0.1168009
[Epoch 10; Iter   333/  823] train: loss: 0.0266958
[Epoch 10; Iter   363/  823] train: loss: 0.1788519
[Epoch 10; Iter   393/  823] train: loss: 0.0300094
[Epoch 10; Iter   423/  823] train: loss: 0.1144417
[Epoch 10; Iter   453/  823] train: loss: 0.0760711
[Epoch 10; Iter   483/  823] train: loss: 0.0303845
[Epoch 10; Iter   513/  823] train: loss: 0.0350919
[Epoch 10; Iter   543/  823] train: loss: 0.0267250
[Epoch 10; Iter   573/  823] train: loss: 0.1823098
[Epoch 10; Iter   603/  823] train: loss: 0.0372628
[Epoch 10; Iter   633/  823] train: loss: 0.2334573
[Epoch 10; Iter   663/  823] train: loss: 0.0354408
[Epoch 10; Iter   693/  823] train: loss: 0.3299064
[Epoch 10; Iter   723/  823] train: loss: 0.1101458
[Epoch 10; Iter   753/  823] train: loss: 0.0272187
[Epoch 10; Iter   783/  823] train: loss: 0.2465622
[Epoch 10; Iter   813/  823] train: loss: 0.1541244
[Epoch 10] ogbg-molhiv: 0.787220 val loss: 0.131293
[Epoch 10] ogbg-molhiv: 0.752013 test loss: 0.147223
[Epoch 11; Iter    20/  823] train: loss: 0.0526142
[Epoch 11; Iter    50/  823] train: loss: 0.0569849
[Epoch 11; Iter    80/  823] train: loss: 0.0335870
[Epoch 11; Iter   110/  823] train: loss: 0.0296276
[Epoch 11; Iter   140/  823] train: loss: 0.0321850
[Epoch 11; Iter   170/  823] train: loss: 0.0266173
[Epoch 11; Iter   200/  823] train: loss: 0.0584413
[Epoch 11; Iter   230/  823] train: loss: 0.0477071
[Epoch 11; Iter   260/  823] train: loss: 0.0727261
[Epoch 11; Iter   290/  823] train: loss: 0.0247288
[Epoch 11; Iter   320/  823] train: loss: 0.0265421
[Epoch 11; Iter   350/  823] train: loss: 0.2857034
[Epoch 11; Iter   380/  823] train: loss: 0.2141407
[Epoch 11; Iter   410/  823] train: loss: 0.2850241
[Epoch 11; Iter   440/  823] train: loss: 0.0765490
[Epoch 11; Iter   470/  823] train: loss: 0.1275609
[Epoch 11; Iter   500/  823] train: loss: 0.2071247
[Epoch 11; Iter   530/  823] train: loss: 0.1448256
[Epoch 11; Iter   560/  823] train: loss: 0.0307996
[Epoch 11; Iter   590/  823] train: loss: 0.0355739
[Epoch 11; Iter   620/  823] train: loss: 0.3306120
[Epoch 11; Iter   650/  823] train: loss: 0.1252665
[Epoch 11; Iter   680/  823] train: loss: 0.1643300
[Epoch 11; Iter   710/  823] train: loss: 0.0264206
[Epoch 11; Iter   740/  823] train: loss: 0.2034963
[Epoch 11; Iter   770/  823] train: loss: 0.1567040
[Epoch 11; Iter   800/  823] train: loss: 0.2122200
[Epoch 11] ogbg-molhiv: 0.780060 val loss: 0.126649
[Epoch 11] ogbg-molhiv: 0.756481 test loss: 0.130590
[Epoch 12; Iter     7/  823] train: loss: 0.0971875
[Epoch 12; Iter    37/  823] train: loss: 0.2441314
[Epoch 12; Iter    67/  823] train: loss: 0.2583548
[Epoch 12; Iter    97/  823] train: loss: 0.0393282
[Epoch 12; Iter   127/  823] train: loss: 0.0543350
[Epoch 12; Iter   157/  823] train: loss: 0.1533943
[Epoch 12; Iter   187/  823] train: loss: 0.1483029
[Epoch 12; Iter   217/  823] train: loss: 0.0383206
[Epoch 12; Iter   247/  823] train: loss: 0.0312206
[Epoch 12; Iter   277/  823] train: loss: 0.0301432
[Epoch 12; Iter   307/  823] train: loss: 0.1101042
[Epoch 12; Iter   337/  823] train: loss: 0.0248496
[Epoch 12; Iter   367/  823] train: loss: 0.0335237
[Epoch 12; Iter   397/  823] train: loss: 0.0340335
[Epoch 12; Iter   427/  823] train: loss: 0.1669766
[Epoch 12; Iter   457/  823] train: loss: 0.0262064
[Epoch 12; Iter   487/  823] train: loss: 0.1033732
[Epoch 12; Iter   517/  823] train: loss: 0.3119663
[Epoch 12; Iter   547/  823] train: loss: 0.0620873
[Epoch 12; Iter   577/  823] train: loss: 0.1658698
[Epoch 12; Iter   607/  823] train: loss: 0.1704618
[Epoch 12; Iter   637/  823] train: loss: 0.2387609
[Epoch 12; Iter   667/  823] train: loss: 0.2291935
[Epoch 12; Iter   697/  823] train: loss: 0.2556607
[Epoch 12; Iter   727/  823] train: loss: 0.1874324
[Epoch 12; Iter   757/  823] train: loss: 0.0245439
[Epoch 12; Iter   787/  823] train: loss: 0.3036234
[Epoch 12; Iter   817/  823] train: loss: 0.0364456
[Epoch 12] ogbg-molhiv: 0.790417 val loss: 0.122382
[Epoch 12] ogbg-molhiv: 0.750964 test loss: 0.127811
[Epoch 13; Iter    24/  823] train: loss: 0.0228170
[Epoch 13; Iter    54/  823] train: loss: 0.2828323
[Epoch 13; Iter    84/  823] train: loss: 0.0410529
[Epoch 13; Iter   114/  823] train: loss: 0.0317778
[Epoch 13; Iter   144/  823] train: loss: 0.2068848
[Epoch 13; Iter   174/  823] train: loss: 0.0624834
[Epoch 13; Iter   204/  823] train: loss: 0.0327299
[Epoch 13; Iter   234/  823] train: loss: 0.1039814
[Epoch 13; Iter   264/  823] train: loss: 0.1711688
[Epoch 13; Iter   294/  823] train: loss: 0.0502010
[Epoch 13; Iter   324/  823] train: loss: 0.0290565
[Epoch 13; Iter   354/  823] train: loss: 0.0272374
[Epoch 13; Iter   384/  823] train: loss: 0.1653928
[Epoch 13; Iter   414/  823] train: loss: 0.2617911
[Epoch 13; Iter   444/  823] train: loss: 0.3306648
[Epoch 13; Iter   474/  823] train: loss: 0.1755586
[Epoch 13; Iter   504/  823] train: loss: 0.0308913
[Epoch 13; Iter   534/  823] train: loss: 0.0406288
[Epoch 13; Iter   564/  823] train: loss: 0.3180531
[Epoch 13; Iter   594/  823] train: loss: 0.1216312
[Epoch 13; Iter   624/  823] train: loss: 0.0696683
[Epoch 13; Iter   654/  823] train: loss: 0.1199808
[Epoch 13; Iter   684/  823] train: loss: 0.0902478
[Epoch 13; Iter   714/  823] train: loss: 0.0246783
[Epoch 13; Iter   744/  823] train: loss: 0.2231784
[Epoch 13; Iter   774/  823] train: loss: 0.1916032
[Epoch 13; Iter   804/  823] train: loss: 0.1269136
[Epoch 13] ogbg-molhiv: 0.782977 val loss: 0.124186
[Epoch 13] ogbg-molhiv: 0.745387 test loss: 0.131344
[Epoch 14; Iter    11/  823] train: loss: 0.1667610
[Epoch 14; Iter    41/  823] train: loss: 0.1399004
[Epoch 14; Iter    71/  823] train: loss: 0.2398614
[Epoch 14; Iter   101/  823] train: loss: 0.1247700
[Epoch 14; Iter   131/  823] train: loss: 0.1301254
[Epoch 14; Iter   161/  823] train: loss: 0.0503182
[Epoch 14; Iter   191/  823] train: loss: 0.0269565
[Epoch 14; Iter   221/  823] train: loss: 0.1636739
[Epoch 14; Iter   251/  823] train: loss: 0.1384897
[Epoch 14; Iter   281/  823] train: loss: 0.2424016
[Epoch 14; Iter   311/  823] train: loss: 0.0574390
[Epoch 14; Iter   341/  823] train: loss: 0.0213222
[Epoch 14; Iter   371/  823] train: loss: 0.1442661
[Epoch 14; Iter   401/  823] train: loss: 0.0278779
[Epoch 14; Iter   431/  823] train: loss: 0.0323963
[Epoch 14; Iter   461/  823] train: loss: 0.5145379
[Epoch 14; Iter   491/  823] train: loss: 0.0737892
[Epoch 14; Iter   521/  823] train: loss: 0.1988595
[Epoch 14; Iter   551/  823] train: loss: 0.0655303
[Epoch 14; Iter   581/  823] train: loss: 0.2073486
[Epoch 14; Iter   611/  823] train: loss: 0.1463172
[Epoch 14; Iter   641/  823] train: loss: 0.2548518
[Epoch 14; Iter   671/  823] train: loss: 0.1351146
[Epoch 14; Iter   701/  823] train: loss: 0.3275042
[Epoch 14; Iter   731/  823] train: loss: 0.0270353
[Epoch 14; Iter   761/  823] train: loss: 0.0307399
[Epoch 14; Iter   791/  823] train: loss: 0.0435678
[Epoch 14; Iter   821/  823] train: loss: 0.2178661
[Epoch 14] ogbg-molhiv: 0.796820 val loss: 0.199261
[Epoch 14] ogbg-molhiv: 0.773912 test loss: 0.132559
[Epoch 15; Iter    28/  823] train: loss: 0.1534441
[Epoch 15; Iter    58/  823] train: loss: 0.0267419
[Epoch 15; Iter    88/  823] train: loss: 0.1573287
[Epoch 15; Iter   118/  823] train: loss: 0.1075116
[Epoch 15; Iter   148/  823] train: loss: 0.0304316
[Epoch 15; Iter   178/  823] train: loss: 0.0603046
[Epoch 15; Iter   208/  823] train: loss: 0.1464025
[Epoch 15; Iter   238/  823] train: loss: 0.0245879
[Epoch 15; Iter   268/  823] train: loss: 0.1286805
[Epoch 15; Iter   298/  823] train: loss: 0.0724061
[Epoch 15; Iter   328/  823] train: loss: 0.1611738
[Epoch 15; Iter   358/  823] train: loss: 0.0848147
[Epoch 15; Iter   388/  823] train: loss: 0.1295853
[Epoch 15; Iter   418/  823] train: loss: 0.0509838
[Epoch 15; Iter   448/  823] train: loss: 0.0312004
[Epoch 10; Iter   183/  823] train: loss: 0.1786222
[Epoch 10; Iter   213/  823] train: loss: 0.1042876
[Epoch 10; Iter   243/  823] train: loss: 0.1948280
[Epoch 10; Iter   273/  823] train: loss: 0.0690493
[Epoch 10; Iter   303/  823] train: loss: 0.1959424
[Epoch 10; Iter   333/  823] train: loss: 0.1239334
[Epoch 10; Iter   363/  823] train: loss: 0.0466012
[Epoch 10; Iter   393/  823] train: loss: 0.0362000
[Epoch 10; Iter   423/  823] train: loss: 0.1194342
[Epoch 10; Iter   453/  823] train: loss: 0.1686433
[Epoch 10; Iter   483/  823] train: loss: 0.1005270
[Epoch 10; Iter   513/  823] train: loss: 0.1191773
[Epoch 10; Iter   543/  823] train: loss: 0.2852582
[Epoch 10; Iter   573/  823] train: loss: 0.0316900
[Epoch 10; Iter   603/  823] train: loss: 0.0324404
[Epoch 10; Iter   633/  823] train: loss: 0.0269832
[Epoch 10; Iter   663/  823] train: loss: 0.2913583
[Epoch 10; Iter   693/  823] train: loss: 0.1547012
[Epoch 10; Iter   723/  823] train: loss: 0.1706817
[Epoch 10; Iter   753/  823] train: loss: 0.1035028
[Epoch 10; Iter   783/  823] train: loss: 0.0280302
[Epoch 10; Iter   813/  823] train: loss: 0.0357665
[Epoch 10] ogbg-molhiv: 0.768629 val loss: 0.134884
[Epoch 10] ogbg-molhiv: 0.769528 test loss: 0.132300
[Epoch 11; Iter    20/  823] train: loss: 0.0277927
[Epoch 11; Iter    50/  823] train: loss: 0.1944079
[Epoch 11; Iter    80/  823] train: loss: 0.0368831
[Epoch 11; Iter   110/  823] train: loss: 0.2461847
[Epoch 11; Iter   140/  823] train: loss: 0.0280220
[Epoch 11; Iter   170/  823] train: loss: 0.0841442
[Epoch 11; Iter   200/  823] train: loss: 0.1613225
[Epoch 11; Iter   230/  823] train: loss: 0.0397175
[Epoch 11; Iter   260/  823] train: loss: 0.0277496
[Epoch 11; Iter   290/  823] train: loss: 0.0972374
[Epoch 11; Iter   320/  823] train: loss: 0.3465791
[Epoch 11; Iter   350/  823] train: loss: 0.1613212
[Epoch 11; Iter   380/  823] train: loss: 0.1318489
[Epoch 11; Iter   410/  823] train: loss: 0.1354348
[Epoch 11; Iter   440/  823] train: loss: 0.2495297
[Epoch 11; Iter   470/  823] train: loss: 0.2324727
[Epoch 11; Iter   500/  823] train: loss: 0.0312319
[Epoch 11; Iter   530/  823] train: loss: 0.2370667
[Epoch 11; Iter   560/  823] train: loss: 0.0380427
[Epoch 11; Iter   590/  823] train: loss: 0.0944721
[Epoch 11; Iter   620/  823] train: loss: 0.0310916
[Epoch 11; Iter   650/  823] train: loss: 0.0401552
[Epoch 11; Iter   680/  823] train: loss: 0.0298230
[Epoch 11; Iter   710/  823] train: loss: 0.0299879
[Epoch 11; Iter   740/  823] train: loss: 0.2181412
[Epoch 11; Iter   770/  823] train: loss: 0.2272718
[Epoch 11; Iter   800/  823] train: loss: 0.3054867
[Epoch 11] ogbg-molhiv: 0.774517 val loss: 0.335185
[Epoch 11] ogbg-molhiv: 0.758801 test loss: 0.196898
[Epoch 12; Iter     7/  823] train: loss: 0.2721191
[Epoch 12; Iter    37/  823] train: loss: 0.2353656
[Epoch 12; Iter    67/  823] train: loss: 0.0683404
[Epoch 12; Iter    97/  823] train: loss: 0.0300023
[Epoch 12; Iter   127/  823] train: loss: 0.1440063
[Epoch 12; Iter   157/  823] train: loss: 0.1068738
[Epoch 12; Iter   187/  823] train: loss: 0.1047839
[Epoch 12; Iter   217/  823] train: loss: 0.0297187
[Epoch 12; Iter   247/  823] train: loss: 0.1881419
[Epoch 12; Iter   277/  823] train: loss: 0.1440784
[Epoch 12; Iter   307/  823] train: loss: 0.0265114
[Epoch 12; Iter   337/  823] train: loss: 0.1299217
[Epoch 12; Iter   367/  823] train: loss: 0.0548666
[Epoch 12; Iter   397/  823] train: loss: 0.1081976
[Epoch 12; Iter   427/  823] train: loss: 0.0647198
[Epoch 12; Iter   457/  823] train: loss: 0.4259178
[Epoch 12; Iter   487/  823] train: loss: 0.1164350
[Epoch 12; Iter   517/  823] train: loss: 0.0244554
[Epoch 12; Iter   547/  823] train: loss: 0.0379838
[Epoch 12; Iter   577/  823] train: loss: 0.0263543
[Epoch 12; Iter   607/  823] train: loss: 0.2192036
[Epoch 12; Iter   637/  823] train: loss: 0.0424188
[Epoch 12; Iter   667/  823] train: loss: 0.1955272
[Epoch 12; Iter   697/  823] train: loss: 0.0236339
[Epoch 12; Iter   727/  823] train: loss: 0.0324335
[Epoch 12; Iter   757/  823] train: loss: 0.0883300
[Epoch 12; Iter   787/  823] train: loss: 0.1393711
[Epoch 12; Iter   817/  823] train: loss: 0.0291193
[Epoch 12] ogbg-molhiv: 0.782265 val loss: 0.867487
[Epoch 12] ogbg-molhiv: 0.759848 test loss: 0.936160
[Epoch 13; Iter    24/  823] train: loss: 0.0181764
[Epoch 13; Iter    54/  823] train: loss: 0.1021291
[Epoch 13; Iter    84/  823] train: loss: 0.0191702
[Epoch 13; Iter   114/  823] train: loss: 0.1944004
[Epoch 13; Iter   144/  823] train: loss: 0.0958258
[Epoch 13; Iter   174/  823] train: loss: 0.0513610
[Epoch 13; Iter   204/  823] train: loss: 0.0421649
[Epoch 13; Iter   234/  823] train: loss: 0.0716525
[Epoch 13; Iter   264/  823] train: loss: 0.0384369
[Epoch 13; Iter   294/  823] train: loss: 0.1754142
[Epoch 13; Iter   324/  823] train: loss: 0.0429853
[Epoch 13; Iter   354/  823] train: loss: 0.1114295
[Epoch 13; Iter   384/  823] train: loss: 0.1596095
[Epoch 13; Iter   414/  823] train: loss: 0.0310812
[Epoch 13; Iter   444/  823] train: loss: 0.1441683
[Epoch 13; Iter   474/  823] train: loss: 0.3421198
[Epoch 13; Iter   504/  823] train: loss: 0.4085368
[Epoch 13; Iter   534/  823] train: loss: 0.3013547
[Epoch 13; Iter   564/  823] train: loss: 0.0314105
[Epoch 13; Iter   594/  823] train: loss: 0.0455634
[Epoch 13; Iter   624/  823] train: loss: 0.0261721
[Epoch 13; Iter   654/  823] train: loss: 0.0408858
[Epoch 13; Iter   684/  823] train: loss: 0.0412214
[Epoch 13; Iter   714/  823] train: loss: 0.0850583
[Epoch 13; Iter   744/  823] train: loss: 0.1175370
[Epoch 13; Iter   774/  823] train: loss: 0.1021358
[Epoch 13; Iter   804/  823] train: loss: 0.3137232
[Epoch 13] ogbg-molhiv: 0.792031 val loss: 0.127533
[Epoch 13] ogbg-molhiv: 0.759491 test loss: 0.137071
[Epoch 14; Iter    11/  823] train: loss: 0.1604403
[Epoch 14; Iter    41/  823] train: loss: 0.0371258
[Epoch 14; Iter    71/  823] train: loss: 0.1700844
[Epoch 14; Iter   101/  823] train: loss: 0.0581750
[Epoch 14; Iter   131/  823] train: loss: 0.1356169
[Epoch 14; Iter   161/  823] train: loss: 0.3859390
[Epoch 14; Iter   191/  823] train: loss: 0.1284686
[Epoch 14; Iter   221/  823] train: loss: 0.1142673
[Epoch 14; Iter   251/  823] train: loss: 0.0853557
[Epoch 14; Iter   281/  823] train: loss: 0.1087238
[Epoch 14; Iter   311/  823] train: loss: 0.1569813
[Epoch 14; Iter   341/  823] train: loss: 0.1478580
[Epoch 14; Iter   371/  823] train: loss: 0.4320915
[Epoch 14; Iter   401/  823] train: loss: 0.1573092
[Epoch 14; Iter   431/  823] train: loss: 0.2862588
[Epoch 14; Iter   461/  823] train: loss: 0.0211939
[Epoch 14; Iter   491/  823] train: loss: 0.2922336
[Epoch 14; Iter   521/  823] train: loss: 0.0258485
[Epoch 14; Iter   551/  823] train: loss: 0.3452244
[Epoch 14; Iter   581/  823] train: loss: 0.1313164
[Epoch 14; Iter   611/  823] train: loss: 0.0923113
[Epoch 14; Iter   641/  823] train: loss: 0.0776464
[Epoch 14; Iter   671/  823] train: loss: 0.0395341
[Epoch 14; Iter   701/  823] train: loss: 0.2560597
[Epoch 14; Iter   731/  823] train: loss: 0.0325498
[Epoch 14; Iter   761/  823] train: loss: 0.2607808
[Epoch 14; Iter   791/  823] train: loss: 0.0415943
[Epoch 14; Iter   821/  823] train: loss: 0.1722699
[Epoch 14] ogbg-molhiv: 0.786795 val loss: 0.137593
[Epoch 14] ogbg-molhiv: 0.775829 test loss: 0.145285
[Epoch 15; Iter    28/  823] train: loss: 0.0322133
[Epoch 15; Iter    58/  823] train: loss: 0.0349522
[Epoch 15; Iter    88/  823] train: loss: 0.1537453
[Epoch 15; Iter   118/  823] train: loss: 0.0410544
[Epoch 15; Iter   148/  823] train: loss: 0.0260793
[Epoch 15; Iter   178/  823] train: loss: 0.0254552
[Epoch 15; Iter   208/  823] train: loss: 0.2513694
[Epoch 15; Iter   238/  823] train: loss: 0.0267497
[Epoch 15; Iter   268/  823] train: loss: 0.0649380
[Epoch 15; Iter   298/  823] train: loss: 0.0940105
[Epoch 15; Iter   328/  823] train: loss: 0.1376776
[Epoch 15; Iter   358/  823] train: loss: 0.1996319
[Epoch 15; Iter   388/  823] train: loss: 0.0896448
[Epoch 15; Iter   418/  823] train: loss: 0.0458184
[Epoch 15; Iter   448/  823] train: loss: 0.0245261
[Epoch 10; Iter   183/  823] train: loss: 0.0863441
[Epoch 10; Iter   213/  823] train: loss: 0.1589490
[Epoch 10; Iter   243/  823] train: loss: 0.1598509
[Epoch 10; Iter   273/  823] train: loss: 0.1466472
[Epoch 10; Iter   303/  823] train: loss: 0.0403035
[Epoch 10; Iter   333/  823] train: loss: 0.1239433
[Epoch 10; Iter   363/  823] train: loss: 0.1631843
[Epoch 10; Iter   393/  823] train: loss: 0.2199205
[Epoch 10; Iter   423/  823] train: loss: 0.0243640
[Epoch 10; Iter   453/  823] train: loss: 0.1327222
[Epoch 10; Iter   483/  823] train: loss: 0.1092811
[Epoch 10; Iter   513/  823] train: loss: 0.1839950
[Epoch 10; Iter   543/  823] train: loss: 0.1401349
[Epoch 10; Iter   573/  823] train: loss: 0.0738739
[Epoch 10; Iter   603/  823] train: loss: 0.2010010
[Epoch 10; Iter   633/  823] train: loss: 0.0230002
[Epoch 10; Iter   663/  823] train: loss: 0.0323383
[Epoch 10; Iter   693/  823] train: loss: 0.1925756
[Epoch 10; Iter   723/  823] train: loss: 0.1748586
[Epoch 10; Iter   753/  823] train: loss: 0.1890228
[Epoch 10; Iter   783/  823] train: loss: 0.0921846
[Epoch 10; Iter   813/  823] train: loss: 0.0266695
[Epoch 10] ogbg-molhiv: 0.795593 val loss: 0.367383
[Epoch 10] ogbg-molhiv: 0.777530 test loss: 0.389229
[Epoch 11; Iter    20/  823] train: loss: 0.0451106
[Epoch 11; Iter    50/  823] train: loss: 0.1252834
[Epoch 11; Iter    80/  823] train: loss: 0.0401117
[Epoch 11; Iter   110/  823] train: loss: 0.0254522
[Epoch 11; Iter   140/  823] train: loss: 0.1690247
[Epoch 11; Iter   170/  823] train: loss: 0.1719812
[Epoch 11; Iter   200/  823] train: loss: 0.0289181
[Epoch 11; Iter   230/  823] train: loss: 0.0383290
[Epoch 11; Iter   260/  823] train: loss: 0.2995846
[Epoch 11; Iter   290/  823] train: loss: 0.0260181
[Epoch 11; Iter   320/  823] train: loss: 0.0650426
[Epoch 11; Iter   350/  823] train: loss: 0.3455902
[Epoch 11; Iter   380/  823] train: loss: 0.0272960
[Epoch 11; Iter   410/  823] train: loss: 0.0882004
[Epoch 11; Iter   440/  823] train: loss: 0.1760834
[Epoch 11; Iter   470/  823] train: loss: 0.0750087
[Epoch 11; Iter   500/  823] train: loss: 0.1333360
[Epoch 11; Iter   530/  823] train: loss: 0.1722850
[Epoch 11; Iter   560/  823] train: loss: 0.0253896
[Epoch 11; Iter   590/  823] train: loss: 0.0635814
[Epoch 11; Iter   620/  823] train: loss: 0.0360434
[Epoch 11; Iter   650/  823] train: loss: 0.1906961
[Epoch 11; Iter   680/  823] train: loss: 0.0235666
[Epoch 11; Iter   710/  823] train: loss: 0.2313464
[Epoch 11; Iter   740/  823] train: loss: 0.2115965
[Epoch 11; Iter   770/  823] train: loss: 0.1561806
[Epoch 11; Iter   800/  823] train: loss: 0.0477825
[Epoch 11] ogbg-molhiv: 0.788069 val loss: 0.325659
[Epoch 11] ogbg-molhiv: 0.766210 test loss: 0.408082
[Epoch 12; Iter     7/  823] train: loss: 0.0209605
[Epoch 12; Iter    37/  823] train: loss: 0.1451147
[Epoch 12; Iter    67/  823] train: loss: 0.0315724
[Epoch 12; Iter    97/  823] train: loss: 0.0351074
[Epoch 12; Iter   127/  823] train: loss: 0.2472580
[Epoch 12; Iter   157/  823] train: loss: 0.0886848
[Epoch 12; Iter   187/  823] train: loss: 0.1445348
[Epoch 12; Iter   217/  823] train: loss: 0.0265926
[Epoch 12; Iter   247/  823] train: loss: 0.4829717
[Epoch 12; Iter   277/  823] train: loss: 0.1199948
[Epoch 12; Iter   307/  823] train: loss: 0.1783740
[Epoch 12; Iter   337/  823] train: loss: 0.0416244
[Epoch 12; Iter   367/  823] train: loss: 0.0284548
[Epoch 12; Iter   397/  823] train: loss: 0.2382418
[Epoch 12; Iter   427/  823] train: loss: 0.1287943
[Epoch 12; Iter   457/  823] train: loss: 0.0267924
[Epoch 12; Iter   487/  823] train: loss: 0.2663142
[Epoch 12; Iter   517/  823] train: loss: 0.0705627
[Epoch 12; Iter   547/  823] train: loss: 0.0244518
[Epoch 12; Iter   577/  823] train: loss: 0.1471983
[Epoch 12; Iter   607/  823] train: loss: 0.0285244
[Epoch 12; Iter   637/  823] train: loss: 0.4249324
[Epoch 12; Iter   667/  823] train: loss: 0.1777110
[Epoch 12; Iter   697/  823] train: loss: 0.0224556
[Epoch 12; Iter   727/  823] train: loss: 0.0461163
[Epoch 12; Iter   757/  823] train: loss: 0.0836624
[Epoch 12; Iter   787/  823] train: loss: 0.1230971
[Epoch 12; Iter   817/  823] train: loss: 0.1662000
[Epoch 12] ogbg-molhiv: 0.793751 val loss: 0.140438
[Epoch 12] ogbg-molhiv: 0.772982 test loss: 0.150882
[Epoch 13; Iter    24/  823] train: loss: 0.0491364
[Epoch 13; Iter    54/  823] train: loss: 0.1254585
[Epoch 13; Iter    84/  823] train: loss: 0.0466239
[Epoch 13; Iter   114/  823] train: loss: 0.1226570
[Epoch 13; Iter   144/  823] train: loss: 0.2263988
[Epoch 13; Iter   174/  823] train: loss: 0.0360721
[Epoch 13; Iter   204/  823] train: loss: 0.1153940
[Epoch 13; Iter   234/  823] train: loss: 0.1967909
[Epoch 13; Iter   264/  823] train: loss: 0.3636305
[Epoch 13; Iter   294/  823] train: loss: 0.0583058
[Epoch 13; Iter   324/  823] train: loss: 0.0641864
[Epoch 13; Iter   354/  823] train: loss: 0.1384853
[Epoch 13; Iter   384/  823] train: loss: 0.3119375
[Epoch 13; Iter   414/  823] train: loss: 0.0203283
[Epoch 13; Iter   444/  823] train: loss: 0.0272620
[Epoch 13; Iter   474/  823] train: loss: 0.0400104
[Epoch 13; Iter   504/  823] train: loss: 0.1283173
[Epoch 13; Iter   534/  823] train: loss: 0.1968605
[Epoch 13; Iter   564/  823] train: loss: 0.0316070
[Epoch 13; Iter   594/  823] train: loss: 0.1275972
[Epoch 13; Iter   624/  823] train: loss: 0.0218388
[Epoch 13; Iter   654/  823] train: loss: 0.0237914
[Epoch 13; Iter   684/  823] train: loss: 0.2026383
[Epoch 13; Iter   714/  823] train: loss: 0.1102587
[Epoch 13; Iter   744/  823] train: loss: 0.0500853
[Epoch 13; Iter   774/  823] train: loss: 0.2202742
[Epoch 13; Iter   804/  823] train: loss: 0.0294009
[Epoch 13] ogbg-molhiv: 0.794069 val loss: 0.527648
[Epoch 13] ogbg-molhiv: 0.785836 test loss: 0.596930
[Epoch 14; Iter    11/  823] train: loss: 0.1594463
[Epoch 14; Iter    41/  823] train: loss: 0.0884454
[Epoch 14; Iter    71/  823] train: loss: 0.1174244
[Epoch 14; Iter   101/  823] train: loss: 0.0311722
[Epoch 14; Iter   131/  823] train: loss: 0.0523096
[Epoch 14; Iter   161/  823] train: loss: 0.1219338
[Epoch 14; Iter   191/  823] train: loss: 0.2746371
[Epoch 14; Iter   221/  823] train: loss: 0.0346393
[Epoch 14; Iter   251/  823] train: loss: 0.0835653
[Epoch 14; Iter   281/  823] train: loss: 0.1692456
[Epoch 14; Iter   311/  823] train: loss: 0.4123776
[Epoch 14; Iter   341/  823] train: loss: 0.0327870
[Epoch 14; Iter   371/  823] train: loss: 0.0516557
[Epoch 14; Iter   401/  823] train: loss: 0.1552755
[Epoch 14; Iter   431/  823] train: loss: 0.0278837
[Epoch 14; Iter   461/  823] train: loss: 0.0233477
[Epoch 14; Iter   491/  823] train: loss: 0.0265584
[Epoch 14; Iter   521/  823] train: loss: 0.0842204
[Epoch 14; Iter   551/  823] train: loss: 0.3241570
[Epoch 14; Iter   581/  823] train: loss: 0.2511540
[Epoch 14; Iter   611/  823] train: loss: 0.0651544
[Epoch 14; Iter   641/  823] train: loss: 0.0833627
[Epoch 14; Iter   671/  823] train: loss: 0.0445876
[Epoch 14; Iter   701/  823] train: loss: 0.0750283
[Epoch 14; Iter   731/  823] train: loss: 0.1481117
[Epoch 14; Iter   761/  823] train: loss: 0.1845073
[Epoch 14; Iter   791/  823] train: loss: 0.0323626
[Epoch 14; Iter   821/  823] train: loss: 0.1559949
[Epoch 14] ogbg-molhiv: 0.800902 val loss: 0.179422
[Epoch 14] ogbg-molhiv: 0.787108 test loss: 0.206604
[Epoch 15; Iter    28/  823] train: loss: 0.0352783
[Epoch 15; Iter    58/  823] train: loss: 0.1939696
[Epoch 15; Iter    88/  823] train: loss: 0.0284208
[Epoch 15; Iter   118/  823] train: loss: 0.0213617
[Epoch 15; Iter   148/  823] train: loss: 0.0350145
[Epoch 15; Iter   178/  823] train: loss: 0.1139988
[Epoch 15; Iter   208/  823] train: loss: 0.2075580
[Epoch 15; Iter   238/  823] train: loss: 0.1942547
[Epoch 15; Iter   268/  823] train: loss: 0.1169982
[Epoch 15; Iter   298/  823] train: loss: 0.1383027
[Epoch 15; Iter   328/  823] train: loss: 0.0987991
[Epoch 15; Iter   358/  823] train: loss: 0.3563665
[Epoch 15; Iter   388/  823] train: loss: 0.0398595
[Epoch 15; Iter   418/  823] train: loss: 0.0229596
[Epoch 15; Iter   448/  823] train: loss: 0.3240534
[Epoch 12; Iter   143/ 1097] train: loss: 0.0328471
[Epoch 12; Iter   173/ 1097] train: loss: 0.1922272
[Epoch 12; Iter   203/ 1097] train: loss: 0.0713152
[Epoch 12; Iter   233/ 1097] train: loss: 0.2511099
[Epoch 12; Iter   263/ 1097] train: loss: 0.0297926
[Epoch 12; Iter   293/ 1097] train: loss: 0.0256053
[Epoch 12; Iter   323/ 1097] train: loss: 0.0281128
[Epoch 12; Iter   353/ 1097] train: loss: 0.1947798
[Epoch 12; Iter   383/ 1097] train: loss: 0.1781515
[Epoch 12; Iter   413/ 1097] train: loss: 0.2930219
[Epoch 12; Iter   443/ 1097] train: loss: 0.0275789
[Epoch 12; Iter   473/ 1097] train: loss: 0.2481377
[Epoch 12; Iter   503/ 1097] train: loss: 0.1769789
[Epoch 12; Iter   533/ 1097] train: loss: 0.0618577
[Epoch 12; Iter   563/ 1097] train: loss: 0.1467934
[Epoch 12; Iter   593/ 1097] train: loss: 0.0369878
[Epoch 12; Iter   623/ 1097] train: loss: 0.0220885
[Epoch 12; Iter   653/ 1097] train: loss: 0.0459523
[Epoch 12; Iter   683/ 1097] train: loss: 0.1458336
[Epoch 12; Iter   713/ 1097] train: loss: 0.0787447
[Epoch 12; Iter   743/ 1097] train: loss: 0.0496340
[Epoch 12; Iter   773/ 1097] train: loss: 0.1910163
[Epoch 12; Iter   803/ 1097] train: loss: 0.1062657
[Epoch 12; Iter   833/ 1097] train: loss: 0.0398889
[Epoch 12; Iter   863/ 1097] train: loss: 0.2456171
[Epoch 12; Iter   893/ 1097] train: loss: 0.0443801
[Epoch 12; Iter   923/ 1097] train: loss: 0.0205823
[Epoch 12; Iter   953/ 1097] train: loss: 0.1734586
[Epoch 12; Iter   983/ 1097] train: loss: 0.0443690
[Epoch 12; Iter  1013/ 1097] train: loss: 0.2455200
[Epoch 12; Iter  1043/ 1097] train: loss: 0.1462630
[Epoch 12; Iter  1073/ 1097] train: loss: 0.1282576
[Epoch 12] ogbg-molhiv: 0.788281 val loss: 0.686335
[Epoch 12] ogbg-molhiv: 0.740952 test loss: 0.548206
[Epoch 13; Iter     6/ 1097] train: loss: 0.0252628
[Epoch 13; Iter    36/ 1097] train: loss: 0.4459073
[Epoch 13; Iter    66/ 1097] train: loss: 0.1036690
[Epoch 13; Iter    96/ 1097] train: loss: 0.1508115
[Epoch 13; Iter   126/ 1097] train: loss: 0.0305029
[Epoch 13; Iter   156/ 1097] train: loss: 0.3015029
[Epoch 13; Iter   186/ 1097] train: loss: 0.0294044
[Epoch 13; Iter   216/ 1097] train: loss: 0.0908883
[Epoch 13; Iter   246/ 1097] train: loss: 0.0365334
[Epoch 13; Iter   276/ 1097] train: loss: 0.0351515
[Epoch 13; Iter   306/ 1097] train: loss: 0.0285969
[Epoch 13; Iter   336/ 1097] train: loss: 0.1689175
[Epoch 13; Iter   366/ 1097] train: loss: 0.0328089
[Epoch 13; Iter   396/ 1097] train: loss: 0.0417286
[Epoch 13; Iter   426/ 1097] train: loss: 0.0251129
[Epoch 13; Iter   456/ 1097] train: loss: 0.0318038
[Epoch 13; Iter   486/ 1097] train: loss: 0.1214103
[Epoch 13; Iter   516/ 1097] train: loss: 0.0312921
[Epoch 13; Iter   546/ 1097] train: loss: 0.2230424
[Epoch 13; Iter   576/ 1097] train: loss: 0.2038238
[Epoch 13; Iter   606/ 1097] train: loss: 0.1307849
[Epoch 13; Iter   636/ 1097] train: loss: 0.0299711
[Epoch 13; Iter   666/ 1097] train: loss: 0.3028427
[Epoch 13; Iter   696/ 1097] train: loss: 0.0374267
[Epoch 13; Iter   726/ 1097] train: loss: 0.1721984
[Epoch 13; Iter   756/ 1097] train: loss: 0.1746150
[Epoch 13; Iter   786/ 1097] train: loss: 0.2113296
[Epoch 13; Iter   816/ 1097] train: loss: 0.0491910
[Epoch 13; Iter   846/ 1097] train: loss: 0.0274974
[Epoch 13; Iter   876/ 1097] train: loss: 0.1975328
[Epoch 13; Iter   906/ 1097] train: loss: 0.4210705
[Epoch 13; Iter   936/ 1097] train: loss: 0.2422801
[Epoch 13; Iter   966/ 1097] train: loss: 0.2423766
[Epoch 13; Iter   996/ 1097] train: loss: 0.0411796
[Epoch 13; Iter  1026/ 1097] train: loss: 0.2137581
[Epoch 13; Iter  1056/ 1097] train: loss: 0.1498704
[Epoch 13; Iter  1086/ 1097] train: loss: 0.0916081
[Epoch 13] ogbg-molhiv: 0.767576 val loss: 0.133927
[Epoch 13] ogbg-molhiv: 0.761052 test loss: 0.136035
[Epoch 14; Iter    19/ 1097] train: loss: 0.1911472
[Epoch 14; Iter    49/ 1097] train: loss: 0.0532458
[Epoch 14; Iter    79/ 1097] train: loss: 0.0262509
[Epoch 14; Iter   109/ 1097] train: loss: 0.0567600
[Epoch 14; Iter   139/ 1097] train: loss: 0.0300614
[Epoch 14; Iter   169/ 1097] train: loss: 0.0337373
[Epoch 14; Iter   199/ 1097] train: loss: 0.0577403
[Epoch 14; Iter   229/ 1097] train: loss: 0.2031181
[Epoch 14; Iter   259/ 1097] train: loss: 0.0308582
[Epoch 14; Iter   289/ 1097] train: loss: 0.2123977
[Epoch 14; Iter   319/ 1097] train: loss: 0.0943792
[Epoch 14; Iter   349/ 1097] train: loss: 0.1484352
[Epoch 14; Iter   379/ 1097] train: loss: 0.0857025
[Epoch 14; Iter   409/ 1097] train: loss: 0.2280837
[Epoch 14; Iter   439/ 1097] train: loss: 0.2854241
[Epoch 14; Iter   469/ 1097] train: loss: 0.1355873
[Epoch 14; Iter   499/ 1097] train: loss: 0.1299170
[Epoch 14; Iter   529/ 1097] train: loss: 0.0790993
[Epoch 14; Iter   559/ 1097] train: loss: 0.0304211
[Epoch 14; Iter   589/ 1097] train: loss: 0.1062954
[Epoch 14; Iter   619/ 1097] train: loss: 0.2520756
[Epoch 14; Iter   649/ 1097] train: loss: 0.0528205
[Epoch 14; Iter   679/ 1097] train: loss: 0.1234779
[Epoch 14; Iter   709/ 1097] train: loss: 0.0312315
[Epoch 14; Iter   739/ 1097] train: loss: 0.0611059
[Epoch 14; Iter   769/ 1097] train: loss: 0.0592211
[Epoch 14; Iter   799/ 1097] train: loss: 0.1158216
[Epoch 14; Iter   829/ 1097] train: loss: 0.1188138
[Epoch 14; Iter   859/ 1097] train: loss: 0.1732913
[Epoch 14; Iter   889/ 1097] train: loss: 0.0271074
[Epoch 14; Iter   919/ 1097] train: loss: 0.3406564
[Epoch 14; Iter   949/ 1097] train: loss: 0.0485181
[Epoch 14; Iter   979/ 1097] train: loss: 0.0322805
[Epoch 14; Iter  1009/ 1097] train: loss: 0.0445568
[Epoch 14; Iter  1039/ 1097] train: loss: 0.1898771
[Epoch 14; Iter  1069/ 1097] train: loss: 0.3674454
[Epoch 14] ogbg-molhiv: 0.777594 val loss: 36.582699
[Epoch 14] ogbg-molhiv: 0.761329 test loss: 107.132837
[Epoch 15; Iter     2/ 1097] train: loss: 0.0302112
[Epoch 15; Iter    32/ 1097] train: loss: 0.0299032
[Epoch 15; Iter    62/ 1097] train: loss: 0.0800537
[Epoch 15; Iter    92/ 1097] train: loss: 0.0514157
[Epoch 15; Iter   122/ 1097] train: loss: 0.0568417
[Epoch 15; Iter   152/ 1097] train: loss: 0.1622205
[Epoch 15; Iter   182/ 1097] train: loss: 0.1667494
[Epoch 15; Iter   212/ 1097] train: loss: 0.1130928
[Epoch 15; Iter   242/ 1097] train: loss: 0.1865556
[Epoch 15; Iter   272/ 1097] train: loss: 0.1495533
[Epoch 15; Iter   302/ 1097] train: loss: 0.0402422
[Epoch 15; Iter   332/ 1097] train: loss: 0.0334681
[Epoch 15; Iter   362/ 1097] train: loss: 0.1015261
[Epoch 15; Iter   392/ 1097] train: loss: 0.0346608
[Epoch 15; Iter   422/ 1097] train: loss: 0.1613540
[Epoch 15; Iter   452/ 1097] train: loss: 0.0572047
[Epoch 15; Iter   482/ 1097] train: loss: 0.0303207
[Epoch 15; Iter   512/ 1097] train: loss: 0.1053061
[Epoch 15; Iter   542/ 1097] train: loss: 0.3402148
[Epoch 15; Iter   572/ 1097] train: loss: 0.1975847
[Epoch 15; Iter   602/ 1097] train: loss: 0.0855820
[Epoch 15; Iter   632/ 1097] train: loss: 0.0686382
[Epoch 15; Iter   662/ 1097] train: loss: 0.0279756
[Epoch 15; Iter   692/ 1097] train: loss: 0.0798972
[Epoch 15; Iter   722/ 1097] train: loss: 0.1815582
[Epoch 15; Iter   752/ 1097] train: loss: 0.0290887
[Epoch 15; Iter   782/ 1097] train: loss: 0.0283625
[Epoch 15; Iter   812/ 1097] train: loss: 0.0867904
[Epoch 15; Iter   842/ 1097] train: loss: 0.0238558
[Epoch 15; Iter   872/ 1097] train: loss: 0.0339797
[Epoch 15; Iter   902/ 1097] train: loss: 0.1216682
[Epoch 15; Iter   932/ 1097] train: loss: 0.2466649
[Epoch 15; Iter   962/ 1097] train: loss: 0.1358554
[Epoch 15; Iter   992/ 1097] train: loss: 0.0528668
[Epoch 15; Iter  1022/ 1097] train: loss: 0.0296633
[Epoch 15; Iter  1052/ 1097] train: loss: 0.0402749
[Epoch 15; Iter  1082/ 1097] train: loss: 0.1555190
[Epoch 15] ogbg-molhiv: 0.787478 val loss: 0.695368
[Epoch 15] ogbg-molhiv: 0.755603 test loss: 1.119155
[Epoch 16; Iter    15/ 1097] train: loss: 0.0416730
[Epoch 16; Iter    45/ 1097] train: loss: 0.0637027
[Epoch 16; Iter    75/ 1097] train: loss: 0.1867551
[Epoch 16; Iter   105/ 1097] train: loss: 0.1125834
[Epoch 16; Iter   135/ 1097] train: loss: 0.0696414
[Epoch 16; Iter   165/ 1097] train: loss: 0.0530047
[Epoch 16; Iter   195/ 1097] train: loss: 0.1301251
[Epoch 12; Iter   143/ 1097] train: loss: 0.0239985
[Epoch 12; Iter   173/ 1097] train: loss: 0.0168794
[Epoch 12; Iter   203/ 1097] train: loss: 0.0338434
[Epoch 12; Iter   233/ 1097] train: loss: 0.2514845
[Epoch 12; Iter   263/ 1097] train: loss: 0.1914100
[Epoch 12; Iter   293/ 1097] train: loss: 0.1956768
[Epoch 12; Iter   323/ 1097] train: loss: 0.0359104
[Epoch 12; Iter   353/ 1097] train: loss: 0.0352861
[Epoch 12; Iter   383/ 1097] train: loss: 0.1031622
[Epoch 12; Iter   413/ 1097] train: loss: 0.1746463
[Epoch 12; Iter   443/ 1097] train: loss: 0.1887465
[Epoch 12; Iter   473/ 1097] train: loss: 0.0322940
[Epoch 12; Iter   503/ 1097] train: loss: 0.1371782
[Epoch 12; Iter   533/ 1097] train: loss: 0.1335025
[Epoch 12; Iter   563/ 1097] train: loss: 0.0738644
[Epoch 12; Iter   593/ 1097] train: loss: 0.1848357
[Epoch 12; Iter   623/ 1097] train: loss: 0.1364000
[Epoch 12; Iter   653/ 1097] train: loss: 0.0471027
[Epoch 12; Iter   683/ 1097] train: loss: 0.1797969
[Epoch 12; Iter   713/ 1097] train: loss: 0.0634964
[Epoch 12; Iter   743/ 1097] train: loss: 0.1745210
[Epoch 12; Iter   773/ 1097] train: loss: 0.1563624
[Epoch 12; Iter   803/ 1097] train: loss: 0.1563367
[Epoch 12; Iter   833/ 1097] train: loss: 0.0401247
[Epoch 12; Iter   863/ 1097] train: loss: 0.1668000
[Epoch 12; Iter   893/ 1097] train: loss: 0.0353013
[Epoch 12; Iter   923/ 1097] train: loss: 0.0268380
[Epoch 12; Iter   953/ 1097] train: loss: 0.0269254
[Epoch 12; Iter   983/ 1097] train: loss: 0.0497174
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0218414
[Epoch 12; Iter  1043/ 1097] train: loss: 0.0194315
[Epoch 12; Iter  1073/ 1097] train: loss: 0.0183224
[Epoch 12] ogbg-molhiv: 0.781505 val loss: 0.123855
[Epoch 12] ogbg-molhiv: 0.775497 test loss: 0.119044
[Epoch 13; Iter     6/ 1097] train: loss: 0.0228857
[Epoch 13; Iter    36/ 1097] train: loss: 0.0264169
[Epoch 13; Iter    66/ 1097] train: loss: 0.2638585
[Epoch 13; Iter    96/ 1097] train: loss: 0.2300553
[Epoch 13; Iter   126/ 1097] train: loss: 0.0865615
[Epoch 13; Iter   156/ 1097] train: loss: 0.0301694
[Epoch 13; Iter   186/ 1097] train: loss: 0.0193357
[Epoch 13; Iter   216/ 1097] train: loss: 0.0200966
[Epoch 13; Iter   246/ 1097] train: loss: 0.0304886
[Epoch 13; Iter   276/ 1097] train: loss: 0.1302985
[Epoch 13; Iter   306/ 1097] train: loss: 0.0423986
[Epoch 13; Iter   336/ 1097] train: loss: 0.0942051
[Epoch 13; Iter   366/ 1097] train: loss: 0.1431644
[Epoch 13; Iter   396/ 1097] train: loss: 0.0270182
[Epoch 13; Iter   426/ 1097] train: loss: 0.4887284
[Epoch 13; Iter   456/ 1097] train: loss: 0.1684621
[Epoch 13; Iter   486/ 1097] train: loss: 0.0199534
[Epoch 13; Iter   516/ 1097] train: loss: 0.0212367
[Epoch 13; Iter   546/ 1097] train: loss: 0.1545503
[Epoch 13; Iter   576/ 1097] train: loss: 0.0281572
[Epoch 13; Iter   606/ 1097] train: loss: 0.1784999
[Epoch 13; Iter   636/ 1097] train: loss: 0.2155628
[Epoch 13; Iter   666/ 1097] train: loss: 0.0260959
[Epoch 13; Iter   696/ 1097] train: loss: 0.0410258
[Epoch 13; Iter   726/ 1097] train: loss: 0.2625422
[Epoch 13; Iter   756/ 1097] train: loss: 0.1589286
[Epoch 13; Iter   786/ 1097] train: loss: 0.0331325
[Epoch 13; Iter   816/ 1097] train: loss: 0.1130276
[Epoch 13; Iter   846/ 1097] train: loss: 0.2351711
[Epoch 13; Iter   876/ 1097] train: loss: 0.0692828
[Epoch 13; Iter   906/ 1097] train: loss: 0.1804940
[Epoch 13; Iter   936/ 1097] train: loss: 0.0223402
[Epoch 13; Iter   966/ 1097] train: loss: 0.0849076
[Epoch 13; Iter   996/ 1097] train: loss: 0.3313931
[Epoch 13; Iter  1026/ 1097] train: loss: 0.1970831
[Epoch 13; Iter  1056/ 1097] train: loss: 0.1309343
[Epoch 13; Iter  1086/ 1097] train: loss: 0.0439591
[Epoch 13] ogbg-molhiv: 0.766951 val loss: 0.123205
[Epoch 13] ogbg-molhiv: 0.783346 test loss: 0.118845
[Epoch 14; Iter    19/ 1097] train: loss: 0.0322490
[Epoch 14; Iter    49/ 1097] train: loss: 0.0705606
[Epoch 14; Iter    79/ 1097] train: loss: 0.2181810
[Epoch 14; Iter   109/ 1097] train: loss: 0.1582959
[Epoch 14; Iter   139/ 1097] train: loss: 0.2446284
[Epoch 14; Iter   169/ 1097] train: loss: 0.3300415
[Epoch 14; Iter   199/ 1097] train: loss: 0.0610917
[Epoch 14; Iter   229/ 1097] train: loss: 0.2723739
[Epoch 14; Iter   259/ 1097] train: loss: 0.1880366
[Epoch 14; Iter   289/ 1097] train: loss: 0.0284160
[Epoch 14; Iter   319/ 1097] train: loss: 0.0259560
[Epoch 14; Iter   349/ 1097] train: loss: 0.0164096
[Epoch 14; Iter   379/ 1097] train: loss: 0.0550641
[Epoch 14; Iter   409/ 1097] train: loss: 0.1542292
[Epoch 14; Iter   439/ 1097] train: loss: 0.0517343
[Epoch 14; Iter   469/ 1097] train: loss: 0.2400286
[Epoch 14; Iter   499/ 1097] train: loss: 0.0808209
[Epoch 14; Iter   529/ 1097] train: loss: 0.0298920
[Epoch 14; Iter   559/ 1097] train: loss: 0.2353640
[Epoch 14; Iter   589/ 1097] train: loss: 0.2144464
[Epoch 14; Iter   619/ 1097] train: loss: 0.0181586
[Epoch 14; Iter   649/ 1097] train: loss: 0.0178344
[Epoch 14; Iter   679/ 1097] train: loss: 0.0210172
[Epoch 14; Iter   709/ 1097] train: loss: 0.3027088
[Epoch 14; Iter   739/ 1097] train: loss: 0.2733695
[Epoch 14; Iter   769/ 1097] train: loss: 0.3243785
[Epoch 14; Iter   799/ 1097] train: loss: 0.2823569
[Epoch 14; Iter   829/ 1097] train: loss: 0.0766601
[Epoch 14; Iter   859/ 1097] train: loss: 0.0889532
[Epoch 14; Iter   889/ 1097] train: loss: 0.0406476
[Epoch 14; Iter   919/ 1097] train: loss: 0.3317536
[Epoch 14; Iter   949/ 1097] train: loss: 0.0294670
[Epoch 14; Iter   979/ 1097] train: loss: 0.1494289
[Epoch 14; Iter  1009/ 1097] train: loss: 0.0330266
[Epoch 14; Iter  1039/ 1097] train: loss: 0.1203873
[Epoch 14; Iter  1069/ 1097] train: loss: 0.0365454
[Epoch 14] ogbg-molhiv: 0.792442 val loss: 0.306852
[Epoch 14] ogbg-molhiv: 0.805343 test loss: 0.128885
[Epoch 15; Iter     2/ 1097] train: loss: 0.1434397
[Epoch 15; Iter    32/ 1097] train: loss: 0.0261476
[Epoch 15; Iter    62/ 1097] train: loss: 0.0472052
[Epoch 15; Iter    92/ 1097] train: loss: 0.2076013
[Epoch 15; Iter   122/ 1097] train: loss: 0.0241651
[Epoch 15; Iter   152/ 1097] train: loss: 0.0279602
[Epoch 15; Iter   182/ 1097] train: loss: 0.1688212
[Epoch 15; Iter   212/ 1097] train: loss: 0.0198166
[Epoch 15; Iter   242/ 1097] train: loss: 0.0191844
[Epoch 15; Iter   272/ 1097] train: loss: 0.0204264
[Epoch 15; Iter   302/ 1097] train: loss: 0.0239191
[Epoch 15; Iter   332/ 1097] train: loss: 0.0234958
[Epoch 15; Iter   362/ 1097] train: loss: 0.1465928
[Epoch 15; Iter   392/ 1097] train: loss: 0.0401741
[Epoch 15; Iter   422/ 1097] train: loss: 0.3477701
[Epoch 15; Iter   452/ 1097] train: loss: 0.0399592
[Epoch 15; Iter   482/ 1097] train: loss: 0.0229507
[Epoch 15; Iter   512/ 1097] train: loss: 0.3004822
[Epoch 15; Iter   542/ 1097] train: loss: 0.0342693
[Epoch 15; Iter   572/ 1097] train: loss: 0.0437515
[Epoch 15; Iter   602/ 1097] train: loss: 0.0238151
[Epoch 15; Iter   632/ 1097] train: loss: 0.1481104
[Epoch 15; Iter   662/ 1097] train: loss: 0.0642222
[Epoch 15; Iter   692/ 1097] train: loss: 0.3437485
[Epoch 15; Iter   722/ 1097] train: loss: 0.2529501
[Epoch 15; Iter   752/ 1097] train: loss: 0.2767135
[Epoch 15; Iter   782/ 1097] train: loss: 0.0930442
[Epoch 15; Iter   812/ 1097] train: loss: 0.1132073
[Epoch 15; Iter   842/ 1097] train: loss: 0.3267707
[Epoch 15; Iter   872/ 1097] train: loss: 0.1180391
[Epoch 15; Iter   902/ 1097] train: loss: 0.2844965
[Epoch 15; Iter   932/ 1097] train: loss: 0.0338205
[Epoch 15; Iter   962/ 1097] train: loss: 0.4380996
[Epoch 15; Iter   992/ 1097] train: loss: 0.0529803
[Epoch 15; Iter  1022/ 1097] train: loss: 0.1873860
[Epoch 15; Iter  1052/ 1097] train: loss: 0.0164614
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0194020
[Epoch 15] ogbg-molhiv: 0.767195 val loss: 0.128062
[Epoch 15] ogbg-molhiv: 0.794683 test loss: 0.113624
[Epoch 16; Iter    15/ 1097] train: loss: 0.0353835
[Epoch 16; Iter    45/ 1097] train: loss: 0.1341358
[Epoch 16; Iter    75/ 1097] train: loss: 0.1852257
[Epoch 16; Iter   105/ 1097] train: loss: 0.1883710
[Epoch 16; Iter   135/ 1097] train: loss: 0.1849028
[Epoch 16; Iter   165/ 1097] train: loss: 0.0563532
[Epoch 16; Iter   195/ 1097] train: loss: 0.0198147
[Epoch 12; Iter   143/ 1097] train: loss: 0.2541718
[Epoch 12; Iter   173/ 1097] train: loss: 0.0808549
[Epoch 12; Iter   203/ 1097] train: loss: 0.1451671
[Epoch 12; Iter   233/ 1097] train: loss: 0.0249230
[Epoch 12; Iter   263/ 1097] train: loss: 0.1253418
[Epoch 12; Iter   293/ 1097] train: loss: 0.1570537
[Epoch 12; Iter   323/ 1097] train: loss: 0.0564018
[Epoch 12; Iter   353/ 1097] train: loss: 0.2220452
[Epoch 12; Iter   383/ 1097] train: loss: 0.0642415
[Epoch 12; Iter   413/ 1097] train: loss: 0.1903820
[Epoch 12; Iter   443/ 1097] train: loss: 0.1979769
[Epoch 12; Iter   473/ 1097] train: loss: 0.0634611
[Epoch 12; Iter   503/ 1097] train: loss: 0.2212341
[Epoch 12; Iter   533/ 1097] train: loss: 0.0344959
[Epoch 12; Iter   563/ 1097] train: loss: 0.1082617
[Epoch 12; Iter   593/ 1097] train: loss: 0.0867381
[Epoch 12; Iter   623/ 1097] train: loss: 0.0274481
[Epoch 12; Iter   653/ 1097] train: loss: 0.0201144
[Epoch 12; Iter   683/ 1097] train: loss: 0.0368824
[Epoch 12; Iter   713/ 1097] train: loss: 0.0208579
[Epoch 12; Iter   743/ 1097] train: loss: 0.0305693
[Epoch 12; Iter   773/ 1097] train: loss: 0.0311960
[Epoch 12; Iter   803/ 1097] train: loss: 0.1650265
[Epoch 12; Iter   833/ 1097] train: loss: 0.3042426
[Epoch 12; Iter   863/ 1097] train: loss: 0.1710895
[Epoch 12; Iter   893/ 1097] train: loss: 0.1870338
[Epoch 12; Iter   923/ 1097] train: loss: 0.0438967
[Epoch 12; Iter   953/ 1097] train: loss: 0.3310180
[Epoch 12; Iter   983/ 1097] train: loss: 0.2449250
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0243615
[Epoch 12; Iter  1043/ 1097] train: loss: 0.0785576
[Epoch 12; Iter  1073/ 1097] train: loss: 0.0328315
[Epoch 12] ogbg-molhiv: 0.787947 val loss: 0.266167
[Epoch 12] ogbg-molhiv: 0.788631 test loss: 0.457871
[Epoch 13; Iter     6/ 1097] train: loss: 0.0452421
[Epoch 13; Iter    36/ 1097] train: loss: 0.0244338
[Epoch 13; Iter    66/ 1097] train: loss: 0.0163312
[Epoch 13; Iter    96/ 1097] train: loss: 0.0335419
[Epoch 13; Iter   126/ 1097] train: loss: 0.0388558
[Epoch 13; Iter   156/ 1097] train: loss: 0.1155082
[Epoch 13; Iter   186/ 1097] train: loss: 0.0808896
[Epoch 13; Iter   216/ 1097] train: loss: 0.1639606
[Epoch 13; Iter   246/ 1097] train: loss: 0.2877875
[Epoch 13; Iter   276/ 1097] train: loss: 0.1735982
[Epoch 13; Iter   306/ 1097] train: loss: 0.1244007
[Epoch 13; Iter   336/ 1097] train: loss: 0.0606871
[Epoch 13; Iter   366/ 1097] train: loss: 0.0579617
[Epoch 13; Iter   396/ 1097] train: loss: 0.1712382
[Epoch 13; Iter   426/ 1097] train: loss: 0.0207303
[Epoch 13; Iter   456/ 1097] train: loss: 0.0615101
[Epoch 13; Iter   486/ 1097] train: loss: 0.1881601
[Epoch 13; Iter   516/ 1097] train: loss: 0.0939907
[Epoch 13; Iter   546/ 1097] train: loss: 0.0310577
[Epoch 13; Iter   576/ 1097] train: loss: 0.0278533
[Epoch 13; Iter   606/ 1097] train: loss: 0.0174863
[Epoch 13; Iter   636/ 1097] train: loss: 0.0371427
[Epoch 13; Iter   666/ 1097] train: loss: 0.1732365
[Epoch 13; Iter   696/ 1097] train: loss: 0.0332896
[Epoch 13; Iter   726/ 1097] train: loss: 0.2455762
[Epoch 13; Iter   756/ 1097] train: loss: 0.2164602
[Epoch 13; Iter   786/ 1097] train: loss: 0.1936917
[Epoch 13; Iter   816/ 1097] train: loss: 0.0469439
[Epoch 13; Iter   846/ 1097] train: loss: 0.0218838
[Epoch 13; Iter   876/ 1097] train: loss: 0.2593373
[Epoch 13; Iter   906/ 1097] train: loss: 0.0216152
[Epoch 13; Iter   936/ 1097] train: loss: 0.2360118
[Epoch 13; Iter   966/ 1097] train: loss: 0.1066726
[Epoch 13; Iter   996/ 1097] train: loss: 0.4310893
[Epoch 13; Iter  1026/ 1097] train: loss: 0.0253678
[Epoch 13; Iter  1056/ 1097] train: loss: 0.2804829
[Epoch 13; Iter  1086/ 1097] train: loss: 0.0205866
[Epoch 13] ogbg-molhiv: 0.782274 val loss: 0.270025
[Epoch 13] ogbg-molhiv: 0.798771 test loss: 0.169639
[Epoch 14; Iter    19/ 1097] train: loss: 0.0943526
[Epoch 14; Iter    49/ 1097] train: loss: 0.0397954
[Epoch 14; Iter    79/ 1097] train: loss: 0.0617924
[Epoch 14; Iter   109/ 1097] train: loss: 0.2605695
[Epoch 14; Iter   139/ 1097] train: loss: 0.0396382
[Epoch 14; Iter   169/ 1097] train: loss: 0.2377732
[Epoch 14; Iter   199/ 1097] train: loss: 0.0244463
[Epoch 14; Iter   229/ 1097] train: loss: 0.1915235
[Epoch 14; Iter   259/ 1097] train: loss: 0.1111759
[Epoch 14; Iter   289/ 1097] train: loss: 0.0222399
[Epoch 14; Iter   319/ 1097] train: loss: 0.1838035
[Epoch 14; Iter   349/ 1097] train: loss: 0.0283133
[Epoch 14; Iter   379/ 1097] train: loss: 0.1043616
[Epoch 14; Iter   409/ 1097] train: loss: 0.0339486
[Epoch 14; Iter   439/ 1097] train: loss: 0.0184082
[Epoch 14; Iter   469/ 1097] train: loss: 0.0379878
[Epoch 14; Iter   499/ 1097] train: loss: 0.1383837
[Epoch 14; Iter   529/ 1097] train: loss: 0.1888388
[Epoch 14; Iter   559/ 1097] train: loss: 0.0341573
[Epoch 14; Iter   589/ 1097] train: loss: 0.0382437
[Epoch 14; Iter   619/ 1097] train: loss: 0.1544914
[Epoch 14; Iter   649/ 1097] train: loss: 0.0233554
[Epoch 14; Iter   679/ 1097] train: loss: 0.0319535
[Epoch 14; Iter   709/ 1097] train: loss: 0.0841316
[Epoch 14; Iter   739/ 1097] train: loss: 0.0187017
[Epoch 14; Iter   769/ 1097] train: loss: 0.0423791
[Epoch 14; Iter   799/ 1097] train: loss: 0.1561619
[Epoch 14; Iter   829/ 1097] train: loss: 0.2063683
[Epoch 14; Iter   859/ 1097] train: loss: 0.0453361
[Epoch 14; Iter   889/ 1097] train: loss: 0.0849077
[Epoch 14; Iter   919/ 1097] train: loss: 0.1541243
[Epoch 14; Iter   949/ 1097] train: loss: 0.0314706
[Epoch 14; Iter   979/ 1097] train: loss: 0.2670314
[Epoch 14; Iter  1009/ 1097] train: loss: 0.2039039
[Epoch 14; Iter  1039/ 1097] train: loss: 0.0192314
[Epoch 14; Iter  1069/ 1097] train: loss: 0.1731189
[Epoch 14] ogbg-molhiv: 0.796164 val loss: 0.117064
[Epoch 14] ogbg-molhiv: 0.798570 test loss: 0.121579
[Epoch 15; Iter     2/ 1097] train: loss: 0.0643630
[Epoch 15; Iter    32/ 1097] train: loss: 0.0694515
[Epoch 15; Iter    62/ 1097] train: loss: 0.1521859
[Epoch 15; Iter    92/ 1097] train: loss: 0.2064155
[Epoch 15; Iter   122/ 1097] train: loss: 0.1930256
[Epoch 15; Iter   152/ 1097] train: loss: 0.0442005
[Epoch 15; Iter   182/ 1097] train: loss: 0.0648845
[Epoch 15; Iter   212/ 1097] train: loss: 0.1082126
[Epoch 15; Iter   242/ 1097] train: loss: 0.1487577
[Epoch 15; Iter   272/ 1097] train: loss: 0.2313962
[Epoch 15; Iter   302/ 1097] train: loss: 0.0201323
[Epoch 15; Iter   332/ 1097] train: loss: 0.0211361
[Epoch 15; Iter   362/ 1097] train: loss: 0.1541742
[Epoch 15; Iter   392/ 1097] train: loss: 0.0700798
[Epoch 15; Iter   422/ 1097] train: loss: 0.0576000
[Epoch 15; Iter   452/ 1097] train: loss: 0.1892046
[Epoch 15; Iter   482/ 1097] train: loss: 0.0347773
[Epoch 15; Iter   512/ 1097] train: loss: 0.0301548
[Epoch 15; Iter   542/ 1097] train: loss: 0.0187410
[Epoch 15; Iter   572/ 1097] train: loss: 0.0200736
[Epoch 15; Iter   602/ 1097] train: loss: 0.1031377
[Epoch 15; Iter   632/ 1097] train: loss: 0.0259813
[Epoch 15; Iter   662/ 1097] train: loss: 0.0325404
[Epoch 15; Iter   692/ 1097] train: loss: 0.0324005
[Epoch 15; Iter   722/ 1097] train: loss: 0.0236800
[Epoch 15; Iter   752/ 1097] train: loss: 0.0874554
[Epoch 15; Iter   782/ 1097] train: loss: 0.1179652
[Epoch 15; Iter   812/ 1097] train: loss: 0.0231509
[Epoch 15; Iter   842/ 1097] train: loss: 0.0219365
[Epoch 15; Iter   872/ 1097] train: loss: 0.1584405
[Epoch 15; Iter   902/ 1097] train: loss: 0.1428052
[Epoch 15; Iter   932/ 1097] train: loss: 0.0512224
[Epoch 15; Iter   962/ 1097] train: loss: 0.1168423
[Epoch 15; Iter   992/ 1097] train: loss: 0.0267494
[Epoch 15; Iter  1022/ 1097] train: loss: 0.0326400
[Epoch 15; Iter  1052/ 1097] train: loss: 0.2514453
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0253497
[Epoch 15] ogbg-molhiv: 0.813636 val loss: 0.125377
[Epoch 15] ogbg-molhiv: 0.797913 test loss: 0.120763
[Epoch 16; Iter    15/ 1097] train: loss: 0.2022933
[Epoch 16; Iter    45/ 1097] train: loss: 0.1347548
[Epoch 16; Iter    75/ 1097] train: loss: 0.0192779
[Epoch 16; Iter   105/ 1097] train: loss: 0.0391183
[Epoch 16; Iter   135/ 1097] train: loss: 0.1605808
[Epoch 16; Iter   165/ 1097] train: loss: 0.0235710
[Epoch 16; Iter   195/ 1097] train: loss: 0.0219956
[Epoch 13; Iter   630/  960] train: loss: 0.4571061
[Epoch 13; Iter   660/  960] train: loss: 0.0420933
[Epoch 13; Iter   690/  960] train: loss: 0.0183228
[Epoch 13; Iter   720/  960] train: loss: 0.0288085
[Epoch 13; Iter   750/  960] train: loss: 0.0246296
[Epoch 13; Iter   780/  960] train: loss: 0.1153048
[Epoch 13; Iter   810/  960] train: loss: 0.1134252
[Epoch 13; Iter   840/  960] train: loss: 0.2043098
[Epoch 13; Iter   870/  960] train: loss: 0.0280224
[Epoch 13; Iter   900/  960] train: loss: 0.0216352
[Epoch 13; Iter   930/  960] train: loss: 0.1387062
[Epoch 13; Iter   960/  960] train: loss: 0.3081520
[Epoch 13] ogbg-molhiv: 0.795586 val loss: 0.237888
[Epoch 13] ogbg-molhiv: 0.799990 test loss: 0.160724
[Epoch 14; Iter    30/  960] train: loss: 0.1549421
[Epoch 14; Iter    60/  960] train: loss: 0.0258963
[Epoch 14; Iter    90/  960] train: loss: 0.0279880
[Epoch 14; Iter   120/  960] train: loss: 0.0234238
[Epoch 14; Iter   150/  960] train: loss: 0.0243805
[Epoch 14; Iter   180/  960] train: loss: 0.1481896
[Epoch 14; Iter   210/  960] train: loss: 0.0277324
[Epoch 14; Iter   240/  960] train: loss: 0.1015081
[Epoch 14; Iter   270/  960] train: loss: 0.2379037
[Epoch 14; Iter   300/  960] train: loss: 0.1633745
[Epoch 14; Iter   330/  960] train: loss: 0.0277647
[Epoch 14; Iter   360/  960] train: loss: 0.0281691
[Epoch 14; Iter   390/  960] train: loss: 0.1437332
[Epoch 14; Iter   420/  960] train: loss: 0.1705684
[Epoch 14; Iter   450/  960] train: loss: 0.1926723
[Epoch 14; Iter   480/  960] train: loss: 0.1307216
[Epoch 14; Iter   510/  960] train: loss: 0.0277552
[Epoch 14; Iter   540/  960] train: loss: 0.0225875
[Epoch 14; Iter   570/  960] train: loss: 0.1517168
[Epoch 14; Iter   600/  960] train: loss: 0.0832749
[Epoch 14; Iter   630/  960] train: loss: 0.0831832
[Epoch 14; Iter   660/  960] train: loss: 0.0467800
[Epoch 14; Iter   690/  960] train: loss: 0.0403369
[Epoch 14; Iter   720/  960] train: loss: 0.2525091
[Epoch 14; Iter   750/  960] train: loss: 0.0349306
[Epoch 14; Iter   780/  960] train: loss: 0.1330217
[Epoch 14; Iter   810/  960] train: loss: 0.0318931
[Epoch 14; Iter   840/  960] train: loss: 0.4483410
[Epoch 14; Iter   870/  960] train: loss: 0.0752339
[Epoch 14; Iter   900/  960] train: loss: 0.0181776
[Epoch 14; Iter   930/  960] train: loss: 0.0430134
[Epoch 14; Iter   960/  960] train: loss: 0.0199542
[Epoch 14] ogbg-molhiv: 0.790792 val loss: 0.239490
[Epoch 14] ogbg-molhiv: 0.816274 test loss: 0.145306
[Epoch 15; Iter    30/  960] train: loss: 0.0234566
[Epoch 15; Iter    60/  960] train: loss: 0.1695270
[Epoch 15; Iter    90/  960] train: loss: 0.0945314
[Epoch 15; Iter   120/  960] train: loss: 0.0780408
[Epoch 15; Iter   150/  960] train: loss: 0.0255682
[Epoch 15; Iter   180/  960] train: loss: 0.1875052
[Epoch 15; Iter   210/  960] train: loss: 0.0303354
[Epoch 15; Iter   240/  960] train: loss: 0.0168238
[Epoch 15; Iter   270/  960] train: loss: 0.2873368
[Epoch 15; Iter   300/  960] train: loss: 0.0224975
[Epoch 15; Iter   330/  960] train: loss: 0.0320736
[Epoch 15; Iter   360/  960] train: loss: 0.0189359
[Epoch 15; Iter   390/  960] train: loss: 0.0527731
[Epoch 15; Iter   420/  960] train: loss: 0.0204903
[Epoch 15; Iter   450/  960] train: loss: 0.0301416
[Epoch 15; Iter   480/  960] train: loss: 0.0270464
[Epoch 15; Iter   510/  960] train: loss: 0.1594586
[Epoch 15; Iter   540/  960] train: loss: 0.0256579
[Epoch 15; Iter   570/  960] train: loss: 0.0244824
[Epoch 15; Iter   600/  960] train: loss: 0.1984723
[Epoch 15; Iter   630/  960] train: loss: 0.2444117
[Epoch 15; Iter   660/  960] train: loss: 0.0361732
[Epoch 15; Iter   690/  960] train: loss: 0.0294950
[Epoch 15; Iter   720/  960] train: loss: 0.0738385
[Epoch 15; Iter   750/  960] train: loss: 0.0447035
[Epoch 15; Iter   780/  960] train: loss: 0.0252590
[Epoch 15; Iter   810/  960] train: loss: 0.0227618
[Epoch 15; Iter   840/  960] train: loss: 0.1657661
[Epoch 15; Iter   870/  960] train: loss: 0.0348661
[Epoch 15; Iter   900/  960] train: loss: 0.0284273
[Epoch 15; Iter   930/  960] train: loss: 0.1739550
[Epoch 15; Iter   960/  960] train: loss: 0.2565929
[Epoch 15] ogbg-molhiv: 0.804463 val loss: 0.121841
[Epoch 15] ogbg-molhiv: 0.815486 test loss: 0.113978
[Epoch 16; Iter    30/  960] train: loss: 0.0168714
[Epoch 16; Iter    60/  960] train: loss: 0.0371073
[Epoch 16; Iter    90/  960] train: loss: 0.2380586
[Epoch 16; Iter   120/  960] train: loss: 0.0421928
[Epoch 16; Iter   150/  960] train: loss: 0.1638952
[Epoch 16; Iter   180/  960] train: loss: 0.0241938
[Epoch 16; Iter   210/  960] train: loss: 0.0232658
[Epoch 16; Iter   240/  960] train: loss: 0.0311625
[Epoch 16; Iter   270/  960] train: loss: 0.0385730
[Epoch 16; Iter   300/  960] train: loss: 0.2290529
[Epoch 16; Iter   330/  960] train: loss: 0.0331157
[Epoch 16; Iter   360/  960] train: loss: 0.0440957
[Epoch 16; Iter   390/  960] train: loss: 0.0309923
[Epoch 16; Iter   420/  960] train: loss: 0.1194476
[Epoch 16; Iter   450/  960] train: loss: 0.0725618
[Epoch 16; Iter   480/  960] train: loss: 0.0205024
[Epoch 16; Iter   510/  960] train: loss: 0.0681089
[Epoch 16; Iter   540/  960] train: loss: 0.0185439
[Epoch 16; Iter   570/  960] train: loss: 0.0282544
[Epoch 16; Iter   600/  960] train: loss: 0.0252536
[Epoch 16; Iter   630/  960] train: loss: 0.0186426
[Epoch 16; Iter   660/  960] train: loss: 0.4289889
[Epoch 16; Iter   690/  960] train: loss: 0.1763795
[Epoch 16; Iter   720/  960] train: loss: 0.0737671
[Epoch 16; Iter   750/  960] train: loss: 0.0251589
[Epoch 16; Iter   780/  960] train: loss: 0.0907626
[Epoch 16; Iter   810/  960] train: loss: 0.1908347
[Epoch 16; Iter   840/  960] train: loss: 0.0225897
[Epoch 16; Iter   870/  960] train: loss: 0.2464691
[Epoch 16; Iter   900/  960] train: loss: 0.1823484
[Epoch 16; Iter   930/  960] train: loss: 0.1441142
[Epoch 16; Iter   960/  960] train: loss: 0.0277207
[Epoch 16] ogbg-molhiv: 0.801910 val loss: 0.124797
[Epoch 16] ogbg-molhiv: 0.817184 test loss: 0.117117
[Epoch 17; Iter    30/  960] train: loss: 0.1355571
[Epoch 17; Iter    60/  960] train: loss: 0.0306870
[Epoch 17; Iter    90/  960] train: loss: 0.4617971
[Epoch 17; Iter   120/  960] train: loss: 0.1097784
[Epoch 17; Iter   150/  960] train: loss: 0.0833908
[Epoch 17; Iter   180/  960] train: loss: 0.1942862
[Epoch 17; Iter   210/  960] train: loss: 0.3750123
[Epoch 17; Iter   240/  960] train: loss: 0.2452897
[Epoch 17; Iter   270/  960] train: loss: 0.1143969
[Epoch 17; Iter   300/  960] train: loss: 0.0256401
[Epoch 17; Iter   330/  960] train: loss: 0.0169370
[Epoch 17; Iter   360/  960] train: loss: 0.2198963
[Epoch 17; Iter   390/  960] train: loss: 0.1052428
[Epoch 17; Iter   420/  960] train: loss: 0.0229488
[Epoch 17; Iter   450/  960] train: loss: 0.0179051
[Epoch 17; Iter   480/  960] train: loss: 0.0447278
[Epoch 17; Iter   510/  960] train: loss: 0.0187360
[Epoch 17; Iter   540/  960] train: loss: 0.0859274
[Epoch 17; Iter   570/  960] train: loss: 0.2114602
[Epoch 17; Iter   600/  960] train: loss: 0.1157732
[Epoch 17; Iter   630/  960] train: loss: 0.0384616
[Epoch 17; Iter   660/  960] train: loss: 0.0417353
[Epoch 17; Iter   690/  960] train: loss: 0.1192548
[Epoch 17; Iter   720/  960] train: loss: 0.1602604
[Epoch 17; Iter   750/  960] train: loss: 0.0212989
[Epoch 17; Iter   780/  960] train: loss: 0.2062134
[Epoch 17; Iter   810/  960] train: loss: 0.0727476
[Epoch 17; Iter   840/  960] train: loss: 0.0687963
[Epoch 17; Iter   870/  960] train: loss: 0.1448676
[Epoch 17; Iter   900/  960] train: loss: 0.4011906
[Epoch 17; Iter   930/  960] train: loss: 0.0683182
[Epoch 17; Iter   960/  960] train: loss: 0.0207029
[Epoch 17] ogbg-molhiv: 0.796593 val loss: 0.123454
[Epoch 17] ogbg-molhiv: 0.813820 test loss: 0.117268
[Epoch 18; Iter    30/  960] train: loss: 0.0520695
[Epoch 18; Iter    60/  960] train: loss: 0.0260540
[Epoch 18; Iter    90/  960] train: loss: 0.0287582
[Epoch 18; Iter   120/  960] train: loss: 0.0364334
[Epoch 18; Iter   150/  960] train: loss: 0.0318298
[Epoch 18; Iter   180/  960] train: loss: 0.0317175
[Epoch 18; Iter   210/  960] train: loss: 0.1028729
[Epoch 13; Iter   630/  960] train: loss: 0.0236899
[Epoch 13; Iter   660/  960] train: loss: 0.0322183
[Epoch 13; Iter   690/  960] train: loss: 0.1602339
[Epoch 13; Iter   720/  960] train: loss: 0.0309669
[Epoch 13; Iter   750/  960] train: loss: 0.0463926
[Epoch 13; Iter   780/  960] train: loss: 0.0564343
[Epoch 13; Iter   810/  960] train: loss: 0.2670314
[Epoch 13; Iter   840/  960] train: loss: 0.0615824
[Epoch 13; Iter   870/  960] train: loss: 0.0814550
[Epoch 13; Iter   900/  960] train: loss: 0.0502161
[Epoch 13; Iter   930/  960] train: loss: 0.1963266
[Epoch 13; Iter   960/  960] train: loss: 0.0274615
[Epoch 13] ogbg-molhiv: 0.790696 val loss: 0.136685
[Epoch 13] ogbg-molhiv: 0.772268 test loss: 0.127756
[Epoch 14; Iter    30/  960] train: loss: 0.0322985
[Epoch 14; Iter    60/  960] train: loss: 0.0219906
[Epoch 14; Iter    90/  960] train: loss: 0.0246876
[Epoch 14; Iter   120/  960] train: loss: 0.1865631
[Epoch 14; Iter   150/  960] train: loss: 0.0265142
[Epoch 14; Iter   180/  960] train: loss: 0.2816837
[Epoch 14; Iter   210/  960] train: loss: 0.0307592
[Epoch 14; Iter   240/  960] train: loss: 0.0288579
[Epoch 14; Iter   270/  960] train: loss: 0.1746555
[Epoch 14; Iter   300/  960] train: loss: 0.2551450
[Epoch 14; Iter   330/  960] train: loss: 0.3863237
[Epoch 14; Iter   360/  960] train: loss: 0.2764973
[Epoch 14; Iter   390/  960] train: loss: 0.0627216
[Epoch 14; Iter   420/  960] train: loss: 0.2570795
[Epoch 14; Iter   450/  960] train: loss: 0.0218560
[Epoch 14; Iter   480/  960] train: loss: 0.0258664
[Epoch 14; Iter   510/  960] train: loss: 0.0356237
[Epoch 14; Iter   540/  960] train: loss: 0.0266632
[Epoch 14; Iter   570/  960] train: loss: 0.0468297
[Epoch 14; Iter   600/  960] train: loss: 0.0419109
[Epoch 14; Iter   630/  960] train: loss: 0.1151955
[Epoch 14; Iter   660/  960] train: loss: 0.0426615
[Epoch 14; Iter   690/  960] train: loss: 0.0449219
[Epoch 14; Iter   720/  960] train: loss: 0.0327944
[Epoch 14; Iter   750/  960] train: loss: 0.0357848
[Epoch 14; Iter   780/  960] train: loss: 0.1893717
[Epoch 14; Iter   810/  960] train: loss: 0.3601205
[Epoch 14; Iter   840/  960] train: loss: 0.0266542
[Epoch 14; Iter   870/  960] train: loss: 0.0217066
[Epoch 14; Iter   900/  960] train: loss: 0.1576192
[Epoch 14; Iter   930/  960] train: loss: 0.0443009
[Epoch 14; Iter   960/  960] train: loss: 0.0200211
[Epoch 14] ogbg-molhiv: 0.780604 val loss: 0.130338
[Epoch 14] ogbg-molhiv: 0.761488 test loss: 0.126612
[Epoch 15; Iter    30/  960] train: loss: 0.0302257
[Epoch 15; Iter    60/  960] train: loss: 0.0349988
[Epoch 15; Iter    90/  960] train: loss: 0.0296454
[Epoch 15; Iter   120/  960] train: loss: 0.1383875
[Epoch 15; Iter   150/  960] train: loss: 0.0234413
[Epoch 15; Iter   180/  960] train: loss: 0.0489458
[Epoch 15; Iter   210/  960] train: loss: 0.1402700
[Epoch 15; Iter   240/  960] train: loss: 0.1904570
[Epoch 15; Iter   270/  960] train: loss: 0.2488615
[Epoch 15; Iter   300/  960] train: loss: 0.2298655
[Epoch 15; Iter   330/  960] train: loss: 0.3011478
[Epoch 15; Iter   360/  960] train: loss: 0.0318446
[Epoch 15; Iter   390/  960] train: loss: 0.0643903
[Epoch 15; Iter   420/  960] train: loss: 0.0203478
[Epoch 15; Iter   450/  960] train: loss: 0.3919943
[Epoch 15; Iter   480/  960] train: loss: 0.2613675
[Epoch 15; Iter   510/  960] train: loss: 0.0774533
[Epoch 15; Iter   540/  960] train: loss: 0.0241734
[Epoch 15; Iter   570/  960] train: loss: 0.0308811
[Epoch 15; Iter   600/  960] train: loss: 0.1403092
[Epoch 15; Iter   630/  960] train: loss: 0.1997712
[Epoch 15; Iter   660/  960] train: loss: 0.0263587
[Epoch 15; Iter   690/  960] train: loss: 0.1230489
[Epoch 15; Iter   720/  960] train: loss: 0.0334640
[Epoch 15; Iter   750/  960] train: loss: 0.1700106
[Epoch 15; Iter   780/  960] train: loss: 0.0665983
[Epoch 15; Iter   810/  960] train: loss: 0.1550366
[Epoch 15; Iter   840/  960] train: loss: 0.0370045
[Epoch 15; Iter   870/  960] train: loss: 0.0875491
[Epoch 15; Iter   900/  960] train: loss: 0.0333559
[Epoch 15; Iter   930/  960] train: loss: 0.1997916
[Epoch 15; Iter   960/  960] train: loss: 0.0326107
[Epoch 15] ogbg-molhiv: 0.782642 val loss: 0.140139
[Epoch 15] ogbg-molhiv: 0.781803 test loss: 0.119119
[Epoch 16; Iter    30/  960] train: loss: 0.0968036
[Epoch 16; Iter    60/  960] train: loss: 0.0490063
[Epoch 16; Iter    90/  960] train: loss: 0.2626428
[Epoch 16; Iter   120/  960] train: loss: 0.1911965
[Epoch 16; Iter   150/  960] train: loss: 0.3049408
[Epoch 16; Iter   180/  960] train: loss: 0.1434151
[Epoch 16; Iter   210/  960] train: loss: 0.0519025
[Epoch 16; Iter   240/  960] train: loss: 0.0222046
[Epoch 16; Iter   270/  960] train: loss: 0.0624150
[Epoch 16; Iter   300/  960] train: loss: 0.4664246
[Epoch 16; Iter   330/  960] train: loss: 0.0732952
[Epoch 16; Iter   360/  960] train: loss: 0.0981290
[Epoch 16; Iter   390/  960] train: loss: 0.1196208
[Epoch 16; Iter   420/  960] train: loss: 0.2929434
[Epoch 16; Iter   450/  960] train: loss: 0.0750136
[Epoch 16; Iter   480/  960] train: loss: 0.0266449
[Epoch 16; Iter   510/  960] train: loss: 0.0305910
[Epoch 16; Iter   540/  960] train: loss: 0.2692181
[Epoch 16; Iter   570/  960] train: loss: 0.0211726
[Epoch 16; Iter   600/  960] train: loss: 0.1915798
[Epoch 16; Iter   630/  960] train: loss: 0.0374723
[Epoch 16; Iter   660/  960] train: loss: 0.1225625
[Epoch 16; Iter   690/  960] train: loss: 0.0863394
[Epoch 16; Iter   720/  960] train: loss: 0.2705506
[Epoch 16; Iter   750/  960] train: loss: 0.0175430
[Epoch 16; Iter   780/  960] train: loss: 0.0297412
[Epoch 16; Iter   810/  960] train: loss: 0.0388744
[Epoch 16; Iter   840/  960] train: loss: 0.0693792
[Epoch 16; Iter   870/  960] train: loss: 0.0351858
[Epoch 16; Iter   900/  960] train: loss: 0.4710214
[Epoch 16; Iter   930/  960] train: loss: 0.0460134
[Epoch 16; Iter   960/  960] train: loss: 0.0181399
[Epoch 16] ogbg-molhiv: 0.791799 val loss: 0.125321
[Epoch 16] ogbg-molhiv: 0.774804 test loss: 0.120533
[Epoch 17; Iter    30/  960] train: loss: 0.0868256
[Epoch 17; Iter    60/  960] train: loss: 0.0279621
[Epoch 17; Iter    90/  960] train: loss: 0.0202928
[Epoch 17; Iter   120/  960] train: loss: 0.3531945
[Epoch 17; Iter   150/  960] train: loss: 0.1552248
[Epoch 17; Iter   180/  960] train: loss: 0.0183827
[Epoch 17; Iter   210/  960] train: loss: 0.0254242
[Epoch 17; Iter   240/  960] train: loss: 0.0257898
[Epoch 17; Iter   270/  960] train: loss: 0.0263793
[Epoch 17; Iter   300/  960] train: loss: 0.0371155
[Epoch 17; Iter   330/  960] train: loss: 0.0359301
[Epoch 17; Iter   360/  960] train: loss: 0.1001199
[Epoch 17; Iter   390/  960] train: loss: 0.0500207
[Epoch 17; Iter   420/  960] train: loss: 0.0628350
[Epoch 17; Iter   450/  960] train: loss: 0.1253288
[Epoch 17; Iter   480/  960] train: loss: 0.0641109
[Epoch 17; Iter   510/  960] train: loss: 0.0200574
[Epoch 17; Iter   540/  960] train: loss: 0.0249192
[Epoch 17; Iter   570/  960] train: loss: 0.0534858
[Epoch 17; Iter   600/  960] train: loss: 0.0253988
[Epoch 17; Iter   630/  960] train: loss: 0.2866226
[Epoch 17; Iter   660/  960] train: loss: 0.0324713
[Epoch 17; Iter   690/  960] train: loss: 0.1697659
[Epoch 17; Iter   720/  960] train: loss: 0.0237840
[Epoch 17; Iter   750/  960] train: loss: 0.0540048
[Epoch 17; Iter   780/  960] train: loss: 0.4108813
[Epoch 17; Iter   810/  960] train: loss: 0.1454440
[Epoch 17; Iter   840/  960] train: loss: 0.3607133
[Epoch 17; Iter   870/  960] train: loss: 0.0930312
[Epoch 17; Iter   900/  960] train: loss: 0.1118804
[Epoch 17; Iter   930/  960] train: loss: 0.0206485
[Epoch 17; Iter   960/  960] train: loss: 0.1804128
[Epoch 17] ogbg-molhiv: 0.801809 val loss: 0.127723
[Epoch 17] ogbg-molhiv: 0.793653 test loss: 0.120365
[Epoch 18; Iter    30/  960] train: loss: 0.0229631
[Epoch 18; Iter    60/  960] train: loss: 0.2956157
[Epoch 18; Iter    90/  960] train: loss: 0.0283519
[Epoch 18; Iter   120/  960] train: loss: 0.0323874
[Epoch 18; Iter   150/  960] train: loss: 0.1496890
[Epoch 18; Iter   180/  960] train: loss: 0.1822224
[Epoch 18; Iter   210/  960] train: loss: 0.0230975
[Epoch 13; Iter   630/  960] train: loss: 0.0227064
[Epoch 13; Iter   660/  960] train: loss: 0.1114303
[Epoch 13; Iter   690/  960] train: loss: 0.1405239
[Epoch 13; Iter   720/  960] train: loss: 0.0494880
[Epoch 13; Iter   750/  960] train: loss: 0.0350603
[Epoch 13; Iter   780/  960] train: loss: 0.0393272
[Epoch 13; Iter   810/  960] train: loss: 0.1353967
[Epoch 13; Iter   840/  960] train: loss: 0.0258679
[Epoch 13; Iter   870/  960] train: loss: 0.0243587
[Epoch 13; Iter   900/  960] train: loss: 0.0529899
[Epoch 13; Iter   930/  960] train: loss: 0.1924202
[Epoch 13; Iter   960/  960] train: loss: 0.0313885
[Epoch 13] ogbg-molhiv: 0.786061 val loss: 0.280061
[Epoch 13] ogbg-molhiv: 0.790642 test loss: 0.418983
[Epoch 14; Iter    30/  960] train: loss: 0.0376178
[Epoch 14; Iter    60/  960] train: loss: 0.1068707
[Epoch 14; Iter    90/  960] train: loss: 0.3735799
[Epoch 14; Iter   120/  960] train: loss: 0.3023361
[Epoch 14; Iter   150/  960] train: loss: 0.0539545
[Epoch 14; Iter   180/  960] train: loss: 0.0267285
[Epoch 14; Iter   210/  960] train: loss: 0.1539711
[Epoch 14; Iter   240/  960] train: loss: 0.0378741
[Epoch 14; Iter   270/  960] train: loss: 0.0914494
[Epoch 14; Iter   300/  960] train: loss: 0.0213912
[Epoch 14; Iter   330/  960] train: loss: 0.0168740
[Epoch 14; Iter   360/  960] train: loss: 0.0216786
[Epoch 14; Iter   390/  960] train: loss: 0.0714175
[Epoch 14; Iter   420/  960] train: loss: 0.0229925
[Epoch 14; Iter   450/  960] train: loss: 0.1216604
[Epoch 14; Iter   480/  960] train: loss: 0.0570966
[Epoch 14; Iter   510/  960] train: loss: 0.2078075
[Epoch 14; Iter   540/  960] train: loss: 0.0259550
[Epoch 14; Iter   570/  960] train: loss: 0.0434362
[Epoch 14; Iter   600/  960] train: loss: 0.0406995
[Epoch 14; Iter   630/  960] train: loss: 0.0508656
[Epoch 14; Iter   660/  960] train: loss: 0.0898088
[Epoch 14; Iter   690/  960] train: loss: 0.1750505
[Epoch 14; Iter   720/  960] train: loss: 0.0348459
[Epoch 14; Iter   750/  960] train: loss: 0.0759204
[Epoch 14; Iter   780/  960] train: loss: 0.1774065
[Epoch 14; Iter   810/  960] train: loss: 0.0511264
[Epoch 14; Iter   840/  960] train: loss: 0.0264992
[Epoch 14; Iter   870/  960] train: loss: 0.0278257
[Epoch 14; Iter   900/  960] train: loss: 0.0341821
[Epoch 14; Iter   930/  960] train: loss: 0.0299390
[Epoch 14; Iter   960/  960] train: loss: 0.0299089
[Epoch 14] ogbg-molhiv: 0.787635 val loss: 0.133465
[Epoch 14] ogbg-molhiv: 0.793721 test loss: 0.135280
[Epoch 15; Iter    30/  960] train: loss: 0.0459158
[Epoch 15; Iter    60/  960] train: loss: 0.2574419
[Epoch 15; Iter    90/  960] train: loss: 0.0443838
[Epoch 15; Iter   120/  960] train: loss: 0.0241297
[Epoch 15; Iter   150/  960] train: loss: 0.0301844
[Epoch 15; Iter   180/  960] train: loss: 0.1442856
[Epoch 15; Iter   210/  960] train: loss: 0.2056035
[Epoch 15; Iter   240/  960] train: loss: 0.0311221
[Epoch 15; Iter   270/  960] train: loss: 0.0303811
[Epoch 15; Iter   300/  960] train: loss: 0.0284115
[Epoch 15; Iter   330/  960] train: loss: 0.0459914
[Epoch 15; Iter   360/  960] train: loss: 0.1181976
[Epoch 15; Iter   390/  960] train: loss: 0.0328950
[Epoch 15; Iter   420/  960] train: loss: 0.0212659
[Epoch 15; Iter   450/  960] train: loss: 0.0548611
[Epoch 15; Iter   480/  960] train: loss: 0.2836660
[Epoch 15; Iter   510/  960] train: loss: 0.1917407
[Epoch 15; Iter   540/  960] train: loss: 0.0426548
[Epoch 15; Iter   570/  960] train: loss: 0.1829024
[Epoch 15; Iter   600/  960] train: loss: 0.0501914
[Epoch 15; Iter   630/  960] train: loss: 0.0759568
[Epoch 15; Iter   660/  960] train: loss: 0.0259872
[Epoch 15; Iter   690/  960] train: loss: 0.0288425
[Epoch 15; Iter   720/  960] train: loss: 0.3113028
[Epoch 15; Iter   750/  960] train: loss: 0.4501405
[Epoch 15; Iter   780/  960] train: loss: 0.2335183
[Epoch 15; Iter   810/  960] train: loss: 0.1945320
[Epoch 15; Iter   840/  960] train: loss: 0.1326937
[Epoch 15; Iter   870/  960] train: loss: 0.1069779
[Epoch 15; Iter   900/  960] train: loss: 0.1018809
[Epoch 15; Iter   930/  960] train: loss: 0.0286849
[Epoch 15; Iter   960/  960] train: loss: 0.1992496
[Epoch 15] ogbg-molhiv: 0.777223 val loss: 0.136965
[Epoch 15] ogbg-molhiv: 0.781557 test loss: 0.166871
[Epoch 16; Iter    30/  960] train: loss: 0.0708262
[Epoch 16; Iter    60/  960] train: loss: 0.1039544
[Epoch 16; Iter    90/  960] train: loss: 0.1986674
[Epoch 16; Iter   120/  960] train: loss: 0.2285682
[Epoch 16; Iter   150/  960] train: loss: 0.0267801
[Epoch 16; Iter   180/  960] train: loss: 0.0360088
[Epoch 16; Iter   210/  960] train: loss: 0.1349726
[Epoch 16; Iter   240/  960] train: loss: 0.0881608
[Epoch 16; Iter   270/  960] train: loss: 0.0345393
[Epoch 16; Iter   300/  960] train: loss: 0.1189227
[Epoch 16; Iter   330/  960] train: loss: 0.0190091
[Epoch 16; Iter   360/  960] train: loss: 0.0203028
[Epoch 16; Iter   390/  960] train: loss: 0.1387245
[Epoch 16; Iter   420/  960] train: loss: 0.3526146
[Epoch 16; Iter   450/  960] train: loss: 0.0376007
[Epoch 16; Iter   480/  960] train: loss: 0.0532439
[Epoch 16; Iter   510/  960] train: loss: 0.0516867
[Epoch 16; Iter   540/  960] train: loss: 0.0457027
[Epoch 16; Iter   570/  960] train: loss: 0.0344750
[Epoch 16; Iter   600/  960] train: loss: 0.0184815
[Epoch 16; Iter   630/  960] train: loss: 0.0594321
[Epoch 16; Iter   660/  960] train: loss: 0.0232755
[Epoch 16; Iter   690/  960] train: loss: 0.0461890
[Epoch 16; Iter   720/  960] train: loss: 0.0304471
[Epoch 16; Iter   750/  960] train: loss: 0.0331305
[Epoch 16; Iter   780/  960] train: loss: 0.0213436
[Epoch 16; Iter   810/  960] train: loss: 0.2830654
[Epoch 16; Iter   840/  960] train: loss: 0.1363431
[Epoch 16; Iter   870/  960] train: loss: 0.0319914
[Epoch 16; Iter   900/  960] train: loss: 0.0303260
[Epoch 16; Iter   930/  960] train: loss: 0.1945586
[Epoch 16; Iter   960/  960] train: loss: 0.1940668
[Epoch 16] ogbg-molhiv: 0.783919 val loss: 0.130183
[Epoch 16] ogbg-molhiv: 0.777925 test loss: 0.125689
[Epoch 17; Iter    30/  960] train: loss: 0.0364246
[Epoch 17; Iter    60/  960] train: loss: 0.2718508
[Epoch 17; Iter    90/  960] train: loss: 0.0964702
[Epoch 17; Iter   120/  960] train: loss: 0.0163498
[Epoch 17; Iter   150/  960] train: loss: 0.1678297
[Epoch 17; Iter   180/  960] train: loss: 0.0258964
[Epoch 17; Iter   210/  960] train: loss: 0.1149828
[Epoch 17; Iter   240/  960] train: loss: 0.3186440
[Epoch 17; Iter   270/  960] train: loss: 0.1946142
[Epoch 17; Iter   300/  960] train: loss: 0.1258261
[Epoch 17; Iter   330/  960] train: loss: 0.1576563
[Epoch 17; Iter   360/  960] train: loss: 0.0416980
[Epoch 17; Iter   390/  960] train: loss: 0.0207750
[Epoch 17; Iter   420/  960] train: loss: 0.2073115
[Epoch 17; Iter   450/  960] train: loss: 0.1306949
[Epoch 17; Iter   480/  960] train: loss: 0.1247389
[Epoch 17; Iter   510/  960] train: loss: 0.0239245
[Epoch 17; Iter   540/  960] train: loss: 0.0179594
[Epoch 17; Iter   570/  960] train: loss: 0.0465803
[Epoch 17; Iter   600/  960] train: loss: 0.5313357
[Epoch 17; Iter   630/  960] train: loss: 0.1303276
[Epoch 17; Iter   660/  960] train: loss: 0.0656547
[Epoch 17; Iter   690/  960] train: loss: 0.4695396
[Epoch 17; Iter   720/  960] train: loss: 0.2313509
[Epoch 17; Iter   750/  960] train: loss: 0.0467112
[Epoch 17; Iter   780/  960] train: loss: 0.1239287
[Epoch 17; Iter   810/  960] train: loss: 0.0200429
[Epoch 17; Iter   840/  960] train: loss: 0.0682665
[Epoch 17; Iter   870/  960] train: loss: 0.1442930
[Epoch 17; Iter   900/  960] train: loss: 0.1885285
[Epoch 17; Iter   930/  960] train: loss: 0.0405263
[Epoch 17; Iter   960/  960] train: loss: 0.0393339
[Epoch 17] ogbg-molhiv: 0.799615 val loss: 0.128921
[Epoch 17] ogbg-molhiv: 0.808257 test loss: 0.146269
[Epoch 18; Iter    30/  960] train: loss: 0.0519216
[Epoch 18; Iter    60/  960] train: loss: 0.0631585
[Epoch 18; Iter    90/  960] train: loss: 0.0366956
[Epoch 18; Iter   120/  960] train: loss: 0.0916772
[Epoch 18; Iter   150/  960] train: loss: 0.0445222
[Epoch 18; Iter   180/  960] train: loss: 0.2801515
[Epoch 18; Iter   210/  960] train: loss: 0.0280521
[Epoch 15; Iter   478/  823] train: loss: 0.0458255
[Epoch 15; Iter   508/  823] train: loss: 0.0295600
[Epoch 15; Iter   538/  823] train: loss: 0.1003166
[Epoch 15; Iter   568/  823] train: loss: 0.3089923
[Epoch 15; Iter   598/  823] train: loss: 0.1932371
[Epoch 15; Iter   628/  823] train: loss: 0.0383914
[Epoch 15; Iter   658/  823] train: loss: 0.0490617
[Epoch 15; Iter   688/  823] train: loss: 0.0365993
[Epoch 15; Iter   718/  823] train: loss: 0.0611566
[Epoch 15; Iter   748/  823] train: loss: 0.0416473
[Epoch 15; Iter   778/  823] train: loss: 0.5929822
[Epoch 15; Iter   808/  823] train: loss: 0.3085696
[Epoch 15] ogbg-molhiv: 0.796974 val loss: 0.124990
[Epoch 15] ogbg-molhiv: 0.767563 test loss: 0.149525
[Epoch 16; Iter    15/  823] train: loss: 0.0796463
[Epoch 16; Iter    45/  823] train: loss: 0.1388236
[Epoch 16; Iter    75/  823] train: loss: 0.1224245
[Epoch 16; Iter   105/  823] train: loss: 0.0512680
[Epoch 16; Iter   135/  823] train: loss: 0.0262231
[Epoch 16; Iter   165/  823] train: loss: 0.1354262
[Epoch 16; Iter   195/  823] train: loss: 0.1349359
[Epoch 16; Iter   225/  823] train: loss: 0.0390152
[Epoch 16; Iter   255/  823] train: loss: 0.2932208
[Epoch 16; Iter   285/  823] train: loss: 0.0983405
[Epoch 16; Iter   315/  823] train: loss: 0.1960801
[Epoch 16; Iter   345/  823] train: loss: 0.0832836
[Epoch 16; Iter   375/  823] train: loss: 0.0313854
[Epoch 16; Iter   405/  823] train: loss: 0.0399293
[Epoch 16; Iter   435/  823] train: loss: 0.0344495
[Epoch 16; Iter   465/  823] train: loss: 0.1679842
[Epoch 16; Iter   495/  823] train: loss: 0.0931285
[Epoch 16; Iter   525/  823] train: loss: 0.1235364
[Epoch 16; Iter   555/  823] train: loss: 0.4493667
[Epoch 16; Iter   585/  823] train: loss: 0.0301218
[Epoch 16; Iter   615/  823] train: loss: 0.1569831
[Epoch 16; Iter   645/  823] train: loss: 0.0854514
[Epoch 16; Iter   675/  823] train: loss: 0.0711080
[Epoch 16; Iter   705/  823] train: loss: 0.3653932
[Epoch 16; Iter   735/  823] train: loss: 0.1175888
[Epoch 16; Iter   765/  823] train: loss: 0.0608128
[Epoch 16; Iter   795/  823] train: loss: 0.0553429
[Epoch 16] ogbg-molhiv: 0.807737 val loss: 0.130510
[Epoch 16] ogbg-molhiv: 0.769707 test loss: 0.126287
[Epoch 17; Iter     2/  823] train: loss: 0.0197873
[Epoch 17; Iter    32/  823] train: loss: 0.1140642
[Epoch 17; Iter    62/  823] train: loss: 0.1939922
[Epoch 17; Iter    92/  823] train: loss: 0.2315379
[Epoch 17; Iter   122/  823] train: loss: 0.0291456
[Epoch 17; Iter   152/  823] train: loss: 0.0197836
[Epoch 17; Iter   182/  823] train: loss: 0.1320970
[Epoch 17; Iter   212/  823] train: loss: 0.0684997
[Epoch 17; Iter   242/  823] train: loss: 0.0578719
[Epoch 17; Iter   272/  823] train: loss: 0.2087913
[Epoch 17; Iter   302/  823] train: loss: 0.0191704
[Epoch 17; Iter   332/  823] train: loss: 0.1615761
[Epoch 17; Iter   362/  823] train: loss: 0.0753874
[Epoch 17; Iter   392/  823] train: loss: 0.0331851
[Epoch 17; Iter   422/  823] train: loss: 0.0369006
[Epoch 17; Iter   452/  823] train: loss: 0.0197906
[Epoch 17; Iter   482/  823] train: loss: 0.0225272
[Epoch 17; Iter   512/  823] train: loss: 0.2073564
[Epoch 17; Iter   542/  823] train: loss: 0.1682366
[Epoch 17; Iter   572/  823] train: loss: 0.0360014
[Epoch 17; Iter   602/  823] train: loss: 0.1642853
[Epoch 17; Iter   632/  823] train: loss: 0.1131860
[Epoch 17; Iter   662/  823] train: loss: 0.0255203
[Epoch 17; Iter   692/  823] train: loss: 0.1272704
[Epoch 17; Iter   722/  823] train: loss: 0.0492349
[Epoch 17; Iter   752/  823] train: loss: 0.0303137
[Epoch 17; Iter   782/  823] train: loss: 0.1080802
[Epoch 17; Iter   812/  823] train: loss: 0.1886135
[Epoch 17] ogbg-molhiv: 0.703286 val loss: 0.896150
[Epoch 17] ogbg-molhiv: 0.676756 test loss: 0.550651
[Epoch 18; Iter    19/  823] train: loss: 0.1478847
[Epoch 18; Iter    49/  823] train: loss: 0.1480527
[Epoch 18; Iter    79/  823] train: loss: 0.1760595
[Epoch 18; Iter   109/  823] train: loss: 0.1098033
[Epoch 18; Iter   139/  823] train: loss: 0.2549970
[Epoch 18; Iter   169/  823] train: loss: 0.1194229
[Epoch 18; Iter   199/  823] train: loss: 0.2124210
[Epoch 18; Iter   229/  823] train: loss: 0.2583999
[Epoch 18; Iter   259/  823] train: loss: 0.0276666
[Epoch 18; Iter   289/  823] train: loss: 0.2973216
[Epoch 18; Iter   319/  823] train: loss: 0.0882608
[Epoch 18; Iter   349/  823] train: loss: 0.2492157
[Epoch 18; Iter   379/  823] train: loss: 0.1467240
[Epoch 18; Iter   409/  823] train: loss: 0.0204327
[Epoch 18; Iter   439/  823] train: loss: 0.0336339
[Epoch 18; Iter   469/  823] train: loss: 0.1441929
[Epoch 18; Iter   499/  823] train: loss: 0.1094177
[Epoch 18; Iter   529/  823] train: loss: 0.0489697
[Epoch 18; Iter   559/  823] train: loss: 0.0509237
[Epoch 18; Iter   589/  823] train: loss: 0.1471566
[Epoch 18; Iter   619/  823] train: loss: 0.1216004
[Epoch 18; Iter   649/  823] train: loss: 0.1961756
[Epoch 18; Iter   679/  823] train: loss: 0.2701909
[Epoch 18; Iter   709/  823] train: loss: 0.0524798
[Epoch 18; Iter   739/  823] train: loss: 0.0400033
[Epoch 18; Iter   769/  823] train: loss: 0.0314359
[Epoch 18; Iter   799/  823] train: loss: 0.0672581
[Epoch 18] ogbg-molhiv: 0.791388 val loss: 0.132274
[Epoch 18] ogbg-molhiv: 0.785678 test loss: 0.137167
[Epoch 19; Iter     6/  823] train: loss: 0.2331504
[Epoch 19; Iter    36/  823] train: loss: 0.1374244
[Epoch 19; Iter    66/  823] train: loss: 0.0503699
[Epoch 19; Iter    96/  823] train: loss: 0.1690990
[Epoch 19; Iter   126/  823] train: loss: 0.4688851
[Epoch 19; Iter   156/  823] train: loss: 0.1933611
[Epoch 19; Iter   186/  823] train: loss: 0.0242938
[Epoch 19; Iter   216/  823] train: loss: 0.0981621
[Epoch 19; Iter   246/  823] train: loss: 0.1818180
[Epoch 19; Iter   276/  823] train: loss: 0.3098191
[Epoch 19; Iter   306/  823] train: loss: 0.0902132
[Epoch 19; Iter   336/  823] train: loss: 0.1001245
[Epoch 19; Iter   366/  823] train: loss: 0.2855122
[Epoch 19; Iter   396/  823] train: loss: 0.0309332
[Epoch 19; Iter   426/  823] train: loss: 0.0294603
[Epoch 19; Iter   456/  823] train: loss: 0.0411926
[Epoch 19; Iter   486/  823] train: loss: 0.0338711
[Epoch 19; Iter   516/  823] train: loss: 0.1813530
[Epoch 19; Iter   546/  823] train: loss: 0.0264794
[Epoch 19; Iter   576/  823] train: loss: 0.0968899
[Epoch 19; Iter   606/  823] train: loss: 0.0237638
[Epoch 19; Iter   636/  823] train: loss: 0.0307946
[Epoch 19; Iter   666/  823] train: loss: 0.0260709
[Epoch 19; Iter   696/  823] train: loss: 0.0640251
[Epoch 19; Iter   726/  823] train: loss: 0.3636729
[Epoch 19; Iter   756/  823] train: loss: 0.0256851
[Epoch 19; Iter   786/  823] train: loss: 0.0579205
[Epoch 19; Iter   816/  823] train: loss: 0.1287080
[Epoch 19] ogbg-molhiv: 0.792212 val loss: 0.163540
[Epoch 19] ogbg-molhiv: 0.789239 test loss: 0.187032
[Epoch 20; Iter    23/  823] train: loss: 0.1958528
[Epoch 20; Iter    53/  823] train: loss: 0.0278150
[Epoch 20; Iter    83/  823] train: loss: 0.2019454
[Epoch 20; Iter   113/  823] train: loss: 0.0602966
[Epoch 20; Iter   143/  823] train: loss: 0.2327120
[Epoch 20; Iter   173/  823] train: loss: 0.1483710
[Epoch 20; Iter   203/  823] train: loss: 0.1100916
[Epoch 20; Iter   233/  823] train: loss: 0.0236770
[Epoch 20; Iter   263/  823] train: loss: 0.0603603
[Epoch 20; Iter   293/  823] train: loss: 0.1192691
[Epoch 20; Iter   323/  823] train: loss: 0.0433666
[Epoch 20; Iter   353/  823] train: loss: 0.2413817
[Epoch 20; Iter   383/  823] train: loss: 0.0268383
[Epoch 20; Iter   413/  823] train: loss: 0.2959449
[Epoch 20; Iter   443/  823] train: loss: 0.0316390
[Epoch 20; Iter   473/  823] train: loss: 0.0255932
[Epoch 20; Iter   503/  823] train: loss: 0.1859607
[Epoch 20; Iter   533/  823] train: loss: 0.0382446
[Epoch 20; Iter   563/  823] train: loss: 0.0632389
[Epoch 20; Iter   593/  823] train: loss: 0.0184940
[Epoch 20; Iter   623/  823] train: loss: 0.1549711
[Epoch 20; Iter   653/  823] train: loss: 0.0513559
[Epoch 20; Iter   683/  823] train: loss: 0.2831151
[Epoch 20; Iter   713/  823] train: loss: 0.3526039
[Epoch 20; Iter   743/  823] train: loss: 0.0369396
[Epoch 15; Iter   478/  823] train: loss: 0.1314347
[Epoch 15; Iter   508/  823] train: loss: 0.2185051
[Epoch 15; Iter   538/  823] train: loss: 0.1470288
[Epoch 15; Iter   568/  823] train: loss: 0.2398069
[Epoch 15; Iter   598/  823] train: loss: 0.0484779
[Epoch 15; Iter   628/  823] train: loss: 0.3892283
[Epoch 15; Iter   658/  823] train: loss: 0.0231606
[Epoch 15; Iter   688/  823] train: loss: 0.1589223
[Epoch 15; Iter   718/  823] train: loss: 0.0378261
[Epoch 15; Iter   748/  823] train: loss: 0.0289164
[Epoch 15; Iter   778/  823] train: loss: 0.0434822
[Epoch 15; Iter   808/  823] train: loss: 0.1939752
[Epoch 15] ogbg-molhiv: 0.792092 val loss: 0.156597
[Epoch 15] ogbg-molhiv: 0.765264 test loss: 0.142273
[Epoch 16; Iter    15/  823] train: loss: 0.1872214
[Epoch 16; Iter    45/  823] train: loss: 0.1426927
[Epoch 16; Iter    75/  823] train: loss: 0.0385465
[Epoch 16; Iter   105/  823] train: loss: 0.0349519
[Epoch 16; Iter   135/  823] train: loss: 0.1216955
[Epoch 16; Iter   165/  823] train: loss: 0.2682768
[Epoch 16; Iter   195/  823] train: loss: 0.3460076
[Epoch 16; Iter   225/  823] train: loss: 0.0272283
[Epoch 16; Iter   255/  823] train: loss: 0.1519171
[Epoch 16; Iter   285/  823] train: loss: 0.0615504
[Epoch 16; Iter   315/  823] train: loss: 0.3152140
[Epoch 16; Iter   345/  823] train: loss: 0.2826418
[Epoch 16; Iter   375/  823] train: loss: 0.0278433
[Epoch 16; Iter   405/  823] train: loss: 0.1251975
[Epoch 16; Iter   435/  823] train: loss: 0.1718730
[Epoch 16; Iter   465/  823] train: loss: 0.2422885
[Epoch 16; Iter   495/  823] train: loss: 0.0890798
[Epoch 16; Iter   525/  823] train: loss: 0.0248592
[Epoch 16; Iter   555/  823] train: loss: 0.1362621
[Epoch 16; Iter   585/  823] train: loss: 0.0681452
[Epoch 16; Iter   615/  823] train: loss: 0.0233528
[Epoch 16; Iter   645/  823] train: loss: 0.0379007
[Epoch 16; Iter   675/  823] train: loss: 0.1129406
[Epoch 16; Iter   705/  823] train: loss: 0.1788824
[Epoch 16; Iter   735/  823] train: loss: 0.0751827
[Epoch 16; Iter   765/  823] train: loss: 0.1318810
[Epoch 16; Iter   795/  823] train: loss: 0.3353855
[Epoch 16] ogbg-molhiv: 0.803628 val loss: 0.126369
[Epoch 16] ogbg-molhiv: 0.787756 test loss: 0.125228
[Epoch 17; Iter     2/  823] train: loss: 0.0509027
[Epoch 17; Iter    32/  823] train: loss: 0.2128834
[Epoch 17; Iter    62/  823] train: loss: 0.0892949
[Epoch 17; Iter    92/  823] train: loss: 0.0480403
[Epoch 17; Iter   122/  823] train: loss: 0.0237803
[Epoch 17; Iter   152/  823] train: loss: 0.0235942
[Epoch 17; Iter   182/  823] train: loss: 0.0319464
[Epoch 17; Iter   212/  823] train: loss: 0.0180039
[Epoch 17; Iter   242/  823] train: loss: 0.1888007
[Epoch 17; Iter   272/  823] train: loss: 0.1626320
[Epoch 17; Iter   302/  823] train: loss: 0.0301218
[Epoch 17; Iter   332/  823] train: loss: 0.1816119
[Epoch 17; Iter   362/  823] train: loss: 0.0989288
[Epoch 17; Iter   392/  823] train: loss: 0.1007971
[Epoch 17; Iter   422/  823] train: loss: 0.0328939
[Epoch 17; Iter   452/  823] train: loss: 0.1843810
[Epoch 17; Iter   482/  823] train: loss: 0.1822731
[Epoch 17; Iter   512/  823] train: loss: 0.0312058
[Epoch 17; Iter   542/  823] train: loss: 0.0405386
[Epoch 17; Iter   572/  823] train: loss: 0.2028069
[Epoch 17; Iter   602/  823] train: loss: 0.0289537
[Epoch 17; Iter   632/  823] train: loss: 0.1096468
[Epoch 17; Iter   662/  823] train: loss: 0.0315691
[Epoch 17; Iter   692/  823] train: loss: 0.1284536
[Epoch 17; Iter   722/  823] train: loss: 0.1781185
[Epoch 17; Iter   752/  823] train: loss: 0.1182813
[Epoch 17; Iter   782/  823] train: loss: 0.1186707
[Epoch 17; Iter   812/  823] train: loss: 0.1410063
[Epoch 17] ogbg-molhiv: 0.801514 val loss: 0.137938
[Epoch 17] ogbg-molhiv: 0.781624 test loss: 0.138352
[Epoch 18; Iter    19/  823] train: loss: 0.3600603
[Epoch 18; Iter    49/  823] train: loss: 0.0753028
[Epoch 18; Iter    79/  823] train: loss: 0.0420078
[Epoch 18; Iter   109/  823] train: loss: 0.1698714
[Epoch 18; Iter   139/  823] train: loss: 0.2265823
[Epoch 18; Iter   169/  823] train: loss: 0.0237635
[Epoch 18; Iter   199/  823] train: loss: 0.0559521
[Epoch 18; Iter   229/  823] train: loss: 0.0277054
[Epoch 18; Iter   259/  823] train: loss: 0.0208104
[Epoch 18; Iter   289/  823] train: loss: 0.0184716
[Epoch 18; Iter   319/  823] train: loss: 0.1717510
[Epoch 18; Iter   349/  823] train: loss: 0.0432358
[Epoch 18; Iter   379/  823] train: loss: 0.0805202
[Epoch 18; Iter   409/  823] train: loss: 0.0688029
[Epoch 18; Iter   439/  823] train: loss: 0.2255134
[Epoch 18; Iter   469/  823] train: loss: 0.1500026
[Epoch 18; Iter   499/  823] train: loss: 0.2088218
[Epoch 18; Iter   529/  823] train: loss: 0.2366825
[Epoch 18; Iter   559/  823] train: loss: 0.0671609
[Epoch 18; Iter   589/  823] train: loss: 0.0213262
[Epoch 18; Iter   619/  823] train: loss: 0.0789692
[Epoch 18; Iter   649/  823] train: loss: 0.0394289
[Epoch 18; Iter   679/  823] train: loss: 0.3830991
[Epoch 18; Iter   709/  823] train: loss: 0.1928366
[Epoch 18; Iter   739/  823] train: loss: 0.1791515
[Epoch 18; Iter   769/  823] train: loss: 0.0172590
[Epoch 18; Iter   799/  823] train: loss: 0.2475187
[Epoch 18] ogbg-molhiv: 0.806243 val loss: 0.120197
[Epoch 18] ogbg-molhiv: 0.777236 test loss: 0.123829
[Epoch 19; Iter     6/  823] train: loss: 0.1035411
[Epoch 19; Iter    36/  823] train: loss: 0.0441246
[Epoch 19; Iter    66/  823] train: loss: 0.0227351
[Epoch 19; Iter    96/  823] train: loss: 0.0274481
[Epoch 19; Iter   126/  823] train: loss: 0.0167217
[Epoch 19; Iter   156/  823] train: loss: 0.0351824
[Epoch 19; Iter   186/  823] train: loss: 0.1208532
[Epoch 19; Iter   216/  823] train: loss: 0.0326074
[Epoch 19; Iter   246/  823] train: loss: 0.0937813
[Epoch 19; Iter   276/  823] train: loss: 0.0791689
[Epoch 19; Iter   306/  823] train: loss: 0.0234059
[Epoch 19; Iter   336/  823] train: loss: 0.2055438
[Epoch 19; Iter   366/  823] train: loss: 0.0270927
[Epoch 19; Iter   396/  823] train: loss: 0.1244162
[Epoch 19; Iter   426/  823] train: loss: 0.0295476
[Epoch 19; Iter   456/  823] train: loss: 0.0476377
[Epoch 19; Iter   486/  823] train: loss: 0.0327489
[Epoch 19; Iter   516/  823] train: loss: 0.1031424
[Epoch 19; Iter   546/  823] train: loss: 0.2104977
[Epoch 19; Iter   576/  823] train: loss: 0.0321415
[Epoch 19; Iter   606/  823] train: loss: 0.0245341
[Epoch 19; Iter   636/  823] train: loss: 0.0188026
[Epoch 19; Iter   666/  823] train: loss: 0.2204249
[Epoch 19; Iter   696/  823] train: loss: 0.2088583
[Epoch 19; Iter   726/  823] train: loss: 0.1837322
[Epoch 19; Iter   756/  823] train: loss: 0.0673157
[Epoch 19; Iter   786/  823] train: loss: 0.2186882
[Epoch 19; Iter   816/  823] train: loss: 0.1670774
[Epoch 19] ogbg-molhiv: 0.803602 val loss: 0.205182
[Epoch 19] ogbg-molhiv: 0.792460 test loss: 0.209483
[Epoch 20; Iter    23/  823] train: loss: 0.0426237
[Epoch 20; Iter    53/  823] train: loss: 0.1799748
[Epoch 20; Iter    83/  823] train: loss: 0.0314440
[Epoch 20; Iter   113/  823] train: loss: 0.2123104
[Epoch 20; Iter   143/  823] train: loss: 0.0266902
[Epoch 20; Iter   173/  823] train: loss: 0.1901364
[Epoch 20; Iter   203/  823] train: loss: 0.0184505
[Epoch 20; Iter   233/  823] train: loss: 0.0857330
[Epoch 20; Iter   263/  823] train: loss: 0.2398713
[Epoch 20; Iter   293/  823] train: loss: 0.0231300
[Epoch 20; Iter   323/  823] train: loss: 0.0227987
[Epoch 20; Iter   353/  823] train: loss: 0.0321700
[Epoch 20; Iter   383/  823] train: loss: 0.0575031
[Epoch 20; Iter   413/  823] train: loss: 0.0240626
[Epoch 20; Iter   443/  823] train: loss: 0.2367717
[Epoch 20; Iter   473/  823] train: loss: 0.0395278
[Epoch 20; Iter   503/  823] train: loss: 0.0419497
[Epoch 20; Iter   533/  823] train: loss: 0.3723889
[Epoch 20; Iter   563/  823] train: loss: 0.0615308
[Epoch 20; Iter   593/  823] train: loss: 0.2586993
[Epoch 20; Iter   623/  823] train: loss: 0.0284792
[Epoch 20; Iter   653/  823] train: loss: 0.1286321
[Epoch 20; Iter   683/  823] train: loss: 0.1620906
[Epoch 20; Iter   713/  823] train: loss: 0.0303926
[Epoch 20; Iter   743/  823] train: loss: 0.0598078
[Epoch 15; Iter   478/  823] train: loss: 0.1374830
[Epoch 15; Iter   508/  823] train: loss: 0.1778673
[Epoch 15; Iter   538/  823] train: loss: 0.0691112
[Epoch 15; Iter   568/  823] train: loss: 0.1831811
[Epoch 15; Iter   598/  823] train: loss: 0.1686358
[Epoch 15; Iter   628/  823] train: loss: 0.0329618
[Epoch 15; Iter   658/  823] train: loss: 0.0450350
[Epoch 15; Iter   688/  823] train: loss: 0.2417476
[Epoch 15; Iter   718/  823] train: loss: 0.0770817
[Epoch 15; Iter   748/  823] train: loss: 0.0296098
[Epoch 15; Iter   778/  823] train: loss: 0.0428368
[Epoch 15; Iter   808/  823] train: loss: 0.0245390
[Epoch 15] ogbg-molhiv: 0.807880 val loss: 0.116263
[Epoch 15] ogbg-molhiv: 0.794296 test loss: 0.124067
[Epoch 16; Iter    15/  823] train: loss: 0.1482531
[Epoch 16; Iter    45/  823] train: loss: 0.2583544
[Epoch 16; Iter    75/  823] train: loss: 0.0284626
[Epoch 16; Iter   105/  823] train: loss: 0.1562598
[Epoch 16; Iter   135/  823] train: loss: 0.2271911
[Epoch 16; Iter   165/  823] train: loss: 0.2147989
[Epoch 16; Iter   195/  823] train: loss: 0.0739614
[Epoch 16; Iter   225/  823] train: loss: 0.0460964
[Epoch 16; Iter   255/  823] train: loss: 0.0242238
[Epoch 16; Iter   285/  823] train: loss: 0.2179608
[Epoch 16; Iter   315/  823] train: loss: 0.0364910
[Epoch 16; Iter   345/  823] train: loss: 0.3415964
[Epoch 16; Iter   375/  823] train: loss: 0.1566060
[Epoch 16; Iter   405/  823] train: loss: 0.0568726
[Epoch 16; Iter   435/  823] train: loss: 0.0442829
[Epoch 16; Iter   465/  823] train: loss: 0.2180574
[Epoch 16; Iter   495/  823] train: loss: 0.1570561
[Epoch 16; Iter   525/  823] train: loss: 0.0346316
[Epoch 16; Iter   555/  823] train: loss: 0.0415964
[Epoch 16; Iter   585/  823] train: loss: 0.4243964
[Epoch 16; Iter   615/  823] train: loss: 0.0319793
[Epoch 16; Iter   645/  823] train: loss: 0.1720068
[Epoch 16; Iter   675/  823] train: loss: 0.1075042
[Epoch 16; Iter   705/  823] train: loss: 0.1432885
[Epoch 16; Iter   735/  823] train: loss: 0.0275745
[Epoch 16; Iter   765/  823] train: loss: 0.0295208
[Epoch 16; Iter   795/  823] train: loss: 0.0231099
[Epoch 16] ogbg-molhiv: 0.803412 val loss: 0.184924
[Epoch 16] ogbg-molhiv: 0.795116 test loss: 0.203091
[Epoch 17; Iter     2/  823] train: loss: 0.1242583
[Epoch 17; Iter    32/  823] train: loss: 0.0365652
[Epoch 17; Iter    62/  823] train: loss: 0.0313690
[Epoch 17; Iter    92/  823] train: loss: 0.0167277
[Epoch 17; Iter   122/  823] train: loss: 0.0555325
[Epoch 17; Iter   152/  823] train: loss: 0.1771580
[Epoch 17; Iter   182/  823] train: loss: 0.1646646
[Epoch 17; Iter   212/  823] train: loss: 0.0411582
[Epoch 17; Iter   242/  823] train: loss: 0.0315499
[Epoch 17; Iter   272/  823] train: loss: 0.0242076
[Epoch 17; Iter   302/  823] train: loss: 0.0248980
[Epoch 17; Iter   332/  823] train: loss: 0.1320950
[Epoch 17; Iter   362/  823] train: loss: 0.0254284
[Epoch 17; Iter   392/  823] train: loss: 0.0277136
[Epoch 17; Iter   422/  823] train: loss: 0.0523352
[Epoch 17; Iter   452/  823] train: loss: 0.0267362
[Epoch 17; Iter   482/  823] train: loss: 0.1756223
[Epoch 17; Iter   512/  823] train: loss: 0.0402279
[Epoch 17; Iter   542/  823] train: loss: 0.0321411
[Epoch 17; Iter   572/  823] train: loss: 0.4425171
[Epoch 17; Iter   602/  823] train: loss: 0.3273817
[Epoch 17; Iter   632/  823] train: loss: 0.2006484
[Epoch 17; Iter   662/  823] train: loss: 0.0557259
[Epoch 17; Iter   692/  823] train: loss: 0.4023915
[Epoch 17; Iter   722/  823] train: loss: 0.0273815
[Epoch 17; Iter   752/  823] train: loss: 0.1013600
[Epoch 17; Iter   782/  823] train: loss: 0.0434911
[Epoch 17; Iter   812/  823] train: loss: 0.0329441
[Epoch 17] ogbg-molhiv: 0.804430 val loss: 0.229724
[Epoch 17] ogbg-molhiv: 0.795536 test loss: 0.121446
[Epoch 18; Iter    19/  823] train: loss: 0.2205714
[Epoch 18; Iter    49/  823] train: loss: 0.1209436
[Epoch 18; Iter    79/  823] train: loss: 0.0302451
[Epoch 18; Iter   109/  823] train: loss: 0.0622823
[Epoch 18; Iter   139/  823] train: loss: 0.0254792
[Epoch 18; Iter   169/  823] train: loss: 0.0472350
[Epoch 18; Iter   199/  823] train: loss: 0.2561417
[Epoch 18; Iter   229/  823] train: loss: 0.0302942
[Epoch 18; Iter   259/  823] train: loss: 0.0374374
[Epoch 18; Iter   289/  823] train: loss: 0.1603893
[Epoch 18; Iter   319/  823] train: loss: 0.0216019
[Epoch 18; Iter   349/  823] train: loss: 0.1229082
[Epoch 18; Iter   379/  823] train: loss: 0.0212315
[Epoch 18; Iter   409/  823] train: loss: 0.0392714
[Epoch 18; Iter   439/  823] train: loss: 0.1831514
[Epoch 18; Iter   469/  823] train: loss: 0.0536443
[Epoch 18; Iter   499/  823] train: loss: 0.0212233
[Epoch 18; Iter   529/  823] train: loss: 0.0164045
[Epoch 18; Iter   559/  823] train: loss: 0.1817758
[Epoch 18; Iter   589/  823] train: loss: 0.0321587
[Epoch 18; Iter   619/  823] train: loss: 0.1687615
[Epoch 18; Iter   649/  823] train: loss: 0.0295559
[Epoch 18; Iter   679/  823] train: loss: 0.0174793
[Epoch 18; Iter   709/  823] train: loss: 0.1030596
[Epoch 18; Iter   739/  823] train: loss: 0.1911286
[Epoch 18; Iter   769/  823] train: loss: 0.0200318
[Epoch 18; Iter   799/  823] train: loss: 0.1966716
[Epoch 18] ogbg-molhiv: 0.795084 val loss: 0.183886
[Epoch 18] ogbg-molhiv: 0.769715 test loss: 0.186627
[Epoch 19; Iter     6/  823] train: loss: 0.0996897
[Epoch 19; Iter    36/  823] train: loss: 0.0497971
[Epoch 19; Iter    66/  823] train: loss: 0.2287206
[Epoch 19; Iter    96/  823] train: loss: 0.0303124
[Epoch 19; Iter   126/  823] train: loss: 0.0502534
[Epoch 19; Iter   156/  823] train: loss: 0.2449127
[Epoch 19; Iter   186/  823] train: loss: 0.1839469
[Epoch 19; Iter   216/  823] train: loss: 0.2894075
[Epoch 19; Iter   246/  823] train: loss: 0.1389074
[Epoch 19; Iter   276/  823] train: loss: 0.0997498
[Epoch 19; Iter   306/  823] train: loss: 0.1850588
[Epoch 19; Iter   336/  823] train: loss: 0.0258042
[Epoch 19; Iter   366/  823] train: loss: 0.0358853
[Epoch 19; Iter   396/  823] train: loss: 0.1496442
[Epoch 19; Iter   426/  823] train: loss: 0.0524052
[Epoch 19; Iter   456/  823] train: loss: 0.0662429
[Epoch 19; Iter   486/  823] train: loss: 0.1979691
[Epoch 19; Iter   516/  823] train: loss: 0.0371465
[Epoch 19; Iter   546/  823] train: loss: 0.0897460
[Epoch 19; Iter   576/  823] train: loss: 0.1778068
[Epoch 19; Iter   606/  823] train: loss: 0.4405354
[Epoch 19; Iter   636/  823] train: loss: 0.0218814
[Epoch 19; Iter   666/  823] train: loss: 0.0242339
[Epoch 19; Iter   696/  823] train: loss: 0.2560117
[Epoch 19; Iter   726/  823] train: loss: 0.0421032
[Epoch 19; Iter   756/  823] train: loss: 0.0307840
[Epoch 19; Iter   786/  823] train: loss: 0.0779736
[Epoch 19; Iter   816/  823] train: loss: 0.1912255
[Epoch 19] ogbg-molhiv: 0.802811 val loss: 0.125407
[Epoch 19] ogbg-molhiv: 0.787341 test loss: 0.121716
[Epoch 20; Iter    23/  823] train: loss: 0.0387199
[Epoch 20; Iter    53/  823] train: loss: 0.0243854
[Epoch 20; Iter    83/  823] train: loss: 0.0295342
[Epoch 20; Iter   113/  823] train: loss: 0.0362712
[Epoch 20; Iter   143/  823] train: loss: 0.1432289
[Epoch 20; Iter   173/  823] train: loss: 0.0150389
[Epoch 20; Iter   203/  823] train: loss: 0.0876013
[Epoch 20; Iter   233/  823] train: loss: 0.0308211
[Epoch 20; Iter   263/  823] train: loss: 0.1817617
[Epoch 20; Iter   293/  823] train: loss: 0.2954664
[Epoch 20; Iter   323/  823] train: loss: 0.0204495
[Epoch 20; Iter   353/  823] train: loss: 0.0981075
[Epoch 20; Iter   383/  823] train: loss: 0.0255380
[Epoch 20; Iter   413/  823] train: loss: 0.0192734
[Epoch 20; Iter   443/  823] train: loss: 0.2858625
[Epoch 20; Iter   473/  823] train: loss: 0.1492692
[Epoch 20; Iter   503/  823] train: loss: 0.1280703
[Epoch 20; Iter   533/  823] train: loss: 0.0306927
[Epoch 20; Iter   563/  823] train: loss: 0.1715084
[Epoch 20; Iter   593/  823] train: loss: 0.0497594
[Epoch 20; Iter   623/  823] train: loss: 0.0467231
[Epoch 20; Iter   653/  823] train: loss: 0.1611193
[Epoch 20; Iter   683/  823] train: loss: 0.2302990
[Epoch 20; Iter   713/  823] train: loss: 0.1886566
[Epoch 20; Iter   743/  823] train: loss: 0.0227521
[Epoch 16; Iter   225/ 1097] train: loss: 0.0285491
[Epoch 16; Iter   255/ 1097] train: loss: 0.0351053
[Epoch 16; Iter   285/ 1097] train: loss: 0.1451036
[Epoch 16; Iter   315/ 1097] train: loss: 0.3457115
[Epoch 16; Iter   345/ 1097] train: loss: 0.0283845
[Epoch 16; Iter   375/ 1097] train: loss: 0.2421595
[Epoch 16; Iter   405/ 1097] train: loss: 0.0341236
[Epoch 16; Iter   435/ 1097] train: loss: 0.2304443
[Epoch 16; Iter   465/ 1097] train: loss: 0.2393095
[Epoch 16; Iter   495/ 1097] train: loss: 0.1935400
[Epoch 16; Iter   525/ 1097] train: loss: 0.2074383
[Epoch 16; Iter   555/ 1097] train: loss: 0.3077238
[Epoch 16; Iter   585/ 1097] train: loss: 0.2649957
[Epoch 16; Iter   615/ 1097] train: loss: 0.2436005
[Epoch 16; Iter   645/ 1097] train: loss: 0.0248199
[Epoch 16; Iter   675/ 1097] train: loss: 0.0478605
[Epoch 16; Iter   705/ 1097] train: loss: 0.0272211
[Epoch 16; Iter   735/ 1097] train: loss: 0.1226974
[Epoch 16; Iter   765/ 1097] train: loss: 0.0311715
[Epoch 16; Iter   795/ 1097] train: loss: 0.0281753
[Epoch 16; Iter   825/ 1097] train: loss: 0.0309740
[Epoch 16; Iter   855/ 1097] train: loss: 0.0274133
[Epoch 16; Iter   885/ 1097] train: loss: 0.0268574
[Epoch 16; Iter   915/ 1097] train: loss: 0.1610131
[Epoch 16; Iter   945/ 1097] train: loss: 0.1779595
[Epoch 16; Iter   975/ 1097] train: loss: 0.0328020
[Epoch 16; Iter  1005/ 1097] train: loss: 0.0251810
[Epoch 16; Iter  1035/ 1097] train: loss: 0.2015379
[Epoch 16; Iter  1065/ 1097] train: loss: 0.0188915
[Epoch 16; Iter  1095/ 1097] train: loss: 0.0222831
[Epoch 16] ogbg-molhiv: 0.781265 val loss: 0.226170
[Epoch 16] ogbg-molhiv: 0.775727 test loss: 0.291596
[Epoch 17; Iter    28/ 1097] train: loss: 0.2942451
[Epoch 17; Iter    58/ 1097] train: loss: 0.0347548
[Epoch 17; Iter    88/ 1097] train: loss: 0.0219374
[Epoch 17; Iter   118/ 1097] train: loss: 0.1831594
[Epoch 17; Iter   148/ 1097] train: loss: 0.0240359
[Epoch 17; Iter   178/ 1097] train: loss: 0.0286335
[Epoch 17; Iter   208/ 1097] train: loss: 0.0231990
[Epoch 17; Iter   238/ 1097] train: loss: 0.0397534
[Epoch 17; Iter   268/ 1097] train: loss: 0.0316401
[Epoch 17; Iter   298/ 1097] train: loss: 0.2052835
[Epoch 17; Iter   328/ 1097] train: loss: 0.2877183
[Epoch 17; Iter   358/ 1097] train: loss: 0.0257281
[Epoch 17; Iter   388/ 1097] train: loss: 0.0256128
[Epoch 17; Iter   418/ 1097] train: loss: 0.2023688
[Epoch 17; Iter   448/ 1097] train: loss: 0.0265136
[Epoch 17; Iter   478/ 1097] train: loss: 0.2183509
[Epoch 17; Iter   508/ 1097] train: loss: 0.0901809
[Epoch 17; Iter   538/ 1097] train: loss: 0.1026944
[Epoch 17; Iter   568/ 1097] train: loss: 0.2642186
[Epoch 17; Iter   598/ 1097] train: loss: 0.2047684
[Epoch 17; Iter   628/ 1097] train: loss: 0.1523958
[Epoch 17; Iter   658/ 1097] train: loss: 0.0344372
[Epoch 17; Iter   688/ 1097] train: loss: 0.0232535
[Epoch 17; Iter   718/ 1097] train: loss: 0.1048845
[Epoch 17; Iter   748/ 1097] train: loss: 0.1698526
[Epoch 17; Iter   778/ 1097] train: loss: 0.0549384
[Epoch 17; Iter   808/ 1097] train: loss: 0.1298075
[Epoch 17; Iter   838/ 1097] train: loss: 0.0352140
[Epoch 17; Iter   868/ 1097] train: loss: 0.1652263
[Epoch 17; Iter   898/ 1097] train: loss: 0.1921848
[Epoch 17; Iter   928/ 1097] train: loss: 0.0244057
[Epoch 17; Iter   958/ 1097] train: loss: 0.1323767
[Epoch 17; Iter   988/ 1097] train: loss: 0.0818288
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0346019
[Epoch 17; Iter  1048/ 1097] train: loss: 0.0599430
[Epoch 17; Iter  1078/ 1097] train: loss: 0.0359568
[Epoch 17] ogbg-molhiv: 0.784608 val loss: 0.149785
[Epoch 17] ogbg-molhiv: 0.776345 test loss: 0.155062
[Epoch 18; Iter    11/ 1097] train: loss: 0.1703756
[Epoch 18; Iter    41/ 1097] train: loss: 0.0265529
[Epoch 18; Iter    71/ 1097] train: loss: 0.1510307
[Epoch 18; Iter   101/ 1097] train: loss: 0.2591539
[Epoch 18; Iter   131/ 1097] train: loss: 0.0476854
[Epoch 18; Iter   161/ 1097] train: loss: 0.2787710
[Epoch 18; Iter   191/ 1097] train: loss: 0.1052109
[Epoch 18; Iter   221/ 1097] train: loss: 0.0253749
[Epoch 18; Iter   251/ 1097] train: loss: 0.0325393
[Epoch 18; Iter   281/ 1097] train: loss: 0.0652714
[Epoch 18; Iter   311/ 1097] train: loss: 0.0337642
[Epoch 18; Iter   341/ 1097] train: loss: 0.0427399
[Epoch 18; Iter   371/ 1097] train: loss: 0.0203060
[Epoch 18; Iter   401/ 1097] train: loss: 0.0502012
[Epoch 18; Iter   431/ 1097] train: loss: 0.0395726
[Epoch 18; Iter   461/ 1097] train: loss: 0.1881467
[Epoch 18; Iter   491/ 1097] train: loss: 0.0268215
[Epoch 18; Iter   521/ 1097] train: loss: 0.0780872
[Epoch 18; Iter   551/ 1097] train: loss: 0.1799483
[Epoch 18; Iter   581/ 1097] train: loss: 0.2877871
[Epoch 18; Iter   611/ 1097] train: loss: 0.0855770
[Epoch 18; Iter   641/ 1097] train: loss: 0.1351854
[Epoch 18; Iter   671/ 1097] train: loss: 0.2204112
[Epoch 18; Iter   701/ 1097] train: loss: 0.3381483
[Epoch 18; Iter   731/ 1097] train: loss: 0.0966433
[Epoch 18; Iter   761/ 1097] train: loss: 0.0324592
[Epoch 18; Iter   791/ 1097] train: loss: 0.2426235
[Epoch 18; Iter   821/ 1097] train: loss: 0.1532314
[Epoch 18; Iter   851/ 1097] train: loss: 0.0257611
[Epoch 18; Iter   881/ 1097] train: loss: 0.1384501
[Epoch 18; Iter   911/ 1097] train: loss: 0.0308744
[Epoch 18; Iter   941/ 1097] train: loss: 0.1773916
[Epoch 18; Iter   971/ 1097] train: loss: 0.0916665
[Epoch 18; Iter  1001/ 1097] train: loss: 0.3736351
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0280968
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0315807
[Epoch 18; Iter  1091/ 1097] train: loss: 0.1794611
[Epoch 18] ogbg-molhiv: 0.796743 val loss: 0.129045
[Epoch 18] ogbg-molhiv: 0.785281 test loss: 0.134420
[Epoch 19; Iter    24/ 1097] train: loss: 0.0861362
[Epoch 19; Iter    54/ 1097] train: loss: 0.1856130
[Epoch 19; Iter    84/ 1097] train: loss: 0.1510133
[Epoch 19; Iter   114/ 1097] train: loss: 0.1800843
[Epoch 19; Iter   144/ 1097] train: loss: 0.1705113
[Epoch 19; Iter   174/ 1097] train: loss: 0.3692295
[Epoch 19; Iter   204/ 1097] train: loss: 0.0251437
[Epoch 19; Iter   234/ 1097] train: loss: 0.1666926
[Epoch 19; Iter   264/ 1097] train: loss: 0.0263670
[Epoch 19; Iter   294/ 1097] train: loss: 0.0159189
[Epoch 19; Iter   324/ 1097] train: loss: 0.0203755
[Epoch 19; Iter   354/ 1097] train: loss: 0.1743268
[Epoch 19; Iter   384/ 1097] train: loss: 0.2397235
[Epoch 19; Iter   414/ 1097] train: loss: 0.1634440
[Epoch 19; Iter   444/ 1097] train: loss: 0.2560658
[Epoch 19; Iter   474/ 1097] train: loss: 0.1779585
[Epoch 19; Iter   504/ 1097] train: loss: 0.3282275
[Epoch 19; Iter   534/ 1097] train: loss: 0.0974361
[Epoch 19; Iter   564/ 1097] train: loss: 0.2585903
[Epoch 19; Iter   594/ 1097] train: loss: 0.1303011
[Epoch 19; Iter   624/ 1097] train: loss: 0.3505673
[Epoch 19; Iter   654/ 1097] train: loss: 0.1894585
[Epoch 19; Iter   684/ 1097] train: loss: 0.0947027
[Epoch 19; Iter   714/ 1097] train: loss: 0.0850111
[Epoch 19; Iter   744/ 1097] train: loss: 0.0879772
[Epoch 19; Iter   774/ 1097] train: loss: 0.1534661
[Epoch 19; Iter   804/ 1097] train: loss: 0.1860593
[Epoch 19; Iter   834/ 1097] train: loss: 0.0428662
[Epoch 19; Iter   864/ 1097] train: loss: 0.0224193
[Epoch 19; Iter   894/ 1097] train: loss: 0.1987158
[Epoch 19; Iter   924/ 1097] train: loss: 0.1738051
[Epoch 19; Iter   954/ 1097] train: loss: 0.0283738
[Epoch 19; Iter   984/ 1097] train: loss: 0.1530246
[Epoch 19; Iter  1014/ 1097] train: loss: 0.0290882
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0731270
[Epoch 19; Iter  1074/ 1097] train: loss: 0.1683847
[Epoch 19] ogbg-molhiv: 0.811058 val loss: 0.150663
[Epoch 19] ogbg-molhiv: 0.792581 test loss: 0.226462
[Epoch 20; Iter     7/ 1097] train: loss: 0.0905445
[Epoch 20; Iter    37/ 1097] train: loss: 0.0303454
[Epoch 20; Iter    67/ 1097] train: loss: 0.0458215
[Epoch 20; Iter    97/ 1097] train: loss: 0.0216960
[Epoch 20; Iter   127/ 1097] train: loss: 0.0338128
[Epoch 20; Iter   157/ 1097] train: loss: 0.1759240
[Epoch 20; Iter   187/ 1097] train: loss: 0.0338072
[Epoch 20; Iter   217/ 1097] train: loss: 0.0653599
[Epoch 20; Iter   247/ 1097] train: loss: 0.0208082
[Epoch 20; Iter   277/ 1097] train: loss: 0.1285295
[Epoch 16; Iter   225/ 1097] train: loss: 0.3671047
[Epoch 16; Iter   255/ 1097] train: loss: 0.0277557
[Epoch 16; Iter   285/ 1097] train: loss: 0.0345538
[Epoch 16; Iter   315/ 1097] train: loss: 0.0496503
[Epoch 16; Iter   345/ 1097] train: loss: 0.2245128
[Epoch 16; Iter   375/ 1097] train: loss: 0.1962831
[Epoch 16; Iter   405/ 1097] train: loss: 0.0275842
[Epoch 16; Iter   435/ 1097] train: loss: 0.1261300
[Epoch 16; Iter   465/ 1097] train: loss: 0.0206911
[Epoch 16; Iter   495/ 1097] train: loss: 0.0418322
[Epoch 16; Iter   525/ 1097] train: loss: 0.1703052
[Epoch 16; Iter   555/ 1097] train: loss: 0.0693418
[Epoch 16; Iter   585/ 1097] train: loss: 0.0527333
[Epoch 16; Iter   615/ 1097] train: loss: 0.1698029
[Epoch 16; Iter   645/ 1097] train: loss: 0.0680599
[Epoch 16; Iter   675/ 1097] train: loss: 0.0226761
[Epoch 16; Iter   705/ 1097] train: loss: 0.0428456
[Epoch 16; Iter   735/ 1097] train: loss: 0.3427469
[Epoch 16; Iter   765/ 1097] train: loss: 0.0448724
[Epoch 16; Iter   795/ 1097] train: loss: 0.0266879
[Epoch 16; Iter   825/ 1097] train: loss: 0.1248735
[Epoch 16; Iter   855/ 1097] train: loss: 0.1422969
[Epoch 16; Iter   885/ 1097] train: loss: 0.0256295
[Epoch 16; Iter   915/ 1097] train: loss: 0.0271274
[Epoch 16; Iter   945/ 1097] train: loss: 0.0245800
[Epoch 16; Iter   975/ 1097] train: loss: 0.0230362
[Epoch 16; Iter  1005/ 1097] train: loss: 0.0603411
[Epoch 16; Iter  1035/ 1097] train: loss: 0.1484781
[Epoch 16; Iter  1065/ 1097] train: loss: 0.0532346
[Epoch 16; Iter  1095/ 1097] train: loss: 0.0257438
[Epoch 16] ogbg-molhiv: 0.787524 val loss: 0.142907
[Epoch 16] ogbg-molhiv: 0.800301 test loss: 0.124320
[Epoch 17; Iter    28/ 1097] train: loss: 0.0159105
[Epoch 17; Iter    58/ 1097] train: loss: 0.0161636
[Epoch 17; Iter    88/ 1097] train: loss: 0.0340461
[Epoch 17; Iter   118/ 1097] train: loss: 0.1475690
[Epoch 17; Iter   148/ 1097] train: loss: 0.0203350
[Epoch 17; Iter   178/ 1097] train: loss: 0.1938402
[Epoch 17; Iter   208/ 1097] train: loss: 0.0605942
[Epoch 17; Iter   238/ 1097] train: loss: 0.0452389
[Epoch 17; Iter   268/ 1097] train: loss: 0.0617448
[Epoch 17; Iter   298/ 1097] train: loss: 0.0278728
[Epoch 17; Iter   328/ 1097] train: loss: 0.2735287
[Epoch 17; Iter   358/ 1097] train: loss: 0.1011118
[Epoch 17; Iter   388/ 1097] train: loss: 0.0783755
[Epoch 17; Iter   418/ 1097] train: loss: 0.0282845
[Epoch 17; Iter   448/ 1097] train: loss: 0.0451003
[Epoch 17; Iter   478/ 1097] train: loss: 0.0484308
[Epoch 17; Iter   508/ 1097] train: loss: 0.1425778
[Epoch 17; Iter   538/ 1097] train: loss: 0.1905823
[Epoch 17; Iter   568/ 1097] train: loss: 0.0218519
[Epoch 17; Iter   598/ 1097] train: loss: 0.1196563
[Epoch 17; Iter   628/ 1097] train: loss: 0.2691730
[Epoch 17; Iter   658/ 1097] train: loss: 0.0631127
[Epoch 17; Iter   688/ 1097] train: loss: 0.1540142
[Epoch 17; Iter   718/ 1097] train: loss: 0.2830025
[Epoch 17; Iter   748/ 1097] train: loss: 0.2018598
[Epoch 17; Iter   778/ 1097] train: loss: 0.0387366
[Epoch 17; Iter   808/ 1097] train: loss: 0.3778622
[Epoch 17; Iter   838/ 1097] train: loss: 0.0390164
[Epoch 17; Iter   868/ 1097] train: loss: 0.2181503
[Epoch 17; Iter   898/ 1097] train: loss: 0.2321268
[Epoch 17; Iter   928/ 1097] train: loss: 0.0511095
[Epoch 17; Iter   958/ 1097] train: loss: 0.2904368
[Epoch 17; Iter   988/ 1097] train: loss: 0.0192596
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0274687
[Epoch 17; Iter  1048/ 1097] train: loss: 0.0309918
[Epoch 17; Iter  1078/ 1097] train: loss: 0.1303032
[Epoch 17] ogbg-molhiv: 0.783190 val loss: 0.581122
[Epoch 17] ogbg-molhiv: 0.788220 test loss: 0.239489
[Epoch 18; Iter    11/ 1097] train: loss: 0.0271769
[Epoch 18; Iter    41/ 1097] train: loss: 0.2669410
[Epoch 18; Iter    71/ 1097] train: loss: 0.0224307
[Epoch 18; Iter   101/ 1097] train: loss: 0.3375995
[Epoch 18; Iter   131/ 1097] train: loss: 0.0296958
[Epoch 18; Iter   161/ 1097] train: loss: 0.0341454
[Epoch 18; Iter   191/ 1097] train: loss: 0.0477724
[Epoch 18; Iter   221/ 1097] train: loss: 0.2520261
[Epoch 18; Iter   251/ 1097] train: loss: 0.1264473
[Epoch 18; Iter   281/ 1097] train: loss: 0.0328378
[Epoch 18; Iter   311/ 1097] train: loss: 0.0212251
[Epoch 18; Iter   341/ 1097] train: loss: 0.1001711
[Epoch 18; Iter   371/ 1097] train: loss: 0.1248651
[Epoch 18; Iter   401/ 1097] train: loss: 0.2153628
[Epoch 18; Iter   431/ 1097] train: loss: 0.1032720
[Epoch 18; Iter   461/ 1097] train: loss: 0.0216126
[Epoch 18; Iter   491/ 1097] train: loss: 0.0902579
[Epoch 18; Iter   521/ 1097] train: loss: 0.2575190
[Epoch 18; Iter   551/ 1097] train: loss: 0.0479306
[Epoch 18; Iter   581/ 1097] train: loss: 0.1299606
[Epoch 18; Iter   611/ 1097] train: loss: 0.0193372
[Epoch 18; Iter   641/ 1097] train: loss: 0.1689132
[Epoch 18; Iter   671/ 1097] train: loss: 0.0258944
[Epoch 18; Iter   701/ 1097] train: loss: 0.1184870
[Epoch 18; Iter   731/ 1097] train: loss: 0.0771022
[Epoch 18; Iter   761/ 1097] train: loss: 0.1635555
[Epoch 18; Iter   791/ 1097] train: loss: 0.1539299
[Epoch 18; Iter   821/ 1097] train: loss: 0.0837412
[Epoch 18; Iter   851/ 1097] train: loss: 0.1990008
[Epoch 18; Iter   881/ 1097] train: loss: 0.0214834
[Epoch 18; Iter   911/ 1097] train: loss: 0.0282387
[Epoch 18; Iter   941/ 1097] train: loss: 0.0935627
[Epoch 18; Iter   971/ 1097] train: loss: 0.0223994
[Epoch 18; Iter  1001/ 1097] train: loss: 0.0270917
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0563828
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0251602
[Epoch 18; Iter  1091/ 1097] train: loss: 0.0178345
[Epoch 18] ogbg-molhiv: 0.802437 val loss: 2.391064
[Epoch 18] ogbg-molhiv: 0.808683 test loss: 0.202961
[Epoch 19; Iter    24/ 1097] train: loss: 0.0376224
[Epoch 19; Iter    54/ 1097] train: loss: 0.0525351
[Epoch 19; Iter    84/ 1097] train: loss: 0.0433979
[Epoch 19; Iter   114/ 1097] train: loss: 0.0185734
[Epoch 19; Iter   144/ 1097] train: loss: 0.0530038
[Epoch 19; Iter   174/ 1097] train: loss: 0.0543399
[Epoch 19; Iter   204/ 1097] train: loss: 0.0612186
[Epoch 19; Iter   234/ 1097] train: loss: 0.1296143
[Epoch 19; Iter   264/ 1097] train: loss: 0.0611630
[Epoch 19; Iter   294/ 1097] train: loss: 0.0859228
[Epoch 19; Iter   324/ 1097] train: loss: 0.1860481
[Epoch 19; Iter   354/ 1097] train: loss: 0.0716623
[Epoch 19; Iter   384/ 1097] train: loss: 0.0892385
[Epoch 19; Iter   414/ 1097] train: loss: 0.0269694
[Epoch 19; Iter   444/ 1097] train: loss: 0.1339168
[Epoch 19; Iter   474/ 1097] train: loss: 0.0273734
[Epoch 19; Iter   504/ 1097] train: loss: 0.0836611
[Epoch 19; Iter   534/ 1097] train: loss: 0.0520561
[Epoch 19; Iter   564/ 1097] train: loss: 0.0995296
[Epoch 19; Iter   594/ 1097] train: loss: 0.1655211
[Epoch 19; Iter   624/ 1097] train: loss: 0.1505703
[Epoch 19; Iter   654/ 1097] train: loss: 0.2173798
[Epoch 19; Iter   684/ 1097] train: loss: 0.0251123
[Epoch 19; Iter   714/ 1097] train: loss: 0.2286606
[Epoch 19; Iter   744/ 1097] train: loss: 0.0362509
[Epoch 19; Iter   774/ 1097] train: loss: 0.0189184
[Epoch 19; Iter   804/ 1097] train: loss: 0.2781149
[Epoch 19; Iter   834/ 1097] train: loss: 0.0539128
[Epoch 19; Iter   864/ 1097] train: loss: 0.0185161
[Epoch 19; Iter   894/ 1097] train: loss: 0.0522808
[Epoch 19; Iter   924/ 1097] train: loss: 0.0730904
[Epoch 19; Iter   954/ 1097] train: loss: 0.1919619
[Epoch 19; Iter   984/ 1097] train: loss: 0.0817458
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1156525
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0221045
[Epoch 19; Iter  1074/ 1097] train: loss: 0.0337573
[Epoch 19] ogbg-molhiv: 0.793832 val loss: 0.257886
[Epoch 19] ogbg-molhiv: 0.810136 test loss: 0.120775
[Epoch 20; Iter     7/ 1097] train: loss: 0.0245458
[Epoch 20; Iter    37/ 1097] train: loss: 0.0513368
[Epoch 20; Iter    67/ 1097] train: loss: 0.1843063
[Epoch 20; Iter    97/ 1097] train: loss: 0.0291606
[Epoch 20; Iter   127/ 1097] train: loss: 0.0673406
[Epoch 20; Iter   157/ 1097] train: loss: 0.0503904
[Epoch 20; Iter   187/ 1097] train: loss: 0.3038131
[Epoch 20; Iter   217/ 1097] train: loss: 0.0405997
[Epoch 20; Iter   247/ 1097] train: loss: 0.0693294
[Epoch 20; Iter   277/ 1097] train: loss: 0.2042564
[Epoch 16; Iter   225/ 1097] train: loss: 0.0512221
[Epoch 16; Iter   255/ 1097] train: loss: 0.0186905
[Epoch 16; Iter   285/ 1097] train: loss: 0.0699711
[Epoch 16; Iter   315/ 1097] train: loss: 0.0291398
[Epoch 16; Iter   345/ 1097] train: loss: 0.2673361
[Epoch 16; Iter   375/ 1097] train: loss: 0.1823317
[Epoch 16; Iter   405/ 1097] train: loss: 0.0210403
[Epoch 16; Iter   435/ 1097] train: loss: 0.1431685
[Epoch 16; Iter   465/ 1097] train: loss: 0.0265138
[Epoch 16; Iter   495/ 1097] train: loss: 0.0277914
[Epoch 16; Iter   525/ 1097] train: loss: 0.0184184
[Epoch 16; Iter   555/ 1097] train: loss: 0.0397592
[Epoch 16; Iter   585/ 1097] train: loss: 0.2988469
[Epoch 16; Iter   615/ 1097] train: loss: 0.1517033
[Epoch 16; Iter   645/ 1097] train: loss: 0.3235044
[Epoch 16; Iter   675/ 1097] train: loss: 0.1666055
[Epoch 16; Iter   705/ 1097] train: loss: 0.1256110
[Epoch 16; Iter   735/ 1097] train: loss: 0.0223603
[Epoch 16; Iter   765/ 1097] train: loss: 0.0251194
[Epoch 16; Iter   795/ 1097] train: loss: 0.0286313
[Epoch 16; Iter   825/ 1097] train: loss: 0.1754639
[Epoch 16; Iter   855/ 1097] train: loss: 0.0538106
[Epoch 16; Iter   885/ 1097] train: loss: 0.0266429
[Epoch 16; Iter   915/ 1097] train: loss: 0.1435098
[Epoch 16; Iter   945/ 1097] train: loss: 0.0237579
[Epoch 16; Iter   975/ 1097] train: loss: 0.2314828
[Epoch 16; Iter  1005/ 1097] train: loss: 0.0278734
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0445148
[Epoch 16; Iter  1065/ 1097] train: loss: 0.1753072
[Epoch 16; Iter  1095/ 1097] train: loss: 0.0408704
[Epoch 16] ogbg-molhiv: 0.801091 val loss: 0.134149
[Epoch 16] ogbg-molhiv: 0.798992 test loss: 0.117179
[Epoch 17; Iter    28/ 1097] train: loss: 0.1092844
[Epoch 17; Iter    58/ 1097] train: loss: 0.0959237
[Epoch 17; Iter    88/ 1097] train: loss: 0.0239176
[Epoch 17; Iter   118/ 1097] train: loss: 0.1145616
[Epoch 17; Iter   148/ 1097] train: loss: 0.0259322
[Epoch 17; Iter   178/ 1097] train: loss: 0.0452938
[Epoch 17; Iter   208/ 1097] train: loss: 0.2093488
[Epoch 17; Iter   238/ 1097] train: loss: 0.1107477
[Epoch 17; Iter   268/ 1097] train: loss: 0.0183919
[Epoch 17; Iter   298/ 1097] train: loss: 0.0981239
[Epoch 17; Iter   328/ 1097] train: loss: 0.1154875
[Epoch 17; Iter   358/ 1097] train: loss: 0.1703189
[Epoch 17; Iter   388/ 1097] train: loss: 0.1705615
[Epoch 17; Iter   418/ 1097] train: loss: 0.1358035
[Epoch 17; Iter   448/ 1097] train: loss: 0.0167694
[Epoch 17; Iter   478/ 1097] train: loss: 0.0206150
[Epoch 17; Iter   508/ 1097] train: loss: 0.3379155
[Epoch 17; Iter   538/ 1097] train: loss: 0.5236665
[Epoch 17; Iter   568/ 1097] train: loss: 0.0508748
[Epoch 17; Iter   598/ 1097] train: loss: 0.0274378
[Epoch 17; Iter   628/ 1097] train: loss: 0.1590197
[Epoch 17; Iter   658/ 1097] train: loss: 0.2157794
[Epoch 17; Iter   688/ 1097] train: loss: 0.1773909
[Epoch 17; Iter   718/ 1097] train: loss: 0.0222076
[Epoch 17; Iter   748/ 1097] train: loss: 0.1648270
[Epoch 17; Iter   778/ 1097] train: loss: 0.0176408
[Epoch 17; Iter   808/ 1097] train: loss: 0.3249273
[Epoch 17; Iter   838/ 1097] train: loss: 0.0633380
[Epoch 17; Iter   868/ 1097] train: loss: 0.0243176
[Epoch 17; Iter   898/ 1097] train: loss: 0.0319844
[Epoch 17; Iter   928/ 1097] train: loss: 0.1459002
[Epoch 17; Iter   958/ 1097] train: loss: 0.0341823
[Epoch 17; Iter   988/ 1097] train: loss: 0.1060152
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0272103
[Epoch 17; Iter  1048/ 1097] train: loss: 0.0897749
[Epoch 17; Iter  1078/ 1097] train: loss: 0.2205853
[Epoch 17] ogbg-molhiv: 0.810064 val loss: 0.113851
[Epoch 17] ogbg-molhiv: 0.807029 test loss: 0.109703
[Epoch 18; Iter    11/ 1097] train: loss: 0.2812588
[Epoch 18; Iter    41/ 1097] train: loss: 0.0370760
[Epoch 18; Iter    71/ 1097] train: loss: 0.1780622
[Epoch 18; Iter   101/ 1097] train: loss: 0.1271176
[Epoch 18; Iter   131/ 1097] train: loss: 0.0211332
[Epoch 18; Iter   161/ 1097] train: loss: 0.0531541
[Epoch 18; Iter   191/ 1097] train: loss: 0.1708405
[Epoch 18; Iter   221/ 1097] train: loss: 0.0782345
[Epoch 18; Iter   251/ 1097] train: loss: 0.2865854
[Epoch 18; Iter   281/ 1097] train: loss: 0.0335424
[Epoch 18; Iter   311/ 1097] train: loss: 0.1196931
[Epoch 18; Iter   341/ 1097] train: loss: 0.3357638
[Epoch 18; Iter   371/ 1097] train: loss: 0.0767745
[Epoch 18; Iter   401/ 1097] train: loss: 0.0377818
[Epoch 18; Iter   431/ 1097] train: loss: 0.4043764
[Epoch 18; Iter   461/ 1097] train: loss: 0.2024724
[Epoch 18; Iter   491/ 1097] train: loss: 0.2270652
[Epoch 18; Iter   521/ 1097] train: loss: 0.2276321
[Epoch 18; Iter   551/ 1097] train: loss: 0.0698827
[Epoch 18; Iter   581/ 1097] train: loss: 0.1130097
[Epoch 18; Iter   611/ 1097] train: loss: 0.0231214
[Epoch 18; Iter   641/ 1097] train: loss: 0.0421533
[Epoch 18; Iter   671/ 1097] train: loss: 0.0248911
[Epoch 18; Iter   701/ 1097] train: loss: 0.1597864
[Epoch 18; Iter   731/ 1097] train: loss: 0.1410041
[Epoch 18; Iter   761/ 1097] train: loss: 0.0301082
[Epoch 18; Iter   791/ 1097] train: loss: 0.0283941
[Epoch 18; Iter   821/ 1097] train: loss: 0.0326800
[Epoch 18; Iter   851/ 1097] train: loss: 0.0196418
[Epoch 18; Iter   881/ 1097] train: loss: 0.0834011
[Epoch 18; Iter   911/ 1097] train: loss: 0.0196690
[Epoch 18; Iter   941/ 1097] train: loss: 0.0411895
[Epoch 18; Iter   971/ 1097] train: loss: 0.2529361
[Epoch 18; Iter  1001/ 1097] train: loss: 0.1039434
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0511024
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0214796
[Epoch 18; Iter  1091/ 1097] train: loss: 0.3696318
[Epoch 18] ogbg-molhiv: 0.810342 val loss: 0.118979
[Epoch 18] ogbg-molhiv: 0.810887 test loss: 0.175414
[Epoch 19; Iter    24/ 1097] train: loss: 0.0311387
[Epoch 19; Iter    54/ 1097] train: loss: 0.2158186
[Epoch 19; Iter    84/ 1097] train: loss: 0.2693790
[Epoch 19; Iter   114/ 1097] train: loss: 0.1691553
[Epoch 19; Iter   144/ 1097] train: loss: 0.0217696
[Epoch 19; Iter   174/ 1097] train: loss: 0.1800233
[Epoch 19; Iter   204/ 1097] train: loss: 0.2459042
[Epoch 19; Iter   234/ 1097] train: loss: 0.0236217
[Epoch 19; Iter   264/ 1097] train: loss: 0.0149189
[Epoch 19; Iter   294/ 1097] train: loss: 0.1751685
[Epoch 19; Iter   324/ 1097] train: loss: 0.0780856
[Epoch 19; Iter   354/ 1097] train: loss: 0.1923053
[Epoch 19; Iter   384/ 1097] train: loss: 0.0334508
[Epoch 19; Iter   414/ 1097] train: loss: 0.0513656
[Epoch 19; Iter   444/ 1097] train: loss: 0.3060514
[Epoch 19; Iter   474/ 1097] train: loss: 0.1185436
[Epoch 19; Iter   504/ 1097] train: loss: 0.0259038
[Epoch 19; Iter   534/ 1097] train: loss: 0.0506021
[Epoch 19; Iter   564/ 1097] train: loss: 0.0235048
[Epoch 19; Iter   594/ 1097] train: loss: 0.1404323
[Epoch 19; Iter   624/ 1097] train: loss: 0.2071328
[Epoch 19; Iter   654/ 1097] train: loss: 0.0530843
[Epoch 19; Iter   684/ 1097] train: loss: 0.1947575
[Epoch 19; Iter   714/ 1097] train: loss: 0.0869625
[Epoch 19; Iter   744/ 1097] train: loss: 0.0454549
[Epoch 19; Iter   774/ 1097] train: loss: 0.0675104
[Epoch 19; Iter   804/ 1097] train: loss: 0.1421026
[Epoch 19; Iter   834/ 1097] train: loss: 0.1479063
[Epoch 19; Iter   864/ 1097] train: loss: 0.1897637
[Epoch 19; Iter   894/ 1097] train: loss: 0.1838715
[Epoch 19; Iter   924/ 1097] train: loss: 0.3494755
[Epoch 19; Iter   954/ 1097] train: loss: 0.0825685
[Epoch 19; Iter   984/ 1097] train: loss: 0.0308456
[Epoch 19; Iter  1014/ 1097] train: loss: 0.0193200
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0568312
[Epoch 19; Iter  1074/ 1097] train: loss: 0.0202155
[Epoch 19] ogbg-molhiv: 0.802022 val loss: 0.119406
[Epoch 19] ogbg-molhiv: 0.809803 test loss: 0.113156
[Epoch 20; Iter     7/ 1097] train: loss: 0.0261757
[Epoch 20; Iter    37/ 1097] train: loss: 0.0193325
[Epoch 20; Iter    67/ 1097] train: loss: 0.0525746
[Epoch 20; Iter    97/ 1097] train: loss: 0.0357714
[Epoch 20; Iter   127/ 1097] train: loss: 0.0316957
[Epoch 20; Iter   157/ 1097] train: loss: 0.0432246
[Epoch 20; Iter   187/ 1097] train: loss: 0.1596945
[Epoch 20; Iter   217/ 1097] train: loss: 0.0378752
[Epoch 20; Iter   247/ 1097] train: loss: 0.1664248
[Epoch 20; Iter   277/ 1097] train: loss: 0.0382553
[Epoch 18; Iter   240/  960] train: loss: 0.0468850
[Epoch 18; Iter   270/  960] train: loss: 0.0230542
[Epoch 18; Iter   300/  960] train: loss: 0.0226362
[Epoch 18; Iter   330/  960] train: loss: 0.1556530
[Epoch 18; Iter   360/  960] train: loss: 0.0216987
[Epoch 18; Iter   390/  960] train: loss: 0.1389694
[Epoch 18; Iter   420/  960] train: loss: 0.3309828
[Epoch 18; Iter   450/  960] train: loss: 0.0556283
[Epoch 18; Iter   480/  960] train: loss: 0.0820511
[Epoch 18; Iter   510/  960] train: loss: 0.2060333
[Epoch 18; Iter   540/  960] train: loss: 0.0411706
[Epoch 18; Iter   570/  960] train: loss: 0.2462293
[Epoch 18; Iter   600/  960] train: loss: 0.1086833
[Epoch 18; Iter   630/  960] train: loss: 0.0199150
[Epoch 18; Iter   660/  960] train: loss: 0.0951696
[Epoch 18; Iter   690/  960] train: loss: 0.1171674
[Epoch 18; Iter   720/  960] train: loss: 0.0257788
[Epoch 18; Iter   750/  960] train: loss: 0.0457169
[Epoch 18; Iter   780/  960] train: loss: 0.0351585
[Epoch 18; Iter   810/  960] train: loss: 0.0441982
[Epoch 18; Iter   840/  960] train: loss: 0.0263355
[Epoch 18; Iter   870/  960] train: loss: 0.0340537
[Epoch 18; Iter   900/  960] train: loss: 0.0284334
[Epoch 18; Iter   930/  960] train: loss: 0.1978080
[Epoch 18; Iter   960/  960] train: loss: 0.0479606
[Epoch 18] ogbg-molhiv: 0.801435 val loss: 0.121356
[Epoch 18] ogbg-molhiv: 0.829243 test loss: 0.113030
[Epoch 19; Iter    30/  960] train: loss: 0.0335614
[Epoch 19; Iter    60/  960] train: loss: 0.0536442
[Epoch 19; Iter    90/  960] train: loss: 0.0205091
[Epoch 19; Iter   120/  960] train: loss: 0.0358180
[Epoch 19; Iter   150/  960] train: loss: 0.1419016
[Epoch 19; Iter   180/  960] train: loss: 0.0168417
[Epoch 19; Iter   210/  960] train: loss: 0.0153819
[Epoch 19; Iter   240/  960] train: loss: 0.1990021
[Epoch 19; Iter   270/  960] train: loss: 0.2892865
[Epoch 19; Iter   300/  960] train: loss: 0.2235698
[Epoch 19; Iter   330/  960] train: loss: 0.0517374
[Epoch 19; Iter   360/  960] train: loss: 0.0314916
[Epoch 19; Iter   390/  960] train: loss: 0.2411254
[Epoch 19; Iter   420/  960] train: loss: 0.0165397
[Epoch 19; Iter   450/  960] train: loss: 0.0354723
[Epoch 19; Iter   480/  960] train: loss: 0.0355842
[Epoch 19; Iter   510/  960] train: loss: 0.0137236
[Epoch 19; Iter   540/  960] train: loss: 0.1369087
[Epoch 19; Iter   570/  960] train: loss: 0.0154957
[Epoch 19; Iter   600/  960] train: loss: 0.0159791
[Epoch 19; Iter   630/  960] train: loss: 0.1860279
[Epoch 19; Iter   660/  960] train: loss: 0.1189797
[Epoch 19; Iter   690/  960] train: loss: 0.0215235
[Epoch 19; Iter   720/  960] train: loss: 0.1105979
[Epoch 19; Iter   750/  960] train: loss: 0.4280934
[Epoch 19; Iter   780/  960] train: loss: 0.0305333
[Epoch 19; Iter   810/  960] train: loss: 0.0685780
[Epoch 19; Iter   840/  960] train: loss: 0.0625757
[Epoch 19; Iter   870/  960] train: loss: 0.1260894
[Epoch 19; Iter   900/  960] train: loss: 0.2635408
[Epoch 19; Iter   930/  960] train: loss: 0.0399124
[Epoch 19; Iter   960/  960] train: loss: 0.2588939
[Epoch 19] ogbg-molhiv: 0.820819 val loss: 0.121329
[Epoch 19] ogbg-molhiv: 0.826283 test loss: 0.115792
[Epoch 20; Iter    30/  960] train: loss: 0.2478609
[Epoch 20; Iter    60/  960] train: loss: 0.1676786
[Epoch 20; Iter    90/  960] train: loss: 0.3395260
[Epoch 20; Iter   120/  960] train: loss: 0.0275190
[Epoch 20; Iter   150/  960] train: loss: 0.0254877
[Epoch 20; Iter   180/  960] train: loss: 0.4735001
[Epoch 20; Iter   210/  960] train: loss: 0.0453776
[Epoch 20; Iter   240/  960] train: loss: 0.0351800
[Epoch 20; Iter   270/  960] train: loss: 0.1273411
[Epoch 20; Iter   300/  960] train: loss: 0.0235666
[Epoch 20; Iter   330/  960] train: loss: 0.1523160
[Epoch 20; Iter   360/  960] train: loss: 0.3419992
[Epoch 20; Iter   390/  960] train: loss: 0.0372622
[Epoch 20; Iter   420/  960] train: loss: 0.0331115
[Epoch 20; Iter   450/  960] train: loss: 0.0361801
[Epoch 20; Iter   480/  960] train: loss: 0.1384222
[Epoch 20; Iter   510/  960] train: loss: 0.0147372
[Epoch 20; Iter   540/  960] train: loss: 0.0326055
[Epoch 20; Iter   570/  960] train: loss: 0.0561038
[Epoch 20; Iter   600/  960] train: loss: 0.0163394
[Epoch 20; Iter   630/  960] train: loss: 0.0179384
[Epoch 20; Iter   660/  960] train: loss: 0.0989505
[Epoch 20; Iter   690/  960] train: loss: 0.0721758
[Epoch 20; Iter   720/  960] train: loss: 0.0730455
[Epoch 20; Iter   750/  960] train: loss: 0.0164078
[Epoch 20; Iter   780/  960] train: loss: 0.0129286
[Epoch 20; Iter   810/  960] train: loss: 0.2487349
[Epoch 20; Iter   840/  960] train: loss: 0.1970464
[Epoch 20; Iter   870/  960] train: loss: 0.0432789
[Epoch 20; Iter   900/  960] train: loss: 0.1077560
[Epoch 20; Iter   930/  960] train: loss: 0.1344355
[Epoch 20; Iter   960/  960] train: loss: 0.1904753
[Epoch 20] ogbg-molhiv: 0.815348 val loss: 0.148453
[Epoch 20] ogbg-molhiv: 0.819655 test loss: 0.117647
[Epoch 21; Iter    30/  960] train: loss: 0.0260019
[Epoch 21; Iter    60/  960] train: loss: 0.0227113
[Epoch 21; Iter    90/  960] train: loss: 0.0955354
[Epoch 21; Iter   120/  960] train: loss: 0.2461615
[Epoch 21; Iter   150/  960] train: loss: 0.0165146
[Epoch 21; Iter   180/  960] train: loss: 0.2166236
[Epoch 21; Iter   210/  960] train: loss: 0.3122603
[Epoch 21; Iter   240/  960] train: loss: 0.0225256
[Epoch 21; Iter   270/  960] train: loss: 0.0248218
[Epoch 21; Iter   300/  960] train: loss: 0.0341290
[Epoch 21; Iter   330/  960] train: loss: 0.0168736
[Epoch 21; Iter   360/  960] train: loss: 0.0560724
[Epoch 21; Iter   390/  960] train: loss: 0.1007481
[Epoch 21; Iter   420/  960] train: loss: 0.2087618
[Epoch 21; Iter   450/  960] train: loss: 0.0234107
[Epoch 21; Iter   480/  960] train: loss: 0.1756100
[Epoch 21; Iter   510/  960] train: loss: 0.0281147
[Epoch 21; Iter   540/  960] train: loss: 0.0154591
[Epoch 21; Iter   570/  960] train: loss: 0.0712070
[Epoch 21; Iter   600/  960] train: loss: 0.0654696
[Epoch 21; Iter   630/  960] train: loss: 0.2744654
[Epoch 21; Iter   660/  960] train: loss: 0.0224398
[Epoch 21; Iter   690/  960] train: loss: 0.1876355
[Epoch 21; Iter   720/  960] train: loss: 0.0569614
[Epoch 21; Iter   750/  960] train: loss: 0.2009934
[Epoch 21; Iter   780/  960] train: loss: 0.1597309
[Epoch 21; Iter   810/  960] train: loss: 0.0257764
[Epoch 21; Iter   840/  960] train: loss: 0.1316623
[Epoch 21; Iter   870/  960] train: loss: 0.2611566
[Epoch 21; Iter   900/  960] train: loss: 0.0388664
[Epoch 21; Iter   930/  960] train: loss: 0.1768184
[Epoch 21; Iter   960/  960] train: loss: 0.6129606
[Epoch 21] ogbg-molhiv: 0.799816 val loss: 0.122410
[Epoch 21] ogbg-molhiv: 0.815200 test loss: 0.126536
[Epoch 22; Iter    30/  960] train: loss: 0.2100565
[Epoch 22; Iter    60/  960] train: loss: 0.0322326
[Epoch 22; Iter    90/  960] train: loss: 0.2199204
[Epoch 22; Iter   120/  960] train: loss: 0.2846581
[Epoch 22; Iter   150/  960] train: loss: 0.0276340
[Epoch 22; Iter   180/  960] train: loss: 0.0286202
[Epoch 22; Iter   210/  960] train: loss: 0.0252485
[Epoch 22; Iter   240/  960] train: loss: 0.0909138
[Epoch 22; Iter   270/  960] train: loss: 0.0120693
[Epoch 22; Iter   300/  960] train: loss: 0.0342125
[Epoch 22; Iter   330/  960] train: loss: 0.0243249
[Epoch 22; Iter   360/  960] train: loss: 0.0198553
[Epoch 22; Iter   390/  960] train: loss: 0.0849288
[Epoch 22; Iter   420/  960] train: loss: 0.0621963
[Epoch 22; Iter   450/  960] train: loss: 0.1612101
[Epoch 22; Iter   480/  960] train: loss: 0.0180587
[Epoch 22; Iter   510/  960] train: loss: 0.2234426
[Epoch 22; Iter   540/  960] train: loss: 0.0676653
[Epoch 22; Iter   570/  960] train: loss: 0.0273657
[Epoch 22; Iter   600/  960] train: loss: 0.0158229
[Epoch 22; Iter   630/  960] train: loss: 0.0232207
[Epoch 22; Iter   660/  960] train: loss: 0.0211860
[Epoch 22; Iter   690/  960] train: loss: 0.1053840
[Epoch 22; Iter   720/  960] train: loss: 0.0590875
[Epoch 22; Iter   750/  960] train: loss: 0.0966746
[Epoch 22; Iter   780/  960] train: loss: 0.1564700
[Epoch 22; Iter   810/  960] train: loss: 0.1588188
[Epoch 22; Iter   840/  960] train: loss: 0.1918058
[Epoch 18; Iter   240/  960] train: loss: 0.0287136
[Epoch 18; Iter   270/  960] train: loss: 0.1087296
[Epoch 18; Iter   300/  960] train: loss: 0.0381382
[Epoch 18; Iter   330/  960] train: loss: 0.0231889
[Epoch 18; Iter   360/  960] train: loss: 0.0289399
[Epoch 18; Iter   390/  960] train: loss: 0.1861240
[Epoch 18; Iter   420/  960] train: loss: 0.0363362
[Epoch 18; Iter   450/  960] train: loss: 0.0237485
[Epoch 18; Iter   480/  960] train: loss: 0.0207914
[Epoch 18; Iter   510/  960] train: loss: 0.0169219
[Epoch 18; Iter   540/  960] train: loss: 0.2306813
[Epoch 18; Iter   570/  960] train: loss: 0.1635327
[Epoch 18; Iter   600/  960] train: loss: 0.0891684
[Epoch 18; Iter   630/  960] train: loss: 0.1828002
[Epoch 18; Iter   660/  960] train: loss: 0.0859714
[Epoch 18; Iter   690/  960] train: loss: 0.0497460
[Epoch 18; Iter   720/  960] train: loss: 0.0468010
[Epoch 18; Iter   750/  960] train: loss: 0.0340347
[Epoch 18; Iter   780/  960] train: loss: 0.0696416
[Epoch 18; Iter   810/  960] train: loss: 0.0285239
[Epoch 18; Iter   840/  960] train: loss: 0.0342745
[Epoch 18; Iter   870/  960] train: loss: 0.0251133
[Epoch 18; Iter   900/  960] train: loss: 0.0337639
[Epoch 18; Iter   930/  960] train: loss: 0.0200729
[Epoch 18; Iter   960/  960] train: loss: 0.0549885
[Epoch 18] ogbg-molhiv: 0.783152 val loss: 0.137385
[Epoch 18] ogbg-molhiv: 0.797496 test loss: 0.119631
[Epoch 19; Iter    30/  960] train: loss: 0.2390428
[Epoch 19; Iter    60/  960] train: loss: 0.0276194
[Epoch 19; Iter    90/  960] train: loss: 0.0683965
[Epoch 19; Iter   120/  960] train: loss: 0.1010955
[Epoch 19; Iter   150/  960] train: loss: 0.0423387
[Epoch 19; Iter   180/  960] train: loss: 0.0164413
[Epoch 19; Iter   210/  960] train: loss: 0.0282073
[Epoch 19; Iter   240/  960] train: loss: 0.1129643
[Epoch 19; Iter   270/  960] train: loss: 0.0199116
[Epoch 19; Iter   300/  960] train: loss: 0.0274200
[Epoch 19; Iter   330/  960] train: loss: 0.0533698
[Epoch 19; Iter   360/  960] train: loss: 0.0629924
[Epoch 19; Iter   390/  960] train: loss: 0.0867241
[Epoch 19; Iter   420/  960] train: loss: 0.1711989
[Epoch 19; Iter   450/  960] train: loss: 0.1795729
[Epoch 19; Iter   480/  960] train: loss: 0.3495167
[Epoch 19; Iter   510/  960] train: loss: 0.1213843
[Epoch 19; Iter   540/  960] train: loss: 0.0447677
[Epoch 19; Iter   570/  960] train: loss: 0.2698700
[Epoch 19; Iter   600/  960] train: loss: 0.1500039
[Epoch 19; Iter   630/  960] train: loss: 0.2720294
[Epoch 19; Iter   660/  960] train: loss: 0.1223992
[Epoch 19; Iter   690/  960] train: loss: 0.0286808
[Epoch 19; Iter   720/  960] train: loss: 0.0610674
[Epoch 19; Iter   750/  960] train: loss: 0.1560680
[Epoch 19; Iter   780/  960] train: loss: 0.0235802
[Epoch 19; Iter   810/  960] train: loss: 0.1191878
[Epoch 19; Iter   840/  960] train: loss: 0.0433281
[Epoch 19; Iter   870/  960] train: loss: 0.2105974
[Epoch 19; Iter   900/  960] train: loss: 0.0230952
[Epoch 19; Iter   930/  960] train: loss: 0.0238681
[Epoch 19; Iter   960/  960] train: loss: 0.8496305
[Epoch 19] ogbg-molhiv: 0.801642 val loss: 0.126330
[Epoch 19] ogbg-molhiv: 0.785925 test loss: 0.119457
[Epoch 20; Iter    30/  960] train: loss: 0.1820187
[Epoch 20; Iter    60/  960] train: loss: 0.0296918
[Epoch 20; Iter    90/  960] train: loss: 0.1497561
[Epoch 20; Iter   120/  960] train: loss: 0.0587202
[Epoch 20; Iter   150/  960] train: loss: 0.1601364
[Epoch 20; Iter   180/  960] train: loss: 0.0594764
[Epoch 20; Iter   210/  960] train: loss: 0.0620005
[Epoch 20; Iter   240/  960] train: loss: 0.0189479
[Epoch 20; Iter   270/  960] train: loss: 0.0430349
[Epoch 20; Iter   300/  960] train: loss: 0.0265522
[Epoch 20; Iter   330/  960] train: loss: 0.0359717
[Epoch 20; Iter   360/  960] train: loss: 0.1329617
[Epoch 20; Iter   390/  960] train: loss: 0.2379933
[Epoch 20; Iter   420/  960] train: loss: 0.0757973
[Epoch 20; Iter   450/  960] train: loss: 0.2648780
[Epoch 20; Iter   480/  960] train: loss: 0.2491026
[Epoch 20; Iter   510/  960] train: loss: 0.0195345
[Epoch 20; Iter   540/  960] train: loss: 0.2392846
[Epoch 20; Iter   570/  960] train: loss: 0.0216675
[Epoch 20; Iter   600/  960] train: loss: 0.1658642
[Epoch 20; Iter   630/  960] train: loss: 0.1727515
[Epoch 20; Iter   660/  960] train: loss: 0.0420675
[Epoch 20; Iter   690/  960] train: loss: 0.0335328
[Epoch 20; Iter   720/  960] train: loss: 0.0522312
[Epoch 20; Iter   750/  960] train: loss: 0.1617698
[Epoch 20; Iter   780/  960] train: loss: 0.0629552
[Epoch 20; Iter   810/  960] train: loss: 0.0307149
[Epoch 20; Iter   840/  960] train: loss: 0.0198637
[Epoch 20; Iter   870/  960] train: loss: 0.0928766
[Epoch 20; Iter   900/  960] train: loss: 0.0386813
[Epoch 20; Iter   930/  960] train: loss: 0.1111295
[Epoch 20; Iter   960/  960] train: loss: 0.0186680
[Epoch 20] ogbg-molhiv: 0.798753 val loss: 0.384897
[Epoch 20] ogbg-molhiv: 0.810556 test loss: 0.375322
[Epoch 21; Iter    30/  960] train: loss: 0.2108748
[Epoch 21; Iter    60/  960] train: loss: 0.1610269
[Epoch 21; Iter    90/  960] train: loss: 0.0631820
[Epoch 21; Iter   120/  960] train: loss: 0.0271539
[Epoch 21; Iter   150/  960] train: loss: 0.0407905
[Epoch 21; Iter   180/  960] train: loss: 0.0611999
[Epoch 21; Iter   210/  960] train: loss: 0.1142264
[Epoch 21; Iter   240/  960] train: loss: 0.1210933
[Epoch 21; Iter   270/  960] train: loss: 0.1572397
[Epoch 21; Iter   300/  960] train: loss: 0.2059927
[Epoch 21; Iter   330/  960] train: loss: 0.0290565
[Epoch 21; Iter   360/  960] train: loss: 0.0272325
[Epoch 21; Iter   390/  960] train: loss: 0.1153147
[Epoch 21; Iter   420/  960] train: loss: 0.1503892
[Epoch 21; Iter   450/  960] train: loss: 0.0287471
[Epoch 21; Iter   480/  960] train: loss: 0.1984224
[Epoch 21; Iter   510/  960] train: loss: 0.0210259
[Epoch 21; Iter   540/  960] train: loss: 0.0235374
[Epoch 21; Iter   570/  960] train: loss: 0.2150481
[Epoch 21; Iter   600/  960] train: loss: 0.0559811
[Epoch 21; Iter   630/  960] train: loss: 0.0489001
[Epoch 21; Iter   660/  960] train: loss: 0.0388844
[Epoch 21; Iter   690/  960] train: loss: 0.0383751
[Epoch 21; Iter   720/  960] train: loss: 0.0975262
[Epoch 21; Iter   750/  960] train: loss: 0.0542899
[Epoch 21; Iter   780/  960] train: loss: 0.0737247
[Epoch 21; Iter   810/  960] train: loss: 0.0516852
[Epoch 21; Iter   840/  960] train: loss: 0.3905977
[Epoch 21; Iter   870/  960] train: loss: 0.0244642
[Epoch 21; Iter   900/  960] train: loss: 0.0393511
[Epoch 21; Iter   930/  960] train: loss: 0.0331235
[Epoch 21; Iter   960/  960] train: loss: 0.0407362
[Epoch 21] ogbg-molhiv: 0.785194 val loss: 0.196941
[Epoch 21] ogbg-molhiv: 0.799347 test loss: 0.116749
[Epoch 22; Iter    30/  960] train: loss: 0.0694149
[Epoch 22; Iter    60/  960] train: loss: 0.0942876
[Epoch 22; Iter    90/  960] train: loss: 0.0666599
[Epoch 22; Iter   120/  960] train: loss: 0.1761118
[Epoch 22; Iter   150/  960] train: loss: 0.0281020
[Epoch 22; Iter   180/  960] train: loss: 0.0463605
[Epoch 22; Iter   210/  960] train: loss: 0.0232385
[Epoch 22; Iter   240/  960] train: loss: 0.0451464
[Epoch 22; Iter   270/  960] train: loss: 0.0219845
[Epoch 22; Iter   300/  960] train: loss: 0.1190035
[Epoch 22; Iter   330/  960] train: loss: 0.1545574
[Epoch 22; Iter   360/  960] train: loss: 0.2126024
[Epoch 22; Iter   390/  960] train: loss: 0.0285343
[Epoch 22; Iter   420/  960] train: loss: 0.0186190
[Epoch 22; Iter   450/  960] train: loss: 0.0343033
[Epoch 22; Iter   480/  960] train: loss: 0.1703192
[Epoch 22; Iter   510/  960] train: loss: 0.0233696
[Epoch 22; Iter   540/  960] train: loss: 0.1172384
[Epoch 22; Iter   570/  960] train: loss: 0.0330704
[Epoch 22; Iter   600/  960] train: loss: 0.0741120
[Epoch 22; Iter   630/  960] train: loss: 0.0331811
[Epoch 22; Iter   660/  960] train: loss: 0.0364621
[Epoch 22; Iter   690/  960] train: loss: 0.1528220
[Epoch 22; Iter   720/  960] train: loss: 0.0228550
[Epoch 22; Iter   750/  960] train: loss: 0.0907131
[Epoch 22; Iter   780/  960] train: loss: 0.0237808
[Epoch 22; Iter   810/  960] train: loss: 0.2440223
[Epoch 22; Iter   840/  960] train: loss: 0.0193000
[Epoch 18; Iter   240/  960] train: loss: 0.0247647
[Epoch 18; Iter   270/  960] train: loss: 0.0257720
[Epoch 18; Iter   300/  960] train: loss: 0.1882159
[Epoch 18; Iter   330/  960] train: loss: 0.0596560
[Epoch 18; Iter   360/  960] train: loss: 0.0978503
[Epoch 18; Iter   390/  960] train: loss: 0.0175048
[Epoch 18; Iter   420/  960] train: loss: 0.0199178
[Epoch 18; Iter   450/  960] train: loss: 0.0675190
[Epoch 18; Iter   480/  960] train: loss: 0.0161625
[Epoch 18; Iter   510/  960] train: loss: 0.3587433
[Epoch 18; Iter   540/  960] train: loss: 0.5542873
[Epoch 18; Iter   570/  960] train: loss: 0.0425730
[Epoch 18; Iter   600/  960] train: loss: 0.1822483
[Epoch 18; Iter   630/  960] train: loss: 0.1578859
[Epoch 18; Iter   660/  960] train: loss: 0.0697939
[Epoch 18; Iter   690/  960] train: loss: 0.0318296
[Epoch 18; Iter   720/  960] train: loss: 0.2180656
[Epoch 18; Iter   750/  960] train: loss: 0.0318055
[Epoch 18; Iter   780/  960] train: loss: 0.2580468
[Epoch 18; Iter   810/  960] train: loss: 0.1046266
[Epoch 18; Iter   840/  960] train: loss: 0.0809193
[Epoch 18; Iter   870/  960] train: loss: 0.0480961
[Epoch 18; Iter   900/  960] train: loss: 0.0435861
[Epoch 18; Iter   930/  960] train: loss: 0.0410849
[Epoch 18; Iter   960/  960] train: loss: 0.1620533
[Epoch 18] ogbg-molhiv: 0.789065 val loss: 0.126932
[Epoch 18] ogbg-molhiv: 0.807465 test loss: 0.170459
[Epoch 19; Iter    30/  960] train: loss: 0.0343308
[Epoch 19; Iter    60/  960] train: loss: 0.1137855
[Epoch 19; Iter    90/  960] train: loss: 0.1178650
[Epoch 19; Iter   120/  960] train: loss: 0.0325212
[Epoch 19; Iter   150/  960] train: loss: 0.1713309
[Epoch 19; Iter   180/  960] train: loss: 0.0278134
[Epoch 19; Iter   210/  960] train: loss: 0.0202255
[Epoch 19; Iter   240/  960] train: loss: 0.0198466
[Epoch 19; Iter   270/  960] train: loss: 0.0338634
[Epoch 19; Iter   300/  960] train: loss: 0.0895605
[Epoch 19; Iter   330/  960] train: loss: 0.0547902
[Epoch 19; Iter   360/  960] train: loss: 0.1500817
[Epoch 19; Iter   390/  960] train: loss: 0.2026230
[Epoch 19; Iter   420/  960] train: loss: 0.0596607
[Epoch 19; Iter   450/  960] train: loss: 0.1845229
[Epoch 19; Iter   480/  960] train: loss: 0.0193415
[Epoch 19; Iter   510/  960] train: loss: 0.1052801
[Epoch 19; Iter   540/  960] train: loss: 0.0773663
[Epoch 19; Iter   570/  960] train: loss: 0.0291708
[Epoch 19; Iter   600/  960] train: loss: 0.0701699
[Epoch 19; Iter   630/  960] train: loss: 0.0486486
[Epoch 19; Iter   660/  960] train: loss: 0.3636537
[Epoch 19; Iter   690/  960] train: loss: 0.1300114
[Epoch 19; Iter   720/  960] train: loss: 0.0258977
[Epoch 19; Iter   750/  960] train: loss: 0.0461692
[Epoch 19; Iter   780/  960] train: loss: 0.0310917
[Epoch 19; Iter   810/  960] train: loss: 0.2941436
[Epoch 19; Iter   840/  960] train: loss: 0.0505027
[Epoch 19; Iter   870/  960] train: loss: 0.0185865
[Epoch 19; Iter   900/  960] train: loss: 0.0825353
[Epoch 19; Iter   930/  960] train: loss: 0.2149945
[Epoch 19; Iter   960/  960] train: loss: 0.0336760
[Epoch 19] ogbg-molhiv: 0.792232 val loss: 0.129027
[Epoch 19] ogbg-molhiv: 0.811101 test loss: 0.128702
[Epoch 20; Iter    30/  960] train: loss: 0.0331231
[Epoch 20; Iter    60/  960] train: loss: 0.0267461
[Epoch 20; Iter    90/  960] train: loss: 0.1917659
[Epoch 20; Iter   120/  960] train: loss: 0.3482851
[Epoch 20; Iter   150/  960] train: loss: 0.0203935
[Epoch 20; Iter   180/  960] train: loss: 0.0207206
[Epoch 20; Iter   210/  960] train: loss: 0.1442453
[Epoch 20; Iter   240/  960] train: loss: 0.1839281
[Epoch 20; Iter   270/  960] train: loss: 0.1918480
[Epoch 20; Iter   300/  960] train: loss: 0.1388927
[Epoch 20; Iter   330/  960] train: loss: 0.2149695
[Epoch 20; Iter   360/  960] train: loss: 0.0229412
[Epoch 20; Iter   390/  960] train: loss: 0.3499245
[Epoch 20; Iter   420/  960] train: loss: 0.2126980
[Epoch 20; Iter   450/  960] train: loss: 0.0593021
[Epoch 20; Iter   480/  960] train: loss: 0.0513866
[Epoch 20; Iter   510/  960] train: loss: 0.1673993
[Epoch 20; Iter   540/  960] train: loss: 0.0923852
[Epoch 20; Iter   570/  960] train: loss: 0.0228211
[Epoch 20; Iter   600/  960] train: loss: 0.0286781
[Epoch 20; Iter   630/  960] train: loss: 0.0363354
[Epoch 20; Iter   660/  960] train: loss: 0.0524799
[Epoch 20; Iter   690/  960] train: loss: 0.1103769
[Epoch 20; Iter   720/  960] train: loss: 0.0321761
[Epoch 20; Iter   750/  960] train: loss: 0.2210621
[Epoch 20; Iter   780/  960] train: loss: 0.1668953
[Epoch 20; Iter   810/  960] train: loss: 0.1717804
[Epoch 20; Iter   840/  960] train: loss: 0.1261186
[Epoch 20; Iter   870/  960] train: loss: 0.3845626
[Epoch 20; Iter   900/  960] train: loss: 0.0288882
[Epoch 20; Iter   930/  960] train: loss: 0.0223275
[Epoch 20; Iter   960/  960] train: loss: 0.2880888
[Epoch 20] ogbg-molhiv: 0.801033 val loss: 0.126292
[Epoch 20] ogbg-molhiv: 0.797355 test loss: 0.159529
[Epoch 21; Iter    30/  960] train: loss: 0.1841056
[Epoch 21; Iter    60/  960] train: loss: 0.0408697
[Epoch 21; Iter    90/  960] train: loss: 0.2314215
[Epoch 21; Iter   120/  960] train: loss: 0.0869666
[Epoch 21; Iter   150/  960] train: loss: 0.0379669
[Epoch 21; Iter   180/  960] train: loss: 0.1119172
[Epoch 21; Iter   210/  960] train: loss: 0.0700180
[Epoch 21; Iter   240/  960] train: loss: 0.1091392
[Epoch 21; Iter   270/  960] train: loss: 0.0283491
[Epoch 21; Iter   300/  960] train: loss: 0.0647060
[Epoch 21; Iter   330/  960] train: loss: 0.2952621
[Epoch 21; Iter   360/  960] train: loss: 0.0171240
[Epoch 21; Iter   390/  960] train: loss: 0.1177293
[Epoch 21; Iter   420/  960] train: loss: 0.0883519
[Epoch 21; Iter   450/  960] train: loss: 0.1521156
[Epoch 21; Iter   480/  960] train: loss: 0.0363678
[Epoch 21; Iter   510/  960] train: loss: 0.0536855
[Epoch 21; Iter   540/  960] train: loss: 0.2869526
[Epoch 21; Iter   570/  960] train: loss: 0.2750844
[Epoch 21; Iter   600/  960] train: loss: 0.0736781
[Epoch 21; Iter   630/  960] train: loss: 0.1528352
[Epoch 21; Iter   660/  960] train: loss: 0.1486110
[Epoch 21; Iter   690/  960] train: loss: 0.0317865
[Epoch 21; Iter   720/  960] train: loss: 0.0252693
[Epoch 21; Iter   750/  960] train: loss: 0.1224588
[Epoch 21; Iter   780/  960] train: loss: 0.0347655
[Epoch 21; Iter   810/  960] train: loss: 0.0197613
[Epoch 21; Iter   840/  960] train: loss: 0.1614461
[Epoch 21; Iter   870/  960] train: loss: 0.0371689
[Epoch 21; Iter   900/  960] train: loss: 0.1203715
[Epoch 21; Iter   930/  960] train: loss: 0.1798378
[Epoch 21; Iter   960/  960] train: loss: 0.0615026
[Epoch 21] ogbg-molhiv: 0.798843 val loss: 0.127456
[Epoch 21] ogbg-molhiv: 0.818938 test loss: 0.141605
[Epoch 22; Iter    30/  960] train: loss: 0.0380130
[Epoch 22; Iter    60/  960] train: loss: 0.1050883
[Epoch 22; Iter    90/  960] train: loss: 0.0308268
[Epoch 22; Iter   120/  960] train: loss: 0.1741831
[Epoch 22; Iter   150/  960] train: loss: 0.0666722
[Epoch 22; Iter   180/  960] train: loss: 0.0845250
[Epoch 22; Iter   210/  960] train: loss: 0.1417229
[Epoch 22; Iter   240/  960] train: loss: 0.0263476
[Epoch 22; Iter   270/  960] train: loss: 0.2245251
[Epoch 22; Iter   300/  960] train: loss: 0.0253204
[Epoch 22; Iter   330/  960] train: loss: 0.0182734
[Epoch 22; Iter   360/  960] train: loss: 0.1757346
[Epoch 22; Iter   390/  960] train: loss: 0.0313817
[Epoch 22; Iter   420/  960] train: loss: 0.1104151
[Epoch 22; Iter   450/  960] train: loss: 0.1442439
[Epoch 22; Iter   480/  960] train: loss: 0.0504247
[Epoch 22; Iter   510/  960] train: loss: 0.0433770
[Epoch 22; Iter   540/  960] train: loss: 0.1893597
[Epoch 22; Iter   570/  960] train: loss: 0.1757997
[Epoch 22; Iter   600/  960] train: loss: 0.1300344
[Epoch 22; Iter   630/  960] train: loss: 0.1621674
[Epoch 22; Iter   660/  960] train: loss: 0.0729141
[Epoch 22; Iter   690/  960] train: loss: 0.1544358
[Epoch 22; Iter   720/  960] train: loss: 0.2381158
[Epoch 22; Iter   750/  960] train: loss: 0.1999531
[Epoch 22; Iter   780/  960] train: loss: 0.1423725
[Epoch 22; Iter   810/  960] train: loss: 0.2856402
[Epoch 22; Iter   840/  960] train: loss: 0.0649005
[Epoch 20; Iter   307/ 1097] train: loss: 0.0302982
[Epoch 20; Iter   337/ 1097] train: loss: 0.1879195
[Epoch 20; Iter   367/ 1097] train: loss: 0.0861157
[Epoch 20; Iter   397/ 1097] train: loss: 0.0251295
[Epoch 20; Iter   427/ 1097] train: loss: 0.0363780
[Epoch 20; Iter   457/ 1097] train: loss: 0.0251824
[Epoch 20; Iter   487/ 1097] train: loss: 0.3330285
[Epoch 20; Iter   517/ 1097] train: loss: 0.0322963
[Epoch 20; Iter   547/ 1097] train: loss: 0.0477870
[Epoch 20; Iter   577/ 1097] train: loss: 0.0285743
[Epoch 20; Iter   607/ 1097] train: loss: 0.0543223
[Epoch 20; Iter   637/ 1097] train: loss: 0.0217289
[Epoch 20; Iter   667/ 1097] train: loss: 0.3480318
[Epoch 20; Iter   697/ 1097] train: loss: 0.0279233
[Epoch 20; Iter   727/ 1097] train: loss: 0.0911391
[Epoch 20; Iter   757/ 1097] train: loss: 0.1740784
[Epoch 20; Iter   787/ 1097] train: loss: 0.2469207
[Epoch 20; Iter   817/ 1097] train: loss: 0.3704822
[Epoch 20; Iter   847/ 1097] train: loss: 0.1446159
[Epoch 20; Iter   877/ 1097] train: loss: 0.0938910
[Epoch 20; Iter   907/ 1097] train: loss: 0.1830301
[Epoch 20; Iter   937/ 1097] train: loss: 0.0977390
[Epoch 20; Iter   967/ 1097] train: loss: 0.0931572
[Epoch 20; Iter   997/ 1097] train: loss: 0.1169090
[Epoch 20; Iter  1027/ 1097] train: loss: 0.1268214
[Epoch 20; Iter  1057/ 1097] train: loss: 0.0263311
[Epoch 20; Iter  1087/ 1097] train: loss: 0.0699015
[Epoch 20] ogbg-molhiv: 0.813926 val loss: 0.133467
[Epoch 20] ogbg-molhiv: 0.799908 test loss: 0.120313
[Epoch 21; Iter    20/ 1097] train: loss: 0.1464607
[Epoch 21; Iter    50/ 1097] train: loss: 0.4440495
[Epoch 21; Iter    80/ 1097] train: loss: 0.1830935
[Epoch 21; Iter   110/ 1097] train: loss: 0.2521922
[Epoch 21; Iter   140/ 1097] train: loss: 0.0179514
[Epoch 21; Iter   170/ 1097] train: loss: 0.0864125
[Epoch 21; Iter   200/ 1097] train: loss: 0.0813932
[Epoch 21; Iter   230/ 1097] train: loss: 0.2047767
[Epoch 21; Iter   260/ 1097] train: loss: 0.0252103
[Epoch 21; Iter   290/ 1097] train: loss: 0.1266049
[Epoch 21; Iter   320/ 1097] train: loss: 0.1394987
[Epoch 21; Iter   350/ 1097] train: loss: 0.0762273
[Epoch 21; Iter   380/ 1097] train: loss: 0.0875051
[Epoch 21; Iter   410/ 1097] train: loss: 0.0160732
[Epoch 21; Iter   440/ 1097] train: loss: 0.0262834
[Epoch 21; Iter   470/ 1097] train: loss: 0.2876844
[Epoch 21; Iter   500/ 1097] train: loss: 0.1496168
[Epoch 21; Iter   530/ 1097] train: loss: 0.0375646
[Epoch 21; Iter   560/ 1097] train: loss: 0.0283943
[Epoch 21; Iter   590/ 1097] train: loss: 0.0414314
[Epoch 21; Iter   620/ 1097] train: loss: 0.0419465
[Epoch 21; Iter   650/ 1097] train: loss: 0.0818661
[Epoch 21; Iter   680/ 1097] train: loss: 0.0456151
[Epoch 21; Iter   710/ 1097] train: loss: 0.0367202
[Epoch 21; Iter   740/ 1097] train: loss: 0.0231002
[Epoch 21; Iter   770/ 1097] train: loss: 0.0316077
[Epoch 21; Iter   800/ 1097] train: loss: 0.0400193
[Epoch 21; Iter   830/ 1097] train: loss: 0.0287751
[Epoch 21; Iter   860/ 1097] train: loss: 0.0375388
[Epoch 21; Iter   890/ 1097] train: loss: 0.0280146
[Epoch 21; Iter   920/ 1097] train: loss: 0.0802631
[Epoch 21; Iter   950/ 1097] train: loss: 0.1204741
[Epoch 21; Iter   980/ 1097] train: loss: 0.3018309
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0393961
[Epoch 21; Iter  1040/ 1097] train: loss: 0.1189225
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0623350
[Epoch 21] ogbg-molhiv: 0.810262 val loss: 0.116650
[Epoch 21] ogbg-molhiv: 0.794009 test loss: 0.120318
[Epoch 22; Iter     3/ 1097] train: loss: 0.0256422
[Epoch 22; Iter    33/ 1097] train: loss: 0.1781681
[Epoch 22; Iter    63/ 1097] train: loss: 0.2762829
[Epoch 22; Iter    93/ 1097] train: loss: 0.1836576
[Epoch 22; Iter   123/ 1097] train: loss: 0.1755109
[Epoch 22; Iter   153/ 1097] train: loss: 0.1609978
[Epoch 22; Iter   183/ 1097] train: loss: 0.0250429
[Epoch 22; Iter   213/ 1097] train: loss: 0.1611443
[Epoch 22; Iter   243/ 1097] train: loss: 0.2345966
[Epoch 22; Iter   273/ 1097] train: loss: 0.2975831
[Epoch 22; Iter   303/ 1097] train: loss: 0.0548812
[Epoch 22; Iter   333/ 1097] train: loss: 0.1765129
[Epoch 22; Iter   363/ 1097] train: loss: 0.0402901
[Epoch 22; Iter   393/ 1097] train: loss: 0.0240141
[Epoch 22; Iter   423/ 1097] train: loss: 0.0336567
[Epoch 22; Iter   453/ 1097] train: loss: 0.1711528
[Epoch 22; Iter   483/ 1097] train: loss: 0.0331536
[Epoch 22; Iter   513/ 1097] train: loss: 0.0982013
[Epoch 22; Iter   543/ 1097] train: loss: 0.1717536
[Epoch 22; Iter   573/ 1097] train: loss: 0.0216885
[Epoch 22; Iter   603/ 1097] train: loss: 0.0218681
[Epoch 22; Iter   633/ 1097] train: loss: 0.1514078
[Epoch 22; Iter   663/ 1097] train: loss: 0.4432177
[Epoch 22; Iter   693/ 1097] train: loss: 0.0309632
[Epoch 22; Iter   723/ 1097] train: loss: 0.5838838
[Epoch 22; Iter   753/ 1097] train: loss: 0.0439888
[Epoch 22; Iter   783/ 1097] train: loss: 0.0311315
[Epoch 22; Iter   813/ 1097] train: loss: 0.0324960
[Epoch 22; Iter   843/ 1097] train: loss: 0.0611786
[Epoch 22; Iter   873/ 1097] train: loss: 0.1010612
[Epoch 22; Iter   903/ 1097] train: loss: 0.0268208
[Epoch 22; Iter   933/ 1097] train: loss: 0.0281444
[Epoch 22; Iter   963/ 1097] train: loss: 0.0211068
[Epoch 22; Iter   993/ 1097] train: loss: 0.1495303
[Epoch 22; Iter  1023/ 1097] train: loss: 0.0237767
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0251677
[Epoch 22; Iter  1083/ 1097] train: loss: 0.1512834
[Epoch 22] ogbg-molhiv: 0.812506 val loss: 0.117305
[Epoch 22] ogbg-molhiv: 0.800101 test loss: 0.117297
[Epoch 23; Iter    16/ 1097] train: loss: 0.0836381
[Epoch 23; Iter    46/ 1097] train: loss: 0.0869050
[Epoch 23; Iter    76/ 1097] train: loss: 0.5634757
[Epoch 23; Iter   106/ 1097] train: loss: 0.0576759
[Epoch 23; Iter   136/ 1097] train: loss: 0.0446730
[Epoch 23; Iter   166/ 1097] train: loss: 0.1537589
[Epoch 23; Iter   196/ 1097] train: loss: 0.1281529
[Epoch 23; Iter   226/ 1097] train: loss: 0.0279758
[Epoch 23; Iter   256/ 1097] train: loss: 0.0452528
[Epoch 23; Iter   286/ 1097] train: loss: 0.2937630
[Epoch 23; Iter   316/ 1097] train: loss: 0.0323357
[Epoch 23; Iter   346/ 1097] train: loss: 0.2209699
[Epoch 23; Iter   376/ 1097] train: loss: 0.1399170
[Epoch 23; Iter   406/ 1097] train: loss: 0.0173147
[Epoch 23; Iter   436/ 1097] train: loss: 0.1134015
[Epoch 23; Iter   466/ 1097] train: loss: 0.1482506
[Epoch 23; Iter   496/ 1097] train: loss: 0.0222833
[Epoch 23; Iter   526/ 1097] train: loss: 0.1594803
[Epoch 23; Iter   556/ 1097] train: loss: 0.0791693
[Epoch 23; Iter   586/ 1097] train: loss: 0.0262776
[Epoch 23; Iter   616/ 1097] train: loss: 0.0443739
[Epoch 23; Iter   646/ 1097] train: loss: 0.0398727
[Epoch 23; Iter   676/ 1097] train: loss: 0.1558316
[Epoch 23; Iter   706/ 1097] train: loss: 0.0752456
[Epoch 23; Iter   736/ 1097] train: loss: 0.0342064
[Epoch 23; Iter   766/ 1097] train: loss: 0.1187926
[Epoch 23; Iter   796/ 1097] train: loss: 0.1385492
[Epoch 23; Iter   826/ 1097] train: loss: 0.0209660
[Epoch 23; Iter   856/ 1097] train: loss: 0.1077921
[Epoch 23; Iter   886/ 1097] train: loss: 0.0297261
[Epoch 23; Iter   916/ 1097] train: loss: 0.0320553
[Epoch 23; Iter   946/ 1097] train: loss: 0.1488196
[Epoch 23; Iter   976/ 1097] train: loss: 0.2102517
[Epoch 23; Iter  1006/ 1097] train: loss: 0.1588633
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0428468
[Epoch 23; Iter  1066/ 1097] train: loss: 0.0312682
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0439586
[Epoch 23] ogbg-molhiv: 0.802227 val loss: 0.131561
[Epoch 23] ogbg-molhiv: 0.798582 test loss: 0.124811
[Epoch 24; Iter    29/ 1097] train: loss: 0.0741104
[Epoch 24; Iter    59/ 1097] train: loss: 0.0394516
[Epoch 24; Iter    89/ 1097] train: loss: 0.1036858
[Epoch 24; Iter   119/ 1097] train: loss: 0.1110643
[Epoch 24; Iter   149/ 1097] train: loss: 0.0251306
[Epoch 24; Iter   179/ 1097] train: loss: 0.5415301
[Epoch 24; Iter   209/ 1097] train: loss: 0.1657564
[Epoch 24; Iter   239/ 1097] train: loss: 0.0288637
[Epoch 24; Iter   269/ 1097] train: loss: 0.2575380
[Epoch 24; Iter   299/ 1097] train: loss: 0.2213594
[Epoch 24; Iter   329/ 1097] train: loss: 0.0486762
[Epoch 24; Iter   359/ 1097] train: loss: 0.1627304
[Epoch 20; Iter   773/  823] train: loss: 0.0209321
[Epoch 20; Iter   803/  823] train: loss: 0.3424192
[Epoch 20] ogbg-molhiv: 0.799774 val loss: 0.178516
[Epoch 20] ogbg-molhiv: 0.789458 test loss: 0.163987
[Epoch 21; Iter    10/  823] train: loss: 0.1905208
[Epoch 21; Iter    40/  823] train: loss: 0.0591026
[Epoch 21; Iter    70/  823] train: loss: 0.2309113
[Epoch 21; Iter   100/  823] train: loss: 0.1664325
[Epoch 21; Iter   130/  823] train: loss: 0.0409944
[Epoch 21; Iter   160/  823] train: loss: 0.2522942
[Epoch 21; Iter   190/  823] train: loss: 0.0233931
[Epoch 21; Iter   220/  823] train: loss: 0.5578303
[Epoch 21; Iter   250/  823] train: loss: 0.1608079
[Epoch 21; Iter   280/  823] train: loss: 0.0962600
[Epoch 21; Iter   310/  823] train: loss: 0.0189370
[Epoch 21; Iter   340/  823] train: loss: 0.1093564
[Epoch 21; Iter   370/  823] train: loss: 0.0199705
[Epoch 21; Iter   400/  823] train: loss: 0.1548341
[Epoch 21; Iter   430/  823] train: loss: 0.0348745
[Epoch 21; Iter   460/  823] train: loss: 0.2192890
[Epoch 21; Iter   490/  823] train: loss: 0.2973847
[Epoch 21; Iter   520/  823] train: loss: 0.0444924
[Epoch 21; Iter   550/  823] train: loss: 0.0256734
[Epoch 21; Iter   580/  823] train: loss: 0.1031424
[Epoch 21; Iter   610/  823] train: loss: 0.0334121
[Epoch 21; Iter   640/  823] train: loss: 0.0266765
[Epoch 21; Iter   670/  823] train: loss: 0.1268037
[Epoch 21; Iter   700/  823] train: loss: 0.1196378
[Epoch 21; Iter   730/  823] train: loss: 0.0615825
[Epoch 21; Iter   760/  823] train: loss: 0.0416914
[Epoch 21; Iter   790/  823] train: loss: 0.1781017
[Epoch 21; Iter   820/  823] train: loss: 0.1216977
[Epoch 21] ogbg-molhiv: 0.792960 val loss: 0.120410
[Epoch 21] ogbg-molhiv: 0.787176 test loss: 0.129220
[Epoch 22; Iter    27/  823] train: loss: 0.0193025
[Epoch 22; Iter    57/  823] train: loss: 0.0257632
[Epoch 22; Iter    87/  823] train: loss: 0.1221524
[Epoch 22; Iter   117/  823] train: loss: 0.0949267
[Epoch 22; Iter   147/  823] train: loss: 0.1693517
[Epoch 22; Iter   177/  823] train: loss: 0.0279408
[Epoch 22; Iter   207/  823] train: loss: 0.0703609
[Epoch 22; Iter   237/  823] train: loss: 0.0228289
[Epoch 22; Iter   267/  823] train: loss: 0.0961022
[Epoch 22; Iter   297/  823] train: loss: 0.0461363
[Epoch 22; Iter   327/  823] train: loss: 0.0232801
[Epoch 22; Iter   357/  823] train: loss: 0.0676768
[Epoch 22; Iter   387/  823] train: loss: 0.1056935
[Epoch 22; Iter   417/  823] train: loss: 0.1044195
[Epoch 22; Iter   447/  823] train: loss: 0.0378401
[Epoch 22; Iter   477/  823] train: loss: 0.1757363
[Epoch 22; Iter   507/  823] train: loss: 0.2577952
[Epoch 22; Iter   537/  823] train: loss: 0.0462954
[Epoch 22; Iter   567/  823] train: loss: 0.0232078
[Epoch 22; Iter   597/  823] train: loss: 0.2009632
[Epoch 22; Iter   627/  823] train: loss: 0.0287907
[Epoch 22; Iter   657/  823] train: loss: 0.0314138
[Epoch 22; Iter   687/  823] train: loss: 0.0237868
[Epoch 22; Iter   717/  823] train: loss: 0.0884672
[Epoch 22; Iter   747/  823] train: loss: 0.3595192
[Epoch 22; Iter   777/  823] train: loss: 0.0560942
[Epoch 22; Iter   807/  823] train: loss: 0.2267686
[Epoch 22] ogbg-molhiv: 0.799651 val loss: 0.116046
[Epoch 22] ogbg-molhiv: 0.782048 test loss: 0.122202
[Epoch 23; Iter    14/  823] train: loss: 0.0299315
[Epoch 23; Iter    44/  823] train: loss: 0.3225147
[Epoch 23; Iter    74/  823] train: loss: 0.1423161
[Epoch 23; Iter   104/  823] train: loss: 0.1884726
[Epoch 23; Iter   134/  823] train: loss: 0.4787526
[Epoch 23; Iter   164/  823] train: loss: 0.0434214
[Epoch 23; Iter   194/  823] train: loss: 0.1155513
[Epoch 23; Iter   224/  823] train: loss: 0.2049114
[Epoch 23; Iter   254/  823] train: loss: 0.0935434
[Epoch 23; Iter   284/  823] train: loss: 0.2475488
[Epoch 23; Iter   314/  823] train: loss: 0.1070114
[Epoch 23; Iter   344/  823] train: loss: 0.1153407
[Epoch 23; Iter   374/  823] train: loss: 0.0177058
[Epoch 23; Iter   404/  823] train: loss: 0.0340686
[Epoch 23; Iter   434/  823] train: loss: 0.1677985
[Epoch 23; Iter   464/  823] train: loss: 0.0894691
[Epoch 23; Iter   494/  823] train: loss: 0.0561621
[Epoch 23; Iter   524/  823] train: loss: 0.0977599
[Epoch 23; Iter   554/  823] train: loss: 0.3542467
[Epoch 23; Iter   584/  823] train: loss: 0.2025393
[Epoch 23; Iter   614/  823] train: loss: 0.0975102
[Epoch 23; Iter   644/  823] train: loss: 0.0360399
[Epoch 23; Iter   674/  823] train: loss: 0.0187686
[Epoch 23; Iter   704/  823] train: loss: 0.0380198
[Epoch 23; Iter   734/  823] train: loss: 0.2753914
[Epoch 23; Iter   764/  823] train: loss: 0.1376509
[Epoch 23; Iter   794/  823] train: loss: 0.1685895
[Epoch 23] ogbg-molhiv: 0.817881 val loss: 0.135571
[Epoch 23] ogbg-molhiv: 0.793648 test loss: 0.159613
[Epoch 24; Iter     1/  823] train: loss: 0.2544092
[Epoch 24; Iter    31/  823] train: loss: 0.0545241
[Epoch 24; Iter    61/  823] train: loss: 0.0301754
[Epoch 24; Iter    91/  823] train: loss: 0.2002647
[Epoch 24; Iter   121/  823] train: loss: 0.1853098
[Epoch 24; Iter   151/  823] train: loss: 0.0224220
[Epoch 24; Iter   181/  823] train: loss: 0.2164904
[Epoch 24; Iter   211/  823] train: loss: 0.0285323
[Epoch 24; Iter   241/  823] train: loss: 0.0305652
[Epoch 24; Iter   271/  823] train: loss: 0.0672447
[Epoch 24; Iter   301/  823] train: loss: 0.1411979
[Epoch 24; Iter   331/  823] train: loss: 0.0357893
[Epoch 24; Iter   361/  823] train: loss: 0.0312403
[Epoch 24; Iter   391/  823] train: loss: 0.0767831
[Epoch 24; Iter   421/  823] train: loss: 0.1848184
[Epoch 24; Iter   451/  823] train: loss: 0.0258060
[Epoch 24; Iter   481/  823] train: loss: 0.2250490
[Epoch 24; Iter   511/  823] train: loss: 0.0470894
[Epoch 24; Iter   541/  823] train: loss: 0.1461385
[Epoch 24; Iter   571/  823] train: loss: 0.0234278
[Epoch 24; Iter   601/  823] train: loss: 0.1752269
[Epoch 24; Iter   631/  823] train: loss: 0.1707040
[Epoch 24; Iter   661/  823] train: loss: 0.0221189
[Epoch 24; Iter   691/  823] train: loss: 0.0260767
[Epoch 24; Iter   721/  823] train: loss: 0.2984297
[Epoch 24; Iter   751/  823] train: loss: 0.0490498
[Epoch 24; Iter   781/  823] train: loss: 0.0202922
[Epoch 24; Iter   811/  823] train: loss: 0.0236263
[Epoch 24] ogbg-molhiv: 0.815093 val loss: 0.135697
[Epoch 24] ogbg-molhiv: 0.778607 test loss: 0.130288
[Epoch 25; Iter    18/  823] train: loss: 0.0551307
[Epoch 25; Iter    48/  823] train: loss: 0.0250932
[Epoch 25; Iter    78/  823] train: loss: 0.0501682
[Epoch 25; Iter   108/  823] train: loss: 0.1886055
[Epoch 25; Iter   138/  823] train: loss: 0.1386359
[Epoch 25; Iter   168/  823] train: loss: 0.0192978
[Epoch 25; Iter   198/  823] train: loss: 0.3425466
[Epoch 25; Iter   228/  823] train: loss: 0.0336768
[Epoch 25; Iter   258/  823] train: loss: 0.0667604
[Epoch 25; Iter   288/  823] train: loss: 0.0212812
[Epoch 25; Iter   318/  823] train: loss: 0.1573334
[Epoch 25; Iter   348/  823] train: loss: 0.2513701
[Epoch 25; Iter   378/  823] train: loss: 0.0279276
[Epoch 25; Iter   408/  823] train: loss: 0.5025034
[Epoch 25; Iter   438/  823] train: loss: 0.1726382
[Epoch 25; Iter   468/  823] train: loss: 0.0625215
[Epoch 25; Iter   498/  823] train: loss: 0.0175956
[Epoch 25; Iter   528/  823] train: loss: 0.0553647
[Epoch 25; Iter   558/  823] train: loss: 0.2377138
[Epoch 25; Iter   588/  823] train: loss: 0.4301930
[Epoch 25; Iter   618/  823] train: loss: 0.1200081
[Epoch 25; Iter   648/  823] train: loss: 0.0491153
[Epoch 25; Iter   678/  823] train: loss: 0.0417905
[Epoch 25; Iter   708/  823] train: loss: 0.2079175
[Epoch 25; Iter   738/  823] train: loss: 0.4246642
[Epoch 25; Iter   768/  823] train: loss: 0.1941252
[Epoch 25; Iter   798/  823] train: loss: 0.0920123
[Epoch 25] ogbg-molhiv: 0.812190 val loss: 0.146201
[Epoch 25] ogbg-molhiv: 0.794281 test loss: 0.156295
[Epoch 26; Iter     5/  823] train: loss: 0.0403451
[Epoch 26; Iter    35/  823] train: loss: 0.0598263
[Epoch 26; Iter    65/  823] train: loss: 0.0777287
[Epoch 26; Iter    95/  823] train: loss: 0.0284747
[Epoch 26; Iter   125/  823] train: loss: 0.1086604
[Epoch 26; Iter   155/  823] train: loss: 0.2501542
[Epoch 20; Iter   307/ 1097] train: loss: 0.1403874
[Epoch 20; Iter   337/ 1097] train: loss: 0.0187653
[Epoch 20; Iter   367/ 1097] train: loss: 0.0216477
[Epoch 20; Iter   397/ 1097] train: loss: 0.0194510
[Epoch 20; Iter   427/ 1097] train: loss: 0.0863360
[Epoch 20; Iter   457/ 1097] train: loss: 0.2558754
[Epoch 20; Iter   487/ 1097] train: loss: 0.0247859
[Epoch 20; Iter   517/ 1097] train: loss: 0.1642820
[Epoch 20; Iter   547/ 1097] train: loss: 0.0276485
[Epoch 20; Iter   577/ 1097] train: loss: 0.0241746
[Epoch 20; Iter   607/ 1097] train: loss: 0.1130913
[Epoch 20; Iter   637/ 1097] train: loss: 0.0283005
[Epoch 20; Iter   667/ 1097] train: loss: 0.0300447
[Epoch 20; Iter   697/ 1097] train: loss: 0.0485082
[Epoch 20; Iter   727/ 1097] train: loss: 0.1982259
[Epoch 20; Iter   757/ 1097] train: loss: 0.0218467
[Epoch 20; Iter   787/ 1097] train: loss: 0.1631075
[Epoch 20; Iter   817/ 1097] train: loss: 0.0237436
[Epoch 20; Iter   847/ 1097] train: loss: 0.0266000
[Epoch 20; Iter   877/ 1097] train: loss: 0.0207877
[Epoch 20; Iter   907/ 1097] train: loss: 0.0354052
[Epoch 20; Iter   937/ 1097] train: loss: 0.0411501
[Epoch 20; Iter   967/ 1097] train: loss: 0.0243226
[Epoch 20; Iter   997/ 1097] train: loss: 0.0222269
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0276041
[Epoch 20; Iter  1057/ 1097] train: loss: 0.0194192
[Epoch 20; Iter  1087/ 1097] train: loss: 0.2413318
[Epoch 20] ogbg-molhiv: 0.799418 val loss: 0.426318
[Epoch 20] ogbg-molhiv: 0.785329 test loss: 0.118133
[Epoch 21; Iter    20/ 1097] train: loss: 0.0498341
[Epoch 21; Iter    50/ 1097] train: loss: 0.1492294
[Epoch 21; Iter    80/ 1097] train: loss: 0.0234443
[Epoch 21; Iter   110/ 1097] train: loss: 0.0182557
[Epoch 21; Iter   140/ 1097] train: loss: 0.0185664
[Epoch 21; Iter   170/ 1097] train: loss: 0.0530147
[Epoch 21; Iter   200/ 1097] train: loss: 0.0215395
[Epoch 21; Iter   230/ 1097] train: loss: 0.1075944
[Epoch 21; Iter   260/ 1097] train: loss: 0.1698157
[Epoch 21; Iter   290/ 1097] train: loss: 0.0490993
[Epoch 21; Iter   320/ 1097] train: loss: 0.0888606
[Epoch 21; Iter   350/ 1097] train: loss: 0.0538338
[Epoch 21; Iter   380/ 1097] train: loss: 0.0405581
[Epoch 21; Iter   410/ 1097] train: loss: 0.1436351
[Epoch 21; Iter   440/ 1097] train: loss: 0.2195983
[Epoch 21; Iter   470/ 1097] train: loss: 0.0706986
[Epoch 21; Iter   500/ 1097] train: loss: 0.2551185
[Epoch 21; Iter   530/ 1097] train: loss: 0.0714086
[Epoch 21; Iter   560/ 1097] train: loss: 0.0346894
[Epoch 21; Iter   590/ 1097] train: loss: 0.1459694
[Epoch 21; Iter   620/ 1097] train: loss: 0.1969649
[Epoch 21; Iter   650/ 1097] train: loss: 0.0325870
[Epoch 21; Iter   680/ 1097] train: loss: 0.0472513
[Epoch 21; Iter   710/ 1097] train: loss: 0.1038220
[Epoch 21; Iter   740/ 1097] train: loss: 0.0188876
[Epoch 21; Iter   770/ 1097] train: loss: 0.1225592
[Epoch 21; Iter   800/ 1097] train: loss: 0.1477797
[Epoch 21; Iter   830/ 1097] train: loss: 0.1446272
[Epoch 21; Iter   860/ 1097] train: loss: 0.0497296
[Epoch 21; Iter   890/ 1097] train: loss: 0.0650564
[Epoch 21; Iter   920/ 1097] train: loss: 0.0205997
[Epoch 21; Iter   950/ 1097] train: loss: 0.0230819
[Epoch 21; Iter   980/ 1097] train: loss: 0.0196265
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0426913
[Epoch 21; Iter  1040/ 1097] train: loss: 0.0443226
[Epoch 21; Iter  1070/ 1097] train: loss: 0.1443757
[Epoch 21] ogbg-molhiv: 0.777758 val loss: 0.770991
[Epoch 21] ogbg-molhiv: 0.799482 test loss: 0.112945
[Epoch 22; Iter     3/ 1097] train: loss: 0.0284581
[Epoch 22; Iter    33/ 1097] train: loss: 0.0300382
[Epoch 22; Iter    63/ 1097] train: loss: 0.1112325
[Epoch 22; Iter    93/ 1097] train: loss: 0.0411856
[Epoch 22; Iter   123/ 1097] train: loss: 0.1339582
[Epoch 22; Iter   153/ 1097] train: loss: 0.0189313
[Epoch 22; Iter   183/ 1097] train: loss: 0.1228870
[Epoch 22; Iter   213/ 1097] train: loss: 0.0202232
[Epoch 22; Iter   243/ 1097] train: loss: 0.0271462
[Epoch 22; Iter   273/ 1097] train: loss: 0.1271353
[Epoch 22; Iter   303/ 1097] train: loss: 0.3040966
[Epoch 22; Iter   333/ 1097] train: loss: 0.2388133
[Epoch 22; Iter   363/ 1097] train: loss: 0.0658524
[Epoch 22; Iter   393/ 1097] train: loss: 0.0284490
[Epoch 22; Iter   423/ 1097] train: loss: 0.0392417
[Epoch 22; Iter   453/ 1097] train: loss: 0.0880645
[Epoch 22; Iter   483/ 1097] train: loss: 0.0185389
[Epoch 22; Iter   513/ 1097] train: loss: 0.3673884
[Epoch 22; Iter   543/ 1097] train: loss: 0.0778298
[Epoch 22; Iter   573/ 1097] train: loss: 0.1265084
[Epoch 22; Iter   603/ 1097] train: loss: 0.0882318
[Epoch 22; Iter   633/ 1097] train: loss: 0.1223847
[Epoch 22; Iter   663/ 1097] train: loss: 0.0833824
[Epoch 22; Iter   693/ 1097] train: loss: 0.0179257
[Epoch 22; Iter   723/ 1097] train: loss: 0.0156303
[Epoch 22; Iter   753/ 1097] train: loss: 0.0887470
[Epoch 22; Iter   783/ 1097] train: loss: 0.0743913
[Epoch 22; Iter   813/ 1097] train: loss: 0.0215555
[Epoch 22; Iter   843/ 1097] train: loss: 0.0202099
[Epoch 22; Iter   873/ 1097] train: loss: 0.3846874
[Epoch 22; Iter   903/ 1097] train: loss: 0.3117726
[Epoch 22; Iter   933/ 1097] train: loss: 0.1217048
[Epoch 22; Iter   963/ 1097] train: loss: 0.0641229
[Epoch 22; Iter   993/ 1097] train: loss: 0.0231841
[Epoch 22; Iter  1023/ 1097] train: loss: 0.0392342
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0210934
[Epoch 22; Iter  1083/ 1097] train: loss: 0.1213522
[Epoch 22] ogbg-molhiv: 0.807958 val loss: 0.196334
[Epoch 22] ogbg-molhiv: 0.826750 test loss: 0.148442
[Epoch 23; Iter    16/ 1097] train: loss: 0.0219563
[Epoch 23; Iter    46/ 1097] train: loss: 0.0387428
[Epoch 23; Iter    76/ 1097] train: loss: 0.1275605
[Epoch 23; Iter   106/ 1097] train: loss: 0.1481885
[Epoch 23; Iter   136/ 1097] train: loss: 0.0408129
[Epoch 23; Iter   166/ 1097] train: loss: 0.0554810
[Epoch 23; Iter   196/ 1097] train: loss: 0.0260072
[Epoch 23; Iter   226/ 1097] train: loss: 0.0200985
[Epoch 23; Iter   256/ 1097] train: loss: 0.0176963
[Epoch 23; Iter   286/ 1097] train: loss: 0.0231587
[Epoch 23; Iter   316/ 1097] train: loss: 0.0310706
[Epoch 23; Iter   346/ 1097] train: loss: 0.1325295
[Epoch 23; Iter   376/ 1097] train: loss: 0.0353420
[Epoch 23; Iter   406/ 1097] train: loss: 0.1454740
[Epoch 23; Iter   436/ 1097] train: loss: 0.1727566
[Epoch 23; Iter   466/ 1097] train: loss: 0.0304493
[Epoch 23; Iter   496/ 1097] train: loss: 0.3153069
[Epoch 23; Iter   526/ 1097] train: loss: 0.0189879
[Epoch 23; Iter   556/ 1097] train: loss: 0.0460115
[Epoch 23; Iter   586/ 1097] train: loss: 0.3022587
[Epoch 23; Iter   616/ 1097] train: loss: 0.0613110
[Epoch 23; Iter   646/ 1097] train: loss: 0.0151217
[Epoch 23; Iter   676/ 1097] train: loss: 0.1788954
[Epoch 23; Iter   706/ 1097] train: loss: 0.0373297
[Epoch 23; Iter   736/ 1097] train: loss: 0.0320850
[Epoch 23; Iter   766/ 1097] train: loss: 0.2839002
[Epoch 23; Iter   796/ 1097] train: loss: 0.0188310
[Epoch 23; Iter   826/ 1097] train: loss: 0.1580990
[Epoch 23; Iter   856/ 1097] train: loss: 0.0227823
[Epoch 23; Iter   886/ 1097] train: loss: 0.0246319
[Epoch 23; Iter   916/ 1097] train: loss: 0.2166851
[Epoch 23; Iter   946/ 1097] train: loss: 0.0474048
[Epoch 23; Iter   976/ 1097] train: loss: 0.0288718
[Epoch 23; Iter  1006/ 1097] train: loss: 0.1595263
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0740599
[Epoch 23; Iter  1066/ 1097] train: loss: 0.0989195
[Epoch 23; Iter  1096/ 1097] train: loss: 0.1718151
[Epoch 23] ogbg-molhiv: 0.797635 val loss: 0.285212
[Epoch 23] ogbg-molhiv: 0.807865 test loss: 0.160775
[Epoch 24; Iter    29/ 1097] train: loss: 0.0214990
[Epoch 24; Iter    59/ 1097] train: loss: 0.0422446
[Epoch 24; Iter    89/ 1097] train: loss: 0.0665792
[Epoch 24; Iter   119/ 1097] train: loss: 0.0192318
[Epoch 24; Iter   149/ 1097] train: loss: 0.2544941
[Epoch 24; Iter   179/ 1097] train: loss: 0.0248872
[Epoch 24; Iter   209/ 1097] train: loss: 0.0256089
[Epoch 24; Iter   239/ 1097] train: loss: 0.0224716
[Epoch 24; Iter   269/ 1097] train: loss: 0.0373256
[Epoch 24; Iter   299/ 1097] train: loss: 0.1387430
[Epoch 24; Iter   329/ 1097] train: loss: 0.0387003
[Epoch 24; Iter   359/ 1097] train: loss: 0.0292853
[Epoch 20; Iter   307/ 1097] train: loss: 0.0181263
[Epoch 20; Iter   337/ 1097] train: loss: 0.3547665
[Epoch 20; Iter   367/ 1097] train: loss: 0.0459248
[Epoch 20; Iter   397/ 1097] train: loss: 0.0213055
[Epoch 20; Iter   427/ 1097] train: loss: 0.3974151
[Epoch 20; Iter   457/ 1097] train: loss: 0.0882730
[Epoch 20; Iter   487/ 1097] train: loss: 0.0406801
[Epoch 20; Iter   517/ 1097] train: loss: 0.1880001
[Epoch 20; Iter   547/ 1097] train: loss: 0.3189444
[Epoch 20; Iter   577/ 1097] train: loss: 0.3244348
[Epoch 20; Iter   607/ 1097] train: loss: 0.0456665
[Epoch 20; Iter   637/ 1097] train: loss: 0.0824675
[Epoch 20; Iter   667/ 1097] train: loss: 0.0652898
[Epoch 20; Iter   697/ 1097] train: loss: 0.4079726
[Epoch 20; Iter   727/ 1097] train: loss: 0.2016300
[Epoch 20; Iter   757/ 1097] train: loss: 0.0673252
[Epoch 20; Iter   787/ 1097] train: loss: 0.0465675
[Epoch 20; Iter   817/ 1097] train: loss: 0.0773575
[Epoch 20; Iter   847/ 1097] train: loss: 0.0429828
[Epoch 20; Iter   877/ 1097] train: loss: 0.0789795
[Epoch 20; Iter   907/ 1097] train: loss: 0.0494418
[Epoch 20; Iter   937/ 1097] train: loss: 0.0757001
[Epoch 20; Iter   967/ 1097] train: loss: 0.1347855
[Epoch 20; Iter   997/ 1097] train: loss: 0.1440679
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0512271
[Epoch 20; Iter  1057/ 1097] train: loss: 0.0870774
[Epoch 20; Iter  1087/ 1097] train: loss: 0.0592297
[Epoch 20] ogbg-molhiv: 0.798461 val loss: 0.244072
[Epoch 20] ogbg-molhiv: 0.804338 test loss: 0.209549
[Epoch 21; Iter    20/ 1097] train: loss: 0.0280060
[Epoch 21; Iter    50/ 1097] train: loss: 0.0206966
[Epoch 21; Iter    80/ 1097] train: loss: 0.0598344
[Epoch 21; Iter   110/ 1097] train: loss: 0.2970121
[Epoch 21; Iter   140/ 1097] train: loss: 0.0435258
[Epoch 21; Iter   170/ 1097] train: loss: 0.0324695
[Epoch 21; Iter   200/ 1097] train: loss: 0.0224107
[Epoch 21; Iter   230/ 1097] train: loss: 0.0279692
[Epoch 21; Iter   260/ 1097] train: loss: 0.1777371
[Epoch 21; Iter   290/ 1097] train: loss: 0.1567641
[Epoch 21; Iter   320/ 1097] train: loss: 0.1443543
[Epoch 21; Iter   350/ 1097] train: loss: 0.0677889
[Epoch 21; Iter   380/ 1097] train: loss: 0.1825464
[Epoch 21; Iter   410/ 1097] train: loss: 0.0723212
[Epoch 21; Iter   440/ 1097] train: loss: 0.0189339
[Epoch 21; Iter   470/ 1097] train: loss: 0.0131274
[Epoch 21; Iter   500/ 1097] train: loss: 0.0154015
[Epoch 21; Iter   530/ 1097] train: loss: 0.1467358
[Epoch 21; Iter   560/ 1097] train: loss: 0.0204527
[Epoch 21; Iter   590/ 1097] train: loss: 0.0819881
[Epoch 21; Iter   620/ 1097] train: loss: 0.0303149
[Epoch 21; Iter   650/ 1097] train: loss: 0.0372397
[Epoch 21; Iter   680/ 1097] train: loss: 0.0198488
[Epoch 21; Iter   710/ 1097] train: loss: 0.1369715
[Epoch 21; Iter   740/ 1097] train: loss: 0.0427219
[Epoch 21; Iter   770/ 1097] train: loss: 0.0460926
[Epoch 21; Iter   800/ 1097] train: loss: 0.0445480
[Epoch 21; Iter   830/ 1097] train: loss: 0.1132349
[Epoch 21; Iter   860/ 1097] train: loss: 0.0391233
[Epoch 21; Iter   890/ 1097] train: loss: 0.2039651
[Epoch 21; Iter   920/ 1097] train: loss: 0.0832914
[Epoch 21; Iter   950/ 1097] train: loss: 0.2555822
[Epoch 21; Iter   980/ 1097] train: loss: 0.2805045
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0341752
[Epoch 21; Iter  1040/ 1097] train: loss: 0.0183421
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0817928
[Epoch 21] ogbg-molhiv: 0.819776 val loss: 0.192843
[Epoch 21] ogbg-molhiv: 0.804962 test loss: 0.168626
[Epoch 22; Iter     3/ 1097] train: loss: 0.0243290
[Epoch 22; Iter    33/ 1097] train: loss: 0.0425323
[Epoch 22; Iter    63/ 1097] train: loss: 0.0414312
[Epoch 22; Iter    93/ 1097] train: loss: 0.0719528
[Epoch 22; Iter   123/ 1097] train: loss: 0.1712407
[Epoch 22; Iter   153/ 1097] train: loss: 0.1478175
[Epoch 22; Iter   183/ 1097] train: loss: 0.1822942
[Epoch 22; Iter   213/ 1097] train: loss: 0.2342760
[Epoch 22; Iter   243/ 1097] train: loss: 0.1338932
[Epoch 22; Iter   273/ 1097] train: loss: 0.0538247
[Epoch 22; Iter   303/ 1097] train: loss: 0.1423240
[Epoch 22; Iter   333/ 1097] train: loss: 0.0295375
[Epoch 22; Iter   363/ 1097] train: loss: 0.0411099
[Epoch 22; Iter   393/ 1097] train: loss: 0.0414981
[Epoch 22; Iter   423/ 1097] train: loss: 0.0696941
[Epoch 22; Iter   453/ 1097] train: loss: 0.2028958
[Epoch 22; Iter   483/ 1097] train: loss: 0.0958226
[Epoch 22; Iter   513/ 1097] train: loss: 0.1780852
[Epoch 22; Iter   543/ 1097] train: loss: 0.0645861
[Epoch 22; Iter   573/ 1097] train: loss: 0.0696408
[Epoch 22; Iter   603/ 1097] train: loss: 0.1444782
[Epoch 22; Iter   633/ 1097] train: loss: 0.0208060
[Epoch 22; Iter   663/ 1097] train: loss: 0.0169074
[Epoch 22; Iter   693/ 1097] train: loss: 0.1741180
[Epoch 22; Iter   723/ 1097] train: loss: 0.1079897
[Epoch 22; Iter   753/ 1097] train: loss: 0.1156283
[Epoch 22; Iter   783/ 1097] train: loss: 0.4042516
[Epoch 22; Iter   813/ 1097] train: loss: 0.1161033
[Epoch 22; Iter   843/ 1097] train: loss: 0.1407293
[Epoch 22; Iter   873/ 1097] train: loss: 0.0230338
[Epoch 22; Iter   903/ 1097] train: loss: 0.0602212
[Epoch 22; Iter   933/ 1097] train: loss: 0.1638092
[Epoch 22; Iter   963/ 1097] train: loss: 0.0215133
[Epoch 22; Iter   993/ 1097] train: loss: 0.0202672
[Epoch 22; Iter  1023/ 1097] train: loss: 0.0523244
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0297724
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0359405
[Epoch 22] ogbg-molhiv: 0.808608 val loss: 0.117966
[Epoch 22] ogbg-molhiv: 0.803238 test loss: 0.117789
[Epoch 23; Iter    16/ 1097] train: loss: 0.1512515
[Epoch 23; Iter    46/ 1097] train: loss: 0.0130158
[Epoch 23; Iter    76/ 1097] train: loss: 0.4353814
[Epoch 23; Iter   106/ 1097] train: loss: 0.0144685
[Epoch 23; Iter   136/ 1097] train: loss: 0.0252660
[Epoch 23; Iter   166/ 1097] train: loss: 0.1206399
[Epoch 23; Iter   196/ 1097] train: loss: 0.0234592
[Epoch 23; Iter   226/ 1097] train: loss: 0.0837108
[Epoch 23; Iter   256/ 1097] train: loss: 0.3300066
[Epoch 23; Iter   286/ 1097] train: loss: 0.0163514
[Epoch 23; Iter   316/ 1097] train: loss: 0.0139290
[Epoch 23; Iter   346/ 1097] train: loss: 0.1459562
[Epoch 23; Iter   376/ 1097] train: loss: 0.2016796
[Epoch 23; Iter   406/ 1097] train: loss: 0.0196390
[Epoch 23; Iter   436/ 1097] train: loss: 0.0230710
[Epoch 23; Iter   466/ 1097] train: loss: 0.0174173
[Epoch 23; Iter   496/ 1097] train: loss: 0.0511133
[Epoch 23; Iter   526/ 1097] train: loss: 0.0920920
[Epoch 23; Iter   556/ 1097] train: loss: 0.0210731
[Epoch 23; Iter   586/ 1097] train: loss: 0.0197033
[Epoch 23; Iter   616/ 1097] train: loss: 0.0236490
[Epoch 23; Iter   646/ 1097] train: loss: 0.1960694
[Epoch 23; Iter   676/ 1097] train: loss: 0.0205939
[Epoch 23; Iter   706/ 1097] train: loss: 0.0725839
[Epoch 23; Iter   736/ 1097] train: loss: 0.0249654
[Epoch 23; Iter   766/ 1097] train: loss: 0.0347125
[Epoch 23; Iter   796/ 1097] train: loss: 0.1832452
[Epoch 23; Iter   826/ 1097] train: loss: 0.2901605
[Epoch 23; Iter   856/ 1097] train: loss: 0.1651808
[Epoch 23; Iter   886/ 1097] train: loss: 0.0925947
[Epoch 23; Iter   916/ 1097] train: loss: 0.0352206
[Epoch 23; Iter   946/ 1097] train: loss: 0.2418675
[Epoch 23; Iter   976/ 1097] train: loss: 0.1425230
[Epoch 23; Iter  1006/ 1097] train: loss: 0.0273445
[Epoch 23; Iter  1036/ 1097] train: loss: 0.1624639
[Epoch 23; Iter  1066/ 1097] train: loss: 0.1390787
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0239581
[Epoch 23] ogbg-molhiv: 0.811121 val loss: 0.127736
[Epoch 23] ogbg-molhiv: 0.819581 test loss: 0.126723
[Epoch 24; Iter    29/ 1097] train: loss: 0.1480637
[Epoch 24; Iter    59/ 1097] train: loss: 0.0148880
[Epoch 24; Iter    89/ 1097] train: loss: 0.1209979
[Epoch 24; Iter   119/ 1097] train: loss: 0.3771702
[Epoch 24; Iter   149/ 1097] train: loss: 0.0418054
[Epoch 24; Iter   179/ 1097] train: loss: 0.0275384
[Epoch 24; Iter   209/ 1097] train: loss: 0.0154545
[Epoch 24; Iter   239/ 1097] train: loss: 0.0954093
[Epoch 24; Iter   269/ 1097] train: loss: 0.0672450
[Epoch 24; Iter   299/ 1097] train: loss: 0.2860523
[Epoch 24; Iter   329/ 1097] train: loss: 0.0216359
[Epoch 24; Iter   359/ 1097] train: loss: 0.0362593
[Epoch 20; Iter   773/  823] train: loss: 0.0240262
[Epoch 20; Iter   803/  823] train: loss: 0.0982978
[Epoch 20] ogbg-molhiv: 0.799173 val loss: 0.711966
[Epoch 20] ogbg-molhiv: 0.797255 test loss: 0.768075
[Epoch 21; Iter    10/  823] train: loss: 0.1248212
[Epoch 21; Iter    40/  823] train: loss: 0.1405906
[Epoch 21; Iter    70/  823] train: loss: 0.1700863
[Epoch 21; Iter   100/  823] train: loss: 0.0686264
[Epoch 21; Iter   130/  823] train: loss: 0.0358768
[Epoch 21; Iter   160/  823] train: loss: 0.0727695
[Epoch 21; Iter   190/  823] train: loss: 0.0868187
[Epoch 21; Iter   220/  823] train: loss: 0.1977797
[Epoch 21; Iter   250/  823] train: loss: 0.0408658
[Epoch 21; Iter   280/  823] train: loss: 0.0362145
[Epoch 21; Iter   310/  823] train: loss: 0.0911082
[Epoch 21; Iter   340/  823] train: loss: 0.1722928
[Epoch 21; Iter   370/  823] train: loss: 0.0235151
[Epoch 21; Iter   400/  823] train: loss: 0.2068786
[Epoch 21; Iter   430/  823] train: loss: 0.2411366
[Epoch 21; Iter   460/  823] train: loss: 0.0207317
[Epoch 21; Iter   490/  823] train: loss: 0.1635629
[Epoch 21; Iter   520/  823] train: loss: 0.1124813
[Epoch 21; Iter   550/  823] train: loss: 0.0336467
[Epoch 21; Iter   580/  823] train: loss: 0.0253978
[Epoch 21; Iter   610/  823] train: loss: 0.2357058
[Epoch 21; Iter   640/  823] train: loss: 0.0612367
[Epoch 21; Iter   670/  823] train: loss: 0.0360195
[Epoch 21; Iter   700/  823] train: loss: 0.2520079
[Epoch 21; Iter   730/  823] train: loss: 0.0252944
[Epoch 21; Iter   760/  823] train: loss: 0.0441373
[Epoch 21; Iter   790/  823] train: loss: 0.0567827
[Epoch 21; Iter   820/  823] train: loss: 0.0245014
[Epoch 21] ogbg-molhiv: 0.812215 val loss: 0.115906
[Epoch 21] ogbg-molhiv: 0.784253 test loss: 0.233382
[Epoch 22; Iter    27/  823] train: loss: 0.1398203
[Epoch 22; Iter    57/  823] train: loss: 0.0199893
[Epoch 22; Iter    87/  823] train: loss: 0.0313488
[Epoch 22; Iter   117/  823] train: loss: 0.1600579
[Epoch 22; Iter   147/  823] train: loss: 0.0359041
[Epoch 22; Iter   177/  823] train: loss: 0.1258906
[Epoch 22; Iter   207/  823] train: loss: 0.0255428
[Epoch 22; Iter   237/  823] train: loss: 0.0260865
[Epoch 22; Iter   267/  823] train: loss: 0.1533693
[Epoch 22; Iter   297/  823] train: loss: 0.1341042
[Epoch 22; Iter   327/  823] train: loss: 0.3446872
[Epoch 22; Iter   357/  823] train: loss: 0.1140218
[Epoch 22; Iter   387/  823] train: loss: 0.0694028
[Epoch 22; Iter   417/  823] train: loss: 0.1481472
[Epoch 22; Iter   447/  823] train: loss: 0.2057338
[Epoch 22; Iter   477/  823] train: loss: 0.0379371
[Epoch 22; Iter   507/  823] train: loss: 0.1124692
[Epoch 22; Iter   537/  823] train: loss: 0.0273852
[Epoch 22; Iter   567/  823] train: loss: 0.0302124
[Epoch 22; Iter   597/  823] train: loss: 0.0541062
[Epoch 22; Iter   627/  823] train: loss: 0.1047686
[Epoch 22; Iter   657/  823] train: loss: 0.0236018
[Epoch 22; Iter   687/  823] train: loss: 0.0512531
[Epoch 22; Iter   717/  823] train: loss: 0.0268588
[Epoch 22; Iter   747/  823] train: loss: 0.1340564
[Epoch 22; Iter   777/  823] train: loss: 0.3339210
[Epoch 22; Iter   807/  823] train: loss: 0.0395522
[Epoch 22] ogbg-molhiv: 0.813306 val loss: 0.120335
[Epoch 22] ogbg-molhiv: 0.788874 test loss: 0.188499
[Epoch 23; Iter    14/  823] train: loss: 0.2244991
[Epoch 23; Iter    44/  823] train: loss: 0.1329119
[Epoch 23; Iter    74/  823] train: loss: 0.0264306
[Epoch 23; Iter   104/  823] train: loss: 0.1344873
[Epoch 23; Iter   134/  823] train: loss: 0.0798429
[Epoch 23; Iter   164/  823] train: loss: 0.0329487
[Epoch 23; Iter   194/  823] train: loss: 0.0280273
[Epoch 23; Iter   224/  823] train: loss: 0.1489483
[Epoch 23; Iter   254/  823] train: loss: 0.0192484
[Epoch 23; Iter   284/  823] train: loss: 0.3398218
[Epoch 23; Iter   314/  823] train: loss: 0.1866693
[Epoch 23; Iter   344/  823] train: loss: 0.1442793
[Epoch 23; Iter   374/  823] train: loss: 0.0244810
[Epoch 23; Iter   404/  823] train: loss: 0.1529935
[Epoch 23; Iter   434/  823] train: loss: 0.1435486
[Epoch 23; Iter   464/  823] train: loss: 0.0217100
[Epoch 23; Iter   494/  823] train: loss: 0.0484541
[Epoch 23; Iter   524/  823] train: loss: 0.3009343
[Epoch 23; Iter   554/  823] train: loss: 0.0707400
[Epoch 23; Iter   584/  823] train: loss: 0.0415361
[Epoch 23; Iter   614/  823] train: loss: 0.1561400
[Epoch 23; Iter   644/  823] train: loss: 0.0277377
[Epoch 23; Iter   674/  823] train: loss: 0.0778139
[Epoch 23; Iter   704/  823] train: loss: 0.0999152
[Epoch 23; Iter   734/  823] train: loss: 0.3334640
[Epoch 23; Iter   764/  823] train: loss: 0.2628751
[Epoch 23; Iter   794/  823] train: loss: 0.0294674
[Epoch 23] ogbg-molhiv: 0.815517 val loss: 0.277601
[Epoch 23] ogbg-molhiv: 0.790937 test loss: 0.599573
[Epoch 24; Iter     1/  823] train: loss: 0.0595748
[Epoch 24; Iter    31/  823] train: loss: 0.0229467
[Epoch 24; Iter    61/  823] train: loss: 0.1999950
[Epoch 24; Iter    91/  823] train: loss: 0.0380063
[Epoch 24; Iter   121/  823] train: loss: 0.2012327
[Epoch 24; Iter   151/  823] train: loss: 0.0254020
[Epoch 24; Iter   181/  823] train: loss: 0.1954431
[Epoch 24; Iter   211/  823] train: loss: 0.1418597
[Epoch 24; Iter   241/  823] train: loss: 0.0458446
[Epoch 24; Iter   271/  823] train: loss: 0.0228427
[Epoch 24; Iter   301/  823] train: loss: 0.0388284
[Epoch 24; Iter   331/  823] train: loss: 0.0366543
[Epoch 24; Iter   361/  823] train: loss: 0.0464144
[Epoch 24; Iter   391/  823] train: loss: 0.0392053
[Epoch 24; Iter   421/  823] train: loss: 0.1441267
[Epoch 24; Iter   451/  823] train: loss: 0.1874721
[Epoch 24; Iter   481/  823] train: loss: 0.1105439
[Epoch 24; Iter   511/  823] train: loss: 0.1908257
[Epoch 24; Iter   541/  823] train: loss: 0.0274651
[Epoch 24; Iter   571/  823] train: loss: 0.1309847
[Epoch 24; Iter   601/  823] train: loss: 0.0270306
[Epoch 24; Iter   631/  823] train: loss: 0.0735504
[Epoch 24; Iter   661/  823] train: loss: 0.0217477
[Epoch 24; Iter   691/  823] train: loss: 0.0367527
[Epoch 24; Iter   721/  823] train: loss: 0.0519625
[Epoch 24; Iter   751/  823] train: loss: 0.0169837
[Epoch 24; Iter   781/  823] train: loss: 0.0465207
[Epoch 24; Iter   811/  823] train: loss: 0.1683814
[Epoch 24] ogbg-molhiv: 0.812468 val loss: 0.185355
[Epoch 24] ogbg-molhiv: 0.781187 test loss: 0.667873
[Epoch 25; Iter    18/  823] train: loss: 0.0254736
[Epoch 25; Iter    48/  823] train: loss: 0.1539641
[Epoch 25; Iter    78/  823] train: loss: 0.0221045
[Epoch 25; Iter   108/  823] train: loss: 0.1984176
[Epoch 25; Iter   138/  823] train: loss: 0.0267640
[Epoch 25; Iter   168/  823] train: loss: 0.0257712
[Epoch 25; Iter   198/  823] train: loss: 0.1567771
[Epoch 25; Iter   228/  823] train: loss: 0.0251749
[Epoch 25; Iter   258/  823] train: loss: 0.0265063
[Epoch 25; Iter   288/  823] train: loss: 0.1437509
[Epoch 25; Iter   318/  823] train: loss: 0.1083243
[Epoch 25; Iter   348/  823] train: loss: 0.0314665
[Epoch 25; Iter   378/  823] train: loss: 0.2031977
[Epoch 25; Iter   408/  823] train: loss: 0.4237431
[Epoch 25; Iter   438/  823] train: loss: 0.0241700
[Epoch 25; Iter   468/  823] train: loss: 0.1291134
[Epoch 25; Iter   498/  823] train: loss: 0.0260651
[Epoch 25; Iter   528/  823] train: loss: 0.0291073
[Epoch 25; Iter   558/  823] train: loss: 0.0477601
[Epoch 25; Iter   588/  823] train: loss: 0.3095137
[Epoch 25; Iter   618/  823] train: loss: 0.0398746
[Epoch 25; Iter   648/  823] train: loss: 0.0209608
[Epoch 25; Iter   678/  823] train: loss: 0.0249849
[Epoch 25; Iter   708/  823] train: loss: 0.0475848
[Epoch 25; Iter   738/  823] train: loss: 0.0188373
[Epoch 25; Iter   768/  823] train: loss: 0.0283346
[Epoch 25; Iter   798/  823] train: loss: 0.1322513
[Epoch 25] ogbg-molhiv: 0.824824 val loss: 0.134825
[Epoch 25] ogbg-molhiv: 0.788792 test loss: 0.355673
[Epoch 26; Iter     5/  823] train: loss: 0.0197823
[Epoch 26; Iter    35/  823] train: loss: 0.0840184
[Epoch 26; Iter    65/  823] train: loss: 0.0210805
[Epoch 26; Iter    95/  823] train: loss: 0.0205536
[Epoch 26; Iter   125/  823] train: loss: 0.0397989
[Epoch 26; Iter   155/  823] train: loss: 0.0477128
[Epoch 20; Iter   773/  823] train: loss: 0.0356840
[Epoch 20; Iter   803/  823] train: loss: 0.1037449
[Epoch 20] ogbg-molhiv: 0.822869 val loss: 0.322158
[Epoch 20] ogbg-molhiv: 0.787091 test loss: 0.188990
[Epoch 21; Iter    10/  823] train: loss: 0.0831449
[Epoch 21; Iter    40/  823] train: loss: 0.0180981
[Epoch 21; Iter    70/  823] train: loss: 0.0392743
[Epoch 21; Iter   100/  823] train: loss: 0.0235408
[Epoch 21; Iter   130/  823] train: loss: 0.0250172
[Epoch 21; Iter   160/  823] train: loss: 0.0594751
[Epoch 21; Iter   190/  823] train: loss: 0.1267230
[Epoch 21; Iter   220/  823] train: loss: 0.0436855
[Epoch 21; Iter   250/  823] train: loss: 0.0196642
[Epoch 21; Iter   280/  823] train: loss: 0.0303287
[Epoch 21; Iter   310/  823] train: loss: 0.0860984
[Epoch 21; Iter   340/  823] train: loss: 0.1025673
[Epoch 21; Iter   370/  823] train: loss: 0.0387164
[Epoch 21; Iter   400/  823] train: loss: 0.1347980
[Epoch 21; Iter   430/  823] train: loss: 0.2571411
[Epoch 21; Iter   460/  823] train: loss: 0.1159894
[Epoch 21; Iter   490/  823] train: loss: 0.0250104
[Epoch 21; Iter   520/  823] train: loss: 0.0395407
[Epoch 21; Iter   550/  823] train: loss: 0.0310749
[Epoch 21; Iter   580/  823] train: loss: 0.2225318
[Epoch 21; Iter   610/  823] train: loss: 0.1724243
[Epoch 21; Iter   640/  823] train: loss: 0.0376755
[Epoch 21; Iter   670/  823] train: loss: 0.0324319
[Epoch 21; Iter   700/  823] train: loss: 0.0249867
[Epoch 21; Iter   730/  823] train: loss: 0.0550728
[Epoch 21; Iter   760/  823] train: loss: 0.0199887
[Epoch 21; Iter   790/  823] train: loss: 0.1189287
[Epoch 21; Iter   820/  823] train: loss: 0.0994839
[Epoch 21] ogbg-molhiv: 0.817965 val loss: 0.188710
[Epoch 21] ogbg-molhiv: 0.793678 test loss: 0.138241
[Epoch 22; Iter    27/  823] train: loss: 0.0312777
[Epoch 22; Iter    57/  823] train: loss: 0.1779840
[Epoch 22; Iter    87/  823] train: loss: 0.2357334
[Epoch 22; Iter   117/  823] train: loss: 0.0524412
[Epoch 22; Iter   147/  823] train: loss: 0.4854560
[Epoch 22; Iter   177/  823] train: loss: 0.0754081
[Epoch 22; Iter   207/  823] train: loss: 0.0917718
[Epoch 22; Iter   237/  823] train: loss: 0.0231187
[Epoch 22; Iter   267/  823] train: loss: 0.2242957
[Epoch 22; Iter   297/  823] train: loss: 0.0251262
[Epoch 22; Iter   327/  823] train: loss: 0.2245953
[Epoch 22; Iter   357/  823] train: loss: 0.2035942
[Epoch 22; Iter   387/  823] train: loss: 0.1959511
[Epoch 22; Iter   417/  823] train: loss: 0.1818197
[Epoch 22; Iter   447/  823] train: loss: 0.0203752
[Epoch 22; Iter   477/  823] train: loss: 0.4246493
[Epoch 22; Iter   507/  823] train: loss: 0.0256072
[Epoch 22; Iter   537/  823] train: loss: 0.0311790
[Epoch 22; Iter   567/  823] train: loss: 0.1408899
[Epoch 22; Iter   597/  823] train: loss: 0.2962660
[Epoch 22; Iter   627/  823] train: loss: 0.0249280
[Epoch 22; Iter   657/  823] train: loss: 0.0702388
[Epoch 22; Iter   687/  823] train: loss: 0.1203878
[Epoch 22; Iter   717/  823] train: loss: 0.0531156
[Epoch 22; Iter   747/  823] train: loss: 0.0437567
[Epoch 22; Iter   777/  823] train: loss: 0.1370539
[Epoch 22; Iter   807/  823] train: loss: 0.2013990
[Epoch 22] ogbg-molhiv: 0.817687 val loss: 0.136321
[Epoch 22] ogbg-molhiv: 0.790569 test loss: 0.180718
[Epoch 23; Iter    14/  823] train: loss: 0.0265773
[Epoch 23; Iter    44/  823] train: loss: 0.0981351
[Epoch 23; Iter    74/  823] train: loss: 0.1520355
[Epoch 23; Iter   104/  823] train: loss: 0.1358815
[Epoch 23; Iter   134/  823] train: loss: 0.0321997
[Epoch 23; Iter   164/  823] train: loss: 0.2665884
[Epoch 23; Iter   194/  823] train: loss: 0.0883549
[Epoch 23; Iter   224/  823] train: loss: 0.1406469
[Epoch 23; Iter   254/  823] train: loss: 0.0602271
[Epoch 23; Iter   284/  823] train: loss: 0.0517191
[Epoch 23; Iter   314/  823] train: loss: 0.0214346
[Epoch 23; Iter   344/  823] train: loss: 0.0320840
[Epoch 23; Iter   374/  823] train: loss: 0.2377087
[Epoch 23; Iter   404/  823] train: loss: 0.1983507
[Epoch 23; Iter   434/  823] train: loss: 0.1927743
[Epoch 23; Iter   464/  823] train: loss: 0.0350184
[Epoch 23; Iter   494/  823] train: loss: 0.0214153
[Epoch 23; Iter   524/  823] train: loss: 0.0198010
[Epoch 23; Iter   554/  823] train: loss: 0.0311575
[Epoch 23; Iter   584/  823] train: loss: 0.0377598
[Epoch 23; Iter   614/  823] train: loss: 0.2407297
[Epoch 23; Iter   644/  823] train: loss: 0.0238024
[Epoch 23; Iter   674/  823] train: loss: 0.1687047
[Epoch 23; Iter   704/  823] train: loss: 0.1242620
[Epoch 23; Iter   734/  823] train: loss: 0.1201357
[Epoch 23; Iter   764/  823] train: loss: 0.0820606
[Epoch 23; Iter   794/  823] train: loss: 0.1324538
[Epoch 23] ogbg-molhiv: 0.815906 val loss: 0.114639
[Epoch 23] ogbg-molhiv: 0.793201 test loss: 0.124232
[Epoch 24; Iter     1/  823] train: loss: 0.0230848
[Epoch 24; Iter    31/  823] train: loss: 0.2998937
[Epoch 24; Iter    61/  823] train: loss: 0.1361852
[Epoch 24; Iter    91/  823] train: loss: 0.1330236
[Epoch 24; Iter   121/  823] train: loss: 0.0311064
[Epoch 24; Iter   151/  823] train: loss: 0.0584670
[Epoch 24; Iter   181/  823] train: loss: 0.0340722
[Epoch 24; Iter   211/  823] train: loss: 0.0410650
[Epoch 24; Iter   241/  823] train: loss: 0.1255904
[Epoch 24; Iter   271/  823] train: loss: 0.0752553
[Epoch 24; Iter   301/  823] train: loss: 0.0412211
[Epoch 24; Iter   331/  823] train: loss: 0.0551349
[Epoch 24; Iter   361/  823] train: loss: 0.0598645
[Epoch 24; Iter   391/  823] train: loss: 0.0301401
[Epoch 24; Iter   421/  823] train: loss: 0.0576848
[Epoch 24; Iter   451/  823] train: loss: 0.0259716
[Epoch 24; Iter   481/  823] train: loss: 0.1380114
[Epoch 24; Iter   511/  823] train: loss: 0.0590100
[Epoch 24; Iter   541/  823] train: loss: 0.1987219
[Epoch 24; Iter   571/  823] train: loss: 0.0482944
[Epoch 24; Iter   601/  823] train: loss: 0.1387526
[Epoch 24; Iter   631/  823] train: loss: 0.0323894
[Epoch 24; Iter   661/  823] train: loss: 0.0255331
[Epoch 24; Iter   691/  823] train: loss: 0.0200205
[Epoch 24; Iter   721/  823] train: loss: 0.0171244
[Epoch 24; Iter   751/  823] train: loss: 0.0223334
[Epoch 24; Iter   781/  823] train: loss: 0.1781832
[Epoch 24; Iter   811/  823] train: loss: 0.1056936
[Epoch 24] ogbg-molhiv: 0.801749 val loss: 0.123991
[Epoch 24] ogbg-molhiv: 0.777600 test loss: 0.151870
[Epoch 25; Iter    18/  823] train: loss: 0.0617634
[Epoch 25; Iter    48/  823] train: loss: 0.1812569
[Epoch 25; Iter    78/  823] train: loss: 0.0226829
[Epoch 25; Iter   108/  823] train: loss: 0.2201958
[Epoch 25; Iter   138/  823] train: loss: 0.0174450
[Epoch 25; Iter   168/  823] train: loss: 0.1117532
[Epoch 25; Iter   198/  823] train: loss: 0.1540528
[Epoch 25; Iter   228/  823] train: loss: 0.0250232
[Epoch 25; Iter   258/  823] train: loss: 0.1344771
[Epoch 25; Iter   288/  823] train: loss: 0.2414268
[Epoch 25; Iter   318/  823] train: loss: 0.0299059
[Epoch 25; Iter   348/  823] train: loss: 0.1703019
[Epoch 25; Iter   378/  823] train: loss: 0.0535463
[Epoch 25; Iter   408/  823] train: loss: 0.1013168
[Epoch 25; Iter   438/  823] train: loss: 0.3024938
[Epoch 25; Iter   468/  823] train: loss: 0.2077457
[Epoch 25; Iter   498/  823] train: loss: 0.0454557
[Epoch 25; Iter   528/  823] train: loss: 0.0486012
[Epoch 25; Iter   558/  823] train: loss: 0.0840886
[Epoch 25; Iter   588/  823] train: loss: 0.0436059
[Epoch 25; Iter   618/  823] train: loss: 0.2850404
[Epoch 25; Iter   648/  823] train: loss: 0.0319082
[Epoch 25; Iter   678/  823] train: loss: 0.0304138
[Epoch 25; Iter   708/  823] train: loss: 0.0529957
[Epoch 25; Iter   738/  823] train: loss: 0.0263831
[Epoch 25; Iter   768/  823] train: loss: 0.1658496
[Epoch 25; Iter   798/  823] train: loss: 0.1667985
[Epoch 25] ogbg-molhiv: 0.812818 val loss: 0.112551
[Epoch 25] ogbg-molhiv: 0.795622 test loss: 0.121602
[Epoch 26; Iter     5/  823] train: loss: 0.0310027
[Epoch 26; Iter    35/  823] train: loss: 0.1685236
[Epoch 26; Iter    65/  823] train: loss: 0.1445228
[Epoch 26; Iter    95/  823] train: loss: 0.1004639
[Epoch 26; Iter   125/  823] train: loss: 0.1934990
[Epoch 26; Iter   155/  823] train: loss: 0.1497201
[Epoch 22; Iter   870/  960] train: loss: 0.0377284
[Epoch 22; Iter   900/  960] train: loss: 0.0895041
[Epoch 22; Iter   930/  960] train: loss: 0.0194709
[Epoch 22; Iter   960/  960] train: loss: 0.0174177
[Epoch 22] ogbg-molhiv: 0.794910 val loss: 0.165273
[Epoch 22] ogbg-molhiv: 0.802792 test loss: 0.141612
[Epoch 23; Iter    30/  960] train: loss: 0.0495995
[Epoch 23; Iter    60/  960] train: loss: 0.1982319
[Epoch 23; Iter    90/  960] train: loss: 0.0165336
[Epoch 23; Iter   120/  960] train: loss: 0.0717095
[Epoch 23; Iter   150/  960] train: loss: 0.1069892
[Epoch 23; Iter   180/  960] train: loss: 0.0280753
[Epoch 23; Iter   210/  960] train: loss: 0.0120906
[Epoch 23; Iter   240/  960] train: loss: 0.0249610
[Epoch 23; Iter   270/  960] train: loss: 0.0356694
[Epoch 23; Iter   300/  960] train: loss: 0.4243848
[Epoch 23; Iter   330/  960] train: loss: 0.0938904
[Epoch 23; Iter   360/  960] train: loss: 0.0347623
[Epoch 23; Iter   390/  960] train: loss: 0.0267393
[Epoch 23; Iter   420/  960] train: loss: 0.0239327
[Epoch 23; Iter   450/  960] train: loss: 0.1455523
[Epoch 23; Iter   480/  960] train: loss: 0.0174596
[Epoch 23; Iter   510/  960] train: loss: 0.0211992
[Epoch 23; Iter   540/  960] train: loss: 0.0234853
[Epoch 23; Iter   570/  960] train: loss: 0.0429245
[Epoch 23; Iter   600/  960] train: loss: 0.0290266
[Epoch 23; Iter   630/  960] train: loss: 0.0480633
[Epoch 23; Iter   660/  960] train: loss: 0.0490349
[Epoch 23; Iter   690/  960] train: loss: 0.0258885
[Epoch 23; Iter   720/  960] train: loss: 0.0383581
[Epoch 23; Iter   750/  960] train: loss: 0.0324619
[Epoch 23; Iter   780/  960] train: loss: 0.2799638
[Epoch 23; Iter   810/  960] train: loss: 0.2607475
[Epoch 23; Iter   840/  960] train: loss: 0.0225116
[Epoch 23; Iter   870/  960] train: loss: 0.0537578
[Epoch 23; Iter   900/  960] train: loss: 0.2062408
[Epoch 23; Iter   930/  960] train: loss: 0.0738673
[Epoch 23; Iter   960/  960] train: loss: 0.0248401
[Epoch 23] ogbg-molhiv: 0.811728 val loss: 0.217449
[Epoch 23] ogbg-molhiv: 0.806701 test loss: 0.242133
[Epoch 24; Iter    30/  960] train: loss: 0.1086308
[Epoch 24; Iter    60/  960] train: loss: 0.0195461
[Epoch 24; Iter    90/  960] train: loss: 0.1305387
[Epoch 24; Iter   120/  960] train: loss: 0.2615479
[Epoch 24; Iter   150/  960] train: loss: 0.2329827
[Epoch 24; Iter   180/  960] train: loss: 0.0963271
[Epoch 24; Iter   210/  960] train: loss: 0.0292383
[Epoch 24; Iter   240/  960] train: loss: 0.1197534
[Epoch 24; Iter   270/  960] train: loss: 0.0343928
[Epoch 24; Iter   300/  960] train: loss: 0.0295233
[Epoch 24; Iter   330/  960] train: loss: 0.1803970
[Epoch 24; Iter   360/  960] train: loss: 0.0454913
[Epoch 24; Iter   390/  960] train: loss: 0.0594729
[Epoch 24; Iter   420/  960] train: loss: 0.0219257
[Epoch 24; Iter   450/  960] train: loss: 0.1683900
[Epoch 24; Iter   480/  960] train: loss: 0.0234793
[Epoch 24; Iter   510/  960] train: loss: 0.0391197
[Epoch 24; Iter   540/  960] train: loss: 0.1970891
[Epoch 24; Iter   570/  960] train: loss: 0.0143931
[Epoch 24; Iter   600/  960] train: loss: 0.1397018
[Epoch 24; Iter   630/  960] train: loss: 0.0197752
[Epoch 24; Iter   660/  960] train: loss: 0.1447047
[Epoch 24; Iter   690/  960] train: loss: 0.0188537
[Epoch 24; Iter   720/  960] train: loss: 0.2238247
[Epoch 24; Iter   750/  960] train: loss: 0.0321041
[Epoch 24; Iter   780/  960] train: loss: 0.0321578
[Epoch 24; Iter   810/  960] train: loss: 0.1146258
[Epoch 24; Iter   840/  960] train: loss: 0.0222563
[Epoch 24; Iter   870/  960] train: loss: 0.1554436
[Epoch 24; Iter   900/  960] train: loss: 0.3397409
[Epoch 24; Iter   930/  960] train: loss: 0.0912868
[Epoch 24; Iter   960/  960] train: loss: 0.0181452
[Epoch 24] ogbg-molhiv: 0.809484 val loss: 0.190415
[Epoch 24] ogbg-molhiv: 0.810743 test loss: 0.149130
[Epoch 25; Iter    30/  960] train: loss: 0.1970429
[Epoch 25; Iter    60/  960] train: loss: 0.1234931
[Epoch 25; Iter    90/  960] train: loss: 0.0678376
[Epoch 25; Iter   120/  960] train: loss: 0.0163043
[Epoch 25; Iter   150/  960] train: loss: 0.1564700
[Epoch 25; Iter   180/  960] train: loss: 0.3830928
[Epoch 25; Iter   210/  960] train: loss: 0.1695449
[Epoch 25; Iter   240/  960] train: loss: 0.0855742
[Epoch 25; Iter   270/  960] train: loss: 0.1783925
[Epoch 25; Iter   300/  960] train: loss: 0.2284929
[Epoch 25; Iter   330/  960] train: loss: 0.1060911
[Epoch 25; Iter   360/  960] train: loss: 0.0928096
[Epoch 25; Iter   390/  960] train: loss: 0.0442351
[Epoch 25; Iter   420/  960] train: loss: 0.0332407
[Epoch 25; Iter   450/  960] train: loss: 0.0484513
[Epoch 25; Iter   480/  960] train: loss: 0.0500782
[Epoch 25; Iter   510/  960] train: loss: 0.1600576
[Epoch 25; Iter   540/  960] train: loss: 0.7019396
[Epoch 25; Iter   570/  960] train: loss: 0.0250806
[Epoch 25; Iter   600/  960] train: loss: 0.0616382
[Epoch 25; Iter   630/  960] train: loss: 0.0960499
[Epoch 25; Iter   660/  960] train: loss: 0.0265956
[Epoch 25; Iter   690/  960] train: loss: 0.2958743
[Epoch 25; Iter   720/  960] train: loss: 0.0903937
[Epoch 25; Iter   750/  960] train: loss: 0.1485312
[Epoch 25; Iter   780/  960] train: loss: 0.1801244
[Epoch 25; Iter   810/  960] train: loss: 0.2729175
[Epoch 25; Iter   840/  960] train: loss: 0.0462592
[Epoch 25; Iter   870/  960] train: loss: 0.0233021
[Epoch 25; Iter   900/  960] train: loss: 0.1347135
[Epoch 25; Iter   930/  960] train: loss: 0.0255698
[Epoch 25; Iter   960/  960] train: loss: 0.0832361
[Epoch 25] ogbg-molhiv: 0.807265 val loss: 0.308252
[Epoch 25] ogbg-molhiv: 0.822361 test loss: 0.163519
[Epoch 26; Iter    30/  960] train: loss: 0.0341752
[Epoch 26; Iter    60/  960] train: loss: 0.2488478
[Epoch 26; Iter    90/  960] train: loss: 0.0268256
[Epoch 26; Iter   120/  960] train: loss: 0.0351454
[Epoch 26; Iter   150/  960] train: loss: 0.0149275
[Epoch 26; Iter   180/  960] train: loss: 0.0299158
[Epoch 26; Iter   210/  960] train: loss: 0.0435500
[Epoch 26; Iter   240/  960] train: loss: 0.0351520
[Epoch 26; Iter   270/  960] train: loss: 0.0292352
[Epoch 26; Iter   300/  960] train: loss: 0.0388379
[Epoch 26; Iter   330/  960] train: loss: 0.0748678
[Epoch 26; Iter   360/  960] train: loss: 0.1672925
[Epoch 26; Iter   390/  960] train: loss: 0.0264545
[Epoch 26; Iter   420/  960] train: loss: 0.0154310
[Epoch 26; Iter   450/  960] train: loss: 0.1121953
[Epoch 26; Iter   480/  960] train: loss: 0.0282455
[Epoch 26; Iter   510/  960] train: loss: 0.1318240
[Epoch 26; Iter   540/  960] train: loss: 0.1332645
[Epoch 26; Iter   570/  960] train: loss: 0.0452105
[Epoch 26; Iter   600/  960] train: loss: 0.0212690
[Epoch 26; Iter   630/  960] train: loss: 0.0177979
[Epoch 26; Iter   660/  960] train: loss: 0.0500854
[Epoch 26; Iter   690/  960] train: loss: 0.1702237
[Epoch 26; Iter   720/  960] train: loss: 0.1618082
[Epoch 26; Iter   750/  960] train: loss: 0.0135003
[Epoch 26; Iter   780/  960] train: loss: 0.0852518
[Epoch 26; Iter   810/  960] train: loss: 0.0957710
[Epoch 26; Iter   840/  960] train: loss: 0.0346725
[Epoch 26; Iter   870/  960] train: loss: 0.0249343
[Epoch 26; Iter   900/  960] train: loss: 0.0805499
[Epoch 26; Iter   930/  960] train: loss: 0.0186416
[Epoch 26; Iter   960/  960] train: loss: 0.0833349
[Epoch 26] ogbg-molhiv: 0.812659 val loss: 0.127060
[Epoch 26] ogbg-molhiv: 0.822422 test loss: 0.119294
[Epoch 27; Iter    30/  960] train: loss: 0.1794293
[Epoch 27; Iter    60/  960] train: loss: 0.0562370
[Epoch 27; Iter    90/  960] train: loss: 0.2100075
[Epoch 27; Iter   120/  960] train: loss: 0.1826733
[Epoch 27; Iter   150/  960] train: loss: 0.2351309
[Epoch 27; Iter   180/  960] train: loss: 0.0224452
[Epoch 27; Iter   210/  960] train: loss: 0.0279900
[Epoch 27; Iter   240/  960] train: loss: 0.0813684
[Epoch 27; Iter   270/  960] train: loss: 0.0788318
[Epoch 27; Iter   300/  960] train: loss: 0.0677497
[Epoch 27; Iter   330/  960] train: loss: 0.0843486
[Epoch 27; Iter   360/  960] train: loss: 0.2339389
[Epoch 27; Iter   390/  960] train: loss: 0.0284281
[Epoch 27; Iter   420/  960] train: loss: 0.0902804
[Epoch 27; Iter   450/  960] train: loss: 0.1217144
[Epoch 22; Iter   870/  960] train: loss: 0.0291325
[Epoch 22; Iter   900/  960] train: loss: 0.1236156
[Epoch 22; Iter   930/  960] train: loss: 0.0172918
[Epoch 22; Iter   960/  960] train: loss: 0.0375007
[Epoch 22] ogbg-molhiv: 0.811479 val loss: 0.134295
[Epoch 22] ogbg-molhiv: 0.812840 test loss: 0.116428
[Epoch 23; Iter    30/  960] train: loss: 0.1022656
[Epoch 23; Iter    60/  960] train: loss: 0.0413614
[Epoch 23; Iter    90/  960] train: loss: 0.0138168
[Epoch 23; Iter   120/  960] train: loss: 0.0155704
[Epoch 23; Iter   150/  960] train: loss: 0.0553279
[Epoch 23; Iter   180/  960] train: loss: 0.0501184
[Epoch 23; Iter   210/  960] train: loss: 0.1729622
[Epoch 23; Iter   240/  960] train: loss: 0.0172970
[Epoch 23; Iter   270/  960] train: loss: 0.2718409
[Epoch 23; Iter   300/  960] train: loss: 0.0359597
[Epoch 23; Iter   330/  960] train: loss: 0.0271378
[Epoch 23; Iter   360/  960] train: loss: 0.3286426
[Epoch 23; Iter   390/  960] train: loss: 0.1703533
[Epoch 23; Iter   420/  960] train: loss: 0.0861426
[Epoch 23; Iter   450/  960] train: loss: 0.1416347
[Epoch 23; Iter   480/  960] train: loss: 0.0946764
[Epoch 23; Iter   510/  960] train: loss: 0.0413984
[Epoch 23; Iter   540/  960] train: loss: 0.0181302
[Epoch 23; Iter   570/  960] train: loss: 0.0161468
[Epoch 23; Iter   600/  960] train: loss: 0.0202312
[Epoch 23; Iter   630/  960] train: loss: 0.0873757
[Epoch 23; Iter   660/  960] train: loss: 0.0261779
[Epoch 23; Iter   690/  960] train: loss: 0.1592205
[Epoch 23; Iter   720/  960] train: loss: 0.0304897
[Epoch 23; Iter   750/  960] train: loss: 0.0485643
[Epoch 23; Iter   780/  960] train: loss: 0.0417953
[Epoch 23; Iter   810/  960] train: loss: 0.0849024
[Epoch 23; Iter   840/  960] train: loss: 0.0569551
[Epoch 23; Iter   870/  960] train: loss: 0.2757897
[Epoch 23; Iter   900/  960] train: loss: 0.1501790
[Epoch 23; Iter   930/  960] train: loss: 0.0172159
[Epoch 23; Iter   960/  960] train: loss: 0.2220065
[Epoch 23] ogbg-molhiv: 0.833540 val loss: 0.117158
[Epoch 23] ogbg-molhiv: 0.821809 test loss: 0.113672
[Epoch 24; Iter    30/  960] train: loss: 0.0211918
[Epoch 24; Iter    60/  960] train: loss: 0.0309297
[Epoch 24; Iter    90/  960] train: loss: 0.0178932
[Epoch 24; Iter   120/  960] train: loss: 0.0639637
[Epoch 24; Iter   150/  960] train: loss: 0.0687840
[Epoch 24; Iter   180/  960] train: loss: 0.1986342
[Epoch 24; Iter   210/  960] train: loss: 0.0842483
[Epoch 24; Iter   240/  960] train: loss: 0.0392364
[Epoch 24; Iter   270/  960] train: loss: 0.2907420
[Epoch 24; Iter   300/  960] train: loss: 0.3279518
[Epoch 24; Iter   330/  960] train: loss: 0.0388887
[Epoch 24; Iter   360/  960] train: loss: 0.1764495
[Epoch 24; Iter   390/  960] train: loss: 0.1505496
[Epoch 24; Iter   420/  960] train: loss: 0.0188146
[Epoch 24; Iter   450/  960] train: loss: 0.0720667
[Epoch 24; Iter   480/  960] train: loss: 0.1633219
[Epoch 24; Iter   510/  960] train: loss: 0.0160773
[Epoch 24; Iter   540/  960] train: loss: 0.0616480
[Epoch 24; Iter   570/  960] train: loss: 0.1597183
[Epoch 24; Iter   600/  960] train: loss: 0.3013935
[Epoch 24; Iter   630/  960] train: loss: 0.0217896
[Epoch 24; Iter   660/  960] train: loss: 0.0218587
[Epoch 24; Iter   690/  960] train: loss: 0.0277715
[Epoch 24; Iter   720/  960] train: loss: 0.1465753
[Epoch 24; Iter   750/  960] train: loss: 0.1552532
[Epoch 24; Iter   780/  960] train: loss: 0.0551093
[Epoch 24; Iter   810/  960] train: loss: 0.0657327
[Epoch 24; Iter   840/  960] train: loss: 0.0985691
[Epoch 24; Iter   870/  960] train: loss: 0.2983535
[Epoch 24; Iter   900/  960] train: loss: 0.0534377
[Epoch 24; Iter   930/  960] train: loss: 0.0236677
[Epoch 24; Iter   960/  960] train: loss: 0.8144131
[Epoch 24] ogbg-molhiv: 0.827091 val loss: 0.120351
[Epoch 24] ogbg-molhiv: 0.827023 test loss: 0.114395
[Epoch 25; Iter    30/  960] train: loss: 0.3973643
[Epoch 25; Iter    60/  960] train: loss: 0.0201239
[Epoch 25; Iter    90/  960] train: loss: 0.2262830
[Epoch 25; Iter   120/  960] train: loss: 0.2311746
[Epoch 25; Iter   150/  960] train: loss: 0.0227496
[Epoch 25; Iter   180/  960] train: loss: 0.0232134
[Epoch 25; Iter   210/  960] train: loss: 0.1246530
[Epoch 25; Iter   240/  960] train: loss: 0.0861255
[Epoch 25; Iter   270/  960] train: loss: 0.1081382
[Epoch 25; Iter   300/  960] train: loss: 0.0682671
[Epoch 25; Iter   330/  960] train: loss: 0.0321917
[Epoch 25; Iter   360/  960] train: loss: 0.0385756
[Epoch 25; Iter   390/  960] train: loss: 0.0147502
[Epoch 25; Iter   420/  960] train: loss: 0.0552260
[Epoch 25; Iter   450/  960] train: loss: 0.0270776
[Epoch 25; Iter   480/  960] train: loss: 0.0520956
[Epoch 25; Iter   510/  960] train: loss: 0.0443200
[Epoch 25; Iter   540/  960] train: loss: 0.1105372
[Epoch 25; Iter   570/  960] train: loss: 0.1902555
[Epoch 25; Iter   600/  960] train: loss: 0.0511858
[Epoch 25; Iter   630/  960] train: loss: 0.0395922
[Epoch 25; Iter   660/  960] train: loss: 0.0208135
[Epoch 25; Iter   690/  960] train: loss: 0.0492354
[Epoch 25; Iter   720/  960] train: loss: 0.0259819
[Epoch 25; Iter   750/  960] train: loss: 0.0526953
[Epoch 25; Iter   780/  960] train: loss: 0.0324013
[Epoch 25; Iter   810/  960] train: loss: 0.0450006
[Epoch 25; Iter   840/  960] train: loss: 0.2317977
[Epoch 25; Iter   870/  960] train: loss: 0.1548865
[Epoch 25; Iter   900/  960] train: loss: 0.0729109
[Epoch 25; Iter   930/  960] train: loss: 0.0612126
[Epoch 25; Iter   960/  960] train: loss: 0.2539211
[Epoch 25] ogbg-molhiv: 0.822684 val loss: 0.918112
[Epoch 25] ogbg-molhiv: 0.826020 test loss: 0.443416
[Epoch 26; Iter    30/  960] train: loss: 0.1779296
[Epoch 26; Iter    60/  960] train: loss: 0.0205694
[Epoch 26; Iter    90/  960] train: loss: 0.0276556
[Epoch 26; Iter   120/  960] train: loss: 0.1297989
[Epoch 26; Iter   150/  960] train: loss: 0.0540339
[Epoch 26; Iter   180/  960] train: loss: 0.0324813
[Epoch 26; Iter   210/  960] train: loss: 0.2856615
[Epoch 26; Iter   240/  960] train: loss: 0.0249194
[Epoch 26; Iter   270/  960] train: loss: 0.0698146
[Epoch 26; Iter   300/  960] train: loss: 0.2806692
[Epoch 26; Iter   330/  960] train: loss: 0.0183916
[Epoch 26; Iter   360/  960] train: loss: 0.0231729
[Epoch 26; Iter   390/  960] train: loss: 0.1017132
[Epoch 26; Iter   420/  960] train: loss: 0.0656392
[Epoch 26; Iter   450/  960] train: loss: 0.0173784
[Epoch 26; Iter   480/  960] train: loss: 0.0476794
[Epoch 26; Iter   510/  960] train: loss: 0.1889658
[Epoch 26; Iter   540/  960] train: loss: 0.0405982
[Epoch 26; Iter   570/  960] train: loss: 0.0502077
[Epoch 26; Iter   600/  960] train: loss: 0.0211090
[Epoch 26; Iter   630/  960] train: loss: 0.0178378
[Epoch 26; Iter   660/  960] train: loss: 0.1723768
[Epoch 26; Iter   690/  960] train: loss: 0.1985635
[Epoch 26; Iter   720/  960] train: loss: 0.1205368
[Epoch 26; Iter   750/  960] train: loss: 0.0217470
[Epoch 26; Iter   780/  960] train: loss: 0.2837157
[Epoch 26; Iter   810/  960] train: loss: 0.0254033
[Epoch 26; Iter   840/  960] train: loss: 0.0258174
[Epoch 26; Iter   870/  960] train: loss: 0.2013273
[Epoch 26; Iter   900/  960] train: loss: 0.0335037
[Epoch 26; Iter   930/  960] train: loss: 0.3818233
[Epoch 26; Iter   960/  960] train: loss: 0.4416498
[Epoch 26] ogbg-molhiv: 0.814852 val loss: 0.149115
[Epoch 26] ogbg-molhiv: 0.824109 test loss: 0.132936
[Epoch 27; Iter    30/  960] train: loss: 0.0271535
[Epoch 27; Iter    60/  960] train: loss: 0.0130511
[Epoch 27; Iter    90/  960] train: loss: 0.0173664
[Epoch 27; Iter   120/  960] train: loss: 0.1746333
[Epoch 27; Iter   150/  960] train: loss: 0.1570738
[Epoch 27; Iter   180/  960] train: loss: 0.1411511
[Epoch 27; Iter   210/  960] train: loss: 0.1288635
[Epoch 27; Iter   240/  960] train: loss: 0.5098793
[Epoch 27; Iter   270/  960] train: loss: 0.0276557
[Epoch 27; Iter   300/  960] train: loss: 0.1442625
[Epoch 27; Iter   330/  960] train: loss: 0.2154675
[Epoch 27; Iter   360/  960] train: loss: 0.1107818
[Epoch 27; Iter   390/  960] train: loss: 0.1045255
[Epoch 27; Iter   420/  960] train: loss: 0.1939894
[Epoch 27; Iter   450/  960] train: loss: 0.1223465
[Epoch 22; Iter   870/  960] train: loss: 0.0220034
[Epoch 22; Iter   900/  960] train: loss: 0.0155796
[Epoch 22; Iter   930/  960] train: loss: 0.1526969
[Epoch 22; Iter   960/  960] train: loss: 0.1670824
[Epoch 22] ogbg-molhiv: 0.794670 val loss: 0.126382
[Epoch 22] ogbg-molhiv: 0.818919 test loss: 0.178852
[Epoch 23; Iter    30/  960] train: loss: 0.0668335
[Epoch 23; Iter    60/  960] train: loss: 0.1518165
[Epoch 23; Iter    90/  960] train: loss: 0.1644831
[Epoch 23; Iter   120/  960] train: loss: 0.0251605
[Epoch 23; Iter   150/  960] train: loss: 0.0537874
[Epoch 23; Iter   180/  960] train: loss: 0.0278580
[Epoch 23; Iter   210/  960] train: loss: 0.0294893
[Epoch 23; Iter   240/  960] train: loss: 0.1034213
[Epoch 23; Iter   270/  960] train: loss: 0.0262212
[Epoch 23; Iter   300/  960] train: loss: 0.0619345
[Epoch 23; Iter   330/  960] train: loss: 0.2294998
[Epoch 23; Iter   360/  960] train: loss: 0.0234287
[Epoch 23; Iter   390/  960] train: loss: 0.2010515
[Epoch 23; Iter   420/  960] train: loss: 0.1593682
[Epoch 23; Iter   450/  960] train: loss: 0.0952874
[Epoch 23; Iter   480/  960] train: loss: 0.0209020
[Epoch 23; Iter   510/  960] train: loss: 0.0272316
[Epoch 23; Iter   540/  960] train: loss: 0.0323517
[Epoch 23; Iter   570/  960] train: loss: 0.0279696
[Epoch 23; Iter   600/  960] train: loss: 0.0898376
[Epoch 23; Iter   630/  960] train: loss: 0.0563243
[Epoch 23; Iter   660/  960] train: loss: 0.0342325
[Epoch 23; Iter   690/  960] train: loss: 0.0176533
[Epoch 23; Iter   720/  960] train: loss: 0.0253299
[Epoch 23; Iter   750/  960] train: loss: 0.1723248
[Epoch 23; Iter   780/  960] train: loss: 0.1437091
[Epoch 23; Iter   810/  960] train: loss: 0.0261794
[Epoch 23; Iter   840/  960] train: loss: 0.1553726
[Epoch 23; Iter   870/  960] train: loss: 0.1258271
[Epoch 23; Iter   900/  960] train: loss: 0.0239109
[Epoch 23; Iter   930/  960] train: loss: 0.0182918
[Epoch 23; Iter   960/  960] train: loss: 0.1316873
[Epoch 23] ogbg-molhiv: 0.808584 val loss: 0.126750
[Epoch 23] ogbg-molhiv: 0.819599 test loss: 0.124232
[Epoch 24; Iter    30/  960] train: loss: 0.0365054
[Epoch 24; Iter    60/  960] train: loss: 0.0167486
[Epoch 24; Iter    90/  960] train: loss: 0.0913497
[Epoch 24; Iter   120/  960] train: loss: 0.0295704
[Epoch 24; Iter   150/  960] train: loss: 0.0818012
[Epoch 24; Iter   180/  960] train: loss: 0.1647789
[Epoch 24; Iter   210/  960] train: loss: 0.0414063
[Epoch 24; Iter   240/  960] train: loss: 0.0405689
[Epoch 24; Iter   270/  960] train: loss: 0.0248027
[Epoch 24; Iter   300/  960] train: loss: 0.0202823
[Epoch 24; Iter   330/  960] train: loss: 0.0614283
[Epoch 24; Iter   360/  960] train: loss: 0.0203408
[Epoch 24; Iter   390/  960] train: loss: 0.0308367
[Epoch 24; Iter   420/  960] train: loss: 0.0324594
[Epoch 24; Iter   450/  960] train: loss: 0.0251269
[Epoch 24; Iter   480/  960] train: loss: 0.0248859
[Epoch 24; Iter   510/  960] train: loss: 0.3685226
[Epoch 24; Iter   540/  960] train: loss: 0.0769597
[Epoch 24; Iter   570/  960] train: loss: 0.0181495
[Epoch 24; Iter   600/  960] train: loss: 0.0273001
[Epoch 24; Iter   630/  960] train: loss: 0.0438517
[Epoch 24; Iter   660/  960] train: loss: 0.0276573
[Epoch 24; Iter   690/  960] train: loss: 0.0763590
[Epoch 24; Iter   720/  960] train: loss: 0.1360807
[Epoch 24; Iter   750/  960] train: loss: 0.1767902
[Epoch 24; Iter   780/  960] train: loss: 0.0217272
[Epoch 24; Iter   810/  960] train: loss: 0.1322460
[Epoch 24; Iter   840/  960] train: loss: 0.0607268
[Epoch 24; Iter   870/  960] train: loss: 0.0249665
[Epoch 24; Iter   900/  960] train: loss: 0.0456973
[Epoch 24; Iter   930/  960] train: loss: 0.0725684
[Epoch 24; Iter   960/  960] train: loss: 0.0771047
[Epoch 24] ogbg-molhiv: 0.799539 val loss: 0.145688
[Epoch 24] ogbg-molhiv: 0.815505 test loss: 0.131392
[Epoch 25; Iter    30/  960] train: loss: 0.0247859
[Epoch 25; Iter    60/  960] train: loss: 0.1040738
[Epoch 25; Iter    90/  960] train: loss: 0.6511862
[Epoch 25; Iter   120/  960] train: loss: 0.1730112
[Epoch 25; Iter   150/  960] train: loss: 0.0272345
[Epoch 25; Iter   180/  960] train: loss: 0.1816266
[Epoch 25; Iter   210/  960] train: loss: 0.1742921
[Epoch 25; Iter   240/  960] train: loss: 0.0701730
[Epoch 25; Iter   270/  960] train: loss: 0.0184864
[Epoch 25; Iter   300/  960] train: loss: 0.1644272
[Epoch 25; Iter   330/  960] train: loss: 0.1438813
[Epoch 25; Iter   360/  960] train: loss: 0.4488057
[Epoch 25; Iter   390/  960] train: loss: 0.0508158
[Epoch 25; Iter   420/  960] train: loss: 0.1979657
[Epoch 25; Iter   450/  960] train: loss: 0.1179830
[Epoch 25; Iter   480/  960] train: loss: 0.0997222
[Epoch 25; Iter   510/  960] train: loss: 0.0444556
[Epoch 25; Iter   540/  960] train: loss: 0.0208759
[Epoch 25; Iter   570/  960] train: loss: 0.0943451
[Epoch 25; Iter   600/  960] train: loss: 0.0675375
[Epoch 25; Iter   630/  960] train: loss: 0.1507800
[Epoch 25; Iter   660/  960] train: loss: 0.0357348
[Epoch 25; Iter   690/  960] train: loss: 0.0437116
[Epoch 25; Iter   720/  960] train: loss: 0.3202364
[Epoch 25; Iter   750/  960] train: loss: 0.1532952
[Epoch 25; Iter   780/  960] train: loss: 0.2414562
[Epoch 25; Iter   810/  960] train: loss: 0.1235174
[Epoch 25; Iter   840/  960] train: loss: 0.3957367
[Epoch 25; Iter   870/  960] train: loss: 0.1590739
[Epoch 25; Iter   900/  960] train: loss: 0.1556066
[Epoch 25; Iter   930/  960] train: loss: 0.0194451
[Epoch 25; Iter   960/  960] train: loss: 0.0210039
[Epoch 25] ogbg-molhiv: 0.792306 val loss: 0.128506
[Epoch 25] ogbg-molhiv: 0.816070 test loss: 0.126955
[Epoch 26; Iter    30/  960] train: loss: 0.0248620
[Epoch 26; Iter    60/  960] train: loss: 0.0276102
[Epoch 26; Iter    90/  960] train: loss: 0.0390991
[Epoch 26; Iter   120/  960] train: loss: 0.0217552
[Epoch 26; Iter   150/  960] train: loss: 0.0837142
[Epoch 26; Iter   180/  960] train: loss: 0.0489471
[Epoch 26; Iter   210/  960] train: loss: 0.1231285
[Epoch 26; Iter   240/  960] train: loss: 0.0970178
[Epoch 26; Iter   270/  960] train: loss: 0.0551870
[Epoch 26; Iter   300/  960] train: loss: 0.0280659
[Epoch 26; Iter   330/  960] train: loss: 0.0282436
[Epoch 26; Iter   360/  960] train: loss: 0.1642770
[Epoch 26; Iter   390/  960] train: loss: 0.1118895
[Epoch 26; Iter   420/  960] train: loss: 0.0418502
[Epoch 26; Iter   450/  960] train: loss: 0.1075849
[Epoch 26; Iter   480/  960] train: loss: 0.0339446
[Epoch 26; Iter   510/  960] train: loss: 0.0721884
[Epoch 26; Iter   540/  960] train: loss: 0.0255447
[Epoch 26; Iter   570/  960] train: loss: 0.0501047
[Epoch 26; Iter   600/  960] train: loss: 0.0187634
[Epoch 26; Iter   630/  960] train: loss: 0.2822386
[Epoch 26; Iter   660/  960] train: loss: 0.0317912
[Epoch 26; Iter   690/  960] train: loss: 0.0593639
[Epoch 26; Iter   720/  960] train: loss: 0.0888284
[Epoch 26; Iter   750/  960] train: loss: 0.0232705
[Epoch 26; Iter   780/  960] train: loss: 0.0191799
[Epoch 26; Iter   810/  960] train: loss: 0.0563554
[Epoch 26; Iter   840/  960] train: loss: 0.0210182
[Epoch 26; Iter   870/  960] train: loss: 0.1601263
[Epoch 26; Iter   900/  960] train: loss: 0.0485754
[Epoch 26; Iter   930/  960] train: loss: 0.0804059
[Epoch 26; Iter   960/  960] train: loss: 0.1394832
[Epoch 26] ogbg-molhiv: 0.803914 val loss: 0.142272
[Epoch 26] ogbg-molhiv: 0.823750 test loss: 0.128414
[Epoch 27; Iter    30/  960] train: loss: 0.0453371
[Epoch 27; Iter    60/  960] train: loss: 0.0497269
[Epoch 27; Iter    90/  960] train: loss: 0.1847066
[Epoch 27; Iter   120/  960] train: loss: 0.0248763
[Epoch 27; Iter   150/  960] train: loss: 0.1988907
[Epoch 27; Iter   180/  960] train: loss: 0.0527126
[Epoch 27; Iter   210/  960] train: loss: 0.0193530
[Epoch 27; Iter   240/  960] train: loss: 0.0235936
[Epoch 27; Iter   270/  960] train: loss: 0.1313775
[Epoch 27; Iter   300/  960] train: loss: 0.5564880
[Epoch 27; Iter   330/  960] train: loss: 0.1504490
[Epoch 27; Iter   360/  960] train: loss: 0.1349715
[Epoch 27; Iter   390/  960] train: loss: 0.1258267
[Epoch 27; Iter   420/  960] train: loss: 0.0167544
[Epoch 27; Iter   450/  960] train: loss: 0.0392901
[Epoch 24; Iter   389/ 1097] train: loss: 0.1663927
[Epoch 24; Iter   419/ 1097] train: loss: 0.1224229
[Epoch 24; Iter   449/ 1097] train: loss: 0.1226428
[Epoch 24; Iter   479/ 1097] train: loss: 0.0296727
[Epoch 24; Iter   509/ 1097] train: loss: 0.0187495
[Epoch 24; Iter   539/ 1097] train: loss: 0.0189579
[Epoch 24; Iter   569/ 1097] train: loss: 0.1485274
[Epoch 24; Iter   599/ 1097] train: loss: 0.0378046
[Epoch 24; Iter   629/ 1097] train: loss: 0.5470776
[Epoch 24; Iter   659/ 1097] train: loss: 0.0340502
[Epoch 24; Iter   689/ 1097] train: loss: 0.1789745
[Epoch 24; Iter   719/ 1097] train: loss: 0.3470748
[Epoch 24; Iter   749/ 1097] train: loss: 0.1403816
[Epoch 24; Iter   779/ 1097] train: loss: 0.3071352
[Epoch 24; Iter   809/ 1097] train: loss: 0.0537702
[Epoch 24; Iter   839/ 1097] train: loss: 0.1521685
[Epoch 24; Iter   869/ 1097] train: loss: 0.0270287
[Epoch 24; Iter   899/ 1097] train: loss: 0.0231967
[Epoch 24; Iter   929/ 1097] train: loss: 0.0395997
[Epoch 24; Iter   959/ 1097] train: loss: 0.0546013
[Epoch 24; Iter   989/ 1097] train: loss: 0.0289270
[Epoch 24; Iter  1019/ 1097] train: loss: 0.0242035
[Epoch 24; Iter  1049/ 1097] train: loss: 0.0381222
[Epoch 24; Iter  1079/ 1097] train: loss: 0.0264827
[Epoch 24] ogbg-molhiv: 0.816186 val loss: 0.125580
[Epoch 24] ogbg-molhiv: 0.803497 test loss: 0.115675
[Epoch 25; Iter    12/ 1097] train: loss: 0.0283375
[Epoch 25; Iter    42/ 1097] train: loss: 0.1734203
[Epoch 25; Iter    72/ 1097] train: loss: 0.1776993
[Epoch 25; Iter   102/ 1097] train: loss: 0.0574816
[Epoch 25; Iter   132/ 1097] train: loss: 0.0323893
[Epoch 25; Iter   162/ 1097] train: loss: 0.1782524
[Epoch 25; Iter   192/ 1097] train: loss: 0.0490287
[Epoch 25; Iter   222/ 1097] train: loss: 0.0362984
[Epoch 25; Iter   252/ 1097] train: loss: 0.1286377
[Epoch 25; Iter   282/ 1097] train: loss: 0.1921131
[Epoch 25; Iter   312/ 1097] train: loss: 0.0338921
[Epoch 25; Iter   342/ 1097] train: loss: 0.1534452
[Epoch 25; Iter   372/ 1097] train: loss: 0.3900140
[Epoch 25; Iter   402/ 1097] train: loss: 0.0396750
[Epoch 25; Iter   432/ 1097] train: loss: 0.3322247
[Epoch 25; Iter   462/ 1097] train: loss: 0.0304604
[Epoch 25; Iter   492/ 1097] train: loss: 0.0324525
[Epoch 25; Iter   522/ 1097] train: loss: 0.0291222
[Epoch 25; Iter   552/ 1097] train: loss: 0.1393775
[Epoch 25; Iter   582/ 1097] train: loss: 0.0217419
[Epoch 25; Iter   612/ 1097] train: loss: 0.0240614
[Epoch 25; Iter   642/ 1097] train: loss: 0.1190308
[Epoch 25; Iter   672/ 1097] train: loss: 0.1038113
[Epoch 25; Iter   702/ 1097] train: loss: 0.2318132
[Epoch 25; Iter   732/ 1097] train: loss: 0.0890028
[Epoch 25; Iter   762/ 1097] train: loss: 0.0273884
[Epoch 25; Iter   792/ 1097] train: loss: 0.0303385
[Epoch 25; Iter   822/ 1097] train: loss: 0.0412623
[Epoch 25; Iter   852/ 1097] train: loss: 0.0463096
[Epoch 25; Iter   882/ 1097] train: loss: 0.0185963
[Epoch 25; Iter   912/ 1097] train: loss: 0.0286610
[Epoch 25; Iter   942/ 1097] train: loss: 0.1602713
[Epoch 25; Iter   972/ 1097] train: loss: 0.0834492
[Epoch 25; Iter  1002/ 1097] train: loss: 0.0368584
[Epoch 25; Iter  1032/ 1097] train: loss: 0.1874278
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0325042
[Epoch 25; Iter  1092/ 1097] train: loss: 0.2486531
[Epoch 25] ogbg-molhiv: 0.800347 val loss: 0.127322
[Epoch 25] ogbg-molhiv: 0.777849 test loss: 0.121750
[Epoch 26; Iter    25/ 1097] train: loss: 0.0320764
[Epoch 26; Iter    55/ 1097] train: loss: 0.0344972
[Epoch 26; Iter    85/ 1097] train: loss: 0.0775289
[Epoch 26; Iter   115/ 1097] train: loss: 0.2956187
[Epoch 26; Iter   145/ 1097] train: loss: 0.1532389
[Epoch 26; Iter   175/ 1097] train: loss: 0.0338459
[Epoch 26; Iter   205/ 1097] train: loss: 0.1639432
[Epoch 26; Iter   235/ 1097] train: loss: 0.0223181
[Epoch 26; Iter   265/ 1097] train: loss: 0.0721199
[Epoch 26; Iter   295/ 1097] train: loss: 0.0251275
[Epoch 26; Iter   325/ 1097] train: loss: 0.1752497
[Epoch 26; Iter   355/ 1097] train: loss: 0.1844979
[Epoch 26; Iter   385/ 1097] train: loss: 0.0269503
[Epoch 26; Iter   415/ 1097] train: loss: 0.1366650
[Epoch 26; Iter   445/ 1097] train: loss: 0.0220052
[Epoch 26; Iter   475/ 1097] train: loss: 0.0326061
[Epoch 26; Iter   505/ 1097] train: loss: 0.1025820
[Epoch 26; Iter   535/ 1097] train: loss: 0.0637639
[Epoch 26; Iter   565/ 1097] train: loss: 0.0232125
[Epoch 26; Iter   595/ 1097] train: loss: 0.0245977
[Epoch 26; Iter   625/ 1097] train: loss: 0.0192930
[Epoch 26; Iter   655/ 1097] train: loss: 0.1196278
[Epoch 26; Iter   685/ 1097] train: loss: 0.0324384
[Epoch 26; Iter   715/ 1097] train: loss: 0.0248424
[Epoch 26; Iter   745/ 1097] train: loss: 0.2106110
[Epoch 26; Iter   775/ 1097] train: loss: 0.0942091
[Epoch 26; Iter   805/ 1097] train: loss: 0.0497542
[Epoch 26; Iter   835/ 1097] train: loss: 0.0370386
[Epoch 26; Iter   865/ 1097] train: loss: 0.0521718
[Epoch 26; Iter   895/ 1097] train: loss: 0.0711857
[Epoch 26; Iter   925/ 1097] train: loss: 0.0887227
[Epoch 26; Iter   955/ 1097] train: loss: 0.1415233
[Epoch 26; Iter   985/ 1097] train: loss: 0.2372140
[Epoch 26; Iter  1015/ 1097] train: loss: 0.0265523
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0713022
[Epoch 26; Iter  1075/ 1097] train: loss: 0.0601908
[Epoch 26] ogbg-molhiv: 0.818636 val loss: 0.117514
[Epoch 26] ogbg-molhiv: 0.797944 test loss: 0.117992
[Epoch 27; Iter     8/ 1097] train: loss: 0.0569697
[Epoch 27; Iter    38/ 1097] train: loss: 0.0366688
[Epoch 27; Iter    68/ 1097] train: loss: 0.1211604
[Epoch 27; Iter    98/ 1097] train: loss: 0.0262951
[Epoch 27; Iter   128/ 1097] train: loss: 0.1197684
[Epoch 27; Iter   158/ 1097] train: loss: 0.0721430
[Epoch 27; Iter   188/ 1097] train: loss: 0.0366997
[Epoch 27; Iter   218/ 1097] train: loss: 0.1738515
[Epoch 27; Iter   248/ 1097] train: loss: 0.0183741
[Epoch 27; Iter   278/ 1097] train: loss: 0.2678237
[Epoch 27; Iter   308/ 1097] train: loss: 0.0384538
[Epoch 27; Iter   338/ 1097] train: loss: 0.0871786
[Epoch 27; Iter   368/ 1097] train: loss: 0.0841771
[Epoch 27; Iter   398/ 1097] train: loss: 0.1093546
[Epoch 27; Iter   428/ 1097] train: loss: 0.0346401
[Epoch 27; Iter   458/ 1097] train: loss: 0.0210252
[Epoch 27; Iter   488/ 1097] train: loss: 0.1486293
[Epoch 27; Iter   518/ 1097] train: loss: 0.0300057
[Epoch 27; Iter   548/ 1097] train: loss: 0.0383377
[Epoch 27; Iter   578/ 1097] train: loss: 0.1570750
[Epoch 27; Iter   608/ 1097] train: loss: 0.0255362
[Epoch 27; Iter   638/ 1097] train: loss: 0.2179829
[Epoch 27; Iter   668/ 1097] train: loss: 0.1087442
[Epoch 27; Iter   698/ 1097] train: loss: 0.0415538
[Epoch 27; Iter   728/ 1097] train: loss: 0.0351923
[Epoch 27; Iter   758/ 1097] train: loss: 0.0367456
[Epoch 27; Iter   788/ 1097] train: loss: 0.1271188
[Epoch 27; Iter   818/ 1097] train: loss: 0.0911863
[Epoch 27; Iter   848/ 1097] train: loss: 0.0427810
[Epoch 27; Iter   878/ 1097] train: loss: 0.0575424
[Epoch 27; Iter   908/ 1097] train: loss: 0.0330475
[Epoch 27; Iter   938/ 1097] train: loss: 0.0241303
[Epoch 27; Iter   968/ 1097] train: loss: 0.0340717
[Epoch 27; Iter   998/ 1097] train: loss: 0.4299454
[Epoch 27; Iter  1028/ 1097] train: loss: 0.2222578
[Epoch 27; Iter  1058/ 1097] train: loss: 0.1144844
[Epoch 27; Iter  1088/ 1097] train: loss: 0.0917655
[Epoch 27] ogbg-molhiv: 0.804771 val loss: 0.116643
[Epoch 27] ogbg-molhiv: 0.805605 test loss: 0.112107
[Epoch 28; Iter    21/ 1097] train: loss: 0.0258262
[Epoch 28; Iter    51/ 1097] train: loss: 0.0229332
[Epoch 28; Iter    81/ 1097] train: loss: 0.1703457
[Epoch 28; Iter   111/ 1097] train: loss: 0.0933906
[Epoch 28; Iter   141/ 1097] train: loss: 0.0228012
[Epoch 28; Iter   171/ 1097] train: loss: 0.0492808
[Epoch 28; Iter   201/ 1097] train: loss: 0.0217604
[Epoch 28; Iter   231/ 1097] train: loss: 0.0274276
[Epoch 28; Iter   261/ 1097] train: loss: 0.1777417
[Epoch 28; Iter   291/ 1097] train: loss: 0.0393225
[Epoch 28; Iter   321/ 1097] train: loss: 0.1041934
[Epoch 28; Iter   351/ 1097] train: loss: 0.1676150
[Epoch 28; Iter   381/ 1097] train: loss: 0.1956877
[Epoch 28; Iter   411/ 1097] train: loss: 0.0482294
[Epoch 28; Iter   441/ 1097] train: loss: 0.0384713
[Epoch 24; Iter   389/ 1097] train: loss: 0.0650455
[Epoch 24; Iter   419/ 1097] train: loss: 0.0290112
[Epoch 24; Iter   449/ 1097] train: loss: 0.2261611
[Epoch 24; Iter   479/ 1097] train: loss: 0.0213890
[Epoch 24; Iter   509/ 1097] train: loss: 0.1117498
[Epoch 24; Iter   539/ 1097] train: loss: 0.1369640
[Epoch 24; Iter   569/ 1097] train: loss: 0.0330369
[Epoch 24; Iter   599/ 1097] train: loss: 0.2062232
[Epoch 24; Iter   629/ 1097] train: loss: 0.0502123
[Epoch 24; Iter   659/ 1097] train: loss: 0.0319770
[Epoch 24; Iter   689/ 1097] train: loss: 0.0276975
[Epoch 24; Iter   719/ 1097] train: loss: 0.1396094
[Epoch 24; Iter   749/ 1097] train: loss: 0.2444094
[Epoch 24; Iter   779/ 1097] train: loss: 0.3821300
[Epoch 24; Iter   809/ 1097] train: loss: 0.1978077
[Epoch 24; Iter   839/ 1097] train: loss: 0.0173630
[Epoch 24; Iter   869/ 1097] train: loss: 0.0366245
[Epoch 24; Iter   899/ 1097] train: loss: 0.0217532
[Epoch 24; Iter   929/ 1097] train: loss: 0.0415173
[Epoch 24; Iter   959/ 1097] train: loss: 0.0176732
[Epoch 24; Iter   989/ 1097] train: loss: 0.0269416
[Epoch 24; Iter  1019/ 1097] train: loss: 0.0311649
[Epoch 24; Iter  1049/ 1097] train: loss: 0.2097290
[Epoch 24; Iter  1079/ 1097] train: loss: 0.1776499
[Epoch 24] ogbg-molhiv: 0.780757 val loss: 0.210556
[Epoch 24] ogbg-molhiv: 0.823660 test loss: 0.164955
[Epoch 25; Iter    12/ 1097] train: loss: 0.0174675
[Epoch 25; Iter    42/ 1097] train: loss: 0.1856409
[Epoch 25; Iter    72/ 1097] train: loss: 0.0264150
[Epoch 25; Iter   102/ 1097] train: loss: 0.1461360
[Epoch 25; Iter   132/ 1097] train: loss: 0.2432642
[Epoch 25; Iter   162/ 1097] train: loss: 0.0526068
[Epoch 25; Iter   192/ 1097] train: loss: 0.3590756
[Epoch 25; Iter   222/ 1097] train: loss: 0.0169615
[Epoch 25; Iter   252/ 1097] train: loss: 0.1368110
[Epoch 25; Iter   282/ 1097] train: loss: 0.0435853
[Epoch 25; Iter   312/ 1097] train: loss: 0.0202142
[Epoch 25; Iter   342/ 1097] train: loss: 0.1038932
[Epoch 25; Iter   372/ 1097] train: loss: 0.3696862
[Epoch 25; Iter   402/ 1097] train: loss: 0.0217124
[Epoch 25; Iter   432/ 1097] train: loss: 0.2660300
[Epoch 25; Iter   462/ 1097] train: loss: 0.0248556
[Epoch 25; Iter   492/ 1097] train: loss: 0.0297360
[Epoch 25; Iter   522/ 1097] train: loss: 0.0226621
[Epoch 25; Iter   552/ 1097] train: loss: 0.2232303
[Epoch 25; Iter   582/ 1097] train: loss: 0.3145440
[Epoch 25; Iter   612/ 1097] train: loss: 0.0727595
[Epoch 25; Iter   642/ 1097] train: loss: 0.1168259
[Epoch 25; Iter   672/ 1097] train: loss: 0.0805036
[Epoch 25; Iter   702/ 1097] train: loss: 0.0168059
[Epoch 25; Iter   732/ 1097] train: loss: 0.0791111
[Epoch 25; Iter   762/ 1097] train: loss: 0.0961180
[Epoch 25; Iter   792/ 1097] train: loss: 0.4556808
[Epoch 25; Iter   822/ 1097] train: loss: 0.0289543
[Epoch 25; Iter   852/ 1097] train: loss: 0.1145183
[Epoch 25; Iter   882/ 1097] train: loss: 0.2145541
[Epoch 25; Iter   912/ 1097] train: loss: 0.1400689
[Epoch 25; Iter   942/ 1097] train: loss: 0.0295924
[Epoch 25; Iter   972/ 1097] train: loss: 0.0291164
[Epoch 25; Iter  1002/ 1097] train: loss: 0.0556061
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0750302
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0185463
[Epoch 25; Iter  1092/ 1097] train: loss: 0.1471072
[Epoch 25] ogbg-molhiv: 0.779676 val loss: 0.329179
[Epoch 25] ogbg-molhiv: 0.798292 test loss: 0.124358
[Epoch 26; Iter    25/ 1097] train: loss: 0.0157280
[Epoch 26; Iter    55/ 1097] train: loss: 0.2480810
[Epoch 26; Iter    85/ 1097] train: loss: 0.0220167
[Epoch 26; Iter   115/ 1097] train: loss: 0.1425510
[Epoch 26; Iter   145/ 1097] train: loss: 0.0266111
[Epoch 26; Iter   175/ 1097] train: loss: 0.1560175
[Epoch 26; Iter   205/ 1097] train: loss: 0.0475840
[Epoch 26; Iter   235/ 1097] train: loss: 0.2198244
[Epoch 26; Iter   265/ 1097] train: loss: 0.1236108
[Epoch 26; Iter   295/ 1097] train: loss: 0.1213831
[Epoch 26; Iter   325/ 1097] train: loss: 0.0207007
[Epoch 26; Iter   355/ 1097] train: loss: 0.1219498
[Epoch 26; Iter   385/ 1097] train: loss: 0.0877850
[Epoch 26; Iter   415/ 1097] train: loss: 0.2215094
[Epoch 26; Iter   445/ 1097] train: loss: 0.0852968
[Epoch 26; Iter   475/ 1097] train: loss: 0.0299367
[Epoch 26; Iter   505/ 1097] train: loss: 0.0236838
[Epoch 26; Iter   535/ 1097] train: loss: 0.1539944
[Epoch 26; Iter   565/ 1097] train: loss: 0.4258707
[Epoch 26; Iter   595/ 1097] train: loss: 0.1203235
[Epoch 26; Iter   625/ 1097] train: loss: 0.1586970
[Epoch 26; Iter   655/ 1097] train: loss: 0.0460462
[Epoch 26; Iter   685/ 1097] train: loss: 0.0341928
[Epoch 26; Iter   715/ 1097] train: loss: 0.0818493
[Epoch 26; Iter   745/ 1097] train: loss: 0.0228216
[Epoch 26; Iter   775/ 1097] train: loss: 0.0548465
[Epoch 26; Iter   805/ 1097] train: loss: 0.1517872
[Epoch 26; Iter   835/ 1097] train: loss: 0.0394646
[Epoch 26; Iter   865/ 1097] train: loss: 0.0290180
[Epoch 26; Iter   895/ 1097] train: loss: 0.0278390
[Epoch 26; Iter   925/ 1097] train: loss: 0.0619941
[Epoch 26; Iter   955/ 1097] train: loss: 0.3091421
[Epoch 26; Iter   985/ 1097] train: loss: 0.1272721
[Epoch 26; Iter  1015/ 1097] train: loss: 0.0699832
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0193951
[Epoch 26; Iter  1075/ 1097] train: loss: 0.2111836
[Epoch 26] ogbg-molhiv: 0.768780 val loss: 0.136612
[Epoch 26] ogbg-molhiv: 0.803448 test loss: 0.124624
[Epoch 27; Iter     8/ 1097] train: loss: 0.0230121
[Epoch 27; Iter    38/ 1097] train: loss: 0.1283194
[Epoch 27; Iter    68/ 1097] train: loss: 0.0541190
[Epoch 27; Iter    98/ 1097] train: loss: 0.0893633
[Epoch 27; Iter   128/ 1097] train: loss: 0.0535580
[Epoch 27; Iter   158/ 1097] train: loss: 0.0217077
[Epoch 27; Iter   188/ 1097] train: loss: 0.0277080
[Epoch 27; Iter   218/ 1097] train: loss: 0.0529229
[Epoch 27; Iter   248/ 1097] train: loss: 0.0367120
[Epoch 27; Iter   278/ 1097] train: loss: 0.0469098
[Epoch 27; Iter   308/ 1097] train: loss: 0.0249894
[Epoch 27; Iter   338/ 1097] train: loss: 0.1555241
[Epoch 27; Iter   368/ 1097] train: loss: 0.0215827
[Epoch 27; Iter   398/ 1097] train: loss: 0.1717665
[Epoch 27; Iter   428/ 1097] train: loss: 0.0643335
[Epoch 27; Iter   458/ 1097] train: loss: 0.0284730
[Epoch 27; Iter   488/ 1097] train: loss: 0.0366471
[Epoch 27; Iter   518/ 1097] train: loss: 0.0341499
[Epoch 27; Iter   548/ 1097] train: loss: 0.0768705
[Epoch 27; Iter   578/ 1097] train: loss: 0.0327038
[Epoch 27; Iter   608/ 1097] train: loss: 0.1443615
[Epoch 27; Iter   638/ 1097] train: loss: 0.0397318
[Epoch 27; Iter   668/ 1097] train: loss: 0.0255332
[Epoch 27; Iter   698/ 1097] train: loss: 0.1617557
[Epoch 27; Iter   728/ 1097] train: loss: 0.0548974
[Epoch 27; Iter   758/ 1097] train: loss: 0.2048041
[Epoch 27; Iter   788/ 1097] train: loss: 0.0453858
[Epoch 27; Iter   818/ 1097] train: loss: 0.0479497
[Epoch 27; Iter   848/ 1097] train: loss: 0.0171545
[Epoch 27; Iter   878/ 1097] train: loss: 0.1462390
[Epoch 27; Iter   908/ 1097] train: loss: 0.0222725
[Epoch 27; Iter   938/ 1097] train: loss: 0.2301795
[Epoch 27; Iter   968/ 1097] train: loss: 0.4295500
[Epoch 27; Iter   998/ 1097] train: loss: 0.1467232
[Epoch 27; Iter  1028/ 1097] train: loss: 0.0503298
[Epoch 27; Iter  1058/ 1097] train: loss: 0.0643021
[Epoch 27; Iter  1088/ 1097] train: loss: 0.2097680
[Epoch 27] ogbg-molhiv: 0.782628 val loss: 0.191131
[Epoch 27] ogbg-molhiv: 0.823992 test loss: 0.225557
[Epoch 28; Iter    21/ 1097] train: loss: 0.0706465
[Epoch 28; Iter    51/ 1097] train: loss: 0.0216954
[Epoch 28; Iter    81/ 1097] train: loss: 0.1852366
[Epoch 28; Iter   111/ 1097] train: loss: 0.1550407
[Epoch 28; Iter   141/ 1097] train: loss: 0.0466752
[Epoch 28; Iter   171/ 1097] train: loss: 0.0177645
[Epoch 28; Iter   201/ 1097] train: loss: 0.1302092
[Epoch 28; Iter   231/ 1097] train: loss: 0.0255635
[Epoch 28; Iter   261/ 1097] train: loss: 0.1636042
[Epoch 28; Iter   291/ 1097] train: loss: 0.0253447
[Epoch 28; Iter   321/ 1097] train: loss: 0.0926561
[Epoch 28; Iter   351/ 1097] train: loss: 0.1785296
[Epoch 28; Iter   381/ 1097] train: loss: 0.0538630
[Epoch 28; Iter   411/ 1097] train: loss: 0.0323697
[Epoch 28; Iter   441/ 1097] train: loss: 0.0249149
[Epoch 24; Iter   389/ 1097] train: loss: 0.0577952
[Epoch 24; Iter   419/ 1097] train: loss: 0.0348130
[Epoch 24; Iter   449/ 1097] train: loss: 0.1263177
[Epoch 24; Iter   479/ 1097] train: loss: 0.2340907
[Epoch 24; Iter   509/ 1097] train: loss: 0.0240999
[Epoch 24; Iter   539/ 1097] train: loss: 0.0700818
[Epoch 24; Iter   569/ 1097] train: loss: 0.0214110
[Epoch 24; Iter   599/ 1097] train: loss: 0.1888906
[Epoch 24; Iter   629/ 1097] train: loss: 0.0454515
[Epoch 24; Iter   659/ 1097] train: loss: 0.2896832
[Epoch 24; Iter   689/ 1097] train: loss: 0.1989251
[Epoch 24; Iter   719/ 1097] train: loss: 0.0279371
[Epoch 24; Iter   749/ 1097] train: loss: 0.1839504
[Epoch 24; Iter   779/ 1097] train: loss: 0.0231058
[Epoch 24; Iter   809/ 1097] train: loss: 0.1014901
[Epoch 24; Iter   839/ 1097] train: loss: 0.0879365
[Epoch 24; Iter   869/ 1097] train: loss: 0.0164563
[Epoch 24; Iter   899/ 1097] train: loss: 0.1435731
[Epoch 24; Iter   929/ 1097] train: loss: 0.0368356
[Epoch 24; Iter   959/ 1097] train: loss: 0.0188012
[Epoch 24; Iter   989/ 1097] train: loss: 0.0199613
[Epoch 24; Iter  1019/ 1097] train: loss: 0.2501865
[Epoch 24; Iter  1049/ 1097] train: loss: 0.0438875
[Epoch 24; Iter  1079/ 1097] train: loss: 0.1022647
[Epoch 24] ogbg-molhiv: 0.808997 val loss: 0.116527
[Epoch 24] ogbg-molhiv: 0.817052 test loss: 0.114666
[Epoch 25; Iter    12/ 1097] train: loss: 0.1279081
[Epoch 25; Iter    42/ 1097] train: loss: 0.1070492
[Epoch 25; Iter    72/ 1097] train: loss: 0.0254641
[Epoch 25; Iter   102/ 1097] train: loss: 0.0460717
[Epoch 25; Iter   132/ 1097] train: loss: 0.2671273
[Epoch 25; Iter   162/ 1097] train: loss: 0.1914488
[Epoch 25; Iter   192/ 1097] train: loss: 0.0198148
[Epoch 25; Iter   222/ 1097] train: loss: 0.0886187
[Epoch 25; Iter   252/ 1097] train: loss: 0.0184939
[Epoch 25; Iter   282/ 1097] train: loss: 0.0971144
[Epoch 25; Iter   312/ 1097] train: loss: 0.1694208
[Epoch 25; Iter   342/ 1097] train: loss: 0.0321171
[Epoch 25; Iter   372/ 1097] train: loss: 0.0236743
[Epoch 25; Iter   402/ 1097] train: loss: 0.1027144
[Epoch 25; Iter   432/ 1097] train: loss: 0.0248102
[Epoch 25; Iter   462/ 1097] train: loss: 0.0203487
[Epoch 25; Iter   492/ 1097] train: loss: 0.0310237
[Epoch 25; Iter   522/ 1097] train: loss: 0.0193377
[Epoch 25; Iter   552/ 1097] train: loss: 0.1966075
[Epoch 25; Iter   582/ 1097] train: loss: 0.1681146
[Epoch 25; Iter   612/ 1097] train: loss: 0.0235352
[Epoch 25; Iter   642/ 1097] train: loss: 0.0270571
[Epoch 25; Iter   672/ 1097] train: loss: 0.1483755
[Epoch 25; Iter   702/ 1097] train: loss: 0.1513815
[Epoch 25; Iter   732/ 1097] train: loss: 0.0409182
[Epoch 25; Iter   762/ 1097] train: loss: 0.1023916
[Epoch 25; Iter   792/ 1097] train: loss: 0.0477750
[Epoch 25; Iter   822/ 1097] train: loss: 0.0245379
[Epoch 25; Iter   852/ 1097] train: loss: 0.0183357
[Epoch 25; Iter   882/ 1097] train: loss: 0.1113177
[Epoch 25; Iter   912/ 1097] train: loss: 0.1357843
[Epoch 25; Iter   942/ 1097] train: loss: 0.1603045
[Epoch 25; Iter   972/ 1097] train: loss: 0.0165783
[Epoch 25; Iter  1002/ 1097] train: loss: 0.2010596
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0174884
[Epoch 25; Iter  1062/ 1097] train: loss: 0.1197185
[Epoch 25; Iter  1092/ 1097] train: loss: 0.0220536
[Epoch 25] ogbg-molhiv: 0.825398 val loss: 0.120220
[Epoch 25] ogbg-molhiv: 0.817028 test loss: 0.124412
[Epoch 26; Iter    25/ 1097] train: loss: 0.0793497
[Epoch 26; Iter    55/ 1097] train: loss: 0.0684406
[Epoch 26; Iter    85/ 1097] train: loss: 0.1042289
[Epoch 26; Iter   115/ 1097] train: loss: 0.0382842
[Epoch 26; Iter   145/ 1097] train: loss: 0.1797149
[Epoch 26; Iter   175/ 1097] train: loss: 0.0258307
[Epoch 26; Iter   205/ 1097] train: loss: 0.0189120
[Epoch 26; Iter   235/ 1097] train: loss: 0.0479954
[Epoch 26; Iter   265/ 1097] train: loss: 0.1097524
[Epoch 26; Iter   295/ 1097] train: loss: 0.0181315
[Epoch 26; Iter   325/ 1097] train: loss: 0.0323178
[Epoch 26; Iter   355/ 1097] train: loss: 0.2135666
[Epoch 26; Iter   385/ 1097] train: loss: 0.0521206
[Epoch 26; Iter   415/ 1097] train: loss: 0.0884446
[Epoch 26; Iter   445/ 1097] train: loss: 0.1733963
[Epoch 26; Iter   475/ 1097] train: loss: 0.1140660
[Epoch 26; Iter   505/ 1097] train: loss: 0.0548036
[Epoch 26; Iter   535/ 1097] train: loss: 0.0212899
[Epoch 26; Iter   565/ 1097] train: loss: 0.1926228
[Epoch 26; Iter   595/ 1097] train: loss: 0.0177393
[Epoch 26; Iter   625/ 1097] train: loss: 0.0144781
[Epoch 26; Iter   655/ 1097] train: loss: 0.0777244
[Epoch 26; Iter   685/ 1097] train: loss: 0.0305261
[Epoch 26; Iter   715/ 1097] train: loss: 0.0276895
[Epoch 26; Iter   745/ 1097] train: loss: 0.0402668
[Epoch 26; Iter   775/ 1097] train: loss: 0.0198900
[Epoch 26; Iter   805/ 1097] train: loss: 0.1572206
[Epoch 26; Iter   835/ 1097] train: loss: 0.0330936
[Epoch 26; Iter   865/ 1097] train: loss: 0.0212147
[Epoch 26; Iter   895/ 1097] train: loss: 0.0480106
[Epoch 26; Iter   925/ 1097] train: loss: 0.0256800
[Epoch 26; Iter   955/ 1097] train: loss: 0.1861043
[Epoch 26; Iter   985/ 1097] train: loss: 0.0214093
[Epoch 26; Iter  1015/ 1097] train: loss: 0.0255572
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0414559
[Epoch 26; Iter  1075/ 1097] train: loss: 0.0564274
[Epoch 26] ogbg-molhiv: 0.809179 val loss: 0.156128
[Epoch 26] ogbg-molhiv: 0.823676 test loss: 0.112697
[Epoch 27; Iter     8/ 1097] train: loss: 0.0183319
[Epoch 27; Iter    38/ 1097] train: loss: 0.0183640
[Epoch 27; Iter    68/ 1097] train: loss: 0.0169025
[Epoch 27; Iter    98/ 1097] train: loss: 0.1356978
[Epoch 27; Iter   128/ 1097] train: loss: 0.1135936
[Epoch 27; Iter   158/ 1097] train: loss: 0.0230965
[Epoch 27; Iter   188/ 1097] train: loss: 0.0524369
[Epoch 27; Iter   218/ 1097] train: loss: 0.1727764
[Epoch 27; Iter   248/ 1097] train: loss: 0.0265914
[Epoch 27; Iter   278/ 1097] train: loss: 0.1408979
[Epoch 27; Iter   308/ 1097] train: loss: 0.0377322
[Epoch 27; Iter   338/ 1097] train: loss: 0.0217181
[Epoch 27; Iter   368/ 1097] train: loss: 0.0333439
[Epoch 27; Iter   398/ 1097] train: loss: 0.1634086
[Epoch 27; Iter   428/ 1097] train: loss: 0.1456248
[Epoch 27; Iter   458/ 1097] train: loss: 0.0255560
[Epoch 27; Iter   488/ 1097] train: loss: 0.2000629
[Epoch 27; Iter   518/ 1097] train: loss: 0.0493665
[Epoch 27; Iter   548/ 1097] train: loss: 0.0228563
[Epoch 27; Iter   578/ 1097] train: loss: 0.0220172
[Epoch 27; Iter   608/ 1097] train: loss: 0.0310928
[Epoch 27; Iter   638/ 1097] train: loss: 0.0924591
[Epoch 27; Iter   668/ 1097] train: loss: 0.0251414
[Epoch 27; Iter   698/ 1097] train: loss: 0.2387656
[Epoch 27; Iter   728/ 1097] train: loss: 0.1614238
[Epoch 27; Iter   758/ 1097] train: loss: 0.0343604
[Epoch 27; Iter   788/ 1097] train: loss: 0.1325713
[Epoch 27; Iter   818/ 1097] train: loss: 0.1146355
[Epoch 27; Iter   848/ 1097] train: loss: 0.0776766
[Epoch 27; Iter   878/ 1097] train: loss: 0.1697978
[Epoch 27; Iter   908/ 1097] train: loss: 0.1648655
[Epoch 27; Iter   938/ 1097] train: loss: 0.2305752
[Epoch 27; Iter   968/ 1097] train: loss: 0.0287591
[Epoch 27; Iter   998/ 1097] train: loss: 0.0898484
[Epoch 27; Iter  1028/ 1097] train: loss: 0.0280624
[Epoch 27; Iter  1058/ 1097] train: loss: 0.2042279
[Epoch 27; Iter  1088/ 1097] train: loss: 0.0204842
[Epoch 27] ogbg-molhiv: 0.816161 val loss: 0.120212
[Epoch 27] ogbg-molhiv: 0.815463 test loss: 0.120023
[Epoch 28; Iter    21/ 1097] train: loss: 0.0330303
[Epoch 28; Iter    51/ 1097] train: loss: 0.0985180
[Epoch 28; Iter    81/ 1097] train: loss: 0.0273372
[Epoch 28; Iter   111/ 1097] train: loss: 0.0645604
[Epoch 28; Iter   141/ 1097] train: loss: 0.1306851
[Epoch 28; Iter   171/ 1097] train: loss: 0.0361928
[Epoch 28; Iter   201/ 1097] train: loss: 0.0172278
[Epoch 28; Iter   231/ 1097] train: loss: 0.0932984
[Epoch 28; Iter   261/ 1097] train: loss: 0.1370067
[Epoch 28; Iter   291/ 1097] train: loss: 0.0256395
[Epoch 28; Iter   321/ 1097] train: loss: 0.0122954
[Epoch 28; Iter   351/ 1097] train: loss: 0.1293744
[Epoch 28; Iter   381/ 1097] train: loss: 0.1680354
[Epoch 28; Iter   411/ 1097] train: loss: 0.1642640
[Epoch 28; Iter   441/ 1097] train: loss: 0.1003087
[Epoch 26; Iter   185/  823] train: loss: 0.0216924
[Epoch 26; Iter   215/  823] train: loss: 0.0194377
[Epoch 26; Iter   245/  823] train: loss: 0.0300649
[Epoch 26; Iter   275/  823] train: loss: 0.1488132
[Epoch 26; Iter   305/  823] train: loss: 0.0304765
[Epoch 26; Iter   335/  823] train: loss: 0.0301292
[Epoch 26; Iter   365/  823] train: loss: 0.1906410
[Epoch 26; Iter   395/  823] train: loss: 0.1527925
[Epoch 26; Iter   425/  823] train: loss: 0.1528452
[Epoch 26; Iter   455/  823] train: loss: 0.0245777
[Epoch 26; Iter   485/  823] train: loss: 0.3029452
[Epoch 26; Iter   515/  823] train: loss: 0.0240092
[Epoch 26; Iter   545/  823] train: loss: 0.2073255
[Epoch 26; Iter   575/  823] train: loss: 0.0357384
[Epoch 26; Iter   605/  823] train: loss: 0.0546283
[Epoch 26; Iter   635/  823] train: loss: 0.0935365
[Epoch 26; Iter   665/  823] train: loss: 0.0186910
[Epoch 26; Iter   695/  823] train: loss: 0.2068639
[Epoch 26; Iter   725/  823] train: loss: 0.0240386
[Epoch 26; Iter   755/  823] train: loss: 0.0191100
[Epoch 26; Iter   785/  823] train: loss: 0.0197640
[Epoch 26; Iter   815/  823] train: loss: 0.0241186
[Epoch 26] ogbg-molhiv: 0.814523 val loss: 0.117854
[Epoch 26] ogbg-molhiv: 0.800763 test loss: 0.124642
[Epoch 27; Iter    22/  823] train: loss: 0.0328452
[Epoch 27; Iter    52/  823] train: loss: 0.0401817
[Epoch 27; Iter    82/  823] train: loss: 0.0481374
[Epoch 27; Iter   112/  823] train: loss: 0.0461976
[Epoch 27; Iter   142/  823] train: loss: 0.0729018
[Epoch 27; Iter   172/  823] train: loss: 0.1553833
[Epoch 27; Iter   202/  823] train: loss: 0.1632912
[Epoch 27; Iter   232/  823] train: loss: 0.1419267
[Epoch 27; Iter   262/  823] train: loss: 0.0271156
[Epoch 27; Iter   292/  823] train: loss: 0.1055600
[Epoch 27; Iter   322/  823] train: loss: 0.1121560
[Epoch 27; Iter   352/  823] train: loss: 0.1003330
[Epoch 27; Iter   382/  823] train: loss: 0.0200077
[Epoch 27; Iter   412/  823] train: loss: 0.0510283
[Epoch 27; Iter   442/  823] train: loss: 0.0233409
[Epoch 27; Iter   472/  823] train: loss: 0.0343544
[Epoch 27; Iter   502/  823] train: loss: 0.1683023
[Epoch 27; Iter   532/  823] train: loss: 0.1747147
[Epoch 27; Iter   562/  823] train: loss: 0.1333144
[Epoch 27; Iter   592/  823] train: loss: 0.0915589
[Epoch 27; Iter   622/  823] train: loss: 0.2270392
[Epoch 27; Iter   652/  823] train: loss: 0.0261329
[Epoch 27; Iter   682/  823] train: loss: 0.1218848
[Epoch 27; Iter   712/  823] train: loss: 0.0790500
[Epoch 27; Iter   742/  823] train: loss: 0.0199412
[Epoch 27; Iter   772/  823] train: loss: 0.0289513
[Epoch 27; Iter   802/  823] train: loss: 0.0155290
[Epoch 27] ogbg-molhiv: 0.816790 val loss: 0.154032
[Epoch 27] ogbg-molhiv: 0.795953 test loss: 0.164117
[Epoch 28; Iter     9/  823] train: loss: 0.1926176
[Epoch 28; Iter    39/  823] train: loss: 0.1386384
[Epoch 28; Iter    69/  823] train: loss: 0.1238127
[Epoch 28; Iter    99/  823] train: loss: 0.0388887
[Epoch 28; Iter   129/  823] train: loss: 0.1936900
[Epoch 28; Iter   159/  823] train: loss: 0.0147438
[Epoch 28; Iter   189/  823] train: loss: 0.1739059
[Epoch 28; Iter   219/  823] train: loss: 0.0632000
[Epoch 28; Iter   249/  823] train: loss: 0.0189539
[Epoch 28; Iter   279/  823] train: loss: 0.0514020
[Epoch 28; Iter   309/  823] train: loss: 0.0264119
[Epoch 28; Iter   339/  823] train: loss: 0.0202518
[Epoch 28; Iter   369/  823] train: loss: 0.0228990
[Epoch 28; Iter   399/  823] train: loss: 0.1865945
[Epoch 28; Iter   429/  823] train: loss: 0.1749908
[Epoch 28; Iter   459/  823] train: loss: 0.1649126
[Epoch 28; Iter   489/  823] train: loss: 0.0373762
[Epoch 28; Iter   519/  823] train: loss: 0.1374664
[Epoch 28; Iter   549/  823] train: loss: 0.1919918
[Epoch 28; Iter   579/  823] train: loss: 0.2915072
[Epoch 28; Iter   609/  823] train: loss: 0.1968236
[Epoch 28; Iter   639/  823] train: loss: 0.0553271
[Epoch 28; Iter   669/  823] train: loss: 0.1233035
[Epoch 28; Iter   699/  823] train: loss: 0.0427110
[Epoch 28; Iter   729/  823] train: loss: 0.0971654
[Epoch 28; Iter   759/  823] train: loss: 0.0676827
[Epoch 28; Iter   789/  823] train: loss: 0.0389343
[Epoch 28; Iter   819/  823] train: loss: 0.2889965
[Epoch 28] ogbg-molhiv: 0.817934 val loss: 0.119665
[Epoch 28] ogbg-molhiv: 0.802636 test loss: 0.121877
[Epoch 29; Iter    26/  823] train: loss: 0.1764694
[Epoch 29; Iter    56/  823] train: loss: 0.1854196
[Epoch 29; Iter    86/  823] train: loss: 0.0620436
[Epoch 29; Iter   116/  823] train: loss: 0.1653183
[Epoch 29; Iter   146/  823] train: loss: 0.2408435
[Epoch 29; Iter   176/  823] train: loss: 0.0498134
[Epoch 29; Iter   206/  823] train: loss: 0.1567513
[Epoch 29; Iter   236/  823] train: loss: 0.0216819
[Epoch 29; Iter   266/  823] train: loss: 0.2447199
[Epoch 29; Iter   296/  823] train: loss: 0.1825149
[Epoch 29; Iter   326/  823] train: loss: 0.0906275
[Epoch 29; Iter   356/  823] train: loss: 0.0147642
[Epoch 29; Iter   386/  823] train: loss: 0.0548486
[Epoch 29; Iter   416/  823] train: loss: 0.0859016
[Epoch 29; Iter   446/  823] train: loss: 0.1199347
[Epoch 29; Iter   476/  823] train: loss: 0.0220003
[Epoch 29; Iter   506/  823] train: loss: 0.0363584
[Epoch 29; Iter   536/  823] train: loss: 0.1149524
[Epoch 29; Iter   566/  823] train: loss: 0.1783157
[Epoch 29; Iter   596/  823] train: loss: 0.0213861
[Epoch 29; Iter   626/  823] train: loss: 0.1140342
[Epoch 29; Iter   656/  823] train: loss: 0.1946170
[Epoch 29; Iter   686/  823] train: loss: 0.1624580
[Epoch 29; Iter   716/  823] train: loss: 0.2423336
[Epoch 29; Iter   746/  823] train: loss: 0.1314470
[Epoch 29; Iter   776/  823] train: loss: 0.2383804
[Epoch 29; Iter   806/  823] train: loss: 0.0220980
[Epoch 29] ogbg-molhiv: 0.821956 val loss: 0.123671
[Epoch 29] ogbg-molhiv: 0.800373 test loss: 0.121874
[Epoch 30; Iter    13/  823] train: loss: 0.0200827
[Epoch 30; Iter    43/  823] train: loss: 0.0192849
[Epoch 30; Iter    73/  823] train: loss: 0.2429693
[Epoch 30; Iter   103/  823] train: loss: 0.0272044
[Epoch 30; Iter   133/  823] train: loss: 0.0296174
[Epoch 30; Iter   163/  823] train: loss: 0.0510446
[Epoch 30; Iter   193/  823] train: loss: 0.2980622
[Epoch 30; Iter   223/  823] train: loss: 0.0285018
[Epoch 30; Iter   253/  823] train: loss: 0.3057890
[Epoch 30; Iter   283/  823] train: loss: 0.1644709
[Epoch 30; Iter   313/  823] train: loss: 0.0232776
[Epoch 30; Iter   343/  823] train: loss: 0.0861396
[Epoch 30; Iter   373/  823] train: loss: 0.0180122
[Epoch 30; Iter   403/  823] train: loss: 0.0923036
[Epoch 30; Iter   433/  823] train: loss: 0.1074635
[Epoch 30; Iter   463/  823] train: loss: 0.0169666
[Epoch 30; Iter   493/  823] train: loss: 0.0229801
[Epoch 30; Iter   523/  823] train: loss: 0.0197615
[Epoch 30; Iter   553/  823] train: loss: 0.0773614
[Epoch 30; Iter   583/  823] train: loss: 0.1115895
[Epoch 30; Iter   613/  823] train: loss: 0.0262403
[Epoch 30; Iter   643/  823] train: loss: 0.0629647
[Epoch 30; Iter   673/  823] train: loss: 0.0393302
[Epoch 30; Iter   703/  823] train: loss: 0.0196365
[Epoch 30; Iter   733/  823] train: loss: 0.0170811
[Epoch 30; Iter   763/  823] train: loss: 0.1691886
[Epoch 30; Iter   793/  823] train: loss: 0.2519599
[Epoch 30; Iter   823/  823] train: loss: 0.0209819
[Epoch 30] ogbg-molhiv: 0.824641 val loss: 0.126058
[Epoch 30] ogbg-molhiv: 0.805336 test loss: 0.236154
[Epoch 31; Iter    30/  823] train: loss: 0.0208298
[Epoch 31; Iter    60/  823] train: loss: 0.1009135
[Epoch 31; Iter    90/  823] train: loss: 0.0445782
[Epoch 31; Iter   120/  823] train: loss: 0.1667761
[Epoch 31; Iter   150/  823] train: loss: 0.1757004
[Epoch 31; Iter   180/  823] train: loss: 0.0731911
[Epoch 31; Iter   210/  823] train: loss: 0.0206291
[Epoch 31; Iter   240/  823] train: loss: 0.0180016
[Epoch 31; Iter   270/  823] train: loss: 0.0943078
[Epoch 31; Iter   300/  823] train: loss: 0.0587257
[Epoch 31; Iter   330/  823] train: loss: 0.0153372
[Epoch 31; Iter   360/  823] train: loss: 0.0211341
[Epoch 31; Iter   390/  823] train: loss: 0.3446265
[Epoch 31; Iter   420/  823] train: loss: 0.0270203
[Epoch 31; Iter   450/  823] train: loss: 0.0923067
[Epoch 26; Iter   185/  823] train: loss: 0.1242574
[Epoch 26; Iter   215/  823] train: loss: 0.0488184
[Epoch 26; Iter   245/  823] train: loss: 0.0237086
[Epoch 26; Iter   275/  823] train: loss: 0.0443243
[Epoch 26; Iter   305/  823] train: loss: 0.1421555
[Epoch 26; Iter   335/  823] train: loss: 0.0342919
[Epoch 26; Iter   365/  823] train: loss: 0.0600974
[Epoch 26; Iter   395/  823] train: loss: 0.2523264
[Epoch 26; Iter   425/  823] train: loss: 0.0233959
[Epoch 26; Iter   455/  823] train: loss: 0.2547244
[Epoch 26; Iter   485/  823] train: loss: 0.0482562
[Epoch 26; Iter   515/  823] train: loss: 0.0472537
[Epoch 26; Iter   545/  823] train: loss: 0.1295053
[Epoch 26; Iter   575/  823] train: loss: 0.0303618
[Epoch 26; Iter   605/  823] train: loss: 0.1305724
[Epoch 26; Iter   635/  823] train: loss: 0.1699507
[Epoch 26; Iter   665/  823] train: loss: 0.0291084
[Epoch 26; Iter   695/  823] train: loss: 0.0256990
[Epoch 26; Iter   725/  823] train: loss: 0.1499607
[Epoch 26; Iter   755/  823] train: loss: 0.0458167
[Epoch 26; Iter   785/  823] train: loss: 0.1743397
[Epoch 26; Iter   815/  823] train: loss: 0.0487764
[Epoch 26] ogbg-molhiv: 0.822685 val loss: 0.207141
[Epoch 26] ogbg-molhiv: 0.797145 test loss: 0.617615
[Epoch 27; Iter    22/  823] train: loss: 0.0410546
[Epoch 27; Iter    52/  823] train: loss: 0.0422034
[Epoch 27; Iter    82/  823] train: loss: 0.1365848
[Epoch 27; Iter   112/  823] train: loss: 0.1627048
[Epoch 27; Iter   142/  823] train: loss: 0.0424772
[Epoch 27; Iter   172/  823] train: loss: 0.1505892
[Epoch 27; Iter   202/  823] train: loss: 0.0347360
[Epoch 27; Iter   232/  823] train: loss: 0.4582267
[Epoch 27; Iter   262/  823] train: loss: 0.2434707
[Epoch 27; Iter   292/  823] train: loss: 0.2513148
[Epoch 27; Iter   322/  823] train: loss: 0.0533035
[Epoch 27; Iter   352/  823] train: loss: 0.3519513
[Epoch 27; Iter   382/  823] train: loss: 0.1722557
[Epoch 27; Iter   412/  823] train: loss: 0.1730537
[Epoch 27; Iter   442/  823] train: loss: 0.1139536
[Epoch 27; Iter   472/  823] train: loss: 0.0917258
[Epoch 27; Iter   502/  823] train: loss: 0.0183412
[Epoch 27; Iter   532/  823] train: loss: 0.0358017
[Epoch 27; Iter   562/  823] train: loss: 0.1808028
[Epoch 27; Iter   592/  823] train: loss: 0.0487334
[Epoch 27; Iter   622/  823] train: loss: 0.0393785
[Epoch 27; Iter   652/  823] train: loss: 0.0860915
[Epoch 27; Iter   682/  823] train: loss: 0.2009705
[Epoch 27; Iter   712/  823] train: loss: 0.1223306
[Epoch 27; Iter   742/  823] train: loss: 0.0258261
[Epoch 27; Iter   772/  823] train: loss: 0.0558984
[Epoch 27; Iter   802/  823] train: loss: 0.1441388
[Epoch 27] ogbg-molhiv: 0.819325 val loss: 0.113048
[Epoch 27] ogbg-molhiv: 0.793587 test loss: 0.184597
[Epoch 28; Iter     9/  823] train: loss: 0.0364197
[Epoch 28; Iter    39/  823] train: loss: 0.0228815
[Epoch 28; Iter    69/  823] train: loss: 0.0180007
[Epoch 28; Iter    99/  823] train: loss: 0.1469932
[Epoch 28; Iter   129/  823] train: loss: 0.0395992
[Epoch 28; Iter   159/  823] train: loss: 0.0340679
[Epoch 28; Iter   189/  823] train: loss: 0.2484175
[Epoch 28; Iter   219/  823] train: loss: 0.0761002
[Epoch 28; Iter   249/  823] train: loss: 0.0918515
[Epoch 28; Iter   279/  823] train: loss: 0.1535430
[Epoch 28; Iter   309/  823] train: loss: 0.2480733
[Epoch 28; Iter   339/  823] train: loss: 0.0571292
[Epoch 28; Iter   369/  823] train: loss: 0.0175292
[Epoch 28; Iter   399/  823] train: loss: 0.2018422
[Epoch 28; Iter   429/  823] train: loss: 0.1605341
[Epoch 28; Iter   459/  823] train: loss: 0.0540343
[Epoch 28; Iter   489/  823] train: loss: 0.1932262
[Epoch 28; Iter   519/  823] train: loss: 0.0917224
[Epoch 28; Iter   549/  823] train: loss: 0.1711436
[Epoch 28; Iter   579/  823] train: loss: 0.0252333
[Epoch 28; Iter   609/  823] train: loss: 0.1271872
[Epoch 28; Iter   639/  823] train: loss: 0.1054604
[Epoch 28; Iter   669/  823] train: loss: 0.0614322
[Epoch 28; Iter   699/  823] train: loss: 0.0555462
[Epoch 28; Iter   729/  823] train: loss: 0.2078612
[Epoch 28; Iter   759/  823] train: loss: 0.0221625
[Epoch 28; Iter   789/  823] train: loss: 0.1379999
[Epoch 28; Iter   819/  823] train: loss: 0.0333862
[Epoch 28] ogbg-molhiv: 0.823930 val loss: 0.138272
[Epoch 28] ogbg-molhiv: 0.793943 test loss: 0.316718
[Epoch 29; Iter    26/  823] train: loss: 0.0718893
[Epoch 29; Iter    56/  823] train: loss: 0.0130959
[Epoch 29; Iter    86/  823] train: loss: 0.1704462
[Epoch 29; Iter   116/  823] train: loss: 0.0216954
[Epoch 29; Iter   146/  823] train: loss: 0.0224528
[Epoch 29; Iter   176/  823] train: loss: 0.4474940
[Epoch 29; Iter   206/  823] train: loss: 0.0252346
[Epoch 29; Iter   236/  823] train: loss: 0.2275230
[Epoch 29; Iter   266/  823] train: loss: 0.1632972
[Epoch 29; Iter   296/  823] train: loss: 0.1943771
[Epoch 29; Iter   326/  823] train: loss: 0.0950804
[Epoch 29; Iter   356/  823] train: loss: 0.1649338
[Epoch 29; Iter   386/  823] train: loss: 0.1239322
[Epoch 29; Iter   416/  823] train: loss: 0.1334051
[Epoch 29; Iter   446/  823] train: loss: 0.0232817
[Epoch 29; Iter   476/  823] train: loss: 0.2961031
[Epoch 29; Iter   506/  823] train: loss: 0.0388118
[Epoch 29; Iter   536/  823] train: loss: 0.0386674
[Epoch 29; Iter   566/  823] train: loss: 0.0295651
[Epoch 29; Iter   596/  823] train: loss: 0.4901835
[Epoch 29; Iter   626/  823] train: loss: 0.0195051
[Epoch 29; Iter   656/  823] train: loss: 0.0572990
[Epoch 29; Iter   686/  823] train: loss: 0.0288508
[Epoch 29; Iter   716/  823] train: loss: 0.1362291
[Epoch 29; Iter   746/  823] train: loss: 0.1219757
[Epoch 29; Iter   776/  823] train: loss: 0.0361172
[Epoch 29; Iter   806/  823] train: loss: 0.3186238
[Epoch 29] ogbg-molhiv: 0.826498 val loss: 0.132118
[Epoch 29] ogbg-molhiv: 0.795958 test loss: 0.315891
[Epoch 30; Iter    13/  823] train: loss: 0.1941317
[Epoch 30; Iter    43/  823] train: loss: 0.0744935
[Epoch 30; Iter    73/  823] train: loss: 0.0162181
[Epoch 30; Iter   103/  823] train: loss: 0.1367405
[Epoch 30; Iter   133/  823] train: loss: 0.1069081
[Epoch 30; Iter   163/  823] train: loss: 0.0152819
[Epoch 30; Iter   193/  823] train: loss: 0.0343407
[Epoch 30; Iter   223/  823] train: loss: 0.0244430
[Epoch 30; Iter   253/  823] train: loss: 0.0179871
[Epoch 30; Iter   283/  823] train: loss: 0.0308779
[Epoch 30; Iter   313/  823] train: loss: 0.0157856
[Epoch 30; Iter   343/  823] train: loss: 0.1647069
[Epoch 30; Iter   373/  823] train: loss: 0.0447734
[Epoch 30; Iter   403/  823] train: loss: 0.1093783
[Epoch 30; Iter   433/  823] train: loss: 0.0324175
[Epoch 30; Iter   463/  823] train: loss: 0.0183877
[Epoch 30; Iter   493/  823] train: loss: 0.0448364
[Epoch 30; Iter   523/  823] train: loss: 0.1753578
[Epoch 30; Iter   553/  823] train: loss: 0.0306901
[Epoch 30; Iter   583/  823] train: loss: 0.1469014
[Epoch 30; Iter   613/  823] train: loss: 0.2582838
[Epoch 30; Iter   643/  823] train: loss: 0.3300123
[Epoch 30; Iter   673/  823] train: loss: 0.1798762
[Epoch 30; Iter   703/  823] train: loss: 0.0376065
[Epoch 30; Iter   733/  823] train: loss: 0.1716101
[Epoch 30; Iter   763/  823] train: loss: 0.1778633
[Epoch 30; Iter   793/  823] train: loss: 0.1334919
[Epoch 30; Iter   823/  823] train: loss: 0.0313193
[Epoch 30] ogbg-molhiv: 0.830694 val loss: 0.113762
[Epoch 30] ogbg-molhiv: 0.786939 test loss: 0.231243
[Epoch 31; Iter    30/  823] train: loss: 0.0646233
[Epoch 31; Iter    60/  823] train: loss: 0.1719457
[Epoch 31; Iter    90/  823] train: loss: 0.1827848
[Epoch 31; Iter   120/  823] train: loss: 0.1635288
[Epoch 31; Iter   150/  823] train: loss: 0.0570721
[Epoch 31; Iter   180/  823] train: loss: 0.1429152
[Epoch 31; Iter   210/  823] train: loss: 0.3218510
[Epoch 31; Iter   240/  823] train: loss: 0.0563547
[Epoch 31; Iter   270/  823] train: loss: 0.0193350
[Epoch 31; Iter   300/  823] train: loss: 0.0253644
[Epoch 31; Iter   330/  823] train: loss: 0.0491729
[Epoch 31; Iter   360/  823] train: loss: 0.0873042
[Epoch 31; Iter   390/  823] train: loss: 0.2218776
[Epoch 31; Iter   420/  823] train: loss: 0.0616081
[Epoch 31; Iter   450/  823] train: loss: 0.0558969
[Epoch 26; Iter   185/  823] train: loss: 0.1684594
[Epoch 26; Iter   215/  823] train: loss: 0.0359192
[Epoch 26; Iter   245/  823] train: loss: 0.0660241
[Epoch 26; Iter   275/  823] train: loss: 0.0479484
[Epoch 26; Iter   305/  823] train: loss: 0.1920308
[Epoch 26; Iter   335/  823] train: loss: 0.1570225
[Epoch 26; Iter   365/  823] train: loss: 0.2099151
[Epoch 26; Iter   395/  823] train: loss: 0.0328923
[Epoch 26; Iter   425/  823] train: loss: 0.1093863
[Epoch 26; Iter   455/  823] train: loss: 0.0327108
[Epoch 26; Iter   485/  823] train: loss: 0.0294756
[Epoch 26; Iter   515/  823] train: loss: 0.0316390
[Epoch 26; Iter   545/  823] train: loss: 0.0240286
[Epoch 26; Iter   575/  823] train: loss: 0.1160433
[Epoch 26; Iter   605/  823] train: loss: 0.1529640
[Epoch 26; Iter   635/  823] train: loss: 0.0224701
[Epoch 26; Iter   665/  823] train: loss: 0.0344527
[Epoch 26; Iter   695/  823] train: loss: 0.0267327
[Epoch 26; Iter   725/  823] train: loss: 0.3327105
[Epoch 26; Iter   755/  823] train: loss: 0.0877247
[Epoch 26; Iter   785/  823] train: loss: 0.0541320
[Epoch 26; Iter   815/  823] train: loss: 0.2603621
[Epoch 26] ogbg-molhiv: 0.816993 val loss: 0.343762
[Epoch 26] ogbg-molhiv: 0.804454 test loss: 0.120127
[Epoch 27; Iter    22/  823] train: loss: 0.0401975
[Epoch 27; Iter    52/  823] train: loss: 0.1170057
[Epoch 27; Iter    82/  823] train: loss: 0.0222580
[Epoch 27; Iter   112/  823] train: loss: 0.0411425
[Epoch 27; Iter   142/  823] train: loss: 0.1240364
[Epoch 27; Iter   172/  823] train: loss: 0.1734153
[Epoch 27; Iter   202/  823] train: loss: 0.1563111
[Epoch 27; Iter   232/  823] train: loss: 0.0245930
[Epoch 27; Iter   262/  823] train: loss: 0.3067088
[Epoch 27; Iter   292/  823] train: loss: 0.0492863
[Epoch 27; Iter   322/  823] train: loss: 0.0177392
[Epoch 27; Iter   352/  823] train: loss: 0.0230019
[Epoch 27; Iter   382/  823] train: loss: 0.0221146
[Epoch 27; Iter   412/  823] train: loss: 0.0187403
[Epoch 27; Iter   442/  823] train: loss: 0.0162695
[Epoch 27; Iter   472/  823] train: loss: 0.0436390
[Epoch 27; Iter   502/  823] train: loss: 0.0269525
[Epoch 27; Iter   532/  823] train: loss: 0.0259982
[Epoch 27; Iter   562/  823] train: loss: 0.0206888
[Epoch 27; Iter   592/  823] train: loss: 0.2511834
[Epoch 27; Iter   622/  823] train: loss: 0.0634587
[Epoch 27; Iter   652/  823] train: loss: 0.0437413
[Epoch 27; Iter   682/  823] train: loss: 0.0332074
[Epoch 27; Iter   712/  823] train: loss: 0.2703401
[Epoch 27; Iter   742/  823] train: loss: 0.0462782
[Epoch 27; Iter   772/  823] train: loss: 0.1894476
[Epoch 27; Iter   802/  823] train: loss: 0.1432667
[Epoch 27] ogbg-molhiv: 0.824591 val loss: 0.111498
[Epoch 27] ogbg-molhiv: 0.801027 test loss: 0.190891
[Epoch 28; Iter     9/  823] train: loss: 0.0191036
[Epoch 28; Iter    39/  823] train: loss: 0.5849558
[Epoch 28; Iter    69/  823] train: loss: 0.0669253
[Epoch 28; Iter    99/  823] train: loss: 0.0293877
[Epoch 28; Iter   129/  823] train: loss: 0.0383776
[Epoch 28; Iter   159/  823] train: loss: 0.0194659
[Epoch 28; Iter   189/  823] train: loss: 0.0846728
[Epoch 28; Iter   219/  823] train: loss: 0.1862198
[Epoch 28; Iter   249/  823] train: loss: 0.2085038
[Epoch 28; Iter   279/  823] train: loss: 0.1158488
[Epoch 28; Iter   309/  823] train: loss: 0.3297032
[Epoch 28; Iter   339/  823] train: loss: 0.2179699
[Epoch 28; Iter   369/  823] train: loss: 0.0220613
[Epoch 28; Iter   399/  823] train: loss: 0.1442204
[Epoch 28; Iter   429/  823] train: loss: 0.2344261
[Epoch 28; Iter   459/  823] train: loss: 0.0709861
[Epoch 28; Iter   489/  823] train: loss: 0.0210358
[Epoch 28; Iter   519/  823] train: loss: 0.0227629
[Epoch 28; Iter   549/  823] train: loss: 0.0774396
[Epoch 28; Iter   579/  823] train: loss: 0.2876284
[Epoch 28; Iter   609/  823] train: loss: 0.0196663
[Epoch 28; Iter   639/  823] train: loss: 0.1098837
[Epoch 28; Iter   669/  823] train: loss: 0.0411528
[Epoch 28; Iter   699/  823] train: loss: 0.2742181
[Epoch 28; Iter   729/  823] train: loss: 0.1730536
[Epoch 28; Iter   759/  823] train: loss: 0.0177795
[Epoch 28; Iter   789/  823] train: loss: 0.2216115
[Epoch 28; Iter   819/  823] train: loss: 0.0363255
[Epoch 28] ogbg-molhiv: 0.816657 val loss: 0.118311
[Epoch 28] ogbg-molhiv: 0.792326 test loss: 0.155299
[Epoch 29; Iter    26/  823] train: loss: 0.0969092
[Epoch 29; Iter    56/  823] train: loss: 0.1022790
[Epoch 29; Iter    86/  823] train: loss: 0.2009422
[Epoch 29; Iter   116/  823] train: loss: 0.0371561
[Epoch 29; Iter   146/  823] train: loss: 0.1221169
[Epoch 29; Iter   176/  823] train: loss: 0.0125662
[Epoch 29; Iter   206/  823] train: loss: 0.0182321
[Epoch 29; Iter   236/  823] train: loss: 0.1420458
[Epoch 29; Iter   266/  823] train: loss: 0.0140669
[Epoch 29; Iter   296/  823] train: loss: 0.0113578
[Epoch 29; Iter   326/  823] train: loss: 0.0197285
[Epoch 29; Iter   356/  823] train: loss: 0.0661101
[Epoch 29; Iter   386/  823] train: loss: 0.1820718
[Epoch 29; Iter   416/  823] train: loss: 0.1565462
[Epoch 29; Iter   446/  823] train: loss: 0.0221098
[Epoch 29; Iter   476/  823] train: loss: 0.3499725
[Epoch 29; Iter   506/  823] train: loss: 0.1524890
[Epoch 29; Iter   536/  823] train: loss: 0.0406354
[Epoch 29; Iter   566/  823] train: loss: 0.1564203
[Epoch 29; Iter   596/  823] train: loss: 0.1424394
[Epoch 29; Iter   626/  823] train: loss: 0.0407255
[Epoch 29; Iter   656/  823] train: loss: 0.0284018
[Epoch 29; Iter   686/  823] train: loss: 0.0575766
[Epoch 29; Iter   716/  823] train: loss: 0.0285875
[Epoch 29; Iter   746/  823] train: loss: 0.0405186
[Epoch 29; Iter   776/  823] train: loss: 0.2095726
[Epoch 29; Iter   806/  823] train: loss: 0.1070840
[Epoch 29] ogbg-molhiv: 0.814437 val loss: 0.157448
[Epoch 29] ogbg-molhiv: 0.803096 test loss: 0.128689
[Epoch 30; Iter    13/  823] train: loss: 0.1793567
[Epoch 30; Iter    43/  823] train: loss: 0.1435844
[Epoch 30; Iter    73/  823] train: loss: 0.4753316
[Epoch 30; Iter   103/  823] train: loss: 0.2803750
[Epoch 30; Iter   133/  823] train: loss: 0.0198399
[Epoch 30; Iter   163/  823] train: loss: 0.0471940
[Epoch 30; Iter   193/  823] train: loss: 0.0241049
[Epoch 30; Iter   223/  823] train: loss: 0.0297545
[Epoch 30; Iter   253/  823] train: loss: 0.0877023
[Epoch 30; Iter   283/  823] train: loss: 0.0136888
[Epoch 30; Iter   313/  823] train: loss: 0.0104529
[Epoch 30; Iter   343/  823] train: loss: 0.2173521
[Epoch 30; Iter   373/  823] train: loss: 0.0393851
[Epoch 30; Iter   403/  823] train: loss: 0.0253812
[Epoch 30; Iter   433/  823] train: loss: 0.0306801
[Epoch 30; Iter   463/  823] train: loss: 0.0249069
[Epoch 30; Iter   493/  823] train: loss: 0.1016579
[Epoch 30; Iter   523/  823] train: loss: 0.0223564
[Epoch 30; Iter   553/  823] train: loss: 0.1156232
[Epoch 30; Iter   583/  823] train: loss: 0.0161742
[Epoch 30; Iter   613/  823] train: loss: 0.0278772
[Epoch 30; Iter   643/  823] train: loss: 0.0361565
[Epoch 30; Iter   673/  823] train: loss: 0.0276519
[Epoch 30; Iter   703/  823] train: loss: 0.0544132
[Epoch 30; Iter   733/  823] train: loss: 0.0840130
[Epoch 30; Iter   763/  823] train: loss: 0.0349406
[Epoch 30; Iter   793/  823] train: loss: 0.5113580
[Epoch 30; Iter   823/  823] train: loss: 0.0230670
[Epoch 30] ogbg-molhiv: 0.833747 val loss: 0.115175
[Epoch 30] ogbg-molhiv: 0.796669 test loss: 0.127407
[Epoch 31; Iter    30/  823] train: loss: 0.0327448
[Epoch 31; Iter    60/  823] train: loss: 0.1051626
[Epoch 31; Iter    90/  823] train: loss: 0.0246854
[Epoch 31; Iter   120/  823] train: loss: 0.0290287
[Epoch 31; Iter   150/  823] train: loss: 0.0467523
[Epoch 31; Iter   180/  823] train: loss: 0.1171403
[Epoch 31; Iter   210/  823] train: loss: 0.0239401
[Epoch 31; Iter   240/  823] train: loss: 0.0260501
[Epoch 31; Iter   270/  823] train: loss: 0.3210331
[Epoch 31; Iter   300/  823] train: loss: 0.2229058
[Epoch 31; Iter   330/  823] train: loss: 0.1942625
[Epoch 31; Iter   360/  823] train: loss: 0.0335417
[Epoch 31; Iter   390/  823] train: loss: 0.0341503
[Epoch 31; Iter   420/  823] train: loss: 0.1283474
[Epoch 31; Iter   450/  823] train: loss: 0.0452021
[Epoch 27; Iter   480/  960] train: loss: 0.0262647
[Epoch 27; Iter   510/  960] train: loss: 0.2044358
[Epoch 27; Iter   540/  960] train: loss: 0.0318211
[Epoch 27; Iter   570/  960] train: loss: 0.0571678
[Epoch 27; Iter   600/  960] train: loss: 0.2715899
[Epoch 27; Iter   630/  960] train: loss: 0.0188569
[Epoch 27; Iter   660/  960] train: loss: 0.0995231
[Epoch 27; Iter   690/  960] train: loss: 0.2279844
[Epoch 27; Iter   720/  960] train: loss: 0.0247904
[Epoch 27; Iter   750/  960] train: loss: 0.1503057
[Epoch 27; Iter   780/  960] train: loss: 0.0708789
[Epoch 27; Iter   810/  960] train: loss: 0.1687132
[Epoch 27; Iter   840/  960] train: loss: 0.0211401
[Epoch 27; Iter   870/  960] train: loss: 0.0833500
[Epoch 27; Iter   900/  960] train: loss: 0.0257092
[Epoch 27; Iter   930/  960] train: loss: 0.0756835
[Epoch 27; Iter   960/  960] train: loss: 0.0164258
[Epoch 27] ogbg-molhiv: 0.811874 val loss: 0.127248
[Epoch 27] ogbg-molhiv: 0.808608 test loss: 0.121951
[Epoch 28; Iter    30/  960] train: loss: 0.1080182
[Epoch 28; Iter    60/  960] train: loss: 0.0401582
[Epoch 28; Iter    90/  960] train: loss: 0.0212127
[Epoch 28; Iter   120/  960] train: loss: 0.0957532
[Epoch 28; Iter   150/  960] train: loss: 0.0957467
[Epoch 28; Iter   180/  960] train: loss: 0.0416856
[Epoch 28; Iter   210/  960] train: loss: 0.0370186
[Epoch 28; Iter   240/  960] train: loss: 0.0250761
[Epoch 28; Iter   270/  960] train: loss: 0.2608538
[Epoch 28; Iter   300/  960] train: loss: 0.1124472
[Epoch 28; Iter   330/  960] train: loss: 0.0213081
[Epoch 28; Iter   360/  960] train: loss: 0.0279751
[Epoch 28; Iter   390/  960] train: loss: 0.0194121
[Epoch 28; Iter   420/  960] train: loss: 0.1183581
[Epoch 28; Iter   450/  960] train: loss: 0.0290956
[Epoch 28; Iter   480/  960] train: loss: 0.0257436
[Epoch 28; Iter   510/  960] train: loss: 0.3183730
[Epoch 28; Iter   540/  960] train: loss: 0.1953272
[Epoch 28; Iter   570/  960] train: loss: 0.0793920
[Epoch 28; Iter   600/  960] train: loss: 0.2639005
[Epoch 28; Iter   630/  960] train: loss: 0.2351218
[Epoch 28; Iter   660/  960] train: loss: 0.0184889
[Epoch 28; Iter   690/  960] train: loss: 0.0405906
[Epoch 28; Iter   720/  960] train: loss: 0.1674452
[Epoch 28; Iter   750/  960] train: loss: 0.0407347
[Epoch 28; Iter   780/  960] train: loss: 0.1119208
[Epoch 28; Iter   810/  960] train: loss: 0.0192462
[Epoch 28; Iter   840/  960] train: loss: 0.0166029
[Epoch 28; Iter   870/  960] train: loss: 0.0860284
[Epoch 28; Iter   900/  960] train: loss: 0.1461952
[Epoch 28; Iter   930/  960] train: loss: 0.0263722
[Epoch 28; Iter   960/  960] train: loss: 0.2808095
[Epoch 28] ogbg-molhiv: 0.810897 val loss: 0.125927
[Epoch 28] ogbg-molhiv: 0.828623 test loss: 0.117923
[Epoch 29; Iter    30/  960] train: loss: 0.0989448
[Epoch 29; Iter    60/  960] train: loss: 0.0566351
[Epoch 29; Iter    90/  960] train: loss: 0.1731792
[Epoch 29; Iter   120/  960] train: loss: 0.0519660
[Epoch 29; Iter   150/  960] train: loss: 0.1787509
[Epoch 29; Iter   180/  960] train: loss: 0.0373872
[Epoch 29; Iter   210/  960] train: loss: 0.2190063
[Epoch 29; Iter   240/  960] train: loss: 0.0169867
[Epoch 29; Iter   270/  960] train: loss: 0.1374597
[Epoch 29; Iter   300/  960] train: loss: 0.0319401
[Epoch 29; Iter   330/  960] train: loss: 0.1221533
[Epoch 29; Iter   360/  960] train: loss: 0.0210627
[Epoch 29; Iter   390/  960] train: loss: 0.0270125
[Epoch 29; Iter   420/  960] train: loss: 0.0777392
[Epoch 29; Iter   450/  960] train: loss: 0.0239309
[Epoch 29; Iter   480/  960] train: loss: 0.0297792
[Epoch 29; Iter   510/  960] train: loss: 0.0252637
[Epoch 29; Iter   540/  960] train: loss: 0.1729962
[Epoch 29; Iter   570/  960] train: loss: 0.0762427
[Epoch 29; Iter   600/  960] train: loss: 0.0131547
[Epoch 29; Iter   630/  960] train: loss: 0.0444268
[Epoch 29; Iter   660/  960] train: loss: 0.1728501
[Epoch 29; Iter   690/  960] train: loss: 0.0125410
[Epoch 29; Iter   720/  960] train: loss: 0.2612771
[Epoch 29; Iter   750/  960] train: loss: 0.1216762
[Epoch 29; Iter   780/  960] train: loss: 0.0240093
[Epoch 29; Iter   810/  960] train: loss: 0.1362978
[Epoch 29; Iter   840/  960] train: loss: 0.0181563
[Epoch 29; Iter   870/  960] train: loss: 0.0296402
[Epoch 29; Iter   900/  960] train: loss: 0.0279038
[Epoch 29; Iter   930/  960] train: loss: 0.0240764
[Epoch 29; Iter   960/  960] train: loss: 0.0249653
[Epoch 29] ogbg-molhiv: 0.816850 val loss: 0.123930
[Epoch 29] ogbg-molhiv: 0.812466 test loss: 0.118397
[Epoch 30; Iter    30/  960] train: loss: 0.0295828
[Epoch 30; Iter    60/  960] train: loss: 0.0174577
[Epoch 30; Iter    90/  960] train: loss: 0.0307241
[Epoch 30; Iter   120/  960] train: loss: 0.0336439
[Epoch 30; Iter   150/  960] train: loss: 0.0190040
[Epoch 30; Iter   180/  960] train: loss: 0.0292061
[Epoch 30; Iter   210/  960] train: loss: 0.0337290
[Epoch 30; Iter   240/  960] train: loss: 0.0260203
[Epoch 30; Iter   270/  960] train: loss: 0.1290275
[Epoch 30; Iter   300/  960] train: loss: 0.0510479
[Epoch 30; Iter   330/  960] train: loss: 0.0474151
[Epoch 30; Iter   360/  960] train: loss: 0.0847999
[Epoch 30; Iter   390/  960] train: loss: 0.0158210
[Epoch 30; Iter   420/  960] train: loss: 0.0228301
[Epoch 30; Iter   450/  960] train: loss: 0.1205404
[Epoch 30; Iter   480/  960] train: loss: 0.0459015
[Epoch 30; Iter   510/  960] train: loss: 0.0140483
[Epoch 30; Iter   540/  960] train: loss: 0.1651868
[Epoch 30; Iter   570/  960] train: loss: 0.0751013
[Epoch 30; Iter   600/  960] train: loss: 0.0412864
[Epoch 30; Iter   630/  960] train: loss: 0.0363012
[Epoch 30; Iter   660/  960] train: loss: 0.0334837
[Epoch 30; Iter   690/  960] train: loss: 0.0432464
[Epoch 30; Iter   720/  960] train: loss: 0.0143594
[Epoch 30; Iter   750/  960] train: loss: 0.0189751
[Epoch 30; Iter   780/  960] train: loss: 0.1005129
[Epoch 30; Iter   810/  960] train: loss: 0.1478324
[Epoch 30; Iter   840/  960] train: loss: 0.0924228
[Epoch 30; Iter   870/  960] train: loss: 0.0298883
[Epoch 30; Iter   900/  960] train: loss: 0.0134443
[Epoch 30; Iter   930/  960] train: loss: 0.2200806
[Epoch 30; Iter   960/  960] train: loss: 0.0220230
[Epoch 30] ogbg-molhiv: 0.816319 val loss: 0.126691
[Epoch 30] ogbg-molhiv: 0.823935 test loss: 0.118116
[Epoch 31; Iter    30/  960] train: loss: 0.1534958
[Epoch 31; Iter    60/  960] train: loss: 0.0251935
[Epoch 31; Iter    90/  960] train: loss: 0.0159353
[Epoch 31; Iter   120/  960] train: loss: 0.1151791
[Epoch 31; Iter   150/  960] train: loss: 0.0201193
[Epoch 31; Iter   180/  960] train: loss: 0.1010254
[Epoch 31; Iter   210/  960] train: loss: 0.0135394
[Epoch 31; Iter   240/  960] train: loss: 0.0197911
[Epoch 31; Iter   270/  960] train: loss: 0.0168020
[Epoch 31; Iter   300/  960] train: loss: 0.1359074
[Epoch 31; Iter   330/  960] train: loss: 0.0257146
[Epoch 31; Iter   360/  960] train: loss: 0.0289462
[Epoch 31; Iter   390/  960] train: loss: 0.2025498
[Epoch 31; Iter   420/  960] train: loss: 0.0318390
[Epoch 31; Iter   450/  960] train: loss: 0.0474316
[Epoch 31; Iter   480/  960] train: loss: 0.0314702
[Epoch 31; Iter   510/  960] train: loss: 0.0166886
[Epoch 31; Iter   540/  960] train: loss: 0.0168985
[Epoch 31; Iter   570/  960] train: loss: 0.0177116
[Epoch 31; Iter   600/  960] train: loss: 0.0271702
[Epoch 31; Iter   630/  960] train: loss: 0.0364154
[Epoch 31; Iter   660/  960] train: loss: 0.0217115
[Epoch 31; Iter   690/  960] train: loss: 0.0490558
[Epoch 31; Iter   720/  960] train: loss: 0.0329096
[Epoch 31; Iter   750/  960] train: loss: 0.0185534
[Epoch 31; Iter   780/  960] train: loss: 0.0162267
[Epoch 31; Iter   810/  960] train: loss: 0.1500218
[Epoch 31; Iter   840/  960] train: loss: 0.1406208
[Epoch 31; Iter   870/  960] train: loss: 0.0137344
[Epoch 31; Iter   900/  960] train: loss: 0.2469776
[Epoch 31; Iter   930/  960] train: loss: 0.0151165
[Epoch 31; Iter   960/  960] train: loss: 0.0228021
[Epoch 31] ogbg-molhiv: 0.818836 val loss: 0.128338
[Epoch 31] ogbg-molhiv: 0.816137 test loss: 0.121099
[Epoch 32; Iter    30/  960] train: loss: 0.0138963
[Epoch 32; Iter    60/  960] train: loss: 0.0394038
[Epoch 27; Iter   480/  960] train: loss: 0.0136153
[Epoch 27; Iter   510/  960] train: loss: 0.0244572
[Epoch 27; Iter   540/  960] train: loss: 0.0185503
[Epoch 27; Iter   570/  960] train: loss: 0.0528677
[Epoch 27; Iter   600/  960] train: loss: 0.0306801
[Epoch 27; Iter   630/  960] train: loss: 0.0550373
[Epoch 27; Iter   660/  960] train: loss: 0.0206961
[Epoch 27; Iter   690/  960] train: loss: 0.0283749
[Epoch 27; Iter   720/  960] train: loss: 0.1530493
[Epoch 27; Iter   750/  960] train: loss: 0.0207993
[Epoch 27; Iter   780/  960] train: loss: 0.0455730
[Epoch 27; Iter   810/  960] train: loss: 0.1808320
[Epoch 27; Iter   840/  960] train: loss: 0.0210888
[Epoch 27; Iter   870/  960] train: loss: 0.1178955
[Epoch 27; Iter   900/  960] train: loss: 0.0174393
[Epoch 27; Iter   930/  960] train: loss: 0.1456033
[Epoch 27; Iter   960/  960] train: loss: 0.0357539
[Epoch 27] ogbg-molhiv: 0.830162 val loss: 0.137228
[Epoch 27] ogbg-molhiv: 0.828433 test loss: 0.136675
[Epoch 28; Iter    30/  960] train: loss: 0.0797217
[Epoch 28; Iter    60/  960] train: loss: 0.0185470
[Epoch 28; Iter    90/  960] train: loss: 0.4213316
[Epoch 28; Iter   120/  960] train: loss: 0.0288489
[Epoch 28; Iter   150/  960] train: loss: 0.3824821
[Epoch 28; Iter   180/  960] train: loss: 0.0650290
[Epoch 28; Iter   210/  960] train: loss: 0.0146967
[Epoch 28; Iter   240/  960] train: loss: 0.0218280
[Epoch 28; Iter   270/  960] train: loss: 0.0108451
[Epoch 28; Iter   300/  960] train: loss: 0.0868257
[Epoch 28; Iter   330/  960] train: loss: 0.1959212
[Epoch 28; Iter   360/  960] train: loss: 0.0958864
[Epoch 28; Iter   390/  960] train: loss: 0.0625179
[Epoch 28; Iter   420/  960] train: loss: 0.0364390
[Epoch 28; Iter   450/  960] train: loss: 0.0157076
[Epoch 28; Iter   480/  960] train: loss: 0.0200484
[Epoch 28; Iter   510/  960] train: loss: 0.0210548
[Epoch 28; Iter   540/  960] train: loss: 0.3416093
[Epoch 28; Iter   570/  960] train: loss: 0.0297321
[Epoch 28; Iter   600/  960] train: loss: 0.0432178
[Epoch 28; Iter   630/  960] train: loss: 0.1364749
[Epoch 28; Iter   660/  960] train: loss: 0.0824135
[Epoch 28; Iter   690/  960] train: loss: 0.0733335
[Epoch 28; Iter   720/  960] train: loss: 0.1019900
[Epoch 28; Iter   750/  960] train: loss: 0.1322663
[Epoch 28; Iter   780/  960] train: loss: 0.1035285
[Epoch 28; Iter   810/  960] train: loss: 0.0519977
[Epoch 28; Iter   840/  960] train: loss: 0.0397002
[Epoch 28; Iter   870/  960] train: loss: 0.1002593
[Epoch 28; Iter   900/  960] train: loss: 0.0659365
[Epoch 28; Iter   930/  960] train: loss: 0.0891645
[Epoch 28; Iter   960/  960] train: loss: 0.2650012
[Epoch 28] ogbg-molhiv: 0.815337 val loss: 0.126193
[Epoch 28] ogbg-molhiv: 0.821191 test loss: 0.142847
[Epoch 29; Iter    30/  960] train: loss: 0.1152258
[Epoch 29; Iter    60/  960] train: loss: 0.1513150
[Epoch 29; Iter    90/  960] train: loss: 0.0237242
[Epoch 29; Iter   120/  960] train: loss: 0.0340872
[Epoch 29; Iter   150/  960] train: loss: 0.1103180
[Epoch 29; Iter   180/  960] train: loss: 0.0648845
[Epoch 29; Iter   210/  960] train: loss: 0.0435947
[Epoch 29; Iter   240/  960] train: loss: 0.0539816
[Epoch 29; Iter   270/  960] train: loss: 0.0275252
[Epoch 29; Iter   300/  960] train: loss: 0.0152448
[Epoch 29; Iter   330/  960] train: loss: 0.1746710
[Epoch 29; Iter   360/  960] train: loss: 0.0259243
[Epoch 29; Iter   390/  960] train: loss: 0.0563038
[Epoch 29; Iter   420/  960] train: loss: 0.1599211
[Epoch 29; Iter   450/  960] train: loss: 0.0256026
[Epoch 29; Iter   480/  960] train: loss: 0.2387432
[Epoch 29; Iter   510/  960] train: loss: 0.0318831
[Epoch 29; Iter   540/  960] train: loss: 0.0501299
[Epoch 29; Iter   570/  960] train: loss: 0.0129616
[Epoch 29; Iter   600/  960] train: loss: 0.0164761
[Epoch 29; Iter   630/  960] train: loss: 0.1095350
[Epoch 29; Iter   660/  960] train: loss: 0.0978107
[Epoch 29; Iter   690/  960] train: loss: 0.2452927
[Epoch 29; Iter   720/  960] train: loss: 0.0442747
[Epoch 29; Iter   750/  960] train: loss: 0.1580328
[Epoch 29; Iter   780/  960] train: loss: 0.0698349
[Epoch 29; Iter   810/  960] train: loss: 0.0135203
[Epoch 29; Iter   840/  960] train: loss: 0.0239244
[Epoch 29; Iter   870/  960] train: loss: 0.1160563
[Epoch 29; Iter   900/  960] train: loss: 0.0279657
[Epoch 29; Iter   930/  960] train: loss: 0.0142099
[Epoch 29; Iter   960/  960] train: loss: 0.0962371
[Epoch 29] ogbg-molhiv: 0.821632 val loss: 0.125490
[Epoch 29] ogbg-molhiv: 0.817006 test loss: 0.123177
[Epoch 30; Iter    30/  960] train: loss: 0.1744514
[Epoch 30; Iter    60/  960] train: loss: 0.0192579
[Epoch 30; Iter    90/  960] train: loss: 0.0187588
[Epoch 30; Iter   120/  960] train: loss: 0.1112320
[Epoch 30; Iter   150/  960] train: loss: 0.0209953
[Epoch 30; Iter   180/  960] train: loss: 0.1183770
[Epoch 30; Iter   210/  960] train: loss: 0.0536739
[Epoch 30; Iter   240/  960] train: loss: 0.1754821
[Epoch 30; Iter   270/  960] train: loss: 0.0885715
[Epoch 30; Iter   300/  960] train: loss: 0.1643000
[Epoch 30; Iter   330/  960] train: loss: 0.0146178
[Epoch 30; Iter   360/  960] train: loss: 0.0338778
[Epoch 30; Iter   390/  960] train: loss: 0.1835368
[Epoch 30; Iter   420/  960] train: loss: 0.0332992
[Epoch 30; Iter   450/  960] train: loss: 0.0499841
[Epoch 30; Iter   480/  960] train: loss: 0.0453011
[Epoch 30; Iter   510/  960] train: loss: 0.0640076
[Epoch 30; Iter   540/  960] train: loss: 0.0251113
[Epoch 30; Iter   570/  960] train: loss: 0.0269763
[Epoch 30; Iter   600/  960] train: loss: 0.1585342
[Epoch 30; Iter   630/  960] train: loss: 0.0972665
[Epoch 30; Iter   660/  960] train: loss: 0.2134271
[Epoch 30; Iter   690/  960] train: loss: 0.0438781
[Epoch 30; Iter   720/  960] train: loss: 0.0194216
[Epoch 30; Iter   750/  960] train: loss: 0.0236546
[Epoch 30; Iter   780/  960] train: loss: 0.1168480
[Epoch 30; Iter   810/  960] train: loss: 0.0298933
[Epoch 30; Iter   840/  960] train: loss: 0.0166842
[Epoch 30; Iter   870/  960] train: loss: 0.0622647
[Epoch 30; Iter   900/  960] train: loss: 0.0898264
[Epoch 30; Iter   930/  960] train: loss: 0.1633521
[Epoch 30; Iter   960/  960] train: loss: 0.0191496
[Epoch 30] ogbg-molhiv: 0.825590 val loss: 0.128653
[Epoch 30] ogbg-molhiv: 0.817097 test loss: 0.121522
[Epoch 31; Iter    30/  960] train: loss: 0.0902400
[Epoch 31; Iter    60/  960] train: loss: 0.0119975
[Epoch 31; Iter    90/  960] train: loss: 0.1420046
[Epoch 31; Iter   120/  960] train: loss: 0.0216861
[Epoch 31; Iter   150/  960] train: loss: 0.0265655
[Epoch 31; Iter   180/  960] train: loss: 0.0437736
[Epoch 31; Iter   210/  960] train: loss: 0.1674185
[Epoch 31; Iter   240/  960] train: loss: 0.1794182
[Epoch 31; Iter   270/  960] train: loss: 0.0185555
[Epoch 31; Iter   300/  960] train: loss: 0.0272174
[Epoch 31; Iter   330/  960] train: loss: 0.2127482
[Epoch 31; Iter   360/  960] train: loss: 0.0135685
[Epoch 31; Iter   390/  960] train: loss: 0.0142419
[Epoch 31; Iter   420/  960] train: loss: 0.0147778
[Epoch 31; Iter   450/  960] train: loss: 0.0467041
[Epoch 31; Iter   480/  960] train: loss: 0.0185032
[Epoch 31; Iter   510/  960] train: loss: 0.0165682
[Epoch 31; Iter   540/  960] train: loss: 0.0426406
[Epoch 31; Iter   570/  960] train: loss: 0.0530817
[Epoch 31; Iter   600/  960] train: loss: 0.0142466
[Epoch 31; Iter   630/  960] train: loss: 0.1470728
[Epoch 31; Iter   660/  960] train: loss: 0.0141479
[Epoch 31; Iter   690/  960] train: loss: 0.0308439
[Epoch 31; Iter   720/  960] train: loss: 0.0964250
[Epoch 31; Iter   750/  960] train: loss: 0.0997732
[Epoch 31; Iter   780/  960] train: loss: 0.0293716
[Epoch 31; Iter   810/  960] train: loss: 0.1364415
[Epoch 31; Iter   840/  960] train: loss: 0.0400368
[Epoch 31; Iter   870/  960] train: loss: 0.0262951
[Epoch 31; Iter   900/  960] train: loss: 0.2175786
[Epoch 31; Iter   930/  960] train: loss: 0.0146373
[Epoch 31; Iter   960/  960] train: loss: 0.0217461
[Epoch 31] ogbg-molhiv: 0.813767 val loss: 0.139482
[Epoch 31] ogbg-molhiv: 0.818649 test loss: 0.129502
[Epoch 32; Iter    30/  960] train: loss: 0.0312430
[Epoch 32; Iter    60/  960] train: loss: 0.0149936
[Epoch 27; Iter   480/  960] train: loss: 0.2243310
[Epoch 27; Iter   510/  960] train: loss: 0.1474538
[Epoch 27; Iter   540/  960] train: loss: 0.0268831
[Epoch 27; Iter   570/  960] train: loss: 0.0285235
[Epoch 27; Iter   600/  960] train: loss: 0.0187024
[Epoch 27; Iter   630/  960] train: loss: 0.1363416
[Epoch 27; Iter   660/  960] train: loss: 0.1547721
[Epoch 27; Iter   690/  960] train: loss: 0.1442402
[Epoch 27; Iter   720/  960] train: loss: 0.1494194
[Epoch 27; Iter   750/  960] train: loss: 0.0193871
[Epoch 27; Iter   780/  960] train: loss: 0.2302548
[Epoch 27; Iter   810/  960] train: loss: 0.0218689
[Epoch 27; Iter   840/  960] train: loss: 0.0513925
[Epoch 27; Iter   870/  960] train: loss: 0.0268838
[Epoch 27; Iter   900/  960] train: loss: 0.2160835
[Epoch 27; Iter   930/  960] train: loss: 0.0310733
[Epoch 27; Iter   960/  960] train: loss: 0.0205607
[Epoch 27] ogbg-molhiv: 0.804436 val loss: 0.126070
[Epoch 27] ogbg-molhiv: 0.815234 test loss: 0.113901
[Epoch 28; Iter    30/  960] train: loss: 0.0164325
[Epoch 28; Iter    60/  960] train: loss: 0.0260193
[Epoch 28; Iter    90/  960] train: loss: 0.1095882
[Epoch 28; Iter   120/  960] train: loss: 0.2193152
[Epoch 28; Iter   150/  960] train: loss: 0.0266311
[Epoch 28; Iter   180/  960] train: loss: 0.0214485
[Epoch 28; Iter   210/  960] train: loss: 0.0173127
[Epoch 28; Iter   240/  960] train: loss: 0.0967357
[Epoch 28; Iter   270/  960] train: loss: 0.0208212
[Epoch 28; Iter   300/  960] train: loss: 0.0419583
[Epoch 28; Iter   330/  960] train: loss: 0.2743267
[Epoch 28; Iter   360/  960] train: loss: 0.0241413
[Epoch 28; Iter   390/  960] train: loss: 0.0291755
[Epoch 28; Iter   420/  960] train: loss: 0.3228895
[Epoch 28; Iter   450/  960] train: loss: 0.0258333
[Epoch 28; Iter   480/  960] train: loss: 0.1073560
[Epoch 28; Iter   510/  960] train: loss: 0.0281443
[Epoch 28; Iter   540/  960] train: loss: 0.0360849
[Epoch 28; Iter   570/  960] train: loss: 0.0347271
[Epoch 28; Iter   600/  960] train: loss: 0.0279421
[Epoch 28; Iter   630/  960] train: loss: 0.0324501
[Epoch 28; Iter   660/  960] train: loss: 0.1042114
[Epoch 28; Iter   690/  960] train: loss: 0.1860616
[Epoch 28; Iter   720/  960] train: loss: 0.1376697
[Epoch 28; Iter   750/  960] train: loss: 0.0827184
[Epoch 28; Iter   780/  960] train: loss: 0.0163812
[Epoch 28; Iter   810/  960] train: loss: 0.0163136
[Epoch 28; Iter   840/  960] train: loss: 0.2093692
[Epoch 28; Iter   870/  960] train: loss: 0.0174958
[Epoch 28; Iter   900/  960] train: loss: 0.1414040
[Epoch 28; Iter   930/  960] train: loss: 0.0853430
[Epoch 28; Iter   960/  960] train: loss: 0.2009425
[Epoch 28] ogbg-molhiv: 0.786682 val loss: 0.132552
[Epoch 28] ogbg-molhiv: 0.810824 test loss: 0.119953
[Epoch 29; Iter    30/  960] train: loss: 0.0349321
[Epoch 29; Iter    60/  960] train: loss: 0.2668829
[Epoch 29; Iter    90/  960] train: loss: 0.2692622
[Epoch 29; Iter   120/  960] train: loss: 0.1039256
[Epoch 29; Iter   150/  960] train: loss: 0.0888333
[Epoch 29; Iter   180/  960] train: loss: 0.0184837
[Epoch 29; Iter   210/  960] train: loss: 0.0207481
[Epoch 29; Iter   240/  960] train: loss: 0.0346209
[Epoch 29; Iter   270/  960] train: loss: 0.1584556
[Epoch 29; Iter   300/  960] train: loss: 0.0268668
[Epoch 29; Iter   330/  960] train: loss: 0.2129472
[Epoch 29; Iter   360/  960] train: loss: 0.0303135
[Epoch 29; Iter   390/  960] train: loss: 0.0158082
[Epoch 29; Iter   420/  960] train: loss: 0.0924161
[Epoch 29; Iter   450/  960] train: loss: 0.1674455
[Epoch 29; Iter   480/  960] train: loss: 0.3470347
[Epoch 29; Iter   510/  960] train: loss: 0.0332361
[Epoch 29; Iter   540/  960] train: loss: 0.0282668
[Epoch 29; Iter   570/  960] train: loss: 0.0471246
[Epoch 29; Iter   600/  960] train: loss: 0.0211930
[Epoch 29; Iter   630/  960] train: loss: 0.0317879
[Epoch 29; Iter   660/  960] train: loss: 0.0991756
[Epoch 29; Iter   690/  960] train: loss: 0.0895438
[Epoch 29; Iter   720/  960] train: loss: 0.0680368
[Epoch 29; Iter   750/  960] train: loss: 0.1376467
[Epoch 29; Iter   780/  960] train: loss: 0.0182911
[Epoch 29; Iter   810/  960] train: loss: 0.0160526
[Epoch 29; Iter   840/  960] train: loss: 0.2024987
[Epoch 29; Iter   870/  960] train: loss: 0.2024055
[Epoch 29; Iter   900/  960] train: loss: 0.0712395
[Epoch 29; Iter   930/  960] train: loss: 0.0205837
[Epoch 29; Iter   960/  960] train: loss: 0.0250596
[Epoch 29] ogbg-molhiv: 0.805125 val loss: 0.128737
[Epoch 29] ogbg-molhiv: 0.831467 test loss: 0.113690
[Epoch 30; Iter    30/  960] train: loss: 0.0954189
[Epoch 30; Iter    60/  960] train: loss: 0.0262988
[Epoch 30; Iter    90/  960] train: loss: 0.0229869
[Epoch 30; Iter   120/  960] train: loss: 0.0581530
[Epoch 30; Iter   150/  960] train: loss: 0.3258708
[Epoch 30; Iter   180/  960] train: loss: 0.0875707
[Epoch 30; Iter   210/  960] train: loss: 0.0460134
[Epoch 30; Iter   240/  960] train: loss: 0.0239765
[Epoch 30; Iter   270/  960] train: loss: 0.0164462
[Epoch 30; Iter   300/  960] train: loss: 0.1856110
[Epoch 30; Iter   330/  960] train: loss: 0.0615461
[Epoch 30; Iter   360/  960] train: loss: 0.0311686
[Epoch 30; Iter   390/  960] train: loss: 0.0650271
[Epoch 30; Iter   420/  960] train: loss: 0.0258249
[Epoch 30; Iter   450/  960] train: loss: 0.0786456
[Epoch 30; Iter   480/  960] train: loss: 0.1109535
[Epoch 30; Iter   510/  960] train: loss: 0.1624322
[Epoch 30; Iter   540/  960] train: loss: 0.1312079
[Epoch 30; Iter   570/  960] train: loss: 0.1502754
[Epoch 30; Iter   600/  960] train: loss: 0.2101369
[Epoch 30; Iter   630/  960] train: loss: 0.0089623
[Epoch 30; Iter   660/  960] train: loss: 0.0858603
[Epoch 30; Iter   690/  960] train: loss: 0.0987845
[Epoch 30; Iter   720/  960] train: loss: 0.0980592
[Epoch 30; Iter   750/  960] train: loss: 0.0809228
[Epoch 30; Iter   780/  960] train: loss: 0.0501040
[Epoch 30; Iter   810/  960] train: loss: 0.0377301
[Epoch 30; Iter   840/  960] train: loss: 0.0575594
[Epoch 30; Iter   870/  960] train: loss: 0.0194655
[Epoch 30; Iter   900/  960] train: loss: 0.2804486
[Epoch 30; Iter   930/  960] train: loss: 0.0153143
[Epoch 30; Iter   960/  960] train: loss: 0.0198618
[Epoch 30] ogbg-molhiv: 0.794433 val loss: 0.127828
[Epoch 30] ogbg-molhiv: 0.824311 test loss: 0.114718
[Epoch 31; Iter    30/  960] train: loss: 0.1929313
[Epoch 31; Iter    60/  960] train: loss: 0.0916899
[Epoch 31; Iter    90/  960] train: loss: 0.0500277
[Epoch 31; Iter   120/  960] train: loss: 0.0571903
[Epoch 31; Iter   150/  960] train: loss: 0.0860867
[Epoch 31; Iter   180/  960] train: loss: 0.0289045
[Epoch 31; Iter   210/  960] train: loss: 0.0218167
[Epoch 31; Iter   240/  960] train: loss: 0.1945049
[Epoch 31; Iter   270/  960] train: loss: 0.0216947
[Epoch 31; Iter   300/  960] train: loss: 0.0814526
[Epoch 31; Iter   330/  960] train: loss: 0.0858149
[Epoch 31; Iter   360/  960] train: loss: 0.0353190
[Epoch 31; Iter   390/  960] train: loss: 0.1041833
[Epoch 31; Iter   420/  960] train: loss: 0.0765410
[Epoch 31; Iter   450/  960] train: loss: 0.1851429
[Epoch 31; Iter   480/  960] train: loss: 0.2459706
[Epoch 31; Iter   510/  960] train: loss: 0.0808971
[Epoch 31; Iter   540/  960] train: loss: 0.0349651
[Epoch 31; Iter   570/  960] train: loss: 0.2173958
[Epoch 31; Iter   600/  960] train: loss: 0.0131928
[Epoch 31; Iter   630/  960] train: loss: 0.0340478
[Epoch 31; Iter   660/  960] train: loss: 0.0352666
[Epoch 31; Iter   690/  960] train: loss: 0.1422571
[Epoch 31; Iter   720/  960] train: loss: 0.0245036
[Epoch 31; Iter   750/  960] train: loss: 0.0505116
[Epoch 31; Iter   780/  960] train: loss: 0.0319590
[Epoch 31; Iter   810/  960] train: loss: 0.0133248
[Epoch 31; Iter   840/  960] train: loss: 0.1438954
[Epoch 31; Iter   870/  960] train: loss: 0.1626364
[Epoch 31; Iter   900/  960] train: loss: 0.0454084
[Epoch 31; Iter   930/  960] train: loss: 0.0426932
[Epoch 31; Iter   960/  960] train: loss: 0.0139074
[Epoch 31] ogbg-molhiv: 0.802800 val loss: 0.130818
[Epoch 31] ogbg-molhiv: 0.816475 test loss: 0.121110
[Epoch 32; Iter    30/  960] train: loss: 0.1333805
[Epoch 32; Iter    60/  960] train: loss: 0.1168261
[Epoch 28; Iter   471/ 1097] train: loss: 0.0252304
[Epoch 28; Iter   501/ 1097] train: loss: 0.0236267
[Epoch 28; Iter   531/ 1097] train: loss: 0.0565868
[Epoch 28; Iter   561/ 1097] train: loss: 0.0234602
[Epoch 28; Iter   591/ 1097] train: loss: 0.0260638
[Epoch 28; Iter   621/ 1097] train: loss: 0.0329285
[Epoch 28; Iter   651/ 1097] train: loss: 0.1307901
[Epoch 28; Iter   681/ 1097] train: loss: 0.1998415
[Epoch 28; Iter   711/ 1097] train: loss: 0.1335594
[Epoch 28; Iter   741/ 1097] train: loss: 0.1846023
[Epoch 28; Iter   771/ 1097] train: loss: 0.1576736
[Epoch 28; Iter   801/ 1097] train: loss: 0.2068002
[Epoch 28; Iter   831/ 1097] train: loss: 0.0335902
[Epoch 28; Iter   861/ 1097] train: loss: 0.0725313
[Epoch 28; Iter   891/ 1097] train: loss: 0.1158746
[Epoch 28; Iter   921/ 1097] train: loss: 0.0218663
[Epoch 28; Iter   951/ 1097] train: loss: 0.0880571
[Epoch 28; Iter   981/ 1097] train: loss: 0.1933784
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0559878
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0307589
[Epoch 28; Iter  1071/ 1097] train: loss: 0.1217906
[Epoch 28] ogbg-molhiv: 0.813611 val loss: 0.177762
[Epoch 28] ogbg-molhiv: 0.807417 test loss: 0.125906
[Epoch 29; Iter     4/ 1097] train: loss: 0.0455126
[Epoch 29; Iter    34/ 1097] train: loss: 0.0222543
[Epoch 29; Iter    64/ 1097] train: loss: 0.0996621
[Epoch 29; Iter    94/ 1097] train: loss: 0.5256332
[Epoch 29; Iter   124/ 1097] train: loss: 0.0261616
[Epoch 29; Iter   154/ 1097] train: loss: 0.2474768
[Epoch 29; Iter   184/ 1097] train: loss: 0.0269413
[Epoch 29; Iter   214/ 1097] train: loss: 0.0190981
[Epoch 29; Iter   244/ 1097] train: loss: 0.0236978
[Epoch 29; Iter   274/ 1097] train: loss: 0.3910619
[Epoch 29; Iter   304/ 1097] train: loss: 0.2551241
[Epoch 29; Iter   334/ 1097] train: loss: 0.1442885
[Epoch 29; Iter   364/ 1097] train: loss: 0.1365404
[Epoch 29; Iter   394/ 1097] train: loss: 0.0349615
[Epoch 29; Iter   424/ 1097] train: loss: 0.1387949
[Epoch 29; Iter   454/ 1097] train: loss: 0.0374575
[Epoch 29; Iter   484/ 1097] train: loss: 0.1102089
[Epoch 29; Iter   514/ 1097] train: loss: 0.0515229
[Epoch 29; Iter   544/ 1097] train: loss: 0.0933917
[Epoch 29; Iter   574/ 1097] train: loss: 0.1830038
[Epoch 29; Iter   604/ 1097] train: loss: 0.4012473
[Epoch 29; Iter   634/ 1097] train: loss: 0.0866912
[Epoch 29; Iter   664/ 1097] train: loss: 0.0215627
[Epoch 29; Iter   694/ 1097] train: loss: 0.3491727
[Epoch 29; Iter   724/ 1097] train: loss: 0.0992417
[Epoch 29; Iter   754/ 1097] train: loss: 0.0632747
[Epoch 29; Iter   784/ 1097] train: loss: 0.0489974
[Epoch 29; Iter   814/ 1097] train: loss: 0.1086039
[Epoch 29; Iter   844/ 1097] train: loss: 0.1975125
[Epoch 29; Iter   874/ 1097] train: loss: 0.4282289
[Epoch 29; Iter   904/ 1097] train: loss: 0.1913314
[Epoch 29; Iter   934/ 1097] train: loss: 0.0309076
[Epoch 29; Iter   964/ 1097] train: loss: 0.2071531
[Epoch 29; Iter   994/ 1097] train: loss: 0.0197862
[Epoch 29; Iter  1024/ 1097] train: loss: 0.1608087
[Epoch 29; Iter  1054/ 1097] train: loss: 0.1377803
[Epoch 29; Iter  1084/ 1097] train: loss: 0.1844967
[Epoch 29] ogbg-molhiv: 0.815052 val loss: 0.389971
[Epoch 29] ogbg-molhiv: 0.801364 test loss: 0.619010
[Epoch 30; Iter    17/ 1097] train: loss: 0.0254865
[Epoch 30; Iter    47/ 1097] train: loss: 0.1453996
[Epoch 30; Iter    77/ 1097] train: loss: 0.2546445
[Epoch 30; Iter   107/ 1097] train: loss: 0.0946253
[Epoch 30; Iter   137/ 1097] train: loss: 0.0857451
[Epoch 30; Iter   167/ 1097] train: loss: 0.1345104
[Epoch 30; Iter   197/ 1097] train: loss: 0.2364286
[Epoch 30; Iter   227/ 1097] train: loss: 0.0258638
[Epoch 30; Iter   257/ 1097] train: loss: 0.0199258
[Epoch 30; Iter   287/ 1097] train: loss: 0.0350785
[Epoch 30; Iter   317/ 1097] train: loss: 0.0165917
[Epoch 30; Iter   347/ 1097] train: loss: 0.2717894
[Epoch 30; Iter   377/ 1097] train: loss: 0.0519499
[Epoch 30; Iter   407/ 1097] train: loss: 0.0272179
[Epoch 30; Iter   437/ 1097] train: loss: 0.1185716
[Epoch 30; Iter   467/ 1097] train: loss: 0.0309313
[Epoch 30; Iter   497/ 1097] train: loss: 0.1576015
[Epoch 30; Iter   527/ 1097] train: loss: 0.1532637
[Epoch 30; Iter   557/ 1097] train: loss: 0.0212674
[Epoch 30; Iter   587/ 1097] train: loss: 0.2860986
[Epoch 30; Iter   617/ 1097] train: loss: 0.2012122
[Epoch 30; Iter   647/ 1097] train: loss: 0.1893549
[Epoch 30; Iter   677/ 1097] train: loss: 0.0754006
[Epoch 30; Iter   707/ 1097] train: loss: 0.0150562
[Epoch 30; Iter   737/ 1097] train: loss: 0.0202661
[Epoch 30; Iter   767/ 1097] train: loss: 0.0673308
[Epoch 30; Iter   797/ 1097] train: loss: 0.0263077
[Epoch 30; Iter   827/ 1097] train: loss: 0.2710185
[Epoch 30; Iter   857/ 1097] train: loss: 0.0808664
[Epoch 30; Iter   887/ 1097] train: loss: 0.0215104
[Epoch 30; Iter   917/ 1097] train: loss: 0.1465022
[Epoch 30; Iter   947/ 1097] train: loss: 0.0311685
[Epoch 30; Iter   977/ 1097] train: loss: 0.2407653
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0995933
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0229098
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0480525
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0293955
[Epoch 30] ogbg-molhiv: 0.807633 val loss: 0.377587
[Epoch 30] ogbg-molhiv: 0.801839 test loss: 0.155104
[Epoch 31; Iter    30/ 1097] train: loss: 0.1780961
[Epoch 31; Iter    60/ 1097] train: loss: 0.0427014
[Epoch 31; Iter    90/ 1097] train: loss: 0.0264523
[Epoch 31; Iter   120/ 1097] train: loss: 0.0333581
[Epoch 31; Iter   150/ 1097] train: loss: 0.0527088
[Epoch 31; Iter   180/ 1097] train: loss: 0.2898349
[Epoch 31; Iter   210/ 1097] train: loss: 0.0412129
[Epoch 31; Iter   240/ 1097] train: loss: 0.2130284
[Epoch 31; Iter   270/ 1097] train: loss: 0.0167145
[Epoch 31; Iter   300/ 1097] train: loss: 0.0217140
[Epoch 31; Iter   330/ 1097] train: loss: 0.1191863
[Epoch 31; Iter   360/ 1097] train: loss: 0.1100267
[Epoch 31; Iter   390/ 1097] train: loss: 0.0175209
[Epoch 31; Iter   420/ 1097] train: loss: 0.1979250
[Epoch 31; Iter   450/ 1097] train: loss: 0.2238272
[Epoch 31; Iter   480/ 1097] train: loss: 0.0621164
[Epoch 31; Iter   510/ 1097] train: loss: 0.1037648
[Epoch 31; Iter   540/ 1097] train: loss: 0.2547200
[Epoch 31; Iter   570/ 1097] train: loss: 0.1209636
[Epoch 31; Iter   600/ 1097] train: loss: 0.1441992
[Epoch 31; Iter   630/ 1097] train: loss: 0.0835365
[Epoch 31; Iter   660/ 1097] train: loss: 0.0203827
[Epoch 31; Iter   690/ 1097] train: loss: 0.0336407
[Epoch 31; Iter   720/ 1097] train: loss: 0.0233017
[Epoch 31; Iter   750/ 1097] train: loss: 0.0259205
[Epoch 31; Iter   780/ 1097] train: loss: 0.0231380
[Epoch 31; Iter   810/ 1097] train: loss: 0.2049704
[Epoch 31; Iter   840/ 1097] train: loss: 0.0341765
[Epoch 31; Iter   870/ 1097] train: loss: 0.0818989
[Epoch 31; Iter   900/ 1097] train: loss: 0.1028996
[Epoch 31; Iter   930/ 1097] train: loss: 0.0424524
[Epoch 31; Iter   960/ 1097] train: loss: 0.0395749
[Epoch 31; Iter   990/ 1097] train: loss: 0.2863339
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0372375
[Epoch 31; Iter  1050/ 1097] train: loss: 0.1178897
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0910547
[Epoch 31] ogbg-molhiv: 0.822080 val loss: 0.202707
[Epoch 31] ogbg-molhiv: 0.808610 test loss: 0.114266
[Epoch 32; Iter    13/ 1097] train: loss: 0.1564163
[Epoch 32; Iter    43/ 1097] train: loss: 0.0227992
[Epoch 32; Iter    73/ 1097] train: loss: 0.0756837
[Epoch 32; Iter   103/ 1097] train: loss: 0.0290856
[Epoch 32; Iter   133/ 1097] train: loss: 0.1413789
[Epoch 32; Iter   163/ 1097] train: loss: 0.0440823
[Epoch 32; Iter   193/ 1097] train: loss: 0.0220743
[Epoch 32; Iter   223/ 1097] train: loss: 0.0163971
[Epoch 32; Iter   253/ 1097] train: loss: 0.0998805
[Epoch 32; Iter   283/ 1097] train: loss: 0.2065737
[Epoch 32; Iter   313/ 1097] train: loss: 0.1527076
[Epoch 32; Iter   343/ 1097] train: loss: 0.0288077
[Epoch 32; Iter   373/ 1097] train: loss: 0.0214158
[Epoch 32; Iter   403/ 1097] train: loss: 0.0547496
[Epoch 32; Iter   433/ 1097] train: loss: 0.0185046
[Epoch 32; Iter   463/ 1097] train: loss: 0.1455894
[Epoch 32; Iter   493/ 1097] train: loss: 0.1320513
[Epoch 32; Iter   523/ 1097] train: loss: 0.0520535
[Epoch 28; Iter   471/ 1097] train: loss: 0.2390508
[Epoch 28; Iter   501/ 1097] train: loss: 0.0113423
[Epoch 28; Iter   531/ 1097] train: loss: 0.0161061
[Epoch 28; Iter   561/ 1097] train: loss: 0.0249131
[Epoch 28; Iter   591/ 1097] train: loss: 0.0126279
[Epoch 28; Iter   621/ 1097] train: loss: 0.1042767
[Epoch 28; Iter   651/ 1097] train: loss: 0.0503953
[Epoch 28; Iter   681/ 1097] train: loss: 0.1477996
[Epoch 28; Iter   711/ 1097] train: loss: 0.0361238
[Epoch 28; Iter   741/ 1097] train: loss: 0.0336832
[Epoch 28; Iter   771/ 1097] train: loss: 0.0518342
[Epoch 28; Iter   801/ 1097] train: loss: 0.1189499
[Epoch 28; Iter   831/ 1097] train: loss: 0.1465483
[Epoch 28; Iter   861/ 1097] train: loss: 0.2370559
[Epoch 28; Iter   891/ 1097] train: loss: 0.1892107
[Epoch 28; Iter   921/ 1097] train: loss: 0.0822758
[Epoch 28; Iter   951/ 1097] train: loss: 0.0779195
[Epoch 28; Iter   981/ 1097] train: loss: 0.2358015
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0335894
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0825122
[Epoch 28; Iter  1071/ 1097] train: loss: 0.1398242
[Epoch 28] ogbg-molhiv: 0.800948 val loss: 0.637321
[Epoch 28] ogbg-molhiv: 0.803285 test loss: 1.134890
[Epoch 29; Iter     4/ 1097] train: loss: 0.1067269
[Epoch 29; Iter    34/ 1097] train: loss: 0.0971540
[Epoch 29; Iter    64/ 1097] train: loss: 0.0360897
[Epoch 29; Iter    94/ 1097] train: loss: 0.4483305
[Epoch 29; Iter   124/ 1097] train: loss: 0.0872589
[Epoch 29; Iter   154/ 1097] train: loss: 0.1107399
[Epoch 29; Iter   184/ 1097] train: loss: 0.0181733
[Epoch 29; Iter   214/ 1097] train: loss: 0.1854922
[Epoch 29; Iter   244/ 1097] train: loss: 0.0190185
[Epoch 29; Iter   274/ 1097] train: loss: 0.2656882
[Epoch 29; Iter   304/ 1097] train: loss: 0.2044623
[Epoch 29; Iter   334/ 1097] train: loss: 0.0527211
[Epoch 29; Iter   364/ 1097] train: loss: 0.1143354
[Epoch 29; Iter   394/ 1097] train: loss: 0.0216017
[Epoch 29; Iter   424/ 1097] train: loss: 0.0845332
[Epoch 29; Iter   454/ 1097] train: loss: 0.0519123
[Epoch 29; Iter   484/ 1097] train: loss: 0.0582885
[Epoch 29; Iter   514/ 1097] train: loss: 0.0213023
[Epoch 29; Iter   544/ 1097] train: loss: 0.1037812
[Epoch 29; Iter   574/ 1097] train: loss: 0.2031385
[Epoch 29; Iter   604/ 1097] train: loss: 0.6107691
[Epoch 29; Iter   634/ 1097] train: loss: 0.0323847
[Epoch 29; Iter   664/ 1097] train: loss: 0.1546925
[Epoch 29; Iter   694/ 1097] train: loss: 0.0250513
[Epoch 29; Iter   724/ 1097] train: loss: 0.1344094
[Epoch 29; Iter   754/ 1097] train: loss: 0.0185978
[Epoch 29; Iter   784/ 1097] train: loss: 0.1258168
[Epoch 29; Iter   814/ 1097] train: loss: 0.0669791
[Epoch 29; Iter   844/ 1097] train: loss: 0.0300786
[Epoch 29; Iter   874/ 1097] train: loss: 0.0200335
[Epoch 29; Iter   904/ 1097] train: loss: 0.0205545
[Epoch 29; Iter   934/ 1097] train: loss: 0.0568861
[Epoch 29; Iter   964/ 1097] train: loss: 0.1543258
[Epoch 29; Iter   994/ 1097] train: loss: 0.1157681
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0513490
[Epoch 29; Iter  1054/ 1097] train: loss: 0.1688416
[Epoch 29; Iter  1084/ 1097] train: loss: 0.1000470
[Epoch 29] ogbg-molhiv: 0.802411 val loss: 0.153236
[Epoch 29] ogbg-molhiv: 0.815486 test loss: 0.121177
[Epoch 30; Iter    17/ 1097] train: loss: 0.0256899
[Epoch 30; Iter    47/ 1097] train: loss: 0.0489071
[Epoch 30; Iter    77/ 1097] train: loss: 0.0270145
[Epoch 30; Iter   107/ 1097] train: loss: 0.0234034
[Epoch 30; Iter   137/ 1097] train: loss: 0.0169303
[Epoch 30; Iter   167/ 1097] train: loss: 0.0659869
[Epoch 30; Iter   197/ 1097] train: loss: 0.1898888
[Epoch 30; Iter   227/ 1097] train: loss: 0.1888698
[Epoch 30; Iter   257/ 1097] train: loss: 0.1340540
[Epoch 30; Iter   287/ 1097] train: loss: 0.0157112
[Epoch 30; Iter   317/ 1097] train: loss: 0.0258671
[Epoch 30; Iter   347/ 1097] train: loss: 0.0229198
[Epoch 30; Iter   377/ 1097] train: loss: 0.0247789
[Epoch 30; Iter   407/ 1097] train: loss: 0.0374597
[Epoch 30; Iter   437/ 1097] train: loss: 0.1191841
[Epoch 30; Iter   467/ 1097] train: loss: 0.0721722
[Epoch 30; Iter   497/ 1097] train: loss: 0.0422012
[Epoch 30; Iter   527/ 1097] train: loss: 0.0647216
[Epoch 30; Iter   557/ 1097] train: loss: 0.0740924
[Epoch 30; Iter   587/ 1097] train: loss: 0.0284015
[Epoch 30; Iter   617/ 1097] train: loss: 0.3972946
[Epoch 30; Iter   647/ 1097] train: loss: 0.0247350
[Epoch 30; Iter   677/ 1097] train: loss: 0.0791673
[Epoch 30; Iter   707/ 1097] train: loss: 0.0418507
[Epoch 30; Iter   737/ 1097] train: loss: 0.0313902
[Epoch 30; Iter   767/ 1097] train: loss: 0.0503479
[Epoch 30; Iter   797/ 1097] train: loss: 0.0947785
[Epoch 30; Iter   827/ 1097] train: loss: 0.0224366
[Epoch 30; Iter   857/ 1097] train: loss: 0.0148054
[Epoch 30; Iter   887/ 1097] train: loss: 0.1610238
[Epoch 30; Iter   917/ 1097] train: loss: 0.0676239
[Epoch 30; Iter   947/ 1097] train: loss: 0.0477103
[Epoch 30; Iter   977/ 1097] train: loss: 0.1037307
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0954389
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0990165
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0431383
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0229753
[Epoch 30] ogbg-molhiv: 0.808178 val loss: 0.119702
[Epoch 30] ogbg-molhiv: 0.816233 test loss: 0.193629
[Epoch 31; Iter    30/ 1097] train: loss: 0.0211293
[Epoch 31; Iter    60/ 1097] train: loss: 0.0390784
[Epoch 31; Iter    90/ 1097] train: loss: 0.0229468
[Epoch 31; Iter   120/ 1097] train: loss: 0.2914608
[Epoch 31; Iter   150/ 1097] train: loss: 0.0912839
[Epoch 31; Iter   180/ 1097] train: loss: 0.1699729
[Epoch 31; Iter   210/ 1097] train: loss: 0.1526962
[Epoch 31; Iter   240/ 1097] train: loss: 0.1664134
[Epoch 31; Iter   270/ 1097] train: loss: 0.0568799
[Epoch 31; Iter   300/ 1097] train: loss: 0.0173799
[Epoch 31; Iter   330/ 1097] train: loss: 0.0451222
[Epoch 31; Iter   360/ 1097] train: loss: 0.0276917
[Epoch 31; Iter   390/ 1097] train: loss: 0.0224179
[Epoch 31; Iter   420/ 1097] train: loss: 0.0205468
[Epoch 31; Iter   450/ 1097] train: loss: 0.0596618
[Epoch 31; Iter   480/ 1097] train: loss: 0.0281546
[Epoch 31; Iter   510/ 1097] train: loss: 0.2286813
[Epoch 31; Iter   540/ 1097] train: loss: 0.0421319
[Epoch 31; Iter   570/ 1097] train: loss: 0.0381580
[Epoch 31; Iter   600/ 1097] train: loss: 0.0197388
[Epoch 31; Iter   630/ 1097] train: loss: 0.0149194
[Epoch 31; Iter   660/ 1097] train: loss: 0.0189133
[Epoch 31; Iter   690/ 1097] train: loss: 0.0194475
[Epoch 31; Iter   720/ 1097] train: loss: 0.0348645
[Epoch 31; Iter   750/ 1097] train: loss: 0.0134242
[Epoch 31; Iter   780/ 1097] train: loss: 0.0222653
[Epoch 31; Iter   810/ 1097] train: loss: 0.1416050
[Epoch 31; Iter   840/ 1097] train: loss: 0.0276575
[Epoch 31; Iter   870/ 1097] train: loss: 0.0825797
[Epoch 31; Iter   900/ 1097] train: loss: 0.0294678
[Epoch 31; Iter   930/ 1097] train: loss: 0.0517187
[Epoch 31; Iter   960/ 1097] train: loss: 0.2801075
[Epoch 31; Iter   990/ 1097] train: loss: 0.0087144
[Epoch 31; Iter  1020/ 1097] train: loss: 0.1839751
[Epoch 31; Iter  1050/ 1097] train: loss: 0.1506200
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0489965
[Epoch 31] ogbg-molhiv: 0.813244 val loss: 0.178491
[Epoch 31] ogbg-molhiv: 0.822113 test loss: 0.332899
[Epoch 32; Iter    13/ 1097] train: loss: 0.1267123
[Epoch 32; Iter    43/ 1097] train: loss: 0.1209595
[Epoch 32; Iter    73/ 1097] train: loss: 0.0292372
[Epoch 32; Iter   103/ 1097] train: loss: 0.0479755
[Epoch 32; Iter   133/ 1097] train: loss: 0.2094633
[Epoch 32; Iter   163/ 1097] train: loss: 0.1535531
[Epoch 32; Iter   193/ 1097] train: loss: 0.0627850
[Epoch 32; Iter   223/ 1097] train: loss: 0.1020694
[Epoch 32; Iter   253/ 1097] train: loss: 0.0255036
[Epoch 32; Iter   283/ 1097] train: loss: 0.0156622
[Epoch 32; Iter   313/ 1097] train: loss: 0.0237814
[Epoch 32; Iter   343/ 1097] train: loss: 0.2035347
[Epoch 32; Iter   373/ 1097] train: loss: 0.0664589
[Epoch 32; Iter   403/ 1097] train: loss: 0.0312181
[Epoch 32; Iter   433/ 1097] train: loss: 0.0348717
[Epoch 32; Iter   463/ 1097] train: loss: 0.2244098
[Epoch 32; Iter   493/ 1097] train: loss: 0.0931616
[Epoch 32; Iter   523/ 1097] train: loss: 0.1818001
[Epoch 28; Iter   471/ 1097] train: loss: 0.1151720
[Epoch 28; Iter   501/ 1097] train: loss: 0.0266718
[Epoch 28; Iter   531/ 1097] train: loss: 0.0176413
[Epoch 28; Iter   561/ 1097] train: loss: 0.0195367
[Epoch 28; Iter   591/ 1097] train: loss: 0.0159877
[Epoch 28; Iter   621/ 1097] train: loss: 0.2089621
[Epoch 28; Iter   651/ 1097] train: loss: 0.0115568
[Epoch 28; Iter   681/ 1097] train: loss: 0.3467920
[Epoch 28; Iter   711/ 1097] train: loss: 0.0664935
[Epoch 28; Iter   741/ 1097] train: loss: 0.1456550
[Epoch 28; Iter   771/ 1097] train: loss: 0.0626640
[Epoch 28; Iter   801/ 1097] train: loss: 0.0532134
[Epoch 28; Iter   831/ 1097] train: loss: 0.0433994
[Epoch 28; Iter   861/ 1097] train: loss: 0.0910917
[Epoch 28; Iter   891/ 1097] train: loss: 0.2115635
[Epoch 28; Iter   921/ 1097] train: loss: 0.0464689
[Epoch 28; Iter   951/ 1097] train: loss: 0.0252245
[Epoch 28; Iter   981/ 1097] train: loss: 0.1288805
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0279092
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0855899
[Epoch 28; Iter  1071/ 1097] train: loss: 0.1543642
[Epoch 28] ogbg-molhiv: 0.810401 val loss: 0.116736
[Epoch 28] ogbg-molhiv: 0.811549 test loss: 0.119791
[Epoch 29; Iter     4/ 1097] train: loss: 0.0164641
[Epoch 29; Iter    34/ 1097] train: loss: 0.0211087
[Epoch 29; Iter    64/ 1097] train: loss: 0.0310854
[Epoch 29; Iter    94/ 1097] train: loss: 0.3826798
[Epoch 29; Iter   124/ 1097] train: loss: 0.0205360
[Epoch 29; Iter   154/ 1097] train: loss: 0.2049131
[Epoch 29; Iter   184/ 1097] train: loss: 0.0242863
[Epoch 29; Iter   214/ 1097] train: loss: 0.0342321
[Epoch 29; Iter   244/ 1097] train: loss: 0.0312455
[Epoch 29; Iter   274/ 1097] train: loss: 0.1035501
[Epoch 29; Iter   304/ 1097] train: loss: 0.0863431
[Epoch 29; Iter   334/ 1097] train: loss: 0.1007827
[Epoch 29; Iter   364/ 1097] train: loss: 0.2223364
[Epoch 29; Iter   394/ 1097] train: loss: 0.0284137
[Epoch 29; Iter   424/ 1097] train: loss: 0.0382645
[Epoch 29; Iter   454/ 1097] train: loss: 0.0218996
[Epoch 29; Iter   484/ 1097] train: loss: 0.1115632
[Epoch 29; Iter   514/ 1097] train: loss: 0.0505899
[Epoch 29; Iter   544/ 1097] train: loss: 0.1040149
[Epoch 29; Iter   574/ 1097] train: loss: 0.0617521
[Epoch 29; Iter   604/ 1097] train: loss: 0.0238207
[Epoch 29; Iter   634/ 1097] train: loss: 0.1278168
[Epoch 29; Iter   664/ 1097] train: loss: 0.0119751
[Epoch 29; Iter   694/ 1097] train: loss: 0.0169960
[Epoch 29; Iter   724/ 1097] train: loss: 0.1462804
[Epoch 29; Iter   754/ 1097] train: loss: 0.0436202
[Epoch 29; Iter   784/ 1097] train: loss: 0.0912972
[Epoch 29; Iter   814/ 1097] train: loss: 0.1196863
[Epoch 29; Iter   844/ 1097] train: loss: 0.0222479
[Epoch 29; Iter   874/ 1097] train: loss: 0.0558871
[Epoch 29; Iter   904/ 1097] train: loss: 0.0303278
[Epoch 29; Iter   934/ 1097] train: loss: 0.1333238
[Epoch 29; Iter   964/ 1097] train: loss: 0.2557914
[Epoch 29; Iter   994/ 1097] train: loss: 0.1276456
[Epoch 29; Iter  1024/ 1097] train: loss: 0.1491379
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0150064
[Epoch 29; Iter  1084/ 1097] train: loss: 0.0352697
[Epoch 29] ogbg-molhiv: 0.810716 val loss: 0.248485
[Epoch 29] ogbg-molhiv: 0.830595 test loss: 0.213548
[Epoch 30; Iter    17/ 1097] train: loss: 0.0290083
[Epoch 30; Iter    47/ 1097] train: loss: 0.1354427
[Epoch 30; Iter    77/ 1097] train: loss: 0.1359071
[Epoch 30; Iter   107/ 1097] train: loss: 0.0229657
[Epoch 30; Iter   137/ 1097] train: loss: 0.0353103
[Epoch 30; Iter   167/ 1097] train: loss: 0.0153545
[Epoch 30; Iter   197/ 1097] train: loss: 0.0391442
[Epoch 30; Iter   227/ 1097] train: loss: 0.0243082
[Epoch 30; Iter   257/ 1097] train: loss: 0.0147754
[Epoch 30; Iter   287/ 1097] train: loss: 0.0264306
[Epoch 30; Iter   317/ 1097] train: loss: 0.0222819
[Epoch 30; Iter   347/ 1097] train: loss: 0.1940727
[Epoch 30; Iter   377/ 1097] train: loss: 0.0571475
[Epoch 30; Iter   407/ 1097] train: loss: 0.1255886
[Epoch 30; Iter   437/ 1097] train: loss: 0.0274372
[Epoch 30; Iter   467/ 1097] train: loss: 0.0188769
[Epoch 30; Iter   497/ 1097] train: loss: 0.1298156
[Epoch 30; Iter   527/ 1097] train: loss: 0.0499813
[Epoch 30; Iter   557/ 1097] train: loss: 0.0201433
[Epoch 30; Iter   587/ 1097] train: loss: 0.2098547
[Epoch 30; Iter   617/ 1097] train: loss: 0.1816597
[Epoch 30; Iter   647/ 1097] train: loss: 0.1361965
[Epoch 30; Iter   677/ 1097] train: loss: 0.0684969
[Epoch 30; Iter   707/ 1097] train: loss: 0.0430562
[Epoch 30; Iter   737/ 1097] train: loss: 0.0637941
[Epoch 30; Iter   767/ 1097] train: loss: 0.3091972
[Epoch 30; Iter   797/ 1097] train: loss: 0.0263805
[Epoch 30; Iter   827/ 1097] train: loss: 0.0205790
[Epoch 30; Iter   857/ 1097] train: loss: 0.2387407
[Epoch 30; Iter   887/ 1097] train: loss: 0.0618817
[Epoch 30; Iter   917/ 1097] train: loss: 0.6603006
[Epoch 30; Iter   947/ 1097] train: loss: 0.2348708
[Epoch 30; Iter   977/ 1097] train: loss: 0.0345403
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0304283
[Epoch 30; Iter  1037/ 1097] train: loss: 0.0995333
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0307240
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0389461
[Epoch 30] ogbg-molhiv: 0.812878 val loss: 0.125009
[Epoch 30] ogbg-molhiv: 0.837710 test loss: 0.111644
[Epoch 31; Iter    30/ 1097] train: loss: 0.1411295
[Epoch 31; Iter    60/ 1097] train: loss: 0.0165700
[Epoch 31; Iter    90/ 1097] train: loss: 0.0954897
[Epoch 31; Iter   120/ 1097] train: loss: 0.0180691
[Epoch 31; Iter   150/ 1097] train: loss: 0.0457797
[Epoch 31; Iter   180/ 1097] train: loss: 0.0116078
[Epoch 31; Iter   210/ 1097] train: loss: 0.0182237
[Epoch 31; Iter   240/ 1097] train: loss: 0.0267952
[Epoch 31; Iter   270/ 1097] train: loss: 0.0185132
[Epoch 31; Iter   300/ 1097] train: loss: 0.0173079
[Epoch 31; Iter   330/ 1097] train: loss: 0.0417697
[Epoch 31; Iter   360/ 1097] train: loss: 0.0781776
[Epoch 31; Iter   390/ 1097] train: loss: 0.1419843
[Epoch 31; Iter   420/ 1097] train: loss: 0.0522984
[Epoch 31; Iter   450/ 1097] train: loss: 0.1864994
[Epoch 31; Iter   480/ 1097] train: loss: 0.0176447
[Epoch 31; Iter   510/ 1097] train: loss: 0.1229126
[Epoch 31; Iter   540/ 1097] train: loss: 0.0364049
[Epoch 31; Iter   570/ 1097] train: loss: 0.0241325
[Epoch 31; Iter   600/ 1097] train: loss: 0.1569670
[Epoch 31; Iter   630/ 1097] train: loss: 0.0651007
[Epoch 31; Iter   660/ 1097] train: loss: 0.0186336
[Epoch 31; Iter   690/ 1097] train: loss: 0.0415343
[Epoch 31; Iter   720/ 1097] train: loss: 0.0296690
[Epoch 31; Iter   750/ 1097] train: loss: 0.1822540
[Epoch 31; Iter   780/ 1097] train: loss: 0.2154133
[Epoch 31; Iter   810/ 1097] train: loss: 0.1166819
[Epoch 31; Iter   840/ 1097] train: loss: 0.0199558
[Epoch 31; Iter   870/ 1097] train: loss: 0.0161223
[Epoch 31; Iter   900/ 1097] train: loss: 0.0732341
[Epoch 31; Iter   930/ 1097] train: loss: 0.0375522
[Epoch 31; Iter   960/ 1097] train: loss: 0.0204796
[Epoch 31; Iter   990/ 1097] train: loss: 0.0271426
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0830106
[Epoch 31; Iter  1050/ 1097] train: loss: 0.1504149
[Epoch 31; Iter  1080/ 1097] train: loss: 0.2062028
[Epoch 31] ogbg-molhiv: 0.817851 val loss: 0.130542
[Epoch 31] ogbg-molhiv: 0.837712 test loss: 0.119525
[Epoch 32; Iter    13/ 1097] train: loss: 0.0879593
[Epoch 32; Iter    43/ 1097] train: loss: 0.0537519
[Epoch 32; Iter    73/ 1097] train: loss: 0.0184563
[Epoch 32; Iter   103/ 1097] train: loss: 0.0111438
[Epoch 32; Iter   133/ 1097] train: loss: 0.0206386
[Epoch 32; Iter   163/ 1097] train: loss: 0.1026239
[Epoch 32; Iter   193/ 1097] train: loss: 0.1548425
[Epoch 32; Iter   223/ 1097] train: loss: 0.2097397
[Epoch 32; Iter   253/ 1097] train: loss: 0.0182367
[Epoch 32; Iter   283/ 1097] train: loss: 0.0222921
[Epoch 32; Iter   313/ 1097] train: loss: 0.0161325
[Epoch 32; Iter   343/ 1097] train: loss: 0.0196708
[Epoch 32; Iter   373/ 1097] train: loss: 0.0114738
[Epoch 32; Iter   403/ 1097] train: loss: 0.0397376
[Epoch 32; Iter   433/ 1097] train: loss: 0.0777847
[Epoch 32; Iter   463/ 1097] train: loss: 0.1649866
[Epoch 32; Iter   493/ 1097] train: loss: 0.0619214
[Epoch 32; Iter   523/ 1097] train: loss: 0.1581356
[Epoch 31; Iter   480/  823] train: loss: 0.0283648
[Epoch 31; Iter   510/  823] train: loss: 0.0220159
[Epoch 31; Iter   540/  823] train: loss: 0.1821470
[Epoch 31; Iter   570/  823] train: loss: 0.1671500
[Epoch 31; Iter   600/  823] train: loss: 0.2237497
[Epoch 31; Iter   630/  823] train: loss: 0.3803522
[Epoch 31; Iter   660/  823] train: loss: 0.0510025
[Epoch 31; Iter   690/  823] train: loss: 0.0433731
[Epoch 31; Iter   720/  823] train: loss: 0.1528396
[Epoch 31; Iter   750/  823] train: loss: 0.0935861
[Epoch 31; Iter   780/  823] train: loss: 0.0297023
[Epoch 31; Iter   810/  823] train: loss: 0.1174696
[Epoch 31] ogbg-molhiv: 0.830125 val loss: 0.162500
[Epoch 31] ogbg-molhiv: 0.801961 test loss: 0.200125
[Epoch 32; Iter    17/  823] train: loss: 0.0822216
[Epoch 32; Iter    47/  823] train: loss: 0.2141133
[Epoch 32; Iter    77/  823] train: loss: 0.0419369
[Epoch 32; Iter   107/  823] train: loss: 0.0128100
[Epoch 32; Iter   137/  823] train: loss: 0.1156965
[Epoch 32; Iter   167/  823] train: loss: 0.0300131
[Epoch 32; Iter   197/  823] train: loss: 0.2028905
[Epoch 32; Iter   227/  823] train: loss: 0.2183257
[Epoch 32; Iter   257/  823] train: loss: 0.1395917
[Epoch 32; Iter   287/  823] train: loss: 0.1256038
[Epoch 32; Iter   317/  823] train: loss: 0.0363612
[Epoch 32; Iter   347/  823] train: loss: 0.0437621
[Epoch 32; Iter   377/  823] train: loss: 0.0326916
[Epoch 32; Iter   407/  823] train: loss: 0.0295856
[Epoch 32; Iter   437/  823] train: loss: 0.0552282
[Epoch 32; Iter   467/  823] train: loss: 0.3037612
[Epoch 32; Iter   497/  823] train: loss: 0.0190726
[Epoch 32; Iter   527/  823] train: loss: 0.0532767
[Epoch 32; Iter   557/  823] train: loss: 0.0349300
[Epoch 32; Iter   587/  823] train: loss: 0.2079348
[Epoch 32; Iter   617/  823] train: loss: 0.1769625
[Epoch 32; Iter   647/  823] train: loss: 0.0437389
[Epoch 32; Iter   677/  823] train: loss: 0.0839973
[Epoch 32; Iter   707/  823] train: loss: 0.0165153
[Epoch 32; Iter   737/  823] train: loss: 0.1796500
[Epoch 32; Iter   767/  823] train: loss: 0.0264040
[Epoch 32; Iter   797/  823] train: loss: 0.0503222
[Epoch 32] ogbg-molhiv: 0.831335 val loss: 0.114166
[Epoch 32] ogbg-molhiv: 0.808875 test loss: 0.121625
[Epoch 33; Iter     4/  823] train: loss: 0.0191829
[Epoch 33; Iter    34/  823] train: loss: 0.1273511
[Epoch 33; Iter    64/  823] train: loss: 0.0297760
[Epoch 33; Iter    94/  823] train: loss: 0.2543477
[Epoch 33; Iter   124/  823] train: loss: 0.0323762
[Epoch 33; Iter   154/  823] train: loss: 0.2520285
[Epoch 33; Iter   184/  823] train: loss: 0.2981898
[Epoch 33; Iter   214/  823] train: loss: 0.2278793
[Epoch 33; Iter   244/  823] train: loss: 0.0380560
[Epoch 33; Iter   274/  823] train: loss: 0.0334381
[Epoch 33; Iter   304/  823] train: loss: 0.0316041
[Epoch 33; Iter   334/  823] train: loss: 0.0937461
[Epoch 33; Iter   364/  823] train: loss: 0.0225232
[Epoch 33; Iter   394/  823] train: loss: 0.0815779
[Epoch 33; Iter   424/  823] train: loss: 0.0152367
[Epoch 33; Iter   454/  823] train: loss: 0.2877456
[Epoch 33; Iter   484/  823] train: loss: 0.1428438
[Epoch 33; Iter   514/  823] train: loss: 0.1343785
[Epoch 33; Iter   544/  823] train: loss: 0.0299911
[Epoch 33; Iter   574/  823] train: loss: 0.0205698
[Epoch 33; Iter   604/  823] train: loss: 0.0191037
[Epoch 33; Iter   634/  823] train: loss: 0.0680128
[Epoch 33; Iter   664/  823] train: loss: 0.1649732
[Epoch 33; Iter   694/  823] train: loss: 0.0239246
[Epoch 33; Iter   724/  823] train: loss: 0.1464930
[Epoch 33; Iter   754/  823] train: loss: 0.0202810
[Epoch 33; Iter   784/  823] train: loss: 0.0350237
[Epoch 33; Iter   814/  823] train: loss: 0.0336570
[Epoch 33] ogbg-molhiv: 0.830924 val loss: 0.109620
[Epoch 33] ogbg-molhiv: 0.808422 test loss: 0.137587
[Epoch 34; Iter    21/  823] train: loss: 0.2096609
[Epoch 34; Iter    51/  823] train: loss: 0.0227929
[Epoch 34; Iter    81/  823] train: loss: 0.2126121
[Epoch 34; Iter   111/  823] train: loss: 0.0433206
[Epoch 34; Iter   141/  823] train: loss: 0.2763715
[Epoch 34; Iter   171/  823] train: loss: 0.2727832
[Epoch 34; Iter   201/  823] train: loss: 0.0222945
[Epoch 34; Iter   231/  823] train: loss: 0.0384787
[Epoch 34; Iter   261/  823] train: loss: 0.0758909
[Epoch 34; Iter   291/  823] train: loss: 0.0167026
[Epoch 34; Iter   321/  823] train: loss: 0.0993392
[Epoch 34; Iter   351/  823] train: loss: 0.0663777
[Epoch 34; Iter   381/  823] train: loss: 0.2310933
[Epoch 34; Iter   411/  823] train: loss: 0.0161264
[Epoch 34; Iter   441/  823] train: loss: 0.0820501
[Epoch 34; Iter   471/  823] train: loss: 0.0194747
[Epoch 34; Iter   501/  823] train: loss: 0.1299329
[Epoch 34; Iter   531/  823] train: loss: 0.0197868
[Epoch 34; Iter   561/  823] train: loss: 0.0239583
[Epoch 34; Iter   591/  823] train: loss: 0.0675210
[Epoch 34; Iter   621/  823] train: loss: 0.0133879
[Epoch 34; Iter   651/  823] train: loss: 0.1541681
[Epoch 34; Iter   681/  823] train: loss: 0.1756657
[Epoch 34; Iter   711/  823] train: loss: 0.0209688
[Epoch 34; Iter   741/  823] train: loss: 0.0805294
[Epoch 34; Iter   771/  823] train: loss: 0.3016449
[Epoch 34; Iter   801/  823] train: loss: 0.3549612
[Epoch 34] ogbg-molhiv: 0.838251 val loss: 0.245207
[Epoch 34] ogbg-molhiv: 0.799833 test loss: 0.257679
[Epoch 35; Iter     8/  823] train: loss: 0.0941224
[Epoch 35; Iter    38/  823] train: loss: 0.1833756
[Epoch 35; Iter    68/  823] train: loss: 0.0536508
[Epoch 35; Iter    98/  823] train: loss: 0.0999180
[Epoch 35; Iter   128/  823] train: loss: 0.1616110
[Epoch 35; Iter   158/  823] train: loss: 0.0225764
[Epoch 35; Iter   188/  823] train: loss: 0.0273098
[Epoch 35; Iter   218/  823] train: loss: 0.0234101
[Epoch 35; Iter   248/  823] train: loss: 0.0453593
[Epoch 35; Iter   278/  823] train: loss: 0.0333006
[Epoch 35; Iter   308/  823] train: loss: 0.0219418
[Epoch 35; Iter   338/  823] train: loss: 0.0222479
[Epoch 35; Iter   368/  823] train: loss: 0.0214765
[Epoch 35; Iter   398/  823] train: loss: 0.3303331
[Epoch 35; Iter   428/  823] train: loss: 0.1411371
[Epoch 35; Iter   458/  823] train: loss: 0.0209975
[Epoch 35; Iter   488/  823] train: loss: 0.1357905
[Epoch 35; Iter   518/  823] train: loss: 0.0378829
[Epoch 35; Iter   548/  823] train: loss: 0.0142903
[Epoch 35; Iter   578/  823] train: loss: 0.0282475
[Epoch 35; Iter   608/  823] train: loss: 0.0863175
[Epoch 35; Iter   638/  823] train: loss: 0.0157882
[Epoch 35; Iter   668/  823] train: loss: 0.0384924
[Epoch 35; Iter   698/  823] train: loss: 0.0997119
[Epoch 35; Iter   728/  823] train: loss: 0.0290548
[Epoch 35; Iter   758/  823] train: loss: 0.0255466
[Epoch 35; Iter   788/  823] train: loss: 0.0216630
[Epoch 35; Iter   818/  823] train: loss: 0.0272501
[Epoch 35] ogbg-molhiv: 0.830529 val loss: 0.121312
[Epoch 35] ogbg-molhiv: 0.800158 test loss: 0.271370
[Epoch 36; Iter    25/  823] train: loss: 0.0235910
[Epoch 36; Iter    55/  823] train: loss: 0.0734087
[Epoch 36; Iter    85/  823] train: loss: 0.0209146
[Epoch 36; Iter   115/  823] train: loss: 0.4084911
[Epoch 36; Iter   145/  823] train: loss: 0.1695213
[Epoch 36; Iter   175/  823] train: loss: 0.1989667
[Epoch 36; Iter   205/  823] train: loss: 0.1941414
[Epoch 36; Iter   235/  823] train: loss: 0.0238740
[Epoch 36; Iter   265/  823] train: loss: 0.0312226
[Epoch 36; Iter   295/  823] train: loss: 0.0156061
[Epoch 36; Iter   325/  823] train: loss: 0.0156852
[Epoch 36; Iter   355/  823] train: loss: 0.1896315
[Epoch 36; Iter   385/  823] train: loss: 0.1066417
[Epoch 36; Iter   415/  823] train: loss: 0.0805017
[Epoch 36; Iter   445/  823] train: loss: 0.1603657
[Epoch 36; Iter   475/  823] train: loss: 0.2309979
[Epoch 36; Iter   505/  823] train: loss: 0.0476698
[Epoch 36; Iter   535/  823] train: loss: 0.0258100
[Epoch 36; Iter   565/  823] train: loss: 0.0680466
[Epoch 36; Iter   595/  823] train: loss: 0.0201605
[Epoch 36; Iter   625/  823] train: loss: 0.0324140
[Epoch 36; Iter   655/  823] train: loss: 0.0467675
[Epoch 36; Iter   685/  823] train: loss: 0.0231007
[Epoch 36; Iter   715/  823] train: loss: 0.3621749
[Epoch 36; Iter   745/  823] train: loss: 0.1163148
[Epoch 31; Iter   480/  823] train: loss: 0.0280469
[Epoch 31; Iter   510/  823] train: loss: 0.0388115
[Epoch 31; Iter   540/  823] train: loss: 0.1002485
[Epoch 31; Iter   570/  823] train: loss: 0.1911292
[Epoch 31; Iter   600/  823] train: loss: 0.0163124
[Epoch 31; Iter   630/  823] train: loss: 0.1754546
[Epoch 31; Iter   660/  823] train: loss: 0.0216699
[Epoch 31; Iter   690/  823] train: loss: 0.2152638
[Epoch 31; Iter   720/  823] train: loss: 0.0290979
[Epoch 31; Iter   750/  823] train: loss: 0.0146479
[Epoch 31; Iter   780/  823] train: loss: 0.1282826
[Epoch 31; Iter   810/  823] train: loss: 0.0750751
[Epoch 31] ogbg-molhiv: 0.832137 val loss: 0.115170
[Epoch 31] ogbg-molhiv: 0.798928 test loss: 0.231276
[Epoch 32; Iter    17/  823] train: loss: 0.0150599
[Epoch 32; Iter    47/  823] train: loss: 0.1195495
[Epoch 32; Iter    77/  823] train: loss: 0.0334055
[Epoch 32; Iter   107/  823] train: loss: 0.3009231
[Epoch 32; Iter   137/  823] train: loss: 0.0528251
[Epoch 32; Iter   167/  823] train: loss: 0.0196134
[Epoch 32; Iter   197/  823] train: loss: 0.0189154
[Epoch 32; Iter   227/  823] train: loss: 0.1623120
[Epoch 32; Iter   257/  823] train: loss: 0.0369004
[Epoch 32; Iter   287/  823] train: loss: 0.0591253
[Epoch 32; Iter   317/  823] train: loss: 0.0153839
[Epoch 32; Iter   347/  823] train: loss: 0.0603114
[Epoch 32; Iter   377/  823] train: loss: 0.1092334
[Epoch 32; Iter   407/  823] train: loss: 0.2358089
[Epoch 32; Iter   437/  823] train: loss: 0.0334562
[Epoch 32; Iter   467/  823] train: loss: 0.2476061
[Epoch 32; Iter   497/  823] train: loss: 0.0328660
[Epoch 32; Iter   527/  823] train: loss: 0.0192841
[Epoch 32; Iter   557/  823] train: loss: 0.1658198
[Epoch 32; Iter   587/  823] train: loss: 0.0335023
[Epoch 32; Iter   617/  823] train: loss: 0.0182057
[Epoch 32; Iter   647/  823] train: loss: 0.0681233
[Epoch 32; Iter   677/  823] train: loss: 0.0383716
[Epoch 32; Iter   707/  823] train: loss: 0.0233095
[Epoch 32; Iter   737/  823] train: loss: 0.1930935
[Epoch 32; Iter   767/  823] train: loss: 0.1243237
[Epoch 32; Iter   797/  823] train: loss: 0.2102570
[Epoch 32] ogbg-molhiv: 0.837550 val loss: 0.123594
[Epoch 32] ogbg-molhiv: 0.801623 test loss: 0.140298
[Epoch 33; Iter     4/  823] train: loss: 0.1295746
[Epoch 33; Iter    34/  823] train: loss: 0.0766483
[Epoch 33; Iter    64/  823] train: loss: 0.1474078
[Epoch 33; Iter    94/  823] train: loss: 0.0169267
[Epoch 33; Iter   124/  823] train: loss: 0.2249860
[Epoch 33; Iter   154/  823] train: loss: 0.0501779
[Epoch 33; Iter   184/  823] train: loss: 0.0918863
[Epoch 33; Iter   214/  823] train: loss: 0.0240348
[Epoch 33; Iter   244/  823] train: loss: 0.0684054
[Epoch 33; Iter   274/  823] train: loss: 0.2713043
[Epoch 33; Iter   304/  823] train: loss: 0.0466713
[Epoch 33; Iter   334/  823] train: loss: 0.1018347
[Epoch 33; Iter   364/  823] train: loss: 0.0777327
[Epoch 33; Iter   394/  823] train: loss: 0.0307860
[Epoch 33; Iter   424/  823] train: loss: 0.0234726
[Epoch 33; Iter   454/  823] train: loss: 0.0318185
[Epoch 33; Iter   484/  823] train: loss: 0.0376320
[Epoch 33; Iter   514/  823] train: loss: 0.0315126
[Epoch 33; Iter   544/  823] train: loss: 0.0180909
[Epoch 33; Iter   574/  823] train: loss: 0.0186924
[Epoch 33; Iter   604/  823] train: loss: 0.0884975
[Epoch 33; Iter   634/  823] train: loss: 0.1139527
[Epoch 33; Iter   664/  823] train: loss: 0.0233659
[Epoch 33; Iter   694/  823] train: loss: 0.0143609
[Epoch 33; Iter   724/  823] train: loss: 0.1513302
[Epoch 33; Iter   754/  823] train: loss: 0.0114466
[Epoch 33; Iter   784/  823] train: loss: 0.0147157
[Epoch 33; Iter   814/  823] train: loss: 0.1362808
[Epoch 33] ogbg-molhiv: 0.838701 val loss: 0.154960
[Epoch 33] ogbg-molhiv: 0.801164 test loss: 0.234419
[Epoch 34; Iter    21/  823] train: loss: 0.0149928
[Epoch 34; Iter    51/  823] train: loss: 0.0165283
[Epoch 34; Iter    81/  823] train: loss: 0.0293719
[Epoch 34; Iter   111/  823] train: loss: 0.2756553
[Epoch 34; Iter   141/  823] train: loss: 0.1947061
[Epoch 34; Iter   171/  823] train: loss: 0.0211027
[Epoch 34; Iter   201/  823] train: loss: 0.1775339
[Epoch 34; Iter   231/  823] train: loss: 0.2265216
[Epoch 34; Iter   261/  823] train: loss: 0.0776257
[Epoch 34; Iter   291/  823] train: loss: 0.0261171
[Epoch 34; Iter   321/  823] train: loss: 0.0769510
[Epoch 34; Iter   351/  823] train: loss: 0.0228738
[Epoch 34; Iter   381/  823] train: loss: 0.1394873
[Epoch 34; Iter   411/  823] train: loss: 0.0749545
[Epoch 34; Iter   441/  823] train: loss: 0.0712377
[Epoch 34; Iter   471/  823] train: loss: 0.0197985
[Epoch 34; Iter   501/  823] train: loss: 0.0277312
[Epoch 34; Iter   531/  823] train: loss: 0.2973934
[Epoch 34; Iter   561/  823] train: loss: 0.0599860
[Epoch 34; Iter   591/  823] train: loss: 0.1061429
[Epoch 34; Iter   621/  823] train: loss: 0.2091542
[Epoch 34; Iter   651/  823] train: loss: 0.0659803
[Epoch 34; Iter   681/  823] train: loss: 0.0540564
[Epoch 34; Iter   711/  823] train: loss: 0.0305269
[Epoch 34; Iter   741/  823] train: loss: 0.0327050
[Epoch 34; Iter   771/  823] train: loss: 0.0335269
[Epoch 34; Iter   801/  823] train: loss: 0.1358093
[Epoch 34] ogbg-molhiv: 0.835355 val loss: 1.337788
[Epoch 34] ogbg-molhiv: 0.799407 test loss: 1.226409
[Epoch 35; Iter     8/  823] train: loss: 0.0287557
[Epoch 35; Iter    38/  823] train: loss: 0.0511304
[Epoch 35; Iter    68/  823] train: loss: 0.0607198
[Epoch 35; Iter    98/  823] train: loss: 0.0566888
[Epoch 35; Iter   128/  823] train: loss: 0.0184843
[Epoch 35; Iter   158/  823] train: loss: 0.0225956
[Epoch 35; Iter   188/  823] train: loss: 0.1236150
[Epoch 35; Iter   218/  823] train: loss: 0.0926692
[Epoch 35; Iter   248/  823] train: loss: 0.0316116
[Epoch 35; Iter   278/  823] train: loss: 0.2197593
[Epoch 35; Iter   308/  823] train: loss: 0.2179310
[Epoch 35; Iter   338/  823] train: loss: 0.1581779
[Epoch 35; Iter   368/  823] train: loss: 0.0642724
[Epoch 35; Iter   398/  823] train: loss: 0.1929926
[Epoch 35; Iter   428/  823] train: loss: 0.0626489
[Epoch 35; Iter   458/  823] train: loss: 0.2460221
[Epoch 35; Iter   488/  823] train: loss: 0.2237566
[Epoch 35; Iter   518/  823] train: loss: 0.1103979
[Epoch 35; Iter   548/  823] train: loss: 0.2075416
[Epoch 35; Iter   578/  823] train: loss: 0.0168424
[Epoch 35; Iter   608/  823] train: loss: 0.0985221
[Epoch 35; Iter   638/  823] train: loss: 0.0768973
[Epoch 35; Iter   668/  823] train: loss: 0.1196107
[Epoch 35; Iter   698/  823] train: loss: 0.0731960
[Epoch 35; Iter   728/  823] train: loss: 0.0155136
[Epoch 35; Iter   758/  823] train: loss: 0.0161832
[Epoch 35; Iter   788/  823] train: loss: 0.0723035
[Epoch 35; Iter   818/  823] train: loss: 0.1272515
[Epoch 35] ogbg-molhiv: 0.833937 val loss: 0.113754
[Epoch 35] ogbg-molhiv: 0.803267 test loss: 0.150336
[Epoch 36; Iter    25/  823] train: loss: 0.0931309
[Epoch 36; Iter    55/  823] train: loss: 0.0239664
[Epoch 36; Iter    85/  823] train: loss: 0.0311909
[Epoch 36; Iter   115/  823] train: loss: 0.0659135
[Epoch 36; Iter   145/  823] train: loss: 0.0587151
[Epoch 36; Iter   175/  823] train: loss: 0.0312111
[Epoch 36; Iter   205/  823] train: loss: 0.1866714
[Epoch 36; Iter   235/  823] train: loss: 0.0335095
[Epoch 36; Iter   265/  823] train: loss: 0.0238467
[Epoch 36; Iter   295/  823] train: loss: 0.1006803
[Epoch 36; Iter   325/  823] train: loss: 0.0352612
[Epoch 36; Iter   355/  823] train: loss: 0.0924603
[Epoch 36; Iter   385/  823] train: loss: 0.0879044
[Epoch 36; Iter   415/  823] train: loss: 0.0280425
[Epoch 36; Iter   445/  823] train: loss: 0.0311855
[Epoch 36; Iter   475/  823] train: loss: 0.1061441
[Epoch 36; Iter   505/  823] train: loss: 0.0504223
[Epoch 36; Iter   535/  823] train: loss: 0.1963212
[Epoch 36; Iter   565/  823] train: loss: 0.0158189
[Epoch 36; Iter   595/  823] train: loss: 0.0933269
[Epoch 36; Iter   625/  823] train: loss: 0.0130904
[Epoch 36; Iter   655/  823] train: loss: 0.0132861
[Epoch 36; Iter   685/  823] train: loss: 0.0558575
[Epoch 36; Iter   715/  823] train: loss: 0.0644677
[Epoch 36; Iter   745/  823] train: loss: 0.0177309
[Epoch 31; Iter   480/  823] train: loss: 0.0570994
[Epoch 31; Iter   510/  823] train: loss: 0.2124908
[Epoch 31; Iter   540/  823] train: loss: 0.0292224
[Epoch 31; Iter   570/  823] train: loss: 0.0189461
[Epoch 31; Iter   600/  823] train: loss: 0.0377895
[Epoch 31; Iter   630/  823] train: loss: 0.0456456
[Epoch 31; Iter   660/  823] train: loss: 0.0691347
[Epoch 31; Iter   690/  823] train: loss: 0.1055143
[Epoch 31; Iter   720/  823] train: loss: 0.0169516
[Epoch 31; Iter   750/  823] train: loss: 0.0194659
[Epoch 31; Iter   780/  823] train: loss: 0.0891420
[Epoch 31; Iter   810/  823] train: loss: 0.0161084
[Epoch 31] ogbg-molhiv: 0.822032 val loss: 0.158619
[Epoch 31] ogbg-molhiv: 0.796080 test loss: 0.124080
[Epoch 32; Iter    17/  823] train: loss: 0.0262611
[Epoch 32; Iter    47/  823] train: loss: 0.0189148
[Epoch 32; Iter    77/  823] train: loss: 0.1806751
[Epoch 32; Iter   107/  823] train: loss: 0.0452877
[Epoch 32; Iter   137/  823] train: loss: 0.0290035
[Epoch 32; Iter   167/  823] train: loss: 0.0184702
[Epoch 32; Iter   197/  823] train: loss: 0.0269015
[Epoch 32; Iter   227/  823] train: loss: 0.1095657
[Epoch 32; Iter   257/  823] train: loss: 0.0528059
[Epoch 32; Iter   287/  823] train: loss: 0.1465412
[Epoch 32; Iter   317/  823] train: loss: 0.0345737
[Epoch 32; Iter   347/  823] train: loss: 0.0132410
[Epoch 32; Iter   377/  823] train: loss: 0.1115287
[Epoch 32; Iter   407/  823] train: loss: 0.0264229
[Epoch 32; Iter   437/  823] train: loss: 0.0465588
[Epoch 32; Iter   467/  823] train: loss: 0.1166386
[Epoch 32; Iter   497/  823] train: loss: 0.1499038
[Epoch 32; Iter   527/  823] train: loss: 0.0750695
[Epoch 32; Iter   557/  823] train: loss: 0.0274467
[Epoch 32; Iter   587/  823] train: loss: 0.0131128
[Epoch 32; Iter   617/  823] train: loss: 0.0144857
[Epoch 32; Iter   647/  823] train: loss: 0.0243629
[Epoch 32; Iter   677/  823] train: loss: 0.0476845
[Epoch 32; Iter   707/  823] train: loss: 0.0565185
[Epoch 32; Iter   737/  823] train: loss: 0.0389040
[Epoch 32; Iter   767/  823] train: loss: 0.1311589
[Epoch 32; Iter   797/  823] train: loss: 0.0900690
[Epoch 32] ogbg-molhiv: 0.835441 val loss: 0.122161
[Epoch 32] ogbg-molhiv: 0.806328 test loss: 0.135605
[Epoch 33; Iter     4/  823] train: loss: 0.0177168
[Epoch 33; Iter    34/  823] train: loss: 0.1771747
[Epoch 33; Iter    64/  823] train: loss: 0.0521055
[Epoch 33; Iter    94/  823] train: loss: 0.0158517
[Epoch 33; Iter   124/  823] train: loss: 0.0213360
[Epoch 33; Iter   154/  823] train: loss: 0.0139490
[Epoch 33; Iter   184/  823] train: loss: 0.0513050
[Epoch 33; Iter   214/  823] train: loss: 0.1711543
[Epoch 33; Iter   244/  823] train: loss: 0.0261279
[Epoch 33; Iter   274/  823] train: loss: 0.0154622
[Epoch 33; Iter   304/  823] train: loss: 0.0141080
[Epoch 33; Iter   334/  823] train: loss: 0.0211798
[Epoch 33; Iter   364/  823] train: loss: 0.0128499
[Epoch 33; Iter   394/  823] train: loss: 0.0334740
[Epoch 33; Iter   424/  823] train: loss: 0.0690205
[Epoch 33; Iter   454/  823] train: loss: 0.0123645
[Epoch 33; Iter   484/  823] train: loss: 0.1335853
[Epoch 33; Iter   514/  823] train: loss: 0.2093826
[Epoch 33; Iter   544/  823] train: loss: 0.0653907
[Epoch 33; Iter   574/  823] train: loss: 0.0390935
[Epoch 33; Iter   604/  823] train: loss: 0.3568197
[Epoch 33; Iter   634/  823] train: loss: 0.0218352
[Epoch 33; Iter   664/  823] train: loss: 0.0193153
[Epoch 33; Iter   694/  823] train: loss: 0.0709172
[Epoch 33; Iter   724/  823] train: loss: 0.1022546
[Epoch 33; Iter   754/  823] train: loss: 0.0942762
[Epoch 33; Iter   784/  823] train: loss: 0.0287941
[Epoch 33; Iter   814/  823] train: loss: 0.2951550
[Epoch 33] ogbg-molhiv: 0.829187 val loss: 0.118961
[Epoch 33] ogbg-molhiv: 0.795100 test loss: 0.128533
[Epoch 34; Iter    21/  823] train: loss: 0.0283317
[Epoch 34; Iter    51/  823] train: loss: 0.0204735
[Epoch 34; Iter    81/  823] train: loss: 0.0350147
[Epoch 34; Iter   111/  823] train: loss: 0.0219086
[Epoch 34; Iter   141/  823] train: loss: 0.0225494
[Epoch 34; Iter   171/  823] train: loss: 0.1792959
[Epoch 34; Iter   201/  823] train: loss: 0.1000007
[Epoch 34; Iter   231/  823] train: loss: 0.0159368
[Epoch 34; Iter   261/  823] train: loss: 0.0167804
[Epoch 34; Iter   291/  823] train: loss: 0.0976892
[Epoch 34; Iter   321/  823] train: loss: 0.0217413
[Epoch 34; Iter   351/  823] train: loss: 0.0125208
[Epoch 34; Iter   381/  823] train: loss: 0.1262822
[Epoch 34; Iter   411/  823] train: loss: 0.1813515
[Epoch 34; Iter   441/  823] train: loss: 0.0595956
[Epoch 34; Iter   471/  823] train: loss: 0.0382163
[Epoch 34; Iter   501/  823] train: loss: 0.0712607
[Epoch 34; Iter   531/  823] train: loss: 0.0845052
[Epoch 34; Iter   561/  823] train: loss: 0.1119842
[Epoch 34; Iter   591/  823] train: loss: 0.1003660
[Epoch 34; Iter   621/  823] train: loss: 0.1829744
[Epoch 34; Iter   651/  823] train: loss: 0.0098728
[Epoch 34; Iter   681/  823] train: loss: 0.0228925
[Epoch 34; Iter   711/  823] train: loss: 0.1337423
[Epoch 34; Iter   741/  823] train: loss: 0.0303929
[Epoch 34; Iter   771/  823] train: loss: 0.0365025
[Epoch 34; Iter   801/  823] train: loss: 0.0437437
[Epoch 34] ogbg-molhiv: 0.830134 val loss: 0.113801
[Epoch 34] ogbg-molhiv: 0.795068 test loss: 0.125021
[Epoch 35; Iter     8/  823] train: loss: 0.0237233
[Epoch 35; Iter    38/  823] train: loss: 0.0579783
[Epoch 35; Iter    68/  823] train: loss: 0.0236286
[Epoch 35; Iter    98/  823] train: loss: 0.0318854
[Epoch 35; Iter   128/  823] train: loss: 0.0809960
[Epoch 35; Iter   158/  823] train: loss: 0.0846050
[Epoch 35; Iter   188/  823] train: loss: 0.0422472
[Epoch 35; Iter   218/  823] train: loss: 0.0224140
[Epoch 35; Iter   248/  823] train: loss: 0.1340180
[Epoch 35; Iter   278/  823] train: loss: 0.1253273
[Epoch 35; Iter   308/  823] train: loss: 0.1011183
[Epoch 35; Iter   338/  823] train: loss: 0.0887459
[Epoch 35; Iter   368/  823] train: loss: 0.0184446
[Epoch 35; Iter   398/  823] train: loss: 0.1329982
[Epoch 35; Iter   428/  823] train: loss: 0.2904461
[Epoch 35; Iter   458/  823] train: loss: 0.1381718
[Epoch 35; Iter   488/  823] train: loss: 0.0284369
[Epoch 35; Iter   518/  823] train: loss: 0.0357340
[Epoch 35; Iter   548/  823] train: loss: 0.1523422
[Epoch 35; Iter   578/  823] train: loss: 0.0373029
[Epoch 35; Iter   608/  823] train: loss: 0.0351144
[Epoch 35; Iter   638/  823] train: loss: 0.0441969
[Epoch 35; Iter   668/  823] train: loss: 0.1063516
[Epoch 35; Iter   698/  823] train: loss: 0.0129191
[Epoch 35; Iter   728/  823] train: loss: 0.0325028
[Epoch 35; Iter   758/  823] train: loss: 0.2115173
[Epoch 35; Iter   788/  823] train: loss: 0.2725354
[Epoch 35; Iter   818/  823] train: loss: 0.0137841
[Epoch 35] ogbg-molhiv: 0.825964 val loss: 0.135637
[Epoch 35] ogbg-molhiv: 0.789765 test loss: 0.146007
[Epoch 36; Iter    25/  823] train: loss: 0.1676285
[Epoch 36; Iter    55/  823] train: loss: 0.0594227
[Epoch 36; Iter    85/  823] train: loss: 0.0180467
[Epoch 36; Iter   115/  823] train: loss: 0.0144137
[Epoch 36; Iter   145/  823] train: loss: 0.0276772
[Epoch 36; Iter   175/  823] train: loss: 0.0102345
[Epoch 36; Iter   205/  823] train: loss: 0.0202767
[Epoch 36; Iter   235/  823] train: loss: 0.0233337
[Epoch 36; Iter   265/  823] train: loss: 0.1674848
[Epoch 36; Iter   295/  823] train: loss: 0.4161547
[Epoch 36; Iter   325/  823] train: loss: 0.0228600
[Epoch 36; Iter   355/  823] train: loss: 0.0148730
[Epoch 36; Iter   385/  823] train: loss: 0.0109219
[Epoch 36; Iter   415/  823] train: loss: 0.0484109
[Epoch 36; Iter   445/  823] train: loss: 0.0156304
[Epoch 36; Iter   475/  823] train: loss: 0.0110082
[Epoch 36; Iter   505/  823] train: loss: 0.0668681
[Epoch 36; Iter   535/  823] train: loss: 0.1192024
[Epoch 36; Iter   565/  823] train: loss: 0.1153430
[Epoch 36; Iter   595/  823] train: loss: 0.1117950
[Epoch 36; Iter   625/  823] train: loss: 0.0328455
[Epoch 36; Iter   655/  823] train: loss: 0.0915284
[Epoch 36; Iter   685/  823] train: loss: 0.0897179
[Epoch 36; Iter   715/  823] train: loss: 0.1590421
[Epoch 36; Iter   745/  823] train: loss: 0.1129565
[Epoch 32; Iter    90/  960] train: loss: 0.0114188
[Epoch 32; Iter   120/  960] train: loss: 0.0170155
[Epoch 32; Iter   150/  960] train: loss: 0.1482191
[Epoch 32; Iter   180/  960] train: loss: 0.0198549
[Epoch 32; Iter   210/  960] train: loss: 0.0745475
[Epoch 32; Iter   240/  960] train: loss: 0.0577465
[Epoch 32; Iter   270/  960] train: loss: 0.0382732
[Epoch 32; Iter   300/  960] train: loss: 0.0956381
[Epoch 32; Iter   330/  960] train: loss: 0.0344097
[Epoch 32; Iter   360/  960] train: loss: 0.0178379
[Epoch 32; Iter   390/  960] train: loss: 0.2640142
[Epoch 32; Iter   420/  960] train: loss: 0.1377262
[Epoch 32; Iter   450/  960] train: loss: 0.0357028
[Epoch 32; Iter   480/  960] train: loss: 0.0226001
[Epoch 32; Iter   510/  960] train: loss: 0.2140813
[Epoch 32; Iter   540/  960] train: loss: 0.0834989
[Epoch 32; Iter   570/  960] train: loss: 0.2044843
[Epoch 32; Iter   600/  960] train: loss: 0.0223688
[Epoch 32; Iter   630/  960] train: loss: 0.1558869
[Epoch 32; Iter   660/  960] train: loss: 0.2241067
[Epoch 32; Iter   690/  960] train: loss: 0.4465505
[Epoch 32; Iter   720/  960] train: loss: 0.0959747
[Epoch 32; Iter   750/  960] train: loss: 0.0185296
[Epoch 32; Iter   780/  960] train: loss: 0.1627765
[Epoch 32; Iter   810/  960] train: loss: 0.0357855
[Epoch 32; Iter   840/  960] train: loss: 0.0173678
[Epoch 32; Iter   870/  960] train: loss: 0.0299807
[Epoch 32; Iter   900/  960] train: loss: 0.0343577
[Epoch 32; Iter   930/  960] train: loss: 0.1798517
[Epoch 32; Iter   960/  960] train: loss: 0.4053748
[Epoch 32] ogbg-molhiv: 0.817840 val loss: 0.326447
[Epoch 32] ogbg-molhiv: 0.818353 test loss: 0.213870
[Epoch 33; Iter    30/  960] train: loss: 0.0198170
[Epoch 33; Iter    60/  960] train: loss: 0.0572360
[Epoch 33; Iter    90/  960] train: loss: 0.0214975
[Epoch 33; Iter   120/  960] train: loss: 0.0235482
[Epoch 33; Iter   150/  960] train: loss: 0.0457637
[Epoch 33; Iter   180/  960] train: loss: 0.1161545
[Epoch 33; Iter   210/  960] train: loss: 0.1482614
[Epoch 33; Iter   240/  960] train: loss: 0.0949874
[Epoch 33; Iter   270/  960] train: loss: 0.0218859
[Epoch 33; Iter   300/  960] train: loss: 0.1054408
[Epoch 33; Iter   330/  960] train: loss: 0.0186259
[Epoch 33; Iter   360/  960] train: loss: 0.0319299
[Epoch 33; Iter   390/  960] train: loss: 0.1035175
[Epoch 33; Iter   420/  960] train: loss: 0.0786854
[Epoch 33; Iter   450/  960] train: loss: 0.0098178
[Epoch 33; Iter   480/  960] train: loss: 0.0136310
[Epoch 33; Iter   510/  960] train: loss: 0.0156925
[Epoch 33; Iter   540/  960] train: loss: 0.0234876
[Epoch 33; Iter   570/  960] train: loss: 0.0599471
[Epoch 33; Iter   600/  960] train: loss: 0.0225117
[Epoch 33; Iter   630/  960] train: loss: 0.0554635
[Epoch 33; Iter   660/  960] train: loss: 0.1208148
[Epoch 33; Iter   690/  960] train: loss: 0.0326508
[Epoch 33; Iter   720/  960] train: loss: 0.0186885
[Epoch 33; Iter   750/  960] train: loss: 0.0490725
[Epoch 33; Iter   780/  960] train: loss: 0.0549508
[Epoch 33; Iter   810/  960] train: loss: 0.2521485
[Epoch 33; Iter   840/  960] train: loss: 0.0167298
[Epoch 33; Iter   870/  960] train: loss: 0.0118980
[Epoch 33; Iter   900/  960] train: loss: 0.0258704
[Epoch 33; Iter   930/  960] train: loss: 0.0121736
[Epoch 33; Iter   960/  960] train: loss: 0.1887950
[Epoch 33] ogbg-molhiv: 0.821714 val loss: 0.203090
[Epoch 33] ogbg-molhiv: 0.821182 test loss: 0.130247
[Epoch 34; Iter    30/  960] train: loss: 0.1178777
[Epoch 34; Iter    60/  960] train: loss: 0.0855472
[Epoch 34; Iter    90/  960] train: loss: 0.0173926
[Epoch 34; Iter   120/  960] train: loss: 0.0153960
[Epoch 34; Iter   150/  960] train: loss: 0.0785468
[Epoch 34; Iter   180/  960] train: loss: 0.0449121
[Epoch 34; Iter   210/  960] train: loss: 0.2281819
[Epoch 34; Iter   240/  960] train: loss: 0.2223975
[Epoch 34; Iter   270/  960] train: loss: 0.2569811
[Epoch 34; Iter   300/  960] train: loss: 0.0242492
[Epoch 34; Iter   330/  960] train: loss: 0.1037859
[Epoch 34; Iter   360/  960] train: loss: 0.0447233
[Epoch 34; Iter   390/  960] train: loss: 0.0348879
[Epoch 34; Iter   420/  960] train: loss: 0.0152417
[Epoch 34; Iter   450/  960] train: loss: 0.0141604
[Epoch 34; Iter   480/  960] train: loss: 0.0213401
[Epoch 34; Iter   510/  960] train: loss: 0.0149037
[Epoch 34; Iter   540/  960] train: loss: 0.0143106
[Epoch 34; Iter   570/  960] train: loss: 0.0269575
[Epoch 34; Iter   600/  960] train: loss: 0.2220936
[Epoch 34; Iter   630/  960] train: loss: 0.2032949
[Epoch 34; Iter   660/  960] train: loss: 0.0306526
[Epoch 34; Iter   690/  960] train: loss: 0.1476802
[Epoch 34; Iter   720/  960] train: loss: 0.2988622
[Epoch 34; Iter   750/  960] train: loss: 0.0296890
[Epoch 34; Iter   780/  960] train: loss: 0.0190101
[Epoch 34; Iter   810/  960] train: loss: 0.0714743
[Epoch 34; Iter   840/  960] train: loss: 0.0386268
[Epoch 34; Iter   870/  960] train: loss: 0.0166191
[Epoch 34; Iter   900/  960] train: loss: 0.0540181
[Epoch 34; Iter   930/  960] train: loss: 0.0112731
[Epoch 34; Iter   960/  960] train: loss: 0.0736305
[Epoch 34] ogbg-molhiv: 0.822241 val loss: 0.185470
[Epoch 34] ogbg-molhiv: 0.817123 test loss: 0.121442
[Epoch 35; Iter    30/  960] train: loss: 0.0340028
[Epoch 35; Iter    60/  960] train: loss: 0.3509342
[Epoch 35; Iter    90/  960] train: loss: 0.0325383
[Epoch 35; Iter   120/  960] train: loss: 0.0537407
[Epoch 35; Iter   150/  960] train: loss: 0.0154245
[Epoch 35; Iter   180/  960] train: loss: 0.0340640
[Epoch 35; Iter   210/  960] train: loss: 0.0127893
[Epoch 35; Iter   240/  960] train: loss: 0.0172383
[Epoch 35; Iter   270/  960] train: loss: 0.0654492
[Epoch 35; Iter   300/  960] train: loss: 0.0709704
[Epoch 35; Iter   330/  960] train: loss: 0.0337351
[Epoch 35; Iter   360/  960] train: loss: 0.0266791
[Epoch 35; Iter   390/  960] train: loss: 0.0307359
[Epoch 35; Iter   420/  960] train: loss: 0.2924500
[Epoch 35; Iter   450/  960] train: loss: 0.1606019
[Epoch 35; Iter   480/  960] train: loss: 0.0771132
[Epoch 35; Iter   510/  960] train: loss: 0.0987324
[Epoch 35; Iter   540/  960] train: loss: 0.0278716
[Epoch 35; Iter   570/  960] train: loss: 0.0304293
[Epoch 35; Iter   600/  960] train: loss: 0.0844533
[Epoch 35; Iter   630/  960] train: loss: 0.0174137
[Epoch 35; Iter   660/  960] train: loss: 0.0232826
[Epoch 35; Iter   690/  960] train: loss: 0.1255570
[Epoch 35; Iter   720/  960] train: loss: 0.0340851
[Epoch 35; Iter   750/  960] train: loss: 0.0568751
[Epoch 35; Iter   780/  960] train: loss: 0.0289846
[Epoch 35; Iter   810/  960] train: loss: 0.4389886
[Epoch 35; Iter   840/  960] train: loss: 0.0104396
[Epoch 35; Iter   870/  960] train: loss: 0.1533008
[Epoch 35; Iter   900/  960] train: loss: 0.0181585
[Epoch 35; Iter   930/  960] train: loss: 0.0192909
[Epoch 35; Iter   960/  960] train: loss: 0.1836247
[Epoch 35] ogbg-molhiv: 0.826484 val loss: 0.174993
[Epoch 35] ogbg-molhiv: 0.820889 test loss: 0.124207
[Epoch 36; Iter    30/  960] train: loss: 0.0147500
[Epoch 36; Iter    60/  960] train: loss: 0.0370210
[Epoch 36; Iter    90/  960] train: loss: 0.2260369
[Epoch 36; Iter   120/  960] train: loss: 0.0441931
[Epoch 36; Iter   150/  960] train: loss: 0.1213530
[Epoch 36; Iter   180/  960] train: loss: 0.0107808
[Epoch 36; Iter   210/  960] train: loss: 0.1206543
[Epoch 36; Iter   240/  960] train: loss: 0.0442513
[Epoch 36; Iter   270/  960] train: loss: 0.0098215
[Epoch 36; Iter   300/  960] train: loss: 0.2024894
[Epoch 36; Iter   330/  960] train: loss: 0.0260971
[Epoch 36; Iter   360/  960] train: loss: 0.3496142
[Epoch 36; Iter   390/  960] train: loss: 0.1531490
[Epoch 36; Iter   420/  960] train: loss: 0.2155582
[Epoch 36; Iter   450/  960] train: loss: 0.4341356
[Epoch 36; Iter   480/  960] train: loss: 0.1259905
[Epoch 36; Iter   510/  960] train: loss: 0.0089636
[Epoch 36; Iter   540/  960] train: loss: 0.0223989
[Epoch 36; Iter   570/  960] train: loss: 0.0137478
[Epoch 36; Iter   600/  960] train: loss: 0.0636704
[Epoch 36; Iter   630/  960] train: loss: 0.0217601
[Epoch 36; Iter   660/  960] train: loss: 0.1214367
[Epoch 36; Iter   690/  960] train: loss: 0.2326767
[Epoch 32; Iter    90/  960] train: loss: 0.0639771
[Epoch 32; Iter   120/  960] train: loss: 0.0852005
[Epoch 32; Iter   150/  960] train: loss: 0.1145575
[Epoch 32; Iter   180/  960] train: loss: 0.1897446
[Epoch 32; Iter   210/  960] train: loss: 0.0788300
[Epoch 32; Iter   240/  960] train: loss: 0.0240925
[Epoch 32; Iter   270/  960] train: loss: 0.1361960
[Epoch 32; Iter   300/  960] train: loss: 0.0108999
[Epoch 32; Iter   330/  960] train: loss: 0.0203768
[Epoch 32; Iter   360/  960] train: loss: 0.0644663
[Epoch 32; Iter   390/  960] train: loss: 0.0962634
[Epoch 32; Iter   420/  960] train: loss: 0.2456705
[Epoch 32; Iter   450/  960] train: loss: 0.0278573
[Epoch 32; Iter   480/  960] train: loss: 0.0759582
[Epoch 32; Iter   510/  960] train: loss: 0.0432263
[Epoch 32; Iter   540/  960] train: loss: 0.0310044
[Epoch 32; Iter   570/  960] train: loss: 0.0148527
[Epoch 32; Iter   600/  960] train: loss: 0.3720205
[Epoch 32; Iter   630/  960] train: loss: 0.0627569
[Epoch 32; Iter   660/  960] train: loss: 0.1979258
[Epoch 32; Iter   690/  960] train: loss: 0.0119812
[Epoch 32; Iter   720/  960] train: loss: 0.0201413
[Epoch 32; Iter   750/  960] train: loss: 0.0675975
[Epoch 32; Iter   780/  960] train: loss: 0.1654223
[Epoch 32; Iter   810/  960] train: loss: 0.0855489
[Epoch 32; Iter   840/  960] train: loss: 0.0312725
[Epoch 32; Iter   870/  960] train: loss: 0.1373371
[Epoch 32; Iter   900/  960] train: loss: 0.0488552
[Epoch 32; Iter   930/  960] train: loss: 0.2834983
[Epoch 32; Iter   960/  960] train: loss: 0.0386063
[Epoch 32] ogbg-molhiv: 0.801543 val loss: 0.131551
[Epoch 32] ogbg-molhiv: 0.825584 test loss: 0.120028
[Epoch 33; Iter    30/  960] train: loss: 0.0086548
[Epoch 33; Iter    60/  960] train: loss: 0.1137407
[Epoch 33; Iter    90/  960] train: loss: 0.0371123
[Epoch 33; Iter   120/  960] train: loss: 0.0508011
[Epoch 33; Iter   150/  960] train: loss: 0.0453242
[Epoch 33; Iter   180/  960] train: loss: 0.0170414
[Epoch 33; Iter   210/  960] train: loss: 0.0940430
[Epoch 33; Iter   240/  960] train: loss: 0.0190468
[Epoch 33; Iter   270/  960] train: loss: 0.1324564
[Epoch 33; Iter   300/  960] train: loss: 0.0568553
[Epoch 33; Iter   330/  960] train: loss: 0.2066652
[Epoch 33; Iter   360/  960] train: loss: 0.2749518
[Epoch 33; Iter   390/  960] train: loss: 0.0365696
[Epoch 33; Iter   420/  960] train: loss: 0.2615043
[Epoch 33; Iter   450/  960] train: loss: 0.0243563
[Epoch 33; Iter   480/  960] train: loss: 0.3751312
[Epoch 33; Iter   510/  960] train: loss: 0.0191554
[Epoch 33; Iter   540/  960] train: loss: 0.2600916
[Epoch 33; Iter   570/  960] train: loss: 0.2596649
[Epoch 33; Iter   600/  960] train: loss: 0.1374249
[Epoch 33; Iter   630/  960] train: loss: 0.1314577
[Epoch 33; Iter   660/  960] train: loss: 0.0147984
[Epoch 33; Iter   690/  960] train: loss: 0.0142366
[Epoch 33; Iter   720/  960] train: loss: 0.2385714
[Epoch 33; Iter   750/  960] train: loss: 0.0169228
[Epoch 33; Iter   780/  960] train: loss: 0.1283888
[Epoch 33; Iter   810/  960] train: loss: 0.0161760
[Epoch 33; Iter   840/  960] train: loss: 0.2757335
[Epoch 33; Iter   870/  960] train: loss: 0.1770316
[Epoch 33; Iter   900/  960] train: loss: 0.1713578
[Epoch 33; Iter   930/  960] train: loss: 0.0276274
[Epoch 33; Iter   960/  960] train: loss: 0.2004760
[Epoch 33] ogbg-molhiv: 0.800809 val loss: 0.130331
[Epoch 33] ogbg-molhiv: 0.814048 test loss: 0.119766
[Epoch 34; Iter    30/  960] train: loss: 0.0580246
[Epoch 34; Iter    60/  960] train: loss: 0.0284981
[Epoch 34; Iter    90/  960] train: loss: 0.1814390
[Epoch 34; Iter   120/  960] train: loss: 0.0195922
[Epoch 34; Iter   150/  960] train: loss: 0.0135474
[Epoch 34; Iter   180/  960] train: loss: 0.0449455
[Epoch 34; Iter   210/  960] train: loss: 0.0204924
[Epoch 34; Iter   240/  960] train: loss: 0.0544379
[Epoch 34; Iter   270/  960] train: loss: 0.0386997
[Epoch 34; Iter   300/  960] train: loss: 0.1148146
[Epoch 34; Iter   330/  960] train: loss: 0.0379073
[Epoch 34; Iter   360/  960] train: loss: 0.0302529
[Epoch 34; Iter   390/  960] train: loss: 0.0625630
[Epoch 34; Iter   420/  960] train: loss: 0.1458354
[Epoch 34; Iter   450/  960] train: loss: 0.0648755
[Epoch 34; Iter   480/  960] train: loss: 0.2596723
[Epoch 34; Iter   510/  960] train: loss: 0.1035032
[Epoch 34; Iter   540/  960] train: loss: 0.0290757
[Epoch 34; Iter   570/  960] train: loss: 0.3081986
[Epoch 34; Iter   600/  960] train: loss: 0.2687016
[Epoch 34; Iter   630/  960] train: loss: 0.0354225
[Epoch 34; Iter   660/  960] train: loss: 0.0926462
[Epoch 34; Iter   690/  960] train: loss: 0.0159966
[Epoch 34; Iter   720/  960] train: loss: 0.1565845
[Epoch 34; Iter   750/  960] train: loss: 0.0356861
[Epoch 34; Iter   780/  960] train: loss: 0.0323220
[Epoch 34; Iter   810/  960] train: loss: 0.0493613
[Epoch 34; Iter   840/  960] train: loss: 0.0658854
[Epoch 34; Iter   870/  960] train: loss: 0.1087108
[Epoch 34; Iter   900/  960] train: loss: 0.0690530
[Epoch 34; Iter   930/  960] train: loss: 0.0198131
[Epoch 34; Iter   960/  960] train: loss: 0.0469174
[Epoch 34] ogbg-molhiv: 0.806219 val loss: 0.129903
[Epoch 34] ogbg-molhiv: 0.827011 test loss: 0.117660
[Epoch 35; Iter    30/  960] train: loss: 0.0401449
[Epoch 35; Iter    60/  960] train: loss: 0.0353458
[Epoch 35; Iter    90/  960] train: loss: 0.0681195
[Epoch 35; Iter   120/  960] train: loss: 0.0875538
[Epoch 35; Iter   150/  960] train: loss: 0.2059091
[Epoch 35; Iter   180/  960] train: loss: 0.1538963
[Epoch 35; Iter   210/  960] train: loss: 0.0231179
[Epoch 35; Iter   240/  960] train: loss: 0.1297222
[Epoch 35; Iter   270/  960] train: loss: 0.1679931
[Epoch 35; Iter   300/  960] train: loss: 0.0179991
[Epoch 35; Iter   330/  960] train: loss: 0.0137212
[Epoch 35; Iter   360/  960] train: loss: 0.0154176
[Epoch 35; Iter   390/  960] train: loss: 0.1159427
[Epoch 35; Iter   420/  960] train: loss: 0.0273252
[Epoch 35; Iter   450/  960] train: loss: 0.0147015
[Epoch 35; Iter   480/  960] train: loss: 0.0432610
[Epoch 35; Iter   510/  960] train: loss: 0.0126595
[Epoch 35; Iter   540/  960] train: loss: 0.1895277
[Epoch 35; Iter   570/  960] train: loss: 0.0644523
[Epoch 35; Iter   600/  960] train: loss: 0.0690879
[Epoch 35; Iter   630/  960] train: loss: 0.0223250
[Epoch 35; Iter   660/  960] train: loss: 0.0079093
[Epoch 35; Iter   690/  960] train: loss: 0.1480905
[Epoch 35; Iter   720/  960] train: loss: 0.1222582
[Epoch 35; Iter   750/  960] train: loss: 0.1419974
[Epoch 35; Iter   780/  960] train: loss: 0.0998093
[Epoch 35; Iter   810/  960] train: loss: 0.2068501
[Epoch 35; Iter   840/  960] train: loss: 0.0133752
[Epoch 35; Iter   870/  960] train: loss: 0.0554080
[Epoch 35; Iter   900/  960] train: loss: 0.0622650
[Epoch 35; Iter   930/  960] train: loss: 0.0210866
[Epoch 35; Iter   960/  960] train: loss: 0.2493178
[Epoch 35] ogbg-molhiv: 0.805500 val loss: 0.134488
[Epoch 35] ogbg-molhiv: 0.825647 test loss: 0.118306
[Epoch 36; Iter    30/  960] train: loss: 0.1237208
[Epoch 36; Iter    60/  960] train: loss: 0.0197670
[Epoch 36; Iter    90/  960] train: loss: 0.0815842
[Epoch 36; Iter   120/  960] train: loss: 0.0663026
[Epoch 36; Iter   150/  960] train: loss: 0.2548424
[Epoch 36; Iter   180/  960] train: loss: 0.0307686
[Epoch 36; Iter   210/  960] train: loss: 0.0957265
[Epoch 36; Iter   240/  960] train: loss: 0.1742955
[Epoch 36; Iter   270/  960] train: loss: 0.0461263
[Epoch 36; Iter   300/  960] train: loss: 0.3067173
[Epoch 36; Iter   330/  960] train: loss: 0.0461152
[Epoch 36; Iter   360/  960] train: loss: 0.0232568
[Epoch 36; Iter   390/  960] train: loss: 0.0165166
[Epoch 36; Iter   420/  960] train: loss: 0.0932326
[Epoch 36; Iter   450/  960] train: loss: 0.2706590
[Epoch 36; Iter   480/  960] train: loss: 0.0309481
[Epoch 36; Iter   510/  960] train: loss: 0.0101559
[Epoch 36; Iter   540/  960] train: loss: 0.0457792
[Epoch 36; Iter   570/  960] train: loss: 0.0117616
[Epoch 36; Iter   600/  960] train: loss: 0.2347480
[Epoch 36; Iter   630/  960] train: loss: 0.1244346
[Epoch 36; Iter   660/  960] train: loss: 0.1404288
[Epoch 36; Iter   690/  960] train: loss: 0.0509207
[Epoch 32; Iter    90/  960] train: loss: 0.0747765
[Epoch 32; Iter   120/  960] train: loss: 0.0283021
[Epoch 32; Iter   150/  960] train: loss: 0.0932841
[Epoch 32; Iter   180/  960] train: loss: 0.0858864
[Epoch 32; Iter   210/  960] train: loss: 0.0176689
[Epoch 32; Iter   240/  960] train: loss: 0.3731122
[Epoch 32; Iter   270/  960] train: loss: 0.0150625
[Epoch 32; Iter   300/  960] train: loss: 0.0227605
[Epoch 32; Iter   330/  960] train: loss: 0.0227854
[Epoch 32; Iter   360/  960] train: loss: 0.0139520
[Epoch 32; Iter   390/  960] train: loss: 0.0823398
[Epoch 32; Iter   420/  960] train: loss: 0.0278330
[Epoch 32; Iter   450/  960] train: loss: 0.0256739
[Epoch 32; Iter   480/  960] train: loss: 0.1302387
[Epoch 32; Iter   510/  960] train: loss: 0.0352187
[Epoch 32; Iter   540/  960] train: loss: 0.1774731
[Epoch 32; Iter   570/  960] train: loss: 0.0292847
[Epoch 32; Iter   600/  960] train: loss: 0.0286051
[Epoch 32; Iter   630/  960] train: loss: 0.0131867
[Epoch 32; Iter   660/  960] train: loss: 0.0237830
[Epoch 32; Iter   690/  960] train: loss: 0.0921082
[Epoch 32; Iter   720/  960] train: loss: 0.0179709
[Epoch 32; Iter   750/  960] train: loss: 0.0196005
[Epoch 32; Iter   780/  960] train: loss: 0.1940426
[Epoch 32; Iter   810/  960] train: loss: 0.1475383
[Epoch 32; Iter   840/  960] train: loss: 0.0215850
[Epoch 32; Iter   870/  960] train: loss: 0.0809698
[Epoch 32; Iter   900/  960] train: loss: 0.0104921
[Epoch 32; Iter   930/  960] train: loss: 0.1802398
[Epoch 32; Iter   960/  960] train: loss: 0.1780720
[Epoch 32] ogbg-molhiv: 0.826698 val loss: 0.411604
[Epoch 32] ogbg-molhiv: 0.822526 test loss: 0.281834
[Epoch 33; Iter    30/  960] train: loss: 0.0106478
[Epoch 33; Iter    60/  960] train: loss: 0.1565528
[Epoch 33; Iter    90/  960] train: loss: 0.2133995
[Epoch 33; Iter   120/  960] train: loss: 0.0186679
[Epoch 33; Iter   150/  960] train: loss: 0.0226522
[Epoch 33; Iter   180/  960] train: loss: 0.0761534
[Epoch 33; Iter   210/  960] train: loss: 0.0196911
[Epoch 33; Iter   240/  960] train: loss: 0.0101621
[Epoch 33; Iter   270/  960] train: loss: 0.0132915
[Epoch 33; Iter   300/  960] train: loss: 0.0302568
[Epoch 33; Iter   330/  960] train: loss: 0.0417916
[Epoch 33; Iter   360/  960] train: loss: 0.0172966
[Epoch 33; Iter   390/  960] train: loss: 0.1073848
[Epoch 33; Iter   420/  960] train: loss: 0.1125558
[Epoch 33; Iter   450/  960] train: loss: 0.0935202
[Epoch 33; Iter   480/  960] train: loss: 0.1224143
[Epoch 33; Iter   510/  960] train: loss: 0.0644809
[Epoch 33; Iter   540/  960] train: loss: 0.1735862
[Epoch 33; Iter   570/  960] train: loss: 0.0839315
[Epoch 33; Iter   600/  960] train: loss: 0.3016469
[Epoch 33; Iter   630/  960] train: loss: 0.0455096
[Epoch 33; Iter   660/  960] train: loss: 0.0544413
[Epoch 33; Iter   690/  960] train: loss: 0.0206671
[Epoch 33; Iter   720/  960] train: loss: 0.1295580
[Epoch 33; Iter   750/  960] train: loss: 0.0292324
[Epoch 33; Iter   780/  960] train: loss: 0.0120539
[Epoch 33; Iter   810/  960] train: loss: 0.0127711
[Epoch 33; Iter   840/  960] train: loss: 0.0232029
[Epoch 33; Iter   870/  960] train: loss: 0.1297291
[Epoch 33; Iter   900/  960] train: loss: 0.0106803
[Epoch 33; Iter   930/  960] train: loss: 0.1289590
[Epoch 33; Iter   960/  960] train: loss: 0.0079422
[Epoch 33] ogbg-molhiv: 0.810097 val loss: 0.138540
[Epoch 33] ogbg-molhiv: 0.815021 test loss: 0.129003
[Epoch 34; Iter    30/  960] train: loss: 0.0852910
[Epoch 34; Iter    60/  960] train: loss: 0.0144280
[Epoch 34; Iter    90/  960] train: loss: 0.0161453
[Epoch 34; Iter   120/  960] train: loss: 0.0276041
[Epoch 34; Iter   150/  960] train: loss: 0.2247106
[Epoch 34; Iter   180/  960] train: loss: 0.0092437
[Epoch 34; Iter   210/  960] train: loss: 0.0688139
[Epoch 34; Iter   240/  960] train: loss: 0.0127924
[Epoch 34; Iter   270/  960] train: loss: 0.1751009
[Epoch 34; Iter   300/  960] train: loss: 0.0243432
[Epoch 34; Iter   330/  960] train: loss: 0.0214047
[Epoch 34; Iter   360/  960] train: loss: 0.0163929
[Epoch 34; Iter   390/  960] train: loss: 0.0117251
[Epoch 34; Iter   420/  960] train: loss: 0.0826399
[Epoch 34; Iter   450/  960] train: loss: 0.0098704
[Epoch 34; Iter   480/  960] train: loss: 0.0691740
[Epoch 34; Iter   510/  960] train: loss: 0.1188098
[Epoch 34; Iter   540/  960] train: loss: 0.0091099
[Epoch 34; Iter   570/  960] train: loss: 0.0214337
[Epoch 34; Iter   600/  960] train: loss: 0.1828797
[Epoch 34; Iter   630/  960] train: loss: 0.0851230
[Epoch 34; Iter   660/  960] train: loss: 0.1163542
[Epoch 34; Iter   690/  960] train: loss: 0.0185210
[Epoch 34; Iter   720/  960] train: loss: 0.2297882
[Epoch 34; Iter   750/  960] train: loss: 0.0144212
[Epoch 34; Iter   780/  960] train: loss: 0.0697964
[Epoch 34; Iter   810/  960] train: loss: 0.0311796
[Epoch 34; Iter   840/  960] train: loss: 0.0330771
[Epoch 34; Iter   870/  960] train: loss: 0.0198718
[Epoch 34; Iter   900/  960] train: loss: 0.0374707
[Epoch 34; Iter   930/  960] train: loss: 0.0180579
[Epoch 34; Iter   960/  960] train: loss: 0.0125767
[Epoch 34] ogbg-molhiv: 0.818642 val loss: 0.148335
[Epoch 34] ogbg-molhiv: 0.807418 test loss: 0.140182
[Epoch 35; Iter    30/  960] train: loss: 0.0176716
[Epoch 35; Iter    60/  960] train: loss: 0.1068329
[Epoch 35; Iter    90/  960] train: loss: 0.0899055
[Epoch 35; Iter   120/  960] train: loss: 0.0880451
[Epoch 35; Iter   150/  960] train: loss: 0.0153229
[Epoch 35; Iter   180/  960] train: loss: 0.0196228
[Epoch 35; Iter   210/  960] train: loss: 0.0242742
[Epoch 35; Iter   240/  960] train: loss: 0.1661989
[Epoch 35; Iter   270/  960] train: loss: 0.0616071
[Epoch 35; Iter   300/  960] train: loss: 0.0416353
[Epoch 35; Iter   330/  960] train: loss: 0.0207922
[Epoch 35; Iter   360/  960] train: loss: 0.0303251
[Epoch 35; Iter   390/  960] train: loss: 0.0278962
[Epoch 35; Iter   420/  960] train: loss: 0.1542920
[Epoch 35; Iter   450/  960] train: loss: 0.0148074
[Epoch 35; Iter   480/  960] train: loss: 0.0123860
[Epoch 35; Iter   510/  960] train: loss: 0.0115339
[Epoch 35; Iter   540/  960] train: loss: 0.0189667
[Epoch 35; Iter   570/  960] train: loss: 0.0225669
[Epoch 35; Iter   600/  960] train: loss: 0.0194529
[Epoch 35; Iter   630/  960] train: loss: 0.0922472
[Epoch 35; Iter   660/  960] train: loss: 0.0227331
[Epoch 35; Iter   690/  960] train: loss: 0.2507774
[Epoch 35; Iter   720/  960] train: loss: 0.0124704
[Epoch 35; Iter   750/  960] train: loss: 0.0398295
[Epoch 35; Iter   780/  960] train: loss: 0.0229885
[Epoch 35; Iter   810/  960] train: loss: 0.0108733
[Epoch 35; Iter   840/  960] train: loss: 0.0831519
[Epoch 35; Iter   870/  960] train: loss: 0.0054378
[Epoch 35; Iter   900/  960] train: loss: 0.1303075
[Epoch 35; Iter   930/  960] train: loss: 0.0144972
[Epoch 35; Iter   960/  960] train: loss: 0.0243839
[Epoch 35] ogbg-molhiv: 0.830678 val loss: 0.142999
[Epoch 35] ogbg-molhiv: 0.825026 test loss: 0.133038
[Epoch 36; Iter    30/  960] train: loss: 0.0270486
[Epoch 36; Iter    60/  960] train: loss: 0.0340326
[Epoch 36; Iter    90/  960] train: loss: 0.0388141
[Epoch 36; Iter   120/  960] train: loss: 0.0200085
[Epoch 36; Iter   150/  960] train: loss: 0.0228734
[Epoch 36; Iter   180/  960] train: loss: 0.0792803
[Epoch 36; Iter   210/  960] train: loss: 0.0731006
[Epoch 36; Iter   240/  960] train: loss: 0.0258901
[Epoch 36; Iter   270/  960] train: loss: 0.0120341
[Epoch 36; Iter   300/  960] train: loss: 0.1296715
[Epoch 36; Iter   330/  960] train: loss: 0.0717547
[Epoch 36; Iter   360/  960] train: loss: 0.0145257
[Epoch 36; Iter   390/  960] train: loss: 0.0055492
[Epoch 36; Iter   420/  960] train: loss: 0.1624306
[Epoch 36; Iter   450/  960] train: loss: 0.1039477
[Epoch 36; Iter   480/  960] train: loss: 0.2479513
[Epoch 36; Iter   510/  960] train: loss: 0.0337209
[Epoch 36; Iter   540/  960] train: loss: 0.0708693
[Epoch 36; Iter   570/  960] train: loss: 0.1587077
[Epoch 36; Iter   600/  960] train: loss: 0.1237432
[Epoch 36; Iter   630/  960] train: loss: 0.0166230
[Epoch 36; Iter   660/  960] train: loss: 0.0055690
[Epoch 36; Iter   690/  960] train: loss: 0.0518236
[Epoch 32; Iter   553/ 1097] train: loss: 0.1465110
[Epoch 32; Iter   583/ 1097] train: loss: 0.0256769
[Epoch 32; Iter   613/ 1097] train: loss: 0.0184024
[Epoch 32; Iter   643/ 1097] train: loss: 0.0302319
[Epoch 32; Iter   673/ 1097] train: loss: 0.2241804
[Epoch 32; Iter   703/ 1097] train: loss: 0.0319293
[Epoch 32; Iter   733/ 1097] train: loss: 0.3002456
[Epoch 32; Iter   763/ 1097] train: loss: 0.1455627
[Epoch 32; Iter   793/ 1097] train: loss: 0.0267277
[Epoch 32; Iter   823/ 1097] train: loss: 0.2369791
[Epoch 32; Iter   853/ 1097] train: loss: 0.1182541
[Epoch 32; Iter   883/ 1097] train: loss: 0.0177347
[Epoch 32; Iter   913/ 1097] train: loss: 0.0496097
[Epoch 32; Iter   943/ 1097] train: loss: 0.0238769
[Epoch 32; Iter   973/ 1097] train: loss: 0.3983557
[Epoch 32; Iter  1003/ 1097] train: loss: 0.1779889
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0352138
[Epoch 32; Iter  1063/ 1097] train: loss: 0.1293888
[Epoch 32; Iter  1093/ 1097] train: loss: 0.1353357
[Epoch 32] ogbg-molhiv: 0.828944 val loss: 0.299770
[Epoch 32] ogbg-molhiv: 0.823903 test loss: 0.177286
[Epoch 33; Iter    26/ 1097] train: loss: 0.0466475
[Epoch 33; Iter    56/ 1097] train: loss: 0.1095322
[Epoch 33; Iter    86/ 1097] train: loss: 0.3081895
[Epoch 33; Iter   116/ 1097] train: loss: 0.0340866
[Epoch 33; Iter   146/ 1097] train: loss: 0.0173710
[Epoch 33; Iter   176/ 1097] train: loss: 0.1539194
[Epoch 33; Iter   206/ 1097] train: loss: 0.3083791
[Epoch 33; Iter   236/ 1097] train: loss: 0.4995113
[Epoch 33; Iter   266/ 1097] train: loss: 0.0380693
[Epoch 33; Iter   296/ 1097] train: loss: 0.0405406
[Epoch 33; Iter   326/ 1097] train: loss: 0.2157569
[Epoch 33; Iter   356/ 1097] train: loss: 0.0182230
[Epoch 33; Iter   386/ 1097] train: loss: 0.0608509
[Epoch 33; Iter   416/ 1097] train: loss: 0.2680296
[Epoch 33; Iter   446/ 1097] train: loss: 0.0310174
[Epoch 33; Iter   476/ 1097] train: loss: 0.0364416
[Epoch 33; Iter   506/ 1097] train: loss: 0.0411961
[Epoch 33; Iter   536/ 1097] train: loss: 0.0174110
[Epoch 33; Iter   566/ 1097] train: loss: 0.0250256
[Epoch 33; Iter   596/ 1097] train: loss: 0.0695547
[Epoch 33; Iter   626/ 1097] train: loss: 0.1579200
[Epoch 33; Iter   656/ 1097] train: loss: 0.0626569
[Epoch 33; Iter   686/ 1097] train: loss: 0.1413951
[Epoch 33; Iter   716/ 1097] train: loss: 0.0179943
[Epoch 33; Iter   746/ 1097] train: loss: 0.0934321
[Epoch 33; Iter   776/ 1097] train: loss: 0.0190557
[Epoch 33; Iter   806/ 1097] train: loss: 0.0161138
[Epoch 33; Iter   836/ 1097] train: loss: 0.2324783
[Epoch 33; Iter   866/ 1097] train: loss: 0.0541062
[Epoch 33; Iter   896/ 1097] train: loss: 0.0572839
[Epoch 33; Iter   926/ 1097] train: loss: 0.1608654
[Epoch 33; Iter   956/ 1097] train: loss: 0.1382969
[Epoch 33; Iter   986/ 1097] train: loss: 0.0289944
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0208966
[Epoch 33; Iter  1046/ 1097] train: loss: 0.1496664
[Epoch 33; Iter  1076/ 1097] train: loss: 0.0220921
[Epoch 33] ogbg-molhiv: 0.827454 val loss: 0.404750
[Epoch 33] ogbg-molhiv: 0.805570 test loss: 0.112811
[Epoch 34; Iter     9/ 1097] train: loss: 0.0189464
[Epoch 34; Iter    39/ 1097] train: loss: 0.0835543
[Epoch 34; Iter    69/ 1097] train: loss: 0.0423127
[Epoch 34; Iter    99/ 1097] train: loss: 0.0394049
[Epoch 34; Iter   129/ 1097] train: loss: 0.0331656
[Epoch 34; Iter   159/ 1097] train: loss: 0.1245947
[Epoch 34; Iter   189/ 1097] train: loss: 0.0559899
[Epoch 34; Iter   219/ 1097] train: loss: 0.1969001
[Epoch 34; Iter   249/ 1097] train: loss: 0.0354157
[Epoch 34; Iter   279/ 1097] train: loss: 0.1517854
[Epoch 34; Iter   309/ 1097] train: loss: 0.0210447
[Epoch 34; Iter   339/ 1097] train: loss: 0.1076140
[Epoch 34; Iter   369/ 1097] train: loss: 0.0404528
[Epoch 34; Iter   399/ 1097] train: loss: 0.0450302
[Epoch 34; Iter   429/ 1097] train: loss: 0.0169257
[Epoch 34; Iter   459/ 1097] train: loss: 0.0357974
[Epoch 34; Iter   489/ 1097] train: loss: 0.0913068
[Epoch 34; Iter   519/ 1097] train: loss: 0.0308414
[Epoch 34; Iter   549/ 1097] train: loss: 0.1192153
[Epoch 34; Iter   579/ 1097] train: loss: 0.1921325
[Epoch 34; Iter   609/ 1097] train: loss: 0.0957993
[Epoch 34; Iter   639/ 1097] train: loss: 0.0503550
[Epoch 34; Iter   669/ 1097] train: loss: 0.0897154
[Epoch 34; Iter   699/ 1097] train: loss: 0.2346430
[Epoch 34; Iter   729/ 1097] train: loss: 0.2688506
[Epoch 34; Iter   759/ 1097] train: loss: 0.0343878
[Epoch 34; Iter   789/ 1097] train: loss: 0.0535324
[Epoch 34; Iter   819/ 1097] train: loss: 0.0233389
[Epoch 34; Iter   849/ 1097] train: loss: 0.1536292
[Epoch 34; Iter   879/ 1097] train: loss: 0.1990816
[Epoch 34; Iter   909/ 1097] train: loss: 0.0288829
[Epoch 34; Iter   939/ 1097] train: loss: 0.1324219
[Epoch 34; Iter   969/ 1097] train: loss: 0.1537462
[Epoch 34; Iter   999/ 1097] train: loss: 0.3208090
[Epoch 34; Iter  1029/ 1097] train: loss: 0.1051632
[Epoch 34; Iter  1059/ 1097] train: loss: 0.0163506
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0191573
[Epoch 34] ogbg-molhiv: 0.815397 val loss: 0.398856
[Epoch 34] ogbg-molhiv: 0.810315 test loss: 0.440044
[Epoch 35; Iter    22/ 1097] train: loss: 0.0263325
[Epoch 35; Iter    52/ 1097] train: loss: 0.1378994
[Epoch 35; Iter    82/ 1097] train: loss: 0.0159134
[Epoch 35; Iter   112/ 1097] train: loss: 0.0248125
[Epoch 35; Iter   142/ 1097] train: loss: 0.0192552
[Epoch 35; Iter   172/ 1097] train: loss: 0.0218835
[Epoch 35; Iter   202/ 1097] train: loss: 0.2078302
[Epoch 35; Iter   232/ 1097] train: loss: 0.0725980
[Epoch 35; Iter   262/ 1097] train: loss: 0.1727196
[Epoch 35; Iter   292/ 1097] train: loss: 0.0938784
[Epoch 35; Iter   322/ 1097] train: loss: 0.0900036
[Epoch 35; Iter   352/ 1097] train: loss: 0.1582061
[Epoch 35; Iter   382/ 1097] train: loss: 0.0322888
[Epoch 35; Iter   412/ 1097] train: loss: 0.0266181
[Epoch 35; Iter   442/ 1097] train: loss: 0.1559407
[Epoch 35; Iter   472/ 1097] train: loss: 0.0237941
[Epoch 35; Iter   502/ 1097] train: loss: 0.1598917
[Epoch 35; Iter   532/ 1097] train: loss: 0.0383824
[Epoch 35; Iter   562/ 1097] train: loss: 0.0473376
[Epoch 35; Iter   592/ 1097] train: loss: 0.2079661
[Epoch 35; Iter   622/ 1097] train: loss: 0.0871757
[Epoch 35; Iter   652/ 1097] train: loss: 0.0722477
[Epoch 35; Iter   682/ 1097] train: loss: 0.0579021
[Epoch 35; Iter   712/ 1097] train: loss: 0.0214859
[Epoch 35; Iter   742/ 1097] train: loss: 0.0742726
[Epoch 35; Iter   772/ 1097] train: loss: 0.0686523
[Epoch 35; Iter   802/ 1097] train: loss: 0.1553018
[Epoch 35; Iter   832/ 1097] train: loss: 0.2815942
[Epoch 35; Iter   862/ 1097] train: loss: 0.0481079
[Epoch 35; Iter   892/ 1097] train: loss: 0.0239697
[Epoch 35; Iter   922/ 1097] train: loss: 0.0502439
[Epoch 35; Iter   952/ 1097] train: loss: 0.0164587
[Epoch 35; Iter   982/ 1097] train: loss: 0.0750327
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0427488
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0334686
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0243713
[Epoch 35] ogbg-molhiv: 0.832108 val loss: 0.350904
[Epoch 35] ogbg-molhiv: 0.819970 test loss: 0.128778
[Epoch 36; Iter     5/ 1097] train: loss: 0.0625685
[Epoch 36; Iter    35/ 1097] train: loss: 0.0792195
[Epoch 36; Iter    65/ 1097] train: loss: 0.0383610
[Epoch 36; Iter    95/ 1097] train: loss: 0.0482863
[Epoch 36; Iter   125/ 1097] train: loss: 0.1825593
[Epoch 36; Iter   155/ 1097] train: loss: 0.1479943
[Epoch 36; Iter   185/ 1097] train: loss: 0.0366111
[Epoch 36; Iter   215/ 1097] train: loss: 0.0224984
[Epoch 36; Iter   245/ 1097] train: loss: 0.0179536
[Epoch 36; Iter   275/ 1097] train: loss: 0.0330786
[Epoch 36; Iter   305/ 1097] train: loss: 0.1037005
[Epoch 36; Iter   335/ 1097] train: loss: 0.4228089
[Epoch 36; Iter   365/ 1097] train: loss: 0.0804721
[Epoch 36; Iter   395/ 1097] train: loss: 0.0136840
[Epoch 36; Iter   425/ 1097] train: loss: 0.0177107
[Epoch 36; Iter   455/ 1097] train: loss: 0.1366813
[Epoch 36; Iter   485/ 1097] train: loss: 0.0148314
[Epoch 36; Iter   515/ 1097] train: loss: 0.0413082
[Epoch 36; Iter   545/ 1097] train: loss: 0.1445840
[Epoch 36; Iter   575/ 1097] train: loss: 0.0970512
[Epoch 36; Iter   605/ 1097] train: loss: 0.3719212
[Epoch 32; Iter   553/ 1097] train: loss: 0.0342610
[Epoch 32; Iter   583/ 1097] train: loss: 0.1967824
[Epoch 32; Iter   613/ 1097] train: loss: 0.0265451
[Epoch 32; Iter   643/ 1097] train: loss: 0.0215841
[Epoch 32; Iter   673/ 1097] train: loss: 0.0130135
[Epoch 32; Iter   703/ 1097] train: loss: 0.0200673
[Epoch 32; Iter   733/ 1097] train: loss: 0.2159756
[Epoch 32; Iter   763/ 1097] train: loss: 0.0466579
[Epoch 32; Iter   793/ 1097] train: loss: 0.0208246
[Epoch 32; Iter   823/ 1097] train: loss: 0.0158010
[Epoch 32; Iter   853/ 1097] train: loss: 0.0597013
[Epoch 32; Iter   883/ 1097] train: loss: 0.0276472
[Epoch 32; Iter   913/ 1097] train: loss: 0.0318516
[Epoch 32; Iter   943/ 1097] train: loss: 0.0221390
[Epoch 32; Iter   973/ 1097] train: loss: 0.0155522
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0511730
[Epoch 32; Iter  1033/ 1097] train: loss: 0.1378980
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0235178
[Epoch 32; Iter  1093/ 1097] train: loss: 0.2645922
[Epoch 32] ogbg-molhiv: 0.809869 val loss: 0.121674
[Epoch 32] ogbg-molhiv: 0.831808 test loss: 0.117079
[Epoch 33; Iter    26/ 1097] train: loss: 0.0107076
[Epoch 33; Iter    56/ 1097] train: loss: 0.0128319
[Epoch 33; Iter    86/ 1097] train: loss: 0.0685914
[Epoch 33; Iter   116/ 1097] train: loss: 0.0465140
[Epoch 33; Iter   146/ 1097] train: loss: 0.0443356
[Epoch 33; Iter   176/ 1097] train: loss: 0.1337897
[Epoch 33; Iter   206/ 1097] train: loss: 0.0243495
[Epoch 33; Iter   236/ 1097] train: loss: 0.0340894
[Epoch 33; Iter   266/ 1097] train: loss: 0.0334964
[Epoch 33; Iter   296/ 1097] train: loss: 0.0234146
[Epoch 33; Iter   326/ 1097] train: loss: 0.1620990
[Epoch 33; Iter   356/ 1097] train: loss: 0.0904411
[Epoch 33; Iter   386/ 1097] train: loss: 0.0324521
[Epoch 33; Iter   416/ 1097] train: loss: 0.0568213
[Epoch 33; Iter   446/ 1097] train: loss: 0.0225156
[Epoch 33; Iter   476/ 1097] train: loss: 0.0676126
[Epoch 33; Iter   506/ 1097] train: loss: 0.0323473
[Epoch 33; Iter   536/ 1097] train: loss: 0.0140314
[Epoch 33; Iter   566/ 1097] train: loss: 0.0129138
[Epoch 33; Iter   596/ 1097] train: loss: 0.0804322
[Epoch 33; Iter   626/ 1097] train: loss: 0.2746296
[Epoch 33; Iter   656/ 1097] train: loss: 0.0266417
[Epoch 33; Iter   686/ 1097] train: loss: 0.0894530
[Epoch 33; Iter   716/ 1097] train: loss: 0.0145677
[Epoch 33; Iter   746/ 1097] train: loss: 0.0341755
[Epoch 33; Iter   776/ 1097] train: loss: 0.0768665
[Epoch 33; Iter   806/ 1097] train: loss: 0.1450685
[Epoch 33; Iter   836/ 1097] train: loss: 0.3765600
[Epoch 33; Iter   866/ 1097] train: loss: 0.0326195
[Epoch 33; Iter   896/ 1097] train: loss: 0.0268609
[Epoch 33; Iter   926/ 1097] train: loss: 0.0272970
[Epoch 33; Iter   956/ 1097] train: loss: 0.0144194
[Epoch 33; Iter   986/ 1097] train: loss: 0.0350712
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0174538
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0150159
[Epoch 33; Iter  1076/ 1097] train: loss: 0.0669445
[Epoch 33] ogbg-molhiv: 0.817558 val loss: 0.123600
[Epoch 33] ogbg-molhiv: 0.826069 test loss: 0.122826
[Epoch 34; Iter     9/ 1097] train: loss: 0.0146969
[Epoch 34; Iter    39/ 1097] train: loss: 0.0972171
[Epoch 34; Iter    69/ 1097] train: loss: 0.2107980
[Epoch 34; Iter    99/ 1097] train: loss: 0.1065863
[Epoch 34; Iter   129/ 1097] train: loss: 0.0578923
[Epoch 34; Iter   159/ 1097] train: loss: 0.0346435
[Epoch 34; Iter   189/ 1097] train: loss: 0.0177874
[Epoch 34; Iter   219/ 1097] train: loss: 0.1143762
[Epoch 34; Iter   249/ 1097] train: loss: 0.0113964
[Epoch 34; Iter   279/ 1097] train: loss: 0.0109307
[Epoch 34; Iter   309/ 1097] train: loss: 0.1066280
[Epoch 34; Iter   339/ 1097] train: loss: 0.0137326
[Epoch 34; Iter   369/ 1097] train: loss: 0.0281741
[Epoch 34; Iter   399/ 1097] train: loss: 0.0616418
[Epoch 34; Iter   429/ 1097] train: loss: 0.0547808
[Epoch 34; Iter   459/ 1097] train: loss: 0.1300573
[Epoch 34; Iter   489/ 1097] train: loss: 0.0822228
[Epoch 34; Iter   519/ 1097] train: loss: 0.1407622
[Epoch 34; Iter   549/ 1097] train: loss: 0.0761652
[Epoch 34; Iter   579/ 1097] train: loss: 0.0371547
[Epoch 34; Iter   609/ 1097] train: loss: 0.0495760
[Epoch 34; Iter   639/ 1097] train: loss: 0.0137644
[Epoch 34; Iter   669/ 1097] train: loss: 0.0102474
[Epoch 34; Iter   699/ 1097] train: loss: 0.0289470
[Epoch 34; Iter   729/ 1097] train: loss: 0.0227690
[Epoch 34; Iter   759/ 1097] train: loss: 0.0259813
[Epoch 34; Iter   789/ 1097] train: loss: 0.0932820
[Epoch 34; Iter   819/ 1097] train: loss: 0.0372781
[Epoch 34; Iter   849/ 1097] train: loss: 0.1586487
[Epoch 34; Iter   879/ 1097] train: loss: 0.1146394
[Epoch 34; Iter   909/ 1097] train: loss: 0.0648958
[Epoch 34; Iter   939/ 1097] train: loss: 0.0243595
[Epoch 34; Iter   969/ 1097] train: loss: 0.0325498
[Epoch 34; Iter   999/ 1097] train: loss: 0.2765256
[Epoch 34; Iter  1029/ 1097] train: loss: 0.0956126
[Epoch 34; Iter  1059/ 1097] train: loss: 0.0410407
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0426642
[Epoch 34] ogbg-molhiv: 0.806871 val loss: 0.215635
[Epoch 34] ogbg-molhiv: 0.827047 test loss: 0.209128
[Epoch 35; Iter    22/ 1097] train: loss: 0.0910095
[Epoch 35; Iter    52/ 1097] train: loss: 0.0165712
[Epoch 35; Iter    82/ 1097] train: loss: 0.0234018
[Epoch 35; Iter   112/ 1097] train: loss: 0.1765397
[Epoch 35; Iter   142/ 1097] train: loss: 0.0367994
[Epoch 35; Iter   172/ 1097] train: loss: 0.0120993
[Epoch 35; Iter   202/ 1097] train: loss: 0.0916812
[Epoch 35; Iter   232/ 1097] train: loss: 0.0285191
[Epoch 35; Iter   262/ 1097] train: loss: 0.0936056
[Epoch 35; Iter   292/ 1097] train: loss: 0.1501501
[Epoch 35; Iter   322/ 1097] train: loss: 0.0664576
[Epoch 35; Iter   352/ 1097] train: loss: 0.1098722
[Epoch 35; Iter   382/ 1097] train: loss: 0.0233392
[Epoch 35; Iter   412/ 1097] train: loss: 0.2661447
[Epoch 35; Iter   442/ 1097] train: loss: 0.0094752
[Epoch 35; Iter   472/ 1097] train: loss: 0.0549037
[Epoch 35; Iter   502/ 1097] train: loss: 0.0436879
[Epoch 35; Iter   532/ 1097] train: loss: 0.1241132
[Epoch 35; Iter   562/ 1097] train: loss: 0.0641458
[Epoch 35; Iter   592/ 1097] train: loss: 0.0428290
[Epoch 35; Iter   622/ 1097] train: loss: 0.0174699
[Epoch 35; Iter   652/ 1097] train: loss: 0.2186612
[Epoch 35; Iter   682/ 1097] train: loss: 0.0850949
[Epoch 35; Iter   712/ 1097] train: loss: 0.1900123
[Epoch 35; Iter   742/ 1097] train: loss: 0.0127679
[Epoch 35; Iter   772/ 1097] train: loss: 0.0185381
[Epoch 35; Iter   802/ 1097] train: loss: 0.0330037
[Epoch 35; Iter   832/ 1097] train: loss: 0.0259707
[Epoch 35; Iter   862/ 1097] train: loss: 0.1928237
[Epoch 35; Iter   892/ 1097] train: loss: 0.1666782
[Epoch 35; Iter   922/ 1097] train: loss: 0.1605818
[Epoch 35; Iter   952/ 1097] train: loss: 0.0353044
[Epoch 35; Iter   982/ 1097] train: loss: 0.0607511
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0771476
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0884934
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0736967
[Epoch 35] ogbg-molhiv: 0.814427 val loss: 0.129488
[Epoch 35] ogbg-molhiv: 0.828540 test loss: 0.123593
[Epoch 36; Iter     5/ 1097] train: loss: 0.0183342
[Epoch 36; Iter    35/ 1097] train: loss: 0.0314397
[Epoch 36; Iter    65/ 1097] train: loss: 0.2144247
[Epoch 36; Iter    95/ 1097] train: loss: 0.0195597
[Epoch 36; Iter   125/ 1097] train: loss: 0.0233995
[Epoch 36; Iter   155/ 1097] train: loss: 0.1200143
[Epoch 36; Iter   185/ 1097] train: loss: 0.1118690
[Epoch 36; Iter   215/ 1097] train: loss: 0.0109149
[Epoch 36; Iter   245/ 1097] train: loss: 0.0464585
[Epoch 36; Iter   275/ 1097] train: loss: 0.2424785
[Epoch 36; Iter   305/ 1097] train: loss: 0.0281515
[Epoch 36; Iter   335/ 1097] train: loss: 0.0090878
[Epoch 36; Iter   365/ 1097] train: loss: 0.2732680
[Epoch 36; Iter   395/ 1097] train: loss: 0.0187097
[Epoch 36; Iter   425/ 1097] train: loss: 0.0157436
[Epoch 36; Iter   455/ 1097] train: loss: 0.0252643
[Epoch 36; Iter   485/ 1097] train: loss: 0.0635512
[Epoch 36; Iter   515/ 1097] train: loss: 0.0266450
[Epoch 36; Iter   545/ 1097] train: loss: 0.0295987
[Epoch 36; Iter   575/ 1097] train: loss: 0.0956818
[Epoch 36; Iter   605/ 1097] train: loss: 0.0299336
[Epoch 32; Iter   553/ 1097] train: loss: 0.0388966
[Epoch 32; Iter   583/ 1097] train: loss: 0.0461288
[Epoch 32; Iter   613/ 1097] train: loss: 0.2779047
[Epoch 32; Iter   643/ 1097] train: loss: 0.3155281
[Epoch 32; Iter   673/ 1097] train: loss: 0.0212169
[Epoch 32; Iter   703/ 1097] train: loss: 0.0151253
[Epoch 32; Iter   733/ 1097] train: loss: 0.0445545
[Epoch 32; Iter   763/ 1097] train: loss: 0.0185749
[Epoch 32; Iter   793/ 1097] train: loss: 0.2175601
[Epoch 32; Iter   823/ 1097] train: loss: 0.1872232
[Epoch 32; Iter   853/ 1097] train: loss: 0.0297410
[Epoch 32; Iter   883/ 1097] train: loss: 0.1305707
[Epoch 32; Iter   913/ 1097] train: loss: 0.0573983
[Epoch 32; Iter   943/ 1097] train: loss: 0.1201910
[Epoch 32; Iter   973/ 1097] train: loss: 0.0183439
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0332188
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0129364
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0504429
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0651749
[Epoch 32] ogbg-molhiv: 0.799316 val loss: 0.188497
[Epoch 32] ogbg-molhiv: 0.804086 test loss: 0.236268
[Epoch 33; Iter    26/ 1097] train: loss: 0.0923142
[Epoch 33; Iter    56/ 1097] train: loss: 0.0095016
[Epoch 33; Iter    86/ 1097] train: loss: 0.0270062
[Epoch 33; Iter   116/ 1097] train: loss: 0.0239560
[Epoch 33; Iter   146/ 1097] train: loss: 0.1922927
[Epoch 33; Iter   176/ 1097] train: loss: 0.0107968
[Epoch 33; Iter   206/ 1097] train: loss: 0.0184417
[Epoch 33; Iter   236/ 1097] train: loss: 0.2251883
[Epoch 33; Iter   266/ 1097] train: loss: 0.3464965
[Epoch 33; Iter   296/ 1097] train: loss: 0.0147367
[Epoch 33; Iter   326/ 1097] train: loss: 0.0335287
[Epoch 33; Iter   356/ 1097] train: loss: 0.1104096
[Epoch 33; Iter   386/ 1097] train: loss: 0.0107120
[Epoch 33; Iter   416/ 1097] train: loss: 0.0100204
[Epoch 33; Iter   446/ 1097] train: loss: 0.2432111
[Epoch 33; Iter   476/ 1097] train: loss: 0.0790179
[Epoch 33; Iter   506/ 1097] train: loss: 0.0110470
[Epoch 33; Iter   536/ 1097] train: loss: 0.3689843
[Epoch 33; Iter   566/ 1097] train: loss: 0.0316090
[Epoch 33; Iter   596/ 1097] train: loss: 0.0171172
[Epoch 33; Iter   626/ 1097] train: loss: 0.0654801
[Epoch 33; Iter   656/ 1097] train: loss: 0.0115628
[Epoch 33; Iter   686/ 1097] train: loss: 0.0125525
[Epoch 33; Iter   716/ 1097] train: loss: 0.1486975
[Epoch 33; Iter   746/ 1097] train: loss: 0.0248485
[Epoch 33; Iter   776/ 1097] train: loss: 0.1904233
[Epoch 33; Iter   806/ 1097] train: loss: 0.0255067
[Epoch 33; Iter   836/ 1097] train: loss: 0.0183231
[Epoch 33; Iter   866/ 1097] train: loss: 0.0272118
[Epoch 33; Iter   896/ 1097] train: loss: 0.0382650
[Epoch 33; Iter   926/ 1097] train: loss: 0.0149362
[Epoch 33; Iter   956/ 1097] train: loss: 0.2546907
[Epoch 33; Iter   986/ 1097] train: loss: 0.0604282
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0207015
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0118417
[Epoch 33; Iter  1076/ 1097] train: loss: 0.0382815
[Epoch 33] ogbg-molhiv: 0.806422 val loss: 0.194967
[Epoch 33] ogbg-molhiv: 0.812262 test loss: 0.362940
[Epoch 34; Iter     9/ 1097] train: loss: 0.0237764
[Epoch 34; Iter    39/ 1097] train: loss: 0.0351895
[Epoch 34; Iter    69/ 1097] train: loss: 0.0276446
[Epoch 34; Iter    99/ 1097] train: loss: 0.0203982
[Epoch 34; Iter   129/ 1097] train: loss: 0.0303622
[Epoch 34; Iter   159/ 1097] train: loss: 0.1035627
[Epoch 34; Iter   189/ 1097] train: loss: 0.1126494
[Epoch 34; Iter   219/ 1097] train: loss: 0.1583981
[Epoch 34; Iter   249/ 1097] train: loss: 0.0221259
[Epoch 34; Iter   279/ 1097] train: loss: 0.1197367
[Epoch 34; Iter   309/ 1097] train: loss: 0.1798497
[Epoch 34; Iter   339/ 1097] train: loss: 0.0772477
[Epoch 34; Iter   369/ 1097] train: loss: 0.0157040
[Epoch 34; Iter   399/ 1097] train: loss: 0.0306345
[Epoch 34; Iter   429/ 1097] train: loss: 0.1908711
[Epoch 34; Iter   459/ 1097] train: loss: 0.0938142
[Epoch 34; Iter   489/ 1097] train: loss: 0.0153579
[Epoch 34; Iter   519/ 1097] train: loss: 0.0188724
[Epoch 34; Iter   549/ 1097] train: loss: 0.0153536
[Epoch 34; Iter   579/ 1097] train: loss: 0.0966461
[Epoch 34; Iter   609/ 1097] train: loss: 0.0672757
[Epoch 34; Iter   639/ 1097] train: loss: 0.0107866
[Epoch 34; Iter   669/ 1097] train: loss: 0.0211171
[Epoch 34; Iter   699/ 1097] train: loss: 0.0103486
[Epoch 34; Iter   729/ 1097] train: loss: 0.0180418
[Epoch 34; Iter   759/ 1097] train: loss: 0.1916073
[Epoch 34; Iter   789/ 1097] train: loss: 0.1681973
[Epoch 34; Iter   819/ 1097] train: loss: 0.0128726
[Epoch 34; Iter   849/ 1097] train: loss: 0.1308594
[Epoch 34; Iter   879/ 1097] train: loss: 0.0177876
[Epoch 34; Iter   909/ 1097] train: loss: 0.0144368
[Epoch 34; Iter   939/ 1097] train: loss: 0.0155125
[Epoch 34; Iter   969/ 1097] train: loss: 0.0338099
[Epoch 34; Iter   999/ 1097] train: loss: 0.0280955
[Epoch 34; Iter  1029/ 1097] train: loss: 0.0217983
[Epoch 34; Iter  1059/ 1097] train: loss: 0.0159611
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0348698
[Epoch 34] ogbg-molhiv: 0.803984 val loss: 0.187810
[Epoch 34] ogbg-molhiv: 0.815373 test loss: 0.317595
[Epoch 35; Iter    22/ 1097] train: loss: 0.0351251
[Epoch 35; Iter    52/ 1097] train: loss: 0.0264806
[Epoch 35; Iter    82/ 1097] train: loss: 0.0383227
[Epoch 35; Iter   112/ 1097] train: loss: 0.1119936
[Epoch 35; Iter   142/ 1097] train: loss: 0.0178730
[Epoch 35; Iter   172/ 1097] train: loss: 0.0297941
[Epoch 35; Iter   202/ 1097] train: loss: 0.1818199
[Epoch 35; Iter   232/ 1097] train: loss: 0.0958467
[Epoch 35; Iter   262/ 1097] train: loss: 0.0993854
[Epoch 35; Iter   292/ 1097] train: loss: 0.0121565
[Epoch 35; Iter   322/ 1097] train: loss: 0.0729774
[Epoch 35; Iter   352/ 1097] train: loss: 0.1516353
[Epoch 35; Iter   382/ 1097] train: loss: 0.0525050
[Epoch 35; Iter   412/ 1097] train: loss: 0.0133571
[Epoch 35; Iter   442/ 1097] train: loss: 0.0722819
[Epoch 35; Iter   472/ 1097] train: loss: 0.0763104
[Epoch 35; Iter   502/ 1097] train: loss: 0.0239988
[Epoch 35; Iter   532/ 1097] train: loss: 0.0441246
[Epoch 35; Iter   562/ 1097] train: loss: 0.4018162
[Epoch 35; Iter   592/ 1097] train: loss: 0.0136188
[Epoch 35; Iter   622/ 1097] train: loss: 0.1726267
[Epoch 35; Iter   652/ 1097] train: loss: 0.0262154
[Epoch 35; Iter   682/ 1097] train: loss: 0.0171351
[Epoch 35; Iter   712/ 1097] train: loss: 0.0968175
[Epoch 35; Iter   742/ 1097] train: loss: 0.0144310
[Epoch 35; Iter   772/ 1097] train: loss: 0.3073040
[Epoch 35; Iter   802/ 1097] train: loss: 0.0127205
[Epoch 35; Iter   832/ 1097] train: loss: 0.0446453
[Epoch 35; Iter   862/ 1097] train: loss: 0.0198234
[Epoch 35; Iter   892/ 1097] train: loss: 0.1243428
[Epoch 35; Iter   922/ 1097] train: loss: 0.0370633
[Epoch 35; Iter   952/ 1097] train: loss: 0.0284391
[Epoch 35; Iter   982/ 1097] train: loss: 0.0483326
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0793777
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0375334
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0138371
[Epoch 35] ogbg-molhiv: 0.804072 val loss: 0.280927
[Epoch 35] ogbg-molhiv: 0.830826 test loss: 0.420320
[Epoch 36; Iter     5/ 1097] train: loss: 0.0165009
[Epoch 36; Iter    35/ 1097] train: loss: 0.0263919
[Epoch 36; Iter    65/ 1097] train: loss: 0.2174762
[Epoch 36; Iter    95/ 1097] train: loss: 0.0542405
[Epoch 36; Iter   125/ 1097] train: loss: 0.0582222
[Epoch 36; Iter   155/ 1097] train: loss: 0.0396920
[Epoch 36; Iter   185/ 1097] train: loss: 0.0564703
[Epoch 36; Iter   215/ 1097] train: loss: 0.0151025
[Epoch 36; Iter   245/ 1097] train: loss: 0.0257849
[Epoch 36; Iter   275/ 1097] train: loss: 0.0180537
[Epoch 36; Iter   305/ 1097] train: loss: 0.0189084
[Epoch 36; Iter   335/ 1097] train: loss: 0.0361878
[Epoch 36; Iter   365/ 1097] train: loss: 0.0216626
[Epoch 36; Iter   395/ 1097] train: loss: 0.1473762
[Epoch 36; Iter   425/ 1097] train: loss: 0.1055670
[Epoch 36; Iter   455/ 1097] train: loss: 0.0330155
[Epoch 36; Iter   485/ 1097] train: loss: 0.0390517
[Epoch 36; Iter   515/ 1097] train: loss: 0.0846211
[Epoch 36; Iter   545/ 1097] train: loss: 0.1272408
[Epoch 36; Iter   575/ 1097] train: loss: 0.0598848
[Epoch 36; Iter   605/ 1097] train: loss: 0.1119239
[Epoch 36; Iter   775/  823] train: loss: 0.0149226
[Epoch 36; Iter   805/  823] train: loss: 0.1655986
[Epoch 36] ogbg-molhiv: 0.830130 val loss: 0.150272
[Epoch 36] ogbg-molhiv: 0.795027 test loss: 0.191196
[Epoch 37; Iter    12/  823] train: loss: 0.0150824
[Epoch 37; Iter    42/  823] train: loss: 0.0194552
[Epoch 37; Iter    72/  823] train: loss: 0.0260407
[Epoch 37; Iter   102/  823] train: loss: 0.0182366
[Epoch 37; Iter   132/  823] train: loss: 0.0220208
[Epoch 37; Iter   162/  823] train: loss: 0.0318088
[Epoch 37; Iter   192/  823] train: loss: 0.1022399
[Epoch 37; Iter   222/  823] train: loss: 0.0225167
[Epoch 37; Iter   252/  823] train: loss: 0.1196472
[Epoch 37; Iter   282/  823] train: loss: 0.0216948
[Epoch 37; Iter   312/  823] train: loss: 0.0808249
[Epoch 37; Iter   342/  823] train: loss: 0.1070695
[Epoch 37; Iter   372/  823] train: loss: 0.2790871
[Epoch 37; Iter   402/  823] train: loss: 0.0968355
[Epoch 37; Iter   432/  823] train: loss: 0.0186367
[Epoch 37; Iter   462/  823] train: loss: 0.0456224
[Epoch 37; Iter   492/  823] train: loss: 0.0883653
[Epoch 37; Iter   522/  823] train: loss: 0.2005949
[Epoch 37; Iter   552/  823] train: loss: 0.1641884
[Epoch 37; Iter   582/  823] train: loss: 0.1555078
[Epoch 37; Iter   612/  823] train: loss: 0.0606836
[Epoch 37; Iter   642/  823] train: loss: 0.0481232
[Epoch 37; Iter   672/  823] train: loss: 0.0139394
[Epoch 37; Iter   702/  823] train: loss: 0.1119175
[Epoch 37; Iter   732/  823] train: loss: 0.1119358
[Epoch 37; Iter   762/  823] train: loss: 0.2179494
[Epoch 37; Iter   792/  823] train: loss: 0.0537712
[Epoch 37; Iter   822/  823] train: loss: 0.1814684
[Epoch 37] ogbg-molhiv: 0.832155 val loss: 0.124751
[Epoch 37] ogbg-molhiv: 0.795488 test loss: 0.163042
[Epoch 38; Iter    29/  823] train: loss: 0.0486323
[Epoch 38; Iter    59/  823] train: loss: 0.1375244
[Epoch 38; Iter    89/  823] train: loss: 0.0164178
[Epoch 38; Iter   119/  823] train: loss: 0.1806955
[Epoch 38; Iter   149/  823] train: loss: 0.0170350
[Epoch 38; Iter   179/  823] train: loss: 0.0418569
[Epoch 38; Iter   209/  823] train: loss: 0.0331994
[Epoch 38; Iter   239/  823] train: loss: 0.1879346
[Epoch 38; Iter   269/  823] train: loss: 0.0987120
[Epoch 38; Iter   299/  823] train: loss: 0.1085722
[Epoch 38; Iter   329/  823] train: loss: 0.0327296
[Epoch 38; Iter   359/  823] train: loss: 0.0599729
[Epoch 38; Iter   389/  823] train: loss: 0.0147696
[Epoch 38; Iter   419/  823] train: loss: 0.0154290
[Epoch 38; Iter   449/  823] train: loss: 0.1546508
[Epoch 38; Iter   479/  823] train: loss: 0.1257058
[Epoch 38; Iter   509/  823] train: loss: 0.0104866
[Epoch 38; Iter   539/  823] train: loss: 0.0439347
[Epoch 38; Iter   569/  823] train: loss: 0.0498248
[Epoch 38; Iter   599/  823] train: loss: 0.0678434
[Epoch 38; Iter   629/  823] train: loss: 0.0288517
[Epoch 38; Iter   659/  823] train: loss: 0.1374106
[Epoch 38; Iter   689/  823] train: loss: 0.0276554
[Epoch 38; Iter   719/  823] train: loss: 0.0792508
[Epoch 38; Iter   749/  823] train: loss: 0.0151028
[Epoch 38; Iter   779/  823] train: loss: 0.0231474
[Epoch 38; Iter   809/  823] train: loss: 0.1989401
[Epoch 38] ogbg-molhiv: 0.830954 val loss: 0.111169
[Epoch 38] ogbg-molhiv: 0.802826 test loss: 0.142387
[Epoch 39; Iter    16/  823] train: loss: 0.1160591
[Epoch 39; Iter    46/  823] train: loss: 0.1410743
[Epoch 39; Iter    76/  823] train: loss: 0.2648910
[Epoch 39; Iter   106/  823] train: loss: 0.0234598
[Epoch 39; Iter   136/  823] train: loss: 0.1600027
[Epoch 39; Iter   166/  823] train: loss: 0.0320776
[Epoch 39; Iter   196/  823] train: loss: 0.0223383
[Epoch 39; Iter   226/  823] train: loss: 0.2953115
[Epoch 39; Iter   256/  823] train: loss: 0.0540276
[Epoch 39; Iter   286/  823] train: loss: 0.0215573
[Epoch 39; Iter   316/  823] train: loss: 0.2085177
[Epoch 39; Iter   346/  823] train: loss: 0.0342671
[Epoch 39; Iter   376/  823] train: loss: 0.1726884
[Epoch 39; Iter   406/  823] train: loss: 0.2015251
[Epoch 39; Iter   436/  823] train: loss: 0.1552575
[Epoch 39; Iter   466/  823] train: loss: 0.1629098
[Epoch 39; Iter   496/  823] train: loss: 0.3701335
[Epoch 39; Iter   526/  823] train: loss: 0.0179491
[Epoch 39; Iter   556/  823] train: loss: 0.0176678
[Epoch 39; Iter   586/  823] train: loss: 0.0171957
[Epoch 39; Iter   616/  823] train: loss: 0.0180181
[Epoch 39; Iter   646/  823] train: loss: 0.0188077
[Epoch 39; Iter   676/  823] train: loss: 0.0200262
[Epoch 39; Iter   706/  823] train: loss: 0.2856885
[Epoch 39; Iter   736/  823] train: loss: 0.0139372
[Epoch 39; Iter   766/  823] train: loss: 0.1432152
[Epoch 39; Iter   796/  823] train: loss: 0.0246822
[Epoch 39] ogbg-molhiv: 0.829704 val loss: 0.119330
[Epoch 39] ogbg-molhiv: 0.794501 test loss: 0.157289
[Epoch 40; Iter     3/  823] train: loss: 0.0453917
[Epoch 40; Iter    33/  823] train: loss: 0.0356377
[Epoch 40; Iter    63/  823] train: loss: 0.0286851
[Epoch 40; Iter    93/  823] train: loss: 0.0523928
[Epoch 40; Iter   123/  823] train: loss: 0.0728656
[Epoch 40; Iter   153/  823] train: loss: 0.0930731
[Epoch 40; Iter   183/  823] train: loss: 0.0161981
[Epoch 40; Iter   213/  823] train: loss: 0.2221013
[Epoch 40; Iter   243/  823] train: loss: 0.0719038
[Epoch 40; Iter   273/  823] train: loss: 0.0385318
[Epoch 40; Iter   303/  823] train: loss: 0.0178322
[Epoch 40; Iter   333/  823] train: loss: 0.1761203
[Epoch 40; Iter   363/  823] train: loss: 0.1358358
[Epoch 40; Iter   393/  823] train: loss: 0.0466569
[Epoch 40; Iter   423/  823] train: loss: 0.0268826
[Epoch 40; Iter   453/  823] train: loss: 0.1131349
[Epoch 40; Iter   483/  823] train: loss: 0.1028930
[Epoch 40; Iter   513/  823] train: loss: 0.0841806
[Epoch 40; Iter   543/  823] train: loss: 0.0489753
[Epoch 40; Iter   573/  823] train: loss: 0.0162168
[Epoch 40; Iter   603/  823] train: loss: 0.2239143
[Epoch 40; Iter   633/  823] train: loss: 0.0287804
[Epoch 40; Iter   663/  823] train: loss: 0.1019352
[Epoch 40; Iter   693/  823] train: loss: 0.1602358
[Epoch 40; Iter   723/  823] train: loss: 0.0653015
[Epoch 40; Iter   753/  823] train: loss: 0.1110206
[Epoch 40; Iter   783/  823] train: loss: 0.0750621
[Epoch 40; Iter   813/  823] train: loss: 0.1211602
[Epoch 40] ogbg-molhiv: 0.833725 val loss: 0.114024
[Epoch 40] ogbg-molhiv: 0.803414 test loss: 0.126010
[Epoch 41; Iter    20/  823] train: loss: 0.0683807
[Epoch 41; Iter    50/  823] train: loss: 0.0166845
[Epoch 41; Iter    80/  823] train: loss: 0.0211230
[Epoch 41; Iter   110/  823] train: loss: 0.0268536
[Epoch 41; Iter   140/  823] train: loss: 0.0306531
[Epoch 41; Iter   170/  823] train: loss: 0.0878408
[Epoch 41; Iter   200/  823] train: loss: 0.1066310
[Epoch 41; Iter   230/  823] train: loss: 0.0991968
[Epoch 41; Iter   260/  823] train: loss: 0.0524453
[Epoch 41; Iter   290/  823] train: loss: 0.1337440
[Epoch 41; Iter   320/  823] train: loss: 0.0171532
[Epoch 41; Iter   350/  823] train: loss: 0.1552761
[Epoch 41; Iter   380/  823] train: loss: 0.0175385
[Epoch 41; Iter   410/  823] train: loss: 0.1139804
[Epoch 41; Iter   440/  823] train: loss: 0.0650237
[Epoch 41; Iter   470/  823] train: loss: 0.0150984
[Epoch 41; Iter   500/  823] train: loss: 0.1158226
[Epoch 41; Iter   530/  823] train: loss: 0.1059918
[Epoch 41; Iter   560/  823] train: loss: 0.1343381
[Epoch 41; Iter   590/  823] train: loss: 0.1351572
[Epoch 41; Iter   620/  823] train: loss: 0.0868278
[Epoch 41; Iter   650/  823] train: loss: 0.0198902
[Epoch 41; Iter   680/  823] train: loss: 0.0266520
[Epoch 41; Iter   710/  823] train: loss: 0.0893247
[Epoch 41; Iter   740/  823] train: loss: 0.1101753
[Epoch 41; Iter   770/  823] train: loss: 0.1338336
[Epoch 41; Iter   800/  823] train: loss: 0.0687573
[Epoch 41] ogbg-molhiv: 0.836353 val loss: 0.117570
[Epoch 41] ogbg-molhiv: 0.805160 test loss: 0.145970
[Epoch 42; Iter     7/  823] train: loss: 0.2224307
[Epoch 42; Iter    37/  823] train: loss: 0.0593434
[Epoch 42; Iter    67/  823] train: loss: 0.0227050
[Epoch 42; Iter    97/  823] train: loss: 0.0764373
[Epoch 42; Iter   127/  823] train: loss: 0.1330959
[Epoch 42; Iter   157/  823] train: loss: 0.1376215
[Epoch 36; Iter   775/  823] train: loss: 0.0508693
[Epoch 36; Iter   805/  823] train: loss: 0.0340454
[Epoch 36] ogbg-molhiv: 0.834122 val loss: 0.153758
[Epoch 36] ogbg-molhiv: 0.801287 test loss: 0.187361
[Epoch 37; Iter    12/  823] train: loss: 0.1075220
[Epoch 37; Iter    42/  823] train: loss: 0.0271906
[Epoch 37; Iter    72/  823] train: loss: 0.0115335
[Epoch 37; Iter   102/  823] train: loss: 0.0088889
[Epoch 37; Iter   132/  823] train: loss: 0.0183381
[Epoch 37; Iter   162/  823] train: loss: 0.0151006
[Epoch 37; Iter   192/  823] train: loss: 0.0604386
[Epoch 37; Iter   222/  823] train: loss: 0.0571706
[Epoch 37; Iter   252/  823] train: loss: 0.0767065
[Epoch 37; Iter   282/  823] train: loss: 0.0469138
[Epoch 37; Iter   312/  823] train: loss: 0.0477146
[Epoch 37; Iter   342/  823] train: loss: 0.0968695
[Epoch 37; Iter   372/  823] train: loss: 0.0371038
[Epoch 37; Iter   402/  823] train: loss: 0.1263089
[Epoch 37; Iter   432/  823] train: loss: 0.0129027
[Epoch 37; Iter   462/  823] train: loss: 0.0491020
[Epoch 37; Iter   492/  823] train: loss: 0.0768393
[Epoch 37; Iter   522/  823] train: loss: 0.0218395
[Epoch 37; Iter   552/  823] train: loss: 0.1449638
[Epoch 37; Iter   582/  823] train: loss: 0.0727099
[Epoch 37; Iter   612/  823] train: loss: 0.0223115
[Epoch 37; Iter   642/  823] train: loss: 0.1653160
[Epoch 37; Iter   672/  823] train: loss: 0.0171142
[Epoch 37; Iter   702/  823] train: loss: 0.0179359
[Epoch 37; Iter   732/  823] train: loss: 0.2171721
[Epoch 37; Iter   762/  823] train: loss: 0.1981775
[Epoch 37; Iter   792/  823] train: loss: 0.0300779
[Epoch 37; Iter   822/  823] train: loss: 0.0665853
[Epoch 37] ogbg-molhiv: 0.835862 val loss: 0.174566
[Epoch 37] ogbg-molhiv: 0.806962 test loss: 0.411678
[Epoch 38; Iter    29/  823] train: loss: 0.0213874
[Epoch 38; Iter    59/  823] train: loss: 0.0150867
[Epoch 38; Iter    89/  823] train: loss: 0.0217838
[Epoch 38; Iter   119/  823] train: loss: 0.0157418
[Epoch 38; Iter   149/  823] train: loss: 0.0191050
[Epoch 38; Iter   179/  823] train: loss: 0.0646366
[Epoch 38; Iter   209/  823] train: loss: 0.0426871
[Epoch 38; Iter   239/  823] train: loss: 0.0294120
[Epoch 38; Iter   269/  823] train: loss: 0.0463040
[Epoch 38; Iter   299/  823] train: loss: 0.0099962
[Epoch 38; Iter   329/  823] train: loss: 0.0351803
[Epoch 38; Iter   359/  823] train: loss: 0.0175984
[Epoch 38; Iter   389/  823] train: loss: 0.2521643
[Epoch 38; Iter   419/  823] train: loss: 0.0109125
[Epoch 38; Iter   449/  823] train: loss: 0.0280084
[Epoch 38; Iter   479/  823] train: loss: 0.0282286
[Epoch 38; Iter   509/  823] train: loss: 0.3145163
[Epoch 38; Iter   539/  823] train: loss: 0.0483934
[Epoch 38; Iter   569/  823] train: loss: 0.0191067
[Epoch 38; Iter   599/  823] train: loss: 0.0118586
[Epoch 38; Iter   629/  823] train: loss: 0.2587295
[Epoch 38; Iter   659/  823] train: loss: 0.0120787
[Epoch 38; Iter   689/  823] train: loss: 0.0762295
[Epoch 38; Iter   719/  823] train: loss: 0.0218280
[Epoch 38; Iter   749/  823] train: loss: 0.0526783
[Epoch 38; Iter   779/  823] train: loss: 0.1068030
[Epoch 38; Iter   809/  823] train: loss: 0.0192528
[Epoch 38] ogbg-molhiv: 0.839545 val loss: 0.117034
[Epoch 38] ogbg-molhiv: 0.806818 test loss: 0.241333
[Epoch 39; Iter    16/  823] train: loss: 0.0175661
[Epoch 39; Iter    46/  823] train: loss: 0.0278269
[Epoch 39; Iter    76/  823] train: loss: 0.1060968
[Epoch 39; Iter   106/  823] train: loss: 0.0812947
[Epoch 39; Iter   136/  823] train: loss: 0.0781051
[Epoch 39; Iter   166/  823] train: loss: 0.0188881
[Epoch 39; Iter   196/  823] train: loss: 0.0217591
[Epoch 39; Iter   226/  823] train: loss: 0.0402999
[Epoch 39; Iter   256/  823] train: loss: 0.0335943
[Epoch 39; Iter   286/  823] train: loss: 0.1975407
[Epoch 39; Iter   316/  823] train: loss: 0.1850389
[Epoch 39; Iter   346/  823] train: loss: 0.1489440
[Epoch 39; Iter   376/  823] train: loss: 0.0293993
[Epoch 39; Iter   406/  823] train: loss: 0.0617131
[Epoch 39; Iter   436/  823] train: loss: 0.0943730
[Epoch 39; Iter   466/  823] train: loss: 0.0467197
[Epoch 39; Iter   496/  823] train: loss: 0.1274376
[Epoch 39; Iter   526/  823] train: loss: 0.1841868
[Epoch 39; Iter   556/  823] train: loss: 0.0090630
[Epoch 39; Iter   586/  823] train: loss: 0.0193933
[Epoch 39; Iter   616/  823] train: loss: 0.0252116
[Epoch 39; Iter   646/  823] train: loss: 0.0196326
[Epoch 39; Iter   676/  823] train: loss: 0.0142501
[Epoch 39; Iter   706/  823] train: loss: 0.0291602
[Epoch 39; Iter   736/  823] train: loss: 0.0563884
[Epoch 39; Iter   766/  823] train: loss: 0.0247446
[Epoch 39; Iter   796/  823] train: loss: 0.2712407
[Epoch 39] ogbg-molhiv: 0.837310 val loss: 0.134492
[Epoch 39] ogbg-molhiv: 0.811231 test loss: 0.214999
[Epoch 40; Iter     3/  823] train: loss: 0.1922442
[Epoch 40; Iter    33/  823] train: loss: 0.0986681
[Epoch 40; Iter    63/  823] train: loss: 0.0164127
[Epoch 40; Iter    93/  823] train: loss: 0.0948325
[Epoch 40; Iter   123/  823] train: loss: 0.1313983
[Epoch 40; Iter   153/  823] train: loss: 0.1604719
[Epoch 40; Iter   183/  823] train: loss: 0.0312530
[Epoch 40; Iter   213/  823] train: loss: 0.1423263
[Epoch 40; Iter   243/  823] train: loss: 0.0908910
[Epoch 40; Iter   273/  823] train: loss: 0.0567319
[Epoch 40; Iter   303/  823] train: loss: 0.1226050
[Epoch 40; Iter   333/  823] train: loss: 0.0087597
[Epoch 40; Iter   363/  823] train: loss: 0.0308405
[Epoch 40; Iter   393/  823] train: loss: 0.0435080
[Epoch 40; Iter   423/  823] train: loss: 0.1352307
[Epoch 40; Iter   453/  823] train: loss: 0.0093847
[Epoch 40; Iter   483/  823] train: loss: 0.0231025
[Epoch 40; Iter   513/  823] train: loss: 0.0600916
[Epoch 40; Iter   543/  823] train: loss: 0.2090451
[Epoch 40; Iter   573/  823] train: loss: 0.0416890
[Epoch 40; Iter   603/  823] train: loss: 0.0235612
[Epoch 40; Iter   633/  823] train: loss: 0.0264348
[Epoch 40; Iter   663/  823] train: loss: 0.0120264
[Epoch 40; Iter   693/  823] train: loss: 0.0626451
[Epoch 40; Iter   723/  823] train: loss: 0.0791662
[Epoch 40; Iter   753/  823] train: loss: 0.0407810
[Epoch 40; Iter   783/  823] train: loss: 0.0405830
[Epoch 40; Iter   813/  823] train: loss: 0.0167619
[Epoch 40] ogbg-molhiv: 0.827979 val loss: 0.252755
[Epoch 40] ogbg-molhiv: 0.795671 test loss: 0.680723
[Epoch 41; Iter    20/  823] train: loss: 0.0914177
[Epoch 41; Iter    50/  823] train: loss: 0.0323207
[Epoch 41; Iter    80/  823] train: loss: 0.0264331
[Epoch 41; Iter   110/  823] train: loss: 0.0135450
[Epoch 41; Iter   140/  823] train: loss: 0.0131294
[Epoch 41; Iter   170/  823] train: loss: 0.0330418
[Epoch 41; Iter   200/  823] train: loss: 0.0230932
[Epoch 41; Iter   230/  823] train: loss: 0.7721009
[Epoch 41; Iter   260/  823] train: loss: 0.0138391
[Epoch 41; Iter   290/  823] train: loss: 0.1992044
[Epoch 41; Iter   320/  823] train: loss: 0.0337890
[Epoch 41; Iter   350/  823] train: loss: 0.0740369
[Epoch 41; Iter   380/  823] train: loss: 0.1261922
[Epoch 41; Iter   410/  823] train: loss: 0.1015812
[Epoch 41; Iter   440/  823] train: loss: 0.0806670
[Epoch 41; Iter   470/  823] train: loss: 0.1341937
[Epoch 41; Iter   500/  823] train: loss: 0.3071830
[Epoch 41; Iter   530/  823] train: loss: 0.0460278
[Epoch 41; Iter   560/  823] train: loss: 0.2933008
[Epoch 41; Iter   590/  823] train: loss: 0.0177207
[Epoch 41; Iter   620/  823] train: loss: 0.0338772
[Epoch 41; Iter   650/  823] train: loss: 0.0837916
[Epoch 41; Iter   680/  823] train: loss: 0.0250892
[Epoch 41; Iter   710/  823] train: loss: 0.0990287
[Epoch 41; Iter   740/  823] train: loss: 0.0115819
[Epoch 41; Iter   770/  823] train: loss: 0.0571934
[Epoch 41; Iter   800/  823] train: loss: 0.1452046
[Epoch 41] ogbg-molhiv: 0.837324 val loss: 0.141291
[Epoch 41] ogbg-molhiv: 0.808418 test loss: 0.278975
[Epoch 42; Iter     7/  823] train: loss: 0.1119688
[Epoch 42; Iter    37/  823] train: loss: 0.0244660
[Epoch 42; Iter    67/  823] train: loss: 0.0096665
[Epoch 42; Iter    97/  823] train: loss: 0.1164608
[Epoch 42; Iter   127/  823] train: loss: 0.0936982
[Epoch 42; Iter   157/  823] train: loss: 0.1716823
[Epoch 36; Iter   720/  960] train: loss: 0.0183065
[Epoch 36; Iter   750/  960] train: loss: 0.0310857
[Epoch 36; Iter   780/  960] train: loss: 0.0726535
[Epoch 36; Iter   810/  960] train: loss: 0.1308499
[Epoch 36; Iter   840/  960] train: loss: 0.0264997
[Epoch 36; Iter   870/  960] train: loss: 0.0533042
[Epoch 36; Iter   900/  960] train: loss: 0.0505231
[Epoch 36; Iter   930/  960] train: loss: 0.0715103
[Epoch 36; Iter   960/  960] train: loss: 0.1755089
[Epoch 36] ogbg-molhiv: 0.814709 val loss: 0.192251
[Epoch 36] ogbg-molhiv: 0.813826 test loss: 0.132240
[Epoch 37; Iter    30/  960] train: loss: 0.0577518
[Epoch 37; Iter    60/  960] train: loss: 0.0175138
[Epoch 37; Iter    90/  960] train: loss: 0.0202574
[Epoch 37; Iter   120/  960] train: loss: 0.1196477
[Epoch 37; Iter   150/  960] train: loss: 0.0116170
[Epoch 37; Iter   180/  960] train: loss: 0.0115351
[Epoch 37; Iter   210/  960] train: loss: 0.0148726
[Epoch 37; Iter   240/  960] train: loss: 0.1503926
[Epoch 37; Iter   270/  960] train: loss: 0.0298475
[Epoch 37; Iter   300/  960] train: loss: 0.0587156
[Epoch 37; Iter   330/  960] train: loss: 0.3011682
[Epoch 37; Iter   360/  960] train: loss: 0.0083936
[Epoch 37; Iter   390/  960] train: loss: 0.0249527
[Epoch 37; Iter   420/  960] train: loss: 0.1072535
[Epoch 37; Iter   450/  960] train: loss: 0.2781040
[Epoch 37; Iter   480/  960] train: loss: 0.0574181
[Epoch 37; Iter   510/  960] train: loss: 0.0256795
[Epoch 37; Iter   540/  960] train: loss: 0.0184870
[Epoch 37; Iter   570/  960] train: loss: 0.0200670
[Epoch 37; Iter   600/  960] train: loss: 0.0267056
[Epoch 37; Iter   630/  960] train: loss: 0.2126964
[Epoch 37; Iter   660/  960] train: loss: 0.0397522
[Epoch 37; Iter   690/  960] train: loss: 0.2046038
[Epoch 37; Iter   720/  960] train: loss: 0.0129205
[Epoch 37; Iter   750/  960] train: loss: 0.0830904
[Epoch 37; Iter   780/  960] train: loss: 0.0702886
[Epoch 37; Iter   810/  960] train: loss: 0.1417851
[Epoch 37; Iter   840/  960] train: loss: 0.0189390
[Epoch 37; Iter   870/  960] train: loss: 0.0121644
[Epoch 37; Iter   900/  960] train: loss: 0.0161167
[Epoch 37; Iter   930/  960] train: loss: 0.0241836
[Epoch 37; Iter   960/  960] train: loss: 0.2479015
[Epoch 37] ogbg-molhiv: 0.825749 val loss: 0.128648
[Epoch 37] ogbg-molhiv: 0.821877 test loss: 0.123324
[Epoch 38; Iter    30/  960] train: loss: 0.2382334
[Epoch 38; Iter    60/  960] train: loss: 0.0289497
[Epoch 38; Iter    90/  960] train: loss: 0.0649063
[Epoch 38; Iter   120/  960] train: loss: 0.0297644
[Epoch 38; Iter   150/  960] train: loss: 0.3100269
[Epoch 38; Iter   180/  960] train: loss: 0.0959356
[Epoch 38; Iter   210/  960] train: loss: 0.0810443
[Epoch 38; Iter   240/  960] train: loss: 0.2181406
[Epoch 38; Iter   270/  960] train: loss: 0.0399126
[Epoch 38; Iter   300/  960] train: loss: 0.0118963
[Epoch 38; Iter   330/  960] train: loss: 0.0406868
[Epoch 38; Iter   360/  960] train: loss: 0.1980158
[Epoch 38; Iter   390/  960] train: loss: 0.0283927
[Epoch 38; Iter   420/  960] train: loss: 0.1876177
[Epoch 38; Iter   450/  960] train: loss: 0.0344531
[Epoch 38; Iter   480/  960] train: loss: 0.1143854
[Epoch 38; Iter   510/  960] train: loss: 0.0273806
[Epoch 38; Iter   540/  960] train: loss: 0.0171169
[Epoch 38; Iter   570/  960] train: loss: 0.2707162
[Epoch 38; Iter   600/  960] train: loss: 0.1982923
[Epoch 38; Iter   630/  960] train: loss: 0.0227291
[Epoch 38; Iter   660/  960] train: loss: 0.0142602
[Epoch 38; Iter   690/  960] train: loss: 0.0330826
[Epoch 38; Iter   720/  960] train: loss: 0.0085898
[Epoch 38; Iter   750/  960] train: loss: 0.0684505
[Epoch 38; Iter   780/  960] train: loss: 0.3529580
[Epoch 38; Iter   810/  960] train: loss: 0.0964075
[Epoch 38; Iter   840/  960] train: loss: 0.0380835
[Epoch 38; Iter   870/  960] train: loss: 0.0089565
[Epoch 38; Iter   900/  960] train: loss: 0.1532374
[Epoch 38; Iter   930/  960] train: loss: 0.0226662
[Epoch 38; Iter   960/  960] train: loss: 0.0065925
[Epoch 38] ogbg-molhiv: 0.810866 val loss: 0.189614
[Epoch 38] ogbg-molhiv: 0.817171 test loss: 0.129327
[Epoch 39; Iter    30/  960] train: loss: 0.0286723
[Epoch 39; Iter    60/  960] train: loss: 0.0154740
[Epoch 39; Iter    90/  960] train: loss: 0.1084052
[Epoch 39; Iter   120/  960] train: loss: 0.0792918
[Epoch 39; Iter   150/  960] train: loss: 0.2207393
[Epoch 39; Iter   180/  960] train: loss: 0.0212517
[Epoch 39; Iter   210/  960] train: loss: 0.0677854
[Epoch 39; Iter   240/  960] train: loss: 0.0379874
[Epoch 39; Iter   270/  960] train: loss: 0.1679881
[Epoch 39; Iter   300/  960] train: loss: 0.0464171
[Epoch 39; Iter   330/  960] train: loss: 0.0252694
[Epoch 39; Iter   360/  960] train: loss: 0.1005632
[Epoch 39; Iter   390/  960] train: loss: 0.0244606
[Epoch 39; Iter   420/  960] train: loss: 0.1626785
[Epoch 39; Iter   450/  960] train: loss: 0.0112716
[Epoch 39; Iter   480/  960] train: loss: 0.1270522
[Epoch 39; Iter   510/  960] train: loss: 0.0078425
[Epoch 39; Iter   540/  960] train: loss: 0.1795235
[Epoch 39; Iter   570/  960] train: loss: 0.0062274
[Epoch 39; Iter   600/  960] train: loss: 0.0359355
[Epoch 39; Iter   630/  960] train: loss: 0.1530722
[Epoch 39; Iter   660/  960] train: loss: 0.0505222
[Epoch 39; Iter   690/  960] train: loss: 0.0847295
[Epoch 39; Iter   720/  960] train: loss: 0.0603750
[Epoch 39; Iter   750/  960] train: loss: 0.0916960
[Epoch 39; Iter   780/  960] train: loss: 0.2036638
[Epoch 39; Iter   810/  960] train: loss: 0.1088181
[Epoch 39; Iter   840/  960] train: loss: 0.0579036
[Epoch 39; Iter   870/  960] train: loss: 0.1199498
[Epoch 39; Iter   900/  960] train: loss: 0.0574306
[Epoch 39; Iter   930/  960] train: loss: 0.1088804
[Epoch 39; Iter   960/  960] train: loss: 0.1819431
[Epoch 39] ogbg-molhiv: 0.812304 val loss: 0.137074
[Epoch 39] ogbg-molhiv: 0.811803 test loss: 0.129562
[Epoch 40; Iter    30/  960] train: loss: 0.4195405
[Epoch 40; Iter    60/  960] train: loss: 0.2469190
[Epoch 40; Iter    90/  960] train: loss: 0.0251724
[Epoch 40; Iter   120/  960] train: loss: 0.0121249
[Epoch 40; Iter   150/  960] train: loss: 0.1456964
[Epoch 40; Iter   180/  960] train: loss: 0.0273162
[Epoch 40; Iter   210/  960] train: loss: 0.0142743
[Epoch 40; Iter   240/  960] train: loss: 0.1723790
[Epoch 40; Iter   270/  960] train: loss: 0.0515751
[Epoch 40; Iter   300/  960] train: loss: 0.1294498
[Epoch 40; Iter   330/  960] train: loss: 0.0154146
[Epoch 40; Iter   360/  960] train: loss: 0.0247968
[Epoch 40; Iter   390/  960] train: loss: 0.0319450
[Epoch 40; Iter   420/  960] train: loss: 0.0086229
[Epoch 40; Iter   450/  960] train: loss: 0.0096958
[Epoch 40; Iter   480/  960] train: loss: 0.0530672
[Epoch 40; Iter   510/  960] train: loss: 0.0119111
[Epoch 40; Iter   540/  960] train: loss: 0.0160718
[Epoch 40; Iter   570/  960] train: loss: 0.1135367
[Epoch 40; Iter   600/  960] train: loss: 0.0265880
[Epoch 40; Iter   630/  960] train: loss: 0.0493626
[Epoch 40; Iter   660/  960] train: loss: 0.0307993
[Epoch 40; Iter   690/  960] train: loss: 0.0486056
[Epoch 40; Iter   720/  960] train: loss: 0.0805271
[Epoch 40; Iter   750/  960] train: loss: 0.0119914
[Epoch 40; Iter   780/  960] train: loss: 0.1614138
[Epoch 40; Iter   810/  960] train: loss: 0.0495238
[Epoch 40; Iter   840/  960] train: loss: 0.0892354
[Epoch 40; Iter   870/  960] train: loss: 0.0539359
[Epoch 40; Iter   900/  960] train: loss: 0.1801140
[Epoch 40; Iter   930/  960] train: loss: 0.0125904
[Epoch 40; Iter   960/  960] train: loss: 0.0063058
[Epoch 40] ogbg-molhiv: 0.827690 val loss: 0.131282
[Epoch 40] ogbg-molhiv: 0.811907 test loss: 0.126846
[Epoch 41; Iter    30/  960] train: loss: 0.0273458
[Epoch 41; Iter    60/  960] train: loss: 0.0227814
[Epoch 41; Iter    90/  960] train: loss: 0.0398162
[Epoch 41; Iter   120/  960] train: loss: 0.1118832
[Epoch 41; Iter   150/  960] train: loss: 0.0416802
[Epoch 41; Iter   180/  960] train: loss: 0.0287761
[Epoch 41; Iter   210/  960] train: loss: 0.0450343
[Epoch 41; Iter   240/  960] train: loss: 0.0429422
[Epoch 41; Iter   270/  960] train: loss: 0.1774384
[Epoch 41; Iter   300/  960] train: loss: 0.0091930
[Epoch 36; Iter   775/  823] train: loss: 0.0113733
[Epoch 36; Iter   805/  823] train: loss: 0.0831762
[Epoch 36] ogbg-molhiv: 0.825296 val loss: 0.135884
[Epoch 36] ogbg-molhiv: 0.796553 test loss: 0.127163
[Epoch 37; Iter    12/  823] train: loss: 0.0235116
[Epoch 37; Iter    42/  823] train: loss: 0.1624255
[Epoch 37; Iter    72/  823] train: loss: 0.2219069
[Epoch 37; Iter   102/  823] train: loss: 0.2470228
[Epoch 37; Iter   132/  823] train: loss: 0.0105137
[Epoch 37; Iter   162/  823] train: loss: 0.0389455
[Epoch 37; Iter   192/  823] train: loss: 0.0115964
[Epoch 37; Iter   222/  823] train: loss: 0.0202972
[Epoch 37; Iter   252/  823] train: loss: 0.1144462
[Epoch 37; Iter   282/  823] train: loss: 0.1102077
[Epoch 37; Iter   312/  823] train: loss: 0.0146130
[Epoch 37; Iter   342/  823] train: loss: 0.0093546
[Epoch 37; Iter   372/  823] train: loss: 0.1085291
[Epoch 37; Iter   402/  823] train: loss: 0.0651254
[Epoch 37; Iter   432/  823] train: loss: 0.1026863
[Epoch 37; Iter   462/  823] train: loss: 0.1269214
[Epoch 37; Iter   492/  823] train: loss: 0.0130697
[Epoch 37; Iter   522/  823] train: loss: 0.0484930
[Epoch 37; Iter   552/  823] train: loss: 0.0293744
[Epoch 37; Iter   582/  823] train: loss: 0.2498282
[Epoch 37; Iter   612/  823] train: loss: 0.0792867
[Epoch 37; Iter   642/  823] train: loss: 0.1181324
[Epoch 37; Iter   672/  823] train: loss: 0.1893150
[Epoch 37; Iter   702/  823] train: loss: 0.0606923
[Epoch 37; Iter   732/  823] train: loss: 0.0086620
[Epoch 37; Iter   762/  823] train: loss: 0.3056963
[Epoch 37; Iter   792/  823] train: loss: 0.0196622
[Epoch 37; Iter   822/  823] train: loss: 0.2383189
[Epoch 37] ogbg-molhiv: 0.832037 val loss: 0.272562
[Epoch 37] ogbg-molhiv: 0.788114 test loss: 0.223416
[Epoch 38; Iter    29/  823] train: loss: 0.0818448
[Epoch 38; Iter    59/  823] train: loss: 0.0713602
[Epoch 38; Iter    89/  823] train: loss: 0.1908379
[Epoch 38; Iter   119/  823] train: loss: 0.0423816
[Epoch 38; Iter   149/  823] train: loss: 0.0149459
[Epoch 38; Iter   179/  823] train: loss: 0.0353961
[Epoch 38; Iter   209/  823] train: loss: 0.1417917
[Epoch 38; Iter   239/  823] train: loss: 0.2021265
[Epoch 38; Iter   269/  823] train: loss: 0.0388528
[Epoch 38; Iter   299/  823] train: loss: 0.0373717
[Epoch 38; Iter   329/  823] train: loss: 0.1060974
[Epoch 38; Iter   359/  823] train: loss: 0.0175270
[Epoch 38; Iter   389/  823] train: loss: 0.0247494
[Epoch 38; Iter   419/  823] train: loss: 0.0374658
[Epoch 38; Iter   449/  823] train: loss: 0.0816889
[Epoch 38; Iter   479/  823] train: loss: 0.0503809
[Epoch 38; Iter   509/  823] train: loss: 0.1198228
[Epoch 38; Iter   539/  823] train: loss: 0.0496373
[Epoch 38; Iter   569/  823] train: loss: 0.0405820
[Epoch 38; Iter   599/  823] train: loss: 0.0255812
[Epoch 38; Iter   629/  823] train: loss: 0.0126609
[Epoch 38; Iter   659/  823] train: loss: 0.0584232
[Epoch 38; Iter   689/  823] train: loss: 0.0193654
[Epoch 38; Iter   719/  823] train: loss: 0.0540725
[Epoch 38; Iter   749/  823] train: loss: 0.0305025
[Epoch 38; Iter   779/  823] train: loss: 0.0479460
[Epoch 38; Iter   809/  823] train: loss: 0.0085862
[Epoch 38] ogbg-molhiv: 0.835945 val loss: 0.124222
[Epoch 38] ogbg-molhiv: 0.798687 test loss: 0.140309
[Epoch 39; Iter    16/  823] train: loss: 0.1086885
[Epoch 39; Iter    46/  823] train: loss: 0.0097695
[Epoch 39; Iter    76/  823] train: loss: 0.0121408
[Epoch 39; Iter   106/  823] train: loss: 0.0633148
[Epoch 39; Iter   136/  823] train: loss: 0.0281541
[Epoch 39; Iter   166/  823] train: loss: 0.0154794
[Epoch 39; Iter   196/  823] train: loss: 0.0396417
[Epoch 39; Iter   226/  823] train: loss: 0.0348722
[Epoch 39; Iter   256/  823] train: loss: 0.0307967
[Epoch 39; Iter   286/  823] train: loss: 0.0069719
[Epoch 39; Iter   316/  823] train: loss: 0.0458954
[Epoch 39; Iter   346/  823] train: loss: 0.1037202
[Epoch 39; Iter   376/  823] train: loss: 0.0343944
[Epoch 39; Iter   406/  823] train: loss: 0.0458677
[Epoch 39; Iter   436/  823] train: loss: 0.1058953
[Epoch 39; Iter   466/  823] train: loss: 0.0406414
[Epoch 39; Iter   496/  823] train: loss: 0.0232911
[Epoch 39; Iter   526/  823] train: loss: 0.0603959
[Epoch 39; Iter   556/  823] train: loss: 0.0177430
[Epoch 39; Iter   586/  823] train: loss: 0.0872190
[Epoch 39; Iter   616/  823] train: loss: 0.0177667
[Epoch 39; Iter   646/  823] train: loss: 0.0101180
[Epoch 39; Iter   676/  823] train: loss: 0.0383108
[Epoch 39; Iter   706/  823] train: loss: 0.0204532
[Epoch 39; Iter   736/  823] train: loss: 0.0209148
[Epoch 39; Iter   766/  823] train: loss: 0.0127316
[Epoch 39; Iter   796/  823] train: loss: 0.0248120
[Epoch 39] ogbg-molhiv: 0.840924 val loss: 0.149616
[Epoch 39] ogbg-molhiv: 0.796223 test loss: 0.202952
[Epoch 40; Iter     3/  823] train: loss: 0.0637326
[Epoch 40; Iter    33/  823] train: loss: 0.0119454
[Epoch 40; Iter    63/  823] train: loss: 0.1730585
[Epoch 40; Iter    93/  823] train: loss: 0.1532897
[Epoch 40; Iter   123/  823] train: loss: 0.0226585
[Epoch 40; Iter   153/  823] train: loss: 0.0680558
[Epoch 40; Iter   183/  823] train: loss: 0.0528575
[Epoch 40; Iter   213/  823] train: loss: 0.0274971
[Epoch 40; Iter   243/  823] train: loss: 0.0892176
[Epoch 40; Iter   273/  823] train: loss: 0.0564886
[Epoch 40; Iter   303/  823] train: loss: 0.1593083
[Epoch 40; Iter   333/  823] train: loss: 0.0346594
[Epoch 40; Iter   363/  823] train: loss: 0.0226731
[Epoch 40; Iter   393/  823] train: loss: 0.0164820
[Epoch 40; Iter   423/  823] train: loss: 0.0252872
[Epoch 40; Iter   453/  823] train: loss: 0.0167353
[Epoch 40; Iter   483/  823] train: loss: 0.0155594
[Epoch 40; Iter   513/  823] train: loss: 0.1224898
[Epoch 40; Iter   543/  823] train: loss: 0.0334493
[Epoch 40; Iter   573/  823] train: loss: 0.0171931
[Epoch 40; Iter   603/  823] train: loss: 0.0281392
[Epoch 40; Iter   633/  823] train: loss: 0.0120131
[Epoch 40; Iter   663/  823] train: loss: 0.0167763
[Epoch 40; Iter   693/  823] train: loss: 0.0218678
[Epoch 40; Iter   723/  823] train: loss: 0.1018074
[Epoch 40; Iter   753/  823] train: loss: 0.0207726
[Epoch 40; Iter   783/  823] train: loss: 0.0095598
[Epoch 40; Iter   813/  823] train: loss: 0.0841373
[Epoch 40] ogbg-molhiv: 0.829214 val loss: 0.422279
[Epoch 40] ogbg-molhiv: 0.795776 test loss: 0.202513
[Epoch 41; Iter    20/  823] train: loss: 0.0127870
[Epoch 41; Iter    50/  823] train: loss: 0.0092900
[Epoch 41; Iter    80/  823] train: loss: 0.0160864
[Epoch 41; Iter   110/  823] train: loss: 0.0741547
[Epoch 41; Iter   140/  823] train: loss: 0.0107898
[Epoch 41; Iter   170/  823] train: loss: 0.0082100
[Epoch 41; Iter   200/  823] train: loss: 0.0105894
[Epoch 41; Iter   230/  823] train: loss: 0.0197623
[Epoch 41; Iter   260/  823] train: loss: 0.0953836
[Epoch 41; Iter   290/  823] train: loss: 0.0347530
[Epoch 41; Iter   320/  823] train: loss: 0.0359948
[Epoch 41; Iter   350/  823] train: loss: 0.0524769
[Epoch 41; Iter   380/  823] train: loss: 0.0187508
[Epoch 41; Iter   410/  823] train: loss: 0.0110459
[Epoch 41; Iter   440/  823] train: loss: 0.0237525
[Epoch 41; Iter   470/  823] train: loss: 0.0194668
[Epoch 41; Iter   500/  823] train: loss: 0.0193274
[Epoch 41; Iter   530/  823] train: loss: 0.0159031
[Epoch 41; Iter   560/  823] train: loss: 0.0211828
[Epoch 41; Iter   590/  823] train: loss: 0.1783944
[Epoch 41; Iter   620/  823] train: loss: 0.0051039
[Epoch 41; Iter   650/  823] train: loss: 0.0121718
[Epoch 41; Iter   680/  823] train: loss: 0.0620413
[Epoch 41; Iter   710/  823] train: loss: 0.0093659
[Epoch 41; Iter   740/  823] train: loss: 0.0453464
[Epoch 41; Iter   770/  823] train: loss: 0.0231884
[Epoch 41; Iter   800/  823] train: loss: 0.0941080
[Epoch 41] ogbg-molhiv: 0.838831 val loss: 0.148976
[Epoch 41] ogbg-molhiv: 0.793847 test loss: 0.211189
[Epoch 42; Iter     7/  823] train: loss: 0.0176004
[Epoch 42; Iter    37/  823] train: loss: 0.1027625
[Epoch 42; Iter    67/  823] train: loss: 0.0584795
[Epoch 42; Iter    97/  823] train: loss: 0.0462566
[Epoch 42; Iter   127/  823] train: loss: 0.0207366
[Epoch 42; Iter   157/  823] train: loss: 0.0114321
[Epoch 36; Iter   720/  960] train: loss: 0.0824976
[Epoch 36; Iter   750/  960] train: loss: 0.0295308
[Epoch 36; Iter   780/  960] train: loss: 0.0450842
[Epoch 36; Iter   810/  960] train: loss: 0.0104971
[Epoch 36; Iter   840/  960] train: loss: 0.1264338
[Epoch 36; Iter   870/  960] train: loss: 0.0251273
[Epoch 36; Iter   900/  960] train: loss: 0.0657857
[Epoch 36; Iter   930/  960] train: loss: 0.0263730
[Epoch 36; Iter   960/  960] train: loss: 0.0085836
[Epoch 36] ogbg-molhiv: 0.831461 val loss: 0.138615
[Epoch 36] ogbg-molhiv: 0.823814 test loss: 0.134565
[Epoch 37; Iter    30/  960] train: loss: 0.0169646
[Epoch 37; Iter    60/  960] train: loss: 0.0415636
[Epoch 37; Iter    90/  960] train: loss: 0.0366322
[Epoch 37; Iter   120/  960] train: loss: 0.0345398
[Epoch 37; Iter   150/  960] train: loss: 0.0115766
[Epoch 37; Iter   180/  960] train: loss: 0.1065582
[Epoch 37; Iter   210/  960] train: loss: 0.0134107
[Epoch 37; Iter   240/  960] train: loss: 0.0200483
[Epoch 37; Iter   270/  960] train: loss: 0.1252465
[Epoch 37; Iter   300/  960] train: loss: 0.0090483
[Epoch 37; Iter   330/  960] train: loss: 0.1517880
[Epoch 37; Iter   360/  960] train: loss: 0.0666535
[Epoch 37; Iter   390/  960] train: loss: 0.0218395
[Epoch 37; Iter   420/  960] train: loss: 0.0085640
[Epoch 37; Iter   450/  960] train: loss: 0.0279413
[Epoch 37; Iter   480/  960] train: loss: 0.1124199
[Epoch 37; Iter   510/  960] train: loss: 0.0671176
[Epoch 37; Iter   540/  960] train: loss: 0.0084076
[Epoch 37; Iter   570/  960] train: loss: 0.0296277
[Epoch 37; Iter   600/  960] train: loss: 0.0203831
[Epoch 37; Iter   630/  960] train: loss: 0.0848249
[Epoch 37; Iter   660/  960] train: loss: 0.0552996
[Epoch 37; Iter   690/  960] train: loss: 0.0162344
[Epoch 37; Iter   720/  960] train: loss: 0.0548825
[Epoch 37; Iter   750/  960] train: loss: 0.3451724
[Epoch 37; Iter   780/  960] train: loss: 0.0445659
[Epoch 37; Iter   810/  960] train: loss: 0.0220104
[Epoch 37; Iter   840/  960] train: loss: 0.0106996
[Epoch 37; Iter   870/  960] train: loss: 0.0108774
[Epoch 37; Iter   900/  960] train: loss: 0.1936982
[Epoch 37; Iter   930/  960] train: loss: 0.0166630
[Epoch 37; Iter   960/  960] train: loss: 0.0694421
[Epoch 37] ogbg-molhiv: 0.822953 val loss: 0.537038
[Epoch 37] ogbg-molhiv: 0.820716 test loss: 0.390390
[Epoch 38; Iter    30/  960] train: loss: 0.0064110
[Epoch 38; Iter    60/  960] train: loss: 0.0129557
[Epoch 38; Iter    90/  960] train: loss: 0.0056474
[Epoch 38; Iter   120/  960] train: loss: 0.0180693
[Epoch 38; Iter   150/  960] train: loss: 0.0527316
[Epoch 38; Iter   180/  960] train: loss: 0.0683664
[Epoch 38; Iter   210/  960] train: loss: 0.1462793
[Epoch 38; Iter   240/  960] train: loss: 0.0092362
[Epoch 38; Iter   270/  960] train: loss: 0.0143628
[Epoch 38; Iter   300/  960] train: loss: 0.0078974
[Epoch 38; Iter   330/  960] train: loss: 0.0396329
[Epoch 38; Iter   360/  960] train: loss: 0.0120315
[Epoch 38; Iter   390/  960] train: loss: 0.0146494
[Epoch 38; Iter   420/  960] train: loss: 0.0088536
[Epoch 38; Iter   450/  960] train: loss: 0.0293696
[Epoch 38; Iter   480/  960] train: loss: 0.1222531
[Epoch 38; Iter   510/  960] train: loss: 0.0508457
[Epoch 38; Iter   540/  960] train: loss: 0.1706158
[Epoch 38; Iter   570/  960] train: loss: 0.0122000
[Epoch 38; Iter   600/  960] train: loss: 0.0623993
[Epoch 38; Iter   630/  960] train: loss: 0.0204293
[Epoch 38; Iter   660/  960] train: loss: 0.0446850
[Epoch 38; Iter   690/  960] train: loss: 0.0114130
[Epoch 38; Iter   720/  960] train: loss: 0.0561262
[Epoch 38; Iter   750/  960] train: loss: 0.1063194
[Epoch 38; Iter   780/  960] train: loss: 0.1007742
[Epoch 38; Iter   810/  960] train: loss: 0.1031205
[Epoch 38; Iter   840/  960] train: loss: 0.0265076
[Epoch 38; Iter   870/  960] train: loss: 0.0136302
[Epoch 38; Iter   900/  960] train: loss: 0.1801174
[Epoch 38; Iter   930/  960] train: loss: 0.0338650
[Epoch 38; Iter   960/  960] train: loss: 0.0136135
[Epoch 38] ogbg-molhiv: 0.833530 val loss: 0.152376
[Epoch 38] ogbg-molhiv: 0.818265 test loss: 0.150198
[Epoch 39; Iter    30/  960] train: loss: 0.0080441
[Epoch 39; Iter    60/  960] train: loss: 0.0230454
[Epoch 39; Iter    90/  960] train: loss: 0.0341286
[Epoch 39; Iter   120/  960] train: loss: 0.0178260
[Epoch 39; Iter   150/  960] train: loss: 0.0125381
[Epoch 39; Iter   180/  960] train: loss: 0.1486205
[Epoch 39; Iter   210/  960] train: loss: 0.0477882
[Epoch 39; Iter   240/  960] train: loss: 0.0334628
[Epoch 39; Iter   270/  960] train: loss: 0.1077744
[Epoch 39; Iter   300/  960] train: loss: 0.0171432
[Epoch 39; Iter   330/  960] train: loss: 0.0868407
[Epoch 39; Iter   360/  960] train: loss: 0.0413346
[Epoch 39; Iter   390/  960] train: loss: 0.0629728
[Epoch 39; Iter   420/  960] train: loss: 0.0123709
[Epoch 39; Iter   450/  960] train: loss: 0.3470939
[Epoch 39; Iter   480/  960] train: loss: 0.1508578
[Epoch 39; Iter   510/  960] train: loss: 0.0395951
[Epoch 39; Iter   540/  960] train: loss: 0.0593678
[Epoch 39; Iter   570/  960] train: loss: 0.0368167
[Epoch 39; Iter   600/  960] train: loss: 0.0265215
[Epoch 39; Iter   630/  960] train: loss: 0.0507963
[Epoch 39; Iter   660/  960] train: loss: 0.0850488
[Epoch 39; Iter   690/  960] train: loss: 0.0185062
[Epoch 39; Iter   720/  960] train: loss: 0.0957776
[Epoch 39; Iter   750/  960] train: loss: 0.0794132
[Epoch 39; Iter   780/  960] train: loss: 0.3022680
[Epoch 39; Iter   810/  960] train: loss: 0.1526420
[Epoch 39; Iter   840/  960] train: loss: 0.0453184
[Epoch 39; Iter   870/  960] train: loss: 0.1319332
[Epoch 39; Iter   900/  960] train: loss: 0.0846663
[Epoch 39; Iter   930/  960] train: loss: 0.1245726
[Epoch 39; Iter   960/  960] train: loss: 0.0480709
[Epoch 39] ogbg-molhiv: 0.831070 val loss: 0.139061
[Epoch 39] ogbg-molhiv: 0.823079 test loss: 0.136401
[Epoch 40; Iter    30/  960] train: loss: 0.0154531
[Epoch 40; Iter    60/  960] train: loss: 0.0104091
[Epoch 40; Iter    90/  960] train: loss: 0.1955134
[Epoch 40; Iter   120/  960] train: loss: 0.0604900
[Epoch 40; Iter   150/  960] train: loss: 0.0157597
[Epoch 40; Iter   180/  960] train: loss: 0.0174356
[Epoch 40; Iter   210/  960] train: loss: 0.1144217
[Epoch 40; Iter   240/  960] train: loss: 0.0748211
[Epoch 40; Iter   270/  960] train: loss: 0.0442503
[Epoch 40; Iter   300/  960] train: loss: 0.0426490
[Epoch 40; Iter   330/  960] train: loss: 0.1081564
[Epoch 40; Iter   360/  960] train: loss: 0.0776997
[Epoch 40; Iter   390/  960] train: loss: 0.0800086
[Epoch 40; Iter   420/  960] train: loss: 0.0241129
[Epoch 40; Iter   450/  960] train: loss: 0.0726947
[Epoch 40; Iter   480/  960] train: loss: 0.0345031
[Epoch 40; Iter   510/  960] train: loss: 0.0068235
[Epoch 40; Iter   540/  960] train: loss: 0.0101620
[Epoch 40; Iter   570/  960] train: loss: 0.1793803
[Epoch 40; Iter   600/  960] train: loss: 0.1554352
[Epoch 40; Iter   630/  960] train: loss: 0.0546726
[Epoch 40; Iter   660/  960] train: loss: 0.1353288
[Epoch 40; Iter   690/  960] train: loss: 0.1400453
[Epoch 40; Iter   720/  960] train: loss: 0.0505873
[Epoch 40; Iter   750/  960] train: loss: 0.0158228
[Epoch 40; Iter   780/  960] train: loss: 0.1082582
[Epoch 40; Iter   810/  960] train: loss: 0.1146727
[Epoch 40; Iter   840/  960] train: loss: 0.0128556
[Epoch 40; Iter   870/  960] train: loss: 0.0286577
[Epoch 40; Iter   900/  960] train: loss: 0.0653882
[Epoch 40; Iter   930/  960] train: loss: 0.0682867
[Epoch 40; Iter   960/  960] train: loss: 0.0129063
[Epoch 40] ogbg-molhiv: 0.809989 val loss: 0.151533
[Epoch 40] ogbg-molhiv: 0.812637 test loss: 0.140276
[Epoch 41; Iter    30/  960] train: loss: 0.0097254
[Epoch 41; Iter    60/  960] train: loss: 0.0124328
[Epoch 41; Iter    90/  960] train: loss: 0.0296774
[Epoch 41; Iter   120/  960] train: loss: 0.0314996
[Epoch 41; Iter   150/  960] train: loss: 0.1639802
[Epoch 41; Iter   180/  960] train: loss: 0.0121436
[Epoch 41; Iter   210/  960] train: loss: 0.0283612
[Epoch 41; Iter   240/  960] train: loss: 0.1110897
[Epoch 41; Iter   270/  960] train: loss: 0.0169025
[Epoch 41; Iter   300/  960] train: loss: 0.0782640
[Epoch 36; Iter   720/  960] train: loss: 0.0179670
[Epoch 36; Iter   750/  960] train: loss: 0.1579891
[Epoch 36; Iter   780/  960] train: loss: 0.0174514
[Epoch 36; Iter   810/  960] train: loss: 0.0205340
[Epoch 36; Iter   840/  960] train: loss: 0.0539274
[Epoch 36; Iter   870/  960] train: loss: 0.1849577
[Epoch 36; Iter   900/  960] train: loss: 0.1348143
[Epoch 36; Iter   930/  960] train: loss: 0.0466561
[Epoch 36; Iter   960/  960] train: loss: 0.0117616
[Epoch 36] ogbg-molhiv: 0.803295 val loss: 0.137617
[Epoch 36] ogbg-molhiv: 0.807604 test loss: 0.131663
[Epoch 37; Iter    30/  960] train: loss: 0.0739020
[Epoch 37; Iter    60/  960] train: loss: 0.0944468
[Epoch 37; Iter    90/  960] train: loss: 0.0231663
[Epoch 37; Iter   120/  960] train: loss: 0.0126286
[Epoch 37; Iter   150/  960] train: loss: 0.0164903
[Epoch 37; Iter   180/  960] train: loss: 0.0106695
[Epoch 37; Iter   210/  960] train: loss: 0.1632865
[Epoch 37; Iter   240/  960] train: loss: 0.0819751
[Epoch 37; Iter   270/  960] train: loss: 0.0849854
[Epoch 37; Iter   300/  960] train: loss: 0.1343225
[Epoch 37; Iter   330/  960] train: loss: 0.0900699
[Epoch 37; Iter   360/  960] train: loss: 0.0341518
[Epoch 37; Iter   390/  960] train: loss: 0.0819929
[Epoch 37; Iter   420/  960] train: loss: 0.2921510
[Epoch 37; Iter   450/  960] train: loss: 0.0852001
[Epoch 37; Iter   480/  960] train: loss: 0.0289759
[Epoch 37; Iter   510/  960] train: loss: 0.0212030
[Epoch 37; Iter   540/  960] train: loss: 0.0246414
[Epoch 37; Iter   570/  960] train: loss: 0.1075489
[Epoch 37; Iter   600/  960] train: loss: 0.0179838
[Epoch 37; Iter   630/  960] train: loss: 0.0163215
[Epoch 37; Iter   660/  960] train: loss: 0.0155552
[Epoch 37; Iter   690/  960] train: loss: 0.0258922
[Epoch 37; Iter   720/  960] train: loss: 0.0222741
[Epoch 37; Iter   750/  960] train: loss: 0.0174820
[Epoch 37; Iter   780/  960] train: loss: 0.0149000
[Epoch 37; Iter   810/  960] train: loss: 0.0461120
[Epoch 37; Iter   840/  960] train: loss: 0.0771580
[Epoch 37; Iter   870/  960] train: loss: 0.0092914
[Epoch 37; Iter   900/  960] train: loss: 0.0727121
[Epoch 37; Iter   930/  960] train: loss: 0.0169467
[Epoch 37; Iter   960/  960] train: loss: 0.0524411
[Epoch 37] ogbg-molhiv: 0.808814 val loss: 0.142807
[Epoch 37] ogbg-molhiv: 0.814408 test loss: 0.132351
[Epoch 38; Iter    30/  960] train: loss: 0.0154725
[Epoch 38; Iter    60/  960] train: loss: 0.1888098
[Epoch 38; Iter    90/  960] train: loss: 0.0173782
[Epoch 38; Iter   120/  960] train: loss: 0.0139694
[Epoch 38; Iter   150/  960] train: loss: 0.0181792
[Epoch 38; Iter   180/  960] train: loss: 0.0177708
[Epoch 38; Iter   210/  960] train: loss: 0.0256828
[Epoch 38; Iter   240/  960] train: loss: 0.0410911
[Epoch 38; Iter   270/  960] train: loss: 0.0711181
[Epoch 38; Iter   300/  960] train: loss: 0.0464276
[Epoch 38; Iter   330/  960] train: loss: 0.0230114
[Epoch 38; Iter   360/  960] train: loss: 0.1375762
[Epoch 38; Iter   390/  960] train: loss: 0.0160807
[Epoch 38; Iter   420/  960] train: loss: 0.0892616
[Epoch 38; Iter   450/  960] train: loss: 0.0556442
[Epoch 38; Iter   480/  960] train: loss: 0.1214541
[Epoch 38; Iter   510/  960] train: loss: 0.1727169
[Epoch 38; Iter   540/  960] train: loss: 0.0138635
[Epoch 38; Iter   570/  960] train: loss: 0.0559265
[Epoch 38; Iter   600/  960] train: loss: 0.0107818
[Epoch 38; Iter   630/  960] train: loss: 0.0759992
[Epoch 38; Iter   660/  960] train: loss: 0.0280465
[Epoch 38; Iter   690/  960] train: loss: 0.0459991
[Epoch 38; Iter   720/  960] train: loss: 0.0734391
[Epoch 38; Iter   750/  960] train: loss: 0.0503738
[Epoch 38; Iter   780/  960] train: loss: 0.0286623
[Epoch 38; Iter   810/  960] train: loss: 0.0125969
[Epoch 38; Iter   840/  960] train: loss: 0.1275112
[Epoch 38; Iter   870/  960] train: loss: 0.0293110
[Epoch 38; Iter   900/  960] train: loss: 0.0396483
[Epoch 38; Iter   930/  960] train: loss: 0.0859689
[Epoch 38; Iter   960/  960] train: loss: 0.0116705
[Epoch 38] ogbg-molhiv: 0.800693 val loss: 0.142601
[Epoch 38] ogbg-molhiv: 0.812154 test loss: 0.130833
[Epoch 39; Iter    30/  960] train: loss: 0.0822925
[Epoch 39; Iter    60/  960] train: loss: 0.0177593
[Epoch 39; Iter    90/  960] train: loss: 0.1974074
[Epoch 39; Iter   120/  960] train: loss: 0.0161577
[Epoch 39; Iter   150/  960] train: loss: 0.0188506
[Epoch 39; Iter   180/  960] train: loss: 0.0106460
[Epoch 39; Iter   210/  960] train: loss: 0.0153203
[Epoch 39; Iter   240/  960] train: loss: 0.0560058
[Epoch 39; Iter   270/  960] train: loss: 0.0190056
[Epoch 39; Iter   300/  960] train: loss: 0.0198675
[Epoch 39; Iter   330/  960] train: loss: 0.0183288
[Epoch 39; Iter   360/  960] train: loss: 0.0534763
[Epoch 39; Iter   390/  960] train: loss: 0.0656877
[Epoch 39; Iter   420/  960] train: loss: 0.0155596
[Epoch 39; Iter   450/  960] train: loss: 0.0245835
[Epoch 39; Iter   480/  960] train: loss: 0.0978263
[Epoch 39; Iter   510/  960] train: loss: 0.1262166
[Epoch 39; Iter   540/  960] train: loss: 0.1010640
[Epoch 39; Iter   570/  960] train: loss: 0.0277596
[Epoch 39; Iter   600/  960] train: loss: 0.4168862
[Epoch 39; Iter   630/  960] train: loss: 0.0240800
[Epoch 39; Iter   660/  960] train: loss: 0.0181740
[Epoch 39; Iter   690/  960] train: loss: 0.0210409
[Epoch 39; Iter   720/  960] train: loss: 0.0576336
[Epoch 39; Iter   750/  960] train: loss: 0.0996971
[Epoch 39; Iter   780/  960] train: loss: 0.0301717
[Epoch 39; Iter   810/  960] train: loss: 0.0157493
[Epoch 39; Iter   840/  960] train: loss: 0.1253830
[Epoch 39; Iter   870/  960] train: loss: 0.0365671
[Epoch 39; Iter   900/  960] train: loss: 0.0114830
[Epoch 39; Iter   930/  960] train: loss: 0.1243653
[Epoch 39; Iter   960/  960] train: loss: 0.0533858
[Epoch 39] ogbg-molhiv: 0.806410 val loss: 0.144579
[Epoch 39] ogbg-molhiv: 0.821215 test loss: 0.134314
[Epoch 40; Iter    30/  960] train: loss: 0.0219637
[Epoch 40; Iter    60/  960] train: loss: 0.0519162
[Epoch 40; Iter    90/  960] train: loss: 0.1882000
[Epoch 40; Iter   120/  960] train: loss: 0.1392713
[Epoch 40; Iter   150/  960] train: loss: 0.0158817
[Epoch 40; Iter   180/  960] train: loss: 0.1649945
[Epoch 40; Iter   210/  960] train: loss: 0.1746668
[Epoch 40; Iter   240/  960] train: loss: 0.0504206
[Epoch 40; Iter   270/  960] train: loss: 0.0833882
[Epoch 40; Iter   300/  960] train: loss: 0.1125301
[Epoch 40; Iter   330/  960] train: loss: 0.0921082
[Epoch 40; Iter   360/  960] train: loss: 0.0125307
[Epoch 40; Iter   390/  960] train: loss: 0.0163279
[Epoch 40; Iter   420/  960] train: loss: 0.0181369
[Epoch 40; Iter   450/  960] train: loss: 0.0357426
[Epoch 40; Iter   480/  960] train: loss: 0.0234724
[Epoch 40; Iter   510/  960] train: loss: 0.0816046
[Epoch 40; Iter   540/  960] train: loss: 0.0274497
[Epoch 40; Iter   570/  960] train: loss: 0.3040055
[Epoch 40; Iter   600/  960] train: loss: 0.1044818
[Epoch 40; Iter   630/  960] train: loss: 0.0113525
[Epoch 40; Iter   660/  960] train: loss: 0.0266348
[Epoch 40; Iter   690/  960] train: loss: 0.1022380
[Epoch 40; Iter   720/  960] train: loss: 0.1940147
[Epoch 40; Iter   750/  960] train: loss: 0.0144325
[Epoch 40; Iter   780/  960] train: loss: 0.0296070
[Epoch 40; Iter   810/  960] train: loss: 0.0554035
[Epoch 40; Iter   840/  960] train: loss: 0.0100099
[Epoch 40; Iter   870/  960] train: loss: 0.2554769
[Epoch 40; Iter   900/  960] train: loss: 0.0089847
[Epoch 40; Iter   930/  960] train: loss: 0.0175025
[Epoch 40; Iter   960/  960] train: loss: 0.0240289
[Epoch 40] ogbg-molhiv: 0.807077 val loss: 0.140012
[Epoch 40] ogbg-molhiv: 0.815469 test loss: 0.127312
[Epoch 41; Iter    30/  960] train: loss: 0.0269759
[Epoch 41; Iter    60/  960] train: loss: 0.0149442
[Epoch 41; Iter    90/  960] train: loss: 0.0195880
[Epoch 41; Iter   120/  960] train: loss: 0.0245730
[Epoch 41; Iter   150/  960] train: loss: 0.1439308
[Epoch 41; Iter   180/  960] train: loss: 0.0720018
[Epoch 41; Iter   210/  960] train: loss: 0.0302064
[Epoch 41; Iter   240/  960] train: loss: 0.0087254
[Epoch 41; Iter   270/  960] train: loss: 0.0158959
[Epoch 41; Iter   300/  960] train: loss: 0.0605355
[Epoch 36; Iter   635/ 1097] train: loss: 0.0263782
[Epoch 36; Iter   665/ 1097] train: loss: 0.1306792
[Epoch 36; Iter   695/ 1097] train: loss: 0.0857952
[Epoch 36; Iter   725/ 1097] train: loss: 0.1536978
[Epoch 36; Iter   755/ 1097] train: loss: 0.1402270
[Epoch 36; Iter   785/ 1097] train: loss: 0.1884081
[Epoch 36; Iter   815/ 1097] train: loss: 0.0327810
[Epoch 36; Iter   845/ 1097] train: loss: 0.1291103
[Epoch 36; Iter   875/ 1097] train: loss: 0.0328979
[Epoch 36; Iter   905/ 1097] train: loss: 0.0517454
[Epoch 36; Iter   935/ 1097] train: loss: 0.0605882
[Epoch 36; Iter   965/ 1097] train: loss: 0.1116997
[Epoch 36; Iter   995/ 1097] train: loss: 0.0319524
[Epoch 36; Iter  1025/ 1097] train: loss: 0.1218796
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0452277
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0233052
[Epoch 36] ogbg-molhiv: 0.817722 val loss: 0.440297
[Epoch 36] ogbg-molhiv: 0.810539 test loss: 0.185885
[Epoch 37; Iter    18/ 1097] train: loss: 0.0850204
[Epoch 37; Iter    48/ 1097] train: loss: 0.0395492
[Epoch 37; Iter    78/ 1097] train: loss: 0.0233894
[Epoch 37; Iter   108/ 1097] train: loss: 0.1993335
[Epoch 37; Iter   138/ 1097] train: loss: 0.2311581
[Epoch 37; Iter   168/ 1097] train: loss: 0.0253533
[Epoch 37; Iter   198/ 1097] train: loss: 0.1368264
[Epoch 37; Iter   228/ 1097] train: loss: 0.2754477
[Epoch 37; Iter   258/ 1097] train: loss: 0.0135807
[Epoch 37; Iter   288/ 1097] train: loss: 0.2236666
[Epoch 37; Iter   318/ 1097] train: loss: 0.0224016
[Epoch 37; Iter   348/ 1097] train: loss: 0.0120752
[Epoch 37; Iter   378/ 1097] train: loss: 0.0945360
[Epoch 37; Iter   408/ 1097] train: loss: 0.1587992
[Epoch 37; Iter   438/ 1097] train: loss: 0.0465437
[Epoch 37; Iter   468/ 1097] train: loss: 0.1438819
[Epoch 37; Iter   498/ 1097] train: loss: 0.0156216
[Epoch 37; Iter   528/ 1097] train: loss: 0.1144629
[Epoch 37; Iter   558/ 1097] train: loss: 0.0160464
[Epoch 37; Iter   588/ 1097] train: loss: 0.0207174
[Epoch 37; Iter   618/ 1097] train: loss: 0.0190783
[Epoch 37; Iter   648/ 1097] train: loss: 0.0572019
[Epoch 37; Iter   678/ 1097] train: loss: 0.0209376
[Epoch 37; Iter   708/ 1097] train: loss: 0.0177579
[Epoch 37; Iter   738/ 1097] train: loss: 0.0195943
[Epoch 37; Iter   768/ 1097] train: loss: 0.0499660
[Epoch 37; Iter   798/ 1097] train: loss: 0.0268821
[Epoch 37; Iter   828/ 1097] train: loss: 0.0261033
[Epoch 37; Iter   858/ 1097] train: loss: 0.0540282
[Epoch 37; Iter   888/ 1097] train: loss: 0.1911023
[Epoch 37; Iter   918/ 1097] train: loss: 0.0286451
[Epoch 37; Iter   948/ 1097] train: loss: 0.0534456
[Epoch 37; Iter   978/ 1097] train: loss: 0.0261417
[Epoch 37; Iter  1008/ 1097] train: loss: 0.1993109
[Epoch 37; Iter  1038/ 1097] train: loss: 0.1465716
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0553401
[Epoch 37] ogbg-molhiv: 0.832562 val loss: 0.459025
[Epoch 37] ogbg-molhiv: 0.812974 test loss: 0.253365
[Epoch 38; Iter     1/ 1097] train: loss: 0.0310283
[Epoch 38; Iter    31/ 1097] train: loss: 0.0180093
[Epoch 38; Iter    61/ 1097] train: loss: 0.0464913
[Epoch 38; Iter    91/ 1097] train: loss: 0.0419170
[Epoch 38; Iter   121/ 1097] train: loss: 0.0162795
[Epoch 38; Iter   151/ 1097] train: loss: 0.1789783
[Epoch 38; Iter   181/ 1097] train: loss: 0.0261517
[Epoch 38; Iter   211/ 1097] train: loss: 0.0252955
[Epoch 38; Iter   241/ 1097] train: loss: 0.0224257
[Epoch 38; Iter   271/ 1097] train: loss: 0.0176572
[Epoch 38; Iter   301/ 1097] train: loss: 0.1492929
[Epoch 38; Iter   331/ 1097] train: loss: 0.0229074
[Epoch 38; Iter   361/ 1097] train: loss: 0.1531778
[Epoch 38; Iter   391/ 1097] train: loss: 0.1949204
[Epoch 38; Iter   421/ 1097] train: loss: 0.1238934
[Epoch 38; Iter   451/ 1097] train: loss: 0.0654044
[Epoch 38; Iter   481/ 1097] train: loss: 0.0231676
[Epoch 38; Iter   511/ 1097] train: loss: 0.1330343
[Epoch 38; Iter   541/ 1097] train: loss: 0.0183642
[Epoch 38; Iter   571/ 1097] train: loss: 0.1750077
[Epoch 38; Iter   601/ 1097] train: loss: 0.0485443
[Epoch 38; Iter   631/ 1097] train: loss: 0.0156275
[Epoch 38; Iter   661/ 1097] train: loss: 0.0257904
[Epoch 38; Iter   691/ 1097] train: loss: 0.2319412
[Epoch 38; Iter   721/ 1097] train: loss: 0.4303685
[Epoch 38; Iter   751/ 1097] train: loss: 0.0903599
[Epoch 38; Iter   781/ 1097] train: loss: 0.1806965
[Epoch 38; Iter   811/ 1097] train: loss: 0.1987689
[Epoch 38; Iter   841/ 1097] train: loss: 0.0630834
[Epoch 38; Iter   871/ 1097] train: loss: 0.1413819
[Epoch 38; Iter   901/ 1097] train: loss: 0.1836319
[Epoch 38; Iter   931/ 1097] train: loss: 0.1361067
[Epoch 38; Iter   961/ 1097] train: loss: 0.0590190
[Epoch 38; Iter   991/ 1097] train: loss: 0.1657058
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0341695
[Epoch 38; Iter  1051/ 1097] train: loss: 0.2127252
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0173094
[Epoch 38] ogbg-molhiv: 0.832641 val loss: 0.229322
[Epoch 38] ogbg-molhiv: 0.818058 test loss: 0.491966
[Epoch 39; Iter    14/ 1097] train: loss: 0.0690559
[Epoch 39; Iter    44/ 1097] train: loss: 0.1807152
[Epoch 39; Iter    74/ 1097] train: loss: 0.0441303
[Epoch 39; Iter   104/ 1097] train: loss: 0.0247902
[Epoch 39; Iter   134/ 1097] train: loss: 0.0417948
[Epoch 39; Iter   164/ 1097] train: loss: 0.0425254
[Epoch 39; Iter   194/ 1097] train: loss: 0.1159174
[Epoch 39; Iter   224/ 1097] train: loss: 0.2222828
[Epoch 39; Iter   254/ 1097] train: loss: 0.1388501
[Epoch 39; Iter   284/ 1097] train: loss: 0.0148365
[Epoch 39; Iter   314/ 1097] train: loss: 0.0525037
[Epoch 39; Iter   344/ 1097] train: loss: 0.0195332
[Epoch 39; Iter   374/ 1097] train: loss: 0.0301147
[Epoch 39; Iter   404/ 1097] train: loss: 0.1704761
[Epoch 39; Iter   434/ 1097] train: loss: 0.1421828
[Epoch 39; Iter   464/ 1097] train: loss: 0.1206401
[Epoch 39; Iter   494/ 1097] train: loss: 0.0273981
[Epoch 39; Iter   524/ 1097] train: loss: 0.0276593
[Epoch 39; Iter   554/ 1097] train: loss: 0.0204586
[Epoch 39; Iter   584/ 1097] train: loss: 0.1500415
[Epoch 39; Iter   614/ 1097] train: loss: 0.1624305
[Epoch 39; Iter   644/ 1097] train: loss: 0.0473077
[Epoch 39; Iter   674/ 1097] train: loss: 0.0167908
[Epoch 39; Iter   704/ 1097] train: loss: 0.0695070
[Epoch 39; Iter   734/ 1097] train: loss: 0.0484811
[Epoch 39; Iter   764/ 1097] train: loss: 0.0873227
[Epoch 39; Iter   794/ 1097] train: loss: 0.0345693
[Epoch 39; Iter   824/ 1097] train: loss: 0.0195232
[Epoch 39; Iter   854/ 1097] train: loss: 0.2058908
[Epoch 39; Iter   884/ 1097] train: loss: 0.0930864
[Epoch 39; Iter   914/ 1097] train: loss: 0.0173402
[Epoch 39; Iter   944/ 1097] train: loss: 0.0259462
[Epoch 39; Iter   974/ 1097] train: loss: 0.1303326
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0144682
[Epoch 39; Iter  1034/ 1097] train: loss: 0.1393976
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0350481
[Epoch 39; Iter  1094/ 1097] train: loss: 0.0439657
[Epoch 39] ogbg-molhiv: 0.825837 val loss: 0.662384
[Epoch 39] ogbg-molhiv: 0.819821 test loss: 0.257285
[Epoch 40; Iter    27/ 1097] train: loss: 0.0139503
[Epoch 40; Iter    57/ 1097] train: loss: 0.0245770
[Epoch 40; Iter    87/ 1097] train: loss: 0.0245587
[Epoch 40; Iter   117/ 1097] train: loss: 0.0152136
[Epoch 40; Iter   147/ 1097] train: loss: 0.0422154
[Epoch 40; Iter   177/ 1097] train: loss: 0.1344384
[Epoch 40; Iter   207/ 1097] train: loss: 0.0174170
[Epoch 40; Iter   237/ 1097] train: loss: 0.0155896
[Epoch 40; Iter   267/ 1097] train: loss: 0.0704809
[Epoch 40; Iter   297/ 1097] train: loss: 0.0947940
[Epoch 40; Iter   327/ 1097] train: loss: 0.0606837
[Epoch 40; Iter   357/ 1097] train: loss: 0.0182664
[Epoch 40; Iter   387/ 1097] train: loss: 0.0147194
[Epoch 40; Iter   417/ 1097] train: loss: 0.1838794
[Epoch 40; Iter   447/ 1097] train: loss: 0.0375373
[Epoch 40; Iter   477/ 1097] train: loss: 0.0898141
[Epoch 40; Iter   507/ 1097] train: loss: 0.0185913
[Epoch 40; Iter   537/ 1097] train: loss: 0.0248684
[Epoch 40; Iter   567/ 1097] train: loss: 0.1353337
[Epoch 40; Iter   597/ 1097] train: loss: 0.0349473
[Epoch 40; Iter   627/ 1097] train: loss: 0.0835571
[Epoch 40; Iter   657/ 1097] train: loss: 0.1357269
[Epoch 40; Iter   687/ 1097] train: loss: 0.0279795
[Epoch 36; Iter   635/ 1097] train: loss: 0.0851030
[Epoch 36; Iter   665/ 1097] train: loss: 0.0132995
[Epoch 36; Iter   695/ 1097] train: loss: 0.0642897
[Epoch 36; Iter   725/ 1097] train: loss: 0.1034383
[Epoch 36; Iter   755/ 1097] train: loss: 0.0691848
[Epoch 36; Iter   785/ 1097] train: loss: 0.0223019
[Epoch 36; Iter   815/ 1097] train: loss: 0.0173355
[Epoch 36; Iter   845/ 1097] train: loss: 0.0256173
[Epoch 36; Iter   875/ 1097] train: loss: 0.1752242
[Epoch 36; Iter   905/ 1097] train: loss: 0.0374492
[Epoch 36; Iter   935/ 1097] train: loss: 0.0537480
[Epoch 36; Iter   965/ 1097] train: loss: 0.2426751
[Epoch 36; Iter   995/ 1097] train: loss: 0.1679703
[Epoch 36; Iter  1025/ 1097] train: loss: 0.0322513
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0129427
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0274323
[Epoch 36] ogbg-molhiv: 0.822246 val loss: 0.570302
[Epoch 36] ogbg-molhiv: 0.834519 test loss: 0.538516
[Epoch 37; Iter    18/ 1097] train: loss: 0.0290342
[Epoch 37; Iter    48/ 1097] train: loss: 0.0241629
[Epoch 37; Iter    78/ 1097] train: loss: 0.0074146
[Epoch 37; Iter   108/ 1097] train: loss: 0.0128948
[Epoch 37; Iter   138/ 1097] train: loss: 0.0449001
[Epoch 37; Iter   168/ 1097] train: loss: 0.0137451
[Epoch 37; Iter   198/ 1097] train: loss: 0.0169748
[Epoch 37; Iter   228/ 1097] train: loss: 0.0219790
[Epoch 37; Iter   258/ 1097] train: loss: 0.3266508
[Epoch 37; Iter   288/ 1097] train: loss: 0.0270176
[Epoch 37; Iter   318/ 1097] train: loss: 0.0139045
[Epoch 37; Iter   348/ 1097] train: loss: 0.0695938
[Epoch 37; Iter   378/ 1097] train: loss: 0.0151537
[Epoch 37; Iter   408/ 1097] train: loss: 0.0106293
[Epoch 37; Iter   438/ 1097] train: loss: 0.0806552
[Epoch 37; Iter   468/ 1097] train: loss: 0.1157647
[Epoch 37; Iter   498/ 1097] train: loss: 0.2020859
[Epoch 37; Iter   528/ 1097] train: loss: 0.0235248
[Epoch 37; Iter   558/ 1097] train: loss: 0.3134362
[Epoch 37; Iter   588/ 1097] train: loss: 0.0327205
[Epoch 37; Iter   618/ 1097] train: loss: 0.0168359
[Epoch 37; Iter   648/ 1097] train: loss: 0.0440442
[Epoch 37; Iter   678/ 1097] train: loss: 0.0121373
[Epoch 37; Iter   708/ 1097] train: loss: 0.1150592
[Epoch 37; Iter   738/ 1097] train: loss: 0.0120165
[Epoch 37; Iter   768/ 1097] train: loss: 0.0137211
[Epoch 37; Iter   798/ 1097] train: loss: 0.0298236
[Epoch 37; Iter   828/ 1097] train: loss: 0.0210654
[Epoch 37; Iter   858/ 1097] train: loss: 0.1318797
[Epoch 37; Iter   888/ 1097] train: loss: 0.0536429
[Epoch 37; Iter   918/ 1097] train: loss: 0.1119821
[Epoch 37; Iter   948/ 1097] train: loss: 0.1337398
[Epoch 37; Iter   978/ 1097] train: loss: 0.4430776
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0087340
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0307073
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0138150
[Epoch 37] ogbg-molhiv: 0.810428 val loss: 0.129398
[Epoch 37] ogbg-molhiv: 0.829842 test loss: 0.119978
[Epoch 38; Iter     1/ 1097] train: loss: 0.0905160
[Epoch 38; Iter    31/ 1097] train: loss: 0.0144898
[Epoch 38; Iter    61/ 1097] train: loss: 0.0127946
[Epoch 38; Iter    91/ 1097] train: loss: 0.0166757
[Epoch 38; Iter   121/ 1097] train: loss: 0.1501299
[Epoch 38; Iter   151/ 1097] train: loss: 0.0450317
[Epoch 38; Iter   181/ 1097] train: loss: 0.0103193
[Epoch 38; Iter   211/ 1097] train: loss: 0.0215157
[Epoch 38; Iter   241/ 1097] train: loss: 0.0280554
[Epoch 38; Iter   271/ 1097] train: loss: 0.0639175
[Epoch 38; Iter   301/ 1097] train: loss: 0.0132369
[Epoch 38; Iter   331/ 1097] train: loss: 0.1644147
[Epoch 38; Iter   361/ 1097] train: loss: 0.1846525
[Epoch 38; Iter   391/ 1097] train: loss: 0.0457490
[Epoch 38; Iter   421/ 1097] train: loss: 0.0130218
[Epoch 38; Iter   451/ 1097] train: loss: 0.0220744
[Epoch 38; Iter   481/ 1097] train: loss: 0.0568834
[Epoch 38; Iter   511/ 1097] train: loss: 0.1488327
[Epoch 38; Iter   541/ 1097] train: loss: 0.0139876
[Epoch 38; Iter   571/ 1097] train: loss: 0.1199406
[Epoch 38; Iter   601/ 1097] train: loss: 0.0126703
[Epoch 38; Iter   631/ 1097] train: loss: 0.0786932
[Epoch 38; Iter   661/ 1097] train: loss: 0.1240511
[Epoch 38; Iter   691/ 1097] train: loss: 0.0146663
[Epoch 38; Iter   721/ 1097] train: loss: 0.0081127
[Epoch 38; Iter   751/ 1097] train: loss: 0.0367794
[Epoch 38; Iter   781/ 1097] train: loss: 0.2243976
[Epoch 38; Iter   811/ 1097] train: loss: 0.0835725
[Epoch 38; Iter   841/ 1097] train: loss: 0.1085420
[Epoch 38; Iter   871/ 1097] train: loss: 0.2028603
[Epoch 38; Iter   901/ 1097] train: loss: 0.0157018
[Epoch 38; Iter   931/ 1097] train: loss: 0.0738587
[Epoch 38; Iter   961/ 1097] train: loss: 0.0724391
[Epoch 38; Iter   991/ 1097] train: loss: 0.0207531
[Epoch 38; Iter  1021/ 1097] train: loss: 0.1068850
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0420128
[Epoch 38; Iter  1081/ 1097] train: loss: 0.3121608
[Epoch 38] ogbg-molhiv: 0.815956 val loss: 0.130720
[Epoch 38] ogbg-molhiv: 0.817002 test loss: 0.124996
[Epoch 39; Iter    14/ 1097] train: loss: 0.0861019
[Epoch 39; Iter    44/ 1097] train: loss: 0.0117959
[Epoch 39; Iter    74/ 1097] train: loss: 0.1523485
[Epoch 39; Iter   104/ 1097] train: loss: 0.2411714
[Epoch 39; Iter   134/ 1097] train: loss: 0.0583141
[Epoch 39; Iter   164/ 1097] train: loss: 0.0938876
[Epoch 39; Iter   194/ 1097] train: loss: 0.0825582
[Epoch 39; Iter   224/ 1097] train: loss: 0.1246716
[Epoch 39; Iter   254/ 1097] train: loss: 0.1330985
[Epoch 39; Iter   284/ 1097] train: loss: 0.0474777
[Epoch 39; Iter   314/ 1097] train: loss: 0.0461070
[Epoch 39; Iter   344/ 1097] train: loss: 0.0206442
[Epoch 39; Iter   374/ 1097] train: loss: 0.0416276
[Epoch 39; Iter   404/ 1097] train: loss: 0.0124203
[Epoch 39; Iter   434/ 1097] train: loss: 0.0132361
[Epoch 39; Iter   464/ 1097] train: loss: 0.0655179
[Epoch 39; Iter   494/ 1097] train: loss: 0.0247004
[Epoch 39; Iter   524/ 1097] train: loss: 0.0136440
[Epoch 39; Iter   554/ 1097] train: loss: 0.0312429
[Epoch 39; Iter   584/ 1097] train: loss: 0.0733812
[Epoch 39; Iter   614/ 1097] train: loss: 0.0169387
[Epoch 39; Iter   644/ 1097] train: loss: 0.0785972
[Epoch 39; Iter   674/ 1097] train: loss: 0.0561693
[Epoch 39; Iter   704/ 1097] train: loss: 0.0068832
[Epoch 39; Iter   734/ 1097] train: loss: 0.0220486
[Epoch 39; Iter   764/ 1097] train: loss: 0.1476711
[Epoch 39; Iter   794/ 1097] train: loss: 0.0136620
[Epoch 39; Iter   824/ 1097] train: loss: 0.0125847
[Epoch 39; Iter   854/ 1097] train: loss: 0.1407914
[Epoch 39; Iter   884/ 1097] train: loss: 0.1151038
[Epoch 39; Iter   914/ 1097] train: loss: 0.0986611
[Epoch 39; Iter   944/ 1097] train: loss: 0.0114072
[Epoch 39; Iter   974/ 1097] train: loss: 0.0684230
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0941567
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0184736
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0534661
[Epoch 39; Iter  1094/ 1097] train: loss: 0.1015812
[Epoch 39] ogbg-molhiv: 0.817727 val loss: 0.230745
[Epoch 39] ogbg-molhiv: 0.841226 test loss: 0.250302
[Epoch 40; Iter    27/ 1097] train: loss: 0.0071463
[Epoch 40; Iter    57/ 1097] train: loss: 0.1235146
[Epoch 40; Iter    87/ 1097] train: loss: 0.0341387
[Epoch 40; Iter   117/ 1097] train: loss: 0.0092898
[Epoch 40; Iter   147/ 1097] train: loss: 0.0654270
[Epoch 40; Iter   177/ 1097] train: loss: 0.0163525
[Epoch 40; Iter   207/ 1097] train: loss: 0.0198529
[Epoch 40; Iter   237/ 1097] train: loss: 0.0219746
[Epoch 40; Iter   267/ 1097] train: loss: 0.0784640
[Epoch 40; Iter   297/ 1097] train: loss: 0.0252094
[Epoch 40; Iter   327/ 1097] train: loss: 0.0533005
[Epoch 40; Iter   357/ 1097] train: loss: 0.0452619
[Epoch 40; Iter   387/ 1097] train: loss: 0.0216981
[Epoch 40; Iter   417/ 1097] train: loss: 0.0115712
[Epoch 40; Iter   447/ 1097] train: loss: 0.0898073
[Epoch 40; Iter   477/ 1097] train: loss: 0.1971188
[Epoch 40; Iter   507/ 1097] train: loss: 0.1016228
[Epoch 40; Iter   537/ 1097] train: loss: 0.1391810
[Epoch 40; Iter   567/ 1097] train: loss: 0.1832806
[Epoch 40; Iter   597/ 1097] train: loss: 0.0108511
[Epoch 40; Iter   627/ 1097] train: loss: 0.2665243
[Epoch 40; Iter   657/ 1097] train: loss: 0.1369193
[Epoch 40; Iter   687/ 1097] train: loss: 0.1298539
[Epoch 36; Iter   635/ 1097] train: loss: 0.2007761
[Epoch 36; Iter   665/ 1097] train: loss: 0.0554301
[Epoch 36; Iter   695/ 1097] train: loss: 0.1401674
[Epoch 36; Iter   725/ 1097] train: loss: 0.0970251
[Epoch 36; Iter   755/ 1097] train: loss: 0.0958535
[Epoch 36; Iter   785/ 1097] train: loss: 0.3411845
[Epoch 36; Iter   815/ 1097] train: loss: 0.0468354
[Epoch 36; Iter   845/ 1097] train: loss: 0.0748177
[Epoch 36; Iter   875/ 1097] train: loss: 0.0244491
[Epoch 36; Iter   905/ 1097] train: loss: 0.0543081
[Epoch 36; Iter   935/ 1097] train: loss: 0.0501012
[Epoch 36; Iter   965/ 1097] train: loss: 0.0574373
[Epoch 36; Iter   995/ 1097] train: loss: 0.0204876
[Epoch 36; Iter  1025/ 1097] train: loss: 0.0135728
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0432258
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0111820
[Epoch 36] ogbg-molhiv: 0.793172 val loss: 0.142566
[Epoch 36] ogbg-molhiv: 0.818667 test loss: 0.132313
[Epoch 37; Iter    18/ 1097] train: loss: 0.0460083
[Epoch 37; Iter    48/ 1097] train: loss: 0.0430819
[Epoch 37; Iter    78/ 1097] train: loss: 0.0273496
[Epoch 37; Iter   108/ 1097] train: loss: 0.0698255
[Epoch 37; Iter   138/ 1097] train: loss: 0.0728693
[Epoch 37; Iter   168/ 1097] train: loss: 0.1091659
[Epoch 37; Iter   198/ 1097] train: loss: 0.1379315
[Epoch 37; Iter   228/ 1097] train: loss: 0.0447450
[Epoch 37; Iter   258/ 1097] train: loss: 0.2510784
[Epoch 37; Iter   288/ 1097] train: loss: 0.0244652
[Epoch 37; Iter   318/ 1097] train: loss: 0.0184198
[Epoch 37; Iter   348/ 1097] train: loss: 0.1140534
[Epoch 37; Iter   378/ 1097] train: loss: 0.0542393
[Epoch 37; Iter   408/ 1097] train: loss: 0.0493642
[Epoch 37; Iter   438/ 1097] train: loss: 0.0159020
[Epoch 37; Iter   468/ 1097] train: loss: 0.0148870
[Epoch 37; Iter   498/ 1097] train: loss: 0.0149559
[Epoch 37; Iter   528/ 1097] train: loss: 0.1651686
[Epoch 37; Iter   558/ 1097] train: loss: 0.0373934
[Epoch 37; Iter   588/ 1097] train: loss: 0.0605484
[Epoch 37; Iter   618/ 1097] train: loss: 0.2053654
[Epoch 37; Iter   648/ 1097] train: loss: 0.2006641
[Epoch 37; Iter   678/ 1097] train: loss: 0.0142120
[Epoch 37; Iter   708/ 1097] train: loss: 0.0385620
[Epoch 37; Iter   738/ 1097] train: loss: 0.2734029
[Epoch 37; Iter   768/ 1097] train: loss: 0.0160287
[Epoch 37; Iter   798/ 1097] train: loss: 0.0169828
[Epoch 37; Iter   828/ 1097] train: loss: 0.0098212
[Epoch 37; Iter   858/ 1097] train: loss: 0.0198734
[Epoch 37; Iter   888/ 1097] train: loss: 0.0924897
[Epoch 37; Iter   918/ 1097] train: loss: 0.0785328
[Epoch 37; Iter   948/ 1097] train: loss: 0.0158526
[Epoch 37; Iter   978/ 1097] train: loss: 0.0143319
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0158301
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0115412
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0132024
[Epoch 37] ogbg-molhiv: 0.795662 val loss: 0.335077
[Epoch 37] ogbg-molhiv: 0.817970 test loss: 0.559891
[Epoch 38; Iter     1/ 1097] train: loss: 0.0871728
[Epoch 38; Iter    31/ 1097] train: loss: 0.0235420
[Epoch 38; Iter    61/ 1097] train: loss: 0.1526419
[Epoch 38; Iter    91/ 1097] train: loss: 0.0532198
[Epoch 38; Iter   121/ 1097] train: loss: 0.0089541
[Epoch 38; Iter   151/ 1097] train: loss: 0.1671652
[Epoch 38; Iter   181/ 1097] train: loss: 0.0144469
[Epoch 38; Iter   211/ 1097] train: loss: 0.1218051
[Epoch 38; Iter   241/ 1097] train: loss: 0.0622726
[Epoch 38; Iter   271/ 1097] train: loss: 0.0936021
[Epoch 38; Iter   301/ 1097] train: loss: 0.1319025
[Epoch 38; Iter   331/ 1097] train: loss: 0.0487360
[Epoch 38; Iter   361/ 1097] train: loss: 0.0112847
[Epoch 38; Iter   391/ 1097] train: loss: 0.1365622
[Epoch 38; Iter   421/ 1097] train: loss: 0.0092886
[Epoch 38; Iter   451/ 1097] train: loss: 0.1328330
[Epoch 38; Iter   481/ 1097] train: loss: 0.0218564
[Epoch 38; Iter   511/ 1097] train: loss: 0.0189252
[Epoch 38; Iter   541/ 1097] train: loss: 0.1695927
[Epoch 38; Iter   571/ 1097] train: loss: 0.2272129
[Epoch 38; Iter   601/ 1097] train: loss: 0.0142039
[Epoch 38; Iter   631/ 1097] train: loss: 0.1577502
[Epoch 38; Iter   661/ 1097] train: loss: 0.0379931
[Epoch 38; Iter   691/ 1097] train: loss: 0.1474074
[Epoch 38; Iter   721/ 1097] train: loss: 0.1712199
[Epoch 38; Iter   751/ 1097] train: loss: 0.0160088
[Epoch 38; Iter   781/ 1097] train: loss: 0.0160927
[Epoch 38; Iter   811/ 1097] train: loss: 0.0448683
[Epoch 38; Iter   841/ 1097] train: loss: 0.1215948
[Epoch 38; Iter   871/ 1097] train: loss: 0.0222432
[Epoch 38; Iter   901/ 1097] train: loss: 0.0436379
[Epoch 38; Iter   931/ 1097] train: loss: 0.0787058
[Epoch 38; Iter   961/ 1097] train: loss: 0.0207325
[Epoch 38; Iter   991/ 1097] train: loss: 0.0813330
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0553833
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0856135
[Epoch 38; Iter  1081/ 1097] train: loss: 0.1262372
[Epoch 38] ogbg-molhiv: 0.811434 val loss: 0.148330
[Epoch 38] ogbg-molhiv: 0.832112 test loss: 0.129982
[Epoch 39; Iter    14/ 1097] train: loss: 0.1389719
[Epoch 39; Iter    44/ 1097] train: loss: 0.0546876
[Epoch 39; Iter    74/ 1097] train: loss: 0.0119650
[Epoch 39; Iter   104/ 1097] train: loss: 0.0214919
[Epoch 39; Iter   134/ 1097] train: loss: 0.0472056
[Epoch 39; Iter   164/ 1097] train: loss: 0.0136976
[Epoch 39; Iter   194/ 1097] train: loss: 0.0568340
[Epoch 39; Iter   224/ 1097] train: loss: 0.0947433
[Epoch 39; Iter   254/ 1097] train: loss: 0.0773337
[Epoch 39; Iter   284/ 1097] train: loss: 0.0139137
[Epoch 39; Iter   314/ 1097] train: loss: 0.0125561
[Epoch 39; Iter   344/ 1097] train: loss: 0.0166925
[Epoch 39; Iter   374/ 1097] train: loss: 0.0349641
[Epoch 39; Iter   404/ 1097] train: loss: 0.0478188
[Epoch 39; Iter   434/ 1097] train: loss: 0.0063828
[Epoch 39; Iter   464/ 1097] train: loss: 0.0216012
[Epoch 39; Iter   494/ 1097] train: loss: 0.0092882
[Epoch 39; Iter   524/ 1097] train: loss: 0.0490580
[Epoch 39; Iter   554/ 1097] train: loss: 0.0341448
[Epoch 39; Iter   584/ 1097] train: loss: 0.0643139
[Epoch 39; Iter   614/ 1097] train: loss: 0.0064959
[Epoch 39; Iter   644/ 1097] train: loss: 0.0109128
[Epoch 39; Iter   674/ 1097] train: loss: 0.0664611
[Epoch 39; Iter   704/ 1097] train: loss: 0.0584936
[Epoch 39; Iter   734/ 1097] train: loss: 0.0345358
[Epoch 39; Iter   764/ 1097] train: loss: 0.0740665
[Epoch 39; Iter   794/ 1097] train: loss: 0.0882819
[Epoch 39; Iter   824/ 1097] train: loss: 0.0420926
[Epoch 39; Iter   854/ 1097] train: loss: 0.1490272
[Epoch 39; Iter   884/ 1097] train: loss: 0.0909248
[Epoch 39; Iter   914/ 1097] train: loss: 0.0736484
[Epoch 39; Iter   944/ 1097] train: loss: 0.1918056
[Epoch 39; Iter   974/ 1097] train: loss: 0.3071158
[Epoch 39; Iter  1004/ 1097] train: loss: 0.1417504
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0084524
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0384974
[Epoch 39; Iter  1094/ 1097] train: loss: 0.1643235
[Epoch 39] ogbg-molhiv: 0.802462 val loss: 0.138562
[Epoch 39] ogbg-molhiv: 0.818050 test loss: 0.131134
[Epoch 40; Iter    27/ 1097] train: loss: 0.0426809
[Epoch 40; Iter    57/ 1097] train: loss: 0.0650180
[Epoch 40; Iter    87/ 1097] train: loss: 0.0440181
[Epoch 40; Iter   117/ 1097] train: loss: 0.0150476
[Epoch 40; Iter   147/ 1097] train: loss: 0.1008757
[Epoch 40; Iter   177/ 1097] train: loss: 0.0688246
[Epoch 40; Iter   207/ 1097] train: loss: 0.1309055
[Epoch 40; Iter   237/ 1097] train: loss: 0.1596263
[Epoch 40; Iter   267/ 1097] train: loss: 0.1070359
[Epoch 40; Iter   297/ 1097] train: loss: 0.0129128
[Epoch 40; Iter   327/ 1097] train: loss: 0.1609532
[Epoch 40; Iter   357/ 1097] train: loss: 0.2509081
[Epoch 40; Iter   387/ 1097] train: loss: 0.0316227
[Epoch 40; Iter   417/ 1097] train: loss: 0.1650870
[Epoch 40; Iter   447/ 1097] train: loss: 0.1759431
[Epoch 40; Iter   477/ 1097] train: loss: 0.0316625
[Epoch 40; Iter   507/ 1097] train: loss: 0.0152799
[Epoch 40; Iter   537/ 1097] train: loss: 0.0660089
[Epoch 40; Iter   567/ 1097] train: loss: 0.1362049
[Epoch 40; Iter   597/ 1097] train: loss: 0.0183502
[Epoch 40; Iter   627/ 1097] train: loss: 0.0174646
[Epoch 40; Iter   657/ 1097] train: loss: 0.0174713
[Epoch 40; Iter   687/ 1097] train: loss: 0.0690882
[Epoch 42; Iter   187/  823] train: loss: 0.0273971
[Epoch 42; Iter   217/  823] train: loss: 0.0501982
[Epoch 42; Iter   247/  823] train: loss: 0.0285097
[Epoch 42; Iter   277/  823] train: loss: 0.2992767
[Epoch 42; Iter   307/  823] train: loss: 0.0372487
[Epoch 42; Iter   337/  823] train: loss: 0.0193787
[Epoch 42; Iter   367/  823] train: loss: 0.0142758
[Epoch 42; Iter   397/  823] train: loss: 0.0958456
[Epoch 42; Iter   427/  823] train: loss: 0.0721056
[Epoch 42; Iter   457/  823] train: loss: 0.0316455
[Epoch 42; Iter   487/  823] train: loss: 0.0246144
[Epoch 42; Iter   517/  823] train: loss: 0.0237883
[Epoch 42; Iter   547/  823] train: loss: 0.0205759
[Epoch 42; Iter   577/  823] train: loss: 0.0876393
[Epoch 42; Iter   607/  823] train: loss: 0.0126490
[Epoch 42; Iter   637/  823] train: loss: 0.0233084
[Epoch 42; Iter   667/  823] train: loss: 0.0211618
[Epoch 42; Iter   697/  823] train: loss: 0.1531883
[Epoch 42; Iter   727/  823] train: loss: 0.1070056
[Epoch 42; Iter   757/  823] train: loss: 0.1239707
[Epoch 42; Iter   787/  823] train: loss: 0.1067990
[Epoch 42; Iter   817/  823] train: loss: 0.0138380
[Epoch 42] ogbg-molhiv: 0.826673 val loss: 0.144553
[Epoch 42] ogbg-molhiv: 0.798342 test loss: 0.138752
[Epoch 43; Iter    24/  823] train: loss: 0.0299045
[Epoch 43; Iter    54/  823] train: loss: 0.1091326
[Epoch 43; Iter    84/  823] train: loss: 0.4754891
[Epoch 43; Iter   114/  823] train: loss: 0.0276420
[Epoch 43; Iter   144/  823] train: loss: 0.0401979
[Epoch 43; Iter   174/  823] train: loss: 0.3141395
[Epoch 43; Iter   204/  823] train: loss: 0.0573455
[Epoch 43; Iter   234/  823] train: loss: 0.0302863
[Epoch 43; Iter   264/  823] train: loss: 0.0195410
[Epoch 43; Iter   294/  823] train: loss: 0.0146258
[Epoch 43; Iter   324/  823] train: loss: 0.0246791
[Epoch 43; Iter   354/  823] train: loss: 0.0833188
[Epoch 43; Iter   384/  823] train: loss: 0.0187158
[Epoch 43; Iter   414/  823] train: loss: 0.0193841
[Epoch 43; Iter   444/  823] train: loss: 0.1950931
[Epoch 43; Iter   474/  823] train: loss: 0.0164551
[Epoch 43; Iter   504/  823] train: loss: 0.1104244
[Epoch 43; Iter   534/  823] train: loss: 0.2869497
[Epoch 43; Iter   564/  823] train: loss: 0.0407708
[Epoch 43; Iter   594/  823] train: loss: 0.1230544
[Epoch 43; Iter   624/  823] train: loss: 0.1506738
[Epoch 43; Iter   654/  823] train: loss: 0.0278269
[Epoch 43; Iter   684/  823] train: loss: 0.0569953
[Epoch 43; Iter   714/  823] train: loss: 0.0249546
[Epoch 43; Iter   744/  823] train: loss: 0.4163203
[Epoch 43; Iter   774/  823] train: loss: 0.0505916
[Epoch 43; Iter   804/  823] train: loss: 0.0256437
[Epoch 43] ogbg-molhiv: 0.830406 val loss: 0.200485
[Epoch 43] ogbg-molhiv: 0.797567 test loss: 0.204886
[Epoch 44; Iter    11/  823] train: loss: 0.1152554
[Epoch 44; Iter    41/  823] train: loss: 0.2784919
[Epoch 44; Iter    71/  823] train: loss: 0.0554752
[Epoch 44; Iter   101/  823] train: loss: 0.1118430
[Epoch 44; Iter   131/  823] train: loss: 0.0322375
[Epoch 44; Iter   161/  823] train: loss: 0.0131902
[Epoch 44; Iter   191/  823] train: loss: 0.0502160
[Epoch 44; Iter   221/  823] train: loss: 0.0362997
[Epoch 44; Iter   251/  823] train: loss: 0.1202241
[Epoch 44; Iter   281/  823] train: loss: 0.2432368
[Epoch 44; Iter   311/  823] train: loss: 0.0151964
[Epoch 44; Iter   341/  823] train: loss: 0.1539035
[Epoch 44; Iter   371/  823] train: loss: 0.0200033
[Epoch 44; Iter   401/  823] train: loss: 0.0558981
[Epoch 44; Iter   431/  823] train: loss: 0.0076667
[Epoch 44; Iter   461/  823] train: loss: 0.2856165
[Epoch 44; Iter   491/  823] train: loss: 0.1929174
[Epoch 44; Iter   521/  823] train: loss: 0.0090496
[Epoch 44; Iter   551/  823] train: loss: 0.3781684
[Epoch 44; Iter   581/  823] train: loss: 0.0222075
[Epoch 44; Iter   611/  823] train: loss: 0.1103950
[Epoch 44; Iter   641/  823] train: loss: 0.1060021
[Epoch 44; Iter   671/  823] train: loss: 0.0318046
[Epoch 44; Iter   701/  823] train: loss: 0.0168106
[Epoch 44; Iter   731/  823] train: loss: 0.0430804
[Epoch 44; Iter   761/  823] train: loss: 0.0334726
[Epoch 44; Iter   791/  823] train: loss: 0.0545299
[Epoch 44; Iter   821/  823] train: loss: 0.0307169
[Epoch 44] ogbg-molhiv: 0.835862 val loss: 0.168040
[Epoch 44] ogbg-molhiv: 0.798077 test loss: 0.197755
[Epoch 45; Iter    28/  823] train: loss: 0.0922238
[Epoch 45; Iter    58/  823] train: loss: 0.0382286
[Epoch 45; Iter    88/  823] train: loss: 0.0805973
[Epoch 45; Iter   118/  823] train: loss: 0.1086302
[Epoch 45; Iter   148/  823] train: loss: 0.0593107
[Epoch 45; Iter   178/  823] train: loss: 0.0334084
[Epoch 45; Iter   208/  823] train: loss: 0.2233183
[Epoch 45; Iter   238/  823] train: loss: 0.0520543
[Epoch 45; Iter   268/  823] train: loss: 0.0114965
[Epoch 45; Iter   298/  823] train: loss: 0.0265004
[Epoch 45; Iter   328/  823] train: loss: 0.0230278
[Epoch 45; Iter   358/  823] train: loss: 0.2935241
[Epoch 45; Iter   388/  823] train: loss: 0.0122156
[Epoch 45; Iter   418/  823] train: loss: 0.0136179
[Epoch 45; Iter   448/  823] train: loss: 0.0919841
[Epoch 45; Iter   478/  823] train: loss: 0.0116932
[Epoch 45; Iter   508/  823] train: loss: 0.0225384
[Epoch 45; Iter   538/  823] train: loss: 0.2031908
[Epoch 45; Iter   568/  823] train: loss: 0.0205489
[Epoch 45; Iter   598/  823] train: loss: 0.1288927
[Epoch 45; Iter   628/  823] train: loss: 0.2609844
[Epoch 45; Iter   658/  823] train: loss: 0.0370772
[Epoch 45; Iter   688/  823] train: loss: 0.2510195
[Epoch 45; Iter   718/  823] train: loss: 0.0578835
[Epoch 45; Iter   748/  823] train: loss: 0.0245248
[Epoch 45; Iter   778/  823] train: loss: 0.0236969
[Epoch 45; Iter   808/  823] train: loss: 0.0610593
[Epoch 45] ogbg-molhiv: 0.830752 val loss: 0.163332
[Epoch 45] ogbg-molhiv: 0.796956 test loss: 0.138190
[Epoch 46; Iter    15/  823] train: loss: 0.0140844
[Epoch 46; Iter    45/  823] train: loss: 0.0808436
[Epoch 46; Iter    75/  823] train: loss: 0.1647770
[Epoch 46; Iter   105/  823] train: loss: 0.0151811
[Epoch 46; Iter   135/  823] train: loss: 0.0206966
[Epoch 46; Iter   165/  823] train: loss: 0.0327563
[Epoch 46; Iter   195/  823] train: loss: 0.0404192
[Epoch 46; Iter   225/  823] train: loss: 0.0449855
[Epoch 46; Iter   255/  823] train: loss: 0.0622685
[Epoch 46; Iter   285/  823] train: loss: 0.0189757
[Epoch 46; Iter   315/  823] train: loss: 0.0682199
[Epoch 46; Iter   345/  823] train: loss: 0.0138409
[Epoch 46; Iter   375/  823] train: loss: 0.0258737
[Epoch 46; Iter   405/  823] train: loss: 0.0241018
[Epoch 46; Iter   435/  823] train: loss: 0.0215003
[Epoch 46; Iter   465/  823] train: loss: 0.0285936
[Epoch 46; Iter   495/  823] train: loss: 0.3784294
[Epoch 46; Iter   525/  823] train: loss: 0.2805237
[Epoch 46; Iter   555/  823] train: loss: 0.0135762
[Epoch 46; Iter   585/  823] train: loss: 0.2820324
[Epoch 46; Iter   615/  823] train: loss: 0.0520165
[Epoch 46; Iter   645/  823] train: loss: 0.1547898
[Epoch 46; Iter   675/  823] train: loss: 0.0291655
[Epoch 46; Iter   705/  823] train: loss: 0.2084962
[Epoch 46; Iter   735/  823] train: loss: 0.0169866
[Epoch 46; Iter   765/  823] train: loss: 0.1500965
[Epoch 46; Iter   795/  823] train: loss: 0.1527250
[Epoch 46] ogbg-molhiv: 0.836687 val loss: 0.241201
[Epoch 46] ogbg-molhiv: 0.807298 test loss: 0.219010
[Epoch 47; Iter     2/  823] train: loss: 0.0119968
[Epoch 47; Iter    32/  823] train: loss: 0.0195192
[Epoch 47; Iter    62/  823] train: loss: 0.0197631
[Epoch 47; Iter    92/  823] train: loss: 0.0491318
[Epoch 47; Iter   122/  823] train: loss: 0.1027805
[Epoch 47; Iter   152/  823] train: loss: 0.0295932
[Epoch 47; Iter   182/  823] train: loss: 0.0527240
[Epoch 47; Iter   212/  823] train: loss: 0.1210483
[Epoch 47; Iter   242/  823] train: loss: 0.0200913
[Epoch 47; Iter   272/  823] train: loss: 0.1379183
[Epoch 47; Iter   302/  823] train: loss: 0.0118712
[Epoch 47; Iter   332/  823] train: loss: 0.0880623
[Epoch 47; Iter   362/  823] train: loss: 0.1442328
[Epoch 47; Iter   392/  823] train: loss: 0.0221861
[Epoch 47; Iter   422/  823] train: loss: 0.0199151
[Epoch 47; Iter   452/  823] train: loss: 0.0130806
[Epoch 41; Iter   330/  960] train: loss: 0.1603710
[Epoch 41; Iter   360/  960] train: loss: 0.1472739
[Epoch 41; Iter   390/  960] train: loss: 0.0628262
[Epoch 41; Iter   420/  960] train: loss: 0.0376427
[Epoch 41; Iter   450/  960] train: loss: 0.0791959
[Epoch 41; Iter   480/  960] train: loss: 0.0173071
[Epoch 41; Iter   510/  960] train: loss: 0.0738244
[Epoch 41; Iter   540/  960] train: loss: 0.0095567
[Epoch 41; Iter   570/  960] train: loss: 0.0809640
[Epoch 41; Iter   600/  960] train: loss: 0.1560574
[Epoch 41; Iter   630/  960] train: loss: 0.0099423
[Epoch 41; Iter   660/  960] train: loss: 0.0229362
[Epoch 41; Iter   690/  960] train: loss: 0.0818991
[Epoch 41; Iter   720/  960] train: loss: 0.0553892
[Epoch 41; Iter   750/  960] train: loss: 0.0473432
[Epoch 41; Iter   780/  960] train: loss: 0.0520781
[Epoch 41; Iter   810/  960] train: loss: 0.1325042
[Epoch 41; Iter   840/  960] train: loss: 0.1284307
[Epoch 41; Iter   870/  960] train: loss: 0.0517064
[Epoch 41; Iter   900/  960] train: loss: 0.0542577
[Epoch 41; Iter   930/  960] train: loss: 0.1800106
[Epoch 41; Iter   960/  960] train: loss: 0.0073133
[Epoch 41] ogbg-molhiv: 0.812843 val loss: 0.142349
[Epoch 41] ogbg-molhiv: 0.818193 test loss: 0.130528
[Epoch 42; Iter    30/  960] train: loss: 0.1551406
[Epoch 42; Iter    60/  960] train: loss: 0.0385767
[Epoch 42; Iter    90/  960] train: loss: 0.0339123
[Epoch 42; Iter   120/  960] train: loss: 0.0137010
[Epoch 42; Iter   150/  960] train: loss: 0.0611956
[Epoch 42; Iter   180/  960] train: loss: 0.0931785
[Epoch 42; Iter   210/  960] train: loss: 0.1550359
[Epoch 42; Iter   240/  960] train: loss: 0.0459164
[Epoch 42; Iter   270/  960] train: loss: 0.0223078
[Epoch 42; Iter   300/  960] train: loss: 0.0576709
[Epoch 42; Iter   330/  960] train: loss: 0.1288603
[Epoch 42; Iter   360/  960] train: loss: 0.0307854
[Epoch 42; Iter   390/  960] train: loss: 0.0117908
[Epoch 42; Iter   420/  960] train: loss: 0.0366842
[Epoch 42; Iter   450/  960] train: loss: 0.0250563
[Epoch 42; Iter   480/  960] train: loss: 0.0872141
[Epoch 42; Iter   510/  960] train: loss: 0.1396523
[Epoch 42; Iter   540/  960] train: loss: 0.1760949
[Epoch 42; Iter   570/  960] train: loss: 0.0378400
[Epoch 42; Iter   600/  960] train: loss: 0.0376886
[Epoch 42; Iter   630/  960] train: loss: 0.2614561
[Epoch 42; Iter   660/  960] train: loss: 0.0670327
[Epoch 42; Iter   690/  960] train: loss: 0.0413616
[Epoch 42; Iter   720/  960] train: loss: 0.0286037
[Epoch 42; Iter   750/  960] train: loss: 0.1320079
[Epoch 42; Iter   780/  960] train: loss: 0.0117675
[Epoch 42; Iter   810/  960] train: loss: 0.0262867
[Epoch 42; Iter   840/  960] train: loss: 0.0111787
[Epoch 42; Iter   870/  960] train: loss: 0.0613547
[Epoch 42; Iter   900/  960] train: loss: 0.0439657
[Epoch 42; Iter   930/  960] train: loss: 0.0326208
[Epoch 42; Iter   960/  960] train: loss: 0.1028741
[Epoch 42] ogbg-molhiv: 0.815379 val loss: 0.140177
[Epoch 42] ogbg-molhiv: 0.815585 test loss: 0.131407
[Epoch 43; Iter    30/  960] train: loss: 0.0349624
[Epoch 43; Iter    60/  960] train: loss: 0.0068818
[Epoch 43; Iter    90/  960] train: loss: 0.0184933
[Epoch 43; Iter   120/  960] train: loss: 0.1676261
[Epoch 43; Iter   150/  960] train: loss: 0.0394510
[Epoch 43; Iter   180/  960] train: loss: 0.0651167
[Epoch 43; Iter   210/  960] train: loss: 0.0192126
[Epoch 43; Iter   240/  960] train: loss: 0.0412429
[Epoch 43; Iter   270/  960] train: loss: 0.0778454
[Epoch 43; Iter   300/  960] train: loss: 0.0155938
[Epoch 43; Iter   330/  960] train: loss: 0.0071204
[Epoch 43; Iter   360/  960] train: loss: 0.2259024
[Epoch 43; Iter   390/  960] train: loss: 0.0111134
[Epoch 43; Iter   420/  960] train: loss: 0.1055299
[Epoch 43; Iter   450/  960] train: loss: 0.0445655
[Epoch 43; Iter   480/  960] train: loss: 0.1248353
[Epoch 43; Iter   510/  960] train: loss: 0.0399165
[Epoch 43; Iter   540/  960] train: loss: 0.0529142
[Epoch 43; Iter   570/  960] train: loss: 0.1485265
[Epoch 43; Iter   600/  960] train: loss: 0.1215915
[Epoch 43; Iter   630/  960] train: loss: 0.2517961
[Epoch 43; Iter   660/  960] train: loss: 0.0176619
[Epoch 43; Iter   690/  960] train: loss: 0.0270807
[Epoch 43; Iter   720/  960] train: loss: 0.0166122
[Epoch 43; Iter   750/  960] train: loss: 0.0142234
[Epoch 43; Iter   780/  960] train: loss: 0.0129247
[Epoch 43; Iter   810/  960] train: loss: 0.1474578
[Epoch 43; Iter   840/  960] train: loss: 0.1868887
[Epoch 43; Iter   870/  960] train: loss: 0.1576485
[Epoch 43; Iter   900/  960] train: loss: 0.1172270
[Epoch 43; Iter   930/  960] train: loss: 0.0137368
[Epoch 43; Iter   960/  960] train: loss: 0.1016539
[Epoch 43] ogbg-molhiv: 0.814973 val loss: 0.143864
[Epoch 43] ogbg-molhiv: 0.817906 test loss: 0.133273
[Epoch 44; Iter    30/  960] train: loss: 0.1022927
[Epoch 44; Iter    60/  960] train: loss: 0.0248466
[Epoch 44; Iter    90/  960] train: loss: 0.0246822
[Epoch 44; Iter   120/  960] train: loss: 0.0161614
[Epoch 44; Iter   150/  960] train: loss: 0.0466174
[Epoch 44; Iter   180/  960] train: loss: 0.0611323
[Epoch 44; Iter   210/  960] train: loss: 0.0236737
[Epoch 44; Iter   240/  960] train: loss: 0.1224654
[Epoch 44; Iter   270/  960] train: loss: 0.0100441
[Epoch 44; Iter   300/  960] train: loss: 0.1750027
[Epoch 44; Iter   330/  960] train: loss: 0.0840247
[Epoch 44; Iter   360/  960] train: loss: 0.3646719
[Epoch 44; Iter   390/  960] train: loss: 0.0429041
[Epoch 44; Iter   420/  960] train: loss: 0.1177330
[Epoch 44; Iter   450/  960] train: loss: 0.0203171
[Epoch 44; Iter   480/  960] train: loss: 0.0679883
[Epoch 44; Iter   510/  960] train: loss: 0.0729751
[Epoch 44; Iter   540/  960] train: loss: 0.0086128
[Epoch 44; Iter   570/  960] train: loss: 0.0348246
[Epoch 44; Iter   600/  960] train: loss: 0.0119514
[Epoch 44; Iter   630/  960] train: loss: 0.0086431
[Epoch 44; Iter   660/  960] train: loss: 0.1520849
[Epoch 44; Iter   690/  960] train: loss: 0.1614122
[Epoch 44; Iter   720/  960] train: loss: 0.0824861
[Epoch 44; Iter   750/  960] train: loss: 0.0869151
[Epoch 44; Iter   780/  960] train: loss: 0.0846785
[Epoch 44; Iter   810/  960] train: loss: 0.1437897
[Epoch 44; Iter   840/  960] train: loss: 0.0641968
[Epoch 44; Iter   870/  960] train: loss: 0.0180485
[Epoch 44; Iter   900/  960] train: loss: 0.0285931
[Epoch 44; Iter   930/  960] train: loss: 0.1113171
[Epoch 44; Iter   960/  960] train: loss: 0.0394882
[Epoch 44] ogbg-molhiv: 0.805244 val loss: 0.150792
[Epoch 44] ogbg-molhiv: 0.821576 test loss: 0.133890
[Epoch 45; Iter    30/  960] train: loss: 0.0094644
[Epoch 45; Iter    60/  960] train: loss: 0.1859546
[Epoch 45; Iter    90/  960] train: loss: 0.0200606
[Epoch 45; Iter   120/  960] train: loss: 0.0227653
[Epoch 45; Iter   150/  960] train: loss: 0.0230073
[Epoch 45; Iter   180/  960] train: loss: 0.0147344
[Epoch 45; Iter   210/  960] train: loss: 0.0239603
[Epoch 45; Iter   240/  960] train: loss: 0.0211366
[Epoch 45; Iter   270/  960] train: loss: 0.0071702
[Epoch 45; Iter   300/  960] train: loss: 0.0485254
[Epoch 45; Iter   330/  960] train: loss: 0.0445441
[Epoch 45; Iter   360/  960] train: loss: 0.0099860
[Epoch 45; Iter   390/  960] train: loss: 0.0396519
[Epoch 45; Iter   420/  960] train: loss: 0.0375689
[Epoch 45; Iter   450/  960] train: loss: 0.0250904
[Epoch 45; Iter   480/  960] train: loss: 0.0182369
[Epoch 45; Iter   510/  960] train: loss: 0.0110359
[Epoch 45; Iter   540/  960] train: loss: 0.0146473
[Epoch 45; Iter   570/  960] train: loss: 0.1822843
[Epoch 45; Iter   600/  960] train: loss: 0.0193236
[Epoch 45; Iter   630/  960] train: loss: 0.0054939
[Epoch 45; Iter   660/  960] train: loss: 0.0288662
[Epoch 45; Iter   690/  960] train: loss: 0.0214979
[Epoch 45; Iter   720/  960] train: loss: 0.0114654
[Epoch 45; Iter   750/  960] train: loss: 0.1228009
[Epoch 45; Iter   780/  960] train: loss: 0.2841267
[Epoch 45; Iter   810/  960] train: loss: 0.0276833
[Epoch 45; Iter   840/  960] train: loss: 0.0273535
[Epoch 45; Iter   870/  960] train: loss: 0.0808830
[Epoch 45; Iter   900/  960] train: loss: 0.0193513
[Epoch 45; Iter   930/  960] train: loss: 0.0779372
[Epoch 41; Iter   330/  960] train: loss: 0.0761982
[Epoch 41; Iter   360/  960] train: loss: 0.0220822
[Epoch 41; Iter   390/  960] train: loss: 0.0214320
[Epoch 41; Iter   420/  960] train: loss: 0.0544094
[Epoch 41; Iter   450/  960] train: loss: 0.1245449
[Epoch 41; Iter   480/  960] train: loss: 0.0115064
[Epoch 41; Iter   510/  960] train: loss: 0.0679640
[Epoch 41; Iter   540/  960] train: loss: 0.0106746
[Epoch 41; Iter   570/  960] train: loss: 0.0305970
[Epoch 41; Iter   600/  960] train: loss: 0.0189296
[Epoch 41; Iter   630/  960] train: loss: 0.1168209
[Epoch 41; Iter   660/  960] train: loss: 0.0105976
[Epoch 41; Iter   690/  960] train: loss: 0.0046233
[Epoch 41; Iter   720/  960] train: loss: 0.0260472
[Epoch 41; Iter   750/  960] train: loss: 0.1162278
[Epoch 41; Iter   780/  960] train: loss: 0.0615361
[Epoch 41; Iter   810/  960] train: loss: 0.0126816
[Epoch 41; Iter   840/  960] train: loss: 0.0277251
[Epoch 41; Iter   870/  960] train: loss: 0.0101398
[Epoch 41; Iter   900/  960] train: loss: 0.0741037
[Epoch 41; Iter   930/  960] train: loss: 0.0506511
[Epoch 41; Iter   960/  960] train: loss: 0.0225533
[Epoch 41] ogbg-molhiv: 0.817217 val loss: 0.151507
[Epoch 41] ogbg-molhiv: 0.822009 test loss: 0.143607
[Epoch 42; Iter    30/  960] train: loss: 0.0137350
[Epoch 42; Iter    60/  960] train: loss: 0.0129943
[Epoch 42; Iter    90/  960] train: loss: 0.0092634
[Epoch 42; Iter   120/  960] train: loss: 0.0235191
[Epoch 42; Iter   150/  960] train: loss: 0.0106008
[Epoch 42; Iter   180/  960] train: loss: 0.0476818
[Epoch 42; Iter   210/  960] train: loss: 0.0102695
[Epoch 42; Iter   240/  960] train: loss: 0.0454291
[Epoch 42; Iter   270/  960] train: loss: 0.0172533
[Epoch 42; Iter   300/  960] train: loss: 0.0185625
[Epoch 42; Iter   330/  960] train: loss: 0.0062805
[Epoch 42; Iter   360/  960] train: loss: 0.0381001
[Epoch 42; Iter   390/  960] train: loss: 0.0973046
[Epoch 42; Iter   420/  960] train: loss: 0.0320085
[Epoch 42; Iter   450/  960] train: loss: 0.1564489
[Epoch 42; Iter   480/  960] train: loss: 0.0714467
[Epoch 42; Iter   510/  960] train: loss: 0.0815794
[Epoch 42; Iter   540/  960] train: loss: 0.0628531
[Epoch 42; Iter   570/  960] train: loss: 0.3778619
[Epoch 42; Iter   600/  960] train: loss: 0.1458450
[Epoch 42; Iter   630/  960] train: loss: 0.0099133
[Epoch 42; Iter   660/  960] train: loss: 0.0415753
[Epoch 42; Iter   690/  960] train: loss: 0.0056336
[Epoch 42; Iter   720/  960] train: loss: 0.0523270
[Epoch 42; Iter   750/  960] train: loss: 0.0363271
[Epoch 42; Iter   780/  960] train: loss: 0.0688328
[Epoch 42; Iter   810/  960] train: loss: 0.0923812
[Epoch 42; Iter   840/  960] train: loss: 0.0740118
[Epoch 42; Iter   870/  960] train: loss: 0.0253508
[Epoch 42; Iter   900/  960] train: loss: 0.0941903
[Epoch 42; Iter   930/  960] train: loss: 0.0823877
[Epoch 42; Iter   960/  960] train: loss: 0.0732214
[Epoch 42] ogbg-molhiv: 0.819863 val loss: 1.211631
[Epoch 42] ogbg-molhiv: 0.822196 test loss: 1.096881
[Epoch 43; Iter    30/  960] train: loss: 0.0267739
[Epoch 43; Iter    60/  960] train: loss: 0.1536045
[Epoch 43; Iter    90/  960] train: loss: 0.0061362
[Epoch 43; Iter   120/  960] train: loss: 0.0463522
[Epoch 43; Iter   150/  960] train: loss: 0.0098048
[Epoch 43; Iter   180/  960] train: loss: 0.0575070
[Epoch 43; Iter   210/  960] train: loss: 0.0066981
[Epoch 43; Iter   240/  960] train: loss: 0.0358741
[Epoch 43; Iter   270/  960] train: loss: 0.1333593
[Epoch 43; Iter   300/  960] train: loss: 0.1112670
[Epoch 43; Iter   330/  960] train: loss: 0.0173165
[Epoch 43; Iter   360/  960] train: loss: 0.0191489
[Epoch 43; Iter   390/  960] train: loss: 0.0875474
[Epoch 43; Iter   420/  960] train: loss: 0.0732288
[Epoch 43; Iter   450/  960] train: loss: 0.0161837
[Epoch 43; Iter   480/  960] train: loss: 0.0344055
[Epoch 43; Iter   510/  960] train: loss: 0.0077111
[Epoch 43; Iter   540/  960] train: loss: 0.0084114
[Epoch 43; Iter   570/  960] train: loss: 0.1587836
[Epoch 43; Iter   600/  960] train: loss: 0.0266511
[Epoch 43; Iter   630/  960] train: loss: 0.0955033
[Epoch 43; Iter   660/  960] train: loss: 0.0306325
[Epoch 43; Iter   690/  960] train: loss: 0.0096810
[Epoch 43; Iter   720/  960] train: loss: 0.0557945
[Epoch 43; Iter   750/  960] train: loss: 0.0071617
[Epoch 43; Iter   780/  960] train: loss: 0.0171704
[Epoch 43; Iter   810/  960] train: loss: 0.0087931
[Epoch 43; Iter   840/  960] train: loss: 0.0237294
[Epoch 43; Iter   870/  960] train: loss: 0.0229711
[Epoch 43; Iter   900/  960] train: loss: 0.1160024
[Epoch 43; Iter   930/  960] train: loss: 0.0366200
[Epoch 43; Iter   960/  960] train: loss: 0.0114178
[Epoch 43] ogbg-molhiv: 0.823142 val loss: 0.156837
[Epoch 43] ogbg-molhiv: 0.810327 test loss: 0.155689
[Epoch 44; Iter    30/  960] train: loss: 0.0530763
[Epoch 44; Iter    60/  960] train: loss: 0.1184723
[Epoch 44; Iter    90/  960] train: loss: 0.0272495
[Epoch 44; Iter   120/  960] train: loss: 0.0105360
[Epoch 44; Iter   150/  960] train: loss: 0.0069762
[Epoch 44; Iter   180/  960] train: loss: 0.0139227
[Epoch 44; Iter   210/  960] train: loss: 0.0786568
[Epoch 44; Iter   240/  960] train: loss: 0.0295145
[Epoch 44; Iter   270/  960] train: loss: 0.0212007
[Epoch 44; Iter   300/  960] train: loss: 0.0351138
[Epoch 44; Iter   330/  960] train: loss: 0.0456208
[Epoch 44; Iter   360/  960] train: loss: 0.0181416
[Epoch 44; Iter   390/  960] train: loss: 0.1091697
[Epoch 44; Iter   420/  960] train: loss: 0.0096274
[Epoch 44; Iter   450/  960] train: loss: 0.1033215
[Epoch 44; Iter   480/  960] train: loss: 0.0122528
[Epoch 44; Iter   510/  960] train: loss: 0.0038623
[Epoch 44; Iter   540/  960] train: loss: 0.1227672
[Epoch 44; Iter   570/  960] train: loss: 0.0180886
[Epoch 44; Iter   600/  960] train: loss: 0.0053028
[Epoch 44; Iter   630/  960] train: loss: 0.0910254
[Epoch 44; Iter   660/  960] train: loss: 0.0322178
[Epoch 44; Iter   690/  960] train: loss: 0.0720334
[Epoch 44; Iter   720/  960] train: loss: 0.1212210
[Epoch 44; Iter   750/  960] train: loss: 0.0625429
[Epoch 44; Iter   780/  960] train: loss: 0.0145433
[Epoch 44; Iter   810/  960] train: loss: 0.0446898
[Epoch 44; Iter   840/  960] train: loss: 0.0213070
[Epoch 44; Iter   870/  960] train: loss: 0.0692265
[Epoch 44; Iter   900/  960] train: loss: 0.1974197
[Epoch 44; Iter   930/  960] train: loss: 0.0150989
[Epoch 44; Iter   960/  960] train: loss: 0.0021570
[Epoch 44] ogbg-molhiv: 0.824594 val loss: 0.158155
[Epoch 44] ogbg-molhiv: 0.817557 test loss: 0.154866
[Epoch 45; Iter    30/  960] train: loss: 0.0138271
[Epoch 45; Iter    60/  960] train: loss: 0.0272757
[Epoch 45; Iter    90/  960] train: loss: 0.0171072
[Epoch 45; Iter   120/  960] train: loss: 0.0690853
[Epoch 45; Iter   150/  960] train: loss: 0.0705665
[Epoch 45; Iter   180/  960] train: loss: 0.0217208
[Epoch 45; Iter   210/  960] train: loss: 0.0278305
[Epoch 45; Iter   240/  960] train: loss: 0.0164319
[Epoch 45; Iter   270/  960] train: loss: 0.0267908
[Epoch 45; Iter   300/  960] train: loss: 0.1652735
[Epoch 45; Iter   330/  960] train: loss: 0.0933169
[Epoch 45; Iter   360/  960] train: loss: 0.0531637
[Epoch 45; Iter   390/  960] train: loss: 0.1000091
[Epoch 45; Iter   420/  960] train: loss: 0.0247388
[Epoch 45; Iter   450/  960] train: loss: 0.0266332
[Epoch 45; Iter   480/  960] train: loss: 0.0301522
[Epoch 45; Iter   510/  960] train: loss: 0.0043081
[Epoch 45; Iter   540/  960] train: loss: 0.1462106
[Epoch 45; Iter   570/  960] train: loss: 0.0251290
[Epoch 45; Iter   600/  960] train: loss: 0.0670622
[Epoch 45; Iter   630/  960] train: loss: 0.3366214
[Epoch 45; Iter   660/  960] train: loss: 0.0073128
[Epoch 45; Iter   690/  960] train: loss: 0.2234117
[Epoch 45; Iter   720/  960] train: loss: 0.0116753
[Epoch 45; Iter   750/  960] train: loss: 0.2085896
[Epoch 45; Iter   780/  960] train: loss: 0.3091667
[Epoch 45; Iter   810/  960] train: loss: 0.0800027
[Epoch 45; Iter   840/  960] train: loss: 0.0993874
[Epoch 45; Iter   870/  960] train: loss: 0.1485329
[Epoch 45; Iter   900/  960] train: loss: 0.0057356
[Epoch 45; Iter   930/  960] train: loss: 0.0428487
[Epoch 42; Iter   187/  823] train: loss: 0.0381366
[Epoch 42; Iter   217/  823] train: loss: 0.0481949
[Epoch 42; Iter   247/  823] train: loss: 0.0884322
[Epoch 42; Iter   277/  823] train: loss: 0.1751950
[Epoch 42; Iter   307/  823] train: loss: 0.0186031
[Epoch 42; Iter   337/  823] train: loss: 0.0152763
[Epoch 42; Iter   367/  823] train: loss: 0.0253914
[Epoch 42; Iter   397/  823] train: loss: 0.0955199
[Epoch 42; Iter   427/  823] train: loss: 0.0099957
[Epoch 42; Iter   457/  823] train: loss: 0.1861044
[Epoch 42; Iter   487/  823] train: loss: 0.2327300
[Epoch 42; Iter   517/  823] train: loss: 0.0212707
[Epoch 42; Iter   547/  823] train: loss: 0.0681287
[Epoch 42; Iter   577/  823] train: loss: 0.0963478
[Epoch 42; Iter   607/  823] train: loss: 0.1677744
[Epoch 42; Iter   637/  823] train: loss: 0.1628372
[Epoch 42; Iter   667/  823] train: loss: 0.1509614
[Epoch 42; Iter   697/  823] train: loss: 0.1338574
[Epoch 42; Iter   727/  823] train: loss: 0.0605762
[Epoch 42; Iter   757/  823] train: loss: 0.0289292
[Epoch 42; Iter   787/  823] train: loss: 0.2418397
[Epoch 42; Iter   817/  823] train: loss: 0.1508102
[Epoch 42] ogbg-molhiv: 0.833601 val loss: 0.119133
[Epoch 42] ogbg-molhiv: 0.807882 test loss: 0.190976
[Epoch 43; Iter    24/  823] train: loss: 0.0495155
[Epoch 43; Iter    54/  823] train: loss: 0.0261928
[Epoch 43; Iter    84/  823] train: loss: 0.0240184
[Epoch 43; Iter   114/  823] train: loss: 0.0129060
[Epoch 43; Iter   144/  823] train: loss: 0.1028882
[Epoch 43; Iter   174/  823] train: loss: 0.0874990
[Epoch 43; Iter   204/  823] train: loss: 0.0170212
[Epoch 43; Iter   234/  823] train: loss: 0.0114542
[Epoch 43; Iter   264/  823] train: loss: 0.0882420
[Epoch 43; Iter   294/  823] train: loss: 0.0747928
[Epoch 43; Iter   324/  823] train: loss: 0.0060786
[Epoch 43; Iter   354/  823] train: loss: 0.0181860
[Epoch 43; Iter   384/  823] train: loss: 0.0491746
[Epoch 43; Iter   414/  823] train: loss: 0.2272566
[Epoch 43; Iter   444/  823] train: loss: 0.0249907
[Epoch 43; Iter   474/  823] train: loss: 0.0110855
[Epoch 43; Iter   504/  823] train: loss: 0.2589263
[Epoch 43; Iter   534/  823] train: loss: 0.0194078
[Epoch 43; Iter   564/  823] train: loss: 0.0493360
[Epoch 43; Iter   594/  823] train: loss: 0.0168584
[Epoch 43; Iter   624/  823] train: loss: 0.0270240
[Epoch 43; Iter   654/  823] train: loss: 0.0070448
[Epoch 43; Iter   684/  823] train: loss: 0.1669856
[Epoch 43; Iter   714/  823] train: loss: 0.0256879
[Epoch 43; Iter   744/  823] train: loss: 0.0879307
[Epoch 43; Iter   774/  823] train: loss: 0.0660870
[Epoch 43; Iter   804/  823] train: loss: 0.0144940
[Epoch 43] ogbg-molhiv: 0.841120 val loss: 0.153192
[Epoch 43] ogbg-molhiv: 0.807396 test loss: 0.280492
[Epoch 44; Iter    11/  823] train: loss: 0.0463969
[Epoch 44; Iter    41/  823] train: loss: 0.0597646
[Epoch 44; Iter    71/  823] train: loss: 0.0119946
[Epoch 44; Iter   101/  823] train: loss: 0.1200718
[Epoch 44; Iter   131/  823] train: loss: 0.0101249
[Epoch 44; Iter   161/  823] train: loss: 0.0207753
[Epoch 44; Iter   191/  823] train: loss: 0.0473825
[Epoch 44; Iter   221/  823] train: loss: 0.0644934
[Epoch 44; Iter   251/  823] train: loss: 0.0117250
[Epoch 44; Iter   281/  823] train: loss: 0.0150018
[Epoch 44; Iter   311/  823] train: loss: 0.0427949
[Epoch 44; Iter   341/  823] train: loss: 0.0179027
[Epoch 44; Iter   371/  823] train: loss: 0.1746879
[Epoch 44; Iter   401/  823] train: loss: 0.1369956
[Epoch 44; Iter   431/  823] train: loss: 0.0293109
[Epoch 44; Iter   461/  823] train: loss: 0.0228595
[Epoch 44; Iter   491/  823] train: loss: 0.0389965
[Epoch 44; Iter   521/  823] train: loss: 0.0613181
[Epoch 44; Iter   551/  823] train: loss: 0.0311453
[Epoch 44; Iter   581/  823] train: loss: 0.0797080
[Epoch 44; Iter   611/  823] train: loss: 0.1063184
[Epoch 44; Iter   641/  823] train: loss: 0.0329549
[Epoch 44; Iter   671/  823] train: loss: 0.0171464
[Epoch 44; Iter   701/  823] train: loss: 0.0994482
[Epoch 44; Iter   731/  823] train: loss: 0.0212975
[Epoch 44; Iter   761/  823] train: loss: 0.0161396
[Epoch 44; Iter   791/  823] train: loss: 0.0517626
[Epoch 44; Iter   821/  823] train: loss: 0.0366777
[Epoch 44] ogbg-molhiv: 0.834629 val loss: 0.128875
[Epoch 44] ogbg-molhiv: 0.802942 test loss: 0.150386
[Epoch 45; Iter    28/  823] train: loss: 0.0193253
[Epoch 45; Iter    58/  823] train: loss: 0.0309533
[Epoch 45; Iter    88/  823] train: loss: 0.1005562
[Epoch 45; Iter   118/  823] train: loss: 0.0821208
[Epoch 45; Iter   148/  823] train: loss: 0.0226515
[Epoch 45; Iter   178/  823] train: loss: 0.0546722
[Epoch 45; Iter   208/  823] train: loss: 0.0401276
[Epoch 45; Iter   238/  823] train: loss: 0.1059739
[Epoch 45; Iter   268/  823] train: loss: 0.0387874
[Epoch 45; Iter   298/  823] train: loss: 0.0189377
[Epoch 45; Iter   328/  823] train: loss: 0.0377144
[Epoch 45; Iter   358/  823] train: loss: 0.0188575
[Epoch 45; Iter   388/  823] train: loss: 0.0142830
[Epoch 45; Iter   418/  823] train: loss: 0.0211169
[Epoch 45; Iter   448/  823] train: loss: 0.0818537
[Epoch 45; Iter   478/  823] train: loss: 0.0318770
[Epoch 45; Iter   508/  823] train: loss: 0.0238529
[Epoch 45; Iter   538/  823] train: loss: 0.1377667
[Epoch 45; Iter   568/  823] train: loss: 0.0664176
[Epoch 45; Iter   598/  823] train: loss: 0.0163823
[Epoch 45; Iter   628/  823] train: loss: 0.0328682
[Epoch 45; Iter   658/  823] train: loss: 0.0132751
[Epoch 45; Iter   688/  823] train: loss: 0.0329252
[Epoch 45; Iter   718/  823] train: loss: 0.0298025
[Epoch 45; Iter   748/  823] train: loss: 0.0149785
[Epoch 45; Iter   778/  823] train: loss: 0.0612342
[Epoch 45; Iter   808/  823] train: loss: 0.1497096
[Epoch 45] ogbg-molhiv: 0.828680 val loss: 0.126167
[Epoch 45] ogbg-molhiv: 0.801975 test loss: 0.193356
[Epoch 46; Iter    15/  823] train: loss: 0.0237053
[Epoch 46; Iter    45/  823] train: loss: 0.0279258
[Epoch 46; Iter    75/  823] train: loss: 0.2001930
[Epoch 46; Iter   105/  823] train: loss: 0.0072435
[Epoch 46; Iter   135/  823] train: loss: 0.0517804
[Epoch 46; Iter   165/  823] train: loss: 0.0376875
[Epoch 46; Iter   195/  823] train: loss: 0.0105803
[Epoch 46; Iter   225/  823] train: loss: 0.0122988
[Epoch 46; Iter   255/  823] train: loss: 0.0599579
[Epoch 46; Iter   285/  823] train: loss: 0.0132185
[Epoch 46; Iter   315/  823] train: loss: 0.0354346
[Epoch 46; Iter   345/  823] train: loss: 0.0147507
[Epoch 46; Iter   375/  823] train: loss: 0.0134819
[Epoch 46; Iter   405/  823] train: loss: 0.0711748
[Epoch 46; Iter   435/  823] train: loss: 0.0134694
[Epoch 46; Iter   465/  823] train: loss: 0.0200649
[Epoch 46; Iter   495/  823] train: loss: 0.0144479
[Epoch 46; Iter   525/  823] train: loss: 0.0542788
[Epoch 46; Iter   555/  823] train: loss: 0.0145438
[Epoch 46; Iter   585/  823] train: loss: 0.2361338
[Epoch 46; Iter   615/  823] train: loss: 0.1544744
[Epoch 46; Iter   645/  823] train: loss: 0.0326994
[Epoch 46; Iter   675/  823] train: loss: 0.0153240
[Epoch 46; Iter   705/  823] train: loss: 0.0756385
[Epoch 46; Iter   735/  823] train: loss: 0.0757976
[Epoch 46; Iter   765/  823] train: loss: 0.0575972
[Epoch 46; Iter   795/  823] train: loss: 0.2081484
[Epoch 46] ogbg-molhiv: 0.830740 val loss: 0.124260
[Epoch 46] ogbg-molhiv: 0.806870 test loss: 0.161182
[Epoch 47; Iter     2/  823] train: loss: 0.0187014
[Epoch 47; Iter    32/  823] train: loss: 0.0089684
[Epoch 47; Iter    62/  823] train: loss: 0.0234349
[Epoch 47; Iter    92/  823] train: loss: 0.0373818
[Epoch 47; Iter   122/  823] train: loss: 0.0164412
[Epoch 47; Iter   152/  823] train: loss: 0.0110665
[Epoch 47; Iter   182/  823] train: loss: 0.1664780
[Epoch 47; Iter   212/  823] train: loss: 0.0159475
[Epoch 47; Iter   242/  823] train: loss: 0.0270868
[Epoch 47; Iter   272/  823] train: loss: 0.0389735
[Epoch 47; Iter   302/  823] train: loss: 0.0163999
[Epoch 47; Iter   332/  823] train: loss: 0.0628448
[Epoch 47; Iter   362/  823] train: loss: 0.0417680
[Epoch 47; Iter   392/  823] train: loss: 0.1311900
[Epoch 47; Iter   422/  823] train: loss: 0.0472511
[Epoch 47; Iter   452/  823] train: loss: 0.0250916
[Epoch 41; Iter   330/  960] train: loss: 0.1525280
[Epoch 41; Iter   360/  960] train: loss: 0.1214510
[Epoch 41; Iter   390/  960] train: loss: 0.1115784
[Epoch 41; Iter   420/  960] train: loss: 0.0671853
[Epoch 41; Iter   450/  960] train: loss: 0.1935911
[Epoch 41; Iter   480/  960] train: loss: 0.0898880
[Epoch 41; Iter   510/  960] train: loss: 0.1969398
[Epoch 41; Iter   540/  960] train: loss: 0.1500382
[Epoch 41; Iter   570/  960] train: loss: 0.0422957
[Epoch 41; Iter   600/  960] train: loss: 0.1577524
[Epoch 41; Iter   630/  960] train: loss: 0.2251743
[Epoch 41; Iter   660/  960] train: loss: 0.0155625
[Epoch 41; Iter   690/  960] train: loss: 0.0148183
[Epoch 41; Iter   720/  960] train: loss: 0.0098779
[Epoch 41; Iter   750/  960] train: loss: 0.0112558
[Epoch 41; Iter   780/  960] train: loss: 0.0301177
[Epoch 41; Iter   810/  960] train: loss: 0.0227838
[Epoch 41; Iter   840/  960] train: loss: 0.0163383
[Epoch 41; Iter   870/  960] train: loss: 0.0126456
[Epoch 41; Iter   900/  960] train: loss: 0.1679221
[Epoch 41; Iter   930/  960] train: loss: 0.0935263
[Epoch 41; Iter   960/  960] train: loss: 0.0282930
[Epoch 41] ogbg-molhiv: 0.812131 val loss: 0.133571
[Epoch 41] ogbg-molhiv: 0.816639 test loss: 0.126972
[Epoch 42; Iter    30/  960] train: loss: 0.0116484
[Epoch 42; Iter    60/  960] train: loss: 0.3042959
[Epoch 42; Iter    90/  960] train: loss: 0.0123221
[Epoch 42; Iter   120/  960] train: loss: 0.0491180
[Epoch 42; Iter   150/  960] train: loss: 0.1270985
[Epoch 42; Iter   180/  960] train: loss: 0.0183408
[Epoch 42; Iter   210/  960] train: loss: 0.0222995
[Epoch 42; Iter   240/  960] train: loss: 0.0113581
[Epoch 42; Iter   270/  960] train: loss: 0.0360856
[Epoch 42; Iter   300/  960] train: loss: 0.0207704
[Epoch 42; Iter   330/  960] train: loss: 0.1935956
[Epoch 42; Iter   360/  960] train: loss: 0.2385080
[Epoch 42; Iter   390/  960] train: loss: 0.0408785
[Epoch 42; Iter   420/  960] train: loss: 0.0271326
[Epoch 42; Iter   450/  960] train: loss: 0.0980616
[Epoch 42; Iter   480/  960] train: loss: 0.0093576
[Epoch 42; Iter   510/  960] train: loss: 0.0207080
[Epoch 42; Iter   540/  960] train: loss: 0.1685516
[Epoch 42; Iter   570/  960] train: loss: 0.0064135
[Epoch 42; Iter   600/  960] train: loss: 0.0828956
[Epoch 42; Iter   630/  960] train: loss: 0.2513582
[Epoch 42; Iter   660/  960] train: loss: 0.0104069
[Epoch 42; Iter   690/  960] train: loss: 0.0177452
[Epoch 42; Iter   720/  960] train: loss: 0.1304316
[Epoch 42; Iter   750/  960] train: loss: 0.1224740
[Epoch 42; Iter   780/  960] train: loss: 0.0126936
[Epoch 42; Iter   810/  960] train: loss: 0.0122527
[Epoch 42; Iter   840/  960] train: loss: 0.1590071
[Epoch 42; Iter   870/  960] train: loss: 0.0105147
[Epoch 42; Iter   900/  960] train: loss: 0.0630953
[Epoch 42; Iter   930/  960] train: loss: 0.0873815
[Epoch 42; Iter   960/  960] train: loss: 0.0377935
[Epoch 42] ogbg-molhiv: 0.803836 val loss: 0.143929
[Epoch 42] ogbg-molhiv: 0.804531 test loss: 0.154803
[Epoch 43; Iter    30/  960] train: loss: 0.0128380
[Epoch 43; Iter    60/  960] train: loss: 0.0417689
[Epoch 43; Iter    90/  960] train: loss: 0.0275134
[Epoch 43; Iter   120/  960] train: loss: 0.0140058
[Epoch 43; Iter   150/  960] train: loss: 0.0659050
[Epoch 43; Iter   180/  960] train: loss: 0.0448018
[Epoch 43; Iter   210/  960] train: loss: 0.2734956
[Epoch 43; Iter   240/  960] train: loss: 0.0285243
[Epoch 43; Iter   270/  960] train: loss: 0.0555892
[Epoch 43; Iter   300/  960] train: loss: 0.0177845
[Epoch 43; Iter   330/  960] train: loss: 0.1770924
[Epoch 43; Iter   360/  960] train: loss: 0.0270968
[Epoch 43; Iter   390/  960] train: loss: 0.1370982
[Epoch 43; Iter   420/  960] train: loss: 0.0257458
[Epoch 43; Iter   450/  960] train: loss: 0.0993504
[Epoch 43; Iter   480/  960] train: loss: 0.1635884
[Epoch 43; Iter   510/  960] train: loss: 0.0047527
[Epoch 43; Iter   540/  960] train: loss: 0.0177665
[Epoch 43; Iter   570/  960] train: loss: 0.0192945
[Epoch 43; Iter   600/  960] train: loss: 0.0412845
[Epoch 43; Iter   630/  960] train: loss: 0.0291860
[Epoch 43; Iter   660/  960] train: loss: 0.0193888
[Epoch 43; Iter   690/  960] train: loss: 0.0417966
[Epoch 43; Iter   720/  960] train: loss: 0.0117907
[Epoch 43; Iter   750/  960] train: loss: 0.1764082
[Epoch 43; Iter   780/  960] train: loss: 0.0586701
[Epoch 43; Iter   810/  960] train: loss: 0.0962340
[Epoch 43; Iter   840/  960] train: loss: 0.0130461
[Epoch 43; Iter   870/  960] train: loss: 0.1072483
[Epoch 43; Iter   900/  960] train: loss: 0.1574475
[Epoch 43; Iter   930/  960] train: loss: 0.0524930
[Epoch 43; Iter   960/  960] train: loss: 0.0152524
[Epoch 43] ogbg-molhiv: 0.807751 val loss: 0.145086
[Epoch 43] ogbg-molhiv: 0.793399 test loss: 0.143364
[Epoch 44; Iter    30/  960] train: loss: 0.1118953
[Epoch 44; Iter    60/  960] train: loss: 0.0194473
[Epoch 44; Iter    90/  960] train: loss: 0.0438382
[Epoch 44; Iter   120/  960] train: loss: 0.0907012
[Epoch 44; Iter   150/  960] train: loss: 0.0986846
[Epoch 44; Iter   180/  960] train: loss: 0.0734731
[Epoch 44; Iter   210/  960] train: loss: 0.0637665
[Epoch 44; Iter   240/  960] train: loss: 0.0167443
[Epoch 44; Iter   270/  960] train: loss: 0.0591937
[Epoch 44; Iter   300/  960] train: loss: 0.0102771
[Epoch 44; Iter   330/  960] train: loss: 0.0238498
[Epoch 44; Iter   360/  960] train: loss: 0.0108468
[Epoch 44; Iter   390/  960] train: loss: 0.0529038
[Epoch 44; Iter   420/  960] train: loss: 0.1053131
[Epoch 44; Iter   450/  960] train: loss: 0.0165379
[Epoch 44; Iter   480/  960] train: loss: 0.0336164
[Epoch 44; Iter   510/  960] train: loss: 0.0708578
[Epoch 44; Iter   540/  960] train: loss: 0.0929201
[Epoch 44; Iter   570/  960] train: loss: 0.0342634
[Epoch 44; Iter   600/  960] train: loss: 0.0131967
[Epoch 44; Iter   630/  960] train: loss: 0.0701558
[Epoch 44; Iter   660/  960] train: loss: 0.0099568
[Epoch 44; Iter   690/  960] train: loss: 0.0119549
[Epoch 44; Iter   720/  960] train: loss: 0.0650379
[Epoch 44; Iter   750/  960] train: loss: 0.0642592
[Epoch 44; Iter   780/  960] train: loss: 0.2794763
[Epoch 44; Iter   810/  960] train: loss: 0.0087175
[Epoch 44; Iter   840/  960] train: loss: 0.0225306
[Epoch 44; Iter   870/  960] train: loss: 0.0201757
[Epoch 44; Iter   900/  960] train: loss: 0.0077273
[Epoch 44; Iter   930/  960] train: loss: 0.2894114
[Epoch 44; Iter   960/  960] train: loss: 0.0129171
[Epoch 44] ogbg-molhiv: 0.807000 val loss: 0.145593
[Epoch 44] ogbg-molhiv: 0.808571 test loss: 0.136569
[Epoch 45; Iter    30/  960] train: loss: 0.0256413
[Epoch 45; Iter    60/  960] train: loss: 0.0976556
[Epoch 45; Iter    90/  960] train: loss: 0.0416170
[Epoch 45; Iter   120/  960] train: loss: 0.0892327
[Epoch 45; Iter   150/  960] train: loss: 0.0105344
[Epoch 45; Iter   180/  960] train: loss: 0.0075608
[Epoch 45; Iter   210/  960] train: loss: 0.0068840
[Epoch 45; Iter   240/  960] train: loss: 0.2021712
[Epoch 45; Iter   270/  960] train: loss: 0.0818923
[Epoch 45; Iter   300/  960] train: loss: 0.0375804
[Epoch 45; Iter   330/  960] train: loss: 0.1447391
[Epoch 45; Iter   360/  960] train: loss: 0.0255799
[Epoch 45; Iter   390/  960] train: loss: 0.0433802
[Epoch 45; Iter   420/  960] train: loss: 0.0122902
[Epoch 45; Iter   450/  960] train: loss: 0.1208869
[Epoch 45; Iter   480/  960] train: loss: 0.0089155
[Epoch 45; Iter   510/  960] train: loss: 0.0136903
[Epoch 45; Iter   540/  960] train: loss: 0.1951803
[Epoch 45; Iter   570/  960] train: loss: 0.0139493
[Epoch 45; Iter   600/  960] train: loss: 0.2445296
[Epoch 45; Iter   630/  960] train: loss: 0.0233384
[Epoch 45; Iter   660/  960] train: loss: 0.0250651
[Epoch 45; Iter   690/  960] train: loss: 0.0385833
[Epoch 45; Iter   720/  960] train: loss: 0.0173854
[Epoch 45; Iter   750/  960] train: loss: 0.0616365
[Epoch 45; Iter   780/  960] train: loss: 0.0117056
[Epoch 45; Iter   810/  960] train: loss: 0.0342335
[Epoch 45; Iter   840/  960] train: loss: 0.0162018
[Epoch 45; Iter   870/  960] train: loss: 0.0191902
[Epoch 45; Iter   900/  960] train: loss: 0.0145278
[Epoch 45; Iter   930/  960] train: loss: 0.0342586
[Epoch 40; Iter   717/ 1097] train: loss: 0.2263525
[Epoch 40; Iter   747/ 1097] train: loss: 0.1284404
[Epoch 40; Iter   777/ 1097] train: loss: 0.0413928
[Epoch 40; Iter   807/ 1097] train: loss: 0.0352957
[Epoch 40; Iter   837/ 1097] train: loss: 0.2647429
[Epoch 40; Iter   867/ 1097] train: loss: 0.0219019
[Epoch 40; Iter   897/ 1097] train: loss: 0.0221532
[Epoch 40; Iter   927/ 1097] train: loss: 0.0151569
[Epoch 40; Iter   957/ 1097] train: loss: 0.0878541
[Epoch 40; Iter   987/ 1097] train: loss: 0.0595126
[Epoch 40; Iter  1017/ 1097] train: loss: 0.1008866
[Epoch 40; Iter  1047/ 1097] train: loss: 0.2147484
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0699191
[Epoch 40] ogbg-molhiv: 0.833786 val loss: 0.248539
[Epoch 40] ogbg-molhiv: 0.819732 test loss: 0.115105
[Epoch 41; Iter    10/ 1097] train: loss: 0.0230369
[Epoch 41; Iter    40/ 1097] train: loss: 0.1737775
[Epoch 41; Iter    70/ 1097] train: loss: 0.0331277
[Epoch 41; Iter   100/ 1097] train: loss: 0.1879736
[Epoch 41; Iter   130/ 1097] train: loss: 0.2282012
[Epoch 41; Iter   160/ 1097] train: loss: 0.1499241
[Epoch 41; Iter   190/ 1097] train: loss: 0.0116214
[Epoch 41; Iter   220/ 1097] train: loss: 0.0159748
[Epoch 41; Iter   250/ 1097] train: loss: 0.2205106
[Epoch 41; Iter   280/ 1097] train: loss: 0.0283211
[Epoch 41; Iter   310/ 1097] train: loss: 0.0457363
[Epoch 41; Iter   340/ 1097] train: loss: 0.0381522
[Epoch 41; Iter   370/ 1097] train: loss: 0.0654189
[Epoch 41; Iter   400/ 1097] train: loss: 0.0206276
[Epoch 41; Iter   430/ 1097] train: loss: 0.1904340
[Epoch 41; Iter   460/ 1097] train: loss: 0.0299568
[Epoch 41; Iter   490/ 1097] train: loss: 0.1437901
[Epoch 41; Iter   520/ 1097] train: loss: 0.0288723
[Epoch 41; Iter   550/ 1097] train: loss: 0.0168512
[Epoch 41; Iter   580/ 1097] train: loss: 0.0279896
[Epoch 41; Iter   610/ 1097] train: loss: 0.0871551
[Epoch 41; Iter   640/ 1097] train: loss: 0.0281476
[Epoch 41; Iter   670/ 1097] train: loss: 0.1060141
[Epoch 41; Iter   700/ 1097] train: loss: 0.3969393
[Epoch 41; Iter   730/ 1097] train: loss: 0.1898565
[Epoch 41; Iter   760/ 1097] train: loss: 0.0797434
[Epoch 41; Iter   790/ 1097] train: loss: 0.0400831
[Epoch 41; Iter   820/ 1097] train: loss: 0.0323573
[Epoch 41; Iter   850/ 1097] train: loss: 0.0315414
[Epoch 41; Iter   880/ 1097] train: loss: 0.2289731
[Epoch 41; Iter   910/ 1097] train: loss: 0.0919815
[Epoch 41; Iter   940/ 1097] train: loss: 0.0262822
[Epoch 41; Iter   970/ 1097] train: loss: 0.0419343
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0913194
[Epoch 41; Iter  1030/ 1097] train: loss: 0.1005225
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0485493
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0482254
[Epoch 41] ogbg-molhiv: 0.839534 val loss: 0.367994
[Epoch 41] ogbg-molhiv: 0.810581 test loss: 0.316065
[Epoch 42; Iter    23/ 1097] train: loss: 0.1233154
[Epoch 42; Iter    53/ 1097] train: loss: 0.1041583
[Epoch 42; Iter    83/ 1097] train: loss: 0.1144351
[Epoch 42; Iter   113/ 1097] train: loss: 0.0238561
[Epoch 42; Iter   143/ 1097] train: loss: 0.3264366
[Epoch 42; Iter   173/ 1097] train: loss: 0.1477493
[Epoch 42; Iter   203/ 1097] train: loss: 0.0318720
[Epoch 42; Iter   233/ 1097] train: loss: 0.1462610
[Epoch 42; Iter   263/ 1097] train: loss: 0.1365620
[Epoch 42; Iter   293/ 1097] train: loss: 0.2787889
[Epoch 42; Iter   323/ 1097] train: loss: 0.1279044
[Epoch 42; Iter   353/ 1097] train: loss: 0.0492079
[Epoch 42; Iter   383/ 1097] train: loss: 0.0228840
[Epoch 42; Iter   413/ 1097] train: loss: 0.1307954
[Epoch 42; Iter   443/ 1097] train: loss: 0.0550161
[Epoch 42; Iter   473/ 1097] train: loss: 0.0758690
[Epoch 42; Iter   503/ 1097] train: loss: 0.2213788
[Epoch 42; Iter   533/ 1097] train: loss: 0.0150032
[Epoch 42; Iter   563/ 1097] train: loss: 0.1539409
[Epoch 42; Iter   593/ 1097] train: loss: 0.0130472
[Epoch 42; Iter   623/ 1097] train: loss: 0.0214052
[Epoch 42; Iter   653/ 1097] train: loss: 0.1515853
[Epoch 42; Iter   683/ 1097] train: loss: 0.1600870
[Epoch 42; Iter   713/ 1097] train: loss: 0.1637442
[Epoch 42; Iter   743/ 1097] train: loss: 0.2708665
[Epoch 42; Iter   773/ 1097] train: loss: 0.0242315
[Epoch 42; Iter   803/ 1097] train: loss: 0.0145385
[Epoch 42; Iter   833/ 1097] train: loss: 0.1542223
[Epoch 42; Iter   863/ 1097] train: loss: 0.0328465
[Epoch 42; Iter   893/ 1097] train: loss: 0.0629700
[Epoch 42; Iter   923/ 1097] train: loss: 0.0495438
[Epoch 42; Iter   953/ 1097] train: loss: 0.0190256
[Epoch 42; Iter   983/ 1097] train: loss: 0.0143569
[Epoch 42; Iter  1013/ 1097] train: loss: 0.0143722
[Epoch 42; Iter  1043/ 1097] train: loss: 0.1347450
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0976557
[Epoch 42] ogbg-molhiv: 0.822796 val loss: 0.292760
[Epoch 42] ogbg-molhiv: 0.810347 test loss: 0.118351
[Epoch 43; Iter     6/ 1097] train: loss: 0.0396080
[Epoch 43; Iter    36/ 1097] train: loss: 0.2401322
[Epoch 43; Iter    66/ 1097] train: loss: 0.3320568
[Epoch 43; Iter    96/ 1097] train: loss: 0.0234160
[Epoch 43; Iter   126/ 1097] train: loss: 0.1019330
[Epoch 43; Iter   156/ 1097] train: loss: 0.0200743
[Epoch 43; Iter   186/ 1097] train: loss: 0.0411750
[Epoch 43; Iter   216/ 1097] train: loss: 0.0805141
[Epoch 43; Iter   246/ 1097] train: loss: 0.0410563
[Epoch 43; Iter   276/ 1097] train: loss: 0.0274343
[Epoch 43; Iter   306/ 1097] train: loss: 0.0273816
[Epoch 43; Iter   336/ 1097] train: loss: 0.0272520
[Epoch 43; Iter   366/ 1097] train: loss: 0.1823999
[Epoch 43; Iter   396/ 1097] train: loss: 0.1002517
[Epoch 43; Iter   426/ 1097] train: loss: 0.0285263
[Epoch 43; Iter   456/ 1097] train: loss: 0.0753847
[Epoch 43; Iter   486/ 1097] train: loss: 0.1527943
[Epoch 43; Iter   516/ 1097] train: loss: 0.0174093
[Epoch 43; Iter   546/ 1097] train: loss: 0.0407385
[Epoch 43; Iter   576/ 1097] train: loss: 0.0116977
[Epoch 43; Iter   606/ 1097] train: loss: 0.0181065
[Epoch 43; Iter   636/ 1097] train: loss: 0.0488170
[Epoch 43; Iter   666/ 1097] train: loss: 0.0189166
[Epoch 43; Iter   696/ 1097] train: loss: 0.0971495
[Epoch 43; Iter   726/ 1097] train: loss: 0.0263131
[Epoch 43; Iter   756/ 1097] train: loss: 0.2875163
[Epoch 43; Iter   786/ 1097] train: loss: 0.0627012
[Epoch 43; Iter   816/ 1097] train: loss: 0.0140041
[Epoch 43; Iter   846/ 1097] train: loss: 0.0311202
[Epoch 43; Iter   876/ 1097] train: loss: 0.0298919
[Epoch 43; Iter   906/ 1097] train: loss: 0.0310984
[Epoch 43; Iter   936/ 1097] train: loss: 0.1637747
[Epoch 43; Iter   966/ 1097] train: loss: 0.1392422
[Epoch 43; Iter   996/ 1097] train: loss: 0.0685831
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0290756
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0492353
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0962789
[Epoch 43] ogbg-molhiv: 0.825881 val loss: 0.119982
[Epoch 43] ogbg-molhiv: 0.809187 test loss: 0.118567
[Epoch 44; Iter    19/ 1097] train: loss: 0.1558176
[Epoch 44; Iter    49/ 1097] train: loss: 0.0321043
[Epoch 44; Iter    79/ 1097] train: loss: 0.0156465
[Epoch 44; Iter   109/ 1097] train: loss: 0.0143120
[Epoch 44; Iter   139/ 1097] train: loss: 0.0287524
[Epoch 44; Iter   169/ 1097] train: loss: 0.0393747
[Epoch 44; Iter   199/ 1097] train: loss: 0.0651138
[Epoch 44; Iter   229/ 1097] train: loss: 0.2752064
[Epoch 44; Iter   259/ 1097] train: loss: 0.0661987
[Epoch 44; Iter   289/ 1097] train: loss: 0.0947236
[Epoch 44; Iter   319/ 1097] train: loss: 0.0183546
[Epoch 44; Iter   349/ 1097] train: loss: 0.0231016
[Epoch 44; Iter   379/ 1097] train: loss: 0.0823101
[Epoch 44; Iter   409/ 1097] train: loss: 0.1941733
[Epoch 44; Iter   439/ 1097] train: loss: 0.0612297
[Epoch 44; Iter   469/ 1097] train: loss: 0.0702602
[Epoch 44; Iter   499/ 1097] train: loss: 0.1725177
[Epoch 44; Iter   529/ 1097] train: loss: 0.1454620
[Epoch 44; Iter   559/ 1097] train: loss: 0.0576036
[Epoch 44; Iter   589/ 1097] train: loss: 0.0296369
[Epoch 44; Iter   619/ 1097] train: loss: 0.1503765
[Epoch 44; Iter   649/ 1097] train: loss: 0.0192102
[Epoch 44; Iter   679/ 1097] train: loss: 0.0212032
[Epoch 44; Iter   709/ 1097] train: loss: 0.0237297
[Epoch 44; Iter   739/ 1097] train: loss: 0.0180518
[Epoch 44; Iter   769/ 1097] train: loss: 0.0140219
[Epoch 40; Iter   717/ 1097] train: loss: 0.0293721
[Epoch 40; Iter   747/ 1097] train: loss: 0.0041777
[Epoch 40; Iter   777/ 1097] train: loss: 0.0198267
[Epoch 40; Iter   807/ 1097] train: loss: 0.1243830
[Epoch 40; Iter   837/ 1097] train: loss: 0.0713741
[Epoch 40; Iter   867/ 1097] train: loss: 0.2045563
[Epoch 40; Iter   897/ 1097] train: loss: 0.0339119
[Epoch 40; Iter   927/ 1097] train: loss: 0.0106737
[Epoch 40; Iter   957/ 1097] train: loss: 0.0220390
[Epoch 40; Iter   987/ 1097] train: loss: 0.4018234
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0066872
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0652098
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0657337
[Epoch 40] ogbg-molhiv: 0.794293 val loss: 0.140281
[Epoch 40] ogbg-molhiv: 0.808453 test loss: 0.138268
[Epoch 41; Iter    10/ 1097] train: loss: 0.0212357
[Epoch 41; Iter    40/ 1097] train: loss: 0.0559616
[Epoch 41; Iter    70/ 1097] train: loss: 0.0976446
[Epoch 41; Iter   100/ 1097] train: loss: 0.0415971
[Epoch 41; Iter   130/ 1097] train: loss: 0.0136012
[Epoch 41; Iter   160/ 1097] train: loss: 0.0221337
[Epoch 41; Iter   190/ 1097] train: loss: 0.1159145
[Epoch 41; Iter   220/ 1097] train: loss: 0.0275292
[Epoch 41; Iter   250/ 1097] train: loss: 0.2324122
[Epoch 41; Iter   280/ 1097] train: loss: 0.0663188
[Epoch 41; Iter   310/ 1097] train: loss: 0.0607208
[Epoch 41; Iter   340/ 1097] train: loss: 0.1360483
[Epoch 41; Iter   370/ 1097] train: loss: 0.0325800
[Epoch 41; Iter   400/ 1097] train: loss: 0.2604814
[Epoch 41; Iter   430/ 1097] train: loss: 0.1621951
[Epoch 41; Iter   460/ 1097] train: loss: 0.0553750
[Epoch 41; Iter   490/ 1097] train: loss: 0.0340805
[Epoch 41; Iter   520/ 1097] train: loss: 0.0204345
[Epoch 41; Iter   550/ 1097] train: loss: 0.0237347
[Epoch 41; Iter   580/ 1097] train: loss: 0.0069908
[Epoch 41; Iter   610/ 1097] train: loss: 0.1657308
[Epoch 41; Iter   640/ 1097] train: loss: 0.0429000
[Epoch 41; Iter   670/ 1097] train: loss: 0.1172404
[Epoch 41; Iter   700/ 1097] train: loss: 0.0090640
[Epoch 41; Iter   730/ 1097] train: loss: 0.0356750
[Epoch 41; Iter   760/ 1097] train: loss: 0.0148872
[Epoch 41; Iter   790/ 1097] train: loss: 0.0096866
[Epoch 41; Iter   820/ 1097] train: loss: 0.0112120
[Epoch 41; Iter   850/ 1097] train: loss: 0.0994965
[Epoch 41; Iter   880/ 1097] train: loss: 0.0762860
[Epoch 41; Iter   910/ 1097] train: loss: 0.0560142
[Epoch 41; Iter   940/ 1097] train: loss: 0.0202594
[Epoch 41; Iter   970/ 1097] train: loss: 0.0433932
[Epoch 41; Iter  1000/ 1097] train: loss: 0.1873470
[Epoch 41; Iter  1030/ 1097] train: loss: 0.1359337
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0101494
[Epoch 41; Iter  1090/ 1097] train: loss: 0.1010841
[Epoch 41] ogbg-molhiv: 0.798365 val loss: 0.239523
[Epoch 41] ogbg-molhiv: 0.809839 test loss: 0.248868
[Epoch 42; Iter    23/ 1097] train: loss: 0.1955884
[Epoch 42; Iter    53/ 1097] train: loss: 0.0422104
[Epoch 42; Iter    83/ 1097] train: loss: 0.0108521
[Epoch 42; Iter   113/ 1097] train: loss: 0.0449840
[Epoch 42; Iter   143/ 1097] train: loss: 0.0474818
[Epoch 42; Iter   173/ 1097] train: loss: 0.0491458
[Epoch 42; Iter   203/ 1097] train: loss: 0.1364312
[Epoch 42; Iter   233/ 1097] train: loss: 0.0554820
[Epoch 42; Iter   263/ 1097] train: loss: 0.0092408
[Epoch 42; Iter   293/ 1097] train: loss: 0.0216950
[Epoch 42; Iter   323/ 1097] train: loss: 0.0401352
[Epoch 42; Iter   353/ 1097] train: loss: 0.0107963
[Epoch 42; Iter   383/ 1097] train: loss: 0.1371695
[Epoch 42; Iter   413/ 1097] train: loss: 0.0410354
[Epoch 42; Iter   443/ 1097] train: loss: 0.1729402
[Epoch 42; Iter   473/ 1097] train: loss: 0.0062170
[Epoch 42; Iter   503/ 1097] train: loss: 0.0162366
[Epoch 42; Iter   533/ 1097] train: loss: 0.0267548
[Epoch 42; Iter   563/ 1097] train: loss: 0.0290964
[Epoch 42; Iter   593/ 1097] train: loss: 0.0539776
[Epoch 42; Iter   623/ 1097] train: loss: 0.0487105
[Epoch 42; Iter   653/ 1097] train: loss: 0.0068166
[Epoch 42; Iter   683/ 1097] train: loss: 0.1072152
[Epoch 42; Iter   713/ 1097] train: loss: 0.0483520
[Epoch 42; Iter   743/ 1097] train: loss: 0.0222729
[Epoch 42; Iter   773/ 1097] train: loss: 0.0775220
[Epoch 42; Iter   803/ 1097] train: loss: 0.0101176
[Epoch 42; Iter   833/ 1097] train: loss: 0.0767446
[Epoch 42; Iter   863/ 1097] train: loss: 0.0091362
[Epoch 42; Iter   893/ 1097] train: loss: 0.0111593
[Epoch 42; Iter   923/ 1097] train: loss: 0.0066430
[Epoch 42; Iter   953/ 1097] train: loss: 0.0098318
[Epoch 42; Iter   983/ 1097] train: loss: 0.0415789
[Epoch 42; Iter  1013/ 1097] train: loss: 0.0410600
[Epoch 42; Iter  1043/ 1097] train: loss: 0.1421729
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0634094
[Epoch 42] ogbg-molhiv: 0.803170 val loss: 0.255600
[Epoch 42] ogbg-molhiv: 0.817798 test loss: 0.433623
[Epoch 43; Iter     6/ 1097] train: loss: 0.0185104
[Epoch 43; Iter    36/ 1097] train: loss: 0.1591492
[Epoch 43; Iter    66/ 1097] train: loss: 0.0709974
[Epoch 43; Iter    96/ 1097] train: loss: 0.0502272
[Epoch 43; Iter   126/ 1097] train: loss: 0.1107720
[Epoch 43; Iter   156/ 1097] train: loss: 0.0966170
[Epoch 43; Iter   186/ 1097] train: loss: 0.0127279
[Epoch 43; Iter   216/ 1097] train: loss: 0.0141866
[Epoch 43; Iter   246/ 1097] train: loss: 0.0927926
[Epoch 43; Iter   276/ 1097] train: loss: 0.0669001
[Epoch 43; Iter   306/ 1097] train: loss: 0.0133780
[Epoch 43; Iter   336/ 1097] train: loss: 0.0086430
[Epoch 43; Iter   366/ 1097] train: loss: 0.0159908
[Epoch 43; Iter   396/ 1097] train: loss: 0.0126713
[Epoch 43; Iter   426/ 1097] train: loss: 0.0070889
[Epoch 43; Iter   456/ 1097] train: loss: 0.0147536
[Epoch 43; Iter   486/ 1097] train: loss: 0.0315527
[Epoch 43; Iter   516/ 1097] train: loss: 0.0055131
[Epoch 43; Iter   546/ 1097] train: loss: 0.0375447
[Epoch 43; Iter   576/ 1097] train: loss: 0.0365540
[Epoch 43; Iter   606/ 1097] train: loss: 0.1686551
[Epoch 43; Iter   636/ 1097] train: loss: 0.0103815
[Epoch 43; Iter   666/ 1097] train: loss: 0.0442105
[Epoch 43; Iter   696/ 1097] train: loss: 0.0117897
[Epoch 43; Iter   726/ 1097] train: loss: 0.1368840
[Epoch 43; Iter   756/ 1097] train: loss: 0.0188149
[Epoch 43; Iter   786/ 1097] train: loss: 0.1682640
[Epoch 43; Iter   816/ 1097] train: loss: 0.0852172
[Epoch 43; Iter   846/ 1097] train: loss: 0.1283889
[Epoch 43; Iter   876/ 1097] train: loss: 0.1052554
[Epoch 43; Iter   906/ 1097] train: loss: 0.0161791
[Epoch 43; Iter   936/ 1097] train: loss: 0.0413216
[Epoch 43; Iter   966/ 1097] train: loss: 0.0160669
[Epoch 43; Iter   996/ 1097] train: loss: 0.0583631
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0558687
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0223704
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0219111
[Epoch 43] ogbg-molhiv: 0.801737 val loss: 0.155117
[Epoch 43] ogbg-molhiv: 0.815714 test loss: 0.177643
[Epoch 44; Iter    19/ 1097] train: loss: 0.1514332
[Epoch 44; Iter    49/ 1097] train: loss: 0.3173456
[Epoch 44; Iter    79/ 1097] train: loss: 0.0067891
[Epoch 44; Iter   109/ 1097] train: loss: 0.0121165
[Epoch 44; Iter   139/ 1097] train: loss: 0.2086080
[Epoch 44; Iter   169/ 1097] train: loss: 0.0777828
[Epoch 44; Iter   199/ 1097] train: loss: 0.0393564
[Epoch 44; Iter   229/ 1097] train: loss: 0.0218231
[Epoch 44; Iter   259/ 1097] train: loss: 0.0084046
[Epoch 44; Iter   289/ 1097] train: loss: 0.0271850
[Epoch 44; Iter   319/ 1097] train: loss: 0.0099224
[Epoch 44; Iter   349/ 1097] train: loss: 0.0844234
[Epoch 44; Iter   379/ 1097] train: loss: 0.0551569
[Epoch 44; Iter   409/ 1097] train: loss: 0.0192218
[Epoch 44; Iter   439/ 1097] train: loss: 0.0324871
[Epoch 44; Iter   469/ 1097] train: loss: 0.0177441
[Epoch 44; Iter   499/ 1097] train: loss: 0.1135861
[Epoch 44; Iter   529/ 1097] train: loss: 0.0037358
[Epoch 44; Iter   559/ 1097] train: loss: 0.0133374
[Epoch 44; Iter   589/ 1097] train: loss: 0.0058776
[Epoch 44; Iter   619/ 1097] train: loss: 0.0132507
[Epoch 44; Iter   649/ 1097] train: loss: 0.0086627
[Epoch 44; Iter   679/ 1097] train: loss: 0.0438795
[Epoch 44; Iter   709/ 1097] train: loss: 0.0178461
[Epoch 44; Iter   739/ 1097] train: loss: 0.1672834
[Epoch 44; Iter   769/ 1097] train: loss: 0.0372408
[Epoch 40; Iter   717/ 1097] train: loss: 0.0870263
[Epoch 40; Iter   747/ 1097] train: loss: 0.0377983
[Epoch 40; Iter   777/ 1097] train: loss: 0.0651452
[Epoch 40; Iter   807/ 1097] train: loss: 0.0173199
[Epoch 40; Iter   837/ 1097] train: loss: 0.0674345
[Epoch 40; Iter   867/ 1097] train: loss: 0.0479091
[Epoch 40; Iter   897/ 1097] train: loss: 0.0148866
[Epoch 40; Iter   927/ 1097] train: loss: 0.0255197
[Epoch 40; Iter   957/ 1097] train: loss: 0.0279653
[Epoch 40; Iter   987/ 1097] train: loss: 0.0317992
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0287154
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0087019
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0877420
[Epoch 40] ogbg-molhiv: 0.810206 val loss: 0.203802
[Epoch 40] ogbg-molhiv: 0.821197 test loss: 0.174295
[Epoch 41; Iter    10/ 1097] train: loss: 0.0482262
[Epoch 41; Iter    40/ 1097] train: loss: 0.0287675
[Epoch 41; Iter    70/ 1097] train: loss: 0.0303698
[Epoch 41; Iter   100/ 1097] train: loss: 0.0411686
[Epoch 41; Iter   130/ 1097] train: loss: 0.0275109
[Epoch 41; Iter   160/ 1097] train: loss: 0.0118388
[Epoch 41; Iter   190/ 1097] train: loss: 0.0169059
[Epoch 41; Iter   220/ 1097] train: loss: 0.0074285
[Epoch 41; Iter   250/ 1097] train: loss: 0.3162669
[Epoch 41; Iter   280/ 1097] train: loss: 0.1405165
[Epoch 41; Iter   310/ 1097] train: loss: 0.0432313
[Epoch 41; Iter   340/ 1097] train: loss: 0.0154365
[Epoch 41; Iter   370/ 1097] train: loss: 0.0985190
[Epoch 41; Iter   400/ 1097] train: loss: 0.0471026
[Epoch 41; Iter   430/ 1097] train: loss: 0.0108698
[Epoch 41; Iter   460/ 1097] train: loss: 0.0795602
[Epoch 41; Iter   490/ 1097] train: loss: 0.2527042
[Epoch 41; Iter   520/ 1097] train: loss: 0.0309938
[Epoch 41; Iter   550/ 1097] train: loss: 0.0104944
[Epoch 41; Iter   580/ 1097] train: loss: 0.2046576
[Epoch 41; Iter   610/ 1097] train: loss: 0.0130145
[Epoch 41; Iter   640/ 1097] train: loss: 0.0189963
[Epoch 41; Iter   670/ 1097] train: loss: 0.0133573
[Epoch 41; Iter   700/ 1097] train: loss: 0.1871517
[Epoch 41; Iter   730/ 1097] train: loss: 0.0748759
[Epoch 41; Iter   760/ 1097] train: loss: 0.0468019
[Epoch 41; Iter   790/ 1097] train: loss: 0.0270276
[Epoch 41; Iter   820/ 1097] train: loss: 0.0223615
[Epoch 41; Iter   850/ 1097] train: loss: 0.0737687
[Epoch 41; Iter   880/ 1097] train: loss: 0.0855476
[Epoch 41; Iter   910/ 1097] train: loss: 0.0610176
[Epoch 41; Iter   940/ 1097] train: loss: 0.0616578
[Epoch 41; Iter   970/ 1097] train: loss: 0.0231995
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0587585
[Epoch 41; Iter  1030/ 1097] train: loss: 0.1029181
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0304585
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0633556
[Epoch 41] ogbg-molhiv: 0.818540 val loss: 0.141602
[Epoch 41] ogbg-molhiv: 0.820896 test loss: 0.142657
[Epoch 42; Iter    23/ 1097] train: loss: 0.0459784
[Epoch 42; Iter    53/ 1097] train: loss: 0.0273224
[Epoch 42; Iter    83/ 1097] train: loss: 0.0337010
[Epoch 42; Iter   113/ 1097] train: loss: 0.0297879
[Epoch 42; Iter   143/ 1097] train: loss: 0.0501614
[Epoch 42; Iter   173/ 1097] train: loss: 0.0452372
[Epoch 42; Iter   203/ 1097] train: loss: 0.1937162
[Epoch 42; Iter   233/ 1097] train: loss: 0.0236415
[Epoch 42; Iter   263/ 1097] train: loss: 0.0699284
[Epoch 42; Iter   293/ 1097] train: loss: 0.2289603
[Epoch 42; Iter   323/ 1097] train: loss: 0.0321016
[Epoch 42; Iter   353/ 1097] train: loss: 0.0176354
[Epoch 42; Iter   383/ 1097] train: loss: 0.0135447
[Epoch 42; Iter   413/ 1097] train: loss: 0.0915369
[Epoch 42; Iter   443/ 1097] train: loss: 0.0321640
[Epoch 42; Iter   473/ 1097] train: loss: 0.2109326
[Epoch 42; Iter   503/ 1097] train: loss: 0.0451174
[Epoch 42; Iter   533/ 1097] train: loss: 0.0139823
[Epoch 42; Iter   563/ 1097] train: loss: 0.0176784
[Epoch 42; Iter   593/ 1097] train: loss: 0.0170562
[Epoch 42; Iter   623/ 1097] train: loss: 0.1033862
[Epoch 42; Iter   653/ 1097] train: loss: 0.0130794
[Epoch 42; Iter   683/ 1097] train: loss: 0.0105357
[Epoch 42; Iter   713/ 1097] train: loss: 0.0103077
[Epoch 42; Iter   743/ 1097] train: loss: 0.0700367
[Epoch 42; Iter   773/ 1097] train: loss: 0.0291980
[Epoch 42; Iter   803/ 1097] train: loss: 0.0232310
[Epoch 42; Iter   833/ 1097] train: loss: 0.0254829
[Epoch 42; Iter   863/ 1097] train: loss: 0.0301342
[Epoch 42; Iter   893/ 1097] train: loss: 0.0482414
[Epoch 42; Iter   923/ 1097] train: loss: 0.0132579
[Epoch 42; Iter   953/ 1097] train: loss: 0.0221932
[Epoch 42; Iter   983/ 1097] train: loss: 0.0190737
[Epoch 42; Iter  1013/ 1097] train: loss: 0.0052377
[Epoch 42; Iter  1043/ 1097] train: loss: 0.0321393
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0380639
[Epoch 42] ogbg-molhiv: 0.822192 val loss: 0.146421
[Epoch 42] ogbg-molhiv: 0.832088 test loss: 0.136900
[Epoch 43; Iter     6/ 1097] train: loss: 0.0241393
[Epoch 43; Iter    36/ 1097] train: loss: 0.0523674
[Epoch 43; Iter    66/ 1097] train: loss: 0.0275229
[Epoch 43; Iter    96/ 1097] train: loss: 0.0264839
[Epoch 43; Iter   126/ 1097] train: loss: 0.0548405
[Epoch 43; Iter   156/ 1097] train: loss: 0.0149069
[Epoch 43; Iter   186/ 1097] train: loss: 0.0494043
[Epoch 43; Iter   216/ 1097] train: loss: 0.0148753
[Epoch 43; Iter   246/ 1097] train: loss: 0.0093659
[Epoch 43; Iter   276/ 1097] train: loss: 0.0069803
[Epoch 43; Iter   306/ 1097] train: loss: 0.0221037
[Epoch 43; Iter   336/ 1097] train: loss: 0.3093975
[Epoch 43; Iter   366/ 1097] train: loss: 0.0195936
[Epoch 43; Iter   396/ 1097] train: loss: 0.0457700
[Epoch 43; Iter   426/ 1097] train: loss: 0.1589281
[Epoch 43; Iter   456/ 1097] train: loss: 0.0602790
[Epoch 43; Iter   486/ 1097] train: loss: 0.1575792
[Epoch 43; Iter   516/ 1097] train: loss: 0.0175493
[Epoch 43; Iter   546/ 1097] train: loss: 0.0941691
[Epoch 43; Iter   576/ 1097] train: loss: 0.0925575
[Epoch 43; Iter   606/ 1097] train: loss: 0.0072915
[Epoch 43; Iter   636/ 1097] train: loss: 0.0183812
[Epoch 43; Iter   666/ 1097] train: loss: 0.0570916
[Epoch 43; Iter   696/ 1097] train: loss: 0.0188154
[Epoch 43; Iter   726/ 1097] train: loss: 0.0853212
[Epoch 43; Iter   756/ 1097] train: loss: 0.1808272
[Epoch 43; Iter   786/ 1097] train: loss: 0.0244995
[Epoch 43; Iter   816/ 1097] train: loss: 0.1169681
[Epoch 43; Iter   846/ 1097] train: loss: 0.0173866
[Epoch 43; Iter   876/ 1097] train: loss: 0.0396604
[Epoch 43; Iter   906/ 1097] train: loss: 0.0181316
[Epoch 43; Iter   936/ 1097] train: loss: 0.0988772
[Epoch 43; Iter   966/ 1097] train: loss: 0.1505567
[Epoch 43; Iter   996/ 1097] train: loss: 0.0325762
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0781904
[Epoch 43; Iter  1056/ 1097] train: loss: 0.1405929
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0279874
[Epoch 43] ogbg-molhiv: 0.814478 val loss: 0.139036
[Epoch 43] ogbg-molhiv: 0.820570 test loss: 0.134948
[Epoch 44; Iter    19/ 1097] train: loss: 0.1540930
[Epoch 44; Iter    49/ 1097] train: loss: 0.0763945
[Epoch 44; Iter    79/ 1097] train: loss: 0.0187627
[Epoch 44; Iter   109/ 1097] train: loss: 0.0701143
[Epoch 44; Iter   139/ 1097] train: loss: 0.1340430
[Epoch 44; Iter   169/ 1097] train: loss: 0.0220212
[Epoch 44; Iter   199/ 1097] train: loss: 0.0703144
[Epoch 44; Iter   229/ 1097] train: loss: 0.0126008
[Epoch 44; Iter   259/ 1097] train: loss: 0.0327820
[Epoch 44; Iter   289/ 1097] train: loss: 0.0323509
[Epoch 44; Iter   319/ 1097] train: loss: 0.1738323
[Epoch 44; Iter   349/ 1097] train: loss: 0.0108073
[Epoch 44; Iter   379/ 1097] train: loss: 0.0188352
[Epoch 44; Iter   409/ 1097] train: loss: 0.0328794
[Epoch 44; Iter   439/ 1097] train: loss: 0.1027946
[Epoch 44; Iter   469/ 1097] train: loss: 0.0112950
[Epoch 44; Iter   499/ 1097] train: loss: 0.0417476
[Epoch 44; Iter   529/ 1097] train: loss: 0.0122616
[Epoch 44; Iter   559/ 1097] train: loss: 0.2952251
[Epoch 44; Iter   589/ 1097] train: loss: 0.0658095
[Epoch 44; Iter   619/ 1097] train: loss: 0.2563258
[Epoch 44; Iter   649/ 1097] train: loss: 0.0608235
[Epoch 44; Iter   679/ 1097] train: loss: 0.2153006
[Epoch 44; Iter   709/ 1097] train: loss: 0.0192183
[Epoch 44; Iter   739/ 1097] train: loss: 0.0205462
[Epoch 44; Iter   769/ 1097] train: loss: 0.1432489
[Epoch 42; Iter   187/  823] train: loss: 0.0148558
[Epoch 42; Iter   217/  823] train: loss: 0.0266784
[Epoch 42; Iter   247/  823] train: loss: 0.0110638
[Epoch 42; Iter   277/  823] train: loss: 0.1709017
[Epoch 42; Iter   307/  823] train: loss: 0.1202383
[Epoch 42; Iter   337/  823] train: loss: 0.1695802
[Epoch 42; Iter   367/  823] train: loss: 0.0100425
[Epoch 42; Iter   397/  823] train: loss: 0.0365198
[Epoch 42; Iter   427/  823] train: loss: 0.4345892
[Epoch 42; Iter   457/  823] train: loss: 0.0118910
[Epoch 42; Iter   487/  823] train: loss: 0.0540573
[Epoch 42; Iter   517/  823] train: loss: 0.0261644
[Epoch 42; Iter   547/  823] train: loss: 0.1387712
[Epoch 42; Iter   577/  823] train: loss: 0.0291516
[Epoch 42; Iter   607/  823] train: loss: 0.0348317
[Epoch 42; Iter   637/  823] train: loss: 0.0268888
[Epoch 42; Iter   667/  823] train: loss: 0.0879452
[Epoch 42; Iter   697/  823] train: loss: 0.0212901
[Epoch 42; Iter   727/  823] train: loss: 0.0263502
[Epoch 42; Iter   757/  823] train: loss: 0.0705972
[Epoch 42; Iter   787/  823] train: loss: 0.0168505
[Epoch 42; Iter   817/  823] train: loss: 0.0121644
[Epoch 42] ogbg-molhiv: 0.829267 val loss: 0.393792
[Epoch 42] ogbg-molhiv: 0.801249 test loss: 0.204251
[Epoch 43; Iter    24/  823] train: loss: 0.0527319
[Epoch 43; Iter    54/  823] train: loss: 0.0131302
[Epoch 43; Iter    84/  823] train: loss: 0.0218938
[Epoch 43; Iter   114/  823] train: loss: 0.0159609
[Epoch 43; Iter   144/  823] train: loss: 0.0495716
[Epoch 43; Iter   174/  823] train: loss: 0.0134797
[Epoch 43; Iter   204/  823] train: loss: 0.2411569
[Epoch 43; Iter   234/  823] train: loss: 0.0174462
[Epoch 43; Iter   264/  823] train: loss: 0.0123145
[Epoch 43; Iter   294/  823] train: loss: 0.0718927
[Epoch 43; Iter   324/  823] train: loss: 0.0783141
[Epoch 43; Iter   354/  823] train: loss: 0.0081485
[Epoch 43; Iter   384/  823] train: loss: 0.0207086
[Epoch 43; Iter   414/  823] train: loss: 0.0490658
[Epoch 43; Iter   444/  823] train: loss: 0.0686274
[Epoch 43; Iter   474/  823] train: loss: 0.1610275
[Epoch 43; Iter   504/  823] train: loss: 0.0180026
[Epoch 43; Iter   534/  823] train: loss: 0.0193808
[Epoch 43; Iter   564/  823] train: loss: 0.0094596
[Epoch 43; Iter   594/  823] train: loss: 0.2396841
[Epoch 43; Iter   624/  823] train: loss: 0.0989061
[Epoch 43; Iter   654/  823] train: loss: 0.0256393
[Epoch 43; Iter   684/  823] train: loss: 0.0072304
[Epoch 43; Iter   714/  823] train: loss: 0.0346903
[Epoch 43; Iter   744/  823] train: loss: 0.0837931
[Epoch 43; Iter   774/  823] train: loss: 0.0307010
[Epoch 43; Iter   804/  823] train: loss: 0.0755406
[Epoch 43] ogbg-molhiv: 0.827312 val loss: 0.204974
[Epoch 43] ogbg-molhiv: 0.790258 test loss: 0.209858
[Epoch 44; Iter    11/  823] train: loss: 0.0226018
[Epoch 44; Iter    41/  823] train: loss: 0.0144329
[Epoch 44; Iter    71/  823] train: loss: 0.0253971
[Epoch 44; Iter   101/  823] train: loss: 0.0280227
[Epoch 44; Iter   131/  823] train: loss: 0.0174918
[Epoch 44; Iter   161/  823] train: loss: 0.0864889
[Epoch 44; Iter   191/  823] train: loss: 0.2157564
[Epoch 44; Iter   221/  823] train: loss: 0.0624050
[Epoch 44; Iter   251/  823] train: loss: 0.0090824
[Epoch 44; Iter   281/  823] train: loss: 0.0354975
[Epoch 44; Iter   311/  823] train: loss: 0.1256383
[Epoch 44; Iter   341/  823] train: loss: 0.0068805
[Epoch 44; Iter   371/  823] train: loss: 0.0332068
[Epoch 44; Iter   401/  823] train: loss: 0.0072313
[Epoch 44; Iter   431/  823] train: loss: 0.1867880
[Epoch 44; Iter   461/  823] train: loss: 0.0127499
[Epoch 44; Iter   491/  823] train: loss: 0.2738250
[Epoch 44; Iter   521/  823] train: loss: 0.0104034
[Epoch 44; Iter   551/  823] train: loss: 0.0198247
[Epoch 44; Iter   581/  823] train: loss: 0.0608947
[Epoch 44; Iter   611/  823] train: loss: 0.0438073
[Epoch 44; Iter   641/  823] train: loss: 0.0208148
[Epoch 44; Iter   671/  823] train: loss: 0.0180335
[Epoch 44; Iter   701/  823] train: loss: 0.0195882
[Epoch 44; Iter   731/  823] train: loss: 0.2093673
[Epoch 44; Iter   761/  823] train: loss: 0.0170322
[Epoch 44; Iter   791/  823] train: loss: 0.0340787
[Epoch 44; Iter   821/  823] train: loss: 0.0685622
[Epoch 44] ogbg-molhiv: 0.826435 val loss: 0.155574
[Epoch 44] ogbg-molhiv: 0.789471 test loss: 0.145362
[Epoch 45; Iter    28/  823] train: loss: 0.1068782
[Epoch 45; Iter    58/  823] train: loss: 0.1078977
[Epoch 45; Iter    88/  823] train: loss: 0.0114807
[Epoch 45; Iter   118/  823] train: loss: 0.0215009
[Epoch 45; Iter   148/  823] train: loss: 0.0191193
[Epoch 45; Iter   178/  823] train: loss: 0.1959917
[Epoch 45; Iter   208/  823] train: loss: 0.0124368
[Epoch 45; Iter   238/  823] train: loss: 0.0715944
[Epoch 45; Iter   268/  823] train: loss: 0.0129879
[Epoch 45; Iter   298/  823] train: loss: 0.0135849
[Epoch 45; Iter   328/  823] train: loss: 0.0962070
[Epoch 45; Iter   358/  823] train: loss: 0.0255848
[Epoch 45; Iter   388/  823] train: loss: 0.0235450
[Epoch 45; Iter   418/  823] train: loss: 0.0213796
[Epoch 45; Iter   448/  823] train: loss: 0.0097094
[Epoch 45; Iter   478/  823] train: loss: 0.0642701
[Epoch 45; Iter   508/  823] train: loss: 0.0160561
[Epoch 45; Iter   538/  823] train: loss: 0.1200229
[Epoch 45; Iter   568/  823] train: loss: 0.0321325
[Epoch 45; Iter   598/  823] train: loss: 0.0077514
[Epoch 45; Iter   628/  823] train: loss: 0.0073333
[Epoch 45; Iter   658/  823] train: loss: 0.0623529
[Epoch 45; Iter   688/  823] train: loss: 0.0403571
[Epoch 45; Iter   718/  823] train: loss: 0.1635981
[Epoch 45; Iter   748/  823] train: loss: 0.0107580
[Epoch 45; Iter   778/  823] train: loss: 0.0201717
[Epoch 45; Iter   808/  823] train: loss: 0.1151169
[Epoch 45] ogbg-molhiv: 0.832823 val loss: 0.125588
[Epoch 45] ogbg-molhiv: 0.791037 test loss: 0.195801
[Epoch 46; Iter    15/  823] train: loss: 0.0219576
[Epoch 46; Iter    45/  823] train: loss: 0.0122984
[Epoch 46; Iter    75/  823] train: loss: 0.0943753
[Epoch 46; Iter   105/  823] train: loss: 0.1902082
[Epoch 46; Iter   135/  823] train: loss: 0.1555568
[Epoch 46; Iter   165/  823] train: loss: 0.0239009
[Epoch 46; Iter   195/  823] train: loss: 0.0897214
[Epoch 46; Iter   225/  823] train: loss: 0.1978135
[Epoch 46; Iter   255/  823] train: loss: 0.0093019
[Epoch 46; Iter   285/  823] train: loss: 0.0069043
[Epoch 46; Iter   315/  823] train: loss: 0.0091130
[Epoch 46; Iter   345/  823] train: loss: 0.0154094
[Epoch 46; Iter   375/  823] train: loss: 0.0550754
[Epoch 46; Iter   405/  823] train: loss: 0.0164094
[Epoch 46; Iter   435/  823] train: loss: 0.0116657
[Epoch 46; Iter   465/  823] train: loss: 0.2143872
[Epoch 46; Iter   495/  823] train: loss: 0.0891538
[Epoch 46; Iter   525/  823] train: loss: 0.0446474
[Epoch 46; Iter   555/  823] train: loss: 0.0103384
[Epoch 46; Iter   585/  823] train: loss: 0.1241661
[Epoch 46; Iter   615/  823] train: loss: 0.0133469
[Epoch 46; Iter   645/  823] train: loss: 0.2378949
[Epoch 46; Iter   675/  823] train: loss: 0.0411756
[Epoch 46; Iter   705/  823] train: loss: 0.1667712
[Epoch 46; Iter   735/  823] train: loss: 0.0430547
[Epoch 46; Iter   765/  823] train: loss: 0.0042140
[Epoch 46; Iter   795/  823] train: loss: 0.0374355
[Epoch 46] ogbg-molhiv: 0.831308 val loss: 0.152487
[Epoch 46] ogbg-molhiv: 0.793921 test loss: 0.186144
[Epoch 47; Iter     2/  823] train: loss: 0.0060616
[Epoch 47; Iter    32/  823] train: loss: 0.1158135
[Epoch 47; Iter    62/  823] train: loss: 0.0695175
[Epoch 47; Iter    92/  823] train: loss: 0.0865646
[Epoch 47; Iter   122/  823] train: loss: 0.0163904
[Epoch 47; Iter   152/  823] train: loss: 0.0075795
[Epoch 47; Iter   182/  823] train: loss: 0.0058598
[Epoch 47; Iter   212/  823] train: loss: 0.0042664
[Epoch 47; Iter   242/  823] train: loss: 0.0072821
[Epoch 47; Iter   272/  823] train: loss: 0.0067784
[Epoch 47; Iter   302/  823] train: loss: 0.0205399
[Epoch 47; Iter   332/  823] train: loss: 0.0715772
[Epoch 47; Iter   362/  823] train: loss: 0.0214181
[Epoch 47; Iter   392/  823] train: loss: 0.0223275
[Epoch 47; Iter   422/  823] train: loss: 0.0435305
[Epoch 47; Iter   452/  823] train: loss: 0.0288750
[Epoch 44; Iter   799/ 1097] train: loss: 0.0343321
[Epoch 44; Iter   829/ 1097] train: loss: 0.1551222
[Epoch 44; Iter   859/ 1097] train: loss: 0.0505469
[Epoch 44; Iter   889/ 1097] train: loss: 0.0883529
[Epoch 44; Iter   919/ 1097] train: loss: 0.0241873
[Epoch 44; Iter   949/ 1097] train: loss: 0.0861570
[Epoch 44; Iter   979/ 1097] train: loss: 0.0768462
[Epoch 44; Iter  1009/ 1097] train: loss: 0.1275087
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0266446
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0372310
[Epoch 44] ogbg-molhiv: 0.815506 val loss: 0.141050
[Epoch 44] ogbg-molhiv: 0.821435 test loss: 0.131109
[Epoch 45; Iter     2/ 1097] train: loss: 0.0110251
[Epoch 45; Iter    32/ 1097] train: loss: 0.0202382
[Epoch 45; Iter    62/ 1097] train: loss: 0.0123014
[Epoch 45; Iter    92/ 1097] train: loss: 0.0958533
[Epoch 45; Iter   122/ 1097] train: loss: 0.0755639
[Epoch 45; Iter   152/ 1097] train: loss: 0.0155218
[Epoch 45; Iter   182/ 1097] train: loss: 0.0095236
[Epoch 45; Iter   212/ 1097] train: loss: 0.0083072
[Epoch 45; Iter   242/ 1097] train: loss: 0.0097645
[Epoch 45; Iter   272/ 1097] train: loss: 0.0377470
[Epoch 45; Iter   302/ 1097] train: loss: 0.0148382
[Epoch 45; Iter   332/ 1097] train: loss: 0.0657932
[Epoch 45; Iter   362/ 1097] train: loss: 0.0192089
[Epoch 45; Iter   392/ 1097] train: loss: 0.1733040
[Epoch 45; Iter   422/ 1097] train: loss: 0.0185755
[Epoch 45; Iter   452/ 1097] train: loss: 0.1603521
[Epoch 45; Iter   482/ 1097] train: loss: 0.0534102
[Epoch 45; Iter   512/ 1097] train: loss: 0.0157898
[Epoch 45; Iter   542/ 1097] train: loss: 0.0633651
[Epoch 45; Iter   572/ 1097] train: loss: 0.0130397
[Epoch 45; Iter   602/ 1097] train: loss: 0.0467144
[Epoch 45; Iter   632/ 1097] train: loss: 0.0085718
[Epoch 45; Iter   662/ 1097] train: loss: 0.0811245
[Epoch 45; Iter   692/ 1097] train: loss: 0.0932394
[Epoch 45; Iter   722/ 1097] train: loss: 0.1211380
[Epoch 45; Iter   752/ 1097] train: loss: 0.0096585
[Epoch 45; Iter   782/ 1097] train: loss: 0.0284935
[Epoch 45; Iter   812/ 1097] train: loss: 0.0932503
[Epoch 45; Iter   842/ 1097] train: loss: 0.0931855
[Epoch 45; Iter   872/ 1097] train: loss: 0.0230006
[Epoch 45; Iter   902/ 1097] train: loss: 0.0354442
[Epoch 45; Iter   932/ 1097] train: loss: 0.2201677
[Epoch 45; Iter   962/ 1097] train: loss: 0.0064820
[Epoch 45; Iter   992/ 1097] train: loss: 0.0517058
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0093477
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0881347
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0926118
[Epoch 45] ogbg-molhiv: 0.808229 val loss: 0.229304
[Epoch 45] ogbg-molhiv: 0.816755 test loss: 0.205647
[Epoch 46; Iter    15/ 1097] train: loss: 0.0727304
[Epoch 46; Iter    45/ 1097] train: loss: 0.0128633
[Epoch 46; Iter    75/ 1097] train: loss: 0.0464963
[Epoch 46; Iter   105/ 1097] train: loss: 0.0212575
[Epoch 46; Iter   135/ 1097] train: loss: 0.0031746
[Epoch 46; Iter   165/ 1097] train: loss: 0.0117954
[Epoch 46; Iter   195/ 1097] train: loss: 0.0378182
[Epoch 46; Iter   225/ 1097] train: loss: 0.0079248
[Epoch 46; Iter   255/ 1097] train: loss: 0.0132454
[Epoch 46; Iter   285/ 1097] train: loss: 0.0685628
[Epoch 46; Iter   315/ 1097] train: loss: 0.0044473
[Epoch 46; Iter   345/ 1097] train: loss: 0.0158921
[Epoch 46; Iter   375/ 1097] train: loss: 0.0207164
[Epoch 46; Iter   405/ 1097] train: loss: 0.0991090
[Epoch 46; Iter   435/ 1097] train: loss: 0.0907773
[Epoch 46; Iter   465/ 1097] train: loss: 0.0136810
[Epoch 46; Iter   495/ 1097] train: loss: 0.0432890
[Epoch 46; Iter   525/ 1097] train: loss: 0.0080434
[Epoch 46; Iter   555/ 1097] train: loss: 0.0216085
[Epoch 46; Iter   585/ 1097] train: loss: 0.0069273
[Epoch 46; Iter   615/ 1097] train: loss: 0.0070925
[Epoch 46; Iter   645/ 1097] train: loss: 0.2040168
[Epoch 46; Iter   675/ 1097] train: loss: 0.0562218
[Epoch 46; Iter   705/ 1097] train: loss: 0.0461063
[Epoch 46; Iter   735/ 1097] train: loss: 0.0106792
[Epoch 46; Iter   765/ 1097] train: loss: 0.0461146
[Epoch 46; Iter   795/ 1097] train: loss: 0.0388029
[Epoch 46; Iter   825/ 1097] train: loss: 0.1107341
[Epoch 46; Iter   855/ 1097] train: loss: 0.0413995
[Epoch 46; Iter   885/ 1097] train: loss: 0.0407372
[Epoch 46; Iter   915/ 1097] train: loss: 0.0177974
[Epoch 46; Iter   945/ 1097] train: loss: 0.0145098
[Epoch 46; Iter   975/ 1097] train: loss: 0.0647785
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0438280
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0356022
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0137771
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0283058
[Epoch 46] ogbg-molhiv: 0.810846 val loss: 0.164455
[Epoch 46] ogbg-molhiv: 0.811589 test loss: 0.250419
[Epoch 47; Iter    28/ 1097] train: loss: 0.0174509
[Epoch 47; Iter    58/ 1097] train: loss: 0.0159514
[Epoch 47; Iter    88/ 1097] train: loss: 0.0166451
[Epoch 47; Iter   118/ 1097] train: loss: 0.0368163
[Epoch 47; Iter   148/ 1097] train: loss: 0.0460249
[Epoch 47; Iter   178/ 1097] train: loss: 0.0103354
[Epoch 47; Iter   208/ 1097] train: loss: 0.0703938
[Epoch 47; Iter   238/ 1097] train: loss: 0.0051996
[Epoch 47; Iter   268/ 1097] train: loss: 0.0473661
[Epoch 47; Iter   298/ 1097] train: loss: 0.0200836
[Epoch 47; Iter   328/ 1097] train: loss: 0.0302338
[Epoch 47; Iter   358/ 1097] train: loss: 0.2487228
[Epoch 47; Iter   388/ 1097] train: loss: 0.0260962
[Epoch 47; Iter   418/ 1097] train: loss: 0.0272368
[Epoch 47; Iter   448/ 1097] train: loss: 0.1055229
[Epoch 47; Iter   478/ 1097] train: loss: 0.0326318
[Epoch 47; Iter   508/ 1097] train: loss: 0.0114553
[Epoch 47; Iter   538/ 1097] train: loss: 0.0266792
[Epoch 47; Iter   568/ 1097] train: loss: 0.0103548
[Epoch 47; Iter   598/ 1097] train: loss: 0.1084727
[Epoch 47; Iter   628/ 1097] train: loss: 0.0894973
[Epoch 47; Iter   658/ 1097] train: loss: 0.0864715
[Epoch 47; Iter   688/ 1097] train: loss: 0.0189149
[Epoch 47; Iter   718/ 1097] train: loss: 0.0121803
[Epoch 47; Iter   748/ 1097] train: loss: 0.0163828
[Epoch 47; Iter   778/ 1097] train: loss: 0.0090208
[Epoch 47; Iter   808/ 1097] train: loss: 0.0266607
[Epoch 47; Iter   838/ 1097] train: loss: 0.0192643
[Epoch 47; Iter   868/ 1097] train: loss: 0.0054729
[Epoch 47; Iter   898/ 1097] train: loss: 0.0134318
[Epoch 47; Iter   928/ 1097] train: loss: 0.0286633
[Epoch 47; Iter   958/ 1097] train: loss: 0.0081427
[Epoch 47; Iter   988/ 1097] train: loss: 0.0090950
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0700895
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0118777
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0058402
[Epoch 47] ogbg-molhiv: 0.808803 val loss: 0.226598
[Epoch 47] ogbg-molhiv: 0.821837 test loss: 0.375675
[Epoch 48; Iter    11/ 1097] train: loss: 0.0081223
[Epoch 48; Iter    41/ 1097] train: loss: 0.0079862
[Epoch 48; Iter    71/ 1097] train: loss: 0.1145065
[Epoch 48; Iter   101/ 1097] train: loss: 0.0103772
[Epoch 48; Iter   131/ 1097] train: loss: 0.0111640
[Epoch 48; Iter   161/ 1097] train: loss: 0.1376685
[Epoch 48; Iter   191/ 1097] train: loss: 0.1001503
[Epoch 48; Iter   221/ 1097] train: loss: 0.0412416
[Epoch 48; Iter   251/ 1097] train: loss: 0.0084066
[Epoch 48; Iter   281/ 1097] train: loss: 0.0600374
[Epoch 48; Iter   311/ 1097] train: loss: 0.0558015
[Epoch 48; Iter   341/ 1097] train: loss: 0.0201804
[Epoch 48; Iter   371/ 1097] train: loss: 0.0079646
[Epoch 48; Iter   401/ 1097] train: loss: 0.0089950
[Epoch 48; Iter   431/ 1097] train: loss: 0.0553928
[Epoch 48; Iter   461/ 1097] train: loss: 0.0373326
[Epoch 48; Iter   491/ 1097] train: loss: 0.0507167
[Epoch 48; Iter   521/ 1097] train: loss: 0.1536505
[Epoch 48; Iter   551/ 1097] train: loss: 0.1129878
[Epoch 48; Iter   581/ 1097] train: loss: 0.0104903
[Epoch 48; Iter   611/ 1097] train: loss: 0.1043128
[Epoch 48; Iter   641/ 1097] train: loss: 0.2110981
[Epoch 48; Iter   671/ 1097] train: loss: 0.0105248
[Epoch 48; Iter   701/ 1097] train: loss: 0.0306845
[Epoch 48; Iter   731/ 1097] train: loss: 0.0359335
[Epoch 48; Iter   761/ 1097] train: loss: 0.0178817
[Epoch 48; Iter   791/ 1097] train: loss: 0.0058500
[Epoch 48; Iter   821/ 1097] train: loss: 0.0444213
[Epoch 48; Iter   851/ 1097] train: loss: 0.0974678
[Epoch 47; Iter   482/  823] train: loss: 0.0261370
[Epoch 47; Iter   512/  823] train: loss: 0.0310636
[Epoch 47; Iter   542/  823] train: loss: 0.0350760
[Epoch 47; Iter   572/  823] train: loss: 0.1030032
[Epoch 47; Iter   602/  823] train: loss: 0.1282571
[Epoch 47; Iter   632/  823] train: loss: 0.0161520
[Epoch 47; Iter   662/  823] train: loss: 0.0566343
[Epoch 47; Iter   692/  823] train: loss: 0.0307945
[Epoch 47; Iter   722/  823] train: loss: 0.0608276
[Epoch 47; Iter   752/  823] train: loss: 0.0200326
[Epoch 47; Iter   782/  823] train: loss: 0.2282885
[Epoch 47; Iter   812/  823] train: loss: 0.0320166
[Epoch 47] ogbg-molhiv: 0.843206 val loss: 0.120538
[Epoch 47] ogbg-molhiv: 0.805308 test loss: 0.135179
[Epoch 48; Iter    19/  823] train: loss: 0.0228322
[Epoch 48; Iter    49/  823] train: loss: 0.0940574
[Epoch 48; Iter    79/  823] train: loss: 0.1549590
[Epoch 48; Iter   109/  823] train: loss: 0.0569523
[Epoch 48; Iter   139/  823] train: loss: 0.1881446
[Epoch 48; Iter   169/  823] train: loss: 0.1122203
[Epoch 48; Iter   199/  823] train: loss: 0.0233550
[Epoch 48; Iter   229/  823] train: loss: 0.1092818
[Epoch 48; Iter   259/  823] train: loss: 0.0814411
[Epoch 48; Iter   289/  823] train: loss: 0.1244479
[Epoch 48; Iter   319/  823] train: loss: 0.0165517
[Epoch 48; Iter   349/  823] train: loss: 0.0675037
[Epoch 48; Iter   379/  823] train: loss: 0.0255688
[Epoch 48; Iter   409/  823] train: loss: 0.0261960
[Epoch 48; Iter   439/  823] train: loss: 0.0268707
[Epoch 48; Iter   469/  823] train: loss: 0.0068280
[Epoch 48; Iter   499/  823] train: loss: 0.0278781
[Epoch 48; Iter   529/  823] train: loss: 0.1138181
[Epoch 48; Iter   559/  823] train: loss: 0.0722088
[Epoch 48; Iter   589/  823] train: loss: 0.1858008
[Epoch 48; Iter   619/  823] train: loss: 0.1354211
[Epoch 48; Iter   649/  823] train: loss: 0.0360341
[Epoch 48; Iter   679/  823] train: loss: 0.0185189
[Epoch 48; Iter   709/  823] train: loss: 0.0259344
[Epoch 48; Iter   739/  823] train: loss: 0.1193149
[Epoch 48; Iter   769/  823] train: loss: 0.0202663
[Epoch 48; Iter   799/  823] train: loss: 0.2620806
[Epoch 48] ogbg-molhiv: 0.838564 val loss: 0.134647
[Epoch 48] ogbg-molhiv: 0.808752 test loss: 0.137651
[Epoch 49; Iter     6/  823] train: loss: 0.0207115
[Epoch 49; Iter    36/  823] train: loss: 0.1558483
[Epoch 49; Iter    66/  823] train: loss: 0.0325115
[Epoch 49; Iter    96/  823] train: loss: 0.0203314
[Epoch 49; Iter   126/  823] train: loss: 0.0940243
[Epoch 49; Iter   156/  823] train: loss: 0.1529069
[Epoch 49; Iter   186/  823] train: loss: 0.0481637
[Epoch 49; Iter   216/  823] train: loss: 0.0779570
[Epoch 49; Iter   246/  823] train: loss: 0.1047407
[Epoch 49; Iter   276/  823] train: loss: 0.0694935
[Epoch 49; Iter   306/  823] train: loss: 0.0252375
[Epoch 49; Iter   336/  823] train: loss: 0.1480606
[Epoch 49; Iter   366/  823] train: loss: 0.0236115
[Epoch 49; Iter   396/  823] train: loss: 0.0974083
[Epoch 49; Iter   426/  823] train: loss: 0.0343348
[Epoch 49; Iter   456/  823] train: loss: 0.0309248
[Epoch 49; Iter   486/  823] train: loss: 0.0186433
[Epoch 49; Iter   516/  823] train: loss: 0.0178538
[Epoch 49; Iter   546/  823] train: loss: 0.0533979
[Epoch 49; Iter   576/  823] train: loss: 0.0320747
[Epoch 49; Iter   606/  823] train: loss: 0.0533687
[Epoch 49; Iter   636/  823] train: loss: 0.2411439
[Epoch 49; Iter   666/  823] train: loss: 0.1791370
[Epoch 49; Iter   696/  823] train: loss: 0.0175616
[Epoch 49; Iter   726/  823] train: loss: 0.0252392
[Epoch 49; Iter   756/  823] train: loss: 0.1069053
[Epoch 49; Iter   786/  823] train: loss: 0.0720998
[Epoch 49; Iter   816/  823] train: loss: 0.0188687
[Epoch 49] ogbg-molhiv: 0.834220 val loss: 0.129117
[Epoch 49] ogbg-molhiv: 0.799765 test loss: 0.142693
[Epoch 50; Iter    23/  823] train: loss: 0.0331200
[Epoch 50; Iter    53/  823] train: loss: 0.0992246
[Epoch 50; Iter    83/  823] train: loss: 0.0168241
[Epoch 50; Iter   113/  823] train: loss: 0.0433882
[Epoch 50; Iter   143/  823] train: loss: 0.0916959
[Epoch 50; Iter   173/  823] train: loss: 0.0104364
[Epoch 50; Iter   203/  823] train: loss: 0.2413988
[Epoch 50; Iter   233/  823] train: loss: 0.0320584
[Epoch 50; Iter   263/  823] train: loss: 0.0789043
[Epoch 50; Iter   293/  823] train: loss: 0.0097445
[Epoch 50; Iter   323/  823] train: loss: 0.0701805
[Epoch 50; Iter   353/  823] train: loss: 0.1059765
[Epoch 50; Iter   383/  823] train: loss: 0.0423388
[Epoch 50; Iter   413/  823] train: loss: 0.0154007
[Epoch 50; Iter   443/  823] train: loss: 0.1542173
[Epoch 50; Iter   473/  823] train: loss: 0.2397378
[Epoch 50; Iter   503/  823] train: loss: 0.0117041
[Epoch 50; Iter   533/  823] train: loss: 0.0380142
[Epoch 50; Iter   563/  823] train: loss: 0.1695958
[Epoch 50; Iter   593/  823] train: loss: 0.1239376
[Epoch 50; Iter   623/  823] train: loss: 0.0340267
[Epoch 50; Iter   653/  823] train: loss: 0.0144300
[Epoch 50; Iter   683/  823] train: loss: 0.0128131
[Epoch 50; Iter   713/  823] train: loss: 0.0235143
[Epoch 50; Iter   743/  823] train: loss: 0.0282475
[Epoch 50; Iter   773/  823] train: loss: 0.0510873
[Epoch 50; Iter   803/  823] train: loss: 0.0403805
[Epoch 50] ogbg-molhiv: 0.832892 val loss: 0.137005
[Epoch 50] ogbg-molhiv: 0.808347 test loss: 0.145150
[Epoch 51; Iter    10/  823] train: loss: 0.1431926
[Epoch 51; Iter    40/  823] train: loss: 0.0498740
[Epoch 51; Iter    70/  823] train: loss: 0.0936270
[Epoch 51; Iter   100/  823] train: loss: 0.2061863
[Epoch 51; Iter   130/  823] train: loss: 0.0226031
[Epoch 51; Iter   160/  823] train: loss: 0.1782703
[Epoch 51; Iter   190/  823] train: loss: 0.0351646
[Epoch 51; Iter   220/  823] train: loss: 0.0219742
[Epoch 51; Iter   250/  823] train: loss: 0.0337958
[Epoch 51; Iter   280/  823] train: loss: 0.0745670
[Epoch 51; Iter   310/  823] train: loss: 0.1259054
[Epoch 51; Iter   340/  823] train: loss: 0.0950574
[Epoch 51; Iter   370/  823] train: loss: 0.1295961
[Epoch 51; Iter   400/  823] train: loss: 0.0701487
[Epoch 51; Iter   430/  823] train: loss: 0.0237105
[Epoch 51; Iter   460/  823] train: loss: 0.0422922
[Epoch 51; Iter   490/  823] train: loss: 0.0523121
[Epoch 51; Iter   520/  823] train: loss: 0.1033685
[Epoch 51; Iter   550/  823] train: loss: 0.1894505
[Epoch 51; Iter   580/  823] train: loss: 0.2286554
[Epoch 51; Iter   610/  823] train: loss: 0.0377245
[Epoch 51; Iter   640/  823] train: loss: 0.0512806
[Epoch 51; Iter   670/  823] train: loss: 0.0219684
[Epoch 51; Iter   700/  823] train: loss: 0.1477029
[Epoch 51; Iter   730/  823] train: loss: 0.0189651
[Epoch 51; Iter   760/  823] train: loss: 0.0127017
[Epoch 51; Iter   790/  823] train: loss: 0.0139875
[Epoch 51; Iter   820/  823] train: loss: 0.0242171
[Epoch 51] ogbg-molhiv: 0.830466 val loss: 0.258867
[Epoch 51] ogbg-molhiv: 0.803282 test loss: 0.155293
[Epoch 52; Iter    27/  823] train: loss: 0.0429836
[Epoch 52; Iter    57/  823] train: loss: 0.0574120
[Epoch 52; Iter    87/  823] train: loss: 0.0393222
[Epoch 52; Iter   117/  823] train: loss: 0.0183660
[Epoch 52; Iter   147/  823] train: loss: 0.0142297
[Epoch 52; Iter   177/  823] train: loss: 0.1094462
[Epoch 52; Iter   207/  823] train: loss: 0.0911587
[Epoch 52; Iter   237/  823] train: loss: 0.1034892
[Epoch 52; Iter   267/  823] train: loss: 0.0313414
[Epoch 52; Iter   297/  823] train: loss: 0.0620892
[Epoch 52; Iter   327/  823] train: loss: 0.0271574
[Epoch 52; Iter   357/  823] train: loss: 0.1184258
[Epoch 52; Iter   387/  823] train: loss: 0.0121489
[Epoch 52; Iter   417/  823] train: loss: 0.0526854
[Epoch 52; Iter   447/  823] train: loss: 0.0524299
[Epoch 52; Iter   477/  823] train: loss: 0.0990466
[Epoch 52; Iter   507/  823] train: loss: 0.0294892
[Epoch 52; Iter   537/  823] train: loss: 0.6192647
[Epoch 52; Iter   567/  823] train: loss: 0.1955451
[Epoch 52; Iter   597/  823] train: loss: 0.2552888
[Epoch 52; Iter   627/  823] train: loss: 0.0369142
[Epoch 52; Iter   657/  823] train: loss: 0.0155072
[Epoch 52; Iter   687/  823] train: loss: 0.0129952
[Epoch 52; Iter   717/  823] train: loss: 0.0192774
[Epoch 52; Iter   747/  823] train: loss: 0.0986583
[Epoch 44; Iter   799/ 1097] train: loss: 0.0177786
[Epoch 44; Iter   829/ 1097] train: loss: 0.0639412
[Epoch 44; Iter   859/ 1097] train: loss: 0.0677025
[Epoch 44; Iter   889/ 1097] train: loss: 0.0377136
[Epoch 44; Iter   919/ 1097] train: loss: 0.1194530
[Epoch 44; Iter   949/ 1097] train: loss: 0.1542131
[Epoch 44; Iter   979/ 1097] train: loss: 0.0395973
[Epoch 44; Iter  1009/ 1097] train: loss: 0.0519556
[Epoch 44; Iter  1039/ 1097] train: loss: 0.1591190
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0179832
[Epoch 44] ogbg-molhiv: 0.836148 val loss: 0.407801
[Epoch 44] ogbg-molhiv: 0.812771 test loss: 0.131322
[Epoch 45; Iter     2/ 1097] train: loss: 0.0258426
[Epoch 45; Iter    32/ 1097] train: loss: 0.0208376
[Epoch 45; Iter    62/ 1097] train: loss: 0.1643861
[Epoch 45; Iter    92/ 1097] train: loss: 0.0859022
[Epoch 45; Iter   122/ 1097] train: loss: 0.0211171
[Epoch 45; Iter   152/ 1097] train: loss: 0.0228226
[Epoch 45; Iter   182/ 1097] train: loss: 0.0411360
[Epoch 45; Iter   212/ 1097] train: loss: 0.0383162
[Epoch 45; Iter   242/ 1097] train: loss: 0.0123803
[Epoch 45; Iter   272/ 1097] train: loss: 0.0349901
[Epoch 45; Iter   302/ 1097] train: loss: 0.0230258
[Epoch 45; Iter   332/ 1097] train: loss: 0.0545451
[Epoch 45; Iter   362/ 1097] train: loss: 0.2037224
[Epoch 45; Iter   392/ 1097] train: loss: 0.1057633
[Epoch 45; Iter   422/ 1097] train: loss: 0.1738311
[Epoch 45; Iter   452/ 1097] train: loss: 0.0396506
[Epoch 45; Iter   482/ 1097] train: loss: 0.0204495
[Epoch 45; Iter   512/ 1097] train: loss: 0.0358247
[Epoch 45; Iter   542/ 1097] train: loss: 0.1298911
[Epoch 45; Iter   572/ 1097] train: loss: 0.0333316
[Epoch 45; Iter   602/ 1097] train: loss: 0.0208428
[Epoch 45; Iter   632/ 1097] train: loss: 0.2313804
[Epoch 45; Iter   662/ 1097] train: loss: 0.2422207
[Epoch 45; Iter   692/ 1097] train: loss: 0.0093260
[Epoch 45; Iter   722/ 1097] train: loss: 0.0209078
[Epoch 45; Iter   752/ 1097] train: loss: 0.0376163
[Epoch 45; Iter   782/ 1097] train: loss: 0.0640583
[Epoch 45; Iter   812/ 1097] train: loss: 0.0256483
[Epoch 45; Iter   842/ 1097] train: loss: 0.0132976
[Epoch 45; Iter   872/ 1097] train: loss: 0.0244755
[Epoch 45; Iter   902/ 1097] train: loss: 0.1912797
[Epoch 45; Iter   932/ 1097] train: loss: 0.0557341
[Epoch 45; Iter   962/ 1097] train: loss: 0.0535133
[Epoch 45; Iter   992/ 1097] train: loss: 0.0159732
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0241819
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0246645
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0219816
[Epoch 45] ogbg-molhiv: 0.825600 val loss: 0.202557
[Epoch 45] ogbg-molhiv: 0.814355 test loss: 0.111927
[Epoch 46; Iter    15/ 1097] train: loss: 0.0171929
[Epoch 46; Iter    45/ 1097] train: loss: 0.0429852
[Epoch 46; Iter    75/ 1097] train: loss: 0.1742424
[Epoch 46; Iter   105/ 1097] train: loss: 0.0470022
[Epoch 46; Iter   135/ 1097] train: loss: 0.0386704
[Epoch 46; Iter   165/ 1097] train: loss: 0.1567451
[Epoch 46; Iter   195/ 1097] train: loss: 0.2383986
[Epoch 46; Iter   225/ 1097] train: loss: 0.0252939
[Epoch 46; Iter   255/ 1097] train: loss: 0.0329009
[Epoch 46; Iter   285/ 1097] train: loss: 0.2591614
[Epoch 46; Iter   315/ 1097] train: loss: 0.0184426
[Epoch 46; Iter   345/ 1097] train: loss: 0.0397208
[Epoch 46; Iter   375/ 1097] train: loss: 0.0320859
[Epoch 46; Iter   405/ 1097] train: loss: 0.1508473
[Epoch 46; Iter   435/ 1097] train: loss: 0.1449825
[Epoch 46; Iter   465/ 1097] train: loss: 0.1311262
[Epoch 46; Iter   495/ 1097] train: loss: 0.0361848
[Epoch 46; Iter   525/ 1097] train: loss: 0.0759683
[Epoch 46; Iter   555/ 1097] train: loss: 0.0750419
[Epoch 46; Iter   585/ 1097] train: loss: 0.0215679
[Epoch 46; Iter   615/ 1097] train: loss: 0.1353464
[Epoch 46; Iter   645/ 1097] train: loss: 0.1348265
[Epoch 46; Iter   675/ 1097] train: loss: 0.1207147
[Epoch 46; Iter   705/ 1097] train: loss: 0.1834436
[Epoch 46; Iter   735/ 1097] train: loss: 0.0189270
[Epoch 46; Iter   765/ 1097] train: loss: 0.1513978
[Epoch 46; Iter   795/ 1097] train: loss: 0.0183946
[Epoch 46; Iter   825/ 1097] train: loss: 0.0629219
[Epoch 46; Iter   855/ 1097] train: loss: 0.0284386
[Epoch 46; Iter   885/ 1097] train: loss: 0.0144042
[Epoch 46; Iter   915/ 1097] train: loss: 0.0157191
[Epoch 46; Iter   945/ 1097] train: loss: 0.2935392
[Epoch 46; Iter   975/ 1097] train: loss: 0.1516458
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0173345
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0191983
[Epoch 46; Iter  1065/ 1097] train: loss: 0.2013405
[Epoch 46; Iter  1095/ 1097] train: loss: 0.1194418
[Epoch 46] ogbg-molhiv: 0.828007 val loss: 0.331393
[Epoch 46] ogbg-molhiv: 0.816084 test loss: 0.116023
[Epoch 47; Iter    28/ 1097] train: loss: 0.0218557
[Epoch 47; Iter    58/ 1097] train: loss: 0.0849162
[Epoch 47; Iter    88/ 1097] train: loss: 0.1860342
[Epoch 47; Iter   118/ 1097] train: loss: 0.0163250
[Epoch 47; Iter   148/ 1097] train: loss: 0.0681534
[Epoch 47; Iter   178/ 1097] train: loss: 0.1617165
[Epoch 47; Iter   208/ 1097] train: loss: 0.0132302
[Epoch 47; Iter   238/ 1097] train: loss: 0.0866054
[Epoch 47; Iter   268/ 1097] train: loss: 0.1277090
[Epoch 47; Iter   298/ 1097] train: loss: 0.0139068
[Epoch 47; Iter   328/ 1097] train: loss: 0.1091584
[Epoch 47; Iter   358/ 1097] train: loss: 0.2680538
[Epoch 47; Iter   388/ 1097] train: loss: 0.1093205
[Epoch 47; Iter   418/ 1097] train: loss: 0.0121767
[Epoch 47; Iter   448/ 1097] train: loss: 0.2949893
[Epoch 47; Iter   478/ 1097] train: loss: 0.0183407
[Epoch 47; Iter   508/ 1097] train: loss: 0.0099286
[Epoch 47; Iter   538/ 1097] train: loss: 0.1885133
[Epoch 47; Iter   568/ 1097] train: loss: 0.0682629
[Epoch 47; Iter   598/ 1097] train: loss: 0.0357199
[Epoch 47; Iter   628/ 1097] train: loss: 0.0436010
[Epoch 47; Iter   658/ 1097] train: loss: 0.2120914
[Epoch 47; Iter   688/ 1097] train: loss: 0.0271116
[Epoch 47; Iter   718/ 1097] train: loss: 0.0619801
[Epoch 47; Iter   748/ 1097] train: loss: 0.0269740
[Epoch 47; Iter   778/ 1097] train: loss: 0.0601287
[Epoch 47; Iter   808/ 1097] train: loss: 0.0244135
[Epoch 47; Iter   838/ 1097] train: loss: 0.1031661
[Epoch 47; Iter   868/ 1097] train: loss: 0.0485845
[Epoch 47; Iter   898/ 1097] train: loss: 0.1172791
[Epoch 47; Iter   928/ 1097] train: loss: 0.0219705
[Epoch 47; Iter   958/ 1097] train: loss: 0.1080905
[Epoch 47; Iter   988/ 1097] train: loss: 0.0477823
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0334191
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0381611
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0678328
[Epoch 47] ogbg-molhiv: 0.825766 val loss: 0.154538
[Epoch 47] ogbg-molhiv: 0.819205 test loss: 0.114053
[Epoch 48; Iter    11/ 1097] train: loss: 0.0272546
[Epoch 48; Iter    41/ 1097] train: loss: 0.0727148
[Epoch 48; Iter    71/ 1097] train: loss: 0.0752883
[Epoch 48; Iter   101/ 1097] train: loss: 0.0114809
[Epoch 48; Iter   131/ 1097] train: loss: 0.0198534
[Epoch 48; Iter   161/ 1097] train: loss: 0.0276613
[Epoch 48; Iter   191/ 1097] train: loss: 0.0356514
[Epoch 48; Iter   221/ 1097] train: loss: 0.0164757
[Epoch 48; Iter   251/ 1097] train: loss: 0.0165284
[Epoch 48; Iter   281/ 1097] train: loss: 0.0340646
[Epoch 48; Iter   311/ 1097] train: loss: 0.1463848
[Epoch 48; Iter   341/ 1097] train: loss: 0.0312061
[Epoch 48; Iter   371/ 1097] train: loss: 0.0342184
[Epoch 48; Iter   401/ 1097] train: loss: 0.0917435
[Epoch 48; Iter   431/ 1097] train: loss: 0.0201364
[Epoch 48; Iter   461/ 1097] train: loss: 0.0389740
[Epoch 48; Iter   491/ 1097] train: loss: 0.2623952
[Epoch 48; Iter   521/ 1097] train: loss: 0.0464353
[Epoch 48; Iter   551/ 1097] train: loss: 0.0225944
[Epoch 48; Iter   581/ 1097] train: loss: 0.0276070
[Epoch 48; Iter   611/ 1097] train: loss: 0.0132621
[Epoch 48; Iter   641/ 1097] train: loss: 0.1360923
[Epoch 48; Iter   671/ 1097] train: loss: 0.2389989
[Epoch 48; Iter   701/ 1097] train: loss: 0.0648418
[Epoch 48; Iter   731/ 1097] train: loss: 0.1672634
[Epoch 48; Iter   761/ 1097] train: loss: 0.0278991
[Epoch 48; Iter   791/ 1097] train: loss: 0.0431535
[Epoch 48; Iter   821/ 1097] train: loss: 0.3407535
[Epoch 48; Iter   851/ 1097] train: loss: 0.0088830
[Epoch 45; Iter   960/  960] train: loss: 0.0021617
[Epoch 45] ogbg-molhiv: 0.830620 val loss: 0.156384
[Epoch 45] ogbg-molhiv: 0.822956 test loss: 0.154081
[Epoch 46; Iter    30/  960] train: loss: 0.0312202
[Epoch 46; Iter    60/  960] train: loss: 0.0324009
[Epoch 46; Iter    90/  960] train: loss: 0.0235837
[Epoch 46; Iter   120/  960] train: loss: 0.1767093
[Epoch 46; Iter   150/  960] train: loss: 0.0388269
[Epoch 46; Iter   180/  960] train: loss: 0.0299164
[Epoch 46; Iter   210/  960] train: loss: 0.0115848
[Epoch 46; Iter   240/  960] train: loss: 0.0141447
[Epoch 46; Iter   270/  960] train: loss: 0.0268388
[Epoch 46; Iter   300/  960] train: loss: 0.0283875
[Epoch 46; Iter   330/  960] train: loss: 0.0984717
[Epoch 46; Iter   360/  960] train: loss: 0.0037941
[Epoch 46; Iter   390/  960] train: loss: 0.0101981
[Epoch 46; Iter   420/  960] train: loss: 0.0260592
[Epoch 46; Iter   450/  960] train: loss: 0.0195593
[Epoch 46; Iter   480/  960] train: loss: 0.0119492
[Epoch 46; Iter   510/  960] train: loss: 0.0240571
[Epoch 46; Iter   540/  960] train: loss: 0.0062372
[Epoch 46; Iter   570/  960] train: loss: 0.0079768
[Epoch 46; Iter   600/  960] train: loss: 0.1153555
[Epoch 46; Iter   630/  960] train: loss: 0.0057169
[Epoch 46; Iter   660/  960] train: loss: 0.0112720
[Epoch 46; Iter   690/  960] train: loss: 0.1685970
[Epoch 46; Iter   720/  960] train: loss: 0.1202890
[Epoch 46; Iter   750/  960] train: loss: 0.0199418
[Epoch 46; Iter   780/  960] train: loss: 0.0225673
[Epoch 46; Iter   810/  960] train: loss: 0.0108382
[Epoch 46; Iter   840/  960] train: loss: 0.1123706
[Epoch 46; Iter   870/  960] train: loss: 0.0122095
[Epoch 46; Iter   900/  960] train: loss: 0.1706937
[Epoch 46; Iter   930/  960] train: loss: 0.0645966
[Epoch 46; Iter   960/  960] train: loss: 0.0837707
[Epoch 46] ogbg-molhiv: 0.824197 val loss: 0.161380
[Epoch 46] ogbg-molhiv: 0.810266 test loss: 0.159046
[Epoch 47; Iter    30/  960] train: loss: 0.2416712
[Epoch 47; Iter    60/  960] train: loss: 0.0134834
[Epoch 47; Iter    90/  960] train: loss: 0.0170936
[Epoch 47; Iter   120/  960] train: loss: 0.1633042
[Epoch 47; Iter   150/  960] train: loss: 0.0048632
[Epoch 47; Iter   180/  960] train: loss: 0.0353541
[Epoch 47; Iter   210/  960] train: loss: 0.0147380
[Epoch 47; Iter   240/  960] train: loss: 0.0327564
[Epoch 47; Iter   270/  960] train: loss: 0.0132110
[Epoch 47; Iter   300/  960] train: loss: 0.1599895
[Epoch 47; Iter   330/  960] train: loss: 0.0198169
[Epoch 47; Iter   360/  960] train: loss: 0.0073877
[Epoch 47; Iter   390/  960] train: loss: 0.0534809
[Epoch 47; Iter   420/  960] train: loss: 0.0500421
[Epoch 47; Iter   450/  960] train: loss: 0.1062139
[Epoch 47; Iter   480/  960] train: loss: 0.0177134
[Epoch 47; Iter   510/  960] train: loss: 0.1110806
[Epoch 47; Iter   540/  960] train: loss: 0.0545433
[Epoch 47; Iter   570/  960] train: loss: 0.0277077
[Epoch 47; Iter   600/  960] train: loss: 0.0078628
[Epoch 47; Iter   630/  960] train: loss: 0.0418341
[Epoch 47; Iter   660/  960] train: loss: 0.0330862
[Epoch 47; Iter   690/  960] train: loss: 0.0351131
[Epoch 47; Iter   720/  960] train: loss: 0.0288588
[Epoch 47; Iter   750/  960] train: loss: 0.2238825
[Epoch 47; Iter   780/  960] train: loss: 0.0850665
[Epoch 47; Iter   810/  960] train: loss: 0.0305330
[Epoch 47; Iter   840/  960] train: loss: 0.0173729
[Epoch 47; Iter   870/  960] train: loss: 0.0277305
[Epoch 47; Iter   900/  960] train: loss: 0.0059262
[Epoch 47; Iter   930/  960] train: loss: 0.0156278
[Epoch 47; Iter   960/  960] train: loss: 0.0091050
[Epoch 47] ogbg-molhiv: 0.818948 val loss: 0.183263
[Epoch 47] ogbg-molhiv: 0.824589 test loss: 0.184743
[Epoch 48; Iter    30/  960] train: loss: 0.0255846
[Epoch 48; Iter    60/  960] train: loss: 0.0146542
[Epoch 48; Iter    90/  960] train: loss: 0.1079492
[Epoch 48; Iter   120/  960] train: loss: 0.0056368
[Epoch 48; Iter   150/  960] train: loss: 0.0050137
[Epoch 48; Iter   180/  960] train: loss: 0.0182407
[Epoch 48; Iter   210/  960] train: loss: 0.0724725
[Epoch 48; Iter   240/  960] train: loss: 0.0050868
[Epoch 48; Iter   270/  960] train: loss: 0.0073266
[Epoch 48; Iter   300/  960] train: loss: 0.0276898
[Epoch 48; Iter   330/  960] train: loss: 0.1106540
[Epoch 48; Iter   360/  960] train: loss: 0.0311931
[Epoch 48; Iter   390/  960] train: loss: 0.0181574
[Epoch 48; Iter   420/  960] train: loss: 0.0546994
[Epoch 48; Iter   450/  960] train: loss: 0.0119105
[Epoch 48; Iter   480/  960] train: loss: 0.0153586
[Epoch 48; Iter   510/  960] train: loss: 0.4375494
[Epoch 48; Iter   540/  960] train: loss: 0.2208697
[Epoch 48; Iter   570/  960] train: loss: 0.0313968
[Epoch 48; Iter   600/  960] train: loss: 0.0849765
[Epoch 48; Iter   630/  960] train: loss: 0.1008096
[Epoch 48; Iter   660/  960] train: loss: 0.0033623
[Epoch 48; Iter   690/  960] train: loss: 0.3101057
[Epoch 48; Iter   720/  960] train: loss: 0.0130665
[Epoch 48; Iter   750/  960] train: loss: 0.0047157
[Epoch 48; Iter   780/  960] train: loss: 0.0124899
[Epoch 48; Iter   810/  960] train: loss: 0.0459544
[Epoch 48; Iter   840/  960] train: loss: 0.0047864
[Epoch 48; Iter   870/  960] train: loss: 0.0083241
[Epoch 48; Iter   900/  960] train: loss: 0.0035654
[Epoch 48; Iter   930/  960] train: loss: 0.0289695
[Epoch 48; Iter   960/  960] train: loss: 0.0046082
[Epoch 48] ogbg-molhiv: 0.815613 val loss: 0.169370
[Epoch 48] ogbg-molhiv: 0.816844 test loss: 0.161850
[Epoch 49; Iter    30/  960] train: loss: 0.0527533
[Epoch 49; Iter    60/  960] train: loss: 0.0040096
[Epoch 49; Iter    90/  960] train: loss: 0.0166842
[Epoch 49; Iter   120/  960] train: loss: 0.0164919
[Epoch 49; Iter   150/  960] train: loss: 0.0294925
[Epoch 49; Iter   180/  960] train: loss: 0.0214592
[Epoch 49; Iter   210/  960] train: loss: 0.0476182
[Epoch 49; Iter   240/  960] train: loss: 0.0304205
[Epoch 49; Iter   270/  960] train: loss: 0.1337858
[Epoch 49; Iter   300/  960] train: loss: 0.0209703
[Epoch 49; Iter   330/  960] train: loss: 0.0220323
[Epoch 49; Iter   360/  960] train: loss: 0.0990296
[Epoch 49; Iter   390/  960] train: loss: 0.0041357
[Epoch 49; Iter   420/  960] train: loss: 0.1034157
[Epoch 49; Iter   450/  960] train: loss: 0.0155802
[Epoch 49; Iter   480/  960] train: loss: 0.0574111
[Epoch 49; Iter   510/  960] train: loss: 0.1347995
[Epoch 49; Iter   540/  960] train: loss: 0.0731859
[Epoch 49; Iter   570/  960] train: loss: 0.0189858
[Epoch 49; Iter   600/  960] train: loss: 0.0615924
[Epoch 49; Iter   630/  960] train: loss: 0.0192641
[Epoch 49; Iter   660/  960] train: loss: 0.0052015
[Epoch 49; Iter   690/  960] train: loss: 0.0063299
[Epoch 49; Iter   720/  960] train: loss: 0.0045406
[Epoch 49; Iter   750/  960] train: loss: 0.1649766
[Epoch 49; Iter   780/  960] train: loss: 0.0230050
[Epoch 49; Iter   810/  960] train: loss: 0.0466649
[Epoch 49; Iter   840/  960] train: loss: 0.0145526
[Epoch 49; Iter   870/  960] train: loss: 0.0083781
[Epoch 49; Iter   900/  960] train: loss: 0.0798953
[Epoch 49; Iter   930/  960] train: loss: 0.0671752
[Epoch 49; Iter   960/  960] train: loss: 0.1912149
[Epoch 49] ogbg-molhiv: 0.820274 val loss: 0.176453
[Epoch 49] ogbg-molhiv: 0.819173 test loss: 0.173656
[Epoch 50; Iter    30/  960] train: loss: 0.0209815
[Epoch 50; Iter    60/  960] train: loss: 0.0039050
[Epoch 50; Iter    90/  960] train: loss: 0.0093479
[Epoch 50; Iter   120/  960] train: loss: 0.0021657
[Epoch 50; Iter   150/  960] train: loss: 0.0082565
[Epoch 50; Iter   180/  960] train: loss: 0.0089754
[Epoch 50; Iter   210/  960] train: loss: 0.0132155
[Epoch 50; Iter   240/  960] train: loss: 0.0737699
[Epoch 50; Iter   270/  960] train: loss: 0.0268419
[Epoch 50; Iter   300/  960] train: loss: 0.0590871
[Epoch 50; Iter   330/  960] train: loss: 0.0151597
[Epoch 50; Iter   360/  960] train: loss: 0.0411576
[Epoch 50; Iter   390/  960] train: loss: 0.0038457
[Epoch 50; Iter   420/  960] train: loss: 0.0333308
[Epoch 50; Iter   450/  960] train: loss: 0.0900718
[Epoch 50; Iter   480/  960] train: loss: 0.0722364
[Epoch 50; Iter   510/  960] train: loss: 0.0808792
[Epoch 50; Iter   540/  960] train: loss: 0.0019727
[Epoch 45; Iter   960/  960] train: loss: 0.0204689
[Epoch 45] ogbg-molhiv: 0.808759 val loss: 0.151954
[Epoch 45] ogbg-molhiv: 0.824442 test loss: 0.137479
[Epoch 46; Iter    30/  960] train: loss: 0.0243204
[Epoch 46; Iter    60/  960] train: loss: 0.0881528
[Epoch 46; Iter    90/  960] train: loss: 0.0852083
[Epoch 46; Iter   120/  960] train: loss: 0.0197598
[Epoch 46; Iter   150/  960] train: loss: 0.0110928
[Epoch 46; Iter   180/  960] train: loss: 0.0343632
[Epoch 46; Iter   210/  960] train: loss: 0.0090165
[Epoch 46; Iter   240/  960] train: loss: 0.1657200
[Epoch 46; Iter   270/  960] train: loss: 0.0232710
[Epoch 46; Iter   300/  960] train: loss: 0.1274212
[Epoch 46; Iter   330/  960] train: loss: 0.0106635
[Epoch 46; Iter   360/  960] train: loss: 0.0097826
[Epoch 46; Iter   390/  960] train: loss: 0.0791863
[Epoch 46; Iter   420/  960] train: loss: 0.1703583
[Epoch 46; Iter   450/  960] train: loss: 0.1156474
[Epoch 46; Iter   480/  960] train: loss: 0.2694555
[Epoch 46; Iter   510/  960] train: loss: 0.0081238
[Epoch 46; Iter   540/  960] train: loss: 0.0631431
[Epoch 46; Iter   570/  960] train: loss: 0.0102140
[Epoch 46; Iter   600/  960] train: loss: 0.0340546
[Epoch 46; Iter   630/  960] train: loss: 0.0071013
[Epoch 46; Iter   660/  960] train: loss: 0.1047028
[Epoch 46; Iter   690/  960] train: loss: 0.0195303
[Epoch 46; Iter   720/  960] train: loss: 0.0461696
[Epoch 46; Iter   750/  960] train: loss: 0.0069342
[Epoch 46; Iter   780/  960] train: loss: 0.0115326
[Epoch 46; Iter   810/  960] train: loss: 0.0947933
[Epoch 46; Iter   840/  960] train: loss: 0.1493718
[Epoch 46; Iter   870/  960] train: loss: 0.0548685
[Epoch 46; Iter   900/  960] train: loss: 0.1486114
[Epoch 46; Iter   930/  960] train: loss: 0.2192257
[Epoch 46; Iter   960/  960] train: loss: 0.0300900
[Epoch 46] ogbg-molhiv: 0.802504 val loss: 0.157472
[Epoch 46] ogbg-molhiv: 0.809398 test loss: 0.145435
[Epoch 47; Iter    30/  960] train: loss: 0.0839650
[Epoch 47; Iter    60/  960] train: loss: 0.1470915
[Epoch 47; Iter    90/  960] train: loss: 0.0070911
[Epoch 47; Iter   120/  960] train: loss: 0.0942563
[Epoch 47; Iter   150/  960] train: loss: 0.0759888
[Epoch 47; Iter   180/  960] train: loss: 0.0346050
[Epoch 47; Iter   210/  960] train: loss: 0.1283045
[Epoch 47; Iter   240/  960] train: loss: 0.2524821
[Epoch 47; Iter   270/  960] train: loss: 0.0276855
[Epoch 47; Iter   300/  960] train: loss: 0.0213840
[Epoch 47; Iter   330/  960] train: loss: 0.1164743
[Epoch 47; Iter   360/  960] train: loss: 0.0250023
[Epoch 47; Iter   390/  960] train: loss: 0.1736281
[Epoch 47; Iter   420/  960] train: loss: 0.0774092
[Epoch 47; Iter   450/  960] train: loss: 0.1776475
[Epoch 47; Iter   480/  960] train: loss: 0.0129543
[Epoch 47; Iter   510/  960] train: loss: 0.0659104
[Epoch 47; Iter   540/  960] train: loss: 0.0181248
[Epoch 47; Iter   570/  960] train: loss: 0.0023114
[Epoch 47; Iter   600/  960] train: loss: 0.0112945
[Epoch 47; Iter   630/  960] train: loss: 0.1525111
[Epoch 47; Iter   660/  960] train: loss: 0.1008591
[Epoch 47; Iter   690/  960] train: loss: 0.1887352
[Epoch 47; Iter   720/  960] train: loss: 0.0285543
[Epoch 47; Iter   750/  960] train: loss: 0.0175489
[Epoch 47; Iter   780/  960] train: loss: 0.0045212
[Epoch 47; Iter   810/  960] train: loss: 0.0375121
[Epoch 47; Iter   840/  960] train: loss: 0.0535541
[Epoch 47; Iter   870/  960] train: loss: 0.0187055
[Epoch 47; Iter   900/  960] train: loss: 0.2227020
[Epoch 47; Iter   930/  960] train: loss: 0.0219272
[Epoch 47; Iter   960/  960] train: loss: 0.0276997
[Epoch 47] ogbg-molhiv: 0.818180 val loss: 0.145362
[Epoch 47] ogbg-molhiv: 0.802957 test loss: 0.142321
[Epoch 48; Iter    30/  960] train: loss: 0.0445109
[Epoch 48; Iter    60/  960] train: loss: 0.0216376
[Epoch 48; Iter    90/  960] train: loss: 0.0355116
[Epoch 48; Iter   120/  960] train: loss: 0.0158773
[Epoch 48; Iter   150/  960] train: loss: 0.0474867
[Epoch 48; Iter   180/  960] train: loss: 0.1841684
[Epoch 48; Iter   210/  960] train: loss: 0.1976631
[Epoch 48; Iter   240/  960] train: loss: 0.0086982
[Epoch 48; Iter   270/  960] train: loss: 0.0179746
[Epoch 48; Iter   300/  960] train: loss: 0.0104011
[Epoch 48; Iter   330/  960] train: loss: 0.0506298
[Epoch 48; Iter   360/  960] train: loss: 0.0850515
[Epoch 48; Iter   390/  960] train: loss: 0.0148153
[Epoch 48; Iter   420/  960] train: loss: 0.1353441
[Epoch 48; Iter   450/  960] train: loss: 0.0193502
[Epoch 48; Iter   480/  960] train: loss: 0.1214819
[Epoch 48; Iter   510/  960] train: loss: 0.1568930
[Epoch 48; Iter   540/  960] train: loss: 0.0280020
[Epoch 48; Iter   570/  960] train: loss: 0.0072834
[Epoch 48; Iter   600/  960] train: loss: 0.0422836
[Epoch 48; Iter   630/  960] train: loss: 0.0230381
[Epoch 48; Iter   660/  960] train: loss: 0.0134403
[Epoch 48; Iter   690/  960] train: loss: 0.0243656
[Epoch 48; Iter   720/  960] train: loss: 0.0199796
[Epoch 48; Iter   750/  960] train: loss: 0.0282165
[Epoch 48; Iter   780/  960] train: loss: 0.0236709
[Epoch 48; Iter   810/  960] train: loss: 0.0200823
[Epoch 48; Iter   840/  960] train: loss: 0.0332482
[Epoch 48; Iter   870/  960] train: loss: 0.0591203
[Epoch 48; Iter   900/  960] train: loss: 0.1038817
[Epoch 48; Iter   930/  960] train: loss: 0.0142326
[Epoch 48; Iter   960/  960] train: loss: 0.0138816
[Epoch 48] ogbg-molhiv: 0.810309 val loss: 0.156133
[Epoch 48] ogbg-molhiv: 0.808556 test loss: 0.146527
[Epoch 49; Iter    30/  960] train: loss: 0.0309778
[Epoch 49; Iter    60/  960] train: loss: 0.0066529
[Epoch 49; Iter    90/  960] train: loss: 0.0642265
[Epoch 49; Iter   120/  960] train: loss: 0.0261081
[Epoch 49; Iter   150/  960] train: loss: 0.0194910
[Epoch 49; Iter   180/  960] train: loss: 0.1571053
[Epoch 49; Iter   210/  960] train: loss: 0.0085094
[Epoch 49; Iter   240/  960] train: loss: 0.0203898
[Epoch 49; Iter   270/  960] train: loss: 0.0417216
[Epoch 49; Iter   300/  960] train: loss: 0.0524678
[Epoch 49; Iter   330/  960] train: loss: 0.0535038
[Epoch 49; Iter   360/  960] train: loss: 0.0105325
[Epoch 49; Iter   390/  960] train: loss: 0.0350540
[Epoch 49; Iter   420/  960] train: loss: 0.0217055
[Epoch 49; Iter   450/  960] train: loss: 0.0196297
[Epoch 49; Iter   480/  960] train: loss: 0.0317975
[Epoch 49; Iter   510/  960] train: loss: 0.0330324
[Epoch 49; Iter   540/  960] train: loss: 0.0089851
[Epoch 49; Iter   570/  960] train: loss: 0.0135108
[Epoch 49; Iter   600/  960] train: loss: 0.0095740
[Epoch 49; Iter   630/  960] train: loss: 0.0579631
[Epoch 49; Iter   660/  960] train: loss: 0.0913120
[Epoch 49; Iter   690/  960] train: loss: 0.0973971
[Epoch 49; Iter   720/  960] train: loss: 0.0842356
[Epoch 49; Iter   750/  960] train: loss: 0.1204432
[Epoch 49; Iter   780/  960] train: loss: 0.0109493
[Epoch 49; Iter   810/  960] train: loss: 0.0223671
[Epoch 49; Iter   840/  960] train: loss: 0.1326772
[Epoch 49; Iter   870/  960] train: loss: 0.0352318
[Epoch 49; Iter   900/  960] train: loss: 0.0211298
[Epoch 49; Iter   930/  960] train: loss: 0.0127853
[Epoch 49; Iter   960/  960] train: loss: 0.0115180
[Epoch 49] ogbg-molhiv: 0.814342 val loss: 0.149029
[Epoch 49] ogbg-molhiv: 0.806050 test loss: 0.143293
[Epoch 50; Iter    30/  960] train: loss: 0.0393189
[Epoch 50; Iter    60/  960] train: loss: 0.0376675
[Epoch 50; Iter    90/  960] train: loss: 0.0083022
[Epoch 50; Iter   120/  960] train: loss: 0.0274752
[Epoch 50; Iter   150/  960] train: loss: 0.0632547
[Epoch 50; Iter   180/  960] train: loss: 0.0565502
[Epoch 50; Iter   210/  960] train: loss: 0.0226556
[Epoch 50; Iter   240/  960] train: loss: 0.0040573
[Epoch 50; Iter   270/  960] train: loss: 0.0109213
[Epoch 50; Iter   300/  960] train: loss: 0.1280012
[Epoch 50; Iter   330/  960] train: loss: 0.0257062
[Epoch 50; Iter   360/  960] train: loss: 0.0199688
[Epoch 50; Iter   390/  960] train: loss: 0.1837523
[Epoch 50; Iter   420/  960] train: loss: 0.0179926
[Epoch 50; Iter   450/  960] train: loss: 0.0278321
[Epoch 50; Iter   480/  960] train: loss: 0.0401276
[Epoch 50; Iter   510/  960] train: loss: 0.0271101
[Epoch 50; Iter   540/  960] train: loss: 0.0128876
[Epoch 45; Iter   960/  960] train: loss: 0.2736002
[Epoch 45] ogbg-molhiv: 0.802057 val loss: 0.147624
[Epoch 45] ogbg-molhiv: 0.803931 test loss: 0.133114
[Epoch 46; Iter    30/  960] train: loss: 0.0289054
[Epoch 46; Iter    60/  960] train: loss: 0.0097809
[Epoch 46; Iter    90/  960] train: loss: 0.0338551
[Epoch 46; Iter   120/  960] train: loss: 0.0166720
[Epoch 46; Iter   150/  960] train: loss: 0.1660935
[Epoch 46; Iter   180/  960] train: loss: 0.0329245
[Epoch 46; Iter   210/  960] train: loss: 0.0690101
[Epoch 46; Iter   240/  960] train: loss: 0.0151725
[Epoch 46; Iter   270/  960] train: loss: 0.0189735
[Epoch 46; Iter   300/  960] train: loss: 0.0110475
[Epoch 46; Iter   330/  960] train: loss: 0.0944544
[Epoch 46; Iter   360/  960] train: loss: 0.0933453
[Epoch 46; Iter   390/  960] train: loss: 0.0190401
[Epoch 46; Iter   420/  960] train: loss: 0.0083149
[Epoch 46; Iter   450/  960] train: loss: 0.0138622
[Epoch 46; Iter   480/  960] train: loss: 0.0272257
[Epoch 46; Iter   510/  960] train: loss: 0.1685832
[Epoch 46; Iter   540/  960] train: loss: 0.0081690
[Epoch 46; Iter   570/  960] train: loss: 0.1158685
[Epoch 46; Iter   600/  960] train: loss: 0.0291110
[Epoch 46; Iter   630/  960] train: loss: 0.2237927
[Epoch 46; Iter   660/  960] train: loss: 0.0360164
[Epoch 46; Iter   690/  960] train: loss: 0.1061051
[Epoch 46; Iter   720/  960] train: loss: 0.0155108
[Epoch 46; Iter   750/  960] train: loss: 0.2433722
[Epoch 46; Iter   780/  960] train: loss: 0.0103553
[Epoch 46; Iter   810/  960] train: loss: 0.0147303
[Epoch 46; Iter   840/  960] train: loss: 0.0111167
[Epoch 46; Iter   870/  960] train: loss: 0.0250400
[Epoch 46; Iter   900/  960] train: loss: 0.1344077
[Epoch 46; Iter   930/  960] train: loss: 0.0109247
[Epoch 46; Iter   960/  960] train: loss: 0.0745827
[Epoch 46] ogbg-molhiv: 0.807930 val loss: 0.147857
[Epoch 46] ogbg-molhiv: 0.815099 test loss: 0.139364
[Epoch 47; Iter    30/  960] train: loss: 0.0677226
[Epoch 47; Iter    60/  960] train: loss: 0.0474532
[Epoch 47; Iter    90/  960] train: loss: 0.0304129
[Epoch 47; Iter   120/  960] train: loss: 0.0216249
[Epoch 47; Iter   150/  960] train: loss: 0.0832916
[Epoch 47; Iter   180/  960] train: loss: 0.0108329
[Epoch 47; Iter   210/  960] train: loss: 0.0150293
[Epoch 47; Iter   240/  960] train: loss: 0.0438410
[Epoch 47; Iter   270/  960] train: loss: 0.0579395
[Epoch 47; Iter   300/  960] train: loss: 0.0149386
[Epoch 47; Iter   330/  960] train: loss: 0.0150094
[Epoch 47; Iter   360/  960] train: loss: 0.1175202
[Epoch 47; Iter   390/  960] train: loss: 0.0163429
[Epoch 47; Iter   420/  960] train: loss: 0.0136794
[Epoch 47; Iter   450/  960] train: loss: 0.0191196
[Epoch 47; Iter   480/  960] train: loss: 0.1609063
[Epoch 47; Iter   510/  960] train: loss: 0.0101584
[Epoch 47; Iter   540/  960] train: loss: 0.2789297
[Epoch 47; Iter   570/  960] train: loss: 0.0956230
[Epoch 47; Iter   600/  960] train: loss: 0.0439712
[Epoch 47; Iter   630/  960] train: loss: 0.0231277
[Epoch 47; Iter   660/  960] train: loss: 0.0189588
[Epoch 47; Iter   690/  960] train: loss: 0.0079403
[Epoch 47; Iter   720/  960] train: loss: 0.1067625
[Epoch 47; Iter   750/  960] train: loss: 0.1210817
[Epoch 47; Iter   780/  960] train: loss: 0.0669989
[Epoch 47; Iter   810/  960] train: loss: 0.0226089
[Epoch 47; Iter   840/  960] train: loss: 0.0273091
[Epoch 47; Iter   870/  960] train: loss: 0.1220138
[Epoch 47; Iter   900/  960] train: loss: 0.0238578
[Epoch 47; Iter   930/  960] train: loss: 0.0261408
[Epoch 47; Iter   960/  960] train: loss: 0.0113642
[Epoch 47] ogbg-molhiv: 0.805547 val loss: 0.151326
[Epoch 47] ogbg-molhiv: 0.810256 test loss: 0.140612
[Epoch 48; Iter    30/  960] train: loss: 0.0843101
[Epoch 48; Iter    60/  960] train: loss: 0.0878167
[Epoch 48; Iter    90/  960] train: loss: 0.0132616
[Epoch 48; Iter   120/  960] train: loss: 0.0153283
[Epoch 48; Iter   150/  960] train: loss: 0.0104925
[Epoch 48; Iter   180/  960] train: loss: 0.0230596
[Epoch 48; Iter   210/  960] train: loss: 0.1282124
[Epoch 48; Iter   240/  960] train: loss: 0.0244226
[Epoch 48; Iter   270/  960] train: loss: 0.0551711
[Epoch 48; Iter   300/  960] train: loss: 0.0414446
[Epoch 48; Iter   330/  960] train: loss: 0.0122088
[Epoch 48; Iter   360/  960] train: loss: 0.0245000
[Epoch 48; Iter   390/  960] train: loss: 0.0238022
[Epoch 48; Iter   420/  960] train: loss: 0.0511778
[Epoch 48; Iter   450/  960] train: loss: 0.0301944
[Epoch 48; Iter   480/  960] train: loss: 0.0872492
[Epoch 48; Iter   510/  960] train: loss: 0.0318633
[Epoch 48; Iter   540/  960] train: loss: 0.0562525
[Epoch 48; Iter   570/  960] train: loss: 0.0123040
[Epoch 48; Iter   600/  960] train: loss: 0.0743350
[Epoch 48; Iter   630/  960] train: loss: 0.0130548
[Epoch 48; Iter   660/  960] train: loss: 0.0539429
[Epoch 48; Iter   690/  960] train: loss: 0.1291356
[Epoch 48; Iter   720/  960] train: loss: 0.0294837
[Epoch 48; Iter   750/  960] train: loss: 0.0069957
[Epoch 48; Iter   780/  960] train: loss: 0.0117886
[Epoch 48; Iter   810/  960] train: loss: 0.0227321
[Epoch 48; Iter   840/  960] train: loss: 0.0068922
[Epoch 48; Iter   870/  960] train: loss: 0.2645610
[Epoch 48; Iter   900/  960] train: loss: 0.0518867
[Epoch 48; Iter   930/  960] train: loss: 0.0423774
[Epoch 48; Iter   960/  960] train: loss: 0.1646499
[Epoch 48] ogbg-molhiv: 0.796362 val loss: 0.149433
[Epoch 48] ogbg-molhiv: 0.798854 test loss: 0.143931
[Epoch 49; Iter    30/  960] train: loss: 0.0576450
[Epoch 49; Iter    60/  960] train: loss: 0.0419354
[Epoch 49; Iter    90/  960] train: loss: 0.0145029
[Epoch 49; Iter   120/  960] train: loss: 0.0127897
[Epoch 49; Iter   150/  960] train: loss: 0.0086354
[Epoch 49; Iter   180/  960] train: loss: 0.0600227
[Epoch 49; Iter   210/  960] train: loss: 0.0238646
[Epoch 49; Iter   240/  960] train: loss: 0.0536442
[Epoch 49; Iter   270/  960] train: loss: 0.0082423
[Epoch 49; Iter   300/  960] train: loss: 0.2736746
[Epoch 49; Iter   330/  960] train: loss: 0.0125798
[Epoch 49; Iter   360/  960] train: loss: 0.0528933
[Epoch 49; Iter   390/  960] train: loss: 0.0128675
[Epoch 49; Iter   420/  960] train: loss: 0.0252771
[Epoch 49; Iter   450/  960] train: loss: 0.1296379
[Epoch 49; Iter   480/  960] train: loss: 0.0933174
[Epoch 49; Iter   510/  960] train: loss: 0.0133959
[Epoch 49; Iter   540/  960] train: loss: 0.0243000
[Epoch 49; Iter   570/  960] train: loss: 0.0242989
[Epoch 49; Iter   600/  960] train: loss: 0.0050761
[Epoch 49; Iter   630/  960] train: loss: 0.0062916
[Epoch 49; Iter   660/  960] train: loss: 0.0122258
[Epoch 49; Iter   690/  960] train: loss: 0.0597689
[Epoch 49; Iter   720/  960] train: loss: 0.0203655
[Epoch 49; Iter   750/  960] train: loss: 0.0097835
[Epoch 49; Iter   780/  960] train: loss: 0.0218904
[Epoch 49; Iter   810/  960] train: loss: 0.0318805
[Epoch 49; Iter   840/  960] train: loss: 0.0632458
[Epoch 49; Iter   870/  960] train: loss: 0.0241365
[Epoch 49; Iter   900/  960] train: loss: 0.0416748
[Epoch 49; Iter   930/  960] train: loss: 0.0332342
[Epoch 49; Iter   960/  960] train: loss: 0.0066885
[Epoch 49] ogbg-molhiv: 0.812650 val loss: 0.182160
[Epoch 49] ogbg-molhiv: 0.804730 test loss: 0.197700
[Epoch 50; Iter    30/  960] train: loss: 0.1960629
[Epoch 50; Iter    60/  960] train: loss: 0.0072783
[Epoch 50; Iter    90/  960] train: loss: 0.0322482
[Epoch 50; Iter   120/  960] train: loss: 0.0173854
[Epoch 50; Iter   150/  960] train: loss: 0.0232889
[Epoch 50; Iter   180/  960] train: loss: 0.0325671
[Epoch 50; Iter   210/  960] train: loss: 0.2527706
[Epoch 50; Iter   240/  960] train: loss: 0.0068147
[Epoch 50; Iter   270/  960] train: loss: 0.0915038
[Epoch 50; Iter   300/  960] train: loss: 0.0405793
[Epoch 50; Iter   330/  960] train: loss: 0.0049620
[Epoch 50; Iter   360/  960] train: loss: 0.0326364
[Epoch 50; Iter   390/  960] train: loss: 0.0168692
[Epoch 50; Iter   420/  960] train: loss: 0.0639451
[Epoch 50; Iter   450/  960] train: loss: 0.0171334
[Epoch 50; Iter   480/  960] train: loss: 0.1443383
[Epoch 50; Iter   510/  960] train: loss: 0.0107822
[Epoch 50; Iter   540/  960] train: loss: 0.1248339
[Epoch 44; Iter   799/ 1097] train: loss: 0.1579740
[Epoch 44; Iter   829/ 1097] train: loss: 0.0830989
[Epoch 44; Iter   859/ 1097] train: loss: 0.0217393
[Epoch 44; Iter   889/ 1097] train: loss: 0.1088963
[Epoch 44; Iter   919/ 1097] train: loss: 0.0081049
[Epoch 44; Iter   949/ 1097] train: loss: 0.0075477
[Epoch 44; Iter   979/ 1097] train: loss: 0.1869884
[Epoch 44; Iter  1009/ 1097] train: loss: 0.1236738
[Epoch 44; Iter  1039/ 1097] train: loss: 0.1339475
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0480235
[Epoch 44] ogbg-molhiv: 0.818865 val loss: 0.140606
[Epoch 44] ogbg-molhiv: 0.821898 test loss: 0.138685
[Epoch 45; Iter     2/ 1097] train: loss: 0.0736525
[Epoch 45; Iter    32/ 1097] train: loss: 0.0166173
[Epoch 45; Iter    62/ 1097] train: loss: 0.0230591
[Epoch 45; Iter    92/ 1097] train: loss: 0.0775338
[Epoch 45; Iter   122/ 1097] train: loss: 0.1245848
[Epoch 45; Iter   152/ 1097] train: loss: 0.0056101
[Epoch 45; Iter   182/ 1097] train: loss: 0.0430653
[Epoch 45; Iter   212/ 1097] train: loss: 0.1933522
[Epoch 45; Iter   242/ 1097] train: loss: 0.0077920
[Epoch 45; Iter   272/ 1097] train: loss: 0.0495939
[Epoch 45; Iter   302/ 1097] train: loss: 0.0159995
[Epoch 45; Iter   332/ 1097] train: loss: 0.0102134
[Epoch 45; Iter   362/ 1097] train: loss: 0.3290890
[Epoch 45; Iter   392/ 1097] train: loss: 0.0282576
[Epoch 45; Iter   422/ 1097] train: loss: 0.0236546
[Epoch 45; Iter   452/ 1097] train: loss: 0.0077810
[Epoch 45; Iter   482/ 1097] train: loss: 0.0367169
[Epoch 45; Iter   512/ 1097] train: loss: 0.2143863
[Epoch 45; Iter   542/ 1097] train: loss: 0.0220707
[Epoch 45; Iter   572/ 1097] train: loss: 0.1073492
[Epoch 45; Iter   602/ 1097] train: loss: 0.1451934
[Epoch 45; Iter   632/ 1097] train: loss: 0.0824822
[Epoch 45; Iter   662/ 1097] train: loss: 0.0268245
[Epoch 45; Iter   692/ 1097] train: loss: 0.0671733
[Epoch 45; Iter   722/ 1097] train: loss: 0.0337466
[Epoch 45; Iter   752/ 1097] train: loss: 0.0547108
[Epoch 45; Iter   782/ 1097] train: loss: 0.0147250
[Epoch 45; Iter   812/ 1097] train: loss: 0.2051460
[Epoch 45; Iter   842/ 1097] train: loss: 0.0835555
[Epoch 45; Iter   872/ 1097] train: loss: 0.0166809
[Epoch 45; Iter   902/ 1097] train: loss: 0.0441652
[Epoch 45; Iter   932/ 1097] train: loss: 0.0254097
[Epoch 45; Iter   962/ 1097] train: loss: 0.0582138
[Epoch 45; Iter   992/ 1097] train: loss: 0.0138431
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0109958
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0124869
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0710317
[Epoch 45] ogbg-molhiv: 0.822909 val loss: 0.142399
[Epoch 45] ogbg-molhiv: 0.820921 test loss: 0.142238
[Epoch 46; Iter    15/ 1097] train: loss: 0.0166951
[Epoch 46; Iter    45/ 1097] train: loss: 0.1089843
[Epoch 46; Iter    75/ 1097] train: loss: 0.0494064
[Epoch 46; Iter   105/ 1097] train: loss: 0.0312417
[Epoch 46; Iter   135/ 1097] train: loss: 0.0314383
[Epoch 46; Iter   165/ 1097] train: loss: 0.0149858
[Epoch 46; Iter   195/ 1097] train: loss: 0.0068984
[Epoch 46; Iter   225/ 1097] train: loss: 0.1302131
[Epoch 46; Iter   255/ 1097] train: loss: 0.0351734
[Epoch 46; Iter   285/ 1097] train: loss: 0.0256330
[Epoch 46; Iter   315/ 1097] train: loss: 0.0079987
[Epoch 46; Iter   345/ 1097] train: loss: 0.0324965
[Epoch 46; Iter   375/ 1097] train: loss: 0.0479348
[Epoch 46; Iter   405/ 1097] train: loss: 0.1129680
[Epoch 46; Iter   435/ 1097] train: loss: 0.0598415
[Epoch 46; Iter   465/ 1097] train: loss: 0.0393475
[Epoch 46; Iter   495/ 1097] train: loss: 0.0605689
[Epoch 46; Iter   525/ 1097] train: loss: 0.1645767
[Epoch 46; Iter   555/ 1097] train: loss: 0.0069730
[Epoch 46; Iter   585/ 1097] train: loss: 0.0233356
[Epoch 46; Iter   615/ 1097] train: loss: 0.2286757
[Epoch 46; Iter   645/ 1097] train: loss: 0.0486059
[Epoch 46; Iter   675/ 1097] train: loss: 0.0225964
[Epoch 46; Iter   705/ 1097] train: loss: 0.0236586
[Epoch 46; Iter   735/ 1097] train: loss: 0.0208374
[Epoch 46; Iter   765/ 1097] train: loss: 0.1185831
[Epoch 46; Iter   795/ 1097] train: loss: 0.0244088
[Epoch 46; Iter   825/ 1097] train: loss: 0.0176114
[Epoch 46; Iter   855/ 1097] train: loss: 0.0071758
[Epoch 46; Iter   885/ 1097] train: loss: 0.0462461
[Epoch 46; Iter   915/ 1097] train: loss: 0.0369606
[Epoch 46; Iter   945/ 1097] train: loss: 0.0236888
[Epoch 46; Iter   975/ 1097] train: loss: 0.1269125
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0375030
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0724865
[Epoch 46; Iter  1065/ 1097] train: loss: 0.2334162
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0059713
[Epoch 46] ogbg-molhiv: 0.824526 val loss: 0.194659
[Epoch 46] ogbg-molhiv: 0.815448 test loss: 0.155140
[Epoch 47; Iter    28/ 1097] train: loss: 0.0119725
[Epoch 47; Iter    58/ 1097] train: loss: 0.1756940
[Epoch 47; Iter    88/ 1097] train: loss: 0.0397621
[Epoch 47; Iter   118/ 1097] train: loss: 0.0466852
[Epoch 47; Iter   148/ 1097] train: loss: 0.0394127
[Epoch 47; Iter   178/ 1097] train: loss: 0.0326628
[Epoch 47; Iter   208/ 1097] train: loss: 0.0635963
[Epoch 47; Iter   238/ 1097] train: loss: 0.2049713
[Epoch 47; Iter   268/ 1097] train: loss: 0.0427411
[Epoch 47; Iter   298/ 1097] train: loss: 0.0137469
[Epoch 47; Iter   328/ 1097] train: loss: 0.0811279
[Epoch 47; Iter   358/ 1097] train: loss: 0.0380084
[Epoch 47; Iter   388/ 1097] train: loss: 0.0974449
[Epoch 47; Iter   418/ 1097] train: loss: 0.0088774
[Epoch 47; Iter   448/ 1097] train: loss: 0.1340648
[Epoch 47; Iter   478/ 1097] train: loss: 0.0044177
[Epoch 47; Iter   508/ 1097] train: loss: 0.0160470
[Epoch 47; Iter   538/ 1097] train: loss: 0.0131919
[Epoch 47; Iter   568/ 1097] train: loss: 0.0686514
[Epoch 47; Iter   598/ 1097] train: loss: 0.0644654
[Epoch 47; Iter   628/ 1097] train: loss: 0.0285426
[Epoch 47; Iter   658/ 1097] train: loss: 0.0922224
[Epoch 47; Iter   688/ 1097] train: loss: 0.1296784
[Epoch 47; Iter   718/ 1097] train: loss: 0.0109227
[Epoch 47; Iter   748/ 1097] train: loss: 0.0373488
[Epoch 47; Iter   778/ 1097] train: loss: 0.0323734
[Epoch 47; Iter   808/ 1097] train: loss: 0.0146772
[Epoch 47; Iter   838/ 1097] train: loss: 0.0339410
[Epoch 47; Iter   868/ 1097] train: loss: 0.0505790
[Epoch 47; Iter   898/ 1097] train: loss: 0.0039530
[Epoch 47; Iter   928/ 1097] train: loss: 0.0169188
[Epoch 47; Iter   958/ 1097] train: loss: 0.0122351
[Epoch 47; Iter   988/ 1097] train: loss: 0.0207202
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0823132
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0070139
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0520907
[Epoch 47] ogbg-molhiv: 0.818624 val loss: 0.142377
[Epoch 47] ogbg-molhiv: 0.826248 test loss: 0.138044
[Epoch 48; Iter    11/ 1097] train: loss: 0.0031472
[Epoch 48; Iter    41/ 1097] train: loss: 0.0777524
[Epoch 48; Iter    71/ 1097] train: loss: 0.0318472
[Epoch 48; Iter   101/ 1097] train: loss: 0.0296688
[Epoch 48; Iter   131/ 1097] train: loss: 0.0558884
[Epoch 48; Iter   161/ 1097] train: loss: 0.0702210
[Epoch 48; Iter   191/ 1097] train: loss: 0.1645018
[Epoch 48; Iter   221/ 1097] train: loss: 0.0338246
[Epoch 48; Iter   251/ 1097] train: loss: 0.0661268
[Epoch 48; Iter   281/ 1097] train: loss: 0.0607058
[Epoch 48; Iter   311/ 1097] train: loss: 0.0122324
[Epoch 48; Iter   341/ 1097] train: loss: 0.0177546
[Epoch 48; Iter   371/ 1097] train: loss: 0.0462048
[Epoch 48; Iter   401/ 1097] train: loss: 0.2751598
[Epoch 48; Iter   431/ 1097] train: loss: 0.0998264
[Epoch 48; Iter   461/ 1097] train: loss: 0.1049955
[Epoch 48; Iter   491/ 1097] train: loss: 0.0125031
[Epoch 48; Iter   521/ 1097] train: loss: 0.0673800
[Epoch 48; Iter   551/ 1097] train: loss: 0.0061547
[Epoch 48; Iter   581/ 1097] train: loss: 0.0293072
[Epoch 48; Iter   611/ 1097] train: loss: 0.2535850
[Epoch 48; Iter   641/ 1097] train: loss: 0.0081221
[Epoch 48; Iter   671/ 1097] train: loss: 0.0523886
[Epoch 48; Iter   701/ 1097] train: loss: 0.1541885
[Epoch 48; Iter   731/ 1097] train: loss: 0.0059290
[Epoch 48; Iter   761/ 1097] train: loss: 0.0108991
[Epoch 48; Iter   791/ 1097] train: loss: 0.0199562
[Epoch 48; Iter   821/ 1097] train: loss: 0.1757563
[Epoch 48; Iter   851/ 1097] train: loss: 0.0259306
[Epoch 47; Iter   482/  823] train: loss: 0.0130600
[Epoch 47; Iter   512/  823] train: loss: 0.0425189
[Epoch 47; Iter   542/  823] train: loss: 0.2200247
[Epoch 47; Iter   572/  823] train: loss: 0.0121547
[Epoch 47; Iter   602/  823] train: loss: 0.0346967
[Epoch 47; Iter   632/  823] train: loss: 0.0228032
[Epoch 47; Iter   662/  823] train: loss: 0.0259604
[Epoch 47; Iter   692/  823] train: loss: 0.0305016
[Epoch 47; Iter   722/  823] train: loss: 0.1116766
[Epoch 47; Iter   752/  823] train: loss: 0.2549902
[Epoch 47; Iter   782/  823] train: loss: 0.0254217
[Epoch 47; Iter   812/  823] train: loss: 0.1652998
[Epoch 47] ogbg-molhiv: 0.834768 val loss: 0.134979
[Epoch 47] ogbg-molhiv: 0.811779 test loss: 0.184659
[Epoch 48; Iter    19/  823] train: loss: 0.1610124
[Epoch 48; Iter    49/  823] train: loss: 0.0433073
[Epoch 48; Iter    79/  823] train: loss: 0.0074903
[Epoch 48; Iter   109/  823] train: loss: 0.0376879
[Epoch 48; Iter   139/  823] train: loss: 0.0230749
[Epoch 48; Iter   169/  823] train: loss: 0.0088600
[Epoch 48; Iter   199/  823] train: loss: 0.0071979
[Epoch 48; Iter   229/  823] train: loss: 0.0155904
[Epoch 48; Iter   259/  823] train: loss: 0.0320181
[Epoch 48; Iter   289/  823] train: loss: 0.0062728
[Epoch 48; Iter   319/  823] train: loss: 0.1461721
[Epoch 48; Iter   349/  823] train: loss: 0.1774770
[Epoch 48; Iter   379/  823] train: loss: 0.0291866
[Epoch 48; Iter   409/  823] train: loss: 0.1160635
[Epoch 48; Iter   439/  823] train: loss: 0.0614380
[Epoch 48; Iter   469/  823] train: loss: 0.0120673
[Epoch 48; Iter   499/  823] train: loss: 0.0084288
[Epoch 48; Iter   529/  823] train: loss: 0.1375270
[Epoch 48; Iter   559/  823] train: loss: 0.0069607
[Epoch 48; Iter   589/  823] train: loss: 0.0736934
[Epoch 48; Iter   619/  823] train: loss: 0.0110755
[Epoch 48; Iter   649/  823] train: loss: 0.1771866
[Epoch 48; Iter   679/  823] train: loss: 0.0105462
[Epoch 48; Iter   709/  823] train: loss: 0.0222458
[Epoch 48; Iter   739/  823] train: loss: 0.1068204
[Epoch 48; Iter   769/  823] train: loss: 0.0157277
[Epoch 48; Iter   799/  823] train: loss: 0.0351112
[Epoch 48] ogbg-molhiv: 0.832339 val loss: 0.133605
[Epoch 48] ogbg-molhiv: 0.804220 test loss: 0.148406
[Epoch 49; Iter     6/  823] train: loss: 0.0093634
[Epoch 49; Iter    36/  823] train: loss: 0.0970389
[Epoch 49; Iter    66/  823] train: loss: 0.0807415
[Epoch 49; Iter    96/  823] train: loss: 0.0480325
[Epoch 49; Iter   126/  823] train: loss: 0.0146852
[Epoch 49; Iter   156/  823] train: loss: 0.0279129
[Epoch 49; Iter   186/  823] train: loss: 0.1298210
[Epoch 49; Iter   216/  823] train: loss: 0.0268536
[Epoch 49; Iter   246/  823] train: loss: 0.0309570
[Epoch 49; Iter   276/  823] train: loss: 0.0208057
[Epoch 49; Iter   306/  823] train: loss: 0.0269574
[Epoch 49; Iter   336/  823] train: loss: 0.0750011
[Epoch 49; Iter   366/  823] train: loss: 0.0261579
[Epoch 49; Iter   396/  823] train: loss: 0.0583569
[Epoch 49; Iter   426/  823] train: loss: 0.1556732
[Epoch 49; Iter   456/  823] train: loss: 0.0253334
[Epoch 49; Iter   486/  823] train: loss: 0.0253349
[Epoch 49; Iter   516/  823] train: loss: 0.0124825
[Epoch 49; Iter   546/  823] train: loss: 0.0241520
[Epoch 49; Iter   576/  823] train: loss: 0.0103060
[Epoch 49; Iter   606/  823] train: loss: 0.0081573
[Epoch 49; Iter   636/  823] train: loss: 0.0180171
[Epoch 49; Iter   666/  823] train: loss: 0.0281391
[Epoch 49; Iter   696/  823] train: loss: 0.0193701
[Epoch 49; Iter   726/  823] train: loss: 0.1655402
[Epoch 49; Iter   756/  823] train: loss: 0.1797323
[Epoch 49; Iter   786/  823] train: loss: 0.1517707
[Epoch 49; Iter   816/  823] train: loss: 0.0394636
[Epoch 49] ogbg-molhiv: 0.833938 val loss: 0.125509
[Epoch 49] ogbg-molhiv: 0.810182 test loss: 0.168113
[Epoch 50; Iter    23/  823] train: loss: 0.0164217
[Epoch 50; Iter    53/  823] train: loss: 0.0250099
[Epoch 50; Iter    83/  823] train: loss: 0.0710463
[Epoch 50; Iter   113/  823] train: loss: 0.0757542
[Epoch 50; Iter   143/  823] train: loss: 0.0374781
[Epoch 50; Iter   173/  823] train: loss: 0.0079515
[Epoch 50; Iter   203/  823] train: loss: 0.1263043
[Epoch 50; Iter   233/  823] train: loss: 0.0353298
[Epoch 50; Iter   263/  823] train: loss: 0.0220472
[Epoch 50; Iter   293/  823] train: loss: 0.0127320
[Epoch 50; Iter   323/  823] train: loss: 0.0108273
[Epoch 50; Iter   353/  823] train: loss: 0.0185508
[Epoch 50; Iter   383/  823] train: loss: 0.0437124
[Epoch 50; Iter   413/  823] train: loss: 0.0768076
[Epoch 50; Iter   443/  823] train: loss: 0.0436308
[Epoch 50; Iter   473/  823] train: loss: 0.1386525
[Epoch 50; Iter   503/  823] train: loss: 0.0058689
[Epoch 50; Iter   533/  823] train: loss: 0.0165199
[Epoch 50; Iter   563/  823] train: loss: 0.0339162
[Epoch 50; Iter   593/  823] train: loss: 0.0216726
[Epoch 50; Iter   623/  823] train: loss: 0.0087529
[Epoch 50; Iter   653/  823] train: loss: 0.0202444
[Epoch 50; Iter   683/  823] train: loss: 0.0349864
[Epoch 50; Iter   713/  823] train: loss: 0.0206166
[Epoch 50; Iter   743/  823] train: loss: 0.0095287
[Epoch 50; Iter   773/  823] train: loss: 0.0146064
[Epoch 50; Iter   803/  823] train: loss: 0.1554290
[Epoch 50] ogbg-molhiv: 0.842478 val loss: 0.129758
[Epoch 50] ogbg-molhiv: 0.809335 test loss: 0.172762
[Epoch 51; Iter    10/  823] train: loss: 0.0181309
[Epoch 51; Iter    40/  823] train: loss: 0.0261773
[Epoch 51; Iter    70/  823] train: loss: 0.0073899
[Epoch 51; Iter   100/  823] train: loss: 0.0551485
[Epoch 51; Iter   130/  823] train: loss: 0.1205435
[Epoch 51; Iter   160/  823] train: loss: 0.0844492
[Epoch 51; Iter   190/  823] train: loss: 0.0089451
[Epoch 51; Iter   220/  823] train: loss: 0.0077005
[Epoch 51; Iter   250/  823] train: loss: 0.0659436
[Epoch 51; Iter   280/  823] train: loss: 0.1197259
[Epoch 51; Iter   310/  823] train: loss: 0.0177005
[Epoch 51; Iter   340/  823] train: loss: 0.0892924
[Epoch 51; Iter   370/  823] train: loss: 0.1160588
[Epoch 51; Iter   400/  823] train: loss: 0.0572737
[Epoch 51; Iter   430/  823] train: loss: 0.0272154
[Epoch 51; Iter   460/  823] train: loss: 0.0179962
[Epoch 51; Iter   490/  823] train: loss: 0.0058244
[Epoch 51; Iter   520/  823] train: loss: 0.0226923
[Epoch 51; Iter   550/  823] train: loss: 0.0086661
[Epoch 51; Iter   580/  823] train: loss: 0.2126189
[Epoch 51; Iter   610/  823] train: loss: 0.0306904
[Epoch 51; Iter   640/  823] train: loss: 0.0100171
[Epoch 51; Iter   670/  823] train: loss: 0.0479445
[Epoch 51; Iter   700/  823] train: loss: 0.0308072
[Epoch 51; Iter   730/  823] train: loss: 0.1668504
[Epoch 51; Iter   760/  823] train: loss: 0.0109420
[Epoch 51; Iter   790/  823] train: loss: 0.0084494
[Epoch 51; Iter   820/  823] train: loss: 0.0179305
[Epoch 51] ogbg-molhiv: 0.834300 val loss: 0.133099
[Epoch 51] ogbg-molhiv: 0.801964 test loss: 0.215542
[Epoch 52; Iter    27/  823] train: loss: 0.0112190
[Epoch 52; Iter    57/  823] train: loss: 0.0067572
[Epoch 52; Iter    87/  823] train: loss: 0.0058907
[Epoch 52; Iter   117/  823] train: loss: 0.0173196
[Epoch 52; Iter   147/  823] train: loss: 0.0186373
[Epoch 52; Iter   177/  823] train: loss: 0.0634595
[Epoch 52; Iter   207/  823] train: loss: 0.1606472
[Epoch 52; Iter   237/  823] train: loss: 0.0076263
[Epoch 52; Iter   267/  823] train: loss: 0.0757869
[Epoch 52; Iter   297/  823] train: loss: 0.0085766
[Epoch 52; Iter   327/  823] train: loss: 0.1049989
[Epoch 52; Iter   357/  823] train: loss: 0.1260826
[Epoch 52; Iter   387/  823] train: loss: 0.0389767
[Epoch 52; Iter   417/  823] train: loss: 0.0105869
[Epoch 52; Iter   447/  823] train: loss: 0.0782601
[Epoch 52; Iter   477/  823] train: loss: 0.0301704
[Epoch 52; Iter   507/  823] train: loss: 0.0116653
[Epoch 52; Iter   537/  823] train: loss: 0.0238691
[Epoch 52; Iter   567/  823] train: loss: 0.0810126
[Epoch 52; Iter   597/  823] train: loss: 0.0291851
[Epoch 52; Iter   627/  823] train: loss: 0.0513506
[Epoch 52; Iter   657/  823] train: loss: 0.0180352
[Epoch 52; Iter   687/  823] train: loss: 0.1120059
[Epoch 52; Iter   717/  823] train: loss: 0.1836530
[Epoch 52; Iter   747/  823] train: loss: 0.0135710
[Epoch 47; Iter   482/  823] train: loss: 0.0538764
[Epoch 47; Iter   512/  823] train: loss: 0.0087631
[Epoch 47; Iter   542/  823] train: loss: 0.3640254
[Epoch 47; Iter   572/  823] train: loss: 0.0344537
[Epoch 47; Iter   602/  823] train: loss: 0.0576945
[Epoch 47; Iter   632/  823] train: loss: 0.0687315
[Epoch 47; Iter   662/  823] train: loss: 0.1026606
[Epoch 47; Iter   692/  823] train: loss: 0.1121931
[Epoch 47; Iter   722/  823] train: loss: 0.0206526
[Epoch 47; Iter   752/  823] train: loss: 0.0364070
[Epoch 47; Iter   782/  823] train: loss: 0.0785972
[Epoch 47; Iter   812/  823] train: loss: 0.1039176
[Epoch 47] ogbg-molhiv: 0.827410 val loss: 0.126187
[Epoch 47] ogbg-molhiv: 0.803576 test loss: 0.189024
[Epoch 48; Iter    19/  823] train: loss: 0.0084398
[Epoch 48; Iter    49/  823] train: loss: 0.0336772
[Epoch 48; Iter    79/  823] train: loss: 0.2722979
[Epoch 48; Iter   109/  823] train: loss: 0.0345692
[Epoch 48; Iter   139/  823] train: loss: 0.0294422
[Epoch 48; Iter   169/  823] train: loss: 0.2228004
[Epoch 48; Iter   199/  823] train: loss: 0.0218304
[Epoch 48; Iter   229/  823] train: loss: 0.0466782
[Epoch 48; Iter   259/  823] train: loss: 0.0251065
[Epoch 48; Iter   289/  823] train: loss: 0.0132354
[Epoch 48; Iter   319/  823] train: loss: 0.0122837
[Epoch 48; Iter   349/  823] train: loss: 0.0107537
[Epoch 48; Iter   379/  823] train: loss: 0.0072259
[Epoch 48; Iter   409/  823] train: loss: 0.0465816
[Epoch 48; Iter   439/  823] train: loss: 0.0657676
[Epoch 48; Iter   469/  823] train: loss: 0.0262386
[Epoch 48; Iter   499/  823] train: loss: 0.0469798
[Epoch 48; Iter   529/  823] train: loss: 0.0530451
[Epoch 48; Iter   559/  823] train: loss: 0.0561938
[Epoch 48; Iter   589/  823] train: loss: 0.0900452
[Epoch 48; Iter   619/  823] train: loss: 0.0450605
[Epoch 48; Iter   649/  823] train: loss: 0.0144828
[Epoch 48; Iter   679/  823] train: loss: 0.0130976
[Epoch 48; Iter   709/  823] train: loss: 0.0342005
[Epoch 48; Iter   739/  823] train: loss: 0.0747905
[Epoch 48; Iter   769/  823] train: loss: 0.0109294
[Epoch 48; Iter   799/  823] train: loss: 0.0281309
[Epoch 48] ogbg-molhiv: 0.831220 val loss: 0.164610
[Epoch 48] ogbg-molhiv: 0.806634 test loss: 0.249868
[Epoch 49; Iter     6/  823] train: loss: 0.0213025
[Epoch 49; Iter    36/  823] train: loss: 0.0086111
[Epoch 49; Iter    66/  823] train: loss: 0.0091857
[Epoch 49; Iter    96/  823] train: loss: 0.0137008
[Epoch 49; Iter   126/  823] train: loss: 0.0316089
[Epoch 49; Iter   156/  823] train: loss: 0.1132746
[Epoch 49; Iter   186/  823] train: loss: 0.0261577
[Epoch 49; Iter   216/  823] train: loss: 0.0733483
[Epoch 49; Iter   246/  823] train: loss: 0.0095932
[Epoch 49; Iter   276/  823] train: loss: 0.1986012
[Epoch 49; Iter   306/  823] train: loss: 0.1072031
[Epoch 49; Iter   336/  823] train: loss: 0.0187821
[Epoch 49; Iter   366/  823] train: loss: 0.0505828
[Epoch 49; Iter   396/  823] train: loss: 0.0423515
[Epoch 49; Iter   426/  823] train: loss: 0.0785185
[Epoch 49; Iter   456/  823] train: loss: 0.0563433
[Epoch 49; Iter   486/  823] train: loss: 0.0863156
[Epoch 49; Iter   516/  823] train: loss: 0.0257574
[Epoch 49; Iter   546/  823] train: loss: 0.0293598
[Epoch 49; Iter   576/  823] train: loss: 0.0942646
[Epoch 49; Iter   606/  823] train: loss: 0.1090410
[Epoch 49; Iter   636/  823] train: loss: 0.0351000
[Epoch 49; Iter   666/  823] train: loss: 0.0291705
[Epoch 49; Iter   696/  823] train: loss: 0.0281199
[Epoch 49; Iter   726/  823] train: loss: 0.0460651
[Epoch 49; Iter   756/  823] train: loss: 0.1460115
[Epoch 49; Iter   786/  823] train: loss: 0.0225205
[Epoch 49; Iter   816/  823] train: loss: 0.0098305
[Epoch 49] ogbg-molhiv: 0.822456 val loss: 0.151610
[Epoch 49] ogbg-molhiv: 0.798999 test loss: 0.216572
[Epoch 50; Iter    23/  823] train: loss: 0.0074434
[Epoch 50; Iter    53/  823] train: loss: 0.0402858
[Epoch 50; Iter    83/  823] train: loss: 0.0590898
[Epoch 50; Iter   113/  823] train: loss: 0.0096161
[Epoch 50; Iter   143/  823] train: loss: 0.0294009
[Epoch 50; Iter   173/  823] train: loss: 0.0220071
[Epoch 50; Iter   203/  823] train: loss: 0.0301386
[Epoch 50; Iter   233/  823] train: loss: 0.0130183
[Epoch 50; Iter   263/  823] train: loss: 0.1593394
[Epoch 50; Iter   293/  823] train: loss: 0.0288964
[Epoch 50; Iter   323/  823] train: loss: 0.0092494
[Epoch 50; Iter   353/  823] train: loss: 0.1093485
[Epoch 50; Iter   383/  823] train: loss: 0.0163427
[Epoch 50; Iter   413/  823] train: loss: 0.0035736
[Epoch 50; Iter   443/  823] train: loss: 0.0135388
[Epoch 50; Iter   473/  823] train: loss: 0.1630004
[Epoch 50; Iter   503/  823] train: loss: 0.0637506
[Epoch 50; Iter   533/  823] train: loss: 0.0098069
[Epoch 50; Iter   563/  823] train: loss: 0.0165823
[Epoch 50; Iter   593/  823] train: loss: 0.0703189
[Epoch 50; Iter   623/  823] train: loss: 0.0644935
[Epoch 50; Iter   653/  823] train: loss: 0.0785066
[Epoch 50; Iter   683/  823] train: loss: 0.0417966
[Epoch 50; Iter   713/  823] train: loss: 0.1072358
[Epoch 50; Iter   743/  823] train: loss: 0.0304967
[Epoch 50; Iter   773/  823] train: loss: 0.0146601
[Epoch 50; Iter   803/  823] train: loss: 0.1183502
[Epoch 50] ogbg-molhiv: 0.822851 val loss: 0.140234
[Epoch 50] ogbg-molhiv: 0.789947 test loss: 0.203234
[Epoch 51; Iter    10/  823] train: loss: 0.1049427
[Epoch 51; Iter    40/  823] train: loss: 0.0049076
[Epoch 51; Iter    70/  823] train: loss: 0.0225161
[Epoch 51; Iter   100/  823] train: loss: 0.0246334
[Epoch 51; Iter   130/  823] train: loss: 0.0070399
[Epoch 51; Iter   160/  823] train: loss: 0.0126445
[Epoch 51; Iter   190/  823] train: loss: 0.0163433
[Epoch 51; Iter   220/  823] train: loss: 0.0793475
[Epoch 51; Iter   250/  823] train: loss: 0.1897133
[Epoch 51; Iter   280/  823] train: loss: 0.0313586
[Epoch 51; Iter   310/  823] train: loss: 0.0086699
[Epoch 51; Iter   340/  823] train: loss: 0.0063832
[Epoch 51; Iter   370/  823] train: loss: 0.1081418
[Epoch 51; Iter   400/  823] train: loss: 0.0078052
[Epoch 51; Iter   430/  823] train: loss: 0.0097969
[Epoch 51; Iter   460/  823] train: loss: 0.1927739
[Epoch 51; Iter   490/  823] train: loss: 0.0368483
[Epoch 51; Iter   520/  823] train: loss: 0.0112432
[Epoch 51; Iter   550/  823] train: loss: 0.0112370
[Epoch 51; Iter   580/  823] train: loss: 0.0230956
[Epoch 51; Iter   610/  823] train: loss: 0.0329174
[Epoch 51; Iter   640/  823] train: loss: 0.0330296
[Epoch 51; Iter   670/  823] train: loss: 0.0059033
[Epoch 51; Iter   700/  823] train: loss: 0.0587388
[Epoch 51; Iter   730/  823] train: loss: 0.0273738
[Epoch 51; Iter   760/  823] train: loss: 0.0893822
[Epoch 51; Iter   790/  823] train: loss: 0.0162079
[Epoch 51; Iter   820/  823] train: loss: 0.1896437
[Epoch 51] ogbg-molhiv: 0.828433 val loss: 0.158079
[Epoch 51] ogbg-molhiv: 0.797672 test loss: 0.251519
[Epoch 52; Iter    27/  823] train: loss: 0.0340288
[Epoch 52; Iter    57/  823] train: loss: 0.0201321
[Epoch 52; Iter    87/  823] train: loss: 0.0232736
[Epoch 52; Iter   117/  823] train: loss: 0.0309065
[Epoch 52; Iter   147/  823] train: loss: 0.0849767
[Epoch 52; Iter   177/  823] train: loss: 0.0130146
[Epoch 52; Iter   207/  823] train: loss: 0.0583597
[Epoch 52; Iter   237/  823] train: loss: 0.0512848
[Epoch 52; Iter   267/  823] train: loss: 0.0312793
[Epoch 52; Iter   297/  823] train: loss: 0.0086748
[Epoch 52; Iter   327/  823] train: loss: 0.0398280
[Epoch 52; Iter   357/  823] train: loss: 0.0310522
[Epoch 52; Iter   387/  823] train: loss: 0.0085718
[Epoch 52; Iter   417/  823] train: loss: 0.0087441
[Epoch 52; Iter   447/  823] train: loss: 0.0569533
[Epoch 52; Iter   477/  823] train: loss: 0.0374167
[Epoch 52; Iter   507/  823] train: loss: 0.0156400
[Epoch 52; Iter   537/  823] train: loss: 0.0070712
[Epoch 52; Iter   567/  823] train: loss: 0.0776707
[Epoch 52; Iter   597/  823] train: loss: 0.1025611
[Epoch 52; Iter   627/  823] train: loss: 0.0104761
[Epoch 52; Iter   657/  823] train: loss: 0.0228639
[Epoch 52; Iter   687/  823] train: loss: 0.0059444
[Epoch 52; Iter   717/  823] train: loss: 0.0267867
[Epoch 52; Iter   747/  823] train: loss: 0.0718522
[Epoch 48; Iter   881/ 1097] train: loss: 0.0199967
[Epoch 48; Iter   911/ 1097] train: loss: 0.2561424
[Epoch 48; Iter   941/ 1097] train: loss: 0.0911353
[Epoch 48; Iter   971/ 1097] train: loss: 0.0287878
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0183105
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0179771
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0311078
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0228375
[Epoch 48] ogbg-molhiv: 0.835037 val loss: 0.347953
[Epoch 48] ogbg-molhiv: 0.809797 test loss: 0.155773
[Epoch 49; Iter    24/ 1097] train: loss: 0.1718946
[Epoch 49; Iter    54/ 1097] train: loss: 0.0403264
[Epoch 49; Iter    84/ 1097] train: loss: 0.0514714
[Epoch 49; Iter   114/ 1097] train: loss: 0.0124998
[Epoch 49; Iter   144/ 1097] train: loss: 0.1984411
[Epoch 49; Iter   174/ 1097] train: loss: 0.0230749
[Epoch 49; Iter   204/ 1097] train: loss: 0.1190771
[Epoch 49; Iter   234/ 1097] train: loss: 0.0582317
[Epoch 49; Iter   264/ 1097] train: loss: 0.0215338
[Epoch 49; Iter   294/ 1097] train: loss: 0.1559643
[Epoch 49; Iter   324/ 1097] train: loss: 0.0205337
[Epoch 49; Iter   354/ 1097] train: loss: 0.0986644
[Epoch 49; Iter   384/ 1097] train: loss: 0.0691400
[Epoch 49; Iter   414/ 1097] train: loss: 0.0220453
[Epoch 49; Iter   444/ 1097] train: loss: 0.0272107
[Epoch 49; Iter   474/ 1097] train: loss: 0.0205007
[Epoch 49; Iter   504/ 1097] train: loss: 0.1212816
[Epoch 49; Iter   534/ 1097] train: loss: 0.0210322
[Epoch 49; Iter   564/ 1097] train: loss: 0.2306919
[Epoch 49; Iter   594/ 1097] train: loss: 0.1583973
[Epoch 49; Iter   624/ 1097] train: loss: 0.0257227
[Epoch 49; Iter   654/ 1097] train: loss: 0.0309392
[Epoch 49; Iter   684/ 1097] train: loss: 0.0232382
[Epoch 49; Iter   714/ 1097] train: loss: 0.4893397
[Epoch 49; Iter   744/ 1097] train: loss: 0.0654083
[Epoch 49; Iter   774/ 1097] train: loss: 0.0433608
[Epoch 49; Iter   804/ 1097] train: loss: 0.0292730
[Epoch 49; Iter   834/ 1097] train: loss: 0.0178024
[Epoch 49; Iter   864/ 1097] train: loss: 0.0140168
[Epoch 49; Iter   894/ 1097] train: loss: 0.0788009
[Epoch 49; Iter   924/ 1097] train: loss: 0.0691699
[Epoch 49; Iter   954/ 1097] train: loss: 0.1323000
[Epoch 49; Iter   984/ 1097] train: loss: 0.0733585
[Epoch 49; Iter  1014/ 1097] train: loss: 0.1549069
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0170184
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0112705
[Epoch 49] ogbg-molhiv: 0.832543 val loss: 0.261568
[Epoch 49] ogbg-molhiv: 0.804825 test loss: 0.351596
[Epoch 50; Iter     7/ 1097] train: loss: 0.0298489
[Epoch 50; Iter    37/ 1097] train: loss: 0.0419523
[Epoch 50; Iter    67/ 1097] train: loss: 0.0689418
[Epoch 50; Iter    97/ 1097] train: loss: 0.0419261
[Epoch 50; Iter   127/ 1097] train: loss: 0.0721028
[Epoch 50; Iter   157/ 1097] train: loss: 0.0155706
[Epoch 50; Iter   187/ 1097] train: loss: 0.0279695
[Epoch 50; Iter   217/ 1097] train: loss: 0.3038972
[Epoch 50; Iter   247/ 1097] train: loss: 0.3039716
[Epoch 50; Iter   277/ 1097] train: loss: 0.1013660
[Epoch 50; Iter   307/ 1097] train: loss: 0.0782596
[Epoch 50; Iter   337/ 1097] train: loss: 0.0391584
[Epoch 50; Iter   367/ 1097] train: loss: 0.1648231
[Epoch 50; Iter   397/ 1097] train: loss: 0.0208230
[Epoch 50; Iter   427/ 1097] train: loss: 0.1135957
[Epoch 50; Iter   457/ 1097] train: loss: 0.0214454
[Epoch 50; Iter   487/ 1097] train: loss: 0.0172624
[Epoch 50; Iter   517/ 1097] train: loss: 0.0397958
[Epoch 50; Iter   547/ 1097] train: loss: 0.1118315
[Epoch 50; Iter   577/ 1097] train: loss: 0.0199482
[Epoch 50; Iter   607/ 1097] train: loss: 0.3529729
[Epoch 50; Iter   637/ 1097] train: loss: 0.0293055
[Epoch 50; Iter   667/ 1097] train: loss: 0.0394765
[Epoch 50; Iter   697/ 1097] train: loss: 0.0318509
[Epoch 50; Iter   727/ 1097] train: loss: 0.0157392
[Epoch 50; Iter   757/ 1097] train: loss: 0.1484297
[Epoch 50; Iter   787/ 1097] train: loss: 0.0300099
[Epoch 50; Iter   817/ 1097] train: loss: 0.0926644
[Epoch 50; Iter   847/ 1097] train: loss: 0.0589892
[Epoch 50; Iter   877/ 1097] train: loss: 0.0955762
[Epoch 50; Iter   907/ 1097] train: loss: 0.1208462
[Epoch 50; Iter   937/ 1097] train: loss: 0.0417987
[Epoch 50; Iter   967/ 1097] train: loss: 0.0214275
[Epoch 50; Iter   997/ 1097] train: loss: 0.0388508
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0215323
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0785234
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0172846
[Epoch 50] ogbg-molhiv: 0.823299 val loss: 0.409912
[Epoch 50] ogbg-molhiv: 0.807892 test loss: 0.773618
[Epoch 51; Iter    20/ 1097] train: loss: 0.0131503
[Epoch 51; Iter    50/ 1097] train: loss: 0.2312632
[Epoch 51; Iter    80/ 1097] train: loss: 0.0437231
[Epoch 51; Iter   110/ 1097] train: loss: 0.0326780
[Epoch 51; Iter   140/ 1097] train: loss: 0.0835923
[Epoch 51; Iter   170/ 1097] train: loss: 0.0304107
[Epoch 51; Iter   200/ 1097] train: loss: 0.1255154
[Epoch 51; Iter   230/ 1097] train: loss: 0.0428285
[Epoch 51; Iter   260/ 1097] train: loss: 0.0614367
[Epoch 51; Iter   290/ 1097] train: loss: 0.0227863
[Epoch 51; Iter   320/ 1097] train: loss: 0.0591500
[Epoch 51; Iter   350/ 1097] train: loss: 0.0145043
[Epoch 51; Iter   380/ 1097] train: loss: 0.0533847
[Epoch 51; Iter   410/ 1097] train: loss: 0.1000997
[Epoch 51; Iter   440/ 1097] train: loss: 0.0310417
[Epoch 51; Iter   470/ 1097] train: loss: 0.0602533
[Epoch 51; Iter   500/ 1097] train: loss: 0.0244825
[Epoch 51; Iter   530/ 1097] train: loss: 0.1214099
[Epoch 51; Iter   560/ 1097] train: loss: 0.0582932
[Epoch 51; Iter   590/ 1097] train: loss: 0.0889301
[Epoch 51; Iter   620/ 1097] train: loss: 0.1413052
[Epoch 51; Iter   650/ 1097] train: loss: 0.0141374
[Epoch 51; Iter   680/ 1097] train: loss: 0.1699672
[Epoch 51; Iter   710/ 1097] train: loss: 0.0233069
[Epoch 51; Iter   740/ 1097] train: loss: 0.0307832
[Epoch 51; Iter   770/ 1097] train: loss: 0.0392815
[Epoch 51; Iter   800/ 1097] train: loss: 0.0895596
[Epoch 51; Iter   830/ 1097] train: loss: 0.0141196
[Epoch 51; Iter   860/ 1097] train: loss: 0.0289446
[Epoch 51; Iter   890/ 1097] train: loss: 0.0785773
[Epoch 51; Iter   920/ 1097] train: loss: 0.0181134
[Epoch 51; Iter   950/ 1097] train: loss: 0.0328253
[Epoch 51; Iter   980/ 1097] train: loss: 0.0923324
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0335044
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0173200
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0787462
[Epoch 51] ogbg-molhiv: 0.822612 val loss: 0.529260
[Epoch 51] ogbg-molhiv: 0.801700 test loss: 0.816516
[Epoch 52; Iter     3/ 1097] train: loss: 0.0127928
[Epoch 52; Iter    33/ 1097] train: loss: 0.0234833
[Epoch 52; Iter    63/ 1097] train: loss: 0.0961144
[Epoch 52; Iter    93/ 1097] train: loss: 0.1610048
[Epoch 52; Iter   123/ 1097] train: loss: 0.0564266
[Epoch 52; Iter   153/ 1097] train: loss: 0.0145243
[Epoch 52; Iter   183/ 1097] train: loss: 0.0606755
[Epoch 52; Iter   213/ 1097] train: loss: 0.0084482
[Epoch 52; Iter   243/ 1097] train: loss: 0.0156613
[Epoch 52; Iter   273/ 1097] train: loss: 0.1386301
[Epoch 52; Iter   303/ 1097] train: loss: 0.1333777
[Epoch 52; Iter   333/ 1097] train: loss: 0.1298231
[Epoch 52; Iter   363/ 1097] train: loss: 0.0169695
[Epoch 52; Iter   393/ 1097] train: loss: 0.0385474
[Epoch 52; Iter   423/ 1097] train: loss: 0.0237364
[Epoch 52; Iter   453/ 1097] train: loss: 0.0140365
[Epoch 52; Iter   483/ 1097] train: loss: 0.0341078
[Epoch 52; Iter   513/ 1097] train: loss: 0.0136858
[Epoch 52; Iter   543/ 1097] train: loss: 0.0128536
[Epoch 52; Iter   573/ 1097] train: loss: 0.1729286
[Epoch 52; Iter   603/ 1097] train: loss: 0.0804096
[Epoch 52; Iter   633/ 1097] train: loss: 0.0384420
[Epoch 52; Iter   663/ 1097] train: loss: 0.1179811
[Epoch 52; Iter   693/ 1097] train: loss: 0.0902186
[Epoch 52; Iter   723/ 1097] train: loss: 0.1984783
[Epoch 52; Iter   753/ 1097] train: loss: 0.0277406
[Epoch 52; Iter   783/ 1097] train: loss: 0.0206165
[Epoch 52; Iter   813/ 1097] train: loss: 0.0748193
[Epoch 52; Iter   843/ 1097] train: loss: 0.0363009
[Epoch 52; Iter   873/ 1097] train: loss: 0.0216008
[Epoch 52; Iter   903/ 1097] train: loss: 0.0139436
[Epoch 52; Iter   933/ 1097] train: loss: 0.0509431
[Epoch 48; Iter   881/ 1097] train: loss: 0.0623256
[Epoch 48; Iter   911/ 1097] train: loss: 0.0291152
[Epoch 48; Iter   941/ 1097] train: loss: 0.0329065
[Epoch 48; Iter   971/ 1097] train: loss: 0.0688295
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0118507
[Epoch 48; Iter  1031/ 1097] train: loss: 0.1228743
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0075157
[Epoch 48; Iter  1091/ 1097] train: loss: 0.2177880
[Epoch 48] ogbg-molhiv: 0.803828 val loss: 0.153098
[Epoch 48] ogbg-molhiv: 0.817405 test loss: 0.156245
[Epoch 49; Iter    24/ 1097] train: loss: 0.0161263
[Epoch 49; Iter    54/ 1097] train: loss: 0.1783905
[Epoch 49; Iter    84/ 1097] train: loss: 0.0064907
[Epoch 49; Iter   114/ 1097] train: loss: 0.1839599
[Epoch 49; Iter   144/ 1097] train: loss: 0.0110328
[Epoch 49; Iter   174/ 1097] train: loss: 0.0472110
[Epoch 49; Iter   204/ 1097] train: loss: 0.0739740
[Epoch 49; Iter   234/ 1097] train: loss: 0.0170785
[Epoch 49; Iter   264/ 1097] train: loss: 0.0274076
[Epoch 49; Iter   294/ 1097] train: loss: 0.1495165
[Epoch 49; Iter   324/ 1097] train: loss: 0.0701043
[Epoch 49; Iter   354/ 1097] train: loss: 0.0388785
[Epoch 49; Iter   384/ 1097] train: loss: 0.0085277
[Epoch 49; Iter   414/ 1097] train: loss: 0.0364471
[Epoch 49; Iter   444/ 1097] train: loss: 0.0161333
[Epoch 49; Iter   474/ 1097] train: loss: 0.0390809
[Epoch 49; Iter   504/ 1097] train: loss: 0.0169795
[Epoch 49; Iter   534/ 1097] train: loss: 0.0105460
[Epoch 49; Iter   564/ 1097] train: loss: 0.0509375
[Epoch 49; Iter   594/ 1097] train: loss: 0.0380798
[Epoch 49; Iter   624/ 1097] train: loss: 0.0081976
[Epoch 49; Iter   654/ 1097] train: loss: 0.0122413
[Epoch 49; Iter   684/ 1097] train: loss: 0.0205101
[Epoch 49; Iter   714/ 1097] train: loss: 0.1569457
[Epoch 49; Iter   744/ 1097] train: loss: 0.0096018
[Epoch 49; Iter   774/ 1097] train: loss: 0.0345304
[Epoch 49; Iter   804/ 1097] train: loss: 0.0552609
[Epoch 49; Iter   834/ 1097] train: loss: 0.0424454
[Epoch 49; Iter   864/ 1097] train: loss: 0.1210061
[Epoch 49; Iter   894/ 1097] train: loss: 0.0104184
[Epoch 49; Iter   924/ 1097] train: loss: 0.0748113
[Epoch 49; Iter   954/ 1097] train: loss: 0.0265476
[Epoch 49; Iter   984/ 1097] train: loss: 0.1801793
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0068212
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0383182
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0282804
[Epoch 49] ogbg-molhiv: 0.815052 val loss: 0.149639
[Epoch 49] ogbg-molhiv: 0.812130 test loss: 0.211064
[Epoch 50; Iter     7/ 1097] train: loss: 0.0125286
[Epoch 50; Iter    37/ 1097] train: loss: 0.0244484
[Epoch 50; Iter    67/ 1097] train: loss: 0.0919733
[Epoch 50; Iter    97/ 1097] train: loss: 0.0144256
[Epoch 50; Iter   127/ 1097] train: loss: 0.0692687
[Epoch 50; Iter   157/ 1097] train: loss: 0.1041629
[Epoch 50; Iter   187/ 1097] train: loss: 0.0331242
[Epoch 50; Iter   217/ 1097] train: loss: 0.0275042
[Epoch 50; Iter   247/ 1097] train: loss: 0.0713627
[Epoch 50; Iter   277/ 1097] train: loss: 0.1237571
[Epoch 50; Iter   307/ 1097] train: loss: 0.0081236
[Epoch 50; Iter   337/ 1097] train: loss: 0.0056159
[Epoch 50; Iter   367/ 1097] train: loss: 0.0056331
[Epoch 50; Iter   397/ 1097] train: loss: 0.0056295
[Epoch 50; Iter   427/ 1097] train: loss: 0.1760689
[Epoch 50; Iter   457/ 1097] train: loss: 0.0107915
[Epoch 50; Iter   487/ 1097] train: loss: 0.0046552
[Epoch 50; Iter   517/ 1097] train: loss: 0.0619529
[Epoch 50; Iter   547/ 1097] train: loss: 0.0132403
[Epoch 50; Iter   577/ 1097] train: loss: 0.0085463
[Epoch 50; Iter   607/ 1097] train: loss: 0.0213902
[Epoch 50; Iter   637/ 1097] train: loss: 0.1866697
[Epoch 50; Iter   667/ 1097] train: loss: 0.0129995
[Epoch 50; Iter   697/ 1097] train: loss: 0.0124030
[Epoch 50; Iter   727/ 1097] train: loss: 0.0104904
[Epoch 50; Iter   757/ 1097] train: loss: 0.0116515
[Epoch 50; Iter   787/ 1097] train: loss: 0.0110580
[Epoch 50; Iter   817/ 1097] train: loss: 0.0385760
[Epoch 50; Iter   847/ 1097] train: loss: 0.1265252
[Epoch 50; Iter   877/ 1097] train: loss: 0.0962564
[Epoch 50; Iter   907/ 1097] train: loss: 0.0519217
[Epoch 50; Iter   937/ 1097] train: loss: 0.2108317
[Epoch 50; Iter   967/ 1097] train: loss: 0.0602407
[Epoch 50; Iter   997/ 1097] train: loss: 0.0178055
[Epoch 50; Iter  1027/ 1097] train: loss: 0.1295399
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0196317
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0314098
[Epoch 50] ogbg-molhiv: 0.824541 val loss: 0.161382
[Epoch 50] ogbg-molhiv: 0.814905 test loss: 0.339623
[Epoch 51; Iter    20/ 1097] train: loss: 0.0152608
[Epoch 51; Iter    50/ 1097] train: loss: 0.1382772
[Epoch 51; Iter    80/ 1097] train: loss: 0.0361222
[Epoch 51; Iter   110/ 1097] train: loss: 0.1386610
[Epoch 51; Iter   140/ 1097] train: loss: 0.0195976
[Epoch 51; Iter   170/ 1097] train: loss: 0.0079542
[Epoch 51; Iter   200/ 1097] train: loss: 0.0264760
[Epoch 51; Iter   230/ 1097] train: loss: 0.0646950
[Epoch 51; Iter   260/ 1097] train: loss: 0.0157985
[Epoch 51; Iter   290/ 1097] train: loss: 0.0289606
[Epoch 51; Iter   320/ 1097] train: loss: 0.2215277
[Epoch 51; Iter   350/ 1097] train: loss: 0.1637622
[Epoch 51; Iter   380/ 1097] train: loss: 0.0379244
[Epoch 51; Iter   410/ 1097] train: loss: 0.0242457
[Epoch 51; Iter   440/ 1097] train: loss: 0.0103865
[Epoch 51; Iter   470/ 1097] train: loss: 0.1370221
[Epoch 51; Iter   500/ 1097] train: loss: 0.1504182
[Epoch 51; Iter   530/ 1097] train: loss: 0.0857108
[Epoch 51; Iter   560/ 1097] train: loss: 0.0201163
[Epoch 51; Iter   590/ 1097] train: loss: 0.0068438
[Epoch 51; Iter   620/ 1097] train: loss: 0.1432582
[Epoch 51; Iter   650/ 1097] train: loss: 0.1180656
[Epoch 51; Iter   680/ 1097] train: loss: 0.0324731
[Epoch 51; Iter   710/ 1097] train: loss: 0.1451176
[Epoch 51; Iter   740/ 1097] train: loss: 0.0072826
[Epoch 51; Iter   770/ 1097] train: loss: 0.0124984
[Epoch 51; Iter   800/ 1097] train: loss: 0.0040739
[Epoch 51; Iter   830/ 1097] train: loss: 0.1176717
[Epoch 51; Iter   860/ 1097] train: loss: 0.0188401
[Epoch 51; Iter   890/ 1097] train: loss: 0.0055962
[Epoch 51; Iter   920/ 1097] train: loss: 0.0110774
[Epoch 51; Iter   950/ 1097] train: loss: 0.0235741
[Epoch 51; Iter   980/ 1097] train: loss: 0.0676773
[Epoch 51; Iter  1010/ 1097] train: loss: 0.1724284
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0843670
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0246124
[Epoch 51] ogbg-molhiv: 0.804563 val loss: 0.164000
[Epoch 51] ogbg-molhiv: 0.802628 test loss: 0.208035
[Epoch 52; Iter     3/ 1097] train: loss: 0.0704671
[Epoch 52; Iter    33/ 1097] train: loss: 0.0084809
[Epoch 52; Iter    63/ 1097] train: loss: 0.0073000
[Epoch 52; Iter    93/ 1097] train: loss: 0.0202321
[Epoch 52; Iter   123/ 1097] train: loss: 0.1009449
[Epoch 52; Iter   153/ 1097] train: loss: 0.0905389
[Epoch 52; Iter   183/ 1097] train: loss: 0.1210932
[Epoch 52; Iter   213/ 1097] train: loss: 0.0099339
[Epoch 52; Iter   243/ 1097] train: loss: 0.0046848
[Epoch 52; Iter   273/ 1097] train: loss: 0.0204672
[Epoch 52; Iter   303/ 1097] train: loss: 0.1992853
[Epoch 52; Iter   333/ 1097] train: loss: 0.0525400
[Epoch 52; Iter   363/ 1097] train: loss: 0.0441947
[Epoch 52; Iter   393/ 1097] train: loss: 0.0035975
[Epoch 52; Iter   423/ 1097] train: loss: 0.0285538
[Epoch 52; Iter   453/ 1097] train: loss: 0.0469809
[Epoch 52; Iter   483/ 1097] train: loss: 0.0577731
[Epoch 52; Iter   513/ 1097] train: loss: 0.0212198
[Epoch 52; Iter   543/ 1097] train: loss: 0.0692975
[Epoch 52; Iter   573/ 1097] train: loss: 0.0083572
[Epoch 52; Iter   603/ 1097] train: loss: 0.0064771
[Epoch 52; Iter   633/ 1097] train: loss: 0.0196107
[Epoch 52; Iter   663/ 1097] train: loss: 0.0133752
[Epoch 52; Iter   693/ 1097] train: loss: 0.0519132
[Epoch 52; Iter   723/ 1097] train: loss: 0.0733223
[Epoch 52; Iter   753/ 1097] train: loss: 0.0880010
[Epoch 52; Iter   783/ 1097] train: loss: 0.0417001
[Epoch 52; Iter   813/ 1097] train: loss: 0.0296493
[Epoch 52; Iter   843/ 1097] train: loss: 0.0449300
[Epoch 52; Iter   873/ 1097] train: loss: 0.0084292
[Epoch 52; Iter   903/ 1097] train: loss: 0.0259149
[Epoch 52; Iter   933/ 1097] train: loss: 0.3268649
[Epoch 48; Iter   881/ 1097] train: loss: 0.0182137
[Epoch 48; Iter   911/ 1097] train: loss: 0.0113834
[Epoch 48; Iter   941/ 1097] train: loss: 0.0045038
[Epoch 48; Iter   971/ 1097] train: loss: 0.0425687
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0138535
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0395835
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0344405
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0499184
[Epoch 48] ogbg-molhiv: 0.809942 val loss: 0.146354
[Epoch 48] ogbg-molhiv: 0.815262 test loss: 0.142039
[Epoch 49; Iter    24/ 1097] train: loss: 0.1114992
[Epoch 49; Iter    54/ 1097] train: loss: 0.0765898
[Epoch 49; Iter    84/ 1097] train: loss: 0.0268698
[Epoch 49; Iter   114/ 1097] train: loss: 0.0204478
[Epoch 49; Iter   144/ 1097] train: loss: 0.0232758
[Epoch 49; Iter   174/ 1097] train: loss: 0.0202308
[Epoch 49; Iter   204/ 1097] train: loss: 0.0835444
[Epoch 49; Iter   234/ 1097] train: loss: 0.0897598
[Epoch 49; Iter   264/ 1097] train: loss: 0.0250577
[Epoch 49; Iter   294/ 1097] train: loss: 0.0830596
[Epoch 49; Iter   324/ 1097] train: loss: 0.1019005
[Epoch 49; Iter   354/ 1097] train: loss: 0.1633504
[Epoch 49; Iter   384/ 1097] train: loss: 0.0056530
[Epoch 49; Iter   414/ 1097] train: loss: 0.0448980
[Epoch 49; Iter   444/ 1097] train: loss: 0.0143926
[Epoch 49; Iter   474/ 1097] train: loss: 0.0145007
[Epoch 49; Iter   504/ 1097] train: loss: 0.0137089
[Epoch 49; Iter   534/ 1097] train: loss: 0.1223010
[Epoch 49; Iter   564/ 1097] train: loss: 0.0456569
[Epoch 49; Iter   594/ 1097] train: loss: 0.0089926
[Epoch 49; Iter   624/ 1097] train: loss: 0.0701755
[Epoch 49; Iter   654/ 1097] train: loss: 0.0056146
[Epoch 49; Iter   684/ 1097] train: loss: 0.0530416
[Epoch 49; Iter   714/ 1097] train: loss: 0.0111718
[Epoch 49; Iter   744/ 1097] train: loss: 0.0236099
[Epoch 49; Iter   774/ 1097] train: loss: 0.0847158
[Epoch 49; Iter   804/ 1097] train: loss: 0.0131311
[Epoch 49; Iter   834/ 1097] train: loss: 0.0298533
[Epoch 49; Iter   864/ 1097] train: loss: 0.0315224
[Epoch 49; Iter   894/ 1097] train: loss: 0.0065944
[Epoch 49; Iter   924/ 1097] train: loss: 0.0738322
[Epoch 49; Iter   954/ 1097] train: loss: 0.1275381
[Epoch 49; Iter   984/ 1097] train: loss: 0.0393695
[Epoch 49; Iter  1014/ 1097] train: loss: 0.3429439
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0136499
[Epoch 49; Iter  1074/ 1097] train: loss: 0.1273567
[Epoch 49] ogbg-molhiv: 0.811781 val loss: 0.169310
[Epoch 49] ogbg-molhiv: 0.821696 test loss: 0.147784
[Epoch 50; Iter     7/ 1097] train: loss: 0.0268673
[Epoch 50; Iter    37/ 1097] train: loss: 0.1419688
[Epoch 50; Iter    67/ 1097] train: loss: 0.1009547
[Epoch 50; Iter    97/ 1097] train: loss: 0.0135423
[Epoch 50; Iter   127/ 1097] train: loss: 0.0746883
[Epoch 50; Iter   157/ 1097] train: loss: 0.2025389
[Epoch 50; Iter   187/ 1097] train: loss: 0.0744648
[Epoch 50; Iter   217/ 1097] train: loss: 0.0647918
[Epoch 50; Iter   247/ 1097] train: loss: 0.1195454
[Epoch 50; Iter   277/ 1097] train: loss: 0.0549048
[Epoch 50; Iter   307/ 1097] train: loss: 0.0170025
[Epoch 50; Iter   337/ 1097] train: loss: 0.0098417
[Epoch 50; Iter   367/ 1097] train: loss: 0.0453984
[Epoch 50; Iter   397/ 1097] train: loss: 0.0439346
[Epoch 50; Iter   427/ 1097] train: loss: 0.0739023
[Epoch 50; Iter   457/ 1097] train: loss: 0.0341033
[Epoch 50; Iter   487/ 1097] train: loss: 0.0104169
[Epoch 50; Iter   517/ 1097] train: loss: 0.0669481
[Epoch 50; Iter   547/ 1097] train: loss: 0.0056931
[Epoch 50; Iter   577/ 1097] train: loss: 0.0073083
[Epoch 50; Iter   607/ 1097] train: loss: 0.0105035
[Epoch 50; Iter   637/ 1097] train: loss: 0.0198128
[Epoch 50; Iter   667/ 1097] train: loss: 0.0774141
[Epoch 50; Iter   697/ 1097] train: loss: 0.0391585
[Epoch 50; Iter   727/ 1097] train: loss: 0.0677520
[Epoch 50; Iter   757/ 1097] train: loss: 0.1633027
[Epoch 50; Iter   787/ 1097] train: loss: 0.0283882
[Epoch 50; Iter   817/ 1097] train: loss: 0.0179881
[Epoch 50; Iter   847/ 1097] train: loss: 0.0119656
[Epoch 50; Iter   877/ 1097] train: loss: 0.0452189
[Epoch 50; Iter   907/ 1097] train: loss: 0.2092365
[Epoch 50; Iter   937/ 1097] train: loss: 0.0384851
[Epoch 50; Iter   967/ 1097] train: loss: 0.0427587
[Epoch 50; Iter   997/ 1097] train: loss: 0.0903980
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0480036
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0354946
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0218617
[Epoch 50] ogbg-molhiv: 0.823512 val loss: 0.149534
[Epoch 50] ogbg-molhiv: 0.815484 test loss: 0.144960
[Epoch 51; Iter    20/ 1097] train: loss: 0.0174791
[Epoch 51; Iter    50/ 1097] train: loss: 0.0115701
[Epoch 51; Iter    80/ 1097] train: loss: 0.0577049
[Epoch 51; Iter   110/ 1097] train: loss: 0.0381980
[Epoch 51; Iter   140/ 1097] train: loss: 0.0753689
[Epoch 51; Iter   170/ 1097] train: loss: 0.0294050
[Epoch 51; Iter   200/ 1097] train: loss: 0.0091356
[Epoch 51; Iter   230/ 1097] train: loss: 0.0831047
[Epoch 51; Iter   260/ 1097] train: loss: 0.0122252
[Epoch 51; Iter   290/ 1097] train: loss: 0.0379758
[Epoch 51; Iter   320/ 1097] train: loss: 0.0042994
[Epoch 51; Iter   350/ 1097] train: loss: 0.0153777
[Epoch 51; Iter   380/ 1097] train: loss: 0.0585303
[Epoch 51; Iter   410/ 1097] train: loss: 0.0166264
[Epoch 51; Iter   440/ 1097] train: loss: 0.0123510
[Epoch 51; Iter   470/ 1097] train: loss: 0.0609574
[Epoch 51; Iter   500/ 1097] train: loss: 0.0111860
[Epoch 51; Iter   530/ 1097] train: loss: 0.0442646
[Epoch 51; Iter   560/ 1097] train: loss: 0.0239808
[Epoch 51; Iter   590/ 1097] train: loss: 0.0853270
[Epoch 51; Iter   620/ 1097] train: loss: 0.0978263
[Epoch 51; Iter   650/ 1097] train: loss: 0.1107680
[Epoch 51; Iter   680/ 1097] train: loss: 0.0100736
[Epoch 51; Iter   710/ 1097] train: loss: 0.1286404
[Epoch 51; Iter   740/ 1097] train: loss: 0.1817787
[Epoch 51; Iter   770/ 1097] train: loss: 0.0254240
[Epoch 51; Iter   800/ 1097] train: loss: 0.0188870
[Epoch 51; Iter   830/ 1097] train: loss: 0.1818268
[Epoch 51; Iter   860/ 1097] train: loss: 0.3163376
[Epoch 51; Iter   890/ 1097] train: loss: 0.0294100
[Epoch 51; Iter   920/ 1097] train: loss: 0.0642691
[Epoch 51; Iter   950/ 1097] train: loss: 0.0121363
[Epoch 51; Iter   980/ 1097] train: loss: 0.0035999
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0076295
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0059037
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0077502
[Epoch 51] ogbg-molhiv: 0.816373 val loss: 0.149705
[Epoch 51] ogbg-molhiv: 0.817187 test loss: 0.144214
[Epoch 52; Iter     3/ 1097] train: loss: 0.0051725
[Epoch 52; Iter    33/ 1097] train: loss: 0.0075082
[Epoch 52; Iter    63/ 1097] train: loss: 0.0195528
[Epoch 52; Iter    93/ 1097] train: loss: 0.1676629
[Epoch 52; Iter   123/ 1097] train: loss: 0.0589331
[Epoch 52; Iter   153/ 1097] train: loss: 0.0102627
[Epoch 52; Iter   183/ 1097] train: loss: 0.0242172
[Epoch 52; Iter   213/ 1097] train: loss: 0.0926617
[Epoch 52; Iter   243/ 1097] train: loss: 0.0634591
[Epoch 52; Iter   273/ 1097] train: loss: 0.0247782
[Epoch 52; Iter   303/ 1097] train: loss: 0.0419242
[Epoch 52; Iter   333/ 1097] train: loss: 0.0233371
[Epoch 52; Iter   363/ 1097] train: loss: 0.0195281
[Epoch 52; Iter   393/ 1097] train: loss: 0.0259058
[Epoch 52; Iter   423/ 1097] train: loss: 0.1225796
[Epoch 52; Iter   453/ 1097] train: loss: 0.0063036
[Epoch 52; Iter   483/ 1097] train: loss: 0.0545408
[Epoch 52; Iter   513/ 1097] train: loss: 0.0800956
[Epoch 52; Iter   543/ 1097] train: loss: 0.2567720
[Epoch 52; Iter   573/ 1097] train: loss: 0.1017693
[Epoch 52; Iter   603/ 1097] train: loss: 0.0062190
[Epoch 52; Iter   633/ 1097] train: loss: 0.1606319
[Epoch 52; Iter   663/ 1097] train: loss: 0.0171117
[Epoch 52; Iter   693/ 1097] train: loss: 0.1472086
[Epoch 52; Iter   723/ 1097] train: loss: 0.0362866
[Epoch 52; Iter   753/ 1097] train: loss: 0.0101038
[Epoch 52; Iter   783/ 1097] train: loss: 0.0114301
[Epoch 52; Iter   813/ 1097] train: loss: 0.1830985
[Epoch 52; Iter   843/ 1097] train: loss: 0.0760822
[Epoch 52; Iter   873/ 1097] train: loss: 0.0119983
[Epoch 52; Iter   903/ 1097] train: loss: 0.0173519
[Epoch 52; Iter   933/ 1097] train: loss: 0.0299560
[Epoch 50; Iter   570/  960] train: loss: 0.0233761
[Epoch 50; Iter   600/  960] train: loss: 0.0391782
[Epoch 50; Iter   630/  960] train: loss: 0.0105774
[Epoch 50; Iter   660/  960] train: loss: 0.3032856
[Epoch 50; Iter   690/  960] train: loss: 0.0044978
[Epoch 50; Iter   720/  960] train: loss: 0.0061405
[Epoch 50; Iter   750/  960] train: loss: 0.0545610
[Epoch 50; Iter   780/  960] train: loss: 0.0189332
[Epoch 50; Iter   810/  960] train: loss: 0.0897093
[Epoch 50; Iter   840/  960] train: loss: 0.0325522
[Epoch 50; Iter   870/  960] train: loss: 0.0905013
[Epoch 50; Iter   900/  960] train: loss: 0.0297092
[Epoch 50; Iter   930/  960] train: loss: 0.0058426
[Epoch 50; Iter   960/  960] train: loss: 0.2817901
[Epoch 50] ogbg-molhiv: 0.814130 val loss: 0.189268
[Epoch 50] ogbg-molhiv: 0.804932 test loss: 0.179071
[Epoch 51; Iter    30/  960] train: loss: 0.0106212
[Epoch 51; Iter    60/  960] train: loss: 0.0628150
[Epoch 51; Iter    90/  960] train: loss: 0.0162652
[Epoch 51; Iter   120/  960] train: loss: 0.0050808
[Epoch 51; Iter   150/  960] train: loss: 0.0075650
[Epoch 51; Iter   180/  960] train: loss: 0.0120456
[Epoch 51; Iter   210/  960] train: loss: 0.0166678
[Epoch 51; Iter   240/  960] train: loss: 0.0206703
[Epoch 51; Iter   270/  960] train: loss: 0.0046641
[Epoch 51; Iter   300/  960] train: loss: 0.0685969
[Epoch 51; Iter   330/  960] train: loss: 0.0035459
[Epoch 51; Iter   360/  960] train: loss: 0.0694973
[Epoch 51; Iter   390/  960] train: loss: 0.0775972
[Epoch 51; Iter   420/  960] train: loss: 0.1070914
[Epoch 51; Iter   450/  960] train: loss: 0.2411959
[Epoch 51; Iter   480/  960] train: loss: 0.0110983
[Epoch 51; Iter   510/  960] train: loss: 0.0890334
[Epoch 51; Iter   540/  960] train: loss: 0.0067503
[Epoch 51; Iter   570/  960] train: loss: 0.0040196
[Epoch 51; Iter   600/  960] train: loss: 0.0518754
[Epoch 51; Iter   630/  960] train: loss: 0.0043217
[Epoch 51; Iter   660/  960] train: loss: 0.0737073
[Epoch 51; Iter   690/  960] train: loss: 0.0217870
[Epoch 51; Iter   720/  960] train: loss: 0.0089817
[Epoch 51; Iter   750/  960] train: loss: 0.0061238
[Epoch 51; Iter   780/  960] train: loss: 0.0250815
[Epoch 51; Iter   810/  960] train: loss: 0.0106005
[Epoch 51; Iter   840/  960] train: loss: 0.1222572
[Epoch 51; Iter   870/  960] train: loss: 0.1149635
[Epoch 51; Iter   900/  960] train: loss: 0.0117620
[Epoch 51; Iter   930/  960] train: loss: 0.0111824
[Epoch 51; Iter   960/  960] train: loss: 0.0064860
[Epoch 51] ogbg-molhiv: 0.818530 val loss: 0.172894
[Epoch 51] ogbg-molhiv: 0.808800 test loss: 0.169049
[Epoch 52; Iter    30/  960] train: loss: 0.0137508
[Epoch 52; Iter    60/  960] train: loss: 0.0201975
[Epoch 52; Iter    90/  960] train: loss: 0.0560139
[Epoch 52; Iter   120/  960] train: loss: 0.0059856
[Epoch 52; Iter   150/  960] train: loss: 0.0117334
[Epoch 52; Iter   180/  960] train: loss: 0.0856757
[Epoch 52; Iter   210/  960] train: loss: 0.0276365
[Epoch 52; Iter   240/  960] train: loss: 0.1062386
[Epoch 52; Iter   270/  960] train: loss: 0.0157274
[Epoch 52; Iter   300/  960] train: loss: 0.0396467
[Epoch 52; Iter   330/  960] train: loss: 0.0023271
[Epoch 52; Iter   360/  960] train: loss: 0.0327961
[Epoch 52; Iter   390/  960] train: loss: 0.0088542
[Epoch 52; Iter   420/  960] train: loss: 0.0091572
[Epoch 52; Iter   450/  960] train: loss: 0.0220540
[Epoch 52; Iter   480/  960] train: loss: 0.0040108
[Epoch 52; Iter   510/  960] train: loss: 0.0121860
[Epoch 52; Iter   540/  960] train: loss: 0.0223090
[Epoch 52; Iter   570/  960] train: loss: 0.0486400
[Epoch 52; Iter   600/  960] train: loss: 0.0213847
[Epoch 52; Iter   630/  960] train: loss: 0.1194313
[Epoch 52; Iter   660/  960] train: loss: 0.0093046
[Epoch 52; Iter   690/  960] train: loss: 0.0127657
[Epoch 52; Iter   720/  960] train: loss: 0.0625319
[Epoch 52; Iter   750/  960] train: loss: 0.0307943
[Epoch 52; Iter   780/  960] train: loss: 0.0345162
[Epoch 52; Iter   810/  960] train: loss: 0.0048011
[Epoch 52; Iter   840/  960] train: loss: 0.0905972
[Epoch 52; Iter   870/  960] train: loss: 0.0106059
[Epoch 52; Iter   900/  960] train: loss: 0.0080878
[Epoch 52; Iter   930/  960] train: loss: 0.0194852
[Epoch 52; Iter   960/  960] train: loss: 0.0383457
[Epoch 52] ogbg-molhiv: 0.817641 val loss: 0.182814
[Epoch 52] ogbg-molhiv: 0.809511 test loss: 0.180869
[Epoch 53; Iter    30/  960] train: loss: 0.0093741
[Epoch 53; Iter    60/  960] train: loss: 0.0122676
[Epoch 53; Iter    90/  960] train: loss: 0.0292218
[Epoch 53; Iter   120/  960] train: loss: 0.0289401
[Epoch 53; Iter   150/  960] train: loss: 0.0338706
[Epoch 53; Iter   180/  960] train: loss: 0.0035195
[Epoch 53; Iter   210/  960] train: loss: 0.0025840
[Epoch 53; Iter   240/  960] train: loss: 0.1126888
[Epoch 53; Iter   270/  960] train: loss: 0.1056446
[Epoch 53; Iter   300/  960] train: loss: 0.0808167
[Epoch 53; Iter   330/  960] train: loss: 0.0044793
[Epoch 53; Iter   360/  960] train: loss: 0.0319397
[Epoch 53; Iter   390/  960] train: loss: 0.0285927
[Epoch 53; Iter   420/  960] train: loss: 0.0091242
[Epoch 53; Iter   450/  960] train: loss: 0.0191876
[Epoch 53; Iter   480/  960] train: loss: 0.1069085
[Epoch 53; Iter   510/  960] train: loss: 0.0128623
[Epoch 53; Iter   540/  960] train: loss: 0.0063266
[Epoch 53; Iter   570/  960] train: loss: 0.0863955
[Epoch 53; Iter   600/  960] train: loss: 0.0323807
[Epoch 53; Iter   630/  960] train: loss: 0.0199143
[Epoch 53; Iter   660/  960] train: loss: 0.0834907
[Epoch 53; Iter   690/  960] train: loss: 0.0342991
[Epoch 53; Iter   720/  960] train: loss: 0.1331324
[Epoch 53; Iter   750/  960] train: loss: 0.0111464
[Epoch 53; Iter   780/  960] train: loss: 0.0830964
[Epoch 53; Iter   810/  960] train: loss: 0.1223601
[Epoch 53; Iter   840/  960] train: loss: 0.1627627
[Epoch 53; Iter   870/  960] train: loss: 0.0349698
[Epoch 53; Iter   900/  960] train: loss: 0.0097618
[Epoch 53; Iter   930/  960] train: loss: 0.0452420
[Epoch 53; Iter   960/  960] train: loss: 0.2257761
[Epoch 53] ogbg-molhiv: 0.817267 val loss: 0.172844
[Epoch 53] ogbg-molhiv: 0.811045 test loss: 0.170734
[Epoch 54; Iter    30/  960] train: loss: 0.0115713
[Epoch 54; Iter    60/  960] train: loss: 0.0465041
[Epoch 54; Iter    90/  960] train: loss: 0.0139524
[Epoch 54; Iter   120/  960] train: loss: 0.2533740
[Epoch 54; Iter   150/  960] train: loss: 0.0376536
[Epoch 54; Iter   180/  960] train: loss: 0.0102973
[Epoch 54; Iter   210/  960] train: loss: 0.0244533
[Epoch 54; Iter   240/  960] train: loss: 0.0636409
[Epoch 54; Iter   270/  960] train: loss: 0.0256860
[Epoch 54; Iter   300/  960] train: loss: 0.0247657
[Epoch 54; Iter   330/  960] train: loss: 0.2639204
[Epoch 54; Iter   360/  960] train: loss: 0.0323176
[Epoch 54; Iter   390/  960] train: loss: 0.0512401
[Epoch 54; Iter   420/  960] train: loss: 0.0034538
[Epoch 54; Iter   450/  960] train: loss: 0.0443983
[Epoch 54; Iter   480/  960] train: loss: 0.0149322
[Epoch 54; Iter   510/  960] train: loss: 0.0774866
[Epoch 54; Iter   540/  960] train: loss: 0.0378200
[Epoch 54; Iter   570/  960] train: loss: 0.0635131
[Epoch 54; Iter   600/  960] train: loss: 0.1512290
[Epoch 54; Iter   630/  960] train: loss: 0.0904285
[Epoch 54; Iter   660/  960] train: loss: 0.0013050
[Epoch 54; Iter   690/  960] train: loss: 0.0075032
[Epoch 54; Iter   720/  960] train: loss: 0.0083860
[Epoch 54; Iter   750/  960] train: loss: 0.0521326
[Epoch 54; Iter   780/  960] train: loss: 0.0150137
[Epoch 54; Iter   810/  960] train: loss: 0.0982849
[Epoch 54; Iter   840/  960] train: loss: 0.0049161
[Epoch 54; Iter   870/  960] train: loss: 0.0359546
[Epoch 54; Iter   900/  960] train: loss: 0.0350650
[Epoch 54; Iter   930/  960] train: loss: 0.0095692
[Epoch 54; Iter   960/  960] train: loss: 0.0141398
[Epoch 54] ogbg-molhiv: 0.829933 val loss: 0.165323
[Epoch 54] ogbg-molhiv: 0.812282 test loss: 0.171676
[Epoch 55; Iter    30/  960] train: loss: 0.0097892
[Epoch 55; Iter    60/  960] train: loss: 0.0048705
[Epoch 55; Iter    90/  960] train: loss: 0.0049416
[Epoch 55; Iter   120/  960] train: loss: 0.0911454
[Epoch 55; Iter   150/  960] train: loss: 0.0576954
[Epoch 50; Iter   570/  960] train: loss: 0.0181064
[Epoch 50; Iter   600/  960] train: loss: 0.1127707
[Epoch 50; Iter   630/  960] train: loss: 0.0695822
[Epoch 50; Iter   660/  960] train: loss: 0.1152973
[Epoch 50; Iter   690/  960] train: loss: 0.1838363
[Epoch 50; Iter   720/  960] train: loss: 0.0407925
[Epoch 50; Iter   750/  960] train: loss: 0.0707737
[Epoch 50; Iter   780/  960] train: loss: 0.0269571
[Epoch 50; Iter   810/  960] train: loss: 0.1641876
[Epoch 50; Iter   840/  960] train: loss: 0.0127344
[Epoch 50; Iter   870/  960] train: loss: 0.0124296
[Epoch 50; Iter   900/  960] train: loss: 0.0080802
[Epoch 50; Iter   930/  960] train: loss: 0.0576247
[Epoch 50; Iter   960/  960] train: loss: 0.0275560
[Epoch 50] ogbg-molhiv: 0.820716 val loss: 0.152184
[Epoch 50] ogbg-molhiv: 0.806593 test loss: 0.148585
[Epoch 51; Iter    30/  960] train: loss: 0.0096596
[Epoch 51; Iter    60/  960] train: loss: 0.0113973
[Epoch 51; Iter    90/  960] train: loss: 0.0853814
[Epoch 51; Iter   120/  960] train: loss: 0.0375925
[Epoch 51; Iter   150/  960] train: loss: 0.0737072
[Epoch 51; Iter   180/  960] train: loss: 0.0148321
[Epoch 51; Iter   210/  960] train: loss: 0.2565697
[Epoch 51; Iter   240/  960] train: loss: 0.0197341
[Epoch 51; Iter   270/  960] train: loss: 0.0177068
[Epoch 51; Iter   300/  960] train: loss: 0.0796517
[Epoch 51; Iter   330/  960] train: loss: 0.0206694
[Epoch 51; Iter   360/  960] train: loss: 0.0434411
[Epoch 51; Iter   390/  960] train: loss: 0.0132789
[Epoch 51; Iter   420/  960] train: loss: 0.0220656
[Epoch 51; Iter   450/  960] train: loss: 0.0478313
[Epoch 51; Iter   480/  960] train: loss: 0.0253725
[Epoch 51; Iter   510/  960] train: loss: 0.0119257
[Epoch 51; Iter   540/  960] train: loss: 0.0395952
[Epoch 51; Iter   570/  960] train: loss: 0.2149298
[Epoch 51; Iter   600/  960] train: loss: 0.1064183
[Epoch 51; Iter   630/  960] train: loss: 0.2144704
[Epoch 51; Iter   660/  960] train: loss: 0.0467846
[Epoch 51; Iter   690/  960] train: loss: 0.0454226
[Epoch 51; Iter   720/  960] train: loss: 0.1019585
[Epoch 51; Iter   750/  960] train: loss: 0.1295756
[Epoch 51; Iter   780/  960] train: loss: 0.1007089
[Epoch 51; Iter   810/  960] train: loss: 0.0131671
[Epoch 51; Iter   840/  960] train: loss: 0.0906608
[Epoch 51; Iter   870/  960] train: loss: 0.1805050
[Epoch 51; Iter   900/  960] train: loss: 0.0098083
[Epoch 51; Iter   930/  960] train: loss: 0.0483439
[Epoch 51; Iter   960/  960] train: loss: 0.0079037
[Epoch 51] ogbg-molhiv: 0.820879 val loss: 0.157344
[Epoch 51] ogbg-molhiv: 0.817264 test loss: 0.148865
[Epoch 52; Iter    30/  960] train: loss: 0.1335036
[Epoch 52; Iter    60/  960] train: loss: 0.1426544
[Epoch 52; Iter    90/  960] train: loss: 0.0361551
[Epoch 52; Iter   120/  960] train: loss: 0.0316806
[Epoch 52; Iter   150/  960] train: loss: 0.0193977
[Epoch 52; Iter   180/  960] train: loss: 0.0291093
[Epoch 52; Iter   210/  960] train: loss: 0.0563163
[Epoch 52; Iter   240/  960] train: loss: 0.0817316
[Epoch 52; Iter   270/  960] train: loss: 0.0072847
[Epoch 52; Iter   300/  960] train: loss: 0.1230064
[Epoch 52; Iter   330/  960] train: loss: 0.0092159
[Epoch 52; Iter   360/  960] train: loss: 0.0229519
[Epoch 52; Iter   390/  960] train: loss: 0.1293157
[Epoch 52; Iter   420/  960] train: loss: 0.0100595
[Epoch 52; Iter   450/  960] train: loss: 0.0136144
[Epoch 52; Iter   480/  960] train: loss: 0.0432235
[Epoch 52; Iter   510/  960] train: loss: 0.0080738
[Epoch 52; Iter   540/  960] train: loss: 0.0307779
[Epoch 52; Iter   570/  960] train: loss: 0.0164789
[Epoch 52; Iter   600/  960] train: loss: 0.0475985
[Epoch 52; Iter   630/  960] train: loss: 0.0917281
[Epoch 52; Iter   660/  960] train: loss: 0.2045229
[Epoch 52; Iter   690/  960] train: loss: 0.0152707
[Epoch 52; Iter   720/  960] train: loss: 0.0296986
[Epoch 52; Iter   750/  960] train: loss: 0.0299594
[Epoch 52; Iter   780/  960] train: loss: 0.0861562
[Epoch 52; Iter   810/  960] train: loss: 0.0201534
[Epoch 52; Iter   840/  960] train: loss: 0.0159405
[Epoch 52; Iter   870/  960] train: loss: 0.0104032
[Epoch 52; Iter   900/  960] train: loss: 0.1105336
[Epoch 52; Iter   930/  960] train: loss: 0.0357128
[Epoch 52; Iter   960/  960] train: loss: 0.0104977
[Epoch 52] ogbg-molhiv: 0.821849 val loss: 0.157122
[Epoch 52] ogbg-molhiv: 0.810883 test loss: 0.150395
[Epoch 53; Iter    30/  960] train: loss: 0.0885583
[Epoch 53; Iter    60/  960] train: loss: 0.1373736
[Epoch 53; Iter    90/  960] train: loss: 0.0183790
[Epoch 53; Iter   120/  960] train: loss: 0.0077961
[Epoch 53; Iter   150/  960] train: loss: 0.0094883
[Epoch 53; Iter   180/  960] train: loss: 0.0125483
[Epoch 53; Iter   210/  960] train: loss: 0.0174733
[Epoch 53; Iter   240/  960] train: loss: 0.0080177
[Epoch 53; Iter   270/  960] train: loss: 0.0620352
[Epoch 53; Iter   300/  960] train: loss: 0.0168884
[Epoch 53; Iter   330/  960] train: loss: 0.0067322
[Epoch 53; Iter   360/  960] train: loss: 0.0932716
[Epoch 53; Iter   390/  960] train: loss: 0.0742794
[Epoch 53; Iter   420/  960] train: loss: 0.1528358
[Epoch 53; Iter   450/  960] train: loss: 0.1187870
[Epoch 53; Iter   480/  960] train: loss: 0.0279802
[Epoch 53; Iter   510/  960] train: loss: 0.0046123
[Epoch 53; Iter   540/  960] train: loss: 0.0089322
[Epoch 53; Iter   570/  960] train: loss: 0.0214139
[Epoch 53; Iter   600/  960] train: loss: 0.0651973
[Epoch 53; Iter   630/  960] train: loss: 0.0064108
[Epoch 53; Iter   660/  960] train: loss: 0.0849616
[Epoch 53; Iter   690/  960] train: loss: 0.1142129
[Epoch 53; Iter   720/  960] train: loss: 0.0210650
[Epoch 53; Iter   750/  960] train: loss: 0.0388317
[Epoch 53; Iter   780/  960] train: loss: 0.1404435
[Epoch 53; Iter   810/  960] train: loss: 0.0120655
[Epoch 53; Iter   840/  960] train: loss: 0.0111358
[Epoch 53; Iter   870/  960] train: loss: 0.0598057
[Epoch 53; Iter   900/  960] train: loss: 0.0325980
[Epoch 53; Iter   930/  960] train: loss: 0.0917405
[Epoch 53; Iter   960/  960] train: loss: 0.0044937
[Epoch 53] ogbg-molhiv: 0.815998 val loss: 0.158840
[Epoch 53] ogbg-molhiv: 0.803411 test loss: 0.156646
[Epoch 54; Iter    30/  960] train: loss: 0.0874567
[Epoch 54; Iter    60/  960] train: loss: 0.0357460
[Epoch 54; Iter    90/  960] train: loss: 0.0220796
[Epoch 54; Iter   120/  960] train: loss: 0.1943067
[Epoch 54; Iter   150/  960] train: loss: 0.0111740
[Epoch 54; Iter   180/  960] train: loss: 0.1288458
[Epoch 54; Iter   210/  960] train: loss: 0.0768925
[Epoch 54; Iter   240/  960] train: loss: 0.0062812
[Epoch 54; Iter   270/  960] train: loss: 0.1237688
[Epoch 54; Iter   300/  960] train: loss: 0.0247809
[Epoch 54; Iter   330/  960] train: loss: 0.0850487
[Epoch 54; Iter   360/  960] train: loss: 0.0395898
[Epoch 54; Iter   390/  960] train: loss: 0.0038601
[Epoch 54; Iter   420/  960] train: loss: 0.0107957
[Epoch 54; Iter   450/  960] train: loss: 0.0096988
[Epoch 54; Iter   480/  960] train: loss: 0.0299075
[Epoch 54; Iter   510/  960] train: loss: 0.0131883
[Epoch 54; Iter   540/  960] train: loss: 0.0195234
[Epoch 54; Iter   570/  960] train: loss: 0.0696717
[Epoch 54; Iter   600/  960] train: loss: 0.0534962
[Epoch 54; Iter   630/  960] train: loss: 0.0116283
[Epoch 54; Iter   660/  960] train: loss: 0.0152476
[Epoch 54; Iter   690/  960] train: loss: 0.0926587
[Epoch 54; Iter   720/  960] train: loss: 0.0413151
[Epoch 54; Iter   750/  960] train: loss: 0.0242629
[Epoch 54; Iter   780/  960] train: loss: 0.0098794
[Epoch 54; Iter   810/  960] train: loss: 0.0058630
[Epoch 54; Iter   840/  960] train: loss: 0.0116768
[Epoch 54; Iter   870/  960] train: loss: 0.0103260
[Epoch 54; Iter   900/  960] train: loss: 0.0465059
[Epoch 54; Iter   930/  960] train: loss: 0.0766205
[Epoch 54; Iter   960/  960] train: loss: 0.0730825
[Epoch 54] ogbg-molhiv: 0.820720 val loss: 0.157923
[Epoch 54] ogbg-molhiv: 0.808424 test loss: 0.149512
[Epoch 55; Iter    30/  960] train: loss: 0.0443807
[Epoch 55; Iter    60/  960] train: loss: 0.0393208
[Epoch 55; Iter    90/  960] train: loss: 0.0286913
[Epoch 55; Iter   120/  960] train: loss: 0.0241950
[Epoch 55; Iter   150/  960] train: loss: 0.0974113
[Epoch 50; Iter   570/  960] train: loss: 0.0154214
[Epoch 50; Iter   600/  960] train: loss: 0.0119873
[Epoch 50; Iter   630/  960] train: loss: 0.1237978
[Epoch 50; Iter   660/  960] train: loss: 0.1013226
[Epoch 50; Iter   690/  960] train: loss: 0.0491336
[Epoch 50; Iter   720/  960] train: loss: 0.0065175
[Epoch 50; Iter   750/  960] train: loss: 0.0292026
[Epoch 50; Iter   780/  960] train: loss: 0.0168666
[Epoch 50; Iter   810/  960] train: loss: 0.1000373
[Epoch 50; Iter   840/  960] train: loss: 0.0067436
[Epoch 50; Iter   870/  960] train: loss: 0.0342467
[Epoch 50; Iter   900/  960] train: loss: 0.0243608
[Epoch 50; Iter   930/  960] train: loss: 0.0469009
[Epoch 50; Iter   960/  960] train: loss: 0.0283740
[Epoch 50] ogbg-molhiv: 0.796232 val loss: 0.162303
[Epoch 50] ogbg-molhiv: 0.800336 test loss: 0.158319
[Epoch 51; Iter    30/  960] train: loss: 0.2597193
[Epoch 51; Iter    60/  960] train: loss: 0.0150396
[Epoch 51; Iter    90/  960] train: loss: 0.0303005
[Epoch 51; Iter   120/  960] train: loss: 0.0509566
[Epoch 51; Iter   150/  960] train: loss: 0.1434378
[Epoch 51; Iter   180/  960] train: loss: 0.0094673
[Epoch 51; Iter   210/  960] train: loss: 0.0146160
[Epoch 51; Iter   240/  960] train: loss: 0.0790782
[Epoch 51; Iter   270/  960] train: loss: 0.0058082
[Epoch 51; Iter   300/  960] train: loss: 0.0262656
[Epoch 51; Iter   330/  960] train: loss: 0.0140270
[Epoch 51; Iter   360/  960] train: loss: 0.0076968
[Epoch 51; Iter   390/  960] train: loss: 0.0093989
[Epoch 51; Iter   420/  960] train: loss: 0.0107708
[Epoch 51; Iter   450/  960] train: loss: 0.0205731
[Epoch 51; Iter   480/  960] train: loss: 0.2055719
[Epoch 51; Iter   510/  960] train: loss: 0.1343091
[Epoch 51; Iter   540/  960] train: loss: 0.0248250
[Epoch 51; Iter   570/  960] train: loss: 0.0548935
[Epoch 51; Iter   600/  960] train: loss: 0.0187725
[Epoch 51; Iter   630/  960] train: loss: 0.0883858
[Epoch 51; Iter   660/  960] train: loss: 0.0039283
[Epoch 51; Iter   690/  960] train: loss: 0.0527992
[Epoch 51; Iter   720/  960] train: loss: 0.0490479
[Epoch 51; Iter   750/  960] train: loss: 0.0245316
[Epoch 51; Iter   780/  960] train: loss: 0.0852073
[Epoch 51; Iter   810/  960] train: loss: 0.0293490
[Epoch 51; Iter   840/  960] train: loss: 0.1306670
[Epoch 51; Iter   870/  960] train: loss: 0.0322357
[Epoch 51; Iter   900/  960] train: loss: 0.0125025
[Epoch 51; Iter   930/  960] train: loss: 0.0180032
[Epoch 51; Iter   960/  960] train: loss: 0.0108049
[Epoch 51] ogbg-molhiv: 0.782540 val loss: 0.217038
[Epoch 51] ogbg-molhiv: 0.810341 test loss: 0.164303
[Epoch 52; Iter    30/  960] train: loss: 0.0050770
[Epoch 52; Iter    60/  960] train: loss: 0.1397097
[Epoch 52; Iter    90/  960] train: loss: 0.1255049
[Epoch 52; Iter   120/  960] train: loss: 0.0153779
[Epoch 52; Iter   150/  960] train: loss: 0.1500471
[Epoch 52; Iter   180/  960] train: loss: 0.0151974
[Epoch 52; Iter   210/  960] train: loss: 0.1994614
[Epoch 52; Iter   240/  960] train: loss: 0.0154179
[Epoch 52; Iter   270/  960] train: loss: 0.0113287
[Epoch 52; Iter   300/  960] train: loss: 0.1083867
[Epoch 52; Iter   330/  960] train: loss: 0.0826076
[Epoch 52; Iter   360/  960] train: loss: 0.0607194
[Epoch 52; Iter   390/  960] train: loss: 0.0179725
[Epoch 52; Iter   420/  960] train: loss: 0.0322652
[Epoch 52; Iter   450/  960] train: loss: 0.0405343
[Epoch 52; Iter   480/  960] train: loss: 0.0598251
[Epoch 52; Iter   510/  960] train: loss: 0.0911827
[Epoch 52; Iter   540/  960] train: loss: 0.0357554
[Epoch 52; Iter   570/  960] train: loss: 0.0113201
[Epoch 52; Iter   600/  960] train: loss: 0.0148731
[Epoch 52; Iter   630/  960] train: loss: 0.0689883
[Epoch 52; Iter   660/  960] train: loss: 0.0188703
[Epoch 52; Iter   690/  960] train: loss: 0.0105907
[Epoch 52; Iter   720/  960] train: loss: 0.0195037
[Epoch 52; Iter   750/  960] train: loss: 0.0191240
[Epoch 52; Iter   780/  960] train: loss: 0.0273306
[Epoch 52; Iter   810/  960] train: loss: 0.0507347
[Epoch 52; Iter   840/  960] train: loss: 0.2275954
[Epoch 52; Iter   870/  960] train: loss: 0.0363569
[Epoch 52; Iter   900/  960] train: loss: 0.0196421
[Epoch 52; Iter   930/  960] train: loss: 0.0170287
[Epoch 52; Iter   960/  960] train: loss: 0.0120949
[Epoch 52] ogbg-molhiv: 0.806578 val loss: 0.180651
[Epoch 52] ogbg-molhiv: 0.813764 test loss: 0.183781
[Epoch 53; Iter    30/  960] train: loss: 0.0882307
[Epoch 53; Iter    60/  960] train: loss: 0.0674429
[Epoch 53; Iter    90/  960] train: loss: 0.0077223
[Epoch 53; Iter   120/  960] train: loss: 0.0832688
[Epoch 53; Iter   150/  960] train: loss: 0.0076304
[Epoch 53; Iter   180/  960] train: loss: 0.0223659
[Epoch 53; Iter   210/  960] train: loss: 0.0066116
[Epoch 53; Iter   240/  960] train: loss: 0.1936730
[Epoch 53; Iter   270/  960] train: loss: 0.0345276
[Epoch 53; Iter   300/  960] train: loss: 0.0921118
[Epoch 53; Iter   330/  960] train: loss: 0.0132281
[Epoch 53; Iter   360/  960] train: loss: 0.1627004
[Epoch 53; Iter   390/  960] train: loss: 0.0046143
[Epoch 53; Iter   420/  960] train: loss: 0.0822861
[Epoch 53; Iter   450/  960] train: loss: 0.0317236
[Epoch 53; Iter   480/  960] train: loss: 0.0269855
[Epoch 53; Iter   510/  960] train: loss: 0.0266282
[Epoch 53; Iter   540/  960] train: loss: 0.0670824
[Epoch 53; Iter   570/  960] train: loss: 0.0199900
[Epoch 53; Iter   600/  960] train: loss: 0.0215725
[Epoch 53; Iter   630/  960] train: loss: 0.2142050
[Epoch 53; Iter   660/  960] train: loss: 0.1373840
[Epoch 53; Iter   690/  960] train: loss: 0.1853368
[Epoch 53; Iter   720/  960] train: loss: 0.0434993
[Epoch 53; Iter   750/  960] train: loss: 0.0094996
[Epoch 53; Iter   780/  960] train: loss: 0.0112498
[Epoch 53; Iter   810/  960] train: loss: 0.0954324
[Epoch 53; Iter   840/  960] train: loss: 0.0754943
[Epoch 53; Iter   870/  960] train: loss: 0.0436535
[Epoch 53; Iter   900/  960] train: loss: 0.1597849
[Epoch 53; Iter   930/  960] train: loss: 0.0171039
[Epoch 53; Iter   960/  960] train: loss: 0.0235668
[Epoch 53] ogbg-molhiv: 0.812006 val loss: 0.163044
[Epoch 53] ogbg-molhiv: 0.820152 test loss: 0.201195
[Epoch 54; Iter    30/  960] train: loss: 0.0115594
[Epoch 54; Iter    60/  960] train: loss: 0.0087132
[Epoch 54; Iter    90/  960] train: loss: 0.0053590
[Epoch 54; Iter   120/  960] train: loss: 0.0081429
[Epoch 54; Iter   150/  960] train: loss: 0.0908511
[Epoch 54; Iter   180/  960] train: loss: 0.0197105
[Epoch 54; Iter   210/  960] train: loss: 0.0250997
[Epoch 54; Iter   240/  960] train: loss: 0.0190993
[Epoch 54; Iter   270/  960] train: loss: 0.0067186
[Epoch 54; Iter   300/  960] train: loss: 0.0414179
[Epoch 54; Iter   330/  960] train: loss: 0.0209893
[Epoch 54; Iter   360/  960] train: loss: 0.0054218
[Epoch 54; Iter   390/  960] train: loss: 0.0114996
[Epoch 54; Iter   420/  960] train: loss: 0.1710094
[Epoch 54; Iter   450/  960] train: loss: 0.0148759
[Epoch 54; Iter   480/  960] train: loss: 0.1653214
[Epoch 54; Iter   510/  960] train: loss: 0.0635298
[Epoch 54; Iter   540/  960] train: loss: 0.0237514
[Epoch 54; Iter   570/  960] train: loss: 0.2063974
[Epoch 54; Iter   600/  960] train: loss: 0.0885555
[Epoch 54; Iter   630/  960] train: loss: 0.0497601
[Epoch 54; Iter   660/  960] train: loss: 0.0963088
[Epoch 54; Iter   690/  960] train: loss: 0.0128780
[Epoch 54; Iter   720/  960] train: loss: 0.0045951
[Epoch 54; Iter   750/  960] train: loss: 0.0052688
[Epoch 54; Iter   780/  960] train: loss: 0.0447543
[Epoch 54; Iter   810/  960] train: loss: 0.0502734
[Epoch 54; Iter   840/  960] train: loss: 0.0472266
[Epoch 54; Iter   870/  960] train: loss: 0.0061364
[Epoch 54; Iter   900/  960] train: loss: 0.0145064
[Epoch 54; Iter   930/  960] train: loss: 0.1249127
[Epoch 54; Iter   960/  960] train: loss: 0.0153754
[Epoch 54] ogbg-molhiv: 0.801489 val loss: 0.175487
[Epoch 54] ogbg-molhiv: 0.821341 test loss: 0.202610
[Epoch 55; Iter    30/  960] train: loss: 0.0693252
[Epoch 55; Iter    60/  960] train: loss: 0.0176586
[Epoch 55; Iter    90/  960] train: loss: 0.0508691
[Epoch 55; Iter   120/  960] train: loss: 0.0198709
[Epoch 55; Iter   150/  960] train: loss: 0.0954933
[Epoch 52; Iter   777/  823] train: loss: 0.0140341
[Epoch 52; Iter   807/  823] train: loss: 0.0260135
[Epoch 52] ogbg-molhiv: 0.821286 val loss: 0.146502
[Epoch 52] ogbg-molhiv: 0.808949 test loss: 0.146025
[Epoch 53; Iter    14/  823] train: loss: 0.0295733
[Epoch 53; Iter    44/  823] train: loss: 0.0104673
[Epoch 53; Iter    74/  823] train: loss: 0.0258693
[Epoch 53; Iter   104/  823] train: loss: 0.0839887
[Epoch 53; Iter   134/  823] train: loss: 0.1900450
[Epoch 53; Iter   164/  823] train: loss: 0.0138828
[Epoch 53; Iter   194/  823] train: loss: 0.0276466
[Epoch 53; Iter   224/  823] train: loss: 0.0230047
[Epoch 53; Iter   254/  823] train: loss: 0.0258231
[Epoch 53; Iter   284/  823] train: loss: 0.1469071
[Epoch 53; Iter   314/  823] train: loss: 0.0438528
[Epoch 53; Iter   344/  823] train: loss: 0.0865876
[Epoch 53; Iter   374/  823] train: loss: 0.0280074
[Epoch 53; Iter   404/  823] train: loss: 0.0573875
[Epoch 53; Iter   434/  823] train: loss: 0.0406568
[Epoch 53; Iter   464/  823] train: loss: 0.0229149
[Epoch 53; Iter   494/  823] train: loss: 0.1099275
[Epoch 53; Iter   524/  823] train: loss: 0.0486617
[Epoch 53; Iter   554/  823] train: loss: 0.0180443
[Epoch 53; Iter   584/  823] train: loss: 0.0387810
[Epoch 53; Iter   614/  823] train: loss: 0.0208175
[Epoch 53; Iter   644/  823] train: loss: 0.1325268
[Epoch 53; Iter   674/  823] train: loss: 0.0749475
[Epoch 53; Iter   704/  823] train: loss: 0.1015879
[Epoch 53; Iter   734/  823] train: loss: 0.0170261
[Epoch 53; Iter   764/  823] train: loss: 0.0184655
[Epoch 53; Iter   794/  823] train: loss: 0.0617094
[Epoch 53] ogbg-molhiv: 0.837752 val loss: 0.230050
[Epoch 53] ogbg-molhiv: 0.799276 test loss: 0.169024
[Epoch 54; Iter     1/  823] train: loss: 0.0145035
[Epoch 54; Iter    31/  823] train: loss: 0.0433641
[Epoch 54; Iter    61/  823] train: loss: 0.0131875
[Epoch 54; Iter    91/  823] train: loss: 0.0352192
[Epoch 54; Iter   121/  823] train: loss: 0.0164180
[Epoch 54; Iter   151/  823] train: loss: 0.0110422
[Epoch 54; Iter   181/  823] train: loss: 0.0996681
[Epoch 54; Iter   211/  823] train: loss: 0.0690424
[Epoch 54; Iter   241/  823] train: loss: 0.0366231
[Epoch 54; Iter   271/  823] train: loss: 0.0675310
[Epoch 54; Iter   301/  823] train: loss: 0.0130174
[Epoch 54; Iter   331/  823] train: loss: 0.0198425
[Epoch 54; Iter   361/  823] train: loss: 0.1209877
[Epoch 54; Iter   391/  823] train: loss: 0.0143717
[Epoch 54; Iter   421/  823] train: loss: 0.0207403
[Epoch 54; Iter   451/  823] train: loss: 0.0194763
[Epoch 54; Iter   481/  823] train: loss: 0.0233776
[Epoch 54; Iter   511/  823] train: loss: 0.0347410
[Epoch 54; Iter   541/  823] train: loss: 0.3006544
[Epoch 54; Iter   571/  823] train: loss: 0.0196710
[Epoch 54; Iter   601/  823] train: loss: 0.0356429
[Epoch 54; Iter   631/  823] train: loss: 0.0112739
[Epoch 54; Iter   661/  823] train: loss: 0.1273792
[Epoch 54; Iter   691/  823] train: loss: 0.0469725
[Epoch 54; Iter   721/  823] train: loss: 0.0081296
[Epoch 54; Iter   751/  823] train: loss: 0.0163920
[Epoch 54; Iter   781/  823] train: loss: 0.1841213
[Epoch 54; Iter   811/  823] train: loss: 0.1790374
[Epoch 54] ogbg-molhiv: 0.826898 val loss: 0.224057
[Epoch 54] ogbg-molhiv: 0.800756 test loss: 0.197815
[Epoch 55; Iter    18/  823] train: loss: 0.0089103
[Epoch 55; Iter    48/  823] train: loss: 0.0105170
[Epoch 55; Iter    78/  823] train: loss: 0.0817410
[Epoch 55; Iter   108/  823] train: loss: 0.0308590
[Epoch 55; Iter   138/  823] train: loss: 0.0208753
[Epoch 55; Iter   168/  823] train: loss: 0.0080391
[Epoch 55; Iter   198/  823] train: loss: 0.0215928
[Epoch 55; Iter   228/  823] train: loss: 0.0132005
[Epoch 55; Iter   258/  823] train: loss: 0.1876540
[Epoch 55; Iter   288/  823] train: loss: 0.0237619
[Epoch 55; Iter   318/  823] train: loss: 0.0399255
[Epoch 55; Iter   348/  823] train: loss: 0.0120182
[Epoch 55; Iter   378/  823] train: loss: 0.1287722
[Epoch 55; Iter   408/  823] train: loss: 0.0194060
[Epoch 55; Iter   438/  823] train: loss: 0.0240614
[Epoch 55; Iter   468/  823] train: loss: 0.0155569
[Epoch 55; Iter   498/  823] train: loss: 0.0266097
[Epoch 55; Iter   528/  823] train: loss: 0.2860348
[Epoch 55; Iter   558/  823] train: loss: 0.0210759
[Epoch 55; Iter   588/  823] train: loss: 0.0435129
[Epoch 55; Iter   618/  823] train: loss: 0.0166727
[Epoch 55; Iter   648/  823] train: loss: 0.0160899
[Epoch 55; Iter   678/  823] train: loss: 0.0622983
[Epoch 55; Iter   708/  823] train: loss: 0.1045927
[Epoch 55; Iter   738/  823] train: loss: 0.0161606
[Epoch 55; Iter   768/  823] train: loss: 0.0156277
[Epoch 55; Iter   798/  823] train: loss: 0.0055641
[Epoch 55] ogbg-molhiv: 0.839307 val loss: 0.190153
[Epoch 55] ogbg-molhiv: 0.804573 test loss: 0.200067
[Epoch 56; Iter     5/  823] train: loss: 0.0125798
[Epoch 56; Iter    35/  823] train: loss: 0.1079587
[Epoch 56; Iter    65/  823] train: loss: 0.1617884
[Epoch 56; Iter    95/  823] train: loss: 0.0110957
[Epoch 56; Iter   125/  823] train: loss: 0.0374637
[Epoch 56; Iter   155/  823] train: loss: 0.1133212
[Epoch 56; Iter   185/  823] train: loss: 0.0615255
[Epoch 56; Iter   215/  823] train: loss: 0.0489633
[Epoch 56; Iter   245/  823] train: loss: 0.0412513
[Epoch 56; Iter   275/  823] train: loss: 0.0301745
[Epoch 56; Iter   305/  823] train: loss: 0.0136285
[Epoch 56; Iter   335/  823] train: loss: 0.0064361
[Epoch 56; Iter   365/  823] train: loss: 0.0768497
[Epoch 56; Iter   395/  823] train: loss: 0.0867342
[Epoch 56; Iter   425/  823] train: loss: 0.0153497
[Epoch 56; Iter   455/  823] train: loss: 0.0100692
[Epoch 56; Iter   485/  823] train: loss: 0.0589227
[Epoch 56; Iter   515/  823] train: loss: 0.0348152
[Epoch 56; Iter   545/  823] train: loss: 0.0228201
[Epoch 56; Iter   575/  823] train: loss: 0.0068412
[Epoch 56; Iter   605/  823] train: loss: 0.0406202
[Epoch 56; Iter   635/  823] train: loss: 0.0109750
[Epoch 56; Iter   665/  823] train: loss: 0.0482907
[Epoch 56; Iter   695/  823] train: loss: 0.0132523
[Epoch 56; Iter   725/  823] train: loss: 0.0456701
[Epoch 56; Iter   755/  823] train: loss: 0.0827738
[Epoch 56; Iter   785/  823] train: loss: 0.2899511
[Epoch 56; Iter   815/  823] train: loss: 0.1347410
[Epoch 56] ogbg-molhiv: 0.832693 val loss: 0.163116
[Epoch 56] ogbg-molhiv: 0.809975 test loss: 0.194629
[Epoch 57; Iter    22/  823] train: loss: 0.0426699
[Epoch 57; Iter    52/  823] train: loss: 0.0236115
[Epoch 57; Iter    82/  823] train: loss: 0.0311994
[Epoch 57; Iter   112/  823] train: loss: 0.0164029
[Epoch 57; Iter   142/  823] train: loss: 0.0077905
[Epoch 57; Iter   172/  823] train: loss: 0.0306939
[Epoch 57; Iter   202/  823] train: loss: 0.0273294
[Epoch 57; Iter   232/  823] train: loss: 0.0433897
[Epoch 57; Iter   262/  823] train: loss: 0.0411798
[Epoch 57; Iter   292/  823] train: loss: 0.1477855
[Epoch 57; Iter   322/  823] train: loss: 0.0669719
[Epoch 57; Iter   352/  823] train: loss: 0.0449626
[Epoch 57; Iter   382/  823] train: loss: 0.1254279
[Epoch 57; Iter   412/  823] train: loss: 0.0449871
[Epoch 57; Iter   442/  823] train: loss: 0.0224887
[Epoch 57; Iter   472/  823] train: loss: 0.0085520
[Epoch 57; Iter   502/  823] train: loss: 0.1340579
[Epoch 57; Iter   532/  823] train: loss: 0.0109689
[Epoch 57; Iter   562/  823] train: loss: 0.0327591
[Epoch 57; Iter   592/  823] train: loss: 0.0047603
[Epoch 57; Iter   622/  823] train: loss: 0.0538987
[Epoch 57; Iter   652/  823] train: loss: 0.2111286
[Epoch 57; Iter   682/  823] train: loss: 0.0129504
[Epoch 57; Iter   712/  823] train: loss: 0.0613323
[Epoch 57; Iter   742/  823] train: loss: 0.3247637
[Epoch 57; Iter   772/  823] train: loss: 0.0308575
[Epoch 57; Iter   802/  823] train: loss: 0.1336775
[Epoch 57] ogbg-molhiv: 0.832024 val loss: 0.161376
[Epoch 57] ogbg-molhiv: 0.807014 test loss: 0.211505
[Epoch 58; Iter     9/  823] train: loss: 0.0129173
[Epoch 58; Iter    39/  823] train: loss: 0.0407661
[Epoch 58; Iter    69/  823] train: loss: 0.0076252
[Epoch 58; Iter    99/  823] train: loss: 0.0052872
[Epoch 58; Iter   129/  823] train: loss: 0.0317761
[Epoch 58; Iter   159/  823] train: loss: 0.0230605
[Epoch 52; Iter   777/  823] train: loss: 0.0072124
[Epoch 52; Iter   807/  823] train: loss: 0.2280157
[Epoch 52] ogbg-molhiv: 0.828288 val loss: 0.141527
[Epoch 52] ogbg-molhiv: 0.789309 test loss: 0.182231
[Epoch 53; Iter    14/  823] train: loss: 0.2573361
[Epoch 53; Iter    44/  823] train: loss: 0.0633374
[Epoch 53; Iter    74/  823] train: loss: 0.0910068
[Epoch 53; Iter   104/  823] train: loss: 0.0774936
[Epoch 53; Iter   134/  823] train: loss: 0.0200627
[Epoch 53; Iter   164/  823] train: loss: 0.0107095
[Epoch 53; Iter   194/  823] train: loss: 0.0079994
[Epoch 53; Iter   224/  823] train: loss: 0.1300846
[Epoch 53; Iter   254/  823] train: loss: 0.0136700
[Epoch 53; Iter   284/  823] train: loss: 0.0512488
[Epoch 53; Iter   314/  823] train: loss: 0.0081647
[Epoch 53; Iter   344/  823] train: loss: 0.0159843
[Epoch 53; Iter   374/  823] train: loss: 0.0157834
[Epoch 53; Iter   404/  823] train: loss: 0.1461918
[Epoch 53; Iter   434/  823] train: loss: 0.0545072
[Epoch 53; Iter   464/  823] train: loss: 0.0076353
[Epoch 53; Iter   494/  823] train: loss: 0.0401455
[Epoch 53; Iter   524/  823] train: loss: 0.0212978
[Epoch 53; Iter   554/  823] train: loss: 0.0977235
[Epoch 53; Iter   584/  823] train: loss: 0.0858250
[Epoch 53; Iter   614/  823] train: loss: 0.0075139
[Epoch 53; Iter   644/  823] train: loss: 0.0397700
[Epoch 53; Iter   674/  823] train: loss: 0.0264247
[Epoch 53; Iter   704/  823] train: loss: 0.2260355
[Epoch 53; Iter   734/  823] train: loss: 0.0228235
[Epoch 53; Iter   764/  823] train: loss: 0.0560483
[Epoch 53; Iter   794/  823] train: loss: 0.0485114
[Epoch 53] ogbg-molhiv: 0.830749 val loss: 0.127960
[Epoch 53] ogbg-molhiv: 0.817945 test loss: 0.151760
[Epoch 54; Iter     1/  823] train: loss: 0.0788570
[Epoch 54; Iter    31/  823] train: loss: 0.1407122
[Epoch 54; Iter    61/  823] train: loss: 0.0402107
[Epoch 54; Iter    91/  823] train: loss: 0.0331036
[Epoch 54; Iter   121/  823] train: loss: 0.0246698
[Epoch 54; Iter   151/  823] train: loss: 0.1997993
[Epoch 54; Iter   181/  823] train: loss: 0.0663187
[Epoch 54; Iter   211/  823] train: loss: 0.0144334
[Epoch 54; Iter   241/  823] train: loss: 0.0090091
[Epoch 54; Iter   271/  823] train: loss: 0.0856480
[Epoch 54; Iter   301/  823] train: loss: 0.0917822
[Epoch 54; Iter   331/  823] train: loss: 0.0179392
[Epoch 54; Iter   361/  823] train: loss: 0.0173386
[Epoch 54; Iter   391/  823] train: loss: 0.0630984
[Epoch 54; Iter   421/  823] train: loss: 0.0229278
[Epoch 54; Iter   451/  823] train: loss: 0.0183337
[Epoch 54; Iter   481/  823] train: loss: 0.0897380
[Epoch 54; Iter   511/  823] train: loss: 0.0523995
[Epoch 54; Iter   541/  823] train: loss: 0.0101371
[Epoch 54; Iter   571/  823] train: loss: 0.0648485
[Epoch 54; Iter   601/  823] train: loss: 0.1188861
[Epoch 54; Iter   631/  823] train: loss: 0.0128349
[Epoch 54; Iter   661/  823] train: loss: 0.0306892
[Epoch 54; Iter   691/  823] train: loss: 0.0052706
[Epoch 54; Iter   721/  823] train: loss: 0.0060606
[Epoch 54; Iter   751/  823] train: loss: 0.0417731
[Epoch 54; Iter   781/  823] train: loss: 0.0929497
[Epoch 54; Iter   811/  823] train: loss: 0.0062289
[Epoch 54] ogbg-molhiv: 0.826110 val loss: 0.210709
[Epoch 54] ogbg-molhiv: 0.807889 test loss: 0.254500
[Epoch 55; Iter    18/  823] train: loss: 0.0047643
[Epoch 55; Iter    48/  823] train: loss: 0.0236419
[Epoch 55; Iter    78/  823] train: loss: 0.0063186
[Epoch 55; Iter   108/  823] train: loss: 0.0745111
[Epoch 55; Iter   138/  823] train: loss: 0.0223021
[Epoch 55; Iter   168/  823] train: loss: 0.1014432
[Epoch 55; Iter   198/  823] train: loss: 0.0453995
[Epoch 55; Iter   228/  823] train: loss: 0.0495270
[Epoch 55; Iter   258/  823] train: loss: 0.0205129
[Epoch 55; Iter   288/  823] train: loss: 0.0108571
[Epoch 55; Iter   318/  823] train: loss: 0.0151335
[Epoch 55; Iter   348/  823] train: loss: 0.0823907
[Epoch 55; Iter   378/  823] train: loss: 0.0093849
[Epoch 55; Iter   408/  823] train: loss: 0.1875508
[Epoch 55; Iter   438/  823] train: loss: 0.0615854
[Epoch 55; Iter   468/  823] train: loss: 0.0473244
[Epoch 55; Iter   498/  823] train: loss: 0.0192822
[Epoch 55; Iter   528/  823] train: loss: 0.1212208
[Epoch 55; Iter   558/  823] train: loss: 0.0563350
[Epoch 55; Iter   588/  823] train: loss: 0.0196284
[Epoch 55; Iter   618/  823] train: loss: 0.0082831
[Epoch 55; Iter   648/  823] train: loss: 0.0938255
[Epoch 55; Iter   678/  823] train: loss: 0.1663157
[Epoch 55; Iter   708/  823] train: loss: 0.0439562
[Epoch 55; Iter   738/  823] train: loss: 0.0293242
[Epoch 55; Iter   768/  823] train: loss: 0.0114057
[Epoch 55; Iter   798/  823] train: loss: 0.1638786
[Epoch 55] ogbg-molhiv: 0.833594 val loss: 0.162499
[Epoch 55] ogbg-molhiv: 0.807153 test loss: 0.164909
[Epoch 56; Iter     5/  823] train: loss: 0.0116341
[Epoch 56; Iter    35/  823] train: loss: 0.0845386
[Epoch 56; Iter    65/  823] train: loss: 0.0103068
[Epoch 56; Iter    95/  823] train: loss: 0.0145306
[Epoch 56; Iter   125/  823] train: loss: 0.0546861
[Epoch 56; Iter   155/  823] train: loss: 0.1707418
[Epoch 56; Iter   185/  823] train: loss: 0.0776501
[Epoch 56; Iter   215/  823] train: loss: 0.0157144
[Epoch 56; Iter   245/  823] train: loss: 0.0411971
[Epoch 56; Iter   275/  823] train: loss: 0.0804394
[Epoch 56; Iter   305/  823] train: loss: 0.1084474
[Epoch 56; Iter   335/  823] train: loss: 0.0048508
[Epoch 56; Iter   365/  823] train: loss: 0.0306910
[Epoch 56; Iter   395/  823] train: loss: 0.0158414
[Epoch 56; Iter   425/  823] train: loss: 0.0188308
[Epoch 56; Iter   455/  823] train: loss: 0.0367256
[Epoch 56; Iter   485/  823] train: loss: 0.0365286
[Epoch 56; Iter   515/  823] train: loss: 0.0391543
[Epoch 56; Iter   545/  823] train: loss: 0.0083358
[Epoch 56; Iter   575/  823] train: loss: 0.0127386
[Epoch 56; Iter   605/  823] train: loss: 0.0200700
[Epoch 56; Iter   635/  823] train: loss: 0.0288515
[Epoch 56; Iter   665/  823] train: loss: 0.0299170
[Epoch 56; Iter   695/  823] train: loss: 0.0160813
[Epoch 56; Iter   725/  823] train: loss: 0.1072965
[Epoch 56; Iter   755/  823] train: loss: 0.0142788
[Epoch 56; Iter   785/  823] train: loss: 0.0658634
[Epoch 56; Iter   815/  823] train: loss: 0.0163611
[Epoch 56] ogbg-molhiv: 0.840802 val loss: 0.210811
[Epoch 56] ogbg-molhiv: 0.818897 test loss: 0.150513
[Epoch 57; Iter    22/  823] train: loss: 0.0411855
[Epoch 57; Iter    52/  823] train: loss: 0.0160387
[Epoch 57; Iter    82/  823] train: loss: 0.0717455
[Epoch 57; Iter   112/  823] train: loss: 0.0189210
[Epoch 57; Iter   142/  823] train: loss: 0.0060638
[Epoch 57; Iter   172/  823] train: loss: 0.0322500
[Epoch 57; Iter   202/  823] train: loss: 0.0071483
[Epoch 57; Iter   232/  823] train: loss: 0.0039896
[Epoch 57; Iter   262/  823] train: loss: 0.0923383
[Epoch 57; Iter   292/  823] train: loss: 0.0345592
[Epoch 57; Iter   322/  823] train: loss: 0.1774998
[Epoch 57; Iter   352/  823] train: loss: 0.0242218
[Epoch 57; Iter   382/  823] train: loss: 0.1078297
[Epoch 57; Iter   412/  823] train: loss: 0.0650608
[Epoch 57; Iter   442/  823] train: loss: 0.1093368
[Epoch 57; Iter   472/  823] train: loss: 0.0079420
[Epoch 57; Iter   502/  823] train: loss: 0.0642647
[Epoch 57; Iter   532/  823] train: loss: 0.1015389
[Epoch 57; Iter   562/  823] train: loss: 0.0339576
[Epoch 57; Iter   592/  823] train: loss: 0.0097420
[Epoch 57; Iter   622/  823] train: loss: 0.0059307
[Epoch 57; Iter   652/  823] train: loss: 0.0219872
[Epoch 57; Iter   682/  823] train: loss: 0.0074853
[Epoch 57; Iter   712/  823] train: loss: 0.0087144
[Epoch 57; Iter   742/  823] train: loss: 0.0121313
[Epoch 57; Iter   772/  823] train: loss: 0.0226154
[Epoch 57; Iter   802/  823] train: loss: 0.0289530
[Epoch 57] ogbg-molhiv: 0.832863 val loss: 0.158584
[Epoch 57] ogbg-molhiv: 0.811925 test loss: 0.152552
[Epoch 58; Iter     9/  823] train: loss: 0.0530462
[Epoch 58; Iter    39/  823] train: loss: 0.0077943
[Epoch 58; Iter    69/  823] train: loss: 0.0315054
[Epoch 58; Iter    99/  823] train: loss: 0.0227455
[Epoch 58; Iter   129/  823] train: loss: 0.0162553
[Epoch 58; Iter   159/  823] train: loss: 0.0103781
[Epoch 52; Iter   777/  823] train: loss: 0.0349732
[Epoch 52; Iter   807/  823] train: loss: 0.0988932
[Epoch 52] ogbg-molhiv: 0.821045 val loss: 0.269259
[Epoch 52] ogbg-molhiv: 0.797803 test loss: 0.390887
[Epoch 53; Iter    14/  823] train: loss: 0.0319813
[Epoch 53; Iter    44/  823] train: loss: 0.0379566
[Epoch 53; Iter    74/  823] train: loss: 0.0409729
[Epoch 53; Iter   104/  823] train: loss: 0.1392352
[Epoch 53; Iter   134/  823] train: loss: 0.0125093
[Epoch 53; Iter   164/  823] train: loss: 0.0115295
[Epoch 53; Iter   194/  823] train: loss: 0.0438188
[Epoch 53; Iter   224/  823] train: loss: 0.0247516
[Epoch 53; Iter   254/  823] train: loss: 0.0275739
[Epoch 53; Iter   284/  823] train: loss: 0.0439789
[Epoch 53; Iter   314/  823] train: loss: 0.0461870
[Epoch 53; Iter   344/  823] train: loss: 0.0415606
[Epoch 53; Iter   374/  823] train: loss: 0.0121647
[Epoch 53; Iter   404/  823] train: loss: 0.0355684
[Epoch 53; Iter   434/  823] train: loss: 0.0348284
[Epoch 53; Iter   464/  823] train: loss: 0.0101702
[Epoch 53; Iter   494/  823] train: loss: 0.2917165
[Epoch 53; Iter   524/  823] train: loss: 0.0681357
[Epoch 53; Iter   554/  823] train: loss: 0.0241893
[Epoch 53; Iter   584/  823] train: loss: 0.0093639
[Epoch 53; Iter   614/  823] train: loss: 0.0390148
[Epoch 53; Iter   644/  823] train: loss: 0.0703611
[Epoch 53; Iter   674/  823] train: loss: 0.2345983
[Epoch 53; Iter   704/  823] train: loss: 0.0499791
[Epoch 53; Iter   734/  823] train: loss: 0.0083012
[Epoch 53; Iter   764/  823] train: loss: 0.0082348
[Epoch 53; Iter   794/  823] train: loss: 0.0073158
[Epoch 53] ogbg-molhiv: 0.831469 val loss: 0.138514
[Epoch 53] ogbg-molhiv: 0.802402 test loss: 0.211723
[Epoch 54; Iter     1/  823] train: loss: 0.0577306
[Epoch 54; Iter    31/  823] train: loss: 0.1166850
[Epoch 54; Iter    61/  823] train: loss: 0.0867984
[Epoch 54; Iter    91/  823] train: loss: 0.0247761
[Epoch 54; Iter   121/  823] train: loss: 0.0375746
[Epoch 54; Iter   151/  823] train: loss: 0.0816917
[Epoch 54; Iter   181/  823] train: loss: 0.0261041
[Epoch 54; Iter   211/  823] train: loss: 0.0075217
[Epoch 54; Iter   241/  823] train: loss: 0.0093033
[Epoch 54; Iter   271/  823] train: loss: 0.0246956
[Epoch 54; Iter   301/  823] train: loss: 0.2531808
[Epoch 54; Iter   331/  823] train: loss: 0.0191385
[Epoch 54; Iter   361/  823] train: loss: 0.0046566
[Epoch 54; Iter   391/  823] train: loss: 0.2847191
[Epoch 54; Iter   421/  823] train: loss: 0.1413151
[Epoch 54; Iter   451/  823] train: loss: 0.1030062
[Epoch 54; Iter   481/  823] train: loss: 0.0051308
[Epoch 54; Iter   511/  823] train: loss: 0.1162779
[Epoch 54; Iter   541/  823] train: loss: 0.0057499
[Epoch 54; Iter   571/  823] train: loss: 0.0794796
[Epoch 54; Iter   601/  823] train: loss: 0.0145370
[Epoch 54; Iter   631/  823] train: loss: 0.0338348
[Epoch 54; Iter   661/  823] train: loss: 0.0436030
[Epoch 54; Iter   691/  823] train: loss: 0.0238785
[Epoch 54; Iter   721/  823] train: loss: 0.0213073
[Epoch 54; Iter   751/  823] train: loss: 0.0138821
[Epoch 54; Iter   781/  823] train: loss: 0.0793350
[Epoch 54; Iter   811/  823] train: loss: 0.1292922
[Epoch 54] ogbg-molhiv: 0.820413 val loss: 0.142119
[Epoch 54] ogbg-molhiv: 0.798302 test loss: 0.209574
[Epoch 55; Iter    18/  823] train: loss: 0.0078587
[Epoch 55; Iter    48/  823] train: loss: 0.1497009
[Epoch 55; Iter    78/  823] train: loss: 0.0100832
[Epoch 55; Iter   108/  823] train: loss: 0.0126005
[Epoch 55; Iter   138/  823] train: loss: 0.0057207
[Epoch 55; Iter   168/  823] train: loss: 0.0174933
[Epoch 55; Iter   198/  823] train: loss: 0.0336945
[Epoch 55; Iter   228/  823] train: loss: 0.0063089
[Epoch 55; Iter   258/  823] train: loss: 0.0294204
[Epoch 55; Iter   288/  823] train: loss: 0.0407998
[Epoch 55; Iter   318/  823] train: loss: 0.0129952
[Epoch 55; Iter   348/  823] train: loss: 0.0071476
[Epoch 55; Iter   378/  823] train: loss: 0.0172817
[Epoch 55; Iter   408/  823] train: loss: 0.0288337
[Epoch 55; Iter   438/  823] train: loss: 0.0739912
[Epoch 55; Iter   468/  823] train: loss: 0.0598216
[Epoch 55; Iter   498/  823] train: loss: 0.0677954
[Epoch 55; Iter   528/  823] train: loss: 0.0258038
[Epoch 55; Iter   558/  823] train: loss: 0.0236514
[Epoch 55; Iter   588/  823] train: loss: 0.0228655
[Epoch 55; Iter   618/  823] train: loss: 0.0141183
[Epoch 55; Iter   648/  823] train: loss: 0.0240601
[Epoch 55; Iter   678/  823] train: loss: 0.0110070
[Epoch 55; Iter   708/  823] train: loss: 0.0232839
[Epoch 55; Iter   738/  823] train: loss: 0.0086738
[Epoch 55; Iter   768/  823] train: loss: 0.0290591
[Epoch 55; Iter   798/  823] train: loss: 0.0441559
[Epoch 55] ogbg-molhiv: 0.824177 val loss: 0.166537
[Epoch 55] ogbg-molhiv: 0.790680 test loss: 0.271072
[Epoch 56; Iter     5/  823] train: loss: 0.0088715
[Epoch 56; Iter    35/  823] train: loss: 0.0249754
[Epoch 56; Iter    65/  823] train: loss: 0.0786760
[Epoch 56; Iter    95/  823] train: loss: 0.0360229
[Epoch 56; Iter   125/  823] train: loss: 0.0524583
[Epoch 56; Iter   155/  823] train: loss: 0.0236944
[Epoch 56; Iter   185/  823] train: loss: 0.0719817
[Epoch 56; Iter   215/  823] train: loss: 0.1195356
[Epoch 56; Iter   245/  823] train: loss: 0.0317330
[Epoch 56; Iter   275/  823] train: loss: 0.0100139
[Epoch 56; Iter   305/  823] train: loss: 0.0531962
[Epoch 56; Iter   335/  823] train: loss: 0.0114552
[Epoch 56; Iter   365/  823] train: loss: 0.0181064
[Epoch 56; Iter   395/  823] train: loss: 0.0377936
[Epoch 56; Iter   425/  823] train: loss: 0.0768185
[Epoch 56; Iter   455/  823] train: loss: 0.0059802
[Epoch 56; Iter   485/  823] train: loss: 0.0173729
[Epoch 56; Iter   515/  823] train: loss: 0.0140539
[Epoch 56; Iter   545/  823] train: loss: 0.0059913
[Epoch 56; Iter   575/  823] train: loss: 0.0105724
[Epoch 56; Iter   605/  823] train: loss: 0.0333807
[Epoch 56; Iter   635/  823] train: loss: 0.0100152
[Epoch 56; Iter   665/  823] train: loss: 0.0679034
[Epoch 56; Iter   695/  823] train: loss: 0.0101400
[Epoch 56; Iter   725/  823] train: loss: 0.0172754
[Epoch 56; Iter   755/  823] train: loss: 0.0157038
[Epoch 56; Iter   785/  823] train: loss: 0.1294747
[Epoch 56; Iter   815/  823] train: loss: 0.0831934
[Epoch 56] ogbg-molhiv: 0.823051 val loss: 0.148295
[Epoch 56] ogbg-molhiv: 0.800589 test loss: 0.246942
[Epoch 57; Iter    22/  823] train: loss: 0.0104447
[Epoch 57; Iter    52/  823] train: loss: 0.0100976
[Epoch 57; Iter    82/  823] train: loss: 0.0042211
[Epoch 57; Iter   112/  823] train: loss: 0.0043012
[Epoch 57; Iter   142/  823] train: loss: 0.0098065
[Epoch 57; Iter   172/  823] train: loss: 0.0034835
[Epoch 57; Iter   202/  823] train: loss: 0.0340728
[Epoch 57; Iter   232/  823] train: loss: 0.0606358
[Epoch 57; Iter   262/  823] train: loss: 0.1362219
[Epoch 57; Iter   292/  823] train: loss: 0.0055963
[Epoch 57; Iter   322/  823] train: loss: 0.0046133
[Epoch 57; Iter   352/  823] train: loss: 0.0160235
[Epoch 57; Iter   382/  823] train: loss: 0.0102355
[Epoch 57; Iter   412/  823] train: loss: 0.0120950
[Epoch 57; Iter   442/  823] train: loss: 0.0195991
[Epoch 57; Iter   472/  823] train: loss: 0.0122395
[Epoch 57; Iter   502/  823] train: loss: 0.0586926
[Epoch 57; Iter   532/  823] train: loss: 0.0518772
[Epoch 57; Iter   562/  823] train: loss: 0.0074831
[Epoch 57; Iter   592/  823] train: loss: 0.0041418
[Epoch 57; Iter   622/  823] train: loss: 0.0273045
[Epoch 57; Iter   652/  823] train: loss: 0.0294302
[Epoch 57; Iter   682/  823] train: loss: 0.0158160
[Epoch 57; Iter   712/  823] train: loss: 0.0706624
[Epoch 57; Iter   742/  823] train: loss: 0.0601346
[Epoch 57; Iter   772/  823] train: loss: 0.0147867
[Epoch 57; Iter   802/  823] train: loss: 0.0089464
[Epoch 57] ogbg-molhiv: 0.825196 val loss: 0.147941
[Epoch 57] ogbg-molhiv: 0.803634 test loss: 0.239202
[Epoch 58; Iter     9/  823] train: loss: 0.0271499
[Epoch 58; Iter    39/  823] train: loss: 0.0112825
[Epoch 58; Iter    69/  823] train: loss: 0.0259857
[Epoch 58; Iter    99/  823] train: loss: 0.0040156
[Epoch 58; Iter   129/  823] train: loss: 0.0033525
[Epoch 58; Iter   159/  823] train: loss: 0.0052129
[Epoch 52; Iter   963/ 1097] train: loss: 0.0524398
[Epoch 52; Iter   993/ 1097] train: loss: 0.0994590
[Epoch 52; Iter  1023/ 1097] train: loss: 0.0253512
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0258981
[Epoch 52; Iter  1083/ 1097] train: loss: 0.0232449
[Epoch 52] ogbg-molhiv: 0.829392 val loss: 0.402698
[Epoch 52] ogbg-molhiv: 0.818461 test loss: 0.831442
[Epoch 53; Iter    16/ 1097] train: loss: 0.0887612
[Epoch 53; Iter    46/ 1097] train: loss: 0.0113616
[Epoch 53; Iter    76/ 1097] train: loss: 0.0189916
[Epoch 53; Iter   106/ 1097] train: loss: 0.0205818
[Epoch 53; Iter   136/ 1097] train: loss: 0.0323960
[Epoch 53; Iter   166/ 1097] train: loss: 0.0470129
[Epoch 53; Iter   196/ 1097] train: loss: 0.0543370
[Epoch 53; Iter   226/ 1097] train: loss: 0.0166723
[Epoch 53; Iter   256/ 1097] train: loss: 0.0187144
[Epoch 53; Iter   286/ 1097] train: loss: 0.0889254
[Epoch 53; Iter   316/ 1097] train: loss: 0.0123579
[Epoch 53; Iter   346/ 1097] train: loss: 0.1512805
[Epoch 53; Iter   376/ 1097] train: loss: 0.0161244
[Epoch 53; Iter   406/ 1097] train: loss: 0.0228756
[Epoch 53; Iter   436/ 1097] train: loss: 0.0808102
[Epoch 53; Iter   466/ 1097] train: loss: 0.1214366
[Epoch 53; Iter   496/ 1097] train: loss: 0.0260907
[Epoch 53; Iter   526/ 1097] train: loss: 0.0692548
[Epoch 53; Iter   556/ 1097] train: loss: 0.0564376
[Epoch 53; Iter   586/ 1097] train: loss: 0.0151676
[Epoch 53; Iter   616/ 1097] train: loss: 0.0406868
[Epoch 53; Iter   646/ 1097] train: loss: 0.1519244
[Epoch 53; Iter   676/ 1097] train: loss: 0.0368200
[Epoch 53; Iter   706/ 1097] train: loss: 0.0157207
[Epoch 53; Iter   736/ 1097] train: loss: 0.1207380
[Epoch 53; Iter   766/ 1097] train: loss: 0.0173412
[Epoch 53; Iter   796/ 1097] train: loss: 0.0841881
[Epoch 53; Iter   826/ 1097] train: loss: 0.0182460
[Epoch 53; Iter   856/ 1097] train: loss: 0.0685642
[Epoch 53; Iter   886/ 1097] train: loss: 0.1439716
[Epoch 53; Iter   916/ 1097] train: loss: 0.0694244
[Epoch 53; Iter   946/ 1097] train: loss: 0.2033083
[Epoch 53; Iter   976/ 1097] train: loss: 0.1190860
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0245695
[Epoch 53; Iter  1036/ 1097] train: loss: 0.0283143
[Epoch 53; Iter  1066/ 1097] train: loss: 0.0553668
[Epoch 53; Iter  1096/ 1097] train: loss: 0.0421673
[Epoch 53] ogbg-molhiv: 0.836556 val loss: 0.356841
[Epoch 53] ogbg-molhiv: 0.819647 test loss: 1.044967
[Epoch 54; Iter    29/ 1097] train: loss: 0.0486539
[Epoch 54; Iter    59/ 1097] train: loss: 0.0288649
[Epoch 54; Iter    89/ 1097] train: loss: 0.0977762
[Epoch 54; Iter   119/ 1097] train: loss: 0.1520559
[Epoch 54; Iter   149/ 1097] train: loss: 0.0227104
[Epoch 54; Iter   179/ 1097] train: loss: 0.0673764
[Epoch 54; Iter   209/ 1097] train: loss: 0.1525920
[Epoch 54; Iter   239/ 1097] train: loss: 0.0115954
[Epoch 54; Iter   269/ 1097] train: loss: 0.1595623
[Epoch 54; Iter   299/ 1097] train: loss: 0.0366444
[Epoch 54; Iter   329/ 1097] train: loss: 0.0278093
[Epoch 54; Iter   359/ 1097] train: loss: 0.0440867
[Epoch 54; Iter   389/ 1097] train: loss: 0.0198999
[Epoch 54; Iter   419/ 1097] train: loss: 0.0086606
[Epoch 54; Iter   449/ 1097] train: loss: 0.2335637
[Epoch 54; Iter   479/ 1097] train: loss: 0.0934259
[Epoch 54; Iter   509/ 1097] train: loss: 0.0325422
[Epoch 54; Iter   539/ 1097] train: loss: 0.0900155
[Epoch 54; Iter   569/ 1097] train: loss: 0.0119471
[Epoch 54; Iter   599/ 1097] train: loss: 0.0228712
[Epoch 54; Iter   629/ 1097] train: loss: 0.0146960
[Epoch 54; Iter   659/ 1097] train: loss: 0.1897134
[Epoch 54; Iter   689/ 1097] train: loss: 0.0234139
[Epoch 54; Iter   719/ 1097] train: loss: 0.1603490
[Epoch 54; Iter   749/ 1097] train: loss: 0.0532600
[Epoch 54; Iter   779/ 1097] train: loss: 0.0538284
[Epoch 54; Iter   809/ 1097] train: loss: 0.0227940
[Epoch 54; Iter   839/ 1097] train: loss: 0.2530819
[Epoch 54; Iter   869/ 1097] train: loss: 0.0614107
[Epoch 54; Iter   899/ 1097] train: loss: 0.0610558
[Epoch 54; Iter   929/ 1097] train: loss: 0.0184376
[Epoch 54; Iter   959/ 1097] train: loss: 0.0177311
[Epoch 54; Iter   989/ 1097] train: loss: 0.1906592
[Epoch 54; Iter  1019/ 1097] train: loss: 0.2198377
[Epoch 54; Iter  1049/ 1097] train: loss: 0.3028040
[Epoch 54; Iter  1079/ 1097] train: loss: 0.1256388
[Epoch 54] ogbg-molhiv: 0.826230 val loss: 0.123811
[Epoch 54] ogbg-molhiv: 0.810168 test loss: 0.767862
[Epoch 55; Iter    12/ 1097] train: loss: 0.0651677
[Epoch 55; Iter    42/ 1097] train: loss: 0.0195702
[Epoch 55; Iter    72/ 1097] train: loss: 0.0410432
[Epoch 55; Iter   102/ 1097] train: loss: 0.0273280
[Epoch 55; Iter   132/ 1097] train: loss: 0.0401169
[Epoch 55; Iter   162/ 1097] train: loss: 0.0215400
[Epoch 55; Iter   192/ 1097] train: loss: 0.0164039
[Epoch 55; Iter   222/ 1097] train: loss: 0.0131778
[Epoch 55; Iter   252/ 1097] train: loss: 0.0173372
[Epoch 55; Iter   282/ 1097] train: loss: 0.0315371
[Epoch 55; Iter   312/ 1097] train: loss: 0.0657091
[Epoch 55; Iter   342/ 1097] train: loss: 0.1918172
[Epoch 55; Iter   372/ 1097] train: loss: 0.0659882
[Epoch 55; Iter   402/ 1097] train: loss: 0.0271934
[Epoch 55; Iter   432/ 1097] train: loss: 0.1815590
[Epoch 55; Iter   462/ 1097] train: loss: 0.1143249
[Epoch 55; Iter   492/ 1097] train: loss: 0.0277070
[Epoch 55; Iter   522/ 1097] train: loss: 0.0745798
[Epoch 55; Iter   552/ 1097] train: loss: 0.0190678
[Epoch 55; Iter   582/ 1097] train: loss: 0.1087479
[Epoch 55; Iter   612/ 1097] train: loss: 0.0224408
[Epoch 55; Iter   642/ 1097] train: loss: 0.0305930
[Epoch 55; Iter   672/ 1097] train: loss: 0.0227677
[Epoch 55; Iter   702/ 1097] train: loss: 0.0210317
[Epoch 55; Iter   732/ 1097] train: loss: 0.0107819
[Epoch 55; Iter   762/ 1097] train: loss: 0.3589041
[Epoch 55; Iter   792/ 1097] train: loss: 0.1252854
[Epoch 55; Iter   822/ 1097] train: loss: 0.0249109
[Epoch 55; Iter   852/ 1097] train: loss: 0.1046090
[Epoch 55; Iter   882/ 1097] train: loss: 0.1072505
[Epoch 55; Iter   912/ 1097] train: loss: 0.0182276
[Epoch 55; Iter   942/ 1097] train: loss: 0.1328582
[Epoch 55; Iter   972/ 1097] train: loss: 0.0210515
[Epoch 55; Iter  1002/ 1097] train: loss: 0.2099309
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0087541
[Epoch 55; Iter  1062/ 1097] train: loss: 0.0216820
[Epoch 55; Iter  1092/ 1097] train: loss: 0.0698882
[Epoch 55] ogbg-molhiv: 0.826795 val loss: 0.706755
[Epoch 55] ogbg-molhiv: 0.804482 test loss: 0.975802
[Epoch 56; Iter    25/ 1097] train: loss: 0.0148583
[Epoch 56; Iter    55/ 1097] train: loss: 0.0180088
[Epoch 56; Iter    85/ 1097] train: loss: 0.1895228
[Epoch 56; Iter   115/ 1097] train: loss: 0.0275544
[Epoch 56; Iter   145/ 1097] train: loss: 0.0440956
[Epoch 56; Iter   175/ 1097] train: loss: 0.1166513
[Epoch 56; Iter   205/ 1097] train: loss: 0.0604449
[Epoch 56; Iter   235/ 1097] train: loss: 0.0785906
[Epoch 56; Iter   265/ 1097] train: loss: 0.1038588
[Epoch 56; Iter   295/ 1097] train: loss: 0.0105032
[Epoch 56; Iter   325/ 1097] train: loss: 0.0639115
[Epoch 56; Iter   355/ 1097] train: loss: 0.0284772
[Epoch 56; Iter   385/ 1097] train: loss: 0.0530754
[Epoch 56; Iter   415/ 1097] train: loss: 0.0211028
[Epoch 56; Iter   445/ 1097] train: loss: 0.0960621
[Epoch 56; Iter   475/ 1097] train: loss: 0.0242259
[Epoch 56; Iter   505/ 1097] train: loss: 0.1204721
[Epoch 56; Iter   535/ 1097] train: loss: 0.0395031
[Epoch 56; Iter   565/ 1097] train: loss: 0.0820713
[Epoch 56; Iter   595/ 1097] train: loss: 0.0556523
[Epoch 56; Iter   625/ 1097] train: loss: 0.0208374
[Epoch 56; Iter   655/ 1097] train: loss: 0.0215452
[Epoch 56; Iter   685/ 1097] train: loss: 0.0838157
[Epoch 56; Iter   715/ 1097] train: loss: 0.0092884
[Epoch 56; Iter   745/ 1097] train: loss: 0.1479944
[Epoch 56; Iter   775/ 1097] train: loss: 0.2719590
[Epoch 56; Iter   805/ 1097] train: loss: 0.0189644
[Epoch 56; Iter   835/ 1097] train: loss: 0.0165691
[Epoch 56; Iter   865/ 1097] train: loss: 0.0179480
[Epoch 56; Iter   895/ 1097] train: loss: 0.0135870
[Epoch 56; Iter   925/ 1097] train: loss: 0.0196573
[Epoch 56; Iter   955/ 1097] train: loss: 0.0222402
[Epoch 56; Iter   985/ 1097] train: loss: 0.0791660
[Epoch 56; Iter  1015/ 1097] train: loss: 0.0463959
[Epoch 52; Iter   963/ 1097] train: loss: 0.0191370
[Epoch 52; Iter   993/ 1097] train: loss: 0.0642196
[Epoch 52; Iter  1023/ 1097] train: loss: 0.0507014
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0139452
[Epoch 52; Iter  1083/ 1097] train: loss: 0.0099742
[Epoch 52] ogbg-molhiv: 0.804920 val loss: 0.157132
[Epoch 52] ogbg-molhiv: 0.811108 test loss: 0.147029
[Epoch 53; Iter    16/ 1097] train: loss: 0.0278999
[Epoch 53; Iter    46/ 1097] train: loss: 0.0032543
[Epoch 53; Iter    76/ 1097] train: loss: 0.0115189
[Epoch 53; Iter   106/ 1097] train: loss: 0.0249400
[Epoch 53; Iter   136/ 1097] train: loss: 0.1239130
[Epoch 53; Iter   166/ 1097] train: loss: 0.0375685
[Epoch 53; Iter   196/ 1097] train: loss: 0.1645023
[Epoch 53; Iter   226/ 1097] train: loss: 0.1521823
[Epoch 53; Iter   256/ 1097] train: loss: 0.0524134
[Epoch 53; Iter   286/ 1097] train: loss: 0.0150591
[Epoch 53; Iter   316/ 1097] train: loss: 0.0230035
[Epoch 53; Iter   346/ 1097] train: loss: 0.0140747
[Epoch 53; Iter   376/ 1097] train: loss: 0.0301016
[Epoch 53; Iter   406/ 1097] train: loss: 0.0131733
[Epoch 53; Iter   436/ 1097] train: loss: 0.0272658
[Epoch 53; Iter   466/ 1097] train: loss: 0.0751424
[Epoch 53; Iter   496/ 1097] train: loss: 0.0055401
[Epoch 53; Iter   526/ 1097] train: loss: 0.0047924
[Epoch 53; Iter   556/ 1097] train: loss: 0.0062030
[Epoch 53; Iter   586/ 1097] train: loss: 0.0076384
[Epoch 53; Iter   616/ 1097] train: loss: 0.0058715
[Epoch 53; Iter   646/ 1097] train: loss: 0.0133783
[Epoch 53; Iter   676/ 1097] train: loss: 0.0739398
[Epoch 53; Iter   706/ 1097] train: loss: 0.0087218
[Epoch 53; Iter   736/ 1097] train: loss: 0.0603999
[Epoch 53; Iter   766/ 1097] train: loss: 0.0818563
[Epoch 53; Iter   796/ 1097] train: loss: 0.0535709
[Epoch 53; Iter   826/ 1097] train: loss: 0.0149122
[Epoch 53; Iter   856/ 1097] train: loss: 0.0043379
[Epoch 53; Iter   886/ 1097] train: loss: 0.0315896
[Epoch 53; Iter   916/ 1097] train: loss: 0.2283685
[Epoch 53; Iter   946/ 1097] train: loss: 0.0307742
[Epoch 53; Iter   976/ 1097] train: loss: 0.0107721
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0089417
[Epoch 53; Iter  1036/ 1097] train: loss: 0.0034971
[Epoch 53; Iter  1066/ 1097] train: loss: 0.0676704
[Epoch 53; Iter  1096/ 1097] train: loss: 0.1525035
[Epoch 53] ogbg-molhiv: 0.815148 val loss: 0.157410
[Epoch 53] ogbg-molhiv: 0.816803 test loss: 0.148362
[Epoch 54; Iter    29/ 1097] train: loss: 0.0584132
[Epoch 54; Iter    59/ 1097] train: loss: 0.0522592
[Epoch 54; Iter    89/ 1097] train: loss: 0.0944424
[Epoch 54; Iter   119/ 1097] train: loss: 0.0143322
[Epoch 54; Iter   149/ 1097] train: loss: 0.0054210
[Epoch 54; Iter   179/ 1097] train: loss: 0.0341160
[Epoch 54; Iter   209/ 1097] train: loss: 0.0912917
[Epoch 54; Iter   239/ 1097] train: loss: 0.0140314
[Epoch 54; Iter   269/ 1097] train: loss: 0.0277325
[Epoch 54; Iter   299/ 1097] train: loss: 0.0086543
[Epoch 54; Iter   329/ 1097] train: loss: 0.0516545
[Epoch 54; Iter   359/ 1097] train: loss: 0.0121976
[Epoch 54; Iter   389/ 1097] train: loss: 0.1989909
[Epoch 54; Iter   419/ 1097] train: loss: 0.0719718
[Epoch 54; Iter   449/ 1097] train: loss: 0.0942904
[Epoch 54; Iter   479/ 1097] train: loss: 0.0308371
[Epoch 54; Iter   509/ 1097] train: loss: 0.0258892
[Epoch 54; Iter   539/ 1097] train: loss: 0.0310797
[Epoch 54; Iter   569/ 1097] train: loss: 0.0080936
[Epoch 54; Iter   599/ 1097] train: loss: 0.1691595
[Epoch 54; Iter   629/ 1097] train: loss: 0.0477160
[Epoch 54; Iter   659/ 1097] train: loss: 0.0472055
[Epoch 54; Iter   689/ 1097] train: loss: 0.0105906
[Epoch 54; Iter   719/ 1097] train: loss: 0.0400090
[Epoch 54; Iter   749/ 1097] train: loss: 0.0155907
[Epoch 54; Iter   779/ 1097] train: loss: 0.0200238
[Epoch 54; Iter   809/ 1097] train: loss: 0.0330680
[Epoch 54; Iter   839/ 1097] train: loss: 0.0639061
[Epoch 54; Iter   869/ 1097] train: loss: 0.0629380
[Epoch 54; Iter   899/ 1097] train: loss: 0.2034217
[Epoch 54; Iter   929/ 1097] train: loss: 0.1017909
[Epoch 54; Iter   959/ 1097] train: loss: 0.0173120
[Epoch 54; Iter   989/ 1097] train: loss: 0.0130479
[Epoch 54; Iter  1019/ 1097] train: loss: 0.0046498
[Epoch 54; Iter  1049/ 1097] train: loss: 0.1769225
[Epoch 54; Iter  1079/ 1097] train: loss: 0.0167448
[Epoch 54] ogbg-molhiv: 0.808603 val loss: 0.153493
[Epoch 54] ogbg-molhiv: 0.823130 test loss: 0.147471
[Epoch 55; Iter    12/ 1097] train: loss: 0.0751191
[Epoch 55; Iter    42/ 1097] train: loss: 0.0468372
[Epoch 55; Iter    72/ 1097] train: loss: 0.0289410
[Epoch 55; Iter   102/ 1097] train: loss: 0.0120014
[Epoch 55; Iter   132/ 1097] train: loss: 0.0749951
[Epoch 55; Iter   162/ 1097] train: loss: 0.0864624
[Epoch 55; Iter   192/ 1097] train: loss: 0.0917701
[Epoch 55; Iter   222/ 1097] train: loss: 0.0190512
[Epoch 55; Iter   252/ 1097] train: loss: 0.0886669
[Epoch 55; Iter   282/ 1097] train: loss: 0.0102135
[Epoch 55; Iter   312/ 1097] train: loss: 0.0202322
[Epoch 55; Iter   342/ 1097] train: loss: 0.0072845
[Epoch 55; Iter   372/ 1097] train: loss: 0.0257722
[Epoch 55; Iter   402/ 1097] train: loss: 0.0111606
[Epoch 55; Iter   432/ 1097] train: loss: 0.0405951
[Epoch 55; Iter   462/ 1097] train: loss: 0.0266205
[Epoch 55; Iter   492/ 1097] train: loss: 0.0038774
[Epoch 55; Iter   522/ 1097] train: loss: 0.0404717
[Epoch 55; Iter   552/ 1097] train: loss: 0.0048378
[Epoch 55; Iter   582/ 1097] train: loss: 0.0148733
[Epoch 55; Iter   612/ 1097] train: loss: 0.0098242
[Epoch 55; Iter   642/ 1097] train: loss: 0.1377945
[Epoch 55; Iter   672/ 1097] train: loss: 0.0233785
[Epoch 55; Iter   702/ 1097] train: loss: 0.0185035
[Epoch 55; Iter   732/ 1097] train: loss: 0.0141703
[Epoch 55; Iter   762/ 1097] train: loss: 0.0107715
[Epoch 55; Iter   792/ 1097] train: loss: 0.1952532
[Epoch 55; Iter   822/ 1097] train: loss: 0.0098604
[Epoch 55; Iter   852/ 1097] train: loss: 0.0411050
[Epoch 55; Iter   882/ 1097] train: loss: 0.0049861
[Epoch 55; Iter   912/ 1097] train: loss: 0.0031220
[Epoch 55; Iter   942/ 1097] train: loss: 0.0086565
[Epoch 55; Iter   972/ 1097] train: loss: 0.0458405
[Epoch 55; Iter  1002/ 1097] train: loss: 0.0281984
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0316370
[Epoch 55; Iter  1062/ 1097] train: loss: 0.1030992
[Epoch 55; Iter  1092/ 1097] train: loss: 0.0617253
[Epoch 55] ogbg-molhiv: 0.814460 val loss: 0.156443
[Epoch 55] ogbg-molhiv: 0.825514 test loss: 0.150693
[Epoch 56; Iter    25/ 1097] train: loss: 0.0056750
[Epoch 56; Iter    55/ 1097] train: loss: 0.0133630
[Epoch 56; Iter    85/ 1097] train: loss: 0.0175480
[Epoch 56; Iter   115/ 1097] train: loss: 0.0756484
[Epoch 56; Iter   145/ 1097] train: loss: 0.0061327
[Epoch 56; Iter   175/ 1097] train: loss: 0.0270005
[Epoch 56; Iter   205/ 1097] train: loss: 0.0051734
[Epoch 56; Iter   235/ 1097] train: loss: 0.0240995
[Epoch 56; Iter   265/ 1097] train: loss: 0.0341518
[Epoch 56; Iter   295/ 1097] train: loss: 0.0644003
[Epoch 56; Iter   325/ 1097] train: loss: 0.0466367
[Epoch 56; Iter   355/ 1097] train: loss: 0.0114966
[Epoch 56; Iter   385/ 1097] train: loss: 0.0277668
[Epoch 56; Iter   415/ 1097] train: loss: 0.0286314
[Epoch 56; Iter   445/ 1097] train: loss: 0.0057477
[Epoch 56; Iter   475/ 1097] train: loss: 0.0392303
[Epoch 56; Iter   505/ 1097] train: loss: 0.0077713
[Epoch 56; Iter   535/ 1097] train: loss: 0.0080788
[Epoch 56; Iter   565/ 1097] train: loss: 0.0426383
[Epoch 56; Iter   595/ 1097] train: loss: 0.0534702
[Epoch 56; Iter   625/ 1097] train: loss: 0.0149369
[Epoch 56; Iter   655/ 1097] train: loss: 0.1642478
[Epoch 56; Iter   685/ 1097] train: loss: 0.0608763
[Epoch 56; Iter   715/ 1097] train: loss: 0.0438820
[Epoch 56; Iter   745/ 1097] train: loss: 0.0100953
[Epoch 56; Iter   775/ 1097] train: loss: 0.0991542
[Epoch 56; Iter   805/ 1097] train: loss: 0.0515582
[Epoch 56; Iter   835/ 1097] train: loss: 0.0269862
[Epoch 56; Iter   865/ 1097] train: loss: 0.0164361
[Epoch 56; Iter   895/ 1097] train: loss: 0.0055319
[Epoch 56; Iter   925/ 1097] train: loss: 0.1204943
[Epoch 56; Iter   955/ 1097] train: loss: 0.0045641
[Epoch 56; Iter   985/ 1097] train: loss: 0.0705878
[Epoch 56; Iter  1015/ 1097] train: loss: 0.0124161
[Epoch 52; Iter   963/ 1097] train: loss: 0.0093334
[Epoch 52; Iter   993/ 1097] train: loss: 0.1850794
[Epoch 52; Iter  1023/ 1097] train: loss: 0.0816764
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0295108
[Epoch 52; Iter  1083/ 1097] train: loss: 0.0421627
[Epoch 52] ogbg-molhiv: 0.812031 val loss: 0.300781
[Epoch 52] ogbg-molhiv: 0.818969 test loss: 0.319345
[Epoch 53; Iter    16/ 1097] train: loss: 0.0857143
[Epoch 53; Iter    46/ 1097] train: loss: 0.0147722
[Epoch 53; Iter    76/ 1097] train: loss: 0.0270156
[Epoch 53; Iter   106/ 1097] train: loss: 0.0888564
[Epoch 53; Iter   136/ 1097] train: loss: 0.0135703
[Epoch 53; Iter   166/ 1097] train: loss: 0.0269596
[Epoch 53; Iter   196/ 1097] train: loss: 0.0527904
[Epoch 53; Iter   226/ 1097] train: loss: 0.1432316
[Epoch 53; Iter   256/ 1097] train: loss: 0.0051313
[Epoch 53; Iter   286/ 1097] train: loss: 0.0591440
[Epoch 53; Iter   316/ 1097] train: loss: 0.0141180
[Epoch 53; Iter   346/ 1097] train: loss: 0.0336531
[Epoch 53; Iter   376/ 1097] train: loss: 0.1153764
[Epoch 53; Iter   406/ 1097] train: loss: 0.0101019
[Epoch 53; Iter   436/ 1097] train: loss: 0.0175372
[Epoch 53; Iter   466/ 1097] train: loss: 0.0100460
[Epoch 53; Iter   496/ 1097] train: loss: 0.0078174
[Epoch 53; Iter   526/ 1097] train: loss: 0.0660923
[Epoch 53; Iter   556/ 1097] train: loss: 0.1475510
[Epoch 53; Iter   586/ 1097] train: loss: 0.1017237
[Epoch 53; Iter   616/ 1097] train: loss: 0.0074740
[Epoch 53; Iter   646/ 1097] train: loss: 0.2349295
[Epoch 53; Iter   676/ 1097] train: loss: 0.0269308
[Epoch 53; Iter   706/ 1097] train: loss: 0.0220453
[Epoch 53; Iter   736/ 1097] train: loss: 0.0035039
[Epoch 53; Iter   766/ 1097] train: loss: 0.0099076
[Epoch 53; Iter   796/ 1097] train: loss: 0.0179663
[Epoch 53; Iter   826/ 1097] train: loss: 0.1715935
[Epoch 53; Iter   856/ 1097] train: loss: 0.0230765
[Epoch 53; Iter   886/ 1097] train: loss: 0.0074470
[Epoch 53; Iter   916/ 1097] train: loss: 0.0087420
[Epoch 53; Iter   946/ 1097] train: loss: 0.0037277
[Epoch 53; Iter   976/ 1097] train: loss: 0.0115427
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0388919
[Epoch 53; Iter  1036/ 1097] train: loss: 0.0046054
[Epoch 53; Iter  1066/ 1097] train: loss: 0.0211786
[Epoch 53; Iter  1096/ 1097] train: loss: 0.0207321
[Epoch 53] ogbg-molhiv: 0.804214 val loss: 0.165929
[Epoch 53] ogbg-molhiv: 0.808569 test loss: 0.190303
[Epoch 54; Iter    29/ 1097] train: loss: 0.0030026
[Epoch 54; Iter    59/ 1097] train: loss: 0.0091830
[Epoch 54; Iter    89/ 1097] train: loss: 0.0036218
[Epoch 54; Iter   119/ 1097] train: loss: 0.0132274
[Epoch 54; Iter   149/ 1097] train: loss: 0.0054518
[Epoch 54; Iter   179/ 1097] train: loss: 0.0059079
[Epoch 54; Iter   209/ 1097] train: loss: 0.0066708
[Epoch 54; Iter   239/ 1097] train: loss: 0.0891022
[Epoch 54; Iter   269/ 1097] train: loss: 0.0323168
[Epoch 54; Iter   299/ 1097] train: loss: 0.0720567
[Epoch 54; Iter   329/ 1097] train: loss: 0.0530644
[Epoch 54; Iter   359/ 1097] train: loss: 0.0665866
[Epoch 54; Iter   389/ 1097] train: loss: 0.0042910
[Epoch 54; Iter   419/ 1097] train: loss: 0.0280666
[Epoch 54; Iter   449/ 1097] train: loss: 0.0050136
[Epoch 54; Iter   479/ 1097] train: loss: 0.0250116
[Epoch 54; Iter   509/ 1097] train: loss: 0.0776027
[Epoch 54; Iter   539/ 1097] train: loss: 0.0130248
[Epoch 54; Iter   569/ 1097] train: loss: 0.0163150
[Epoch 54; Iter   599/ 1097] train: loss: 0.0403080
[Epoch 54; Iter   629/ 1097] train: loss: 0.0110911
[Epoch 54; Iter   659/ 1097] train: loss: 0.0036709
[Epoch 54; Iter   689/ 1097] train: loss: 0.0955546
[Epoch 54; Iter   719/ 1097] train: loss: 0.0195183
[Epoch 54; Iter   749/ 1097] train: loss: 0.0272056
[Epoch 54; Iter   779/ 1097] train: loss: 0.0692619
[Epoch 54; Iter   809/ 1097] train: loss: 0.0158993
[Epoch 54; Iter   839/ 1097] train: loss: 0.0080604
[Epoch 54; Iter   869/ 1097] train: loss: 0.0381510
[Epoch 54; Iter   899/ 1097] train: loss: 0.0053106
[Epoch 54; Iter   929/ 1097] train: loss: 0.0033359
[Epoch 54; Iter   959/ 1097] train: loss: 0.0147040
[Epoch 54; Iter   989/ 1097] train: loss: 0.0232820
[Epoch 54; Iter  1019/ 1097] train: loss: 0.0531058
[Epoch 54; Iter  1049/ 1097] train: loss: 0.0300156
[Epoch 54; Iter  1079/ 1097] train: loss: 0.0121570
[Epoch 54] ogbg-molhiv: 0.802142 val loss: 0.154263
[Epoch 54] ogbg-molhiv: 0.811711 test loss: 0.159177
[Epoch 55; Iter    12/ 1097] train: loss: 0.1323104
[Epoch 55; Iter    42/ 1097] train: loss: 0.1478760
[Epoch 55; Iter    72/ 1097] train: loss: 0.0252945
[Epoch 55; Iter   102/ 1097] train: loss: 0.0091766
[Epoch 55; Iter   132/ 1097] train: loss: 0.0693698
[Epoch 55; Iter   162/ 1097] train: loss: 0.0557907
[Epoch 55; Iter   192/ 1097] train: loss: 0.0703958
[Epoch 55; Iter   222/ 1097] train: loss: 0.0138785
[Epoch 55; Iter   252/ 1097] train: loss: 0.0221286
[Epoch 55; Iter   282/ 1097] train: loss: 0.0115297
[Epoch 55; Iter   312/ 1097] train: loss: 0.0076495
[Epoch 55; Iter   342/ 1097] train: loss: 0.0142773
[Epoch 55; Iter   372/ 1097] train: loss: 0.0415916
[Epoch 55; Iter   402/ 1097] train: loss: 0.0309321
[Epoch 55; Iter   432/ 1097] train: loss: 0.0094830
[Epoch 55; Iter   462/ 1097] train: loss: 0.0539048
[Epoch 55; Iter   492/ 1097] train: loss: 0.1203326
[Epoch 55; Iter   522/ 1097] train: loss: 0.0180082
[Epoch 55; Iter   552/ 1097] train: loss: 0.0205397
[Epoch 55; Iter   582/ 1097] train: loss: 0.0072548
[Epoch 55; Iter   612/ 1097] train: loss: 0.0346295
[Epoch 55; Iter   642/ 1097] train: loss: 0.0096831
[Epoch 55; Iter   672/ 1097] train: loss: 0.1040451
[Epoch 55; Iter   702/ 1097] train: loss: 0.3011540
[Epoch 55; Iter   732/ 1097] train: loss: 0.0155057
[Epoch 55; Iter   762/ 1097] train: loss: 0.0423411
[Epoch 55; Iter   792/ 1097] train: loss: 0.0309460
[Epoch 55; Iter   822/ 1097] train: loss: 0.0055737
[Epoch 55; Iter   852/ 1097] train: loss: 0.0100919
[Epoch 55; Iter   882/ 1097] train: loss: 0.0160061
[Epoch 55; Iter   912/ 1097] train: loss: 0.0305234
[Epoch 55; Iter   942/ 1097] train: loss: 0.0197700
[Epoch 55; Iter   972/ 1097] train: loss: 0.0220902
[Epoch 55; Iter  1002/ 1097] train: loss: 0.0247478
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0253914
[Epoch 55; Iter  1062/ 1097] train: loss: 0.0483096
[Epoch 55; Iter  1092/ 1097] train: loss: 0.0380163
[Epoch 55] ogbg-molhiv: 0.808261 val loss: 0.204019
[Epoch 55] ogbg-molhiv: 0.805416 test loss: 0.177514
[Epoch 56; Iter    25/ 1097] train: loss: 0.0147650
[Epoch 56; Iter    55/ 1097] train: loss: 0.0128657
[Epoch 56; Iter    85/ 1097] train: loss: 0.0031123
[Epoch 56; Iter   115/ 1097] train: loss: 0.0162185
[Epoch 56; Iter   145/ 1097] train: loss: 0.0037481
[Epoch 56; Iter   175/ 1097] train: loss: 0.0219640
[Epoch 56; Iter   205/ 1097] train: loss: 0.0054392
[Epoch 56; Iter   235/ 1097] train: loss: 0.0036436
[Epoch 56; Iter   265/ 1097] train: loss: 0.0048230
[Epoch 56; Iter   295/ 1097] train: loss: 0.0079607
[Epoch 56; Iter   325/ 1097] train: loss: 0.0155739
[Epoch 56; Iter   355/ 1097] train: loss: 0.0628013
[Epoch 56; Iter   385/ 1097] train: loss: 0.0112724
[Epoch 56; Iter   415/ 1097] train: loss: 0.0304289
[Epoch 56; Iter   445/ 1097] train: loss: 0.0128584
[Epoch 56; Iter   475/ 1097] train: loss: 0.0080423
[Epoch 56; Iter   505/ 1097] train: loss: 0.0193430
[Epoch 56; Iter   535/ 1097] train: loss: 0.0085946
[Epoch 56; Iter   565/ 1097] train: loss: 0.0224119
[Epoch 56; Iter   595/ 1097] train: loss: 0.0549868
[Epoch 56; Iter   625/ 1097] train: loss: 0.0093900
[Epoch 56; Iter   655/ 1097] train: loss: 0.0036746
[Epoch 56; Iter   685/ 1097] train: loss: 0.0708929
[Epoch 56; Iter   715/ 1097] train: loss: 0.0156726
[Epoch 56; Iter   745/ 1097] train: loss: 0.0508412
[Epoch 56; Iter   775/ 1097] train: loss: 0.0254501
[Epoch 56; Iter   805/ 1097] train: loss: 0.0297948
[Epoch 56; Iter   835/ 1097] train: loss: 0.0691196
[Epoch 56; Iter   865/ 1097] train: loss: 0.0399792
[Epoch 56; Iter   895/ 1097] train: loss: 0.0110888
[Epoch 56; Iter   925/ 1097] train: loss: 0.0630931
[Epoch 56; Iter   955/ 1097] train: loss: 0.0343471
[Epoch 56; Iter   985/ 1097] train: loss: 0.0446379
[Epoch 56; Iter  1015/ 1097] train: loss: 0.0605235
