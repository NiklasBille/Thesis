>>> Starting run for dataset: clintox
Running SCAFF configs_split_experiments/3DInfomax/clintox/scaff/train_prop=0.6.yml on cuda:0
Running SCAFF configs_split_experiments/3DInfomax/clintox/scaff/train_prop=0.7.yml on cuda:1
Running SCAFF configs_split_experiments/3DInfomax/clintox/scaff/train_prop=0.8.yml on cuda:2
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
Starting process for seed 4: python train.py --config configs_split_experiments/3DInfomax/clintox/scaff/train_prop=0.8.yml --seed 4 --device cuda:2
Starting process for seed 4: python train.py --config configs_split_experiments/3DInfomax/clintox/scaff/train_prop=0.7.yml --seed 4 --device cuda:1
Starting process for seed 4: python train.py --config configs_split_experiments/3DInfomax/clintox/scaff/train_prop=0.6.yml --seed 4 --device cuda:0
Starting process for seed 5: python train.py --config configs_split_experiments/3DInfomax/clintox/scaff/train_prop=0.8.yml --seed 5 --device cuda:2
Starting process for seed 5: python train.py --config configs_split_experiments/3DInfomax/clintox/scaff/train_prop=0.7.yml --seed 5 --device cuda:1
Starting process for seed 5: python train.py --config configs_split_experiments/3DInfomax/clintox/scaff/train_prop=0.6.yml --seed 5 --device cuda:0
Starting process for seed 6: python train.py --config configs_split_experiments/3DInfomax/clintox/scaff/train_prop=0.8.yml --seed 6 --device cuda:2
Starting process for seed 6: python train.py --config configs_split_experiments/3DInfomax/clintox/scaff/train_prop=0.7.yml --seed 6 --device cuda:1
Starting process for seed 6: python train.py --config configs_split_experiments/3DInfomax/clintox/scaff/train_prop=0.6.yml --seed 6 --device cuda:0
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[ Using Seed :  5  ]
using device:  cuda:2
Log directory:  runs/split/3DInfomax/clintox/scaff/train_prop=0.8/PNA_ogbg-molclintox_3DInfomax_clintox_scaff=0.8_5_26-05_09-18-13
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/clintox/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_scaff=0.8
logdir: runs/split/3DInfomax/clintox/scaff/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/   40] train: loss: 0.6928144
[Epoch 1] ogbg-molclintox: 0.456483 val loss: 0.693326
[Epoch 1] ogbg-molclintox: 0.651081 test loss: 0.693582
[Epoch 2; Iter    20/   40] train: loss: 0.6927844
[Epoch 2] ogbg-molclintox: 0.517903 val loss: 0.692143
[Epoch 2] ogbg-molclintox: 0.641503 test loss: 0.694549
[Epoch 3; Iter    10/   40] train: loss: 0.6926650
[Epoch 3; Iter    40/   40] train: loss: 0.6926810
[Epoch 3] ogbg-molclintox: 0.546897 val loss: 0.692437
[Epoch 3] ogbg-molclintox: 0.641242 test loss: 0.695051
[Epoch 4; Iter    30/   40] train: loss: 0.6918060
[Epoch 4] ogbg-molclintox: 0.532799 val loss: 0.691490
[Epoch 4] ogbg-molclintox: 0.647525 test loss: 0.693552
[Epoch 5; Iter    20/   40] train: loss: 0.6911660
[Epoch 5] ogbg-molclintox: 0.535484 val loss: 0.690544
[Epoch 5] ogbg-molclintox: 0.645040 test loss: 0.692404
[Epoch 6; Iter    10/   40] train: loss: 0.6905714
[Epoch 6; Iter    40/   40] train: loss: 0.6910768
[Epoch 6] ogbg-molclintox: 0.550805 val loss: 0.690849
[Epoch 6] ogbg-molclintox: 0.641555 test loss: 0.692972
[Epoch 7; Iter    30/   40] train: loss: 0.6918393
[Epoch 7] ogbg-molclintox: 0.533586 val loss: 0.689218
[Epoch 7] ogbg-molclintox: 0.644966 test loss: 0.690931
[Epoch 8; Iter    20/   40] train: loss: 0.6909466
[Epoch 8] ogbg-molclintox: 0.541841 val loss: 0.688564
[Epoch 8] ogbg-molclintox: 0.642803 test loss: 0.690988
[Epoch 9; Iter    10/   40] train: loss: 0.6899628
[Epoch 9; Iter    40/   40] train: loss: 0.6851919
[Epoch 9] ogbg-molclintox: 0.536183 val loss: 0.688863
[Epoch 9] ogbg-molclintox: 0.629012 test loss: 0.691169
[Epoch 10; Iter    30/   40] train: loss: 0.6904100
[Epoch 10] ogbg-molclintox: 0.557911 val loss: 0.686853
[Epoch 10] ogbg-molclintox: 0.646490 test loss: 0.688930
[Epoch 11; Iter    20/   40] train: loss: 0.6866365
[Epoch 11] ogbg-molclintox: 0.529390 val loss: 0.685580
[Epoch 11] ogbg-molclintox: 0.647801 test loss: 0.687817
[Epoch 12; Iter    10/   40] train: loss: 0.6891339
[Epoch 12; Iter    40/   40] train: loss: 0.6849339
[Epoch 12] ogbg-molclintox: 0.540266 val loss: 0.684287
[Epoch 12] ogbg-molclintox: 0.647838 test loss: 0.686901
[Epoch 13; Iter    30/   40] train: loss: 0.6852233
[Epoch 13] ogbg-molclintox: 0.554189 val loss: 0.682768
[Epoch 13] ogbg-molclintox: 0.657583 test loss: 0.685117
[Epoch 14; Iter    20/   40] train: loss: 0.6830212
[Epoch 14] ogbg-molclintox: 0.556287 val loss: 0.681857
[Epoch 14] ogbg-molclintox: 0.652074 test loss: 0.683872
[Epoch 15; Iter    10/   40] train: loss: 0.6827161
[Epoch 15; Iter    40/   40] train: loss: 0.6798384
[Epoch 15] ogbg-molclintox: 0.571334 val loss: 0.680730
[Epoch 15] ogbg-molclintox: 0.641006 test loss: 0.683466
[Epoch 16; Iter    30/   40] train: loss: 0.6793367
[Epoch 16] ogbg-molclintox: 0.567202 val loss: 0.678146
[Epoch 16] ogbg-molclintox: 0.645941 test loss: 0.681381
[Epoch 17; Iter    20/   40] train: loss: 0.6819030
[Epoch 17] ogbg-molclintox: 0.554052 val loss: 0.677181
[Epoch 17] ogbg-molclintox: 0.643804 test loss: 0.679913
[Epoch 18; Iter    10/   40] train: loss: 0.6768451
[Epoch 18; Iter    40/   40] train: loss: 0.6784310
[Epoch 18] ogbg-molclintox: 0.712063 val loss: 0.669492
[Epoch 18] ogbg-molclintox: 0.614526 test loss: 0.693558
[Epoch 19; Iter    30/   40] train: loss: 0.6467096
[Epoch 19] ogbg-molclintox: 0.723389 val loss: 0.714380
[Epoch 19] ogbg-molclintox: 0.634625 test loss: 0.725267
[Epoch 20; Iter    20/   40] train: loss: 0.6045088
[Epoch 20] ogbg-molclintox: 0.793330 val loss: 0.531298
[Epoch 20] ogbg-molclintox: 0.610678 test loss: 0.572734
[Epoch 21; Iter    10/   40] train: loss: 0.5612971
[Epoch 21; Iter    40/   40] train: loss: 0.4851509
[Epoch 21] ogbg-molclintox: 0.842927 val loss: 0.541447
[Epoch 21] ogbg-molclintox: 0.671650 test loss: 0.568222
[Epoch 22; Iter    30/   40] train: loss: 0.5137609
[Epoch 22] ogbg-molclintox: 0.843215 val loss: 0.353176
[Epoch 22] ogbg-molclintox: 0.675773 test loss: 0.421567
[Epoch 23; Iter    20/   40] train: loss: 0.3403093
[Epoch 23] ogbg-molclintox: 0.729310 val loss: 0.300209
[Epoch 23] ogbg-molclintox: 0.725991 test loss: 0.364342
[Epoch 24; Iter    10/   40] train: loss: 0.3051439
[Epoch 24; Iter    40/   40] train: loss: 0.5466050
[Epoch 24] ogbg-molclintox: 0.710541 val loss: 0.311583
[Epoch 24] ogbg-molclintox: 0.706238 test loss: 0.335044
[Epoch 25; Iter    30/   40] train: loss: 0.2853580
[Epoch 25] ogbg-molclintox: 0.784102 val loss: 0.224295
[Epoch 25] ogbg-molclintox: 0.683920 test loss: 0.395517
[Epoch 26; Iter    20/   40] train: loss: 0.2424668
[Epoch 26] ogbg-molclintox: 0.730933 val loss: 0.188614
[Epoch 26] ogbg-molclintox: 0.685739 test loss: 0.299086
[Epoch 27; Iter    10/   40] train: loss: 0.2292866
[Epoch 27; Iter    40/   40] train: loss: 0.1003353
[Epoch 27] ogbg-molclintox: 0.826520 val loss: 0.162830
[Epoch 27] ogbg-molclintox: 0.716432 test loss: 0.268130
[Epoch 28; Iter    30/   40] train: loss: 0.2675993
[Epoch 28] ogbg-molclintox: 0.905338 val loss: 0.196631
[Epoch 28] ogbg-molclintox: 0.686964 test loss: 0.282625
[Epoch 29; Iter    20/   40] train: loss: 0.2412586
[Epoch 29] ogbg-molclintox: 0.915040 val loss: 0.138408
[Epoch 29] ogbg-molclintox: 0.681570 test loss: 0.232742
[Epoch 30; Iter    10/   40] train: loss: 0.1672240
[Epoch 30; Iter    40/   40] train: loss: 0.3388390
[Epoch 30] ogbg-molclintox: 0.853803 val loss: 0.141605
[Epoch 30] ogbg-molclintox: 0.725479 test loss: 0.224693
[Epoch 31; Iter    30/   40] train: loss: 0.2915382
[Epoch 31] ogbg-molclintox: 0.814020 val loss: 0.134163
[ Using Seed :  5  ]
using device:  cuda:0
Log directory:  runs/split/3DInfomax/clintox/scaff/train_prop=0.6/PNA_ogbg-molclintox_3DInfomax_clintox_scaff=0.6_5_26-05_09-18-12
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/clintox/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_scaff=0.6
logdir: runs/split/3DInfomax/clintox/scaff/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/   30] train: loss: 0.6914638
[Epoch 1] ogbg-molclintox: 0.583591 val loss: 0.693419
[Epoch 1] ogbg-molclintox: 0.587107 test loss: 0.693485
[Epoch 2; Iter    30/   30] train: loss: 0.6922876
[Epoch 2] ogbg-molclintox: 0.566333 val loss: 0.692623
[Epoch 2] ogbg-molclintox: 0.590808 test loss: 0.693373
[Epoch 3; Iter    30/   30] train: loss: 0.6934357
[Epoch 3] ogbg-molclintox: 0.575959 val loss: 0.691353
[Epoch 3] ogbg-molclintox: 0.606098 test loss: 0.693068
[Epoch 4; Iter    30/   30] train: loss: 0.6928977
[Epoch 4] ogbg-molclintox: 0.585839 val loss: 0.690585
[Epoch 4] ogbg-molclintox: 0.614830 test loss: 0.692305
[Epoch 5; Iter    30/   30] train: loss: 0.6916953
[Epoch 5] ogbg-molclintox: 0.585499 val loss: 0.690346
[Epoch 5] ogbg-molclintox: 0.611401 test loss: 0.692222
[Epoch 6; Iter    30/   30] train: loss: 0.6938783
[Epoch 6] ogbg-molclintox: 0.584649 val loss: 0.689820
[Epoch 6] ogbg-molclintox: 0.617497 test loss: 0.691319
[Epoch 7; Iter    30/   30] train: loss: 0.6915960
[Epoch 7] ogbg-molclintox: 0.582169 val loss: 0.689513
[Epoch 7] ogbg-molclintox: 0.618836 test loss: 0.691038
[Epoch 8; Iter    30/   30] train: loss: 0.6922224
[Epoch 8] ogbg-molclintox: 0.581734 val loss: 0.689671
[Epoch 8] ogbg-molclintox: 0.616879 test loss: 0.690998
[Epoch 9; Iter    30/   30] train: loss: 0.6905034
[Epoch 9] ogbg-molclintox: 0.586167 val loss: 0.689154
[Epoch 9] ogbg-molclintox: 0.617008 test loss: 0.690479
[Epoch 10; Iter    30/   30] train: loss: 0.6887912
[Epoch 10] ogbg-molclintox: 0.579882 val loss: 0.688966
[Epoch 10] ogbg-molclintox: 0.616284 test loss: 0.689954
[Epoch 11; Iter    30/   30] train: loss: 0.6898218
[Epoch 11] ogbg-molclintox: 0.589422 val loss: 0.687518
[Epoch 11] ogbg-molclintox: 0.627139 test loss: 0.688807
[Epoch 12; Iter    30/   30] train: loss: 0.6892880
[Epoch 12] ogbg-molclintox: 0.590906 val loss: 0.687336
[Epoch 12] ogbg-molclintox: 0.621801 test loss: 0.688626
[Epoch 13; Iter    30/   30] train: loss: 0.6881101
[Epoch 13] ogbg-molclintox: 0.587403 val loss: 0.686577
[Epoch 13] ogbg-molclintox: 0.624737 test loss: 0.687692
[Epoch 14; Iter    30/   30] train: loss: 0.6866255
[Epoch 14] ogbg-molclintox: 0.600258 val loss: 0.686120
[Epoch 14] ogbg-molclintox: 0.623077 test loss: 0.687051
[Epoch 15; Iter    30/   30] train: loss: 0.6868670
[Epoch 15] ogbg-molclintox: 0.584897 val loss: 0.684407
[Epoch 15] ogbg-molclintox: 0.623571 test loss: 0.685562
[Epoch 16; Iter    30/   30] train: loss: 0.6859041
[Epoch 16] ogbg-molclintox: 0.601482 val loss: 0.684073
[Epoch 16] ogbg-molclintox: 0.633376 test loss: 0.684991
[Epoch 17; Iter    30/   30] train: loss: 0.6884309
[Epoch 17] ogbg-molclintox: 0.588486 val loss: 0.683485
[Epoch 17] ogbg-molclintox: 0.623842 test loss: 0.684319
[Epoch 18; Iter    30/   30] train: loss: 0.6842282
[Epoch 18] ogbg-molclintox: 0.590686 val loss: 0.681363
[Epoch 18] ogbg-molclintox: 0.628765 test loss: 0.682178
[Epoch 19; Iter    30/   30] train: loss: 0.6811510
[Epoch 19] ogbg-molclintox: 0.602269 val loss: 0.682330
[Epoch 19] ogbg-molclintox: 0.629619 test loss: 0.682363
[Epoch 20; Iter    30/   30] train: loss: 0.6821746
[Epoch 20] ogbg-molclintox: 0.597718 val loss: 0.680445
[Epoch 20] ogbg-molclintox: 0.629239 test loss: 0.681091
[Epoch 21; Iter    30/   30] train: loss: 0.6806300
[Epoch 21] ogbg-molclintox: 0.597537 val loss: 0.678843
[Epoch 21] ogbg-molclintox: 0.629027 test loss: 0.679218
[Epoch 22; Iter    30/   30] train: loss: 0.6770748
[Epoch 22] ogbg-molclintox: 0.606768 val loss: 0.678278
[Epoch 22] ogbg-molclintox: 0.632644 test loss: 0.678487
[Epoch 23; Iter    30/   30] train: loss: 0.6798537
[Epoch 23] ogbg-molclintox: 0.590216 val loss: 0.683806
[Epoch 23] ogbg-molclintox: 0.685904 test loss: 0.679591
[Epoch 24; Iter    30/   30] train: loss: 0.6586206
[Epoch 24] ogbg-molclintox: 0.643217 val loss: 0.698820
[Epoch 24] ogbg-molclintox: 0.683080 test loss: 0.681373
[Epoch 25; Iter    30/   30] train: loss: 0.6322347
[Epoch 25] ogbg-molclintox: 0.611522 val loss: 0.783770
[Epoch 25] ogbg-molclintox: 0.661165 test loss: 0.715436
[Epoch 26; Iter    30/   30] train: loss: 0.5837734
[Epoch 26] ogbg-molclintox: 0.635168 val loss: 0.564002
[Epoch 26] ogbg-molclintox: 0.658996 test loss: 0.551906
[Epoch 27; Iter    30/   30] train: loss: 0.5234009
[Epoch 27] ogbg-molclintox: 0.630128 val loss: 0.721038
[Epoch 27] ogbg-molclintox: 0.709574 test loss: 0.684286
[Epoch 28; Iter    30/   30] train: loss: 0.4922935
[Epoch 28] ogbg-molclintox: 0.667370 val loss: 0.505543
[Epoch 28] ogbg-molclintox: 0.698829 test loss: 0.497491
[Epoch 29; Iter    30/   30] train: loss: 0.4226409
[Epoch 29] ogbg-molclintox: 0.659368 val loss: 0.490610
[Epoch 29] ogbg-molclintox: 0.705629 test loss: 0.440918
[Epoch 30; Iter    30/   30] train: loss: 0.4191513
[Epoch 30] ogbg-molclintox: 0.634974 val loss: 0.585429
[Epoch 30] ogbg-molclintox: 0.751573 test loss: 0.508783
[Epoch 31; Iter    30/   30] train: loss: 0.3722823
[Epoch 31] ogbg-molclintox: 0.571976 val loss: 0.412091
[Epoch 31] ogbg-molclintox: 0.696402 test loss: 0.401687
[Epoch 32; Iter    30/   30] train: loss: 0.2425002
[Epoch 32] ogbg-molclintox: 0.680820 val loss: 0.389404
[Epoch 32] ogbg-molclintox: 0.695730 test loss: 0.372910
[Epoch 33; Iter    30/   30] train: loss: 0.1772301
[Epoch 33] ogbg-molclintox: 0.656953 val loss: 0.345318
[Epoch 33] ogbg-molclintox: 0.733277 test loss: 0.293563
[Epoch 34; Iter    30/   30] train: loss: 0.1456442
[Epoch 34] ogbg-molclintox: 0.599250 val loss: 0.327106
[ Using Seed :  4  ]
using device:  cuda:2
Log directory:  runs/split/3DInfomax/clintox/scaff/train_prop=0.8/PNA_ogbg-molclintox_3DInfomax_clintox_scaff=0.8_4_26-05_09-18-13
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/clintox/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_scaff=0.8
logdir: runs/split/3DInfomax/clintox/scaff/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/   40] train: loss: 0.6929867
[Epoch 1] ogbg-molclintox: 0.542866 val loss: 0.693127
[Epoch 1] ogbg-molclintox: 0.456819 test loss: 0.693144
[Epoch 2; Iter    20/   40] train: loss: 0.6927838
[Epoch 2] ogbg-molclintox: 0.499745 val loss: 0.692438
[Epoch 2] ogbg-molclintox: 0.483089 test loss: 0.693220
[Epoch 3; Iter    10/   40] train: loss: 0.6928375
[Epoch 3; Iter    40/   40] train: loss: 0.6895658
[Epoch 3] ogbg-molclintox: 0.462921 val loss: 0.692153
[Epoch 3] ogbg-molclintox: 0.487273 test loss: 0.693170
[Epoch 4; Iter    30/   40] train: loss: 0.6925436
[Epoch 4] ogbg-molclintox: 0.465243 val loss: 0.692166
[Epoch 4] ogbg-molclintox: 0.492405 test loss: 0.693064
[Epoch 5; Iter    20/   40] train: loss: 0.6924810
[Epoch 5] ogbg-molclintox: 0.468540 val loss: 0.691044
[Epoch 5] ogbg-molclintox: 0.488371 test loss: 0.692189
[Epoch 6; Iter    10/   40] train: loss: 0.6917564
[Epoch 6; Iter    40/   40] train: loss: 0.6905861
[Epoch 6] ogbg-molclintox: 0.481015 val loss: 0.690270
[Epoch 6] ogbg-molclintox: 0.496540 test loss: 0.691694
[Epoch 7; Iter    30/   40] train: loss: 0.6900141
[Epoch 7] ogbg-molclintox: 0.466354 val loss: 0.688802
[Epoch 7] ogbg-molclintox: 0.498751 test loss: 0.690683
[Epoch 8; Iter    20/   40] train: loss: 0.6913281
[Epoch 8] ogbg-molclintox: 0.453693 val loss: 0.688768
[Epoch 8] ogbg-molclintox: 0.496066 test loss: 0.689756
[Epoch 9; Iter    10/   40] train: loss: 0.6883451
[Epoch 9; Iter    40/   40] train: loss: 0.6899762
[Epoch 9] ogbg-molclintox: 0.481763 val loss: 0.686636
[Epoch 9] ogbg-molclintox: 0.497489 test loss: 0.688651
[Epoch 10; Iter    30/   40] train: loss: 0.6878768
[Epoch 10] ogbg-molclintox: 0.466354 val loss: 0.686224
[Epoch 10] ogbg-molclintox: 0.493455 test loss: 0.687543
[Epoch 11; Iter    20/   40] train: loss: 0.6849096
[Epoch 11] ogbg-molclintox: 0.473821 val loss: 0.684343
[Epoch 11] ogbg-molclintox: 0.503884 test loss: 0.686226
[Epoch 12; Iter    10/   40] train: loss: 0.6838738
[Epoch 12; Iter    40/   40] train: loss: 0.6859403
[Epoch 12] ogbg-molclintox: 0.482800 val loss: 0.683498
[Epoch 12] ogbg-molclintox: 0.501086 test loss: 0.685164
[Epoch 13; Iter    30/   40] train: loss: 0.6840032
[Epoch 13] ogbg-molclintox: 0.475044 val loss: 0.680580
[Epoch 13] ogbg-molclintox: 0.501912 test loss: 0.682924
[Epoch 14; Iter    20/   40] train: loss: 0.6812614
[Epoch 14] ogbg-molclintox: 0.494337 val loss: 0.678344
[Epoch 14] ogbg-molclintox: 0.498251 test loss: 0.680924
[Epoch 15; Iter    10/   40] train: loss: 0.6800463
[Epoch 15; Iter    40/   40] train: loss: 0.6766953
[Epoch 15] ogbg-molclintox: 0.483123 val loss: 0.677273
[Epoch 15] ogbg-molclintox: 0.507197 test loss: 0.679588
[Epoch 16; Iter    30/   40] train: loss: 0.6756249
[Epoch 16] ogbg-molclintox: 0.479553 val loss: 0.675650
[Epoch 16] ogbg-molclintox: 0.500761 test loss: 0.677696
[Epoch 17; Iter    20/   40] train: loss: 0.6745874
[Epoch 17] ogbg-molclintox: 0.482125 val loss: 0.672826
[Epoch 17] ogbg-molclintox: 0.504709 test loss: 0.675402
[Epoch 18; Iter    10/   40] train: loss: 0.6714396
[Epoch 18; Iter    40/   40] train: loss: 0.6601542
[Epoch 18] ogbg-molclintox: 0.704996 val loss: 0.653071
[Epoch 18] ogbg-molclintox: 0.634188 test loss: 0.669855
[Epoch 19; Iter    30/   40] train: loss: 0.6434895
[Epoch 19] ogbg-molclintox: 0.765684 val loss: 0.680171
[Epoch 19] ogbg-molclintox: 0.608602 test loss: 0.662226
[Epoch 20; Iter    20/   40] train: loss: 0.6146854
[Epoch 20] ogbg-molclintox: 0.679663 val loss: 0.634147
[Epoch 20] ogbg-molclintox: 0.560771 test loss: 0.596960
[Epoch 21; Iter    10/   40] train: loss: 0.5369684
[Epoch 21; Iter    40/   40] train: loss: 0.4754680
[Epoch 21] ogbg-molclintox: 0.711079 val loss: 0.532818
[Epoch 21] ogbg-molclintox: 0.663066 test loss: 0.512131
[Epoch 22; Iter    30/   40] train: loss: 0.4224999
[Epoch 22] ogbg-molclintox: 0.832589 val loss: 0.395449
[Epoch 22] ogbg-molclintox: 0.675523 test loss: 0.465073
[Epoch 23; Iter    20/   40] train: loss: 0.4295991
[Epoch 23] ogbg-molclintox: 0.698667 val loss: 0.438658
[Epoch 23] ogbg-molclintox: 0.645040 test loss: 0.375941
[Epoch 24; Iter    10/   40] train: loss: 0.3165945
[Epoch 24; Iter    40/   40] train: loss: 0.3532533
[Epoch 24] ogbg-molclintox: 0.758990 val loss: 0.277617
[Epoch 24] ogbg-molclintox: 0.701319 test loss: 0.351332
[Epoch 25; Iter    30/   40] train: loss: 0.3070916
[Epoch 25] ogbg-molclintox: 0.879527 val loss: 0.324053
[Epoch 25] ogbg-molclintox: 0.704539 test loss: 0.354807
[Epoch 26; Iter    20/   40] train: loss: 0.1932262
[Epoch 26] ogbg-molclintox: 0.889180 val loss: 0.205910
[Epoch 26] ogbg-molclintox: 0.608277 test loss: 0.280941
[Epoch 27; Iter    10/   40] train: loss: 0.2136182
[Epoch 27; Iter    40/   40] train: loss: 0.1810317
[Epoch 27] ogbg-molclintox: 0.807502 val loss: 0.198696
[Epoch 27] ogbg-molclintox: 0.673058 test loss: 0.247413
[Epoch 28; Iter    30/   40] train: loss: 0.2130024
[Epoch 28] ogbg-molclintox: 0.877144 val loss: 0.149172
[Epoch 28] ogbg-molclintox: 0.674298 test loss: 0.335700
[Epoch 29; Iter    20/   40] train: loss: 0.3423033
[Epoch 29] ogbg-molclintox: 0.838732 val loss: 0.146394
[Epoch 29] ogbg-molclintox: 0.698708 test loss: 0.233396
[Epoch 30; Iter    10/   40] train: loss: 0.1812040
[Epoch 30; Iter    40/   40] train: loss: 0.0976095
[Epoch 30] ogbg-molclintox: 0.852194 val loss: 0.142879
[Epoch 30] ogbg-molclintox: 0.631200 test loss: 0.240127
[Epoch 31; Iter    30/   40] train: loss: 0.2157429
[Epoch 31] ogbg-molclintox: 0.842478 val loss: 0.180818
[ Using Seed :  6  ]
using device:  cuda:1
Log directory:  runs/split/3DInfomax/clintox/scaff/train_prop=0.7/PNA_ogbg-molclintox_3DInfomax_clintox_scaff=0.7_6_26-05_09-18-13
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/clintox/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_scaff=0.7
logdir: runs/split/3DInfomax/clintox/scaff/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/   35] train: loss: 0.6894172
[Epoch 1] ogbg-molclintox: 0.497068 val loss: 0.692858
[Epoch 1] ogbg-molclintox: 0.469206 test loss: 0.691912
[Epoch 2; Iter    25/   35] train: loss: 0.6947442
[Epoch 2] ogbg-molclintox: 0.478193 val loss: 0.693592
[Epoch 2] ogbg-molclintox: 0.500675 test loss: 0.690165
[Epoch 3; Iter    20/   35] train: loss: 0.6926025
[Epoch 3] ogbg-molclintox: 0.453481 val loss: 0.693576
[Epoch 3] ogbg-molclintox: 0.498923 test loss: 0.688713
[Epoch 4; Iter    15/   35] train: loss: 0.6935095
[Epoch 4] ogbg-molclintox: 0.456949 val loss: 0.693420
[Epoch 4] ogbg-molclintox: 0.501927 test loss: 0.688438
[Epoch 5; Iter    10/   35] train: loss: 0.6919869
[Epoch 5] ogbg-molclintox: 0.446871 val loss: 0.692804
[Epoch 5] ogbg-molclintox: 0.497358 test loss: 0.687828
[Epoch 6; Iter     5/   35] train: loss: 0.6929004
[Epoch 6; Iter    35/   35] train: loss: 0.6910963
[Epoch 6] ogbg-molclintox: 0.458073 val loss: 0.692253
[Epoch 6] ogbg-molclintox: 0.503934 test loss: 0.686717
[Epoch 7; Iter    30/   35] train: loss: 0.6918077
[Epoch 7] ogbg-molclintox: 0.455979 val loss: 0.692033
[Epoch 7] ogbg-molclintox: 0.494546 test loss: 0.687134
[Epoch 8; Iter    25/   35] train: loss: 0.6903616
[Epoch 8] ogbg-molclintox: 0.467608 val loss: 0.690818
[Epoch 8] ogbg-molclintox: 0.508356 test loss: 0.685419
[Epoch 9; Iter    20/   35] train: loss: 0.6885281
[Epoch 9] ogbg-molclintox: 0.457912 val loss: 0.689557
[Epoch 9] ogbg-molclintox: 0.501202 test loss: 0.684128
[Epoch 10; Iter    15/   35] train: loss: 0.6876380
[Epoch 10] ogbg-molclintox: 0.468650 val loss: 0.689381
[Epoch 10] ogbg-molclintox: 0.502092 test loss: 0.684218
[Epoch 11; Iter    10/   35] train: loss: 0.6876528
[Epoch 11] ogbg-molclintox: 0.465505 val loss: 0.688446
[Epoch 11] ogbg-molclintox: 0.504932 test loss: 0.683017
[Epoch 12; Iter     5/   35] train: loss: 0.6858121
[Epoch 12; Iter    35/   35] train: loss: 0.6842408
[Epoch 12] ogbg-molclintox: 0.469086 val loss: 0.686810
[Epoch 12] ogbg-molclintox: 0.500788 test loss: 0.681028
[Epoch 13; Iter    30/   35] train: loss: 0.6835201
[Epoch 13] ogbg-molclintox: 0.475609 val loss: 0.686338
[Epoch 13] ogbg-molclintox: 0.500589 test loss: 0.680865
[Epoch 14; Iter    25/   35] train: loss: 0.6854627
[Epoch 14] ogbg-molclintox: 0.465676 val loss: 0.684609
[Epoch 14] ogbg-molclintox: 0.505521 test loss: 0.678926
[Epoch 15; Iter    20/   35] train: loss: 0.6831190
[Epoch 15] ogbg-molclintox: 0.460784 val loss: 0.683186
[Epoch 15] ogbg-molclintox: 0.496978 test loss: 0.677643
[Epoch 16; Iter    15/   35] train: loss: 0.6817734
[Epoch 16] ogbg-molclintox: 0.479671 val loss: 0.681981
[Epoch 16] ogbg-molclintox: 0.505470 test loss: 0.676330
[Epoch 17; Iter    10/   35] train: loss: 0.6792748
[Epoch 17] ogbg-molclintox: 0.472885 val loss: 0.680186
[Epoch 17] ogbg-molclintox: 0.500402 test loss: 0.674478
[Epoch 18; Iter     5/   35] train: loss: 0.6761583
[Epoch 18; Iter    35/   35] train: loss: 0.6739914
[Epoch 18] ogbg-molclintox: 0.478127 val loss: 0.678223
[Epoch 18] ogbg-molclintox: 0.501786 test loss: 0.672215
[Epoch 19; Iter    30/   35] train: loss: 0.6729228
[Epoch 19] ogbg-molclintox: 0.480859 val loss: 0.677112
[Epoch 19] ogbg-molclintox: 0.518951 test loss: 0.670736
[Epoch 20; Iter    25/   35] train: loss: 0.6732684
[Epoch 20] ogbg-molclintox: 0.685337 val loss: 0.686272
[Epoch 20] ogbg-molclintox: 0.551112 test loss: 0.677885
[Epoch 21; Iter    20/   35] train: loss: 0.6600699
[Epoch 21] ogbg-molclintox: 0.687172 val loss: 0.692479
[Epoch 21] ogbg-molclintox: 0.592246 test loss: 0.673009
[Epoch 22; Iter    15/   35] train: loss: 0.6245446
[Epoch 22] ogbg-molclintox: 0.724554 val loss: 0.662568
[Epoch 22] ogbg-molclintox: 0.614185 test loss: 0.644304
[Epoch 23; Iter    10/   35] train: loss: 0.6095034
[Epoch 23] ogbg-molclintox: 0.735861 val loss: 0.580509
[Epoch 23] ogbg-molclintox: 0.597388 test loss: 0.547001
[Epoch 24; Iter     5/   35] train: loss: 0.5579485
[Epoch 24; Iter    35/   35] train: loss: 0.4979330
[Epoch 24] ogbg-molclintox: 0.724678 val loss: 0.590553
[Epoch 24] ogbg-molclintox: 0.605296 test loss: 0.581579
[Epoch 25; Iter    30/   35] train: loss: 0.4380438
[Epoch 25] ogbg-molclintox: 0.752580 val loss: 0.492432
[Epoch 25] ogbg-molclintox: 0.647315 test loss: 0.481883
[Epoch 26; Iter    25/   35] train: loss: 0.4440945
[Epoch 26] ogbg-molclintox: 0.749550 val loss: 0.345640
[Epoch 26] ogbg-molclintox: 0.615262 test loss: 0.332177
[Epoch 27; Iter    20/   35] train: loss: 0.2695760
[Epoch 27] ogbg-molclintox: 0.772824 val loss: 0.408190
[Epoch 27] ogbg-molclintox: 0.661584 test loss: 0.381608
[Epoch 28; Iter    15/   35] train: loss: 0.2302574
[Epoch 28] ogbg-molclintox: 0.751822 val loss: 0.315451
[Epoch 28] ogbg-molclintox: 0.600132 test loss: 0.295999
[Epoch 29; Iter    10/   35] train: loss: 0.2805713
[Epoch 29] ogbg-molclintox: 0.772847 val loss: 0.268526
[Epoch 29] ogbg-molclintox: 0.681482 test loss: 0.236345
[Epoch 30; Iter     5/   35] train: loss: 0.2563228
[Epoch 30; Iter    35/   35] train: loss: 0.2633386
[Epoch 30] ogbg-molclintox: 0.745877 val loss: 0.279866
[Epoch 30] ogbg-molclintox: 0.705887 test loss: 0.249638
[Epoch 31; Iter    30/   35] train: loss: 0.2539424
[Epoch 31] ogbg-molclintox: 0.739276 val loss: 0.272191
[Epoch 31] ogbg-molclintox: 0.704350 test loss: 0.241658
[Epoch 32; Iter    25/   35] train: loss: 0.2525656
[Epoch 32] ogbg-molclintox: 0.787226 val loss: 0.243267
[Epoch 32] ogbg-molclintox: 0.686278 test loss: 0.213067
[ Using Seed :  4  ]
using device:  cuda:0
Log directory:  runs/split/3DInfomax/clintox/scaff/train_prop=0.6/PNA_ogbg-molclintox_3DInfomax_clintox_scaff=0.6_4_26-05_09-18-11
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/clintox/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_scaff=0.6
logdir: runs/split/3DInfomax/clintox/scaff/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/   30] train: loss: 0.6944867
[Epoch 1] ogbg-molclintox: 0.501187 val loss: 0.693136
[Epoch 1] ogbg-molclintox: 0.495096 test loss: 0.693102
[Epoch 2; Iter    30/   30] train: loss: 0.6928307
[Epoch 2] ogbg-molclintox: 0.493353 val loss: 0.692802
[Epoch 2] ogbg-molclintox: 0.491929 test loss: 0.693058
[Epoch 3; Iter    30/   30] train: loss: 0.6925985
[Epoch 3] ogbg-molclintox: 0.486668 val loss: 0.691474
[Epoch 3] ogbg-molclintox: 0.490317 test loss: 0.692669
[Epoch 4; Iter    30/   30] train: loss: 0.6918300
[Epoch 4] ogbg-molclintox: 0.483880 val loss: 0.691167
[Epoch 4] ogbg-molclintox: 0.485026 test loss: 0.692508
[Epoch 5; Iter    30/   30] train: loss: 0.6927167
[Epoch 5] ogbg-molclintox: 0.487644 val loss: 0.689764
[Epoch 5] ogbg-molclintox: 0.477908 test loss: 0.691510
[Epoch 6; Iter    30/   30] train: loss: 0.6914400
[Epoch 6] ogbg-molclintox: 0.485283 val loss: 0.690331
[Epoch 6] ogbg-molclintox: 0.483700 test loss: 0.691909
[Epoch 7; Iter    30/   30] train: loss: 0.6911881
[Epoch 7] ogbg-molclintox: 0.488004 val loss: 0.689349
[Epoch 7] ogbg-molclintox: 0.484425 test loss: 0.690836
[Epoch 8; Iter    30/   30] train: loss: 0.6919422
[Epoch 8] ogbg-molclintox: 0.483612 val loss: 0.689105
[Epoch 8] ogbg-molclintox: 0.492586 test loss: 0.690472
[Epoch 9; Iter    30/   30] train: loss: 0.6898082
[Epoch 9] ogbg-molclintox: 0.488151 val loss: 0.687412
[Epoch 9] ogbg-molclintox: 0.496448 test loss: 0.688758
[Epoch 10; Iter    30/   30] train: loss: 0.6888427
[Epoch 10] ogbg-molclintox: 0.491881 val loss: 0.687713
[Epoch 10] ogbg-molclintox: 0.488862 test loss: 0.689061
[Epoch 11; Iter    30/   30] train: loss: 0.6881445
[Epoch 11] ogbg-molclintox: 0.487930 val loss: 0.686788
[Epoch 11] ogbg-molclintox: 0.495054 test loss: 0.688068
[Epoch 12; Iter    30/   30] train: loss: 0.6866884
[Epoch 12] ogbg-molclintox: 0.489108 val loss: 0.686461
[Epoch 12] ogbg-molclintox: 0.494383 test loss: 0.687643
[Epoch 13; Iter    30/   30] train: loss: 0.6861467
[Epoch 13] ogbg-molclintox: 0.490170 val loss: 0.685701
[Epoch 13] ogbg-molclintox: 0.495282 test loss: 0.686744
[Epoch 14; Iter    30/   30] train: loss: 0.6848439
[Epoch 14] ogbg-molclintox: 0.489596 val loss: 0.683696
[Epoch 14] ogbg-molclintox: 0.493163 test loss: 0.685130
[Epoch 15; Iter    30/   30] train: loss: 0.6875782
[Epoch 15] ogbg-molclintox: 0.491294 val loss: 0.683264
[Epoch 15] ogbg-molclintox: 0.500374 test loss: 0.684232
[Epoch 16; Iter    30/   30] train: loss: 0.6825119
[Epoch 16] ogbg-molclintox: 0.489656 val loss: 0.682956
[Epoch 16] ogbg-molclintox: 0.494731 test loss: 0.683862
[Epoch 17; Iter    30/   30] train: loss: 0.6834695
[Epoch 17] ogbg-molclintox: 0.489849 val loss: 0.681120
[Epoch 17] ogbg-molclintox: 0.502503 test loss: 0.681868
[Epoch 18; Iter    30/   30] train: loss: 0.6826528
[Epoch 18] ogbg-molclintox: 0.485585 val loss: 0.680219
[Epoch 18] ogbg-molclintox: 0.503392 test loss: 0.680695
[Epoch 19; Iter    30/   30] train: loss: 0.6792282
[Epoch 19] ogbg-molclintox: 0.485645 val loss: 0.678404
[Epoch 19] ogbg-molclintox: 0.505785 test loss: 0.678868
[Epoch 20; Iter    30/   30] train: loss: 0.6810931
[Epoch 20] ogbg-molclintox: 0.493379 val loss: 0.678192
[Epoch 20] ogbg-molclintox: 0.505738 test loss: 0.678366
[Epoch 21; Iter    30/   30] train: loss: 0.6811414
[Epoch 21] ogbg-molclintox: 0.485431 val loss: 0.676503
[Epoch 21] ogbg-molclintox: 0.511613 test loss: 0.676460
[Epoch 22; Iter    30/   30] train: loss: 0.6786594
[Epoch 22] ogbg-molclintox: 0.489990 val loss: 0.674178
[Epoch 22] ogbg-molclintox: 0.512803 test loss: 0.674591
[Epoch 23; Iter    30/   30] train: loss: 0.6728641
[Epoch 23] ogbg-molclintox: 0.546180 val loss: 0.680490
[Epoch 23] ogbg-molclintox: 0.584374 test loss: 0.676882
[Epoch 24; Iter    30/   30] train: loss: 0.6581809
[Epoch 24] ogbg-molclintox: 0.605619 val loss: 0.703727
[Epoch 24] ogbg-molclintox: 0.645916 test loss: 0.679788
[Epoch 25; Iter    30/   30] train: loss: 0.6306469
[Epoch 25] ogbg-molclintox: 0.607632 val loss: 0.685635
[Epoch 25] ogbg-molclintox: 0.671507 test loss: 0.640686
[Epoch 26; Iter    30/   30] train: loss: 0.5897762
[Epoch 26] ogbg-molclintox: 0.635809 val loss: 0.723862
[Epoch 26] ogbg-molclintox: 0.661769 test loss: 0.661472
[Epoch 27; Iter    30/   30] train: loss: 0.5338179
[Epoch 27] ogbg-molclintox: 0.662222 val loss: 0.549090
[Epoch 27] ogbg-molclintox: 0.668129 test loss: 0.511128
[Epoch 28; Iter    30/   30] train: loss: 0.5197785
[Epoch 28] ogbg-molclintox: 0.634881 val loss: 0.605376
[Epoch 28] ogbg-molclintox: 0.683896 test loss: 0.579425
[Epoch 29; Iter    30/   30] train: loss: 0.4039052
[Epoch 29] ogbg-molclintox: 0.653692 val loss: 0.411826
[Epoch 29] ogbg-molclintox: 0.695020 test loss: 0.386004
[Epoch 30; Iter    30/   30] train: loss: 0.3421558
[Epoch 30] ogbg-molclintox: 0.634072 val loss: 0.502036
[Epoch 30] ogbg-molclintox: 0.701935 test loss: 0.439757
[Epoch 31; Iter    30/   30] train: loss: 0.3383249
[Epoch 31] ogbg-molclintox: 0.617065 val loss: 0.427330
[Epoch 31] ogbg-molclintox: 0.681866 test loss: 0.370246
[Epoch 32; Iter    30/   30] train: loss: 0.2262088
[Epoch 32] ogbg-molclintox: 0.680204 val loss: 0.412287
[Epoch 32] ogbg-molclintox: 0.661355 test loss: 0.352063
[Epoch 33; Iter    30/   30] train: loss: 0.2399263
[Epoch 33] ogbg-molclintox: 0.717293 val loss: 0.347375
[Epoch 33] ogbg-molclintox: 0.691931 test loss: 0.310191
[Epoch 34; Iter    30/   30] train: loss: 0.1969940
[Epoch 34] ogbg-molclintox: 0.670484 val loss: 0.407362
[ Using Seed :  5  ]
using device:  cuda:1
Log directory:  runs/split/3DInfomax/clintox/scaff/train_prop=0.7/PNA_ogbg-molclintox_3DInfomax_clintox_scaff=0.7_5_26-05_09-18-13
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/clintox/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_scaff=0.7
logdir: runs/split/3DInfomax/clintox/scaff/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/   35] train: loss: 0.6931309
[Epoch 1] ogbg-molclintox: 0.582591 val loss: 0.693493
[Epoch 1] ogbg-molclintox: 0.605013 test loss: 0.693480
[Epoch 2; Iter    25/   35] train: loss: 0.6930714
[Epoch 2] ogbg-molclintox: 0.547864 val loss: 0.692852
[Epoch 2] ogbg-molclintox: 0.644617 test loss: 0.693014
[Epoch 3; Iter    20/   35] train: loss: 0.6928923
[Epoch 3] ogbg-molclintox: 0.560395 val loss: 0.692662
[Epoch 3] ogbg-molclintox: 0.652026 test loss: 0.692547
[Epoch 4; Iter    15/   35] train: loss: 0.6923447
[Epoch 4] ogbg-molclintox: 0.575364 val loss: 0.693247
[Epoch 4] ogbg-molclintox: 0.655251 test loss: 0.693111
[Epoch 5; Iter    10/   35] train: loss: 0.6919950
[Epoch 5] ogbg-molclintox: 0.569417 val loss: 0.692161
[Epoch 5] ogbg-molclintox: 0.653205 test loss: 0.691850
[Epoch 6; Iter     5/   35] train: loss: 0.6925192
[Epoch 6; Iter    35/   35] train: loss: 0.6915823
[Epoch 6] ogbg-molclintox: 0.574670 val loss: 0.692343
[Epoch 6] ogbg-molclintox: 0.652281 test loss: 0.692239
[Epoch 7; Iter    30/   35] train: loss: 0.6917108
[Epoch 7] ogbg-molclintox: 0.564863 val loss: 0.690972
[Epoch 7] ogbg-molclintox: 0.653403 test loss: 0.690621
[Epoch 8; Iter    25/   35] train: loss: 0.6907886
[Epoch 8] ogbg-molclintox: 0.575426 val loss: 0.690915
[Epoch 8] ogbg-molclintox: 0.655523 test loss: 0.690447
[Epoch 9; Iter    20/   35] train: loss: 0.6911180
[Epoch 9] ogbg-molclintox: 0.563698 val loss: 0.690010
[Epoch 9] ogbg-molclintox: 0.650858 test loss: 0.689779
[Epoch 10; Iter    15/   35] train: loss: 0.6894090
[Epoch 10] ogbg-molclintox: 0.575909 val loss: 0.689487
[Epoch 10] ogbg-molclintox: 0.655609 test loss: 0.689158
[Epoch 11; Iter    10/   35] train: loss: 0.6883299
[Epoch 11] ogbg-molclintox: 0.571276 val loss: 0.688843
[Epoch 11] ogbg-molclintox: 0.646669 test loss: 0.688275
[Epoch 12; Iter     5/   35] train: loss: 0.6885483
[Epoch 12; Iter    35/   35] train: loss: 0.6866606
[Epoch 12] ogbg-molclintox: 0.575822 val loss: 0.687667
[Epoch 12] ogbg-molclintox: 0.655098 test loss: 0.687381
[Epoch 13; Iter    30/   35] train: loss: 0.6864733
[Epoch 13] ogbg-molclintox: 0.573422 val loss: 0.686685
[Epoch 13] ogbg-molclintox: 0.647927 test loss: 0.686219
[Epoch 14; Iter    25/   35] train: loss: 0.6860126
[Epoch 14] ogbg-molclintox: 0.577483 val loss: 0.685833
[Epoch 14] ogbg-molclintox: 0.654084 test loss: 0.685034
[Epoch 15; Iter    20/   35] train: loss: 0.6841166
[Epoch 15] ogbg-molclintox: 0.580378 val loss: 0.684577
[Epoch 15] ogbg-molclintox: 0.656011 test loss: 0.683816
[Epoch 16; Iter    15/   35] train: loss: 0.6811808
[Epoch 16] ogbg-molclintox: 0.574693 val loss: 0.683289
[Epoch 16] ogbg-molclintox: 0.646765 test loss: 0.682786
[Epoch 17; Iter    10/   35] train: loss: 0.6822464
[Epoch 17] ogbg-molclintox: 0.584142 val loss: 0.682237
[Epoch 17] ogbg-molclintox: 0.658959 test loss: 0.681506
[Epoch 18; Iter     5/   35] train: loss: 0.6808546
[Epoch 18; Iter    35/   35] train: loss: 0.6829891
[Epoch 18] ogbg-molclintox: 0.583389 val loss: 0.681059
[Epoch 18] ogbg-molclintox: 0.655076 test loss: 0.680221
[Epoch 19; Iter    30/   35] train: loss: 0.6792501
[Epoch 19] ogbg-molclintox: 0.595857 val loss: 0.679924
[Epoch 19] ogbg-molclintox: 0.649180 test loss: 0.678900
[Epoch 20; Iter    25/   35] train: loss: 0.6756275
[Epoch 20] ogbg-molclintox: 0.698275 val loss: 0.685708
[Epoch 20] ogbg-molclintox: 0.610041 test loss: 0.679226
[Epoch 21; Iter    20/   35] train: loss: 0.6708728
[Epoch 21] ogbg-molclintox: 0.694525 val loss: 0.692196
[Epoch 21] ogbg-molclintox: 0.591140 test loss: 0.673875
[Epoch 22; Iter    15/   35] train: loss: 0.6246984
[Epoch 22] ogbg-molclintox: 0.706598 val loss: 0.692069
[Epoch 22] ogbg-molclintox: 0.585460 test loss: 0.666241
[Epoch 23; Iter    10/   35] train: loss: 0.5911976
[Epoch 23] ogbg-molclintox: 0.718117 val loss: 0.514965
[Epoch 23] ogbg-molclintox: 0.602819 test loss: 0.513189
[Epoch 24; Iter     5/   35] train: loss: 0.5537026
[Epoch 24; Iter    35/   35] train: loss: 0.4594098
[Epoch 24] ogbg-molclintox: 0.719851 val loss: 0.548017
[Epoch 24] ogbg-molclintox: 0.642530 test loss: 0.543002
[Epoch 25; Iter    30/   35] train: loss: 0.4351848
[Epoch 25] ogbg-molclintox: 0.723560 val loss: 0.464349
[Epoch 25] ogbg-molclintox: 0.634389 test loss: 0.462496
[Epoch 26; Iter    25/   35] train: loss: 0.3305568
[Epoch 26] ogbg-molclintox: 0.738595 val loss: 0.394659
[Epoch 26] ogbg-molclintox: 0.639157 test loss: 0.392306
[Epoch 27; Iter    20/   35] train: loss: 0.2993216
[Epoch 27] ogbg-molclintox: 0.728724 val loss: 0.383853
[Epoch 27] ogbg-molclintox: 0.615880 test loss: 0.379049
[Epoch 28; Iter    15/   35] train: loss: 0.3149242
[Epoch 28] ogbg-molclintox: 0.730804 val loss: 0.333497
[Epoch 28] ogbg-molclintox: 0.645432 test loss: 0.321078
[Epoch 29; Iter    10/   35] train: loss: 0.2922310
[Epoch 29] ogbg-molclintox: 0.765169 val loss: 0.277269
[Epoch 29] ogbg-molclintox: 0.683834 test loss: 0.302563
[Epoch 30; Iter     5/   35] train: loss: 0.2904559
[Epoch 30; Iter    35/   35] train: loss: 0.1303249
[Epoch 30] ogbg-molclintox: 0.783048 val loss: 0.278414
[Epoch 30] ogbg-molclintox: 0.602104 test loss: 0.280437
[Epoch 31; Iter    30/   35] train: loss: 0.1476864
[Epoch 31] ogbg-molclintox: 0.771760 val loss: 0.254886
[Epoch 31] ogbg-molclintox: 0.593697 test loss: 0.269081
[Epoch 32; Iter    25/   35] train: loss: 0.2710709
[Epoch 32] ogbg-molclintox: 0.763731 val loss: 0.267848
[Epoch 32] ogbg-molclintox: 0.645450 test loss: 0.267312
[ Using Seed :  6  ]
using device:  cuda:2
Log directory:  runs/split/3DInfomax/clintox/scaff/train_prop=0.8/PNA_ogbg-molclintox_3DInfomax_clintox_scaff=0.8_6_26-05_09-18-13
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/clintox/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_scaff=0.8
logdir: runs/split/3DInfomax/clintox/scaff/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/   40] train: loss: 0.6934478
[Epoch 1] ogbg-molclintox: 0.487903 val loss: 0.692126
[Epoch 1] ogbg-molclintox: 0.471031 test loss: 0.692166
[Epoch 2; Iter    20/   40] train: loss: 0.6932403
[Epoch 2] ogbg-molclintox: 0.444307 val loss: 0.690806
[Epoch 2] ogbg-molclintox: 0.478263 test loss: 0.691136
[Epoch 3; Iter    10/   40] train: loss: 0.6932287
[Epoch 3; Iter    40/   40] train: loss: 0.6925523
[Epoch 3] ogbg-molclintox: 0.433867 val loss: 0.689739
[Epoch 3] ogbg-molclintox: 0.483372 test loss: 0.690132
[Epoch 4; Iter    30/   40] train: loss: 0.6920084
[Epoch 4] ogbg-molclintox: 0.430669 val loss: 0.690009
[Epoch 4] ogbg-molclintox: 0.482173 test loss: 0.690224
[Epoch 5; Iter    20/   40] train: loss: 0.6925848
[Epoch 5] ogbg-molclintox: 0.450274 val loss: 0.689134
[Epoch 5] ogbg-molclintox: 0.486932 test loss: 0.689449
[Epoch 6; Iter    10/   40] train: loss: 0.6908295
[Epoch 6; Iter    40/   40] train: loss: 0.6904486
[Epoch 6] ogbg-molclintox: 0.429422 val loss: 0.688672
[Epoch 6] ogbg-molclintox: 0.484321 test loss: 0.688949
[Epoch 7; Iter    30/   40] train: loss: 0.6899174
[Epoch 7] ogbg-molclintox: 0.453008 val loss: 0.687762
[Epoch 7] ogbg-molclintox: 0.468596 test loss: 0.687863
[Epoch 8; Iter    20/   40] train: loss: 0.6886778
[Epoch 8] ogbg-molclintox: 0.463048 val loss: 0.685917
[Epoch 8] ogbg-molclintox: 0.487470 test loss: 0.686741
[Epoch 9; Iter    10/   40] train: loss: 0.6890686
[Epoch 9; Iter    40/   40] train: loss: 0.6866022
[Epoch 9] ogbg-molclintox: 0.443306 val loss: 0.685542
[Epoch 9] ogbg-molclintox: 0.487795 test loss: 0.685763
[Epoch 10; Iter    30/   40] train: loss: 0.6862919
[Epoch 10] ogbg-molclintox: 0.467356 val loss: 0.683264
[Epoch 10] ogbg-molclintox: 0.482547 test loss: 0.684032
[Epoch 11; Iter    20/   40] train: loss: 0.6848166
[Epoch 11] ogbg-molclintox: 0.458965 val loss: 0.682190
[Epoch 11] ogbg-molclintox: 0.485797 test loss: 0.682923
[Epoch 12; Iter    10/   40] train: loss: 0.6851652
[Epoch 12; Iter    40/   40] train: loss: 0.6820204
[Epoch 12] ogbg-molclintox: 0.467855 val loss: 0.680804
[Epoch 12] ogbg-molclintox: 0.485147 test loss: 0.682291
[Epoch 13; Iter    30/   40] train: loss: 0.6852475
[Epoch 13] ogbg-molclintox: 0.458715 val loss: 0.678089
[Epoch 13] ogbg-molclintox: 0.484310 test loss: 0.679402
[Epoch 14; Iter    20/   40] train: loss: 0.6790775
[Epoch 14] ogbg-molclintox: 0.450896 val loss: 0.677733
[Epoch 14] ogbg-molclintox: 0.487283 test loss: 0.678875
[Epoch 15; Iter    10/   40] train: loss: 0.6796404
[Epoch 15; Iter    40/   40] train: loss: 0.6757994
[Epoch 15] ogbg-molclintox: 0.491505 val loss: 0.675888
[Epoch 15] ogbg-molclintox: 0.493054 test loss: 0.677443
[Epoch 16; Iter    30/   40] train: loss: 0.6742938
[Epoch 16] ogbg-molclintox: 0.481254 val loss: 0.671603
[Epoch 16] ogbg-molclintox: 0.491105 test loss: 0.673235
[Epoch 17; Iter    20/   40] train: loss: 0.6734114
[Epoch 17] ogbg-molclintox: 0.482878 val loss: 0.668616
[Epoch 17] ogbg-molclintox: 0.496439 test loss: 0.670941
[Epoch 18; Iter    10/   40] train: loss: 0.6707343
[Epoch 18; Iter    40/   40] train: loss: 0.6629328
[Epoch 18] ogbg-molclintox: 0.687514 val loss: 0.673913
[Epoch 18] ogbg-molclintox: 0.616502 test loss: 0.691955
[Epoch 19; Iter    30/   40] train: loss: 0.6441582
[Epoch 19] ogbg-molclintox: 0.734377 val loss: 0.647526
[Epoch 19] ogbg-molclintox: 0.619822 test loss: 0.648917
[Epoch 20; Iter    20/   40] train: loss: 0.6314338
[Epoch 20] ogbg-molclintox: 0.802947 val loss: 0.580672
[Epoch 20] ogbg-molclintox: 0.577808 test loss: 0.560349
[Epoch 21; Iter    10/   40] train: loss: 0.5436885
[Epoch 21; Iter    40/   40] train: loss: 0.4815641
[Epoch 21] ogbg-molclintox: 0.784752 val loss: 0.452325
[Epoch 21] ogbg-molclintox: 0.627252 test loss: 0.497630
[Epoch 22; Iter    30/   40] train: loss: 0.4441553
[Epoch 22] ogbg-molclintox: 0.733580 val loss: 0.437480
[Epoch 22] ogbg-molclintox: 0.672524 test loss: 0.480988
[Epoch 23; Iter    20/   40] train: loss: 0.4067132
[Epoch 23] ogbg-molclintox: 0.807639 val loss: 0.439307
[Epoch 23] ogbg-molclintox: 0.745216 test loss: 0.517334
[Epoch 24; Iter    10/   40] train: loss: 0.3762583
[Epoch 24; Iter    40/   40] train: loss: 0.2670995
[Epoch 24] ogbg-molclintox: 0.723603 val loss: 0.250404
[Epoch 24] ogbg-molclintox: 0.623483 test loss: 0.336670
[Epoch 25; Iter    30/   40] train: loss: 0.2167194
[Epoch 25] ogbg-molclintox: 0.755669 val loss: 0.244063
[Epoch 25] ogbg-molclintox: 0.730174 test loss: 0.298607
[Epoch 26; Iter    20/   40] train: loss: 0.2779230
[Epoch 26] ogbg-molclintox: 0.760051 val loss: 0.395770
[Epoch 26] ogbg-molclintox: 0.701566 test loss: 0.309540
[Epoch 27; Iter    10/   40] train: loss: 0.2270784
[Epoch 27; Iter    40/   40] train: loss: 0.1072790
[Epoch 27] ogbg-molclintox: 0.822124 val loss: 0.192718
[Epoch 27] ogbg-molclintox: 0.667664 test loss: 0.279213
[Epoch 28; Iter    30/   40] train: loss: 0.2387445
[Epoch 28] ogbg-molclintox: 0.770867 val loss: 0.242338
[Epoch 28] ogbg-molclintox: 0.595909 test loss: 0.283054
[Epoch 29; Iter    20/   40] train: loss: 0.2415772
[Epoch 29] ogbg-molclintox: 0.790582 val loss: 0.150508
[Epoch 29] ogbg-molclintox: 0.684742 test loss: 0.235386
[Epoch 30; Iter    10/   40] train: loss: 0.2692940
[Epoch 30; Iter    40/   40] train: loss: 0.1143826
[Epoch 30] ogbg-molclintox: 0.858175 val loss: 0.198107
[Epoch 30] ogbg-molclintox: 0.670697 test loss: 0.256192
[Epoch 31; Iter    30/   40] train: loss: 0.2725683
[Epoch 31] ogbg-molclintox: 0.860983 val loss: 0.145708
[ Using Seed :  4  ]
using device:  cuda:1
Log directory:  runs/split/3DInfomax/clintox/scaff/train_prop=0.7/PNA_ogbg-molclintox_3DInfomax_clintox_scaff=0.7_4_26-05_09-18-13
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/clintox/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_scaff=0.7
logdir: runs/split/3DInfomax/clintox/scaff/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/   35] train: loss: 0.6919692
[Epoch 1] ogbg-molclintox: 0.527764 val loss: 0.692959
[Epoch 1] ogbg-molclintox: 0.476917 test loss: 0.693070
[Epoch 2; Iter    25/   35] train: loss: 0.6924950
[Epoch 2] ogbg-molclintox: 0.527240 val loss: 0.692189
[Epoch 2] ogbg-molclintox: 0.484292 test loss: 0.692569
[Epoch 3; Iter    20/   35] train: loss: 0.6939953
[Epoch 3] ogbg-molclintox: 0.530857 val loss: 0.690800
[Epoch 3] ogbg-molclintox: 0.492682 test loss: 0.691410
[Epoch 4; Iter    15/   35] train: loss: 0.6931772
[Epoch 4] ogbg-molclintox: 0.533063 val loss: 0.691070
[Epoch 4] ogbg-molclintox: 0.492745 test loss: 0.691771
[Epoch 5; Iter    10/   35] train: loss: 0.6922648
[Epoch 5] ogbg-molclintox: 0.532107 val loss: 0.690078
[Epoch 5] ogbg-molclintox: 0.485046 test loss: 0.690662
[Epoch 6; Iter     5/   35] train: loss: 0.6919827
[Epoch 6; Iter    35/   35] train: loss: 0.6919515
[Epoch 6] ogbg-molclintox: 0.538599 val loss: 0.689917
[Epoch 6] ogbg-molclintox: 0.498879 test loss: 0.690283
[Epoch 7; Iter    30/   35] train: loss: 0.6921222
[Epoch 7] ogbg-molclintox: 0.543725 val loss: 0.688757
[Epoch 7] ogbg-molclintox: 0.488901 test loss: 0.689517
[Epoch 8; Iter    25/   35] train: loss: 0.6918529
[Epoch 8] ogbg-molclintox: 0.533124 val loss: 0.688491
[Epoch 8] ogbg-molclintox: 0.493153 test loss: 0.689027
[Epoch 9; Iter    20/   35] train: loss: 0.6888868
[Epoch 9] ogbg-molclintox: 0.534969 val loss: 0.687593
[Epoch 9] ogbg-molclintox: 0.503952 test loss: 0.687783
[Epoch 10; Iter    15/   35] train: loss: 0.6881587
[Epoch 10] ogbg-molclintox: 0.533647 val loss: 0.687000
[Epoch 10] ogbg-molclintox: 0.501158 test loss: 0.687215
[Epoch 11; Iter    10/   35] train: loss: 0.6890491
[Epoch 11] ogbg-molclintox: 0.535489 val loss: 0.686068
[Epoch 11] ogbg-molclintox: 0.495970 test loss: 0.686251
[Epoch 12; Iter     5/   35] train: loss: 0.6868868
[Epoch 12; Iter    35/   35] train: loss: 0.6881945
[Epoch 12] ogbg-molclintox: 0.534797 val loss: 0.684879
[Epoch 12] ogbg-molclintox: 0.498907 test loss: 0.685199
[Epoch 13; Iter    30/   35] train: loss: 0.6838323
[Epoch 13] ogbg-molclintox: 0.534882 val loss: 0.683274
[Epoch 13] ogbg-molclintox: 0.500012 test loss: 0.683216
[Epoch 14; Iter    25/   35] train: loss: 0.6833413
[Epoch 14] ogbg-molclintox: 0.546858 val loss: 0.682317
[Epoch 14] ogbg-molclintox: 0.502966 test loss: 0.682120
[Epoch 15; Iter    20/   35] train: loss: 0.6828517
[Epoch 15] ogbg-molclintox: 0.545520 val loss: 0.681167
[Epoch 15] ogbg-molclintox: 0.496243 test loss: 0.681288
[Epoch 16; Iter    15/   35] train: loss: 0.6800821
[Epoch 16] ogbg-molclintox: 0.549222 val loss: 0.680063
[Epoch 16] ogbg-molclintox: 0.497076 test loss: 0.680045
[Epoch 17; Iter    10/   35] train: loss: 0.6804727
[Epoch 17] ogbg-molclintox: 0.546411 val loss: 0.678067
[Epoch 17] ogbg-molclintox: 0.504831 test loss: 0.677508
[Epoch 18; Iter     5/   35] train: loss: 0.6791893
[Epoch 18; Iter    35/   35] train: loss: 0.6749530
[Epoch 18] ogbg-molclintox: 0.550549 val loss: 0.676148
[Epoch 18] ogbg-molclintox: 0.498567 test loss: 0.675855
[Epoch 19; Iter    30/   35] train: loss: 0.6751904
[Epoch 19] ogbg-molclintox: 0.549978 val loss: 0.674883
[Epoch 19] ogbg-molclintox: 0.500818 test loss: 0.674097
[Epoch 20; Iter    25/   35] train: loss: 0.6716946
[Epoch 20] ogbg-molclintox: 0.674751 val loss: 0.681198
[Epoch 20] ogbg-molclintox: 0.595891 test loss: 0.675572
[Epoch 21; Iter    20/   35] train: loss: 0.6597311
[Epoch 21] ogbg-molclintox: 0.707580 val loss: 0.687184
[Epoch 21] ogbg-molclintox: 0.584547 test loss: 0.670123
[Epoch 22; Iter    15/   35] train: loss: 0.6283587
[Epoch 22] ogbg-molclintox: 0.710315 val loss: 0.672358
[Epoch 22] ogbg-molclintox: 0.613199 test loss: 0.657520
[Epoch 23; Iter    10/   35] train: loss: 0.5913277
[Epoch 23] ogbg-molclintox: 0.741641 val loss: 0.573199
[Epoch 23] ogbg-molclintox: 0.605245 test loss: 0.553611
[Epoch 24; Iter     5/   35] train: loss: 0.5401227
[Epoch 24; Iter    35/   35] train: loss: 0.5228423
[Epoch 24] ogbg-molclintox: 0.688232 val loss: 0.581011
[Epoch 24] ogbg-molclintox: 0.672479 test loss: 0.569304
[Epoch 25; Iter    30/   35] train: loss: 0.4753720
[Epoch 25] ogbg-molclintox: 0.692010 val loss: 0.523132
[Epoch 25] ogbg-molclintox: 0.667094 test loss: 0.513077
[Epoch 26; Iter    25/   35] train: loss: 0.4268534
[Epoch 26] ogbg-molclintox: 0.746939 val loss: 0.427676
[Epoch 26] ogbg-molclintox: 0.669651 test loss: 0.410651
[Epoch 27; Iter    20/   35] train: loss: 0.3525230
[Epoch 27] ogbg-molclintox: 0.721196 val loss: 0.307827
[Epoch 27] ogbg-molclintox: 0.655053 test loss: 0.281722
[Epoch 28; Iter    15/   35] train: loss: 0.4381572
[Epoch 28] ogbg-molclintox: 0.771389 val loss: 0.323651
[Epoch 28] ogbg-molclintox: 0.629667 test loss: 0.304790
[Epoch 29; Iter    10/   35] train: loss: 0.2440966
[Epoch 29] ogbg-molclintox: 0.701616 val loss: 0.333756
[Epoch 29] ogbg-molclintox: 0.640517 test loss: 0.307338
[Epoch 30; Iter     5/   35] train: loss: 0.3081316
[Epoch 30; Iter    35/   35] train: loss: 0.2405018
[Epoch 30] ogbg-molclintox: 0.756423 val loss: 0.282835
[Epoch 30] ogbg-molclintox: 0.618862 test loss: 0.266599
[Epoch 31; Iter    30/   35] train: loss: 0.2665949
[Epoch 31] ogbg-molclintox: 0.711351 val loss: 0.272691
[Epoch 31] ogbg-molclintox: 0.658959 test loss: 0.257194
[Epoch 32; Iter    25/   35] train: loss: 0.1680813
[Epoch 32] ogbg-molclintox: 0.731710 val loss: 0.259223
[Epoch 32] ogbg-molclintox: 0.632717 test loss: 0.238200
[ Using Seed :  6  ]
using device:  cuda:0
Log directory:  runs/split/3DInfomax/clintox/scaff/train_prop=0.6/PNA_ogbg-molclintox_3DInfomax_clintox_scaff=0.6_6_26-05_09-18-13
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/clintox/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_scaff=0.6
logdir: runs/split/3DInfomax/clintox/scaff/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/   30] train: loss: 0.6927177
[Epoch 1] ogbg-molclintox: 0.487841 val loss: 0.692582
[Epoch 1] ogbg-molclintox: 0.476809 test loss: 0.692275
[Epoch 2; Iter    30/   30] train: loss: 0.6916473
[Epoch 2] ogbg-molclintox: 0.502367 val loss: 0.691917
[Epoch 2] ogbg-molclintox: 0.474868 test loss: 0.691190
[Epoch 3; Iter    30/   30] train: loss: 0.6921510
[Epoch 3] ogbg-molclintox: 0.477271 val loss: 0.691862
[Epoch 3] ogbg-molclintox: 0.465050 test loss: 0.690959
[Epoch 4; Iter    30/   30] train: loss: 0.6912996
[Epoch 4] ogbg-molclintox: 0.477284 val loss: 0.691459
[Epoch 4] ogbg-molclintox: 0.461330 test loss: 0.690618
[Epoch 5; Iter    30/   30] train: loss: 0.6907143
[Epoch 5] ogbg-molclintox: 0.478521 val loss: 0.691179
[Epoch 5] ogbg-molclintox: 0.461736 test loss: 0.690355
[Epoch 6; Iter    30/   30] train: loss: 0.6916488
[Epoch 6] ogbg-molclintox: 0.472698 val loss: 0.690398
[Epoch 6] ogbg-molclintox: 0.466945 test loss: 0.689098
[Epoch 7; Iter    30/   30] train: loss: 0.6917086
[Epoch 7] ogbg-molclintox: 0.485494 val loss: 0.690224
[Epoch 7] ogbg-molclintox: 0.467875 test loss: 0.689228
[Epoch 8; Iter    30/   30] train: loss: 0.6913750
[Epoch 8] ogbg-molclintox: 0.470680 val loss: 0.689113
[Epoch 8] ogbg-molclintox: 0.471041 test loss: 0.687662
[Epoch 9; Iter    30/   30] train: loss: 0.6896604
[Epoch 9] ogbg-molclintox: 0.482793 val loss: 0.689096
[Epoch 9] ogbg-molclintox: 0.467817 test loss: 0.687964
[Epoch 10; Iter    30/   30] train: loss: 0.6882946
[Epoch 10] ogbg-molclintox: 0.477699 val loss: 0.687916
[Epoch 10] ogbg-molclintox: 0.479150 test loss: 0.686616
[Epoch 11; Iter    30/   30] train: loss: 0.6872087
[Epoch 11] ogbg-molclintox: 0.484318 val loss: 0.687085
[Epoch 11] ogbg-molclintox: 0.466812 test loss: 0.686073
[Epoch 12; Iter    30/   30] train: loss: 0.6879084
[Epoch 12] ogbg-molclintox: 0.492874 val loss: 0.687749
[Epoch 12] ogbg-molclintox: 0.463762 test loss: 0.686483
[Epoch 13; Iter    30/   30] train: loss: 0.6858157
[Epoch 13] ogbg-molclintox: 0.484792 val loss: 0.686655
[Epoch 13] ogbg-molclintox: 0.474818 test loss: 0.685361
[Epoch 14; Iter    30/   30] train: loss: 0.6872701
[Epoch 14] ogbg-molclintox: 0.476134 val loss: 0.684686
[Epoch 14] ogbg-molclintox: 0.474548 test loss: 0.682945
[Epoch 15; Iter    30/   30] train: loss: 0.6848338
[Epoch 15] ogbg-molclintox: 0.480152 val loss: 0.683785
[Epoch 15] ogbg-molclintox: 0.487693 test loss: 0.682163
[Epoch 16; Iter    30/   30] train: loss: 0.6863791
[Epoch 16] ogbg-molclintox: 0.480500 val loss: 0.682730
[Epoch 16] ogbg-molclintox: 0.474964 test loss: 0.681257
[Epoch 17; Iter    30/   30] train: loss: 0.6812262
[Epoch 17] ogbg-molclintox: 0.483020 val loss: 0.681343
[Epoch 17] ogbg-molclintox: 0.477265 test loss: 0.679727
[Epoch 18; Iter    30/   30] train: loss: 0.6790718
[Epoch 18] ogbg-molclintox: 0.480961 val loss: 0.680594
[Epoch 18] ogbg-molclintox: 0.490128 test loss: 0.678824
[Epoch 19; Iter    30/   30] train: loss: 0.6779429
[Epoch 19] ogbg-molclintox: 0.484498 val loss: 0.679076
[Epoch 19] ogbg-molclintox: 0.489459 test loss: 0.677188
[Epoch 20; Iter    30/   30] train: loss: 0.6756849
[Epoch 20] ogbg-molclintox: 0.488008 val loss: 0.677966
[Epoch 20] ogbg-molclintox: 0.498721 test loss: 0.676003
[Epoch 21; Iter    30/   30] train: loss: 0.6748587
[Epoch 21] ogbg-molclintox: 0.486276 val loss: 0.676530
[Epoch 21] ogbg-molclintox: 0.499021 test loss: 0.674461
[Epoch 22; Iter    30/   30] train: loss: 0.6799359
[Epoch 22] ogbg-molclintox: 0.484197 val loss: 0.674524
[Epoch 22] ogbg-molclintox: 0.504809 test loss: 0.671951
[Epoch 23; Iter    30/   30] train: loss: 0.6705831
[Epoch 23] ogbg-molclintox: 0.545617 val loss: 0.681353
[Epoch 23] ogbg-molclintox: 0.616759 test loss: 0.677239
[Epoch 24; Iter    30/   30] train: loss: 0.6619729
[Epoch 24] ogbg-molclintox: 0.599135 val loss: 0.705816
[Epoch 24] ogbg-molclintox: 0.654543 test loss: 0.676237
[Epoch 25; Iter    30/   30] train: loss: 0.6280338
[Epoch 25] ogbg-molclintox: 0.611610 val loss: 0.733294
[Epoch 25] ogbg-molclintox: 0.674608 test loss: 0.692721
[Epoch 26; Iter    30/   30] train: loss: 0.5638154
[Epoch 26] ogbg-molclintox: 0.599337 val loss: 0.710903
[Epoch 26] ogbg-molclintox: 0.668328 test loss: 0.673585
[Epoch 27; Iter    30/   30] train: loss: 0.5263190
[Epoch 27] ogbg-molclintox: 0.599597 val loss: 0.598478
[Epoch 27] ogbg-molclintox: 0.661914 test loss: 0.528583
[Epoch 28; Iter    30/   30] train: loss: 0.4894408
[Epoch 28] ogbg-molclintox: 0.666815 val loss: 0.445520
[Epoch 28] ogbg-molclintox: 0.687835 test loss: 0.440613
[Epoch 29; Iter    30/   30] train: loss: 0.4256802
[Epoch 29] ogbg-molclintox: 0.663485 val loss: 0.560235
[Epoch 29] ogbg-molclintox: 0.702459 test loss: 0.516366
[Epoch 30; Iter    30/   30] train: loss: 0.3848771
[Epoch 30] ogbg-molclintox: 0.621852 val loss: 0.391363
[Epoch 30] ogbg-molclintox: 0.734384 test loss: 0.368880
[Epoch 31; Iter    30/   30] train: loss: 0.2861761
[Epoch 31] ogbg-molclintox: 0.629204 val loss: 0.412566
[Epoch 31] ogbg-molclintox: 0.684074 test loss: 0.349087
[Epoch 32; Iter    30/   30] train: loss: 0.2228008
[Epoch 32] ogbg-molclintox: 0.703407 val loss: 0.397072
[Epoch 32] ogbg-molclintox: 0.707975 test loss: 0.349255
[Epoch 33; Iter    30/   30] train: loss: 0.2424572
[Epoch 33] ogbg-molclintox: 0.726250 val loss: 0.277819
[Epoch 33] ogbg-molclintox: 0.710486 test loss: 0.260213
[Epoch 34; Iter    30/   30] train: loss: 0.3120702
[Epoch 34] ogbg-molclintox: 0.704324 val loss: 0.239791
[Epoch 31] ogbg-molclintox: 0.689426 test loss: 0.489176
[Epoch 32; Iter    20/   40] train: loss: 0.1912041
[Epoch 32] ogbg-molclintox: 0.896921 val loss: 0.135131
[Epoch 32] ogbg-molclintox: 0.701442 test loss: 0.429953
[Epoch 33; Iter    10/   40] train: loss: 0.0918464
[Epoch 33; Iter    40/   40] train: loss: 0.3517769
[Epoch 33] ogbg-molclintox: 0.865930 val loss: 0.141238
[Epoch 33] ogbg-molclintox: 0.696945 test loss: 0.227643
[Epoch 34; Iter    30/   40] train: loss: 0.0688761
[Epoch 34] ogbg-molclintox: 0.884597 val loss: 0.146472
[Epoch 34] ogbg-molclintox: 0.659697 test loss: 0.352021
[Epoch 35; Iter    20/   40] train: loss: 0.2000411
[Epoch 35] ogbg-molclintox: 0.904687 val loss: 0.121694
[Epoch 35] ogbg-molclintox: 0.756934 test loss: 0.275174
[Epoch 36; Iter    10/   40] train: loss: 0.1438867
[Epoch 36; Iter    40/   40] train: loss: 0.2674505
[Epoch 36] ogbg-molclintox: 0.938665 val loss: 0.117676
[Epoch 36] ogbg-molclintox: 0.776753 test loss: 0.227476
[Epoch 37; Iter    30/   40] train: loss: 0.1837731
[Epoch 37] ogbg-molclintox: 0.886681 val loss: 0.579645
[Epoch 37] ogbg-molclintox: 0.701315 test loss: 2.172573
[Epoch 38; Iter    20/   40] train: loss: 0.0678248
[Epoch 38] ogbg-molclintox: 0.918473 val loss: 0.180657
[Epoch 38] ogbg-molclintox: 0.776541 test loss: 0.467712
[Epoch 39; Iter    10/   40] train: loss: 0.1687528
[Epoch 39; Iter    40/   40] train: loss: 0.0986435
[Epoch 39] ogbg-molclintox: 0.986214 val loss: 0.074819
[Epoch 39] ogbg-molclintox: 0.848594 test loss: 0.249214
[Epoch 40; Iter    30/   40] train: loss: 0.1205658
[Epoch 40] ogbg-molclintox: 0.936529 val loss: 0.093970
[Epoch 40] ogbg-molclintox: 0.840578 test loss: 0.223865
[Epoch 41; Iter    20/   40] train: loss: 0.0583589
[Epoch 41] ogbg-molclintox: 0.990772 val loss: 0.067378
[Epoch 41] ogbg-molclintox: 0.844676 test loss: 0.469258
[Epoch 42; Iter    10/   40] train: loss: 0.0891091
[Epoch 42; Iter    40/   40] train: loss: 0.0503768
[Epoch 42] ogbg-molclintox: 0.816080 val loss: 0.113418
[Epoch 42] ogbg-molclintox: 0.869471 test loss: 1.026036
[Epoch 43; Iter    30/   40] train: loss: 0.0675116
[Epoch 43] ogbg-molclintox: 0.944470 val loss: 0.169350
[Epoch 43] ogbg-molclintox: 0.852019 test loss: 0.230228
[Epoch 44; Iter    20/   40] train: loss: 0.0815777
[Epoch 44] ogbg-molclintox: 0.961303 val loss: 0.110210
[Epoch 44] ogbg-molclintox: 0.818054 test loss: 0.202825
[Epoch 45; Iter    10/   40] train: loss: 0.1558238
[Epoch 45; Iter    40/   40] train: loss: 0.0368975
[Epoch 45] ogbg-molclintox: 0.977549 val loss: 0.093874
[Epoch 45] ogbg-molclintox: 0.876452 test loss: 0.188333
[Epoch 46; Iter    30/   40] train: loss: 0.0485084
[Epoch 46] ogbg-molclintox: 0.992982 val loss: 0.052344
[Epoch 46] ogbg-molclintox: 0.783503 test loss: 0.255295
[Epoch 47; Iter    20/   40] train: loss: 0.1396208
[Epoch 47] ogbg-molclintox: 0.990298 val loss: 0.073918
[Epoch 47] ogbg-molclintox: 0.844149 test loss: 2.429794
[Epoch 48; Iter    10/   40] train: loss: 0.0649102
[Epoch 48; Iter    40/   40] train: loss: 0.1227954
[Epoch 48] ogbg-molclintox: 0.926851 val loss: 0.079566
[Epoch 48] ogbg-molclintox: 0.885286 test loss: 0.159843
[Epoch 49; Iter    30/   40] train: loss: 0.0332839
[Epoch 49] ogbg-molclintox: 0.912805 val loss: 0.147230
[Epoch 49] ogbg-molclintox: 0.829197 test loss: 0.197735
[Epoch 50; Iter    20/   40] train: loss: 0.1722583
[Epoch 50] ogbg-molclintox: 0.979871 val loss: 0.070819
[Epoch 50] ogbg-molclintox: 0.809373 test loss: 0.165151
[Epoch 51; Iter    10/   40] train: loss: 0.0738312
[Epoch 51; Iter    40/   40] train: loss: 0.0158995
[Epoch 51] ogbg-molclintox: 0.991471 val loss: 0.061775
[Epoch 51] ogbg-molclintox: 0.830896 test loss: 0.207857
[Epoch 52; Iter    30/   40] train: loss: 0.0652286
[Epoch 52] ogbg-molclintox: 0.987476 val loss: 0.074668
[Epoch 52] ogbg-molclintox: 0.845012 test loss: 0.171867
[Epoch 53; Iter    20/   40] train: loss: 0.0613991
[Epoch 53] ogbg-molclintox: 0.978160 val loss: 0.067328
[Epoch 53] ogbg-molclintox: 0.899241 test loss: 0.141519
[Epoch 54; Iter    10/   40] train: loss: 0.0453139
[Epoch 54; Iter    40/   40] train: loss: 0.0276824
[Epoch 54] ogbg-molclintox: 0.987363 val loss: 0.065324
[Epoch 54] ogbg-molclintox: 0.829522 test loss: 0.209015
[Epoch 55; Iter    30/   40] train: loss: 0.2308533
[Epoch 55] ogbg-molclintox: 0.980096 val loss: 0.080672
[Epoch 55] ogbg-molclintox: 0.823015 test loss: 0.239375
[Epoch 56; Iter    20/   40] train: loss: 0.1183325
[Epoch 56] ogbg-molclintox: 0.783901 val loss: 3.013709
[Epoch 56] ogbg-molclintox: 0.803079 test loss: 10.655856
[Epoch 57; Iter    10/   40] train: loss: 0.1322553
[Epoch 57; Iter    40/   40] train: loss: 0.0657151
[Epoch 57] ogbg-molclintox: 0.951664 val loss: 0.082845
[Epoch 57] ogbg-molclintox: 0.833556 test loss: 0.345018
[Epoch 58; Iter    30/   40] train: loss: 0.1804201
[Epoch 58] ogbg-molclintox: 0.994493 val loss: 0.052500
[Epoch 58] ogbg-molclintox: 0.876892 test loss: 0.151714
[Epoch 59; Iter    20/   40] train: loss: 0.0276787
[Epoch 59] ogbg-molclintox: 0.949228 val loss: 0.095193
[Epoch 59] ogbg-molclintox: 0.864387 test loss: 0.628881
[Epoch 60; Iter    10/   40] train: loss: 0.0715606
[Epoch 60; Iter    40/   40] train: loss: 0.3239653
[Epoch 60] ogbg-molclintox: 0.972580 val loss: 0.109865
[Epoch 60] ogbg-molclintox: 0.843540 test loss: 0.191855
[Epoch 61; Iter    30/   40] train: loss: 0.1645628
[Epoch 61] ogbg-molclintox: 0.982082 val loss: 0.078680
[Epoch 61] ogbg-molclintox: 0.793110 test loss: 0.207763
[Epoch 62; Iter    20/   40] train: loss: 0.0834197
[Epoch 62] ogbg-molclintox: 0.935594 val loss: 0.105185
[Epoch 62] ogbg-molclintox: 0.858104 test loss: 0.179912
[Epoch 63; Iter    10/   40] train: loss: 0.0447879
[Epoch 63; Iter    40/   40] train: loss: 0.0198451
[Epoch 63] ogbg-molclintox: 0.982556 val loss: 0.061125
[Epoch 63] ogbg-molclintox: 0.864275 test loss: 0.692050
[Epoch 64; Iter    30/   40] train: loss: 0.1119218
[Epoch 64] ogbg-molclintox: 0.981994 val loss: 0.062781
[Epoch 64] ogbg-molclintox: 0.859755 test loss: 0.197303
[Epoch 65; Iter    20/   40] train: loss: 0.0244974
[Epoch 65] ogbg-molclintox: 0.960055 val loss: 0.081155
[Epoch 65] ogbg-molclintox: 0.845912 test loss: 0.173623
[Epoch 66; Iter    10/   40] train: loss: 0.0729721
[Epoch 66; Iter    40/   40] train: loss: 0.0607047
[Epoch 66] ogbg-molclintox: 0.959630 val loss: 0.090249
[Epoch 66] ogbg-molclintox: 0.796882 test loss: 1.953375
[Epoch 67; Iter    30/   40] train: loss: 0.2446602
[Epoch 67] ogbg-molclintox: 0.972017 val loss: 0.084265
[Epoch 67] ogbg-molclintox: 0.817105 test loss: 0.505986
[Epoch 68; Iter    20/   40] train: loss: 0.1479662
[Epoch 68] ogbg-molclintox: 0.988649 val loss: 0.069099
[Epoch 68] ogbg-molclintox: 0.858967 test loss: 0.175330
[Epoch 69; Iter    10/   40] train: loss: 0.0620207
[Epoch 69; Iter    40/   40] train: loss: 0.1197691
[Epoch 69] ogbg-molclintox: 0.930572 val loss: 0.085346
[Epoch 69] ogbg-molclintox: 0.853920 test loss: 0.210605
[Epoch 70; Iter    30/   40] train: loss: 0.1118035
[Epoch 70] ogbg-molclintox: 0.984317 val loss: 0.076695
[Epoch 70] ogbg-molclintox: 0.855045 test loss: 0.177288
[Epoch 71; Iter    20/   40] train: loss: 0.1139642
[Epoch 71] ogbg-molclintox: 0.987926 val loss: 0.059626
[Epoch 71] ogbg-molclintox: 0.848037 test loss: 0.197739
[Epoch 72; Iter    10/   40] train: loss: 0.0116203
[Epoch 72; Iter    40/   40] train: loss: 0.0523706
[Epoch 72] ogbg-molclintox: 0.979871 val loss: 0.069510
[Epoch 72] ogbg-molclintox: 0.826051 test loss: 0.208243
[Epoch 73; Iter    30/   40] train: loss: 0.2063259
[Epoch 73] ogbg-molclintox: 0.995080 val loss: 0.049297
[Epoch 73] ogbg-molclintox: 0.886085 test loss: 0.144259
[Epoch 74; Iter    20/   40] train: loss: 0.0275275
[Epoch 74] ogbg-molclintox: 0.977162 val loss: 0.075624
[Epoch 74] ogbg-molclintox: 0.888573 test loss: 0.176274
[Epoch 75; Iter    10/   40] train: loss: 0.0975190
[Epoch 75; Iter    40/   40] train: loss: 0.0905788
[Epoch 75] ogbg-molclintox: 0.981495 val loss: 0.113300
[Epoch 75] ogbg-molclintox: 0.833746 test loss: 0.192823
[Epoch 76; Iter    30/   40] train: loss: 0.0701240
[Epoch 31] ogbg-molclintox: 0.658061 test loss: 0.238734
[Epoch 32; Iter    20/   40] train: loss: 0.1597704
[Epoch 32] ogbg-molclintox: 0.686519 val loss: 0.161562
[Epoch 32] ogbg-molclintox: 0.622893 test loss: 0.246291
[Epoch 33; Iter    10/   40] train: loss: 0.1888978
[Epoch 33; Iter    40/   40] train: loss: 0.6619499
[Epoch 33] ogbg-molclintox: 0.919984 val loss: 0.128793
[Epoch 33] ogbg-molclintox: 0.649540 test loss: 0.235353
[Epoch 34; Iter    30/   40] train: loss: 0.1590526
[Epoch 34] ogbg-molclintox: 0.843641 val loss: 0.158037
[Epoch 34] ogbg-molclintox: 0.571365 test loss: 0.252334
[Epoch 35; Iter    20/   40] train: loss: 0.1991692
[Epoch 35] ogbg-molclintox: 0.900379 val loss: 0.127453
[Epoch 35] ogbg-molclintox: 0.716085 test loss: 0.286899
[Epoch 36; Iter    10/   40] train: loss: 0.2026929
[Epoch 36; Iter    40/   40] train: loss: 0.3901300
[Epoch 36] ogbg-molclintox: 0.823772 val loss: 0.129895
[Epoch 36] ogbg-molclintox: 0.802740 test loss: 0.375494
[Epoch 37; Iter    30/   40] train: loss: 0.3608456
[Epoch 37] ogbg-molclintox: 0.745081 val loss: 0.267971
[Epoch 37] ogbg-molclintox: 0.690154 test loss: 0.303997
[Epoch 38; Iter    20/   40] train: loss: 0.2484218
[Epoch 38] ogbg-molclintox: 0.909382 val loss: 0.115348
[Epoch 38] ogbg-molclintox: 0.851571 test loss: 0.387369
[Epoch 39; Iter    10/   40] train: loss: 0.1476990
[Epoch 39; Iter    40/   40] train: loss: 0.0868082
[Epoch 39] ogbg-molclintox: 0.963176 val loss: 0.089893
[Epoch 39] ogbg-molclintox: 0.830085 test loss: 0.285033
[Epoch 40; Iter    30/   40] train: loss: 0.3455032
[Epoch 40] ogbg-molclintox: 0.951189 val loss: 0.126258
[Epoch 40] ogbg-molclintox: 0.843637 test loss: 4.070794
[Epoch 41; Iter    20/   40] train: loss: 0.3062618
[Epoch 41] ogbg-molclintox: 0.892824 val loss: 0.118912
[Epoch 41] ogbg-molclintox: 0.824150 test loss: 10.199541
[Epoch 42; Iter    10/   40] train: loss: 0.0548931
[Epoch 42; Iter    40/   40] train: loss: 0.1159932
[Epoch 42] ogbg-molclintox: 0.963513 val loss: 0.104910
[Epoch 42] ogbg-molclintox: 0.858855 test loss: 1.394793
[Epoch 43; Iter    30/   40] train: loss: 0.3637165
[Epoch 43] ogbg-molclintox: 0.981182 val loss: 0.079354
[Epoch 43] ogbg-molclintox: 0.813747 test loss: 0.212147
[Epoch 44; Iter    20/   40] train: loss: 0.0423213
[Epoch 44] ogbg-molclintox: 0.954686 val loss: 0.085833
[Epoch 44] ogbg-molclintox: 0.834030 test loss: 0.698293
[Epoch 45; Iter    10/   40] train: loss: 0.1148272
[Epoch 45; Iter    40/   40] train: loss: 0.1872550
[Epoch 45] ogbg-molclintox: 0.970369 val loss: 0.081192
[Epoch 45] ogbg-molclintox: 0.864988 test loss: 0.280829
[Epoch 46; Iter    30/   40] train: loss: 0.1078847
[Epoch 46] ogbg-molclintox: 0.994044 val loss: 0.061038
[Epoch 46] ogbg-molclintox: 0.845012 test loss: 0.777877
[Epoch 47; Iter    20/   40] train: loss: 0.2319885
[Epoch 47] ogbg-molclintox: 0.947992 val loss: 0.471213
[Epoch 47] ogbg-molclintox: 0.789214 test loss: 1.670370
[Epoch 48; Iter    10/   40] train: loss: 0.0835375
[Epoch 48; Iter    40/   40] train: loss: 0.1590162
[Epoch 48] ogbg-molclintox: 0.991921 val loss: 0.055470
[Epoch 48] ogbg-molclintox: 0.908698 test loss: 0.157288
[Epoch 49; Iter    30/   40] train: loss: 0.2940640
[Epoch 49] ogbg-molclintox: 0.982918 val loss: 0.135349
[Epoch 49] ogbg-molclintox: 0.875742 test loss: 2.414612
[Epoch 50; Iter    20/   40] train: loss: 0.1322891
[Epoch 50] ogbg-molclintox: 0.953674 val loss: 0.091873
[Epoch 50] ogbg-molclintox: 0.866497 test loss: 0.193484
[Epoch 51; Iter    10/   40] train: loss: 0.2113490
[Epoch 51; Iter    40/   40] train: loss: 0.0526865
[Epoch 51] ogbg-molclintox: 0.955009 val loss: 0.076663
[Epoch 51] ogbg-molclintox: 0.829522 test loss: 0.629023
[Epoch 52; Iter    30/   40] train: loss: 0.1114447
[Epoch 52] ogbg-molclintox: 0.852841 val loss: 0.141587
[Epoch 52] ogbg-molclintox: 0.797144 test loss: 0.231622
[Epoch 53; Iter    20/   40] train: loss: 0.1691435
[Epoch 53] ogbg-molclintox: 0.928450 val loss: 0.107432
[Epoch 53] ogbg-molclintox: 0.839853 test loss: 0.173134
[Epoch 54; Iter    10/   40] train: loss: 0.1805274
[Epoch 54; Iter    40/   40] train: loss: 0.0706381
[Epoch 54] ogbg-molclintox: 0.921158 val loss: 0.089850
[Epoch 54] ogbg-molclintox: 0.771621 test loss: 0.364212
[Epoch 55; Iter    30/   40] train: loss: 0.1604413
[Epoch 55] ogbg-molclintox: 0.967034 val loss: 0.074832
[Epoch 55] ogbg-molclintox: 0.848747 test loss: 0.156173
[Epoch 56; Iter    20/   40] train: loss: 0.2524031
[Epoch 56] ogbg-molclintox: 0.943996 val loss: 0.415555
[Epoch 56] ogbg-molclintox: 0.753131 test loss: 0.736700
[Epoch 57; Iter    10/   40] train: loss: 0.1397318
[Epoch 57; Iter    40/   40] train: loss: 0.1601826
[Epoch 57] ogbg-molclintox: 0.983417 val loss: 0.071644
[Epoch 57] ogbg-molclintox: 0.861963 test loss: 0.199222
[Epoch 58; Iter    30/   40] train: loss: 0.3044528
[Epoch 58] ogbg-molclintox: 0.980033 val loss: 0.059319
[Epoch 58] ogbg-molclintox: 0.836055 test loss: 3.194926
[Epoch 59; Iter    20/   40] train: loss: 0.1601881
[Epoch 59] ogbg-molclintox: 0.942647 val loss: 0.075402
[Epoch 59] ogbg-molclintox: 0.805814 test loss: 0.630591
[Epoch 60; Iter    10/   40] train: loss: 0.0493589
[Epoch 60; Iter    40/   40] train: loss: 0.0614789
[Epoch 60] ogbg-molclintox: 0.987862 val loss: 0.066679
[Epoch 60] ogbg-molclintox: 0.819037 test loss: 1.040840
[Epoch 61; Iter    30/   40] train: loss: 0.0722876
[Epoch 61] ogbg-molclintox: 0.988649 val loss: 0.062493
[Epoch 61] ogbg-molclintox: 0.853080 test loss: 2.760927
[Epoch 62; Iter    20/   40] train: loss: 0.0784342
[Epoch 62] ogbg-molclintox: 0.929149 val loss: 0.107573
[Epoch 62] ogbg-molclintox: 0.800338 test loss: 6.012286
[Epoch 63; Iter    10/   40] train: loss: 0.3172386
[Epoch 63; Iter    40/   40] train: loss: 0.0289400
[Epoch 63] ogbg-molclintox: 0.926777 val loss: 0.095265
[Epoch 63] ogbg-molclintox: 0.793417 test loss: 2.616411
[Epoch 64; Iter    30/   40] train: loss: 0.0239702
[Epoch 64] ogbg-molclintox: 0.979783 val loss: 0.069435
[Epoch 64] ogbg-molclintox: 0.858029 test loss: 11.336597
[Epoch 65; Iter    20/   40] train: loss: 0.0339122
[Epoch 65] ogbg-molclintox: 0.983979 val loss: 0.062067
[Epoch 65] ogbg-molclintox: 0.842412 test loss: 3.269318
[Epoch 66; Iter    10/   40] train: loss: 0.0363663
[Epoch 66; Iter    40/   40] train: loss: 0.2514281
[Epoch 66] ogbg-molclintox: 0.862930 val loss: 0.101097
[Epoch 66] ogbg-molclintox: 0.833283 test loss: 5.850610
[Epoch 67; Iter    30/   40] train: loss: 0.0755982
[Epoch 67] ogbg-molclintox: 0.976013 val loss: 0.083234
[Epoch 67] ogbg-molclintox: 0.762626 test loss: 9.203244
[Epoch 68; Iter    20/   40] train: loss: 0.0570368
[Epoch 68] ogbg-molclintox: 0.981157 val loss: 0.083220
[Epoch 68] ogbg-molclintox: 0.829171 test loss: 7.233569
[Epoch 69; Iter    10/   40] train: loss: 0.0221726
[Epoch 69; Iter    40/   40] train: loss: 0.0604074
[Epoch 69] ogbg-molclintox: 0.961777 val loss: 0.075215
[Epoch 69] ogbg-molclintox: 0.860177 test loss: 8.041461
[Epoch 70; Iter    30/   40] train: loss: 0.0667516
[Epoch 70] ogbg-molclintox: 0.974189 val loss: 0.077123
[Epoch 70] ogbg-molclintox: 0.811372 test loss: 8.327852
[Epoch 71; Iter    20/   40] train: loss: 0.0363693
[Epoch 71] ogbg-molclintox: 0.977686 val loss: 0.081420
[Epoch 71] ogbg-molclintox: 0.874655 test loss: 9.229429
[Epoch 72; Iter    10/   40] train: loss: 0.0231830
[Epoch 72; Iter    40/   40] train: loss: 0.0723072
[Epoch 72] ogbg-molclintox: 0.989486 val loss: 0.048978
[Epoch 72] ogbg-molclintox: 0.815619 test loss: 11.129584
[Epoch 73; Iter    30/   40] train: loss: 0.2160161
[Epoch 73] ogbg-molclintox: 0.964012 val loss: 0.115730
[Epoch 73] ogbg-molclintox: 0.857342 test loss: 28.975559
[Epoch 74; Iter    20/   40] train: loss: 0.0551755
[Epoch 74] ogbg-molclintox: 0.982830 val loss: 0.062307
[Epoch 74] ogbg-molclintox: 0.872843 test loss: 7.844583
[Epoch 75; Iter    10/   40] train: loss: 0.0423638
[Epoch 75; Iter    40/   40] train: loss: 0.0275981
[Epoch 75] ogbg-molclintox: 0.943708 val loss: 0.068395
[Epoch 75] ogbg-molclintox: 0.860002 test loss: 7.316435
[Epoch 76; Iter    30/   40] train: loss: 0.0091045
[Epoch 34] ogbg-molclintox: 0.695645 test loss: 0.327390
[Epoch 35; Iter    30/   30] train: loss: 0.3152419
[Epoch 35] ogbg-molclintox: 0.677577 val loss: 0.289878
[Epoch 35] ogbg-molclintox: 0.715374 test loss: 0.235649
[Epoch 36; Iter    30/   30] train: loss: 0.4448172
[Epoch 36] ogbg-molclintox: 0.603040 val loss: 0.271385
[Epoch 36] ogbg-molclintox: 0.640556 test loss: 0.220442
[Epoch 37; Iter    30/   30] train: loss: 0.3409156
[Epoch 37] ogbg-molclintox: 0.667690 val loss: 0.324565
[Epoch 37] ogbg-molclintox: 0.736638 test loss: 0.253099
[Epoch 38; Iter    30/   30] train: loss: 0.1506409
[Epoch 38] ogbg-molclintox: 0.668178 val loss: 0.261197
[Epoch 38] ogbg-molclintox: 0.724236 test loss: 0.197769
[Epoch 39; Iter    30/   30] train: loss: 0.3239018
[Epoch 39] ogbg-molclintox: 0.650784 val loss: 0.293118
[Epoch 39] ogbg-molclintox: 0.720508 test loss: 0.236286
[Epoch 40; Iter    30/   30] train: loss: 0.0970002
[Epoch 40] ogbg-molclintox: 0.702110 val loss: 0.316976
[Epoch 40] ogbg-molclintox: 0.739184 test loss: 0.237704
[Epoch 41; Iter    30/   30] train: loss: 0.1845066
[Epoch 41] ogbg-molclintox: 0.693761 val loss: 0.268123
[Epoch 41] ogbg-molclintox: 0.737853 test loss: 0.223135
[Epoch 42; Iter    30/   30] train: loss: 0.0691344
[Epoch 42] ogbg-molclintox: 0.684282 val loss: 0.288854
[Epoch 42] ogbg-molclintox: 0.708361 test loss: 0.233953
[Epoch 43; Iter    30/   30] train: loss: 0.1303389
[Epoch 43] ogbg-molclintox: 0.657167 val loss: 0.387136
[Epoch 43] ogbg-molclintox: 0.714757 test loss: 0.258770
[Epoch 44; Iter    30/   30] train: loss: 0.1384411
[Epoch 44] ogbg-molclintox: 0.690111 val loss: 0.273482
[Epoch 44] ogbg-molclintox: 0.754000 test loss: 0.226099
[Epoch 45; Iter    30/   30] train: loss: 0.0964158
[Epoch 45] ogbg-molclintox: 0.709083 val loss: 0.240160
[Epoch 45] ogbg-molclintox: 0.752090 test loss: 0.188415
[Epoch 46; Iter    30/   30] train: loss: 0.0841349
[Epoch 46] ogbg-molclintox: 0.772477 val loss: 0.233368
[Epoch 46] ogbg-molclintox: 0.811778 test loss: 0.173918
[Epoch 47; Iter    30/   30] train: loss: 0.2139716
[Epoch 47] ogbg-molclintox: 0.771126 val loss: 0.237595
[Epoch 47] ogbg-molclintox: 0.829141 test loss: 0.276970
[Epoch 48; Iter    30/   30] train: loss: 0.1540321
[Epoch 48] ogbg-molclintox: 0.639458 val loss: 1.145118
[Epoch 48] ogbg-molclintox: 0.808386 test loss: 1.257882
[Epoch 49; Iter    30/   30] train: loss: 0.1186436
[Epoch 49] ogbg-molclintox: 0.642253 val loss: 1.949097
[Epoch 49] ogbg-molclintox: 0.739032 test loss: 3.138759
[Epoch 50; Iter    30/   30] train: loss: 0.2284071
[Epoch 50] ogbg-molclintox: 0.810773 val loss: 0.571988
[Epoch 50] ogbg-molclintox: 0.828668 test loss: 1.392233
[Epoch 51; Iter    30/   30] train: loss: 0.1158634
[Epoch 51] ogbg-molclintox: 0.838842 val loss: 0.368148
[Epoch 51] ogbg-molclintox: 0.875023 test loss: 0.184538
[Epoch 52; Iter    30/   30] train: loss: 0.2287955
[Epoch 52] ogbg-molclintox: 0.889261 val loss: 0.226862
[Epoch 52] ogbg-molclintox: 0.874849 test loss: 0.176663
[Epoch 53; Iter    30/   30] train: loss: 0.1292540
[Epoch 53] ogbg-molclintox: 0.875931 val loss: 0.186654
[Epoch 53] ogbg-molclintox: 0.916586 test loss: 0.171323
[Epoch 54; Iter    30/   30] train: loss: 0.0768288
[Epoch 54] ogbg-molclintox: 0.902435 val loss: 0.368902
[Epoch 54] ogbg-molclintox: 0.922546 test loss: 0.593960
[Epoch 55; Iter    30/   30] train: loss: 0.1667350
[Epoch 55] ogbg-molclintox: 0.876706 val loss: 0.206106
[Epoch 55] ogbg-molclintox: 0.896706 test loss: 0.161126
[Epoch 56; Iter    30/   30] train: loss: 0.1546144
[Epoch 56] ogbg-molclintox: 0.590567 val loss: 0.422147
[Epoch 56] ogbg-molclintox: 0.537417 test loss: 0.455644
[Epoch 57; Iter    30/   30] train: loss: 0.1234227
[Epoch 57] ogbg-molclintox: 0.914315 val loss: 0.172243
[Epoch 57] ogbg-molclintox: 0.911462 test loss: 0.366076
[Epoch 58; Iter    30/   30] train: loss: 0.0644888
[Epoch 58] ogbg-molclintox: 0.867608 val loss: 0.215292
[Epoch 58] ogbg-molclintox: 0.880389 test loss: 0.188970
[Epoch 59; Iter    30/   30] train: loss: 0.1318809
[Epoch 59] ogbg-molclintox: 0.876366 val loss: 0.193922
[Epoch 59] ogbg-molclintox: 0.897133 test loss: 0.204731
[Epoch 60; Iter    30/   30] train: loss: 0.1324044
[Epoch 60] ogbg-molclintox: 0.857145 val loss: 0.258457
[Epoch 60] ogbg-molclintox: 0.912202 test loss: 0.202051
[Epoch 61; Iter    30/   30] train: loss: 0.0687727
[Epoch 61] ogbg-molclintox: 0.906051 val loss: 1.943857
[Epoch 61] ogbg-molclintox: 0.927191 test loss: 2.125994
[Epoch 62; Iter    30/   30] train: loss: 0.0588657
[Epoch 62] ogbg-molclintox: 0.909689 val loss: 0.209902
[Epoch 62] ogbg-molclintox: 0.867165 test loss: 0.402165
[Epoch 63; Iter    30/   30] train: loss: 0.0989467
[Epoch 63] ogbg-molclintox: 0.862989 val loss: 0.265079
[Epoch 63] ogbg-molclintox: 0.900940 test loss: 0.417233
[Epoch 64; Iter    30/   30] train: loss: 0.1509237
[Epoch 64] ogbg-molclintox: 0.857313 val loss: 0.407998
[Epoch 64] ogbg-molclintox: 0.912012 test loss: 0.310683
[Epoch 65; Iter    30/   30] train: loss: 0.0490242
[Epoch 65] ogbg-molclintox: 0.924743 val loss: 0.180191
[Epoch 65] ogbg-molclintox: 0.957657 test loss: 0.151000
[Epoch 66; Iter    30/   30] train: loss: 0.0391170
[Epoch 66] ogbg-molclintox: 0.823878 val loss: 1.691302
[Epoch 66] ogbg-molclintox: 0.861091 test loss: 2.058284
[Epoch 67; Iter    30/   30] train: loss: 0.1580119
[Epoch 67] ogbg-molclintox: 0.880825 val loss: 0.281179
[Epoch 67] ogbg-molclintox: 0.905141 test loss: 0.136919
[Epoch 68; Iter    30/   30] train: loss: 0.0662977
[Epoch 68] ogbg-molclintox: 0.899862 val loss: 0.165323
[Epoch 68] ogbg-molclintox: 0.918640 test loss: 0.139629
[Epoch 69; Iter    30/   30] train: loss: 0.0984698
[Epoch 69] ogbg-molclintox: 0.929489 val loss: 0.297702
[Epoch 69] ogbg-molclintox: 0.934000 test loss: 0.536087
[Epoch 70; Iter    30/   30] train: loss: 0.1659186
[Epoch 70] ogbg-molclintox: 0.895296 val loss: 0.176086
[Epoch 70] ogbg-molclintox: 0.908129 test loss: 0.198335
[Epoch 71; Iter    30/   30] train: loss: 0.3233139
[Epoch 71] ogbg-molclintox: 0.889367 val loss: 0.175509
[Epoch 71] ogbg-molclintox: 0.932830 test loss: 0.157222
[Epoch 72; Iter    30/   30] train: loss: 0.1364946
[Epoch 72] ogbg-molclintox: 0.899228 val loss: 0.169442
[Epoch 72] ogbg-molclintox: 0.927584 test loss: 0.132050
[Epoch 73; Iter    30/   30] train: loss: 0.1290956
[Epoch 73] ogbg-molclintox: 0.914241 val loss: 0.166105
[Epoch 73] ogbg-molclintox: 0.940643 test loss: 0.121869
[Epoch 74; Iter    30/   30] train: loss: 0.2465355
[Epoch 74] ogbg-molclintox: 0.919113 val loss: 0.247513
[Epoch 74] ogbg-molclintox: 0.944363 test loss: 0.251014
[Epoch 75; Iter    30/   30] train: loss: 0.1785791
[Epoch 75] ogbg-molclintox: 0.871574 val loss: 0.195892
[Epoch 75] ogbg-molclintox: 0.922488 test loss: 0.288732
[Epoch 76; Iter    30/   30] train: loss: 0.1058616
[Epoch 76] ogbg-molclintox: 0.900952 val loss: 0.200679
[Epoch 76] ogbg-molclintox: 0.930819 test loss: 0.256021
[Epoch 77; Iter    30/   30] train: loss: 0.0414695
[Epoch 77] ogbg-molclintox: 0.900591 val loss: 0.169249
[Epoch 77] ogbg-molclintox: 0.928966 test loss: 0.156600
[Epoch 78; Iter    30/   30] train: loss: 0.0495071
[Epoch 78] ogbg-molclintox: 0.914014 val loss: 0.229725
[Epoch 78] ogbg-molclintox: 0.899651 test loss: 0.279974
[Epoch 79; Iter    30/   30] train: loss: 0.0719270
[Epoch 79] ogbg-molclintox: 0.877730 val loss: 0.211712
[Epoch 79] ogbg-molclintox: 0.929543 test loss: 0.155405
[Epoch 80; Iter    30/   30] train: loss: 0.0834538
[Epoch 80] ogbg-molclintox: 0.911795 val loss: 0.209349
[Epoch 80] ogbg-molclintox: 0.937857 test loss: 0.131312
[Epoch 81; Iter    30/   30] train: loss: 0.0583979
[Epoch 81] ogbg-molclintox: 0.880229 val loss: 0.187545
[Epoch 81] ogbg-molclintox: 0.869479 test loss: 0.231473
[Epoch 82; Iter    30/   30] train: loss: 0.5303884
[Epoch 82] ogbg-molclintox: 0.873497 val loss: 0.279886
[Epoch 82] ogbg-molclintox: 0.922351 test loss: 0.213968
[Epoch 83; Iter    30/   30] train: loss: 0.1596080
[Epoch 83] ogbg-molclintox: 0.919837 val loss: 0.147503
[Epoch 83] ogbg-molclintox: 0.894370 test loss: 0.180785
[Epoch 33; Iter    20/   35] train: loss: 0.1386232
[Epoch 33] ogbg-molclintox: 0.780611 val loss: 0.251453
[Epoch 33] ogbg-molclintox: 0.686527 test loss: 0.260212
[Epoch 34; Iter    15/   35] train: loss: 0.1459390
[Epoch 34] ogbg-molclintox: 0.769890 val loss: 0.243672
[Epoch 34] ogbg-molclintox: 0.653947 test loss: 0.249496
[Epoch 35; Iter    10/   35] train: loss: 0.1130583
[Epoch 35] ogbg-molclintox: 0.790518 val loss: 0.235668
[Epoch 35] ogbg-molclintox: 0.669951 test loss: 0.240547
[Epoch 36; Iter     5/   35] train: loss: 0.2111318
[Epoch 36; Iter    35/   35] train: loss: 0.1309726
[Epoch 36] ogbg-molclintox: 0.785924 val loss: 0.239991
[Epoch 36] ogbg-molclintox: 0.645540 test loss: 0.242958
[Epoch 37; Iter    30/   35] train: loss: 0.1247946
[Epoch 37] ogbg-molclintox: 0.770916 val loss: 0.268357
[Epoch 37] ogbg-molclintox: 0.636481 test loss: 0.286595
[Epoch 38; Iter    25/   35] train: loss: 0.1765062
[Epoch 38] ogbg-molclintox: 0.742347 val loss: 0.232954
[Epoch 38] ogbg-molclintox: 0.651771 test loss: 0.216387
[Epoch 39; Iter    20/   35] train: loss: 0.2198773
[Epoch 39] ogbg-molclintox: 0.797069 val loss: 0.278668
[Epoch 39] ogbg-molclintox: 0.708727 test loss: 0.216835
[Epoch 40; Iter    15/   35] train: loss: 0.1303499
[Epoch 40] ogbg-molclintox: 0.799943 val loss: 0.258436
[Epoch 40] ogbg-molclintox: 0.644565 test loss: 0.451506
[Epoch 41; Iter    10/   35] train: loss: 0.1178051
[Epoch 41] ogbg-molclintox: 0.811784 val loss: 0.284005
[Epoch 41] ogbg-molclintox: 0.810633 test loss: 0.931148
[Epoch 42; Iter     5/   35] train: loss: 0.3220226
[Epoch 42; Iter    35/   35] train: loss: 0.5084205
[Epoch 42] ogbg-molclintox: 0.892083 val loss: 0.355771
[Epoch 42] ogbg-molclintox: 0.855225 test loss: 0.465045
[Epoch 43; Iter    30/   35] train: loss: 0.2292977
[Epoch 43] ogbg-molclintox: 0.886173 val loss: 0.203653
[Epoch 43] ogbg-molclintox: 0.726522 test loss: 0.597300
[Epoch 44; Iter    25/   35] train: loss: 0.2422299
[Epoch 44] ogbg-molclintox: 0.871402 val loss: 1.844841
[Epoch 44] ogbg-molclintox: 0.687695 test loss: 4.514388
[Epoch 45; Iter    20/   35] train: loss: 0.2846560
[Epoch 45] ogbg-molclintox: 0.921296 val loss: 0.271610
[Epoch 45] ogbg-molclintox: 0.791812 test loss: 0.347582
[Epoch 46; Iter    15/   35] train: loss: 0.0940191
[Epoch 46] ogbg-molclintox: 0.959980 val loss: 0.132504
[Epoch 46] ogbg-molclintox: 0.854743 test loss: 0.149827
[Epoch 47; Iter    10/   35] train: loss: 0.1032501
[Epoch 47] ogbg-molclintox: 0.939126 val loss: 0.356462
[Epoch 47] ogbg-molclintox: 0.862141 test loss: 0.522864
[Epoch 48; Iter     5/   35] train: loss: 0.0644675
[Epoch 48; Iter    35/   35] train: loss: 0.3371986
[Epoch 48] ogbg-molclintox: 0.950530 val loss: 0.174043
[Epoch 48] ogbg-molclintox: 0.821222 test loss: 0.226115
[Epoch 49; Iter    30/   35] train: loss: 0.0444510
[Epoch 49] ogbg-molclintox: 0.932217 val loss: 0.353860
[Epoch 49] ogbg-molclintox: 0.828133 test loss: 0.428244
[Epoch 50; Iter    25/   35] train: loss: 0.0846528
[Epoch 50] ogbg-molclintox: 0.971211 val loss: 0.377500
[Epoch 50] ogbg-molclintox: 0.882238 test loss: 1.076885
[Epoch 51; Iter    20/   35] train: loss: 0.1588502
[Epoch 51] ogbg-molclintox: 0.984806 val loss: 0.161197
[Epoch 51] ogbg-molclintox: 0.856580 test loss: 0.941937
[Epoch 52; Iter    15/   35] train: loss: 0.1013431
[Epoch 52] ogbg-molclintox: 0.972350 val loss: 0.142733
[Epoch 52] ogbg-molclintox: 0.865021 test loss: 0.327161
[Epoch 53; Iter    10/   35] train: loss: 0.0472766
[Epoch 53] ogbg-molclintox: 0.964066 val loss: 0.299151
[Epoch 53] ogbg-molclintox: 0.891484 test loss: 0.597965
[Epoch 54; Iter     5/   35] train: loss: 0.0313253
[Epoch 54; Iter    35/   35] train: loss: 0.2382534
[Epoch 54] ogbg-molclintox: 0.972152 val loss: 0.106900
[Epoch 54] ogbg-molclintox: 0.883525 test loss: 0.290342
[Epoch 55; Iter    30/   35] train: loss: 0.1602290
[Epoch 55] ogbg-molclintox: 0.744623 val loss: 1.254907
[Epoch 55] ogbg-molclintox: 0.623426 test loss: 1.901828
[Epoch 56; Iter    25/   35] train: loss: 0.1420801
[Epoch 56] ogbg-molclintox: 0.927373 val loss: 0.323350
[Epoch 56] ogbg-molclintox: 0.877606 test loss: 0.374442
[Epoch 57; Iter    20/   35] train: loss: 0.0994324
[Epoch 57] ogbg-molclintox: 0.945786 val loss: 0.193256
[Epoch 57] ogbg-molclintox: 0.869789 test loss: 0.245568
[Epoch 58; Iter    15/   35] train: loss: 0.1146486
[Epoch 58] ogbg-molclintox: 0.947609 val loss: 0.575703
[Epoch 58] ogbg-molclintox: 0.878854 test loss: 1.174980
[Epoch 59; Iter    10/   35] train: loss: 0.1380458
[Epoch 59] ogbg-molclintox: 0.946308 val loss: 0.237982
[Epoch 59] ogbg-molclintox: 0.899999 test loss: 0.154010
[Epoch 60; Iter     5/   35] train: loss: 0.0644028
[Epoch 60; Iter    35/   35] train: loss: 0.3039192
[Epoch 60] ogbg-molclintox: 0.958530 val loss: 0.261737
[Epoch 60] ogbg-molclintox: 0.897896 test loss: 0.130013
[Epoch 61; Iter    30/   35] train: loss: 0.0838731
[Epoch 61] ogbg-molclintox: 0.957888 val loss: 0.136571
[Epoch 61] ogbg-molclintox: 0.821421 test loss: 0.147964
[Epoch 62; Iter    25/   35] train: loss: 0.0697294
[Epoch 62] ogbg-molclintox: 0.972795 val loss: 0.191000
[Epoch 62] ogbg-molclintox: 0.891694 test loss: 0.168652
[Epoch 63; Iter    20/   35] train: loss: 0.0458926
[Epoch 63] ogbg-molclintox: 0.976993 val loss: 0.119721
[Epoch 63] ogbg-molclintox: 0.882703 test loss: 0.365893
[Epoch 64; Iter    15/   35] train: loss: 0.2126966
[Epoch 64] ogbg-molclintox: 0.968871 val loss: 0.121052
[Epoch 64] ogbg-molclintox: 0.878961 test loss: 0.137307
[Epoch 65; Iter    10/   35] train: loss: 0.0507742
[Epoch 65] ogbg-molclintox: 0.952526 val loss: 0.150766
[Epoch 65] ogbg-molclintox: 0.826194 test loss: 0.276748
[Epoch 66; Iter     5/   35] train: loss: 0.0946460
[Epoch 66; Iter    35/   35] train: loss: 0.1569251
[Epoch 66] ogbg-molclintox: 0.975038 val loss: 0.113177
[Epoch 66] ogbg-molclintox: 0.898542 test loss: 0.143095
[Epoch 67; Iter    30/   35] train: loss: 0.3377617
[Epoch 67] ogbg-molclintox: 0.975978 val loss: 0.119757
[Epoch 67] ogbg-molclintox: 0.860934 test loss: 0.144098
[Epoch 68; Iter    25/   35] train: loss: 0.1955831
[Epoch 68] ogbg-molclintox: 0.888787 val loss: 0.684240
[Epoch 68] ogbg-molclintox: 0.793393 test loss: 0.900126
[Epoch 69; Iter    20/   35] train: loss: 0.0477722
[Epoch 69] ogbg-molclintox: 0.967496 val loss: 0.122387
[Epoch 69] ogbg-molclintox: 0.902147 test loss: 0.143944
[Epoch 70; Iter    15/   35] train: loss: 0.0515653
[Epoch 70] ogbg-molclintox: 0.794456 val loss: 3.057438
[Epoch 70] ogbg-molclintox: 0.672451 test loss: 3.193630
[Epoch 71; Iter    10/   35] train: loss: 0.3198860
[Epoch 71] ogbg-molclintox: 0.932217 val loss: 0.186399
[Epoch 71] ogbg-molclintox: 0.854001 test loss: 0.421132
[Epoch 72; Iter     5/   35] train: loss: 0.0727584
[Epoch 72; Iter    35/   35] train: loss: 0.0273228
[Epoch 72] ogbg-molclintox: 0.957070 val loss: 0.137925
[Epoch 72] ogbg-molclintox: 0.899387 test loss: 0.179843
[Epoch 73; Iter    30/   35] train: loss: 0.0640733
[Epoch 73] ogbg-molclintox: 0.979531 val loss: 0.107940
[Epoch 73] ogbg-molclintox: 0.922499 test loss: 0.139441
[Epoch 74; Iter    25/   35] train: loss: 0.0856429
[Epoch 74] ogbg-molclintox: 0.966504 val loss: 0.128900
[Epoch 74] ogbg-molclintox: 0.866217 test loss: 0.170743
[Epoch 75; Iter    20/   35] train: loss: 0.1067743
[Epoch 75] ogbg-molclintox: 0.968276 val loss: 0.120091
[Epoch 75] ogbg-molclintox: 0.902023 test loss: 0.122189
[Epoch 76; Iter    15/   35] train: loss: 0.1707248
[Epoch 76] ogbg-molclintox: 0.973340 val loss: 0.130061
[Epoch 76] ogbg-molclintox: 0.840095 test loss: 0.287177
[Epoch 77; Iter    10/   35] train: loss: 0.0433626
[Epoch 77] ogbg-molclintox: 0.966131 val loss: 0.119528
[Epoch 77] ogbg-molclintox: 0.843813 test loss: 0.150351
[Epoch 78; Iter     5/   35] train: loss: 0.0244633
[Epoch 78; Iter    35/   35] train: loss: 0.0165793
[Epoch 78] ogbg-molclintox: 0.956290 val loss: 0.142989
[Epoch 78] ogbg-molclintox: 0.834499 test loss: 0.121091
[Epoch 79; Iter    30/   35] train: loss: 0.5102715
[Epoch 79] ogbg-molclintox: 0.872242 val loss: 0.207736
[Epoch 79] ogbg-molclintox: 0.848297 test loss: 0.236496
[Epoch 31] ogbg-molclintox: 0.717108 test loss: 0.215688
[Epoch 32; Iter    20/   40] train: loss: 0.2740614
[Epoch 32] ogbg-molclintox: 0.780654 val loss: 0.186595
[Epoch 32] ogbg-molclintox: 0.673013 test loss: 0.289068
[Epoch 33; Iter    10/   40] train: loss: 0.3586622
[Epoch 33; Iter    40/   40] train: loss: 0.2419899
[Epoch 33] ogbg-molclintox: 0.718870 val loss: 0.200923
[Epoch 33] ogbg-molclintox: 0.734096 test loss: 0.252353
[Epoch 34; Iter    30/   40] train: loss: 0.1287272
[Epoch 34] ogbg-molclintox: 0.832002 val loss: 0.137936
[Epoch 34] ogbg-molclintox: 0.655409 test loss: 0.248011
[Epoch 35; Iter    20/   40] train: loss: 0.1677677
[Epoch 35] ogbg-molclintox: 0.764936 val loss: 0.156285
[Epoch 35] ogbg-molclintox: 0.769286 test loss: 0.206387
[Epoch 36; Iter    10/   40] train: loss: 0.2273070
[Epoch 36; Iter    40/   40] train: loss: 0.4273088
[Epoch 36] ogbg-molclintox: 0.916625 val loss: 0.120932
[Epoch 36] ogbg-molclintox: 0.818357 test loss: 0.436308
[Epoch 37; Iter    30/   40] train: loss: 0.1884886
[Epoch 37] ogbg-molclintox: 0.811634 val loss: 0.371793
[Epoch 37] ogbg-molclintox: 0.790361 test loss: 0.423519
[Epoch 38; Iter    20/   40] train: loss: 0.2669347
[Epoch 38] ogbg-molclintox: 0.762648 val loss: 0.264398
[Epoch 38] ogbg-molclintox: 0.783480 test loss: 0.220255
[Epoch 39; Iter    10/   40] train: loss: 0.0656325
[Epoch 39; Iter    40/   40] train: loss: 0.0622509
[Epoch 39] ogbg-molclintox: 0.818540 val loss: 0.117339
[Epoch 39] ogbg-molclintox: 0.899891 test loss: 0.178112
[Epoch 40; Iter    30/   40] train: loss: 0.2063422
[Epoch 40] ogbg-molclintox: 0.940563 val loss: 0.158055
[Epoch 40] ogbg-molclintox: 0.728650 test loss: 0.314558
[Epoch 41; Iter    20/   40] train: loss: 0.1505130
[Epoch 41] ogbg-molclintox: 0.761949 val loss: 0.210856
[Epoch 41] ogbg-molclintox: 0.818816 test loss: 0.264117
[Epoch 42; Iter    10/   40] train: loss: 0.1201194
[Epoch 42; Iter    40/   40] train: loss: 0.0464816
[Epoch 42] ogbg-molclintox: 0.949453 val loss: 0.079316
[Epoch 42] ogbg-molclintox: 0.761528 test loss: 0.594917
[Epoch 43; Iter    30/   40] train: loss: 0.1866038
[Epoch 43] ogbg-molclintox: 0.870812 val loss: 0.132232
[Epoch 43] ogbg-molclintox: 0.712562 test loss: 0.253795
[Epoch 44; Iter    20/   40] train: loss: 0.1123304
[Epoch 44] ogbg-molclintox: 0.939389 val loss: 0.095635
[Epoch 44] ogbg-molclintox: 0.828285 test loss: 0.196463
[Epoch 45; Iter    10/   40] train: loss: 0.2555117
[Epoch 45; Iter    40/   40] train: loss: 0.2588549
[Epoch 45] ogbg-molclintox: 0.898418 val loss: 0.102521
[Epoch 45] ogbg-molclintox: 0.848784 test loss: 0.181039
[Epoch 46; Iter    30/   40] train: loss: 0.1631899
[Epoch 46] ogbg-molclintox: 0.970281 val loss: 0.148042
[Epoch 46] ogbg-molclintox: 0.871607 test loss: 0.418151
[Epoch 47; Iter    20/   40] train: loss: 0.0975863
[Epoch 47] ogbg-molclintox: 0.975089 val loss: 0.078218
[Epoch 47] ogbg-molclintox: 0.858679 test loss: 0.205280
[Epoch 48; Iter    10/   40] train: loss: 0.0798398
[Epoch 48; Iter    40/   40] train: loss: 0.1578911
[Epoch 48] ogbg-molclintox: 0.984791 val loss: 0.072698
[Epoch 48] ogbg-molclintox: 0.846999 test loss: 0.188528
[Epoch 49; Iter    30/   40] train: loss: 0.0994605
[Epoch 49] ogbg-molclintox: 0.925941 val loss: 0.128089
[Epoch 49] ogbg-molclintox: 0.811771 test loss: 0.557255
[Epoch 50; Iter    20/   40] train: loss: 0.0687682
[Epoch 50] ogbg-molclintox: 0.938901 val loss: 0.087276
[Epoch 50] ogbg-molclintox: 0.869810 test loss: 0.184117
[Epoch 51; Iter    10/   40] train: loss: 0.1368119
[Epoch 51; Iter    40/   40] train: loss: 0.5998988
[Epoch 51] ogbg-molclintox: 0.983779 val loss: 0.076315
[Epoch 51] ogbg-molclintox: 0.859729 test loss: 0.171519
[Epoch 52; Iter    30/   40] train: loss: 0.2288206
[Epoch 52] ogbg-molclintox: 0.946182 val loss: 0.090942
[Epoch 52] ogbg-molclintox: 0.831083 test loss: 0.195754
[Epoch 53; Iter    20/   40] train: loss: 0.0838677
[Epoch 53] ogbg-molclintox: 0.964213 val loss: 0.074506
[Epoch 53] ogbg-molclintox: 0.830059 test loss: 0.383046
[Epoch 54; Iter    10/   40] train: loss: 0.1268070
[Epoch 54; Iter    40/   40] train: loss: 0.1564885
[Epoch 54] ogbg-molclintox: 0.983392 val loss: 0.068091
[Epoch 54] ogbg-molclintox: 0.809325 test loss: 0.229008
[Epoch 55; Iter    30/   40] train: loss: 0.1035657
[Epoch 55] ogbg-molclintox: 0.874256 val loss: 0.121655
[Epoch 55] ogbg-molclintox: 0.816568 test loss: 0.913118
[Epoch 56; Iter    20/   40] train: loss: 0.0635706
[Epoch 56] ogbg-molclintox: 0.945806 val loss: 0.087341
[Epoch 56] ogbg-molclintox: 0.853084 test loss: 0.201874
[Epoch 57; Iter    10/   40] train: loss: 0.0681246
[Epoch 57; Iter    40/   40] train: loss: 0.0850952
[Epoch 57] ogbg-molclintox: 0.894223 val loss: 0.101197
[Epoch 57] ogbg-molclintox: 0.810360 test loss: 0.285745
[Epoch 58; Iter    30/   40] train: loss: 0.0578377
[Epoch 58] ogbg-molclintox: 0.974502 val loss: 0.105077
[Epoch 58] ogbg-molclintox: 0.850286 test loss: 0.274133
[Epoch 59; Iter    20/   40] train: loss: 0.0355681
[Epoch 59] ogbg-molclintox: 0.947092 val loss: 0.080031
[Epoch 59] ogbg-molclintox: 0.833133 test loss: 0.202409
[Epoch 60; Iter    10/   40] train: loss: 0.0418629
[Epoch 60; Iter    40/   40] train: loss: 0.0771397
[Epoch 60] ogbg-molclintox: 0.868637 val loss: 0.106654
[Epoch 60] ogbg-molclintox: 0.838355 test loss: 1.343063
[Epoch 61; Iter    30/   40] train: loss: 0.0857255
[Epoch 61] ogbg-molclintox: 0.826756 val loss: 0.131927
[Epoch 61] ogbg-molclintox: 0.831934 test loss: 0.756395
[Epoch 62; Iter    20/   40] train: loss: 0.0943573
[Epoch 62] ogbg-molclintox: 0.947630 val loss: 0.081197
[Epoch 62] ogbg-molclintox: 0.876594 test loss: 0.628903
[Epoch 63; Iter    10/   40] train: loss: 0.0877788
[Epoch 63; Iter    40/   40] train: loss: 0.2292525
[Epoch 63] ogbg-molclintox: 0.968208 val loss: 0.080522
[Epoch 63] ogbg-molclintox: 0.825827 test loss: 0.197944
[Epoch 64; Iter    30/   40] train: loss: 0.0410058
[Epoch 64] ogbg-molclintox: 0.947992 val loss: 0.108010
[Epoch 64] ogbg-molclintox: 0.876904 test loss: 1.312304
[Epoch 65; Iter    20/   40] train: loss: 0.1622224
[Epoch 65] ogbg-molclintox: 0.952275 val loss: 0.255577
[Epoch 65] ogbg-molclintox: 0.856643 test loss: 0.589770
[Epoch 66; Iter    10/   40] train: loss: 0.1031329
[Epoch 66; Iter    40/   40] train: loss: 0.0388227
[Epoch 66] ogbg-molclintox: 0.859271 val loss: 0.130621
[Epoch 66] ogbg-molclintox: 0.813632 test loss: 0.385627
[Epoch 67; Iter    30/   40] train: loss: 0.0253499
[Epoch 67] ogbg-molclintox: 0.954559 val loss: 0.083490
[Epoch 67] ogbg-molclintox: 0.890220 test loss: 0.438413
[Epoch 68; Iter    20/   40] train: loss: 0.0500474
[Epoch 68] ogbg-molclintox: 0.967396 val loss: 0.073811
[Epoch 68] ogbg-molclintox: 0.875555 test loss: 0.351644
[Epoch 69; Iter    10/   40] train: loss: 0.0247165
[Epoch 69; Iter    40/   40] train: loss: 0.0510603
[Epoch 69] ogbg-molclintox: 0.960266 val loss: 0.093726
[Epoch 69] ogbg-molclintox: 0.863401 test loss: 1.084745
[Epoch 70; Iter    30/   40] train: loss: 0.0938885
[Epoch 70] ogbg-molclintox: 0.936216 val loss: 0.084376
[Epoch 70] ogbg-molclintox: 0.881289 test loss: 0.214027
[Epoch 71; Iter    20/   40] train: loss: 0.0805146
[Epoch 71] ogbg-molclintox: 0.868661 val loss: 0.100163
[Epoch 71] ogbg-molclintox: 0.850211 test loss: 0.263000
[Epoch 72; Iter    10/   40] train: loss: 0.0106373
[Epoch 72; Iter    40/   40] train: loss: 0.0235821
[Epoch 72] ogbg-molclintox: 0.920982 val loss: 0.099868
[Epoch 72] ogbg-molclintox: 0.855893 test loss: 0.921968
[Epoch 73; Iter    30/   40] train: loss: 0.0817529
[Epoch 73] ogbg-molclintox: 0.918547 val loss: 0.137837
[Epoch 73] ogbg-molclintox: 0.848471 test loss: 0.398811
[Epoch 74; Iter    20/   40] train: loss: 0.0936829
[Epoch 74] ogbg-molclintox: 0.906047 val loss: 0.107097
[Epoch 74] ogbg-molclintox: 0.826511 test loss: 0.360058
[Epoch 75; Iter    10/   40] train: loss: 0.0731110
[Epoch 75; Iter    40/   40] train: loss: 0.0214946
[Epoch 75] ogbg-molclintox: 0.938402 val loss: 0.095702
[Epoch 75] ogbg-molclintox: 0.875805 test loss: 1.915787
[Epoch 76; Iter    30/   40] train: loss: 0.0480931
[Epoch 33; Iter    20/   35] train: loss: 0.3694453
[Epoch 33] ogbg-molclintox: 0.805603 val loss: 0.234495
[Epoch 33] ogbg-molclintox: 0.620880 test loss: 0.220685
[Epoch 34; Iter    15/   35] train: loss: 0.1386372
[Epoch 34] ogbg-molclintox: 0.758719 val loss: 0.243555
[Epoch 34] ogbg-molclintox: 0.581203 test loss: 0.228697
[Epoch 35; Iter    10/   35] train: loss: 0.2307664
[Epoch 35] ogbg-molclintox: 0.740767 val loss: 0.246708
[Epoch 35] ogbg-molclintox: 0.585256 test loss: 0.223965
[Epoch 36; Iter     5/   35] train: loss: 0.1735723
[Epoch 36; Iter    35/   35] train: loss: 0.3170388
[Epoch 36] ogbg-molclintox: 0.773664 val loss: 0.240779
[Epoch 36] ogbg-molclintox: 0.721193 test loss: 0.259544
[Epoch 37; Iter    30/   35] train: loss: 0.2516917
[Epoch 37] ogbg-molclintox: 0.767613 val loss: 0.236381
[Epoch 37] ogbg-molclintox: 0.676635 test loss: 0.222042
[Epoch 38; Iter    25/   35] train: loss: 0.2500812
[Epoch 38] ogbg-molclintox: 0.755202 val loss: 0.256023
[Epoch 38] ogbg-molclintox: 0.622008 test loss: 0.285102
[Epoch 39; Iter    20/   35] train: loss: 0.2285180
[Epoch 39] ogbg-molclintox: 0.773231 val loss: 0.249901
[Epoch 39] ogbg-molclintox: 0.689702 test loss: 0.254066
[Epoch 40; Iter    15/   35] train: loss: 0.1173371
[Epoch 40] ogbg-molclintox: 0.824835 val loss: 0.225398
[Epoch 40] ogbg-molclintox: 0.663477 test loss: 0.290111
[Epoch 41; Iter    10/   35] train: loss: 0.2497236
[Epoch 41] ogbg-molclintox: 0.889136 val loss: 0.197107
[Epoch 41] ogbg-molclintox: 0.766681 test loss: 0.256792
[Epoch 42; Iter     5/   35] train: loss: 0.0896953
[Epoch 42; Iter    35/   35] train: loss: 0.0824478
[Epoch 42] ogbg-molclintox: 0.895306 val loss: 0.194557
[Epoch 42] ogbg-molclintox: 0.763761 test loss: 0.469110
[Epoch 43; Iter    30/   35] train: loss: 0.0571957
[Epoch 43] ogbg-molclintox: 0.911575 val loss: 0.284559
[Epoch 43] ogbg-molclintox: 0.854930 test loss: 1.122877
[Epoch 44; Iter    25/   35] train: loss: 0.2969636
[Epoch 44] ogbg-molclintox: 0.916259 val loss: 0.155952
[Epoch 44] ogbg-molclintox: 0.839862 test loss: 0.147032
[Epoch 45; Iter    20/   35] train: loss: 0.1677030
[Epoch 45] ogbg-molclintox: 0.938542 val loss: 0.191611
[Epoch 45] ogbg-molclintox: 0.866512 test loss: 0.267346
[Epoch 46; Iter    15/   35] train: loss: 0.1136089
[Epoch 46] ogbg-molclintox: 0.983048 val loss: 0.124824
[Epoch 46] ogbg-molclintox: 0.886008 test loss: 0.161254
[Epoch 47; Iter    10/   35] train: loss: 0.1562458
[Epoch 47] ogbg-molclintox: 0.911722 val loss: 0.179479
[Epoch 47] ogbg-molclintox: 0.859131 test loss: 0.150037
[Epoch 48; Iter     5/   35] train: loss: 0.1350489
[Epoch 48; Iter    35/   35] train: loss: 0.1071968
[Epoch 48] ogbg-molclintox: 0.942497 val loss: 0.134825
[Epoch 48] ogbg-molclintox: 0.846784 test loss: 0.161866
[Epoch 49; Iter    30/   35] train: loss: 0.0889601
[Epoch 49] ogbg-molclintox: 0.921952 val loss: 0.179741
[Epoch 49] ogbg-molclintox: 0.850038 test loss: 0.142072
[Epoch 50; Iter    25/   35] train: loss: 0.1641231
[Epoch 50] ogbg-molclintox: 0.883299 val loss: 0.177220
[Epoch 50] ogbg-molclintox: 0.801166 test loss: 0.178751
[Epoch 51; Iter    20/   35] train: loss: 0.1757540
[Epoch 51] ogbg-molclintox: 0.943015 val loss: 0.128607
[Epoch 51] ogbg-molclintox: 0.811234 test loss: 0.186278
[Epoch 52; Iter    15/   35] train: loss: 0.0616110
[Epoch 52] ogbg-molclintox: 0.986070 val loss: 0.098797
[Epoch 52] ogbg-molclintox: 0.868780 test loss: 0.112302
[Epoch 53; Iter    10/   35] train: loss: 0.0829483
[Epoch 53] ogbg-molclintox: 0.969538 val loss: 0.144421
[Epoch 53] ogbg-molclintox: 0.822895 test loss: 0.160654
[Epoch 54; Iter     5/   35] train: loss: 0.2192522
[Epoch 54; Iter    35/   35] train: loss: 0.0967776
[Epoch 54] ogbg-molclintox: 0.976905 val loss: 0.105201
[Epoch 54] ogbg-molclintox: 0.843371 test loss: 0.130957
[Epoch 55; Iter    30/   35] train: loss: 0.1179292
[Epoch 55] ogbg-molclintox: 0.934940 val loss: 0.141838
[Epoch 55] ogbg-molclintox: 0.832969 test loss: 0.155037
[Epoch 56; Iter    25/   35] train: loss: 0.0949664
[Epoch 56] ogbg-molclintox: 0.970021 val loss: 0.115357
[Epoch 56] ogbg-molclintox: 0.820531 test loss: 0.149189
[Epoch 57; Iter    20/   35] train: loss: 0.0378330
[Epoch 57] ogbg-molclintox: 0.958417 val loss: 0.188436
[Epoch 57] ogbg-molclintox: 0.857209 test loss: 0.205648
[Epoch 58; Iter    15/   35] train: loss: 0.0453395
[Epoch 58] ogbg-molclintox: 0.943743 val loss: 0.119243
[Epoch 58] ogbg-molclintox: 0.865055 test loss: 0.176134
[Epoch 59; Iter    10/   35] train: loss: 0.0668740
[Epoch 59] ogbg-molclintox: 0.940723 val loss: 0.145854
[Epoch 59] ogbg-molclintox: 0.823507 test loss: 0.144502
[Epoch 60; Iter     5/   35] train: loss: 0.0346635
[Epoch 60; Iter    35/   35] train: loss: 0.0136248
[Epoch 60] ogbg-molclintox: 0.954022 val loss: 0.163984
[Epoch 60] ogbg-molclintox: 0.882952 test loss: 0.142375
[Epoch 61; Iter    30/   35] train: loss: 0.0527687
[Epoch 61] ogbg-molclintox: 0.955669 val loss: 0.133769
[Epoch 61] ogbg-molclintox: 0.803575 test loss: 0.159282
[Epoch 62; Iter    25/   35] train: loss: 0.3784643
[Epoch 62] ogbg-molclintox: 0.964856 val loss: 0.166789
[Epoch 62] ogbg-molclintox: 0.878751 test loss: 0.160186
[Epoch 63; Iter    20/   35] train: loss: 0.1659122
[Epoch 63] ogbg-molclintox: 0.947139 val loss: 0.149453
[Epoch 63] ogbg-molclintox: 0.867601 test loss: 0.279345
[Epoch 64; Iter    15/   35] train: loss: 0.0775170
[Epoch 64] ogbg-molclintox: 0.936624 val loss: 0.293800
[Epoch 64] ogbg-molclintox: 0.815956 test loss: 0.204935
[Epoch 65; Iter    10/   35] train: loss: 0.0533229
[Epoch 65] ogbg-molclintox: 0.976808 val loss: 0.109834
[Epoch 65] ogbg-molclintox: 0.883587 test loss: 1.580565
[Epoch 66; Iter     5/   35] train: loss: 0.0747486
[Epoch 66; Iter    35/   35] train: loss: 0.2996107
[Epoch 66] ogbg-molclintox: 0.896341 val loss: 0.154676
[Epoch 66] ogbg-molclintox: 0.816602 test loss: 0.155294
[Epoch 67; Iter    30/   35] train: loss: 0.0480611
[Epoch 67] ogbg-molclintox: 0.943944 val loss: 0.163598
[Epoch 67] ogbg-molclintox: 0.815786 test loss: 0.158665
[Epoch 68; Iter    25/   35] train: loss: 0.0412378
[Epoch 68] ogbg-molclintox: 0.963321 val loss: 0.118546
[Epoch 68] ogbg-molclintox: 0.852385 test loss: 0.135830
[Epoch 69; Iter    20/   35] train: loss: 0.1111782
[Epoch 69] ogbg-molclintox: 0.965860 val loss: 0.161407
[Epoch 69] ogbg-molclintox: 0.915566 test loss: 0.120800
[Epoch 70; Iter    15/   35] train: loss: 0.1443552
[Epoch 70] ogbg-molclintox: 0.932872 val loss: 0.149204
[Epoch 70] ogbg-molclintox: 0.853071 test loss: 0.150920
[Epoch 71; Iter    10/   35] train: loss: 0.1107538
[Epoch 71] ogbg-molclintox: 0.963978 val loss: 0.121734
[Epoch 71] ogbg-molclintox: 0.847391 test loss: 0.140744
[Epoch 72; Iter     5/   35] train: loss: 0.0393875
[Epoch 72; Iter    35/   35] train: loss: 0.0490824
[Epoch 72] ogbg-molclintox: 0.930406 val loss: 0.163539
[Epoch 72] ogbg-molclintox: 0.853848 test loss: 0.138101
[Epoch 73; Iter    30/   35] train: loss: 0.0425997
[Epoch 73] ogbg-molclintox: 0.932538 val loss: 0.189359
[Epoch 73] ogbg-molclintox: 0.836115 test loss: 0.151962
[Epoch 74; Iter    25/   35] train: loss: 0.0819296
[Epoch 74] ogbg-molclintox: 0.932377 val loss: 0.139901
[Epoch 74] ogbg-molclintox: 0.890322 test loss: 0.115799
[Epoch 75; Iter    20/   35] train: loss: 0.0701953
[Epoch 75] ogbg-molclintox: 0.933812 val loss: 0.203295
[Epoch 75] ogbg-molclintox: 0.860962 test loss: 0.149959
[Epoch 76; Iter    15/   35] train: loss: 0.1251924
[Epoch 76] ogbg-molclintox: 0.928698 val loss: 0.161783
[Epoch 76] ogbg-molclintox: 0.883797 test loss: 0.126696
[Epoch 77; Iter    10/   35] train: loss: 0.0835316
[Epoch 77] ogbg-molclintox: 0.926382 val loss: 0.136104
[Epoch 77] ogbg-molclintox: 0.874755 test loss: 0.115274
[Epoch 78; Iter     5/   35] train: loss: 0.0326113
[Epoch 78; Iter    35/   35] train: loss: 0.1063224
[Epoch 78] ogbg-molclintox: 0.939013 val loss: 0.123292
[Epoch 78] ogbg-molclintox: 0.869999 test loss: 0.127457
[Epoch 79; Iter    30/   35] train: loss: 0.0508326
[Epoch 79] ogbg-molclintox: 0.929515 val loss: 0.130341
[Epoch 79] ogbg-molclintox: 0.857045 test loss: 0.124108
[Epoch 33; Iter    20/   35] train: loss: 0.2333593
[Epoch 33] ogbg-molclintox: 0.775682 val loss: 0.236248
[Epoch 33] ogbg-molclintox: 0.618607 test loss: 0.216338
[Epoch 34; Iter    15/   35] train: loss: 0.1513443
[Epoch 34] ogbg-molclintox: 0.797724 val loss: 0.245709
[Epoch 34] ogbg-molclintox: 0.659282 test loss: 0.229008
[Epoch 35; Iter    10/   35] train: loss: 0.0868892
[Epoch 35] ogbg-molclintox: 0.795211 val loss: 0.224843
[Epoch 35] ogbg-molclintox: 0.679396 test loss: 0.199911
[Epoch 36; Iter     5/   35] train: loss: 0.2610711
[Epoch 36; Iter    35/   35] train: loss: 0.1092145
[Epoch 36] ogbg-molclintox: 0.788313 val loss: 0.238500
[Epoch 36] ogbg-molclintox: 0.670183 test loss: 0.231244
[Epoch 37; Iter    30/   35] train: loss: 0.2258659
[Epoch 37] ogbg-molclintox: 0.808922 val loss: 0.224319
[Epoch 37] ogbg-molclintox: 0.710070 test loss: 0.199929
[Epoch 38; Iter    25/   35] train: loss: 0.3254723
[Epoch 38] ogbg-molclintox: 0.754160 val loss: 0.270688
[Epoch 38] ogbg-molclintox: 0.579457 test loss: 0.267159
[Epoch 39; Iter    20/   35] train: loss: 0.2247974
[Epoch 39] ogbg-molclintox: 0.785345 val loss: 0.240986
[Epoch 39] ogbg-molclintox: 0.630087 test loss: 0.238998
[Epoch 40; Iter    15/   35] train: loss: 0.0706281
[Epoch 40] ogbg-molclintox: 0.828740 val loss: 0.290308
[Epoch 40] ogbg-molclintox: 0.706975 test loss: 0.322062
[Epoch 41; Iter    10/   35] train: loss: 0.2025977
[Epoch 41] ogbg-molclintox: 0.877090 val loss: 0.276417
[Epoch 41] ogbg-molclintox: 0.662689 test loss: 0.846375
[Epoch 42; Iter     5/   35] train: loss: 0.1278781
[Epoch 42; Iter    35/   35] train: loss: 0.2170697
[Epoch 42] ogbg-molclintox: 0.937540 val loss: 0.293643
[Epoch 42] ogbg-molclintox: 0.803728 test loss: 0.700128
[Epoch 43; Iter    30/   35] train: loss: 0.1584674
[Epoch 43] ogbg-molclintox: 0.875600 val loss: 0.240089
[Epoch 43] ogbg-molclintox: 0.741851 test loss: 0.275330
[Epoch 44; Iter    25/   35] train: loss: 0.2271867
[Epoch 44] ogbg-molclintox: 0.904073 val loss: 0.207591
[Epoch 44] ogbg-molclintox: 0.692689 test loss: 0.330819
[Epoch 45; Iter    20/   35] train: loss: 0.2276999
[Epoch 45] ogbg-molclintox: 0.903774 val loss: 0.161580
[Epoch 45] ogbg-molclintox: 0.863871 test loss: 0.347071
[Epoch 46; Iter    15/   35] train: loss: 0.1147443
[Epoch 46] ogbg-molclintox: 0.946209 val loss: 0.161164
[Epoch 46] ogbg-molclintox: 0.813507 test loss: 0.411779
[Epoch 47; Iter    10/   35] train: loss: 0.1090411
[Epoch 47] ogbg-molclintox: 0.980039 val loss: 0.133448
[Epoch 47] ogbg-molclintox: 0.853638 test loss: 0.242631
[Epoch 48; Iter     5/   35] train: loss: 0.1621556
[Epoch 48; Iter    35/   35] train: loss: 0.3227451
[Epoch 48] ogbg-molclintox: 0.949888 val loss: 0.150011
[Epoch 48] ogbg-molclintox: 0.769754 test loss: 0.206706
[Epoch 49; Iter    30/   35] train: loss: 0.1523025
[Epoch 49] ogbg-molclintox: 0.970911 val loss: 0.151308
[Epoch 49] ogbg-molclintox: 0.874942 test loss: 0.235403
[Epoch 50; Iter    25/   35] train: loss: 0.0854069
[Epoch 50] ogbg-molclintox: 0.950529 val loss: 0.202209
[Epoch 50] ogbg-molclintox: 0.873967 test loss: 1.805151
[Epoch 51; Iter    20/   35] train: loss: 0.1621184
[Epoch 51] ogbg-molclintox: 0.973217 val loss: 0.115413
[Epoch 51] ogbg-molclintox: 0.843757 test loss: 0.167899
[Epoch 52; Iter    15/   35] train: loss: 0.1704920
[Epoch 52] ogbg-molclintox: 0.930693 val loss: 0.184944
[Epoch 52] ogbg-molclintox: 0.858831 test loss: 0.200865
[Epoch 53; Iter    10/   35] train: loss: 0.0765518
[Epoch 53] ogbg-molclintox: 0.971260 val loss: 0.147604
[Epoch 53] ogbg-molclintox: 0.867130 test loss: 0.143751
[Epoch 54; Iter     5/   35] train: loss: 0.2788813
[Epoch 54; Iter    35/   35] train: loss: 0.1051611
[Epoch 54] ogbg-molclintox: 0.972447 val loss: 0.113211
[Epoch 54] ogbg-molclintox: 0.851506 test loss: 0.140318
[Epoch 55; Iter    30/   35] train: loss: 0.1608009
[Epoch 55] ogbg-molclintox: 0.959744 val loss: 0.120054
[Epoch 55] ogbg-molclintox: 0.837470 test loss: 0.143692
[Epoch 56; Iter    25/   35] train: loss: 0.1499784
[Epoch 56] ogbg-molclintox: 0.979939 val loss: 0.092618
[Epoch 56] ogbg-molclintox: 0.887011 test loss: 0.132387
[Epoch 57; Iter    20/   35] train: loss: 0.0572691
[Epoch 57] ogbg-molclintox: 0.956375 val loss: 0.157793
[Epoch 57] ogbg-molclintox: 0.838258 test loss: 0.157195
[Epoch 58; Iter    15/   35] train: loss: 0.0632818
[Epoch 58] ogbg-molclintox: 0.959618 val loss: 0.134914
[Epoch 58] ogbg-molclintox: 0.888774 test loss: 0.132210
[Epoch 59; Iter    10/   35] train: loss: 0.0533352
[Epoch 59] ogbg-molclintox: 0.968683 val loss: 0.121434
[Epoch 59] ogbg-molclintox: 0.858076 test loss: 0.143622
[Epoch 60; Iter     5/   35] train: loss: 0.0614795
[Epoch 60; Iter    35/   35] train: loss: 0.0164943
[Epoch 60] ogbg-molclintox: 0.953006 val loss: 0.128429
[Epoch 60] ogbg-molclintox: 0.812645 test loss: 0.169749
[Epoch 61; Iter    30/   35] train: loss: 0.0820627
[Epoch 61] ogbg-molclintox: 0.976410 val loss: 0.106029
[Epoch 61] ogbg-molclintox: 0.882952 test loss: 0.136547
[Epoch 62; Iter    25/   35] train: loss: 0.1210379
[Epoch 62] ogbg-molclintox: 0.974219 val loss: 0.140352
[Epoch 62] ogbg-molclintox: 0.880339 test loss: 0.133275
[Epoch 63; Iter    20/   35] train: loss: 0.0909897
[Epoch 63] ogbg-molclintox: 0.967383 val loss: 0.165959
[Epoch 63] ogbg-molclintox: 0.905962 test loss: 0.142497
[Epoch 64; Iter    15/   35] train: loss: 0.1038242
[Epoch 64] ogbg-molclintox: 0.957959 val loss: 0.135309
[Epoch 64] ogbg-molclintox: 0.876994 test loss: 0.147777
[Epoch 65; Iter    10/   35] train: loss: 0.1084958
[Epoch 65] ogbg-molclintox: 0.966900 val loss: 0.186667
[Epoch 65] ogbg-molclintox: 0.894075 test loss: 0.144376
[Epoch 66; Iter     5/   35] train: loss: 0.0777914
[Epoch 66; Iter    35/   35] train: loss: 0.0140943
[Epoch 66] ogbg-molclintox: 0.971803 val loss: 0.120032
[Epoch 66] ogbg-molclintox: 0.856909 test loss: 0.141662
[Epoch 67; Iter    30/   35] train: loss: 0.1360332
[Epoch 67] ogbg-molclintox: 0.964213 val loss: 0.169754
[Epoch 67] ogbg-molclintox: 0.803909 test loss: 0.258644
[Epoch 68; Iter    25/   35] train: loss: 0.1069774
[Epoch 68] ogbg-molclintox: 0.964474 val loss: 0.163571
[Epoch 68] ogbg-molclintox: 0.848490 test loss: 0.154570
[Epoch 69; Iter    20/   35] train: loss: 0.0412223
[Epoch 69] ogbg-molclintox: 0.953069 val loss: 0.117587
[Epoch 69] ogbg-molclintox: 0.846552 test loss: 0.160505
[Epoch 70; Iter    15/   35] train: loss: 0.0719645
[Epoch 70] ogbg-molclintox: 0.969326 val loss: 0.196817
[Epoch 70] ogbg-molclintox: 0.899267 test loss: 0.132229
[Epoch 71; Iter    10/   35] train: loss: 0.0572012
[Epoch 71] ogbg-molclintox: 0.958752 val loss: 0.116709
[Epoch 71] ogbg-molclintox: 0.845735 test loss: 0.161127
[Epoch 72; Iter     5/   35] train: loss: 0.0410980
[Epoch 72; Iter    35/   35] train: loss: 0.2037864
[Epoch 72] ogbg-molclintox: 0.973475 val loss: 0.159937
[Epoch 72] ogbg-molclintox: 0.869874 test loss: 0.127502
[Epoch 73; Iter    30/   35] train: loss: 0.1756867
[Epoch 73] ogbg-molclintox: 0.962974 val loss: 0.129906
[Epoch 73] ogbg-molclintox: 0.899131 test loss: 0.136516
[Epoch 74; Iter    25/   35] train: loss: 0.1226593
[Epoch 74] ogbg-molclintox: 0.970143 val loss: 0.117620
[Epoch 74] ogbg-molclintox: 0.859845 test loss: 0.141537
[Epoch 75; Iter    20/   35] train: loss: 0.0605540
[Epoch 75] ogbg-molclintox: 0.971035 val loss: 0.099880
[Epoch 75] ogbg-molclintox: 0.887266 test loss: 0.281575
[Epoch 76; Iter    15/   35] train: loss: 0.0585808
[Epoch 76] ogbg-molclintox: 0.966503 val loss: 0.273698
[Epoch 76] ogbg-molclintox: 0.851387 test loss: 0.462679
[Epoch 77; Iter    10/   35] train: loss: 0.1686323
[Epoch 77] ogbg-molclintox: 0.964868 val loss: 0.232680
[Epoch 77] ogbg-molclintox: 0.905424 test loss: 0.147366
[Epoch 78; Iter     5/   35] train: loss: 0.0442067
[Epoch 78; Iter    35/   35] train: loss: 0.0209567
[Epoch 78] ogbg-molclintox: 0.976359 val loss: 0.144622
[Epoch 78] ogbg-molclintox: 0.864335 test loss: 0.149331
[Epoch 79; Iter    30/   35] train: loss: 0.0369517
[Epoch 79] ogbg-molclintox: 0.972225 val loss: 0.123441
[Epoch 79] ogbg-molclintox: 0.879647 test loss: 0.140899
[Epoch 34] ogbg-molclintox: 0.717947 test loss: 0.403567
[Epoch 35; Iter    30/   30] train: loss: 0.2362033
[Epoch 35] ogbg-molclintox: 0.661298 val loss: 0.363888
[Epoch 35] ogbg-molclintox: 0.683634 test loss: 0.306366
[Epoch 36; Iter    30/   30] train: loss: 0.1110068
[Epoch 36] ogbg-molclintox: 0.697518 val loss: 0.326170
[Epoch 36] ogbg-molclintox: 0.753084 test loss: 0.261412
[Epoch 37; Iter    30/   30] train: loss: 0.4573223
[Epoch 37] ogbg-molclintox: 0.723516 val loss: 0.317189
[Epoch 37] ogbg-molclintox: 0.738866 test loss: 0.238770
[Epoch 38; Iter    30/   30] train: loss: 0.1587967
[Epoch 38] ogbg-molclintox: 0.670592 val loss: 0.240845
[Epoch 38] ogbg-molclintox: 0.648686 test loss: 0.210854
[Epoch 39; Iter    30/   30] train: loss: 0.1068224
[Epoch 39] ogbg-molclintox: 0.705106 val loss: 0.266990
[Epoch 39] ogbg-molclintox: 0.749489 test loss: 0.226472
[Epoch 40; Iter    30/   30] train: loss: 0.1026267
[Epoch 40] ogbg-molclintox: 0.710039 val loss: 0.247946
[Epoch 40] ogbg-molclintox: 0.734196 test loss: 0.200440
[Epoch 41; Iter    30/   30] train: loss: 0.0976091
[Epoch 41] ogbg-molclintox: 0.688707 val loss: 0.290799
[Epoch 41] ogbg-molclintox: 0.731010 test loss: 0.211653
[Epoch 42; Iter    30/   30] train: loss: 0.2215587
[Epoch 42] ogbg-molclintox: 0.676112 val loss: 0.287563
[Epoch 42] ogbg-molclintox: 0.725180 test loss: 0.208276
[Epoch 43; Iter    30/   30] train: loss: 0.1161164
[Epoch 43] ogbg-molclintox: 0.705539 val loss: 0.298612
[Epoch 43] ogbg-molclintox: 0.716046 test loss: 0.233862
[Epoch 44; Iter    30/   30] train: loss: 0.3193498
[Epoch 44] ogbg-molclintox: 0.702745 val loss: 0.261960
[Epoch 44] ogbg-molclintox: 0.735449 test loss: 0.194066
[Epoch 45; Iter    30/   30] train: loss: 0.0991794
[Epoch 45] ogbg-molclintox: 0.684141 val loss: 0.349988
[Epoch 45] ogbg-molclintox: 0.683435 test loss: 0.254117
[Epoch 46; Iter    30/   30] train: loss: 0.0852973
[Epoch 46] ogbg-molclintox: 0.729759 val loss: 0.239981
[Epoch 46] ogbg-molclintox: 0.747946 test loss: 0.201513
[Epoch 47; Iter    30/   30] train: loss: 0.2313996
[Epoch 47] ogbg-molclintox: 0.736639 val loss: 0.248496
[Epoch 47] ogbg-molclintox: 0.785091 test loss: 0.191649
[Epoch 48; Iter    30/   30] train: loss: 0.2156487
[Epoch 48] ogbg-molclintox: 0.754367 val loss: 1.137804
[Epoch 48] ogbg-molclintox: 0.776054 test loss: 2.374932
[Epoch 49; Iter    30/   30] train: loss: 0.2851712
[Epoch 49] ogbg-molclintox: 0.812432 val loss: 0.236619
[Epoch 49] ogbg-molclintox: 0.828769 test loss: 0.326793
[Epoch 50; Iter    30/   30] train: loss: 0.0510163
[Epoch 50] ogbg-molclintox: 0.823287 val loss: 2.253793
[Epoch 50] ogbg-molclintox: 0.813079 test loss: 4.907669
[Epoch 51; Iter    30/   30] train: loss: 0.2268313
[Epoch 51] ogbg-molclintox: 0.774987 val loss: 0.778659
[Epoch 51] ogbg-molclintox: 0.805063 test loss: 0.763921
[Epoch 52; Iter    30/   30] train: loss: 0.0622865
[Epoch 52] ogbg-molclintox: 0.834132 val loss: 0.236431
[Epoch 52] ogbg-molclintox: 0.852008 test loss: 0.219727
[Epoch 53; Iter    30/   30] train: loss: 0.1051017
[Epoch 53] ogbg-molclintox: 0.822037 val loss: 0.204521
[Epoch 53] ogbg-molclintox: 0.877407 test loss: 0.264258
[Epoch 54; Iter    30/   30] train: loss: 0.0839336
[Epoch 54] ogbg-molclintox: 0.856190 val loss: 0.308836
[Epoch 54] ogbg-molclintox: 0.845367 test loss: 2.366598
[Epoch 55; Iter    30/   30] train: loss: 0.1279092
[Epoch 55] ogbg-molclintox: 0.885998 val loss: 0.175170
[Epoch 55] ogbg-molclintox: 0.910902 test loss: 0.238263
[Epoch 56; Iter    30/   30] train: loss: 0.2670504
[Epoch 56] ogbg-molclintox: 0.821463 val loss: 0.215690
[Epoch 56] ogbg-molclintox: 0.830253 test loss: 0.179896
[Epoch 57; Iter    30/   30] train: loss: 0.0659954
[Epoch 57] ogbg-molclintox: 0.862120 val loss: 0.507898
[Epoch 57] ogbg-molclintox: 0.909206 test loss: 0.538127
[Epoch 58; Iter    30/   30] train: loss: 0.0458570
[Epoch 58] ogbg-molclintox: 0.897329 val loss: 0.175753
[Epoch 58] ogbg-molclintox: 0.900180 test loss: 0.178928
[Epoch 59; Iter    30/   30] train: loss: 0.1165696
[Epoch 59] ogbg-molclintox: 0.869246 val loss: 0.215973
[Epoch 59] ogbg-molclintox: 0.831651 test loss: 0.207803
[Epoch 60; Iter    30/   30] train: loss: 0.2300842
[Epoch 60] ogbg-molclintox: 0.888010 val loss: 0.279039
[Epoch 60] ogbg-molclintox: 0.892428 test loss: 0.302457
[Epoch 61; Iter    30/   30] train: loss: 0.2700776
[Epoch 61] ogbg-molclintox: 0.787090 val loss: 15.539009
[Epoch 61] ogbg-molclintox: 0.713250 test loss: 27.305559
[Epoch 62; Iter    30/   30] train: loss: 0.0793266
[Epoch 62] ogbg-molclintox: 0.892396 val loss: 0.185424
[Epoch 62] ogbg-molclintox: 0.886353 test loss: 0.173822
[Epoch 63; Iter    30/   30] train: loss: 0.1508697
[Epoch 63] ogbg-molclintox: 0.865777 val loss: 0.182245
[Epoch 63] ogbg-molclintox: 0.898563 test loss: 0.143679
[Epoch 64; Iter    30/   30] train: loss: 0.0932226
[Epoch 64] ogbg-molclintox: 0.829893 val loss: 0.316872
[Epoch 64] ogbg-molclintox: 0.873799 test loss: 0.260483
[Epoch 65; Iter    30/   30] train: loss: 0.0497180
[Epoch 65] ogbg-molclintox: 0.875189 val loss: 0.201460
[Epoch 65] ogbg-molclintox: 0.908058 test loss: 0.157299
[Epoch 66; Iter    30/   30] train: loss: 0.1159944
[Epoch 66] ogbg-molclintox: 0.869300 val loss: 0.215200
[Epoch 66] ogbg-molclintox: 0.942044 test loss: 0.138768
[Epoch 67; Iter    30/   30] train: loss: 0.0458074
[Epoch 67] ogbg-molclintox: 0.696744 val loss: 0.385366
[Epoch 67] ogbg-molclintox: 0.763072 test loss: 0.305957
[Epoch 68; Iter    30/   30] train: loss: 0.1070914
[Epoch 68] ogbg-molclintox: 0.891387 val loss: 0.175227
[Epoch 68] ogbg-molclintox: 0.924884 test loss: 0.148735
[Epoch 69; Iter    30/   30] train: loss: 0.2181160
[Epoch 69] ogbg-molclintox: 0.861566 val loss: 0.211464
[Epoch 69] ogbg-molclintox: 0.875654 test loss: 0.265147
[Epoch 70; Iter    30/   30] train: loss: 0.1660751
[Epoch 70] ogbg-molclintox: 0.844833 val loss: 0.231479
[Epoch 70] ogbg-molclintox: 0.902036 test loss: 0.170037
[Epoch 71; Iter    30/   30] train: loss: 0.2435174
[Epoch 71] ogbg-molclintox: 0.898466 val loss: 0.176582
[Epoch 71] ogbg-molclintox: 0.887913 test loss: 0.218003
[Epoch 72; Iter    30/   30] train: loss: 0.0176763
[Epoch 72] ogbg-molclintox: 0.903807 val loss: 0.165086
[Epoch 72] ogbg-molclintox: 0.920730 test loss: 0.148560
[Epoch 73; Iter    30/   30] train: loss: 0.1095750
[Epoch 73] ogbg-molclintox: 0.855222 val loss: 0.220844
[Epoch 73] ogbg-molclintox: 0.928782 test loss: 0.161179
[Epoch 74; Iter    30/   30] train: loss: 0.0630528
[Epoch 74] ogbg-molclintox: 0.897450 val loss: 0.185232
[Epoch 74] ogbg-molclintox: 0.916822 test loss: 0.484366
[Epoch 75; Iter    30/   30] train: loss: 0.0751415
[Epoch 75] ogbg-molclintox: 0.879989 val loss: 0.224871
[Epoch 75] ogbg-molclintox: 0.915553 test loss: 0.344340
[Epoch 76; Iter    30/   30] train: loss: 0.0547876
[Epoch 76] ogbg-molclintox: 0.873659 val loss: 0.186324
[Epoch 76] ogbg-molclintox: 0.929003 test loss: 0.218182
[Epoch 77; Iter    30/   30] train: loss: 0.0306726
[Epoch 77] ogbg-molclintox: 0.879709 val loss: 0.215224
[Epoch 77] ogbg-molclintox: 0.897878 test loss: 0.226034
[Epoch 78; Iter    30/   30] train: loss: 0.2099236
[Epoch 78] ogbg-molclintox: 0.877797 val loss: 0.182039
[Epoch 78] ogbg-molclintox: 0.886661 test loss: 0.310063
[Epoch 79; Iter    30/   30] train: loss: 0.1290241
[Epoch 79] ogbg-molclintox: 0.871587 val loss: 0.183327
[Epoch 79] ogbg-molclintox: 0.929926 test loss: 0.261300
[Epoch 80; Iter    30/   30] train: loss: 0.0909265
[Epoch 80] ogbg-molclintox: 0.853197 val loss: 0.210600
[Epoch 80] ogbg-molclintox: 0.913508 test loss: 0.264301
[Epoch 81; Iter    30/   30] train: loss: 0.1154829
[Epoch 81] ogbg-molclintox: 0.858618 val loss: 0.198394
[Epoch 81] ogbg-molclintox: 0.935923 test loss: 0.215981
[Epoch 82; Iter    30/   30] train: loss: 0.1376701
[Epoch 82] ogbg-molclintox: 0.841170 val loss: 0.265110
[Epoch 82] ogbg-molclintox: 0.925742 test loss: 0.334699
[Epoch 83; Iter    30/   30] train: loss: 0.0859896
[Epoch 83] ogbg-molclintox: 0.892069 val loss: 0.194444
[Epoch 83] ogbg-molclintox: 0.928689 test loss: 0.294635
[Epoch 34] ogbg-molclintox: 0.671554 test loss: 0.211067
[Epoch 35; Iter    30/   30] train: loss: 0.1963206
[Epoch 35] ogbg-molclintox: 0.669602 val loss: 0.279709
[Epoch 35] ogbg-molclintox: 0.648362 test loss: 0.246122
[Epoch 36; Iter    30/   30] train: loss: 0.5258000
[Epoch 36] ogbg-molclintox: 0.681547 val loss: 0.322101
[Epoch 36] ogbg-molclintox: 0.682645 test loss: 0.253944
[Epoch 37; Iter    30/   30] train: loss: 0.2685195
[Epoch 37] ogbg-molclintox: 0.674254 val loss: 0.282719
[Epoch 37] ogbg-molclintox: 0.703281 test loss: 0.214357
[Epoch 38; Iter    30/   30] train: loss: 0.0981501
[Epoch 38] ogbg-molclintox: 0.754006 val loss: 0.262066
[Epoch 38] ogbg-molclintox: 0.741341 test loss: 0.216578
[Epoch 39; Iter    30/   30] train: loss: 0.3139600
[Epoch 39] ogbg-molclintox: 0.689876 val loss: 0.366339
[Epoch 39] ogbg-molclintox: 0.750399 test loss: 0.277287
[Epoch 40; Iter    30/   30] train: loss: 0.1607618
[Epoch 40] ogbg-molclintox: 0.748705 val loss: 0.224522
[Epoch 40] ogbg-molclintox: 0.706070 test loss: 0.186567
[Epoch 41; Iter    30/   30] train: loss: 0.3184302
[Epoch 41] ogbg-molclintox: 0.732367 val loss: 0.235297
[Epoch 41] ogbg-molclintox: 0.744864 test loss: 0.192175
[Epoch 42; Iter    30/   30] train: loss: 0.2325943
[Epoch 42] ogbg-molclintox: 0.738757 val loss: 0.269319
[Epoch 42] ogbg-molclintox: 0.774748 test loss: 0.213635
[Epoch 43; Iter    30/   30] train: loss: 0.1328960
[Epoch 43] ogbg-molclintox: 0.709049 val loss: 0.238852
[Epoch 43] ogbg-molclintox: 0.737073 test loss: 0.180855
[Epoch 44; Iter    30/   30] train: loss: 0.1151750
[Epoch 44] ogbg-molclintox: 0.675805 val loss: 0.309776
[Epoch 44] ogbg-molclintox: 0.767596 test loss: 0.227681
[Epoch 45; Iter    30/   30] train: loss: 0.4078088
[Epoch 45] ogbg-molclintox: 0.669729 val loss: 0.257018
[Epoch 45] ogbg-molclintox: 0.784622 test loss: 0.188707
[Epoch 46; Iter    30/   30] train: loss: 0.3300614
[Epoch 46] ogbg-molclintox: 0.731960 val loss: 0.289018
[Epoch 46] ogbg-molclintox: 0.762396 test loss: 0.245061
[Epoch 47; Iter    30/   30] train: loss: 0.0949217
[Epoch 47] ogbg-molclintox: 0.760451 val loss: 0.302780
[Epoch 47] ogbg-molclintox: 0.773415 test loss: 0.223020
[Epoch 48; Iter    30/   30] train: loss: 0.1621451
[Epoch 48] ogbg-molclintox: 0.773387 val loss: 0.260176
[Epoch 48] ogbg-molclintox: 0.825731 test loss: 0.188145
[Epoch 49; Iter    30/   30] train: loss: 0.0684577
[Epoch 49] ogbg-molclintox: 0.818855 val loss: 0.262910
[Epoch 49] ogbg-molclintox: 0.813808 test loss: 0.771195
[Epoch 50; Iter    30/   30] train: loss: 0.1233587
[Epoch 50] ogbg-molclintox: 0.835266 val loss: 0.520699
[Epoch 50] ogbg-molclintox: 0.857703 test loss: 0.431678
[Epoch 51; Iter    30/   30] train: loss: 0.1132674
[Epoch 51] ogbg-molclintox: 0.828743 val loss: 0.294781
[Epoch 51] ogbg-molclintox: 0.892303 test loss: 0.250534
[Epoch 52; Iter    30/   30] train: loss: 0.0633046
[Epoch 52] ogbg-molclintox: 0.861626 val loss: 0.326807
[Epoch 52] ogbg-molclintox: 0.865802 test loss: 0.604444
[Epoch 53; Iter    30/   30] train: loss: 0.0868915
[Epoch 53] ogbg-molclintox: 0.825534 val loss: 0.279204
[Epoch 53] ogbg-molclintox: 0.845954 test loss: 0.352524
[Epoch 54; Iter    30/   30] train: loss: 0.2142571
[Epoch 54] ogbg-molclintox: 0.892115 val loss: 0.224807
[Epoch 54] ogbg-molclintox: 0.910260 test loss: 0.348787
[Epoch 55; Iter    30/   30] train: loss: 0.1760839
[Epoch 55] ogbg-molclintox: 0.885538 val loss: 0.170380
[Epoch 55] ogbg-molclintox: 0.918052 test loss: 0.757305
[Epoch 56; Iter    30/   30] train: loss: 0.2139180
[Epoch 56] ogbg-molclintox: 0.887128 val loss: 0.213629
[Epoch 56] ogbg-molclintox: 0.860500 test loss: 2.679407
[Epoch 57; Iter    30/   30] train: loss: 0.0801826
[Epoch 57] ogbg-molclintox: 0.793454 val loss: 0.234982
[Epoch 57] ogbg-molclintox: 0.819206 test loss: 0.341591
[Epoch 58; Iter    30/   30] train: loss: 0.1637936
[Epoch 58] ogbg-molclintox: 0.790457 val loss: 0.274535
[Epoch 58] ogbg-molclintox: 0.822496 test loss: 0.240905
[Epoch 59; Iter    30/   30] train: loss: 0.1446274
[Epoch 59] ogbg-molclintox: 0.830722 val loss: 0.228807
[Epoch 59] ogbg-molclintox: 0.863284 test loss: 0.165499
[Epoch 60; Iter    30/   30] train: loss: 0.1082881
[Epoch 60] ogbg-molclintox: 0.860690 val loss: 0.196273
[Epoch 60] ogbg-molclintox: 0.871606 test loss: 0.146580
[Epoch 61; Iter    30/   30] train: loss: 0.0929344
[Epoch 61] ogbg-molclintox: 0.926983 val loss: 0.165525
[Epoch 61] ogbg-molclintox: 0.949480 test loss: 0.255620
[Epoch 62; Iter    30/   30] train: loss: 0.3366454
[Epoch 62] ogbg-molclintox: 0.851939 val loss: 0.275642
[Epoch 62] ogbg-molclintox: 0.871794 test loss: 0.244884
[Epoch 63; Iter    30/   30] train: loss: 0.1132498
[Epoch 63] ogbg-molclintox: 0.883712 val loss: 0.181468
[Epoch 63] ogbg-molclintox: 0.866220 test loss: 0.145486
[Epoch 64; Iter    30/   30] train: loss: 0.1538137
[Epoch 64] ogbg-molclintox: 0.896113 val loss: 0.274514
[Epoch 64] ogbg-molclintox: 0.927895 test loss: 0.177095
[Epoch 65; Iter    30/   30] train: loss: 0.1432830
[Epoch 65] ogbg-molclintox: 0.878144 val loss: 0.180052
[Epoch 65] ogbg-molclintox: 0.908777 test loss: 0.126046
[Epoch 66; Iter    30/   30] train: loss: 0.0835340
[Epoch 66] ogbg-molclintox: 0.884555 val loss: 0.210518
[Epoch 66] ogbg-molclintox: 0.885171 test loss: 0.204413
[Epoch 67; Iter    30/   30] train: loss: 0.3663498
[Epoch 67] ogbg-molclintox: 0.872415 val loss: 0.209785
[Epoch 67] ogbg-molclintox: 0.872168 test loss: 0.221015
[Epoch 68; Iter    30/   30] train: loss: 0.1601983
[Epoch 68] ogbg-molclintox: 0.911903 val loss: 0.155024
[Epoch 68] ogbg-molclintox: 0.934051 test loss: 0.107316
[Epoch 69; Iter    30/   30] train: loss: 0.0257720
[Epoch 69] ogbg-molclintox: 0.897042 val loss: 0.167424
[Epoch 69] ogbg-molclintox: 0.916487 test loss: 0.123543
[Epoch 70; Iter    30/   30] train: loss: 0.1324475
[Epoch 70] ogbg-molclintox: 0.899601 val loss: 0.251546
[Epoch 70] ogbg-molclintox: 0.894670 test loss: 0.190424
[Epoch 71; Iter    30/   30] train: loss: 0.2121409
[Epoch 71] ogbg-molclintox: 0.908393 val loss: 0.184828
[Epoch 71] ogbg-molclintox: 0.934034 test loss: 0.135020
[Epoch 72; Iter    30/   30] train: loss: 0.1278970
[Epoch 72] ogbg-molclintox: 0.901414 val loss: 0.188125
[Epoch 72] ogbg-molclintox: 0.895942 test loss: 0.144365
[Epoch 73; Iter    30/   30] train: loss: 0.0902312
[Epoch 73] ogbg-molclintox: 0.909456 val loss: 0.176159
[Epoch 73] ogbg-molclintox: 0.900978 test loss: 0.139944
[Epoch 74; Iter    30/   30] train: loss: 0.2905012
[Epoch 74] ogbg-molclintox: 0.942003 val loss: 0.160945
[Epoch 74] ogbg-molclintox: 0.907892 test loss: 0.141646
[Epoch 75; Iter    30/   30] train: loss: 0.2507574
[Epoch 75] ogbg-molclintox: 0.927858 val loss: 0.184264
[Epoch 75] ogbg-molclintox: 0.903579 test loss: 0.137438
[Epoch 76; Iter    30/   30] train: loss: 0.0153139
[Epoch 76] ogbg-molclintox: 0.911488 val loss: 0.161536
[Epoch 76] ogbg-molclintox: 0.901167 test loss: 0.146575
[Epoch 77; Iter    30/   30] train: loss: 0.0737920
[Epoch 77] ogbg-molclintox: 0.918474 val loss: 0.178452
[Epoch 77] ogbg-molclintox: 0.939916 test loss: 0.117283
[Epoch 78; Iter    30/   30] train: loss: 0.0211315
[Epoch 78] ogbg-molclintox: 0.927945 val loss: 0.180125
[Epoch 78] ogbg-molclintox: 0.881801 test loss: 0.153546
[Epoch 79; Iter    30/   30] train: loss: 0.0200885
[Epoch 79] ogbg-molclintox: 0.886072 val loss: 0.171225
[Epoch 79] ogbg-molclintox: 0.893348 test loss: 0.135019
[Epoch 80; Iter    30/   30] train: loss: 0.2207704
[Epoch 80] ogbg-molclintox: 0.884542 val loss: 0.207969
[Epoch 80] ogbg-molclintox: 0.935036 test loss: 0.142025
[Epoch 81; Iter    30/   30] train: loss: 0.0416669
[Epoch 81] ogbg-molclintox: 0.908193 val loss: 0.212994
[Epoch 81] ogbg-molclintox: 0.914307 test loss: 0.144270
[Epoch 82; Iter    30/   30] train: loss: 0.0733025
[Epoch 82] ogbg-molclintox: 0.922211 val loss: 0.161872
[Epoch 82] ogbg-molclintox: 0.928510 test loss: 0.133788
[Epoch 83; Iter    30/   30] train: loss: 0.2224132
[Epoch 83] ogbg-molclintox: 0.869513 val loss: 0.191831
[Epoch 83] ogbg-molclintox: 0.885188 test loss: 0.152436
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 80; Iter    25/   35] train: loss: 0.0515058
[Epoch 80] ogbg-molclintox: 0.946024 val loss: 0.162010
[Epoch 80] ogbg-molclintox: 0.893854 test loss: 0.183382
[Epoch 81; Iter    20/   35] train: loss: 0.3686268
[Epoch 81] ogbg-molclintox: 0.948327 val loss: 0.154131
[Epoch 81] ogbg-molclintox: 0.878876 test loss: 0.168549
[Epoch 82; Iter    15/   35] train: loss: 0.0431770
[Epoch 82] ogbg-molclintox: 0.971620 val loss: 0.120171
[Epoch 82] ogbg-molclintox: 0.902210 test loss: 0.172634
[Epoch 83; Iter    10/   35] train: loss: 0.0940439
[Epoch 83] ogbg-molclintox: 0.959161 val loss: 0.151937
[Epoch 83] ogbg-molclintox: 0.888763 test loss: 0.222789
[Epoch 84; Iter     5/   35] train: loss: 0.1226306
[Epoch 84; Iter    35/   35] train: loss: 0.0421387
[Epoch 84] ogbg-molclintox: 0.945750 val loss: 0.161419
[Epoch 84] ogbg-molclintox: 0.883939 test loss: 0.188434
[Epoch 85; Iter    30/   35] train: loss: 0.0754770
[Epoch 85] ogbg-molclintox: 0.957997 val loss: 0.127295
[Epoch 85] ogbg-molclintox: 0.854942 test loss: 0.161262
[Epoch 86; Iter    25/   35] train: loss: 0.0853668
[Epoch 86] ogbg-molclintox: 0.966320 val loss: 0.169851
[Epoch 86] ogbg-molclintox: 0.898202 test loss: 0.217649
[Epoch 87; Iter    20/   35] train: loss: 0.0664979
[Epoch 87] ogbg-molclintox: 0.966504 val loss: 0.140128
[Epoch 87] ogbg-molclintox: 0.884460 test loss: 0.195201
[Epoch 88; Iter    15/   35] train: loss: 0.0242622
[Epoch 88] ogbg-molclintox: 0.974034 val loss: 0.125813
[Epoch 88] ogbg-molclintox: 0.887589 test loss: 0.180870
[Epoch 89; Iter    10/   35] train: loss: 0.1390768
[Epoch 89] ogbg-molclintox: 0.956451 val loss: 0.155588
[Epoch 89] ogbg-molclintox: 0.879857 test loss: 0.215545
[Epoch 90; Iter     5/   35] train: loss: 0.1298624
[Epoch 90; Iter    35/   35] train: loss: 0.0346741
[Epoch 90] ogbg-molclintox: 0.940825 val loss: 0.157458
[Epoch 90] ogbg-molclintox: 0.840310 test loss: 0.143588
[Epoch 91; Iter    30/   35] train: loss: 0.1716791
[Epoch 91] ogbg-molclintox: 0.964412 val loss: 0.129707
[Epoch 91] ogbg-molclintox: 0.877895 test loss: 0.170483
[Epoch 92; Iter    25/   35] train: loss: 0.0370807
[Epoch 92] ogbg-molclintox: 0.948698 val loss: 0.135716
[Epoch 92] ogbg-molclintox: 0.816376 test loss: 0.190022
[Epoch 93; Iter    20/   35] train: loss: 0.0827294
[Epoch 93] ogbg-molclintox: 0.977079 val loss: 0.110193
[Epoch 93] ogbg-molclintox: 0.857045 test loss: 0.157750
[Epoch 94; Iter    15/   35] train: loss: 0.1490443
[Epoch 94] ogbg-molclintox: 0.963099 val loss: 0.204003
[Epoch 94] ogbg-molclintox: 0.890770 test loss: 0.248097
[Epoch 95; Iter    10/   35] train: loss: 0.1383361
[Epoch 95] ogbg-molclintox: 0.959014 val loss: 0.116510
[Epoch 95] ogbg-molclintox: 0.855424 test loss: 0.163497
[Epoch 96; Iter     5/   35] train: loss: 0.0570312
[Epoch 96; Iter    35/   35] train: loss: 0.1426374
[Epoch 96] ogbg-molclintox: 0.965130 val loss: 0.127471
[Epoch 96] ogbg-molclintox: 0.887493 test loss: 0.171291
[Epoch 97; Iter    30/   35] train: loss: 0.0798544
[Epoch 97] ogbg-molclintox: 0.973141 val loss: 0.105984
[Epoch 97] ogbg-molclintox: 0.844250 test loss: 0.171549
[Epoch 98; Iter    25/   35] train: loss: 0.1989656
[Epoch 98] ogbg-molclintox: 0.970617 val loss: 0.121530
[Epoch 98] ogbg-molclintox: 0.851915 test loss: 0.191796
[Epoch 99; Iter    20/   35] train: loss: 0.0865620
[Epoch 99] ogbg-molclintox: 0.967310 val loss: 0.138690
[Epoch 99] ogbg-molclintox: 0.881269 test loss: 0.149745
[Epoch 100; Iter    15/   35] train: loss: 0.0344392
[Epoch 100] ogbg-molclintox: 0.961118 val loss: 0.130807
[Epoch 100] ogbg-molclintox: 0.847617 test loss: 0.238222
[Epoch 101; Iter    10/   35] train: loss: 0.0207865
[Epoch 101] ogbg-molclintox: 0.972598 val loss: 0.110238
[Epoch 101] ogbg-molclintox: 0.859176 test loss: 0.169852
[Epoch 102; Iter     5/   35] train: loss: 0.0357753
[Epoch 102; Iter    35/   35] train: loss: 0.0830282
[Epoch 102] ogbg-molclintox: 0.969129 val loss: 0.108065
[Epoch 102] ogbg-molclintox: 0.849919 test loss: 0.161726
[Epoch 103; Iter    30/   35] train: loss: 0.1068469
[Epoch 103] ogbg-molclintox: 0.960783 val loss: 0.129553
[Epoch 103] ogbg-molclintox: 0.863570 test loss: 0.184737
[Epoch 104; Iter    25/   35] train: loss: 0.0295953
[Epoch 104] ogbg-molclintox: 0.965242 val loss: 0.116301
[Epoch 104] ogbg-molclintox: 0.865072 test loss: 0.151892
[Epoch 105; Iter    20/   35] train: loss: 0.0775934
[Epoch 105] ogbg-molclintox: 0.955348 val loss: 0.200301
[Epoch 105] ogbg-molclintox: 0.822997 test loss: 0.287035
[Epoch 106; Iter    15/   35] train: loss: 0.1674516
[Epoch 106] ogbg-molclintox: 0.965143 val loss: 0.106926
[Epoch 106] ogbg-molclintox: 0.847056 test loss: 0.149531
[Epoch 107; Iter    10/   35] train: loss: 0.0607198
[Epoch 107] ogbg-molclintox: 0.967198 val loss: 0.115627
[Epoch 107] ogbg-molclintox: 0.853899 test loss: 0.138606
[Epoch 108; Iter     5/   35] train: loss: 0.0324966
[Epoch 108; Iter    35/   35] train: loss: 0.1131424
[Epoch 108] ogbg-molclintox: 0.963360 val loss: 0.114227
[Epoch 108] ogbg-molclintox: 0.836104 test loss: 0.154633
[Epoch 109; Iter    30/   35] train: loss: 0.1227883
[Epoch 109] ogbg-molclintox: 0.968585 val loss: 0.112667
[Epoch 109] ogbg-molclintox: 0.855616 test loss: 0.148630
[Epoch 110; Iter    25/   35] train: loss: 0.0287891
[Epoch 110] ogbg-molclintox: 0.983556 val loss: 0.090719
[Epoch 110] ogbg-molclintox: 0.864040 test loss: 0.177905
[Epoch 111; Iter    20/   35] train: loss: 0.0873336
[Epoch 111] ogbg-molclintox: 0.981934 val loss: 0.089457
[Epoch 111] ogbg-molclintox: 0.854624 test loss: 0.154714
[Epoch 112; Iter    15/   35] train: loss: 0.0496634
[Epoch 112] ogbg-molclintox: 0.968822 val loss: 0.106621
[Epoch 112] ogbg-molclintox: 0.827419 test loss: 0.154988
[Epoch 113; Iter    10/   35] train: loss: 0.0495118
[Epoch 113] ogbg-molclintox: 0.980423 val loss: 0.091903
[Epoch 113] ogbg-molclintox: 0.871172 test loss: 0.149261
[Epoch 114; Iter     5/   35] train: loss: 0.0139585
[Epoch 114; Iter    35/   35] train: loss: 0.0638430
[Epoch 114] ogbg-molclintox: 0.963645 val loss: 0.105882
[Epoch 114] ogbg-molclintox: 0.826710 test loss: 0.164217
[Epoch 115; Iter    30/   35] train: loss: 0.0358880
[Epoch 115] ogbg-molclintox: 0.973650 val loss: 0.097410
[Epoch 115] ogbg-molclintox: 0.850078 test loss: 0.164493
[Epoch 116; Iter    25/   35] train: loss: 0.0855391
[Epoch 116] ogbg-molclintox: 0.979606 val loss: 0.088083
[Epoch 116] ogbg-molclintox: 0.843711 test loss: 0.163742
[Epoch 117; Iter    20/   35] train: loss: 0.0202037
[Epoch 117] ogbg-molclintox: 0.976176 val loss: 0.111692
[Epoch 117] ogbg-molclintox: 0.844023 test loss: 0.191051
[Epoch 118; Iter    15/   35] train: loss: 0.1116641
[Epoch 118] ogbg-molclintox: 0.972027 val loss: 0.122763
[Epoch 118] ogbg-molclintox: 0.848734 test loss: 0.205236
[Epoch 119; Iter    10/   35] train: loss: 0.1540949
[Epoch 119] ogbg-molclintox: 0.971607 val loss: 0.111197
[Epoch 119] ogbg-molclintox: 0.847056 test loss: 0.164093
[Epoch 120; Iter     5/   35] train: loss: 0.0247393
[Epoch 120; Iter    35/   35] train: loss: 0.0188511
[Epoch 120] ogbg-molclintox: 0.974715 val loss: 0.112495
[Epoch 120] ogbg-molclintox: 0.850066 test loss: 0.176759
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 120 epochs. Best model checkpoint was in epoch 51.
Statistics on  val_best_checkpoint
mean_pred: 0.11980452388525009
std_pred: 3.754446268081665
mean_targets: 0.5067567825317383
std_targets: 0.500518262386322
prcauc: 0.9336910479143274
rocauc: 0.9848062896656247
ogbg-molclintox: 0.9848062896656247
OGBNanLabelBCEWithLogitsLoss: 0.16119674686342478
Statistics on  test
mean_pred: 0.10764699429273605
std_pred: 12.466204643249512
mean_targets: 0.5022522807121277
std_targets: 0.5005589127540588
prcauc: 0.6809922883720492
rocauc: 0.85658010367726
ogbg-molclintox: 0.85658010367726
OGBNanLabelBCEWithLogitsLoss: 0.9419365674257278
Statistics on  train
mean_pred: 0.16122868657112122
std_pred: 4.820430278778076
mean_targets: 0.5067763924598694
std_targets: 0.500075101852417
prcauc: 0.81568530804895
rocauc: 0.9538100924571165
ogbg-molclintox: 0.9538100924571165
OGBNanLabelBCEWithLogitsLoss: 0.21138515951378004
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 80; Iter    25/   35] train: loss: 0.0981684
[Epoch 80] ogbg-molclintox: 0.939422 val loss: 0.143256
[Epoch 80] ogbg-molclintox: 0.866410 test loss: 0.128179
[Epoch 81; Iter    20/   35] train: loss: 0.1070751
[Epoch 81] ogbg-molclintox: 0.944560 val loss: 0.143750
[Epoch 81] ogbg-molclintox: 0.901002 test loss: 0.116371
[Epoch 82; Iter    15/   35] train: loss: 0.0716290
[Epoch 82] ogbg-molclintox: 0.941602 val loss: 0.137445
[Epoch 82] ogbg-molclintox: 0.884313 test loss: 0.121820
[Epoch 83; Iter    10/   35] train: loss: 0.0157003
[Epoch 83] ogbg-molclintox: 0.945427 val loss: 0.156516
[Epoch 83] ogbg-molclintox: 0.904370 test loss: 0.115241
[Epoch 84; Iter     5/   35] train: loss: 0.0621279
[Epoch 84; Iter    35/   35] train: loss: 0.0299487
[Epoch 84] ogbg-molclintox: 0.949254 val loss: 0.140683
[Epoch 84] ogbg-molclintox: 0.881580 test loss: 0.123703
[Epoch 85; Iter    30/   35] train: loss: 0.0883762
[Epoch 85] ogbg-molclintox: 0.962045 val loss: 0.124907
[Epoch 85] ogbg-molclintox: 0.864210 test loss: 0.135851
[Epoch 86; Iter    25/   35] train: loss: 0.1551048
[Epoch 86] ogbg-molclintox: 0.935980 val loss: 0.144298
[Epoch 86] ogbg-molclintox: 0.858354 test loss: 0.134324
[Epoch 87; Iter    20/   35] train: loss: 0.0712664
[Epoch 87] ogbg-molclintox: 0.937910 val loss: 0.164021
[Epoch 87] ogbg-molclintox: 0.894285 test loss: 0.127130
[Epoch 88; Iter    15/   35] train: loss: 0.0097075
[Epoch 88] ogbg-molclintox: 0.949612 val loss: 0.137750
[Epoch 88] ogbg-molclintox: 0.876682 test loss: 0.133331
[Epoch 89; Iter    10/   35] train: loss: 0.0102662
[Epoch 89] ogbg-molclintox: 0.953105 val loss: 0.151347
[Epoch 89] ogbg-molclintox: 0.874239 test loss: 0.137603
[Epoch 90; Iter     5/   35] train: loss: 0.1101508
[Epoch 90; Iter    35/   35] train: loss: 0.0024871
[Epoch 90] ogbg-molclintox: 0.960028 val loss: 0.132762
[Epoch 90] ogbg-molclintox: 0.902255 test loss: 0.130178
[Epoch 91; Iter    30/   35] train: loss: 0.0159904
[Epoch 91] ogbg-molclintox: 0.945057 val loss: 0.147296
[Epoch 91] ogbg-molclintox: 0.882006 test loss: 0.129179
[Epoch 92; Iter    25/   35] train: loss: 0.1256356
[Epoch 92] ogbg-molclintox: 0.940796 val loss: 0.141611
[Epoch 92] ogbg-molclintox: 0.883287 test loss: 0.124057
[Epoch 93; Iter    20/   35] train: loss: 0.0436425
[Epoch 93] ogbg-molclintox: 0.948957 val loss: 0.133707
[Epoch 93] ogbg-molclintox: 0.869488 test loss: 0.141333
[Epoch 94; Iter    15/   35] train: loss: 0.1058108
[Epoch 94] ogbg-molclintox: 0.959085 val loss: 0.136532
[Epoch 94] ogbg-molclintox: 0.844607 test loss: 0.149692
[Epoch 95; Iter    10/   35] train: loss: 0.0742562
[Epoch 95] ogbg-molclintox: 0.958615 val loss: 0.139088
[Epoch 95] ogbg-molclintox: 0.890356 test loss: 0.130483
[Epoch 96; Iter     5/   35] train: loss: 0.0474863
[Epoch 96; Iter    35/   35] train: loss: 0.4388141
[Epoch 96] ogbg-molclintox: 0.945799 val loss: 0.137707
[Epoch 96] ogbg-molclintox: 0.874369 test loss: 0.130545
[Epoch 97; Iter    30/   35] train: loss: 0.1236603
[Epoch 97] ogbg-molclintox: 0.947284 val loss: 0.184269
[Epoch 97] ogbg-molclintox: 0.886115 test loss: 0.141521
[Epoch 98; Iter    25/   35] train: loss: 0.0882718
[Epoch 98] ogbg-molclintox: 0.927831 val loss: 0.155084
[Epoch 98] ogbg-molclintox: 0.853592 test loss: 0.139126
[Epoch 99; Iter    20/   35] train: loss: 0.0899405
[Epoch 99] ogbg-molclintox: 0.957278 val loss: 0.140581
[Epoch 99] ogbg-molclintox: 0.868661 test loss: 0.152776
[Epoch 100; Iter    15/   35] train: loss: 0.0309285
[Epoch 100] ogbg-molclintox: 0.944103 val loss: 0.145676
[Epoch 100] ogbg-molclintox: 0.866025 test loss: 0.138601
[Epoch 101; Iter    10/   35] train: loss: 0.0439027
[Epoch 101] ogbg-molclintox: 0.958380 val loss: 0.140042
[Epoch 101] ogbg-molclintox: 0.891184 test loss: 0.131380
[Epoch 102; Iter     5/   35] train: loss: 0.0458436
[Epoch 102; Iter    35/   35] train: loss: 0.0936373
[Epoch 102] ogbg-molclintox: 0.953576 val loss: 0.153709
[Epoch 102] ogbg-molclintox: 0.896161 test loss: 0.127931
[Epoch 103; Iter    30/   35] train: loss: 0.0761319
[Epoch 103] ogbg-molclintox: 0.955445 val loss: 0.150231
[Epoch 103] ogbg-molclintox: 0.890112 test loss: 0.124924
[Epoch 104; Iter    25/   35] train: loss: 0.0374553
[Epoch 104] ogbg-molclintox: 0.952659 val loss: 0.158694
[Epoch 104] ogbg-molclintox: 0.898088 test loss: 0.120567
[Epoch 105; Iter    20/   35] train: loss: 0.1001102
[Epoch 105] ogbg-molclintox: 0.943273 val loss: 0.154268
[Epoch 105] ogbg-molclintox: 0.895759 test loss: 0.124065
[Epoch 106; Iter    15/   35] train: loss: 0.0042514
[Epoch 106] ogbg-molclintox: 0.946096 val loss: 0.150233
[Epoch 106] ogbg-molclintox: 0.889778 test loss: 0.128534
[Epoch 107; Iter    10/   35] train: loss: 0.0826464
[Epoch 107] ogbg-molclintox: 0.935756 val loss: 0.156695
[Epoch 107] ogbg-molclintox: 0.872096 test loss: 0.134227
[Epoch 108; Iter     5/   35] train: loss: 0.0318664
[Epoch 108; Iter    35/   35] train: loss: 0.0087624
[Epoch 108] ogbg-molclintox: 0.947099 val loss: 0.152217
[Epoch 108] ogbg-molclintox: 0.887567 test loss: 0.126925
[Epoch 109; Iter    30/   35] train: loss: 0.0353713
[Epoch 109] ogbg-molclintox: 0.941427 val loss: 0.155493
[Epoch 109] ogbg-molclintox: 0.885866 test loss: 0.126044
[Epoch 110; Iter    25/   35] train: loss: 0.0070363
[Epoch 110] ogbg-molclintox: 0.951990 val loss: 0.151049
[Epoch 110] ogbg-molclintox: 0.880594 test loss: 0.129831
[Epoch 111; Iter    20/   35] train: loss: 0.0518865
[Epoch 111] ogbg-molclintox: 0.937552 val loss: 0.163961
[Epoch 111] ogbg-molclintox: 0.883967 test loss: 0.134497
[Epoch 112; Iter    15/   35] train: loss: 0.0487331
[Epoch 112] ogbg-molclintox: 0.945477 val loss: 0.144637
[Epoch 112] ogbg-molclintox: 0.894234 test loss: 0.136545
[Epoch 113; Iter    10/   35] train: loss: 0.0607187
[Epoch 113] ogbg-molclintox: 0.942827 val loss: 0.153041
[Epoch 113] ogbg-molclintox: 0.901558 test loss: 0.123812
[Epoch 114; Iter     5/   35] train: loss: 0.0393614
[Epoch 114; Iter    35/   35] train: loss: 0.0256712
[Epoch 114] ogbg-molclintox: 0.947966 val loss: 0.143128
[Epoch 114] ogbg-molclintox: 0.894772 test loss: 0.124039
[Epoch 115; Iter    30/   35] train: loss: 0.0595378
[Epoch 115] ogbg-molclintox: 0.944053 val loss: 0.155253
[Epoch 115] ogbg-molclintox: 0.889007 test loss: 0.127208
[Epoch 116; Iter    25/   35] train: loss: 0.0790850
[Epoch 116] ogbg-molclintox: 0.946393 val loss: 0.157272
[Epoch 116] ogbg-molclintox: 0.887159 test loss: 0.125681
[Epoch 117; Iter    20/   35] train: loss: 0.1118535
[Epoch 117] ogbg-molclintox: 0.948560 val loss: 0.146435
[Epoch 117] ogbg-molclintox: 0.872108 test loss: 0.138896
[Epoch 118; Iter    15/   35] train: loss: 0.0734521
[Epoch 118] ogbg-molclintox: 0.941452 val loss: 0.169234
[Epoch 118] ogbg-molclintox: 0.880554 test loss: 0.131682
[Epoch 119; Iter    10/   35] train: loss: 0.1062234
[Epoch 119] ogbg-molclintox: 0.945316 val loss: 0.154153
[Epoch 119] ogbg-molclintox: 0.907000 test loss: 0.128668
[Epoch 120; Iter     5/   35] train: loss: 0.0991234
[Epoch 120; Iter    35/   35] train: loss: 0.1373954
[Epoch 120] ogbg-molclintox: 0.950219 val loss: 0.147935
[Epoch 120] ogbg-molclintox: 0.893576 test loss: 0.131114
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 120 epochs. Best model checkpoint was in epoch 52.
Statistics on  val_best_checkpoint
mean_pred: 0.1671048104763031
std_pred: 5.6067728996276855
mean_targets: 0.5067567825317383
std_targets: 0.500518262386322
prcauc: 0.9401618914148148
rocauc: 0.9860696694136593
ogbg-molclintox: 0.9860696694136593
OGBNanLabelBCEWithLogitsLoss: 0.09879720171738882
Statistics on  test
mean_pred: 0.1756681501865387
std_pred: 5.407958030700684
mean_targets: 0.5022522807121277
std_targets: 0.5005589127540588
prcauc: 0.8019943052263437
rocauc: 0.8687797918248155
ogbg-molclintox: 0.8687797918248155
OGBNanLabelBCEWithLogitsLoss: 0.11230230471119285
Statistics on  train
mean_pred: 0.18717001378536224
std_pred: 5.6393046379089355
mean_targets: 0.5067763924598694
std_targets: 0.500075101852417
prcauc: 0.8975317813748557
rocauc: 0.9685490013086977
ogbg-molclintox: 0.9685490013086977
OGBNanLabelBCEWithLogitsLoss: 0.1110144447003092
[Epoch 76] ogbg-molclintox: 0.976013 val loss: 0.110689
[Epoch 76] ogbg-molclintox: 0.872496 test loss: 0.216498
[Epoch 77; Iter    20/   40] train: loss: 0.0132796
[Epoch 77] ogbg-molclintox: 0.951752 val loss: 0.085367
[Epoch 77] ogbg-molclintox: 0.873968 test loss: 0.167995
[Epoch 78; Iter    10/   40] train: loss: 0.0151824
[Epoch 78; Iter    40/   40] train: loss: 0.0058550
[Epoch 78] ogbg-molclintox: 0.975514 val loss: 0.079177
[Epoch 78] ogbg-molclintox: 0.853207 test loss: 0.174178
[Epoch 79; Iter    30/   40] train: loss: 0.1454252
[Epoch 79] ogbg-molclintox: 0.984566 val loss: 0.056063
[Epoch 79] ogbg-molclintox: 0.873546 test loss: 0.171889
[Epoch 80; Iter    20/   40] train: loss: 0.0772777
[Epoch 80] ogbg-molclintox: 0.977187 val loss: 0.083305
[Epoch 80] ogbg-molclintox: 0.862254 test loss: 0.196607
[Epoch 81; Iter    10/   40] train: loss: 0.0407098
[Epoch 81; Iter    40/   40] train: loss: 0.0145639
[Epoch 81] ogbg-molclintox: 0.911167 val loss: 0.078710
[Epoch 81] ogbg-molclintox: 0.858929 test loss: 0.178158
[Epoch 82; Iter    30/   40] train: loss: 0.0250318
[Epoch 82] ogbg-molclintox: 0.982219 val loss: 0.065017
[Epoch 82] ogbg-molclintox: 0.876030 test loss: 0.179610
[Epoch 83; Iter    20/   40] train: loss: 0.0229089
[Epoch 83] ogbg-molclintox: 0.964300 val loss: 0.080887
[Epoch 83] ogbg-molclintox: 0.855045 test loss: 0.181504
[Epoch 84; Iter    10/   40] train: loss: 0.0142985
[Epoch 84; Iter    40/   40] train: loss: 0.0087905
[Epoch 84] ogbg-molclintox: 0.933408 val loss: 0.097493
[Epoch 84] ogbg-molclintox: 0.866762 test loss: 0.186290
[Epoch 85; Iter    30/   40] train: loss: 0.0309263
[Epoch 85] ogbg-molclintox: 0.969245 val loss: 0.081905
[Epoch 85] ogbg-molclintox: 0.872358 test loss: 0.176514
[Epoch 86; Iter    20/   40] train: loss: 0.0398489
[Epoch 86] ogbg-molclintox: 0.968321 val loss: 0.081655
[Epoch 86] ogbg-molclintox: 0.878390 test loss: 0.183492
[Epoch 87; Iter    10/   40] train: loss: 0.1114142
[Epoch 87; Iter    40/   40] train: loss: 0.0210319
[Epoch 87] ogbg-molclintox: 0.971705 val loss: 0.077683
[Epoch 87] ogbg-molclintox: 0.902139 test loss: 0.158901
[Epoch 88; Iter    30/   40] train: loss: 0.0481329
[Epoch 88] ogbg-molclintox: 0.921931 val loss: 0.090420
[Epoch 88] ogbg-molclintox: 0.892607 test loss: 0.166977
[Epoch 89; Iter    20/   40] train: loss: 0.0552872
[Epoch 89] ogbg-molclintox: 0.860083 val loss: 0.102617
[Epoch 89] ogbg-molclintox: 0.873968 test loss: 0.172740
[Epoch 90; Iter    10/   40] train: loss: 0.0159495
[Epoch 90; Iter    40/   40] train: loss: 0.0094786
[Epoch 90] ogbg-molclintox: 0.946818 val loss: 0.086483
[Epoch 90] ogbg-molclintox: 0.864226 test loss: 0.182538
[Epoch 91; Iter    30/   40] train: loss: 0.0303319
[Epoch 91] ogbg-molclintox: 0.882559 val loss: 0.099368
[Epoch 91] ogbg-molclintox: 0.873669 test loss: 0.183228
[Epoch 92; Iter    20/   40] train: loss: 0.0320422
[Epoch 92] ogbg-molclintox: 0.971929 val loss: 0.086829
[Epoch 92] ogbg-molclintox: 0.869086 test loss: 0.185045
[Epoch 93; Iter    10/   40] train: loss: 0.0305402
[Epoch 93; Iter    40/   40] train: loss: 0.2085828
[Epoch 93] ogbg-molclintox: 0.945194 val loss: 0.088786
[Epoch 93] ogbg-molclintox: 0.887997 test loss: 0.162020
[Epoch 94; Iter    30/   40] train: loss: 0.0291844
[Epoch 94] ogbg-molclintox: 0.973103 val loss: 0.079847
[Epoch 94] ogbg-molclintox: 0.870109 test loss: 0.172368
[Epoch 95; Iter    20/   40] train: loss: 0.0072827
[Epoch 95] ogbg-molclintox: 0.925653 val loss: 0.096549
[Epoch 95] ogbg-molclintox: 0.851608 test loss: 0.187999
[Epoch 96; Iter    10/   40] train: loss: 0.0464585
[Epoch 96; Iter    40/   40] train: loss: 0.0526600
[Epoch 96] ogbg-molclintox: 0.930035 val loss: 0.100529
[Epoch 96] ogbg-molclintox: 0.872108 test loss: 0.178590
[Epoch 97; Iter    30/   40] train: loss: 0.0427565
[Epoch 97] ogbg-molclintox: 0.874568 val loss: 0.114299
[Epoch 97] ogbg-molclintox: 0.881588 test loss: 0.183393
[Epoch 98; Iter    20/   40] train: loss: 0.0873072
[Epoch 98] ogbg-molclintox: 0.900878 val loss: 0.118125
[Epoch 98] ogbg-molclintox: 0.859766 test loss: 0.190799
[Epoch 99; Iter    10/   40] train: loss: 0.0178421
[Epoch 99; Iter    40/   40] train: loss: 0.0383534
[Epoch 99] ogbg-molclintox: 0.879713 val loss: 0.108403
[Epoch 99] ogbg-molclintox: 0.876941 test loss: 0.178730
[Epoch 100; Iter    30/   40] train: loss: 0.0259426
[Epoch 100] ogbg-molclintox: 0.832389 val loss: 0.136339
[Epoch 100] ogbg-molclintox: 0.892043 test loss: 0.187384
[Epoch 101; Iter    20/   40] train: loss: 0.0263362
[Epoch 101] ogbg-molclintox: 0.939189 val loss: 0.094436
[Epoch 101] ogbg-molclintox: 0.877292 test loss: 0.180930
[Epoch 102; Iter    10/   40] train: loss: 0.0766971
[Epoch 102; Iter    40/   40] train: loss: 0.0072819
[Epoch 102] ogbg-molclintox: 0.857124 val loss: 0.125422
[Epoch 102] ogbg-molclintox: 0.877277 test loss: 0.188383
[Epoch 103; Iter    30/   40] train: loss: 0.0995157
[Epoch 103] ogbg-molclintox: 0.907822 val loss: 0.096773
[Epoch 103] ogbg-molclintox: 0.885185 test loss: 0.207477
[Epoch 104; Iter    20/   40] train: loss: 0.0290233
[Epoch 104] ogbg-molclintox: 0.821674 val loss: 0.148148
[Epoch 104] ogbg-molclintox: 0.888845 test loss: 0.189449
[Epoch 105; Iter    10/   40] train: loss: 0.0066780
[Epoch 105; Iter    40/   40] train: loss: 0.1790119
[Epoch 105] ogbg-molclintox: 0.907808 val loss: 0.108274
[Epoch 105] ogbg-molclintox: 0.845699 test loss: 0.198131
[Epoch 106; Iter    30/   40] train: loss: 0.1557377
[Epoch 106] ogbg-molclintox: 0.926865 val loss: 0.118383
[Epoch 106] ogbg-molclintox: 0.833907 test loss: 0.224235
[Epoch 107; Iter    20/   40] train: loss: 0.0394222
[Epoch 107] ogbg-molclintox: 0.945981 val loss: 0.102232
[Epoch 107] ogbg-molclintox: 0.871095 test loss: 0.189393
[Epoch 108; Iter    10/   40] train: loss: 0.0074851
[Epoch 108; Iter    40/   40] train: loss: 0.0157618
[Epoch 108] ogbg-molclintox: 0.803067 val loss: 0.149773
[Epoch 108] ogbg-molclintox: 0.772633 test loss: 0.243673
[Epoch 109; Iter    30/   40] train: loss: 0.0833574
[Epoch 109] ogbg-molclintox: 0.860832 val loss: 0.113132
[Epoch 109] ogbg-molclintox: 0.799404 test loss: 0.227117
[Epoch 110; Iter    20/   40] train: loss: 0.0469967
[Epoch 110] ogbg-molclintox: 0.879400 val loss: 0.124544
[Epoch 110] ogbg-molclintox: 0.796969 test loss: 0.238673
[Epoch 111; Iter    10/   40] train: loss: 0.0134680
[Epoch 111; Iter    40/   40] train: loss: 0.0229471
[Epoch 111] ogbg-molclintox: 0.873894 val loss: 0.116539
[Epoch 111] ogbg-molclintox: 0.857103 test loss: 0.217781
[Epoch 112; Iter    30/   40] train: loss: 0.0527645
[Epoch 112] ogbg-molclintox: 0.832800 val loss: 0.121162
[Epoch 112] ogbg-molclintox: 0.841176 test loss: 0.236450
[Epoch 113; Iter    20/   40] train: loss: 0.2810831
[Epoch 113] ogbg-molclintox: 0.871522 val loss: 0.113922
[Epoch 113] ogbg-molclintox: 0.828509 test loss: 0.223917
[Epoch 114; Iter    10/   40] train: loss: 0.0070589
[Epoch 114; Iter    40/   40] train: loss: 0.0024256
[Epoch 114] ogbg-molclintox: 0.866602 val loss: 0.108785
[Epoch 114] ogbg-molclintox: 0.848385 test loss: 0.218760
[Epoch 115; Iter    30/   40] train: loss: 0.0105079
[Epoch 115] ogbg-molclintox: 0.834536 val loss: 0.131050
[Epoch 115] ogbg-molclintox: 0.831109 test loss: 0.228866
[Epoch 116; Iter    20/   40] train: loss: 0.0538083
[Epoch 116] ogbg-molclintox: 0.821650 val loss: 0.129096
[Epoch 116] ogbg-molclintox: 0.841288 test loss: 0.221378
[Epoch 117; Iter    10/   40] train: loss: 0.0796648
[Epoch 117; Iter    40/   40] train: loss: 0.0037889
[Epoch 117] ogbg-molclintox: 0.841241 val loss: 0.127612
[Epoch 117] ogbg-molclintox: 0.857140 test loss: 0.209492
[Epoch 118; Iter    30/   40] train: loss: 0.0559258
[Epoch 118] ogbg-molclintox: 0.852068 val loss: 0.124437
[Epoch 118] ogbg-molclintox: 0.850182 test loss: 0.212374
[Epoch 119; Iter    20/   40] train: loss: 0.0257784
[Epoch 119] ogbg-molclintox: 0.822236 val loss: 0.129045
[Epoch 119] ogbg-molclintox: 0.867147 test loss: 0.206741
[Epoch 120; Iter    10/   40] train: loss: 0.0683343
[Epoch 120; Iter    40/   40] train: loss: 0.0027589
[Epoch 120] ogbg-molclintox: 0.822437 val loss: 0.126448
[Epoch 80; Iter    25/   35] train: loss: 0.0208468
[Epoch 80] ogbg-molclintox: 0.972075 val loss: 0.109153
[Epoch 80] ogbg-molclintox: 0.848008 test loss: 0.144614
[Epoch 81; Iter    20/   35] train: loss: 0.0215108
[Epoch 81] ogbg-molclintox: 0.976323 val loss: 0.120796
[Epoch 81] ogbg-molclintox: 0.896682 test loss: 0.131615
[Epoch 82; Iter    15/   35] train: loss: 0.0847034
[Epoch 82] ogbg-molclintox: 0.973153 val loss: 0.125653
[Epoch 82] ogbg-molclintox: 0.895316 test loss: 0.127566
[Epoch 83; Iter    10/   35] train: loss: 0.1016738
[Epoch 83] ogbg-molclintox: 0.970070 val loss: 0.135277
[Epoch 83] ogbg-molclintox: 0.907482 test loss: 0.123261
[Epoch 84; Iter     5/   35] train: loss: 0.0803992
[Epoch 84; Iter    35/   35] train: loss: 0.0087900
[Epoch 84] ogbg-molclintox: 0.975567 val loss: 0.109900
[Epoch 84] ogbg-molclintox: 0.911223 test loss: 0.124867
[Epoch 85; Iter    30/   35] train: loss: 0.1083637
[Epoch 85] ogbg-molclintox: 0.969153 val loss: 0.108555
[Epoch 85] ogbg-molclintox: 0.905305 test loss: 0.130498
[Epoch 86; Iter    25/   35] train: loss: 0.0233141
[Epoch 86] ogbg-molclintox: 0.975369 val loss: 0.139860
[Epoch 86] ogbg-molclintox: 0.906161 test loss: 0.191267
[Epoch 87; Iter    20/   35] train: loss: 0.0595900
[Epoch 87] ogbg-molclintox: 0.973995 val loss: 0.113170
[Epoch 87] ogbg-molclintox: 0.882465 test loss: 0.155003
[Epoch 88; Iter    15/   35] train: loss: 0.0556013
[Epoch 88] ogbg-molclintox: 0.974168 val loss: 0.127511
[Epoch 88] ogbg-molclintox: 0.910679 test loss: 0.131139
[Epoch 89; Iter    10/   35] train: loss: 0.0089263
[Epoch 89] ogbg-molclintox: 0.980583 val loss: 0.112565
[Epoch 89] ogbg-molclintox: 0.931768 test loss: 0.101045
[Epoch 90; Iter     5/   35] train: loss: 0.1014449
[Epoch 90; Iter    35/   35] train: loss: 0.0134814
[Epoch 90] ogbg-molclintox: 0.970206 val loss: 0.104850
[Epoch 90] ogbg-molclintox: 0.905299 test loss: 0.130016
[Epoch 91; Iter    30/   35] train: loss: 0.1238146
[Epoch 91] ogbg-molclintox: 0.980434 val loss: 0.087277
[Epoch 91] ogbg-molclintox: 0.896858 test loss: 0.147921
[Epoch 92; Iter    25/   35] train: loss: 0.0892609
[Epoch 92] ogbg-molclintox: 0.975790 val loss: 0.113211
[Epoch 92] ogbg-molclintox: 0.904812 test loss: 0.115901
[Epoch 93; Iter    20/   35] train: loss: 0.0250678
[Epoch 93] ogbg-molclintox: 0.974837 val loss: 0.101068
[Epoch 93] ogbg-molclintox: 0.896921 test loss: 0.125893
[Epoch 94; Iter    15/   35] train: loss: 0.1011008
[Epoch 94] ogbg-molclintox: 0.973772 val loss: 0.135245
[Epoch 94] ogbg-molclintox: 0.897357 test loss: 0.188647
[Epoch 95; Iter    10/   35] train: loss: 0.0185478
[Epoch 95] ogbg-molclintox: 0.978527 val loss: 0.116982
[Epoch 95] ogbg-molclintox: 0.914336 test loss: 0.136924
[Epoch 96; Iter     5/   35] train: loss: 0.0706733
[Epoch 96; Iter    35/   35] train: loss: 0.0026551
[Epoch 96] ogbg-molclintox: 0.973053 val loss: 0.112472
[Epoch 96] ogbg-molclintox: 0.897896 test loss: 0.124954
[Epoch 97; Iter    30/   35] train: loss: 0.0224723
[Epoch 97] ogbg-molclintox: 0.969549 val loss: 0.122771
[Epoch 97] ogbg-molclintox: 0.905237 test loss: 0.126265
[Epoch 98; Iter    25/   35] train: loss: 0.0272741
[Epoch 98] ogbg-molclintox: 0.970515 val loss: 0.117129
[Epoch 98] ogbg-molclintox: 0.918480 test loss: 0.114780
[Epoch 99; Iter    20/   35] train: loss: 0.1216189
[Epoch 99] ogbg-molclintox: 0.974725 val loss: 0.115139
[Epoch 99] ogbg-molclintox: 0.911025 test loss: 0.124960
[Epoch 100; Iter    15/   35] train: loss: 0.0351869
[Epoch 100] ogbg-molclintox: 0.970739 val loss: 0.128498
[Epoch 100] ogbg-molclintox: 0.907822 test loss: 0.132555
[Epoch 101; Iter    10/   35] train: loss: 0.0502189
[Epoch 101] ogbg-molclintox: 0.938670 val loss: 0.197281
[Epoch 101] ogbg-molclintox: 0.803280 test loss: 0.652804
[Epoch 102; Iter     5/   35] train: loss: 0.0889665
[Epoch 102; Iter    35/   35] train: loss: 0.1377945
[Epoch 102] ogbg-molclintox: 0.933340 val loss: 0.156156
[Epoch 102] ogbg-molclintox: 0.823139 test loss: 0.168730
[Epoch 103; Iter    30/   35] train: loss: 0.1061838
[Epoch 103] ogbg-molclintox: 0.966676 val loss: 0.120314
[Epoch 103] ogbg-molclintox: 0.850248 test loss: 0.155050
[Epoch 104; Iter    25/   35] train: loss: 0.1301533
[Epoch 104] ogbg-molclintox: 0.904836 val loss: 0.223192
[Epoch 104] ogbg-molclintox: 0.783240 test loss: 0.197791
[Epoch 105; Iter    20/   35] train: loss: 0.0888844
[Epoch 105] ogbg-molclintox: 0.952015 val loss: 0.190545
[Epoch 105] ogbg-molclintox: 0.815786 test loss: 0.170523
[Epoch 106; Iter    15/   35] train: loss: 0.0107700
[Epoch 106] ogbg-molclintox: 0.949935 val loss: 0.151134
[Epoch 106] ogbg-molclintox: 0.815667 test loss: 0.179640
[Epoch 107; Iter    10/   35] train: loss: 0.0092680
[Epoch 107] ogbg-molclintox: 0.964657 val loss: 0.113307
[Epoch 107] ogbg-molclintox: 0.837135 test loss: 0.170128
[Epoch 108; Iter     5/   35] train: loss: 0.1048574
[Epoch 108; Iter    35/   35] train: loss: 0.0154410
[Epoch 108] ogbg-molclintox: 0.955385 val loss: 0.133415
[Epoch 108] ogbg-molclintox: 0.853020 test loss: 0.159851
[Epoch 109; Iter    30/   35] train: loss: 0.0674040
[Epoch 109] ogbg-molclintox: 0.971618 val loss: 0.128834
[Epoch 109] ogbg-molclintox: 0.841047 test loss: 0.163532
[Epoch 110; Iter    25/   35] train: loss: 0.0284689
[Epoch 110] ogbg-molclintox: 0.939805 val loss: 0.140239
[Epoch 110] ogbg-molclintox: 0.799102 test loss: 0.183691
[Epoch 111; Iter    20/   35] train: loss: 0.2268380
[Epoch 111] ogbg-molclintox: 0.952485 val loss: 0.136559
[Epoch 111] ogbg-molclintox: 0.844528 test loss: 0.161569
[Epoch 112; Iter    15/   35] train: loss: 0.1572120
[Epoch 112] ogbg-molclintox: 0.958268 val loss: 0.129566
[Epoch 112] ogbg-molclintox: 0.846438 test loss: 0.153455
[Epoch 113; Iter    10/   35] train: loss: 0.0144921
[Epoch 113] ogbg-molclintox: 0.937512 val loss: 0.144546
[Epoch 113] ogbg-molclintox: 0.842640 test loss: 0.156037
[Epoch 114; Iter     5/   35] train: loss: 0.0274583
[Epoch 114; Iter    35/   35] train: loss: 0.4007909
[Epoch 114] ogbg-molclintox: 0.919237 val loss: 0.224515
[Epoch 114] ogbg-molclintox: 0.861444 test loss: 0.149548
[Epoch 115; Iter    30/   35] train: loss: 0.0259952
[Epoch 115] ogbg-molclintox: 0.956895 val loss: 0.166031
[Epoch 115] ogbg-molclintox: 0.876149 test loss: 0.143307
[Epoch 116; Iter    25/   35] train: loss: 0.0254911
[Epoch 116] ogbg-molclintox: 0.950629 val loss: 0.128358
[Epoch 116] ogbg-molclintox: 0.849136 test loss: 0.154885
[Epoch 117; Iter    20/   35] train: loss: 0.0937261
[Epoch 117] ogbg-molclintox: 0.963965 val loss: 0.147078
[Epoch 117] ogbg-molclintox: 0.863802 test loss: 0.148614
[Epoch 118; Iter    15/   35] train: loss: 0.0414004
[Epoch 118] ogbg-molclintox: 0.958479 val loss: 0.132336
[Epoch 118] ogbg-molclintox: 0.884834 test loss: 0.147671
[Epoch 119; Iter    10/   35] train: loss: 0.0318835
[Epoch 119] ogbg-molclintox: 0.965104 val loss: 0.145294
[Epoch 119] ogbg-molclintox: 0.889568 test loss: 0.136369
[Epoch 120; Iter     5/   35] train: loss: 0.0365929
[Epoch 120; Iter    35/   35] train: loss: 0.2282117
[Epoch 120] ogbg-molclintox: 0.962590 val loss: 0.136094
[Epoch 120] ogbg-molclintox: 0.840145 test loss: 0.160728
[Epoch 121; Iter    30/   35] train: loss: 0.0351998
[Epoch 121] ogbg-molclintox: 0.967370 val loss: 0.126582
[Epoch 121] ogbg-molclintox: 0.835593 test loss: 0.164916
[Epoch 122; Iter    25/   35] train: loss: 0.1260638
[Epoch 122] ogbg-molclintox: 0.961871 val loss: 0.129570
[Epoch 122] ogbg-molclintox: 0.875203 test loss: 0.157055
[Epoch 123; Iter    20/   35] train: loss: 0.0054732
[Epoch 123] ogbg-molclintox: 0.965650 val loss: 0.133997
[Epoch 123] ogbg-molclintox: 0.867453 test loss: 0.142897
[Epoch 124; Iter    15/   35] train: loss: 0.0087258
[Epoch 124] ogbg-molclintox: 0.964634 val loss: 0.126675
[Epoch 124] ogbg-molclintox: 0.835157 test loss: 0.164941
[Epoch 125; Iter    10/   35] train: loss: 0.0137301
[Epoch 125] ogbg-molclintox: 0.972744 val loss: 0.155046
[Epoch 125] ogbg-molclintox: 0.865066 test loss: 0.138483
[Epoch 126; Iter     5/   35] train: loss: 0.0316485
[Epoch 126; Iter    35/   35] train: loss: 0.0129095
[Epoch 76] ogbg-molclintox: 0.978747 val loss: 0.063100
[Epoch 76] ogbg-molclintox: 0.834344 test loss: 11.543672
[Epoch 77; Iter    20/   40] train: loss: 0.0143761
[Epoch 77] ogbg-molclintox: 0.962027 val loss: 0.071818
[Epoch 77] ogbg-molclintox: 0.847559 test loss: 11.532219
[Epoch 78; Iter    10/   40] train: loss: 0.1430707
[Epoch 78; Iter    40/   40] train: loss: 0.0998539
[Epoch 78] ogbg-molclintox: 0.963450 val loss: 0.067118
[Epoch 78] ogbg-molclintox: 0.854832 test loss: 8.227569
[Epoch 79; Iter    30/   40] train: loss: 0.0277511
[Epoch 79] ogbg-molclintox: 0.976512 val loss: 0.068274
[Epoch 79] ogbg-molclintox: 0.840552 test loss: 10.256344
[Epoch 80; Iter    20/   40] train: loss: 0.0437458
[Epoch 80] ogbg-molclintox: 0.952187 val loss: 0.086016
[Epoch 80] ogbg-molclintox: 0.845486 test loss: 12.129324
[Epoch 81; Iter    10/   40] train: loss: 0.0612320
[Epoch 81; Iter    40/   40] train: loss: 0.0236313
[Epoch 81] ogbg-molclintox: 0.970081 val loss: 0.069446
[Epoch 81] ogbg-molclintox: 0.835793 test loss: 11.553594
[Epoch 82; Iter    30/   40] train: loss: 0.0363204
[Epoch 82] ogbg-molclintox: 0.970643 val loss: 0.083680
[Epoch 82] ogbg-molclintox: 0.826249 test loss: 12.316744
[Epoch 83; Iter    20/   40] train: loss: 0.0563784
[Epoch 83] ogbg-molclintox: 0.954647 val loss: 0.091423
[Epoch 83] ogbg-molclintox: 0.853394 test loss: 9.728644
[Epoch 84; Iter    10/   40] train: loss: 0.0179576
[Epoch 84; Iter    40/   40] train: loss: 0.2008066
[Epoch 84] ogbg-molclintox: 0.971705 val loss: 0.066654
[Epoch 84] ogbg-molclintox: 0.820841 test loss: 9.672703
[Epoch 85; Iter    30/   40] train: loss: 0.0078590
[Epoch 85] ogbg-molclintox: 0.949640 val loss: 0.087111
[Epoch 85] ogbg-molclintox: 0.828349 test loss: 12.506951
[Epoch 86; Iter    20/   40] train: loss: 0.0508348
[Epoch 86] ogbg-molclintox: 0.966335 val loss: 0.082679
[Epoch 86] ogbg-molclintox: 0.834333 test loss: 8.710867
[Epoch 87; Iter    10/   40] train: loss: 0.0675768
[Epoch 87; Iter    40/   40] train: loss: 0.0445418
[Epoch 87] ogbg-molclintox: 0.940387 val loss: 0.107853
[Epoch 87] ogbg-molclintox: 0.818140 test loss: 13.222213
[Epoch 88; Iter    30/   40] train: loss: 0.0248324
[Epoch 88] ogbg-molclintox: 0.967147 val loss: 0.076978
[Epoch 88] ogbg-molclintox: 0.873781 test loss: 8.210134
[Epoch 89; Iter    20/   40] train: loss: 0.0679428
[Epoch 89] ogbg-molclintox: 0.954647 val loss: 0.081219
[Epoch 89] ogbg-molclintox: 0.856154 test loss: 10.119705
[Epoch 90; Iter    10/   40] train: loss: 0.0679912
[Epoch 90; Iter    40/   40] train: loss: 0.1802697
[Epoch 90] ogbg-molclintox: 0.933956 val loss: 0.093945
[Epoch 90] ogbg-molclintox: 0.815432 test loss: 11.167751
[Epoch 91; Iter    30/   40] train: loss: 0.0483919
[Epoch 91] ogbg-molclintox: 0.943434 val loss: 0.084477
[Epoch 91] ogbg-molclintox: 0.824763 test loss: 11.132743
[Epoch 92; Iter    20/   40] train: loss: 0.1318894
[Epoch 92] ogbg-molclintox: 0.935042 val loss: 0.094074
[Epoch 92] ogbg-molclintox: 0.823265 test loss: 13.020151
[Epoch 93; Iter    10/   40] train: loss: 0.0221499
[Epoch 93; Iter    40/   40] train: loss: 0.0137743
[Epoch 93] ogbg-molclintox: 0.892037 val loss: 0.100006
[Epoch 93] ogbg-molclintox: 0.827064 test loss: 17.751087
[Epoch 94; Iter    30/   40] train: loss: 0.0531250
[Epoch 94] ogbg-molclintox: 0.955097 val loss: 0.078757
[Epoch 94] ogbg-molclintox: 0.822466 test loss: 13.785321
[Epoch 95; Iter    20/   40] train: loss: 0.0383247
[Epoch 95] ogbg-molclintox: 0.957444 val loss: 0.074410
[Epoch 95] ogbg-molclintox: 0.831509 test loss: 12.570924
[Epoch 96; Iter    10/   40] train: loss: 0.0291792
[Epoch 96; Iter    40/   40] train: loss: 0.0292911
[Epoch 96] ogbg-molclintox: 0.954960 val loss: 0.087941
[Epoch 96] ogbg-molclintox: 0.821166 test loss: 12.305048
[Epoch 97; Iter    30/   40] train: loss: 0.0059870
[Epoch 97] ogbg-molclintox: 0.976937 val loss: 0.067641
[Epoch 97] ogbg-molclintox: 0.849035 test loss: 10.114719
[Epoch 98; Iter    20/   40] train: loss: 0.0142331
[Epoch 98] ogbg-molclintox: 0.947380 val loss: 0.096556
[Epoch 98] ogbg-molclintox: 0.809261 test loss: 9.174938
[Epoch 99; Iter    10/   40] train: loss: 0.1054533
[Epoch 99; Iter    40/   40] train: loss: 0.0094167
[Epoch 99] ogbg-molclintox: 0.958168 val loss: 0.076225
[Epoch 99] ogbg-molclintox: 0.863714 test loss: 6.024874
[Epoch 100; Iter    30/   40] train: loss: 0.0125855
[Epoch 100] ogbg-molclintox: 0.907808 val loss: 0.093364
[Epoch 100] ogbg-molclintox: 0.818667 test loss: 6.285673
[Epoch 101; Iter    20/   40] train: loss: 0.0696681
[Epoch 101] ogbg-molclintox: 0.951014 val loss: 0.112839
[Epoch 101] ogbg-molclintox: 0.777706 test loss: 9.266826
[Epoch 102; Iter    10/   40] train: loss: 0.0791691
[Epoch 102; Iter    40/   40] train: loss: 0.1085736
[Epoch 102] ogbg-molclintox: 0.977798 val loss: 0.072413
[Epoch 102] ogbg-molclintox: 0.831722 test loss: 8.884023
[Epoch 103; Iter    30/   40] train: loss: 0.0683491
[Epoch 103] ogbg-molclintox: 0.940250 val loss: 0.100049
[Epoch 103] ogbg-molclintox: 0.809373 test loss: 9.564777
[Epoch 104; Iter    20/   40] train: loss: 0.0282249
[Epoch 104] ogbg-molclintox: 0.910992 val loss: 0.094479
[Epoch 104] ogbg-molclintox: 0.840204 test loss: 8.038538
[Epoch 105; Iter    10/   40] train: loss: 0.0365108
[Epoch 105; Iter    40/   40] train: loss: 0.0310168
[Epoch 105] ogbg-molclintox: 0.959792 val loss: 0.100225
[Epoch 105] ogbg-molclintox: 0.830310 test loss: 6.973873
[Epoch 106; Iter    30/   40] train: loss: 0.0954534
[Epoch 106] ogbg-molclintox: 0.964350 val loss: 0.080835
[Epoch 106] ogbg-molclintox: 0.835457 test loss: 8.889118
[Epoch 107; Iter    20/   40] train: loss: 0.0783731
[Epoch 107] ogbg-molclintox: 0.936754 val loss: 0.102544
[Epoch 107] ogbg-molclintox: 0.798967 test loss: 10.018181
[Epoch 108; Iter    10/   40] train: loss: 0.0063270
[Epoch 108; Iter    40/   40] train: loss: 0.0300641
[Epoch 108] ogbg-molclintox: 0.950539 val loss: 0.086634
[Epoch 108] ogbg-molclintox: 0.838692 test loss: 8.849476
[Epoch 109; Iter    30/   40] train: loss: 0.0749773
[Epoch 109] ogbg-molclintox: 0.938514 val loss: 0.099915
[Epoch 109] ogbg-molclintox: 0.843551 test loss: 10.439722
[Epoch 110; Iter    20/   40] train: loss: 0.0994495
[Epoch 110] ogbg-molclintox: 0.922381 val loss: 0.104779
[Epoch 110] ogbg-molclintox: 0.814196 test loss: 9.368322
[Epoch 111; Iter    10/   40] train: loss: 0.0777599
[Epoch 111; Iter    40/   40] train: loss: 0.1351593
[Epoch 111] ogbg-molclintox: 0.911280 val loss: 0.105910
[Epoch 111] ogbg-molclintox: 0.821341 test loss: 8.506058
[Epoch 112; Iter    30/   40] train: loss: 0.3128518
[Epoch 112] ogbg-molclintox: 0.947493 val loss: 0.104625
[Epoch 112] ogbg-molclintox: 0.817456 test loss: 9.686906
[Epoch 113; Iter    20/   40] train: loss: 0.0184425
[Epoch 113] ogbg-molclintox: 0.963988 val loss: 0.090897
[Epoch 113] ogbg-molclintox: 0.832345 test loss: 12.299093
[Epoch 114; Iter    10/   40] train: loss: 0.0947381
[Epoch 114; Iter    40/   40] train: loss: 0.0076867
[Epoch 114] ogbg-molclintox: 0.923442 val loss: 0.102080
[Epoch 114] ogbg-molclintox: 0.829185 test loss: 7.656518
[Epoch 115; Iter    30/   40] train: loss: 0.0176105
[Epoch 115] ogbg-molclintox: 0.946456 val loss: 0.101262
[Epoch 115] ogbg-molclintox: 0.812220 test loss: 7.838345
[Epoch 116; Iter    20/   40] train: loss: 0.0106166
[Epoch 116] ogbg-molclintox: 0.938289 val loss: 0.099928
[Epoch 116] ogbg-molclintox: 0.835132 test loss: 9.055467
[Epoch 117; Iter    10/   40] train: loss: 0.0492265
[Epoch 117; Iter    40/   40] train: loss: 0.0035504
[Epoch 117] ogbg-molclintox: 0.952862 val loss: 0.088164
[Epoch 117] ogbg-molclintox: 0.829936 test loss: 9.608577
[Epoch 118; Iter    30/   40] train: loss: 0.0919432
[Epoch 118] ogbg-molclintox: 0.953112 val loss: 0.081632
[Epoch 118] ogbg-molclintox: 0.842864 test loss: 6.415507
[Epoch 119; Iter    20/   40] train: loss: 0.0316655
[Epoch 119] ogbg-molclintox: 0.936978 val loss: 0.100385
[Epoch 119] ogbg-molclintox: 0.823153 test loss: 7.656600
[Epoch 120; Iter    10/   40] train: loss: 0.0252030
[Epoch 120; Iter    40/   40] train: loss: 0.0055089
[Epoch 120] ogbg-molclintox: 0.921906 val loss: 0.096694
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 76] ogbg-molclintox: 0.923667 val loss: 0.107496
[Epoch 76] ogbg-molclintox: 0.891456 test loss: 0.391885
[Epoch 77; Iter    20/   40] train: loss: 0.0341511
[Epoch 77] ogbg-molclintox: 0.940861 val loss: 0.089443
[Epoch 77] ogbg-molclintox: 0.873893 test loss: 1.970131
[Epoch 78; Iter    10/   40] train: loss: 0.0704227
[Epoch 78; Iter    40/   40] train: loss: 0.3365185
[Epoch 78] ogbg-molclintox: 0.825944 val loss: 0.129659
[Epoch 78] ogbg-molclintox: 0.854720 test loss: 3.113159
[Epoch 79; Iter    30/   40] train: loss: 0.1611588
[Epoch 79] ogbg-molclintox: 0.968932 val loss: 0.075558
[Epoch 79] ogbg-molclintox: 0.861514 test loss: 0.219742
[Epoch 80; Iter    20/   40] train: loss: 0.0586804
[Epoch 80] ogbg-molclintox: 0.866539 val loss: 0.134211
[Epoch 80] ogbg-molclintox: 0.835969 test loss: 0.201851
[Epoch 81; Iter    10/   40] train: loss: 0.1331829
[Epoch 81; Iter    40/   40] train: loss: 0.0401802
[Epoch 81] ogbg-molclintox: 0.899455 val loss: 0.106608
[Epoch 81] ogbg-molclintox: 0.858227 test loss: 0.169265
[Epoch 82; Iter    30/   40] train: loss: 0.0638601
[Epoch 82] ogbg-molclintox: 0.940387 val loss: 0.095377
[Epoch 82] ogbg-molclintox: 0.830847 test loss: 0.195816
[Epoch 83; Iter    20/   40] train: loss: 0.1205901
[Epoch 83] ogbg-molclintox: 0.816491 val loss: 0.443919
[Epoch 83] ogbg-molclintox: 0.801851 test loss: 0.214036
[Epoch 84; Iter    10/   40] train: loss: 0.0154416
[Epoch 84; Iter    40/   40] train: loss: 0.2135922
[Epoch 84] ogbg-molclintox: 0.928924 val loss: 0.103863
[Epoch 84] ogbg-molclintox: 0.850633 test loss: 0.208118
[Epoch 85; Iter    30/   40] train: loss: 0.0556174
[Epoch 85] ogbg-molclintox: 0.874006 val loss: 0.136016
[Epoch 85] ogbg-molclintox: 0.884038 test loss: 0.185397
[Epoch 86; Iter    20/   40] train: loss: 0.0583573
[Epoch 86] ogbg-molclintox: 0.951126 val loss: 0.120284
[Epoch 86] ogbg-molclintox: 0.865713 test loss: 0.182492
[Epoch 87; Iter    10/   40] train: loss: 0.0433425
[Epoch 87; Iter    40/   40] train: loss: 0.1019556
[Epoch 87] ogbg-molclintox: 0.898780 val loss: 0.122061
[Epoch 87] ogbg-molclintox: 0.866512 test loss: 0.195539
[Epoch 88; Iter    30/   40] train: loss: 0.1124741
[Epoch 88] ogbg-molclintox: 0.920308 val loss: 0.126924
[Epoch 88] ogbg-molclintox: 0.881065 test loss: 0.207831
[Epoch 89; Iter    20/   40] train: loss: 0.2648556
[Epoch 89] ogbg-molclintox: 0.941786 val loss: 0.102980
[Epoch 89] ogbg-molclintox: 0.875480 test loss: 0.207670
[Epoch 90; Iter    10/   40] train: loss: 0.1913759
[Epoch 90; Iter    40/   40] train: loss: 0.0463275
[Epoch 90] ogbg-molclintox: 0.911754 val loss: 0.127719
[Epoch 90] ogbg-molclintox: 0.844862 test loss: 0.191039
[Epoch 91; Iter    30/   40] train: loss: 0.0116284
[Epoch 91] ogbg-molclintox: 0.954060 val loss: 0.094465
[Epoch 91] ogbg-molclintox: 0.893331 test loss: 0.183598
[Epoch 92; Iter    20/   40] train: loss: 0.0914617
[Epoch 92] ogbg-molclintox: 0.901989 val loss: 0.098457
[Epoch 92] ogbg-molclintox: 0.908683 test loss: 0.140169
[Epoch 93; Iter    10/   40] train: loss: 0.0245720
[Epoch 93; Iter    40/   40] train: loss: 0.0286795
[Epoch 93] ogbg-molclintox: 0.921369 val loss: 0.141868
[Epoch 93] ogbg-molclintox: 0.887923 test loss: 0.172179
[Epoch 94; Iter    30/   40] train: loss: 0.0060633
[Epoch 94] ogbg-molclintox: 0.887753 val loss: 0.091512
[Epoch 94] ogbg-molclintox: 0.925149 test loss: 0.132746
[Epoch 95; Iter    20/   40] train: loss: 0.0620588
[Epoch 95] ogbg-molclintox: 0.920870 val loss: 0.151111
[Epoch 95] ogbg-molclintox: 0.889271 test loss: 0.160931
[Epoch 96; Iter    10/   40] train: loss: 0.0296699
[Epoch 96; Iter    40/   40] train: loss: 0.2049796
[Epoch 96] ogbg-molclintox: 0.922068 val loss: 0.092896
[Epoch 96] ogbg-molclintox: 0.910196 test loss: 0.189356
[Epoch 97; Iter    30/   40] train: loss: 0.0308068
[Epoch 97] ogbg-molclintox: 0.848220 val loss: 0.117481
[Epoch 97] ogbg-molclintox: 0.866822 test loss: 0.342555
[Epoch 98; Iter    20/   40] train: loss: 0.0511708
[Epoch 98] ogbg-molclintox: 0.931321 val loss: 0.092895
[Epoch 98] ogbg-molclintox: 0.889559 test loss: 0.253189
[Epoch 99; Iter    10/   40] train: loss: 0.1579965
[Epoch 99; Iter    40/   40] train: loss: 0.0182649
[Epoch 99] ogbg-molclintox: 0.891338 val loss: 0.107917
[Epoch 99] ogbg-molclintox: 0.854469 test loss: 0.462466
[Epoch 100; Iter    30/   40] train: loss: 0.0512200
[Epoch 100] ogbg-molclintox: 0.929174 val loss: 0.104339
[Epoch 100] ogbg-molclintox: 0.856517 test loss: 0.344731
[Epoch 101; Iter    20/   40] train: loss: 0.1188329
[Epoch 101] ogbg-molclintox: 0.887142 val loss: 0.115774
[Epoch 101] ogbg-molclintox: 0.886810 test loss: 0.311093
[Epoch 102; Iter    10/   40] train: loss: 0.0127097
[Epoch 102; Iter    40/   40] train: loss: 0.1415060
[Epoch 102] ogbg-molclintox: 0.927687 val loss: 0.097345
[Epoch 102] ogbg-molclintox: 0.876680 test loss: 0.328968
[Epoch 103; Iter    30/   40] train: loss: 0.0193503
[Epoch 103] ogbg-molclintox: 0.832561 val loss: 0.145397
[Epoch 103] ogbg-molclintox: 0.838729 test loss: 0.274544
[Epoch 104; Iter    20/   40] train: loss: 0.0335238
[Epoch 104] ogbg-molclintox: 0.894472 val loss: 0.116624
[Epoch 104] ogbg-molclintox: 0.854619 test loss: 0.502710
[Epoch 105; Iter    10/   40] train: loss: 0.0316200
[Epoch 105; Iter    40/   40] train: loss: 0.0117482
[Epoch 105] ogbg-molclintox: 0.933419 val loss: 0.095987
[Epoch 105] ogbg-molclintox: 0.897455 test loss: 2.630958
[Epoch 106; Iter    30/   40] train: loss: 0.0372837
[Epoch 106] ogbg-molclintox: 0.928049 val loss: 0.109142
[Epoch 106] ogbg-molclintox: 0.891370 test loss: 9.394664
[Epoch 107; Iter    20/   40] train: loss: 0.0814127
[Epoch 107] ogbg-molclintox: 0.952212 val loss: 0.094900
[Epoch 107] ogbg-molclintox: 0.886709 test loss: 9.827839
[Epoch 108; Iter    10/   40] train: loss: 0.0377677
[Epoch 108; Iter    40/   40] train: loss: 0.0071929
[Epoch 108] ogbg-molclintox: 0.858832 val loss: 0.128855
[Epoch 108] ogbg-molclintox: 0.812560 test loss: 7.948651
[Epoch 109; Iter    30/   40] train: loss: 0.0376717
[Epoch 109] ogbg-molclintox: 0.886404 val loss: 0.112005
[Epoch 109] ogbg-molclintox: 0.873605 test loss: 11.770721
[Epoch 110; Iter    20/   40] train: loss: 0.0434480
[Epoch 110] ogbg-molclintox: 0.948329 val loss: 0.100357
[Epoch 110] ogbg-molclintox: 0.873243 test loss: 11.961979
[Epoch 111; Iter    10/   40] train: loss: 0.0175563
[Epoch 111; Iter    40/   40] train: loss: 0.0020410
[Epoch 111] ogbg-molclintox: 0.951376 val loss: 0.102337
[Epoch 111] ogbg-molclintox: 0.876941 test loss: 11.507464
[Epoch 112; Iter    30/   40] train: loss: 0.0489308
[Epoch 112] ogbg-molclintox: 0.916024 val loss: 0.110151
[Epoch 112] ogbg-molclintox: 0.853618 test loss: 11.350308
[Epoch 113; Iter    20/   40] train: loss: 0.1073031
[Epoch 113] ogbg-molclintox: 0.926538 val loss: 0.107665
[Epoch 113] ogbg-molclintox: 0.860801 test loss: 11.072677
[Epoch 114; Iter    10/   40] train: loss: 0.0330196
[Epoch 114; Iter    40/   40] train: loss: 0.2322651
[Epoch 114] ogbg-molclintox: 0.950564 val loss: 0.099834
[Epoch 114] ogbg-molclintox: 0.870584 test loss: 11.769094
[Epoch 115; Iter    30/   40] train: loss: 0.0957641
[Epoch 115] ogbg-molclintox: 0.947879 val loss: 0.107132
[Epoch 115] ogbg-molclintox: 0.866385 test loss: 12.277618
[Epoch 116; Iter    20/   40] train: loss: 0.0468742
[Epoch 116] ogbg-molclintox: 0.932495 val loss: 0.115044
[Epoch 116] ogbg-molclintox: 0.846286 test loss: 11.856515
[Epoch 117; Iter    10/   40] train: loss: 0.0455975
[Epoch 117; Iter    40/   40] train: loss: 0.0425777
[Epoch 117] ogbg-molclintox: 0.933644 val loss: 0.106871
[Epoch 117] ogbg-molclintox: 0.862037 test loss: 10.725265
[Epoch 118; Iter    30/   40] train: loss: 0.0314282
[Epoch 118] ogbg-molclintox: 0.957919 val loss: 0.108742
[Epoch 118] ogbg-molclintox: 0.866774 test loss: 10.664590
[Epoch 119; Iter    20/   40] train: loss: 0.0613282
[Epoch 119] ogbg-molclintox: 0.919545 val loss: 0.112900
[Epoch 119] ogbg-molclintox: 0.872881 test loss: 10.181742
[Epoch 120; Iter    10/   40] train: loss: 0.1742932
[Epoch 120; Iter    40/   40] train: loss: 0.0047811
[Epoch 120] ogbg-molclintox: 0.952437 val loss: 0.107235
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 120] ogbg-molclintox: 0.845438 test loss: 7.353354
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 120 epochs. Best model checkpoint was in epoch 46.
Statistics on  val_best_checkpoint
mean_pred: 0.19540517032146454
std_pred: 5.184990882873535
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.9651320854479764
rocauc: 0.9940436324239141
ogbg-molclintox: 0.9940436324239141
OGBNanLabelBCEWithLogitsLoss: 0.06103826453909278
Statistics on  test
mean_pred: 0.12358541041612625
std_pred: 8.4865083694458
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.7009760114407944
rocauc: 0.8450118166336495
ogbg-molclintox: 0.8450118166336495
OGBNanLabelBCEWithLogitsLoss: 0.7778774037957191
Statistics on  train
mean_pred: 0.22917230427265167
std_pred: 5.351119518280029
mean_targets: 0.5067738890647888
std_targets: 0.500059962272644
prcauc: 0.9186424503003301
rocauc: 0.9801855940033568
ogbg-molclintox: 0.9801855940033568
OGBNanLabelBCEWithLogitsLoss: 0.09840185306966305
[Epoch 84; Iter    30/   30] train: loss: 0.2967243
[Epoch 84] ogbg-molclintox: 0.896005 val loss: 0.188811
[Epoch 84] ogbg-molclintox: 0.905519 test loss: 0.373470
[Epoch 85; Iter    30/   30] train: loss: 0.0880775
[Epoch 85] ogbg-molclintox: 0.881446 val loss: 0.189525
[Epoch 85] ogbg-molclintox: 0.930808 test loss: 0.189220
[Epoch 86; Iter    30/   30] train: loss: 0.0922442
[Epoch 86] ogbg-molclintox: 0.879649 val loss: 0.192417
[Epoch 86] ogbg-molclintox: 0.906501 test loss: 0.226278
[Epoch 87; Iter    30/   30] train: loss: 0.1468765
[Epoch 87] ogbg-molclintox: 0.862936 val loss: 0.216376
[Epoch 87] ogbg-molclintox: 0.943075 test loss: 0.187180
[Epoch 88; Iter    30/   30] train: loss: 0.2318383
[Epoch 88] ogbg-molclintox: 0.885243 val loss: 0.183901
[Epoch 88] ogbg-molclintox: 0.912186 test loss: 0.227752
[Epoch 89; Iter    30/   30] train: loss: 0.1216055
[Epoch 89] ogbg-molclintox: 0.891092 val loss: 0.161923
[Epoch 89] ogbg-molclintox: 0.918840 test loss: 0.168540
[Epoch 90; Iter    30/   30] train: loss: 0.2876233
[Epoch 90] ogbg-molclintox: 0.877991 val loss: 0.174902
[Epoch 90] ogbg-molclintox: 0.932736 test loss: 0.297812
[Epoch 91; Iter    30/   30] train: loss: 0.2424104
[Epoch 91] ogbg-molclintox: 0.884040 val loss: 0.195233
[Epoch 91] ogbg-molclintox: 0.930602 test loss: 0.933764
[Epoch 92; Iter    30/   30] train: loss: 0.1208536
[Epoch 92] ogbg-molclintox: 0.879949 val loss: 0.178423
[Epoch 92] ogbg-molclintox: 0.939165 test loss: 0.212202
[Epoch 93; Iter    30/   30] train: loss: 0.3400046
[Epoch 93] ogbg-molclintox: 0.853377 val loss: 0.209426
[Epoch 93] ogbg-molclintox: 0.897791 test loss: 0.527270
[Epoch 94; Iter    30/   30] train: loss: 0.1022992
[Epoch 94] ogbg-molclintox: 0.885933 val loss: 0.189897
[Epoch 94] ogbg-molclintox: 0.919535 test loss: 0.863734
[Epoch 95; Iter    30/   30] train: loss: 0.1319132
[Epoch 95] ogbg-molclintox: 0.883847 val loss: 0.184271
[Epoch 95] ogbg-molclintox: 0.924884 test loss: 0.407735
[Epoch 96; Iter    30/   30] train: loss: 0.0164276
[Epoch 96] ogbg-molclintox: 0.876360 val loss: 0.183716
[Epoch 96] ogbg-molclintox: 0.930800 test loss: 0.270594
[Epoch 97; Iter    30/   30] train: loss: 0.5300671
[Epoch 97] ogbg-molclintox: 0.866031 val loss: 0.184527
[Epoch 97] ogbg-molclintox: 0.930931 test loss: 0.292661
[Epoch 98; Iter    30/   30] train: loss: 0.0093784
[Epoch 98] ogbg-molclintox: 0.862623 val loss: 0.215887
[Epoch 98] ogbg-molclintox: 0.943060 test loss: 0.314380
[Epoch 99; Iter    30/   30] train: loss: 0.0679071
[Epoch 99] ogbg-molclintox: 0.852849 val loss: 0.213910
[Epoch 99] ogbg-molclintox: 0.925754 test loss: 0.349155
[Epoch 100; Iter    30/   30] train: loss: 0.0695698
[Epoch 100] ogbg-molclintox: 0.832608 val loss: 0.228824
[Epoch 100] ogbg-molclintox: 0.886657 test loss: 0.748600
[Epoch 101; Iter    30/   30] train: loss: 0.0419825
[Epoch 101] ogbg-molclintox: 0.862830 val loss: 0.209375
[Epoch 101] ogbg-molclintox: 0.927690 test loss: 1.077713
[Epoch 102; Iter    30/   30] train: loss: 0.1231148
[Epoch 102] ogbg-molclintox: 0.849279 val loss: 0.216733
[Epoch 102] ogbg-molclintox: 0.925696 test loss: 0.534178
[Epoch 103; Iter    30/   30] train: loss: 0.1167736
[Epoch 103] ogbg-molclintox: 0.867737 val loss: 0.218861
[Epoch 103] ogbg-molclintox: 0.923450 test loss: 0.773784
[Epoch 104; Iter    30/   30] train: loss: 0.0668768
[Epoch 104] ogbg-molclintox: 0.863525 val loss: 0.217027
[Epoch 104] ogbg-molclintox: 0.929722 test loss: 0.938076
[Epoch 105; Iter    30/   30] train: loss: 0.0247829
[Epoch 105] ogbg-molclintox: 0.879595 val loss: 0.196855
[Epoch 105] ogbg-molclintox: 0.933309 test loss: 1.488318
[Epoch 106; Iter    30/   30] train: loss: 0.0070991
[Epoch 106] ogbg-molclintox: 0.863030 val loss: 0.228861
[Epoch 106] ogbg-molclintox: 0.934814 test loss: 0.410280
[Epoch 107; Iter    30/   30] train: loss: 0.0819363
[Epoch 107] ogbg-molclintox: 0.870798 val loss: 0.183959
[Epoch 107] ogbg-molclintox: 0.925213 test loss: 0.587496
[Epoch 108; Iter    30/   30] train: loss: 0.1804909
[Epoch 108] ogbg-molclintox: 0.856152 val loss: 0.216901
[Epoch 108] ogbg-molclintox: 0.938900 test loss: 0.698734
[Epoch 109; Iter    30/   30] train: loss: 0.0172623
[Epoch 109] ogbg-molclintox: 0.874720 val loss: 0.211240
[Epoch 109] ogbg-molclintox: 0.940626 test loss: 0.392211
[Epoch 110; Iter    30/   30] train: loss: 0.0976750
[Epoch 110] ogbg-molclintox: 0.849834 val loss: 0.236521
[Epoch 110] ogbg-molclintox: 0.922775 test loss: 0.199946
[Epoch 111; Iter    30/   30] train: loss: 0.0136598
[Epoch 111] ogbg-molclintox: 0.852956 val loss: 0.247013
[Epoch 111] ogbg-molclintox: 0.945232 test loss: 0.160807
[Epoch 112; Iter    30/   30] train: loss: 0.0070474
[Epoch 112] ogbg-molclintox: 0.847888 val loss: 0.231245
[Epoch 112] ogbg-molclintox: 0.931438 test loss: 0.238510
[Epoch 113; Iter    30/   30] train: loss: 0.0187938
[Epoch 113] ogbg-molclintox: 0.864828 val loss: 0.205143
[Epoch 113] ogbg-molclintox: 0.932551 test loss: 0.353811
[Epoch 114; Iter    30/   30] train: loss: 0.0640232
[Epoch 114] ogbg-molclintox: 0.879507 val loss: 0.254490
[Epoch 114] ogbg-molclintox: 0.927497 test loss: 0.419288
[Epoch 115; Iter    30/   30] train: loss: 0.0374366
[Epoch 115] ogbg-molclintox: 0.857515 val loss: 0.214662
[Epoch 115] ogbg-molclintox: 0.926631 test loss: 0.549761
[Epoch 116; Iter    30/   30] train: loss: 0.0756024
[Epoch 116] ogbg-molclintox: 0.904381 val loss: 0.171089
[Epoch 116] ogbg-molclintox: 0.945328 test loss: 0.612160
[Epoch 117; Iter    30/   30] train: loss: 0.0123904
[Epoch 117] ogbg-molclintox: 0.890149 val loss: 0.320802
[Epoch 117] ogbg-molclintox: 0.945170 test loss: 0.463199
[Epoch 118; Iter    30/   30] train: loss: 0.0026381
[Epoch 118] ogbg-molclintox: 0.856926 val loss: 0.214224
[Epoch 118] ogbg-molclintox: 0.933603 test loss: 0.886055
[Epoch 119; Iter    30/   30] train: loss: 0.0079638
[Epoch 119] ogbg-molclintox: 0.848645 val loss: 0.206962
[Epoch 119] ogbg-molclintox: 0.918319 test loss: 0.703717
[Epoch 120; Iter    30/   30] train: loss: 0.0060088
[Epoch 120] ogbg-molclintox: 0.862315 val loss: 0.206310
[Epoch 120] ogbg-molclintox: 0.936263 test loss: 0.144444
[Epoch 121; Iter    30/   30] train: loss: 0.0480797
[Epoch 121] ogbg-molclintox: 0.899260 val loss: 0.185134
[Epoch 121] ogbg-molclintox: 0.941002 test loss: 0.182935
[Epoch 122; Iter    30/   30] train: loss: 0.2073694
[Epoch 122] ogbg-molclintox: 0.903525 val loss: 0.190865
[Epoch 122] ogbg-molclintox: 0.938611 test loss: 0.244860
[Epoch 123; Iter    30/   30] train: loss: 0.0429951
[Epoch 123] ogbg-molclintox: 0.897622 val loss: 0.204646
[Epoch 123] ogbg-molclintox: 0.944266 test loss: 0.294181
[Epoch 124; Iter    30/   30] train: loss: 0.0105585
[Epoch 124] ogbg-molclintox: 0.880396 val loss: 0.200618
[Epoch 124] ogbg-molclintox: 0.940109 test loss: 0.383638
[Epoch 125; Iter    30/   30] train: loss: 0.1194845
[Epoch 125] ogbg-molclintox: 0.882336 val loss: 0.192978
[Epoch 125] ogbg-molclintox: 0.938671 test loss: 0.280149
[Epoch 126; Iter    30/   30] train: loss: 0.0018558
[Epoch 126] ogbg-molclintox: 0.876266 val loss: 0.206496
[Epoch 126] ogbg-molclintox: 0.941029 test loss: 0.317770
[Epoch 127; Iter    30/   30] train: loss: 0.0101748
[Epoch 127] ogbg-molclintox: 0.869902 val loss: 0.215587
[Epoch 127] ogbg-molclintox: 0.942790 test loss: 0.184756
[Epoch 128; Iter    30/   30] train: loss: 0.0181613
[Epoch 128] ogbg-molclintox: 0.871734 val loss: 0.204508
[Epoch 128] ogbg-molclintox: 0.943526 test loss: 0.275927
[Epoch 129; Iter    30/   30] train: loss: 0.0703729
[Epoch 129] ogbg-molclintox: 0.863772 val loss: 0.200852
[Epoch 129] ogbg-molclintox: 0.937739 test loss: 0.157971
[Epoch 130; Iter    30/   30] train: loss: 0.1133378
[Epoch 130] ogbg-molclintox: 0.842842 val loss: 0.218862
[Epoch 130] ogbg-molclintox: 0.928943 test loss: 0.157779
[Epoch 131; Iter    30/   30] train: loss: 0.1892082
[Epoch 131] ogbg-molclintox: 0.877991 val loss: 0.214162
[Epoch 131] ogbg-molclintox: 0.936162 test loss: 0.197147
[Epoch 132; Iter    30/   30] train: loss: 0.1128181
[Epoch 132] ogbg-molclintox: 0.869668 val loss: 0.207017
[Epoch 132] ogbg-molclintox: 0.941375 test loss: 0.258507
[Epoch 120] ogbg-molclintox: 0.871133 test loss: 11.357682
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 120 epochs. Best model checkpoint was in epoch 48.
Statistics on  val_best_checkpoint
mean_pred: 0.2783963680267334
std_pred: 5.166340351104736
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.8807073123680711
rocauc: 0.9847910305656785
ogbg-molclintox: 0.9847910305656785
OGBNanLabelBCEWithLogitsLoss: 0.07269817553460597
Statistics on  test
mean_pred: 0.17041891813278198
std_pred: 4.505177974700928
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.7321070611604619
rocauc: 0.8469989226010497
ogbg-molclintox: 0.8469989226010497
OGBNanLabelBCEWithLogitsLoss: 0.18852763921022414
Statistics on  train
mean_pred: 0.233964204788208
std_pred: 5.054538726806641
mean_targets: 0.5067738890647888
std_targets: 0.500059962272644
prcauc: 0.8928037736116436
rocauc: 0.9754555452311889
ogbg-molclintox: 0.9754555452311889
OGBNanLabelBCEWithLogitsLoss: 0.10597109799273312
[Epoch 84; Iter    30/   30] train: loss: 0.1390555
[Epoch 84] ogbg-molclintox: 0.940446 val loss: 0.139767
[Epoch 84] ogbg-molclintox: 0.930347 test loss: 0.184572
[Epoch 85; Iter    30/   30] train: loss: 0.0503549
[Epoch 85] ogbg-molclintox: 0.914977 val loss: 0.152882
[Epoch 85] ogbg-molclintox: 0.926191 test loss: 0.127731
[Epoch 86; Iter    30/   30] train: loss: 0.1937030
[Epoch 86] ogbg-molclintox: 0.903699 val loss: 0.195247
[Epoch 86] ogbg-molclintox: 0.926322 test loss: 0.175607
[Epoch 87; Iter    30/   30] train: loss: 0.0157318
[Epoch 87] ogbg-molclintox: 0.732588 val loss: 0.262637
[Epoch 87] ogbg-molclintox: 0.769866 test loss: 1.755534
[Epoch 88; Iter    30/   30] train: loss: 0.1134506
[Epoch 88] ogbg-molclintox: 0.916533 val loss: 0.197431
[Epoch 88] ogbg-molclintox: 0.895684 test loss: 0.246377
[Epoch 89; Iter    30/   30] train: loss: 0.0772436
[Epoch 89] ogbg-molclintox: 0.849143 val loss: 0.379160
[Epoch 89] ogbg-molclintox: 0.867434 test loss: 0.280488
[Epoch 90; Iter    30/   30] train: loss: 0.0141839
[Epoch 90] ogbg-molclintox: 0.900123 val loss: 0.189991
[Epoch 90] ogbg-molclintox: 0.864080 test loss: 0.351592
[Epoch 91; Iter    30/   30] train: loss: 0.3195128
[Epoch 91] ogbg-molclintox: 0.861505 val loss: 2.373347
[Epoch 91] ogbg-molclintox: 0.895216 test loss: 1.564918
[Epoch 92; Iter    30/   30] train: loss: 0.0100551
[Epoch 92] ogbg-molclintox: 0.916046 val loss: 0.186699
[Epoch 92] ogbg-molclintox: 0.836744 test loss: 0.171331
[Epoch 93; Iter    30/   30] train: loss: 0.0276019
[Epoch 93] ogbg-molclintox: 0.909388 val loss: 0.175774
[Epoch 93] ogbg-molclintox: 0.910690 test loss: 0.149637
[Epoch 94; Iter    30/   30] train: loss: 0.1149833
[Epoch 94] ogbg-molclintox: 0.895584 val loss: 0.266433
[Epoch 94] ogbg-molclintox: 0.891973 test loss: 0.213719
[Epoch 95; Iter    30/   30] train: loss: 0.0195063
[Epoch 95] ogbg-molclintox: 0.918928 val loss: 0.165416
[Epoch 95] ogbg-molclintox: 0.941658 test loss: 0.122844
[Epoch 96; Iter    30/   30] train: loss: 0.0384231
[Epoch 96] ogbg-molclintox: 0.913633 val loss: 0.161034
[Epoch 96] ogbg-molclintox: 0.927449 test loss: 0.121833
[Epoch 97; Iter    30/   30] train: loss: 0.0121957
[Epoch 97] ogbg-molclintox: 0.910251 val loss: 0.172863
[Epoch 97] ogbg-molclintox: 0.927223 test loss: 0.352643
[Epoch 98; Iter    30/   30] train: loss: 0.0480662
[Epoch 98] ogbg-molclintox: 0.904823 val loss: 0.174690
[Epoch 98] ogbg-molclintox: 0.938731 test loss: 0.280318
[Epoch 99; Iter    30/   30] train: loss: 0.2881485
[Epoch 99] ogbg-molclintox: 0.916835 val loss: 0.166549
[Epoch 99] ogbg-molclintox: 0.938602 test loss: 0.143659
[Epoch 100; Iter    30/   30] train: loss: 0.0208016
[Epoch 100] ogbg-molclintox: 0.908051 val loss: 0.173474
[Epoch 100] ogbg-molclintox: 0.918202 test loss: 0.152370
[Epoch 101; Iter    30/   30] train: loss: 0.0204568
[Epoch 101] ogbg-molclintox: 0.901902 val loss: 0.159826
[Epoch 101] ogbg-molclintox: 0.920164 test loss: 0.118909
[Epoch 102; Iter    30/   30] train: loss: 0.1724127
[Epoch 102] ogbg-molclintox: 0.918340 val loss: 0.153887
[Epoch 102] ogbg-molclintox: 0.945737 test loss: 0.128761
[Epoch 103; Iter    30/   30] train: loss: 0.0060862
[Epoch 103] ogbg-molclintox: 0.913352 val loss: 0.187290
[Epoch 103] ogbg-molclintox: 0.932513 test loss: 0.199038
[Epoch 104; Iter    30/   30] train: loss: 0.0858598
[Epoch 104] ogbg-molclintox: 0.907516 val loss: 0.204691
[Epoch 104] ogbg-molclintox: 0.918232 test loss: 0.164115
[Epoch 105; Iter    30/   30] train: loss: 0.0746080
[Epoch 105] ogbg-molclintox: 0.902905 val loss: 0.168974
[Epoch 105] ogbg-molclintox: 0.918526 test loss: 0.517862
[Epoch 106; Iter    30/   30] train: loss: 0.0232373
[Epoch 106] ogbg-molclintox: 0.904242 val loss: 0.217086
[Epoch 106] ogbg-molclintox: 0.929576 test loss: 0.161246
[Epoch 107; Iter    30/   30] train: loss: 0.0422334
[Epoch 107] ogbg-molclintox: 0.898906 val loss: 0.236672
[Epoch 107] ogbg-molclintox: 0.938759 test loss: 0.110596
[Epoch 108; Iter    30/   30] train: loss: 0.0046047
[Epoch 108] ogbg-molclintox: 0.906849 val loss: 0.214562
[Epoch 108] ogbg-molclintox: 0.932328 test loss: 0.122243
[Epoch 109; Iter    30/   30] train: loss: 0.0488811
[Epoch 109] ogbg-molclintox: 0.919850 val loss: 0.179572
[Epoch 109] ogbg-molclintox: 0.944637 test loss: 0.140419
[Epoch 110; Iter    30/   30] train: loss: 0.0377498
[Epoch 110] ogbg-molclintox: 0.906120 val loss: 0.166157
[Epoch 110] ogbg-molclintox: 0.934208 test loss: 0.147366
[Epoch 111; Iter    30/   30] train: loss: 0.0896018
[Epoch 111] ogbg-molclintox: 0.904168 val loss: 0.180501
[Epoch 111] ogbg-molclintox: 0.934494 test loss: 0.157280
[Epoch 112; Iter    30/   30] train: loss: 0.0878279
[Epoch 112] ogbg-molclintox: 0.911107 val loss: 0.170173
[Epoch 112] ogbg-molclintox: 0.935805 test loss: 0.138937
[Epoch 113; Iter    30/   30] train: loss: 0.1498165
[Epoch 113] ogbg-molclintox: 0.892122 val loss: 0.206435
[Epoch 113] ogbg-molclintox: 0.927490 test loss: 0.150467
[Epoch 114; Iter    30/   30] train: loss: 0.0526746
[Epoch 114] ogbg-molclintox: 0.882589 val loss: 0.192384
[Epoch 114] ogbg-molclintox: 0.933607 test loss: 0.143777
[Epoch 115; Iter    30/   30] train: loss: 0.0784588
[Epoch 115] ogbg-molclintox: 0.888712 val loss: 0.187250
[Epoch 115] ogbg-molclintox: 0.935350 test loss: 0.139234
[Epoch 116; Iter    30/   30] train: loss: 0.0374297
[Epoch 116] ogbg-molclintox: 0.903960 val loss: 0.173298
[Epoch 116] ogbg-molclintox: 0.942601 test loss: 0.130965
[Epoch 117; Iter    30/   30] train: loss: 0.0093274
[Epoch 117] ogbg-molclintox: 0.900806 val loss: 0.176197
[Epoch 117] ogbg-molclintox: 0.934412 test loss: 0.131587
[Epoch 118; Iter    30/   30] train: loss: 0.2376249
[Epoch 118] ogbg-molclintox: 0.878158 val loss: 0.195296
[Epoch 118] ogbg-molclintox: 0.921832 test loss: 0.147778
[Epoch 119; Iter    30/   30] train: loss: 0.0119790
[Epoch 119] ogbg-molclintox: 0.897603 val loss: 0.191392
[Epoch 119] ogbg-molclintox: 0.934189 test loss: 0.123711
[Epoch 120; Iter    30/   30] train: loss: 0.0380488
[Epoch 120] ogbg-molclintox: 0.907543 val loss: 0.184480
[Epoch 120] ogbg-molclintox: 0.929439 test loss: 0.138919
[Epoch 121; Iter    30/   30] train: loss: 0.0203866
[Epoch 121] ogbg-molclintox: 0.901949 val loss: 0.185044
[Epoch 121] ogbg-molclintox: 0.932545 test loss: 0.150236
[Epoch 122; Iter    30/   30] train: loss: 0.0279146
[Epoch 122] ogbg-molclintox: 0.890531 val loss: 0.186177
[Epoch 122] ogbg-molclintox: 0.927020 test loss: 0.151211
[Epoch 123; Iter    30/   30] train: loss: 0.0318658
[Epoch 123] ogbg-molclintox: 0.879708 val loss: 0.204562
[Epoch 123] ogbg-molclintox: 0.933882 test loss: 0.290103
[Epoch 124; Iter    30/   30] train: loss: 0.0852281
[Epoch 124] ogbg-molclintox: 0.855542 val loss: 0.204136
[Epoch 124] ogbg-molclintox: 0.898829 test loss: 0.149326
[Epoch 125; Iter    30/   30] train: loss: 0.1206328
[Epoch 125] ogbg-molclintox: 0.899869 val loss: 0.208981
[Epoch 125] ogbg-molclintox: 0.939784 test loss: 0.138013
[Epoch 126; Iter    30/   30] train: loss: 0.1751346
[Epoch 126] ogbg-molclintox: 0.895651 val loss: 0.204840
[Epoch 126] ogbg-molclintox: 0.936150 test loss: 0.158986
[Epoch 127; Iter    30/   30] train: loss: 0.0673909
[Epoch 127] ogbg-molclintox: 0.898372 val loss: 0.184406
[Epoch 127] ogbg-molclintox: 0.934425 test loss: 0.149106
[Epoch 128; Iter    30/   30] train: loss: 0.0366884
[Epoch 128] ogbg-molclintox: 0.889481 val loss: 0.186462
[Epoch 128] ogbg-molclintox: 0.924822 test loss: 0.147523
[Epoch 129; Iter    30/   30] train: loss: 0.0671506
[Epoch 129] ogbg-molclintox: 0.882262 val loss: 0.187596
[Epoch 129] ogbg-molclintox: 0.934126 test loss: 0.136574
[Epoch 130; Iter    30/   30] train: loss: 0.1073398
[Epoch 130] ogbg-molclintox: 0.880871 val loss: 0.201916
[Epoch 130] ogbg-molclintox: 0.936207 test loss: 0.148883
[Epoch 131; Iter    30/   30] train: loss: 0.0395495
[Epoch 131] ogbg-molclintox: 0.891106 val loss: 0.183260
[Epoch 131] ogbg-molclintox: 0.932914 test loss: 0.146097
[Epoch 132; Iter    30/   30] train: loss: 0.0166447
[Epoch 132] ogbg-molclintox: 0.884802 val loss: 0.203846
[Epoch 132] ogbg-molclintox: 0.929864 test loss: 0.152963
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 120] ogbg-molclintox: 0.862075 test loss: 0.210532
[Epoch 121; Iter    30/   40] train: loss: 0.0094799
[Epoch 121] ogbg-molclintox: 0.791569 val loss: 0.134568
[Epoch 121] ogbg-molclintox: 0.848172 test loss: 0.221586
[Epoch 122; Iter    20/   40] train: loss: 0.0460349
[Epoch 122] ogbg-molclintox: 0.880113 val loss: 0.126951
[Epoch 122] ogbg-molclintox: 0.870382 test loss: 0.223822
[Epoch 123; Iter    10/   40] train: loss: 0.0574150
[Epoch 123; Iter    40/   40] train: loss: 0.0041022
[Epoch 123] ogbg-molclintox: 0.863755 val loss: 0.123221
[Epoch 123] ogbg-molclintox: 0.877666 test loss: 0.200682
[Epoch 124; Iter    30/   40] train: loss: 0.0546431
[Epoch 124] ogbg-molclintox: 0.854640 val loss: 0.118313
[Epoch 124] ogbg-molclintox: 0.864536 test loss: 0.196341
[Epoch 125; Iter    20/   40] train: loss: 0.0588305
[Epoch 125] ogbg-molclintox: 0.895010 val loss: 0.118694
[Epoch 125] ogbg-molclintox: 0.889058 test loss: 0.186713
[Epoch 126; Iter    10/   40] train: loss: 0.0538163
[Epoch 126; Iter    40/   40] train: loss: 0.0141129
[Epoch 126] ogbg-molclintox: 0.814070 val loss: 0.142077
[Epoch 126] ogbg-molclintox: 0.874129 test loss: 0.200543
[Epoch 127; Iter    30/   40] train: loss: 0.0163506
[Epoch 127] ogbg-molclintox: 0.852904 val loss: 0.132613
[Epoch 127] ogbg-molclintox: 0.893642 test loss: 0.199197
[Epoch 128; Iter    20/   40] train: loss: 0.0348097
[Epoch 128] ogbg-molclintox: 0.867227 val loss: 0.123164
[Epoch 128] ogbg-molclintox: 0.878540 test loss: 0.199064
[Epoch 129; Iter    10/   40] train: loss: 0.0579105
[Epoch 129; Iter    40/   40] train: loss: 0.0051225
[Epoch 129] ogbg-molclintox: 0.816094 val loss: 0.122337
[Epoch 129] ogbg-molclintox: 0.868432 test loss: 0.185437
[Epoch 130; Iter    30/   40] train: loss: 0.0385176
[Epoch 130] ogbg-molclintox: 0.849871 val loss: 0.123251
[Epoch 130] ogbg-molclintox: 0.873867 test loss: 0.208724
[Epoch 131; Iter    20/   40] train: loss: 0.0322375
[Epoch 131] ogbg-molclintox: 0.865730 val loss: 0.125960
[Epoch 131] ogbg-molclintox: 0.875865 test loss: 0.204268
[Epoch 132; Iter    10/   40] train: loss: 0.0143650
[Epoch 132; Iter    40/   40] train: loss: 0.0149451
[Epoch 132] ogbg-molclintox: 0.867853 val loss: 0.141855
[Epoch 132] ogbg-molclintox: 0.872817 test loss: 0.211137
[Epoch 133; Iter    30/   40] train: loss: 0.0206769
[Epoch 133] ogbg-molclintox: 0.808665 val loss: 0.140126
[Epoch 133] ogbg-molclintox: 0.867846 test loss: 0.209055
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 133 epochs. Best model checkpoint was in epoch 73.
Statistics on  val_best_checkpoint
mean_pred: 0.2794173061847687
std_pred: 6.4091477394104
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.9178084105094594
rocauc: 0.9950802718408353
ogbg-molclintox: 0.9950802718408353
OGBNanLabelBCEWithLogitsLoss: 0.04929745104163885
Statistics on  test
mean_pred: 0.24885603785514832
std_pred: 5.495881080627441
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.7964773776639392
rocauc: 0.8860850450074723
ogbg-molclintox: 0.8860850450074723
OGBNanLabelBCEWithLogitsLoss: 0.14425852596759797
Statistics on  train
mean_pred: 0.29006728529930115
std_pred: 6.123788356781006
mean_targets: 0.5067738890647888
std_targets: 0.500059962272644
prcauc: 0.9592817469619508
rocauc: 0.9894498861006124
ogbg-molclintox: 0.9894498861006124
OGBNanLabelBCEWithLogitsLoss: 0.06633849752834067
All runs completed.
[Epoch 84; Iter    30/   30] train: loss: 0.2078491
[Epoch 84] ogbg-molclintox: 0.904416 val loss: 0.171129
[Epoch 84] ogbg-molclintox: 0.888031 test loss: 0.145821
[Epoch 85; Iter    30/   30] train: loss: 0.0088656
[Epoch 85] ogbg-molclintox: 0.900459 val loss: 0.170416
[Epoch 85] ogbg-molclintox: 0.914833 test loss: 0.126083
[Epoch 86; Iter    30/   30] train: loss: 0.0529300
[Epoch 86] ogbg-molclintox: 0.898326 val loss: 0.177587
[Epoch 86] ogbg-molclintox: 0.921460 test loss: 0.130908
[Epoch 87; Iter    30/   30] train: loss: 0.1283041
[Epoch 87] ogbg-molclintox: 0.877697 val loss: 0.199532
[Epoch 87] ogbg-molclintox: 0.918342 test loss: 0.139628
[Epoch 88; Iter    30/   30] train: loss: 0.0868345
[Epoch 88] ogbg-molclintox: 0.906361 val loss: 0.193344
[Epoch 88] ogbg-molclintox: 0.918769 test loss: 0.142630
[Epoch 89; Iter    30/   30] train: loss: 0.1156019
[Epoch 89] ogbg-molclintox: 0.872977 val loss: 0.208852
[Epoch 89] ogbg-molclintox: 0.894800 test loss: 0.146666
[Epoch 90; Iter    30/   30] train: loss: 0.0380140
[Epoch 90] ogbg-molclintox: 0.877704 val loss: 0.213768
[Epoch 90] ogbg-molclintox: 0.903393 test loss: 0.144966
[Epoch 91; Iter    30/   30] train: loss: 0.2121190
[Epoch 91] ogbg-molclintox: 0.884422 val loss: 0.193151
[Epoch 91] ogbg-molclintox: 0.918424 test loss: 0.130377
[Epoch 92; Iter    30/   30] train: loss: 0.0285323
[Epoch 92] ogbg-molclintox: 0.901983 val loss: 0.194881
[Epoch 92] ogbg-molclintox: 0.932938 test loss: 0.131774
[Epoch 93; Iter    30/   30] train: loss: 0.2321952
[Epoch 93] ogbg-molclintox: 0.888627 val loss: 0.195437
[Epoch 93] ogbg-molclintox: 0.913086 test loss: 0.140902
[Epoch 94; Iter    30/   30] train: loss: 0.0750298
[Epoch 94] ogbg-molclintox: 0.901281 val loss: 0.188863
[Epoch 94] ogbg-molclintox: 0.901478 test loss: 0.141812
[Epoch 95; Iter    30/   30] train: loss: 0.0165855
[Epoch 95] ogbg-molclintox: 0.916268 val loss: 0.185426
[Epoch 95] ogbg-molclintox: 0.932467 test loss: 0.129017
[Epoch 96; Iter    30/   30] train: loss: 0.0224037
[Epoch 96] ogbg-molclintox: 0.913440 val loss: 0.174792
[Epoch 96] ogbg-molclintox: 0.922946 test loss: 0.131366
[Epoch 97; Iter    30/   30] train: loss: 0.1517035
[Epoch 97] ogbg-molclintox: 0.902116 val loss: 0.184856
[Epoch 97] ogbg-molclintox: 0.928089 test loss: 0.130189
[Epoch 98; Iter    30/   30] train: loss: 0.0200359
[Epoch 98] ogbg-molclintox: 0.870450 val loss: 0.201049
[Epoch 98] ogbg-molclintox: 0.908306 test loss: 0.142737
[Epoch 99; Iter    30/   30] train: loss: 0.1539948
[Epoch 99] ogbg-molclintox: 0.884702 val loss: 0.198289
[Epoch 99] ogbg-molclintox: 0.914223 test loss: 0.143639
[Epoch 100; Iter    30/   30] train: loss: 0.0560040
[Epoch 100] ogbg-molclintox: 0.883519 val loss: 0.205478
[Epoch 100] ogbg-molclintox: 0.921016 test loss: 0.142298
[Epoch 101; Iter    30/   30] train: loss: 0.0164255
[Epoch 101] ogbg-molclintox: 0.877456 val loss: 0.205565
[Epoch 101] ogbg-molclintox: 0.911135 test loss: 0.144685
[Epoch 102; Iter    30/   30] train: loss: 0.1047800
[Epoch 102] ogbg-molclintox: 0.890537 val loss: 0.195541
[Epoch 102] ogbg-molclintox: 0.917917 test loss: 0.143926
[Epoch 103; Iter    30/   30] train: loss: 0.1840766
[Epoch 103] ogbg-molclintox: 0.898251 val loss: 0.199715
[Epoch 103] ogbg-molclintox: 0.905957 test loss: 0.161596
[Epoch 104; Iter    30/   30] train: loss: 0.0087484
[Epoch 104] ogbg-molclintox: 0.892175 val loss: 0.186211
[Epoch 104] ogbg-molclintox: 0.898682 test loss: 0.156091
[Epoch 105; Iter    30/   30] train: loss: 0.1244682
[Epoch 105] ogbg-molclintox: 0.909843 val loss: 0.163887
[Epoch 105] ogbg-molclintox: 0.914272 test loss: 0.137628
[Epoch 106; Iter    30/   30] train: loss: 0.0088683
[Epoch 106] ogbg-molclintox: 0.885604 val loss: 0.191440
[Epoch 106] ogbg-molclintox: 0.923384 test loss: 0.148009
[Epoch 107; Iter    30/   30] train: loss: 0.0344491
[Epoch 107] ogbg-molclintox: 0.910485 val loss: 0.182612
[Epoch 107] ogbg-molclintox: 0.922590 test loss: 0.136882
[Epoch 108; Iter    30/   30] train: loss: 0.0257536
[Epoch 108] ogbg-molclintox: 0.905191 val loss: 0.186189
[Epoch 108] ogbg-molclintox: 0.922611 test loss: 0.143098
[Epoch 109; Iter    30/   30] train: loss: 0.0541021
[Epoch 109] ogbg-molclintox: 0.883686 val loss: 0.195223
[Epoch 109] ogbg-molclintox: 0.901631 test loss: 0.155447
[Epoch 110; Iter    30/   30] train: loss: 0.0453891
[Epoch 110] ogbg-molclintox: 0.903901 val loss: 0.172690
[Epoch 110] ogbg-molclintox: 0.895840 test loss: 0.150789
[Epoch 111; Iter    30/   30] train: loss: 0.0207349
[Epoch 111] ogbg-molclintox: 0.858030 val loss: 0.208304
[Epoch 111] ogbg-molclintox: 0.868892 test loss: 0.169653
[Epoch 112; Iter    30/   30] train: loss: 0.1984756
[Epoch 112] ogbg-molclintox: 0.864485 val loss: 0.236044
[Epoch 112] ogbg-molclintox: 0.859326 test loss: 0.204586
[Epoch 113; Iter    30/   30] train: loss: 0.0195003
[Epoch 113] ogbg-molclintox: 0.879138 val loss: 0.211866
[Epoch 113] ogbg-molclintox: 0.870574 test loss: 0.182155
[Epoch 114; Iter    30/   30] train: loss: 0.0524087
[Epoch 114] ogbg-molclintox: 0.891753 val loss: 0.202526
[Epoch 114] ogbg-molclintox: 0.891703 test loss: 0.159816
[Epoch 115; Iter    30/   30] train: loss: 0.0400551
[Epoch 115] ogbg-molclintox: 0.890790 val loss: 0.200175
[Epoch 115] ogbg-molclintox: 0.862050 test loss: 0.164699
[Epoch 116; Iter    30/   30] train: loss: 0.2069624
[Epoch 116] ogbg-molclintox: 0.875663 val loss: 0.217638
[Epoch 116] ogbg-molclintox: 0.879217 test loss: 0.169511
[Epoch 117; Iter    30/   30] train: loss: 0.2263398
[Epoch 117] ogbg-molclintox: 0.870094 val loss: 0.202762
[Epoch 117] ogbg-molclintox: 0.879299 test loss: 0.147664
[Epoch 118; Iter    30/   30] train: loss: 0.1271236
[Epoch 118] ogbg-molclintox: 0.894875 val loss: 0.195719
[Epoch 118] ogbg-molclintox: 0.883846 test loss: 0.148064
[Epoch 119; Iter    30/   30] train: loss: 0.1789083
[Epoch 119] ogbg-molclintox: 0.883999 val loss: 0.211936
[Epoch 119] ogbg-molclintox: 0.897290 test loss: 0.154603
[Epoch 120; Iter    30/   30] train: loss: 0.0312871
[Epoch 120] ogbg-molclintox: 0.890871 val loss: 0.205726
[Epoch 120] ogbg-molclintox: 0.893214 test loss: 0.162162
[Epoch 121; Iter    30/   30] train: loss: 0.0768957
[Epoch 121] ogbg-molclintox: 0.865756 val loss: 0.220944
[Epoch 121] ogbg-molclintox: 0.890325 test loss: 0.158519
[Epoch 122; Iter    30/   30] train: loss: 0.0875229
[Epoch 122] ogbg-molclintox: 0.875436 val loss: 0.218236
[Epoch 122] ogbg-molclintox: 0.902856 test loss: 0.163183
[Epoch 123; Iter    30/   30] train: loss: 0.0118392
[Epoch 123] ogbg-molclintox: 0.876672 val loss: 0.207863
[Epoch 123] ogbg-molclintox: 0.908900 test loss: 0.144192
[Epoch 124; Iter    30/   30] train: loss: 0.0085714
[Epoch 124] ogbg-molclintox: 0.881939 val loss: 0.212698
[Epoch 124] ogbg-molclintox: 0.891175 test loss: 0.165759
[Epoch 125; Iter    30/   30] train: loss: 0.0159618
[Epoch 125] ogbg-molclintox: 0.872581 val loss: 0.233073
[Epoch 125] ogbg-molclintox: 0.896212 test loss: 0.175575
[Epoch 126; Iter    30/   30] train: loss: 0.0516488
[Epoch 126] ogbg-molclintox: 0.882628 val loss: 0.211404
[Epoch 126] ogbg-molclintox: 0.896015 test loss: 0.165375
[Epoch 127; Iter    30/   30] train: loss: 0.0534479
[Epoch 127] ogbg-molclintox: 0.881057 val loss: 0.213725
[Epoch 127] ogbg-molclintox: 0.900392 test loss: 0.160343
[Epoch 128; Iter    30/   30] train: loss: 0.0245023
[Epoch 128] ogbg-molclintox: 0.890924 val loss: 0.214091
[Epoch 128] ogbg-molclintox: 0.919071 test loss: 0.153216
[Epoch 129; Iter    30/   30] train: loss: 0.0125456
[Epoch 129] ogbg-molclintox: 0.894781 val loss: 0.192796
[Epoch 129] ogbg-molclintox: 0.907907 test loss: 0.152399
[Epoch 130; Iter    30/   30] train: loss: 0.0235139
[Epoch 130] ogbg-molclintox: 0.904174 val loss: 0.190349
[Epoch 130] ogbg-molclintox: 0.905062 test loss: 0.148146
[Epoch 131; Iter    30/   30] train: loss: 0.0261702
[Epoch 131] ogbg-molclintox: 0.891159 val loss: 0.208847
[Epoch 131] ogbg-molclintox: 0.898698 test loss: 0.170772
[Epoch 132; Iter    30/   30] train: loss: 0.1087833
[Epoch 132] ogbg-molclintox: 0.897730 val loss: 0.198230
[Epoch 132] ogbg-molclintox: 0.911383 test loss: 0.143294
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 133; Iter    30/   30] train: loss: 0.0099599
[Epoch 133] ogbg-molclintox: 0.891058 val loss: 0.234033
[Epoch 133] ogbg-molclintox: 0.904474 test loss: 0.176067
[Epoch 134; Iter    30/   30] train: loss: 0.1545774
[Epoch 134] ogbg-molclintox: 0.889654 val loss: 0.209002
[Epoch 134] ogbg-molclintox: 0.912345 test loss: 0.143161
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 134 epochs. Best model checkpoint was in epoch 74.
Statistics on  val_best_checkpoint
mean_pred: 0.1421658992767334
std_pred: 5.418717861175537
mean_targets: 0.505084753036499
std_targets: 0.5003983974456787
prcauc: 0.7808426685035013
rocauc: 0.9420034072462331
ogbg-molclintox: 0.9420034072462331
OGBNanLabelBCEWithLogitsLoss: 0.1609454981982708
Statistics on  test
mean_pred: 0.18474237620830536
std_pred: 5.3624067306518555
mean_targets: 0.5033783912658691
std_targets: 0.5004113912582397
prcauc: 0.7862370913864798
rocauc: 0.9078916540020263
ogbg-molclintox: 0.9078916540020263
OGBNanLabelBCEWithLogitsLoss: 0.1416464754845947
Statistics on  train
mean_pred: 0.28032103180885315
std_pred: 5.752659797668457
mean_targets: 0.5073363780975342
std_targets: 0.500087320804596
prcauc: 0.9384645786327213
rocauc: 0.9869387670528511
ogbg-molclintox: 0.9869387670528511
OGBNanLabelBCEWithLogitsLoss: 0.07788324064264694
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 126] ogbg-molclintox: 0.966824 val loss: 0.126326
[Epoch 126] ogbg-molclintox: 0.869108 test loss: 0.140079
[Epoch 127; Iter    30/   35] train: loss: 0.0850122
[Epoch 127] ogbg-molclintox: 0.941379 val loss: 0.138079
[Epoch 127] ogbg-molclintox: 0.869227 test loss: 0.148676
[Epoch 128; Iter    25/   35] train: loss: 0.0458061
[Epoch 128] ogbg-molclintox: 0.965203 val loss: 0.113908
[Epoch 128] ogbg-molclintox: 0.859477 test loss: 0.147427
[Epoch 129; Iter    20/   35] train: loss: 0.0422033
[Epoch 129] ogbg-molclintox: 0.960461 val loss: 0.161738
[Epoch 129] ogbg-molclintox: 0.836324 test loss: 0.168603
[Epoch 130; Iter    15/   35] train: loss: 0.2311201
[Epoch 130] ogbg-molclintox: 0.961637 val loss: 0.114912
[Epoch 130] ogbg-molclintox: 0.838898 test loss: 0.151775
[Epoch 131; Iter    10/   35] train: loss: 0.0119598
[Epoch 131] ogbg-molclintox: 0.973302 val loss: 0.103079
[Epoch 131] ogbg-molclintox: 0.863842 test loss: 0.142528
[Epoch 132; Iter     5/   35] train: loss: 0.0048793
[Epoch 132; Iter    35/   35] train: loss: 0.0242566
[Epoch 132] ogbg-molclintox: 0.969761 val loss: 0.107906
[Epoch 132] ogbg-molclintox: 0.847368 test loss: 0.138733
[Epoch 133; Iter    30/   35] train: loss: 0.0579138
[Epoch 133] ogbg-molclintox: 0.971494 val loss: 0.102805
[Epoch 133] ogbg-molclintox: 0.851994 test loss: 0.146100
[Epoch 134; Iter    25/   35] train: loss: 0.1063620
[Epoch 134] ogbg-molclintox: 0.970083 val loss: 0.104360
[Epoch 134] ogbg-molclintox: 0.850094 test loss: 0.154783
[Epoch 135; Iter    20/   35] train: loss: 0.0830517
[Epoch 135] ogbg-molclintox: 0.954778 val loss: 0.129392
[Epoch 135] ogbg-molclintox: 0.831619 test loss: 0.157939
[Epoch 136; Iter    15/   35] train: loss: 0.0047785
[Epoch 136] ogbg-molclintox: 0.965637 val loss: 0.144282
[Epoch 136] ogbg-molclintox: 0.857039 test loss: 0.148227
[Epoch 137; Iter    10/   35] train: loss: 0.0445362
[Epoch 137] ogbg-molclintox: 0.963692 val loss: 0.122543
[Epoch 137] ogbg-molclintox: 0.841415 test loss: 0.157464
[Epoch 138; Iter     5/   35] train: loss: 0.0909557
[Epoch 138; Iter    35/   35] train: loss: 0.0187709
[Epoch 138] ogbg-molclintox: 0.960820 val loss: 0.122194
[Epoch 138] ogbg-molclintox: 0.840009 test loss: 0.162404
[Epoch 139; Iter    30/   35] train: loss: 0.0065258
[Epoch 139] ogbg-molclintox: 0.954096 val loss: 0.128947
[Epoch 139] ogbg-molclintox: 0.828269 test loss: 0.162417
[Epoch 140; Iter    25/   35] train: loss: 0.0734281
[Epoch 140] ogbg-molclintox: 0.961662 val loss: 0.123859
[Epoch 140] ogbg-molclintox: 0.876864 test loss: 0.143880
[Epoch 141; Iter    20/   35] train: loss: 0.0081206
[Epoch 141] ogbg-molclintox: 0.964113 val loss: 0.120347
[Epoch 141] ogbg-molclintox: 0.845571 test loss: 0.158486
[Epoch 142; Iter    15/   35] train: loss: 0.0340948
[Epoch 142] ogbg-molclintox: 0.963135 val loss: 0.120628
[Epoch 142] ogbg-molclintox: 0.851149 test loss: 0.155470
[Epoch 143; Iter    10/   35] train: loss: 0.0331432
[Epoch 143] ogbg-molclintox: 0.966714 val loss: 0.122229
[Epoch 143] ogbg-molclintox: 0.864278 test loss: 0.152724
[Epoch 144; Iter     5/   35] train: loss: 0.0706415
[Epoch 144; Iter    35/   35] train: loss: 0.0716511
[Epoch 144] ogbg-molclintox: 0.965736 val loss: 0.125534
[Epoch 144] ogbg-molclintox: 0.866138 test loss: 0.150990
[Epoch 145; Iter    30/   35] train: loss: 0.0263456
[Epoch 145] ogbg-molclintox: 0.964572 val loss: 0.121535
[Epoch 145] ogbg-molclintox: 0.851172 test loss: 0.160638
[Epoch 146; Iter    25/   35] train: loss: 0.0928025
[Epoch 146] ogbg-molclintox: 0.961700 val loss: 0.120694
[Epoch 146] ogbg-molclintox: 0.848326 test loss: 0.156781
[Epoch 147; Iter    20/   35] train: loss: 0.0367790
[Epoch 147] ogbg-molclintox: 0.959669 val loss: 0.121371
[Epoch 147] ogbg-molclintox: 0.843910 test loss: 0.157619
[Epoch 148; Iter    15/   35] train: loss: 0.0218269
[Epoch 148] ogbg-molclintox: 0.958580 val loss: 0.128312
[Epoch 148] ogbg-molclintox: 0.837209 test loss: 0.162013
[Epoch 149; Iter    10/   35] train: loss: 0.0400099
[Epoch 149] ogbg-molclintox: 0.959073 val loss: 0.122024
[Epoch 149] ogbg-molclintox: 0.865503 test loss: 0.151937
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 149 epochs. Best model checkpoint was in epoch 89.
Statistics on  val_best_checkpoint
mean_pred: 0.07259979844093323
std_pred: 6.325323581695557
mean_targets: 0.5067567825317383
std_targets: 0.500518262386322
prcauc: 0.9387899107427626
rocauc: 0.9805827886710239
ogbg-molclintox: 0.9805827886710239
OGBNanLabelBCEWithLogitsLoss: 0.11256532958941534
Statistics on  test
mean_pred: 0.15330232679843903
std_pred: 5.968489646911621
mean_targets: 0.5022522807121277
std_targets: 0.5005589127540588
prcauc: 0.8269862572669884
rocauc: 0.9317679161281057
ogbg-molclintox: 0.9317679161281057
OGBNanLabelBCEWithLogitsLoss: 0.10104484064504504
Statistics on  train
mean_pred: 0.21230722963809967
std_pred: 6.879713535308838
mean_targets: 0.5067763924598694
std_targets: 0.500075101852417
prcauc: 0.9720866877276853
rocauc: 0.9953154727928172
ogbg-molclintox: 0.9953154727928172
OGBNanLabelBCEWithLogitsLoss: 0.04693469910749367
All runs completed.
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 133; Iter    30/   30] train: loss: 0.0803595
[Epoch 133] ogbg-molclintox: 0.882335 val loss: 0.188061
[Epoch 133] ogbg-molclintox: 0.934135 test loss: 0.148119
[Epoch 134; Iter    30/   30] train: loss: 0.1186038
[Epoch 134] ogbg-molclintox: 0.864179 val loss: 0.219526
[Epoch 134] ogbg-molclintox: 0.934835 test loss: 0.237247
[Epoch 135; Iter    30/   30] train: loss: 0.1156898
[Epoch 135] ogbg-molclintox: 0.896768 val loss: 0.180074
[Epoch 135] ogbg-molclintox: 0.941566 test loss: 0.261772
[Epoch 136; Iter    30/   30] train: loss: 0.0167348
[Epoch 136] ogbg-molclintox: 0.888258 val loss: 0.193833
[Epoch 136] ogbg-molclintox: 0.941605 test loss: 0.137761
[Epoch 137; Iter    30/   30] train: loss: 0.0073187
[Epoch 137] ogbg-molclintox: 0.862422 val loss: 0.215038
[Epoch 137] ogbg-molclintox: 0.937901 test loss: 0.138767
[Epoch 138; Iter    30/   30] train: loss: 0.0029686
[Epoch 138] ogbg-molclintox: 0.886326 val loss: 0.270937
[Epoch 138] ogbg-molclintox: 0.942601 test loss: 0.140977
[Epoch 139; Iter    30/   30] train: loss: 0.0534418
[Epoch 139] ogbg-molclintox: 0.886119 val loss: 0.194207
[Epoch 139] ogbg-molclintox: 0.931581 test loss: 0.145951
[Epoch 140; Iter    30/   30] train: loss: 0.0902457
[Epoch 140] ogbg-molclintox: 0.892744 val loss: 0.190471
[Epoch 140] ogbg-molclintox: 0.938366 test loss: 0.147710
[Epoch 141; Iter    30/   30] train: loss: 0.0919262
[Epoch 141] ogbg-molclintox: 0.884595 val loss: 0.197271
[Epoch 141] ogbg-molclintox: 0.941409 test loss: 0.139507
[Epoch 142; Iter    30/   30] train: loss: 0.0062312
[Epoch 142] ogbg-molclintox: 0.878083 val loss: 0.205466
[Epoch 142] ogbg-molclintox: 0.938333 test loss: 0.152542
[Epoch 143; Iter    30/   30] train: loss: 0.1570906
[Epoch 143] ogbg-molclintox: 0.872997 val loss: 0.210019
[Epoch 143] ogbg-molclintox: 0.938194 test loss: 0.144417
[Epoch 144; Iter    30/   30] train: loss: 0.0462649
[Epoch 144] ogbg-molclintox: 0.873224 val loss: 0.211277
[Epoch 144] ogbg-molclintox: 0.931957 test loss: 0.144991
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 144 epochs. Best model checkpoint was in epoch 84.
Statistics on  val_best_checkpoint
mean_pred: 0.16618473827838898
std_pred: 5.102477550506592
mean_targets: 0.505084753036499
std_targets: 0.5003983974456787
prcauc: 0.8331491196302208
rocauc: 0.9404456565975974
ogbg-molclintox: 0.9404456565975974
OGBNanLabelBCEWithLogitsLoss: 0.13976710066199302
Statistics on  test
mean_pred: 0.14667214453220367
std_pred: 5.3780035972595215
mean_targets: 0.5033783912658691
std_targets: 0.5004113912582397
prcauc: 0.7125242744856684
rocauc: 0.9303468528368795
ogbg-molclintox: 0.9303468528368795
OGBNanLabelBCEWithLogitsLoss: 0.18457182552665471
Statistics on  train
mean_pred: 0.26946544647216797
std_pred: 5.748112201690674
mean_targets: 0.5073363780975342
std_targets: 0.500087320804596
prcauc: 0.9384373485914849
rocauc: 0.9883971379574539
ogbg-molclintox: 0.9883971379574539
OGBNanLabelBCEWithLogitsLoss: 0.07848179352780184
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 133; Iter    30/   30] train: loss: 0.2114609
[Epoch 133] ogbg-molclintox: 0.868405 val loss: 0.225270
[Epoch 133] ogbg-molclintox: 0.943575 test loss: 0.242125
[Epoch 134; Iter    30/   30] train: loss: 0.0608058
[Epoch 134] ogbg-molclintox: 0.847274 val loss: 0.250817
[Epoch 134] ogbg-molclintox: 0.950008 test loss: 0.225184
[Epoch 135; Iter    30/   30] train: loss: 0.0135990
[Epoch 135] ogbg-molclintox: 0.848571 val loss: 0.248203
[Epoch 135] ogbg-molclintox: 0.948475 test loss: 0.263775
[Epoch 136; Iter    30/   30] train: loss: 0.0680718
[Epoch 136] ogbg-molclintox: 0.830529 val loss: 0.249263
[Epoch 136] ogbg-molclintox: 0.943161 test loss: 0.271142
[Epoch 137; Iter    30/   30] train: loss: 0.0148562
[Epoch 137] ogbg-molclintox: 0.836097 val loss: 0.251841
[Epoch 137] ogbg-molclintox: 0.942494 test loss: 0.211745
[Epoch 138; Iter    30/   30] train: loss: 0.0505060
[Epoch 138] ogbg-molclintox: 0.848952 val loss: 0.236851
[Epoch 138] ogbg-molclintox: 0.956175 test loss: 0.200598
[Epoch 139; Iter    30/   30] train: loss: 0.0681647
[Epoch 139] ogbg-molclintox: 0.839359 val loss: 0.246967
[Epoch 139] ogbg-molclintox: 0.956917 test loss: 0.216120
[Epoch 140; Iter    30/   30] train: loss: 0.0107728
[Epoch 140] ogbg-molclintox: 0.837106 val loss: 0.260327
[Epoch 140] ogbg-molclintox: 0.954558 test loss: 0.189899
[Epoch 141; Iter    30/   30] train: loss: 0.1894929
[Epoch 141] ogbg-molclintox: 0.833911 val loss: 0.244856
[Epoch 141] ogbg-molclintox: 0.953074 test loss: 0.183705
[Epoch 142; Iter    30/   30] train: loss: 0.0109721
[Epoch 142] ogbg-molclintox: 0.842187 val loss: 0.256905
[Epoch 142] ogbg-molclintox: 0.944554 test loss: 0.152648
[Epoch 143; Iter    30/   30] train: loss: 0.1042311
[Epoch 143] ogbg-molclintox: 0.848791 val loss: 0.236837
[Epoch 143] ogbg-molclintox: 0.949495 test loss: 0.234825
[Epoch 144; Iter    30/   30] train: loss: 0.0328157
[Epoch 144] ogbg-molclintox: 0.859821 val loss: 0.232237
[Epoch 144] ogbg-molclintox: 0.960774 test loss: 0.239944
[Epoch 145; Iter    30/   30] train: loss: 0.0192091
[Epoch 145] ogbg-molclintox: 0.838684 val loss: 0.237781
[Epoch 145] ogbg-molclintox: 0.953865 test loss: 0.195109
[Epoch 146; Iter    30/   30] train: loss: 0.0330618
[Epoch 146] ogbg-molclintox: 0.839186 val loss: 0.259159
[Epoch 146] ogbg-molclintox: 0.931096 test loss: 0.227411
[Epoch 147; Iter    30/   30] train: loss: 0.0127360
[Epoch 147] ogbg-molclintox: 0.842575 val loss: 0.263708
[Epoch 147] ogbg-molclintox: 0.933286 test loss: 0.287470
[Epoch 148; Iter    30/   30] train: loss: 0.1163039
[Epoch 148] ogbg-molclintox: 0.864180 val loss: 0.241419
[Epoch 148] ogbg-molclintox: 0.946241 test loss: 0.252606
[Epoch 149; Iter    30/   30] train: loss: 0.0046590
[Epoch 149] ogbg-molclintox: 0.862515 val loss: 0.259769
[Epoch 149] ogbg-molclintox: 0.944477 test loss: 0.253496
[Epoch 150; Iter    30/   30] train: loss: 0.0474553
[Epoch 150] ogbg-molclintox: 0.864808 val loss: 0.235720
[Epoch 150] ogbg-molclintox: 0.942244 test loss: 0.198346
[Epoch 151; Iter    30/   30] train: loss: 0.0232505
[Epoch 151] ogbg-molclintox: 0.856827 val loss: 0.244372
[Epoch 151] ogbg-molclintox: 0.941686 test loss: 0.169285
[Epoch 152; Iter    30/   30] train: loss: 0.0079625
[Epoch 152] ogbg-molclintox: 0.873940 val loss: 0.238494
[Epoch 152] ogbg-molclintox: 0.942588 test loss: 0.227874
[Epoch 153; Iter    30/   30] train: loss: 0.0189574
[Epoch 153] ogbg-molclintox: 0.875624 val loss: 0.231993
[Epoch 153] ogbg-molclintox: 0.945975 test loss: 0.237098
[Epoch 154; Iter    30/   30] train: loss: 0.2024808
[Epoch 154] ogbg-molclintox: 0.877409 val loss: 0.220475
[Epoch 154] ogbg-molclintox: 0.950047 test loss: 0.167160
[Epoch 155; Iter    30/   30] train: loss: 0.1510102
[Epoch 155] ogbg-molclintox: 0.854868 val loss: 0.240836
[Epoch 155] ogbg-molclintox: 0.947767 test loss: 0.182808
[Epoch 156; Iter    30/   30] train: loss: 0.0027709
[Epoch 156] ogbg-molclintox: 0.877516 val loss: 0.213790
[Epoch 156] ogbg-molclintox: 0.953135 test loss: 0.164043
[Epoch 157; Iter    30/   30] train: loss: 0.0769440
[Epoch 157] ogbg-molclintox: 0.874635 val loss: 0.236106
[Epoch 157] ogbg-molclintox: 0.949347 test loss: 0.169269
[Epoch 158; Iter    30/   30] train: loss: 0.0700631
[Epoch 158] ogbg-molclintox: 0.870550 val loss: 0.222190
[Epoch 158] ogbg-molclintox: 0.949600 test loss: 0.219174
[Epoch 159; Iter    30/   30] train: loss: 0.0056879
[Epoch 159] ogbg-molclintox: 0.883947 val loss: 0.243817
[Epoch 159] ogbg-molclintox: 0.947806 test loss: 0.245731
[Epoch 160; Iter    30/   30] train: loss: 0.0585001
[Epoch 160] ogbg-molclintox: 0.870016 val loss: 0.222264
[Epoch 160] ogbg-molclintox: 0.947561 test loss: 0.192170
[Epoch 161; Iter    30/   30] train: loss: 0.1166464
[Epoch 161] ogbg-molclintox: 0.861285 val loss: 0.238675
[Epoch 161] ogbg-molclintox: 0.937325 test loss: 0.194490
[Epoch 162; Iter    30/   30] train: loss: 0.0015987
[Epoch 162] ogbg-molclintox: 0.864894 val loss: 0.245146
[Epoch 162] ogbg-molclintox: 0.944702 test loss: 0.214086
[Epoch 163; Iter    30/   30] train: loss: 0.0493925
[Epoch 163] ogbg-molclintox: 0.861659 val loss: 0.235810
[Epoch 163] ogbg-molclintox: 0.949085 test loss: 0.180583
[Epoch 164; Iter    30/   30] train: loss: 0.0066514
[Epoch 164] ogbg-molclintox: 0.875342 val loss: 0.240778
[Epoch 164] ogbg-molclintox: 0.950933 test loss: 0.187067
[Epoch 165; Iter    30/   30] train: loss: 0.0416479
[Epoch 165] ogbg-molclintox: 0.856887 val loss: 0.239633
[Epoch 165] ogbg-molclintox: 0.952436 test loss: 0.137164
[Epoch 166; Iter    30/   30] train: loss: 0.0094209
[Epoch 166] ogbg-molclintox: 0.847668 val loss: 0.258608
[Epoch 166] ogbg-molclintox: 0.951199 test loss: 0.163184
[Epoch 167; Iter    30/   30] train: loss: 0.1005812
[Epoch 167] ogbg-molclintox: 0.839192 val loss: 0.255674
[Epoch 167] ogbg-molclintox: 0.952622 test loss: 0.167717
[Epoch 168; Iter    30/   30] train: loss: 0.1360411
[Epoch 168] ogbg-molclintox: 0.827882 val loss: 0.288798
[Epoch 168] ogbg-molclintox: 0.946756 test loss: 0.190216
[Epoch 169; Iter    30/   30] train: loss: 0.0046731
[Epoch 169] ogbg-molclintox: 0.834453 val loss: 0.259215
[Epoch 169] ogbg-molclintox: 0.941167 test loss: 0.204047
[Epoch 170; Iter    30/   30] train: loss: 0.0567422
[Epoch 170] ogbg-molclintox: 0.843304 val loss: 0.257719
[Epoch 170] ogbg-molclintox: 0.940796 test loss: 0.191020
[Epoch 171; Iter    30/   30] train: loss: 0.1029444
[Epoch 171] ogbg-molclintox: 0.850517 val loss: 0.255055
[Epoch 171] ogbg-molclintox: 0.951289 test loss: 0.158804
[Epoch 172; Iter    30/   30] train: loss: 0.0035137
[Epoch 172] ogbg-molclintox: 0.850115 val loss: 0.264455
[Epoch 172] ogbg-molclintox: 0.951974 test loss: 0.216411
[Epoch 173; Iter    30/   30] train: loss: 0.0823209
[Epoch 173] ogbg-molclintox: 0.851305 val loss: 0.269678
[Epoch 173] ogbg-molclintox: 0.951000 test loss: 0.188675
[Epoch 174; Iter    30/   30] train: loss: 0.0552869
[Epoch 174] ogbg-molclintox: 0.838878 val loss: 0.251856
[Epoch 174] ogbg-molclintox: 0.950040 test loss: 0.146155
[Epoch 175; Iter    30/   30] train: loss: 0.0533868
[Epoch 175] ogbg-molclintox: 0.844975 val loss: 0.250249
[Epoch 175] ogbg-molclintox: 0.951678 test loss: 0.191662
[Epoch 176; Iter    30/   30] train: loss: 0.0229092
[Epoch 176] ogbg-molclintox: 0.843818 val loss: 0.259085
[Epoch 176] ogbg-molclintox: 0.951560 test loss: 0.140129
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 176 epochs. Best model checkpoint was in epoch 116.
Statistics on  val_best_checkpoint
mean_pred: 0.24543094635009766
std_pred: 6.242282390594482
mean_targets: 0.505084753036499
std_targets: 0.5003983974456787
prcauc: 0.8080109977602129
rocauc: 0.9043812769602645
ogbg-molclintox: 0.9043812769602645
OGBNanLabelBCEWithLogitsLoss: 0.17108923606574536
Statistics on  test
mean_pred: 0.09388278424739838
std_pred: 9.799104690551758
mean_targets: 0.5033783912658691
std_targets: 0.5004113912582397
prcauc: 0.740914501770834
rocauc: 0.9453283308004052
ogbg-molclintox: 0.9453283308004052
OGBNanLabelBCEWithLogitsLoss: 0.6121602797415108
Statistics on  train
mean_pred: 0.3059234619140625
std_pred: 6.7004008293151855
mean_targets: 0.5073363780975342
std_targets: 0.500087320804596
prcauc: 0.9737045782582747
rocauc: 0.9952020411513369
ogbg-molclintox: 0.9952020411513369
OGBNanLabelBCEWithLogitsLoss: 0.04825090820280214
All runs completed.
